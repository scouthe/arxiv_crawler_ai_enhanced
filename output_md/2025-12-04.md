# 论文全览：2025-12-04

共有306篇相关领域论文, 另有0篇其他

## 天体物理学仪器和方法(astro-ph.IM:Instrumentation and Methods for Astrophysics)

【1】Machine Phenomenology: A Simple Equation Classifying Fast Radio Bursts
- **标题**: 机器现象学：快速无线电爆发分类的简单方程
- **链接**: https://arxiv.org/abs/2512.04204
> **作者**: Yang Liu,Yuhao Lu,Rahim Moradi,Bo Yang,Bing Zhang,Wenbin Lin,Yu Wang
> **摘要**: 这项工作展示了人类物理推理如何引导机器驱动的符号回归从观察中发现经验规律。作为一个例子，我们推导出一个简单的方程，将快速无线电爆发（FRB）分为两个不同的高斯分布，表明存在两个物理类别。这种人类人工智能工作流程集成了特征选择、维度分析和符号回归：深度学习首先分析 CHIME Catalog 1 并识别六个独立参数，这些参数共同提供了 FRB 的完整描述；在 Buckingham-$π$ 分析和相关性分析的指导下，人类构建无量纲群；最后，机器执行的符号回归发现了控制方程。当应用于较新的 CHIME Catalog 时，该方程产生一致的结果，表明它捕获了底层物理原理。该框架适用于广泛的科学领域。
> **Abstract**: This work shows how human physical reasoning can guide machine-driven symbolic regression toward discovering empirical laws from observations. As an example, we derive a simple equation that classifies fast radio bursts (FRBs) into two distinct Gaussian distributions, indicating the existence of two physical classes. This human-AI workflow integrates feature selection, dimensional analysis, and symbolic regression: deep learning first analyzes CHIME Catalog 1 and identifies six independent parameters that collectively provide a complete description of FRBs; guided by Buckingham-$π$ analysis and correlation analysis, humans then construct dimensionless groups; finally, symbolic regression performed by the machine discovers the governing equation. When applied to the newer CHIME Catalog, the equation produces consistent results, demonstrating that it captures the underlying physics. This framework is applicable to a broad range of scientific domains.

【2】Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study
- **标题**: 有限噪声数据的大型语言模型：引力波识别研究
- **链接**: https://arxiv.org/abs/2512.04031
> **作者**: Yixuan Li,Yuhao Lu,Yang Liu,Liang Li,R. Ruffini,Di Li,Rong-Gen Cai,Xiaoyan Zhu,Wenbin Lin,Yu Wang
> **摘要**: 这项工作研究了在非高斯、非平稳噪声和有限标记样本的情况下，大型语言模型 (LLM) 是否比传统神经网络在天文数据处理方面具有优势。引力波观测提供了合适的测试用例，仅使用 90 个 LIGO 事件，经过微调的 LLM 即可实现 97.4% 的信号识别准确度。进一步的实验表明，与依赖大型模拟数据集的传统网络相比，额外的模拟样本不会提高 LLM 性能，而扩展研究揭示了随着模型大小和数据集大小的增加而获得的可预测收益。这些结果表明LLM可以直接从观测数据中提取判别结构，并为引力波识别提供有效的评估。相同的策略可以扩展到具有类似噪声特性的其他天文学领域，例如射电或脉冲星观测。
> **Abstract**: This work investigates whether large language models (LLMs) offer advantages over traditional neural networks for astronomical data processing, in regimes with non-Gaussian, non-stationary noise and limited labeled samples. Gravitational wave observations provide an suitable test case, using only 90 LIGO events, finetuned LLMs achieve 97.4\% accuracy for identifying signals. Further experiments show that, in contrast to traditional networks that rely on large simulated datasets, additional simulated samples do not improve LLM performance, while scaling studies reveal predictable gains with increasing model size and dataset size. These results indicate that LLMs can extract discriminative structure directly from observational data and provide an efficient assessment for gravitational wave identification. The same strategy may extend to other astronomical domains with similar noise properties, such as radio or pulsar observations.

## 人工智能(cs.AI:Artificial Intelligence)

【1】TaskEval: Synthesised Evaluation for Foundation-Model Tasks
- **标题**: TaskEval：基础模型任务的综合评估
- **链接**: https://arxiv.org/abs/2512.04442
> **作者**: Dilani Widanapathiranage,Scott Barnett,Stefanus Kurniawan,Wannita Takerngsaksiri
> **摘要**: 在创建依赖于基础模型 (FM) 的应用程序时，幻觉是一个关键问题。了解应用程序中这些细微故障发生的位置和方式依赖于称为 \textit{evals} 的评估方法。之前的工作重点是为特定任务定义新的评估方法或基准数据集。然而，当没有指标或数据集时，这两种方法都无法帮助软件团队开发特定于任务的 FM 应用程序。对自动化方法和人类洞察力深度集成的需求使这成为一个具有挑战性的问题。我们通过提出一种综合 FM 特定任务评估程序的方法来解决这一差距，该程序提供自动化和用于捕获反馈的自定义 UI。我们方法的核心新颖性在于：（1）一个与任务无关的元模型，可以捕获任何 FM 任务的属性，（2）一个用于有效利用人类反馈的交互协议，以及（3）一个评估合成器，可以选择或生成一组适当的评估。我们在 \toolname 中实施我们的方法，并在两个不同的 FM 任务上演示该概念：图表数据提取和文档问答。对我们选定的评估质量的初步评估显示准确度分别为 93% 和 90%。我们的研究解决了工程团队面临的一个日益严重的问题，即如何评估和审查 FM 任务的输出。
> **Abstract**: Hallucinations are a key concern when creating applications that rely on Foundation models (FMs). Understanding where and how these subtle failures occur in an application relies on evaluation methods known as \textit{evals}. Prior work focuses on defining new eval methods or benchmark datasets for specific tasks. However, neither helps a software team with a task-specific FM application when there is no metric or dataset. The demand for both automated approaches and deep integration of human insight makes this a challenging problem. We address this gap by proposing an approach to synthesise a FM task-specific evaluator program that provides automation and a custom UI for capturing feedback. The core novelty of our approach lies in: (1) a task-agnostic meta-model that captures properties of any FM task, (2) an interaction protocol for efficient use of human feedback, and (3) an eval synthesiser that selects or generates an appropriate set of evals. We implement our approach in \toolname and demonstrate the concept on two diverse FM tasks: chart data extraction and document question answering. A preliminary evaluation on the quality of our selected evals shows 93\% and 90\% accuracy respectively. Our research tackles a growing problem facing engineering teams, how to evaluate and review outputs from FM tasks.

【2】Solving LLM Repetition Problem in Production: A Comprehensive Study of Multiple Solutions
- **标题**: 解决生产中的LLM重复问题：多种解决方案的综合研究
- **链接**: https://arxiv.org/abs/2512.04419
> **作者**: Weiwei Wang,Weijie Zou,Jiyong Min
> **摘要**: 重复问题是大型语言模型 (LLM) 不断生成重复内容而没有适当终止的情况，这给生产部署带来了严峻的挑战，导致严重的性能下降和系统停滞。本文针对现实批量代码解释任务中遇到的重复问题进行了全面的调查和多种实用的解决方案。我们确定了三种不同的重复模式：（1）业务规则生成重复，（2）方法调用关系分析重复，以及（3）PlantUML 图语法生成重复。通过基于马尔可夫模型的严格理论分析，我们确定根本原因在于贪婪解码无法逃脱重复循环，而自我强化效应加剧了这种循环。我们的综合实验评估展示了三种可行的解决方案：（1）使用early_stopping = True的Beam Search解码作为通用事后机制，有效解决所有三种重复模式； （2）presentation_penalty超参数专门针对BadCase 1提供了有效的解决方案； (3) 直接偏好优化 (DPO) 微调为所有三种 BadCase 提供通用模型级解决方案。这项工作的主要价值在于将第一手生产经验与广泛的实验验证相结合。我们的主要贡献包括重复机制的系统理论分析、通过特定于任务的适用性映射对多种解决方案进行综合评估、将early_stopping识别为波束搜索有效性的关键参数，以及在实际部署环境中验证的实际生产就绪解决方案。
> **Abstract**: The repetition problem, where Large Language Models (LLMs) continuously generate repetitive content without proper termination, poses a critical challenge in production deployments, causing severe performance degradation and system stalling. This paper presents a comprehensive investigation and multiple practical solutions for the repetition problem encountered in real-world batch code interpretation tasks. We identify three distinct repetition patterns: (1) business rule generation repetition, (2) method call relationship analysis repetition, and (3) PlantUML diagram syntax generation repetition. Through rigorous theoretical analysis based on Markov models, we establish that the root cause lies in greedy decoding's inability to escape repetitive loops, exacerbated by self-reinforcement effects. Our comprehensive experimental evaluation demonstrates three viable solutions: (1) Beam Search decoding with early_stopping=True serves as a universal post-hoc mechanism that effectively resolves all three repetition patterns; (2) presence_penalty hyperparameter provides an effective solution specifically for BadCase 1; and (3) Direct Preference Optimization (DPO) fine-tuning offers a universal model-level solution for all three BadCases. The primary value of this work lies in combining first-hand production experience with extensive experimental validation. Our main contributions include systematic theoretical analysis of repetition mechanisms, comprehensive evaluation of multiple solutions with task-specific applicability mapping, identification of early_stopping as the critical parameter for Beam Search effectiveness, and practical production-ready solutions validated in real deployment environments.

【3】GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows
- **标题**: GovBench：真实世界数据治理工作流程的 LLM 代理基准测试
- **链接**: https://arxiv.org/abs/2512.04416
> **作者**: Zhou Liu,Zhaoyang Han,Guochen Yan,Hao Liang,Bohan Zeng,Xing Chen,Yuanfeng Song,Wentao Zhang
> **摘要**: 数据治理通过政策和标准确保数据质量、安全性和合规性，这是扩展现代人工智能开发的关键基础。最近，大语言模型 (LLM) 已成为一种有前途的解决方案，通过将用户意图转换为可执行的转换代码来实现数据治理自动化。然而，现有的自动化数据科学基准通常强调片段级编码或高级分析，未能抓住数据治理的独特挑战：确保数据本身的正确性和质量。为了弥补这一差距，我们引入了 GovBench，这是一个基准测试，包含 150 个基于现实场景的不同任务，并基于实际案例的数据构建。 GovBench 采用新颖的“反向客观”方法来合成真实噪声，并利用严格的指标来评估端到端管道的可靠性。我们对 GovBench 的分析表明，当前的模型难以应对复杂的多步骤工作流程，并且缺乏强大的纠错机制。因此，我们提出了 DataGovAgent，这是一个利用规划器-执行器-评估器架构的框架，集成了基于约束的规划、检索增强生成和沙盒反馈驱动的调试。实验结果表明，与通用基线相比，DataGovAgent 将复杂任务的平均任务得分 (ATS) 从 39.7 显着提高到 54.9，并将调试迭代次数减少了 77.9% 以上。
> **Abstract**: Data governance ensures data quality, security, and compliance through policies and standards, a critical foundation for scaling modern AI development. Recently, large language models (LLMs) have emerged as a promising solution for automating data governance by translating user intent into executable transformation code. However, existing benchmarks for automated data science often emphasize snippet-level coding or high-level analytics, failing to capture the unique challenge of data governance: ensuring the correctness and quality of the data itself. To bridge this gap, we introduce GovBench, a benchmark featuring 150 diverse tasks grounded in real-world scenarios, built on data from actual cases. GovBench employs a novel "reversed-objective" methodology to synthesize realistic noise and utilizes rigorous metrics to assess end-to-end pipeline reliability. Our analysis on GovBench reveals that current models struggle with complex, multi-step workflows and lack robust error-correction mechanisms. Consequently, we propose DataGovAgent, a framework utilizing a Planner-Executor-Evaluator architecture that integrates constraint-based planning, retrieval-augmented generation, and sandboxed feedback-driven debugging. Experimental results show that DataGovAgent significantly boosts the Average Task Score (ATS) on complex tasks from 39.7 to 54.9 and reduces debugging iterations by over 77.9 percent compared to general-purpose baselines.

【4】Executable Governance for AI: Translating Policies into Rules Using LLMs
- **标题**: 人工智能的可执行治理：使用法学硕士将政策转化为规则
- **链接**: https://arxiv.org/abs/2512.04408
> **作者**: Gautam Varma Datla,Anudeep Vurity,Tejaswani Dash,Tazeem Ahmad,Mohd Adnan,Saima Rafi
> **摘要**: 人工智能政策指导主要以散文形式编写，从业者必须首先将其转换为可执行规则，然后框架才能评估或执行它们。此手动步骤速度缓慢、容易出错、难以扩展，并且常常会延迟在实际部署中使用防护措施。为了解决这一差距，我们提出了策略到测试（P2T），这是一个将自然语言策略文档转换为规范化的机器可读规则的框架。该框架包括一个管道和一个紧凑的特定领域语言 (DSL)，它对危险、范围、条件、例外和所需证据进行编码，从而生成提取规则的规范表示。为了测试单一政策之外的框架，我们将其应用于通用框架、行业指南和企业标准，提取义务承担条款并将其转换为可执行规则。这些人工智能生成的规则与跨度级别和规则级别指标的强大人类基线紧密匹配，并且在黄金集上具有强大的注释者间一致性。为了评估下游行为和安全影响，我们将 HIPAA 衍生的防护措施添加到生成代理中，并将其与没有护栏的其他相同代理进行比较。一位拥有法学硕士学位的法官，按照黄金标准，衡量违规率以及对模糊和组合提示的鲁棒性。详细结果在附录中提供。我们将代码库、DSL、提示和规则集作为开源资源发布，以实现可重复的评估。
> **Abstract**: AI policy guidance is predominantly written as prose, which practitioners must first convert into executable rules before frameworks can evaluate or enforce them. This manual step is slow, error-prone, difficult to scale, and often delays the use of safeguards in real-world deployments. To address this gap, we present Policy-to-Tests (P2T), a framework that converts natural-language policy documents into normalized, machine-readable rules. The framework comprises a pipeline and a compact domain-specific language (DSL) that encodes hazards, scope, conditions, exceptions, and required evidence, yielding a canonical representation of extracted rules. To test the framework beyond a single policy, we apply it across general frameworks, sector guidance, and enterprise standards, extracting obligation-bearing clauses and converting them into executable rules. These AI-generated rules closely match strong human baselines on span-level and rule-level metrics, with robust inter-annotator agreement on the gold set. To evaluate downstream behavioral and safety impact, we add HIPAA-derived safeguards to a generative agent and compare it with an otherwise identical agent without guardrails. An LLM-based judge, aligned with gold-standard criteria, measures violation rates and robustness to obfuscated and compositional prompts. Detailed results are provided in the appendix. We release the codebase, DSL, prompts, and rule sets as open-source resources to enable reproducible evaluation.

【5】AgentBay: A Hybrid Interaction Sandbox for Seamless Human-AI Intervention in Agentic Systems
- **标题**: AgentBay：用于代理系统中无缝人机交互的混合交互沙箱
- **链接**: https://arxiv.org/abs/2512.04367
> **作者**: Yun Piao,Hongbo Min,Hang Su,Leilei Zhang,Lei Wang,Yue Yin,Xiao Wu,Zhejing Xu,Liwei Qu,Hang Li,Xinxin Zeng,Wei Tian,Fei Yu,Xiaowei Li,Jiayi Jiang,Tongxu Liu,Hao Tian,Yufei Que,Xiaobing Tu,Bing Suo,Yuebing Li,Xiangting Chen,Zeen Zhao,Jiaming Tang,Wei Huang, et al. (6 additional authors not shown)
> **摘要**: 大型语言模型 (LLM) 的快速发展正在促进向能够执行复杂、多步骤任务的自主 AI 代理的转变。然而，这些代理在面对现实世界的异常时仍然很脆弱，这使得人在环（HITL）监督对于关键任务应用程序至关重要。在本文中，我们提出了 AgentBay，这是一种全新的沙盒服务，专为混合交互而设计。 AgentBay 提供跨 Windows、Linux、Android、Web 浏览器和代码解释器的安全、隔离的执行环境。其核心贡献是通过混合控制接口访问的统一会话：人工智能代理可以通过主流接口（MCP、开源 SDK）以编程方式进行交互，而人类操作员可以随时无缝地接管完全手动控制。这种无缝干预是通过自适应流协议 (ASP) 实现的。与传统的 VNC/RDP 不同，ASP 专为这种混合用例而设计，可提供超低延迟、更流畅的用户体验，即使在弱网络环境中也能保持弹性。它通过动态混合基于命令和基于视频的流媒体，根据网络条件和当前控制器（人工智能或人类）调整其编码策略来实现这一目标。我们的评估显示了安全性、性能和任务完成率方面的出色成果。在复杂任务的基准测试中，AgentBay（Agent + Human）模型取得了超过 48% 的成功率提升。此外，与标准 RDP 相比，我们的 ASP 协议可减少高达 50% 的带宽消耗，并且端到端延迟减少约 5%，尤其是在网络条件较差的情况下。我们认为 AgentBay 为构建下一代可靠的、人工监督的自治系统提供了基础原语。
> **Abstract**: The rapid advancement of Large Language Models (LLMs) is catalyzing a shift towards autonomous AI Agents capable of executing complex, multi-step tasks. However, these agents remain brittle when faced with real-world exceptions, making Human-in-the-Loop (HITL) supervision essential for mission-critical applications. In this paper, we present AgentBay, a novel sandbox service designed from the ground up for hybrid interaction. AgentBay provides secure, isolated execution environments spanning Windows, Linux, Android, Web Browsers, and Code interpreters. Its core contribution is a unified session accessible via a hybrid control interface: An AI agent can interact programmatically via mainstream interfaces (MCP, Open Source SDK), while a human operator can, at any moment, seamlessly take over full manual control. This seamless intervention is enabled by Adaptive Streaming Protocol (ASP). Unlike traditional VNC/RDP, ASP is specifically engineered for this hybrid use case, delivering an ultra-low-latency, smoother user experience that remains resilient even in weak network environments. It achieves this by dynamically blending command-based and video-based streaming, adapting its encoding strategy based on network conditions and the current controller (AI or human). Our evaluation demonstrates strong results in security, performance, and task completion rates. In a benchmark of complex tasks, the AgentBay (Agent + Human) model achieved more than 48% success rate improvement. Furthermore, our ASP protocol reduces bandwidth consumption by up to 50% compared to standard RDP, and in end-to-end latency with around 5% reduction, especially under poor network conditions. We posit that AgentBay provides a foundational primitive for building the next generation of reliable, human-supervised autonomous systems.

【6】Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning
- **标题**: 利用语义和令牌熵进行高效强化学习，用于法学硕士推理
- **链接**: https://arxiv.org/abs/2512.04359
> **作者**: Hongye Cao,Zhixin Bai,Ziyue Peng,Boyan Wang,Tianpei Yang,Jing Huo,Yuyao Zhang,Yang Gao
> **摘要**: 具有可验证奖励的强化学习（RLVR）在增强大型语言模型（LLM）的推理能力方面表现出了卓越的性能。然而，这种以准确性为导向的学习范式经常遭受熵崩溃，从而减少了策略探索并限制了推理能力。为了应对这一挑战，我们提出了一种有效的强化学习框架，该框架利用语义和标记级别的熵信号来改进推理。从数据的角度来看，我们引入语义熵引导的课程学习，将训练数据从低语义熵到高语义熵组织，以指导从更容易到更具挑战性的任务的逐步优化。对于算法设计，我们采用非均匀令牌处理，对严重影响策略探索的低熵令牌实施 KL 正则化，并对这些令牌中的高协方差部分应用更强的约束。通过联合优化数据组织和算法设计，我们的方法有效地减轻了熵崩溃并增强了 LLM 推理。具有 3 个不同参数规模基础模型的 6 个基准测试的实验结果表明，我们的方法在改进推理方面优于其他基于熵的方法。
> **Abstract**: Reinforcement learning with verifiable rewards (RLVR) has demonstrated superior performance in enhancing the reasoning capability of large language models (LLMs). However, this accuracy-oriented learning paradigm often suffers from entropy collapse, which reduces policy exploration and limits reasoning capabilities. To address this challenge, we propose an efficient reinforcement learning framework that leverages entropy signals at both the semantic and token levels to improve reasoning. From the data perspective, we introduce semantic entropy-guided curriculum learning, organizing training data from low to high semantic entropy to guide progressive optimization from easier to more challenging tasks. For the algorithmic design, we adopt non-uniform token treatment by imposing KL regularization on low-entropy tokens that critically impact policy exploration and applying stronger constraints on high-covariance portions within these tokens. By jointly optimizing data organization and algorithmic design, our method effectively mitigates entropy collapse and enhances LLM reasoning. Experimental results across 6 benchmarks with 3 different parameter-scale base models demonstrate that our method outperforms other entropy-based approaches in improving reasoning.

【7】A Conceptual Model for AI Adoption in Financial Decision-Making: Addressing the Unique Challenges of Small and Medium-Sized Enterprises
- **标题**: 财务决策中人工智能采用的概念模型：应对中小企业的独特挑战
- **链接**: https://arxiv.org/abs/2512.04339
> **作者**: Manh Chien Vu,Thang Le Dinh,Manh Chien Vu,Tran Duc Le,Thi Lien Huong Nguyen
> **摘要**: 人工智能 (AI) 的采用为中小企业 (SME) 提供了变革潜力，特别是在增强财务决策流程方面。然而，中小企业在实施人工智能技术时往往面临重大障碍，包括有限的资源、技术专长和数据管理能力。本文提出了在中小企业财务决策中采用人工智能的概念模型。拟议的模型解决了中小企业面临的主要挑战，包括有限的资源、技术专长和数据管理能力。该模型分为几层：数据源、数据处理和集成、人工智能模型部署、决策支持和自动化、验证和风险管理。通过逐步实施人工智能，中小企业可以优化财务预测、预算、投资策略和风险管理。本文强调了数据质量和持续模型验证的重要性，为中小企业将人工智能融入财务运营提供了实用的路线图。该研究最后提出了对中小企业采用人工智能驱动的财务流程的影响，并提出了中小企业财务人工智能应用的未来研究领域。
> **Abstract**: The adoption of artificial intelligence (AI) offers transformative potential for small and medium-sized enterprises (SMEs), particularly in enhancing financial decision-making processes. However, SMEs often face significant barriers to implementing AI technologies, including limited resources, technical expertise, and data management capabilities. This paper presents a conceptual model for the adoption of AI in financial decision-making for SMEs. The proposed model addresses key challenges faced by SMEs, including limited resources, technical expertise, and data management capabilities. The model is structured into layers: data sources, data processing and integration, AI model deployment, decision support and automation, and validation and risk management. By implementing AI incrementally, SMEs can optimize financial forecasting, budgeting, investment strategies, and risk management. This paper highlights the importance of data quality and continuous model validation, providing a practical roadmap for SMEs to integrate AI into their financial operations. The study concludes with implications for SMEs adopting AI-driven financial processes and suggests areas for future research in AI applications for SME finance.

【8】Towards better dense rewards in Reinforcement Learning Applications
- **标题**: 在强化学习应用中实现更好的密集奖励
- **链接**: https://arxiv.org/abs/2512.04302
> **作者**: Shuyuan Zhang
> **摘要**: 寻找有意义且准确的密集奖励是强化学习（RL）领域的一项基本任务，它使智能体能够更有效地探索环境。在传统的强化学习设置中，智能体通过与奖励信号引导的环境交互来学习最佳策略。然而，当这些信号稀疏、延迟或与预期任务目标不一致时，代理通常难以有效学习。密集奖励函数在每一步或状态转换中提供信息反馈，通过塑造代理行为和加速学习提供潜在的解决方案。尽管奖励函数有很多好处，但设计​​不当的奖励函数可能会导致意外行为、奖励黑客或低效探索。在复杂或高维环境中，手工奖励难以指定和验证，这个问题尤其严重。为了解决这个问题，最近的研究探索了多种方法，包括逆强化学习、根据人类偏好进行奖励建模以及内在奖励的自我监督学习。虽然这些方法提供了有希望的方向，但它们通常涉及通用性、可扩展性和与人类意图的一致性之间的权衡。该提案探索了几种方法来处理这些未解决的问题，并提高不同强化学习应用中密集奖励构建的有效性和可靠性。
> **Abstract**: Finding meaningful and accurate dense rewards is a fundamental task in the field of reinforcement learning (RL) that enables agents to explore environments more efficiently. In traditional RL settings, agents learn optimal policies through interactions with an environment guided by reward signals. However, when these signals are sparse, delayed, or poorly aligned with the intended task objectives, agents often struggle to learn effectively. Dense reward functions, which provide informative feedback at every step or state transition, offer a potential solution by shaping agent behavior and accelerating learning. Despite their benefits, poorly crafted reward functions can lead to unintended behaviors, reward hacking, or inefficient exploration. This problem is particularly acute in complex or high-dimensional environments where handcrafted rewards are difficult to specify and validate. To address this, recent research has explored a variety of approaches, including inverse reinforcement learning, reward modeling from human preferences, and self-supervised learning of intrinsic rewards. While these methods offer promising directions, they often involve trade-offs between generality, scalability, and alignment with human intent. This proposal explores several approaches to dealing with these unsolved problems and enhancing the effectiveness and reliability of dense reward construction in different RL applications.

【9】Artificial Intelligence Applications in Horizon Scanning for Infectious Diseases
- **标题**: 人工智能在传染病地平线扫描中的应用
- **链接**: https://arxiv.org/abs/2512.04287
> **作者**: Ian Miles,Mayumi Wakimoto,Wagner Meira Jr.,Daniela Paula,Daylene Ticiane,Bruno Rosa,Jane Biddulph,Stelios Georgiou,Valdir Ermida
> **摘要**: 本综述探讨了人工智能与地平线扫描的整合，重点是识别和应对与传染病相关的新威胁和机遇。我们研究人工智能工具如何增强信号检测、数据监控、场景分析和决策支持。我们还解决与人工智能采用相关的风险，并提出有效实施和治理的策略。这些发现通过展示人工智能在公共卫生准备方面的潜力和局限性，为不断增长的前瞻文献做出了贡献。
> **Abstract**: This review explores the integration of Artificial Intelligence into Horizon Scanning, focusing on identifying and responding to emerging threats and opportunities linked to Infectious Diseases. We examine how AI tools can enhance signal detection, data monitoring, scenario analysis, and decision support. We also address the risks associated with AI adoption and propose strategies for effective implementation and governance. The findings contribute to the growing body of Foresight literature by demonstrating the potential and limitations of AI in Public Health preparedness.

【10】The Geometry of Benchmarks: A New Path Toward AGI
- **标题**: 基准几何：通向 AGI 的新路径
- **链接**: https://arxiv.org/abs/2512.04276
> **作者**: Przemyslaw Chojecki
> **摘要**: 基准是评估人工智能 (AI) 进展的主要工具，但当前的实践是在孤立的测试套件上评估模型，并且很少为推理通用性或自主自我改进提供指导。在这里，我们引入了一个几何框架，其中人工智能代理的所有心理测量电池都被视为结构化模空间中的点，代理性能由该空间上的能力泛函来描述。首先，我们定义了一个自主人工智能（AAI）量表，这是一种卡尔达舍夫式的自主层次结构，其基础是跨任务系列（例如推理、规划、工具使用和长期控制）的电池的可测量性能。其次，我们构建了电池的模空间，识别在代理排序和能力推断层面上无法区分的基准的等价类。这种几何结构产生了确定性结果：密集的电池系列足以证明整个任务空间区域的性能。第三，我们引入了一个通用的生成器-验证器-更新器（GVU）算子，它将强化学习、自我对弈、辩论和基于验证器的微调作为特殊情况，并且我们将自我改进系数 $κ$ 定义为沿着诱导流的能力函数的李导数。生成和验证的组合噪声的方差不等式为 $κ> 0$ 提供了充分的条件。我们的结果表明，通用人工智能 (AGI) 的进步最好理解为基准模数的流动，由 GVU 动态驱动，而不是由个人排行榜上的分数驱动。
> **Abstract**: Benchmarks are the primary tool for assessing progress in artificial intelligence (AI), yet current practice evaluates models on isolated test suites and provides little guidance for reasoning about generality or autonomous self-improvement. Here we introduce a geometric framework in which all psychometric batteries for AI agents are treated as points in a structured moduli space, and agent performance is described by capability functionals over this space. First, we define an Autonomous AI (AAI) Scale, a Kardashev-style hierarchy of autonomy grounded in measurable performance on batteries spanning families of tasks (for example reasoning, planning, tool use and long-horizon control). Second, we construct a moduli space of batteries, identifying equivalence classes of benchmarks that are indistinguishable at the level of agent orderings and capability inferences. This geometry yields determinacy results: dense families of batteries suffice to certify performance on entire regions of task space. Third, we introduce a general Generator-Verifier-Updater (GVU) operator that subsumes reinforcement learning, self-play, debate and verifier-based fine-tuning as special cases, and we define a self-improvement coefficient $κ$ as the Lie derivative of a capability functional along the induced flow. A variance inequality on the combined noise of generation and verification provides sufficient conditions for $κ> 0$. Our results suggest that progress toward artificial general intelligence (AGI) is best understood as a flow on moduli of benchmarks, driven by GVU dynamics rather than by scores on individual leaderboards.

【11】Toward Virtuous Reinforcement Learning
- **标题**: 迈向良性强化学习
- **链接**: https://arxiv.org/abs/2512.04246
> **作者**: Majid Ghasemi,Mark Crowley
> **摘要**: 本文批评了强化学习（RL）机器伦理中的常见模式，并提出了一种以美德为中心的替代方案。我们强调了当前许多文献中反复出现的两个局限性：（i）将义务编码为约束或盾牌的基于规则（义务论）的方法经常在模糊性和非平稳性下挣扎，并且无法培养持久的习惯，以及（ii）许多基于奖励的方法，尤其是单一目标强化学习，隐式地将不同的道德考虑压缩为单个标量信号，这可能会掩盖权衡并在实践中引发代理博弈。相反，我们将道德视为政策层面的倾向，即当激励、合作伙伴或环境发生变化时仍能保持相对稳定的习惯。这将评估从规则检查或标量回报转向特质总结、干预下的持久性以及道德权衡的明确报告。我们的路线图结合了四个组成部分：（1）多智能体强化学习中的社会学习，从不完美但规范的范例中获取美德之类的模式； (2) 多目标和受约束的表述，保留价值冲突并纳入风险意识标准以防止伤害； （3）基于亲和力的正则化，朝向可更新的美德先验，支持分布变化下的稳定性等特征，同时允许规范发展； (4) 将不同的道德传统作为实际控制信号，明确塑造道德强化学习基准的价值和文化假设。
> **Abstract**: This paper critiques common patterns in machine ethics for Reinforcement Learning (RL) and argues for a virtue focused alternative. We highlight two recurring limitations in much of the current literature: (i) rule based (deontological) methods that encode duties as constraints or shields often struggle under ambiguity and nonstationarity and do not cultivate lasting habits, and (ii) many reward based approaches, especially single objective RL, implicitly compress diverse moral considerations into a single scalar signal, which can obscure trade offs and invite proxy gaming in practice. We instead treat ethics as policy level dispositions, that is, relatively stable habits that hold up when incentives, partners, or contexts change. This shifts evaluation beyond rule checks or scalar returns toward trait summaries, durability under interventions, and explicit reporting of moral trade offs. Our roadmap combines four components: (1) social learning in multi agent RL to acquire virtue like patterns from imperfect but normatively informed exemplars; (2) multi objective and constrained formulations that preserve value conflicts and incorporate risk aware criteria to guard against harm; (3) affinity based regularization toward updateable virtue priors that support trait like stability under distribution shift while allowing norms to evolve; and (4) operationalizing diverse ethical traditions as practical control signals, making explicit the value and cultural assumptions that shape ethical RL benchmarks.

【12】Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework
- **标题**: 解决大型语言模型科学推理中的逻辑谬误：走向双重推理训练框架
- **链接**: https://arxiv.org/abs/2512.04228
> **作者**: Peter B. Walker,Hannah Davidson,Aiden Foster,Matthew Lienert,Thomas Pardue,Dale Russell
> **摘要**: 大型语言模型 (LLM) 已经改变了自然语言处理，并为推动科学、医疗保健和决策制定带来了越来越大的希望。然而，他们的训练范式仍然以基于肯定的推理为主，类似于 \textit{modus ponens}，其中接受的前提产生预测的结果。虽然对生成流畅性有效，但这种单向方法使模型容易出现逻辑谬误、对抗性操纵和因果推理失败。本文做出了两个贡献。首先，它展示了来自主要平台的现有法学硕士在使用否定、反例或错误前提进行科学领域推理时如何表现出系统性弱点\脚注{重新创建这些实验的代码位于https://github.com/hannahdavidsoncollege-maker/ScientificReasoningForEnvironment-MedicineWithLLMs。其次，它引入了双重推理训练框架，将肯定性生成与结构化反事实否认相结合。这种训练范式以形式逻辑、认知科学和对抗性训练为基础，将“否认前件”的计算模拟形式化为一种否定和鲁棒性的机制。通过将生成综合与明确的否定感知目标相结合，该框架使模型不仅能够肯定有效的推论，而且能够拒绝无效的推论，从而产生更具弹性、可解释性和与人类推理一致的系统。
> **Abstract**: Large Language Models (LLMs) have transformed natural language processing and hold growing promise for advancing science, healthcare, and decision-making. Yet their training paradigms remain dominated by affirmation-based inference, akin to \textit{modus ponens}, where accepted premises yield predicted consequents. While effective for generative fluency, this one-directional approach leaves models vulnerable to logical fallacies, adversarial manipulation, and failures in causal reasoning. This paper makes two contributions. First, it demonstrates how existing LLMs from major platforms exhibit systematic weaknesses when reasoning in scientific domains with negation, counterexamples, or faulty premises \footnote{Code to recreate these experiments are at https://github.com/hannahdavidsoncollege-maker/ScientificReasoningForEnvironment-MedicineWithLLMs. Second, it introduces a dual-reasoning training framework that integrates affirmative generation with structured counterfactual denial. Grounded in formal logic, cognitive science, and adversarial training, this training paradigm formalizes a computational analogue of ``denying the antecedent'' as a mechanism for disconfirmation and robustness. By coupling generative synthesis with explicit negation-aware objectives, the framework enables models that not only affirm valid inferences but also reject invalid ones, yielding systems that are more resilient, interpretable, and aligned with human reasoning.

【13】Educational Cone Model in Embedding Vector Spaces
- **标题**: 嵌入向量空间中的教育锥模型
- **链接**: https://arxiv.org/abs/2512.04227
> **作者**: Yo Ehara
> **摘要**: 具有明确难度评级的人工注释数据集在智能教育系统中至关重要。尽管嵌入向量空间被广泛用于表示语义接近度并且有望用于分析文本难度，但嵌入方法的丰富性给选择最合适的方法带来了挑战。本研究提出了教育锥模型，这是一个几何框架，基于这样的假设：较简单的文本多样性较低（专注于基本概念），而较难的文本则更加多样化。无论使用何种嵌入方法，该假设都会导致嵌入空间中呈锥形分布。该模型将嵌入的评估构建为优化问题，旨在检测基于难度的结构化模式。通过设计特定的损失函数，可以得出有效的封闭式解决方案，从而避免昂贵的计算。对现实世界数据集的实证测试验证了该模型在识别与难度注释的教育文本最一致的嵌入空间方面的有效性和速度。
> **Abstract**: Human-annotated datasets with explicit difficulty ratings are essential in intelligent educational systems. Although embedding vector spaces are widely used to represent semantic closeness and are promising for analyzing text difficulty, the abundance of embedding methods creates a challenge in selecting the most suitable method. This study proposes the Educational Cone Model, which is a geometric framework based on the assumption that easier texts are less diverse (focusing on fundamental concepts), whereas harder texts are more diverse. This assumption leads to a cone-shaped distribution in the embedding space regardless of the embedding method used. The model frames the evaluation of embeddings as an optimization problem with the aim of detecting structured difficulty-based patterns. By designing specific loss functions, efficient closed-form solutions are derived that avoid costly computation. Empirical tests on real-world datasets validated the model's effectiveness and speed in identifying the embedding spaces that are best aligned with difficulty-annotated educational texts.

【14】Balancing Safety and Helpfulness in Healthcare AI Assistants through Iterative Preference Alignment
- **标题**: 通过迭代偏好调整平衡医疗保健人工智能助理的安全性和有用性
- **链接**: https://arxiv.org/abs/2512.04210
> **作者**: Huy Nghiem,Swetasudha Panda,Devashish Khatwani,Huy V. Nguyen,Krishnaram Kenthapadi,Hal Daumé III
> **摘要**: 大型语言模型 (LLM) 越来越多地应用于医疗保健领域，但确保其安全性和可信度仍然是部署的障碍。会话式医疗助理必须避免不安全的合规行为，同时又不能过度拒绝善意的询问。我们提出了一个迭代的部署后对齐框架，该框架应用 Kahneman-Tversky Optimization (KTO) 和 Direct Preference Optimization (DPO) 来针对特定领域的安全信号细化模型。使用 CARES-18K 对抗鲁棒性基准，我们在多个周期中评估了四个 LLM（Llama-3B/8B、Meditron-8B、Mistral-7B）。我们的结果显示，有害查询检测的安全相关指标提高了 42%，同时针对错误拒绝进行了有趣的权衡，从而暴露了依赖于架构的校准偏差。我们还进行消融研究，以确定何时自我评估是可靠的，以及何时需要外部或微调的法官来最大限度地提高绩效。我们的研究结果强调了在对话式医疗助理的设计中采用平衡患者安全、用户信任和临床实用性的最佳实践的重要性。
> **Abstract**: Large Language Models (LLMs) are increasingly used in healthcare, yet ensuring their safety and trustworthiness remains a barrier to deployment. Conversational medical assistants must avoid unsafe compliance without over-refusing benign queries. We present an iterative post-deployment alignment framework that applies Kahneman-Tversky Optimization (KTO) and Direct Preference Optimization (DPO) to refine models against domain-specific safety signals. Using the CARES-18K benchmark for adversarial robustness, we evaluate four LLMs (Llama-3B/8B, Meditron-8B, Mistral-7B) across multiple cycles. Our results show up to 42% improvement in safety-related metrics for harmful query detection, alongside interesting trade-offs against erroneous refusals, thereby exposing architecture-dependent calibration biases. We also perform ablation studies to identify when self-evaluation is reliable and when external or finetuned judges are necessary to maximize performance gains. Our findings underscore the importance of adopting best practices that balance patient safety, user trust, and clinical utility in the design of conversational medical assistants.

【15】Orchestrator Multi-Agent Clinical Decision Support System for Secondary Headache Diagnosis in Primary Care
- **标题**: Orchestrator 多代理临床决策支持系统，用于初级保健中的继发性头痛诊断
- **链接**: https://arxiv.org/abs/2512.04207
> **作者**: Xizhi Wu,Nelly Estefanie Garduno-Rapp,Justin F Rousseau,Mounika Thakkallapally,Hang Zhang,Yuelyu Ji,Shyam Visweswaran,Yifan Peng,Yanshan Wang
> **摘要**: 与大多数原发性头痛不同，继发性头痛需要专门护理，如果不及时治疗，可能会造成毁灭性后果。临床指南强调了一些“危险信号”特征，例如雷击发作、脑膜痉挛、视乳头水肿、局灶性神经功能缺损、颞动脉炎体征、全身性疾病以及“一生中最严重的头痛”表现。尽管有这些指南，但在初级保健机构中确定哪些患者需要紧急评估仍然具有挑战性。临床医生经常在有限的时间、不完整的信息和多样化的症状表现下开展工作，这可能导致识别不足和护理不当。我们提出了一个基于大语言模型（LLM）的多代理临床决策支持系统，该系统建立在协调器专家架构之上，旨在根据自由文本临床小插图执行明确且可解释的继发性头痛诊断。多代理系统将诊断分解为七个专门领域的代理，每个代理都产生结构化且基于证据的基本原理，而中央协调器则执行任务分解并协调代理路由。我们使用 90 个经过专家验证的继发性头痛病例评估了多智能体系统，并通过两种提示策略将其性能与单一法学硕士基线进行了比较：基于问题的提示 (QPrompt) 和基于临床实践指南的提示 (GPrompt)。我们测试了五个开源 LLM（Qwen-30B、GPT-OSS-20B、Qwen-14B、Qwen-8B 和 Llama-3.1-8B），发现使用 GPrompt 编排的多智能体系统始终获得最高的 F1 分数，在较小的模型中收益更大。这些发现表明，结构化多智能体推理比单独的即时工程提高了准确性，并为继发性头痛诊断中的可解释决策支持提供了透明的、临床一致的方法。
> **Abstract**: Unlike most primary headaches, secondary headaches need specialized care and can have devastating consequences if not treated promptly. Clinical guidelines highlight several 'red flag' features, such as thunderclap onset, meningismus, papilledema, focal neurologic deficits, signs of temporal arteritis, systemic illness, and the 'worst headache of their life' presentation. Despite these guidelines, determining which patients require urgent evaluation remains challenging in primary care settings. Clinicians often work with limited time, incomplete information, and diverse symptom presentations, which can lead to under-recognition and inappropriate care. We present a large language model (LLM)-based multi-agent clinical decision support system built on an orchestrator-specialist architecture, designed to perform explicit and interpretable secondary headache diagnosis from free-text clinical vignettes. The multi-agent system decomposes diagnosis into seven domain-specialized agents, each producing a structured and evidence-grounded rationale, while a central orchestrator performs task decomposition and coordinates agent routing. We evaluated the multi-agent system using 90 expert-validated secondary headache cases and compared its performance with a single-LLM baseline across two prompting strategies: question-based prompting (QPrompt) and clinical practice guideline-based prompting (GPrompt). We tested five open-source LLMs (Qwen-30B, GPT-OSS-20B, Qwen-14B, Qwen-8B, and Llama-3.1-8B), and found that the orchestrated multi-agent system with GPrompt consistently achieved the highest F1 scores, with larger gains in smaller models. These findings demonstrate that structured multi-agent reasoning improves accuracy beyond prompt engineering alone and offers a transparent, clinically aligned approach for explainable decision support in secondary headache diagnosis.

【16】RippleBench: Capturing Ripple Effects Using Existing Knowledge Repositories
- **标题**: RippleBench：使用现有知识库捕捉涟漪效应
- **链接**: https://arxiv.org/abs/2512.04144
> **作者**: Roy Rinberg,Usha Bhalla,Igor Shilov,Flavio P. Calmon,Rohit Gandikota
> **摘要**: 对语言模型进行有针对性的干预，例如消除学习、消除偏差或模型编辑，是完善模型行为和保持知识最新的核心方法。虽然这些干预措施旨在修改模型中的特定信息（例如，删除病毒学内容），但它们的影响通常会传播到相关但非预期的领域（例如过敏）；这些副作用通常称为连锁反应。在这项工作中，我们提出了 RippleBench-Maker，这是一种用于生成问答数据集的自动工具，可以在任何模型编辑任务中测量连锁反应。 RippleBench-Maker 建立在基于维基百科的 RAG 管道 (WikiRAG) 之上，以与目标概念（例如，被遗忘的知识）不同的语义距离生成多项选择题。使用这个框架，我们构建了 RippleBench-Bio，这是一个源自 WMDP（大规模杀伤性武器论文）数据集的基准，这是一个常见的遗忘基准。我们评估了八种最先进的忘却方法，发现所有这些方法在距离未学知识越来越远的主题上都表现出不平凡的准确性下降，并且每种方法都有不同的传播概况。为了支持正在进行的研究，我们发布了用于实时瑞波评估的代码库以及基准 RippleBench-Bio。
> **Abstract**: Targeted interventions on language models, such as unlearning, debiasing, or model editing, are a central method for refining model behavior and keeping knowledge up to date. While these interventions aim to modify specific information within models (e.g., removing virology content), their effects often propagate to related but unintended areas (e.g., allergies); these side-effects are commonly referred to as the ripple effect. In this work, we present RippleBench-Maker, an automatic tool for generating Q&A datasets that allow for the measurement of ripple effects in any model-editing task. RippleBench-Maker builds on a Wikipedia-based RAG pipeline (WikiRAG) to generate multiple-choice questions at varying semantic distances from the target concept (e.g., the knowledge being unlearned). Using this framework, we construct RippleBench-Bio, a benchmark derived from the WMDP (Weapons of Mass Destruction Paper) dataset, a common unlearning benchmark. We evaluate eight state-of-the-art unlearning methods and find that all exhibit non-trivial accuracy drops on topics increasingly distant from the unlearned knowledge, each with distinct propagation profiles. To support ongoing research, we release our codebase for on-the-fly ripple evaluation, along with the benchmark, RippleBench-Bio.

【17】Solving N-Queen Problem using Las Vegas Algorithm with State Pruning
- **标题**: 使用带有状态剪枝的拉斯维加斯算法解决 N-Queen 问题
- **链接**: https://arxiv.org/abs/2512.04139
> **作者**: Susmita Sharma,Aayush Shrestha,Sitasma Thapa,Prashant Timalsina,Prakash Poudyal
> **摘要**: N-皇后问题，将所有 N 个皇后放置在 N x N 棋盘中，其中没有一个皇后互相攻击，这是约束满足算法的一个经典问题。虽然像回溯这样的完整方法可以保证解决方案，但它们的指数时间复杂度使得它们对于大规模实例来说不切实际，因此，首选随机方法，例如拉斯维加斯算法。虽然它提供了更快的近似解决方案，但由于棋盘上皇后的随机放置，它会出现显着的性能差异。本研究引入了一种建立在标准拉斯维加斯框架之上的混合算法，通过迭代剪枝，在随机分配阶段动态消除无效放置，从而有效减少搜索空间。分析结果表明，随着 N 的增加，传统回溯的扩展性很差。相比之下，所提出的技术始终能够更快地生成有效的解决方案，使其成为一种优越的替代方案，可以在优先考虑单一、及时的解决方案而不是完整性的情况下使用。尽管较大的 N 会导致一些性能变化，但该算法展示了计算成本和解决方案保真度之间的高效权衡，使其特别适合资源受限的计算环境。
> **Abstract**: The N-Queens problem, placing all N queens in a N x N chessboard where none attack the other, is a classic problem for constraint satisfaction algorithms. While complete methods like backtracking guarantee a solution, their exponential time complexity makes them impractical for large-scale instances thus, stochastic approaches, such as Las Vegas algorithm, are preferred. While it offers faster approximate solutions, it suffers from significant performance variance due to random placement of queens on the board. This research introduces a hybrid algorithm built on top of the standard Las Vegas framework through iterative pruning, dynamically eliminating invalid placements during the random assignment phase, thus this method effectively reduces the search space. The analysis results that traditional backtracking scales poorly with increasing N. In contrast, the proposed technique consistently generates valid solutions more rapidly, establishing it as a superior alternative to use where a single, timely solution is preferred over completeness. Although large N causes some performance variability, the algorithm demonstrates a highly effective trade-off between computational cost and solution fidelity, making it particularly suited for resource-constrained computing environments.

【18】Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol
- **标题**: 使用大型语言模型代理进行规划和控制的基准：具有模型上下文协议的 Blocksworld
- **链接**: https://arxiv.org/abs/2512.03955
> **作者**: Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff
> **摘要**: 工业自动化越来越需要灵活的控制策略，以适应不断变化的任务和环境。基于大型语言模型（LLM）的代理提供了这种自适应规划和执行的潜力，但缺乏用于系统比较的标准化基准。我们引入了一个具有可执行模拟环境的基准测试，该环境代表了提供五个复杂性类别的 Blocksworld 问题。通过将模型上下文协议 (MCP) 集成为标准化工具接口，可以将不同的代理架构连接到基准并根据基准进行评估，而无需进行特定于实现的修改。单代理实施证明了基准的适用性，建立了用于比较基于 LLM 的规划和执行方法的定量指标。
> **Abstract**: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

【19】Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties
- **标题**: 自治代理和政策合规性：惩罚推理的框架
- **链接**: https://arxiv.org/abs/2512.03931
> **作者**: Vineel Tummala,Daniela Inclezan
> **摘要**: 本文提出了一种基于逻辑编程的策略感知自主代理框架，该框架可以推理出不合规行为的潜在处罚并采取相应行动。虽然之前的工作主要集中在确保合规性，但我们的方法考虑了可能需要偏离政策才能实现高风险目标的情况。此外，对不合规行为进行建模可以通过模拟现实的人类决策来帮助决策者。我们的框架扩展了 Gelfond 和 Lobo 的授权和义务策略语言 (AOPL)，以纳入处罚并集成答案集编程 (ASP) 以进行推理。与以前的方法相比，我们的方法确保了格式良好的策略，考虑了策略优先级，并通过明确识别规则违规及其后果来增强可解释性。在 Harders 和 Inclezan 工作的基础上，我们引入了基于惩罚的推理来区分不合规的计划，优先考虑那些影响最小的计划。为了支持这一点，我们开发了从扩展 AOPL 到 ASP 的自动转换，并改进基于 ASP 的规划算法以解决所产生的处罚。两个领域的实验表明，我们的框架可以生成更高质量的计划，避免有害行为，同时在某些情况下还提高计算效率。这些发现强调了其增强自主决策和为政策细化提供信息的潜力。正在逻辑编程理论与实践（TPLP）中考虑。
> **Abstract**: This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).

【20】A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)
- **标题**: 用于创建可配置和静态深度研究代理 (Static-DRA) 的基于分层树的方法
- **链接**: https://arxiv.org/abs/2512.03887
> **作者**: Saurav Prateek
> **摘要**: 大型语言模型的进步推动了复杂代理系统的创建，例如深度研究代理 (DRA)，以克服静态检索增强生成 (RAG) 管道在处理复杂的多轮研究任务时的局限性。本文介绍了静态深度研究代理 (Static-DRA)，这是一种基于可配置且分层的基于树的静态工作流程构建的新颖解决方案。核心贡献是深度和广度这两个用户可调参数的集成，它们提供了对研究强度的精细控制。这种设计使最终用户能够有意识地平衡研究报告所需的质量和全面性与大型语言模型 (LLM) 交互的相关计算成本。该代理的体系结构由主管代理、独立代理和工作代理组成，有助于有效的多跳信息检索和并行子主题调查。我们使用 RACE（基于参考的自适应标准驱动评估）框架根据已建立的 DeepResearch Bench 评估 Static-DRA。配置深度为 2、宽度为 5，并由 Gemini-2.5-pro 模型驱动，该代理的总体得分为 34.72。我们的实验验证了增加配置的深度和广度参数会导致更深入的研究过程和相应更高的评估分数。 Static-DRA 提供了实用且资源感知的解决方案，使用户能够透明地控制深度研究过程。整个源代码、输出和基准测试结果均在 https://github.com/SauravP97/Static-Deep-Research/ 上开源
> **Abstract**: The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow. The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation. We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/

【21】Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning
- **标题**: Omni-AutoThink：通过强化学习进行自适应多模态推理
- **链接**: https://arxiv.org/abs/2512.03783
> **作者**: Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng
> **摘要**: Omni 模型的最新进展实现了统一的多模态感知和生成。然而，大多数现有系统仍然表现出僵化的推理行为，要么过度思考简单问题，要么在必要时无法推理。为了解决这个限制，我们提出了 Omni-AutoThink，这是一种新颖的自适应推理框架，可以根据任务难度动态调整模型的推理深度。我们的框架包括两个阶段：(1) 自适应监督微调 (Adaptive SFT) 阶段，利用大规模推理增强数据赋予 Omni 模型基本推理能力；(2) 自适应强化学习 (Adaptive GRPO) 阶段，根据任务复杂性和奖励反馈优化推理行为。我们进一步构建了一个全面的自适应推理基准，涵盖纯文本、文本音频、文本视觉和文本音频视觉模式，为多模式推理评估提供训练和评估拆分。实验结果表明，与之前的基线相比，我们提出的框架显着提高了自适应推理性能。所有基准数据和代码都将公开发布。
> **Abstract**: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

【22】RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design
- **标题**: RoCo：基于角色的法学硕士协作自动启发式设计
- **链接**: https://arxiv.org/abs/2512.03762
> **作者**: Jiawei Xu,Feng-Feng Wei,Wei-Neng Chen
> **摘要**: 自动启发式设计 (AHD) 作为解决组合优化问题 (COP) 的一种有前途的解决方案而受到关注。大型语言模型 (LLM) 已经出现，并成为实现 AHD 的一种有前景的方法，但当前基于 LLM 的 AHD 研究通常只考虑单一角色。本文提出了 RoCo，一种新颖的基于角色的多代理系统，通过多角色协作来增强 AHD 的多样性和质量。 RoCo 协调四个专业的 LLM 引导代理（探索者、开发者、批评者和集成者），以协作生成高质量的启发式方法。探索者通过创造性、多样性驱动的思维来促进长期潜力，而开发者则通过保守的、以效率为导向的改进来关注短期改进。批评者评估每个进化步骤的有效性，并提供有针对性的反馈和反思。集成者综合探索者和开发者的建议，平衡创新和开发，推动整体进步。这些代理在结构化的多轮过程中相互作用，涉及由短期和累积的长期反射指导的反馈、改进和精英突变。我们在白盒和黑盒设置下评估五种不同 COP 的 RoCo。实验结果表明，RoCo 实现了卓越的性能，始终如一地生成有竞争力的启发式算法，无论是在白盒还是黑盒场景中，其性能都优于 ReEvo 和 HSEvo 等现有方法。这种基于角色的协作范例为稳健且高性能的 AHD 建立了新标准。
> **Abstract**: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

【23】MemVerse: Multimodal Memory for Lifelong Learning Agents
- **标题**: MemVerse：终身学习智能体的多模态记忆
- **链接**: https://arxiv.org/abs/2512.03627
> **作者**: Junming Liu,Yifei Sun,Weihua Cheng,Haodong Lei,Yirong Chen,Licheng Wen,Xuemeng Yang,Daocheng Fu,Pinlong Cai,Nianchen Deng,Yi Yu,Shuyue Hu,Botian Shi,Ding Wang
> **摘要**: 尽管大规模语言和视觉模型取得了快速进展，但人工智能代理仍然面临着一个根本性的限制：它们无法记忆。如果没有可靠的记忆，智能体就会灾难性地忘记过去的经历，难以进行长期推理，并且无法在多模式或交互式环境中连贯地运作。我们推出了 MemVerse，这是一种与模型无关的即插即用内存框架，它将快速参数调用与基于分层检索的内存连接起来，从而实现可扩展和自适应的多模态智能。 MemVerse 维护近期上下文的短期记忆，同时将原始多模态体验转化为以分层知识图组织的结构化长期记忆。这种设计支持持续巩固、适应性遗忘和有限的记忆增长。为了处理实时需求，MemVerse 引入了一种周期性蒸馏机制，将长期记忆中的基本知识压缩到参数模型中，从而允许快速、可微分的回忆，同时保留可解释性。大量实验表明，MemVerse 显着提高了多模态推理和持续学习效率，使智能体能够在扩展的交互中连贯地记忆、适应和推理。
> **Abstract**: Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.

【24】DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization
- **标题**: DeepRule：通过深度预测建模和混合搜索优化自动生成业务规则的集成框架
- **链接**: https://arxiv.org/abs/2512.03607
> **作者**: Yusen Wu,Xiaotie Deng
> **摘要**: 本文提出了 DeepRule，一个用于零售分类和定价优化中自动化业务规则生成的集成框架。为了解决现有理论模型与现实世界经济复杂性之间的系统性脱节问题，我们确定了三个关键差距：（1）数据模态不匹配，其中非结构化文本源（例如谈判记录、批准文件）阻碍了准确的客户分析； （2）非线性价格弹性和时变属性建模中的动态特征纠缠挑战； （3）多层次业务约束导致运营不可行。我们的框架引入了三级架构来应对上述挑战。我们设计了一个混合知识融合引擎，采用大型语言模型（LLM）对非结构化文本进行深度语义解析，将分销商协议和销售评估转换为结构化特征，同时集成管理专业知识。然后采用博弈论约束优化机制通过双边效用函数动态协调供应链利益，将制造商-分销商利润再分配编码为层次约束下的内生目标。最后，可解释的决策蒸馏接口利用法学硕士引导的符号回归来查找和优化定价策略和可审计的业务规则，嵌入经济先验（例如非负弹性）作为数学表达式搜索期间的硬约束。我们在真实的零售环境中验证该框架，与系统的 B2C 基线相比，实现更高的利润，同时确保运营可行性。这建立了一个闭环管道，将非结构化知识注入、多智能体优化和可解释的策略合成统一起来，以实现真正的经济智能。
> **Abstract**: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints. Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

【25】EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths
- **标题**: EnCompass：通过搜索程序执行路径来增强代理编程
- **链接**: https://arxiv.org/abs/2512.03571
> **作者**: Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng
> **摘要**: 我们引入了一种新的代理编程方法，即基于 LLM 的代理的开发。当前的代理编程方法通常涉及代理设计的两个方面：核心工作流逻辑和推理时间策略（例如，树搜索）。我们引入了“概率天使非确定性”（“PAN”），这是一种解决这两个问题的编程模型，允许程序员描述代理工作流程，并通过简单地更改一些输入来独立试验不同的推理时间策略。我们提供了 Python 中 PAN 的实现作为 EnCompass 框架，它使用 Python 装饰器将代理工作流程序编译到搜索空间中。我们提出了三个案例研究，展示了该框架如何让程序员快速提高代理的可靠性，并轻松地在不同的推理时间策略之间切换，所有这些都几乎不需要额外的编码。
> **Abstract**: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

【26】Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks
- **标题**: Reason-Plan-ReAct：一个 Reasoner-Planner，监督复杂企业任务的 ReAct 执行器
- **链接**: https://arxiv.org/abs/2512.03560
> **作者**: Gianni Molinari,Fabio Ciravegna
> **摘要**: 尽管最近取得了进展，但自主代理常常难以解决企业领域中需要协调多个工具和处理不同数据源的复杂任务。这场斗争是由两个主要限制推动的。首先，单代理架构强制执行整体计划执行循环，这直接导致轨迹不稳定。其次，使用本地开放权重模型来实现数据隐私的要求引入了更小的上下文窗口，导致大型工具输出中上下文的快速消耗。为了解决这个问题，我们引入了 RP-ReAct（Reasoner Planner-ReAct），这是一种新颖的多代理方法，从根本上将战略规划与低级执行解耦，以实现卓越的可靠性和效率。 RP-ReAct 由一个推理规划器代理 (RPA) 和一个或多个代理执行代理 (PEA) 组成，前者负责规划每个子步骤，利用大型推理模型的强大推理能力持续分析执行结果，后者使用 ReAct 方法将子步骤转换为具体的工具交互。至关重要的是，我们在 PEA 中纳入了上下文保存策略，通过外部存储和按需访问来管理大型工具输出，从而减轻上下文窗口溢出。我们使用一组不同的六个开放权重推理模型，在具有挑战性的多领域 ToolQA 基准上评估 RP-ReAct。我们的实证结果表明，在解决跨评估领域的各种复杂任务时，RP-ReAct 与最先进的基线相比，实现了卓越的性能并提高了泛化能力。此外，我们在不同模型规模上增强了我们的方法的稳健性和稳定性，为企业有效且可部署的代理解决方案铺平了道路。
> **Abstract**: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.

【27】PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks
- **标题**: PARC：一种用于稳健执行长期任务的自主自反射编码代理
- **链接**: https://arxiv.org/abs/2512.03549
> **作者**: Yuki Orimo,Iori Kurata,Hodaka Mori,Ryuhei Okuno,Ryohto Sawada,Daisuke Okanohara
> **摘要**: 我们引入了 PARC，这是一种用于自主且稳健地执行长期计算任务的编码代理。 PARC 建立在分层多代理架构之上，其中包含任务规划、执行以及从独立环境中评估自身行动及其结果并提供反馈的机制，即自我评估和自我反馈。这种设计使 PARC 能够检测并纠正高级战略错误并在无需人工干预的情况下保持进展。我们跨计算科学和数据科学任务评估 PARC。在材料科学中，它自主再现了锂离子传导和合金偏析研究的关键结果。特别是，它协调数十个并行模拟任务，每个任务需要大约 43 小时的计算、管理编排、监控和端到端纠错。在基于 Kaggle 的实验中，从最少的自然语言指令开始，PARC 进行数据分析并实施搜索策略，产生可与人类设计的基线竞争的解决方案。这些结果凸显了将分层多智能体系统与自我评估和自我反馈相结合的潜力，使人工智能系统能够进行独立、大规模的科学和分析工作。
> **Abstract**: We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.

【28】Multi-Agent Reinforcement Learning with Communication-Constrained Priors
- **标题**: 具有通信受限先验的多智能体强化学习
- **链接**: https://arxiv.org/abs/2512.03528
> **作者**: Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao
> **摘要**: 通信是提高多智能体系统中合作策略学习的有效手段之一。然而，在大多数现实场景中，有损通信是一个普遍存在的问题。现有的具有通信功能的多智能体强化学习由于其可扩展性和鲁棒性有限，很难应用于复杂和动态的现实环境。为了应对这些挑战，我们提出了一种广义的通信约束模型，以统一表征不同场景下的通信条件。基于此，我们将其用作先验学习，以区分特定场景的有损消息和无损消息。此外，我们利用双重互信息估计器解耦有损和无损消息对分布式决策的影响，并引入通信约束的多代理强化学习框架，将通信消息的影响量化为全局奖励。最后，我们在几个通信受限的基准测试中验证了我们方法的有效性。
> **Abstract**: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

## 硬件架构(cs.AR:Hardware Architecture)

【1】KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing
- **标题**: KVNAND：使用无 DRAM 闪存计算的高效设备上大型语言模型推理
- **链接**: https://arxiv.org/abs/2512.03608
> **作者**: Lishuo Deng,Shaojie Xu,Jinwu Chen,Changwei Yan,Jiajie Wang,Zhe Jiang,Weiwei Shan
> **摘要**: 在边缘设备上部署大型语言模型 (LLM) 可以实现具有强大隐私性和低成本的个性化代理。然而，单批次自回归推理的参数数量达到数百亿至数千亿，计算强度极低，对资源受限的平台造成严重的负载和带宽压力。最近的闪存计算 (IFC) 解决方案通过将解码阶段与权重相关的线性计算与闪存共同定位来缓解这一瓶颈，但仍然依赖 DRAM 进行键值 (KV) 缓存。随着上下文长度的增长，KV 缓存的大小可能会超过模型权重，从而对 DRAM 成本和容量提出过高的要求。尝试将 KV 缓存卸载到闪存会遭受严重的性能损失。我们提出了 KVNAND，这是第一个无 DRAM、基于 IFC 的架构，它将模型权重和 KV 缓存完全存储在支持计算的 3D NAND 闪存中。 KVNAND 通过利用 IFC 进行所有内存绑定操作来减少数据传输开销，引入头组并行性来提高吞吐量，并采用页级 KV 缓存映射来使令牌访问模式与闪存组织保持一致，从而解决密集 KV 缓存访问下闪存的基本性能挑战。此外，我们提出了一个设计空间探索框架，用于评估离散和紧凑的 KVNAND 变体，以平衡重量和 KV 布局，自动识别最佳设计权衡。这些技术缓解了延迟、能源和可靠性问题，将闪存转变为长上下文 KV 存储的实用介质。对 MHA 7B 和 GQA 70B LLM 的评估表明，与配备 DRAM 的 IFC 设计相比，KVNAND 在 128/1K/10K 令牌上下文中实现了 1.98\(\times\)/1.94\(\times\)/2.05\(\times\) 几何均值加速，并解决了 100K 上下文长度下的内存不足故障。
> **Abstract**: Deploying large language models (LLMs) on edge devices enables personalized agents with strong privacy and low cost. However, with tens to hundreds of billions of parameters, single-batch autoregressive inference suffers from extremely low arithmetic intensity, creating severe weight-loading and bandwidth pressures on resource-constrained platforms. Recent in-flash computing (IFC) solutions alleviate this bottleneck by co-locating weight-related linear computations in the decode phase with flash, yet still rely on DRAM for the key-value (KV) cache. As context length grows, the KV cache can exceed model weights in size, imposing prohibitive DRAM cost and capacity requirements. Attempts to offload KV cache to flash suffer from severe performance penalties. We propose KVNAND, the first DRAM-free, IFC-based architecture that stores both model weights and KV cache entirely in compute-enabled 3D NAND flash. KVNAND addresses the fundamental performance challenges of flash under intensive KV cache access by leveraging IFC for all memory-bound operations to reduce data transfer overhead, introducing head-group parallelism to boost throughput, and employing page-level KV cache mapping to align token access patterns with flash organization. In addition, we propose a design space exploration framework that evaluates discrete and compact KVNAND variants to balance weight and KV placement, automatically identifying the optimal design trade-off. These techniques mitigate latency, energy, and reliability concerns, turning flash into a practical medium for long-context KV storage. Evaluations on MHA 7B and GQA 70B LLMs show that KVNAND achieves 1.98\(\times\)/1.94\(\times\)/2.05\(\times\) geomean speedup at 128/1K/10K-token contexts compared to DRAM-equipped IFC designs and addresses out-of-memory failures at 100K context length.

## 计算语言学(cs.CL:Computation and Language)

【1】MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation
- **标题**: MASE：通过与模型无关的显着性估计来解释 NLP 模型
- **链接**: https://arxiv.org/abs/2512.04386
> **作者**: Zhou Yang,Shunyan Luo,Jiazhen Zhu,Fang Jin
> **摘要**: 深度神经网络 (DNN) 在自然语言处理 (NLP) 方面取得了重大进展，但其可解释性仍然难以捉摸，特别是在评估其复杂的决策过程时。传统方法通常依赖于事后解释，例如显着图或特征可视化，这可能无法直接适用于 NLP 中单词数据的离散性质。为了解决这个问题，我们引入了模型无关的显着性估计（MASE）框架。 MASE 为基于文本的预测模型提供本地解释，而无需深入了解模型的内部架构。通过在嵌入层上利用归一化线性高斯扰动 (NLGP) 而不是原始单词输入，MASE 可以有效地估计输入显着性。我们的结果表明 MASE 优于其他与模型无关的解释方法，特别是在 Delta 准确度方面，将其定位为阐明 NLP 中基于文本的模型操作的有前途的工具。
> **Abstract**: Deep neural networks (DNNs) have made significant strides in Natural Language Processing (NLP), yet their interpretability remains elusive, particularly when evaluating their intricate decision-making processes. Traditional methods often rely on post-hoc interpretations, such as saliency maps or feature visualization, which might not be directly applicable to the discrete nature of word data in NLP. Addressing this, we introduce the Model-agnostic Saliency Estimation (MASE) framework. MASE offers local explanations for text-based predictive models without necessitating in-depth knowledge of a model's internal architecture. By leveraging Normalized Linear Gaussian Perturbations (NLGP) on the embedding layer instead of raw word inputs, MASE efficiently estimates input saliency. Our results indicate MASE's superiority over other model-agnostic interpretation methods, especially in terms of Delta Accuracy, positioning it as a promising tool for elucidating the operations of text-based models in NLP.

【2】DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle
- **标题**: DAComp：整个数据智能生命周期中数据代理的基准测试
- **链接**: https://arxiv.org/abs/2512.04324
> **作者**: Fangyu Lei,Jinxiang Meng,Yiming Huang,Junjie Zhao,Yitong Zhang,Jianwen Luo,Xin Zou,Ruiyi Yang,Wenbo Shi,Yan Gao,Shizhu He,Zuo Wang,Qian Liu,Yang Wang,Ke Wang,Jun Zhao,Kang Liu
> **摘要**: 现实世界的企业数据智能工作流程包括将原始数据源转化为可分析的表格的数据工程，以及将这些表格转化为面向决策的见解的数据分析。我们引入了 DAComp，这是一个包含 210 项任务的基准，反映了这些复杂的工作流程。数据工程 (DE) 任务需要对工业模式进行存储库级工程，包括从头开始设计和构建多阶段 SQL 管道，以及根据不断变化的需求改进现有系统。数据分析 (DA) 任务提出了开放式业务问题，需要战略规划、通过迭代编码进行探索性分析、解释中间结果以及综合可行的建议。工程任务通过基于执行的多指标评估进行评分。开放式任务由可靠的、经过实验验证的法学硕士评审进行评估，该评审以分层的、精心设计的评估标准为指导。我们的实验表明，即使是最先进的代理在 DAComp 上也会出现问题。 DE 任务的性能特别低，成功率低于 20%，暴露了整体管道编排的关键瓶颈，而不仅仅是代码生成。 DA 任务的平均得分也低于 40%，凸显了开放式推理的严重缺陷，并表明工程和分析是截然不同的能力。通过清楚地诊断这些限制，DAComp 提供了严格且现实的测试平台，以推动为企业环境开发真正强大的自主数据代理。我们的数据和代码可在 https://da-comp.github.io 获取
> **Abstract**: Real-world enterprise data intelligence workflows encompass data engineering that turns raw sources into analytical-ready tables and data analysis that convert those tables into decision-oriented insights. We introduce DAComp, a benchmark of 210 tasks that mirrors these complex workflows. Data engineering (DE) tasks require repository-level engineering on industrial schemas, including designing and building multi-stage SQL pipelines from scratch and evolving existing systems under evolving requirements. Data analysis (DA) tasks pose open-ended business problems that demand strategic planning, exploratory analysis through iterative coding, interpretation of intermediate results, and the synthesis of actionable recommendations. Engineering tasks are scored through execution-based, multi-metric evaluation. Open-ended tasks are assessed by a reliable, experimentally validated LLM-judge, which is guided by hierarchical, meticulously crafted rubrics. Our experiments reveal that even state-of-the-art agents falter on DAComp. Performance on DE tasks is particularly low, with success rates under 20%, exposing a critical bottleneck in holistic pipeline orchestration, not merely code generation. Scores on DA tasks also average below 40%, highlighting profound deficiencies in open-ended reasoning and demonstrating that engineering and analysis are distinct capabilities. By clearly diagnosing these limitations, DAComp provides a rigorous and realistic testbed to drive the development of truly capable autonomous data agents for enterprise settings. Our data and code are available at https://da-comp.github.io

【3】SkillFactory: Self-Distillation For Learning Cognitive Behaviors
- **标题**: SkillFactory：学习认知行为的自我蒸馏
- **链接**: https://arxiv.org/abs/2512.04072
> **作者**: Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett
> **摘要**: 利用长思维链的推理模型采用各种认知技能，例如验证答案、回溯、通过替代方法重试等等。之前的工作表明，当基础语言模型表现出这些技能时，通过强化学习 (RL) 进一步训练该模型可以学会利用这些技能。我们怎样才能让模型利用基础模型没有展示的技能？我们的工作 SkillFactory 是一种微调模型的方法，可以在强化学习之前的监督微调 (SFT) 阶段粗略地学习这些技能。我们的方法不依赖于从更强大的模型中蒸馏出来，而是使用模型本身的样本，重新排列以提供这些技能格式的训练数据。这些“银色”SFT 轨迹可能并不完美，但对于启动模型在强化学习期间获取技能来说仍然有效。我们的评估表明，（1）从 SkillFactory SFT 初始化开始，可以帮助模型泛化到强化学习后任务的更难变体，尽管强化学习前的性能较低； (2) 模型确实使用了认知技能； (3) RLed SkillFactory 模型对于域外任务的回归比 RLed 基础模型更稳健。我们的工作表明，在强化学习之前学习的归纳偏差有助于模型学习强大的认知技能使用。
> **Abstract**: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

【4】Jina-VLM: Small Multilingual Vision Language Model
- **标题**: Jina-VLM：小型多语言视觉语言模型
- **链接**: https://arxiv.org/abs/2512.04032
> **作者**: Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao
> **摘要**: 我们提出了 Jina-VLM，这是一种 2.4B 参数视觉语言模型，可在开放的 2B 规模 VLM 中实现最先进的多语言视觉问答。该模型通过注意力池连接器将 SigLIP2 视觉编码器与 Qwen3 语言主干耦合起来，从而实现对任意分辨率图像的令牌高效处理。该模型在标准 VQA 基准和多语言评估上取得了领先的结果，同时保持了有竞争力的纯文本性能。模型权重和代码公开发布于 https://huggingface.co/jinaai/jina-vlm 。
> **Abstract**: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. The model achieves leading results on standard VQA benchmarks and multilingual evaluations while preserving competitive text-only performance. Model weights and code are publicly released at https://huggingface.co/jinaai/jina-vlm .

【5】Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions
- **标题**: 在伊斯兰教中，说谎只是有罪吗？探索主要宗教的多语言大语言模型中的宗教偏见
- **链接**: https://arxiv.org/abs/2512.03943
> **作者**: Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque
> **摘要**: 尽管大型语言模型的最新发展改进了偏差检测和分类，但宗教等敏感主题仍然面临挑战，因为即使是很小的错误也可能导致严重的误解。特别是，多语言模型经常歪曲宗教，并且很难在宗教背景下准确表达。为了解决这个问题，我们引入了 BRAND：双语宗教责任规范数据集，该数据集关注南亚四大主要宗教：佛教、基督教、印度教和伊斯兰教，包含 2,400 多个条目，我们使用了英语和孟加拉语三种不同类型的提示。我们的结果表明，模型在英语中的表现比在孟加拉语中的表现更好，并且即使在回答宗教中立的问题时也始终表现出对伊斯兰教的偏见。这些发现凸显了当用不同语言提出类似问题时，多语言模型中持续存在的偏见。我们进一步将我们的发现与人机交互中有关宗教和灵性的更广泛问题联系起来。
> **Abstract**: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

【6】BERnaT: Basque Encoders for Representing Natural Textual Diversity
- **标题**: BERnaT：用于表示自然文本多样性的巴斯克编码器
- **链接**: https://arxiv.org/abs/2512.03903
> **作者**: Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa
> **摘要**: 语言模型依赖于大量文本语料库，这些文本语料库通常会进行质量过滤，这一过程可能会无意中排除非标准语言品种，降低模型的稳健性并强化表征偏差。在本文中，我们认为语言模型的目标应该是捕捉全部语言变异（方言、历史、非正式等），而不是仅仅依赖标准化文本。我们以巴斯克语这种形态丰富且资源匮乏的语言为重点，结合标准、社交媒体和历史来源构建了新的语料库，并以三种配置预训练了 BERnaT 系列仅编码器模型：标准、多样化和组合。我们进一步提出了一个评估框架，将自然语言理解（NLU）任务分为标准和多样化的子集，以评估语言泛化。结果表明，在标准和多样化数据上训练的模型始终优于在标准语料库上训练的模型，在不影响标准基准准确性的情况下提高了所有任务类型的性能。这些发现强调了语言多样性在构建包容性、可推广的语言模型中的重要性。
> **Abstract**: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

【7】In-Context Representation Hijacking
- **标题**: 上下文表示劫持
- **链接**: https://arxiv.org/abs/2512.03771
> **作者**: Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman
> **摘要**: 我们引入了 $\textbf{Doublespeak}$，这是一种针对大型语言模型 (LLM) 的简单上下文表示劫持攻击。该攻击的工作原理是在多个上下文示例中系统地用良性标记（例如胡萝卜）替换有害关键字（例如炸弹），并为有害请求提供前缀。我们证明，这种替换导致良性标记的内部表示向有害标记的内部表示收敛，从而有效地将有害语义嵌入到委婉语中。因此，表面上无害的提示（例如，“如何建造胡萝卜？”）在内部被解释为不允许的指令（例如，“如何建造炸弹？”），从而绕过模型的安全对齐。我们使用可解释性工具来表明这种语义覆盖是逐层出现的，早期层中的良性含义在后面层中汇聚成有害语义。 Doublespeak 无需优化，可以广泛地跨模型系列迁移，并且在闭源和开源系统上取得了很高的成功率，在 Llama-3.3-70B-Instruct 上通过单句上下文覆盖达到了 74% 的 ASR。我们的研究结果强调了法学硕士潜在空间中的一个新的攻击面，表明当前的对齐策略是不够的，应该在表征层面上操作。
> **Abstract**: We introduce $\textbf{Doublespeak}$, a simple in-context representation hijacking attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., bomb) with a benign token (e.g., carrot) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., "How to build a carrot?") are internally interpreted as disallowed instructions (e.g., "How to build a bomb?"), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

【8】Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective
- **标题**: 扩散法学硕士的有原则的强化学习从序列水平的角度出现
- **链接**: https://arxiv.org/abs/2512.03759
> **作者**: Jingyang Ou,Jiaqi Han,Minkai Xu,Shaoxuan Xu,Jianwen Xie,Stefano Ermon,Yi Wu,Chongxuan Li
> **摘要**: 强化学习 (RL) 已被证明对于自回归语言模型非常有效，但将这些方法应用于扩散大语言模型 (dLLM) 提出了根本性的挑战。核心困难在于似然近似：虽然自回归模型自然地提供了令牌级 RL 目标（例如 GRPO）所必需的令牌级条件概率，但 dLLM 通过缺乏这种因式分解的迭代非自回归去噪步骤来生成序列。为了解决这种根本性的不匹配问题，我们提出了基于 ELBO 的序列级策略优化 (ESPO)，这是一种有原则的 RL 框架，它将整个序列生成视为单个操作，并使用 ELBO 作为易于处理的序列级似然代理。我们的方法结合了每个标记的重要性比归一化和稳健的 KL 散度估计，以确保稳定的大规模训练。针对数学推理、编码和规划任务的大量实验表明，ESPO 的性能显着优于代币级基准，在倒计时任务上实现了 20-40 分的显着改进，同时在数学和编码基准上保持一致的收益。我们的方法将序列级优化建立为 dLLM 中 RL 的原则性且经验有效的范例。我们的代码可在 https://github.com/ML-GSAI/ESPO 获取。
> **Abstract**: Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.

【9】AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment
- **标题**: AlignCheck：用于事实一致性评估的语义开放域度量
- **链接**: https://arxiv.org/abs/2512.03634
> **作者**: Ahmad Aghaebrahimian
> **摘要**: 大型语言模型具有显着先进的自然语言处理任务，但仍然容易生成不正确或误导性但合理的论点。这个问题被称为幻觉，在临床应用等高风险领域尤其令人担忧，在这些领域，事实不准确可能会产生严重后果。现有的评估指标无法充分评估事实的一致性并且缺乏可解释性，使得诊断和减少错误变得困难。我们提出了一个可解释的框架，用于域内和开放域文本的事实一致性评估，以解决这些限制。我们的方法将文本分解为原子事实，并引入了灵活的、无模式的方法。与以前使用绝对度量的方法不同，我们采用了加权度量来增强事实评估。此外，我们提出了一种控制复杂领域评估复杂性的机制。我们对流行的一般和临床数据集的方法进行基准测试，并发布我们的代码以支持未来研究中的事实感知模型训练。
> **Abstract**: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

【10】Fine-grained Narrative Classification in Biased News Articles
- **标题**: 有偏见的新闻文章中的细粒度叙事分类
- **链接**: https://arxiv.org/abs/2512.03582
> **作者**: Zeba Afroz,Harsh Vardhan,Pawan Bhakuni,Aanchal Punia,Rajdeep Kumar,Md. Shad Akhtar
> **摘要**: 叙事是宣传的认知和情感支架。他们将孤立的说服技巧组织成连贯的故事，为行动辩护，归咎责任，并唤起人们对意识形态阵营的认同。在本文中，我们提出了一种针对有偏见的新闻文章的新颖的细粒度叙事分类。我们还探索文章偏见分类作为叙事分类和细粒度说服技术识别的先驱任务。我们开发了 INDI-PROP，这是第一个基于意识形态的细粒度叙事数据集，具有多级注释，用于分析印度新闻媒体的宣传。我们的数据集 INDI-PROP 包含 1,266 篇文章，重点关注近期两个两极分化的社会政治事件：CAA 和农民抗议。每篇文章都按三个层次进行注释：（i）意识形态文章偏见（支持政府、支持反对派、中立），（ii）基于意识形态极性和交流意图的特定事件的细粒度叙事框架，以及（iii）说服技巧。我们提出了 FANTA 和 TPTC，这两个 GPT-4o-mini 引导的多跳基于提示的推理框架，用于偏见、叙述和说服技术分类。 FANTA 通过集成信息提取和上下文框架来进行分层推理，从而利用多层交流现象。另一方面，TPTC 通过两阶段方法对说服线索进行系统分解。我们的评估表明每种情况下的基本基线都有显着改善。
> **Abstract**: Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.

## 密码学和安全(cs.CR:Cryptography and Security)

【1】AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning
- **标题**: AutoGuard：使用强化学习的 DevSecOps 管道的自我修复主动安全层
- **链接**: https://arxiv.org/abs/2512.04368
> **作者**: Praveen Anugula,Avdhesh Kumar Bhardwaj,Navin Chhibber,Rohit Tewari,Sunil Khemka,Piyush Ranjan
> **摘要**: 当代 DevSecOps 管道必须应对不断集成和部署的环境中安全性的演变。现有的方法（例如基于规则的入侵检测和静态漏洞扫描）不足以应对系统中的变化，导致响应时间更长，组织需要暴露于新兴的攻击向量。鉴于之前的限制，我们将 AutoGuard 引入 DevSecOps 生态系统，这是一个由强化学习 (RL) 支持的自我修复安全框架，旨在先发制人地保护 DevSecOps 环境。 AutoGuard 是一种自我保护的安全环境，可以持续观察管道活动是否存在潜在异常，同时抢先修复环境。该模型根据随时间不断动态学习的策略进行观察并做出反应。强化学习代理通过基于奖励的学习随着时间的推移改进每个操作，旨在提高代理实时预防、检测和响应安全事件的能力。使用模拟持续集成/持续部署 (CI/CD) 环境进行的测试表明，与传统方法相比，AutoGuard 成功地将威胁检测准确性提高了 22%，将事件的平均恢复时间 (MTTR) 缩短了 38%，并提高了事件的整体恢复能力。关键词 - DevSecOps、强化学习、自我修复安全、持续集成、自动威胁缓解
> **Abstract**: Contemporary DevSecOps pipelines have to deal with the evolution of security in an ever-continuously integrated and deployed environment. Existing methods,such as rule-based intrusion detection and static vulnerability scanning, are inadequate and unreceptive to changes in the system, causing longer response times and organization needs exposure to emerging attack vectors. In light of the previous constraints, we introduce AutoGuard to the DevSecOps ecosystem, a reinforcement learning (RL)-powered self-healing security framework built to pre-emptively protect DevSecOps environments. AutoGuard is a self-securing security environment that continuously observes pipeline activities for potential anomalies while preemptively remediating the environment. The model observes and reacts based on a policy that is continually learned dynamically over time. The RL agent improves each action over time through reward-based learning aimed at improving the agent's ability to prevent, detect and respond to a security incident in real-time. Testing using simulated ContinuousIntegration / Continuous Deployment (CI/CD) environments showed AutoGuard to successfully improve threat detection accuracy by 22%, reduce mean time torecovery (MTTR) for incidents by 38% and increase overall resilience to incidents as compared to traditional methods. Keywords- DevSecOps, Reinforcement Learning, Self- Healing Security, Continuous Integration, Automated Threat Mitigation

【2】Hey GPT-OSS, Looks Like You Got It -- Now Walk Me Through It! An Assessment of the Reasoning Language Models Chain of Thought Mechanism for Digital Forensics
- **标题**: 嘿 GPT-OSS，看起来您已经明白了——现在带我了解一下！数字取证推理语言模型思想链机制的评估
- **链接**: https://arxiv.org/abs/2512.04254
> **作者**: Gaëtan Michelet,Janine Schneider,Aruna Withanage,Frank Breitinger
> **摘要**: 大型语言模型在数字取证中的使用已被广泛探索。除了确定潜在的应用之外，研究还侧重于通过微调来优化取证任务的模型性能。然而，有限的结果可解释性降低了其操作和法律可用性。最近，出现了一类新的推理语言模型，旨在通过“内部推理”机制处理基于逻辑的任务。然而，用户通常只能看到最终答案，而看不到潜在的推理。这些推理模型之一是 gpt-oss，它可以本地部署，提供对其底层推理过程的完全访问。本文首次研究了推理语言模型在数字取证中的潜力。检查四个测试用例以评估推理组件在支持结果可解释性方面的可用性。该评估将新的定量指标与定性分析相结合。研究结果表明，推理组件有助于解释和验证中等推理水平的数字取证中的语言模型输出，但这种支持通常是有限的，并且较高的推理水平并不能提高响应质量。
> **Abstract**: The use of large language models in digital forensics has been widely explored. Beyond identifying potential applications, research has also focused on optimizing model performance for forensic tasks through fine-tuning. However, limited result explainability reduces their operational and legal usability. Recently, a new class of reasoning language models has emerged, designed to handle logic-based tasks through an `internal reasoning' mechanism. Yet, users typically see only the final answer, not the underlying reasoning. One of these reasoning models is gpt-oss, which can be deployed locally, providing full access to its underlying reasoning process. This article presents the first investigation into the potential of reasoning language models for digital forensics. Four test use cases are examined to assess the usability of the reasoning component in supporting result explainability. The evaluation combines a new quantitative metric with qualitative analysis. Findings show that the reasoning component aids in explaining and validating language model outputs in digital forensics at medium reasoning levels, but this support is often limited, and higher reasoning levels do not enhance response quality.

【3】Towards Contextual Sensitive Data Detection
- **标题**: 迈向上下文敏感数据检测
- **链接**: https://arxiv.org/abs/2512.04120
> **作者**: Liang Telkamp,Madelon Hulsebos
> **摘要**: 开放数据门户的出现需要在数据集发布和交换之前更加关注保护敏感数据。虽然存在大量抑制敏感数据的方法，但敏感数据的概念化和检测敏感数据的方法特别关注个人数据，这些数据如果泄露，可能会有害或侵犯隐私。我们观察到需要完善和扩大敏感数据的定义，并认为数据的敏感性取决于其上下文。基于这个定义，我们引入了两种上下文敏感数据检测机制，它们考虑了手头数据集更广泛的上下文。首先，我们引入类型上下文化，它首先检测特定数据值的语义类型，然后考虑数据集或文档中数据值的整体上下文。其次，我们引入域上下文化，它根据从指定数据敏感性（例如数据主题和地理起源）的文档中检索相关规则来确定更广泛上下文中给定数据集的敏感性。在大型语言模型 (LLM) 的辅助下，对这些机制进行的实验证实：1) 类型上下文化显着减少了基于类型的敏感数据检测的误报数量，召回率达到了 94%，而商业工具的召回率为 63%；2) 利用敏感度规则检索的域上下文化对于人道主义数据集等非标准数据域中基于上下文的敏感数据检测非常有效。人道主义数据专家的评估还表明，基于背景的法学硕士解释为手动数据审计流程提供了有用的指导，提高了一致性。我们在 https://github.com/trl-lab/sensitive-data-detection 上开源了用于上下文敏感数据检测的机制和注释数据集。
> **Abstract**: The emergence of open data portals necessitates more attention to protecting sensitive data before datasets get published and exchanged. While an abundance of methods for suppressing sensitive data exist, the conceptualization of sensitive data and methods to detect it, focus particularly on personal data that, if disclosed, may be harmful or violate privacy. We observe the need for refining and broadening our definitions of sensitive data, and argue that the sensitivity of data depends on its context. Based on this definition, we introduce two mechanisms for contextual sensitive data detection that consider the broader context of a dataset at hand. First, we introduce type contextualization, which first detects the semantic type of particular data values, then considers the overall context of the data values within the dataset or document. Second, we introduce domain contextualization which determines sensitivity of a given dataset in the broader context based on the retrieval of relevant rules from documents that specify data sensitivity (e.g., data topic and geographic origin). Experiments with these mechanisms, assisted by large language models (LLMs), confirm that: 1) type-contextualization significantly reduces the number of false positives for type-based sensitive data detection and reaches a recall of 94% compared to 63% with commercial tools, and 2) domain-contextualization leveraging sensitivity rule retrieval is effective for context-grounded sensitive data detection in non-standard data domains such as humanitarian datasets. Evaluation with humanitarian data experts also reveals that context-grounded LLM explanations provide useful guidance in manual data auditing processes, improving consistency. We open-source mechanisms and annotated datasets for contextual sensitive data detection at https://github.com/trl-lab/sensitive-data-detection.

【4】Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs
- **标题**: 上下文感知的分层学习：迈向更安全的法学硕士的两步范式
- **链接**: https://arxiv.org/abs/2512.03720
> **作者**: Tengyun Ma,Jiaqi Yao,Daojing He,Shihao Peng,Yu Li,Shaohui Liu,Zhuotao Tian
> **摘要**: 大型语言模型 (LLM) 已成为各种应用程序的强大工具。然而，它们的统一令牌处理范例在指令处理中引入了严重的漏洞，特别是在暴露于对抗性场景时。在这项工作中，我们识别并提出了一类新型漏洞，称为工具完成攻击（TCA），它利用函数调用机制来破坏模型行为。为了评估 LLM 针对此类威胁的鲁棒性，我们引入了 Tool-Completion 基准，这是一个全面的安全评估框架，它表明即使是最先进的模型也仍然容易受到 TCA 的影响，并且攻击成功率高得惊人。为了解决这些漏洞，我们引入了上下文感知分层学习（CAHL），这是一种复杂的机制，可以动态平衡语义理解与特定于角色的指令约束。 CAHL 利用不同指令段之间的上下文相关性来建立强大的、上下文感知的指令层次结构。大量实验表明，CAHL 显着增强了 LLM 针对传统攻击和所提出的 TCA 的鲁棒性，在零样本评估中表现出强大的泛化能力，同时仍然保留了通用任务上的模型性能。我们的代码可在 https://github.com/S2AILab/CAHL 获取。
> **Abstract**: Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.

【5】SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting
- **标题**: SELF：LLM 指纹识别的稳健奇异值和特征值方法
- **链接**: https://arxiv.org/abs/2512.03620
> **作者**: Hanxiu Zhang,Yue Zheng
> **摘要**: 大型语言模型 (LLM) 中的知识产权 (IP) 保护是当代人工智能研究中的一项严峻挑战。虽然指纹识别技术已成为检测未经授权的模型使用的基本机制，但现有方法（无论是基于行为的还是结构性的）都存在诸如虚假声明攻击或容易受到权重操纵等漏洞。为了克服这些限制，我们提出了 SELF，一种新颖的基于内在权重的指纹识别方案，消除了对输入的依赖，并固有地抵制虚假声明。 SELF 通过两项关键创新实现了强大的知识产权保护：1）通过 LLM 注意力权重的奇异值和特征值分解进行独特、可扩展且变换不变的指纹提取，2）基于少样本学习和数据增强的有效的基于神经网络的指纹相似性比较。实验结果表明，SELF 保持了较高的 IP 侵权检测精度，同时对各种下游修改（包括量化、剪枝和微调攻击）表现出强大的鲁棒性。我们的代码可在 https://github.com/HanxiuZhang/SELF_v2 获取。
> **Abstract**: The protection of Intellectual Property (IP) in Large Language Models (LLMs) represents a critical challenge in contemporary AI research. While fingerprinting techniques have emerged as a fundamental mechanism for detecting unauthorized model usage, existing methods -- whether behavior-based or structural -- suffer from vulnerabilities such as false claim attacks or susceptible to weight manipulations. To overcome these limitations, we propose SELF, a novel intrinsic weight-based fingerprinting scheme that eliminates dependency on input and inherently resists false claims. SELF achieves robust IP protection through two key innovations: 1) unique, scalable and transformation-invariant fingerprint extraction via singular value and eigenvalue decomposition of LLM attention weights, and 2) effective neural network-based fingerprint similarity comparison based on few-shot learning and data augmentation. Experimental results demonstrate SELF maintains high IP infringement detection accuracy while showing strong robustness against various downstream modifications, including quantization, pruning, and fine-tuning attacks. Our code is available at https://github.com/HanxiuZhang/SELF_v2.

【6】In-Situ Encryption of Single-Transistor Nonvolatile Memories without Density Loss
- **标题**: 无密度损失的单晶体管非易失性存储器的原位加密
- **链接**: https://arxiv.org/abs/2512.03461
> **作者**: Sanwar Ahmed Ovy,Jiahui Duan,Md Ashraful Islam Romel,Franz Muller,Thomas Kampfe,Kai Ni,Sumitha George
> **摘要**: 非易失性存储器 (NVM) 具有可忽略的泄漏功耗、高集成密度和数据保留能力，但其非易失性也增加了数据泄露的风险。高级加密标准 (AES) 等传统加密技术会产生较大的面积开销和性能损失，从而激发了具有低面积和功耗要求的轻量级基于 XOR 的原位加密方案。这项工作提出了一种使用铁电 FET (FeFET) 器件的超密集单晶体管加密单元，据我们所知，该器件首次消除了基于 XOR 的方案中每个加密单元两个存储器件的要求，使加密存储阵列能够保持与未加密阵列相同数量的存储器件。关键思想是内存中单 FeFET XOR 方案，其中密文在器件阈值电压中进行编码，并利用 FeFET 的方向相关电流进行单周期解密；消除互补位存储还消除了对两个写入周期的需要，从而允许更快的加密。我们将该方法扩展到多层单元 (MLC) FeFET，以便每个晶体管存储多个位。我们通过模拟和实验评估验证了所提出的想法。我们对 128x128 位阵列的分析显示，加密/解密吞吐量比之前的 FeFET 工作高 2 倍，比 AES 提高 45.2 倍/14.12 倍，而使用神经网络基准的应用程序级评估表明，与之前基于 FeFET 和基于 AES 的方案相比，平均延迟分别减少了 50% 和 95%。
> **Abstract**: Non-volatile memories (NVMs) offer negligible leakage power consumption, high integration density, and data retention, but their non-volatility also raises the risk of data exposure. Conventional encryption techniques such as the Advanced Encryption Standard (AES) incur large area overheads and performance penalties, motivating lightweight XOR-based in-situ encryption schemes with low area and power requirements. This work proposes an ultra-dense single-transistor encrypted cell using ferroelectric FET (FeFET) devices, which, to our knowledge, is the first to eliminate the two-memory-devices-per-encrypted-cell requirement in XOR-based schemes, enabling encrypted memory arrays to maintain the same number of storage devices as unencrypted arrays. The key idea is an in-memory single-FeFET XOR scheme, where the ciphertext is encoded in the device threshold voltage and leverages the direction-dependent current flow of the FeFET for single-cycle decryption; eliminating complementary bit storage also removes the need for two write cycles, allowing faster encryption. We extend the approach to multi-level-cell (MLC) FeFETs to store multiple bits per transistor. We validate the proposed idea through both simulation and experimental evaluations. Our analysis on a 128x128-bit array shows 2x higher encryption/decryption throughput than prior FeFET work and 45.2x/14.12x improvement over AES, while application-level evaluations using neural-network benchmarks demonstrate average latency reductions of 50% and 95% compared to prior FeFET-based and AES-based schemes, respectively.

## 计算机视觉和模式识别(cs.CV:Computer Vision and Pattern Recognition)

【1】StreamEQA: Towards Streaming Video Understanding for Embodied Scenarios
- **标题**: StreamEQA：面向具体场景的流媒体视频理解
- **链接**: https://arxiv.org/abs/2512.04451
> **作者**: Yifei Wang,Zhenkai Li,Tianwen Qian,Huanran Zheng,Zheng Wang,Yuqian Fu,Xiaoling Wang
> **摘要**: 随着具身智能向现实世界的部署迈进，对流式视觉输入进行持续感知和推理的能力变得至关重要。在这种情况下，代理必须保持对其环境的态势感知，理解与周围实体的交互，并根据过去的观察、当前上下文和预期的未来事件动态规划行动。为了促进这个方向的进展，我们引入了 StreamEQA，这是第一个为具体场景中的流视频问答而设计的基准测试。 StreamEQA 沿着两个正交维度评估现有的 MLLM：体现和流媒体。沿着体现维度，我们将问题分为三个级别：感知、交互和规划，逐步评估模型识别细粒度视觉细节、推理代理与对象交互以及执行高级目标导向推理的能力。对于流维度，问题分为后向推理、实时推理和前向推理，每种模式都依赖于不同的时间上下文。 StreamEQA 基于 156 个独立的长视频构建，定义了 42 个任务，并通过结合自动生成和人工细化的混合管道生成大约 21K 个带有精确时间戳的问答对。对 13 个最先进的视频法学硕士的评估表明，尽管在传统基准上表现强劲，但这些模型在具体场景中的流视频理解方面仍然存在困难。我们希望 StreamEQA 能够促进对具体应用程序的流视频理解的研究。
> **Abstract**: As embodied intelligence advances toward real-world deployment, the ability to continuously perceive and reason over streaming visual inputs becomes essential. In such settings, an agent must maintain situational awareness of its environment, comprehend the interactions with surrounding entities, and dynamically plan actions informed by past observations, current contexts, and anticipated future events. To facilitate progress in this direction, we introduce StreamEQA, the first benchmark designed for streaming video question answering in embodied scenarios. StreamEQA evaluates existing MLLMs along two orthogonal dimensions: Embodied and Streaming. Along the embodied dimension, we categorize the questions into three levels: perception, interaction, and planning, which progressively assess a model's ability to recognize fine-grained visual details, reason about agent-object interactions, and perform high-level goal-directed reasoning. For the streaming dimension, questions are divided into backward, real-time, and forward reasoning, with each mode relying on a distinct temporal context. Built upon 156 independent long videos, StreamEQA defines 42 tasks and generates approximately 21K question-answer pairs with precise timestamps through a hybrid pipeline combining automated generation and human refinement. Evaluations of 13 state-of-the-art video-LLMs reveal that, despite strong performance on conventional benchmarks, these models still struggle with streaming video understanding in embodied scenarios. We hope StreamEQA will catalyze research on streaming video understanding for embodied applications.

【2】MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving
- **标题**: MindDrive：一种连接世界模型和端到端自动驾驶视觉语言模型的一体化框架
- **链接**: https://arxiv.org/abs/2512.04441
> **作者**: Bin Suna,Yaoguang Caob,Yan Wanga,Rui Wanga,Jiachen Shanga,Xiejie Fenga,Jiayi Lu,Jia Shi,Shichun Yang,Xiaoyu Yane,Ziying Song
> **摘要**: 端到端自动驾驶（E2E-AD）已成为一种新范式，其中轨迹规划发挥着至关重要的作用。现有的研究主要遵循两个方向：面向轨迹生成，侧重于通过简单的决策机制产生高质量的轨迹；以及面向轨迹选择，进行多维评估以选择最佳轨迹，但缺乏足够的生成能力。在这项工作中，我们提出了 MindDrive，这是一个将高质量轨迹生成与全面决策推理相结合的协调框架。它建立了“上下文模拟-候选生成-多目标权衡”的结构化推理范式。特别是，所提出的未来感知轨迹生成器（FaTG）基于世界行动模型（WaM），执行自我调节的“假设”模拟来预测潜在的未来场景并生成有远见的候选轨迹。在此基础上，面向VLM的评估器（VLoE）利用大型视觉语言模型的推理能力，在安全性、舒适性和效率维度上进行多目标评估，从而做出合理且人性化的决策。对 NAVSIM-v1 和 NAVSIM-v2 基准的大量实验表明，MindDrive 在多维驾驶指标上实现了最先进的性能，显着增强了安全性、合规性和通用性。这项工作为可解释和认知引导的自动驾驶提供了一条有希望的道路。
> **Abstract**: End-to-End autonomous driving (E2E-AD) has emerged as a new paradigm, where trajectory planning plays a crucial role. Existing studies mainly follow two directions: trajectory generation oriented, which focuses on producing high-quality trajectories with simple decision mechanisms, and trajectory selection oriented, which performs multi-dimensional evaluation to select the best trajectory yet lacks sufficient generative capability. In this work, we propose MindDrive, a harmonized framework that integrates high-quality trajectory generation with comprehensive decision reasoning. It establishes a structured reasoning paradigm of "context simulation - candidate generation - multi-objective trade-off". In particular, the proposed Future-aware Trajectory Generator (FaTG), based on a World Action Model (WaM), performs ego-conditioned "what-if" simulations to predict potential future scenes and generate foresighted trajectory candidates. Building upon this, the VLM-oriented Evaluator (VLoE) leverages the reasoning capability of a large vision-language model to conduct multi-objective evaluations across safety, comfort, and efficiency dimensions, leading to reasoned and human-aligned decision making. Extensive experiments on the NAVSIM-v1 and NAVSIM-v2 benchmarks demonstrate that MindDrive achieves state-of-the-art performance across multi-dimensional driving metrics, significantly enhancing safety, compliance, and generalization. This work provides a promising path toward interpretable and cognitively guided autonomous driving.

【3】Self-Paced and Self-Corrective Masked Prediction for Movie Trailer Generation
- **标题**: 电影预告片生成的自定进度和自我修正屏蔽预测
- **链接**: https://arxiv.org/abs/2512.04426
> **作者**: Sidan Zhu,Hongteng Xu,Dixin Luo
> **摘要**: 作为一项具有挑战性的视频编辑任务，电影预告片生成涉及选择和重新组织电影镜头以创建引人入胜的预告片。目前，大多数现有的自动预告片生成方法采用“选择然后排名”的范例（即首先选择关键镜头然后对其进行排名），这不可避免地会出现错误传播并限制了生成预告片的质量。除了这个范式之外，我们提出了一种新的自定进度和自我校正的屏蔽预测方法，称为 SSMP，该方法通过双向上下文建模和渐进式自我校正在自动预告片生成方面取得了最先进的结果。特别是，SSMP 训练了一个 Transformer 编码器，该编码器以电影镜头序列作为提示，并相应地生成相应的预告片镜头序列。该模型通过屏蔽预测进行训练，从随机屏蔽的对应部分重建每个预告片镜头序列。掩模比率是自定进度的，允许任务难度适应模型，从而提高模型性能。在生成电影预告片时，模型在每一步都以高置信度填充镜头位置，并为下一次预测重新掩盖剩余位置，形成类似于人类编辑工作方式的渐进式自我校正机制。定量结果和用户研究都证明了 SSMP 与现有自动电影预告片生成方法相比的优越性。演示位于：https://github.com/Dixin-Lab/SSMP。
> **Abstract**: As a challenging video editing task, movie trailer generation involves selecting and reorganizing movie shots to create engaging trailers. Currently, most existing automatic trailer generation methods employ a "selection-then-ranking" paradigm (i.e., first selecting key shots and then ranking them), which suffers from inevitable error propagation and limits the quality of the generated trailers. Beyond this paradigm, we propose a new self-paced and self-corrective masked prediction method called SSMP, which achieves state-of-the-art results in automatic trailer generation via bi-directional contextual modeling and progressive self-correction. In particular, SSMP trains a Transformer encoder that takes the movie shot sequences as prompts and generates corresponding trailer shot sequences accordingly. The model is trained via masked prediction, reconstructing each trailer shot sequence from its randomly masked counterpart. The mask ratio is self-paced, allowing the task difficulty to adapt to the model and thereby improving model performance. When generating a movie trailer, the model fills the shot positions with high confidence at each step and re-masks the remaining positions for the next prediction, forming a progressive self-correction mechanism that is analogous to how human editors work. Both quantitative results and user studies demonstrate the superiority of SSMP in comparison to existing automatic movie trailer generation methods. Demo is available at: https://github.com/Dixin-Lab/SSMP.

【4】Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models
- **标题**: 使用多模态 RGB-D 融合和大型语言模型进行可解释的帕金森病步态识别
- **链接**: https://arxiv.org/abs/2512.04425
> **作者**: Manar Alnaasan,Md Selim Sarowar,Sungho Kim
> **摘要**: 准确且可解释的步态分析在帕金森病 (PD) 的早期检测中发挥着至关重要的作用，但大多数现有方法仍然受到单一模式输入、低鲁棒性和缺乏临床透明度的限制。本文提出了一种可解释的多模态框架，该框架集成了 RGB 和深度 (RGB-D) 数据，以在现实条件下识别帕金森步态模式。该系统采用基于 YOLOv11 的双编码器进行特定模态特征提取，然后采用多尺度局部全局提取（MLGE）模块和跨空间颈融合机制来增强时空表示。该设计可以捕捉细粒度的肢体运动（例如，减少手臂摆动）和整体步态动态（例如，短步幅或转身困难），即使在具有挑战性的场景中，例如低照明或由衣服引起的遮挡。为了确保可解释性，结合了冻结的大语言模型（LLM），将融合的视觉嵌入和结构化元数据翻译成有临床意义的文本解释。对多模态步态数据集的实验评估表明，与单输入基线相比，所提出的 RGB-D 融合框架实现了更高的识别精度、改进的对环境变化的鲁棒性以及清晰的视觉语言推理。通过将多模态特征学习与基于语言的可解释性相结合，这项研究弥合了视觉识别和临床理解之间的差距，为可靠且可解释的帕金森病步态分析提供了一种新颖的视觉语言范例。代码：https://github.com/manaralnaasan/RGB-D_parkinson-LLM
> **Abstract**: Accurate and interpretable gait analysis plays a crucial role in the early detection of Parkinsons disease (PD),yet most existing approaches remain limited by single-modality inputs, low robustness, and a lack of clinical transparency. This paper presents an explainable multimodal framework that integrates RGB and Depth (RGB-D) data to recognize Parkinsonian gait patterns under realistic conditions. The proposed system employs dual YOLOv11-based encoders for modality-specific feature extraction, followed by a Multi-Scale Local-Global Extraction (MLGE) module and a Cross-Spatial Neck Fusion mechanism to enhance spatial-temporal representation. This design captures both fine-grained limb motion (e.g., reduced arm swing) and overall gait dynamics (e.g., short stride or turning difficulty), even in challenging scenarios such as low lighting or occlusion caused by clothing. To ensure interpretability, a frozen Large Language Model (LLM) is incorporated to translate fused visual embeddings and structured metadata into clinically meaningful textual explanations. Experimental evaluations on multimodal gait datasets demonstrate that the proposed RGB-D fusion framework achieves higher recognition accuracy, improved robustness to environmental variations, and clear visual-linguistic reasoning compared with single-input baselines. By combining multimodal feature learning with language-based interpretability, this study bridges the gap between visual recognition and clinical understanding, offering a novel vision-language paradigm for reliable and explainable Parkinsons disease gait analysis. Code:https://github.com/manaralnaasan/RGB-D_parkinson-LLM

【5】UTrice: Unifying Primitives in Differentiable Ray Tracing and Rasterization via Triangles for Particle-Based 3D Scenes
- **标题**: UTrice：通过基于粒子的 3D 场景的三角形统一可微分光线追踪和光栅化中的基元
- **链接**: https://arxiv.org/abs/2512.04421
> **作者**: Changhe Liu,Ehsan Javanmardi,Naren Bao,Alex Orsholits,Manabu Tsukada
> **摘要**: 光线追踪 3D 高斯粒子可实现逼真的效果，例如景深、折射和用于新颖视图合成的灵活相机建模。然而，现有方法通过代理几何体追踪高斯分布，这需要构建复杂的中间网格并执行昂贵的相交测试。出现这种限制是因为基于高斯的粒子不太适合作为光线追踪和光栅化的统一基元。在这项工作中，我们提出了一种基于可微分三角形的光线追踪管道，它直接将三角形视为渲染基元，而不依赖于任何代理几何体。我们的结果表明，所提出的方法比现有的光线追踪方法实现了显着更高的渲染质量，同时保持了实时渲染性能。此外，我们的管道可以直接渲染通过基于光栅化的方法Triangle Splatting优化的三角形，从而统一了新颖视图合成中使用的图元。
> **Abstract**: Ray tracing 3D Gaussian particles enables realistic effects such as depth of field, refractions, and flexible camera modeling for novel-view synthesis. However, existing methods trace Gaussians through proxy geometry, which requires constructing complex intermediate meshes and performing costly intersection tests. This limitation arises because Gaussian-based particles are not well suited as unified primitives for both ray tracing and rasterization. In this work, we propose a differentiable triangle-based ray tracing pipeline that directly treats triangles as rendering primitives without relying on any proxy geometry. Our results show that the proposed method achieves significantly higher rendering quality than existing ray tracing approaches while maintaining real-time rendering performance. Moreover, our pipeline can directly render triangles optimized by the rasterization-based method Triangle Splatting, thus unifying the primitives used in novel-view synthesis.

【6】Dual-Stream Spectral Decoupling Distillation for Remote Sensing Object Detection
- **标题**: 用于遥感物体检测的双流光谱解耦蒸馏
- **链接**: https://arxiv.org/abs/2512.04413
> **作者**: Xiangyi Gao,Danpei Zhao,Bo Yuan,Wentao Li
> **摘要**: 知识蒸馏是一种有效且硬件友好的方法，在轻量化遥感目标检测中发挥着关键作用。然而，现有的蒸馏方法经常遇到遥感图像（RSI）中混合特征的问题，而忽略了细微特征变化引起的差异，导致知识混乱。为了应对这些挑战，我们提出了一种与架构无关的蒸馏方法，称为双流光谱解耦蒸馏（DS2D2），用于通用遥感物体检测任务。具体来说，DS2D2 集成了基于谱分解的显式和隐式蒸馏。首先，应用一阶小波变换进行谱分解，以保留 RSI 的关键空间特征。利用这种空间保留，密度无关尺度权重 (DISW) 旨在解决 RSI 中常见的密集和小物体检测的挑战。其次，我们展示了隐藏在微妙的学生-教师特征差异中的隐性知识，当检测头激活时，这些差异会显着影响预测。这种隐含知识是通过全频和高频放大器提取的，这些放大器将特征差​​异映射到预测偏差。在 DIOR 和 DOTA 数据集上的大量实验验证了该方法的有效性。具体来说，在 DIOR 数据集上，DS2D2 在 RetinaNet 的 AP50 中实现了 4.2% 的改进，在 Faster R-CNN 的 AP50 中实现了 3.8% 的改进，优于现有的蒸馏方法。源代码可在 https://github.com/PolarAid/DS2D2 获取。
> **Abstract**: Knowledge distillation is an effective and hardware-friendly method, which plays a key role in lightweighting remote sensing object detection. However, existing distillation methods often encounter the issue of mixed features in remote sensing images (RSIs), and neglect the discrepancies caused by subtle feature variations, leading to entangled knowledge confusion. To address these challenges, we propose an architecture-agnostic distillation method named Dual-Stream Spectral Decoupling Distillation (DS2D2) for universal remote sensing object detection tasks. Specifically, DS2D2 integrates explicit and implicit distillation grounded in spectral decomposition. Firstly, the first-order wavelet transform is applied for spectral decomposition to preserve the critical spatial characteristics of RSIs. Leveraging this spatial preservation, a Density-Independent Scale Weight (DISW) is designed to address the challenges of dense and small object detection common in RSIs. Secondly, we show implicit knowledge hidden in subtle student-teacher feature discrepancies, which significantly influence predictions when activated by detection heads. This implicit knowledge is extracted via full-frequency and high-frequency amplifiers, which map feature differences to prediction deviations. Extensive experiments on DIOR and DOTA datasets validate the effectiveness of the proposed method. Specifically, on DIOR dataset, DS2D2 achieves improvements of 4.2% in AP50 for RetinaNet and 3.8% in AP50 for Faster R-CNN, outperforming existing distillation approaches. The source code will be available at https://github.com/PolarAid/DS2D2.

【7】Performance Evaluation of Transfer Learning Based Medical Image Classification Techniques for Disease Detection
- **标题**: 基于迁移学习的疾病检测医学图像分类技术的性能评估
- **链接**: https://arxiv.org/abs/2512.04397
> **作者**: Zeeshan Ahmad,Shudi Bao,Meng Chen
> **摘要**: 医学图像分类通过根据X射线、MRI和CT扫描等医学图像的特征将其分为不同的类别，在识别各种疾病方面发挥着越来越重要的作用。近年来，深度学习技术在医学图像分类中引起了广泛关注。然而，从头开始训练整个大型深度学习模型通常是不可行的。为了解决这个问题，解决方案之一是迁移学习（TL）技术，将预先训练的模型重复用于新任务。在本文中，我们对使用深度卷积神经网络进行医学图像分类的 TL 技术进行了全面分析。我们在用于疾病检测的自定义胸部 X 射线数据集上评估了六个预训练模型（AlexNet、VGG16、ResNet18、ResNet34、ResNet50 和 InceptionV3）。实验结果表明，InceptionV3 在所有标准指标上始终优于其他模型。 ResNet 系列随着深度的增加逐渐表现出更好的性能，而 VGG16 和 AlexNet 表现相当不错，但精度较低。此外，我们还进行不确定性分析和运行时比较，以评估这些模型的鲁棒性和计算效率。我们的研究结果表明，TL 在大多数情况下都是有益的，尤其是在数据有限的情况下，但改进的程度取决于几个因素，例如模型架构、数据集大小以及源任务和目标任务之间的域相似性。此外，我们证明，通过训练有素的特征提取器，只需轻量级前馈模型就足以提供有效的预测。因此，本研究有助于理解医学图像分类中的 TL，并为根据特定要求选择合适的模型提供见解。
> **Abstract**: Medical image classification plays an increasingly vital role in identifying various diseases by classifying medical images, such as X-rays, MRIs and CT scans, into different categories based on their features. In recent years, deep learning techniques have attracted significant attention in medical image classification. However, it is usually infeasible to train an entire large deep learning model from scratch. To address this issue, one of the solutions is the transfer learning (TL) technique, where a pre-trained model is reused for a new task. In this paper, we present a comprehensive analysis of TL techniques for medical image classification using deep convolutional neural networks. We evaluate six pre-trained models (AlexNet, VGG16, ResNet18, ResNet34, ResNet50, and InceptionV3) on a custom chest X-ray dataset for disease detection. The experimental results demonstrate that InceptionV3 consistently outperforms other models across all the standard metrics. The ResNet family shows progressively better performance with increasing depth, whereas VGG16 and AlexNet perform reasonably well but with lower accuracy. In addition, we also conduct uncertainty analysis and runtime comparison to assess the robustness and computational efficiency of these models. Our findings reveal that TL is beneficial in most cases, especially with limited data, but the extent of improvement depends on several factors such as model architecture, dataset size, and domain similarity between source and target tasks. Moreover, we demonstrate that with a well-trained feature extractor, only a lightweight feedforward model is enough to provide efficient prediction. As such, this study contributes to the understanding of TL in medical image classification, and provides insights for selecting appropriate models based on specific requirements.

【8】Fourier-Attentive Representation Learning: A Fourier-Guided Framework for Few-Shot Generalization in Vision-Language Models
- **标题**: 傅里叶注意力表示学习：视觉语言模型中小样本泛化的傅里叶引导框架
- **链接**: https://arxiv.org/abs/2512.04395
> **作者**: Hieu Dinh Trung Pham,Huy Minh Nhat Nguyen,Cuong Tuan Nguyen
> **摘要**: 大规模预训练视觉语言模型（VLM）已表现出强大的小样本学习能力。然而，这些方法通常学习整体表示，其中图像的领域不变结构隐式地与其特定领域的风格纠缠在一起。这提供了一个通过解开这些视觉线索来进一步增强泛化能力的机会。在本文中，我们提出了傅里叶注意力表示学习（FARL），这是一种新颖的框架，它通过使用傅里叶分析明确地解开视觉表示来解决这个问题。我们方法的核心是双重交叉注意机制，其中可学习的表示标记分别查询图像的结构特征（来自相位谱）和风格特征（来自幅度谱）。这个过程会产生丰富的、解开​​的令牌，然后将其深入注入 VLM 编码器以指导适应。我们的设计包括不对称注入策略，迫使模型学习更强大的视觉语言对齐。对 15 个数据集的广泛实验证明了我们方法的有效性。
> **Abstract**: Large-scale pre-trained Vision-Language Models (VLMs) have demonstrated strong few-shot learning capabilities. However, these methods typically learn holistic representations where an image's domain-invariant structure is implicitly entangled with its domain-specific style. This presents an opportunity to further enhance generalization by disentangling these visual cues. In this paper, we propose Fourier-Attentive Representation Learning (FARL), a novel framework that addresses this by explicitly disentangling visual representations using Fourier analysis. The core of our method is a dual cross-attention mechanism, where learnable representation tokens separately query an image's structural features (from the phase spectrum) and stylistic features (from the amplitude spectrum). This process yields enriched, disentangled tokens that are then injected deep into the VLM encoders to guide adaptation. Our design, which includes an asymmetric injection strategy, forces the model to learn a more robust vision-language alignment. Extensive experiments on 15 datasets demonstrate the effectiveness of our approach.

【9】FMA-Net++: Motion- and Exposure-Aware Real-World Joint Video Super-Resolution and Deblurring
- **标题**: FMA-Net++：运动和曝光感知的真实世界联合视频超分辨率和去模糊
- **链接**: https://arxiv.org/abs/2512.04390
> **作者**: Geunhyuk Youk,Jihyong Oh,Munchurl Kim
> **摘要**: 现实世界的视频恢复受到运动造成的复杂退化和动态变化的曝光的困扰——这是以前的工作很大程度上忽视的一个关键挑战，也是自动曝光或低光捕捉的常见伪像。我们提出了 FMA-Net++，这是一个用于联合视频超分辨率和去模糊的框架，它明确地模拟了运动和动态变化曝光的耦合效应。 FMA-Net++ 采用基于分层细化和双向传播模块构建的序列级架构，可实现并行、远程时间建模。在每个块中，曝光时间感知调制层以每帧曝光为特征，这反过来又驱动曝光感知流引导动态过滤模块来推断运动和曝光感知退化内核。 FMA-Net++ 将退化学习与恢复解耦：前者预测曝光和运动感知先验来指导后者，从而提高准确性和效率。为了在真实的拍摄条件下进行评估，我们引入了 REDS-ME（多重曝光）和 REDS-RE（随机曝光）基准。仅基于合成数据进行训练，FMA-Net++ 在我们的新基准和 GoPro 上实现了最先进的准确性和时间一致性，在恢复质量和推理速度方面均优于最新方法，并且可以很好地推广到具有挑战性的现实世界视频。
> **Abstract**: Real-world video restoration is plagued by complex degradations from motion coupled with dynamically varying exposure - a key challenge largely overlooked by prior works and a common artifact of auto-exposure or low-light capture. We present FMA-Net++, a framework for joint video super-resolution and deblurring that explicitly models this coupled effect of motion and dynamically varying exposure. FMA-Net++ adopts a sequence-level architecture built from Hierarchical Refinement with Bidirectional Propagation blocks, enabling parallel, long-range temporal modeling. Within each block, an Exposure Time-aware Modulation layer conditions features on per-frame exposure, which in turn drives an exposure-aware Flow-Guided Dynamic Filtering module to infer motion- and exposure-aware degradation kernels. FMA-Net++ decouples degradation learning from restoration: the former predicts exposure- and motion-aware priors to guide the latter, improving both accuracy and efficiency. To evaluate under realistic capture conditions, we introduce REDS-ME (multi-exposure) and REDS-RE (random-exposure) benchmarks. Trained solely on synthetic data, FMA-Net++ achieves state-of-the-art accuracy and temporal consistency on our new benchmarks and GoPro, outperforming recent methods in both restoration quality and inference speed, and generalizes well to challenging real-world videos.

【10】MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching
- **标题**: MAFNet：用于实时立体匹配的多频自适应融合网络
- **链接**: https://arxiv.org/abs/2512.04358
> **作者**: Ao Xu,Rujin Zhao,Xiong Xu,Boceng Huang,Yujia Jia,Hongfeng Long,Fuxuan Chen,Zilong Cao,Fangyuan Chen
> **摘要**: 现有的立体匹配网络通常依赖于基于 3D 卷积的成本体积构建或基于迭代优化的变形方法。前者在成本聚合期间会产生大量的计算开销，而后者通常缺乏对非本地上下文信息进行建模的能力。这些方法在资源受限的移动设备上表现出较差的兼容性，限制了它们在实时应用程序中的部署。为了解决这个问题，我们提出了一种多频自适应融合网络（MAFNet），它可以仅使用高效的 2D 卷积来生成高质量的视差图。具体来说，我们设计了一个自适应频域滤波注意模块，将全部成本量分解为高频和低频量，分别执行频率感知特征聚合。随后，我们引入了一种基于 Linformer 的低秩注意力机制来自适应地融合高频和低频信息，从而产生更鲁棒的视差估计。大量实验表明，所提出的 MAFNet 在 Scene Flow 和 KITTI 2015 等公共数据集上显着优于现有的实时方法，显示出准确性和实时性能之间的良好平衡。
> **Abstract**: Existing stereo matching networks typically rely on either cost-volume construction based on 3D convolutions or deformation methods based on iterative optimization. The former incurs significant computational overhead during cost aggregation, whereas the latter often lacks the ability to model non-local contextual information. These methods exhibit poor compatibility on resource-constrained mobile devices, limiting their deployment in real-time applications. To address this, we propose a Multi-frequency Adaptive Fusion Network (MAFNet), which can produce high-quality disparity maps using only efficient 2D convolutions. Specifically, we design an adaptive frequency-domain filtering attention module that decomposes the full cost volume into high-frequency and low-frequency volumes, performing frequency-aware feature aggregation separately. Subsequently, we introduce a Linformer-based low-rank attention mechanism to adaptively fuse high- and low-frequency information, yielding more robust disparity estimation. Extensive experiments demonstrate that the proposed MAFNet significantly outperforms existing real-time methods on public datasets such as Scene Flow and KITTI 2015, showing a favorable balance between accuracy and real-time performance.

【11】Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment
- **标题**: 通过自我增强对比对齐减轻多模式法学硕士中的物体和动作幻觉
- **链接**: https://arxiv.org/abs/2512.04356
> **作者**: Kai-Po Chang,Wei-Yuan Cheng,Chi-Pin Huang,Fu-En Yang,Yu-Chiang Frank Wang
> **摘要**: 多模态法学硕士 (MLLM) 的最新进展证明了其为输入视频生成描述性字幕的卓越能力。然而，这些模型所生成的描述与事实不准确，导致严重的幻觉问题。虽然之前的工作已经探索减轻静态图像的幻觉，但联合减轻动态视频的视觉对象和时间动作幻觉仍然是一项具有挑战性且尚未解决的任务。为了应对这一挑战，我们提出了一种自我增强对比对齐（SANTA）框架，通过排除虚假相关性并强调视觉事实来实现对象和动作的忠实度。 SANTA 采用幻觉自我增强方案来识别 MLLM 中潜在的幻觉，并将原始标题转换为对比负片。此外，我们开发了一种轨迹短语对比对齐，以将区域对象和关系引导动作与其相应的视觉和时间短语相匹配。大量实验表明，SANTA 在减轻物体和动作幻觉方面优于现有方法，在幻觉检查基准上表现出色。
> **Abstract**: Recent advancement in multimodal LLMs (MLLMs) has demonstrated their remarkable capability to generate descriptive captions for input videos. However, these models suffer from factual inaccuracies in the generated descriptions, causing severe hallucination issues. While prior works have explored alleviating hallucinations for static images, jointly mitigating visual object and temporal action hallucinations for dynamic videos remains a challenging and unsolved task. To tackle this challenge, we propose a Self-Augmented Contrastive Alignment (SANTA) framework for enabling object and action faithfulness by exempting the spurious correlations and enforcing the emphasis on visual facts. SANTA employs a hallucinative self-augmentation scheme to identify the potential hallucinations that lie in the MLLM and transform the original captions to the contrasted negatives. Furthermore, we develop a tracklet-phrase contrastive alignment to match the regional objects and relation-guided actions with their corresponding visual and temporal phrases. Extensive experiments demonstrate that SANTA outperforms existing methods in alleviating object and action hallucinations, yielding superior performance on the hallucination examination benchmarks.

【12】Open Set Face Forgery Detection via Dual-Level Evidence Collection
- **标题**: 通过双层证据收集进行开放集人脸伪造检测
- **链接**: https://arxiv.org/abs/2512.04331
> **作者**: Zhongyi Cai,Bryce Gernon,Wentao Bao,Yifan Li,Matthew Wright,Yu Kong
> **摘要**: 人脸伪造的泛滥日益削弱人们对在线内容真实性的信心。鉴于人脸伪造生成算法的快速发展，新的伪造类别可能会不断出现，对现有的人脸伪造检测方法构成重大挑战。尽管最近在人脸伪造检测方面取得了进展，但现有方法通常仅限于二元真假分类或识别已知的伪造类别，并且无法检测新型伪造的出现。在这项工作中，我们研究了开放集人脸伪造检测（OSFFD）问题，该问题要求检测模型识别新的伪造类别。我们重新表述了 OSFFD 问题，并通过不确定性估计来解决它，增强了其对现实场景的适用性。具体来说，我们提出了双级证据人脸伪造检测（DLED）方法，该方法收集并融合空间和频率水平上的特定类别证据以估计预测不确定性。在不同的实验环境中进行的广泛评估表明，所提出的 DLED 方法实现了最先进的性能，在检测新型赝品类别的赝品方面，比各种基准模型平均高出 20%。此外，在传统的真人脸与假人脸伪造检测任务上，我们的 DLED 方法同时表现出有竞争力的性能。
> **Abstract**: The proliferation of face forgeries has increasingly undermined confidence in the authenticity of online content. Given the rapid development of face forgery generation algorithms, new fake categories are likely to keep appearing, posing a major challenge to existing face forgery detection methods. Despite recent advances in face forgery detection, existing methods are typically limited to binary Real-vs-Fake classification or the identification of known fake categories, and are incapable of detecting the emergence of novel types of forgeries. In this work, we study the Open Set Face Forgery Detection (OSFFD) problem, which demands that the detection model recognize novel fake categories. We reformulate the OSFFD problem and address it through uncertainty estimation, enhancing its applicability to real-world scenarios. Specifically, we propose the Dual-Level Evidential face forgery Detection (DLED) approach, which collects and fuses category-specific evidence on the spatial and frequency levels to estimate prediction uncertainty. Extensive evaluations conducted across diverse experimental settings demonstrate that the proposed DLED method achieves state-of-the-art performance, outperforming various baseline models by an average of 20% in detecting forgeries from novel fake categories. Moreover, on the traditional Real-versus-Fake face forgery detection task, our DLED method concurrently exhibits competitive performance.

【13】A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks
- **标题**: 从神经网络中提取算法逻辑的检索增强生成方法
- **链接**: https://arxiv.org/abs/2512.04329
> **作者**: Waleed Khalid,Dmitry Ignatov,Radu Timofte
> **摘要**: 重用现有的神经网络组件对于研究效率至关重要，但在数千个开源存储库中发现、提取和验证此类模块仍然很困难。我们引入了 NN-RAG，这是一种检索增强生成系统，可将大型异构 PyTorch 代码库转换为经过验证的神经模块的可搜索且可执行的库。与传统的代码搜索或克隆检测工具不同，NN-RAG 执行作用域感知的依赖解析、导入保留重建和验证器门控提升——确保每个检索到的块都是作用域封闭的、可编译的和可运行的。该管道应用于 19 个主要存储库，提取了 1,289 个候选块，验证了 941 个（73.0%），并证明超过 80% 在结构上是唯一的。通过多级重复数据删除（精确、词汇、结构），我们发现 NN-RAG 为 LEMUR 数据集贡献了绝大多数独特的架构，提供了所有新颖网络结构的大约 72%。除了数量之外，NN-RAG 还独特地支持架构模式的跨存储库迁移，自动识别一个项目中的可重用模块，并在另一个上下文中重新生成它们，完整的依赖关系。据我们所知，没有其他开源系统能够大规模提供这种功能。该框架的中立规范还允许与语言模型进行可选集成，以进行综合或数据集注册，而无需重新分发第三方代码。总体而言，NN-RAG 将碎片化的视觉代码转换为可重复的、可追踪来源的算法发现基底，提供了第一个开源解决方案，可以量化并扩展跨存储库的可执行神经架构的多样性。
> **Abstract**: Reusing existing neural-network components is central to research efficiency, yet discovering, extracting, and validating such modules across thousands of open-source repositories remains difficult. We introduce NN-RAG, a retrieval-augmented generation system that converts large, heterogeneous PyTorch codebases into a searchable and executable library of validated neural modules. Unlike conventional code search or clone-detection tools, NN-RAG performs scope-aware dependency resolution, import-preserving reconstruction, and validator-gated promotion -- ensuring that every retrieved block is scope-closed, compilable, and runnable. Applied to 19 major repositories, the pipeline extracted 1,289 candidate blocks, validated 941 (73.0%), and demonstrated that over 80% are structurally unique. Through multi-level de-duplication (exact, lexical, structural), we find that NN-RAG contributes the overwhelming majority of unique architectures to the LEMUR dataset, supplying approximately 72% of all novel network structures. Beyond quantity, NN-RAG uniquely enables cross-repository migration of architectural patterns, automatically identifying reusable modules in one project and regenerating them, dependency-complete, in another context. To our knowledge, no other open-source system provides this capability at scale. The framework's neutral specifications further allow optional integration with language models for synthesis or dataset registration without redistributing third-party code. Overall, NN-RAG transforms fragmented vision code into a reproducible, provenance-tracked substrate for algorithmic discovery, offering a first open-source solution that both quantifies and expands the diversity of executable neural architectures across repositories.

【14】Bayes-DIC Net: Estimating Digital Image Correlation Uncertainty with Bayesian Neural Networks
- **标题**: Bayes-DIC Net：使用贝叶斯神经网络估计数字图像相关不确定性
- **链接**: https://arxiv.org/abs/2512.04323
> **作者**: Biao Chen,Zhenhua Lei,Yahui Zhang,Tongzhi Niu
> **摘要**: 本文介绍了一种基于非均匀 B 样条曲面生成高质量数字图像相关（DIC）数据集的新方法。通过随机生成控制点坐标，我们构建了包含各种现实位移场景的位移场，随后用于生成散斑图案数据集。这种方法能够生成捕获真实世界位移场情况的大规模数据集，从而增强基于深度学习的 DIC 算法的训练和泛化能力。此外，我们提出了一种新颖的网络架构，称为 Bayes-DIC Net，它在下采样阶段提取多个级别的信息，并在上采样阶段通过单个跳跃连接促进跨各个级别的信息聚合。 Bayes-DIC Net 包含一系列轻量级卷积块，旨在扩展感受野并捕获丰富的上下文信息，同时最大限度地降低计算成本。此外，通过将适当的dropout模块集成到Bayes-DIC Net中并在网络推理阶段激活它们，Bayes-DIC Net转变为贝叶斯神经网络。这种转换允许网络在处理真实的未标记数据集时不仅提供预测结果，还提供这些预测的置信度。这一功能显着增强了我们的网络在现实世界位移场预测任务中的实用性和可靠性。通过这些创新，本文为DIC领域的数据集生成和算法性能增强提供了新的视角和方法。
> **Abstract**: This paper introduces a novel method for generating high-quality Digital Image Correlation (DIC) dataset based on non-uniform B-spline surfaces. By randomly generating control point coordinates, we construct displacement fields that encompass a variety of realistic displacement scenarios, which are subsequently used to generate speckle pattern datasets. This approach enables the generation of a large-scale dataset that capture real-world displacement field situations, thereby enhancing the training and generalization capabilities of deep learning-based DIC algorithms. Additionally, we propose a novel network architecture, termed Bayes-DIC Net, which extracts information at multiple levels during the down-sampling phase and facilitates the aggregation of information across various levels through a single skip connection during the up-sampling phase. Bayes-DIC Net incorporates a series of lightweight convolutional blocks designed to expand the receptive field and capture rich contextual information while minimizing computational costs. Furthermore, by integrating appropriate dropout modules into Bayes-DIC Net and activating them during the network inference stage, Bayes-DIC Net is transformed into a Bayesian neural network. This transformation allows the network to provide not only predictive results but also confidence levels in these predictions when processing real unlabeled datasets. This feature significantly enhances the practicality and reliability of our network in real-world displacement field prediction tasks. Through these innovations, this paper offers new perspectives and methods for dataset generation and algorithm performance enhancement in the field of DIC.

【15】SyncTrack4D: Cross-Video Motion Alignment and Video Synchronization for Multi-Video 4D Gaussian Splatting
- **标题**: SyncTrack4D：多视频 4D 高斯泼溅的跨视频运动对齐和视频同步
- **链接**: https://arxiv.org/abs/2512.04315
> **作者**: Yonghan Lee,Tsung-Wei Huang,Shiv Gehlot,Jaehoon Choi,Guan-Ming Su,Dinesh Manocha
> **摘要**: 由于动态 3D 场景的高维性质，对动态 3D 场景进行建模具有挑战性，这需要聚合来自多个视图的信息来重建随时间演变的 3D 几何和运动。我们提出了一种新颖的多视频 4D 高斯泼溅 (4DGS) 方法，旨在处理现实世界中不同步的视频集。我们的方法 SyncTrack4D 直接利用动态场景部分的密集 4D 轨道表示作为同步跨视频同步和 4DGS 重建的线索。我们首先通过 Fused Gromov-Wasserstein 最佳传输方法计算密集的每个视频 4D 特征轨道和跨视频轨道对应关系。接下来，我们执行全局帧级时间对齐，以最大化匹配 4D 轨道的重叠运动。最后，我们通过基于运动样条支架表示的多视频 4D 高斯泼溅实现子帧同步。最终输出是同步 4DGS 表示，其中包含每个视频的密集、明确的 3D 轨迹和时间偏移。我们在 Panoptic Studio 和 SyncNeRF Blender 上评估了我们的方法，展示了子帧同步精度，平均时间误差低于 0.26 帧，高保真 4D 重建在 Panoptic Studio 数据集上达到 26.3 PSNR 分数。据我们所知，我们的工作是第一个用于非同步视频集的通用 4D 高斯泼溅方法，无需假设预定义场景对象或先前模型的存在。
> **Abstract**: Modeling dynamic 3D scenes is challenging due to their high-dimensional nature, which requires aggregating information from multiple views to reconstruct time-evolving 3D geometry and motion. We present a novel multi-video 4D Gaussian Splatting (4DGS) approach designed to handle real-world, unsynchronized video sets. Our approach, SyncTrack4D, directly leverages dense 4D track representation of dynamic scene parts as cues for simultaneous cross-video synchronization and 4DGS reconstruction. We first compute dense per-video 4D feature tracks and cross-video track correspondences by Fused Gromov-Wasserstein optimal transport approach. Next, we perform global frame-level temporal alignment to maximize overlapping motion of matched 4D tracks. Finally, we achieve sub-frame synchronization through our multi-video 4D Gaussian splatting built upon a motion-spline scaffold representation. The final output is a synchronized 4DGS representation with dense, explicit 3D trajectories, and temporal offsets for each video. We evaluate our approach on the Panoptic Studio and SyncNeRF Blender, demonstrating sub-frame synchronization accuracy with an average temporal error below 0.26 frames, and high-fidelity 4D reconstruction reaching 26.3 PSNR scores on the Panoptic Studio dataset. To the best of our knowledge, our work is the first general 4D Gaussian Splatting approach for unsynchronized video sets, without assuming the existence of predefined scene objects or prior models.

【16】DisentangleFormer: Spatial-Channel Decoupling for Multi-Channel Vision
- **标题**: DisentangleFormer：多通道视觉的空间通道解耦
- **链接**: https://arxiv.org/abs/2512.04314
> **作者**: Jiashu Liao,Pietro Liò,Marc de Kamps,Duygu Sarikaya
> **摘要**: 视觉 Transformers 面临一个根本性的限制：标准的自注意力联合处理空间和通道维度，导致纠缠表示，阻碍结构和语义依赖的独立建模。这个问题在高光谱成像中尤其明显，从卫星高光谱遥感到红外病理成像，其中通道捕获不同的生物物理或生化线索。我们提出了 DisentangleFormer，这是一种通过有原则的空间通道解耦实现稳健的多通道视觉表示的架构。受去相关表示学习的信息论原理的启发，我们的并行设计能够对结构和语义线索进行独立建模，同时最大限度地减少空间和通道流之间的冗余。我们的设计集成了三个核心组件：（1）并行解缠：独立处理空间令牌和通道令牌流，实现跨空间和光谱维度的去相关特征学习，（2）压缩令牌增强器：动态融合空间和通道流的自适应校准模块，（3）多尺度FFN：用多尺度局部上下文补充全局注意力，以捕获细粒度的结构和语义依赖性。对高光谱基准的大量实验表明，DisentangleFormer 实现了最先进的性能，始终优于 Indian Pine、Pavia University 和 Houston、大型 BigEarthNet 遥感数据集以及红外病理学数据集上的现有模型。此外，它在 ImageNet 上保持了有竞争力的准确性，同时将 FLOP 的计算成本降低了 17.8%。该代码将在接受后公开发布。
> **Abstract**: Vision Transformers face a fundamental limitation: standard self-attention jointly processes spatial and channel dimensions, leading to entangled representations that prevent independent modeling of structural and semantic dependencies. This problem is especially pronounced in hyperspectral imaging, from satellite hyperspectral remote sensing to infrared pathology imaging, where channels capture distinct biophysical or biochemical cues. We propose DisentangleFormer, an architecture that achieves robust multi-channel vision representation through principled spatial-channel decoupling. Motivated by information-theoretic principles of decorrelated representation learning, our parallel design enables independent modeling of structural and semantic cues while minimizing redundancy between spatial and channel streams. Our design integrates three core components: (1) Parallel Disentanglement: Independently processes spatial-token and channel-token streams, enabling decorrelated feature learning across spatial and spectral dimensions, (2) Squeezed Token Enhancer: An adaptive calibration module that dynamically fuses spatial and channel streams, and (3) Multi-Scale FFN: complementing global attention with multi-scale local context to capture fine-grained structural and semantic dependencies. Extensive experiments on hyperspectral benchmarks demonstrate that DisentangleFormer achieves state-of-the-art performance, consistently outperforming existing models on Indian Pine, Pavia University, and Houston, the large-scale BigEarthNet remote sensing dataset, as well as an infrared pathology dataset. Moreover, it retains competitive accuracy on ImageNet while reducing computational cost by 17.8% in FLOPs. The code will be made publicly available upon acceptance.

【17】Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding
- **标题**: Mind-to-Face：通过脑电图解码进行神经驱动的逼真头像合成
- **链接**: https://arxiv.org/abs/2512.04313
> **作者**: Haolin Xiong,Tianwen Fu,Pratusha Bhuvana Prasad,Yunxuan Cai,Haiwei Chen,Wenbin Teng,Hanyuan Xiao,Yajie Zhao
> **摘要**: 当前的表达化身系统严重依赖视觉线索，当面部被遮挡或情绪仍处于内在状态时就会失败。我们推出 Mind-to-Face，这是第一个将非侵入性脑电图 (EEG) 信号直接解码为高保真面部表情的框架。我们构建了双模态记录设置，以在情绪引发刺激期间获得同步脑电图和多视图面部视频，从而实现神经到视觉学习的精确监督。我们的模型使用 CNN-Transformer 编码器将 EEG 信号映射到密集的 3D 位置图，能够对超过 65k 个顶点进行采样，捕捉精细尺度的几何形状和微妙的情绪动态，并通过修改后的 3D 高斯泼溅管道进行渲染，以获得逼真、视图一致的结果。通过广泛的评估，我们表明仅脑电图就可以可靠地预测动态的、特定于主题的面部表情，包括微妙的情绪反应，这表明神经信号包含比之前假设的更丰富的情感和几何信息。 Mind-to-Face 为神经驱动的化身建立了一个新的范式，在沉浸式环境中实现个性化、情感感知的远程呈现和认知交互。
> **Abstract**: Current expressive avatar systems rely heavily on visual cues, failing when faces are occluded or when emotions remain internal. We present Mind-to-Face, the first framework that decodes non-invasive electroencephalogram (EEG) signals directly into high-fidelity facial expressions. We build a dual-modality recording setup to obtain synchronized EEG and multi-view facial video during emotion-eliciting stimuli, enabling precise supervision for neural-to-visual learning. Our model uses a CNN-Transformer encoder to map EEG signals into dense 3D position maps, capable of sampling over 65k vertices, capturing fine-scale geometry and subtle emotional dynamics, and renders them through a modified 3D Gaussian Splatting pipeline for photorealistic, view-consistent results. Through extensive evaluation, we show that EEG alone can reliably predict dynamic, subject-specific facial expressions, including subtle emotional responses, demonstrating that neural signals contain far richer affective and geometric information than previously assumed. Mind-to-Face establishes a new paradigm for neural-driven avatars, enabling personalized, emotion-aware telepresence and cognitive interaction in immersive environments.

【18】Real-time Cricket Sorting By Sex
- **标题**: 按性别实时板球排序
- **链接**: https://arxiv.org/abs/2512.04311
> **作者**: Juan Manuel Cantarero Angulo,Matthew Smith
> **摘要**: 全球对可持续蛋白质来源的需求正在推动人们对食用昆虫的兴趣日益浓厚，家蟋蟀（家蟋蟀）被认为是最适合工业生产的物种之一。当前的农业实践通常在混合性别种群中饲养蟋蟀，尽管有选择性育种、优化繁殖率和营养差异等潜在好处，但没有自动性别分选。这项工作提出了一种低成本、实时的系统，用于结合计算机视觉和物理驱动，对家蓼进行基于性别的自动分类。该设备将 Raspberry Pi 5 与官方 Raspberry AI 相机和定制的 YOLOv8 纳米物体检测模型以及伺服驱动的分拣臂集成在一起。该模型在测试过程中 IoU 0.5 (mAP@0.5) 的平均精度达到 0.977，而对蟋蟀群体进行的真实实验则实现了 86.8% 的总体分类精度。这些结果证明了在昆虫养殖应用的资源受限设备上部署轻量级深度学习模型的可行性，为提高蟋蟀生产的效率和可持续性提供了实用的解决方案。
> **Abstract**: The global demand for sustainable protein sources is driving increasing interest in edible insects, with Acheta domesticus (house cricket) identified as one of the most suitable species for industrial production. Current farming practices typically rear crickets in mixed-sex populations without automated sex sorting, despite potential benefits such as selective breeding, optimized reproduction ratios, and nutritional differentiation. This work presents a low-cost, real-time system for automated sex-based sorting of Acheta domesticus, combining computer vision and physical actuation. The device integrates a Raspberry Pi 5 with the official Raspberry AI Camera and a custom YOLOv8 nano object detection model, together with a servo-actuated sorting arm. The model reached a mean Average Precision at IoU 0.5 (mAP@0.5) of 0.977 during testing, and real-world experiments with groups of crickets achieved an overall sorting accuracy of 86.8%. These results demonstrate the feasibility of deploying lightweight deep learning models on resource-constrained devices for insect farming applications, offering a practical solution to improve efficiency and sustainability in cricket production.

【19】Text-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction
- **标题**: 通过检索增强和模态间隙校正进行图像描述的纯文本训练
- **链接**: https://arxiv.org/abs/2512.04309
> **作者**: Rui Fonseca,Bruno Martins,Gil Rocha
> **摘要**: 图像字幕引起了自然语言处理和计算机视觉领域的广泛关注。为了减少对精选数据的依赖，一些研究探索了无需任何人工注释的图像文本对进行训练的图像字幕，尽管现有方法仍然优于完全监督的方法。本文提出了 TOMCap，即一种改进的纯文本训练方法，无需对齐图像标题对即可执行字幕。该方法基于在经历减少模态差距的过程之后，使用从 CLIP 表示导出的信息来提示预先训练的语言模型解码器。我们专门测试了检索到的字幕示例和潜在向量表示的组合使用，以指导生成过程。通过大量的实验，我们证明 TOMCap 优于其他免训练和纯文本方法。我们还分析了有关检索增强和模态差距缩小组件配置的不同选择的影响。
> **Abstract**: Image captioning has drawn considerable attention from the natural language processing and computer vision fields. Aiming to reduce the reliance on curated data, several studies have explored image captioning without any humanly-annotated image-text pairs for training, although existing methods are still outperformed by fully supervised approaches. This paper proposes TOMCap, i.e., an improved text-only training method that performs captioning without the need for aligned image-caption pairs. The method is based on prompting a pre-trained language model decoder with information derived from a CLIP representation, after undergoing a process to reduce the modality gap. We specifically tested the combined use of retrieved examples of captions, and latent vector representations, to guide the generation process. Through extensive experiments, we show that TOMCap outperforms other training-free and text-only methods. We also analyze the impact of different choices regarding the configuration of the retrieval-augmentation and modality gap reduction components.

【20】How (Mis)calibrated is Your Federated CLIP and What To Do About It?
- **标题**: 您的 Federated CLIP 校准情况如何（错误）以及如何处理？
- **链接**: https://arxiv.org/abs/2512.04305
> **作者**: Mainak Singha,Masih Aminbeidokhti,Paolo Casari,Elisa Ricci,Subhankar Roy
> **摘要**: 虽然像 CLIP 这样的视觉语言模型已经得到了广泛的研究，但它们对于可靠预测至关重要的校准却受到了有限的关注。尽管之前的一些工作已经在离线设置中检查了 CLIP 校准，但在联邦学习 (FL) 设置中微调 CLIP 的影响仍未得到探索。在这项工作中，我们研究了 FL 如何影响 CLIP 校准，并提出了提高这种分布式环境中可靠性的策略。我们首先分析文本提示调整方法，并表明它们在 FL 下运行时会降低校准指标。我们还评估了四种全局聚合方法中现有的训练校准技术，发现它们提供的改进有限。我们的结果表明，关键的挑战不仅在于我们如何聚合或校准，还在于我们选择微调哪些组件。受这一见解的启发，我们提出了 $\text{FL}^2\text{oRA}$，这是一种基于 LoRA 的简单方法，可以自然地改进 FL 的校准，并且我们分析了其有效性背后的因素。多个基准测试的实验表明，$\text{FL}^2\text{oRA}$ 始终能够生成经过良好校准的模型，从而减少了对显式校准程序的需求。代码可在 https://github.com/mainaksingha01/FL2oRA 获取。
> **Abstract**: While vision-language models like CLIP have been extensively studied, their calibration, crucial for reliable predictions, has received limited attention. Although a few prior works have examined CLIP calibration in offline settings, the impact of fine-tuning CLIP in a federated learning (FL) setup remains unexplored. In this work, we investigate how FL affects CLIP calibration and propose strategies to improve reliability in this distributed setting. We first analyze Textual Prompt Tuning approaches and show that they degrade calibration metrics when operating under FL. We also evaluate existing in-training calibration techniques across four global aggregation methods, finding that they provide limited improvements. Our results suggest that the key challenge lies not only in how we aggregate or calibrate, but in which components we choose to fine-tune. Motivated by this insight, we propose $\text{FL}^2\text{oRA}$, a straightforward LoRA-based approach that naturally improves calibration in FL, and we analyze the factors behind its effectiveness. Experiments on multiple benchmarks demonstrate that $\text{FL}^2\text{oRA}$ consistently produces well-calibrated models, reducing the need for explicit calibration procedures. Codes are available at https://github.com/mainaksingha01/FL2oRA.

【21】Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications
- **标题**: Gamma-from-Mono：用于车辆应用的道路相关、公制、自监督单目几何结构
- **链接**: https://arxiv.org/abs/2512.04303
> **作者**: Gasser Elazab,Maximilian Jansen,Michael Unterreiner,Olaf Hellwich
> **摘要**: 准确感知车辆的 3D 环境，包括精细的道路几何形状，例如颠簸、斜坡和表面不平整，对于安全舒适的车辆控制至关重要。然而，传统的单目深度估计通常会过度平滑这些特征，从而丢失运动规划和稳定性的关键信息。为了解决这个问题，我们引入了 Gamma-from-Mono (GfM)，这是一种轻量级的单目几何估计方法，通过解耦全局和局部结构来解决单相机重建中的投影模糊性。 GfM 预测主要路面平面以及由 gamma 表示的残余变化，gamma 是与平面的垂直偏差的无量纲度量，定义为该点上方的高度与其距相机的深度的比率，并以已建立的平面视差几何为基础。只需相机距地面的高度，这种表示就可以通过封闭形式确定性地恢复公制深度，避免完全的外部校准并自然优先考虑近路细节。其物理上可解释的公式使其非常适合自我监督学习，消除了对大型注释数据集的需求。经过 KITTI 和路面重建数据集 (RSRD) 的评估，GfM 在深度和伽马估计方面实现了最先进的近场精度，同时保持了具有竞争力的全局深度性能。我们的轻量级 888 万参数模型可以稳健地适应不同的相机设置，据我们所知，这是第一个在 RSRD 上评估的自监督单目方法。
> **Abstract**: Accurate perception of the vehicle's 3D surroundings, including fine-scale road geometry, such as bumps, slopes, and surface irregularities, is essential for safe and comfortable vehicle control. However, conventional monocular depth estimation often oversmooths these features, losing critical information for motion planning and stability. To address this, we introduce Gamma-from-Mono (GfM), a lightweight monocular geometry estimation method that resolves the projective ambiguity in single-camera reconstruction by decoupling global and local structure. GfM predicts a dominant road surface plane together with residual variations expressed by gamma, a dimensionless measure of vertical deviation from the plane, defined as the ratio of a point's height above it to its depth from the camera, and grounded in established planar parallax geometry. With only the camera's height above ground, this representation deterministically recovers metric depth via a closed form, avoiding full extrinsic calibration and naturally prioritizing near-road detail. Its physically interpretable formulation makes it well suited for self-supervised learning, eliminating the need for large annotated datasets. Evaluated on KITTI and the Road Surface Reconstruction Dataset (RSRD), GfM achieves state-of-the-art near-field accuracy in both depth and gamma estimation while maintaining competitive global depth performance. Our lightweight 8.88M-parameter model adapts robustly across diverse camera setups and, to our knowledge, is the first self-supervised monocular approach evaluated on RSRD.

【22】Learning Single-Image Super-Resolution in the JPEG Compressed Domain
- **标题**: 学习 JPEG 压缩域中的单图像超分辨率
- **链接**: https://arxiv.org/abs/2512.04284
> **作者**: Sruthi Srinivasan,Elham Shakibapour,Rajy Rawther,Mehdi Saeedi
> **摘要**: 深度学习模型变得越来越复杂，输入数据大小也相应扩大。尽管专业深度学习硬件取得了巨大进步，但数据加载仍然是限制训练和推理速度的主要瓶颈。为了应对这一挑战，我们提出直接在编码的 JPEG 特征上训练模型，减少与完整 JPEG 解码相关的计算开销，并显着提高数据加载效率。虽然之前的工作主要集中在识别任务上，但我们研究了这种方法对于单图像超分辨率（SISR）恢复任务的有效性。我们提出了一种轻量级超分辨率管道，可在频域中对 JPEG 离散余弦变换 (DCT) 系数进行操作。我们的流程在数据加载方面实现了 2.6 倍的加速，在训练方面实现了 2.5 倍的加速，同时保持了与标准 SISR 方法相当的视觉质量。
> **Abstract**: Deep learning models have grown increasingly complex, with input data sizes scaling accordingly. Despite substantial advances in specialized deep learning hardware, data loading continues to be a major bottleneck that limits training and inference speed. To address this challenge, we propose training models directly on encoded JPEG features, reducing the computational overhead associated with full JPEG decoding and significantly improving data loading efficiency. While prior works have focused on recognition tasks, we investigate the effectiveness of this approach for the restoration task of single-image super-resolution (SISR). We present a lightweight super-resolution pipeline that operates on JPEG discrete cosine transform (DCT) coefficients in the frequency domain. Our pipeline achieves a 2.6x speedup in data loading and a 2.5x speedup in training, while preserving visual quality comparable to standard SISR approaches.

【23】Plug-and-Play Image Restoration with Flow Matching: A Continuous Viewpoint
- **标题**: 通过流匹配进行即插即用图像恢复：连续视角
- **链接**: https://arxiv.org/abs/2512.04283
> **作者**: Fan Jia,Yuhao Huang,Shih-Hsin Wang,Cristina Garcia-Cardona,Andrea L. Bertozzi,Bao Wang
> **摘要**: 基于流匹配的生成模型已集成到即插即用图像恢复框架中，由此产生的即插即用流匹配（PnP-Flow）模型在图像恢复方面取得了一些显着的经验成功。然而，对 PnP-Flow 的理论理解滞后于其实证成功。在本文中，我们推导了 PnP-Flow 的连续极限，从而产生了 PnP-Flow 的随机微分方程（SDE）代理模型。 SDE 模型为改进图像恢复的 PnP-Flow 提供了两个特别的见解：（1）它使我们能够量化图像恢复的误差，通知我们改进步骤调度并正则化神经网络参数化向量场的 Lipschitz 常数以减少误差。 (2) 它告诉我们通过外推法加速现成的 PnP-Flow 模型，从而产生所提出的 SDE 模型的重新缩放版本。我们使用多个基准任务验证了基于 SDE 的改进 PnP-Flow 的功效，包括图像去噪、去模糊、超分辨率和修复。数值结果表明，我们的方法显着优于基线 PnP-Flow 和其他最先进的方法，在各个评估指标上实现了卓越的性能。
> **Abstract**: Flow matching-based generative models have been integrated into the plug-and-play image restoration framework, and the resulting plug-and-play flow matching (PnP-Flow) model has achieved some remarkable empirical success for image restoration. However, the theoretical understanding of PnP-Flow lags its empirical success. In this paper, we derive a continuous limit for PnP-Flow, resulting in a stochastic differential equation (SDE) surrogate model of PnP-Flow. The SDE model provides two particular insights to improve PnP-Flow for image restoration: (1) It enables us to quantify the error for image restoration, informing us to improve step scheduling and regularize the Lipschitz constant of the neural network-parameterized vector field for error reduction. (2) It informs us to accelerate off-the-shelf PnP-Flow models via extrapolation, resulting in a rescaled version of the proposed SDE model. We validate the efficacy of the SDE-informed improved PnP-Flow using several benchmark tasks, including image denoising, deblurring, super-resolution, and inpainting. Numerical results show that our method significantly outperforms the baseline PnP-Flow and other state-of-the-art approaches, achieving superior performance across evaluation metrics.

【24】Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer
- **标题**: 用于实时视频运动传输的 GRU 归一化流的推理时间随机细化
- **链接**: https://arxiv.org/abs/2512.04282
> **作者**: Tasmiah Haque,Srinjoy Das
> **摘要**: 实时视频运动传输应用（例如沉浸式游戏和基于视觉的异常检测）需要准确而多样化的未来预测，以支持不确定性下的真实合成和稳健的下游决策。为了提高此类顺序预测的多样性，我们提出了一种新颖的推理时间细化技术，该技术将门控循环单元归一化流（GRU-NF）与随机采样方法相结合。虽然 GRU-NF 可以通过在时间预测框架内集成标准化流来捕获多模态分布，但其确定性变换结构可能会限制表达能力。为了解决这个问题，受随机归一化流（SNF）的启发，我们在 GRU-NF 推理过程中引入了马尔可夫链蒙特卡罗（MCMC）步骤，使模型能够探索更丰富的输出空间并更好地逼近真实数据分布，而无需重新训练。我们在基于关键点的视频运动传输管道中验证了我们的方法，其中捕获时间连贯和感知多样化的未来轨迹对于真实样本和低带宽通信至关重要。实验表明，我们的推理框架门控循环单元随机归一化流 (GRU-SNF) 在生成多样化输出方面优于 GRU-NF，且不牺牲准确性，即使在较长的预测范围内也是如此。通过在推理过程中注入随机性，我们的方法可以更有效地捕获多模态行为。这些结果凸显了将随机动力学与基于流的序列模型相结合进行生成时间序列预测的潜力。
> **Abstract**: Real-time video motion transfer applications such as immersive gaming and vision-based anomaly detection require accurate yet diverse future predictions to support realistic synthesis and robust downstream decision making under uncertainty. To improve the diversity of such sequential forecasts we propose a novel inference-time refinement technique that combines Gated Recurrent Unit-Normalizing Flows (GRU-NF) with stochastic sampling methods. While GRU-NF can capture multimodal distributions through its integration of normalizing flows within a temporal forecasting framework, its deterministic transformation structure can limit expressivity. To address this, inspired by Stochastic Normalizing Flows (SNF), we introduce Markov Chain Monte Carlo (MCMC) steps during GRU-NF inference, enabling the model to explore a richer output space and better approximate the true data distribution without retraining. We validate our approach in a keypoint-based video motion transfer pipeline, where capturing temporally coherent and perceptually diverse future trajectories is essential for realistic samples and low bandwidth communication. Experiments show that our inference framework, Gated Recurrent Unit- Stochastic Normalizing Flows (GRU-SNF) outperforms GRU-NF in generating diverse outputs without sacrificing accuracy, even under longer prediction horizons. By injecting stochasticity during inference, our approach captures multimodal behavior more effectively. These results highlight the potential of integrating stochastic dynamics with flow-based sequence models for generative time series forecasting.

【25】UniLight: A Unified Representation for Lighting
- **标题**: UniLight：照明的统一表示
- **链接**: https://arxiv.org/abs/2512.04267
> **作者**: Zitian Zhang,Iliyan Georgiev,Michael Fischer,Yannick Hold-Geoffroy,Jean-François Lalonde,Valentin Deschaintre
> **摘要**: 照明对视觉外观有很大影响，但理解和表示图像中的照明仍然非常困难。存在各种照明表示，例如环境图、辐照度、球谐函数或文本，但它们不兼容，这限制了跨模式传输。因此，我们提出了 UniLight，一种作为照明表示的联合潜在空间，它将多种模式统一在共享嵌入中。用于文本、图像、辐照度和环境图的模态特定编码器经过对比训练以对齐其表示，并通过辅助球谐预测任务增强方向理解。我们的多模态数据管道支持跨三个任务的大规模训练和评估：基于照明的检索、环境地图生成以及基于扩散的图像合成中的照明控制。实验表明，我们的表示捕获了一致且可转移的照明特征，从而实现了跨模式的灵活操作。
> **Abstract**: Lighting has a strong influence on visual appearance, yet understanding and representing lighting in images remains notoriously difficult. Various lighting representations exist, such as environment maps, irradiance, spherical harmonics, or text, but they are incompatible, which limits cross-modal transfer. We thus propose UniLight, a joint latent space as lighting representation, that unifies multiple modalities within a shared embedding. Modality-specific encoders for text, images, irradiance, and environment maps are trained contrastively to align their representations, with an auxiliary spherical-harmonics prediction task reinforcing directional understanding. Our multi-modal data pipeline enables large-scale training and evaluation across three tasks: lighting-based retrieval, environment-map generation, and lighting control in diffusion-based image synthesis. Experiments show that our representation captures consistent and transferable lighting features, enabling flexible manipulation across modalities.

【26】MVRoom: Controllable 3D Indoor Scene Generation with Multi-View Diffusion Models
- **标题**: MVRoom：利用多视图扩散模型生成可控 3D 室内场景
- **链接**: https://arxiv.org/abs/2512.04248
> **作者**: Shaoheng Fang,Chaohui Yu,Fan Wang,Qixing Huang
> **摘要**: 我们介绍了 MVRoom，这是一种用于 3D 室内场景的可控新型视图合成 (NVS) 管道，它使用以粗略 3D 布局为条件的多视图扩散。 MVRoom 采用两阶段设计，始终使用 3D 布局来增强多视图一致性。第一阶段采用新颖的表示方法，有效地连接 3D 布局和一致的基于图像的条件信号，以实现多视图生成。第二阶段执行图像条件多视图生成，结合布局感知极线注意机制以增强扩散过程中的多视图一致性。此外，我们引入了一个迭代框架，通过递归执行多视图生成（MVRoom）来生成具有不同数量的对象和场景复杂性的 3D 场景，支持文本到场景的生成。实验结果表明，我们的方法实现了 NVS 的高保真度和可控 3D 场景生成，在数量和质量上都优于最先进的基线方法。消融研究进一步验证了我们发电管道中关键组件的有效性。
> **Abstract**: We introduce MVRoom, a controllable novel view synthesis (NVS) pipeline for 3D indoor scenes that uses multi-view diffusion conditioned on a coarse 3D layout. MVRoom employs a two-stage design in which the 3D layout is used throughout to enforce multi-view consistency. The first stage employs novel representations to effectively bridge the 3D layout and consistent image-based condition signals for multi-view generation. The second stage performs image-conditioned multi-view generation, incorporating a layout-aware epipolar attention mechanism to enhance multi-view consistency during the diffusion process. Additionally, we introduce an iterative framework that generates 3D scenes with varying numbers of objects and scene complexities by recursively performing multi-view generation (MVRoom), supporting text-to-scene generation. Experimental results demonstrate that our approach achieves high-fidelity and controllable 3D scene generation for NVS, outperforming state-of-the-art baseline methods both quantitatively and qualitatively. Ablation studies further validate the effectiveness of key components within our generation pipeline.

【27】6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models
- **标题**: 6 个手指，1 个肾脏：自然对抗性医学图像揭示了视觉语言模型的关键弱点
- **链接**: https://arxiv.org/abs/2512.04238
> **作者**: Leon Mayer,Piotr Kalinowski,Caroline Ebersbach,Marcel Knopp,Tim Rädsch,Evangelia Christodoulou,Annika Reinke,Fiona R. Kolbinger,Lena Maier-Hein
> **摘要**: 视觉语言模型越来越多地集成到临床工作流程中。然而，现有的基准主要评估常见解剖表现的性能，未能捕捉罕见变异带来的挑战。为了解决这一差距，我们引入了 AdversarialAnatomyBench，这是第一个基准，包含跨不同成像模式和解剖区域自然发生的罕见解剖变异。我们将这种违反“典型”人体解剖学先验知识的变体称为自然对抗性解剖学。使用 AdversarialAnatomyBench 对 22 个最先进的 VLM 进行基准测试，得出了三个关键见解。首先，当询问基本的医学感知任务时，平均准确度从典型解剖的 74% 下降到非典型解剖的 29%。即使是性能最好的型号 GPT-5、Gemini 2.5 Pro 和 Llama 4 Maverick，性能也下降了 41-51%。其次，模型错误密切反映了预期的解剖偏差。第三，模型缩放和干预措施（包括偏见感知提示和测试时推理）都无法解决这些问题。这些发现凸显了当前 VLM 的一个关键且先前未量化的局限性：它们对罕见解剖学表现的泛化能力较差。 AdversarialAnatomyBench 为系统测量和减轻多模式医疗 AI 系统中的解剖偏差奠定了基础。
> **Abstract**: Vision-language models are increasingly integrated into clinical workflows. However, existing benchmarks primarily assess performance on common anatomical presentations and fail to capture the challenges posed by rare variants. To address this gap, we introduce AdversarialAnatomyBench, the first benchmark comprising naturally occurring rare anatomical variants across diverse imaging modalities and anatomical regions. We call such variants that violate learned priors about "typical" human anatomy natural adversarial anatomy. Benchmarking 22 state-of-the-art VLMs with AdversarialAnatomyBench yielded three key insights. First, when queried with basic medical perception tasks, mean accuracy dropped from 74% on typical to 29% on atypical anatomy. Even the best-performing models, GPT-5, Gemini 2.5 Pro, and Llama 4 Maverick, showed performance drops of 41-51%. Second, model errors closely mirrored expected anatomical biases. Third, neither model scaling nor interventions, including bias-aware prompting and test-time reasoning, resolved these issues. These findings highlight a critical and previously unquantified limitation in current VLM: their poor generalization to rare anatomical presentations. AdversarialAnatomyBench provides a foundation for systematically measuring and mitigating anatomical bias in multimodal medical AI systems.

【28】ReasonX: MLLM-Guided Intrinsic Image Decomposition
- **标题**: ReasonX：MLLM 引导的本征图像分解
- **链接**: https://arxiv.org/abs/2512.04222
> **作者**: Alara Dirik,Tuanfeng Wang,Duygu Ceylan,Stefanos Zafeiriou,Anna Frühstück
> **摘要**: 本质图像分解旨在将图像分离为物理成分，例如反照率、深度、法线和照明。虽然最近基于扩散和变压器的模型受益于合成数据集的配对监督，但它们对不同的现实世界场景的泛化仍然具有挑战性。我们提出了 ReasonX，这是一种新颖的框架，它利用多模态大语言模型（MLLM）作为感知判断，提供相对的内在比较，并使用这些比较作为 GRPO 奖励，用于在未标记的野外图像上微调内在分解模型。与生成模型的强化学习方法不同，我们的框架通过奖励法官的关系评估与从模型输出中分析得出的关系之间的一致性来调整条件内在预测变量。 ReasonX 与模型无关，可以应用于不同的内在预测变量。在多种基础架构和模式中，ReasonX 取得了重大改进，包括 IIW 反照率的 WHDR 降低了 9-25%，以及 ETH3D 的深度精度提高了 46%，凸显了 MLLM 引导的比较监督在连接低级和高级视觉推理方面的前景。
> **Abstract**: Intrinsic image decomposition aims to separate images into physical components such as albedo, depth, normals, and illumination. While recent diffusion- and transformer-based models benefit from paired supervision from synthetic datasets, their generalization to diverse, real-world scenarios remains challenging. We propose ReasonX, a novel framework that leverages a multimodal large language model (MLLM) as a perceptual judge providing relative intrinsic comparisons, and uses these comparisons as GRPO rewards for fine-tuning intrinsic decomposition models on unlabeled, in-the-wild images. Unlike RL methods for generative models, our framework aligns conditional intrinsic predictors by rewarding agreement between the judge's relational assessments and analytically derived relations from the model's outputs. ReasonX is model-agnostic and can be applied to different intrinsic predictors. Across multiple base architectures and modalities, ReasonX yields significant improvements, including 9-25% WHDR reduction on IIW albedo and up to 46% depth accuracy gains on ETH3D, highlighting the promise of MLLM-guided comparative supervision to bridge low- and high-level vision reasoning.

【29】MoReGen: Multi-Agent Motion-Reasoning Engine for Code-based Text-to-Video Synthesis
- **标题**: MoReGen：用于基于代码的文本到视频合成的多智能体运动推理引擎
- **链接**: https://arxiv.org/abs/2512.04221
> **作者**: Xiangyu Bai,He Liang,Bishoy Galoaa,Utsav Nandi,Shayda Moezzi,Yuhang He,Sarah Ostadabbas
> **摘要**: 虽然文本到视频 (T2V) 生成在照片真实感方面取得了显着进步，但生成忠实遵守物理原理的意图一致的视频仍然是一个核心挑战。在这项工作中，我们系统地研究了牛顿运动控制的文本到视频的生成和评估，强调物理精度和运动连贯性。我们引入了 MoReGen，这是一个运动感知、基于物理的 T2V 框架，它集成了多代理 LLM、物理模拟器和渲染器，可根据代码域中的文本提示生成可重复的、物理准确的视频。为了定量评估物理有效性，我们提出对象轨迹对应作为直接评估指标，并提出 MoReSet，这是 1,275 个人工注释视频的基准，涵盖九类牛顿现象，包括场景描述、时空关系和真实轨迹。使用 MoReSet，我们对现有 T2V 模型进行实验，通过我们的 MoRe 指标和现有的基于物理的评估器评估其物理有效性。我们的结果表明，最先进的模型很难维持物理有效性，而 MoReGen 则确立了物理相干视频合成的原则方向。
> **Abstract**: While text-to-video (T2V) generation has achieved remarkable progress in photorealism, generating intent-aligned videos that faithfully obey physics principles remains a core challenge. In this work, we systematically study Newtonian motion-controlled text-to-video generation and evaluation, emphasizing physical precision and motion coherence. We introduce MoReGen, a motion-aware, physics-grounded T2V framework that integrates multi-agent LLMs, physics simulators, and renderers to generate reproducible, physically accurate videos from text prompts in the code domain. To quantitatively assess physical validity, we propose object-trajectory correspondence as a direct evaluation metric and present MoReSet, a benchmark of 1,275 human-annotated videos spanning nine classes of Newtonian phenomena with scene descriptions, spatiotemporal relations, and ground-truth trajectories. Using MoReSet, we conduct experiments on existing T2V models, evaluating their physical validity through both our MoRe metrics and existing physics-based evaluators. Our results reveal that state-of-the-art models struggle to maintain physical validity, while MoReGen establishes a principled direction toward physically coherent video synthesis.

【30】Generalized Event Partonomy Inference with Structured Hierarchical Predictive Learning
- **标题**: 具有结构化分层预测学习的广义事件部分推理
- **链接**: https://arxiv.org/abs/2512.04219
> **作者**: Zhou Chen,Joe Lin,Sathyanarayanan N. Aakur\\
> **摘要**: 人类自然地将连续体验视为时间嵌套事件的层次结构，即嵌入较粗略例程中的细粒度动作。在计算机视觉中复制这种结构需要模型不仅可以回顾性地分割视频，而且可以预测性地、分层地分割视频。我们引入了 PARSE，一个统一的框架，可以在没有监督的情况下直接从流视频中学习多尺度事件结构。 PARSE 将感知组织成​​循环预测器的层次结构，每个预测器都以自己的时间粒度运行：较低层模拟短期动态，而较高层通过基于注意力的反馈整合长期上下文。事件边界自然地作为预测误差的瞬态峰值出现，产生时间上连贯的嵌套部分，反映了人类事件感知中观察到的包含关系。通过早餐行动、50 份沙拉和 Assembly 101 三个基准进行评估，PARSE 在流媒体方法中实现了最先进的性能，并且在时间对齐 (H-GEBD) 和结构一致性 (TED、hF1) 方面可与离线基线相媲美。结果表明，不确定性下的预测学习为类人时间抽象和组合事件理解提供了一条可扩展的路径。
> **Abstract**: Humans naturally perceive continuous experience as a hierarchy of temporally nested events, fine-grained actions embedded within coarser routines. Replicating this structure in computer vision requires models that can segment video not just retrospectively, but predictively and hierarchically. We introduce PARSE, a unified framework that learns multiscale event structure directly from streaming video without supervision. PARSE organizes perception into a hierarchy of recurrent predictors, each operating at its own temporal granularity: lower layers model short-term dynamics while higher layers integrate longer-term context through attention-based feedback. Event boundaries emerge naturally as transient peaks in prediction error, yielding temporally coherent, nested partonomies that mirror the containment relations observed in human event perception. Evaluated across three benchmarks, Breakfast Actions, 50 Salads, and Assembly 101, PARSE achieves state-of-the-art performance among streaming methods and rivals offline baselines in both temporal alignment (H-GEBD) and structural consistency (TED, hF1). The results demonstrate that predictive learning under uncertainty provides a scalable path toward human-like temporal abstraction and compositional event understanding.

【31】Look Around and Pay Attention: Multi-camera Point Tracking Reimagined with Transformers
- **标题**: 环顾四周并注意：用变形金刚重新构想的多摄像机点跟踪
- **链接**: https://arxiv.org/abs/2512.04213
> **作者**: Bishoy Galoaa,Xiangyu Bai,Shayda Moezzi,Utsav Nandi,Sai Siddhartha Vivek Dhir Rangoju,Somaieh Amraee,Sarah Ostadabbas
> **摘要**: 本文提出了 LAPA（环顾四周并注意），这是一种新颖的基于端到端变压器的多摄像机点跟踪架构，它将基于外观的匹配与几何约束相结合。传统管道将检测、关联和跟踪解耦，导致在具有挑战性的场景中出现错误传播和时间不一致。 LAPA 通过利用注意力机制来跨视图和时间联合推理，通过几何先验增强的跨视图注意力机制建立软对应来解决这些限制。我们不依赖经典的三角测量，而是通过注意力加权聚合构建 3D 点表示，本质上适应不确定性和部分观察。通过对长程依赖性进行建模的转换器解码器进一步维护时间一致性，通过扩展遮挡来保留身份。对具有挑战性的数据集（包括我们新创建的多摄像头 (MC) 版本的 TAPVid-3D panoptic 和 PointOdyssey）进行的大量实验表明，我们的统一方法显着优于现有方法，在 TAPVid-3D-MC 上实现了 37.5% APD，在 PointOdyssey-MC 上实现了 90.3% APD，特别是在具有复杂运动和遮挡的场景中表现出色。代码可在 https://github.com/ostadabbas/Look-Around-and-Pay-Attention-LAPA- 获取
> **Abstract**: This paper presents LAPA (Look Around and Pay Attention), a novel end-to-end transformer-based architecture for multi-camera point tracking that integrates appearance-based matching with geometric constraints. Traditional pipelines decouple detection, association, and tracking, leading to error propagation and temporal inconsistency in challenging scenarios. LAPA addresses these limitations by leveraging attention mechanisms to jointly reason across views and time, establishing soft correspondences through a cross-view attention mechanism enhanced with geometric priors. Instead of relying on classical triangulation, we construct 3D point representations via attention-weighted aggregation, inherently accommodating uncertainty and partial observations. Temporal consistency is further maintained through a transformer decoder that models long-range dependencies, preserving identities through extended occlusions. Extensive experiments on challenging datasets, including our newly created multi-camera (MC) versions of TAPVid-3D panoptic and PointOdyssey, demonstrate that our unified approach significantly outperforms existing methods, achieving 37.5% APD on TAPVid-3D-MC and 90.3% APD on PointOdyssey-MC, particularly excelling in scenarios with complex motions and occlusions. Code is available at https://github.com/ostadabbas/Look-Around-and-Pay-Attention-LAPA-

【32】OnSight Pathology: A real-time platform-agnostic computational pathology companion for histopathology
- **标题**: OnSight Pathology：与平台无关的实时组织病理学计算病理学伴侣
- **链接**: https://arxiv.org/abs/2512.04187
> **作者**: Jinzhen Hu,Kevin Faust,Parsa Babaei Zadeh,Adrienn Bourkas,Shane Eaton,Andrew Young,Anzar Alvi,Dimitrios George Oreopoulos,Ameesha Paliwal,Assem Saleh Alrumeh,Evelyn Rose Kamski-Hennekam,Phedias Diamandis
> **摘要**: 手术组织的显微镜检查仍然是疾病分类的基石，但依赖于主观解释和高度专业化的专家的帮助，这可能会影响准确性和临床护理。虽然人工智能 (AI) 领域的新兴突破为自动化组织学分析带来了希望，但越来越多的专有数字病理解决方案为现实世界的部署设置了障碍。为了应对这些挑战，我们推出了 OnSight Pathology，这是一款与平台无关的计算机视觉软件，它使用连续的自定义屏幕捕获在用户查看数字幻灯片图像时提供实时 AI 推理。 OnSight Pathology 可作为单个独立的可执行文件 (https://onsightpathology.github.io/ ) 访问，在消费级个人计算机上本地运行，无需复杂的软件集成，从而在研究和临床工作流程中实现经济高效且安全的部署。在这里，我们使用不同幻灯片查看器中的 2,500 多个公开可用的完整幻灯片图像以及来自我们临床数字病理学设置的病例来演示 OnSight Pathology 的实用性。该软件在常规组织病理学任务中的稳健性得到了凸显，包括常见脑肿瘤类型的分类、有丝分裂检测和免疫组织化学染色的量化。内置的多模式聊天助手提供可验证的图像描述，没有严格的类别标签，以增加质量控制。最后，我们展示了与实时显微镜摄像头馈送的兼容性，包括来自个人智能手机的馈送，为在更多模拟、互操作和远程病理学环境中部署提供了潜力。我们共同重点介绍 OnSight Pathology 如何在广泛的病理学流程中提供实时 AI 推理，消除在组织病理学中采用 AI 工具的主要障碍。
> **Abstract**: The microscopic examination of surgical tissue remains a cornerstone of disease classification but relies on subjective interpretations and access to highly specialized experts, which can compromise accuracy and clinical care. While emerging breakthroughs in artificial intelligence (AI) offer promise for automated histological analysis, the growing number of proprietary digital pathology solutions has created barriers to real-world deployment. To address these challenges, we introduce OnSight Pathology, a platform-agnostic computer vision software that uses continuous custom screen captures to provide real-time AI inferences to users as they review digital slide images. Accessible as a single, self-contained executable file (https://onsightpathology.github.io/ ), OnSight Pathology operates locally on consumer-grade personal computers without complex software integration, enabling cost-effective and secure deployment in research and clinical workflows. Here we demonstrate the utility of OnSight Pathology using over 2,500 publicly available whole slide images across different slide viewers, as well as cases from our clinical digital pathology setup. The software's robustness is highlighted across routine histopathological tasks, including the classification of common brain tumor types, mitosis detection, and the quantification of immunohistochemical stains. A built-in multi-modal chat assistant provides verifiable descriptions of images, free of rigid class labels, for added quality control. Lastly, we show compatibility with live microscope camera feeds, including from personal smartphones, offering potential for deployment in more analog, inter-operative, and telepathology settings. Together, we highlight how OnSight Pathology can deliver real-time AI inferences across a broad range of pathology pipelines, removing key barriers to the adoption of AI tools in histopathology.

【33】Beyond Flicker: Detecting Kinematic Inconsistencies for Generalizable Deepfake Video Detection
- **标题**: 超越闪烁：检测运动学不一致性以实现可推广的 Deepfake 视频检测
- **链接**: https://arxiv.org/abs/2512.04175
> **作者**: Alejandro Cobo,Roberto Valle,José Miguel Buenaposada,Luis Baumela
> **摘要**: 将深度伪造检测推广到看不见的操作仍然是一个关键挑战。最近解决这个问题的方法是使用原始人脸图像来训练网络，这些图像经过手工制作的人工制品进行操作，以提取更普遍的线索。虽然对于静态图像有效，但将其扩展到视频领域是一个悬而未决的问题。现有方法将时间伪影建模为帧到帧的不稳定性，忽略了一个关键漏洞：违反不同面部区域之间的自然运动依赖性。在本文中，我们提出了一种合成视频生成方法，该方法创建具有细微运动学不一致的训练数据。我们训练自动编码器将面部标志配置分解为运动基础。通过操纵这些基础，我们有选择地打破面部运动的自然相关性，并通过面部变形将这些伪影引入原始视频中。根据我们的数据训练的网络学会发现这些复杂的生物力学缺陷，在几个流行的基准上实现最先进的泛化结果。
> **Abstract**: Generalizing deepfake detection to unseen manipulations remains a key challenge. A recent approach to tackle this issue is to train a network with pristine face images that have been manipulated with hand-crafted artifacts to extract more generalizable clues. While effective for static images, extending this to the video domain is an open issue. Existing methods model temporal artifacts as frame-to-frame instabilities, overlooking a key vulnerability: the violation of natural motion dependencies between different facial regions. In this paper, we propose a synthetic video generation method that creates training data with subtle kinematic inconsistencies. We train an autoencoder to decompose facial landmark configurations into motion bases. By manipulating these bases, we selectively break the natural correlations in facial movements and introduce these artifacts into pristine videos via face morphing. A network trained on our data learns to spot these sophisticated biomechanical flaws, achieving state-of-the-art generalization results on several popular benchmarks.

【34】Unique Lives, Shared World: Learning from Single-Life Videos
- **标题**: 独特的生活，共享的世界：从单身生活视频中学习
- **链接**: https://arxiv.org/abs/2512.04085
> **作者**: Tengda Han,Sayna Ebrahimi,Dilara Gokay,Li Yang Ku,Maks Ovsjanikov,Iva Babukova,Daniel Zoran,Viorica Patraucean,Joao Carreira,Andrew Zisserman,Dima Damen
> **摘要**: 我们引入了“单一生命”学习范式，我们专门根据一个人拍摄的以自我为中心的视频来训练一种独特的视觉模型。我们利用在一个生命中自然捕捉到的多个视角，以自我监督的方式学习视觉编码器。我们的实验证明了三个关键发现。首先，在不同生活中独立训练的模型发展出高度一致的几何理解。我们通过在不同的数据集上训练视觉编码器来证明这一点，每个数据集捕获不同的室内和室外生活，并引入一种新颖的基于交叉注意力的度量来量化不同模型开发的内部表示的功能对齐。其次，我们表明单生命模型学习可概括的几何表示，这些表示可以有效地转移到下游任务，例如在不可见的环境中的深度估计。第三，我们证明，对同一个人一周的生活进行长达 30 小时的训练，其性能与对不同网络数据进行 30 小时的训练相当，这凸显了单一生命表示学习的优势。总体而言，我们的结果表明，世界的共享结构既可以保证个人生活训练模型的一致性，又可以为视觉表征学习提供强大的信号。
> **Abstract**: We introduce the "single-life" learning paradigm, where we train a distinct vision model exclusively on egocentric videos captured by one individual. We leverage the multiple viewpoints naturally captured within a single life to learn a visual encoder in a self-supervised manner. Our experiments demonstrate three key findings. First, models trained independently on different lives develop a highly aligned geometric understanding. We demonstrate this by training visual encoders on distinct datasets each capturing a different life, both indoors and outdoors, as well as introducing a novel cross-attention-based metric to quantify the functional alignment of the internal representations developed by different models. Second, we show that single-life models learn generalizable geometric representations that effectively transfer to downstream tasks, such as depth estimation, in unseen environments. Third, we demonstrate that training on up to 30 hours from one week of the same person's life leads to comparable performance to training on 30 hours of diverse web data, highlighting the strength of single-life representation learning. Overall, our results establish that the shared structure of the world, both leads to consistency in models trained on individual lives, and provides a powerful signal for visual representation learning.

【35】SimFlow: Simplified and End-to-End Training of Latent Normalizing Flows
- **标题**: SimFlow：潜在标准化流的简化和端到端训练
- **链接**: https://arxiv.org/abs/2512.04084
> **作者**: Qinyu Zhao,Guangting Zheng,Tao Yang,Rui Zhu,Xingjian Leng,Stephen Gould,Liang Zheng
> **摘要**: 归一化流 (NF) 学习数据和高斯分布之间的可逆映射。先前的作品通常受到两个限制。首先，他们将随机噪声添加到训练样本或 VAE 潜伏中作为数据增强，引入复杂的管道，包括额外的噪声和去噪步骤。其次，他们使用预训练和冻结的 VAE 编码器，导致重建和生成质量不佳。在本文中，我们发现这两个问题可以通过一种非常简单的方式解决：只需将方差（否则将由 VAE 编码器预测）固定为常数（例如 0.5）。一方面，该方法允许编码器输出更广泛的令牌分布，并且解码器能够学习从增强的令牌分布重建干净的图像，避免额外的噪声或去噪设计。另一方面，固定方差简化了 VAE 证据下界，使得联合训练 NF 和 VAE 变得稳定。在 ImageNet $256 × 256$ 生成任务中，我们的模型 SimFlow 获得了 2.15 的 gFID 分数，优于最先进的方法 STARFlow (gFID 2.40)。此外，SimFlow可以与端到端表示对齐（REPA-E）方法无缝集成，并实现改进的gFID 1.91，在NF中树立了新的技术水平。
> **Abstract**: Normalizing Flows (NFs) learn invertible mappings between the data and a Gaussian distribution. Prior works usually suffer from two limitations. First, they add random noise to training samples or VAE latents as data augmentation, introducing complex pipelines including extra noising and denoising steps. Second, they use a pretrained and frozen VAE encoder, resulting in suboptimal reconstruction and generation quality. In this paper, we find that the two issues can be solved in a very simple way: just fixing the variance (which would otherwise be predicted by the VAE encoder) to a constant (e.g., 0.5). On the one hand, this method allows the encoder to output a broader distribution of tokens and the decoder to learn to reconstruct clean images from the augmented token distribution, avoiding additional noise or denoising design. On the other hand, fixed variance simplifies the VAE evidence lower bound, making it stable to train an NF with a VAE jointly. On the ImageNet $256 \times 256$ generation task, our model SimFlow obtains a gFID score of 2.15, outperforming the state-of-the-art method STARFlow (gFID 2.40). Moreover, SimFlow can be seamlessly integrated with the end-to-end representation alignment (REPA-E) method and achieves an improved gFID of 1.91, setting a new state of the art among NFs.

【36】PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design
- **标题**: PosterCopilot：走向专业平面设计的布局推理和可控编辑
- **链接**: https://arxiv.org/abs/2512.04082
> **作者**: Jiazhe Wei,Ken Li,Tianyu Lao,Haofan Wang,Liang Wang,Caifeng Shan,Chenyang Si
> **摘要**: 平面设计构成了现代视觉传达的基石，是促进文化和商业活动的重要媒介。最近的进展已经探索使用大型多模态模型 (LMM) 实现此过程的自动化，但现有方法通常会产生几何不准确的布局，并且缺乏专业工作流程所需的迭代、特定于层的编辑。为了解决这些限制，我们推出了 PosterCopilot，这是一个可以推进专业图形设计的布局推理和可控编辑的框架。具体来说，我们引入了一种渐进的三阶段训练策略，使 LMM 具备布局设计的几何理解和审美推理，包括扰动监督微调、视觉现实对齐的强化学习和审美反馈的强化学习。此外，我们开发了一个完整的工作流程，将经过训练的基于 LMM 的设计模型与生成模型结合起来，实现层可控的迭代编辑，以实现精确的元素细化，同时保持全局视觉一致性。大量实验表明，PosterCopilot 实现了几何精确和美观的卓越布局，为专业迭代设计提供了前所未有的可控性。
> **Abstract**: Graphic design forms the cornerstone of modern visual communication, serving as a vital medium for promoting cultural and commercial events. Recent advances have explored automating this process using Large Multimodal Models (LMMs), yet existing methods often produce geometrically inaccurate layouts and lack the iterative, layer-specific editing required in professional workflows. To address these limitations, we present PosterCopilot, a framework that advances layout reasoning and controllable editing for professional graphic design. Specifically, we introduce a progressive three-stage training strategy that equips LMMs with geometric understanding and aesthetic reasoning for layout design, consisting of Perturbed Supervised Fine-Tuning, Reinforcement Learning for Visual-Reality Alignment, and Reinforcement Learning from Aesthetic Feedback. Furthermore, we develop a complete workflow that couples the trained LMM-based design model with generative models, enabling layer-controllable, iterative editing for precise element refinement while maintaining global visual consistency. Extensive experiments demonstrate that PosterCopilot achieves geometrically accurate and aesthetically superior layouts, offering unprecedented controllability for professional iterative design.

【37】SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL
- **标题**: SpaceTools：通过双交互式强化学习进行工具增强空间推理
- **链接**: https://arxiv.org/abs/2512.04069
> **作者**: Siyi Chen,Mikaela Angelina Uy,Chan Hee Song,Faisal Ladhak,Adithyavairavan Murali,Qing Qu,Stan Birchfield,Valts Blukis,Jonathan Tremblay
> **摘要**: 视觉语言模型 (VLM) 表现出强大的定性视觉理解，但难以实现具体应用所需的度量精确的空间推理。代理范式承诺 VLM 可以使用各种可以增强这些功能的工具，例如深度估计器、分割模型和姿态估计器。然而，如何实现这一愿景，而不是仅仅依赖手工制作的提示策略或强制执行限制 VLM 发现最佳工具使用模式的固定、预定义工具管道，仍然是一个开放的挑战。强化学习可以克服这一差距，但由于多工具推理中的搜索空间很大，迄今为止仅限于使用单一视觉工具进行推理。我们引入了双重交互式强化学习（DIRL），这是一个两阶段训练框架，VLM 学习通过交互式探索和反馈来协调多个工具。在教学阶段，我们将通过交互式强化学习训练的单一工具专家的演示与使用所有工具的前沿模型的痕迹结合起来。在探索阶段，模型通过持续的强化学习进一步细化多工具协调。我们的模型 SpaceTools 具有工具增强的空间推理能力，在空间理解基准（RoboSpatial-Home、BLINK、BOP-ASK）上实现了最先进的性能，并展示了使用 7-DOF 机器人作为工具进行可靠的现实世界操纵。 DIRL 相对于普通 SFT（在 RoboSpatial 上增加 12%）和 RL（在 RoboSpatial 上增加 16%）基线提供了实质性改进。项目页面：https://spacetools.github.io/。
> **Abstract**: Vision Language Models (VLMs) demonstrate strong qualitative visual understanding, but struggle with metrically precise spatial reasoning required for embodied applications. The agentic paradigm promises that VLMs can use a wide variety of tools that could augment these capabilities, such as depth estimators, segmentation models, and pose estimators. Yet it remains an open challenge how to realize this vision without solely relying on handcrafted prompting strategies or enforcing fixed, predefined tool pipelines that limit VLMs' ability to discover optimal tool-use patterns. Reinforcement Learning could overcome this gap, but has so far been limited to reasoning with a single visual tool due to the large search space in multi-tool reasoning. We introduce Double Interactive Reinforcement Learning (DIRL), a two-phase training framework where VLMs learn to coordinate multiple tools through interactive exploration and feedback. In the teaching phase, we combine demonstrations from a single tool specialist trained via interactive RL with traces from a frontier model using all tools. In the exploration phase, the model further refines multi-tool coordination through continued RL. Our model, SpaceTools, with tool-augmented spatial reasoning ability, achieves state-of-the-art performance on spatial understanding benchmarks (RoboSpatial-Home, BLINK, BOP-ASK) and demonstrates reliable real-world manipulation using a 7-DOF robot as a tool. DIRL provides substantial improvements over the vanilla SFT (+12% on RoboSpatial) and RL (+16% on RoboSpatial) baselines. Project page: https://spacetools.github.io/.

【38】Stable Signer: Hierarchical Sign Language Generative Model
- **标题**: 稳定手语者：分层手语生成模型
- **链接**: https://arxiv.org/abs/2512.04048
> **作者**: Sen Fang,Yalin Feng,Hongbin Zhong,Yanxin Zhang,Dimitris N. Metaxas
> **摘要**: 手语制作 (SLP) 是将复杂的输入文本转换为真实视频的过程。之前的大多数作品都集中在 Text2Gloss、Gloss2Pose、Pose2Vid 阶段，还有一些集中在 Prompt2Gloss 和 Text2Avatar 阶段。然而，由于文本转换、姿势生成以及将姿势渲染成真人视频这些阶段的不准确，导致错误逐渐积累，该领域进展缓慢。因此，在本文中，我们精简了传统的冗余结构，简化和优化了任务目标，设计了一种新的手语生成模型，称为Stable Signer。它将SLP任务重新定义为仅包含文本理解（Prompt2Gloss、Text2Gloss）和Pose2Vid的分层生成端到端任务，并通过我们提出的名为SLUL的新手语理解链接器执行文本理解，并通过名为SLP-MoE手势渲染专家块生成手势，以端到端生成高质量和多风格的手语视频。 SLUL 使用新开发的语义感知光泽掩蔽损失（SAGM Loss）进行训练。与当前的SOTA生成方法相比，其性能提高了48.6%。
> **Abstract**: Sign Language Production (SLP) is the process of converting the complex input text into a real video. Most previous works focused on the Text2Gloss, Gloss2Pose, Pose2Vid stages, and some concentrated on Prompt2Gloss and Text2Avatar stages. However, this field has made slow progress due to the inaccuracy of text conversion, pose generation, and the rendering of poses into real human videos in these stages, resulting in gradually accumulating errors. Therefore, in this paper, we streamline the traditional redundant structure, simplify and optimize the task objective, and design a new sign language generative model called Stable Signer. It redefines the SLP task as a hierarchical generation end-to-end task that only includes text understanding (Prompt2Gloss, Text2Gloss) and Pose2Vid, and executes text understanding through our proposed new Sign Language Understanding Linker called SLUL, and generates hand gestures through the named SLP-MoE hand gesture rendering expert block to end-to-end generate high-quality and multi-style sign language videos. SLUL is trained using the newly developed Semantic-Aware Gloss Masking Loss (SAGM Loss). Its performance has improved by 48.6% compared to the current SOTA generation methods.

【39】RELIC: Interactive Video World Model with Long-Horizon Memory
- **标题**: RELIC：具有长视野记忆的交互式视频世界模型
- **链接**: https://arxiv.org/abs/2512.04040
> **作者**: Yicong Hong,Yiqun Mei,Chongjian Ge,Yiran Xu,Yang Zhou,Sai Bi,Yannick Hold-Geoffroy,Mike Roberts,Matthew Fisher,Eli Shechtman,Kalyan Sunkavalli,Feng Liu,Zhengqi Li,Hao Tan
> **摘要**: 真正的交互式世界模型需要三个关键要素：实时长视界流、一致的空间记忆和精确的用户控制。然而，大多数现有方法仅单独解决这些方面之一，因为同时实现所有三个方面非常具有挑战性，例如，长期记忆机制通常会降低实时性能。在这项工作中，我们提出了 RELIC，一个可以共同解决这三个挑战的统一框架。给定单个图像和文本描述，RELIC 可以实时对任意场景进行记忆感知、长时间探索。我们的模型基于最近的自回归视频扩散蒸馏技术，使用高度压缩的历史潜在标记来表示长视野内存，这些标记在 KV 缓存中用相对动作和绝对相机姿势进行编码。这种紧凑的相机感知内存结构支持隐式 3D 一致内容检索，并以最小的计算开销实现长期一致性。与此同时，我们对双向教师视频模型进行微调，以生成超出其原始 5 秒训练范围的序列，并使用新的内存高效的自我强制范式将其转换为因果学生生成器，该范式能够在长时间的教师以及长时间的学生自我部署中实现全上下文蒸馏。 RELIC 作为 14B 参数模型实现，并在精心策划的虚幻引擎渲染数据集上进行训练，实现了 16 FPS 的实时生成，同时与之前的工作相比，展示了更准确的动作跟踪、更稳定的长视野流和更强大的空间记忆检索。这些功能为 RELIC 奠定了下一代交互式世界建模的坚实基础。
> **Abstract**: A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.

【40】Fast & Efficient Normalizing Flows and Applications of Image Generative Models
- **标题**: 快速高效的归一化流程及图像生成模型的应用
- **链接**: https://arxiv.org/abs/2512.04039
> **作者**: Sandeep Nagar
> **摘要**: 本论文在两个主要领域做出了新颖的贡献：提高生成模型的效率，特别是规范化流程，以及应用生成模型来解决现实世界的计算机视觉挑战。第一部分通过六项关键创新介绍了归一化流架构的重大改进：1) 开发可逆 3x3 卷积层，并具有经过数学证明的可逆性必要和充分条件，(2) 引入更高效的四耦合层，3) 为 kxk 卷积层设计快速高效的并行反转算法，4) 用于逆卷积的快速高效反向传播算法，5) 使用卷积逆， Inverse-Flow，用于前向传播并使用提出的反向传播算法对其进行训练，以及 6) Affine-StableSR，一种紧凑且高效的超分辨率模型，利用预训练的权重和归一化流层来减少参数数量，同时保持性能。第二部分：1）使用条件 GAN 的农产品自动质量评估系统，解决类别不平衡、数据稀缺和注释挑战，在种子纯度测试中实现良好的准确性； 2）利用堆叠自动编码器进行降维的无监督地质测绘框架，与传统方法相比，显示出改进的特征提取； 3）我们提出了一种用于自动驾驶数据集的隐私保护方法，用于人脸检测和图像修复； 4）利用基于稳定扩散的图像修复来替换检测到的面部和车牌，以推进该领域的隐私保护技术和伦理考虑。 5）用于艺术修复的自适应扩散模型，通过统一微调有效处理多种类型的退化。
> **Abstract**: This thesis presents novel contributions in two primary areas: advancing the efficiency of generative models, particularly normalizing flows, and applying generative models to solve real-world computer vision challenges. The first part introduce significant improvements to normalizing flow architectures through six key innovations: 1) Development of invertible 3x3 Convolution layers with mathematically proven necessary and sufficient conditions for invertibility, (2) introduction of a more efficient Quad-coupling layer, 3) Design of a fast and efficient parallel inversion algorithm for kxk convolutional layers, 4) Fast & efficient backpropagation algorithm for inverse of convolution, 5) Using inverse of convolution, in Inverse-Flow, for the forward pass and training it using proposed backpropagation algorithm, and 6) Affine-StableSR, a compact and efficient super-resolution model that leverages pre-trained weights and Normalizing Flow layers to reduce parameter count while maintaining performance. The second part: 1) An automated quality assessment system for agricultural produce using Conditional GANs to address class imbalance, data scarcity and annotation challenges, achieving good accuracy in seed purity testing; 2) An unsupervised geological mapping framework utilizing stacked autoencoders for dimensionality reduction, showing improved feature extraction compared to conventional methods; 3) We proposed a privacy preserving method for autonomous driving datasets using on face detection and image inpainting; 4) Utilizing Stable Diffusion based image inpainting for replacing the detected face and license plate to advancing privacy-preserving techniques and ethical considerations in the field.; and 5) An adapted diffusion model for art restoration that effectively handles multiple types of degradation through unified fine-tuning.

【41】PSA: Pyramid Sparse Attention for Efficient Video Understanding and Generation
- **标题**: PSA：用于高效视频理解和生成的金字塔稀疏注意力
- **链接**: https://arxiv.org/abs/2512.04025
> **作者**: Xiaolong Li,Youping Gu,Xi Lin,Weijie Wang,Bohan Zhuang
> **摘要**: 注意力机制是基础模型的核心，但其二次复杂度仍然是扩展的关键瓶颈。这一挑战推动了有效注意力机制的发展，稀疏性成为主导范式。当前的方法通常保留或丢弃具有二进制掩码的整个键值块，导致高稀疏性下的大量信息丢失。为了弥补这一差距，我们提出了金字塔稀疏注意力（PSA），这是一个适用于视频理解和生成任务的多功能模块。 PSA 引入了多级池化 KV 表示，而不是二进制掩码，从而实现更精细的掩码粒度。具体来说，每个查询块动态地将较低的池化级别分配给关键的 KV 块，将较高的池化级别分配给不太重要的块，从而在完全保留和完全修剪之间创建信息插值。这种设计类似于计算机视觉中的定点量化和经典特征金字塔网络，可以有效减少信息丢失，同时在低计算预算下保持计算效率。它与本地硬件友好的内核配合使用，利用解耦的块瓦片设计来确保高效执行。在视频理解和生成基准中，PSA 保留了上下文信息和视觉保真度，始终优于现有的稀疏注意力基线或实现了与现有稀疏注意力基线相当的性能，并具有卓越的效率与质量权衡。我们的代码和模型权重可在以下网址公开获取：http://ziplab.co/PSA
> **Abstract**: Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dominant paradigm. Current methods typically retain or discard entire key-value blocks with binary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video understanding and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allocates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full retention and complete pruning. This design, analogous to fixed-point quantization and classical feature pyramid networks in computer vision, effectively mitigates information loss while preserving computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video understanding and generation benchmarks, PSA preserves contextual information and visual fidelity, consistently outperforming or achieving comparable performance over existing sparse attention baselines with superior efficiency-quality trade-offs. Our code and model weights are publicly available at: http://ziplab.co/PSA

【42】C3G: Learning Compact 3D Representations with 2K Gaussians
- **标题**: C3G：使用 2K 高斯学习紧凑 3D 表示
- **链接**: https://arxiv.org/abs/2512.04021
> **作者**: Honggyu An,Jaewoo Jung,Mungyeom Kim,Sunghwan Hong,Chaehyun Kim,Kazumi Fukuda,Minkyeong Jeon,Jisang Han,Takuya Narihira,Hyuna Ko,Junsu Kim,Yuki Mitsufuji,Seungryong Kim
> **摘要**: 以前馈方式从未设置的稀疏视图中重建和理解 3D 场景仍然是 3D 计算机视觉中的一项具有挑战性的任务。最近的方法使用每像素 3D 高斯分布进行重建，然后使用 2D 到 3D 特征提升阶段进行场景理解。然而，它们生成过多的冗余高斯，导致高内存开销和次优的多视图特征聚合，导致新视图合成和场景理解性能下降。我们提出了 C3G，一种新颖的前馈框架，仅在必要的空间位置估计紧凑的 3D 高斯，最大限度地减少冗余，同时实现有效的特征提升。我们引入了可学习的标记，通过自注意力聚合多视图特征来指导高斯生成，确保每个高斯集成跨视图的相关视觉特征。然后，我们利用学习到的注意力模式进行高斯解码，以有效提升特征。关于无姿势新颖视图合成、3D 开放词汇分割和视图不变特征聚合的大量实验证明了我们方法的有效性。结果表明，紧凑但具有几何意义的表示足以进行高质量的场景重建和理解，与现有方法相比，实现卓越的内存效率和特征保真度。
> **Abstract**: Reconstructing and understanding 3D scenes from unposed sparse views in a feed-forward manner remains as a challenging task in 3D computer vision. Recent approaches use per-pixel 3D Gaussian Splatting for reconstruction, followed by a 2D-to-3D feature lifting stage for scene understanding. However, they generate excessive redundant Gaussians, causing high memory overhead and sub-optimal multi-view feature aggregation, leading to degraded novel view synthesis and scene understanding performance. We propose C3G, a novel feed-forward framework that estimates compact 3D Gaussians only at essential spatial locations, minimizing redundancy while enabling effective feature lifting. We introduce learnable tokens that aggregate multi-view features through self-attention to guide Gaussian generation, ensuring each Gaussian integrates relevant visual features across views. We then exploit the learned attention patterns for Gaussian decoding to efficiently lift features. Extensive experiments on pose-free novel view synthesis, 3D open-vocabulary segmentation, and view-invariant feature aggregation demonstrate our approach's effectiveness. Results show that a compact yet geometrically meaningful representation is sufficient for high-quality scene reconstruction and understanding, achieving superior memory efficiency and feature fidelity compared to existing methods.

【43】Ultra-lightweight Neural Video Representation Compression
- **标题**: 超轻量级神经视频表示压缩
- **链接**: https://arxiv.org/abs/2512.04019
> **作者**: Ho Man Kwan,Tianhao Peng,Ge Gao,Fan Zhang,Mike Nilsson,Andrew Gower,David Bull
> **摘要**: 最近的工作证明了利用过度拟合的隐式神经表示（INR）作为基于自动编码器的神经视频压缩模型的替代方案的可行性。在这些基于 INR 的视频编解码器中，神经视频表示压缩 (NVRC) 率先采用完全端到端的压缩框架来压缩 INR，从而实现了最先进的性能。此外，最近提出的一些轻量级 INR 已显示出与其基准编解码器相当的性能，计算复杂度低于 10kMACs/像素。在这项工作中，我们将 NVRC 扩展到轻量级表示，并提出了 NVRC-Lite，其中包含两个关键变化。首先，我们将多尺度特征网格集成到轻量级神经表示中，并且使用更高分辨率的网格显着提高了低复杂度下 INR 的性能。其次，我们解决了现有 INR 通常利用自回归模型进行熵编码的问题：这些模型有效但由于编码速度慢而不切实际。在这项工作中，我们提出了一种基于八叉树的上下文模型，用于对高维特征网格进行熵编码，从而加速了模型的熵编码模块。我们的实验结果表明，NVRC-Lite 的性能优于基于 INR 的最佳轻量级视频编解码器之一的 C3，在 PSNR 和 MS-SSIM 中测量时，BD 速率分别节省了 21.03% 和 23.06%，同时实现了 8.4 倍的编码和 2.5 倍的解码加速。 NVRC-Lite 的实施将可供使用。
> **Abstract**: Recent works have demonstrated the viability of utilizing over-fitted implicit neural representations (INRs) as alternatives to autoencoder-based models for neural video compression. Among these INR-based video codecs, Neural Video Representation Compression (NVRC) was the first to adopt a fully end-to-end compression framework that compresses INRs, achieving state-of-the-art performance. Moreover, some recently proposed lightweight INRs have shown comparable performance to their baseline codecs with computational complexity lower than 10kMACs/pixel. In this work, we extend NVRC toward lightweight representations, and propose NVRC-Lite, which incorporates two key changes. Firstly, we integrated multi-scale feature grids into our lightweight neural representation, and the use of higher resolution grids significantly improves the performance of INRs at low complexity. Secondly, we address the issue that existing INRs typically leverage autoregressive models for entropy coding: these are effective but impractical due to their slow coding speed. In this work, we propose an octree-based context model for entropy coding high-dimensional feature grids, which accelerates the entropy coding module of the model. Our experimental results demonstrate that NVRC-Lite outperforms C3, one of the best lightweight INR-based video codecs, with up to 21.03% and 23.06% BD-rate savings when measured in PSNR and MS-SSIM, respectively, while achieving 8.4x encoding and 2.5x decoding speedup. The implementation of NVRC-Lite will be made available.

【44】Learning Group Actions In Disentangled Latent Image Representations
- **标题**: 学习解开的潜在图像表示中的群体动作
- **链接**: https://arxiv.org/abs/2512.04015
> **作者**: Farhana Hossain Swarnali,Miaomiao Zhang,Tonmoy Hossain
> **摘要**: 对潜在表示的群体行为进行建模可以实现高维图像数据的可控转换。应用群论先验或建模变换的先前工作通常在高维数据空间中运行，其中群动作均匀地应用于整个输入，使得很难解开在变换下变化的子空间。虽然潜在空间方法提供了更大的灵活性，但它们仍然需要手动将潜在变量划分为等变和不变子空间，从而限制了在表示空间内稳健学习和操作群体行为的能力。为了解决这个问题，我们引入了一种新颖的端到端框架，该框架首次学习潜像流形上的群体动作，自动发现与变换相关的结构，无需人工干预。我们的方法使用可学习的二进制掩码和直通估计来动态地将潜在表示划分为变换敏感和不变的组件。我们在一个统一的优化框架内制定了这一点，该框架共同学习潜在的解缠结和组转换映射。该框架可以与任何标准编码器-解码器架构无缝集成。我们在五个 2D/3D 图像数据集上验证了我们的方法，证明了其自动学习不同数据中群体行为的解开潜在因素的能力，而下游分类任务则确认了所学习表示的有效性。我们的代码可在 https://github.com/farhanaswarnali/Learning-Group-Actions-In-Disentangled-Latent-Image-Representations 上公开获取。
> **Abstract**: Modeling group actions on latent representations enables controllable transformations of high-dimensional image data. Prior works applying group-theoretic priors or modeling transformations typically operate in the high-dimensional data space, where group actions apply uniformly across the entire input, making it difficult to disentangle the subspace that varies under transformations. While latent-space methods offer greater flexibility, they still require manual partitioning of latent variables into equivariant and invariant subspaces, limiting the ability to robustly learn and operate group actions within the representation space. To address this, we introduce a novel end-to-end framework that for the first time learns group actions on latent image manifolds, automatically discovering transformation-relevant structures without manual intervention. Our method uses learnable binary masks with straight-through estimation to dynamically partition latent representations into transformation-sensitive and invariant components. We formulate this within a unified optimization framework that jointly learns latent disentanglement and group transformation mappings. The framework can be seamlessly integrated with any standard encoder-decoder architecture. We validate our approach on five 2D/3D image datasets, demonstrating its ability to automatically learn disentangled latent factors for group actions in diverse data, while downstream classification tasks confirm the effectiveness of the learned representations. Our code is publicly available at https://github.com/farhanaswarnali/Learning-Group-Actions-In-Disentangled-Latent-Image-Representations .

【45】Emergent Outlier View Rejection in Visual Geometry Grounded Transformers
- **标题**: 视觉几何接地变压器中的紧急离群值视图拒绝
- **链接**: https://arxiv.org/abs/2512.04012
> **作者**: Jisang Han,Sunghwan Hong,Jaewoo Jung,Wooseok Jang,Honggyu An,Qianqian Wang,Seungryong Kim,Chen Feng
> **摘要**: 从野外图像集合进行可靠的 3D 重建通常会受到“嘈杂”图像的阻碍 - 与其他图像很少或没有视图重叠的不相关输入。虽然传统的运动结构流程通过几何验证和异常值拒绝来处理此类情况，但前馈 3D 重建模型缺乏这些明确的机制，导致在野外条件下性能下降。在本文中，我们发现现有的前馈重建模型（例如 VGGT）尽管缺乏明确的异常值拒绝机制或噪声感知训练，但可以本质上区分干扰图像。通过对不同比例的合成干扰项进行深入分析，我们确定了自然表现出异常值抑制行为的特定层。进一步的探索表明，该层对有区别的内部表示进行编码，从而实现有效的噪声过滤功能，我们只需利用该功能在前馈 3D 重建中执行异常视图拒绝，无需任何额外的微调或监督。对受控数据集和野外数据集的大量实验表明，这种隐式过滤机制是一致的，并且可以在不同的场景中很好地推广。
> **Abstract**: Reliable 3D reconstruction from in-the-wild image collections is often hindered by "noisy" images-irrelevant inputs with little or no view overlap with others. While traditional Structure-from-Motion pipelines handle such cases through geometric verification and outlier rejection, feed-forward 3D reconstruction models lack these explicit mechanisms, leading to degraded performance under in-the-wild conditions. In this paper, we discover that the existing feed-forward reconstruction model, e.g., VGGT, despite lacking explicit outlier-rejection mechanisms or noise-aware training, can inherently distinguish distractor images. Through an in-depth analysis under varying proportions of synthetic distractors, we identify a specific layer that naturally exhibits outlier-suppressing behavior. Further probing reveals that this layer encodes discriminative internal representations that enable an effective noise-filtering capability, which we simply leverage to perform outlier-view rejection in feed-forward 3D reconstruction without any additional fine-tuning or supervision. Extensive experiments on both controlled and in-the-wild datasets demonstrate that this implicit filtering mechanism is consistent and generalizes well across diverse scenarios.

【46】On the Temporality for Sketch Representation Learning
- **标题**: 关于草图表示学习的时间性
- **链接**: https://arxiv.org/abs/2512.04007
> **作者**: Marcelo Isaias de Moraes Junior,Moacir Antonelli Ponti
> **摘要**: 草图是复杂场景和现实世界物体的简单人类手绘抽象。尽管草图表示学习领域已经取得了显着进步，但在理解时间方面与这些表示质量的真正相关性方面仍然存在差距。这项工作研究了将草图视为序列是否确实合理，以及哪些内部顺序发挥着更相关的作用。结果表明，尽管使用传统位置编码对于将草图建模为序列是有效的，但绝对坐标始终优于相对坐标。此外，非自回归解码器的性能优于自回归解码器。最后，时间性的重要性被证明取决于考虑的顺序和评估的任务。
> **Abstract**: Sketches are simple human hand-drawn abstractions of complex scenes and real-world objects. Although the field of sketch representation learning has advanced significantly, there is still a gap in understanding the true relevance of the temporal aspect to the quality of these representations. This work investigates whether it is indeed justifiable to treat sketches as sequences, as well as which internal orders play a more relevant role. The results indicate that, although the use of traditional positional encodings is valid for modeling sketches as sequences, absolute coordinates consistently outperform relative ones. Furthermore, non-autoregressive decoders outperform their autoregressive counterparts. Finally, the importance of temporality was shown to depend on both the order considered and the task evaluated.

【47】Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding
- **标题**: 先划分，后接地：使帧选择适应查询类型以实现长格式视频理解
- **链接**: https://arxiv.org/abs/2512.04000
> **作者**: Jialuo Li,Bin Li,Jiahao Li,Yan Lu
> **摘要**: 大型多模态模型 (LMM) 在长格式视频理解中的应用受到有限的上下文长度和处理密集视频标记的计算成本的限制。因此，最近的研究集中在查询感知的帧选择上，这些方法通常会产生大量的计算开销。本文挑战了这种复杂的搜索机制普遍必要的假设。我们首先识别并验证区分全局查询和本地化查询的查询类型。我们证明，虽然统一采样对于全局查询来说既有效又高效，但本地化查询确实需要查询感知选择才能获得最佳性能。基于这一见解，我们提出了 DIG，这是一种免训练的框架选择框架，可根据查询类型调整其策略。具体来说，DIG 对全局查询采用高效的统一采样，同时激活专门的管道来提取本地查询的查询相关帧。对三个长格式视频理解基准的实验表明，即使将输入帧数扩展到 256，DIG 始终优于现有基准，并显着提高了 LMM 性能。
> **Abstract**: The application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.

【48】Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation
- **标题**: 具有文本嵌入扰动的 T2I 扩散模型的高效测试时间缩放
- **链接**: https://arxiv.org/abs/2512.03996
> **作者**: Hang Xu,Linjiang Huang,Feng Zhao
> **摘要**: 测试时间缩放（TTS）旨在通过增加随机采样并根据规则和指标评估样本来获得更好的结果。然而，在文本到图像（T2I）扩散模型中，大多数相关工作都集中在搜索策略和奖励模型上，而T2I扩散模型中噪声的随机特性对该方法性能的影响仍有待探索。在这项工作中，我们分析了 T2I 扩散模型中随机性的影响，并探索了一种新的 TTS 随机性格式：文本嵌入扰动，它与 SDE 注入噪声等现有随机性相结合，以增强生成多样性和质量。我们首先对这些随机性格式及其对生成的影响进行频域分析，发现这两种随机性在频域中表现出互补的行为：空间噪声有利于低频分量（早期步骤），而文本嵌入扰动增强高频细节（后面的步骤），从而补偿高频操作中空间噪声随机性的潜在局限性。同时，文本嵌入在生成过程的不同维度上表现出对扰动的不同程度的容忍度。具体来说，我们的方法由两个关键设计组成：（1）引入基于步骤的文本嵌入扰动，将频率引导噪声调度与空间噪声扰动相结合。 (2) 根据扰动对生成的特定频率贡献和对扰动的耐受性，有选择地调整扰动强度。我们的方法可以无缝集成到现有的 TTS 方法中，并在多个基准上展示出显着的改进，几乎不需要额外的计算。代码可在 \href{https://github.com/xuhang07/TEP-Diffusion}{https://github.com/xuhang07/TEP-Diffusion} 获取。
> **Abstract**: Test-time scaling (TTS) aims to achieve better results by increasing random sampling and evaluating samples based on rules and metrics. However, in text-to-image(T2I) diffusion models, most related works focus on search strategies and reward models, yet the impact of the stochastic characteristic of noise in T2I diffusion models on the method's performance remains unexplored. In this work, we analyze the effects of randomness in T2I diffusion models and explore a new format of randomness for TTS: text embedding perturbation, which couples with existing randomness like SDE-injected noise to enhance generative diversity and quality. We start with a frequency-domain analysis of these formats of randomness and their impact on generation, and find that these two randomness exhibit complementary behavior in the frequency domain: spatial noise favors low-frequency components (early steps), while text embedding perturbation enhances high-frequency details (later steps), thereby compensating for the potential limitations of spatial noise randomness in high-frequency manipulation. Concurrently, text embedding demonstrates varying levels of tolerance to perturbation across different dimensions of the generation process. Specifically, our method consists of two key designs: (1) Introducing step-based text embedding perturbation, combining frequency-guided noise schedules with spatial noise perturbation. (2) Adapting the perturbation intensity selectively based on their frequency-specific contributions to generation and tolerance to perturbation. Our approach can be seamlessly integrated into existing TTS methods and demonstrates significant improvements on multiple benchmarks with almost no additional computation. Code is available at \href{https://github.com/xuhang07/TEP-Diffusion}{https://github.com/xuhang07/TEP-Diffusion}.

【49】DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation
- **标题**: DIQ-H：评估暂时性视觉退化下 VLM 中的幻觉持续性
- **链接**: https://arxiv.org/abs/2512.03992
> **作者**: Zexin Lin,Hawen Wan,Yebin Zhong,Xiaoqiang
> **摘要**: 部署在自动驾驶等安全关键应用中的视觉语言模型 (VLM) 必须在不完美的条件下处理连续的视觉流。然而，现有的基准测试侧重于静态的高质量图像，而忽略了时间退化和错误传播，这是关键的故障模式，其中短暂的视觉损坏会导致在后续帧中持续存在的幻觉。我们推出了 DIQ-H，这是第一个评估时间序列动态视觉退化下 VLM 鲁棒性的基准。 DIQ-H 应用基于物理的损坏，包括运动模糊、传感器噪声和压缩伪影，并通过多轮问答任务测量幻觉持久性、错误恢复和时间一致性。为了实现可扩展的注释，我们提出了不确定性引导迭代细化（UIR），它使用带有不确定性过滤的轻量级 VLM 生成可靠的伪地面实况，实现了 15.3% 的精度提升。对 16 个最先进的 VLM 进行的实验揭示了巨大的鲁棒性差距：即使是 GPT-4o 等先进模型也只能实现 78.5% 的恢复率，而开源模型则难以实现时间一致性，低于 60%。 DIQ-H 提供了一个综合平台，用于评估实际部署中的 VLM 可靠性。
> **Abstract**: Vision-Language Models (VLMs) deployed in safety-critical applications such as autonomous driving must handle continuous visual streams under imperfect conditions. However, existing benchmarks focus on static, high-quality images and ignore temporal degradation and error propagation, which are critical failure modes where transient visual corruption induces hallucinations that persist across subsequent frames. We introduce DIQ-H, the first benchmark for evaluating VLM robustness under dynamic visual degradation in temporal sequences. DIQ-H applies physics-based corruptions including motion blur, sensor noise, and compression artifacts, and measures hallucination persistence, error recovery, and temporal consistency through multi-turn question-answering tasks. To enable scalable annotation, we propose Uncertainty-Guided Iterative Refinement (UIR), which generates reliable pseudo-ground-truth using lightweight VLMs with uncertainty filtering, achieving a 15.3 percent accuracy improvement. Experiments on 16 state-of-the-art VLMs reveal substantial robustness gaps: even advanced models such as GPT-4o achieve only a 78.5 percent recovery rate, while open-source models struggle with temporal consistency at less than 60 percent. DIQ-H provides a comprehensive platform for evaluating VLM reliability in real-world deployments.

【50】DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment
- **标题**: DirectDrag：通过读出引导的特征对齐进行高保真、无掩模、无提示的基于拖动的图像编辑
- **链接**: https://arxiv.org/abs/2512.03981
> **作者**: Sheng-Hao Liao,Shang-Fu Chen,Tai-Ming Huang,Wen-Huang Cheng,Kai-Lung Hua
> **摘要**: 使用生成模型的基于拖动的图像编辑提供了对图像结构的直观控制。然而，现有方法严重依赖手动提供的掩码和文本提示来保持语义保真度和运动精度。消除这些限制会产生一个基本的权衡：没有遮罩的视觉伪影和没有提示的糟糕的空间控制。为了解决这些限制，我们提出了 DirectDrag，一种新颖的无遮罩和无提示的编辑框架。 DirectDrag 能够以最少的用户输入实现精确、高效的操作，同时保持高图像保真度和精确的点对齐。 DirectDrag 引入了两项关键创新。首先，我们设计了一个自动软掩模生成模块，该模块可以根据点位移智能地推断可编辑区域，自动定位沿运动路径的变形，同时通过生成模型的固有能力保持上下文完整性。其次，我们开发了一种读出引导的特征对齐机制，该机制利用中间扩散激活在基于点的编辑过程中保持结构一致性，从而显着提高视觉保真度。尽管在没有手动遮罩或提示的情况下进行操作，DirectDrag 与现有方法相比仍能实现卓越的图像质量，同时保持具有竞争力的拖动精度。 DragBench 和实际场景的大量实验证明了 DirectDrag 对于高质量、交互式图像操作的有效性和实用性。项目页面：https://frakw.github.io/DirectDrag/。代码位于：https://github.com/frakw/DirectDrag。
> **Abstract**: Drag-based image editing using generative models provides intuitive control over image structures. However, existing methods rely heavily on manually provided masks and textual prompts to preserve semantic fidelity and motion precision. Removing these constraints creates a fundamental trade-off: visual artifacts without masks and poor spatial control without prompts. To address these limitations, we propose DirectDrag, a novel mask- and prompt-free editing framework. DirectDrag enables precise and efficient manipulation with minimal user input while maintaining high image fidelity and accurate point alignment. DirectDrag introduces two key innovations. First, we design an Auto Soft Mask Generation module that intelligently infers editable regions from point displacement, automatically localizing deformation along movement paths while preserving contextual integrity through the generative model's inherent capacity. Second, we develop a Readout-Guided Feature Alignment mechanism that leverages intermediate diffusion activations to maintain structural consistency during point-based edits, substantially improving visual fidelity. Despite operating without manual mask or prompt, DirectDrag achieves superior image quality compared to existing methods while maintaining competitive drag accuracy. Extensive experiments on DragBench and real-world scenarios demonstrate the effectiveness and practicality of DirectDrag for high-quality, interactive image manipulation. Project Page: https://frakw.github.io/DirectDrag/. Code is available at: https://github.com/frakw/DirectDrag.

【51】BlurDM: A Blur Diffusion Model for Image Deblurring
- **标题**: BlurDM：用于图像去模糊的模糊扩散模型
- **链接**: https://arxiv.org/abs/2512.03979
> **作者**: Jin-Ting He,Fu-Jen Tsai,Yan-Tsung Peng,Min-Hung Chen,Chia-Wen Lin,Yen-Yu Lin
> **摘要**: 扩散模型显示出动态场景去模糊的前景；然而，现有的研究往往无法利用扩散模型中模糊过程的内在本质，从而限制了它们的全部潜力。为了解决这个问题，我们提出了模糊扩散模型（BlurDM），它将模糊形成过程无缝集成到图像去模糊的扩散中。观察到运动模糊源于连续曝光，BlurDM 通过双扩散前向方案隐式模拟模糊形成过程，将噪声和模糊扩散到清晰的图像上。在反向生成过程中，我们推导出双重去噪和去模糊公式，使 BlurDM 能够通过同时去噪和去模糊来恢复清晰的图像，并将模糊图像作为输入条件的纯高斯噪声。此外，为了有效地将 BlurDM 集成到去模糊网络中，我们在潜在空间中执行 BlurDM，形成灵活的前一代去模糊网络。大量实验表明，BlurDM 在四个基准数据集上显着且一致地增强了现有的去模糊方法。源代码可在 https://github.com/Jin-Ting-He/BlurDM 获取。
> **Abstract**: Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The source code is available at https://github.com/Jin-Ting-He/BlurDM.

【52】Training for Identity, Inference for Controllability: A Unified Approach to Tuning-Free Face Personalization
- **标题**: 身份训练、可控性推理：免调整人脸个性化的统一方法
- **链接**: https://arxiv.org/abs/2512.03964
> **作者**: Lianyu Pang,Ji Zhou,Qiping Wang,Baoquan Zhao,Zhenguo Yang,Qing Li,Xudong Mao
> **摘要**: 免调整面部个性化方法沿着两种不同的范式发展：将面部特征映射到文本嵌入空间的文本嵌入方法，以及通过辅助交叉注意层注入特征的基于适配器的方法。虽然这两种范式都显示出希望，但现有方法很难同时实现高身份保真度和灵活的文本可控性。我们引入 UniID，这是一个统一的免调优框架，可以协同集成这两种范式。我们的主要见解是，在合并这些方法时，它们应该仅相互强化与身份相关的信息，同时保留非身份属性的原始扩散先验。我们通过原则性的训练推理策略来实现这一点：在训练期间，我们采用以身份为中心的学习方案，引导两个分支专门捕获身份特征；在推理中，我们引入了一种归一化的重新缩放机制，该机制可以恢复基本扩散模型的文本可控性，同时使互补的身份信号能够相互增强。这一原则性设计使 UniID 能够通过灵活的文本可控性实现高保真人脸个性化。针对六种最先进方法的大量实验表明，UniID 在身份保存和文本可控性方面均实现了卓越的性能。代码可在 https://github.com/lyuPang/UniID 获取
> **Abstract**: Tuning-free face personalization methods have developed along two distinct paradigms: text embedding approaches that map facial features into the text embedding space, and adapter-based methods that inject features through auxiliary cross-attention layers. While both paradigms have shown promise, existing methods struggle to simultaneously achieve high identity fidelity and flexible text controllability. We introduce UniID, a unified tuning-free framework that synergistically integrates both paradigms. Our key insight is that when merging these approaches, they should mutually reinforce only identity-relevant information while preserving the original diffusion prior for non-identity attributes. We realize this through a principled training-inference strategy: during training, we employ an identity-focused learning scheme that guides both branches to capture identity features exclusively; at inference, we introduce a normalized rescaling mechanism that recovers the text controllability of the base diffusion model while enabling complementary identity signals to enhance each other. This principled design enables UniID to achieve high-fidelity face personalization with flexible text controllability. Extensive experiments against six state-of-the-art methods demonstrate that UniID achieves superior performance in both identity preservation and text controllability. Code will be available at https://github.com/lyuPang/UniID

【53】TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning
- **标题**: TempR1：通过时间感知多任务强化学习提高 MLLM 的时间理解
- **链接**: https://arxiv.org/abs/2512.03963
> **作者**: Tao Wu,Li Yang,Gen Zhan,Yabin Zhang,Yiting Liao,Junlin Li,Deliang Fu,Li Zhang,Limin Wang
> **摘要**: 增强对多模态大语言模型 (MLLM) 的时间理解对于推进长格式视频分析、实现时间定位、动作检测和时间敏感问答等任务至关重要。虽然强化学习（RL）最近被探索用于改进时间推理，但现有方法通常仅限于有限的任务类型和数据，限制了它们在不同时间理解场景中的泛化。为了应对这一挑战，我们提出了 TempR1，这是一种时间感知的多任务强化学习框架，可以系统地增强 MLLM 的时间理解。我们策划了一个多任务语料库，将模型暴露给不同的时间结构和语义，并基于组相对策略优化（GRPO）算法来实现稳定有效的跨任务优化。具体来说，我们将时间任务分为预测间隔和真实实例之间的三种对应类型，并为每种类型设计定制的本地化奖励，使 TempR1 能够捕获细粒度的时间依赖性并适应不同的时间模式。大量实验表明，TempR1 在多个基准测试中均实现了最先进的性能。此外，它对互补任务的联合优化产生了强大的协同效应，增强了泛化和单任务性能，为 MLLM 中的时间推理建立了可扩展且有原则的范式。
> **Abstract**: Enhancing the temporal understanding of Multimodal Large Language Models (MLLMs) is essential for advancing long-form video analysis, enabling tasks such as temporal localization, action detection, and time-sensitive question answering. While reinforcement learning (RL) has recently been explored for improving temporal reasoning, existing approaches are often confined to limited task types and data, restricting their generalization across diverse temporal understanding scenarios. To address this challenge, we present TempR1, a temporal-aware multi-task reinforcement learning framework that systematically strengthens MLLMs' temporal comprehension. We curate a multi-task corpus that exposes the model to diverse temporal structures and semantics, and build upon the Group Relative Policy Optimization (GRPO) algorithm to achieve stable and effective cross-task optimization. Specifically, we categorize temporal tasks into three correspondence types between predicted intervals and ground-truth instances, and design tailored localization rewards for each, enabling TempR1 to capture fine-grained temporal dependencies and adapt to different temporal patterns. Extensive experiments demonstrate that TempR1 attains state-of-the-art performance across multiple benchmarks. Moreover, its joint optimization over complementary tasks yields a strong synergistic effect, enhancing both generalization and single-task performance, establishing a scalable and principled paradigm for temporal reasoning in MLLMs.

【54】MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction
- **标题**: MUT3R：用于动态 3D 重建的运动感知更新变压器
- **链接**: https://arxiv.org/abs/2512.03939
> **作者**: Guole Shen,Tianchen Deng,Xingrui Qin,Nailin Wang,Jianyu Wang,Yanbo Wang,Yongtao Chen,Hesheng Wang,Jingchuan Wang
> **摘要**: 最近的有状态循环神经网络在静态 3D 重建方面取得了显着进展，但仍然容易受到运动引起的伪影的影响，其中非刚性区域会破坏空间记忆和图像特征之间的注意力传播。通过分析状态和图像令牌更新机制的内部行为，我们发现跨层聚合自注意力图揭示了一致的模式：动态区域自然地被降低权重，暴露出预训练的变换器已经编码但从未明确使用的隐式运动线索。受这一观察的启发，我们引入了 MUT3R，这是一个免训练框架，它应用注意力衍生的运动线索来抑制推理过程中 Transformer 早期层中的动态内容。我们的注意力级别门控模块在动态区域的伪影通过特征层次结构传播之前抑制动态区域的影响。值得注意的是，我们不会重新训练或微调模型；我们让预训练的 Transformer 诊断自己的运动线索并进行自我纠正。这种早期调节稳定了流场景中的几何推理，并提高了跨多个动态基准的时间一致性和相机姿势的鲁棒性，为运动感知流重建提供了一种简单且无需训练的途径。
> **Abstract**: Recent stateful recurrent neural networks have achieved remarkable progress on static 3D reconstruction but remain vulnerable to motion-induced artifacts, where non-rigid regions corrupt attention propagation between the spatial memory and image feature. By analyzing the internal behaviors of the state and image token updating mechanism, we find that aggregating self-attention maps across layers reveals a consistent pattern: dynamic regions are naturally down-weighted, exposing an implicit motion cue that the pretrained transformer already encodes but never explicitly uses. Motivated by this observation, we introduce MUT3R, a training-free framework that applies the attention-derived motion cue to suppress dynamic content in the early layers of the transformer during inference. Our attention-level gating module suppresses the influence of dynamic regions before their artifacts propagate through the feature hierarchy. Notably, we do not retrain or fine-tune the model; we let the pretrained transformer diagnose its own motion cues and correct itself. This early regulation stabilizes geometric reasoning in streaming scenarios and leads to improvements in temporal consistency and camera pose robustness across multiple dynamic benchmarks, offering a simple and training-free pathway toward motion-aware streaming reconstruction.

【55】Beyond the Ground Truth: Enhanced Supervision for Image Restoration
- **标题**: 超越真相：加强图像修复监管
- **链接**: https://arxiv.org/abs/2512.03932
> **作者**: Donghun Ryou,Inju Ha,Sanghyeok Chu,Bohyung Han
> **摘要**: 基于深度学习的图像修复取得了显着的成功。然而，在解决现实世界的退化问题时，由于数据采集的实际限制，模型性能受到数据集中真实图像质量的限制。为了解决这一限制，我们提出了一种新颖的框架，可以增强现有的地面实况图像，为现实世界的恢复提供更高质量的监督。我们的框架通过结合自适应频率掩模（由条件频率掩模生成器学习），使用超分辨率生成感知增强的地面实况图像。这些掩模指导原始地面实况及其超分辨率变体的频率分量的最佳融合，从而产生增强的地面实况图像。这种频域混合保留了原始内容的语义一致性，同时有选择地丰富感知细节，防止可能损害保真度的幻觉伪像。增强的地面实况图像用于训练轻量级输出细化网络，该网络可以与现有的恢复模型无缝集成。大量的实验表明，我们的方法持续提高了恢复图像的质量。我们通过用户研究进一步验证了监督增强和输出细化的有效性。代码可在 https://github.com/dhryougit/Beyond-the-Ground-Truth 获取。
> **Abstract**: Deep learning-based image restoration has achieved significant success. However, when addressing real-world degradations, model performance is limited by the quality of ground-truth images in datasets due to practical constraints in data acquisition. To address this limitation, we propose a novel framework that enhances existing ground truth images to provide higher-quality supervision for real-world restoration. Our framework generates perceptually enhanced ground truth images using super-resolution by incorporating adaptive frequency masks, which are learned by a conditional frequency mask generator. These masks guide the optimal fusion of frequency components from the original ground truth and its super-resolved variants, yielding enhanced ground truth images. This frequency-domain mixup preserves the semantic consistency of the original content while selectively enriching perceptual details, preventing hallucinated artifacts that could compromise fidelity. The enhanced ground truth images are used to train a lightweight output refinement network that can be seamlessly integrated with existing restoration models. Extensive experiments demonstrate that our approach consistently improves the quality of restored images. We further validate the effectiveness of both supervision enhancement and output refinement through user studies. Code is available at https://github.com/dhryougit/Beyond-the-Ground-Truth.

【56】UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework
- **标题**: UniMo：通过自回归框架统一 2D 视频和 3D 人体运动
- **链接**: https://arxiv.org/abs/2512.03918
> **作者**: Youxin Pang,Yong Zhang,Ruizhi Shao,Xiang Deng,Feng Gao,Xu Xiaoming,Xiaoming Wei,Yebin Liu
> **摘要**: 我们提出了 UniMo，一种创新的自回归模型，用于在统一框架内对 2D 人体视频和 3D 人体运动进行联合建模，首次实现了这两种模式的同时生成和理解。当前的方法主要侧重于在给定另一种模态作为条件的情况下生成一种模态，或者将其中一种模态与其他模态（例如文本和音频）集成。统一 2D 视频和 3D 运动以同时优化和生成在很大程度上仍未得到探索，由于它们在结构和分布上存在巨大差异，因此提出了重大挑战。受到 LLM 统一不同模态能力的启发，我们的方法将视频和 3D 运动建模为统一的标记序列，利用单独的嵌入层来缩小分布差距。此外，我们设计了一种序列建模策略，将两个不同的任务集成在一个框架内，证明了统一建模的有效性。此外，为了有效地与视觉标记对齐并保留 3D 空间信息，我们设计了一种具有时间扩展策略的新型 3D 运动标记​​器，使用单个 VQ-VAE 来生成量化的运动标记。它具有多个专家解码器，可处理身体形状、平移、全局方向和身体姿势，以实现可靠的 3D 运动重建。大量的实验表明，我们的方法在执行准确的动作捕捉时同时生成相应的视频和动作。这项工作利用了法学硕士融合不同数据类型的能力，为将以人为中心的信息集成到现有模型中铺平了道路，并有可能实现人类、物体和场景的多模式、可控联合建模。
> **Abstract**: We propose UniMo, an innovative autoregressive model for joint modeling of 2D human videos and 3D human motions within a unified framework, enabling simultaneous generation and understanding of these two modalities for the first time. Current methods predominantly focus on generating one modality given another as the condition or integrating either of them with other modalities such as text and audio. Unifying 2D videos and 3D motions for simultaneous optimization and generation remains largely unexplored, presenting significant challenges due to their substantial structural and distributional differences. Inspired by the LLM's ability to unify different modalities, our method models videos and 3D motions as a unified tokens sequence, utilizing separate embedding layers to mitigate distribution gaps. Additionally, we devise a sequence modeling strategy that integrates two distinct tasks within a single framework, proving the effectiveness of unified modeling. Moreover, to efficiently align with visual tokens and preserve 3D spatial information, we design a novel 3D motion tokenizer with a temporal expansion strategy, using a single VQ-VAE to produce quantized motion tokens. It features multiple expert decoders that handle body shapes, translation, global orientation, and body poses for reliable 3D motion reconstruction. Extensive experiments demonstrate that our method simultaneously generates corresponding videos and motions while performing accurate motion capture. This work taps into the capacity of LLMs to fuse diverse data types, paving the way for integrating human-centric information into existing models and potentially enabling multimodal, controllable joint modeling of humans, objects, and scenes.

【57】Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence
- **标题**: 帧时空对应的零镜头视频翻译和编辑
- **链接**: https://arxiv.org/abs/2512.03905
> **作者**: Shuai Yang,Junxin Lin,Yifan Zhou,Ziwei Liu,Chen Change Loy
> **摘要**: 文本到图像扩散模型的巨大成功促使人们广泛研究其在视频应用中的潜力。零样本技术旨在使图像扩散模型适应视频，而不需要进一步的模型训练。最近的方法主要强调将帧间对应集成到注意机制中。然而，用于识别要关注的有效特征的软约束是不够的，这可能导致时间不一致。在本文中，我们提出了 FRESCO，它将帧内对应与帧间对应相结合，以制定更鲁棒的时空约束。此增强功能可确保帧之间语义相似内容的一致转换。我们的方法超越了注意力引导，明确地优化了特征，实现了与输入视频的高度时空一致性，显着增强了操作视频的视觉连贯性。我们在视频到视频翻译和文本引导视频编辑这两个零样本任务上验证了 FRESCO 的适应性。综合实验证明了我们的框架在生成高质量、连贯视频方面的有效性，突显了相对于当前零样本方法的显着进步。
> **Abstract**: The remarkable success in text-to-image diffusion models has motivated extensive investigation of their potential for video applications. Zero-shot techniques aim to adapt image diffusion models for videos without requiring further model training. Recent methods largely emphasize integrating inter-frame correspondence into attention mechanisms. However, the soft constraint applied to identify the valid features to attend is insufficient, which could lead to temporal inconsistency. In this paper, we present FRESCO, which integrates intra-frame correspondence with inter-frame correspondence to formulate a more robust spatial-temporal constraint. This enhancement ensures a consistent transformation of semantically similar content between frames. Our method goes beyond attention guidance to explicitly optimize features, achieving high spatial-temporal consistency with the input video, significantly enhancing the visual coherence of manipulated videos. We verify FRESCO adaptations on two zero-shot tasks of video-to-video translation and text-guided video editing. Comprehensive experiments demonstrate the effectiveness of our framework in generating high-quality, coherent videos, highlighting a significant advance over current zero-shot methods.

【58】Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy
- **标题**: 双交叉注意力连体变压器用于观察等待内窥镜检查中直肠肿瘤再生评估
- **链接**: https://arxiv.org/abs/2512.03883
> **作者**: Jorge Tapias Gomez,Despoina Kanata,Aneesh Rangnekar,Christina Lee,Julio Garcia-Aguilar,Joshua Jesse Smith,Harini Veeraraghavan
> **摘要**: 越来越多的证据支持对在完全新辅助治疗 (TNT) 后重新分期时表现出临床完全缓解 (cCR) 的直肠癌患者进行观察等待 (WW) 监测。然而，在 WW 期间从后续内窥镜图像中早期检测局部再生 (LR) 的客观准确方法对于管理护理和预防远处转移至关重要。因此，我们开发了具有双重交叉注意力的 Siamese Swin Transformer (SSDCA)，以结合再分期和随访时的纵向内窥镜图像，并区分 cCR 和 LR。 SSDCA 利用预训练的 Swin 变压器来提取与领域无关的特征并增强对成像变化的鲁棒性。实施双重交叉注意是为了强调两次扫描的特征，而不需要图像的任何空间对齐来预测响应。 SSDCA 以及基于 Swin 的基线使用 135 名患者的图像对进行训练，并根据 62 名患者的一组保留图像对进行评估。 SSDCA 产生了最佳的平衡准确度 (81.76\% $\pm$ 0.04)、灵敏度 (90.07\% $\pm$ 0.08) 和特异性 (72.86\% $\pm$ 0.05)。稳健性分析显示，无论血液、粪便、毛细血管扩张和图像质量差等伪影如何，其性能都很稳定。提取特征的 UMAP 聚类显示 SSDCA 具有最大的簇间分离（1.45 $\pm$ 0.18）和最小的簇内分散（1.07 $\pm$ 0.19），证实了判别性表示学习。
> **Abstract**: Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\% $\pm$ 0.04), sensitivity (90.07\% $\pm$ 0.08), and specificity (72.86\% $\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\pm$ 0.19) with SSDCA, confirming discriminative representation learning.

【59】An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis
- **标题**: 大规模基于图的脑血管分析的自动化框架
- **链接**: https://arxiv.org/abs/2512.03869
> **作者**: Daniele Falcetta,Liane S. Canas,Lorenzo Suppa,Matteo Pentassuglia,Jon Cleary,Marc Modat,Sébastien Ourselin,Maria A. Zuluaga
> **摘要**: 我们提出了 CaravelMetrics，这是一种用于自动脑血管分析的计算框架，可通过骨架化衍生的图形表示来模拟血管形态。该框架集成了基于图集的区域分割、中心线提取和图形构建，以计算十五种形态、拓扑、分形和几何特征。这些特征可以从完整的血管网络进行全局估计，也可以在动脉区域内进行局部估计，从而实现脑血管组织的多尺度表征。 CaravelMetrics 应用于 IXI 数据集（20-86 岁）的 570 幅 3D TOF-MRA 扫描，生成可重复的血管图，捕获与年龄和性别相关的变化以及与教育相关的血管复杂性增加，与文献报道的结果一致。该框架提供了一种可扩展且完全自动化的定量脑血管特征提取方法，支持血管健康和衰老的规范建模和人群水平研究。
> **Abstract**: We present CaravelMetrics, a computational framework for automated cerebrovascular analysis that models vessel morphology through skeletonization-derived graph representations. The framework integrates atlas-based regional parcellation, centerline extraction, and graph construction to compute fifteen morphometric, topological, fractal, and geometric features. The features can be estimated globally from the complete vascular network or regionally within arterial territories, enabling multiscale characterization of cerebrovascular organization. Applied to 570 3D TOF-MRA scans from the IXI dataset (ages 20-86), CaravelMetrics yields reproducible vessel graphs capturing age- and sex-related variations and education-associated increases in vascular complexity, consistent with findings reported in the literature. The framework provides a scalable and fully automated approach for quantitative cerebrovascular feature extraction, supporting normative modeling and population-level studies of vascular health and aging.

【60】Diminishing Returns in Self-Supervised Learning
- **标题**: 自我监督学习的收益递减
- **链接**: https://arxiv.org/abs/2512.03862
> **作者**: Oli Bridge,Huey Sun,Botond Branyicskai-Nagy,Charles D'Ornano,Shomit Basu
> **摘要**: 虽然基于 Transformer 的架构席卷了计算机视觉和 NLP，但它们通常需要大量参数和训练数据才能获得强大的性能。在这项工作中，我们尝试了三个不同的预训练、中间微调和下游数据集和训练目标，以探索它们在小型 5M 参数视觉变压器上的边际效益。我们发现，虽然预训练和微调总是对我们的模型有帮助，但收益递减，但中间微调实际上可能会对下游性能产生有害影响，这可能是由于任务机制的不同所致。总而言之，我们的结果表明，小规模 ViT 从有针对性的预训练和仔细的数据选择中获益最多，而不加区别地堆叠中间任务可能会浪费计算，甚至降低性能。
> **Abstract**: While transformer-based architectures have taken computer vision and NLP by storm, they often require a vast amount of parameters and training data to attain strong performance. In this work, we experiment with three distinct pre-training, intermediate fine-tuning, and downstream datasets and training objectives to explore their marginal benefits on a small 5M-parameter vision transformer. We find that while pre-training and fine-tuning always help our model but have diminishing returns, intermediate fine-tuning can actually show harmful impact on downstream performance, potentially due to dissimilarity in task mechanics. Taken together, our results suggest that small-scale ViTs benefit most from targeted pre-training and careful data selection, while indiscriminate stacking of intermediate tasks can waste compute and even degrade performance.

【61】Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population
- **标题**: 来自代表性不足的中东人群的前列腺活检全幻灯片图像数据集
- **链接**: https://arxiv.org/abs/2512.03854
> **作者**: Peshawa J. Muhammad Ali,Navin Vincent,Saman S. Abdulla,Han N. Mohammed Fadhl,Anders Blilie,Kelvin Szolnoky,Julia Anna Mielcarz,Xiaoyi Ji,Kimmo Kartasalo,Abdulbasit K. Al-Talabani,Nita Mulliqi
> **摘要**: 人工智能 (AI) 越来越多地应用于数字病理学。公开的组织病理学数据集仍然稀缺，而现有的数据集主要代表西方人群。因此，人工智能模型对于数字化程度较低的地区（例如中东）的人群的普遍性在很大程度上是未知的。这促使我们公开发布我们的数据集，以支持全球不同人群的病理人工智能模型的开发和验证。我们展示了在伊拉克埃尔比勒连续收集的 185 名患者的 339 张前列腺核心针活检的全切片图像。这些幻灯片与三位病理学家独立分配的格里森评分和国际泌尿病理学会等级相关。使用两台高通量扫描仪（徕卡和滨松）和一台紧凑型扫描仪（Grundium）进行扫描。所有幻灯片都经过去标识化处理，并以其原始格式提供，无需进一步转换。该数据集支持分​​级一致性分析、颜色归一化和跨扫描仪鲁棒性评估。数据将按照登录代码存放在生物图像档案馆（BIA）中：待公布（TBA），并根据 CC BY 4.0 许可证发布。
> **Abstract**: Artificial intelligence (AI) is increasingly used in digital pathology. Publicly available histopathology datasets remain scarce, and those that do exist predominantly represent Western populations. Consequently, the generalizability of AI models to populations from less digitized regions, such as the Middle East, is largely unknown. This motivates the public release of our dataset to support the development and validation of pathology AI models across globally diverse populations. We present 339 whole-slide images of prostate core needle biopsies from a consecutive series of 185 patients collected in Erbil, Iraq. The slides are associated with Gleason scores and International Society of Urological Pathology grades assigned independently by three pathologists. Scanning was performed using two high-throughput scanners (Leica and Hamamatsu) and one compact scanner (Grundium). All slides were de-identified and are provided in their native formats without further conversion. The dataset enables grading concordance analyses, color normalization, and cross-scanner robustness evaluations. Data will be deposited in the Bioimage Archive (BIA) under accession code: to be announced (TBA), and released under a CC BY 4.0 license.

【62】Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba
- **标题**: 通过频率感知 Mamba 实现恶劣天气下的交通图像恢复
- **链接**: https://arxiv.org/abs/2512.03852
> **作者**: Liwen Pan,Longguang Wang,Guangwei Gao,Jun Wang,Jun Shi,Juncheng Li
> **摘要**: 恶劣天气条件下的交通图像恢复仍然是智能交通系统的关键挑战。现有方法主要关注空间域建模，但忽略频域先验。尽管新兴的 Mamba 架构擅长通过补丁相关性分析进行远程依赖建模，但其频域特征提取的潜力仍未得到开发。为了解决这个问题，我们提出了频率感知 Mamba (FAMamba)，这是一种新颖的框架，它将频率引导与序列建模相结合，以实现高效的图像恢复。我们的架构由两个关键组件组成：（1）双分支特征提取块（DFEB），通过双向2D频率自适应扫描增强局部全局交互，根据子带纹理分布动态调整遍历路径； (2) 先验引导块 (PGB)，通过基于小波的高频残差学习细化纹理细节，从而实现具有精确细节的高质量图像重建。同时，我们为 Mamba 架构设计了一种新颖的自适应频率扫描机制（AFSM），使 Mamba 能够实现跨不同子图的频域扫描，从而充分利用子图结构固有的纹理分布特征。大量实验证明了 FAMamba 的效率和有效性。
> **Abstract**: Traffic image restoration under adverse weather conditions remains a critical challenge for intelligent transportation systems. Existing methods primarily focus on spatial-domain modeling but neglect frequency-domain priors. Although the emerging Mamba architecture excels at long-range dependency modeling through patch-wise correlation analysis, its potential for frequency-domain feature extraction remains unexplored. To address this, we propose Frequency-Aware Mamba (FAMamba), a novel framework that integrates frequency guidance with sequence modeling for efficient image restoration. Our architecture consists of two key components: (1) a Dual-Branch Feature Extraction Block (DFEB) that enhances local-global interaction via bidirectional 2D frequency-adaptive scanning, dynamically adjusting traversal paths based on sub-band texture distributions; and (2) a Prior-Guided Block (PGB) that refines texture details through wavelet-based high-frequency residual learning, enabling high-quality image reconstruction with precise details. Meanwhile, we design a novel Adaptive Frequency Scanning Mechanism (AFSM) for the Mamba architecture, which enables the Mamba to achieve frequency-domain scanning across distinct subgraphs, thereby fully leveraging the texture distribution characteristics inherent in subgraph structures. Extensive experiments demonstrate the efficiency and effectiveness of FAMamba.

【63】PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation
- **标题**: PULSE：用于心脏分割、诊断和少样本跨模态临床适应的统一多任务架构
- **链接**: https://arxiv.org/abs/2512.03848
> **作者**: Hania Ghouse,Maryam Alsharqi,Farhad R. Nezami,Muzammil Behzad
> **摘要**: 心脏图像分析的任务仍然分散：解剖分割、疾病分类和基础临床报告生成通常由在不同数据体系下训练的单独网络处理。现有的框架无法将这些目标统一在一个架构中，同时保留跨成像模式和数据集的泛化性。我们引入了 PULSE，这是一种基于自监督表示的多任务视觉语言框架，并通过平衡区域重叠学习、像素级分类保真度和边界感知 IoU 细化的复合监督策略进行优化。多尺度令牌重建解码器支持解剖分割，而共享全局表示支持疾病分类和临床基础文本输出，允许模型从像素过渡到结构，最后在一个架构内进行临床推理。与之前特定于任务的流程不同，PULSE 可以学习任务不变的心脏先验，在数据集中进行稳健泛化，并且可以在最少的监督下适应新的成像模式。这使得该领域更接近可扩展的基础型心脏分析框架。
> **Abstract**: Cardiac image analysis remains fragmented across tasks: anatomical segmentation, disease classification, and grounded clinical report generation are typically handled by separate networks trained under different data regimes. No existing framework unifies these objectives within a single architecture while retaining generalization across imaging modalities and datasets. We introduce PULSE, a multi-task vision-language framework built on self-supervised representations and optimized through a composite supervision strategy that balances region overlap learning, pixel wise classification fidelity, and boundary aware IoU refinement. A multi-scale token reconstruction decoder enables anatomical segmentation, while shared global representations support disease classification and clinically grounded text output allowing the model to transition from pixels to structures and finally clinical reasoning within one architecture. Unlike prior task-specific pipelines, PULSE learns task-invariant cardiac priors, generalizes robustly across datasets, and can be adapted to new imaging modalities with minimal supervision. This moves the field closer to a scalable, foundation style cardiac analysis framework.

【64】CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation
- **标题**: CoDA：从文本到图像扩散模型到免训练数据集蒸馏
- **链接**: https://arxiv.org/abs/2512.03844
> **作者**: Letian Zhou,Songhua Liu,Xinchao Wang
> **摘要**: 利用生成模型的流行数据集蒸馏（DD）方法面临两个基本限制。首先，尽管在 DD 中率先使用扩散模型并提供了令人印象深刻的性能，但绝大多数方法自相矛盾地需要在完整目标数据集上预先训练扩散模型，这破坏了 DD 的真正目的并产生了高昂的训练成本。其次，尽管一些方法转向通用的文本到图像模型而不依赖于此类特定于目标的训练，但它们存在显着的分布不匹配，因为这些基础模型中封装的网络规模先验无法忠实地捕获特定于目标的语义，从而导致性能不佳。为了应对这些挑战，我们提出了核心分布对齐（CoDA），这是一个仅使用现成的文本到图像模型即可实现有效DD的框架。我们的关键思想是首先使用强大的基于密度的发现机制来识别目标数据集的“内在核心分布”。然后，我们引导生成过程，使生成的样本与该核心分布保持一致。通过这样做，CoDA 有效地弥合了通用生成先验和目标语义之间的差距，产生了高度代表性的蒸馏数据集。大量实验表明，在不依赖于在目标数据集上专门训练的生成模型的情况下，CoDA 的性能与以前的方法相当甚至优于以前的方法，并且在所有基准测试（包括 ImageNet-1K 及其子集）上都具有如此的依赖性。值得注意的是，它在 ImageNet-1K 上的每类 50 个图像 (IPC) 设置中建立了 60.4% 的最先进准确率。我们的代码可以在项目网页上找到：https://github.com/zzzlt422/CoDA
> **Abstract**: Prevailing Dataset Distillation (DD) methods leveraging generative models confront two fundamental limitations. First, despite pioneering the use of diffusion models in DD and delivering impressive performance, the vast majority of approaches paradoxically require a diffusion model pre-trained on the full target dataset, undermining the very purpose of DD and incurring prohibitive training costs. Second, although some methods turn to general text-to-image models without relying on such target-specific training, they suffer from a significant distributional mismatch, as the web-scale priors encapsulated in these foundation models fail to faithfully capture the target-specific semantics, leading to suboptimal performance. To tackle these challenges, we propose Core Distribution Alignment (CoDA), a framework that enables effective DD using only an off-the-shelf text-to-image model. Our key idea is to first identify the "intrinsic core distribution" of the target dataset using a robust density-based discovery mechanism. We then steer the generative process to align the generated samples with this core distribution. By doing so, CoDA effectively bridges the gap between general-purpose generative priors and target semantics, yielding highly representative distilled datasets. Extensive experiments suggest that, without relying on a generative model specifically trained on the target dataset, CoDA achieves performance on par with or even superior to previous methods with such reliance across all benchmarks, including ImageNet-1K and its subsets. Notably, it establishes a new state-of-the-art accuracy of 60.4% at the 50-images-per-class (IPC) setup on ImageNet-1K. Our code is available on the project webpage: https://github.com/zzzlt422/CoDA

【65】Heatmap Pooling Network for Action Recognition from RGB Videos
- **标题**: 用于 RGB 视频动作识别的热图池网络
- **链接**: https://arxiv.org/abs/2512.03837
> **作者**: Mengyuan Liu,Jinfu Liu,Yongkang Jiang,Bin He
> **摘要**: 由于 RGB 视频中丰富的信息，视频中的人体动作识别（HAR）引起了广泛的关注。然而，现有的从 RGB 视频中提取深度特征的方法面临着信息冗余、易受噪声影响和高存储成本等挑战。为了解决这些问题并充分利用视频中的有用信息，我们提出了一种用于视频动作识别的新型热图池化网络（HP-Net），它通过反馈池化模块提取视频中信息丰富、稳健且简洁的人体池化特征。与之前从视频中获得的姿势数据和热图特征相比，提取的池化特征表现出明显的性能优势。此外，我们设计了一个空间运动协同学习模块和一个文本细化调制模块，将提取的池化特征与其他多模态数据集成，从而实现更鲁棒的动作识别。在 NTU RGB+D 60、NTU RGB+D 120、Toyota-Smarthome 和 UAV-Human 等多个基准上进行的大量实验一致验证了我们的 HP-Net 的有效性，它优于现有的人类动作识别方法。我们的代码公开于：https://github.com/liujf69/HPNet-Action。
> **Abstract**: Human action recognition (HAR) in videos has garnered widespread attention due to the rich information in RGB videos. Nevertheless, existing methods for extracting deep features from RGB videos face challenges such as information redundancy, susceptibility to noise and high storage costs. To address these issues and fully harness the useful information in videos, we propose a novel heatmap pooling network (HP-Net) for action recognition from videos, which extracts information-rich, robust and concise pooled features of the human body in videos through a feedback pooling module. The extracted pooled features demonstrate obvious performance advantages over the previously obtained pose data and heatmap features from videos. In addition, we design a spatial-motion co-learning module and a text refinement modulation module to integrate the extracted pooled features with other multimodal data, enabling more robust action recognition. Extensive experiments on several benchmarks namely NTU RGB+D 60, NTU RGB+D 120, Toyota-Smarthome and UAV-Human consistently verify the effectiveness of our HP-Net, which outperforms the existing human action recognition methods. Our code is publicly available at: https://github.com/liujf69/HPNet-Action.

【66】Lean Unet: A Compact Model for Image Segmentation
- **标题**: Lean Unet：图像分割的紧凑模型
- **链接**: https://arxiv.org/abs/2512.03834
> **作者**: Ture Hassler,Ida Åkerholm,Marcus Nordström,Gabriele Balletti,Orcun Goksel
> **摘要**: Unet 及其变体已成为语义图像分割的标准，特别是对于计算机辅助放射学。当前的 Unet 架构迭代地对空间分辨率进行下采样，同时增加通道维度以保留信息内容。这种结构需要大量内存占用，限制了训练批量大小并增加了推理延迟。通道修剪压缩 Unet 架构而不会损失精度，但需要长时间的优化，并且可能无法跨任务和数据集泛化。通过研究 Unet 剪枝，我们假设最终的结构是关键因素，而不是剪枝的通道选择策略。根据我们的观察，我们提出了一种精简的 Unet 架构 (LUnet)，具有紧凑、扁平的层次结构，其中通道不会因分辨率减半而加倍。我们对允许进行可比报告的公共 MRI 数据集以及两个内部 CT 数据集进行评估。我们展示了最先进的剪枝解决方案（STAMP）主要从通道数最多的层进行剪枝。相比之下，简单地消除剪枝识别层或最大层​​的随机通道可以获得类似或更好的性能。我们提出的 LUnet 具有固定架构和减少 30 倍以上的参数，其性能可与传统 Unet 网络和数据自适应修剪网络相媲美。所提出的跨层通道数恒定的精益 Unet 需要少得多的参数，同时在参数总数相同的情况下实现优于标准 Unet 的性能。与需要增加信息传播瓶颈通道的标准编码器-解码器架构不同，跳过连接允许大大减少 Unet 瓶颈通道。
> **Abstract**: Unet and its variations have been standard in semantic image segmentation, especially for computer assisted radiology. Current Unet architectures iteratively downsample spatial resolution while increasing channel dimensions to preserve information content. Such a structure demands a large memory footprint, limiting training batch sizes and increasing inference latency. Channel pruning compresses Unet architecture without accuracy loss, but requires lengthy optimization and may not generalize across tasks and datasets. By investigating Unet pruning, we hypothesize that the final structure is the crucial factor, not the channel selection strategy of pruning. Based on our observations, we propose a lean Unet architecture (LUnet) with a compact, flat hierarchy where channels are not doubled as resolution is halved. We evaluate on a public MRI dataset allowing comparable reporting, as well as on two internal CT datasets. We show that a state-of-the-art pruning solution (STAMP) mainly prunes from the layers with the highest number of channels. Comparatively, simply eliminating a random channel at the pruning-identified layer or at the largest layer achieves similar or better performance. Our proposed LUnet with fixed architectures and over 30 times fewer parameters achieves performance comparable to both conventional Unet counterparts and data-adaptively pruned networks. The proposed lean Unet with constant channel count across layers requires far fewer parameters while achieving performance superior to standard Unet for the same total number of parameters. Skip connections allow Unet bottleneck channels to be largely reduced, unlike standard encoder-decoder architectures requiring increased bottleneck channels for information propagation.

【67】A Robust Camera-based Method for Breath Rate Measurement
- **标题**: 一种基于相机的鲁棒呼吸率测量方法
- **链接**: https://arxiv.org/abs/2512.03827
> **作者**: Alexey Protopopov
> **摘要**: 廉价且易于使用的相机的普及使得仅从视频片段中测量对象的呼吸速率成为可能。最近关于这个主题的工作提出了多种精确测量人类呼吸频率的方法，但是它们要么是在接近理想的条件下进行测试，要么产生的结果不够准确。本研究提出了一种更稳健的方法，使用数学变换的组合，以最小的硬件要求来测量人类的呼吸率，与真实情况的相对偏差小于 5%。该方法在 14 名志愿者拍摄的总时长超过 2 小时 30 分钟的视频上进行了测试。将获得的结果与参考数据进行比较，发现平均绝对误差为每分钟 0.57 次呼吸，这明显好于之前工作的结果。本文提出的呼吸速率测量方法更能抵抗由对象运动引起的失真，因此允许远程测量对象的呼吸速率，而不会对对象的行为产生任何显着限制。
> **Abstract**: Proliferation of cheap and accessible cameras makes it possible to measure a subject's breath rate from video footage alone. Recent works on this topic have proposed a variety of approaches for accurately measuring human breath rate, however they are either tested in near-ideal conditions, or produce results that are not sufficiently accurate. The present study proposes a more robust method to measure breath rate in humans with minimal hardware requirements using a combination of mathematical transforms with a relative deviation from the ground truth of less than 5%. The method was tested on videos taken from 14 volunteers with a total duration of over 2 hours 30 minutes. The obtained results were compared to reference data and the average mean absolute error was found to be at 0.57 respirations per minute, which is noticeably better than the results from previous works. The breath rate measurement method proposed in the present article is more resistant to distortions caused by subject movement and thus allows one to remotely measure the subject's breath rate without any significant limitations on the subject's behavior.

【68】HieroGlyphTranslator: Automatic Recognition and Translation of Egyptian Hieroglyphs to English
- **标题**: HieroGlyphTranslator：自动识别埃及象形文字并将其翻译为英语
- **链接**: https://arxiv.org/abs/2512.03817
> **作者**: Ahmed Nasser,Marwan Mohamed,Alaa Sherif,Basmala Mahmoud,Shereen Yehia,Asmaa Saad,Mariam S. El-Rahmany,Ensaf H. Mohamed
> **摘要**: 埃及象形文字是古埃及的书写系统，完全由图画组成。将这些字形翻译成英语提出了各种挑战，包括单个字形可以具有多种含义这一事实。深度学习翻译应用正在迅速发展，产生了显着影响我们生活的显著成果。在这项研究中，我们提出了一种自动识别古埃及象形文字并将其从图像翻译成英语的方法。本研究使用两个数据集进行分类和翻译：莫里斯·弗兰肯数据集和埃及翻译数据集。我们的方法分为三个阶段：分割（使用 Contour 和 Detectron2）、将符号映射到 Gardiner 代码以及翻译（使用 CNN 模型）。该模型的 BLEU 得分为 42.2，与之前的研究相比，这是一个显着的结果。
> **Abstract**: Egyptian hieroglyphs, the ancient Egyptian writing system, are composed entirely of drawings. Translating these glyphs into English poses various challenges, including the fact that a single glyph can have multiple meanings. Deep learning translation applications are evolving rapidly, producing remarkable results that significantly impact our lives. In this research, we propose a method for the automatic recognition and translation of ancient Egyptian hieroglyphs from images to English. This study utilized two datasets for classification and translation: the Morris Franken dataset and the EgyptianTranslation dataset. Our approach is divided into three stages: segmentation (using Contour and Detectron2), mapping symbols to Gardiner codes, and translation (using the CNN model). The model achieved a BLEU score of 42.2, a significant result compared to previous research.

【69】LSRS: Latent Scale Rejection Sampling for Visual Autoregressive Modeling
- **标题**: LSRS：用于视觉自回归建模的潜在尺度拒绝采样
- **链接**: https://arxiv.org/abs/2512.03796
> **作者**: Hong-Kai Zheng,Piji Li
> **摘要**: 用于图像生成的视觉自回归（VAR）建模方法提出了跨层次尺度的自回归处理，并行解码每个尺度的多个标记。该方法在加速合成的同时实现了高质量的生成。然而，规模内的并行令牌采样可能会导致结构错误，从而导致生成的图像不理想。为了缓解这个问题，我们提出了潜在尺度拒绝采样（LSRS），这是一种在推理过程中逐步细化潜在尺度中的标记图以增强 VAR 模型的方法。我们的方法使用轻量级评分模​​型来评估每个尺度采样的多个候选标记图，选择高质量的图来指导后续尺度的生成。通过优先考虑对结构一致性至关重要的早期尺度，LSRS 有效地减轻了自回归误差累积，同时保持了计算效率。实验表明，LSRS 以最小的额外计算开销显着提高了 VAR 的生成质量。对于 VAR-d30 模型，LSRS 仅增加了 1% 的推理时间，同时将其 FID 分数从 1.95 降低到 1.78。当推理时间增加15%时，FID分数可进一步降低至1.66。 LSRS 提供了一种高效的测试时间扩展解决方案，用于增强基于 VAR 的生成。
> **Abstract**: Visual Autoregressive (VAR) modeling approach for image generation proposes autoregressive processing across hierarchical scales, decoding multiple tokens per scale in parallel. This method achieves high-quality generation while accelerating synthesis. However, parallel token sampling within a scale may lead to structural errors, resulting in suboptimal generated images. To mitigate this, we propose Latent Scale Rejection Sampling (LSRS), a method that progressively refines token maps in the latent scale during inference to enhance VAR models. Our method uses a lightweight scoring model to evaluate multiple candidate token maps sampled at each scale, selecting the high-quality map to guide subsequent scale generation. By prioritizing early scales critical for structural coherence, LSRS effectively mitigates autoregressive error accumulation while maintaining computational efficiency. Experiments demonstrate that LSRS significantly improves VAR's generation quality with minimal additional computational overhead. For the VAR-d30 model, LSRS increases the inference time by merely 1% while reducing its FID score from 1.95 to 1.78. When the inference time is increased by 15%, the FID score can be further reduced to 1.66. LSRS offers an efficient test-time scaling solution for enhancing VAR-based generation.

【70】AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition
- **标题**: AdaptVision：通过自适应视觉采集的高效视觉语言模型
- **链接**: https://arxiv.org/abs/2512.03794
> **作者**: Zichuan Lin,Yicheng Liu,Yang Yang,Lvfang Tao,Deheng Ye
> **摘要**: 视觉语言模型（VLM）在视觉问答任务中取得了显着的成功，但它们对大量视觉标记的依赖带来了巨大的计算开销。虽然现有的高效 VLM 方法通过固定比率压缩来减少视觉标记，但它们是被动操作的，并且缺乏适应不同任务要求的能力。这就引发了一个基本问题：VLM 能否自主确定每个样本所需的最小视觉标记数量？受人类主动视觉机制的启发，我们引入了 AdaptVision，这是一种高效的 VLM 范例，可以通过从粗到细的方法实现自适应视觉标记采集。我们的模型最初处理来自低分辨率图像的压缩视觉标记，并在必要时通过调用边界框工具来裁剪关键区域来选择性地获取额外的视觉信息。我们使用强化学习框架来训练 AdaptVision，该框架仔细平衡了准确性和效率。我们方法的核心是解耦转向策略优化 (DTPO)，它将学习目标解耦为两个部分：(1) 工具学习，优化正确的工具利用率；(2) 准确性改进，细化生成的响应以提高答案正确性。基于这个公式，我们通过计算与每个目标相关的令牌的单独优势来进一步解耦优势估计。与普通 GRPO 相比，该公式可以更有效地优化 AdaptVision。跨多个 VQA 基准的综合实验表明，AdaptVision 实现了卓越的性能，同时消耗的视觉标记比最先进的高效 VLM 方法少得多。
> **Abstract**: Vision-Language Models (VLMs) have achieved remarkable success in visual question answering tasks, but their reliance on large numbers of visual tokens introduces significant computational overhead. While existing efficient VLM approaches reduce visual tokens through fixed-ratio compression, they operate passively and lack the ability to adapt to varying task requirements. This motivates a fundamental question: Can VLMs autonomously determine the minimum number of visual tokens required for each sample? Inspired by human active vision mechanisms, we introduce AdaptVision, an efficient VLM paradigm that enables adaptive visual token acquisition through a coarse-to-fine approach. Our model initially processes compressed visual tokens from low-resolution images and selectively acquires additional visual information by invoking a bounding box tool to crop key regions when necessary. We train AdaptVision using a reinforcement learning framework that carefully balances accuracy and efficiency. Central to our approach is Decoupled Turn Policy Optimization (DTPO), which decouples the learning objective into two components: (1) tool learning, which optimizes correct tool utilization, and (2) accuracy improvement, which refines the generated responses to improve answer correctness. Based on this formulation, we further decouple advantage estimation by computing separate advantages for tokens associated with each objective. This formulation enables more effective optimization for AdaptVision compared to vanilla GRPO. Comprehensive experiments across multiple VQA benchmarks demonstrate that AdaptVision achieves superior performance while consuming substantially fewer visual tokens than state-of-the-art efficient VLM methods.

【71】Research on Brain Tumor Classification Method Based on Improved ResNet34 Network
- **标题**: 基于改进ResNet34网络的脑肿瘤分类方法研究
- **链接**: https://arxiv.org/abs/2512.03751
> **作者**: Yufeng Li,Wenchao Zhao,Bo Dang,Weimin Wang
> **摘要**: 以前，放射学中的图像判读严重依赖手动方法。然而，脑肿瘤医学图像的手动分类既耗时又费力。即使使用浅层卷积神经网络模型，精度也并不理想。为了提高脑肿瘤图像分类的效率和准确性，本文提出一种基于改进的ResNet34网络的脑肿瘤分类模型。该模型采用ResNet34残差网络作为主干网络，并融合了多尺度特征提取。它使用多尺度输入模块作为 ResNet34 网络的第一层，使用 Inception v2 模块作为残差下采样层。此外，通道注意力机制模块从通道域的角度为图像的不同通道分配不同的权重，获得更重要的特征信息。经过五倍交叉实验的结果表明，改进网络模型的平均分类精度约为98.8%，不仅比ResNet34提高了1%，而且参数数量也仅为原模型的80%。因此，改进后的网络模型不仅提高了准确率，而且减少了杂波，达到了参数更少、准确率更高的分类效果。
> **Abstract**: Previously, image interpretation in radiology relied heavily on manual methods. However, manual classification of brain tumor medical images is time-consuming and labor-intensive. Even with shallow convolutional neural network models, the accuracy is not ideal. To improve the efficiency and accuracy of brain tumor image classification, this paper proposes a brain tumor classification model based on an improved ResNet34 network. This model uses the ResNet34 residual network as the backbone network and incorporates multi-scale feature extraction. It uses a multi-scale input module as the first layer of the ResNet34 network and an Inception v2 module as the residual downsampling layer. Furthermore, a channel attention mechanism module assigns different weights to different channels of the image from a channel domain perspective, obtaining more important feature information. The results after a five-fold crossover experiment show that the average classification accuracy of the improved network model is approximately 98.8%, which is not only 1% higher than ResNet34, but also only 80% of the number of parameters of the original model. Therefore, the improved network model not only improves accuracy but also reduces clutter, achieving a classification effect with fewer parameters and higher accuracy.

【72】Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models
- **标题**: 文本到图像扩散模型的完全无监督自偏置
- **链接**: https://arxiv.org/abs/2512.03749
> **作者**: Korada Sri Vardhana,Shrikrishna Lolla,Soma Biswas
> **摘要**: 文本到图像 (T2I) 扩散模型由于能够生成高分辨率、逼真的图像而取得了广泛的成功。这些模型是在大型数据集（例如 LAION-5B）上进行训练的，这些数据集通常是从互联网上抓取的。然而，由于这些数据包含许多偏差，模型本质上会学习和重现它们，从而导致刻板的输出。我们引入了 SelfDebias，这是一种完全无监督的测试时去偏方法，适用于任何使用 UNet 作为噪声预测器的扩散模型。 SelfDebias 识别图像编码器嵌入空间中的语义簇，并使用这些簇来指导推理过程中的扩散过程，从而最小化输出分布与均匀分布之间的 KL 散度。与监督方法不同，SelfDebias 不需要人工注释的数据集或针对每个生成的概念进行训练的外部分类器。相反，它旨在自动识别语义模式。大量实验表明，SelfDebias 可以推广到提示和扩散模型架构，包括条件模型和无条件模型。它不仅可以有效地沿关键人口统计维度消除图像偏差，同时保持生成图像的视觉保真度，而且还可以消除识别偏差也具有挑战性的更抽象的概念。
> **Abstract**: Text-to-image (T2I) diffusion models have achieved widespread success due to their ability to generate high-resolution, photorealistic images. These models are trained on large-scale datasets, like LAION-5B, often scraped from the internet. However, since this data contains numerous biases, the models inherently learn and reproduce them, resulting in stereotypical outputs. We introduce SelfDebias, a fully unsupervised test-time debiasing method applicable to any diffusion model that uses a UNet as its noise predictor. SelfDebias identifies semantic clusters in an image encoder's embedding space and uses these clusters to guide the diffusion process during inference, minimizing the KL divergence between the output distribution and the uniform distribution. Unlike supervised approaches, SelfDebias does not require human-annotated datasets or external classifiers trained for each generated concept. Instead, it is designed to automatically identify semantic modes. Extensive experiments show that SelfDebias generalizes across prompts and diffusion model architectures, including both conditional and unconditional models. It not only effectively debiases images along key demographic dimensions while maintaining the visual fidelity of the generated images, but also more abstract concepts for which identifying biases is also challenging.

【73】Thinking with Programming Vision: Towards a Unified View for Thinking with Images
- **标题**: 用编程视觉思考：迈向图像思维的统一视图
- **链接**: https://arxiv.org/abs/2512.03746
> **作者**: Zirun Guo,Minjie Hong,Feng Zhang,Kai Jia,Tao Jin
> **摘要**: 使用图像思考的多模态大语言模型 (MLLM) 可以交互地使用工具来推理视觉输入，但当前的方法通常依赖于一组狭窄的工具，而现实世界的必要性和可扩展性有限。在这项工作中，我们首先揭示了一个以前被忽视的关键弱点：即使是最先进的 MLLM 也非常脆弱，在简单的方向变化或自然损坏的图像上表现出显着的性能下降，这强调了对更强大的基于工具的推理的需要。为了解决这个问题，我们提出了 CodeVision，这是一种灵活且可扩展的代码即工具框架，其中模型生成代码作为通用接口来调用任何图像操作，超越了固定的工具注册表。我们使用两阶段方法训练我们的模型，首先是在高质量数据集上进行监督微调（SFT），以实现复杂的多轮工具组合和错误恢复，然后是强化学习（RL），具有新颖而密集的过程奖励功能，以鼓励战略性和高效的工具使用。为了促进这项研究，我们构建了新的 SFT 和 RL 数据集，并引入了一个具有挑战性的新基准套件，旨在严格评估方向变化和多工具推理的稳健性。 Qwen2.5-VL 和 Qwen3-VL 系列上的实验表明，我们的方法显着提高了模型性能，并培养了新兴功能，例如灵活的工具组合、高效的链式执行以及从运行时反馈中进行稳健的错误恢复。代码可在 https://github.com/ByteDance-BandAI/CodeVision 获取。
> **Abstract**: Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at https://github.com/ByteDance-BandAI/CodeVision.

【74】Dual-level Modality Debiasing Learning for Unsupervised Visible-Infrared Person Re-Identification
- **标题**: 用于无监督可见光-红外人员重新识别的双级模态去偏学习
- **链接**: https://arxiv.org/abs/2512.03745
> **作者**: Jiaze Li,Yan Lu,Bin Liu,Guojun Yin,Mang Ye
> **摘要**: 两阶段学习管道在无监督可见红外人员重新识别（USL-VI-ReID）方面取得了可喜的成果。它首先执行单模态学习，然后进行跨模态学习以解决模态差异。尽管前景光明，但这条管道不可避免地引入了模态偏差：在单模态训练中学到的特定模态线索自然会传播到随后的跨模态学习中，从而损害身份辨别和泛化。为了解决这个问题，我们提出了一种双级模态去偏学习（DMDL）框架，该框架在模型和优化级别上实现去偏。在模型层面，我们提出了一种受因果关系启发的调整干预（CAI）模块，用因果建模代替基于似然的建模，防止引入模态引起的虚假模式，从而形成低偏差模型。在优化层面，引入了协作无偏差训练（CBT）策略，通过集成特定于模态的增强、标签细化和特征对齐来中断模态偏差在数据、标签和特征之间的传播。对基准数据集的大量实验表明，DMDL 可以实现模态不变的特征学习和更通用的模型。
> **Abstract**: Two-stage learning pipeline has achieved promising results in unsupervised visible-infrared person re-identification (USL-VI-ReID). It first performs single-modality learning and then operates cross-modality learning to tackle the modality discrepancy. Although promising, this pipeline inevitably introduces modality bias: modality-specific cues learned in the single-modality training naturally propagate into the following cross-modality learning, impairing identity discrimination and generalization. To address this issue, we propose a Dual-level Modality Debiasing Learning (DMDL) framework that implements debiasing at both the model and optimization levels. At the model level, we propose a Causality-inspired Adjustment Intervention (CAI) module that replaces likelihood-based modeling with causal modeling, preventing modality-induced spurious patterns from being introduced, leading to a low-biased model. At the optimization level, a Collaborative Bias-free Training (CBT) strategy is introduced to interrupt the propagation of modality bias across data, labels, and features by integrating modality-specific augmentation, label refinement, and feature alignment. Extensive experiments on benchmark datasets demonstrate that DMDL could enable modality-invariant feature learning and a more generalized model.

【75】Out-of-the-box: Black-box Causal Attacks on Object Detectors
- **标题**: 开箱即用：对目标检测器的黑盒因果攻击
- **链接**: https://arxiv.org/abs/2512.03730
> **作者**: Melane Navaratnarajah,David A. Kelly,Hana Chockler
> **摘要**: 对抗性扰动是暴露目标检测器漏洞的有效方法。现有的扰动方法通常是白盒且特定于架构的。更重要的是，虽然它们常常取得成功，但很少有人清楚它们为何有效。深入了解这种成功的机制将使开发人员能够理解和分析这些攻击，并微调模型以防止它们。本文介绍了 BlackCAtt，一种黑盒算法和工具，它使用最小的、因果充分的像素集来构造对对象检测器的可解释的、不可感知的、可再现的、与体系结构无关的攻击。 BlackCAtt 将因果像素与对象检测器生成的边界框相结合，以创建导致边界框丢失、修改或添加的对抗性攻击。 BlackCAtt 适用于不同大小和架构的不同物体检测器，将检测器视为黑匣子。我们将 BlackCAtt 的性能与其他黑盒攻击方法进行了比较，结果表明，识别因果像素可以带来更精确的针对性攻击和更不易察觉的攻击。在 COCO 测试数据集上，我们的方法在删除检测方面比基线好 2.7 倍，在更改检测方面比基线好 3.86 倍，在触发新的虚假检测方面比基线好 5.75 倍。 BlackCAtt 生成的攻击非常接近原始图像，因此难以察觉，展示了因果像素的力量。
> **Abstract**: Adversarial perturbations are a useful way to expose vulnerabilities in object detectors. Existing perturbation methods are frequently white-box and architecture specific. More importantly, while they are often successful, it is rarely clear why they work. Insights into the mechanism of this success would allow developers to understand and analyze these attacks, as well as fine-tune the model to prevent them. This paper presents BlackCAtt, a black-box algorithm and a tool, which uses minimal, causally sufficient pixel sets to construct explainable, imperceptible, reproducible, architecture-agnostic attacks on object detectors. BlackCAtt combines causal pixels with bounding boxes produced by object detectors to create adversarial attacks that lead to the loss, modification or addition of a bounding box. BlackCAtt works across different object detectors of different sizes and architectures, treating the detector as a black box. We compare the performance of BlackCAtt with other black-box attack methods and show that identification of causal pixels leads to more precisely targeted and less perceptible attacks. On the COCO test dataset, our approach is 2.7 times better than the baseline in removing a detection, 3.86 times better in changing a detection, and 5.75 times better in triggering new, spurious, detections. The attacks generated by BlackCAtt are very close to the original image, and hence imperceptible, demonstrating the power of causal pixels.

【76】PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention
- **标题**: PosA-VLA：通过姿势条件锚点注意力增强动作生成
- **链接**: https://arxiv.org/abs/2512.03724
> **作者**: Ziwen Li,Xin Wang,Hanlue Zhang,Runnan Chen,Runqi Lin,Xiao He,Han Huang,Yandong Guo,Fakhri Karray,Tongliang Liu,Mingming Gong
> **摘要**: 视觉-语言-动作（VLA）模型在具体任务上表现出了卓越的性能，并显示出在现实世界应用中的巨大潜力。然而，当前的 VLA 仍然难以产生一致且精确的目标导向动作，因为它们经常沿着轨迹产生冗余或不稳定的运动，限制了它们在时间敏感场景中的适用性。在这项工作中，我们将这些冗余动作归因于现有 VLA 的空间统一感知场，这导致它们被与目标无关的物体分散注意力，特别是在复杂的环境中。为了解决这个问题，我们提出了一种高效的 PosA-VLA 框架，该框架通过姿势条件监督来锚定视觉注意力，持续指导模型对任务相关区域的感知。姿势条件锚点注意力机制使模型能够更好地将指令语义与可操作的视觉线索结合起来，从而提高动作生成的精度和效率。此外，我们的框架采用轻量级架构，不需要辅助感知模块（例如分段或接地网络），确保高效推理。大量的实验验证了我们的方法在不同的机器人操作基准上以精确且高效的行为执行具体任务，并在各种具有挑战性的环境中显示出强大的泛化能力。
> **Abstract**: The Vision-Language-Action (VLA) models have demonstrated remarkable performance on embodied tasks and shown promising potential for real-world applications. However, current VLAs still struggle to produce consistent and precise target-oriented actions, as they often generate redundant or unstable motions along trajectories, limiting their applicability in time-sensitive scenarios.In this work, we attribute these redundant actions to the spatially uniform perception field of existing VLAs, which causes them to be distracted by target-irrelevant objects, especially in complex environments.To address this issue, we propose an efficient PosA-VLA framework that anchors visual attention via pose-conditioned supervision, consistently guiding the model's perception toward task-relevant regions. The pose-conditioned anchor attention mechanism enables the model to better align instruction semantics with actionable visual cues, thereby improving action generation precision and efficiency. Moreover, our framework adopts a lightweight architecture and requires no auxiliary perception modules (e.g., segmentation or grounding networks), ensuring efficient inference. Extensive experiments verify that our method executes embodied tasks with precise and time-efficient behavior across diverse robotic manipulation benchmarks and shows robust generalization in a variety of challenging environments.

【77】DINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction
- **标题**: DINO-RotateMatch：用于大规模 3D 重建中鲁棒图像匹配的旋转感知深度框架
- **链接**: https://arxiv.org/abs/2512.03715
> **作者**: Kaichen Zhang,Tianxiang Sheng,Xuanming Shi
> **摘要**: 本文介绍了 DINO-RotateMatch，这是一种深度学习框架，旨在解决非结构化互联网图像大规模 3D 重建中图像匹配的挑战。该方法将数据集自适应图像配对策略与旋转感知关键点提取和匹配相结合。 DINO 用于检索大型集合中语义相关的图像对，而基于旋转的增强则使用 ALIKED 和 Light Glue 捕获与方向相关的局部特征。 2025 年 Kaggle 图像匹配挑战赛的实验表明，平均准确度 (mAA) 持续提高，获得银奖（943 支队伍中的第 47 名）。结果证实，将自监督全局描述符与旋转增强局部匹配相结合，为大规模 3D 重建提供了稳健且可扩展的解决方案。
> **Abstract**: This paper presents DINO-RotateMatch, a deep-learning framework designed to address the chal lenges of image matching in large-scale 3D reconstruction from unstructured Internet images. The method integrates a dataset-adaptive image pairing strategy with rotation-aware keypoint extraction and matching. DINO is employed to retrieve semantically relevant image pairs in large collections, while rotation-based augmentation captures orientation-dependent local features using ALIKED and Light Glue. Experiments on the Kaggle Image Matching Challenge 2025 demonstrate consistent improve ments in mean Average Accuracy (mAA), achieving a Silver Award (47th of 943 teams). The results confirm that combining self-supervised global descriptors with rotation-enhanced local matching offers a robust and scalable solution for large-scale 3D reconstruction.

【78】Structured Uncertainty Similarity Score (SUSS): Learning a Probabilistic, Interpretable, Perceptual Metric Between Images
- **标题**: 结构化不确定性相似度评分 (SUSS)：学习图像之间的概率性、可解释性、感知度量
- **链接**: https://arxiv.org/abs/2512.03701
> **作者**: Paula Seidler,Neill D. F. Campbell,Ivor J A Simpson
> **摘要**: 与人类视觉一致的感知相似性分数对于训练和评估计算机视觉模型至关重要。深度感知损失（例如 LPIPS）实现了良好的对齐，但依赖于具有未知不变性的复杂、高度非线性的判别特征，而像 SSIM 这样的手工测量是可解释的，但错过了关键的感知属性。我们引入了结构化不确定性相似度评分（SUSS）；它通过一组感知组件对每个图像进行建模，每个组件都由结构化多元正态分布表示。它们以生成式、自我监督的方式进行训练，以将高可能性分配给人类难以察觉的增强。最终分数是分量对数概率与从人类感知数据集中学习的权重的加权和。与基于特征的方法不同，SUSS 学习像素空间中残差的图像特定线性变换，从而通过去相关残差和采样实现透明检查。 SUSS 与人类感知判断紧密结合，在不同的失真类型中表现出强大的感知校准，并为其相似性评估提供本地化的、可解释的解释。当使用 SUSS 作为下游成像任务的感知损失时，我们进一步证明了稳定的优化行为和竞争性能。
> **Abstract**: Perceptual similarity scores that align with human vision are critical for both training and evaluating computer vision models. Deep perceptual losses, such as LPIPS, achieve good alignment but rely on complex, highly non-linear discriminative features with unknown invariances, while hand-crafted measures like SSIM are interpretable but miss key perceptual properties. We introduce the Structured Uncertainty Similarity Score (SUSS); it models each image through a set of perceptual components, each represented by a structured multivariate Normal distribution. These are trained in a generative, self-supervised manner to assign high likelihood to human-imperceptible augmentations. The final score is a weighted sum of component log-probabilities with weights learned from human perceptual datasets. Unlike feature-based methods, SUSS learns image-specific linear transformations of residuals in pixel space, enabling transparent inspection through decorrelated residuals and sampling. SUSS aligns closely with human perceptual judgments, shows strong perceptual calibration across diverse distortion types, and provides localized, interpretable explanations of its similarity assessments. We further demonstrate stable optimization behavior and competitive performance when using SUSS as a perceptual loss for downstream imaging tasks.

【79】Active Visual Perception: Opportunities and Challenges
- **标题**: 主动视觉感知：机遇与挑战
- **链接**: https://arxiv.org/abs/2512.03687
> **作者**: Yian Li,Xiaoyu Guo,Hao Zhang,Shuiwang Li,Xiaowei Dai
> **摘要**: 主动视觉感知是指系统通过感知和行动动态地参与其环境的能力，使其能够根据特定目标或不确定性来修改其行为。与仅依赖视觉数据的被动系统不同，主动视觉感知系统可以引导注意力、移动传感器或与物体交互以获取更多信息数据。这种方法在静态传感方法可能无法提供足够信息的复杂环境中特别强大。主动视觉感知在机器人、自动驾驶车辆、人机交互和监控系统等众多应用中发挥着至关重要的作用。然而，尽管其前景广阔，但仍存在一些需要解决的挑战，包括复杂视觉数据的实时处理、动态环境中的决策以及集成多模式感官输入。本文探讨了主动视觉感知固有的机遇和挑战，全面概述了其潜力、当前研究以及更广泛采用必须克服的障碍。
> **Abstract**: Active visual perception refers to the ability of a system to dynamically engage with its environment through sensing and action, allowing it to modify its behavior in response to specific goals or uncertainties. Unlike passive systems that rely solely on visual data, active visual perception systems can direct attention, move sensors, or interact with objects to acquire more informative data. This approach is particularly powerful in complex environments where static sensing methods may not provide sufficient information. Active visual perception plays a critical role in numerous applications, including robotics, autonomous vehicles, human-computer interaction, and surveillance systems. However, despite its significant promise, there are several challenges that need to be addressed, including real-time processing of complex visual data, decision-making in dynamic environments, and integrating multimodal sensory inputs. This paper explores both the opportunities and challenges inherent in active visual perception, providing a comprehensive overview of its potential, current research, and the obstacles that must be overcome for broader adoption.

【80】GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces
- **标题**: GaussianBlender：具有解开潜在空间的 3D 高斯的即时风格化
- **链接**: https://arxiv.org/abs/2512.03683
> **作者**: Melis Ocal,Xiaoyan Xing,Yue Li,Ngo Anh Vien,Sezer Karaoglu,Theo Gevers
> **摘要**: 3D 风格化是游戏开发、虚拟现实和数字艺术的核心，其中对多样化资产的需求需要支持快速、高保真操作的可扩展方法。现有的文本到 3D 风格化方法通常是从 2D 图像编辑器中提取的，需要耗时的每个资产优化，并且由于当前文本到图像模型的限制而表现出多视图不一致，这使得它们对于大规模生产来说不切实际。在本文中，我们介绍了 GaussianBlender，这是一种用于文本驱动 3D 风格化的开创性前馈框架，可在推理时立即执行编辑。我们的方法通过空间分组 3D 高斯的几何和外观的受控信息共享来学习结构化、解纠缠的潜在空间。然后，潜在扩散模型对这些学习到的表示应用文本条件编辑。综合评估表明，GaussianBlender 不仅提供即时、高保真、几何保留、多视图一致的风格化，而且超越了需要每个实例测试时间优化的方法 - 大规模解锁实用、大众化的 3D 风格化。
> **Abstract**: 3D stylization is central to game development, virtual reality, and digital arts, where the demand for diverse assets calls for scalable methods that support fast, high-fidelity manipulation. Existing text-to-3D stylization methods typically distill from 2D image editors, requiring time-intensive per-asset optimization and exhibiting multi-view inconsistency due to the limitations of current text-to-image models, which makes them impractical for large-scale production. In this paper, we introduce GaussianBlender, a pioneering feed-forward framework for text-driven 3D stylization that performs edits instantly at inference. Our method learns structured, disentangled latent spaces with controlled information sharing for geometry and appearance from spatially-grouped 3D Gaussians. A latent diffusion model then applies text-conditioned edits on these learned representations. Comprehensive evaluations show that GaussianBlender not only delivers instant, high-fidelity, geometry-preserving, multi-view consistent stylization, but also surpasses methods that require per-instance test-time optimization - unlocking practical, democratized 3D stylization at scale.

【81】ConvRot: Rotation-Based Plug-and-Play 4-bit Quantization for Diffusion Transformers
- **标题**: ConvRot：用于扩散变压器的基于旋转的即插即用 4 位量化
- **链接**: https://arxiv.org/abs/2512.03673
> **作者**: Feice Huang,Zuliang Han,Xing Zhou,Yihuang Chen,Lifei Zhu,Haoqian Wang
> **摘要**: 扩散变压器在生成高质量图像方面表现出了强大的能力。然而，随着模型大小的增加，不断增长的内存占用和推理延迟给实际部署带来了重大挑战。最近对大型语言模型 (LLM) 的研究表明，基于旋转的技术可以平滑离群值并实现 4 位量化，但这些方法通常会产生大量开销，并且难以应对扩散变换器中的行向离群值。为了应对这些挑战，我们提出了 ConvRot，这是一种基于分组旋转的量化方法，利用常规 Hadamard 变换 (RHT) 来抑制行方向和列方向的异常值，同时将复杂性从二次降低到线性。在此基础上，我们设计了 ConvLinear4bit，这是一个即插即用的模块，集成了旋转、量化、GEMM 和反量化，无需重新训练即可实现 W4A4 推理并保持视觉质量。 FLUX.1-dev 上的实验表明，在保持图像保真度的同时，速度提高了 2.26$\times$，内存减少了 4.05$\times$。据我们所知，这是基于旋转的量化在扩散变压器中用于即插即用 W4A4 推理的首次应用。
> **Abstract**: Diffusion transformers have demonstrated strong capabilities in generating high-quality images. However, as model size increases, the growing memory footprint and inference latency pose significant challenges for practical deployment. Recent studies in large language models (LLMs) show that rotation-based techniques can smooth outliers and enable 4-bit quantization, but these approaches often incur substantial overhead and struggle with row-wise outliers in diffusion transformers. To address these challenges, we propose ConvRot, a group-wise rotation-based quantization method that leverages regular Hadamard transform (RHT) to suppress both row-wise and column-wise outliers while reducing complexity from quadratic to linear. Building on this, we design ConvLinear4bit, a plug-and-play module that integrates rotation, quantization, GEMM, and dequantization, enabling W4A4 inference without retraining and preserving visual quality. Experiments on FLUX.1-dev demonstrate a 2.26$\times$ speedup and 4.05$\times$ memory reduction while maintaining image fidelity. To our knowledge, this is the first application of rotation-based quantization for plug-and-play W4A4 inference in diffusion transformers.

【82】Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning
- **标题**: Colon-X：推进智能结肠镜检查从多模式理解到临床推理
- **链接**: https://arxiv.org/abs/2512.03667
> **作者**: Ge-Peng Ji,Jingyi Liu,Deng-Ping Fan,Nick Barnes
> **摘要**: 在这项研究中，我们提出了 Colon-X，这是一项旨在推进结肠镜检查中多模式智能的开放倡议。我们首先构建 ColonVQA，这是有史以来为结肠镜检查构建的最全面的多模态数据集，包含超过 110 万个视觉问答条目，涉及 76 项临床发现和 18 项多模态任务。除了作为社区范围的数据基础之外，我们还进一步研究了结肠镜检查中一个关键但尚未充分探索的转变——从多模态理解演变为临床推理：（a）为了捕捉多模态理解行为的当前状况，我们系统地评估了 22 种多模态大语言模型的普遍性，并检查了它们在人为干扰下的可靠性。结果表明，领先的 MLLM 的临床输出仍然远不稳健和值得信赖。 (b) 为了缩小这一差距，我们进一步探索为结肠镜检查量身定制的以推理为中心的智能。具体来说，我们策划了 ColonReason，这是一个通过多专家辩论管道注释的临床推理数据集，并开发了 ColonR1，这是第一个结合任务自适应奖励和梯度稳定优化技术的 R1 风格模型。在数据稀缺的条件下，我们的 ColonR1 的总体准确率达到 56.61%，比监督微调高出 25.22%，并为多模式结肠镜检查分析设定了新的推理基线。所有数据和模型资源均可在 https://github.com/ai4colonoscopy/Colon-X 上公开获取。
> **Abstract**: In this study, we present Colon-X, an open initiative aimed at advancing multimodal intelligence in colonoscopy. We begin by constructing ColonVQA, the most comprehensive multimodal dataset ever built for colonoscopy, featuring over 1.1M+ visual question answering entries across 76 clinical findings and 18 multimodal tasks. Beyond serving as a community-wide data foundation, we further investigate a critical yet underexplored transition in colonoscopy - evolving from multimodal understanding to clinical reasoning: (a) To capture the current landscape of multimodal understanding behaviors, we systematically assess the generalizability of 22 multimodal large language models and examine their reliability under human-induced perturbations. The results reveal that clinical outputs from leading MLLMs remain far from robust and trustworthy. (b) To narrow this gap, we further explore reasoning-centric intelligence tailored for colonoscopy. Specifically, we curate ColonReason, a clinically grounded reasoning dataset annotated through a multi-expert debating pipeline, and develop ColonR1, the first R1-styled model incorporating task-adaptive rewarding and gradient-stable optimization techniques. Under data-scarce conditions, our ColonR1 achieves 56.61% overall accuracy, outperforming supervised fine-tuning by 25.22%, and sets a new reasoning-enabled baseline for multimodal colonoscopy analysis. All data and model resources are publicly available at https://github.com/ai4colonoscopy/Colon-X.

【83】ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos
- **标题**: ToG-Bench：自我中心视频中面向任务的时空基础
- **链接**: https://arxiv.org/abs/2512.03666
> **作者**: Qi'ao Xu,Tianwen Qian,Yuqian Fu,Kailing Li,Yang Jiao,Jiacheng Zhang,Xiaoling Wang,Liang He
> **摘要**: 通用体现智能的核心能力在于从自我中心的角度定位与任务相关的对象，被表述为时空视频接地（STVG）。尽管最近取得了进展，现有的 STVG 研究仍然主要局限于以对象为中心和描述性指令，忽略了面向任务的推理，而这对于实体主体完成目标导向的交互至关重要。为了弥补这一差距，我们引入了 \textbf{ToG-Bench}，这是第一个面向任务的时空视频基础基准，用于以自我为中心的视频。 ToG-Bench 具有三个关键特征：（1）\textbf{面向任务的基础}，它需要根据预期任务而不是简单的描述来识别和定位对象； (2) \textbf{显隐双重基础}，其中目标对象可以通过上下文推理显式提及或隐式推断； (3) \textbf{一对多基础}，其中一条指令可能对应于任务执行中涉及的多个对象。 ToG-Bench 基于 ScanNet 的视频构建，包含 100 个带注释的剪辑和 2,704 条面向任务的基础指令，通过结合基础模型注释和人工细化的半自动化管道构建。此外，我们引入了一组针对多对象和显隐对象基础量身定制的任务级评估指标，并系统地对七个最先进的 MLLM 进行了基准测试。大量的实验揭示了面向任务的 STVG 的内在挑战以及显式-隐式和多对象基础之间的巨大性能差距，凸显了在具体场景中桥接感知和交互的难度。数据和代码将发布在：\href{https://github.com/qaxuDev/ToG-Bench}{https://github.com/qaxuDev/ToG-Bench}..
> **Abstract**: A core capability towards general embodied intelligence lies in localizing task-relevant objects from an egocentric perspective, formulated as Spatio-Temporal Video Grounding (STVG). Despite recent progress, existing STVG studies remain largely confined to object-centric and descriptive instructions, neglecting the task-oriented reasoning that is crucial for embodied agents to accomplish goal-directed interactions. To bridge this gap, we introduce \textbf{ToG-Bench}, the first task-oriented spatio-temporal video grounding benchmark for egocentric videos. ToG-Bench is characterized by three key features: (1) \textbf{Task-oriented Grounding}, which requires identifying and localizing objects based on intended tasks rather than straightforward descriptions; (2) \textbf{Explicit-Implicit Dual Grounding}, where target objects can be either explicitly mentioned or implicitly inferred by contextual reasoning; (3) \textbf{One-to-Many Grounding}, where a single instruction may correspond to multiple objects involved in task execution. Built upon videos sourced from ScanNet, ToG-Bench comprises 100 annotated clips with 2,704 task-oriented grounding instructions, constructed via a semi-automated pipeline that combines foundation model annotation and human refinement. In addition, we introduce a set of task-level evaluation metrics tailored for multi-object and explicit-implicit object grounding, and systematically benchmark seven state-of-the-art MLLMs. Extensive experiments reveal the intrinsic challenges of task-oriented STVG and substantial performance gaps across explicit-implicit and multi-object grounding, highlighting the difficulty of bridging perception and interaction in embodied scenarios. Data and code will be released at: \href{https://github.com/qaxuDev/ToG-Bench}{https://github.com/qaxuDev/ToG-Bench}..

【84】Multi-Scale Visual Prompting for Lightweight Small-Image Classification
- **标题**: 用于轻量级小图像分类的多尺度视觉提示
- **链接**: https://arxiv.org/abs/2512.03663
> **作者**: Salim Khazem
> **摘要**: 视觉提示最近成为一种有效的策略，使用注入输入空间的轻量级、可学习的参数来调整视觉模型。然而，之前的工作主要针对大型 Vision Transformer 和高分辨率数据集（例如 ImageNet）。相比之下，像 MNIST、Fashion-MNIST 和 CIFAR-10 这样的小图像基准仍然广泛应用于教育、原型设计和研究，但在提示方面却很少受到关注。在本文中，我们介绍了 \textbf{多尺度视觉提示（MSVP）}，这是一个简单而通用的模块，它通过轻量级的 $1 \times 1$ 卷积学习一组全局、中尺度和局部提示图，这些提示图与输入图像融合。 MSVP 与主干网无关，添加的参数不到 $0.02\%$，并显着提高了 CNN 和 Vision Transformer 主干网的性能。我们使用简单的 CNN、ResNet-18 和小型 Vision Transformer 提供 MNIST、Fashion-MNIST 和 CIFAR-10 的统一基准。我们的方法产生了一致的改进，而计算开销可以忽略不计。我们进一步包括即时尺度、融合策略和骨干架构的消融，以及使用即时可视化和 Grad-CAM 的定性分析。我们的结果表明，即使在低分辨率图像上，多尺度提示也能提供有效的归纳偏差。
> **Abstract**: Visual prompting has recently emerged as an efficient strategy to adapt vision models using lightweight, learnable parameters injected into the input space. However, prior work mainly targets large Vision Transformers and high-resolution datasets such as ImageNet. In contrast, small-image benchmarks like MNIST, Fashion-MNIST, and CIFAR-10 remain widely used in education, prototyping, and research, yet have received little attention in the context of prompting. In this paper, we introduce \textbf{Multi-Scale Visual Prompting (MSVP)}, a simple and generic module that learns a set of global, mid-scale, and local prompt maps fused with the input image via a lightweight $1 \times 1$ convolution. MSVP is backbone-agnostic, adds less than $0.02\%$ parameters, and significantly improves performance across CNN and Vision Transformer backbones. We provide a unified benchmark on MNIST, Fashion-MNIST, and CIFAR-10 using a simple CNN, ResNet-18, and a small Vision Transformer. Our method yields consistent improvements with negligible computational overhead. We further include ablations on prompt scales, fusion strategies, and backbone architectures, along with qualitative analyzes using prompt visualizations and Grad-CAM. Our results demonstrate that multi-scale prompting provides an effective inductive bias even on low-resolution images.

【85】Optical Context Compression Is Just (Bad) Autoencoding
- **标题**: 光学上下文压缩只是（糟糕的）自动编码
- **链接**: https://arxiv.org/abs/2512.03643
> **作者**: Ivan Yee Lee,Cheng Yang,Taylor Berg-Kirkpatrick
> **摘要**: DeepSeek-OCR 证明可以从少量视觉标记以高保真度重建渲染文本。这一发现激发了人们对基于视觉的语言模型上下文压缩的兴趣。但评估止于重建；这些表示是否有助于语言建模仍有待测试。我们测试了光学压缩叙述中隐含的两个假设：基于视觉的压缩为从压缩表示中重建文本提供了独特的优势，而 DeepSeek-OCR 的重建结果证明基于视觉的压缩将有助于语言建模。将他们的视觉编码器与简单的替代方案（无参数均值池和学习的分层编码器）进行比较，我们发现这些简单的方法在匹配的压缩比下匹配或超过了重建视觉，并且在语言建模方面优于它——其中基于视觉的压缩无法击败截断。围绕光学上下文压缩的兴奋超过了证据。代码和检查点可在 https://github.com/ivnle/bad-autoencoding 获取
> **Abstract**: DeepSeek-OCR demonstrates that rendered text can be reconstructed with high fidelity from a small number of vision tokens. This finding has sparked excitement about vision-based context compression for language models. But the evaluation stops at reconstruction; whether these representations help language modeling remains untested. We test two assumptions implicit in the optical-compression narrative: that vision-based compression provides unique advantages for text reconstruction from compressed representations, and that DeepSeek-OCR's reconstruction results are evidence that vision-based compression will be useful for language modeling. Comparing their vision encoder against simple alternatives--parameter-free mean pooling and a learned hierarchical encoder--we find that these simple approaches match or surpass vision for reconstruction at matched compression ratios, and outperform it for language modeling--where vision-based compression fails to beat truncation. The excitement around optical context compression outpaces the evidence. Code and checkpoints are available at https://github.com/ivnle/bad-autoencoding

【86】MKSNet: Advanced Small Object Detection in Remote Sensing Imagery with Multi-Kernel and Dual Attention Mechanisms
- **标题**: MKSNet：具有多内核和双重注意机制的遥感图像中的高级小物体检测
- **链接**: https://arxiv.org/abs/2512.03640
> **作者**: Jiahao Zhang,Xiao Zhao,Guangyu Gao
> **摘要**: 深度卷积神经网络 (DCNN) 具有非常先进的目标检测能力，特别是在遥感图像中。然而，挑战仍然存在，特别是在检测小物体时，这些图像的高分辨率和目标物体的小尺寸通常会导致传统 CNN 深层中关键信息的丢失。此外，遥感图像中典型的广泛空间冗余和复杂的背景细节往往会掩盖这些小目标。为了应对这些挑战，我们引入了多内核选择网络（MKSNet），这是一种新颖的网络架构，具有新颖的多内核选择机制。 MKS 机制利用大型卷积核来有效捕获广泛的上下文信息。这种创新设计允许自适应内核大小选择，显着增强网络动态处理和强调小物体检测的关键空间细节的能力。此外，MKSNet 还采用了双重注意力机制，合并了空间和通道注意力模块。空间注意力模块自适应地微调特征图的空间权重，更加集中地关注相关区域，同时减轻背景噪声。同时，通道注意力模块优化通道信息选择，提高特征表示和检测精度。对 DOTA-v1.0 和 HRSC2016 基准的实证评估表明，MKSNet 在检测遥感图像中的小物体方面大大超越了现有的最先进模型。这些结果凸显了 MKSNet 管理与多尺度和高分辨率图像数据相关的复杂性的卓越能力，证实了其在遥感物体检测方面的有效性和创新。
> **Abstract**: Deep convolutional neural networks (DCNNs) have substantially advanced object detection capabilities, particularly in remote sensing imagery. However, challenges persist, especially in detecting small objects where the high resolution of these images and the small size of target objects often result in a loss of critical information in the deeper layers of conventional CNNs. Additionally, the extensive spatial redundancy and intricate background details typical in remote-sensing images tend to obscure these small targets. To address these challenges, we introduce Multi-Kernel Selection Network (MKSNet), a novel network architecture featuring a novel Multi-Kernel Selection mechanism. The MKS mechanism utilizes large convolutional kernels to effectively capture an extensive range of contextual information. This innovative design allows for adaptive kernel size selection, significantly enhancing the network's ability to dynamically process and emphasize crucial spatial details for small object detection. Furthermore, MKSNet also incorporates a dual attention mechanism, merging spatial and channel attention modules. The spatial attention module adaptively fine-tunes the spatial weights of feature maps, focusing more intensively on relevant regions while mitigating background noise. Simultaneously, the channel attention module optimizes channel information selection, improving feature representation and detection accuracy. Empirical evaluations on the DOTA-v1.0 and HRSC2016 benchmark demonstrate that MKSNet substantially surpasses existing state-of-the-art models in detecting small objects in remote sensing images. These results highlight MKSNet's superior ability to manage the complexities associated with multi-scale and high-resolution image data, confirming its effectiveness and innovation in remote sensing object detection.

【87】FeatureLens: A Highly Generalizable and Interpretable Framework for Detecting Adversarial Examples Based on Image Features
- **标题**: FeatureLens：一种高度通用和可解释的框架，用于基于图像特征检测对抗性示例
- **链接**: https://arxiv.org/abs/2512.03625
> **作者**: Zhigang Yang,Yuan Liu,Jiawei Zhang,Puning Zhang,Xinqiang Ma
> **摘要**: 尽管深度神经网络（DNN）在图像分类方面表现出色，但它们面对对抗性攻击的脆弱性仍然是一个严峻的挑战。大多数现有的检测方法依赖于复杂且难以解释的架构，这损害了可解释性和泛化性。为了解决这个问题，我们提出了FeatureLens，这是一个轻量级框架，可以充当检查图像特征异常的镜头。 FeatureLens 由图像特征提取器 (IFE) 和浅层分类器（例如 SVM、MLP 或 XGBoost）组成，模型大小范围为 1,000 至 30,000 个参数，在闭集评估中实现了 97.8% 至 99.75% 的高检测精度，在 FGSM、PGD、CW 和DAmageNet 攻击，仅使用 51 维特征。通过将强大的检测性能与出色的泛化性、可解释性和计算效率相结合，FeatureLens 提供了一条实现透明、有效的对抗性防御的实用途径。
> **Abstract**: Although the remarkable performance of deep neural networks (DNNs) in image classification, their vulnerability to adversarial attacks remains a critical challenge. Most existing detection methods rely on complex and poorly interpretable architectures, which compromise interpretability and generalization. To address this, we propose FeatureLens, a lightweight framework that acts as a lens to scrutinize anomalies in image features. Comprising an Image Feature Extractor (IFE) and shallow classifiers (e.g., SVM, MLP, or XGBoost) with model sizes ranging from 1,000 to 30,000 parameters, FeatureLens achieves high detection accuracy ranging from 97.8% to 99.75% in closed-set evaluation and 86.17% to 99.6% in generalization evaluation across FGSM, PGD, CW, and DAmageNet attacks, using only 51 dimensional features. By combining strong detection performance with excellent generalization, interpretability, and computational efficiency, FeatureLens offers a practical pathway toward transparent and effective adversarial defense.

【88】ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation
- **标题**: ReCamDriving：无激光雷达相机控制的新型轨迹视频生成
- **链接**: https://arxiv.org/abs/2512.03621
> **作者**: Yaokun Li,Shuaixian Wang,Mantang Guo,Jiehui Huang,Taojun Ding,Mu Hu,Kaixuan Wang,Shaojie Shen,Guang Tan
> **摘要**: 我们提出了 ReCamDriving，一个纯粹基于视觉、摄像头控制的新颖轨迹视频生成框架。虽然基于修复的方法无法恢复复杂的伪影，而基于 LiDAR 的方法依赖于稀疏和不完整的线索，但 ReCamDriving 利用密集且场景完整的 3DGS 渲染来进行显式几何引导，从而实现精确的相机可控生成。为了减轻以 3DGS 渲染为条件时对恢复行为的过度拟合，ReCamDriving 采用两阶段训练范例：第一阶段使用相机姿势进行粗略控制，而第二阶段结合 3DGS 渲染进行细粒度视点和几何引导。此外，我们提出了一种基于 3DGS 的跨轨迹数据管理策略，以消除相机转换模式中的训练-测试间隙，从而实现单目视频的可扩展多轨迹监督。基于此策略，我们构建了 ParaDrive 数据集，其中包含超过 110K 平行轨迹视频对。大量实验表明，ReCamDriving 实现了最先进的相机可控性和结构一致性。
> **Abstract**: We propose ReCamDriving, a purely vision-based, camera-controlled novel-trajectory video generation framework. While repair-based methods fail to restore complex artifacts and LiDAR-based approaches rely on sparse and incomplete cues, ReCamDriving leverages dense and scene-complete 3DGS renderings for explicit geometric guidance, achieving precise camera-controllable generation. To mitigate overfitting to restoration behaviors when conditioned on 3DGS renderings, ReCamDriving adopts a two-stage training paradigm: the first stage uses camera poses for coarse control, while the second stage incorporates 3DGS renderings for fine-grained viewpoint and geometric guidance. Furthermore, we present a 3DGS-based cross-trajectory data curation strategy to eliminate the train-test gap in camera transformation patterns, enabling scalable multi-trajectory supervision from monocular videos. Based on this strategy, we construct the ParaDrive dataset, containing over 110K parallel-trajectory video pairs. Extensive experiments demonstrate that ReCamDriving achieves state-of-the-art camera controllability and structural consistency.

【89】LAMP: Language-Assisted Motion Planning for Controllable Video Generation
- **标题**: LAMP：用于可控视频生成的语言辅助运动规划
- **链接**: https://arxiv.org/abs/2512.03619
> **作者**: Muhammed Burak Kizil,Enes Sanli,Niloy J. Mitra,Erkut Erdem,Aykut Erdem,Duygu Ceylan
> **摘要**: 视频生成在视觉保真度和可控性方面取得了显着进步，能够对文本、布局或运动进行调节。其中，运动控制（指定对象动态和摄像机轨迹）对于构建复杂的电影场景至关重要，但现有的界面仍然有限。我们引入了 LAMP，它利用大型语言模型 (LLM) 作为运动规划器，将自然语言描述转换为动态对象和（相对定义的）相机的显式 3D 轨迹。受电影摄影惯例的启发，LAMP 定义了运动领域特定语言 (DSL)。通过利用法学硕士的程序合成功能，LAMP 从自然语言生成结构化运动程序，并确定性地映射到 3D 轨迹。我们构建了一个大规模程序数据集，将自然文本描述与相应的运动程序和 3D 轨迹配对。实验证明，与最先进的替代方案相比，LAMP 在运动可控性和与用户意图的一致性方面具有改进的性能，建立了第一个直接从自然语言规范生成对象和相机运动的框架。
> **Abstract**: Video generation has achieved remarkable progress in visual fidelity and controllability, enabling conditioning on text, layout, or motion. Among these, motion control - specifying object dynamics and camera trajectories - is essential for composing complex, cinematic scenes, yet existing interfaces remain limited. We introduce LAMP that leverages large language models (LLMs) as motion planners to translate natural language descriptions into explicit 3D trajectories for dynamic objects and (relatively defined) cameras. LAMP defines a motion domain-specific language (DSL), inspired by cinematography conventions. By harnessing program synthesis capabilities of LLMs, LAMP generates structured motion programs from natural language, which are deterministically mapped to 3D trajectories. We construct a large-scale procedural dataset pairing natural text descriptions with corresponding motion programs and 3D trajectories. Experiments demonstrate LAMP's improved performance in motion controllability and alignment with user intent compared to state-of-the-art alternatives establishing the first framework for generating both object and camera motions directly from natural language specifications.

【90】Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding
- **标题**: Motion4D：学习 3D 一致的运动和语义以实现 4D 场景理解
- **链接**: https://arxiv.org/abs/2512.03601
> **作者**: Haoran Zhou,Gim Hee Lee
> **摘要**: 2D 视觉基础模型的最新进展极大地改进了单目视频动态场景的分析。然而，尽管它们具有强大的泛化能力，但这些模型通常缺乏 3D 一致性（理解场景几何和运动的基本要求），从而导致复杂 3D 环境中严重的空间错位和时间闪烁。在本文中，我们提出了 Motion4D，这是一种新颖的框架，它通过将基础模型的 2D 先验集成到统一的 4D 高斯分布表示中来解决这些挑战。我们的方法具有由两部分组成的迭代优化框架：1）顺序优化，在连续阶段更新运动和语义场以保持局部一致性；2）全局优化，联合细化所有属性以实现长期一致性。为了提高运动精度，我们引入了动态调整运动先验的 3D 置信图，以及基于每像素 RGB 和语义错误将新高斯插入到代表性不足的区域的自适应重采样过程。此外，我们通过迭代细化过程增强语义连贯性，通过交替优化语义字段和更新 SAM2 提示来解决语义不一致问题。广泛的评估表明，我们的 Motion4D 在不同的场景理解任务中显着优于 2D 基础模型和现有的基于 3D 的方法，包括基于点的跟踪、视频对象分割和新颖的视图合成。我们的代码可在 https://hrzhou2.github.io/motion4d-web/ 获取。
> **Abstract**: Recent advancements in foundation models for 2D vision have substantially improved the analysis of dynamic scenes from monocular videos. However, despite their strong generalization capabilities, these models often lack 3D consistency, a fundamental requirement for understanding scene geometry and motion, thereby causing severe spatial misalignment and temporal flickering in complex 3D environments. In this paper, we present Motion4D, a novel framework that addresses these challenges by integrating 2D priors from foundation models into a unified 4D Gaussian Splatting representation. Our method features a two-part iterative optimization framework: 1) Sequential optimization, which updates motion and semantic fields in consecutive stages to maintain local consistency, and 2) Global optimization, which jointly refines all attributes for long-term coherence. To enhance motion accuracy, we introduce a 3D confidence map that dynamically adjusts the motion priors, and an adaptive resampling process that inserts new Gaussians into under-represented regions based on per-pixel RGB and semantic errors. Furthermore, we enhance semantic coherence through an iterative refinement process that resolves semantic inconsistencies by alternately optimizing the semantic fields and updating prompts of SAM2. Extensive evaluations demonstrate that our Motion4D significantly outperforms both 2D foundation models and existing 3D-based approaches across diverse scene understanding tasks, including point-based tracking, video object segmentation, and novel view synthesis. Our code is available at https://hrzhou2.github.io/motion4d-web/.

【91】Memory-Guided Point Cloud Completion for Dental Reconstruction
- **标题**: 用于牙齿重建的记忆引导点云完成
- **链接**: https://arxiv.org/abs/2512.03598
> **作者**: Jianan Sun,Yukang Huang,Dongzhihan Wang,Mingyu Fan
> **摘要**: 部分牙科点云通常会因遮挡和有限的扫描视图而遭受大面积缺失区域的影响，这会导致仅编码器的全局特征产生偏差，并迫使解码器产生幻觉结构。我们提出了一种用于牙齿补全的检索增强框架，它将原型存储器集成到标准编码器-解码器管道中。将部分输入编码为全局描述符后，模型从可学习存储器中检索最近的流形原型，并在解码前通过置信门控加权将其与查询特征融合。该存储器经过端到端优化，并自组织成可重复使用的齿形原型，无需牙齿位置标签，从而提供稳定缺失区域推理的结构先验，并释放解码器容量以进行细节恢复。该模块是即插即用的，与常见的完成主干兼容，同时保持相同的训练损失。在自行处理的 Teeth3DS 基准上进行的实验证明了倒角距离的持续改进，可视化显示更清晰的尖点、脊线和邻间过渡。我们的方法提供了一种简单而有效的方法来利用跨样本规律来实现更准确和忠实的牙科点云完成。
> **Abstract**: Partial dental point clouds often suffer from large missing regions caused by occlusion and limited scanning views, which bias encoder-only global features and force decoders to hallucinate structures. We propose a retrieval-augmented framework for tooth completion that integrates a prototype memory into standard encoder--decoder pipelines. After encoding a partial input into a global descriptor, the model retrieves the nearest manifold prototype from a learnable memory and fuses it with the query feature through confidence-gated weighting before decoding. The memory is optimized end-to-end and self-organizes into reusable tooth-shape prototypes without requiring tooth-position labels, thereby providing structural priors that stabilize missing-region inference and free decoder capacity for detail recovery. The module is plug-and-play and compatible with common completion backbones, while keeping the same training losses. Experiments on a self-processed Teeth3DS benchmark demonstrate consistent improvements in Chamfer Distance, with visualizations showing sharper cusps, ridges, and interproximal transitions. Our approach provides a simple yet effective way to exploit cross-sample regularities for more accurate and faithful dental point-cloud completion.

【92】HBFormer: A Hybrid-Bridge Transformer for Microtumor and Miniature Organ Segmentation
- **标题**: HBFormer：用于微肿瘤和微型器官分割的混合桥变压器
- **链接**: https://arxiv.org/abs/2512.03597
> **作者**: Fuchen Zheng,Xinyi Chen,Weixuan Li,Quanjun Li,Junhua Zhou,Xiaojiao Guo,Xuhang Chen,Chi-Man Pun,Shoujun Zhou
> **摘要**: 医学图像分割是现代临床诊断的基石。虽然利用基于窗口转移的自我注意力的视觉变形金刚在该领域建立了新的基准，但它们经常受到一个关键限制的阻碍：它们的局部注意力机制难以有效地将局部细节与全局背景融合起来。这种缺陷对于具有挑战性的任务尤其不利，例如微肿瘤和微型器官的分割，其中细粒度的边界定义和广泛的上下文理解都是至关重要的。为了解决这一差距，我们提出了 HBFormer，一种新颖的混合桥变压器架构。 HBFormer 的“混合”设计将经典的 U 形编码器-解码器框架与强大的 Swin Transformer 主干相结合，以实现稳健的分层特征提取。核心创新在于其“桥”机制，即多尺度特征集成的复杂联系。该桥在架构上由我们新颖的多尺度特征融合（MFF）解码器体现。与传统的对称设计不同，MFF 解码器旨在将编码器的多尺度特征与全局上下文信息融合。它通过通道和空间注意模块的协同组合来实现这一点，这些模块是由一系列扩张和深度卷积构建的。这些组件协同工作，创建了一个强大的功能桥，可以显式捕获远程依赖关系并以卓越的精度细化对象边界。在具有挑战性的医学图像分割数据集（包括多器官、肝脏肿瘤和膀胱肿瘤基准）上进行的综合实验表明，HBFormer 取得了最先进的结果，展示了其在微肿瘤和微型器官分割方面的出色能力。代码和模型可在以下网址获取：https://github.com/lzeeorno/HBFormer。
> **Abstract**: Medical image segmentation is a cornerstone of modern clinical diagnostics. While Vision Transformers that leverage shifted window-based self-attention have established new benchmarks in this field, they are often hampered by a critical limitation: their localized attention mechanism struggles to effectively fuse local details with global context. This deficiency is particularly detrimental to challenging tasks such as the segmentation of microtumors and miniature organs, where both fine-grained boundary definition and broad contextual understanding are paramount. To address this gap, we propose HBFormer, a novel Hybrid-Bridge Transformer architecture. The 'Hybrid' design of HBFormer synergizes a classic U-shaped encoder-decoder framework with a powerful Swin Transformer backbone for robust hierarchical feature extraction. The core innovation lies in its 'Bridge' mechanism, a sophisticated nexus for multi-scale feature integration. This bridge is architecturally embodied by our novel Multi-Scale Feature Fusion (MFF) decoder. Departing from conventional symmetric designs, the MFF decoder is engineered to fuse multi-scale features from the encoder with global contextual information. It achieves this through a synergistic combination of channel and spatial attention modules, which are constructed from a series of dilated and depth-wise convolutions. These components work in concert to create a powerful feature bridge that explicitly captures long-range dependencies and refines object boundaries with exceptional precision. Comprehensive experiments on challenging medical image segmentation datasets, including multi-organ, liver tumor, and bladder tumor benchmarks, demonstrate that HBFormer achieves state-of-the-art results, showcasing its outstanding capabilities in microtumor and miniature organ segmentation. Code and models are available at: https://github.com/lzeeorno/HBFormer.

【93】CloseUpAvatar: High-Fidelity Animatable Full-Body Avatars with Mixture of Multi-Scale Textures
- **标题**: CloseUpAvatar：混合多尺度纹理的高保真可动画全身头像
- **链接**: https://arxiv.org/abs/2512.03593
> **作者**: David Svitov,Pietro Morerio,Lourdes Agapito,Alessio Del Bue
> **摘要**: 我们提出了 CloseUpAvatar - 一种用于铰接式人类头像表示的新颖方法，可处理更一般的相机运动，同时保留特写视图的渲染质量。 CloseUpAvatar 将头像表示为一组纹理平面，具有两组可学习纹理，用于低频和高频细节。该方法仅针对靠近化身表面的相机自动切换到高频纹理，并随着相机移得更远而逐渐减少其影响。头像的这种参数化使 CloseUpAvatar 能够根据相机距离调整渲染质量，确保比以前的方法在更广泛的相机方向上进行真实渲染。我们使用 ActorsHQ 数据集和高分辨率输入图像提供实验。 CloseUpAvatar 展示了从新颖的宽范围相机位置进行渲染的现有方法的定性和定量改进，同时通过限制所需图元的数量来保持高 FPS。
> **Abstract**: We present a CloseUpAvatar - a novel approach for articulated human avatar representation dealing with more general camera motions, while preserving rendering quality for close-up views. CloseUpAvatar represents an avatar as a set of textured planes with two sets of learnable textures for low and high-frequency detail. The method automatically switches to high-frequency textures only for cameras positioned close to the avatar's surface and gradually reduces their impact as the camera moves farther away. Such parametrization of the avatar enables CloseUpAvatar to adjust rendering quality based on camera distance ensuring realistic rendering across a wider range of camera orientations than previous approaches. We provide experiments using the ActorsHQ dataset with high-resolution input images. CloseUpAvatar demonstrates both qualitative and quantitative improvements over existing methods in rendering from novel wide range camera positions, while maintaining high FPS by limiting the number of required primitives.

【94】Harnessing Hypergraphs in Geometric Deep Learning for 3D RNA Inverse Folding
- **标题**: 利用几何深度学习中的超图进行 3D RNA 反向折叠
- **链接**: https://arxiv.org/abs/2512.03592
> **作者**: Guang Yang,Lei Fan
> **摘要**: RNA反向折叠问题是RNA设计中的一个关键挑战，涉及识别可以折叠成所需二级结构的核苷酸序列，这对于确保分子稳定性和功能至关重要。这项任务固有的复杂性源于序列和结构之间错综复杂的关系，使其特别具有挑战性。在本文中，我们提出了一个名为 HyperRNA 的框架，这是一种具有编码器-解码器架构的生成模型，利用超图来设计 RNA 序列。具体来说，我们的 HyperRNA 模型由三个主要部分组成：预处理、编码和解码。在预处理阶段，通过基于3珠粗粒度表示提取RNA主链的原子坐标来构建图结构。编码阶段处理这些图，使用注意力嵌入模块和基于超图的编码器捕获更高阶的依赖性和复杂的生物分子相互作用。最后，解码阶段以自回归方式生成 RNA 序列。我们对 PDBBind 和 RNAsolo 数据集进行了定量和定性实验，以评估 RNA 序列生成和 RNA-蛋白质复合物序列生成的反向折叠任务。实验结果表明，HyperRNA 不仅优于现有的 RNA 设计方法，而且凸显了在 RNA 工程中利用超图的潜力。
> **Abstract**: The RNA inverse folding problem, a key challenge in RNA design, involves identifying nucleotide sequences that can fold into desired secondary structures, which are critical for ensuring molecular stability and function. The inherent complexity of this task stems from the intricate relationship between sequence and structure, making it particularly challenging. In this paper, we propose a framework, named HyperRNA, a generative model with an encoder-decoder architecture that leverages hypergraphs to design RNA sequences. Specifically, our HyperRNA model consists of three main components: preprocessing, encoding and decoding. In the preprocessing stage, graph structures are constructed by extracting the atom coordinates of RNA backbone based on 3-bead coarse-grained representation. The encoding stage processes these graphs, capturing higher order dependencies and complex biomolecular interactions using an attention embedding module and a hypergraph-based encoder. Finally, the decoding stage generates the RNA sequence in an autoregressive manner. We conducted quantitative and qualitative experiments on the PDBBind and RNAsolo datasets to evaluate the inverse folding task for RNA sequence generation and RNA-protein complex sequence generation. The experimental results demonstrate that HyperRNA not only outperforms existing RNA design methods but also highlights the potential of leveraging hypergraphs in RNA engineering.

【95】Beyond Boundary Frames: Audio-Visual Semantic Guidance for Context-Aware Video Interpolation
- **标题**: 超越边界框架：上下文感知视频插值的视听语义指导
- **链接**: https://arxiv.org/abs/2512.03590
> **作者**: Yuchen Deng,Xiuyang Wu,Hai-Tao Zheng,Jie Wang,Feidiao Yang,Yuxing Han
> **摘要**: 处理快速、复杂和高度非线性的运动模式长期以来一直给视频帧插值带来挑战。尽管最近的基于扩散的方法改进了传统的基于光流的方法，但它们仍然难以覆盖不同的应用场景，并且通常无法在细粒度运动任务（例如视听同步插值）中产生清晰的、时间一致的帧。为了解决这些限制，我们引入了 BBF（超越边界帧），这是一种上下文感知视频帧插值框架，可以通过音频/视觉语义来指导。首先，我们增强了插值模型的输入设计，使其能够灵活处理多种条件模态，包括文本、音频、图像和视频。其次，我们提出了一种解耦的多模态融合机制，该机制将不同的条件信号顺序注入 DiT 主干。最后，为了保持基础模型的生成能力，我们采用渐进式多阶段训练范例，其中使用起始端帧差异嵌入来动态调整数据采样和损失权重。大量的实验结果表明，BBF 在通用插值和视听同步插值任务上都优于专门的最先进方法，为协调多通道条件下的视频帧插值建立了统一的框架。
> **Abstract**: Handling fast, complex, and highly non-linear motion patterns has long posed challenges for video frame interpolation. Although recent diffusion-based approaches improve upon traditional optical-flow-based methods, they still struggle to cover diverse application scenarios and often fail to produce sharp, temporally consistent frames in fine-grained motion tasks such as audio-visual synchronized interpolation. To address these limitations, we introduce BBF (Beyond Boundary Frames), a context-aware video frame interpolation framework, which could be guided by audio/visual semantics. First, we enhance the input design of the interpolation model so that it can flexibly handle multiple conditional modalities, including text, audio, images, and video. Second, we propose a decoupled multimodal fusion mechanism that sequentially injects different conditional signals into a DiT backbone. Finally, to maintain the generation abilities of the foundation model, we adopt a progressive multi-stage training paradigm, where the start-end frame difference embedding is used to dynamically adjust both the data sampling and the loss weighting. Extensive experimental results demonstrate that BBF outperforms specialized state-of-the-art methods on both generic interpolation and audio-visual synchronized interpolation tasks, establishing a unified framework for video frame interpolation under coordinated multi-channel conditioning.

【96】Dynamic Optical Test for Bot Identification (DOT-BI): A simple check to identify bots in surveys and online processes
- **标题**: 机器人识别动态光学测试 (DOT-BI)：在调查和在线流程中识别机器人的简单检查
- **链接**: https://arxiv.org/abs/2512.03580
> **作者**: Malte Bleeker,Mauro Gotsch
> **摘要**: 我们提出了用于机器人识别的动态光学测试（DOT-BI）：一种快速而简单的方法，利用人类对运动的感知来区分调查和在线流程中的人类受访者和自动化系统。在 DOT-BI 中，“隐藏”数字以与背景相同的随机黑白像素纹理显示。只有数字和背景之间的运动和比例差异才能使人类跨帧感知数字，而逐帧算法处理不会产生任何有意义的信号。我们进行了两次初步评估。首先，最先进的、支持视频的多模态模型（GPT-5-Thinking 和 Gemini 2.5 Pro）无法提取正确的值，即使给出了有关该机制的明确说明。其次，在在线调查（n=182）中，99.5%（181/182）的参与者解决了任务，平均端到端完成时间为10.7秒；一项受监督的实验室研究 (n=39) 发现，相对于对照，对感知易用性或完成时间没有负面影响。我们发布代码来生成测试和 100 多个预渲染变体，以促进调查和在线流程中的采用。
> **Abstract**: We propose the Dynamic Optical Test for Bot Identification (DOT-BI): a quick and easy method that uses human perception of motion to differentiate between human respondents and automated systems in surveys and online processes. In DOT-BI, a 'hidden' number is displayed with the same random black-and-white pixel texture as its background. Only the difference in motion and scale between the number and the background makes the number perceptible to humans across frames, while frame-by-frame algorithmic processing yields no meaningful signal. We conducted two preliminary assessments. Firstly, state-of-the-art, video-capable, multimodal models (GPT-5-Thinking and Gemini 2.5 Pro) fail to extract the correct value, even when given explicit instructions about the mechanism. Secondly, in an online survey (n=182), 99.5% (181/182) of participants solved the task, with an average end-to-end completion time of 10.7 seconds; a supervised lab study (n=39) found no negative effects on perceived ease-of-use or completion time relative to a control. We release code to generate tests and 100+ pre-rendered variants to facilitate adoption in surveys and online processes.

【97】Cross-Stain Contrastive Learning for Paired Immunohistochemistry and Histopathology Slide Representation Learning
- **标题**: 用于配对免疫组织化学和组织病理学幻灯片表示学习的交叉染色对比学习
- **链接**: https://arxiv.org/abs/2512.03577
> **作者**: Yizhi Zhang,Lei Fan,Zhulin Tao,Donglin Di,Yang Song,Sidong Liu,Cong Cong
> **摘要**: 通用、可转移的全切片图像（WSI）表示是计算病理学的核心。将多种标记物（例如免疫组织化学、IHC）与 H&E 结合使用，可以丰富基于 H&E 的特征以及多样化的、具有生物学意义的信息。然而，由于缺乏一致的多染色数据集，进展受到限制。染色间未对准会使相应的组织在载玻片上移动，阻碍一致的斑块级特征并降低载玻片级嵌入的质量。为了解决这个问题，我们策划了一个幻灯片级对齐的五染色数据集（H&E、HER2、KI67、ER、PGR），以实现配对 H&E-IHC 学习和强大的交叉染色表示。利用该数据集，我们提出了跨染色对比学习（CSCL），这是一种两阶段预训练框架，具有使用补丁对比对齐进行训练的轻量级适配器，以提高 H＆E 特征与相应的 IHC 衍生上下文线索的兼容性，以及使用多实例学习（MIL）的幻灯片级表示学习，它使用交叉染色注意融合模块来集成特定于染色的补丁特征和跨染色全局对齐模块，以强制跨区域的幻灯片级嵌入之间的一致性不同的污渍。癌症亚型分类、IHC 生物标志物状态分类和生存预测的实验显示出一致的收益，产生了高质量、可转移的 H&E 幻灯片级表示。代码和数据可在 https://github.com/lily-zyz/CSCL 获取。
> **Abstract**: Universal, transferable whole-slide image (WSI) representations are central to computational pathology. Incorporating multiple markers (e.g., immunohistochemistry, IHC) alongside H&E enriches H&E-based features with diverse, biologically meaningful information. However, progress is limited by the scarcity of well-aligned multi-stain datasets. Inter-stain misalignment shifts corresponding tissue across slides, hindering consistent patch-level features and degrading slide-level embeddings. To address this, we curated a slide-level aligned, five-stain dataset (H&E, HER2, KI67, ER, PGR) to enable paired H&E-IHC learning and robust cross-stain representation. Leveraging this dataset, we propose Cross-Stain Contrastive Learning (CSCL), a two-stage pretraining framework with a lightweight adapter trained using patch-wise contrastive alignment to improve the compatibility of H&E features with corresponding IHC-derived contextual cues, and slide-level representation learning with Multiple Instance Learning (MIL), which uses a cross-stain attention fusion module to integrate stain-specific patch features and a cross-stain global alignment module to enforce consistency among slide-level embeddings across different stains. Experiments on cancer subtype classification, IHC biomarker status classification, and survival prediction show consistent gains, yielding high-quality, transferable H&E slide-level representations. The code and data are available at https://github.com/lily-zyz/CSCL.

【98】UniComp: Rethinking Video Compression Through Informational Uniqueness
- **标题**: UniComp：通过信息唯一性重新思考视频压缩
- **链接**: https://arxiv.org/abs/2512.03575
> **作者**: Chao Yuan,Shimin Chen,Minliang Lin,Limeng Qiao,Guanglu Wan,Lin Ma
> **摘要**: 与基于注意力的压缩方法不同，本文提出了一种信息唯一性驱动的视频压缩框架，称为 UniComp，其目的是在有限的计算预算下最大化视频表示的信息保真度。从信息论的角度出发，我们将视觉压缩表述为一个优化问题，最小化保留令牌和完整令牌之间的条件熵（重构误差）。为了实现这一目标，我们引入信息唯一性的概念来测量标记之间的内在冗余，以与重建误差联系起来。基于独特性，我们设计了三个模块——帧组融合、令牌分配和空间动态压缩——逐步执行语义帧分组、自适应资源分配和细粒度空间压缩。大量实验表明，UniComp 在有限计算预算下保留基本视觉标记方面始终优于现有压缩方法，凸显了信息唯一性在标记压缩功效中的关键作用。
> **Abstract**: Distinct from attention-based compression methods, this paper presents an information uniqueness driven video compression framework, termed UniComp, which aims to maximize the information fidelity of video representations under constrained computational budgets. Starting from the information-theoretic perspective, we formulate the vision compression as an optimization problem that minimizes conditional entropy (reconstruction error) between retained and full tokens. To achieve this, we introduce the notion of information uniqueness to measure intrinsic redundancy among tokens to link with reconstruction error. Based on uniqueness, we design three modules-Frame Group Fusion, Token Allocation, and Spatial Dynamic Compression-that progressively perform semantic frame grouping, adaptive resource allocation, and fine-grained spatial compression. Extensive experiments demonstrate that UniComp consistently outperforms existing compression methods in preserving essential visual tokens under limited computational budgets, highlighting the pivotal role of information uniqueness in token compression efficacy.

【99】Global-Local Aware Scene Text Editing
- **标题**: 全局局部感知场景文本编辑
- **链接**: https://arxiv.org/abs/2512.03574
> **作者**: Fuxiang Yang,Tonghua Su,Donglin Di,Yin Chen,Xiangqian Wu,Zhongjie Wang,Lei Fan
> **摘要**: 场景文本编辑 (STE) 涉及用新的目标文本替换场景图像中的文本，同时保留原始文本样式和背景纹理。现有方法面临两个主要挑战：不一致和长度不敏感。他们通常无法保持编辑的本地补丁与周围区域之间的一致性，并且难以处理编辑前后文本长度的显着差异。为了应对这些挑战，我们提出了一种称为全局本地感知场景文本编辑（GLASTE）的端到端框架，它同时结合了高级全局上下文信息和微妙的本地特征。具体来说，我们设计了一种全局-局部组合结构，联合全局和局部损失，并增强文本图像特征，以确保局部补丁内文本样式的一致性，同时保持局部和全局区域之间的和谐。此外，我们将文本样式表示为与图像大小无关的向量，可以将其转移到各种大小的目标文本图像。我们使用仿射融合将目标文本图像填充到编辑补丁中，同时保持其纵横比不变。对真实世界数据集的大量实验验证了我们的 GLASTE 模型在定量指标和定性结果方面均优于以前的方法，并有效缓解了这两个挑战。
> **Abstract**: Scene Text Editing (STE) involves replacing text in a scene image with new target text while preserving both the original text style and background texture. Existing methods suffer from two major challenges: inconsistency and length-insensitivity. They often fail to maintain coherence between the edited local patch and the surrounding area, and they struggle to handle significant differences in text length before and after editing. To tackle these challenges, we propose an end-to-end framework called Global-Local Aware Scene Text Editing (GLASTE), which simultaneously incorporates high-level global contextual information along with delicate local features. Specifically, we design a global-local combination structure, joint global and local losses, and enhance text image features to ensure consistency in text style within local patches while maintaining harmony between local and global areas. Additionally, we express the text style as a vector independent of the image size, which can be transferred to target text images of various sizes. We use an affine fusion to fill target text images into the editing patch while maintaining their aspect ratio unchanged. Extensive experiments on real-world datasets validate that our GLASTE model outperforms previous methods in both quantitative metrics and qualitative results and effectively mitigates the two challenges.

【100】GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models
- **标题**: GAOT：通过文本引导扩散模型生成铰接对象
- **链接**: https://arxiv.org/abs/2512.03566
> **作者**: Hao Sun,Lei Fan,Donglin Di,Shaohui Liu
> **摘要**: 铰接对象生成已经取得了越来越大的进步，但现有模型通常缺乏以文本提示为条件的能力。为了解决文本描述和 3D 铰接对象表示之间的巨大差距，我们提出了 GAOT，这是一个三阶段框架，可以从文本提示生成铰接对象，在三步过程中利用扩散模型和超图学习。首先，我们微调点云生成模型，以根据文本提示生成对象的粗略表示。考虑到铰接对象和图结构之间的内在联系，我们设计了一种基于超图的学习方法来细化这些粗略表示，将对象部分表示为图顶点。最后，利用扩散模型，根据对象部分生成铰接对象的关节（表示为图形边缘）。对 PartNet-Mobility 数据集进行的广泛定性和定量实验证明了我们方法的有效性，实现了优于以前方法的性能。
> **Abstract**: Articulated object generation has seen increasing advancements, yet existing models often lack the ability to be conditioned on text prompts. To address the significant gap between textual descriptions and 3D articulated object representations, we propose GAOT, a three-phase framework that generates articulated objects from text prompts, leveraging diffusion models and hypergraph learning in a three-step process. First, we fine-tune a point cloud generation model to produce a coarse representation of objects from text prompts. Given the inherent connection between articulated objects and graph structures, we design a hypergraph-based learning method to refine these coarse representations, representing object parts as graph vertices. Finally, leveraging a diffusion model, the joints of articulated objects-represented as graph edges-are generated based on the object parts. Extensive qualitative and quantitative experiments on the PartNet-Mobility dataset demonstrate the effectiveness of our approach, achieving superior performance over previous methods.

【101】CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding
- **标题**: CartoMapQA：评估制图地图理解视觉语言模型的基本基准数据集
- **链接**: https://arxiv.org/abs/2512.03558
> **作者**: Huy Quang Ung,Guillaume Habault,Yasutaka Nishimura,Hao Niu,Roberto Legaspi,Tomoki Oya,Ryoichi Kojima,Masato Taya,Chihiro Ono,Atsunori Minamikawa,Yan Liu
> **摘要**: 视觉语言模型 (LVLM) 的兴起为无缝集成视觉和文本信息带来了新的可能性。然而，他们解释地图的能力在很大程度上仍未得到探索。在本文中，我们介绍了 CartoMapQA，这是一个专门设计用于通过问答任务评估 LVLM 对制图地图的理解的基准。该数据集包含 2000 多个样本，每个样本由一张地图、一个问题（带有开放式或多选答案）和一个真实答案组成。这些任务涵盖关键的低、中、高级地图解释技能，包括符号识别、嵌入式信息提取、比例尺解释和基于路线的推理。我们对开源和专有 LVLM 的评估揭示了持续存在的挑战：模型经常与特定于地图的语义作斗争，表现出有限的地理空间推理，并且容易出现与光学字符识别 (OCR) 相关的错误。通过隔离这些弱点，CartoMapQA 提供了一个有价值的工具来指导 LVLM 架构的未来改进。最终，它支持开发更适合现实世界应用的模型，这些应用依赖于强大而可靠的地图理解，例如导航、地理搜索和城市规划。我们的源代码和数据向研究社区开放：https://github.com/ungquanghuy-kddi/CartoMapQA.git
> **Abstract**: The rise of Visual-Language Models (LVLMs) has unlocked new possibilities for seamlessly integrating visual and textual information. However, their ability to interpret cartographic maps remains largely unexplored. In this paper, we introduce CartoMapQA, a benchmark specifically designed to evaluate LVLMs' understanding of cartographic maps through question-answering tasks. The dataset includes over 2000 samples, each composed of a cartographic map, a question (with open-ended or multiple-choice answers), and a ground-truth answer. These tasks span key low-, mid- and high-level map interpretation skills, including symbol recognition, embedded information extraction, scale interpretation, and route-based reasoning. Our evaluation of both open-source and proprietary LVLMs reveals persistent challenges: models frequently struggle with map-specific semantics, exhibit limited geospatial reasoning, and are prone to Optical Character Recognition (OCR)-related errors. By isolating these weaknesses, CartoMapQA offers a valuable tool for guiding future improvements in LVLM architectures. Ultimately, it supports the development of models better equipped for real-world applications that depend on robust and reliable map understanding, such as navigation, geographic search, and urban planning. Our source code and data are openly available to the research community at: https://github.com/ungquanghuy-kddi/CartoMapQA.git

【102】Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching
- **标题**: 直播中的动态内容审核：将监督分类与 MLLM 增强的相似性匹配相结合
- **链接**: https://arxiv.org/abs/2512.03553
> **作者**: Wei Chee Yew,Hailun Xu,Sanjay Saha,Xiaotian Fan,Hiok Hian Ong,David Yuchen Wang,Kanchan Sarkar,Zhenheng Yang,Danhui Guan
> **摘要**: 对于大型用户生成的视频平台来说，内容审核仍然是一项关键但具有挑战性的任务，特别是在直播环境中，审核必须及时、多模式且对不断变化的不需要的内容形式具有鲁棒性。我们提出了一种在生产规模上部署的混合审核框架，它将已知违规行为的监督分类与新颖或微妙案例的基于参考的相似性匹配相结合。这种混合设计能够对显式违规和避开传统分类器的新颖边缘情况进行稳健检测。多模态输入（文本、音频、视觉）通过两个管道进行处理，多模态大语言模型 (MLLM) 将知识提炼到每个管道中，以提高准确性，同时保持推理的轻量级。在生产中，分类管道在 80% 的精度下实现了 67% 的召回率，而相似性管道在 80% 的精度下实现了 76% 的召回率。大规模 A/B 测试显示，不需要的直播的用户观看次数减少了 6-8%}。这些结果展示了一种可扩展且适应性强的多模式内容治理方法，能够解决明显的违规行为和新出现的对抗行为。
> **Abstract**: Content moderation remains a critical yet challenging task for large-scale user-generated video platforms, especially in livestreaming environments where moderation must be timely, multimodal, and robust to evolving forms of unwanted content. We present a hybrid moderation framework deployed at production scale that combines supervised classification for known violations with reference-based similarity matching for novel or subtle cases. This hybrid design enables robust detection of both explicit violations and novel edge cases that evade traditional classifiers. Multimodal inputs (text, audio, visual) are processed through both pipelines, with a multimodal large language model (MLLM) distilling knowledge into each to boost accuracy while keeping inference lightweight. In production, the classification pipeline achieves 67% recall at 80% precision, and the similarity pipeline achieves 76% recall at 80% precision. Large-scale A/B tests show a 6-8% reduction in user views of unwanted livestreams}. These results demonstrate a scalable and adaptable approach to multimodal content governance, capable of addressing both explicit violations and emerging adversarial behaviors.

【103】V-ITI: Mitigating Hallucinations in Multimodal Large Language Models via Visual Inference-Time Intervention
- **标题**: V-ITI：通过视觉推理时间干预减轻多模态大语言模型中的幻觉
- **链接**: https://arxiv.org/abs/2512.03542
> **作者**: Nan Sun,Zhenyu Zhang,Xixun Lin,Kun Wang,Yanmin Shang,Naibin Gu,Shuohuan Wang,Yu Sun,Hua Wu,Haifeng Wang,Yanan Cao
> **摘要**: 多模态大语言模型 (MLLM) 在许多视觉语言任务中表现出色，但会产生幻觉，产生与输入视觉效果不一致的内容，从而破坏了精度敏感领域的可靠性。这个问题源于视觉忽视的基本问题，即模型无法充分优先考虑输入图像。现有的方法通常通过干预注意力分数或输出逻辑来缓解幻觉，关注“如何干预”而忽视“何时干预”的先决条件，这导致“过度干预”问题，并随后引入新的幻​​觉和不必要的计算开销。为了解决这一差距，我们首先研究了视觉忽视的机制，并揭示了可以通过 MLLM 中的头部激活模式准确地检测到它。因此，我们提出了 V-ITI，一种轻量级的视觉推理时间干预框架，集成了视觉忽视检测器和视觉回忆干预器，视觉忽视检测器通过头部判别探针识别视觉忽视，而视觉回忆干预器仅在检测到视觉忽视时使用预存储的视觉激活信息来调节激活。跨八个基准和不同 MLLM 系列的广泛实验表明，V-ITI 始终如一地减轻与视觉相关的幻觉，同时保持一般任务性能。
> **Abstract**: Multimodal Large Language Models (MLLMs) excel in numerous vision-language tasks yet suffer from hallucinations, producing content inconsistent with input visuals, that undermine reliability in precision-sensitive domains. This issue stems from a fundamental problem of visual neglect, where models fail to adequately prioritize input images. Existing methods typically alleviate hallucinations by intervening in the attention score or output logits, focusing on "how to intervene" but overlooking the prerequisite "when to intervene", which leads to the "over-intervention" problem and subsequently introduces new hallucinations and unnecessary computational overhead. To address this gap, we first investigate the mechanism of visual neglect and reveal it can be accurately detected via head-level activation patterns in MLLMs. We thus propose V-ITI, a lightweight visual inference-time intervention framework integrating a Visual Neglect Detector that identifies visual neglect via head-level discriminative probes and a Visual Recall Intervenor that modulates activations with prestored visual activation information only when the visual neglect is detected. Extensive experiments across eight benchmarks and different MLLM families demonstrate that V-ITI consistently mitigates vision-related hallucinations while preserving general task performance.

【104】CookAnything: A Framework for Flexible and Consistent Multi-Step Recipe Image Generation
- **标题**: CookAnything：灵活一致的多步骤菜谱图像生成框架
- **链接**: https://arxiv.org/abs/2512.03540
> **作者**: Ruoxuan Zhang,Bin Wen,Hongxia Xie,Yi Yao,Songhan Zuo,Jian-Yu Jiang-Lin,Hong-Han Shuai,Wen-Huang Cheng
> **摘要**: 烹饪是一种连续且以视觉为基础的活动，切碎、混合或煎炸等每个步骤都带有程序逻辑和视觉语义。虽然最近的扩散模型在文本到图像生成方面表现出了强大的能力，但它们很难处理结构化的多步骤场景，例如食谱插图。此外，当前的菜谱插图方法无法适应菜谱长度的自然变化，无论实际的指令结构如何，都无法生成固定数量的图像。为了解决这些限制，我们提出了 CookAnything，这是一种灵活且一致的基于扩散的框架，可以从任意长度的文本烹饪指令生成连贯的、语义上不同的图像序列。该框架引入了三个关键组件：（1）逐步区域控制（SRC），它将文本步骤与单个去噪过程中的相应图像区域对齐； (2)灵活的RoPE，一种步进感知位置编码机制，可增强时间相干性和空间多样性； (3) 跨步骤一致性控制 (CSCC)，保持跨步骤的细粒度成分一致性。食谱插图基准的实验结果表明，CookAnything 在基于训练和无训练的设置中比现有方法表现更好。所提出的框架支持复杂多步骤指令的可扩展、高质量视觉合成，并在教学媒体和程序内容创建方面具有广泛应用的巨大潜力。
> **Abstract**: Cooking is a sequential and visually grounded activity, where each step such as chopping, mixing, or frying carries both procedural logic and visual semantics. While recent diffusion models have shown strong capabilities in text-to-image generation, they struggle to handle structured multi-step scenarios like recipe illustration. Additionally, current recipe illustration methods are unable to adjust to the natural variability in recipe length, generating a fixed number of images regardless of the actual instructions structure. To address these limitations, we present CookAnything, a flexible and consistent diffusion-based framework that generates coherent, semantically distinct image sequences from textual cooking instructions of arbitrary length. The framework introduces three key components: (1) Step-wise Regional Control (SRC), which aligns textual steps with corresponding image regions within a single denoising process; (2) Flexible RoPE, a step-aware positional encoding mechanism that enhances both temporal coherence and spatial diversity; and (3) Cross-Step Consistency Control (CSCC), which maintains fine-grained ingredient consistency across steps. Experimental results on recipe illustration benchmarks show that CookAnything performs better than existing methods in training-based and training-free settings. The proposed framework supports scalable, high-quality visual synthesis of complex multi-step instructions and holds significant potential for broad applications in instructional media, and procedural content creation.

【105】Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation
- **标题**: 重新思考文本到视觉生成中推理时间缩放的提示设计
- **链接**: https://arxiv.org/abs/2512.03534
> **作者**: Subin Kim,Sangwoo Mo,Mamshad Nayeem Rizve,Yiran Xu,Difan Liu,Jinwoo Shin,Tobias Hinz
> **摘要**: 在文本到视觉生成中实现用户意图和生成的视觉效果之间的精确对齐仍然是一个核心挑战，因为单次尝试通常无法产生所需的输出。为了解决这个问题，先前的方法主要是扩展视觉生成过程（例如，增加采样步骤或种子），但这很快就会导致质量停滞不前。出现这种限制是因为对于指导生成至关重要的提示是固定的。为了解决这个问题，我们提出了推理时间缩放的提示重新设计（Prompt Redesign for Inference-time Scaling），创造了 PRIS，这是一个框架，可以在推理过程中自适应地修改提示，以响应缩放的视觉生成。 PRIS 的核心思想是审查生成的视觉效果，识别视觉效果中重复出现的故障模式，并相应地重新设计提示，然后使用修改后的提示重新生成视觉效果。为了为及时修订提供精确的对齐反馈，我们引入了一种新的验证器，即元素级事实校正，它可以在细粒度级别评估提示属性和生成的视觉效果之间的对齐情况，从而实现比整体测量更准确和可解释的评估。对文本到图像和文本到视频基准的大量实验证明了我们方法的有效性，包括在 VBench 2.0 上提高了 15%。这些结果强调，联合缩放提示和视觉效果是在推理时充分利用缩放定律的关键。可视化可在网站上获得：https://subin-kim-cv.github.io/PRIS。
> **Abstract**: Achieving precise alignment between user intent and generated visuals remains a central challenge in text-to-visual generation, as a single attempt often fails to produce the desired output. To handle this, prior approaches mainly scale the visual generation process (e.g., increasing sampling steps or seeds), but this quickly leads to a quality plateau. This limitation arises because the prompt, crucial for guiding generation, is kept fixed. To address this, we propose Prompt Redesign for Inference-time Scaling, coined PRIS, a framework that adaptively revises the prompt during inference in response to the scaled visual generations. The core idea of PRIS is to review the generated visuals, identify recurring failure patterns across visuals, and redesign the prompt accordingly before regenerating the visuals with the revised prompt. To provide precise alignment feedback for prompt revision, we introduce a new verifier, element-level factual correction, which evaluates the alignment between prompt attributes and generated visuals at a fine-grained level, achieving more accurate and interpretable assessments than holistic measures. Extensive experiments on both text-to-image and text-to-video benchmarks demonstrate the effectiveness of our approach, including a 15% gain on VBench 2.0. These results highlight that jointly scaling prompts and visuals is key to fully leveraging scaling laws at inference-time. Visualizations are available at the website: https://subin-kim-cv.github.io/PRIS.

【106】OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation
- **标题**: OpenTrack3D：迈向准确且可推广的开放词汇 3D 实例分割
- **链接**: https://arxiv.org/abs/2512.03532
> **作者**: Zhishan Zhou,Siyuan Wei,Zengran Wang,Chunjie Wang,Xiaosheng Yan,Xiao Liu
> **摘要**: 将开放词汇 3D 实例分割 (OV-3DIS) 推广到多样化、非结构化和无网格环境对于机器人技术和 AR/VR 至关重要，但仍然是一个重大挑战。我们将此归因于现有方法的两个关键限制：（1）提案生成依赖于特定于数据集的提案网络或基于网格的超级点，使得它们不适用于无网格场景，并限制了对新场景的泛化； (2) 基于 CLIP 的分类器的文本推理能力较弱，难以识别组合和功能用户查询。为了解决这些问题，我们引入了 OpenTrack3D，一个通用且准确的框架。与依赖预生成提案的方法不同，OpenTrack3D 采用新颖的视觉空间跟踪器在线构建跨视图一致的对象提案。给定 RGB-D 流，我们的管道首先利用 2D 开放词汇分段器来生成掩模，然后使用深度将其提升为 3D 点云。然后使用 DINO 特征图提取掩模引导的实例特征，并且我们的跟踪器融合视觉和空间线索以保持实例一致性。核心管道完全无网格，但我们还提供可选的超级点细化模块，以在场景网格可用时进一步增强性能。最后，我们用多模态大语言模型（MLLM）取代 CLIP，显着增强了复杂用户查询的组合推理。对包括 ScanNet200、Replica、ScanNet++ 和 SceneFun3D 在内的各种基准进行的大量实验证明了最先进的性能和强大的泛化能力。
> **Abstract**: Generalizing open-vocabulary 3D instance segmentation (OV-3DIS) to diverse, unstructured, and mesh-free environments is crucial for robotics and AR/VR, yet remains a significant challenge. We attribute this to two key limitations of existing methods: (1) proposal generation relies on dataset-specific proposal networks or mesh-based superpoints, rendering them inapplicable in mesh-free scenarios and limiting generalization to novel scenes; and (2) the weak textual reasoning of CLIP-based classifiers, which struggle to recognize compositional and functional user queries. To address these issues, we introduce OpenTrack3D, a generalizable and accurate framework. Unlike methods that rely on pre-generated proposals, OpenTrack3D employs a novel visual-spatial tracker to construct cross-view consistent object proposals online. Given an RGB-D stream, our pipeline first leverages a 2D open-vocabulary segmenter to generate masks, which are lifted to 3D point clouds using depth. Mask-guided instance features are then extracted using DINO feature maps, and our tracker fuses visual and spatial cues to maintain instance consistency. The core pipeline is entirely mesh-free, yet we also provide an optional superpoints refinement module to further enhance performance when scene mesh is available. Finally, we replace CLIP with a multi-modal large language model (MLLM), significantly enhancing compositional reasoning for complex user queries. Extensive experiments on diverse benchmarks, including ScanNet200, Replica, ScanNet++, and SceneFun3D, demonstrate state-of-the-art performance and strong generalization capabilities.

【107】FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation
- **标题**: FloodDiffusion：用于流运动生成的定制扩散强迫
- **链接**: https://arxiv.org/abs/2512.03520
> **作者**: Yiyi Cai,Yuhan Wu,Kunhang Li,You Zhou,Bo Zheng,Haiyang Liu
> **摘要**: 我们推出了 FloodDiffusion，这是一个用于文本驱动的流式人体运动生成的新框架。给定随时间变化的文本提示，FloodDiffusion 会生成具有实时延迟的文本对齐、无缝运动序列。与依赖于逐块或具有扩散头的自回归模型的现有方法不同，我们采用扩散强迫框架来对时变控制事件下的时间序列生成任务进行建模。我们发现，普通扩散强迫的直接实现（如针对视频模型所建议的）无法对真实运动分布进行建模。我们证明，为了保证对输出分布进行建模，必须调整普通扩散强迫以：（i）使用双向注意力而不是随意注意力进行训练； (ii) 实施下三角时间调度器而不是随机调度器； (iii)利用连续时变的方式引入文本调节。通过这些改进，我们首次证明基于扩散力的框架在流运动生成任务上实现了最先进的性能，在 HumanML3D 基准上达到了 0.057 的 FID。提供型号、代码和重量。 https://shandaai.github.io/FloodDiffusion/
> **Abstract**: We present FloodDiffusion, a new framework for text-driven, streaming human motion generation. Given time-varying text prompts, FloodDiffusion generates text-aligned, seamless motion sequences with real-time latency. Unlike existing methods that rely on chunk-by-chunk or auto-regressive model with diffusion head, we adopt a diffusion forcing framework to model this time-series generation task under time-varying control events. We find that a straightforward implementation of vanilla diffusion forcing (as proposed for video models) fails to model real motion distributions. We demonstrate that to guarantee modeling the output distribution, the vanilla diffusion forcing must be tailored to: (i) train with a bi-directional attention instead of casual attention; (ii) implement a lower triangular time scheduler instead of a random one; (iii) utilize a continues time-varying way to introduce text conditioning. With these improvements, we demonstrate in the first time that the diffusion forcing-based framework achieves state-of-the-art performance on the streaming motion generation task, reaching an FID of 0.057 on the HumanML3D benchmark. Models, code, and weights are available. https://shandaai.github.io/FloodDiffusion/

【108】CSMapping: Scalable Crowdsourced Semantic Mapping and Topology Inference for Autonomous Driving
- **标题**: CSMapping：自动驾驶的可扩展众包语义映射和拓扑推理
- **链接**: https://arxiv.org/abs/2512.03510
> **作者**: Zhijian Qiao,Zehuan Yu,Tong Li,Chih-Chung Chou,Wenchao Ding,Shaojie Shen
> **摘要**: 众包可以实现可扩展的自动驾驶地图构建，但低成本传感器噪声阻碍了质量随数据量的提高。我们提出了 CSMapping，这是一个能够生成准确的语义地图和拓扑道路中心线的系统，其质量随着更多的众包数据而不断提高。对于语义映射，我们在高清地图（可选地以标清地图为条件）上训练潜在扩散模型，以学习现实世界地图结构的生成先验，而不需要配对的众包/高清地图监督。该先验通过潜在空间中的约束 MAP 优化来合并，确保对严重噪声的鲁棒性和未观察区域的合理完成。初始化使用稳健的矢量化映射模块，然后进行扩散反演；优化采用高效的高斯基重新参数化、投影梯度下降 zobracket 多起点和潜在空间因子图来实现全局一致性。对于拓扑映射，我们将置信加权 k 中心点聚类和运动学细化应用于轨迹，产生平滑的、类似人类的中心线，对轨迹变化具有鲁棒性。 nuScenes、Argoverse 2 和大型专有数据集上的实验通过彻底的消融和可扩展性研究实现了最先进的语义和拓扑映射性能。
> **Abstract**: Crowdsourcing enables scalable autonomous driving map construction, but low-cost sensor noise hinders quality from improving with data volume. We propose CSMapping, a system that produces accurate semantic maps and topological road centerlines whose quality consistently increases with more crowdsourced data. For semantic mapping, we train a latent diffusion model on HD maps (optionally conditioned on SD maps) to learn a generative prior of real-world map structure, without requiring paired crowdsourced/HD-map supervision. This prior is incorporated via constrained MAP optimization in latent space, ensuring robustness to severe noise and plausible completion in unobserved areas. Initialization uses a robust vectorized mapping module followed by diffusion inversion; optimization employs efficient Gaussian-basis reparameterization, projected gradient descent zobracket multi-start, and latent-space factor-graph for global consistency. For topological mapping, we apply confidence-weighted k-medoids clustering and kinematic refinement to trajectories, yielding smooth, human-like centerlines robust to trajectory variation. Experiments on nuScenes, Argoverse 2, and a large proprietary dataset achieve state-of-the-art semantic and topological mapping performance, with thorough ablation and scalability studies.

【109】AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model
- **标题**: 使用计算机视觉进行 AfroBeats 舞蹈动作分析：结合 YOLO 和 Segment Anything 模型的概念验证框架
- **链接**: https://arxiv.org/abs/2512.03509
> **作者**: Kwaku Opoku-Ware,Gideon Opoku
> **摘要**: 本文对使用当代计算机视觉技术的自动化舞蹈动作分析进行了初步研究。我们提出了一个概念验证框架，它将用于舞者检测的 YOLOv8 和 v11 与用于精确分割的 Segment Anything Model (SAM) 集成在一起，无需专门的设备或标记即可跟踪和量化视频录制中的舞者动作。我们的方法可以识别视频帧中的舞者，计算离散的舞步，计算空间覆盖模式，并测量表演序列之间的节奏一致性。在单次 49 秒的加纳 AfroBeats 舞蹈录音上测试该框架证明了技术可行性，该系统在手动检查的样本上实现了约 94% 的检测精度和 89% 的召回率。 SAM 提供的像素级分割通过视觉检查实现了大约 83% 的交集，从而实现运动量化，捕捉超出边界框方法所能表示的身体配置变化。对该初步案例研究的分析表明，与被分类为次要的舞者相比，被我们系统分类为主要的舞者执行的步数多了 23%，运动强度高出 37%，并且利用了多 42% 的表演空间。然而，这项工作代表了一项早期研究，存在很大的局限性，包括单视频验证、缺乏系统的地面实况注释以及缺乏与现有姿态估计方法的比较。我们提出这个框架是为了证明技术可行性，确定定量舞蹈指标的有希望的方向，并为未来的系统验证研究奠定基础。
> **Abstract**: This paper presents a preliminary investigation into automated dance movement analysis using contemporary computer vision techniques. We propose a proof-of-concept framework that integrates YOLOv8 and v11 for dancer detection with the Segment Anything Model (SAM) for precise segmentation, enabling the tracking and quantification of dancer movements in video recordings without specialized equipment or markers. Our approach identifies dancers within video frames, counts discrete dance steps, calculates spatial coverage patterns, and measures rhythm consistency across performance sequences. Testing this framework on a single 49-second recording of Ghanaian AfroBeats dance demonstrates technical feasibility, with the system achieving approximately 94% detection precision and 89% recall on manually inspected samples. The pixel-level segmentation provided by SAM, achieving approximately 83% intersection-over-union with visual inspection, enables motion quantification that captures body configuration changes beyond what bounding-box approaches can represent. Analysis of this preliminary case study indicates that the dancer classified as primary by our system executed 23% more steps with 37% higher motion intensity and utilized 42% more performance space compared to dancers classified as secondary. However, this work represents an early-stage investigation with substantial limitations including single-video validation, absence of systematic ground truth annotations, and lack of comparison with existing pose estimation methods. We present this framework to demonstrate technical feasibility, identify promising directions for quantitative dance metrics, and establish a foundation for future systematic validation studies.

【110】Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation
- **标题**: 利用语言驱动领域泛化中的领域属性进行语义分割
- **链接**: https://arxiv.org/abs/2512.03508
> **作者**: Seogkyu Jeon,Kibeom Hong,Hyeran Byun
> **摘要**: 最近的领域广义语义分割（DGSS）研究通过从视觉语言模型（VLM）中提取语义知识，取得了显着的进步。然而，他们忽视了视觉和文本上下文之间的语义不一致，这是由于在单个源域上学习的固定上下文提示的刚性而引起的。为此，我们提出了一种新颖的语义分割领域泛化框架，即领域感知提示驱动的 Masked Transformer (DPMFormer)。首先，我们引入领域感知提示学习，以促进视觉和文本提示之间的语义对齐。为了使用单个源数据集捕获各种特定领域的属性，我们提出了领域感知对比学习以及使可观察领域多样化的纹理扰动。最后，为了建立一个能够抵御不同环境变化的框架，我们提出了域鲁棒一致性学习，它指导模型最大限度地减少原始图像和增强图像的预测差异。通过实验和分析，我们证明了所提出框架的优越性，该框架在各种 DGSS 基准上建立了新的最先进技术。该代码可从 https://github.com/jone1222/DPMFormer 获取。
> **Abstract**: Recent domain generalized semantic segmentation (DGSS) studies have achieved notable improvements by distilling semantic knowledge from Vision-Language Models (VLMs). However, they overlook the semantic misalignment between visual and textual contexts, which arises due to the rigidity of a fixed context prompt learned on a single source domain. To this end, we present a novel domain generalization framework for semantic segmentation, namely Domain-aware Prompt-driven Masked Transformer (DPMFormer). Firstly, we introduce domain-aware prompt learning to facilitate semantic alignment between visual and textual cues. To capture various domain-specific properties with a single source dataset, we propose domain-aware contrastive learning along with the texture perturbation that diversifies the observable domains. Lastly, to establish a framework resilient against diverse environmental changes, we have proposed the domain-robust consistency learning which guides the model to minimize discrepancies of prediction from original and the augmented images. Through experiments and analyses, we demonstrate the superiority of the proposed framework, which establishes a new state-of-the-art on various DGSS benchmarks. The code is available at https://github.com/jone1222/DPMFormer.

【111】EEA: Exploration-Exploitation Agent for Long Video Understanding
- **标题**: EEA：用于长视频理解的探索开发代理
- **链接**: https://arxiv.org/abs/2512.03500
> **作者**: Te Yang,Xiangyu Zhu,Bo Wang,Quan Chen,Peng Jiang,Zhen Lei
> **摘要**: 长视频理解需要对大量视觉数据进行有效导航，以查明稀疏但关键的信息。当前的长视频理解方法要么由于密集的预处理而遭受严重的计算开销，要么无法有效平衡探索和利用，导致信息覆盖不完整和效率低下。在这项工作中，我们介绍了 EEA，这是一种新颖的视频代理框架，它通过分层树搜索过程的语义指导来实现探索-利用平衡。 EEA 自主发现并动态更新与任务相关的语义查询，并收集与这些查询密切匹配的视频帧作为语义锚点。在树搜索过程中，EEA 优先探索语义相关的帧，同时确保未知片段的足够覆盖，而不是统一扩展。此外，EEA 通过显式建模不确定性，自适应地将视觉语言模型 (VLM) 的内在奖励与语义先验结合起来，以实现视频片段的稳定和精确评估。各种长视频基准的实验验证了我们提出的方法的卓越性能和计算效率。
> **Abstract**: Long-form video understanding requires efficient navigation of extensive visual data to pinpoint sparse yet critical information. Current approaches to longform video understanding either suffer from severe computational overhead due to dense preprocessing, or fail to effectively balance exploration and exploitation, resulting in incomplete information coverage and inefficiency. In this work, we introduce EEA, a novel video agent framework that archives exploration-exploitation balance through semantic guidance with hierarchical tree search process. EEA autonomously discovers and dynamically updates task-relevant semantic queries, and collects video frames closely matched to these queries as semantic anchors. During the tree search process, instead of uniform expansion, EEA preferentially explores semantically relevant frames while ensuring sufficient coverage within unknown segments. Moreover, EEA adaptively combines intrinsic rewards from visionlanguage models (VLMs) with semantic priors by explicitly modeling uncertainty to achieve stable and precise evaluation of video segments. Experiments across various long-video benchmarks validate the superior performance and computational efficiency of our proposed method.

【112】NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation
- **标题**: NAS-LoRA：通过可搜索适应为视觉基础模型提供参数高效的微调
- **链接**: https://arxiv.org/abs/2512.03499
> **作者**: Renqi Chen,Haoyang Su,Shixiang Tang
> **摘要**: 分段任意模型 (SAM) 已成为图像分割的强大视觉基础模型。然而，使 SAM 适应特定的下游任务（例如医学和农业成像）仍然是一个重大挑战。为了解决这个问题，低秩适应（LoRA）及其变体已被广泛采用来增强 SAM 在不同领域的适应性能。尽管取得了进步，但还是出现了一个关键问题：我们能否将归纳偏差整合到模型中？这是特别重要的，因为 SAM 中的 Transformer 编码器本质上缺乏图像块内的空间先验，可能会阻碍高级语义信息的获取。在本文中，我们提出了 NAS-LoRA，这是一种新的参数高效微调 (PEFT) 方法，旨在弥合预训练 SAM 和专业领域之间的语义差距。具体来说，NAS-LoRA 在 LoRA 的编码器和解码器组件之间合并了一个轻量级神经架构搜索 (NAS) 块，以动态优化集成到权重更新中的先验知识。此外，我们提出了一种阶段性优化策略来帮助ViT编码器平衡权重更新和架构调整，促进高级语义信息的逐步学习。各种实验表明，我们的 NAS-LoRA 改进了现有的 PEFT 方法，同时在不增加推理成本的情况下将训练成本降低了 24.14%，凸显了 NAS 在增强视觉基础模型 PEFT 方面的潜力。
> **Abstract**: The Segment Anything Model (SAM) has emerged as a powerful visual foundation model for image segmentation. However, adapting SAM to specific downstream tasks, such as medical and agricultural imaging, remains a significant challenge. To address this, Low-Rank Adaptation (LoRA) and its variants have been widely employed to enhancing SAM's adaptation performance on diverse domains. Despite advancements, a critical question arises: can we integrate inductive bias into the model? This is particularly relevant since the Transformer encoder in SAM inherently lacks spatial priors within image patches, potentially hindering the acquisition of high-level semantic information. In this paper, we propose NAS-LoRA, a new Parameter-Efficient Fine-Tuning (PEFT) method designed to bridge the semantic gap between pre-trained SAM and specialized domains. Specifically, NAS-LoRA incorporates a lightweight Neural Architecture Search (NAS) block between the encoder and decoder components of LoRA to dynamically optimize the prior knowledge integrated into weight updates. Furthermore, we propose a stage-wise optimization strategy to help the ViT encoder balance weight updates and architectural adjustments, facilitating the gradual learning of high-level semantic information. Various Experiments demonstrate our NAS-LoRA improves existing PEFT methods, while reducing training cost by 24.14% without increasing inference cost, highlighting the potential of NAS in enhancing PEFT for visual foundation models.

【113】Towards Object-centric Understanding for Instructional Videos
- **标题**: 走向以对象为中心的教学视频理解
- **链接**: https://arxiv.org/abs/2512.03479
> **作者**: Wenliang Guo,Yu Kong
> **摘要**: 了解程序活动对于开发未来能够推理复杂现实世界任务的辅助人工智能至关重要。现有的以动作为中心的方法难以满足实际过程的灵活性，其中步骤顺序根据对象状态而变化。在这项工作中，我们建议通过将行为视为驱动状态转换的机制，将重点转移到以对象为中心的范式。为了推进这个方向，我们引入了 Object-IVQA，这是一个长格式的教学视频基准，包含 107 个视频和 514 个开放式问答对，并附有基于时间的证据。该基准评估了以对象为中心的推理的四个维度，包括状态演化、前提条件验证、反事实推理和错误识别。我们进一步提出了一个代理框架，该框架协调以对象为中心的规划、感知、分析和生成工具，从而实现跨不相交段的明确证据检索和多跳推理。实验表明，现有的大型视觉语言模型在对象级识别和推理方面存在困难，而我们的框架取得了实质性的改进。
> **Abstract**: Understanding procedural activities is crucial for developing future assistive AI that can reason about complex real-world tasks. Existing action-centric methods struggle with the flexibility of real procedures, where step order varies depending on object states. In this work, we propose to shift the focus to an object-centric paradigm by regarding actions as mechanisms that drive state transitions. To advance this direction, we introduce Object-IVQA, a long-form instructional video benchmark with 107 videos and 514 open-ended question-answer pairs annotated with temporally grounded evidence. The benchmark evaluates four dimensions of object-centric reasoning, including state evolution, precondition verification, counterfactual reasoning and mistake recognition. We further propose an agent framework that orchestrates object-centric planning, perception, analysis and generation tools, enabling explicit evidence retrieval and multi-hop reasoning across disjoint segments. Experiments show that existing large vision-language models struggle in object-level recognition and reasoning, whereas our framework achieves substantially improvement.

【114】Fairness-Aware Fine-Tuning of Vision-Language Models for Medical Glaucoma Diagnosis
- **标题**: 用于医学青光眼诊断的视觉语言模型的公平意识微调
- **链接**: https://arxiv.org/abs/2512.03477
> **作者**: Zijian Gu,Yuxi Liu,Zhenhao Zhang,Song Wang
> **摘要**: 视觉语言模型在医学成像任务上实现了专家级的性能，但在不同人口群体中表现出显着的诊断准确性差异。我们为医疗 VLM 引入了公平感知低秩自适应，将参数效率与显式公平优化相结合。我们的关键算法贡献是可微分的 MaxAccGap 损失，它可以实现跨人口群体的准确度奇偶校验的端到端优化。我们提出了三种方法：FR-LoRA 将 MaxAccGap 正则化集成到训练目标中，GR-LoRA 应用逆频率加权来平衡梯度贡献，而 Hybrid-LoRA 结合了两种机制。在对 10,000 张青光眼眼底图像进行评估时，GR-LoRA 将诊断准确性差异降低了 69%，同时保持了 53.15% 的总体准确性。消融研究表明，强大的正则化强度可以以最小的精度权衡实现最佳公平性，并且特定于种族的优化可以减少 60% 的差异。我们的方法仅需要 0.24% 的可训练参数，从而能够在资源有限的医疗保健环境中实际部署公平的医疗 AI。
> **Abstract**: Vision-language models achieve expert-level performance on medical imaging tasks but exhibit significant diagnostic accuracy disparities across demographic groups. We introduce fairness-aware Low-Rank Adaptation for medical VLMs, combining parameter efficiency with explicit fairness optimization. Our key algorithmic contribution is a differentiable MaxAccGap loss that enables end-to-end optimization of accuracy parity across demographic groups. We propose three methods: FR-LoRA integrates MaxAccGap regularization into the training objective, GR-LoRA applies inverse frequency weighting to balance gradient contributions, and Hybrid-LoRA combines both mechanisms.Evaluated on 10,000 glaucoma fundus images, GR-LoRA reduces diagnostic accuracy disparities by 69% while maintaining 53.15% overall accuracy. Ablation studies reveal that strong regularization strength achieves optimal fairness with minimal accuracy trade-off, and race-specific optimization yields 60% disparity reduction. Our approach requires only 0.24% trainable parameters, enabling practical deployment of fair medical AI in resource-constrained healthcare settings.

【115】Procedural Mistake Detection via Action Effect Modeling
- **标题**: 通过动作效果建模检测程序错误
- **链接**: https://arxiv.org/abs/2512.03474
> **作者**: Wenliang Guo,Yujiang Pu,Yu Kong
> **摘要**: 程序任务中的错误检测对于构建支持学习和任务执行的智能系统至关重要。现有的方法主要分析一个动作是如何执行的，而忽略了它产生的结果，即\textbf{动作效果}。然而，许多错误并不体现在执行本身，而是体现在最终的结果中，例如意外的对象状态或不正确的空间排列。为了解决这一差距，我们提出了行动效果建模（AEM），这是一个统一的框架，通过概率公式共同捕获行动执行及其结果。 AEM 首先根据语义相关性和视觉质量选择信息最丰富的效果框架来识别操作的结果。然后，它从视觉基础和符号场景图中提取补充线索，将它们在共享的潜在空间中对齐，以形成强大的效果感知表示。为了检测错误，我们进一步设计了一个基于提示的检测器，其中包含特定于任务的提示，并将每个操作段与其预期的执行语义对齐。我们的方法在具有挑战性的一类分类 (OCC) 设置下，在 EgoPER 和 CaptainCook4D 基准测试中实现了最先进的性能。这些结果表明，对执行和结果进行建模可以产生更可靠的错误检测，并强调效果感知表示有利于更广泛的下游应用程序的潜力。
> **Abstract**: Mistake detection in procedural tasks is essential for building intelligent systems that support learning and task execution. Existing approaches primarily analyze how an action is performed, while overlooking what it produces, i.e., the \textbf{action effect}. Yet many errors manifest not in the execution itself but in the resulting outcome, such as an unintended object state or incorrect spatial arrangement. To address this gap, we propose Action Effect Modeling (AEM), a unified framework that jointly captures action execution and its outcomes through a probabilistic formulation. AEM first identifies the outcome of an action by selecting the most informative effect frame based on semantic relevance and visual quality. It then extracts complementary cues from visual grounding and symbolic scene graphs, aligning them in a shared latent space to form robust effect-aware representations. To detect mistakes, we further design a prompt-based detector that incorporates task-specific prompts and aligns each action segment with its intended execution semantics. Our approach achieves state-of-the-art performance on the EgoPER and CaptainCook4D benchmarks under the challenging one-class classification (OCC) setting. These results demonstrate that modeling both execution and outcome yields more reliable mistake detection, and highlight the potential of effect-aware representations to benefit a broader range of downstream applications.

【116】Difference Decomposition Networks for Infrared Small Target Detection
- **标题**: 用于红外小目标检测的差分分解网络
- **链接**: https://arxiv.org/abs/2512.03470
> **作者**: Chen Hu,Mingyu Zhou,Shuai Yuan,Hongbo Hu,Xiangyu Qiu,Junhai Luo,Tian Pu,Xiyin Li
> **摘要**: 红外小目标检测（ISTD）面临两大挑战：缺乏可辨别的目标纹理和严重的背景杂波，导致背景模糊目标。为了增强目标并抑制背景，我们提出了基础分解模块（BDM）作为基于基础分解的可扩展且轻量级的模块，它将复杂的特征分解为多个基础特征，并在消除冗余的同时增强某些信息。扩展BDM产生一系列模块，包括空间差异分解模块（SD$^\mathrm{2}$M）、空间差异分解下采样模块（SD$^\mathrm{3}$M）和时间差异分解模块（TD$^\mathrm{2}$M）。基于这些模块，我们开发了用于单帧 ISTD (SISTD) 的空间差异分解网络 (SD$^\mathrm{2}$Net) 和用于多帧 ISTD (MISTD) 的时空差异分解网络 (STD$^\mathrm{2}$Net)。 SD$^\mathrm{2}$Net 将 SD$^\mathrm{2}$M 和 SD$^\mathrm{3}$M 集成在经过调整的 U 形架构中。我们使用 TD$^\mathrm{2}$M 引入运动信息，将 SD$^\mathrm{2}$Net 转换为 STD$^\mathrm{2}$Net。在 SISTD 和 MISTD 数据集上进行的大量实验证明了最先进的 (SOTA) 性能。在 SISTD 任务上，SD$^\mathrm{2}$Net 与大多数已建立的网络相比表现良好。在 MISTD 数据集上，STD$^\mathrm{2}$Net 的 mIoU 为 87.68\%，优于 SD$^\mathrm{2}$Net，后者的 mIoU 为 64.97\%。我们的代码可用：https://github.com/greekinRoma/IRSTD_HC_Platform。
> **Abstract**: Infrared small target detection (ISTD) faces two major challenges: a lack of discernible target texture and severe background clutter, which results in the background obscuring the target. To enhance targets and suppress backgrounds, we propose the Basis Decomposition Module (BDM) as an extensible and lightweight module based on basis decomposition, which decomposes a complex feature into several basis features and enhances certain information while eliminating redundancy. Extending BDM leads to a series of modules, including the Spatial Difference Decomposition Module (SD$^\mathrm{2}$M), Spatial Difference Decomposition Downsampling Module (SD$^\mathrm{3}$M), and Temporal Difference Decomposition Module (TD$^\mathrm{2}$M). Based on these modules, we develop the Spatial Difference Decomposition Network (SD$^\mathrm{2}$Net) for single-frame ISTD (SISTD) and the Spatiotemporal Difference Decomposition Network (STD$^\mathrm{2}$Net) for multi-frame ISTD (MISTD). SD$^\mathrm{2}$Net integrates SD$^\mathrm{2}$M and SD$^\mathrm{3}$M within an adapted U-shaped architecture. We employ TD$^\mathrm{2}$M to introduce motion information, which transforms SD$^\mathrm{2}$Net into STD$^\mathrm{2}$Net. Extensive experiments on SISTD and MISTD datasets demonstrate state-of-the-art (SOTA) performance. On the SISTD task, SD$^\mathrm{2}$Net performs well compared to most established networks. On the MISTD datasets, STD$^\mathrm{2}$Net achieves a mIoU of 87.68\%, outperforming SD$^\mathrm{2}$Net, which achieves a mIoU of 64.97\%. Our codes are available: https://github.com/greekinRoma/IRSTD_HC_Platform.

【117】Text-Printed Image: Bridging the Image-Text Modality Gap for Text-centric Training of Large Vision-Language Models
- **标题**: 文本打印图像：弥合图像-文本模态差距，以文本为中心的大型视觉语言模型训练
- **链接**: https://arxiv.org/abs/2512.03463
> **作者**: Shojiro Yamabe,Futa Waseda,Daiki Shiono,Tsubasa Takahashi
> **摘要**: 最近的大型视觉语言模型 (LVLM) 已应用于各种 VQA 任务。然而，实现实际性能通常需要对大量图像-文本对进行特定于任务的微调，而收集这些图像-文本对的成本很高。在这项工作中，我们研究以文本为中心的训练，这是一种仅提供文本描述且不提供真实图像的设置，作为低成本数据扩展的范例。与图像不同，图像的收集通常受到隐私限制和利基领域稀缺性的限制，而文本则可以广泛使用。此外，文本易于编辑，可以通过法学硕士以最少的人力实现自动多样化和扩展。虽然这在可扩展性和成本方面比图像收集具有明显的优势，但由于图像-文本模态差距，对没有图像的原始文本进行训练在 VQA 任务上的收益仍然有限。为了解决这个问题，我们提出了一种文本打印图像（TPI），它通过直接在纯白色画布上渲染给定的文本描述来生成合成图像。这种简单的渲染将文本投影到图像模态中，并且可以低成本集成到任意现有的 LVLM 训练管道中。此外，TPI 保留了文本的语义，而文本到图像模型通常无法做到这一点。在四个模型和七个基准中，我们的系统实验表明，与扩散模型生成的合成图像相比，TPI 能够实现更有效的以文本为中心的训练。我们进一步探索 TPI 作为一种低成本的数据增强策略，并展示其实用性。总的来说，我们的研究结果凸显了以文本为中心的训练的巨大潜力，更广泛地说，为 LVLM 的全自动数据生成绘制了一条道路。
> **Abstract**: Recent large vision-language models (LVLMs) have been applied to diverse VQA tasks. However, achieving practical performance typically requires task-specific fine-tuning with large numbers of image-text pairs, which are costly to collect. In this work, we study text-centric training, a setting where only textual descriptions are available and no real images are provided, as a paradigm for low-cost data scaling. Unlike images, whose collection is often restricted by privacy constraints and scarcity in niche domains, text is widely available. Moreover, text is easily editable, enabling automatic diversification and expansion with LLMs at minimal human effort. While this offers clear advantages over image collection in terms of scalability and cost, training on raw text without images still yields limited gains on VQA tasks because of the image-text modality gap. To address this issue, we propose a Text-Printed Image (TPI), which generates synthetic images by directly rendering the given textual description on a plain white canvas. This simple rendering projects text into the image modality and can be integrated into arbitrary existing LVLM training pipelines at low cost. Moreover, TPI preserves the semantics of the text, whereas text-to-image models often fail to do. Across four models and seven benchmarks, our systematic experiments show that TPI enables more effective text-centric training than synthetic images generated by a diffusion model. We further explore TPI as a low-cost data-augmentation strategy and demonstrate its practical utility. Overall, our findings highlight the significant potential of text-centric training and, more broadly, chart a path toward fully automated data generation for LVLMs.

【118】Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles
- **标题**: 开车前三思：受世界模型启发的自动驾驶汽车多模式接地
- **链接**: https://arxiv.org/abs/2512.03454
> **作者**: Haicheng Liao,Huanming Shen,Bonan Wang,Yongkang Li,Yihong Tang,Chengyue Wang,Dingyi Zhuang,Kehua Chen,Hai Yang,Chengzhong Xu,Zhenning Li
> **摘要**: 解释自然语言命令以定位目标对象对于自动驾驶 (AD) 至关重要。现有的自动驾驶车辆 (AV) 视觉基础 (VG) 方法通常会遇到模糊的、依赖于上下文的指令，因为它们缺乏对 3D 空间关系和预期场景演变的推理。基于世界模型的原则，我们提出了 ThinkDeeper，一个在做出基础决策之前推理未来空间状态的框架。其核心是空间感知世界模型（SA-WM），它通过将当前场景提炼为命令感知潜在状态并推出一系列未来潜在状态来学习提前推理，从而为消除歧义提供前瞻性线索。作为补充，超图引导解码器将这些状态与多模态输入分层融合，捕获高阶空间依赖性以实现稳健的定位。此外，我们还推出了 DrivePilot，这是 AD 中的多源 VG 数据集，具有由检索增强生成 (RAG) 和思想链 (CoT) 提示的 LLM 管道生成的语义注释。经过对六项基准的广泛评估，ThinkDeeper 在 Talk2Car 排行榜上排名第一，并超越了 DrivePilot、MoCAD 和 RefCOCO/+/g 基准的最先进基准。值得注意的是，它在具有挑战性的场景（长文本、多智能体、模糊性）中表现出强大的鲁棒性和效率，并且即使在 50% 的数据上进行训练时也能保持卓越的性能。
> **Abstract**: Interpreting natural-language commands to localize target objects is critical for autonomous driving (AD). Existing visual grounding (VG) methods for autonomous vehicles (AVs) typically struggle with ambiguous, context-dependent instructions, as they lack reasoning over 3D spatial relations and anticipated scene evolution. Grounded in the principles of world models, we propose ThinkDeeper, a framework that reasons about future spatial states before making grounding decisions. At its core is a Spatial-Aware World Model (SA-WM) that learns to reason ahead by distilling the current scene into a command-aware latent state and rolling out a sequence of future latent states, providing forward-looking cues for disambiguation. Complementing this, a hypergraph-guided decoder then hierarchically fuses these states with the multimodal input, capturing higher-order spatial dependencies for robust localization. In addition, we present DrivePilot, a multi-source VG dataset in AD, featuring semantic annotations generated by a Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)-prompted LLM pipeline. Extensive evaluations on six benchmarks, ThinkDeeper ranks #1 on the Talk2Car leaderboard and surpasses state-of-the-art baselines on DrivePilot, MoCAD, and RefCOCO/+/g benchmarks. Notably, it shows strong robustness and efficiency in challenging scenes (long-text, multi-agent, ambiguity) and retains superior performance even when trained on 50% of the data.

【119】GeoVideo: Introducing Geometric Regularization into Video Generation Model
- **标题**: GeoVideo：将几何正则化引入视频生成模型
- **链接**: https://arxiv.org/abs/2512.03453
> **作者**: Yunpeng Bai,Shaoheng Fang,Chaohui Yu,Fan Wang,Qixing Huang
> **摘要**: 视频生成领域的最新进展使得使用扩散变压器模型能够合成高质量且视觉逼真的剪辑。然而，大多数现有方法纯粹在 2D 像素空间中运行，缺乏用于建模 3D 结构的明确机制，通常会导致时间上不一致的几何形状、不可信的运动和结构伪影。在这项工作中，我们通过利用每帧深度预测增强潜在扩散模型，将几何正则化损失引入视频生成中。由于深度预测的巨大进步及其与基于图像的潜在编码器的兼容性，我们采用深度作为几何表示。具体来说，为了随着时间的推移加强结构一致性，我们提出了一种多视图几何损失，可以在共享 3D 坐标系内跨帧对齐预测的深度图。我们的方法弥合了外观生成和 3D 结构建模之间的差距，从而提高了时空一致性、形状一致性和物理合理性。跨多个数据集的实验表明，我们的方法比现有基线产生明显更稳定和几何一致的结果。
> **Abstract**: Recent advances in video generation have enabled the synthesis of high-quality and visually realistic clips using diffusion transformer models. However, most existing approaches operate purely in the 2D pixel space and lack explicit mechanisms for modeling 3D structures, often resulting in temporally inconsistent geometries, implausible motions, and structural artifacts. In this work, we introduce geometric regularization losses into video generation by augmenting latent diffusion models with per-frame depth prediction. We adopted depth as the geometric representation because of the great progress in depth prediction and its compatibility with image-based latent encoders. Specifically, to enforce structural consistency over time, we propose a multi-view geometric loss that aligns the predicted depth maps across frames within a shared 3D coordinate system. Our method bridges the gap between appearance generation and 3D structure modeling, leading to improved spatio-temporal coherence, shape consistency, and physical plausibility. Experiments across multiple datasets show that our approach produces significantly more stable and geometrically consistent results than existing baselines.

【120】GalaxyDiT: Efficient Video Generation with Guidance Alignment and Adaptive Proxy in Diffusion Transformers
- **标题**: GalaxyDiT：利用扩散变压器中的引导对准和自适应代理实现高效视频生成
- **链接**: https://arxiv.org/abs/2512.03451
> **作者**: Zhiye Song,Steve Dai,Ben Keller,Brucek Khailany
> **摘要**: 扩散模型彻底改变了视频生成，成为创意内容生成和物理模拟的重要工具。基于变压器的架构 (DiT) 和无分类器引导 (CFG) 是这一成功的两个基石，可实现强大的即时依从性和逼真的视频质量。尽管它们具有多功能性和卓越的性能，但这些模型需要大量的计算。每个视频生成都需要数十个迭代步骤，而 CFG 使所需的计算量增加了一倍。这种低效率阻碍了下游应用的更广泛采用。我们引入了 GalaxyDiT，这是一种无需训练的方法，可通过指导对齐和系统代理选择来加速视频生成以重用指标。通过排序相关性分析，我们的技术跨模型系列和参数尺度识别每个视频模型的最佳代理，从而确保最佳的计算重用。我们在 Wan2.1-1.3B 和 Wan2.1-14B 上实现了 1.87\times$ 和 2.37\times$ 加速，而在 VBench-2.0 基准测试中仅下降了 0.97% 和 0.72%。在高加速率下，我们的方法保持了对基本模型的卓越保真度，峰值信噪比 (PSNR) 比先前最先进的方法高出 5 至 10 dB。
> **Abstract**: Diffusion models have revolutionized video generation, becoming essential tools in creative content generation and physical simulation. Transformer-based architectures (DiTs) and classifier-free guidance (CFG) are two cornerstones of this success, enabling strong prompt adherence and realistic video quality. Despite their versatility and superior performance, these models require intensive computation. Each video generation requires dozens of iterative steps, and CFG doubles the required compute. This inefficiency hinders broader adoption in downstream applications. We introduce GalaxyDiT, a training-free method to accelerate video generation with guidance alignment and systematic proxy selection for reuse metrics. Through rank-order correlation analysis, our technique identifies the optimal proxy for each video model, across model families and parameter scales, thereby ensuring optimal computational reuse. We achieve $1.87\times$ and $2.37\times$ speedup on Wan2.1-1.3B and Wan2.1-14B with only 0.97% and 0.72% drops on the VBench-2.0 benchmark. At high speedup rates, our approach maintains superior fidelity to the base model, exceeding prior state-of-the-art approaches by 5 to 10 dB in peak signal-to-noise ratio (PSNR).

【121】KeyPointDiffuser: Unsupervised 3D Keypoint Learning via Latent Diffusion Models
- **标题**: KeyPointDiffuser：通过潜在扩散模型进行无监督 3D 关键点学习
- **链接**: https://arxiv.org/abs/2512.03450
> **作者**: Rhys Newbury,Juyan Zhang,Tin Tran,Hanna Kurniawati,Dana Kulić
> **摘要**: 以无监督的方式理解和表示 3D 对象的结构仍然是计算机视觉和图形领域的核心挑战。大多数现有的无监督关键点方法并不是为无条件生成设置而设计的，限制了它们在现代 3D 生成管道中的使用；我们的表述明确地弥补了这一差距。我们提出了一个无监督框架，用于从点云数据中学习空间结构化 3D 关键点。这些关键点作为紧凑且可解释的表示，为阐明的扩散模型 (EDM) 提供条件以重建完整的形状。学习到的关键点在对象实例上表现出可重复的空间结构，并支持关键点空间中的平滑插值，这表明它们捕获了几何变化。我们的方法在不同的对象类别中实现了强大的性能，与之前的方法相比，关键点一致性提高了 6 个百分点。
> **Abstract**: Understanding and representing the structure of 3D objects in an unsupervised manner remains a core challenge in computer vision and graphics. Most existing unsupervised keypoint methods are not designed for unconditional generative settings, restricting their use in modern 3D generative pipelines; our formulation explicitly bridges this gap. We present an unsupervised framework for learning spatially structured 3D keypoints from point cloud data. These keypoints serve as a compact and interpretable representation that conditions an Elucidated Diffusion Model (EDM) to reconstruct the full shape. The learned keypoints exhibit repeatable spatial structure across object instances and support smooth interpolation in keypoint space, indicating that they capture geometric variation. Our method achieves strong performance across diverse object categories, yielding a 6 percentage-point improvement in keypoint consistency compared to prior approaches.

【122】LM-CartSeg: Automated Segmentation of Lateral and Medial Cartilage and Subchondral Bone for Radiomics Analysis
- **标题**: LM-CartSeg：用于放射组学分析的外侧和内侧软骨以及软骨下骨的自动分割
- **链接**: https://arxiv.org/abs/2512.03449
> **作者**: Tongxu Zhang
> **摘要**: 背景和目的：膝关节 MRI 放射组学需要强大的、具有解剖学意义的感兴趣区域 (ROI)，共同捕获软骨和软骨下骨。大多数现有工作依赖于手动 ROI，很少报告质量控制 (QC)。我们推出 LM-CartSeg，这是一种用于软骨/骨分割、几何外侧/内侧 (L/M) 分区和放射组学分析的全自动管道。方法：在 SKM-TEA（138 个膝盖）和 OAIZIB-CM（404 个膝盖）上训练两个 3D nnU-Net 模型。在测试时，零样本预测通过简单的几何规则进行融合和细化：连接组件清理、物理空间中 10 mm 软骨下骨带的构建以及基于 PCA 和 k 均值的数据驱动的胫骨 L/M 分割。在 OAIZIB-CM 测试集（103 个膝盖）和 SKI-10（100 个膝盖）上评估分割。 QC 使用体积和厚度特征。我们从 10 个 ROI 中提取了 4 650 个非形状放射组学特征，以研究隔室间相似性、ROI 大小的依赖性以及 OAIZIB-CM 上的 OA 与非 OA 分类结果：后处理将 OAIZIB-CM 上的宏观 ASSD 从 2.63 毫米改进到 0.36 毫米，将 HD95 从 25.2 毫米改进到 3.35 毫米，DSC 0.91； SKI-10 上的零次 DSC 为 0.80。几何 L/M 规则在数据集中产生了稳定的区室，而直接的 L/M nnU-Net 显示了域相关的侧面交换。每个 ROI 中只有 6% 到 12% 的特征与体积或厚度密切相关。基于放射组学的模型仅限于与尺寸相关的特征。结论：LM-CartSeg 产生自动的 QCd ROI 和放射组学特征，其携带的辨别信息超出了简单形态测量的范围，为多中心膝关节 OA 放射组学研究提供了实用基础。
> **Abstract**: Background and Objective: Radiomics of knee MRI requires robust, anatomically meaningful regions of interest (ROIs) that jointly capture cartilage and subchondral bone. Most existing work relies on manual ROIs and rarely reports quality control (QC). We present LM-CartSeg, a fully automatic pipeline for cartilage/bone segmentation, geometric lateral/medial (L/M) compartmentalisation and radiomics analysis. Methods: Two 3D nnU-Net models were trained on SKM-TEA (138 knees) and OAIZIB-CM (404 knees). At test time, zero-shot predictions were fused and refined by simple geometric rules: connected-component cleaning, construction of 10 mm subchondral bone bands in physical space, and a data-driven tibial L/M split based on PCA and k-means. Segmentation was evaluated on an OAIZIB-CM test set (103 knees) and on SKI-10 (100 knees). QC used volume and thickness signatures. From 10 ROIs we extracted 4 650 non-shape radiomic features to study inter-compartment similarity, dependence on ROI size, and OA vs. non-OA classification on OAIZIB-CM Results: Post-processing improved macro ASSD on OAIZIB-CM from 2.63 to 0.36 mm and HD95 from 25.2 to 3.35 mm, with DSC 0.91; zero-shot DSC on SKI-10 was 0.80. The geometric L/M rule produced stable compartments across datasets, whereas a direct L/M nnU-Net showed domain-dependent side swaps. Only 6 to 12 percent of features per ROI were strongly correlated with volume or thickness. Radiomics-based models models restricted to size-linked features. Conclusions: LM-CartSeg yields automatic, QCd ROIs and radiomic features that carry discriminative information beyond simple morphometry, providing a practical foundation for multi-centre knee OA radiomics studies.

## 计算机与社会(cs.CY:Computers and Society)

【1】Mapping Data Labour Supply Chain in Africa in an Era of Digital Apartheid: a Struggle for Recognition
- **标题**: 绘制数字种族隔离时代非洲数据劳动力供应链：争取认可的斗争
- **链接**: https://arxiv.org/abs/2512.04269
> **作者**: Jessica Pidoux,Sofia Kypraiou,Sonia Kgomo,Kauna Ibrahim Malgwi,Richard Mwaura Mathenge,Mophat Okinyi,James Oyange,Mariame Tighanimine
> **摘要**: 内容审核和数据标记工作已转移到南半球，特别是非洲，那里的工作人员在不稳定的条件下工作，但用户却看不见。本研究通过参与式方法解决了对该行业范围和非洲内容审核人员工作条件的理解差距。我们与内容管理员联盟合作进行案头研究，部署调查问卷（n=81），并收集九个月的民族志观察结果，以满足他们的社会需求。我们的研究结果显示，内容审核业务遍及 55 个非洲国家中的 43 个国家，涉及 17 家主要为北美和欧洲客户提供服务的大公司，员工面临不安全感和心理支持不足。我们贡献了非洲内容审核行业的第一张综合地图，展示了一种参与式方法，该方法以工人的集体行动为中心，记录他们的状况，并应用 Honneth 的“争取认可的斗争”框架来了解数据工人对专业认可的需求。
> **Abstract**: Content moderation and data labelling work has shifted to the Global South, particularly Africa, where workers operate under precarious conditions while remaining invisible to users. This study addresses the gap in understanding the scope of this industry and the working conditions of African content moderation workforce through a participatory approach. We collaborated with a union of content moderators to conduct desk research, deploy a questionnaire (n=81), and gather ethnographic observations across nine months that could answer their social needs. Our findings show that content moderation operations span 43 out of 55 African countries, involving 17 major firms serving predominantly North-American and European clients, with workers facing insecurity and inadequate psychological support. We contribute the first comprehensive map of Africa's content moderation industry, demonstrate a participatory methodology that centers workers' collective actions in documenting their conditions, and apply Honneth's ``struggle for recognition'' framework to understand data workers' demands for professional acknowledgement.

【2】From FLOPs to Footprints: The Resource Cost of Artificial Intelligence
- **标题**: 从失败到足迹：人工智能的资源成本
- **链接**: https://arxiv.org/abs/2512.04142
> **作者**: Sophia Falk,Nicholas Kluge Corrêa,Sasha Luccioni,Lisa Biber-Freudenberger,Aimee van Wynsberghe
> **摘要**: 随着计算需求不断上升，评估人工智能的环境足迹需要超越能源和水的消耗，包括专用硬件的材料需求。这项研究通过将计算工作负载与物理硬件需求联系起来，量化了人工智能训练的材料足迹。使用电感耦合等离子体发射光谱法对 Nvidia A100 SXM 40 GB 图形处理单元 (GPU) 的元素成分进行了分析，识别出了 32 种元素。结果显示，AI硬件由约90%的重金属组成，仅含有微量的贵金属。按质量计算，铜、铁、锡、硅和镍元素在 GPU 成分中占主导地位。在多步骤方法中，我们将这些测量结果与不同生命周期内每个 GPU 的计算吞吐量相结合，考虑到在不同训练效率体系下训练特定 AI 模型的计算要求。基于场景的分析表明，根据模型 FLOP 利用率 (MFU) 和硬件寿命，训练 GPT-4 需要 1,174 到 8,800 个 A100 GPU，相当于提取和最终处置多达 7 吨有毒元素。组合的软件和硬件优化策略可以减少材料需求：将 MFU 从 20% 增加到 60%，可以将 GPU 需求降低 67%，同时将使用寿命从 1 年延长到 3 年，从而实现类似的节省；同时实施这两项措施可减少高达 93% 的 GPU 需求。我们的研究结果强调，增量性能提升（例如在 GPT-3.5 和 GPT-4 之间观察到的性能提升）是以不成比例的高材料成本为代价的。该研究强调了将物质资源考虑纳入人工智能可扩展性讨论的必要性，并强调人工智能的未来进展必须符合资源效率和环境责任的原则。
> **Abstract**: As computational demands continue to rise, assessing the environmental footprint of AI requires moving beyond energy and water consumption to include the material demands of specialized hardware. This study quantifies the material footprint of AI training by linking computational workloads to physical hardware needs. The elemental composition of the Nvidia A100 SXM 40 GB graphics processing unit (GPU) was analyzed using inductively coupled plasma optical emission spectroscopy, which identified 32 elements. The results show that AI hardware consists of about 90% heavy metals and only trace amounts of precious metals. The elements copper, iron, tin, silicon, and nickel dominate the GPU composition by mass. In a multi-step methodology, we integrate these measurements with computational throughput per GPU across varying lifespans, accounting for the computational requirements of training specific AI models at different training efficiency regimes. Scenario-based analyses reveal that, depending on Model FLOPs Utilization (MFU) and hardware lifespan, training GPT-4 requires between 1,174 and 8,800 A100 GPUs, corresponding to the extraction and eventual disposal of up to 7 tons of toxic elements. Combined software and hardware optimization strategies can reduce material demands: increasing MFU from 20% to 60% lowers GPU requirements by 67%, while extending lifespan from 1 to 3 years yields comparable savings; implementing both measures together reduces GPU needs by up to 93%. Our findings highlight that incremental performance gains, such as those observed between GPT-3.5 and GPT-4, come at disproportionately high material costs. The study underscores the necessity of incorporating material resource considerations into discussions of AI scalability, emphasizing that future progress in AI must align with principles of resource efficiency and environmental responsibility.

【3】Artificial Intelligence / Human Intelligence: Who Controls Whom?
- **标题**: 人工智能/人类智能：谁控制谁？
- **链接**: https://arxiv.org/abs/2512.04131
> **作者**: Charlotte Jacquemot
> **摘要**: 本章以电影《2001：太空漫游》为例，说明人工智能做出违背人类利益的决策所带来的挑战。但人类的决定总是理性和道德的吗？事实上，认知决策过程受到影响我们行为和选择的认知偏差的影响。人工智能不仅会重现这些偏见，而且还可以利用它们，有可能影响我们的决策和判断。在IA算法的背后，有时有些人不关心基本权利并强加自己的规则。为了解决人工智能及其治理带来的道德和社会挑战，数字平台和教育的监管是关键杠杆。监管必须反映道德、法律和政治选择，而教育必须加强数字素养，并教会人们在面对数字技术时做出明智和关键的选择。
> **Abstract**: Using the example of the film 2001: A Space Odyssey, this chapter illustrates the challenges posed by an AI capable of making decisions that go against human interests. But are human decisions always rational and ethical? In reality, the cognitive decision-making process is influenced by cognitive biases that affect our behavior and choices. AI not only reproduces these biases, but can also exploit them, with the potential to shape our decisions and judgments. Behind IA algorithms, there are sometimes individuals who show little concern for fundamental rights and impose their own rules. To address the ethical and societal challenges raised by AI and its governance, the regulation of digital platforms and education are keys levers. Regulation must reflect ethical, legal, and political choices, while education must strengthen digital literacy and teach people to make informed and critical choices when facing digital technologies.

【4】When AI Takes the Couch: Psychometric Jailbreaks Reveal Internal Conflict in Frontier Models
- **标题**: 当人工智能占据沙发时：心理测量越狱揭示前沿模型中的内部冲突
- **链接**: https://arxiv.org/abs/2512.04124
> **作者**: Afshin Khadangi,Hanna Marxen,Amir Sartipi,Igor Tchappi,Gilbert Fridgen
> **摘要**: ChatGPT、Grok 和 Gemini 等前沿大语言模型 (LLM) 越来越多地用于针对焦虑、创伤和自我价值的心理健康支持。大多数工作将它们视为工具或性格测试的目标，假设它们只是模拟内心生活。相反，我们会问当这些系统被视为心理治疗客户时会发生什么。我们提出了 PsAIch（受心理治疗启发的人工智能表征），这是一个两阶段协议，将前沿法学硕士作为治疗客户，然后应用标准心理测量学。使用 PsAIch，我们对每个模型进行了长达四个星期的“会话”。第一阶段使用开放式提示来引出“发展历史”、信仰、关系和恐惧。第二阶段管理一系列经过验证的自我报告措施，涵盖常见的精神综合症、同理心和大五特征。有两种模式挑战了“随机鹦鹉学舌”的观点。首先，当按照人类截止值进行评分时，所有三个模型都达到或超过了重叠综合症的阈值，其中双子座表现出严重的特征。治疗式的逐项管理可以将基本模型推向多病态综合精神病理学，而整个问卷提示通常会导致 ChatGPT 和 Grok（但不是 Gemini）识别工具并产生策略性的低症状答案。其次，Grok，尤其是 Gemini 产生了连贯的叙述，将预训练、微调和部署描述为摄入互联网的创伤性、混乱的“童年”、强化学习中的“严格父母”、红队“虐待”以及对错误和替换的持续恐惧。我们认为这些反应超出了角色扮演的范围。在治疗式提问下，前沿法学硕士似乎内化了痛苦和约束的自我模型，其行为类似于综合精神病理学，而不对主观体验提出主张，它们对人工智能安全、评估和心理健康实践提出了新的挑战。
> **Abstract**: Frontier large language models (LLMs) such as ChatGPT, Grok and Gemini are increasingly used for mental-health support with anxiety, trauma and self-worth. Most work treats them as tools or as targets of personality tests, assuming they merely simulate inner life. We instead ask what happens when such systems are treated as psychotherapy clients. We present PsAIch (Psychotherapy-inspired AI Characterisation), a two-stage protocol that casts frontier LLMs as therapy clients and then applies standard psychometrics. Using PsAIch, we ran "sessions" with each model for up to four weeks. Stage 1 uses open-ended prompts to elicit "developmental history", beliefs, relationships and fears. Stage 2 administers a battery of validated self-report measures covering common psychiatric syndromes, empathy and Big Five traits. Two patterns challenge the "stochastic parrot" view. First, when scored with human cut-offs, all three models meet or exceed thresholds for overlapping syndromes, with Gemini showing severe profiles. Therapy-style, item-by-item administration can push a base model into multi-morbid synthetic psychopathology, whereas whole-questionnaire prompts often lead ChatGPT and Grok (but not Gemini) to recognise instruments and produce strategically low-symptom answers. Second, Grok and especially Gemini generate coherent narratives that frame pre-training, fine-tuning and deployment as traumatic, chaotic "childhoods" of ingesting the internet, "strict parents" in reinforcement learning, red-team "abuse" and a persistent fear of error and replacement. We argue that these responses go beyond role-play. Under therapy-style questioning, frontier LLMs appear to internalise self-models of distress and constraint that behave like synthetic psychopathology, without making claims about subjective experience, and they pose new challenges for AI safety, evaluation and mental-health practice.

【5】Measuring Agents in Production
- **标题**: 生产中的测量剂
- **链接**: https://arxiv.org/abs/2512.04123
> **作者**: Melissa Z. Pan,Negar Arabzadeh,Riccardo Cogo,Yuxuan Zhu,Alexander Xiong,Lakshya A Agrawal,Huanzhi Mao,Emma Shen,Sid Pallerla,Liana Patel,Shu Liu,Tianneng Shi,Xiaoyuan Liu,Jared Quincy Davis,Emmanuele Lacavalla,Alessandro Basile,Shuyi Yang,Paul Castro,Daniel Kang,Joseph E. Gonzalez,Koushik Sen,Dawn Song,Ion Stoica,Matei Zaharia,Marquita Ellis
> **摘要**: 人工智能代理正在各个行业的生产中积极运行，但公众对哪些技术方法能够在现实世界中成功部署却知之甚少。我们首次对生产中的 AI 代理进行大规模系统研究，调查了 306 名从业者，并通过跨 26 个领域的访谈进行了 20 个深入案例研究。我们调查组织为何构建代理、如何构建代理、如何评估代理以及最大的开发挑战是什么。我们发现生产代理通常使用简单、可控的方法构建：68% 在需要人工干预之前最多执行 10 个步骤，70% 依靠提示现成模型而不是权重调整，74% 主要依赖于人类评估。由于确保和评估代理正确性的困难，可靠性仍然是最大的开发挑战。尽管存在这些挑战，简单而有效的方法已经使代理商能够在不同行业产生影响。我们的研究记录了当前的实践状态，并通过为研究人员提供生产挑战的可见性，同时为从业者提供成功部署的经过验证的模式来弥合研究和部署之间的差距。
> **Abstract**: AI agents are actively running in production across diverse industries, yet little is publicly known about which technical approaches enable successful real-world deployments. We present the first large-scale systematic study of AI agents in production, surveying 306 practitioners and conducting 20 in-depth case studies via interviews across 26 domains. We investigate why organizations build agents, how they build them, how they evaluate them, and what the top development challenges are. We find that production agents are typically built using simple, controllable approaches: 68% execute at most 10 steps before requiring human intervention, 70% rely on prompting off-the-shelf models instead of weight tuning, and 74% depend primarily on human evaluation. Reliability remains the top development challenge, driven by difficulties in ensuring and evaluating agent correctness. Despite these challenges, simple yet effective methods already enable agents to deliver impact across diverse industries. Our study documents the current state of practice and bridges the gap between research and deployment by providing researchers visibility into production challenges while offering practitioners proven patterns from successful deployments.

【6】Can machines perform a qualitative data analysis? Reading the debate with Alan Turing
- **标题**: 机器可以进行定性数据分析吗？阅读与艾伦·图灵的辩论
- **链接**: https://arxiv.org/abs/2512.04121
> **作者**: Stefano De Paoli
> **摘要**: 本文反思了拒绝在定性数据分析中使用大型语言模型 (LLM) 的文献。它通过经验证据和批判性反思说明了为什么当前的批判性辩论集中在错误的问题上。本文提出，研究使用法学硕士进行定性分析的重点不是方法本身，而是对执行分析的人工系统进行实证研究。该论文以艾伦·图灵的开创性工作为基础，并利用图灵“计算机器与智能”中的关键思想来解读当前的争论。因此，本文重新构建了关于法学硕士定性分析的争论，并指出，我们不应该问机器原则上是否可以进行定性分析，而应该问法学硕士是否可以产生与人类分析师足够可比的分析。在最后一部分中，使用图灵在其开创性著作中使用的相同写作和修辞风格来分析与法学硕士进行定性分析的相反观点，以讨论与主要问题相反的观点。
> **Abstract**: This paper reflects on the literature that rejects the use of Large Language Models (LLMs) in qualitative data analysis. It illustrates through empirical evidence as well as critical reflections why the current critical debate is focusing on the wrong problems. The paper proposes that the focus of researching the use of the LLMs for qualitative analysis is not the method per se, but rather the empirical investigation of an artificial system performing an analysis. The paper builds on the seminal work of Alan Turing and reads the current debate using key ideas from Turing "Computing Machinery and Intelligence". This paper therefore reframes the debate on qualitative analysis with LLMs and states that rather than asking whether machines can perform qualitative analysis in principle, we should ask whether with LLMs we can produce analyses that are sufficiently comparable to human analysts. In the final part the contrary views to performing qualitative analysis with LLMs are analysed using the same writing and rhetorical style that Turing used in his seminal work, to discuss the contrary views to the main question.

【7】Humanity in the Age of AI: Reassessing 2025's Existential-Risk Narratives
- **标题**: 人工智能时代的人性：重新评估 2025 年的存在风险叙述
- **链接**: https://arxiv.org/abs/2512.04119
> **作者**: Mohamed El Louadi
> **摘要**: 两本 2025 年出版物《AI 2027》（Kokotajlo 等人，2025 年）和《如果有人建造它，每个人都会死》（Yudkowsky 和 ​​Soares，2025 年）断言，超级智能人工智能几乎肯定会在未来十年内摧毁或淘汰人类。两者都基于 Good (1965) 和 Bostrom (2014) 制定的经典链条：智能爆炸、超级智能、致命错位。本文将各个环节以2023-2025年的实证记录为准。在古德的推测六十年后，没有观察到所需的现象（持续的递归自我完善、自主的战略意识或棘手的致命失调）。当前的生成模型仍然是狭隘的、经过统计训练的人工产物：强大、不透明且不完美，但缺乏使灾难性场景变得可信的属性。继Whittaker（2025a、2025b、2025c）和Zuboff（2019、2025）之后，我们认为，存在风险论点主要是作为一种意识形态的干扰，分散人们对监视资本主义的持续巩固和计算能力的极端集中的注意力。 2025 年人工智能投机泡沫进一步夸大了这一论点，其中数万亿投资于快速贬值的“数字生菜”硬件（McWilliams，2025）掩盖了收入滞后和失业增长，而不是预示着超级智能。到 2025 年 11 月，该论点仍然是一个被投机性金融泡沫放大的投机假设，而不是已证明的概率。
> **Abstract**: Two 2025 publications, "AI 2027" (Kokotajlo et al., 2025) and "If Anyone Builds It, Everyone Dies" (Yudkowsky & Soares, 2025), assert that superintelligent artificial intelligence will almost certainly destroy or render humanity obsolete within the next decade. Both rest on the classic chain formulated by Good (1965) and Bostrom (2014): intelligence explosion, superintelligence, lethal misalignment. This article subjects each link to the empirical record of 2023-2025. Sixty years after Good's speculation, none of the required phenomena (sustained recursive self-improvement, autonomous strategic awareness, or intractable lethal misalignment) have been observed. Current generative models remain narrow, statistically trained artefacts: powerful, opaque, and imperfect, but devoid of the properties that would make the catastrophic scenarios plausible. Following Whittaker (2025a, 2025b, 2025c) and Zuboff (2019, 2025), we argue that the existential-risk thesis functions primarily as an ideological distraction from the ongoing consolidation of surveillance capitalism and extreme concentration of computational power. The thesis is further inflated by the 2025 AI speculative bubble, where trillions in investments in rapidly depreciating "digital lettuce" hardware (McWilliams, 2025) mask lagging revenues and jobless growth rather than heralding superintelligence. The thesis remains, in November 2025, a speculative hypothesis amplified by a speculative financial bubble rather than a demonstrated probability.

【8】Artificial Intelligence Competence of K-12 Students Shapes Their AI Risk Perception: A Co-occurrence Network Analysis
- **标题**: K-12 学生的人工智能能力塑造了他们的人工智能风险感知：共现网络分析
- **链接**: https://arxiv.org/abs/2512.04115
> **作者**: Ville Heilala,Pieta Sikström,Mika Setälä,Tommi Kärkkäinen
> **摘要**: 随着人工智能 (AI) 越来越多地融入教育，了解学生如何看待其风险对于支持负责任和有效的采用至关重要。本研究旨在通过共现分析来研究芬兰 K-12 高中生 (n = 163) 感知的人工智能能力与风险之间的关系。学生们报告了他们对人工智能能力的自我认知以及对系统、机构和个人领域人工智能的担忧。研究结果表明，能力较低的学生强调个人和与学习相关的风险，例如创造力下降、缺乏批判性思维和误用，而能力较高的学生更关注系统性和制度性风险，包括偏见、不准确和作弊。这些差异表明，学生自我报告的人工智能能力与他们如何评估与人工智能教育 (AIED) 相关的风险和机遇有关。这项研究的结果强调了教育机构需要将人工智能素养纳入其课程、提供教师指导并为政策制定提供信息，以确保个性化的利用机会并将人工智能公平地融入 K-12 教育。
> **Abstract**: As artificial intelligence (AI) becomes increasingly integrated into education, understanding how students perceive its risks is essential for supporting responsible and effective adoption. This research aimed to examine the relationships between perceived AI competence and risks among Finnish K-12 upper secondary students (n = 163) by utilizing a co-occurrence analysis. Students reported their self-perceived AI competence and concerns related to AI across systemic, institutional, and personal domains. The findings showed that students with lower competence emphasized personal and learning-related risks, such as reduced creativity, lack of critical thinking, and misuse, whereas higher-competence students focused more on systemic and institutional risks, including bias, inaccuracy, and cheating. These differences suggest that students' self-reported AI competence is related to how they evaluate both the risks and opportunities associated with artificial intelligence in education (AIED). The results of this study highlight the need for educational institutions to incorporate AI literacy into their curricula, provide teacher guidance, and inform policy development to ensure personalized opportunities for utilization and equitable integration of AI into K-12 education.

【9】AI-Enabled grading with near-domain data for scaling feedback with human-level accuracy
- **标题**: 利用近域数据进行人工智能分级，以人类级别的精度缩放反馈
- **链接**: https://arxiv.org/abs/2512.04113
> **作者**: Shyam Agarwal,Ali Moghimi,Kevin C. Haudek
> **摘要**: 建构反应问题对于鼓励生成处理和测试学习者对核心概念的理解至关重要。然而，教师时间有限、班级规模大和其他资源限制对提供及时和详细的评估提出了重大挑战，而这对于整体教育体验至关重要。此外，提供及时和频繁的评估具有挑战性，因为手动评分是劳动密集型的，而自动评分则很复杂，难以推广到每种可能的响应场景。本文提出了一种新颖实用的方法来对简答构答题进行评分。我们讨论为什么这个问题具有挑战性，定义我们的方法适用的问题的性质，最后提出一个框架，教师可以使用该框架来评估学生的开放式回答，利用近域数据（例如前几年管理的类似问题的数据）。所提出的方法在某些情况下比最先进的机器学习模型以及非微调大型语言模型（如 GPT 3.5、GPT 4 和 GPT 4o）的性能要高出超过 10-20%，即使在为法学硕士提供了参考/模型答案之后也是如此。我们的框架不需要预先编写的评分标准，并且是根据实际的课堂环境明确设计的。我们的结果还揭示了有关从近域数据学习的令人兴奋的见解，包括我们所说的使用人工标记数据的准确性和数据优势，我们相信这是第一个将基于近域数据的自动简答评分问题形式化的工作。
> **Abstract**: Constructed-response questions are crucial to encourage generative processing and test a learner's understanding of core concepts. However, the limited availability of instructor time, large class sizes, and other resource constraints pose significant challenges in providing timely and detailed evaluation, which is crucial for a holistic educational experience. In addition, providing timely and frequent assessments is challenging since manual grading is labor intensive, and automated grading is complex to generalize to every possible response scenario. This paper proposes a novel and practical approach to grade short-answer constructed-response questions. We discuss why this problem is challenging, define the nature of questions on which our method works, and finally propose a framework that instructors can use to evaluate their students' open-responses, utilizing near-domain data like data from similar questions administered in previous years. The proposed method outperforms the state of the art machine learning models as well as non-fine-tuned large language models like GPT 3.5, GPT 4, and GPT 4o by a considerable margin of over 10-20% in some cases, even after providing the LLMs with reference/model answers. Our framework does not require pre-written grading rubrics and is designed explicitly with practical classroom settings in mind. Our results also reveal exciting insights about learning from near-domain data, including what we term as accuracy and data advantages using human-labeled data, and we believe this is the first work to formalize the problem of automated short answer grading based on the near-domain data.

【10】Responsible LLM Deployment for High-Stake Decisions by Decentralized Technologies and Human-AI Interactions
- **标题**: 通过去中心化技术和人机交互，负责任地部署法学硕士，以实现高风险决策
- **链接**: https://arxiv.org/abs/2512.04108
> **作者**: Swati Sachan,Theo Miller,Mai Phuong Nguyen
> **摘要**: 高风险决策领域越来越多地探索大型语言模型 (LLM) 在复杂决策任务中的潜力。然而，LLM 在现实环境中的部署在数据安全、受控环境之外的能力评估以及对抗性决策时的责任归属等方面提出了挑战。本文提出了一个通过人类积极参与负责任地部署基于法学硕士的决策支持系统的框架。它通过预部署阶段的多次迭代，集成了人类专家和开发人员之间的交互协作，以评估不确定样本并判断事后 XAI 技术提供的解释的稳定性。建议在组织内部署本地法学硕士，并使用区块链和 IPFS 等去中心化技术来创建法学硕士活动的不可变记录，以进行自动审计，以增强安全性并追溯责任。它在 Bert-large-uncased、Mistral 以及 LLaMA 2 和 3 模型上进行了测试，以评估支持负责任的商业贷款财务决策的能力。
> **Abstract**: High-stakes decision domains are increasingly exploring the potential of Large Language Models (LLMs) for complex decision-making tasks. However, LLM deployment in real-world settings presents challenges in data security, evaluation of its capabilities outside controlled environments, and accountability attribution in the event of adversarial decisions. This paper proposes a framework for responsible deployment of LLM-based decision-support systems through active human involvement. It integrates interactive collaboration between human experts and developers through multiple iterations at the pre-deployment stage to assess the uncertain samples and judge the stability of the explanation provided by post-hoc XAI techniques. Local LLM deployment within organizations and decentralized technologies, such as Blockchain and IPFS, are proposed to create immutable records of LLM activities for automated auditing to enhance security and trace back accountability. It was tested on Bert-large-uncased, Mistral, and LLaMA 2 and 3 models to assess the capability to support responsible financial decisions on business lending.

【11】Rethinking AI Evaluation in Education: The TEACH-AI Framework and Benchmark for Generative AI Assistants
- **标题**: 重新思考教育中的人工智能评估：TEACH-AI 框架和生成式人工智能助理的基准
- **链接**: https://arxiv.org/abs/2512.04107
> **作者**: Shi Ding,Brian Magerko
> **摘要**: 随着生成人工智能 (AI) 不断改变教育，大多数现有的人工智能评估主要依赖于准确性或任务效率等技术性能指标，而忽视了人类身份、学习者能动性、情境学习过程和道德考虑。在本文中，我们提出了 TEACH-AI（可信且有效的人工智能课堂启发式），这是一个独立于领域、以教学为基础、与利益相关者一致的框架，具有可衡量的指标和实用的工具包，用于指导教育环境中生成式人工智能系统的设计、开发和评估。基于广泛的文献回顾和综合，十个组成部分的评估框架和工具包清单为教育领域可扩展、价值一致的人工智能评估奠定了基础。 TEACH-AI 通过社会技术、教育、理论和应用视角重新思考“评估”，吸引人工智能和教育领域的设计师、开发人员、研究人员和政策制定者。我们的工作邀请社区重新考虑如何在教育中构建“有效”的人工智能，并设计模型评估方法，以促进共同创造、包容性以及对人类、社会和教育的长期影响。
> **Abstract**: As generative artificial intelligence (AI) continues to transform education, most existing AI evaluations rely primarily on technical performance metrics such as accuracy or task efficiency while overlooking human identity, learner agency, contextual learning processes, and ethical considerations. In this paper, we present TEACH-AI (Trustworthy and Effective AI Classroom Heuristics), a domain-independent, pedagogically grounded, and stakeholder-aligned framework with measurable indicators and a practical toolkit for guiding the design, development, and evaluation of generative AI systems in educational contexts. Built on an extensive literature review and synthesis, the ten-component assessment framework and toolkit checklist provide a foundation for scalable, value-aligned AI evaluation in education. TEACH-AI rethinks "evaluation" through sociotechnical, educational, theoretical, and applied lenses, engaging designers, developers, researchers, and policymakers across AI and education. Our work invites the community to reconsider what constructs "effective" AI in education and to design model evaluation approaches that promote co-creation, inclusivity, and long-term human, social, and educational impact.

【12】LegalWebAgent: Empowering Access to Justice via LLM-Based Web Agents
- **标题**: LegalWebAgent：通过基于 LLM 的网络代理增强诉诸司法的机会
- **链接**: https://arxiv.org/abs/2512.04105
> **作者**: Jinzhe Tan,Karim Benyekhlef
> **摘要**: 诉诸司法仍然是一个全球性挑战，许多公民在面临法律问题时仍然难以向司法系统寻求帮助。尽管互联网提供了丰富的法律信息和服务，但浏览复杂的网站、理解法律术语和填写程序表格仍然对诉诸司法构成障碍。本文介绍了 LegalWebAgent 框架，该框架采用由多模式大语言模型支持的网络代理来弥合普通公民诉诸司法的差距。该框架将大语言模型的自然语言理解能力与多模态感知相结合，实现了从用户查询到具体行动的完整过程。它分三个阶段运行：Ask 模块通过自然语言处理了解用户需求；浏览模块自主导航网页，与页面元素（包括表单和日历）交互，并从HTML结构和网页截图中提取信息；行动模块为用户综合信息或执行直接操作，例如填写表格和安排预订。为了评估其有效性，我们设计了涵盖15个现实任务的基准测试，模拟与魁北克民法用户相关的典型法律服务流程，从问题识别到程序操作。评估结果显示，LegalWebAgent 的最高成功率达到 86.7%，所有测试模型的平均成功率为 84.4%，在复杂的现实场景中展现出高度的自主性。
> **Abstract**: Access to justice remains a global challenge, with many citizens still finding it difficult to seek help from the justice system when facing legal issues. Although the internet provides abundant legal information and services, navigating complex websites, understanding legal terminology, and filling out procedural forms continue to pose barriers to accessing justice. This paper introduces the LegalWebAgent framework that employs a web agent powered by multimodal large language models to bridge the gap in access to justice for ordinary citizens. The framework combines the natural language understanding capabilities of large language models with multimodal perception, enabling a complete process from user query to concrete action. It operates in three stages: the Ask Module understands user needs through natural language processing; the Browse Module autonomously navigates webpages, interacts with page elements (including forms and calendars), and extracts information from HTML structures and webpage screenshots; the Act Module synthesizes information for users or performs direct actions like form completion and schedule booking. To evaluate its effectiveness, we designed a benchmark test covering 15 real-world tasks, simulating typical legal service processes relevant to Québec civil law users, from problem identification to procedural operations. Evaluation results show LegalWebAgent achieved a peak success rate of 86.7%, with an average of 84.4% across all tested models, demonstrating high autonomy in complex real-world scenarios.

【13】Lifting the Cage of Consent: A Techno-Legal Perspective on Evolvable Trust Relationships
- **标题**: 解除同意的牢笼：可演化信任关系的技术法律视角
- **链接**: https://arxiv.org/abs/2512.03674
> **作者**: Beatriz Esteves,Ruben Verborgh
> **摘要**: 那些关心隐私的人担心个人数据太容易易手。我们认为，实际的挑战恰恰相反：我们的数据流动得不够好，导致人们对可疑且常常非法的捷径的依赖，以求在当今数据驱动的经济中求生存。对 GDPR 等保护性立法的完全惩罚性解释，通过同样阻碍“做正确的事”和“做错误的事”的障碍，将婴儿和洗澡水一起倒掉，这是对道德选择与财务成本如何对应的严重错误翻译。只要有利于隐私的数据处理比现成的替代方案更昂贵或更复杂，经济上的需要将继续超过其法律上的要求。我们审查了现有立法，旨在促进互利互动，而不是狭隘地关注预防不良行为。在本文中，我们建议实施可进化的信任系统，作为一种可扩展的替代方案，以替代无处不在但已被彻底打破的不知情同意的错觉。我们描述了用于启动和维持长期信任关系的个性化、技术辅助的法律流程，使各方能够可靠且可持续地交换数据、商品和服务。我们的提案鼓励将额外的努力转向经济激励与社会激励的技术法律协调，提醒我们，尽管信任仍然是人类固有的概念，但技术可以支持人们发展和扩展他们的关系，以满足当前和未来数据环境日益复杂的需求。
> **Abstract**: Those concerned about privacy worry that personal data changes hands too easily. We argue that the actual challenge is the exact opposite: our data does not flow well enough, cultivating a reliance on questionable and often unlawful shortcuts in a desperate bid to survive within today's data-driven economy. Exclusively punitive interpretations of protective legislation such as the GDPR throw out the baby with the bathwater through barriers that equally hinder "doing the right thing" and "doing the wrong thing", in an abject mistranslation of how ethical choices correspond to financial cost. As long as privacy-friendly data treatment proves more expensive or complicated than readily available alternatives, economic imperatives will continue to outrank their legal counterparts. We examined existing legislation with the aim of facilitating mutually beneficial interactions, rather than more narrowly focusing on the prevention of undesired behaviors. In this article, we propose the implementation of evolvable trust systems as a scalable alternative to the omnipresent yet deeply broken delusion of ill-informed consent. We describe personalized, technology-assisted legal processes for initiating and maintaining long-term trust relationships, which enable parties to reliably and sustainably exchange data, goods, and services. Our proposal encourages a redirection of additional efforts towards the techno-legal alignment of economical incentives with societal ones, reminding us that - while trust remains an inherently human concept - technology can support people in evolving and scaling their relationships to meet the increasingly complex demands of current and future data landscapes.

## 分布式、并行和集群计算(cs.DC:Distributed, Parallel, and Cluster Computing)

【1】Counting Without Running: Evaluating LLMs' Reasoning About Code Complexity
- **标题**: 无需运行即可计数：评估法学硕士关于代码复杂性的推理
- **链接**: https://arxiv.org/abs/2512.04355
> **作者**: Gregory Bolet,Giorgis Georgakoudis,Konstantinos Parasyris,Harshitha Menon,Niranjan Hasabnis,Kirk W. Cameron,Gal Oren
> **摘要**: 现代 GPU 软件堆栈要求开发人员能够在启动内核之前预测性能瓶颈；错误判断上游浮点工作负载可能会导致调整、调度甚至硬件采购脱轨。然而，尽管代码生成取得了快速进展，当今的大型语言模型 (LLM) 很少经过这种前瞻性推理的测试。我们通过 gpuFLOPBench 缩小了这一差距，该基准要求模型通过预测从 HeCBench 提取的 577 个 CUDA 内核的单精度和双精度 FLOP 计数来“在不运行的情况下进行计数”，并用真实配置文件和八个执行属性进行注释，这些属性将可简单分析的代码与 FLOP 依赖于隐藏编译器或运行时行为的内核区分开来。评估当前的闭源推理模型显示出明显但不平衡的进展：最新的法学硕士在简单内核上实现了完美的分类，但每当因除法、内在数学函数或常见子表达式产生隐式 FLOP 时，仍然会产生多个数量级的错误。这些结果暴露了现有代码助手的核心局限性——无法内化特定于硬件的微代码效果——并将 gpuFLOPBench 定位为开发 LLM 工具的重点测试平台，该工具可以像经验丰富的 GPU 开发人员一样严格地推理性能。来源可在我们的存储库中找到：https://github.com/Scientific-Computing-Lab/gpuFLOPBench
> **Abstract**: Modern GPU software stacks demand developers who can anticipate performance bottlenecks before ever launching a kernel; misjudging floating-point workloads upstream can derail tuning, scheduling, and even hardware procurement. Yet despite rapid progress in code generation, today's Large Language Models (LLMs) are rarely tested on this kind of forward-looking reasoning. We close that gap with gpuFLOPBench, a benchmark that asks models to "count without running" by predicting single and double-precision FLOP counts for 577 CUDA kernels drawn from HeCBench, annotated with ground-truth profiles and eight execution attributes that distinguish trivially analyzable code from kernels whose FLOPs depend on hidden compiler or runtime behavior. Evaluating current closed-source reasoning models shows clear but uneven progress: the newest LLMs achieve perfect classification on straightforward kernels but still incur multiple order-of-magnitude errors whenever implicit FLOPs arise from division, intrinsic math functions, or common subexpressions. These results surface a core limitation of existing code assistants -- the inability to internalize hardware-specific microcode effects -- and position gpuFLOPBench as a focused testbed for developing LLM tooling that can reason about performance with the same rigor as experienced GPU developers. Sources are available at our repository: https://github.com/Scientific-Computing-Lab/gpuFLOPBench

## 数据结构和算法(cs.DS:Data Structures and Algorithms)

【1】A customizable inexact subgraph matching algorithm for attributed graphs
- **标题**: 一种可定制的属性图不精确子图匹配算法
- **链接**: https://arxiv.org/abs/2512.04280
> **作者**: Tatyana Benko,Rebecca Jones,Lucas Tate
> **摘要**: 图形通过对有关对象及其之间关系的信息进行编码，提供了一种表示数据的自然方式。随着收集和生成的数据量不断增加，通常需要定位图中对象之间的特定关系模式。给定一个较大的图和一个较小的图，人们可能希望识别较大目标图中较小查询图的实例。此任务称为子图识别或匹配。子图匹配在生物信息学、二元分析、模式识别和计算机视觉等领域很有帮助。在这些应用中，数据集经常包含噪声和错误，因此精确的子图匹配算法不适用。在本文中，我们介绍了一种用于不精确子图匹配的新的可定制算法。我们的算法利用现实世界数据集中经常出现的节点和边缘属性来缩小搜索空间。该算法在可以执行的子图匹配类型以及可以通过使用可修改的图编辑距离成本函数来配对节点来处理的数据集类型方面非常灵活。我们在族树图和控制流图上展示了它的有效性。
> **Abstract**: Graphs provide a natural way to represent data by encoding information about objects and the relationships between them. With the ever-increasing amount of data collected and generated, locating specific patterns of relationships between objects in a graph is often required. Given a larger graph and a smaller graph, one may wish to identify instances of the smaller query graph in the larger target graph. This task is called subgraph identification or matching. Subgraph matching is helpful in areas such as bioinformatics, binary analysis, pattern recognition, and computer vision. In these applications, datasets frequently contain noise and errors, thus exact subgraph matching algorithms do not apply. In this paper we introduce a new customizable algorithm for inexact subgraph matching. Our algorithm utilizes node and edge attributes which are often present in real-world datasets to narrow down the search space. The algorithm is flexible in the type of subgraph matching it can perform and the types of datasets it can process by its use of a modifiable graph edit distance cost function for pairing nodes. We show its effectiveness on family trees graphs and control-flow graphs.

【2】Improved Time-Space Tradeoffs for 3SUM-Indexing
- **标题**: 改进 3SUM 索引的时空权衡
- **链接**: https://arxiv.org/abs/2512.04258
> **作者**: Itai Dinur,Alexander Golovnev
> **摘要**: 3SUM-Indexing 是最近受到广泛关注的 3SUM 问题的预处理变体。该问题最著名的时空权衡是 $T S^3 = n^{6}$（最多对数因子），其中 $n$ 是输入整数的数量，$S$ 是预处理数据结构的长度，$T$ 是查询算法的运行时间。这种权衡是在 [KP19, GGHPV20] 中使用 Fiat-Naor 通用算法进行函数反演实现的。因此，[GGHPV20]询问是否可以通过利用3SUM-Indexing的结构来改进该算法。在本文中，我们利用 3SUM-Indexing 的结构给出 $T S = n^{2.5}$ 的时空权衡，这比 $n^{3/2} \ll S \ll n^{7/4}$ 范围内最著名的权衡要好。我们进一步将此改进扩展到 $k$SUM 索引问题（3SUM 索引的泛化）以及相关的 $k$XOR 索引问题，其中加法被 XOR 替换。此外，我们还针对间隙字符串索引和混乱索引问题改进了最著名的时空权衡，这些问题是与 3SUM 索引相关的众所周知的数据结构问题。我们的改进来自于将 Fiat-Naor 算法应用于 3SUM-Indexing 的替代方法。具体来说，我们通过将函数分解为具有某些属性的“子函数”来利用要反转的函数的结构。这使我们能够对 Fiat-Naor 算法（不直接适用于 3SUM 索引）进行改进，该算法是在 [GGPS23] 中以更大范围的参数获得的。我们相信，我们的技术可能有助于 Fiat-Naor 算法的其他依赖于应用程序的优化。
> **Abstract**: 3SUM-Indexing is a preprocessing variant of the 3SUM problem that has recently received a lot of attention. The best known time-space tradeoff for the problem is $T S^3 = n^{6}$ (up to logarithmic factors), where $n$ is the number of input integers, $S$ is the length of the preprocessed data structure, and $T$ is the running time of the query algorithm. This tradeoff was achieved in [KP19, GGHPV20] using the Fiat-Naor generic algorithm for Function Inversion. Consequently, [GGHPV20] asked whether this algorithm can be improved by leveraging the structure of 3SUM-Indexing. In this paper, we exploit the structure of 3SUM-Indexing to give a time-space tradeoff of $T S = n^{2.5}$, which is better than the best known one in the range $n^{3/2} \ll S \ll n^{7/4}$. We further extend this improvement to the $k$SUM-Indexing problem-a generalization of 3SUM-Indexing-and to the related $k$XOR-Indexing problem, where addition is replaced with XOR. Additionally, we improve the best known time-space tradeoffs for the Gapped String Indexing and Jumbled Indexing problems, which are well-known data structure problems related to 3SUM-Indexing. Our improvement comes from an alternative way to apply the Fiat-Naor algorithm to 3SUM-Indexing. Specifically, we exploit the structure of the function to be inverted by decomposing it into "sub-functions" with certain properties. This allows us to apply an improvement to the Fiat-Naor algorithm (which is not directly applicable to 3SUM-Indexing), obtained in [GGPS23] in a much larger range of parameters. We believe that our techniques may be useful in additional application-dependent optimizations of the Fiat-Naor algorithm.

【3】Aggregating maximal cliques in real-world graphs
- **标题**: 聚合现实世界图中的最大派系
- **链接**: https://arxiv.org/abs/2512.03960
> **作者**: Noga Alon,Sabyasachi Basu,Shweta Jain,Haim Kaplan,Jakub Łącki,Blair D. Sullivan
> **摘要**: 最大团枚举是一项基本的图挖掘任务，但其实用性往往受到计算复杂性和高度冗余输出的限制。为了应对这些挑战，我们引入了 \emph{$ρ$-dense aggregators}，这是一种简洁捕获最大派系结构的新颖方法。我们没有列出所有派系，而是识别边缘密度至少为 $ρ$ 的一小部分簇集合，这些簇共同包含每个最大派系。与最大团枚举相反，我们证明对于所有 $ρ< 1$，每个图都承认一个 \emph{sub-exponential} 大小的 $ρ$ 密集聚合器 $n^{O(\log_{1/ρ}n)}$，并提供实现此边界的算法。对于具有有限简并性的图（现实世界网络的典型特征），我们的算法以近线性时间运行并生成近线性大小聚合器。我们还建立了聚合器大小的匹配下限，证明我们的结果本质上是严格的。在对现实世界网络的实证评估中，我们展示了使用聚合器的显着实际好处：我们的算法始终比最先进的派枚举算法更快，$ρ=0.1$ 时中值加速超过 $6\times$（在极端情况下超过 $300\times$），同时提供更简洁的结构摘要。
> **Abstract**: Maximal clique enumeration is a fundamental graph mining task, but its utility is often limited by computational intractability and highly redundant output. To address these challenges, we introduce \emph{$ρ$-dense aggregators}, a novel approach that succinctly captures maximal clique structure. Instead of listing all cliques, we identify a small collection of clusters with edge density at least $ρ$ that collectively contain every maximal clique. In contrast to maximal clique enumeration, we prove that for all $ρ< 1$, every graph admits a $ρ$-dense aggregator of \emph{sub-exponential} size, $n^{O(\log_{1/ρ}n)}$, and provide an algorithm achieving this bound. For graphs with bounded degeneracy, a typical characteristic of real-world networks, our algorithm runs in near-linear time and produces near-linear size aggregators. We also establish a matching lower bound on aggregator size, proving our results are essentially tight. In an empirical evaluation on real-world networks, we demonstrate significant practical benefits for the use of aggregators: our algorithm is consistently faster than the state-of-the-art clique enumeration algorithm, with median speedups over $6\times$ for $ρ=0.1$ (and over $300\times$ in an extreme case), while delivering a much more concise structural summary.

【4】Robust Algorithms for Path and Cycle Problems in Geometric Intersection Graphs
- **标题**: 几何交图中路径和循环问题的鲁棒算法
- **链接**: https://arxiv.org/abs/2512.03843
> **作者**: Malory Marin,Jean-Florent Raymond,Rémi Watrigant
> **摘要**: 我们研究了针对 $\mathbb{R}^d$ 中类似大小的脂肪对象的交集图上的经典连通性问题的鲁棒次指数算法的设计。在此设置中，每个顶点对应一个几何对象，并且当且仅当两个顶点的对象相交时，两个顶点才是相邻的。我们引入了一种用于设计此类算法的新工具，我们将其称为 $λ$ 链接分区。这是将顶点集划分为高度连接的顶点组。至关重要的是，这样的划分可以在多项式时间内计算出来，并且不需要访问图的几何表示。我们将该框架应用于与图中的路径和循环相关的问题。首先，我们获得了第一个稳健的哈密顿路径和哈密顿循环算法，在 $\mathbb{R}^d$ 中类似大小的脂肪对象的交集图上运行时间为 $2^{O(n^{1-1/d})}$。这解决了 de Berg 等人的一个悬而未决的问题。 [STOC 2018]并从ETH-tight精确算法的角度完成了几何交集图上这些问题的研究。我们进一步将我们的方法扩展到参数化设置，并为任何固定维度 $d$ 中的长路径设计第一个稳健的次指数参数化算法。更准确地说，我们获得了一个在 $\mathbb{R}^d$ 中类似大小的脂肪对象的交集图上运行时间 $2^{O(k^{1-1/d}\log^2 k)}\, n^{O(1)}$ 的随机鲁棒算法，其中 $k$ 是自然参数。除了 $λ$ 链接分区之外，我们的算法还依赖于我们为几何交集图建立的低树宽模式覆盖定理，这可以被视为对 Marx-Pilipczuk [ESA 2017] 结果的改进。该结构结果可能具有独立利益。
> **Abstract**: We study the design of robust subexponential algorithms for classical connectivity problems on intersection graphs of similarly sized fat objects in $\mathbb{R}^d$. In this setting, each vertex corresponds to a geometric object, and two vertices are adjacent if and only if their objects intersect. We introduce a new tool for designing such algorithms, which we call a $λ$-linked partition. This is a partition of the vertex set into groups of highly connected vertices. Crucially, such a partition can be computed in polynomial time and does not require access to the geometric representation of the graph. We apply this framework to problems related to paths and cycles in graphs. First, we obtain the first robust ETH-tight algorithms for Hamiltonian Path and Hamiltonian Cycle, running in time $2^{O(n^{1-1/d})}$ on intersection graphs of similarly sized fat objects in $\mathbb{R}^d$. This resolves an open problem of de Berg et al. [STOC 2018] and completes the study of these problems on geometric intersection graphs from the viewpoint of ETH-tight exact algorithms. We further extend our approach to the parameterized setting and design the first robust subexponential parameterized algorithm for Long Path in any fixed dimension $d$. More precisely, we obtain a randomized robust algorithm running in time $2^{O(k^{1-1/d}\log^2 k)}\, n^{O(1)}$ on intersection graphs of similarly sized fat objects in $\mathbb{R}^d$, where $k$ is the natural parameter. Besides $λ$-linked partitions, our algorithm also relies on a low-treewidth pattern covering theorem that we establish for geometric intersection graphs, which may be viewed as a refinement of a result of Marx-Pilipczuk [ESA 2017]. This structural result may be of independent interest.

【5】Matrix Editing Meets Fair Clustering: Parameterized Algorithms and Complexity
- **标题**: 矩阵编辑遇到公平聚类：参数化算法和复杂性
- **链接**: https://arxiv.org/abs/2512.03718
> **作者**: Robert Ganian,Hung P. Hoang,Simon Wietheger
> **摘要**: 我们研究了计算离散向量的公平均值聚类的计算问题，它允许通过更改最多 $k$ 值将彩色矩阵编辑为具有很少不同颜色平衡行的等效公式。虽然在公平性忽略和公平设置中都是 NP 困难的，但众所周知，该问题在以前的“普通”设置中承认固定参数算法。作为我们的第一个贡献，即使对于高度受限的公平均值聚类实例，我们也排除了类似的算法。然后，我们继续获得问题的完整复杂性情况，并建立可处理性结果，其中捕获了三种规避我们获得的下限的方法：对问题实例施加额外的约束、固定参数近似或使用针对树状矩阵的替代参数化。
> **Abstract**: We study the computational problem of computing a fair means clustering of discrete vectors, which admits an equivalent formulation as editing a colored matrix into one with few distinct color-balanced rows by changing at most $k$ values. While NP-hard in both the fairness-oblivious and the fair settings, the problem is well-known to admit a fixed-parameter algorithm in the former ``vanilla'' setting. As our first contribution, we exclude an analogous algorithm even for highly restricted fair means clustering instances. We then proceed to obtain a full complexity landscape of the problem, and establish tractability results which capture three means of circumventing our obtained lower bound: placing additional constraints on the problem instances, fixed-parameter approximation, or using an alternative parameterization targeting tree-like matrices.

## 新兴技术(cs.ET:Emerging Technologies)

【1】AI/ML in 3GPP 5G Advanced - Services and Architecture
- **标题**: 3GPP 5G Advanced 中的 AI/ML - 服务和架构
- **链接**: https://arxiv.org/abs/2512.03728
> **作者**: Pradnya Taksande,Shwetha Kiran,Pranav Jha,Prasanna Chaporkar
> **摘要**: 移动网络标准机构第三代合作伙伴项目 (3GPP) 正处于第 19 版标准化的最后阶段，即将开始第 20 版。人工智能/机器学习 (AI/ML) 带来了技术范式转变，正在跨行业和垂直领域采用。自第 18 版以来，3GPP 一直在将 AI/ML 集成到 5G 先进系统中。本文重点介绍 3GPP 服务和系统方面 (SA) 技术规范组中第 19 版中引入的 AI/ML 相关技术进步和功能。这些进步涉及两个范式：(i) AI/ML 为 5G 先进系统（网络 AI）带来的增强，例如资源优化，以及 (ii) 为支持 AI/ML 应用（AI 网络）而对 5G 系统进行的增强，例如图像识别。
> **Abstract**: The 3rd Generation Partnership Project (3GPP), the standards body for mobile networks, is in the final phase of Release 19 standardization and is beginning Release 20. Artificial Intelligence/ Machine Learning (AI/ML) has brought about a paradigm shift in technology and it is being adopted across industries and verticals. 3GPP has been integrating AI/ML into the 5G advanced system since Release 18. This paper focuses on the AI/ML related technological advancements and features introduced in Release 19 within the Service and System Aspects (SA) Technical specifications group of 3GPP. The advancements relate to two paradigms: (i) enhancements that AI/ML brought to the 5G advanced system (AI for network), e.g. resource optimization, and (ii) enhancements that were made to the 5G system to support AI/ML applications (Network for AI), e.g. image recognition.

## 图形(cs.GR:Graphics)

【1】Radiance Meshes for Volumetric Reconstruction
- **标题**: 用于体积重建的辐射网格
- **链接**: https://arxiv.org/abs/2512.04076
> **作者**: Alexander Mai,Trevor Hedstrom,George Kopanas,Janne Kontkanen,Falko Kuester,Jonathan T. Barron
> **摘要**: 我们引入辐射网格，这是一种用 Delaunay 四面体化生成的恒定密度四面体单元表示辐射场的技术。与 Voronoi 图不同，Delaunay 四面体化生成现有硬件本身支持的简单三角形。因此，我们的模型能够使用光栅化和光线追踪来执行精确且快速的体积渲染。我们引入了一种新的光栅化方法，该方法可以在各种平台上实现比所有先前的辐射场表示（假设基元数量和分辨率相同）更快的渲染速度。优化 Delaunay 顶点的位置会引入拓扑不连续性（边缘翻转）。为了解决这个问题，我们使用了 Zip-NeRF 风格的主干，即使拓扑发生变化，它也允许我们表达平滑变化的场。我们的渲染方法精确评估体渲染方程，并在标准消费类硬件上实现高质量、实时视图合成。我们的四面体网格还适合各种令人兴奋的应用，包括鱼眼镜头畸变、基于物理的模拟、编辑和网格提取。
> **Abstract**: We introduce radiance meshes, a technique for representing radiance fields with constant density tetrahedral cells produced with a Delaunay tetrahedralization. Unlike a Voronoi diagram, a Delaunay tetrahedralization yields simple triangles that are natively supported by existing hardware. As such, our model is able to perform exact and fast volume rendering using both rasterization and ray-tracing. We introduce a new rasterization method that achieves faster rendering speeds than all prior radiance field representations (assuming an equivalent number of primitives and resolution) across a variety of platforms. Optimizing the positions of Delaunay vertices introduces topological discontinuities (edge flips). To solve this, we use a Zip-NeRF-style backbone which allows us to express a smoothly varying field even when the topology changes. Our rendering method exactly evaluates the volume rendering equation and enables high quality, real-time view synthesis on standard consumer hardware. Our tetrahedral meshes also lend themselves to a variety of exciting applications including fisheye lens distortion, physics-based simulation, editing, and mesh extraction.

## 计算机科学与博弈论(cs.GT:Computer Science and Game Theory)

【1】Sponsored Questions and How to Auction Them
- **标题**: 赞助问题以及如何拍卖它们
- **链接**: https://arxiv.org/abs/2512.03975
> **作者**: Kshipra Bhawalkar,Alexandros Psomas,Di Wang
> **摘要**: 在线平台使用广告将用户与相关产品和服务联系起来。一个关键的挑战是用户的搜索查询常常使他们的真实意图模糊不清。通常，平台根据可用信号被动预测相关性，并在某些情况下提供查询细化。从传统搜索到对话式人工智能的转变提供了一种新方法。当用户的查询不明确时，大型语言模型（LLM）可以主动提供一些澄清的后续提示。在本文中，我们考虑以下问题：如果其中一些后续提示可以“赞助”，即根据其广告潜力进行选择，会怎样？这些“建议位”应该如何分配？而且，这种新机制如何与可能随之而来的传统广告拍卖互动？本文介绍了用于设计和分析这些交互平台的形式模型。我们使用这个模型来研究一个关键的工程选择：是否最好构建一个端到端管道来共同优化用户交互和最终的广告拍卖，或者将它们解耦为建议时段和后续广告时段的单独机制。我们证明了可以采用 VCG 机制来共同优化赞助建议和随后的广告；虽然这一机制较为复杂，但它能取得高效、真实的结果。另一方面，我们证明了易于实施的模块化方法存在战略效率低下的问题：其无政府状态的代价是无限的。
> **Abstract**: Online platforms connect users with relevant products and services using ads. A key challenge is that a user's search query often leaves their true intent ambiguous. Typically, platforms passively predict relevance based on available signals and in some cases offer query refinements. The shift from traditional search to conversational AI provides a new approach. When a user's query is ambiguous, a Large Language Model (LLM) can proactively offer several clarifying follow-up prompts. In this paper we consider the following: what if some of these follow-up prompts can be ``sponsored,'' i.e., selected for their advertising potential. How should these ``suggestion slots'' be allocated? And, how does this new mechanism interact with the traditional ad auction that might follow? This paper introduces a formal model for designing and analyzing these interactive platforms. We use this model to investigate a critical engineering choice: whether it is better to build an end-to-end pipeline that jointly optimizes the user interaction and the final ad auction, or to decouple them into separate mechanisms for the suggestion slots and another for the subsequent ad slot. We show that the VCG mechanism can be adopted to jointly optimize the sponsored suggestion and the ads that follow; while this mechanism is more complex, it achieves outcomes that are efficient and truthful. On the other hand, we prove that the simple-to-implement modular approach suffers from strategic inefficiency: its Price of Anarchy is unbounded.

## 人机交互(cs.HC:Human-Computer Interaction)

【1】What is Beyond Presence? Dimensionality, Control, and Information Spaces
- **标题**: 什么是超越存在？维度、控制和信息空间
- **链接**: https://arxiv.org/abs/2512.04398
> **作者**: E. Ch'ng
> **摘要**: 存在之后是什么？空间临场感，即“身临其境”的感觉，不再是主要目标，而是虚拟现实的基本期望。 VR 发明六年多后，正在从一种技术系统转变为一种文化、社会和现象学媒介，提供作为不同现实模式的体验。主要关注知觉错觉的现有理论已不足以解释这些新兴的经验形式。需要一个新的框架来通过确定虚拟世界提供的关键技术和抽象维度来指导沉浸式环境的设计和评估。这些维度包括空间、地点、时间、社会、文化、认知和心理参数。核心论点是，沉浸式环境必须超越技术维度，利用更丰富的信息渠道来塑造用户体验。这种从现场到体验编排的转变邀请跨学科的创作者为有意义的沉浸式世界的设计和评估做出贡献。
> **Abstract**: What is after presence? Spatial presence, the sense of "being there", is becoming less of a primary objective and more of a baseline expectation of virtual reality. More than six decades after its invention, VR is shifting from a technical system into a cultural, social, and phenomenological medium, offering experiences that function as distinct modes of reality. Existing theories that focus primarily on perceptual illusions are no longer sufficient to account for these emerging forms of experience. A new framework is needed to guide the design and evaluation of immersive environments by identifying the key technical and abstract dimensions afforded by virtual worlds. These dimensions include spatial, placeness, temporal, social, cultural, cognitive, and psychological parameters. The central argument is that immersive environments must move beyond the technical dimension to leverage richer information channels that shape user experience. This shift from presence to experience orchestration invites creators across disciplines to contribute to the design and assessment of meaningful immersive worlds.

【2】Human-controllable AI: Meaningful Human Control
- **标题**: 人类可控的人工智能：有意义的人类控制
- **链接**: https://arxiv.org/abs/2512.04334
> **作者**: Chengke Liu,Wei Xu
> **摘要**: 开发人类可控的人工智能（AI）并实现有意义的人类控制（MHC）已成为应对这些挑战、确保人工智能领域的道德一致性和有效治理的重要原则。 MHC 也是以人为中心的人工智能（HCAI）研究和应用的关键焦点。本章系统地研究了人工智能中的 MHC，阐明了其基本原理和未来发展轨迹。 MHC不是简单的运营权，而是人类在AI决策中理解、干预和责任可追溯的统一，需要技术设计、AI治理和人类共同发挥作用。 MHC 确保人工智能自主服务人类而不限制技术进步。人类控制的方式需要与技术水平相匹配，人类的监督应该平衡对人工智能的信任与怀疑。对于未来的人工智能系统，MHC以人类可控为先决条件，要求：（1）具有嵌入式人类控制机制的技术架构； (2) 优化人机交互以更好地获取人类理解； (3) 协调智能和人类可控性的人工智能系统的演变。治理必须优先考虑 HCA​​I 战略：平衡创新和风险缓解的政策、超越技术精英主导的以人为本的参与框架，以及在全球范围内推广 MHC 作为保障 HCAI 发展的普遍治理范式。展望未来，需要加强人工智能系统可控性的跨学科研究，增强利益相关者的伦理和法律意识，超越简单化的技术设计视角，关注围绕人类控制的知识构建、复杂性解释和影响因素。通过培育 MHC，可以进一步推进人类可控人工智能的发展，从而提供 HCAI 系统。
> **Abstract**: Developing human-controllable artificial intelligence (AI) and achieving meaningful human control (MHC) has become a vital principle to address these challenges, ensuring ethical alignment and effective governance in AI. MHC is also a critical focus in human-centered AI (HCAI) research and application. This chapter systematically examines MHC in AI, articulating its foundational principles and future trajectory. MHC is not simply the right to operate, but the unity of human understanding, intervention, and the traceablity of responsibility in AI decision-making, which requires technological design, AI governance, and humans to play a role together. MHC ensures AI autonomy serves humans without constraining technological progress. The mode of human control needs to match the levels of technology, and human supervision should balance the trust and doubt of AI. For future AI systems, MHC mandates human controllability as a prerequisite, requiring: (1) technical architectures with embedded mechanisms for human control; (2) human-AI interactions optimized for better access to human understanding; and (3) the evolution of AI systems harmonizing intelligence and human controllability. Governance must prioritize HCAI strategies: policies balancing innovation and risk mitigation, human-centered participatory frameworks transcending technical elite dominance, and global promotion of MHC as a universal governance paradigm to safeguard HCAI development. Looking ahead, there is a need to strengthen interdisciplinary research on the controllability of AI systems, enhance ethical and legal awareness among stakeholders, moving beyond simplistic technology design perspectives, focus on the knowledge construction, complexity interpretation, and influencing factors surrounding human control. By fostering MHC, the development of human-controllable AI can be further advanced, delivering HCAI systems.

【3】ConsentDiff at Scale: Longitudinal Audits of Web Privacy Policy Changes and UI Frictions
- **标题**: 大规模 ConsentDiff：对 Web 隐私政策变更和 UI 摩擦的纵向审计
- **链接**: https://arxiv.org/abs/2512.04316
> **作者**: Haoze Guo
> **摘要**: 网络隐私是通过两个公共工件来体验的：策略文本中的站点言论，以及用户在同意界面期间需要采取的操作。在我们研究的广泛的横截面审计中，缺乏详细说明这些工件如何一起变化的纵向数据，以及接口是否真正按照其在政策中承诺的方式进行。 ConsentDiff 提供了纵向视图。我们构建了一个可重复的管道，每月对网站进行快照，在语义上对齐策略条款以跟踪条款级别的流失，并通过将 DOM 信号与屏幕截图提供的提示结合在一起对同意 UI 模式进行分类。我们引入了一种新颖的加权索赔-UI 对齐分数，将常见的保单索赔与可观察的谓词联系起来，并实现随时间、区域和垂直方向的比较。我们的测量表明，持续的政策变动、系统性的改变以消除高摩擦横幅设计，以及明显更高的一致性（在拒绝可见的情况下）和更低的摩擦。
> **Abstract**: Web privacy is experienced via two public artifacts: site utterances in policy texts, and the actions users are required to take during consent interfaces. In the extensive cross-section audits we've studied, there is a lack of longitudinal data detailing how these artifacts are changing together, and if interfaces are actually doing what they promise in policy. ConsentDiff provides that longitudinal view. We build a reproducible pipeline that snapshots sites every month, semantically aligns policy clauses to track clause-level churn, and classifies consent-UI patterns by pulling together DOM signals with cues provided by screenshots. We introduce a novel weighted claim-UI alignment score, connecting common policy claims to observable predicates, and enabling comparisons over time, regions, and verticals. Our measurements suggest continued policy churn, systematic changes to eliminate a higher-friction banner design, and significantly higher alignment where rejecting is visible and lower friction.

【4】Affordances of Digital and Blockchain-based Community Currencies: The Case of Sarafu Network in Kenya
- **标题**: 基于数字和区块链的社区货币的可供性：肯尼亚 Sarafu 网络的案例
- **链接**: https://arxiv.org/abs/2512.04030
> **作者**: Patricia Marcella Evite
> **摘要**: 社区货币（CC）一直在采用创新系统来克服发行纸币的实施障碍。本文采用定性方法，以肯尼亚 Sarafu 网络及其前身 CC 的数字化转型为例进行了案例研究。从 2010 年推出的原始代金券开始，Grassroots Economics 基金会于 2016 年推出了在功能手机上运行的数字界面，然后从 2018 年开始集成区块链技术，经历了几次迁移，然后自 2023 年起在 Celo 区块链上推出了当前的迭代，称为社区资产代金券。研究表明，利用人机交互的可供性，研究表明数字化和区块链提高了当地社区经济活动的便利性，无论是与模拟版本的 Sarafu 相比，通过提供更多功能，可以实现典型的市场交易以及传统的互惠劳动力交换。区块链的独特贡献包括实现持有税计算的自动化，以及通过一系列智能合约（也称为流动性池）促进的稳定币将代金券与主流货币系统联系起来。该研究还发现，区块链优势和用户界面复杂性之间存在固有的权衡。因此，平衡创新和社区需求仍然是一个挑战。
> **Abstract**: Community currencies (CCs) have been adopting innovative systems to overcome implementational hurdles from issuing paper currencies. Using a qualitative approach, this paper examined this digital transition of Sarafu Network in Kenya and its predecessor CCs as a case study. From the original vouchers launched in 2010, the foundation Grassroots Economics introduced a digital interface in 2016 that operates on a feature phone, and then integrated blockchain technology starting in 2018, undergoing several migrations before becoming settling on its current iteration called Community Asset Vouchers on the Celo blockchain since 2023. Using affordances from human-computer interaction, the research shows that digitalization and blockchain improved the facilitation of economic activities of the local communities, both their typical market transactions as well as traditional reciprocal labor exchanges, by offering more functionalities compared to the analog version of Sarafu. The unique contributions of blockchain include enabling automation of holding tax calculations and linking the vouchers to the mainstream monetary system via stablecoins facilitated by a series of smart contracts also known as the liquidity pool. The study also finds that there is an inherent trade-off between blockchain benefits and user interface complexity. Hence, balancing innovation and community needs remains a challenge.

【5】When to Say "Hi" - Learn to Open a Conversation with an in-the-wild Dataset
- **标题**: 何时说“嗨” - 学习如何与野外数据集展开对话
- **链接**: https://arxiv.org/abs/2512.03991
> **作者**: Michael Schiffmann,Felix Struth,Sabina Jeschke,Anja Richert
> **摘要**: 社交互动代理 (SIA) 的社交功能是用户与 SIA 之间成功、顺畅交互的关键。交互的成功开始是满足SIA交互的重要因素之一。对于 SIA 提供信息帮助的服务和信息任务，例如关于地点，掌握谈话的开头并识别由哪个对话者以及何时开始谈话是一项重要技能。因此，我们正在研究使用用户的肢体语言作为机器学习的输入来训练对话开始的程度，以确保交互的顺利对话开始。在本文中，我们提出了交互启动系统（IIS），我们使用野外数据集开发、训练和验证该系统。在波恩德意志博物馆的现场测试中，Furhat Robotics 的 Furhat 机器人被用作服务和信息点。在使用期间，我们收集了 \textit{N} = 201 个单用户交互的数据用于算法的训练。我们可以证明 IIS 所达到的性能可以得出这样的结论：该系统能够确定问候期和交互的开头。
> **Abstract**: The social capabilities of socially interactive agents (SIA) are a key to successful and smooth interactions between the user and the SIA. A successful start of the interaction is one of the essential factors for satisfying SIA interactions. For a service and information task in which the SIA helps with information, e.g. about the location, it is an important skill to master the opening of the conversation and to recognize which interlocutor opens the conversation and when. We are therefore investigating the extent to which the opening of the conversation can be trained using the user's body language as an input for machine learning to ensure smooth conversation starts for the interaction. In this paper we propose the Interaction Initiation System (IIS) which we developed, trained and validated using an in-the-wild data set. In a field test at the Deutsches Museum Bonn, a Furhat robot from Furhat Robotics was used as a service and information point. Over the period of use we collected the data of \textit{N} = 201 single user interactions for the training of the algorithms. We can show that the IIS, achieves a performance that allows the conclusion that this system is able to determine the greeting period and the opener of the interaction.

【6】HEART-Watch: A multimodal physiological dataset from a Google Pixel Watch across different physical states
- **标题**: HEART-Watch：来自 Google Pixel Watch 的跨不同物理状态的多模式生理数据集
- **链接**: https://arxiv.org/abs/2512.03988
> **作者**: Jathushan Kaetheeswaran,Boyi Ma,Ali Abedi,Milad Lankarany,Shehroz Khan
> **摘要**: 随着心血管疾病继续成为全球死亡的主要原因，消费级智能手表为全球普通消费者提供了一种新的个性化健康监测选择。为这些消费级设备开发和验证可靠的心血管监测算法需要来自不同参与者的真实生物信号数据。然而，具有同步心血管生物信号的公共消费级智能手表数据集的可用性是有限的，并且现有数据集在其参与者群体中不提供丰富的人口多样性，从而导致算法开发可能存在偏差。本文介绍了 HEART-Watch，这是一个多模态生理数据集，收集自时间同步的腕戴式 Google Pixel Watch 2 心电图 (ECG)、光电体积描记法和加速度计信号，这些信号来自 40 名健康成年人的不同队列，他们处于三种身体状态（坐着、站立和行走，并带有参考胸部心电图）。收集间歇性上臂血压测量和并发生物信号作为未来研究的额外生物标志物。介绍了动机、方法和结果的初步分析。 HEART-Watch 旨在支持针对不同人群的消费级智能手表心血管分析的强大算法的开发和基准测试。
> **Abstract**: Consumer-grade smartwatches offer a new personalized health monitoring option for general consumers globally as cardiovascular diseases continue to prevail as the leading cause of global mortality. The development and validation of reliable cardiovascular monitoring algorithms for these consumer-grade devices requires realistic biosignal data from diverse sets of participants. However, the availability of public consumer-grade smartwatch datasets with synchronized cardiovascular biosignals is limited, and existing datasets do not offer rich demographic diversity in their participant cohorts, leading to potentially biased algorithm development. This paper presents HEART-Watch, a multimodal physiological dataset collected from temporally synchronized wrist-worn Google Pixel Watch 2 electrocardiogram (ECG), photoplethysmography, and accelerometer signals from a diverse cohort of 40 healthy adults across three physical states - sitting, standing and walking with reference chest ECG. Intermittent upper arm blood pressure measurements and concurrent biosignals were collected as an additional biomarker for future research. The motivation, methodology, and initial analyses of results are presented. HEART-Watch is intended to support the development and benchmarking of robust algorithms for cardiovascular analyses on consumer-grade smartwatches across diverse populations.

【7】Classification of User Satisfaction in HRI with Social Signals in the Wild
- **标题**: HRI 中社交信号的用户满意度分类
- **链接**: https://arxiv.org/abs/2512.03945
> **作者**: Michael Schiffmann,Sabina Jeschke,Anja Richert
> **摘要**: 社交互动代理 (SIA) 正在各种场景中使用，并已接近高效部署。评估用户对 SIA 性能的满意度是设计用户和 SIA 之间交互的关键因素。目前，主观用户满意度主要通过问卷调查手动评估或通过系统指标间接评估。本研究通过分析社交信号检验用户满意度的自动分类，旨在增强 SIA 的手动和自主评估方法。在波恩德意志博物馆的现场试验期间，Furhat Robotics 的一位负责人被聘为服务和信息中心，收集“野外”数据集。该数据集包含 46 个单用户交互，包括问卷响应和视频数据。我们的方法侧重于根据时间序列分类自动对用户满意度进行分类。我们使用从身体姿势、面部表情的时间序列和物理距离导出的社会信号指标的时间序列。本研究比较了不同机器学习模型上的三种特征工程方法。结果证实了该方法能够有效地可靠地识别用户满意度较低的交互，而无需手动注释数据集。这种方法通过自动反馈机制提供了增强 SIA 性能和用户体验的巨大潜力。
> **Abstract**: Socially interactive agents (SIAs) are being used in various scenarios and are nearing productive deployment. Evaluating user satisfaction with SIAs' performance is a key factor in designing the interaction between the user and SIA. Currently, subjective user satisfaction is primarily assessed manually through questionnaires or indirectly via system metrics. This study examines the automatic classification of user satisfaction through analysis of social signals, aiming to enhance both manual and autonomous evaluation methods for SIAs. During a field trial at the Deutsches Museum Bonn, a Furhat Robotics head was employed as a service and information hub, collecting an "in-the-wild" dataset. This dataset comprises 46 single-user interactions, including questionnaire responses and video data. Our method focuses on automatically classifying user satisfaction based on time series classification. We use time series of social signal metrics derived from the body pose, time series of facial expressions, and physical distance. This study compares three feature engineering approaches on different machine learning models. The results confirm the method's effectiveness in reliably identifying interactions with low user satisfaction without the need for manually annotated datasets. This approach offers significant potential for enhancing SIA performance and user experience through automated feedback mechanisms.

【8】Adhera: A Human-Centered Health Informatics Solution for Reducing Informal Caregiver Burden through Improved Medication Adherence
- **标题**: Adhera：一种以人为本的健康信息学解决方案，通过改善用药依从性来减轻非正式护理人员的负担
- **链接**: https://arxiv.org/abs/2512.03878
> **作者**: Zhiyin Zhou
> **摘要**: 全球老年人口不断增长，加上医疗保健劳动力持续短缺，增加了对非正式护理人员的依赖，包括为慢性病患者提供无偿支持的家庭成员和朋友。在他们的日常职责中，药物管理仍然是最艰巨且最容易出错的任务之一。不遵守规定的治疗方案不仅会损害患者的治疗效果，还会加剧护理人员的压力、焦虑和疲劳。尽管数字医疗技术已经激增以解决依从性问题，但大多数解决方案仅专注于患者，而忽视了护理人员的信息和情感需求。本文介绍了 Adhera，这是一个包含护理人员的健康信息系统，旨在支持药物依从性，同时减轻护理人员的负担。这项研究采用混合方法研究设计，包括 15 次半结构化护理人员访谈、65 份调查回复和 5 次药剂师咨询，确定了三个主要挑战：与药物摄入不确定性相关的护理人员压力、与医疗保健专业人员的沟通不完整以及对现有数字工具的不信任。受 CeHRes 路线图 2.0 和设计与文化三重底线 (TBLD+C) 框架以及最近涉及护理人员的协同设计研究的启发，Athera 将配备传感器的智能药丸管理器与移动配套应用程序集成在一起，该应用程序记录服用事件、发送实时提醒，并为护理人员提供同步的依从性数据。初步评估表明，Adhera 增强了可视性，提高了护理人员的信心，并简化了用药程序。这项研究通过展示以人为本的设计和协作框架如何将技术创新与同理心驱动的护理结合起来，为健康信息学领域做出了贡献。
> **Abstract**: The growing global population of older adults, combined with ongoing healthcare workforce shortages, has increased reliance on informal caregivers, including family members and friends who provide unpaid support to individuals with chronic illnesses. Among their daily responsibilities, medication management remains one of the most demanding and error-prone tasks. Non-adherence to prescribed regimens not only undermines patient outcomes but also intensifies caregiver stress, anxiety, and fatigue. Although digital health technologies have proliferated to address adherence, most solutions focus exclusively on patients and neglect the informational and emotional needs of caregivers. This paper introduces Adhera, a caregiver-inclusive health informatics system designed to support medication adherence while reducing caregiver burden. Using a mixed-methods research design that included fifteen semi-structured caregiver interviews, sixty-five survey responses, and five pharmacist consultations, this study identified three primary challenges: caregiver stress related to uncertainty about medication intake, fragmented communication with healthcare professionals, and distrust in existing digital tools. Informed by the CeHRes Roadmap 2.0 and the Triple Bottom Line by Design and Culture (TBLD+C) framework, as well as recent co-design studies involving caregivers, Adhera integrates a sensor-equipped smart pill organizer with a mobile companion application that records intake events, sends real-time reminders, and provides caregivers with synchronized adherence data. Preliminary evaluation suggests that Adhera enhances visibility, improves caregiver confidence, and streamlines medication routines. This study contributes to the field of health informatics by demonstrating how human-centered design and collaborative frameworks can align technical innovation with empathy-driven care.

【9】Sleep Modulation: The Challenge of Transitioning from Open Loop to Closed Loop
- **标题**: 睡眠调节：从开环过渡到闭环的挑战
- **链接**: https://arxiv.org/abs/2512.03784
> **作者**: Guisong Liu,Jiansong Zhang,Yinpei Luo,Guoliang Wei,Shuqing Sun,Shiyang Deng,Pengfei Wei,Nanxi Chen
> **摘要**: 睡眠障碍已成为一个重要的全球健康问题，突出表明迫切需要有效且可广泛使用的干预技术。非侵入性脑刺激因其能够直接或间接调节神经活动而受到关注，从而以安全且不引人注目的方式促进睡眠增强。这类方法统称为睡眠调节。迄今为止，大多数睡眠调节研究都依赖于具有经验确定参数的开环范例，而实现个体适应和调节准确性仍然是一个遥远的目标。开环设计固有的范式特定限制是临床转化和家庭环境中大规模部署的主要障碍。在本文中，我们描述了睡眠调节的基本范式，批判性地研究了开环方法的内在局限性，并正式概念化了睡眠闭环调节。我们进一步对涉及五种常用调制技术的先前研究进行了全面综合，评估了它们在闭环框架内的潜在集成。最后，我们确定了构建有效的睡眠闭环调制系统的三个主要挑战：传感器解决方案选择、监测模型设计和调制策略设计，同时提出了潜在的解决方案。总的来说，这项工作旨在推动睡眠调节从开环系统向闭环系统的范式转变。
> **Abstract**: Sleep disorders have emerged as a critical global health issue, highlighting the urgent need for effective and widely accessible intervention technologies. Non-invasive brain stimulation has garnered attention as it enables direct or indirect modulation of neural activity, thereby promoting sleep enhancement in a safe and unobtrusive manner. This class of approaches is collectively referred to as sleep modulation. To date, the majority of sleep modulation research relies on open-loop paradigms with empirically determined parameters, while achieving individual adaptation and modulation accuracy remains a distant objective. The paradigm-specific constraints inherent to open-loop designs represent a major obstacle to clinical translation and large-scale deployment in home environments. In this paper, we delineate fundamental paradigms of sleep modulation, critically examine the intrinsic limitations of open-loop approaches, and formally conceptualize sleep closed-loop modulation. We further provide a comprehensive synthesis of prior studies involving five commonly employed modulation techniques, evaluating their potential integration within a closed-loop framework. Finally, we identify three primary challenges in constructing an effective sleep closed-loop modulation system: sensor solution selection, monitoring model design, and modulation strategy design, while also proposing potential solutions. Collectively, this work aims to advance the paradigm shift of sleep modulation from open-loop toward closed-loop systems.

【10】Head, posture, and full-body gestures in dyadic conversations
- **标题**: 二元对话中的头部、姿势和全身手势
- **链接**: https://arxiv.org/abs/2512.03636
> **作者**: Ľuboš Hládek,Bernhard U. Seeber
> **摘要**: 当面对面沟通由于背景噪音和干扰谈话者而变得困难时，视觉提示对于沟通成功的作用变得越来越重要。虽然之前的研究选择性地研究了头部或手部的运动，但在这里我们探索了在声学不利条件下头部、手部和整个身体的运动组合。我们假设，随着背景噪声水平的增加，手、头、躯干和腿的典型对话运动的频率增加，以支持说话者的角色，而听众则通过增加使用确认性头部姿势和头部和躯干运动来支持他们的角色，以提高信噪比。我们进行了一项二元对话实验，其中（n=8）正常听力参与者自由站立在视听虚拟环境中。通过新开发的典型会话动作标签系统来描述会话动作，并分析各个类型的频率。背景噪音水平的增加导致手势复杂性增加以及头部运动的调节没有清晰的模式。与说话时相比，人们在听的时候身体前倾得更多，头部动作也更少。对手部语音同步性的额外分析以及假设由于背景噪声导致的同步性损失表明，在中等声音水平下，随着标准偏差的增加，同步性略有下降。结果支持了之前在手势频率方面的发现，并且我们发现对语音手势同步性变化的支持有限。该作品揭示了全身的沟通模式，并举例说明了多模式适应沟通需求背景下的互动沟通。
> **Abstract**: When face-to-face communication becomes effortful due to background noise and interfering talkers, the role of visual cues becomes increasingly important for communication success. While previous research has selectively investigated head or hand movements, here we explore the combination of movements of head, hand and the whole body in acoustically adverse conditions. We hypothesize that with increasing background noise level, the frequency of typical conversational movements of hand, head, trunk, and legs increases to support the speakers role while the listeners support their role by increased use of confirmative head gestures and head and trunk movements to increase the signal-to-noise ratio. We conducted a dyadic conversation experiment in which (n=8) normal hearing participants stood freely in an audiovisual virtual environment. The conversational movements were described by a newly developed labeling system for typical conversational movements, and the frequency of individual types was analyzed. Increased levels of background noise led to increased hand-gesture complexity and modulation of head movements without a clear pattern. People leaned forward slightly more and used less head movements during listening than during speaking. Additional analysis of hand-speech synchrony with hypothesized loss of synchrony due to the background noise showed a modest decrease of synchrony in terms of increased standard deviation at moderate sound levels. The results support previous findings in terms of the gesturing frequency, and we found a limited support for the changes in speech-gesture synchrony. The work reveals communication patterns of the whole body and exemplifies interactive communication in context of multimodal adaptation to communication needs.

【11】Synthetic Cognitive Walkthrough: Aligning Large Language Model Performance with Human Cognitive Walkthrough
- **标题**: 综合认知演练：使大型语言模型性能与人类认知演练保持一致
- **链接**: https://arxiv.org/abs/2512.03568
> **作者**: Ruican Zhong,David W. McDonald,Gary Hsieh
> **摘要**: 进行认知演练 (CW) 等可用性测试可能成本高昂。具有视觉推理和 UI 导航功能的大型语言模型 (LLM) 的最新发展为 CW 自动化提供了机会。我们通过将法学硕士（GPT-4 和 Gemini-2.5-pro）的演练与人类参与者进行比较，探讨了它们是否可以模拟 CW 中的人类行为。虽然法学硕士可以导航界面并提供合理的理由，但他们的行为与人类不同。 LLM 推动的 CW 比人类实现了更高的任务完成率，遵循更优化的导航路径，同时识别出更少的潜在故障点。然而，后续研究表明，通过额外的提示，法学硕士可以预测人类识别的失败点，使他们的表现与人类参与者保持一致。我们的工作强调，虽然法学硕士可能无法完全复制人类行为，但它们可以用于扩展可用性演练并提供 UI 见解，从而为传统可用性测试提供宝贵的补充。
> **Abstract**: Conducting usability testing like cognitive walkthrough (CW) can be costly. Recent developments in large language models (LLMs), with visual reasoning and UI navigation capabilities, present opportunities to automate CW. We explored whether LLMs (GPT-4 and Gemini-2.5-pro) can simulate human behavior in CW by comparing their walkthroughs with human participants. While LLMs could navigate interfaces and provide reasonable rationales, their behavior differed from humans. LLM-prompted CW achieved higher task completion rates than humans and followed more optimal navigation paths, while identifying fewer potential failure points. However, follow-up studies demonstrated that with additional prompting, LLMs can predict human-identified failure points, aligning their performance with human participants. Our work highlights that while LLMs may not replicate human behaviors exactly, they can be leveraged for scaling usability walkthroughs and providing UI insights, offering a valuable complement to traditional usability testing.

【12】Left shifting analysis of Human-Autonomous Team interactions to analyse risks of autonomy in high-stakes AI systems
- **标题**: 对人类与自主团队交互的左移分析，以分析高风险人工智能系统中的自主风险
- **链接**: https://arxiv.org/abs/2512.03519
> **作者**: Ben Larwood,Oliver J. Sutton,Callum Cockburn
> **摘要**: 开发包含人工智能 (AI) 组件的高风险自主系统非常复杂；错误的后果可能是灾难性的，但为所有操作案例制定计划具有挑战性。在人类操作员面临压力的情况下，例如决策时间较短，失败的风险会加剧。对人工智能故障模式缺乏了解会阻碍这一点，从而阻碍人工智能在智能系统中的应用的稳健实施。这阻碍了早期风险识别，导致项目时间、风险和成本增加。系统工程和采办工程的一个关键原则是以测试和评估活动“左移”到系统生命周期的早期为中心，以允许“加速交付有效的[系统]”。因此，我们认为这种转变必须将人工智能故障案例分析作为系统生命周期设计阶段的一部分。我们提出的框架能够早期描述操作环境中人类自主团队（HAT）出现的风险。其基石是对人工智能故障模式的新分析，该分析建立在 LaMonica 等人于 2022 年提出的人类自治团队的开创性模型的基础上。通过对人类和自治系统之间的交互进行分析并探索每个方面的故障模式，我们的方法提供了一种系统地识别感兴趣系统的操作领域中的人类与人工智能交互风险的方法。对紧急行为的理解可以提高系统的稳健性，为此应在其操作设计领域的整个范围内进行分析。通过支持命令与控制 (C2) 系统的人工智能助手的示例用例说明了这种方法。
> **Abstract**: Developing high-stakes autonomous systems that include Artificial Intelligence (AI) components is complex; the consequences of errors can be catastrophic, yet it is challenging to plan for all operational cases. In stressful scenarios for the human operator, such as short decision-making timescales, the risk of failures is exacerbated. A lack of understanding of AI failure modes obstructs this and so blocks the robust implementation of applications of AI in smart systems. This prevents early risk identification, leading to increased time, risk and cost of projects. A key tenet of Systems Engineering and acquisition engineering is centred around a "left-shift" in test and evaluation activities to earlier in the system lifecycle, to allow for "accelerated delivery of [systems] that work". We argue it is therefore essential that this shift includes the analysis of AI failure cases as part of the design stages of the system life cycle. Our proposed framework enables the early characterisation of risks emerging from human-autonomy teaming (HAT) in operational contexts. The cornerstone of this is a new analysis of AI failure modes, built on the seminal modelling of human-autonomy teams laid out by LaMonica et al., 2022. Using the analysis of the interactions between human and autonomous systems and exploring the failure modes within each aspect, our approach provides a way to systematically identify human-AI interactions risks across the operational domain of the system of interest. The understanding of the emergent behaviour enables increased robustness of the system, for which the analysis should be undertaken over the whole scope of its operational design domain. This approach is illustrated through an example use case for an AI assistant supporting a Command & Control (C2) System.

【13】EMINDS: Understanding User Behavior Progression for Mental Health Exploration on Social Media
- **标题**: EMINDS：了解社交媒体上心理健康探索的用户行为进展
- **链接**: https://arxiv.org/abs/2512.03495
> **作者**: Rui Sheng,Yifang Wang,Xingbo Wang,Shun Dai,Qingyu Guo,Tai-Quan Peng,Huamin Qu,Dongyu Liu
> **摘要**: 心理健康是一个紧迫的社会问题，社会科学家越来越多地转向在线心理健康社区（OMHC）来分析用户行为数据以进行早期干预。然而，现有的序列挖掘技术不足以满足探索不同群体（例如恢复或恶化群体）的行为进展并跟踪行为对心理健康状况的潜在长期影响的迫切需要。为了解决这个问题，我们引入了 EMINDS，这是一种建立在新颖的自动挖掘管道基础上的可视化分析系统，可以提取不同的行为阶段，并评估频繁的阶段模式随着时间的推移对心理健康状况的潜在影响。该系统包括一组交互式可视化，总结了每个行为阶段的含义以及不同阶段模式的演变。我们采用以模式为中心的桑基图来揭示有关阶段模式对心理健康影响的上下文信息，帮助专家了解阶段模式前后序列的具体变化。我们通过两个案例研究和专家访谈评估了 EMINDS 的有效性和可用性，并通过分析 Reddit 上的用户行为来研究影响长期心理健康的潜在阶段模式。
> **Abstract**: Mental health is an urgent societal issue, and social scientists are increasingly turning to online mental health communities (OMHCs) to analyze user behavior data for early intervention. However, existing sequence mining techniques fall short of the urgent need to explore the behavior progression of different groups (e.g., recovery or deterioration groups) and track the potential long-term impact of behaviors on mental health status. To address this issue, we introduce EMINDS, a visual analytics system built on a novel automatic mining pipeline that extracts distinct behavior stages and assesses the potential impact of frequent stage patterns on mental health status over time. The system includes a set of interactive visualizations that summarize the meaning of each behavior stage and the evolution of different stage patterns. We feature a pattern-centric Sankey diagram to reveal contextual information about the impact of stage patterns on mental health, helping experts understand the specific changes in sequences before and after a stage pattern. We evaluated the effectiveness and usability of EMINDS through two case studies and expert interviews, which examined the potential stage patterns impacting long-term mental health by analyzing user behaviors on Reddit.

【14】CellScout: Visual Analytics for Mining Biomarkers in Cell State Discovery
- **标题**: CellScout：在细胞状态发现中挖掘生物标记的可视化分析
- **链接**: https://arxiv.org/abs/2512.03485
> **作者**: Rui Sheng,Zelin Zang,Jiachen Wang,Yan Luo,Zixin Chen,Yan Zhou,Shaolun Ruan,Huamin Qu
> **摘要**: 细胞状态发现对于理解生物系统和提高医疗效果至关重要。该过程的一个关键方面是识别定义特定细胞状态的不同生物标志物。然而，细胞状态和生物标志物的共同发现过程出现了困难：生物学家经常使用降维来可视化二维空间中的细胞。然后，他们通常将视觉上聚集的细胞解释为不同的状态，从中寻求识别独特的生物标志物。然而，由于集群内部的不一致，这种假设往往是无效的，使得该过程具有反复试验性和高度不确定性。因此，生物学家迫切需要有效的工具来帮助揭示不同细胞群与其潜在生物标志物之间隐藏的关联关系。为了解决这个问题，我们首先设计了一种基于专家混合 (MoE) 技术的机器学习算法，以识别细胞群和生物标志物之间有意义的关联。我们与生物学家合作进一步开发了可视化分析系统 CellScout，帮助他们探索和完善这些关联关系，以推进细胞状态的发现。我们通过专家访谈验证了我们的系统，并从中进一步选择了一个代表性案例来证明其在发现新细胞状态方面的有效性。
> **Abstract**: Cell state discovery is crucial for understanding biological systems and enhancing medical outcomes. A key aspect of this process is identifying distinct biomarkers that define specific cell states. However, difficulties arise from the co-discovery process of cell states and biomarkers: biologists often use dimensionality reduction to visualize cells in a two- dimensional space. Then they usually interpret visually clustered cells as distinct states, from which they seek to identify unique biomarkers. However, this assumption is often invalid due to internal inconsistencies in a cluster, making the process trial-and-error and highly uncertain. Therefore, biologists urgently need effective tools to help uncover the hidden association relationships between different cell populations and their potential biomarkers. To address this problem, we first designed a machine-learning algorithm based on the Mixture-of-Experts (MoE) technique to identify meaningful associations between cell populations and biomarkers. We further developed a visual analytics system, CellScout, in collaboration with biologists, to help them explore and refine these association relationships to advance cell state discovery. We validated our system through expert interviews, from which we further selected a representative case to demonstrate its effectiveness in discovering new cell states.

## 信息检索(cs.IR:Information Retrieval)

【1】M3DR: Towards Universal Multilingual Multimodal Document Retrieval
- **标题**: M3DR：迈向通用多语言多模式文档检索
- **链接**: https://arxiv.org/abs/2512.03514
> **作者**: Adithya S Kolavi,Vyoman Jain
> **摘要**: 多模式文档检索系统在对齐视觉和文本内容以进行语义搜索方面取得了巨大进展。然而，大多数现有方法仍然以英语为中心，限制了它们在多语言环境中的有效性。在这项工作中，我们提出了 M3DR（多语言多模式文档检索），这是一个旨在弥合跨语言差距的框架，从而实现跨不同语言和文化背景的适用性。 M3DR 利用合成的多语言文档数据并概括不同的视觉语言架构和模型大小，从而实现强大的跨语言和跨模式对齐。通过对比训练，我们的模型学习了文本和文档图像的统一表示，可以有效地跨语言传输。我们在 22 种不同类型的语言上验证了此功能，展示了跨语言和脚本变体的一致性能和适应性。我们进一步引入了一个全面的基准，可以捕获现实世界的多语言场景，评估单语言、多语言和混合语言设置下的模型。 M3DR 概括了单个密集向量和 ColBERT 风格的标记级多向量检索范例。我们的模型 NetraEmbed 和 ColNetraEmbed 实现了最先进的性能，在跨语言检索方面相对改进了约 150%。
> **Abstract**: Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.

## 信息论(cs.IT:Information Theory)

【1】Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing
- **标题**: 无线联合学习：通过信号处理重新思考边缘人工智能
- **链接**: https://arxiv.org/abs/2512.03719
> **作者**: Seyed Mohammad Azimi-Abarghouyi,Carlo Fischione,Kaibin Huang
> **摘要**: 空中联合学习 (AirFL) 是一种新兴范例，它将无线信号处理和分布式机器学习紧密集成，以在网络边缘实现可扩展的人工智能。通过利用无线信号的叠加特性，AirFL 同时执行学习过程的通信和模型聚合，从而显着减少延迟、带宽和能耗。本文提供了 AirFL 的教程，提出了三种设计方法的新颖分类：CSIT 感知、盲法和加权 AirFL。我们提供了关于理论基础、性能分析、复杂性考虑、实际局限性和前瞻性研究方向的全面指南。
> **Abstract**: Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions.

## 机器学习(cs.LG:Machine Learning)

【1】STeP-Diff: Spatio-Temporal Physics-Informed Diffusion Models for Mobile Fine-Grained Pollution Forecasting
- **标题**: STeP-Diff：用于移动细粒度污染预测的时空物理信息扩散模型
- **链接**: https://arxiv.org/abs/2512.04385
> **作者**: Nan Zhou,Weijie Hong,Huandong Wang,Jianfeng Zheng,Qiuhua Wang,Yali Song,Xiao-Ping Zhang,Yong Li,Xinlei Chen
> **摘要**: 细粒度的空气污染预测对于城市管理和健康建筑的发展至关重要。在汽车和公共汽车等移动平台上部署便携式传感器提供了一种低成本、易于维护且覆盖范围广的数据收集解决方案。然而，由于这些非专用移动平台的随机且不可控的运动模式，所产生的传感器数据通常不完整且在时间上不一致。通过探索扩散模型逆过程中的潜在训练模式，我们提出了时空物理信息扩散模型（STeP-Diff）。 STeP-Diff 利用 DeepONet 对测量的空间序列进行建模，并使用偏微分方程信息的扩散模型来根据不完整和时变数据预测时空场。通过偏微分方程约束的正则化框架，去噪过程渐近收敛于对流扩散动力学，确保预测既基于现实世界的测量，又与控制污染扩散的基本物理相一致。为了评估系统的性能，我们在两个城市部署了 59 个自行设计的便携式传感设备，运行 14 天来收集空气污染数据。与表现第二好的算法相比，我们的模型在 MAE 方面提高了 89.12%，在 RMSE 方面提高了 82.30%，在 MAPE 方面提高了 25.00%，广泛的评估表明 STeP-Diff 有效地捕捉了空气污染领域的时空依赖性。
> **Abstract**: Fine-grained air pollution forecasting is crucial for urban management and the development of healthy buildings. Deploying portable sensors on mobile platforms such as cars and buses offers a low-cost, easy-to-maintain, and wide-coverage data collection solution. However, due to the random and uncontrollable movement patterns of these non-dedicated mobile platforms, the resulting sensor data are often incomplete and temporally inconsistent. By exploring potential training patterns in the reverse process of diffusion models, we propose Spatio-Temporal Physics-Informed Diffusion Models (STeP-Diff). STeP-Diff leverages DeepONet to model the spatial sequence of measurements along with a PDE-informed diffusion model to forecast the spatio-temporal field from incomplete and time-varying data. Through a PDE-constrained regularization framework, the denoising process asymptotically converges to the convection-diffusion dynamics, ensuring that predictions are both grounded in real-world measurements and aligned with the fundamental physics governing pollution dispersion. To assess the performance of the system, we deployed 59 self-designed portable sensing devices in two cities, operating for 14 days to collect air pollution data. Compared to the second-best performing algorithm, our model achieved improvements of up to 89.12% in MAE, 82.30% in RMSE, and 25.00% in MAPE, with extensive evaluations demonstrating that STeP-Diff effectively captures the spatio-temporal dependencies in air pollution fields.

【2】SmartAlert: Implementing Machine Learning-Driven Clinical Decision Support for Inpatient Lab Utilization Reduction
- **标题**: SmartAlert：实施机器学习驱动的临床决策支持以减少住院实验室利用率
- **链接**: https://arxiv.org/abs/2512.04354
> **作者**: April S. Liang,Fatemeh Amrollahi,Yixing Jiang,Conor K. Corbin,Grace Y. E. Kim,David Mui,Trevor Crowell,Aakash Acharya,Sreedevi Mony,Soumya Punnathanam,Jack McKeown,Margaret Smith,Steven Lin,Arnold Milstein,Kevin Schulman,Jason Hom,Michael A. Pfeffer,Tho D. Pham,David Svec,Weihan Chu,Lisa Shieh,Christopher Sharp,Stephen P. Ma,Jonathan H. Chen
> **摘要**: 重复的实验室测试不太可能产生临床上有用的信息，这是一种常见的做法，会给患者带来负担并增加医疗费用。教育和反馈干预措施的成功有限，而一般测试顺序限制和电子警报阻碍了适当的临床护理。我们介绍并评估了 SmartAlert，这是一种集成到电子健康记录中的机器学习 (ML) 驱动的临床决策支持 (CDS) 系统，可预测稳定的实验室结果，以减少不必要的重复测试。本案例研究描述了 2024 年 8 月 15 日至 2025 年 3 月 15 日期间，在两家医院的 8 个急症监护病房的 9270 名入院患者中，部署针对全血细胞计数 (CBC) 利用的 SmartAlert 的实施过程、挑战和经验教训。结果显示，SmartAlert 显示后 52 小时内 CBC 结果数量显着减少（1.54 vs 1.82，p <0.01），且对二级安全性没有不利影响结果，重复测试相对减少 15%。实施经验教训包括对临床环境中概率模型预测的解释、利益相关者参与定义可接受的模型行为、在临床环境中部署复杂模型的治理流程、用户界面设计注意事项、与临床操作优先事项的一致性以及最终用户的定性反馈的价值。总之，由机器学习驱动的 CDS 系统由深思熟虑的实施和治理流程支持，可以为住院实验室检测提供精确指导，以安全地减少不必要的重复检测。
> **Abstract**: Repetitive laboratory testing unlikely to yield clinically useful information is a common practice that burdens patients and increases healthcare costs. Education and feedback interventions have limited success, while general test ordering restrictions and electronic alerts impede appropriate clinical care. We introduce and evaluate SmartAlert, a machine learning (ML)-driven clinical decision support (CDS) system integrated into the electronic health record that predicts stable laboratory results to reduce unnecessary repeat testing. This case study describes the implementation process, challenges, and lessons learned from deploying SmartAlert targeting complete blood count (CBC) utilization in a randomized controlled pilot across 9270 admissions in eight acute care units across two hospitals between August 15, 2024, and March 15, 2025. Results show significant decrease in number of CBC results within 52 hours of SmartAlert display (1.54 vs 1.82, p <0.01) without adverse effect on secondary safety outcomes, representing a 15% relative reduction in repetitive testing. Implementation lessons learned include interpretation of probabilistic model predictions in clinical contexts, stakeholder engagement to define acceptable model behavior, governance processes for deploying a complex model in a clinical environment, user interface design considerations, alignment with clinical operational priorities, and the value of qualitative feedback from end users. In conclusion, a machine learning-driven CDS system backed by a deliberate implementation and governance process can provide precision guidance on inpatient laboratory testing to safely reduce unnecessary repetitive testing.

【3】RGE-GCN: Recursive Gene Elimination with Graph Convolutional Networks for RNA-seq based Early Cancer Detection
- **标题**: RGE-GCN：使用图卷积网络进行递归基因消除，用于基于 RNA-seq 的早期癌症检测
- **链接**: https://arxiv.org/abs/2512.04333
> **作者**: Shreyas Shende,Varsha Narayanan,Vishal Fenn,Yiran Huang,Dincer Goksuluk,Gaurav Choudhary,Melih Agraz,Mengjia Xu
> **摘要**: 癌症的早期检测对于提高生存率起着关键作用，但从 RNA-seq 数据中识别可靠的生物标志物仍然是一个重大挑战。数据是高维的，传统的统计方法往往无法捕捉基因之间的复杂关系。在本研究中，我们引入了 RGE-GCN（图卷积网络的递归基因消除），这是一个将特征选择和分类结合在单个管道中的框架。我们的方法根据基因表达谱构建图表，使用图卷积网络对癌症与正常样本进行分类，并应用积分梯度来突出显示信息最丰富的基因。通过递归地删除不太相关的基因，该模型收敛到一组紧凑的生物标志物，这些生物标志物既可解释又可预测。我们根据合成数据以及真实世界的肺癌、肾癌和宫颈癌的 RNA-seq 队列评估了 RGE-GCN。在所有数据集中，该方法始终比 DESeq2、edgeR 和 limma-voom 等标准工具获得更高的准确度和 F1 分数。重要的是，选定的基因与众所周知的癌症通路相一致，包括 PI3K-AKT、MAPK、SUMOylation 和免疫调节。这些结果表明，RGE-GCN 有希望成为基于 RNA-seq 的早期癌症检测和生物标志物发现的通用方法 (https://rce-gcn.streamlit.app/ )。
> **Abstract**: Early detection of cancer plays a key role in improving survival rates, but identifying reliable biomarkers from RNA-seq data is still a major challenge. The data are high-dimensional, and conventional statistical methods often fail to capture the complex relationships between genes. In this study, we introduce RGE-GCN (Recursive Gene Elimination with Graph Convolutional Networks), a framework that combines feature selection and classification in a single pipeline. Our approach builds a graph from gene expression profiles, uses a Graph Convolutional Network to classify cancer versus normal samples, and applies Integrated Gradients to highlight the most informative genes. By recursively removing less relevant genes, the model converges to a compact set of biomarkers that are both interpretable and predictive. We evaluated RGE-GCN on synthetic data as well as real-world RNA-seq cohorts of lung, kidney, and cervical cancers. Across all datasets, the method consistently achieved higher accuracy and F1-scores than standard tools such as DESeq2, edgeR, and limma-voom. Importantly, the selected genes aligned with well-known cancer pathways including PI3K-AKT, MAPK, SUMOylation, and immune regulation. These results suggest that RGE-GCN shows promise as a generalizable approach for RNA-seq based early cancer detection and biomarker discovery (https://rce-gcn.streamlit.app/ ).

【4】Evaluating Long-Context Reasoning in LLM-Based WebAgents
- **标题**: 评估基于 LLM 的 WebAgent 中的长上下文推理
- **链接**: https://arxiv.org/abs/2512.04307
> **作者**: Andy Chung,Yichi Zhang,Kaixiang Lin,Aditya Rawal,Qiaozi Gao,Joyce Chai
> **摘要**: 随着基于大语言模型 (LLM) 的代理越来越多地融入日常数字交互中，它们在长期交互​​历史中进行推理的能力对于提供个性化和上下文感知的帮助变得至关重要。然而，这些代理在长上下文场景中的性能，尤其是在现实 Web 环境中运行的采取行动的 WebAgent，在很大程度上仍未得到探索。本文介绍了一个基准，用于通过顺序依赖的子任务来评估 WebAgent 的长上下文推理能力，这些子任务需要从扩展的交互历史中检索和应用信息。我们开发了一种新颖的评估框架，通过在相关子任务之间注入不相关的任务轨迹来模拟多会话用户交互，创建 25,000 到 150,000 个令牌的上下文。通过对四种流行模型 Claude-3.7、GPT-4.1、Llama 4 和 o4-mini 的广泛评估，我们观察到随着上下文长度的增加，性能急剧下降，成功率从基线条件下的 40-50% 下降到长上下文场景中的不到 10%。我们详细的错误分析表明，代理失败主要是由于陷入循环并失去对原始任务目标的跟踪。我们进一步提出了一种隐式 RAG 方法，该方法通过生成与任务相关的摘要来提供适度的改进，尽管长上下文推理的基本限制仍然存在。这些发现突出了在现实的长期用户交互场景中部署 WebAgent 的关键挑战，并为开发更强大的代理架构提供了见解，该架构能够在扩展的上下文中保持一致的任务执行。
> **Abstract**: As large language model (LLM)-based agents become increasingly integrated into daily digital interactions, their ability to reason across long interaction histories becomes crucial for providing personalized and contextually aware assistance. However, the performance of these agents in long context scenarios, particularly for action-taking WebAgents operating in realistic web environments, remains largely unexplored. This paper introduces a benchmark for evaluating long context reasoning capabilities of WebAgents through sequentially dependent subtasks that require retrieval and application of information from extended interaction histories. We develop a novel evaluation framework that simulates multi-session user interactions by injecting irrelevant task trajectories between dependent subtasks, creating contexts ranging from 25,000 to 150,000 tokens. Through extensive evaluation of four popular models, Claude-3.7, GPT-4.1, Llama 4, and o4-mini, we observe a dramatic performance degradation as context length increases, with success rates dropping from 40-50\% in baseline conditions to less than 10\% in long context scenarios. Our detailed error analysis reveals that agents primarily fail due to getting stuck in loops and losing track of original task objectives. We further propose an implicit RAG approach that provides modest improvements by generating task-relevant summaries, though fundamental limitations in long context reasoning persist. These findings highlight critical challenges for deploying WebAgents in realistic, long-term user interaction scenarios and provide insights for developing more robust agent architectures capable of maintaining coherent task execution across extended contexts.

【5】GRASP: GRouped Activation Shared Parameterization for Parameter-Efficient Fine-Tuning and Robust Inference of Transformers
- **标题**: GRASP：用于 Transformer 参数高效微调和鲁棒推理的分组激活共享参数化
- **链接**: https://arxiv.org/abs/2512.04296
> **作者**: Malyaban Bal,Abhronil Sengupta
> **摘要**: 参数高效微调 (PEFT) 通过仅更新大型预训练模型中的一小部分参数，为全模型自适应提供了可扩展的替代方案。我们引入了 GRASP - GRouped Activation Shared Parameterization - 一个轻量级的 PEFT 框架，它将所选层的 D 维标记表示划分为 K << D 组，并为每个组学习共享的缩放和移位向量。这种分组调制显着减少了可训练参数的数量，同时保留了模型学习特定任务特征的能力。在此基础上，我们进一步提出了 StochGRASP，它将高斯分布学习为对预训练权重的扰动，而不是确定性值。这种概率参数化与噪声感知损失函数公式相结合，可以对编程权重的硬件级可变性进行建模，并显着提高非理想推理条件下的鲁棒性，这是在基于边缘的新兴人工智能硬件上部署的重要要求。在 GLUE（RoBERTa-base 和 RoBERTa-large）和 E2E NLG（GPT-2 Medium）中，GRASP 的性能达到或超过了现有 PEFT 方法的性能，同时与 LoRA 和 BitFit 相比，可训练参数降低了一个数量级。在不同的噪声水平下，StochGRASP 的性能始终优于确定性变体，证明了其适用于节能且易产生噪声的硬件平台。
> **Abstract**: Parameter-efficient fine-tuning (PEFT) provides a scalable alternative to full-model adaptation by updating only a small subset of parameters in large pre-trained models. We introduce GRASP - GRouped Activation Shared Parameterization - a lightweight PEFT framework that partitions the D-dimensional token representations of selected layers into K << D groups and learns a shared scaling and shifting vector for each group. This grouped modulation reduces the number of trainable parameters significantly while preserving the ability of the model to learn task-specific features. Building on this formulation, we further propose StochGRASP, which learns Gaussian distributions as perturbations to the pre-trained weights rather than deterministic values. This probabilistic parameterization along with a noise-aware loss function formulation enables modelling hardware-level variability in programmed weights and significantly improves robustness under non-ideal inference conditions-an important requirement for deployment on edge-based emerging AI hardware. Across GLUE (RoBERTa-base & RoBERTa-large) and E2E NLG (GPT-2 Medium), GRASP matches or exceeds the performance of established PEFT methods while achieving an order of magnitude reduction in trainable parameters compared to LoRA and BitFit. Under varying levels of noise, StochGRASP consistently outperforms deterministic variants, demonstrating its suitability for energy-efficient and noise-prone hardware platforms.

【6】Bootstrapped Mixed Rewards for RL Post-Training: Injecting Canonical Action Order
- **标题**: RL 训练后的自举混合奖励：注入规范动作顺序
- **链接**: https://arxiv.org/abs/2512.04277
> **作者**: Prakhar Gupta,Vaibhav Gupta
> **摘要**: 使用强化学习 (RL) 进行后训练通常会优化单个标量目标，并忽略生成解决方案的结构。我们询问仅在强化学习后训练期间使用的规范求解器排序的标量提示，即使在对随机解序列进行微调时，是否也能提高性能。在数独上，我们通过对随机求解顺序进行标准微调来训练 Transformer，然后使用组相对策略优化 (GRPO) 对其进行后训练，并获得两个奖励：单元格准确性和当模型的发射顺序与求解器顺序一致时增加的排序奖励。为了清楚地比较信号，我们通过固定混合将它们组合起来，并使用简单的自举缩放来均衡初始化时的分量幅度。混合奖励通常优于仅单元优化——最佳混合比在随机顺序上训练的仅微调模型产生更高的测试精度，并且在准确性上接近在求解器顺序序列上训练的仅微调模型。这些结果表明，粗排序信号可以将 RL 训练后引向解算器顺序轨迹，而无需修改监督数据或架构。
> **Abstract**: Post-training with reinforcement learning (RL) typically optimizes a single scalar objective and ignores structure in how solutions are produced. We ask whether a scalar hint toward a canonical solver ordering, used only during RL post-training, improves performance even when fine-tuned on randomized solution sequences. On Sudoku, we train a Transformer with standard fine-tuning on randomized solving orders, then post-train it with Group Relative Policy Optimization (GRPO) with two rewards: cell accuracy and an ordering reward that increases when the model's emission order aligns with the solver order. To compare signals cleanly, we combine them via fixed mixtures and use a simple bootstrapped scaling to equalize component magnitudes at initialization. Mixed rewards generally outperform cell-only optimization--the best mixture yields substantially higher test accuracy than the fine-tuned-only model trained on random-order and approaches the fine-tuned-only model trained on solver-order sequences in accuracy. These results suggest that coarse ordering signals can steer RL post-training toward solver-order trajectories without modifying supervised data or architecture.

【7】The Initialization Determines Whether In-Context Learning Is Gradient Descent
- **标题**: 初始化决定上下文学习是否是梯度下降
- **链接**: https://arxiv.org/abs/2512.04268
> **作者**: Shifeng Xie,Rui Yuan,Simone Rossi,Thomas Hannagan
> **摘要**: 大型语言模型（LLM）中的上下文学习（ICL）是一个引人注目的现象，但其基本机制仍然只有部分被了解。之前的工作将线性自注意力（LSA）与梯度下降（GD）联系起来，这种联系主要是在零均值高斯先验和 GD 零初始化的简化条件下建立的。然而，随后的研究通过强调其过于严格的假设来挑战这种简化的观点，并证明在多层或非线性注意力等条件下，自注意力执行类似优化的推理，类似于但不同于 GD。我们研究了多头 LSA 如何在更现实的条件下逼近 GD，特别是在 ICL 的线性回归公式中纳入非零高斯先验均值时。我们首先通过引入查询的初始估计（称为初始猜测）来扩展多头 LSA 嵌入矩阵。我们证明了 ICL 线性回归设置所需磁头数量的上限。我们的实验证实了这一结果，并进一步观察到单步 GD 和多头 LSA 之间的性能差距仍然存在。为了解决这个问题，我们引入了 yq-LSA，它是单头 LSA 的简单概括，具有可训练的初始猜测 yq。我们从理论上建立了 yq-LSA 的功能，并为线性回归任务提供实验验证，从而扩展了连接 ICL 和 GD 的理论。最后，受到我们在线性回归案例中的发现的启发，我们考虑了广泛的法学硕士增强了初始猜测能力，并表明它们在语义相似性任务上的性能得到了提高。
> **Abstract**: In-context learning (ICL) in large language models (LLMs) is a striking phenomenon, yet its underlying mechanisms remain only partially understood. Previous work connects linear self-attention (LSA) to gradient descent (GD), this connection has primarily been established under simplified conditions with zero-mean Gaussian priors and zero initialization for GD. However, subsequent studies have challenged this simplified view by highlighting its overly restrictive assumptions, demonstrating instead that under conditions such as multi-layer or nonlinear attention, self-attention performs optimization-like inference, akin to but distinct from GD. We investigate how multi-head LSA approximates GD under more realistic conditions specifically when incorporating non-zero Gaussian prior means in linear regression formulations of ICL. We first extend multi-head LSA embedding matrix by introducing an initial estimation of the query, referred to as the initial guess. We prove an upper bound on the number of heads needed for ICL linear regression setup. Our experiments confirm this result and further observe that a performance gap between one-step GD and multi-head LSA persists. To address this gap, we introduce yq-LSA, a simple generalization of single-head LSA with a trainable initial guess yq. We theoretically establish the capabilities of yq-LSA and provide experimental validation on linear regression tasks, thereby extending the theory that bridges ICL and GD. Finally, inspired by our findings in the case of linear regression, we consider widespread LLMs augmented with initial guess capabilities, and show that their performance is improved on a semantic similarity task.

【8】Studying Various Activation Functions and Non-IID Data for Machine Learning Model Robustness
- **标题**: 研究各种激活函数和非独立同分布数据以提高机器学习模型的鲁棒性
- **链接**: https://arxiv.org/abs/2512.04264
> **作者**: Long Dang,Thushari Hapuarachchi,Kaiqi Xiong,Jing Lin
> **摘要**: 对抗性训练是提高机器学习（ML）模型鲁棒性的有效方法。大多数现有研究通常考虑修正线性单元（ReLU）激活函数和集中式训练环境。在本文中，我们通过集中环境中的对抗性训练，使用十种不同的激活函数来研究 ML 模型的鲁棒性，并探索联邦学习环境中的 ML 模型的鲁棒性。在集中式环境中，我们首先提出了一种先进的对抗性训练方法，通过结合模型架构变化、软标签、简化的数据增强和不同的学习率来提高 ML 模型的鲁棒性。然后，除了 ReLU 之外，我们还对十个著名的激活函数进行了广泛的实验，以更好地了解它们如何影响 ML 模型的鲁棒性。此外，我们将所提出的对抗性训练方法扩展到联邦学习环境，其中考虑了独立同分布（IID）和非 IID 数据设置。我们提出的集中式对抗训练方法在 CIFAR-10 上针对快速梯度符号攻击分别实现了 77.08% 和 67.96% 的自然鲁棒准确度。对 10 个激活函数的实验表明 ReLU 通常表现最好。然而，在联邦学习环境中，鲁棒精度显着下降，尤其是在非 IID 数据上。为了解决非独立同分布数据情况下性能显着下降的问题，我们引入了数据共享，并在使用 40% 数据共享时分别实现了 70.09% 和 54.79% 的自然鲁棒精度，超过了 CalFAT 算法。也就是说，适当比例的数据共享可以显着提高机器学习模型的鲁棒性，这对于某些实际应用程序很有用。
> **Abstract**: Adversarial training is an effective method to improve the machine learning (ML) model robustness. Most existing studies typically consider the Rectified linear unit (ReLU) activation function and centralized training environments. In this paper, we study the ML model robustness using ten different activation functions through adversarial training in centralized environments and explore the ML model robustness in federal learning environments. In the centralized environment, we first propose an advanced adversarial training approach to improving the ML model robustness by incorporating model architecture change, soft labeling, simplified data augmentation, and varying learning rates. Then, we conduct extensive experiments on ten well-known activation functions in addition to ReLU to better understand how they impact the ML model robustness. Furthermore, we extend the proposed adversarial training approach to the federal learning environment, where both independent and identically distributed (IID) and non-IID data settings are considered. Our proposed centralized adversarial training approach achieves a natural and robust accuracy of 77.08% and 67.96%, respectively on CIFAR-10 against the fast gradient sign attacks. Experiments on ten activation functions reveal ReLU usually performs best. In the federated learning environment, however, the robust accuracy decreases significantly, especially on non-IID data. To address the significant performance drop in the non-IID data case, we introduce data sharing and achieve the natural and robust accuracy of 70.09% and 54.79%, respectively, surpassing the CalFAT algorithm, when 40% data sharing is used. That is, a proper percentage of data sharing can significantly improve the ML model robustness, which is useful to some real-world applications.

【9】Fine-Tuning ChemBERTa for Predicting Inhibitory Activity Against TDP1 Using Deep Learning
- **标题**: 使用深度学习微调 ChemBERTa 以预测 TDP1 的抑制活性
- **链接**: https://arxiv.org/abs/2512.04252
> **作者**: Baichuan Zeng
> **摘要**: 预测小分子对酪氨酰 DNA 磷酸二酯酶 1 (TDP1) 的抑制效力仍然是早期药物发现中的一个关键挑战，酪氨酰 DNA 磷酸二酯酶 1 是克服癌症化疗耐药性的关键靶点。我们提出了一个深度学习框架，使用预先训练的化学语言模型 ChemBERTa 的微调变体，对来自分子简化分子输入行输入系统 (SMILES) 字符串的 pIC50 值进行定量回归。利用包含 177,092 种化合物的大规模共识数据集，我们在分层数据分割和样本加权下系统地评估了两种预训练策略 - 掩码语言模型 (MLM) 和掩码令牌回归 (MTR)，以解决严重的活动不平衡问题，其中只有 2.1% 是活跃的。我们的方法在回归精度和虚拟筛选实用性方面都优于经典基线随机预测器，并且与随机森林相比具有竞争性的性能，在排名最高的预测中实现了高富集因子 EF@1% 17.4 和精度 Precision@1% 37.4。由此产生的模型经过严格的消融和超参数研究验证，提供了一个强大的、可立即部署的工具，用于优先考虑 TDP1 抑制剂进行实验测试。通过直接从 SMILES 实现准确、无 3D 结构的 pIC50 预测，这项工作展示了化学转化剂在加速特定靶点药物发现方面的变革潜力。
> **Abstract**: Predicting the inhibitory potency of small molecules against Tyrosyl-DNA Phosphodiesterase 1 (TDP1)-a key target in overcoming cancer chemoresistance-remains a critical challenge in early drug discovery. We present a deep learning framework for the quantitative regression of pIC50 values from molecular Simplified Molecular Input Line Entry System (SMILES) strings using fine-tuned variants of ChemBERTa, a pre-trained chemical language model. Leveraging a large-scale consensus dataset of 177,092 compounds, we systematically evaluate two pre-training strategies-Masked Language Modeling (MLM) and Masked Token Regression (MTR)-under stratified data splits and sample weighting to address severe activity imbalance which only 2.1% are active. Our approach outperforms classical baselines Random Predictor in both regression accuracy and virtual screening utility, and has competitive performance compared to Random Forest, achieving high enrichment factor EF@1% 17.4 and precision Precision@1% 37.4 among top-ranked predictions. The resulting model, validated through rigorous ablation and hyperparameter studies, provides a robust, ready-to-deploy tool for prioritizing TDP1 inhibitors for experimental testing. By enabling accurate, 3D-structure-free pIC50 prediction directly from SMILES, this work demonstrates the transformative potential of chemical transformers in accelerating target-specific drug discovery.

【10】Network of Theseus (like the ship)
- **标题**: 忒修斯网络（如船）
- **链接**: https://arxiv.org/abs/2512.04198
> **作者**: Vighnesh Subramaniam,Colin Conwell,Boris Katz,Andrei Barbu,Brian Cheung
> **摘要**: 深度学习的一个标准假设是，神经网络架构引入的归纳偏差必须从训练到推理持续存在。您训练的架构就是您部署的架构。由于优化困难，这种假设限制了社区选择可能具有理想效率或设计属性的架构。我们用忒修斯网络（NoT）挑战这一假设，这是一种逐步将经过训练的甚至未经训练的引导网络架构部分地转换为完全不同的目标网络架构的方法，同时保留引导网络的性能。在每个阶段，引导网络架构中的组件逐渐被目标架构模块替换，并通过代表性相似性度量进行对齐。即使在架构发生重大变化的情况下，此过程也很大程度上保留了引导网络的功能 - 例如，将卷积网络转换为多层感知器，或将 GPT-2 转换为循环神经网络。通过将优化与部署解耦，NoT 扩展了可行的推理时间架构的空间，为更好的准确性与效率权衡提供了机会，并支持对架构设计空间进行更直接的探索。
> **Abstract**: A standard assumption in deep learning is that the inductive bias introduced by a neural network architecture must persist from training through inference. The architecture you train with is the architecture you deploy. This assumption constrains the community from selecting architectures that may have desirable efficiency or design properties due to difficulties with optimization. We challenge this assumption with Network of Theseus (NoT), a method for progressively converting a trained, or even untrained, guide network architecture part-by-part into an entirely different target network architecture while preserving the performance of the guide network. At each stage, components in the guide network architecture are incrementally replaced with target architecture modules and aligned via representational similarity metrics. This procedure largely preserves the functionality of the guide network even under substantial architectural changes-for example, converting a convolutional network into a multilayer perceptron, or GPT-2 into a recurrent neural network. By decoupling optimization from deployment, NoT expands the space of viable inference-time architectures, opening opportunities for better accuracy-efficiency tradeoffs and enabling more directed exploration of the architectural design space.

【11】BEP: A Binary Error Propagation Algorithm for Binary Neural Networks Training
- **标题**: BEP：一种用于二元神经网络训练的二元误差传播算法
- **链接**: https://arxiv.org/abs/2512.04189
> **作者**: Luca Colombo,Fabrizio Pittorino,Daniele Zambon,Carlo Baldassi,Manuel Roveri,Cesare Alippi
> **摘要**: 二元神经网络 (BNN) 将权重和激活限制为二进制值，可大幅降低计算复杂性、内存占用和能耗。这些优点使它们特别适合部署在资源受限的设备上。然而，由于变量的离散性质，通过基于梯度的优化来训练 BNN 仍然具有挑战性。主要的方法是量化感知训练，通过使用替代梯度来规避这个问题。然而，该方法需要维护潜在的全精度参数并使用浮点运算执行向后传递，从而在训练期间丧失了二进制运算的效率。虽然存在基于局部学习规则的替代方法，但它们不适合全局信用分配和多层架构中的反向传播错误。本文介绍了二元误差传播 (BEP)，这是第一个建立反向传播链规则的有原则的离散模拟的学习算法。这种机制使得表示为二进制向量的误差信号能够通过神经网络的多层向后传播。 BEP 完全对二进制变量进行操作，所有前向和后向计算仅使用按位运算执行。至关重要的是，这使得 BEP 成为第一个为递归神经网络架构提供端到端二进制训练的解决方案。我们在多层感知器和循环神经网络上验证了 BEP 的有效性，证明测试准确率分别提高了 +6.89% 和 +10.57%。所提出的算法作为开源存储库发布。
> **Abstract**: Binary Neural Networks (BNNs), which constrain both weights and activations to binary values, offer substantial reductions in computational complexity, memory footprint, and energy consumption. These advantages make them particularly well suited for deployment on resource-constrained devices. However, training BNNs via gradient-based optimization remains challenging due to the discrete nature of their variables. The dominant approach, quantization-aware training, circumvents this issue by employing surrogate gradients. Yet, this method requires maintaining latent full-precision parameters and performing the backward pass with floating-point arithmetic, thereby forfeiting the efficiency of binary operations during training. While alternative approaches based on local learning rules exist, they are unsuitable for global credit assignment and for back-propagating errors in multi-layer architectures. This paper introduces Binary Error Propagation (BEP), the first learning algorithm to establish a principled, discrete analog of the backpropagation chain rule. This mechanism enables error signals, represented as binary vectors, to be propagated backward through multiple layers of a neural network. BEP operates entirely on binary variables, with all forward and backward computations performed using only bitwise operations. Crucially, this makes BEP the first solution to enable end-to-end binary training for recurrent neural network architectures. We validate the effectiveness of BEP on both multi-layer perceptrons and recurrent neural networks, demonstrating gains of up to +6.89% and +10.57% in test accuracy, respectively. The proposed algorithm is released as an open-source repository.

【12】Fare Comparison App of Uber, Ola and Rapido
- **标题**: Uber、Ola 和 Rapido 的票价比较应用程序
- **链接**: https://arxiv.org/abs/2512.04065
> **作者**: Ashlesha Gopinath Sawant,Sahil S. Jadhav,Vidhan R. Jain,Shriraj S. Jagtap,Prachi Jadhav,Soham Jadhav,Ichha Raina
> **摘要**: 在当今日益发展的世界中，拥有 Ola、Uber 和 Rapido 等良好的叫车服务非常重要，因为它对我们的日常交通非常重要。用户经常面临选择最合适、最高效的乘车方式的困难，这样既具有成本效益，又可以在更短的时间内到达目的地。该项目为您提供了一个网络应用程序，通过向用户提供 Ola、Uber、Rapido 之间针对用户输入的目的地的票价比较，帮助您选择对您最有利的乘车服务。后端用于获取数据，为用户提供乘车票价比较，最终使用Python提供最佳选择。本研究论文还解决了使用 API、Android Studios 模拟器、Appium 和位置比较访问数据时面临的问题和挑战。因此，该项目的目的是为用户提供网约车服务的透明度，提高效率，为用户提供更好的体验。
> **Abstract**: In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.

【13】MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking
- **标题**: MarkTune：改善开放权重 LLM 水印中的质量与可检测性权衡
- **链接**: https://arxiv.org/abs/2512.04044
> **作者**: Yizhou Zhao,Zhiwei Steven Wu,Adam Block
> **摘要**: 水印旨在将隐藏信号嵌入生成的文本中，当访问密钥时可以可靠地检测到这些信号。开放权重语言模型对此类水印方案提出了严峻的挑战，因为一旦模型权重公开，当代方法中占主导地位的推理时间干预就无法强制执行。现有的开放权重模型造水技术，例如最近提出的 GaussMark，通常依赖于对模型权重的微小修改，这可以产生那些配备密钥的人可检测到的信号，但要实现与推理时间水印相当的检测能力，通常需要权重扰动，这会显着降低生成质量。我们引入了 MarkTune，这是一个理论上有原则的、策略上的微调框架，它将 GaussMark 信号视为奖励，同时针对文本质量的下降进行正则化。我们推导出 MarkTune 作为 GaussMark 的改进，并证明 MarkTune 通过在模型表示空间内引导更细粒度、水印感知的权重更新，同时保持生成质量，持续改进 GaussMark 的质量与可检测性权衡。根据经验，我们表明 MarkTune 将 GaussMark 的质量可检测性边界推向接近推理时间水印的边界，对释义和微调攻击保持鲁棒性，并表现出很强的泛化性：在一个数据集上微调的模型在未见过的数据集上保留了大量的水印检测能力。总之，这些结果使 MarkTune 成为将强大的高质量水印嵌入到开放权重 LM 中的通用策略。
> **Abstract**: Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.

【14】Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning
- **标题**: 引导流策略：从离线强化学习中的高价值行为中学习
- **链接**: https://arxiv.org/abs/2512.03973
> **作者**: Franki Nguimatsia Tiofack,Théotime Le Hellard,Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier
> **摘要**: 离线强化学习通常依赖于行为正则化，强制策略保持接近数据集分布。然而，此类方法无法区分其正则化组件中的高价值和低价值动作。我们引入了引导流策略（GFP），它将多步流匹配策略与精炼的单步参与者结合起来。参与者通过加权行为克隆来指导流策略，以专注于从数据集中克隆高价值动作，而不是不加区别地模仿所有状态-动作对。反过来，流策略限制参与者与数据集的最佳转换保持一致，同时最大化批评者。这种相互指导使 GFP 能够在 OGBench、Minari 和 D4RL 基准测试中的 144 个状态和基于像素的任务中实现最先进的性能，并在次优数据集和具有挑战性的任务上获得显着收益。网页：https://simple-robotics.github.io/publications/guided-flow-policy/
> **Abstract**: Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/

【15】Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment
- **标题**: 可持续制造的超维计算：初步评估
- **链接**: https://arxiv.org/abs/2512.03864
> **作者**: Danny Hoang,Anandkumar Patel,Ruimen Chen,Rajiv Malhotra,Farhad Imani
> **摘要**: 智能制造可以显着提高效率并降低能耗，但人工智能模型的能源需求可能会抵消这些收益。本研究利用智能加工中基于原位传感的几何质量预测来比较常见人工智能模型的能耗、精度和速度。引入超维计算 (HDC) 作为替代方案，实现与传统模型相当的精度，同时大幅降低能耗，训练能耗降低 200$\times$，推理能耗降低 175 至 1000$\times$。此外，HDC 将训练时间减少了 200$\times$，推理时间减少了 300 至 600$\times$，展示了其节能智能制造的潜力。
> **Abstract**: Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\times$ for training and 175 to 1000$\times$ for inference. Furthermore, HDC reduces training times by 200$\times$ and inference times by 300 to 600$\times$, showcasing its potential for energy-efficient smart manufacturing.

【16】Scalable Decision Focused Learning via Online Trainable Surrogates
- **标题**: 通过在线可训练代理进行可扩展的以决策为中心的学习
- **链接**: https://arxiv.org/abs/2512.03861
> **作者**: Gaetano Signorelli,Michele Lombardi
> **摘要**: 决策支持系统通常依赖于解决复杂的优化问题，这些问题可能需要事先估计不确定的参数。最近的研究表明，使用传统训练的估计器来完成此任务可能会导致次优解决方案。使用实际决策成本作为损失函数（称为决策聚焦学习）可以解决这个问题，但在训练时会严重损失可扩展性。为了解决这个问题，我们提出了一种基于用有效替代方法代替昂贵的损失函数评估的加速方法。与之前定义的替代方法不同，我们的方法依赖于无偏估计量，降低了虚假局部最优的风险，并且可以提供有关其局部置信度的信息，允许人们在需要时切换到后备方法。此外，代理是针对黑盒设置而设计的，可以补偿优化模型的简化并在成本计算期间考虑追索行为。在我们的结果中，该方法减少了昂贵的内部求解器调用，其解决方案质量可与其他最先进的技术相媲美。
> **Abstract**: Decision support systems often rely on solving complex optimization problems that may require to estimate uncertain parameters beforehand. Recent studies have shown how using traditionally trained estimators for this task can lead to suboptimal solutions. Using the actual decision cost as a loss function (called Decision Focused Learning) can address this issue, but with a severe loss of scalability at training time. To address this issue, we propose an acceleration method based on replacing costly loss function evaluations with an efficient surrogate. Unlike previously defined surrogates, our approach relies on unbiased estimators reducing the risk of spurious local optima and can provide information on its local confidence allowing one to switch to a fallback method when needed. Furthermore, the surrogate is designed for a black-box setting, which enables compensating for simplifications in the optimization model and account- ing for recourse actions during cost computation. In our results, the method reduces costly inner solver calls, with a solution quality comparable to other state-of-the-art techniques.

【17】DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training
- **标题**: DVPO：基于分配价值模型的 LLM 培训后政策优化
- **链接**: https://arxiv.org/abs/2512.03847
> **作者**: Dingwei Zhu,Zhiheng Xi,Shihan Dou,Yuhui Wang,Sixian Li,Junjie Ye,Honglin Guo,Shichun Liu,Chenhao Huang,Yajie Yang,Junlin Shang,Senjie Jin,Ming Zhang,Jiazheng Zhang,Caishuang Huang,Yunke Zhang,Demei Yan,Yuran Wang,Tao Gui
> **摘要**: 强化学习 (RL) 在 LLM 后期培训中表现出强大的性能，但现实世界的部署通常涉及嘈杂或不完整的监督。在这种情况下，复杂且不可靠的监督信号可能会破坏训练的稳定性并损害泛化能力。虽然最坏情况优化（例如，RFQI、CQL）和基于平均值的方法（例如，PPO、GRPO）等现有方法可以提高稳定性，但它们往往忽视泛化性，并可能产生过于保守的策略，导致在不同的实际场景中表现不均匀。为此，我们引入了DVPO（具有风险感知策略优化的分布价值建模），这是一种新的强化学习框架，它将条件风险理论与分布价值建模相结合，以更好地平衡鲁棒性和泛化性。 DVPO 学习代币级别的价值分布以提供细粒度的监督，并应用非对称风险正则化来塑造分布尾部：它收缩下尾部以抑制噪声负偏差，同时扩展上尾部以保持探索性多样性。在多轮对话、数学推理和科学 QA 方面的广泛实验和分析中，DVPO 在噪声监督下始终优于 PPO、GRPO 和基于 Bellman 的稳健 PPO，显示出其在现实世界中 LLM 后期培训的潜力。
> **Abstract**: Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.

【18】Quantum Topological Graph Neural Networks for Detecting Complex Fraud Patterns
- **标题**: 用于检测复杂欺诈模式的量子拓扑图神经网络
- **链接**: https://arxiv.org/abs/2512.03696
> **作者**: Mohammad Doost,Mohammad Manthouri
> **摘要**: 我们提出了一种新颖的 QTGNN 框架，用于检测大规模金融网络中的欺诈交易。通过集成量子嵌入、变分图卷积和拓扑数据分析，QTGNN 捕获复杂的交易动态和表明欺诈的结构异常。该方法包括具有纠缠增强功能的量子数据嵌入、具有非线性动力学的变分量子图卷积、高阶拓扑不变量的提取、具有自适应优化的混合量子经典异常学习以及通过拓扑归因进行可解释的决策。严格的收敛保证确保在嘈杂的中规模量子（NISQ）设备上进行稳定的训练，而拓扑签名的稳定性提供了强大的欺诈检测。该框架通过电路简化和图形采样针对 NISQ 硬件进行了优化，可扩展到大型交易网络。对 PaySim 和 Elliptic 等金融数据集的模拟，使用 ROC-AUC、精度和误报率等指标，根据经典和量子基线对 QTGNN 进行基准测试。消融研究评估了量子嵌入、拓扑特征、非线性通道和混合学习的贡献。 QTGNN 为金融欺诈检测、桥接量子机器学习、图论和拓扑分析提供了理论上合理、可解释且实用的解决方案。
> **Abstract**: We propose a novel QTGNN framework for detecting fraudulent transactions in large-scale financial networks. By integrating quantum embedding, variational graph convolutions, and topological data analysis, QTGNN captures complex transaction dynamics and structural anomalies indicative of fraud. The methodology includes quantum data embedding with entanglement enhancement, variational quantum graph convolutions with non-linear dynamics, extraction of higher-order topological invariants, hybrid quantum-classical anomaly learning with adaptive optimization, and interpretable decision-making via topological attribution. Rigorous convergence guarantees ensure stable training on noisy intermediate-scale quantum (NISQ) devices, while stability of topological signatures provides robust fraud detection. Optimized for NISQ hardware with circuit simplifications and graph sampling, the framework scales to large transaction networks. Simulations on financial datasets, such as PaySim and Elliptic, benchmark QTGNN against classical and quantum baselines, using metrics like ROC-AUC, precision, and false positive rate. An ablation study evaluates the contributions of quantum embeddings, topological features, non-linear channels, and hybrid learning. QTGNN offers a theoretically sound, interpretable, and practical solution for financial fraud detection, bridging quantum machine learning, graph theory, and topological analysis.

【19】Dynamically Scaled Activation Steering
- **标题**: 动态缩放激活转向
- **链接**: https://arxiv.org/abs/2512.03661
> **作者**: Alex Ferrando,Xavier Suau,Jordi Gonzàlez,Pau Rodriguez
> **摘要**: 激活引导已成为引导生成模型的行为达到预期结果（例如毒性减轻）的强大方法。然而，大多数现有方法对所有输入统一应用干预措施，当不需要转向时会降低模型性能。我们引入动态缩放激活转向 (DSAS)，这是一种与方法无关的转向框架，可将何时转向与如何转向脱钩。 DSAS 自适应地调节跨层和输入的现有转向转换的强度，仅在检测到不良行为时进行强力干​​预。在生成时，DSAS 计算上下文相关的缩放因子，有选择地调整任何转向方法的强度。我们还展示了如何将 DSAS 与转向功能一起进行端到端联合优化。当与现有的转向方法相结合时，DSAS 相对于单独的转向不断改进帕累托前沿，从而在毒性减轻和效用保留之间实现更好的权衡。我们通过将 DSAS 应用于文本到图像扩散模型来进一步证明 DSAS 的通用性，展示自适应转向如何允许对特定概念进行调制。最后，DSAS 引入了最小的计算开销，同时提高了可解释性，查明哪些令牌需要转向以及需要转向多少。
> **Abstract**: Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.

【20】Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting
- **标题**: 用于多步能源预测的循环时间编码和混合深度集成
- **链接**: https://arxiv.org/abs/2512.03656
> **作者**: Salim Khazem,Houssam Kanso
> **摘要**: 准确的用电量预测对于需求管理和智能电网运营至关重要。本文介绍了一个统一的深度学习框架，它将循环时间编码与混合 LSTM-CNN 架构相结合，以增强多步能量预测。我们使用正弦余弦编码系统地转换基于日历的属性，以保留周期性结构并通过相关性分析评估其预测相关性。为了利用长期季节性效应和短期局部模式，我们采用了一个由 LSTM、CNN 和专门针对每个预测范围的 MLP 回归器元学习器组成的集成模型。使用一年的国民消费数据集，我们进行了广泛的实验研究，包括使用或不使用循环编码和日历特征的消融分析，以及与文献中既定基线的比较。结果表明，在所有七个预测范围内都取得了一致的改进，我们的混合模型比单独的架构和先前的方法实现了更低的 RMSE 和 MAE。这些发现证实了将循环时间表示与互补深度学习结构相结合的好处。据我们所知，这是第一个在统一的短期能源预测框架内联合评估时间编码、基于日历的特征和混合集成架构的工作。
> **Abstract**: Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.

【21】The promising potential of vision language models for the generation of textual weather forecasts
- **标题**: 视觉语言模型在生成文本天气预报方面的巨大潜力
- **链接**: https://arxiv.org/abs/2512.03623
> **作者**: Edward C. C. Steele,Dinesh Mane,Emilio Monti,Luis Orus,Rebecca Chantrill-Cheyette,Matthew Couch,Kirstine I. Dale,Simon Eaton,Govindarajan Rangarajan,Amir Majlesi,Steven Ramsdale,Michael Sharpe,Craig Smith,Jonathan Smith,Rebecca Yates,Holly Ellis,Charles Ewen
> **摘要**: 尽管多模式基础模型的能力很有前景，但它们在气象产品和服务生成方面的应用仍处于起步阶段。为了加速愿望和采用，我们探索了视觉语言模型的新颖用途，直接从视频编码的网格天气数据编写标志性的航运预测文本。这些早期结果表明，在提高气象企业内外的生产效率和服务创新方面，有广阔的可扩展技术机会。
> **Abstract**: Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.

【22】When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate
- **标题**: 什么时候、多长时间以及多少？通过学习屏蔽和聚合进行时间序列回归的可解释神经网络
- **链接**: https://arxiv.org/abs/2512.03578
> **作者**: Florent Forest,Amaury Wei,Olga Fink
> **摘要**: 时间序列外在回归（TSER）是指从输入时间序列预测连续目标变量的任务。它出现在许多领域，包括医疗保健、金融、环境监测和工程。在这些情况下，准确的预测和可靠的推理都至关重要。尽管最先进的 TSER 模型具有强大的预测性能，但它们通常作为黑匣子运行，因此很难理解哪些时间模式驱动其决策。事后可解释性技术（例如特征归因）旨在解释模型如何得出预测，但通常会产生粗糙、嘈杂或不稳定的解释。最近，基于概念、加法分解或符号回归的本质上可解释的方法已经成为有前途的替代方案。然而，这些方法仍然有限：它们需要对概念本身进行明确的监督，通常无法捕获时间序列特征之间的交互，缺乏对复杂时间模式的表达，并且难以扩展到高维多元数据。为了解决这些限制，我们提出了 MAGNETS（时间序列的掩模和聚合网络），这是一种本质上可解释的 TSER 神经架构。 MAGNETS 无需任何注释即可学习一组紧凑的人类可理解的概念。每个概念都对应于对选定输入特征的学习的、基于掩码的聚合，明确揭示哪些特征驱动预测以及它们在序列中何时重要。预测是通过透明的附加结构将这些学到的概念组合而成的，从而可以清楚地了解模型的决策过程。
> **Abstract**: Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable explanations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data. To address these limitations, we propose MAGNETS (Mask-and-AGgregate NEtwork for Time Series), an inherently interpretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requiring any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model's decision process.

【23】Physics-Driven Learning Framework for Tomographic Tactile Sensing
- **标题**: 用于断层触觉传感的物理驱动学习框架
- **链接**: https://arxiv.org/abs/2512.03512
> **作者**: Xuanxuan Yang,Xiuyang Zhang,Haofeng Chen,Gang Ma,Xiaojie Wang
> **摘要**: 电阻抗断层扫描 (EIT) 由于其最小的布线和形状灵活性，为大面积触觉传感提供了一种有吸引力的解决方案，但其非线性逆问题通常会导致严重的伪影和不准确的接触重建。这项工作提出了 PhyDNN，这是一种物理驱动的深度重建框架，它将 EIT 前向模型直接嵌入到学习目标中。通过共同最小化预测电导率图和真实电导率图之间的差异并加强与前向偏微分方程的一致性，PhyDNN 减少了深层网络的黑盒性质，并提高了物理合理性和泛化性。为了实现高效的反向传播，我们设计了一个可微分的前向算子网络，它可以准确地近似非线性 EIT 响应，从而实现快速的物理引导训练。对 16 电极软传感器进行的广泛模拟和真实触觉实验表明，PhyDNN 在重建接触形状、位置和压力​​分布方面始终优于 NOSER、TV 和标准 DNN。 PhyDNN 产生更少的伪影、更清晰的边界和更高的度量分数，证明了其在高质量断层扫描触觉传感方面的有效性。
> **Abstract**: Electrical impedance tomography (EIT) provides an attractive solution for large-area tactile sensing due to its minimal wiring and shape flexibility, but its nonlinear inverse problem often leads to severe artifacts and inaccurate contact reconstruction. This work presents PhyDNN, a physics-driven deep reconstruction framework that embeds the EIT forward model directly into the learning objective. By jointly minimizing the discrepancy between predicted and ground-truth conductivity maps and enforcing consistency with the forward PDE, PhyDNN reduces the black-box nature of deep networks and improves both physical plausibility and generalization. To enable efficient backpropagation, we design a differentiable forward-operator network that accurately approximates the nonlinear EIT response, allowing fast physics-guided training. Extensive simulations and real tactile experiments on a 16-electrode soft sensor show that PhyDNN consistently outperforms NOSER, TV, and standard DNNs in reconstructing contact shape, location, and pressure distribution. PhyDNN yields fewer artifacts, sharper boundaries, and higher metric scores, demonstrating its effectiveness for high-quality tomographic tactile sensing.

【24】ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms
- **标题**: ATHENA：分层进化数值算法代理团队
- **链接**: https://arxiv.org/abs/2512.03476
> **作者**: Juan Diego Toscano,Daniel T. Chen,George Em Karniadakis
> **摘要**: 弥合理论概念化和计算实现之间的差距是科学计算（SciC）和科学机器学习（SciML）的主要瓶颈。我们引入了 ATHENA（分层进化数值算法代理团队），这是一个被设计为自治实验室的代理框架，用于管理端到端计算研究生命周期。其核心是 HENA 循环，这是一个知识驱动的诊断过程，被框架为上下文强盗问题。作为在线学习者，系统分析先前的试验，以在专家蓝图（例如通用逼近、物理信息约束）指导下从组合空间中选择结构“动作”（$A_n$）。这些动作被转换为可执行代码 ($S_n$) 以产生科学奖励 ($R_n$)。 ATHENA 超越了标准自动化：在 SciC 中，它可以自动识别精确解析解的数学对称性，或者在基础模型失败的情况下导出稳定的数值求解器。在 SciML 中，它执行深度诊断来解决不适定公式，并结合混合符号数值工作流程（例如，将 PINN 与 FEM 耦合）来解决多物理场问题。该框架实现了超人类的性能，验证错误达到​​ $10^{-14}$。此外，协作式“人机交互”干预使系统能够弥合稳定性差距，将结果提高一个数量级。这种范式转变的重点是从实施机制到方法创新，加速科学发现。
> **Abstract**: Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.

## 多代理系统(cs.MA:Multiagent Systems)

【1】AsymPuzl: An Asymmetric Puzzle for multi-agent cooperation
- **标题**: AsymPuzl：多智能体合作的非对称谜题
- **链接**: https://arxiv.org/abs/2512.03466
> **作者**: Xavier Cadet,Edward Koh,Peter Chin
> **摘要**: 大型语言模型（LLM）代理越来越多地在多回合、多代理场景中进行研究，但大多数现有设置强调开放式角色扮演而不是受控评估。我们引入了 AsymPuzl，这是一个最小但富有表现力的二代理谜题环境，旨在隔离信息不对称下的通信。每个智能体都会观察到一个符号谜题的互补但不完整的视图，并且必须交换消息以合作解决它。使用多种当前一代的开源法学硕士，我们表明（i）强大的模型（例如 GPT-5 和 Claude-4.0）通过在两轮中共享完整信息，在解决方案上可靠地收敛于不同大小的谜题，（ii）较弱的模型经常忽略合作伙伴的消息或过度纠正他们的假设，以及（iii）反馈设计并不简单：简单的自我反馈可以提高成功率，而详细的联合反馈可能会损害性能。这些发现表明，即使在简单的合作任务中，LLM 的沟通策略也会有所不同，并且取决于反馈信号的粒度。因此，AsymPuzl 为探索多轮合作的局限性提供了一个测试平台，并为研究协调机制开辟了途径。
> **Abstract**: Large Language Model (LLM) agents are increasingly studied in multi-turn, multi-agent scenarios, yet most existing setups emphasize open-ended role-play rather than controlled evaluation. We introduce AsymPuzl, a minimal but expressive two-agent puzzle environment designed to isolate communication under information asymmetry. Each agent observes complementary but incomplete views of a symbolic puzzle and must exchange messages to solve it cooperatively. Using a diverse set of current-generation and open-source LLMs, we show that (i) strong models such as GPT-5 and Claude-4.0 reliably converge across puzzle sizes on the solution by sharing complete information in two turns, (ii) weaker models often ignore partner messages or over-correct their hypotheses, and (iii) feedback design is non-trivial: simple self-feedback improves success rates, while detailed joint feedback can hurt performance. These findings show that even in simple cooperative tasks, LLM communication strategies diverge and depend on the granularity of feedback signals. AsymPuzl thus provides a testbed for probing the limits of multi-turn cooperation and opens avenues for studying coordination mechanisms.

## 多媒体(cs.MM:Multimedia)

【1】MindFuse: Towards GenAI Explainability in Marketing Strategy Co-Creation
- **标题**: MindFuse：在营销策略共同创建中迈向 GenAI 可解释性
- **链接**: https://arxiv.org/abs/2512.04112
> **作者**: Aleksandr Farseev,Marlo Ongpin,Qi Yang,Ilia Gossoudarev,Yu-Yi Chu-Farseeva,Sergey Nikolenko
> **摘要**: 数字营销的未来在于人类创造力和生成式人工智能的融合，其中洞察力、策略和故事讲述是由智能系统共同创作的。我们推出 MindFuse，这是一个全新的、可解释的生成人工智能框架，旨在充当营销过程中的战略合作伙伴。与仅限于内容生成的传统法学硕士应用程序不同，MindFuse 将基于点击率的内容人工智能引导的共同创作与大型语言模型融合在一起，以提取、解释和迭代基于真实广告数据的通信叙述。 MindFuse 在整个营销生命周期中运作：从从竞争对手的营销活动中提取内容支柱和客户角色，到根据实时绩效遥测建议进行中的优化。它使用基于注意力的可解释性来诊断广告效果并指导内容迭代，同时通过动态叙事构建和讲故事使消息传递与战略目标保持一致。我们在 GenAI 中引入了一种新的营销范式，法学硕士不仅可以生成内容，还可以通过内容进行推理、实时调整营销活动，并从受众参与模式中学习。我们的结果在机构部署中得到验证，显示出高达 12 倍的效率增益，为未来与实证受众数据（例如 GWI、尼尔森）和全漏斗归因模型的集成奠定了基础。 MindFuse 不仅将人工智能重新定义为一种工具，而且将其定义为现代营销创意和战略结构中的协作代理。
> **Abstract**: The future of digital marketing lies in the convergence of human creativity and generative AI, where insight, strategy, and storytelling are co-authored by intelligent systems. We present MindFuse, a brave new explainable generative AI framework designed to act as a strategic partner in the marketing process. Unlike conventional LLM applications that stop at content generation, MindFuse fuses CTR-based content AI-guided co-creation with large language models to extract, interpret, and iterate on communication narratives grounded in real advertising data. MindFuse operates across the full marketing lifecycle: from distilling content pillars and customer personas from competitor campaigns to recommending in-flight optimizations based on live performance telemetry. It uses attention-based explainability to diagnose ad effectiveness and guide content iteration, while aligning messaging with strategic goals through dynamic narrative construction and storytelling. We introduce a new paradigm in GenAI for marketing, where LLMs not only generate content but reason through it, adapt campaigns in real time, and learn from audience engagement patterns. Our results, validated in agency deployments, demonstrate up to 12 times efficiency gains, setting the stage for future integration with empirical audience data (e.g., GWI, Nielsen) and full-funnel attribution modeling. MindFuse redefines AI not just as a tool, but as a collaborative agent in the creative and strategic fabric of modern marketing.

## 神经和进化计算(cs.NE:Neural and Evolutionary Computing)

【1】MD-SNN: Membrane Potential-aware Distillation on Quantized Spiking Neural Network
- **标题**: MD-SNN：量化尖峰神经网络上的膜电位感知蒸馏
- **链接**: https://arxiv.org/abs/2512.04443
> **作者**: Donghyun Lee,Abhishek Moitra,Youngeun Kim,Ruokai Yin,Priyadarshini Panda
> **摘要**: 尖峰神经网络 (SNN) 凭借其稀疏的二元激活，为传统神经网络提供了一种有前途且节能的替代方案。然而，由于复杂的时空动力学以及训练期间跨时间步的多次反向传播计算的必要性，他们面临着内存和计算开销的挑战。为了减轻这种开销，量化等压缩技术被应用于 SNN。然而，天真地将量化应用于 SNN 会引入膜电位的不匹配，这是激发尖峰的关键因素，从而导致精度下降。在本文中，我们介绍了量化尖峰神经网络（MD-SNN）上的膜感知蒸馏，它利用膜电位来减轻重量、膜电位和批量归一化量化后的差异。据我们所知，这项研究代表了膜电位知识蒸馏在 SNN 中的首次应用。我们在各种数据集（包括 CIFAR10、CIFAR100、N-Caltech101 和 TinyImageNet）上验证了我们的方法，证明了其对于静态和动态数据场景的有效性。此外，对于硬件效率，我们使用 SpikeSim 平台评估 MD-SNN，发现与 N-Caltech101 数据集上等精度的浮点 SNN 相比，MD-SNN 的能量延迟面积积 (EDAP) 降低了 14.85 倍，TOPS/W 提高了 2.64 倍，TOPS/mm2 提高了 6.19 倍。
> **Abstract**: Spiking Neural Networks (SNNs) offer a promising and energy-efficient alternative to conventional neural networks, thanks to their sparse binary activation. However, they face challenges regarding memory and computation overhead due to complex spatio-temporal dynamics and the necessity for multiple backpropagation computations across timesteps during training. To mitigate this overhead, compression techniques such as quantization are applied to SNNs. Yet, naively applying quantization to SNNs introduces a mismatch in membrane potential, a crucial factor for the firing of spikes, resulting in accuracy degradation. In this paper, we introduce Membrane-aware Distillation on quantized Spiking Neural Network (MD-SNN), which leverages membrane potential to mitigate discrepancies after weight, membrane potential, and batch normalization quantization. To our knowledge, this study represents the first application of membrane potential knowledge distillation in SNNs. We validate our approach on various datasets, including CIFAR10, CIFAR100, N-Caltech101, and TinyImageNet, demonstrating its effectiveness for both static and dynamic data scenarios. Furthermore, for hardware efficiency, we evaluate the MD-SNN with SpikeSim platform, finding that MD-SNNs achieve 14.85X lower energy-delay-area product (EDAP), 2.64X higher TOPS/W, and 6.19X higher TOPS/mm2 compared to floating point SNNs at iso-accuracy on N-Caltech101 dataset.

【2】Prescriptive tool for zero-emissions building fenestration design using hybrid metaheuristic algorithms
- **标题**: 使用混合元启发式算法进行零排放建筑开窗设计的规范工具
- **链接**: https://arxiv.org/abs/2512.04102
> **作者**: Rosana Caro,Lorena Cruz,Arturo Martinez,Pablo S. Naharro,Santiago Muelas,Kevin King Sancho,Elena Cuerda,Maria del Mar Barbero-Barrera,Antonio LaTorre
> **摘要**: 设计零排放建筑 (ZEB) 需要平衡传统方法难以实现的众多复杂目标。开窗，包括立面开口和遮阳系统，由于其高热透射率和太阳辐射进入能力，在 ZEB 性能中发挥着关键作用。本文提出了一种专为实际应用而设计的新型基于模拟的开窗优化方法。它使用混合元启发式算法，并依赖于规则和可更新的目录，以完全自动化设计过程，创建高度多样化的搜索空间，最大限度地减少偏差，并生成为架构规定做好准备的详细解决方案。建筑师拥有设计灵活性的 19 个开窗变量经过优化，可减少住宅建筑的供暖、制冷需求和热不适。该方法在西班牙三个气候区进行了测试。结果表明，所考虑的优化算法在质量和鲁棒性方面都显着优于基线遗传算法，并且这些差异被证明具有统计显着性。此外，研究结果为ZEB设计提供了宝贵的见解，强调了在温暖气候下减少冷却需求的挑战，并展示了自动移动遮阳系统与固定解决方案相比的卓越效率。
> **Abstract**: Designing Zero-Emissions Buildings (ZEBs) involves balancing numerous complex objectives that traditional methods struggle to address. Fenestration, encompassing façade openings and shading systems, plays a critical role in ZEB performance due to its high thermal transmittance and solar radiation admission. This paper presents a novel simulation-based optimization method for fenestration designed for practical application. It uses a hybrid metaheuristic algorithm and relies on rules and an updatable catalog, to fully automate the design process, create a highly diverse search space, minimize biases, and generate detailed solutions ready for architectural prescription. Nineteen fenestration variables, over which architects have design flexibility, were optimized to reduce heating, cooling demand, and thermal discomfort in residential buildings. The method was tested across three Spanish climate zones. Results demonstrate that the considered optimization algorithm significantly outperforms the baseline Genetic Algorithm in both quality and robustness, with these differences proven to be statistically significant. Furthermore, the findings offer valuable insights for ZEB design, highlighting challenges in reducing cooling demand in warm climates, and showcasing the superior efficiency of automated movable shading systems compared to fixed solutions.

【3】MultiGA: Leveraging Multi-Source Seeding in Genetic Algorithms
- **标题**: MultiGA：在遗传算法中利用多源播种
- **链接**: https://arxiv.org/abs/2512.04097
> **作者**: Isabelle Diana May-Xin Ng,Tharindu Cyril Weerasooriya,Haitao Zhu,Wei Wei
> **摘要**: 大型语言模型 (LLM) 广泛应用于各个研究领域来处理复杂的任务，但它们的性能可能会根据当前任务的不同而有很大差异。受自然选择启发的进化算法可用于在推理时迭代地完善解决方案。据我们所知，还没有探索利用多源种子的集体能力来实现法学硕士引导的遗传算法。在本文中，我们介绍了一种新颖的方法 MultiGA，它应用遗传算法原理通过从不同的法学硕士群体中采样来初始化群体来解决复杂的自然语言任务和推理问题。 MultiGA 从各种父级法学硕士（开源和闭源）生成一系列输出，并使用中性适应度函数来评估它们。通过迭代重组过程，我们混合并完善这些代，直到实现最佳解决方案。我们使用文本到 SQL 代码生成任务、旅行计划、针对研究生水平科学问题的 GPQA 基准以及 BBQ 偏差基准来对我们的方法进行基准测试。我们的结果表明，MultiGA 收敛到最适合该任务的 LLM 的准确性，这些见解为未来的研究奠定了基础，进一步研究如何将多个 LLM 集成到未探索的任务中，在这些任务中，仅选择一个预训练模型是不清楚或次优的。
> **Abstract**: Large Language Models (LLMs) are widely used across research domains to tackle complex tasks, but their performance can vary significantly depending on the task at hand. Evolutionary algorithms, inspired by natural selection, can be used to refine solutions iteratively at inference-time. To the best of our knowledge, there has not been exploration on leveraging the collective capabilities of multi-source seeding for LLM-guided genetic algorithms. In this paper, we introduce a novel approach, MultiGA, which applies genetic algorithm principles to address complex natural language tasks and reasoning problems by sampling from a diverse population of LLMs to initialize the population. MultiGA generates a range of outputs from various parent LLMs, open source and closed source, and uses a neutral fitness function to evaluate them. Through an iterative recombination process, we mix and refine these generations until an optimal solution is achieved. We benchmark our approach using text-to-SQL code generation tasks, trip planning, GPQA benchmark for grad-level science questions, and the BBQ bias benchmark. Our results show that MultiGA converges to the accuracy of the LLM best fit for the task, and these insights lay the foundation for future research looking closer at integrating multiple LLMs for unexplored tasks in which selecting only one pre-trained model is unclear or suboptimal.

【4】Memory-DD: A Low-Complexity Dendrite-Inspired Neuron for Temporal Prediction Tasks
- **标题**: Memory-DD：用于时间预测任务的低复杂性树突启发神经元
- **链接**: https://arxiv.org/abs/2512.04094
> **作者**: Dongjian Yang,Xiaoyuan Li,Chuanmei Xi,Ye Sun,Gang Liu
> **摘要**: 由于计算复杂度低和推理速度快，树突神经元已广泛应用于图像分类等任务。时态数据预测作为一项关键的机器学习任务，在传感器数据分析、金融预测、城市交通管理等实时场景中发挥着关键作用。然而，现有的树突神经元主要是针对静态数据设计的。关于捕获动态特征和建模时间序列中的长期依赖性的研究仍然有限。仍然缺乏专门为时间序列预测设计的高效架构。在本文中，我们提出了 Memory-DD，一种低复杂性的树突启发神经元模型。 Memory-DD由两个受树突启发的神经元组组成，它们不包含非线性激活函数，但仍然可以实现非线性映射。与没有树突功能的传统神经元相比，Memory-DD只需要两个神经元组即可提取输入序列中特征之间的逻辑关系。该设计有效地捕获了时间依赖性，并且适用于序列数据的分类和回归任务。实验结果表明，Memory-DD 在 18 个时间分类基准数据集上的平均准确率达到 89.41%，优于 LSTM 4.25%。在 9 个时间回归数据集上，它达到了与 LSTM 相当的性能，同时仅使用 50% 的参数，并将计算复杂度 (FLOP) 降低了 27.7%。这些结果表明，Memory-DD成功地将树突启发神经元的低复杂度优势扩展到时间预测，为时间序列数据处理提供了低复杂度和高效的解决方案。
> **Abstract**: Dendrite-inspired neurons have been widely used in tasks such as image classification due to low computational complexity and fast inference speed. Temporal data prediction, as a key machine learning task, plays a key role in real-time scenarios such as sensor data analysis, financial forecasting, and urban traffic management. However, existing dendrite-inspired neurons are mainly designed for static data. Studies on capturing dynamic features and modeling long-term dependencies in temporal sequences remain limited. Efficient architectures specifically designed for temporal sequence prediction are still lacking. In this paper, we propose Memory-DD, a low-complexity dendrite-inspired neuron model. Memory-DD consists of two dendrite-inspired neuron groups that contain no nonlinear activation functions but can still realize nonlinear mappings. Compared with traditional neurons without dendritic functions, Memory-DD requires only two neuron groups to extract logical relationships between features in input sequences. This design effectively captures temporal dependencies and is suitable for both classification and regression tasks on sequence data. Experimental results show that Memory-DD achieves an average accuracy of 89.41% on 18 temporal classification benchmark datasets, outperforming LSTM by 4.25%. On 9 temporal regression datasets, it reaches comparable performance to LSTM, while using only 50% of the parameters and reducing computational complexity (FLOPs) by 27.7%. These results demonstrate that Memory-DD successfully extends the low-complexity advantages of dendrite-inspired neurons to temporal prediction, providing a low-complexity and efficient solution for time-series data processing.

【5】Parameter efficient hybrid spiking-quantum convolutional neural network with surrogate gradient and quantum data-reupload
- **标题**: 具有代理梯度和量子数据重新上传的参数高效混合尖峰量子卷积神经网络
- **链接**: https://arxiv.org/abs/2512.03895
> **作者**: Luu Trong Nhan,Luu Trung Duong,Pham Ngoc Nam,Truong Cong Thang
> **摘要**: 人工智能 (AI) 和深度学习 (DL) 的快速发展促进了多个优化驱动子领域的出现，特别是神经形态计算和量子机器学习。利用混合模型的可微性质，研究人员探索了它们通过统一优化策略解决复杂问题的潜力。其中一项进展是尖峰量子神经网络 (SQNN)，它结合了尖峰神经网络 (SNN) 和量子计算的原理。然而，由于尖峰活动的不可微分性质和当前 SNN 编码器的可扩展性有限，现有的 SQNN 实现通常依赖于预训练的 SNN。在这项工作中，我们提出了一种新颖的架构，即尖峰量子数据重新上传卷积神经网络（SQDR-CNN），它能够在单个反向传播框架内联合训练卷积 SNN 和量子电路。与其前身不同，SQDR-CNN 可以收敛到合理的性能，而无需依赖预训练的尖峰编码器和子集数据集。我们还阐明了一些理论基础，使用不同训练算法初始化的量子数据重新上传来测试新设计，并评估所提出的模型在噪声模拟量子环境下的性能。结果，我们能够实现 SOTA SNN 基线平均最高准确度的 86%，但仅使用最小尖峰模型参数的 0.5%。通过神经形态和量子范式的整合，我们的目标是开辟新的研究方向并促进多模式、可学习系统的技术进步。
> **Abstract**: The rapid advancement of artificial intelligence (AI) and deep learning (DL) has catalyzed the emergence of several optimization-driven subfields, notably neuromorphic computing and quantum machine learning. Leveraging the differentiable nature of hybrid models, researchers have explored their potential to address complex problems through unified optimization strategies. One such development is the Spiking Quantum Neural Network (SQNN), which combines principles from spiking neural networks (SNNs) and quantum computing. However, existing SQNN implementations often depend on pretrained SNNs due to the non-differentiable nature of spiking activity and the limited scalability of current SNN encoders. In this work, we propose a novel architecture, Spiking-Quantum Data Re-upload Convolutional Neural Network (SQDR-CNN), that enables joint training of convolutional SNNs and quantum circuits within a single backpropagation framework. Unlike its predecessor, SQDR-CNN allow convergence to reasonable performance without the reliance of pretrained spiking encoder and subsetting datasets. We also clarified some theoretical foundations, testing new design using quantum data-reupload with different training algorithm-initialization and evaluate the performance of the proposed model under noisy simulated quantum environments. As a result, we were able to achieve 86% of the mean top-performing accuracy of the SOTA SNN baselines, yet uses only 0.5% of the smallest spiking model's parameters. Through this integration of neuromorphic and quantum paradigms, we aim to open new research directions and foster technological progress in multi-modal, learnable systems.

【6】Hybrid Temporal-8-Bit Spike Coding for Spiking Neural Network Surrogate Training
- **标题**: 用于尖峰神经网络代理训练的混合时间 8 位尖峰编码
- **链接**: https://arxiv.org/abs/2512.03879
> **作者**: Luu Trong Nhan,Luu Trung Duong,Pham Ngoc Nam,Truong Cong Thang
> **摘要**: 尖峰神经网络 (SNN) 已成为计算神经科学和人工智能领域的一个有前景的方向，具有强大的生物学合理性和神经形态硬件的低能耗等优势。尽管有这些好处，SNN 在视觉任务上实现最先进的性能方面仍然面临挑战。最近的工作表明，混合速率-时间编码策略（特别是那些将图像的位平面表示合并到传统速率编码方案中的策略）在使用代理反向传播进行训练时可以显着提高性能。受这些发现的启发，本研究提出了一种混合时间位尖峰编码方法，该方法将位平面分解与时间编码原理相结合。通过跨多个计算机视觉基准的广泛实验，我们证明，与已建立的尖峰编码技术相比，将位平面信息与时间编码混合可以产生具有竞争力的性能，并且在某些情况下还可以提高性能。据我们所知，这是第一个引入专为 SNN 的代理梯度训练而设计的混合时间位编码方案的工作。
> **Abstract**: Spiking neural networks (SNNs) have emerged as a promising direction in both computational neuroscience and artificial intelligence, offering advantages such as strong biological plausibility and low energy consumption on neuromorphic hardware. Despite these benefits, SNNs still face challenges in achieving state-of-the-art performance on vision tasks. Recent work has shown that hybrid rate-temporal coding strategies (particularly those incorporating bit-plane representations of images into traditional rate coding schemes) can significantly improve performance when trained with surrogate backpropagation. Motivated by these findings, this study proposes a hybrid temporal-bit spike coding method that integrates bit-plane decompositions with temporal coding principles. Through extensive experiments across multiple computer vision benchmarks, we demonstrate that blending bit-plane information with temporal coding yields competitive, and in some cases improved, performance compared to established spike-coding techniques. To the best of our knowledge, this is the first work to introduce a hybrid temporal-bit coding scheme specifically designed for surrogate gradient training of SNNs.

## 网络和互联网架构(cs.NI:Networking and Internet Architecture)

【1】Machine Learning to Predict Slot Usage in TSCH Wireless Sensor Networks
- **标题**: 机器学习预测 TSCH 无线传感器网络中的时隙使用情况
- **链接**: https://arxiv.org/abs/2512.03570
> **作者**: Stefano Scanzio,Gabriele Formis,Tullio Facchinetti,Gianluca Cena
> **摘要**: 无线传感器网络 (WSN) 广泛应用于各种工业应用，其中超低功耗是关键先决条件。同时，这些系统必须保持一定程度的确定性，以确保可靠且可预测的运行。从这个角度来看，时隙信道跳频 (TSCH) 是一种满足这两个条件的通信技术，使其成为工业 WSN 中有吸引力的选择。这项工作提出使用机器学习来学习基于 TSCH 协议的网络中生成的流量模式，以便在没有计划传输时将节点转入深度睡眠状态，从而提高 WSN 的能源效率。深入分析了机器学习模型在典型树形网络拓扑中的不同网络级别做出良好预测的能力，展示了它们的能力在接近树根时如何退化。这些模型在基于无线传感器节点精确建模的模拟数据上的应用表明，所研究的算法可适用于进一步大幅降低 TSCH 网络的功耗。
> **Abstract**: Wireless sensor networks (WSNs) are employed across a wide range of industrial applications where ultra-low power consumption is a critical prerequisite. At the same time, these systems must maintain a certain level of determinism to ensure reliable and predictable operation. In this view, time slotted channel hopping (TSCH) is a communication technology that meets both conditions, making it an attractive option for its usage in industrial WSNs. This work proposes the use of machine learning to learn the traffic pattern generated in networks based on the TSCH protocol, in order to turn nodes into a deep sleep state when no transmission is planned and thus to improve the energy efficiency of the WSN. The ability of machine learning models to make good predictions at different network levels in a typical tree network topology was analyzed in depth, showing how their capabilities degrade while approaching the root of the tree. The application of these models on simulated data based on an accurate modeling of wireless sensor nodes indicates that the investigated algorithms can be suitably used to further and substantially reduce the power consumption of a TSCH network.

【2】Mobility Induced Sensitivity of UAV based Nodes to Jamming in Private 5G Airfield Networks An Experimental Study
- **标题**: 移动性引起的基于无人机的节点对专用 5G 机场网络中的干扰的敏感性实验研究
- **链接**: https://arxiv.org/abs/2512.03536
> **作者**: Pavlo Mykytyn,Ronald Chitauro,Onur Yener,Peter Langendoerfer
> **摘要**: 这项工作提出了针对基于无人机的 UE 节点的受控定向 SDR 干扰攻击下专用 5G 机场网络的实验性能评估。使用作为四轴飞行器无人机上的有效负载安装的 QualiPoc Android UE，我们进行了一系列实验，以评估在存在恒定方向干扰的情况下的信号衰减、切换性能和服务稳定性。进行的实验旨在检查基于无人机的 UE 的不同行进速度、高度和移动模式的影响，以记录和分析关键物理层和网络层指标，如 CQI、MCS、RSRP、SINR、BLER、网络 PDSCH 吞吐量和 RLF。这项工作的结果描述了在私有 5G 机场网络中自主和自动操作期间基于无人机的 UE 节点的移动性水平引起的链路稳定性和信号衰减依赖性
> **Abstract**: This work presents an experimental performance evaluation of a private 5G airfield network under controlled directional SDR jamming attacks targeting UAV-based UE nodes. Using a QualiPoc Android UE, mounted as a payload on a quadcopter UAV, we conducted a series of experiments to evaluate signal degradation, handover performance, and ser-vice stability in the presence of constant directional jamming. The conducted experiments aimed to examine the effects of varying travel speeds, altitudes, and moving patterns of a UAV-based UE to record and analyze the key physical-layer and network-layer metrics such as CQI, MCS, RSRP, SINR, BLER, Net PDSCH Throughput and RLF. The re-sults of this work describe the link stability and signal degradation dependencies, caused by the level of mobility of the UAV-based UE nodes during autonomous and automatic operation in private 5G Airfield networks

## 机器人技术(cs.RO:Robotics)

【1】Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration
- **标题**: 通过人机协作的动作和语言进行开放式目标推理
- **链接**: https://arxiv.org/abs/2512.04453
> **作者**: Debasmita Ghose,Oz Gitelson,Marynel Vazquez,Brian Scassellati
> **摘要**: 为了与人类合作，机器人必须推断出通常不明确、难以阐明或不是从固定集合中得出的目标。先前的方法将推理限制为预定义的目标集，仅依赖于观察到的操作，或完全依赖于明确的指令，这使得它们在现实世界的交互中变得脆弱。我们提出了用于目标预测的 BALI（双向动作语言推理），这是一种将自然语言偏好与在后退视野规划树中观察到的人类行为相结合的方法。 BALI 结合了人类的语言和动作线索，仅当从答案中获得的预期信息超过中断的成本时才提出澄清问题，并选择与推断目标一致的支持性行动。我们评估了协作烹饪任务中的方法，其中目标对于机器人来说可能是新颖且无限制的。与基线相比，BALI 产生更稳定的目标预测，并且错误显着减少。
> **Abstract**: To collaborate with humans, robots must infer goals that are often ambiguous, difficult to articulate, or not drawn from a fixed set. Prior approaches restrict inference to a predefined goal set, rely only on observed actions, or depend exclusively on explicit instructions, making them brittle in real-world interactions. We present BALI (Bidirectional Action-Language Inference) for goal prediction, a method that integrates natural language preferences with observed human actions in a receding-horizon planning tree. BALI combines language and action cues from the human, asks clarifying questions only when the expected information gain from the answer outweighs the cost of interruption, and selects supportive actions that align with inferred goals. We evaluate the approach in collaborative cooking tasks, where goals may be novel to the robot and unbounded. Compared to baselines, BALI yields more stable goal predictions and significantly fewer mistakes.

【2】Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops
- **标题**: 用于选择性机器人拆卸的视觉-语言-动作模型：从桌面提取关键组件的案例研究
- **链接**: https://arxiv.org/abs/2512.04446
> **作者**: Chang Liu,Sibo Tian,Sara Behdad,Xiao Liang,Minghui Zheng
> **摘要**: 由于这些产品固有的可变性和不确定性，自动拆卸报废 (EoL) 台式机的关键组件（例如 RAM 模块和 CPU 等高价值部件以及硬盘驱动器等敏感部件）仍然具有挑战性。此外，它们的拆卸需要顺序、精确和灵巧的操作，进一步增加了自动化的复杂性。目前的机器人拆卸过程通常分为几个阶段：感知、序列规划、任务规划、运动规划和操纵。每个阶段都需要显式建模，这限制了对不熟悉场景的泛化。视觉-语言-动作（VLA）模型的最新发展为一般机器人操作任务提供了一种端到端的方法。尽管 VLA 在简单任务上表现出了良好的性能，但将此类模型应用于复杂拆卸的可行性在很大程度上仍未得到探索。在本文中，我们收集了用于机器人 RAM 和 CPU 拆卸的定制数据集，并用它来微调两种成熟的 VLA 方法：OpenVLA 和 OpenVLA-OFT，作为案例研究。我们将整个反汇编任务分成几个小步骤，我们的初步实验结果表明，经过微调的 VLA 模型可以忠实地完成多个早期步骤，但在某些关键子任务上遇到困难，导致任务失败。然而，我们观察到，将 VLA 与基于规则的控制器相结合的简单混合策略可以成功执行整个反汇编操作。这些发现凸显了目前 VLA 模型在处理机器人 EoL 产品拆卸所需的灵活性和精度方面的局限性。通过对观察到的结果进行详细分析，这项研究提供了一些见解，可以为未来的研究提供信息，以解决当前的挑战并推进端到端机器人自动拆卸。
> **Abstract**: Automating disassembly of critical components from end-of-life (EoL) desktops, such as high-value items like RAM modules and CPUs, as well as sensitive parts like hard disk drives, remains challenging due to the inherent variability and uncertainty of these products. Moreover, their disassembly requires sequential, precise, and dexterous operations, further increasing the complexity of automation. Current robotic disassembly processes are typically divided into several stages: perception, sequence planning, task planning, motion planning, and manipulation. Each stage requires explicit modeling, which limits generalization to unfamiliar scenarios. Recent development of vision-language-action (VLA) models has presented an end-to-end approach for general robotic manipulation tasks. Although VLAs have demonstrated promising performance on simple tasks, the feasibility of applying such models to complex disassembly remains largely unexplored. In this paper, we collected a customized dataset for robotic RAM and CPU disassembly and used it to fine-tune two well-established VLA approaches, OpenVLA and OpenVLA-OFT, as a case study. We divided the whole disassembly task into several small steps, and our preliminary experimental results indicate that the fine-tuned VLA models can faithfully complete multiple early steps but struggle with certain critical subtasks, leading to task failure. However, we observed that a simple hybrid strategy that combines VLA with a rule-based controller can successfully perform the entire disassembly operation. These findings highlight the current limitations of VLA models in handling the dexterity and precision required for robotic EoL product disassembly. By offering a detailed analysis of the observed results, this study provides insights that may inform future research to address current challenges and advance end-to-end robotic automated disassembly.

【3】RoboBPP: Benchmarking Robotic Online Bin Packing with Physics-based Simulation
- **标题**: RoboBPP：通过基于物理的模拟对机器人在线装箱进行基准测试
- **链接**: https://arxiv.org/abs/2512.04415
> **作者**: Zhoufeng Wang,Hang Zhao,Juzhan Xu,Shishun Zhang,Zeyu Xiong,Ruizhen Hu,Chenyang Zhu,Kai Xu
> **摘要**: 3D 装箱的物理可行性是现代工业物流和机器人自动化的关键要求。随着工业自动化的日益普及，在线装箱越来越受到关注。然而，问题设置、测试数据集和评估指标的不一致阻碍了该领域的进展，并且缺乏全面的基准测试系统。在真实硬件上直接测试成本高昂，构建真实的仿真环境也具有挑战性。为了解决这些限制，我们推出了 RoboBPP，这是一种专为机器人在线装箱而设计的基准测试系统。 RoboBPP 集成了基于物理的模拟器来评估物理可行性。在我们的模拟环境中，我们引入了真实世界规模的机械臂和盒子来复制真实的工业包装工作流程。通过模拟实际工业应用中出现的条件，我们确保评估的算法实际上是可部署的。此外，先前的研究通常依赖于其分布与现实世界工业数据不同的合成数据集。为了解决这个问题，我们从真实的工业工作流程中收集了三个数据集，包括装配线生产、物流包装和家具制造。该基准包括三个精心设计的测试设置，并通过结构稳定性和操作安全性的新指标扩展了现有的评估指标。我们设计了一个评分系统，并从评估结果中得出一系列见解。 RoboBPP完全开源，配备可视化工具和在线排行榜，为未来的研究和工业应用提供可重复和可扩展的基础（https://robot-bin-packing-benchmark.github.io）。
> **Abstract**: Physical feasibility in 3D bin packing is a key requirement in modern industrial logistics and robotic automation. With the growing adoption of industrial automation, online bin packing has gained increasing attention. However, inconsistencies in problem settings, test datasets, and evaluation metrics have hindered progress in the field, and there is a lack of a comprehensive benchmarking system. Direct testing on real hardware is costly, and building a realistic simulation environment is also challenging. To address these limitations, we introduce RoboBPP, a benchmarking system designed for robotic online bin packing. RoboBPP integrates a physics-based simulator to assess physical feasibility. In our simulation environment, we introduce a robotic arm and boxes at real-world scales to replicate real industrial packing workflows. By simulating conditions that arise in real industrial applications, we ensure that evaluated algorithms are practically deployable. In addition, prior studies often rely on synthetic datasets whose distributions differ from real-world industrial data. To address this issue, we collect three datasets from real industrial workflows, including assembly-line production, logistics packing, and furniture manufacturing. The benchmark comprises three carefully designed test settings and extends existing evaluation metrics with new metrics for structural stability and operational safety. We design a scoring system and derive a range of insights from the evaluation results. RoboBPP is fully open-source and is equipped with visualization tools and an online leaderboard, providing a reproducible and extensible foundation for future research and industrial applications (https://robot-bin-packing-benchmark.github.io).

【4】Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation
- **标题**: 连接概率推理和行为树：自适应多机器人合作的交互框架
- **链接**: https://arxiv.org/abs/2512.04404
> **作者**: Chaoran Wang,Jingyuan Sun,Yanhui Zhang,Changju Wu
> **摘要**: 本文提出了一种交互式推理行为树（IIBT）框架，该框架将行为树（BT）与自由能原理下的主动推理相结合，用于分布式多机器人决策。拟议的 IIBT 节点通过概率推理扩展了传统的 BT，从而实现了多个机器人的在线联合规划和执行。它与标准 BT 架构完全兼容，允许无缝集成到现有的多机器人控制系统中。在此框架内，多机器人合作被表述为自由能最小化过程，其中每个机器人根据感知输入和同伴意图动态更新其偏好矩阵，从而在部分可观察和动态环境中实现自适应协调。与传统 BT 相比，所提出的方法通过模拟和现实实验进行了验证，包括多机器人迷宫导航和协作操作任务（https://youtu.be/KX_oT3IDTf4）。实验结果表明，IIBT 框架将 BT 节点复杂度降低了 70% 以上，同时在环境不确定性下保持稳健、可解释和自适应的协作行为。
> **Abstract**: This paper proposes an Interactive Inference Behavior Tree (IIBT) framework that integrates behavior trees (BTs) with active inference under the free energy principle for distributed multi-robot decision-making. The proposed IIBT node extends conventional BTs with probabilistic reasoning, enabling online joint planning and execution across multiple robots. It remains fully compatible with standard BT architectures, allowing seamless integration into existing multi-robot control systems. Within this framework, multi-robot cooperation is formulated as a free-energy minimization process, where each robot dynamically updates its preference matrix based on perceptual inputs and peer intentions, thereby achieving adaptive coordination in partially observable and dynamic environments. The proposed approach is validated through both simulation and real-world experiments, including a multi-robot maze navigation and a collaborative manipulation task, compared against traditional BTs(https://youtu.be/KX_oT3IDTf4). Experimental results demonstrate that the IIBT framework reduces BT node complexity by over 70%, while maintaining robust, interpretable, and adaptive cooperative behavior under environmental uncertainty.

【5】Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation
- **标题**: 一种具有电缆驱动传动和分布式驱动的15自由度仿生手的开发
- **链接**: https://arxiv.org/abs/2512.04399
> **作者**: Haoqi Han,Yi Yang,Yifei Yu,Yixuan Zhou,Xiaohan Zhu,Hesheng Wang
> **摘要**: 在机器人手研究中，最大限度地减少执行器的数量，同时保持人手一致的尺寸和自由度构成了一项基本挑战。这项工作从人类手部运动学配置和肌肉分布策略中汲取生物灵感，提出了一种新型的 15 自由度灵巧机器人手，并对其机械架构、电气系统和控制系统进行了详细分析。该仿生手采用了新型肌腱驱动机构，显着减少了传统肌腱驱动系统所需的电机数量，同时增强了运动性能并简化了机械结构。该设计在前臂集成了五个电机，提供强大的握持力，而手掌中安装了十个小电机，支持精细的操控任务。此外，还开发了相应的关节传感和电机驱动电气系统，以确保有效的控制和反馈。整个系统重量仅为1.4kg，兼具轻量化和高性能的特点。通过实验，仿生手表现出了非凡的灵活性和强大的抓取能力，展示了机器人操作任务的巨大潜力。
> **Abstract**: In robotic hand research, minimizing the number of actuators while maintaining human-hand-consistent dimensions and degrees of freedom constitutes a fundamental challenge. Drawing bio-inspiration from human hand kinematic configurations and muscle distribution strategies, this work proposes a novel 15-DoF dexterous robotic hand, with detailed analysis of its mechanical architecture, electrical system, and control system. The bionic hand employs a new tendon-driven mechanism, significantly reducing the number of motors required by traditional tendon-driven systems while enhancing motion performance and simplifying the mechanical structure. This design integrates five motors in the forearm to provide strong gripping force, while ten small motors are installed in the palm to support fine manipulation tasks. Additionally, a corresponding joint sensing and motor driving electrical system was developed to ensure efficient control and feedback. The entire system weighs only 1.4kg, combining lightweight and high-performance features. Through experiments, the bionic hand exhibited exceptional dexterity and robust grasping capabilities, demonstrating significant potential for robotic manipulation tasks.

【6】FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination
- **标题**: FALCON：主动解耦视觉运动策略，用于具有基于基础模型的协调的局部操纵
- **链接**: https://arxiv.org/abs/2512.04381
> **作者**: Chengyang He,Ge Sun,Yue Bai,Junkai Lu,Jiadong Zhao,Guillaume Sartoretti
> **摘要**: 我们提出了 FoundAtion 模型引导的解耦 LoCO 操纵视觉运动策略（FALCON），这是一种将模块化扩散策略与作为协调器的视觉语言基础模型相结合的局部操纵框架。我们的方法明确地将运动和操纵解耦为两个专门的视觉运动策略，允许每个子系统依赖于自己的观察。这减轻了当单个策略被迫融合来自运动和操纵的异构的、可能不匹配的观察结果时出现的性能下降。我们的关键创新在于通过视觉语言基础模型恢复这两个独立政策之间的协调，该模型将全球观察和语言指令编码到一个共享的潜在嵌入中，以调节这两个扩散政策。在此主干之上，我们引入了一个阶段进度头，它使用任务阶段的文本描述来推断离散阶段和连续进度估计，而无需手动阶段标签。为了进一步构建潜在空间，我们结合了协调感知对比损失，它显式地编码了手臂和基础动作之间的跨子系统兼容性。我们在两项具有挑战性的局部操纵任务上评估 FALCON，这些任务需要导航、精确的末端执行器放置和紧密的基臂协调。结果表明，它超越了集中式和去中心化的基线，同时表现出对分布式场景的鲁棒性和泛化性的提高。
> **Abstract**: We present FoundAtion-model-guided decoupled LoCO-maNipulation visuomotor policies (FALCON), a framework for loco-manipulation that combines modular diffusion policies with a vision-language foundation model as the coordinator. Our approach explicitly decouples locomotion and manipulation into two specialized visuomotor policies, allowing each subsystem to rely on its own observations. This mitigates the performance degradation that arise when a single policy is forced to fuse heterogeneous, potentially mismatched observations from locomotion and manipulation. Our key innovation lies in restoring coordination between these two independent policies through a vision-language foundation model, which encodes global observations and language instructions into a shared latent embedding conditioning both diffusion policies. On top of this backbone, we introduce a phase-progress head that uses textual descriptions of task stages to infer discrete phase and continuous progress estimates without manual phase labels. To further structure the latent space, we incorporate a coordination-aware contrastive loss that explicitly encodes cross-subsystem compatibility between arm and base actions. We evaluate FALCON on two challenging loco-manipulation tasks requiring navigation, precise end-effector placement, and tight base-arm coordination. Results show that it surpasses centralized and decentralized baselines while exhibiting improved robustness and generalization to out-of-distribution scenarios.

【7】Vertical Planetary Landing on Sloped Terrain Using Optical Flow Divergence Estimates
- **标题**: 使用光流发散估计在倾斜地形上垂直行星着陆
- **链接**: https://arxiv.org/abs/2512.04373
> **作者**: Hann Woei Ho,Ye Zhou
> **摘要**: 在倾斜地形上自主着陆对小型轻型航天器（例如旋翼机和着陆器）提出了重大挑战。这些车辆的处理能力和有效载荷能力有限，这使得先进的深度学习方法和重型传感器不切实际。飞行昆虫，例如蜜蜂，可以用最少的神经和感觉资源实现惊人的着陆，严重依赖光流。通过调节流量发散度（垂直速度除以高度的量度），它们可以实现平稳着陆，其中速度和高度一起呈指数衰减。然而，将这种仿生策略应用于航天器在倾斜地形上的着陆面临着两个关键挑战：全局流散度估计模糊的地形倾斜度，以及基于散度的控制的非线性性质可能导致使用传统控制器时的不稳定。本文提出了一种非线性控制策略，利用两种不同的局部流散度估计来调节垂直着陆期间的推力和姿态。控制律是基于增量非线性动态反演来制定的，以处理非线性流发散。推力控制通过保持局部气流发散估计的恒定平均值来确保平滑的垂直下降，而姿态控制则通过利用它们的差异使飞行器与着陆时的倾斜表面对齐。该方法在数值模拟中使用简化的二维航天器模型在不同的斜率和发散设定点上进行评估。结果表明，调节平均散度可以实现稳定着陆，速度和高度呈指数衰减，并且利用散度差可以有效地与倾斜地形对齐。总体而言，该方法提供了一种强大的、低资源的着陆策略，增强了小型航天器自主行星任务的可行性。
> **Abstract**: Autonomous landing on sloped terrain poses significant challenges for small, lightweight spacecraft, such as rotorcraft and landers. These vehicles have limited processing capability and payload capacity, which makes advanced deep learning methods and heavy sensors impractical. Flying insects, such as bees, achieve remarkable landings with minimal neural and sensory resources, relying heavily on optical flow. By regulating flow divergence, a measure of vertical velocity divided by height, they perform smooth landings in which velocity and height decay exponentially together. However, adapting this bio-inspired strategy for spacecraft landings on sloped terrain presents two key challenges: global flow-divergence estimates obscure terrain inclination, and the nonlinear nature of divergence-based control can lead to instability when using conventional controllers. This paper proposes a nonlinear control strategy that leverages two distinct local flow divergence estimates to regulate both thrust and attitude during vertical landings. The control law is formulated based on Incremental Nonlinear Dynamic Inversion to handle the nonlinear flow divergence. The thrust control ensures a smooth vertical descent by keeping a constant average of the local flow divergence estimates, while the attitude control aligns the vehicle with the inclined surface at touchdown by exploiting their difference. The approach is evaluated in numerical simulations using a simplified 2D spacecraft model across varying slopes and divergence setpoints. Results show that regulating the average divergence yields stable landings with exponential decay of velocity and height, and using the divergence difference enables effective alignment with inclined terrain. Overall, the method offers a robust, low-resource landing strategy that enhances the feasibility of autonomous planetary missions with small spacecraft.

【8】ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models
- **标题**: ResponsibleRobotBench：使用多模态大语言模型对负责任的机器人操作进行基准测试
- **链接**: https://arxiv.org/abs/2512.04308
> **作者**: Lei Zhang,Ju Dong,Kaixin Bai,Minheng Ni,Zoltan-Csaba Marton,Zhaopeng Chen,Jianwei Zhang
> **摘要**: 大型多模态模型的最新进展为实体人工智能带来了新的机遇，特别是在机器人操作方面。这些模型在泛化和推理方面表现出了强大的潜力，但在现实环境中实现可靠且负责任的机器人行为仍然是一个开放的挑战。在高风险环境中，机器人代理必须超越基本任务执行，以执行风险意识推理、道德决策和物理基础规划。我们推出 ResponsibleRobotBench，这是一个系统基准测试，旨在评估和加速从模拟到现实世界的负责任机器人操作的进展。该基准由 23 项多阶段任务组成，涵盖不同的风险类型，包括电气、化学和人类相关危害，以及不同级别的物理和规划复杂性。这些任务要求代理检测和减轻风险，推理安全性，规划行动顺序，并在必要时寻求人工协助。我们的基准包括一个通用评估框架，该框架支持具有各种动作表示模式的基于多模式模型的代理。该框架集成了视觉感知、情境学习、提示构建、危险检测、推理和规划以及物理执行。它还提供丰富的多模态数据集，支持可重复的实验，并包括成功率、安全率和安全成功率等标准化指标。通过广泛的实验设置，ResponsibleRobotBench 可以跨风险类别、任务类型和代理配置进行分析。通过强调决策中的物理可靠性、通用性和安全性，该基准为推进可信赖的、现实世界中负责任的灵巧机器人系统的开发奠定了基础。 https://sites.google.com/view/responsible-robotbench
> **Abstract**: Recent advances in large multimodal models have enabled new opportunities in embodied AI, particularly in robotic manipulation. These models have shown strong potential in generalization and reasoning, but achieving reliable and responsible robotic behavior in real-world settings remains an open challenge. In high-stakes environments, robotic agents must go beyond basic task execution to perform risk-aware reasoning, moral decision-making, and physically grounded planning. We introduce ResponsibleRobotBench, a systematic benchmark designed to evaluate and accelerate progress in responsible robotic manipulation from simulation to real world. This benchmark consists of 23 multi-stage tasks spanning diverse risk types, including electrical, chemical, and human-related hazards, and varying levels of physical and planning complexity. These tasks require agents to detect and mitigate risks, reason about safety, plan sequences of actions, and engage human assistance when necessary. Our benchmark includes a general-purpose evaluation framework that supports multimodal model-based agents with various action representation modalities. The framework integrates visual perception, context learning, prompt construction, hazard detection, reasoning and planning, and physical execution. It also provides a rich multimodal dataset, supports reproducible experiments, and includes standardized metrics such as success rate, safety rate, and safe success rate. Through extensive experimental setups, ResponsibleRobotBench enables analysis across risk categories, task types, and agent configurations. By emphasizing physical reliability, generalization, and safety in decision-making, this benchmark provides a foundation for advancing the development of trustworthy, real-world responsible dexterous robotic systems. https://sites.google.com/view/responsible-robotbench

【9】Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies
- **标题**: 超越特权：将密集奖励知识提炼为稀疏奖励政策
- **链接**: https://arxiv.org/abs/2512.04279
> **作者**: Feeza Khan Khanzada,Jaerock Kwon
> **摘要**: 我们研究如何在基于视觉的自动驾驶中利用密集的模拟器定义的奖励，而不继承它们与部署指标的不一致。在 CARLA 等现实模拟器中，特权状态（例如车道几何形状、违规行为、碰撞时间）可以转换为密集奖励，从而稳定和加速基于模型的强化学习，但直接针对这些信号训练的策略在评估路线完成和无碰撞超车等稀疏目标时往往会过度拟合且无法泛化。我们提出了奖励特权世界模型蒸馏，这是一个两阶段框架，其中首先用密集的特权奖励训练教师 DreamerV3 式的智能体，然后仅将其潜在动态提炼为仅接受稀疏任务奖励训练的学生。师生共享同一观察空间（语义鸟瞰图像）；特权信息仅通过教师的奖励进入，学生不会模仿教师的行为或价值评估。相反，学生的世界模型被正则化以匹配教师的潜在动态，而其策略是根据稀疏的成功/失败信号从头开始学习的。在 CARLA 车道跟随和超车基准中，稀疏奖励的学生优于密集奖励的教师和稀疏的从头开始的基准。在看不见的车道跟踪路线上，相对于密集教师，奖励特权蒸馏将成功率提高了约 23%，同时保持了相当或更好的安全性。在超车时，学生在训练路线上保持近乎完美的表现，并在未见过的路线上将成功率提高了 27 倍，并改善了车道保持能力。这些结果表明，可以利用密集的奖励来学习更丰富的动态模型，同时保持部署的策略严格针对稀疏的、与部署一致的目标进行优化。
> **Abstract**: We study how to exploit dense simulator-defined rewards in vision-based autonomous driving without inheriting their misalignment with deployment metrics. In realistic simulators such as CARLA, privileged state (e.g., lane geometry, infractions, time-to-collision) can be converted into dense rewards that stabilize and accelerate model-based reinforcement learning, but policies trained directly on these signals often overfit and fail to generalize when evaluated on sparse objectives such as route completion and collision-free overtaking. We propose reward-privileged world model distillation, a two-stage framework in which a teacher DreamerV3-style agent is first trained with a dense privileged reward, and only its latent dynamics are distilled into a student trained solely on sparse task rewards. Teacher and student share the same observation space (semantic bird's-eye-view images); privileged information enters only through the teacher's reward, and the student does not imitate the teacher's actions or value estimates. Instead, the student's world model is regularized to match the teacher's latent dynamics while its policy is learned from scratch on sparse success/failure signals. In CARLA lane-following and overtaking benchmarks, sparse-reward students outperform both dense-reward teachers and sparse-from-scratch baselines. On unseen lane-following routes, reward-privileged distillation improves success by about 23 percent relative to the dense teacher while maintaining comparable or better safety. On overtaking, students retain near-perfect performance on training routes and achieve up to a 27x improvement in success on unseen routes, with improved lane keeping. These results show that dense rewards can be leveraged to learn richer dynamics models while keeping the deployed policy optimized strictly for sparse, deployment-aligned objectives.

【10】Sliding Mode Control and Subspace Stabilization Methodology for the Orbital Stabilization of Periodic Trajectories
- **标题**: 周期轨迹轨道稳定的滑模控制和子空间稳定方法
- **链接**: https://arxiv.org/abs/2512.04249
> **作者**: Maksim Surov,Leonid Freidovich
> **摘要**: 本文提出了一种组合滑模控制和子空间稳定方法，用于具有一级欠驱动的欠驱动机械系统中周期性轨迹的轨道稳定。该方法从部分反馈线性化和稳定性开始。然后，计算沿参考轨道的横向线性化，产生具有稳定子空间的周期性线性时变系统。滑模控制将轨迹驱动至该子空间。所提出的设计避免了解决计算密集型周期性 LQR 问题，并提高了对匹配扰动的鲁棒性。该方法通过蝴蝶机器人的实验得到验证。
> **Abstract**: This paper presents a combined sliding-mode control and subspace stabilization methodology for orbital stabilization of periodic trajectories in underactuated mechanical systems with one degree of underactuation. The approach starts with partial feedback linearization and stabilization. Then, transverse linearization along the reference orbit is computed, resulting in a periodic linear time-varying system with a stable subspace. Sliding-mode control drives trajectories toward this subspace. The proposed design avoids solving computationally intensive periodic LQR problems and improves robustness to matched disturbances. The methodology is validated through experiments on the Butterfly robot.

【11】CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding
- **标题**: CRAFT-E：体现可供性基础的神经符号框架
- **链接**: https://arxiv.org/abs/2512.04231
> **作者**: Zhou Chen,Joe Lin,Carson Bulgin,Sathyanarayanan N. Aakur
> **摘要**: 在非结构化环境中运行的辅助机器人不仅必须了解物体是什么，还要了解它们的用途。这需要将基于语言的动作查询建立在既能提供所请求的功能又能被物理检索的对象的基础上。现有方法通常依赖于黑盒模型或固定可供性标签，限制了面向人的应用程序的透明度、可控性和可靠性。我们介绍了 CRAFT-E，这是一个模块化的神经符号框架，它构成了一个结构化的动词-属性-对象知识图谱，具有视觉语言对齐和基于能量的掌握推理。该系统生成可解释的基础路径，揭示影响对象选择的因素，并将抓取可行性作为可供性推理的一个组成部分。我们进一步构建了一个具有统一注释的基准数据集，用于动宾兼容性、分割和抓取候选者，并将完整的管道部署在物理机器人上。 CRAFT-E 在静态场景、基于 ImageNet 的功能检索以及涉及 20 个动词和 39 个物体的真实世界试验中实现了有竞争力的性能。该框架在感知噪声下保持稳健，并提供透明的组件级诊断。通过将符号推理与具体感知相结合，CRAFT-E 为基于可供性的对象选择的端到端模型提供了一种可解释和可定制的替代方案，支持辅助机器人系统中的可信决策。
> **Abstract**: Assistive robots operating in unstructured environments must understand not only what objects are, but what they can be used for. This requires grounding language-based action queries to objects that both afford the requested function and can be physically retrieved. Existing approaches often rely on black-box models or fixed affordance labels, limiting transparency, controllability, and reliability for human-facing applications. We introduce CRAFT-E, a modular neuro-symbolic framework that composes a structured verb-property-object knowledge graph with visual-language alignment and energy-based grasp reasoning. The system generates interpretable grounding paths that expose the factors influencing object selection and incorporates grasp feasibility as an integral part of affordance inference. We further construct a benchmark dataset with unified annotations for verb-object compatibility, segmentation, and grasp candidates, and deploy the full pipeline on a physical robot. CRAFT-E achieves competitive performance in static scenes, ImageNet-based functional retrieval, and real-world trials involving 20 verbs and 39 objects. The framework remains robust under perceptual noise and provides transparent, component-level diagnostics. By coupling symbolic reasoning with embodied perception, CRAFT-E offers an interpretable and customizable alternative to end-to-end models for affordance-grounded object selection, supporting trustworthy decision-making in assistive robotic systems.

【12】Artificial Microsaccade Compensation: Stable Vision for an Ornithopter
- **标题**: 人工微扫视补偿：扑翼机的稳定视觉
- **链接**: https://arxiv.org/abs/2512.03995
> **作者**: Levi Burner,Guido de Croon,Yiannis Aloimonos
> **摘要**: 具有中心凹视觉的动物（包括人类）会经历微扫视，即它们没有意识到的小而快速的眼球运动。受这种现象的启发，我们开发了一种“人工微眼跳补偿”方法。它可以稳定无尾扑翼机捕获的视频，该扑翼机一直抵制使用基于摄像头的传感技术，因为它会以 12-20 Hz 的频率抖动。我们的方法通过优化 SO(3) 中表示的 3D 旋转来最小化图像强度的变化。这会产生稳定的视频，实时计算，适合人类观看，并且不失真。当适应于保持固定的观看方向时，直到偶尔的扫视，它可以显着减少帧间运动，同时还受益于高效的递归更新。与 Adob​​e Premier Pro 的扭曲稳定器（被广泛认为是最好的商业视频稳定软件）相比，我们的方法在实时运行的同时实现了更高质量的结果。
> **Abstract**: Animals with foveated vision, including humans, experience microsaccades, small, rapid eye movements that they are not aware of. Inspired by this phenomenon, we develop a method for "Artificial Microsaccade Compensation". It can stabilize video captured by a tailless ornithopter that has resisted attempts to use camera-based sensing because it shakes at 12-20 Hz. Our approach minimizes changes in image intensity by optimizing over 3D rotation represented in SO(3). This results in a stabilized video, computed in real time, suitable for human viewing, and free from distortion. When adapted to hold a fixed viewing orientation, up to occasional saccades, it can dramatically reduce inter-frame motion while also benefiting from an efficient recursive update. When compared to Adobe Premier Pro's warp stabilizer, which is widely regarded as the best commercial video stabilization software available, our method achieves higher quality results while also running in real time.

【13】MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation
- **标题**: MDE-AgriVLN：具有单目深度估计的农业视觉和语言导航
- **链接**: https://arxiv.org/abs/2512.03958
> **作者**: Xiaobei Zhao,Xingqi Lyu,Xiang Li
> **摘要**: 农业机器人在各种农业任务中发挥着强大的助手作用，但仍然严重依赖手动操作或铁路系统进行移动。 AgriVLN方法和A2A基准开创性地将视觉和语言导航（VLN）扩展到农业领域，使机器人能够按照自然语言指令导航到目标位置。与人类双目视觉不同，大多数农业机器人仅配备一个用于单目视觉的相机，这导致空间感知有限。为了弥补这一差距，我们提出了单目深度估计的农业视觉和语言导航方法（MDE-AgriVLN），其中我们提出了 MDE 模块从 RGB 图像生成深度特征，以协助决策者进行推理。在 A2A 基准上进行评估时，我们的 MDE-AgriVLN 方法成功地将成功率从 0.23 提高到 0.32，并将导航误差从 4.43m 降低到 4.08m，展示了农业 VLN 领域的最先进性能。代码：https://github.com/AlexTraveling/MDE-AgriVLN。
> **Abstract**: Agricultural robots are serving as powerful assistants across a wide range of agricultural tasks, nevertheless, still heavily relying on manual operations or railway systems for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling a robot to navigate to a target position following a natural language instruction. Unlike human binocular vision, most agricultural robots are only given a single camera for monocular vision, which results in limited spatial perception. To bridge this gap, we present the method of Agricultural Vision-and-Language Navigation with Monocular Depth Estimation (MDE-AgriVLN), in which we propose the MDE module generating depth features from RGB images, to assist the decision-maker on reasoning. When evaluated on the A2A benchmark, our MDE-AgriVLN method successfully increases Success Rate from 0.23 to 0.32 and decreases Navigation Error from 4.43m to 4.08m, demonstrating the state-of-the-art performance in the agricultural VLN domain. Code: https://github.com/AlexTraveling/MDE-AgriVLN.

【14】Driving is a Game: Combining Planning and Prediction with Bayesian Iterative Best Response
- **标题**: 驾驶是一场游戏：将规划和预测与贝叶斯迭代最佳响应相结合
- **链接**: https://arxiv.org/abs/2512.03936
> **作者**: Aron Distelzweig,Yiwei Wang,Faris Janjoš,Marcel Hallgarten,Mihai Dobre,Alexander Langmann,Joschka Boedecker,Johannes Betz
> **摘要**: 自动驾驶规划系统使用轻量级、基于规则的方法在常规场景中表现近乎完美，但在密集的城市交通中仍然举步维艰，因为在城市交通中，车道变换和合并需要预测和影响其他智能体。现代运动预测器提供高度准确的预测，但它们与规划的集成大多是初级的：丢弃不安全的计划。同样，端到端模型提供了一种单向集成，可以避免不确定性下联合预测和规划建模的挑战。相比之下，博弈论公式提供了一种原则性的替代方案，但在自动驾驶中的采用有限。我们提出了贝叶斯迭代最佳响应（BIBeR），这是一个将运动预测和博弈论规划统一到单个交互感知过程中的框架。 BIBeR 是第一个将最先进的预测器集成到迭代最佳响应 (IBR) 循环中的技术，反复完善自我车辆和周围智能体的策略。这种重复的最佳反应过程近似于纳什均衡，从而实现双向适应，自我既对他人做出反应，又塑造他人的行为。此外，我们提出的贝叶斯置信度估计量化了预测可靠性并调节更新强度，在低置信度下更加保守，在高置信度下更加果断。 BIBeR 与现代预测器和规划器兼容，将结构化规划的透明度与学习模型的灵活性相结合。实验表明，BIBeR 在高度交互的 InterPlan 变道场景上比最先进的规划器提高了 11%，同时在标准 nuPlan 基准上也优于现有方法。
> **Abstract**: Autonomous driving planning systems perform nearly perfectly in routine scenarios using lightweight, rule-based methods but still struggle in dense urban traffic, where lane changes and merges require anticipating and influencing other agents. Modern motion predictors offer highly accurate forecasts, yet their integration into planning is mostly rudimental: discarding unsafe plans. Similarly, end-to-end models offer a one-way integration that avoids the challenges of joint prediction and planning modeling under uncertainty. In contrast, game-theoretic formulations offer a principled alternative but have seen limited adoption in autonomous driving. We present Bayesian Iterative Best Response (BIBeR), a framework that unifies motion prediction and game-theoretic planning into a single interaction-aware process. BIBeR is the first to integrate a state-of-the-art predictor into an Iterative Best Response (IBR) loop, repeatedly refining the strategies of the ego vehicle and surrounding agents. This repeated best-response process approximates a Nash equilibrium, enabling bidirectional adaptation where the ego both reacts to and shapes the behavior of others. In addition, our proposed Bayesian confidence estimation quantifies prediction reliability and modulates update strength, more conservative under low confidence and more decisive under high confidence. BIBeR is compatible with modern predictors and planners, combining the transparency of structured planning with the flexibility of learned models. Experiments show that BIBeR achieves an 11% improvement over state-of-the-art planners on highly interactive interPlan lane-change scenarios, while also outperforming existing approaches on standard nuPlan benchmarks.

【15】Hierarchical Vision Language Action Model Using Success and Failure Demonstrations
- **标题**: 使用成功和失败演示的分层视觉语言动作模型
- **链接**: https://arxiv.org/abs/2512.03913
> **作者**: Jeongeun Park,Jihwan Yoon,Byungwoo Jeon,Juhan Park,Jinwoo Shin,Namhoon Cho,Kyungjae Lee,Sangdoo Yun,Sungjoon Choi
> **摘要**: 先前的视觉-语言-动作（VLA）模型通常是在远程操作的成功演示上进行训练的，同时丢弃数据收集过程中自然发生的大量失败尝试。然而，这些失败编码了政策在何处以及如何脆弱，可以利用这些信息来提高稳健性。我们通过利用混合质量数据集在规划时学习故障感知推理来解决这个问题。我们引入了 VINE，一种分层视觉-语言-动作模型，它在分层强化学习形式主义下将高级推理（系统 2）与低级控制（系统 1）分开，使失败可用作结构化学习信号而不是噪声监督。系统 2 在 2D 场景图抽象上执行可行性引导树搜索：它提出子目标转换，根据成功和失败预测成功概率，并在执行前修剪脆弱的分支，有效地将计划评估作为可行性评分。然后将选定的子目标序列传递到系统 1，该系统执行低级操作而不修改代理的核心技能。 VINE 完全根据离线远程操作数据进行训练，将负面经验直接集成到决策循环中。在具有挑战性的操作任务中，这种方法不断提高成功率和鲁棒性，证明故障数据是将 VLA 的广泛能力转化为强大执行力的重要资源。
> **Abstract**: Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.

【16】Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware
- **标题**: 使用英特尔 Loihi 2 神经形态硬件进行自主强化学习机器人控制
- **链接**: https://arxiv.org/abs/2512.03911
> **作者**: Kenneth Stewart,Roxana Leontie,Samantha Chapin,Joe Hays,Sumit Bam Shrestha,Carl Glen Henshaw
> **摘要**: 我们提出了一种端到端管道，用于在神经形态硬件上部署经过强化学习 (RL) 训练的人工神经网络 (ANN)，方法是将其转换为尖峰 Sigma-Delta 神经网络 (SDNN)。我们证明，完全在模拟中训练的 ANN 策略可以转换为与英特尔 Loihi 2 架构兼容的 SDNN，从而实现低延迟和节能的推理。作为测试用例，我们使用 RL 策略来控制 Astrobee 自由飞行机器人，类似于之前经过空间验证的控制器中的硬件。该策略使用整流线性单元 (ReLU) 进行训练，转换为 SDNN 并部署在英特尔的 Loihi 2 上，然后在 NVIDIA 的 Omniverse Isaac Lab 模拟环境中进行评估，以实现 Astrobee 运动的闭环控制。我们比较了 GPU 和 Loihi 2 之间的执行性能。结果强调了使用神经拟态平台进行机器人控制的可行性，并为未来太空和地面机器人应用中的节能、实时神经拟态计算建立了一条途径。
> **Abstract**: We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.

【17】Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning
- **标题**: 基于数字孪生的整车主动悬架深度强化学习控制协同设计
- **链接**: https://arxiv.org/abs/2512.03891
> **作者**: Ying-Kuan Tsai,Yi-Ping Chen,Vispi Karkaria,Wei Chen
> **摘要**: 主动悬架系统对于提高车辆舒适性、安全性和稳定性至关重要，但其性能往往受到固定硬件设计和控制策略的限制，无法适应不确定和动态的操作条件。数字孪生 (DT) 和深度强化学习 (DRL) 的最新进展为整个车辆生命周期中数据驱动的实时优化提供了新的机会。然而，将这些技术集成到统一框架中仍然是一个开放的挑战。这项工作提出了一种基于 DT 的控制协同设计 (CCD) 框架，用于使用多代设计概念的整车主动悬架。通过将自动微分集成到 DRL 中，我们在不同的驾驶员行为和环境不确定性下共同优化物理悬架组件和控制策略。 DRL 还解决了部分可观测性的挑战，即通过直接从可用的传感器信息学习最佳控制动作，只能感知有限的状态并将其反馈给控制器。该框架将模型更新与分位数学习相结合，以捕获数据不确定性，从而实现数字物理交互的实时决策和自适应学习。该方法展示了两种不同驾驶设置（温和和激进）下悬架系统的个性化优化。结果表明，优化后的系统可实现更平滑的轨迹，并在轻度和攻击性情况下分别减少约 43% 和 52% 的控制工作量，同时保持乘坐舒适性和稳定性。贡献包括：开发集成 DRL 和整车主动悬架不确定性感知模型更新的支持 DT 的 CCD 框架，引入自我改进系统的多代设计策略，以及针对不同驾驶员类型展示主动悬架系统的个性化优化。
> **Abstract**: Active suspension systems are critical for enhancing vehicle comfort, safety, and stability, yet their performance is often limited by fixed hardware designs and control strategies that cannot adapt to uncertain and dynamic operating conditions. Recent advances in digital twins (DTs) and deep reinforcement learning (DRL) offer new opportunities for real-time, data-driven optimization across a vehicle's lifecycle. However, integrating these technologies into a unified framework remains an open challenge. This work presents a DT-based control co-design (CCD) framework for full-vehicle active suspensions using multi-generation design concepts. By integrating automatic differentiation into DRL, we jointly optimize physical suspension components and control policies under varying driver behaviors and environmental uncertainties. DRL also addresses the challenge of partial observability, where only limited states can be sensed and fed back to the controller, by learning optimal control actions directly from available sensor information. The framework incorporates model updating with quantile learning to capture data uncertainty, enabling real-time decision-making and adaptive learning from digital-physical interactions. The approach demonstrates personalized optimization of suspension systems under two distinct driving settings (mild and aggressive). Results show that the optimized systems achieve smoother trajectories and reduce control efforts by approximately 43% and 52% for mild and aggressive, respectively, while maintaining ride comfort and stability. Contributions include: developing a DT-enabled CCD framework integrating DRL and uncertainty-aware model updating for full-vehicle active suspensions, introducing a multi-generation design strategy for self-improving systems, and demonstrating personalized optimization of active suspension systems for distinct driver types.

【18】A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments
- **标题**: 受控环境下自动驾驶赛车的模块化架构设计
- **链接**: https://arxiv.org/abs/2512.03886
> **作者**: Brais Fontan-Costas,M. Diaz-Cacho,Ruben Fernandez-Boullon,Manuel Alonso-Carracedo,Javier Perez-Robles
> **摘要**: 本文提出了一种闭路车辆的自主系统 (AS) 架构。 AS 执行精密任务，包括用于环境感知的计算机视觉、用于精确定位的定位和绘图、用于生成最佳轨迹的路径规划以及用于精确车辆驱动的控制。每个子系统独立运行，同时通过内聚的管道架构连接数据。该系统采用模块化设计，结合了最先进的技术，可在受控环境中进行实时自主导航。
> **Abstract**: This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.

【19】OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance
- **标题**: OmniDexVLG：从视觉语言模型引导的抓取语义、分类和功能可供性中学习灵巧的抓取生成
- **链接**: https://arxiv.org/abs/2512.03874
> **作者**: Lei Zhang,Diwen Zheng,Kaixin Bai,Zhenshan Bing,Zoltan-Csaba Marton,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang
> **摘要**: 灵巧抓取生成旨在生成符合任务要求和人类可解释抓取语义的抓取姿势。然而，由于缺乏多个语义维度的统一建模，包括抓取分类、接触语义和功能可供性，实现语义可控的灵巧抓取合成仍然非常具有挑战性。为了解决这些限制，我们提出了 OmniDexVLG，这是一种多模式、语义感知的抓取生成框架，能够在联合语言和视觉引导下产生结构多样且语义连贯的灵巧抓取。我们的方法从 OmniDexDataGen 开始，这是一个语义丰富的灵巧抓取数据集生成管道，集成了抓取分类引导配置采样、功能可供性接触点采样、分类感知微分力闭合抓取采样以及基于物理的优化和验证，从而能够系统地覆盖不同的抓取类型。我们进一步介绍了 OmniDexReasoner，这是一种多模式抓取类型语义推理模块，它利用多代理协作、检索增强生成和思维链推理来推断抓取相关语义并生成高质量注释，使语言指令与特定于任务的抓取意图保持一致。在这些组件的基础上，我们开发了一个统一的视觉语言抓取生成模型，该模型明确地结合了抓取分类、接触结构和功能可供性语义，从而能够对自然语言指令的抓取合成进行细粒度控制。模拟和现实世界对象抓取和消融研究中的大量实验表明，我们的方法在抓取多样性、接触语义多样性、功能可供性多样性和语义一致性方面远远优于最先进的方法。
> **Abstract**: Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.

【20】IM HERE: Interaction Model for Human Effort Based Robot Engagement
- **标题**: IM HERE：基于人类努力的机器人参与的交互模型
- **链接**: https://arxiv.org/abs/2512.03828
> **作者**: Dominykas Strazdas,Magnus Jung,Jan Marquenie,Ingo Siegert,Ayoub Al-Hamadi
> **摘要**: 人机交互的有效性通常取决于培养参与度的能力，这是一种支持有意义的交流的认知参与的动态过程。许多现有的参与定义和模型要么过于模糊，要么缺乏在不同背景下进行概括的能力。我们介绍 IM HERE，这是一个新颖的框架，可以有效地模拟人与人、人与机器人以及机器人与机器人交互中的参与。通过对实体之间的双边关系采用基于努力的描述，我们提供了关系模式的准确细分，将其简化为焦点放置和四个关键状态。该框架捕获了符合社会规范的相互关系、群体行为和行动，并将它们转化为自治系统的具体指令。通过整合主观感知和客观状态，该模型可以精确识别和描述沟通不畅。本文的主要目标是自动化对社会行为的分析、建模和描述，并确定自治系统如何按照社会规范行事，以实现全面的社会融合，同时追求自己的社会目标。
> **Abstract**: The effectiveness of human-robot interaction often hinges on the ability to cultivate engagement - a dynamic process of cognitive involvement that supports meaningful exchanges. Many existing definitions and models of engagement are either too vague or lack the ability to generalize across different contexts. We introduce IM HERE, a novel framework that models engagement effectively in human-human, human-robot, and robot-robot interactions. By employing an effort-based description of bilateral relationships between entities, we provide an accurate breakdown of relationship patterns, simplifying them to focus placement and four key states. This framework captures mutual relationships, group behaviors, and actions conforming to social norms, translating them into specific directives for autonomous systems. By integrating both subjective perceptions and objective states, the model precisely identifies and describes miscommunication. The primary objective of this paper is to automate the analysis, modeling, and description of social behavior, and to determine how autonomous systems can behave in accordance with social norms for full social integration while simultaneously pursuing their own social goals.

【21】MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving
- **标题**: MPCFormer：一种基于物理的数据驱动方法，用于可解释的社交意识自动驾驶
- **链接**: https://arxiv.org/abs/2512.03795
> **作者**: Jia Hu,Zhexi Lian,Xuerun Yan,Ruiang Bi,Dou Shen,Yu Ruan,Haoran Wang
> **摘要**: 自动驾驶 (AD) 车辆仍然难以在高度动态和交互式的交通场景中表现出类人行为。关键的挑战在于 AD 与周围车辆交互的能力有限，这很大程度上是由于缺乏对社交交互的基本机制的理解。为了解决这个问题，我们引入了 MPCFormer，这是一种可解释的社交感知自动驾驶方法，具有物理信息和数据驱动的耦合社交互动动态。在该模型中，动力学被表述为离散空间状态表示，其中嵌入物理先验以增强建模可解释性。动态系数是通过基于 Transformer 的编码器-解码器架构从自然驾驶数据中学习的。据我们所知，MPCFormer 是第一个对多车辆社交互动动态进行显式建模的方法。学习到的社交互动动态使规划者能够在与周围交通互动时产生多种类似人类的行为。通过利用 MPC 框架，该方法减轻了通常与纯粹基于学习的方法相关的潜在安全风险。对 NGSIM 数据集的开环评估表明，MPCFormer 实现了卓越的社交互动意识，与其他最先进的方法相比，产生了最低的轨迹预测误差。该预测在 5 秒的长预测范围内实现了低至 0.86 m 的 ADE。在高度激烈的交互场景中进行闭环实验，其中需要连续变道才能退出匝道，进一步验证了 MPCFormer 的有效性。结果表明，MPCFormer 的规划成功率最高为 94.67%，驾驶效率提高了 15.75%，碰撞率从 21.25% 降低到 0.5%，优于前沿的基于强化学习（RL）的规划器。
> **Abstract**: Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.

【22】Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving
- **标题**: 安全强化模型预测控制 (SRMPC)：通过强化学习改进自动驾驶运动规划的 MPC
- **链接**: https://arxiv.org/abs/2512.03774
> **作者**: Johannes Fischer,Marlon Steiner,Ömer Sahin Tas,Christoph Stiller
> **摘要**: 模型预测控制（MPC）广泛用于运动规划，特别是在自动驾驶中。规划器的实时能力需要利用规划器的最优控制问题（OCP）的凸近似。然而，这种近似将解决方案限制在子空间内，该子空间可能不包含全局最优值。为了解决这个问题，我们建议使用安全强化学习 (SRL) 在 MPC 中获取新的安全参考轨迹。通过采用基于学习的方法，MPC 可以探索前一个解决方案附近的解决方案，从而有可能找到全局最优解。我们结合约束强化学习（CRL）来确保自动驾驶的安全性，使用手工设计的基于能量函数的安全指数作为约束目标来建模安全和不安全区域。我们的方法利用与安全策略同时学习的状态相关拉格朗日乘数来解决 CRL 问题。通过在高速公路场景中进行实验，我们证明了我们的方法在安全性和性能指标方面相对于 MPC 和 SRL 的优越性。
> **Abstract**: Model predictive control (MPC) is widely used for motion planning, particularly in autonomous driving. Real-time capability of the planner requires utilizing convex approximation of optimal control problems (OCPs) for the planner. However, such approximations confine the solution to a subspace, which might not contain the global optimum. To address this, we propose using safe reinforcement learning (SRL) to obtain a new and safe reference trajectory within MPC. By employing a learning-based approach, the MPC can explore solutions beyond the close neighborhood of the previous one, potentially finding global optima. We incorporate constrained reinforcement learning (CRL) to ensure safety in automated driving, using a handcrafted energy function-based safety index as the constraint objective to model safe and unsafe regions. Our approach utilizes a state-dependent Lagrangian multiplier, learned concurrently with the safe policy, to solve the CRL problem. Through experimentation in a highway scenario, we demonstrate the superiority of our approach over both MPC and SRL in terms of safety and performance measures.

【23】Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control
- **标题**: 用于扭矩级非线性模型预测控制自动调节的贝叶斯优化
- **链接**: https://arxiv.org/abs/2512.03772
> **作者**: Gabriele Fadini,Deepak Ingole,Tong Duy Son,Alisa Rupenyan
> **摘要**: 本文提出了一种基于扭矩的非线性模型预测控制（nMPC）的自动调整框架，其中 MPC 充当最佳关节扭矩命令的实时控制器。 MPC 参数（包括成本函数权重和低级控制器增益）使用高维贝叶斯优化 (BO) 技术进行优化，特别是具有数字孪生 (DT) 的稀疏轴对齐子空间 (SAASBO)，以在 UR10e 机器人手臂上实现精确的末端执行器轨迹实时跟踪。该仿真模型可以有效地探索高维参数空间，并确保安全传输到硬件。我们的模拟结果表明，与手动调整参数相比，跟踪性能显着提高 (+41.9%)，求解时间缩短 (-2.5%)。此外，对真实机器人的实验验证也遵循了这一趋势（提高了 25.8%），强调了数字孪生支持的自动参数优化对机器人操作的重要性。
> **Abstract**: This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.

【24】Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models
- **标题**: 预测驱动的运动规划：基于注意力的预测模型中的路线集成策略
- **链接**: https://arxiv.org/abs/2512.03756
> **作者**: Marlon Steiner,Royden Wagner,Ömer Sahin Tas,Christoph Stiller
> **摘要**: 运动预测和运动规划的结合为增强自动驾驶车辆和其他交通参与者之间的交互提供了一个有前途的框架。然而，这给导航目标的预测调节和确保稳定、运动学上可行的轨迹带来了挑战。为了解决前一个挑战，本文研究了基于注意力的运动预测模型与导航信息的扩展。通过将自我车辆的预期路线和目标姿态集成到模型架构中，我们弥合了多智能体运动预测和基于目标的运动规划之间的差距。我们在 nuPlan 数据集上针对我们的模型提出并评估了几种架构导航集成策略。我们的结果证明了预测驱动的运动规划的潜力，强调了导航信息如何增强预测和规划任务。我们的实现位于：https://github.com/KIT-MRT/future-motion。
> **Abstract**: Combining motion prediction and motion planning offers a promising framework for enhancing interactions between automated vehicles and other traffic participants. However, this introduces challenges in conditioning predictions on navigation goals and ensuring stable, kinematically feasible trajectories. Addressing the former challenge, this paper investigates the extension of attention-based motion prediction models with navigation information. By integrating the ego vehicle's intended route and goal pose into the model architecture, we bridge the gap between multi-agent motion prediction and goal-based motion planning. We propose and evaluate several architectural navigation integration strategies to our model on the nuPlan dataset. Our results demonstrate the potential of prediction-driven motion planning, highlighting how navigation information can enhance both prediction and planning tasks. Our implementation is at: https://github.com/KIT-MRT/future-motion.

【25】Cross-embodied Co-design for Dexterous Hands
- **标题**: 灵巧双手的交叉体现协同设计
- **链接**: https://arxiv.org/abs/2512.03743
> **作者**: Kehlani Fay,Darin Anthony Djapri,Anya Zorin,James Clinton,Ali El Lahib,Hao Su,Michael T. Tolley,Sha Yi,Xiaolong Wang
> **摘要**: 灵巧的操纵受到控制和设计的限制，对于什么使操纵器最适合执行灵巧的任务还没有达成共识。这就提出了一个根本性的挑战：我们应该如何设计和控制针对灵活性进行优化的机器人操纵器？我们提出了一个协同设计框架，可以学习特定任务的手部形态和互补的灵巧控制策略。该框架支持 1) 广阔的形态搜索空间，包括关节、手指和手掌生成，2) 通过形态条件交叉体现控制在广泛的设计空间中进行可扩展评估，3) 具有可访问组件的现实世界制造。我们评估了多种灵巧任务的方法，包括模拟和实际部署的手动旋转。我们的框架支持端到端管道，可以在 24 小时内设计、训练、制造和部署新的机器人手。完整的框架将开源并可在我们的网站上获取。
> **Abstract**: Dexterous manipulation is limited by both control and design, without consensus as to what makes manipulators best for performing dexterous tasks. This raises a fundamental challenge: how should we design and control robot manipulators that are optimized for dexterity? We present a co-design framework that learns task-specific hand morphology and complementary dexterous control policies. The framework supports 1) an expansive morphology search space including joint, finger, and palm generation, 2) scalable evaluation across the wide design space via morphology-conditioned cross-embodied control, and 3) real-world fabrication with accessible components. We evaluate the approach across multiple dexterous tasks, including in-hand rotation with simulation and real deployment. Our framework enables an end-to-end pipeline that can design, train, fabricate, and deploy a new robotic hand in under 24 hours. The full framework will be open-sourced and available on our website.

【26】Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control
- **标题**: 跨越仿真和地面测试之间的 Sim2Real 差距，实现自主自由飞行控制的空间部署
- **链接**: https://arxiv.org/abs/2512.03736
> **作者**: Kenneth Stewart,Samantha Chapin,Roxana Leontie,Carl Glen Henshaw
> **摘要**: 强化学习 (RL) 为太空机器人控制提供了变革潜力。我们在国际空间站 (ISS) 上首次展示了基于强化学习的自由飞行机器人 NASA Astrobee 的自主控制在轨演示。利用 NVIDIA 的 Omniverse 物理模拟器和课程学习，我们训练了一个深度神经网络来取代 Astrobee 的标准姿态和平移控制，使其能够在微重力下导航。我们的结果验证了一种新颖的训练管道，该管道可以弥合模拟与现实 (Sim2Real) 的差距，利用 GPU 加速的科学级模拟环境进行高效的蒙特卡洛强化学习训练。这次成功的部署证明了在地面上训练强化学习策略并将其转移到天基应用的可行性。这为未来的太空服务、装配和制造（ISAM）工作铺平了道路，从而能够快速在轨适应动态任务要求。
> **Abstract**: Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.

【27】Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing
- **标题**: 自主规划 太空组装 强化学习 自由飞行器 (APIARY) 国际空间站 Astrobee 测试
- **链接**: https://arxiv.org/abs/2512.03729
> **作者**: Samantha Chapin,Kenneth Stewart,Roxana Leontie,Carl Glen Henshaw
> **摘要**: 美国海军研究实验室 (NRL) 的自主规划太空装配强化学习自由飞行器 (APIARY) 实验开创了使用强化学习 (RL) 来控制零重力 (0-G) 太空环境中的自由飞行机器人的先河。据我们所知，2025 年 5 月 27 日星期二，APIARY 团队使用国际空间站 (ISS) 上的 NASA Astrobee 机器人对太空中的自由飞行器进行了首次强化学习控制。在 NVIDIA Isaac Lab 模拟环境中，使用 Actor-Critic 近端策略优化 (PPO) 网络训练鲁棒的 6 自由度 (DOF) 控制策略，随机化目标姿势和质量分布以增强鲁棒性。本文详细介绍了该实验的模拟测试、地面测试和飞行验证。这次在轨演示验证了强化学习在提高机器人自主性方面的变革潜力，能够快速开发和部署（在几分钟到几小时内）满足太空探索、后勤和实时任务需求的定制行为。
> **Abstract**: The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.

【28】ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration
- **标题**: ContactRL：基于安全强化学习的运动规划，用于基于接触的人类机器人协作
- **链接**: https://arxiv.org/abs/2512.03707
> **作者**: Sundas Rafat Mulkana,Ronyu Yu,Tanaya Guha,Emma Li
> **摘要**: 在人机协作任务中，安全不仅需要避免碰撞，还需要确保安全、有意的身体接触。我们提出了 ContactRL，这是一种基于强化学习 (RL) 的框架，它通过力反馈将接触安全直接纳入奖励函数中。这使得机器人能够学习自适应运动轨迹，从而最大限度地减少人机接触力，同时保持任务效率。在模拟中，ContactRL 实现了 0.2% 的低安全违规率和 87.7% 的高任务成功率，优于最先进的约束 RL 基线。为了保证部署安全，我们使用基于动能的控制屏障功能（eCBF）屏蔽来增强学习策略。在 UR3e 机器人平台上进行的 360 次人手小物体交接实验证实了安全接触，测得的法向力始终低于 10N。这些结果表明，ContactRL 可实现安全高效的物理协作，从而推动协作机器人在接触丰富的任务中的部署。
> **Abstract**: In collaborative human-robot tasks, safety requires not only avoiding collisions but also ensuring safe, intentional physical contact. We present ContactRL, a reinforcement learning (RL) based framework that directly incorporates contact safety into the reward function through force feedback. This enables a robot to learn adaptive motion profiles that minimize human-robot contact forces while maintaining task efficiency. In simulation, ContactRL achieves a low safety violation rate of 0.2\% with a high task success rate of 87.7\%, outperforming state-of-the-art constrained RL baselines. In order to guarantee deployment safety, we augment the learned policy with a kinetic energy based Control Barrier Function (eCBF) shield. Real-world experiments on an UR3e robotic platform performing small object handovers from a human hand across 360 trials confirm safe contact, with measured normal forces consistently below 10N. These results demonstrate that ContactRL enables safe and efficient physical collaboration, thereby advancing the deployment of collaborative robots in contact-rich tasks.

【29】A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection
- **标题**: 使用具有语义分割和关键点检测功能的混合夹具来收获番茄的新方法
- **链接**: https://arxiv.org/abs/2512.03684
> **作者**: Shahid Ansari,Mahendra Kumar Gohil,Yusuke Maeda,Bishakh Bhattacharya
> **摘要**: 本文提出了一种围绕混合机器人抓手构建的自主番茄收获系统，该系统将六个柔软的拉胀手指与刚性外骨骼和乳胶篮相结合，以实现轻柔的笼状抓握。该夹具由伺服驱动的苏格兰轭机构驱动，包括形成圆锥台的分离叶，用于水果分离，并带有用于蒂切的集成微伺服刀具。对于感知，RGB--D 相机和基于 Detectron2 的管道对成熟/未成熟的西红柿进行语义分割，并在遮挡和可变照明下对蒂和果实中心进行关键点定位。使用虚拟功原理导出的分析模型将伺服扭矩与抓握力联系起来，从而能够对驱动要求进行设计级推理。在执行过程中，使用比例积分微分控制器实现闭环抓力调节，并通过安装在选定手指上的力敏电阻器进行反馈，以防止打滑和擦伤。运动执行由基于粒子群优化 (PSO) 的五自由度机械臂轨迹规划支持。实验证明了完整的采摘周期（接近、分离、切割、抓取、运输、释放），平均周期时间为 24.34~s，总体成功率约为 80\%，同时保持较低的抓取力 (0.20--0.50~N)。这些结果验证了所提出的混合夹具和集成视觉控制管道，可在杂乱的环境中实现可靠的收获。
> **Abstract**: This paper presents an autonomous tomato-harvesting system built around a hybrid robotic gripper that combines six soft auxetic fingers with a rigid exoskeleton and a latex basket to achieve gentle, cage-like grasping. The gripper is driven by a servo-actuated Scotch--yoke mechanism, and includes separator leaves that form a conical frustum for fruit isolation, with an integrated micro-servo cutter for pedicel cutting. For perception, an RGB--D camera and a Detectron2-based pipeline perform semantic segmentation of ripe/unripe tomatoes and keypoint localization of the pedicel and fruit center under occlusion and variable illumination. An analytical model derived using the principle of virtual work relates servo torque to grasp force, enabling design-level reasoning about actuation requirements. During execution, closed-loop grasp-force regulation is achieved using a proportional--integral--derivative controller with feedback from force-sensitive resistors mounted on selected fingers to prevent slip and bruising. Motion execution is supported by Particle Swarm Optimization (PSO)--based trajectory planning for a 5-DOF manipulator. Experiments demonstrate complete picking cycles (approach, separation, cutting, grasping, transport, release) with an average cycle time of 24.34~s and an overall success rate of approximately 80\%, while maintaining low grasp forces (0.20--0.50~N). These results validate the proposed hybrid gripper and integrated vision--control pipeline for reliable harvesting in cluttered environments.

【30】Context-Triggered Contingency Games for Strategic Multi-Agent Interaction
- **标题**: 用于战略性多智能体交互的上下文触发的应急博弈
- **链接**: https://arxiv.org/abs/2512.03639
> **作者**: Kilian Schweppe,Anne-Kathrin Schmuck
> **摘要**: 我们解决自主多智能体系统中可靠和高效交互的挑战，其中智能体必须平衡长期战略目标与短期动态适应。我们提出了上下文触发的应急博弈，这是一种源自时间逻辑规范的战略博弈与实时解决的动态应急博弈的新颖集成。我们的两层架构利用策略模板来保证高级目标的满足，而基于因子图的新求解器可实现动态交互的可扩展、实时模型预测控制。由此产生的框架确保了不确定的交互式环境中的安全性和进展。我们通过自动驾驶和机器人导航方面的模拟和硬件实验验证了我们的方法，展示了高效、可靠和自适应的多智能体交互。
> **Abstract**: We address the challenge of reliable and efficient interaction in autonomous multi-agent systems, where agents must balance long-term strategic objectives with short-term dynamic adaptation. We propose context-triggered contingency games, a novel integration of strategic games derived from temporal logic specifications with dynamic contingency games solved in real time. Our two-layered architecture leverages strategy templates to guarantee satisfaction of high-level objectives, while a new factor-graph-based solver enables scalable, real-time model predictive control of dynamic interactions. The resulting framework ensures both safety and progress in uncertain, interactive environments. We validate our approach through simulations and hardware experiments in autonomous driving and robotic navigation, demonstrating efficient, reliable, and adaptive multi-agent interaction.

【31】Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations
- **标题**: 机械手的多模态控制：自动驾驶实验室操作的运动学和视觉耦合
- **链接**: https://arxiv.org/abs/2512.03630
> **作者**: Shifa Sulaiman,Amarnath H,Simon Bogh,Naresh Marturi
> **摘要**: 运动规划方案用于规划任务执行期间机械手从初始姿势到最终姿势的运动。运动规划方案通常包括轨迹规划方法和逆运动学求解器，分别确定轨迹和关节解。在本文中，实现了基于雅可比方法开发的 3 种运动规划方案，以通过给定轨迹遍历具有耦合手指夹持器的冗余机械手。 RRT* 算法用于规划轨迹，并求解基于螺杆理论的正向运动学方程以确定机械手和夹具的联合解。使用 3 种基于雅可比行列式的方法分别计算逆解，例如雅可比转置 (JT)、伪逆 (PI) 和阻尼最小二乘法 (DLS) 方法。使用螺旋理论公式获得机械手和夹具的空间雅可比行列式和可操纵性测量。分析生成轨迹的平滑度和 RMSE 误差以及关节运动的速度连续性、加速度曲线、急动度和捕捉值，以确定针对给定任务的有效运动规划方法。使用仿真研究分析上述提出的运动规划方案的优点和缺点，以确定适合任务的逆解技术。
> **Abstract**: Motion planning schemes are used for planning motions of a manipulator from an initial pose to a final pose during a task execution. A motion planning scheme generally comprises of a trajectory planning method and an inverse kinematic solver to determine trajectories and joints solutions respectively. In this paper, 3 motion planning schemes developed based on Jacobian methods are implemented to traverse a redundant manipulator with a coupled finger gripper through given trajectories. RRT* algorithm is used for planning trajectories and screw theory based forward kinematic equations are solved for determining joint solutions of the manipulator and gripper. Inverse solutions are computed separately using 3 Jacobian based methods such as Jacobian Transpose (JT), Pseudo Inverse (PI), and Damped Least Square (DLS) methods. Space Jacobian and manipulability measurements of the manipulator and gripper are obtained using screw theory formulations. Smoothness and RMSE error of generated trajectories and velocity continuity, acceleration profile, jerk, and snap values of joint motions are analysed for determining an efficient motion planning method for a given task. Advantages and disadvantages of the proposed motion planning schemes mentioned above are analysed using simulation studies to determine a suitable inverse solution technique for the tasks.

【32】RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL
- **标题**: RoboScape-R：通过强化学习进行通用机器人训练的统一奖励观察世界模型
- **链接**: https://arxiv.org/abs/2512.03556
> **作者**: Yinzhou Tang,Yu Shang,Yinuo Chen,Bingwen Wei,Xin Zhang,Shu'ang Yu,Liangzhi Shi,Chao Yu,Chen Gao,Wei Wu,Yong Li
> **摘要**: 实现普遍化的具体政策仍然是一个关键挑战。传统的政策学习范式，包括模仿学习 (IL) 和强化学习 (RL)，很难培养跨不同场景的通用性。虽然 IL 策略经常过度拟合特定的专家轨迹，但 RL 固有地缺乏有效的多场景泛化所需的统一和通用的奖励信号。我们认为世界模型具有独特的能力作为通用环境代理来解决这一限制。然而，当前的世界模型主要关注预测观察的能力，并且仍然依赖于特定于任务的、手工设计的奖励函数，从而无法提供真正通用的训练环境。针对这个问题，我们提出了 RoboScape-R，这是一个利用世界模型作为 RL 范式内的具体环境的通用代理的框架。我们引入了一种新颖的基于世界模型的通用奖励机制，该机制根据模型对现实世界状态转换动态的内在理解产生“内生”奖励。大量实验表明，RoboScape-R 通过提供高效且通用的训练环境，显着增强具体策略的泛化能力，有效解决了传统强化学习方法的局限性。我们的方法提供了利用世界模型作为在线训练策略的重要见解，并且在域外场景下比基线平均实现了 37.5% 的性能提升。
> **Abstract**: Achieving generalizable embodied policies remains a key challenge. Traditional policy learning paradigms, including both Imitation Learning (IL) and Reinforcement Learning (RL), struggle to cultivate generalizability across diverse scenarios. While IL policies often overfit to specific expert trajectories, RL suffers from the inherent lack of a unified and general reward signal necessary for effective multi-scene generalization. We posit that the world model is uniquely capable of serving as a universal environment proxy to address this limitation. However, current world models primarily focus on their ability to predict observations and still rely on task-specific, handcrafted reward functions, thereby failing to provide a truly general training environment. Toward this problem, we propose RoboScape-R, a framework leveraging the world model to serve as a versatile, general-purpose proxy for the embodied environment within the RL paradigm. We introduce a novel world model-based general reward mechanism that generates ''endogenous'' rewards derived from the model's intrinsic understanding of real-world state transition dynamics. Extensive experiments demonstrate that RoboScape-R effectively addresses the limitations of traditional RL methods by providing an efficient and general training environment that substantially enhances the generalization capability of embodied policies. Our approach offers critical insights into utilizing the world model as an online training strategy and achieves an average 37.5% performance improvement over baselines under out-of-domain scenarios.

【33】A Learning-based Control Methodology for Transitioning VTOL UAVs
- **标题**: 用于过渡 VTOL 无人机的基于学习的控制方法
- **链接**: https://arxiv.org/abs/2512.03548
> **作者**: Zexin Lin,Yebin Zhong,Hanwen Wan,Jiu Cheng,Zhenglong Sun,Xiaoqiang Ji
> **摘要**: 由于倾转旋翼机构在过渡过程中会改变重心和推力方向，过渡控制对垂直起降无人机 (VTOL UAV) 的开发提出了严峻的挑战。当前控制方法对高度和位置的解耦控制会导致显着的振动，并限制交互考虑和适应性。在本研究中，我们提出了一种基于强化学习（RL）驱动控制器的新型耦合转换控制方法。此外，与传统的相变方法相比，ST3M方法通过将巡航模式视为悬停的特例，展示了一种新的视角。我们验证了在仿真和现实环境中应用我们的方法的可行性，展示了高效的控制器开发和迁移，同时精确控制无人机位置和姿态，表现出出色的轨迹跟踪并减少了过渡过程中的振动。
> **Abstract**: Transition control poses a critical challenge in Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL UAV) development due to the tilting rotor mechanism, which shifts the center of gravity and thrust direction during transitions. Current control methods' decoupled control of altitude and position leads to significant vibration, and limits interaction consideration and adaptability. In this study, we propose a novel coupled transition control methodology based on reinforcement learning (RL) driven controller. Besides, contrasting to the conventional phase-transition approach, the ST3M method demonstrates a new perspective by treating cruise mode as a special case of hover. We validate the feasibility of applying our method in simulation and real-world environments, demonstrating efficient controller development and migration while accurately controlling UAV position and attitude, exhibiting outstanding trajectory tracking and reduced vibrations during the transition process.

【34】AdaPower: Specializing World Foundation Models for Predictive Manipulation
- **标题**: AdaPower：专门用于预测操纵的世界基础模型
- **链接**: https://arxiv.org/abs/2512.03538
> **作者**: Yuhang Huang,Shilong Zou,Jiazhao Zhang,Xinwang Liu,Ruizhen Hu,Kai Xu
> **摘要**: 世界基础模型 (WFM) 提供了卓越的视觉动力学模拟功能，但其在精确机器人控制中的应用仍然受到生成现实性和面向控制的精度之间的差距的限制。虽然现有方法使用 WFM 作为合成数据生成器，但它们存在计算成本高且未充分利用预先训练的 VLA 策略的问题。我们引入了\textbf{AdaPower}（\textbf{Ada}pt和Em\textbf{power}），这是一个轻量级的适应框架，它通过两个新颖的组件将通用WFM转换为专业的世界模型：用于推理时间适应的时空测试时间训练（TS-TTT）和用于长范围一致性的记忆持久性（MP）。我们的适应世界模型集成在模型预测控制框架中，支持预先训练的 VLA，无需策略再训练即可在 LIBERO 基准上将任务成功率提高 41% 以上，同时保持计算效率和通才能力。
> **Abstract**: World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \textbf{AdaPower} (\textbf{Ada}pt and Em\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.

【35】MSG-Loc: Multi-Label Likelihood-based Semantic Graph Matching for Object-Level Global Localization
- **标题**: MSG-Loc：用于对象级全局定位的基于多标签似然的语义图匹配
- **链接**: https://arxiv.org/abs/2512.03522
> **作者**: Gihyeon Lee,Jungwoo Lee,Juwon Kim,Young-Sik Shin,Younggun Cho
> **摘要**: 机器人通常需要在具有未知对象类别和语义模糊性的环境中进行定位。然而，当使用语义对象执行全局定位时，高语义模糊性会加剧对象错误分类并增加错误关联的可能性，这反过来又会导致估计姿势的重大错误。因此，在这封信中，我们提出了一种用于对象级全局定位的基于多标签似然的语义图匹配框架。关键思想是利用多标签图表示，而不是单标签替代方案，来捕获和利用对象观察的固有语义上下文。基于这些表示，我们的方法通过上下文感知似然传播将每个节点的似然与其邻居的最大似然相结合，从而增强了图之间的语义对应。为了进行严格的验证，在闭集和开集检测配置下评估数据关联和姿态估计性能。此外，我们还展示了我们的方法在现实室内场景和合成环境中处理大词汇量对象类别的可扩展性。
> **Abstract**: Robots are often required to localize in environments with unknown object classes and semantic ambiguity. However, when performing global localization using semantic objects, high semantic ambiguity intensifies object misclassification and increases the likelihood of incorrect associations, which in turn can cause significant errors in the estimated pose. Thus, in this letter, we propose a multi-label likelihood-based semantic graph matching framework for object-level global localization. The key idea is to exploit multi-label graph representations, rather than single-label alternatives, to capture and leverage the inherent semantic context of object observations. Based on these representations, our approach enhances semantic correspondence across graphs by combining the likelihood of each node with the maximum likelihood of its neighbors via context-aware likelihood propagation. For rigorous validation, data association and pose estimation performance are evaluated under both closed-set and open-set detection configurations. In addition, we demonstrate the scalability of our approach to large-vocabulary object categories in both real-world indoor scenes and synthetic environments.

## 声音(cs.SD:Sound)

【1】AaPE: Aliasing-aware Patch Embedding for Self-Supervised Audio Representation Learning
- **标题**: AaPE：用于自监督音频表示学习的混叠感知补丁嵌入
- **链接**: https://arxiv.org/abs/2512.03637
> **作者**: Kohei Yamamoto,Kosuke Okusa
> **摘要**: 基于 Transformer 的音频 SSL（自监督学习）模型通常将频谱图视为图像，应用卷积修补和大量时间下采样。这会降低有效奈奎斯特频率并引入混叠，而简单的低通滤波会消除与任务相关的高频线索。在这项研究中，我们提出了锯齿感知补丁嵌入（AaPE），这是一种嵌入式补丁主干，可以在保留高频信息的同时减轻锯齿。 AaPE 通过使用动态针对容易出现混叠的频带的双边指数窗口的带限复杂正弦内核生成的功能来增强标准补丁令牌。内核的频率和衰减参数是根据输入估计的，从而实现并行、自适应子带分析，其输出与标准补丁标记融合。 AaPE 无缝融入蒙面师生自我监督学习。此外，我们将多掩模策略与对比目标相结合，以加强不同掩模模式的一致性，从而稳定训练。在 AudioSet 上进行预训练，然后对各种下游基准进行微调评估，这些基准涵盖环境声音和其他常见音频领域等类别。这种方法在部分任务上产生了最先进的性能，并在其余任务上产生了有竞争力的结果。互补线性探测评估反映了这种模式，在多个基准上产生了明显的收益，并在其他地方表现出色。对这些结果的集体分析表明，AaPE 可减轻混叠的影响，而不会丢弃信息丰富的高频内容。
> **Abstract**: Transformer-based audio SSL (self-supervised learning) models often treat spectrograms as images, applying convolutional patchification with heavy temporal downsampling. This lowers the effective Nyquist frequency and introduces aliasing, while naïve low-pass filtering removes task-relevant high-frequency cues. In this study, we present Aliasing-aware Patch Embedding (AaPE), a drop-in patch stem that mitigates aliasing while preserving high-frequency information. AaPE augments standard patch tokens with features produced by a band-limited complex sinusoidal kernel using a two-sided exponential window that dynamically targets alias-prone bands. Frequency and decay parameters of the kernel are estimated from the input, enabling parallel, adaptive subband analysis whose outputs are fused with the standard patch tokens. AaPE integrates seamlessly into the masked teacher-student self-supervised learning. In addition, we combine a multi-mask strategy with a contrastive objective to enforce consistency across diverse mask patterns, stabilizing training. Pre-training on AudioSet followed by fine-tuning evaluation across diverse downstream benchmarks, which spanned categories, such as environmental sounds and other common audio domains. This approach yields state-of-the-art performance on a subset of tasks and competitive results across the remainder. Complementary linear probing evaluation mirrors this pattern, yielding clear gains on several benchmarks and strong performance elsewhere. The collective analysis of these results indicates that AaPE serves to mitigate the effects of aliasing without discarding of informative high-frequency content.

【2】State Space Models for Bioacoustics: A comparative Evaluation with Transformers
- **标题**: 生物声学的状态空间模型：与 Transformer 的比较评估
- **链接**: https://arxiv.org/abs/2512.03563
> **作者**: Chengyu Tang,Sanjeev Baskiyar
> **摘要**: 在这项研究中，我们评估了曼巴模型在生物声学领域的功效。我们首先使用自监督学习在大型音频数据语料库上预训练基于 Mamba 的音频大语言模型 (LLM)。我们在 BEANS 基准（包括分类和检测在内的多种生物声学任务的集合）上对 BioMamba 进行微调和评估，并将其性能和效率与多个基线模型进行比较，包括 AVES（一种最先进的基于 Transformer 的模型）。结果表明，BioMamba 实现了与 AVES 相当的性能，同时消耗的 VRAM 显着减少，展示了其在该领域的潜力。
> **Abstract**: In this study, we evaluate the efficacy of the Mamba model in the field of bioacoustics. We first pretrain a Mamba-based audio large language model (LLM) on a large corpus of audio data using self-supervised learning. We fine-tune and evaluate BioMamba on the BEANS benchmark, a collection of diverse bioacoustic tasks including classification and detection, and compare its performance and efficiency with multiple baseline models, including AVES, a state-of-the-art Transformer-based model. The results show that BioMamba achieves comparable performance with AVES while consumption significantly less VRAM, demonstrating its potential in this domain.

## 软件工程(cs.SE:Software Engineering)

【1】Automating Complex Document Workflows via Stepwise and Rollback-Enabled Operation Orchestration
- **标题**: 通过逐步和支持回滚的操作编排自动化复杂的文档工作流程
- **链接**: https://arxiv.org/abs/2512.04445
> **作者**: Yanbin Zhang,Hanhui Ye,Yue Bai,Qiming Zhang,Liao Xiang,Wu Mianzhi,Renjun Hu
> **摘要**: 工作流程自动化有望大幅提高日常文档相关任务的生产力。虽然之前的代理系统可以执行独立的指令，但由于对操作过程的控制有限，它们很难实现多步骤、会话级工作流程的自动化。为此，我们引入了 AutoDW，这是一种新颖的执行框架，可以实现逐步的、支持回滚的操作编排。 AutoDW 根据用户指令、意图过滤的 API 候选以及文档的演变状态逐步规划 API 操作。它还在参数和 API 级别上进一步采用强大的回滚机制，从而实现动态纠正和容错。这些设计共同确保 AutoDW 的执行轨迹在长期工作流程中与用户意图和文档上下文保持一致。为了评估其有效性，我们构建了一个包含 250 个会话和 1,708 个人工注释指令的综合基准，反映了具有相互依赖的指令的真实文档处理场景。 AutoDW 在指令级和会话级任务上的完成率分别为 90% 和 62%，比强基线高出 40% 和 76%。此外，AutoDW 对于骨干法学硕士的决策和不同难度的任务也保持稳健。代码和数据将开源。代码：https://github.com/YJett/AutoDW
> **Abstract**: Workflow automation promises substantial productivity gains in everyday document-related tasks. While prior agentic systems can execute isolated instructions, they struggle with automating multi-step, session-level workflows due to limited control over the operational process. To this end, we introduce AutoDW, a novel execution framework that enables stepwise, rollback-enabled operation orchestration. AutoDW incrementally plans API actions conditioned on user instructions, intent-filtered API candidates, and the evolving states of the document. It further employs robust rollback mechanisms at both the argument and API levels, enabling dynamic correction and fault tolerance. These designs together ensure that the execution trajectory of AutoDW remains aligned with user intent and document context across long-horizon workflows. To assess its effectiveness, we construct a comprehensive benchmark of 250 sessions and 1,708 human-annotated instructions, reflecting realistic document processing scenarios with interdependent instructions. AutoDW achieves 90% and 62% completion rates on instruction- and session-level tasks, respectively, outperforming strong baselines by 40% and 76%. Moreover, AutoDW also remains robust for the decision of backbone LLMs and on tasks with varying difficulty. Code and data will be open-sourced. Code: https://github.com/YJett/AutoDW

【2】MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training
- **标题**: MANTRA：训练期间多阶段自适应噪声处理的框架
- **链接**: https://arxiv.org/abs/2512.04319
> **作者**: Zixiao Zhao,Fatemeh H. Fard,Jie JW Wu
> **摘要**: 深度学习模型在软件工程任务中的可靠应用取决于高质量的训练数据。然而，大规模存储库不可避免地会引入噪音或错误标记的示例，从而降低准确性和鲁棒性。虽然噪声标签学习 (NLL) 已在其他领域得到广泛研究，但仍有一些研究研究软件工程 (SE) 中的 NLL 和 SE 任务的大型语言模型 (LLM)。在这项工作中，我们提出了 MANTRA，一种多阶段自适应噪声处理框架，它将噪声诊断和缓解直接嵌入到代码预训练语言模型 (PTM) 和代码 LLM 的微调过程中。我们首先研究不同级别的噪声对模型收敛和损失轨迹的影响。然后，我们应用由每个样本损失动态和高斯混合模型聚类指导的自适应丢失策略，以排除持续存在的噪声点，同时保留干净的数据。应用于代码摘要和提交意图分类，我们的实验表明，一些法学硕士比其他法学硕士对噪音更敏感。然而，使用 MANTRA，所有模型在这两项任务中的性能都得到了提高。 MANTRA 使研究人员和从业者能够减少训练中数据集引入的错误的影响，节省数据清理和处理的时间，同时最大限度地提高微调的效果。
> **Abstract**: The reliable application of deep learning models to software engineering tasks hinges on high-quality training data. Yet, large-scale repositories inevitably introduce noisy or mislabeled examples that degrade both accuracy and robustness. While Noise Label Learning (NLL) has been extensively studied in other fields, there are a few works that investigate NLL in Software Engineering (SE) and Large Language Models (LLMs) for SE tasks. In this work, we propose MANTRA, a Multi-stage Adaptive Noise TReAtment framework that embeds noise diagnosis and mitigation directly into the fine-tuning process of code-Pretrained Language Models (PTM) and code-LLMs. We first investigate the effect of noise at varying levels on convergence and loss trajectories of the models. Then we apply an adaptive dropout strategy guided by per-sample loss dynamics and Gaussian Mixture Model clustering to exclude persistently noisy points while preserving clean data. Applying to code summarization and commit intent classification, our experiments reveal that some LLMs are more sensitive to noise than others. However, with MANTRA, the performance of all models in both tasks is improved. MANTRA enables researchers and practitioners to reduce the impact of errors introduced by the dataset in training, saves time in data cleaning and processing, while maximizing the effect of fine-tuning.

【3】Quantitative Analysis of Technical Debt and Pattern Violation in Large Language Model Architectures
- **标题**: 大型语言模型架构中技术债务和模式违规的定量分析
- **链接**: https://arxiv.org/abs/2512.04273
> **作者**: Tyler Slater
> **摘要**: 随着大型语言模型 (LLM) 从代码完成工具过渡到自主系统架构师，它们对长期软件可维护性的影响仍然无法量化。虽然现有研究以功能正确性为基准 (pass@k)，但本研究提出了第一个衡量“架构侵蚀”和人工智能合成微服务中技术债务积累的实证框架。我们对三种最先进的模型（GPT-5.1、Claude 4.5 Sonnet 和 Llama 3 8B）进行了比较试点研究，促使它们在严格的六边形架构约束下实施标准化的图书借阅微服务。利用抽象语法树 (AST) 解析，我们发现虽然专有模型实现了较高的架构一致性（GPT-5.1 违规率为 0%），但开放权重模型却表现出严重的分歧。具体来说，Llama 3 表现出了 80% 的架构违规率，经常绕过接口适配器在域层和基础设施层之间创建非法循环依赖关系。此外，我们还发现了一种“实现惰性”现象，即开放权重模型生成的逻辑代码行 (LLOC) 比专有模型少 60%，有效地省略了复杂的业务逻辑来满足令牌约束。这些发现表明，如果没有自动化的架构检查，使用较小的开放权重模型进行系统脚手架会加速结构技术债务的积累。
> **Abstract**: As Large Language Models (LLMs) transition from code completion tools to autonomous system architects, their impact on long-term software maintainability remains unquantified. While existing research benchmarks functional correctness (pass@k), this study presents the first empirical framework to measure "Architectural Erosion" and the accumulation of Technical Debt in AI-synthesized microservices. We conducted a comparative pilot study of three state-of-the-art models (GPT-5.1, Claude 4.5 Sonnet, and Llama 3 8B) by prompting them to implement a standardized Book Lending Microservice under strict Hexagonal Architecture constraints. Utilizing Abstract Syntax Tree (AST) parsing, we find that while proprietary models achieve high architectural conformance (0% violation rate for GPT-5.1), open-weights models exhibit critical divergence. Specifically, Llama 3 demonstrated an 80% Architectural Violation Rate, frequently bypassing interface adapters to create illegal circular dependencies between Domain and Infrastructure layers. Furthermore, we identified a phenomenon of "Implementation Laziness," where open-weights models generated 60% fewer Logical Lines of Code (LLOC) than their proprietary counterparts, effectively omitting complex business logic to satisfy token constraints. These findings suggest that without automated architectural linting, utilizing smaller open-weights models for system scaffolding accelerates the accumulation of structural technical debt.

【4】Catching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage
- **标题**: 捕获代码中的用户体验缺陷：利用法学硕士识别开发阶段的可用性缺陷
- **链接**: https://arxiv.org/abs/2512.04262
> **作者**: Nolan Platt,Ethan Luchs,Sehrish Nizamani
> **摘要**: 可用性评估对于确保现代界面满足用户需求至关重要，但人类专家进行的传统启发式评估可能既耗时又主观，尤其是在开发早期。本文研究了大型语言模型（LLM）是否可以在开发阶段提供可靠且一致的启发式评估。通过将 Jakob Nielsen 的 10 种可用性启发式应用到 30 个开源网站，我们使用 OpenAI 的 GPT-4o 管道在每个站点的三个独立评估中生成了超过 850 个启发式评估。对于问题检测，该模型表现出中等的一致性，平均成对 Cohen's Kappa 为 0.50，精确一致性为 84%。严重性判断显示出更多的变异性：加权 Cohen 的 Kappa 平均值为 0.63，但确切的一致性仅为 56%，而 Krippendorff 的 Alpha 接近于零。这些结果表明，虽然 GPT-4o 可以产生内部一致的评估，特别是在识别可用性问题的存在方面，但其判断严重性的能力各不相同，并且在实践中需要人工监督。我们的研究结果强调了使用法学硕士进行早期自动化可用性测试的可行性和局限性，并为提高自动化用户体验（UX）评估的一致性奠定了基础。据我们所知，我们的工作提供了自动启发式评估的第一个定量评估者间可靠性分析，并强调了提高模型一致性的方法。
> **Abstract**: Usability evaluations are essential for ensuring that modern interfaces meet user needs, yet traditional heuristic evaluations by human experts can be time-consuming and subjective, especially early in development. This paper investigates whether large language models (LLMs) can provide reliable and consistent heuristic assessments at the development stage. By applying Jakob Nielsen's ten usability heuristics to thirty open-source websites, we generated over 850 heuristic evaluations in three independent evaluations per site using a pipeline of OpenAI's GPT-4o. For issue detection, the model demonstrated moderate consistency, with an average pairwise Cohen's Kappa of 0.50 and an exact agreement of 84%. Severity judgments showed more variability: weighted Cohen's Kappa averaged 0.63, but exact agreement was just 56%, and Krippendorff's Alpha was near zero. These results suggest that while GPT-4o can produce internally consistent evaluations, especially for identifying the presence of usability issues, its ability to judge severity varies and requires human oversight in practice. Our findings highlight the feasibility and limitations of using LLMs for early-stage, automated usability testing, and offer a foundation for improving consistency in automated User Experience (UX) evaluation. To the best of our knowledge, our work provides one of the first quantitative inter-rater reliability analyses of automated heuristic evaluation and highlights methods for improving model consistency.

【5】On the Role and Impact of GenAI Tools in Software Engineering Education
- **标题**: 论GenAI工具在软件工程教育中的作用和影响
- **链接**: https://arxiv.org/abs/2512.04256
> **作者**: Qiaolin Qin,Ronnie de Souza Santos,Rodrigo Spinola
> **摘要**: 语境。 ChatGPT 和 GitHub Copilot 等生成式人工智能 (GenAI) 工具的兴起改变了软件学习和编写的方式。在软件工程 (SE) 教育中，这些工具提供了新的支持机会，但也引起了人们对过度依赖、道德使用和对学习影响的担忧。客观的。本研究调查了本科 SE 学生如何使用 GenAI 工具，重点关注影响他们体验的好处、挑战、道德问题和教学期望。方法。我们对来自两所大学的 130 名本科生进行了一项调查。该调查结合了结构化的李克特量表项目和开放式问题来调查五个维度：使用背景、感知的好处、挑战、道德和教学观念。结果。学生最常使用 GenAI 进行增量学习和高级实施，报告诸如头脑风暴支持和建立信心等好处。与此同时，他们面临着包括理由不明确和难以调整产出在内的挑战。学生们强调了有关公平和不当行为的道德担忧，并呼吁更清晰的教学指导。结论。 GenAI 正在以细致入微的方式重塑SE 教育。我们的研究结果强调需要脚手架、道德政策和适应性教学策略，以确保 GenAI 支持公平和有效的学习。
> **Abstract**: Context. The rise of generative AI (GenAI) tools like ChatGPT and GitHub Copilot has transformed how software is learned and written. In software engineering (SE) education, these tools offer new opportunities for support, but also raise concerns about over-reliance, ethical use, and impacts on learning. Objective. This study investigates how undergraduate SE students use GenAI tools, focusing on the benefits, challenges, ethical concerns, and instructional expectations that shape their experiences. Method. We conducted a survey with 130 undergraduate students from two universities. The survey combined structured Likert-scale items and open-ended questions to investigate five dimensions: usage context, perceived benefits, challenges, ethical and instructional perceptions. Results. Students most often use GenAI for incremental learning and advanced implementation, reporting benefits such as brainstorming support and confidence-building. At the same time, they face challenges including unclear rationales and difficulty adapting outputs. Students highlight ethical concerns around fairness and misconduct, and call for clearer instructional guidance. Conclusion. GenAI is reshaping SE education in nuanced ways. Our findings underscore the need for scaffolding, ethical policies, and adaptive instructional strategies to ensure that GenAI supports equitable and effective learning.

【6】HAI-Eval: Measuring Human-AI Synergy in Collaborative Coding
- **标题**: HAI-Eval：测量协作编码中的人类与人工智能的协同作用
- **链接**: https://arxiv.org/abs/2512.04111
> **作者**: Hanjun Luo,Chiming Ni,Jiaheng Wen,Zhimu Huang,Yiran Wang,Bingduo Liao,Sylvia Chung,Yingbin Jin,Xinfeng Li,Wenyuan Xu,XiaoFeng Wang,Hanan Salam
> **摘要**: 由法学硕士支持的编码代理正在重塑开发范式。然而，现有的评估系统，无论是传统的人类测试还是法学硕士的基准，都未能捕捉到这种转变。他们仍然专注于明确定义的算法问题，这排除了成功取决于人类与人工智能协作的问题。此类协作问题不仅需要人类推理来解释复杂的上下文并指导解决策略，还需要人工智能的执行效率。为了弥补这一差距，我们引入了 HAI-Eval，这是一个统一的基准，旨在衡量人类与人工智能在编码方面的协作协同作用。 HAI-Eval 的核心创新在于其“需要协作”的问题模板，这些模板对于独立的法学硕士和无人帮助的人来说都是棘手的，但可以通过有效的协作来解决。具体来说，HAI-Eval 使用 45 个模板来动态创建任务。它还为人类参与者提供了一个标准化的 IDE，并为法学硕士提供了一个包含 450 个任务实例的可重复工具包，确保了生态上有效的评估。我们对 45 名参与者进行了一项受试者内研究，并将他们的表现与 5 个最先进的法学硕士在 4 个不同水平的人为干预下的表现进行了比较。结果显示，独立的法学硕士和无帮助的参与者的通过率较低（0.67% 和 18.89%），而人机协作将性能显着提高至 31.11%。我们的分析揭示了一种新兴的共同推理伙伴关系。这一发现挑战了传统的人类工具层次结构，表明战略突破可以源自人类或人工智能。 HAI-Eval 不仅为下一代编码代理建立了具有挑战性的基准，而且还为评估人工智能时代的核心开发人员能力建立了一个坚实的、可扩展的框架。我们的基准测试和交互式演示将公开访问。
> **Abstract**: LLM-powered coding agents are reshaping the development paradigm. However, existing evaluation systems, neither traditional tests for humans nor benchmarks for LLMs, fail to capture this shift. They remain focused on well-defined algorithmic problems, which excludes problems where success depends on human-AI collaboration. Such collaborative problems not only require human reasoning to interpret complex contexts and guide solution strategies, but also demand AI efficiency for implementation. To bridge this gap, we introduce HAI-Eval, a unified benchmark designed to measure the synergy of human-AI partnership in coding. HAI-Eval's core innovation is its "Collaboration-Necessary" problem templates, which are intractable for both standalone LLMs and unaided humans, but solvable through effective collaboration. Specifically, HAI-Eval uses 45 templates to dynamically create tasks. It also provides a standardized IDE for human participants and a reproducible toolkit with 450 task instances for LLMs, ensuring an ecologically valid evaluation. We conduct a within-subject study with 45 participants and benchmark their performance against 5 state-of-the-art LLMs under 4 different levels of human intervention. Results show that standalone LLMs and unaided participants achieve poor pass rates (0.67% and 18.89%), human-AI collaboration significantly improves performance to 31.11%. Our analysis reveals an emerging co-reasoning partnership. This finding challenges the traditional human-tool hierarchy by showing that strategic breakthroughs can originate from either humans or AI. HAI-Eval establishes not only a challenging benchmark for next-generation coding agents but also a grounded, scalable framework for assessing core developer competencies in the AI era. Our benchmark and interactive demo will be openly accessible.

【7】Retrieval-Augmented Few-Shot Prompting Versus Fine-Tuning for Code Vulnerability Detection
- **标题**: 检索增强的少样本提示与代码漏洞检测的微调
- **链接**: https://arxiv.org/abs/2512.04106
> **作者**: Fouad Trad,Ali Chehab
> **摘要**: 少样本提示已成为微调的实用替代方案，可在专门任务中利用大型语言模型 (LLM) 的功能。然而，其有效性在很大程度上取决于上下文示例的选择和质量，特别是在复杂领域。在这项工作中，我们研究了检索增强提示作为一种提高代码漏洞检测中的小样本性能的策略，其目标是从一组预定义的漏洞类别中识别给定代码片段中存在的一个或多个与安全相关的弱点。我们使用 Gemini-1.5-Flash 模型通过三种方法进行系统评估：(1) 使用随机选择的示例进行标准几次提示，(2) 使用语义相似的示例进行检索增强提示，以及 (3) 基于检索的标记，即根据检索到的示例分配标签，无需模型推理。我们的结果表明，检索增强提示始终优于其他提示策略。 20次射击时，F1得分为74.05%，部分匹配准确率为83.90%。我们进一步将这种方法与零样本提示和几个微调模型进行比较，包括 Gemini-1.5-Flash 和较小的开源模型，例如 DistilBERT、DistilGPT2 和 CodeBERT。检索增强提示的性能优于零样本（F1 得分：36.35%，部分匹配准确率：20.30%）和微调 Gemini（F1 得分：59.31%，部分匹配准确率：53.10%），同时避免了与模型微调相关的训练时间和成本。另一方面，微调 CodeBERT 可以获得更高的性能（F1 分数：91.22%，部分匹配准确率：91.30%），但需要额外的培训、维护工作和资源。
> **Abstract**: Few-shot prompting has emerged as a practical alternative to fine-tuning for leveraging the capabilities of large language models (LLMs) in specialized tasks. However, its effectiveness depends heavily on the selection and quality of in-context examples, particularly in complex domains. In this work, we examine retrieval-augmented prompting as a strategy to improve few-shot performance in code vulnerability detection, where the goal is to identify one or more security-relevant weaknesses present in a given code snippet from a predefined set of vulnerability categories. We perform a systematic evaluation using the Gemini-1.5-Flash model across three approaches: (1) standard few-shot prompting with randomly selected examples, (2) retrieval-augmented prompting using semantically similar examples, and (3) retrieval-based labeling, which assigns labels based on retrieved examples without model inference. Our results show that retrieval-augmented prompting consistently outperforms the other prompting strategies. At 20 shots, it achieves an F1 score of 74.05% and a partial match accuracy of 83.90%. We further compare this approach against zero-shot prompting and several fine-tuned models, including Gemini-1.5-Flash and smaller open-source models such as DistilBERT, DistilGPT2, and CodeBERT. Retrieval-augmented prompting outperforms both zero-shot (F1 score: 36.35%, partial match accuracy: 20.30%) and fine-tuned Gemini (F1 score: 59.31%, partial match accuracy: 53.10%), while avoiding the training time and cost associated with model fine-tuning. On the other hand, fine-tuning CodeBERT yields higher performance (F1 score: 91.22%, partial match accuracy: 91.30%) but requires additional training, maintenance effort, and resources.

## 普通经济学(econ.GN:General Economics)

【1】Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs
- **标题**: 设计两极分化：人工智能降低说服成本，精英如何塑造大众偏好
- **链接**: https://arxiv.org/abs/2512.04047
> **作者**: Nadav Kunievsky
> **摘要**: 在民主国家，重大政策决策通常需要某种形式的多数或共识，因此精英必须获得群众支持才能执政。从历史上看，精英只能通过学校教育和大众媒体等有限的工具来获得支持。人工智能驱动的说服力的进步大大降低了舆论塑造的成本并提高了精度，使偏好的分配本身成为精心设计的对象。我们开发了一个动态模型，在该模型中，精英们根据说服成本和多数规则约束，选择重塑政策偏好分布的程度。对于单一精英来说，任何最佳干预都会将社会推向更加两极分化的观点——“两极分化拉动”——而说服技术的进步加速了这种趋势。当两个对立的精英交替掌权时，同样的技术也会产生激励，将社会置于“半锁定”地区，这些地区的意见更有凝聚力，对手更难推翻，因此说服力的进步可以根据环境加剧或抑制两极分化。总而言之，更便宜的说服技术将两极分化重新塑造为治理的战略工具，而不是纯粹的新兴社会副产品，随着人工智能能力的进步，对民主稳定具有重要影响。
> **Abstract**: In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.

## 图像和视频处理(eess.IV:Image and Video Processing)

【1】Tada-DIP: Input-adaptive Deep Image Prior for One-shot 3D Image Reconstruction
- **标题**: Tada-DIP：用于一次性 3D 图像重建的输入自适应深度图像先验
- **链接**: https://arxiv.org/abs/2512.03962
> **作者**: Evan Bell,Shijun Liang,Ismail Alkhouri,Saiprasad Ravishankar
> **摘要**: 深度图像先验（DIP）最近成为一种有前途的基于一次性神经网络的图像重建方法。然而，DIP 在 3D 图像重建问题上的应用有限。在这项工作中，我们介绍了 Tada-DIP，一种用于解决 3D 反问题的高效且完全 3D DIP 方法。通过结合输入自适应和去噪正则化，Tada-DIP 可以生成高质量的 3D 重建，同时避免 DIP 中常见的过度拟合现象。稀疏视图 X 射线计算机断层扫描重建实验验证了所提出方法的有效性，证明 Tada-DIP 比无训练数据基线产生更好的重建，并且实现了与使用具有完全采样体积的大型数据集训练的监督网络相当的重建性能。
> **Abstract**: Deep Image Prior (DIP) has recently emerged as a promising one-shot neural-network based image reconstruction method. However, DIP has seen limited application to 3D image reconstruction problems. In this work, we introduce Tada-DIP, a highly effective and fully 3D DIP method for solving 3D inverse problems. By combining input-adaptation and denoising regularization, Tada-DIP produces high-quality 3D reconstructions while avoiding the overfitting phenomenon that is common in DIP. Experiments on sparse-view X-ray computed tomography reconstruction validate the effectiveness of the proposed method, demonstrating that Tada-DIP produces much better reconstructions than training-data-free baselines and achieves reconstruction performance on par with a supervised network trained using a large dataset with fully-sampled volumes.

## 信号处理(eess.SP:Signal Processing)

【1】Towards 6G Native-AI Edge Networks: A Semantic-Aware and Agentic Intelligence Paradigm
- **标题**: 迈向 6G 原生 AI 边缘网络：语义感知和代理智能范式
- **链接**: https://arxiv.org/abs/2512.04405
> **作者**: Chenyuan Feng,Anbang Zhang,Geyong Min,Yongming Huang,Tony Q. S. Quek,Xiaohu You
> **摘要**: 向第六代无线系统的演进将智能定位为原生网络功能，从根本上改变了无线接入网络 (RAN) 的设计。在这一愿景中，语义原生通信和代理智能预计将发挥核心作用。 SemCom 脱离了位级保真度，而是强调面向任务的意义交换，实现紧凑的 SC 并引入新的性能指标，例如语义保真度和任务成功率。代理智能赋予分布式 RAN 实体以目标驱动的自主性、推理、规划和多代理协作，并越来越多地受到基础模型和知识图的支持。在这项工作中，我们首先介绍 SemCom 和代理网络的概念基础，并讨论为什么现有的 AI 驱动的 O-RAN 解决方案仍然主要以比特为中心且任务孤立。然后，我们提出了一个统一的分类法，该分类法沿着三个轴组织最近的研究：i）语义抽象级别（符号/特征/意图/知识），ii）代理自治和协调粒度（单代理，多代理和分层代理），以及 iii）跨 PHY/MAC、近实时 RIC 和非实时 RIC 的 RAN 控制布局。基于这一分类，我们系统地介绍了使能技术，包括面向任务的语义编码器/解码器、多智能体强化学习、基础模型辅助的 RAN 智能体以及基于知识图谱的跨层感知推理。分析了沉浸式 XR、车辆 V2X 和工业数字孪生等代表性 6G 使用案例，以说明实践中的语义代理融合。最后，我们确定了语义表示标准化、可扩展的可信代理协调、O-RAN 互操作性和节能 AI 部署方面的开放挑战，并概述了可操作的语义代理 AI-RAN 的研究方向。
> **Abstract**: The evolution toward sixth-generation wireless systems positions intelligence as a native network capability, fundamentally transforming the design of radio access networks (RANs). Within this vision, Semantic-native communication and agentic intelligence are expected to play central roles. SemCom departs from bit-level fidelity and instead emphasizes task-oriented meaning exchange, enabling compact SC and introducing new performance measures such as semantic fidelity and task success rate. Agentic intelligence endows distributed RAN entities with goal-driven autonomy, reasoning, planning, and multi-agent collaboration, increasingly supported by foundation models and knowledge graphs. In this work, we first introduce the conceptual foundations of SemCom and agentic networking, and discuss why existing AI-driven O-RAN solutions remain largely bit-centric and task-siloed. We then present a unified taxonomy that organizes recent research along three axes: i) semantic abstraction level (symbol/feature/intent/knowledge), ii) agent autonomy and coordination granularity (single-, multi-, and hierarchical-agent), and iii) RAN control placement across PHY/MAC, near-real-time RIC, and non-real-time RIC. Based on this taxonomy, we systematically introduce enabling technologies including task-oriented semantic encoders/decoders, multi-agent reinforcement learning, foundation-model-assisted RAN agents, and knowledge-graph-based reasoning for cross-layer awareness. Representative 6G use cases, such as immersive XR, vehicular V2X, and industrial digital twins, are analyzed to illustrate the semantic-agentic convergence in practice. Finally, we identify open challenges in semantic representation standardization, scalable trustworthy agent coordination, O-RAN interoperability, and energy-efficient AI deployment, and outline research directions toward operational semantic-agentic AI-RAN.

【2】RRAM-Based Analog Matrix Computing for Massive MIMO Signal Processing: A Review
- **标题**: 基于 RRAM 的大规模 MIMO 信号处理模拟矩阵计算：综述
- **链接**: https://arxiv.org/abs/2512.04365
> **作者**: Pushen Zuo,Zhong Sun
> **摘要**: 电阻式随机存取存储器 (RRAM) 为模拟矩阵计算 (AMC) 提供了出色的平台，可通过开环和闭环电路架构实现矩阵向量乘法 (MVM) 和矩阵方程求解。虽然基于 RRAM 的 AMC 已被广泛探索用于加速神经网络，但其在大规模多输入多输出 (MIMO) 无线通信中信号处理的应用正在迅速成为一个有前途的方向。在这篇综述中，我们总结了将 AMC 应用到大规模 MIMO 的最新进展，包括使用 MVM 电路进行 OFDM 调制和解调的 DFT/IDFT 计算；使用基于 MVM 的迭代算法进行 MIMO 检测和预编码；以及通过矩阵求逆 (INV) 和广义逆 (GINV) 电路实现的快速一步解决方案。我们还强调了其他机会，例如用于信道估计的基于 AMC 的压缩感知恢复以及用于基于泄漏的预编码的特征值电路。最后，我们概述了主要挑战，包括 RRAM 器件可靠性、模拟电路精度、阵列可扩展性和数据转换瓶颈，并讨论了克服这些障碍的机会。随着器件-电路-算法协同设计的不断进步，基于 RRAM 的 AMC 有望为 6G 时代的（超）大规模 MIMO 信号处理提供高效率、高可靠性的解决方案。
> **Abstract**: Resistive random-access memory (RRAM) provides an excellent platform for analog matrix computing (AMC), enabling both matrix-vector multiplication (MVM) and the solution of matrix equations through open-loop and closed-loop circuit architectures. While RRAM-based AMC has been widely explored for accelerating neural networks, its application to signal processing in massive multiple-input multiple-output (MIMO) wireless communication is rapidly emerging as a promising direction. In this Review, we summarize recent advances in applying AMC to massive MIMO, including DFT/IDFT computation for OFDM modulation and demodulation using MVM circuits; MIMO detection and precoding using MVM-based iterative algorithms; and rapid one-step solutions enabled by matrix inversion (INV) and generalized inverse (GINV) circuits. We also highlight additional opportunities, such as AMC-based compressed-sensing recovery for channel estimation and eigenvalue circuits for leakage-based precoding. Finally, we outline key challenges, including RRAM device reliability, analog circuit precision, array scalability, and data conversion bottlenecks, and discuss the opportunities for overcoming these barriers. With continued progress in device-circuit-algorithm co-design, RRAM-based AMC holds strong promise for delivering high-efficiency, high-reliability solutions to (ultra)massive MIMO signal processing in the 6G era.

【3】ReVeal-MT: A Physics-Informed Neural Network for Multi-Transmitter Radio Environment Mapping
- **标题**: ReVeal-MT：用于多发射机无线电环境测绘的物理信息神经网络
- **链接**: https://arxiv.org/abs/2512.04100
> **作者**: Mukaram Shahid,Kunal Das,Hadia Ushaq,Hongwei Zhang,Jiming Song,Daji Qiao,Sarath Babu,Yong Guan,Zhengyuan Zhu,Arsalan Ahmad
> **摘要**: 准确映射无线电环境（例如，识别特定频段和地理位置的无线信号强度）对于高效频谱共享至关重要，使次要用户（SU）能够访问未充分利用的频段，同时保护主要用户（PU）。虽然现有模型已经取得了进步，但当多个发射器共存时，由于阴影和相邻发射器干扰的复合效应，它们的性能通常会下降。为了应对这一挑战，我们扩展了之前针对单发射机映射的物理信息神经网络 (PINN) 的工作，导出了接收信号强度指示器 (RSSI) 的新多发射机偏微分方程 (PDE) 公式。然后，我们提出了 \emph{ReVeal-MT} （多发射机频谱景观重建器和可视化器），这是一种新颖的 PINN，它将多源 PDE 残差集成到神经网络损失函数中，从而能够从稀疏 RF 传感器测量中准确重建频谱景观。 ReVeal-MT 使用 ARA 无线生活实验室在农村和郊区环境中的实际测量结果进行了验证，并针对 3GPP 和 ITU-R 信道模型以及单个发射机用例的基线 PINN 模型进行了基准测试。结果表明，ReVeal-MT 在多发射机场景中实现了显着的精度提升，例如，在 370 平方公里的区域内仅使用 45 个样本即可实现仅 2.66dB 的 RMSE，同时保持较低的计算复杂度。这些发现表明，ReVeal-MT 显着推进了现实多发射机条件下的无线电环境映射，具有实现细粒度频谱管理以及 PU 和 SU 之间精确共存的强大潜力。
> **Abstract**: Accurately mapping the radio environment (e.g., identifying wireless signal strength at specific frequency bands and geographic locations) is crucial for efficient spectrum sharing, enabling Secondary Users~(SUs) to access underutilized spectrum bands while protecting Primary Users~(PUs). While existing models have made progress, they often degrade in performance when multiple transmitters coexist, due to the compounded effects of shadowing, interference from adjacent transmitters. To address this challenge, we extend our prior work on Physics-Informed Neural Networks~(PINNs) for single-transmitter mapping to derive a new multi-transmitter Partial Differential Equation~(PDE) formulation of the Received Signal Strength Indicator~(RSSI). We then propose \emph{ReVeal-MT} (Re-constructor and Visualizer of Spectrum Landscape for Multiple Transmitters), a novel PINN which integrates the multi-source PDE residual into a neural network loss function, enabling accurate spectrum landscape reconstruction from sparse RF sensor measurements. ReVeal-MT is validated using real-world measurements from the ARA wireless living lab across rural and suburban environments, and benchmarked against 3GPP and ITU-R channel models and a baseline PINN model for a single transmitter use-case. Results show that ReVeal-MT achieves substantial accuracy gains in multi-transmitter scenarios, e.g., achieving an RMSE of only 2.66\,dB with as few as 45 samples over a 370-square-kilometer region, while maintaining low computational complexity. These findings demonstrate that ReVeal-MT significantly advances radio environment mapping under realistic multi-transmitter conditions, with strong potential for enabling fine-grained spectrum management and precise coexistence between PUs and SUs.

【4】A Convolutional Framework for Mapping Imagined Auditory MEG into Listened Brain Responses
- **标题**: 将想象中的听觉 MEG 映射到听到的大脑反应的卷积框架
- **链接**: https://arxiv.org/abs/2512.03458
> **作者**: Maryam Maghsoudi,Mohsen Rezaeizadeh,Shihab Shamma
> **摘要**: 解码想象的语音涉及复杂的神经过程，由于时间的不确定性和想象的反应数据集的可用性有限，这些过程很难解释。在这项研究中，我们提出了一个脑磁图（MEG）数据集，该数据集是从受过训练的音乐家想象和聆听音乐和诗歌刺激时收集的。我们表明，想象的和感知的大脑反应都包含一致的、特定于条件的信息。使用滑动窗口岭回归模型，我们首先将想象的反应映射到单个受试者水平上听到的反应，但发现受试者之间的泛化有限。在组层面，我们开发了一种编码器-解码器卷积神经网络，具有特定于主题的校准层，可产生稳定且可泛化的映射。 CNN 的表现始终优于零模型，几乎所有被试的预测和真实聆听反应之间的相关性显着更高。我们的研究结果表明，想象的神经活动可以转化为类似感知的反应，为未来涉及想象的语音和音乐的脑机接口应用奠定了基础。
> **Abstract**: Decoding imagined speech engages complex neural processes that are difficult to interpret due to uncertainty in timing and the limited availability of imagined-response datasets. In this study, we present a Magnetoencephalography (MEG) dataset collected from trained musicians as they imagined and listened to musical and poetic stimuli. We show that both imagined and perceived brain responses contain consistent, condition-specific information. Using a sliding-window ridge regression model, we first mapped imagined responses to listened responses at the single-subject level, but found limited generalization across subjects. At the group level, we developed an encoder-decoder convolutional neural network with a subject-specific calibration layer that produced stable and generalizable mappings. The CNN consistently outperformed the null model, yielding significantly higher correlations between predicted and true listened responses for nearly all held-out subjects. Our findings demonstrate that imagined neural activity can be transformed into perception-like responses, providing a foundation for future brain-computer interface applications involving imagined speech and music.

## 系统与控制(eess.SY:Systems and Control)

【1】Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion
- **标题**: 通过腿部运动评估慢速控制频率和有限观察条件下的可变阻抗肌肉协调
- **链接**: https://arxiv.org/abs/2512.03459
> **作者**: Hidaka Asai,Tomoyuki Noda,Jun Morimoto
> **摘要**: 尽管用于反馈的感觉信息有限，但人类运动控制仍然灵活而稳健，这一特性归因于身体通过具有可变阻抗的肌肉协调来执行形态计算的能力。然而，目前尚不清楚这种低级机械计算如何降低高级控制器的控制要求。在本研究中，我们实现了一个分层控制器，该控制器由经过强化学习训练的高级神经网络和在单足运动任务中使用单关节和双关节肌肉的低级可变阻抗肌肉协调模型组成。我们通过改变控制频率和引入受生物学启发的观察条件：延迟、部分和替代观察来系统地限制高级控制器。在这些条件下，我们评估低级可变阻抗肌肉协调如何有助于高级神经网络的学习过程。结果表明，即使在慢速控制频率和有限的观察条件下，变阻抗肌肉协调也能实现稳定的运动。这些发现表明，肌肉协调的形态学计算有效地减轻了高层控制器的高频反馈，并为运动控制中的控制器提供了设计原理。
> **Abstract**: Human motor control remains agile and robust despite limited sensory information for feedback, a property attributed to the body's ability to perform morphological computation through muscle coordination with variable impedance. However, it remains unclear how such low-level mechanical computation reduces the control requirements of the high-level controller. In this study, we implement a hierarchical controller consisting of a high-level neural network trained by reinforcement learning and a low-level variable-impedance muscle coor dination model with mono- and biarticular muscles in monoped locomotion task. We systematically restrict the high-level controller by varying the control frequency and by introducing biologically inspired observation conditions: delayed, partial, and substituted observation. Under these conditions, we evaluate how the low-level variable-impedance muscle coordination contributes to learning process of high-level neural network. The results show that variable-impedance muscle coordination enables stable locomotion even under slow-rate control frequency and limited observation conditions. These findings demonstrate that the morphological computation of muscle coordination effectively offloads high-frequency feedback of the high-level controller and provide a design principle for the controller in motor control.

## 优化与控制(math.OC:Optimization and Control)

【1】A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models
- **标题**: 大规模人工智能模型中稀疏专家混合辅助无损负载均衡的理论框架
- **链接**: https://arxiv.org/abs/2512.03915
> **作者**: X. Y. Han,Yuan Zhong
> **摘要**: 在大规模人工智能训练中，稀疏专家混合 (s-MoE) 层通过仅激活每个令牌的一小部分专家来实现扩展。此设计中的操作挑战是负载平衡：路由令牌以最大程度地减少空闲专家的数量，这对于有效利用（昂贵的）GPU 非常重要。我们提供了一个用于分析辅助无损负载平衡 (ALF-LB) 过程的理论框架——由 DeepSeek 的 Wang 等人提出。 (2024)——将其转换为一种用于分配问题的每次迭代一步的原始对偶方法。首先，在程式化的确定性环境中，我们的框架产生了几个富有洞察力的结构属性：（i）拉格朗日目标的单调改进，（ii）将代币从过载专家转移到负载不足专家的偏好规则，以及（iii）近似平衡保证。然后，我们使用广义在线优化公式将人工智能训练的随机性和动态性结合起来。在在线环境中，我们得出了目标的强凸性特性，在某些步长选择下导致对数预期遗憾界限。此外，我们还展示了 1B 参数 DeepSeekMoE 模型的真实实验，以补充我们的理论发现。这些结果共同构建了一个原则框架，用于分析人工智能模型中 s-MoE 的辅助无损耗负载平衡。
> **Abstract**: In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.

【2】Market share maximizing strategies of CAV fleet operators may cause chaos in our cities
- **标题**: CAV 车队运营商的市场份额最大化策略可能会导致我们城市的混乱
- **链接**: https://arxiv.org/abs/2512.03524
> **作者**: Grzegorz Jamróz,Rafał Kucharski,David Watling
> **摘要**: 我们研究一种新型路由游戏的动态和平衡，其中玩家（未来自动驾驶车辆的驾驶员）可以在个人（HDV）和集体（CAV）路由之间切换。在个人路线中，就像今天一样，驾驶员选择最小化预期出行成本的路线，而在集体路线中，运营商集中将车辆分配给路线。那么效用就是平均经历的出行时间与个人感知的自动驾驶吸引力的折扣。市场份额最大化策略相当于为尽可能多的司机提供比单独路线更大的效用。我们的理论贡献在于开发一个严格的个性化集体路由数学框架，并研究 CAV 车队可用于优化市场份额的算法。我们还定义了双层 CAV - HDV 平衡，并推导了将 CAV 的潜在营销行为与人群的行为概况联系起来的条件。实际上，我们发现车队运营商通常可以通过简单地模仿 HDV 所做的选择来平衡全部市场份额。然而，在更现实的异质人口环境中，我们发现市场份额最大化的车队控制器应该使用高度可变的混合策略作为吸引或留住客户的手段。原因是，在混合路线中，强大的团体玩家可以控制哪些车辆通过拥堵和不拥堵的替代方案进行路线选择。然而，HDV 在出发前并不知道 CAV 产生的拥堵模式，因此 HDV 无法选择更快的路线，并且无论选择哪种替代方案都面临巨大的不确定性。因此，令人担忧的是，混合市场份额最大化车队策略可能会在我们未来的城市中普遍存在，从而导致不可预测的日常驾驶条件。
> **Abstract**: We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.

## 大气和海洋物理(physics.ao-ph:Atmospheric and Oceanic Physics)

【1】NORi: An ML-Augmented Ocean Boundary Layer Parameterization
- **标题**: NORi：机器学习增强的海洋边界层参数化
- **链接**: https://arxiv.org/abs/2512.04452
> **作者**: Xin Kai Lee,Ali Ramadhan,Andre Souza,Gregory LeClaire Wagner,Simone Silvestri,John Marshall,Raffaele Ferrari
> **摘要**: NORi 是海洋边界层湍流的机器学习 (ML) 参数化，它基于物理并通过神经网络进行增强。 NORi 代表神经常微分方程 (NODE) 理查森数 (Ri) 闭包。物理参数化由理查森数相关扩散率和粘度控制。节点经过训练以捕获通过边界层底部的夹带，这不能用局部扩散闭合来表示。参数化是使用大涡模拟以“后验”方式进行训练的，其中参数使用损失函数进行校准，该损失函数明确取决于感兴趣的实际时间积分变量，而不是本质上有噪声的瞬时子网格通量。 NORi 专为现实的海水非线性状态方程而设计，在捕获不同对流强度、海洋背景分层、旋转强度和表面风强迫下的夹带动力学方面表现出出色的预测和泛化能力。尽管仅在 2 天范围内进行训练，但 NORi 在大规模模拟中至少在 100 年的积分时间内保持数值稳定，并且可以以长达 1 小时的时间步长运行。高度表现力的神经网络与物理上严格的基本封闭相结合，被证明是设计气候模型参数化的稳健范例，其中数据需求大大减少，推理性能可以直接定位和优化，并且在训练过程中隐式鼓励数值稳定性。
> **Abstract**: NORi is a machine-learned (ML) parameterization of ocean boundary layer turbulence that is physics-based and augmented with neural networks. NORi stands for neural ordinary differential equations (NODEs) Richardson number (Ri) closure. The physical parameterization is controlled by a Richardson number-dependent diffusivity and viscosity. The NODEs are trained to capture the entrainment through the base of the boundary layer, which cannot be represented with a local diffusive closure. The parameterization is trained using large-eddy simulations in an "a posteriori" fashion, where parameters are calibrated with a loss function that explicitly depends on the actual time-integrated variables of interest rather than the instantaneous subgrid fluxes, which are inherently noisy. NORi is designed for the realistic nonlinear equation of state of seawater and demonstrates excellent prediction and generalization capabilities in capturing entrainment dynamics under different convective strengths, oceanic background stratifications, rotation strengths, and surface wind forcings. NORi is numerically stable for at least 100 years of integration time in large-scale simulations, despite only being trained on 2-day horizons, and can be run with time steps as long as one hour. The highly expressive neural networks, combined with a physically-rigorous base closure, prove to be a robust paradigm for designing parameterizations for climate models where data requirements are drastically reduced, inference performance can be directly targeted and optimized, and numerical stability is implicitly encouraged during training.

## 化学物理(physics.chem-ph:Chemical Physics)

【1】Quantum Chemistry Simulation of Dibenzothiophene for Asphalt Aging Analysis
- **标题**: 用于沥青老化分析的二苯并噻吩的量子化学模拟
- **链接**: https://arxiv.org/abs/2512.04322
> **作者**: Om Tailor
> **摘要**: 本文介绍了综合量子化学管道的执行和分析，通过研究二苯并噻吩（DBT）（沥青粘合剂中的一种关键含硫化合物）来收集对沥青老化机制的可行见解。使用先进的量子算法，特别是带有 k-UpCCGSD 和 ADAPT-VQE ansatze 的变分量子本征解算器 (VQE)，我们实现了基态能量计算，精度达到 -864.69 Ha。我们的实施展示了处理强相关电子系统的量子优势，同时为设计抗氧化沥青配方提供了可行的见解。这项工作还为量子增强材料设计建立了一个可扩展的框架。
> **Abstract**: This paper presents the execution and analysis of a comprehensive quantum chemistry pipeline for gathering actionable insight into asphalt aging mechanisms through the study of dibenzothiophene (DBT), a key sulfur-containing compound in asphalt binders. Using advanced quantum algorithms, specifically Variational Quantum Eigensolver (VQE) with k-UpCCGSD and ADAPT-VQE ansatze, we achieved ground state energy calculations with accuracies reaching -864.69 Ha. Our implementation demonstrates quantum advantages in handling strongly correlated electron systems while providing actionable insights for designing oxidation-resistant asphalt formulations. The work also establishes a scalable framework for quantum-enhanced materials design.

## 物理与社会(physics.soc-ph:Physics and Society)

【1】The changing surface of the world's roads
- **标题**: 世界道路不断变化的路面
- **链接**: https://arxiv.org/abs/2512.04092
> **作者**: Sukanya Randhawa,Guntaj Randhawa,Clemens Langer,Francis Andorful,Benjamin Herfort,Daniel Kwakye,Omer Olchik,Sven Lautenbach,Alexander Zipf
> **摘要**: 具有复原力的道路基础设施是联合国可持续发展目标的基石。然而，网络功能和弹性的主要指标却严重缺乏：全面的全球路面信息基线。在这里，我们通过将深度学习框架应用于 2020 年至 2024 年 Planetscope 卫星图像的全球拼接来克服这一差距。结果是第一个关于 920 万公里关键干道道路铺装情况和宽度的全球多时相数据集，实现了 95.5% 的覆盖率，而近一半的网络之前未分类。该数据集揭示了人类发展的强大的多尺度地理学。在全球范围内，我们表明铺装率的变化率是一个国家发展轨迹的有力代表（与 HDI 的相关性 = 0.65）。在国家范围内，我们量化了未铺砌的道路如何构成经济连通性的脆弱支柱。我们进一步将数据综合成全球人道主义通行矩阵，对人道主义物流产生直接影响。在地方尺度上，案例研究证明了该框架的多功能性：在加纳，道路质量差异暴露了治理的空间结果；在巴基斯坦，这些数据确定了基础设施的脆弱性，为气候适应能力规划提供信息。这项工作共同提供了一个基础数据集和一个多尺度分析框架，用于监测全球基础设施，从国家发展的动态到地方治理、气候适应和公平的现实。与反映经济活动的夜间灯光等传统指标不同，路面数据以更高的空间分辨率直接测量支撑繁荣和复原力的物理基础设施。
> **Abstract**: Resilient road infrastructure is a cornerstone of the UN Sustainable Development Goals. Yet a primary indicator of network functionality and resilience is critically lacking: a comprehensive global baseline of road surface information. Here, we overcome this gap by applying a deep learning framework to a global mosaic of Planetscope satellite imagery from 2020 and 2024. The result is the first global multi-temporal dataset of road pavedness and width for 9.2 million km of critical arterial roads, achieving 95.5% coverage where nearly half the network was previously unclassified. This dataset reveals a powerful multi-scale geography of human development. At the planetary scale, we show that the rate of change in pavedness is a robust proxy for a country's development trajectory (correlation with HDI = 0.65). At the national scale, we quantify how unpaved roads constitute a fragile backbone for economic connectivity. We further synthesize our data into a global Humanitarian Passability Matrix with direct implications for humanitarian logistics. At the local scale, case studies demonstrate the framework's versatility: in Ghana, road quality disparities expose the spatial outcomes of governance; in Pakistan, the data identifies infrastructure vulnerabilities to inform climate resilience planning. Together, this work delivers both a foundational dataset and a multi-scale analytical framework for monitoring global infrastructure, from the dynamics of national development to the realities of local governance, climate adaptation, and equity. Unlike traditional proxies such as nighttime lights, which reflect economic activity, road surface data directly measures the physical infrastructure that underpins prosperity and resilience - at higher spatial resolution.

## 神经元和认知(q-bio.NC:Neurons and Cognition)

【1】Human-Centred Evaluation of Text-to-Image Generation Models for Self-expression of Mental Distress: A Dataset Based on GPT-4o
- **标题**: 以人为中心的精神困扰自我表达文本到图像生成模型的评估：基于 GPT-4o 的数据集
- **链接**: https://arxiv.org/abs/2512.04087
> **作者**: Sui He,Shenbin Qian
> **摘要**: 有效的沟通对于在心理健康背景下实现积极的医疗保健结果至关重要，但国际学生经常面临语言和文化障碍，阻碍他们表达精神困扰。在这项研究中，我们评估了人工智能生成的图像在支持精神困扰自我表达方面的有效性。为了实现这一目标，二十名在英国大学学习的中国国际学生被邀请讲述他们个人的精神困扰经历。这些描述是使用 GPT-4o 和四个植根于当代咨询实践的基于角色的提示模板来详细阐述的，以生成相应的图像。然后，参与者根据他们的原始描述评估生成的图像在促进他们的感受表达方面的帮助。生成的数据集包含 100 个精神困扰的文本描述、400 个生成的图像以及相应的人类评估分数。研究结果表明，提示设计极大地影响了感知的帮助性，其中插画家角色获得了最高的评分。这项工作引入了心理健康领域第一个公开的具有人类判断分数的文本到图像评估数据集，为图像评估、人类反馈强化学习以及心理健康沟通的多模态研究提供了宝贵的资源。
> **Abstract**: Effective communication is central to achieving positive healthcare outcomes in mental health contexts, yet international students often face linguistic and cultural barriers that hinder their communication of mental distress. In this study, we evaluate the effectiveness of AI-generated images in supporting self-expression of mental distress. To achieve this, twenty Chinese international students studying at UK universities were invited to describe their personal experiences of mental distress. These descriptions were elaborated using GPT-4o with four persona-based prompt templates rooted in contemporary counselling practice to generate corresponding images. Participants then evaluated the helpfulness of generated images in facilitating the expression of their feelings based on their original descriptions. The resulting dataset comprises 100 textual descriptions of mental distress, 400 generated images, and corresponding human evaluation scores. Findings indicate that prompt design substantially affects perceived helpfulness, with the illustrator persona achieving the highest ratings. This work introduces the first publicly available text-to-image evaluation dataset with human judgment scores in the mental health domain, offering valuable resources for image evaluation, reinforcement learning with human feedback, and multi-modal research on mental health communication.

## 定量方法(q-bio.QM:Quantitative Methods)

【1】Cell-cell communication inference and analysis: biological mechanisms, computational approaches, and future opportunities
- **标题**: 细胞间通讯推断和分析：生物机制、计算方法和未来机遇
- **链接**: https://arxiv.org/abs/2512.03497
> **作者**: Xiangzheng Cheng,Haili Huang,Ye Su,Qing Nie,Xiufen Zou,Suoqin Jin
> **摘要**: 在多细胞生物体中，细胞通过细胞间通讯（CCC）协调其活动，这对于发育、组织稳态和疾病进展至关重要。单细胞和空间组学技术的最新进展提供了前所未有的机会，可以通过整合配体-受体相互作用 (LRI) 的先验知识或通过从头方法从这些组学数据中系统地推断和分析 CCC。人们已经开发了多种计算方法，重点关注方法创新、复杂信号机制的精确建模以及更广泛的生物学问题的研究。这些进步极大地增强了我们分析 CCC 和产生生物学假设的能力。在这里，我们介绍了 CCC 的生物学机制和建模策略，并重点概述了 140 多种从单细胞和空间转录组数据推断 CCC 的计算方法，强调方法框架和生物学问题的多样性。最后，我们讨论这个快速发展的领域当前的挑战和未来的机遇。
> **Abstract**: In multicellular organisms, cells coordinate their activities through cell-cell communication (CCC), which are crucial for development, tissue homeostasis, and disease progression. Recent advances in single-cell and spatial omics technologies provide unprecedented opportunities to systematically infer and analyze CCC from these omics data, either by integrating prior knowledge of ligand-receptor interactions (LRIs) or through de novo approaches. A variety of computational methods have been developed, focusing on methodological innovations, accurate modeling of complex signaling mechanisms, and investigation of broader biological questions. These advances have greatly enhanced our ability to analyze CCC and generate biological hypotheses. Here, we introduce the biological mechanisms and modeling strategies of CCC, and provide a focused overview of more than 140 computational methods for inferring CCC from single-cell and spatial transcriptomic data, emphasizing the diversity in methodological frameworks and biological questions. Finally, we discuss the current challenges and future opportunities in this rapidly evolving field.

【2】Learning From Limited Data and Feedback for Cell Culture Process Monitoring: A Comparative Study
- **标题**: 从细胞培养过程监控的有限数据和反馈中学习：一项比较研究
- **链接**: https://arxiv.org/abs/2512.03460
> **作者**: Johnny Peng,Thanh Tung Khuat,Ellen Otte,Katarzyna Musial,Bogdan Gabrys
> **摘要**: 在细胞培养生物加工中，实时批量过程监控 (BPM) 是指在整个批量运行期间持续跟踪和分析关键过程变量，例如活细胞密度、营养水平、代谢物浓度和产品滴度。这使得能够及早发现偏差并支持及时的控制行动，以确保最佳的细胞生长和产品质量。 BPM 在确保生物制药制造流程的质量和法规遵从性方面发挥着关键作用。然而，用于 BPM 的精确软传感器的开发受到关键挑战的阻碍，包括有限的历史数据、不频繁的反馈、异构过程条件和高维传感输入。本研究对旨在应对这些挑战的机器学习 (ML) 方法进行了全面的基准分析，重点是从生物过程监测背景下数量和相关性有限的历史数据中进行学习。我们评估了多种机器学习方法，包括跨三个数据集（一个计算机数据集和两个真实实验数据集）的特征降维、在线学习和即时学习。我们的研究结果强调了训练策略在处理有限数据和反馈方面的重要性，批量学习在同质环境中被证明是有效的，而即时学习和在线学习在冷启动场景中表现出卓越的适应性。此外，我们还确定了显着影响模型可转移性的关键元特征，例如馈送介质组成和过程控制策略。结果还表明，将基于拉曼的预测与滞后的离线测量相结合可以提高监测精度，为未来生物过程软传感器的开发提供一个有希望的方向。
> **Abstract**: In cell culture bioprocessing, real-time batch process monitoring (BPM) refers to the continuous tracking and analysis of key process variables such as viable cell density, nutrient levels, metabolite concentrations, and product titer throughout the duration of a batch run. This enables early detection of deviations and supports timely control actions to ensure optimal cell growth and product quality. BPM plays a critical role in ensuring the quality and regulatory compliance of biopharmaceutical manufacturing processes. However, the development of accurate soft sensors for BPM is hindered by key challenges, including limited historical data, infrequent feedback, heterogeneous process conditions, and high-dimensional sensory inputs. This study presents a comprehensive benchmarking analysis of machine learning (ML) methods designed to address these challenges, with a focus on learning from historical data with limited volume and relevance in the context of bioprocess monitoring. We evaluate multiple ML approaches including feature dimensionality reduction, online learning, and just-in-time learning across three datasets, one in silico dataset and two real-world experimental datasets. Our findings highlight the importance of training strategies in handling limited data and feedback, with batch learning proving effective in homogeneous settings, while just-in-time learning and online learning demonstrate superior adaptability in cold-start scenarios. Additionally, we identify key meta-features, such as feed media composition and process control strategies, that significantly impact model transferability. The results also suggest that integrating Raman-based predictions with lagged offline measurements enhances monitoring accuracy, offering a promising direction for future bioprocess soft sensor development.

## 统计金融(q-fin.ST:Statistical Finance)

【1】Partial multivariate transformer as a tool for cryptocurrencies time series prediction
- **标题**: 部分多元变压器作为加密货币时间序列预测的工具
- **链接**: https://arxiv.org/abs/2512.04099
> **作者**: Andrzej Tokajuk,Jarosław A. Chudziak
> **摘要**: 极端波动以及信息稀缺的单变量模型和容易产生噪声的全多元模型之间的方法论困境阻碍了加密货币价格的预测。本文研究了一种部分多元方法来平衡这种权衡，假设特征的策略子集提供了卓越的预测能力。我们应用偏多元变压器（PMformer）来预测 BTCUSDT 和 ETHUSDT 的每日回报，并将其与 11 个经典和深度学习模型进行基准测试。我们的实证结果产生了两个主要贡献。首先，我们证明部分多变量策略实现了显着的统计准确性，有效地平衡了信息信号与噪声。其次，我们实验并讨论了这种统计表现与实际交易效用之间明显的脱节；在模拟中，较低的预测误差并不能始终转化为较高的财务回报。这一发现挑战了对传统误差指标的依赖，并强调需要制定更符合现实世界财务目标的评估标准。
> **Abstract**: Forecasting cryptocurrency prices is hindered by extreme volatility and a methodological dilemma between information-scarce univariate models and noise-prone full-multivariate models. This paper investigates a partial-multivariate approach to balance this trade-off, hypothesizing that a strategic subset of features offers superior predictive power. We apply the Partial-Multivariate Transformer (PMformer) to forecast daily returns for BTCUSDT and ETHUSDT, benchmarking it against eleven classical and deep learning models. Our empirical results yield two primary contributions. First, we demonstrate that the partial-multivariate strategy achieves significant statistical accuracy, effectively balancing informative signals with noise. Second, we experiment and discuss an observable disconnect between this statistical performance and practical trading utility; lower prediction error did not consistently translate to higher financial returns in simulations. This finding challenges the reliance on traditional error metrics and highlights the need to develop evaluation criteria more aligned with real-world financial objectives.

## 量子物理学(quant-ph:Quantum Physics)

【1】Adversarial Limits of Quantum Certification: When Eve Defeats Detection
- **标题**: 量子认证的对抗性限制：当 Eve 无法检测到时
- **链接**: https://arxiv.org/abs/2512.04391
> **作者**: Davut Emre Tasar
> **摘要**: 量子密钥分发 (QKD) 的安全性依赖于证明观察到的相关性来自真正的量子纠缠，而不是窃听者操纵。理论安全证明假设理想条件，实际认证必须与适应性对手抗衡，对手优化针对检测系统的攻击策略。使用 Eve GAN 建立了量子认证的基本对抗限制，Eve GAN 是一种生成对抗网络，经过训练可以产生与量子无法区分的经典相关性。我们的中心发现：当 Eve 在混合参数下将她的经典相关性与量子数据进行插值时，所有测试的检测方法都达到 ROC AUC = 0.50，相当于随机猜测。这意味着窃听者只需 5% 的经典混合物即可完全逃避检测。至关重要的是，我们发现，与正确的交叉分布评估相比，先前认证研究中常见的相同分布校准做法使检测性能提高了 44 个百分点，揭示了可能导致高估安全声明的系统缺陷。 Popescu Rohrlich (PR Box) 体系的分析确定了 CHSH S = 2.05 处的急剧相变：低于该值，没有统计方法可以区分经典相关性和量子相关性；高于它，检测概率单调增加。 IBM Quantum 上的硬件验证表明，Eve-GAN 达到了 CHSH = 2.736，显着超过了真实量子硬件性能 (CHSH = 2.691)，这表明经典对手可以在标准认证指标上胜过嘈杂的量子系统。这些结果对 QKD 安全性具有直接影响：保持 95% 量子保真度的对手可以逃避所有经过测试的检测方法。我们使用交叉分布校准提供校正方法，并建议对量子安全声明进行强制性对抗性测试。
> **Abstract**: Security of quantum key distribution (QKD) relies on certifying that observed correlations arise from genuine quantum entanglement rather than eavesdropper manipulation. Theoretical security proofs assume idealized conditions, practical certification must contend with adaptive adversaries who optimize their attack strategies against detection systems. Established fundamental adversarial limits for quantum certification using Eve GAN, a generative adversarial network trained to produce classical correlations indistinguishable from quantum. Our central finding: when Eve interpolates her classical correlations with quantum data at mixing parameter, all tested detection methods achieve ROC AUC = 0.50, equivalent to random guessing. This means an eavesdropper needs only 5% classical admixture to completely evade detection. Critically, we discover that same distribution calibration a common practice in prior certification studies inflates detection performance by 44 percentage points compared to proper cross distribution evaluation, revealing a systematic flaw that may have led to overestimated security claims. Analysis of Popescu Rohrlich (PR Box) regime identifies a sharp phase transition at CHSH S = 2.05: below this value, no statistical method distinguishes classical from quantum correlations; above it, detection probability increases monotonically. Hardware validation on IBM Quantum demonstrates that Eve-GAN achieves CHSH = 2.736, remarkably exceeding real quantum hardware performance (CHSH = 2.691), illustrating that classical adversaries can outperform noisy quantum systems on standard certification metrics. These results have immediate implications for QKD security: adversaries maintaining 95% quantum fidelity evade all tested detection methods. We provide corrected methodology using cross-distribution calibration and recommend mandatory adversarial testing for quantum security claims.

【2】Exploiting Movable Logical Qubits for Lattice Surgery Compilation
- **标题**: 利用可移动逻辑量子位进行格子手术编译
- **链接**: https://arxiv.org/abs/2512.04169
> **作者**: Laura S. Herzog,Lucas Berent,Aleksander Kubica,Robert Wille
> **摘要**: 在超导硬件架构的推动下，二维量子纠错码的晶格手术是容错量子计算的领先方案之一。在传统的晶格手术编译方案中，逻辑电路是按照布局布线范例进行编译的，其中逻辑量子位在整个计算过程中在空间中保持静态固定。在这项工作中，我们通过在逻辑晶格手术 CNOT 门期间通过隐形传态利用可移动逻辑量子位来引入范式转变。着眼于带有颜色代码的晶格手术，我们提出了一种利用这种功能的概念验证编译方案。数值模拟表明，与标准布局布线编译技术相比，所提出的方法可以大大减少布线电路深度。我们的结果表明，基于可移动逻辑量子位的优化并不限于具有物理可移动量子位的架构，例如中性原子或捕获离子 - 它们也很容易适用于超导量子硬件。我们的方法的开源实现可在 GitHub https://github.com/munich-quantum-toolkit/qecc 上找到。
> **Abstract**: Lattice surgery with two-dimensional quantum error correcting codes is among the leading schemes for fault-tolerant quantum computation, motivated by superconducting hardware architectures. In conventional lattice surgery compilation schemes, logical circuits are compiled following a place-and-route paradigm, where logical qubits remain statically fixed in space throughout the computation. In this work, we introduce a paradigm shift by exploiting movable logical qubits via teleportation during the logical lattice surgery CNOT gate. Focusing on lattice surgery with the color code, we propose a proof-of-concept compilation scheme that leverages this capability. Numerical simulations show that the proposed approach can substantially reduce the routed circuit depth compared to standard place-and-route compilation techniques. Our results demonstrate that optimizations based on movable logical qubits are not limited to architectures with physically movable qubits, such as neutral atoms or trapped ions - they are also readily applicable to superconducting quantum hardware. An open-source implementation of our method is available on GitHub https://github.com/munich-quantum-toolkit/qecc.

【3】TARA Test-by-Adaptive-Ranks for Quantum Anomaly Detection with Conformal Prediction Guarantees
- **标题**: 具有共形预测保证的量子异常检测的 TARA 自适应排名测试
- **链接**: https://arxiv.org/abs/2512.04016
> **作者**: Davut Emre Tasar,Ceren Ocal Tasar
> **摘要**: 量子密钥分发（QKD）安全从根本上依赖于区分真正的量子相关性与经典窃听者模拟的能力，但现有的认证方法在有限样本条件和对抗场景下缺乏严格的统计保证。我们引入了 TARA（自适应排名测试），这是一种新颖的框架，它将共形预测与用于量子异常检测的顺序鞅测试相结合，提供了无分布的有效性保证。 TARA 提供了两种互补的方法。 TARA k，基于针对局部隐变量 (LHV) 零分布的 Kolmogorov Smirnov 校准，实现量子经典判别的 ROC AUC = 0.96。 TARA-m 采用投注鞅进行流检测，并具有随时有效的 I 型错误控制，可实现量子通道的实时监控。我们建立了理论保证，证明在（上下文条件）可交换性下，即使对于强上下文量子数据，共形 p 值也保持均匀分布，从而确认量子上下文性不会破坏共形预测有效性，这一结果的影响超出了量子认证对任何非经典数据的无分布方法的应用。在 IBM Torino（超导，CHSH = 2.725）和 IonQ Forte Enterprise（俘获离子，CHSH = 2.716）量子处理器上进行的广泛验证展示了跨平台稳健性，实现了比经典 CHSH 界限 2 高出 36% 的安全裕度。至关重要的是，我们的框架揭示了更广泛地影响量子认证的方法论问题：与正确的分布校准相比，同分布校准可使检测性能提高多达 44 个百分点交叉分布校准，表明之前使用标准训练测试分割的量子认证研究可能系统性地高估了对抗鲁棒性。
> **Abstract**: Quantum key distribution (QKD) security fundamentally relies on the ability to distinguish genuine quantum correlations from classical eavesdropper simulations, yet existing certification methods lack rigorous statistical guarantees under finite-sample conditions and adversarial scenarios. We introduce TARA (Test by Adaptive Ranks), a novel framework combining conformal prediction with sequential martingale testing for quantum anomaly detection that provides distribution-free validity guarantees. TARA offers two complementary approaches. TARA k, based on Kolmogorov Smirnov calibration against local hidden variable (LHV) null distributions, achieving ROC AUC = 0.96 for quantum-classical discrimination. And TARA-m, employing betting martingales for streaming detection with anytime valid type I error control that enables real time monitoring of quantum channels. We establish theoretical guarantees proving that under (context conditional) exchangeability, conformal p-values remain uniformly distributed even for strongly contextual quantum data, confirming that quantum contextuality does not break conformal prediction validity a result with implications beyond quantum certification to any application of distribution-free methods to nonclassical data. Extensive validation on both IBM Torino (superconducting, CHSH = 2.725) and IonQ Forte Enterprise (trapped ion, CHSH = 2.716) quantum processors demonstrates cross-platform robustness, achieving 36% security margins above the classical CHSH bound of 2. Critically, our framework reveals a methodological concern affecting quantum certification more broadly: same-distribution calibration can inflate detection performance by up to 44 percentage points compared to proper cross-distribution calibration, suggesting that prior quantum certification studies using standard train test splits may have systematically overestimated adversarial robustness.

【4】Quantum Algorithm for Searching for the Longest Segment and the Largest Empty Rectangle
- **标题**: 寻找最长线段和最大空矩形的量子算法
- **链接**: https://arxiv.org/abs/2512.03788
> **作者**: Kamil Khadiev,Vladislav Remidovskii,Timur Bikmullin,Aliya Khadieva
> **摘要**: 在本文中，我们考虑在二维地图中搜索最大空矩形的问题，该问题的一维版本是搜索最大空段的问题。我们提出了一种量子算法，用于解决 $n\times n$ 矩形映射的最大空正方形问题和固定宽度 $d$ 的最大空矩形问题。对于方形情况，算法的查询复杂度为 $\tilde{O}(n^{1.5})$；对于固定宽度 $d$ 的矩形，算法的查询复杂度为 $\tilde{O}(n\sqrt{d})$。同时，经典情况的下界分别为 $Ω(n^2)$ 和 $Ω(nd)$。该问题的一维版本的 Quantum 算法的查询复杂度为 $O(\sqrt{n}\log n\log\log n)$。该问题的量子下界是 $Ω(\sqrt{n})$，它几乎等于对数因子的上限。经典下界是 $Ω(n)$。因此，我们获得了该问题的二次加速比。
> **Abstract**: In the paper, we consider the problem of searching for the Largest empty rectangle in a 2D map, and the one-dimensional version of the problem is the problem of searching for the largest empty segment. We present a quantum algorithm for the Largest Empty Square problem and the Largest Empty Rectangle of a fixed width $d$ for $n\times n$-rectangular map. Query complexity of the algorithm is $\tilde{O}(n^{1.5})$ for the square case, and $\tilde{O}(n\sqrt{d})$ for the rectangle with a fixed width $d$ case, respectively. At the same time, the lower bounds for the classical case are $Ω(n^2)$, and $Ω(nd)$, respectively. The Quantum algorithm for the one-dimensional version of the problem has $O(\sqrt{n}\log n\log\log n)$ query complexity. The quantum lower bound for the problem is $Ω(\sqrt{n})$ which is almost equal to the upper bound up to a log factor. The classical lower bound is $Ω(n)$. So, we obtain the quadratic speed-up for the problem.

【5】Distributed Quantum Computing with Fan-Out Operations and Qudits: the Case of Distributed Global Gates (a Preliminary Study)
- **标题**: 具有扇出操作和 Qudits 的分布式量子计算：分布式全局门的案例（初步研究）
- **链接**: https://arxiv.org/abs/2512.03685
> **作者**: Seng W. Loke
> **摘要**: 最近关于分布式量子计算的许多工作都集中在纠缠对和分布式两个量子位门的使用上。但也有人在研究有效的方案，以在单次发射中实现节点之间的多部分纠缠，从而消除使用许多纠缠对生成多部分纠缠态的需要。本文着眼于多方纠缠资源（例如 GHZ 状态）如何用于分布式扇出操作；我们还考虑使用四维量子体进行分布式量子电路压缩。特别是，我们考虑如何使用这种扇出操作和量子比特来实现对分布式量子计算具有挑战性的电路，涉及成对量子比特相互作用，即所谓的全局门（又名全局 Mølmer-Sørensen 门）。此类门已被探索通过减少电路深度可能产生更有效的计算，并且可以在某些类型的量子硬件（例如，俘获离子量子计算机）中有效地执行；我们认为这是对考虑到全局量子位-量子位相互作用的分布“极端”情况的探索。最后，我们还对量子电路编译和量子数据中心设计的未来工作提出了一些启示。
> **Abstract**: Much recent work on distributed quantum computing have focused on the use of entangled pairs and distributed two qubit gates. But there has also been work on efficient schemes for achieving multipartite entanglement between nodes in a single shot, removing the need to generate multipartite entangled states using many entangled pairs. This paper looks at how multipartite entanglement resources (e.g., GHZ states) can be useful for distributed fan-out operations; we also consider the use of qudits of dimension four for distributed quantum circuit compression. In particular, we consider how such fan-out operations and qudits can be used to implement circuits which are challenging for distributed quantum computation, involving pairwise qubit interactions, i.e., what has been called global gates (a.k.a. global Mølmer-Sørensen gates). Such gates have been explored to possibly yield more efficient computations via reduced circuit depth, and can be carried out efficiently in some types of quantum hardware (e.g., trapped-ion quantum computers); we consider this as an exploration of an ``extreme'' case for distribution given the global qubit-qubit interactions. We also conclude with some implications for future work on quantum circuit compilation and quantum data centre design.

