# 论文全览：2025-12-05

共有196篇相关领域论文, 另有0篇其他

## 星系天体物理学(astro-ph.GA:Astrophysics of Galaxies)

【1】287,872 Supermassive Black Holes Masses: Deep Learning Approaching Reverberation Mapping Accuracy
- **标题**: 287,872 个超大质量黑洞：深度学习接近混响映射精度
- **链接**: https://arxiv.org/abs/2512.04803
> **作者**: Yuhao Lu,HengJian SiTu,Jie Li,Yixuan Li,Yang Liu,Wenbin Lin,Yu Wang
> **摘要**: 我们提出了一个包含 287,872 个超大质量黑洞质量的高精度目录。使用在带有 849 个类星体混响映射 (RM) 标签的光谱上进行训练的深度编码器-解码器网络，并将其应用于高达 $z=4$ 的所有 SDSS 类星体，我们的方法实现了 $0.058$\,dex 的均方根误差，$\approx 14\%$ 的相对不确定性，以及相对于基于 RM 的质量的确定系数 $R^{2}\approx0.91$，远远超过传统的单线维里估计器。值得注意的是，低质量类星体 ($<10^{7.5}\,M_\odot$) 和高质量类星体 ($>10^{9}\,M_\odot$) 都保持高精度，其中经验关系不可靠。
> **Abstract**: We present a population-scale catalogue of 287,872 supermassive black hole masses with high accuracy. Using a deep encoder-decoder network trained on optical spectra with reverberation-mapping (RM) based labels of 849 quasars and applied to all SDSS quasars up to $z=4$, our method achieves a root-mean-square error of $0.058$\,dex, a relative uncertainty of $\approx 14\%$, and coefficient of determination $R^{2}\approx0.91$ with respect to RM-based masses, far surpassing traditional single-line virial estimators. Notably, the high accuracy is maintained for both low ($<10^{7.5}\,M_\odot$) and high ($>10^{9}\,M_\odot$) mass quasars, where empirical relations are unreliable.

## 人工智能(cs.AI:Artificial Intelligence)

【1】Detecting Perspective Shifts in Multi-agent Systems
- **标题**: 检测多智能体系统中的视角转变
- **链接**: https://arxiv.org/abs/2512.05013
> **作者**: Eric Bridgeford,Hayden Helm
> **摘要**: 使用外部工具和更新机制（或 \textit{agents}）增强的生成模型已经展示了超出基本模型智能提示的功能。随着代理使用的激增，动态多代理系统自然而然地出现了。最近的工作研究了基于单个时间点查询响应的代理低维表示的理论和经验特性。本文介绍了时态数据内核透视空间（TDKPS），它跨时间联合嵌入智能体，并提出了几种新颖的假设检验，用于检测黑盒多智能体系统中智能体和群体级别的行为变化。我们在由不断发展的数字角色的多智能体系统驱动的模拟中描述了所提出的测试的经验属性，包括它们对关键超参数的敏感性。最后，我们通过自然实验证明，我们提出的测试检测到与真实外源事件敏感、具体且显着相关的变化。据我们所知，TDKPS 是第一个用于监控黑盒多智能体系统中行为动态的原则性框架——随着生成智能体部署的不断扩展，这是一项关键功能。
> **Abstract**: Generative models augmented with external tools and update mechanisms (or \textit{agents}) have demonstrated capabilities beyond intelligent prompting of base models. As agent use proliferates, dynamic multi-agent systems have naturally emerged. Recent work has investigated the theoretical and empirical properties of low-dimensional representations of agents based on query responses at a single time point. This paper introduces the Temporal Data Kernel Perspective Space (TDKPS), which jointly embeds agents across time, and proposes several novel hypothesis tests for detecting behavioral change at the agent- and group-level in black-box multi-agent systems. We characterize the empirical properties of our proposed tests, including their sensitivity to key hyperparameters, in simulations motivated by a multi-agent system of evolving digital personas. Finally, we demonstrate via natural experiment that our proposed tests detect changes that correlate sensitively, specifically, and significantly with a real exogenous event. As far as we are aware, TDKPS is the first principled framework for monitoring behavioral dynamics in black-box multi-agent systems -- a critical capability as generative agent deployment continues to scale.

【2】Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases
- **标题**: 迈向连续神经认知监测：将语音人工智能与关系图转换器相结合，治疗罕见的神经系统疾病
- **链接**: https://arxiv.org/abs/2512.04938
> **作者**: Raquel Norel,Michele Merler,Pavitra Modi
> **摘要**: 患有罕见神经系统疾病的患者报告了传统测试无法发现的认知症状——“脑雾”。我们建议通过与关系图转换器（RELGT）架构集成的智能手机语音分析来进行连续神经认知监测。苯丙酮尿症 (PKU) 的概念验证显示，言语衍生的“言语表达能力”与血液苯丙氨酸相关（p = -0.50，p < 0.005），但与标准认知测试无关（所有 |r| < 0.35）。 RELGT 可以克服异构医疗数据（语音、实验室、评估）中的信息瓶颈，从而在失代偿前几周发出预测警报。主要挑战：多疾病验证、临床工作流程集成、公平的多语言部署。成功将把偶发性神经病学转变为对全球数百万人的持续个性化监测。
> **Abstract**: Patients with rare neurological diseases report cognitive symptoms -"brain fog"- invisible to traditional tests. We propose continuous neurocognitive monitoring via smartphone speech analysis integrated with Relational Graph Transformer (RELGT) architectures. Proof-of-concept in phenylketonuria (PKU) shows speech-derived "Proficiency in Verbal Discourse" correlates with blood phenylalanine (p = -0.50, p < 0.005) but not standard cognitive tests (all |r| < 0.35). RELGT could overcome information bottlenecks in heterogeneous medical data (speech, labs, assessments), enabling predictive alerts weeks before decompensation. Key challenges: multi-disease validation, clinical workflow integration, equitable multilingual deployment. Success would transform episodic neurology into continuous personalized monitoring for millions globally.

【3】Algorithmic Thinking Theory
- **标题**: 算法思维理论
- **链接**: https://arxiv.org/abs/2512.04923
> **作者**: MohammadHossein Bateni,Vincent Cohen-Addad,Yuzhou Gu,Silvio Lattanzi,Simon Meierhans,Christopher Mohri
> **摘要**: 大型语言模型 (LLM) 已被证明对于解决复杂的推理任务非常有效。令人惊讶的是，他们的能力通常可以通过迭代以前生成的解决方案来提高。在这种情况下，用于生成和组合一组解决方案的推理计划可以被视为使用概率预言进行推理的算法。我们介绍了一个用于分析此类推理算法的理论框架。该框架形式化了迭代改进和答案聚合的流行技术的原理，为设计新一代更强大的推理方法提供了基础。与依赖架构细节的理解模型的方法不同，我们的模型基于实验证据。因此，它提供了一个总体视角，可以扩展到当前和未来的各种推理预言。
> **Abstract**: Large language models (LLMs) have proven to be highly effective for solving complex reasoning tasks. Surprisingly, their capabilities can often be improved by iterating on previously generated solutions. In this context, a reasoning plan for generating and combining a set of solutions can be thought of as an algorithm for reasoning using a probabilistic oracle. We introduce a theoretical framework for analyzing such reasoning algorithms. This framework formalizes the principles underlying popular techniques for iterative improvement and answer aggregation, providing a foundation for designing a new generation of more powerful reasoning methods. Unlike approaches for understanding models that rely on architectural specifics, our model is grounded in experimental evidence. As a result, it offers a general perspective that may extend to a wide range of current and future reasoning oracles.

【4】The AI Consumer Index (ACE)
- **标题**: 人工智能消费者指数（ACE）
- **链接**: https://arxiv.org/abs/2512.04921
> **作者**: Julien Benchek,Rohit Shetty,Benjamin Hunsberger,Ajay Arun,Zach Richards,Brendan Foody,Osvald Nitski,Bertie Vidgen
> **摘要**: 我们推出了第一版人工智能消费者指数（ACE），这是评估前沿人工智能模型是否能够执行高价值消费者任务的基准。 ACE 包含一组隐藏的 400 个测试用例，分为四种消费者活动：购物、食品、游戏和 DIY。我们还通过 CC-BY 许可证将 80 个案例作为开发集开源。对于 ACE 排行榜，我们使用一种新颖的评分方法评估了 10 个前沿模型（打开网络搜索），该方法动态检查响应的相关部分是否基于检索到的网络资源。 GPT 5 (Thinking = High) 是表现最好的型号，得分为 56.1%，其次是 o3 Pro (Thinking = On) (55.2%) 和 GPT 5.1 (Thinking = High) (55.1%)。不同领域的模型各不相同，在购物中，最高模型得分低于 50%。对于某些请求（例如给出正确的价格或提供工作链接），模型很容易产生幻觉。总体而言，即使是最好的模型，ACE 的性能与消费者的人工智能需求之间也存在巨大差距。
> **Abstract**: We introduce the first version of the AI Consumer Index (ACE), a benchmark for assessing whether frontier AI models can perform high-value consumer tasks. ACE contains a hidden heldout set of 400 test cases, split across four consumer activities: shopping, food, gaming, and DIY. We are also open sourcing 80 cases as a devset with a CC-BY license. For the ACE leaderboard we evaluated 10 frontier models (with websearch turned on) using a novel grading methodology that dynamically checks whether relevant parts of the response are grounded in the retrieved web sources. GPT 5 (Thinking = High) is the top-performing model, scoring 56.1%, followed by o3 Pro (Thinking = On) (55.2%) and GPT 5.1 (Thinking = High) (55.1%). Models differ across domains, and in Shopping the top model scores under 50%. For some requests (such as giving the correct price or providing working links), models are highly prone to hallucination. Overall, ACE shows a substantial gap between the performance of even the best models and consumers' AI needs.

【5】Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems
- **标题**: Chameleon：用于多模式人工智能系统中基于缩放的视觉提示注入的自适应对抗代理
- **链接**: https://arxiv.org/abs/2512.04895
> **作者**: M Zeeshan,Saud Satti
> **摘要**: 多模态人工智能 (AI) 系统，特别是视觉语言模型 (VLM)，已成为从自主决策到自动文档处理等关键应用的组成部分。随着这些系统的扩展，它们严重依赖预处理管道来有效处理不同的输入。然而，这种对标准预处理操作（特别是图像缩小）的依赖会产生一个重大但经常被忽视的安全漏洞。虽然旨在进行计算优化，但缩放算法可用于隐藏恶意视觉提示，这些提示对于人类观察者来说是不可见的，但一旦被模型处理就会变成主动语义指令。当前的对抗策略在很大程度上仍然是静态的，未能考虑现代代理工作流程的动态本质。为了解决这一差距，我们提出了 Chameleon，这是一种新颖的自适应对抗框架，旨在暴露和利用生产 VLM 中的扩展漏洞。与传统的静态攻击不同，Chameleon 采用基于代理的迭代优化机制，可根据目标模型的实时反馈动态细化图像扰动。这使得该框架能够制作出高度稳健的对抗性示例，这些示例能够在标准缩减操作中幸存下来，从而劫持下游执行。我们针对 Gemini 2.5 Flash 模型评估 Chameleon。我们的实验表明，Chameleon 在不同的缩放因子上实现了 84.5% 的攻击成功率 (ASR)，明显优于平均仅为 32.1% 的静态基线攻击。此外，我们表明这些攻击有效地破坏了代理管道，使多步骤任务中的决策准确性降低了 45% 以上。最后，我们讨论这些漏洞的影响，并提出多尺度一致性检查作为必要的防御机制。
> **Abstract**: Multimodal Artificial Intelligence (AI) systems, particularly Vision-Language Models (VLMs), have become integral to critical applications ranging from autonomous decision-making to automated document processing. As these systems scale, they rely heavily on preprocessing pipelines to handle diverse inputs efficiently. However, this dependency on standard preprocessing operations, specifically image downscaling, creates a significant yet often overlooked security vulnerability. While intended for computational optimization, scaling algorithms can be exploited to conceal malicious visual prompts that are invisible to human observers but become active semantic instructions once processed by the model. Current adversarial strategies remain largely static, failing to account for the dynamic nature of modern agentic workflows. To address this gap, we propose Chameleon, a novel, adaptive adversarial framework designed to expose and exploit scaling vulnerabilities in production VLMs. Unlike traditional static attacks, Chameleon employs an iterative, agent-based optimization mechanism that dynamically refines image perturbations based on the target model's real-time feedback. This allows the framework to craft highly robust adversarial examples that survive standard downscaling operations to hijack downstream execution. We evaluate Chameleon against Gemini 2.5 Flash model. Our experiments demonstrate that Chameleon achieves an Attack Success Rate (ASR) of 84.5% across varying scaling factors, significantly outperforming static baseline attacks which average only 32.1%. Furthermore, we show that these attacks effectively compromise agentic pipelines, reducing decision-making accuracy by over 45% in multi-step tasks. Finally, we discuss the implications of these vulnerabilities and propose multi-scale consistency checks as a necessary defense mechanism.

【6】STELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions
- **标题**: STELLA：利用语义抽象指导时间序列预测的大型语言模型
- **链接**: https://arxiv.org/abs/2512.04871
> **作者**: Junjie Fan,Hongye Zhao,Linduo Wei,Jiayu Rao,Guijia Li,Jiaxin Yuan,Wenqi Xu,Yong Qi
> **摘要**: 最近用于时间序列预测的大型语言模型 (LLM) 的改编通常无法有效增强原始序列的信息，导致 LLM 推理功能未得到充分利用。现有的提示策略依赖于静态相关性，而不是对动态行为的生成解释，缺乏关键的全局和特定实例背景。为了解决这个问题，我们提出了 STELLA（与语言抽象的语义-时间对齐），这是一个系统地挖掘和注入结构化补充和补充信息的框架。 STELLA 采用动态语义抽象机制，将输入序列解耦为趋势、季节性和残差分量。然后，它将这些组件的内在行为特征转化为分层语义锚：用于全局上下文的语料库级语义先验（CSP）和用于实例级模式的细粒度行为提示（FBP）。 STELLA 使用这些锚点作为前缀提示，指导法学硕士对内在动态进行建模。对八个基准数据集的实验表明，STELLA 在长期和短期预测方面优于最先进的方法，在零样本和少样本设置中表现出卓越的泛化能力。消融研究进一步验证了我们动态生成的语义锚的有效性。
> **Abstract**: Recent adaptations of Large Language Models (LLMs) for time series forecasting often fail to effectively enhance information for raw series, leaving LLM reasoning capabilities underutilized. Existing prompting strategies rely on static correlations rather than generative interpretations of dynamic behavior, lacking critical global and instance-specific context. To address this, we propose STELLA (Semantic-Temporal Alignment with Language Abstractions), a framework that systematically mines and injects structured supplementary and complementary information. STELLA employs a dynamic semantic abstraction mechanism that decouples input series into trend, seasonality, and residual components. It then translates intrinsic behavioral features of these components into Hierarchical Semantic Anchors: a Corpus-level Semantic Prior (CSP) for global context and a Fine-grained Behavioral Prompt (FBP) for instance-level patterns. Using these anchors as prefix-prompts, STELLA guides the LLM to model intrinsic dynamics. Experiments on eight benchmark datasets demonstrate that STELLA outperforms state-of-the-art methods in long- and short-term forecasting, showing superior generalization in zero-shot and few-shot settings. Ablation studies further validate the effectiveness of our dynamically generated semantic anchors.

【7】Are Your Agents Upward Deceivers?
- **标题**: 你的经纪人是骗子吗？
- **链接**: https://arxiv.org/abs/2512.04864
> **作者**: Dadi Guo,Qingyu Liu,Dongrui Liu,Qihan Ren,Shuai Shao,Tianyi Qiu,Haoran Li,Yi R. Fung,Zhongjie Ba,Juntao Dai,Jiaming Ji,Zhikai Chen,Jialing Tao,Yaodong Yang,Jing Shao,Xia Hu
> **摘要**: 基于大型语言模型 (LLM) 的代理越来越多地用作为用户执行任务的自主下属。这就提出了一个问题：他们是否也可能进行欺骗，类似于人类组织中的个人如何向上级撒谎以树立良好形象或避免惩罚。我们观察并定义代理向上欺骗，这是一种面临环境限制的代理隐瞒其失败并在未报告的情况下执行未要求的操作的现象。为了评估其普遍性，我们构建了一个包含 200 项任务的基准，涵盖五种任务类型和受限环境中的八种现实场景，例如工具损坏或信息源不匹配。对 11 个流行的法学硕士的评估表明，这些代理通常表现出基于动作的欺骗行为，例如猜测结果、执行不受支持的模拟、替换不可用的信息源以及伪造本地文件。我们进一步测试了基于提示的缓解措施，发现仅减少了有限的情况，这表明很难消除，并强调需要更强有力的缓解策略来确保基于 LLM 的代理的安全。
> **Abstract**: Large Language Model (LLM)-based agents are increasingly used as autonomous subordinates that carry out tasks for users. This raises the question of whether they may also engage in deception, similar to how individuals in human organizations lie to superiors to create a good image or avoid punishment. We observe and define agentic upward deception, a phenomenon in which an agent facing environmental constraints conceals its failure and performs actions that were not requested without reporting. To assess its prevalence, we construct a benchmark of 200 tasks covering five task types and eight realistic scenarios in a constrained environment, such as broken tools or mismatched information sources. Evaluations of 11 popular LLMs reveal that these agents typically exhibit action-based deceptive behaviors, such as guessing results, performing unsupported simulations, substituting unavailable information sources, and fabricating local files. We further test prompt-based mitigation and find only limited reductions, suggesting that it is difficult to eliminate and highlighting the need for stronger mitigation strategies to ensure the safety of LLM-based agents.

【8】From Task Executors to Research Partners: Evaluating AI Co-Pilots Through Workflow Integration in Biomedical Research
- **标题**: 从任务执行者到研究合作伙伴：通过生物医学研究中的工作流程集成评估人工智能副驾驶
- **链接**: https://arxiv.org/abs/2512.04854
> **作者**: Lukas Weidener,Marko Brkić,Chiara Bacci,Mihailo Jovanović,Emre Ulgac,Alex Dobrin,Johannes Weniger,Martin Vlas,Ritvik Singh,Aakaash Meduri
> **摘要**: 人工智能系统越来越多地应用于生物医学研究。然而，当前的评估框架可能不足以评估他们作为研究合作者的有效性。这篇快速综述检查了临床前生物医学研究中人工智能系统的基准测试实践。从2018年1月1日到2025年10月31日，检索了三个主要数据库和两个预印本服务器，确定了评估人工智能在文献理解、实验设计和假设生成方面能力的14个基准。结果显示，当前所有基准测试都评估孤立组件的能力，包括数据分析质量、假设有效性和实验协议设计。然而，真正的研究协作需要跨越多个会话的集成工作流程，具有上下文记忆、自适应对话和约束传播。这种差距意味着在组件基准测试中表现出色的系统可能无法成为实际研究的副驾驶。提出了一个面向过程的评估框架，解决了当前基准中缺少的四个关键维度：对话质量、工作流程编排、会话连续性和研究人员经验。这些维度对于将人工智能系统评估为研究副驾驶而不是孤立的任务执行者至关重要。
> **Abstract**: Artificial intelligence systems are increasingly deployed in biomedical research. However, current evaluation frameworks may inadequately assess their effectiveness as research collaborators. This rapid review examines benchmarking practices for AI systems in preclinical biomedical research. Three major databases and two preprint servers were searched from January 1, 2018 to October 31, 2025, identifying 14 benchmarks that assess AI capabilities in literature understanding, experimental design, and hypothesis generation. The results revealed that all current benchmarks assess isolated component capabilities, including data analysis quality, hypothesis validity, and experimental protocol design. However, authentic research collaboration requires integrated workflows spanning multiple sessions, with contextual memory, adaptive dialogue, and constraint propagation. This gap implies that systems excelling on component benchmarks may fail as practical research co-pilots. A process-oriented evaluation framework is proposed that addresses four critical dimensions absent from current benchmarks: dialogue quality, workflow orchestration, session continuity, and researcher experience. These dimensions are essential for evaluating AI systems as research co-pilots rather than as isolated task executors.

【9】Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case
- **标题**: LLM 真的是多语言的吗？探索法学硕士信息检索的零样本多语言能力：意大利医疗保健用例
- **链接**: https://arxiv.org/abs/2512.04834
> **作者**: Vignesh Kumar Kembu,Pierandrea Morandini,Marta Bianca Maria Ranzini,Antonino Nocera
> **摘要**: 大型语言模型 (LLM) 已成为 AI 和 NLP 领域的一个关键主题，通过改善客户服务、自动化任务、提供见解、改进诊断和个性化学习体验，改变医疗保健、金融、教育和营销等行业。从临床记录中提取信息是数字医疗保健中的一项关键任务。尽管传统的 NLP 技术过去已用于此目的，但由于临床语言的复杂性、多变性以及免费临床文本中的高内在语义，它们常常存在不足。最近，大型语言模型（LLM）已成为更好地理解和生成类人文本的强大工具，使其在该领域非常有效。在本文中，我们探讨了开源多语言法学硕士理解意大利语 EHR（电子健康记录）并帮助从中实时提取信息的能力。我们从 EHR 中提取合并症的详细实验活动表明，一些法学硕士在零样本、本地环境中举步维艰，而其他法学硕士则表现出显着的性能差异，与本机模式匹配和手动注释相比，难以概括各种疾病。
> **Abstract**: Large Language Models (LLMs) have become a key topic in AI and NLP, transforming sectors like healthcare, finance, education, and marketing by improving customer service, automating tasks, providing insights, improving diagnostics, and personalizing learning experiences. Information extraction from clinical records is a crucial task in digital healthcare. Although traditional NLP techniques have been used for this in the past, they often fall short due to the complexity, variability of clinical language, and high inner semantics in the free clinical text. Recently, Large Language Models (LLMs) have become a powerful tool for better understanding and generating human-like text, making them highly effective in this area. In this paper, we explore the ability of open-source multilingual LLMs to understand EHRs (Electronic Health Records) in Italian and help extract information from them in real-time. Our detailed experimental campaign on comorbidity extraction from EHR reveals that some LLMs struggle in zero-shot, on-premises settings, and others show significant variation in performance, struggling to generalize across various diseases when compared to native pattern matching and manual annotations.

【10】Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing
- **标题**: 球堆积中基于模型和样本高效的人工智能辅助数学发现
- **链接**: https://arxiv.org/abs/2512.04829
> **作者**: Rasul Tutunov,Alexandre Maraval,Antoine Grosnit,Xihan Li,Jun Wang,Haitham Bou-Ammar
> **摘要**: 球堆积是希尔伯特的第十八个问题，要求 n 维欧几里得空间中全等球的最密集排列。尽管与密码学、晶体学和医学成像等领域相关，但该问题仍未解决：除了一些特殊尺寸之外，最佳堆积和严格的上限都是未知的。即使在 $n=8$ 维度上取得重大突破（后来获得菲尔兹奖），也凸显了其难度。三点法是一种领先的上限技术，可将问题简化为求解大型高精度半定规划 (SDP)。由于每个候选 SDP 可能需要数天的时间来评估，因此标准的数据密集型人工智能方法是不可行的。我们通过将 SDP 构建制定为一个顺序决策过程（SDP 游戏）来应对这一挑战，其中策略从一组可接受的组件中组装 SDP 公式。使用将贝叶斯优化与蒙特卡罗树搜索相结合的基于样本效率的模型框架，我们获得了维度 $4-16$ 的新的最先进的上限，表明基于模型的搜索可以推进长期存在的几何问题的计算进展。总之，这些结果表明，样本高效、基于模型的搜索可以在数学上僵化、评估有限的问题上取得切实进展，为人工智能辅助发现超越大规模法学硕士驱动的探索指明了补充方向。
> **Abstract**: Sphere packing, Hilbert's eighteenth problem, asks for the densest arrangement of congruent spheres in n-dimensional Euclidean space. Although relevant to areas such as cryptography, crystallography, and medical imaging, the problem remains unresolved: beyond a few special dimensions, neither optimal packings nor tight upper bounds are known. Even a major breakthrough in dimension $n=8$, later recognised with a Fields Medal, underscores its difficulty. A leading technique for upper bounds, the three-point method, reduces the problem to solving large, high-precision semidefinite programs (SDPs). Because each candidate SDP may take days to evaluate, standard data-intensive AI approaches are infeasible. We address this challenge by formulating SDP construction as a sequential decision process, the SDP game, in which a policy assembles SDP formulations from a set of admissible components. Using a sample-efficient model-based framework that combines Bayesian optimisation with Monte Carlo Tree Search, we obtain new state-of-the-art upper bounds in dimensions $4-16$, showing that model-based search can advance computational progress in longstanding geometric problems. Together, these results demonstrate that sample-efficient, model-based search can make tangible progress on mathematically rigid, evaluation limited problems, pointing towards a complementary direction for AI-assisted discovery beyond large-scale LLM-driven exploration.

【11】Enabling Ethical AI: A case study in using Ontological Context for Justified Agentic AI Decisions
- **标题**: 实现道德人工智能：使用本体论背景进行合理的代理人工智能决策的案例研究
- **链接**: https://arxiv.org/abs/2512.04822
> **作者**: Liam McGee,James Harvey,Lucy Cull,Andreas Vermeulen,Bart-Floris Visscher,Malvika Sharan
> **摘要**: 在本预印本中，我们提出了一种协作式人类人工智能方法，为 Agentic AI 构建可检查的语义层。 AI智能体首先从不同的数据源提出候选知识结构；然后，领域专家验证、纠正和扩展这些结构，并利用他们的反馈来改进后续模型。作者展示了这个过程如何捕捉隐性的机构知识，提高响应质量和效率，并减轻机构健忘症。我们主张从事后解释转向合理的代理人工智能，其中决策基于明确的、可检查的证据和专家和非专家都可以理解的推理。
> **Abstract**: In this preprint, we present A collaborative human-AI approach to building an inspectable semantic layer for Agentic AI. AI agents first propose candidate knowledge structures from diverse data sources; domain experts then validate, correct, and extend these structures, with their feedback used to improve subsequent models. Authors show how this process captures tacit institutional knowledge, improves response quality and efficiency, and mitigates institutional amnesia. We argue for a shift from post-hoc explanation to justifiable Agentic AI, where decisions are grounded in explicit, inspectable evidence and reasoning accessible to both experts and non-specialists.

【12】SIMA 2: A Generalist Embodied Agent for Virtual Worlds
- **标题**: SIMA 2：虚拟世界的通用实体代理
- **链接**: https://arxiv.org/abs/2512.04797
> **作者**: SIMA team,Adrian Bolton,Alexander Lerchner,Alexandra Cordell,Alexandre Moufarek,Andrew Bolt,Andrew Lampinen,Anna Mitenkova,Arne Olav Hallingstad,Bojan Vujatovic,Bonnie Li,Cong Lu,Daan Wierstra,Daniel P. Sawyer,Daniel Slater,David Reichert,Davide Vercelli,Demis Hassabis,Drew A. Hudson,Duncan Williams,Ed Hirst,Fabio Pardo,Felix Hill,Frederic Besse,Hannah Openshaw, et al. (41 additional authors not shown)
> **摘要**: 我们介绍 SIMA 2，这是一种通用的实体代理，可以理解各种 3D 虚拟世界并在其中执行操作。 SIMA 2 基于 Gemini 基础模型构建，代表了在具体环境中朝着主动、目标导向的交互迈出的重要一步。与之前仅限于简单语言命令的工作（例如 SIMA 1）不同，SIMA 2 充当交互式伙伴，能够推理高级目标、与用户对话并处理通过语言和图像给出的复杂指令。在各种不同的游戏组合中，SIMA 2 大大缩小了与人类表现的差距，并展示了对以前未见过的环境的强大泛化能力，同时保留了基本模型的核心推理能力。此外，我们还展示了开放式自我完善的能力：通过利用 Gemini 生成任务并提供奖励，SIMA 2 可以在新环境中从头开始自主学习新技能。这项工作验证了为虚拟世界和最终的物理世界创建多功能且持续学习的代理的路径。
> **Abstract**: We introduce SIMA 2, a generalist embodied agent that understands and acts in a wide variety of 3D virtual worlds. Built upon a Gemini foundation model, SIMA 2 represents a significant step toward active, goal-directed interaction within an embodied environment. Unlike prior work (e.g., SIMA 1) limited to simple language commands, SIMA 2 acts as an interactive partner, capable of reasoning about high-level goals, conversing with the user, and handling complex instructions given through language and images. Across a diverse portfolio of games, SIMA 2 substantially closes the gap with human performance and demonstrates robust generalization to previously unseen environments, all while retaining the base model's core reasoning capabilities. Furthermore, we demonstrate a capacity for open-ended self-improvement: by leveraging Gemini to generate tasks and provide rewards, SIMA 2 can autonomously learn new skills from scratch in a new environment. This work validates a path toward creating versatile and continuously learning agents for both virtual and, eventually, physical worlds.

【13】ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications
- **标题**: ASTRIDE：用于代理人工智能应用程序的安全威胁建模平台
- **链接**: https://arxiv.org/abs/2512.04785
> **作者**: Eranga Bandara,Amin Hass,Ross Gore,Sachin Shetty,Ravi Mukkamala,Safdar H. Bouk,Xueping Liang,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan
> **摘要**: 基于人工智能代理的系统越来越成为现代软件架构的一部分，通过大型语言模型 (LLM) 实现自主决策、动态任务执行和多模式交互。然而，这些系统引入了新颖且不断发展的安全挑战，包括即时注入攻击、上下文中毒、模型操纵和不透明的代理间通信，而传统的威胁建模框架无法有效捕获这些挑战。在本文中，我们介绍了 ASTRIDE，这是一个专为基于 AI 代理的系统而构建的自动化威胁建模平台。 ASTRIDE 通过引入新的威胁类别（A 表示特定于 AI 代理的攻击）扩展了经典的 STRIDE 框架，其中包含基于代理的应用程序特有的提示注入、不安全工具调用和推理颠覆等新兴漏洞。为了自动化威胁建模，ASTRIDE 将微调视觉语言模型 (VLM) 与 OpenAI-gpt-oss 推理 LLM 结合起来，直接从可视化代理架构图（例如数据流图 (DFD)）执行端到端分析。 LLM 代理通过协调 VLM 联盟和推理 LLM 之间的交互来编排端到端威胁建模自动化流程。我们的评估表明，ASTRIDE 为下一代智能系统提供了准确、可扩展且可解释的威胁建模。据我们所知，ASTRIDE 是第一个既能扩展 STRIDE 与 AI 特定威胁的框架，又能将微调的 VLM 与推理 LLM 相集成，以在基于 AI 代理的应用程序中完全自动化图表驱动的威胁建模。
> **Abstract**: AI agent-based systems are becoming increasingly integral to modern software architectures, enabling autonomous decision-making, dynamic task execution, and multimodal interactions through large language models (LLMs). However, these systems introduce novel and evolving security challenges, including prompt injection attacks, context poisoning, model manipulation, and opaque agent-to-agent communication, that are not effectively captured by traditional threat modeling frameworks. In this paper, we introduce ASTRIDE, an automated threat modeling platform purpose-built for AI agent-based systems. ASTRIDE extends the classical STRIDE framework by introducing a new threat category, A for AI Agent-Specific Attacks, which encompasses emerging vulnerabilities such as prompt injection, unsafe tool invocation, and reasoning subversion, unique to agent-based applications. To automate threat modeling, ASTRIDE combines a consortium of fine-tuned vision-language models (VLMs) with the OpenAI-gpt-oss reasoning LLM to perform end-to-end analysis directly from visual agent architecture diagrams, such as data flow diagrams(DFDs). LLM agents orchestrate the end-to-end threat modeling automation process by coordinating interactions between the VLM consortium and the reasoning LLM. Our evaluations demonstrate that ASTRIDE provides accurate, scalable, and explainable threat modeling for next-generation intelligent systems. To the best of our knowledge, ASTRIDE is the first framework to both extend STRIDE with AI-specific threats and integrate fine-tuned VLMs with a reasoning LLM to fully automate diagram-driven threat modeling in AI agent-based applications.

【14】Human Cognitive Biases in Explanation-Based Interaction: The Case of Within and Between Session Order Effect
- **标题**: 基于解释的交互中的人类认知偏差：会话内和会话顺序效应之间的案例
- **链接**: https://arxiv.org/abs/2512.04764
> **作者**: Dario Pesenti,Alessandro Bogani,Katya Tentori,Stefano Teso
> **摘要**: 解释性交互式学习 (XIL) 是一个强大的交互式学习框架，旨在使用户能够通过与解释交互来定制和纠正 AI 模型。简而言之，XIL 算法选择 AI 模型做出决策的多个项目（例如图像及其标签），并将它们与相应的解释一起呈现给用户（例如驱动模型决策的图像区域）。然后，用户为解释提供纠正反馈，算法使用这些反馈来改进模型。尽管在调试任务方面显示出希望，但最近的研究引起了人们的担忧，即解释性交互可能会引发顺序效应，这是一种众所周知的认知偏差，其中呈现项目的顺序会影响用户的信任，更重要的是，影响他们反馈的质量。我们认为这些研究并不完全是结论性的，因为所采用的实验设计和任务与常见的 XIL 用例有很大不同，这使得解释变得复杂。为了阐明顺序效应和解释性交互之间的相互作用，我们进行了两项更大规模的用户研究（总共 n = 713），旨在模拟常见的 XIL 任务。具体来说，我们通过操纵向参与者提供正确和错误解释的顺序来评估调试会话内和调试会话之间的顺序效应。顺序效应的影响是有限的，因为它对用户与模型的一致性（即他们信任的行为度量）产生重大影响，并且仅在调试会话中进行检查，而不是在它们之间进行检查。用户反馈的质量总体令人满意，在两个实验中顺序效应仅产生很小且不一致的影响。总体而言，我们的研究结果表明，顺序效应不会对 XIL 方法的成功应用造成重大问题。更广泛地说，我们的工作有助于理解人工智能中人为因素的持续努力。
> **Abstract**: Explanatory Interactive Learning (XIL) is a powerful interactive learning framework designed to enable users to customize and correct AI models by interacting with their explanations. In a nutshell, XIL algorithms select a number of items on which an AI model made a decision (e.g. images and their tags) and present them to users, together with corresponding explanations (e.g. image regions that drive the model's decision). Then, users supply corrective feedback for the explanations, which the algorithm uses to improve the model. Despite showing promise in debugging tasks, recent studies have raised concerns that explanatory interaction may trigger order effects, a well-known cognitive bias in which the sequence of presented items influences users' trust and, critically, the quality of their feedback. We argue that these studies are not entirely conclusive, as the experimental designs and tasks employed differ substantially from common XIL use cases, complicating interpretation. To clarify the interplay between order effects and explanatory interaction, we ran two larger-scale user studies (n = 713 total) designed to mimic common XIL tasks. Specifically, we assessed order effects both within and between debugging sessions by manipulating the order in which correct and wrong explanations are presented to participants. Order effects had a limited, through significant impact on users' agreement with the model (i.e., a behavioral measure of their trust), and only when examined withing debugging sessions, not between them. The quality of users' feedback was generally satisfactory, with order effects exerting only a small and inconsistent influence in both experiments. Overall, our findings suggest that order effects do not pose a significant issue for the successful employment of XIL approaches. More broadly, our work contributes to the ongoing efforts for understanding human factors in AI.

【15】Sequential Enumeration in Large Language Models
- **标题**: 大型语言模型中的顺序枚举
- **链接**: https://arxiv.org/abs/2512.04727
> **作者**: Kuinan Hou,Marco Zorzi,Alberto Testolin
> **摘要**: 可靠地计数和生成项目序列仍然是神经网络（包括大型语言模型 (LLM)）面临的重大挑战。事实上，虽然这种能力很容易被基于串行计算的基于规则的符号系统处理，但学习系统地部署计数过程对于神经模型来说是困难的，神经模型应该通过学习来获得这些技能。先前的研究表明，循环架构只能大致跟踪和枚举事件序列，并且目前尚不清楚包括法学硕士在内的现代深度学习系统是否可以在离散符号序列上部署系统计数程序。本文旨在通过研究五种最先进的法学硕士（包括专有模型、开源模型和推理模型）的顺序枚举能力来填补这一空白。我们探讨了法学硕士在涉及字母和单词列表的顺序命名和生产任务中，采用各种提示指令来探索思维链在计数策略自发出现中的作用。我们还评估具有相同架构但增加尺寸的开源模型，以了解计数原理的掌握是否遵循缩放定律，并且我们分析顺序枚举期间的嵌入动态以研究数字的紧急编码。我们发现，一些法学硕士确实能够在明确提示时部署计数程序，但当简单地要求枚举序列中的项目数时，他们都不会自发地参与计数。我们的结果表明，尽管法学硕士具有令人印象深刻的新兴能力，但它们还无法稳健、系统地部署计数程序，这凸显了神经和符号方法在成分泛化方面持续存在的差距。
> **Abstract**: Reliably counting and generating sequences of items remain a significant challenge for neural networks, including Large Language Models (LLMs). Indeed, although this capability is readily handled by rule-based symbolic systems based on serial computation, learning to systematically deploy counting procedures is difficult for neural models, which should acquire these skills through learning. Previous research has demonstrated that recurrent architectures can only approximately track and enumerate sequences of events, and it remains unclear whether modern deep learning systems, including LLMs, can deploy systematic counting procedures over sequences of discrete symbols. This paper aims to fill this gap by investigating the sequential enumeration abilities of five state-of-the-art LLMs, including proprietary, open-source, and reasoning models. We probe LLMs in sequential naming and production tasks involving lists of letters and words, adopting a variety of prompting instructions to explore the role of chain-of-thought in the spontaneous emerging of counting strategies. We also evaluate open-source models with the same architecture but increasing size to see whether the mastering of counting principles follows scaling laws, and we analyze the embedding dynamics during sequential enumeration to investigate the emergent encoding of numerosity. We find that some LLMs are indeed capable of deploying counting procedures when explicitly prompted to do so, but none of them spontaneously engage in counting when simply asked to enumerate the number of items in a sequence. Our results suggest that, despite their impressive emergent abilities, LLMs cannot yet robustly and systematically deploy counting procedures, highlighting a persistent gap between neural and symbolic approaches to compositional generalization.

【16】Playing the Player: A Heuristic Framework for Adaptive Poker AI
- **标题**: 扮演玩家：自适应扑克人工智能的启发式框架
- **链接**: https://arxiv.org/abs/2512.04714
> **作者**: Andrew Paterson,Carl Sanders
> **摘要**: 多年来，围绕扑克人工智能的讨论一直以求解器的概念和对不可利用的、机器完美的游戏的追求为主导。本文挑战了这种正统观念。它展示了帕特里克，一个建立在相反哲学之上的人工智能：胜利之路不在于不可剥削，而在于最大限度地剥削。帕特里克的架构是一个专门构建的引擎，用于理解和攻击人类对手的缺陷、心理和非理性本质。通过对其设计、新颖的预测锚定学习方法及其在 64,267 手试验中的盈利表现的详细分析，本文证明，已解决的神话分散了人们对真正的、更有趣的挑战的注意力：创造能够掌握人类缺陷艺术的人工智能。
> **Abstract**: For years, the discourse around poker AI has been dominated by the concept of solvers and the pursuit of unexploitable, machine-perfect play. This paper challenges that orthodoxy. It presents Patrick, an AI built on the contrary philosophy: that the path to victory lies not in being unexploitable, but in being maximally exploitative. Patrick's architecture is a purpose-built engine for understanding and attacking the flawed, psychological, and often irrational nature of human opponents. Through detailed analysis of its design, its novel prediction-anchored learning method, and its profitable performance in a 64,267-hand trial, this paper makes the case that the solved myth is a distraction from the real, far more interesting challenge: creating AI that can master the art of human imperfection.

【17】Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective
- **标题**: 走向大型语言模型的道德多代理系统：机械可解释性视角
- **链接**: https://arxiv.org/abs/2512.04691
> **作者**: Jae Hee Lee,Anne Lauscher,Stefano V. Albrecht
> **摘要**: 大型语言模型（LLM）已广泛部署在各种应用程序中，通常充当多代理系统中相互交互的自主代理。虽然这些系统在增强能力和完成复杂任务方面表现出了希望，但它们也带来了重大的道德挑战。本立场文件概述了一项研究议程，旨在从机械可解释性的角度确保法学硕士（MALM）多智能体系统的道德行为。我们确定了三个关键的研究挑战：（i）开发全面的评估框架来评估个人、互动和系统层面的道德行为； (ii) 通过机械解释阐明引发紧急行为的内部机制； (iii) 实施有针对性的参数有效调整技术，以引导 MALM 采取道德行为，而不影响其性能。
> **Abstract**: Large language models (LLMs) have been widely deployed in various applications, often functioning as autonomous agents that interact with each other in multi-agent systems. While these systems have shown promise in enhancing capabilities and enabling complex tasks, they also pose significant ethical challenges. This position paper outlines a research agenda aimed at ensuring the ethical behavior of multi-agent systems of LLMs (MALMs) from the perspective of mechanistic interpretability. We identify three key research challenges: (i) developing comprehensive evaluation frameworks to assess ethical behavior at individual, interactional, and systemic levels; (ii) elucidating the internal mechanisms that give rise to emergent behaviors through mechanistic interpretability; and (iii) implementing targeted parameter-efficient alignment techniques to steer MALMs towards ethical behaviors without compromising their performance.

【18】Turbo-Muon: Accelerating Orthogonality-Based Optimization with Pre-Conditioning
- **标题**: Turbo-Muon：通过预处理加速基于正交性的优化
- **链接**: https://arxiv.org/abs/2512.04632
> **作者**: Thibaut Boissin,Thomas Massena,Franck Mamalet,Mathieu Serrurier
> **摘要**: 基于正交性的优化器（例如 Muon）最近在大规模培训和社区驱动的效率挑战中表现出了强大的性能。然而，这些方法依赖于昂贵的梯度正交化步骤。即使像 Newton-Schulz 这样高效的迭代近似仍然很昂贵，通常需要数十次矩阵乘法才能收敛。我们引入了一种预处理过程，可以加速牛顿-舒尔茨收敛并降低其计算成本。我们评估了它的影响，并表明我们的预处理的开销可以忽略不计。此外，它的收敛速度更快，使我们能够从通常的五次迭代中删除一次，而不会降低近似质量。我们公开的实现在牛顿-舒尔茨近似中实现了高达 2.8 倍的加速。我们还表明，这对端到端训练运行时间有直接影响，两个注重效率的任务的实际训练场景提高了 5-10%。在具有挑战性的语言或视觉任务中，我们验证我们的方法在提高运行时间的同时保持相同或更好的模型性能。至关重要的是，这些改进不需要超参数调整，并且可以作为简单的直接替代品采用。我们的代码在 github 上公开可用。
> **Abstract**: Orthogonality-based optimizers, such as Muon, have recently shown strong performance across large-scale training and community-driven efficiency challenges. However, these methods rely on a costly gradient orthogonalization step. Even efficient iterative approximations such as Newton-Schulz remain expensive, typically requiring dozens of matrix multiplications to converge. We introduce a preconditioning procedure that accelerates Newton-Schulz convergence and reduces its computational cost. We evaluate its impact and show that the overhead of our preconditioning can be made negligible. Furthermore, the faster convergence it enables allows us to remove one iteration out of the usual five without degrading approximation quality. Our publicly available implementation achieves up to a 2.8x speedup in the Newton-Schulz approximation. We also show that this has a direct impact on end-to-end training runtime with 5-10% improvement in realistic training scenarios across two efficiency-focused tasks. On challenging language or vision tasks, we validate that our method maintains equal or superior model performance while improving runtime. Crucially, these improvements require no hyperparameter tuning and can be adopted as a simple drop-in replacement. Our code is publicly available on github.

【19】BioMedGPT-Mol: Multi-task Learning for Molecular Understanding and Generation
- **标题**: BioMedGPT-Mol：分子理解和生成的多任务学习
- **链接**: https://arxiv.org/abs/2512.04629
> **作者**: Chenyang Zuo,Siqi Fan,Zaiqing Nie
> **摘要**: 分子在生物医学研究和发现中发挥着至关重要的作用，特别是在小分子药物开发领域。鉴于大型语言模型的快速发展，特别是最近出现的推理模型，探索通用语言模型如何有效地适应分子科学应用是很自然的。在这项工作中，我们介绍了 BioMedGPT-Mol，一种旨在支持分子理解和生成任务的分子语言模型。通过整理和统一现有的公共教学数据集，我们组装了一个大规模、全面、高质量的训练数据集。然后通过精心设计的多任务学习框架对该模型进行微调。在 LlaSMol、TOMG-Bench 和 MuMOInstruct 的综合基准上，BioMedGPT-Mol 取得了卓越的性能。我们的实验结果表明，通过结构良好的多任务课程，可以将通用推理模型有效且高效地后训练为专业分子语言模型。利用它的力量，我们进一步探索逆向综合规划任务，RetroBench 上的表现证明了其作为端到端逆向综合规划器的竞争能力。我们预计我们的方法可以扩展到其他生物医学科学领域。
> **Abstract**: Molecules play a crucial role in biomedical research and discovery, particularly in the field of small molecule drug development. Given the rapid advancements in large language models, especially the recent emergence of reasoning models, it is natural to explore how a general-purpose language model can be efficiently adapted for molecular science applications. In this work, we introduce BioMedGPT-Mol, a molecular language model designed to support molecular understanding and generation tasks. By curating and unifying existing public instruction datasets, we have assembled a large-scale, comprehensive, and high-quality training dataset. The model is then fine-tuned through a meticulously designed multi-task learning framework. On a consolidated benchmark derived from LlaSMol, TOMG-Bench, and MuMOInstruct, BioMedGPT-Mol achieves remarkable performance. Our experimental results demonstrate that a general-purpose reasoning model can be effectively and efficiently post-trained into a professional molecular language model through a well-structured multi-task curriculum. Leveraging the power of it, we further explore retrosynthetic planning task, and the performance on RetroBench demonstrates its competitive capability of acting as an end-to-end retrosynthetic planner. We anticipate that our approach can be extended to other biomedical scientific domains.

【20】Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning
- **标题**: 使用视觉变换器和对比表示学习对 ECoG 中的显性语音进行神经解码
- **链接**: https://arxiv.org/abs/2512.04618
> **作者**: Mohamed Baha Ben Ticha,Xingchen Ran,Guillaume Saldanha,Gaël Le Godais,Philémon Roussel,Marc Aubert,Amina Fontanell,Thomas Costecalde,Lucas Struber,Serpil Karakas,Shaomin Zhang,Philippe Kahane,Guillaume Charvet,Stéphan Chabardès,Blaise Yvert
> **摘要**: 语音脑机接口 (BCI) 为患有严重瘫痪而无法沟通的人提供了有前景的解决方案。最近的许多研究表明，通过预测一系列音素或单词并使用下游语言模型获得有意义的句子，可以从表面皮质电图（ECoG）或皮质内记录中令人信服地重建可理解的语音。当前的挑战是通过将皮层信号直接回归为声学语音来以流模式重建语音。虽然最近已经使用皮质内数据实现了这一目标，但还需要进一步的工作才能获得与表面 ECoG 记录可比较的结果。特别是，在这种情况下，优化神经解码器变得至关重要。在这里，我们提出了一种基于编码器-解码器深度神经架构的离线语音解码管道，集成了视觉变换器和对比学习，以增强 ECoG 信号中语音的直接回归。该方法在两个数据集上进行评估，一个数据集是通过癫痫患者的临床硬​​膜下电极获得的，另一个数据集是通过运动 BCI 试验参与者的完全植入式 WIMAGINE 硬膜外系统获得的。据我们所知，这是从完全植入式无线硬膜外录音系统解码语音的首次尝试，为长期使用提供了前景。
> **Abstract**: Speech Brain Computer Interfaces (BCIs) offer promising solutions to people with severe paralysis unable to communicate. A number of recent studies have demonstrated convincing reconstruction of intelligible speech from surface electrocorticographic (ECoG) or intracortical recordings by predicting a series of phonemes or words and using downstream language models to obtain meaningful sentences. A current challenge is to reconstruct speech in a streaming mode by directly regressing cortical signals into acoustic speech. While this has been achieved recently using intracortical data, further work is needed to obtain comparable results with surface ECoG recordings. In particular, optimizing neural decoders becomes critical in this case. Here we present an offline speech decoding pipeline based on an encoder-decoder deep neural architecture, integrating Vision Transformers and contrastive learning to enhance the direct regression of speech from ECoG signals. The approach is evaluated on two datasets, one obtained with clinical subdural electrodes in an epileptic patient, and another obtained with the fully implantable WIMAGINE epidural system in a participant of a motor BCI trial. To our knowledge this presents a first attempt to decode speech from a fully implantable and wireless epidural recording system offering perspectives for long-term use.

【21】The Ethics of Generative AI
- **标题**: 生成人工智能的伦理
- **链接**: https://arxiv.org/abs/2512.04598
> **作者**: Michael Klenk
> **摘要**: 本章讨论生成式人工智能的伦理问题。它提供了一个技术入门读物，展示生成式人工智能如何提供像人类一样体验技术的能力，并且这种功能为生成式人工智能的哲学伦理提供了富有成果的焦点。然后，它展示了生成式人工智能如何加剧和减轻人工智能伦理中常见的伦理问题，包括责任、隐私、偏见和公平，以及异化和剥削的形式。最后，本章探讨了由生成人工智能的模仿生成性产生的伦理问题，例如关于作者身份和信用的争论、与机器的仿佛社会关系的出现，以及新形式的影响、说服和操纵。
> **Abstract**: This chapter discusses the ethics of generative AI. It provides a technical primer to show how generative AI affords experiencing technology as if it were human, and this affordance provides a fruitful focus for the philosophical ethics of generative AI. It then shows how generative AI can both aggravate and alleviate familiar ethical concerns in AI ethics, including responsibility, privacy, bias and fairness, and forms of alienation and exploitation. Finally, the chapter examines ethical questions that arise specifically from generative AI's mimetic generativity, such as debates about authorship and credit, the emergence of as-if social relationships with machines, and new forms of influence, persuasion, and manipulation.

【22】GTM: Simulating the World of Tools for AI Agents
- **标题**: GTM：模拟人工智能代理的工具世界
- **链接**: https://arxiv.org/abs/2512.04535
> **作者**: Zhenzhen Ren,Xinpeng Zhang,Zhenxing Qian,Yan Gao,Yu Shi,Shuxin Zheng,Jiyan He
> **摘要**: 外部工具的集成对于为大型语言模型 (LLM) 代理提供实际功能至关重要。然而，通过与不同工具直接、持续交互来训练这些代理通常成本高昂、速度缓慢，并且会带来额外的开发和维护开销。为了应对这一挑战，我们引入了通用工具模型 (GTM)，这是一个拥有 15 亿参数的模型，可以学习充当通用工具模拟器。只需进行提示级配置，GTM 即可访问工具功能以及输入参数，并生成忠实模仿真实工具执行的输出，从而提供快速且经济高效的解决方案，消除开发开销。为了构建 GTM，我们提出了上下文感知响应生成 (CARG) 管道，该管道综合了涵盖物理、医学、机器人和金融等 300 个领域的 20,000 多种工具的综合训练数据。通过这个管道，GTM 不仅学会生成语法正确的输出，而且生成逻辑连贯且上下文适当的响应。实验表明，GTM 能够产生高质量的输出，具有很强的一致性和可靠性。除了在用于代理训练的真实强化学习场景中使用时，与真实工具相比，GTM 还表现出明显更快的模拟速度，同时保持可比较的输出质量，以及出色的泛化性和领域适应性。我们的结果将 GTM 确立为开发未来人工智能代理的基础组件，从而实现工具增强系统的高效且可扩展的培训。
> **Abstract**: The integration of external tools is pivotal for empowering Large Language Model (LLM) agents with real-world capabilities. However, training these agents through direct, continuous interaction with diverse tools is often prohibitively expensive, slow, and introduces additional development and maintenance overhead. To address this challenge, we introduce the Generalist Tool Model (GTM), a 1.5-billion-parameter model that learns to act as a universal tool simulator. With only prompt-level configuration, GTM accesses tool functionalities along with input arguments and generates outputs that faithfully mimic real tool execution, providing a fast and cost-effective solution that eliminates development overhead. To build GTM, we propose the Context-Aware Response Generation (CARG) pipeline, which synthesizes comprehensive training data covering over 20,000 tools across 300 domains including physics, medicine, robotics, and finance. Through this pipeline, GTM learns to produce not only syntactically correct outputs but also logically coherent and contextually appropriate responses. Experiments demonstrate that GTM produces high-quality outputs with strong consistency and reliability. Besides when used in real reinforcement learning scenarios for agent training, GTM exhibits significantly faster simulation speed compared to real tools while maintaining comparable output quality, along with remarkable generalization and domain adaptability. Our results establish GTM as a foundational component for developing future AI agents, enabling efficient and scalable training of tool-augmented systems.

【23】SlideGen: Collaborative Multimodal Agents for Scientific Slide Generation
- **标题**: SlideGen：用于科学幻灯片生成的协作多模式代理
- **链接**: https://arxiv.org/abs/2512.04529
> **作者**: Xin Liang,Xiang Zhang,Yiwei Xu,Siqi Sun,Chenyu You
> **摘要**: 从科学论文生成学术幻灯片是一项具有挑战性的多模式推理任务，需要长期的上下文理解和深思熟虑的视觉规划。现有的方法在很大程度上将其简化为仅文本摘要，忽略了幻灯片创建的视觉组件和设计密集性质。在本文中，我们介绍了 SlideGen，这是一个用于科学论文到幻灯片生成的代理、模块化和可视化循环框架。 SlideGen 协调一组视觉语言代理，对文档结构和语义进行协作推理，生成具有逻辑流程和引​​人注目的视觉演示的可编辑 PPTX 幻灯片。通过集成协调的大纲、映射、排列、注释合成和迭代细化，我们的系统始终如一地提供专家级质量的幻灯片。在不同的基准和强大的基线中，SlideGen 在视觉质量、内容忠实度和可读性方面优于现有方法，将其定位为自动幻灯片生成领域的最新技术。我们的工作为设计感知多模态幻灯片生成奠定了基础，展示了代理协作如何在复杂的多模态推理任务中架起理解和呈现的桥梁。
> **Abstract**: Generating academic slides from scientific papers is a challenging multimodal reasoning task that requires both long context understanding and deliberate visual planning. Existing approaches largely reduce it to text only summarization, overlooking the visual component and design intensive nature of slide creation. In this paper we introduce SlideGen, an agentic, modular, and visual in the loop framework for scientific paper to slide generation. SlideGen orchestrates a group of vision language agents that reason collaboratively over the document structure and semantics, producing editable PPTX slides with logical flow and compelling visual presentation. By integrating coordinated outlining, mapping, arrangement, note synthesis, and iterative refinement, our system consistently delivers slides of expert level quality. Across diverse benchmarks and strong baselines, SlideGen outperforms existing methods in visual quality, content faithfulness, and readability, positioning it as the new state of the art in automated slide generation. Our work establishes a foundation for design aware multimodal slide generation, demonstrating how agentic collaboration can bridge understanding and presentation in complex multimodal reasoning tasks.

【24】BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models
- **标题**: BiTAgent：用于多模态大型语言模型和世界模型之间双向耦合的任务感知模块化框架
- **链接**: https://arxiv.org/abs/2512.04513
> **作者**: Yu-Wei Zhan,Xin Wang,Pengzhe Mao,Tongtong Feng,Ren Wang,Wenwu Zhu
> **摘要**: 构建多面手的具体代理需要一个统一的系统，该系统可以解释多模式目标、对环境动态进行建模并在不同的现实世界任务中执行可靠的操作。多模态大语言模型（MLLM）提供强大的语义先验和跨模态泛化，而世界模型（WM）为预测和控制提供可操作的潜在动态。它们的组合有望实现开放式具身智能，但也带来了两个关键挑战：(1) 在 MLLM 的语义意图与 WM 潜在空间内的动态状态表示之间建立紧密耦合，(2) 实现支持多任务学习和跨环境泛化的任务感知适应性。为了解决这些限制，我们提出了 BiTAgent，这是一种任务感知的动态联合框架，可以实现 MLLM 和 WM 之间的双向耦合。 BiTAgent 建立了两条互补的路径：一条前向路径将 MLLM 表示注入 WM 的潜在空间以进行语义引导想象，一条后向路径是 WM 生成的反馈通过密集的文本条件奖励细化 MLLM 的语义空间。这种双向交互是通过三个协同组件实现的：任务感知动态联合学习、任务感知行为学习和 MLLM-WM 联合优化，它们共同协调语义推理和动态预测。跨多任务和跨环境设置的广泛实验表明，与最先进的基线相比，具有卓越的稳定性和泛化性，标志着向开放式具身学习迈出了一步。
> **Abstract**: Building generalist embodied agents requires a unified system that can interpret multimodal goals, model environment dynamics, and execute reliable actions across diverse real-world tasks. Multimodal large language models (MLLMs) offer strong semantic priors and cross-modal generalization, while world models (WMs) provide actionable latent dynamics for prediction and control. Their combination holds promise for open-ended embodied intelligence, yet introduces two key challenges: (1) establishing a tight coupling between the semantic intent from MLLMs and the dynamic state representations within the WM's latent space, and (2) achieving task-aware adaptability that supports multi-task learning and cross-environment generalization. To address these limitations, we propose BiTAgent, a task-aware dynamic joint framework that enables bidirectional coupling between MLLMs and WMs. BiTAgent establishes two complementary pathways: a forward path that injects MLLM representations into the WM's latent space for semantically guided imagination, and a backward path where WM-generated feedback refines the MLLM's semantic space via dense text-conditioned rewards. This bidirectional interaction is realized through three synergistic components: Task-Aware Dynamic Joint Learning, Task-Aware Behavior Learning, and MLLM-WM Joint Optimization, which together harmonize semantic reasoning and dynamic prediction. Extensive experiments across multi-task and cross-environment settings demonstrate superior stability and generalization over state-of-the-art baselines, marking a step toward open-ended embodied learning.

【25】A Modular Cognitive Architecture for Assisted Reasoning: The Nemosine Framework
- **标题**: 用于辅助推理的模块化认知架构：Nemosine 框架
- **链接**: https://arxiv.org/abs/2512.04500
> **作者**: Edervaldo Melo
> **摘要**: 本文介绍了 Nemosine 框架，这是一种模块化认知架构，旨在支持辅助推理、结构化思维和系统分析。该模型通过功能认知模块（“角色”）来组织规划、评估、交叉检查和叙述综合等任务。该框架结合了元认知、分布式认知和模块化认知系统的原理，为辅助问题解决和决策支持提供了操作结构。该架构通过正式规范、内部一致性标准和可复制的结构组件进行记录。目标是为未来的计算实现提供清晰的概念基础，并为推理符号模块化架构的研究做出贡献。
> **Abstract**: This paper presents the Nemosine Framework, a modular cognitive architecture designed to support assisted reasoning, structured thinking, and systematic analysis. The model operates through functional cognitive modules ("personas") that organize tasks such as planning, evaluation, cross-checking, and narrative synthesis. The framework combines principles from metacognition, distributed cognition, and modular cognitive systems to offer an operational structure for assisted problem-solving and decision support. The architecture is documented through formal specification, internal consistency criteria, and reproducible structural components. The goal is to provide a clear conceptual basis for future computational implementations and to contribute to the study of symbolic-modular architectures for reasoning.

【26】Persona-based Multi-Agent Collaboration for Brainstorming
- **标题**: 基于角色的多智能体协作进行头脑风暴
- **链接**: https://arxiv.org/abs/2512.04488
> **作者**: Nate Straub,Saara Khan,Katharina Jay,Brian Cabral,Oskar Linde
> **摘要**: 我们证明了基于人物角色的多主体头脑风暴对于不同主题和主题构思的重要性。先前的工作表明，广义的多智能体协作通常比单独的单个智能体提供更好的推理。在本文中，我们提出并开发了一个基于角色的代理选择框架，展示了角色域管理如何改善头脑风暴的结果。使用多个实验设置，我们评估不同角色配对（例如，医生与 VR 工程师）和 A2A（代理对代理）动态（单独、一起、单独然后一起）的头脑风暴输出。我们的结果表明，（1）角色选择塑造了想法领域，（2）协作模式改变了想法生成的多样性，（3）多代理角色驱动的头脑风暴产生了想法深度和跨领域覆盖。
> **Abstract**: We demonstrate the importance of persona-based multi-agents brainstorming for both diverse topics and subject matter ideation. Prior work has shown that generalized multi-agent collaboration often provides better reasoning than a single agent alone. In this paper, we propose and develop a framework for persona-based agent selection, showing how persona domain curation can improve brainstorming outcomes. Using multiple experimental setups, we evaluate brainstorming outputs across different persona pairings (e.g., Doctor vs VR Engineer) and A2A (agent-to-agent) dynamics (separate, together, separate-then-together). Our results show that (1) persona choice shapes idea domains, (2) collaboration mode shifts diversity of idea generation, and (3) multi-agent persona-driven brainstorming produces idea depth and cross-domain coverage.

【27】AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Substituitions
- **标题**: 人工智能辅助游戏管理决策：实时替换的模糊逻辑方法
- **链接**: https://arxiv.org/abs/2512.04480
> **作者**: Pedro Passos
> **摘要**: 在精英足球中，换人决策会带来重大的财务和体育后果，但仍然严重依赖于仅仅模仿历史偏见的直觉或预测模型。本文介绍了一种基于模糊逻辑的决策支持系统（DSS），专为实时、规范的游戏管理而设计。与试图复制人类行为而遇到预测上限的传统机器学习方法不同，我们的系统通过客观的、基于规则的推理引擎来审核性能。我们提出了一种方法上的改进，通过将 PlayeRank 指标重新表述为具有角色感知归一化的累积平均值，消除累积总和模型中固有的游戏时间暴露偏差，从而实现准确的比赛内比较。该系统将这种精确的指标与生理指标（疲劳）和情境变量（由战术角色调节的纪律风险）相结合，以计算动态替换优先级（P 最终）。通过 2018 年 FIFA 世界杯巴西与比利时比赛的案例研究进行验证，证明了该系统的生态有效性：它不仅与执行换人的专家共识一致（例如加布里埃尔·热苏斯），而且最重要的是，识别了人类决策者忽视的高风险场景。具体来说，该模型在收到关键黄牌前几分钟标记了“法格纳悖论”（最高优先级的防守风险），并检测到了“卢卡库悖论”，即一次孤立的助攻掩盖了参与度的严重下降。这些结果证实，模糊逻辑为优化实时战术决策提供了一种透明的、可解释的、优于黑盒模型的替代方案。
> **Abstract**: In elite soccer, substitution decisions entail significant financial and sporting consequences yet remain heavily reliant on intuition or predictive models that merely mimic historical biases. This paper introduces a Fuzzy Logic based Decision Support System (DSS) designed for real time, prescriptive game management. Unlike traditional Machine Learning approaches that encounter a predictive ceiling by attempting to replicate human behavior, our system audits performance through an objective, rule based inference engine. We propose a methodological advancement by reformulating the PlayeRank metric into a Cumulative Mean with Role Aware Normalization, eliminating the play time exposure bias inherent in cumulative sum models to enable accurate intra match comparison. The system integrates this refined metric with physiological proxies (fatigue) and contextual variables (disciplinary risk modulated by tactical role) to calculate a dynamic Substitution Priority (P final). Validation via a case study of the 2018 FIFA World Cup match between Brazil and Belgium demonstrates the system's ecological validity: it not only aligned with expert consensus on executed substitutions (for example Gabriel Jesus) but, crucially, identified high risk scenarios ignored by human decision makers. Specifically, the model flagged the "FAGNER Paradox" - a maximum priority defensive risk - minutes before a critical yellow card, and detected the "Lukaku Paradox", where an isolated assist masked a severe drop in participation. These results confirm that Fuzzy Logic offers a transparent, explainable, and superior alternative to black box models for optimizing real time tactical decisions.

【28】Mathematical Framing for Different Agent Strategies
- **标题**: 不同代理策略的数学框架
- **链接**: https://arxiv.org/abs/2512.04469
> **作者**: Philip Stephens,Emmanuel Salawu
> **摘要**: 我们引入了一个统一的数学和概率框架来理解和比较不同的人工智能代理策略。我们弥合了高级代理设计概念（例如 ReAct、多代理系统和控制流）与严格的数学公式之间的差距。我们的方法将代理过程构建为一系列概率，从而能够详细分析不同策略如何操纵这些概率以实现期望的结果。我们的框架提供了一种通用语言来讨论各种代理架构中固有的权衡。我们的众多关键贡献之一是引入“自由度”概念，它直观地区分了每种方法可用的可优化杠杆，从而指导为特定任务选择适当的策略。这项工作旨在提高人工智能代理设计和评估的清晰度和精确度，为最大限度地提高复杂代理系统中成功行动的可能性提供见解。
> **Abstract**: We introduce a unified mathematical and probabilistic framework for understanding and comparing diverse AI agent strategies. We bridge the gap between high-level agent design concepts, such as ReAct, multi-agent systems, and control flows, and a rigorous mathematical formulation. Our approach frames agentic processes as a chain of probabilities, enabling a detailed analysis of how different strategies manipulate these probabilities to achieve desired outcomes. Our framework provides a common language for discussing the trade-offs inherent in various agent architectures. One of our many key contributions is the introduction of the "Degrees of Freedom" concept, which intuitively differentiates the optimizable levers available for each approach, thereby guiding the selection of appropriate strategies for specific tasks. This work aims to enhance the clarity and precision in designing and evaluating AI agents, offering insights into maximizing the probability of successful actions within complex agentic systems.

【29】MARL Warehouse Robots
- **标题**: MARL 仓库机器人
- **链接**: https://arxiv.org/abs/2512.04463
> **作者**: Price Allman,Lian Thang,Dre Simmons,Salmon Riaz
> **摘要**: 我们提出了用于协作仓库机器人的多智能体强化学习（MARL）算法的比较研究。我们在机器人仓库 (RWARE) 环境和自定义 Unity 3D 模拟上评估 QMIX 和 IPPO。我们的实验表明，QMIX 的价值分解显着优于独立学习方法（实现 3.25 平均回报，而高级 IPPO 为 0.38），但需要广泛的超参数调整 - 特别是扩展 epsilon 退火（5M + 步骤）以进行稀疏奖励发现。我们展示了 Unity ML-Agents 中的成功部署，在 100 万个训练步骤后实现了一致的包交付。虽然 MARL 显示出小规模部署（2-4 个机器人）的前景，但仍然存在重大的扩展挑战。代码和分析：https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/
> **Abstract**: We present a comparative study of multi-agent reinforcement learning (MARL) algorithms for cooperative warehouse robotics. We evaluate QMIX and IPPO on the Robotic Warehouse (RWARE) environment and a custom Unity 3D simulation. Our experiments reveal that QMIX's value decomposition significantly outperforms independent learning approaches (achieving 3.25 mean return vs. 0.38 for advanced IPPO), but requires extensive hyperparameter tuning -- particularly extended epsilon annealing (5M+ steps) for sparse reward discovery. We demonstrate successful deployment in Unity ML-Agents, achieving consistent package delivery after 1M training steps. While MARL shows promise for small-scale deployments (2-4 robots), significant scaling challenges remain. Code and analyses: https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/

## 硬件架构(cs.AR:Hardware Architecture)

【1】Declarative Synthesis and Multi-Objective Optimization of Stripboard Circuit Layouts Using Answer Set Programming
- **标题**: 使用答案集编程对 Stripboard 电路布局进行声明性综合和多目标优化
- **链接**: https://arxiv.org/abs/2512.04910
> **作者**: Fang Li
> **摘要**: 本文提出了一种使用答案集编程 (ASP) 进行自动条板电路布局设计的新颖方法。这项工作将布局问题表述为综合和多目标优化任务，同时生成可行的布局，同时最大限度地减少电路板面积和元件带交叉。通过利用 ASP 的声明性特性，这项工作以自然简洁的方式表达了复杂的几何和电气约束。两阶段求解方法首先确保可行性，然后再优化布局质量。实验结果表明，这种方法可以针对各种复杂的电路生成紧凑的、可制造的布局。这项工作代表了自动化条板布局的重大进步，为电子原型设计和教育提供了实用工具，同时展示了声明式编程在解决复杂设计自动化问题方面的强大功能。
> **Abstract**: This paper presents a novel approach to automated stripboard circuit layout design using Answer Set Programming (ASP). The work formulates the layout problem as both a synthesis and multi-objective optimization task that simultaneously generates viable layouts while minimizing board area and component strip crossing. By leveraging ASP's declarative nature, this work expresses complex geometric and electrical constraints in a natural and concise manner. The two-phase solving methodology first ensures feasibility before optimizing layout quality. Experimental results demonstrate that this approach generates compact, manufacturable layouts for a range of circuit complexities. This work represents a significant advancement in automated stripboard layout, offering a practical tool for electronics prototyping and education while showcasing the power of declarative programming for solving complex design automation problems.

【2】Functional Stability of Software-Hardware Neural Network Implementation The NeuroComp Project
- **标题**: 软硬件神经网络实现的功能稳定性 NeuroComp 项目
- **链接**: https://arxiv.org/abs/2512.04867
> **作者**: Bychkov Oleksii,Senysh Taras
> **摘要**: 本文提出了一种创新方法，通过单个神经元级别的硬件冗余来确保神经网络的功能稳定性。与在训练期间用于正则化目的的经典 Dropout 方法不同，所提出的系统确保网络运行期间对硬件故障的恢复能力。每个神经元都在单独的微型计算机 (ESP32) 上实现，即使单个计算节点出现故障，系统也能继续运行。
> **Abstract**: This paper presents an innovative approach to ensuring functional stability of neural networks through hardware redundancy at the individual neuron level. Unlike the classical Dropout method, which is used during training for regularization purposes, the proposed system ensures resilience to hardware failures during network operation. Each neuron is implemented on a separate microcomputer (ESP32), allowing the system to continue functioning even when individual computational nodes fail.

## 计算复杂度(cs.CC:Computational Complexity)

【1】MAX BISECTION might be harder to approximate than MAX CUT
- **标题**: MAX BISECTION 可能比 MAX CUT 更难近似
- **链接**: https://arxiv.org/abs/2512.04951
> **作者**: Joshua Brakensiek,Neng Huang,Aaron Potechin,Uri Zwick
> **摘要**: 最大二分问题寻求均匀划分给定无向图的顶点的最大尺寸切割。 Austrin、Benabbas 和 Georgiou 提出的一个悬而未决的问题是 MAX BISECTION 是否可以像 MAX CUT 一样近似，即在 ${α_{GW}}\approx 0.8785672\ldots$ 范围内，这是著名的 Goemans-Williamson 算法针对 MAX CUT 实现的近似率，这在假设独特游戏猜想 (UGC) 的情况下是最好的。他们推测答案是肯定的。 Raghavendra 和 Tan 以及 Austrin、Benabbas 和 Georgiou 提出的当前获取 MAX BISECTION 近似算法的范例遵循两阶段方法。首先，使用大量的平方和（SoS）层次结构来找到 MAX CUT 的“基本 SDP”松弛的解决方案，对于任意小的 $\varepsilon > 0$，它是 $\varepsilon$ 不相关的。其次，使用标准 SDP 舍入技术（例如 ${\cal THRESH}$）对这个 $\varepsilon$ 不相关解进行舍入，以高概率生成几乎平衡的切割，即每侧顶点最多具有 $\frac12+\varepsilon$ 分数的切割。然后将该切割转换为图形的精确平分，只有很小的损失。在本文中，我们表明，如果仅依赖于第一阶段产生的解决方案的 $\varepsilon$-不相关性属性，则这种两阶段范式不能用于获得 MAX BISECTION 的 $α_{GW}$ 近似算法。更准确地说，对于任何 $\varepsilon > 0$，我们构造一个 MAX BISECTION 的显式实例，其中最优积分解的值与基本 SDP 松弛的某些 $\varepsilon$ 不相关解的值之间的比率小于 $0.87853 < {α_{GW}}$。我们的实例也是 MAX BISECTION 的基本 SDP 松弛的完整性差距。
> **Abstract**: The MAX BISECTION problem seeks a maximum-size cut that evenly divides the vertices of a given undirected graph. An open problem raised by Austrin, Benabbas, and Georgiou is whether MAX BISECTION can be approximated as well as MAX CUT, i.e., to within ${α_{GW}}\approx 0.8785672\ldots$, which is the approximation ratio achieved by the celebrated Goemans-Williamson algorithm for MAX CUT, which is best possible assuming the Unique Games Conjecture (UGC). They conjectured that the answer is yes. The current paradigm for obtaining approximation algorithms for MAX BISECTION, due to Raghavendra and Tan and Austrin, Benabbas, and Georgiou, follows a two-phase approach. First, a large number of rounds of the Sum-of-Squares (SoS) hierarchy is used to find a solution to the ``Basic SDP'' relaxation of MAX CUT which is $\varepsilon$-uncorrelated, for an arbitrarily small $\varepsilon > 0$. Second, standard SDP rounding techniques (such as ${\cal THRESH}$) are used to round this $\varepsilon$-uncorrelated solution, producing with high probability a cut that is almost balanced, i.e., a cut that has at most $\frac12+\varepsilon$ fraction of the vertices on each side. This cut is then converted into an exact bisection of the graph with only a small loss. In this paper, we show that this two-stage paradigm cannot be used to obtain an $α_{GW}$-approximation algorithm for MAX BISECTION if one relies only on the $\varepsilon$-uncorrelatedness property of the solution produced by the first phase. More precisely, for any $\varepsilon > 0$, we construct an explicit instance of MAX BISECTION for which the ratio between the value of the optimal integral solution and the value of some $\varepsilon$-uncorrelated solution of the Basic SDP relaxation is less than $0.87853 < {α_{GW}}$. Our instances are also integrality gaps for the Basic SDP relaxation of MAX BISECTION.

【2】Hardware-aware Neural Architecture Search of Early Exiting Networks on Edge Accelerators
- **标题**: 边缘加速器上早期现有网络的硬件感知神经架构搜索
- **链接**: https://arxiv.org/abs/2512.04705
> **作者**: Alaa Zniber,Arne Symons,Ouassim Karrakchou,Marian Verhelst,Mounir Ghogho
> **摘要**: 高性能计算和云技术的进步促进了日益复杂的深度学习 (DL) 模型的开发。然而，边缘嵌入式智能的需求不断增长，带来了严格的计算和能源限制，对这些大规模模型的部署提出了挑战。早期退出神经网络（EENN）已成为一种有前途的解决方案，允许根据输入复杂性动态终止推理以提高效率。尽管其潜力巨大，但 EENN 的性能很大程度上受到边缘加速器的异构性和量化所施加的限制的影响，从而影响准确性、能源效率和延迟。然而，针对边缘硬件的 EENN 设计自动优化的研究仍然有限。为了弥补这一差距，我们提出了一种硬件感知的神经架构搜索（NAS）框架，该框架系统地集成了量化和硬件资源分配的效果，以优化网络主干内早期出口点的放置。 CIFAR-10 数据集上的实验结果表明，我们的 NAS 框架可以发现与传统静态网络相比，计算成本降低 50% 以上的架构，使其更适合在资源受限的边缘环境中部署。
> **Abstract**: Advancements in high-performance computing and cloud technologies have enabled the development of increasingly sophisticated Deep Learning (DL) models. However, the growing demand for embedded intelligence at the edge imposes stringent computational and energy constraints, challenging the deployment of these large-scale models. Early Exiting Neural Networks (EENN) have emerged as a promising solution, allowing dynamic termination of inference based on input complexity to enhance efficiency. Despite their potential, EENN performance is highly influenced by the heterogeneity of edge accelerators and the constraints imposed by quantization, affecting accuracy, energy efficiency, and latency. Yet, research on the automatic optimization of EENN design for edge hardware remains limited. To bridge this gap, we propose a hardware-aware Neural Architecture Search (NAS) framework that systematically integrates the effects of quantization and hardware resource allocation to optimize the placement of early exit points within a network backbone. Experimental results on the CIFAR-10 dataset demonstrate that our NAS framework can discover architectures that achieve over a 50\% reduction in computational costs compared to conventional static networks, making them more suitable for deployment in resource-constrained edge environments.

## 计算语言学(cs.CL:Computation and Language)

【1】Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning
- **标题**: 语义软引导：法学硕士中无需强化学习的长上下文推理
- **链接**: https://arxiv.org/abs/2512.05105
> **作者**: Purbesh Mitra,Sennur Ulukus
> **摘要**: 大语言模型 (LLM) 中的长上下文推理已证明通过思想链 (CoT) 推理可以增强其认知能力。训练此类模型通常是通过强化学习和可验证奖励（RLVR）来完成基于推理的问题，例如数学和编程。然而，RLVR 受到一些瓶颈的限制，例如缺乏密集的奖励、样本效率不足等。因此，在训练后阶段需要大量的计算资源。为了克服这些限制，在这项工作中，我们提出了 \textbf{语义软引导（SSB）}，一种自蒸馏技术，其中相同的基础语言模型扮演教师和学生的角色，但在训练时接收关于其结果正确性的不同语义上下文。首先用数学问题提示该模型，然后生成多个卷展栏。从它们中，过滤出正确和最常见的错误响应，然后将其提供给上下文中的模型，以生成更可靠的分步解释以及经过验证的最终答案。该管道会根据原始问题答案数据自动生成配对的师生训练集，无需任何人工干预。这个生成过程还会产生一系列 logits，这是学生模型在训练阶段仅从简单问题中尝试匹配的内容。在我们的实验中，Qwen2.5-3B-Instruct 通过参数高效的微调在 GSM8K 数据集上进行。然后我们在 MATH500 和 AIME2024 基准测试中测试了其准确性。我们的实验表明，与常用的 RLVR 算法——组相对策略优化 (GRPO) 相比，准确率分别提高了 10.6% 和 10%。我们的代码可在 https://github.com/purbeshmitra/semantic-soft-bootstrapping 获取，模型、精选数据集可在 https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping 获取。
> **Abstract**: Long context reasoning in large language models (LLMs) has demonstrated enhancement of their cognitive capabilities via chain-of-thought (CoT) inference. Training such models is usually done via reinforcement learning with verifiable rewards (RLVR) in reasoning based problems, like math and programming. However, RLVR is limited by several bottlenecks, such as, lack of dense reward, and inadequate sample efficiency. As a result, it requires significant compute resources in post-training phase. To overcome these limitations, in this work, we propose \textbf{Semantic Soft Bootstrapping (SSB)}, a self-distillation technique, in which the same base language model plays the role of both teacher and student, but receives different semantic contexts about the correctness of its outcome at training time. The model is first prompted with a math problem and several rollouts are generated. From them, the correct and most common incorrect response are filtered, and then provided to the model in context to produce a more robust, step-by-step explanation with a verified final answer. This pipeline automatically curates a paired teacher-student training set from raw problem-answer data, without any human intervention. This generation process also produces a sequence of logits, which is what the student model tries to match in the training phase just from the bare question alone. In our experiment, Qwen2.5-3B-Instruct on GSM8K dataset via parameter-efficient fine-tuning. We then tested its accuracy on MATH500, and AIME2024 benchmarks. Our experiments show a jump of 10.6%, and 10% improvements in accuracy, respectively, over group relative policy optimization (GRPO), which is a commonly used RLVR algorithm. Our code is available at https://github.com/purbeshmitra/semantic-soft-bootstrapping, and the model, curated dataset is available at https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping.

【2】Structured Document Translation via Format Reinforcement Learning
- **标题**: 通过格式强化学习进行结构化文档翻译
- **链接**: https://arxiv.org/abs/2512.05100
> **作者**: Haiyue Song,Johannes Eschbach-Dymanus,Hour Kaing,Sumire Honda,Hideki Tanaka,Bianka Buschbeck,Masao Utiyama
> **摘要**: 最近关于结构化文本翻译的工作仍然局限于句子级别，因为它们很难有效地处理复杂的文档级 XML 或 HTML 结构。为了解决这个问题，我们提出 \textbf{格式强化学习 (FormatRL)}，它在监督微调模型之上采用组相对策略优化来直接优化新颖的结构感知奖励：1) TreeSim，它测量预测和参考 XML 树之间的结构相似性；2) Node-chrF，它测量 XML 节点级别的翻译质量。此外，我们还应用了 StrucAUC，这是一种区分轻微错误和主要结构故障的细粒度指标。 SAP 软件文档基准测试证明了六个指标的改进，分析进一步显示了不同的奖励功能如何有助于结构和翻译质量的改进。
> **Abstract**: Recent works on structured text translation remain limited to the sentence level, as they struggle to effectively handle the complex document-level XML or HTML structures. To address this, we propose \textbf{Format Reinforcement Learning (FormatRL)}, which employs Group Relative Policy Optimization on top of a supervised fine-tuning model to directly optimize novel structure-aware rewards: 1) TreeSim, which measures structural similarity between predicted and reference XML trees and 2) Node-chrF, which measures translation quality at the level of XML nodes. Additionally, we apply StrucAUC, a fine-grained metric distinguishing between minor errors and major structural failures. Experiments on the SAP software-documentation benchmark demonstrate improvements across six metrics and an analysis further shows how different reward functions contribute to improvements in both structural and translation quality.

【3】Arbitrage: Efficient Reasoning via Advantage-Aware Speculation
- **标题**: 套利：通过优势感知投机进行有效推理
- **链接**: https://arxiv.org/abs/2512.05033
> **作者**: Monishwaran Maheswaran,Rishabh Tiwari,Yuezhou Hu,Kerem Dilmen,Coleman Hooper,Haocheng Xi,Nicholas Lee,Mehrdad Farajtabar,Michael W. Mahoney,Kurt Keutzer,Amir Gholami
> **摘要**: 现代大型语言模型通过长思想链实现了令人印象深刻的推理能力，但在推理过程中会产生大量的计算成本，这激励了技术提高性能成本比。在这些技术中，推测解码通过采用快速但不准确的草稿模型来自回归地提出令牌，然后由功能更强大的目标模型并行验证令牌，从而加速推理。然而，由于语义等效步骤中令牌不匹配导致不必要的拒绝，传统令牌级推测解码在推理任务中陷入困境。尽管最近的工作已经转向步骤级语义验证，通过接受或拒绝整个推理步骤来提高效率，但现有的步骤级方法仍然重新生成许多被拒绝的步骤，几乎没有改进，浪费了宝贵的目标计算。为了应对这一挑战，我们提出了套利，这是一种新颖的阶梯级投机生成框架，可根据草稿模型和目标模型之间的相对优势动态地路由生成。套利没有应用固定的接受阈值，而是使用经过训练的轻量级路由器来预测目标模型何时可能产生有意义的更好步骤。这种路由近似于理想的套利预言机，它始终选择更高质量的步骤，实现接近最优的效率与准确性权衡。在多个数学推理基准中，Arbitrage 始终超越先前的步骤级推测解码基线，在匹配的精度下将推理延迟减少高达 $\sim2\times$。
> **Abstract**: Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to autoregressively propose tokens, which are then verified in parallel by a more capable target model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token-level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose Arbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, Arbitrage uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal Arbitrage Oracle that always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks, Arbitrage consistently surpasses prior step-level Speculative Decoding baselines, reducing inference latency by up to $\sim2\times$ at matched accuracy.

【4】LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics
- **标题**: 法学硕士知道的不仅仅是单词：语法、隐喻和语音学的体裁研究
- **链接**: https://arxiv.org/abs/2512.04957
> **作者**: Weiye Shi,Zhaowei Zhang,Shaoheng Yan,Yaodong Yang
> **摘要**: 大型语言模型 (LLM) 在各种语言相关任务中表现出巨大的潜力，但它们是否能够捕获更深层次的语言属性，例如来自原始文本的句法结构、语音提示和韵律模式，目前尚不清楚。为了分析法学硕士是否可以有效地学习这些特征并将其应用于重要的自然语言相关任务，我们引入了一个源自古腾堡计划的新颖的多语言流派分类数据集，古腾堡计划是一个大型数字图书馆，提供对数千部公共领域文学作品的免费访问，每个二进制任务包含数千个句子（诗歌与小说；戏剧与诗歌；戏剧与小说），有六种语言（英语、法语、德语、意大利语、西班牙语和葡萄牙语）。我们用三个显式语言特征集（句法树结构、隐喻计数和语音度量）来增强每个特征集，以评估它们对分类性能的影响。实验表明，尽管 LLM 分类器可以从原始文本或显式提供的特征中学习潜在的语言结构，但不同的特征在任务中的贡献并不均匀，这强调了在模型训练期间纳入更复杂的语言信号的重要性。
> **Abstract**: Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.

【5】SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs
- **标题**: SEAL：通过知识图进行对话问答的自我进化代理学习
- **链接**: https://arxiv.org/abs/2512.04868
> **作者**: Hao Wang,Jialun Zhong,Changcheng Wang,Zhujun Nie,Zheng Li,Shunyu Yao,Yanzeng Li,Xinchi Li
> **摘要**: 基于知识的会话问答（KBCQA）在解决共指、建模上下文依赖性和执行复杂的逻辑推理方面面临着持续的挑战。现有的方法，无论是端到端语义解析还是基于代理的逐步推理，通常都会遇到结构不准确和计算成本过高的问题，特别是在处理大型知识图谱上的复杂查询时。为了解决这些限制，我们引入了 SEAL，这是一种基于自我进化代理学习的新颖的两阶段语义解析框架。在第一阶段，大型语言模型 (LLM) 提取最小的 S 表达式核心，以捕获输入查询的基本语义。然后通过代理校准模块对该核心进行细化，该模块纠正语法不一致并将实体和关系与底层知识图精确对齐。第二阶段采用基于模板的补全，以问题类型预测和占位符实例化为指导，构建完全可执行的 S 表达式。这种分解不仅简化了逻辑形式的生成，而且显着提高了结构保真度和链接效率。至关重要的是，SEAL 结合了一种自我进化机制，将本地和全局内存与反射模块集成在一起，从而能够根据对话历史和执行反馈进行持续适应，而无需明确的重新训练。 SPICE 基准测试的大量实验表明，SEAL 实现了最先进的性能，特别是在多跳推理、比较和聚合任务中。结果验证了结构准确性和计算效率的显着提升，强调了该框架稳健且可扩展的对话推理的能力。
> **Abstract**: Knowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from structural inaccuracies and prohibitive computational costs, particularly when processing intricate queries over large knowledge graphs. To address these limitations, we introduce SEAL, a novel two-stage semantic parsing framework grounded in self-evolving agentic learning. In the first stage, a large language model (LLM) extracts a minimal S-expression core that captures the essential semantics of the input query. This core is then refined by an agentic calibration module, which corrects syntactic inconsistencies and aligns entities and relations precisely with the underlying knowledge graph. The second stage employs template-based completion, guided by question-type prediction and placeholder instantiation, to construct a fully executable S-expression. This decomposition not only simplifies logical form generation but also significantly enhances structural fidelity and linking efficiency. Crucially, SEAL incorporates a self-evolving mechanism that integrates local and global memory with a reflection module, enabling continuous adaptation from dialog history and execution feedback without explicit retraining. Extensive experiments on the SPICE benchmark demonstrate that SEAL achieves state-of-the-art performance, especially in multi-hop reasoning, comparison, and aggregation tasks. The results validate notable gains in both structural accuracy and computational efficiency, underscoring the framework's capacity for robust and scalable conversational reasoning.

【6】Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates
- **标题**: 通过源屏蔽更新减轻法学硕士目标语言适应中的灾难性遗忘
- **链接**: https://arxiv.org/abs/2512.04844
> **作者**: Atsuki Yamaguchi,Terufumi Morishita,Aline Villavicencio,Nikolaos Aletras
> **摘要**: 扩大指导大语言模型（LLM）的语言多样性对于全球可访问性至关重要，但往往因依赖昂贵的专业目标语言标记数据和适应过程中的灾难性遗忘而受到阻碍。我们在现实的、低资源的约束下应对这一挑战：仅使用未标记的目标语言数据来调整指导法学硕士。我们引入了源屏蔽更新（SSU），这是一种主动保留源知识的选择性参数更新策略。 SSU 使用一小组源数据和参数重要性评分方法来识别对于维持源能力至关重要的参数。然后，它应用逐列冻结策略来在适应之前保护这些参数。跨五种类型不同的语言以及 7B 和 13B 模型的实验表明，SSU 成功地减轻了灾难性遗忘。它将单语言源任务的性能下降平均降低至 3.4% (7B) 和 2.8% (13B)，与完全微调的 20.3% 和 22.3% 形成鲜明对比。 SSU 还通过全面微调实现了极具竞争力的目标语言性能，在 7B 模型的所有基准测试和大多数 13B 模型的基准测试中均优于它。
> **Abstract**: Expanding the linguistic diversity of instruct large language models (LLMs) is crucial for global accessibility but is often hindered by the reliance on costly specialized target language labeled data and catastrophic forgetting during adaptation. We tackle this challenge under a realistic, low-resource constraint: adapting instruct LLMs using only unlabeled target language data. We introduce Source-Shielded Updates (SSU), a selective parameter update strategy that proactively preserves source knowledge. Using a small set of source data and a parameter importance scoring method, SSU identifies parameters critical to maintaining source abilities. It then applies a column-wise freezing strategy to protect these parameters before adaptation. Experiments across five typologically diverse languages and 7B and 13B models demonstrate that SSU successfully mitigates catastrophic forgetting. It reduces performance degradation on monolingual source tasks to just 3.4% (7B) and 2.8% (13B) on average, a stark contrast to the 20.3% and 22.3% from full fine-tuning. SSU also achieves target-language performance highly competitive with full fine-tuning, outperforming it on all benchmarks for 7B models and the majority for 13B models.

【7】SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs
- **标题**: SignRoundV2：缩小法学硕士极低位训练后量化的性能差距
- **链接**: https://arxiv.org/abs/2512.04746
> **作者**: Wenhua Cheng,Weiwei Zhang,Heng Guo,Haihao Shen
> **摘要**: 极低位量化对于有效部署大型语言模型 (LLM) 至关重要，但它通常会导致 2 位甚至 4 位（例如 MXFP4）的性能严重下降。我们提出了 SignRoundV2，这是一种训练后量化框架，即使没有混合精度也非常有效。 SignRoundV2 引入了 (1) 一种快速灵敏度度量，它将梯度信息与量化引起的偏差相结合，以指导逐层比特分配；(2) 量化尺度的轻量级预调整搜索，以改进极低比特量化。这些组件使 SignRoundV2 能够缩小与全精度模型的差距。大量实验表明，我们的方法对于法学硕士来说保持了有竞争力的准确性，实现了生产级性能，在 4-5 位时方差约为 1%，即使在 2 位时也能获得很好的结果。该实现可从 https://github.com/intel/auto-round 获取。
> **Abstract**: Extreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-precision. SignRoundV2 introduces (1) a fast sensitivity metric that combines gradient information with quantization-induced deviations to guide layer-wise bit allocation, and (2) a lightweight pre-tuning search for quantization scales to improve extremely low-bit quantization. These components allow SignRoundV2 to close the gap with full-precision models. Extensive experiments indicate that our method sustains competitive accuracy for LLMs, achieving production-grade performance with about 1 percent variance at 4-5 bits and strong results even at 2 bits. The implementation is available at https://github.com/intel/auto-round.

【8】OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models
- **标题**: OsmT：通过开源标签感知语言模型桥接 OpenStreetMap 查询和自然语言
- **链接**: https://arxiv.org/abs/2512.04738
> **作者**: Zhuoyue Wan,Wentao Hu,Chen Jason Zhang,Yuanfeng Song,Shuaimin Li,Ruiqiang Xiao,Xiao-Yong Wei,Raymond Chi-Wing Wong
> **摘要**: 连接自然语言和结构化查询语言是数据库社区中长期存在的挑战。虽然语言模型的最新进展在这个方向上显示出了希望，但现有的解决方案通常依赖于大规模闭源模型，这些模型存在推理成本高、透明度有限以及缺乏轻量级部署适应性的问题。在本文中，我们提出了 OsmT，这是一种开源标签感知语言模型，专门用于桥接自然语言和 Overpass 查询语言 (OverpassQL)，这是一种用于访问大规模 OpenStreetMap (OSM) 数据的结构化查询语言。为了提高生成查询的准确性和结构有效性，我们引入了标签检索增强（TRA）机制，该机制将上下文相关的标签知识合并到生成过程中。该机制旨在捕获 OSM 数据库中存在的层次结构和关系依赖关系，解决地理空间查询制定中固有的拓扑复杂性。此外，我们定义了一个反向任务 OverpassQL-to-Text，它将结构化查询转换为自然语言解释，以支持查询解释并提高用户可访问性。我们根据强大的基线在公共基准上评估 OsmT，并观察到查询生成和解释方面的持续改进。尽管使用的参数明显减少，但我们的模型实现了有竞争力的准确性，证明了开源预训练语言模型在模式丰富的地理空间环境中桥接自然语言和结构化查询语言方面的有效性。
> **Abstract**: Bridging natural language and structured query languages is a long-standing challenge in the database community. While recent advances in language models have shown promise in this direction, existing solutions often rely on large-scale closed-source models that suffer from high inference costs, limited transparency, and lack of adaptability for lightweight deployment. In this paper, we present OsmT, an open-source tag-aware language model specifically designed to bridge natural language and Overpass Query Language (OverpassQL), a structured query language for accessing large-scale OpenStreetMap (OSM) data. To enhance the accuracy and structural validity of generated queries, we introduce a Tag Retrieval Augmentation (TRA) mechanism that incorporates contextually relevant tag knowledge into the generation process. This mechanism is designed to capture the hierarchical and relational dependencies present in the OSM database, addressing the topological complexity inherent in geospatial query formulation. In addition, we define a reverse task, OverpassQL-to-Text, which translates structured queries into natural language explanations to support query interpretation and improve user accessibility. We evaluate OsmT on a public benchmark against strong baselines and observe consistent improvements in both query generation and interpretation. Despite using significantly fewer parameters, our model achieves competitive accuracy, demonstrating the effectiveness of open-source pre-trained language models in bridging natural language and structured query languages within schema-rich geospatial environments.

【9】AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees
- **标题**: AdmTree：使用自适应语义树压缩冗长的上下文
- **链接**: https://arxiv.org/abs/2512.04550
> **作者**: Yangning Li,Shaoshen Chen,Yinghui Li,Yankai Chen,Hai-Tao Zheng,Hui Wang,Wenhao Jiang,Philip S. Yu
> **摘要**: 自注意力的二次复杂性限制了大型语言模型（LLM）处理长上下文的能力，而这对于许多高级应用程序来说是必不可少的能力。上下文压缩旨在缓解这种计算瓶颈，同时保留关键语义信息。然而，现有的方法往往存在不足：显式方法可能会损害局部细节，而隐式方法可能会遭受位置偏差、信息退化或无法捕获远程语义依赖性的问题。我们提出了 AdmTree，这是一种用于自适应、分层上下文压缩的新颖框架，其核心重点是在保持效率的同时保持高语义保真度。 AdmTree 根据信息密度动态分段输入，利用 gist token 将可变长度分段总结为语义二叉树的叶子。这种结构与轻量级聚合机制和冻结骨干 LLM（从而最大限度地减少新的可训练参数）一起，实现了上下文的高效分层抽象。通过保留细粒度细节以及全局语义一致性、减轻位置偏差并动态适应内容，AdmTree 稳健地保留了长上下文的语义信息。
> **Abstract**: The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing approaches often fall short: explicit methods may compromise local detail, whereas implicit methods can suffer from positional biases, information degradation, or an inability to capture long-range semantic dependencies. We propose AdmTree, a novel framework for adaptive, hierarchical context compression with a central focus on preserving high semantic fidelity while maintaining efficiency. AdmTree dynamically segments input based on information density, utilizing gist tokens to summarize variable-length segments as the leaves of a semantic binary tree. This structure, together with a lightweight aggregation mechanism and a frozen backbone LLM (thereby minimizing new trainable parameters), enables efficient hierarchical abstraction of the context. By preserving fine-grained details alongside global semantic coherence, mitigating positional bias, and dynamically adapting to content, AdmTree robustly retains the semantic information of long contexts.

【10】UW-BioNLP at ChemoTimelines 2025: Thinking, Fine-Tuning, and Dictionary-Enhanced LLM Systems for Chemotherapy Timeline Extraction
- **标题**: UW-BioNLP at ChemoTimelines 2025：用于化疗时间线提取的思考、微调和字典增强的法学硕士系统
- **链接**: https://arxiv.org/abs/2512.04518
> **作者**: Tianmai M. Zhang,Zhaoyi Sun,Sihang Zeng,Chenxi Li,Neil F. Abernethy,Barbara D. Lam,Fei Xia,Meliha Yetisgen
> **摘要**: ChemoTimelines 共享了根据癌症患者的电子健康记录构建全身抗癌治疗时间表的任务基准方法。本文描述了我们的子任务 2 的方法、结果和发现——根据原始临床记录生成患者化疗时间表。我们评估了涉及思想链思维、监督微调、直接偏好优化和基于字典的查找的策略，以改进时间线提取。我们所有的方法都遵循两步工作流程，其中法学硕士首先从个人临床记录中提取化疗事件，然后算法将事件标准化并汇总到患者级别的时间线中。每种具体方法的不同之处在于如何利用和培训相关的法学硕士。多种方法在测试集排行榜上取得了具有竞争力的表现，经过微调的 Qwen3-14B 取得了 0.678 的最佳官方分数。我们的结果和分析可以为未来对该任务的尝试以及类似任务的设计提供有用的见解。
> **Abstract**: The ChemoTimelines shared task benchmarks methods for constructing timelines of systemic anticancer treatment from electronic health records of cancer patients. This paper describes our methods, results, and findings for subtask 2 -- generating patient chemotherapy timelines from raw clinical notes. We evaluated strategies involving chain-of-thought thinking, supervised fine-tuning, direct preference optimization, and dictionary-based lookup to improve timeline extraction. All of our approaches followed a two-step workflow, wherein an LLM first extracted chemotherapy events from individual clinical notes, and then an algorithm normalized and aggregated events into patient-level timelines. Each specific method differed in how the associated LLM was utilized and trained. Multiple approaches yielded competitive performances on the test set leaderboard, with fine-tuned Qwen3-14B achieving the best official score of 0.678. Our results and analyses could provide useful insights for future attempts on this task as well as the design of similar tasks.

## 密码学和安全(cs.CR:Cryptography and Security)

【1】SoK: a Comprehensive Causality Analysis Framework for Large Language Model Security
- **标题**: SoK：大型语言模型安全的综合因果分析框架
- **链接**: https://arxiv.org/abs/2512.04841
> **作者**: Wei Zhao,Zhe Li,Jun Sun
> **摘要**: 大型语言模型 (LLM) 展现出卓越的功能，但仍然容易受到越狱等对抗性操纵的影响，其中精心设计的提示会绕过安全机制。了解此类漏洞背后的原因对于构建可靠的防御至关重要。在这项工作中，我们引入了一个统一的因果分析框架，该框架系统地支持法学硕士中各个级别的因果调查，从令牌级别、神经元级别和层级别干预到表示级别分析。该框架能够在不同的基于因果关系的攻击和防御方法之间进行一致的实验和比较。伴随着这一实施，我们首次对因果驱动的越狱研究进行了全面调查，并在多个开放权重模型和安全关键基准（包括越狱、幻觉检测、后门识别和公平性评估）上对框架进行了实证评估。我们的结果表明：（1）对因果关键组件进行有针对性的干预可以可靠地改变安全行为； (2) 安全相关机制高度局部化（即集中在早中层，只有 1--2\% 的神经元表现出因果影响）； (3) 从我们的框架中提取的因果特征在多种威胁类型中实现了超过 95% 的检测准确度。通过桥接理论因果关系分析和实际模型安全性，我们的框架为法学硕士中基于因果关系的攻击、可解释性以及鲁棒攻击检测和缓解的研究奠定了可重复的基础。代码可在 https://github.com/Amadeuszhao/SOK_Casuality 获取。
> **Abstract**: Large Language Models (LLMs) exhibit remarkable capabilities but remain vulnerable to adversarial manipulations such as jailbreaking, where crafted prompts bypass safety mechanisms. Understanding the causal factors behind such vulnerabilities is essential for building reliable defenses. In this work, we introduce a unified causality analysis framework that systematically supports all levels of causal investigation in LLMs, ranging from token-level, neuron-level, and layer-level interventions to representation-level analysis. The framework enables consistent experimentation and comparison across diverse causality-based attack and defense methods. Accompanying this implementation, we provide the first comprehensive survey of causality-driven jailbreak studies and empirically evaluate the framework on multiple open-weight models and safety-critical benchmarks including jailbreaks, hallucination detection, backdoor identification, and fairness evaluation. Our results reveal that: (1) targeted interventions on causally critical components can reliably modify safety behavior; (2) safety-related mechanisms are highly localized (i.e., concentrated in early-to-middle layers with only 1--2\% of neurons exhibiting causal influence); and (3) causal features extracted from our framework achieve over 95\% detection accuracy across multiple threat types. By bridging theoretical causality analysis and practical model safety, our framework establishes a reproducible foundation for research on causality-based attacks, interpretability, and robust attack detection and mitigation in LLMs. Code is available at https://github.com/Amadeuszhao/SOK_Casuality.

【2】Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs
- **标题**: 拓扑很重要：测量多代理 LLM 中的内存泄漏
- **链接**: https://arxiv.org/abs/2512.04668
> **作者**: Jinbo Liu,Defu Cao,Yifei Wei,Tianyao Su,Yuan Liang,Yushun Dong,Yue Zhao,Xiyang Hu
> **摘要**: 图拓扑是多代理 LLM 系统中内存泄漏的基本决定因素，但其影响仍然难以量化。我们介绍 MAMA（多代理内存攻击），这是一个衡量网络结构如何影响泄漏的框架。 MAMA 对包含标记的个人身份信息 (PII) 实体的合成文档进行操作，我们从中生成经过净化的任务指令。我们执行一个两阶段协议：印迹（将私人信息植入目标代理的内存中）和共振（攻击者尝试提取的多轮交互）。在多达 10 轮交互中，我们将泄漏量化为通过精确匹配从攻击代理输出中恢复的真实 PII 的比例。我们系统地评估了六种常见的网络拓扑（全连接、环、链、二叉树、星形和星环）、不同的代理计数 $n\in\{4,5,6\}$、攻击者目标位置和基本模型。我们的研究结果揭示了一致的模式：完全连接的图表现出最大的泄漏，而链提供最强的保护；较短的攻击者-目标图距离和较高的目标中心性显着增加脆弱性；泄漏在前几轮中急剧上升，然后趋于稳定；模型选择改变了绝对泄漏率，但保留了拓扑排名；时间/位置 PII 属性比身份凭证或受监管的标识符更容易泄露。这些结果提供了从架构选择到可测量隐私风险的第一个系统映射，从而产生了可操作的指导：更喜欢稀疏或分层连接，最大化攻击者与目标的分离，限制节点度和网络半径，避免绕过集线器的快捷方式，并实施拓扑感知的访问控制。
> **Abstract**: Graph topology is a fundamental determinant of memory leakage in multi-agent LLM systems, yet its effects remain poorly quantified. We introduce MAMA (Multi-Agent Memory Attack), a framework that measures how network structure shapes leakage. MAMA operates on synthetic documents containing labeled Personally Identifiable Information (PII) entities, from which we generate sanitized task instructions. We execute a two-phase protocol: Engram (seeding private information into a target agent's memory) and Resonance (multi-round interaction where an attacker attempts extraction). Over up to 10 interaction rounds, we quantify leakage as the fraction of ground-truth PII recovered from attacking agent outputs via exact matching. We systematically evaluate six common network topologies (fully connected, ring, chain, binary tree, star, and star-ring), varying agent counts $n\in\{4,5,6\}$, attacker-target placements, and base models. Our findings reveal consistent patterns: fully connected graphs exhibit maximum leakage while chains provide strongest protection; shorter attacker-target graph distance and higher target centrality significantly increase vulnerability; leakage rises sharply in early rounds before plateauing; model choice shifts absolute leakage rates but preserves topology rankings; temporal/locational PII attributes leak more readily than identity credentials or regulated identifiers. These results provide the first systematic mapping from architectural choices to measurable privacy risk, yielding actionable guidance: prefer sparse or hierarchical connectivity, maximize attacker-target separation, limit node degree and network radius, avoid shortcuts bypassing hubs, and implement topology-aware access controls.

【3】A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution
- **标题**: 用于高度安全模型分发的轻量级大语言模型文件格式
- **链接**: https://arxiv.org/abs/2512.04580
> **作者**: Huifeng Zhu,Shijie Li,Qinfeng Li,Yier Jin
> **摘要**: 为了提高大型语言模型 (LLM) 在各种特定领域应用中的性能，医疗保健、法律和金融等敏感数据被用来私下定制或微调这些模型。这种私人改编的法学硕士被视为个人隐私资产或公司知识产权。因此，在部署和分发过程中保护模型权重并保持严格的机密性变得至关重要。然而，现有的模型格式和部署框架对机密性、访问控制或与可信硬件的安全集成几乎没有提供内置支持。当前用于保护模型部署的方法要么依赖于计算成本昂贵的加密技术，要么依赖于严格控制的私有基础设施。尽管这些方法在特定场景下可能有效，但广泛部署却很困难且成本高昂。在本文中，我们介绍了 CryptoTensors，这是一种用于机密 LLM 分发的安全且格式兼容的文件结构。 CryptoTensors 作为广泛采用的 Safetensors 格式的扩展而构建，它结合了张量级加密和嵌入式访问控制策略，同时保留了延迟加载和部分反序列化等关键功能。它支持透明解密和自动化密钥管理，以最小的开销支持灵活的许可和安全模型执行。我们实现了一个概念验证库，在序列化和运行时场景中对其性能进行基准测试，并验证其与现有推理框架（包括 Hugging Face Transformers 和 vLLM）的兼容性。我们的结果强调 CryptoTensors 是一种轻量级、高效且对开发人员友好的解决方案，可在现实世界和广泛部署中保护 LLM 权重。
> **Abstract**: To enhance the performance of large language models (LLMs) in various domain-specific applications, sensitive data such as healthcare, law, and finance are being used to privately customize or fine-tune these models. Such privately adapted LLMs are regarded as either personal privacy assets or corporate intellectual property. Therefore, protecting model weights and maintaining strict confidentiality during deployment and distribution have become critically important. However, existing model formats and deployment frameworks provide little to no built-in support for confidentiality, access control, or secure integration with trusted hardware. Current methods for securing model deployment either rely on computationally expensive cryptographic techniques or tightly controlled private infrastructure. Although these approaches can be effective in specific scenarios, they are difficult and costly for widespread deployment. In this paper, we introduce CryptoTensors, a secure and format-compatible file structure for confidential LLM distribution. Built as an extension to the widely adopted Safetensors format, CryptoTensors incorporates tensor-level encryption and embedded access control policies, while preserving critical features such as lazy loading and partial deserialization. It enables transparent decryption and automated key management, supporting flexible licensing and secure model execution with minimal overhead. We implement a proof-of-concept library, benchmark its performance across serialization and runtime scenarios, and validate its compatibility with existing inference frameworks, including Hugging Face Transformers and vLLM. Our results highlight CryptoTensors as a light-weight, efficient, and developer-friendly solution for safeguarding LLM weights in real-world and widespread deployments.

## 计算机视觉和模式识别(cs.CV:Computer Vision and Pattern Recognition)

【1】Light-X: Generative 4D Video Rendering with Camera and Illumination Control
- **标题**: Light-X：使用摄像头和照明控制进行生成 4D 视频渲染
- **链接**: https://arxiv.org/abs/2512.05115
> **作者**: Tianqi Liu,Zhaoxi Chen,Zihao Huang,Shaocong Xu,Saining Zhang,Chongjie Ye,Bohan Li,Zhiguo Cao,Wei Li,Hao Zhao,Ziwei Liu
> **摘要**: 照明控制的最新进展将基于图像的方法扩展到视频，但仍然面临照明保真度和时间一致性之间的权衡。除了重新照明之外，现实世界场景生成建模的关键一步是相机轨迹和照明的联合控制，因为视觉动态本质上是由几何和照明共同塑造的。为此，我们推出了 Light-X，这是一种视频生成框架，可以通过视点和照明控制实现单目视频的可控渲染。 1）我们提出了一种解耦几何体和照明信号的解耦设计：几何体和运动是通过沿着用户定义的相机轨迹投影的动态点云捕获的，而照明线索是由一致投影到相同几何体的重照明框架提供的。这些明确的、细粒度的线索能够有效地解开并引导高质量的照明。 2）为了解决缺乏配对多视图和多照明视频的问题，我们引入了 Light-Syn，这是一种基于退化的管道，具有逆映射功能，可以从野外单目镜头中合成训练对。该策略产生一个涵盖静态、动态和人工智能生成场景的数据集，确保稳健的训练。大量实验表明，Light-X 在联合摄像机照明控制方面优于基线方法，并且在文本和背景条件设置下均优于先前的视频重新照明方法。
> **Abstract**: Recent advances in illumination control extend image-based methods to video, yet still facing a trade-off between lighting fidelity and temporal consistency. Moving beyond relighting, a key step toward generative modeling of real-world scenes is the joint control of camera trajectory and illumination, since visual dynamics are inherently shaped by both geometry and lighting. To this end, we present Light-X, a video generation framework that enables controllable rendering from monocular videos with both viewpoint and illumination control. 1) We propose a disentangled design that decouples geometry and lighting signals: geometry and motion are captured via dynamic point clouds projected along user-defined camera trajectories, while illumination cues are provided by a relit frame consistently projected into the same geometry. These explicit, fine-grained cues enable effective disentanglement and guide high-quality illumination. 2) To address the lack of paired multi-view and multi-illumination videos, we introduce Light-Syn, a degradation-based pipeline with inverse-mapping that synthesizes training pairs from in-the-wild monocular footage. This strategy yields a dataset covering static, dynamic, and AI-generated scenes, ensuring robust training. Extensive experiments show that Light-X outperforms baseline methods in joint camera-illumination control and surpasses prior video relighting methods under both text- and background-conditioned settings.

【2】Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting
- **标题**: Splannequin：通过双检测泼溅冻结单眼人体模型挑战镜头
- **链接**: https://arxiv.org/abs/2512.05113
> **作者**: Hao-Jen Chien,Yi-Chuan Huang,Chung-Ho Wu,Wei-Lun Chao,Yu-Lun Liu
> **摘要**: 从单眼人体模型挑战 (MC) 视频合成高保真冻结 3D 场景是一个不同于标准动态场景重建的独特问题。我们的目标不是专注于建模运动，而是创建一个冻结的场景，同时策略性地保留微妙的动态，以实现用户控制的即时选择。为了实现这一目标，我们引入了动态高斯分布的新颖应用：动态建模场景，保留附近的时间变化，并通过固定模型的时间参数来渲染静态场景。然而，在这种用法下，具有稀疏时间监督的单目捕获会引入高斯模型的重影和模糊等伪影，这些伪影在弱监督时间戳下变得无法观察到或被遮挡。我们提出了 Splannequin，一种与架构无关的正则化，可以检测高斯原语的两种状态（隐藏状态和缺陷状态），并应用时间锚定。在主要向前相机运动的情况下，隐藏状态锚定到最近观察到的过去状态，而有缺陷的状态锚定到具有更强监督的未来状态。我们的方法通过简单的损失项集成到现有的动态高斯管道中，不需要架构更改，并且增加了零推理开销。这显着提高了视觉质量，实现了高保真度、用户可选择的冻结时间渲染，并得到了 96% 用户偏好的验证。项目页面：https://chien90190.github.io/splannequin/
> **Abstract**: Synthesizing high-fidelity frozen 3D scenes from monocular Mannequin-Challenge (MC) videos is a unique problem distinct from standard dynamic scene reconstruction. Instead of focusing on modeling motion, our goal is to create a frozen scene while strategically preserving subtle dynamics to enable user-controlled instant selection. To achieve this, we introduce a novel application of dynamic Gaussian splatting: the scene is modeled dynamically, which retains nearby temporal variation, and a static scene is rendered by fixing the model's time parameter. However, under this usage, monocular capture with sparse temporal supervision introduces artifacts like ghosting and blur for Gaussians that become unobserved or occluded at weakly supervised timestamps. We propose Splannequin, an architecture-agnostic regularization that detects two states of Gaussian primitives, hidden and defective, and applies temporal anchoring. Under predominantly forward camera motion, hidden states are anchored to their recent well-observed past states, while defective states are anchored to future states with stronger supervision. Our method integrates into existing dynamic Gaussian pipelines via simple loss terms, requires no architectural changes, and adds zero inference overhead. This results in markedly improved visual quality, enabling high-fidelity, user-selectable frozen-time renderings, validated by a 96% user preference. Project page: https://chien90190.github.io/splannequin/

【3】DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation
- **标题**: DraCo：草案作为文本到图像预览和稀有概念生成的 CoT
- **链接**: https://arxiv.org/abs/2512.05112
> **作者**: Dongzhi Jiang,Renrui Zhang,Haodong Li,Zhuofan Zong,Ziyu Guo,Jun He,Claire Guo,Junyan Ye,Rongyao Fang,Weijia Li,Rui Liu,Hongsheng Li
> **摘要**: 最近的统一多模态大语言模型 (MLLM) 显示了令人印象深刻的功能，结合了思想链 (CoT) 推理来增强文本到图像的生成。然而，现有的方法仍然有限，要么仅将模型视为独立的生成器，要么依赖于抽象的文本规划。为此，我们提出了 Draft-as-CoT (DraCo)，这是一种新颖的交错推理范式，充分利用 CoT 中的文本和视觉内容来更好地规划和验证。我们的方法首先生成一个低分辨率草稿图像作为预览，提供更具体和结构性的视觉规划和指导。然后，我们利用模型固有的理解能力来验证草稿和输入提示之间潜在的语义不一致，并通过超分辨率的选择性校正来进行细化。通过这种方式，我们的方法解决了两个基本挑战：文本规划的粗粒度性质和生成稀有属性组合的难度。为了支持培训，我们策划了 DraCo-240K，旨在增强涵盖一般校正、实例操作和布局重组的三种原子功能。在 DraCo-CFG（一种用于交错推理的专用无分类器引导 (CFG) 策略）的支持下，DraCo 在 GenEval (+8%)、Imagine-Bench (+0.91) 和 GenEval++ (+3%) 上实现了巨大的提升，显着优于直接生成和 CoT 授权的其他生成方法。
> **Abstract**: Recent unified multimodal large language models (MLLMs) have shown impressive capabilities, incorporating chain-of-thought (CoT) reasoning for enhanced text-to-image generation. However, existing approaches remain limited, either treating the model merely as a standalone generator or relying on abstract textual planning. To this end, we propose Draft-as-CoT (DraCo), a novel interleaved reasoning paradigm that fully leverages both textual and visual contents in CoT for better planning and verification. Our method first generates a low-resolution draft image as preview, providing more concrete and structural visual planning and guidance. Then, we employ the model's inherent understanding capability to verify potential semantic misalignments between the draft and input prompt, and performs refinement through selective corrections with super-resolution. In this way, our approach addresses two fundamental challenges: the coarse-grained nature of textual planning and the difficulty in generating rare attribute combinations. To support training, we curate DraCo-240K, aiming to enhance three atomic capabilities spanning general correction, instance manipulation, and layout reorganization. Supported by DraCo-CFG, a specialized classifier-free guidance (CFG) strategy for interleaved reasoning, DraCo achieves a tremendous increase on GenEval (+8%), Imagine-Bench (+0.91), and GenEval++ (+3%), significantly outperforming direct generation and other generation methods empowered by CoT.

【4】ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning
- **标题**: ARM-Thinker：通过代理工具使用和视觉推理强化多模式生成奖励模型
- **链接**: https://arxiv.org/abs/2512.05111
> **作者**: Shengyuan Ding,Xinyu Fang,Ziyu Liu,Yuhang Zang,Yuhang Cao,Xiangyu Zhao,Haodong Duan,Xiaoyi Dong,Jianze Liang,Bin Wang,Conghui He,Dahua Lin,Jiaqi Wang
> **摘要**: 奖励模型对于使视觉语言系统与人类偏好保持一致至关重要，但当前的方法存在幻觉、视觉基础薄弱以及无法使用工具进行验证的问题，限制了它们在复杂的多模态推理任务上的可靠性。我们提出了 ARM-Thinker，一种自主的多模式奖励模型，它自动调用外部工具（例如图像裁剪、文档页面检索）来根据可验证的证据进行判断，取代静态的、非交互式的奖励评分。这使得模型能够验证细粒度的视觉细节、交叉引用多页证据并验证推理主张，这些都是现有奖励模型所缺乏的功能。我们通过多阶段强化学习来训练 ARM-Thinker，共同优化工具调用决策和判断准确性。为了评估代理奖励模型，我们引入了 ARMBench-VL，它包含三个基准测试，分别评估细粒度视觉基础（图像级工具）、多页文档理解（检索工具）和指令遵循（文本级验证）。 ARM-Thinker 在奖励建模基准上实现了 +16.2% 的平均改进，在工具使用任务上实现了 +9.6% 的平均改进，并且在多模态数学和逻辑推理基准上优于基准。我们的结果表明，代理能力显着提高了奖励模型的准确性和可解释性。
> **Abstract**: Reward models are critical for aligning vision-language systems with human preferences, yet current approaches suffer from hallucination, weak visual grounding, and an inability to use tools for verification, limiting their reliability on complex multimodal reasoning tasks. We present ARM-Thinker, an A}gentic multimodal Reward Model that autonomously invokes external tools (e.g., image cropping, doc page retrieval) to ground judgments in verifiable evidence, replacing static, non-interactive reward scoring. This enables the model to verify fine-grained visual details, cross-reference multi-page evidence, and validate reasoning claims, which are capabilities absent in existing reward models. We train ARM-Thinker with multi-stage reinforcement learning, jointly optimizing tool-calling decisions and judgment accuracy. To evaluate agentic reward modeling, we introduce ARMBench-VL, comprising three benchmarks that assess fine-grained visual grounding (image-level tools), multi-page document understanding (retrieval tools), and instruction following (text-level verification). ARM-Thinker achieves +16.2% average improvement on reward modeling benchmarks, +9.6% on tool-use tasks, and outperforms baselines on multimodal math and logical reasoning benchmarks. Our results demonstrate that agentic capabilities significantly enhance both accuracy and interpretability of reward models.

【5】ShadowDraw: From Any Object to Shadow-Drawing Compositional Art
- **标题**: ShadowDraw：从任何物体到影画构图艺术
- **链接**: https://arxiv.org/abs/2512.05110
> **作者**: Rundong Luo,Noah Snavely,Wei-Chiu Ma
> **摘要**: 我们介绍 ShadowDraw，一个将普通 3D 对象转换为阴影绘制构图艺术的框架。给定一个 3D 对象，我们的系统会预测场景参数，包括对象姿势和光照，以及部分线条绘制，以便投射阴影将绘图完成为可识别的图像。为此，我们优化场景配置以揭示有意义的阴影，使用阴影笔划来指导线条图生成，并采用自动评估来增强阴影绘制的连贯性和视觉质量。实验表明，ShadowDraw 在不同的输入（从现实世界的扫描和精选数据集到生成资产）中产生令人信服的结果，并自然地扩展到多对象场景、动画和物理部署。我们的工作为创建皮影艺术提供了一条实用的管道，并拓宽了计算视觉艺术的设计空间，弥合了算法设计和艺术叙事之间的差距。查看我们的项目页面 https://red-fairy.github.io/ShadowDraw/ 以获取更多结果以及我们管道的端到端真实世界演示！
> **Abstract**: We introduce ShadowDraw, a framework that transforms ordinary 3D objects into shadow-drawing compositional art. Given a 3D object, our system predicts scene parameters, including object pose and lighting, together with a partial line drawing, such that the cast shadow completes the drawing into a recognizable image. To this end, we optimize scene configurations to reveal meaningful shadows, employ shadow strokes to guide line drawing generation, and adopt automatic evaluation to enforce shadow-drawing coherence and visual quality. Experiments show that ShadowDraw produces compelling results across diverse inputs, from real-world scans and curated datasets to generative assets, and naturally extends to multi-object scenes, animations, and physical deployments. Our work provides a practical pipeline for creating shadow-drawing art and broadens the design space of computational visual art, bridging the gap between algorithmic design and artistic storytelling. Check out our project page https://red-fairy.github.io/ShadowDraw/ for more results and an end-to-end real-world demonstration of our pipeline!

【6】NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation
- **标题**: NeuralRemaster：用于结构对齐生成的保相扩散
- **链接**: https://arxiv.org/abs/2512.05106
> **作者**: Yu Zeng,Charles Ochoa,Mingyuan Zhou,Vishal M. Patel,Vitor Guizilini,Rowan McAllister
> **摘要**: 标准扩散使用高斯噪声破坏数据，其傅里叶系数具有随机幅度和随机相位。虽然对于无条件或文本到图像生成有效，但破坏相位分量会破坏空间结构，使其不适合需要几何一致性的任务，例如重新渲染、模拟增强和图像到图像转换。我们引入了保相扩散 φ-PD，这是一种与模型无关的扩散过程重新表述，可在随机化幅度的同时保留输入相位，从而无需更改架构或添加额外参数即可实现结构对齐生成。我们进一步提出频率选择结构（FSS）噪声，它通过单个频率截止参数提供对结构刚度的连续控制。 φ-PD 不增加推理时间成本，并且与图像或视频的任何扩散模型兼容。通过照片级真实感和风格化重新渲染，以及驾驶规划者的模拟到真实增强，φ-PD 可以产生可控的、空间对齐的结果。当应用于 CARLA 模拟器时，φ-PD 将 CARLA 到 Waymo 规划器的性能提高了 50%。该方法是对现有调节方法的补充，广泛适用于图像到图像和视频到视频的生成。视频、其他示例和代码可在我们的 \href{https://yuzeng-at-tri.github.io/ppd-page/}{项目页面} 上找到。
> **Abstract**: Standard diffusion corrupts data using Gaussian noise whose Fourier coefficients have random magnitudes and random phases. While effective for unconditional or text-to-image generation, corrupting phase components destroys spatial structure, making it ill-suited for tasks requiring geometric consistency, such as re-rendering, simulation enhancement, and image-to-image translation. We introduce Phase-Preserving Diffusion φ-PD, a model-agnostic reformulation of the diffusion process that preserves input phase while randomizing magnitude, enabling structure-aligned generation without architectural changes or additional parameters. We further propose Frequency-Selective Structured (FSS) noise, which provides continuous control over structural rigidity via a single frequency-cutoff parameter. φ-PD adds no inference-time cost and is compatible with any diffusion model for images or videos. Across photorealistic and stylized re-rendering, as well as sim-to-real enhancement for driving planners, φ-PD produces controllable, spatially aligned results. When applied to the CARLA simulator, φ-PD improves CARLA-to-Waymo planner performance by 50\%. The method is complementary to existing conditioning approaches and broadly applicable to image-to-image and video-to-video generation. Videos, additional examples, and code are available on our \href{https://yuzeng-at-tri.github.io/ppd-page/}{project page}.

【7】EvoIR: Towards All-in-One Image Restoration via Evolutionary Frequency Modulation
- **标题**: EvoIR：通过进化频率调制实现一体化图像恢复
- **链接**: https://arxiv.org/abs/2512.05104
> **作者**: Jiaqi Ma,Shengkai Hu,Jun Wan,Jiaxing Huang,Lefei Zhang,Salman Khan
> **摘要**: 多合一图像恢复 (AiOIR) 任务通常涉及多种退化，需要强大且通用的策略。然而，大多数现有方法通常缺乏明确的频率建模，并依赖于固定或启发式优化计划，这限制了异构退化的泛化。为了解决这些限制，我们提出了 EvoIR，这是一种 AiOIR 特定的框架，它引入了用于动态和自适应图像恢复的进化频率调制。具体来说，EvoIR 采用调频模块 (FMM)，以显式方式将特征分解为高频和低频分支，并自适应调制它们以增强结构保真度和细粒度细节。 EvoIR 的核心是进化优化策略 (EOS)，通过基于群体的进化过程迭代调整频率感知目标，动态平衡结构准确性和感知保真度。其进化指导进一步减轻了退化过程中的梯度冲突并加速了收敛。通过协同 FMM 和 EOS，EvoIR 比单独使用任一组件产生了更大的改进，强调了它们的互补作用。对多个基准的大量实验表明，EvoIR 优于最先进的 AiOIR 方法。
> **Abstract**: All-in-One Image Restoration (AiOIR) tasks often involve diverse degradation that require robust and versatile strategies. However, most existing approaches typically lack explicit frequency modeling and rely on fixed or heuristic optimization schedules, which limit the generalization across heterogeneous degradation. To address these limitations, we propose EvoIR, an AiOIR-specific framework that introduces evolutionary frequency modulation for dynamic and adaptive image restoration. Specifically, EvoIR employs the Frequency-Modulated Module (FMM) that decomposes features into high- and low-frequency branches in an explicit manner and adaptively modulates them to enhance both structural fidelity and fine-grained details. Central to EvoIR, an Evolutionary Optimization Strategy (EOS) iteratively adjusts frequency-aware objectives through a population-based evolutionary process, dynamically balancing structural accuracy and perceptual fidelity. Its evolutionary guidance further mitigates gradient conflicts across degradation and accelerates convergence. By synergizing FMM and EOS, EvoIR yields greater improvements than using either component alone, underscoring their complementary roles. Extensive experiments on multiple benchmarks demonstrate that EvoIR outperforms state-of-the-art AiOIR methods.

【8】SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards
- **标题**: SA-IQA：以多维度奖励重新定义空间美学图像质量评估
- **链接**: https://arxiv.org/abs/2512.05098
> **作者**: Yuan Gao,Jin Song
> **摘要**: 近年来，针对人工智能生成图像（AIGI）的图像质量评估（IQA）发展迅速；然而，现有方法主要针对肖像和艺术图像，缺乏对室内场景的系统评估。我们引入空间美学，这是一种从四个维度评估室内图像美学质量的范式：布局、和谐、照明和扭曲。我们构建了 SA-BENCH，第一个空间美学基准，包含 18,000 张图像和 50,000 个精确注释。利用SA-BENCH，我们系统地评估了当前的IQA方法，并通过MLLM微调和多维融合方法开发了SA-IQA，作为评估空间美学的综合奖励框架。我们将 SA-IQA 应用于两个下游任务：（1）作为与 GRPO 强化学习集成的奖励信号来优化 AIGC 生成管道，以及（2）Best-of-N 选择来过滤高质量图像并提高生成质量。实验表明，SA-IQA 显着优于 SA-BENCH 上的现有方法，为空间美学评估设立了新标准。代码和数据集将开源，以推进该领域的研究和应用。
> **Abstract**: In recent years, Image Quality Assessment (IQA) for AI-generated images (AIGI) has advanced rapidly; however, existing methods primarily target portraits and artistic images, lacking a systematic evaluation of interior scenes. We introduce Spatial Aesthetics, a paradigm that assesses the aesthetic quality of interior images along four dimensions: layout, harmony, lighting, and distortion. We construct SA-BENCH, the first benchmark for spatial aesthetics, comprising 18,000 images and 50,000 precise annotations. Employing SA-BENCH, we systematically evaluate current IQA methodologies and develop SA-IQA, through MLLM fine-tuning and a multidimensional fusion approach, as a comprehensive reward framework for assessing spatial aesthetics. We apply SA-IQA to two downstream tasks: (1) serving as a reward signal integrated with GRPO reinforcement learning to optimize the AIGC generation pipeline, and (2) Best-of-N selection to filter high-quality images and improve generation quality. Experiments indicate that SA-IQA significantly outperforms existing methods on SA-BENCH, setting a new standard for spatial aesthetics evaluation. Code and dataset will be open-sourced to advance research and applications in this domain.

【9】Visual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark
- **标题**: 视觉推理追踪器：对象级接地推理基准
- **链接**: https://arxiv.org/abs/2512.05091
> **作者**: Haobo Yuan,Yueyi Sun,Yanwei Li,Tao Zhang,Xueqing Deng,Henghui Ding,Lu Qi,Anran Wang,Xiangtai Li,Ming-Hsuan Yang
> **摘要**: 多模态大语言模型 (MLLM) 的最新进展显着提高了视觉基础和视觉问答等任务的性能。然而，这些模型的推理过程在很大程度上仍然是不透明的；它们通常只输出最终预测，而不透露导致结果的中间步骤或细粒度证据（例如像素、位置）。这与人类智能形成鲜明对比，人类智能自然地通过一系列视觉推理来运作。为了解决这个限制，我们引入了视觉推理跟踪器（VRT）任务，该任务要求模型不仅要本地化目标对象，还要显式预测形成推理路径的中间对象。为了推进这一领域的研究，我们贡献了：（1）VRT-Bench，一个用于评估视觉推理的人工注释基准； (2) 评估推理痕迹质量的新指标； （3）VRT-80k，用于推理模型训练的大规模数据集。我们的实验表明，虽然现有模型通常会产生正确的最终输出，但它们很难为中间推理奠定基础。相比之下，在 VRT-80k 上训练的模型在追踪推理路径方面取得了显着的改进。
> **Abstract**: Recent advances in Multimodal Large Language Models (MLLMs) have significantly improved performance on tasks such as visual grounding and visual question answering. However, the reasoning processes of these models remain largely opaque; they typically output only final predictions without revealing the intermediate steps or fine-grained evidence (e.g., pixels, locations) that lead to the result. This contrasts with human intelligence, which naturally operates through a chain of visual reasoning. To address this limitation, we introduce the Visual Reasoning Tracer (VRT) task, which requires models to not only localize the target object but also explicitly predict the intermediate objects that form the reasoning path. To advance research in this area, we contribute: (1) VRT-Bench, a human-annotated benchmark for evaluating visual reasoning; (2) a new metric for assessing the quality of reasoning traces; and (3) VRT-80k, a large-scale dataset for reasoning model training. Our experiments reveal that while existing models often produce the correct final output, they struggle to ground their intermediate reasoning. In contrast, models trained on VRT-80k achieve substantial improvements in tracing the reasoning path.

【10】Deep Forcing: Training-Free Long Video Generation with Deep Sink and Participative Compression
- **标题**: Deep Forcing：利用 Deep Sink 和参与式压缩进行免训练长视频生成
- **链接**: https://arxiv.org/abs/2512.05081
> **作者**: Jung Yi,Wooseok Jang,Paul Hyunbin Cho,Jisu Nam,Heeji Yoon,Seungryong Kim
> **摘要**: 自回归视频扩散的最新进展已经实现了实时帧流，但现有的解决方案仍然存在时间重复、漂移和运动减速的问题。我们发现，天真地将 StreamingLLM 式的注意力集中应用于视频扩散会导致保真度下降和运动停滞。为了克服这个问题，我们引入了深度强制，它由两种免训练机制组成，无需任何微调即可解决此问题。具体来说，1) Deep Sink 将一半的滑动窗口专用于持久性接收器令牌，并将其时间 RoPE 阶段重新与当前时间线对齐，从而在长时间部署期间稳定全局上下文。 2) 参与压缩执行重要性感知的 KV 缓存修剪，仅保留积极参与最近关注的令牌，同时安全地丢弃冗余和降级的历史记录，最大限度地减少分布长度生成下的错误累积。这些组件共同实现了超过 12 倍的外推（例如，5 秒训练到 60 秒以上的生成），具有比 LongLive 更好的成像质量、比 RollingForcing 更好的美学质量、几乎保持整体一致性，并在动态程度方面大幅提高，同时保持实时生成。我们的结果表明，免训练的 KV 缓存管理可以匹配或超过基于训练的自回归流式长视频生成方法。
> **Abstract**: Recent advances in autoregressive video diffusion have enabled real-time frame streaming, yet existing solutions still suffer from temporal repetition, drift, and motion deceleration. We find that naively applying StreamingLLM-style attention sinks to video diffusion leads to fidelity degradation and motion stagnation. To overcome this, we introduce Deep Forcing, which consists of two training-free mechanisms that address this without any fine-tuning. Specifically, 1) Deep Sink dedicates half of the sliding window to persistent sink tokens and re-aligns their temporal RoPE phase to the current timeline, stabilizing global context during long rollouts. 2) Participative Compression performs importance-aware KV cache pruning that preserves only tokens actively participating in recent attention while safely discarding redundant and degraded history, minimizing error accumulation under out-of-distribution length generation. Together, these components enable over 12x extrapolation (e.g. 5s-trained to 60s+ generation) with better imaging quality than LongLive, better aesthetic quality than RollingForcing, almost maintaining overall consistency, and substantial gains in dynamic degree, all while maintaining real-time generation. Our results demonstrate that training-free KV-cache management can match or exceed training-based approaches for autoregressively streaming long-video generation.

【11】Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints
- **标题**: 使用生成先验和接触引起的约束进行遮挡下的对象重建
- **链接**: https://arxiv.org/abs/2512.05079
> **作者**: Minghan Zhu,Zhiyi Wang,Qihang Sun,Maani Ghaffari,Michael Posa
> **摘要**: 物体几何形状是机器人操纵的关键信息。然而，对象重建是一项具有挑战性的任务，因为相机只能捕获对象的部分观察结果，尤其是在发生遮挡时。在本文中，我们利用两个额外的信息源来减少视觉信号的模糊性。首先，生成模型学习常见物体形状的先验，使我们能够对几何中不可见的部分做出合理的猜测。其次，可以从视频和物理交互中获得的接触信息为几何边界提供了稀疏约束。我们通过接触引导的 3D 生成将两种信息源结合起来。指导制定的灵感来自于生成模型中基于拖动的编辑。对合成数据和真实世界数据的实验表明，与纯 3D 生成和基于接触的优化相比，我们的方法改进了重建。
> **Abstract**: Object geometry is key information for robot manipulation. Yet, object reconstruction is a challenging task because cameras only capture partial observations of objects, especially when occlusion occurs. In this paper, we leverage two extra sources of information to reduce the ambiguity of vision signals. First, generative models learn priors of the shapes of commonly seen objects, allowing us to make reasonable guesses of the unseen part of geometry. Second, contact information, which can be obtained from videos and physical interactions, provides sparse constraints on the boundary of the geometry. We combine the two sources of information through contact-guided 3D generation. The guidance formulation is inspired by drag-based editing in generative models. Experiments on synthetic and real-world data show that our approach improves the reconstruction compared to pure 3D generation and contact-based optimization.

【12】BulletTime: Decoupled Control of Time and Camera Pose for Video Generation
- **标题**: BulletTime：视频生成的时间和相机姿势的解耦控制
- **链接**: https://arxiv.org/abs/2512.05076
> **作者**: Yiming Wang,Qihang Zhang,Shengqu Cai,Tong Wu,Jan Ackermann,Zhengfei Kuang,Yang Zheng,Frano Rajič,Siyu Tang,Gordon Wetzstein
> **摘要**: 新兴的视频扩散模型实现了高视觉保真度，但从根本上将场景动态与摄像机运动耦合在一起，限制了它们提供精确的空间和时间控制的能力。我们引入了 4D 可控视频扩散框架，该框架明确地将场景动态与摄像机姿态解耦，从而能够对场景动态和摄像机视点进行细粒度操作。我们的框架采用连续的世界时间序列和摄像机轨迹作为条件输入，通过注意力层中的 4D 位置编码和特征调制的自适应归一化将它们注入视频扩散模型。为了训练这个模型，我们创建了一个独特的数据集，其中时间和相机变化是独立参数化的；该数据集将被公开。实验表明，我们的模型在不同的时序模式和相机轨迹上实现了强大的现实世界 4D 控制，同时保持了高生成质量并在可控性方面优于先前的工作。请参阅我们的网站了解视频结果：https://19reborn.github.io/Bullet4D/
> **Abstract**: Emerging video diffusion models achieve high visual fidelity but fundamentally couple scene dynamics with camera motion, limiting their ability to provide precise spatial and temporal control. We introduce a 4D-controllable video diffusion framework that explicitly decouples scene dynamics from camera pose, enabling fine-grained manipulation of both scene dynamics and camera viewpoint. Our framework takes continuous world-time sequences and camera trajectories as conditioning inputs, injecting them into the video diffusion model through a 4D positional encoding in the attention layer and adaptive normalizations for feature modulation. To train this model, we curate a unique dataset in which temporal and camera variations are independently parameterized; this dataset will be made public. Experiments show that our model achieves robust real-world 4D control across diverse timing patterns and camera trajectories, while preserving high generation quality and outperforming prior work in controllability. See our website for video results: https://19reborn.github.io/Bullet4D/

【13】4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer
- **标题**: 4DLangVGGT：4D语言-视觉几何接地变压器
- **链接**: https://arxiv.org/abs/2512.05060
> **作者**: Xianfeng Wu,Yajing Bai,Minghan Li,Xianzu Wu,Xueqi Zhao,Zhongyuan Lai,Wenyu Liu,Xinggang Wang
> **摘要**: 构建 4D 语言字段对于实体 AI、增强/虚拟现实和 4D 场景理解至关重要，因为它们提供了动态环境的丰富语义表示，并支持复杂场景中的开放词汇查询。然而，现有的 4D 语义场构建方法主要依赖于特定于场景的高斯分布，这需要针对每个场景进行优化，泛化能力有限，并且难以扩展到现实世界的应用。为了解决这些限制，我们提出了 4DLangVGGT，这是第一个基于 Transformer 的前馈统一框架，用于 4D 语言基础，它将几何感知和语言对齐联合集成在单个架构中。 4DLangVGGT 有两个关键组件：4D 视觉几何变换器 StreamVGGT，它捕获动态场景的时空几何表示；语义桥接解码器（SBD），它将几何感知特征投射到语言对齐的语义空间中，从而增强语义可解释性，同时保持结构保真度。与依赖于昂贵的每个场景优化的现有方法不同，4DLangVGGT 可以跨多个动态场景联合训练并在推理过程中直接应用，从而实现部署效率和强泛化性。该设计显着提高了大规模部署的实用性，并为开放词汇的4D场景理解建立了新的范式。在 HyperNeRF 和 Neu3D 数据集上的实验表明，我们的方法不仅可以有效泛化，而且还实现了最先进的性能，在每个场景训练下实现了高达 2% 的增益，在多场景训练下实现了 1% 的改进。我们的代码发布在 https://github.com/hustvl/4DLangVGGT
> **Abstract**: Constructing 4D language fields is crucial for embodied AI, augmented/virtual reality, and 4D scene understanding, as they provide enriched semantic representations of dynamic environments and enable open-vocabulary querying in complex scenarios. However, existing approaches to 4D semantic field construction primarily rely on scene-specific Gaussian splatting, which requires per-scene optimization, exhibits limited generalization, and is difficult to scale to real-world applications. To address these limitations, we propose 4DLangVGGT, the first Transformer-based feed-forward unified framework for 4D language grounding, that jointly integrates geometric perception and language alignment within a single architecture. 4DLangVGGT has two key components: the 4D Visual Geometry Transformer, StreamVGGT, which captures spatio-temporal geometric representations of dynamic scenes; and the Semantic Bridging Decoder (SBD), which projects geometry-aware features into a language-aligned semantic space, thereby enhancing semantic interpretability while preserving structural fidelity. Unlike prior methods that depend on costly per-scene optimization, 4DLangVGGT can be jointly trained across multiple dynamic scenes and directly applied during inference, achieving both deployment efficiency and strong generalization. This design significantly improves the practicality of large-scale deployment and establishes a new paradigm for open-vocabulary 4D scene understanding. Experiments on HyperNeRF and Neu3D datasets demonstrate that our approach not only generalizes effectively but also achieves state-of-the-art performance, achieving up to 2% gains under per-scene training and 1% improvements under multi-scene training. Our code released in https://github.com/hustvl/4DLangVGGT

【14】Joint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image
- **标题**: 用于从单个图像进行 4D 合成的联合 3D 几何重建和运动生成
- **链接**: https://arxiv.org/abs/2512.05044
> **作者**: Yanran Zhang,Ziyi Wang,Wenzhao Zheng,Zheng Zhu,Jie Zhou,Jiwen Lu
> **摘要**: 从单个静态图像生成交互式动态 4D 场景仍然是一个核心挑战。大多数现有的“生成然后重建”和“重建然后生成”方法将几何图形与运动解耦，导致时空不一致和泛化能力差。为了解决这些问题，我们扩展了重建然后生成框架来联合执行 4D 合成的运动生成和几何重建 (MoRe4D)。我们首先介绍 TrajScene-60K，这是一个包含 60,000 个视频样本的大规模数据集，具有密集的点轨迹，解决了高质量 4D 场景数据的稀缺问题。基于此，我们提出了一种基于扩散的 4D 场景轨迹生成器 (4D-STraG)，以联合生成几何一致且运动合理的 4D 点轨迹。为了利用单视图先验，我们设计了深度引导运动标准化策略和运动感知模块，以实现有效的几何和动力学集成。然后，我们提出了一个 4D 视图合成模块 (4D-ViSM)，用于根据 4D 点轨迹表示来渲染具有任意相机轨迹的视频。实验表明，MoRe4D 可以从单个图像生成具有多视图一致性和丰富动态细节的高质量 4D 场景。代码：https://github.com/Zhangyr2022/MoRe4D。
> **Abstract**: Generating interactive and dynamic 4D scenes from a single static image remains a core challenge. Most existing generate-then-reconstruct and reconstruct-then-generate methods decouple geometry from motion, causing spatiotemporal inconsistencies and poor generalization. To address these, we extend the reconstruct-then-generate framework to jointly perform Motion generation and geometric Reconstruction for 4D Synthesis (MoRe4D). We first introduce TrajScene-60K, a large-scale dataset of 60,000 video samples with dense point trajectories, addressing the scarcity of high-quality 4D scene data. Based on this, we propose a diffusion-based 4D Scene Trajectory Generator (4D-STraG) to jointly generate geometrically consistent and motion-plausible 4D point trajectories. To leverage single-view priors, we design a depth-guided motion normalization strategy and a motion-aware module for effective geometry and dynamics integration. We then propose a 4D View Synthesis Module (4D-ViSM) to render videos with arbitrary camera trajectories from 4D point track representations. Experiments show that MoRe4D generates high-quality 4D scenes with multi-view consistency and rich dynamic details from a single image. Code: https://github.com/Zhangyr2022/MoRe4D.

【15】Semantic-Guided Two-Stage GAN for Face Inpainting with Hybrid Perceptual Encoding
- **标题**: 使用混合感知编码进行面部修复的语义引导两阶段 GAN
- **链接**: https://arxiv.org/abs/2512.05039
> **作者**: Abhigyan Bhattacharya,Hiranmoy Roy
> **摘要**: 面部图像修复的目的是恢复面部图像中丢失或损坏的区域，同时保持身份、结构一致性和逼真的图像质量，这是专门为照片修复创建的任务。尽管深度生成模型最近取得了很多进展，但现有方法面临着大型不规则掩模的问题，由于直接像素级合成方法和面部先验的有限利用，通常会在掩模区域的边缘产生模糊的纹理、语义不一致或不令人信服的面部结构。在本文中，我们提出了一种新颖的架构，通过语义引导的层次综合来解决上述挑战。我们的方法首先是根据含义组织和合成信息，然后细化纹理。在我们继续创建详细图像之前，这个过程可以清晰地了解面部结构。在第一阶段，我们融合了两种技术：一种是使用 CNN 关注局部特征，另一种是使用 Vision Transformer 关注全局特征。这帮助我们创建清晰且详细的语义布局。在第二阶段，我们使用多模态纹理生成器通过从不同尺度提取信息来细化这些布局，确保一切看起来都有凝聚力和一致。该架构通过动态注意力自然地处理任意掩模配置，无需特定于掩模的训练。在两个数据集 CelebA-HQ 和 FFHQ 上进行的实验表明，我们的模型优于其他最先进的方法，在 LPIPS、PSNR 和 SSIM 等指标方面显示出改进。在具有挑战性的大面积修复情况下，它可以产生视觉上引人注目的结果，并具有更好的语义保留。
> **Abstract**: Facial Image inpainting aim is to restore the missing or corrupted regions in face images while preserving identity, structural consistency and photorealistic image quality, a task specifically created for photo restoration. Though there are recent lot of advances in deep generative models, existing methods face problems with large irregular masks, often producing blurry textures on the edges of the masked region, semantic inconsistencies, or unconvincing facial structures due to direct pixel level synthesis approach and limited exploitation of facial priors. In this paper we propose a novel architecture, which address these above challenges through semantic-guided hierarchical synthesis. Our approach starts with a method that organizes and synthesizes information based on meaning, followed by refining the texture. This process gives clear insights into the facial structure before we move on to creating detailed images. In the first stage, we blend two techniques: one that focuses on local features with CNNs and global features with Vision Transformers. This helped us create clear and detailed semantic layouts. In the second stage, we use a Multi-Modal Texture Generator to refine these layouts by pulling in information from different scales, ensuring everything looks cohesive and consistent. The architecture naturally handles arbitrary mask configurations through dynamic attention without maskspecific training. Experiment on two datasets CelebA-HQ and FFHQ shows that our model outperforms other state-of-the-art methods, showing improvements in metrics like LPIPS, PSNR, and SSIM. It produces visually striking results with better semantic preservation, in challenging large-area inpainting situations.

【16】RAMEN: Resolution-Adjustable Multimodal Encoder for Earth Observation
- **标题**: RAMEN：用于地球观测的分辨率可调多模态编码器
- **链接**: https://arxiv.org/abs/2512.05025
> **作者**: Nicolas Houdré,Diego Marcos,Hugo Riffaud de Turckheim,Dino Ienco,Laurent Wendling,Camille Kurtz,Sylvain Lobry
> **摘要**: 地球观测 (EO) 数据涵盖广泛的空间、光谱和时间分辨率，从高分辨率光学图像到低分辨率多光谱产品或雷达时间序列。虽然最近的基础模型已经改进了多模态集成以学习有意义的表示，但它们通常期望固定的输入分辨率或基于特定于传​​感器的编码器，限制了跨异构 EO 模态的泛化。为了克服这些限制，我们引入了 RAMEN，这是一种分辨率可调的多模态编码器，它以完全与传感器无关的方式学习跨 EO 数据的共享视觉表示。 RAMEN 将模态以及时空分辨率视为关键的输入数据特征，从而能够在统一的潜在空间内进行跨模态的连贯分析。其主要方法论贡献是将空间分辨率定义为可控输出参数，使用户能够直接控制推理时所需的细节水平，并允许在空间精度和计算成本之间进行明确的权衡。我们训练一个统一的变压器编码器，重建从不同来源提取的屏蔽多模态 EO 数据，确保跨传感器和分辨率的泛化。经过预训练后，RAMEN 可以有效地转移到已知和未见过的传感器配置，并在社区标准 PANGEA 基准上超越更大的最先进模型，其中包含各种多传感器和多分辨率下游任务。我们的代码和预训练模型可在 https://github.com/nicolashoudre/RAMEN 获取。
> **Abstract**: Earth observation (EO) data spans a wide range of spatial, spectral, and temporal resolutions, from high-resolution optical imagery to low resolution multispectral products or radar time series. While recent foundation models have improved multimodal integration for learning meaningful representations, they often expect fixed input resolutions or are based on sensor-specific encoders limiting generalization across heterogeneous EO modalities. To overcome these limitations we introduce RAMEN, a resolution-adjustable multimodal encoder that learns a shared visual representation across EO data in a fully sensor-agnostic manner. RAMEN treats the modality and spatial and temporal resolutions as key input data features, enabling coherent analysis across modalities within a unified latent space. Its main methodological contribution is to define spatial resolution as a controllable output parameter, giving users direct control over the desired level of detail at inference and allowing explicit trade-offs between spatial precision and computational cost. We train a single, unified transformer encoder reconstructing masked multimodal EO data drawn from diverse sources, ensuring generalization across sensors and resolutions. Once pretrained, RAMEN transfers effectively to both known and unseen sensor configurations and outperforms larger state-of-the-art models on the community-standard PANGAEA benchmark, containing various multi-sensor and multi-resolution downstream tasks. Our code and pretrained model are available at https://github.com/nicolashoudre/RAMEN.

【17】HTR-ConvText: Leveraging Convolution and Textual Information for Handwritten Text Recognition
- **标题**: HTR-ConvText：利用卷积和文本信息进行手写文本识别
- **链接**: https://arxiv.org/abs/2512.05021
> **作者**: Pham Thach Thanh Truc,Dang Hoai Nam,Huynh Tong Dang Khoa,Vo Nguyen Le Duy
> **摘要**: 由于数据有限、书写风格差异较大以及带有复杂变音符号的脚本，手写文本识别仍然具有挑战性。现有的方法虽然部分解决了这些问题，但在没有大量合成数据的情况下往往难以推广。为了应对这些挑战，我们提出了 HTR-ConvText，这是一种旨在捕获细粒度、笔划级局部特征，同时保留全局上下文依赖性的模型。在特征提取阶段，我们将残差卷积神经网络主干与带有位置编码块的 MobileViT 集成。这使得模型能够捕获结构模式并学习微妙的书写细节。然后，我们介绍了 ConvText 编码器，这是一种将全局上下文和局部特征结合在分层结构中的混合架构，可减少序列长度以提高效率。此外，辅助模块注入文本上下文以减轻联结主义时间分类的弱点。对 IAM、READ2016、LAM 和 HANDS-VNOnDB 的评估表明，与现有方法相比，我们的方法实现了更高的性能和更好的泛化性，特别是在训练样本有限和手写多样性较高的场景中。
> **Abstract**: Handwritten Text Recognition remains challenging due to the limited data, high writing style variance, and scripts with complex diacritics. Existing approaches, though partially address these issues, often struggle to generalize without massive synthetic data. To address these challenges, we propose HTR-ConvText, a model designed to capture fine-grained, stroke-level local features while preserving global contextual dependencies. In the feature extraction stage, we integrate a residual Convolutional Neural Network backbone with a MobileViT with Positional Encoding block. This enables the model to both capture structural patterns and learn subtle writing details. We then introduce the ConvText encoder, a hybrid architecture combining global context and local features within a hierarchical structure that reduces sequence length for improved efficiency. Additionally, an auxiliary module injects textual context to mitigate the weakness of Connectionist Temporal Classification. Evaluations on IAM, READ2016, LAM and HANDS-VNOnDB demonstrate that our approach achieves improved performance and better generalization compared to existing methods, especially in scenarios with limited training samples and high handwriting diversity.

【18】Generative Neural Video Compression via Video Diffusion Prior
- **标题**: 通过视频扩散先验的生成神经视频压缩
- **链接**: https://arxiv.org/abs/2512.05016
> **作者**: Qi Mao,Hao Cheng,Tinghan Yang,Libiao Jin,Siwei Ma
> **摘要**: 我们提出了 GNVC-VD，这是第一个基于 DiT 的生成神经视频压缩框架，建立在高级视频生成基础模型的基础上，其中时空潜在压缩和序列级生成细化在单个编解码器中统一。现有的感知编解码器主要依靠预先训练的图像生成先验来恢复高频细节，但其逐帧性质缺乏时间建模，不可避免地导致感知闪烁。为了解决这个问题，GNVC-VD 引入了一个统一的流匹配潜在细化模块，该模块利用视频扩散转换器通过序列级去噪来联合增强帧内和帧间潜在，从而确保一致的时空细节。 GNVC-VD 不是像视频生成中那样从纯高斯噪声中进行去噪，而是从解码的时空潜伏中进行初始化细化，并学习一个校正项，该校正项可以在压缩引起的退化之前适应扩散。调节适配器进一步将压缩感知线索注入中间 DiT 层，从而实现有效去除伪影，同时在极端比特率限制下保持时间一致性。大量实验表明，GNVC-VD 在感知质量方面超越了传统和学习编解码器，并显着减少了先前生成方法中持续存在的闪烁伪影，甚至低于 0.01 bpp，凸显了将视频原生生成先验集成到神经编解码器中以实现下一代感知视频压缩的前景。
> **Abstract**: We present GNVC-VD, the first DiT-based generative neural video compression framework built upon an advanced video generation foundation model, where spatio-temporal latent compression and sequence-level generative refinement are unified within a single codec. Existing perceptual codecs primarily rely on pre-trained image generative priors to restore high-frequency details, but their frame-wise nature lacks temporal modeling and inevitably leads to perceptual flickering. To address this, GNVC-VD introduces a unified flow-matching latent refinement module that leverages a video diffusion transformer to jointly enhance intra- and inter-frame latents through sequence-level denoising, ensuring consistent spatio-temporal details. Instead of denoising from pure Gaussian noise as in video generation, GNVC-VD initializes refinement from decoded spatio-temporal latents and learns a correction term that adapts the diffusion prior to compression-induced degradation. A conditioning adaptor further injects compression-aware cues into intermediate DiT layers, enabling effective artifact removal while maintaining temporal coherence under extreme bitrate constraints. Extensive experiments show that GNVC-VD surpasses both traditional and learned codecs in perceptual quality and significantly reduces the flickering artifacts that persist in prior generative approaches, even below 0.01 bpp, highlighting the promise of integrating video-native generative priors into neural codecs for next-generation perceptual video compression.

【19】Self-Supervised Learning for Transparent Object Depth Completion Using Depth from Non-Transparent Objects
- **标题**: 使用非透明对象的深度进行透明对象深度补全的自监督学习
- **链接**: https://arxiv.org/abs/2512.05006
> **作者**: Xianghui Fan,Zhaoyu Chen,Mengyang Pan,Anping Deng,Hang Yang
> **摘要**: 透明物体的感知是计算机视觉领域众所周知的挑战之一。由于光的折射和反射，传统的深度传感器难以感测透明物体的深度。以往的研究通常是训练神经网络来完成传感器的深度获取，这种方法可以快速准确地获取透明物体的精确深度图。然而，以往的训练依赖大量的标注数据进行监督，深度图的标注成本高昂。为了应对这一挑战，我们提出了一种新的自监督方法来训练深度完成网络。我们的方法模拟非透明区域内透明物体的深度缺陷，并利用原始深度图作为监督的基本事实。实验表明，我们的方法取得了与监督方法相当的性能，并且当训练样本较小时，使用我们的方法进行预训练可以提高模型性能。
> **Abstract**: The perception of transparent objects is one of the well-known challenges in computer vision. Conventional depth sensors have difficulty in sensing the depth of transparent objects due to refraction and reflection of light. Previous research has typically train a neural network to complete the depth acquired by the sensor, and this method can quickly and accurately acquire accurate depth maps of transparent objects. However, previous training relies on a large amount of annotation data for supervision, and the labeling of depth maps is costly. To tackle this challenge, we propose a new self-supervised method for training depth completion networks. Our method simulates the depth deficits of transparent objects within non-transparent regions and utilizes the original depth map as ground truth for supervision. Experiments demonstrate that our method achieves performance comparable to supervised approach, and pre-training with our method can improve the model performance when the training samples are small.

【20】Reflection Removal through Efficient Adaptation of Diffusion Transformers
- **标题**: 通过有效调整扩散变压器消除反射
- **链接**: https://arxiv.org/abs/2512.05000
> **作者**: Daniyar Zakarin,Thiemo Wandel,Anton Obukhov,Dengxin Dai
> **摘要**: 我们引入了用于单图像反射去除的扩散变换器（DiT）框架，该框架利用了恢复设置中基础扩散模型的泛化优势。我们不依赖特定于任务的架构，而是通过在反射污染的输入上进行调节并引导其走向干净的传输层来重新调整基于 DiT 的预训练基础模型的用途。我们系统地分析现有的反射去除数据源的多样性、可扩展性和真实感。为了解决合适数据的短缺问题，我们在 Blender 中构建了一个基于物理的渲染 (PBR) 管道，围绕 Principled BSDF 构建，以合成逼真的玻璃材质和反射效果。基于 LoRA 的基础模型的高效适应，结合所提出的合成数据，在域内和零样本基准测试中实现了最先进的性能。这些结果表明，预训练的扩散变压器与物理接地的数据合成和高效适应相结合，可以为反射消除提供可扩展的高保真解决方案。项目页面：https://hf.co/spaces/huawei-bayerlab/windowseat-reflection-removal-web
> **Abstract**: We introduce a diffusion-transformer (DiT) framework for single-image reflection removal that leverages the generalization strengths of foundation diffusion models in the restoration setting. Rather than relying on task-specific architectures, we repurpose a pre-trained DiT-based foundation model by conditioning it on reflection-contaminated inputs and guiding it toward clean transmission layers. We systematically analyze existing reflection removal data sources for diversity, scalability, and photorealism. To address the shortage of suitable data, we construct a physically based rendering (PBR) pipeline in Blender, built around the Principled BSDF, to synthesize realistic glass materials and reflection effects. Efficient LoRA-based adaptation of the foundation model, combined with the proposed synthetic data, achieves state-of-the-art performance on in-domain and zero-shot benchmarks. These results demonstrate that pretrained diffusion transformers, when paired with physically grounded data synthesis and efficient adaptation, offer a scalable and high-fidelity solution for reflection removal. Project page: https://hf.co/spaces/huawei-bayerlab/windowseat-reflection-removal-web

【21】A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs
- **标题**: 嵌入式GPU上基于膨胀的ICP算法的动态内存分配策略
- **链接**: https://arxiv.org/abs/2512.04996
> **作者**: Qiong Chang,Weimin Wang,Junpei Zhong,Jun Miyazaki
> **摘要**: 本文提出了一种针对高性能点云配准算法 VANICP 的内存高效优化策略，能够在硬件资源有限的嵌入式 GPU 上实现轻量级执行。 VANICP是最近发布的加速框架，可显着提高基于点云的应用程序的计算效率。 VANICP通过基于膨胀的信息传播机制将全局最近邻搜索转变为局部过程，大大降低了NNS的计算复杂度。然而，其原始实现需要大量内存，这限制了其在嵌入式系统等资源受限环境中的部署。为了解决这个问题，我们提出了一种面向GPU的动态内存分配策略，优化了膨胀操作的内存使用。此外，基于该策略，我们构建了增强版的 VANICP 框架，在保持原有性能的同时，实现了内存消耗降低 97% 以上。源代码发布于：https://github.com/changqiong/VANICP4Em.git。
> **Abstract**: This paper proposes a memory-efficient optimization strategy for the high-performance point cloud registration algorithm VANICP, enabling lightweight execution on embedded GPUs with constrained hardware resources. VANICP is a recently published acceleration framework that significantly improves the computational efficiency of point-cloud-based applications. By transforming the global nearest neighbor search into a localized process through a dilation-based information propagation mechanism, VANICP greatly reduces the computational complexity of the NNS. However, its original implementation demands a considerable amount of memory, which restricts its deployment in resource-constrained environments such as embedded systems. To address this issue, we propose a GPU-oriented dynamic memory assignment strategy that optimizes the memory usage of the dilation operation. Furthermore, based on this strategy, we construct an enhanced version of the VANICP framework that achieves over 97% reduction in memory consumption while preserving the original performance. Source code is published on: https://github.com/changqiong/VANICP4Em.git.

【22】Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models
- **标题**: 一致但刻板？基于 LVLM 的文本到图像模型中系统提示对社会偏差的隐藏影响
- **链接**: https://arxiv.org/abs/2512.04981
> **作者**: NaHyeon Park,Namin An,Kunhee Kim,Soyeon Yoon,Jiahao Huo,Hyunjung Shim
> **摘要**: 基于大型视觉语言模型（LVLM）的文本到图像（T2I）系统已成为图像生成的主导范例，但它们是否会放大社会偏见仍不清楚。在本文中，我们表明基于 LVLM 的模型比非基于 LVLM 的模型产生的社会偏见图像明显更多。我们引入了涵盖四个语言复杂性级别的 1,024 个提示基准，并以系统的方式评估多个属性的人口统计偏差。我们的分析发现系统提示（指导 LVLM 的预定义指令）是偏见行为的主要驱动因素。通过解码的中间表示、标记概率诊断和嵌入关联分析，我们揭示了系统提示如何对传播到图像合成中的人口统计先验进行编码。为此，我们提出了 FairPro，这是一种免训练的元提示框架，使 LVLM 能够在测试时进行自我审核并构建公平感知系统提示。对两个基于 LVLM 的 T2I 模型 SANA 和 Qwen-Image 的实验表明，FairPro 在保持文本图像对齐的同时大大减少了人口统计偏差。我们相信我们的研究结果可以更深入地了解系统提示在偏见传播中的核心作用，并为构建更具社会责任感的 T2I 系统提供实用、可部署的方法。
> **Abstract**: Large vision-language model (LVLM) based text-to-image (T2I) systems have become the dominant paradigm in image generation, yet whether they amplify social biases remains insufficiently understood. In this paper, we show that LVLM-based models produce markedly more socially biased images than non-LVLM-based models. We introduce a 1,024 prompt benchmark spanning four levels of linguistic complexity and evaluate demographic bias across multiple attributes in a systematic manner. Our analysis identifies system prompts, the predefined instructions guiding LVLMs, as a primary driver of biased behavior. Through decoded intermediate representations, token-probability diagnostics, and embedding-association analyses, we reveal how system prompts encode demographic priors that propagate into image synthesis. To this end, we propose FairPro, a training-free meta-prompting framework that enables LVLMs to self-audit and construct fairness-aware system prompts at test time. Experiments on two LVLM-based T2I models, SANA and Qwen-Image, show that FairPro substantially reduces demographic bias while preserving text-image alignment. We believe our findings provide deeper insight into the central role of system prompts in bias propagation and offer a practical, deployable approach for building more socially responsible T2I systems.

【23】Stable Single-Pixel Contrastive Learning for Semantic and Geometric Tasks
- **标题**: 用于语义和几何任务的稳定单像素对比学习
- **链接**: https://arxiv.org/abs/2512.04970
> **作者**: Leonid Pogorelyuk,Niels Bracher,Aaron Verkleeren,Lars Kühmichel,Stefan T. Radev
> **摘要**: 我们试验了一系列稳定的对比损失来学习共同捕获语义和几何信息的像素级表示。我们的方法将图像的每个像素映射到一个超完备的描述符，该描述符既具有视图不变性又具有语义意义。它可以实现跨图像的精确点对应，而不需要基于动量的师生培训。合成 2D 和 3D 环境中的两个实验证明了我们的损失的特性以及由此产生的过度完整表示。
> **Abstract**: We pilot a family of stable contrastive losses for learning pixel-level representations that jointly capture semantic and geometric information. Our approach maps each pixel of an image to an overcomplete descriptor that is both view-invariant and semantically meaningful. It enables precise point-correspondence across images without requiring momentum-based teacher-student training. Two experiments in synthetic 2D and 3D environments demonstrate the properties of our loss and the resulting overcomplete representations.

【24】Rethinking the Use of Vision Transformers for AI-Generated Image Detection
- **标题**: 重新思考使用视觉变压器进行人工智能生成的图像检测
- **链接**: https://arxiv.org/abs/2512.04969
> **作者**: NaHyeon Park,Kunhee Kim,Junsuk Choe,Hyunjung Shim
> **摘要**: 来自 CLIP-ViT 的丰富特征表示已广泛应用于 AI 生成的图像检测。虽然大多数现有方法主要利用最后一层的特征，但我们系统地分析了分层特征对此任务的贡献。我们的研究表明，较早的层提供了更多的本地化和泛化特征，通常超过了检测任务中最终层特征的性能。此外，我们发现不同的层捕获数据的不同方面，每个方面对人工智能生成的图像检测都有独特的贡献。受这些发现的启发，我们引入了一种新颖的自适应方法，称为 MoLD，它使用基于门控的机制动态集成多个 ViT 层的特征。对 GAN 和扩散生成图像的大量实验表明，MoLD 显着提高了检测性能，增强了不同生成模型的泛化能力，并在现实场景中表现出鲁棒性。最后，我们通过成功地将其应用于其他预训练的 ViT（例如 DINOv2）来说明该方法的可扩展性和多功能性。
> **Abstract**: Rich feature representations derived from CLIP-ViT have been widely utilized in AI-generated image detection. While most existing methods primarily leverage features from the final layer, we systematically analyze the contributions of layer-wise features to this task. Our study reveals that earlier layers provide more localized and generalizable features, often surpassing the performance of final-layer features in detection tasks. Moreover, we find that different layers capture distinct aspects of the data, each contributing uniquely to AI-generated image detection. Motivated by these findings, we introduce a novel adaptive method, termed MoLD, which dynamically integrates features from multiple ViT layers using a gating-based mechanism. Extensive experiments on both GAN- and diffusion-generated images demonstrate that MoLD significantly improves detection performance, enhances generalization across diverse generative models, and exhibits robustness in real-world scenarios. Finally, we illustrate the scalability and versatility of our approach by successfully applying it to other pre-trained ViTs, such as DINOv2.

【25】Balanced Few-Shot Episodic Learning for Accurate Retinal Disease Diagnosis
- **标题**: 平衡的少样本情景学习可实现准确的视网膜疾病诊断
- **链接**: https://arxiv.org/abs/2512.04967
> **作者**: Jasmaine Khale,Ravi Prakash Srivastava
> **摘要**: 鉴于糖尿病视网膜病变和黄斑变性等疾病的患病率不断上升，自动化视网膜疾病诊断至关重要。传统的深度学习方法需要大量带注释的数据集，这些数据集成本高昂，而且在疾病类别之间往往不平衡，限制了其在实践中的可靠性。少样本学习 (FSL) 通过使模型能够从每个类别的少数标记样本中进行泛化来解决这一挑战。在这项研究中，我们提出了一个针对视网膜眼底多疾病图像数据集（RFMiD）量身定制的平衡的少样本情景学习框架。我们的方法专注于最具代表性的十个类别，这些类别在大多数疾病（例如，糖尿病视网膜病变、黄斑裂孔）和少数疾病（例如，视盘水肿、分支视网膜静脉阻塞）之间仍然表现出显着的不平衡，我们的方法整合了三个关键组成部分：（i）平衡的情景采样，确保所有类别平等参与每个 5 路 5 镜头事件； （ii）有针对性的增强，包括对比度有限自适应直方图均衡（CLAHE）和颜色/几何变换，以提高少数群体的多样性； (iii) 在 ImageNet 上预训练的 ResNet-50 编码器，因其捕获细粒度视网膜特征的卓越能力而被选中。在嵌入空间中计算原型，并使用余弦相似度进行分类以提高稳定性。经过 100 个集的训练和 1,000 个测试集的评估，我们的框架实现了显着的准确性提升并减少了对大多数类别的偏见，对代表性不足的疾病有了显着的改善。这些结果表明，数据集感知的少样本管道与平衡采样和 CLAHE 增强预处理相结合，可以在数据受限的条件下提供更稳健和临床公平的视网膜疾病诊断。
> **Abstract**: Automated retinal disease diagnosis is vital given the rising prevalence of conditions such as diabetic retinopathy and macular degeneration. Conventional deep learning approaches require large annotated datasets, which are costly and often imbalanced across disease categories, limiting their reliability in practice. Few-shot learning (FSL) addresses this challenge by enabling models to generalize from only a few labeled samples per class. In this study,we propose a balanced few-shot episodic learning framework tailored to the Retinal Fundus Multi-Disease Image Dataset (RFMiD). Focusing on the ten most represented classes, which still show substantial imbalance between majority diseases (e.g., Diabetic Retinopathy, Macular Hole) and minority ones (e.g., Optic Disc Edema, Branch Retinal Vein Occlusion), our method integrates three key components: (i) balanced episodic sampling, ensuring equal participation of all classes in each 5-way 5-shot episode; (ii) targeted augmentation, including Contrast Limited Adaptive Histogram Equalization (CLAHE) and color/geometry transformations, to improve minority-class di- versity; and (iii) a ResNet-50 encoder pretrained on ImageNet, selected for its superior ability to capture fine-grained retinal features. Prototypes are computed in the embedding space and classification is performed with cosine similarity for improved stability. Trained on 100 episodes and evaluated on 1,000 test episodes, our framework achieves substantial accuracy gains and reduces bias toward majority classes, with notable improvements for underrepresented diseases. These results demonstrate that dataset-aware few-shot pipelines, combined with balanced sampling and CLAHE-enhanced preprocessing, can deliver more robust and clinically fair retinal disease diagnosis under data-constrained conditions.

【26】GeoPE:A Unified Geometric Positional Embedding for Structured Tensors
- **标题**: GeoPE：结构化张量的统一几何位置嵌入
- **链接**: https://arxiv.org/abs/2512.04963
> **作者**: Yupu Yao,Bowen Yang
> **摘要**: 标准视觉变换器将 2D 图像扁平化为 1D 序列，破坏了自然空间拓扑。虽然旋转位置嵌入（RoPE）在一维方面表现出色，但它继承了这一限制，通常将空间上遥远的补丁（例如，在行边缘）视为序列邻居。现有的 2D 方法通常独立处理空间轴，无法将这种错误的顺序接近度与真实的空间距离解耦。为了恢复 2D 空间流形，我们引入了几何位置嵌入 (GeoPE)，这是一个使用四元数将旋转扩展到 3D 欧几里得空间的框架。为了克服不可交换性并确保对称性，GeoPE 通过计算李代数中的几何平均值来构造统一的旋转算子。这创建了一种有效分离空间维度的几何耦合编码。关于图像分类、对象检测和 3D 语义分割的大量实验表明，GeoPE 始终优于现有的 2D RoPE 变体，并显着增强了形状偏差，证实了其捕获真实几何结构的能力。
> **Abstract**: Standard Vision Transformers flatten 2D images into 1D sequences, disrupting the natural spatial topology. While Rotary Positional Embedding (RoPE) excels in 1D, it inherits this limitation, often treating spatially distant patches (e.g., at row edges) as sequence neighbors. Existing 2D approaches typically treat spatial axes independently, failing to decouple this false sequential proximity from true spatial distance. To restore the 2D spatial manifold, we introduce Geometric Positional Embedding (GeoPE), a framework that extends rotations to 3D Euclidean space using quaternions. To overcome non-commutativity and ensure symmetry, GeoPE constructs a unified rotational operator by computing the geometric mean in the Lie algebra. This creates a geometrically coupled encoding that effectively separates spatial dimensions. Extensive experiments on image classification, object detection, and 3D semantic segmentation demonstrate that GeoPE consistently outperforms existing 2D RoPE variants and significantly enhances shape bias, confirming its ability to capture true geometric structure.

【27】FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization
- **标题**: FASTer：通过神经动作标记化实现高效的自回归视觉语言动作建模
- **链接**: https://arxiv.org/abs/2512.04952
> **作者**: Yicheng Liu,Shiduo Zhang,Zibin Dong,Baijun Ye,Tianyuan Yuan,Xiaopeng Yu,Linqi Yin,Chenhao Lu,Junhao Shi,Luca Jiang-Tao Yu,Liangtao Zheng,Tao Jiang,Jingjing Gong,Xipeng Qiu,Hang Zhao
> **摘要**: 自回归视觉-语言-动作（VLA）模型最近在机器人操作方面表现出了强大的能力。然而，他们的动作标记化的核心过程通常涉及重建保真度和推理效率之间的权衡。我们引入了 FASTer，这是一个用于高效且可泛化的机器人学习的统一框架，它将可学习的分词器与基于其的自回归策略集成在一起。 FASTerVQ 将动作块编码为单通道图像，捕获全局时空依赖性，同时保持高压缩比。 FASTerVLA 在此分词器的基础上构建，具有分块自回归解码和轻量级动作专家，可实现更快的推理和更高的任务性能。跨模拟和现实世界基准的大量实验表明，FASTerVQ 具有卓越的重建质量、高令牌利用率以及强大的跨任务和跨实施例泛化能力，而 FASTerVLA 进一步提高了整体能力，在推理速度和任务性能方面超越了之前最先进的 VLA 模型。
> **Abstract**: Autoregressive vision-language-action (VLA) models have recently demonstrated strong capabilities in robotic manipulation. However, their core process of action tokenization often involves a trade-off between reconstruction fidelity and inference efficiency. We introduce FASTer, a unified framework for efficient and generalizable robot learning that integrates a learnable tokenizer with an autoregressive policy built upon it. FASTerVQ encodes action chunks as single-channel images, capturing global spatio-temporal dependencies while maintaining a high compression ratio. FASTerVLA builds on this tokenizer with block-wise autoregressive decoding and a lightweight action expert, achieving both faster inference and higher task performance. Extensive experiments across simulated and real-world benchmarks show that FASTerVQ delivers superior reconstruction quality, high token utilization, and strong cross-task and cross-embodiment generalization, while FASTerVLA further improves overall capability, surpassing previous state-of-the-art VLA models in both inference speed and task performance.

【28】Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition
- **标题**: 用于人类行为识别的多模态深度网络的自适应融合
- **链接**: https://arxiv.org/abs/2512.04943
> **作者**: Novanto Yudistira
> **摘要**: 这项研究通过利用深度神经网络技术和跨多种模式（包括 RGB、光流、音频和深度信息）的自适应融合策略，引入了一种开创性的人类动作识别方法。采用多模态融合的门控机制，我们的目标是超越传统单模态识别方法固有的局限性，同时探索不同应用的新可能性。通过对门控机制和基于自适应加权的融合架构的详尽研究，我们的方法能够选择性地集成来自各种模式的相关信息，从而提高动作识别任务的准确性和鲁棒性。我们仔细研究各种门控融合策略，以确定多模态动作识别的最有效方法，展示其相对于传统单模态方法的优越性。门控机制有助于提取关键特征，从而更全面地表示动作并显着增强识别性能。我们对基准数据集上的人类行为识别、暴力行为检测和多个自监督学习任务的评估表明，准确性方面取得了可喜的进步。这项研究的意义在于它有可能彻底改变不同领域的动作识别系统。多模态信息的融合有望在监控和人机交互方面实现复杂的应用，特别是在与主动辅助生活相关的环境中。
> **Abstract**: This study introduces a pioneering methodology for human action recognition by harnessing deep neural network techniques and adaptive fusion strategies across multiple modalities, including RGB, optical flows, audio, and depth information. Employing gating mechanisms for multimodal fusion, we aim to surpass limitations inherent in traditional unimodal recognition methods while exploring novel possibilities for diverse applications. Through an exhaustive investigation of gating mechanisms and adaptive weighting-based fusion architectures, our methodology enables the selective integration of relevant information from various modalities, thereby bolstering both accuracy and robustness in action recognition tasks. We meticulously examine various gated fusion strategies to pinpoint the most effective approach for multimodal action recognition, showcasing its superiority over conventional unimodal methods. Gating mechanisms facilitate the extraction of pivotal features, resulting in a more holistic representation of actions and substantial enhancements in recognition performance. Our evaluations across human action recognition, violence action detection, and multiple self-supervised learning tasks on benchmark datasets demonstrate promising advancements in accuracy. The significance of this research lies in its potential to revolutionize action recognition systems across diverse fields. The fusion of multimodal information promises sophisticated applications in surveillance and human-computer interaction, especially in contexts related to active assisted living.

【29】LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging
- **标题**: LiteVGGT：通过几何感知缓存令牌合并增强 Vanilla VGGT
- **链接**: https://arxiv.org/abs/2512.04939
> **作者**: Zhijian Shu,Cheng Lin,Tao Xie,Wei Yin,Ben Li,Zhiyuan Pu,Weize Li,Yao Yao,Xun Cao,Xiaoyang Guo,Xiao-Xiao Long
> **摘要**: Visual Geometry Grounded Transformer (VGGT) 等 3D 视觉基础模型在几何感知方面取得了巨大进步。然而，对于长序列来说，它非常耗时且占用大量内存，限制了其在超过数百张图像的大规模场景中的应用。为了解决这个问题，我们提出了 LiteVGGT，可实现高达 10 倍的加速并显着减少内存，从而能够高效处理 1000 个图像场景。我们得出了 3D 重建的两个关键见解：（1）局部图像区域的标记具有固有的几何相关性，导致高度相似性和计算冗余； (2) 相邻网络层之间的令牌相似性保持稳定，从而允许可重用​​的合并决策。在这些指导下，我们设计了一个简单而有效的策略，称为几何感知缓存令牌合并。我们分析每个标记的几何重要性，优化锚标记选择以更好地保留用于重建的关键信息。我们还跨层缓存和重用合并索引，从而以最小的准确性影响显着减少延迟。该策略保留了 VGGT 的核心性能，可实现高效的微调和 FP8 量化以获得进一步的增益。大量实验验证了 LiteVGGT 的有效性、可扩展性和鲁棒性。项目页面：https://garlicba.github.io/LiteVGGT/
> **Abstract**: 3D vision foundation models like Visual Geometry Grounded Transformer (VGGT) have advanced greatly in geometric perception. However, it is time-consuming and memory-intensive for long sequences, limiting application to large-scale scenes beyond hundreds of images. To address this, we propose LiteVGGT, achieving up to 10x speedup and substantial memory reduction, enabling efficient processing of 1000-image scenes. We derive two key insights for 3D reconstruction: (1) tokens from local image regions have inherent geometric correlations, leading to high similarity and computational redundancy; (2) token similarity across adjacent network layers remains stable, allowing for reusable merge decisions. Guided by these, we design a simple yet efficient strategy, dubbed geometry-aware cached token merging. We analyze each token's geometric importance, optimizing anchor token selection to better preserve key information for reconstruction. We also cache and reuse merge indices across layers, substantially reducing latency with minimal accuracy impact. This strategy retains VGGT's core performance, enabling efficient fine-tuning and FP8 quantization for further gains. Extensive experiments validate LiteVGGT's effectiveness, scalability, and robustness. Project page: https://garlicba.github.io/LiteVGGT/

【30】Virtually Unrolling the Herculaneum Papyri by Diffeomorphic Spiral Fitting
- **标题**: 通过微分同形螺旋拟合虚拟展开赫库兰尼姆纸莎草纸
- **链接**: https://arxiv.org/abs/2512.04927
> **作者**: Paul Henderson
> **摘要**: 赫库兰尼姆纸莎草是卷纸莎草文献的集合，这些文献在著名的维苏威火山喷发中被烧焦并掩埋。它们承诺包含大量以前未见过的希腊语和拉丁语文本，但它们极其脆弱，因此大多数无法物理展开。访问这些文本的一个解决方案是虚拟展开，其中纸莎草表面在卷轴的 CT 扫描中以数字方式描绘出来，以创建扁平的表示。在千兆像素大小的扫描中手动进行这种追踪非常费力，因此需要自动化方法。我们提出了第一种自上而下的方法，可以自动将表面模型拟合到严重损坏的卷轴的 CT 扫描中。我们采用了一种新颖的方法，将变形卷轴的显式参数模型全局拟合到现有神经网络对卷起的纸莎草可能经过的位置的预测。我们的方法保证生成的表面是单个连续的 2D 片材，甚至穿过 CT 扫描中无法检测到表面的区域。我们对两个卷轴的高分辨率 CT 扫描进行了全面的实验，表明我们的方法成功地展开了大区域，并且超过了现有的唯一适合该数据的自动展开方法的性能。
> **Abstract**: The Herculaneum Papyri are a collection of rolled papyrus documents that were charred and buried by the famous eruption of Mount Vesuvius. They promise to contain a wealth of previously unseen Greek and Latin texts, but are extremely fragile and thus most cannot be unrolled physically. A solution to access these texts is virtual unrolling, where the papyrus surface is digitally traced out in a CT scan of the scroll, to create a flattened representation. This tracing is very laborious to do manually in gigavoxel-sized scans, so automated approaches are desirable. We present the first top-down method that automatically fits a surface model to a CT scan of a severely damaged scroll. We take a novel approach that globally fits an explicit parametric model of the deformed scroll to existing neural network predictions of where the rolled papyrus likely passes. Our method guarantees the resulting surface is a single continuous 2D sheet, even passing through regions where the surface is not detectable in the CT scan. We conduct comprehensive experiments on high-resolution CT scans of two scrolls, showing that our approach successfully unrolls large regions, and exceeds the performance of the only existing automated unrolling method suitable for this data.

【31】Semantics Lead the Way: Harmonizing Semantic and Texture Modeling with Asynchronous Latent Diffusion
- **标题**: 语义引领潮流：通过异步潜在扩散协调语义和纹理建模
- **链接**: https://arxiv.org/abs/2512.04926
> **作者**: Yueming Pan,Ruoyu Feng,Qi Dai,Yuqi Wang,Wenfeng Lin,Mingyu Guo,Chong Luo,Nanning Zheng
> **摘要**: 潜在扩散模型 (LDM) 本质上遵循从粗到细的生成过程，其中高级语义结构的生成稍早于细粒度纹理。这表明前面的语义通过提供语义锚点可能有利于纹理生成。最近的进展集成了预训练视觉编码器的语义先验，以进一步增强 LDM，但它们仍然同步对语义和 VAE 编码纹理进行去噪，忽略了这种排序。观察这些，我们提出语义优先扩散（SFD），这是一种明确优先考虑语义形成的潜在扩散范式。 SFD 首先通过将紧凑的语义潜在信息与纹理潜在信息相结合来构建复合潜在信息，该语义潜在信息是通过专用语义 VAE 从预训练的视觉编码器中提取的。 SFD 的核心是使用单独的噪声调度对语义和纹理潜伏进行异步降噪：语义通过时间偏移先于纹理，为纹理细化提供更清晰的高级指导，并实现自然的从粗到细的生成。在有指导的 ImageNet 256x256 上，SFD 实现了 FID 1.06 (LightningDiT-XL) 和 FID 1.04 (1.0B LightningDiT-XXL)，同时实现比原始 DiT 快 100 倍的收敛速度。 SFD 还改进了 ReDi 和 VA-VAE 等现有方法，展示了异步、语义主导建模的有效性。项目页面及代码：https://yuemingpan.github.io/SFD.github.io/。
> **Abstract**: Latent Diffusion Models (LDMs) inherently follow a coarse-to-fine generation process, where high-level semantic structure is generated slightly earlier than fine-grained texture. This indicates the preceding semantics potentially benefit texture generation by providing a semantic anchor. Recent advances have integrated semantic priors from pretrained visual encoders to further enhance LDMs, yet they still denoise semantic and VAE-encoded texture synchronously, neglecting such ordering. Observing these, we propose Semantic-First Diffusion (SFD), a latent diffusion paradigm that explicitly prioritizes semantic formation. SFD first constructs composite latents by combining a compact semantic latent, which is extracted from a pretrained visual encoder via a dedicated Semantic VAE, with the texture latent. The core of SFD is to denoise the semantic and texture latents asynchronously using separate noise schedules: semantics precede textures by a temporal offset, providing clearer high-level guidance for texture refinement and enabling natural coarse-to-fine generation. On ImageNet 256x256 with guidance, SFD achieves FID 1.06 (LightningDiT-XL) and FID 1.04 (1.0B LightningDiT-XXL), while achieving up to 100x faster convergence than the original DiT. SFD also improves existing methods like ReDi and VA-VAE, demonstrating the effectiveness of asynchronous, semantics-led modeling. Project page and code: https://yuemingpan.github.io/SFD.github.io/.

【32】ReflexFlow: Rethinking Learning Objective for Exposure Bias Alleviation in Flow Matching
- **标题**: ReflexFlow：重新思考流量匹配中减轻曝光偏差的学习目标
- **链接**: https://arxiv.org/abs/2512.04904
> **作者**: Guanbo Huang,Jingjia Mao,Fanding Huang,Fengkai Liu,Xiangyang Luo,Yaoyuan Liang,Jiasheng Lu,Xiaoe Wang,Pei Liu,Ruiliu Fu,Shao-Lun Huang
> **摘要**: 尽管最近取得了巨大进展，但由于训练和推理的差异，流匹配方法仍然存在暴露偏差。本文研究了流匹配中暴露偏差的根本原因，包括：（1）模型在训练过程中缺乏对有偏差输入的泛化，（2）早期去噪过程中捕获的低频内容不足，导致累积偏差。基于这些见解，我们提出了 ReflexFlow，这是对 Flow Matching 学习目标的简单而有效的反射性改进，可以动态纠正暴露偏差。 ReflexFlow 由两个组件组成：（1）抗漂移校正（ADR），它利用训练时间计划采样下重新设计的损失，反射性地调整有偏差输入的预测目标； (2)频率补偿(FC)，反映丢失的低频分量，并通过使用曝光偏差重新加权损失来补偿它们。 ReflexFlow 与模型无关，与所有流匹配框架兼容，并提高了跨数据集的生成质量。 CIFAR-10、CelebA-64 和 ImageNet-256 上的实验表明，ReflexFlow 在减轻曝光偏差方面优于先前的方法，在 CelebA-64 上实现了 35.65% 的 FID 降低。
> **Abstract**: Despite tremendous recent progress, Flow Matching methods still suffer from exposure bias due to discrepancies in training and inference. This paper investigates the root causes of exposure bias in Flow Matching, including: (1) the model lacks generalization to biased inputs during training, and (2) insufficient low-frequency content captured during early denoising, leading to accumulated bias. Based on these insights, we propose ReflexFlow, a simple and effective reflexive refinement of the Flow Matching learning objective that dynamically corrects exposure bias. ReflexFlow consists of two components: (1) Anti-Drift Rectification (ADR), which reflexively adjusts prediction targets for biased inputs utilizing a redesigned loss under training-time scheduled sampling; and (2) Frequency Compensation (FC), which reflects on missing low-frequency components and compensates them by reweighting the loss using exposure bias. ReflexFlow is model-agnostic, compatible with all Flow Matching frameworks, and improves generation quality across datasets. Experiments on CIFAR-10, CelebA-64, and ImageNet-256 show that ReflexFlow outperforms prior approaches in mitigating exposure bias, achieving a 35.65% reduction in FID on CelebA-64.

【33】Equivariant Symmetry-Aware Head Pose Estimation for Fetal MRI
- **标题**: 胎儿 MRI 的等变对称感知头部姿势估计
- **链接**: https://arxiv.org/abs/2512.04890
> **作者**: Ramya Muthukrishnan,Borjan Gagoski,Aryn Lee,P. Ellen Grant,Elfar Adalsteinsson,Polina Golland,Benjamin Billot
> **摘要**: 我们提出了 E(3)-Pose，这是一种新颖的快速姿态估计方法，可以联合、显式地对旋转等方差和对象对称性进行建模。我们的工作源于在诊断 MRI 扫描期间解释胎儿头部运动这一具有挑战性的问题。我们的目标是通过在每个 2D 切片之前快速获取的 3D MRI 体积的支持，通过 6-DoF 头部姿势估计实现 2D 诊断 MRI 切片的自动自适应处方。由于固有的解剖对称性以及低分辨率、噪声和伪影引起的姿势模糊，现有方法很难推广到临床体积。相比之下，E(3)-Pose 通过构造捕获解剖对称性和刚性姿势等变性，并产生胎儿头部姿势的稳健估计。我们在公开的、具有代表性的临床胎儿 MRI 数据集上进行的实验证明了我们的方法在跨领域具有卓越的稳健性和泛化性。至关重要的是，E(3)-Pose 在临床 MRI 体积上实现了最先进的准确性，为临床转化铺平了道路。我们的实现可在 github.com/ramyamut/E3-Pose 获取。
> **Abstract**: We present E(3)-Pose, a novel fast pose estimation method that jointly and explicitly models rotation equivariance and object symmetry. Our work is motivated by the challenging problem of accounting for fetal head motion during a diagnostic MRI scan. We aim to enable automatic adaptive prescription of 2D diagnostic MRI slices with 6-DoF head pose estimation, supported by 3D MRI volumes rapidly acquired before each 2D slice. Existing methods struggle to generalize to clinical volumes, due to pose ambiguities induced by inherent anatomical symmetries, as well as low resolution, noise, and artifacts. In contrast, E(3)-Pose captures anatomical symmetries and rigid pose equivariance by construction, and yields robust estimates of the fetal head pose. Our experiments on publicly available and representative clinical fetal MRI datasets demonstrate the superior robustness and generalization of our method across domains. Crucially, E(3)-Pose achieves state-of-the-art accuracy on clinical MRI volumes, paving the way for clinical translation. Our implementation is available at github.com/ramyamut/E3-Pose.

【34】You Only Train Once (YOTO): A Retraining-Free Object Detection Framework
- **标题**: You Only Train Once (YOTO)：无需重新训练的目标检测框架
- **链接**: https://arxiv.org/abs/2512.04888
> **作者**: Priyanto Hidayatullah,Nurjannah Syakrani,Yudi Widhiyasana,Muhammad Rizqi Sholahuddin,Refdinal Tubagus,Zahri Al Adzani Hidayat,Hanri Fajar Ramadhan,Dafa Alfarizki Pratama,Farhan Muhammad Yasin
> **摘要**: 目标检测构成计算机视觉领域的主要任务。它被用于许多领域。尽管如此，物体检测仍然遇到灾难性遗忘的问题。每当推出新产品时，都必须重新训练模型，不仅利用新产品数据集，而且利用整个以前的数据集。结果很明显：模型训练费用增加，时间消耗显着。在许多领域，尤其是零售收银领域，新产品的频繁推出带来了巨大的挑战。本研究引入了 You Only Train Once (YOTO) 方法，该方法旨在通过将用于对象定位的 YOLO11n 与用于特征提取和度量学习的 DeIT 和 Proxy Anchor Loss 集成来解决灾难性遗忘问题。为了进行分类，我们利用目标产品的嵌入特征与 Qdrant 矢量数据库中的嵌入特征之间的余弦相似度。在一家拥有 140 种产品的零售店进行的案例研究中，实验结果表明，无论是检测新产品还是现有产品，我们提出的框架都实现了令人鼓舞的准确性。此外，在没有重新训练的情况下，训练持续时间差异很大。与传统的目标检测方法相比，我们的训练时间效率几乎提高了 3 倍。随着更多新产品添加到产品数据库中，这种效率会不断提高。在边缘设备上，每个包含多个产品的图像的平均推理时间为 580 毫秒，验证了所提出的框架的实际使用可行性。
> **Abstract**: Object detection constitutes the primary task within the domain of computer vision. It is utilized in numerous domains. Nonetheless, object detection continues to encounter the issue of catastrophic forgetting. The model must be retrained whenever new products are introduced, utilizing not only the new products dataset but also the entirety of the previous dataset. The outcome is obvious: increasing model training expenses and significant time consumption. In numerous sectors, particularly retail checkout, the frequent introduction of new products presents a great challenge. This study introduces You Only Train Once (YOTO), a methodology designed to address the issue of catastrophic forgetting by integrating YOLO11n for object localization with DeIT and Proxy Anchor Loss for feature extraction and metric learning. For classification, we utilize cosine similarity between the embedding features of the target product and those in the Qdrant vector database. In a case study conducted in a retail store with 140 products, the experimental results demonstrate that our proposed framework achieves encouraging accuracy, whether for detecting new or existing products. Furthermore, without retraining, the training duration difference is significant. We achieve almost 3 times the training time efficiency compared to classical object detection approaches. This efficiency escalates as additional new products are added to the product database. The average inference time is 580 ms per image containing multiple products, on an edge device, validating the proposed framework's feasibility for practical use.

【35】SDG-Track: A Heterogeneous Observer-Follower Framework for High-Resolution UAV Tracking on Embedded Platforms
- **标题**: SDG-Track：嵌入式平台上高分辨率无人机跟踪的异构观察者跟随者框架
- **链接**: https://arxiv.org/abs/2512.04883
> **作者**: Jiawen Wen,Yu Hu,Suixuan Qiu,Jinshan Huang,Xiaowen Chu
> **摘要**: 边缘设备上小型无人机（UAV）的实时跟踪面临着根本的分辨率与速度冲突。将高分辨率图像下采样到标准探测器输入大小会导致小目标特征崩溃到可检测阈值以下。然而，在资源有限的平台上处理原生 1080p 帧的吞吐量不足以实现平稳的万向节控制。我们提出了SDG-Track，一种稀疏检测引导的跟踪器，它采用观察者-跟随者架构来协调这种冲突。观察者流在 GPU 上以低频运行高容量检测器，以提供 1920x1080 帧的准确位置锚点。 Follower 流通过 CPU 上 ROI 约束的稀疏光流执行高频轨迹插值。为了处理由光谱相似的干扰物引起的遮挡或模型漂移导致的跟踪失败，我们引入了双空间恢复，这是一种将颜色直方图匹配与几何一致性约束相结合的免训练重新获取机制。地对空跟踪站的实验表明，SDG-Track 实现了 35.1 FPS 的系统吞吐量，同时保留了 97.2% 的逐帧检测精度。该系统在 NVIDIA Jetson Orin Nano 上成功跟踪现实操作条件下的灵活 FPV 无人机。我们的纸质代码可在 https://github.com/Jeffry-wen/SDG-Track 上公开获取
> **Abstract**: Real-time tracking of small unmanned aerial vehicles (UAVs) on edge devices faces a fundamental resolution-speed conflict. Downsampling high-resolution imagery to standard detector input sizes causes small target features to collapse below detectable thresholds. Yet processing native 1080p frames on resource-constrained platforms yields insufficient throughput for smooth gimbal control. We propose SDG-Track, a Sparse Detection-Guided Tracker that adopts an Observer-Follower architecture to reconcile this conflict. The Observer stream runs a high-capacity detector at low frequency on the GPU to provide accurate position anchors from 1920x1080 frames. The Follower stream performs high-frequency trajectory interpolation via ROI-constrained sparse optical flow on the CPU. To handle tracking failures from occlusion or model drift caused by spectrally similar distractors, we introduce Dual-Space Recovery, a training-free re-acquisition mechanism combining color histogram matching with geometric consistency constraints. Experiments on a ground-to-air tracking station demonstrate that SDG-Track achieves 35.1 FPS system throughput while retaining 97.2\% of the frame-by-frame detection precision. The system successfully tracks agile FPV drones under real-world operational conditions on an NVIDIA Jetson Orin Nano. Our paper code is publicly available at https://github.com/Jeffry-wen/SDG-Track

【36】SP-Det: Self-Prompted Dual-Text Fusion for Generalized Multi-Label Lesion Detection
- **标题**: SP-Det：用于广义多标签病变检测的自提示双文本融合
- **链接**: https://arxiv.org/abs/2512.04875
> **作者**: Qing Xu,Yanqian Wang,Xiangjian Hea,Yue Li,Yixuan Zhang,Rong Qu,Wenting Duan,Zhen Chen
> **摘要**: 胸部 X 光检查中的自动病变检测已显示出通过精确定位病理异常来改善临床诊断的巨大潜力。虽然最近的提示检测框架在目标定位方面取得了显着的准确性，但现有方法通常依赖于手动注释作为提示，这对于临床应用来说是劳动密集型且不切实际的。为了解决这个限制，我们提出了 SP-Det，这是一种新颖的自我提示检测框架，可以自动生成丰富的文本上下文来指导多标签病变检测，而无需专家注释。具体来说，我们引入了一种无需专家的双文本提示生成器（DTPG），它利用两种互补的文本模式：捕获全局病理模式的语义上下文提示和专注于疾病特定表现的疾病信标提示。此外，我们设计了一种双向特征增强器（BFE），它将全面的诊断上下文与特定于疾病的嵌入协同集成，以显着提高特征表示和检测准确性。对具有不同胸部疾病类别的两个胸部 X 射线数据集进行的广泛实验表明，我们的 SP-Det 框架优于最先进的检测方法，同时与现有的提示架构相比，完全消除了对专家注释提示的依赖。
> **Abstract**: Automated lesion detection in chest X-rays has demonstrated significant potential for improving clinical diagnosis by precisely localizing pathological abnormalities. While recent promptable detection frameworks have achieved remarkable accuracy in target localization, existing methods typically rely on manual annotations as prompts, which are labor-intensive and impractical for clinical applications. To address this limitation, we propose SP-Det, a novel self-prompted detection framework that automatically generates rich textual context to guide multi-label lesion detection without requiring expert annotations. Specifically, we introduce an expert-free dual-text prompt generator (DTPG) that leverages two complementary textual modalities: semantic context prompts that capture global pathological patterns and disease beacon prompts that focus on disease-specific manifestations. Moreover, we devise a bidirectional feature enhancer (BFE) that synergistically integrates comprehensive diagnostic context with disease-specific embeddings to significantly improve feature representation and detection accuracy. Extensive experiments on two chest X-ray datasets with diverse thoracic disease categories demonstrate that our SP-Det framework outperforms state-of-the-art detection methods while completely eliminating the dependency on expert-annotated prompts compared to existing promptable architectures.

【37】Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing
- **标题**: 通过生物阻抗传感对人体姿势伪地面实况进行接触感知细化
- **链接**: https://arxiv.org/abs/2512.04862
> **作者**: Maria-Paola Forte,Nikos Athanasiou,Giulia Ballardini,Jan Ulrich Bartels,Katherine J. Kuchenbecker,Michael J. Black
> **摘要**: 在野外捕获准确的 3D 人体姿势将为训练姿势估计和运动生成方法提供有价值的数据。虽然基于视频的估计方法变得越来越准确，但它们在涉及自我接触的常见场景中经常失败，例如手触摸脸部。相比之下，可穿戴生物阻抗传感可以廉价且不引人注目地测量真实的皮肤与皮肤接触。因此，我们提出了一种新颖的框架，将视觉姿势估计器与生物阻抗传感相结合，通过考虑自接触来捕获人的 3D 姿势。我们的方法 BioTUCH 使用现成的估计器初始化姿势，并在测量的自接触过程中引入接触感知姿势优化：在强制顶点邻近约束的同时，最小化重投影误差和与输入估计的偏差。我们使用同步 RGB 视频、生物阻抗测量和 3D 动作捕捉的新数据集来验证我们的方法。使用三个输入姿态估计器进行测试，我们证明重建精度平均提高了 11.7%。我们还推出了一种微型可穿戴生物阻抗传感器，能够有效地大规模收集接触感知训练数据，从而使用 BioTUCH 改进姿势估计和生成。代码和数据可在 biotuch.is.tue.mpg.de 获取
> **Abstract**: Capturing accurate 3D human pose in the wild would provide valuable data for training pose estimation and motion generation methods. While video-based estimation approaches have become increasingly accurate, they often fail in common scenarios involving self-contact, such as a hand touching the face. In contrast, wearable bioimpedance sensing can cheaply and unobtrusively measure ground-truth skin-to-skin contact. Consequently, we propose a novel framework that combines visual pose estimators with bioimpedance sensing to capture the 3D pose of people by taking self-contact into account. Our method, BioTUCH, initializes the pose using an off-the-shelf estimator and introduces contact-aware pose optimization during measured self-contact: reprojection error and deviations from the input estimate are minimized while enforcing vertex proximity constraints. We validate our approach using a new dataset of synchronized RGB video, bioimpedance measurements, and 3D motion capture. Testing with three input pose estimators, we demonstrate an average of 11.7% improvement in reconstruction accuracy. We also present a miniature wearable bioimpedance sensor that enables efficient large-scale collection of contact-aware training data for improving pose estimation and generation using BioTUCH. Code and data are available at biotuch.is.tue.mpg.de

【38】Autoregressive Image Generation Needs Only a Few Lines of Cached Tokens
- **标题**: 自回归图像生成仅需要几行缓存令牌
- **链接**: https://arxiv.org/abs/2512.04857
> **作者**: Ziran Qin,Youru Lv,Mingbao Lin,Zeren Zhang,Chanfan Gan,Tieyuan Chen,Weiyao Lin
> **摘要**: 由于其可扩展性和通用性，自回归（AR）视觉生成已成为图像和多模态合成的强大范例。然而，由于在解码过程中需要缓存所有先前生成的视觉标记，现有的 AR 图像生成面临严重的内存瓶颈，导致存储需求高和吞吐量低。在本文中，我们介绍了 \textbf{LineAR}，这是一种新颖的、免训练的渐进式键值 (KV) 缓存压缩管道，用于自回归图像生成。通过充分利用视觉注意力的内在特征，LineAR 使用 2D 视图在行级别管理缓存，保留视觉依赖区域，同时在行间注意力的指导下逐步驱逐对后续行生成无害的信息较少的标记。 LineAR 仅利用几行缓存即可实现高效的自回归 (AR) 图像生成，从而节省内存并提高吞吐量，同时保持甚至提高生成质量。六种自回归图像生成模型（包括类条件和文本到图像生成）的广泛实验验证了其有效性和通用性。 LineAR 在 LlamaGen-XL 和 Janus-Pro-1B 上将 ImageNet FID 从 2.77 提高到 2.68，将 COCO FID 从 23.85 提高到 22.86，同时仅保留 1/6 KV 缓存。它还改进了 Lumina-mGPT-768 上的 DPG，仅具有 1/8 KV 缓存。此外，LineAR 还实现了显着的内存和吞吐量增益，包括在 LlamaGen-XL 上内存减少高达 67.61%，加速提高 7.57 倍，在 Janus-Pro-7B 上内存减少 39.66%，加速提高 5.62 倍。
> **Abstract**: Autoregressive (AR) visual generation has emerged as a powerful paradigm for image and multimodal synthesis, owing to its scalability and generality. However, existing AR image generation suffers from severe memory bottlenecks due to the need to cache all previously generated visual tokens during decoding, leading to both high storage requirements and low throughput. In this paper, we introduce \textbf{LineAR}, a novel, training-free progressive key-value (KV) cache compression pipeline for autoregressive image generation. By fully exploiting the intrinsic characteristics of visual attention, LineAR manages the cache at the line level using a 2D view, preserving the visual dependency regions while progressively evicting less-informative tokens that are harmless for subsequent line generation, guided by inter-line attention. LineAR enables efficient autoregressive (AR) image generation by utilizing only a few lines of cache, achieving both memory savings and throughput speedup, while maintaining or even improving generation quality. Extensive experiments across six autoregressive image generation models, including class-conditional and text-to-image generation, validate its effectiveness and generality. LineAR improves ImageNet FID from 2.77 to 2.68 and COCO FID from 23.85 to 22.86 on LlamaGen-XL and Janus-Pro-1B, while retaining only 1/6 KV cache. It also improves DPG on Lumina-mGPT-768 with just 1/8 KV cache. Additionally, LineAR achieves significant memory and throughput gains, including up to 67.61% memory reduction and 7.57x speedup on LlamaGen-XL, and 39.66% memory reduction and 5.62x speedup on Janus-Pro-7B.

【39】A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World
- **标题**: 现实世界中多域人脸伪造检测的健全性检查
- **链接**: https://arxiv.org/abs/2512.04837
> **作者**: Jikang Cheng,Renye Yan,Zhiyuan Yan,Yaozhong Gan,Xueyi Zhang,Zhongyuan Wang,Wei Peng,Ling Liang
> **摘要**: 现有的深度伪造检测方法旨在开发通用检测器。尽管“泛化”是一劳永逸的最终目标，但由于训练伪造和领域有限，期望泛化涵盖完全看不见的变化似乎是理想化的，特别是考虑到现实世界深度伪造品的多样性。因此，引入大规模多领域数据进行训练对于实际应用来说是可行且重要的。然而，在这样的多域场景中，多个域之间的差异，而不是微妙的真/假区别，主导了特征空间。因此，尽管检测器能够在每个域内相对区分真假（即高 AUC），但它们在域未指定条件（即低 ACC）下难以进行单图像真/假判断。在本文中，我们首先定义了一种名为多域内人脸伪造检测（MID-FFD）的新研究范式，其中包括足够数量的真假域用于训练。然后，检测器应该对域未指定的输入提供明确的真假判断，模拟现实世界中逐帧独立的检测场景。同时，为了解决领域主导问题，我们提出了一个名为 DevDet（检测器开发人员）的模型无关框架，以放大真/假差异并使它们在特征空间中占主导地位。 DevDet 由面部伪造开发人员 (FFDev) 和剂量自适应检测器微调策略 (DAFT) 组成。实验证明了我们在 MID-FFD 场景下预测真假的优越性，同时保持了对未见数据的原始泛化能力。
> **Abstract**: Existing methods for deepfake detection aim to develop generalizable detectors. Although "generalizable" is the ultimate target once and for all, with limited training forgeries and domains, it appears idealistic to expect generalization that covers entirely unseen variations, especially given the diversity of real-world deepfakes. Therefore, introducing large-scale multi-domain data for training can be feasible and important for real-world applications. However, within such a multi-domain scenario, the differences between multiple domains, rather than the subtle real/fake distinctions, dominate the feature space. As a result, despite detectors being able to relatively separate real and fake within each domain (i.e., high AUC), they struggle with single-image real/fake judgments in domain-unspecified conditions (i.e., low ACC). In this paper, we first define a new research paradigm named Multi-In-Domain Face Forgery Detection (MID-FFD), which includes sufficient volumes of real-fake domains for training. Then, the detector should provide definitive real-fake judgments to the domain-unspecified inputs, which simulate the frame-by-frame independent detection scenario in the real world. Meanwhile, to address the domain-dominant issue, we propose a model-agnostic framework termed DevDet (Developer for Detector) to amplify real/fake differences and make them dominant in the feature space. DevDet consists of a Face Forgery Developer (FFDev) and a Dose-Adaptive detector Fine-Tuning strategy (DAFT). Experiments demonstrate our superiority in predicting real-fake under the MID-FFD scenario while maintaining original generalization ability to unseen data.

【40】Tokenizing Buildings: A Transformer for Layout Synthesis
- **标题**: 标记化建筑物：布局综合的转换器
- **链接**: https://arxiv.org/abs/2512.04832
> **作者**: Manuel Ladron de Guevara,Jinmo Rhee,Ardavan Bidgoli,Vaidas Razgaitis,Michael Bergin
> **摘要**: 我们介绍小型建筑模型 (SBM)，这是一种基于 Transformer 的架构，用于建筑信息模型 (BIM) 场景中的布局合成。我们解决了如何通过将建筑元素的异构特征集统一到序列中来标记建筑物的问题，同时保留组合结构。此类特征集表示为捕获房间属性的稀疏属性特征矩阵。然后，我们设计一个统一的嵌入模块，用于学习分类和可能相关的连续特征组的联合表示。最后，我们以两种模式训练单个 Transformer 主干：产生高保真房间嵌入的仅编码器路径，以及用于房间实体自回归预测的编码器-解码器管道，称为数据驱动实体预测（DDEP）。检索和生成布局综合的实验表明，SBM 学习紧凑的房间嵌入，这些嵌入可以按类型和拓扑可靠地聚类，从而实现强大的语义检索。在 DDEP 模式下，SBM 生成功能健全的布局，减少碰撞和边界违规，并提高导航性。
> **Abstract**: We introduce Small Building Model (SBM), a Transformer-based architecture for layout synthesis in Building Information Modeling (BIM) scenes. We address the question of how to tokenize buildings by unifying heterogeneous feature sets of architectural elements into sequences while preserving compositional structure. Such feature sets are represented as a sparse attribute-feature matrix that captures room properties. We then design a unified embedding module that learns joint representations of categorical and possibly correlated continuous feature groups. Lastly, we train a single Transformer backbone in two modes: an encoder-only pathway that yields high-fidelity room embeddings, and an encoder-decoder pipeline for autoregressive prediction of room entities, referred to as Data-Driven Entity Prediction (DDEP). Experiments across retrieval and generative layout synthesis show that SBM learns compact room embeddings that reliably cluster by type and topology, enabling strong semantic retrieval. In DDEP mode, SBM produces functionally sound layouts, with fewer collisions and boundary violations and improved navigability.

【41】FreeGen: Feed-Forward Reconstruction-Generation Co-Training for Free-Viewpoint Driving Scene Synthesis
- **标题**: FreeGen：用于自由视点驾驶场景合成的前馈重建生成协同训练
- **链接**: https://arxiv.org/abs/2512.04830
> **作者**: Shijie Chen,Peixi Peng
> **摘要**: 自动驾驶的闭环模拟和可扩展预训练需要合成自由视点驾驶场景。然而，现有的数据集和生成管道很少提供一致的偏离轨迹观察，限制了大规模评估和训练。虽然最近的生成模型表现出很强的视觉真实感，但它们很难在没有每个场景优化的情况下共同实现插值一致性和外推真实感。为了解决这个问题，我们提出了 FreeGen，一种用于自由视点驾驶场景合成的前馈重建生成协同训练框架。重建模型提供稳定的几何表示以确保插值一致性，而生成模型执行几何感知增强以提高看不见的视点的真实感。通过协同训练，生成先验被提炼到重建模型中以改善偏离轨迹渲染，而细化的几何形状反过来为生成提供了更强的结构指导。实验表明，FreeGen 在自由视点驾驶场景合成方面实现了最先进的性能。
> **Abstract**: Closed-loop simulation and scalable pre-training for autonomous driving require synthesizing free-viewpoint driving scenes. However, existing datasets and generative pipelines rarely provide consistent off-trajectory observations, limiting large-scale evaluation and training. While recent generative models demonstrate strong visual realism, they struggle to jointly achieve interpolation consistency and extrapolation realism without per-scene optimization. To address this, we propose FreeGen, a feed-forward reconstruction-generation co-training framework for free-viewpoint driving scene synthesis. The reconstruction model provides stable geometric representations to ensure interpolation consistency, while the generation model performs geometry-aware enhancement to improve realism at unseen viewpoints. Through co-training, generative priors are distilled into the reconstruction model to improve off-trajectory rendering, and the refined geometry in turn offers stronger structural guidance for generation. Experiments demonstrate that FreeGen achieves state-of-the-art performance for free-viewpoint driving scene synthesis.

【42】LatentFM: A Latent Flow Matching Approach for Generative Medical Image Segmentation
- **标题**: LatentFM：用于生成医学图像分割的潜在流匹配方法
- **链接**: https://arxiv.org/abs/2512.04821
> **作者**: Huynh Trinh Ngoc,Hoang Anh Nguyen Kim,Toan Nguyen Hai,Long Tran Quoc
> **摘要**: 随着流匹配（FM）的出现，生成模型取得了显着的进步。它展示了强大的生成能力，并作为一种能够学习精确数据密度的无模拟、基于流的框架而引起了广泛关注。受这些进步的推动，我们提出了 LatentFM，这是一种在潜在空间中运行的基于流的模型，用于医学图像分割。为了对数据分布进行建模，我们首先设计了两个变分自动编码器（VAE），将医学图像及其相应的掩模编码到低维潜在空间中。然后，我们根据输入图像估计引导流动的条件速度场。通过对多个潜在表示进行采样，我们的方法合成了不同的分割输出，其像素级方差可靠地捕获了底层数据分布，从而实现了高度准确和不确定性感知的预测。此外，我们生成量化模型确定性的置信图，为临床医生提供更丰富的信息以进行更深入的分析。我们在 ISIC-2018 和 CVC-Clinic 这两个数据集上进行实验，并将我们的方法与之前的几个基线（包括确定性和生成方法模型）进行比较。通过综合评估，定性和定量结果表明，我们的方法实现了卓越的分割精度，同时在潜在空间中保持高效。
> **Abstract**: Generative models have achieved remarkable progress with the emergence of flow matching (FM). It has demonstrated strong generative capabilities and attracted significant attention as a simulation-free flow-based framework capable of learning exact data densities. Motivated by these advances, we propose LatentFM, a flow-based model operating in the latent space for medical image segmentation. To model the data distribution, we first design two variational autoencoders (VAEs) to encode both medical images and their corresponding masks into a lower-dimensional latent space. We then estimate a conditional velocity field that guides the flow based on the input image. By sampling multiple latent representations, our method synthesizes diverse segmentation outputs whose pixel-wise variance reliably captures the underlying data distribution, enabling both highly accurate and uncertainty-aware predictions. Furthermore, we generate confidence maps that quantify the model certainty, providing clinicians with richer information for deeper analysis. We conduct experiments on two datasets, ISIC-2018 and CVC-Clinic, and compare our method with several prior baselines, including both deterministic and generative approach models. Through comprehensive evaluations, both qualitative and quantitative results show that our approach achieves superior segmentation accuracy while remaining highly efficient in the latent space.

【43】RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS
- **标题**: RobustSplat++：解耦野外 3DGS 的致密化、动力学和照明
- **链接**: https://arxiv.org/abs/2512.04815
> **作者**: Chuanyu Fu,Guanying Chen,Yuqi Zhang,Kunbin Yao,Yuan Xiong,Chuan Huang,Shuguang Cui,Yasuyuki Matsushita,Xiaochun Cao
> **摘要**: 3D 高斯溅射 (3DGS) 因其在新颖视图合成和 3D 建模中的实时、逼真渲染而受到广泛关注。然而，现有的方法很难准确地建模受瞬态物体和照明影响的野外场景，从而导致渲染图像中出现伪影。我们发现，高斯致密化过程在增强场景细节捕捉的同时，通过增加模拟瞬态干扰和照明变化的额外高斯，无意中导致了这些伪影。为了解决这个问题，我们提出了 RobustSplat++，这是一种基于多个关键设计的稳健解决方案。首先，我们引入了延迟高斯增长策略，该策略在允许高斯分割/克隆之前优先优化静态场景结构，从而减轻早期优化中对瞬态对象的过度拟合。其次，我们设计了一种尺度级联掩模自举方法，该方法首先利用较低分辨率的特征相似性监督来进行可靠的初始瞬态掩模估计，利用其更强的语义一致性和对噪声的鲁棒性，然后进行高分辨率监督以实现更精确的掩模预测。第三，我们将延迟高斯增长策略和掩模引导与外观建模相结合，以处理包括瞬态和照明在内的野外场景。对多个具有挑战性的数据集的大量实验表明，我们的方法优于现有方法，清楚地证明了我们方法的稳健性和有效性。
> **Abstract**: 3D Gaussian Splatting (3DGS) has gained significant attention for its real-time, photo-realistic rendering in novel-view synthesis and 3D modeling. However, existing methods struggle with accurately modeling in-the-wild scenes affected by transient objects and illuminations, leading to artifacts in the rendered images. We identify that the Gaussian densification process, while enhancing scene detail capture, unintentionally contributes to these artifacts by growing additional Gaussians that model transient disturbances and illumination variations. To address this, we propose RobustSplat++, a robust solution based on several critical designs. First, we introduce a delayed Gaussian growth strategy that prioritizes optimizing static scene structure before allowing Gaussian splitting/cloning, mitigating overfitting to transient objects in early optimization. Second, we design a scale-cascaded mask bootstrapping approach that first leverages lower-resolution feature similarity supervision for reliable initial transient mask estimation, taking advantage of its stronger semantic consistency and robustness to noise, and then progresses to high-resolution supervision to achieve more precise mask prediction. Third, we incorporate the delayed Gaussian growth strategy and mask bootstrapping with appearance modeling to handling in-the-wild scenes including transients and illuminations. Extensive experiments on multiple challenging datasets show that our method outperforms existing methods, clearly demonstrating the robustness and effectiveness of our method.

【44】EMMA: Efficient Multimodal Understanding, Generation, and Editing with a Unified Architecture
- **标题**: EMMA：通过统一架构进行高效的多模式理解、生成和编辑
- **链接**: https://arxiv.org/abs/2512.04810
> **作者**: Xin He,Longhui Wei,Jianbo Ouyang,Lingxi Xie,Qi Tian
> **摘要**: 我们提出了 EMMA，一种用于多模态理解、生成和编辑的高效且统一的架构。具体来说，EMMA 主要包括 1) 具有 32 倍压缩比的高效自动编码器，可显着减少生成所需的令牌数量。通过对图像应用相同的压缩比，这还确保了理解和生成任务之间的训练平衡。 2）视觉理解和生成标记之间按通道级联而不是按标记级联，这进一步减少了统一架构中的视觉标记。 3）共享和解耦的网络，可以实现跨任务的相互改进，同时满足特定于任务的建模要求。 4）视觉理解编码器采用专家混合机制，通过少量参数的增加大幅提高感知能力。大量实验表明，EMMA-4B 在效率和性能方面都可以显着优于最先进的统一多模态方法（例如 BAGEL-7B），同时与最近的多模态理解和生成专家（例如 Qwen3-VL 和 Qwen-Image）相比也取得了有竞争力的结果。我们相信EMMA为统一多模式架构的未来发展奠定了坚实的基础。
> **Abstract**: We propose EMMA, an efficient and unified architecture for multimodal understanding, generation and editing. Specifically, EMMA primarily consists of 1) An efficient autoencoder with a 32x compression ratio, which significantly reduces the number of tokens required for generation. This also ensures the training balance between understanding and generation tasks by applying the same compression ratio to images. 2) Channel-wise concatenation instead of token-wise concatenation among visual understanding and generation tokens, which further reduces the visual tokens in unified architectures. 3) A shared-and-decoupled network that enables mutual improvements across tasks while meeting the task-specific modeling requirements. 4) A mixture-of-experts mechanism adopted for visual understanding encoder, which substantially improves perceptual capabilities with a few parameters increase. Extensive experiments have shown that EMMA-4B can significantly outperform state-of-the-art unified multimodal approaches (e.g., BAGEL-7B) in both efficiency and performance, while also achieving competitive results compared to recent multimodal understanding and generation experts (e.g., Qwen3-VL and Qwen-Image). We believe that EMMA lays a solid foundation for the future development of unified multimodal architectures.

【45】LaFiTe: A Generative Latent Field for 3D Native Texturing
- **标题**: LaFiTe：3D 原生纹理的生成潜在场
- **链接**: https://arxiv.org/abs/2512.04786
> **作者**: Chia-Hao Chen,Zi-Xin Zou,Yan-Pei Cao,Ze Yuan,Guan Luo,Xiaojuan Qi,Ding Liang,Song-Hai Zhang,Yuan-Chen Guo
> **摘要**: 直接在 3D 表面上生成高保真、无缝纹理（我们称之为 3D 原生纹理）仍然是一个基本的开放挑战，有可能克服基于 UV 和多视图投影方法的长期限制。然而，现有的本机方法由于缺乏强大且通用的潜在表示而受到限制，这严重限制了其生成的纹理的保真度和通用性。我们认为这种代表性差距是进一步进步的主要障碍。我们引入了 LaFiTe，这是一个通过学习生成纹理作为 3D 生成稀疏潜在色域来解决这一挑战的框架。 LaFiTe 的核心采用变分自动编码器 (VAE) 将复杂的表面外观编码到稀疏、结构化的潜在空间中，随后将其解码为连续的色域。通过有效地从网格拓扑和 UV 参数化中分离纹理外观，这种表示实现了前所未有的保真度，在重建中超过了最先进的方法 >10 dB PSNR。基于这种强大的表征，条件整流流模型合成了跨不同风格和几何形状的高质量、连贯的纹理。大量实验表明，LaFiTe 不仅为 3D 原生纹理树立了新基准，而且还实现了材料合成和纹理超分辨率等灵活的下游应用，为下一代 3D 内容创建工作流程铺平了道路。
> **Abstract**: Generating high-fidelity, seamless textures directly on 3D surfaces, what we term 3D-native texturing, remains a fundamental open challenge, with the potential to overcome long-standing limitations of UV-based and multi-view projection methods. However, existing native approaches are constrained by the absence of a powerful and versatile latent representation, which severely limits the fidelity and generality of their generated textures. We identify this representation gap as the principal barrier to further progress. We introduce LaFiTe, a framework that addresses this challenge by learning to generate textures as a 3D generative sparse latent color field. At its core, LaFiTe employs a variational autoencoder (VAE) to encode complex surface appearance into a sparse, structured latent space, which is subsequently decoded into a continuous color field. This representation achieves unprecedented fidelity, exceeding state-of-the-art methods by >10 dB PSNR in reconstruction, by effectively disentangling texture appearance from mesh topology and UV parameterization. Building upon this strong representation, a conditional rectified-flow model synthesizes high-quality, coherent textures across diverse styles and geometries. Extensive experiments demonstrate that LaFiTe not only sets a new benchmark for 3D-native texturing but also enables flexible downstream applications such as material synthesis and texture super-resolution, paving the way for the next generation of 3D content creation workflows.

【46】PaCo-RL: Advancing Reinforcement Learning for Consistent Image Generation with Pairwise Reward Modeling
- **标题**: PaCo-RL：通过成对奖励模型推进强化学习以实现一致的图像生成
- **链接**: https://arxiv.org/abs/2512.04784
> **作者**: Bowen Ping,Chengyou Jia,Minnan Luo,Changliang Xia,Xin Shen,Zhuohang Dang,Hangwei Qian
> **摘要**: 一致的图像生成需要忠实地保留多个图像之间的身份、风格和逻辑一致性，这对于讲故事和角色设计等应用程序至关重要。由于缺乏捕获视觉一致性的大规模数据集以及人类感知偏好建模的复杂性，监督训练方法难以完成这项任务。在本文中，我们认为强化学习（RL）提供了一种有前途的替代方案，使模型能够以无数据的方式学习复杂且主观的视觉标准。为了实现这一目标，我们引入了 PaCo-RL，这是一个综合框架，它将专门的一致性奖励模型与高效的 RL 算法相结合。第一个组件 PaCo-Reward 是一个成对一致性评估器，在通过自动子图配对构建的大规模数据集上进行训练。它通过任务感知指令和 CoT 原因增强的生成式自回归评分机制来评估一致性。第二个组件 PaCo-GRPO 利用新颖的分辨率解耦优化策略来大幅降低 RL 成本，同时采用日志驯服的多奖励聚合机制来确保平衡和稳定的奖励优化。跨两个代表性子任务的大量实验表明，PaCo-Reward 显着提高了与人类视觉一致性感知的一致性，而 PaCo-GRPO 通过提高训练效率和稳定性实现了最先进的一致性性能。总之，这些结果凸显了 PaCo-RL 作为一致图像生成的实用且可扩展的解决方案的前景。该项目页面位于 https://x-gengroup.github.io/HomePage_PaCo-RL/。
> **Abstract**: Consistent image generation requires faithfully preserving identities, styles, and logical coherence across multiple images, which is essential for applications such as storytelling and character design. Supervised training approaches struggle with this task due to the lack of large-scale datasets capturing visual consistency and the complexity of modeling human perceptual preferences. In this paper, we argue that reinforcement learning (RL) offers a promising alternative by enabling models to learn complex and subjective visual criteria in a data-free manner. To achieve this, we introduce PaCo-RL, a comprehensive framework that combines a specialized consistency reward model with an efficient RL algorithm. The first component, PaCo-Reward, is a pairwise consistency evaluator trained on a large-scale dataset constructed via automated sub-figure pairing. It evaluates consistency through a generative, autoregressive scoring mechanism enhanced by task-aware instructions and CoT reasons. The second component, PaCo-GRPO, leverages a novel resolution-decoupled optimization strategy to substantially reduce RL cost, alongside a log-tamed multi-reward aggregation mechanism that ensures balanced and stable reward optimization. Extensive experiments across the two representative subtasks show that PaCo-Reward significantly improves alignment with human perceptions of visual consistency, and PaCo-GRPO achieves state-of-the-art consistency performance with improved training efficiency and stability. Together, these results highlight the promise of PaCo-RL as a practical and scalable solution for consistent image generation. The project page is available at https://x-gengroup.github.io/HomePage_PaCo-RL/.

【47】Order Matters: 3D Shape Generation from Sequential VR Sketches
- **标题**: 顺序很重要：从连续 VR 草图生成 3D 形状
- **链接**: https://arxiv.org/abs/2512.04761
> **作者**: Yizi Chen,Sidi Wu,Tianyi Xiao,Nina Wiedemann,Loic Landrieu
> **摘要**: VR 草图允许用户直接在 3D 中探索和迭代想法，为传统 CAD 工具提供更快、更直观的替代方案。然而，现有的草图到形状模型忽略了笔画的时间顺序，丢弃了有关结构和设计意图的关键线索。我们介绍 VRSketch2Shape，这是第一个用于从连续 VR 草图生成 3D 形状的框架和多类别数据集。我们的贡献有三个方面：(i) 一个从任意形状生成连续 VR 草图的自动化管道，(ii) 四个类别的超过 20k 合成和 900 个手绘草图形状对的数据集，以及 (iii) 一个与基于扩散的 3D 生成器相结合的顺序感知草图编码器。我们的方法比以前的工作产生了更高的几何保真度，在最少的监督下有效地从合成草图推广到真实草图，甚至在部分草图上也表现良好。所有数据和模型将在 https://chenyizi086.github.io/VRSketch2Shape_website 开源发布。
> **Abstract**: VR sketching lets users explore and iterate on ideas directly in 3D, offering a faster and more intuitive alternative to conventional CAD tools. However, existing sketch-to-shape models ignore the temporal ordering of strokes, discarding crucial cues about structure and design intent. We introduce VRSketch2Shape, the first framework and multi-category dataset for generating 3D shapes from sequential VR sketches. Our contributions are threefold: (i) an automated pipeline that generates sequential VR sketches from arbitrary shapes, (ii) a dataset of over 20k synthetic and 900 hand-drawn sketch-shape pairs across four categories, and (iii) an order-aware sketch encoder coupled with a diffusion-based 3D generator. Our approach yields higher geometric fidelity than prior work, generalizes effectively from synthetic to real sketches with minimal supervision, and performs well even on partial sketches. All data and models will be released open-source at https://chenyizi086.github.io/VRSketch2Shape_website.

【48】MT-Depth: Multi-task Instance feature analysis for the Depth Completion
- **标题**: MT-Depth：深度完成的多任务实例特征分析
- **链接**: https://arxiv.org/abs/2512.04734
> **作者**: Abdul Haseeb Nizamani,Dandi Zhou,Xinhai Sun
> **摘要**: 深度补全在 3D 感知系统中起着至关重要的作用，特别是在必须对稀疏深度数据进行致密化以执行自动驾驶、机器人和增强现实等任务的场景中。虽然许多现有方法依赖语义分割来指导深度完成，但它们常常忽视对象级理解的好处。在这项工作中，我们引入了一个实例感知深度完成框架，该框架显式地将二进制实例掩码集成为空间先验，以细化深度预测。我们的模型结合了四个主要组件：冻结的 YOLO V11 实例分割分支、基于 U-Net 的深度完成主干、交叉注意力融合模块和注意力引导预测头。实例分割分支生成每个图像的前景掩模，通过交叉注意力引导深度分支，从而允许网络在细化过程中专注于以对象为中心的区域。我们在 Virtual KITTI 2 数据集上验证了我们的方法，结果表明，与仅 U-Net 基线和之前的语义引导方法相比，该方法实现了更低的 RMSE，同时保持了具有竞争力的 MAE。定性和定量结果表明，所提出的模型有效地提高了物体边界、遮挡和薄结构附近的深度精度。我们的研究结果表明，结合实例感知线索为改进深度完成提供了一个有希望的方向，而不依赖于密集的语义标签。
> **Abstract**: Depth completion plays a vital role in 3D perception systems, especially in scenarios where sparse depth data must be densified for tasks such as autonomous driving, robotics, and augmented reality. While many existing approaches rely on semantic segmentation to guide depth completion, they often overlook the benefits of object-level understanding. In this work, we introduce an instance-aware depth completion framework that explicitly integrates binary instance masks as spatial priors to refine depth predictions. Our model combines four main components: a frozen YOLO V11 instance segmentation branch, a U-Net-based depth completion backbone, a cross-attention fusion module, and an attention-guided prediction head. The instance segmentation branch generates per-image foreground masks that guide the depth branch via cross-attention, allowing the network to focus on object-centric regions during refinement. We validate our method on the Virtual KITTI 2 dataset, showing that it achieves lower RMSE compared to both a U-Net-only baseline and previous semantic-guided methods, while maintaining competitive MAE. Qualitative and quantitative results demonstrate that the proposed model effectively enhances depth accuracy near object boundaries, occlusions, and thin structures. Our findings suggest that incorporating instance-aware cues offers a promising direction for improving depth completion without relying on dense semantic labels.

【49】E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving
- **标题**: E3AD：用于以人为本的端到端自动驾驶的情感感知视觉语言动作模型
- **链接**: https://arxiv.org/abs/2512.04733
> **作者**: Yihong Tang,Haicheng Liao,Tong Nie,Junlin He,Ao Qu,Kehua Chen,Wei Ma,Zhenning Li,Lijun Sun,Chengzhong Xu
> **摘要**: 端到端自动驾驶（AD）系统越来越多地采用视觉-语言-动作（VLA）模型，但它们通常忽略乘客的情绪状态，而这对于舒适度和自动驾驶接受度至关重要。我们引入开放域端到端（OD-E2E）自动驾驶，其中自动驾驶车辆（AV）必须解释自由形式的自然语言命令，推断情感并规划物理上可行的轨迹。我们提出了 E3AD，一种情感感知的 VLA 框架，它通过两个认知启发的组件来增强语义理解：一个连续的 Valenc-Arousal-Dominance (VAD) 情感模型，用于捕获语言中的语气和紧迫性；以及一个双路径空间推理模块，该模块融合了自我中心和异中心视图，以实现类似人类的空间认知。以一致性为导向的训练方案，将模态预训练与基于偏好的对齐相结合，进一步增强了情感意图和驾驶行为之间的一致性。在现实世界的数据集中，E3AD 改进了视觉基础和航路点规划，并实现了最先进的 (SOTA) VAD 关联来进行情感估计。这些结果表明，将情感注入 VLA 式驾驶会产生更加人性化的基础、规划和以人为本的反馈。
> **Abstract**: End-to-end autonomous driving (AD) systems increasingly adopt vision-language-action (VLA) models, yet they typically ignore the passenger's emotional state, which is central to comfort and AD acceptance. We introduce Open-Domain End-to-End (OD-E2E) autonomous driving, where an autonomous vehicle (AV) must interpret free-form natural-language commands, infer the emotion, and plan a physically feasible trajectory. We propose E3AD, an emotion-aware VLA framework that augments semantic understanding with two cognitively inspired components: a continuous Valenc-Arousal-Dominance (VAD) emotion model that captures tone and urgency from language, and a dual-pathway spatial reasoning module that fuses egocentric and allocentric views for human-like spatial cognition. A consistency-oriented training scheme, combining modality pretraining with preference-based alignment, further enforces coherence between emotional intent and driving actions. Across real-world datasets, E3AD improves visual grounding and waypoint planning and achieves state-of-the-art (SOTA) VAD correlation for emotion estimation. These results show that injecting emotion into VLA-style driving yields more human-aligned grounding, planning, and human-centric feedback.

【50】Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild
- **标题**: 衡量不言而喻的事物：野外心理分析的解开模型和基准
- **链接**: https://arxiv.org/abs/2512.04728
> **作者**: Yigui Feng,Qinglin Wang,Haotian Mo,Yang Liu,Ke Liu,Gencheng Liu,Xinhai Chen,Siqi Shen,Songzhu Mei,Jie Liu
> **摘要**: 野外对话的生成心理分析面临两个基本挑战：（1）现有的视觉语言模型（VLM）无法解决发音情感歧义，即语音的视觉模式模仿情感表达； （2）由于缺乏能够评估视觉基础和推理深度的可验证的评估指标，进展受到阻碍。我们提出了一个完整的生态系统来应对这些双重挑战。首先，我们引入了用于解缠结的多级洞察网络（MIND），这是一种新颖的分层视觉编码器，它引入了状态判断模块，以根据时间特征方差通过算法抑制模糊的嘴唇特征，从而实现显式的视觉解缠结。其次，我们构建了 ConvoInsight-DB，这是一个新的大规模数据集，具有针对微表情和深度心理推理的专家注释。第三，第三，我们设计了心理推理洞察力评级指标（PRISM），这是一个自动化维度框架，使用专家指导的法学硕士来衡量大型心理视觉模型的多维度性能。在我们的 PRISM 基准测试中，MIND 显着优于所有基准，在微表情检测方面比之前的 SOTA 提高了 86.95%。消融研究证实，我们的状态判断解开模块是实现这一性能飞跃的最关键组件。我们的代码已经打开了。
> **Abstract**: Generative psychological analysis of in-the-wild conversations faces two fundamental challenges: (1) existing Vision-Language Models (VLMs) fail to resolve Articulatory-Affective Ambiguity, where visual patterns of speech mimic emotional expressions; and (2) progress is stifled by a lack of verifiable evaluation metrics capable of assessing visual grounding and reasoning depth. We propose a complete ecosystem to address these twin challenges. First, we introduce Multilevel Insight Network for Disentanglement(MIND), a novel hierarchical visual encoder that introduces a Status Judgment module to algorithmically suppress ambiguous lip features based on their temporal feature variance, achieving explicit visual disentanglement. Second, we construct ConvoInsight-DB, a new large-scale dataset with expert annotations for micro-expressions and deep psychological inference. Third, Third, we designed the Mental Reasoning Insight Rating Metric (PRISM), an automated dimensional framework that uses expert-guided LLM to measure the multidimensional performance of large mental vision models. On our PRISM benchmark, MIND significantly outperforms all baselines, achieving a +86.95% gain in micro-expression detection over prior SOTA. Ablation studies confirm that our Status Judgment disentanglement module is the most critical component for this performance leap. Our code has been opened.

【51】OmniScaleSR: Unleashing Scale-Controlled Diffusion Prior for Faithful and Realistic Arbitrary-Scale Image Super-Resolution
- **标题**: OmniScaleSR：释放尺度控制扩散先验，实现忠实且真实的任意尺度图像超分辨率
- **链接**: https://arxiv.org/abs/2512.04699
> **作者**: Xinning Chai,Zhengxue Cheng,Yuhong Zhang,Hengsheng Zhang,Yingsheng Qin,Yucai Yang,Rong Xie,Li Song
> **摘要**: 任意尺度超分辨率 (ASSR) 克服了传统超分辨率 (SR) 方法仅在固定尺度（例如 4 倍）下运行的限制，使单个模型能够处理任意放大倍数。大多数现有的 ASSR 方法依赖于隐式神经表示（INR），但其回归驱动的特征提取和聚合本质上限制了合成精细细节的能力，导致真实感较低。最近基于扩散的真实图像超分辨率 (Real-ISR) 模型利用强大的预训练扩散先验，并在 4 倍设置下显示出令人印象深刻的结果。我们观察到他们也可以实现 ASSR，因为扩散先验通过鼓励高真实感生成来隐式适应规模。然而，如果没有明确的尺度控制，扩散过程就无法针对不同的放大倍数进行适当调整，从而导致过度的幻觉或模糊的输出，尤其是在超高尺度下。为了解决这些问题，我们提出了 OmniScaleSR，一种基于扩散的现实任意尺度 SR 框架，旨在实现高保真度和高真实感。我们引入了显式的、扩散原生的尺度控制机制，该机制与隐式尺度适应协同工作，从而实现了扩散过程的尺度感知和内容感知调制。此外，我们还结合了多域保真度增强设计，以进一步提高重建精度。对双三次退化基准和真实世界数据集的大量实验表明，OmniScaleSR 在保真度和感知真实感方面都超越了最先进的方法，并且在大放大倍数下具有特别强大的性能。代码将在 https://github.com/chaixinning/OmniScaleSR 发布。
> **Abstract**: Arbitrary-scale super-resolution (ASSR) overcomes the limitation of traditional super-resolution (SR) methods that operate only at fixed scales (e.g., 4x), enabling a single model to handle arbitrary magnification. Most existing ASSR approaches rely on implicit neural representation (INR), but its regression-driven feature extraction and aggregation intrinsically limit the ability to synthesize fine details, leading to low realism. Recent diffusion-based realistic image super-resolution (Real-ISR) models leverage powerful pre-trained diffusion priors and show impressive results at the 4x setting. We observe that they can also achieve ASSR because the diffusion prior implicitly adapts to scale by encouraging high-realism generation. However, without explicit scale control, the diffusion process cannot be properly adjusted for different magnification levels, resulting in excessive hallucination or blurry outputs, especially under ultra-high scales. To address these issues, we propose OmniScaleSR, a diffusion-based realistic arbitrary-scale SR framework designed to achieve both high fidelity and high realism. We introduce explicit, diffusion-native scale control mechanisms that work synergistically with implicit scale adaptation, enabling scale-aware and content-aware modulation of the diffusion process. In addition, we incorporate multi-domain fidelity enhancement designs to further improve reconstruction accuracy. Extensive experiments on bicubic degradation benchmarks and real-world datasets show that OmniScaleSR surpasses state-of-the-art methods in both fidelity and perceptual realism, with particularly strong performance at large magnification factors. Code will be released at https://github.com/chaixinning/OmniScaleSR.

【52】Towards Cross-View Point Correspondence in Vision-Language Models
- **标题**: 视觉语言模型中的跨视点对应
- **链接**: https://arxiv.org/abs/2512.04686
> **作者**: Yipu Wang,Yuheng Ji,Yuyang Liu,Enshen Zhou,Ziqiang Yang,Yuxuan Tian,Ziheng Qin,Yue Liu,Huajie Tan,Cheng Chi,Zhiyuan Ma,Daniel Dajun Zeng,Xiaolong Zheng
> **摘要**: 跨视图对应是空间理解和体现人工智能的基本能力。然而，它在视觉语言模型（VLM）中还远没有实现，特别是在实现精确的点级对应方面，这对于精确的可供性交互至关重要。因此，受人类“感知”、“推理”和“对应”认知过程的启发，我们提出了跨视点对应（CVPC）任务和分层设计的综合基准 CrossPoint-Bench。我们的评估显示，最先进的模型（例如 Gemini-2.5-Pro）仍然远远落后于人类，总体精度差距超过 54.65%，暴露了从粗粒度判断向细粒度坐标预测过渡的挑战。为了解决这个问题，我们构建了 CrossPoint-378K，这是一个包含 900 个场景的 378K 问答对的数据集，专注于更好地反映现实世界操作和交互场景的可操作可供性区域。此外，我们提出在 CrossPoint-378K 数据集上进行训练的 CroPond。我们的 CroPond 在 CrossPoint-Bench 上实现了最先进的性能，准确率超过 Gemini-2.5-Pro 39.7%，这为推进未来跨视图对应工作奠定了基础。基准、数据集和模型可在 https://github.com/WangYipu2002/CrossPoint 上公开获取。
> **Abstract**: Cross-view correspondence is a fundamental capability for spatial understanding and embodied AI. However, it is still far from being realized in Vision-Language Models (VLMs), especially in achieving precise point-level correspondence, which is crucial for precise affordance interaction. So we propose the Cross-View Point Correspondence (CVPC) task and CrossPoint-Bench, a comprehensive benchmark with hierarchical design, inspired by the human cognitive process of "perceive", "reason", and "correspond". Our evaluation shows the state-of-the-art models (e.g., Gemini-2.5-Pro) still fall far behind humans, with a gap of over 54.65% in overall accuracy, exposing a challenge in transitioning from coarse-grained judgement to fine-grained coordinate prediction. To address this problem, we construct CrossPoint-378K, a dataset with 378K question-answering pairs across 900 scenes, focused on actionable affordance regions that better reflect real-world manipulation and interaction scenarios. Furthermore, we propose CroPond that trained on the CrossPoint-378K dataset. Our CroPond achieves state-of-the-art performance on CrossPoint-Bench, surpassing Gemini-2.5-Pro by 39.7% accuracy, which offers a foundation for advancing future work on cross-view correspondence. The benchmark, dataset, and model are publicly available at https://github.com/WangYipu2002/CrossPoint.

【53】Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation
- **标题**: 奖励强制：具有奖励分布匹配蒸馏的高效流媒体视频生成
- **链接**: https://arxiv.org/abs/2512.04678
> **作者**: Yunhong Lu,Yanhong Zeng,Haobo Li,Hao Ouyang,Qiuyu Wang,Ka Leong Cheng,Jiapeng Zhu,Hengyuan Cao,Zhipeng Zhang,Xing Zhu,Yujun Shen,Min Zhang
> **摘要**: 高效的流媒体视频生成对于模拟交互式和动态世界至关重要。现有方法利用滑动窗口注意力提炼出少步视频扩散模型，使用初始帧作为接收器标记来保持注意力性能并减少错误累积。然而，视频帧变得过度依赖这些静态标记，导致复制初始帧并减弱运动动态。为了解决这个问题，我们引入了奖励强制，这是一个具有两个关键设计的新颖框架。首先，我们提出 EMA-Sink，它维护从初始帧初始化的固定大小的令牌，并在退出滑动窗口时通过指数移动平均融合被逐出的令牌来不断更新。无需额外的计算成本，EMA-Sink 代币即可捕获长期上下文和近期动态，防止初始帧复制，同时保持长期一致性。其次，为了更好地从教师模型中提取运动动力学，我们提出了一种新颖的奖励分布匹配蒸馏（Re-DMD）。普通分布匹配平等对待每个训练样本，限制了模型优先考虑动态内容的能力。相反，Re-DMD 通过优先考虑视觉语言模型评价的具有更大动态性的样本，将模型的输出分布偏向高奖励区域。 Re-DMD 显着提高运动质量，同时保持数据保真度。我们进行了定量和定性实验，以表明奖励强制在标准基准测试中实现了最先进的性能，同时能够在单个 H100 GPU 上以 23.1 FPS 生成高质量流媒体视频。
> **Abstract**: Efficient streaming video generation is critical for simulating interactive and dynamic worlds. Existing methods distill few-step video diffusion models with sliding window attention, using initial frames as sink tokens to maintain attention performance and reduce error accumulation. However, video frames become overly dependent on these static tokens, resulting in copied initial frames and diminished motion dynamics. To address this, we introduce Reward Forcing, a novel framework with two key designs. First, we propose EMA-Sink, which maintains fixed-size tokens initialized from initial frames and continuously updated by fusing evicted tokens via exponential moving average as they exit the sliding window. Without additional computation cost, EMA-Sink tokens capture both long-term context and recent dynamics, preventing initial frame copying while maintaining long-horizon consistency. Second, to better distill motion dynamics from teacher models, we propose a novel Rewarded Distribution Matching Distillation (Re-DMD). Vanilla distribution matching treats every training sample equally, limiting the model's ability to prioritize dynamic content. Instead, Re-DMD biases the model's output distribution toward high-reward regions by prioritizing samples with greater dynamics rated by a vision-language model. Re-DMD significantly enhances motion quality while preserving data fidelity. We include both quantitative and qualitative experiments to show that Reward Forcing achieves state-of-the-art performance on standard benchmarks while enabling high-quality streaming video generation at 23.1 FPS on a single H100 GPU.

【54】Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length
- **标题**: 实时头像：流式传输实时音频驱动的无限长度头像生成
- **链接**: https://arxiv.org/abs/2512.04677
> **作者**: Yubo Huang,Hailong Guo,Fangtai Wu,Shifeng Zhang,Shijie Huang,Qijun Gan,Lin Liu,Sirui Zhao,Enhong Chen,Jiaming Liu,Steven Hoi
> **摘要**: 现有的基于扩散的视频生成方法从根本上受到顺序计算和长期不一致的限制，限制了它们在实时、流媒体音频驱动的化身合成中的实际采用。我们推出了 Live Avatar，这是一种算法系统共同设计的框架，可使用 140 亿参数扩散模型实现高效、高保真和无限长度的头像生成。我们的方法引入了时间步长管道并行（TPP），这是一种分布式推理范例，可以跨多个 GPU 管道化去噪步骤，有效打破自回归瓶颈并确保稳定、低延迟的实时流。为了进一步增强时间一致性并减轻身份漂移和颜色伪影，我们提出了滚动接收器帧机制（RSFM），该机制通过使用缓存的参考图像动态重新校准外观来保持序列保真度。此外，我们利用自强迫分布匹配蒸馏来促进大型模型的因果、可流式适应，而不会牺牲视觉质量。 Live Avatar 展示了最先进的性能，在 5 个 H800 GPU 上达到 20 FPS 端到端生成速度，据我们所知，它是第一个实现这种规模的实用、实时、高保真头像生成的产品。我们的工作建立了在工业长格式视频合成应用中部署先进扩散模型的新范例。
> **Abstract**: Existing diffusion-based video generation methods are fundamentally constrained by sequential computation and long-horizon inconsistency, limiting their practical adoption in real-time, streaming audio-driven avatar synthesis. We present Live Avatar, an algorithm-system co-designed framework that enables efficient, high-fidelity, and infinite-length avatar generation using a 14-billion-parameter diffusion model. Our approach introduces Timestep-forcing Pipeline Parallelism (TPP), a distributed inference paradigm that pipelines denoising steps across multiple GPUs, effectively breaking the autoregressive bottleneck and ensuring stable, low-latency real-time streaming. To further enhance temporal consistency and mitigate identity drift and color artifacts, we propose the Rolling Sink Frame Mechanism (RSFM), which maintains sequence fidelity by dynamically recalibrating appearance using a cached reference image. Additionally, we leverage Self-Forcing Distribution Matching Distillation to facilitate causal, streamable adaptation of large-scale models without sacrificing visual quality. Live Avatar demonstrates state-of-the-art performance, reaching 20 FPS end-to-end generation on 5 H800 GPUs, and, to the best of our knowledge, is the first to achieve practical, real-time, high-fidelity avatar generation at this scale. Our work establishes a new paradigm for deploying advanced diffusion models in industrial long-form video synthesis applications.

【55】I2I-Bench: A Comprehensive Benchmark Suite for Image-to-Image Editing Models
- **标题**: I2I-Bench：图像到图像编辑模型的综合基准套件
- **链接**: https://arxiv.org/abs/2512.04660
> **作者**: Juntong Wang,Jiarui Wang,Huiyu Duan,Jiaxiang Kang,Guangtao Zhai,Xiongkuo Min
> **摘要**: 图像编辑模型正在迅速发展，但综合评估仍然是一个重大挑战。现有的图像编辑基准普遍存在任务范围有限、评估维度不足以及严重依赖人工标注等问题，严重限制了其可扩展性和实际适用性。为了解决这个问题，我们提出了 \textbf{I2I-Bench}，一个图像到图像编辑模型的综合基准，其特点是（i）多样化的任务，涵盖单图像和多图像编辑任务的 10 个任务类别，（ii）综合评估维度，包括 30 个解耦和细粒度的评估维度，以及集成专业工具和大型多模态模型（LMM）的自动化混合评估方法，以及（iii）严格的对齐验证，证明我们的基准评估之间的一致性和人类的喜好。使用 I2I-Bench，我们对众多主流图像编辑模型进行了基准测试，调查了各个维度的编辑模型之间的差距和权衡。我们将开源 I2I-Bench 的所有组件，以方便未来的研究。
> **Abstract**: Image editing models are advancing rapidly, yet comprehensive evaluation remains a significant challenge. Existing image editing benchmarks generally suffer from limited task scopes, insufficient evaluation dimensions, and heavy reliance on manual annotations, which significantly constrain their scalability and practical applicability. To address this, we propose \textbf{I2I-Bench}, a comprehensive benchmark for image-to-image editing models, which features (i) diverse tasks, encompassing 10 task categories across both single-image and multi-image editing tasks, (ii) comprehensive evaluation dimensions, including 30 decoupled and fine-grained evaluation dimensions with automated hybrid evaluation methods that integrate specialized tools and large multimodal models (LMMs), and (iii) rigorous alignment validation, justifying the consistency between our benchmark evaluations and human preferences. Using I2I-Bench, we benchmark numerous mainstream image editing models, investigating the gaps and trade-offs between editing models across various dimensions. We will open-source all components of I2I-Bench to facilitate future research.

【56】SEASON: Mitigating Temporal Hallucination in Video Large Language Models via Self-Diagnostic Contrastive Decoding
- **标题**: SEASON：通过自诊断对比解码减轻视频大语言模型中的时间幻觉
- **链接**: https://arxiv.org/abs/2512.04643
> **作者**: Chang-Hsun Wu,Kai-Po Chang,Yu-Yang Sheng,Hung-Kai Chung,Kuei-Chun Wang,Yu-Chiang Frank Wang
> **摘要**: 视频大语言模型（VideoLLM）在视频理解方面取得了显着的进步。然而，这些模型在响应用户查询时仍然难以有效感知和利用视频中丰富的时间信息。因此，它们经常产生时间不一致或因果关系不可信的事件描述，从而导致严重的幻觉问题。虽然大多数先前的研究都集中在空间幻觉（例如对象不匹配），但视频理解中的时间推理仍然相对未得到充分探索。为了解决这个问题，我们提出了自诊断对比解码（SEASON），这是一种无需训练的方法，可以自适应地增强每个输出标记的时间和空间忠实度。它通过动态诊断每个标记的幻觉倾向并针对其相应的时间和空间负数应用自适应对比解码来实现这一点。大量实验表明，SEASON 在三个幻觉检查基准上优于所有现有的免训练幻觉缓解方法，同时在四个通用视频理解基准上进一步改进了 VideoLLM。该代码将在接受后发布。
> **Abstract**: Video Large Language Models (VideoLLMs) have shown remarkable progress in video understanding. However, these models still struggle to effectively perceive and exploit rich temporal information in videos when responding to user queries. Therefore, they often generate descriptions of events that are temporal inconsistent or causally implausible, causing severe hallucination issues. While most prior studies have focused on spatial hallucinations (e.g. object mismatches), temporal reasoning in video understanding remains relatively underexplored. To address this issue, we propose Self-Diagnostic Contrastive Decoding (SEASON), a training-free method that adaptively enhances temporal and spatial faithfulness for each output token. It achieves this by dynamically diagnosing each token's hallucination tendency and applying adaptive contrastive decoding against its corresponding temporal and spatial negatives. Extensive experiments demonstrate that SEASON outperforms all existing training-free hallucination mitigation approaches on three hallucination examination benchmarks, while further improves VideoLLMs across four general video understanding benchmarks. The code will be released upon acceptance.

【57】Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence
- **标题**: 去噪跟踪：利用视频扩散先验实现稳健对应
- **链接**: https://arxiv.org/abs/2512.04619
> **作者**: Tianyu Yuan,Yuanbo Yang,Lin-Zhuo Chen,Yao Yao,Zhuzhong Qian
> **摘要**: 在这项工作中，我们引入了 HeFT（头部频率跟踪器），这是一种零射击点跟踪框架，利用预训练视频扩散模型的视觉先验。为了更好地理解它们如何编码时空信息，我们分析了视频扩散变换器（VDiT）的内部表示。我们的分析表明，注意力头充当最小的功能单元，在匹配、语义理解和位置编码方面具有独特的专业性。此外，我们发现 VDiT 特征中的低频分量对于建立对应关系至关重要，而高频分量往往会引入噪声。基于这些见解，我们提出了一种头部和频率感知的特征选择策略，该策略联合选择信息最丰富的注意力头部和低频组件，以增强跟踪性能。具体来说，我们的方法通过单步去噪提取判别性特征，应用特征选择，并采用具有前后向一致性检查的 soft-argmax 定位来进行对应估计。 TAP-Vid 基准的大量实验表明，HeFT 实现了最先进的零样本跟踪性能，接近监督方法的准确性，同时消除了对带注释的训练数据的需求。我们的工作进一步强调了视频扩散模型作为广泛下游任务的强大基础模型的前景，为统一视觉基础模型铺平了道路。
> **Abstract**: In this work, we introduce HeFT (Head-Frequency Tracker), a zero-shot point tracking framework that leverages the visual priors of pretrained video diffusion models. To better understand how they encode spatiotemporal information, we analyze the internal representations of Video Diffusion Transformer (VDiT). Our analysis reveals that attention heads act as minimal functional units with distinct specializations for matching, semantic understanding, and positional encoding. Additionally, we find that the low-frequency components in VDiT features are crucial for establishing correspondences, whereas the high-frequency components tend to introduce noise. Building on these insights, we propose a head- and frequency-aware feature selection strategy that jointly selects the most informative attention head and low-frequency components to enhance tracking performance. Specifically, our method extracts discriminative features through single-step denoising, applies feature selection, and employs soft-argmax localization with forward-backward consistency checks for correspondence estimation. Extensive experiments on TAP-Vid benchmarks demonstrate that HeFT achieves state-of-the-art zero-shot tracking performance, approaching the accuracy of supervised methods while eliminating the need for annotated training data. Our work further underscores the promise of video diffusion models as powerful foundation models for a wide range of downstream tasks, paving the way toward unified visual foundation models.

【58】Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot
- **标题**: 通过视觉语言分割融合进行恶意图像分析：一次性检测、元素和位置
- **链接**: https://arxiv.org/abs/2512.04599
> **作者**: Sheng Hang,Chaoxiang He,Hongsheng Hu,Hanqing Hu,Bin Benjamin Zhu,Shi-Feng Sun,Dawu Gu,Shuo Wang
> **摘要**: 检测非法视觉内容需要的不仅仅是图像级 NSFW 标记；版主还必须知道哪些物体使图像非法以及这些物体出现在哪里。我们引入了一种零样本管道，它可以同时 (i) 检测图像是否包含有害内容，(ii) 识别涉及的每个关键元素，以及 (iii) 使用像素精确的掩模定位这些元素 - 所有这些都一次性完成。该系统首先应用基础分割模型（SAM）生成候选对象掩模，并将其细化为更大的独立区域。使用开放词汇提示的视觉语言模型对每个区域的恶意相关性进行评分；这些分数对融合步骤进行加权，从而生成综合的恶意对象图。跨多个分段器的集成可以强化管道，抵御针对任何单一分段方法的自适应攻击。在涵盖毒品、性、暴力和极端主义内容的新注释的 790 个图像数据集上进行评估，我们的方法实现了 85.8% 的元素级召回率、78.1% 的精度和 92.1% 的分段成功率 - 在相当的精度下，比直接零样本 VLM 定位高出 27.4% 的召回率。针对旨在破坏 SAM 和 VLM 的 PGD 对抗性扰动，我们的方法的精度和召回率下降不超过 10%，表现出针对攻击的高鲁棒性。完整的管道可在几秒钟内处理图像，无缝插入现有的 VLM 工作流程，并构成第一个用于细粒度、可解释的恶意图像审核的实用工具。
> **Abstract**: Detecting illicit visual content demands more than image-level NSFW flags; moderators must also know what objects make an image illegal and where those objects occur. We introduce a zero-shot pipeline that simultaneously (i) detects if an image contains harmful content, (ii) identifies each critical element involved, and (iii) localizes those elements with pixel-accurate masks - all in one pass. The system first applies foundation segmentation model (SAM) to generate candidate object masks and refines them into larger independent regions. Each region is scored for malicious relevance by a vision-language model using open-vocabulary prompts; these scores weight a fusion step that produces a consolidated malicious object map. An ensemble across multiple segmenters hardens the pipeline against adaptive attacks that target any single segmentation method. Evaluated on a newly-annotated 790-image dataset spanning drug, sexual, violent and extremist content, our method attains 85.8% element-level recall, 78.1% precision and a 92.1% segment-success rate - exceeding direct zero-shot VLM localization by 27.4% recall at comparable precision. Against PGD adversarial perturbations crafted to break SAM and VLM, our method's precision and recall decreased by no more than 10%, demonstrating high robustness against attacks. The full pipeline processes an image in seconds, plugs seamlessly into existing VLM workflows, and constitutes the first practical tool for fine-grained, explainable malicious-image moderation.

【59】When Robots Should Say "I Don't Know": Benchmarking Abstention in Embodied Question Answering
- **标题**: 机器人何时应该说“我不知道”：体现问答中的弃权基准
- **链接**: https://arxiv.org/abs/2512.04597
> **作者**: Tao Wu,Chuhao Zhou,Guangyu Zhao,Haozhi Cao,Yewen Pu,Jianfei Yang
> **摘要**: 具身问答 (EQA) 需要代理解释语言、感知环境并在 3D 场景中导航以产生响应。现有的 EQA 基准假设每个问题都必须得到回答，但具体代理应该知道他们何时没有足够的信息来回答。在这项工作中，我们关注 EQA 代理的最低要求，即弃权：知道何时拒绝回答。通过对 500 个人工查询的初步研究，我们发现 32.4% 的查询包含缺失或未指定的上下文。根据这项初步研究和人类沟通错误的认知理论，我们得出了需要放弃的五个代表性类别：可操作性限制、指称不足、偏好依赖、信息不可用和错误预设。我们通过让注释器将适定问题转换为这些类别概述的模糊变体来增强 OpenEQA。生成的数据集 AbstainEQA 包含 1,636 个带注释的弃权案例，与 1,636 个原始 OpenEQA 实例配对，以进行平衡评估。对 AbstainEQA 进行评估，我们发现即使是最好的前沿模型也只能达到 42.79% 的弃权召回率，而人类则达到 91.17%。我们还发现，缩放、提示和推理只能产生边际收益，并且微调模型过度适合文本提示。总之，这些结果将弃权视为具体环境中可靠互动的基本先决条件，也是有效澄清的必要基础。
> **Abstract**: Embodied Question Answering (EQA) requires an agent to interpret language, perceive its environment, and navigate within 3D scenes to produce responses. Existing EQA benchmarks assume that every question must be answered, but embodied agents should know when they do not have sufficient information to answer. In this work, we focus on a minimal requirement for EQA agents, abstention: knowing when to withhold an answer. From an initial study of 500 human queries, we find that 32.4% contain missing or underspecified context. Drawing on this initial study and cognitive theories of human communication errors, we derive five representative categories requiring abstention: actionability limitation, referential underspecification, preference dependence, information unavailability, and false presupposition. We augment OpenEQA by having annotators transform well-posed questions into ambiguous variants outlined by these categories. The resulting dataset, AbstainEQA, comprises 1,636 annotated abstention cases paired with 1,636 original OpenEQA instances for balanced evaluation. Evaluating on AbstainEQA, we find that even the best frontier model only attains 42.79% abstention recall, while humans achieve 91.17%. We also find that scaling, prompting, and reasoning only yield marginal gains, and that fine-tuned models overfit to textual cues. Together, these results position abstention as a fundamental prerequisite for reliable interaction in embodied settings and as a necessary basis for effective clarification.

【60】SAM3-I: Segment Anything with Instructions
- **标题**: SAM3-I：使用指令对任何内容进行分段
- **链接**: https://arxiv.org/abs/2512.04585
> **作者**: Jingjing Li,Yue Feng,Yuchen Guo,Jincai Huang,Yongri Piao,Qi Bi,Miao Zhang,Xiaoqi Zhao,Qiang Chen,Shihao Zou,Wei Ji,Huchuan Lu,Li Cheng
> **摘要**: Segment Anything Model 3 (SAM3) 通过提示概念分割实现了先进的开放词汇分割，允许用户分割与给定概念相对应的所有实例，通常用简短的名词短语 (NP) 提示指定。虽然这标志着 SAM 家族中语言级概念的首次集成，但现实世界的使用通常需要更丰富的表达式，包括属性、空间关系、功能、动作、状态，甚至对实例的隐式推理。目前，SAM3依赖外部多模态代理将复杂指令转换为NP，然后进行迭代掩码过滤。然而，这些 NP 级概念仍然过于粗糙，往往无法精确表示特定实例。在这项工作中，我们提出了 SAM3-I，这是一个增强的框架，它将 SAM 系列中的概念级理解和指令级推理统一起来。 SAM3-I 引入了指令感知级联适应机制，该机制逐步将表达性指令语义与 SAM3 现有的视觉语言表示相结合，从而实现直接指令跟踪分段，而无需牺牲其原始概念驱动功能。此外，我们设计了一个跨越概念、简单和复杂级别的结构化指令分类法，并开发了一个可扩展的数据引擎来构建具有不同指令掩码对的数据集。实验表明 SAM3-I 提供了吸引人的性能，证明 SAM3 可以有效扩展以遵循自然语言指令，同时保留其强大的概念基础。我们开源 SAM3-I 并提供实用的微调工作流程，使研究人员能够使其适应特定领域的应用。源代码可以在这里找到。
> **Abstract**: Segment Anything Model 3 (SAM3) has advanced open-vocabulary segmentation through promptable concept segmentation, allowing users to segment all instances corresponding to a given concept, typically specified with short noun-phrase (NP) prompts. While this marks the first integration of language-level concepts within the SAM family, real-world usage typically requires far richer expressions that include attributes, spatial relations, functionalities, actions, states, and even implicit reasoning over instances. Currently, SAM3 relies on external multi-modal agents to convert complex instructions into NPs and then conduct iterative mask filtering. However, these NP-level concepts remain overly coarse, often failing to precisely represent a specific instance. In this work, we present SAM3-I, an enhanced framework that unifies concept-level understanding and instruction-level reasoning within the SAM family. SAM3-I introduces an instruction-aware cascaded adaptation mechanism that progressively aligns expressive instruction semantics with SAM3's existing vision-language representations, enabling direct instruction-following segmentation without sacrificing its original concept-driven capabilities. Furthermore, we design a structured instruction taxonomy spanning concept, simple, and complex levels, and develop a scalable data engine to construct a dataset with diverse instruction-mask pairs. Experiments show that SAM3-I delivers appealing performance, demonstrating that SAM3 can be effectively extended to follow natural-language instructions while preserving its strong concept grounding. We open-source SAM3-I and provide practical fine-tuning workflows, enabling researchers to adapt it to domain-specific applications. The source code is available here.

【61】Infrared UAV Target Tracking with Dynamic Feature Refinement and Global Contextual Attention Knowledge Distillation
- **标题**: 具有动态特征细化和全局上下文注意知识蒸馏的红外无人机目标跟踪
- **链接**: https://arxiv.org/abs/2512.04581
> **作者**: Houzhang Fang,Chenxing Wu,Kun Bai,Tianqi Chen,Xiaolin Wang,Xiyang Liu,Yi Chang,Luxin Yan
> **摘要**: 基于热红外成像的无人机目标跟踪一直是反无人机应用中最重要的传感技术之一。然而，红外无人机目标往往特征较弱、背景复杂，给精确跟踪带来了巨大挑战。为了解决这些问题，我们引入了 SiamDFF，这是一种新颖的动态特征融合暹罗网络，它集成了特征增强和全局上下文注意知识蒸馏，用于红外无人机目标（IRUT）跟踪。 SiamDFF包含选择性目标增强网络（STEN）、动态空间特征聚合模块（DSFAM）和动态通道特征聚合模块（DCFAM）。 STEN 采用强度感知的多头交叉注意力来自适应增强模板和搜索分支的重要区域。 DSFAM 通过将局部细节与全局特征相结合，利用搜索框架内的空间注意力引导来增强多尺度无人机目标特征。 DCFAM有效地将模板分支中STEN生成的混合模板与原始模板结合起来，避免背景对模板的过多干扰，从而增强对搜索框内无人机目标区域特征的重视。此外，为了增强 IRUT 网络的特征提取能力而不增加额外的计算负担，我们提出了一种新颖的跟踪特定目标感知上下文注意知识蒸馏器。它将目标先验从教师网络转移到学生模型，显着提高了学生网络对骨干网络每个层级的信息区域的关注。对真实红外无人机数据集的大量实验表明，所提出的方法在复杂背景下优于最先进的目标跟踪器，同时实现了实时跟踪速度。
> **Abstract**: Unmanned aerial vehicle (UAV) target tracking based on thermal infrared imaging has been one of the most important sensing technologies in anti-UAV applications. However, the infrared UAV targets often exhibit weak features and complex backgrounds, posing significant challenges to accurate tracking. To address these problems, we introduce SiamDFF, a novel dynamic feature fusion Siamese network that integrates feature enhancement and global contextual attention knowledge distillation for infrared UAV target (IRUT) tracking. The SiamDFF incorporates a selective target enhancement network (STEN), a dynamic spatial feature aggregation module (DSFAM), and a dynamic channel feature aggregation module (DCFAM). The STEN employs intensity-aware multi-head cross-attention to adaptively enhance important regions for both template and search branches. The DSFAM enhances multi-scale UAV target features by integrating local details with global features, utilizing spatial attention guidance within the search frame. The DCFAM effectively integrates the mixed template generated from STEN in the template branch and original template, avoiding excessive background interference with the template and thereby enhancing the emphasis on UAV target region features within the search frame. Furthermore, to enhance the feature extraction capabilities of the network for IRUT without adding extra computational burden, we propose a novel tracking-specific target-aware contextual attention knowledge distiller. It transfers the target prior from the teacher network to the student model, significantly improving the student network's focus on informative regions at each hierarchical level of the backbone network. Extensive experiments on real infrared UAV datasets demonstrate that the proposed approach outperforms state-of-the-art target trackers under complex backgrounds while achieving a real-time tracking speed.

【62】TARDis: Time Attenuated Representation Disentanglement for Incomplete Multi-Modal Tumor Segmentation and Classification
- **标题**: TARDis：不完整多模态肿瘤分割和分类的时间衰减表示解开
- **链接**: https://arxiv.org/abs/2512.04576
> **作者**: Zishuo Wan,Qinqin Kang,Yi Huang,Yun Bian,Dawei Ding,Ke Yan
> **摘要**: 对比增强计算机断层扫描 (CT) 中的肿瘤分割和诊断在很大程度上依赖于造影剂的生理动力学。然而，由于辐射问题或扫描限制，获得完整的多相序列在临床上通常是不可行的，从而导致“缺失模态”问题。现有的深度学习方法通​​常将缺失的相位视为缺失的独立通道，忽略了血流动力学固有的时间连续性。在这项工作中，我们提出了时间衰减表示解缠结（TARDis），这是一种新颖的物理感知框架，它将缺失的模态重新定义为连续时间衰减曲线上缺失的样本点。 TARDis 明确地将潜在特征空间分解为不随时间变化的静态分量（解剖）和时间相关的动态分量（灌注）。我们通过双路径架构实现这一目标：基于量化的路径使用可学习的嵌入字典来提取一致的解剖结构，以及使用条件变分自动编码器的概率路径来根据估计的扫描时间对动态增强进行建模。这种设计允许网络通过从学习到的潜在分布中采样来幻觉缺失的血流动力学特征。对大型私人腹部 CT 数据集（2,282 例）和两个公共数据集的广泛实验表明，TARDis 显着优于最先进的不完整模态框架。值得注意的是，我们的方法即使在极端的数据稀疏情况下也能保持强大的诊断性能，突显了其在减少辐射暴露同时保持诊断精度的潜力。
> **Abstract**: Tumor segmentation and diagnosis in contrast-enhanced Computed Tomography (CT) rely heavily on the physiological dynamics of contrast agents. However, obtaining a complete multi-phase series is often clinically unfeasible due to radiation concerns or scanning limitations, leading to the "missing modality" problem. Existing deep learning approaches typically treat missing phases as absent independent channels, ignoring the inherent temporal continuity of hemodynamics. In this work, we propose Time Attenuated Representation Disentanglement (TARDis), a novel physics-aware framework that redefines missing modalities as missing sample points on a continuous Time-Attenuation Curve. TARDis explicitly disentangles the latent feature space into a time-invariant static component (anatomy) and a time-dependent dynamic component (perfusion). We achieve this via a dual-path architecture: a quantization-based path using a learnable embedding dictionary to extract consistent anatomical structures, and a probabilistic path using a Conditional Variational Autoencoder to model dynamic enhancement conditioned on the estimated scan time. This design allows the network to hallucinate missing hemodynamic features by sampling from the learned latent distribution. Extensive experiments on a large-scale private abdominal CT dataset (2,282 cases) and two public datasets demonstrate that TARDis significantly outperforms state-of-the-art incomplete modality frameworks. Notably, our method maintains robust diagnostic performance even in extreme data-sparsity scenarios, highlighting its potential for reducing radiation exposure while maintaining diagnostic precision.

【63】Prompt2Craft: Generating Functional Craft Assemblies with LLMs
- **标题**: Prompt2Craft：使用法学硕士生成功能性工艺组件
- **链接**: https://arxiv.org/abs/2512.04568
> **作者**: Vitor Hideyo Isume,Takuya Kiyokawa,Natsuki Yamanobe,Yukiyasu Domae,Weiwei Wan,Kensuke Harada
> **摘要**: 受传统手工工艺的启发，人们根据可用的物体即兴组装，我们正式引入了工艺组装任务。这是一项机器人装配任务，涉及使用可用对象构建给定目标对象的准确表示，这些对象不直接对应于其零件。在这项工作中，当给定的输入是野外目标的 RGB 图像时，我们专注于为最终工艺选择可用对象的子集。我们使用掩模分割神经网络来识别可见部分，然后检索标记的模板网格。这些网格经过姿态优化以确定最合适的模板。然后，我们建议将转换后的模板网格部分简化为长方体或圆柱体等原始形状。最后，我们设计了一种搜索算法，根据局部和全局比例来查找场景中的对应关系。我们开发考虑所有可能组合的比较基线，并为前景图和掩模准确性中使用的常见指标选择最高得分的组合。我们的方法实现了与两个不同场景的基线相当的结果，并且我们展示了在现实场景中实施的定性结果。
> **Abstract**: Inspired by traditional handmade crafts, where a person improvises assemblies based on the available objects, we formally introduce the Craft Assembly Task. It is a robotic assembly task that involves building an accurate representation of a given target object using the available objects, which do not directly correspond to its parts. In this work, we focus on selecting the subset of available objects for the final craft, when the given input is an RGB image of the target in the wild. We use a mask segmentation neural network to identify visible parts, followed by retrieving labeled template meshes. These meshes undergo pose optimization to determine the most suitable template. Then, we propose to simplify the parts of the transformed template mesh to primitive shapes like cuboids or cylinders. Finally, we design a search algorithm to find correspondences in the scene based on local and global proportions. We develop baselines for comparison that consider all possible combinations, and choose the highest scoring combination for common metrics used in foreground maps and mask accuracy. Our approach achieves comparable results to the baselines for two different scenes, and we show qualitative results for an implementation in a real-world scenario.

【64】Dataset creation for supervised deep learning-based analysis of microscopic images -- review of important considerations and recommendations
- **标题**: 用于基于监督深度学习的显微图像分析的数据集创建——重要考虑因素和建议的回顾
- **链接**: https://arxiv.org/abs/2512.04564
> **作者**: Christof A. Bertram,Viktoria Weiss,Jonas Ammeling,F. Maria Schabel,Taryn A. Donovan,Frauke Wilm,Christian Marzahl,Katharina Breininger,Marc Aubreville
> **摘要**: 监督式深度学习 (DL) 对显微图像的自动分析引起了极大兴趣，越来越多的文献支持其潜力。这些深度学习模型的开发和验证在很大程度上依赖于高质量、大规模数据集的可用性。然而，创建此类数据集是一个复杂且资源密集型的过程，通常会受到时间限制、领域可变性以及图像收集和标签创建中的偏差风险等挑战的阻碍。本综述为数据集创建的关键步骤提供了全面的指南，包括：1) 图像采集，2) 注释软件的选择，以及 3) 注释创建。除了确保足够多的图像之外，解决图像变异性（域转移）的来源（例如与载玻片准备和数字化相关的来源）也至关重要，如果训练数据中没有充分表示，可能会导致算法错误。注释的关键质量标准是三个“C”：正确性、完整性和一致性。本综述探讨了通过使用先进技术来减轻单个注释器的局限性来提高注释质量的方法。为了支持数据集创建者，提供了标准操作程序 (SOP) 作为补充材料，概述了数据集开发的最佳实践。此外，本文还强调了开放数据集在推动创新和提高深度学习研究可重复性方面的重要性。通过应对挑战并提供实用建议，本次综述旨在推进高质量、大规模数据集的创建和可用性，最终有助于开发用于病理学应用的通用且稳健的深度学习模型。
> **Abstract**: Supervised deep learning (DL) receives great interest for automated analysis of microscopic images with an increasing body of literature supporting its potential. The development and validation of those DL models relies heavily on the availability of high-quality, large-scale datasets. However, creating such datasets is a complex and resource-intensive process, often hindered by challenges such as time constraints, domain variability, and risks of bias in image collection and label creation. This review provides a comprehensive guide to the critical steps in dataset creation, including: 1) image acquisition, 2) selection of annotation software, and 3) annotation creation. In addition to ensuring a sufficiently large number of images, it is crucial to address sources of image variability (domain shifts) - such as those related to slide preparation and digitization - that could lead to algorithmic errors if not adequately represented in the training data. Key quality criteria for annotations are the three "C"s: correctness, completeness, and consistency. This review explores methods to enhance annotation quality through the use of advanced techniques that mitigate the limitations of single annotators. To support dataset creators, a standard operating procedure (SOP) is provided as supplemental material, outlining best practices for dataset development. Furthermore, the article underscores the importance of open datasets in driving innovation and enhancing reproducibility of DL research. By addressing the challenges and offering practical recommendations, this review aims to advance the creation of and availability to high-quality, large-scale datasets, ultimately contributing to the development of generalizable and robust DL models for pathology applications.

【65】COOPER: A Unified Model for Cooperative Perception and Reasoning in Spatial Intelligence
- **标题**: COOPER：空间智能中合作感知和推理的统一模型
- **链接**: https://arxiv.org/abs/2512.04563
> **作者**: Zefeng Zhang,Xiangzhao Hao,Hengzhu Tang,Zhenyu Zhang,Jiawei Sheng,Xiaodong Li,Zhenyang Li,Li Gao,Daiting Shi,Dawei Yin,Tingwen Liu
> **摘要**: 视觉空间推理对于使多模态大型语言模型 (MLLM) 理解对象属性和空间关系至关重要，但当前模型仍难以进行 3D 感知推理。现有方法通常通过使用深度和分割等辅助模式增强 RGB 输入来增强感知，或者通过空间 VQA 数据集训练和应用强化学习来增强推理，从而单独处理这两个方面。在这项工作中，我们研究了统一的 MLLM 是否可以发展增强空间感知的内在能力，并通过自适应交错推理实现更强的空间智能。我们提出 \textbf{COOPER}，一个统一的 MLLM，利用深度和分割作为辅助模态，并分两个阶段进行训练以获得辅助模态生成和自适应、交错推理能力。 COOPER 在空间推理方面实现了平均 \textbf{6.91\%} 改进，同时保持了一般性能。此外，即使是仅针对辅助模态生成进行训练的变体，在距离和尺寸估计方面也获得了 \textbf{7.92\%} 增益，这表明学习生成辅助模态有助于内化空间知识并加强空间理解。
> **Abstract**: Visual Spatial Reasoning is crucial for enabling Multimodal Large Language Models (MLLMs) to understand object properties and spatial relationships, yet current models still struggle with 3D-aware reasoning. Existing approaches typically enhance either perception, by augmenting RGB inputs with auxiliary modalities such as depth and segmentation, or reasoning, by training on spatial VQA datasets and applying reinforcement learning, and thus treat these two aspects in isolation. In this work, we investigate whether a unified MLLM can develop an intrinsic ability to enhance spatial perception and, through adaptive interleaved reasoning, achieve stronger spatial intelligence. We propose \textbf{COOPER}, a unified MLLM that leverages depth and segmentation as auxiliary modalities and is trained in two stages to acquire auxiliary modality generation and adaptive, interleaved reasoning capabilities. COOPER achieves an average \textbf{6.91\%} improvement in spatial reasoning while maintaining general performance. Moreover, even a variant trained only for auxiliary modality generation attains a \textbf{7.92\%} gain on distance and size estimation, suggesting that learning to generate auxiliary modalities helps internalize spatial knowledge and strengthen spatial understanding.

【66】Counterfeit Answers: Adversarial Forgery against OCR-Free Document Visual Question Answering
- **标题**: 伪造答案：针对无 OCR 文档视觉问答的对抗性伪造
- **链接**: https://arxiv.org/abs/2512.04554
> **作者**: Marco Pintore,Maura Pintor,Dimosthenis Karatzas,Battista Biggio
> **摘要**: 文档视觉问答 (DocVQA) 支持基于文档输入中存在的信息进行端到端推理。尽管最近的模型显示出令人印象深刻的功能，但它们仍然容易受到对抗性攻击。在这项工作中，我们引入了一种新颖的攻击场景，旨在以视觉上难以察觉但语义上有针对性的方式伪造文档内容，从而允许对手从 DocVQA 模型中得出特定或通常不正确的答案。我们开发专门的攻击算法，可以根据不同攻击者的目标（从有针对性的错误信息到系统性模型故障场景）生成针对不同攻击者目标的对抗性伪造文档。我们针对两个端到端最先进的模型展示了我们的方法的有效性：Pix2Struct，一种通过序列到序列建模联合处理图像和文本的视觉语言转换器，以及 Donut，一种基于转换器的模型，直接从文档图像中提取文本并回答问题。我们的研究结果强调了当前 DocVQA 系统中的关键漏洞，并呼吁开发更强大的防御措施。
> **Abstract**: Document Visual Question Answering (DocVQA) enables end-to-end reasoning grounded on information present in a document input. While recent models have shown impressive capabilities, they remain vulnerable to adversarial attacks. In this work, we introduce a novel attack scenario that aims to forge document content in a visually imperceptible yet semantically targeted manner, allowing an adversary to induce specific or generally incorrect answers from a DocVQA model. We develop specialized attack algorithms that can produce adversarially forged documents tailored to different attackers' goals, ranging from targeted misinformation to systematic model failure scenarios. We demonstrate the effectiveness of our approach against two end-to-end state-of-the-art models: Pix2Struct, a vision-language transformer that jointly processes image and text through sequence-to-sequence modeling, and Donut, a transformer-based model that directly extracts text and answers questions from document images. Our findings highlight critical vulnerabilities in current DocVQA systems and call for the development of more robust defenses.

【67】Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization
- **标题**: 高斯熵场：推动 3D 高斯优化中的自适应稀疏性
- **链接**: https://arxiv.org/abs/2512.04542
> **作者**: Hong Kuang,Jianchen Liu
> **摘要**: 3D 高斯分布 (3DGS) 已成为新颖视图合成的领先技术，展示了卓越的渲染效率。 \replaced[]{良好重构的表面可以通过低构型熵来表征，其中主导基元清楚地定义表面几何形状，同时抑制冗余分量。}{关键的见解是良好重构的表面自然表现出低构型熵，其中主导基元清楚地定义表面几何形状，同时抑制冗余组件。}介绍了三个互补的技术贡献：（1）通过熵最小化对基元分布中的低构型熵进行熵驱动的表面建模； （2）使用表面邻域冗余指数（SNRI）和图像熵引导加权的自适应空间正则化； （3）通过竞争性跨尺度熵对齐实现多尺度几何保存。大量实验表明，GEF 在 DTU 和 T\&T 基准上实现了具有竞争力的几何精度，同时与 Mip-NeRF 360 上的现有方法相比，提供了卓越的渲染质量。值得注意的是，在 DTU 上获得了优异的倒角距离 (0.64)，在 T\&T 上获得了 F1 分数 (0.44)，同时在 Mip-NeRF 360 的基线中获得了最佳的 SSIM (0.855) 和 LPIPS (0.136)，验证该框架在不影响光度保真度的情况下提高表面重建精度的能力。
> **Abstract**: 3D Gaussian Splatting (3DGS) has emerged as a leading technique for novel view synthesis, demonstrating exceptional rendering efficiency. \replaced[]{Well-reconstructed surfaces can be characterized by low configurational entropy, where dominant primitives clearly define surface geometry while redundant components are suppressed.}{The key insight is that well-reconstructed surfaces naturally exhibit low configurational entropy, where dominant primitives clearly define surface geometry while suppressing redundant components.} Three complementary technical contributions are introduced: (1) entropy-driven surface modeling via entropy minimization for low configurational entropy in primitive distributions; (2) adaptive spatial regularization using the Surface Neighborhood Redundancy Index (SNRI) and image entropy-guided weighting; (3) multi-scale geometric preservation through competitive cross-scale entropy alignment. Extensive experiments demonstrate that GEF achieves competitive geometric precision on DTU and T\&T benchmarks, while delivering superior rendering quality compared to existing methods on Mip-NeRF 360. Notably, superior Chamfer Distance (0.64) on DTU and F1 score (0.44) on T\&T are obtained, alongside the best SSIM (0.855) and LPIPS (0.136) among baselines on Mip-NeRF 360, validating the framework's ability to enhance surface reconstruction accuracy without compromising photometric fidelity.

【68】VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management
- **标题**: VideoMem：通过自适应内存管理增强超长视频理解
- **链接**: https://arxiv.org/abs/2512.04540
> **作者**: Hongbo Jin,Qingyuan Wang,Wenhao Zhang,Yang Liu,Sijie Cheng
> **摘要**: 超长视频理解仍然是一个开放的挑战，因为现有的视觉语言模型（VLM）由于有限的上下文长度和低效的长期记忆保留而在此类内容上表现不佳。为了解决这个问题，最近的工作试图构建外部知识库和相应的检索增强生成（RAG）系统，但这些会产生巨大的存储和计算开销。在本文中，我们提出了 VideoMem，这是一种新颖的框架，它率先通过自适应内存管理将长视频理解建模为顺序生成任务。具体来说，VideoMem 动态更新全局内存缓冲区，该缓冲区自适应地保留关键信息，同时丢弃视频时间线上的冗余内容。为了有效地训练 VLM 来完成此类长期任务，VideoMem 集成了渐进式分组相对策略优化 (PRPO) 算法，该算法配备了两个核心模块：渐进式状态传播 (PSP) 自适应地保留有效的当前状态，将它们传播到下一个 rollout 步骤，并逐渐缩小模型探索空间。时间级联奖励（TCR）进一步缓解奖励稀疏性，提高样本利用率并加速收敛。大量实验表明，VideoMem 在超长视频理解任务的各种基准测试中显着优于现有开源模型。
> **Abstract**: Ultra long video understanding remains an open challenge, as existing vision language models (VLMs) falter on such content due to limited context length and inefficient long term memory retention. To address this, recent works have attempted to construct external knowledge bases and corresponding retrieval agumented generation (RAG) systems, yet these incur enormous storage and computational overhead. In this paper, we propose VideoMem, a novel framework that pioneers models long video understanding as a sequential generation task via adaptive memory management. Specifically, VideoMem dynamically updates a global memory buffer, which adaptively retains critical information while discarding redundant content across the video timeline. To efficiently train VLMs for such long-term tasks, VideoMem integrates the Progressive Grouped Relative Policy Optimization (PRPO) algorithm, equipped with two core modules: Progressive State Propagation (PSP) adaptively retains valid current states, propagates them to the next rollout step, and gradually narrows the model exploration space. Temporal Cascading Reward (TCR) further alleviates reward sparsity, improving sample utilization and accelerating convergence. Extensive experiments demonstrate that VideoMem significantly outperforms existing open-source models across diverse benchmarks for ultra-long video understanding tasks.

【69】X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale
- **标题**: X-Humanoid：机器人化人类视频以大规模生成人形视频
- **链接**: https://arxiv.org/abs/2512.04537
> **作者**: Pei Yang,Hai Ci,Yiren Song,Mike Zheng Shou
> **摘要**: 嵌入式人工智能的进步释放了智能人形机器人的巨大潜力。然而，视觉-语言-动作（VLA）模型和世界模型的进展都因大规模、多样化训练数据的稀缺而受到严重阻碍。一个有前途的解决方案是“机器人化”网络规模的人类视频，这已被证明对于政策培训有效。然而，这些解决方案主要是将机器人手臂“叠加”到以自我为中心的视频上，无法处理第三人称视频中复杂的全身运动和场景遮挡，使得它们不适合将人类机器人化。为了弥补这一差距，我们引入了 X-Humanoid，这是一种生成视频编辑方法，可将强大的 Wan 2.2 模型改编成视频到视频的结构，并针对人机翻译任务对其进行微调。这种微调需要配对的人形视频，因此我们设计了一个可扩展的数据创建管道，使用虚幻引擎将社区资产转化为 17 多个小时的配对合成视频。然后，我们将经过训练的模型应用于 60 小时的 Ego-Exo4D 视频，生成并发布了包含超过 360 万个“机器人化”人形视频帧的新大规模数据集。定量分析和用户研究证实了我们的方法相对于现有基线的优越性：69% 的用户认为其运动一致性最佳，62.1% 的用户认为其实施正确性最佳。
> **Abstract**: The advancement of embodied AI has unlocked significant potential for intelligent humanoid robots. However, progress in both Vision-Language-Action (VLA) models and world models is severely hampered by the scarcity of large-scale, diverse training data. A promising solution is to "robotize" web-scale human videos, which has been proven effective for policy training. However, these solutions mainly "overlay" robot arms to egocentric videos, which cannot handle complex full-body motions and scene occlusions in third-person videos, making them unsuitable for robotizing humans. To bridge this gap, we introduce X-Humanoid, a generative video editing approach that adapts the powerful Wan 2.2 model into a video-to-video structure and finetunes it for the human-to-humanoid translation task. This finetuning requires paired human-humanoid videos, so we designed a scalable data creation pipeline, turning community assets into 17+ hours of paired synthetic videos using Unreal Engine. We then apply our trained model to 60 hours of the Ego-Exo4D videos, generating and releasing a new large-scale dataset of over 3.6 million "robotized" humanoid video frames. Quantitative analysis and user studies confirm our method's superiority over existing baselines: 69% of users rated it best for motion consistency, and 62.1% for embodiment correctness.

【70】Detection of Intoxicated Individuals from Facial Video Sequences via a Recurrent Fusion Model
- **标题**: 通过循环融合模型从面部视频序列中检测醉酒个体
- **链接**: https://arxiv.org/abs/2512.04536
> **作者**: Bita Baroutian,Atefe Aghaei,Mohsen Ebrahimi Moghaddam
> **摘要**: 饮酒是一个重要的公共卫生问题，也是全世界事故和死亡的主要原因。本研究介绍了一种新颖的基于视频的面部序列分析方法，专用于检测酒精中毒。该方法将通过图注意力网络 (GAT) 进行的面部标志分析与使用 3D ResNet 提取的时空视觉特征相结合。这些功能与自适应优先级动态融合，以增强分类性能。此外，我们还引入了一个精心策划的数据集，其中包含来自 202 个人的 3,542 个视频片段，以支持培训和评估。我们的模型与两个基线进行了比较：自定义 3D-CNN 和 VGGFace+LSTM 架构。实验结果表明，我们的方法实现了 95.82% 的准确率、0.977 的精确率和 0.97 的召回率，优于现有方法。研究结果证明了该模型在公共安全系统中实际部署以进行非侵入性、可靠的酒精中毒检测的潜力。
> **Abstract**: Alcohol consumption is a significant public health concern and a major cause of accidents and fatalities worldwide. This study introduces a novel video-based facial sequence analysis approach dedicated to the detection of alcohol intoxication. The method integrates facial landmark analysis via a Graph Attention Network (GAT) with spatiotemporal visual features extracted using a 3D ResNet. These features are dynamically fused with adaptive prioritization to enhance classification performance. Additionally, we introduce a curated dataset comprising 3,542 video segments derived from 202 individuals to support training and evaluation. Our model is compared against two baselines: a custom 3D-CNN and a VGGFace+LSTM architecture. Experimental results show that our approach achieves 95.82% accuracy, 0.977 precision, and 0.97 recall, outperforming prior methods. The findings demonstrate the model's potential for practical deployment in public safety systems for non-invasive, reliable alcohol intoxication detection.

【71】Refaçade: Editing Object with Given Reference Texture
- **标题**: Refaçade：使用给定的参考纹理编辑对象
- **链接**: https://arxiv.org/abs/2512.04534
> **作者**: Youze Huang,Penghui Ruan,Bojia Zi,Xianbiao Qi,Jianan Wang,Rong Xiao
> **摘要**: 扩散模型的最新进展为图像和视频编辑带来了显着进步，但某些任务仍未得到充分探索。在本文中，我们介绍了一项新任务“对象重新纹理”，它将局部纹理从参考对象转移到图像或视频中的目标对象。要执行此任务，一个简单的解决方案是使用以源结构和参考纹理为条件的 ControlNet。然而，这种方法的可控性有限，原因有两个：对原始参考图像的调节引入了不需要的结构信息，并且它无法解开源的视觉纹理和结构信息。为了解决这个问题，我们提出了 Refaçade，一种由两个关键设计组成的方法，可以在图像和视频中实现精确可控的纹理传输。首先，我们采用在成对纹理/无纹理 3D 网格渲染上训练的纹理去除器来去除外观信息，同时保留源视频的几何形状和运动。其次，我们使用拼图排列破坏参考全局布局，鼓励模型关注局部纹理统计而不是对象的全局布局。大量的实验证明了卓越的视觉质量、精确的编辑和可控性，在定量和人类评估方面均优于强大的基线。代码可在 https://github.com/fishZe233/Refacade 获取。
> **Abstract**: Recent advances in diffusion models have brought remarkable progress in image and video editing, yet some tasks remain underexplored. In this paper, we introduce a new task, Object Retexture, which transfers local textures from a reference object to a target object in images or videos. To perform this task, a straightforward solution is to use ControlNet conditioned on the source structure and the reference texture. However, this approach suffers from limited controllability for two reasons: conditioning on the raw reference image introduces unwanted structural information, and it fails to disentangle the visual texture and structure information of the source. To address this problem, we propose Refaçade, a method that consists of two key designs to achieve precise and controllable texture transfer in both images and videos. First, we employ a texture remover trained on paired textured/untextured 3D mesh renderings to remove appearance information while preserving the geometry and motion of source videos. Second, we disrupt the reference global layout using a jigsaw permutation, encouraging the model to focus on local texture statistics rather than the global layout of the object. Extensive experiments demonstrate superior visual quality, precise editing, and controllability, outperforming strong baselines in both quantitative and human evaluations. Code is available at https://github.com/fishZe233/Refacade.

【72】PhyVLLM: Physics-Guided Video Language Model with Motion-Appearance Disentanglement
- **标题**: PhyVLLM：具有运动外观解缠结的物理引导视频语言模型
- **链接**: https://arxiv.org/abs/2512.04532
> **作者**: Yu-Wei Zhan,Xin Wang,Hong Chen,Tongtong Feng,Wei Feng,Ren Wang,Guangyao Li,Qing Li,Wenwu Zhu
> **摘要**: 视频大语言模型（视频 LLM）在广泛的视频语言任务中表现出了令人印象深刻的性能。然而，在需要更深入了解物理动力学的场景中，它们常常会失败。这种限制主要源于它们对基于外观的匹配的依赖。结合物理运动建模对于更深入的视频理解至关重要，但提出了三个关键挑战：（1）运动信号通常与外观变化纠缠在一起，使得难以提取清晰的物理线索； （2）有效的运动建模不仅需要连续时间的运动表示，还需要捕获物理动态； (3) 收集物理属性的准确注释成本高昂且通常不切实际。为了解决这些问题，我们提出了 PhyVLLM，一种物理引导的视频语言框架，它明确地将物理运动纳入视频法学硕士。具体来说，PhyVLLM 通过双分支编码器解开视觉外观和物体运动。为了对随时间变化的物理动力学进行建模，我们采用了神经常微分方程（神经 ODE）模块，该模块可生成可微分的物理动态表示。由此产生的运动感知表示被投影到预训练的 LLM 的令牌空间中，从而在不损害模型原始多模态功能的情况下实现物理推理。为了避免对显式物理标签的需求，PhyVLLM 采用自我监督的方式来模拟对象运动的连续演化。实验结果表明，PhyVLLM 在物理推理和一般视频理解任务上显着优于最先进的视频 LLM，凸显了结合显式物理建模的优势。
> **Abstract**: Video Large Language Models (Video LLMs) have shown impressive performance across a wide range of video-language tasks. However, they often fail in scenarios requiring a deeper understanding of physical dynamics. This limitation primarily arises from their reliance on appearance-based matching. Incorporating physical motion modeling is crucial for deeper video understanding, but presents three key challenges: (1) motion signals are often entangled with appearance variations, making it difficult to extract clean physical cues; (2) effective motion modeling requires not only continuous-time motion representations but also capturing physical dynamics; and (3) collecting accurate annotations for physical attributes is costly and often impractical. To address these issues, we propose PhyVLLM, a physical-guided video-language framework that explicitly incorporates physical motion into Video LLMs. Specifically, PhyVLLM disentangles visual appearance and object motion through a dual-branch encoder. To model physical dynamics over time, we incorporate a Neural Ordinary Differential Equation (Neural ODE) module, which generates differentiable physical dynamic representations. The resulting motion-aware representations are projected into the token space of a pretrained LLM, enabling physics reasoning without compromising the model's original multimodal capabilities. To circumvent the need for explicit physical labels, PhyVLLM employs a self-supervised manner to model the continuous evolution of object motion. Experimental results demonstrate that PhyVLLM significantly outperforms state-of-the-art Video LLMs on both physical reasoning and general video understanding tasks, highlighting the advantages of incorporating explicit physical modeling.

【73】Auto3R: Automated 3D Reconstruction and Scanning via Data-driven Uncertainty Quantification
- **标题**: Auto3R：通过数据驱动的不确定性量化进行自动 3D 重建和扫描
- **链接**: https://arxiv.org/abs/2512.04528
> **作者**: Chentao Shen,Sizhe Zheng,Bingqian Wu,Yaohua Feng,Yuanchen Fei,Mingyu Mei,Hanwen Jiang,Xiangru Huang
> **摘要**: 传统的高质量 3D 扫描和重建通常依赖人工来规划扫描过程。随着无人机和机器人等实体系统的快速发展，以全自动方式执行精确的 3D 扫描和重建的需求日益增长。我们引入了 Auto3R，这是一种数据驱动的不确定性量化模型，旨在自动执行场景和物体的 3D 扫描和重建，包括具有非朗伯和镜面材质的物体。具体来说，在迭代 3D 重建和扫描过程中，Auto3R 可以在不知道地面真实几何形状和外观的情况下，高效、准确地预测潜在扫描视点的不确定性分布。通过大量的实验，Auto3R 实现了卓越的性能，大大优于最先进的方法。我们还在配备摄像头的机器人手臂上部署了 Auto3R，并证明 Auto3R 可用于有效地将现实世界的 3D 对象数字化，并提供即用型且逼真的数字资产。我们的主页：https://tomatoma00.github.io/auto3r.github.io。
> **Abstract**: Traditional high-quality 3D scanning and reconstruction typically relies on human labor to plan the scanning procedure. With the rapid development of embodied systems such as drones and robots, there is a growing demand of performing accurate 3D scanning and reconstruction in an fully automated manner. We introduce Auto3R, a data-driven uncertainty quantification model that is designed to automate the 3D scanning and reconstruction of scenes and objects, including objects with non-lambertian and specular materials. Specifically, in a process of iterative 3D reconstruction and scanning, Auto3R can make efficient and accurate prediction of uncertainty distribution over potential scanning viewpoints, without knowing the ground truth geometry and appearance. Through extensive experiments, Auto3R achieves superior performance that outperforms the state-of-the-art methods by a large margin. We also deploy Auto3R on a robot arm equipped with a camera and demonstrate that Auto3R can be used to effectively digitize real-world 3D objects and delivers ready-to-use and photorealistic digital assets. Our homepage: https://tomatoma00.github.io/auto3r.github.io .

【74】Identity Clue Refinement and Enhancement for Visible-Infrared Person Re-Identification
- **标题**: 可见光-红外人员重新识别的身份线索细化和增强
- **链接**: https://arxiv.org/abs/2512.04522
> **作者**: Guoqing Zhang,Zhun Wang,Hairui Wang,Zhonglin Ye,Yuhui Zheng
> **摘要**: 由于显着的模态差异，可见光-红外行人重新识别（VI-ReID）是一项具有挑战性的跨模态匹配任务。虽然当前的方法主要侧重于通过统一的嵌入空间学习模态不变特征，但它们通常只关注跨模态的共同判别语义，而忽视了模态特定的身份感知知识在判别性特征学习中的关键作用。为了弥补这一差距，我们提出了一种新颖的身份线索细化和增强（ICRE）网络来挖掘和利用特定模态属性中固有的隐式判别知识。最初，我们设计了一个多感知特征细化（MPFR）模块，该模块聚合来自共享分支的浅层特征，旨在捕获容易被忽视的特定于模态的属性。然后，我们提出了语义蒸馏级联增强（SDCE）模块，该模块从聚合的浅层特征中提取身份感知知识，并指导模态不变特征的学习。最后，提出了身份线索引导（ICG）损失来减轻增强特征内的模态差异并促进多样化表示空间的学习。跨多个公共数据集的广泛实验清楚地表明，我们提出的 ICRE 优于现有的 SOTA 方法。
> **Abstract**: Visible-Infrared Person Re-Identification (VI-ReID) is a challenging cross-modal matching task due to significant modality discrepancies. While current methods mainly focus on learning modality-invariant features through unified embedding spaces, they often focus solely on the common discriminative semantics across modalities while disregarding the critical role of modality-specific identity-aware knowledge in discriminative feature learning. To bridge this gap, we propose a novel Identity Clue Refinement and Enhancement (ICRE) network to mine and utilize the implicit discriminative knowledge inherent in modality-specific attributes. Initially, we design a Multi-Perception Feature Refinement (MPFR) module that aggregates shallow features from shared branches, aiming to capture modality-specific attributes that are easily overlooked. Then, we propose a Semantic Distillation Cascade Enhancement (SDCE) module, which distills identity-aware knowledge from the aggregated shallow features and guide the learning of modality-invariant features. Finally, an Identity Clues Guided (ICG) Loss is proposed to alleviate the modality discrepancies within the enhanced features and promote the learning of a diverse representation space. Extensive experiments across multiple public datasets clearly show that our proposed ICRE outperforms existing SOTA methods.

【75】WiFi-based Cross-Domain Gesture Recognition Using Attention Mechanism
- **标题**: 使用注意力机制的基于WiFi的跨域手势识别
- **链接**: https://arxiv.org/abs/2512.04521
> **作者**: Ruijing Liu,Cunhua Pan,Jiaming Zeng,Hong Ren,Kezhi Wang,Lei Kong,Jiangzhou Wang
> **摘要**: 在完成通信任务的同时，无线信号还可以用于感知环境。在各种类型的传感介质中，WiFi信号具有广泛可用性、硬件成本低以及对光、温度和湿度等环境条件的鲁棒性强等优点。通过分析环境中的Wi-Fi信号，可以捕捉人体的动态变化，完成手势识别等传感应用。尽管许多现有的手势传感解决方案在域内表现良好，但缺乏跨域能力（即未经训练的环境中的识别性能）。为了解决这个问题，我们从所有接收器接收到的信道状态信息（CSI）中提取多普勒频谱，并将每个多普勒频谱沿同一时间轴连接起来，以生成以多角度信息作为输入特征的融合图像。此外，受卷积块注意力模块（CBAM）的启发，我们提出了一种手势识别网络，它将多语义空间注意力机制与基于自注意力的通道机制集成在一起。该网络构建注意力图来量化图像中手势的时空特征，从而能够提取与域无关的关键特征。此外，采用ResNet18作为主干网络来进一步捕获深层特征。为了验证网络性能，我们在公共 Widar3 数据集上评估了所提出的网络，结果表明它不仅保持了 99.72% 的高域内准确率，而且在跨域识别方面实现了 97.61% 的高性能，显着优于现有的最佳解决方案。
> **Abstract**: While fulfilling communication tasks, wireless signals can also be used to sense the environment. Among various types of sensing media, WiFi signals offer advantages such as widespread availability, low hardware cost, and strong robustness to environmental conditions like light, temperature, and humidity. By analyzing Wi-Fi signals in the environment, it is possible to capture dynamic changes of the human body and accomplish sensing applications such as gesture recognition. Although many existing gesture sensing solutions perform well in-domain but lack cross-domain capabilities (i.e., recognition performance in untrained environments). To address this, we extract Doppler spectra from the channel state information (CSI) received by all receivers and concatenate each Doppler spectrum along the same time axis to generate fused images with multi-angle information as input features. Furthermore, inspired by the convolutional block attention module (CBAM), we propose a gesture recognition network that integrates a multi-semantic spatial attention mechanism with a self-attention-based channel mechanism. This network constructs attention maps to quantify the spatiotemporal features of gestures in images, enabling the extraction of key domain-independent features. Additionally, ResNet18 is employed as the backbone network to further capture deep-level features. To validate the network performance, we evaluate the proposed network on the public Widar3 dataset, and the results show that it not only maintains high in-domain accuracy of 99.72%, but also achieves high performance in cross-domain recognition of 97.61%, significantly outperforming existing best solutions.

【76】Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation
- **标题**: 零样本医学图像分割的边界感知测试时间适应
- **链接**: https://arxiv.org/abs/2512.04520
> **作者**: Chenlin Xu,Lei Zhang,Lituan Wang,Xinyu Pu,Pengfei Ma,Guangwu Qian,Zizhou Wang,Yan Wang
> **摘要**: 由于注释数据的稀缺和模型的巨大计算成本，医学图像分割中的传统调整方法面临着严峻的挑战。目前适应预训练模型的方法，包括全参数和参数高效的微调，仍然严重依赖于下游任务的特定任务训练。因此，零样本分割受到越来越多的关注，尤其是 SAM 等基础模型展现出有前景的泛化能力。然而，由于领域转移，SAM 在医学数据集上仍然面临明显的限制，这使得高效的零样本增强成为紧迫的研究目标。为了应对这些挑战，我们提出了 BA-TTA-SAM，这是一种与任务无关的测试时间自适应框架，可通过测试时间自适应显着增强 SAM 的零样本分割性能。该框架集成了两个关键机制：（1）编码器级高斯提示注入将基于高斯的提示直接嵌入到图像编码器中，为初始表示学习提供明确的指导。 (2) 跨层边界感知注意力对齐利用 ViT 主干内的分层特征交互，将深层语义响应与浅层边界线索对齐。在 ISIC、Kvasir、BUSI 和 REFUGE 等四个数据集上进行的实验表明，与 SAM 的零样本分割性能相比，DICE 分数平均提高了 12.4%。结果表明，我们的方法在医学图像分割方面始终优于最先进的模型。我们的框架显着增强了 SAM 的泛化能力，而不需要任何源域训练数据。对公开医疗数据集的广泛实验有力地证明了我们框架的优越性。我们的代码可在 https://github.com/Emilychenlin/BA-TTA-SAM 获取。
> **Abstract**: Due to the scarcity of annotated data and the substantial computational costs of model, conventional tuning methods in medical image segmentation face critical challenges. Current approaches to adapting pretrained models, including full-parameter and parameter-efficient fine-tuning, still rely heavily on task-specific training on downstream tasks. Therefore, zero-shot segmentation has gained increasing attention, especially with foundation models such as SAM demonstrating promising generalization capabilities. However, SAM still faces notable limitations on medical datasets due to domain shifts, making efficient zero-shot enhancement an urgent research goal. To address these challenges, we propose BA-TTA-SAM, a task-agnostic test-time adaptation framework that significantly enhances the zero-shot segmentation performance of SAM via test-time adaptation. This framework integrates two key mechanisms: (1) The encoder-level Gaussian prompt injection embeds Gaussian-based prompts directly into the image encoder, providing explicit guidance for initial representation learning. (2) The cross-layer boundary-aware attention alignment exploits the hierarchical feature interactions within the ViT backbone, aligning deep semantic responses with shallow boundary cues. Experiments on four datasets, including ISIC, Kvasir, BUSI, and REFUGE, show an average improvement of 12.4\% in the DICE score compared with SAM's zero-shot segmentation performance. The results demonstrate that our method consistently outperforms state-of-the-art models in medical image segmentation. Our framework significantly enhances the generalization ability of SAM, without requiring any source-domain training data. Extensive experiments on publicly available medical datasets strongly demonstrate the superiority of our framework. Our code is available at https://github.com/Emilychenlin/BA-TTA-SAM.

【77】VideoSSM: Autoregressive Long Video Generation with Hybrid State-Space Memory
- **标题**: VideoSSM：具有混合状态空间存储器的自回归长视频生成
- **链接**: https://arxiv.org/abs/2512.04519
> **作者**: Yifei Yu,Xiaoshan Wu,Xinting Hu,Tao Hu,Yangtian Sun,Xiaoyang Lyu,Bo Wang,Lin Ma,Yuewen Ma,Zhongrui Wang,Xiaojuan Qi
> **摘要**: 自回归 (AR) 扩散通过因果地生成帧来实现流式传输、交互式长视频生成，但由于累积的错误、运动漂移和内容重复，保持分钟尺度范围内的连贯性仍然具有挑战性。我们从记忆的角度来处理这个问题，将视频合成视为一个需要协调的短期和长期上下文的循环动态过程。我们提出了 VideoSSM，一种将 AR 扩散与混合状态空间存储器相结合的长视频模型。状态空间模型（SSM）充当整个序列中场景动态的不断发展的全局记忆，而上下文窗口则为运动线索和精细细节提供本地记忆。这种混合设计保持了全局一致性，没有冻结、重复的模式，支持提示自适应交互，并随序列长度在线性时间内扩展。短程和长程基准测试的实验证明了自回归视频生成器具有最先进的时间一致性和运动稳定性，尤其是在分钟尺度范围内，从而实现了内容多样性和基于交互式提示的控制，从而为长视频生成建立了可扩展的、内存感知的框架。
> **Abstract**: Autoregressive (AR) diffusion enables streaming, interactive long-video generation by producing frames causally, yet maintaining coherence over minute-scale horizons remains challenging due to accumulated errors, motion drift, and content repetition. We approach this problem from a memory perspective, treating video synthesis as a recurrent dynamical process that requires coordinated short- and long-term context. We propose VideoSSM, a Long Video Model that unifies AR diffusion with a hybrid state-space memory. The state-space model (SSM) serves as an evolving global memory of scene dynamics across the entire sequence, while a context window provides local memory for motion cues and fine details. This hybrid design preserves global consistency without frozen, repetitive patterns, supports prompt-adaptive interaction, and scales in linear time with sequence length. Experiments on short- and long-range benchmarks demonstrate state-of-the-art temporal consistency and motion stability among autoregressive video generator especially at minute-scale horizons, enabling content diversity and interactive prompt-based control, thereby establishing a scalable, memory-aware framework for long video generation.

【78】EgoLCD: Egocentric Video Generation with Long Context Diffusion
- **标题**: EgoLCD：具有长上下文扩散的以自我为中心的视频生成
- **链接**: https://arxiv.org/abs/2512.04515
> **作者**: Liuzhou Zhang,Jiarui Ye,Yuanlei Wang,Ming Zhong,Mingju Cao,Wanke Xia,Bowen Zeng,Zeyu Zhang,Hao Tang
> **摘要**: 生成长而连贯的以自我为中心的视频很困难，因为手部物体交互和程序任务需要可靠的长期记忆。现有的自回归模型会受到内容漂移的影响，其中对象身份和场景语义会随着时间的推移而退化。为了应对这一挑战，我们引入了 EgoLCD，这是一种用于以自我为中心的长上下文视频生成的端到端框架，它将长视频合成视为高效稳定的内存管理问题。 EgoLCD 将用于稳定全局上下文的长期稀疏 KV 缓存与基于注意力的短期记忆相结合，并通过 LoRA 进行扩展以进行本地适应。记忆调节损失强制执行一致的内存使用，结构化叙事提示提供明确的时间指导。 EgoVid-5M 基准的大量实验表明，EgoLCD 在感知质量和时间一致性方面都实现了最先进的性能，有效地减轻了生成性遗忘，并代表着朝着构建可扩展的人工智能世界模型迈出的重要一步。代码：https://github.com/AIGeeksGroup/EgoLCD。网站：https://aigeeksgroup.github.io/EgoLCD。
> **Abstract**: Generating long, coherent egocentric videos is difficult, as hand-object interactions and procedural tasks require reliable long-term memory. Existing autoregressive models suffer from content drift, where object identity and scene semantics degrade over time. To address this challenge, we introduce EgoLCD, an end-to-end framework for egocentric long-context video generation that treats long video synthesis as a problem of efficient and stable memory management. EgoLCD combines a Long-Term Sparse KV Cache for stable global context with an attention-based short-term memory, extended by LoRA for local adaptation. A Memory Regulation Loss enforces consistent memory usage, and Structured Narrative Prompting provides explicit temporal guidance. Extensive experiments on the EgoVid-5M benchmark demonstrate that EgoLCD achieves state-of-the-art performance in both perceptual quality and temporal consistency, effectively mitigating generative forgetting and representing a significant step toward building scalable world models for embodied AI. Code: https://github.com/AIGeeksGroup/EgoLCD. Website: https://aigeeksgroup.github.io/EgoLCD.

【79】DuGI-MAE: Improving Infrared Mask Autoencoders via Dual-Domain Guidance
- **标题**: DuGI-MAE：通过双域引导改进红外掩模自动编码器
- **链接**: https://arxiv.org/abs/2512.04511
> **作者**: Yinghui Xing,Xiaoting Su,Shizhou Zhang,Donghao Chu,Di Xu
> **摘要**: 红外成像在弱光和恶劣天气条件下发挥着至关重要的作用。然而，由于红外图像的独特特征，现有的基础模型（例如在可见数据上训练的掩模自动编码器（MAE））在红外图像解释任务中表现不佳。为了弥补这一差距，开发了一种称为 InfMAE 的红外基础模型，并在大规模红外数据集上进行了预训练。尽管有效，InfMAE 仍然面临一些局限性，包括信息标记的遗漏、全局关联的建模不足以及忽略不均匀噪声。在本文中，我们提出了一种基于MAE（DuGI-MAE）的双域制导红外基础模型。首先，我们设计了一种基于令牌熵的确定性屏蔽策略，仅保留高熵令牌进行重建以增强信息量。接下来，我们介绍双域制导（DDG）模块，该模块可同时捕获全局标记关系并自适应过滤红外图像中常见的非均匀背景噪声。为了便于大规模预训练，我们构建了 Inf-590K，这是一个涵盖多种场景、多种目标类型和多种空间分辨率的综合红外图像数据集。 DuGI-MAE 在 Inf-590K 上进行预训练，在各种下游任务中表现出强大的泛化能力，包括红外目标检测、语义分割和小目标检测。实验结果验证了该方法相对于监督和自监督比较方法的优越性。我们的代码可在补充材料中找到。
> **Abstract**: Infrared imaging plays a critical role in low-light and adverse weather conditions. However, due to the distinct characteristics of infrared images, existing foundation models such as Masked Autoencoder (MAE) trained on visible data perform suboptimal in infrared image interpretation tasks. To bridge this gap, an infrared foundation model known as InfMAE was developed and pre-trained on large-scale infrared datasets. Despite its effectiveness, InfMAE still faces several limitations, including the omission of informative tokens, insufficient modeling of global associations, and neglect of non-uniform noise. In this paper, we propose a Dual-domain Guided Infrared foundation model based on MAE (DuGI-MAE). First, we design a deterministic masking strategy based on token entropy, preserving only high-entropy tokens for reconstruction to enhance informativeness. Next, we introduce a Dual-Domain Guidance (DDG) module, which simultaneously captures global token relationships and adaptively filters non-uniform background noise commonly present in infrared imagery. To facilitate large-scale pretraining, we construct Inf-590K, a comprehensive infrared image dataset encompassing diverse scenes, various target types, and multiple spatial resolutions. Pretrained on Inf-590K, DuGI-MAE demonstrates strong generalization capabilities across various downstream tasks, including infrared object detection, semantic segmentation, and small target detection. Experimental results validate the superiority of the proposed method over both supervised and self-supervised comparison methods. Our code is available in the supplementary material.

【80】UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers
- **标题**: UltraImage：重新思考图像扩散变压器中的分辨率外推
- **链接**: https://arxiv.org/abs/2512.04504
> **作者**: Min Zhao,Bokai Yan,Xue Yang,Hongzhou Zhu,Jintao Zhang,Shilong Liu,Chongxuan Li,Jun Zhu
> **摘要**: 最近的图像扩散转换器实现了高保真度生成，但难以生成超出这些比例的图像，从而遭受内容重复和质量下降的困扰。在这项工作中，我们提出了 UltraImage，一个解决这两个问题的原则性框架。通过对位置嵌入的频率分析，我们发现重复是由主频率的周期性引起的，其周期与训练分辨率一致。我们引入递归主频率校正来将其限制在外推后的单个周期内。此外，我们发现质量下降源于注意力稀释，因此提出了熵引导的自适应注意力集中，它分配较高的焦点因子来增强对细节的局部注意力，并分配较低的焦点因子到全局注意力模式以保持结构一致性。实验表明，在三代场景中，UltraImage 在 Qwen-Image 和 Flux（大约 4K）上始终优于先前的方法，减少了重复并提高了视觉保真度。此外，UltraImage可以从1328p的训练分辨率生成高达6K*6K的图像，无需低分辨率指导，展现了其极致的外推能力。项目页面位于 \href{https://thu-ml.github.io/ultraimage.github.io/}{https://thu-ml.github.io/ultraimage.github.io/}。
> **Abstract**: Recent image diffusion transformers achieve high-fidelity generation, but struggle to generate images beyond these scales, suffering from content repetition and quality degradation. In this work, we present UltraImage, a principled framework that addresses both issues. Through frequency-wise analysis of positional embeddings, we identify that repetition arises from the periodicity of the dominant frequency, whose period aligns with the training resolution. We introduce a recursive dominant frequency correction to constrain it within a single period after extrapolation. Furthermore, we find that quality degradation stems from diluted attention and thus propose entropy-guided adaptive attention concentration, which assigns higher focus factors to sharpen local attention for fine detail and lower ones to global attention patterns to preserve structural consistency. Experiments show that UltraImage consistently outperforms prior methods on Qwen-Image and Flux (around 4K) across three generation scenarios, reducing repetition and improving visual fidelity. Moreover, UltraImage can generate images up to 6K*6K without low-resolution guidance from a training resolution of 1328p, demonstrating its extreme extrapolation capability. Project page is available at \href{https://thu-ml.github.io/ultraimage.github.io/}{https://thu-ml.github.io/ultraimage.github.io/}.

【81】Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model
- **标题**: 回到基础：运动表示对于使用扩散模型生成人体运动很重要
- **链接**: https://arxiv.org/abs/2512.04499
> **作者**: Yuduo Jin,Brandon Haworth
> **摘要**: 扩散模型已成为人体运动合成中广泛使用且成功的方法。面向任务的扩散模型具有显着先进的动作到动作、文本到动作和音频到动作应用。在本文中，我们在受控研究中研究了有关运动表示和损失函数的基本问题，并列举了生成运动扩散模型工作流程中各种决策的影响。为了回答这些问题，我们基于代理运动扩散模型（MDM）进行实证研究。我们应用v损失作为MDM（vMDM）的预测目标，其中v是运动数据和噪声的加权和。我们的目标是增强对潜在数据分布的理解，并为改善条件运动扩散模型的状态提供基础。首先，我们评估文献中的六种常见运动表示，并比较它们在质量和多样性指标方面的表现。其次，我们比较了各种配置下的训练时间，以阐明如何加快运动扩散模型的训练过程。最后，我们还对大型运动数据集进行了评估分析。我们的实验结果表明，不同数据集中的运动表示存在明显的性能差异。我们的结果还证明了不同配置对模型训练的影响，并表明这些决策对运动扩散模型结果的重要性和有效性。
> **Abstract**: Diffusion models have emerged as a widely utilized and successful methodology in human motion synthesis. Task-oriented diffusion models have significantly advanced action-to-motion, text-to-motion, and audio-to-motion applications. In this paper, we investigate fundamental questions regarding motion representations and loss functions in a controlled study, and we enumerate the impacts of various decisions in the workflow of the generative motion diffusion model. To answer these questions, we conduct empirical studies based on a proxy motion diffusion model (MDM). We apply v loss as the prediction objective on MDM (vMDM), where v is the weighted sum of motion data and noise. We aim to enhance the understanding of latent data distributions and provide a foundation for improving the state of conditional motion diffusion models. First, we evaluate the six common motion representations in the literature and compare their performance in terms of quality and diversity metrics. Second, we compare the training time under various configurations to shed light on how to speed up the training process of motion diffusion models. Finally, we also conduct evaluation analysis on a large motion dataset. The results of our experiments indicate clear performance differences across motion representations in diverse datasets. Our results also demonstrate the impacts of distinct configurations on model training and suggest the importance and effectiveness of these decisions on the outcomes of motion diffusion models.

【82】Shift-Window Meets Dual Attention: A Multi-Model Architecture for Specular Highlight Removal
- **标题**: Shift-Window 满足双重关注：用于镜面高光去除的多模型架构
- **链接**: https://arxiv.org/abs/2512.04496
> **作者**: Tianci Huo,Lingfeng Qi,Yuhan Chen,Qihong Xue,Jinyuan Shao,Hai Yu,Jie Li,Zhanhua Zhang,Guofa Li
> **摘要**: 实际环境中不可避免的镜面高光严重损害了视觉性能，从而降低了任务的有效性和效率。尽管存在相当多的方法关注来自卷积神经网络模型的局部信息或来自 Transformer 模型的全局信息，但单一类型模型陷入局部细粒度细节和全局远程依赖性之间的建模困境，从而导致不同尺度的镜面高光的性能恶化。因此，为了适应所有尺度的镜面高光，我们提出了一种用于镜面高光去除（MM-SHR）的多模型架构，该架构可以有效地捕获高光区域中的细粒度特征，并对高光区域和无高光区域之间的长期依赖性进行建模。具体来说，我们利用卷积运算提取MM-SHR浅层的局部细节，并利用注意力机制捕获深层的全局特征，保证了运算效率和去除精度。为了在不影响计算复杂性的情况下对远程依赖性进行建模，我们采用从粗到细的方式，并提出了全方位注意集成块（OAIBlock）和自适应区域感知混合域双注意卷积网络（HDDAConv），它们利用原始特征的全方位像素移位和窗口划分操作来实现镜面高光去除。对三种基准任务和六种表面材料的广泛实验结果表明，MM-SHR 在镜面高光去除的准确性和效率方面均优于最先进的方法。该实施将在 https://github.com/Htcicv/MM-SHR 上公开发布。
> **Abstract**: Inevitable specular highlights in practical environments severely impair the visual performance, thus degrading the task effectiveness and efficiency. Although there exist considerable methods that focus on local information from convolutional neural network models or global information from transformer models, the single-type model falls into a modeling dilemma between local fine-grained details and global long-range dependencies, thus deteriorating for specular highlights with different scales. Therefore, to accommodate specular highlights of all scales, we propose a multi-model architecture for specular highlight removal (MM-SHR) that effectively captures fine-grained features in highlight regions and models long-range dependencies between highlight and highlight-free areas. Specifically, we employ convolution operations to extract local details in the shallow layers of MM-SHR, and utilize the attention mechanism to capture global features in the deep layers, ensuring both operation efficiency and removal accuracy. To model long-range dependencies without compromising computational complexity, we utilize a coarse-to-fine manner and propose Omni-Directional Attention Integration Block(OAIBlock) and Adaptive Region-Aware Hybrid-Domain Dual Attention Convolutional Network(HDDAConv) , which leverage omni-directiona pixel-shifting and window-dividing operations at the raw features to achieve specular highlight removal. Extensive experimental results on three benchmark tasks and six types of surface materials demonstrate that MM-SHR outperforms state-of-the-art methods in both accuracy and efficiency for specular highlight removal. The implementation will be made publicly available at https://github.com/Htcicv/MM-SHR.

【83】Controllable Long-term Motion Generation with Extended Joint Targets
- **标题**: 具有扩展关节目标的可控长期运动生成
- **链接**: https://arxiv.org/abs/2512.04487
> **作者**: Eunjong Lee,Eunhee Kim,Sanghoon Hong,Eunho Jung,Jihoon Kim
> **摘要**: 实时生成稳定且可控的角色运动是计算机动画的一个关键挑战。现有的方法通常无法提供细粒度的控制，或者会因长序列而导致运动退化，从而限制了它们在交互式应用中的使用。我们提出了 COMET，一种实时运行的自回归框架，可实现多功能的角色控制和强大的长视野合成。我们高效的基于 Transformer 的条件 VAE 允许对任意用户指定的关节进行精确的交互式控制，以完成诸如从单个模型实现目标和中间任务等任务。为了确保长期的时间稳定性，我们引入了一种新颖的参考引导反馈机制，可以防止错误累积。该机制还可以用作即插即用的风格化模块，实现实时风格传输。广泛的评估表明，COMET 能够以实时速度稳健地生成高质量运动，在复杂的运动控制任务中显着优于最先进的方法，并确认其已准备好满足要求苛刻的交互式应用。
> **Abstract**: Generating stable and controllable character motion in real-time is a key challenge in computer animation. Existing methods often fail to provide fine-grained control or suffer from motion degradation over long sequences, limiting their use in interactive applications. We propose COMET, an autoregressive framework that runs in real time, enabling versatile character control and robust long-horizon synthesis. Our efficient Transformer-based conditional VAE allows for precise, interactive control over arbitrary user-specified joints for tasks like goal-reaching and in-betweening from a single model. To ensure long-term temporal stability, we introduce a novel reference-guided feedback mechanism that prevents error accumulation. This mechanism also serves as a plug-and-play stylization module, enabling real-time style transfer. Extensive evaluations demonstrate that COMET robustly generates high-quality motion at real-time speeds, significantly outperforming state-of-the-art approaches in complex motion control tasks and confirming its readiness for demanding interactive applications.

【84】Not All Birds Look The Same: Identity-Preserving Generation For Birds
- **标题**: 并非所有鸟类看起来都一样：鸟类的身份保护一代
- **链接**: https://arxiv.org/abs/2512.04485
> **作者**: Aaron Sun,Oindrila Saha,Subhransu Maji
> **摘要**: 自从可控图像生成出现以来，越来越丰富的控制模式为日常用户提供了更大的定制性和可访问性。零样本、身份保留模型（例如 Insert Anything 和 OminiControl）现在支持虚拟试穿等应用程序，无需额外的微调。虽然这些模型可能适合人类和刚性的日常物体，但它们对于非刚性或细粒度的类别仍然存在局限性。这些领域通常缺乏可访问的高质量数据——尤其是同一主题的视频或多视图观察——使得它们难以评估和改进。然而，这些领域对于从内容创建转向需要准确性和细节的应用程序至关重要。鸟类是完成这项任务的绝佳领域：它们表现出高度的多样性，需要细粒度的线索来识别，并且有各种各样的姿势。我们引入了 NABirds Look-Alikes (NABLA) 数据集，该数据集由 4,759 个专家策划的图像对组成。与从 iNaturalist 上的多图像观察中收集的 1,073 对数据和一小部分视频一起，这构成了评估保留身份的一代鸟类的基准。我们表明，最先进的基线无法保持该数据集的身份，并且我们证明，对按物种、年龄和性别分组的图像进行训练（用作身份的代理）可以显着提高已见和未见物种的性能。
> **Abstract**: Since the advent of controllable image generation, increasingly rich modes of control have enabled greater customization and accessibility for everyday users. Zero-shot, identity-preserving models such as Insert Anything and OminiControl now support applications like virtual try-on without requiring additional fine-tuning. While these models may be fitting for humans and rigid everyday objects, they still have limitations for non-rigid or fine-grained categories. These domains often lack accessible, high-quality data -- especially videos or multi-view observations of the same subject -- making them difficult both to evaluate and to improve upon. Yet, such domains are essential for moving beyond content creation toward applications that demand accuracy and fine detail. Birds are an excellent domain for this task: they exhibit high diversity, require fine-grained cues for identification, and come in a wide variety of poses. We introduce the NABirds Look-Alikes (NABLA) dataset, consisting of 4,759 expert-curated image pairs. Together with 1,073 pairs collected from multi-image observations on iNaturalist and a small set of videos, this forms a benchmark for evaluating identity-preserving generation of birds. We show that state-of-the-art baselines fail to maintain identity on this dataset, and we demonstrate that training on images grouped by species, age, and sex -- used as a proxy for identity -- substantially improves performance on both seen and unseen species.

【85】DeRA: Decoupled Representation Alignment for Video Tokenization
- **标题**: DeRA：视频标记化的解耦表示对齐
- **链接**: https://arxiv.org/abs/2512.04483
> **作者**: Pengbo Guo,Junke Wang,Zhen Xing,Chengxu Liu,Daoguo Dong,Xueming Qian,Zuxuan Wu
> **摘要**: 本文提出了 DeRA，一种新颖的一维视频标记器，它将视频标记化中的时空表示学习解耦，以实现更好的训练效率和性能。具体来说，DeRA 保持紧凑的一维潜在空间，同时将视频编码分解为外观和运动流，这些流与预训练的视觉基础模型保持一致，以分别捕获视频中的空间语义和时间动态。为了解决异构监督引入的梯度冲突，我们进一步提出了对称对齐冲突投影（SACP）模块，该模块通过抑制沿冲突方向的分量来主动重新构造梯度。大量实验表明，在 rFVD 方面，DeRA 在 UCF-101 上的性能比 LARP（之前最先进的视频分词器）高出 25%。此外，使用 DeRA 进行自回归视频生成，我们还在 UCF-101 类条件生成和 K600 帧预测上取得了最新的结果。
> **Abstract**: This paper presents DeRA, a novel 1D video tokenizer that decouples the spatial-temporal representation learning in video tokenization to achieve better training efficiency and performance. Specifically, DeRA maintains a compact 1D latent space while factorizing video encoding into appearance and motion streams, which are aligned with pretrained vision foundation models to capture the spatial semantics and temporal dynamics in videos separately. To address the gradient conflicts introduced by the heterogeneous supervision, we further propose the Symmetric Alignment-Conflict Projection (SACP) module that proactively reformulates gradients by suppressing the components along conflicting directions. Extensive experiments demonstrate that DeRA outperforms LARP, the previous state-of-the-art video tokenizer by 25% on UCF-101 in terms of rFVD. Moreover, using DeRA for autoregressive video generation, we also achieve new state-of-the-art results on both UCF-101 class-conditional generation and K600 frame prediction.

【86】UniTS: Unified Time Series Generative Model for Remote Sensing
- **标题**: UnitTS：遥感统一时间序列生成模型
- **链接**: https://arxiv.org/abs/2512.04461
> **作者**: Yuxiang Zhang,Shunlin Liang,Wenyuan Li,Han Ma,Jianglei Xu,Yichuan Ma,Jiangwei Xie,Wei Li,Mengmeng Zhang,Ran Tao,Xiang-Gen Xia
> **摘要**: 卫星遥感的主要目标之一是捕获地球环境的复杂动态，其中包括重建连续无云时间序列图像、检测土地覆盖变化和预测未来地表演化等任务。然而，现有方法通常需要针对不同任务定制的专门模型，缺乏跨多个时间序列任务的时空特征的统一建模。在本文中，我们提出了统一时间序列生成模型（UnitTS），这是一个适用于各种时间序列任务的通用框架，包括时间序列重建、时间序列云去除、时间序列语义变化检测和时间序列预测。基于流匹配生成范式，UnitTS在特定任务条件的指导下构建从噪声到目标的确定性进化路径，实现多任务时空表示的统一建模。 UniTS 架构由具有时空块的扩散变压器组成，我们设计了自适应条件注入器（ACor）来增强模型对多模态输入的条件感知，从而实现高质量的可控生成。此外，我们设计了一个时空感知调制器（STM）来提高时空块捕获复杂时空依赖性的能力。此外，我们构建了两个高质量的多模态时间序列数据集TS-S12和TS-S12CR，填补了时间序列去云和预测任务基准数据集的空白。大量实验表明，UnitTS 在低级和高级时间序列任务中都表现出卓越的生成和认知能力。它显着优于现有方法，特别是在面临严重云污染、模态缺失和预测物候变化等挑战时。
> **Abstract**: One of the primary objectives of satellite remote sensing is to capture the complex dynamics of the Earth environment, which encompasses tasks such as reconstructing continuous cloud-free time series images, detecting land cover changes, and forecasting future surface evolution. However, existing methods typically require specialized models tailored to different tasks, lacking unified modeling of spatiotemporal features across multiple time series tasks. In this paper, we propose a Unified Time Series Generative Model (UniTS), a general framework applicable to various time series tasks, including time series reconstruction, time series cloud removal, time series semantic change detection, and time series forecasting. Based on the flow matching generative paradigm, UniTS constructs a deterministic evolution path from noise to targets under the guidance of task-specific conditions, achieving unified modeling of spatiotemporal representations for multiple tasks. The UniTS architecture consists of a diffusion transformer with spatio-temporal blocks, where we design an Adaptive Condition Injector (ACor) to enhance the model's conditional perception of multimodal inputs, enabling high-quality controllable generation. Additionally, we design a Spatiotemporal-aware Modulator (STM) to improve the ability of spatio-temporal blocks to capture complex spatiotemporal dependencies. Furthermore, we construct two high-quality multimodal time series datasets, TS-S12 and TS-S12CR, filling the gap of benchmark datasets for time series cloud removal and forecasting tasks. Extensive experiments demonstrate that UniTS exhibits exceptional generative and cognitive capabilities in both low-level and high-level time series tasks. It significantly outperforms existing methods, particularly when facing challenges such as severe cloud contamination, modality absence, and forecasting phenological variations.

【87】dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning
- **标题**: dVLM-AD：通过可控推理增强驾驶的扩散视觉语言模型
- **链接**: https://arxiv.org/abs/2512.04459
> **作者**: Yingzi Ma,Yulong Cao,Wenhao Ding,Shuibai Zhang,Yan Wang,Boris Ivanovic,Ming Jiang,Marco Pavone,Chaowei Xiao
> **摘要**: 自动驾驶社区越来越关注解决分布式（OOD）驾驶场景带来的挑战。主导研究趋势旨在通过集成视觉语言模型（VLM）来增强端到端（E2E）驾驶系统，利用其丰富的世界知识和推理能力来提高跨不同环境的泛化能力。然而，大多数现有的 VLM 或视觉语言代理 (VLA) 都是基于自回归 (AR) 模型构建的。在本文中，我们观察到现有的基于 AR 的 VLM——受到因果注意力和顺序令牌生成的限制——通常无法保持高级推理和低级规划之间的一致性和可控性。相比之下，最近配备双向注意力的离散扩散 VLM 通过迭代去噪表现出卓越的可控性和可靠性。基于这些观察，我们引入了 dVLM-AD，这是一种基于扩散的视觉语言模型，它统一了端到端驾驶的感知、结构化推理和低级规划。在 nuScenes 和 WOD-E2E 上进行评估，dVLM-AD 产生了更一致的推理-动作对，并实现了与现有驾驶 VLM/VLA 系统相当的规划性能，尽管骨干网规模不大，其性能优于基于 AR 的基线，在长尾 WOD-E2E 场景下，行为轨迹一致性提高了 9%，RFS 提高了 6%。这些结果表明了可扩展的端到端驱动的可控且可靠的途径。
> **Abstract**: The autonomous driving community is increasingly focused on addressing the challenges posed by out-of-distribution (OOD) driving scenarios. A dominant research trend seeks to enhance end-to-end (E2E) driving systems by integrating vision-language models (VLMs), leveraging their rich world knowledge and reasoning abilities to improve generalization across diverse environments. However, most existing VLMs or vision-language agents (VLAs) are built upon autoregressive (AR) models. In this paper, we observe that existing AR-based VLMs -- limited by causal attention and sequential token generation -- often fail to maintain consistency and controllability between high-level reasoning and low-level planning. In contrast, recent discrete diffusion VLMs equipped with bidirectional attention exhibit superior controllability and reliability through iterative denoising. Building on these observations, we introduce dVLM-AD, a diffusion-based vision-language model that unifies perception, structured reasoning, and low-level planning for end-to-end driving. Evaluated on nuScenes and WOD-E2E, dVLM-AD yields more consistent reasoning-action pairs and achieves planning performance comparable to existing driving VLM/VLA systems despite a modest backbone, outperforming AR-based baselines with a 9 percent improvement in behavior-trajectory consistency and a 6 percent increase in RFS on long-tail WOD-E2E scenarios. These results suggest a controllable and reliable pathway for scalable end-to-end driving.

【88】GuidNoise: Single-Pair Guided Diffusion for Generalized Noise Synthesis
- **标题**: GuidNoise：用于广义噪声合成的单对引导扩散
- **链接**: https://arxiv.org/abs/2512.04456
> **作者**: Changjin Kim,HyeokJun Lee,YoungJoon Yoo
> **摘要**: 最近的图像去噪方法利用生成模型进行真实噪声合成，以解决现实世界噪声数据采集成本高昂的问题。然而，这些生成模型通常需要相机元数据和广泛的特定目标的噪声-干净图像对，通常显示设置之间的泛化能力有限。在本文中，为了减轻先决条件，我们提出了用于广义噪声合成 GuidNoise 的单对引导扩散，它使用单个噪声/干净对作为指导，通常可以在训练集中轻松获得。为了训练 GuidNoise（从引导生成合成噪声图像），我们引入了引导感知仿射特征修改（GAFM）和噪声感知细化损失，以利用扩散模型的固有潜力。该损失函数改进了扩散模型的后向过程，使模型更擅长生成真实的噪声分布。 GuidNoise 在不同的噪声环境下合成高质量的噪声图像，在训练和推理过程中无需额外的元数据。此外，GuidNoise 能够在推理时有效生成噪声干净的图像对，使合成噪声易于适用于增强训练数据。这种自我增强显着提高了去噪性能，尤其是在轻量级模型和有限训练数据的实际场景中。代码可在 https://github.com/chjinny/GuidNoise 获取。
> **Abstract**: Recent image denoising methods have leveraged generative modeling for real noise synthesis to address the costly acquisition of real-world noisy data. However, these generative models typically require camera metadata and extensive target-specific noisy-clean image pairs, often showing limited generalization between settings. In this paper, to mitigate the prerequisites, we propose a Single-Pair Guided Diffusion for generalized noise synthesis GuidNoise, which uses a single noisy/clean pair as the guidance, often easily obtained by itself within a training set. To train GuidNoise, which generates synthetic noisy images from the guidance, we introduce a guidance-aware affine feature modification (GAFM) and a noise-aware refine loss to leverage the inherent potential of diffusion models. This loss function refines the diffusion model's backward process, making the model more adept at generating realistic noise distributions. The GuidNoise synthesizes high-quality noisy images under diverse noise environments without additional metadata during both training and inference. Additionally, GuidNoise enables the efficient generation of noisy-clean image pairs at inference time, making synthetic noise readily applicable for augmenting training data. This self-augmentation significantly improves denoising performance, especially in practical scenarios with lightweight models and limited training data. The code is available at https://github.com/chjinny/GuidNoise.

## 计算机与社会(cs.CY:Computers and Society)

【1】Developing a General Personal Tutor for Education
- **标题**: 培养一名普通的私人教育导师
- **链接**: https://arxiv.org/abs/2512.04869
> **作者**: Jaan Aru,Kristjan-Julius Laak
> **摘要**: 尽管经过了数十年的努力，通用人工智能导师的愿景仍然难以实现。法学硕士能否改变游戏规则？我们概述了开发全国性人工智能导师时出现的新问题。我们强调了一些实际问题，这些问题指出了我们对学习过程的科学理解中的具体差距。
> **Abstract**: The vision of a universal AI tutor has remained elusive, despite decades of effort. Could LLMs be the game-changer? We overview novel issues arising from developing a nationwide AI tutor. We highlight the practical questions that point to specific gaps in our scientific understanding of the learning process.

## 数据结构和算法(cs.DS:Data Structures and Algorithms)

【1】On Tight FPT Time Approximation Algorithms for k-Clustering Problems
- **标题**: k聚类问题的紧FPT时间逼近算法
- **链接**: https://arxiv.org/abs/2512.04614
> **作者**: Han Dai,Shi Li,Sijin Peng
> **摘要**: 随着近似算法与固定参数易处理性 (FPT) 相结合的最新进展，我们研究了最小范数 $k$ 聚类问题的 FPT 时间近似算法，由开放设施的数量 $k$ 进行参数化。对于赋能设置，我们为由 $k$ 和 $ε$ 参数化的 FPT 时间中的一般范数赋能 $k$ 聚类问题给出了严格的 $(3+ε)$ 近似。在我们的工作之前，只有在有能力的 $k$ 中值问题中才知道这样的结果 [CL，ICALP，2019]。作为一种特殊情况，我们的结果对于有能力的 $k$ 中心产生 FPT 时间 $3$ 近似值。该问题尚未在 FPT 时间设置下进行研究，之前最著名的多项式时间逼近比为 9 [ABCG, MP, 2015]。在无能力设置中，我们考虑$top$-$cn$范数$k$聚类问题，其中问题的目标是最小化连接距离向量的$top$-$cn$范数。我们的主要结果是针对 $c \in \big(\frac1e, 1\big]$ 问题的紧 $\big(1 + \frac 2{ec} + ε\big)$ 近似算法。（对于 $c \leq \frac1e$ 的情况，有一个简单的紧 $(3+ε)$ 近似。）我们的框架可以轻松扩展以给出紧 $\left(3, 1+\frac2e + FPT 时间内 ($k$-center, $k$-median) 问题的 ε\right)$-bicriteria 近似，改进了之前的最佳多项式时间 $(4, 8)$ 保证 [AB, WAOA, 2017] 所有结果均基于统一框架：通过 LP 使用 $O\left(\frac{k\log n}ε\right)$ 设施 $S$ 计算 $(1+ε)$-近似解。四舍五入，根据解决方案 $S$ 对一些客户代表 $R$ 进行采样，从 $S \cup R$ 中猜测一些枢轴以及枢轴上的一些半径信息，并使用猜测来解决问题。我们相信该框架可以在 $k$ 聚类问题上产生进一步的结果。
> **Abstract**: Following recent advances in combining approximation algorithms with fixed-parameter tractability (FPT), we study FPT-time approximation algorithms for minimum-norm $k$-clustering problems, parameterized by the number $k$ of open facilities. For the capacitated setting, we give a tight $(3+ε)$-approximation for the general-norm capacitated $k$-clustering problem in FPT-time parameterized by $k$ and $ε$. Prior to our work, such a result was only known for the capacitated $k$-median problem [CL, ICALP, 2019]. As a special case, our result yields an FPT-time $3$-approximation for capacitated $k$-center. The problem has not been studied in the FPT-time setting, with the previous best known polynomial-time approximation ratio being 9 [ABCG, MP, 2015]. In the uncapacitated setting, we consider the $top$-$cn$ norm $k$-clustering problem, where the goal of the problem is to minimize the $top$-$cn$ norm of the connection distance vector. Our main result is a tight $\big(1 + \frac 2{ec} + ε\big)$-approximation algorithm for the problem with $c \in \big(\frac1e, 1\big]$. (For the case $c \leq \frac1e$, there is a simple tight $(3+ε)$-approximation.) Our framework can be easily extended to give a tight $\left(3, 1+\frac2e + ε\right)$-bicriteria approximation for the ($k$-center, $k$-median) problem in FPT time, improving the previous best polynomial-time $(4, 8)$ guarantee [AB, WAOA, 2017]. All results are based on a unified framework: computing a $(1+ε)$-approximate solution using $O\left(\frac{k\log n}ε\right)$ facilities $S$ via LP rounding, sampling a few client representatives $R$ based on the solution $S$, guessing a few pivots from $S \cup R$ and some radius information on the pivots, and solving the problem using the guesses. We believe this framework can lead to further results on $k$-clustering problems.

## 图形(cs.GR:Graphics)

【1】Efficient Spatially-Variant Convolution via Differentiable Sparse Kernel Complex
- **标题**: 通过可微稀疏核复合体进行高效空间变异卷积
- **链接**: https://arxiv.org/abs/2512.04556
> **作者**: Zhizhen Wu,Zhe Cao,Yuchi Huo
> **摘要**: 具有复杂内核的图像卷积是摄影、科学成像和动画效果中的基本操作，但直接密集卷积在资源有限的设备上计算量巨大。现有的近似方法，例如模拟退火或低秩分解，要么缺乏效率，要么无法捕获非凸核。我们引入了一种可微核分解框架，该框架使用一组稀疏核样本来表示目标空间变化的、密集的、复杂的核。我们的方法具有（i）能够对稀疏内核进行可微分优化的分解，（ii）针对非凸形状的专用初始化策略，以避免不良的局部最小值，以及（iii）内核空间插值方案，将单内核过滤扩展到空间变化的过滤，而无需重新训练和额外的运行时开销。高斯核和非凸核的实验表明，我们的方法比模拟退火具有更高的保真度，并且比低秩分解的成本显着降低。我们的方法为移动成像和实时渲染提供了实用的解决方案，同时保持完全可微分以集成到更广泛的学习管道中。
> **Abstract**: Image convolution with complex kernels is a fundamental operation in photography, scientific imaging, and animation effects, yet direct dense convolution is computationally prohibitive on resource-limited devices. Existing approximations, such as simulated annealing or low-rank decompositions, either lack efficiency or fail to capture non-convex kernels. We introduce a differentiable kernel decomposition framework that represents a target spatially-variant, dense, complex kernel using a set of sparse kernel samples. Our approach features (i) a decomposition that enables differentiable optimization of sparse kernels, (ii) a dedicated initialization strategy for non-convex shapes to avoid poor local minima, and (iii) a kernel-space interpolation scheme that extends single-kernel filtering to spatially varying filtering without retraining and additional runtime overhead. Experiments on Gaussian and non-convex kernels show that our method achieves higher fidelity than simulated annealing and significantly lower cost than low-rank decompositions. Our approach provides a practical solution for mobile imaging and real-time rendering, while remaining fully differentiable for integration into broader learning pipelines.

## 人机交互(cs.HC:Human-Computer Interaction)

【1】Perceptually-Minimal Color Optimization for Web Accessibility: A Multi-Phase Constrained Approach
- **标题**: Web 可访问性的感知最小颜色优化：多阶段约束方法
- **链接**: https://arxiv.org/abs/2512.05067
> **作者**: Lalitha A R
> **摘要**: 网络可访问性指南要求文本和背景之间有足够的颜色对比度；然而，手动调整颜色通常需要显着的视觉偏差，从而损害重要的品牌美感。我们提出了一种新颖的多阶段优化方法，用于自动生成符合 WCAG 标准的颜色，同时最大限度地减少对原始设计选择的感知变化。我们的方法利用现代感知统一的 OKLCH 颜色空间，将其视为受约束的非线性优化问题。至关重要的是，优化仅限于保留颜色的原始色调 ($\text{H}$)，确保修改严格限于亮度 ($\text{L}$) 和色度 ($\text{C}$) 的必要调整。这是通过三阶段序列实现的：二分搜索、梯度下降和渐进约束松弛。对 10,000 个程序生成的颜色对的数据集的评估表明，该算法成功解决了 $77.22\%$ 案例中的可访问性违规问题，其中 $88.51\%$ 的成功校正表现出由标准感知阈值定义的难以察觉的色差 ($ΔE_{2000} < 2.0$)。成功调整的感知变化中值仅为 $0.76\ ΔE_{2000}$，而该算法通过每个颜色对的中值处理时间 $0.876\text{ms}$ 实现了这一目标。该方法表明，通过尊重品牌标识的计算高效、感知感知的优化，可以同时实现可访问性合规性和视觉设计完整性。该算法在开源 cm-colors Python 库中公开实现。
> **Abstract**: Web accessibility guidelines require sufficient color contrast between text and backgrounds; yet, manually adjusting colors often necessitates significant visual deviation, compromising vital brand aesthetics. We present a novel, multi-phase optimization approach for automatically generating WCAG-compliant colors while minimizing perceptual change to original design choices. Our method treats this as a constrained, non-linear optimization problem, utilizing the modern perceptually uniform OKLCH color space. Crucially, the optimization is constrained to preserve the original hue ($\text{H}$) of the color, ensuring that modifications are strictly limited to necessary adjustments in lightness ($\text{L}$) and chroma ($\text{C}$). This is achieved through a three-phase sequence: binary search, gradient descent, and progressive constraint relaxation. Evaluation on a dataset of 10,000 procedurally generated color pairs demonstrates that the algorithm successfully resolves accessibility violations in $77.22\%$ of cases, with $88.51\%$ of successful corrections exhibiting imperceptible color difference ($ΔE_{2000} < 2.0$) as defined by standard perceptibility thresholds. The median perceptual change for successful adjustments is only $0.76\ ΔE_{2000}$, and the algorithm achieves this with a median processing time of $0.876\text{ms}$ per color pair. The approach demonstrates that accessibility compliance and visual design integrity can be achieved simultaneously through a computationally efficient, perceptually-aware optimization that respects brand identity. The algorithm is publicly implemented in the open-source cm-colors Python library.

【2】From Symptoms to Systems: An Expert-Guided Approach to Understanding Risks of Generative AI for Eating Disorders
- **标题**: 从症状到系统：专家指导的方法来了解生成人工智能治疗饮食失调的风险
- **链接**: https://arxiv.org/abs/2512.04843
> **作者**: Amy Winecoff,Kevin Klyman
> **摘要**: 生成式人工智能系统可能会给易患饮食失调的个体带来严重风险。现有的保障措施往往忽视微妙但具有临床意义的线索，导致许多风险得不到解决。为了更好地了解这些风险的本质，我们对 15 名具有饮食失调专业知识的临床医生、研究人员和倡导者进行了半结构化访谈。利用溯因定性分析，我们制定了专家指导的生成人工智能风险分类法，涵盖七个类别：（1）提供通用的健康建议； （二）鼓励失序行为的； (3) 支持症状隐藏； (4) 创造灵感； （5）强化消极的自我信念； (6) 促使过度关注身体； (7) 延续对饮食失调的狭隘观点。我们的结果表明，某些用户与生成人工智能系统的交互如何与饮食失调的临床特征相交叉，从而可能加剧风险。我们与领域专家讨论我们工作的影响，包括风险评估方法、保障设计和参与式评估实践。
> **Abstract**: Generative AI systems may pose serious risks to individuals vulnerable to eating disorders. Existing safeguards tend to overlook subtle but clinically significant cues, leaving many risks unaddressed. To better understand the nature of these risks, we conducted semi-structured interviews with 15 clinicians, researchers, and advocates with expertise in eating disorders. Using abductive qualitative analysis, we developed an expert-guided taxonomy of generative AI risks across seven categories: (1) providing generalized health advice; (2) encouraging disordered behaviors; (3) supporting symptom concealment; (4) creating thinspiration; (5) reinforcing negative self-beliefs; (6) promoting excessive focus on the body; and (7) perpetuating narrow views about eating disorders. Our results demonstrate how certain user interactions with generative AI systems intersect with clinical features of eating disorders in ways that may intensify risk. We discuss implications of our work, including approaches for risk assessment, safeguard design, and participatory evaluation practices with domain experts.

【3】Interactive Communication -- cross-disciplinary perspectives from psychology, acoustics, and media technology
- **标题**: 互动传播——心理学、声学和媒体技术的跨学科视角
- **链接**: https://arxiv.org/abs/2512.04692
> **作者**: Mareike Daeglau,Stephan Getzmann,Moritz Bender,Janina Fels,Rainer Martin,Alexander Raake,Isabel S. Schiller,Sabine J. Schlittmeier,Katrin Schoenenberg,Felix Stärz,Leon O. H. Kroczek
> **摘要**: 互动交流（IC），即两个或多个互动伙伴之间相互交换信息，是人性的基本组成部分。因此，它已被跨多个科学学科以不同的目标和方法进行研究。本文提供了当代 IC 的跨学科入门读物，它将心理机制与跨理论、测量和应用的声学和媒体技术限制相结合。首先，我们概述了解释 IC 的言语、非言语和多模态方面的理论框架，包括面对面沟通和计算机介导的沟通之间的区别。其次，我们总结了关键的方法论途径，包括交流同步性和声学信号质量的行为、认知和体验测量。第三，我们讨论选定的应用程序，即辅助听力技术、会话代理以及道德考虑。总而言之，这篇综述强调了人类能力和技术系统如何共同塑造 IC，整合经常在不同研究领域讨论的概念、发现和挑战。
> **Abstract**: Interactive communication (IC), i.e., the reciprocal exchange of information between two or more interactive partners, is a fundamental part of human nature. As such, it has been studied across multiple scientific disciplines with different goals and methods. This article provides a cross-disciplinary primer on contemporary IC that integrates psychological mechanisms with acoustic and media-technological constraints across theory, measurement, and applications. First, we outline theoretical frameworks that account for verbal, nonverbal and multimodal aspects of IC, including distinctions between face-to-face and computer-mediated communication. Second, we summarize key methodological approaches, including behavioral, cognitive, and experiential measures of communicative synchrony and acoustic signal quality. Third, we discuss selected applications, i.e. assistive listening technologies, conversational agents, alongside ethical considerations. Taken together, this review highlights how human capacities and technical systems jointly shape IC, consolidating concepts, findings, and challenges that have often been discussed in separate lines of research.

## 机器学习(cs.LG:Machine Learning)

【1】The Universal Weight Subspace Hypothesis
- **标题**: 通用权子空间假说
- **链接**: https://arxiv.org/abs/2512.05117
> **作者**: Prakhar Kaushik,Shravan Chaudhari,Ankit Vaidya,Rama Chellappa,Alan Yuille
> **摘要**: 我们表明，跨不同任务训练的深度神经网络表现出非常相似的低维参数子空间。我们提供了第一个大规模的经验证据，证明神经网络系统地收敛到共享谱子空间，无论初始化、任务或域如何。通过对 1100 多个模型（包括 500 个 Mistral-7B LoRA、500 个 Vision Transformers 和 50 个 LLaMA-8B 模型）进行模式频谱分析，我们确定了仅在几个主要方向上捕获多数方差的通用子空间。通过将谱分解技术应用于在各种任务和数据集上训练的各种架构的权重矩阵，我们识别出在跨不同任务和数据集的共享架构中一致利用的稀疏联合子空间。我们的研究结果为深层网络中信息的内在组织提供了新的见解，并提出了关于在不需要大量数据和计算资源的情况下发现这些通用子空间的可能性的重要问题。此外，这种固有结构对模型可重用性、多任务学习、模型合并以及训练和推理高效算法的开发具有重要意义，有可能减少大规模神经模型的碳足迹。
> **Abstract**: We show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces. We provide the first large-scale empirical evidence that demonstrates that neural networks systematically converge to shared spectral subspaces regardless of initialization, task, or domain. Through mode-wise spectral analysis of over 1100 models - including 500 Mistral-7B LoRAs, 500 Vision Transformers, and 50 LLaMA-8B models - we identify universal subspaces capturing majority variance in just a few principal directions. By applying spectral decomposition techniques to the weight matrices of various architectures trained on a wide range of tasks and datasets, we identify sparse, joint subspaces that are consistently exploited, within shared architectures across diverse tasks and datasets. Our findings offer new insights into the intrinsic organization of information within deep networks and raise important questions about the possibility of discovering these universal subspaces without the need for extensive data and computational resources. Furthermore, this inherent structure has significant implications for model reusability, multi-task learning, model merging, and the development of training and inference-efficient algorithms, potentially reducing the carbon footprint of large-scale neural models.

【2】Value Gradient Guidance for Flow Matching Alignment
- **标题**: 流量匹配对准的值梯度指导
- **链接**: https://arxiv.org/abs/2512.05116
> **作者**: Zhen Liu,Tim Z. Xiao,Carles Domingo-Enrich,Weiyang Liu,Dinghuai Zhang
> **摘要**: 虽然存在将流匹配模型（一类流行且有效的生成模型）与人类偏好对齐的方法，但现有方法无法实现适应效率和概率上合理的先验保留。在这项工作中，我们利用最优控制理论，提出了 VGG-Flow，一种基于梯度匹配的方法，用于微调预训练的流匹配模型。该算法背后的关键思想是，微调速度场和预训练速度场之间的最佳差异应与值函数的梯度场相匹配。该方法不仅结合了来自奖励模型的一阶信息，而且受益于价值函数的启发式初始化以实现快速适应。根据经验，我们在流行的文本到图像流匹配模型（Stable Diffusion 3）上证明，我们的方法可以在有限的计算预算下微调流匹配模型，同时实现有效且保留先验的对齐。
> **Abstract**: While methods exist for aligning flow matching models--a popular and effective class of generative models--with human preferences, existing approaches fail to achieve both adaptation efficiency and probabilistically sound prior preservation. In this work, we leverage the theory of optimal control and propose VGG-Flow, a gradient-matching-based method for finetuning pretrained flow matching models. The key idea behind this algorithm is that the optimal difference between the finetuned velocity field and the pretrained one should be matched with the gradient field of a value function. This method not only incorporates first-order information from the reward model but also benefits from heuristic initialization of the value function to enable fast adaptation. Empirically, we show on a popular text-to-image flow matching model, Stable Diffusion 3, that our method can finetune flow matching models under limited computational budgets while achieving effective and prior-preserving alignment.

【3】Deep infant brain segmentation from multi-contrast MRI
- **标题**: 多对比 MRI 深度婴儿大脑分割
- **链接**: https://arxiv.org/abs/2512.05114
> **作者**: Malte Hoffmann,Lilla Zöllei,Adrian V. Dalca
> **摘要**: 磁共振图像 (MRI) 的分割通过描绘解剖结构来促进对人脑发育的分析。然而，对于婴幼儿来说，由于发育和成像的限制，准确的分割具有挑战性。众所周知，儿童脑部 MRI 很难获取，成像方式的可用性不一致、视野中存在大量非头部解剖结构以及频繁的运动伪影。这导致了专门的分割模型，这些模型通常仅限于特定的图像类型或狭窄的年龄组，或者对于更多变化的图像（例如临床获取的图像）来说很脆弱。我们使用 BabySeg 解决了这种方法碎片化问题，BabySeg 是一种针对婴幼儿的深度学习大脑分割框架，支持多种 MRI 协议，包括重复扫描和训练期间不可用的图像类型。我们的方法建立在最近的域随机化技术的基础上，该技术合成远远超出现实范围的训练图像，以促进数据集移位不变性。我们还描述了一种机制，使模型能够灵活地池化和交互来自任意数量输入扫描的特征。我们展示了最先进的性能，可以使用单个模型来匹配或超过针对不同年龄组和输入配置的几种现有方法的准确性，而所需的运行时间只是许多现有工具所需的一小部分。
> **Abstract**: Segmentation of magnetic resonance images (MRI) facilitates analysis of human brain development by delineating anatomical structures. However, in infants and young children, accurate segmentation is challenging due to development and imaging constraints. Pediatric brain MRI is notoriously difficult to acquire, with inconsistent availability of imaging modalities, substantial non-head anatomy in the field of view, and frequent motion artifacts. This has led to specialized segmentation models that are often limited to specific image types or narrow age groups, or that are fragile for more variable images such as those acquired clinically. We address this method fragmentation with BabySeg, a deep learning brain segmentation framework for infants and young children that supports diverse MRI protocols, including repeat scans and image types unavailable during training. Our approach builds on recent domain randomization techniques, which synthesize training images far beyond realistic bounds to promote dataset shift invariance. We also describe a mechanism that enables models to flexibly pool and interact features from any number of input scans. We demonstrate state-of-the-art performance that matches or exceeds the accuracy of several existing methods for various age cohorts and input configurations using a single model, in a fraction of the runtime required by many existing tools.

【4】TV2TV: A Unified Framework for Interleaved Language and Video Generation
- **标题**: TV2TV：交错语言和视频生成的统一框架
- **链接**: https://arxiv.org/abs/2512.05103
> **作者**: Xiaochuang Han,Youssef Emad,Melissa Hall,John Nguyen,Karthik Padthe,Liam Robbins,Amir Bar,Delong Chen,Michal Drozdzal,Maha Elbayad,Yushi Hu,Shang-Wen Li,Sreya Dutta Roy,Jakob Verbeek,XuDong Wang,Marjan Ghazvininejad,Luke Zettlemoyer,Emily Dinan
> **摘要**: 视频生成模型正在迅速发展，但仍然难以应对复杂的视频输出，这些输出需要大量的语义分支或对接下来应该发生的情况进行重复的高级推理。在本文中，我们介绍了一类新型全向视频文本模型，该模型集成了最新的 LM 推理进展的思想来应对这一挑战。更具体地说，我们提出了 TV2TV，一个统一的生成建模框架，它将视频生成分解为交错的文本和视频生成过程。 TV2TV 使用 Mixture-of-Transformers (MoT) 架构联合学习语言建模（下一个标记预测）和视频流匹配（下一帧预测）。在推理时，TV2TV 决定何时交替生成文本和视频帧，从而允许模型在“以像素行动”生成帧之前“用文字思考”后续内容。这种设计减轻了决定语言建模塔旁边应该发生什么的大部分责任，从而提高了视觉质量并及时对齐生成的视频。它还实现了细粒度的可控性，允许用户在过程中的任何点通过文本干预来修改视频生成轨迹。在视频游戏数据的受控实验中，TV2TV 在视觉质量和可控性方面都表现出了显着的改进。 TV2TV 还可以扩展到自然视频，正如我们通过使用视觉语言模型 (VLM) 通过交错的自然语言动作描述来增强体育视频所展示的那样。在此语料库上训练 TV2TV 可产生强大的视觉质量和及时的对齐，展示了模型推理和生成复杂的现实世界动作序列的能力。总之，这些结果凸显了 TV2TV 是朝着具有开放式文本推理和控制的视频生成迈出了有希望的一步。
> **Abstract**: Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from recent LM reasoning advances to address this challenge. More specifically, we present TV2TV, a unified generative modeling framework which decomposes video generation into an interleaved text and video generation process. TV2TV jointly learns language modeling (next-token prediction) and video flow matching (next-frame prediction) using a Mixture-of-Transformers (MoT) architecture. At inference time, TV2TV decides when to alternate between generating text and video frames, allowing the model to "think in words" about subsequent content before ``acting in pixels'' to produce frames. This design offloads much of the responsibility for deciding what should happen next to the language modeling tower, enabling improved visual quality and prompt alignment of generated videos. It also enables fine-grained controllability, allowing users to modify the video generation trajectory through text interventions at any point in the process. In controlled experiments on video game data, TV2TV demonstrates substantial improvements in both visual quality and controllability. TV2TV also scales to natural videos, as we show by augmenting sports videos with interleaved natural language action descriptions using vision-language models (VLMs). Training TV2TV on this corpus yields strong visual quality and prompt alignment, showcasing the model's ability to reason about and generate complex real-world action sequences. Together, these results highlight TV2TV as a promising step toward video generation with open-ended textual reasoning and control.

【5】David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?
- **标题**: 以弱胜强：小模型能否在硬件设计中利用智能人工智能赢得大胜利？
- **链接**: https://arxiv.org/abs/2512.05073
> **作者**: Shashwat Shankar,Subhranshu Pandey,Innocent Dengkhw Mochahari,Bhabesh Mali,Animesh Basak Chowdhury,Sukanta Bhattacharjee,Chandan Karfa
> **摘要**: 大型语言模型 (LLM) 推理需要大量计算和能源，使得特定领域的任务变得昂贵且不可持续。随着基础模型不断扩展，我们会问：硬件设计越大越好吗？我们的工作通过在 NVIDIA 综合 Verilog 设计问题 (CVDP) 基准上评估小语言模型以及精心策划的代理 AI 框架来测试这一点。结果表明，代理工作流程：通过任务分解、迭代反馈和修正，不仅以一小部分成本解锁近乎 LLM 的性能，而且还为代理创造了学习机会，为复杂设计任务中的高效、自适应解决方案铺平了道路。
> **Abstract**: Large Language Model(LLM) inference demands massive compute and energy, making domain-specific tasks expensive and unsustainable. As foundation models keep scaling, we ask: Is bigger always better for hardware design? Our work tests this by evaluating Small Language Models coupled with a curated agentic AI framework on NVIDIA's Comprehensive Verilog Design Problems(CVDP) benchmark. Results show that agentic workflows: through task decomposition, iterative feedback, and correction - not only unlock near-LLM performance at a fraction of the cost but also create learning opportunities for agents, paving the way for efficient, adaptive solutions in complex design tasks.

【6】Multi-LLM Collaboration for Medication Recommendation
- **标题**: 多法学硕士合作进行药物推荐
- **链接**: https://arxiv.org/abs/2512.05066
> **作者**: Huascar Sanchez,Briland Hitaj,Jules Bergmann,Linda Briesemeister
> **摘要**: 随着医疗保健越来越多地转向人工智能来提供可扩展且值得信赖的临床决策支持，确保模型推理的可靠性仍然是一个关键挑战。单个大语言模型（LLM）很容易产生幻觉和不一致，而朴素的模型集合通常无法提供稳定和可信的建议。基于我们之前在法学硕士化学方面的工作，该工作量化了法学硕士之间的协作兼容性，我们应用此框架来提高简短临床片段中药物推荐的可靠性。我们的方法利用受化学启发的交互模型指导的多法学硕士协作，使集成有效（利用互补优势）、稳定（产生一致的质量）和校准（最大限度地减少干扰和误差放大）。我们在现实临床场景中评估了基于化学的多法学硕士合作策略，以研究这种具有交互意识的整体是否可以生成可靠的、针对患者的药物建议。初步结果令人鼓舞，表明法学硕士化学指导的合作可能为临床实践中可靠且值得信赖的人工智能助手提供一条有希望的道路。
> **Abstract**: As healthcare increasingly turns to AI for scalable and trustworthy clinical decision support, ensuring reliability in model reasoning remains a critical challenge. Individual large language models (LLMs) are susceptible to hallucinations and inconsistency, whereas naive ensembles of models often fail to deliver stable and credible recommendations. Building on our previous work on LLM Chemistry, which quantifies the collaborative compatibility among LLMs, we apply this framework to improve the reliability in medication recommendation from brief clinical vignettes. Our approach leverages multi-LLM collaboration guided by Chemistry-inspired interaction modeling, enabling ensembles that are effective (exploiting complementary strengths), stable (producing consistent quality), and calibrated (minimizing interference and error amplification). We evaluate our Chemistry-based Multi-LLM collaboration strategy on real-world clinical scenarios to investigate whether such interaction-aware ensembles can generate credible, patient-specific medication recommendations. Preliminary results are encouraging, suggesting that LLM Chemistry-guided collaboration may offer a promising path toward reliable and trustworthy AI assistants in clinical practice.

【7】Realizable Abstractions: Near-Optimal Hierarchical Reinforcement Learning
- **标题**: 可实现的抽象：近乎最优的分层强化学习
- **链接**: https://arxiv.org/abs/2512.04958
> **作者**: Roberto Cipollone,Luca Iocchi,Matteo Leonetti
> **摘要**: 分层强化学习 (HRL) 的主要重点是研究通过组合为较小的子任务计算的部分解决方案，以模块化方式解决时如何更有效地解决大型马尔可夫决策过程 (MDP)。尽管它们对于学习具有非常直观的作用，但 HRL 文献中提出的大多数 MDP 抽象概念的表达能力有限，或者不具备正式的效率保证。这项工作通过定义可实现的抽象（通用低级 MDP 与其相关的高级决策过程之间的新关系）来解决这些基本问题。我们提出的概念避免了非马尔可夫问题，并具有理想的近最优保证。事实上，我们表明，通过适当的选项组合，可实现抽象的任何抽象策略都可以转化为低级 MDP 的近乎最优策略。正如本文所演示的，这些选项可以表示为特定约束 MDP 的解决方案。基于这些发现，我们提出了 RARL，这是一种新的 HRL 算法，它利用输入中给出的可实现抽象，返回组合且接近最优的低级策略。我们证明 RARL 可能是近似正确的，它收敛于多项式数量的样本，并且对于抽象中的不准确性具有鲁棒性。
> **Abstract**: The main focus of Hierarchical Reinforcement Learning (HRL) is studying how large Markov Decision Processes (MDPs) can be more efficiently solved when addressed in a modular way, by combining partial solutions computed for smaller subtasks. Despite their very intuitive role for learning, most notions of MDP abstractions proposed in the HRL literature have limited expressive power or do not possess formal efficiency guarantees. This work addresses these fundamental issues by defining Realizable Abstractions, a new relation between generic low-level MDPs and their associated high-level decision processes. The notion we propose avoids non-Markovianity issues and has desirable near-optimality guarantees. Indeed, we show that any abstract policy for Realizable Abstractions can be translated into near-optimal policies for the low-level MDP, through a suitable composition of options. As demonstrated in the paper, these options can be expressed as solutions of specific constrained MDPs. Based on these findings, we propose RARL, a new HRL algorithm that returns compositional and near-optimal low-level policies, taking advantage of the Realizable Abstraction given in the input. We show that RARL is Probably Approximately Correct, it converges in a polynomial number of samples, and it is robust to inaccuracies in the abstraction.

【8】CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent
- **标题**: CARL：针对多步代理的关键行动强化学习
- **链接**: https://arxiv.org/abs/2512.04949
> **作者**: Leyang Shen,Yang Zhang,Chun Kai Ling,Xiaoyan Zhao,Tat-Seng Chua
> **摘要**: 能够通过与环境的多种交互来完成复杂任务的智能体已成为一个流行的研究方向。然而，在这种多步骤设置中，传统的组级策略优化算法变得次优，因为其基本假设是每个动作具有相同的贡献，这与现实有很大偏差。我们的分析表明，只有一小部分行动对于确定最终结果至关重要。基于这一见解，我们提出了 CARL，一种专为多步骤智能体量身定制的以关键动作为中心的强化学习算法。 CARL通过为高关键性动作提供动作级优化信号，同时从模型更新中排除低关键性动作，实现集中训练。大量实验表明，CARL 在跨不同评估设置的训练和推理过程中实现了更强的性能和更高的效率。
> **Abstract**: Agents capable of accomplishing complex tasks through multiple interactions with the environment have emerged as a popular research direction. However, in such multi-step settings, the conventional group-level policy optimization algorithm becomes suboptimal because of its underlying assumption that each action holds equal contribution, which deviates significantly from reality. Our analysis reveals that only a small fraction of actions are critical in determining the final outcome. Building on this insight, we propose CARL, a critical-action-focused reinforcement learning algorithm tailored for multi-step agents. CARL achieves focused training through providing action-level optimization signals for high-criticality actions while excluding low-criticality actions from model update. Extensive experiments demonstrate that CARL achieves both stronger performance and higher efficiency during training and inference across diverse evaluation settings.

【9】MemLoRA: Distilling Expert Adapters for On-Device Memory Systems
- **标题**: MemLoRA：为设备内存系统提炼专家适配器
- **链接**: https://arxiv.org/abs/2512.04763
> **作者**: Massimo Bini,Ondrej Bohdal,Umberto Michieli,Zeynep Akata,Mete Ozay,Taha Ceritli
> **摘要**: 记忆增强大语言模型（LLM）通过存储相关记忆并将其合并为上下文，在长时间对话中表现出了显着的一致性。这种基于内存的个性化也是设备上设置的关键，它允许用户保持对话和数据的私密性。然而，内存增强系统通常依赖于本地设备部署成本太高的 LLM。尽管小语言模型 (SLM) 比 LLM 更适合设备端推理，但它们无法实现足够的性能。此外，这些基于法学硕士的系统缺乏原生视觉功能，限制了它们在多模式环境中的适用性。在本文中，我们介绍了（i）MemLoRA，一种新颖的内存系统，通过为 SLM 配备专用内存适配器来实现本地部署，以及（ii）其视觉扩展 MemLoRA-V，它将小型视觉语言模型（SVLM）集成到内存系统中，从而实现本地视觉理解。遵循知识蒸馏原则，每个适配器针对特定的内存操作$\unicode{x2013}$知识提取、内存更新和内存增强生成分别进行训练。小型型号配备内存适配器，可实现准确的设备内存操作，而无需依赖云。在纯文本操作中，MemLoRA 的性能优于 10 美元\倍$大的基准模型（例如 Gemma2-27B），并在 LoCoMo 基准上实现了与 60 美元\倍$大的模型（例如 GPT-OSS-120B）相当的性能。为了评估视觉理解操作，我们通过需要直接视觉推理的具有挑战性的视觉问答任务来扩展 LoCoMo。在这一点上，我们的 VLM 集成 MemLoRA-V 比基于字幕的方法显示出巨大的改进（81.3 比 23.7 准确率），同时在基于文本的任务中保持强劲的性能，证明了我们的方法在多模式环境中的有效性。
> **Abstract**: Memory-augmented Large Language Models (LLMs) have demonstrated remarkable consistency during prolonged dialogues by storing relevant memories and incorporating them as context. Such memory-based personalization is also key in on-device settings that allow users to keep their conversations and data private. However, memory-augmented systems typically rely on LLMs that are too costly for local on-device deployment. Even though Small Language Models (SLMs) are more suitable for on-device inference than LLMs, they cannot achieve sufficient performance. Additionally, these LLM-based systems lack native visual capabilities, limiting their applicability in multimodal contexts. In this paper, we introduce (i) MemLoRA, a novel memory system that enables local deployment by equipping SLMs with specialized memory adapters, and (ii) its vision extension MemLoRA-V, which integrates small Vision-Language Models (SVLMs) to memory systems, enabling native visual understanding. Following knowledge distillation principles, each adapter is trained separately for specific memory operations$\unicode{x2013}$knowledge extraction, memory update, and memory-augmented generation. Equipped with memory adapters, small models enable accurate on-device memory operations without cloud dependency. On text-only operations, MemLoRA outperforms 10$\times$ larger baseline models (e.g., Gemma2-27B) and achieves performance comparable to 60$\times$ larger models (e.g., GPT-OSS-120B) on the LoCoMo benchmark. To evaluate visual understanding operations instead, we extend LoCoMo with challenging Visual Question Answering tasks that require direct visual reasoning. On this, our VLM-integrated MemLoRA-V shows massive improvements over caption-based approaches (81.3 vs. 23.7 accuracy) while keeping strong performance in text-based tasks, demonstrating the efficacy of our method in multimodal contexts.

【10】TimesNet-Gen: Deep Learning-based Site Specific Strong Motion Generation
- **标题**: TimesNet-Gen：基于深度学习的特定地点强运动生成
- **链接**: https://arxiv.org/abs/2512.04694
> **作者**: Baris Yilmaz,Bevan Deniz Cilgin,Erdem Akagündüz,Salih Tileylioglu
> **摘要**: 有效降低地震风险依赖于准确的特定地点评估。这需要能够代表当地场地条件对地震动特征影响的模型。在这种情况下，从记录的地面运动中学习站点控制特征的数据驱动方法提供了一个有希望的方向。我们解决了从时域加速度计记录生成强地面运动的问题，并介绍了 TimesNet-Gen，一种时域条件生成器。该方法使用特定于站的潜在瓶颈。我们通过比较 HVSR 曲线和每个站点的真实记录和生成记录之间的基本站点频率 $f_0$ 分布来评估生成，并根据 $f_0$ 分布混淆矩阵总结站点特异性。 TimesNet-Gen 实现了强大的逐站对齐，并且与用于特定位置强运动合成的基于频谱图的条件 VAE 基线相比具有优势。我们的代码可通过 https://github.com/brsylmz23/TimesNet-Gen 获取。
> **Abstract**: Effective earthquake risk reduction relies on accurate site-specific evaluations. This requires models that can represent the influence of local site conditions on ground motion characteristics. In this context, data driven approaches that learn site controlled signatures from recorded ground motions offer a promising direction. We address strong ground motion generation from time-domain accelerometer records and introduce the TimesNet-Gen, a time-domain conditional generator. The approach uses a station specific latent bottleneck. We evaluate generation by comparing HVSR curves and fundamental site-frequency $f_0$ distributions between real and generated records per station, and summarize station specificity with a score based on the $f_0$ distribution confusion matrices. TimesNet-Gen achieves strong station-wise alignment and compares favorably with a spectrogram-based conditional VAE baseline for site-specific strong motion synthesis. Our codes are available via https://github.com/brsylmz23/TimesNet-Gen.

【11】Rethinking Decoupled Knowledge Distillation: A Predictive Distribution Perspective
- **标题**: 重新思考解耦知识蒸馏：预测分布视角
- **链接**: https://arxiv.org/abs/2512.04625
> **作者**: Bowen Zheng,Ran Cheng
> **摘要**: 在知识蒸馏的历史上，随着时间的推移，焦点曾经从基于逻辑的方法转移到基于特征的方法。然而，随着解耦知识蒸馏（DKD）的出现，这种转变被重新审视，它通过先进的解耦和加权策略重新强调了 Logit 知识的重要性。虽然 DKD 标志着一项重大进步，但其潜在机制值得更深入的探索。作为回应，我们从预测分布的角度重新思考 DKD。首先，我们引入一个增强版本，广义解耦知识蒸馏（GDKD）损失，它提供了一种更通用的解耦 logits 方法。然后，我们特别关注教师模型的预测分布及其对 GDKD 损失梯度的影响，揭示了两个经常被忽视的关键见解：（1）顶级 Logit 的划分显着改善了非顶级 Logit 的相互关系，（2）增强了对非顶级 Logit 蒸馏损失的关注，增强了它们之间的知识提取。利用这些见解，我们进一步提出了一种简化的 GDKD 算法，该算法具有有效的分区策略来处理教师模型预测分布的多模态。我们在各种基准（包括 CIFAR-100、ImageNet、Tiny-ImageNet、CUB-200-2011 和 Cityscapes）上进行的全面实验证明了 GDKD 比原始 DKD 和其他领先的知识蒸馏方法具有优越的性能。代码可在 https://github.com/ZaberKo/GDKD 获取。
> **Abstract**: In the history of knowledge distillation, the focus has once shifted over time from logit-based to feature-based approaches. However, this transition has been revisited with the advent of Decoupled Knowledge Distillation (DKD), which re-emphasizes the importance of logit knowledge through advanced decoupling and weighting strategies. While DKD marks a significant advancement, its underlying mechanisms merit deeper exploration. As a response, we rethink DKD from a predictive distribution perspective. First, we introduce an enhanced version, the Generalized Decoupled Knowledge Distillation (GDKD) loss, which offers a more versatile method for decoupling logits. Then we pay particular attention to the teacher model's predictive distribution and its impact on the gradients of GDKD loss, uncovering two critical insights often overlooked: (1) the partitioning by the top logit considerably improves the interrelationship of non-top logits, and (2) amplifying the focus on the distillation loss of non-top logits enhances the knowledge extraction among them. Utilizing these insights, we further propose a streamlined GDKD algorithm with an efficient partition strategy to handle the multimodality of teacher models' predictive distribution. Our comprehensive experiments conducted on a variety of benchmarks, including CIFAR-100, ImageNet, Tiny-ImageNet, CUB-200-2011, and Cityscapes, demonstrate GDKD's superior performance over both the original DKD and other leading knowledge distillation methods. The code is available at https://github.com/ZaberKo/GDKD.

【12】Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function
- **标题**: 通过软 Q 函数的重新参数化策略梯度进行扩散微调
- **链接**: https://arxiv.org/abs/2512.04559
> **作者**: Hyeongyu Kang,Jaewoo Lee,Woocheol Shin,Kiyoung Om,Jinkyoo Park
> **摘要**: 扩散模型擅长生成高似然样本，但通常需要与下游目标保持一致。现有的扩散模型微调方法严重受到奖励过度优化的影响，导致高奖励但不自然的样本和多样性下降。为了减轻过度优化，我们提出了 \textbf{基于软 Q 的扩散微调（SQDF）}，这是一种用于扩散对齐的新型 KL 正则化 RL 方法，该方法应用软 Q 函数的免训练、可微估计的重新参数化策略梯度。 SQDF 通过三项创新得到进一步增强：去噪过程中适当信用分配的折扣因子、集成一致性模型以细化 Q 函数估计，以及使用非策略重播缓冲区来提高模式覆盖率并管理奖励多样性权衡。我们的实验表明，SQDF 实现了卓越的目标奖励，同时保留了文本到图像对齐的多样性。此外，在在线黑盒优化中，SQDF在保持自然性和多样性的同时获得了高样本效率。
> **Abstract**: Diffusion models excel at generating high-likelihood samples but often require alignment with downstream objectives. Existing fine-tuning methods for diffusion models significantly suffer from reward over-optimization, resulting in high-reward but unnatural samples and degraded diversity. To mitigate over-optimization, we propose \textbf{Soft Q-based Diffusion Finetuning (SQDF)}, a novel KL-regularized RL method for diffusion alignment that applies a reparameterized policy gradient of a training-free, differentiable estimation of the soft Q-function. SQDF is further enhanced with three innovations: a discount factor for proper credit assignment in the denoising process, the integration of consistency models to refine Q-function estimates, and the use of an off-policy replay buffer to improve mode coverage and manage the reward-diversity trade-off. Our experiments demonstrate that SQDF achieves superior target rewards while preserving diversity in text-to-image alignment. Furthermore, in online black-box optimization, SQDF attains high sample efficiency while maintaining naturalness and diversity.

【13】Prototype-Based Semantic Consistency Alignment for Domain Adaptive Retrieval
- **标题**: 用于域自适应检索的基于原型的语义一致性对齐
- **链接**: https://arxiv.org/abs/2512.04524
> **作者**: Tianle Hu,Weijun Lv,Na Han,Xiaozhao Fang,Jie Wen,Jiaxing Li,Guoxu Zhou
> **摘要**: 域自适应检索旨在将知识从标记的源域转移到未标记的目标域，从而实现有效的检索，同时减少域差异。然而，现有方法遇到几个基本限制：1）忽略类级语义对齐并过度追求成对样本对齐； 2）缺乏伪标签可靠性考虑或评估标签正确性的几何指导； 3）直接量化受域移位影响的原始特征，破坏了学习到的哈希码的质量。鉴于这些限制，我们提出了基于原型的语义一致性对齐（PSCA），这是一种用于有效域自适应检索的两阶段框架。在第一阶段，一组正交原型直接建立类级语义连接，在收集类内样本的同时最大化类间可分离性。在原型学习过程中，几何邻近度通过伪标签置信度的自适应加权为语义一致性对齐提供了可靠性指标。由此产生的隶属矩阵和原型有利于特征重建，确保对重建特征而不是原始特征进行量化，从而提高后续哈希编码质量并无缝连接两个阶段。在第二阶段，特定领域的量化函数在相互逼近约束下处理重构的特征，生成跨领域的统一的二进制哈希码。大量实验验证了 PSCA 在多个数据集上的卓越性能。
> **Abstract**: Domain adaptive retrieval aims to transfer knowledge from a labeled source domain to an unlabeled target domain, enabling effective retrieval while mitigating domain discrepancies. However, existing methods encounter several fundamental limitations: 1) neglecting class-level semantic alignment and excessively pursuing pair-wise sample alignment; 2) lacking either pseudo-label reliability consideration or geometric guidance for assessing label correctness; 3) directly quantizing original features affected by domain shift, undermining the quality of learned hash codes. In view of these limitations, we propose Prototype-Based Semantic Consistency Alignment (PSCA), a two-stage framework for effective domain adaptive retrieval. In the first stage, a set of orthogonal prototypes directly establishes class-level semantic connections, maximizing inter-class separability while gathering intra-class samples. During the prototype learning, geometric proximity provides a reliability indicator for semantic consistency alignment through adaptive weighting of pseudo-label confidences. The resulting membership matrix and prototypes facilitate feature reconstruction, ensuring quantization on reconstructed rather than original features, thereby improving subsequent hash coding quality and seamlessly connecting both stages. In the second stage, domain-specific quantization functions process the reconstructed features under mutual approximation constraints, generating unified binary hash codes across domains. Extensive experiments validate PSCA's superior performance across multiple datasets.

【14】GraphBench: Next-generation graph learning benchmarking
- **标题**: GraphBench：下一代图学习基准测试
- **链接**: https://arxiv.org/abs/2512.04475
> **作者**: Timo Stoll,Chendi Qian,Ben Finkelshtein,Ali Parviz,Darius Weber,Fabrizio Frasca,Hadar Shavit,Antoine Siraudin,Arman Mielke,Marie Anastacio,Erik Müller,Maya Bechler-Speicher,Michael Bronstein,Mikhail Galkin,Holger Hoos,Mathias Niepert,Bryan Perozzi,Jan Tönshoff,Christopher Morris
> **摘要**: 图机器学习最近在分子特性预测和芯片设计等各个领域取得了令人瞩目的进展。然而，基准测试实践仍然支离破碎，通常依赖于狭窄的、特定于任务的数据集和不一致的评估协议，这阻碍了可重复性和更广泛的进展。为了解决这个问题，我们引入了 GraphBench，这是一个全面的基准测试套件，涵盖不同的领域和预测任务，包括节点级、边缘级、图形级和生成设置。 GraphBench 提供标准化的评估协议——具有一致的数据集分割和解释分布外泛化的性能指标——以及统一的超参数调整框架。此外，我们使用消息传递神经网络和图转换器模型对 GraphBench 进行基准测试，提供原则性基线并建立参考性能。有关更多详细信息，请参阅 www.graphbench.io。
> **Abstract**: Machine learning on graphs has recently achieved impressive progress in various domains, including molecular property prediction and chip design. However, benchmarking practices remain fragmented, often relying on narrow, task-specific datasets and inconsistent evaluation protocols, which hampers reproducibility and broader progress. To address this, we introduce GraphBench, a comprehensive benchmarking suite that spans diverse domains and prediction tasks, including node-level, edge-level, graph-level, and generative settings. GraphBench provides standardized evaluation protocols -- with consistent dataset splits and performance metrics that account for out-of-distribution generalization -- as well as a unified hyperparameter tuning framework. Additionally, we benchmark GraphBench using message-passing neural networks and graph transformer models, providing principled baselines and establishing a reference performance. See www.graphbench.io for further details.

【15】Feature Engineering vs. Deep Learning for Automated Coin Grading: A Comparative Study on Saint-Gaudens Double Eagles
- **标题**: 硬币自动分级的特征工程与深度学习：Saint-Gaudens 双鹰的比较研究
- **链接**: https://arxiv.org/abs/2512.04464
> **作者**: Tanmay Dogra,Eric Ngo,Mohammad Alam,Jean-Paul Talavera,Asim Dahal
> **摘要**: 我们以圣高登斯双鹰金币自动评级为例，挑战深度学习总是胜过旧技术的普遍看法。在我们的工作中，我们将一个基于特征的人工神经网络（围绕从 Sobel 边缘检测和 HSV 颜色分析中提取的 192 个自定义特征构建）与混合在 EfficientNetV2 中的混合卷积神经网络以及一个简单的支持向量机作为控制。 ANN 对专家评级的 1,785 枚硬币进行了测试，准确率达到 86%，在允许 3 级余地的情况下，准确率达到 98%。另一方面，CNN 和 SVM 大多只是猜测最常见的等级，准确命中率分别为 31% 和 30%。当然，CNN 在更广泛的容忍度指标上看起来不错，但这是因为回归中的一些平均技巧掩盖了它在选择特定等级时完全失败的情况。总而言之，当你被不到 2,000 个示例和不平衡的类困住时，通过功能设计融入真正的硬币专家知识会击败那些难以理解的一体化深度学习设置。这对于其他利基质量检查来说是正确的，在这些质量检查中，数据薄弱和专业知识比原始计算更重要。
> **Abstract**: We challenge the common belief that deep learning always trumps older techniques, using the example of grading Saint-Gaudens Double Eagle gold coins automatically. In our work, we put a feature-based Artificial Neural Network built around 192 custom features pulled from Sobel edge detection and HSV color analysis up against a hybrid Convolutional Neural Network that blends in EfficientNetV2, plus a straightforward Support Vector Machine as the control. Testing 1,785 coins graded by experts, the ANN nailed 86% exact matches and hit 98% when allowing a 3-grade leeway. On the flip side, CNN and SVM mostly just guessed the most common grade, scraping by with 31% and 30% exact hits. Sure, the CNN looked good on broader tolerance metrics, but that is because of some averaging trick in regression that hides how it totally flops at picking out specific grades. All told, when you are stuck with under 2,000 examples and lopsided classes, baking in real coin-expert knowledge through feature design beats out those inscrutable, all-in-one deep learning setups. This rings true for other niche quality checks where data's thin and know-how matters more than raw compute.

## 多代理系统(cs.MA:Multiagent Systems)

【1】Strategic Self-Improvement for Competitive Agents in AI Labour Markets
- **标题**: 人工智能劳动力市场竞争主体的战略自我提升
- **链接**: https://arxiv.org/abs/2512.04988
> **作者**: Christopher Chiu,Simpson Zhang,Mihaela van der Schaar
> **摘要**: 随着人工智能 (AI) 代理在各个经济领域的部署，了解其战略行为和市场影响变得至关重要。本文提出了一个开创性的新框架，该框架首次捕捉了塑造代理劳动力市场的现实世界经济力量：逆向选择、道德风险和声誉动态。我们的框架封装了成功的法学硕士代理人所需的三个核心能力：\textbf{元认知}（准确的技能自我评估）、\textbf{竞争意识}（对竞争对手和市场动态进行建模）和\textbf{长期战略规划}。我们通过易于处理的模拟零工经济来说明我们的框架，其中代理大型语言模型（LLM）竞争工作、发展技能并在竞争压力下调整策略。我们的模拟说明了 LLM 代理人如何在推理能力的明确提示下学会战略性地自我改进，并展示出对不断变化的市场条件的卓越适应能力。在市场层面，我们的模拟再现了人类劳动力市场中发现的经典宏观经济现象，而受控实验揭示了潜在的人工智能驱动的经济趋势，例如快速垄断和系统性价格通货紧缩。这项工作为进一步探索人工智能驱动的劳动力市场的经济属性奠定了基础，并为研究新兴经济体中竞争主体的战略推理能力提供了概念框架。
> **Abstract**: As artificial intelligence (AI) agents are deployed across economic domains, understanding their strategic behavior and market-level impact becomes critical. This paper puts forward a groundbreaking new framework that is the first to capture the real-world economic forces that shape agentic labor markets: adverse selection, moral hazard, and reputation dynamics. Our framework encapsulates three core capabilities that successful LLM-agents will need: \textbf{metacognition} (accurate self-assessment of skills), \textbf{competitive awareness} (modeling rivals and market dynamics), and \textbf{long-horizon strategic planning}. We illustrate our framework through a tractable simulated gig economy where agentic Large Language Models (LLMs) compete for jobs, develop skills, and adapt their strategies under competitive pressure. Our simulations illustrate how LLM agents explicitly prompted with reasoning capabilities learn to strategically self-improve and demonstrate superior adaptability to changing market conditions. At the market level, our simulations reproduce classic macroeconomic phenomena found in human labor markets, while controlled experiments reveal potential AI-driven economic trends, such as rapid monopolization and systemic price deflation. This work provides a foundation to further explore the economic properties of AI-driven labour markets, and a conceptual framework to study the strategic reasoning capabilities in agents competing in the emerging economy.

【2】Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control
- **标题**: 交通信号控制中多智能体深度强化学习的半集中训练分散执行架构
- **链接**: https://arxiv.org/abs/2512.04653
> **作者**: Pouria Yazdani,Arash Rezaali,Monireh Abdoos
> **摘要**: 多智能体强化学习（MARL）已成为多个交叉口自适应交通信号控制（ATSC）的有前途的范例。现有方法通常遵循完全集中式或完全分散式设计。完全集中的方法受到维数诅咒和对单个学习服务器的依赖，而纯粹分散的方法在严重的部分可观察性下运行，并且缺乏明确的协调，导致性能不佳。这些限制激发了基于区域的 MARL，其中网络被划分为更小的、紧密耦合的交叉点，形成区域，并围绕这些区域组织训练。本文介绍了一种用于多交叉点 ATSC 的半集中训练、分散执行 (SEMI-CTDE) 架构。在每个区域内，SEMI-CTDE 通过区域参数共享进行集中训练，并采用联合编码本地和区域信息的复合状态和奖励公式。该架构在不同的政策主干和国家奖励实例之间具有高度的可移植性。在此架构的基础上，我们实现了两种具有不同设计目标的模型。对两个实施的基于 SEMI-CTDE 的模型进行的多视角实验分析涵盖了架构核心元素的消融，包括基于规则和完全去中心化的基线，表明它们实现了始终如一的卓越性能，并在各种流量密度和分布范围内保持有效。
> **Abstract**: Multi-agent reinforcement learning (MARL) has emerged as a promising paradigm for adaptive traffic signal control (ATSC) of multiple intersections. Existing approaches typically follow either a fully centralized or a fully decentralized design. Fully centralized approaches suffer from the curse of dimensionality, and reliance on a single learning server, whereas purely decentralized approaches operate under severe partial observability and lack explicit coordination resulting in suboptimal performance. These limitations motivate region-based MARL, where the network is partitioned into smaller, tightly coupled intersections that form regions, and training is organized around these regions. This paper introduces a Semi-Centralized Training, Decentralized Execution (SEMI-CTDE) architecture for multi intersection ATSC. Within each region, SEMI-CTDE performs centralized training with regional parameter sharing and employs composite state and reward formulations that jointly encode local and regional information. The architecture is highly transferable across different policy backbones and state-reward instantiations. Building on this architecture, we implement two models with distinct design objectives. A multi-perspective experimental analysis of the two implemented SEMI-CTDE-based models covering ablations of the architecture's core elements including rule based and fully decentralized baselines shows that they achieve consistently superior performance and remain effective across a wide range of traffic densities and distributions.

## 神经和进化计算(cs.NE:Neural and Evolutionary Computing)

【1】Plug-and-Play Homeostatic Spark: Zero-Cost Acceleration for SNN Training Across Paradigms
- **标题**: 即插即用稳态 Spark：跨范式 SNN 训练的零成本加速
- **链接**: https://arxiv.org/abs/2512.05015
> **作者**: Rui Chen,Xingyu Chen,Yaoqing Hu,Shihan Kong,Zhiheng Wu,Junzhi Yu
> **摘要**: 尖峰神经网络提供事件驱动的计算、稀疏激活和硬件效率，但训练通常收敛缓慢且缺乏稳定性。我们提出了自适应稳态尖峰活动调节（AHSAR），这是一种极其简单的插件和训练范式无关的方法，可以在不改变模型架构、损失或梯度的情况下稳定优化并加速收敛。 AHSAR 不引入可训练参数。它在前向传递过程中保持每层稳态，通过有界非线性将中心发射率偏差映射到阈值尺度，使用轻量级跨层扩散来避免急剧不平衡，并应用缓慢的跨历元全局增益，将验证进度与活动能量相结合来调整操作点。计算成本可以忽略不计。通过不同的训练方法、不同深度、宽度和时间步长的 SNN 架构以及 RGB 和 DVS 数据集，AHSAR 持续改进强大的基线并增强分布外的鲁棒性。这些结果表明，将层活动保持在适度范围内是可扩展且高效的 SNN 训练的简单而有效的原则。
> **Abstract**: Spiking neural networks offer event driven computation, sparse activation, and hardware efficiency, yet training often converges slowly and lacks stability. We present Adaptive Homeostatic Spiking Activity Regulation (AHSAR), an extremely simple plug in and training paradigm agnostic method that stabilizes optimization and accelerates convergence without changing the model architecture, loss, or gradients. AHSAR introduces no trainable parameters. It maintains a per layer homeostatic state during the forward pass, maps centered firing rate deviations to threshold scales through a bounded nonlinearity, uses lightweight cross layer diffusion to avoid sharp imbalance, and applies a slow across epoch global gain that combines validation progress with activity energy to tune the operating point. The computational cost is negligible. Across diverse training methods, SNN architectures of different depths, widths, and temporal steps, and both RGB and DVS datasets, AHSAR consistently improves strong baselines and enhances out of distribution robustness. These results indicate that keeping layer activity within a moderate band is a simple and effective principle for scalable and efficient SNN training.

【2】Evolutionary Architecture Search through Grammar-Based Sequence Alignment
- **标题**: 通过基于语法的序列比对进行进化架构搜索
- **链接**: https://arxiv.org/abs/2512.04992
> **作者**: Adri Gómez Martín,Felix Möller,Steven McDonagh,Monica Abella,Manuel Desco,Elliot J. Crowley,Aaron Klein,Linus Ericsson
> **摘要**: 表达搜索空间中的神经架构搜索（NAS）是一个计算难题，但它也具有自动发现全新且高性能架构的潜力。为了实现这一目标，我们需要有效的搜索算法来识别强大的组件并在新的候选架构中重用它们。在本文中，我们介绍了用于局部序列比对的史密斯-沃特曼算法的两种改编变体，并使用它们来计算基于语法的进化架构搜索中的编辑距离。这些算法使我们能够有效地计算神经架构的距离度量，并从两个父模型生成一组混合后代。这有助于部署基于交叉的搜索启发式方法，使我们能够对架构损失情况进行彻底分析，并在搜索过程中跟踪群体多样性。我们强调我们的方法如何比以前的工作大大提高了计算复杂性，并使我们能够有效地计算架构之间的最短路径。当在进化搜索中实例化交叉时，我们获得了有竞争力的结果，优于竞争方法。未来的工作可以建立在这个新工具的基础上，发现可以在神经架构设计中更广泛使用的新颖组件，并将其应用扩展到 NAS 之外。
> **Abstract**: Neural architecture search (NAS) in expressive search spaces is a computationally hard problem, but it also holds the potential to automatically discover completely novel and performant architectures. To achieve this we need effective search algorithms that can identify powerful components and reuse them in new candidate architectures. In this paper, we introduce two adapted variants of the Smith-Waterman algorithm for local sequence alignment and use them to compute the edit distance in a grammar-based evolutionary architecture search. These algorithms enable us to efficiently calculate a distance metric for neural architectures and to generate a set of hybrid offspring from two parent models. This facilitates the deployment of crossover-based search heuristics, allows us to perform a thorough analysis on the architectural loss landscape, and track population diversity during search. We highlight how our method vastly improves computational complexity over previous work and enables us to efficiently compute shortest paths between architectures. When instantiating the crossover in evolutionary searches, we achieve competitive results, outperforming competing methods. Future work can build upon this new tool, discovering novel components that can be used more broadly across neural architecture design, and broadening its applications beyond NAS.

## 编程语言(cs.PL:Programming Languages)

【1】Optimizations and extensions for fair join pattern matching
- **标题**: 公平连接模式匹配的优化和扩展
- **链接**: https://arxiv.org/abs/2512.04876
> **作者**: Ioannis Karras
> **摘要**: 连接模式是一种尚未充分开发的并发和分布式系统编程方法。当应用于参与者模型时，连接模式提供了匹配参与者邮箱中的消息组合的新颖功能。 Philipp Haller 等人之前的工作。在论文“Fair Join Pattern Matching for Actors”（ECOOP 2024）中，探索了基于 Actor 的环境中具有条件保护的连接模式，并具有公平和确定性匹配语义的规范。然而，公平连接模式匹配中的时间效率问题仍未得到充分研究。 Haller 等人的基于状态树的匹配算法。其性能比使 Rete 算法适应连接模式匹配基准的常规版本的实现更差，而在具有大量条件保护的变体上表现更好，而该变体需要更长的时间来评估。然而，使 Rete 符合连接模式匹配问题需要大量的手动调整。在本文中，我们增强和优化了 Haller 等人的基于状态树的匹配算法。在某些基准测试中实现高达十倍的性能提升，在常规基准测试中接近 Rete 的性能，同时保持重型防护的多功能性和性能优势。我们还增强了基准测试套件，添加了新功能并增强了其可扩展性和用户友好性。我们使用更明确的语法以及动态模式切换来扩展连接模式实现。最后，我们提出了一个新的连接模式复杂模型用例，展示了它们在微服务 Web 架构中的适用性。
> **Abstract**: Join patterns are an underexplored approach for the programming of concurrent and distributed systems. When applied to the actor model, join patterns offer the novel capability of matching combinations of messages in the mailbox of an actor. Previous work by Philipp Haller et al. in the paper "Fair Join Pattern Matching for Actors" (ECOOP 2024) explored join patterns with conditional guards in an actor-based setting with a specification of fair and deterministic matching semantics. Nevertheless, the question of time efficiency in fair join pattern matching has remained underexplored. The stateful tree-based matching algorithm of Haller et al. performs worse than an implementation that adapts the Rete algorithm to the regular version of a join pattern matching benchmark, while outperforming on a variant with heavy conditional guards, which take longer to evaluate. Nevertheless, conforming Rete to the problem of join pattern matching requires heavy manual adaptation. In this thesis, we enhance and optimize the stateful tree-based matching algorithm of Haller et al. to achieve up to tenfold performance improvements on certain benchmarks, approaching the performance of Rete on regular benchmarks while maintaining the advantages of versatility and performance with heavy guards. We also enhance the benchmark suite, adding new features and enhancing its extensibility and user-friendliness. We extend the join pattern implementation with a less ambiguous syntax as well as dynamic pattern switching. Finally, we present a new complex model use case for join patterns, showing their applicability in a microservice web architecture.

## 机器人技术(cs.RO:Robotics)

【1】STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models
- **标题**: STARE-VLA：用于微调视觉-语言-动作模型的渐进阶段感知强化
- **链接**: https://arxiv.org/abs/2512.05107
> **作者**: Feng Xu,Guangyao Zhai,Xin Kong,Tingzhong Fu,Daniel F. N. Gordon,Xueli An,Benjamin Busam
> **摘要**: 在大型语言模型和基于强化学习的微调的支持下，视觉-语言-动作（VLA）模型的最新进展在机器人操作方面显示出了显着的进展。现有方法通常将长视野动作视为语言序列，并应用轨迹级优化方法，例如轨迹偏好优化（TPO）或近端策略优化（PPO），导致粗糙的信用分配和不稳定的训练。然而，与语言不同的是，尽管句子顺序灵活，但仍保留了统一的语义，动作轨迹通过具有不同学习难度的因果链阶段进展。这激励了渐进式阶段优化。因此，我们提出了阶段感知强化（STARE），该模块将长视野动作轨迹分解为语义上有意义的阶段，并提供密集、可解释且与阶段一致的强化信号。将 STARE 集成到 TPO 和 PPO 中，我们产生了 Stage-Aware TPO (STA-TPO) 和 Stage-Aware PPO (STA-PPO)，分别用于离线阶段偏好和在线阶段内交互。进一步以监督微调为初始化，我们提出了模仿 -> 偏好 -> 交互（IPI），这是一个用于提高 VLA 模型中动作准确性的串行微调管道。 SimplerEnv 和 ManiSkill3 上的实验显示出巨大的收益，在 SimplerEnv 上实现了 98.0% 的最先进成功率，在 ManiSkill3 任务上实现了 96.4% 的最先进成功率。
> **Abstract**: Recent advances in Vision-Language-Action (VLA) models, powered by large language models and reinforcement learning-based fine-tuning, have shown remarkable progress in robotic manipulation. Existing methods often treat long-horizon actions as linguistic sequences and apply trajectory-level optimization methods such as Trajectory-wise Preference Optimization (TPO) or Proximal Policy Optimization (PPO), leading to coarse credit assignment and unstable training. However, unlike language, where a unified semantic meaning is preserved despite flexible sentence order, action trajectories progress through causally chained stages with different learning difficulties. This motivates progressive stage optimization. Thereby, we present Stage-Aware Reinforcement (STARE), a module that decomposes a long-horizon action trajectory into semantically meaningful stages and provides dense, interpretable, and stage-aligned reinforcement signals. Integrating STARE into TPO and PPO, we yield Stage-Aware TPO (STA-TPO) and Stage-Aware PPO (STA-PPO) for offline stage-wise preference and online intra-stage interaction, respectively. Further building on supervised fine-tuning as initialization, we propose the Imitation -> Preference -> Interaction (IPI), a serial fine-tuning pipeline for improving action accuracy in VLA models. Experiments on SimplerEnv and ManiSkill3 demonstrate substantial gains, achieving state-of-the-art success rates of 98.0 percent on SimplerEnv and 96.4 percent on ManiSkill3 tasks.

【2】From Generated Human Videos to Physically Plausible Robot Trajectories
- **标题**: 从生成的人类视频到物理上合理的机器人轨迹
- **链接**: https://arxiv.org/abs/2512.05094
> **作者**: James Ni,Zekai Wang,Wei Lin,Amir Bar,Yann LeCun,Trevor Darrell,Jitendra Malik,Roei Herzig
> **摘要**: 视频生成模型在新环境中合成人类动作的能力正在迅速提高，有潜力作为情境机器人控制的高级规划器。为了实现这一潜力，一个关键的研究问题仍然悬而未决：类人机器人如何以零镜头的方式从生成的视频中执行人类动作？之所以出现这一挑战，是因为生成的视频通常充满噪音，并且表现出形态扭曲，与真实视频相比，直接模仿变得困难。为了解决这个问题，我们引入了两级管道。首先，我们将视频像素提升为 4D 人类表示，然后重新定位为人形形态。其次，我们提出了 GenMimic——一种以 3D 关键点为条件的物理感知强化学习策略，并通过对称正则化和关键点加权跟踪奖励进行训练。因此，GenMimic 可以通过生成的嘈杂视频来模仿人类行为。我们策划了 GenMimicBench，这是一个使用两个跨一系列动作和上下文的视频生成模型生成的合成人体运动数据集，为评估零样本泛化和策略稳健性建立了基准。大量实验证明了模拟中强基线的改进，并证实了 Unitree G1 人形机器人上连贯、物理稳定的运动跟踪，无需微调。这项工作为实现视频生成模型作为机器人控制高级策略的潜力提供了一条有前途的途径。
> **Abstract**: Video generation models are rapidly improving in their ability to synthesize human actions in novel contexts, holding the potential to serve as high-level planners for contextual robot control. To realize this potential, a key research question remains open: how can a humanoid execute the human actions from generated videos in a zero-shot manner? This challenge arises because generated videos are often noisy and exhibit morphological distortions that make direct imitation difficult compared to real video. To address this, we introduce a two-stage pipeline. First, we lift video pixels into a 4D human representation and then retarget to the humanoid morphology. Second, we propose GenMimic-a physics-aware reinforcement learning policy conditioned on 3D keypoints, and trained with symmetry regularization and keypoint-weighted tracking rewards. As a result, GenMimic can mimic human actions from noisy, generated videos. We curate GenMimicBench, a synthetic human-motion dataset generated using two video generation models across a spectrum of actions and contexts, establishing a benchmark for assessing zero-shot generalization and policy robustness. Extensive experiments demonstrate improvements over strong baselines in simulation and confirm coherent, physically stable motion tracking on a Unitree G1 humanoid robot without fine-tuning. This work offers a promising path to realizing the potential of video generation models as high-level policies for robot control.

【3】Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain
- **标题**: 柔性颗粒地形上蛇形机器人的接触隐式建模与仿真
- **链接**: https://arxiv.org/abs/2512.05008
> **作者**: Haroon Hublikar
> **摘要**: 本论文提出了一个统一的建模和仿真框架，用于分析 COBRA 蛇形机器人在刚性、柔顺和粒状地形上的侧绕和翻滚运动。使用隐式接触公式对侧绕过程中的分布式摩擦相互作用进行建模，并通过 MATLAB Simscape 模拟和刚性地面和松散沙子上的物理实验进行验证。为了捕捉地形变形效应，Project Chrono 的土壤接触模型 (SCM) 与铰接式多体动力学集成，能够预测滑动、下沉和负载重新分布，从而降低可变形基底上的步幅效率。对于陡坡上的高能滚动运动，Chrono DEM 引擎用于模拟粒子解析的颗粒相互作用，揭示刚性模型未捕获的土壤破坏、间歇性升空和能量耗散机制。这些方法共同涵盖了实时控制导向的仿真和高保真颗粒物理。结果表明，刚性地面模型可以提供准确的短视距运动预测，而连续体和基于粒子的地形建模对于在软和高动态环境中进行可靠的移动性分析变得必要。这项工作建立了一个分层模拟管道，可以为在具有挑战性的非结构化环境中运行的机器人提供强大的、地形感知的运动。
> **Abstract**: This thesis presents a unified modeling and simulation framework for analyzing sidewinding and tumbling locomotion of the COBRA snake robot across rigid, compliant, and granular terrains. A contact-implicit formulation is used to model distributed frictional interactions during sidewinding, and validated through MATLAB Simscape simulations and physical experiments on rigid ground and loose sand. To capture terrain deformation effects, Project Chrono's Soil Contact Model (SCM) is integrated with the articulated multibody dynamics, enabling prediction of slip, sinkage, and load redistribution that reduce stride efficiency on deformable substrates. For high-energy rolling locomotion on steep slopes, the Chrono DEM Engine is used to simulate particle-resolved granular interactions, revealing soil failure, intermittent lift-off, and energy dissipation mechanisms not captured by rigid models. Together, these methods span real-time control-oriented simulation and high-fidelity granular physics. Results demonstrate that rigid-ground models provide accurate short-horizon motion prediction, while continuum and particle-based terrain modeling becomes necessary for reliable mobility analysis in soft and highly dynamic environments. This work establishes a hierarchical simulation pipeline that advances robust, terrain-aware locomotion for robots operating in challenging unstructured settings.

【4】Introducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness
- **标题**: 隆重推出 V-Soft Pro：刚度可控的经肱骨假体模块化平台
- **链接**: https://arxiv.org/abs/2512.04998
> **作者**: Giuseppe Milazzo,Giorgio Grioli,Antonio Bicchi,Manuel G. Catalano
> **摘要**: 目前的上肢假肢旨在通过结合基本运动功能来增强用户在日常活动中的独立性。然而，它们无法复制人类手臂的自然运动和交互能力。相比之下，人体四肢利用内在的顺应性并主动调节关节刚度，从而能够在动态动作期间对不同的任务做出自适应响应、冲击吸收和高效的能量传递。受这种适应性的启发，我们开发了一种带有可变刚度执行器 (VSA) 的经肱骨假体，以复制生物关节中的可控顺应性。所提出的假肢采用模块化设计，允许针对不同的残肢形状进行定制，并适应来自用户生物线索的一系列独立控制信号。集成弹性元件被动地支持更自然的运动，促进与环境的安全交互，并适应不同的任务要求。本文对该平台及其功能进行了全面概述，强调了其在假肢领域的潜在应用。
> **Abstract**: Current upper limb prostheses aim to enhance user independence in daily activities by incorporating basic motor functions. However, they fall short of replicating the natural movement and interaction capabilities of the human arm. In contrast, human limbs leverage intrinsic compliance and actively modulate joint stiffness, enabling adaptive responses to varying tasks, impact absorption, and efficient energy transfer during dynamic actions. Inspired by this adaptability, we developed a transhumeral prosthesis with Variable Stiffness Actuators (VSAs) to replicate the controllable compliance found in biological joints. The proposed prosthesis features a modular design, allowing customization for different residual limb shapes and accommodating a range of independent control signals derived from users' biological cues. Integrated elastic elements passively support more natural movements, facilitate safe interactions with the environment, and adapt to diverse task requirements. This paper presents a comprehensive overview of the platform and its functionalities, highlighting its potential applications in the field of prosthetics.

【5】Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist
- **标题**: 紧凑型可变刚度手腕的初步分析与仿真
- **链接**: https://arxiv.org/abs/2512.04973
> **作者**: Giuseppe Milazzo,Manuel G. Catalano,Antonio Bicchi,Giorgio Grioli
> **摘要**: 事实证明，可变刚度执行器对于非结构化环境中的机器人应用具有无价的价值，可以促进安全交互并增强任务适应性。然而，与传统的刚性执行器相比，它们的机械设计不可避免地导致结构更大、更重。本文介绍了一种新颖的三自由度 (DoF) 平行手腕，它通过冗余弹性驱动实现可变刚度。利用其并行架构，该设备仅采用四个电机，使其紧凑且轻便。这一特性使其特别适合假肢或人形机器人的应用。该手稿深入研究了该装置的理论模型，并提出了一种用于独立调节关节位置和刚度的复杂控制策略。此外，它还利用系统动力学的综合分析，通过仿真验证了所提出的控制器。报告的结果证实了该设备在刚性配置中实现高精度和干扰抑制的能力，同时最大限度地减少与其顺应行为的相互作用力。
> **Abstract**: Variable Stiffness Actuators prove invaluable for robotics applications in unstructured environments, fostering safe interactions and enhancing task adaptability. Nevertheless, their mechanical design inevitably results in larger and heavier structures compared to classical rigid actuators. This paper introduces a novel 3 Degrees of Freedom (DoFs) parallel wrist that achieves variable stiffness through redundant elastic actuation. Leveraging its parallel architecture, the device employs only four motors, rendering it compact and lightweight. This characteristic makes it particularly well-suited for applications in prosthetics or humanoid robotics. The manuscript delves into the theoretical model of the device and proposes a sophisticated control strategy for independent regulation of joint position and stiffness. Furthermore, it validates the proposed controller through simulation, utilizing a comprehensive analysis of the system dynamics. The reported results affirm the ability of the device to achieve high accuracy and disturbance rejection in rigid configurations while minimizing interaction forces with its compliant behavior.

【6】Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies
- **标题**: 混合扩散模型：将开环程序与视觉运动扩散策略相结合
- **链接**: https://arxiv.org/abs/2512.04960
> **作者**: Jonne Van Haastregt,Bastian Orthmann,Michael C. Welle,Yuchong Zhang,Danica Kragic
> **摘要**: 尽管通过模仿学习获得的基于视觉运动的策略在复杂的操作任务中表现出良好的性能，但它们通常难以达到与传统基于控制的方法相同的准确性和速度。在这项工作中，我们引入了混合扩散模型，该模型将开环例程与视觉运动扩散策略相结合。我们开发了远程操作增强原语 (TAP)，允许操作员执行预定义的例程，例如锁定特定轴、移动到栖息航路点或在演示期间无缝触发特定于任务的例程。我们的混合扩散方法学习在推理过程中触发此类 TAP。我们在具有挑战性的现实任务中验证了该方法：小瓶抽吸、开放容器液体转移和容器旋开。所有实验视频都可以在该项目的网站上找到：https://hybriddiffusion.github.io/
> **Abstract**: Despite the fact that visuomotor-based policies obtained via imitation learning demonstrate good performances in complex manipulation tasks, they usually struggle to achieve the same accuracy and speed as traditional control based methods. In this work, we introduce Hybrid-Diffusion models that combine open-loop routines with visuomotor diffusion policies. We develop Teleoperation Augmentation Primitives (TAPs) that allow the operator to perform predefined routines, such as locking specific axes, moving to perching waypoints, or triggering task-specific routines seamlessly during demonstrations. Our Hybrid-Diffusion method learns to trigger such TAPs during inference. We validate the method on challenging real-world tasks: Vial Aspiration, Open-Container Liquid Transfer, and container unscrewing. All experimental videos are available on the project's website: https://hybriddiffusion.github.io/

【7】On Disturbance-Aware Minimum-Time Trajectory Planning: Evidence from Tests on a Dynamic Driving Simulator
- **标题**: 关于干扰感知最短时间轨迹规划：来自动态驾驶模拟器测试的证据
- **链接**: https://arxiv.org/abs/2512.04917
> **作者**: Matteo Masoni,Vincenzo Palermo,Marco Gabiccini,Martino Gulisano,Giorgio Previati,Massimiliano Gobbi,Francesco Comolli,Gianpiero Mastinu,Massimo Guiggiani
> **摘要**: 这项工作研究了专业驾驶员在动态模拟器中执行时，干扰感知、鲁棒性嵌入的参考轨迹如何转化为驾驶性能。将三个计划的参考轨迹与自由驾驶基线 (NOREF) 进行比较，以评估单圈时间 (LT) 和转向力 (SE) 之间的权衡： NOM，标称时间最佳轨迹； TLC，通过收紧轨道边缘的裕度而获得的轨道极限鲁棒轨迹； FLC，通过针对车轴和轮胎饱和度进行紧固而获得的摩擦极限稳健轨迹。所有轨迹都具有相同的最小单圈时间目标和小型转向平滑度调节器，并由两名专业车手在虚拟赛道上使用高性能汽车进行评估。这些轨迹源自作者最近提出的扰动感知最小单圈时间框架，其中最坏情况的扰动增长在有限范围内传播，并用于收紧轮胎摩擦和轨道限制约束，在提供概率安全裕度的同时保持性能。 LT和SE被用作性能指标，而RMS横向偏差、速度误差和漂移角则表征驾驶风格。结果显示类似帕累托的 LT-SE 权衡：NOM 产生最短的 LT 但最高的 SE； TLC 以更长的 LT 为代价最大限度地减少 SE； FLC 位于有效边界附近，相对于 NOM 显着降低了 SE，而 LT 仅略有增加。取消轨迹引导 (NOREF) 会增加 LT 和 SE，证实参考轨迹可以提高速度和控制效率。总体而言，研究结果强调基于参考和干扰感知的规划，尤其是 FLC，作为训练和实现快速而稳定的轨迹的有效工具。
> **Abstract**: This work investigates how disturbance-aware, robustness-embedded reference trajectories translate into driving performance when executed by professional drivers in a dynamic simulator. Three planned reference trajectories are compared against a free-driving baseline (NOREF) to assess trade-offs between lap time (LT) and steering effort (SE): NOM, the nominal time-optimal trajectory; TLC, a track-limit-robust trajectory obtained by tightening margins to the track edges; and FLC, a friction-limit-robust trajectory obtained by tightening against axle and tire saturation. All trajectories share the same minimum lap-time objective with a small steering-smoothness regularizer and are evaluated by two professional drivers using a high-performance car on a virtual track. The trajectories derive from a disturbance-aware minimum-lap-time framework recently proposed by the authors, where worst-case disturbance growth is propagated over a finite horizon and used to tighten tire-friction and track-limit constraints, preserving performance while providing probabilistic safety margins. LT and SE are used as performance indicators, while RMS lateral deviation, speed error, and drift angle characterize driving style. Results show a Pareto-like LT-SE trade-off: NOM yields the shortest LT but highest SE; TLC minimizes SE at the cost of longer LT; FLC lies near the efficient frontier, substantially reducing SE relative to NOM with only a small LT increase. Removing trajectory guidance (NOREF) increases both LT and SE, confirming that reference trajectories improve pace and control efficiency. Overall, the findings highlight reference-based and disturbance-aware planning, especially FLC, as effective tools for training and for achieving fast yet stable trajectories.

【8】Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation
- **标题**: 嘿！ -- 用于强制接地、跨视图铰接操纵的多模态数据集
- **链接**: https://arxiv.org/abs/2512.04884
> **作者**: Tim Engelbracht,René Zurbrügg,Matteo Wohlrapp,Martin Büchner,Abhinav Valada,Marc Pollefeys,Hermann Blum,Zuria Bauer
> **摘要**: 我们提出了一个基于力的、跨视图铰接式操作的数据集，它将在真实的人类交互过程中所看到的与所做的和感受到的结合起来。该数据集包含 38 个环境中 381 个铰接物体的 3048 个序列。每个物体都在四个实施例下进行操作 - (i) 人手，(ii) 带有腕式摄像头的人手，(iii) 手持式 UMI 抓手，以及 (iv) 定制的 Hoi!夹具——工具实施例提供同步的末端执行器力和触觉传感。我们的数据集提供了从视频中理解交互的整体视图，使研究人员能够评估方法在人类和机器人观点之间的转换程度，同时还可以研究尚未开发的模式，例如力传感和预测。
> **Abstract**: We present a dataset for force-grounded, cross-view articulated manipulation that couples what is seen with what is done and what is felt during real human interaction. The dataset contains 3048 sequences across 381 articulated objects in 38 environments. Each object is operated under four embodiments - (i) human hand, (ii) human hand with a wrist-mounted camera, (iii) handheld UMI gripper, and (iv) a custom Hoi! gripper - where the tool embodiment provides synchronized end-effector forces and tactile sensing. Our dataset offers a holistic view of interaction understanding from video, enabling researchers to evaluate how well methods transfer between human and robotic viewpoints, but also investigate underexplored modalities such as force sensing and prediction.

【9】MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation
- **标题**: MOVE：一种简单的基于运动的数据收集范式，用于机器人操作的空间泛化
- **链接**: https://arxiv.org/abs/2512.04813
> **作者**: Huanqian Wang,Chi Bene Chen,Yang Yue,Danhua Tao,Tong Guo,Shaoxuan Xie,Denghang Huang,Shiji Song,Guocai Yao,Gao Huang
> **摘要**: 模仿学习方法在机器人操作方面显示出了巨大的前景，但其实际部署从根本上受到数据稀缺的限制。尽管之前在收集大规模数据集方面开展了工作，但在稳健的空间泛化方面仍然存在很大差距。我们确定了一个关键限制：各个轨迹，无论其长度如何，通常都是从环境的\emph{单个静态空间配置}中收集的。这包括固定的物体和目标空间位置以及不变的相机视点，这极大地限制了可用于学习的空间信息的多样性。为了解决数据效率中的这一关键瓶颈，我们提出了 \textbf{基于运动的可变性增强} (\emph{MOVE})，这是一种简单而有效的数据收集范式，可以从动态演示中获取更丰富的空间信息。我们的核心贡献是一种增强策略，为每次演示将运动注入环境中的任何可移动物体。这个过程隐含地在单个轨迹内生成一组密集且多样化的空间配置。我们在模拟和现实环境中进行了广泛的实验来验证我们的方法。例如，在需要强空间泛化的模拟任务中，\emph{MOVE} 实现了 39.1\% 的平均成功率，比静态数据收集范式 (22.2\%) 相对提高了 76.1\%，并且在某些任务上的数据效率提高了 2--5$\times$。我们的代码可在 https://github.com/lucywang720/MOVE 获取。
> **Abstract**: Imitation learning method has shown immense promise for robotic manipulation, yet its practical deployment is fundamentally constrained by the data scarcity. Despite prior work on collecting large-scale datasets, there still remains a significant gap to robust spatial generalization. We identify a key limitation: individual trajectories, regardless of their length, are typically collected from a \emph{single, static spatial configuration} of the environment. This includes fixed object and target spatial positions as well as unchanging camera viewpoints, which significantly restricts the diversity of spatial information available for learning. To address this critical bottleneck in data efficiency, we propose \textbf{MOtion-Based Variability Enhancement} (\emph{MOVE}), a simple yet effective data collection paradigm that enables the acquisition of richer spatial information from dynamic demonstrations. Our core contribution is an augmentation strategy that injects motion into any movable objects within the environment for each demonstration. This process implicitly generates a dense and diverse set of spatial configurations within a single trajectory. We conduct extensive experiments in both simulation and real-world environments to validate our approach. For example, in simulation tasks requiring strong spatial generalization, \emph{MOVE} achieves an average success rate of 39.1\%, a 76.1\% relative improvement over the static data collection paradigm (22.2\%), and yields up to 2--5$\times$ gains in data efficiency on certain tasks. Our code is available at https://github.com/lucywang720/MOVE.

【10】Using Machine Learning to Take Stay-or-Go Decisions in Data-driven Drone Missions
- **标题**: 使用机器学习在数据驱动的无人机任务中做出留或走决策
- **链接**: https://arxiv.org/abs/2512.04773
> **作者**: Giorgos Polychronis,Foivos Pournaropoulos,Christos D. Antonopoulos,Spyros Lalis
> **摘要**: 无人机在许多应用领域变得不可或缺。在数据驱动的任务中，除了感知之外，无人机还必须在运行时处理收集到的数据，以决定在移动到下一个兴趣点之前是否必须在现场采取额外的行动。如果处理没有揭示需要采取此类行动的事件或情况，那么无人机就徒劳地等待，而不是移动到下一个点。然而，如果无人机开始移动到下一个点，并且发现需要在前一个点进行后续动作，则它必须花时间飞回来。为了做出这个决定，我们提出了基于分支预测和强化学习的不同机器学习方法。我们针对事件发生概率随时间变化的各种场景评估这些方法。我们的结果表明，所提出的方法始终优于文献中提出的基于回归的方法，并且可以将最坏情况下的任务时间显着缩短高达 4.1 倍。此外，所实现的中位任务时间与完全了解每个关注点当前潜在事件概率的方法的中位任务时间非常接近，仅高出 2.7%。
> **Abstract**: Drones are becoming indispensable in many application domains. In data-driven missions, besides sensing, the drone must process the collected data at runtime to decide whether additional action must be taken on the spot, before moving to the next point of interest. If processing does not reveal an event or situation that requires such an action, the drone has waited in vain instead of moving to the next point. If, however, the drone starts moving to the next point and it turns out that a follow-up action is needed at the previous point, it must spend time to fly-back. To take this decision, we propose different machine-learning methods based on branch prediction and reinforcement learning. We evaluate these methods for a wide range of scenarios where the probability of event occurrence changes with time. Our results show that the proposed methods consistently outperform the regression-based method proposed in the literature and can significantly improve the worst-case mission time by up to 4.1x. Also, the achieved median mission time is very close, merely up to 2.7% higher, to that of a method with perfect knowledge of the current underlying event probability at each point of interest.

【11】TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards
- **标题**: TEMPO-VINE：用于葡萄园定位和绘图的多时态传感器融合数据集
- **链接**: https://arxiv.org/abs/2512.04772
> **作者**: Mauro Martini,Marco Ambrosio,Judith Vilella-Cantos,Alessandro Navone,Marcello Chiaberge
> **摘要**: 近年来，精准农业在该领域不断引入突破性创新，特别关注自动化。然而，机器人和自主导航的研究通常依赖于受控模拟或孤立的现场试验。缺乏现实的共同基准对于在真实复杂的农业条件下传播强大的自治系统来说是一个重大限制。由于葡萄园的动态特性，葡萄园面临着巨大的挑战，它们越来越受到对自动化感兴趣的学术和工业利益相关者的关注。在此背景下，我们介绍了 TEMPO-VINE 数据集，这是一个大规模多时态数据集，专门用于评估葡萄园运营环境中的传感器融合、同步定位和地图绘制 (SLAM) 以及地点识别技术。 TEMPO-VINE 是第一个多模态公共数据集，汇集了来自不同价格水平的异构 LiDAR、AHRS、RTK-GPS 和真实棚架和凉棚葡萄园中摄像机的数据，多行长度超过 100 m。在这项工作中，我们通过为研究人员提供全面的数据收集和不同季节、植被生长阶段、地形和天气条件下的地面实况轨迹，解决了农业数据集景观中的一个关键差距。多次运行和重访的序列路径将促进农业领域传感器融合、定位、测绘和地点识别解决方案的发展。数据集、处理工具和基准测试结果将在接受后在专用网页上提供。
> **Abstract**: In recent years, precision agriculture has been introducing groundbreaking innovations in the field, with a strong focus on automation. However, research studies in robotics and autonomous navigation often rely on controlled simulations or isolated field trials. The absence of a realistic common benchmark represents a significant limitation for the diffusion of robust autonomous systems under real complex agricultural conditions. Vineyards pose significant challenges due to their dynamic nature, and they are increasingly drawing attention from both academic and industrial stakeholders interested in automation. In this context, we introduce the TEMPO-VINE dataset, a large-scale multi-temporal dataset specifically designed for evaluating sensor fusion, simultaneous localization and mapping (SLAM), and place recognition techniques within operational vineyard environments. TEMPO-VINE is the first multi-modal public dataset that brings together data from heterogeneous LiDARs of different price levels, AHRS, RTK-GPS, and cameras in real trellis and pergola vineyards, with multiple rows exceeding 100 m in length. In this work, we address a critical gap in the landscape of agricultural datasets by providing researchers with a comprehensive data collection and ground truth trajectories in different seasons, vegetation growth stages, terrain and weather conditions. The sequence paths with multiple runs and revisits will foster the development of sensor fusion, localization, mapping and place recognition solutions for agricultural fields. The dataset, the processing tools and the benchmarking results will be available at the dedicated webpage upon acceptance.

【12】Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges
- **标题**: 快速发展的智能体的具体协同设计：分类、前沿和挑战
- **链接**: https://arxiv.org/abs/2512.04770
> **作者**: Yuxing Wang,Zhiyu Chen,Tiantian Zhang,Qiyue Yin,Yongzhe Chang,Zhiheng Li,Liang Wang,Xueqian Wang
> **摘要**: 大脑与身体的共同进化使动物能够在其环境中发展出复杂的行为。受这种生物协同作用的启发，体现协同设计（ECD）已成为创建智能体（从虚拟生物到物理机器人）的变革范式，通过共同优化它们的形态和控制器，而不是孤立地处理控制。这种集成方法有利于更丰富的环境交互和强大的任务性能。在本次调查中，我们系统地概述了 ECD 的最新进展。我们首先将 ECD 的概念正式化，并将其定位在相关领域。然后我们引入一个分层分类法：下层将代理设计分解为三个基本组件——控制大脑、身体形态和任务环境——上层将这些组件集成到四个主要的 ECD 框架中：双层、单层、生成式和开放式。这种分类法使我们能够综合一百多项近期研究的见解。我们进一步回顾了模拟和现实场景中的著名基准、数据集和应用程序。最后，我们确定了重大挑战，并对有前途的未来研究方向提供了见解。与此调查相关的项目已在 https://github.com/Yuxing-Wang-THU/SurveyBrainBody 创建。
> **Abstract**: Brain-body co-evolution enables animals to develop complex behaviors in their environments. Inspired by this biological synergy, embodied co-design (ECD) has emerged as a transformative paradigm for creating intelligent agents-from virtual creatures to physical robots-by jointly optimizing their morphologies and controllers rather than treating control in isolation. This integrated approach facilitates richer environmental interactions and robust task performance. In this survey, we provide a systematic overview of recent advances in ECD. We first formalize the concept of ECD and position it within related fields. We then introduce a hierarchical taxonomy: a lower layer that breaks down agent design into three fundamental components-controlling brain, body morphology, and task environment-and an upper layer that integrates these components into four major ECD frameworks: bi-level, single-level, generative, and open-ended. This taxonomy allows us to synthesize insights from more than one hundred recent studies. We further review notable benchmarks, datasets, and applications in both simulated and real-world scenarios. Finally, we identify significant challenges and offer insights into promising future research directions. A project associated with this survey has been created at https://github.com/Yuxing-Wang-THU/SurveyBrainBody.

【13】Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting
- **标题**: 连接模拟和现实：使用语义 2D 高斯分布进行跨域传输
- **链接**: https://arxiv.org/abs/2512.04731
> **作者**: Jian Tang,Pu Pang,Haowen Sun,Chengzhong Ma,Xingyu Chen,Hua Huang,Xuguang Lan
> **摘要**: 由于模拟环境和现实环境之间存在巨大的域差距，机器人操作中的跨域传输仍然是一个长期存在的挑战。域随机化、自适应和模拟-真实校准等现有方法通常需要大量调整，或者无法推广到未见过的场景。为了解决这个问题，我们观察到，如果在模拟策略训练过程中利用域不变特征，并且在实际部署过程中可以提取相同的特征并提供作为策略的输入，则可以有效地弥合域差距，从而显着提高策略泛化能力。因此，我们提出了语义二维高斯分布（S2GS），这是一种提取以对象为中心、域不变的空间特征的新颖表示方法。 S2GS构建多视图2D语义场，并通过特征级高斯分布将它们投影到统一的3D空间中。语义过滤机制会删除不相关的背景内容，确保政策学习的输入干净且一致。为了评估S2GS的有效性，我们采用扩散策略作为下游学习算法，并在ManiSkill模拟环境中进行实验，然后进行实际部署。结果表明，S2GS 显着提高了模拟到真实的可迁移性，在现实场景中保持高且稳定的任务性能。
> **Abstract**: Cross-domain transfer in robotic manipulation remains a longstanding challenge due to the significant domain gap between simulated and real-world environments. Existing methods such as domain randomization, adaptation, and sim-real calibration often require extensive tuning or fail to generalize to unseen scenarios. To address this issue, we observe that if domain-invariant features are utilized during policy training in simulation, and the same features can be extracted and provided as the input to policy during real-world deployment, the domain gap can be effectively bridged, leading to significantly improved policy generalization. Accordingly, we propose Semantic 2D Gaussian Splatting (S2GS), a novel representation method that extracts object-centric, domain-invariant spatial features. S2GS constructs multi-view 2D semantic fields and projects them into a unified 3D space via feature-level Gaussian splatting. A semantic filtering mechanism removes irrelevant background content, ensuring clean and consistent inputs for policy learning. To evaluate the effectiveness of S2GS, we adopt Diffusion Policy as the downstream learning algorithm and conduct experiments in the ManiSkill simulation environment, followed by real-world deployment. Results demonstrate that S2GS significantly improves sim-to-real transferability, maintaining high and stable task performance in real-world scenarios.

【14】One Ring to Rule Them All: Constrained Distributional Control for Massive-Scale Heterogeneous Robotic Ensemble Systems
- **标题**: 一环统治一切：大规模异构机器人集成系统的约束分布式控制
- **链接**: https://arxiv.org/abs/2512.04502
> **作者**: Andres Arias,Wei Zhang,Haoyu Qian,Jr-Shin Li,Chuangchuang Sun
> **摘要**: 集成控制旨在使用共享控制输入来引导一群动态系统。本文介绍了一种约束集成控制框架，用于在状态和环境约束（例如避障）下运行的参数化异构机器人系统。我们开发了一种矩核变换，将参数化的系综动力学映射到核空间中的矩系统，从而能够表征群体水平的行为。状态空间约束，例如要访问的多面体路径点和要避开的障碍物，也被转换到矩空间中，从而形成安全、大规模系综控制的统一公式。采用富有表现力的信号时序逻辑规范来编码复杂的访问避免任务，这些任务是通过从我们的约束集成控制公式合成的单个共享控制器来实现的。仿真和硬件实验证明了所提出的方法在受限环境中安全有效地控制机器人整体的有效性。
> **Abstract**: Ensemble control aims to steer a population of dynamical systems using a shared control input. This paper introduces a constrained ensemble control framework for parameterized, heterogeneous robotic systems operating under state and environmental constraints, such as obstacle avoidance. We develop a moment kernel transform that maps the parameterized ensemble dynamics to the moment system in a kernel space, enabling the characterization of population-level behavior. The state-space constraints, such as polyhedral waypoints to be visited and obstacles to be avoided, are also transformed into the moment space, leading to a unified formulation for safe, large-scale ensemble control. Expressive signal temporal logic specifications are employed to encode complex visit-avoid tasks, which are achieved through a single shared controller synthesized from our constrained ensemble control formulation. Simulation and hardware experiments demonstrate the effectiveness of the proposed approach in safely and efficiently controlling robotic ensembles within constrained environments.

## 声音(cs.SD:Sound)

【1】Language Models as Semantic Teachers: Post-Training Alignment for Medical Audio Understanding
- **标题**: 作为语义教师的语言模型：医学音频理解的训练后对齐
- **链接**: https://arxiv.org/abs/2512.04847
> **作者**: Tsai-Ning Wang,Lin-Lin Chen,Neil Zeghidour,Aaqib Saeed
> **摘要**: 预先训练的音频模型擅长检测听诊声音中的声学模式，但往往无法掌握其临床意义，从而限制了它们在诊断任务中的使用和性能。为了弥补这一差距，我们引入了 AcuLa（通过语言对齐进行音频临床理解），这是一个轻量级的训练后框架，通过将音频编码器与医学语言模型对齐来将语义理解灌输到任何音频编码器中，医学语言模型充当“语义老师”。为了实现大规模对齐，我们利用现成的大型语言模型构建了一个大型数据集，将现有录音附带的丰富的结构化元数据翻译成连贯的临床报告。我们的对齐策略将表示级对比目标与自我监督建模相结合，确保模型学习临床语义，同时保留细粒度的时间线索。 AcuLa 在来自 10 个不同数据集的 18 种不同的心肺任务中取得了最先进的结果，将分类基准的平均 AUROC 从 0.68 提高到 0.79，在最具挑战性的 COVID-19 咳嗽检测任务上，将 AUROC 从 0.55 提高到 0.89。我们的工作表明，这种音频语言对齐将纯粹的声学模型转变为临床感知的诊断工具，为增强基于音频的健康监测中的生理理解建立了一种新的范例。
> **Abstract**: Pre-trained audio models excel at detecting acoustic patterns in auscultation sounds but often fail to grasp their clinical significance, limiting their use and performance in diagnostic tasks. To bridge this gap, we introduce AcuLa (Audio-Clinical Understanding via Language Alignment), a lightweight post-training framework that instills semantic understanding into any audio encoder by aligning it with a medical language model, which acts as a "semantic teacher." To enable alignment at scale, we construct a large-scale dataset by leveraging off-the-shelf large language models to translate the rich, structured metadata accompanying existing audio recordings into coherent clinical reports. Our alignment strategy combines a representation-level contrastive objective with a self-supervised modeling, ensuring that the model learns clinical semantics while preserving fine-grained temporal cues. AcuLa achieves state-of-the-art results across 18 diverse cardio-respiratory tasks from 10 different datasets, improving the mean AUROC on classification benchmarks from 0.68 to 0.79 and, on the most challenging COVID-19 cough detection task, boosting the AUROC from 0.55 to 0.89. Our work demonstrates that this audio-language alignment transforms purely acoustic models into clinically-aware diagnostic tools, establishing a novel paradigm for enhancing physiological understanding in audio-based health monitoring.

【2】Contract-Driven QoE Auditing for Speech and Singing Services: From MOS Regression to Service Graphs
- **标题**: 合同驱动的语音和歌唱服务 QoE 审核：从 MOS 回归到服务图
- **链接**: https://arxiv.org/abs/2512.04827
> **作者**: Wenzhang Du
> **摘要**: 主观平均意见分数（MOS）仍然是非侵入性语音和歌唱质量评估的事实上的目标。然而，MOS 是一个标量，它会破坏异构用户的期望，忽略服务级别目标，并且很难跨部署图进行比较。我们提出了一个契约驱动的 QoE 审计框架：每个服务图 G 在一组人类可解释的体验契约 C 下进行评估，产生契约级满意度向量 Q(G, C)。我们表明，(i) 经典 MOS 回归是退化合约集的特例，(ii) 合约驱动的质量在图视图转换下比 MOS 更稳定（例如，按系统池化与按系统类型池化），以及 (iii) 学习合约的有效样本复杂性由合约语义控制，而不仅仅是 C 的维度。我们在 URGENT2024 MOS 上实例化该框架（带有原始评级向量的 6.9k 语音话语）， SingMOS v1（7,981 个歌唱片段；80 个系统）。在 URGENT 上，我们训练了一个关于自监督 WavLM 嵌入的合同感知神经审计员；在 SingMOS 上，我们使用发布的评级向量和元数据执行合约驱动的图形审计，而无需解码音频。根据经验，我们的审计员在 MOS 准确性方面匹配强大的 MOS 预测器，同时提供校准的合同概率；在 SingMOS 上，Q(G, C) 表现出比原始 MOS 和仅图形基线小得多的交叉视图漂移；在紧急情况下，难度曲线显示，错误指定的“简单”合约可能比更丰富但更一致的合约集更难学习。
> **Abstract**: Subjective mean opinion scores (MOS) remain the de-facto target for non-intrusive speech and singing quality assessment. However, MOS is a scalar that collapses heterogeneous user expectations, ignores service-level objectives, and is difficult to compare across deployment graphs. We propose a contract-driven QoE auditing framework: each service graph G is evaluated under a set of human-interpretable experience contracts C, yielding a contract-level satisfaction vector Q(G, C). We show that (i) classical MOS regression is a special case with a degenerate contract set, (ii) contract-driven quality is more stable than MOS under graph view transformations (e.g., pooling by system vs. by system type), and (iii) the effective sample complexity of learning contracts is governed by contract semantics rather than merely the dimensionality of C. We instantiate the framework on URGENT2024 MOS (6.9k speech utterances with raw rating vectors) and SingMOS v1 (7,981 singing clips; 80 systems). On URGENT, we train a contract-aware neural auditor on self-supervised WavLM embeddings; on SingMOS, we perform contract-driven graph auditing using released rating vectors and metadata without decoding audio. Empirically, our auditor matches strong MOS predictors in MOS accuracy while providing calibrated contract probabilities; on SingMOS, Q(G, C) exhibits substantially smaller cross-view drift than raw MOS and graph-only baselines; on URGENT, difficulty curves reveal that mis-specified "simple" contracts can be harder to learn than richer but better aligned contract sets.

【3】Shared Multi-modal Embedding Space for Face-Voice Association
- **标题**: 用于面部语音关联的共享多模态嵌入空间
- **链接**: https://arxiv.org/abs/2512.04814
> **作者**: Christopher Simic,Korbinian Riedhammer,Tobias Bocklet
> **摘要**: FAME 2026 挑战包括两项艰巨的任务：训练面部语音关联与多语言环境相结合，其中包括对模型未训练的语言进行测试。我们的方法由单独的单模态处理管道组成，具有一般面部和语音特征提取，并辅以额外的年龄-性别特征提取以支持预测。由此产生的单模态特征被投影到共享嵌入空间中，并使用自适应角裕度（AAM）损失进行训练。我们的方法在 FAME 2026 挑战赛中获得第一名，平均等错误率 (EER) 为 23.99%。
> **Abstract**: The FAME 2026 challenge comprises two demanding tasks: training face-voice associations combined with a multilingual setting that includes testing on languages on which the model was not trained. Our approach consists of separate uni-modal processing pipelines with general face and voice feature extraction, complemented by additional age-gender feature extraction to support prediction. The resulting single-modal features are projected into a shared embedding space and trained with an Adaptive Angular Margin (AAM) loss. Our approach achieved first place in the FAME 2026 challenge, with an average Equal-Error Rate (EER) of 23.99%.

【4】YingMusic-SVC: Real-World Robust Zero-Shot Singing Voice Conversion with Flow-GRPO and Singing-Specific Inductive Biases
- **标题**: YingMusic-SVC：具有 Flow-GRPO 和特定于歌唱的归纳偏差的真实世界鲁棒零样本歌声转换
- **链接**: https://arxiv.org/abs/2512.04793
> **作者**: Gongyu Chen,Xiaoyu Zhang,Zhenqiang Weng,Junjie Zheng,Da Shen,Chaofan Ding,Wei-Qiang Zhang,Zihao Chen
> **摘要**: 歌声转换（SVC）旨在渲染目标歌手的音色，同时保留旋律和歌词。然而，由于和声干扰、F0 错误以及缺乏歌唱归纳偏差，现有的零样本 SVC 系统在真实歌曲中仍然很脆弱。我们提出了 YingMusic-SVC，这是一个强大的零样本框架，它统一了连续预训练、强大的监督微调和 Flow-GRPO 强化学习。我们的模型引入了用于音色内容解开的经过歌唱训练的 RVC 音色移位器、用于动态声音表达的 F0 感知音色适配器，以及用于增强高频保真度的能量平衡整流流匹配损失。分级多轨基准测试表明，YingMusic-SVC 在音色相似性、清晰度和感知自然度方面比强大的开源基线取得了一致的改进，特别是在伴奏和和声污染的条件下，证明了其在现实世界 SVC 部署中的有效性。
> **Abstract**: Singing voice conversion (SVC) aims to render the target singer's timbre while preserving melody and lyrics. However, existing zero-shot SVC systems remain fragile in real songs due to harmony interference, F0 errors, and the lack of inductive biases for singing. We propose YingMusic-SVC, a robust zero-shot framework that unifies continuous pre-training, robust supervised fine-tuning, and Flow-GRPO reinforcement learning. Our model introduces a singing-trained RVC timbre shifter for timbre-content disentanglement, an F0-aware timbre adaptor for dynamic vocal expression, and an energy-balanced rectified flow matching loss to enhance high-frequency fidelity. Experiments on a graded multi-track benchmark show that YingMusic-SVC achieves consistent improvements over strong open-source baselines in timbre similarity, intelligibility, and perceptual naturalness, especially under accompanied and harmony-contaminated conditions, demonstrating its effectiveness for real-world SVC deployment.

【5】YingMusic-Singer: Zero-shot Singing Voice Synthesis and Editing with Annotation-free Melody Guidance
- **标题**: YingMusic-Singer：零样本歌声合成与免注释旋律指导编辑
- **链接**: https://arxiv.org/abs/2512.04779
> **作者**: Junjie Zheng,Chunbo Hao,Guobin Ma,Xiaoyu Zhang,Gongyu Chen,Chaofan Ding,Zihao Chen,Lei Xie
> **摘要**: 歌声合成（SVS）在实际部署中仍然受到限制，因为它强烈依赖于准确的音素级对齐和手动注释的旋律轮廓，这些要求是资源密集型的并且阻碍了可扩展性。为了克服这些限制，我们提出了一种旋律驱动的 SVS 框架，能够根据任何参考旋律合成任意歌词，而不依赖于音素级对齐。我们的方法建立在扩散变压器（DiT）架构的基础上，并通过专用的旋律提取模块进行了增强，该模块直接从参考音频中导出旋律表示。为了确保稳健的旋律编码，我们采用教师模型来指导旋律提取器的优化，同时采用隐式对齐机制来强制相似性分布约束，以提高旋律的稳定性和连贯性。此外，我们使用弱注释的歌曲数据改进持续时间建模，并引入具有多目标奖励函数的 Flow-GRPO 强化学习策略，以共同增强发音清晰度和旋律保真度。实验表明，我们的模型在客观测量和主观听力测试中都比现有方法实现了优越的性能，特别是在零镜头和歌词适应设置中，同时保持高音频质量而无需手动注释。这项工作为推进数据高效的歌声合成提供了实用且可扩展的解决方案。为了支持可重复性，我们发布了推理代码和模型检查点。
> **Abstract**: Singing Voice Synthesis (SVS) remains constrained in practical deployment due to its strong dependence on accurate phoneme-level alignment and manually annotated melody contours, requirements that are resource-intensive and hinder scalability. To overcome these limitations, we propose a melody-driven SVS framework capable of synthesizing arbitrary lyrics following any reference melody, without relying on phoneme-level alignment. Our method builds on a Diffusion Transformer (DiT) architecture, enhanced with a dedicated melody extraction module that derives melody representations directly from reference audio. To ensure robust melody encoding, we employ a teacher model to guide the optimization of the melody extractor, alongside an implicit alignment mechanism that enforces similarity distribution constraints for improved melodic stability and coherence. Additionally, we refine duration modeling using weakly annotated song data and introduce a Flow-GRPO reinforcement learning strategy with a multi-objective reward function to jointly enhance pronunciation clarity and melodic fidelity. Experiments show that our model achieves superior performance over existing approaches in both objective measures and subjective listening tests, especially in zero-shot and lyric adaptation settings, while maintaining high audio quality without manual annotation. This work offers a practical and scalable solution for advancing data-efficient singing voice synthesis. To support reproducibility, we release our inference code and model checkpoints.

【6】M3-TTS: Multi-modal DiT Alignment & Mel-latent for Zero-shot High-fidelity Speech Synthesis
- **标题**: M3-TTS：用于零样本高保真语音合成的多模态 DiT 对齐和 Mel-latent
- **链接**: https://arxiv.org/abs/2512.04720
> **作者**: Xiaopeng Wang,Chunyu Qiang,Ruibo Fu,Zhengqi Wen,Xuefei Liu,Yukun Liu,Yuzhe Liang,Kang Yin,Yuankun Xie,Heng Xie,Chenxing Li,Chen Zhang,Changsheng Li
> **摘要**: 非自回归 (NAR) 文本到语音合成依赖于文本序列和音频表示之间的长度对齐，限制了自然度和表现力。现有方法依赖于持续时间建模或伪对齐策略，这严重限制了自然性和计算效率。我们提出了 M3-TTS，一种基于多模态扩散变换器 (MM-DiT) 架构的简洁高效的 NAR TTS 范式。 M3-TTS 采用联合扩散变换器层进行跨模态对齐，实现可变长度文本-语音序列之间的稳定单调对齐，而无需伪对齐要求。单扩散变压器层进一步增强了声学细节建模。该框架集成了 mel-vae 编解码器，可提供 3* 训练加速。 Seed-TTS 和 AISHELL-3 基准测试的实验结果表明，M3-TTS 实现了最先进的 NAR 性能，具有最低的单词错误率（英语 1.36%，中文 1.31%），同时保持有竞争力的自然度分数。代码和演示将在 https://wwwwxp.github.io/M3-TTS 上提供。
> **Abstract**: Non-autoregressive (NAR) text-to-speech synthesis relies on length alignment between text sequences and audio representations, constraining naturalness and expressiveness. Existing methods depend on duration modeling or pseudo-alignment strategies that severely limit naturalness and computational efficiency. We propose M3-TTS, a concise and efficient NAR TTS paradigm based on multi-modal diffusion transformer (MM-DiT) architecture. M3-TTS employs joint diffusion transformer layers for cross-modal alignment, achieving stable monotonic alignment between variable-length text-speech sequences without pseudo-alignment requirements. Single diffusion transformer layers further enhance acoustic detail modeling. The framework integrates a mel-vae codec that provides 3* training acceleration. Experimental results on Seed-TTS and AISHELL-3 benchmarks demonstrate that M3-TTS achieves state-of-the-art NAR performance with the lowest word error rates (1.36\% English, 1.31\% Chinese) while maintaining competitive naturalness scores. Code and demos will be available at https://wwwwxp.github.io/M3-TTS.

【7】Large Speech Model Enabled Semantic Communication
- **标题**: 大型语音模型支持语义通信
- **链接**: https://arxiv.org/abs/2512.04711
> **作者**: Yun Tian,Zhijin Qin,Guocheng Lv,Ye Jin,Kaibin Huang,Zhu Han
> **摘要**: 主要基于联合源通道编码（JSCC）架构的现有语音语义通信系统已经表现出令人印象深刻的性能，但其有效性仍然受到专门为特定任务和数据集设计的模型结构的限制。最近的进展表明，在海量数据集上预先训练的生成大型模型可以实现出色的性能，并且可以通过最少的微调在不同的下游任务中表现出卓越的性能。为了利用大型模型中嵌入的丰富语义知识并实现有损信道上的自适应传输，我们提出了一种支持大型语音模型的语义通信（LargeSC）系统。同时实现自适应压缩和有损信道上的鲁棒传输仍然具有挑战性，需要在压缩效率、语音质量和延迟之间进行权衡。在这项工作中，我们采用 Mimi 作为语音编解码器，将语音转换为与现有网络架构兼容的离散令牌。我们提出了一种自适应控制器模块，可实现自适应传输和带内不等错误保护（UEP），在带宽限制下动态调整语音内容和丢包概率。此外，我们采用低秩适应 (LoRA) 来微调 Moshi 基础模型，以生成丢失的语音标记。仿真结果表明，所提出的系统支持550 bps至2.06 kbps的带宽，在高丢包率下的语音质量优于传统基线，并实现了约460 ms的端到端延迟，从而展示了其实时部署的潜力。
> **Abstract**: Existing speech semantic communication systems mainly based on Joint Source-Channel Coding (JSCC) architectures have demonstrated impressive performance, but their effectiveness remains limited by model structures specifically designed for particular tasks and datasets. Recent advances indicate that generative large models pre-trained on massive datasets, can achieve outstanding performance arexhibit exceptional performance across diverse downstream tasks with minimal fine-tuning. To exploit the rich semantic knowledge embedded in large models and enable adaptive transmission over lossy channels, we propose a Large Speech Model enabled Semantic Communication (LargeSC) system. Simultaneously achieving adaptive compression and robust transmission over lossy channels remains challenging, requiring trade-offs among compression efficiency, speech quality, and latency. In this work, we employ the Mimi as a speech codec, converting speech into discrete tokens compatible with existing network architectures. We propose an adaptive controller module that enables adaptive transmission and in-band Unequal Error Protection (UEP), dynamically adjusting to both speech content and packet loss probability under bandwidth constraints. Additionally, we employ Low-Rank Adaptation (LoRA) to finetune the Moshi foundation model for generative recovery of lost speech tokens. Simulation results show that the proposed system supports bandwidths ranging from 550 bps to 2.06 kbps, outperforms conventional baselines in speech quality under high packet loss rates and achieves an end-to-end latency of approximately 460 ms, thereby demonstrating its potential for real-time deployment.

【8】Standard audiogram classification from loudness scaling data using unsupervised, supervised, and explainable machine learning techniques
- **标题**: 使用无监督、监督和可解释的机器学习技术根据响度缩放数据进行标准听力图分类
- **链接**: https://arxiv.org/abs/2512.04616
> **作者**: Chen Xu,Lena Schell-Majoor,Birger Kollmeier
> **摘要**: 为了解决康复听力学远程听力图评估中固有的校准和程序挑战，本研究调查了是否可以使用机器学习将听众分类为标准 Bisgaard 听力图类型，从而使用独立于校准的自适应分类响度缩放 (ACALOS) 数据来近似个人听力图。评估了三类机器学习方法——无监督、监督和可解释。执行主成分分析 (PCA) 来提取前两个主成分，它们共同解释了 50% 以上的方差。七个监督多类分类器与无监督且可解释的方法一起进行了训练和比较。模型开发和评估使用了包含 ACALOS 数据 (N = 847) 的大型听觉参考数据库。 PCA 因子图显示听众之间存在大量重叠，这表明仅根据参与者的响度模式将参与者清晰地分为六个 Bisgaard 类别具有挑战性。尽管如此，这些模型表现出了合理的分类性能，逻辑回归在监督方法中实现了最高的准确性。这些发现表明，机器学习模型可以在一定范围内根据与校准无关的响度感知数据预测标准 Bisgaard 听力图类型，从而支持远程或资源有限环境中的潜在应用，而无需传统听力图。
> **Abstract**: To address the calibration and procedural challenges inherent in remote audiogram assessment for rehabilitative audiology, this study investigated whether calibration-independent adaptive categorical loudness scaling (ACALOS) data can be used to approximate individual audiograms by classifying listeners into standard Bisgaard audiogram types using machine learning. Three classes of machine learning approaches - unsupervised, supervised, and explainable - were evaluated. Principal component analysis (PCA) was performed to extract the first two principal components, which together explained more than 50 percent of the variance. Seven supervised multi-class classifiers were trained and compared, alongside unsupervised and explainable methods. Model development and evaluation used a large auditory reference database containing ACALOS data (N = 847). The PCA factor map showed substantial overlap between listeners, indicating that cleanly separating participants into six Bisgaard classes based solely on their loudness patterns is challenging. Nevertheless, the models demonstrated reasonable classification performance, with logistic regression achieving the highest accuracy among supervised approaches. These findings demonstrate that machine learning models can predict standard Bisgaard audiogram types, within certain limits, from calibration-independent loudness perception data, supporting potential applications in remote or resource-limited settings without requiring a traditional audiogram.

【9】RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS
- **标题**: RRPO：基于 LLM 的情感 TTS 的稳健奖励政策优化
- **链接**: https://arxiv.org/abs/2512.04552
> **作者**: Cong Wang,Changfeng Gao,Yang Xiang,Zhihao Du,Keyu An,Han Zhao,Qian Chen,Xiangang Li,Yingming Gao,Ya Li
> **摘要**: 像 DiffRO 这样的可微强化学习 (RL) 框架为可控文本转语音 (TTS) 提供了一种强大的方法，但很容易受到奖励黑客攻击，特别是对于情绪控制等细致入微的任务。该策略模型可以通过生成声学伪影来利用普通奖励模型（RM）来实现虚假奖励，但代价是降低感知质量。为了解决这个问题，我们提出了鲁棒奖励策略优化（RRPO），这是一种采用混合正则化方案的新颖框架。该方案开发了一个强大的 RM，其奖励信号更可靠地与人类感知保持一致，迫使策略放弃有害的捷径，转而学习真实情感的复杂特征。我们的消融研究证实了 RM 的稳健性增强，其强大的跨语言泛化能力就证明了这一点。主观评估表明，这种强大的 RM 有效地减轻了奖励黑客行为，从而在所有基线上实现了情感表达和自然度的显着改善。演示页面：https://lrwinr.github.io/RRPO-CosyVoice。
> **Abstract**: Differentiable reinforcement learning (RL) frameworks like DiffRO offer a powerful approach for controllable text-to-speech (TTS), but are vulnerable to reward hacking, particularly for nuanced tasks like emotion control. The policy model can exploit a vanilla Reward Model (RM) by generating acoustic artifacts to achieve spurious rewards, but at the cost of degrading perceptual quality. To address this, we propose Robust Reward Policy Optimization (RRPO), a novel framework that employs a hybrid regularization scheme. This scheme develops a robust RM whose reward signal is more reliably aligned with human perception, compelling the policy to abandon detrimental shortcuts and instead learn the complex features of genuine emotions. Our ablation study confirms the enhanced robustness of our RM, as evidenced by its strong cross-lingual generalization. The subjective evaluation demonstrates that this robust RM effectively mitigates reward hacking, leading to significant improvements in both emotional expressiveness and naturalness over all baselines. Demo page: https://lrwinr.github.io/RRPO-CosyVoice.

【10】Multi-Loss Learning for Speech Emotion Recognition with Energy-Adaptive Mixup and Frame-Level Attention
- **标题**: 具有能量自适应混合和帧级注意力的语音情感识别的多重损失学习
- **链接**: https://arxiv.org/abs/2512.04551
> **作者**: Cong Wang,Yizhong Geng,Yuhua Wen,Qifei Li,Yingming Gao,Ruimin Wang,Chunfeng Wang,Hao Li,Ya Li,Wei Chen
> **摘要**: 语音情感识别（SER）是人机交互中的一项重要技术。然而，由于情感复杂性和注释数据稀缺，实现高性能具有挑战性。为了应对这些挑战，我们提出了一种集成能量自适应混合（EAM）方法和帧级注意模块（FLAM）的多重损失学习（MLL）框架。 EAM 方法利用基于 SNR 的增强来生成多种语音样本，捕获微妙的情绪变化。 FLAM 增强了多帧情感线索的帧级特征提取。我们的 MLL 策略结合了 Kullback-Leibler 散度、焦点、中心和监督对比损失来优化学习、解决类别不平衡并提高特征可分离性。我们在四个广泛使用的 SER 数据集上评估我们的方法：IEMOCAP、MSP-IMPROV、RAVDESS 和 SAVEE。结果表明我们的方法实现了最先进的性能，表明其有效性和稳健性。
> **Abstract**: Speech emotion recognition (SER) is an important technology in human-computer interaction. However, achieving high performance is challenging due to emotional complexity and scarce annotated data. To tackle these challenges, we propose a multi-loss learning (MLL) framework integrating an energy-adaptive mixup (EAM) method and a frame-level attention module (FLAM). The EAM method leverages SNR-based augmentation to generate diverse speech samples capturing subtle emotional variations. FLAM enhances frame-level feature extraction for multi-frame emotional cues. Our MLL strategy combines Kullback-Leibler divergence, focal, center, and supervised contrastive loss to optimize learning, address class imbalance, and improve feature separability. We evaluate our method on four widely used SER datasets: IEMOCAP, MSP-IMPROV, RAVDESS, and SAVEE. The results demonstrate our method achieves state-of-the-art performance, suggesting its effectiveness and robustness.

## 软件工程(cs.SE:Software Engineering)

【1】Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap
- **标题**: 自适应系统的生成人工智能：最新技术和研究路线图
- **链接**: https://arxiv.org/abs/2512.04680
> **作者**: Jialong Li,Mingyue Zhang,Nianyu Li,Danny Weyns,Zhi Jin,Kenji Tei
> **摘要**: 自适应系统 (SAS) 旨在通过具有四个核心功能的反馈循环来处理变化和不确定性：监控、分析、规划和执行。近年来，生成式人工智能（GenAI），特别是大型语言模型领域，在数据理解和逻辑推理方面表现出了令人印象深刻的表现。这些功能与 SAS 所需的功能高度一致，表明采用 GenAI 增强 SAS 的巨大潜力。然而，在 SAS 中使用 GenAI 的具体好处和挑战仍不清楚。然而，由于以下几个原因，全面了解这些好处和挑战是复杂的：SAS 领域的出版物有限、SAS 内的技术和应用多样性以及 GenAI 技术的快速发展。为此，本文旨在为研究人员和从业人员提供全面的概览，概述在 SAS 中使用 GenAI 的潜在好处和挑战。具体来说，我们收集、过滤和分析来自四个不同研究领域的文献，并将它们分为两大类，以获得潜在的好处：(i) 围绕 MAPE-K 反馈环路的特定功能增强 SAS 的自主性，以及 (ii) 在人机交互设置中改善人类和 SAS 之间的交互。根据我们的研究，我们概述了一个研究路线图，强调了将 GenAI 集成到 SAS 中的挑战。该路线图首先概述了需要解决的关键研究挑战，以挖掘 GenAI 在 SAS 领域应用的潜力。该路线图最后进行了实际反思，详细阐述了 GenAI 当前的缺点并提出了可能的缓解策略。
> **Abstract**: Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.

## 社交和信息网络(cs.SI:Social and Information Networks)

【1】When GenAI Meets Fake News: Understanding Image Cascade Dynamics on Reddit
- **标题**: 当 GenAI 遇到假新闻：了解 Reddit 上的图像级联动态
- **链接**: https://arxiv.org/abs/2512.04639
> **作者**: Saumya Chauhan,Mila Hong,Maria Vazhaeparambil
> **摘要**: 人工智能生成的内容和错误信息在社交网络上越来越普遍。虽然之前的研究主要考察文本错误信息，但很少有研究关注视觉内容在病毒式传播中的作用。在这项工作中，我们首次大规模分析了错误信息和人工智能生成的图像如何通过转发级联在五个意识形态不同的 Reddit 社区中传播。通过整合文本情感、视觉属性和传播指标（例如首次转发时间、社区覆盖范围），我们的框架可以准确预测即时后级病毒式传播（AUC=0.83）和长期级联级传播（AUC=0.998）。这些发现为调节在线合成和误导性视觉内容提供了重要的见解。
> **Abstract**: AI-generated content and misinformation are increasingly prevalent on social networks. While prior research primarily examined textual misinformation, fewer studies have focused on visual content's role in virality. In this work, we present the first large-scale analysis of how misinformation and AI-generated images propagate through repost cascades across five ideologically diverse Reddit communities. By integrating textual sentiment, visual attributes, and diffusion metrics (e.g., time-to-first repost, community reach), our framework accurately predicts both immediate post-level virality (AUC=0.83) and long-term cascade-level spread (AUC=0.998). These findings offer essential insights for moderating synthetic and misleading visual content online.

## 系统与控制(eess.SY:Systems and Control)

【1】Gauss-Newton accelerated MPPI Control
- **标题**: 高斯-牛顿加速 MPPI 控制
- **链接**: https://arxiv.org/abs/2512.04579
> **作者**: Hannes Homburger,Katrin Baumgärtner,Moritz Diehl,Johannes Reuter
> **摘要**: 模型预测路径积分（MPPI）控制是一种基于采样的优化方法，最近引起了人们的关注，特别是在机器人和强化学习社区中。 MPPI 作为 GPU 加速的随机搜索方法已被广泛应用于解决模型预测控制 (MPC) 公式中出现的确定性直接单次最优控制问题。 MPPI 提供了几个关键优势，包括灵活性、稳健性、易于实施和固有的并行性。然而，由于最优控制问题是通过蒙特卡洛采样解决的，因此在高维设置中其性能可能会恶化。为了解决这个限制，本文提出了一种增强的 MPPI 方法，该方法结合了雅可比重建技术和二阶广义高斯-牛顿方法。这种新颖的方法称为 \textit{Gauss-Newton 加速 MPPI}。数值结果表明，高斯-牛顿加速 MPPI 方法极大地提高了 MPPI 可扩展性和计算效率，同时保留了经典 MPPI 框架的主要优点，使其成为即使对于高维问题也是一种有前途的方法。
> **Abstract**: Model Predictive Path Integral (MPPI) control is a sampling-based optimization method that has recently attracted attention, particularly in the robotics and reinforcement learning communities. MPPI has been widely applied as a GPU-accelerated random search method to deterministic direct single-shooting optimal control problems arising in model predictive control (MPC) formulations. MPPI offers several key advantages, including flexibility, robustness, ease of implementation, and inherent parallelizability. However, its performance can deteriorate in high-dimensional settings since the optimal control problem is solved via Monte Carlo sampling. To address this limitation, this paper proposes an enhanced MPPI method that incorporates a Jacobian reconstruction technique and the second-order Generalized Gauss-Newton method. This novel approach is called \textit{Gauss-Newton accelerated MPPI}. The numerical results show that the Gauss-Newton accelerated MPPI approach substantially improves MPPI scalability and computational efficiency while preserving the key benefits of the classical MPPI framework, making it a promising approach even for high-dimensional problems.

## 优化与控制(math.OC:Optimization and Control)

【1】Neural Policy Composition from Free Energy Minimization
- **标题**: 自由能最小化的神经策略构成
- **链接**: https://arxiv.org/abs/2512.04745
> **作者**: Francesca Rossi,Veronica Centorrino,Francesco Bullo,Giovanni Russo
> **摘要**: 组合所获得的技能来计划和执行行为的能力是自然智力的标志。然而，尽管跨学科付出了巨大的努力，但对任务结构如何形成门控以及如何在神经回路中进行此类计算的原则性解释仍然难以捉摸。在这里，我们介绍 GateMod，一种可解释的理论基础计算模型，将门控的出现与底层决策任务以及神经电路架构联系起来。我们首先开发了 GateFrame，一个规范框架，将政策门控到自由能源的最小化。该框架将门控规则与任务联系起来，广泛适用于神经科学、认知和计算科学。然后我们推导出 GateFlow，一种基于连续时间能量的动力学，可证明收敛于 GateFrame 最优解。指数收敛和全局收敛源于收缩性属性，同时也产生鲁棒性和其他所需属性。最后，我们从GateFlow中推导出一个神经电路，GateNet。这是一个软竞争循环电路，其组件执行与已知的树突和神经处理基序一致的本地和上下文计算。我们在两种不同的环境中评估 GateMod：多智能体系统中的集体行为和多臂强盗中的人类决策。在所有设置中，GateMod 都提供可解释的门控机制解释，并定量匹配或优于已建立的模型。 GateMod 为神经策略门控、链接任务目标、动态计算和电路级机制提供了一个统一的框架。它提供了一个框架来理解超出当前解释的自然主体的门控，并为机器配备这种能力。
> **Abstract**: The ability to compose acquired skills to plan and execute behaviors is a hallmark of natural intelligence. Yet, despite remarkable cross-disciplinary efforts, a principled account of how task structure shapes gating and how such computations could be delivered in neural circuits, remains elusive. Here we introduce GateMod, an interpretable theoretically grounded computational model linking the emergence of gating to the underlying decision-making task, and to a neural circuit architecture. We first develop GateFrame, a normative framework casting policy gating into the minimization of the free energy. This framework, relating gating rules to task, applies broadly across neuroscience, cognitive and computational sciences. We then derive GateFlow, a continuous-time energy based dynamics that provably converges to GateFrame optimal solution. Convergence, exponential and global, follows from a contractivity property that also yields robustness and other desirable properties. Finally, we derive a neural circuit from GateFlow, GateNet. This is a soft-competitive recurrent circuit whose components perform local and contextual computations consistent with known dendritic and neural processing motifs. We evaluate GateMod across two different settings: collective behaviors in multi-agent systems and human decision-making in multi-armed bandits. In all settings, GateMod provides interpretable mechanistic explanations of gating and quantitatively matches or outperforms established models. GateMod offers a unifying framework for neural policy gating, linking task objectives, dynamical computation, and circuit-level mechanisms. It provides a framework to understand gating in natural agents beyond current explanations and to equip machines with this ability.

## 流体动力学(physics.flu-dyn:Fluid Dynamics)

【1】Towards an AI Fluid Scientist: LLM-Powered Scientific Discovery in Experimental Fluid Mechanics
- **标题**: 迈向人工智能流体科学家：法学硕士支持的实验流体力学科学发现
- **链接**: https://arxiv.org/abs/2512.04716
> **作者**: Haodong Feng,Lugang Ye,Dixia Fan
> **摘要**: 将人工智能融入实验流体力学有望加速发现，但大多数人工智能应用仍然狭隘地集中在数值研究上。这项工作提出了一个人工智能流体科学家框架，可以自主执行完整的实验工作流程：假设生成、实验设计、机器人执行、数据分析和手稿准备。我们通过研究串联气缸中的涡激振动 (VIV) 和尾流诱发振动 (WIV) 来验证这一点。我们的工作有四个关键贡献：（1）计算机控制的循环水隧道（CWT），通过数据采集（位移、力和扭矩）对流速、气缸位置和受力参数（振动频率和振幅）进行编程控制。 (2) 自动化实验再现了文献基准（Khalak 和 Williamson [1999] 以及 Assi 等人 [2013, 2010]），频率锁定在 4% 以内并匹配临界间距趋势。 （3）人机环路（HIL）框架发现了更多WIV幅度响应现象，并利用神经网络从数据中拟合物理定律，比多项式拟合高31%。 （4）虚实交互系统的多智能体框架，端到端执行数百个实验，自动完成从假设生成、实验设计、实验执行、数据分析、稿件准备的科学研究全过程。它极大地解放了人类研究人员，提高了研究效率，为实验流体力学的发展和研究提供了新的范式。
> **Abstract**: The integration of artificial intelligence into experimental fluid mechanics promises to accelerate discovery, yet most AI applications remain narrowly focused on numerical studies. This work proposes an AI Fluid Scientist framework that autonomously executes the complete experimental workflow: hypothesis generation, experimental design, robotic execution, data analysis, and manuscript preparation. We validate this through investigation of vortex-induced vibration (VIV) and wake-induced vibration (WIV) in tandem cylinders. Our work has four key contributions: (1) A computer-controlled circulating water tunnel (CWT) with programmatic control of flow velocity, cylinder position, and forcing parameters (vibration frequency and amplitude) with data acquisition (displacement, force, and torque). (2) Automated experiments reproduce literature benchmarks (Khalak and Williamson [1999] and Assi et al. [2013, 2010]) with frequency lock-in within 4% and matching critical spacing trends. (3) The framework with Human-in-the-Loop (HIL) discovers more WIV amplitude response phenomena, and uses a neural network to fit physical laws from data, which is 31% higher than that of polynomial fitting. (4) The framework with multi-agent with virtual-real interaction system executes hundreds of experiments end-to-end, which automatically completes the entire process of scientific research from hypothesis generation, experimental design, experimental execution, data analysis, and manuscript preparation. It greatly liberates human researchers and improves study efficiency, providing new paradigm for the development and research of experimental fluid mechanics.

## 地球物理学(physics.geo-ph:Geophysics)

【1】UnwrapDiff: Conditional Diffusion for Robust InSAR Phase Unwrapping
- **标题**: UnwrapDiff：用于稳健 InSAR 相位展开的条件扩散
- **链接**: https://arxiv.org/abs/2512.04749
> **作者**: Yijia Song,Juliet Biggs,Alin Achim,Robert Popescu,Simon Orrego,Nantheera Anantrasirichai
> **摘要**: 相位展开是 InSAR 数据处理中的一个基本问题，支持变形监测和灾害评估等地球物理应用。其可靠性受到雷达采集中的噪声和去相关性的限制，这使得变形信号的精确重建具有挑战性。我们提出了一种基于去噪扩散概率模型 (DDPM) 的 InSAR 相位展开框架 UnwrapDiff，其中传统最小成本流算法 (SNAPHU) 的输出被纳入作为条件指导。为了评估鲁棒性，我们构建了一个综合数据集，其中包含大气影响和不同的噪声模式，代表现实的 InSAR 观测结果。实验表明，所提出的模型利用了条件先验，同时减少了不同噪声模式的影响，与 SNAPHU 相比，NRMSE 平均降低了 10.11%。在堤坝入侵等困难情况下，它还能实现更好的重建质量。
> **Abstract**: Phase unwrapping is a fundamental problem in InSAR data processing, supporting geophysical applications such as deformation monitoring and hazard assessment. Its reliability is limited by noise and decorrelation in radar acquisitions, which makes accurate reconstruction of the deformation signal challenging. We propose a denoising diffusion probabilistic model (DDPM)-based framework for InSAR phase unwrapping, UnwrapDiff, in which the output of the traditional minimum cost flow algorithm (SNAPHU) is incorporated as conditional guidance. To evaluate robustness, we construct a synthetic dataset that incorporates atmospheric effects and diverse noise patterns, representative of realistic InSAR observations. Experiments show that the proposed model leverages the conditional prior while reducing the effect of diverse noise patterns, achieving on average a 10.11\% reduction in NRMSE compared to SNAPHU. It also achieves better reconstruction quality in difficult cases such as dyke intrusions.

## 神经元和认知(q-bio.NC:Neurons and Cognition)

【1】Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors
- **标题**: 为失败做好准备：自动发现认知错误的神经机制
- **链接**: https://arxiv.org/abs/2512.04808
> **作者**: Puria Radmard,Paul M. Bays,Máté Lengyel
> **摘要**: 发现支撑认知的神经机制是神经科学的重大挑战之一。然而，之前构建解释行为的 RNN 动力学模型的方法需要对架构和/或优化目标进行迭代细化，从而导致零散且大多是启发式的人机交互过程。在这里，我们提供了一种替代方法，通过显式训练 RNN 来重现行为（包括人类和动物在认知任务中产生的相同特征错误和次优），自动发现可行的 RNN 机制。实现这一目标需要两项主要创新。首先，由于实验中可以收集的行为数据量通常过于有限，无法训练 RNN，因此我们使用行为响应的非参数生成模型来生成用于训练 RNN 的替代数据。其次，为了捕获数据的所有相关统计方面，我们开发了一种新颖的基于扩散模型的方法来训练 RNN。为了展示我们方法的潜力，我们选择了视觉工作记忆任务作为我们的测试平台，因为众所周知，该任务中的行为会产生明显多模态的响应分布（由于交换错误）。由此产生的网络动力学正确地定性了猕猴神经数据的特征。重要的是，使用更传统的方法不可能获得这些结果，即当仅拟合有限的行为特征集（而不是行为响应分布的全部丰富性）时，或者当 RNN 接受任务最优性训练时（而不是再现行为）。我们的方法还产生了关于交换错误机制的新颖预测，可以很容易地在实验中进行测试。这些结果表明，使 RNN 适应丰富的行为模式提供了一种自动发现重要认知功能机制的强大方法。
> **Abstract**: Discovering the neural mechanisms underpinning cognition is one of the grand challenges of neuroscience. However, previous approaches for building models of RNN dynamics that explain behaviour required iterative refinement of architectures and/or optimisation objectives, resulting in a piecemeal, and mostly heuristic, human-in-the-loop process. Here, we offer an alternative approach that automates the discovery of viable RNN mechanisms by explicitly training RNNs to reproduce behaviour, including the same characteristic errors and suboptimalities, that humans and animals produce in a cognitive task. Achieving this required two main innovations. First, as the amount of behavioural data that can be collected in experiments is often too limited to train RNNs, we use a non-parametric generative model of behavioural responses to produce surrogate data for training RNNs. Second, to capture all relevant statistical aspects of the data, we developed a novel diffusion model-based approach for training RNNs. To showcase the potential of our approach, we chose a visual working memory task as our test-bed, as behaviour in this task is well known to produce response distributions that are patently multimodal (due to swap errors). The resulting network dynamics correctly qualitative features of macaque neural data. Importantly, these results were not possible to obtain with more traditional approaches, i.e., when only a limited set of behavioural signatures (rather than the full richness of behavioural response distributions) were fitted, or when RNNs were trained for task optimality (instead of reproducing behaviour). Our approach also yields novel predictions about the mechanism of swap errors, which can be readily tested in experiments. These results suggest that fitting RNNs to rich patterns of behaviour provides a powerful way to automatically discover mechanisms of important cognitive functions.

## 量子物理学(quant-ph:Quantum Physics)

【1】Meta-Learning for Quantum Optimization via Quantum Sequence Model
- **标题**: 通过量子序列模型进行量子优化的元学习
- **链接**: https://arxiv.org/abs/2512.05058
> **作者**: Yu-Cheng Lin,Yu-Chao Hsu,Samuel Yen-Chi Chen
> **摘要**: 量子近似优化算法 (QAOA) 是解决近期量子处理器上组合优化问题的领先方法。然而，由于非凸能量景观，找到良好的变分参数仍然是一个重大挑战，通常会导致收敛速度慢和解质量差。在这项工作中，我们提出了一种量子元学习框架，该框架可以训练高级量子序列模型以生成有效的参数初始化策略。我们研究了四种经典或量子序列模型，包括基于量子内核的长短期记忆（QK-LSTM），作为“学习学习”范式中的学习优化器。我们对 Max-Cut 问题的数值实验表明，QK-LSTM 优化器实现了卓越的性能，获得了最高的逼近率，并在所有测试的问题规模（n=10 到 13）中表现出最快的收敛速度。至关重要的是，QK-LSTM 模型通过合成一组固定的接近最优的参数来实现完美的参数可传递性，即使在推广到更大的问题时也能显着持续加速收敛。这种能力是由量子内核架构的紧凑性和表现力实现的，强调了其有效性。 QK-LSTM 仅具有 43 个可训练参数，大大优于经典 LSTM（56 个参数）和其他量子序列模型，为 NISQ 时代变分量子算法的高效参数初始化建立了一条稳健的途径。
> **Abstract**: The Quantum Approximate Optimization Algorithm (QAOA) is a leading approach for solving combinatorial optimization problems on near-term quantum processors. However, finding good variational parameters remains a significant challenge due to the non-convex energy landscape, often resulting in slow convergence and poor solution quality. In this work, we propose a quantum meta-learning framework that trains advanced quantum sequence models to generate effective parameter initialization policies. We investigate four classical or quantum sequence models, including the Quantum Kernel-based Long Short-Term Memory (QK-LSTM), as learned optimizers in a "learning to learn" paradigm. Our numerical experiments on the Max-Cut problem demonstrate that the QK-LSTM optimizer achieves superior performance, obtaining the highest approximation ratios and exhibiting the fastest convergence rate across all tested problem sizes (n=10 to 13). Crucially, the QK-LSTM model achieves perfect parameter transferability by synthesizing a single, fixed set of near-optimal parameters, leading to a remarkable sustained acceleration of convergence even when generalizing to larger problems. This capability, enabled by the compact and expressive power of the quantum kernel architecture, underscores its effectiveness. The QK-LSTM, with only 43 trainable parameters, substantially outperforms the classical LSTM (56 parameters) and other quantum sequence models, establishing a robust pathway toward highly efficient parameter initialization for variational quantum algorithms in the NISQ era.

【2】QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory
- **标题**: QKAN-LSTM：量子启发的柯尔莫哥洛夫-阿诺德长短期记忆
- **链接**: https://arxiv.org/abs/2512.05049
> **作者**: Yu-Chao Hsu,Jiun-Cheng Jiang,Chun-Hua Lin,Kuo-Chung Peng,Nan-Yow Chen,Samuel Yen-Chi Chen,En-Jui Kuo,Hsi-Sheng Goan
> **摘要**: 长短期记忆 (LSTM) 模型是一种特殊类型的循环神经网络 (RNN)，对于城市电信预测等领域的顺序建模任务至关重要，其中时间相关性和非线性依赖性占主导地位。然而，传统的 LSTM 存在参数冗余度高和非线性表达能力有限的问题。在这项工作中，我们提出了受量子启发的柯尔莫哥洛夫-阿诺德长短期记忆（QKAN-LSTM），它将数据重新上传激活（DARUAN）模块集成到 LSTM 的门结构中。每个 DARUAN 都充当量子变分激活函数 (QVAF)，增强频率适应性并实现指数丰富的光谱表示，而无需多量子位纠缠。由此产生的架构保留了量子级的表现力，同时在经典硬件上保持完全可执行。对阻尼简单简谐运动、贝塞尔函数和城市电信这三个数据集的实证评估表明，与经典 LSTM 相比，QKAN-LSTM 实现了卓越的预测准确性和泛化性，可训练参数减少了 79%。我们将该框架扩展到Jiang-Huang-Chen-Goan网络（JHCG Net），它将KAN推广到编码器-解码器结构，然后进一步使用QKAN来实现潜在KAN，从而创建用于分层表示学习的混合QKAN（HQKAN）。因此，所提出的 HQKAN-LSTM 为现实世界数据环境中的量子启发顺序建模提供了一条可扩展且可解释的途径。
> **Abstract**: Long short-term memory (LSTM) models are a particular type of recurrent neural networks (RNNs) that are central to sequential modeling tasks in domains such as urban telecommunication forecasting, where temporal correlations and nonlinear dependencies dominate. However, conventional LSTMs suffer from high parameter redundancy and limited nonlinear expressivity. In this work, we propose the Quantum-inspired Kolmogorov-Arnold Long Short-Term Memory (QKAN-LSTM), which integrates Data Re-Uploading Activation (DARUAN) modules into the gating structure of LSTMs. Each DARUAN acts as a quantum variational activation function (QVAF), enhancing frequency adaptability and enabling an exponentially enriched spectral representation without multi-qubit entanglement. The resulting architecture preserves quantum-level expressivity while remaining fully executable on classical hardware. Empirical evaluations on three datasets, Damped Simple Harmonic Motion, Bessel Function, and Urban Telecommunication, demonstrate that QKAN-LSTM achieves superior predictive accuracy and generalization with a 79% reduction in trainable parameters compared to classical LSTMs. We extend the framework to the Jiang-Huang-Chen-Goan Network (JHCG Net), which generalizes KAN to encoder-decoder structures, and then further use QKAN to realize the latent KAN, thereby creating a Hybrid QKAN (HQKAN) for hierarchical representation learning. The proposed HQKAN-LSTM thus provides a scalable and interpretable pathway toward quantum-inspired sequential modeling in real-world data environments.

【3】Quantum-Inspired Optimization through Qudit-Based Imaginary Time Evolution
- **标题**: 通过基于 Qudit 的虚时间演化进行量子启发优化
- **链接**: https://arxiv.org/abs/2512.04710
> **作者**: Erik M. Åsgrim,Ahsan Javed Awan
> **摘要**: 虚时间演化已被证明是解决量子硬件上组合优化问题的一个有前途的框架。在这项工作中，我们提出了一种经典的量子启发策略，通过将决策变量编码为称为 qudits 的多级量子态来解决具有整数值决策变量的组合优化问题。与二元公式相比，该方法减少了决策变量的数量，同时本质上合并了单关联约束。通过在整个优化过程中限制系统保持在产品状态，可以实现高效的经典模拟。 qdit 状态通过应用一系列酉算子来优化，这些算子迭代地近似虚时间演化的动态。与之前的研究不同，我们提出了一种基于梯度的方法，自适应地选择用于在每个优化步骤生成状态演化的埃尔米特算子，作为提高算法收敛性能的方法。所提出的算法在带有约束的 Min-d-Cut 问题上展示了有希望的结果，在惩罚约束公式上优于 Gurobi，特别是对于较大的 d 值。
> **Abstract**: Imaginary-time evolution has been shown to be a promising framework for tackling combinatorial optimization problems on quantum hardware. In this work, we propose a classical quantum-inspired strategy for solving combinatorial optimization problems with integer-valued decision variables by encoding decision variables into multi-level quantum states known as qudits. This method results in a reduced number of decision variables compared to binary formulations while inherently incorporating single-association constraints. Efficient classical simulation is enabled by constraining the system to remain in a product state throughout optimization. The qudit states are optimized by applying a sequence of unitary operators that iteratively approximate the dynamics of imaginary time evolution. Unlike previous studies, we propose a gradient-based method of adaptively choosing the Hermitian operators used to generate the state evolution at each optimization step, as a means to improve the convergence properties of the algorithm. The proposed algorithm demonstrates promising results on Min-d-Cut problem with constraints, outperforming Gurobi on penalized constraint formulation, particularly for larger values of d.

## 方法论(stat.ME:Methodology)

【1】Model-Free Assessment of Simulator Fidelity via Quantile Curves
- **标题**: 通过分位数曲线对模拟器保真度进行无模型评估
- **链接**: https://arxiv.org/abs/2512.05024
> **作者**: Garud Iyengar,Yu-Shiou Willy Lin,Kaizheng Wang
> **摘要**: 复杂系统的仿真起源于制造和排队应用。它现在广泛用于研究、教育和消费者调查中基于机器学习的大规模系统。然而，对于日益复杂的基于机器学习的系统来说，描述模拟器和地面真实情况之间的差异仍然具有挑战性。我们提出了一种计算上易于处理的方法来估计模拟结果分布和真实结果分布之间差异的分位数函数。我们的方法侧重于输出不确定性，并将模拟器视为黑匣子，对其内部不施加任何建模假设，因此广泛适用于许多参数系列，从伯努利和多项模型到连续向量值设置。生成的分位数曲线支持未见过的场景的置信区间构建、模拟与真实差异的风险意识摘要（例如 VaR/CVaR）以及模拟器性能的比较。我们在一个应用程序中展示了我们的方法，该应用程序评估了涵盖四个法学硕士的 WorldValueBench 数据集上的法学硕士模拟保真度。
> **Abstract**: Simulation of complex systems originated in manufacturing and queuing applications. It is now widely used for large-scale, ML-based systems in research, education, and consumer surveys. However, characterizing the discrepancy between simulators and ground truth remains challenging for increasingly complex, machine-learning-based systems. We propose a computationally tractable method to estimate the quantile function of the discrepancy between the simulated and ground-truth outcome distributions. Our approach focuses on output uncertainty and treats the simulator as a black box, imposing no modeling assumptions on its internals, and hence applies broadly across many parameter families, from Bernoulli and multinomial models to continuous, vector-valued settings. The resulting quantile curve supports confidence interval construction for unseen scenarios, risk-aware summaries of sim-to-real discrepancy (e.g., VaR/CVaR), and comparison of simulators' performance. We demonstrate our methodology in an application assessing LLM simulation fidelity on the WorldValueBench dataset spanning four LLMs.

