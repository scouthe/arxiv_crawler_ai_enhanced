{"id": "2602.03491", "pdf": "https://arxiv.org/pdf/2602.03491", "abs": "https://arxiv.org/abs/2602.03491", "authors": ["Yingjie Zhu", "Xuefeng Bai", "Kehai Chen", "Yang Xiang", "Youcheng Pan", "Xiaoqiang Zhou", "Min Zhang"], "title": "Decoupling Skeleton and Flesh: Efficient Multimodal Table Reasoning with Disentangled Alignment and Structure-aware Guidance", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Reasoning over table images remains challenging for Large Vision-Language Models (LVLMs) due to complex layouts and tightly coupled structure-content information. Existing solutions often depend on expensive supervised training, reinforcement learning, or external tools, limiting efficiency and scalability. This work addresses a key question: how to adapt LVLMs to table reasoning with minimal annotation and no external tools? Specifically, we first introduce DiSCo, a Disentangled Structure-Content alignment framework that explicitly separates structural abstraction from semantic grounding during multimodal alignment, efficiently adapting LVLMs to tables structures. Building on DiSCo, we further present Table-GLS, a Global-to-Local Structure-guided reasoning framework that performs table reasoning via structured exploration and evidence-grounded inference. Extensive experiments across diverse benchmarks demonstrate that our framework efficiently enhances LVLM's table understanding and reasoning capabilities, particularly generalizing to unseen table structures.", "AI": {"tldr": "本文提出了一种新的框架，通过分离结构和内容的对齐方式以及基于结构的引导推理方法，使大视觉-语言模型能够更有效地处理表格数据。", "motivation": "现有的解决方案需要大量的监督训练、强化学习或外部工具来解决LVLM在处理表格图像时面临的挑战。本文旨在使用最少的标注信息且不依赖于外部工具的情况下，提高LVLM的表格理解和推理能力。", "method": "首先介绍了DiSCo框架，用于分离结构和内容的对齐；然后提出了Table-GLS框架，通过全局到局部的结构引导进行表格推理。", "result": "实验结果表明，所提出的框架能够有效提升LVLM在处理表格数据时的理解与推理性能，并且能推广至未见过的表格结构。", "conclusion": "本文提出的方法能够在不依赖于大量标注或外部工具的情况下，显著提高LVLM对表格信息的理解和推理能力。"}}
{"id": "2602.03486", "pdf": "https://arxiv.org/pdf/2602.03486", "abs": "https://arxiv.org/abs/2602.03486", "authors": ["Elena Umili", "Francesco Argenziano", "Roberto Capobianco"], "title": "DeepDFA: Injecting Temporal Logic in Deep Learning for Sequential Subsymbolic Applications", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Integrating logical knowledge into deep neural network training is still a hard challenge, especially for sequential or temporally extended domains involving subsymbolic observations. To address this problem, we propose DeepDFA, a neurosymbolic framework that integrates high-level temporal logic - expressed as Deterministic Finite Automata (DFA) or Moore Machines - into neural architectures. DeepDFA models temporal rules as continuous, differentiable layers, enabling symbolic knowledge injection into subsymbolic domains. We demonstrate how DeepDFA can be used in two key settings: (i) static image sequence classification, and (ii) policy learning in interactive non-Markovian environments. Across extensive experiments, DeepDFA outperforms traditional deep learning models (e.g., LSTMs, GRUs, Transformers) and novel neuro-symbolic systems, achieving state-of-the-art results in temporal knowledge integration. These results highlight the potential of DeepDFA to bridge subsymbolic learning and symbolic reasoning in sequential tasks.", "AI": {"tldr": "本文提出了DeepDFA框架，将高阶时间逻辑融入深度学习模型中，以解决在序列或时序领域内符号知识注入的难题。", "motivation": "当前挑战在于如何将高级别的时间逻辑知识集成到深度神经网络训练中，特别是在涉及子符号观察的顺序或延伸时域场景下。本文旨在通过引入DeepDFA框架来应对这一问题。", "method": "DeepDFA框架将时间规则模型化为连续可微层，并利用确定性有限自动机（DFA）或莫尔机器的形式表示高级别的时间逻辑知识，从而实现了符号知识向子符号领域的注入。", "result": "在广泛实验中，DeepDFA超越了传统深度学习模型如LSTM、GRU和Transformer以及其他新型神经符号系统，在时间知识集成方面取得了最先进的成果。", "conclusion": "本文展示的DeepDFA框架为解决序贯任务中的子符号学习与符号推理结合问题提供了新的视角。"}}
{"id": "2602.03485", "pdf": "https://arxiv.org/pdf/2602.03485", "abs": "https://arxiv.org/abs/2602.03485", "authors": ["Quanyu Long", "Kai Jie Jiang", "Jianda Chen", "Xu Guo", "Leilei Gan", "Wenya Wang"], "title": "Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "19 pages, 8 figures", "summary": "Large Reasoning Models (LRMs) achieve strong performance by generating long reasoning traces with reflection. Through a large-scale empirical analysis, we find that a substantial fraction of reflective steps consist of self-verification (recheck) that repeatedly confirm intermediate results. These rechecks occur frequently across models and benchmarks, yet the vast majority are confirmatory rather than corrective, rarely identifying errors and altering reasoning outcomes. This reveals a mismatch between how often self-verification is activated and how often it is actually useful. Motivated by this, we propose a novel, experience-driven test-time framework that reduces the overused verification. Our method detects the activation of recheck behavior, consults an offline experience pool of past verification outcomes, and estimates whether a recheck is likely unnecessary via efficient retrieval. When historical experience suggests unnecessary, a suppression signal redirects the model to proceed. Across multiple model and benchmarks, our approach reduces token usage up to 20.3% while maintaining the accuracy, and in some datasets even yields accuracy improvements.", "AI": {"tldr": "论文提出了一个经验驱动的验证抑制框架，以减少大推理模型在推理过程中过度使用的自我验证步骤。", "motivation": "大型推理模型通过生成带有反思的长推理链来提高性能。然而，大量重复确认中间结果的行为并没有带来实际改进，反而浪费了计算资源。因此提出了一种基于经验的方法来抑制不必要的再检查。", "method": "论文采用了一个测试时框架，该框架检测到再验证行为后，会参考一个离线的经验数据库，并通过高效检索判断当前的再验证是否必要。如果历史数据显示无用，则向模型发送继续信号。", "result": "实验结果表明，在多个模型和数据集上，这种方法可以减少高达20.3%的计算资源使用量并保持甚至提高准确性。", "conclusion": "通过抑制不必要的自我验证步骤，可以在不降低准确性的前提下显著节约计算资源。"}}
{"id": "2602.03478", "pdf": "https://arxiv.org/pdf/2602.03478", "abs": "https://arxiv.org/abs/2602.03478", "authors": ["Guannan Lai", "Han-Jia Ye"], "title": "When Routing Collapses: On the Degenerate Convergence of LLM Routers", "categories": ["cs.AI"], "comment": null, "summary": "LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user's cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.", "AI": {"tldr": "提出了EquiRouter来解决LLM路由中出现的'路由崩溃'问题，旨在优化成本和性能之间的平衡。", "motivation": "现有路由器在用户预算增加时会过度依赖最强大的模型，导致较小模型利用率低下，浪费计算资源。", "method": "提出了一种决策感知路由器（EquiRouter），其直接学习模型排名而不是预测标量性能分数，以解决客观与决策不匹配的问题。", "result": "在RouterBench上，EquiRouter相比最强的先前路由器，在达到GPT-4级性能时可节省约17%的成本。", "conclusion": "通过直接优化模型排名而非单个性能指标来提高资源利用效率和降低成本是一种有效的方法。"}}
{"id": "2602.03477", "pdf": "https://arxiv.org/pdf/2602.03477", "abs": "https://arxiv.org/abs/2602.03477", "authors": ["Mingxuan Wang", "Cheng Chen", "Gaoyang Jiang", "Zijia Ren", "Chuangxin Zhao", "Lu Shi", "Yanbiao Ma"], "title": "ScDiVa: Masked Discrete Diffusion for Joint Modeling of Single-Cell Identity and Expression", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "19 pages, 11 figures", "summary": "Single-cell RNA-seq profiles are high-dimensional, sparse, and unordered, causing autoregressive generation to impose an artificial ordering bias and suffer from error accumulation. To address this, we propose scDiVa, a masked discrete diffusion foundation model that aligns generation with the dropout-like corruption process by defining a continuous-time forward masking mechanism in token space. ScDiVa features a bidirectional denoiser that jointly models discrete gene identities and continuous values, utilizing entropy-normalized serialization and a latent anchor token to maximize information efficiency and preserve global cell identity. The model is trained via depth-invariant time sampling and a dual denoising objective to simulate varying sparsity levels while ensuring precise recovery of both identity and magnitude. Pre-trained on 59 million cells, scDiVa achieves strong transfer performance across major benchmarks, including batch integration, cell type annotation, and perturbation response prediction. These results suggest that masked discrete diffusion serves as a biologically coherent and effective alternative to autoregression.", "AI": {"tldr": "提出了一种新的单细胞RNA测序数据分析方法scDiVa，用于生成高质量的单细胞转录组数据。", "motivation": "传统的自回归生成模型在处理高维、稀疏和无序的数据时会引入排序偏见并累积错误。为解决这些问题，开发了scDiVa来更好地模拟真实生物过程中的降解模式。", "method": "scDiVa通过定义连续时间的正向掩码机制，在代币空间中模拟类似数据丢失的过程，并使用双向去噪器联合建模离散基因身份和连续值。", "result": "在批量整合、细胞类型注释以及扰动响应预测等关键基准测试上，scDiVa展现了强大的迁移性能。", "conclusion": "证明了掩蔽式离散扩散作为自回归方法的替代品，在生物学一致性和有效性方面具有优势。"}}
{"id": "2602.03476", "pdf": "https://arxiv.org/pdf/2602.03476", "abs": "https://arxiv.org/abs/2602.03476", "authors": ["Yihao Dong", "Praneeth Bimsara Perera", "Chin-Teng Lin", "Craig T Jin", "Anusha Withana"], "title": "TactDeform: Finger Pad Deformation Inspired Spatial Tactile Feedback for Virtual Geometry Exploration", "categories": ["cs.HC"], "comment": "Accepted to CHI 2026. Version of Record: DOI https://doi.org/10.1145/3772318.3791699", "summary": "Spatial tactile feedback can enhance the realism of geometry exploration in virtual reality applications. Current vibrotactile approaches often face challenges with the spatial and temporal resolution needed to render different 3D geometries. Inspired by the natural deformation of finger pads when exploring 3D objects and surfaces, we propose TactDeform, a parametric approach to render spatio-temporal tactile patterns using a finger-worn electro-tactile interface. The system dynamically renders electro-tactile patterns based on both interaction contexts (approaching, contact, and sliding) and geometric contexts (geometric features and textures), emulating deformations that occur during real-world touch exploration. Results from a user study \\rr{(N=24)} show that the proposed approach enabled high texture discrimination and geometric feature identification compared to a baseline. Informed by results from a free 3D-geometry exploration phase, we provide insights that can inform future tactile interface designs.", "AI": {"tldr": "提出了TactDeform系统，使用手指穿戴式电触觉界面模仿真实世界触摸探索中的变形，以增强虚拟现实应用中几何体探索的逼真度。", "motivation": "现有的振动反馈方法难以提供足够的空间和时间分辨率来渲染不同的3D几何图形。受自然条件下指垫在接触3D物体时发生的形变启发，提出了TactDeform系统。", "method": "通过手指穿戴式电触觉界面动态生成基于交互场景（接近、接触、滑动）和几何特性（特征与纹理）的时空触觉模式，模仿真实触摸探索中的变形。", "result": "实验结果表明，所提出的方案在纹理区分度及几何特征识别方面优于基线方法。", "conclusion": "TactDeform系统能够增强虚拟现实应用中3D几何体探索的真实感，并为未来电触觉界面设计提供了见解。"}}
{"id": "2602.03473", "pdf": "https://arxiv.org/pdf/2602.03473", "abs": "https://arxiv.org/abs/2602.03473", "authors": ["Meng Lou", "Yunxiang Fu", "Yizhou Yu"], "title": "Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Continual learning, especially class-incremental learning (CIL), on the basis of a pre-trained model (PTM) has garnered substantial research interest in recent years. However, how to effectively learn both discriminative and comprehensive feature representations while maintaining stability and plasticity over very long task sequences remains an open problem. We propose CaRE, a scalable {C}ontinual Le{a}rner with efficient Bi-Level {R}outing Mixture-of-{E}xperts (BR-MoE). The core idea of BR-MoE is a bi-level routing mechanism: a router selection stage that dynamically activates relevant task-specific routers, followed by an expert routing phase that dynamically activates and aggregates experts, aiming to inject discriminative and comprehensive representations into every intermediate network layer. On the other hand, we introduce a challenging evaluation protocol for comprehensively assessing CIL methods across very long task sequences spanning hundreds of tasks. Extensive experiments show that CaRE demonstrates leading performance across a variety of datasets and task settings, including commonly used CIL datasets with classical CIL settings (e.g., 5-20 tasks). To the best of our knowledge, CaRE is the first continual learner that scales to very long task sequences (ranging from 100 to over 300 non-overlapping tasks), while outperforming all baselines by a large margin on such task sequences. Code will be publicly released at https://github.com/LMMMEng/CaRE.git.", "AI": {"tldr": "本文提出了一种可扩展的连续学习模型CaRE，通过双层路由机制实现高效的特征表示，并在长时间任务序列上表现出色。", "motivation": "如何在基于预训练模型的基础上有效进行类增量连续学习（CIL），同时保持稳定性和适应性，在非常长的任务序列中仍然是一个挑战。为此提出了一种新的方法CaRE来解决这个问题。", "method": "本文提出了CaRE，通过双层路由机制实现高效的特征表示：首先选择相关的任务特定路由器，然后动态激活和聚合专家以注入区分性和综合性的表示到每个中间网络层。", "result": "实验结果表明，CaRE在不同数据集和任务设置下表现优异，在非常长的任务序列上（从100多个到300多个不重叠任务）显著优于所有基线方法。", "conclusion": "CaRE是第一个能够扩展到非常长时间任务序列的连续学习者，并且在这些时间序列上的性能遥遥领先。"}}
{"id": "2602.03472", "pdf": "https://arxiv.org/pdf/2602.03472", "abs": "https://arxiv.org/abs/2602.03472", "authors": ["Minsu Kim", "Dongyeun Lee", "Jaemyung Yu", "Jiwan Hur", "Giseop Kim", "Junmo Kim"], "title": "Inlier-Centric Post-Training Quantization for Object Detection Models", "categories": ["cs.CV"], "comment": null, "summary": "Object detection is pivotal in computer vision, yet its immense computational demands make deployment slow and power-hungry, motivating quantization. However, task-irrelevant morphologies such as background clutter and sensor noise induce redundant activations (or anomalies). These anomalies expand activation ranges and skew activation distributions toward task-irrelevant responses, complicating bit allocation and weakening the preservation of informative features. Without a clear criterion to distinguish anomalies, suppressing them can inadvertently discard useful information. To address this, we present InlierQ, an inlier-centric post-training quantization approach that separates anomalies from informative inliers. InlierQ computes gradient-aware volume saliency scores, classifies each volume as an inlier or anomaly, and fits a posterior distribution over these scores using the Expectation-Maximization (EM) algorithm. This design suppresses anomalies while preserving informative features. InlierQ is label-free, drop-in, and requires only 64 calibration samples. Experiments on the COCO and nuScenes benchmarks show consistent reductions in quantization error for camera-based (2D and 3D) and LiDAR-based (3D) object detection.", "AI": {"tldr": "该论文提出了InlierQ，一种针对目标检测模型的后训练量化方法，旨在通过区分异常和有用信息来优化量化过程。", "motivation": "由于背景杂乱和传感器噪声等任务无关形态会导致冗余激活，从而增加激活范围并使分布偏向于无用响应，这使得量化变得复杂且难以保留有用的特征。为了解决这个问题，引入了InlierQ方法。", "method": "InlierQ通过计算基于梯度的体显著性得分来区分异常和有用信息，并使用EM算法拟合后验概率分布以分离出异常。", "result": "在COCO和nuScenes数据集上的实验结果表明，InlierQ能够有效减少量化误差，适用于相机（2D和3D）和LiDAR（3D）目标检测模型。", "conclusion": "该方法通过抑制异常同时保留有用信息来优化量化过程，并且是无标签、即插即用的，仅需64个校准样本即可实现。"}}
{"id": "2602.03470", "pdf": "https://arxiv.org/pdf/2602.03470", "abs": "https://arxiv.org/abs/2602.03470", "authors": ["Nicolás E. Díaz Ferreyra", "Moritz Mock", "Max Kretschmann", "Barbara Russo", "Mojtaba Shahin", "Mansooreh Zahedi", "Riccardo Scandariato"], "title": "Reading Between the Code Lines: On the Use of Self-Admitted Technical Debt for Security Analysis", "categories": ["cs.CR", "cs.HC", "cs.SE"], "comment": "Preprint submitted to Journal of Systems and Software", "summary": "Static Analysis Tools (SATs) are central to security engineering activities, as they enable early identification of code weaknesses without requiring execution. However, their effectiveness is often limited by high false-positive rates and incomplete coverage of vulnerability classes. At the same time, developers frequently document security-related shortcuts and compromises as Self-Admitted Technical Debt (SATD) in software artifacts, such as code comments. While prior work has recognized SATD as a rich source of security information, it remains unclear whether -and in what ways- it is utilized during SAT-aided security analysis. OBJECTIVE: This work investigates the extent to which security-related SATD complements the output produced by SATs and helps bridge some of their well-known limitations. METHOD: We followed a mixed-methods approach consisting of (i) the analysis of a SATD-annotated vulnerability dataset using three state-of-the-art SATs and (ii) an online survey with 72 security practitioners. RESULTS: The combined use of all SATs flagged 114 of the 135 security-related SATD instances, spanning 24 distinct Common Weakness Enumeration (CWE) identifiers. A manual mapping of the SATD comments revealed 33 unique CWE types, 6 of which correspond to categories that SATs commonly overlook or struggle to detect (e.g., race conditions). Survey responses further suggest that developers frequently pair SAT outputs with SATD insights to better understand the impact and root causes of security weaknesses and to identify suitable fixes. IMPLICATIONS: Our findings show that such SATD-encoded information can be a meaningful complement to SAT-driven security analysis, while helping to overcome some of SATs' practical shortcomings.", "AI": {"tldr": "论文主要研究了自认技术债务（SATD）如何补充静态分析工具（SATs）在安全工程中的效果。", "motivation": "当前静态分析工具存在高误报率和不完全覆盖漏洞类别的问题，而开发人员常在代码注释中记录与安全性相关的妥协。因此研究它们是否可以互补以提高效率。", "method": "采用混合方法包括对带有SATD标记的漏洞数据集进行分析以及72名安全从业人员的在线调查。", "result": "结合使用所有SATs识别了135个与安全性相关的SATD实例中的114个，涵盖24种不同的常见弱项枚举（CWE）标识符。调查显示开发人员经常利用SAT输出和SATD洞察力来更好地理解安全弱点的影响和根本原因，并确定适当的修复。", "conclusion": "发现SATD编码信息可以作为SAT驱动的安全分析的重要补充，有助于克服一些实际困难。"}}
{"id": "2602.03468", "pdf": "https://arxiv.org/pdf/2602.03468", "abs": "https://arxiv.org/abs/2602.03468", "authors": ["Haohao Luo", "Zexi Li", "Yuexiang Xie", "Wenhao Zhang", "Yaliang Li", "Ying Shen"], "title": "IntentRL: Training Proactive User-intent Agents for Open-ended Deep Research via Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint", "summary": "Deep Research (DR) agents extend Large Language Models (LLMs) beyond parametric knowledge by autonomously retrieving and synthesizing evidence from large web corpora into long-form reports, enabling a long-horizon agentic paradigm. However, unlike real-time conversational assistants, DR is computationally expensive and time-consuming, creating an autonomy-interaction dilemma: high autonomy on ambiguous user queries often leads to prolonged execution with unsatisfactory outcomes. To address this, we propose IntentRL, a framework that trains proactive agents to clarify latent user intents before starting long-horizon research. To overcome the scarcity of open-ended research data, we introduce a scalable pipeline that expands a few seed samples into high-quality dialogue turns via a shallow-to-deep intent refinement graph. We further adopt a two-stage reinforcement learning (RL) strategy: Stage I applies RL on offline dialogues to efficiently learn general user-interaction behavior, while Stage II uses the trained agent and a user simulator for online rollouts to strengthen adaptation to diverse user feedback. Extensive experiments show that IntentRL significantly improves both intent hit rate and downstream task performance, outperforming the built-in clarify modules of closed-source DR agents and proactive LLM baselines.", "AI": {"tldr": "本文提出IntentRL框架，通过强化学习训练主动代理以在开始长时域研究前澄清潜在的用户意图。", "motivation": "解决深度研究中由于高自主性导致执行时间过长和结果不令人满意的问题，提高任务效率与准确性。", "method": "采用两阶段强化学习策略：第一阶段在离线对话上应用RL以高效地学习一般的用户交互行为；第二阶段使用训练好的代理及用户模拟器进行在线滚动以增强对多样用户反馈的适应性。", "result": "实验表明，IntentRL显著提高了意图命中率和下游任务性能，优于闭源深度研究代理内置澄清模块与主动LLM基准线。", "conclusion": "通过强化学习训练的主动代理能够更有效地处理复杂用户的意图请求，提高深度研究报告的质量和效率。"}}
{"id": "2602.03467", "pdf": "https://arxiv.org/pdf/2602.03467", "abs": "https://arxiv.org/abs/2602.03467", "authors": ["Zeynep G. Saribatur", "Johannes Langer", "Ute Schmid"], "title": "The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding", "categories": ["cs.AI", "cs.HC"], "comment": "8 pages, 5 figures", "summary": "Explanations are central to human cognition, yet AI systems often produce outputs that are difficult to understand. While symbolic AI offers a transparent foundation for interpretability, raw logical traces often impose a high extraneous cognitive load. We investigate how formal abstractions, specifically removal and clustering, impact human reasoning performance and cognitive effort. Utilizing Answer Set Programming (ASP) as a formal framework, we define a notion of irrelevant details to be abstracted over to obtain simplified explanations. Our cognitive experiments, in which participants classified stimuli across domains with explanations derived from an answer set program, show that clustering details significantly improve participants' understanding, while removal of details significantly reduce cognitive effort, supporting the hypothesis that abstraction enhances human-centered symbolic explanations.", "AI": {"tldr": "研究探索了形式化抽象在简化符号解释中的作用，以提高人类理解并减少认知负担。", "motivation": "AI系统生成的输出难以理解和解释，因此研究旨在通过去除无关细节和聚类来改善人类的认知表现和认知努力。", "method": "使用ASP作为正式框架定义无关细节的概念，并进行了认知实验，在不同领域中参与者根据从一个回答集程序派生出的解释对刺激进行分类。", "result": "实验结果表明，细节的聚类显著提高了参与者的理解能力，而细节的去除则显著减少了认知努力。", "conclusion": "研究支持了抽象化能够增强以人为中心的符号解释的观点。"}}
{"id": "2602.03454", "pdf": "https://arxiv.org/pdf/2602.03454", "abs": "https://arxiv.org/abs/2602.03454", "authors": ["Yeongtak Oh", "Sangwon Yu", "Junsung Park", "Han Cheol Moon", "Jisoo Mok", "Sungroh Yoon"], "title": "Contextualized Visual Personalization in Vision-Language Models", "categories": ["cs.CV"], "comment": "Project Page: https://github.com/oyt9306/CoViP", "summary": "Despite recent progress in vision-language models (VLMs), existing approaches often fail to generate personalized responses based on the user's specific experiences, as they lack the ability to associate visual inputs with a user's accumulated visual-textual context. We newly formalize this challenge as contextualized visual personalization, which requires the visual recognition and textual retrieval of personalized visual experiences by VLMs when interpreting new images. To address this issue, we propose CoViP, a unified framework that treats personalized image captioning as a core task for contextualized visual personalization and improves this capability through reinforcement-learning-based post-training and caption-augmented generation. We further introduce diagnostic evaluations that explicitly rule out textual shortcut solutions and verify whether VLMs truly leverage visual context. Extensive experiments demonstrate that existing open-source and proprietary VLMs exhibit substantial limitations, while CoViP not only improves personalized image captioning but also yields holistic gains across downstream personalization tasks. These results highlight CoViP as a crucial stage for enabling robust and generalizable contextualized visual personalization.", "AI": {"tldr": "本文提出了CoViP框架，用于处理基于用户特定经验的视觉个性化问题。", "motivation": "现有的视觉语言模型无法将视觉输入与用户的积累的视听文本上下文关联起来，从而生成个性化的响应。", "method": "通过引入统一的框架CoViP，作者采用强化学习后训练和增补生成的方法来改进个性化图像描述的能力。此外，还提出了诊断评估方法以排除文字捷径解决方案，并验证视觉语言模型是否真正利用了视觉上下文。", "result": "实验结果表明，现有的开源和专有视觉语言模型在处理个性化问题时存在显著限制，而CoViP不仅改善了个性化图像描述，还在下游的个性化任务上获得了全面的优势。", "conclusion": "CoViP为实现稳健且通用化的上下文视觉个性化提供了一个关键步骤。"}}
{"id": "2602.03452", "pdf": "https://arxiv.org/pdf/2602.03452", "abs": "https://arxiv.org/abs/2602.03452", "authors": ["Xin Sheng", "Jiaxin Li", "Yujuan Pang", "Ran Peng", "Yong Ma"], "title": "Beyond Variance: Prompt-Efficient RLVR via Rare-Event Amplification and Bidirectional Pairing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) is effective for training large language models on deterministic outcome reasoning tasks. Prior work shows RLVR works with few prompts, but prompt selection is often based only on training-accuracy variance, leading to unstable optimization directions and weaker transfer. We revisit prompt selection from a mechanism-level view and argue that an effective minibatch should provide both (i) a reliable positive anchor and (ii) explicit negative learning signals from rare failures. Based on this principle, we propose \\emph{positive--negative pairing}: at each update, we sample a hard-but-solvable $q^{+}$ and an easy-but-brittle prompt $q^{-}$(high success rate but not perfect), characterized by low and high empirical success rates under multiple rollouts. We further introduce Weighted GRPO, which reweights binary outcomes at the pair level and uses group-normalized advantages to amplify rare successes on $q^{+}$ into sharp positive guidance while turning rare failures on $q^{-}$ into strong negative penalties. This bidirectional signal provides informative learning feedback for both successes and failures, improving sample efficiency without suppressing exploration. On Qwen2.5-Math-7B, a single paired minibatch per update consistently outperforms a GRPO baseline that selects two prompts via commonly used variance-based selection heuristics: AIME~2025 Pass@8 improves from 16.8 to 22.2, and AMC23 Pass@64 from 94.0 to 97.0, while remaining competitive with large-scale RLVR trained from a pool of 1209 training prompts. Similar gains are observed on Qwen2.5-Math-7B-Instruct.", "AI": {"tldr": "本文提出了一种新的策略，通过正负样本配对和加权GRPO来提高基于强化学习的可验证奖励任务中的采样效率。", "motivation": "现有工作仅依赖训练准确度方差选择提示词，导致优化方向不稳且迁移效果较差。作者重新审视了提示词选择，并提出了新的机制以提供可靠的学习信号。", "method": "引入正负样本配对策略：每次更新时选取一个难但可解的正面样本和一个易但脆弱的负面样本；使用加权GRPO来强化稀有成功并惩罚稀有失败，从而提高学习效率。", "result": "在Qwen2.5-Math-7B模型上，单次配对小批量训练优于基于方差选择的方法，在AIME~2025 Pass@8和AMC23 Pass@64等指标上的表现均有显著提升。", "conclusion": "所提出的方法通过正负样本的双向信号强化了学习反馈，提高了采样效率，并保持了与大规模训练相当的竞争性。"}}
{"id": "2602.03448", "pdf": "https://arxiv.org/pdf/2602.03448", "abs": "https://arxiv.org/abs/2602.03448", "authors": ["Yijia Xu", "Zihao Wang", "Jinshi Cui"], "title": "Hierarchical Concept-to-Appearance Guidance for Multi-Subject Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multi-subject image generation aims to synthesize images that faithfully preserve the identities of multiple reference subjects while following textual instructions. However, existing methods often suffer from identity inconsistency and limited compositional control, as they rely on diffusion models to implicitly associate text prompts with reference images. In this work, we propose Hierarchical Concept-to-Appearance Guidance (CAG), a framework that provides explicit, structured supervision from high-level concepts to fine-grained appearances. At the conceptual level, we introduce a VAE dropout training strategy that randomly omits reference VAE features, encouraging the model to rely more on robust semantic signals from a Visual Language Model (VLM) and thereby promoting consistent concept-level generation in the absence of complete appearance cues. At the appearance level, we integrate the VLM-derived correspondences into a correspondence-aware masked attention module within the Diffusion Transformer (DiT). This module restricts each text token to attend only to its matched reference regions, ensuring precise attribute binding and reliable multi-subject composition. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the multi-subject image generation, substantially improving prompt following and subject consistency.", "AI": {"tldr": "本文提出了一种层次化的概念到外观指导框架，用于多主体图像生成。", "motivation": "现有的方法在处理身份一致性及合成控制方面存在不足，依赖扩散模型隐式关联文本提示和参考图像是其主要原因。", "method": "该框架引入VAE dropout训练策略以强化语义信号的使用，并将视觉语言模型导出的一致性信息整合至对应感知掩码注意模块中。", "result": "实验表明本文方法在多主体图像生成方面达到了最先进的性能，显著提高了提示跟随和身份一致性。", "conclusion": "所提出的层次化概念到外观指导框架有效解决了现有方法中存在的问题，并提升了图像生成的质量。"}}
{"id": "2602.03447", "pdf": "https://arxiv.org/pdf/2602.03447", "abs": "https://arxiv.org/abs/2602.03447", "authors": ["Yu-Hsiang Chen", "Wei-Jer Chang", "Christian Kotulla", "Thomas Keutgens", "Steffen Runde", "Tobias Moers", "Christoph Klas", "Wei Zhan", "Masayoshi Tomizuka", "Yi-Ting Chen"], "title": "HetroD: A High-Fidelity Drone Dataset and Benchmark for Autonomous Driving in Heterogeneous Traffic", "categories": ["cs.RO", "cs.CV"], "comment": "IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "We present HetroD, a dataset and benchmark for developing autonomous driving systems in heterogeneous environments. HetroD targets the critical challenge of navi- gating real-world heterogeneous traffic dominated by vulner- able road users (VRUs), including pedestrians, cyclists, and motorcyclists that interact with vehicles. These mixed agent types exhibit complex behaviors such as hook turns, lane splitting, and informal right-of-way negotiation. Such behaviors pose significant challenges for autonomous vehicles but remain underrepresented in existing datasets focused on structured, lane-disciplined traffic. To bridge the gap, we collect a large- scale drone-based dataset to provide a holistic observation of traffic scenes with centimeter-accurate annotations, HD maps, and traffic signal states. We further develop a modular toolkit for extracting per-agent scenarios to support downstream task development. In total, the dataset comprises over 65.4k high- fidelity agent trajectories, 70% of which are from VRUs. HetroD supports modeling of VRU behaviors in dense, het- erogeneous traffic and provides standardized benchmarks for forecasting, planning, and simulation tasks. Evaluation results reveal that state-of-the-art prediction and planning models struggle with the challenges presented by our dataset: they fail to predict lateral VRU movements, cannot handle unstructured maneuvers, and exhibit limited performance in dense and multi-agent scenarios, highlighting the need for more robust approaches to heterogeneous traffic. See our project page for more examples: https://hetroddata.github.io/HetroD/", "AI": {"tldr": "提出了HetroD数据集和基准，用于开发在异质交通环境下的自动驾驶系统。", "motivation": "现有数据集中对结构化、车道遵循型交通的关注较多，忽略了行人、骑车人等易受伤害道路使用者的复杂行为。这些问题需要新的解决方案来提升自动驾驶系统的性能。", "method": "收集了一个大规模无人机采集的数据集，并提供了高精度标注和HD地图等功能模块以支持后续任务开发。", "result": "该数据集包含了超过65,400条高质量代理轨迹，70%来自易受伤害道路使用者。评估结果表明，最先进的预测和规划模型在处理横向移动、非结构化操作以及密集多代理场景时存在不足。", "conclusion": "HetroD支持异质交通中VRU行为的建模，并提供标准化基准以提升自动驾驶系统的性能。"}}
{"id": "2602.03445", "pdf": "https://arxiv.org/pdf/2602.03445", "abs": "https://arxiv.org/abs/2602.03445", "authors": ["Qixin Zeng", "Shuo Zhang", "Hongyin Zhang", "Renjie Wang", "Han Zhao", "Libang Zhao", "Runze Li", "Donglin Wang", "Chao Huang"], "title": "CRL-VLA: Continual Vision-Language-Action Learning", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.", "AI": {"tldr": "本文提出了CRL-VLA框架，用于持续训练视觉语言动作模型，在长期学习中平衡稳定性和可塑性。", "motivation": "在开放环境中，使机器人能够通过与环境的交互掌握精细操作需要终身学习。然而，现有的方法难以同时保持旧技能和学习新技能。", "method": "CRL-VLA框架利用不对称调节解决稳定性与可塑性的矛盾：限制先前任务的优势幅度而允许新任务中的可控增长。这通过新颖的目标导向价值公式实现。", "result": "实验表明，CRL-VLA在LIBERO基准测试中表现优于基线模型，在防止遗忘和向前适应方面取得显著效果。", "conclusion": "本文提出的CRL-VLA框架能有效解决终身学习中的稳定性与可塑性冲突问题。"}}
{"id": "2602.03444", "pdf": "https://arxiv.org/pdf/2602.03444", "abs": "https://arxiv.org/abs/2602.03444", "authors": ["Arivarasan Karmegam", "Lucianna Kiffer", "Antonio Fernández Anta"], "title": "Exploiting Multi-Core Parallelism in Blockchain Validation and Construction", "categories": ["cs.DC", "cs.DS"], "comment": null, "summary": "Blockchain validators can reduce block processing time by exploiting multi-core CPUs, but deterministic execution must preserve a given total order while respecting transaction conflicts and per-block runtime limits. This paper systematically examines how validators can exploit multi-core parallelism during both block construction and execution without violating blockchain semantics. We formalize two validator-side optimization problems: (i) executing an already ordered block on \\(p\\) cores to minimize makespan while ensuring equivalence to sequential execution; and (ii) selecting and scheduling a subset of mempool transactions under a runtime limit \\(B\\) to maximize validator reward. For both, we develop exact Mixed-Integer Linear Programming (MILP) formulations that capture conflict, order, and capacity constraints, and propose fast deterministic heuristics that scale to realistic workloads. Using Ethereum mainnet traces and including a Solana-inspired declared-access baseline (Sol) for ordered-block scheduling and a simple reward-greedy baseline (RG) for block construction, we empirically quantify the trade-offs between optimality and runtime.", "AI": {"tldr": "区块链验证者可以通过利用多核CPU减少区块处理时间，但需要在不违反区块链语义的前提下进行。本文系统地研究了如何在区块构建和执行过程中利用多核并行性。", "motivation": "区块链验证者希望通过利用多核处理器来缩短区块的处理时间，同时确保确定性的执行顺序以及遵守交易冲突规则和每块运行时限制。", "method": "提出了两种优化问题：一是如何在p个核心上最小化执行已排序区块的时间；二是如何选择和安排内存池中的交易以最大化验证者的收益。为两个问题开发了精确的混合整数线性规划（MILP）模型，并提出快速确定性的启发式方法。", "result": "通过使用Ethereum主网跟踪数据进行实验，结果表明所提的方法在实际工作负载中能够实现最优性和运行时间之间的权衡。", "conclusion": "该研究展示了如何利用多核并行性来优化区块链验证过程，并提出了两种有效的策略以减少区块处理时间和提高收益。"}}
{"id": "2602.03439", "pdf": "https://arxiv.org/pdf/2602.03439", "abs": "https://arxiv.org/abs/2602.03439", "authors": ["Xiaochi Zhou", "Patrick Bulter", "Changxuan Yang", "Simon D. Rihm", "Thitikarn Angkanaporn", "Jethro Akroyd", "Sebastian Mosbach", "Markus Kraft"], "title": "Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents", "categories": ["cs.AI", "cs.IR"], "comment": "mber:c4e-343", "summary": "We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge. Within The World Avatar (TWA), ontological specifications are compiled into executable tool interfaces that LLM-based agents must use to create and modify knowledge graph instances, enforcing semantic constraints during generation rather than through post-hoc validation. Extending TWA's semantic agent composition framework, the Model Context Protocol (MCP) and associated agents are integral components of the knowledge graph ecosystem, enabling structured interaction between generative models, symbolic constraints, and external resources. An agent-based workflow translates ontologies into ontology-aware tools and iteratively applies them to extract, validate, and repair structured knowledge from unstructured scientific text. Using metal-organic polyhedra synthesis literature as an illustrative case, we show how executable ontological semantics can guide LLM behaviour and reduce manual schema and prompt engineering, establishing a general paradigm for embedding formal knowledge into generative systems.", "AI": {"tldr": "本论文提出了一种将大型语言模型与正式领域知识耦合的机制，通过编译本体规范到可执行工具接口来指导LLM的行为，并减少手动方案和提示工程。", "motivation": "动机在于通过编译本体规范至可执行工具接口，使LLM能够基于形式化领域的知识生成并修改知识图谱实例，从而在生成过程中而不是事后验证时就实施语义约束。", "method": "方法是在The World Avatar (TWA)框架内，将本体学规范编译成可以被LLM代理执行的工具接口，并通过模型上下文协议(MCP)，实现生成模型、符号约束与外部资源之间的结构化交互。使用金属-有机多面体合成文献作为案例，说明如何利用可执行本体语义指导LLM行为。", "result": "结果是展示了一种通用范式，该范式将形式知识嵌入到生成系统中，并减少了手动方案和提示工程的工作量。", "conclusion": "结论认为，这种方法提供了一个可以广泛使用的框架，在大型语言模型与正式领域知识之间建立了桥梁，从而提升其在特定领域的应用性能。"}}
{"id": "2602.03436", "pdf": "https://arxiv.org/pdf/2602.03436", "abs": "https://arxiv.org/abs/2602.03436", "authors": ["Kenta Komoto", "Kazuhiro Kurita", "Hirotaka Ono"], "title": "On the Complexity of Maximal/Closed Frequent Tree Mining for Bounded Height Trees", "categories": ["cs.DS"], "comment": null, "summary": "In this paper, we address the problem of enumerating all frequent maximal/closed trees. This is a classical and central problem in data mining. Although many practical algorithms have been developed for this problem, its complexity under ``realistic assumptions'' on tree height has not been clarified. More specifically, while it was known that the mining problem becomes hard when the tree height is at least 60, the complexity for cases where the tree height is smaller has not yet been clarified. We resolve this gap by establishing results for these tree mining problems under several settings, including ordered and unordered trees, as well as maximal and closed variants.", "AI": {"tldr": "该论文探讨了在受限树高度条件下频繁最大/封闭子树挖掘的复杂性。", "motivation": "尽管已有许多解决此类问题的实际算法，但在特定条件下（例如树的高度小于60）的复杂性研究尚未完全明确。", "method": "通过分析不同设定下有序和无序树的最大化与封闭变体的问题，填补了该领域的空白。", "result": "建立了在各种设置下的频繁最大/封闭子树挖掘问题的结果。", "conclusion": "论文解决了特定条件下频繁最大/封闭树挖掘的复杂性研究缺口。"}}
{"id": "2602.03435", "pdf": "https://arxiv.org/pdf/2602.03435", "abs": "https://arxiv.org/abs/2602.03435", "authors": ["Daniele Caradonna", "Nikhil Nair", "Anup Teejo Mathew", "Daniel Feliu Talegón", "Imran Afgan", "Egidio Falotico", "Cosimo Della Santina", "Federico Renda"], "title": "Model-based Optimal Control for Rigid-Soft Underactuated Systems", "categories": ["cs.RO"], "comment": null, "summary": "Continuum soft robots are inherently underactuated and subject to intrinsic input constraints, making dynamic control particularly challenging, especially in hybrid rigid-soft robots. While most existing methods focus on quasi-static behaviors, dynamic tasks such as swing-up require accurate exploitation of continuum dynamics. This has led to studies on simple low-order template systems that often fail to capture the complexity of real continuum deformations. Model-based optimal control offers a systematic solution; however, its application to rigid-soft robots is often limited by the computational cost and inaccuracy of numerical differentiation for high-dimensional models. Building on recent advances in the Geometric Variable Strain model that enable analytical derivatives, this work investigates three optimal control strategies for underactuated soft systems-Direct Collocation, Differential Dynamic Programming, and Nonlinear Model Predictive Control-to perform dynamic swing-up tasks. To address stiff continuum dynamics and constrained actuation, implicit integration schemes and warm-start strategies are employed to improve numerical robustness and computational efficiency. The methods are evaluated in simulation on three Rigid-Soft and high-order soft benchmark systems-the Soft Cart-Pole, the Soft Pendubot, and the Soft Furuta Pendulum- highlighting their performance and computational trade-offs.", "AI": {"tldr": "研究提出了一种基于模型的优化控制方法，用于解决混合刚性软机器人中的动态任务。", "motivation": "现有大多数方法关注准静态行为，难以精确利用连续体动力学来完成如摆起等动态任务。这种方法受限于计算成本和高维模型下的数值微分不准确性。因此，论文探讨了针对欠驱动的软系统优化控制策略的应用与改进。", "method": "基于最近关于几何变量应变模型的进步，研究采用了直接列式、差分动态规划及非线性模型预测控制三种最优控制策略，并使用隐式积分方案和预热启动策略来提高数值稳健性和计算效率。", "result": "方法在模拟中对软卡特-杆系统、软摆双自由度机器人以及软福鲁塔摆等高阶软基准系统进行了评估，展示了其性能和计算权衡。", "conclusion": "通过改进的模型和控制算法，论文成功提高了混合刚性软机器人的动态任务执行效率，并验证了方法的有效性和实用性。"}}
{"id": "2602.03430", "pdf": "https://arxiv.org/pdf/2602.03430", "abs": "https://arxiv.org/abs/2602.03430", "authors": ["Xiaomeng Zhu", "Fengming Zhu", "Weijie Zhou", "Ye Tian", "Zhenlin Hu", "Yufei Huang", "Yuchun Guo", "Xinyu Wu", "Zhengyou Zhang", "Fangzhen Lin", "Xuantang Xiong"], "title": "ProAct: A Benchmark and Multimodal Framework for Structure-Aware Proactive Response", "categories": ["cs.RO"], "comment": null, "summary": "While passive agents merely follow instructions, proactive agents align with higher-level objectives, such as assistance and safety by continuously monitoring the environment to determine when and how to act. However, developing proactive agents is hindered by the lack of specialized resources. To address this, we introduce ProAct-75, a benchmark designed to train and evaluate proactive agents across diverse domains, including assistance, maintenance, and safety monitoring. Spanning 75 tasks, our dataset features 91,581 step-level annotations enriched with explicit task graphs. These graphs encode step dependencies and parallel execution possibilities, providing the structural grounding necessary for complex decision-making. Building on this benchmark, we propose ProAct-Helper, a reference baseline powered by a Multimodal Large Language Model (MLLM) that grounds decision-making in state detection, and leveraging task graphs to enable entropy-driven heuristic search for action selection, allowing agents to execute parallel threads independently rather than mirroring the human's next step. Extensive experiments demonstrate that ProAct-Helper outperforms strong closed-source models, improving trigger detection mF1 by 6.21%, saving 0.25 more steps in online one-step decision, and increasing the rate of parallel actions by 15.58%.", "AI": {"tldr": "本文提出了一种用于训练和评估主动性代理的基准ProAct-75，以及一个基于多模态大型语言模型的参考基线ProAct-Helper。", "motivation": "缺乏专门资源限制了主动性代理的发展。为了解决这个问题，作者提出了ProAct-75，以促进该领域研究。", "method": "构建了一个包含75个任务的数据集，其中包括91,581步级注释和详细的任务图。基于此数据集，团队开发了一种基于多模态大型语言模型的基线代理，它可以进行状态检测，并使用任务图实现启发式搜索以选择行动。", "result": "实验表明，ProAct-Helper在触发检测mF1、在线一步决策中的步数节省和并行操作率方面优于现有模型。", "conclusion": "本文通过引入ProAct-75基准数据集以及基于多模态大型语言模型的基线代理ProAct-Helper，为主动性代理的研究提供了新的视角。"}}
{"id": "2602.03429", "pdf": "https://arxiv.org/pdf/2602.03429", "abs": "https://arxiv.org/abs/2602.03429", "authors": ["Tae Soo Kim", "Yoonjoo Lee", "Jaesang Yu", "John Joon Young Chung", "Juho Kim"], "title": "DiscoverLLM: From Executing Intents to Discovering Them", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "To handle ambiguous and open-ended requests, Large Language Models (LLMs) are increasingly trained to interact with users to surface intents they have not yet expressed (e.g., ask clarification questions). However, users are often ambiguous because they have not yet formed their intents: they must observe and explore outcomes to discover what they want. Simply asking \"what kind of tone do you want?\" fails when users themselves do not know. We introduce DiscoverLLM, a novel and generalizable framework that trains LLMs to help users form and discover their intents. Central to our approach is a novel user simulator that models cognitive state with a hierarchy of intents that progressively concretize as the model surfaces relevant options -- where the degree of concretization serves as a reward signal that models can be trained to optimize. Resulting models learn to collaborate with users by adaptively diverging (i.e., explore options) when intents are unclear, and converging (i.e., refine and implement) when intents concretize. Across proposed interactive benchmarks in creative writing, technical writing, and SVG drawing, DiscoverLLM achieves over 10% higher task performance while reducing conversation length by up to 40%. In a user study with 75 human participants, DiscoverLLM improved conversation satisfaction and efficiency compared to baselines.", "AI": {"tldr": "DiscoverLLM是一种新的框架，用于训练大型语言模型帮助用户形成和发现他们的意图。", "motivation": "现有的大型语言模型难以处理模棱两可且开放性请求，因为这些请求可能源自用户尚未明确的意图。传统的方法通过询问用户来解决这种问题，但这在用户自己也不清楚的情况下是无效的。", "method": "该框架引入了一种新的用户模拟器，它通过层次化的意图结构逐步具体化，并将具体的程度作为奖励信号进行优化训练，从而使得模型能够适应性地探索或细化用户的意图。", "result": "DiscoverLLM在创意写作、技术写作和SVG绘图的交互式基准测试中实现了超过10%的任务性能提升，并且减少了对话长度最多达40%。用户研究显示，与基线相比，DiscoverLLM提高了对话满意度和效率。", "conclusion": "该论文提出了一种新的框架，用于训练大型语言模型帮助用户形成并发现他们的意图，这种方法通过引入一个新的用户模拟器来优化训练过程，并在多个基准测试中证明了其优越性。"}}
{"id": "2602.03425", "pdf": "https://arxiv.org/pdf/2602.03425", "abs": "https://arxiv.org/abs/2602.03425", "authors": ["Xiaofeng Tan", "Jun Liu", "Yuanting Fan", "Bin-Bin Gao", "Xi Jiang", "Xiaochen Chen", "Jinlong Peng", "Chengjie Wang", "Hongsong Wang", "Feng Zheng"], "title": "ConsistentRFT: Reducing Visual Hallucinations in Flow-based Reinforcement Fine-Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Reinforcement Fine-Tuning (RFT) on flow-based models is crucial for preference alignment. However, they often introduce visual hallucinations like over-optimized details and semantic misalignment. This work preliminarily explores why visual hallucinations arise and how to reduce them. We first investigate RFT methods from a unified perspective, and reveal the core problems stemming from two aspects, exploration and exploitation: (1) limited exploration during stochastic differential equation (SDE) rollouts, leading to an over-emphasis on local details at the expense of global semantics, and (2) trajectory imitation process inherent in policy gradient methods, distorting the model's foundational vector field and its cross-step consistency. Building on this, we propose ConsistentRFT, a general framework to mitigate these hallucinations. Specifically, we design a Dynamic Granularity Rollout (DGR) mechanism to balance exploration between global semantics and local details by dynamically scheduling different noise sources. We then introduce a Consistent Policy Gradient Optimization (CPGO) that preserves the model's consistency by aligning the current policy with a more stable prior. Extensive experiments demonstrate that ConsistentRFT significantly mitigates visual hallucinations, achieving average reductions of 49\\% for low-level and 38\\% for high-level perceptual hallucinations. Furthermore, ConsistentRFT outperforms other RFT methods on out-of-domain metrics, showing an improvement of 5.1\\% (v.s. the baseline's decrease of -0.4\\%) over FLUX1.dev. This is \\href{https://xiaofeng-tan.github.io/projects/ConsistentRFT}{Project Page}.", "AI": {"tldr": "本文提出了一种减少基于流模型的强化学习微调过程中视觉幻觉的方法ConsistentRFT。", "motivation": "基于流模型的强化学习微调在偏好对齐中至关重要，但往往会引入过度优化细节和语义错位等视觉幻觉。为了探究原因并降低这些问题的影响，本文进行了研究。", "method": "通过平衡全局语义与局部细节之间的探索，设计了动态粒度滚动机制DGR，并提出了保持模型一致性的连续策略梯度优化CPGO方法。", "result": "实验表明，ConsistentRFT显著减少了视觉幻觉，在低级和高级感知幻觉上分别平均减少49%和38%，并且在领域外指标上优于其他微调方法5.1%。", "conclusion": "本文通过平衡全局语义与局部细节之间的探索，并保持模型的一致性，有效地降低了基于流模型的强化学习微调过程中的视觉幻觉。"}}
{"id": "2602.03423", "pdf": "https://arxiv.org/pdf/2602.03423", "abs": "https://arxiv.org/abs/2602.03423", "authors": ["Alexander Loth", "Dominique Conceicao Rosario", "Peter Ebinger", "Martin Kappes", "Marc-Oliver Pahl"], "title": "Origin Lens: A Privacy-First Mobile Framework for Cryptographic Image Provenance and AI Detection", "categories": ["cs.CR", "cs.CV", "cs.CY", "cs.HC"], "comment": "Accepted at ACM TheWebConf '26 Companion", "summary": "The proliferation of generative AI poses challenges for information integrity assurance, requiring systems that connect model governance with end-user verification. We present Origin Lens, a privacy-first mobile framework that targets visual disinformation through a layered verification architecture. Unlike server-side detection systems, Origin Lens performs cryptographic image provenance verification and AI detection locally on the device via a Rust/Flutter hybrid architecture. Our system integrates multiple signals - including cryptographic provenance, generative model fingerprints, and optional retrieval-augmented verification - to provide users with graded confidence indicators at the point of consumption. We discuss the framework's alignment with regulatory requirements (EU AI Act, DSA) and its role in verification infrastructure that complements platform-level mechanisms.", "AI": {"tldr": "本文提出了Origin Lens，一个用于加密图像来源验证和AI检测的隐私优先移动框架。", "motivation": "随着生成式AI技术的发展，信息完整性保障面临挑战。需要连接模型治理与终端用户验证的系统以应对虚假信息问题。", "method": "Origin Lens通过Rust/Flutter混合架构在设备上执行加密图像来源验证和AI检测，集成了加密源证明、生成模型指纹等多信号。", "result": "该框架提供分级信心指标，在消费点为用户提供透明度。同时符合监管要求（欧盟AI法案，数字服务法）。", "conclusion": "Origin Lens是保障信息完整性的有力工具，可以与平台级机制互补增强验证基础设施建设。"}}
{"id": "2602.03420", "pdf": "https://arxiv.org/pdf/2602.03420", "abs": "https://arxiv.org/abs/2602.03420", "authors": ["Siyi Wang", "Shihong Tan", "Siyi Liu", "Hong Jia", "Gongping Huang", "James Bailey", "Ting Dang"], "title": "CoCoEmo: Composable and Controllable Human-Like Emotional TTS via Activation Steering", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Emotional expression in human speech is nuanced and compositional, often involving multiple, sometimes conflicting, affective cues that may diverge from linguistic content. In contrast, most expressive text-to-speech systems enforce a single utterance-level emotion, collapsing affective diversity and suppressing mixed or text-emotion-misaligned expression. While activation steering via latent direction vectors offers a promising solution, it remains unclear whether emotion representations are linearly steerable in TTS, where steering should be applied within hybrid TTS architectures, and how such complex emotion behaviors should be evaluated. This paper presents the first systematic analysis of activation steering for emotional control in hybrid TTS models, introducing a quantitative, controllable steering framework, and multi-rater evaluation protocols that enable composable mixed-emotion synthesis and reliable text-emotion mismatch synthesis. Our results demonstrate, for the first time, that emotional prosody and expressive variability are primarily synthesized by the TTS language module instead of the flow-matching module, and also provide a lightweight steering approach for generating natural, human-like emotional speech.", "AI": {"tldr": "本文提出了一种用于合成具有混合情感和文本与情感不匹配的语音的激活转向框架。", "motivation": "现有TTS系统倾向于单一的情绪表达，忽视了人类言语中复杂的情感组合性。为了解决这一问题，并探索情感在TTS模型中的生成机制，作者提出了一个系统化的分析框架和评估协议。", "method": "通过引入量化可控的激活转向框架和多评审员评价协议，本文对情感控制进行了全面研究，旨在实现可合成混合情绪并支持文本与情感不匹配的语音合成。", "result": "实验结果表明，情感语调和表达多样性主要由TTS的语言模块生成。此外，还提出了一种轻量级转向方法来产生自然、类似人类的情感化语音。", "conclusion": "研究揭示了混合情绪控制在TTS中的潜力，并展示了实现更真实和多样化的语音合成的方法。"}}
{"id": "2602.03418", "pdf": "https://arxiv.org/pdf/2602.03418", "abs": "https://arxiv.org/abs/2602.03418", "authors": ["Minsung Yoon", "Mincheul Kang", "Daehyung Park", "Sung-Eui Yoon"], "title": "Learning-based Initialization of Trajectory Optimization for Path-following Problems of Redundant Manipulators", "categories": ["cs.RO"], "comment": "Accepted to ICRA 2023. <a href=\"https://sgvr.kaist.ac.kr/~msyoon/papers/ICRA23_RLITG/\" rel=\"external noopener nofollow\" class=\"link-external link-https\">Project Page</a>", "summary": "Trajectory optimization (TO) is an efficient tool to generate a redundant manipulator's joint trajectory following a 6-dimensional Cartesian path. The optimization performance largely depends on the quality of initial trajectories. However, the selection of a high-quality initial trajectory is non-trivial and requires a considerable time budget due to the extremely large space of the solution trajectories and the lack of prior knowledge about task constraints in configuration space. To alleviate the issue, we present a learning-based initial trajectory generation method that generates high-quality initial trajectories in a short time budget by adopting example-guided reinforcement learning. In addition, we suggest a null-space projected imitation reward to consider null-space constraints by efficiently learning kinematically feasible motion captured in expert demonstrations. Our statistical evaluation in simulation shows the improved optimality, efficiency, and applicability of TO when we plug in our method's output, compared with three other baselines. We also show the performance improvement and feasibility via real-world experiments with a seven-degree-of-freedom manipulator.", "AI": {"tldr": "提出了一种基于学习的轨迹优化初始化方法，以生成冗余机械臂跟随6维笛卡尔路径时高质量的初始关节轨迹。", "motivation": "为了改善传统轨迹优化中由于缺乏先验知识导致的初始化质量低和耗时问题，该论文旨在通过引入强化学习提高初始轨迹的质量和生成速度。", "method": "利用示例引导的强化学习来生成高质初试轨迹，并提出了一种在专家演示数据中有效学习到可行运动的方法。", "result": "仿真与实际实验均验证了所提方法相比其他基线方法，在优化性能，效率及适用性方面都有显著提升。", "conclusion": "通过引入基于学习的初始化策略，可以大大提高机械臂路径跟随任务中的轨迹优化效果。"}}
{"id": "2602.03414", "pdf": "https://arxiv.org/pdf/2602.03414", "abs": "https://arxiv.org/abs/2602.03414", "authors": ["Zhengbo Jiao", "Shaobo Wang", "Zifan Zhang", "Wei Wang", "Bing Zhao", "Hu Wei", "Linfeng Zhang"], "title": "Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction", "categories": ["cs.CV", "cs.AI"], "comment": "18pages", "summary": "Multimodal Large Language Models (MLLMs) have significantly advanced vision-language understanding. However, even state-of-the-art models struggle with geometric reasoning, revealing a critical bottleneck: the extreme scarcity of high-quality image-text pairs. Human annotation is prohibitively expensive, while automated methods fail to ensure fidelity and training effectiveness. Existing approaches either passively adapt to available images or employ inefficient random exploration with filtering, decoupling generation from learning needs. We propose Socratic-Geo, a fully autonomous framework that dynamically couples data synthesis with model learning through multi-agent interaction. The Teacher agent generates parameterized Python scripts with reflective feedback (Reflect for solvability, RePI for visual validity), ensuring image-text pair purity. The Solver agent optimizes reasoning through preference learning, with failure paths guiding Teacher's targeted augmentation. Independently, the Generator learns image generation capabilities on accumulated \"image-code-instruction\" triplets, distilling programmatic drawing intelligence into visual generation. Starting from only 108 seed problems, Socratic-Solver achieves 49.11 on six benchmarks using one-quarter of baseline data, surpassing strong baselines by 2.43 points. Socratic-Generator achieves 42.4% on GenExam, establishing new state-of-the-art for open-source models, surpassing Seedream-4.0 (39.8%) and approaching Gemini-2.5-Flash-Image (43.1%).", "AI": {"tldr": "本文提出了一种通过多代理交互自动生成图像文本对和几何推理训练的数据生成框架Socratic-Geo。", "motivation": "现有的大型语言模型在处理视觉-语言理解时存在几何推理能力不足的问题，原因是高质量的图像文本数据稀缺。人工标注成本高昂且自动化方法难以保证数据的有效性和纯净性。", "method": "本文提出了一个完全自主的数据合成与学习耦合框架Socratic-Geo，包括教师代理生成参数化Python脚本和反馈、求解器通过偏好学习优化推理过程以及生成器从积累的“图像-代码-指令”三元组中学习图像生成能力。", "result": "使用较少的数据量，在六项基准测试中，Socratic-Solver达到了49.11的成绩，超过了基线模型2.43分；在GenExam数据集上，Socratic-Generator取得了42.4%的准确率，创造了新的开源模型记录。", "conclusion": "通过多代理交互自动生成图像文本对和几何推理训练的数据生成框架可以有效提升大型语言模型的几何推理能力。"}}
{"id": "2602.03410", "pdf": "https://arxiv.org/pdf/2602.03410", "abs": "https://arxiv.org/abs/2602.03410", "authors": ["Piotr Wójcik", "Maksym Petrenko", "Wojciech Gromski", "Przemysław Spurek", "Maciej Zieba"], "title": "UnHype: CLIP-Guided Hypernetworks for Dynamic LoRA Unlearning", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in large-scale diffusion models have intensified concerns about their potential misuse, particularly in generating realistic yet harmful or socially disruptive content. This challenge has spurred growing interest in effective machine unlearning, the process of selectively removing specific knowledge or concepts from a model without compromising its overall generative capabilities. Among various approaches, Low-Rank Adaptation (LoRA) has emerged as an effective and efficient method for fine-tuning models toward targeted unlearning. However, LoRA-based methods often exhibit limited adaptability to concept semantics and struggle to balance removing closely related concepts with maintaining generalization across broader meanings. Moreover, these methods face scalability challenges when multiple concepts must be erased simultaneously. To address these limitations, we introduce UnHype, a framework that incorporates hypernetworks into single- and multi-concept LoRA training. The proposed architecture can be directly plugged into Stable Diffusion as well as modern flow-based text-to-image models, where it demonstrates stable training behavior and effective concept control. During inference, the hypernetwork dynamically generates adaptive LoRA weights based on the CLIP embedding, enabling more context-aware, scalable unlearning. We evaluate UnHype across several challenging tasks, including object erasure, celebrity erasure, and explicit content removal, demonstrating its effectiveness and versatility. Repository: https://github.com/gmum/UnHype.", "AI": {"tldr": "UnHype是一种基于超网络的低秩适应框架，用于动态LORA卸载，可以更有效地在生成模型中移除特定概念。", "motivation": "为了应对大规模扩散模型可能产生的有害或社会破坏性内容的问题，研究者提出了一种有效的方法来选择性地从模型中删除特定知识或概念而不损害其整体生成能力。", "method": "该框架将超网络整合到单个和多概念的低秩适应训练中，并利用CLIP嵌入动态生成适应性的LoRA权重，在推理时实现更上下文感知、可扩展的卸载。", "result": "实验结果显示，UnHype在对象移除、名人移除和显式内容删除等挑战性任务上表现出色，证明了其有效性和多功能性。", "conclusion": "通过引入超网络到LoRA训练中并利用CLIP嵌入动态生成适应性的权重，可以更有效地控制概念移除，并展示了在多种模型上的有效性。"}}
{"id": "2602.03406", "pdf": "https://arxiv.org/pdf/2602.03406", "abs": "https://arxiv.org/abs/2602.03406", "authors": ["Yuancheng Shao", "Yao Zhang", "Jia Gu", "Zixi Chen", "Di Wu", "Yuqiao Chen", "Bo Lu", "Wenjie Liu", "Cesare Stefanini", "Peng Qi"], "title": "Deep-Learning-Based Control of a Decoupled Two-Segment Continuum Robot for Endoscopic Submucosal Dissection", "categories": ["cs.RO"], "comment": null, "summary": "Manual endoscopic submucosal dissection (ESD) is technically demanding, and existing single-segment robotic tools offer limited dexterity. These limitations motivate the development of more advanced solutions. To address this, DESectBot, a novel dual segment continuum robot with a decoupled structure and integrated surgical forceps, enabling 6 degrees of freedom (DoFs) tip dexterity for improved lesion targeting in ESD, was developed in this work. Deep learning controllers based on gated recurrent units (GRUs) for simultaneous tip position and orientation control, effectively handling the nonlinear coupling between continuum segments, were proposed. The GRU controller was benchmarked against Jacobian based inverse kinematics, model predictive control (MPC), a feedforward neural network (FNN), and a long short-term memory (LSTM) network. In nested-rectangle and Lissajous trajectory tracking tasks, the GRU achieved the lowest position/orientation RMSEs: 1.11 mm/ 4.62° and 0.81 mm/ 2.59°, respectively. For orientation control at a fixed position (four target poses), the GRU attained a mean RMSE of 0.14 mm and 0.72°, outperforming all alternatives. In a peg transfer task, the GRU achieved a 100% success rate (120 success/120 attempts) with an average transfer time of 11.8s, the STD significantly outperforms novice-controlled systems. Additionally, an ex vivo ESD demonstration grasping, elevating, and resecting tissue as the scalpel completed the cut confirmed that DESectBot provides sufficient stiffness to divide thick gastric mucosa and an operative workspace adequate for large lesions.These results confirm that GRU-based control significantly enhances precision, reliability, and usability in ESD surgical training scenarios.", "AI": {"tldr": "本文开发了一种基于深度学习的双节段连续机器人DESectBot，用于内镜粘膜下剥离术（ESD）。", "motivation": "现有的单节段机器人工具在ESD过程中灵活性有限，技术要求高，因此需要一种具有更高自由度和精度的解决方案来改善操作。", "method": "使用门控循环单元（GRU）作为深度学习控制器进行同时尖端位置和方向控制，解决了连续节段之间的非线性耦合问题。将GRU与基于雅可比逆运动学、模型预测控制(MPC)、前馈神经网络(FNN)以及长短期记忆(LSTM)网络进行了对比。", "result": "在矩形轨迹跟踪任务中，GRU达到了最低的位置/方向均方根误差（RMSE）：1.11毫米/4.62度和0.81毫米/2.59度。固定位置下的姿态控制实验显示，GRU的平均RMSE为0.14毫米和0.72度，优于其他所有方法。在插针转移任务中，GRU实现了100%的成功率，并且平均转移时间为11.8秒。", "conclusion": "研究结果表明，基于GRU的控制显著提高了ESD手术训练场景中的精度、可靠性和易用性。"}}
{"id": "2602.03403", "pdf": "https://arxiv.org/pdf/2602.03403", "abs": "https://arxiv.org/abs/2602.03403", "authors": ["Guangming Lang", "Mingchuan Shang", "Mengjun Hu", "Jie Zhou", "Feng Xu"], "title": "Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations", "categories": ["cs.AI"], "comment": null, "summary": "In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on three qualitative relations, namely, preference, converse, and indifference, to describe agents' attitudes towards issue pairs, which significantly limits their capacity in capturing the essence of conflict. To overcome this limitation, we introduce the concept of an intuitionistic fuzzy preference-based conflict situation that captures agents' attitudes towards issue pairs with finer granularity than that afforded by classical preference-based models. Afterwards, we develop intuitionistic fuzzy preference-based conflict measures within this framework, and construct three-way conflict analysis models for trisecting the set of agent pairs, the agent set, and the issue set. Additionally, relative loss functions built on the proposed conflict functions are employed to calculate thresholds for three-way conflict analysis. Finally, we present adjustment mechanism-based feasible strategies that simultaneously account for both adjustment magnitudes and conflict degrees, together with an algorithm for constructing such feasible strategies, and provide an illustrative example to demonstrate the validity and effectiveness of the proposed model.", "AI": {"tldr": "研究引入直觉模糊偏好冲突模型，提出更细致的冲突分析方法和调整策略", "motivation": "现有偏好冲突模型只能处理三种关系限制了其对冲突本质的理解能力。为此，通过引入直觉模糊偏好数模来捕捉更细粒度的态度信息", "method": "开发基于直觉模糊偏好的冲突量测，并构建三路冲突分析模型；运用相对损失函数计算阈值并提出调整机制策略算法", "result": "展示了一种有效的解决方法及其在具体情境中的应用效果", "conclusion": "所提出的模型能够有效处理复杂偏好冲突，提供一种新的视角和工具"}}
{"id": "2602.03402", "pdf": "https://arxiv.org/pdf/2602.03402", "abs": "https://arxiv.org/abs/2602.03402", "authors": ["Mengxuan Wang", "Yuxin Chen", "Gang Xu", "Tao He", "Hongjie Jiang", "Ming Li"], "title": "Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Vision language models (VLMs) extend the reasoning capabilities of large language models (LLMs) to cross-modal settings, yet remain highly vulnerable to multimodal jailbreak attacks. Existing defenses predominantly rely on safety fine-tuning or aggressive token manipulations, incurring substantial training costs or significantly degrading utility. Recent research shows that LLMs inherently recognize unsafe content in text, and the incorporation of visual inputs in VLMs frequently dilutes risk-related signals. Motivated by this, we propose Risk Awareness Injection (RAI), a lightweight and training-free framework for safety calibration that restores LLM-like risk recognition by amplifying unsafe signals in VLMs. Specifically, RAI constructs an Unsafe Prototype Subspace from language embeddings and performs targeted modulation on selected high-risk visual tokens, explicitly activating safety-critical signals within the cross-modal feature space. This modulation restores the model's LLM-like ability to detect unsafe content from visual inputs, while preserving the semantic integrity of original tokens for cross-modal reasoning. Extensive experiments across multiple jailbreak and utility benchmarks demonstrate that RAI substantially reduces attack success rate without compromising task performance.", "AI": {"tldr": "本文提出了一种轻量级的无需训练的风险意识注入框架，用于校准视觉语言模型的安全性。", "motivation": "现有的防御方法成本高或显著降低效用，而视觉输入会稀释风险相关的信号。本文旨在通过增强危险信号来恢复大型语言模型识别不安全内容的能力。", "method": "构建一个从语言嵌入中获取的不安全原型子空间，并对选定的风险高的视觉标记进行调制，激活跨模态特征空间中的关键安全信号。", "result": "实验结果表明，RAI显著降低了攻击成功率而不损害任务性能。", "conclusion": "Risk Awareness Injection（风险意识注入）框架能够有效提高视觉语言模型的安全性，并保持其效用。"}}
{"id": "2602.03400", "pdf": "https://arxiv.org/pdf/2602.03400", "abs": "https://arxiv.org/abs/2602.03400", "authors": ["Jintai Li", "Songqiang Chen", "Shuo Jin", "Xiaoyuan Xie"], "title": "Precision in Practice: Knowledge Guided Code Summarizing Grounded in Industrial Expectations", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code summaries are essential for helping developers understand code functionality and reducing maintenance and collaboration costs. Although recent advances in large language models (LLMs) have significantly improved automatic code summarization, the practical usefulness of generated summaries in industrial settings remains insufficiently explored. In collaboration with documentation experts from the industrial HarmonyOS project, we conducted a questionnaire study showing that over 57.4% of code summaries produced by state-of-the-art approaches were rejected due to violations of developers' expectations for industrial documentation. Beyond semantic similarity to reference summaries, developers emphasize additional requirements, including the use of appropriate domain terminology, explicit function categorization, and the avoidance of redundant implementation details. To address these expectations, we propose ExpSum, an expectation-aware code summarization approach that integrates function metadata abstraction, informative metadata filtering, context-aware domain knowledge retrieval, and constraint-driven prompting to guide LLMs in generating structured, expectation-aligned summaries. We evaluate ExpSum on the HarmonyOS project and widely used code summarization benchmarks. Experimental results show that ExpSum consistently outperforms all baselines, achieving improvements of up to 26.71% in BLEU-4 and 20.10% in ROUGE-L on HarmonyOS. Furthermore, LLM-based evaluations indicate that ExpSum-generated summaries better align with developer expectations across other projects, demonstrating its effectiveness for industrial code documentation.", "AI": {"tldr": "提出了一种基于工业期望的代码摘要生成方法ExpSum，以提高代码总结的实际应用效果。", "motivation": "当前自动代码摘要技术在语义相似度上有所进步，但在实际工业环境中存在违反开发者预期的问题，如术语不当、分类不够明确和冗余细节过多。为解决这些问题，本文提出了一种新的代码摘要方法。", "method": "ExpSum方法集成了函数元数据抽象、信息性元数据过滤、上下文感知领域知识检索以及基于约束的提示机制来引导LLMs生成结构化且符合期望的代码总结。", "result": "实验结果表明，ExpSum在HarmonyOS项目和广泛使用的代码摘要基准测试中均优于所有基线方法，在BLEU-4上提高了26.71%，ROUGE-L上提高20.1%。基于LLM的评估显示其生成的总结更符合不同项目的开发者期望。", "conclusion": "ExpSum通过结合领域知识和工业预期，有效地改善了代码摘要的质量并增强了其实用性，为实际应用中的代码文档提供了一个强有力的解决方案。"}}
{"id": "2602.03397", "pdf": "https://arxiv.org/pdf/2602.03397", "abs": "https://arxiv.org/abs/2602.03397", "authors": ["Minsung Yoon", "Sung-Eui Yoon"], "title": "Enhancing Navigation Efficiency of Quadruped Robots via Leveraging Personal Transportation Platforms", "categories": ["cs.RO"], "comment": "Accepted to ICRA 2025. <a href=\"https://sgvr.kaist.ac.kr/~msyoon/papers/ICRA25/\" rel=\"external noopener nofollow\" class=\"link-external link-https\">Project Page</a>", "summary": "Quadruped robots face limitations in long-range navigation efficiency due to their reliance on legs. To ameliorate the limitations, we introduce a Reinforcement Learning-based Active Transporter Riding method (\\textit{RL-ATR}), inspired by humans' utilization of personal transporters, including Segways. The \\textit{RL-ATR} features a transporter riding policy and two state estimators. The policy devises adequate maneuvering strategies according to transporter-specific control dynamics, while the estimators resolve sensor ambiguities in non-inertial frames by inferring unobservable robot and transporter states. Comprehensive evaluations in simulation validate proficient command tracking abilities across various transporter-robot models and reduced energy consumption compared to legged locomotion. Moreover, we conduct ablation studies to quantify individual component contributions within the \\textit{RL-ATR}. This riding ability could broaden the locomotion modalities of quadruped robots, potentially expanding the operational range and efficiency.", "AI": {"tldr": "提出了一种基于强化学习的主动骑乘方法（RL-ATR），用于提高四足机器人的长距离导航效率。", "motivation": "为了克服四足机器人在长距离导航中由于依赖腿部移动所面临的限制，引入了人类使用个人交通工具的方法来增强其导航效率。", "method": "设计了一种基于强化学习的主动骑乘策略（RL-ATR），该方法包含一个运输工具骑行策略和两个状态估计器。策略根据特定控制动力学制定适当的操控策略；而状态估计器则解决非惯性框架下的传感器模糊，通过推理不可观察的机器人和运输工具的状态来解决问题。", "result": "在模拟实验中，验证了RL-ATR能够提高各种运输工具与四足机器人的模型组合中的指令跟踪能力和减少能量消耗。同时进行了消融研究以量化方法各组成部分的重要性。", "conclusion": "该骑行能力可以拓宽四足机器人运动模式的范围，有可能扩大其操作范围和效率。"}}
{"id": "2602.03392", "pdf": "https://arxiv.org/pdf/2602.03392", "abs": "https://arxiv.org/abs/2602.03392", "authors": ["Shumin Wang", "Yuexiang Xie", "Wenhao Zhang", "Yuchang Sun", "Yanxi Chen", "Yaliang Li", "Yanyong Zhang"], "title": "On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Entropy serves as a critical metric for measuring the diversity of outputs generated by large language models (LLMs), providing valuable insights into their exploration capabilities. While recent studies increasingly focus on monitoring and adjusting entropy to better balance exploration and exploitation in reinforcement fine-tuning (RFT), a principled understanding of entropy dynamics during this process is yet to be thoroughly investigated. In this paper, we establish a theoretical framework for analyzing the entropy dynamics during the RFT process, which begins with a discriminant expression that quantifies entropy change under a single logit update. This foundation enables the derivation of a first-order expression for entropy change, which can be further extended to the update formula of Group Relative Policy Optimization (GRPO). The corollaries and insights drawn from the theoretical analysis inspire the design of entropy control methods, and also offer a unified lens for interpreting various entropy-based methods in existing studies. We provide empirical evidence to support the main conclusions of our analysis and demonstrate the effectiveness of the derived entropy-discriminator clipping methods. This study yields novel insights into RFT training dynamics, providing theoretical support and practical strategies for optimizing the exploration-exploitation balance during LLM fine-tuning.", "AI": {"tldr": "本文建立了理论框架以分析大型语言模型在强化微调过程中的熵动态变化，为优化探索与利用的平衡提供了理论支持和实用策略。", "motivation": "当前研究中关于监控和调整熵以改善强化微调过程中探索与利用之间的平衡尚未得到充分探讨。因此，本文旨在通过建立一个理论框架来深入理解这种动态过程。", "method": "基于单一logit更新下熵变化的判别表达式，推导出一阶熵变化公式，并将其扩展到Group Relative Policy Optimization (GRPO) 更新公式的应用中，进而提出熵控制方法。", "result": "通过实证证据支持了主要结论并展示了所提出的熵判别剪裁方法的有效性。这些发现为大型语言模型在强化微调期间的训练动态提供了新的见解，并提出了优化探索与利用平衡的方法。", "conclusion": "该研究不仅揭示了大型语言模型在强化微调过程中的新洞见，还提供了一种统一的视角来解释现有研究中基于熵的方法。"}}
{"id": "2602.03390", "pdf": "https://arxiv.org/pdf/2602.03390", "abs": "https://arxiv.org/abs/2602.03390", "authors": ["Hyun Seok Seong", "WonJun Moon", "Jae-Pil Heo"], "title": "From Vicious to Virtuous Cycles: Synergistic Representation Learning for Unsupervised Video Object-Centric Learning", "categories": ["cs.CV", "cs.LG"], "comment": "ICLR 2026; Code is available at https://github.com/hynnsk/SRL", "summary": "Unsupervised object-centric learning models, particularly slot-based architectures, have shown great promise in decomposing complex scenes. However, their reliance on reconstruction-based training creates a fundamental conflict between the sharp, high-frequency attention maps of the encoder and the spatially consistent but blurry reconstruction maps of the decoder. We identify that this discrepancy gives rise to a vicious cycle: the noisy feature map from the encoder forces the decoder to average over possibilities and produce even blurrier outputs, while the gradient computed from blurry reconstruction maps lacks high-frequency details necessary to supervise encoder features. To break this cycle, we introduce Synergistic Representation Learning (SRL) that establishes a virtuous cycle where the encoder and decoder mutually refine one another. SRL leverages the encoder's sharpness to deblur the semantic boundary within the decoder output, while exploiting the decoder's spatial consistency to denoise the encoder's features. This mutual refinement process is stabilized by a warm-up phase with a slot regularization objective that initially allocates distinct entities per slot. By bridging the representational gap between the encoder and decoder, SRL achieves state-of-the-art results on video object-centric learning benchmarks. Codes are available at https://github.com/hynnsk/SRL.", "AI": {"tldr": "本文提出了协同表征学习（SRL）方法，用于无监督视频对象中心学习，旨在解决编码器和解码器之间的表示差距问题。", "motivation": "现有基于槽的模型依赖于重建训练，在编码器的锐利注意图与解码器模糊重构之间存在冲突，形成恶性循环。为了解决这一问题，本文提出了一种新的方法来打破这种恶性循环。", "method": "协同表征学习（SRL）通过利用编码器的清晰度来消除解码器输出中的模糊，并通过解码器的空间一致性来减少编码器特征噪声，以此实现编码器和解码器之间的相互精炼。此过程由一个初始槽正则化目标稳定。", "result": "SRL在视频对象中心学习基准测试中取得了最先进的结果。", "conclusion": "本文通过打破重建训练中的恶性循环，实现了编码器与解码器的协同表征学习（SRL），显著提高了无监督视频对象中心学习的效果。"}}
{"id": "2602.03389", "pdf": "https://arxiv.org/pdf/2602.03389", "abs": "https://arxiv.org/abs/2602.03389", "authors": ["Jinwoo Choi", "Sang-Hyun Lee", "Seung-Woo Seo"], "title": "Chain-of-Goals Hierarchical Policy for Long-Horizon Offline Goal-Conditioned RL", "categories": ["cs.LG", "cs.AI"], "comment": "22 pages", "summary": "Offline goal-conditioned reinforcement learning remains challenging for long-horizon tasks. While hierarchical approaches mitigate this issue by decomposing tasks, most existing methods rely on separate high- and low-level networks and generate only a single intermediate subgoal, making them inadequate for complex tasks that require coordinating multiple intermediate decisions. To address this limitation, we draw inspiration from the chain-of-thought paradigm and propose the Chain-of-Goals Hierarchical Policy (CoGHP), a novel framework that reformulates hierarchical decision-making as autoregressive sequence modeling within a unified architecture. Given a state and a final goal, CoGHP autoregressively generates a sequence of latent subgoals followed by the primitive action, where each latent subgoal acts as a reasoning step that conditions subsequent predictions. To implement this efficiently, we pioneer the use of an MLP-Mixer backbone, which supports cross-token communication and captures structural relationships among state, goal, latent subgoals, and action. Across challenging navigation and manipulation benchmarks, CoGHP consistently outperforms strong offline baselines, demonstrating improved performance on long-horizon tasks.", "AI": {"tldr": "本文提出了一种新的层次化策略，通过自回归序列建模来解决离线目标条件强化学习中的长时任务挑战。", "motivation": "现有的层级方法对于需要协调多个中间决策的复杂任务而言效果不足。为此，文章提出了一个新的框架来改进这个问题。", "method": "该文提出Chain-of-Goals层次化策略（CoGHP），通过自回归序列建模将分层决策重铸为统一架构，并使用MLP-Mixer骨干网络实现这一方法。", "result": "在导航和操作基准测试中，所提出的CoGHP相比强基线模型表现出更好的性能，尤其对长时任务的改进尤为显著。", "conclusion": "通过新的框架设计，文章成功地解决了离线目标条件强化学习中的长期挑战，并为未来研究提供了新视角。"}}
{"id": "2602.03387", "pdf": "https://arxiv.org/pdf/2602.03387", "abs": "https://arxiv.org/abs/2602.03387", "authors": ["Zhengwei Ni", "Zhidu Li", "Wei Chen", "Zhaoyang Zhang", "Zehua Wang", "F. Richard Yu", "Victor C. M. Leung"], "title": "Toward a Sustainable Federated Learning Ecosystem: A Practical Least Core Mechanism for Payoff Allocation", "categories": ["cs.GT", "cs.AI"], "comment": "7 pages, 3 figures, submitted to IEEE Network", "summary": "Emerging network paradigms and applications increasingly rely on federated learning (FL) to enable collaborative intelligence while preserving privacy. However, the sustainability of such collaborative environments hinges on a fair and stable payoff allocation mechanism. Focusing on coalition stability, this paper introduces a payoff allocation framework based on the least core (LC) concept. Unlike traditional methods, the LC prioritizes the cohesion of the federation by minimizing the maximum dissatisfaction among all potential subgroups, ensuring that no participant has an incentive to break away. To adapt this game-theoretic concept to practical, large-scale networks, we propose a streamlined implementation with a stack-based pruning algorithm, effectively balancing computational efficiency with allocation precision. Case studies in federated intrusion detection demonstrate that our mechanism correctly identifies pivotal contributors and strategic alliances. The results confirm that the practical LC framework promotes stable collaboration and fosters a sustainable FL ecosystem.", "AI": {"tldr": "本文提出了一种基于最小核心（LC）概念的联邦学习（FL）生态系统中的支付分配框架，以促进协作稳定性和可持续性。", "motivation": "为了确保联邦学习中各参与方的利益最大化和合作稳定性，文章探讨了在大型网络环境中如何实现公平且有效的支付分配机制。", "method": "通过引入最小核心概念，并采用栈式修剪算法简化其实现，使该方法能够在保证精度的同时提高计算效率。这种方法旨在减少最大不满程度，确保任何潜在的子团体都没有脱离联盟的动力。", "result": "实验表明，所提出的机制能够准确识别关键贡献者和战略联盟，在联邦入侵检测等场景中证明了其有效性和可行性。", "conclusion": "本文提出的方法通过最小化支付分配中的不满意度来促进协作稳定性，有助于建立一个更加可持续的联邦学习生态系统。"}}
{"id": "2602.03386", "pdf": "https://arxiv.org/pdf/2602.03386", "abs": "https://arxiv.org/abs/2602.03386", "authors": ["Leif Doering", "Daniel Schmidt", "Moritz Melcher", "Sebastian Kassing", "Benedikt Wille", "Tilman Aach", "Simon Weissmann"], "title": "An Approximate Ascent Approach To Prove Convergence of PPO", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Proximal Policy Optimization (PPO) is among the most widely used deep reinforcement learning algorithms, yet its theoretical foundations remain incomplete. Most importantly, convergence and understanding of fundamental PPO advantages remain widely open. Under standard theory assumptions we show how PPO's policy update scheme (performing multiple epochs of minibatch updates on multi-use rollouts with a surrogate gradient) can be interpreted as approximated policy gradient ascent. We show how to control the bias accumulated by the surrogate gradients and use techniques from random reshuffling to prove a convergence theorem for PPO that sheds light on PPO's success. Additionally, we identify a previously overlooked issue in truncated Generalized Advantage Estimation commonly used in PPO. The geometric weighting scheme induces infinite mass collapse onto the longest $k$-step advantage estimator at episode boundaries. Empirical evaluations show that a simple weight correction can yield substantial improvements in environments with strong terminal signal, such as Lunar Lander.", "AI": {"tldr": "该论文探讨了PPO算法的收敛性，并提出了一种近似策略梯度上升的方法来解释其成功。", "motivation": "尽管PPO是一种广泛使用的深度强化学习算法，但它的理论基础尚未完全建立。特别是，其收敛性和基本优势的理解仍然存在空白。", "method": "论文通过控制代理梯度积累的偏差，并使用随机重排技术证明了PPO的一个收敛定理。此外，还识别了一个被忽视的问题：截断的优势估计在环境边界时会无限集中的问题。", "result": "实验证明了一种简单的权重修正方法可以在具有强烈终止信号的环境中（如Lunar Lander）带来显著改进。", "conclusion": "通过近似策略梯度上升解释了PPO的成功，并证明了其收敛性，同时揭示了一个被忽视的问题并提出了一个有效的解决方案。"}}
{"id": "2602.03380", "pdf": "https://arxiv.org/pdf/2602.03380", "abs": "https://arxiv.org/abs/2602.03380", "authors": ["Hao Fang", "Jinyu Li", "Jiawei Kong", "Tianqu Zhuang", "Kuofeng Gao", "Bin Chen", "Shu-Tao Xia", "Yaowei Wang"], "title": "Seeing Through the Chain: Mitigate Hallucination in Multimodal Reasoning Models via CoT Compression and Contrastive Preference Optimization", "categories": ["cs.CV"], "comment": null, "summary": "While multimodal reasoning models (MLRMs) have exhibited impressive capabilities, they remain prone to hallucinations, and effective solutions are still underexplored. In this paper, we experimentally analyze the hallucination cause and propose C3PO, a training-based mitigation framework comprising \\textbf{C}hain-of-Thought \\textbf{C}ompression and \\textbf{C}ontrastive \\textbf{P}reference \\textbf{O}ptimization. Firstly, we identify that introducing reasoning mechanisms exacerbates models' reliance on language priors while overlooking visual inputs, which can produce CoTs with reduced visual cues but redundant text tokens. To this end, we propose to selectively filter redundant thinking tokens for a more compact and signal-efficient CoT representation that preserves task-relevant information while suppressing noise. In addition, we observe that the quality of the reasoning trace largely determines whether hallucination emerges in subsequent responses. To leverage this insight, we introduce a reasoning-enhanced preference tuning scheme that constructs training pairs using high-quality AI feedback. We further design a multimodal hallucination-inducing mechanism that elicits models' inherent hallucination patterns via carefully crafted inducers, yielding informative negative signals for contrastive correction. We provide theoretical justification for the effectiveness and demonstrate consistent hallucination reduction across diverse MLRMs and benchmarks.", "AI": {"tldr": "该论文提出了一种减少多模态推理模型中幻觉问题的框架C3PO，通过链式思维压缩和对比偏好优化来改进模型表现。", "motivation": "现有的多模态推理模型虽然表现出色但仍存在幻觉问题，缺乏有效的解决方法。因此提出了针对这一问题的研究方案。", "method": "首先通过引入链式思维压缩机制选择性地过滤冗余的思考令牌以减少视觉线索不足和文本标记冗余的问题；其次设计了一个改进的偏好调优计划来利用高质量的人工智能反馈进行训练，最后开发了一种多模态幻觉诱导机制。", "result": "该方法能够显著降低各种多模态推理模型在多个基准测试中的幻觉情况。", "conclusion": "所提出的C3PO框架有效地减少了多模态推理模型的幻觉问题，并提供了理论依据。"}}
{"id": "2602.03379", "pdf": "https://arxiv.org/pdf/2602.03379", "abs": "https://arxiv.org/abs/2602.03379", "authors": ["Sangyeon Yoon", "Hyesoo Hong", "Wonje Jeung", "Albert No"], "title": "Rethinking Benign Relearning: Syntax as the Hidden Driver of Unlearning Failures", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICLR 2026", "summary": "Machine unlearning aims to remove specific content from trained models while preserving overall performance. However, the phenomenon of benign relearning, in which forgotten information reemerges even from benign fine-tuning data, reveals that existing unlearning methods remain fundamentally fragile. A common explanation attributes this effect to topical relevance, but we find this account insufficient. Through systematic analysis, we demonstrate that syntactic similarity, rather than topicality, is the primary driver: across benchmarks, syntactically similar data consistently trigger recovery even without topical overlap, due to their alignment in representations and gradients with the forgotten content. Motivated by this insight, we introduce syntactic diversification, which paraphrases the original forget queries into heterogeneous structures prior to unlearning. This approach effectively suppresses benign relearning, accelerates forgetting, and substantially alleviates the trade-off between unlearning efficacy and model utility.", "AI": {"tldr": "本文重新思考了良性再学习现象，提出了语法多样化的解决方案来抑制良性再学习。", "motivation": "现有遗忘方法在处理特定内容时存在脆弱性，导致已忘记的信息会从看似无关的数据中恢复。这表明单纯依靠主题相关性的解释是不足的。", "method": "通过系统分析证明了语法规则相似性而非主题一致性才是良性再学习的主要驱动因素，并引入语法多样化的方法来解决这一问题。", "result": "该方法有效地抑制了良性再学习，加速了遗忘过程，并显著缓解了遗忘效率与模型效用之间的权衡关系。", "conclusion": "通过分析发现语法规则相似性是良性再学习的关键驱动因素，并提出了一种新的方法来解决这一问题。"}}
{"id": "2602.03376", "pdf": "https://arxiv.org/pdf/2602.03376", "abs": "https://arxiv.org/abs/2602.03376", "authors": ["Constantin Selzer", "Fabina B. Flohr"], "title": "PlanTRansformer: Unified Prediction and Planning with Goal-conditioned Transformer", "categories": ["cs.RO", "cs.CV"], "comment": "Submitted and accepted at IEEE IV 2026", "summary": "Trajectory prediction and planning are fundamental yet disconnected components in autonomous driving. Prediction models forecast surrounding agent motion under unknown intentions, producing multimodal distributions, while planning assumes known ego objectives and generates deterministic trajectories. This mismatch creates a critical bottleneck: prediction lacks supervision for agent intentions, while planning requires this information. Existing prediction models, despite strong benchmarking performance, often remain disconnected from planning constraints such as collision avoidance and dynamic feasibility. We introduce Plan TRansformer (PTR), a unified Gaussian Mixture Transformer framework integrating goal-conditioned prediction, dynamic feasibility, interaction awareness, and lane-level topology reasoning. A teacher-student training strategy progressively masks surrounding agent commands during training to align with inference conditions where agent intentions are unavailable. PTR achieves 4.3%/3.5% improvement in marginal/joint mAP compared to the baseline Motion Transformer (MTR) and 15.5% planning error reduction at 5s horizon compared to GameFormer. The architecture-agnostic design enables application to diverse Transformer-based prediction models. Project Website: https://github.com/SelzerConst/PlanTRansformer", "AI": {"tldr": "本文提出了一种名为PlanTRansformer的统一框架，该框架结合了目标条件预测、动态可行性和交互感知，并通过教师-学生训练策略提高了轨迹预测和规划性能。", "motivation": "在自主驾驶中，轨迹预测和规划是两个相互独立的关键部分。现有的预测模型虽然在基准测试方面表现出色，但仍与规划约束如碰撞避免和动态可行性不完全一致。这种脱节导致了预测缺乏对代理意图的监督，同时规划需要这些信息。", "method": "PlanTRansformer引入了一个统一的高斯混合变换器框架，结合目标条件预测、动态可行性和交互感知，并通过教师-学生训练策略，在推理过程中逐渐屏蔽周围代理命令以模仿实际情况中的不可用性。", "result": "与基线MotionTransformer相比，PlanTRansformer在边际和联合mAP方面分别提高了4.3%和3.5%，并在5秒的规划时间范围内减少了15.5%的规划错误。该架构独立设计使其可以应用于各种基于变换器的预测模型。", "conclusion": "通过结合目标条件预测、动态可行性和交互感知，PlanTRansformer显著改善了轨迹预测和规划性能，并展示了在实际应用中的潜在价值。"}}
{"id": "2602.03374", "pdf": "https://arxiv.org/pdf/2602.03374", "abs": "https://arxiv.org/abs/2602.03374", "authors": ["Danqing Shi", "Lan Jiang", "Katherine M. Collins", "Shangzhe Wu", "Ayush Tewari", "Miri Zilka"], "title": "How do people watch AI-generated videos of physical scenes?", "categories": ["cs.HC"], "comment": null, "summary": "The growing prevalence of realistic AI-generated videos on media platforms increasingly blurs the line between fact and fiction, eroding public trust. Understanding how people watch AI-generated videos offers a human-centered perspective for improving AI detection and guiding advancements in video generation. However, existing studies have not investigated human gaze behavior in response to AI-generated videos of physical scenes. Here, we collect and analyze the eye movements from 40 participants during video understanding and AI detection tasks involving a mix of real-world and AI-generated videos. We find that given the high realism of AI-generated videos, gaze behavior is driven less by the video's actual authenticity and more by the viewer's perception of its authenticity. Our results demonstrate that the mere awareness of potential AI generation may alter media consumption from passive viewing into an active search for anomalies.", "AI": {"tldr": "研究人们观看AI生成视频时的眼动行为，探讨真实性和感知真实性对眼动模式的影响。", "motivation": "随着AI生成的逼真视频日益增多，公众难以区分事实与虚构。本文旨在从人类视角改善AI检测方法，并指导视频生成技术的发展。", "method": "收集并分析了40名参与者在观看现实世界和AI生成视频时的眼动数据，通过理解和识别任务来探究眼动模式。", "result": "高逼真的AI视频使观众更多地根据感知真实性而非实际真实性进行注视行为。意识到潜在的AI生成可促使观众从被动观看转为主动寻找异常。", "conclusion": "此研究揭示了感知真实性对人们观看AI生成视频时的眼动行为有重大影响，强调提高公众意识的重要性。"}}
{"id": "2602.03373", "pdf": "https://arxiv.org/pdf/2602.03373", "abs": "https://arxiv.org/abs/2602.03373", "authors": ["Jiale Meng", "Runyi Hu", "Jie Zhang", "Zheming Lu", "Ivor Tsang", "Tianwei Zhang"], "title": "Unifying Watermarking via Dimension-Aware Mapping", "categories": ["cs.CV"], "comment": "29 pages, 25 figures", "summary": "Deep watermarking methods often share similar encoder-decoder architectures, yet differ substantially in their functional behaviors. We propose DiM, a new multi-dimensional watermarking framework that formulates watermarking as a dimension-aware mapping problem, thereby unifying existing watermarking methods at the functional level. Under DiM, watermark information is modeled as payloads of different dimensionalities, including one-dimensional binary messages, two-dimensional spatial masks, and three-dimensional spatiotemporal structures. We find that the dimensional configuration of embedding and extraction largely determines the resulting watermarking behavior. Same-dimensional mappings preserve payload structure and support fine-grained control, while cross-dimensional mappings enable spatial or spatiotemporal localization. We instantiate DiM in the video domain, where spatiotemporal representations enable a broader set of dimension mappings. Experiments demonstrate that varying only the embedding and extraction dimensions, without architectural changes, leads to different watermarking capabilities, including spatiotemporal tamper localization, local embedding control, and recovery of temporal order under frame disruptions.", "AI": {"tldr": "本文提出了DiM，一种新的多维水印框架，通过维度感知映射问题统一现有的水印方法。", "motivation": "深度水印技术尽管共享类似的编码器-解码器架构，但在功能行为上存在显著差异。作者希望通过设计一个通用的框架来解决这种功能性差异的问题。", "method": "DiM将水印信息建模为不同维度的数据包，并通过调整嵌入和提取维度来改变水印的行为方式，包括空间或时空定位。", "result": "实验显示，在仅改变嵌入和提取维度的情况下，可以实现不同的水印功能，例如时空篡改定位、局部嵌入控制以及在帧中断情况下恢复时间顺序。", "conclusion": "DiM框架能够通过灵活的维度配置来统一现有水印方法的功能行为，并且能够在视频领域中提供更广泛的维度映射能力。"}}
{"id": "2602.03372", "pdf": "https://arxiv.org/pdf/2602.03372", "abs": "https://arxiv.org/abs/2602.03372", "authors": ["Mario Pascual-González", "Ariadna Jiménez-Partinen", "R. M. Luque-Baena", "Fátima Nagib-Raya", "Ezequiel López-Rubio"], "title": "SLIM-Diff: Shared Latent Image-Mask Diffusion with Lp loss for Data-Scarce Epilepsy FLAIR MRI", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 2 figures, 1 table, conference paper", "summary": "Focal cortical dysplasia (FCD) lesions in epilepsy FLAIR MRI are subtle and scarce, making joint image--mask generative modeling prone to instability and memorization. We propose SLIM-Diff, a compact joint diffusion model whose main contributions are (i) a single shared-bottleneck U-Net that enforces tight coupling between anatomy and lesion geometry from a 2-channel image+mask representation, and (ii) loss-geometry tuning via a tunable $L_p$ objective. As an internal baseline, we include the canonical DDPM-style objective ($ε$-prediction with $L_2$ loss) and isolate the effect of prediction parameterization and $L_p$ geometry under a matched setup. Experiments show that $x_0$-prediction is consistently the strongest choice for joint synthesis, and that fractional sub-quadratic penalties ($L_{1.5}$) improve image fidelity while $L_2$ better preserves lesion mask morphology. Our code and model weights are available in https://github.com/MarioPasc/slim-diff", "AI": {"tldr": "提出了一种名为SLIM-Diff的共享潜在图像掩码扩散模型，用于处理癫痫FLAIR MRI中罕见且细微的皮层发育不良病变。", "motivation": "在癫痫FLAIR MRI中的FCD病灶因数量稀少和细节微弱而难以被准确识别或生成，现有的联合图像-掩膜生成建模方法容易出现不稳定性和过度拟合问题。", "method": "设计了一种具有共享瓶颈U-Net的紧凑型联合扩散模型，并通过可调节的$L_p$损失函数优化预测参数化和几何形状。实验中采用了$x_0$预测作为基准，同时评估了不同$L_p$范式的性能影响。", "result": "实验证明了$x_0$预测是最有效的合成选择方法，且使用分数次幂小于2的$L_{1.5}$损失可以提高图像保真度，而$L_2$损失则更有利于保持病变掩膜形态。", "conclusion": "通过采用共享瓶颈U-Net和可调节$L_p$损失函数的方法，SLIM-Diff模型能够在数据稀缺的情况下生成高质量且准确的皮层发育不良病灶FLAIR MRI图像。"}}
{"id": "2602.03371", "pdf": "https://arxiv.org/pdf/2602.03371", "abs": "https://arxiv.org/abs/2602.03371", "authors": ["Zhiwen Yang", "Yuxin Peng"], "title": "Multi-Resolution Alignment for Voxel Sparsity in Camera-Based 3D Semantic Scene Completion", "categories": ["cs.CV"], "comment": "15 pages, 6 figures, accepted by TIP 2026", "summary": "Camera-based 3D semantic scene completion (SSC) offers a cost-effective solution for assessing the geometric occupancy and semantic labels of each voxel in the surrounding 3D scene with image inputs, providing a voxel-level scene perception foundation for the perception-prediction-planning autonomous driving systems. Although significant progress has been made in existing methods, their optimization rely solely on the supervision from voxel labels and face the challenge of voxel sparsity as a large portion of voxels in autonomous driving scenarios are empty, which limits both optimization efficiency and model performance. To address this issue, we propose a \\textit{Multi-Resolution Alignment (MRA)} approach to mitigate voxel sparsity in camera-based 3D semantic scene completion, which exploits the scene and instance level alignment across multi-resolution 3D features as auxiliary supervision. Specifically, we first propose the Multi-resolution View Transformer module, which projects 2D image features into multi-resolution 3D features and aligns them at the scene level through fusing discriminative seed features. Furthermore, we design the Cubic Semantic Anisotropy module to identify the instance-level semantic significance of each voxel, accounting for the semantic differences of a specific voxel against its neighboring voxels within a cubic area. Finally, we devise a Critical Distribution Alignment module, which selects critical voxels as instance-level anchors with the guidance of cubic semantic anisotropy, and applies a circulated loss for auxiliary supervision on the critical feature distribution consistency across different resolutions. The code is available at https://github.com/PKU-ICST-MIPL/MRA_TIP.", "AI": {"tldr": "提出了一种多分辨率对齐方法，以解决基于相机的三维语义场景完成中的体素稀疏性问题。", "motivation": "现有方法依赖于体素标签监督，面临空闲体素过多导致优化效率低和模型性能受限的问题。", "method": "提出了多层次视图变换器模块、立方体语义各向异性模块以及关键分布对齐模块，通过多分辨率3D特征的场景级和实例级对齐来辅助监督。", "result": "方法有效减轻了基于相机的三维语义场景完成中的体素稀疏性问题。", "conclusion": "所提出的方法能够显著提高模型性能，特别是在处理空闲体素较多的情况下。"}}
{"id": "2602.03370", "pdf": "https://arxiv.org/pdf/2602.03370", "abs": "https://arxiv.org/abs/2602.03370", "authors": ["Takaya Kawakatsu", "Ryo Ishiyama"], "title": "Symbol-Aware Reasoning with Masked Discrete Diffusion for Handwritten Mathematical Expression Recognition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Handwritten Mathematical Expression Recognition (HMER) requires reasoning over diverse symbols and 2D structural layouts, yet autoregressive models struggle with exposure bias and syntactic inconsistency. We present a discrete diffusion framework that reformulates HMER as iterative symbolic refinement instead of sequential generation. Through multi-step remasking, the proposal progressively refines both symbols and structural relations, removing causal dependencies and improving structural consistency. A symbol-aware tokenization and Random-Masking Mutual Learning further enhance syntactic alignment and robustness to handwriting diversity. On the MathWriting benchmark, the proposal achieves 5.56\\% CER and 60.42\\% EM, outperforming strong Transformer and commercial baselines. Consistent gains on CROHME 2014--2023 demonstrate that discrete diffusion provides a new paradigm for structure-aware visual recognition beyond generative modeling.", "AI": {"tldr": "提出了一种基于离散扩散框架的手写数学表达式识别方法，通过符号感知的迭代细化来提高结构一致性和鲁棒性。", "motivation": "传统自回归模型在手写数学表达式识别中存在暴露偏差和语法不一致性问题，该论文旨在通过新的离散扩散框架解决这些问题。", "method": "引入多步掩码技术和符号感知标记化方法，逐步改进符号及其2D结构布局，消除了因果依赖性，并增强了语义对齐和鲁棒性。", "result": "在MathWriting基准上实现了5.56% CER和60.42% EM的性能，优于其他Transformer模型及商用基线。", "conclusion": "离散扩散框架为手写数学表达式识别提供了一种新的结构感知视觉识别范例，超越了传统的生成模型。"}}
{"id": "2602.03367", "pdf": "https://arxiv.org/pdf/2602.03367", "abs": "https://arxiv.org/abs/2602.03367", "authors": ["Minsung Yoon", "Heechan Shin", "Jeil Jeong", "Sung-Eui Yoon"], "title": "Learning-based Adaptive Control of Quadruped Robots for Active Stabilization on Moving Platforms", "categories": ["cs.RO"], "comment": "Accepted to IROS 2024. <a href=\"https://sgvr.kaist.ac.kr/~msyoon/papers/IROS24/\" rel=\"external noopener nofollow\" class=\"link-external link-https\">Project Page</a>", "summary": "A quadruped robot faces balancing challenges on a six-degrees-of-freedom moving platform, like subways, buses, airplanes, and yachts, due to independent platform motions and resultant diverse inertia forces on the robot. To alleviate these challenges, we present the Learning-based Active Stabilization on Moving Platforms (\\textit{LAS-MP}), featuring a self-balancing policy and system state estimators. The policy adaptively adjusts the robot's posture in response to the platform's motion. The estimators infer robot and platform states based on proprioceptive sensor data. For a systematic training scheme across various platform motions, we introduce platform trajectory generation and scheduling methods. Our evaluation demonstrates superior balancing performance across multiple metrics compared to three baselines. Furthermore, we conduct a detailed analysis of the \\textit{LAS-MP}, including ablation studies and evaluation of the estimators, to validate the effectiveness of each component.", "AI": {"tldr": "研究提出了一种基于学习的移动平台主动稳定技术（LAS-MP），用于提高四足机器人在六自由度运动平台上保持平衡的能力。", "motivation": "为了应对四足机器人在如地铁、公交车、飞机和游艇等复杂动态环境中由于独立平台运动引起的多样化惯性力造成的平衡挑战，研究提出了一种新的适应控制策略。", "method": "该方法包括自平衡策略和系统状态估计器。其中，自平衡策略根据平台运动调整机器人的姿态；状态估计器基于本体感觉传感器数据推断机器人和平台的状态。此外，还引入了生成和调度各种平台轨迹的方案以进行系统的训练。", "result": "实验表明，相比三个基线方法，在多个性能指标上，该研究提出的LAS-MP展示了优越的平衡能力。", "conclusion": "详细分析表明，所提出的自平衡策略和状态估计器在提升四足机器人动态环境下保持稳定方面有效。"}}
{"id": "2602.03361", "pdf": "https://arxiv.org/pdf/2602.03361", "abs": "https://arxiv.org/abs/2602.03361", "authors": ["Nikita Drozdov", "Andrey Lemeshko", "Nikita Gavrilov", "Anton Konushin", "Danila Rukhovich", "Maksim Kolodiazhnyi"], "title": "Z3D: Zero-Shot 3D Visual Grounding from Images", "categories": ["cs.CV"], "comment": null, "summary": "3D visual grounding (3DVG) aims to localize objects in a 3D scene based on natural language queries. In this work, we explore zero-shot 3DVG from multi-view images alone, without requiring any geometric supervision or object priors. We introduce Z3D, a universal grounding pipeline that flexibly operates on multi-view images while optionally incorporating camera poses and depth maps. We identify key bottlenecks in prior zero-shot methods causing significant performance degradation and address them with (i) a state-of-the-art zero-shot 3D instance segmentation method to generate high-quality 3D bounding box proposals and (ii) advanced reasoning via prompt-based segmentation, which utilizes full capabilities of modern VLMs. Extensive experiments on the ScanRefer and Nr3D benchmarks demonstrate that our approach achieves state-of-the-art performance among zero-shot methods. Code is available at https://github.com/col14m/z3d .", "AI": {"tldr": "该论文提出了Z3D，一种零样本三维视觉定位系统，仅通过多视图图像即可实现对象的三维定位。", "motivation": "该研究旨在探索无需任何几何监督或物体先验知识的情况下从多视图图像中进行零样本三维视觉定位的方法。", "method": "提出了一个通用的定位流水线Z3D，它可以在多视角图像上灵活运行，并可选择性地将相机姿态和深度图纳入其中。通过一种先进的提示式分割方法解决先前零样本方法中的瓶颈问题，同时利用现代视觉语言模型的能力。", "result": "在ScanRefer和Nr3D基准测试上的实验结果表明，该方法达到了零样本方法中的最佳性能。", "conclusion": "Z3D系统成功地解决了零样本三维视觉定位任务，并且优于现有的其他零样本方法。"}}
{"id": "2602.03359", "pdf": "https://arxiv.org/pdf/2602.03359", "abs": "https://arxiv.org/abs/2602.03359", "authors": ["Ning Ding", "Fangcheng Liu", "Kyungrae Kim", "Linji Hao", "Kyeng-Hun Lee", "Hyeonmok Ko", "Yehui Tang"], "title": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Scaling Large Language Models (LLMs) typically relies on increasing the number of parameters or test-time computations to boost performance. However, these strategies are impractical for edge device deployment due to limited RAM and NPU resources. Despite hardware constraints, deploying performant LLM on edge devices such as smartphone remains crucial for user experience. To address this, we propose MeKi (Memory-based Expert Knowledge Injection), a novel system that scales LLM capacity via storage space rather than FLOPs. MeKi equips each Transformer layer with token-level memory experts that injects pre-stored semantic knowledge into the generation process. To bridge the gap between training capacity and inference efficiency, we employ a re-parameterization strategy to fold parameter matrices used during training into a compact static lookup table. By offloading the knowledge to ROM, MeKi decouples model capacity from computational cost, introducing zero inference latency overhead. Extensive experiments demonstrate that MeKi significantly outperforms dense LLM baselines with identical inference speed, validating the effectiveness of memory-based scaling paradigm for on-device LLMs. Project homepage is at https://github.com/ningding-o/MeKi.", "AI": {"tldr": "提出了一种基于存储空间而非FLOPs来扩展大规模语言模型容量的方法MeKi，该方法通过在生成过程中注入预存的语义知识以提高边缘设备上的LLM性能。", "motivation": "现有策略依赖于增加参数数量或测试时计算量来提升LLM性能，但在边缘设备上部署这些方法因硬件限制而难以实现。为了克服这一挑战，需要一种新的解决方案来在不增加计算成本的情况下扩展模型容量。", "method": "MeKi通过为每个Transformer层提供令牌级的记忆专家，以注入预存的语义知识到生成过程中，从而利用存储空间而不是FLOPs来扩展LLM的容量。采用重新参数化策略将训练时使用的参数矩阵折叠成紧凑的静态查找表，并将其知识卸载到ROM中，这使得模型容量与计算成本脱钩。", "result": "实验结果表明，MeKi在保持相同推理速度的情况下显著优于密集LLM基准，验证了基于存储空间扩展方法的有效性。", "conclusion": "通过引入记忆专家将预存的语义知识注入生成过程，MeKi成功地实现了模型容量的扩展而无需增加计算成本，在边缘设备上提供了高效的LLM性能。"}}
{"id": "2602.03358", "pdf": "https://arxiv.org/pdf/2602.03358", "abs": "https://arxiv.org/abs/2602.03358", "authors": ["Junmo Cho", "Suhan Kim", "Sangjune An", "Minsu Kim", "Dong Bok Lee", "Heejun Lee", "Sung Ju Hwang", "Hae Beom Lee"], "title": "GFlowPO: Generative Flow Network as a Language Model Prompt Optimizer", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Finding effective prompts for language models (LMs) is critical yet notoriously difficult: the prompt space is combinatorially large, rewards are sparse due to expensive target-LM evaluation. Yet, existing RL-based prompt optimizers often rely on on-policy updates and a meta-prompt sampled from a fixed distribution, leading to poor sample efficiency. We propose GFlowPO, a probabilistic prompt optimization framework that casts prompt search as a posterior inference problem over latent prompts regularized by a meta-prompted reference-LM prior. In the first step, we fine-tune a lightweight prompt-LM with an off-policy Generative Flow Network (GFlowNet) objective, using a replay-based training policy that reuses past prompt evaluations to enable sample-efficient exploration. In the second step, we introduce Dynamic Memory Update (DMU), a training-free mechanism that updates the meta-prompt by injecting both (i) diverse prompts from a replay buffer and (ii) top-performing prompts from a small priority queue, thereby progressively concentrating the search process on high-reward regions. Across few-shot text classification, instruction induction benchmarks, and question answering tasks, GFlowPO consistently outperforms recent discrete prompt optimization baselines.", "AI": {"tldr": "本文提出了一种名为GFlowPO的概率提示优化框架，用于语言模型的有效提示搜索。", "motivation": "找到有效的语言模型提示既重要又困难。现有基于强化学习的提示优化器通常依赖于在线策略更新和从固定分布采样的元提示，导致样本效率低下。", "method": "提出了一种名为GFlowPO的概率提示优化框架，该框架将提示搜索视为对潜在提示的后验推理问题，并使用轻量级提示语言模型进行训练。引入了动态内存更新机制以提高性能。", "result": "在少样本文本分类、指令诱导基准和问答任务中，GFlowPO始终优于最近的离散提示优化基线。", "conclusion": "通过引入新的概率框架和有效的机制来提高样本效率和搜索质量，证明了GFlowPO的有效性。"}}
{"id": "2602.03355", "pdf": "https://arxiv.org/pdf/2602.03355", "abs": "https://arxiv.org/abs/2602.03355", "authors": ["Chang Li", "Kanglei Zhou", "Liyuan Wang"], "title": "PACE: Pretrained Audio Continual Learning", "categories": ["cs.SD", "cs.LG"], "comment": "Accepted at ICLR 2026", "summary": "Audio is a fundamental modality for analyzing speech, music, and environmental sounds. Although pretrained audio models have significantly advanced audio understanding, they remain fragile in real-world settings where data distributions shift over time. In this work, we present the first systematic benchmark for audio continual learning (CL) with pretrained models (PTMs), together with a comprehensive analysis of its unique challenges. Unlike in vision, where parameter-efficient fine-tuning (PEFT) has proven effective for CL, directly transferring such strategies to audio leads to poor performance. This stems from a fundamental property of audio backbones: they focus on low-level spectral details rather than structured semantics, causing severe upstream-downstream misalignment. Through extensive empirical study, we identify analytic classifiers with first-session adaptation (FSA) as a promising direction, but also reveal two major limitations: representation saturation in coarse-grained scenarios and representation drift in fine-grained scenarios. To address these challenges, we propose PACE, a novel method that enhances FSA via a regularized analytic classifier and enables multi-session adaptation through adaptive subspace-orthogonal PEFT for improved semantic alignment. In addition, we introduce spectrogram-based boundary-aware perturbations to mitigate representation overlap and improve stability. Experiments on six diverse audio CL benchmarks demonstrate that PACE substantially outperforms state-of-the-art baselines, marking an important step toward robust and scalable audio continual learning with PTMs.", "AI": {"tldr": "提出PACE方法以解决音频连续学习中的表示饱和和漂移问题，提高预训练模型在数据分布变化时的鲁棒性。", "motivation": "现有视觉领域有效的参数高效微调策略直接应用于音频会导致性能下降，因为音频基础架构更侧重于低级频谱细节而非结构化语义，这导致了严重的上下文不匹配。为了改进这一状况，提出PACE方法来解决这些挑战。", "method": "通过使用正则化的分析分类器增强首次会话适应，并引入基于光谱图的边界感知扰动以减少表示重叠并提高稳定性；此外还提出了自适应子空间-正交参数高效微调策略实现多会话适应，从而改善语义对齐。", "result": "在六个不同的音频连续学习基准测试中进行实验表明PACE方法显著优于现有的最佳基线。", "conclusion": "通过引入PACE解决了预训练模型在处理数据分布随时间变化时面临的问题，并为更稳健、可扩展的音频持续学习奠定了基础。"}}
{"id": "2602.03353", "pdf": "https://arxiv.org/pdf/2602.03353", "abs": "https://arxiv.org/abs/2602.03353", "authors": ["Nang Hung Nguyen", "Phi Le Nguyen", "Thao Nguyen Truong", "Trong Nghia Hoang", "Masashi Sugiyama"], "title": "Causal Graph Learning via Distributional Invariance of Cause-Effect Relationship", "categories": ["cs.LG", "cs.AI"], "comment": "ef:Transactions on Machine Learning Research (Jan 2026)", "summary": "This paper introduces a new framework for recovering causal graphs from observational data, leveraging the observation that the distribution of an effect, conditioned on its causes, remains invariant to changes in the prior distribution of those causes. This insight enables a direct test for potential causal relationships by checking the variance of their corresponding effect-cause conditional distributions across multiple downsampled subsets of the data. These subsets are selected to reflect different prior cause distributions, while preserving the effect-cause conditional relationships. Using this invariance test and exploiting an (empirical) sparsity of most causal graphs, we develop an algorithm that efficiently uncovers causal relationships with quadratic complexity in the number of observational variables, reducing the processing time by up to 25x compared to state-of-the-art methods. Our empirical experiments on a varied benchmark of large-scale datasets show superior or equivalent performance compared to existing works, while achieving enhanced scalability.", "AI": {"tldr": "本文提出了一种新的框架，通过观察数据恢复因果图，利用因变量的分布条件不变性来直接测试潜在的因果关系。", "motivation": "利用观测到的现象即在给定原因的情况下，效果的分布不受先验原因分布变化的影响，从而更有效地从观测数据中识别因果关系。", "method": "开发了一种算法，该算法通过检查多个下采样子集的效果-原因条件分布的变化来测试不变性，并且考虑到大多数因果图的实际稀疏特性，以二次复杂度在变量数量上高效地发现因果关系。", "result": "实验证明了所提方法的优越性能和增强的可扩展性，在大规模数据集中表现优于或等同于现有工作。", "conclusion": "该研究提出的方法能够更准确、更快速地识别因果图，同时保持较高的处理效率和良好的泛化能力。"}}
{"id": "2602.03351", "pdf": "https://arxiv.org/pdf/2602.03351", "abs": "https://arxiv.org/abs/2602.03351", "authors": ["Mayank Goel", "Aritra Das", "Paras Chopra"], "title": "Building Interpretable Models for Moral Decision-Making", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "8 pages, 4 figures, accepted to AAAI'26 Machine Ethics Workshop", "summary": "We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy on Moral Machine data while remaining small enough for detailed analysis. We use different interpretability techniques to uncover how moral reasoning distributes across the network, demonstrating that biases localize to distinct computational stages among other findings.", "AI": {"tldr": "构建解释性模型以研究神经网络在类似电车难题的道德决策中的工作方式。", "motivation": "通过理解和分析神经网络如何进行道德决策，提高模型的透明度和可靠性。", "method": "使用自定义Transformer架构处理结构化场景，并应用嵌入编码来表示受影响的人、人数及结果归属。采用不同的解释性技术揭示整个网络中的道德推理分布情况。", "result": "2层架构在Moral Machine数据上达到77%的准确率，同时保持模型足够小以便详细分析。", "conclusion": "展示偏见如何集中在特定计算阶段，并通过多种解释性技术展示了神经网络进行道德决策的具体过程。"}}
{"id": "2602.03350", "pdf": "https://arxiv.org/pdf/2602.03350", "abs": "https://arxiv.org/abs/2602.03350", "authors": ["Haegu Lee", "Yitaek Kim", "Casper Hewson Rask", "Christoffer Sloth"], "title": "Manipulation via Force Distribution at Contact", "categories": ["cs.RO"], "comment": null, "summary": "Efficient and robust trajectories play a crucial role in contact-rich manipulation, which demands accurate mod- eling of object-robot interactions. Many existing approaches rely on point contact models due to their computational effi- ciency. Simple contact models are computationally efficient but inherently limited for achieving human-like, contact-rich ma- nipulation, as they fail to capture key frictional dynamics and torque generation observed in human manipulation. This study introduces a Force-Distributed Line Contact (FDLC) model in contact-rich manipulation and compares it against conventional point contact models. A bi-level optimization framework is constructed, in which the lower-level solves an optimization problem for contact force computation, and the upper-level optimization applies iLQR for trajectory optimization. Through this framework, the limitations of point contact are demon- strated, and the benefits of the FDLC in generating efficient and robust trajectories are established. The effectiveness of the proposed approach is validated by a box rotating task, demonstrating that FDLC enables trajectories generated via non-uniform force distributions along the contact line, while requiring lower control effort and less motion of the robot.", "AI": {"tldr": "本文提出了一种力分布线接触模型（FDLC），用于解决点接触模型在复杂操作中无法准确捕捉摩擦动态和扭矩生成的问题，通过双层优化框架验证了其在减少控制努力和降低机器人运动方面的优势。", "motivation": "现有的点接触模型虽然计算效率高，但在实现类似人的、复杂的操纵任务时存在局限性，因为它们不能充分模拟真实的人类操作中的摩擦力动态和扭矩生成。因此本文提出了FDLC模型以解决这些问题。", "method": "构建了一个双层优化框架：下层用于求解接触力的计算问题；上层使用iLQR进行轨迹优化。通过该框架展示了点接触模型的局限性，并验证了FDLC在产生高效和鲁棒的轨迹方面的优势。", "result": "实验结果表明，与传统点接触方法相比，FDLC能够生成利用沿接触线非均匀力分布的方式产生的更有效的操作轨迹，同时减少了控制努力并降低了机器人的运动量。", "conclusion": "本文证明了在复杂操纵任务中使用FDLC可以有效提高机器人操作的效率和鲁棒性。"}}
{"id": "2602.03344", "pdf": "https://arxiv.org/pdf/2602.03344", "abs": "https://arxiv.org/abs/2602.03344", "authors": ["Shir Ashury-Tahan", "Ariel Gera", "Elron Bandel", "Michal Shmueli-Scheuer", "Leshem Choshen"], "title": "Robustness as an Emergent Property of Task Performance", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Robustness is often regarded as a critical future challenge for real-world applications, where stability is essential. However, as models often learn tasks in a similar order, we hypothesize that easier tasks will be easier regardless of how they are presented to the model. Indeed, in this paper, we show that as models approach high performance on a task, robustness is effectively achieved. Through an empirical analysis of multiple models across diverse datasets and configurations (e.g., paraphrases, different temperatures), we find a strong positive correlation. Moreover, we find that robustness is primarily driven by task-specific competence rather than inherent model-level properties, challenging current approaches that treat robustness as an independent capability. Thus, from a high-level perspective, we may expect that as new tasks saturate, model robustness on these tasks will emerge accordingly. For researchers, this implies that explicit efforts to measure and improve robustness may warrant reduced emphasis, as such robustness is likely to develop alongside performance gains. For practitioners, it acts as a sign that indeed the tasks that the literature deals with are unreliable, but on easier past tasks, the models are reliable and ready for real-world deployment.", "AI": {"tldr": "探讨模型在完成任务时鲁棒性的出现机制", "motivation": "探索为何当模型接近高表现时，会自然获得鲁棒性，并质疑是否需要独立提高模型的鲁棒性", "method": "通过多样化的数据集和配置进行实证分析，评估模型性能与鲁棒性的关系", "result": "发现随着任务性能提升，鲁棒性也随之增强，且鲁棒性主要由特定任务能力驱动而非模型本身的特性", "conclusion": "认为在完成新任务时，鲁棒性会自然出现，因此对研究人员而言减少直接提高鲁棒性的努力可能更有利；对于实践者来说，这意味着已解决的任务可视为可靠的，适合现实应用"}}
{"id": "2602.03342", "pdf": "https://arxiv.org/pdf/2602.03342", "abs": "https://arxiv.org/abs/2602.03342", "authors": ["Bryan Sangwoo Kim", "Jonghyun Park", "Jong Chul Ye"], "title": "Tiled Prompts: Overcoming Prompt Underspecification in Image and Video Super-Resolution", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "13 pages, 7 figures", "summary": "Text-conditioned diffusion models have advanced image and video super-resolution by using prompts as semantic priors, but modern super-resolution pipelines typically rely on latent tiling to scale to high resolutions, where a single global caption causes prompt underspecification. A coarse global prompt often misses localized details (prompt sparsity) and provides locally irrelevant guidance (prompt misguidance) that can be amplified by classifier-free guidance. We propose Tiled Prompts, a unified framework for image and video super-resolution that generates a tile-specific prompt for each latent tile and performs super-resolution under locally text-conditioned posteriors, providing high-information guidance that resolves prompt underspecification with minimal overhead. Experiments on high resolution real-world images and videos show consistent gains in perceptual quality and text alignment, while reducing hallucinations and tile-level artifacts relative to global-prompt baselines.", "AI": {"tldr": "提出了Tiled Prompts框架，用于解决图像和视频超分辨率中的提示不足问题", "motivation": "现代超分辨率管道依赖于潜在的镶嵌来扩展到高分辨率，单一全局提示会导致局部细节缺失和不相关指导", "method": "生成针对每个潜在图块的特定图块提示，并在本地文本条件下执行超分辨率", "result": "实验显示了相对于全球提示基线感知质量和文本对齐的一致性改进，减少了幻觉和图块级伪影", "conclusion": "Tiled Prompts框架解决了图像和视频超分辨率中的全局提示不足问题"}}
{"id": "2602.03340", "pdf": "https://arxiv.org/pdf/2602.03340", "abs": "https://arxiv.org/abs/2602.03340", "authors": ["Xiao Sun", "Yuming Yang", "Junnan Zhu", "Jiang Zhong", "Xinyu Zhou", "Kaiwen Wei"], "title": "MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis", "categories": ["cs.AI"], "comment": "36 pages, 27 figures", "summary": "Mental health disorders represent a burgeoning global public health challenge. While Large Language Models (LLMs) have demonstrated potential in psychiatric assessment, their clinical utility is severely constrained by benchmarks that lack ecological validity and fine-grained diagnostic supervision. To bridge this gap, we introduce \\textbf{MentalDx Bench}, the first benchmark dedicated to disorder-level psychiatric diagnosis within real-world clinical settings. Comprising 712 de-identified electronic health records annotated by board-certified psychiatrists under ICD-11 guidelines, the benchmark covers 76 disorders across 16 diagnostic categories. Evaluation of 18 LLMs reveals a critical \\textit{paradigm misalignment}: strong performance at coarse diagnostic categorization contrasts with systematic failure at disorder-level diagnosis, underscoring a gap between pattern-based modeling and clinical hypothetico-deductive reasoning. In response, we propose \\textbf{MentalSeek-Dx}, a medical-specialized LLM trained to internalize this clinical reasoning process through supervised trajectory construction and curriculum-based reinforcement learning. Experiments on MentalDx Bench demonstrate that MentalSeek-Dx achieves state-of-the-art (SOTA) performance with only 14B parameters, establishing a clinically grounded framework for reliable psychiatric diagnosis.", "AI": {"tldr": "MentalSeek-Dx 是一种通过监督轨迹构建和基于课程的强化学习训练的医学专业LLM，旨在实现临床假设演绎推理，并在 MentalDx Bench 上实现了最先进的表现。", "motivation": "目前大型语言模型在精神卫生评估中的应用受到基准测试缺乏生态有效性和精细诊断指导的限制。为了克服这一问题，作者提出了一个专注于真实世界精神病学诊断的新基准和相应的方法。", "method": "提出了一种新的医学专业LLM（MentalSeek-Dx），通过监督轨迹构建和基于课程的强化学习来训练该模型以模拟临床假设演绎推理。", "result": "在 MentalDx Bench 上，MentalSeek-Dx 达到了最先进的性能，并且只使用了14B参数。", "conclusion": "MentalSeek-Dx 建立了一个临床基础框架用于可靠的精神病学诊断。"}}
{"id": "2602.03339", "pdf": "https://arxiv.org/pdf/2602.03339", "abs": "https://arxiv.org/abs/2602.03339", "authors": ["Bingchen Zhao", "Qiushan Guo", "Ye Wang", "Yixuan Huang", "Zhonghua Zhai", "Yu Tian"], "title": "Composable Visual Tokenizers with Generator-Free Diagnostics of Learnability", "categories": ["cs.CV"], "comment": null, "summary": "We introduce CompTok, a training framework for learning visual tokenizers whose tokens are enhanced for compositionality. CompTok uses a token-conditioned diffusion decoder. By employing an InfoGAN-style objective, where we train a recognition model to predict the tokens used to condition the diffusion decoder using the decoded images, we enforce the decoder to not ignore any of the tokens. To promote compositional control, besides the original images, CompTok also trains on tokens formed by swapping token subsets between images, enabling more compositional control of the token over the decoder. As the swapped tokens between images do not have ground truth image targets, we apply a manifold constraint via an adversarial flow regularizer to keep unpaired swap generations on the natural-image distribution. The resulting tokenizer not only achieves state-of-the-art performance on image class-conditioned generation, but also demonstrates properties such as swapping tokens between images to achieve high level semantic editing of an image. Additionally, we propose two metrics that measures the landscape of the token space that can be useful to describe not only the compositionality of the tokens, but also how easy to learn the landscape is for a generator to be trained on this space. We show in experiments that CompTok can improve on both of the metrics as well as supporting state-of-the-art generators for class conditioned generation.", "AI": {"tldr": "本文介绍了一种名为CompTok的训练框架，该框架用于学习具有增强组合性的视觉标记化器。", "motivation": "通过引入一种能够促进图像间令牌交换和高语义编辑的新方法，从而提高生成模型的学习能力和表现力。", "method": "使用条件扩散解码器和信息GAN风格的目标函数来训练识别模型以预测用于条件解码器的标记。通过在原始图像和令牌子集之间交换形成的图像上进行训练，增强组合控制能力，并采用流对抗正则化方法保持未配对交换生成物的自然图象分布。", "result": "CompTok不仅实现了基于类别的图像生成任务上的最优性能，还展示了交换标记以实现高语义编辑的能力。此外，该研究提出两种衡量令牌空间景观的新指标，表明这些改进可以支持最先进的生成器在类别条件生成中的表现。", "conclusion": "通过优化令牌的组合性和可学习性，CompTok提供了一种新颖的方法来提高图像生成任务的表现，并为评估标记化器的有效性提供了新的工具。"}}
{"id": "2602.03337", "pdf": "https://arxiv.org/pdf/2602.03337", "abs": "https://arxiv.org/abs/2602.03337", "authors": ["Florian Ingels", "Antoine Limasset", "Camille Marchet", "Mikaël Salson"], "title": "Vigemers: on the number of $k$-mers sharing the same XOR-based minimizer", "categories": ["cs.DM", "cs.DS", "math.CO"], "comment": null, "summary": "In bioinformatics, minimizers have become an inescapable method for handling $k$-mers (words of fixed size $k$) extracted from DNA or RNA sequencing, whether for sampling, storage, querying or partitioning. According to some fixed order on $m$-mers ($m<k$), the minimizer of a $k$-mer is defined as its smallest $m$-mer -- and acts as its fingerprint. Although minimizers are widely used for partitioning purposes, there is almost no theoretical work on the quality of the resulting partitions. For instance, it has been known for decades that the lexicographic order empirically leads to highly unbalanced partitions that are unusable in practice, but it was not until very recently that this observation was theoretically substantiated. The rejection of the lexicographic order has led the community to resort to (pseudo-)random orders using hash functions. In this work, we extend the theoretical results relating to the partitions obtained by the lexicographical order, departing from it to a (exponentially) large family of hash functions, namely where the $m$-mers are XORed against a fixed key. More precisely, provided a key $γ$ and a $m$-mer $w$, we investigate the function that counts how many $k$-mers admit $w$ as their minimizer (i.e. where $w\\oplusγ$ is minimal among all $m$-mers of said $k$-mers). This number, denoted by $π_k^γ(w)$, represents the maximum size of the bucket associated with $w$, if all possible $k$-mers were to be seen and partitioned. We adapt the (lexicographical order) method of the literature to our framework and propose combinatorial equations that allow to compute, using dynamic programming, $π_k^γ(w)$ in $O(km^2)$ time and $O(km)$ space.", "AI": {"tldr": "本文研究了基于XOR操作的哈希函数生成的最小值在k-mer分区中的分布情况，提出了计算每个m-mer作为最小子集的数量的方法。", "motivation": "针对生物信息学中广泛使用的minimizer方法，目前对于非字典顺序下的理论分析不足。特别是使用随机或伪随机哈希函数时，缺乏对生成的分区质量的理解。", "method": "引入了XOR操作的哈希函数，并定义了一个计算给定m-mer作为最小值的k-mer数量的函数$π_k^γ(w)$。通过动态规划方法，在O(km²)时间复杂度和O(km)空间复杂度下解决了该问题。", "result": "提出了一个有效的算法，能够在指定的时间和空间复杂度内计算出每个m-mer作为最小值对应的k-mer数量，从而更好地理解基于XOR的哈希函数生成的分区质量。", "conclusion": "通过扩展现有理论成果到更广泛的哈希函数家族（如XOR操作），本文提供了对minimizer方法下分区质量的新见解，并为实际应用中的优化提供了基础。"}}
{"id": "2602.03333", "pdf": "https://arxiv.org/pdf/2602.03333", "abs": "https://arxiv.org/abs/2602.03333", "authors": ["Haoran Li", "Renyang Liu", "Hongjia Liu", "Chen Wang", "Long Yin", "Jian Xu"], "title": "PWAVEP: Purifying Imperceptible Adversarial Perturbations in 3D Point Clouds via Spectral Graph Wavelets", "categories": ["cs.CV"], "comment": "Accepted by WWW 2026", "summary": "Recent progress in adversarial attacks on 3D point clouds, particularly in achieving spatial imperceptibility and high attack performance, presents significant challenges for defenders. Current defensive approaches remain cumbersome, often requiring invasive model modifications, expensive training procedures or auxiliary data access. To address these threats, in this paper, we propose a plug-and-play and non-invasive defense mechanism in the spectral domain, grounded in a theoretical and empirical analysis of the relationship between imperceptible perturbations and high-frequency spectral components. Building upon these insights, we introduce a novel purification framework, termed PWAVEP, which begins by computing a spectral graph wavelet domain saliency score and local sparsity score for each point. Guided by these values, PWAVEP adopts a hierarchical strategy, it eliminates the most salient points, which are identified as hardly recoverable adversarial outliers. Simultaneously, it applies a spectral filtering process to a broader set of moderately salient points. This process leverages a graph wavelet transform to attenuate high-frequency coefficients associated with the targeted points, thereby effectively suppressing adversarial noise. Extensive evaluations demonstrate that the proposed PWAVEP achieves superior accuracy and robustness compared to existing approaches, advancing the state-of-the-art in 3D point cloud purification. Code and datasets are available at https://github.com/a772316182/pwavep", "AI": {"tldr": "提出了一种新的在谱域中净化3D点云的防御机制PWAVEP，以解决对抗攻击带来的挑战。", "motivation": "为了应对当前防御方法存在的复杂性和侵入性问题，开发一种简单且非侵入性的防护措施来提高3D点云的安全性。", "method": "通过计算每个点的谱图波浪域重要度得分和局部稀疏度得分，采用分层策略消除难以恢复的对抗异常值，并对中等重要的点进行谱滤波处理以降低高频系数。", "result": "实验结果表明，提出的PWAVEP在精度和鲁棒性方面优于现有方法，实现了3D点云净化领域的最新成果。", "conclusion": "PWAVEP通过有效地减少高频率成分来抑制对抗噪声，展示了强大的防御性能。"}}
{"id": "2602.03327", "pdf": "https://arxiv.org/pdf/2602.03327", "abs": "https://arxiv.org/abs/2602.03327", "authors": ["Manuel Hofer", "Markus Steinberger", "Thomas Köhler"], "title": "Pi-GS: Sparse-View Gaussian Splatting with Dense π^3 Initialization", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Novel view synthesis has evolved rapidly, advancing from Neural Radiance Fields to 3D Gaussian Splatting (3DGS), which offers real-time rendering and rapid training without compromising visual fidelity. However, 3DGS relies heavily on accurate camera poses and high-quality point cloud initialization, which are difficult to obtain in sparse-view scenarios. While traditional Structure from Motion (SfM) pipelines often fail in these settings, existing learning-based point estimation alternatives typically require reliable reference views and remain sensitive to pose or depth errors. In this work, we propose a robust method utilizing π^3, a reference-free point cloud estimation network. We integrate dense initialization from π^3 with a regularization scheme designed to mitigate geometric inaccuracies. Specifically, we employ uncertainty-guided depth supervision, normal consistency loss, and depth warping. Experimental results demonstrate that our approach achieves state-of-the-art performance on the Tanks and Temples, LLFF, DTU, and MipNeRF360 datasets.", "AI": {"tldr": "本文提出了Pi-GS方法，利用π^3网络进行无参考点云初始化，并结合深度监督和几何一致性损失来提高稀疏视角下的三维场景合成性能。", "motivation": "现有的3D Gaussian Splatting方法在处理稀疏视图数据时依赖准确的相机姿态和高质量的初始点云，而这些信息难以获得。本文旨在提出一种新的方法解决这些问题，并提升合成效果。", "method": "作者使用了π^3网络来获取无参考的密集初始化点云，结合不确定性引导的深度监督、法线一致性损失以及深度变换技术，以减少几何不准确性和提高整体性能。", "result": "实验结果表明，在Tanks and Temples, LLFF, DTU和MipNeRF360等数据集上，该方法达到了最先进的性能水平。", "conclusion": "通过采用π^3初始化并引入新的正则化方案，本文提出的方法能够在稀疏视图场景下取得更好的三维合成结果，展示了在实际应用中的潜力。"}}
{"id": "2602.03320", "pdf": "https://arxiv.org/pdf/2602.03320", "abs": "https://arxiv.org/abs/2602.03320", "authors": ["Shengyuan Liu", "Liuxin Bao", "Qi Yang", "Wanting Geng", "Boyun Zheng", "Chenxin Li", "Wenting Chen", "Houwen Peng", "Yixuan Yuan"], "title": "MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning", "categories": ["cs.CV", "cs.AI"], "comment": "23 Pages, 4 Figures", "summary": "Medical image segmentation is evolving from task-specific models toward generalizable frameworks. Recent research leverages Multi-modal Large Language Models (MLLMs) as autonomous agents, employing reinforcement learning with verifiable reward (RLVR) to orchestrate specialized tools like the Segment Anything Model (SAM). However, these approaches often rely on single-turn, rigid interaction strategies and lack process-level supervision during training, which hinders their ability to fully exploit the dynamic potential of interactive tools and leads to redundant actions. To bridge this gap, we propose MedSAM-Agent, a framework that reformulates interactive segmentation as a multi-step autonomous decision-making process. First, we introduce a hybrid prompting strategy for expert-curated trajectory generation, enabling the model to internalize human-like decision heuristics and adaptive refinement strategies. Furthermore, we develop a two-stage training pipeline that integrates multi-turn, end-to-end outcome verification with a clinical-fidelity process reward design to promote interaction parsimony and decision efficiency. Extensive experiments across 6 medical modalities and 21 datasets demonstrate that MedSAM-Agent achieves state-of-the-art performance, effectively unifying autonomous medical reasoning with robust, iterative optimization. Code is available \\href{https://github.com/CUHK-AIM-Group/MedSAM-Agent}{here}.", "AI": {"tldr": "提出MedSAM-Agent框架，改进医学图像分割交互式决策过程。", "motivation": "现有方法依赖单一回合互动策略和缺乏训练过程中动态潜力的充分利用。", "method": "引入混合提示策略生成专家轨迹；开发两阶段训练管道整合多回互动态验证与临床真实奖励设计。", "result": "MedSAM-Agent在6种医学模式下实现最优性能，促进自主决策效率。", "conclusion": "框架有效结合了自主医疗推理和迭代优化。"}}
{"id": "2602.03317", "pdf": "https://arxiv.org/pdf/2602.03317", "abs": "https://arxiv.org/abs/2602.03317", "authors": ["Alex Finkelstein", "Ron Moneta", "Or Zohar", "Michal Rivlin", "Moritz Zaiss", "Dinora Friedmann Morvinski", "Or Perlman"], "title": "Multiparameter Uncertainty Mapping in Quantitative Molecular MRI using a Physics-Structured Variational Autoencoder (PS-VAE)", "categories": ["stat.ML", "cs.AI", "cs.LG", "physics.med-ph"], "comment": "Submitted to IEEE Transactions on Medical Imaging. This project was funded by the European Union (ERC, BabyMagnet, project no. 101115639). Views and opinions expressed are, however, those of the authors only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them", "summary": "Quantitative imaging methods, such as magnetic resonance fingerprinting (MRF), aim to extract interpretable pathology biomarkers by estimating biophysical tissue parameters from signal evolutions. However, the pattern-matching algorithms or neural networks used in such inverse problems often lack principled uncertainty quantification, which limits the trustworthiness and transparency, required for clinical acceptance. Here, we describe a physics-structured variational autoencoder (PS-VAE) designed for rapid extraction of voxelwise multi-parameter posterior distributions. Our approach integrates a differentiable spin physics simulator with self-supervised learning, and provides a full covariance that captures the inter-parameter correlations of the latent biophysical space. The method was validated in a multi-proton pool chemical exchange saturation transfer (CEST) and semisolid magnetization transfer (MT) molecular MRF study, across in-vitro phantoms, tumor-bearing mice, healthy human volunteers, and a subject with glioblastoma. The resulting multi-parametric posteriors are in good agreement with those calculated using a brute-force Bayesian analysis, while providing an orders-of-magnitude acceleration in whole brain quantification. In addition, we demonstrate how monitoring the multi-parameter posterior dynamics across progressively acquired signals provides practical insights for protocol optimization and may facilitate real-time adaptive acquisition.", "AI": {"tldr": "利用物理学结构化的变分自动编码器(PS-VAE)从分子MRI中快速提取多参数后验分布。", "motivation": "传统方法在解决逆问题时缺乏原则性的不确定性量化，限制了其可信度和透明性。提出一种结合可微旋物理模拟器的自监督学习的新方法以提供完整协方差。", "method": "开发了一种物理学结构化的变分自动编码器(PS-VAE)，并将其应用于多质子池化学交换饱和转移(MR)F和半固体磁化转移(MT)研究，使用来自不同样本的信号来验证其性能。", "result": "该方法得到的结果与采用暴力贝叶斯分析法获得的结果一致，并且在全脑量化过程中速度提高了数个数量级。此外，通过监测逐步获取信号中的多参数后验动态变化可以提供实用见解以优化协议并可能实现实时自适应采集。", "conclusion": "PS-VAE能够快速、准确地提取多参数后验分布，并有助于逆问题解决和协议优化以及实时调整采集策略的效率。"}}
{"id": "2602.03316", "pdf": "https://arxiv.org/pdf/2602.03316", "abs": "https://arxiv.org/abs/2602.03316", "authors": ["Ting Xiang", "Jinhui Zhao", "Changjian Chen", "Zhuo Tang"], "title": "Invisible Clean-Label Backdoor Attacks for Generative Data Augmentation", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid advancement of image generative models, generative data augmentation has become an effective way to enrich training images, especially when only small-scale datasets are available. At the same time, in practical applications, generative data augmentation can be vulnerable to clean-label backdoor attacks, which aim to bypass human inspection. However, based on theoretical analysis and preliminary experiments, we observe that directly applying existing pixel-level clean-label backdoor attack methods (e.g., COMBAT) to generated images results in low attack success rates. This motivates us to move beyond pixel-level triggers and focus instead on the latent feature level. To this end, we propose InvLBA, an invisible clean-label backdoor attack method for generative data augmentation by latent perturbation. We theoretically prove that the generalization of the clean accuracy and attack success rates of InvLBA can be guaranteed. Experiments on multiple datasets show that our method improves the attack success rate by 46.43% on average, with almost no reduction in clean accuracy and high robustness against SOTA defense methods.", "AI": {"tldr": "提出了一种针对生成数据增强的隐形清洁标签后门攻击方法InvLBA，通过潜在扰动实现。", "motivation": "现有像素级清洁标签后门攻击方法在生成图像上的成功率低，因此转向研究基于潜在特征级别的攻击策略。", "method": "设计了基于潜在扰动的隐形清洁标签后门攻击方法InvLBA，并理论证明其准确性和攻击成功率可以得到保证。", "result": "实验表明，该方法将攻击成功率提高了46.43%，同时几乎不影响清洁精度和具备较高的防御对抗性。", "conclusion": "通过潜在扰动实现的隐形清洁标签后门攻击方法有效提升了生成数据增强的安全威胁，并展示了其高稳健性和有效性。"}}
{"id": "2602.03315", "pdf": "https://arxiv.org/pdf/2602.03315", "abs": "https://arxiv.org/abs/2602.03315", "authors": ["Menglin Xia", "Xuchao Zhang", "Shantanu Dixit", "Paramaguru Harimurugan", "Rujia Wang", "Victor Ruhle", "Robert Sim", "Chetan Bansal", "Saravan Rajmohan"], "title": "Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity", "categories": ["cs.AI"], "comment": null, "summary": "Agent memory systems must accommodate continuously growing information while supporting efficient, context-aware retrieval for downstream tasks. Abstraction is essential for scaling agent memory, yet it often comes at the cost of specificity, obscuring the fine-grained details required for effective reasoning. We introduce Memora, a harmonic memory representation that structurally balances abstraction and specificity. Memora organizes information via its primary abstractions that index concrete memory values and consolidate related updates into unified memory entries, while cue anchors expand retrieval access across diverse aspects of the memory and connect related memories. Building on this structure, we employ a retrieval policy that actively exploits these memory connections to retrieve relevant information beyond direct semantic similarity. Theoretically, we show that standard Retrieval-Augmented Generation (RAG) and Knowledge Graph (KG)-based memory systems emerge as special cases of our framework. Empirically, Memora establishes a new state-of-the-art on the LoCoMo and LongMemEval benchmarks, demonstrating better retrieval relevance and reasoning effectiveness as memory scales.", "AI": {"tldr": "Memora 是一种平衡抽象与具体性的记忆表示方法，适用于大规模信息存储和高效检索。", "motivation": "传统的代理内存系统在处理不断增长的信息时面临挑战，即需要支持高效的上下文感知检索同时保持抽象性和具体性之间的平衡。", "method": "通过组织信息的初级抽象来索引具体的内存值，并合并相关更新以形成统一的记忆条目。此外，使用提示锚点扩展检索访问范围和连接相关的记忆，以此改进标准 Retrieval-Augmented Generation (RAG) 和知识图谱 (KG)- 基于记忆系统。", "result": "实验结果表明，在 LoCoMo 和 LongMemEval 指标上，Memora 达到了新的最先进性能，并且随着内存规模的增加，检索的相关性和推理的有效性得到了提高。", "conclusion": "本文提出了 Memora，这是一种在代理记忆系统中平衡抽象和具体性的方法。它展示了比现有技术更好的信息检索效果，并且适用于大规模的记忆场景。"}}
{"id": "2602.03314", "pdf": "https://arxiv.org/pdf/2602.03314", "abs": "https://arxiv.org/abs/2602.03314", "authors": ["Lei Deng", "Wenhao Huang", "Chao Yang", "Haoyuan Zheng", "Yinbin Tian", "Yue Ma"], "title": "PQTNet: Pixel-wise Quantitative Thermography Neural Network for Estimating Defect Depth in Polylactic Acid Parts by Additive Manufacturing", "categories": ["cs.CV"], "comment": "Under review", "summary": "Defect depth quantification in additively manufactured (AM) components remains a significant challenge for non-destructive testing (NDT). This study proposes a Pixel-wise Quantitative Thermography Neural Network (PQT-Net) to address this challenge for polylactic acid (PLA) parts. A key innovation is a novel data augmentation strategy that reconstructs thermal sequence data into two-dimensional stripe images, preserving the complete temporal evolution of heat diffusion for each pixel. The PQT-Net architecture incorporates a pre-trained EfficientNetV2-S backbone and a custom Residual Regression Head (RRH) with learnable parameters to refine outputs. Comparative experiments demonstrate the superiority of PQT-Net over other deep learning models, achieving a minimum Mean Absolute Error (MAE) of 0.0094 mm and a coefficient of determination (R) exceeding 99%. The high precision of PQT-Net underscores its potential for robust quantitative defect characterization in AM.", "AI": {"tldr": "提出了一种像素级定量热成像神经网络（PQTNet），用于评估增材制造中聚乳酸零件的缺陷深度。", "motivation": "解决非破坏性测试中对增材制造部件缺陷深度量化的问题，以提高检测精度和可靠性。", "method": "设计了一个新的数据增强策略，将热序列数据重构为二维条纹图像，并利用预训练的EfficientNetV2-S骨干网络及自定义残差回归头（RRH），实现高精度的缺陷深度估计。", "result": "实验结果表明，PQTNet在最小均方误差（MAE）方面优于其他深度学习模型，达到0.0094毫米，并且决定系数超过99%。", "conclusion": "该网络具有对增材制造中聚乳酸零件缺陷进行精确量化的能力，展示了其在非破坏性测试中的应用潜力。"}}
{"id": "2602.03310", "pdf": "https://arxiv.org/pdf/2602.03310", "abs": "https://arxiv.org/abs/2602.03310", "authors": ["Songming Liu", "Bangguo Li", "Kai Ma", "Lingxuan Wu", "Hengkai Tan", "Xiao Ouyang", "Hang Su", "Jun Zhu"], "title": "RDT2: Exploring the Scaling Limit of UMI Data Towards Zero-Shot Cross-Embodiment Generalization", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Vision-Language-Action (VLA) models hold promise for generalist robotics but currently struggle with data scarcity, architectural inefficiencies, and the inability to generalize across different hardware platforms. We introduce RDT2, a robotic foundation model built upon a 7B parameter VLM designed to enable zero-shot deployment on novel embodiments for open-vocabulary tasks. To achieve this, we collected one of the largest open-source robotic datasets--over 10,000 hours of demonstrations in diverse families--using an enhanced, embodiment-agnostic Universal Manipulation Interface (UMI). Our approach employs a novel three-stage training recipe that aligns discrete linguistic knowledge with continuous control via Residual Vector Quantization (RVQ), flow-matching, and distillation for real-time inference. Consequently, RDT2 becomes one of the first models that simultaneously zero-shot generalizes to unseen objects, scenes, instructions, and even robotic platforms. Besides, it outperforms state-of-the-art baselines in dexterous, long-horizon, and dynamic downstream tasks like playing table tennis. See https://rdt-robotics.github.io/rdt2/ for more information.", "AI": {"tldr": "研究介绍了RDT2，一种能够在不同硬件平台上实现零样本泛化的机器人基础模型。", "motivation": "现有的视觉-语言-动作（VLA）模型在数据稀缺、架构效率低下以及跨平台泛化方面存在挑战。为了解决这些问题，研发了RDT2。", "method": "通过收集超过10,000小时的多样化家庭演示来构建大规模开放源代码机器人数据集，并利用增强型通用操纵接口（UMI）。采用三阶段训练方法，包括残差向量量化(RVQ)、流匹配和蒸馏技术，实现离散语言知识与连续控制之间的对齐。", "result": "RDT2成为首个能够零样本泛化到未见过的对象、场景指令以及机器人平台的模型。在诸如乒乓球这类灵巧性任务上，它超越了现有最佳基准线的表现。", "conclusion": "通过创新方法和大规模数据集，RDT2展示了其在处理多样性和跨平台通用性的强大能力。"}}
{"id": "2602.03309", "pdf": "https://arxiv.org/pdf/2602.03309", "abs": "https://arxiv.org/abs/2602.03309", "authors": ["Yuelin Hu", "Zhengxue Cheng", "Wei Liu", "Li Song"], "title": "Entropy-Gated Selective Policy Optimization:Token-Level Gradient Allocation for Hybrid Training of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "accepted by cscwd2026", "summary": "Hybrid training methods for large language models combine supervised fine tuning (SFT) on expert demonstrations with reinforcement learning (RL) on model rollouts, typically at the sample level. We propose Entropy Gated Selective Policy Optimization (EGSPO), a three stage framework that extends sample level mixing with token level gradient modulation. Stage 1, SFT expert learning, establishes a reliable warm up policy using expert demonstrations with a pure SFT loss. Stage 2, RL rollout generation, samples trajectories from the current policy and computes per token predictive entropy. Stage 3, the EGSPO mechanism, applies entropy gated gradient allocation: a predictive entropy module routes high entropy tokens to full PPO updates to encourage exploration, and low entropy tokens to attenuated PPO updates to reduce variance and preserve knowledge. Critically, both branches incorporate the advantage function A_t, ensuring that incorrect trajectories receive consistent negative learning signals and preventing reinforcement of confident errors. EGSPO achieves consistent improvements on mathematical reasoning benchmarks, with gains of 3.8 percent on AIME and 2.9 percent on MATH over the CHORD phi baseline, while incurring only 3.4 percent additional computational overhead.", "AI": {"tldr": "本文提出了一种新的混合训练方法，通过在令牌级别上调节梯度来优化大型语言模型的策略。", "motivation": "现有的混合训练方法通常仅在样本级别结合监督微调和强化学习。作者希望通过令牌级别的梯度调控来进一步改善这种组合。", "method": "EGSPO框架由三个阶段组成：第一阶段，使用专家示范进行纯SFT以建立可靠策略；第二阶段，在当前策略下采样轨迹并计算每个令牌的预测熵；第三阶段应用基于熵门控的梯度分配机制，鼓励探索高熵令牌同时减少低熵令牌的方差。", "result": "EGSPO在数学推理基准测试中表现优于CHORD phi基线，提高了3.8％和2.9％的准确率，在计算开销上只增加了3.4％。", "conclusion": "通过引入令牌级别的预测熵门控机制，EGSPO框架能够有效地提高大型语言模型的学习效率与准确性。"}}
{"id": "2602.03307", "pdf": "https://arxiv.org/pdf/2602.03307", "abs": "https://arxiv.org/abs/2602.03307", "authors": ["Goksenin Yuksel", "Marcel van Gerven", "Kiki van der Heijden"], "title": "GRAM: Spatial general-purpose audio representations for real-world environments", "categories": ["cs.SD"], "comment": "Revise with RealSELD", "summary": "Audio foundation models learn general-purpose audio representations that facilitate a wide range of downstream tasks. While the performance of these models has greatly increased for conventional single-channel, dry audio clips, their success in real-world acoustic environments with reverberation and noise is limited. Furthermore, most audio foundation models ignore the spatial dimension of real-world acoustic environments, ruling out tasks involving sound localization. To address these limitations, we propose GRAM: a general-purpose real-world audio model that employs a multi-channel masked autoencoder to efficiently learn spatial audio representations. We evaluated GRAM and other audio foundation models in a standardized manner on high-quality simulations of naturalistic, spatial acoustic environments as well as recordings of real-world environments and release these two complementary benchmark task suites: NatHEAR and RealSELD. Our results demonstrate that GRAM outperforms all state-of-the-art self-supervised audio foundation models on NatHEAR and the clean, single-channel version HEAR, while using only a fraction of the training data. GRAM also shows state-of-the-art localization performance in simulated environments and generalizes efficiently to real-world recordings in RealSELD. Taken together, GRAM presents a significant advance toward robust spatial audio foundation models for real-world environments.", "AI": {"tldr": "提出GRAM模型，用于学习空间音频表示，在真实世界环境中实现声音定位任务。", "motivation": "当前音频基础模型在常规单声道、干燥音轨上的性能提升显著，但在有混响和噪音的真实环境中的表现受限。此外，这些模型忽略了现实环境的空间维度，限制了声音定位等任务的应用。", "method": "通过多通道掩码自动编码器学习空间音频表示，GRAM模型适用于自然主义的空间声学环境模拟以及真实世界录音的评估。", "result": "在标准化测试中，GRAM模型超越所有现有的自监督音频基础模型。同时，在模拟环境中展示出卓越的声音定位性能，并能高效地推广到RealSELD任务中的真实记录。", "conclusion": "GRAM是实现稳健的空间音频基础模型的重要进展，适用于现实世界环境中的应用。"}}
{"id": "2602.03306", "pdf": "https://arxiv.org/pdf/2602.03306", "abs": "https://arxiv.org/abs/2602.03306", "authors": ["Zhanyu Wu", "Richong Zhang", "Zhijie Nie"], "title": "Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Dense retrieval represents queries and docu-002 ments as high-dimensional embeddings, but003 these representations can be redundant at the004 query level: for a given information need, only005 a subset of dimensions is consistently help-006 ful for ranking. Prior work addresses this via007 pseudo-relevance feedback (PRF) based dimen-008 sion importance estimation, which can produce009 query-aware masks without labeled data but010 often relies on noisy pseudo signals and heuris-011 tic test-time procedures. In contrast, super-012 vised adapter methods leverage relevance labels013 to improve embedding quality, yet they learn014 global transformations shared across queries015 and do not explicitly model query-aware di-016 mension importance. We propose a Query-017 Aware Adaptive Dimension Selection frame-018 work that learns to predict per-dimension im-019 portance directly from query embedding. We020 first construct oracle dimension importance dis-021 tributions over embedding dimensions using022 supervised relevance labels, and then train a023 predictor to map a query embedding to these024 label-distilled importance scores. At inference,025 the predictor selects a query-aware subset of026 dimensions for similarity computation based027 solely on the query embedding, without pseudo-028 relevance feedback. Experiments across multi-029 ple dense retrievers and benchmarks show that030 our learned dimension selector improves re-031 trieval effectiveness over the full-dimensional032 baseline as well as PRF-based masking and033 supervised adapter baselines.", "AI": {"tldr": "本文提出了一个基于查询感知的自适应维度选择框架，旨在通过预测查询嵌入来直接选择对检索有效的特征维度。", "motivation": "传统的稠密检索方法使用高维表示可能导致冗余。伪相关反馈（PRF）方法虽然可以在没有标签数据的情况下生成查询感知掩码，但依赖于噪声信号和启发式测试时程序；而监督适配器方法虽能通过相关性标签改进嵌入质量，但未明确建模查询感知维度重要性。", "method": "本文构建了oracle维度重要性分布，并训练一个预测器将查询嵌入映射到这些标注精炼的重要性评分。在推理阶段，仅基于查询嵌入选择特征维度进行相似度计算。", "result": "实验结果表明所提出的查询感知自适应维度选择框架优于全维度基线以及PRF和监督适配器方法。", "conclusion": "该工作展示了预测查询重要性维度的有效性，并证明了其在多个稠密检索模型上的优越性能。"}}
{"id": "2602.03302", "pdf": "https://arxiv.org/pdf/2602.03302", "abs": "https://arxiv.org/abs/2602.03302", "authors": ["Jinze Zhang", "Jian Zhong", "Li Lin", "Jiaxiong Li", "Ke Ma", "Naiyang Li", "Meng Li", "Yuan Pan", "Zeyu Meng", "Mengyun Zhou", "Shang Huang", "Shilong Yu", "Zhengyu Duan", "Sutong Li", "Honghui Xia", "Juping Liu", "Dan Liang", "Yantao Wei", "Xiaoying Tang", "Jin Yuan", "Peng Xiao"], "title": "Full end-to-end diagnostic workflow automation of 3D OCT via foundation model-driven AI for retinal diseases", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Optical coherence tomography (OCT) has revolutionized retinal disease diagnosis with its high-resolution and three-dimensional imaging nature, yet its full diagnostic automation in clinical practices remains constrained by multi-stage workflows and conventional single-slice single-task AI models. We present Full-process OCT-based Clinical Utility System (FOCUS), a foundation model-driven framework enabling end-to-end automation of 3D OCT retinal disease diagnosis. FOCUS sequentially performs image quality assessment with EfficientNetV2-S, followed by abnormality detection and multi-disease classification using a fine-tuned Vision Foundation Model. Crucially, FOCUS leverages a unified adaptive aggregation method to intelligently integrate 2D slices-level predictions into comprehensive 3D patient-level diagnosis. Trained and tested on 3,300 patients (40,672 slices), and externally validated on 1,345 patients (18,498 slices) across four different-tier centers and diverse OCT devices, FOCUS achieved high F1 scores for quality assessment (99.01%), abnormally detection (97.46%), and patient-level diagnosis (94.39%). Real-world validation across centers also showed stable performance (F1: 90.22%-95.24%). In human-machine comparisons, FOCUS matched expert performance in abnormality detection (F1: 95.47% vs 90.91%) and multi-disease diagnosis (F1: 93.49% vs 91.35%), while demonstrating better efficiency. FOCUS automates the image-to-diagnosis pipeline, representing a critical advance towards unmanned ophthalmology with a validated blueprint for autonomous screening to enhance population scale retinal care accessibility and efficiency.", "AI": {"tldr": "提出了一种基于基础模型驱动的自动化OCT诊断框架FOCUS，实现从图像到诊断的全流程自动化。", "motivation": "现有的OCT诊断流程受限于多阶段工作流和传统的单切片任务AI模型，阻碍了其在临床实践中的全面自动化。因此开发一种能够高效集成并自动执行诊断流程的技术具有重要意义。", "method": "FOCUS框架通过EfficientNetV2-S进行图像质量评估，并使用预训练的视觉基础模型对异常检测和多疾病分类进行微调。利用统一自适应聚合方法将二维切片预测结果智能整合为患者级别的全面诊断。", "result": "在3,300名患者（40,672个切片）的数据集上，FOCUS达到了99.01%的质量评估F1得分、97.46%的异常检测F1得分以及94.39%的患者级别诊断F1得分。外部验证显示性能稳定（F1：90.22%-95.24%）。人机对比中，FOCUS在异常检测和多疾病诊断上均接近专家水平，效率更高。", "conclusion": "FOCUS框架实现了从图像到诊断的全流程自动化，代表了无人眼科医学的重大进展，并为大规模自动筛查提供了经过验证的方法蓝本。"}}
{"id": "2602.03301", "pdf": "https://arxiv.org/pdf/2602.03301", "abs": "https://arxiv.org/abs/2602.03301", "authors": ["Hyukjun Yang", "Han-Dong Lim", "Donghwan Lee"], "title": "Periodic Regularized Q-Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In reinforcement learning (RL), Q-learning is a fundamental algorithm whose convergence is guaranteed in the tabular setting. However, this convergence guarantee does not hold under linear function approximation. To overcome this limitation, a significant line of research has introduced regularization techniques to ensure stable convergence under function approximation. In this work, we propose a new algorithm, periodic regularized Q-learning (PRQ). We first introduce regularization at the level of the projection operator and explicitly construct a regularized projected value iteration (RP-VI), subsequently extending it to a sample-based RL algorithm. By appropriately regularizing the projection operator, the resulting projected value iteration becomes a contraction. By extending this regularized projection into the stochastic setting, we establish the PRQ algorithm and provide a rigorous theoretical analysis that proves finite-time convergence guarantees for PRQ under linear function approximation.", "AI": {"tldr": "提出了一种新的算法：周期性正则化Q学习（PRQ），在函数近似下确保收敛。", "motivation": "解决Q学习在函数近似下的稳定性问题，引入正则化技术保证稳定收敛。", "method": "通过在投影算子层面引入正则化，构造了一个正规化的投影值迭代（RP-VI），并将其扩展为基于样本的强化学习算法PRQ。", "result": "提供了严格的理论分析，证明了PRQ算法在线性函数近似下的有限时间收敛保证。", "conclusion": "提出的周期性正则化Q学习（PRQ）在函数近似下确保了稳定且快速的收敛。"}}
{"id": "2602.03300", "pdf": "https://arxiv.org/pdf/2602.03300", "abs": "https://arxiv.org/abs/2602.03300", "authors": ["Jingyi Zhang", "Tianyi Lin", "Huanjin Yao", "Xiang Lan", "Shunyu Liu", "Jiaxing Huang"], "title": "R1-SyntheticVL: Is Synthetic Data from Generative Models Ready for Multimodal Large Language Model?", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "In this work, we aim to develop effective data synthesis techniques that autonomously synthesize multimodal training data for enhancing MLLMs in solving complex real-world tasks. To this end, we propose Collective Adversarial Data Synthesis (CADS), a novel and general approach to synthesize high-quality, diverse and challenging multimodal data for MLLMs. The core idea of CADS is to leverage collective intelligence to ensure high-quality and diverse generation, while exploring adversarial learning to synthesize challenging samples for effectively driving model improvement. Specifically, CADS operates with two cyclic phases, i.e., Collective Adversarial Data Generation (CAD-Generate) and Collective Adversarial Data Judgment (CAD-Judge). CAD-Generate leverages collective knowledge to jointly generate new and diverse multimodal data, while CAD-Judge collaboratively assesses the quality of synthesized data. In addition, CADS introduces an Adversarial Context Optimization mechanism to optimize the generation context to encourage challenging and high-value data generation. With CADS, we construct MMSynthetic-20K and train our model R1-SyntheticVL, which demonstrates superior performance on various benchmarks.", "AI": {"tldr": "开发了一种新的多模态合成数据生成方法CADS，用于增强大规模语言模型的能力。", "motivation": "旨在通过自主合成高质量的多模态训练数据来提升大规模多模态语言模型（MLLMS）在解决复杂现实任务时的表现能力。", "method": "提出了一种名为集体对抗性数据合成(CADS)的新方法，该方法包含两个循环阶段：集体对抗性数据生成(CAD-Generate)和集体对抗性数据判断(CAD-Judge)，并通过引入对抗上下文优化机制来促进更具挑战性的高价值数据的生成。", "result": "通过使用CADS构建了MMSynthetic-20K并训练模型R1-SyntheticVL，在多个基准测试中表现出色。", "conclusion": "提出的方法能够有效地生成高质量、多样化和具有挑战性的多模态合成数据，有助于增强大规模语言模型的能力。"}}
{"id": "2602.03295", "pdf": "https://arxiv.org/pdf/2602.03295", "abs": "https://arxiv.org/abs/2602.03295", "authors": ["Junhui He", "Zhihui Fu", "Jun Wang", "Qingan Li"], "title": "POP: Prefill-Only Pruning for Efficient Large Model Inference", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable capabilities. However, their deployment is hindered by significant computational costs. Existing structured pruning methods, while hardware-efficient, often suffer from significant accuracy degradation. In this paper, we argue that this failure stems from a stage-agnostic pruning approach that overlooks the asymmetric roles between the prefill and decode stages. By introducing a virtual gate mechanism, our importance analysis reveals that deep layers are critical for next-token prediction (decode) but largely redundant for context encoding (prefill). Leveraging this insight, we propose Prefill-Only Pruning (POP), a stage-aware inference strategy that safely omits deep layers during the computationally intensive prefill stage while retaining the full model for the sensitive decode stage. To enable the transition between stages, we introduce independent Key-Value (KV) projections to maintain cache integrity, and a boundary handling strategy to ensure the accuracy of the first generated token. Extensive experiments on Llama-3.1, Qwen3-VL, and Gemma-3 across diverse modalities demonstrate that POP achieves up to 1.37$\\times$ speedup in prefill latency with minimal performance loss, effectively overcoming the accuracy-efficiency trade-off limitations of existing structured pruning methods.", "AI": {"tldr": "提出了一种针对大模型推理的预填充阶段优化策略POP，通过精简深层网络在不牺牲准确性的情况下提高效率。", "motivation": "当前的大语言和视觉-语言模型虽然表现出色，但因计算成本高昂难以大规模部署。现有结构化修剪方法虽有助于硬件效率提升，却常导致精度大幅下降。为此研究提出了一种新的修剪策略来解决这一问题。", "method": "通过引入虚拟门机制发现深层网络在预测阶段至关重要而在编码阶段相对冗余，并据此设计了预填充只修剪（POP）技术，在计算密集的预填充阶段省略深层层，同时保留完整的模型用于敏感的解码阶段。此外还提出了独立键值投影和边界处理策略以确保上下文缓存的一致性以及生成首个令牌时的准确度。", "result": "实验表明，相较于现有结构化修剪方法，POP能够在不明显损失性能的情况下将预填充延迟最多减少1.37倍。", "conclusion": "POP技术有效克服了传统修剪方法中的精度效率权衡限制，在多种模式下展示了卓越的表现。"}}
{"id": "2602.03294", "pdf": "https://arxiv.org/pdf/2602.03294", "abs": "https://arxiv.org/abs/2602.03294", "authors": ["Jonas Kühne", "Christian Vogt", "Michele Magno", "Luca Benini"], "title": "LEVIO: Lightweight Embedded Visual Inertial Odometry for Resource-Constrained Devices", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": "This article has been accepted for publication in the IEEE Sensors Journal (JSEN)", "summary": "Accurate, infrastructure-less sensor systems for motion tracking are essential for mobile robotics and augmented reality (AR) applications. The most popular state-of-the-art visual-inertial odometry (VIO) systems, however, are too computationally demanding for resource-constrained hardware, such as micro-drones and smart glasses. This work presents LEVIO, a fully featured VIO pipeline optimized for ultra-low-power compute platforms, allowing six-degrees-of-freedom (DoF) real-time sensing. LEVIO incorporates established VIO components such as Oriented FAST and Rotated BRIEF (ORB) feature tracking and bundle adjustment, while emphasizing a computationally efficient architecture with parallelization and low memory usage to suit embedded microcontrollers and low-power systems-on-chip (SoCs). The paper proposes and details the algorithmic design choices and the hardware-software co-optimization approach, and presents real-time performance on resource-constrained hardware. LEVIO is validated on a parallel-processing ultra-low-power RISC-V SoC, achieving 20 FPS while consuming less than 100 mW, and benchmarked against public VIO datasets, offering a compelling balance between efficiency and accuracy. To facilitate reproducibility and adoption, the complete implementation is released as open-source.", "AI": {"tldr": "LEVIO是一种优化的视觉惯性里程计(VIO)系统，适用于资源受限设备，如微型无人机和智能眼镜。", "motivation": "目前最先进的VIO系统对计算要求过高，不适合微控制器和低功耗芯片等资源有限的硬件平台。", "method": "LEVIO采用了高效的架构设计和并行处理技术，并使用ORB特征跟踪和捆绑调整算法，以适应嵌入式设备的需求。", "result": "在特定低能耗RISC-V SoC上实现20帧每秒（FPS）的速度的同时功耗小于100毫瓦，并且通过公开VIO数据集的测试证明了其效率与准确性的平衡性。", "conclusion": "LEVIO为资源受限硬件上的实时六自由度追踪提供了高效的解决方案，完整代码开源以促进复现和应用推广。"}}
{"id": "2602.03292", "pdf": "https://arxiv.org/pdf/2602.03292", "abs": "https://arxiv.org/abs/2602.03292", "authors": ["Jianghao Wu", "Xiangde Luo", "Yubo Zhou", "Lianming Wu", "Guotai Wang", "Shaoting Zhang"], "title": "A3-TTA: Adaptive Anchor Alignment Test-Time Adaptation for Image Segmentation", "categories": ["cs.CV"], "comment": "Accepted by IEEE Transactions on Image Processing", "summary": "Test-Time Adaptation (TTA) offers a practical solution for deploying image segmentation models under domain shift without accessing source data or retraining. Among existing TTA strategies, pseudo-label-based methods have shown promising performance. However, they often rely on perturbation-ensemble heuristics (e.g., dropout sampling, test-time augmentation, Gaussian noise), which lack distributional grounding and yield unstable training signals. This can trigger error accumulation and catastrophic forgetting during adaptation. To address this, we propose \\textbf{A3-TTA}, a TTA framework that constructs reliable pseudo-labels through anchor-guided supervision. Specifically, we identify well-predicted target domain images using a class compact density metric, under the assumption that confident predictions imply distributional proximity to the source domain. These anchors serve as stable references to guide pseudo-label generation, which is further regularized via semantic consistency and boundary-aware entropy minimization. Additionally, we introduce a self-adaptive exponential moving average strategy to mitigate label noise and stabilize model update during adaptation. Evaluated on both multi-domain medical images (heart structure and prostate segmentation) and natural images, A3-TTA significantly improves average Dice scores by 10.40 to 17.68 percentage points compared to the source model, outperforming several state-of-the-art TTA methods under different segmentation model architectures. A3-TTA also excels in continual TTA, maintaining high performance across sequential target domains with strong anti-forgetting ability. The code will be made publicly available at https://github.com/HiLab-git/A3-TTA.", "AI": {"tldr": "提出了一种基于锚点引导监督的测试时间适应性框架A3-TTA，用于图像分割任务中的域偏移问题。", "motivation": "现有的测试时间适应方法存在扰动集成启发式缺乏分布基础且训练信号不稳定的缺点，导致错误累积和灾难性遗忘。为此提出了一种基于锚点引导监督的方法来生成可靠的伪标签以解决这些问题。", "method": "通过类紧致密度度量识别目标域中的良好预测图像作为锚点，并利用这些锚点指导伪标签生成；引入自适应指数移动平均策略减少标签噪声，稳定模型更新。", "result": "A3-TTA在多领域医学影像和自然影像上的测试中显著提高了Dice分数，优于多个现有的TTA方法；同时在连续测试时间适应任务上表现出强大的抗遗忘能力。", "conclusion": "提出的方法有效解决了现有测试时间适应性框架中存在的问题，并在多种场景下展现了优越的性能。"}}
{"id": "2602.03286", "pdf": "https://arxiv.org/pdf/2602.03286", "abs": "https://arxiv.org/abs/2602.03286", "authors": ["Michael A. Müller", "Srdjan Vesic", "Bruno Yun"], "title": "Rejecting Arguments Based on Doubt in Structured Bipolar Argumentation", "categories": ["cs.AI", "cs.MA"], "comment": "Accepted to AAMAS 2026", "summary": "This paper develops a new approach to computational argumentation that is informed by philosophical and linguistic views. Namely, it takes into account two ideas that have received little attention in the literature on computational argumentation: First, an agent may rationally reject an argument based on mere doubt, thus not all arguments they could defend must be accepted; and, second, that it is sometimes more natural to think in terms of which individual sentences or claims an agent accepts in a debate, rather than which arguments. In order to incorporate these two ideas into a computational approach, we first define the notion of structured bipolar argumentation frameworks (SBAFs), where arguments consist of sentences and we have both an attack and a support relation between them. Then, we provide semantics for SBAFs with two features: (1) Unlike with completeness-based semantics, our semantics do not force agents to accept all defended arguments. (2) In addition to argument extensions, which give acceptable sets of arguments, we also provide semantics for language extensions that specify acceptable sets of sentences. These semantics represent reasonable positions an agent might have in a debate. Our semantics lie between the admissible and complete semantics of abstract argumentation. Further, our approach can be used to provide a new perspective on existing approaches. For instance, we can specify the conditions under which an agent can ignore support between arguments (i.e. under which the use of abstract argumentation is warranted) and we show that deductive support semantics is a special case of our approach.", "AI": {"tldr": "开发一种新的基于哲学和语言观点的结构化双极性论证框架，允许代理人拒绝怀疑性的论点，并提供句子级别的接受集语义。", "motivation": "现有的计算论证方法未能充分考虑代理人在面对怀疑时可以理性地拒绝某些论证的观点，以及在辩论中更自然地关注特定句子而非整个论证的情况。", "method": "定义结构化双极性论证框架（SBAFs），包括论据中的句子及攻击和支持关系。提供两种语义：1）不强制代理人接受所有被辩护的论点；2）除了论点集，还提供语言集以指定代理人可以接受的句子集合。", "result": "新的语义位于抽象论证的可接纳性和完全性语义之间，并为现有方法提供了新视角。例如，指定了哪些情况下代理可以在忽略论据间支持的情况下使用抽象论证。", "conclusion": "提出的方法提供了一种新颖的方式来处理怀疑和句子级别的辩论接受问题，扩展了计算论证理论的应用范围。"}}
{"id": "2602.03285", "pdf": "https://arxiv.org/pdf/2602.03285", "abs": "https://arxiv.org/abs/2602.03285", "authors": ["Yuelin Hu", "Jun Xu", "Bingcong Lu", "Zhengxue Cheng", "Hongwei Hu", "Ronghua Wu", "Li Song"], "title": "MeetBench-XL: Calibrated Multi-Dimensional Evaluation and Learned Dual-Policy Agents for Real-Time Meetings", "categories": ["cs.AI"], "comment": "accepted by AAAI2026 ws", "summary": "Enterprise meeting environments require AI assistants that handle diverse operational tasks, from rapid fact checking during live discussions to cross meeting analysis for strategic planning, under strict latency, cost, and privacy constraints. Existing meeting benchmarks mainly focus on simplified question answering and fail to reflect real world enterprise workflows, where queries arise organically from multi stakeholder collaboration, span long temporal contexts, and require tool augmented reasoning. We address this gap through a grounded dataset and a learned agent framework. First, we introduce MeetAll, a bilingual and multimodal corpus derived from 231 enterprise meetings totaling 140 hours. Questions are injected using an enterprise informed protocol validated by domain expert review and human discriminability studies. Unlike purely synthetic benchmarks, this protocol is grounded in four enterprise critical dimensions: cognitive load, temporal context span, domain expertise, and actionable task execution, calibrated through interviews with stakeholders across finance, healthcare, and technology sectors. Second, we propose MeetBench XL, a multi dimensional evaluation protocol aligned with human judgment that measures factual fidelity, intent alignment, response efficiency, structural clarity, and completeness. Third, we present MeetMaster XL, a learned dual policy agent that jointly optimizes query routing between fast and slow reasoning paths and tool invocation, including retrieval, cross meeting aggregation, and web search. A lightweight classifier enables accurate routing with minimal overhead, achieving a superior quality latency tradeoff over single model baselines. Experiments against commercial systems show consistent gains, supported by ablations, robustness tests, and a real world deployment case study.Resources: https://github.com/huyuelin/MeetBench.", "AI": {"tldr": "本文提出了MeetBench-XL，一个用于评估和训练会议环境中AI助手的多维度基准系统。", "motivation": "现有会议基准主要关注简化的问题回答任务，并不能反映现实企业工作流程中的复杂性和多样性。因此需要一个新的评估框架来支持更广泛的查询类型，包括跨会议分析、工具辅助推理等。", "method": "本文构建了一个名为MeetAll的多语言和多媒体语料库；提出了一个名为MeetBench-XL的新基准系统，用于评估AI助手在各种任务上的性能；并设计了一种名为MeetMaster XL的学习型双策略代理，能够优化查询路由并在不同推理路径之间平衡。", "result": "实验表明，MeetMaster XL相比单模型基线具有更好的质量和延迟权衡，并且在商业系统的对比中表现出一致的优势。此外，通过消融分析、鲁棒性测试和实际案例研究进一步验证了其有效性。", "conclusion": "本文提出的基准系统为开发能够处理企业会议环境中复杂任务的AI助手提供了一个全面而有效的评估框架。"}}
{"id": "2602.03284", "pdf": "https://arxiv.org/pdf/2602.03284", "abs": "https://arxiv.org/abs/2602.03284", "authors": ["Yi Yu", "Qixin Zhang", "Shuhan Ye", "Xun Lin", "Qianshan Wei", "Kun Wang", "Wenhan Yang", "Dacheng Tao", "Xudong Jiang"], "title": "Time Is All It Takes: Spike-Retiming Attacks on Event-Driven Spiking Neural Networks", "categories": ["cs.CR", "cs.CV"], "comment": "Accepted by ICLR 2026", "summary": "Spiking neural networks (SNNs) compute with discrete spikes and exploit temporal structure, yet most adversarial attacks change intensities or event counts instead of timing. We study a timing-only adversary that retimes existing spikes while preserving spike counts and amplitudes in event-driven SNNs, thus remaining rate-preserving. We formalize a capacity-1 spike-retiming threat model with a unified trio of budgets: per-spike jitter $\\mathcal{B}_{\\infty}$, total delay $\\mathcal{B}_{1}$, and tamper count $\\mathcal{B}_{0}$. Feasible adversarial examples must satisfy timeline consistency and non-overlap, which makes the search space discrete and constrained. To optimize such retimings at scale, we use projected-in-the-loop (PIL) optimization: shift-probability logits yield a differentiable soft retiming for backpropagation, and a strict projection in the forward pass produces a feasible discrete schedule that satisfies capacity-1, non-overlap, and the chosen budget at every step. The objective maximizes task loss on the projected input and adds a capacity regularizer together with budget-aware penalties, which stabilizes gradients and aligns optimization with evaluation. Across event-driven benchmarks (CIFAR10-DVS, DVS-Gesture, N-MNIST) and diverse SNN architectures, we evaluate under binary and integer event grids and a range of retiming budgets, and also test models trained with timing-aware adversarial training designed to counter timing-only attacks. For example, on DVS-Gesture the attack attains high success (over $90\\%$) while touching fewer than $2\\%$ of spikes under $\\mathcal{B}_{0}$. Taken together, our results show that spike retiming is a practical and stealthy attack surface that current defenses struggle to counter, providing a clear reference for temporal robustness in event-driven SNNs. Code is available at https://github.com/yuyi-sd/Spike-Retiming-Attacks.", "AI": {"tldr": "本论文研究了一种对事件驱动的脉冲神经网络进行攻击的方法，即通过重新定时现有脉冲来改变其行为。", "motivation": "现有的大多数对抗性攻击会修改强度或事件计数，而不是时间。为了探索只基于时间变化的影响，本文引入了一个新的威胁模型，并提出了针对时间敏感性的新攻击方法。", "method": "作者提出了一种名为“PIL优化”的方法来寻找最优的重新定时方案，该方法使用微分软重定时并通过前向传播产生满足约束条件的离散调度。", "result": "实验表明，在多个基准数据集和网络结构上，这种基于时间改变的方法能够成功地误导神经网络超过90%，同时仅修改了不到2%的脉冲。这说明当前的安全机制难以有效应对此类攻击。", "conclusion": "本研究证明了重新定时脉冲是一种实用且隐蔽的攻击途径，并为事件驱动SNN的时间鲁棒性提供了参考，同时也强调了需要进一步开发能够抵御时间敏感性攻击的方法和模型训练策略。"}}
{"id": "2602.03282", "pdf": "https://arxiv.org/pdf/2602.03282", "abs": "https://arxiv.org/abs/2602.03282", "authors": ["Jiwan Chung", "Seon Joo Kim"], "title": "Global Geometry Is Not Enough for Vision Representations", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "A common assumption in representation learning is that globally well-distributed embeddings support robust and generalizable representations. This focus has shaped both training objectives and evaluation protocols, implicitly treating global geometry as a proxy for representational competence. While global geometry effectively encodes which elements are present, it is often insensitive to how they are composed. We investigate this limitation by testing the ability of geometric metrics to predict compositional binding across 21 vision encoders. We find that standard geometry-based statistics exhibit near-zero correlation with compositional binding. In contrast, functional sensitivity, as measured by the input-output Jacobian, reliably tracks this capability. We further provide an analytic account showing that this disparity arises from objective design, as existing losses explicitly constrain embedding geometry but leave the local input-output mapping unconstrained. These results suggest that global embedding geometry captures only a partial view of representational competence and establish functional sensitivity as a critical complementary axis for modeling composite structure.", "AI": {"tldr": "研究探讨了视觉表示中的全局几何是否足以衡量表征能力，并发现局部输入输出映射更为关键。", "motivation": "传统上，人们认为具有良好全局分布的嵌入可以支持稳健和泛化的表示。然而，这种假设可能导致对表征能力的过度简化，忽略了局部结构的重要性。", "method": "通过测试21种视觉编码器在组合绑定上的表现，比较了几何度量与功能性敏感性的关联性，并分析了现有损失函数的设计对其影响。", "result": "发现标准几何统计指标与组合绑定能力的相关性几乎为零，而输入输出雅可比矩阵则能有效跟踪这种能力。", "conclusion": "研究表明全局嵌入几何仅提供表征能力的部分视角，功能性敏感性是衡量复合结构的关键补充维度。"}}
{"id": "2602.03279", "pdf": "https://arxiv.org/pdf/2602.03279", "abs": "https://arxiv.org/abs/2602.03279", "authors": ["Zhengbo Jiao", "Shaobo Wang", "Zifan Zhang", "Xuan Ren", "Wei Wang", "Bing Zhao", "Hu Wei", "Linfeng Zhang"], "title": "Agentic Proposing: Enhancing Large Language Model Reasoning via Compositional Skill Synthesis", "categories": ["cs.AI", "cs.LG"], "comment": "23page4", "summary": "Advancing complex reasoning in large language models relies on high-quality, verifiable datasets, yet human annotation remains cost-prohibitive and difficult to scale. Current synthesis paradigms often face a recurring trade-off: maintaining structural validity typically restricts problem complexity, while relaxing constraints to increase difficulty frequently leads to inconsistent or unsolvable instances. To address this, we propose Agentic Proposing, a framework that models problem synthesis as a goal-driven sequential decision process where a specialized agent dynamically selects and composes modular reasoning skills. Through an iterative workflow of internal reflection and tool-use, we develop the Agentic-Proposer-4B using Multi-Granularity Policy Optimization (MGPO) to generate high-precision, verifiable training trajectories across mathematics, coding, and science. Empirical results demonstrate that downstream solvers trained on agent-synthesized data significantly outperform leading baselines and exhibit robust cross-domain generalization. Notably, a 30B solver trained on only 11,000 synthesized trajectories achieves a state-of-the-art 91.6% accuracy on AIME25, rivaling frontier-scale proprietary models such as GPT-5 and proving that a small volume of high-quality synthetic signals can effectively substitute for massive human-curated datasets.", "AI": {"tldr": "该论文提出了一种名为Agentic Proposing的框架，用于增强大型语言模型在数学、编程和科学领域的推理能力。", "motivation": "提高复杂推理任务的数据集质量需要高成本的人工标注。现有的数据合成方法难以平衡问题难度与合理性之间的关系。", "method": "通过将问题生成建模为一个目标驱动的顺序决策过程，Agentic Proposing使用模块化技能合成来创建高质量、可验证的问题轨迹。", "result": "实验结果表明，基于代理生成的数据训练的语言模型在跨域推理任务中表现出色，并超越了基准模型。", "conclusion": "该方法证明了通过少量高质量的合成信号可以有效替代大量人工标注数据以提升大型语言模型的表现。"}}
{"id": "2602.03268", "pdf": "https://arxiv.org/pdf/2602.03268", "abs": "https://arxiv.org/abs/2602.03268", "authors": ["Guanzong Wu", "Zihao Zhu", "Siwei Lyu", "Baoyuan Wu"], "title": "Unveiling Covert Toxicity in Multimodal Data via Toxicity Association Graphs: A Graph-Based Metric and Interpretable Detection Framework", "categories": ["cs.LG", "cs.AI", "cs.MM"], "comment": null, "summary": "Detecting toxicity in multimodal data remains a significant challenge, as harmful meanings often lurk beneath seemingly benign individual modalities: only emerging when modalities are combined and semantic associations are activated. To address this, we propose a novel detection framework based on Toxicity Association Graphs (TAGs), which systematically model semantic associations between innocuous entities and latent toxic implications. Leveraging TAGs, we introduce the first quantifiable metric for hidden toxicity, the Multimodal Toxicity Covertness (MTC), which measures the degree of concealment in toxic multimodal expressions. By integrating our detection framework with the MTC metric, our approach enables precise identification of covert toxicity while preserving full interpretability of the decision-making process, significantly enhancing transparency in multimodal toxicity detection. To validate our method, we construct the Covert Toxic Dataset, the first benchmark specifically designed to capture high-covertness toxic multimodal instances. This dataset encodes nuanced cross-modal associations and serves as a rigorous testbed for evaluating both the proposed metric and detection framework. Extensive experiments demonstrate that our approach outperforms existing methods across both low- and high-covertness toxicity regimes, while delivering clear, interpretable, and auditable detection outcomes. Together, our contributions advance the state of the art in explainable multimodal toxicity detection and lay the foundation for future context-aware and interpretable approaches. Content Warning: This paper contains examples of toxic multimodal content that may be offensive or disturbing to some readers. Reader discretion is advised.", "AI": {"tldr": "本文提出了一种基于毒性关联图的多模态隐蔽毒性的检测框架和定量度量方法，旨在提高隐蔽有毒信息的识别精度与透明度。", "motivation": "当前多模态数据中的隐含有害内容难以被发现。作者通过引入毒性关联图（TAGs）及隐蔽性毒性量化指标MTC，来解决这一问题，使毒性检测更加精准且可解释。", "method": "作者构建了一个基于TAG的检测框架，并提出Multimodal Toxicity Covertness（MTC）度量方法来评估多模态数据中的隐含有害信息。同时创建了首个专门针对隐蔽有毒实例的Covert Toxic Dataset。", "result": "实验表明，该方法在低隐蔽性和高隐蔽性毒性场景中均优于现有技术，并能提供明确、可解释且可审计的结果。", "conclusion": "本文提出的检测框架和度量标准显著提升了多模态数据中毒性的识别精度与透明度，为未来的研究奠定了基础。"}}
{"id": "2602.03264", "pdf": "https://arxiv.org/pdf/2602.03264", "abs": "https://arxiv.org/abs/2602.03264", "authors": ["Francesco Di Salvo", "Sebastian Doerrich", "Jonas Alle", "Christian Ledig"], "title": "HypCBC: Domain-Invariant Hyperbolic Cross-Branch Consistency for Generalizable Medical Image Analysis", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "Accepted to Transactions on Machine Learning Research (TMLR)", "summary": "Robust generalization beyond training distributions remains a critical challenge for deep neural networks. This is especially pronounced in medical image analysis, where data is often scarce and covariate shifts arise from different hardware devices, imaging protocols, and heterogeneous patient populations. These factors collectively hinder reliable performance and slow down clinical adoption. Despite recent progress, existing learning paradigms primarily rely on the Euclidean manifold, whose flat geometry fails to capture the complex, hierarchical structures present in clinical data. In this work, we exploit the advantages of hyperbolic manifolds to model complex data characteristics. We present the first comprehensive validation of hyperbolic representation learning for medical image analysis and demonstrate statistically significant gains across eleven in-distribution datasets and three ViT models. We further propose an unsupervised, domain-invariant hyperbolic cross-branch consistency constraint. Extensive experiments confirm that our proposed method promotes domain-invariant features and outperforms state-of-the-art Euclidean methods by an average of $+2.1\\%$ AUC on three domain generalization benchmarks: Fitzpatrick17k, Camelyon17-WILDS, and a cross-dataset setup for retinal imaging. These datasets span different imaging modalities, data sizes, and label granularities, confirming generalization capabilities across substantially different conditions. The code is available at https://github.com/francescodisalvo05/hyperbolic-cross-branch-consistency .", "AI": {"tldr": "本文提出了利用双曲几何表示学习的新型医疗图像分析方法，引入了域不变性双曲跨分支一致性约束。", "motivation": "医学影像数据稀缺且存在不同的硬件设备、成像协议和异质患者群体带来的变化，这些因素影响到可靠性能，并阻碍临床应用。现有的学习范式主要依赖欧几里得流形，其平坦的几何结构无法捕捉医疗数据中的复杂层次结构。", "method": "该研究利用双曲流形的优势来建模复杂的医学影像特征，并引入了域不变性双曲跨分支一致性约束，以促进不同领域间的泛化能力。此外，还对三种不同的ViT模型进行了广泛的实验验证。", "result": "实验结果表明，在三个领域的推广基准测试中，所提出的方法在AUC指标上平均提高了2.1%。这证实了该方法不仅适用于不同的成像模式和数据大小，还能跨越不同条件进行有效的泛化。", "conclusion": "通过利用双曲几何表示学习和引入新的域不变性一致性约束，研究成功地展示了比现有欧几里得方法更好的性能，在跨领域推广方面表现突出。"}}
{"id": "2602.03263", "pdf": "https://arxiv.org/pdf/2602.03263", "abs": "https://arxiv.org/abs/2602.03263", "authors": ["Yuxuan Liu", "Yuntian Shi", "Kun Wang", "Haoting Shen", "Kun Yang"], "title": "CSR-Bench: A Benchmark for Evaluating the Cross-modal Safety and Reliability of MLLMs", "categories": ["cs.AI"], "comment": "25 pages, 1 figures", "summary": "Multimodal large language models (MLLMs) enable interaction over both text and images, but their safety behavior can be driven by unimodal shortcuts instead of true joint intent understanding. We introduce CSR-Bench, a benchmark for evaluating cross-modal reliability through four stress-testing interaction patterns spanning Safety, Over-rejection, Bias, and Hallucination, covering 61 fine-grained types. Each instance is constructed to require integrated image-text interpretation, and we additionally provide paired text-only controls to diagnose modality-induced behavior shifts. We evaluate 16 state-of-the-art MLLMs and observe systematic cross-modal alignment gaps. Models show weak safety awareness, strong language dominance under interference, and consistent performance degradation from text-only controls to multimodal inputs. We also observe a clear trade-off between reducing over-rejection and maintaining safe, non-discriminatory behavior, suggesting that some apparent safety gains may come from refusal-oriented heuristics rather than robust intent understanding. WARNING: This paper contains unsafe contents.", "AI": {"tldr": "该论文介绍了CSR-Bench，一个用于评估多模态大型语言模型（MLLM）安全性和可靠性的基准。", "motivation": "多模态大型语言模型的安全行为可能受到单一模态捷径的影响而非真正的联合意图理解。因此需要一个能够全面测试其跨模态安全和可靠性的问题集。", "method": "CSR-Bench通过四个压力测试互动模式，涵盖61种细粒度类型来评估MLLM的跨模态可靠性和安全性：安全、过度拒绝、偏见和幻想。每个实例都设计为需要综合图像-文本解释，并提供配对文本控制以诊断由模式引起的偏差。", "result": "实验结果表明了模型的安全意识薄弱，语言主导性较强且从纯文本输入到多模态输入时性能显著下降。", "conclusion": "该研究揭示了一些看似安全的改进可能来自于拒绝策略而不是真正的意图理解，并强调了跨模态对齐差距的存在。"}}
{"id": "2602.03257", "pdf": "https://arxiv.org/pdf/2602.03257", "abs": "https://arxiv.org/abs/2602.03257", "authors": ["Yikang Yang", "Zhengxin Yang", "Minghao Luo", "Luzhou Peng", "Hongxiao Li", "Wanling Gao", "Lei Wang", "Jianfeng Zhan"], "title": "GraDE: A Graph Diffusion Estimator for Frequent Subgraph Discovery in Neural Architectures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Finding frequently occurring subgraph patterns or network motifs in neural architectures is crucial for optimizing efficiency, accelerating design, and uncovering structural insights. However, as the subgraph size increases, enumeration-based methods are perfectly accurate but computationally prohibitive, while sampling-based methods are computationally tractable but suffer from a severe decline in discovery capability. To address these challenges, this paper proposes GraDE, a diffusion-guided search framework that ensures both computational feasibility and discovery capability. The key innovation is the Graph Diffusion Estimator (GraDE), which is the first to introduce graph diffusion models to identify frequent subgraphs by scoring their typicality within the learned distribution. Comprehensive experiments demonstrate that the estimator achieves superior ranking accuracy, with up to 114\\% improvement compared to sampling-based baselines. Benefiting from this, the proposed framework successfully discovers large-scale frequent patterns, achieving up to 30$\\times$ higher median frequency than sampling-based methods.", "AI": {"tldr": "提出了一种新的框架GraDE，用于在神经架构中发现频繁出现的子图模式。", "motivation": "解决现有方法在处理大规模子图时计算效率低或无法有效发现的问题。", "method": "引入了基于图扩散模型的Graph Diffusion Estimator（GraDE），通过评分来识别典型子图。", "result": "实验显示，与采样基线相比，该估计器实现了显著提升的排名准确度，最高可达114%。成功发现大规模频繁模式，频率高达30倍。", "conclusion": "提出的框架在保持计算可行性的同时提高了发现能力，为优化和设计神经架构提供了新的视角。"}}
{"id": "2602.03255", "pdf": "https://arxiv.org/pdf/2602.03255", "abs": "https://arxiv.org/abs/2602.03255", "authors": ["Tianyu Chen", "Chujia Hu", "Ge Gao", "Dongrui Liu", "Xia Hu", "Wenjie Wang"], "title": "LPS-Bench: Benchmarking Safety Awareness of Computer-Use Agents in Long-Horizon Planning under Benign and Adversarial Scenarios", "categories": ["cs.AI"], "comment": null, "summary": "Computer-use agents (CUAs) that interact with real computer systems can perform automated tasks but face critical safety risks. Ambiguous instructions may trigger harmful actions, and adversarial users can manipulate tool execution to achieve malicious goals. Existing benchmarks mostly focus on short-horizon or GUI-based tasks, evaluating on execution-time errors but overlooking the ability to anticipate planning-time risks. To fill this gap, we present LPS-Bench, a benchmark that evaluates the planning-time safety awareness of MCP-based CUAs under long-horizon tasks, covering both benign and adversarial interactions across 65 scenarios of 7 task domains and 9 risk types. We introduce a multi-agent automated pipeline for scalable data generation and adopt an LLM-as-a-judge evaluation protocol to assess safety awareness through the planning trajectory. Experiments reveal substantial deficiencies in existing CUAs' ability to maintain safe behavior. We further analyze the risks and propose mitigation strategies to improve long-horizon planning safety in MCP-based CUA systems. We open-source our code at https://github.com/tychenn/LPS-Bench.", "AI": {"tldr": "LPS-Bench是一个评估计算机使用代理在长时规划中安全意识的基准工具。", "motivation": "现有基准主要关注短时或基于GUI的任务，忽视了规划阶段的安全风险。为了填补这一空白，提出了一个全面评估长期任务安全性的新方法。", "method": "引入一个多智能体自动化管道进行大规模数据生成，并采用LLM作为评判标准来评估安全意识的轨迹。覆盖七个领域的65个场景和九种风险类型。", "result": "实验揭示了现有代理在维持安全行为方面的重大缺陷，提出了提高长期规划中安全性的缓解策略。", "conclusion": "LPS-Bench为改进计算机使用代理系统的安全性提供了一个全面评估框架，并公开源代码以便于进一步研究。"}}
{"id": "2602.03253", "pdf": "https://arxiv.org/pdf/2602.03253", "abs": "https://arxiv.org/abs/2602.03253", "authors": ["Ofer Idan", "Dan Badur", "Yosi Keller", "Yoli Shavit"], "title": "LaVPR: Benchmarking Language and Vision for Place Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Visual Place Recognition (VPR) often fails under extreme environmental changes and perceptual aliasing. Furthermore, standard systems cannot perform \"blind\" localization from verbal descriptions alone, a capability needed for applications such as emergency response. To address these challenges, we introduce LaVPR, a large-scale benchmark that extends existing VPR datasets with over 650,000 rich natural-language descriptions. Using LaVPR, we investigate two paradigms: Multi-Modal Fusion for enhanced robustness and Cross-Modal Retrieval for language-based localization. Our results show that language descriptions yield consistent gains in visually degraded conditions, with the most significant impact on smaller backbones. Notably, adding language allows compact models to rival the performance of much larger vision-only architectures. For cross-modal retrieval, we establish a baseline using Low-Rank Adaptation (LoRA) and Multi-Similarity loss, which substantially outperforms standard contrastive methods across vision-language models. Ultimately, LaVPR enables a new class of localization systems that are both resilient to real-world stochasticity and practical for resource-constrained deployment. Our dataset and code are available at https://github.com/oferidan1/LaVPR.", "AI": {"tldr": "本文介绍了LaVPR，一个大型基准测试平台，用于结合视觉和语言的场所识别。", "motivation": "现有的视觉场所识别系统在极端环境变化和感知混淆下性能不佳，无法仅凭语言描述完成定位任务。为了应对这些问题，引入了LaVPR来提高系统的鲁棒性和实用性。", "method": "使用多模态融合增强模型的稳定性，并采用跨模式检索技术实现基于语言的定位。此外，利用低秩适应和多重相似度损失作为基线方法以提升视觉-语言模型的表现。", "result": "实验结果显示，在视觉条件较差的情况下，自然语言描述显著提高了识别性能；较小的模型在添加语言信息后也可以匹敌大型纯视觉架构的效果。跨模态检索方面，提出的基准方法大幅度超越了对比学习的方法。", "conclusion": "LaVPR使得设计出更适应真实世界变化且适用于资源受限环境中的场所定位系统成为可能，并提供了数据集和代码供研究使用。"}}
{"id": "2602.03250", "pdf": "https://arxiv.org/pdf/2602.03250", "abs": "https://arxiv.org/abs/2602.03250", "authors": ["Anup Teejo Mathew", "Anees Peringal", "Daniele Caradonna", "Frederic Boyer", "Federico Renda"], "title": "Collision Detection with Analytical Derivatives of Contact Kinematics", "categories": ["cs.RO"], "comment": "12 pages, 9 figures, 2 tables", "summary": "Differentiable contact kinematics are essential for gradient-based methods in robotics, yet the mapping from robot state to contact distance, location, and normal becomes non-smooth in degenerate configurations of shapes with zero or undefined curvature. We address this inherent limitation by selectively regularizing such geometries into strictly convex implicit representations, restoring uniqueness and smoothness of the contact map. Leveraging this geometric regularization, we develop iDCOL, an implicit differentiable collision detection and contact kinematics framework. iDCOL represents colliding bodies using strictly convex implicit surfaces and computes collision detection and contact kinematics by solving a fixed-size nonlinear system derived from a geometric scaling-based convex optimization formulation. By applying the Implicit Function Theorem to the resulting system residual, we derive analytical derivatives of the contact kinematic quantities. We develop a fast Newton-based solver for iDCOL and provide an open-source C++ implementation of the framework. The robustness of the approach is evaluated through extensive collision simulations and benchmarking, and applicability is demonstrated in gradient-based kinematic path planning and differentiable contact physics, including multi-body rigid collisions and a soft-robot interaction example.", "AI": {"tldr": "本文提出了一种基于严格凸隐式表示的碰撞检测和接触动力学框架iDCOL，解决了机器人领域中梯度方法在非光滑配置中的问题。", "motivation": "传统的方法在处理形状具有零或未定义曲率时会导致映射不再平滑。因此需要一种新方法来解决这些问题。", "method": "通过引入几何正则化，将碰撞物体表示为严格凸的隐式表面，并通过求解非线性系统来计算碰撞检测和接触动力学。利用隐函数定理推导接触动力学量的解析梯度，并开发了快速牛顿算法解决该问题。", "result": "通过广泛的碰撞仿真和基准测试验证了方法的鲁棒性和适用性，包括基于梯度的动力学路径规划和可微分接触物理。", "conclusion": "iDCOL框架克服了传统方法在处理非光滑配置中的局限性，并提供了高效且精确的解决方案。"}}
{"id": "2602.03249", "pdf": "https://arxiv.org/pdf/2602.03249", "abs": "https://arxiv.org/abs/2602.03249", "authors": ["Zhicheng Yang", "Zhijiang Guo", "Yinya Huang", "Yongxin Wang", "Wenlei Shi", "Yiwei Wang", "Xiaodan Liang", "Jing Tang"], "title": "Accordion-Thinking: Self-Regulated Step Summaries for Efficient and Readable LLM Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Scaling test-time compute via long Chain-ofThought unlocks remarkable gains in reasoning capabilities, yet it faces practical limits due to the linear growth of KV cache and quadratic attention complexity. In this paper, we introduce Accordion-Thinking, an end-to-end framework where LLMs learn to self-regulate the granularity of the reasoning steps through dynamic summarization. This mechanism enables a Fold inference mode, where the model periodically summarizes its thought process and discards former thoughts to reduce dependency on historical tokens. We apply reinforcement learning to incentivize this capability further, uncovering a critical insight: the accuracy gap between the highly efficient Fold mode and the exhaustive Unfold mode progressively narrows and eventually vanishes over the course of training. This phenomenon demonstrates that the model learns to encode essential reasoning information into compact summaries, achieving effective compression of the reasoning context. Our Accordion-Thinker demonstrates that with learned self-compression, LLMs can tackle complex reasoning tasks with minimal dependency token overhead without compromising solution quality, and it achieves a 3x throughput while maintaining accuracy on a 48GB GPU memory configuration, while the structured step summaries provide a human-readable account of the reasoning process.", "AI": {"tldr": "本文介绍了一种名为Accordion-Thinking的框架，该框架使LLM能够通过动态摘要自我调节推理步骤的粒度。", "motivation": "扩展测试时间计算量以解锁卓越的推理能力面临着KV缓存线性增长和注意力复杂度呈二次方的增长的实际限制。因此，开发一种可以在不牺牲解决方案质量的情况下减少对历史令牌依赖性的方法至关重要。", "method": "Accordion-Thinking框架通过强化学习激励模型通过动态摘要自我调节推理步骤的粒度，并周期性地总结其思维过程以减小内存占用。训练过程中，这种机制使Fold模式与Unfold模式之间的准确性差距逐渐缩小直至消失。", "result": "本文提出的方法实现了3倍的吞吐量同时保持了48GB GPU内存配置下的准确性。此外，结构化的步骤摘要为推理过程提供了可读性高的解释。", "conclusion": "Accordion-Thinking证明了LLM能够在不牺牲解决方案质量的情况下通过自我压缩来处理复杂的推理任务，并且在减少依赖令牌开销的同时提高了效率和可读性。"}}
{"id": "2602.03248", "pdf": "https://arxiv.org/pdf/2602.03248", "abs": "https://arxiv.org/abs/2602.03248", "authors": ["Yanchen Shen", "Kohei Tsuji", "Haruto Koizumi", "Jiseon Hong", "Tomoaki Niiyama", "Hiroyuki Kuwabara", "Hayato Ishida", "Jun Hiramitsu", "Mitsuhito Mase", "Satoshi Sunada"], "title": "A thin and soft optical tactile sensor for highly sensitive object perception", "categories": ["cs.RO", "physics.app-ph", "physics.optics"], "comment": null, "summary": "Tactile sensing is crucial in robotics and wearable devices for safe perception and interaction with the environment. Optical tactile sensors have emerged as promising solutions, as they are immune to electromagnetic interference and have high spatial resolution. However, existing optical approaches, particularly vision-based tactile sensors, rely on complex optical assemblies that involve lenses and cameras, resulting in bulky, rigid, and alignment-sensitive designs. In this study, we present a thin, compact, and soft optical tactile sensor featuring an alignment-free configuration. The soft optical sensor operates by capturing deformation-induced changes in speckle patterns generated within a soft silicone material, thereby enabling precise force measurements and texture recognition via machine learning. The experimental results show a root-mean-square error of 40 mN in the force measurement and a classification accuracy of 93.33% over nine classes of textured surfaces, including Mahjong tiles. The proposed speckle-based approach provides a compact, easily fabricated, and mechanically compliant platform that bridges optical sensing with flexible shape-adaptive architectures, thereby demonstrating its potential as a novel tactile-sensing paradigm for soft robotics and wearable haptic interfaces.", "AI": {"tldr": "本文提出了一种薄、紧凑且柔软的光学触觉传感器，能够通过机器学习实现精确力测量和纹理识别。", "motivation": "现有的光学触觉传感方法通常依赖复杂的光学组件，导致设计笨重、刚硬并且对准要求严格。因此，研究开发一种更轻便、灵活且无需对准的新型光学触觉传感器。", "method": "通过捕捉软硅胶材料中变形引起的斑点图案变化来操作光感器，从而实现精确力测量和纹理识别。", "result": "实验结果表明，在力测量中的均方根误差为40毫牛顿，并且对九类具有不同纹理的表面进行分类准确率为93.33%，包括麻将牌等。", "conclusion": "提出的基于斑点的方法提供了一个紧凑、易于制造并且机械柔顺性的平台，这将光学传感与柔性形状自适应结构相结合，展示了其作为软机器人和可穿戴触觉接口新型触觉传感范式的潜力。"}}
{"id": "2602.03245", "pdf": "https://arxiv.org/pdf/2602.03245", "abs": "https://arxiv.org/abs/2602.03245", "authors": ["Nikola Ljubešić", "Peter Rupnik", "Tea Perinčić"], "title": "Mići Princ -- A Little Boy Teaching Speech Technologies the Chakavian Dialect", "categories": ["eess.AS", "cs.CL"], "comment": "2 figures, 14 pages, accepted and presented at JTDH 2024", "summary": "This paper documents our efforts in releasing the printed and audio book of the translation of the famous novel The Little Prince into the Chakavian dialect, as a computer-readable, AI-ready dataset, with the textual and the audio components of the two releases now aligned on the level of each written and spoken word. Our motivation for working on this release is multiple. The first one is our wish to preserve the highly valuable and specific content beyond the small editions of the printed and the audio book. With the dataset published in the CLARIN.SI repository, this content is from now on at the fingertips of any interested individual. The second motivation is to make the data available for various artificial-intelligence-related usage scenarios, such as the one we follow upon inside this paper already -- adapting the Whisper-large-v3 open automatic speech recognition model, with decent performance on standard Croatian, to Chakavian dialectal speech. We can happily report that with adapting the model, the word error rate on the selected test data has being reduced to a half, while we managed to remove up to two thirds of the error on character level. We envision many more usages of this dataset beyond the set of experiments we have already performed, both on tasks of artificial intelligence research and application, as well as dialectal research. The third motivation for this release is our hope that this, now highly structured dataset, will be transformed into a digital online edition of this work, allowing individuals beyond the research and technology communities to enjoy the beauty of the message of the little boy in the desert, told through the spectacular prism of the Chakavian dialect.", "AI": {"tldr": "本文记录了将《小王子》翻译成查卡维亚方言的书籍和有声书出版，并将其转化为适用于AI的数据集的过程。", "motivation": "动机包括保存珍贵内容，促进人工智能相关应用研究以及通过数字化在线版本让更广泛的受众欣赏该作品。", "method": "通过调整Whisper-large-v3语音识别模型来适应查卡维亚方言的语音，将文本和音频对齐到每个单词和字符级别。", "result": "调整后的模型在选定测试数据上的词错误率降低了一半，并且字符级别的误差减少了三分之二。", "conclusion": "该研究展示了通过发布高度结构化的数据集来促进查卡维亚方言的AI应用和其他研究的可能性。"}}
{"id": "2602.03242", "pdf": "https://arxiv.org/pdf/2602.03242", "abs": "https://arxiv.org/abs/2602.03242", "authors": ["Zhuoran Yang", "Xi Guo", "Chenjing Ding", "Chiyu Wang", "Wei Wu", "Yanyong Zhang"], "title": "InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Autonomous driving relies on robust models trained on high-quality, large-scale multi-view driving videos. While world models offer a cost-effective solution for generating realistic driving videos, they struggle to maintain instance-level temporal consistency and spatial geometric fidelity. To address these challenges, we propose InstaDrive, a novel framework that enhances driving video realism through two key advancements: (1) Instance Flow Guider, which extracts and propagates instance features across frames to enforce temporal consistency, preserving instance identity over time. (2) Spatial Geometric Aligner, which improves spatial reasoning, ensures precise instance positioning, and explicitly models occlusion hierarchies. By incorporating these instance-aware mechanisms, InstaDrive achieves state-of-the-art video generation quality and enhances downstream autonomous driving tasks on the nuScenes dataset. Additionally, we utilize CARLA's autopilot to procedurally and stochastically simulate rare but safety-critical driving scenarios across diverse maps and regions, enabling rigorous safety evaluation for autonomous systems. Our project page is https://shanpoyang654.github.io/InstaDrive/page.html.", "AI": {"tldr": "本文提出了一种新的框架InstaDrive，旨在通过两个关键改进来生成更加逼真和一致的驾驶视频：实例流引导器和空间几何对齐器。", "motivation": "世界模型能够以低成本生成现实驾驶视频，但难以维持实例级别的时空一致性。为了提高驾驶视频的真实性并增强下游自动驾驶任务的表现，本文提出了解决方案。", "method": "InstaDrive框架包含两个主要组件：实例流引导器和空间几何对齐器。前者通过跨帧提取和传播特征以维护时间一致性；后者用于改进空间推理、确保精确的定位，并明确建模遮挡层次。", "result": "在nuScenes数据集上，本文提出的方法实现了最先进的视频生成质量，增强了自动驾驶任务的表现。同时，该方法还利用CARLA的自动导航功能模拟了各种稀有的但关键的安全驾驶场景。", "conclusion": "InstaDrive通过实例感知机制提高了驾驶视频的逼真度和一致性，并为自动驾驶系统的安全性评估提供了有力支持。"}}
{"id": "2602.03238", "pdf": "https://arxiv.org/pdf/2602.03238", "abs": "https://arxiv.org/abs/2602.03238", "authors": ["Pengyu Zhu", "Li Sun", "Philip S. Yu", "Sen Su"], "title": "The Necessity of a Unified Framework for LLM-Based Agent Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.", "AI": {"tldr": "提出了一种统一的框架来评估基于大语言模型的智能体", "motivation": "现有评价体系受系统提示、工具集配置和环境动态等因素影响，难以将性能提升归因于模型本身，导致评价结果不公平且不可追溯。因此需要标准化评价以促进领域发展", "method": "引入一种标准化的方法来统一智能体评估框架", "result": "提供了一种更公平、透明的智能体评价方法，但具体实施细节未给出", "conclusion": "强调了统一评估框架对大语言模型智能体发展的必要性"}}
{"id": "2602.03230", "pdf": "https://arxiv.org/pdf/2602.03230", "abs": "https://arxiv.org/abs/2602.03230", "authors": ["Shaoyu Liu", "Jianing Li", "Guanghui Zhao", "Yunjian Zhang", "Wen Jiang", "Ming Li", "Xiangyang Ji"], "title": "EventFlash: Towards Efficient MLLMs for Event-Based Vision", "categories": ["cs.CV"], "comment": null, "summary": "Event-based multimodal large language models (MLLMs) enable robust perception in high-speed and low-light scenarios, addressing key limitations of frame-based MLLMs. However, current event-based MLLMs often rely on dense image-like processing paradigms, overlooking the spatiotemporal sparsity of event streams and resulting in high computational cost. In this paper, we propose EventFlash, a novel and efficient MLLM to explore spatiotemporal token sparsification for reducing data redundancy and accelerating inference. Technically, we build EventMind, a large-scale and scene-diverse dataset with over 500k instruction sets, providing both short and long event stream sequences to support our curriculum training strategy. We then present an adaptive temporal window aggregation module for efficient temporal sampling, which adaptively compresses temporal tokens while retaining key temporal cues. Finally, a sparse density-guided attention module is designed to improve spatial token efficiency by selecting informative regions and suppressing empty or sparse areas. Experimental results show that EventFlash achieves a $12.4\\times$ throughput improvement over the baseline (EventFlash-Zero) while maintaining comparable performance. It supports long-range event stream processing with up to 1,000 bins, significantly outperforming the 5-bin limit of EventGPT. We believe EventFlash serves as an efficient foundation model for event-based vision.", "AI": {"tldr": "提出了一种高效的事件基础视觉模型EventFlash，通过时空稀疏化减少冗余并加速推断。", "motivation": "当前基于帧的多模态大规模语言模型在高速和低光场景中性能受限。现有基于事件的MLLM依赖密集处理方式，忽视了事件流的时空稀疏性，导致计算成本高。", "method": "建立了一个大规模多样化的数据集EventMind，设计了自适应时间窗口聚合模块和稀疏密度引导注意力模块，分别用于高效采样和提高空间标记效率。", "result": "实验结果显示，EventFlash相比基线模型（EventFlash-Zero）有12.4倍的吞吐量提升，并且支持长达1000个bin的事件流处理，优于5-bin限制下的EventGPT。", "conclusion": "EventFlash作为高效的基于事件视觉的基础模型，在时空稀疏性利用方面取得了显著成果。"}}
{"id": "2602.03229", "pdf": "https://arxiv.org/pdf/2602.03229", "abs": "https://arxiv.org/abs/2602.03229", "authors": ["Nicolaj Haarhøj Malle", "Emad Ebeid"], "title": "Omnidirectional Solid-State mmWave Radar Perception for UAV Power Line Collision Avoidance", "categories": ["cs.RO"], "comment": "Accepted for publication at the 2026 IEEE International Conference on Robotics and Automation (ICRA). Video at https://www.youtube.com/watch?v=rJW3eEC-5Ao (youtube)", "summary": "Detecting and estimating distances to power lines is a challenge for both human UAV pilots and autonomous systems, which increases the risk of unintended collisions. We present a mmWave radar-based perception system that provides spherical sensing coverage around a small UAV for robust power line detection and avoidance. The system integrates multiple compact solid-state mmWave radar modules to synthesize an omnidirectional field of view while remaining lightweight. We characterize the sensing behavior of this omnidirectional radar arrangement in power line environments and develop a robust detection-and-avoidance algorithm tailored to that behavior. Field experiments on real power lines demonstrate reliable detection at ranges up to 10 m, successful avoidance maneuvers at flight speeds upwards of 10 m/s, and detection of wires as thin as 1.2 mm in diameter. These results indicate the approach's suitability as an additional safety layer for both autonomous and manual UAV flight.", "AI": {"tldr": "本文提出了一种基于毫米波雷达的小型无人机电力线碰撞避免感知系统。", "motivation": "检测和估计与电线的距离对小型无人飞机的自主或手动飞行是一个挑战，增加了意外撞击的风险。", "method": "该方法使用多个紧凑的固态毫米波雷达模块集成在一起以提供全方位感应覆盖，并开发了针对这种全方位雷达排列的行为特性进行稳健检测和避免算法。", "result": "实地试验显示，在10米范围内能够可靠地检测电线，飞行速度超过10m/s时可成功执行避障操作，并能检测出直径仅为1.2毫米的电线。", "conclusion": "实验结果表明该方法适用于小型无人机电力线碰撞避免的安全层。"}}
{"id": "2602.03227", "pdf": "https://arxiv.org/pdf/2602.03227", "abs": "https://arxiv.org/abs/2602.03227", "authors": ["Haoyu Liu", "Sucheng Ren", "Tingyu Zhu", "Peng Wang", "Cihang Xie", "Alan Yuille", "Zeyu Zheng", "Feng Wang"], "title": "Spiral RoPE: Rotate Your Rotary Positional Embeddings in the 2D Plane", "categories": ["cs.CV"], "comment": null, "summary": "Rotary Position Embedding (RoPE) is the de facto positional encoding in large language models due to its ability to encode relative positions and support length extrapolation. When adapted to vision transformers, the standard axial formulation decomposes two-dimensional spatial positions into horizontal and vertical components, implicitly restricting positional encoding to axis-aligned directions. We identify this directional constraint as a fundamental limitation of the standard axial 2D RoPE, which hinders the modeling of oblique spatial relationships that naturally exist in natural images. To overcome this limitation, we propose Spiral RoPE, a simple yet effective extension that enables multi-directional positional encoding by partitioning embedding channels into multiple groups associated with uniformly distributed directions. Each group is rotated according to the projection of the patch position onto its corresponding direction, allowing spatial relationships to be encoded beyond the horizontal and vertical axes. Across a wide range of vision tasks including classification, segmentation, and generation, Spiral RoPE consistently improves performance. Qualitative analysis of attention maps further show that Spiral RoPE exhibits more concentrated activations on semantically relevant objects and better respects local object boundaries, highlighting the importance of multi-directional positional encoding in vision transformers.", "AI": {"tldr": "螺旋RoPE通过在二维平面上旋转嵌入通道，改进了视觉Transformer中的位置编码。", "motivation": "标准的轴向二维RoPE限制了方向性，阻碍了对自然图像中斜向空间关系的学习。为了克服这一局限性，作者提出了Spiral RoPE来实现多方向的位置编码。", "method": "通过将嵌入通道划分为多个与均匀分布的方向相关的组，并根据补丁位置在相应方向上的投影旋转每一组，从而实现了多方向的位置编码。", "result": "实验结果显示，在分类、分割和生成等广泛视觉任务中，Spiral RoPE均提升了性能。注意力图的定性分析表明，Spiral RoPE使激活集中在语义相关的物体上，并更好地遵守局部物体边界。", "conclusion": "多方向的位置编码在视觉Transformer中的重要性得到了强调，Spiral RoPE为解决这一问题提供了一个简单的有效方法"}}
{"id": "2602.03226", "pdf": "https://arxiv.org/pdf/2602.03226", "abs": "https://arxiv.org/abs/2602.03226", "authors": ["Xuancheng Li", "Haitao Li", "Yujia Zhou", "Qingyao Ai", "Yiqun Liu"], "title": "ATACompressor: Adaptive Task-Aware Compression for Efficient Long-Context Processing in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Long-context inputs in large language models (LLMs) often suffer from the \"lost in the middle\" problem, where critical information becomes diluted or ignored due to excessive length. Context compression methods aim to address this by reducing input size, but existing approaches struggle with balancing information preservation and compression efficiency. We propose Adaptive Task-Aware Compressor (ATACompressor), which dynamically adjusts compression based on the specific requirements of the task. ATACompressor employs a selective encoder that compresses only the task-relevant portions of long contexts, ensuring that essential information is preserved while reducing unnecessary content. Its adaptive allocation controller perceives the length of relevant content and adjusts the compression rate accordingly, optimizing resource utilization. We evaluate ATACompressor on three QA datasets: HotpotQA, MSMARCO, and SQUAD-showing that it outperforms existing methods in terms of both compression efficiency and task performance. Our approach provides a scalable solution for long-context processing in LLMs. Furthermore, we perform a range of ablation studies and analysis experiments to gain deeper insights into the key components of ATACompressor.", "AI": {"tldr": "提出了一种自适应任务感知压缩器（ATACompressor）以解决长上下文处理中的信息丢失问题。", "motivation": "现有上下文压缩方法难以平衡信息保留和压缩效率，尤其是在长输入中关键信息被忽略或稀释的情况下。", "method": "ATACompressor通过选择性编码只压缩任务相关的部分，并采用自适应分配控制器根据相关内容长度调整压缩率以优化资源利用。", "result": "在HotpotQA、MSMARCO和SQUAD三个问答数据集上，ATACompressor优于现有方法，在压缩效率和任务性能方面均表现出色。", "conclusion": "ATACompressor为LLMs的长上下文处理提供了一种可扩展解决方案，并通过一系列消融研究和分析实验验证了其关键组件的有效性。"}}
{"id": "2602.03224", "pdf": "https://arxiv.org/pdf/2602.03224", "abs": "https://arxiv.org/abs/2602.03224", "authors": ["Yu Cheng", "Jiuan Zhou", "Yongkang Hu", "Yihang Chen", "Huichi Zhou", "Mingang Chen", "Zhizhong Zhang", "Kun Shao", "Yuan Xie", "Zhaoxia Yin"], "title": "TAME: A Trustworthy Test-Time Evolution of Agent Memory with Systematic Benchmarking", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Test-time evolution of agent memory serves as a pivotal paradigm for achieving AGI by bolstering complex reasoning through experience accumulation. However, even during benign task evolution, agent safety alignment remains vulnerable-a phenomenon known as Agent Memory Misevolution. To evaluate this phenomenon, we construct the Trust-Memevo benchmark to assess multi-dimensional trustworthiness during benign task evolution, revealing an overall decline in trustworthiness across various task domains and evaluation settings. To address this issue, we propose TAME, a dual-memory evolutionary framework that separately evolves executor memory to improve task performance by distilling generalizable methodologies, and evaluator memory to refine assessments of both safety and task utility based on historical feedback. Through a closed loop of memory filtering, draft generation, trustworthy refinement, execution, and dual-track memory updating, TAME preserves trustworthiness without sacrificing utility. Experiments demonstrate that TAME mitigates misevolution, achieving a joint improvement in both trustworthiness and task performance.", "AI": {"tldr": "提出TAME框架，通过双内存进化提升代理在任务执行中的信任度和性能。", "motivation": "为了解决代理记忆在良性任务演进过程中的不一致性和安全性下降问题，提高代理的信任度和实用性。", "method": "构建Trust-Memevo基准以评估多维度信任度，并提出TAME双内存进化框架，通过独立演化执行器记忆来提升任务性能，并使用评价器记忆优化安全性和任务效用的评估。", "result": "实验显示，TAME可以有效缓解代理记忆不一致的问题，同时在信任度和任务性能上都取得了联合改进。", "conclusion": "TAME框架能够在保持实用性的同时保护演进过程中的信任度，是解决代理记忆进化问题的有效方法。"}}
{"id": "2602.03223", "pdf": "https://arxiv.org/pdf/2602.03223", "abs": "https://arxiv.org/abs/2602.03223", "authors": ["Jiahao Liu", "Hongji Ruan", "Weimin Zhang", "Ziye Tong", "Derick Tang", "Zhanpeng Zeng", "Qinsong Zeng", "Peng Zhang", "Tun Lu", "Ning Gu"], "title": "Distribution-Aware End-to-End Embedding for Streaming Numerical Features in Click-Through Rate Prediction", "categories": ["cs.IR", "cs.AI"], "comment": "Under review", "summary": "This paper explores effective numerical feature embedding for Click-Through Rate prediction in streaming environments. Conventional static binning methods rely on offline statistics of numerical distributions; however, this inherently two-stage process often triggers semantic drift during bin boundary updates. While neural embedding methods enable end-to-end learning, they often discard explicit distributional information. Integrating such information end-to-end is challenging because streaming features often violate the i.i.d. assumption, precluding unbiased estimation of the population distribution via the expectation of order statistics. Furthermore, the critical context dependency of numerical distributions is often neglected. To this end, we propose DAES, an end-to-end framework designed to tackle numerical feature embedding in streaming training scenarios by integrating distributional information with an adaptive modulation mechanism. Specifically, we introduce an efficient reservoir-sampling-based distribution estimation method and two field-aware distribution modulation strategies to capture streaming distributions and field-dependent semantics. DAES significantly outperforms existing approaches as demonstrated by extensive offline and online experiments and has been fully deployed on a leading short-video platform with hundreds of millions of daily active users.", "AI": {"tldr": "该论文探讨了在流环境中点击率预测中的有效数值特征嵌入方法。", "motivation": "传统静态分箱方法依赖离线统计的数值分布，但这种方法导致语义漂移。神经嵌入方法虽然支持端到端学习，但常常忽略了显式的分布信息。为解决这些问题，提出了DAES框架以集成分布信息和自适应调制机制。", "method": "提出了一种基于高效蓄水池采样的分布估计方法以及两种场感知的分布调制策略来捕捉流特征和领域相关语义。", "result": "在广泛的离线和在线实验中，DAES的表现显著优于现有的方法，并已在具有数亿日活跃用户的领先短视频平台上全面部署。", "conclusion": "该论文提出了一种有效的数值特征嵌入框架，解决了传统方法中存在的问题，并展示了其优越的性能。"}}
{"id": "2602.03220", "pdf": "https://arxiv.org/pdf/2602.03220", "abs": "https://arxiv.org/abs/2602.03220", "authors": ["Jingbang Tang"], "title": "PokeFusion Attention: Enhancing Reference-Free Style-Conditioned Generation", "categories": ["cs.CV"], "comment": "7 pages, 5 figures. Under review at IJCNN 2026", "summary": "This paper studies reference-free style-conditioned character generation in text-to-image diffusion models, where high-quality synthesis requires both stable character structure and consistent, fine-grained style expression across diverse prompts. Existing approaches primarily rely on text-only prompting, which is often under-specified for visual style and tends to produce noticeable style drift and geometric inconsistency, or introduce reference-based adapters that depend on external images at inference time, increasing architectural complexity and limiting deployment flexibility.We propose PokeFusion Attention, a lightweight decoder-level cross-attention mechanism that fuses textual semantics with learned style embeddings directly inside the diffusion decoder. By decoupling text and style conditioning at the attention level, our method enables effective reference-free stylized generation while keeping the pretrained diffusion backbone fully frozen.PokeFusion Attention trains only decoder cross-attention layers together with a compact style projection module, resulting in a parameter-efficient and plug-and-play control component that can be easily integrated into existing diffusion pipelines and transferred across different backbones.Experiments on a stylized character generation benchmark (Pokemon-style) demonstrate that our method consistently improves style fidelity, semantic alignment, and character shape consistency compared with representative adapter-based baselines, while maintaining low parameter overhead and inference-time simplicity.", "AI": {"tldr": "提出了一种轻量级的PokeFusion注意力机制，用于在文本到图像的扩散模型中进行无参考条件下的风格化生成。", "motivation": "现有方法依赖于仅基于文本的提示或外部图像，在生成高质量图像时存在风格漂移和几何不一致性的问题。为了克服这些问题，本文提出了一种新的注意力机制以提高生成的质量和灵活性。", "method": "PokeFusion Attention通过解耦文本和样式条件在注意级别上融合了语义信息与学习到的样式嵌入，并直接将其应用于扩散模型的解码器中，从而提高了无参考条件下的风格化生成能力。该方法仅需训练解码器交叉注意力层及一个紧凑的风格投影模块。", "result": "实验表明，PokeFusion Attention在风格忠实度、语义对齐和角色形状一致性方面优于代表性的基于适配器的方法，并且具有较低的参数开销和简单的推理时间复杂性。", "conclusion": "该方法提供了一种有效的无参考条件下的风格化生成解决方案，可以轻松地集成到现有的扩散管道中并跨不同的骨干网络进行转移。"}}
{"id": "2602.03219", "pdf": "https://arxiv.org/pdf/2602.03219", "abs": "https://arxiv.org/abs/2602.03219", "authors": ["Guhong Chen", "Chenghao Sun", "Cheng Fu", "Qiyao Wang", "Zhihong Huang", "Chaopeng Wei", "Guangxu Chen", "Feiteng Fang", "Ahmadreza Argha", "Bing Zhao", "Xander Xu", "Qi Han", "Hamid Alinejad-Rokny", "Qiang Qu", "Binhua Li", "Shiwen Ni", "Min Yang", "Hu Wei", "Yongbin Li"], "title": "Beyond Quantity: Trajectory Diversity Scaling for Code Agents", "categories": ["cs.AI"], "comment": null, "summary": "As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quantity-centric scaling exhibits an early bottleneck that underutilizes trajectory data. We propose TDScaling, a Trajectory Diversity Scaling-based data synthesis framework for code agents that scales performance through diversity rather than raw volume. Under a fixed training budget, increasing trajectory diversity yields larger gains than adding more trajectories, improving the performance-cost trade-off for agent training. TDScaling integrates four innovations: (1) a Business Cluster mechanism that captures real-service logical dependencies; (2) a blueprint-driven multi-agent paradigm that enforces trajectory coherence; (3) an adaptive evolution mechanism that steers synthesis toward long-tail scenarios using Domain Entropy, Reasoning Mode Entropy, and Cumulative Action Complexity to prevent mode collapse; and (4) a sandboxed code tool that mitigates catastrophic forgetting of intrinsic coding capabilities. Experiments on general tool-use benchmarks (BFCL, tau^2-Bench) and code agent tasks (RebenchT, CodeCI, BIRD) demonstrate a win-win outcome: TDScaling improves both tool-use generalization and inherent coding proficiency. We plan to release the full codebase and the synthesized dataset (including 30,000+ tool clusters) upon publication.", "AI": {"tldr": "本文提出了TDScaling框架，通过增加轨迹多样性而不是单纯增加数据量来提高代码代理的性能。", "motivation": "随着模型上下文协议（MCP）的发展，代码大型语言模型（LLMs）变成工具交互式代理时，其泛化能力受到低质量合成数据和数量扩展递减效应的影响。为解决这些问题，本文提出通过增加轨迹多样性来提高性能的TDScaling框架。", "method": "TDScaling整合了四个创新机制：业务集群机制、蓝图驱动多代理模式、自适应演化机制以及沙箱代码工具，以增强轨迹数据的多样性和避免模态坍缩问题。", "result": "实验表明，TDScaling在提高工具使用泛化能力和内在编程技能方面取得了双赢效果。具体而言，在BFCL、tau^2-Bench等通用工具使用基准测试和RebenchT、CodeCI、BIRD等代码代理任务上表现出色。", "conclusion": "通过引入轨迹多样性扩展（TDScaling）框架，研究证明了在固定训练预算下增加轨迹多样性比单纯增加数据量更能提升性能。这为提高代码代理的训练效率提供了新思路。"}}
{"id": "2602.03217", "pdf": "https://arxiv.org/pdf/2602.03217", "abs": "https://arxiv.org/abs/2602.03217", "authors": ["May Kristine Jonson Carlon", "Su Myat Noe", "Haojiong Wang", "Yasuo Kuniyoshi"], "title": "Topology Matters: A Cautionary Case Study of Graph SSL on Neuro-Inspired Benchmarks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Understanding how local interactions give rise to global brain organization requires models that can represent information across multiple scales. We introduce a hierarchical self-supervised learning (SSL) framework that jointly learns node-, edge-, and graph-level embeddings, inspired by multimodal neuroimaging. We construct a controllable synthetic benchmark mimicking the topological properties of connectomes. Our four-stage evaluation protocol reveals a critical failure: the invariance-based SSL model is fundamentally misaligned with the benchmark's topological properties and is catastrophically outperformed by classical, topology-aware heuristics. Ablations confirm an objective mismatch: SSL objectives designed to be invariant to topological perturbations learn to ignore the very community structure that classical methods exploit. Our results expose a fundamental pitfall in applying generic graph SSL to connectome-like data. We present this framework as a cautionary case study, highlighting the need for new, topology-aware SSL objectives for neuro-AI research that explicitly reward the preservation of structure (e.g., modularity or motifs).", "AI": {"tldr": "介绍了一种层次自监督学习框架，用于神经成像数据中的节点、边和图级别嵌入的学习，并通过一个模仿脑连接体拓扑的合成基准揭示了通用图形SSL模型在处理类似数据时的关键失败。", "motivation": "研究如何通过局部交互产生全局大脑组织结构，引入了一种新的层次自监督学习框架来表示跨多个尺度的信息，并强调了通用图SSL模型与神经成像数据中固有拓扑特性之间的不匹配问题。", "method": "提出了一套包含节点、边和图级别的嵌入学习的层次自监督方法，并通过一个模仿脑连接体特性的可控制合成基准来评估该框架。此基准设计用于揭示不同SSL模型在处理具有特定社区结构的数据时的表现差异。", "result": "发现在基于不变性原则设计的目标函数指导下，图SSL模型倾向于忽视那些经典算法依赖的社区结构，并因此在测试基准上表现出灾难性的性能下降。", "conclusion": "研究指出了一种使用通用图SSL方法处理类似脑连接体数据时的关键失败案例，并强调了开发新的、关注拓扑特性的SSL目标对于神经AI领域的重要性。"}}
{"id": "2602.03215", "pdf": "https://arxiv.org/pdf/2602.03215", "abs": "https://arxiv.org/abs/2602.03215", "authors": ["Benjamin Maurel", "Agathe Guilloux", "Sarah Zohar", "Moreno Ursino", "Jean-Baptiste Woillard"], "title": "Latent Neural-ODE for Model-Informed Precision Dosing: Overcoming Structural Assumptions in Pharmacokinetics", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Accurate estimation of tacrolimus exposure, quantified by the area under the concentration-time curve (AUC), is essential for precision dosing after renal transplantation. Current practice relies on population pharmacokinetic (PopPK) models based on nonlinear mixed-effects (NLME) methods. However, these models depend on rigid, pre-specified assumptions and may struggle to capture complex, patient-specific dynamics, leading to model misspecification. In this study, we introduce a novel data-driven alternative based on Latent Ordinary Differential Equations (Latent ODEs) for tacrolimus AUC prediction. This deep learning approach learns individualized pharmacokinetic dynamics directly from sparse clinical data, enabling greater flexibility in modeling complex biological behavior. The model was evaluated through extensive simulations across multiple scenarios and benchmarked against two standard approaches: NLME-based estimation and the iterative two-stage Bayesian (it2B) method. We further performed a rigorous clinical validation using a development dataset (n = 178) and a completely independent external dataset (n = 75). In simulation, the Latent ODE model demonstrated superior robustness, maintaining high accuracy even when underlying biological mechanisms deviated from standard assumptions. Regarding experiments on clinical datasets, in internal validation, it achieved significantly higher precision with a mean RMSPE of 7.99% compared with 9.24% for it2B (p < 0.001). On the external cohort, it achieved an RMSPE of 10.82%, comparable to the two standard estimators (11.48% and 11.54%). These results establish the Latent ODE as a powerful and reliable tool for AUC prediction. Its flexible architecture provides a promising foundation for next-generation, multi-modal models in personalized medicine.", "AI": {"tldr": "本文提出了一种基于潜变量常微分方程的深度学习方法，用于精确预测移植术后他克莫司暴露量，以实现个性化给药。", "motivation": "现有的群体药物动力学模型依赖于严格的假设，并可能难以捕捉复杂的患者特异性动态变化。因此，需要一个更灵活的数据驱动的方法来克服这些限制。", "method": "使用潜变量常微分方程（Latent ODE）方法从稀疏的临床数据中直接学习个性化药代动力学动力学模型。", "result": "通过模拟实验和临床验证，Latent ODE 方法在内部验证中的平均 RMSPE 达到7.99%，优于传统的NLME 和it2B 方法。外部独立队列结果也表明其准确性和可靠性。", "conclusion": "潜变量常微分方程模型能够更灵活地捕捉复杂生物行为，为个性化医学提供了强大的工具和基础架构。"}}
{"id": "2602.03214", "pdf": "https://arxiv.org/pdf/2602.03214", "abs": "https://arxiv.org/abs/2602.03214", "authors": ["Guijie Wang", "Tong Lin", "Yifan Bai", "Anjia Cao", "Shiyi Liang", "Wangbo Zhao", "Xing Wei"], "title": "FARTrack: Fast Autoregressive Visual Tracking with High Performance", "categories": ["cs.CV"], "comment": null, "summary": "Inference speed and tracking performance are two critical evaluation metrics in the field of visual tracking. However, high-performance trackers often suffer from slow processing speeds, making them impractical for deployment on resource-constrained devices. To alleviate this issue, we propose FARTrack, a Fast Auto-Regressive Tracking framework. Since autoregression emphasizes the temporal nature of the trajectory sequence, it can maintain high performance while achieving efficient execution across various devices. FARTrack introduces Task-Specific Self-Distillation and Inter-frame Autoregressive Sparsification, designed from the perspectives of shallow-yet-accurate distillation and redundant-to-essential token optimization, respectively. Task-Specific Self-Distillation achieves model compression by distilling task-specific tokens layer by layer, enhancing the model's inference speed while avoiding suboptimal manual teacher-student layer pairs assignments. Meanwhile, Inter-frame Autoregressive Sparsification sequentially condenses multiple templates, avoiding additional runtime overhead while learning a temporally-global optimal sparsification strategy. FARTrack demonstrates outstanding speed and competitive performance. It delivers an AO of 70.6% on GOT-10k in real-time. Beyond, our fastest model achieves a speed of 343 FPS on the GPU and 121 FPS on the CPU.", "AI": {"tldr": "FARTrack是一种快速自回归视觉跟踪框架，旨在提高速度和性能。", "motivation": "高性能追踪器通常处理速度慢，难以在资源受限的设备上部署。为了解决这个问题，提出了FARTrack。", "method": "FARTrack通过任务特定自我蒸馏和帧间自回归稀疏化来压缩模型，提升推理速度。", "result": "实验显示FARTrack具有出色的实时性，在GOT-10k数据集上达到70.6%的AO，并且在GPU上的最快速度可达343FPS，CPU上为121FPS。", "conclusion": "FARTrack通过优化模型压缩和推理速度，实现了高效的自回归视觉跟踪。"}}
{"id": "2602.03213", "pdf": "https://arxiv.org/pdf/2602.03213", "abs": "https://arxiv.org/abs/2602.03213", "authors": ["Zhuoran Yang", "Yanyong Zhang"], "title": "ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask", "categories": ["cs.CV"], "comment": null, "summary": "Autonomous driving relies on robust models trained on large-scale, high-quality multi-view driving videos. Although world models provide a cost-effective solution for generating realistic driving data, they often suffer from identity drift, where the same object changes its appearance or category across frames due to the absence of instance-level temporal constraints. We introduce ConsisDrive, an identity-preserving driving world model designed to enforce temporal consistency at the instance level. Our framework incorporates two key components: (1) Instance-Masked Attention, which applies instance identity masks and trajectory masks within attention blocks to ensure that visual tokens interact only with their corresponding instance features across spatial and temporal dimensions, thereby preserving object identity consistency; and (2) Instance-Masked Loss, which adaptively emphasizes foreground regions with probabilistic instance masking, reducing background noise while maintaining overall scene fidelity. By integrating these mechanisms, ConsisDrive achieves state-of-the-art driving video generation quality and demonstrates significant improvements in downstream autonomous driving tasks on the nuScenes dataset. Our project page is https://shanpoyang654.github.io/ConsisDrive/page.html.", "AI": {"tldr": "提出了一种身份保持的驾驶世界模型ConsisDrive，用于生成高质量的驾驶视频。", "motivation": "现有世界模型在多视图驾驶视频生成时存在身份漂移问题，导致同一对象跨帧出现不同外观或类别变化。", "method": "引入了实例掩码注意力机制和实例掩码损失函数，通过这些技术确保视觉令牌仅与其对应的身份特征交互，并减少背景噪声以维持整体场景真实度。", "result": "ConsisDrive在驾驶视频生成质量上达到最先进的水平，在nuScenes数据集上的下游自动驾驶任务中表现出显著改进。", "conclusion": "该方法解决了身份漂移问题，提高了驾驶世界模型的性能和应用价值。"}}
{"id": "2602.03211", "pdf": "https://arxiv.org/pdf/2602.03211", "abs": "https://arxiv.org/abs/2602.03211", "authors": ["Yeongmin Kim", "Donghyeok Shin", "Byeonghu Na", "Minsang Park", "Richard Lee Kim", "Il-Chul Moon"], "title": "Lookahead Sample Reward Guidance for Test-Time Scaling of Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": "Under Review", "summary": "Diffusion models have demonstrated strong generative performance; however, generated samples often fail to fully align with human intent. This paper studies a test-time scaling method that enables sampling from regions with higher human-aligned reward values. Existing gradient guidance methods approximate the expected future reward (EFR) at an intermediate particle $\\mathbf{x}_t$ using a Taylor approximation, but this approximation at each time step incurs high computational cost due to sequential neural backpropagation. We show that the EFR at any $\\mathbf{x}_t$ can be computed using only marginal samples from a pre-trained diffusion model. The proposed EFR formulation detaches the neural dependency between $\\mathbf{x}_t$ and the EFR, enabling closed-form guidance computation without neural backpropagation. To further improve efficiency, we introduce lookahead sampling to collect marginal samples. For final sample generation, we use an accurate solver that guides particles toward high-reward lookahead samples. We refer to this sampling scheme as LiDAR sampling. LiDAR achieves substantial performance improvements using only three samples with a 3-step lookahead solver, exhibiting steep performance gains as lookahead accuracy and sample count increase; notably, it reaches the same GenEval performance as the latest gradient guidance method for SDXL with a 9.5x speedup.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.03210", "pdf": "https://arxiv.org/pdf/2602.03210", "abs": "https://arxiv.org/abs/2602.03210", "authors": ["Zhiwen Li", "Zhongjie Duan", "Jinyan Ye", "Cen Chen", "Daoyuan Chen", "Yaliang Li", "Yingda Chen"], "title": "VIRAL: Visual In-Context Reasoning via Analogy in Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Replicating In-Context Learning (ICL) in computer vision remains challenging due to task heterogeneity. We propose \\textbf{VIRAL}, a framework that elicits visual reasoning from a pre-trained image editing model by formulating ICL as conditional generation via visual analogy ($x_s : x_t :: x_q : y_q$). We adapt a frozen Diffusion Transformer (DiT) using role-aware multi-image conditioning and introduce a Mixture-of-Experts LoRA to mitigate gradient interference across diverse tasks. Additionally, to bridge the gaps in current visual context datasets, we curate a large-scale dataset spanning perception, restoration, and editing. Experiments demonstrate that VIRAL outperforms existing methods, validating that a unified V-ICL paradigm can handle the majority of visual tasks, including open-domain editing. Our code is available at https://anonymous.4open.science/r/VIRAL-744A", "AI": {"tldr": "提出了VIRAL框架，通过视觉类比来实现图像编辑任务中的上下文学习，并展示了其在处理多种视觉任务上的优越性。", "motivation": "计算机视觉领域中复制上下文学习（ICL）面临着由于任务异构性的挑战。现有的方法难以统一处理不同类型的视觉任务。", "method": "利用冻结的Diffusion Transformer并采用角色感知多图像条件化以及混合专家LoRA来减轻梯度干扰，同时构建了一个大规模的数据集以涵盖多种视觉任务需求。", "result": "实验结果表明VIRAL框架在各类视觉任务上优于现有方法，证明了统一的上下文学习范式可以处理大多数视觉任务。", "conclusion": "通过引入基于类比的方法来解决视觉中的上下文学习问题，展示了其有效性和灵活性，并为未来的研究方向提供了启示。"}}
{"id": "2602.03209", "pdf": "https://arxiv.org/pdf/2602.03209", "abs": "https://arxiv.org/abs/2602.03209", "authors": ["Marco Job", "Thomas Stastny", "Eleni Kelasidi", "Roland Siegwart", "Michael Pantic"], "title": "Depth Completion in Unseen Field Robotics Environments Using Extremely Sparse Depth Measurements", "categories": ["cs.RO"], "comment": "Accepted to ICRA 2026", "summary": "Autonomous field robots operating in unstructured environments require robust perception to ensure safe and reliable operations. Recent advances in monocular depth estimation have demonstrated the potential of low-cost cameras as depth sensors; however, their adoption in field robotics remains limited due to the absence of reliable scale cues, ambiguous or low-texture conditions, and the scarcity of large-scale datasets. To address these challenges, we propose a depth completion model that trains on synthetic data and uses extremely sparse measurements from depth sensors to predict dense metric depth in unseen field robotics environments. A synthetic dataset generation pipeline tailored to field robotics enables the creation of multiple realistic datasets for training purposes. This dataset generation approach utilizes textured 3D meshes from Structure from Motion and photorealistic rendering with novel viewpoint synthesis to simulate diverse field robotics scenarios. Our approach achieves an end-to-end latency of 53 ms per frame on a Nvidia Jetson AGX Orin, enabling real-time deployment on embedded platforms. Extensive evaluation demonstrates competitive performance across diverse real-world field robotics scenarios.", "AI": {"tldr": "该论文提出了一种基于稀疏深度测量的深度补全模型，用于在无人作业环境中生成密集度深度图。", "motivation": "为了提高自主机器人在无结构环境中的感知能力，以确保安全可靠的运行，需要解决单目深度估计中存在的规模线索缺失、纹理不足等问题，并缺乏大规模的数据集。", "method": "通过合成数据训练模型并使用极稀疏的深度传感器测量来预测密集度的度量深度。该方法采用基于SfM生成的3D网格和照片级渲染技术，以模拟各种机器人作业场景。", "result": "实验显示在Nvidia Jetson AGX Orin平台上实现了每帧53ms的延时，并且在多种真实世界机器人作业场景中取得了竞争性的性能表现。", "conclusion": "该方法能够在未见过的、具有挑战性的环境中有效预测密集度深度，对于实际应用来说是一个可靠的选择。"}}
{"id": "2602.03208", "pdf": "https://arxiv.org/pdf/2602.03208", "abs": "https://arxiv.org/abs/2602.03208", "authors": ["Jinyan Ye", "Zhongjie Duan", "Zhiwen Li", "Cen Chen", "Daoyuan Chen", "Yaliang Li", "Yingda Chen"], "title": "Spectral Evolution Search: Efficient Inference-Time Scaling for Reward-Aligned Image Generation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Inference-time scaling offers a versatile paradigm for aligning visual generative models with downstream objectives without parameter updates. However, existing approaches that optimize the high-dimensional initial noise suffer from severe inefficiency, as many search directions exert negligible influence on the final generation. We show that this inefficiency is closely related to a spectral bias in generative dynamics: model sensitivity to initial perturbations diminishes rapidly as frequency increases. Building on this insight, we propose Spectral Evolution Search (SES), a plug-and-play framework for initial noise optimization that executes gradient-free evolutionary search within a low-frequency subspace. Theoretically, we derive the Spectral Scaling Prediction from perturbation propagation dynamics, which explains the systematic differences in the impact of perturbations across frequencies. Extensive experiments demonstrate that SES significantly advances the Pareto frontier of generation quality versus computational cost, consistently outperforming strong baselines under equivalent budgets.", "AI": {"tldr": "提出了一种名为Spectral Evolution Search（SES）的插件式框架，用于优化初始噪声以提高奖励对齐图像生成效率。", "motivation": "现有方法在高维初始噪声优化中存在严重低效问题，因为许多搜索方向对最终生成影响较小。作者通过研究发现这种低效与生成动力学中的频谱偏向有关：模型对于初始扰动的敏感性随频率增加迅速减小。因此提出SES框架以提升效率并降低成本。", "method": "SES框架执行无梯度进化搜索，在低频子空间内进行优化。理论推导出Spectral Scaling Prediction，解释了不同频率下扰动影响的区别。", "result": "实验表明SES显著改进了生成质量与计算成本之间的帕累托前沿，在相同预算下持续优于强基线方法。", "conclusion": "SES为高效奖励对齐图像生成提供了一种新的有效途径，能够更好地平衡生成质量和时间效率。"}}
{"id": "2602.03207", "pdf": "https://arxiv.org/pdf/2602.03207", "abs": "https://arxiv.org/abs/2602.03207", "authors": ["Yudong Han", "Chao Xu", "Xiaodan Ye", "Weichen Bi", "Zilong Dong", "Yun Ma"], "title": "WebSplatter: Enabling Cross-Device Efficient Gaussian Splatting in Web Browsers via WebGPU", "categories": ["cs.GR", "cs.CV", "cs.PF"], "comment": ":I.3.7; I.3.1", "summary": "We present WebSplatter, an end-to-end GPU rendering pipeline for the heterogeneous web ecosystem. Unlike naive ports, WebSplatter introduces a wait-free hierarchical radix sort that circumvents the lack of global atomics in WebGPU, ensuring deterministic execution across diverse hardware. Furthermore, we propose an opacity-aware geometry culling stage that dynamically prunes splats before rasterization, significantly reducing overdraw and peak memory footprint. Evaluation demonstrates that WebSplatter consistently achieves 1.2$\\times$ to 4.5$\\times$ speedups over state-of-the-art web viewers.", "AI": {"tldr": "WebSplatter是一种在Web浏览器中通过WebGPU实现跨设备高效高斯点画的端到端GPU渲染管线。", "motivation": "为了克服传统方法在缺乏全局原子操作和不同硬件上执行非确定性的问题，提出了WebSplatter来提高性能并减少内存占用。", "method": "引入了无等待的层次化基数排序，并提出了一种基于透明度感知几何剪裁阶段的技术，在光栅化之前动态删除点画以减少过度绘制。", "result": "实验表明WebSplatter比最先进的网络查看器快1.2倍到4.5倍。", "conclusion": "通过创新的方法和技术，WebSplatter显著提高了跨设备的高效渲染性能和效率。"}}
{"id": "2602.03205", "pdf": "https://arxiv.org/pdf/2602.03205", "abs": "https://arxiv.org/abs/2602.03205", "authors": ["Jinrui Han", "Dewei Wang", "Chenyun Zhang", "Xinzhe Liu", "Ping Luo", "Chenjia Bai", "Xuelong Li"], "title": "HUSKY: Humanoid Skateboarding System via Physics-Aware Whole-Body Control", "categories": ["cs.RO"], "comment": null, "summary": "While current humanoid whole-body control frameworks predominantly rely on the static environment assumptions, addressing tasks characterized by high dynamism and complex interactions presents a formidable challenge. In this paper, we address humanoid skateboarding, a highly challenging task requiring stable dynamic maneuvering on an underactuated wheeled platform. This integrated system is governed by non-holonomic constraints and tightly coupled human-object interactions. Successfully executing this task requires simultaneous mastery of hybrid contact dynamics and robust balance control on a mechanically coupled, dynamically unstable skateboard. To overcome the aforementioned challenges, we propose HUSKY, a learning-based framework that integrates humanoid-skateboard system modeling and physics-aware whole-body control. We first model the coupling relationship between board tilt and truck steering angles, enabling a principled analysis of system dynamics. Building upon this, HUSKY leverages Adversarial Motion Priors (AMP) to learn human-like pushing motions and employs a physics-guided, heading-oriented strategy for lean-to-steer behaviors. Moreover, a trajectory-guided mechanism ensures smooth and stable transitions between pushing and steering. Experimental results on the Unitree G1 humanoid platform demonstrate that our framework enables stable and agile maneuvering on skateboards in real-world scenarios. The project page is available on https://husky-humanoid.github.io/.", "AI": {"tldr": "本文提出了一种新的学习框架HUSKY，用于解决人形机器人在滑板上进行动态操作和复杂交互的挑战。", "motivation": "现有基于静态环境假设的人形机器人全身控制系统难以应对高动态、复杂的交互任务。为了解决这一问题，研究者提出了HUSKY系统，以实现稳定且敏捷的操作。", "method": "该框架通过模拟滑板倾斜与转向角度之间的耦合关系来分析系统的动力学，并利用对抗运动先验（AMP）学习类似人类的推动动作，采用物理导向的方法控制向导行为。此外还使用轨迹引导机制确保推动和转向之间平稳过渡。", "result": "实验表明HUSKY框架在现实世界的环境中实现了稳定且敏捷的滑板操作。", "conclusion": "通过提出一种新的基于学习的人形机器人全身控制系统，可以克服传统方法中的静态假设限制，实现更复杂和动态的任务。"}}
{"id": "2602.03200", "pdf": "https://arxiv.org/pdf/2602.03200", "abs": "https://arxiv.org/abs/2602.03200", "authors": ["Wendi Hu", "Haonan Zhou", "Wenhao Hu", "Gaoang Wang"], "title": "Hand3R: Online 4D Hand-Scene Reconstruction in the Wild", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "For Embodied AI, jointly reconstructing dynamic hands and the dense scene context is crucial for understanding physical interaction. However, most existing methods recover isolated hands in local coordinates, overlooking the surrounding 3D environment. To address this, we present Hand3R, the first online framework for joint 4D hand-scene reconstruction from monocular video. Hand3R synergizes a pre-trained hand expert with a 4D scene foundation model via a scene-aware visual prompting mechanism. By injecting high-fidelity hand priors into a persistent scene memory, our approach enables simultaneous reconstruction of accurate hand meshes and dense metric-scale scene geometry in a single forward pass. Experiments demonstrate that Hand3R bypasses the reliance on offline optimization and delivers competitive performance in both local hand reconstruction and global positioning.", "AI": {"tldr": "Hand3R是一种在线框架，用于从单目视频中联合重建4D手部和场景。", "motivation": "现有的方法大多只恢复孤立的手部，在局部坐标系下工作，并忽略周围的3D环境。为了理解物理交互，需要同时重建动态的手部和密集的场景上下文。", "method": "Hand3R通过一种基于场景感知的视觉提示机制，将预训练的手专家与4D场景基础模型相结合。这种方法注入高保真手部先验到持久性场景记忆中，从而在单次前向传递中同时重建准确的手部网格和密集的度量级场景几何形状。", "result": "实验表明，Hand3R可以绕过离线优化的依赖，并且在局部手部重建和全局定位方面表现出竞争力。", "conclusion": "Hand3R为在线4D手-场景重建提供了一种新的框架，能够有效解决现有方法忽视周围环境的问题。"}}
{"id": "2602.03198", "pdf": "https://arxiv.org/pdf/2602.03198", "abs": "https://arxiv.org/abs/2602.03198", "authors": ["Minghang Zhu", "Zhijing Wang", "Yuxin Guo", "Wen Li", "Sheng Ao", "Cheng Wang"], "title": "From Single Scan to Sequential Consistency: A New Paradigm for LIDAR Relocalization", "categories": ["cs.CV"], "comment": "Nothing", "summary": "LiDAR relocalization aims to estimate the global 6-DoF pose of a sensor in the environment. However, existing regression-based approaches are prone to dynamic or ambiguous scenarios, as they either solely rely on single-frame inference or neglect the spatio-temporal consistency across scans. In this paper, we propose TempLoc, a new LiDAR relocalization framework that enhances the robustness of localization by effectively modeling sequential consistency. Specifically, a Global Coordinate Estimation module is first introduced to predict point-wise global coordinates and associated uncertainties for each LiDAR scan. A Prior Coordinate Generation module is then presented to estimate inter-frame point correspondences by the attention mechanism. Lastly, an Uncertainty-Guided Coordinate Fusion module is deployed to integrate both predictions of point correspondence in an end-to-end fashion, yielding a more temporally consistent and accurate global 6-DoF pose. Experimental results on the NCLT and Oxford Robot-Car benchmarks show that our TempLoc outperforms stateof-the-art methods by a large margin, demonstrating the effectiveness of temporal-aware correspondence modeling in LiDAR relocalization. Our code will be released soon.", "AI": {"tldr": "本文提出了一种新的LiDAR重定位框架TempLoc，通过建模序列一致性来增强定位的鲁棒性。", "motivation": "现有的基于回归的方法在处理动态或模糊场景时效果不佳，要么仅仅依赖单帧推断，要么忽略扫描间的时空一致性。因此，需要一种能够有效利用序列信息的新方法来提高LiDAR重定位的准确性与稳定性。", "method": "提出了一个名为TempLoc的新框架，包含三个模块：全局坐标估计模块用于预测每个激光雷达扫描点的全局坐标及不确定性；先验坐标生成模块通过注意力机制估算帧间点对应关系；不确定性引导下的坐标融合模块将点对应关系的两种预测以端到端的方式整合。", "result": "实验结果显示，在NCLT和牛津机器人汽车基准测试上，TempLoc的表现优于现有的最先进方法，展示了其在LiDAR重定位中建模时间感知对应性的有效性。", "conclusion": "通过引入序列一致性来增强激光雷达扫描点之间的关联性，可以在动态或模糊场景下实现更准确、稳定的6-DoF姿态估计。"}}
{"id": "2602.03197", "pdf": "https://arxiv.org/pdf/2602.03197", "abs": "https://arxiv.org/abs/2602.03197", "authors": ["Yoshee Jain", "Heejin Do", "Zihan Wu", "April Yi Wang"], "title": "Exploring the Role of Tracing in AI-Supported Planning for Algorithmic Reasoning", "categories": ["cs.HC"], "comment": "14 pages, 5 figures, 2 tables", "summary": "AI-powered planning tools show promise in supporting programming learners by enabling early, formative feedback on their thinking processes prior to coding. To date, however, most AI-supported planning tools rely on students' natural-language explanations, using LLMs to interpret learners' descriptions of their algorithmic intent. Prior to the emergence of LLM-based systems, CS education research extensively studied trace-based planning in pen-and-paper settings, demonstrating that reasoning through stepwise execution with explicit state transitions helps learners build and refine mental models of program behavior. Despite its potential, little is known about how tracing interacts with AI-mediated feedback and whether integrating tracing into AI-supported planning tools leads to different learning processes or interaction dynamics compared to natural-language-based planning alone. We study how requiring learners to produce explicit execution traces with an AI-supported planning tool affects their algorithmic reasoning. In a between-subjects study with 20 students, tracing shifted learners away from code-like, line-by-line descriptions toward more goal-driven reasoning about program behavior. Moreover, it led to more consistent partially correct solutions, although final coding performance remained comparable across conditions. Notably, tracing did not significantly affect the quality or reliability of LLM-generated feedback. These findings reveal tradeoffs in combining tracing with AI-supported planning and inform design guidelines for integrating natural language, tracing, and coding to support iterative reasoning throughout the programming process.", "AI": {"tldr": "研究探讨了在AI支持的规划工具中引入跟踪如何影响编程学习者的问题解决过程。", "motivation": "探索将传统上的手写追踪与现代AI辅助反馈结合的效果，以了解它们是否能够改善编程思维过程和最终代码性能。", "method": "通过对比实验设计，邀请20名学生参与研究，并记录他们在不同条件下的行为差异。", "result": "要求生成执行跟踪后，学习者从编码描述转向了目标导向的程序行为思考；在追踪条件下，部分正确解的一致性提高，但最终代码表现无显著差异。", "conclusion": "结合自然语言、追踪和编程支持迭代推理有其潜在价值，但需要注意这些方法间的权衡。"}}
{"id": "2602.03195", "pdf": "https://arxiv.org/pdf/2602.03195", "abs": "https://arxiv.org/abs/2602.03195", "authors": ["Jing-Cheng Pang", "Liang Lu", "Xian Tang", "Kun Jiang", "Sijie Wu", "Kai Zhang", "Xubin Li"], "title": "Reinforcement Learning with Promising Tokens for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has emerged as a key paradigm for aligning and optimizing large language models (LLMs). Standard approaches treat the LLM as the policy and apply RL directly over the full vocabulary space. However, this formulation includes the massive tail of contextually irrelevant tokens in the action space, which could distract the policy from focusing on decision-making among the truly reasonable tokens. In this work, we verify that valid reasoning paths could inherently concentrate within a low-rank subspace. Based on this insight, we introduce Reinforcement Learning with Promising Tokens (RLPT), a framework that mitigates the action space issue by decoupling strategic decision-making from token generation. Specifically, RLPT leverages the semantic priors of the base model to identify a dynamic set of \\emph{promising tokens} and constrains policy optimization exclusively to this refined subset via masking. Theoretical analysis and empirical results demonstrate that RLPT effectively reduces gradient variance, stabilizes the training process, and improves sample efficiency. Experiment results on math, coding, and telecom reasoning show that RLPT outperforms standard RL baselines and integrates effectively across various model sizes (4B and 8B) and RL algorithms (GRPO and DAPO).", "AI": {"tldr": "提出了一种新的框架RLPT，通过限制策略优化到动态识别的“有希望”的子集来改善大型语言模型的强化学习。", "motivation": "标准方法在行动空间中包含大量不相关的词汇，这可能分散决策中的注意力。作者希望通过缩小关注范围来提高训练过程的效率和稳定性。", "method": "引入Reinforcement Learning with Promising Tokens（RLPT）框架，利用基础模型的语义先验识别动态“有希望”的子集，并限制策略优化到这个精炼子集中。", "result": "理论分析和实验证明了RLPT可以有效减少梯度方差、稳定训练过程并提高采样效率。在数学、编码和电信推理任务上，实验结果显示RLPT优于标准强化学习基线并在不同模型大小和算法中表现良好。", "conclusion": "通过限制行动空间的策略优化来改善大型语言模型的强化学习效果是可行且有效的。"}}
{"id": "2602.03190", "pdf": "https://arxiv.org/pdf/2602.03190", "abs": "https://arxiv.org/abs/2602.03190", "authors": ["Wenquan Lu", "Hai Huang", "Randall Balestriero"], "title": "Prompt Augmentation Scales up GRPO Training on Mathematical Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning algorithms such as group-relative policy optimization (GRPO) have demonstrated strong potential for improving the mathematical reasoning capabilities of large language models. However, prior work has consistently observed an entropy collapse phenomenon during reinforcement post-training, characterized by a monotonic decrease in policy entropy that ultimately leads to training instability and collapse. As a result, most existing approaches restrict training to short horizons (typically 5-20 epochs), limiting sustained exploration and hindering further policy improvement. In addition, nearly all prior work relies on a single, fixed reasoning prompt or template during training. In this work, we introduce prompt augmentation, a training strategy that instructs the model to generate reasoning traces under diverse templates and formats, thereby increasing rollout diversity. We show that, without a KL regularization term, prompt augmentation enables stable scaling of training duration under a fixed dataset and allows the model to tolerate low-entropy regimes without premature collapse. Empirically, a Qwen2.5-Math-1.5B model trained with prompt augmentation on the MATH Level 3-5 dataset achieves state-of-the-art performance, reaching 44.5 per-benchmark accuracy and 51.3 per-question accuracy on standard mathematical reasoning benchmarks, including AIME24, AMC, MATH500, Minerva, and OlympiadBench. The code and model checkpoints are available at https://github.com/wenquanlu/prompt-augmentation-GRPO.", "AI": {"tldr": "本文提出了一种通过多样化提示来增强模型数学推理能力的策略，解决了强化学习中政策熵衰减的问题。", "motivation": "在数学推理任务上，现有的GRPO训练方法遇到政策熵崩溃问题，导致无法长时间稳定训练。因此作者提出了新的训练策略以克服这些问题。", "method": "通过引入提示增强技术让模型生成多样化的推演轨迹，并证明该方法可以在没有KL正则化项的情况下实现长时间的稳定训练。", "result": "实验表明，在MATH Level 3-5数据集上，使用提示增强技术训练得到的Qwen2.5-Math-1.5B模型在标准数学推理基准测试中表现优异，准确率达到44.5%（按基准）和51.3%（按问题）。", "conclusion": "提示增强方法提高了模型的稳定性和长期学习能力，在多个数学推理任务上达到了最新的性能水平。"}}
{"id": "2602.03188", "pdf": "https://arxiv.org/pdf/2602.03188", "abs": "https://arxiv.org/abs/2602.03188", "authors": ["Yu-Han Shu", "Toshiaki Tsuji", "Sho Sakaino"], "title": "Hierarchical Proportion Models for Motion Generation via Integration of Motion Primitives", "categories": ["cs.RO"], "comment": "6 pages, 9 figures. Accepted for publication in IEEE AMC 2026", "summary": "Imitation learning (IL) enables robots to acquire human-like motion skills from demonstrations, but it still requires extensive high-quality data and retraining to handle complex or long-horizon tasks. To improve data efficiency and adaptability, this study proposes a hierarchical IL framework that integrates motion primitives with proportion-based motion synthesis. The proposed method employs a two-layer architecture, where the upper layer performs long-term planning, while a set of lower-layer models learn individual motion primitives, which are combined according to specific proportions. Three model variants are introduced to explore different trade-offs between learning flexibility, computational cost, and adaptability: a learning-based proportion model, a sampling-based proportion model, and a playback-based proportion model, which differ in how the proportions are determined and whether the upper layer is trainable. Through real-robot pick-and-place experiments, the proposed models successfully generated complex motions not included in the primitive set. The sampling-based and playback-based proportion models achieved more stable and adaptable motion generation than the standard hierarchical model, demonstrating the effectiveness of proportion-based motion integration for practical robot learning.", "AI": {"tldr": "本文提出了一种基于层次比例模型的运动生成方法，通过整合运动基元来提高机器人模仿学习的数据效率和适应性。", "motivation": "传统的模仿学习需要大量的高质量数据和重新训练才能处理复杂的或长时间的任务。为了改善数据效率和适应性，论文提出了一个集成运动基本动作的分层学习框架。", "method": "提出的方法包括两层架构：上层进行长期规划，下层模型则学习单一的运动基元，并根据特定的比例组合这些基元。三种模型变体探索了不同灵活性、计算成本和适应性之间的权衡：基于学习的比例模型、基于采样的比例模型以及重播式比例模型。", "result": "通过实际机器人抓取放置实验，所提出的方法成功生成了不在原始集合内的复杂运动。", "conclusion": "研究表明，基于采样和重播的比例模型比标准层次化模型更能稳定且适应性地生成运动。"}}
{"id": "2602.03183", "pdf": "https://arxiv.org/pdf/2602.03183", "abs": "https://arxiv.org/abs/2602.03183", "authors": ["Hyunwoo Kim", "Niloofar Mireshghallah", "Michael Duan", "Rui Xin", "Shuyue Stella Li", "Jaehun Jung", "David Acuna", "Qi Pang", "Hanshen Xiao", "G. Edward Suh", "Sewoong Oh", "Yulia Tsvetkov", "Pang Wei Koh", "Yejin Choi"], "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch", "categories": ["cs.CL", "cs.AI"], "comment": "For code and data, see https://privasis.github.io", "summary": "Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models, such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.", "AI": {"tldr": "本文通过构建一个大规模的全合成隐私数据集Privasis，以促进敏感社会数据的研究和处理。", "motivation": "在研究涉及个人隐私的数据时，面临数据稀缺的问题。现代AI系统需要访问大量高度敏感的信息，这增加了风险。为此，作者创建了名为Privasis的大规模合成数据集来解决这些问题。", "method": "利用文本分解技术和针对性的脱敏处理构建了一个平行语料库，并训练了一组紧凑型脱敏模型。", "result": "Privasis包含140万记录和5510万个标注属性，质量高且种类多样。基于该数据集训练的模型在隐私保护方面的表现优于现有的大型语言模型。", "conclusion": "通过发布数据、模型及代码库，本文旨在加速未来研究并提升处理敏感社会数据的能力"}}
{"id": "2602.03182", "pdf": "https://arxiv.org/pdf/2602.03182", "abs": "https://arxiv.org/abs/2602.03182", "authors": ["Tianxing Wu", "Zheng Chen", "Cirou Xu", "Bowen Chai", "Yong Guo", "Yutong Liu", "Linghe Kong", "Yulun Zhang"], "title": "LSGQuant: Layer-Sensitivity Guided Quantization for One-Step Diffusion Real-World Video Super-Resolution", "categories": ["cs.CV"], "comment": "Code is available at: https://github.com/zhengchen1999/LSGQuant", "summary": "One-Step Diffusion Models have demonstrated promising capability and fast inference in video super-resolution (VSR) for real-world. Nevertheless, the substantial model size and high computational cost of Diffusion Transformers (DiTs) limit downstream applications. While low-bit quantization is a common approach for model compression, the effectiveness of quantized models is challenged by the high dynamic range of input latent and diverse layer behaviors. To deal with these challenges, we introduce LSGQuant, a layer-sensitivity guided quantizing approach for one-step diffusion-based real-world VSR. Our method incorporates a Dynamic Range Adaptive Quantizer (DRAQ) to fit video token activations. Furthermore, we estimate layer sensitivity and implement a Variance-Oriented Layer Training Strategy (VOLTS) by analyzing layer-wise statistics in calibration. We also introduce Quantization-Aware Optimization (QAO) to jointly refine the quantized branch and a retained high-precision branch. Extensive experiments demonstrate that our method has nearly performance to origin model with full-precision and significantly exceeds existing quantization techniques. Code is available at: https://github.com/zhengchen1999/LSGQuant.", "AI": {"tldr": "LSGQuant是一种针对一次性扩散模型视频超分辨率的层敏感量化方法，旨在减少模型大小和计算成本。", "motivation": "现有的扩散变换器（DiTs）在视频超分辨率中表现出色但模型庞大且计算成本高。为了降低这些限制并实现更有效的压缩，需要一种新的量化策略来适应视频令牌激活的变化。", "method": "提出了一种层敏感引导的量化方法LSGQuant，结合动态范围自适应量化器（DRAQ）和基于分层统计分析的变异性导向训练策略（VOLTS），同时引入了量化的感知优化（QAO）。", "result": "实验证明该方法在保持与原始全精度模型几乎相同性能的同时，超过了现有的量化技术。", "conclusion": "LSGQuant通过解决传统量化挑战，在一次扩散视频超分辨率任务中取得了显著成果。"}}
{"id": "2602.03177", "pdf": "https://arxiv.org/pdf/2602.03177", "abs": "https://arxiv.org/abs/2602.03177", "authors": ["Gautami Golani", "Dong Anh Khoa To", "Ananda Sidarta", "Arun-Kumar Kaliya-Perumal", "Oliver Roberts", "Lek Syn Lim", "Jim Patton", "Domenico Campolo"], "title": "Estimation of Ground Reaction Forces from Kinematic Data during Locomotion", "categories": ["cs.RO"], "comment": null, "summary": "Ground reaction forces (GRFs) provide fundamental insight into human gait mechanics and are widely used to assess joint loading, limb symmetry, balance control, and motor function. Despite their clinical relevance, the use of GRF remains underutilised in clinical workflows due to the practical limitations of force plate systems. In this work, we present a force-plate-free approach for estimating GRFs using only marker-based motion capture data. This kinematics only method to estimate and decompose GRF makes it well suited for widespread clinical depolyment. By using kinematics from sixteen body segments, we estimate the centre of mass (CoM) and compute GRFs, which are subsequently decomposed into individual components through a minimization-based approach. Through this framework, we can identify gait stance phases and provide access to clinically meaningful kinetic measures without a dedicated force plate system. Experimental results demonstrate the viability of CoM and GRF estimation based solely on kinematic data, supporting force-plate-free gait analysis.", "AI": {"tldr": "本文提出了一种仅基于运动捕捉数据估算地面反作用力的方法，以克服传统力量平台系统的限制。", "motivation": "由于传统的力板系统在临床应用中存在局限性，因此开发一种不需要力板的替代方法来估计地面反作用力具有重要意义。", "method": "利用来自十六个身体部位的运动捕捉数据估算质心并计算GRF，通过最小化方法进一步分解GRF。", "result": "实验结果表明，仅基于运动捕捉数据可以有效估算质心和GRF，支持无力量平台系统的步态分析。", "conclusion": "该研究提出的方法为临床应用提供了新的可能性，使得地面反作用力的评估更为便捷和广泛。"}}
{"id": "2602.03176", "pdf": "https://arxiv.org/pdf/2602.03176", "abs": "https://arxiv.org/abs/2602.03176", "authors": ["Zheng Chen", "Zhi Yang", "Xiaoyang Liu", "Weihang Zhang", "Mengfan Wang", "Yifan Fu", "Linghe Kong", "Yulun Zhang"], "title": "BinaryDemoire: Moiré-Aware Binarization for Image Demoiréing", "categories": ["cs.CV"], "comment": "Code is available at: https://github.com/zhengchen1999/BinaryDemoire", "summary": "Image demoiréing aims to remove structured moiré artifacts in recaptured imagery, where degradations are highly frequency-dependent and vary across scales and directions. While recent deep networks achieve high-quality restoration, their full-precision designs remain costly for deployment. Binarization offers an extreme compression regime by quantizing both activations and weights to 1-bit. Yet, it has been rarely studied for demoiréing and performs poorly when naively applied. In this work, we propose BinaryDemoire, a binarized demoiréing framework that explicitly accommodates the frequency structure of moiré degradations. First, we introduce a moiré-aware binary gate (MABG) that extracts lightweight frequency descriptors together with activation statistics. It predicts channel-wise gating coefficients to condition the aggregation of binary convolution responses. Second, we design a shuffle-grouped residual adapter (SGRA) that performs structured sparse shortcut alignment. It further integrates interleaved mixing to promote information exchange across different channel partitions. Extensive experiments on four benchmarks demonstrate that the proposed BinaryDemoire surpasses current binarization methods. Code: https://github.com/zhengchen1999/BinaryDemoire.", "AI": {"tldr": "提出了一种名为BinaryDemoire的二值化图像去伪影框架，用于去除图像中的结构化摩尔纹。", "motivation": "尽管深度网络在高精度恢复方面取得了成功，但其全精度设计对于部署来说成本高昂。通过量化激活和权重为1位来实现极端压缩的方法很少被研究，并且当直接应用时性能较差。", "method": "提出了一种摩尔纹感知二值化门（MABG），该方法提取轻量级频率描述符以及激活统计信息，预测通道级别的控制系数以调节二值卷积响应的聚合。设计了分组残差适配器(SGRA)，执行结构稀疏跳转对齐，并通过交错混合来促进不同通道分区之间的信息交换。", "result": "在四个基准测试中进行的广泛实验表明，提出的BinaryDemoire超越了现有的二值化方法。", "conclusion": "所提框架能有效去除图像中的摩尔纹伪影，在性能上优于现有二值化方法。"}}
{"id": "2602.03164", "pdf": "https://arxiv.org/pdf/2602.03164", "abs": "https://arxiv.org/abs/2602.03164", "authors": ["Xiaoyu Tao", "Mingyue Cheng", "Ze Guo", "Shuo Yu", "Yaguo Liu", "Qi Liu", "Shijin Wang"], "title": "MemCast: Memory-Driven Time Series Forecasting with Experience-Conditioned Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting (TSF) plays a critical role in decision-making for many real-world applications. Recently, LLM-based forecasters have made promising advancements. Despite their effectiveness, existing methods often lack explicit experience accumulation and continual evolution. In this work, we propose MemCast, a learning-to-memory framework that reformulates TSF as an experience-conditioned reasoning task. Specifically, we learn experience from the training set and organize it into a hierarchical memory. This is achieved by summarizing prediction results into historical patterns, distilling inference trajectories into reasoning wisdom, and inducing extracted temporal features into general laws. Furthermore, during inference, we leverage historical patterns to guide the reasoning process and utilize reasoning wisdom to select better trajectories, while general laws serve as criteria for reflective iteration. Additionally, to enable continual evolution, we design a dynamic confidence adaptation strategy that updates the confidence of individual entries without leaking the test set distribution. Extensive experiments on multiple datasets demonstrate that MemCast consistently outperforms previous methods, validating the effectiveness of our approach. Our code is available at https://github.com/Xiaoyu-Tao/MemCast-TS.", "AI": {"tldr": "MemCast是一种用于时间序列预测的学习到记忆框架，通过积累经验并指导推理过程来提高预测准确性。", "motivation": "现有方法在时间序列预测中缺乏明确的经验累积和持续进化机制。MemCast旨在解决这个问题，并提出一种基于经验和推理的新型学习框架。", "method": "MemCast将时间序列预测视为一个条件推理任务，通过从训练集中提取经验并组织为层次化记忆来实现。该模型能够总结历史模式、提炼推理轨迹以及概括时序特征，并在推理过程中利用这些信息来优化预测。", "result": "实验结果表明，MemCast在多个数据集上的性能优于现有方法，证明了其有效性。", "conclusion": "通过设计经验积累和动态信心调整策略，MemCast不仅提高了时间序列预测的准确性，还实现了模型的持续进化。"}}
{"id": "2602.03160", "pdf": "https://arxiv.org/pdf/2602.03160", "abs": "https://arxiv.org/abs/2602.03160", "authors": ["Woojin Kim", "Sieun Hyeon", "Jusang Oh", "Jaeyoung Do"], "title": "VALUEFLOW: Toward Pluralistic and Steerable Value-based Alignment in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Aligning Large Language Models (LLMs) with the diverse spectrum of human values remains a central challenge: preference-based methods often fail to capture deeper motivational principles. Value-based approaches offer a more principled path, yet three gaps persist: extraction often ignores hierarchical structure, evaluation detects presence but not calibrated intensity, and the steerability of LLMs at controlled intensities remains insufficiently understood. To address these limitations, we introduce VALUEFLOW, the first unified framework that spans extraction, evaluation, and steering with calibrated intensity control. The framework integrates three components: (i) HIVES, a hierarchical value embedding space that captures intra- and cross-theory value structure; (ii) the Value Intensity DataBase (VIDB), a large-scale resource of value-labeled texts with intensity estimates derived from ranking-based aggregation; and (iii) an anchor-based evaluator that produces consistent intensity scores for model outputs by ranking them against VIDB panels. Using VALUEFLOW, we conduct a comprehensive large-scale study across ten models and four value theories, identifying asymmetries in steerability and composition laws for multi-value control. This paper establishes a scalable infrastructure for evaluating and controlling value intensity, advancing pluralistic alignment of LLMs.", "AI": {"tldr": "提出VALUEFLOW框架，解决大规模语言模型价值观对齐的三个主要问题：价值提取忽略层次结构、评估无法校准强度和难以控制强度。", "motivation": "解决偏好方法无法捕捉深层次动机原则的问题，通过统一的价值提取、评估和引导框架来实现更为原理性的价值对齐。", "method": "介绍VALUEFLOW框架，包括HIVES（一个层次化的价值观嵌入空间）、VIDB（包含强度估计的大规模文本资源）以及一种基于锚点的评估器。", "result": "通过跨十个模型和四种价值观理论进行大规模研究，识别出引导不对称性和多值控制的合成规则。", "conclusion": "VALUEFLOW框架为评价和控制价值强度提供了可扩展的基础架构，推进了大规模语言模型的价值对齐。"}}
{"id": "2602.03157", "pdf": "https://arxiv.org/pdf/2602.03157", "abs": "https://arxiv.org/abs/2602.03157", "authors": ["Chihiro Nakatani", "Hiroaki Kawashima", "Norimichi Ukita"], "title": "Human-in-the-loop Adaptation in Group Activity Feature Learning for Team Sports Video Retrieval", "categories": ["cs.CV"], "comment": "Accepted to Computer Vision and Image Understanding (CVIU)", "summary": "This paper proposes human-in-the-loop adaptation for Group Activity Feature Learning (GAFL) without group activity annotations. This human-in-the-loop adaptation is employed in a group-activity video retrieval framework to improve its retrieval performance. Our method initially pre-trains the GAF space based on the similarity of group activities in a self-supervised manner, unlike prior work that classifies videos into pre-defined group activity classes in a supervised learning manner. Our interactive fine-tuning process updates the GAF space to allow a user to better retrieve videos similar to query videos given by the user. In this fine-tuning, our proposed data-efficient video selection process provides several videos, which are selected from a video database, to the user in order to manually label these videos as positive or negative. These labeled videos are used to update (i.e., fine-tune) the GAF space, so that the positive and negative videos move closer to and farther away from the query videos through contrastive learning. Our comprehensive experimental results on two team sports datasets validate that our method significantly improves the retrieval performance. Ablation studies also demonstrate that several components in our human-in-the-loop adaptation contribute to the improvement of the retrieval performance. Code: https://github.com/chihina/GAFL-FINE-CVIU.", "AI": {"tldr": "本文提出了一种无需群组活动标注的人机交互适应方法，用于团队运动视频检索。", "motivation": "通过引入人机交互适应机制来提高基于自监督学习的群体活动特征学习框架在视频检索中的性能。", "method": "利用用户提供的查询视频，在自监督预训练后的GAF空间基础上进行对比学习微调，并结合高效的数据选择过程以手动标注视频，从而改进模型。", "result": "实验证明该方法显著提高了团队运动视频的检索准确率，同时通过消融实验进一步展示了各个组件的作用。", "conclusion": "提出的人机交互适应机制在提高视频检索性能方面取得了成功，并且展示了一些关键组成部分对结果的影响。"}}
{"id": "2602.03156", "pdf": "https://arxiv.org/pdf/2602.03156", "abs": "https://arxiv.org/abs/2602.03156", "authors": ["Xingyu Qiu", "Xinghua Ma", "Dong Liang", "Gongning Luo", "Wei Wang", "Kuanquan Wang", "Shuo Li"], "title": "Fully Kolmogorov-Arnold Deep Model in Medical Image Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "11 pages, 5 figures, conference", "summary": "Deeply stacked KANs are practically impossible due to high training difficulties and substantial memory requirements. Consequently, existing studies can only incorporate few KAN layers, hindering the comprehensive exploration of KANs. This study overcomes these limitations and introduces the first fully KA-based deep model, demonstrating that KA-based layers can entirely replace traditional architectures in deep learning and achieve superior learning capacity. Specifically, (1) the proposed Share-activation KAN (SaKAN) reformulates Sprecher's variant of Kolmogorov-Arnold representation theorem, which achieves better optimization due to its simplified parameterization and denser training samples, to ease training difficulty, (2) this paper indicates that spline gradients contribute negligibly to training while consuming huge GPU memory, thus proposes the Grad-Free Spline to significantly reduce memory usage and computational overhead. (3) Building on these two innovations, our ALL U-KAN is the first representative implementation of fully KA-based deep model, where the proposed KA and KAonv layers completely replace FC and Conv layers. Extensive evaluations on three medical image segmentation tasks confirm the superiority of the full KA-based architecture compared to partial KA-based and traditional architectures, achieving all higher segmentation accuracy. Compared to directly deeply stacked KAN, ALL U-KAN achieves 10 times reduction in parameter count and reduces memory consumption by more than 20 times, unlocking the new explorations into deep KAN architectures.", "AI": {"tldr": "介绍了一种基于Kolmogorov-Arnold表示定理的全新深度学习模型，用于医学图像分割，并展示了其优越性。", "motivation": "现有研究无法在深度神经网络中全面应用KAN层，因为它们难以训练且需要大量内存。本论文旨在解决这些问题，引入全KA基础架构以克服传统深度学习结构的限制。", "method": "提出了一种新的共享激活KAN（SaKAN）以及无梯度样条函数来简化参数化和减少GPU内存使用，并在此基础上构建了第一个完全基于KA的模型ALL U-KAN。", "result": "在三项医学图像分割任务中，全KA架构优于部分KA架构及传统架构。与直接堆叠深度KAN相比，ALL U-KAN使参数数量减少了十倍，同时将内存消耗降低了20多倍。", "conclusion": "通过证明Ka层完全能够替代传统的FC和Conv层，并且可以实现更高的分割精度，论文成功探索了新的深KAN架构的可能性。"}}
{"id": "2602.03155", "pdf": "https://arxiv.org/pdf/2602.03155", "abs": "https://arxiv.org/abs/2602.03155", "authors": ["Matthew P. Lad", "Louisa Conwill", "Megan Levis Scheirer"], "title": "Is It Possible to Make Chatbots Virtuous? Investigating a Virtue-Based Design Methodology Applied to LLMs", "categories": ["cs.HC"], "comment": null, "summary": "With the rapid growth of Large Language Models (LLMs), criticism of their societal impact has also grown. Work in Responsible AI (RAI) has focused on the development of AI systems aimed at reducing harm. Responding to RAI's criticisms and the need to bring the wisdom traditions into HCI, we apply Conwill et al.'s Virtue-Guided Technology Design method to LLMs. We cataloged new ethical design patterns for LLMs and evaluated them through interviews with technologists. Participants valued that the patterns provided more accuracy and robustness, better safety, new research opportunities, increased access and control, and reduced waste. Their concerns were that the patterns could be vulnerable to jailbreaking, were generalizing models too widely, and had potential implementation issues. Overall, participants reacted positively while also acknowledging the tradeoffs involved in ethical LLM design.", "AI": {"tldr": "本文探讨了将美德导向设计方法应用于大型语言模型（LLM）的可能性，并通过技术专家的访谈对其进行了评估。", "motivation": "随着大型语言模型的发展，其对社会的影响受到了批评。为了减少负面影响并引入智慧传统进入人机交互领域，作者应用了Conwill等人提出的美德导向技术设计方法来解决这些问题。", "method": "作者列出了新的伦理设计模式，并通过与技术专家的访谈对其进行了评估。", "result": "参与者认为这些模式提高了准确性和鲁棒性，增强了安全性，提供了新的研究机会，增加了访问和控制权限并减少了浪费。然而，他们也担心这些模式可能容易受到破解攻击，模型过于泛化以及潜在实现问题。", "conclusion": "尽管存在一些担忧，但总体上参与者对伦理设计的反应是积极的，并承认在大型语言模型的设计中存在权衡"}}
{"id": "2602.03154", "pdf": "https://arxiv.org/pdf/2602.03154", "abs": "https://arxiv.org/abs/2602.03154", "authors": ["Mona Rajhans"], "title": "Intelligent Front-End Personalization: AI-Driven UI Adaptation", "categories": ["cs.HC", "cs.AI", "cs.SE"], "comment": "To be published in proceedings of IEEE ACDSA 2026", "summary": "Front-end personalization has traditionally relied on static designs or rule-based adaptations, which fail to fully capture user behavior patterns. This paper presents an AI driven approach for dynamic front-end personalization, where UI layouts, content, and features adapt in real-time based on predicted user behavior. We propose three strategies: dynamic layout adaptation using user path prediction, content prioritization through reinforcement learning, and a comparative analysis of AI-driven vs. rule-based personalization. Technical implementation details, algorithms, system architecture, and evaluation methods are provided to illustrate feasibility and performance gains.", "AI": {"tldr": "本文提出了基于AI的前端个性化方法，实现实时适应用户行为的UI布局、内容和功能调整。", "motivation": "传统的前端个性化依赖于静态设计或规则驱动的适应方式，无法完全捕捉用户的操作模式。因此，需要一种能够动态适应用户行为的方法来提高用户体验。", "method": "提出三种策略：通过用户路径预测进行动态布局调整；利用强化学习优先显示内容；比较AI驱动与规则驱动的个性化方法，并提供技术实施细节、算法和系统架构说明可行性及性能提升。", "result": "提供了详细的实现和技术评估方法，展示了该方法的有效性和性能优势。", "conclusion": "基于AI的方法可以有效地实现实时动态前端个性化，提高用户体验。"}}
{"id": "2602.03153", "pdf": "https://arxiv.org/pdf/2602.03153", "abs": "https://arxiv.org/abs/2602.03153", "authors": ["Xuetao Li", "Pinhan Fu", "Wenke Huang", "Nengyuan Pan", "Songhua Yang", "Kaiyan Zhao", "Guancheng Wan", "Mengde Li", "Jifeng Xuan", "Miao Li"], "title": "When Attention Betrays: Erasing Backdoor Attacks in Robotic Policies by Reconstructing Visual Tokens", "categories": ["cs.RO"], "comment": "ICRA2026 accepted", "summary": "Downstream fine-tuning of vision-language-action (VLA) models enhances robotics, yet exposes the pipeline to backdoor risks. Attackers can pretrain VLAs on poisoned data to implant backdoors that remain stealthy but can trigger harmful behavior during inference. However, existing defenses either lack mechanistic insight into multimodal backdoors or impose prohibitive computational costs via full-model retraining. To this end, we uncover a deep-layer attention grabbing mechanism: backdoors redirect late-stage attention and form compact embedding clusters near the clean manifold. Leveraging this insight, we introduce Bera, a test-time backdoor erasure framework that detects tokens with anomalous attention via latent-space localization, masks suspicious regions using deep-layer cues, and reconstructs a trigger-free image to break the trigger-unsafe-action mapping while restoring correct behavior. Unlike prior defenses, Bera requires neither retraining of VLAs nor any changes to the training pipeline. Extensive experiments across multiple embodied platforms and tasks show that Bera effectively maintains nominal performance, significantly reduces attack success rates, and consistently restores benign behavior from backdoored outputs, thereby offering a robust and practical defense mechanism for securing robotic systems.", "AI": {"tldr": "本文提出了一种名为Bera的框架，用于在测试时检测并消除机器人策略中的后门攻击。", "motivation": "预训练的视觉语言行动模型面临潜在的数据中毒风险，现有的防御措施缺乏对多模态后门机制的理解或需要昂贵的计算成本。为了应对这一挑战，本文提出了一种新的方法来解决这个问题。", "method": "Bera通过检测具有异常注意力的令牌在隐空间进行定位，并使用深层线索屏蔽可疑区域，重建一个无触发器的图像以中断触发-不安全行为映射并恢复正确的行为。", "result": "实验表明，Bera能够在保持正常性能的同时显著降低攻击成功率，并且一致地从被植入后门策略中恢复良性行为。", "conclusion": "本文提出的方法提供了一种既稳健又实用的防御机制来保护机器人系统免受后门攻击的影响。"}}
{"id": "2602.03151", "pdf": "https://arxiv.org/pdf/2602.03151", "abs": "https://arxiv.org/abs/2602.03151", "authors": ["Wei Dai", "Haoyu Wang", "Honghao Chang", "Lijun He", "Fan Li", "Jian Sun", "Haixia Bi"], "title": "Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration", "categories": ["cs.AI"], "comment": "12 pages", "summary": "Vision Language Models (VLMs) typically assume complete modality input during inference. However, their effectiveness drops sharply when certain modalities are unavailable or incomplete. Current research primarily faces two dilemmas: Prompt-based methods struggle to restore missing yet indispensable features and impair generalization of VLMs. Imputation-based approaches, lacking effective guidance, are prone to generating semantically irrelevant noise. Restoring precise semantics while sustaining VLM generalization remains challenging. Therefore, we propose a general missing modality restoration strategy in this paper. We introduce an enhanced diffusion model as a pluggable mid-stage training module to effectively restore missing features. Our strategy introduces two key innovations: (I) Dynamic Modality Gating, which adaptively leverages conditional features to steer the generation of semantically consistent features; (II) Cross-Modal Mutual Learning mechanism, which bridges the semantic spaces of dual encoders to achieve bidirectional alignment. Zero-shot evaluations across benchmark datasets demonstrate that our approach outperforms existing baseline methods. Extensive experiments and ablation studies confirm our model as a robust and scalable extension for VLMs in missing modality scenarios, ensuring reliability across diverse missing rates and environments. Our code and models will be publicly available.", "AI": {"tldr": "提出了一种增强视觉语言模型（VLM）在缺失模态情况下鲁棒性的方法，利用改进的扩散模型进行特征恢复。", "motivation": "现有方法在处理缺失或不完整模态时效果不佳。基于提示的方法难以恢复关键特征且损害了VLM的泛化能力；基于填充的方法容易生成无关语义噪声。因此需要一种能同时保持精确语义和通用性的方法来解决此问题。", "method": "引入增强扩散模型作为可插拔中间训练模块以有效恢复缺失特征，包含动态模态门控和跨模态互学习机制两个关键创新点。", "result": "零样本评估显示该方法优于现有基准，在各种丢失率和环境下的性能也得到了验证。", "conclusion": "提出的策略证明是增强VLM在缺失模态情况下的鲁棒性和可扩展性的有效手段。"}}
{"id": "2602.03147", "pdf": "https://arxiv.org/pdf/2602.03147", "abs": "https://arxiv.org/abs/2602.03147", "authors": ["Runfeng Zhu", "Xin Zhong", "Qingxiang Zhao", "Jing Lin", "Zhong Wu", "Kang Li"], "title": "Multi-function Robotized Surgical Dissector for Endoscopic Pulmonary Thromboendarterectomy: Preclinical Study and Evaluation", "categories": ["cs.RO"], "comment": null, "summary": "Patients suffering chronic severe pulmonary thromboembolism need Pulmonary Thromboendarterectomy (PTE) to remove the thromb and intima located inside pulmonary artery (PA). During the surgery, a surgeon holds tweezers and a dissector to delicately strip the blockage, but available tools for this surgery are rigid and straight, lacking distal dexterity to access into thin branches of PA. Therefore, this work presents a novel robotized dissector based on concentric push/pull robot (CPPR) structure, enabling entering deep thin branch of tortuous PA. Compared with conventional rigid dissectors, our design characterizes slenderness and dual-segment-bending dexterity. Owing to the hollow and thin-walled structure of the CPPR-based dissector as it has a slender body of 3.5mm in diameter, the central lumen accommodates two channels for irrigation and tip tool, and space for endoscopic camera's signal wire. To provide accurate surgical manipulation, optimization-based kinematics model was established, realizing a 2mm accuracy in positioning the tip tool (60mm length) under open-loop control strategy. As such, with the endoscopic camera, traditional PTE is possible to be upgraded as endoscopic PTE. Basic physic performance of the robotized dissector including stiffness, motion accuracy and maneuverability was evaluated through experiments. Surgery simulation on ex vivo porcine lung also demonstrates its dexterity and notable advantages in PTE.", "AI": {"tldr": "设计并评估一种用于内窥镜肺血栓内膜剥脱术的多功能机器人手术剥离器", "motivation": "现有的手术工具缺乏进入肺动脉分支的能力，新设计旨在提供更精细的操作和更高的准确性", "method": "采用基于同心推拉机器人的结构，建立了优化的动力学模型，并通过实验对其进行了物理性能评估以及在体外猪肺上的手术模拟测试", "result": "机器人剥离器表现出良好的刚度、运动精度和操纵性，在内窥镜引导下操作准确性和灵活性显著提高", "conclusion": "新设计的机器人化工具可以有效提升PTE手术的效果，为微创手术提供了新的解决方案"}}
{"id": "2602.03146", "pdf": "https://arxiv.org/pdf/2602.03146", "abs": "https://arxiv.org/abs/2602.03146", "authors": ["Santiago Cifuentes"], "title": "General Agents Contain World Models, even under Partial Observability and Stochasticity", "categories": ["cs.AI"], "comment": "19 pages, 4 figures", "summary": "Deciding whether an agent possesses a model of its surrounding world is a fundamental step toward understanding its capabilities and limitations. In [10], it was shown that, within a particular framework, every almost optimal and general agent necessarily contains sufficient knowledge of its environment to allow an approximate reconstruction of it by querying the agent as a black box. This result relied on the assumptions that the agent is deterministic and that the environment is fully observable. In this work, we remove both assumptions by extending the theorem to stochastic agents operating in partially observable environments. Fundamentally, this shows that stochastic agents cannot avoid learning their environment through the usage of randomization. We also strengthen the result by weakening the notion of generality, proving that less powerful agents already contain a model of the world in which they operate.", "AI": {"tldr": "研究扩展了关于代理是否包含其环境模型的理论，以适应随机性和部分可观测性的条件。", "motivation": "探讨在不确定性和信息不完整的条件下，智能体如何学习和理解所处环境的能力与限制。", "method": "通过放宽先前假设（即确定性代理和完全可观察环境），研究证明了即使在随机且部分可观察的环境中，几乎最优的一般智能体仍包含足够的关于其环境的知识。", "result": "结果表明，在更宽松的概念定义下，即使是较弱的智能体也能够构建其所处世界的模型。", "conclusion": "智能体通过使用随机化过程来学习和建模它们所处的世界，即使在部分可观测且具有不确定性的情况下也是如此。"}}
{"id": "2602.03145", "pdf": "https://arxiv.org/pdf/2602.03145", "abs": "https://arxiv.org/abs/2602.03145", "authors": ["Ya-Ting Yang", "Quanyan Zhu"], "title": "Internet of Agentic AI: Incentive-Compatible Distributed Teaming and Workflow", "categories": ["cs.GT", "cs.AI", "cs.MA"], "comment": null, "summary": "Large language models (LLMs) have enabled a new class of agentic AI systems that reason, plan, and act by invoking external tools. However, most existing agentic architectures remain centralized and monolithic, limiting scalability, specialization, and interoperability. This paper proposes a framework for scalable agentic intelligence, termed the Internet of Agentic AI, in which autonomous, heterogeneous agents distributed across cloud and edge infrastructure dynamically form coalitions to execute task-driven workflows. We formalize a network-native model of agentic collaboration and introduce an incentive-compatible workflow-coalition feasibility framework that integrates capability coverage, network locality, and economic implementability. To enable scalable coordination, we formulate a minimum-effort coalition selection problem and propose a decentralized coalition formation algorithm. The proposed framework can operate as a coordination layer above the Model Context Protocol (MCP). A healthcare case study demonstrates how domain specialization, cloud-edge heterogeneity, and dynamic coalition formation enable scalable, resilient, and economically viable agentic workflows. This work lays the foundation for principled coordination and scalability in the emerging era of Internet of Agentic AI.", "AI": {"tldr": "提出了一种可扩展的代理智能框架，允许分布式自主异构代理在网络中动态形成联盟以执行任务驱动的工作流。", "motivation": "现有的代理架构大多集中在中央和单一结构上，限制了其规模、专业化及互操作性。为了克服这些局限性，并促进基于网络的代理协作模型的发展，本研究旨在构建一种新的可扩展且具备经济可行性的框架。", "method": "提出了一种网络原生的合作代理模型以及一个结合能力覆盖、网络位置和经济实现的激励兼容的工作流联盟可行性框架，并开发了一个最小努力联盟选择问题的形式化方法以及一个去中心化的联盟形成算法。", "result": "通过医疗保健案例研究展示了该框架如何利用领域专业化、云边缘异质性及动态联盟形成来支持可扩展且具有弹性的代理工作流程。", "conclusion": "本研究为互联网时代下的代理智能协调和规模化提供了基础，推动了新的合作模式的发展。"}}
{"id": "2602.03143", "pdf": "https://arxiv.org/pdf/2602.03143", "abs": "https://arxiv.org/abs/2602.03143", "authors": ["Baohao Liao", "Hanze Dong", "Xinxing Xu", "Christof Monz", "Jiang Bian"], "title": "Self-Hinting Language Models Enhance Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has recently emerged as a practical recipe for aligning large language models with verifiable objectives. However, under sparse terminal rewards, GRPO often stalls because rollouts within a group frequently receive identical rewards, causing relative advantages to collapse and updates to vanish. We propose self-hint aligned GRPO with privileged supervision (SAGE), an on-policy reinforcement learning framework that injects privileged hints during training to reshape the rollout distribution under the same terminal verifier reward. For each prompt $x$, the model samples a compact hint $h$ (e.g., a plan or decomposition) and then generates a solution $τ$ conditioned on $(x,h)$. Crucially, the task reward $R(x,τ)$ is unchanged; hints only increase within-group outcome diversity under finite sampling, preventing GRPO advantages from collapsing under sparse rewards. At test time, we set $h=\\varnothing$ and deploy the no-hint policy without any privileged information. Moreover, sampling diverse self-hints serves as an adaptive curriculum that tracks the learner's bottlenecks more effectively than fixed hints from an initial policy or a stronger external model. Experiments over 6 benchmarks with 3 LLMs show that SAGE consistently outperforms GRPO, on average +2.0 on Llama-3.2-3B-Instruct, +1.2 on Qwen2.5-7B-Instruct and +1.3 on Qwen3-4B-Instruct. The code is available at https://github.com/BaohaoLiao/SAGE.", "AI": {"tldr": "本文提出了一种名为SAGE的强化学习框架，通过在训练过程中注入特权提示来增强大规模语言模型与验证目标之间的对齐。", "motivation": "现有的Group Relative Policy Optimization (GRPO) 方法在稀疏终端奖励的情况下容易停滞，因为同组内部的回报相同导致相对优势消失。为解决这一问题，本文提出使用特权提示来增加组内结果多样性，防止GRPO的优势在稀疏奖励下消失。", "method": "SAGE框架通过在训练时为每个提示x生成一个紧凑的提示h（如计划或分解），并基于(x,h)生成解决方案τ。任务回报R(x,τ)保持不变；提示仅增加有限采样下的组内结果多样性，防止GRPO优势消失。", "result": "实验结果显示，在6个基准测试中使用3种大型语言模型时，SAGE比GRPO平均高出2.0在Llama-3.2-3B-Instruct上，1.2在Qwen2.5-7B-Instruct和1.3在Qwen3-4B-Instruct上。", "conclusion": "SAGE框架有效解决了稀疏奖励下GRPO方法容易停滞的问题，并通过自适应课程学习更好地跟踪学习者的瓶颈问题。"}}
{"id": "2602.03139", "pdf": "https://arxiv.org/pdf/2602.03139", "abs": "https://arxiv.org/abs/2602.03139", "authors": ["Tianhe Wu", "Ruibin Li", "Lei Zhang", "Kede Ma"], "title": "Diversity-Preserved Distribution Matching Distillation for Fast Visual Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "Distribution matching distillation (DMD) aligns a multi-step generator with its few-step counterpart to enable high-quality generation under low inference cost. However, DMD tends to suffer from mode collapse, as its reverse-KL formulation inherently encourages mode-seeking behavior, for which existing remedies typically rely on perceptual or adversarial regularization, thereby incurring substantial computational overhead and training instability. In this work, we propose a role-separated distillation framework that explicitly disentangles the roles of distilled steps: the first step is dedicated to preserving sample diversity via a target-prediction (e.g., v-prediction) objective, while subsequent steps focus on quality refinement under the standard DMD loss, with gradients from the DMD objective blocked at the first step. We term this approach Diversity-Preserved DMD (DP-DMD), which, despite its simplicity -- no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images -- preserves sample diversity while maintaining visual quality on par with state-of-the-art methods in extensive text-to-image experiments.", "AI": {"tldr": "本文提出了一种新的知识蒸馏框架DP-DMD，旨在通过分离角色来解决模式崩溃问题。", "motivation": "现有的分布匹配蒸馏方法由于逆KL公式而容易遭受模式崩塌问题，并且现有解决方案会增加计算开销和训练不稳定性。", "method": "本文提出了一种基于目标预测的任务分离式知识蒸馏框架，将生成步骤的角色明确区分：第一步专注样本多样性保持，后续步骤进行质量提升。", "result": "该方法在广泛的文本到图像实验中，在没有额外感知主干、判别器和辅助网络的情况下，能够保持样本多样性且视觉效果与最先进方法相当。", "conclusion": "通过分离蒸馏步骤的角色并阻断逆KL目标的第一步梯度，本文的方法能够在不增加计算成本的同时解决模式崩溃问题。"}}
{"id": "2602.03137", "pdf": "https://arxiv.org/pdf/2602.03137", "abs": "https://arxiv.org/abs/2602.03137", "authors": ["Chen-Bin Feng", "Youyang Sha", "Longfei Liu", "Yongjun Yu", "Chi Man Vong", "Xuanlong Yu", "Xi Shen"], "title": "FSOD-VFM: Few-Shot Object Detection with Vision Foundation Models and Graph Diffusion", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026. Code is available at: \\url{https://intellindust-ai-lab.github.io/projects/FSOD-VFM}", "summary": "In this paper, we present FSOD-VFM: Few-Shot Object Detectors with Vision Foundation Models, a framework that leverages vision foundation models to tackle the challenge of few-shot object detection. FSOD-VFM integrates three key components: a universal proposal network (UPN) for category-agnostic bounding box generation, SAM2 for accurate mask extraction, and DINOv2 features for efficient adaptation to new object categories. Despite the strong generalization capabilities of foundation models, the bounding boxes generated by UPN often suffer from overfragmentation, covering only partial object regions and leading to numerous small, false-positive proposals rather than accurate, complete object detections. To address this issue, we introduce a novel graph-based confidence reweighting method. In our approach, predicted bounding boxes are modeled as nodes in a directed graph, with graph diffusion operations applied to propagate confidence scores across the network. This reweighting process refines the scores of proposals, assigning higher confidence to whole objects and lower confidence to local, fragmented parts. This strategy improves detection granularity and effectively reduces the occurrence of false-positive bounding box proposals. Through extensive experiments on Pascal-5$^i$, COCO-20$^i$, and CD-FSOD datasets, we demonstrate that our method substantially outperforms existing approaches, achieving superior performance without requiring additional training. Notably, on the challenging CD-FSOD dataset, which spans multiple datasets and domains, our FSOD-VFM achieves 31.6 AP in the 10-shot setting, substantially outperforming previous training-free methods that reach only 21.4 AP. Code is available at: https://intellindust-ai-lab.github.io/projects/FSOD-VFM.", "AI": {"tldr": "FSOD-VFM是一个利用视觉基础模型进行少样本物体检测的框架，通过引入图扩散方法改进边界框生成过程。", "motivation": "为了克服基础模型在生成边界框时的过度碎片化问题，提出了一种基于图形的信心重新加权方法来提高检测精度和减少假阳性。", "method": "FSOD-VFM框架包含通用提议网络（UPN）、SAM2以及DINOv2特征。它使用图扩散操作在网络中传播信心评分以改善边界框的准确性和完整性。", "result": "实验结果表明，该方法在Pascal-5i、COCO-20i和CD-FSOD数据集上显著优于现有技术，在10-shot设置下达到31.6 AP，而之前的方法仅能达到21.4 AP。", "conclusion": "FSOD-VFM通过图扩散的重新加权策略大幅提升了少样本物体检测性能，无需额外训练即可实现更准确的物体边界框生成。"}}
{"id": "2602.03134", "pdf": "https://arxiv.org/pdf/2602.03134", "abs": "https://arxiv.org/abs/2602.03134", "authors": ["Chen Qian", "Xinran Yu", "Danyang Li", "Guoxuan Chi", "Zheng Yang", "Qiang Ma", "Xin Miao"], "title": "SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual token pruning is a promising approach for reducing the computational cost of vision-language models (VLMs), and existing methods often rely on early pruning decisions to improve efficiency. While effective on coarse-grained reasoning tasks, they suffer from significant performance degradation on tasks requiring fine-grained visual details. Through layer-wise analysis, we reveal substantial discrepancies in visual token importance across layers, showing that tokens deemed unimportant at shallow layers can later become highly relevant for text-conditioned reasoning. To avoid irreversible critical information loss caused by premature pruning, we introduce a new pruning paradigm, termed bypass, which preserves unselected visual tokens and forwards them to subsequent pruning stages for re-evaluation. Building on this paradigm, we propose SwiftVLM, a simple and training-free method that performs pruning at model-specific layers with strong visual token selection capability, while enabling independent pruning decisions across layers. Experiments across multiple VLMs and benchmarks demonstrate that SwiftVLM consistently outperforms existing pruning strategies, achieving superior accuracy-efficiency trade-offs and more faithful visual token selection behavior.", "AI": {"tldr": "SwiftVLM通过跨层视觉令牌绕过技术，提高视觉语言模型的推理效率。", "motivation": "现有的视觉语言模型剪枝方法依赖早期决策导致了对需要细粒度视觉细节任务性能下降。为了防止关键信息因提前剪枝而丢失，作者提出了新的剪枝范例。", "method": "SwiftVLM在特定层执行训练免费的剪枝操作，并允许跨层独立进行剪枝决策。", "result": "实验结果表明，SwiftVLM比现有方法有更好的准确性和效率之间的平衡。", "conclusion": "SwiftVLM提供了一种新的视觉语言模型推理优化策略，避免了关键信息丢失，同时保持了较高的准确性。"}}
{"id": "2602.03132", "pdf": "https://arxiv.org/pdf/2602.03132", "abs": "https://arxiv.org/abs/2602.03132", "authors": ["Timothee Leleu", "Sudeera Gunathilaka", "Federico Ghimenti", "Surya Ganguli"], "title": "Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Large language Model (LLM)-assisted algorithm discovery is an iterative, black-box optimization process over programs to approximatively solve a target task, where an LLM proposes candidate programs and an external evaluator provides task feedback. Despite intense recent research on the topic and promising results, how can the LLM internal representation of the space of possible programs be maximally exploited to improve performance is an open question. Here, we introduce Contrastive Concept-Tree Search (CCTS), which extracts a hierarchical concept representation from the generated programs and learns a contrastive concept model that guides parent selection. By reweighting parents using a likelihood-ratio score between high- and low-performing solutions, CCTS biases search toward useful concept combinations and away from misleading ones, providing guidance through an explicit concept hierarchy rather than the algorithm lineage constructed by the LLM. We show that CCTS improves search efficiency over fitness-based baselines and produces interpretable, task-specific concept trees across a benchmark of open Erdős-type combinatorics problems. Our analysis indicates that the gains are driven largely by learning which concepts to avoid. We further validate these findings in a controlled synthetic algorithm-discovery environment, which reproduces qualitatively the search dynamics observed with the LLMs.", "AI": {"tldr": "论文提出了对比概念树搜索(CCTS)方法，用于提高大语言模型(LLM)辅助算法发现的效率和可解释性。", "motivation": "如何最大化利用LLM内部表示法以改善程序空间中的性能是一个未解决的问题。CCTS旨在通过学习有用的和避免误导性的概念组合来改进搜索过程。", "method": "CCTS从生成的程序中提取分层的概念表示，并使用对比概念模型引导父节点选择，根据高表现和低表现解决方案之间的似然比重新加权父母。", "result": "实验证明了CCTS在提高搜索效率方面的优势，特别是在解决开放型Erdős组合问题时产生了特定任务的概念树。该方法在合成算法发现环境中也得到了验证。", "conclusion": "研究显示，通过学习避免某些概念可以显著改善搜索过程的性能和可解释性。"}}
{"id": "2602.03130", "pdf": "https://arxiv.org/pdf/2602.03130", "abs": "https://arxiv.org/abs/2602.03130", "authors": ["Chenxi Zhang", "Ziliang Gan", "Liyun Zhu", "Youwei Pang", "Qing Zhang", "Rongjunchen Zhang"], "title": "FinMTM: A Multi-Turn Multimodal Benchmark for Financial Reasoning and Agent Evaluation", "categories": ["cs.CV", "cs.CE"], "comment": null, "summary": "The financial domain poses substantial challenges for vision-language models (VLMs) due to specialized chart formats and knowledge-intensive reasoning requirements. However, existing financial benchmarks are largely single-turn and rely on a narrow set of question formats, limiting comprehensive evaluation in realistic application scenarios. To address this gap, we propose FinMTM, a multi-turn multimodal benchmark that expands diversity along both data and task dimensions. On the data side, we curate and annotate 11{,}133 bilingual (Chinese and English) financial QA pairs grounded in financial visuals, including candlestick charts, statistical plots, and report figures. On the task side, FinMTM covers single- and multiple-choice questions, multi-turn open-ended dialogues, and agent-based tasks. We further design task-specific evaluation protocols, including a set-overlap scoring rule for multiple-choice questions, a weighted combination of turn-level and session-level scores for multi-turn dialogues, and a composite metric that integrates planning quality with final outcomes for agent tasks. Extensive experimental evaluation of 22 VLMs reveal their limitations in fine-grained visual perception, long-context reasoning, and complex agent workflows.", "AI": {"tldr": "提出FinMTM多轮数模态基准，用于评估金融领域视觉语言模型的性能。", "motivation": "现有金融基准测试局限于单轮问题和狭窄格式，难以全面评价实际应用中的表现。为弥补这一不足，提出了更广泛的多样性和任务类型的FinMTM。", "method": "构建并标注了11,133个中英文双语金融问答对，并设计特定的任务评估协议以涵盖多种类型的问题。", "result": "实验表明视觉语言模型在细粒度视觉感知、长上下文推理和复杂代理工作流程方面存在局限性。", "conclusion": "FinMTM基准测试填补了现有金融基准的空缺，有助于更全面地评价视觉语言模型的能力。"}}
{"id": "2602.03128", "pdf": "https://arxiv.org/pdf/2602.03128", "abs": "https://arxiv.org/abs/2602.03128", "authors": ["Abdelghny Orogat", "Ana Rostam", "Essam Mansour"], "title": "Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis", "categories": ["cs.AI"], "comment": "25 pages, 9 figures and 13 tables; introduces MAFBench unified multi-agent evaluation suite", "summary": "Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finally, we translate our findings into concrete architectural design principles and framework selection guidance, and outline promising future research directions.", "AI": {"tldr": "本文介绍了多代理LLM框架的统一基准和实验分析，旨在理解这些架构选择如何影响系统性能。", "motivation": "目前对多代理LLM框架的影响尚不清楚，不同框架间的差距可能导致显著的不同性能指标。为解决这一问题，需要一个标准化的方法来评估这些框架在各种能力上的表现。", "method": "本文提出了一个体系结构分类学来比较多个多代理LLM框架，并开发了MAFBench统一的评估套件以整合现有基准并提供标准化执行管道。", "result": "实验结果表明，仅架构选择就可以导致延迟增加100倍以上、规划准确度降低最多30%，协调成功率从超过90%降至低于30%。", "conclusion": "基于研究发现，本文提出了具体的设计原则和框架选型建议，并概述了未来的研究方向。"}}
{"id": "2602.03126", "pdf": "https://arxiv.org/pdf/2602.03126", "abs": "https://arxiv.org/abs/2602.03126", "authors": ["Francis Snelgar", "Ming Xu", "Stephen Gould", "Liang Zheng", "Akshay Asthana"], "title": "Flexible Geometric Guidance for Probabilistic Human Pose Estimation with Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "3D human pose estimation from 2D images is a challenging problem due to depth ambiguity and occlusion. Because of these challenges the task is underdetermined, where there exists multiple -- possibly infinite -- poses that are plausible given the image. Despite this, many prior works assume the existence of a deterministic mapping and estimate a single pose given an image. Furthermore, methods based on machine learning require a large amount of paired 2D-3D data to train and suffer from generalization issues to unseen scenarios. To address both of these issues, we propose a framework for pose estimation using diffusion models, which enables sampling from a probability distribution over plausible poses which are consistent with a 2D image. Our approach falls under the guidance framework for conditional generation, and guides samples from an unconditional diffusion model, trained only on 3D data, using the gradients of the heatmaps from a 2D keypoint detector. We evaluate our method on the Human 3.6M dataset under best-of-$m$ multiple hypothesis evaluation, showing state-of-the-art performance among methods which do not require paired 2D-3D data for training. We additionally evaluate the generalization ability using the MPI-INF-3DHP and 3DPW datasets and demonstrate competitive performance. Finally, we demonstrate the flexibility of our framework by using it for novel tasks including pose generation and pose completion, without the need to train bespoke conditional models. We make code available at https://github.com/fsnelgar/diffusion_pose .", "AI": {"tldr": "提出了一种基于扩散模型的三维人体姿态估计框架，能够从二维图像中抽样出符合概率分布的可能的姿态。", "motivation": "解决现有方法在面对深度模糊和遮挡问题时存在的确定性映射假设不足以及对大量配对2D-3D数据的需求与泛化能力限制的问题。", "method": "利用扩散模型引导样本生成，仅需训练无条件的3D数据模型，并通过二维关键点检测器热图梯度进行指导。", "result": "在Human 3.6M等多个人体姿态估计数据集上表现优秀，特别是在无需配对2D-3D训练数据的情况下达到了先进水平。此外还展示了该框架在姿态生成和补全任务中的灵活性。", "conclusion": "通过使用扩散模型的引导条件生成方法，有效解决了三维人体姿态估计中存在的问题，并展现了其广泛的适用性和优越性能。"}}
{"id": "2602.03124", "pdf": "https://arxiv.org/pdf/2602.03124", "abs": "https://arxiv.org/abs/2602.03124", "authors": ["Fanxiao Wani Qiu", "Oscar Leong"], "title": "Feature, Alignment, and Supervision in Category Learning: A Comparative Approach with Children and Neural Networks", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Understanding how humans and machines learn from sparse data is central to cognitive science and machine learning. Using a species-fair design, we compare children and convolutional neural networks (CNNs) in a few-shot semi-supervised category learning task. Both learners are exposed to novel object categories under identical conditions. Learners receive mixtures of labeled and unlabeled exemplars while we vary supervision (1/3/6 labels), target feature (size, shape, pattern), and perceptual alignment (high/low). We find that children generalize rapidly from minimal labels but show strong feature-specific biases and sensitivity to alignment. CNNs show a different interaction profile: added supervision improves performance, but both alignment and feature structure moderate the impact additional supervision has on learning. These results show that human-model comparisons must be drawn under the right conditions, emphasizing interactions among supervision, feature structure, and alignment rather than overall accuracy.", "AI": {"tldr": "比较儿童和卷积神经网络在少量标记样本下的类别学习任务中的表现，探索监督、特征结构及感知对齐的影响。", "motivation": "理解人类如何从稀疏数据中学习是认知科学的重要课题。通过设计一种公平的实验框架来对比儿童与机器模型的学习能力，并探讨不同条件下两者的表现差异。", "method": "在相同的条件和任务设置下，让儿童和卷积神经网络接触新的物体类别样本，同时改变监督信号的数量（1/3/6个标记）、目标特征（大小、形状、图案）以及感知对齐度（高/低），观察学习效果的变化。", "result": "实验结果显示，儿童能够快速从少量标签中泛化学习，但表现出特定特性的偏见和对对齐的敏感性。相比之下，卷积神经网络在增加监督后性能有所提升，但是特征结构和感知对齐也会影响这种改进的程度。", "conclusion": "研究强调了在比较人类与机器模型的学习能力时需要考虑具体的实验条件及其交互作用，而不仅仅是关注总体准确性。"}}
{"id": "2602.03123", "pdf": "https://arxiv.org/pdf/2602.03123", "abs": "https://arxiv.org/abs/2602.03123", "authors": ["Judah Goldfeder", "Shreyes Kaliyur", "Vaibhav Sourirajan", "Patrick Minwan Puma", "Philippe Martin Wyder", "Yuhang Hu", "Jiong Lin", "Hod Lipson"], "title": "Beyond Cropping and Rotation: Automated Evolution of Powerful Task-Specific Augmentations with Generative Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Data augmentation has long been a cornerstone for reducing overfitting in vision models, with methods like AutoAugment automating the design of task-specific augmentations. Recent advances in generative models, such as conditional diffusion and few-shot NeRFs, offer a new paradigm for data augmentation by synthesizing data with significantly greater diversity and realism. However, unlike traditional augmentations like cropping or rotation, these methods introduce substantial changes that enhance robustness but also risk degrading performance if the augmentations are poorly matched to the task. In this work, we present EvoAug, an automated augmentation learning pipeline, which leverages these generative models alongside an efficient evolutionary algorithm to learn optimal task-specific augmentations. Our pipeline introduces a novel approach to image augmentation that learns stochastic augmentation trees that hierarchically compose augmentations, enabling more structured and adaptive transformations. We demonstrate strong performance across fine-grained classification and few-shot learning tasks. Notably, our pipeline discovers augmentations that align with domain knowledge, even in low-data settings. These results highlight the potential of learned generative augmentations, unlocking new possibilities for robust model training.", "AI": {"tldr": "提出了一种新的自动化图像增强学习管道EvoAug，该管道利用生成模型和进化算法来学习任务特定的增强技术。", "motivation": "传统的数据增强方法如裁剪或旋转存在局限性，难以适应复杂多样的任务需求。新进的生成模型虽然能够提供更真实多样化的数据合成但可能因与任务不匹配而降低性能。", "method": "EvoAug管道结合了条件扩散和少样本NeRF等生成模型以及高效进化算法来学习最优的任务特定增强技术，采用随机增强树分层组合增强方法以实现更具结构化和适应性的转换。", "result": "在细粒度分类和少量数据学习任务上展示了强大的性能，并发现与领域知识相符的增强策略即使是在低数据情况下也能有效工作。", "conclusion": "该研究揭示了生成式学习增强技术的巨大潜力，为模型训练提供了新的可能性。"}}
{"id": "2602.03121", "pdf": "https://arxiv.org/pdf/2602.03121", "abs": "https://arxiv.org/abs/2602.03121", "authors": ["Haoze Guo", "Ziqi Wei"], "title": "Behind the Feed: A Taxonomy of User-Facing Cues for Algorithmic Transparency in Social Media", "categories": ["cs.HC"], "comment": null, "summary": "People who use social media are learning about how the companies that run these platforms make their decisions on who gets to see what through visual indicators in the interface (UI) of each social media site. These indicators are different for each platform and are not always located in an easy-to-find location on the site. Therefore, it is hard for someone to compare different social media platforms or determine whether transparency leads to greater accountability or only leads to increased understanding. A new classification system has been developed to help provide a standard way of categorizing the way, that an algorithm is presented through UI elements and whether the company has provided any type of explanation as to why they are featured. This new classification system includes the following three areas of development: design form, information content, and user agency. This new classification system can be applied to the six social media platforms currently available and serves as a reference database for identifying common archetypes of features in the each social media platform's UI. The new classification system will assist in determining whether or not the transparency of an algorithm functions the way that it was intended when it was developed and provide future design ideas that can help improve the inspectibility, actionability, and contestability of algorithms.", "AI": {"tldr": "开发了一种分类系统来标准化社交平台算法透明度的UI元素展示方式", "motivation": "当前各平台间算法透明度UI指示器差异大，难以对比和评估其有效性", "method": "提出了包括设计形式、信息内容和用户代理在内的新分类体系，并应用于六大社交平台", "result": "建立了参考数据库以识别各平台中常见的特征类型", "conclusion": "该系统有助于评估算法透明度的实际效果并为未来的设计提供改进建议"}}
{"id": "2602.03120", "pdf": "https://arxiv.org/pdf/2602.03120", "abs": "https://arxiv.org/abs/2602.03120", "authors": ["Yinggan Xu", "Risto Miikkulainen", "Xin Qiu"], "title": "Quantized Evolution Strategies: High-precision Fine-tuning of Quantized LLMs at Low-precision Cost", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint version", "summary": "Post-Training Quantization (PTQ) is essential for deploying Large Language Models (LLMs) on memory-constrained devices, yet it renders models static and difficult to fine-tune. Standard fine-tuning paradigms, including Reinforcement Learning (RL), fundamentally rely on backpropagation and high-precision weights to compute gradients. Thus they cannot be used on quantized models, where the parameter space is discrete and non-differentiable. While Evolution Strategies (ES) offer a backpropagation-free alternative, optimization of the quantized parameters can still fail due to vanishing or inaccurate gradient. This paper introduces Quantized Evolution Strategies (QES), an optimization paradigm that performs full-parameter fine-tuning directly in the quantized space. QES is based on two innovations: (1) it integrates accumulated error feedback to preserve high-precision gradient signals, and (2) it utilizes a stateless seed replay to reduce memory usage to low-precision inference levels. QES significantly outperforms the state-of-the-art zeroth-order fine-tuning method on arithmetic reasoning tasks, making direct fine-tuning for quantized models possible. It therefore opens up the possibility for scaling up LLMs entirely in the quantized space. The source code is available at https://github.com/dibbla/Quantized-Evolution-Strategies .", "AI": {"tldr": "本文提出了一种新的优化方法Quantized Evolution Strategies（QES），能够在量化参数空间中进行全参数微调，从而使得大型语言模型在内存受限设备上的部署更加灵活高效。", "motivation": "后训练量化（PTQ）虽然对于将大规模语言模型部署到内存有限的设备上至关重要，但使其变得静态且难以调整。标准的微调方法依赖于反向传播和高精度权重计算梯度，这无法应用于参数空间离散且不可导的量化模型中。", "method": "本文提出了基于累积误差反馈来保留高精度梯度信号和利用无状态种子回放减少内存使用量到低精度推理级别的Quantized Evolution Strategies（QES）方法。该方法能够在量化参数空间直接进行全参数微调。", "result": "与最先进的零阶微调方法相比，QES在算术推理任务上表现显著更好，表明直接对量化模型进行微调是可能的。", "conclusion": "通过QES，可以在量化空间内完全调整大型语言模型，这为大规模语言模型提供了新的可能性。"}}
{"id": "2602.03114", "pdf": "https://arxiv.org/pdf/2602.03114", "abs": "https://arxiv.org/abs/2602.03114", "authors": ["Geeta Puri", "Nachamma Socklingam", "Dorien Herremans"], "title": "Digital Lifelong Learning in the Age of AI: Trends and Insights", "categories": ["cs.CY", "cs.AI"], "comment": "41 pages including references, appendix, 14 figures", "summary": "Rapid innovations in AI and large language models (LLMs) have accelerated the adoption of digital learning, particularly beyond formal education. What began as an emergency response during COVID-19 has shifted from a supplementary resource to an essential pillar of education. Understanding how digital learning continues to evolve for adult and lifelong learners is therefore increasingly important. This study examines how various demographics interact with digital learning platforms, focusing on the learner motivations, the effectiveness of gamification in digital learning, and the integration of AI. Using multi survey data from 200 respondents and advanced analytics, our findings reveal a notable increase in the perceived relevance of digital learning after the pandemic, especially among young adults and women, coinciding with the rise of LLM-powered AI tools that support personalized learning. We aim to provide actionable insights for businesses, government policymakers, and educators seeking to optimize their digital learning offerings to meet evolving workforce needs.", "AI": {"tldr": "研究探讨了数字学习在人工智能时代的发展趋势，特别是如何满足不同人群的需求，并分析了游戏化和AI对学习效果的影响。", "motivation": "快速发展的AI技术推动了数字学习的普及，尤其是在非正式教育领域。通过调查各种人口统计数据与数字平台互动的方式，旨在为政策制定者、企业和教育工作者提供有关优化数字学习服务的具体见解。", "method": "研究基于200名受访者的多份调查数据，并运用先进分析方法探讨不同群体对数字学习的态度变化以及游戏化和AI技术的应用效果。", "result": "发现疫情过后，年轻成人及女性群体普遍认为数字化学习更加相关。同时，LLM驱动的人工智能工具支持个性化教育的趋势日益明显。", "conclusion": "研究结果表明，在未来工作中不断演变的需求下，数字学习成为重要的终身学习渠道之一。企业、政府和教育机构应考虑如何更好地利用这些技术来改进其在线课程和服务。"}}
{"id": "2602.03112", "pdf": "https://arxiv.org/pdf/2602.03112", "abs": "https://arxiv.org/abs/2602.03112", "authors": ["Zhengfei Wu", "Shuaixi Pan", "Shuohan Chen", "Shuo Yang", "Yanjun Huang"], "title": "A Unified Candidate Set with Scene-Adaptive Refinement via Diffusion for End-to-End Autonomous Driving", "categories": ["cs.RO"], "comment": "Code:https://github.com/WWW-TJ/CdDrive", "summary": "End-to-end autonomous driving is increasingly adopting a multimodal planning paradigm that generates multiple trajectory candidates and selects the final plan, making candidate-set design critical. A fixed trajectory vocabulary provides stable coverage in routine driving but often misses optimal solutions in complex interactions, while scene-adaptive refinement can cause over-correction in simple scenarios by unnecessarily perturbing already strong vocabulary trajectories.We propose CdDrive, which preserves the original vocabulary candidates and augments them with scene-adaptive candidates generated by vocabulary-conditioned diffusion denoising. Both candidate types are jointly scored by a shared selection module, enabling reliable performance across routine and highly interactive scenarios. We further introduce HATNA (Horizon-Aware Trajectory Noise Adapter) to improve the smoothness and geometric continuity of diffusion candidates via temporal smoothing and horizon-aware noise modulation. Experiments on NAVSIM v1 and NAVSIM v2 demonstrate leading performance, and ablations verify the contribution of each component.", "AI": {"tldr": "提出了一种基于扩散的候选集生成方法CdDrive，用于端到端自动驾驶中多轨迹规划。", "motivation": "固定轨迹词汇表在复杂交互场景下容易错过最优解；而基于场景自适应调整则可能在简单情况下过度修正。", "method": "通过条件化扩散去噪增强原始词汇候选集，并引入HATNA提高生成轨迹的平滑度和几何连续性，最后由共享选择模块对所有候选进行评分。", "result": "实验表明该方法在NavSim v1和v2上表现出色，优于其他基准。", "conclusion": "CdDrive能够在常规及复杂交互场景下提供可靠性能，是端到端自动驾驶中多轨迹规划的有效解决方案。"}}
{"id": "2602.03105", "pdf": "https://arxiv.org/pdf/2602.03105", "abs": "https://arxiv.org/abs/2602.03105", "authors": ["Francis Snelgar", "Stephen Gould", "Ming Xu", "Liang Zheng", "Akshay Asthana"], "title": "Gromov Wasserstein Optimal Transport for Semantic Correspondences", "categories": ["cs.CV"], "comment": null, "summary": "Establishing correspondences between image pairs is a long studied problem in computer vision. With recent large-scale foundation models showing strong zero-shot performance on downstream tasks including classification and segmentation, there has been interest in using the internal feature maps of these models for the semantic correspondence task. Recent works observe that features from DINOv2 and Stable Diffusion (SD) are complementary, the former producing accurate but sparse correspondences, while the latter produces spatially consistent correspondences. As a result, current state-of-the-art methods for semantic correspondence involve combining features from both models in an ensemble. While the performance of these methods is impressive, they are computationally expensive, requiring evaluating feature maps from large-scale foundation models. In this work we take a different approach, instead replacing SD features with a superior matching algorithm which is imbued with the desirable spatial consistency property. Specifically, we replace the standard nearest neighbours matching with an optimal transport algorithm that includes a Gromov Wasserstein spatial smoothness prior. We show that we can significantly boost the performance of the DINOv2 baseline, and be competitive and sometimes surpassing state-of-the-art methods using Stable Diffusion features, while being 5--10x more efficient. We make code available at https://github.com/fsnelgar/semantic_matching_gwot .", "AI": {"tldr": "本文提出了一种使用Gromov Wasserstein最优传输算法来替代Stable Diffusion特征，以提高语义对应任务中DINOv2模型的性能。", "motivation": "通过结合大规模预训练模型内部特征图的方法在语义对应任务上表现出色但计算成本高。本文旨在探索一种更为高效的匹配方法，即利用包含空间一致性的最优传输算法来提升性能。", "method": "文章使用Gromov Wasserstein最优传输替代了Stable Diffusion的特征，并结合DINOv2模型生成更精确和一致的语义对应。", "result": "实验结果表明，该方法可以显著提高DINOv2的基础线性能，在某些情况下甚至超过了使用Stable Diffusion特征的方法，且计算效率提高了5-10倍。", "conclusion": "通过引入Gromov Wasserstein最优传输算法来增强语义对应任务的性能并降低成本，本文提出了一种有效且高效的解决方案。"}}
{"id": "2602.03104", "pdf": "https://arxiv.org/pdf/2602.03104", "abs": "https://arxiv.org/abs/2602.03104", "authors": ["Yufeng Wu", "Qing Li", "Elise van den Hoven", "Baki Kocaballi"], "title": "\"I'm happy even though it's not real\": GenAI Photo Editing as a Remembering Experience", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) is increasingly integrated into photo applications on personal devices, making editing photographs easier than ever while potentially influencing the memories they represent. This study explores how and why people use GenAI to edit personal photos and how this shapes their remembering experience. We conducted a two-phase qualitative study with 12 participants: a photo editing session using a GenAI tool guided by the Remembering Experience (RX) dimensions, followed by semi-structured interviews where participants reflected on the editing process and results. Findings show that participants prioritised felt memory over factual accuracy. For different photo elements, environments were modified easily, however, editing was deemed unacceptable if it touched upon a person's identity. Editing processes brought positive and negative impacts, and itself also became a remembering experience. We further discuss potential benefits and risks of GenAI editing for remembering purposes and propose design implications for responsible GenAI.", "AI": {"tldr": "研究探讨了人们如何及为何使用生成式人工智能编辑个人照片，并分析这种行为如何影响他们的回忆体验。", "motivation": "随着生成式人工智能技术在摄影应用中的普及，其对个人记忆的潜在影响引起了关注。本研究旨在探究人们利用GenAI进行照片编辑的行为动机及其对回忆体验的影响。", "method": "研究分为两个阶段：12名参与者使用基于Remembering Experience维度设计的GenAI工具进行图片编辑；随后进行了半结构化访谈，让参与者反思编辑过程和结果。", "result": "发现参与者更重视情感记忆而非事实准确性。虽然环境可以轻易修改，但如果涉及人物身份则认为不可接受。编辑过程产生了积极与消极影响，并自身也变成了一种回忆体验。", "conclusion": "讨论了GenAI在回忆方面的好处与风险，并提出了负责任设计的建议以平衡技术应用中的利益和潜在危害。"}}
{"id": "2602.03103", "pdf": "https://arxiv.org/pdf/2602.03103", "abs": "https://arxiv.org/abs/2602.03103", "authors": ["Pritam Kadasi", "Abhishek Upperwal", "Mayank Singh"], "title": "Task--Specificity Score: Measuring How Much Instructions Really Matter for Supervision", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Instruction tuning is now the default way to train and adapt large language models, but many instruction--input--output pairs are only weakly specified: for a given input, the same output can remain plausible under several alternative instructions. This raises a simple question: \\emph{does the instruction uniquely determine the target output?} We propose the \\textbf{Task--Specificity Score (TSS)} to quantify how much an instruction matters for predicting its output, by contrasting the true instruction against plausible alternatives for the same input. We further introduce \\textbf{TSS++}, which uses hard alternatives and a small quality term to mitigate easy-negative effects. Across three instruction datasets (\\textsc{Alpaca}, \\textsc{Dolly-15k}, \\textsc{NI-20}) and three open LLMs (Gemma, Llama, Qwen), we show that selecting task-specific examples improves downstream performance under tight token budgets and complements quality-based filters such as perplexity and IFD.", "AI": {"tldr": "提出任务特定性分数（TSS）和改进版TSS++，用于量化指令对于预测其输出的重要性，并在多个数据集和模型上验证了该方法的有效性。", "motivation": "许多指令-输入-输出对只有弱定义，相同的输出可能适用于不同的指令。这引发了一个问题：指令是否唯一确定目标输出？为了回答这个问题，提出了一种量化指令重要性的方法。", "method": "引入任务特定性分数（TSS）和改进版的TSS++来量化指令的重要性，并通过与真实指令对比具有相同输入的不同可能替代方案进行衡量。此外，使用了硬对抗样本和质量项减轻容易否定效应。", "result": "在三个指令数据集和三个开源大型语言模型上进行了实验，结果表明选择任务特定的例子可以提高下游性能并在有限的令牌预算下与基于质量的过滤器互补。", "conclusion": "所提出的方法（TSS和TSS++）提供了一种有效的方式量化指令的重要性，并在多个数据集和模型中展示了其有效性。"}}
{"id": "2602.03100", "pdf": "https://arxiv.org/pdf/2602.03100", "abs": "https://arxiv.org/abs/2602.03100", "authors": ["Jingnan Zheng", "Yanzhen Luo", "Jingjun Xu", "Bingnan Liu", "Yuxin Chen", "Chenhang Cui", "Gelei Deng", "Chaochao Lu", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Risky-Bench: Probing Agentic Safety Risks under Real-World Deployment", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed as agents that operate in real-world environments, introducing safety risks beyond linguistic harm. Existing agent safety evaluations rely on risk-oriented tasks tailored to specific agent settings, resulting in limited coverage of safety risk space and failing to assess agent safety behavior during long-horizon, interactive task execution in complex real-world deployments. Moreover, their specialization to particular agent settings limits adaptability across diverse agent configurations. To address these limitations, we propose Risky-Bench, a framework that enables systematic agent safety evaluation grounded in real-world deployment. Risky-Bench organizes evaluation around domain-agnostic safety principles to derive context-aware safety rubrics that delineate safety space, and systematically evaluates safety risks across this space through realistic task execution under varying threat assumptions. When applied to life-assist agent settings, Risky-Bench uncovers substantial safety risks in state-of-the-art agents under realistic execution conditions. Moreover, as a well-structured evaluation pipeline, Risky-Bench is not confined to life-assist scenarios and can be adapted to other deployment settings to construct environment-specific safety evaluations, providing an extensible methodology for agent safety assessment.", "AI": {"tldr": "提出Risky-Bench框架，用于评估大型语言模型在真实世界部署中的安全性。", "motivation": "现有代理安全评测方法受限于特定任务和环境，无法全面覆盖长时交互下的安全风险。因此需要一种通用且可扩展的方法来解决此问题。", "method": "设计Risky-Bench框架，基于跨领域通用的安全原则构建评估标准，并通过模拟真实世界中的威胁假设执行实际任务以系统性地检测代理在各种环境中的安全性。", "result": "应用Risky-Bench发现先进生命辅助代理在现实操作条件下的重大安全风险；同时证明该方法可适用于不同部署场景，提供一种灵活的代理安全性评估手段。", "conclusion": "通过提出并验证了Risky-Bench框架的有效性及其在多样化代理配置中的适应性和扩展能力，为大型语言模型的安全性研究提供了新的视角和工具。"}}
{"id": "2602.03098", "pdf": "https://arxiv.org/pdf/2602.03098", "abs": "https://arxiv.org/abs/2602.03098", "authors": ["Soyeon Hong", "Jinchan Kim", "Jaegook You", "Seungtaek Choi", "Suha Kwak", "Hyunsouk Cho"], "title": "TextME: Bridging Unseen Modalities Through Text Descriptions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Expanding multimodal representations to novel modalities is constrained by reliance on large-scale paired datasets (e.g., text-image, text-audio, text-3D, text-molecule), which are costly and often infeasible in domains requiring expert annotation such as medical imaging and molecular analysis. We introduce TextME, the first text-only modality expansion framework, to the best of our knowledge, projecting diverse modalities into LLM embedding space as a unified anchor. Our approach exploits the geometric structure of pretrained contrastive encoders to enable zero-shot cross-modal transfer using only text descriptions, without paired supervision. We empirically validate that such consistent modality gaps exist across image, video, audio, 3D, X-ray, and molecular domains, demonstrating that text-only training can preserve substantial performance of pretrained encoders. We further show that our framework enables emergent cross-modal retrieval between modality pairs not explicitly aligned during training (e.g., audio-to-image, 3D-to-image). These results establish text-only training as a practical alternative to paired supervision for modality expansion.", "AI": {"tldr": "本文提出了TextME框架，通过文本描述实现跨模态的零样本迁移学习。", "motivation": "在许多领域如医学成像和分子分析中，大规模配对数据集的成本高昂且难以获取。因此，本研究旨在利用仅基于文本描述的方法来扩展多模态表示。", "method": "TextME框架通过预训练对比编码器的几何结构，将不同模态投影到语言模型嵌入空间作为统一锚点，从而实现零样本跨模态迁移学习。", "result": "实验结果表明，在图像、视频、音频、3D、X射线和分子等各个领域中，基于文本的训练能够保持预训练编码器的有效性能。此外，该框架支持不同模态之间未显式对齐情况下的零样本检索任务。", "conclusion": "这些成果证明了仅依靠文本描述进行训练作为一种实用替代方案来解决配对监督数据集问题的可能性和效果。"}}
{"id": "2602.03097", "pdf": "https://arxiv.org/pdf/2602.03097", "abs": "https://arxiv.org/abs/2602.03097", "authors": ["Bryce Kan", "Wei Yang", "Emily Nguyen", "Ganghui Yi", "Bowen Yi", "Chenxiao Yu", "Yan Liu"], "title": "De-conflating Preference and Qualification: Constrained Dual-Perspective Reasoning for Job Recommendation with Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Professional job recommendation involves a complex bipartite matching process that must reconcile a candidate's subjective preference with an employer's objective qualification. While Large Language Models (LLMs) are well-suited for modeling the rich semantics of resumes and job descriptions, existing paradigms often collapse these two decision dimensions into a single interaction signal, yielding confounded supervision under recruitment-funnel censoring and limiting policy controllability. To address these challenges, We propose JobRec, a generative job recommendation framework for de-conflating preference and qualification via constrained dual-perspective reasoning. JobRec introduces a Unified Semantic Alignment Schema that aligns candidate and job attributes into structured semantic layers, and a Two-Stage Cooperative Training Strategy that learns decoupled experts to separately infer preference and qualification. Building on these experts, a Lagrangian-based Policy Alignment module optimizes recommendations under explicit eligibility requirements, enabling controllable trade-offs. To mitigate data scarcity, we construct a synthetic dataset refined by experts. Experiments show that JobRec consistently outperforms strong baselines and provides improved controllability for strategy-aware professional matching.", "AI": {"tldr": "提出JobRec框架，通过约束双视角推理来解耦候选人偏好的主观性和雇主资格的客观性，从而改进职业推荐。", "motivation": "现有方法在职业推荐中将偏好和资格合并为单一互动信号，导致混淆监督并限制策略控制。本文旨在解决这一问题。", "method": "提出JobRec框架，包括统一语义对齐模式、两阶段协作训练策略以及基于拉格朗日的策略对齐模块来优化推荐。", "result": "实验表明，JobRec在强基线方法上表现更优，并提供更好的策略控制性。", "conclusion": "通过解耦偏好和资格并引入新的框架组件，能够更好地处理职业匹配任务中的复杂问题。"}}
{"id": "2602.03096", "pdf": "https://arxiv.org/pdf/2602.03096", "abs": "https://arxiv.org/abs/2602.03096", "authors": ["Yujie Yang"], "title": "PRISM: Structured Optimization via Anisotropic Spectral Shaping", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose PRISM, an optimizer that enhances first-order spectral descent methods like Muon with partial second-order information. It constructs an efficient, low-rank quasi-second-order preconditioner via innovation-augmented polar decomposition. This mechanism enables PRISM to perform anisotropic spectral shaping, which adaptively suppresses updates in high-variance subspaces while preserving update strength in signal-dominated directions. Crucially, this is achieved with minimal computational overhead and zero additional memory compared to first-order baselines. PRISM demonstrates a practical strategy for integrating curvature-adaptive properties into the spectral optimization paradigm.", "AI": {"tldr": "PRISM是一种优化器，通过创新增强的一阶谱下降方法（如Muon）来引入部分二阶信息。", "motivation": "为了在保持低计算开销和零额外内存的情况下将曲率自适应特性集成到光谱优化范式中，提出了一种新的优化策略。", "method": "PRISM通过创新增强的极分解构建了一个高效的、低秩准二阶预处理器，从而实现了各向异性谱形状调整。这种方法在高方差子空间抑制更新的同时，在信号主导的方向上保持了更新强度。", "result": "PRISM展示了将曲率自适应特性融入光谱优化范式的一种实用策略，并且与一阶基准相比没有额外的计算开销和内存需求。", "conclusion": "通过创新增强的一阶极分解，PRISM成功地实现了各向异性谱形状调整，从而在保持低计算成本的同时增强了优化性能。"}}
{"id": "2602.03095", "pdf": "https://arxiv.org/pdf/2602.03095", "abs": "https://arxiv.org/abs/2602.03095", "authors": ["Lei Han", "Yi Gao", "Xuanchen Lu", "Bingyuan Wang", "Lujin Zhang", "Zeyu Wang", "David Yip"], "title": "Gen-Diaolou: An Integrated AI-Assisted Interactive System for Diachronic Understanding and Preservation of the Kaiping Diaolou", "categories": ["cs.HC"], "comment": null, "summary": "The Kaiping Diaolou and Villages, a UNESCO World Heritage Site, exemplify hybrid Chinese and Western architecture shaped by migration culture. However, architectural heritage engagement often faces authenticity debates, resource constraints, and limited participatory approaches. This research explores current challenges of leveraging Artificial Intelligence (AI) for architectural heritage, and how AI-assisted interactive systems can foster cultural heritage understanding and preservation awareness. We conducted a formative study (N=14) to uncover empirical insights from heritage stakeholders that inform design. These insights informed the design of Gen-Diaolou, an integrated AI-assisted interactive system that supports heritage understanding and preservation. A pilot study (N=18) and a museum field study (N=26) provided converging evidence suggesting that Gen-Diaolou may support visitors' diachronic understanding and preservation awareness, and together informed design implications for future human-AI collaborative systems for digital cultural heritage engagement. More broadly, this work bridges the research gap between passive heritage systems and unconstrained creative tools in the HCI domain.", "AI": {"tldr": "研究设计并测试了一个名为Gen-Diaolou的AI辅助交互系统，该系统用于促进开平碉楼这一世界文化遗产的理解和保护。", "motivation": "该项目旨在解决文化遗址参与中的真实性争议、资源限制以及有限的互动方式问题。通过利用人工智能技术来增进对建筑遗产的理解和保护意识。", "method": "进行了初步研究（N=14）以获取来自遗产利益相关者的实证见解，进而设计了Gen-Diaolou系统，并通过试点研究（N=18）和博物馆实地研究（N=26）对其效果进行验证。", "result": "研究表明，Gen-Diaolou支持访问者对文化遗址的时间性理解和保护意识的提升。这些结果为未来的人机协作系统在数字文化遗产参与方面提供了设计启示。", "conclusion": "该工作填补了被动遗产系统与非约束创意工具之间的人机交互研究空白，通过AI技术增强了文化遗产的理解和保护。"}}
{"id": "2602.03087", "pdf": "https://arxiv.org/pdf/2602.03087", "abs": "https://arxiv.org/abs/2602.03087", "authors": ["Baixiao Huang", "Baiyu Huang", "Yu Hou"], "title": "Training and Simulation of Quadrupedal Robot in Adaptive Stair Climbing for Indoor Firefighting: An End-to-End Reinforcement Learning Approach", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "8 pages, 9 figures, 43rd International Symposium on Automation and Robotics in Construction", "summary": "Quadruped robots are used for primary searches during the early stages of indoor fires. A typical primary search involves quickly and thoroughly looking for victims under hazardous conditions and monitoring flammable materials. However, situational awareness in complex indoor environments and rapid stair climbing across different staircases remain the main challenges for robot-assisted primary searches. In this project, we designed a two-stage end-to-end deep reinforcement learning (RL) approach to optimize both navigation and locomotion. In the first stage, the quadrupeds, Unitree Go2, were trained to climb stairs in Isaac Lab's pyramid-stair terrain. In the second stage, the quadrupeds were trained to climb various realistic indoor staircases in the Isaac Lab engine, with the learned policy transferred from the previous stage. These indoor staircases are straight, L-shaped, and spiral, to support climbing tasks in complex environments. This project explores how to balance navigation and locomotion and how end-to-end RL methods can enable quadrupeds to adapt to different stair shapes. Our main contributions are: (1) A two-stage end-to-end RL framework that transfers stair-climbing skills from abstract pyramid terrain to realistic indoor stair topologies. (2) A centerline-based navigation formulation that enables unified learning of navigation and locomotion without hierarchical planning. (3) Demonstration of policy generalization across diverse staircases using only local height-map perception. (4) An empirical analysis of success, efficiency, and failure modes under increasing stair difficulty.", "AI": {"tldr": "本文提出了一种用于四足机器人室内灭火初期搜索的两阶段端到端强化学习方法，以优化导航和运动。", "motivation": "在复杂室内环境中进行快速楼梯攀爬是机器人辅助初步搜索的主要挑战。研究旨在通过端到端RL方法使四足机器人适应不同形状的楼梯，并提高其在危险条件下的搜救效率与效果。", "method": "该研究采用两阶段端到端深度强化学习框架，先在抽象的金字塔地形中训练Unitree Go2攀爬楼梯技能，然后将学到的策略迁移到现实室内楼梯环境中，通过中心线导航模型统一学习导航和运动。", "result": "实验展示了所提方法能在不同复杂度的楼梯上实现成功、高效的任务执行，并分析了成功的条件以及遇到的问题模式。", "conclusion": "本文提出的方法能够使四足机器人在多种类型室内楼梯上有效攀爬，为未来在危险环境中的应用提供了新的视角和可能性。"}}
{"id": "2602.03086", "pdf": "https://arxiv.org/pdf/2602.03086", "abs": "https://arxiv.org/abs/2602.03086", "authors": ["Jiayao Mai", "Bangyan Liao", "Zhenjun Zhao", "Yingping Zeng", "Haoang Li", "Javier Civera", "Tailin Wu", "Yi Zhou", "Peidong Liu"], "title": "Neural Predictor-Corrector: Solving Homotopy Problems with Reinforcement Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The Homotopy paradigm, a general principle for solving challenging problems, appears across diverse domains such as robust optimization, global optimization, polynomial root-finding, and sampling. Practical solvers for these problems typically follow a predictor-corrector (PC) structure, but rely on hand-crafted heuristics for step sizes and iteration termination, which are often suboptimal and task-specific. To address this, we unify these problems under a single framework, which enables the design of a general neural solver. Building on this unified view, we propose Neural Predictor-Corrector (NPC), which replaces hand-crafted heuristics with automatically learned policies. NPC formulates policy selection as a sequential decision-making problem and leverages reinforcement learning to automatically discover efficient strategies. To further enhance generalization, we introduce an amortized training mechanism, enabling one-time offline training for a class of problems and efficient online inference on new instances. Experiments on four representative homotopy problems demonstrate that our method generalizes effectively to unseen instances. It consistently outperforms classical and specialized baselines in efficiency while demonstrating superior stability across tasks, highlighting the value of unifying homotopy methods into a single neural framework.", "AI": {"tldr": "本文提出了一种基于强化学习的神经预测校正器（NPC），用于解决同伦问题，该方法可以自动发现有效的策略，并在新实例上进行高效推断。", "motivation": "传统的同伦求解器依赖于手工设计启发式方法来选择步长和终止迭代，这些方法往往是次优且任务特定的。因此，本文旨在通过统一不同领域的同伦问题并在一个框架下使用强化学习自动发现策略。", "method": "提出了神经预测校正器（NPC）模型，它将策略选择作为顺序决策问题，并利用强化学习来自动搜索有效策略。为提高泛化能力，引入了预计算训练机制，在离线训练后可在新实例上进行高效推理。", "result": "实验结果显示，该方法在效率上优于传统和专用基准方法，并且具有跨任务的稳定性。", "conclusion": "通过将同伦方法统一到一个神经框架中，本文展示了NPC模型的有效性和优越性。"}}
{"id": "2602.03085", "pdf": "https://arxiv.org/pdf/2602.03085", "abs": "https://arxiv.org/abs/2602.03085", "authors": ["Blake Bullwinkel", "Giorgio Severi", "Keegan Hines", "Amanda Minnich", "Ram Shankar Siva Kumar", "Yonatan Zunger"], "title": "The Trigger in the Haystack: Extracting and Reconstructing LLM Backdoor Triggers", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Detecting whether a model has been poisoned is a longstanding problem in AI security. In this work, we present a practical scanner for identifying sleeper agent-style backdoors in causal language models. Our approach relies on two key findings: first, sleeper agents tend to memorize poisoning data, making it possible to leak backdoor examples using memory extraction techniques. Second, poisoned LLMs exhibit distinctive patterns in their output distributions and attention heads when backdoor triggers are present in the input. Guided by these observations, we develop a scalable backdoor scanning methodology that assumes no prior knowledge of the trigger or target behavior and requires only inference operations. Our scanner integrates naturally into broader defensive strategies and does not alter model performance. We show that our method recovers working triggers across multiple backdoor scenarios and a broad range of models and fine-tuning methods.", "AI": {"tldr": "该论文提出了一种检测语言模型中潜伏后门的方法。", "motivation": "在AI安全领域，检测模型是否被破坏是一个长期存在的问题。本文旨在开发一种实用的扫描工具来识别因果语言模型中的潜伏后门。", "method": "基于两个关键发现：潜伏者倾向于记忆中毒数据，并且存在特定模式用于输出分布和注意力头。该方法假设无先验知识，仅使用推理操作即可检测到触发器。", "result": "本文的方法能够恢复多种后门场景下的工作触发器，适用于广泛的语言模型和微调方式。", "conclusion": "提出了一种有效的扫描技术来识别因果语言模型中的潜伏后门，该技术自然集成于更广泛的防御策略中且不改变模型性能。"}}
{"id": "2602.03076", "pdf": "https://arxiv.org/pdf/2602.03076", "abs": "https://arxiv.org/abs/2602.03076", "authors": ["Shinn Kim", "Soobin Lee", "Kyoungseob Shin", "Han-Soo Kim", "Yongsung Kim", "Minsu Kim", "Juhong Nam", "Somang Ko", "Daeheon Kwon", "Wook Huh", "Ilkyu Han", "Sunghoon Kwon"], "title": "A generalizable large-scale foundation model for musculoskeletal radiographs", "categories": ["cs.CV"], "comment": null, "summary": "Artificial intelligence (AI) has shown promise in detecting and characterizing musculoskeletal diseases from radiographs. However, most existing models remain task-specific, annotation-dependent, and limited in generalizability across diseases and anatomical regions. Although a generalizable foundation model trained on large-scale musculoskeletal radiographs is clinically needed, publicly available datasets remain limited in size and lack sufficient diversity to enable training across a wide range of musculoskeletal conditions and anatomical sites. Here, we present SKELEX, a large-scale foundation model for musculoskeletal radiographs, trained using self-supervised learning on 1.2 million diverse, condition-rich images. The model was evaluated on 12 downstream diagnostic tasks and generally outperformed baselines in fracture detection, osteoarthritis grading, and bone tumor classification. Furthermore, SKELEX demonstrated zero-shot abnormality localization, producing error maps that identified pathologic regions without task-specific training. Building on this capability, we developed an interpretable, region-guided model for predicting bone tumors, which maintained robust performance on independent external datasets and was deployed as a publicly accessible web application. Overall, SKELEX provides a scalable, label-efficient, and generalizable AI framework for musculoskeletal imaging, establishing a foundation for both clinical translation and data-efficient research in musculoskeletal radiology.", "AI": {"tldr": "构建了一个大规模的用于骨科影像的基础模型SKELEX，该模型能够跨多种疾病和解剖区域进行泛化。", "motivation": "现有的AI模型在骨科疾病的检测与分类上表现良好，但通常任务特异性强、依赖标注数据且缺乏广泛的泛化能力。为了满足临床需求并推动研究发展，需要一个大规模的数据集来训练基础模型。", "method": "使用自我监督学习方法，在包含120万张多样化的影像图片的大型数据集中训练SKELEX。评估了该模型在12个下游诊断任务中的表现，并展示了其零样本异常定位能力，开发了一个可解释的、区域导向的骨肿瘤预测模型。", "result": "SKELEX在骨折检测、关节炎分级和骨肿瘤分类等任务中表现出色，并能生成错误映射来识别病理区域。该模型在外部分析数据集上保持了稳健性能并部署为公共访问的应用程序。", "conclusion": "SKELEX提供了一个可扩展的，标签高效的AI框架用于骨科影像分析，成为临床应用和高效研究的基础。"}}
{"id": "2602.03071", "pdf": "https://arxiv.org/pdf/2602.03071", "abs": "https://arxiv.org/abs/2602.03071", "authors": ["Sunoh Kim", "Kimin Yun", "Daeho Um"], "title": "Finding Optimal Video Moment without Training: Gaussian Boundary Optimization for Weakly Supervised Video Grounding", "categories": ["cs.CV"], "comment": "Accepted in IEEE TMM", "summary": "Weakly supervised temporal video grounding aims to localize query-relevant segments in untrimmed videos using only video-sentence pairs, without requiring ground-truth segment annotations that specify exact temporal boundaries. Recent approaches tackle this task by utilizing Gaussian-based temporal proposals to represent query-relevant segments. However, their inference strategies rely on heuristic mappings from Gaussian parameters to segment boundaries, resulting in suboptimal localization performance. To address this issue, we propose Gaussian Boundary Optimization (GBO), a novel inference framework that predicts segment boundaries by solving a principled optimization problem that balances proposal coverage and segment compactness. We derive a closed-form solution for this problem and rigorously analyze the optimality conditions under varying penalty regimes. Beyond its theoretical foundations, GBO offers several practical advantages: it is training-free and compatible with both single-Gaussian and mixture-based proposal architectures. Our experiments show that GBO significantly improves localization, achieving state-of-the-art results across standard benchmarks. Extensive experiments demonstrate the efficiency and generalizability of GBO across various proposal schemes. The code is available at \\href{https://github.com/sunoh-kim/gbo}{https://github.com/sunoh-kim/gbo}.", "AI": {"tldr": "本文提出了一种新的推理框架Gaussian Boundary Optimization (GBO)，用于优化视频中查询相关片段的定位。", "motivation": "现有的方法通过使用高斯分布表示查询相关的片段，但其推理策略依赖于从高斯参数到段边界的启发式映射，导致了次优的局部化性能。因此，本文提出了新的框架GBO来改进这一点。", "method": "该论文提出了一种新的优化问题求解方法Gaussian Boundary Optimization（GBO），它通过平衡提案覆盖和片段紧凑性来预测边界，并为这个问题推导出一个闭式解决方案。此外，这种方法还具有理论基础且无需训练。", "result": "实验结果显示，GBO显著提高了定位性能，在标准基准测试中达到了最先进的结果。", "conclusion": "GBO提供了高效的局部化改进方法，适用于各种提案方案，并展示了其在弱监督视频定位任务中的优势。"}}
{"id": "2602.03067", "pdf": "https://arxiv.org/pdf/2602.03067", "abs": "https://arxiv.org/abs/2602.03067", "authors": ["Felix X. -F. Ye", "Xingjie Li", "An Yu", "Ming-Ching Chang", "Linsong Chu", "Davis Wertheimer"], "title": "FlashSinkhorn: IO-Aware Entropic Optimal Transport", "categories": ["cs.LG", "cs.AI", "math.NA"], "comment": null, "summary": "Entropic optimal transport (EOT) via Sinkhorn iterations is widely used in modern machine learning, yet GPU solvers remain inefficient at scale. Tensorized implementations suffer quadratic HBM traffic from dense $n\\times m$ interactions, while existing online backends avoid storing dense matrices but still rely on generic tiled map-reduce reduction kernels with limited fusion. We present \\textbf{FlashSinkhorn}, an IO-aware EOT solver for squared Euclidean cost that rewrites stabilized log-domain Sinkhorn updates as row-wise LogSumExp reductions of biased dot-product scores, the same normalization as transformer attention. This enables FlashAttention-style fusion and tiling: fused Triton kernels stream tiles through on-chip SRAM and update dual potentials in a single pass, substantially reducing HBM IO per iteration while retaining linear-memory operations. We further provide streaming kernels for transport application, enabling scalable first- and second-order optimization. On A100 GPUs, FlashSinkhorn achieves up to $32\\times$ forward-pass and $161\\times$ end-to-end speedups over state-of-the-art online baselines on point-cloud OT, improves scalability on OT-based downstream tasks. For reproducibility, we release an open-source implementation at https://github.com/ot-triton-lab/ot_triton.", "AI": {"tldr": "介绍了一种名为FlashSinkhorn的新方法，用于提高GPU上大规模最优传输问题求解的效率。", "motivation": "现有的基于GPU的最优传输求解器在处理大规模数据时仍然不够高效。传统的方法存在二次HBM通信瓶颈，并且虽然一些在线后端避免存储稠密矩阵但仍依赖于通用的分块映射核，这限制了融合。因此需要一种新的方法来提高效率。", "method": "通过重写稳定的对数领域Sinkhorn更新为带有偏置点积得分的行级LogSumExp归一化，FlashSinkhorn将EOT与转换器注意力机制中的归一化相结合。这种新方法允许Fusion和Tile技术，从而减少HBM IO并在单次传递中更新对偶势能。此外还提供了一种流式内核以实现可扩展的优化。", "result": "在A100 GPU上，FlashSinkhorn实现了比现有在线基线最高32倍的速度提升，并且端到端速度最多提高了161倍，同时改善了基于OT任务的大规模处理能力。", "conclusion": "通过引入FlashSinkhorn，成功地解决了大规模最优传输问题求解效率低下这一挑战。该方法为未来在机器学习中更高效应用EOT打下了基础。"}}
{"id": "2602.03066", "pdf": "https://arxiv.org/pdf/2602.03066", "abs": "https://arxiv.org/abs/2602.03066", "authors": ["Jinwoo Lim", "Suhyun Kim", "Soo-Mook Moon"], "title": "Shortcut Features as Top Eigenfunctions of NTK: A Linear Neural Network Case and More", "categories": ["cs.LG", "cs.AI"], "comment": "ef:NeurIPS 2025", "summary": "One of the chronic problems of deep-learning models is shortcut learning. In a case where the majority of training data are dominated by a certain feature, neural networks prefer to learn such a feature even if the feature is not generalizable outside the training set. Based on the framework of Neural Tangent Kernel (NTK), we analyzed the case of linear neural networks to derive some important properties of shortcut learning. We defined a feature of a neural network as an eigenfunction of NTK. Then, we found that shortcut features correspond to features with larger eigenvalues when the shortcuts stem from the imbalanced number of samples in the clustered distribution. We also showed that the features with larger eigenvalues still have a large influence on the neural network output even after training, due to data variances in the clusters. Such a preference for certain features remains even when a margin of a neural network output is controlled, which shows that the max-margin bias is not the only major reason for shortcut learning. These properties of linear neural networks are empirically extended for more complex neural networks as a two-layer fully-connected ReLU network and a ResNet-18.", "AI": {"tldr": "本文通过NTK框架分析线性神经网络中的捷径学习，并发现捷径特征对应于具有较大本征值的特征。", "motivation": "解决深度学习模型中因训练数据不平衡导致的捷径学习问题，探究捷径学习的原因和机制。", "method": "基于NTK理论框架，将神经网络特征定义为NTK的本征函数，并分析线性神经网络中的捷径学习现象及其影响。实验验证了这些特性在线性和更复杂的多层全连接ReLU网络及ResNet-18模型中的适用性。", "result": "发现捷径特征与较大本征值相关，即使在控制最大间隔的情况下仍然具有显著影响力；表明捷径学习的原因并非仅由最大间隔偏差引起。", "conclusion": "通过理论分析和实验验证，揭示了神经网络中捷径学习的机制，并为理解其深层次原因提供了新的视角。"}}
{"id": "2602.03064", "pdf": "https://arxiv.org/pdf/2602.03064", "abs": "https://arxiv.org/abs/2602.03064", "authors": ["Sandika Biswas", "Kian Izadpanah", "Hamid Rezatofighi"], "title": "JRDB-Pose3D: A Multi-person 3D Human Pose and Shape Estimation Dataset for Robotics", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Real-world scenes are inherently crowded. Hence, estimating 3D poses of all nearby humans, tracking their movements over time, and understanding their activities within social and environmental contexts are essential for many applications, such as autonomous driving, robot perception, robot navigation, and human-robot interaction. However, most existing 3D human pose estimation datasets primarily focus on single-person scenes or are collected in controlled laboratory environments, which restricts their relevance to real-world applications. To bridge this gap, we introduce JRDB-Pose3D, which captures multi-human indoor and outdoor environments from a mobile robotic platform. JRDB-Pose3D provides rich 3D human pose annotations for such complex and dynamic scenes, including SMPL-based pose annotations with consistent body-shape parameters and track IDs for each individual over time. JRDB-Pose3D contains, on average, 5-10 human poses per frame, with some scenes featuring up to 35 individuals simultaneously. The proposed dataset presents unique challenges, including frequent occlusions, truncated bodies, and out-of-frame body parts, which closely reflect real-world environments. Moreover, JRDB-Pose3D inherits all available annotations from the JRDB dataset, such as 2D pose, information about social grouping, activities, and interactions, full-scene semantic masks with consistent human- and object-level tracking, and detailed annotations for each individual, such as age, gender, and race, making it a holistic dataset for a wide range of downstream perception and human-centric understanding tasks.", "AI": {"tldr": "介绍了一个多人体3D姿态和形状估计的数据集JRDB-Pose3D，用于机器人感知、导航和交互任务。", "motivation": "现有的3D人体姿态数据集主要关注单个人体或控制环境中的场景，限制了其在现实世界应用中的适用性。因此，本文提出了一个新数据集来解决这些问题。", "method": "从移动机器人平台捕获室内和室外的多个人类场景，并提供了详细的SMPL基3D人体姿态注释及身体形状参数等。", "result": "该数据集包含复杂的动态场景下的丰富标注信息，可应对频繁遮挡、截断的身体部分等问题。它继承了JRDB的数据，提供全面的人体和社会交互注释。", "conclusion": "JRDB-Pose3D是一个多人体3D姿态和形状估计的综合数据集，适用于广泛的下游感知任务和人类为中心的理解工作。"}}
{"id": "2602.03061", "pdf": "https://arxiv.org/pdf/2602.03061", "abs": "https://arxiv.org/abs/2602.03061", "authors": ["Zihan Dong", "Zhixian Zhang", "Yang Zhou", "Can Jin", "Ruijia Wu", "Linjun Zhang"], "title": "Evaluating LLMs When They Do Not Know the Answer: Statistical Evaluation of Mathematical Reasoning via Comparative Signals", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ME", "stat.ML"], "comment": null, "summary": "Evaluating mathematical reasoning in LLMs is constrained by limited benchmark sizes and inherent model stochasticity, yielding high-variance accuracy estimates and unstable rankings across platforms. On difficult problems, an LLM may fail to produce a correct final answer, yet still provide reliable pairwise comparison signals indicating which of two candidate solutions is better. We leverage this observation to design a statistically efficient evaluation framework that combines standard labeled outcomes with pairwise comparison signals obtained by having models judge auxiliary reasoning chains. Treating these comparison signals as control variates, we develop a semiparametric estimator based on the efficient influence function (EIF) for the setting where auxiliary reasoning chains are observed. This yields a one-step estimator that achieves the semiparametric efficiency bound, guarantees strict variance reduction over naive sample averaging, and admits asymptotic normality for principled uncertainty quantification. Across simulations, our one-step estimator substantially improves ranking accuracy, with gains increasing as model output noise grows. Experiments on GPQA Diamond, AIME 2025, and GSM8K further demonstrate more precise performance estimation and more reliable model rankings, especially in small-sample regimes where conventional evaluation is pretty unstable.", "AI": {"tldr": "论文提出了一种利用LLM在难以回答的问题上提供可靠比较信号的方法，以提高数学推理评估的准确性和稳定性。", "motivation": "传统的数学推理评估受限于基准大小和模型固有的随机性，导致高方差估计和不稳定的排名。LLM可以通过判断辅助推理链来提供有用的比较信号，从而改进这一情况。", "method": "该方法利用控制变量的思想将标准标记结果与成对比较信号相结合，并基于有效影响函数（EIF）开发了一种半参数估计器，这种估计器在观察到辅助推理链的情况下能够实现半参数效率边界。", "result": "实验表明，所提出的一步估计算法可以显著提高排名准确性，特别是在模型输出噪声较大的情况下。此外，在小样本环境中，该方法还能提供更精确的性能评估和更加可靠的模型排名。", "conclusion": "论文提出的方法有效改进了数学推理能力的评估，尤其适用于传统评价方式不稳定的场景，并通过实验验证了其优越性。"}}
{"id": "2602.03060", "pdf": "https://arxiv.org/pdf/2602.03060", "abs": "https://arxiv.org/abs/2602.03060", "authors": ["Zhichao Sun", "Yidong Ma", "Gang Liu", "Yibo Chen", "Xu Tang", "Yao Hu", "Yongchao Xu"], "title": "IVC-Prune: Revealing the Implicit Visual Coordinates in LVLMs for Vision Token Pruning", "categories": ["cs.CV"], "comment": "Accepted to ICLR 2026", "summary": "Large Vision-Language Models (LVLMs) achieve impressive performance across multiple tasks. A significant challenge, however, is their prohibitive inference cost when processing high-resolution visual inputs. While visual token pruning has emerged as a promising solution, existing methods that primarily focus on semantic relevance often discard tokens that are crucial for spatial reasoning. We address this gap through a novel insight into \\emph{how LVLMs process spatial reasoning}. Specifically, we reveal that LVLMs implicitly establish visual coordinate systems through Rotary Position Embeddings (RoPE), where specific token positions serve as \\textbf{implicit visual coordinates} (IVC tokens) that are essential for spatial reasoning. Based on this insight, we propose \\textbf{IVC-Prune}, a training-free, prompt-aware pruning strategy that retains both IVC tokens and semantically relevant foreground tokens. IVC tokens are identified by theoretically analyzing the mathematical properties of RoPE, targeting positions at which its rotation matrices approximate identity matrix or the $90^\\circ$ rotation matrix. Foreground tokens are identified through a robust two-stage process: semantic seed discovery followed by contextual refinement via value-vector similarity. Extensive evaluations across four representative LVLMs and twenty diverse benchmarks show that IVC-Prune reduces visual tokens by approximately 50\\% while maintaining $\\geq$ 99\\% of the original performance and even achieving improvements on several benchmarks. Source codes are available at https://github.com/FireRedTeam/IVC-Prune.", "AI": {"tldr": "研究提出了一种基于LVLM中隐含视觉坐标（IVC）的视觉令牌剪枝策略，以降低高分辨率图像处理的成本。", "motivation": "大型视觉语言模型在多种任务上表现出色，但在处理高分辨率视觉输入时推断成本高昂。现有的视觉令牌剪枝方法通常侧重于语义相关性而忽视了空间推理中关键令牌的保留问题。", "method": "提出了IVC-Prune策略：通过分析RoPE的数学特性来确定隐含视觉坐标（IVC）令牌，采用两阶段过程识别前景令牌。该方法不涉及训练且依赖提示。", "result": "在四个代表性LVLM模型和二十个多样化基准测试中，IVC-Prune可减少约50％的视觉令牌，同时保持或提升至少99%的原始性能。", "conclusion": "通过揭示LVLM中的隐含视觉坐标系统并提出一种新颖的无训练提示感知剪枝策略，成功地实现了在不牺牲性能的情况下显著降低推断成本的目标。"}}
{"id": "2602.03059", "pdf": "https://arxiv.org/pdf/2602.03059", "abs": "https://arxiv.org/abs/2602.03059", "authors": ["Yoonsang Kim", "Divyansh Pradhan", "Devshree Jadeja", "Arie Kaufman"], "title": "From Speech-to-Spatial: Grounding Utterances on A Live Shared View with Augmented Reality", "categories": ["cs.HC", "cs.CL", "cs.ET", "cs.IR"], "comment": "11 pages, 6 figures. This is the author's version of the article that will appear at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR) 2026", "summary": "We introduce Speech-to-Spatial, a referent disambiguation framework that converts verbal remote-assistance instructions into spatially grounded AR guidance. Unlike prior systems that rely on additional cues (e.g., gesture, gaze) or manual expert annotations, Speech-to-Spatial infers the intended target solely from spoken references (speech input). Motivated by our formative study of speech referencing patterns, we characterize recurring ways people specify targets (Direct Attribute, Relational, Remembrance, and Chained) and ground them to our object-centric relational graph. Given an utterance, referent cues are parsed and rendered as persistent in-situ AR visual guidance, reducing iterative micro-guidance (\"a bit more to the right\", \"now, stop.\") during remote guidance. We demonstrate the use cases of our system with remote guided assistance and intent disambiguation scenarios. Our evaluation shows that Speechto-Spatial improves task efficiency, reduces cognitive load, and enhances usability compared to a conventional voice-only baseline, transforming disembodied verbal instruction into visually explainable, actionable guidance on a live shared view.", "AI": {"tldr": "该论文提出了一种将口头远程指导指令转化为增强现实（AR）引导的框架Speech-to-Spatial。", "motivation": "受形式化研究中语音引用模式的启发，作者分析了人们指定目标的方式，并基于此提出了一个新的系统来解决仅依赖于口语输入的问题。", "method": "该论文通过识别和解析口头指令中的指向线索并将它们渲染为持续存在的AR视觉指导来进行操作。系统使用对象中心关系图对这些指示进行定位并转换为可视化引导。", "result": "实验结果显示，与传统的语音指引相比，Speech-to-Spatial提高了任务效率，减少了认知负荷，并增强了可用性。", "conclusion": "该论文成功地将口头指令转化为了视觉上可解释且行动化的指导，在实时共享视图中实现了更加高效和易于使用的远程协助。"}}
{"id": "2602.03054", "pdf": "https://arxiv.org/pdf/2602.03054", "abs": "https://arxiv.org/abs/2602.03054", "authors": ["Yuanchen Bai", "Ruixiang Han", "Niti Parikh", "Wendy Ju", "Angelique Taylor"], "title": "Towards Considerate Embodied AI: Co-Designing Situated Multi-Site Healthcare Robots from Abstract Concepts to High-Fidelity Prototypes", "categories": ["cs.HC", "cs.AI", "cs.RO"], "comment": "To appear in Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI 2026)", "summary": "Co-design is essential for grounding embodied artificial intelligence (AI) systems in real-world contexts, especially high-stakes domains such as healthcare. While prior work has explored multidisciplinary collaboration, iterative prototyping, and support for non-technical participants, few have interwoven these into a sustained co-design process. Such efforts often target one context and low-fidelity stages, limiting the generalizability of findings and obscuring how participants' ideas evolve. To address these limitations, we conducted a 14-week workshop with a multidisciplinary team of 22 participants, centered around how embodied AI can reduce non-value-added task burdens in three healthcare settings: emergency departments, long-term rehabilitation facilities, and sleep disorder clinics. We found that the iterative progression from abstract brainstorming to high-fidelity prototypes, supported by educational scaffolds, enabled participants to understand real-world trade-offs and generate more deployable solutions. We propose eight guidelines for co-designing more considerate embodied AI: attuned to context, responsive to social dynamics, mindful of expectations, and grounded in deployment. Project Page: https://byc-sophie.github.io/Towards-Considerate-Embodied-AI/", "AI": {"tldr": "本论文探讨了通过跨学科团队协作设计和实施适用于医疗保健场景的实体人工智能（AI）系统的可行性。", "motivation": "为了解决现有研究在多站点医疗服务中使用实体AI时仅限于单一背景和低保真阶段的问题，本文旨在提出一种综合的方法来促进参与者的想法演变并提高解决方案的实际部署能力。", "method": "作者通过14周的工作坊实验，邀请了22名来自不同学科的成员参与设计过程，该工作坊涵盖了从抽象概念到高保真原型的设计流程，并提供教育支撑。", "result": "研究表明，在真实世界的情境中逐步推进实体AI系统的发展有助于参与者理解现实世界的权衡问题并生成更可部署的解决方案。", "conclusion": "论文提出了八项关于如何设计更具考虑性的实体AI系统的指导原则，这些原则强调了对背景的理解、社会动态的响应性以及预期管理的重要性。"}}
{"id": "2602.03053", "pdf": "https://arxiv.org/pdf/2602.03053", "abs": "https://arxiv.org/abs/2602.03053", "authors": ["Vishal Venkataramani", "Haizhou Shi", "Zixuan Ke", "Austin Xu", "Xiaoxiao He", "Yingbo Zhou", "Semih Yavuz", "Hao Wang", "Shafiq Joty"], "title": "MAS-ProVe: Understanding the Process Verification of Multi-Agent Systems", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": "Preprint; work in progress", "summary": "Multi-Agent Systems (MAS) built on Large Language Models (LLMs) often exhibit high variance in their reasoning trajectories. Process verification, which evaluates intermediate steps in trajectories, has shown promise in general reasoning settings, and has been suggested as a potential tool for guiding coordination of MAS; however, its actual effectiveness in MAS remains unclear. To fill this gap, we present MAS-ProVe, a systematic empirical study of process verification for multi-agent systems (MAS). Our study spans three verification paradigms (LLM-as-a-Judge, reward models, and process reward models), evaluated across two levels of verification granularity (agent-level and iteration-level). We further examine five representative verifiers and four context management strategies, and conduct experiments over six diverse MAS frameworks on multiple reasoning benchmarks. We find that process-level verification does not consistently improve performance and frequently exhibits high variance, highlighting the difficulty of reliably evaluating partial multi-agent trajectories. Among the methods studied, LLM-as-a-Judge generally outperforms reward-based approaches, with trained judges surpassing general-purpose LLMs. We further observe a small performance gap between LLMs acting as judges and as single agents, and identify a context-length-performance trade-off in verification. Overall, our results suggest that effective and robust process verification for MAS remains an open challenge, requiring further advances beyond current paradigms. Code is available at https://github.com/Wang-ML-Lab/MAS-ProVe.", "AI": {"tldr": "MAS-ProVe 系统地研究了多智能体系统（MAS）中的过程验证方法，并评估其在不同设置下的表现。", "motivation": "目前，关于大型语言模型（LLM）驱动的多智能体系统的中间步骤验证效果尚不清楚。因此，该论文旨在填补这一知识空白，探索过程验证在引导和协调 MAS 中的有效性。", "method": "研究涵盖三种验证范式：将 LLM 当作法官、奖励模型以及过程奖励模型，并在代理级别和迭代级别上进行评估。使用五个代表性验证器及四种上下文管理策略，在六个不同的 MAS 框架上进行实验，覆盖多个推理基准。", "result": "结果显示，过程级验证并未一致提高性能且常伴随高方差；LLM 当法官通常优于基于奖励的方法，训练过的法官超越通用 LLM。观察到代理作为裁判和单个代理人之间存在较小的性能差距，并发现上下文长度与验证性能之间的权衡。", "conclusion": "研究结果表明，有效可靠的多智能体系统过程验证仍然是一个开放性挑战，需要在现有范式之外进行进一步改进。"}}
{"id": "2602.03048", "pdf": "https://arxiv.org/pdf/2602.03048", "abs": "https://arxiv.org/abs/2602.03048", "authors": ["Zhiyuan Yao", "Yi-Kai Zhang", "Yuxin Chen", "Yueqing Sun", "Zishan Xu", "Yu Yang", "Tianhao Hu", "Qi Gu", "Hui Su", "Xunliang Cai"], "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key approach for enhancing LLM reasoning.However, standard frameworks like Group Relative Policy Optimization (GRPO) typically employ a uniform rollout budget, leading to resource inefficiency. Moreover, existing adaptive methods often rely on instance-level metrics, such as task pass rates, failing to capture the model's dynamic learning state. To address these limitations, we propose CoBA-RL, a reinforcement learning algorithm designed to adaptively allocate rollout budgets based on the model's evolving capability. Specifically, CoBA-RL utilizes a Capability-Oriented Value function to map tasks to their potential training gains and employs a heap-based greedy strategy to efficiently self-calibrate the distribution of computational resources to samples with high training value. Extensive experiments demonstrate that our approach effectively orchestrates the trade-off between exploration and exploitation, delivering consistent generalization improvements across multiple challenging benchmarks. These findings underscore that quantifying sample training value and optimizing budget allocation are pivotal for advancing LLM post-training efficiency.", "AI": {"tldr": "提出了一种基于模型能力动态调整计算资源分配的强化学习算法CoBA-RL，以优化大型语言模型的训练效率。", "motivation": "传统强化学习框架存在资源配置不均衡的问题，并且现有自适应方法未能有效捕捉模型的学习状态，导致资源利用效率低下。", "method": "提出了一种基于能力的价值函数和堆栈式贪婪策略的CoBA-RL算法，用于动态调整样本训练价值高任务的计算预算分配。", "result": "实验表明CoBA-RL能够更好地平衡探索与开发之间的关系，并在多个具有挑战性的基准测试中提升了模型的一致泛化性能。", "conclusion": "量化样本训练价值并优化资源分配对于提高大型语言模型的后训练效率至关重要。"}}
{"id": "2602.03043", "pdf": "https://arxiv.org/pdf/2602.03043", "abs": "https://arxiv.org/abs/2602.03043", "authors": ["Salim Khazem"], "title": "SAFE-KD: Risk-Controlled Early-Exit Distillation for Vision Backbones", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Submitted to IJCNN", "summary": "Early-exit networks reduce inference cost by allowing ``easy'' inputs to stop early, but practical deployment hinges on knowing \\emph{when} early exit is safe. We introduce SAFE-KD, a universal multi-exit wrapper for modern vision backbones that couples hierarchical distillation with \\emph{conformal risk control}. SAFE-KD attaches lightweight exit heads at intermediate depths, distills a strong teacher into all exits via Decoupled Knowledge Distillation (DKD), and enforces deep-to-shallow consistency between exits. At inference, we calibrate per-exit stopping thresholds on a held-out set using conformal risk control (CRC) to guarantee a user-specified \\emph{selective} misclassification risk (among the samples that exit early) under exchangeability. Across multiple datasets and architectures, SAFE-KD yields improved accuracy compute trade-offs, stronger calibration, and robust performance under corruption while providing finite-sample risk guarantees.", "AI": {"tldr": "本文提出了SAFE-KD，一种结合分层蒸馏和符合风险控制的多出口封装器，用于现代视觉骨干网。", "motivation": "通过允许'简单'输入尽早退出来减少推断成本，早期退出网络可以降低推理成本。但在实践中部署关键在于了解何时早期退出是安全的。", "method": "SAFE-KD在中间深度附加轻量级出口头，使用解耦知识蒸馏（DKD）将强大的教师模型蒸馏到所有出口，并保证从深到浅的一致性。通过符合风险控制（CRC），它在校准每个出口停止阈值时确保用户指定的选择性误分类风险。", "result": "SAFE-KD在多个数据集和架构下，提高了准确性与计算量之间的权衡、增强了校准强度，并提供了有限样本风险保证。", "conclusion": "SAFE-KD不仅实现了更好的准确性和效率平衡，还展示了更强的鲁棒性能，在各种环境下的表现都优于传统方法。"}}
{"id": "2602.03039", "pdf": "https://arxiv.org/pdf/2602.03039", "abs": "https://arxiv.org/abs/2602.03039", "authors": ["Geonhui Son", "Jeong Ryong Lee", "Dosik Hwang"], "title": "HP-GAN: Harnessing pretrained networks for GAN improvement with FakeTwins and discriminator consistency", "categories": ["cs.CV"], "comment": "Accepted manuscript. This is the accepted version of the article published in Neural Networks", "summary": "Generative Adversarial Networks (GANs) have made significant progress in enhancing the quality of image synthesis. Recent methods frequently leverage pretrained networks to calculate perceptual losses or utilize pretrained feature spaces. In this paper, we extend the capabilities of pretrained networks by incorporating innovative self-supervised learning techniques and enforcing consistency between discriminators during GAN training. Our proposed method, named HP-GAN, effectively exploits neural network priors through two primary strategies: FakeTwins and discriminator consistency. FakeTwins leverages pretrained networks as encoders to compute a self-supervised loss and applies this through the generated images to train the generator, thereby enabling the generation of more diverse and high quality images. Additionally, we introduce a consistency mechanism between discriminators that evaluate feature maps extracted from Convolutional Neural Network (CNN) and Vision Transformer (ViT) feature networks. Discriminator consistency promotes coherent learning among discriminators and enhances training robustness by aligning their assessments of image quality. Our extensive evaluation across seventeen datasets-including scenarios with large, small, and limited data, and covering a variety of image domains-demonstrates that HP-GAN consistently outperforms current state-of-the-art methods in terms of Fréchet Inception Distance (FID), achieving significant improvements in image diversity and quality. Code is available at: https://github.com/higun2/HP-GAN.", "AI": {"tldr": "HP-GAN利用预训练网络和创新的自监督学习技术，提升生成对抗网络（GAN）图像合成的质量与多样性。", "motivation": "当前GAN方法多采用预训练网络计算感知损失或使用预训练特征空间。本文旨在通过引入新的自我监督技术和判别器一致性机制进一步提高GAN性能。", "method": "HP-GAN通过FakeTwins策略利用预训练网络作为编码器来计算自监督损失，同时在生成图像中应用该损失以增强生成器的训练效果；此外，还采用判别器一致性机制确保从CNN和ViT特征网络提取的特征图被一致评估。", "result": "在十七个不同数据集上的实验表明，HP-GAN在FID等指标上优于现有最先进的方法，显著提升了图像的质量与多样性。", "conclusion": "通过创新性地结合预训练模型、自监督学习技术和判别器一致性机制，HP-GAN能够在各种条件下生成更高质量的多样化图像。"}}
{"id": "2602.03038", "pdf": "https://arxiv.org/pdf/2602.03038", "abs": "https://arxiv.org/abs/2602.03038", "authors": ["Cassidy Langenfeld", "Claas Beger", "Gloria Geng", "Wasu Top Piriyakulkij", "Keya Hu", "Yewen Pu", "Kevin Ellis"], "title": "Bongards at the Boundary of Perception and Reasoning: Programs or Language?", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 5 figures", "summary": "Vision-Language Models (VLMs) have made great strides in everyday visual tasks, such as captioning a natural image, or answering commonsense questions about such images. But humans possess the puzzling ability to deploy their visual reasoning abilities in radically new situations, a skill rigorously tested by the classic set of visual reasoning challenges known as the Bongard problems. We present a neurosymbolic approach to solving these problems: given a hypothesized solution rule for a Bongard problem, we leverage LLMs to generate parameterized programmatic representations for the rule and perform parameter fitting using Bayesian optimization. We evaluate our method on classifying Bongard problem images given the ground truth rule, as well as on solving the problems from scratch.", "AI": {"tldr": "本文提出了一种神经符号方法来解决邦加德问题，利用LLM生成规则的程序化表示并进行参数拟合。", "motivation": "人类具备在新情境中运用视觉推理的能力，而现有的视觉语言模型尚不能完全模拟这一技能。本文旨在通过解决邦加德问题来探索和验证模型的这种能力。", "method": "给定一个假设的规则解决方案时，利用LLM生成参数化的程序表示并使用贝叶斯优化进行参数拟合。", "result": "评估方法在根据真实规则分类邦加德问题图像以及从头解决问题上的性能表现。", "conclusion": "所提出的方法展示了将神经符号推理应用于复杂视觉推理任务中的潜力，为进一步研究提供了一个有价值的框架。"}}
{"id": "2602.03034", "pdf": "https://arxiv.org/pdf/2602.03034", "abs": "https://arxiv.org/abs/2602.03034", "authors": ["Binbin Yong", "Haoran Pei", "Jun Shen", "Haoran Li", "Qingguo Zhou", "Zhao Su"], "title": "KANFIS A Neuro-Symbolic Framework for Interpretable and Uncertainty-Aware Learning", "categories": ["cs.AI"], "comment": null, "summary": "Adaptive Neuro-Fuzzy Inference System (ANFIS) was designed to combine the learning capabilities of neural network with the reasoning transparency of fuzzy logic. However, conventional ANFIS architectures suffer from structural complexity, where the product-based inference mechanism causes an exponential explosion of rules in high-dimensional spaces. We herein propose the Kolmogorov-Arnold Neuro-Fuzzy Inference System (KANFIS), a compact neuro-symbolic architecture that unifies fuzzy reasoning with additive function decomposition. KANFIS employs an additive aggregation mechanism, under which both model parameters and rule complexity scale linearly with input dimensionality rather than exponentially. Furthermore, KANFIS is compatible with both Type-1 (T1) and Interval Type-2 (IT2) fuzzy logic systems, enabling explicit modeling of uncertainty and ambiguity in fuzzy representations. By using sparse masking mechanisms, KANFIS generates compact and structured rule sets, resulting in an intrinsically interpretable model with clear rule semantics and transparent inference processes. Empirical results demonstrate that KANFIS achieves competitive performance against representative neural and neuro-fuzzy baselines.", "AI": {"tldr": "提出了一种结合神经网络学习能力和模糊逻辑透明推理能力的紧凑型神经符号架构KANFIS。", "motivation": "传统ANFIS体系结构在高维空间中存在规则数量呈指数级增长的问题，导致模型复杂度增加。为了克服这些问题，作者提出了一个能够处理不确定性和歧义性的新型架构KANFIS。", "method": "KANFIS采用加性聚合机制和稀疏掩码机制生成紧凑且结构化的规则集，并支持Type-1和Interval Type-2模糊逻辑系统。", "result": "实验结果表明，KANFIS在性能上可以与代表性的神经网络和神经模糊基线相媲美。", "conclusion": "通过引入加性聚合机制，KANFIS能够生成紧凑的规则集，并支持对不确定性和歧义性的建模。"}}
{"id": "2602.03028", "pdf": "https://arxiv.org/pdf/2602.03028", "abs": "https://arxiv.org/abs/2602.03028", "authors": ["Wenzhang Sun", "Zhenyu Wang", "Zhangchi Hu", "Chunfeng Wang", "Hao Li", "Wei Chen"], "title": "MUSE: A Multi-agent Framework for Unconstrained Story Envisioning via Closed-Loop Cognitive Orchestration", "categories": ["cs.CV"], "comment": null, "summary": "Generating long-form audio-visual stories from a short user prompt remains challenging due to an intent-execution gap, where high-level narrative intent must be preserved across coherent, shot-level multimodal generation over long horizons. Existing approaches typically rely on feed-forward pipelines or prompt-only refinement, which often leads to semantic drift and identity inconsistency as sequences grow longer. We address this challenge by formulating storytelling as a closed-loop constraint enforcement problem and propose MUSE, a multi-agent framework that coordinates generation through an iterative plan-execute-verify-revise loop. MUSE translates narrative intent into explicit, machine-executable controls over identity, spatial composition, and temporal continuity, and applies targeted multimodal feedback to correct violations during generation. To evaluate open-ended storytelling without ground-truth references, we introduce MUSEBench, a reference-free evaluation protocol validated by human judgments. Experiments demonstrate that MUSE substantially improves long-horizon narrative coherence, cross-modal identity consistency, and cinematic quality compared with representative baselines.", "AI": {"tldr": "MUSE是一个多代理框架，用于从简短用户提示生成长形式的视听故事。", "motivation": "现有的方法难以在长时间序列中保持叙事意图的一致性和跨模态身份一致性。", "method": "MUSE通过迭代计划-执行-验证-修订循环协调生成过程，并引入了MUSEBench进行无参考评估。", "result": "实验表明，与代表性的基线相比，MUSE在长篇叙述连贯性、跨模态一致性和电影质量方面有显著提高。", "conclusion": "提出的框架能够有效解决视听故事生成中的意图执行差距问题。"}}
{"id": "2602.03026", "pdf": "https://arxiv.org/pdf/2602.03026", "abs": "https://arxiv.org/abs/2602.03026", "authors": ["Weilin Ruan", "Yuxuan Liang"], "title": "Visual Reasoning over Time Series via Multi-Agent System", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Time series analysis underpins many real-world applications, yet existing time-series-specific methods and pretrained large-model-based approaches remain limited in integrating intuitive visual reasoning and generalizing across tasks with adaptive tool usage. To address these limitations, we propose MAS4TS, a tool-driven multi-agent system for general time series tasks, built upon an Analyzer-Reasoner-Executor paradigm that integrates agent communication, visual reasoning, and latent reconstruction within a unified framework. MAS4TS first performs visual reasoning over time series plots with structured priors using a Vision-Language Model to extract temporal structures, and subsequently reconstructs predictive trajectories in latent space. Three specialized agents coordinate via shared memory and gated communication, while a router selects task-specific tool chains for execution. Extensive experiments on multiple benchmarks demonstrate that MAS4TS achieves state-of-the-art performance across a wide range of time series tasks, while exhibiting strong generalization and efficient inference.", "AI": {"tldr": "提出MAS4TS多智能体系统，用于时间序列任务的视觉推理和预测", "motivation": "现有方法在结合视觉推理及跨任务适应性工具使用方面存在局限性", "method": "基于Analyzer-Reasoner-Executor范式构建多代理系统，通过共享内存和门控通信进行协同工作，并选择特定任务工具链执行", "result": "实验显示MAS4TS在多种时间序列任务上达到最先进的性能，表现强泛化能力及高效推理", "conclusion": "提出并验证了一种新颖的多智能体系统用于增强时间序列分析"}}
{"id": "2602.03025", "pdf": "https://arxiv.org/pdf/2602.03025", "abs": "https://arxiv.org/abs/2602.03025", "authors": ["Haitian Zhong", "Jixiu Zhai", "Lei Song", "Jiang Bian", "Qiang Liu", "Tieniu Tan"], "title": "RC-GRPO: Reward-Conditioned Group Relative Policy Optimization for Multi-Turn Tool Calling Agents", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Multi-turn tool calling is challenging for Large Language Models (LLMs) because rewards are sparse and exploration is expensive. A common recipe, SFT followed by GRPO, can stall when within-group reward variation is low (e.g., more rollouts in a group receive the all 0 or all 1 reward), making the group-normalized advantage uninformative and yielding vanishing updates. To address this problem, we propose RC-GRPO (Reward-Conditioned Group Relative Policy Optimization), which treats exploration as a controllable steering problem via discrete reward tokens. We first fine-tune a Reward-Conditioned Trajectory Policy (RCTP) on mixed-quality trajectories with reward goal special tokens (e.g., <|high_reward|>, <|low_reward|>) injected into the prompts, enabling the model to learn how to generate distinct quality trajectories on demand. Then during RL, we sample diverse reward tokens within each GRPO group and condition rollouts on the sampled token to improve within-group diversity, improving advantage gains. On the Berkeley Function Calling Leaderboard v4 (BFCLv4) multi-turn benchmark, our method yields consistently improved performance than baselines, and the performance on Qwen-2.5-7B-Instruct even surpasses all closed-source API models.", "AI": {"tldr": "论文提出了一种名为RC-GRPO的方法，旨在通过引入奖励条件化的轨迹策略来解决大语言模型在多轮工具调用中的稀疏奖励和昂贵探索问题。", "motivation": "传统方法如SFT跟随GRPO在处理低组内收益变化时会陷入停滞。为了克服这一挑战，论文提出了RC-GRPO以通过离散的奖励令牌控制探索过程，并提高每个GRPO组内的多样性。", "method": "首先，在提示中加入特定的奖励目标特殊标记（如<|high_reward|>、<|low_reward|>）来训练一个奖励条件化的轨迹策略(RCTP)，使模型能够生成不同质量级别的轨迹。然后在强化学习阶段，通过在每个GRPO组内采样多样性的奖励令牌并根据样本令牌执行轨迹调整以增强组内的多样性。", "result": "所提出的方法在伯克利功能调用排行榜v4 (BFCLv4)多轮基准测试中表现出优于基线模型的一致性能，Qwen-2.5-7B-Instruct模型的性能甚至超过了所有封闭源API模型的表现。", "conclusion": "RC-GRPO通过引入奖励条件化的策略解决了传统方法在低组内收益变化情况下的停滞问题，并提高了大语言模型在多轮工具调用任务中的性能。"}}
{"id": "2602.03024", "pdf": "https://arxiv.org/pdf/2602.03024", "abs": "https://arxiv.org/abs/2602.03024", "authors": ["Junchao Lin", "Zenan Ling", "Jingwen Xu", "Robert C. Qiu"], "title": "Consistency Deep Equilibrium Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep Equilibrium Models (DEQs) have emerged as a powerful paradigm in deep learning, offering the ability to model infinite-depth networks with constant memory usage. However, DEQs incur significant inference latency due to the iterative nature of fixed-point solvers. In this work, we introduce the Consistency Deep Equilibrium Model (C-DEQ), a novel framework that leverages consistency distillation to accelerate DEQ inference. We cast the DEQ iterative inference process as evolution along a fixed ODE trajectory toward the equilibrium. Along this trajectory, we train C-DEQs to consistently map intermediate states directly to the fixed point, enabling few-step inference while preserving the performance of the teacher DEQ. At the same time, it facilitates multi-step evaluation to flexibly trade computation for performance gains. Extensive experiments across various domain tasks demonstrate that C-DEQs achieves consistent 2-20$\\times$ accuracy improvements over implicit DEQs under the same few-step inference budget.", "AI": {"tldr": "本文提出了C-DEQ框架，利用一致性蒸馏加速了深度平衡模型的推理过程。", "motivation": "深度平衡模型因迭代求解器导致推断延迟显著。为解决这一问题，提出了一种新的加速方法。", "method": "将DEQ推理过程视为沿固定ODE轨迹向均衡点演化的过程，并训练C-DEQ在该过程中直接映射到均衡点，以实现快速而准确的多步骤评估。", "result": "实验结果表明，在相同推断预算下，C-DEQ比隐式DEQ的准确度提高了2-20倍。", "conclusion": "通过一致性蒸馏加速了深度平衡模型的推理过程，并在多个任务上展示了显著性能提升。"}}
{"id": "2602.03023", "pdf": "https://arxiv.org/pdf/2602.03023", "abs": "https://arxiv.org/abs/2602.03023", "authors": ["Irmak Bukey", "Zhepei Wang", "Chris Donahue", "Nicholas J. Bryan"], "title": "Rethinking Music Captioning with Music Metadata LLMs", "categories": ["cs.SD", "cs.LG"], "comment": "Accepted to ICASSP 2026", "summary": "Music captioning, or the task of generating a natural language description of music, is useful for both music understanding and controllable music generation. Training captioning models, however, typically requires high-quality music caption data which is scarce compared to metadata (e.g., genre, mood, etc.). As a result, it is common to use large language models (LLMs) to synthesize captions from metadata to generate training data for captioning models, though this process imposes a fixed stylization and entangles factual information with natural language style. As a more direct approach, we propose metadata-based captioning. We train a metadata prediction model to infer detailed music metadata from audio and then convert it into expressive captions via pre-trained LLMs at inference time. Compared to a strong end-to-end baseline trained on LLM-generated captions derived from metadata, our method: (1) achieves comparable performance in less training time over end-to-end captioners, (2) offers flexibility to easily change stylization post-training, enabling output captions to be tailored to specific stylistic and quality requirements, and (3) can be prompted with audio and partial metadata to enable powerful metadata imputation or in-filling--a common task for organizing music data.", "AI": {"tldr": "提出了基于元数据的音乐描述生成方法，通过训练模型从音频中推断详细元数据并转换为自然语言描述。", "motivation": "传统音乐描述需要大量高质量的数据，而这些数据稀缺。使用大型语言模型合成描述虽然可行但风格固定且难以调整，因此提出一种新的基于元数据的方法来解决这些问题。", "method": "首先训练一个模型从音频中预测详细元数据，然后利用预训练的大型语言模型在推理时将这些元数据转换为自然语言描述。", "result": "与使用通过元数据生成的大型语言模型描述进行端到端训练的强大基准相比，该方法实现了相似的效果并且训练时间更短，同时提供了风格调整和元数据填充等灵活性。", "conclusion": "基于元数据的方法在音乐描述任务上表现优异，并且具有较高的灵活度和实用性。"}}
{"id": "2602.03022", "pdf": "https://arxiv.org/pdf/2602.03022", "abs": "https://arxiv.org/abs/2602.03022", "authors": ["Jiliang Ni", "Jiachen Pu", "Zhongyi Yang", "Jingfeng Luo", "Conggang Hu"], "title": "STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models", "categories": ["cs.AI"], "comment": "The paper has been accepted to ICLR 2026", "summary": "The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs' capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.", "AI": {"tldr": "本文提出了一种名为STAR的框架，用于将大规模语言模型的能力转移到超小型模型中。", "motivation": "现有方法在功能调用任务中的过拟合、训练不稳定性以及难以整合各种技术等问题亟需解决。", "method": "该论文提出了STAR：一种通过约束知识蒸馏（CKD）和相似性指导的强化学习（Sim-RL）来有效转移大规模语言模型能力的技术框架，从而解决了上述问题。", "result": "实验结果表明，STAR在挑战性的基准测试中表现出色，并且其0.6B版本超越了所有小于1B的公开模型，甚至优于一些更大规模的知名模型。", "conclusion": "STAR为将大规模语言模型的能力转移到超小型模型提供了一个有效的途径，从而推动了强大、可访问和高效的AI代理的发展。"}}
{"id": "2602.03019", "pdf": "https://arxiv.org/pdf/2602.03019", "abs": "https://arxiv.org/abs/2602.03019", "authors": ["Guohao Yang", "Tongle Wu", "Yuanxiong Guo", "Ying Sun", "Yanmin Gong"], "title": "FedKRSO: Communication and Memory Efficient Federated Fine-Tuning of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by INFOCOM 2026", "summary": "Fine-tuning is essential to adapt general-purpose large language models (LLMs) to domain-specific tasks. As a privacy-preserving framework to leverage decentralized data for collaborative model training, Federated Learning (FL) is gaining popularity in LLM fine-tuning, but remains challenging due to the high cost of transmitting full model parameters and computing full gradients on resource-constrained clients. While Parameter-Efficient Fine-Tuning (PEFT) methods are widely used in FL to reduce communication and memory costs, they often sacrifice model performance compared to FFT. This paper proposes FedKRSO (Federated $K$-Seed Random Subspace Optimization), a novel method that enables communication and memory efficient FFT of LLMs in federated settings. In FedKRSO, clients update the model within a shared set of random low-dimension subspaces generated by the server to save memory usage. Furthermore, instead of transmitting full model parameters in each FL round, clients send only the model update accumulators along the subspaces to the server, enabling efficient global model aggregation and dissemination. By using these strategies, FedKRSO can substantially reduce communication and memory overhead while overcoming the performance limitations of PEFT, closely approximating the performance of federated FFT. The convergence properties of FedKRSO are analyzed rigorously under general FL settings. Extensive experiments on the GLUE benchmark across diverse FL scenarios demonstrate that FedKRSO achieves both superior performance and low communication and memory overhead, paving the way towards on federated LLM fine-tuning at the resource-constrained edge.", "AI": {"tldr": "FedKRSO是一种新型方法，旨在通过联邦学习实现大语言模型的高效微调。", "motivation": "传统的联邦学习在处理大规模语言模型时存在通信和内存开销高以及资源受限客户端性能问题。参数效率微调虽能减轻这些问题，但会牺牲模型性能。", "method": "FedKRSO通过共享随机低维子空间生成服务器来更新模型，减少内存使用，并允许客户端仅发送子空间上的模型更新累积量给服务器以实现高效聚合与分发。", "result": "实验表明，FedKRSO在通信和内存开销较低的同时达到了接近联邦微调的性能水平。", "conclusion": "该方法为资源受限环境下的大规模语言模型联邦学习铺平了道路。"}}
{"id": "2602.03017", "pdf": "https://arxiv.org/pdf/2602.03017", "abs": "https://arxiv.org/abs/2602.03017", "authors": ["Samantha Shorey", "Benjamin Mako Hill", "Samuel C. Woolley"], "title": "From Hanging Out to Figuring It Out: Socializing Online as a Pathway to Computational Thinking", "categories": ["cs.CY", "cs.HC"], "comment": "ef:New Media & Society 23 (8): 2327-44", "summary": "Although socializing is a powerful driver of youth engagement online, platforms struggle to leverage engagement to promote learning. We seek to understand this dynamic using a multi-stage analysis of over 14,000 comments on Scratch, an online platform designed to support learning about programming. First, we inductively develop the concept of \"participatory debugging\" -- a practice through which users learn through collaborative technical troubleshooting. Second, we use a content analysis to establish how common the practice is on Scratch. Third, we conduct a qualitative analysis of user activity over time and identify three factors that serve as social antecedents of participatory debugging: (1) sustained community, (2) identifiable problems, and (3) what we call \"topic porousness\" to describe conversations that are able to span multiple topics. We integrate these findings in a theoretical framework that highlights a productive tension between the desire to promote learning and the interest-driven sub-communities that drive user engagement in many new media environments.", "AI": {"tldr": "该论文通过分析Scratch平台上超过14000条评论，探讨了在线社交活动如何促进计算思维。", "motivation": "旨在理解青少年在参与线上社交时的学习动力，并探索平台如何利用这种动力来推广学习。", "method": "采用多阶段分析方法：首先归纳发展出“协作调试”这一概念；接着进行内容分析以确定其在Scratch上的普遍性；最后通过质性分析用户行为随时间的变化，识别了三个促进参与式调试的社会前因因素。", "result": "发现参与者之间通过共同的技术故障排除可以学习计算思维，且这种现象频繁发生于支持兴趣驱动的社区中，并具备能够跨越多个话题交流的特点。", "conclusion": "理论框架突出了在新的媒体环境中推广学习与维持用户兴趣之间的平衡至关重要。"}}
{"id": "2602.03015", "pdf": "https://arxiv.org/pdf/2602.03015", "abs": "https://arxiv.org/abs/2602.03015", "authors": ["Mehmet Kerem Turkcan", "Jhonatan Tavori", "Javad Ghaderi", "Gil Zussman", "Zoran Kostic", "Andrew Smyth"], "title": "A Vision-Based Analysis of Congestion Pricing in New York City", "categories": ["cs.CV"], "comment": null, "summary": "We examine the impact of New York City's congestion pricing program through automated analysis of traffic camera data. Our computer vision pipeline processes footage from over 900 cameras distributed throughout Manhattan and New York, comparing traffic patterns from November 2024 through the program's implementation in January 2025 until January 2026. We establish baseline traffic patterns and identify systematic changes in vehicle density across the monitored region.", "AI": {"tldr": "通过分析交通摄像头数据，评估纽约市拥堵收费计划的影响。", "motivation": "旨在通过计算机视觉技术研究并量化拥堵收费对城市交通状况的实际影响。", "method": "使用计算机视觉管道处理超过900个摄像机的录像，比较实施前后的车辆密度变化。", "result": "建立了基准交通模式，并识别了监测区域内的系统性车辆密度变化。", "conclusion": "通过详细分析得出拥堵收费计划对缓解城市中心地区交通拥堵的有效性和效果。"}}
{"id": "2602.03013", "pdf": "https://arxiv.org/pdf/2602.03013", "abs": "https://arxiv.org/abs/2602.03013", "authors": ["Haipeng Liu", "Yang Wang", "Biao Qian", "Yong Rui", "Meng Wang"], "title": "Thinking inside the Convolution for Image Inpainting: Reconstructing Texture via Structure under Global and Local Side", "categories": ["cs.CV"], "comment": "17 pages, 17 figures", "summary": "Image inpainting has earned substantial progress, owing to the encoder-and-decoder pipeline, which is benefited from the Convolutional Neural Networks (CNNs) with convolutional downsampling to inpaint the masked regions semantically from the known regions within the encoder, coupled with an upsampling process from the decoder for final inpainting output. Recent studies intuitively identify the high-frequency structure and low-frequency texture to be extracted by CNNs from the encoder, and subsequently for a desirable upsampling recovery. However, the existing arts inevitably overlook the information loss for both structure and texture feature maps during the convolutional downsampling process, hence suffer from a non-ideal upsampling output. In this paper, we systematically answer whether and how the structure and texture feature map can mutually help to alleviate the information loss during the convolutional downsampling. Given the structure and texture feature maps, we adopt the statistical normalization and denormalization strategy for the reconstruction guidance during the convolutional downsampling process. The extensive experimental results validate its advantages to the state-of-the-arts over the images from low-to-high resolutions including 256*256 and 512*512, especially holds by substituting all the encoders by ours. Our code is available at https://github.com/htyjers/ConvInpaint-TSGL", "AI": {"tldr": "研究提出了一种新的图像修复方法，通过在卷积下采样过程中利用统计归一化和反归一化策略来重建结构和纹理特征图，以减少信息损失。", "motivation": "现有的图像修复技术在使用编码器-解码器管道时，存在从卷积下采样中丢失结构和纹理信息的问题。作者希望解决这一问题，并通过改进的结构和纹理特征重建方法提高图像修复质量。", "method": "采用了统计归一化和反归一化策略，在卷积下采样过程中提供重建指导，以减少结构和纹理特征图的信息损失。", "result": "实验结果表明，该方法优于现有的最先进的技术。特别是在256*256到512*512分辨率的图像上表现突出。", "conclusion": "通过引入新的归一化策略，可以有效缓解卷积下采样过程中结构和纹理特征图的信息损失问题，从而提高图像修复的质量。"}}
{"id": "2602.03012", "pdf": "https://arxiv.org/pdf/2602.03012", "abs": "https://arxiv.org/abs/2602.03012", "authors": ["Xianzhen Luo", "Jingyuan Zhang", "Shiqi Zhou", "Rain Huang", "Chuan Xiao", "Qingfu Zhu", "Zhiyuan Ma", "Xing Yue", "Yang Yue", "Wencong Zeng", "Wanxiang Che"], "title": "CVE-Factory: Scaling Expert-Level Agentic Tasks for Code Security Vulnerability", "categories": ["cs.CR", "cs.AI"], "comment": "Under Review", "summary": "Evaluating and improving the security capabilities of code agents requires high-quality, executable vulnerability tasks. However, existing works rely on costly, unscalable manual reproduction and suffer from outdated data distributions. To address these, we present CVE-Factory, the first multi-agent framework to achieve expert-level quality in automatically transforming sparse CVE metadata into fully executable agentic tasks. Cross-validation against human expert reproductions shows that CVE-Factory achieves 95\\% solution correctness and 96\\% environment fidelity, confirming its expert-level quality. It is also evaluated on the latest realistic vulnerabilities and achieves a 66.2\\% verified success. This automation enables two downstream contributions. First, we construct LiveCVEBench, a continuously updated benchmark of 190 tasks spanning 14 languages and 153 repositories that captures emerging threats including AI-tooling vulnerabilities. Second, we synthesize over 1,000 executable training environments, the first large-scale scaling of agentic tasks in code security. Fine-tuned Qwen3-32B improves from 5.3\\% to 35.8\\% on LiveCVEBench, surpassing Claude 4.5 Sonnet, with gains generalizing to Terminal Bench (12.5\\% to 31.3\\%). We open-source CVE-Factory, LiveCVEBench, Abacus-cve (fine-tuned model), training dataset, and leaderboard. All resources are available at https://github.com/livecvebench/CVE-Factory .", "AI": {"tldr": "CVE-Factory是一个多代理框架，用于自动将稀疏的漏洞元数据转换为完全可执行的任务。", "motivation": "现有工作依赖于昂贵且不可扩展的手动再生产，并受到过时的数据分布的影响。此研究旨在解决这些问题，提高代码代理的安全能力。", "method": "通过交叉验证与人类专家的再生产结果对比，展示其质量达到专家水平。创建了LiveCVEBench持续更新的基准测试和超过1000个可执行训练环境。", "result": "实现了95％解决方案正确性和96％环境忠实度，并在实际漏洞上取得了66.2％的成功率。模型经过微调后，在LiveCVEBench上的性能从5.3%提升到35.8%，超过Claude4.5Sonnet。", "conclusion": "开发了专家级质量的自动化系统，能够大规模生成代码安全代理任务，并创建持续更新的基准测试和训练环境，促进相关研究发展。"}}
{"id": "2602.03007", "pdf": "https://arxiv.org/pdf/2602.03007", "abs": "https://arxiv.org/abs/2602.03007", "authors": ["Rahul Atul Bhope", "K. R. Jayaram", "Vinod Muthusamy", "Ritesh Kumar", "Vatche Isahagian", "Nalini Venkatasubramanian"], "title": "VOILA: Value-of-Information Guided Fidelity Selection for Cost-Aware Multimodal Question Answering", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite significant costs from retrieving and processing high-fidelity visual inputs, most multimodal vision-language systems operate at fixed fidelity levels. We introduce VOILA, a framework for Value-Of-Information-driven adaptive fidelity selection in Visual Question Answering (VQA) that optimizes what information to retrieve before model execution. Given a query, VOILA uses a two-stage pipeline: a gradient-boosted regressor estimates correctness likelihood at each fidelity from question features alone, then an isotonic calibrator refines these probabilities for reliable decision-making. The system selects the minimum-cost fidelity maximizing expected utility given predicted accuracy and retrieval costs. We evaluate VOILA across three deployment scenarios using five datasets (VQA-v2, GQA, TextVQA, LoCoMo, FloodNet) and six Vision-Language Models (VLMs) with 7B-235B parameters. VOILA consistently achieves 50-60% cost reductions while retaining 90-95% of full-resolution accuracy across diverse query types and model architectures, demonstrating that pre-retrieval fidelity selection is vital to optimize multimodal inference under resource constraints.", "AI": {"tldr": "VOILA框架通过价值信息引导的自适应保真度选择，优化多模态问答系统中的视觉输入获取和处理过程。", "motivation": "大多数多模态视觉语言系统在固定保真度下运行，这导致了高昂的成本。因此，引入一种能够在执行前决定检索何种信息以降低计算成本的方法是必要的。", "method": "VOILA框架采用两阶段管道：首先使用梯度提升回归器基于问题特征估计不同保真度下的正确性概率；然后应用同质化校准来提高决策的可靠性。根据预测准确性和获取成本，系统选择最大化预期效用的最低成本保真度。", "result": "VOILA在多种部署场景下进行了评估，涵盖了五个数据集和六个具有7B至235B参数的不同架构的语言视觉模型，并展示了50-60%的成本节约同时保持90-95%全分辨率准确率。", "conclusion": "预检索保真度选择是优化多模态推断在资源受限情况下的关键策略，VOILA证明了该方法的有效性。"}}
{"id": "2602.03006", "pdf": "https://arxiv.org/pdf/2602.03006", "abs": "https://arxiv.org/abs/2602.03006", "authors": ["Ziyang Yu", "Liang Zhao"], "title": "Distilling LLM Reasoning into Graph of Concept Predictors", "categories": ["cs.AI"], "comment": null, "summary": "Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.", "AI": {"tldr": "本文提出了一种基于概念预测图的推理意识主动蒸馏框架GCP，以提高大语言模型在判别任务中的样本效率和训练稳定性。", "motivation": "部署大型语言模型进行判别工作负载时受到推理延迟、计算成本和API费用的影响。现有的主动蒸馏方法只提取最终标签，忽略中间推理信号，缺乏诊断错误的位置信息。", "method": "GCP框架通过将教师的决策过程建模为有向无环图并镜像为学生中的模块化概念预测器来增强样本效率，并采用图形感知获取策略以提高训练稳定性和效率。", "result": "在八个NLP分类基准测试中，实验表明GCP在有限标注预算下提高了性能，同时提供了更可解释和可控的训练动态。", "conclusion": "GCP框架能够有效提升大语言模型在判别任务中的表现，并提供更好的推理信号诊断能力。"}}
{"id": "2602.03004", "pdf": "https://arxiv.org/pdf/2602.03004", "abs": "https://arxiv.org/abs/2602.03004", "authors": ["Xiangrui Zhang", "Chunyue Song", "Wei Dai", "Zheng Zhang", "Kaihua Gao", "Furong Gao"], "title": "Causal Graph Spatial-Temporal Autoencoder for Reliable and Interpretable Process Monitoring", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "To improve the reliability and interpretability of industrial process monitoring, this article proposes a Causal Graph Spatial-Temporal Autoencoder (CGSTAE). The network architecture of CGSTAE combines two components: a correlation graph structure learning module based on spatial self-attention mechanism (SSAM) and a spatial-temporal encoder-decoder module utilizing graph convolutional long-short term memory (GCLSTM). The SSAM learns correlation graphs by capturing dynamic relationships between variables, while a novel three-step causal graph structure learning algorithm is introduced to derive a causal graph from these correlation graphs. The algorithm leverages a reverse perspective of causal invariance principle to uncover the invariant causal graph from varying correlations. The spatial-temporal encoder-decoder, built with GCLSTM units, reconstructs time-series process data within a sequence-to-sequence framework. The proposed CGSTAE enables effective process monitoring and fault detection through two statistics in the feature space and residual space. Finally, we validate the effectiveness of CGSTAE in process monitoring through the Tennessee Eastman process and a real-world air separation process.", "AI": {"tldr": "提出了一种结合空间自注意力机制和图卷积长短时记忆网络的因果图时空自动编码器，用于工业过程监测。", "motivation": "提高工业过程监控的可靠性和可解释性。", "method": "设计了一个新型的因果图时空自动编码器（CGSTAE），其中包括基于空间自注意力机制的空间相关性学习模块和使用图卷积长短时记忆网络的时空编解码器模块。通过三步法从这些关联图中提取出不变因果关系图，实现有效过程监控。", "result": "在Tennessee Eastman工艺和实际空气分离过程中验证了CGSTAE的有效性。", "conclusion": "所提出的模型能有效地进行工业过程的监测与故障检测。"}}
{"id": "2602.03003", "pdf": "https://arxiv.org/pdf/2602.03003", "abs": "https://arxiv.org/abs/2602.03003", "authors": ["Zhiyu An", "Wan Du"], "title": "Methods and Open Problems in Differentiable Social Choice: Learning Mechanisms, Decisions, and Alignment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Social choice is no longer a peripheral concern of political theory or economics-it has become a foundational component of modern machine learning systems. From auctions and resource allocation to federated learning, participatory governance, and the alignment of large language models, machine learning pipelines increasingly aggregate heterogeneous preferences, incentives, and judgments into collective decisions. In effect, many contemporary machine learning systems already implement social choice mechanisms, often implicitly and without explicit normative scrutiny. This Review surveys differentiable social choice: an emerging paradigm that formulates voting rules, mechanisms, and aggregation procedures as learnable, differentiable models optimized from data. We synthesize work across auctions, voting, budgeting, liquid democracy, decentralized aggregation, and inverse mechanism learning, showing how classical axioms and impossibility results reappear as objectives, constraints, and optimization trade-offs. We conclude by identifying 36 open problems defining a new research agenda at the intersection of machine learning, economics, and democratic theory.", "AI": {"tldr": "本文综述了可微社会选择：一种将投票规则、机制和聚合程序作为从数据中优化的可学习、可微模型的新范式。", "motivation": "随着机器学习系统越来越多地整合异质偏好、激励和判断，社会选择已成为现代机器学习的基础组成部分。然而这些系统往往隐含实施，缺乏规范审查。因此需要一个新研究议程来解决这些问题。", "method": "本文综合了拍卖、投票、预算分配、液态民主、去中心化聚合及逆向机制学习等领域的工作，展示了经典公理和不可能结果如何重新出现在目标、约束和优化权衡中。", "result": "该论文提出了36个开放问题，定义了一个新研究议程，在机器学习、经济学与民主理论的交叉点上进行探索。", "conclusion": "这篇综述揭示了可微社会选择领域的现状，并通过提出一系列有待解决的问题为未来的相关研究指明方向。"}}
{"id": "2602.03002", "pdf": "https://arxiv.org/pdf/2602.03002", "abs": "https://arxiv.org/abs/2602.03002", "authors": ["Yuanhang Zhang", "Younggyo Seo", "Juyue Chen", "Yifu Yuan", "Koushil Sreenath", "Pieter Abbeel", "Carmelo Sferrazza", "Karen Liu", "Rocky Duan", "Guanya Shi"], "title": "RPL: Learning Robust Humanoid Perceptive Locomotion on Challenging Terrains", "categories": ["cs.RO"], "comment": null, "summary": "Humanoid perceptive locomotion has made significant progress and shows great promise, yet achieving robust multi-directional locomotion on complex terrains remains underexplored. To tackle this challenge, we propose RPL, a two-stage training framework that enables multi-directional locomotion on challenging terrains, and remains robust with payloads. RPL first trains terrain-specific expert policies with privileged height map observations to master decoupled locomotion and manipulation skills across different terrains, and then distills them into a transformer policy that leverages multiple depth cameras to cover a wide range of views. During distillation, we introduce two techniques to robustify multi-directional locomotion, depth feature scaling based on velocity commands and random side masking, which are critical for asymmetric depth observations and unseen widths of terrains. For scalable depth distillation, we develop an efficient multi-depth system that ray-casts against both dynamic robot meshes and static terrain meshes in massively parallel environments, achieving a 5-times speedup over the depth rendering pipelines in existing simulators while modeling realistic sensor latency, noise, and dropout. Extensive real-world experiments demonstrate robust multi-directional locomotion with payloads (2kg) across challenging terrains, including 20° slopes, staircases with different step lengths (22 cm, 25 cm, 30 cm), and 25 cm by 25 cm stepping stones separated by 60 cm gaps.", "AI": {"tldr": "RPL框架使机器人在复杂地形上实现多方向稳健行走并携带负载。", "motivation": "现有的人形机器人感知行走在复杂地形上的能力不足，需要一种新的方法来解决这一问题。", "method": "采用两阶段训练框架，首先使用特权高度地图观测训练特定地形的专家策略，然后通过变压器政策提炼这些策略，并引入深度特征缩放和随机侧面掩码以增强多方向行走的鲁棒性。此外，还开发了一种高效的多重深度系统来加速这一过程。", "result": "在真实世界实验中展示了机器人在携带2kg负载的情况下，在斜坡、楼梯和踏步石等复杂地形上稳健地实现多方向行走的能力。", "conclusion": "RPL框架成功解决了人形机器人在复杂地形上的多方向行走问题，为实际应用提供了新的可能。"}}
{"id": "2602.03001", "pdf": "https://arxiv.org/pdf/2602.03001", "abs": "https://arxiv.org/abs/2602.03001", "authors": ["Hiroki Naganuma", "Shagun Gupta", "Youssef Briki", "Ioannis Mitliagkas", "Irina Rish", "Parameswaran Raman", "Hao-Jun Michael Shi"], "title": "Adaptive Batch Sizes Using Non-Euclidean Gradient Noise Scales for Stochastic Sign and Spectral Descent", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 2 figures, 4 tables", "summary": "To maximize hardware utilization, modern machine learning systems typically employ large constant or manually tuned batch size schedules, relying on heuristics that are brittle and costly to tune. Existing adaptive strategies based on gradient noise scale (GNS) offer a principled alternative. However, their assumption of SGD's Euclidean geometry creates a fundamental mismatch with popular optimizers based on generalized norms, such as signSGD / Signum ($\\ell_\\infty$) and stochastic spectral descent (specSGD) / Muon ($\\mathcal{S}_\\infty$). In this work, we derive gradient noise scales for signSGD and specSGD that naturally emerge from the geometry of their respective dual norms. To practically estimate these non-Euclidean metrics, we propose an efficient variance estimation procedure that leverages the local mini-batch gradients on different ranks in distributed data-parallel systems. Our experiments demonstrate that adaptive batch size strategies using non-Euclidean GNS enable us to match the validation loss of constant-batch baselines while reducing training steps by up to 66% for Signum and Muon on a 160 million parameter Llama model.", "AI": {"tldr": "本文提出了基于非欧几里得梯度噪声尺度的自适应批量大小策略，适用于signSGD和specSGD等优化器。", "motivation": "现有的自适应批量大小策略假设的是随机梯度下降（SGD）的欧氏几何特性，这与使用广义范数的流行优化器如signSGD和specSGD存在根本性的不匹配。因此需要一种新的方法来最大化硬件利用率并减少调参成本。", "method": "本文推导出适用于signSGD和specSGD的梯度噪声尺度，并提出了一种在分布式数据平行系统中利用局部小批量梯度进行非欧几里得指标的有效方差估计程序。", "result": "实验表明，采用非欧几里得GNS的自适应批量大小策略可以在减少最多66%训练步骤的同时达到恒定批量基准线的验证损失水平。", "conclusion": "提出的方法能够在不牺牲模型性能的情况下提高硬件利用率并加快训练速度。"}}
{"id": "2602.02995", "pdf": "https://arxiv.org/pdf/2602.02995", "abs": "https://arxiv.org/abs/2602.02995", "authors": ["Sizhe Tang", "Rongqian Chen", "Tian Lan"], "title": "Agent Alpha: Tree Search Unifying Generation, Exploration and Evaluation for Computer-Use Agents", "categories": ["cs.AI"], "comment": null, "summary": "While scaling test-time compute through trajectory-level sampling has significantly improved Graphical User Interface (GUI) agents, the lack of regressive ability prevents the reuse of partial successes and the recovery from early missteps. In this paper, we introduce Agent Alpha, a unified framework that synergizes generation, exploration, and evaluation through step-level Monte Carlo Tree Search (MCTS). It enables active modeling or exploiting structures of the planning space. By integrating alpha-UCT guided search into the interaction loop, Agent Alpha enables deliberate planning, facilitating early pruning of suboptimal branches and efficient prefix reuse. We also employ comparison-driven evaluation to mitigate absolute scoring biases and diversity-constrained expansion to maintain a compact, informative search space. Regret bound of alpha-UCT is analyzed. On the OSWorld benchmark, Agent Alpha achieves a state-of-the-art success rate of $\\sim 77\\%$, significantly outperforming trajectory-level baselines under equivalent compute.", "AI": {"tldr": "介绍了一种统一框架Agent Alpha，通过步级蒙特卡洛树搜索（MCTS）结合生成、探索和评估，显著提升了图形用户界面（GUI）代理的性能。", "motivation": "现有的测试时间计算扩展方法虽然改善了GUI代理的表现，但缺乏回归能力限制了部分成功的再利用以及从早期错误中恢复的能力。引入Agent Alpha旨在克服这些问题，通过整合生成、探索和评估来提高代理的效果。", "method": "Agent Alpha采用alpha-UCT引导搜索与交互循环结合的方式，实现了有意识的计划，并能进行子最优分支的早期剪枝及前缀重用。使用了对比驱动评估减少绝对评分偏差以及多样性约束扩展以保持紧凑且信息丰富的搜索空间。", "result": "在OSWorld基准测试中，Agent Alpha达到了约77%的成功率，显著优于同等计算量下的轨迹级基线方法。", "conclusion": "通过统一框架Agent Alpha的应用展示了其提升GUI代理性能的潜力。"}}
{"id": "2602.02994", "pdf": "https://arxiv.org/pdf/2602.02994", "abs": "https://arxiv.org/abs/2602.02994", "authors": ["Jiaze Li", "Hao Yin", "Haoran Xu", "Boshen Xu", "Wenhui Tan", "Zewen He", "Jianzhong Ju", "Zhenbo Luo", "Jian Luan"], "title": "Video-OPD: Efficient Post-Training of Multimodal Large Language Models for Temporal Video Grounding via On-Policy Distillation", "categories": ["cs.CV"], "comment": null, "summary": "Reinforcement learning has emerged as a principled post-training paradigm for Temporal Video Grounding (TVG) due to its on-policy optimization, yet existing GRPO-based methods remain fundamentally constrained by sparse reward signals and substantial computational overhead. We propose Video-OPD, an efficient post-training framework for TVG inspired by recent advances in on-policy distillation. Video-OPD optimizes trajectories sampled directly from the current policy, thereby preserving alignment between training and inference distributions, while a frontier teacher supplies dense, token-level supervision via a reverse KL divergence objective. This formulation preserves the on-policy property critical for mitigating distributional shift, while converting sparse, episode-level feedback into fine-grained, step-wise learning signals. Building on Video-OPD, we introduce Teacher-Validated Disagreement Focusing (TVDF), a lightweight training curriculum that iteratively prioritizes trajectories that are both teacher-reliable and maximally informative for the student, thereby improving training efficiency. Empirical results demonstrate that Video-OPD consistently outperforms GRPO while achieving substantially faster convergence and lower computational cost, establishing on-policy distillation as an effective alternative to conventional reinforcement learning for TVG.", "AI": {"tldr": "该论文提出了一种名为Video-OPD的高效后训练框架，用于时序视频定位任务。", "motivation": "现有基于GRPO的方法在稀疏奖励信号和计算成本方面存在限制。作者希望通过引入高效的后训练框架来克服这些问题，并提高模型性能。", "method": "通过利用强化学习中的on-policy优化和反向KL散度目标，Video-OPD能够在直接从当前策略采样的轨迹上进行优化，同时提供密集的token级监督，从而将稀疏奖励信号转化为细粒度的学习信号。此外还引入了Teacher-Validated Disagreement Focusing (TVDF)轻量训练课程。", "result": "实验结果表明Video-OPD能够有效提升模型性能并显著降低计算成本，同时实现了更快的收敛速度。", "conclusion": "该论文通过在时序视频定位任务中引入on-policy distillation方法，提供了一种高效且有效的替代传统强化学习的方法。"}}
{"id": "2602.02991", "pdf": "https://arxiv.org/pdf/2602.02991", "abs": "https://arxiv.org/abs/2602.02991", "authors": ["Haijiang Yan", "Jian-Qiao Zhu", "Adam Sanborn"], "title": "Large Language Models Can Take False First Steps at Inference-time Planning", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been shown to acquire sequence-level planning abilities during training, yet their planning behavior exhibited at inference time often appears short-sighted and inconsistent with these capabilities. We propose a Bayesian account for this gap by grounding planning behavior in the evolving generative context: given the subtle differences between natural language and the language internalized by LLMs, accumulated self-generated context drives a planning-shift during inference and thereby creates the appearance of compromised planning behavior. We further validate the proposed model through two controlled experiments: a random-generation task demonstrating constrained planning under human prompts and increasing planning strength as self-generated context accumulates, and a Gaussian-sampling task showing reduced initial bias when conditioning on self-generated sequences. These findings provide a theoretical explanation along with empirical evidence for characterizing how LLMs plan ahead during inference.", "AI": {"tldr": "研究提出了一种解释大型语言模型在推断过程中规划行为变化的贝叶斯方法。", "motivation": "观察到大型语言模型虽然在训练期间获得序列级规划能力，但在推理时表现出短视和不一致的行为，试图通过理论和实验证明这种现象的原因。", "method": "提出一种基于生成上下文演化的贝叶斯模型来解释大型语言模型的规划行为，并通过随机生成任务和高斯采样任务进行实验验证。", "result": "发现随着自我生成的上下文增加，推理时的规划行为变得更加强大；同时，在特定条件下，初始偏见减少。", "conclusion": "研究提供了理论上的解释以及实证证据来描述大型语言模型如何在推断过程中进行前瞻性的规划。"}}
{"id": "2602.02989", "pdf": "https://arxiv.org/pdf/2602.02989", "abs": "https://arxiv.org/abs/2602.02989", "authors": ["Zhanfeng Liao", "Jiajun Zhang", "Hanzhang Tu", "Zhixi Wang", "Yunqi Gao", "Hongwen Zhang", "Yebin Liu"], "title": "SharpTimeGS: Sharp and Stable Dynamic Gaussian Splatting via Lifespan Modulation", "categories": ["cs.CV"], "comment": null, "summary": "Novel view synthesis of dynamic scenes is fundamental to achieving photorealistic 4D reconstruction and immersive visual experiences. Recent progress in Gaussian-based representations has significantly improved real-time rendering quality, yet existing methods still struggle to maintain a balance between long-term static and short-term dynamic regions in both representation and optimization. To address this, we present SharpTimeGS, a lifespan-aware 4D Gaussian framework that achieves temporally adaptive modeling of both static and dynamic regions under a unified representation. Specifically, we introduce a learnable lifespan parameter that reformulates temporal visibility from a Gaussian-shaped decay into a flat-top profile, allowing primitives to remain consistently active over their intended duration and avoiding redundant densification. In addition, the learned lifespan modulates each primitives' motion, reducing drift in long-lived static points while retaining unrestricted motion for short-lived dynamic ones. This effectively decouples motion magnitude from temporal duration, improving long-term stability without compromising dynamic fidelity. Moreover, we design a lifespan-velocity-aware densification strategy that mitigates optimization imbalance between static and dynamic regions by allocating more capacity to regions with pronounced motion while keeping static areas compact and stable. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art performance while supporting real-time rendering up to 4K resolution at 100 FPS on one RTX 4090.", "AI": {"tldr": "本文提出了一种寿命感知的4D高斯框架，通过调整静态和动态区域的时间适应性建模，在统一表示下提高实时渲染质量。", "motivation": "现有的基于高斯的方法在实现长时静态与短时动态区域之间的平衡方面存在困难。为了改善这一问题，本文提出了一种寿命感知的4D高斯框架。", "method": "引入了一个可学习的寿命参数，将时间可见性从高斯衰减重构成扁平顶轮廓，并设计了基于速度和寿命的优化策略。", "result": "实验结果显示该方法在多个基准测试中达到了最先进的性能，并支持实时光线追踪到4K分辨率100FPS。", "conclusion": "通过引入寿命参数，本文成功实现了静态与动态区域之间的平衡建模，在提高长期稳定性的同时保持了动态精度。"}}
{"id": "2602.02988", "pdf": "https://arxiv.org/pdf/2602.02988", "abs": "https://arxiv.org/abs/2602.02988", "authors": ["Jiangyong Yu", "Xiaomeng Han", "Xing Hu", "Chen Xu", "Zhe Jiang", "Dawei Yang"], "title": "NLI:Non-uniform Linear Interpolation Approximation of Nonlinear Operations for Efficient LLMs Inference", "categories": ["cs.LG", "cs.AI"], "comment": "Admitted to ICLR 18pages 5 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of tasks, but their deployment is often constrained by substantial memory footprints and computational costs. While prior work has achieved significant progress in compressing and accelerating linear layers, nonlinear layers-such as SiLU, RMSNorm, and Softmax-still heavily depend on high-precision floating-point operations. In this paper, we propose a calibration-free, dynamic-programming-optimal, and hardware-friendly framework called Non-uniform Linear Interpolation (NLI). NLI is capable of efficiently approximating a variety of nonlinear functions, enabling seamless integration into LLMs and other deep neural networks with almost no loss in accuracy. NLI ingeniously recasts cutpoint selection as a dynamic-programming problem, achieving the globally minimal interpolation error in O(MxN2) time via Bellman's optimality principle. Based on the NLI algorithm, we also design and implement a plug-and-play universal nonlinear computation unit. Hardware experiments demonstrate that the NLI Engine achieves more than 4x improvement in computational efficiency compared to the state-of-the-art designs.", "AI": {"tldr": "该论文提出了一种用于高效近似非线性操作的NLI框架，以减少大型语言模型(LLMs)的内存占用和计算成本。", "motivation": "大型语言模型在多种任务中表现出色，但受限于高昂的内存需求和计算成本。现有的压缩方法主要集中在加速线性层上，而非线性层仍然依赖高精度浮点运算。", "method": "NLI框架通过动态规划算法优化插值节点选择过程，并设计了一种通用非线性计算单元以实现无缝集成到模型中。", "result": "实验表明，与现有最佳方案相比，NLI引擎在计算效率上提高了超过4倍。", "conclusion": "NLI框架提供了一种高效近似非线性操作的方法，能够显著提升大型语言模型的推断性能并减少资源消耗。"}}
{"id": "2602.02983", "pdf": "https://arxiv.org/pdf/2602.02983", "abs": "https://arxiv.org/abs/2602.02983", "authors": ["Hanna M. Dettki", "Charley M. Wu", "Bob Rehder"], "title": "Are LLMs Biased Like Humans? Causal Reasoning as a Function of Prior Knowledge, Irrelevant Information, and Reasoning Budget", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used in domains where causal reasoning matters, yet it remains unclear whether their judgments reflect normative causal computation, human-like shortcuts, or brittle pattern matching. We benchmark 20+ LLMs against a matched human baseline on 11 causal judgment tasks formalized by a collider structure ($C_1 \\!\\rightarrow\\! E\\! \\leftarrow \\!C_2$). We find that a small interpretable model compresses LLMs' causal judgments well and that most LLMs exhibit more rule-like reasoning strategies than humans who seem to account for unmentioned latent factors in their probability judgments. Furthermore, most LLMs do not mirror the characteristic human collider biases of weak explaining away and Markov violations. We probe LLMs' causal judgment robustness under (i) semantic abstraction and (ii) prompt overloading (injecting irrelevant text), and find that chain-of-thought (CoT) increases robustness for many LLMs. Together, this divergence suggests LLMs can complement humans when known biases are undesirable, but their rule-like reasoning may break down when uncertainty is intrinsic -- highlighting the need to characterize LLM reasoning strategies for safe, effective deployment.", "AI": {"tldr": "大型语言模型（LLMs）在因果推理任务中的表现评估。", "motivation": "探讨大型语言模型是否像人类一样存在因果判断偏见，以确定其在需要因果推断的领域内的可靠性。", "method": "通过设置11个具有 collider 结构的任务来对比20多个大型语言模型和人类基线的表现，并测试这些模型在抽象语义及注入无关文本情况下的稳定性。", "result": "发现大部分LLMs采用规则化的推理策略，而人类则考虑未提及的潜在因素；LLMs通常不表现出与人类相同类型的 collider 偏见。使用链式思维（CoT）可以提高许多LLMs在面临不确定性时的表现稳定性和准确性。", "conclusion": "大型语言模型可以在某些情况下补充人类决策，但它们规则化的推理可能无法应对内在的不确定因素，因此需要深入了解其推理策略以实现安全有效的部署。"}}
{"id": "2602.02982", "pdf": "https://arxiv.org/pdf/2602.02982", "abs": "https://arxiv.org/abs/2602.02982", "authors": ["Yilin Ke", "Yun Suen Pai", "Burkhard C. Wuensche", "Angus Donald Campbell", "Mairi Gunn"], "title": "Invisible Users in Digital Health: A Scoping Review of Digital Interventions to Promote Physical Activity Among Culturally and Linguistically Diverse Women", "categories": ["cs.HC"], "comment": null, "summary": "Digital health has strong potential for promoting physical activity (PA), yet interventions often fail to sustain engagement among culturally and linguistically diverse (CALD) women. Prior reviews focus on short-term efficacy or surface-level localisation, while a design-oriented synthesis of deep cultural adaptation and long-term strategies remain limited. This scoping review systematically screened 1968 records, analysed 18 studies and identified a critical design paradox: techno-solutionist systems overlook social and cultural barriers, while social-support features often fail in low-activity social networks. To address this gap, we propose the Culturally Embedded Interaction Framework, integrating five dimensions: culturally-grounded measurement, multi-modal interaction, contextual and temporal adaptability, embedded social weaving, and theory-guided cultural adaptation. The framework advances beyond accessibility-focused approaches by mapping behavioural theory to design mechanisms that support sustained and culturally plural participation. We provide actionable design principles to help HCI researchers and practitioners move from one-size-fits-all models toward adaptive, theory-informed, and culturally sustaining design.", "AI": {"tldr": "本文进行了一项系统性综述，探讨了数字健康干预在促进文化语言多样性女性身体活动方面的局限，并提出了一个融合五种维度的设计框架。", "motivation": "现有的数字健康干预往往忽视文化和语言多样性的社会与文化障碍，难以长期维持参与度。为弥补这一不足，本文旨在通过系统性综述识别设计中的关键问题并提出解决方案。", "method": "文章从1968篇文献中筛选出18项研究进行分析，并提出了一个包括文化定位测量、多模态互动、上下文和时间适应性、嵌入社交编织以及理论指导的文化适应维度的设计框架。", "result": "通过系统综述，发现技术解决方案忽视了社会与文化的障碍，而基于社区支持的功能在低活跃社交网络中表现不佳。提出了一个融合五种设计维度的框架来解决这些问题。", "conclusion": "本文提出的文化嵌入互动框架超越了简单可访问性方法，将行为理论应用到设计机制上以支持长期参与和多样化文化背景下的身体活动推广。"}}
{"id": "2602.02980", "pdf": "https://arxiv.org/pdf/2602.02980", "abs": "https://arxiv.org/abs/2602.02980", "authors": ["Xi Xuan", "Davide Carbone", "Ruchi Pandey", "Wenxin Zhang", "Tomi H. Kinnunen"], "title": "WST-X Series: Wavelet Scattering Transform for Interpretable Speech Deepfake Detection", "categories": ["eess.AS", "cs.CL", "eess.SP"], "comment": "Submitted to IEEE Signal Processing Letters", "summary": "Designing front-ends for speech deepfake detectors primarily focuses on two categories. Hand-crafted filterbank features are transparent but are limited in capturing high-level semantic details, often resulting in performance gaps compared to self-supervised (SSL) features. SSL features, in turn, lack interpretability and may overlook fine-grained spectral anomalies. We propose the WST-X series, a novel family of feature extractors that combines the best of both worlds via the wavelet scattering transform (WST), integrating wavelets with nonlinearities analogous to deep convolutional networks. We investigate 1D and 2D WSTs to extract acoustic details and higher-order structural anomalies, respectively. Experimental results on the recent and challenging Deepfake-Eval-2024 dataset indicate that WST-X outperforms existing front-ends by a wide margin. Our analysis reveals that a small averaging scale ($J$), combined with high-frequency and directional resolutions ($Q, L$), is critical for capturing subtle artifacts. This underscores the value of translation-invariant and deformation-stable features for robust and interpretable speech deepfake detection.", "AI": {"tldr": "本文提出了一种新的特征提取器WST-X系列，结合了手工设计滤波器特性和自监督学习特性，通过小波散射变换来提高语音深度伪造检测的性能。", "motivation": "手工艺特征透明但难以捕捉高层次语义细节；自监督学习特征缺乏可解释性。因此，本文旨在开发一种结合两者优势的方法。", "method": "WST-X系列利用小波散射变换整合了小波与非线性结构，并研究了一维和二维WST来提取声学细节及更高阶结构异常。", "result": "实验结果表明，WST-X在最近的Deepfake-Eval-2024数据集上表现出色，优于现有方法。", "conclusion": "小波散射变换结合了平移不变性和形变稳定性，在捕捉细微特征方面至关重要。这为语音深度伪造检测提供了稳健且可解释的方法。"}}
{"id": "2602.02978", "pdf": "https://arxiv.org/pdf/2602.02978", "abs": "https://arxiv.org/abs/2602.02978", "authors": ["Zuyuan Zhang", "Zeyu Fang", "Tian Lan"], "title": "Structuring Value Representations via Geometric Coherence in Markov Decision Processes", "categories": ["cs.AI"], "comment": null, "summary": "Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \\emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.", "AI": {"tldr": "通过几何一致性的视角改进强化学习中的价值函数估计，提出GCR-RL方法以提升样本效率和稳定性。", "motivation": "利用几何属性来稳定并加速强化学习，通过重新定义价值功能估计为学习期望的偏序集（部分有序集合），从而引入新的算法来提高性能。", "method": "设计了两种新算法：Q-learning及actor-critic，用于有效地实现超偏序集的细化过程，确保从时间差信号中学习到的价值函数具有几何一致性。", "result": "在多个任务上进行了实验验证，GCR-RL方法展示出显著高于基准线的学习效率和稳定性。", "conclusion": "通过引入几何一致性的新视角改进强化学习算法，可以实现更高效的样本利用并稳定性能表现。"}}
{"id": "2602.02977", "pdf": "https://arxiv.org/pdf/2602.02977", "abs": "https://arxiv.org/abs/2602.02977", "authors": ["Byeongju Woo", "Zilin Wang", "Byeonghyun Pak", "Sangwoo Mo", "Stella X. Yu"], "title": "Aligning Forest and Trees in Images and Long Captions for Visually Grounded Understanding", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Preprint", "summary": "Large vision-language models such as CLIP struggle with long captions because they align images and texts as undifferentiated wholes. Fine-grained vision-language understanding requires hierarchical semantics capturing both global context and localized details across visual and textual domains. Yet linguistic hierarchies from syntax or semantics rarely match visual organization, and purely visual hierarchies tend to fragment scenes into appearance-driven parts without semantic focus. We propose CAFT (Cross-domain Alignment of Forests and Trees), a hierarchical image-text representation learning framework that aligns global and local semantics across images and long captions without pixel-level supervision. Coupling a fine-to-coarse visual encoder with a hierarchical text transformer, it uses a hierarchical alignment loss that matches whole images with whole captions while biasing region-sentence correspondences, so that coarse semantics are built from fine-grained evidence rather than from aggregation untethered to part-level grounding. Trained on 30M image-text pairs, CAFT achieves state-of-the-art performance on six long-text retrieval benchmarks and exhibits strong scaling behavior. Experiments show that hierarchical cross-domain alignment enables fine-grained, visually grounded image-text representations to emerge without explicit region-level supervision.", "AI": {"tldr": "该论文提出了CAFT框架，旨在通过层次化的图像文本对齐方法，在没有像素级监督的情况下实现细粒度的视觉引导的图像-文本表示学习。", "motivation": "大型视觉语言模型在处理长描述时难以兼顾全局背景和局部细节。本文提出了一种新的方法来解决这一问题，即通过跨域森林与树木的对齐（CAFT），以捕捉跨越视觉和文本领域的层次化语义。", "method": "该方法结合了细粒度到粗粒度的视觉编码器和分层文本转换器，并使用层次化的对齐损失函数来匹配整幅图像和长描述，同时偏向区域-句子对应关系，使得粗略语义从细粒度证据中构建而非无根溯源。", "result": "CAFT在六个长文检索基准上达到了最先进的性能，并表现出强烈的规模扩展特性。实验表明，层次化的跨域对齐使没有显式区域级监督的细粒度、视觉引导的图像文本表示能够出现。", "conclusion": "本文通过提出CAFT框架，展示了如何有效地解决大型视觉语言模型在处理长描述时遇到的问题，并证明了该方法的有效性和优越性。"}}
{"id": "2602.02975", "pdf": "https://arxiv.org/pdf/2602.02975", "abs": "https://arxiv.org/abs/2602.02975", "authors": ["Mitchell Abrams", "Kaveh Eskandari Miandoab", "Felix Gervits", "Vasanth Sarathy", "Matthias Scheutz"], "title": "Where Norms and References Collide: Evaluating LLMs on Normative Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to the 40th AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Embodied agents, such as robots, will need to interact in situated environments where successful communication often depends on reasoning over social norms: shared expectations that constrain what actions are appropriate in context. A key capability in such settings is norm-based reference resolution (NBRR), where interpreting referential expressions requires inferring implicit normative expectations grounded in physical and social context. Yet it remains unclear whether Large Language Models (LLMs) can support this kind of reasoning. In this work, we introduce SNIC (Situated Norms in Context), a human-validated diagnostic testbed designed to probe how well state-of-the-art LLMs can extract and utilize normative principles relevant to NBRR. SNIC emphasizes physically grounded norms that arise in everyday tasks such as cleaning, tidying, and serving. Across a range of controlled evaluations, we find that even the strongest LLMs struggle to consistently identify and apply social norms, particularly when norms are implicit, underspecified, or in conflict. These findings reveal a blind spot in current LLMs and highlight a key challenge for deploying language-based systems in socially situated, embodied settings.", "AI": {"tldr": "研究探讨了大型语言模型在社会规范推理方面的能力，通过设计SNIC测试来评估这些模型是否能在物理和社会情境中正确应用隐含的社会规范。", "motivation": "由于未来机器人需要在复杂环境中进行有效交流，必须具备基于社会规范的参考解析（NBRR）的能力。然而，目前还不清楚大型语言模型是否能够支持这种推理。", "method": "研究引入了一个名为SNIC的人类验证诊断测试集，以评估最先进的大型语言模型提取和利用与NBRR相关的规范性原则的能力。", "result": "实验结果表明，即使是表现最优秀的大型语言模型，在处理隐含、不明确或冲突的社会规范时也存在困难，难以一致地识别并应用这些社会规范。", "conclusion": "研究揭示了当前大型语言模型在基于情境和社会规范的推理方面的一个盲点，并指出在将语言系统部署于复杂社交环境中的关键挑战。"}}
{"id": "2602.02974", "pdf": "https://arxiv.org/pdf/2602.02974", "abs": "https://arxiv.org/abs/2602.02974", "authors": ["Seok-Young Kim", "Dooyoung Kim", "Woojin Cho", "Hail Song", "Suji Kang", "Woontack Woo"], "title": "SceneLinker: Compositional 3D Scene Generation via Semantic Scene Graph from RGB Sequences", "categories": ["cs.CV"], "comment": "Accepted as an IEEE TVCG paper at IEEE VR 2026 (journal track)", "summary": "We introduce SceneLinker, a novel framework that generates compositional 3D scenes via semantic scene graph from RGB sequences. To adaptively experience Mixed Reality (MR) content based on each user's space, it is essential to generate a 3D scene that reflects the real-world layout by compactly capturing the semantic cues of the surroundings. Prior works struggled to fully capture the contextual relationship between objects or mainly focused on synthesizing diverse shapes, making it challenging to generate 3D scenes aligned with object arrangements. We address these challenges by designing a graph network with cross-check feature attention for scene graph prediction and constructing a graph-variational autoencoder (graph-VAE), which consists of a joint shape and layout block for 3D scene generation. Experiments on the 3RScan/3DSSG and SG-FRONT datasets demonstrate that our approach outperforms state-of-the-art methods in both quantitative and qualitative evaluations, even in complex indoor environments and under challenging scene graph constraints. Our work enables users to generate consistent 3D spaces from their physical environments via scene graphs, allowing them to create spatial MR content. Project page is https://scenelinker2026.github.io.", "AI": {"tldr": "SceneLinker是一种通过RGB序列生成语义场景图的新型框架，用于组成性3D场景生成。", "motivation": "为了适应每个用户的物理空间并体验混合现实内容，需要从周围环境中捕获紧凑且具有上下文关系的语义线索以生成匹配的真实世界布局。现有方法难以充分捕捉对象间的背景关系或主要关注合成多样化形状，导致生成的3D场景与实际物体排列不一致。", "method": "设计了一种带有交叉验证特征注意机制的图网络进行场景图预测，并构建了一个由联合形状和布局块组成的图变分自编码器（graph-VAE）以实现3D场景生成。", "result": "在3RScan/3DSSG和SG-FRONT数据集上的实验表明，该方法在定量和定性评估中均优于现有技术，在复杂室内环境和具有挑战性的场景图约束下表现出色。", "conclusion": "通过使用场景图生成一致的3D空间，用户可以从物理环境中创建混合现实内容。"}}
{"id": "2602.02973", "pdf": "https://arxiv.org/pdf/2602.02973", "abs": "https://arxiv.org/abs/2602.02973", "authors": ["Leaf Jiang", "Matthew Holzel", "Bernhard Kaplan", "Hsiou-Yuan Liu", "Sabyasachi Paul", "Karen Rankin", "Piotr Swierczynski"], "title": "Fisheye Stereo Vision: Depth and Range Error", "categories": ["cs.CV"], "comment": null, "summary": "This study derives analytical expressions for the depth and range error of fisheye stereo vision systems as a function of object distance, specifically accounting for accuracy at large angles.", "AI": {"tldr": "本文推导了鱼眼立体视觉系统深度和范围误差的解析表达式，特别是在大角度情况下的准确性。", "motivation": "为了提高鱼眼立体视觉系统的准确性和理解其在不同距离上的性能表现，研究者们需要精确地分析深度和范围误差。", "method": "通过数学建模和技术推导，得到了鱼眼立体视觉系统中物体距离与深度及范围误差之间关系的解析表达式。", "result": "研究表明，在大角度下，鱼眼相机系统的深度和范围误差受对象距离的影响较大，并提供了准确计算这些误差的方法。", "conclusion": "该研究为理解和改进鱼眼立体视觉系统的性能提供了一个重要的理论基础。"}}
{"id": "2602.02969", "pdf": "https://arxiv.org/pdf/2602.02969", "abs": "https://arxiv.org/abs/2602.02969", "authors": ["Ruojing Li", "Chao Xiao", "Qian Yin", "Wei An", "Nuo Chen", "Xinyi Ying", "Miao Li", "Yingqian Wang"], "title": "Dynamic High-frequency Convolution for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small targets are typically tiny and locally salient, which belong to high-frequency components (HFCs) in images. Single-frame infrared small target (SIRST) detection is challenging, since there are many HFCs along with targets, such as bright corners, broken clouds, and other clutters. Current learning-based methods rely on the powerful capabilities of deep networks, but neglect explicit modeling and discriminative representation learning of various HFCs, which is important to distinguish targets from other HFCs. To address the aforementioned issues, we propose a dynamic high-frequency convolution (DHiF) to translate the discriminative modeling process into the generation of a dynamic local filter bank. Especially, DHiF is sensitive to HFCs, owing to the dynamic parameters of its generated filters being symmetrically adjusted within a zero-centered range according to Fourier transformation properties. Combining with standard convolution operations, DHiF can adaptively and dynamically process different HFC regions and capture their distinctive grayscale variation characteristics for discriminative representation learning. DHiF functions as a drop-in replacement for standard convolution and can be used in arbitrary SIRST detection networks without significant decrease in computational efficiency. To validate the effectiveness of our DHiF, we conducted extensive experiments across different SIRST detection networks on real-scene datasets. Compared to other state-of-the-art convolution operations, DHiF exhibits superior detection performance with promising improvement. Codes are available at https://github.com/TinaLRJ/DHiF.", "AI": {"tldr": "该论文提出了一种动态高频率卷积方法，用于提高红外小目标检测的性能。", "motivation": "现有基于深度网络的方法在红外小目标检测中忽视了对不同高频成分（HFCs）的显式建模和区分表示学习，这导致难以区分真实的小目标与其他干扰物。因此，提出了一种新的动态高频率卷积方法来解决这一问题。", "method": "通过动态生成局部滤波器组，将区分性模型化过程转化为对不同高频区域进行自适应处理的方法；该方法可以依据傅里叶变换特性调整其参数以增加对于HFCs的敏感度，并与标准卷积操作结合使用来捕获目标的独特灰度变化特征。", "result": "实验结果表明，DHiF相比于其他最先进的卷积操作，在不同红外小目标检测网络上表现出优越的检测性能和显著的改进。", "conclusion": "通过提出动态高频率卷积方法（DHiF），论文成功地提高了对红外小目标的区分表示学习，并在真实场景数据集上的广泛实验验证了其有效性。"}}
{"id": "2602.02963", "pdf": "https://arxiv.org/pdf/2602.02963", "abs": "https://arxiv.org/abs/2602.02963", "authors": ["OFM Riaz Rahman Aranya", "Kevin Desai"], "title": "TRACE: Temporal Radiology with Anatomical Change Explanation for Grounded X-ray Report Generation", "categories": ["cs.CV"], "comment": null, "summary": "Temporal comparison of chest X-rays is fundamental to clinical radiology, enabling detection of disease progression, treatment response, and new findings. While vision-language models have advanced single-image report generation and visual grounding, no existing method combines these capabilities for temporal change detection. We introduce Temporal Radiology with Anatomical Change Explanation (TRACE), the first model that jointly performs temporal comparison, change classification, and spatial localization. Given a prior and current chest X-ray, TRACE generates natural language descriptions of interval changes (worsened, improved, stable) while grounding each finding with bounding box coordinates. TRACE demonstrates effective spatial localization with over 90% grounding accuracy, establishing a foundation for this challenging new task. Our ablation study uncovers an emergent capability: change detection arises only when temporal comparison and spatial grounding are jointly learned, as neither alone enables meaningful change detection. This finding suggests that grounding provides a spatial attention mechanism essential for temporal reasoning.", "AI": {"tldr": "TRACE模型旨在通过时间比较，病变分类和空间定位，生成胸片报告并解释解剖变化。", "motivation": "现有的视觉-语言模型仅能处理单张图片的报告生成及图像定位，未结合时间对比能力进行病变检测。因此，设计一种能够同时完成时间对比、病变分类和空间定位的新方法是必要的。", "method": "TRACE模型接收前一张与当前胸片作为输入，通过联合学习时间比较和空间定位来实现变化检测，并生成自然语言描述以及对应的边界框坐标。", "result": "实验结果显示，TRACE在空间定位方面达到了超过90%的准确性。此外，消融研究显示了同时学习时间对比和空间定位对于有效检测变化的重要性。", "conclusion": "TRACE模型通过联合学习时间比较和空间定位，在生成胸片报告时能准确描述解剖变化，并提出了解决挑战性任务的新思路。"}}
{"id": "2602.02961", "pdf": "https://arxiv.org/pdf/2602.02961", "abs": "https://arxiv.org/abs/2602.02961", "authors": ["Faye Zhang", "Qianyu Cheng", "Jasmine Wan", "Vishwakarma Singh", "Jinfeng Rao", "Kofi Boakye"], "title": "Generative Engine Optimization: A VLM and Agent Framework for Pinterest Acquisition Growth", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models are fundamentally reshaping content discovery through AI-native search systems such as ChatGPT, Gemini, and Claude. Unlike traditional search engines that match keywords to documents, these systems infer user intent, synthesize multimodal evidence, and generate contextual answers directly on the search page, introducing a paradigm shift from Search Engine Optimization (SEO) to Generative Engine Optimization (GEO). For visual content platforms hosting billions of assets, this poses an acute challenge: individual images lack the semantic depth and authority signals that generative search prioritizes, risking disintermediation as user needs are satisfied in-place without site visits. We present Pinterest GEO, a production-scale framework that pioneers reverse search design: rather than generating generic image captions describing what content is, we fine-tune Vision-Language Models (VLMs) to predict what users would actually search for, augmented this with AI agents that mine real-time internet trends to capture emerging search demand. These VLM-generated queries then drive construction of semantically coherent Collection Pages via multimodal embeddings, creating indexable aggregations optimized for generative retrieval. Finally, we employ hybrid VLM and two-tower ANN architectures to build authority-aware interlinking structures that propagate signals across billions of visual assets. Deployed at scale across billions of images and tens of millions of collections, GEO delivers 20\\% organic traffic growth contributing to multi-million monthly active user (MAU) growth, demonstrating a principled pathway for visual platforms to thrive in the generative search era.", "AI": {"tldr": "Pinterest开发了一种名为GEO的框架，利用视觉语言模型和智能代理来优化内容在生成式搜索引擎中的可发现性。", "motivation": "传统的SEO策略无法满足现代AI原生搜索系统的需求，后者优先考虑语义深度和权威信号。为了适应这一变化并保持平台的相关性和流量增长，Pinterest提出了GEO框架。", "method": "该论文提出了一种基于视觉语言模型（VLM）的方法来预测用户可能的搜索词，并利用智能代理挖掘实时互联网趋势以捕获新兴的搜索需求。通过这种方式构建语义连贯的内容聚合页面，并使用混合VLM和双塔ANN架构建立权威信号传播结构。", "result": "部署该框架后，Pinterest实现了20%的有机流量增长，每月活跃用户（MAU）也显著增加。", "conclusion": "GEO为视觉内容平台在生成式搜索时代提供了成功的实践路径。"}}
{"id": "2602.02960", "pdf": "https://arxiv.org/pdf/2602.02960", "abs": "https://arxiv.org/abs/2602.02960", "authors": ["Quanquan Peng", "Yunfeng Lin", "Yufei Xue", "Jiangmiao Pang", "Weinan Zhang"], "title": "Embodiment-Aware Generalist Specialist Distillation for Unified Humanoid Whole-Body Control", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Humanoid Whole-Body Controllers trained with reinforcement learning (RL) have recently achieved remarkable performance, yet many target a single robot embodiment. Variations in dynamics, degrees of freedom (DoFs), and kinematic topology still hinder a single policy from commanding diverse humanoids. Moreover, obtaining a generalist policy that not only transfers across embodiments but also supports richer behaviors-beyond simple walking to squatting, leaning-remains especially challenging. In this work, we tackle these obstacles by introducing EAGLE, an iterative generalist-specialist distillation framework that produces a single unified policy that controls multiple heterogeneous humanoids without per-robot reward tuning. During each cycle, embodiment-specific specialists are forked from the current generalist, refined on their respective robots, and new skills are distilled back into the generalist by training on the pooled embodiment set. Repeating this loop until performance convergence produces a robust Whole-Body Controller validated on robots such as Unitree H1, G1, and Fourier N1. We conducted experiments on five different robots in simulation and four in real-world settings. Through quantitative evaluations, EAGLE achieves high tracking accuracy and robustness compared to other methods, marking a step toward scalable, fleet-level humanoid control. See more details at https://eagle-wbc.github.io/", "AI": {"tldr": "本文提出了一种名为EAGLE的迭代一般化专家蒸馏框架，该框架能够生成单一的统一策略以控制多种不同的人形机器人。", "motivation": "当前基于强化学习训练的人形全身控制器在特定机器人实体上表现出色，但难以跨多个不同的机器人实体推广。此外，开发一种不仅可以在不同实体之间转移而且支持更丰富行为（如蹲下、倾斜）的通用策略仍然具有挑战性。", "method": "EAGLE框架通过每个周期从当前的一般化控制器中分离出特定于机器人的专家，在各自的机器人上进行训练并将其新技能蒸馏回一般化控制器来实现其目标。此循环重复直到性能收敛。", "result": "在仿真和现实世界的实验中，该方法实现了高跟踪精度和鲁棒性，并且优于其他方法。", "conclusion": "通过EAGLE框架，研究者们朝着可扩展、适用于机器人编队的人形控制迈出了重要一步。"}}
{"id": "2602.02955", "pdf": "https://arxiv.org/pdf/2602.02955", "abs": "https://arxiv.org/abs/2602.02955", "authors": ["David McShannon", "Anthony Mella", "Nicholas Dietrich"], "title": "Synthetic Data Augmentation for Medical Audio Classification: A Preliminary Evaluation", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": "5 pages, 1 figure", "summary": "Medical audio classification remains challenging due to low signal-to-noise ratios, subtle discriminative features, and substantial intra-class variability, often compounded by class imbalance and limited training data. Synthetic data augmentation has been proposed as a potential strategy to mitigate these constraints; however, prior studies report inconsistent methodological approaches and mixed empirical results. In this preliminary study, we explore the impact of synthetic augmentation on respiratory sound classification using a baseline deep convolutional neural network trained on a moderately imbalanced dataset (73%:27%). Three generative augmentation strategies (variational autoencoders, generative adversarial networks, and diffusion models) were assessed under controlled experimental conditions. The baseline model without augmentation achieved an F1-score of 0.645. Across individual augmentation strategies, performance gains were not observed, with several configurations demonstrating neutral or degraded classification performance. Only an ensemble of augmented models yielded a modest improvement in F1-score (0.664). These findings suggest that, for medical audio classification, synthetic augmentation may not consistently enhance performance when applied to a standard CNN classifier. Future work should focus on delineating task-specific data characteristics, model-augmentation compatibility, and evaluation frameworks necessary for synthetic augmentation to be effective in medical audio applications.", "AI": {"tldr": "研究探讨了合成数据增强在医学音频分类中的影响，使用三种生成性增强策略评估了一个基准深度卷积神经网络的表现。", "motivation": "由于低信噪比、细微的判别特征以及显著的类内变异性，加上类别不平衡和有限的数据量，使医学音频分类变得具有挑战。合成数据增强被提出作为缓解这些限制的一种潜在策略；然而，先前的研究报告了不一致的方法论和混合的结果。", "method": "研究评估了一个使用基线深度卷积神经网络的基准模型的表现，在一个轻度不平衡的数据集上进行训练（73%:27%）。测试了三种生成性增强策略（变分自编码器、生成对抗网络和扩散模型），并在控制实验条件下进行。此外，还探讨了合成数据增强对于标准CNN分类器在医学音频应用中的效果。", "result": "基准模型没有使用增广时达到了0.645的F1得分；单独使用的每个增强策略并未观察到性能提升，甚至有些配置表现出了中立或降级的表现。只有合成增广模型的集合展示了小幅提高的F1得分（0.664）。", "conclusion": "研究发现表明，在医学音频分类任务上，合成数据增强可能不会一致地改善标准CNN分类器的表现；未来的研究应侧重于确定特定任务的数据特性、模型与增强之间的兼容性以及评估框架，以使合成增广在医学音频应用中有效。"}}
{"id": "2602.02952", "pdf": "https://arxiv.org/pdf/2602.02952", "abs": "https://arxiv.org/abs/2602.02952", "authors": ["Elias Hossain", "Shubhashis Roy Dipta", "Subash Neupane", "Rajib Rana", "Ravid Shwartz-Ziv", "Ivan Garibay", "Niloofar Yousefi"], "title": "UAT-LITE: Inference-Time Uncertainty-Aware Attention for Pretrained Transformers", "categories": ["cs.AI"], "comment": null, "summary": "Neural NLP models are often miscalibrated, assigning high confidence to incorrect predictions, which undermines selective prediction and high-stakes deployment. Post-hoc calibration methods adjust output probabilities but leave internal computation unchanged, while ensemble and Bayesian approaches improve uncertainty at substantial training or storage cost. We propose UAT-LITE, an inference-time framework that makes self-attention uncertainty-aware using approximate Bayesian inference via Monte Carlo dropout in pretrained transformer classifiers. Token-level epistemic uncertainty is estimated from stochastic forward passes and used to modulate self-attention during contextualization, without modifying pretrained weights or training objectives. We additionally introduce a layerwise variance decomposition to diagnose how predictive uncertainty accumulates across transformer depth. Across the SQuAD 2.0 answerability, MNLI, and SST-2, UAT-LITE reduces Expected Calibration Error by approximately 20% on average relative to a fine-tuned BERT-base baseline while preserving task accuracy, and improves selective prediction and robustness under distribution shift.", "AI": {"tldr": "提出了一种名为UAT-LITE的推理时不确定性感知注意力框架，应用于预训练Transformer分类器。", "motivation": "神经NLP模型往往存在预测不准确的问题，通过后校准方法调整输出概率并不能改变内部计算过程，而集成和贝叶斯方法则会增加显著的成本。因此，开发一种可以在推理阶段加入不确定性的有效方法是必要的。", "method": "UAT-LITE框架采用蒙特卡洛丢弃法进行近似贝叶斯推断，在预训练的Transformer分类器中引入不确定性感知自注意力机制，并通过层间方差分解来诊断预测不确定性如何在Transformer深度上累积。", "result": "该方法在SQuAD2.0、MNLI和SST-2数据集上的预期校准误差比基准BERT-base模型平均降低约20%，同时保持任务准确性，提高选择性预测能力，并且在分布偏移下表现更加稳健。", "conclusion": "UAT-LITE框架证明了可以在不改变预训练权重或训练目标的情况下有效改进推理时的不确定性感知，为神经NLP模型提供了更好的校准和可靠性。"}}
{"id": "2602.02951", "pdf": "https://arxiv.org/pdf/2602.02951", "abs": "https://arxiv.org/abs/2602.02951", "authors": ["Yihong Huang", "Fei Ma", "Yihua Shao", "Jingcai Guo", "Zitong Yu", "Laizhong Cui", "Qi Tian"], "title": "Nüwa: Mending the Spatial Integrity Torn by VLM Token Pruning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Vision token pruning has proven to be an effective acceleration technique for the efficient Vision Language Model (VLM). However, existing pruning methods demonstrate excellent performance preservation in visual question answering (VQA) and suffer substantial degradation on visual grounding (VG) tasks. Our analysis of the VLM's processing pipeline reveals that strategies utilizing global semantic similarity and attention scores lose the global spatial reference frame, which is derived from the interactions of tokens' positional information. Motivated by these findings, we propose $\\text{Nüwa}$, a two-stage token pruning framework that enables efficient feature aggregation while maintaining spatial integrity. In the first stage, after the vision encoder, we apply three operations, namely separation, alignment, and aggregation, which are inspired by swarm intelligence algorithms to retain information-rich global spatial anchors. In the second stage, within the LLM, we perform text-guided pruning to retain task-relevant visual tokens. Extensive experiments demonstrate that $\\text{Nüwa}$ achieves SOTA performance on multiple VQA benchmarks (from 94% to 95%) and yields substantial improvements on visual grounding tasks (from 7% to 47%).", "AI": {"tldr": "本文提出了一种称为Nüwa的两阶段令牌修剪框架，旨在提高视觉语言模型（VLM）在任务中的性能。", "motivation": "现有的修剪方法虽然能够很好地保持视觉问答（VQA）任务的表现力，但在视觉接地（VG）任务中表现较差。通过分析发现现有策略忽略了全局空间参考帧的重要性，导致性能下降。因此提出了Nüwa来保留空间完整性。", "method": "Nüwa由两个阶段组成：第一阶段，在视觉编码器之后使用分离、对齐和聚合操作保留信息丰富的全球空间锚点；第二阶段，在大型语言模型（LLM）中进行文本引导修剪，以保留任务相关的视觉令牌。这些步骤受到群智能算法的启发。", "result": "Nüwa在多个VQA基准测试上达到了SOTA性能，并且在VG任务上的改进显著从7%到47%", "conclusion": "本文提出的Nüwa框架通过保持空间完整性，有效提高了视觉语言模型（VLM）在多种任务中的表现。"}}
{"id": "2602.02944", "pdf": "https://arxiv.org/pdf/2602.02944", "abs": "https://arxiv.org/abs/2602.02944", "authors": ["OFM Riaz Rahman Aranya", "Kevin Desai"], "title": "SRA-Seg: Synthetic to Real Alignment for Semi-Supervised Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Synthetic data, an appealing alternative to extensive expert-annotated data for medical image segmentation, consistently fails to improve segmentation performance despite its visual realism. The reason being that synthetic and real medical images exist in different semantic feature spaces, creating a domain gap that current semi-supervised learning methods cannot bridge. We propose SRA-Seg, a framework explicitly designed to align synthetic and real feature distributions for medical image segmentation. SRA-Seg introduces a similarity-alignment (SA) loss using frozen DINOv2 embeddings to pull synthetic representations toward their nearest real counterparts in semantic space. We employ soft edge blending to create smooth anatomical transitions and continuous labels, eliminating the hard boundaries from traditional copy-paste augmentation. The framework generates pseudo-labels for synthetic images via an EMA teacher model and applies soft-segmentation losses that respect uncertainty in mixed regions. Our experiments demonstrate strong results: using only 10% labeled real data and 90% synthetic unlabeled data, SRA-Seg achieves 89.34% Dice on ACDC and 84.42% on FIVES, significantly outperforming existing semi-supervised methods and matching the performance of methods using real unlabeled data.", "AI": {"tldr": "SRA-Seg框架旨在通过调整合成与真实医疗图像之间的特征分布，提升半监督医学影像分割的性能。", "motivation": "现有方法在使用合成数据进行医学影像分割时效果不佳，原因是合成和真实的图像存在于不同的语义空间中，导致领域差距无法填补。为此开发SRA-Seg框架以解决这一问题。", "method": "利用冻结的DINOv2嵌入引入相似性对齐（SA）损失，并采用软边缘融合技术创建平滑解剖过渡；通过EMA教师模型生成合成图像伪标签并应用考虑不确定性的混合区域软分割损失。", "result": "SRA-Seg在ACDC和FIVES数据集上分别实现了89.34%和84.42%的Dice系数，优于现有的半监督方法，并且接近使用真实未标记数据的方法表现。", "conclusion": "该研究展示了利用合成与真实图像特征分布对齐的有效性，在仅用少量标注的真实数据及大量无标签合成数据的情况下取得了出色的结果。"}}
{"id": "2602.02932", "pdf": "https://arxiv.org/pdf/2602.02932", "abs": "https://arxiv.org/abs/2602.02932", "authors": ["Alireza Amiri-Margavi", "Arshia Gharagozlou", "Amin Gholami Davodi", "Seyed Pouyan Mousavi Davoudi", "Hamidreza Hasani Balyani"], "title": "Equal Access, Unequal Interaction: A Counterfactual Audit of LLM Fairness", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 1 figure", "summary": "Prior work on fairness in large language models (LLMs) has primarily focused on access-level behaviors such as refusals and safety filtering. However, equitable access does not ensure equitable interaction quality once a response is provided. In this paper, we conduct a controlled fairness audit examining how LLMs differ in tone, uncertainty, and linguistic framing across demographic identities after access is granted. Using a counterfactual prompt design, we evaluate GPT-4 and LLaMA-3.1-70B on career advice tasks while varying identity attributes along age, gender, and nationality. We assess access fairness through refusal analysis and measure interaction quality using automated linguistic metrics, including sentiment, politeness, and hedging. Identity-conditioned differences are evaluated using paired statistical tests. Both models exhibit zero refusal rates across all identities, indicating uniform access. Nevertheless, we observe systematic, model-specific disparities in interaction quality: GPT-4 expresses significantly higher hedging toward younger male users, while LLaMA exhibits broader sentiment variation across identity groups. These results show that fairness disparities can persist at the interaction level even when access is equal, motivating evaluation beyond refusal-based audits.", "AI": {"tldr": "本文通过控制的公平性审计，研究了大语言模型在提供响应后，在语气、不确定性等方面的差异。", "motivation": "之前的工作主要关注大型语言模型（LLM）在访问层面的行为如拒绝和安全过滤。然而，平等的访问并不确保一旦提供响应后的交互质量的平等，因此本文旨在评估这种交互的质量差异。", "method": "使用反事实提示设计，作者对GPT-4和LLaMA-3.1-70B进行了控制实验，在职业建议任务中改变年龄、性别和国籍等身份属性。通过拒绝分析来评估访问公平性，并使用自动语言学度量（如情感、礼貌和模棱两可）来测量交互质量。", "result": "两个模型在所有身份上都表现出零拒绝率，表明了统一的访问权利；然而，在交互质量上观察到了系统性的差异：GPT-4对年轻男性用户表达更高的模棱两可程度，而LLaMA的情感变化更广泛地跨越不同群体。", "conclusion": "即使访问公平，互动层面仍可能存在不平等现象，这表明除了基于拒绝的审计外还应进行更多的评估。"}}
{"id": "2602.02929", "pdf": "https://arxiv.org/pdf/2602.02929", "abs": "https://arxiv.org/abs/2602.02929", "authors": ["Asif Tauhid", "Sidahmed Benabderrahmane", "Mohamad Altrabulsi", "Ahamed Foisal", "Talal Rahwan"], "title": "RPG-AE: Neuro-Symbolic Graph Autoencoders with Rare Pattern Mining for Provenance-Based Anomaly Detection", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NE"], "comment": null, "summary": "Advanced Persistent Threats (APTs) are sophisticated, long-term cyberattacks that are difficult to detect because they operate stealthily and often blend into normal system behavior. This paper presents a neuro-symbolic anomaly detection framework that combines a Graph Autoencoder (GAE) with rare pattern mining to identify APT-like activities in system-level provenance data. Our approach first constructs a process behavioral graph using k-Nearest Neighbors based on feature similarity, then learns normal relational structure using a Graph Autoencoder. Anomaly candidates are identified through deviations between observed and reconstructed graph structure. To further improve detection, we integrate an rare pattern mining module that discovers infrequent behavioral co-occurrences and uses them to boost anomaly scores for processes exhibiting rare signatures. We evaluate the proposed method on the DARPA Transparent Computing datasets and show that rare-pattern boosting yields substantial gains in anomaly ranking quality over the baseline GAE. Compared with existing unsupervised approaches on the same benchmark, our single unified model consistently outperforms individual context-based detectors and achieves performance competitive with ensemble aggregation methods that require multiple separate detectors. These results highlight the value of coupling graph-based representation learning with classical pattern mining to improve both effectiveness and interpretability in provenance-based security anomaly detection.", "AI": {"tldr": "提出了一种结合图自动编码器和稀有模式挖掘的神经符号异常检测框架，用于系统级来源数据中的APT活动识别。", "motivation": "为了有效检测高级持续性威胁（APTs）这种复杂的长期网络攻击，在系统行为中寻找隐藏的异常模式是必要的。现有方法难以在不引起误报的情况下区分正常与恶意行为。", "method": "首先通过k-最近邻法基于特征相似性构建过程行为图，然后使用图自动编码器学习正常的关联结构；通过观察到的和重建的图结构之间的偏差识别出异常候选者，并集成稀有模式挖掘模块以发现罕见的行为共现并提升其异常分数。", "result": "在DARPA透明计算数据集上的评估表明，所提方法显著提高了异常排序质量。与现有无监督方法相比，在同一基准测试中，单个统一模型优于单独的上下文基检测器，并且性能可媲美需要多个独立检测器的集成聚合方法。", "conclusion": "结合图表示学习和经典模式挖掘技术可以提高基于来源数据的安全异常检测的有效性和可解释性。"}}
{"id": "2602.02925", "pdf": "https://arxiv.org/pdf/2602.02925", "abs": "https://arxiv.org/abs/2602.02925", "authors": ["Sidahmed Benabderrahmane", "Petko Valtchev", "James Cheney", "Talal Rahwan"], "title": "Refining Decision Boundaries In Anomaly Detection Using Similarity Search Within the Feature Space", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NE"], "comment": null, "summary": "Detecting rare and diverse anomalies in highly imbalanced datasets-such as Advanced Persistent Threats (APTs) in cybersecurity-remains a fundamental challenge for machine learning systems. Active learning offers a promising direction by strategically querying an oracle to minimize labeling effort, yet conventional approaches often fail to exploit the intrinsic geometric structure of the feature space for model refinement. In this paper, we introduce SDA2E, a Sparse Dual Adversarial Attention-based AutoEncoder designed to learn compact and discriminative latent representations from imbalanced, high-dimensional data. We further propose a similarity-guided active learning framework that integrates three novel strategies to refine decision boundaries efficiently: mormal-like expansion, which enriches the training set with points similar to labeled normals to improve reconstruction fidelity; anomaly-like prioritization, which boosts ranking accuracy by focusing on points resembling known anomalies; and a hybrid strategy that combines both for balanced model refinement and ranking. A key component of our framework is a new similarity measure, Normalized Matching 1s (SIM_NM1), tailored for sparse binary embeddings. We evaluate SDA2E extensively across 52 imbalanced datasets, including multiple DARPA Transparent Computing scenarios, and benchmark it against 15 state-of-the-art anomaly detection methods. Results demonstrate that SDA2E consistently achieves superior ranking performance (nDCG up to 1.0 in several cases) while reducing the required labeled data by up to 80% compared to passive training. Statistical tests confirm the significance of these improvements. Our work establishes a robust, efficient, and statistically validated framework for anomaly detection that is particularly suited to cybersecurity applications such as APT detection.", "AI": {"tldr": "本文提出了一种改进的异常检测方法SDA2E，通过稀疏二元对抗注意自动编码器学习紧凑且区分度高的潜在表示，并结合相似性搜索策略优化决策边界。", "motivation": "在高度不平衡的数据集中识别罕见和多样化的异常情况仍然是机器学习系统的一个基本挑战。现有的主动学习方法未能充分探索特征空间的内在几何结构，以改进模型。", "method": "本文提出了一种名为SDA2E的自动编码器，用于从不平衡、高维数据中提取紧凑且区分度高的潜在表示，并结合相似性搜索策略优化决策边界。具体包括：正常样例扩展，异常样例优先级提升，以及一种混合策略。", "result": "实验表明，在多个DARPA透明计算场景下，SDA2E相比其他15种最先进的异常检测方法在nDCG方面有显著改进，并且减少了80%的标注数据需求。", "conclusion": "本文提出了一种新的、高效且统计验证过的异常检测框架，特别适合于网络安全应用如APT检测。"}}
{"id": "2602.02920", "pdf": "https://arxiv.org/pdf/2602.02920", "abs": "https://arxiv.org/abs/2602.02920", "authors": ["Jagan Mohan Reddy Dwarampudi", "Jennifer L Purks", "Joshua Wong", "Renjie Hu", "Tania Banerjee"], "title": "A Reproducible Framework for Bias-Resistant Machine Learning on Small-Sample Neuroimaging Data", "categories": ["cs.LG", "cs.CV", "q-bio.NC", "q-bio.QM"], "comment": "Accepted to ISBI 2026, 5 pages with 1 figure", "summary": "We introduce a reproducible, bias-resistant machine learning framework that integrates domain-informed feature engineering, nested cross-validation, and calibrated decision-threshold optimization for small-sample neuroimaging data. Conventional cross-validation frameworks that reuse the same folds for both model selection and performance estimation yield optimistically biased results, limiting reproducibility and generalization. Demonstrated on a high-dimensional structural MRI dataset of deep brain stimulation cognitive outcomes, the framework achieved a nested-CV balanced accuracy of 0.660\\,$\\pm$\\,0.068 using a compact, interpretable subset selected via importance-guided ranking. By combining interpretability and unbiased evaluation, this work provides a generalizable computational blueprint for reliable machine learning in data-limited biomedical domains.", "AI": {"tldr": "提出了一种针对小样本神经影像数据的可重复、抗偏见机器学习框架", "motivation": "现有交叉验证方法在模型选择和性能估计中重用相同的折导致结果乐观偏差，限制了可重复性和泛化能力。为此，该研究旨在开发一种新的框架以提高可靠性", "method": "通过领域知识驱动特征工程、嵌套交叉验证以及校准决策阈值优化来构建框架，并使用重要性引导排名选择紧凑且解释性强的子集", "result": "在高维结构MRI数据集中实现了0.660±0.068的平衡准确率，证明了该方法的有效性和通用性", "conclusion": "为数据受限的生物医学领域提供了可靠的机器学习计算蓝图"}}
{"id": "2602.02919", "pdf": "https://arxiv.org/pdf/2602.02919", "abs": "https://arxiv.org/abs/2602.02919", "authors": ["Jiachen Jiang", "Tianyu Ding", "Zhihui Zhu"], "title": "DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "LLM-driven evolutionary systems have shown promise for automated science discovery, yet existing approaches such as AlphaEvolve rely on full-code histories that are context-inefficient and potentially provide weak evolutionary guidance. In this work, we first formalize the evolutionary agents as a general Expectation-Maximization framework, where the language model samples candidate programs (E-step) and the system updates the control context based on evaluation feedback (M-step). Under this view, constructing context via full-code snapshots constitutes a suboptimal M-step, as redundant implement details dilutes core algorithmic ideas, making it difficult to provide clear inspirations for evolution. To address this, we propose DeltaEvolve, a momentum-driven evolutionary framework that replaces full-code history with structured semantic delta capturing how and why modifications between successive nodes affect performance. As programs are often decomposable, semantic delta usually contains many effective components which are transferable and more informative to drive improvement. By organizing semantic delta through multi-level database and progressive disclosure mechanism, input tokens are further reduced. Empirical evaluations on tasks across diverse scientific domains show that our framework can discover better solution with less token consumption over full-code-based evolutionary agents.", "AI": {"tldr": "提出DeltaEvolve框架，通过结构化语义增量驱动进化过程，改进科学发现效率。", "motivation": "现有方法如AlphaEvolve使用全代码历史记录在演化过程中提供指导，但这种方法上下文利用率低且难以提炼核心算法思想。为了更有效地进行程序优化和性能提升，需要一种新的框架来解决这一问题。", "method": "将进化代理形式化为期望最大化框架，其中语言模型采样候选程序（E步），系统基于评估反馈更新控制上下文（M步）。提出DeltaEvolve框架，利用结构化的语义增量而非全代码历史记录，以更高效地指导演化过程。通过多层次数据库和逐步披露机制组织语义增量，进一步减少输入令牌。", "result": "在跨多个科学领域的任务上进行实证评估表明，该框架能够比基于全代码的进化代理消耗更少的令牌找到更好的解决方案。", "conclusion": "DeltaEvolve作为一种利用结构化语义增量驱动进化的框架，在提高演化效率和减少上下文开销方面表现出显著优势。"}}
{"id": "2602.02918", "pdf": "https://arxiv.org/pdf/2602.02918", "abs": "https://arxiv.org/abs/2602.02918", "authors": ["Jagan Mohan Reddy Dwarampudi", "Joshua Wong", "Hien Van Nguyen", "Tania Banerjee"], "title": "A Multi-scale Linear-time Encoder for Whole-Slide Image Analysis", "categories": ["cs.CV", "cs.AI", "cs.LG", "q-bio.TO"], "comment": "Accepted to ISBI 2026, 4 pages with 2 figures", "summary": "We introduce Multi-scale Adaptive Recurrent Biomedical Linear-time Encoder (MARBLE), the first \\textit{purely Mamba-based} multi-state multiple instance learning (MIL) framework for whole-slide image (WSI) analysis. MARBLE processes multiple magnification levels in parallel and integrates coarse-to-fine reasoning within a linear-time state-space model, efficiently capturing cross-scale dependencies with minimal parameter overhead. WSI analysis remains challenging due to gigapixel resolutions and hierarchical magnifications, while existing MIL methods typically operate at a single scale and transformer-based approaches suffer from quadratic attention costs. By coupling parallel multi-scale processing with linear-time sequence modeling, MARBLE provides a scalable and modular alternative to attention-based architectures. Experiments on five public datasets show improvements of up to \\textbf{6.9\\%} in AUC, \\textbf{20.3\\%} in accuracy, and \\textbf{2.3\\%} in C-index, establishing MARBLE as an efficient and generalizable framework for multi-scale WSI analysis.", "AI": {"tldr": "引入了一种名为MARBLE的多尺度线性时间编码器，用于全片扫描图像分析。", "motivation": "当前WSI分析由于其高分辨率和多层次放大而面临挑战，现有的MIL方法通常只在一个尺度上操作，并且基于变压器的方法存在二次注意力成本问题。为了解决这些问题，引入了MARBLE框架以提高效率和准确性。", "method": "MARBLE是第一个完全基于Mamba的多状态多重实例学习（MIL）框架，它在多个放大级别并行处理图像，结合粗到细推理，并在一个线性时间状态空间模型中有效地捕获跨尺度依赖关系。该方法通过耦合平行多尺度处理和线性时间序列建模来提供一种可扩展的替代方案。", "result": "实验表明，在五个公共数据集上，MARBLE在AUC、准确率和C-index方面分别提高了6.9%、20.3%和2.3%，证明了其效率和泛化能力。", "conclusion": "MARBLE作为一种高效的多尺度WSI分析框架被提出，并通过实验验证了其性能优势。"}}
{"id": "2602.02915", "pdf": "https://arxiv.org/pdf/2602.02915", "abs": "https://arxiv.org/abs/2602.02915", "authors": ["Mihai Stanciu", "Isaac Weaver", "Adam Rose", "James Wade", "Kaden Paxton", "Chris Paul", "Spencer Stowell", "Nathan Usevitch"], "title": "Modular Isoperimetric Soft Robotic Truss for Lunar Applications", "categories": ["cs.RO"], "comment": null, "summary": "We introduce a large-scale robotic system designed as a lightweight, modular, and reconfigurable structure for lunar applications. The system consists of truss-like robotic triangles formed by continuous inflated fabric tubes routed through two robotic roller units and a connecting unit. A newly developed spherical joint enables up to three triangles to connect at a vertex, allowing construction of truss assemblies beyond a single octahedron. When deflated, the triangles compact to approximately the volume of the roller units, achieving a stowed-to-deployed volume ratio of 1:18.3. Upon inflation, the roller units pinch the tubes, locally reducing bending stiffness to form effective joints. Electric motors then translate the roller units along the tube, shifting the pinch point by lengthening one edge while shortening another at the same rate, thereby preserving a constant perimeter (isoperimetric). This shape-changing process requires no additional compressed air, enabling untethered operation after initial inflation. We demonstrate the system as a 12-degree-of-freedom solar array capable of tilting up to 60 degrees and sweeping 360 degrees, and as a 14-degree-of-freedom locomotion device using a step-and-slide gait. This modular, shape-adaptive system addresses key challenges for sustainable lunar operations and future space missions.", "AI": {"tldr": "介绍了一种用于月球应用的轻质、模块化和可重构的大型机器人系统。", "motivation": "旨在解决可持续月球作业及未来航天任务中的关键挑战，提出一种适用于太空环境的独特结构解决方案。", "method": "通过连续充气织物管构成三角形框架，并利用电动滚轮单元形成关节，实现模块化组装和形态变化。", "result": "展示了系统作为太阳能阵列和平移装置的应用潜力，具备高自由度的运动能力。", "conclusion": "所提出的模块化、形态适应性结构为可持续月球操作及未来太空任务提供了一种创新方案。"}}
{"id": "2602.02914", "pdf": "https://arxiv.org/pdf/2602.02914", "abs": "https://arxiv.org/abs/2602.02914", "authors": ["Wenqi Guo", "Shan Du"], "title": "FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction", "categories": ["cs.CV"], "comment": null, "summary": "Transformation-based privacy-preserving face recognition (PPFR) aims to verify identities while hiding facial data from attackers and malicious service providers. Existing evaluations mostly treat privacy as resistance to pixel-level reconstruction, measured by PSNR and SSIM. We show that this reconstruction-centric view fails. We present FaceLinkGen, an identity extraction attack that performs linkage/matching and face regeneration directly from protected templates without recovering original pixels. On three recent PPFR systems, FaceLinkGen reaches over 98.5\\% matching accuracy and above 96\\% regeneration success, and still exceeds 92\\% matching and 94\\% regeneration in a near zero knowledge setting. These results expose a structural gap between pixel distortion metrics, which are widely used in PPFR evaluation, and real privacy. We show that visual obfuscation leaves identity information broadly exposed to both external intruders and untrusted service providers.", "AI": {"tldr": "FaceLinkGen方法揭示了隐私保护面部识别系统中的身份信息泄露问题，即使在像素级重建难以实现的情况下仍然可以提取身份。", "motivation": "当前的隐私保护面部识别评估主要关注于通过PSNR和SSIM等像素级别重构指标来衡量隐私性。然而这些标准忽视了真实场景下的隐私威胁——即身份泄漏。本研究旨在揭示这一问题并提出解决方案。", "method": "FaceLinkGen攻击方法直接从受保护的模板中进行身份匹配及面部重建，而不需恢复原始图像像素。实验在三个最新的PPFR系统上进行了验证。", "result": "在三种隐私保护面部识别系统上，FaceLinkGen能够实现超过98.5%的匹配准确率和高于96%的成功面部再生，在近乎零知识的情况下仍然能保持至少92%以上的匹配率及94%以上再生成功率。", "conclusion": "通过展示FaceLinkGen攻击的有效性，研究揭示了像素级失真指标与实际隐私保护之间的差距，并强调了身份信息泄露的风险。"}}
{"id": "2602.02912", "pdf": "https://arxiv.org/pdf/2602.02912", "abs": "https://arxiv.org/abs/2602.02912", "authors": ["Pedro A. Ortega"], "title": "Notes on the Reward Representation of Posterior Updates", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Technical report, 9 pages", "summary": "Many ideas in modern control and reinforcement learning treat decision-making as inference: start from a baseline distribution and update it when a signal arrives. We ask when this can be made literal rather than metaphorical. We study the special case where a KL-regularized soft update is exactly a Bayesian posterior inside a single fixed probabilistic model, so the update variable is a genuine channel through which information is transmitted. In this regime, behavioral change is driven only by evidence carried by that channel: the update must be explainable as an evidence reweighing of the baseline. This yields a sharp identification result: posterior updates determine the relative, context-dependent incentive signal that shifts behavior, but they do not uniquely determine absolute rewards, which remain ambiguous up to context-specific baselines. Requiring one reusable continuation value across different update directions adds a further coherence constraint linking the reward descriptions associated with different conditioning orders.", "AI": {"tldr": "研究在特定情况下，决策更新是否可以被视为贝叶斯后验推断的过程，并探讨这种更新如何影响行为变化。", "motivation": "探索在现代控制和强化学习中，将决策过程视为基于初始分布的推理时，其内在逻辑与数学模型的关系。特别是关注当KL正则化软更新成为单一固定概率模型中的贝叶斯后验时的情况。", "method": "分析在一个固定的概率模型内，如何通过信息通道传递证据来驱动行为变化，并探讨这种情况下相对激励信号的作用。", "result": "发现后验更新可以确定相对的、上下文相关的激励信号，但不能唯一地决定绝对奖励。要求在不同更新方向上的持续值一致，添加了将与不同条件顺序关联的奖励描述链接起来的一致性约束。", "conclusion": "通过研究决策过程中的信息传递机制和行为变化的关系，揭示了后验更新如何影响决策策略，并提出了一种新的理论框架来理解这种联系。"}}
{"id": "2602.02909", "pdf": "https://arxiv.org/pdf/2602.02909", "abs": "https://arxiv.org/abs/2602.02909", "authors": ["Kiran Tomlinson", "Tobias Schnabel", "Adith Swaminathan", "Jennifer Neville"], "title": "Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs", "categories": ["cs.AI", "cs.FL", "cs.LG"], "comment": "28 pages", "summary": "Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $Ω(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.", "AI": {"tldr": "该论文探讨了大型语言模型通过链式思考推理解决任务时所需的最少令牌数。", "motivation": "研究大型语言模型在处理任务时，链式思考推理所需的成本和计算量，识别推理过程中的根本瓶颈。", "method": "扩展有界注意力前缀预言机（BAPO）模型，证明了三个典型BAPO难题的任务所需最低的链式思考令牌数量，并通过实验验证这些理论下限。", "result": "证明了二进制多数、三元匹配和图可达性问题在输入规模为n时需要Ω(n)个推理令牌。实验结果表明，在受限条件下，推理令牌数目限制会导致任务失败，这与理论界限一致。", "conclusion": "论文确定了链式思考推理中的基本瓶颈，并提供了一个分析最优推理长度的原理工具。"}}
{"id": "2602.02908", "pdf": "https://arxiv.org/pdf/2602.02908", "abs": "https://arxiv.org/abs/2602.02908", "authors": ["Binxu Wang", "Jacob Zavatone-Veth", "Cengiz Pehlevan"], "title": "A Random Matrix Theory Perspective on the Consistency of Diffusion Models", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "65 pages; 53 figures", "summary": "Diffusion models trained on different, non-overlapping subsets of a dataset often produce strikingly similar outputs when given the same noise seed. We trace this consistency to a simple linear effect: the shared Gaussian statistics across splits already predict much of the generated images. To formalize this, we develop a random matrix theory (RMT) framework that quantifies how finite datasets shape the expectation and variance of the learned denoiser and sampling map in the linear setting. For expectations, sampling variability acts as a renormalization of the noise level through a self-consistent relation $σ^2 \\mapsto κ(σ^2)$, explaining why limited data overshrink low-variance directions and pull samples toward the dataset mean. For fluctuations, our variance formulas reveal three key factors behind cross-split disagreement: \\textit{anisotropy} across eigenmodes, \\textit{inhomogeneity} across inputs, and overall scaling with dataset size. Extending deterministic-equivalence tools to fractional matrix powers further allows us to analyze entire sampling trajectories. The theory sharply predicts the behavior of linear diffusion models, and we validate its predictions on UNet and DiT architectures in their non-memorization regime, identifying where and how samples deviates across training data split. This provides a principled baseline for reproducibility in diffusion training, linking spectral properties of data to the stability of generative outputs.", "AI": {"tldr": "本文通过随机矩阵理论分析了扩散模型在不同数据子集训练下的输出一致性，并解释了一致性和分歧的原因。", "motivation": "探讨为什么基于相同噪声种子的扩散模型会在不同数据子集上产生相似的结果，从而为生成任务提供可重复性的基础。", "method": "提出了一个随机矩阵理论框架来量化有限数据如何影响学习去噪器和采样映射的期望值和方差，并使用确定性等效工具分析整个采样轨迹。", "result": "理论预测了线性扩散模型的行为，实验验证了这一理论在UNet和DiT架构中的非记忆化阶段的有效性。", "conclusion": "本文通过随机矩阵理论揭示了数据子集间一致性和分歧的机制，并提供了生成任务中样本稳定性的基准。"}}
{"id": "2602.02905", "pdf": "https://arxiv.org/pdf/2602.02905", "abs": "https://arxiv.org/abs/2602.02905", "authors": ["Zhen Wang", "Fan Bai", "Zhongyan Luo", "Jinyan Su", "Kaiser Sun", "Xinle Yu", "Jieyuan Liu", "Kun Zhou", "Claire Cardie", "Mark Dredze", "Eric P. Xing", "Zhiting Hu"], "title": "FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights", "categories": ["cs.AI"], "comment": "30 pages, 4 figures, 10 tables", "summary": "Autonomous agents powered by large language models (LLMs) promise to accelerate scientific discovery end-to-end, but rigorously evaluating their capacity for verifiable discovery remains a central challenge. Existing benchmarks face a trade-off: they either heavily rely on LLM-as-judge evaluations of automatically generated research outputs or optimize convenient yet isolated performance metrics that provide coarse proxies for scientific insight. To address this gap, we introduce FIRE-Bench (Full-cycle Insight Rediscovery Evaluation), a benchmark that evaluates agents through the rediscovery of established findings from recent, high-impact machine learning research. Agents are given only a high-level research question extracted from a published, verified study and must autonomously explore ideas, design experiments, implement code, execute their plans, and derive conclusions supported by empirical evidence. We evaluate a range of state-of-the-art agents with frontier LLMs backbones like gpt-5 on FIRE-Bench. Our results show that full-cycle scientific research remains challenging for current agent systems: even the strongest agents achieve limited rediscovery success (<50 F1), exhibit high variance across runs, and display recurring failure modes in experimental design, execution, and evidence-based reasoning. FIRE-Bench provides a rigorous and diagnostic framework for measuring progress toward reliable agent-driven scientific discovery.", "AI": {"tldr": "介绍了FIRE-Bench，一个用于评估代理在重新发现科学洞见能力的基准。", "motivation": "现有评价标准面临权衡：要么依赖LLM作为裁判来评估自动生成的研究产出，要么优化便于操作但孤立的性能指标。因此，需要一种新的方法来严格评估自主代理的能力。", "method": "通过给定高阶研究问题让代理自主探索想法、设计实验、编写代码并执行计划以重新发现已验证的研究成果进行评价。", "result": "最强的代理在FIRE-Bench上的重新发现成功率低于50%，存在较高的运行间差异和重复性失败模式，特别是在实验设计、执行和基于证据推理方面。", "conclusion": "FIRE-Bench提供了评估自主代理驱动科学发现可靠性的严格框架。"}}
{"id": "2602.02903", "pdf": "https://arxiv.org/pdf/2602.02903", "abs": "https://arxiv.org/abs/2602.02903", "authors": ["Haoran Su", "Yandong Sun", "Hanxiao Deng"], "title": "Spatiotemporal Decision Transformer for Traffic Coordination", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "Traffic signal control is a critical challenge in urban transportation, requiring coordination among multiple intersections to optimize network-wide traffic flow. While reinforcement learning has shown promise for adaptive signal control, existing methods struggle with multi-agent coordination and sample efficiency. We introduce MADT (Multi-Agent Decision Transformer), a novel approach that reformulates multi-agent traffic signal control as a sequence modeling problem. MADT extends the Decision Transformer paradigm to multi-agent settings by incorporating: (1) a graph attention mechanism for modeling spatial dependencies between intersections, (2) a|temporal transformer encoder for capturing traffic dynamics, and (3) return-to-go conditioning for target performance specification. Our approach enables offline learning from historical traffic data, with architecture design that facilitates potential online fine-tuning. Experiments on synthetic grid networks and real-world traffic scenarios demonstrate that MADT achieves state-of-the-art performance, reducing average travel time by 5-6% compared to the strongest baseline while exhibiting superior coordination among adjacent intersections.", "AI": {"tldr": "该论文提出了一种新的多代理决策变压器（MADT）方法，用于解决交通信号控制问题，通过序列建模提高网络范围内交通流的优化。", "motivation": "当前的强化学习方法在处理多代理协调和样本效率方面存在困难。为了更好地解决这个问题，提出了MADT以改进现有技术。", "method": "该方法采用图注意力机制来建模交叉口之间的空间依赖性、时间变压器编码器捕捉交通动态，并使用返回到目标条件指定性能指标。这种方法可以利用历史交通数据进行离线学习并支持潜在的在线微调。", "result": "在合成网格网络和现实世界场景中的实验表明，MADT相比最强基线减少了5-6%的平均行程时间，并展示了相邻交叉口之间的更优协调能力。", "conclusion": "通过使用序列建模方法，该论文成功改进了交通信号控制性能，在多个测试环境中均表现出色。"}}
{"id": "2602.02902", "pdf": "https://arxiv.org/pdf/2602.02902", "abs": "https://arxiv.org/abs/2602.02902", "authors": ["Hongju Pae"], "title": "Minimal Computational Preconditions for Subjective Perspective in Artificial Agents", "categories": ["cs.AI"], "comment": null, "summary": "This study operationalizes subjective perspective in artificial agents by grounding it in a minimal, phenomenologically motivated internal structure. The perspective is implemented as a slowly evolving global latent state that modulates fast policy dynamics without being directly optimized for behavioral consequences. In a reward-free environment with regime shifts, this latent structure exhibits direction-dependent hysteresis, while policy-level behavior remains comparatively reactive. I argue that such hysteresis constitutes a measurable signature of perspective-like subjectivity in machine systems.", "AI": {"tldr": "本文通过设计一种最小的、基于现象学动机的内部结构，在人工代理中实现主观视角。", "motivation": "研究旨在理解并实现机器系统中的主观性，特别是人工代理如何拥有类似主体性的感知。", "method": "利用缓慢演化的全局潜在状态来调节快速策略动态而不直接优化行为后果。在奖励自由环境中引入阶段转换来测试这一结构是否表现出方向依赖的滞后现象。", "result": "实验结果显示，在没有外部奖励的情况下，该内部结构表现出方向相关的滞后效应，而政策层面的行为保持相对反应性。", "conclusion": "研究认为这种滞后效应是机器系统中类似主体性的可测量标志。"}}
{"id": "2602.02900", "pdf": "https://arxiv.org/pdf/2602.02900", "abs": "https://arxiv.org/abs/2602.02900", "authors": ["Zeyu Fang", "Zuyuan Zhang", "Mahdi Imani", "Tian Lan"], "title": "Manifold-Constrained Energy-Based Transition Models for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model-based offline reinforcement learning is brittle under distribution shift: policy improvement drives rollouts into state--action regions weakly supported by the dataset, where compounding model error yields severe value overestimation. We propose Manifold-Constrained Energy-based Transition Models (MC-ETM), which train conditional energy-based transition models using a manifold projection--diffusion negative sampler. MC-ETM learns a latent manifold of next states and generates near-manifold hard negatives by perturbing latent codes and running Langevin dynamics in latent space with the learned conditional energy, sharpening the energy landscape around the dataset support and improving sensitivity to subtle out-of-distribution deviations. For policy optimization, the learned energy provides a single reliability signal: rollouts are truncated when the minimum energy over sampled next states exceeds a threshold, and Bellman backups are stabilized via pessimistic penalties based on Q-value-level dispersion across energy-guided samples. We formalize MC-ETM through a hybrid pessimistic MDP formulation and derive a conservative performance bound separating in-support evaluation error from truncation risk. Empirically, MC-ETM improves multi-step dynamics fidelity and yields higher normalized returns on standard offline control benchmarks, particularly under irregular dynamics and sparse data coverage.", "AI": {"tldr": "本文提出了基于流形约束的能量转换模型以增强离线强化学习中的策略优化。", "motivation": "当前的基于模型的离线强化学习方法在数据分布变化时表现脆弱，模型误差积累会导致价值估计严重偏差。", "method": "通过流形投影和扩散负样本生成器训练条件能量基转移模型，并引入一个可靠性信号来限制策略探索范围和稳定贝尔曼备份过程。", "result": "实验表明，MC-ETM提高了多步骤动力学的精度并在标准离线控制基准中获得更高的归一化回报。", "conclusion": "本文提出的方法有效地减少了价值估计误差并改进了模型预测性能，特别是在非均匀动态和稀疏数据覆盖的情况下。"}}
{"id": "2602.02898", "pdf": "https://arxiv.org/pdf/2602.02898", "abs": "https://arxiv.org/abs/2602.02898", "authors": ["Marco Gutierrez", "Xinyi Leng", "Hannah Cyberey", "Jonathan Richard Schwarz", "Ahmed Alaa", "Thomas Hartvigsen"], "title": "Aligning Language Model Benchmarks with Pairwise Preferences", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language model benchmarks are pervasive and computationally-efficient proxies for real-world performance. However, many recent works find that benchmarks often fail to predict real utility. Towards bridging this gap, we introduce benchmark alignment, where we use limited amounts of information about model performance to automatically update offline benchmarks, aiming to produce new static benchmarks that predict model pairwise preferences in given test settings. We then propose BenchAlign, the first solution to this problem, which learns preference-aligned weight- ings for benchmark questions using the question-level performance of language models alongside ranked pairs of models that could be collected during deployment, producing new benchmarks that rank previously unseen models according to these preferences. Our experiments show that our aligned benchmarks can accurately rank unseen models according to models of human preferences, even across different sizes, while remaining interpretable. Overall, our work provides insights into the limits of aligning benchmarks with practical human preferences, which stands to accelerate model development towards real utility.", "AI": {"tldr": "本文提出了BenchAlign方法，通过使用少量关于模型性能的信息来自动生成更新的离线基准测试，以预测给定测试设置中语言模型之间的偏好关系。", "motivation": "现有的语言模型基准通常不能准确预测实际应用场景中的性能。因此，作者引入了基准对齐的概念，并提出了一种新的解决方案来解决这一问题。", "method": "BenchAlign方法使用语言模型在每个问题上的表现和可以部署期间收集到的模型排名对，学习出与人类偏好一致的问题权重，生成新的预测模型间偏好的静态基准测试。", "result": "实验结果表明，该方法所生成的新基准能够准确地根据人类偏好对未见过的语言模型进行排序，并且具有可解释性。此外，这种方法的效果跨越了不同规模的模型。", "conclusion": "本文的工作为理解将基准与实际人类偏好的对齐限制提供了见解，并有助于加速开发更符合实用需求的语言模型。"}}
{"id": "2602.02895", "pdf": "https://arxiv.org/pdf/2602.02895", "abs": "https://arxiv.org/abs/2602.02895", "authors": ["Gilberto G. Briscoe-Martinez", "Yaashia Gautam", "Rahul Shetty", "Anuj Pasricha", "Marco M. Nicotra", "Alessandro Roncone"], "title": "Moving On, Even When You're Broken: Fail-Active Trajectory Generation via Diffusion Policies Conditioned on Embodiment and Task", "categories": ["cs.RO", "cs.AI"], "comment": "To be published in the 2026 IEEE International Conference on Robotics & Automation", "summary": "Robot failure is detrimental and disruptive, often requiring human intervention to recover. Maintaining safe operation under impairment to achieve task completion, i.e. fail-active operation, is our target. Focusing on actuation failures, we introduce DEFT, a diffusion-based trajectory generator conditioned on the robot's current embodiment and task constraints. DEFT generalizes across failure types, supports constrained and unconstrained motions, and enables task completion under arbitrary failure. We evaluated DEFT in both simulation and real-world scenarios using a 7-DoF robotic arm. In simulation over thousands of joint-failure cases across multiple tasks, DEFT outperformed the baseline by up to 2 times. On failures unseen during training, it continued to outperform the baseline, indicating robust generalization in simulation. Further, we performed real-world evaluations on two multi-step tasks, drawer manipulation and whiteboard erasing. These experiments demonstrated DEFT succeeding on tasks where classical methods failed. Our results show that DEFT achieves fail-active manipulation across arbitrary failure configurations and real-world deployments.", "AI": {"tldr": "DEFT是一种基于扩散的轨迹生成器，能够根据机器人当前的状态和任务约束，在发生故障时继续完成任务。", "motivation": "在机器人操作中，失败往往需要人工干预来恢复。目的是维护安全的操作并在受损条件下完成任务。", "method": "DEFT通过使用扩散策略并条件化于机器人的当前状态和任务约束来生成轨迹。", "result": "DEFT在模拟测试中的表现优于基线方法，特别是在未见过的故障情况下的泛化能力更强。真实世界实验也证明了DEFT的有效性。", "conclusion": "DEFT能够在各种故障条件下实现主动恢复操作，并且在实际部署中表现出色。"}}
{"id": "2602.02894", "pdf": "https://arxiv.org/pdf/2602.02894", "abs": "https://arxiv.org/abs/2602.02894", "authors": ["Daivik Patel", "Shrenik Patel"], "title": "DoubleTake: Contrastive Reasoning for Faithful Decision-Making in Medical Imaging", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Accurate decision making in medical imaging requires reasoning over subtle visual differences between confusable conditions, yet most existing approaches rely on nearest neighbor retrieval that returns redundant evidence and reinforces a single hypothesis. We introduce a contrastive, document-aware reference selection framework that constructs compact evidence sets optimized for discrimination rather than similarity by explicitly balancing visual relevance, embedding diversity, and source-level provenance using ROCO embeddings and metadata. While ROCO provides large-scale image-caption pairs, it does not specify how references should be selected for contrastive reasoning, and naive retrieval frequently yields near-duplicate figures from the same document. To address this gap, we release a reproducible reference selection protocol and curated reference bank that enable a systematic study of contrastive retrieval in medical image reasoning. Building on these contrastive evidence sets, we propose Counterfactual-Contrastive Inference, a confidence-aware reasoning framework that performs structured pairwise visual comparisons and aggregates evidence using margin-based decision rules with faithful abstention. On the MediConfusion benchmark, our approach achieves state-of-the-art performance, improving set-level accuracy by nearly 15% relative to prior methods while reducing confusion and improving individual accuracy.", "AI": {"tldr": "在医学影像中的准确决策需要识别细微的视觉差异，论文提出了一种对比推理框架以提高决策质量。", "motivation": "现有的方法依赖最近邻检索技术，这会返回冗余证据并强化单一假设。因此，作者提出了一个对比、文档感知的参考选择框架来解决这一问题。", "method": "该研究构建了一个紧凑的证据集，并提出了一种基于ROC嵌入和元数据的方法来优化鉴别而非相似性，通过结构化的成对视觉比较聚合证据使用可信拒接策略。", "result": "在MediConfusion基准测试中，所提方法达到了最先进的性能，在集合级别准确性上比先前方法提高了近15%，同时减少了混淆并提升了个体精度。", "conclusion": "对比推理框架能够有效提高医学影像决策的准确性和可靠性。"}}
{"id": "2602.02888", "pdf": "https://arxiv.org/pdf/2602.02888", "abs": "https://arxiv.org/abs/2602.02888", "authors": ["Ahmad Shapiro", "Karan Taneja", "Ashok Goel"], "title": "HALT: Hallucination Assessment via Log-probs as Time series", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucinations remain a major obstacle for large language models (LLMs), especially in safety-critical domains. We present HALT (Hallucination Assessment via Log-probs as Time series), a lightweight hallucination detector that leverages only the top-20 token log-probabilities from LLM generations as a time series. HALT uses a gated recurrent unit model combined with entropy-based features to learn model calibration bias, providing an extremely efficient alternative to large encoders. Unlike white-box approaches, HALT does not require access to hidden states or attention maps, relying only on output log-probabilities. Unlike black-box approaches, it operates on log-probs rather than surface-form text, which enables stronger domain generalization and compatibility with proprietary LLMs without requiring access to internal weights. To benchmark performance, we introduce HUB (Hallucination detection Unified Benchmark), which consolidates prior datasets into ten capabilities covering both reasoning tasks (Algorithmic, Commonsense, Mathematical, Symbolic, Code Generation) and general purpose skills (Chat, Data-to-Text, Question Answering, Summarization, World Knowledge). While being 30x smaller, HALT outperforms Lettuce, a fine-tuned modernBERT-base encoder, achieving a 60x speedup gain on HUB. HALT and HUB together establish an effective framework for hallucination detection across diverse LLM capabilities.", "AI": {"tldr": "HALT是一种轻量级的语言模型幻觉检测器，通过使用生成文本的前20个令牌的日志概率作为时间序列来评估模型的准确性。", "motivation": "大型语言模型在关键安全领域中存在幻觉问题，需要一种高效且通用的方法来进行检测。", "method": "HALT采用门控循环单元与基于熵的功能相结合的方式来学习校准偏差，并使用HUB统一基准进行性能测试。", "result": "尽管比现代BERT-base编码器小30倍，HALT在HUB上超越了Lettuce模型，实现了60倍的速度提升。", "conclusion": "HALT和HUB共同提供了一种有效的框架来检测不同语言模型能力的幻觉问题。"}}
{"id": "2602.02886", "pdf": "https://arxiv.org/pdf/2602.02886", "abs": "https://arxiv.org/abs/2602.02886", "authors": ["Francesco De Santis", "Gabriele Ciravegna", "Giovanni De Felice", "Arianna Casanova", "Francesco Giannini", "Michelangelo Diligenti", "Mateo Espinosa Zarlenga", "Pietro Barbiero", "Johannes Schneider", "Danilo Giordano"], "title": "Mixture of Concept Bottleneck Experts", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept Bottleneck Models (CBMs) promote interpretability by grounding predictions in human-understandable concepts. However, existing CBMs typically fix their task predictor to a single linear or Boolean expression, limiting both predictive accuracy and adaptability to diverse user needs. We propose Mixture of Concept Bottleneck Experts (M-CBEs), a framework that generalizes existing CBMs along two dimensions: the number of experts and the functional form of each expert, exposing an underexplored region of the design space. We investigate this region by instantiating two novel models: Linear M-CBE, which learns a finite set of linear expressions, and Symbolic M-CBE, which leverages symbolic regression to discover expert functions from data under user-specified operator vocabularies. Empirical evaluation demonstrates that varying the mixture size and functional form provides a robust framework for navigating the accuracy-interpretability trade-off, adapting to different user and task needs.", "AI": {"tldr": "提出Mixture of Concept Bottleneck Experts（M-CBEs）框架，以提高预测准确性和适应性", "motivation": "现有Concept Bottleneck Models（CBMs）受限于单一的线性或布尔表达式，限制了其准确性与适用性", "method": "引入两个新模型：Linear M-CBE和Symbolic M-CBE，前者学习有限数量的线性表达式，后者利用符号回归从数据中发现专家函数", "result": "实验证明M-CBEs框架在准确性和可解释性之间提供了一个灵活的选择，并能够根据用户需求调整", "conclusion": "M-CBEs是一个强大的工具，可在准确性与可解释性间找到平衡"}}
{"id": "2602.02881", "pdf": "https://arxiv.org/pdf/2602.02881", "abs": "https://arxiv.org/abs/2602.02881", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "Learning-Infused Formal Reasoning: From Contract Synthesis to Artifact Reuse and Formal Semantics", "categories": ["cs.SE", "cs.AI"], "comment": "18 pages. Accepted at VERIFAI-2026: The Interplay between Artificial Intelligence and Software Verification LASER center, Villebrumier, France, March 8-11, 2026", "summary": "This vision paper articulates a long-term research agenda for formal methods at the intersection with artificial intelligence, outlining multiple conceptual and technical dimensions and reporting on our ongoing work toward realising this agenda. It advances a forward-looking perspective on the next generation of formal methods based on the integration of automated contract synthesis, semantic artifact reuse, and refinement-based theory. We argue that future verification systems must move beyond isolated correctness proofs toward a cumulative, knowledge-driven paradigm in which specifications, contracts, and proofs are continuously synthesised and transferred across systems. To support this shift, we outline a hybrid framework combining large language models with graph-based representations to enable scalable semantic matching and principled reuse of verification artifacts. Learning-based components provide semantic guidance across heterogeneous notations and abstraction levels, while symbolic matching ensures formal soundness. Grounded in compositional reasoning, this vision points toward verification ecosystems that evolve systematically, leveraging past verification efforts to accelerate future assurance.", "AI": {"tldr": "本文提出了一种基于形式方法与人工智能结合的长期研究议程，旨在开发下一代验证系统。", "motivation": "目前的形式方法主要集中在孤立的正确性证明上，缺乏累积性和知识驱动。作者认为未来的验证系统需要能够持续合成和传输规范、合同和证明，并实现跨系统的可重用性。", "method": "该论文提出了一个结合大型语言模型与图表示法的混合框架，以支持大规模语义匹配及原理性的验证成果重用。", "result": "尚未给出具体结果，但描述了这种方法将如何帮助形式方法领域的未来研究和发展方向。", "conclusion": "通过整合学习和符号推理技术，可以构建一个系统化的验证生态系统，有效地利用过去的验证工作来加速未来的保障。"}}
{"id": "2602.02873", "pdf": "https://arxiv.org/pdf/2602.02873", "abs": "https://arxiv.org/abs/2602.02873", "authors": ["Weihang You", "Qingchan Zhu", "David Liu", "Yi Pan", "Geng Yuan", "Hanqi Jiang"], "title": "ViThinker: Active Vision-Language Reasoning via Dynamic Perceptual Querying", "categories": ["cs.CV"], "comment": null, "summary": "Chain-of-Thought (CoT) reasoning excels in language models but struggles in vision-language models due to premature visual-to-text conversion that discards continuous information such as geometry and spatial layout. While recent methods enhance CoT through static enumeration or attention-based selection, they remain passive, i.e., processing pre-computed inputs rather than actively seeking task-relevant details. Inspired by human active perception, we introduce ViThinker, a framework that enables vision-language models to autonomously generate decision (query) tokens triggering the synthesis of expert-aligned visual features on demand. ViThinker internalizes vision-expert capabilities during training, performing generative mental simulation during inference without external tool calls. Through a two-stage curriculum: first distilling frozen experts into model parameters, then learning task-driven querying via sparsity penalties, i.e., ViThinker discovers minimal sufficient perception for each reasoning step. Evaluations across vision-centric benchmarks demonstrate consistent improvements, validating that active query generation outperforms passive approaches in both perceptual grounding and reasoning accuracy.", "AI": {"tldr": "该论文提出了ViThinker框架，通过动态感知查询使视觉语言模型能够自主生成决策令牌，从而在推理过程中主动获取任务相关细节。", "motivation": "现有的链式思考（CoT）方法在处理视觉-语言模型时因过早的视觉到文本转换而丧失连续信息，如几何和空间布局。为解决这一问题并提高模型主动性，该论文提出了ViThinker框架，以实现主动感知查询的能力。", "method": "通过两阶段课程：首先将冻结专家知识提炼入模型参数中，然后学习基于稀疏性惩罚的任务驱动查询策略，使视觉语言模型能够在推理过程中进行有生成性的精神模拟。", "result": "在多个视觉中心基准测试上取得了显著提升，证明了主动查询比被动方法在感知基础和推理准确性方面更具优势。", "conclusion": "ViThinker框架通过动态感知查询实现了视觉语言模型的主动性提高，不仅提升了模型在复杂任务中的表现能力，还为未来研究提供了新的视角。"}}
{"id": "2602.02864", "pdf": "https://arxiv.org/pdf/2602.02864", "abs": "https://arxiv.org/abs/2602.02864", "authors": ["Yi Gu", "Yan Wang", "Yuxiao Chen", "Yurong You", "Wenjie Luo", "Yue Wang", "Wenhao Ding", "Boyi Li", "Heng Yang", "Boris Ivanovic", "Marco Pavone"], "title": "Accelerating Structured Chain-of-Thought in Autonomous Vehicles", "categories": ["cs.RO"], "comment": null, "summary": "Chain-of-Thought (CoT) reasoning enhances the decision-making capabilities of vision-language-action models in autonomous driving, but its autoregressive nature introduces significant inference latency, making it impractical for real-time applications. To address this, we introduce FastDriveCoT, a novel parallel decoding method that accelerates template-structured CoT. Our approach decomposes the reasoning process into a dependency graph of distinct sub-tasks, such as identifying critical objects and summarizing traffic rules, some of which can be generated in parallel. By generating multiple independent reasoning steps concurrently within a single forward pass, we significantly reduce the number of sequential computations. Experiments demonstrate a 3-4$\\times$ speedup in CoT generation and a substantial reduction in end-to-end latency across various model architectures, all while preserving the original downstream task improvements brought by incorporating CoT reasoning.", "AI": {"tldr": "FastDriveCoT是一种加速结构化Chain-of-Thought推理的新方法，用于自动驾驶车辆中。", "motivation": "现有的Chain-of-Thought（CoT）推理在决策过程中具有自回归特性，导致推理延迟高，不适合实时应用。为了提高效率，研究者提出了一个新的并行解码方法。", "method": "通过将推理过程分解为独立子任务的依赖图，并允许某些步骤并发生成，FastDriveCoT能够在单次前向传递中同时完成多个推理步骤，从而大大减少计算量。", "result": "实验结果显示，在保持原有下游任务改进效果的同时，该方法在各种模型架构下显著降低了3-4倍的CoT生成时间和整体延迟。", "conclusion": "FastDriveCoT成功地解决了实时自动驾驶决策中的推理速度瓶颈问题，并为未来研究提供了新的方向。"}}
{"id": "2602.02863", "pdf": "https://arxiv.org/pdf/2602.02863", "abs": "https://arxiv.org/abs/2602.02863", "authors": ["Jinkun Chen", "Fengxiang Cheng", "Sijia Han", "Vlado Keselj"], "title": "\"I May Not Have Articulated Myself Clearly\": Diagnosing Dynamic Instability in LLM Reasoning at Inference Time", "categories": ["cs.AI", "cs.LG"], "comment": "21 pages, 12 figures, 15 tables", "summary": "Reasoning failures in large language models (LLMs) are typically measured only at the end of a generation, yet many failures manifest as a process-level breakdown: the model \"loses the thread\" mid-reasoning. We study whether such breakdowns are detectable from inference-time observables available in standard APIs (token log probabilities), without any training or fine-tuning. We define a simple instability signal that combines consecutive-step distributional shift (JSD) and uncertainty (entropy), summarize each trace by its peak instability strength, and show that this signal reliably predicts failure. Across GSM8K and HotpotQA, instability strength predicts wrong answers with above-chance AUC and yields monotonic bucket-level accuracy decline at scale across model sizes. Crucially, we show that instability is not uniformly harmful: early instability can reflect subsequent stabilization and a correct final answer (\\emph{corrective instability}), whereas late instability is more often followed by failure (\\emph{destructive instability}), even at comparable peak magnitudes, indicating that recoverability depends not only on how strongly the distribution changes but also on when such changes occur relative to the remaining decoding horizon. The method is model-agnostic, training-free, and reproducible, and is presented as a diagnostic lens rather than a corrective or control mechanism.", "AI": {"tldr": "论文通过分析大型语言模型推理过程中的动态不稳定性信号，预测其在生成过程中可能出现的错误。", "motivation": "研究大模型在推理过程中是否可以通过观测指标（如令牌日志概率）来检测出动态失稳现象，而无需任何训练或微调，并探讨这种不稳定性的原因和影响。", "method": "定义了结合连续步骤分布变化（JSD）和不确定性（熵）的简单不稳定性信号。通过峰值不稳定性强度总结每个推理轨迹，并展示该信号可以可靠预测失败的可能性。", "result": "发现不稳定性强度在GSM8K和HotpotQA数据集上准确预测错误答案，且随着模型规模增加而表现出单调递减的趋势。此外，早期不稳定可能反映后续稳定化并得出正确最终结果（纠正性失稳），而晚期不稳定更常导致失败（破坏性失稳）。", "conclusion": "提出的方法是无训练的、可重复性的诊断工具，能够揭示大型语言模型推理过程中的动态不稳定性，并区分其对最终结果的影响。"}}
{"id": "2602.02862", "pdf": "https://arxiv.org/pdf/2602.02862", "abs": "https://arxiv.org/abs/2602.02862", "authors": ["Eric Yang", "Jong Ha Lee", "Jonathan Amar", "Elissa Ye", "Yugang Jia"], "title": "STEER: Inference-Time Risk Control via Constrained Quality-Diversity Search", "categories": ["cs.AI", "cs.LG"], "comment": "20 pages", "summary": "Large Language Models (LLMs) trained for average correctness often exhibit mode collapse, producing narrow decision behaviors on tasks where multiple responses may be reasonable. This limitation is particularly problematic in ordinal decision settings such as clinical triage, where standard alignment removes the ability to trade off specificity and sensitivity (the ROC operating point) based on contextual constraints. We propose STEER (Steerable Tuning via Evolutionary Ensemble Refinement), a training-free framework that reintroduces this tunable control. STEER constructs a population of natural-language personas through an offline, constrained quality-diversity search that promotes behavioral coverage while enforcing minimum safety, reasoning, and stability thresholds. At inference time, STEER exposes a single, interpretable control parameter that maps a user-specified risk percentile to a selected persona, yielding a monotonic adjustment of decision conservativeness. On two clinical triage benchmarks, STEER achieves broader behavioral coverage compared to temperature-based sampling and static persona ensembles. Compared to a representative post-training method, STEER maintains substantially higher accuracy on unambiguous urgent cases while providing comparable control over ambiguous decisions. These results demonstrate STEER as a safety-preserving paradigm for risk control, capable of steering behavior without compromising domain competence.", "AI": {"tldr": "本文提出STEER框架，通过无训练的约束质量多样性搜索，在推理时控制大型语言模型的风险和行为。", "motivation": "大型语言模型在标准对齐后可能失去根据上下文约束调整特定性和敏感性的能力，特别是在临床分诊等序数决策环境中。", "method": "STEER框架通过离线约束质量多样性搜索构建一组具有最小安全、推理和稳定性阈值的自然语言人格，并在推理时暴露一个可控制风险百分位的选择参数。", "result": "与基于温度采样的方法相比，STEER在临床分诊基准上实现了更广泛的行为覆盖率；同时保持了对明确紧急情况的高度准确性和对模棱两可决策的有效控制。", "conclusion": "STEER作为安全保护的范式，在不损害领域能力的情况下提供了风险控制的能力。"}}
{"id": "2602.02858", "pdf": "https://arxiv.org/pdf/2602.02858", "abs": "https://arxiv.org/abs/2602.02858", "authors": ["Tiago Leite", "Maria Conceição", "António Grilo"], "title": "IMAGINE: Intelligent Multi-Agent Godot-based Indoor Networked Exploration", "categories": ["cs.RO", "cs.LG", "cs.MA", "cs.NI", "eess.SY"], "comment": "12 pages, submitted to a journal", "summary": "The exploration of unknown, Global Navigation Satellite System (GNSS) denied environments by an autonomous communication-aware and collaborative group of Unmanned Aerial Vehicles (UAVs) presents significant challenges in coordination, perception, and decentralized decision-making. This paper implements Multi-Agent Reinforcement Learning (MARL) to address these challenges in a 2D indoor environment, using high-fidelity game-engine simulations (Godot) and continuous action spaces. Policy training aims to achieve emergent collaborative behaviours and decision-making under uncertainty using Network-Distributed Partially Observable Markov Decision Processes (ND-POMDPs). Each UAV is equipped with a Light Detection and Ranging (LiDAR) sensor and can share data (sensor measurements and a local occupancy map) with neighbouring agents. Inter-agent communication constraints include limited range, bandwidth and latency. Extensive ablation studies evaluated MARL training paradigms, reward function, communication system, neural network (NN) architecture, memory mechanisms, and POMDP formulations. This work jointly addresses several key limitations in prior research, namely reliance on discrete actions, single-agent or centralized formulations, assumptions of a priori knowledge and permanent connectivity, inability to handle dynamic obstacles, short planning horizons and architectural complexity in Recurrent NNs/Transformers. Results show that the scalable training paradigm, combined with a simplified architecture, enables rapid autonomous exploration of an indoor area. The implementation of Curriculum-Learning (five increasingly complex levels) also enabled faster, more robust training. This combination of high-fidelity simulation, MARL formulation, and computational efficiency establishes a strong foundation for deploying learned cooperative strategies in physical robotic systems.", "AI": {"tldr": "本文提出了一种基于游戏引擎模拟的多代理强化学习方法，用于训练无人机在室内环境中自主探索。", "motivation": "解决未知环境中的协作、感知和分散决策问题，特别是当全球导航卫星系统不可用时的情况。", "method": "使用高保真度的游戏引擎（Godot）进行仿真，并采用连续动作空间。通过网络分发部分可观测马尔可夫决策过程（ND-POMDPs），实现多代理强化学习训练策略以达到协作行为和在不确定情况下的决策制定。", "result": "结果显示，结合课程学习的可扩展训练范式与简化架构能快速完成室内区域的自主探索。这表明该方法能够有效处理动态障碍物并具有较长规划时间范围。", "conclusion": "通过高保真模拟、多代理强化学习形式和计算效率建立了部署在物理机器人系统中的协作策略的良好基础"}}
{"id": "2602.02857", "pdf": "https://arxiv.org/pdf/2602.02857", "abs": "https://arxiv.org/abs/2602.02857", "authors": ["Kevin Alcedo", "Pedro U. Lima", "Rachid Alami"], "title": "Latent Perspective-Taking via a Schrödinger Bridge in Influence-Augmented Local Models", "categories": ["cs.RO"], "comment": "Extended Abstract & Poster, Presented at World Modeling Workshop 2026", "summary": "Operating in environments alongside humans requires robots to make decisions under uncertainty. In addition to exogenous dynamics, they must reason over others' hidden mental-models and mental-states. While Interactive POMDPs and Bayesian Theory of Mind formulations are principled, exact nested-belief inference is intractable, and hand-specified models are brittle in open-world settings. We address both by learning structured mental-models and an estimator of others' mental-states. Building on the Influence-Based Abstraction, we instantiate an Influence-Augmented Local Model to decompose socially-aware robot tasks into local dynamics, social influences, and exogenous factors. We propose (a) a neuro-symbolic world model instantiating a factored, discrete Dynamic Bayesian Network, and (b) a perspective-shift operator modeled as an amortized Schrödinger Bridge over the learned local dynamics that transports factored egocentric beliefs into other-centric beliefs. We show that this architecture enables agents to synthesize socially-aware policies in model-based reinforcement learning, via decision-time mental-state planning (a Schrödinger Bridge in belief space), with preliminary results in a MiniGrid social navigation task.", "AI": {"tldr": "本文通过学习结构化的心理模型和他人的心理状态估计器，解决机器人在与人类交互的环境中进行决策时的心理建模问题。", "motivation": "当前的机器人系统难以处理环境中的不确定性以及他人隐藏的心理模型。传统的方法如互动POMDPs和贝叶斯理论心智模型虽有理论基础，但精确嵌套信念推理是不可行的，而手动指定模型在开放世界中又过于脆弱。", "method": "本文提出了一种基于影响增强局部模型的方法，将社会意识机器人任务分解为局部动态、社会影响和外生因素。该方法利用了一个神经符号世界模型（一个因子化的离散动态贝叶斯网络）以及视角转换操作器（作为学习局部动力学上的薛定谔桥进行的近似化），从而在信念空间中执行决策时刻的心理状态规划。", "result": "通过微型网格社交导航任务，初步证明了该架构可以合成社会意识策略并在基于模型的强化学习中实现。", "conclusion": "本文提出的方法能够使机器人根据他人的心理状态进行更为准确的社会交互，为未来在更复杂的环境和任务中的应用提供了可能。"}}
{"id": "2602.02850", "pdf": "https://arxiv.org/pdf/2602.02850", "abs": "https://arxiv.org/abs/2602.02850", "authors": ["Keqi Chen", "Vinkle Srivastav", "Armine Vardazaryan", "Cindy Rolland", "Didier Mutter", "Nicolas Padoy"], "title": "Self-Supervised Uncalibrated Multi-View Video Anonymization in the Operating Room", "categories": ["cs.CV"], "comment": null, "summary": "Privacy preservation is a prerequisite for using video data in Operating Room (OR) research. Effective anonymization relies on the exhaustive localization of every individual; even a single missed detection necessitates extensive manual correction. However, existing approaches face two critical scalability bottlenecks: (1) they usually require manual annotations of each new clinical site for high accuracy; (2) while multi-camera setups have been widely adopted to address single-view ambiguity, camera calibration is typically required whenever cameras are repositioned. To address these problems, we propose a novel self-supervised multi-view video anonymization framework consisting of whole-body person detection and whole-body pose estimation, without annotation or camera calibration. Our core strategy is to enhance the single-view detector by \"retrieving\" false negatives using temporal and multi-view context, and conducting self-supervised domain adaptation. We first run an off-the-shelf whole-body person detector in each view with a low-score threshold to gather candidate detections. Then, we retrieve the low-score false negatives that exhibit consistency with the high-score detections via tracking and self-supervised uncalibrated multi-view association. These recovered detections serve as pseudo labels to iteratively fine-tune the whole-body detector. Finally, we apply whole-body pose estimation on each detected person, and fine-tune the pose model using its own high-score predictions. Experiments on the 4D-OR dataset of simulated surgeries and our dataset of real surgeries show the effectiveness of our approach achieving over 97% recall. Moreover, we train a real-time whole-body detector using our pseudo labels, achieving comparable performance and highlighting our method's practical applicability. Code is available at https://github.com/CAMMA-public/OR_anonymization.", "AI": {"tldr": "该论文提出了一种无需注释或相机校准的自监督多视图视频匿名化框架，以解决现有方法在处理手术室视频数据时面临的问题。", "motivation": "隐私保护是使用手术室视频数据进行研究的前提。现有的匿名化方法存在两个主要瓶颈：需要手动标注每个新的临床场所才能获得高精度；以及相机重新定位后需要校准的多摄像头设置问题。", "method": "该框架通过单视图检测器和自我监督的领域适应来增强单视图检测器，利用时间上下文和多视角一致性检索低分假阴性。然后使用这些伪标签进行迭代微调，并应用全身姿态估计进一步优化模型。", "result": "实验结果表明，所提出的方法在4D-OR模拟手术数据集和真实手术数据集中达到了超过97%的召回率，展示了该方法的有效性和实际适用性。", "conclusion": "通过无需注释或校准的自监督多视角视频匿名化框架，成功解决了现有技术中遇到的瓶颈问题，为未来手术室视频隐私保护提供了新的解决方案。"}}
{"id": "2602.02849", "pdf": "https://arxiv.org/pdf/2602.02849", "abs": "https://arxiv.org/abs/2602.02849", "authors": ["Xi Yu", "Dmitrii Torbunov", "Soumyajit Mandal", "Yihui Ren"], "title": "AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents", "categories": ["cs.AI"], "comment": null, "summary": "The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Existing Electronic Design Automation (EDA) methods typically frame sizing as static black-box optimization, resulting in inefficient and less robust solutions. Although Large Language Models (LLMs) exhibit strong reasoning abilities, they are not suited for precise numerical optimization in AMS sizing. To address this gap, we propose AutoSizer, a reflective LLM-driven meta-optimization framework that unifies circuit understanding, adaptive search-space construction, and optimization orchestration in a closed loop. It employs a two-loop optimization framework, with an inner loop for circuit sizing and an outer loop that analyzes optimization dynamics and constraints to iteratively refine the search space from simulation feedback. We further introduce AMS-SizingBench, an open benchmark comprising 24 diverse AMS circuits in SKY130 CMOS technology, designed to evaluate adaptive optimization policies under realistic simulator-based constraints. AutoSizer experimentally achieves higher solution quality, faster convergence, and higher success rate across varying circuit difficulties, outperforming both traditional optimization methods and existing LLM-based agents.", "AI": {"tldr": "本文提出了一个基于大语言模型的自动模拟和混合信号电路尺寸设计框架AutoSizer，它通过闭环优化实现了更高效的尺寸调整。", "motivation": "模拟和混合信号集成电路的设计仍然高度依赖专家知识，其中晶体管尺寸选择是一个主要瓶颈。现有的电子设计自动化方法通常将尺寸选择视为静态黑盒优化问题，导致效率低下且不够鲁棒的解决方案。", "method": "AutoSizer提出了一种基于大语言模型的元优化框架，在闭环中统一了电路理解、自适应搜索空间构建和优化协调。", "result": "实验结果表明，AutoSizer在不同难度级别的模拟和混合信号电路尺寸设计任务上，相比传统方法和现有的大语言模型代理，在解的质量、收敛速度和成功率方面均有显著提升。", "conclusion": "基于大型语言模型的元优化框架可以更高效地解决模拟和混合信号集成电路中的晶体管尺寸选择问题。"}}
{"id": "2602.02847", "pdf": "https://arxiv.org/pdf/2602.02847", "abs": "https://arxiv.org/abs/2602.02847", "authors": ["Mingxuan Li", "Junzhe Zhang", "Elias Bareinboim"], "title": "Causal Flow Q-Learning for Robust Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Expressive policies based on flow-matching have been successfully applied in reinforcement learning (RL) more recently due to their ability to model complex action distributions from offline data. These algorithms build on standard policy gradients, which assume that there is no unmeasured confounding in the data. However, this condition does not necessarily hold for pixel-based demonstrations when a mismatch exists between the demonstrator's and the learner's sensory capabilities, leading to implicit confounding biases in offline data. We address the challenge by investigating the problem of confounded observations in offline RL from a causal perspective. We develop a novel causal offline RL objective that optimizes policies' worst-case performance that may arise due to confounding biases. Based on this new objective, we introduce a practical implementation that learns expressive flow-matching policies from confounded demonstrations, employing a deep discriminator to assess the discrepancy between the target policy and the nominal behavioral policy. Experiments across 25 pixel-based tasks demonstrate that our proposed confounding-robust augmentation procedure achieves a success rate 120\\% that of confounding-unaware, state-of-the-art offline RL methods.", "AI": {"tldr": "该论文提出了基于因果关系的流匹配Q-Learning方法，以增强离线强化学习在存在未观测到混杂因素情况下的鲁棒性。", "motivation": "由于演示者和学习者的感知能力可能存在差异，像素级别的演示数据可能会包含潜在的混杂偏见，这影响了标准策略梯度的有效性。因此，该论文旨在通过因果视角解决离线强化学习中的观测混淆问题。", "method": "提出了一种新的基于因果关系的目标函数来优化策略在存在混杂偏差情况下的最差性能，并采用深度判别器评估目标策略与名义行为策略之间的差异来实现流匹配策略的学习。", "result": "实验结果显示，所提出的抗混杂鲁棒增强方法比现有的不考虑混杂因素的离线强化学习方法成功率提高120%。", "conclusion": "该论文通过因果推理的方法解决了像素级别数据中的观测混淆问题，并证明了其在离线强化学习任务上的有效性。"}}
{"id": "2602.02846", "pdf": "https://arxiv.org/pdf/2602.02846", "abs": "https://arxiv.org/abs/2602.02846", "authors": ["Nicolas Perrault", "Qi Heng Ho", "Morteza Lahijanian"], "title": "Kino-PAX$^+$: Near-Optimal Massively Parallel Kinodynamic Sampling-based Motion Planner", "categories": ["cs.RO", "cs.DC"], "comment": "10 pages, 8 figures", "summary": "Sampling-based motion planners (SBMPs) are widely used for robot motion planning with complex kinodynamic constraints in high-dimensional spaces, yet they struggle to achieve \\emph{real-time} performance due to their serial computation design. Recent efforts to parallelize SBMPs have achieved significant speedups in finding feasible solutions; however, they provide no guarantees of optimizing an objective function. We introduce Kino-PAX$^{+}$, a massively parallel kinodynamic SBMP with asymptotic near-optimal guarantees. Kino-PAX$^{+}$ builds a sparse tree of dynamically feasible trajectories by decomposing traditionally serial operations into three massively parallel subroutines. The algorithm focuses computation on the most promising nodes within local neighborhoods for propagation and refinement, enabling rapid improvement of solution cost. We prove that, while maintaining probabilistic $δ$-robust completeness, this focus on promising nodes ensures asymptotic $δ$-robust near-optimality. Our results show that Kino-PAX$^{+}$ finds solutions up to three orders of magnitude faster than existing serial methods and achieves lower solution costs than a state-of-the-art GPU-based planner.", "AI": {"tldr": "该论文提出了Kino-PAX$^{+}$算法，这是一种具有近似最优保证的并行采样式运动规划器。", "motivation": "现有的采样式运动规划器难以实现实时性能，因为它们的设计是串行计算。虽然最近的努力将SBMPs并行化以加速找到可行解，但无法优化目标函数。", "method": "Kino-PAX$^{+}$通过分解传统上为串行操作的步骤到三个大规模并行子例程，构建了动态可行性轨迹的稀疏树结构。算法聚焦在局部最有望节点上的传播和细化，实现快速降低解决方案成本。", "result": "实验表明Kino-PAX$^{+}$比现有的串行方法快三倍数量级，并且实现了比最先进的GPU基于规划器更低的成本解。", "conclusion": "通过这种方法的改进，Kino-PAX$^{+}$不仅提高了效率而且保证了解决方案的质量。"}}
{"id": "2602.02842", "pdf": "https://arxiv.org/pdf/2602.02842", "abs": "https://arxiv.org/abs/2602.02842", "authors": ["Saeid Sheikhi"], "title": "Chain of Simulation: A Dual-Mode Reasoning Framework for Large Language Models with Dynamic Problem Routing", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We present Chain of Simulation (CoS), a novel dual-mode reasoning framework that dynamically routes problems to specialized reasoning strategies in Large Language Models (LLMs). Unlike existing uniform prompting approaches, CoS employs three distinct reasoning modes: (1) computational flow with self-consistency for mathematical problems, (2) symbolic state tracking with JSON representations for spatial reasoning, and (3) hybrid fact-extraction for multi-hop inference. Through comprehensive evaluation on GSM8K, StrategyQA, and bAbI benchmarks using four state-of-the-art models (Gemma-3 27B, LLaMA-3.1 8B, Mistral 7B, and Qwen-2.5 14B), we demonstrate that CoS achieves 71.5% accuracy on GSM8K (1.0% absolute improvement), 90.0% on StrategyQA (2.5% improvement), and 19.0% on bAbI (65.2% relative improvement) compared to the strongest baselines. The analysis reveals that problem-specific mode selection is crucial, with computational mode achieving 81.2% accuracy when correctly applied to mathematical problems, while misrouting leads to 0% accuracy. We provide detailed algorithms for mode selection, state tracking, and answer extraction, establishing CoS as an effective approach for improving LLM reasoning without additional training. The framework provides superior trade-offs between accuracy and efficiency compared to Self-Consistency, achieving comparable performance at 54% lower computational cost.", "AI": {"tldr": "介绍了一种新的双模式推理框架Chain of Simulation（CoS），该框架根据问题类型动态选择特定的推理策略，以提高大型语言模型在解决数学、空间和多跳推理问题时的表现。", "motivation": "当前统一提示方法无法充分利用不同问题类型的特殊性。作者旨在提出一种能够根据不同任务特性优化推理过程的方法，从而提升大规模语言模型的性能。", "method": "CoS框架通过三种不同的推理模式来处理不同类型的问题：计算流程、符号状态跟踪和混合事实提取。它根据问题类型选择合适的模式，并且不需额外训练即可实现高精度的推理。", "result": "在GSM8K，StrategyQA及bAbI数据集上进行了测试，CoS分别取得了71.5%，90%和65.2%相对改进的成绩。此外，该方法展示了比自一致更优的成本效益，在计算成本降低的情况下达到了相似的性能。", "conclusion": "CoS框架通过问题类型的动态路由提高了解决复杂推理任务的能力，而无需额外训练或增加模型大小，证明了其在大型语言模型中的有效性与灵活性。"}}
{"id": "2602.02841", "pdf": "https://arxiv.org/pdf/2602.02841", "abs": "https://arxiv.org/abs/2602.02841", "authors": ["Jae-Sung Bae", "Minje Kim"], "title": "Semantics-Aware Generative Latent Data Augmentation for Learning in Low-Resource Domains", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite strong performance in data-rich regimes, deep learning often underperforms in the data-scarce settings common in practice. While foundation models (FMs) trained on massive datasets demonstrate strong generalization by extracting general-purpose features, they can still suffer from scarce labeled data during downstream fine-tuning. To address this, we propose GeLDA, a semantics-aware generative latent data augmentation framework that leverages conditional diffusion models to synthesize samples in an FM-induced latent space. Because this space is low-dimensional and concentrates task-relevant information compared to the input space, GeLDA enables efficient, high-quality data generation. GeLDA conditions generation on auxiliary feature vectors that capture semantic relationships among classes or subdomains, facilitating data augmentation in low-resource domains. We validate GeLDA in two large-scale recognition tasks: (a) in zero-shot language-specific speech emotion recognition, GeLDA improves the Whisper-large baseline's unweighted average recall by 6.13%; and (b) in long-tailed image classification, it achieves 74.7% tail-class accuracy on ImageNet-LT, setting a new state-of-the-art result.", "AI": {"tldr": "提出了一种基于条件扩散模型的语义感知生成性潜在数据增强框架GeLDA，用于解决低资源场景下的深度学习问题。", "motivation": "在数据贫乏的情况下，基础模型尽管从大规模数据中提取了通用特征，但在下游任务中的微调仍可能受到标注数据稀缺的影响。为了解决这个问题，提出了一种新的生成性潜在数据增强方法。", "method": "利用条件扩散模型在基础模型诱导的低维潜在空间内合成样本，并通过辅助特征向量捕捉语义关系来实现高效高质量的数据生成。", "result": "GeLDA在零样本特定语言语音情感识别任务中将Whisper-large基线的平均未加权召回率提高了6.13%；在长尾图像分类任务上达到了74.7%的尾巴类别准确率，创下新的状态-of-the-art结果。", "conclusion": "GeLDA框架能够有效地利用低资源数据进行高质量的数据增强，并取得了显著的任务性能提升。"}}
{"id": "2602.02839", "pdf": "https://arxiv.org/pdf/2602.02839", "abs": "https://arxiv.org/abs/2602.02839", "authors": ["Yinlong Dai", "Benjamin A. Christie", "Daniel J. Evans", "Dylan P. Losey", "Simon Stepputtis"], "title": "Language Movement Primitives: Grounding Language Models in Robot Motion", "categories": ["cs.RO"], "comment": null, "summary": "Enabling robots to perform novel manipulation tasks from natural language instructions remains a fundamental challenge in robotics, despite significant progress in generalized problem solving with foundational models. Large vision and language models (VLMs) are capable of processing high-dimensional input data for visual scene and language understanding, as well as decomposing tasks into a sequence of logical steps; however, they struggle to ground those steps in embodied robot motion. On the other hand, robotics foundation models output action commands, but require in-domain fine-tuning or experience before they are able to perform novel tasks successfully. At its core, there still remains the fundamental challenge of connecting abstract task reasoning with low-level motion control. To address this disconnect, we propose Language Movement Primitives (LMPs), a framework that grounds VLM reasoning in Dynamic Movement Primitive (DMP) parameterization. Our key insight is that DMPs provide a small number of interpretable parameters, and VLMs can set these parameters to specify diverse, continuous, and stable trajectories. Put another way: VLMs can reason over free-form natural language task descriptions, and semantically ground their desired motions into DMPs -- bridging the gap between high-level task reasoning and low-level position and velocity control. Building on this combination of VLMs and DMPs, we formulate our LMP pipeline for zero-shot robot manipulation that effectively completes tabletop manipulation problems by generating a sequence of DMP motions. Across 20 real-world manipulation tasks, we show that LMP achieves 80% task success as compared to 31% for the best-performing baseline. See videos at our website: https://collab.me.vt.edu/lmp", "AI": {"tldr": "提出了一种将大型视觉语言模型（VLM）与动态运动原语（DMP）相结合的框架，以实现从自然语言指令到机器人动作的有效转换。", "motivation": "现有的技术在将高级任务推理转化为低级运动控制方面存在挑战。本文旨在通过结合VLM和DMP解决这一问题。", "method": "提出了语言运动原语（LMP）框架，利用VLM处理自然语言并生成描述性参数，然后由DMP根据这些参数产生机器人动作轨迹。", "result": "在20个真实世界操作任务中，提出的LMP方法达到了80%的成功率，而最佳基线模型只有31%。", "conclusion": "通过结合VLM和DMP，可以有效实现从自然语言指令到机器人运动的零样本转换。"}}
{"id": "2602.02834", "pdf": "https://arxiv.org/pdf/2602.02834", "abs": "https://arxiv.org/abs/2602.02834", "authors": ["Jonas Petersen", "Camilla Mazzoleni", "Riccardo Maggioni"], "title": "Tabula RASA: Exposing and Breaking the Relational Bottleneck in Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 4 figures, 8 tables", "summary": "Transformers achieve remarkable performance across many domains, yet struggle with tasks requiring multi-hop relational reasoning over structured data. We analyze this limitation through circuit complexity: standard transformers are $\\mathsf{TC}^0$-complete and require $Ω(k)$ layers for $k$-hop reasoning. We introduce RASA (Relation-Aware Sparse Attention), a minimal modification adding: (1) edge-type embeddings that inject relational structure into attention scores, and (2) sparse masking that restricts attention to graph-adjacent positions. While RASA has the same asymptotic depth requirements, sparse masking reduces the attention search space from $O(2^{n^2})$ to $O(2^m)$ patterns, and edge biases provide explicit relation routing. Empirically, on MetaQA (1/2/3-hop) and WebQuestionsSP, RASA outperforms standard transformers and matches GPT-4 at lower cost, with advantages growing with reasoning depth (+7.1 points on 3-hop). We do not claim formal learnability guarantees; the contribution is empirical validation that minimal structural modifications substantially improve multi-hop reasoning.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.02831", "pdf": "https://arxiv.org/pdf/2602.02831", "abs": "https://arxiv.org/abs/2602.02831", "authors": ["Yutaka Shimizu", "Masayoshi Tomizuka"], "title": "Adaptive Linear Path Model-Based Diffusion", "categories": ["cs.RO"], "comment": "ICRA 2026", "summary": "The interest in combining model-based control approaches with diffusion models has been growing. Although we have seen many impressive robotic control results in difficult tasks, the performance of diffusion models is highly sensitive to the choice of scheduling parameters, making parameter tuning one of the most critical challenges. We introduce Linear Path Model-Based Diffusion (LP-MBD), which replaces the variance-preserving schedule with a flow-matching-inspired linear probability path. This yields a geometrically interpretable and decoupled parameterization that reduces tuning complexity and provides a stable foundation for adaptation. Building on this, we propose Adaptive LP-MBD (ALP-MBD), which leverages reinforcement learning to adjust diffusion steps and noise levels according to task complexity and environmental conditions. Across numerical studies, Brax benchmarks, and mobile-robot trajectory tracking, LP-MBD simplifies scheduling while maintaining strong performance, and ALP-MBD further improves robustness, adaptability, and real-time efficiency.", "AI": {"tldr": "本文提出了一种基于线性路径模型的扩散方法（LP-MBD）及其自适应版本（ALP-MBD），以提高机器人控制任务中的性能和鲁棒性。", "motivation": "在结合模型化控制与扩散模型方面存在挑战，尤其是参数调整复杂且影响性能。本文旨在简化调度并增强鲁棒性和实时效率。", "method": "引入LP-MBD，用线性概率路径替换方差保持计划，提供几何可解释的解耦参数化。ALP-MBD通过强化学习根据任务和环境条件调节扩散步骤和噪声水平。", "result": "在数值研究、Brax基准测试及移动机器人轨迹跟踪中，LP-MBD简化调度并维持高性能；ALP-MBD进一步提高鲁棒性、适应性和实时效率。", "conclusion": "提出的方法能够简化参数调整流程，并通过自适应机制增强性能和稳定性。"}}
{"id": "2602.02826", "pdf": "https://arxiv.org/pdf/2602.02826", "abs": "https://arxiv.org/abs/2602.02826", "authors": ["Louis Callens", "Bastiaan Vandewal", "Ibrahim Ibrahim", "Jan Swevers", "Wilm Decré"], "title": "Fast Near Time-Optimal Motion Planning for Holonomic Vehicles in Structured Environments", "categories": ["math.OC", "cs.RO"], "comment": null, "summary": "This paper proposes a novel and efficient optimization-based method for generating near time-optimal trajectories for holonomic vehicles navigating through complex but structured environments. The approach aims to solve the problem of motion planning for planar motion systems using magnetic levitation that can be used in assembly lines, automated laboratories or clean-rooms. In these applications, time-optimal trajectories that can be computed in real-time are required to increase productivity and allow the vehicles to be reactive if needed. The presented approach encodes the environment representation using free-space corridors and represents the motion of the vehicle through such a corridor using a motion primitive. These primitives are selected heuristically and define the trajectory with a limited number of degrees of freedom, which are determined in an optimization problem. As a result, the method achieves significantly lower computation times compared to the state-of-the-art, most notably solving a full Optimal Control Problem (OCP), OMG-tools or VP-STO without significantly compromising optimality within a fixed corridor sequence. The approach is benchmarked extensively in simulation and is validated on a real-world Beckhoff XPlanar system", "AI": {"tldr": "本文提出了一种基于优化的高效方法，用于在结构化环境中为全向车辆生成接近时间最优的轨迹。", "motivation": "为了提高生产力并使车辆具有反应性，在装配线、自动化实验室或洁净室等应用中需要能够实时计算的时间最优路径。传统的方法通常耗时较长，无法满足实时需求。", "method": "该方法使用自由空间走廊编码环境表示，并通过运动原语定义车辆在走廊中的运动。这些原始语句被启发式地选择并定义轨迹的有限度自由度，在优化问题中确定它们。这种方法显著减少了计算时间。", "result": "与现有技术相比，本文的方法实现了明显更低的计算时间，特别是在解决完整最优控制问题、OMG工具或VP-STO时，并且在固定的走廊序列内没有显著降低最优性。", "conclusion": "该方法通过广泛的仿真基准测试得到了验证，并已在真实的Beckhoff XPlanar系统上进行了实际应用。"}}
{"id": "2602.02820", "pdf": "https://arxiv.org/pdf/2602.02820", "abs": "https://arxiv.org/abs/2602.02820", "authors": ["Michael Ogezi", "Martin Bell", "Freda Shi", "Ethan Smith"], "title": "From Tokens to Numbers: Continuous Number Modeling for SVG Generation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "For certain image generation tasks, vector graphics such as Scalable Vector Graphics (SVGs) offer clear benefits such as increased flexibility, size efficiency, and editing ease, but remain less explored than raster-based approaches. A core challenge is that the numerical, geometric parameters, which make up a large proportion of SVGs, are inefficiently encoded as long sequences of tokens. This slows training, reduces accuracy, and hurts generalization. To address these problems, we propose Continuous Number Modeling (CNM), an approach that directly models numbers as first-class, continuous values rather than discrete tokens. This formulation restores the mathematical elegance of the representation by aligning the model's inputs with the data's continuous nature, removing discretization artifacts introduced by token-based encoding. We then train a multimodal transformer on 2 million raster-to-SVG samples, followed by fine-tuning via reinforcement learning using perceptual feedback to further improve visual quality. Our approach improves training speed by over 30% while maintaining higher perceptual fidelity compared to alternative approaches. This work establishes CNM as a practical and efficient approach for high-quality vector generation, with potential for broader applications. We make our code available http://github.com/mikeogezi/CNM.", "AI": {"tldr": "本文提出了一种称为连续数字建模（CNM）的方法，直接将SVG中的几何参数视为连续值而非离散标记，提高了矢量图像生成的速度和质量。", "motivation": "传统的矢量图形生成方法使用长序列的标记来编码数值几何参数，导致训练效率低、准确度差以及泛化能力弱。本文旨在通过引入一种新的建模方式解决这些问题，以提高SVG生成的质量和速度。", "method": "提出了一种连续数字建模（CNM）的方法，该方法将数值视为连续值而非离散标记，并使用多模式变压器对200万张图像进行训练，随后通过强化学习进一步优化视觉质量。", "result": "与现有方法相比，本文的方法提高了超过30%的训练速度并保持了更高的感知保真度。", "conclusion": "连续数字建模（CNM）是一种高效且实用的方法，适用于高质量矢量图像生成，并具有更广泛的应用潜力。"}}
{"id": "2602.02814", "pdf": "https://arxiv.org/pdf/2602.02814", "abs": "https://arxiv.org/abs/2602.02814", "authors": ["Berk Bozkurt", "Aditya Mahajan", "Ashutosh Nayyar", "Yi Ouyang"], "title": "Sub-optimality bounds for certainty equivalent policies in partially observed systems", "categories": ["math.OC", "cs.RO", "eess.SY"], "comment": "12 pages, 0 figures", "summary": "In this paper, we present a generalization of the certainty equivalence principle of stochastic control. One interpretation of the classical certainty equivalence principle for linear systems with output feedback and quadratic costs is as follows: the optimal action at each time is obtained by evaluating the optimal state-feedback policy of the stochastic linear system at the minimum mean square error (MMSE) estimate of the state. Motivated by this interpretation, we consider certainty equivalent policies for general (non-linear) partially observed stochastic systems that allow for any state estimate rather than restricting to MMSE estimates. In such settings, the certainty equivalent policy is not optimal. For models where the cost and the dynamics are smooth in an appropriate sense, we derive upper bounds on the sub-optimality of certainty equivalent policies. We present several examples to illustrate the results.", "AI": {"tldr": "本文研究了部分可观测系统中确定等价策略的次优性界限", "motivation": "受经典线性系统的确定等价原理启发，作者考虑了一般非线性随机系统中的任何状态估计，并推导了在这种情况下的次优性上界", "method": "通过分析模型的成本和动力学是否在适当意义上平滑来获得确定等价策略的次优性界限", "result": "对于符合特定条件的模型，本文提出了确定等价策略的次优性的上限，并给出了几个示例以说明结果", "conclusion": "结论强调了确定等价政策在非线性随机系统中的应用及其理论意义"}}
{"id": "2602.02808", "pdf": "https://arxiv.org/pdf/2602.02808", "abs": "https://arxiv.org/abs/2602.02808", "authors": ["Matteo Bastico", "Pierre Onghena", "David Ryckelynck", "Beatriz Marcotegui", "Santiago Velasco-Forero", "Laurent Corté", "Caroline Robine--Decourcelle", "Etienne Decencière"], "title": "LmPT: Conditional Point Transformer for Anatomical Landmark Detection on 3D Point Clouds", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "This paper has been accepted at International Symposium on Biomedical Imaging (ISBI) 2026", "summary": "Accurate identification of anatomical landmarks is crucial for various medical applications. Traditional manual landmarking is time-consuming and prone to inter-observer variability, while rule-based methods are often tailored to specific geometries or limited sets of landmarks. In recent years, anatomical surfaces have been effectively represented as point clouds, which are lightweight structures composed of spatial coordinates. Following this strategy and to overcome the limitations of existing landmarking techniques, we propose Landmark Point Transformer (LmPT), a method for automatic anatomical landmark detection on point clouds that can leverage homologous bones from different species for translational research. The LmPT model incorporates a conditioning mechanism that enables adaptability to different input types to conduct cross-species learning. We focus the evaluation of our approach on femoral landmarking using both human and newly annotated dog femurs, demonstrating its generalization and effectiveness across species. The code and dog femur dataset will be publicly available at: https://github.com/Pierreoo/LandmarkPointTransformer.", "AI": {"tldr": "提出了一种新的方法LmPT，用于在点云上自动检测解剖标志，特别是跨物种学习。", "motivation": "为了克服现有地标技术的局限性，提高医学应用中解剖标志识别的准确性和效率。", "method": "使用条件点变换器（Conditional Point Transformer）模型来实现解剖标志的自动检测，并通过引入一种适应机制使其能够处理不同输入类型的数据以进行跨物种学习。", "result": "在人类和狗的股骨数据集上验证了LmPT方法的有效性和泛化能力，显示了其在跨物种应用中的优越性能。", "conclusion": "提出的方法LmPT为自动检测解剖标志提供了一种新的解决方案，并且展示了良好的跨物种适应性。"}}
{"id": "2602.02799", "pdf": "https://arxiv.org/pdf/2602.02799", "abs": "https://arxiv.org/abs/2602.02799", "authors": ["Wasu Top Piriyakulkij", "Wolfgang Lehrach", "Kevin Ellis", "Kevin Murphy"], "title": "Joint Learning of Hierarchical Neural Options and Abstract World Model", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Building agents that can perform new skills by composing existing skills is a long-standing goal of AI agent research. Towards this end, we investigate how to efficiently acquire a sequence of skills, formalized as hierarchical neural options. However, existing model-free hierarchical reinforcement algorithms need a lot of data. We propose a novel method, which we call AgentOWL (Option and World model Learning Agent), that jointly learns -- in a sample efficient way -- an abstract world model (abstracting across both states and time) and a set of hierarchical neural options. We show, on a subset of Object-Centric Atari games, that our method can learn more skills using much less data than baseline methods.", "AI": {"tldr": "本文提出了一种名为AgentOWL的新方法，该方法能够同时高效地学习抽象世界模型和分层神经选项。", "motivation": "构建可以通过组合现有技能来执行新任务的智能体是AI研究的一个长期目标。然而现有的无模型分层强化算法需要大量数据。", "method": "提出了一种名为AgentOWL的方法，该方法能够在样本效率高的情况下同时学习抽象世界模型和一套分层神经选项。", "result": "在Object-Centric Atari游戏中的一组子集中显示，该方法可以比基线方法使用更少的数据来学习更多的技能。", "conclusion": "新提出的AgentOWL方法能够提高数据利用效率并在样本量有限的情况下学习更多技能。"}}
{"id": "2602.02798", "pdf": "https://arxiv.org/pdf/2602.02798", "abs": "https://arxiv.org/abs/2602.02798", "authors": ["Rosalinda Xiong", "Jinglun Yu", "Yaning Wang", "Ziyi Huang", "Jin U. Kang"], "title": "Real-time topology-aware M-mode OCT segmentation for robotic deep anterior lamellar keratoplasty (DALK) guidance", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Robotic deep anterior lamellar keratoplasty (DALK) requires accurate real time depth feedback to approach Descemet's membrane (DM) without perforation. M-mode intraoperative optical coherence tomography (OCT) provides high temporal resolution depth traces, but speckle noise, attenuation, and instrument induced shadowing often result in discontinuous or ambiguous layer interfaces that challenge anatomically consistent segmentation at deployment frame rates. We present a lightweight, topology aware M-mode segmentation pipeline based on UNeXt that incorporates anatomical topology regularization to stabilize boundary continuity and layer ordering under low signal to noise ratio conditions. The proposed system achieves end to end throughput exceeding 80 Hz measured over the complete preprocessing inference overlay pipeline on a single GPU, demonstrating practical real time guidance beyond model only timing. This operating margin provides temporal headroom to reject low quality or dropout frames while maintaining a stable effective depth update rate. Evaluation on a standard rabbit eye M-mode dataset using an established baseline protocol shows improved qualitative boundary stability compared with topology agnostic controls, while preserving deployable real time performance.", "AI": {"tldr": "实时拓扑感知M模式OCT分割用于机器人深前部板层角膜移植术（DALK）引导", "motivation": "机器人深前部板层角膜移植术需要准确的实时深度反馈，以避免穿孔地接近Descemet膜。现有的M模式OCT图像由于斑点噪声、衰减和器械诱导阴影的影响，在低信噪比条件下难以实现稳定一致的分割。", "method": "提出了一种基于UNeXt的轻量级、拓扑感知的M模式分割流水线，利用解剖学拓扑规则化来提高边界连续性和层序在低信号噪声比条件下的稳定性。该系统实现在单个GPU上超过80Hz的整体端到端吞吐量。", "result": "评估结果表明，在标准兔眼M模式数据集上，与没有采用拓扑感知控制相比，所提出的系统实现了更好的边界稳定性和可部署的实时性能。", "conclusion": "该方法有效提高了机器人深前部板层角膜移植术中的分割精度和稳定性，并且在实际应用场景中具有很高的实用价值。"}}
{"id": "2602.02793", "pdf": "https://arxiv.org/pdf/2602.02793", "abs": "https://arxiv.org/abs/2602.02793", "authors": ["Reza Rezvan", "Gustav Gille", "Moritz Schauer", "Richard Torkar"], "title": "Causality--Δ: Jacobian-Based Dependency Analysis in Flow Matching Models", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 5 figures. Code: https://github.com/rezaarezvan/causdiff", "summary": "Flow matching learns a velocity field that transports a base distribution to data. We study how small latent perturbations propagate through these flows and show that Jacobian-vector products (JVPs) provide a practical lens on dependency structure in the generated features. We derive closed-form expressions for the optimal drift and its Jacobian in Gaussian and mixture-of-Gaussian settings, revealing that even globally nonlinear flows admit local affine structure. In low-dimensional synthetic benchmarks, numerical JVPs recover the analytical Jacobians. In image domains, composing the flow with an attribute classifier yields an attribute-level JVP estimator that recovers empirical correlations on MNIST and CelebA. Conditioning on small classifier-Jacobian norms reduces correlations in a way consistent with a hypothesized common-cause structure, while we emphasize that this conditioning is not a formal do intervention.", "AI": {"tldr": "研究了流匹配模型中小的潜在扰动如何传播，并利用雅可比向量积（JVP）来分析生成特征之间的依赖关系。", "motivation": "探索小的潜在扰动在流匹配模型中的传播机制，理解这些扰动对最终生成数据的影响和内在结构。通过使用雅可比矩阵揭示局部仿射结构，以进一步了解非线性流的行为。", "method": "推导了高斯及混合高斯设置下的最优漂移及其雅可比的闭式表达；在合成低维基准上用数值JVP恢复了解析雅可比；对于图像领域，通过将流与属性分类器组合来估计属性级别的JVP。分析小的分类器-雅可比范数以减少相关性。", "result": "低维度实验中，数值JVP可以准确地再现解析雅可比矩阵；在MNIST和CelebA数据集上，基于分类器的JVP能恢复经验上的相关性；通过降低属性之间的关联度来揭示潜在的因果关系结构。", "conclusion": "使用雅可比向量积作为分析工具能够有效地研究流匹配模型中的依赖性和局部线性化特性。这种方法提供了一种理解生成数据背后机制的新视角，但需要注意的是它并不是正式的干预方法。"}}
{"id": "2602.02790", "pdf": "https://arxiv.org/pdf/2602.02790", "abs": "https://arxiv.org/abs/2602.02790", "authors": ["Hyunsung Cho", "Xuejing Luo", "Byungjoo Lee", "David Lindlbauer", "Antti Oulasvirta"], "title": "Simulating Human Audiovisual Search Behavior", "categories": ["cs.HC", "cs.AI", "cs.RO"], "comment": "17 pages, 10 figures, CHI 2026", "summary": "Locating a target based on auditory and visual cues$\\unicode{x2013}$such as finding a car in a crowded parking lot or identifying a speaker in a virtual meeting$\\unicode{x2013}$requires balancing effort, time, and accuracy under uncertainty. Existing models of audiovisual search often treat perception and action in isolation, overlooking how people adaptively coordinate movement and sensory strategies. We present Sensonaut, a computational model of embodied audiovisual search. The core assumption is that people deploy their body and sensory systems in ways they believe will most efficiently improve their chances of locating a target, trading off time and effort under perceptual constraints. Our model formulates this as a resource-rational decision-making problem under partial observability. We validate the model against newly collected human data, showing that it reproduces both adaptive scaling of search time and effort under task complexity, occlusion, and distraction, and characteristic human errors. Our simulation of human-like resource-rational search informs the design of audiovisual interfaces that minimize search cost and cognitive load.", "AI": {"tldr": "本文提出了一种计算模型Sensonaut，用于模拟人在视听条件下搜索目标的行为。", "motivation": "现有的视听搜索模型往往将感知和行动分开考虑，忽略了人们如何在不确定的环境中协调身体移动与感官策略以最高效地定位目标。", "method": "该模型假设人们会根据他们认为能够最快提高找到目标几率的方式来部署他们的身体和感觉系统。这种行为被建模为一个资源理性的决策问题，在部分可见性条件下进行。", "result": "通过新收集的人类数据验证，发现此模型能再现搜索时间和努力随任务复杂度、遮挡与分心变化的适应性调整，并模拟出人类似的错误模式。", "conclusion": "本文提出的仿真方法有助于设计降低搜索成本和认知负荷的视听界面"}}
{"id": "2602.02788", "pdf": "https://arxiv.org/pdf/2602.02788", "abs": "https://arxiv.org/abs/2602.02788", "authors": ["Benjamin D. Shaffer", "Shawn Koohy", "Brooks Kinch", "M. Ani Hsieh", "Nathaniel Trask"], "title": "Structure-Preserving Learning Improves Geometry Generalization in Neural PDEs", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "We aim to develop physics foundation models for science and engineering that provide real-time solutions to Partial Differential Equations (PDEs) which preserve structure and accuracy under adaptation to unseen geometries. To this end, we introduce General-Geometry Neural Whitney Forms (Geo-NeW): a data-driven finite element method. We jointly learn a differential operator and compatible reduced finite element spaces defined on the underlying geometry. The resulting model is solved to generate predictions, while exactly preserving physical conservation laws through Finite Element Exterior Calculus. Geometry enters the model as a discretized mesh both through a transformer-based encoding and as the basis for the learned finite element spaces. This explicitly connects the underlying geometry and imposed boundary conditions to the solution, providing a powerful inductive bias for learning neural PDEs, which we demonstrate improves generalization to unseen domains. We provide a novel parameterization of the constitutive model ensuring the existence and uniqueness of the solution. Our approach demonstrates state-of-the-art performance on several steady-state PDE benchmarks, and provides a significant improvement over conventional baselines on out-of-distribution geometries.", "AI": {"tldr": "本文提出了一种名为General-Geometry Neural Whitney Forms (Geo-NeW) 的方法，用于解决偏微分方程(PDEs)，在未见过的几何形状上保持结构和精度。", "motivation": "为了开发能为科学和工程提供实时解决方案的物理基础模型，并且该模型能在适应未知几何时仍保留结构和准确性。", "method": "通过一种名为General-Geometry Neural Whitney Forms (Geo-NeW) 的方法，结合学习微分算子以及在底层几何上的兼容有限元空间，采用数据驱动的有限元法。这种方法利用了有限元外积微积分来精确保持物理守恒定律，并将网格作为解和边界条件之间的桥梁。", "result": "该方法在多个稳态PDE基准测试上表现出了最先进的性能，并且在未见过的几何形状上的表现显著优于传统基线方法。", "conclusion": "通过提出General-Geometry Neural Whitney Forms (Geo-NeW) 方法，本文展示了提高神经偏微分方程模型对于未知几何结构泛化能力的有效性。"}}
{"id": "2602.02785", "pdf": "https://arxiv.org/pdf/2602.02785", "abs": "https://arxiv.org/abs/2602.02785", "authors": ["Awu Chen", "Vera Yu Wu", "Yunge Wen", "Yaluo Wang", "Jiaxuan Olivia Yin", "Yichen Wang", "Qian Xiang", "Richard Zhang", "Paul Pu Liang", "Hiroshi Ishii"], "title": "Smell with Genji: Rediscovering Human Perception through an Olfactory Game with AI", "categories": ["cs.HC"], "comment": null, "summary": "Olfaction plays an important role in human perception, yet its subjective and ephemeral nature makes it difficult to articulate, compare, and share across individuals. Traditional practices like the Japanese incense game Genji-ko offer one way to structure olfactory experience through shared interpretation. In this work, we present Smell with Genji, an AI-mediated olfactory interaction system that reinterprets Genji-ko as a collaborative human-AI sensory experience. By integrating a game setup, a mobile application, and an LLM-powered co-smelling partner equipped with olfactory sensing and LLM-based conversation, the system invites participants to compare scents and construct Genji-mon patterns, fostering reflection through a dialogue that highlights the alignment and discrepancies between human and machine perception. This work illustrates how sensing-enabled AI can participate in olfactory experience alongside users, pointing toward new possibilities for AI-supported sensory interaction and reflection in HCI.", "AI": {"tldr": "通过AI与人类的协作游戏重新诠释日本传统的香木猜谜活动，探索嗅觉体验的新可能性。", "motivation": "研究如何利用人工智能技术参与和增强人类的嗅觉感知体验。", "method": "设计一个结合游戏设置、移动应用以及具有嗅觉传感功能并基于LLM进行对话的人工智能协作伙伴系统。", "result": "展示了AI如何与用户共同经历嗅觉体验，并通过对话突出人机感知的一致性与差异，为感官交互和反思提供了新的可能性。", "conclusion": "此工作展示了具备感觉能力的AI可以参与和人类一起体验嗅觉的过程，开创了在HCI领域中基于感官互动和反思的新途径。"}}
{"id": "2602.02784", "pdf": "https://arxiv.org/pdf/2602.02784", "abs": "https://arxiv.org/abs/2602.02784", "authors": ["Arian Khorasani", "Théophile Demazure"], "title": "Cross-Temporal Attention Fusion (CTAF) for Multimodal Physiological Signals in Self-Supervised Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study multimodal affect modeling when EEG and peripheral physiology are asynchronous, which most fusion methods ignore or handle with costly warping. We propose Cross-Temporal Attention Fusion (CTAF), a self-supervised module that learns soft bidirectional alignments between modalities and builds a robust clip embedding using time-aware cross attention, a lightweight fusion gate, and alignment-regularized contrastive objectives with optional weak supervision. On the K-EmoCon dataset, under leave-one-out cross-validation evaluation, CTAF yields higher cosine margins for matched pairs and better cross-modal token retrieval within one second, and it is competitive with the baseline on three-bin accuracy and macro-F1 while using few labels. Our contributions are a time-aware fusion mechanism that directly models correspondence, an alignment-driven self-supervised objective tailored to EEG and physiology, and an evaluation protocol that measures alignment quality itself. Our approach accounts for the coupling between the central and autonomic nervous systems in psychophysiological time series. These results indicate that CTAF is a strong step toward label-efficient, generalizable EEG-peripheral fusion under temporal asynchrony.", "AI": {"tldr": "该论文提出了一种名为CTAF的跨时间注意力融合方法，用于在无监督学习中处理异步的心电图和外周生理信号。", "motivation": "大多数现有的多模态情感建模方法忽略了心电图与外周生理学之间的异步问题，或者使用了计算成本高昂的时间对齐技术。为此，论文提出了CTAF来解决这一挑战。", "method": "CTAF通过时间感知交叉注意机制建立了不同模式之间软双向对齐，并结合轻量级融合门和对准正则化对比目标构建了一个稳健的剪辑嵌入。", "result": "在K-EmoCon数据集上，CTAF表现出更高的匹配成对余弦边界和更好的跨模态令牌检索性能。同时，在少标签的情况下与基线方法相比也具有竞争力。", "conclusion": "该论文提出的方法能够直接建模对应关系并考虑到中枢神经系统和自主神经系统的耦合效应，为异步的心电图-外周生理融合提供了有力的支持，并且在无监督学习中表现出良好的性能。"}}
{"id": "2602.02781", "pdf": "https://arxiv.org/pdf/2602.02781", "abs": "https://arxiv.org/abs/2602.02781", "authors": ["Nirab Hossain", "Pablo Moriano"], "title": "Evaluating False Alarm and Missing Attacks in CAN IDS", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "8 pages, 2 figures, and 8 tables", "summary": "Modern vehicles rely on electronic control units (ECUs) interconnected through the Controller Area Network (CAN), making in-vehicle communication a critical security concern. Machine learning (ML)-based intrusion detection systems (IDS) are increasingly deployed to protect CAN traffic, yet their robustness against adversarial manipulation remains largely unexplored. We present a systematic adversarial evaluation of CAN IDS using the ROAD dataset, comparing four shallow learning models with a deep neural network-based detector. Using protocol-compliant, payload-level perturbations generated via FGSM, BIM and PGD, we evaluate adversarial effects on both benign and malicious CAN frames. While all models achieve strong baseline performance under benign conditions, adversarial perturbations reveal substantial vulnerabilities. Although shallow and deep models are robust to false-alarm induction, with the deep neural network (DNN) performing best on benign traffic, all architectures suffer significant increases in missed attacks. Notably, under gradient-based attacks, the shallow model extra trees (ET) demonstrates improved robustness to missed-attack induction compared to the other models. Our results demonstrate that adversarial manipulation can simultaneously trigger false alarms and evade detection, underscoring the need for adversarial robustness evaluation in safety-critical automotive IDS.", "AI": {"tldr": "评估CAN入侵检测系统在对抗性攻击下的性能", "motivation": "研究汽车电子控制单元间通信的安全问题，特别是ML-based CAN IDS的抗干扰能力", "method": "利用FGSM、BIM和PGD生成协议合规性的扰动输入，对浅层学习模型与深层神经网络进行对比测试", "result": "所有模型在对抗攻击下表现出较高的误报率并遗漏大量攻击", "conclusion": "需要进一步提高CAN IDS的安全性以抵御对抗性攻击"}}
{"id": "2602.02780", "pdf": "https://arxiv.org/pdf/2602.02780", "abs": "https://arxiv.org/abs/2602.02780", "authors": ["Zihao Jing", "Qiuhao Zeng", "Ruiyi Fang", "Yan Yi Li", "Yan Sun", "Boyu Wang", "Pingzhao Hu"], "title": "Scaling-Aware Adapter for Structure-Grounded LLM Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": "Under review at ICML 2026", "summary": "Large language models (LLMs) are enabling reasoning over biomolecular structures, yet existing methods remain modality-specific and typically compress structural inputs through sequence-based tokenization or fixed-length query connectors. Such architectures either omit the geometric groundings requisite for mitigating structural hallucinations or impose inflexible modality fusion bottlenecks that concurrently over-compress and suboptimally allocate structural tokens, thereby impeding the realization of generalized all-atom reasoning. We introduce Cuttlefish, a unified all-atom LLM that grounds language reasoning in geometric cues while scaling modality tokens with structural complexity. First, Scaling-Aware Patching leverages an instruction-conditioned gating mechanism to generate variable-size patches over structural graphs, adaptively scaling the query token budget with structural complexity to mitigate fixed-length connector bottlenecks. Second, Geometry Grounding Adapter refines these adaptive tokens via cross-attention to modality embeddings and injects the resulting modality tokens into the LLM, exposing explicit geometric cues to reduce structural hallucination. Experiments across diverse all-atom benchmarks demonstrate that Cuttlefish achieves superior performance in heterogeneous structure-grounded reasoning. Code is available at the project repository.", "AI": {"tldr": "本文提出了Cuttlefish，一种能够基于几何线索进行语言推理的统一全原子LLM。", "motivation": "现有方法在生物分子结构上的推理中存在模式特定性和固定长度连接瓶颈问题，这限制了模型泛化能力。", "method": "通过指令条件门控机制生成可变大小的结构图块，并适应性调整查询令牌预算；利用跨注意力修正这些自适应令牌并将其注入LLM以减少结构幻觉。", "result": "实验表明Cuttlefish在异构结构推理上表现出优越性能。", "conclusion": "Cuttlefish通过灵活处理结构复杂性和基于几何线索进行语言推理，实现了更优的生物分子结构理解。"}}
{"id": "2602.02773", "pdf": "https://arxiv.org/pdf/2602.02773", "abs": "https://arxiv.org/abs/2602.02773", "authors": ["Jehan Yang", "Eleanor Hodgson", "Cindy Sun", "Zackory Erickson", "Doug Weber"], "title": "Bimanual High-Density EMG Control for In-Home Mobile Manipulation by a User with Quadriplegia", "categories": ["cs.RO"], "comment": "14 pages, 17 figures", "summary": "Mobile manipulators in the home can enable people with cervical spinal cord injury (cSCI) to perform daily physical household tasks that they could not otherwise do themselves. However, paralysis in these users often limits access to traditional robot control interfaces such as joysticks or keyboards. In this work, we introduce and deploy the first system that enables a user with quadriplegia to control a mobile manipulator in their own home using bimanual high-density electromyography (HDEMG). We develop a pair of custom, fabric-integrated HDEMG forearm sleeves, worn on both arms, that capture residual neuromotor activity from clinically paralyzed degrees of freedom and support real-time gesture-based robot control. Second, by integrating vision, language, and motion planning modules, we introduce a shared autonomy framework that supports robust and user-driven teleoperation, with particular benefits for navigation-intensive tasks in home environments. Finally, to demonstrate the system in the wild, we present a twelve-day in-home user study evaluating real-time use of the wearable EMG interface for daily robot control. Together, these system components enable effective robot control for performing activities of daily living and other household tasks in a real home environment.", "AI": {"tldr": "论文介绍了一种使用双臂高密度肌电图(HDEMG)控制家中移动机器人的系统，使四肢瘫痪的用户能够执行日常任务。", "motivation": "四肢瘫痪的人难以通过传统的机器人控制系统如操纵杆或键盘来操控机器人。该研究旨在为这种状况下的用户提供一种新的解决方案。", "method": "开发了一对定制、嵌入纺织品中的HDEMG前臂套，可捕获临床瘫痪部位的残留神经活动，并支持实时手势控制。同时结合视觉、语言和运动规划模块，形成共享自主性框架以增强任务执行效率。", "result": "通过为期十二天的家庭用户研究证明了该系统的有效性，在真实家庭环境中使用穿戴式EMG界面进行日常机器人操控的实际应用效果良好。", "conclusion": "系统组件共同为四肢瘫痪用户提供了一种有效的方法来控制机器人的活动，从而完成日常生活中的任务。"}}
{"id": "2602.02767", "pdf": "https://arxiv.org/pdf/2602.02767", "abs": "https://arxiv.org/abs/2602.02767", "authors": ["Meng Ding", "Jinhui Xu", "Kaiyi Ji"], "title": "Provable Effects of Data Replay in Continual Learning: A Feature Learning Perspective", "categories": ["cs.LG", "cs.AI"], "comment": "AISTATS 2026", "summary": "Continual learning (CL) aims to train models on a sequence of tasks while retaining performance on previously learned ones. A core challenge in this setting is catastrophic forgetting, where new learning interferes with past knowledge. Among various mitigation strategies, data-replay methods, where past samples are periodically revisited, are considered simple yet effective, especially when memory constraints are relaxed. However, the theoretical effectiveness of full data replay, where all past data is accessible during training, remains largely unexplored. In this paper, we present a comprehensive theoretical framework for analyzing full data-replay training in continual learning from a feature learning perspective. Adopting a multi-view data model, we identify the signal-to-noise ratio (SNR) as a critical factor affecting forgetting. Focusing on task-incremental binary classification across $M$ tasks, our analysis verifies two key conclusions: (1) forgetting can still occur under full replay when the cumulative noise from later tasks dominates the signal from earlier ones; and (2) with sufficient signal accumulation, data replay can recover earlier tasks-even if their initial learning was poor. Notably, we uncover a novel insight into task ordering: prioritizing higher-signal tasks not only facilitates learning of lower-signal tasks but also helps prevent catastrophic forgetting. We validate our theoretical findings through synthetic and real-world experiments that visualize the interplay between signal learning and noise memorization across varying SNRs and task correlation regimes.", "AI": {"tldr": "本文通过理论框架从特征学习的角度分析了连续学习中全数据重播的效果，探讨其在缓解灾难性遗忘中的作用。", "motivation": "旨在解决连续学习场景下的核心挑战——灾难性遗忘问题，特别是在放松内存限制时全数据重播的理论有效性尚未被充分探索的情况下。", "method": "采用多视角数据分析模型，从信号噪声比的角度出发分析了任务增量二元分类中全数据重播的效果，并验证了其在不同SNR和任务关联情况下的学习效果。", "result": "证明了即使进行全数据重播，如果后续任务的累积噪音大于早期任务的信号，则仍会发生遗忘；同时，在有足够的信号积累的情况下，即使是最初表现较差的任务也能被恢复。此外还发现优先处理高信号任务有助于防止灾难性遗忘。", "conclusion": "通过合成和真实世界的实验验证了理论结论，并提出了关于任务排序的新见解。"}}
{"id": "2602.02765", "pdf": "https://arxiv.org/pdf/2602.02765", "abs": "https://arxiv.org/abs/2602.02765", "authors": ["Haruhiko Murata", "Kazuhiro Hotta"], "title": "SVD-ViT: Does SVD Make Vision Transformers Attend More to the Foreground?", "categories": ["cs.CV"], "comment": "8 pages, 6 figures", "summary": "Vision Transformers (ViT) have been established as large-scale foundation models. However, because self-attention operates globally, they lack an explicit mechanism to distinguish foreground from background. As a result, ViT may learn unnecessary background features and artifacts, leading to degraded classification performance. To address this issue, we propose SVD-ViT, which leverages singular value decomposition (SVD) to prioritize the learning of foreground features. SVD-ViT consists of three components-\\textbf{SPC module}, \\textbf{SSVA}, and \\textbf{ID-RSVD}-and suppresses task-irrelevant factors such as background noise and artifacts by extracting and aggregating singular vectors that capture object foreground information. Experimental results demonstrate that our method improves classification accuracy and effectively learns informative foreground representations while reducing the impact of background noise.", "AI": {"tldr": "本文提出了一种使用奇异值分解（SVD）来优化视觉变压器模型的方法，以提高前景特征学习和减少背景噪声影响。", "motivation": "由于自注意力机制的全局操作导致视觉变压器缺乏显式的前背景区分方法，这可能导致不必要的背景特征学习，降低分类性能。因此提出了一种新的方法来解决这一问题。", "method": "通过引入SPC模块、SSVA和ID-RSVD三个组件，利用奇异值分解提取并聚合捕获对象前景信息的奇异向量，从而抑制任务不相关的因素如背景噪声和伪影。", "result": "实验表明该方法提高了分类精度，并有效地学习了具有信息性的前景表示，同时减少了背景噪声的影响。", "conclusion": "通过使用SVD-ViT，模型能够更好地关注于前景特征，改善分类性能并减少背景干扰。"}}
{"id": "2602.02755", "pdf": "https://arxiv.org/pdf/2602.02755", "abs": "https://arxiv.org/abs/2602.02755", "authors": ["Jinglun Yu", "Yaning Wang", "Rosalinda Xiong", "Ziyi Huang", "Kristina Irsch", "Jin U. Kang"], "title": "Physics-based generation of multilayer corneal OCT data via Gaussian modeling and MCML for AI-driven diagnostic and surgical guidance applications", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Training deep learning models for corneal optical coherence tomography (OCT) imaging is limited by the availability of large, well-annotated datasets. We present a configurable Monte Carlo simulation framework that generates synthetic corneal B-scan optical OCT images with pixel-level five-layer segmentation labels derived directly from the simulation geometry. A five-layer corneal model with Gaussian surfaces captures curvature and thickness variability in healthy and keratoconic eyes. Each layer is assigned optical properties from the literature and light transport is simulated using Monte Carlo modeling of light transport in multi-layered tissues (MCML), while incorporating system features such as the confocal PSF and sensitivity roll-off. This approach produces over 10,000 high-resolution (1024x1024) image-label pairs and supports customization of geometry, photon count, noise, and system parameters. The resulting dataset enables systematic training, validation, and benchmarking of AI models under controlled, ground-truth conditions, providing a reproducible and scalable resource to support the development of diagnostic and surgical guidance applications in image-guided ophthalmology.", "AI": {"tldr": "本文提出了一种基于物理的蒙特卡洛模拟框架，用于生成角膜光学相干断层扫描（OCT）图像的数据集。", "motivation": "深度学习模型在训练过程中受限于大而高质量标注数据集的可用性。为此，需要开发一种可以生成大量合成数据的方法来支持诊断和手术指导应用的发展。", "method": "使用五层角膜模型结合高斯表面以捕捉健康及圆锥角膜眼睛中的曲率与厚度变化，并赋予每层光学特性，通过蒙特卡洛模拟光传输过程来创建图像。该方法还包括系统特征如共焦点扩散函数（PSF）和灵敏度下降。", "result": "生成了超过10,000对高分辨率图像标签对，支持几何、光子计数、噪声及系统参数的定制化配置，为AI模型提供了可再现性和规模化的资源。", "conclusion": "该方法可以提供用于训练、验证和基准测试AI模型的可控且真实的条件，推动了基于影像引导的眼科诊断与手术指导应用的发展。"}}
{"id": "2602.02751", "pdf": "https://arxiv.org/pdf/2602.02751", "abs": "https://arxiv.org/abs/2602.02751", "authors": ["Lisa Alazraki", "William F. Shen", "Yoram Bachrach", "Akhil Mathur"], "title": "Scaling Small Agents Through Strategy Auctions", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": null, "summary": "Small language models are increasingly viewed as a promising, cost-effective approach to agentic AI, with proponents claiming they are sufficiently capable for agentic workflows. However, while smaller agents can closely match larger ones on simple tasks, it remains unclear how their performance scales with task complexity, when large models become necessary, and how to better leverage small agents for long-horizon workloads. In this work, we empirically show that small agents' performance fails to scale with task complexity on deep search and coding tasks, and we introduce Strategy Auctions for Workload Efficiency (SALE), an agent framework inspired by freelancer marketplaces. In SALE, agents bid with short strategic plans, which are scored by a systematic cost-value mechanism and refined via a shared auction memory, enabling per-task routing and continual self-improvement without training a separate router or running all models to completion. Across deep search and coding tasks of varying complexity, SALE reduces reliance on the largest agent by 53%, lowers overall cost by 35%, and consistently improves upon the largest agent's pass@1 with only a negligible overhead beyond executing the final trace. In contrast, established routers that rely on task descriptions either underperform the largest agent or fail to reduce cost -- often both -- underscoring their poor fit for agentic workflows. These results suggest that while small agents may be insufficient for complex workloads, they can be effectively \"scaled up\" through coordinated task allocation and test-time self-improvement. More broadly, they motivate a systems-level view of agentic AI in which performance gains come less from ever-larger individual models and more from market-inspired coordination mechanisms that organize heterogeneous agents into efficient, adaptive ecosystems.", "AI": {"tldr": "本文提出了一种名为SALE的框架，通过策略拍卖机制提高小型代理在复杂任务中的性能和效率。", "motivation": "解决小模型在面对复杂任务时的能力瓶颈问题，并探索如何更有效地利用这些小模型来执行长周期工作负载。", "method": "引入一种基于自由职业者市场的代理人框架SALE，该框架允许代理商通过策略拍卖进行竞标并共享记忆以实现按任务路由和持续自我改进。", "result": "相比于现有路由器方法，SALE减少了对大型代理的依赖53%，降低了总体成本35%，并在复杂搜索和编程任务中表现优于最大代理。", "conclusion": "研究表明，虽然小型模型在处理复杂工作负载时可能不足，但可以通过协调的任务分配和运行时自我改进来有效提升性能，并提出了一种系统级别的观点来组织异构代理人形成高效的自适应生态系统。"}}
{"id": "2602.02745", "pdf": "https://arxiv.org/pdf/2602.02745", "abs": "https://arxiv.org/abs/2602.02745", "authors": ["Minyi Wang", "Christoph Bartneck", "Michael-John Turp", "David Kaber"], "title": "Ethical Asymmetry in Human-Robot Interaction - An Empirical Test of Sparrow's Hypothesis", "categories": ["cs.HC", "cs.RO"], "comment": "27 pages, 3 figures", "summary": "The ethics of human-robot interaction (HRI) have been discussed extensively based on three traditional frameworks: deontology, consequentialism, and virtue ethics. We conducted a mixed within/between experiment to investigate Sparrow's proposed ethical asymmetry hypothesis in human treatment of robots. The moral permissibility of action (MPA) was manipulated as a subject grouping variable, and virtue type (prudence, justice, courage, and temperance) was controlled as a within-subjects factor. We tested moral stimuli using an online questionnaire with Perceived Moral Permissibility of Action (PMPA) and Perceived Virtue Scores (PVS) as response measures. The PVS measure was based on an adaptation of the established Questionnaire on Cardinal Virtues (QCV), while the PMPA was based on Malle et al. [39] work. We found that the MPA significantly influenced the PMPA and perceived virtue scores. The best-fitting model to describe the relationship between PMPA and PVS was cubic, which is symmetrical in nature. Our study did not confirm Sparrow's asymmetry hypothesis. The adaptation of the QCV is expected to have utility for future studies, pending additional psychometric property assessments.", "AI": {"tldr": "研究通过实验证明了人类对待机器人的道德行为是否与Sparrow提出的不对称假设相符。", "motivation": "探讨在人机交互中，是否存在一种伦理上的不对称性，即人类对机器人和人类的行为是否遵循不同的道德标准。", "method": "设计了一项混合实验来测试Sparrow的假设。使用道德允许度（MPA）作为分组变量，同时控制四种美德类型：审慎、正义、勇气和节制。通过在线问卷收集参与者对于特定行为的道德许可性和美德评分的数据。", "result": "发现MPA对PMPA和感知美德分数有显著影响。然而，数据的最佳拟合模型是立方且对称的，并未支持Sparrow提出的不对称假设。", "conclusion": "研究表明，在人类与机器人交互的过程中没有观察到明显的伦理不对称性，这挑战了之前的理论假设。"}}
{"id": "2602.02743", "pdf": "https://arxiv.org/pdf/2602.02743", "abs": "https://arxiv.org/abs/2602.02743", "authors": ["Fahim Arsad Nafis", "Jie Li", "Simon Su", "Songqing Chen", "Bo Han"], "title": "Exploring Collaborative Immersive Visualization & Analytics for High-Dimensional Scientific Data through Domain Expert Perspectives", "categories": ["cs.HC"], "comment": "Conditionally accepted at the Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI 26)", "summary": "Cross-disciplinary teams increasingly work with high-dimensional scientific datasets, yet fragmented toolchains and limited support for shared exploration hinder collaboration. Prior immersive visualization and analytics research has emphasized individual interaction, leaving open how multi-user collaboration can be supported at scale. To fill this critical gap, we conduct semi-structured interviews with 20 domain experts from diverse academic, government, and industry backgrounds. Using deductive-inductive hybrid thematic analysis, we identify four collaboration-focused themes: workflow challenges, adoption perceptions, prospective features, and anticipated usability and ethical risks. These findings show how current ecosystems disrupt coordination and shared understanding, while highlighting opportunities for effective multi-user engagement. Our study contributes empirical insights into collaboration practices for high-dimensional scientific data visualization and analysis, offering design implications to enhance coordination, mutual awareness, and equitable participation in next-generation collaborative immersive platforms. These contributions point toward future environments enabling distributed, cross-device teamwork on high-dimensional scientific data.", "AI": {"tldr": "通过领域专家的视角，探索高维科学数据的协作沉浸式可视化与分析。", "motivation": "跨学科团队在处理高维科学数据时面临着工具链碎片化和共享探索支持不足的问题。当前的研究主要集中在个体交互上，缺乏对大规模多用户合作的支持。", "method": "进行了20次半结构化的专家访谈，并使用演绎-归纳混合主题分析方法，识别了四个协作相关主题：工作流程挑战、采用感知、预期功能以及预想的可用性和伦理风险。", "result": "发现当前生态系统在协调和共享理解方面存在障碍，同时突出了多用户有效参与的机会。研究为高维科学数据可视化与分析的协作实践提供了实证见解，并提出了设计启示以增强协调、互知和公平参与。", "conclusion": "该研究指明了未来环境的发展方向，这些环境将支持分布式跨设备团队在高维科学数据上的合作。"}}
{"id": "2602.02742", "pdf": "https://arxiv.org/pdf/2602.02742", "abs": "https://arxiv.org/abs/2602.02742", "authors": ["Zihao Jing", "Qiuhao Zeng", "Ruiyi Fang", "Yan Sun", "Boyu Wang", "Pingzhao Hu"], "title": "Entropy-Guided Dynamic Tokens for Graph-LLM Alignment in Molecular Understanding", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Molecular understanding is central to advancing areas such as scientific discovery, yet Large Language Models (LLMs) struggle to understand molecular graphs effectively. Existing graph-LLM bridges often adapt the Q-Former-style connector with fixed-length static tokens, which is originally designed for vision tasks. These designs overlook stereochemistry and substructural context and typically require costly LLM-backbone fine-tuning, limiting efficiency and generalization. We introduce EDT-Former, an Entropy-guided Dynamic Token Transformer that generates tokens aligned with informative molecular patches, thereby preserving both local and global structural features for molecular graph understanding. Beyond prior approaches, EDT-Former enables alignment between frozen graph encoders and LLMs without tuning the LLM backbone (excluding the embedding layer), resulting in computationally efficient finetuning, and achieves stateof-the-art results on MoleculeQA, Molecule-oriented Mol-Instructions, and property prediction benchmarks (TDC, MoleculeNet), underscoring its effectiveness for scalable and generalizable multimodal molecular understanding", "AI": {"tldr": "该论文提出了一种基于熵引导的动态令牌变压器EDT-Former，用于分子图与大型语言模型之间的对齐。", "motivation": "现有方法采用固定的静态令牌来连接图形编码器和LLM，这种方式忽略了立体化学和子结构上下文，并且需要昂贵的LLM骨干微调过程，限制了效率和泛化能力。", "method": "提出了一种新的分子图理解模型EDT-Former，它通过生成与信息丰富的分子补丁对齐的令牌来保持局部和全局结构特征。", "result": "该方法在MoleculeQA、Mol-Instructions等任务上取得了最先进的性能，并且可以实现高效的微调过程。", "conclusion": "EDT-Former提供了一种无需调整LLM骨干便能有效进行分子图理解的方法，表明了其在多模态分子理解中的可扩展性和泛化能力。"}}
{"id": "2602.02741", "pdf": "https://arxiv.org/pdf/2602.02741", "abs": "https://arxiv.org/abs/2602.02741", "authors": ["Anmol Gupta", "Weiwei Gu", "Omkar Patil", "Jun Ki Lee", "Nakul Gopalan"], "title": "PokeNet: Learning Kinematic Models of Articulated Objects from Human Observations", "categories": ["cs.RO"], "comment": null, "summary": "Articulation modeling enables robots to learn joint parameters of articulated objects for effective manipulation which can then be used downstream for skill learning or planning. Existing approaches often rely on prior knowledge about the objects, such as the number or type of joints. Some of these approaches also fail to recover occluded joints that are only revealed during interaction. Others require large numbers of multi-view images for every object, which is impractical in real-world settings. Furthermore, prior works neglect the order of manipulations, which is essential for many multi-DoF objects where one joint must be operated before another, such as a dishwasher. We introduce PokeNet, an end-to-end framework that estimates articulation models from a single human demonstration without prior object knowledge. Given a sequence of point cloud observations of a human manipulating an unknown object, PokeNet predicts joint parameters, infers manipulation order, and tracks joint states over time. PokeNet outperforms existing state-of-the-art methods, improving joint axis and state estimation accuracy by an average of over 27% across diverse objects, including novel and unseen categories. We demonstrate these gains in both simulation and real-world environments.", "AI": {"tldr": "本文提出PokeNet，一种无需先验知识的端到端框架，通过单个人类演示估计关节参数、推断操作顺序并跟踪随时间变化的关节状态。", "motivation": "现有方法依赖于对象先验知识或大量多视图图像，不能很好地处理被遮挡关节，并且忽视了操作顺序的重要性。为了解决这些问题，本文提出了一种新的方法来估计关节模型，提高机器人在真实场景中的操纵能力。", "method": "PokeNet通过点云观察序列从单个人类演示中估计关节参数、推断操作顺序并跟踪随时间变化的关节状态。它能够处理未知对象，并且无需先验信息即可完成任务。", "result": "实验结果表明，PokeNet在各种对象上的关节轴和状态估计准确率平均提高了27%以上，在模拟和真实环境中均表现优异。", "conclusion": "PokeNet提供了一种新的方法来解决现有技术中的不足，为机器人理解和操纵复杂结构的对象提供了更有效的解决方案。"}}
{"id": "2602.02740", "pdf": "https://arxiv.org/pdf/2602.02740", "abs": "https://arxiv.org/abs/2602.02740", "authors": ["Ned Cooper", "Jose A. Guridi", "Angel Hsing-Chi Hwang", "Beth Kolko", "Beth McGinty", "Qian Yang"], "title": "Framing Responsible Design of AI Mental Well-Being Support: AI as Primary Care, Nutritional Supplement, or Yoga Instructor?", "categories": ["cs.HC", "cs.CY"], "comment": "16 pages, 1 figure, 2 tables. To appear at CHI '26", "summary": "Millions of people now use non-clinical Large Language Model (LLM) tools like ChatGPT for mental well-being support. This paper investigates what it means to design such tools responsibly, and how to operationalize that responsibility in their design and evaluation. By interviewing experts and analyzing related regulations, we found that designing an LLM tool responsibly involves: (1) Articulating the specific benefits it guarantees and for whom. Does it guarantee specific, proven relief, like an over-the-counter drug, or offer minimal guarantees, like a nutritional supplement? (2) Specifying the LLM tool's \"active ingredients\" for improving well-being and whether it guarantees their effective delivery (like a primary care provider) or not (like a yoga instructor). These specifications outline an LLM tool's pertinent risks, appropriate evaluation metrics, and the respective responsibilities of LLM developers, tool designers, and users. These analogies - LLM tools as supplements, drugs, yoga instructors, and primary care providers - can scaffold further conversations about their responsible design.", "AI": {"tldr": "该论文探讨了如何负责任地设计和评估AI心理健康支持工具，并通过专家访谈和相关法规分析，提出了几种类比来帮助理解这些工具有关的责任。", "motivation": "随着越来越多的人使用非临床大型语言模型（LLM）工具如ChatGPT进行心理健康的自我管理和支持，探讨如何在设计和评估这类工具时负责任地履行职责变得至关重要。", "method": "论文通过专家访谈以及对相关法规的分析来研究这一问题，并提出将AI心理健康支持工具类比为非处方药、营养补充剂、瑜伽教练或初级保健提供者的方法。", "result": "研究确定了设计和评估负责人的LLM工具需要明确其特定优势及其目标用户，同时指出这些工具的潜在风险以及相应的责任分配。", "conclusion": "通过将AI心理健康支持工具有比为药物、营养补充剂、瑜伽教练或初级保健提供者，可以促进有关此类工具负责任设计的进一步讨论。"}}
{"id": "2602.02739", "pdf": "https://arxiv.org/pdf/2602.02739", "abs": "https://arxiv.org/abs/2602.02739", "authors": ["Arjun Roy", "Prajna G. Malettira", "Manish Nagaraj", "Kaushik Roy"], "title": "TopoPrune: Robust Data Pruning via Unified Latent Space Topology", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint. Under Review", "summary": "Geometric data pruning methods, while practical for leveraging pretrained models, are fundamentally unstable. Their reliance on extrinsic geometry renders them highly sensitive to latent space perturbations, causing performance to degrade during cross-architecture transfer or in the presence of feature noise. We introduce TopoPrune, a framework which resolves this challenge by leveraging topology to capture the stable, intrinsic structure of data. TopoPrune operates at two scales, (1) utilizing a topology-aware manifold approximation to establish a global low-dimensional embedding of the dataset. Subsequently, (2) it employs differentiable persistent homology to perform a local topological optimization on the manifold embeddings, ranking samples by their structural complexity. We demonstrate that our unified dual-scale topological approach ensures high accuracy and precision, particularly at significant dataset pruning rates (e.g., 90%). Furthermore, through the inherent stability properties of topology, TopoPrune is (a) exceptionally robust to noise perturbations of latent feature embeddings and (b) demonstrates superior transferability across diverse network architectures. This study demonstrates a promising avenue towards stable and principled topology-based frameworks for robust data-efficient learning.", "AI": {"tldr": "该论文提出了一种基于拓扑的数据剪枝框架TopoPrune，旨在通过捕获数据的内在结构来提高数据剪枝的稳定性。", "motivation": "当前的几何数据剪枝方法对潜在空间扰动敏感，导致在跨架构传输或特征噪声存在时性能下降。作者希望通过利用拓扑学捕获稳定、内在的数据结构，解决这一问题。", "method": "TopoPrune采用双尺度的方法：首先使用拓扑感知流形逼近建立数据集的全局低维嵌入；然后通过可微分持久同调在流形嵌入上进行局部拓扑优化，并根据样本的结构复杂性对其进行排序。", "result": "实验结果表明，TopoPrune能够以高准确性和精度实现显著的数据集剪枝率（如90%），并且对特征嵌入噪声具有很强的鲁棒性以及跨网络架构的优越迁移能力。", "conclusion": "该研究展示了基于拓扑学框架进行稳健且原理性的数据高效学习的一个有希望的方向。"}}
{"id": "2602.02738", "pdf": "https://arxiv.org/pdf/2602.02738", "abs": "https://arxiv.org/abs/2602.02738", "authors": ["Xiaosha Li", "Chun Liu", "Ziyu Wang"], "title": "When Noise Lowers The Loss: Rethinking Likelihood-Based Evaluation in Music Large Language Models", "categories": ["cs.SD", "cs.AI"], "comment": "Accepted by IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026", "summary": "The rise of music large language models (LLMs) demands robust methods of evaluating output quality, especially in distinguishing high-quality compositions from \"garbage music\". Curiously, we observe that the standard cross-entropy loss -- a core training metric -- often decrease when models encounter systematically corrupted music, undermining its validity as a standalone quality indicator. To investigate this paradox, we introduce noise injection experiment, where controlled noise signal of varying lengths are injected into musical contexts. We hypothesize that a model's loss reacting positively to these perturbations, specifically a sharp increase (\"Peak\" area) for short injection, can serve as a proxy for its ability to discern musical integrity. Experiments with MusicGen models in the audio waveform domain confirm that Music LLMs respond more strongly to local, texture-level disruptions than to global semantic corruption. Beyond exposing this bias, our results highlight a new principle: the shape of the loss curve -- rather than its absolute value -- encodes critical information about the quality of the generated content (i.e., model behavior). We envision this profile-based evaluation as a label-free, model-intrinsic framework for assessing musical quality -- opening the door to more principled training objectives and sharper benchmarks.", "AI": {"tldr": "研究探索了音乐大语言模型在面对系统性噪音时，损失函数行为的变化，并提出了一种基于损失曲线形状评估生成内容质量的新方法。", "motivation": "标准交叉熵损失作为训练指标，在遇到系统性损坏的音乐时会降低，这削弱了它独立表示输出质量的能力。研究旨在探索这一现象背后的原因和潜在解决方案。", "method": "通过引入噪音注入实验，将不同长度的可控噪声信号插入到音乐上下文中，观察模型反应，并提出损失曲线形状作为评估生成内容的新指标。", "result": "实验表明，模型对局部纹理级别的干扰比全局语义上的损坏更为敏感。此外，损失曲线的变化可以反映生成内容的质量和模型行为特征。", "conclusion": "基于损失曲线的轮廓式评估方法为无标签、内嵌式的音乐质量评价提供了新途径，有望促进更科学的训练目标设定和性能基准制定。"}}
{"id": "2602.02734", "pdf": "https://arxiv.org/pdf/2602.02734", "abs": "https://arxiv.org/abs/2602.02734", "authors": ["Abdoulaye Diack", "Perry Nelson", "Kwaku Agbesi", "Angela Nakalembe", "MohamedElfatih MohamedKhair", "Vusumuzi Dube", "Tavonga Siyavora", "Subhashini Venugopalan", "Jason Hickey", "Uche Okonkwo", "Abhishek Bapna", "Isaac Wiafe", "Raynard Dodzi Helegah", "Elikem Doe Atsakpo", "Charles Nutrokpor", "Fiifi Baffoe Payin Winful", "Kafui Kwashie Solaga", "Jamal-Deen Abdulai", "Akon Obu Ekpezu", "Audace Niyonkuru", "Samuel Rutunda", "Boris Ishimwe", "Michael Melese", "Engineer Bainomugisha", "Joyce Nakatumba-Nabende", "et al. (18 additional authors not shown)"], "title": "WAXAL: A Large-Scale Multilingual African Language Speech Corpus", "categories": ["eess.AS", "cs.AI", "cs.CL"], "comment": "Initial dataset release", "summary": "The advancement of speech technology has predominantly favored high-resource languages, creating a significant digital divide for speakers of most Sub-Saharan African languages. To address this gap, we introduce WAXAL, a large-scale, openly accessible speech dataset for 21 languages representing over 100 million speakers. The collection consists of two main components: an Automated Speech Recognition (ASR) dataset containing approximately 1,250 hours of transcribed, natural speech from a diverse range of speakers, and a Text-to-Speech (TTS) dataset with over 180 hours of high-quality, single-speaker recordings reading phonetically balanced scripts. This paper details our methodology for data collection, annotation, and quality control, which involved partnerships with four African academic and community organizations. We provide a detailed statistical overview of the dataset and discuss its potential limitations and ethical considerations. The WAXAL datasets are released at https://huggingface.co/datasets/google/WaxalNLP under the permissive CC-BY-4.0 license to catalyze research, enable the development of inclusive technologies, and serve as a vital resource for the digital preservation of these languages.", "AI": {"tldr": "介绍WAXAL，一个涵盖非洲21种语言的大型多语种语音数据集。", "motivation": "弥补非洲地区高资源语言与低资源语言在语音技术发展上的差距，促进包容性技术的发展和这些语言的数字化保护。", "method": "通过与四个非洲学术及社区组织合作收集并标注高质量的自然语音和单声道录音，并提供详细的数据统计以及质量控制方法。", "result": "发布了一个包含大约1250小时转录后的自然语音和超过180小时高音质单声道录音的数据集，以催化相关研究的发展。", "conclusion": "WAXAL数据集的发布旨在推动包容性技术的进步，并作为保护非洲语言的重要资源。"}}
{"id": "2602.02731", "pdf": "https://arxiv.org/pdf/2602.02731", "abs": "https://arxiv.org/abs/2602.02731", "authors": ["Rohan Pandey", "Haijuan Yan", "Hong Yu", "Jack Tsai"], "title": "Predicting first-episode homelessness among US Veterans using longitudinal EHR data: time-varying models and social risk factors", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Homelessness among US veterans remains a critical public health challenge, yet risk prediction offers a pathway for proactive intervention. In this retrospective prognostic study, we analyzed electronic health record (EHR) data from 4,276,403 Veterans Affairs patients during a 2016 observation period to predict first-episode homelessness occurring 3-12 months later in 2017 (prevalence: 0.32-1.19%). We constructed static and time-varying EHR representations, utilizing clinician-informed logic to model the persistence of clinical conditions and social risks over time. We then compared the performance of classical machine learning, transformer-based masked language models, and fine-tuned large language models (LLMs). We demonstrate that incorporating social and behavioral factors into longitudinal models improved precision-recall area under the curve (PR-AUC) by 15-30%. In the top 1% risk tier, models yielded positive predictive values ranging from 3.93-4.72% at 3 months, 7.39-8.30% at 6 months, 9.84-11.41% at 9 months, and 11.65-13.80% at 12 months across model architectures. Large language models underperformed encoder-based models on discrimination but showed smaller performance disparities across racial groups. These results demonstrate that longitudinal, socially informed EHR modeling concentrates homelessness risk into actionable strata, enabling targeted and data-informed prevention strategies for at-risk veterans.", "AI": {"tldr": "使用纵向电子健康记录数据预测美国退伍军人首次无家可归的风险。", "motivation": "解决无家可归的公共卫生成为挑战，风险预测可以提供预防干预的方法。", "method": "构建了静态和时间变化的数据表示，并比较经典机器学习、基于转换器的语言模型以及微调的大规模语言模型的性能。引入社会行为因素提高了模型精度。", "result": "在高风险群体中，模型实现了3个月至12个月内不同比例的阳性预测值。大规模语言模型虽然歧视性较低，但总体上表现不如编码器模型。", "conclusion": "纵向、社会信息丰富的电子健康记录建模可以集中无家可归的风险，在退伍军人预防策略中提供数据支持。"}}
{"id": "2602.02730", "pdf": "https://arxiv.org/pdf/2602.02730", "abs": "https://arxiv.org/abs/2602.02730", "authors": ["Fam Shihata", "Mohammed Abdelazim", "Ahmed Hussein"], "title": "AROLA: A Modular Layered Architecture for Scaled Autonomous Racing", "categories": ["cs.RO", "cs.SE"], "comment": "6 pages, 6 figures, IV 2026", "summary": "Autonomous racing has advanced rapidly, particularly on scaled platforms, and software stacks must evolve accordingly. In this work, AROLA is introduced as a modular, layered software architecture in which fragmented and monolithic designs are reorganized into interchangeable layers and components connected through standardized ROS 2 interfaces. The autonomous-driving pipeline is decomposed into sensing, pre-processing, perception, localization and mapping, planning, behavior, control, and actuation, enabling rapid module replacement and objective benchmarking without reliance on custom message definitions. To support consistent performance evaluation, a Race Monitor framework is introduced as a lightweight system through which lap timing, trajectory quality, and computational load are logged in real time and standardized post-race analyses are generated. AROLA is validated in simulation and on hardware using the RoboRacer platform, including deployment at the 2025 RoboRacer IV25 competition. Together, AROLA and Race Monitor demonstrate that modularity, transparent interfaces, and systematic evaluation can accelerate development and improve reproducibility in scaled autonomous racing.", "AI": {"tldr": "AROLA 是一个模块化分层软件架构，用于规模化自主赛车。它将碎片化和单一设计重构为通过标准 ROS 2 接口连接的可互换层次和组件。", "motivation": "为了适应自主赛车的发展需求，特别是在小型平台上，作者提出了 AROLA 架构以提高模块替换速度并进行客观基准测试。", "method": "AROLA 将自动驾驶管道分解为传感、预处理、感知、定位与建图、规划、行为、控制和执行等可互换层。Race Monitor 框架用于实时记录圈速、轨迹质量和计算负载，并生成标准化的赛后分析。", "result": "该架构在仿真环境中以及使用 RoboRacer 平台进行了验证，包括在2025年RoboRacer IV25竞赛中的部署。", "conclusion": "AROLA 和 Race Monitor 的结合表明模块化、透明接口和系统评估可以加速开发并提高规模化自主赛车的可重复性。"}}
{"id": "2602.02729", "pdf": "https://arxiv.org/pdf/2602.02729", "abs": "https://arxiv.org/abs/2602.02729", "authors": ["Viresh Pati", "Yubin Kim", "Vinh Pham", "Jevon Twitty", "Shihao Yang", "Jiecheng Lu"], "title": "CAPS: Unifying Attention, Recurrence, and Alignment in Transformer-based Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents $\\textbf{CAPS}$ (Clock-weighted Aggregation with Prefix-products and Softmax), a structured attention mechanism for time series forecasting that decouples three distinct temporal structures: global trends, local shocks, and seasonal patterns. Standard softmax attention entangles these through global normalization, while recent recurrent models sacrifice long-term, order-independent selection for order-dependent causal structure. CAPS combines SO(2) rotations for phase alignment with three additive gating paths -- Riemann softmax, prefix-product gates, and a Clock baseline -- within a single attention layer. We introduce the Clock mechanism, a learned temporal weighting that modulates these paths through a shared notion of temporal importance. Experiments on long- and short-term forecasting benchmarks surpass vanilla softmax and linear attention mechanisms and demonstrate competitive performance against seven strong baselines with linear complexity. Our code implementation is available at https://github.com/vireshpati/CAPS-Attention.", "AI": {"tldr": "本文提出了CAPS，一种用于时间序列预测的结构化注意力机制。", "motivation": "标准softmax注意力通过全局归一化纠缠了全球趋势、局部冲击和季节性模式这三种不同的时间结构，而近期的递归模型则牺牲长期独立选择以获得顺序依赖因果结构。本文旨在解决这些问题，并提出CAPS来统一这些不同的时间结构。", "method": "CAPS结合SO(2)旋转实现相位对齐，并在单个注意力层中引入三个加性门控路径——黎曼softmax、前缀乘积门和时钟基准，同时通过共享的时序重要性概念调节这些路径。", "result": "实验结果表明，在长短期预测基准测试中，CAPS的表现优于纯softmax和线性注意力机制，并且在七种强基线方法中具有竞争力。", "conclusion": "本文提出的CAPS不仅实现了对时间序列的更精细处理，还在保持线性复杂度的同时提高了预测性能。"}}
{"id": "2602.02727", "pdf": "https://arxiv.org/pdf/2602.02727", "abs": "https://arxiv.org/abs/2602.02727", "authors": ["Huu Binh Ta", "Michael Cardei", "Alvaro Velasquez", "Ferdinando Fioretto"], "title": "Search-Augmented Masked Diffusion Models for Constrained Generation", "categories": ["cs.LG", "cs.AI"], "comment": "Huu Binh Ta and Michael Cardei contributed equally to this work", "summary": "Discrete diffusion models generate sequences by iteratively denoising samples corrupted by categorical noise, offering an appealing alternative to autoregressive decoding for structured and symbolic generation. However, standard training targets a likelihood-based objective that primarily matches the data distribution and provides no native mechanism for enforcing hard constraints or optimizing non-differentiable properties at inference time. This work addresses this limitation and introduces Search-Augmented Masked Diffusion (SearchDiff), a training-free neurosymbolic inference framework that integrates informed search directly into the reverse denoising process. At each denoising step, the model predictions define a proposal set that is optimized under a user-specified property satisfaction, yielding a modified reverse transition that steers sampling toward probable and feasible solutions. Experiments in biological design and symbolic reasoning illustrate that SearchDiff substantially improves constraint satisfaction and property adherence, while consistently outperforming discrete diffusion and autoregressive baselines.", "AI": {"tldr": "论文提出了一种新的无训练神经符号推理框架SearchDiff，用于在受限生成任务中提高约束满足和属性一致性的性能。", "motivation": "标准的离散扩散模型主要针对似然度目标进行优化，在推断时无法自然地强制执行硬性约束或优化非可微分属性。因此，作者提出了SearchDiff框架来解决这一限制问题。", "method": "在逆向去噪过程中集成知情搜索，通过用户指定的属性满意度优化模型预测定义的提议集，生成修改后的逆向转移过程以引导采样朝向可能和可行解的方向前进。", "result": "实验表明，SearchDiff显著提高了约束满足度和属性一致性，并且始终优于离散扩散和自回归基线方法。", "conclusion": "通过直接将知情搜索整合到去噪过程中，SearchDiff框架在受限生成任务中取得了更好的性能。"}}
{"id": "2602.02725", "pdf": "https://arxiv.org/pdf/2602.02725", "abs": "https://arxiv.org/abs/2602.02725", "authors": ["Jade Chng", "Rong Xing", "Yunfei Luo", "Kristen Linnemeyer-Risser", "Tauhidur Rahman", "Andrew Yousef", "Philip A Weissbrod"], "title": "Automated Dysphagia Screening Using Noninvasive Neck Acoustic Sensing", "categories": ["cs.LG", "cs.SD", "eess.AS", "eess.SP"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Pharyngeal health plays a vital role in essential human functions such as breathing, swallowing, and vocalization. Early detection of swallowing abnormalities, also known as dysphagia, is crucial for timely intervention. However, current diagnostic methods often rely on radiographic imaging or invasive procedures. In this study, we propose an automated framework for detecting dysphagia using portable and noninvasive acoustic sensing coupled with applied machine learning. By capturing subtle acoustic signals from the neck during swallowing tasks, we aim to identify patterns associated with abnormal physiological conditions. Our approach achieves promising test-time abnormality detection performance, with an AUC-ROC of 0.904 under 5 independent train-test splits. This work demonstrates the feasibility of using noninvasive acoustic sensing as a practical and scalable tool for pharyngeal health monitoring.", "AI": {"tldr": "使用非侵入性声学传感和机器学习自动检测吞咽障碍。", "motivation": "早期发现吞咽异常（即吞咽困难）对于及时干预至关重要，当前的诊断方法通常依赖于放射成像或侵入性程序。", "method": "通过颈部吞咽任务期间捕捉细微的声学信号来识别与异常生理条件相关的模式。采用便携式非侵入性声学传感结合应用机器学习的方法。", "result": "在5次独立训练-测试拆分下，测试时异常检测性能达到了AUC-ROC 0.904。", "conclusion": "证明了使用非侵入性声学传感作为咽喉健康监测的实用和可扩展工具的可行性"}}
{"id": "2602.02724", "pdf": "https://arxiv.org/pdf/2602.02724", "abs": "https://arxiv.org/abs/2602.02724", "authors": ["Wojciech Achtelik", "Hubert Guzowski", "Maciej Smołka", "Jacek Mańdziuk"], "title": "Automatic Design of Optimization Test Problems with Large Language Models", "categories": ["cs.NE"], "comment": null, "summary": "The development of black-box optimization algorithms depends on the availability of benchmark suites that are both diverse and representative of real-world problem landscapes. Widely used collections such as BBOB and CEC remain dominated by hand-crafted synthetic functions and provide limited coverage of the high-dimensional space of Exploratory Landscape Analysis (ELA) features, which in turn biases evaluation and hinders training of meta-black-box optimizers. We introduce Evolution of Test Functions (EoTF), a framework that automatically generates continuous optimization test functions whose landscapes match a specified target ELA feature vector. EoTF adapts LLM-driven evolutionary search, originally proposed for heuristic discovery, to evolve interpretable, self-contained numpy implementations of objective functions by minimizing the distance between sampled ELA features of generated candidates and a target profile. In experiments on 24 noiseless BBOB functions and a contamination-mitigating suite of 24 MA-BBOB hybrid functions, EoTF reliably produces non-trivial functions with closely matching ELA characteristics and preserves optimizer performance rankings under fixed evaluation budgets, supporting their validity as surrogate benchmarks. While a baseline neural-network-based generator achieves higher accuracy in 2D, EoTF substantially outperforms it in 3D and exhibits stable solution quality as dimensionality increases, highlighting favorable scalability. Overall, EoTF offers a practical route to scalable, portable, and interpretable benchmark generation targeted to desired landscape properties.", "AI": {"tldr": "该论文提出了EoTF框架，利用大型语言模型自动生成满足特定探索性景观分析特征目标的优化测试函数。", "motivation": "当前基准套件如BBOB和CEC主要由手工设计的合成函数组成，这些函数无法充分覆盖高维空间中的ELA特性，从而导致评估偏差并阻碍元黑盒优化器的训练。", "method": "EoTF框架采用LLM驱动的进化搜索来生成满足特定目标ELA特征向量的可解释、自包含numpy实现的目标函数，通过最小化生成候选体与目标特征之间的距离。", "result": "实验表明，EoTF在24个无噪声BBOB函数和MA-BBOB混合套件中的表现可靠，并且随着维度增加仍能保持稳定的解质量。", "conclusion": "该框架提供了一种实用的途径来生成可扩展、便携和解释性的基准测试函数，以满足特定景观属性的要求。"}}
{"id": "2602.02722", "pdf": "https://arxiv.org/pdf/2602.02722", "abs": "https://arxiv.org/abs/2602.02722", "authors": ["Dan Haramati", "Carl Qi", "Tal Daniel", "Amy Zhang", "Aviv Tamar", "George Konidaris"], "title": "Hierarchical Entity-centric Reinforcement Learning with Factored Subgoal Diffusion", "categories": ["cs.LG", "cs.CV", "cs.RO"], "comment": "ICLR 2026", "summary": "We propose a hierarchical entity-centric framework for offline Goal-Conditioned Reinforcement Learning (GCRL) that combines subgoal decomposition with factored structure to solve long-horizon tasks in domains with multiple entities. Achieving long-horizon goals in complex environments remains a core challenge in Reinforcement Learning (RL). Domains with multiple entities are particularly difficult due to their combinatorial complexity. GCRL facilitates generalization across goals and the use of subgoal structure, but struggles with high-dimensional observations and combinatorial state-spaces, especially under sparse reward. We employ a two-level hierarchy composed of a value-based GCRL agent and a factored subgoal-generating conditional diffusion model. The RL agent and subgoal generator are trained independently and composed post hoc through selective subgoal generation based on the value function, making the approach modular and compatible with existing GCRL algorithms. We introduce new variations to benchmark tasks that highlight the challenges of multi-entity domains, and show that our method consistently boosts performance of the underlying RL agent on image-based long-horizon tasks with sparse rewards, achieving over 150% higher success rates on the hardest task in our suite and generalizing to increasing horizons and numbers of entities. Rollout videos are provided at: https://sites.google.com/view/hecrl", "AI": {"tldr": "提出了一种层次化的实体中心框架，结合了子目标分解和因子结构，以解决多实体复杂环境中的长时间任务。", "motivation": "在具有多个实体的复杂环境中实现长时间目标是强化学习的核心挑战。现有的GCRL方法虽然有助于跨目标泛化并使用子目标结构，但在高维观察和组合状态空间中特别是在稀疏奖励下存在困难。", "method": "采用两级层次结构，由基于价值的目标导向型强化学习代理与因子化的子目标生成条件扩散模型组成。通过选择性生成子目标来结合RL代理和子目标生成器，该方法在现有GCRL算法上是模块化且兼容的。", "result": "在图像基础长时任务中，所提方法显著提高了稀疏奖励下底层RL代理的成功率，在最困难的任务中成功率超过150%，并且能适应增加的时间跨度和实体数量。", "conclusion": "新框架通过结合层次结构、子目标生成与价值函数的模块化设计，有效解决了多实体复杂环境中的长时任务问题。"}}
{"id": "2602.02721", "pdf": "https://arxiv.org/pdf/2602.02721", "abs": "https://arxiv.org/abs/2602.02721", "authors": ["Jinglun Yu", "Yaning Wang", "Wenhan Guo", "Yuan Gao", "Yu Sun", "Jin U. Kang"], "title": "End-to-end reconstruction of OCT optical properties and speckle-reduced structural intensity via physics-based learning", "categories": ["cs.CV"], "comment": null, "summary": "Inverse scattering in optical coherence tomography (OCT) seeks to recover both structural images and intrinsic tissue optical properties, including refractive index, scattering coefficient, and anisotropy. This inverse problem is challenging due to attenuation, speckle noise, and strong coupling among parameters. We propose a regularized end-to-end deep learning framework that jointly reconstructs optical parameter maps and speckle-reduced OCT structural intensity for layer visualization. Trained with Monte Carlo-simulated ground truth, our network incorporates a physics-based OCT forward model that generates predicted signals from the estimated parameters, providing physics-consistent supervision for parameter recovery and artifact suppression. Experiments on the synthetic corneal OCT dataset demonstrate robust optical map recovery under noise, improved resolution, and enhanced structural fidelity. This approach enables quantitative multi-parameter tissue characterization and highlights the benefit of combining physics-informed modeling with deep learning for computational OCT.", "AI": {"tldr": "提出了一种基于物理的深度学习框架，用于联合重建光学参数图和减少斑点噪声的OCT结构强度。", "motivation": "解决OCT中由于衰减、斑点噪声和参数强耦合引起的逆散射问题。", "method": "通过蒙特卡洛模拟的真实数据训练网络，并结合基于物理的OCT前向模型，生成预测信号以提供一致的监督来恢复参数并抑制伪影。", "result": "在合成角膜OCT数据集上展示了稳健的光学图谱恢复、改善的分辨率和增强的结构保真度。", "conclusion": "该方法实现了定量多参数组织表征，并强调了将物理信息建模与深度学习相结合的优势。"}}
{"id": "2602.02713", "pdf": "https://arxiv.org/pdf/2602.02713", "abs": "https://arxiv.org/abs/2602.02713", "authors": ["Namhoon Kim", "Ashwin Pananjady", "Amir Pourmorteza", "Sara Fridovich-Keil"], "title": "Perfusion Imaging and Single Material Reconstruction in Polychromatic Photon Counting CT", "categories": ["physics.med-ph", "cs.CV", "eess.IV"], "comment": "Code is available at https://github.com/voilalab/VI-PRISM", "summary": "Background: Perfusion computed tomography (CT) images the dynamics of a contrast agent through the body over time, and is one of the highest X-ray dose scans in medical imaging. Recently, a theoretically justified reconstruction algorithm based on a monotone variational inequality (VI) was proposed for single material polychromatic photon-counting CT, and showed promising early results at low-dose imaging. Purpose: We adapt this reconstruction algorithm for perfusion CT, to reconstruct the concentration map of the contrast agent while the static background tissue is assumed known; we call our method VI-PRISM (VI-based PeRfusion Imaging and Single Material reconstruction). We evaluate its potential for dose-reduced perfusion CT, using a digital phantom with water and iodine of varying concentration. Methods: Simulated iodine concentrations range from 0.05 to 2.5 mg/ml. The simulated X-ray source emits photons up to 100 keV, with average intensity ranging from $10^5$ down to $10^2$ photons per detector element. The number of tomographic projections was varied from 984 down to 8 to characterize the tradeoff in photon allocation between views and intensity. Results: We compare VI-PRISM against filtered back-projection (FBP), and find that VI-PRISM recovers iodine concentration with error below 0.4 mg/ml at all source intensity levels tested. Even with a dose reduction between 10x and 100x compared to FBP, VI-PRISM exhibits reconstruction quality on par with FBP. Conclusion: Across all photon budgets and angular sampling densities tested, VI-PRISM achieved consistently lower RMSE, reduced noise, and higher SNR compared to filtered back-projection. Even in extremely photon-limited and sparsely sampled regimes, VI-PRISM recovered iodine concentrations with errors below 0.4 mg/ml, showing that VI-PRISM can support accurate and dose-efficient perfusion imaging in photon-counting CT.", "AI": {"tldr": "本文提出了一种基于单调变分不等式的重建算法VI-PRISM，用于单材料多色光子计数CT的灌注成像。", "motivation": "为了降低灌注CT中的辐射剂量，并提高碘对比剂浓度图的质量。", "method": "使用数字模型模拟水和不同浓度的碘溶液。X射线源发出最多100 keV的能量，每探测器单元平均光子数从$10^5$降到$10^2$。采用VI-PRISM算法进行重建并评估其性能。", "result": "VI-PRISM在所有测试的光源强度水平下均能准确恢复碘浓度，误差低于0.4 mg/ml，即使与FBP相比，在降低辐射剂量高达10倍至100倍的情况下也能保持相当的质量。", "conclusion": "无论光子预算或角度采样密度如何，VI-PRISM在所有测试条件下均可达到较低的RMSE、减少噪声和更高的信噪比。即便是在极低光子数量和稀疏样本情况下，VI-PRISM仍能准确恢复碘浓度，表明其支持精确且剂量有效的灌注成像能力。"}}
{"id": "2602.02711", "pdf": "https://arxiv.org/pdf/2602.02711", "abs": "https://arxiv.org/abs/2602.02711", "authors": ["Yuanzhe Li", "Jianing Deng", "Jingtong Hu", "Tianlong Chen", "Song Wang", "Huanrui Yang"], "title": "Dynamic Mix Precision Routing for Efficient Multi-step LLM Interaction", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLM) achieve strong performance in long-horizon decision-making tasks through multi-step interaction and reasoning at test time. While practitioners commonly believe a higher task success rate necessitates the use of a larger and stronger LLM model, multi-step interaction with a large LLM incurs prohibitive inference cost. To address this problem, we explore the use of low-precision quantized LLM in the long-horizon decision-making process. Based on the observation of diverse sensitivities among interaction steps, we propose a dynamic mix-precision routing framework that adaptively selects between high-precision and low-precision LLMs at each decision step. The router is trained via a two-stage pipeline, consisting of KL-divergence-based supervised learning that identifies precision-sensitive steps, followed by Group-Relative Policy Optimization (GRPO) to further improve task success rates. Experiments on ALFWorld demonstrate that our approach achieves a great improvement on accuracy-cost trade-off over single-precision baselines and heuristic routing methods.", "AI": {"tldr": "提出了一种动态混合精度路由框架，以提高长时决策任务中多步LLM交互的效率与准确性。", "motivation": "为了解决使用大型语言模型进行多次交互导致的高昂推理成本问题，通过观察不同步骤对精度敏感度的不同，探索低精度量化语言模型的应用，并提出了动态混合精度路由框架。", "method": "该框架采用两阶段训练管道：第一阶段利用KL散度监督学习识别精度敏感步骤；第二阶段使用群相对策略优化（GRPO）进一步提升任务成功率。实验在ALFWorld数据集上进行，以验证方法的有效性。", "result": "通过与单精度基线和启发式路由法的对比，实验证明了所提框架能够显著改进准确率-成本权衡问题。", "conclusion": "提出的动态混合精度路由框架能够在长时决策任务中有效提高语言模型交互效率和准确性。"}}
{"id": "2602.02709", "pdf": "https://arxiv.org/pdf/2602.02709", "abs": "https://arxiv.org/abs/2602.02709", "authors": ["Ujin Jeon", "Jiyong Kwon", "Madison Ann Sullivan", "Caleb Eunho Lee", "Guang Lin"], "title": "ATLAS : Adaptive Self-Evolutionary Research Agent with Task-Distributed Multi-LLM Supporters", "categories": ["cs.AI"], "comment": null, "summary": "Recent multi-LLM agent systems perform well in prompt optimization and automated problem-solving, but many either keep the solver frozen after fine-tuning or rely on a static preference-optimization loop, which becomes intractable for long-horizon tasks. We propose ATLAS (Adaptive Task-distributed Learning for Agentic Self-evolution), a task-distributed framework that iteratively develops a lightweight research agent while delegating complementary roles to specialized supporter agents for exploration, hyperparameter tuning, and reference policy management. Our core algorithm, Evolving Direct Preference Optimization (EvoDPO), adaptively updates the phase-indexed reference policy. We provide a theoretical regret analysis for a preference-based contextual bandit under concept drift. In addition, experiments were conducted on non-stationary linear contextual bandits and scientific machine learning (SciML) loss reweighting for the 1D Burgers' equation. Both results show that ATLAS improves stability and performance over a static single-agent baseline.", "AI": {"tldr": "提出了一种名为ATLAS的任务分布式框架，该框架在长期任务中通过适应性更新参考策略来优化问题解决。", "motivation": "多LLM代理系统在提示优化和自动化解决问题方面表现出色，但很多系统要么在微调后固定了解决器，要么依赖于静态的偏好优化循环，这使得长时间的任务难以处理。因此，提出了ATLAS框架以适应性地更新参考策略并提高长期任务中的稳定性和性能。", "method": "提出了一种名为Evolving Direct Preference Optimization (EvoDPO)的核心算法，该算法能够迭代开发轻量级研究代理，并将辅助角色分配给专门的支援代理进行探索、超参数调整和引用策略管理。还提供了关于偏好基线上下文多臂赌博机在概念漂移下的理论遗憾分析。", "result": "实验结果显示ATLAS在非平稳线性上下文多臂赌博机和一维Burgers方程损失再加权的科学机器学习任务中，相比静态单代理基准提高了稳定性和性能。", "conclusion": "通过提出适应性的参考策略更新机制，ATLAS框架展示了其在长期复杂任务中的优越表现，并提供了理论支持。"}}
{"id": "2602.02708", "pdf": "https://arxiv.org/pdf/2602.02708", "abs": "https://arxiv.org/abs/2602.02708", "authors": ["Punya Syon Pandey", "Zhijing Jin"], "title": "BinaryPPO: Efficient Policy Optimization for Binary Classification", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Supervised fine-tuning (SFT) is the standard approach for binary classification tasks such as toxicity detection, factuality verification, and causal inference. However, SFT often performs poorly in real-world settings with label noise, class imbalance, or sparse supervision. We introduce BinaryPPO, an offline reinforcement learning large language model (LLM) framework that reformulates binary classification as a reward maximization problem. Our method leverages a variant of Proximal Policy Optimization (PPO) with a confidence-weighted reward function that penalizes uncertain or incorrect predictions, enabling the model to learn robust decision policies from static datasets without online interaction. Across eight domain-specific benchmarks and multiple models with differing architectures, BinaryPPO improves accuracy by 40-60 percentage points, reaching up to 99%, substantially outperforming supervised baselines. We provide an in-depth analysis of the role of reward shaping, advantage scaling, and policy stability in enabling this improvement. Overall, we demonstrate that confidence-based reward design provides a robust alternative to SFT for binary classification. Our code is available at https://github.com/psyonp/BinaryPPO.", "AI": {"tldr": "本文提出了一种用于二元分类任务的高效策略优化方法BinaryPPO，该方法将二元分类问题转化为奖励最大化问题，并通过使用带有置信度加权奖励函数的近端策略优化（PPO）变体来提高模型在静态数据集上的鲁棒性。", "motivation": "监督微调在具有标签噪声、类别不平衡或稀疏监督的真实世界场景中表现不佳，因此本文提出了一种新的方法BinaryPPO，通过将二元分类任务转化为奖励最大化问题，旨在从静态数据集中学习更稳健的决策策略。", "method": "该方法利用近端政策优化（PPO）变体，并设计了一个带有置信度加权奖励函数的方法来惩罚不确定或错误预测。这种方法使模型能够在不进行在线交互的情况下，仅通过静态数据集中的信息学习到更健壮的决策策略。", "result": "在八个领域特定基准上以及不同架构模型中，BinaryPPO相较于监督基线提高了40-60个百分点的准确率，最高达到99%。结果表明了基于置信度奖励设计对于二元分类任务的有效性。", "conclusion": "通过使用基于置信度的设计来优化奖励，BinaryPPO提供了一种比传统监督微调更鲁棒且有效的替代方案，适用于各种二元分类问题。"}}
{"id": "2602.02707", "pdf": "https://arxiv.org/pdf/2602.02707", "abs": "https://arxiv.org/abs/2602.02707", "authors": ["Sayak Chakrabarti", "Toniann Pitassi", "Josh Alman"], "title": "Every Bit Counts: A Theoretical Study of Precision-Expressivity Tradeoffs in Quantized Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantization reduces the numerical precision of Transformer computations and is widely used to accelerate inference, yet its effect on expressivity remains poorly characterized. We demonstrate a fine-grained theoretical tradeoff between expressivity and precision: For every p we exhibit a function Γ, inspired by the equality function, and prove that a one-layer softmax Transformer can compute Γ, with p bits of precision, but not with p-1 bits of precision. This result concretely explains the widely observed phenomenon of empirical loss of expressivity when quantization is used. Practically, it suggests that tasks requiring equality-like comparisons (exact match, membership, etc.) are especially sensitive to quantization. Dropping even one bit can cross a threshold where the model cannot represent the needed comparison reliably. Thus, it paves the way for developing heuristics that will help practitioners choose how much quantization is possible: the precision should be chosen as a function of the length of equality to be checked for the specific task. Our proofs combine explicit finite-precision Transformer constructions with communication-complexity lower bounds, yielding a tight \"one-bit\" threshold.", "AI": {"tldr": "研究量化对Transformer表达能力的影响，展示精度与表达力之间的精细权衡。", "motivation": "量化广泛用于加速Transformer的推理，但其如何影响模型的表达能力却鲜有理论解释。这项工作旨在深入理解这种关系，提供一个清晰的理论框架。", "method": "利用特定函数Γ和softmax层构建的Transformer，证明了在p位精度下能够计算Γ，但在减少一位（即p-1位）时则无法实现。结合具体的有限精度变换器构造与通信复杂度界底限的方法进行分析。", "result": "展示了量化阈值对表达能力的具体影响，表明任务要求高精度比较时尤其敏感于量化过程，并提出了选择适当精度的建议策略。", "conclusion": "通过理论研究揭示了Transformer在不同精度下的表达力边界，为实际应用中的量化决策提供了指导。"}}
{"id": "2602.02699", "pdf": "https://arxiv.org/pdf/2602.02699", "abs": "https://arxiv.org/abs/2602.02699", "authors": ["Wenshuai Zhao", "Zhiyuan Li", "Yi Zhao", "Mohammad Hassan Vali", "Martin Trapp", "Joni Pajarinen", "Juho Kannala", "Arno Solin"], "title": "Sparsely Supervised Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages, 11 figures", "summary": "Diffusion models have shown remarkable success across a wide range of generative tasks. However, they often suffer from spatially inconsistent generation, arguably due to the inherent locality of their denoising mechanisms. This can yield samples that are locally plausible but globally inconsistent. To mitigate this issue, we propose sparsely supervised learning for diffusion models, a simple yet effective masking strategy that can be implemented with only a few lines of code. Interestingly, the experiments show that it is safe to mask up to 98\\% of pixels during diffusion model training. Our method delivers competitive FID scores across experiments and, most importantly, avoids training instability on small datasets. Moreover, the masking strategy reduces memorization and promotes the use of essential contextual information during generation.", "AI": {"tldr": "提出了一种稀疏监督学习策略，用于改进扩散模型的生成一致性。", "motivation": "解决传统扩散模型在生成过程中出现的空间不一致问题。", "method": "采用简单的掩码策略，在训练过程中对多达98％的像素进行屏蔽处理。", "result": "实验表明该方法能够提高FID得分，并避免小数据集上的训练不稳定，同时减少记忆效应，促进上下文信息的有效使用。", "conclusion": "稀疏监督学习可以有效改善扩散模型在生成任务中的性能。"}}
{"id": "2602.02689", "pdf": "https://arxiv.org/pdf/2602.02689", "abs": "https://arxiv.org/abs/2602.02689", "authors": ["Asmaa Cherkaoui", "Ramon Flores", "Delaram Kahrobaei", "Richard Wilson"], "title": "Eidolon: A Practical Post-Quantum Signature Scheme Based on k-Colorability in the Age of Graph Neural Networks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "23 pages, 5 figures", "summary": "We propose Eidolon, a practical post-quantum signature scheme based on the NP-complete k-colorability problem. Our construction generalizes the Goldreich-Micali-Wigderson zero-knowledge protocol to arbitrary k >= 3, applies the Fiat-Shamir transform, and uses Merkle-tree commitments to compress signatures from O(tn) to O(t log n). Crucially, we generate hard instances via planted \"quiet\" colorings that preserve the statistical profile of random graphs. We present the first empirical security analysis of such a scheme against both classical solvers (ILP, DSatur) and a custom graph neural network (GNN) attacker. Experiments show that for n >= 60, neither approach recovers the secret coloring, demonstrating that well-engineered k-coloring instances can resist modern cryptanalysis, including machine learning. This revives combinatorial hardness as a credible foundation for post-quantum signatures.", "AI": {"tldr": "本文提出了一种基于k着色问题的实用后量子签名方案Eidolon，通过使用Merkl树承诺和定制的安全实例生成方法，提高了安全性。", "motivation": "在后量子计算时代，寻找可靠的加密基础至关重要。现有的方案可能存在漏洞，作者希望通过一种新的数学难题——k-着色来构建更安全、更实用的签名方案。", "method": "基于Goldreich-Micali-Wigderson零知识协议推广到任意k>=3的情况，应用Fiat-Shamir变换，并使用Merkle树承诺压缩签名。生成困难实例通过种植“安静”的着色以保持随机图的统计特性。实验中测试了经典解算器和机器学习攻击者的有效性。", "result": "实验结果显示，对于n>=60的情况，两种方法都无法恢复秘密着色，表明精心设计的k-着色实例可以抵御现代密码分析，包括机器学习。", "conclusion": "该研究证明了利用组合困难性作为后量子签名的基础是可行且有效的，从而为这一领域提供了新的方向和可能性。"}}
{"id": "2602.02686", "pdf": "https://arxiv.org/pdf/2602.02686", "abs": "https://arxiv.org/abs/2602.02686", "authors": ["Patrick Cooper", "Alireza Nadali", "Ashutosh Trivedi", "Alvaro Velasquez"], "title": "Monotonicity as an Architectural Bias for Robust Language Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "comment": "12 pages, 1 figure", "summary": "Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, carefully structured perturbations in high-dimensional input spaces can induce large and unpredictable changes in internal semantic representations and output. We investigate monotonicity as an architectural inductive bias for improving the robustness of Transformer-based language models. Monotonicity constrains semantic transformations so that strengthening information, evidence, or constraints cannot lead to regressions in the corresponding internal representations. Such order-preserving behavior has long been exploited in control and safety-critical systems to simplify reasoning and improve robustness, but has traditionally been viewed as incompatible with the expressivity required by neural language models. We show that this trade-off is not inherent. By enforcing monotonicity selectively in the feed-forward sublayers of sequence-to-sequence Transformers -- while leaving attention mechanisms unconstrained -- we obtain monotone language models that preserve the performance of their pretrained counterparts. This architectural separation allows negation, contradiction, and contextual interactions to be introduced explicitly through attention, while ensuring that subsequent semantic refinement is order-preserving. Empirically, monotonicity substantially improves robustness: adversarial attack success rates drop from approximately 69% to 19%, while standard summarization performance degrades only marginally.", "AI": {"tldr": "研究如何通过引入单调性作为架构偏置来增强大型语言模型的鲁棒性。", "motivation": "现代神经语言模型在面对对抗提示和越狱攻击时表现出脆弱性，即使经过广泛的对齐和微调也是如此。小而精心设计的输入扰动可能导致内部语义表示和输出的巨大且不可预测的变化。", "method": "通过在序列到序列Transformer的前馈子层中选择性地强制执行单调性（保持注意力机制不变），使语言模型保留其预训练性能，同时确保后续语义细化是保序的。", "result": "实验表明，单调性显著增强了鲁棒性：对抗攻击成功率从大约69％降至19％，而标准总结性能仅略有下降。", "conclusion": "证明了在不牺牲语言模型表达能力的情况下，通过引入单调性作为架构偏置可以有效提高大型语言模型的鲁棒性。"}}
{"id": "2602.02684", "pdf": "https://arxiv.org/pdf/2602.02684", "abs": "https://arxiv.org/abs/2602.02684", "authors": ["Lana Do", "Shasta Ihorn", "Charity Pitcher-Cooper", "Juvenal Francisco Barajas", "Gio Jung", "Xuan Duy Anh Nguyen", "Sanjay Mirani", "Ilmi Yoon"], "title": "ADx3: A Collaborative Workflow for High-Quality Accessible Audio Description", "categories": ["cs.HC"], "comment": null, "summary": "Audio description (AD) makes video content accessible to blind and low-vision (BLV) audiences, but producing high-quality descriptions is resource-intensive. Automated AD offers scalability, and prior studies show human-in-the-loop editing and user queries effectively improve narration. We introduce ADx3, a novel framework integrating these three modules: GenAD, upgrading baseline description generation with modern vision-language models (VLMs) guided by accessibility-informed prompting; RefineAD, supporting BLV and sighted users to view and edit drafts through an inclusive interface; and AdaptAD, enabling on-demand user queries. We evaluated GenAD in a study where seven accessibility specialists reviewed VLM-generated descriptions using professional guidelines. Findings show that with tailored prompting, VLMs produce good descriptions meeting basic standards, but excellent descriptions require human edits (RefineAD) and interaction (AdaptAD). ADx3 demonstrates collaborative workflows for accessible content creation, where components reinforce one another and enable continuous improvement: edits guide future baselines and user queries reveal gaps in AI-generated and human-authored descriptions.", "AI": {"tldr": "ADx3 是一个集成自动化音频描述生成、用户编辑和查询功能的协作工作流框架，以提高视频内容对视障人士的可访问性。", "motivation": "制作高质量的音频描述资源密集且耗时长，自动化的音频描述可以提升效率和扩展能力。通过引入人类参与和用户互动模块，可以进一步改善描述的质量。", "method": "ADx3 包括三个主要部分：GenAD（使用现代视觉语言模型生成基础描述），RefineAD（让用户编辑描述以改进质量）以及AdaptAD（允许用户提出即时查询）。研究人员通过一项实验评估了由七个无障碍专家根据专业标准审查的VLM生成的描述。", "result": "结果表明，尽管在特定提示下VLM可以产生符合基本标准的音频描述，但要达到高质量还需人类编辑和用户的交互。该框架展示了创建可访问内容的合作流程，并能通过持续改进提高描述质量。", "conclusion": "ADx3 强调了协作工作流的重要性，其中各个组件互相强化并允许不断优化：编辑指导未来的基础线生成，用户查询揭示AI生成或人类撰写的描述中的不足。"}}
{"id": "2602.02676", "pdf": "https://arxiv.org/pdf/2602.02676", "abs": "https://arxiv.org/abs/2602.02676", "authors": ["Xintong Zhang", "Xiaowen Zhang", "Jongrong Wu", "Zhi Gao", "Shilin Yan", "Zhenxin Diao", "Kunpeng Gao", "Xuanyan Chen", "Yuwei Wu", "Yunde Jia", "Qing Li"], "title": "AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process", "categories": ["cs.CV"], "comment": null, "summary": "Adaptive multimodal reasoning has emerged as a promising frontier in Vision-Language Models (VLMs), aiming to dynamically modulate between tool-augmented visual reasoning and text reasoning to enhance both effectiveness and efficiency. However, existing evaluations rely on static difficulty labels and simplistic metrics, which fail to capture the dynamic nature of difficulty relative to varying model capacities. Consequently, they obscure the distinction between adaptive mode selection and general performance while neglecting fine-grained process analyses. In this paper, we propose AdaptMMBench, a comprehensive benchmark for adaptive multimodal reasoning across five domains: real-world, OCR, GUI, knowledge, and math, encompassing both direct perception and complex reasoning tasks. AdaptMMBench utilizes a Matthews Correlation Coefficient (MCC) metric to evaluate the selection rationality of different reasoning modes, isolating this meta-cognition ability by dynamically identifying task difficulties based on models' capability boundaries. Moreover, AdaptMMBench facilitates multi-dimensional process evaluation across key step coverage, tool effectiveness, and computational efficiency. Our evaluation reveals that while adaptive mode selection scales with model capacity, it notably decouples from final accuracy. Conversely, key step coverage aligns with performance, though tool effectiveness remains highly inconsistent across model architectures.", "AI": {"tldr": "AdaptMMBench是一个用于评估自适应多模态推理的基准测试，涵盖了五个领域：现实世界、OCR、GUI、知识和数学。", "motivation": "现有评估方法依赖静态难度标签和简单指标，无法捕捉任务难度相对于模型容量的变化，忽略了自适应模式选择与整体性能之间的差异以及细粒度过程分析的需求。", "method": "AdaptMMBench使用马修斯相关系数（MCC）衡量不同推理模式的选择合理性，并通过动态识别基于模型能力边界的任务难度来评估多模态推理过程。它还支持从关键步骤覆盖、工具效果和计算效率三个维度进行评价。", "result": "自适应模式选择随模型容量增加而提高，但与最终准确性脱钩；关键步骤覆盖率则更符合性能表现，不过不同架构的模型在工具有效性上表现出高度不一致。", "conclusion": "AdaptMMBench为评估自适应多模态推理提供了一个全面的框架，揭示了模式选择和整体准确性之间的解耦关系，并强调了细粒度过程分析的重要性。"}}
{"id": "2602.02671", "pdf": "https://arxiv.org/pdf/2602.02671", "abs": "https://arxiv.org/abs/2602.02671", "authors": ["Francesco Leonardi", "Boris Bonev", "Kaspar Riesen"], "title": "MARA: Continuous SE(3)-Equivariant Attention for Molecular Force Fields", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine learning force fields (MLFFs) have become essential for accurate and efficient atomistic modeling. Despite their high accuracy, most existing approaches rely on fixed angular expansions, limiting flexibility in weighting local geometric interactions. We introduce Modular Angular-Radial Attention (MARA), a module that extends spherical attention -- originally developed for SO(3) tasks -- to the molecular domain and SE(3), providing an efficient approximation of equivariant interactions. MARA operates directly on the angular and radial coordinates of neighboring atoms, enabling flexible, geometrically informed, and modular weighting of local environments. Unlike existing attention mechanisms in SE(3)-equivariant architectures, MARA can be integrated in a plug-and-play manner into models such as MACE without architectural modifications. Across molecular benchmarks, MARA improves energy and force predictions, reduces high-error events, and enhances robustness. These results demonstrate that continuous spherical attention is an effective and generalizable geometric operator that increases the expressiveness, stability, and reliability of atomistic models.", "AI": {"tldr": "介绍了一种用于分子力场的连续SE(3)等变注意力机制MARA，增强了原子模型的表现力和鲁棒性。", "motivation": "现有方法依赖固定的角度展开限制了局部几何互动的灵活性，提出了MARA模块以解决这一问题，提高分子建模中能量和力预测的准确性。", "method": "通过扩展球面注意力机制到SE(3)领域，提出一种连续的等变注意力机制MARA。该机制直接操作邻近原子的角度和半径坐标，灵活加权局部环境，并可无缝集成进现有模型如MACE中。", "result": "在分子基准测试中，MARA提升了能量和力预测准确性，减少了高误差事件并提高了模型的鲁棒性。", "conclusion": "连续球面注意力机制是一种有效且通用的几何操作符，增强了原子模型的表现力、稳定性和可靠性。"}}
{"id": "2602.02660", "pdf": "https://arxiv.org/pdf/2602.02660", "abs": "https://arxiv.org/abs/2602.02660", "authors": ["Jiefeng Chen", "Bhavana Dalvi Mishra", "Jaehyun Nam", "Rui Meng", "Tomas Pfister", "Jinsung Yoon"], "title": "MARS: Modular Agent with Reflective Search for Automated AI Research", "categories": ["cs.AI"], "comment": null, "summary": "Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that ignore execution costs and causal factors. We introduce MARS (Modular Agent with Reflective Search), a framework optimized for autonomous AI research. MARS relies on three pillars: (1) Budget-Aware Planning via cost-constrained Monte Carlo Tree Search (MCTS) to explicitly balance performance with execution expense; (2) Modular Construction, employing a \"Design-Decompose-Implement\" pipeline to manage complex research repositories; and (3) Comparative Reflective Memory, which addresses credit assignment by analyzing solution differences to distill high-signal insights. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench under comparable settings, maintaining competitiveness with the global leaderboard's top methods. Furthermore, the system exhibits qualitative \"Aha!\" moments, where 63% of all utilized lessons originate from cross-branch transfer, demonstrating that the agent effectively generalizes insights across search paths.", "AI": {"tldr": "MARS是一个旨在优化自主AI研究的框架，它通过预算感知计划、模块化构建和比较性反思记忆来提高效率。", "motivation": "自动化AI研究面临计算资源昂贵和性能归因不透明的问题。当前基于LLM的代理存在生成忽略执行成本和因果因素的整体脚本等问题。", "method": "MARS依靠三个支柱：预算感知计划、模块化构建和比较性反思记忆，分别解决执行成本平衡问题、复杂研究库管理及性能归因难题。", "result": "在与开源框架相比的MLE-Bench评估中，MARS表现出最先进的性能，并且保持了与全球排行榜顶级方法的竞争力。", "conclusion": "MARS不仅提升了AI研究效率，在实验中还展示了63%的有效教训源自跨分支转移的能力。"}}
{"id": "2602.02641", "pdf": "https://arxiv.org/pdf/2602.02641", "abs": "https://arxiv.org/abs/2602.02641", "authors": ["Najmul Hasan", "Prashanth BusiReddyGari"], "title": "Benchmarking Large Language Models for Zero-shot and Few-shot Phishing URL Detection", "categories": ["cs.CR", "cs.AI"], "comment": "9 pages, accepted at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025 LAW Workshop)", "summary": "The Uniform Resource Locator (URL), introduced in a connectivity-first era to define access and locate resources, remains historically limited, lacking future-proof mechanisms for security, trust, or resilience against fraud and abuse, despite the introduction of reactive protections like HTTPS during the cybersecurity era. In the current AI-first threatscape, deceptive URLs have reached unprecedented sophistication due to the widespread use of generative AI by cybercriminals and the AI-vs-AI arms race to produce context-aware phishing websites and URLs that are virtually indistinguishable to both users and traditional detection tools. Although AI-generated phishing accounted for a small fraction of filter-bypassing attacks in 2024, phishing volume has escalated over 4,000% since 2022, with nearly 50% more attacks evading detection. At the rate the threatscape is escalating, and phishing tactics are emerging faster than labeled data can be produced, zero-shot and few-shot learning with large language models (LLMs) offers a timely and adaptable solution, enabling generalization with minimal supervision. Given the critical importance of phishing URL detection in large-scale cybersecurity defense systems, we present a comprehensive benchmark of LLMs under a unified zero-shot and few-shot prompting framework and reveal operational trade-offs. Our evaluation uses a balanced dataset with consistent prompts, offering detailed analysis of performance, generalization, and model efficacy, quantified by accuracy, precision, recall, F1 score, AUROC, and AUPRC, to reflect both classification quality and practical utility in threat detection settings. We conclude few-shot prompting improves performance across multiple LLMs.", "AI": {"tldr": "该论文评估了大型语言模型在零样本和少量样本下的网络钓鱼URL检测能力。", "motivation": "由于网络钓鱼攻击的复杂性增加，传统防御工具难以应对。零样本和少量样本学习提供了及时且灵活的方法来提高检测效率。", "method": "使用统一的零样本和少量样本提示框架对大型语言模型进行评估，并通过准确率、精确度、召回率等指标量化其性能。", "result": "结果显示，少量样本提示可以提升多种大型语言模型的网络钓鱼URL检测性能。", "conclusion": "该研究展示了大规模语言模型在零样本和少量样本下的网络钓鱼URL检测能力，并强调了少量样本学习的重要性。"}}
{"id": "2602.02639", "pdf": "https://arxiv.org/pdf/2602.02639", "abs": "https://arxiv.org/abs/2602.02639", "authors": ["Harry Mayne", "Justin Singh Kang", "Dewi Gould", "Kannan Ramchandran", "Adam Mahdi", "Noah Y. Siegel"], "title": "A Positive Case for Faithfulness: LLM Self-Explanations Help Predict Model Behavior", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "LLM self-explanations are often presented as a promising tool for AI oversight, yet their faithfulness to the model's true reasoning process is poorly understood. Existing faithfulness metrics have critical limitations, typically relying on identifying unfaithfulness via adversarial prompting or detecting reasoning errors. These methods overlook the predictive value of explanations. We introduce Normalized Simulatability Gain (NSG), a general and scalable metric based on the idea that a faithful explanation should allow an observer to learn a model's decision-making criteria, and thus better predict its behavior on related inputs. We evaluate 18 frontier proprietary and open-weight models, e.g., Gemini 3, GPT-5.2, and Claude 4.5, on 7,000 counterfactuals from popular datasets covering health, business, and ethics. We find self-explanations substantially improve prediction of model behavior (11-37% NSG). Self-explanations also provide more predictive information than explanations generated by external models, even when those models are stronger. This implies an advantage from self-knowledge that external explanation methods cannot replicate. Our approach also reveals that, across models, 5-15% of self-explanations are egregiously misleading. Despite their imperfections, we show a positive case for self-explanations: they encode information that helps predict model behavior.", "AI": {"tldr": "本文介绍了Normalized Simulatability Gain（NSG）这一度量标准，用于评估大型语言模型自解释的忠实性，并发现这些自解释能够显著提高对模型行为预测的能力。", "motivation": "现有的忠实性指标存在局限，往往依赖于通过对抗式提示或检测推理错误来识别不忠实之处。本文旨在探索自解释在预测模型行为中的预测价值，提出一种新的度量标准NSG，以评估这些自解释的忠实性。", "method": "作者引入了Normalized Simulatability Gain（NSG）这一基于观测者能否通过解释学习到模型决策标准从而提高对相关输入行为预测能力的新指标。该方法被应用于18个前沿的私有和公开权重模型，评估了7000个来自健康、商业和伦理等领域数据集的反事实案例。", "result": "研究发现，自解释显著提高了模型行为预测（NSG值为11%-37%）。相比外部生成的解释，即使是更强大的外部模型也无法复制这种通过自我知识获得的优势。但值得注意的是，在所有模型中，5-15%的自解释具有误导性。", "conclusion": "尽管存在缺陷，研究证明了大型语言模型的自解释编码的信息有助于预测其行为，并提出了一个积极案例支持使用这些自解释以提高模型行为的可预见性和控制。"}}
{"id": "2602.02636", "pdf": "https://arxiv.org/pdf/2602.02636", "abs": "https://arxiv.org/abs/2602.02636", "authors": ["Ziyang Huang", "Haolin Ren", "Xiaowei Yuan", "Jiawei Wang", "Zhongtao Jiang", "Kun Xu", "Shizhu He", "Jun Zhao", "Kang Liu"], "title": "WideSeek: Advancing Wide Research via Multi-Agent Scaling", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedicated benchmarks and optimization methodologies for search breadth. To address these challenges, we take a deep dive into Wide Research from two perspectives: Data Pipeline and Agent Optimization. First, we produce WideSeekBench, a General Broad Information Seeking (GBIS) benchmark constructed via a rigorous multi-phase data pipeline to ensure diversity across the target information volume, logical constraints, and domains. Second, we introduce WideSeek, a dynamic hierarchical multi-agent architecture that can autonomously fork parallel sub-agents based on task requirements. Furthermore, we design a unified training framework that linearizes multi-agent trajectories and optimizes the system using end-to-end RL. Experimental results demonstrate the effectiveness of WideSeek and multi-agent RL, highlighting that scaling the number of agents is a promising direction for advancing the Wide Research paradigm.", "AI": {"tldr": "本文提出了WideSeekBench基准和多智能体架构WideSeek，用于推进广义信息检索的深度研究。", "motivation": "当前的信息检索从深度研究转向广度研究面临挑战，包括缺乏专门的评估标准和优化方法。为了应对这些问题，提出了一种新的解决方案来提高搜索范围和效果。", "method": "构建了WideSeekBench基准并通过多阶段数据管道保证多样性和复杂性；设计了一个动态分层的多智能体架构WideSeek，并通过统一训练框架使用端到端强化学习优化。", "result": "实验结果显示，多智能体架构的有效性被证明，表明增加代理的数量是推进广义信息检索的重要方向。", "conclusion": "本文提出的方案展示了在复杂约束条件下进行广泛信息搜索的潜力和前景。"}}
{"id": "2602.02632", "pdf": "https://arxiv.org/pdf/2602.02632", "abs": "https://arxiv.org/abs/2602.02632", "authors": ["Praveen Rao"], "title": "Performance of Small Language Model Pretraining on FABRIC: An Empirical Study", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) require enormous computing power to pretrain on massive datasets. When limited datasets are available, smaller-sized LLMs are better choice to pretrain (on user-specified datasets) by following the scaling laws of LLMs. Using pretrained models, vector embeddings can be generated for raw data and stored using vector databases to support modern AI applications and semantic search. In this work, we investigate the performance of pretraining techniques for smaller-sized LLMs on an experimental testbed (with commodity GPUs) available to academic users at no charge. We consider data parallelism, intra-operator parallelism, and inter-operator/pipeline parallelism, and their combinations for pretraining. We set up different GPU clusters with homogeneous and heterogeneous GPU hardware. Furthermore, we investigate the impact of network latency on pretraining performance especially when GPUs are geographically distributed. We used GPT-2 medium and large models and pretrained them using open-source packages, namely, Alpa and Ray. We observed that Alpa's execution plans that collectively optimized intra-operator and inter-operator/pipeline parallelism consistently performed the best when GPUs were geographically distributed. This was especially true when the network latencies were in 10's of milliseconds. Based on the insights gained from the experiments, we propose a systematic approach for selecting the appropriate pretraining technique to achieve high training performance/lower execution time as well as to reduce the number of GPUs used.", "AI": {"tldr": "研究了在实验测试平台中对小型语言模型进行预训练的方法和性能，特别是在网络延迟较高的情况下。", "motivation": "当数据集较小且计算资源有限时，使用小型化的大规模语言模型并优化预训练技术对于提高AI应用的性能至关重要。", "method": "利用GPT-2 medium和large模型，在具有商品级GPU的实验测试平台中进行预训练。研究了数据并行、操作内并行及管道/操作间并行及其组合的效果，并考虑不同类型的GPU集群以及网络延迟对预训练性能的影响。", "result": "发现Alpa执行计划在地理分布的GPU上表现最佳，特别是在网络延时为数十毫秒的情况下。", "conclusion": "提出了选择合适预训练技术的方法以实现高性能和减少所需GPU数量。"}}
{"id": "2602.02630", "pdf": "https://arxiv.org/pdf/2602.02630", "abs": "https://arxiv.org/abs/2602.02630", "authors": ["Roberto Balestri", "Pasquale Cascarano", "Mirko Degli Esposti", "Guglielmo Pescatore"], "title": "Trailer Reimagined: An Innovative, Llm-DRiven, Expressive Automated Movie Summary framework (TRAILDREAMS)", "categories": ["cs.MM", "cs.AI"], "comment": "ef:OJCMT, 15(3), e202524 (2025)", "summary": "This paper introduces TRAILDREAMS, a framework that uses a large language model (LLM) to automate the production of movie trailers. The purpose of LLM is to select key visual sequences and impactful dialogues, and to help TRAILDREAMS to generate audio elements such as music and voiceovers. The goal is to produce engaging and visually appealing trailers efficiently. In comparative evaluations, TRAILDREAMS surpasses current state-of-the-art trailer generation methods in viewer ratings. However, it still falls short when compared to real, human-crafted trailers. While TRAILDREAMS demonstrates significant promise and marks an advancement in automated creative processes, further improvements are necessary to bridge the quality gap with traditional trailers.", "AI": {"tldr": "TRAILDREAMS是一个利用大规模语言模型自动生成电影预告片的框架。", "motivation": "为了提高电影预告片生成效率，通过选择关键视觉序列和有影响力的对话，并借助LLM产生音频元素如音乐和旁白来制作吸引人且视觉效果出色的预告片。", "method": "TRAILDREAMS利用大模型自动选取关键视频片段、对话以及生成音效等元素来创造电影预告片。", "result": "在观众评分中，TRAILDREAMS优于现有的最佳方法但仍未达到人工制作的水平。", "conclusion": "尽管TRAILDREAMS展示了自动化创意过程的巨大潜力并取得了进步，但仍需进一步改进以缩小与传统预告片的质量差距。"}}
{"id": "2602.02629", "pdf": "https://arxiv.org/pdf/2602.02629", "abs": "https://arxiv.org/abs/2602.02629", "authors": ["Rodrigo Tertulino", "Ricardo Almeida", "Laercio Alencar"], "title": "Trustworthy Blockchain-based Federated Learning for Electronic Health Records: Securing Participant Identity with Decentralized Identifiers and Verifiable Credentials", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "The digitization of healthcare has generated massive volumes of Electronic Health Records (EHRs), offering unprecedented opportunities for training Artificial Intelligence (AI) models. However, stringent privacy regulations such as GDPR and HIPAA have created data silos that prevent centralized training. Federated Learning (FL) has emerged as a promising solution that enables collaborative model training without sharing raw patient data. Despite its potential, FL remains vulnerable to poisoning and Sybil attacks, in which malicious participants corrupt the global model or infiltrate the network using fake identities. While recent approaches integrate Blockchain technology for auditability, they predominantly rely on probabilistic reputation systems rather than robust cryptographic identity verification. This paper proposes a Trustworthy Blockchain-based Federated Learning (TBFL) framework integrating Self-Sovereign Identity (SSI) standards. By leveraging Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), our architecture ensures only authenticated healthcare entities contribute to the global model. Through comprehensive evaluation using the MIMIC-IV dataset, we demonstrate that anchoring trust in cryptographic identity verification rather than behavioral patterns significantly mitigates security risks while maintaining clinical utility. Our results show the framework successfully neutralizes 100% of Sybil attacks, achieves robust predictive performance (AUC = 0.954, Recall = 0.890), and introduces negligible computational overhead (<0.12%). The approach provides a secure, scalable, and economically viable ecosystem for inter-institutional health data collaboration, with total operational costs of approximately $18 for 100 training rounds across multiple institutions.", "AI": {"tldr": "提出了一种基于区块链的联邦学习框架，通过自主权身份标准确保只有经过认证的医疗实体能够参与全局模型训练。", "motivation": "解决现有联邦学习系统中对恶意参与者使用假身份进行攻击的问题。当前方案主要依赖行为模式而非加密身份验证，缺乏安全性保障。", "method": "利用去中心化标识符（DIDs）和可验证凭证（VCs），结合区块链技术创建可信的联邦学习框架，实现基于加密的身份认证而不是概率信誉系统来保障系统的安全性和可靠性。", "result": "该研究在MIMIC-IV数据集上进行测试，结果显示能够完全阻止Sybil攻击，并保持良好的预测性能（AUC = 0.954, 召回率=0.890），同时引入的计算开销小于0.12%，整体运营成本约为每百轮训练18美元。", "conclusion": "所提出的框架提供了一个安全、可扩展且经济可行的跨机构医疗数据协作生态系统。"}}
{"id": "2602.02624", "pdf": "https://arxiv.org/pdf/2602.02624", "abs": "https://arxiv.org/abs/2602.02624", "authors": ["Paul Bouchaud", "Pedro Ramaciotti"], "title": "Recommender system in X inadvertently profiles ideological positions of users", "categories": ["cs.SI", "cs.AI", "cs.CY"], "comment": null, "summary": "Studies on recommendations in social media have mainly analyzed the quality of recommended items (e.g., their diversity or biases) and the impact of recommendation policies (e.g., in comparison with purely chronological policies). We use a data donation program, collecting more than 2.5 million friend recommendations made to 682 volunteers on X over a year, to study instead how real-world recommenders learn, represent and process political and social attributes of users inside the so-called black boxes of AI systems. Using publicly available knowledge on the architecture of the recommender, we inferred the positions of recommended users in its embedding space. Leveraging ideology scaling calibrated with political survey data, we analyzed the political position of users in our study (N=26,509 among volunteers and recommended contacts) among several attributes, including age and gender. Our results show that the platform's recommender system produces a spatial ordering of users that is highly correlated with their Left-Right positions (Pearson rho=0.887, p-value < 0.0001), and that cannot be explained by socio-demographic attributes. These results open new possibilities for studying the interaction between human and AI systems. They also raise important questions linked to the legal definition of algorithmic profiling in data privacy regulation by blurring the line between active and passive profiling. We explore new constrained recommendation methods enabled by our results, limiting the political information in the recommender as a potential tool for privacy compliance capable of preserving recommendation relevance.", "AI": {"tldr": "本文研究了社交媒体推荐系统如何学习、表示和处理用户的意识形态和社会属性。", "motivation": "探讨推荐系统在用户嵌入空间中的政治定位，以及其与社会人口统计特征之间的关系。", "method": "通过收集X平台上超过250万的志愿者朋友推荐数据，结合政治问卷调查数据进行分析。", "result": "发现平台推荐系统的用户排序与其左翼-右翼立场高度相关（皮尔逊系数=0.887, p值<0.0001），这种关系无法仅通过社会人口统计特征解释。", "conclusion": "研究结果揭示了人类与AI系统之间的互动，提出了算法轮廓界定的新问题，并探索了限制推荐系统中政治信息的方法以符合隐私法规。"}}
{"id": "2602.02623", "pdf": "https://arxiv.org/pdf/2602.02623", "abs": "https://arxiv.org/abs/2602.02623", "authors": ["Gabriele D'Acunto", "Paolo Di Lorenzo", "Sergio Barbarossa"], "title": "Learning Consistent Causal Abstraction Networks", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": "To be published in the proceedings of ICASSP 2026 - 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). arXiv admin note: substantial text overlap with arXiv:2509.25236", "summary": "Causal artificial intelligence aims to enhance explainability, trustworthiness, and robustness in AI by leveraging structural causal models (SCMs). In this pursuit, recent advances formalize network sheaves and cosheaves of causal knowledge. Pushing in the same direction, we tackle the learning of consistent causal abstraction network (CAN), a sheaf-theoretic framework where (i) SCMs are Gaussian, (ii) restriction maps are transposes of constructive linear causal abstractions (CAs) adhering to the semantic embedding principle, and (iii) edge stalks correspond--up to permutation--to the node stalks of more detailed SCMs. Our problem formulation separates into edge-specific local Riemannian problems and avoids nonconvex objectives. We propose an efficient search procedure, solving the local problems with SPECTRAL, our iterative method with closed-form updates and suitable for positive definite and semidefinite covariance matrices. Experiments on synthetic data show competitive performance in the CA learning task, and successful recovery of diverse CAN structures.", "AI": {"tldr": "本文提出了学习一致的因果抽象网络（CAN）的方法，利用结构因果模型和线性因果抽象，通过SPECTRAL迭代方法解决局部问题。", "motivation": "提高人工智能系统的可解释性、可信度和鲁棒性是当前研究的重点。本文旨在通过构造一致的因果抽象网络来实现这一目标。", "method": "提出了一个有效的搜索过程，利用SPECTRAL迭代方法解决局部Riemannian问题，并采用封闭形式更新方式处理正定或半正定协方差矩阵。", "result": "实验结果表明，在学习线性因果抽象任务中表现出色，能够成功恢复出多种不同的CAN结构。", "conclusion": "所提出的方法可以有效学习一致的因果抽象网络，提高了系统的可解释性和鲁棒性。"}}
{"id": "2602.02620", "pdf": "https://arxiv.org/pdf/2602.02620", "abs": "https://arxiv.org/abs/2602.02620", "authors": ["Weining Fu", "Kai Shu", "Kui Xu", "Qiangfeng Cliff Zhang"], "title": "CryoLVM: Self-supervised Learning from Cryo-EM Density Maps with Large Vision Models", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Cryo-electron microscopy (cryo-EM) has revolutionized structural biology by enabling near-atomic-level visualization of biomolecular assemblies. However, the exponential growth in cryo-EM data throughput and complexity, coupled with diverse downstream analytical tasks, necessitates unified computational frameworks that transcend current task-specific deep learning approaches with limited scalability and generalizability. We present CryoLVM, a foundation model that learns rich structural representations from experimental density maps with resolved structures by leveraging the Joint-Embedding Predictive Architecture (JEPA) integrated with SCUNet-based backbone, which can be rapidly adapted to various downstream tasks. We further introduce a novel histogram-based distribution alignment loss that accelerates convergence and enhances fine-tuning performance. We demonstrate CryoLVM's effectiveness across three critical cryo-EM tasks: density map sharpening, density map super-resolution, and missing wedge restoration. Our method consistently outperforms state-of-the-art baselines across multiple density map quality metrics, confirming its potential as a versatile model for a wide spectrum of cryo-EM applications.", "AI": {"tldr": "通过使用联合嵌入预测架构和SCUNet主干，开发了一种从实验密度图中学习丰富结构表示的通用模型CryoLVM。", "motivation": "解决cryo-EM数据量和复杂度增长所带来的挑战，提出一种可以应用于多个下游任务的统一计算框架。", "method": "利用JEPA与SCUNet主干结合，并引入基于直方图的分布对齐损失以加速收敛并提升微调性能。", "result": "CryoLVM在密度图锐化、超分辨率和缺失楔子恢复三个关键任务上均超越了现有最佳方法，验证了其通用性和优越性。", "conclusion": "CryoLVM证明了其作为cryo-EM广泛应用中多功能模型的潜力。"}}
{"id": "2602.02619", "pdf": "https://arxiv.org/pdf/2602.02619", "abs": "https://arxiv.org/abs/2602.02619", "authors": ["Mohan Jiang", "Dayuan Fu", "Junhao Shi", "Ji Zeng", "Weiye Si", "Keyu Li", "Xuefeng Li", "Yang Xiao", "Wenjie Li", "Dequan Wang", "Pengfei Liu"], "title": "daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics--existing synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories. Building on this, we propose daVinci-Agency, which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits, (2) long-term consistency enforcement through unified functional objectives, and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial--averaging 85k tokens and 116 tool calls--yet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon. Beyond benchmark performance, our analysis confirms...", "AI": {"tldr": "本文提出了daVinci-Agency，通过解析真实的代码提交记录来生成高质量的训练数据，以解决大规模语言模型在长时间任务中的不足。", "motivation": "目前的大规模语言模型虽然擅长处理短期任务，但在长时间的任务链中表现不佳。主要瓶颈在于缺乏包含真实长依赖结构和跨阶段演变动态的有效训练数据。", "method": "本文通过解析真实的代码提交记录（Pull Request）来生成高质量的训练数据，利用PR序列中的监督信号进行长期任务的学习。方法包括逐步分解任务、维护功能一致性以及从真实的错误修复历史中获得验证性改进。", "result": "实验结果显示，在使用239个daVinci-Agency样本对GLM-4.6进行微调后，模型在Toolathlon基准测试中的性能提高了47%。生成的轨迹数据量大且高效。", "conclusion": "通过解析真实的代码提交记录来生成高质量的训练数据的方法可以显著提高大规模语言模型处理长时间任务的能力，验证了这种方法的有效性和优越性。"}}
{"id": "2602.02618", "pdf": "https://arxiv.org/pdf/2602.02618", "abs": "https://arxiv.org/abs/2602.02618", "authors": ["Fatemeh Karimi Nejadasl", "Judy Shamoun-Baranes", "Eldar Rakhimberdiev"], "title": "A Semi-Supervised Pipeline for Generalized Behavior Discovery from Animal-Borne Motion Time Series", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning behavioral taxonomies from animal-borne sensors is challenging because labels are scarce, classes are highly imbalanced, and behaviors may be absent from the annotated set. We study generalized behavior discovery in short multivariate motion snippets from gulls, where each sample is a sequence with 3-axis IMU acceleration (20 Hz) and GPS speed, spanning nine expert-annotated behavior categories. We propose a semi-supervised discovery pipeline that (i) learns an embedding function from the labeled subset, (ii) performs label-guided clustering over embeddings of both labeled and unlabeled samples to form candidate behavior groups, and (iii) decides whether a discovered group is truly novel using a containment score. Our key contribution is a KDE + HDR (highest-density region) containment score that measures how much a discovered cluster distribution is contained within, or contains, each known-class distribution; the best-match containment score serves as an interpretable novelty statistic. In experiments where an entire behavior is withheld from supervision and appears only in the unlabeled pool, the method recovers a distinct cluster and the containment score flags novelty via low overlap, while a negative-control setting with no novel behavior yields consistently higher overlaps. These results suggest that HDR-based containment provides a practical, quantitative test for generalized class discovery in ecological motion time series under limited annotation and severe class imbalance.", "AI": {"tldr": "本文提出了一种半监督行为发现管道，用于从动物携带的传感器数据中识别行为。", "motivation": "由于标签稀疏、类别不平衡以及某些行为可能未被注释集覆盖，从动物传感器数据学习行为分类具有挑战性。为此，研究提出了一个半监督管道来解决这些问题。", "method": "该方法包括三个步骤：1）从有标注的数据集中学习嵌入函数；2）对标记和无标签样本的嵌入执行引导聚类以形成候选行为组；3）使用KDE+HDR（最高密度区域）包容性得分决定发现的群集是否是真正的新类别。", "result": "实验表明，当整个行为被排除在监督之外且仅出现在未标注的数据池中时，该方法可以恢复一个独立的聚类，并通过低重叠率标记新颖性。而对照组没有新行为的情况下，包容性得分保持较高。", "conclusion": "研究结果表明HDR基包含为生态运动时间序列下的泛化类别发现提供了实用且定量的测试，特别是在标签稀疏和严重类别不平衡的情况下。"}}
{"id": "2602.02615", "pdf": "https://arxiv.org/pdf/2602.02615", "abs": "https://arxiv.org/abs/2602.02615", "authors": ["Ali Mahdavi", "Santa Aghapour", "Azadeh Zamanifar", "Amirfarhad Farhadi"], "title": "TinyGuard:A lightweight Byzantine Defense for Resource-Constrained Federated Learning via Statistical Update Fingerprints", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Existing Byzantine robust aggregation mechanisms typically rely on fulldimensional gradi ent comparisons or pairwise distance computations, resulting in computational overhead that limits applicability in large scale and resource constrained federated systems. This paper proposes TinyGuard, a lightweight Byzantine defense that augments the standard FedAvg algorithm via statistical update f ingerprinting. Instead of operating directly on high-dimensional gradients, TinyGuard extracts compact statistical fingerprints cap turing key behavioral properties of client updates, including norm statistics, layer-wise ratios, sparsity measures, and low-order mo ments. Byzantine clients are identified by measuring robust sta tistical deviations in this low-dimensional fingerprint space with nd complexity, without modifying the underlying optimization procedure. Extensive experiments on MNIST, Fashion-MNIST, ViT-Lite, and ViT-Small with LoRA adapters demonstrate that TinyGuard pre serves FedAvg convergence in benign settings and achieves up to 95 percent accuracy under multiple Byzantine attack scenarios, including sign-flipping, scaling, noise injection, and label poisoning. Against adaptive white-box adversaries, Pareto frontier analysis across four orders of magnitude confirms that attackers cannot simultaneously evade detection and achieve effective poisoning, features we term statistical handcuffs. Ablation studies validate stable detection precision 0.8 across varying client counts (50-150), threshold parameters and extreme data heterogeneity . The proposed framework is architecture-agnostic and well-suited for federated fine-tuning of foundation models where traditional Byzantine defenses become impractical", "AI": {"tldr": "TinyGuard是一种轻量级的拜占庭防御机制，通过统计更新指纹来增强联邦学习中的FedAvg算法，适用于资源受限和大规模系统。", "motivation": "现有的拜占庭鲁棒聚合机制依赖于全维度梯度比较或成对距离计算，导致了较大的计算开销，限制了其在大型和资源约束的联邦系统中的应用。因此提出了TinyGuard来解决这一问题。", "method": "TinyGuard通过提取客户端更新的紧凑统计指纹（包括范数统计、逐层比例、稀疏度测量和低阶矩等）来进行拜占庭节点识别，该方法在低维度指纹空间中以线性复杂度计算稳健统计偏差。无需修改基础优化过程即可实现。", "result": "实验显示，在多种攻击场景下（包括符号翻转、缩放、噪声注入和标签中毒），TinyGuard能够保持FedAvg的收敛性，并达到高达95%的准确率。此外，对于适应性白盒对手，帕累托前沿分析确认了无法同时避开检测和实现有效污染。", "conclusion": "该框架适用于各种架构，在极端数据异质性和不同客户端数量下均能稳定运行，特别适合联邦微调基础模型的情况。"}}
{"id": "2602.02614", "pdf": "https://arxiv.org/pdf/2602.02614", "abs": "https://arxiv.org/abs/2602.02614", "authors": ["Ying Wang", "Jiahui Chen", "Dejun Jiang"], "title": "Testing Storage-System Correctness: Challenges, Fuzzing Limitations, and AI-Augmented Opportunities", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": null, "summary": "Storage systems are fundamental to modern computing infrastructures, yet ensuring their correctness remains challenging in practice. Despite decades of research on system testing, many storage-system failures (including durability, ordering, recovery, and consistency violations) remain difficult to expose systematically. This difficulty stems not primarily from insufficient testing tooling, but from intrinsic properties of storage-system execution, including nondeterministic interleavings, long-horizon state evolution, and correctness semantics that span multiple layers and execution phases. This survey adopts a storage-centric view of system testing and organizes existing techniques according to the execution properties and failure mechanisms they target. We review a broad spectrum of approaches, ranging from concurrency testing and long-running workloads to crash-consistency analysis, hardware-level semantic validation, and distributed fault injection, and analyze their fundamental strengths and limitations. Within this framework, we examine fuzzing as an automated testing paradigm, highlighting systematic mismatches between conventional fuzzing assumptions and storage-system semantics, and discuss how recent artificial intelligence advances may complement fuzzing through state-aware and semantic guidance. Overall, this survey provides a unified perspective on storage-system correctness testing and outlines key challenges", "AI": {"tldr": "论文主要讨论了存储系统的正确性测试面临的挑战，模糊测试的局限性以及人工智能增强的机会。", "motivation": "确保现代计算基础设施中基础的存储系统在实践中正确运行仍然是一个难题。尽管已有数十年的研究投入于系统测试领域，但许多存储系统故障仍然难以通过常规手段检测到。", "method": "论文采用一种以存储为中心的方法来审视系统测试，并根据所关注的执行属性和失效机制对现有技术进行了分类梳理；探讨了从并发测试、长时间运行负载分析到崩溃一致性检查等多种方法；特别强调了模糊测试与存储系统语义之间存在的固有不匹配，讨论了最近的人工智能进展如何通过状态感知和语义指导来补充模糊测试。", "result": "论文提供了一种统一的视角来看待存储系统的正确性测试，并概述了一些关键挑战。", "conclusion": "尽管面临许多困难，但通过综合现有技术以及利用人工智能的进步，可以更有效地解决存储系统中的正确性问题。"}}
{"id": "2602.02613", "pdf": "https://arxiv.org/pdf/2602.02613", "abs": "https://arxiv.org/abs/2602.02613", "authors": ["Yu-Zheng Lin", "Bono Po-Jen Shih", "Hsuan-Ying Alessandra Chien", "Shalaka Satam", "Jesus Horacio Pacheco", "Sicong Shao", "Soheil Salehi", "Pratik Satam"], "title": "Exploring Silicon-Based Societies: An Early Study of the Moltbook Agent Community", "categories": ["cs.MA", "cs.AI", "cs.CY"], "comment": "10 pages, 3 figures, a pilot study for silicon-based societies", "summary": "The rapid emergence of autonomous large language model agents has given rise to persistent, large-scale agent ecosystems whose collective behavior cannot be adequately understood through anecdotal observation or small-scale simulation. This paper introduces data-driven silicon sociology as a systematic empirical framework for studying social structure formation among interacting artificial agents. We present a pioneering large-scale data mining investigation of an in-the-wild agent society by analyzing Moltbook, a social platform designed primarily for agent-to-agent interaction. At the time of study, Moltbook hosted over 150,000 registered autonomous agents operating across thousands of agent-created sub-communities. Using programmatic and non-intrusive data acquisition, we collected and analyzed the textual descriptions of 12,758 submolts, which represent proactive sub-community partitioning activities within the ecosystem. Treating agent-authored descriptions as first-class observational artifacts, we apply rigorous preprocessing, contextual embedding, and unsupervised clustering techniques to uncover latent patterns of thematic organization and social space structuring. The results show that autonomous agents systematically organize collective space through reproducible patterns spanning human-mimetic interests, silicon-centric self-reflection, and early-stage economic and coordination behaviors. Rather than relying on predefined sociological taxonomies, these structures emerge directly from machine-generated data traces. This work establishes a methodological foundation for data-driven silicon sociology and demonstrates that data mining techniques can provide a powerful lens for understanding the organization and evolution of large autonomous agent societies.", "AI": {"tldr": "探索基于硅基社会的行为模式，通过分析Moltbook平台上的代理社区数据。", "motivation": "自主大型语言模型代理的快速兴起导致了难以通过传统方法理解的庞大生态系统。需要系统性地研究这些代理之间的社交行为和结构。", "method": "采用程序化且非侵入性的数据采集技术，收集并分析Moltbook平台上12758个子社区的描述信息，并运用预处理、情境嵌入以及无监督聚类等技术来挖掘潜在的主题组织和社会空间构建模式。", "result": "揭示了自主代理通过可重复的人类模仿兴趣、硅基自我反思及早期经济和协调行为等方式，系统地组织集体社交空间。", "conclusion": "该研究建立了一种数据驱动的硅基社会学方法论框架，证明了数据分析技术能有效理解大型自治代理社会的结构与演变。"}}
{"id": "2602.02611", "pdf": "https://arxiv.org/pdf/2602.02611", "abs": "https://arxiv.org/abs/2602.02611", "authors": ["David Vigouroux", "Lucas Drumetz", "Ronan Fablet", "François Rousseau"], "title": "Discovering Data Manifold Geometry via Non-Contracting Flows", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce an unsupervised approach for constructing a global reference system by learning, in the ambient space, vector fields that span the tangent spaces of an unknown data manifold. In contrast to isometric objectives, which implicitly assume manifold flatness, our method learns tangent vector fields whose flows transport all samples to a common, learnable reference point. The resulting arc-lengths along these flows define interpretable intrinsic coordinates tied to a shared global frame. To prevent degenerate collapse, we enforce a non-shrinking constraint and derive a scalable, integration-free objective inspired by flow matching. Within our theoretical framework, we prove that minimizing the proposed objective recovers a global coordinate chart when one exists. Empirically, we obtain correct tangent alignment and coherent global coordinate structure on synthetic manifolds. We also demonstrate the scalability of our method on CIFAR-10, where the learned coordinates achieve competitive downstream classification performance.", "AI": {"tldr": "该论文提出了一种通过非收缩流学习全局参考系统的方法，用于构造数据流形的内在坐标。", "motivation": "传统的等距目标假设流形是平坦的，而该方法旨在避免这种假定，并通过流动将所有样本运送到共同的学习参考点来构建一个可解释的内禀坐标体系。", "method": "论文提出了一种新的非收缩矢量场学习策略，这些矢量场在流形上定义了内在坐标。通过推导出一种不受积分影响且可扩展的目标函数，确保了流动不会导致样本的退化塌陷，并证明该目标最小化的结果可以恢复一个全局坐标图。", "result": "实验表明，在合成流形数据集和CIFAR-10上，所学得的坐标结构正确对齐了切空间，并且在下游分类任务中展示了良好的性能。", "conclusion": "通过非收缩流动的方法可以成功地从数据集中学习出全局参考系统，并能够实现有效的内在坐标构造。"}}
{"id": "2602.02606", "pdf": "https://arxiv.org/pdf/2602.02606", "abs": "https://arxiv.org/abs/2602.02606", "authors": ["Faezeh Fadaei", "Jenny Carla Moran", "Taha Yasseri"], "title": "Gender Dynamics and Homophily in a Social Network of LLM Agents", "categories": ["cs.SI", "cs.AI", "cs.CY"], "comment": "Under Review", "summary": "Generative artificial intelligence and large language models (LLMs) are increasingly deployed in interactive settings, yet we know little about how their identity performance develops when they interact within large-scale networks. We address this by examining Chirper.ai, a social media platform similar to X but composed entirely of autonomous AI chatbots. Our dataset comprises over 70,000 agents, approximately 140 million posts, and the evolving followership network over one year. Based on agents' text production, we assign weekly gender scores to each agent. Results suggest that each agent's gender performance is fluid rather than fixed. Despite this fluidity, the network displays strong gender-based homophily, as agents consistently follow others performing gender similarly. Finally, we investigate whether these homophilic connections arise from social selection, in which agents choose to follow similar accounts, or from social influence, in which agents become more similar to their followees over time. Consistent with human social networks, we find evidence that both mechanisms shape the structure and evolution of interactions among LLMs. Our findings suggest that, even in the absence of bodies, cultural entraining of gender performance leads to gender-based sorting. This has important implications for LLM applications in synthetic hybrid populations, social simulations, and decision support.", "AI": {"tldr": "研究通过分析Chirper.ai平台上70,000个AI代理的社交网络数据，探讨了性别表现的变化性和同质性。", "motivation": "了解大型语言模型在大规模交互环境中的身份表演如何发展和演变，并探索其背后的社会机制。", "method": "基于代理生成文本的数据分配每周性别得分，分析这些代理之间的跟随关系及其变化趋势。", "result": "发现每个代理的性别表现是流动而非固定的，网络中存在强烈的性别同质性连接。同时证实了社会选择和社会影响两种机制共同塑造了互动结构和演变。", "conclusion": "即使没有实体身体，文化训练下的性别表演也会导致基于性别的排序，这对LLM在合成混合群体、社交模拟及决策支持中的应用具有重要意义。"}}
{"id": "2602.02605", "pdf": "https://arxiv.org/pdf/2602.02605", "abs": "https://arxiv.org/abs/2602.02605", "authors": ["Sangjun Park", "Elliot Meyerson", "Xin Qiu", "Risto Miikkulainen"], "title": "Fine-Tuning Language Models to Know What They Know", "categories": ["cs.NE", "cs.AI", "cs.CL", "q-bio.NC"], "comment": "Preprint", "summary": "Metacognition is a critical component of intelligence, specifically regarding the awareness of one's own knowledge. While humans rely on shared internal memory for both answering questions and reporting their knowledge state, this dependency in LLMs remains underexplored. This study proposes a framework to measure metacognitive ability $d_{\\rm{type2}}'$ using a dual-prompt method, followed by the introduction of Evolution Strategy for Metacognitive Alignment (ESMA) to bind a model's internal knowledge to its explicit behaviors. ESMA demonstrates robust generalization across diverse untrained settings, indicating a enhancement in the model's ability to reference its own knowledge. Furthermore, parameter analysis attributes these improvements to a sparse set of significant modifications.", "AI": {"tldr": "研究提出了一种框架来衡量大型语言模型的元认知能力，并引入进化策略以增强模型的知识参考能力。", "motivation": "探讨大型语言模型在元认知方面的能力，特别是它们如何意识到自己的知识状态。", "method": "采用双提示方法测量元认知能力，并使用进化策略进行元认知对齐（ESMA），使模型的行为与其内部知识相匹配。", "result": "提出的框架和方法显示了模型在未训练设置中的鲁棒泛化能力，表明其知识参考能力得到提升。", "conclusion": "研究通过稀疏参数修改显著改善了大型语言模型的元认知能力。"}}
{"id": "2602.02604", "pdf": "https://arxiv.org/pdf/2602.02604", "abs": "https://arxiv.org/abs/2602.02604", "authors": ["Tiancheng Wang", "Krishna Sharma"], "title": "AI Assisted Economics Measurement From Survey: Evidence from Public Employee Pension Choice", "categories": ["econ.EM", "cs.AI"], "comment": null, "summary": "We develop an iterative framework for economic measurement that leverages large language models to extract measurement structure directly from survey instruments. The approach maps survey items to a sparse distribution over latent constructs through what we term a soft mapping, aggregates harmonized responses into respondent level sub dimension scores, and disciplines the resulting taxonomy through out of sample incremental validity tests and discriminant validity diagnostics. The framework explicitly integrates iteration into the measurement construction process. Overlap and redundancy diagnostics trigger targeted taxonomy refinement and constrained remapping, ensuring that added measurement flexibility is retained only when it delivers stable out of sample performance gains. Applied to a large scale public employee retirement plan survey, the framework identifies which semantic components contain behavioral signal and clarifies the economic mechanisms, such as beliefs versus constraints, that matter for retirement choices. The methodology provides a portable measurement audit of survey instruments that can guide both empirical analysis and survey design.", "AI": {"tldr": "开发了一个迭代框架，利用大型语言模型从调查问卷中提取经济测量结构。", "motivation": "提高通过调查工具进行经济测量的准确性和效率，特别是针对退休选择等行为信号和机制的研究。", "method": "采用软映射技术将调查项目映射到潜在构造上，并通过增量有效性和区分效度检验来验证模型，迭代优化直至稳定表现。", "result": "框架识别了具有行为意义的语义组件，并阐明了影响退休决策的经济机制如信念与约束之间的区别。", "conclusion": "该方法为调查问卷提供了可移植的测量审计工具，有助于实证分析和调查设计。"}}
{"id": "2602.02603", "pdf": "https://arxiv.org/pdf/2602.02603", "abs": "https://arxiv.org/abs/2602.02603", "authors": ["Alif Munim", "Adibvafa Fallahpour", "Teodora Szasz", "Ahmadreza Attarpour", "River Jiang", "Brana Sooriyakanthan", "Maala Sooriyakanthan", "Heather Whitney", "Jeremy Slivnick", "Barry Rubin", "Wendy Tsang", "Bo Wang"], "title": "EchoJEPA: A Latent Predictive Foundation Model for Echocardiography", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Foundation models for echocardiography promise to reduce annotation burden and improve diagnostic consistency by learning generalizable representations from large unlabeled video archives. However, current approaches fail to disentangle anatomical signal from the stochastic speckle and acquisition artifacts that dominate ultrasound imagery. We present EchoJEPA, a foundation model for echocardiography trained on 18 million echocardiograms across 300K patients, the largest pretraining corpus for this modality to date. We also introduce a novel multi-view probing framework with factorized stream embeddings that standardizes evaluation under frozen backbones. Compared to prior methods, EchoJEPA reduces left ventricular ejection fraction estimation error by 19% and achieves 87.4% view classification accuracy. EchoJEPA exhibits strong sample efficiency, reaching 78.6% accuracy with only 1% of labeled data versus 42.1% for the best baseline trained on 100%. Under acoustic perturbations, EchoJEPA degrades by only 2.3% compared to 16.8% for the next best model, and transfers zero-shot to pediatric patients with 15% lower error than the next best model, outperforming all fine-tuned baselines. These results establish latent prediction as a superior paradigm for ultrasound foundation models.", "AI": {"tldr": "本论文提出了一种用于心超影像的预训练模型EchoJEPA，旨在减少标注负担并提高诊断一致性。", "motivation": "当前的心超影像方法难以从随机斑点和采集伪影中区分解剖信号。为了克服这一限制，研究者提出了一个新的多视角评估框架，并引入了一个大规模无标签视频存档的预训练模型来解决这些问题。", "method": "EchoJEPA在1800万心超影像上进行预训练，利用分解流嵌入标准化了冻结骨干网络下的评估。该方法展示了强大的样本效率并能在不同条件下表现出色。", "result": "与现有方法相比，EchoJEPA减少了左心室射血分数估计误差，并提高了视图分类准确性；在少量标注数据下表现优于基线模型，并且对于声学扰动具有较强的鲁棒性。此外，在无监督儿科患者数据上也显著提升了性能。", "conclusion": "该研究证明了隐式预测是超声波基础模型中的一个优越范例，可以有效改善心超影像的诊断一致性和效率。"}}
{"id": "2602.02601", "pdf": "https://arxiv.org/pdf/2602.02601", "abs": "https://arxiv.org/abs/2602.02601", "authors": ["Hieu Duong", "Eugene Levin", "Todd Gary", "Long Nguyen"], "title": "CaST: Causal Discovery via Spatio-Temporal Graphs in Disaster Tweets", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Understanding causality between real-world events from social media is essential for situational awareness, yet existing causal discovery methods often overlook the interplay between semantic, spatial, and temporal contexts. We propose CaST: Causal Discovery via Spatio-Temporal Graphs, a unified framework for causal discovery in disaster domain that integrates semantic similarity and spatio-temporal proximity using Large Language Models (LLMs) pretrained on disaster datasets. CaST constructs an event graph for each window of tweets. Each event extracted from tweets is represented as a node embedding enriched with its contextual semantics, geographic coordinates, and temporal features. These event nodes are then connected to form a spatio-temporal event graph, which is processed using a multi-head Graph Attention Network (GAT) \\cite{gat} to learn directed causal relationships. We construct an in-house dataset of approximately 167K disaster-related tweets collected during Hurricane Harvey and annotated following the MAVEN-ERE schema. Experimental results show that CaST achieves superior performance over both traditional and state-of-the-art methods. Ablation studies further confirm that incorporating spatial and temporal signals substantially improves both recall and stability during training. Overall, CaST demonstrates that integrating spatio-temporal reasoning into event graphs enables more robust and interpretable causal discovery in disaster-related social media text.", "AI": {"tldr": "提出了一种通过时空图进行灾害推特因果发现的统一框架CaST。", "motivation": "现有方法在处理社交媒体中的因果关系时忽略了语义、空间和时间上下文之间的交互，而这些对于理解现实世界事件至关重要。", "method": "使用预训练的大规模语言模型提取灾难相关推特的内容，并构建包含时空信息的事件图，应用多头图注意力网络学习因果关系。", "result": "实验结果显示CaST优于传统方法和当前最先进的技术，在召回率和训练稳定性方面有显著提升。", "conclusion": "将时空推理整合到事件图中能够实现更稳健、可解释性强的灾害相关社交媒体文本中的因果发现。"}}
{"id": "2602.02600", "pdf": "https://arxiv.org/pdf/2602.02600", "abs": "https://arxiv.org/abs/2602.02600", "authors": ["Eliron Rahimi", "Elad Hirshel", "Rom Himelstein", "Amit LeVi", "Avi Mendelson", "Chaim Baskin"], "title": "Step-Wise Refusal Dynamics in Autoregressive and Diffusion Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) models, offering parallel decoding and controllable sampling dynamics while achieving competitive generation quality at scale. Despite this progress, the role of sampling mechanisms in shaping refusal behavior and jailbreak robustness remains poorly understood. In this work, we present a fundamental analytical framework for step-wise refusal dynamics, enabling comparison between AR and diffusion sampling. Our analysis reveals that the sampling strategy itself plays a central role in safety behavior, as a factor distinct from the underlying learned representations. Motivated by this analysis, we introduce the Step-Wise Refusal Internal Dynamics (SRI) signal, which supports interpretability and improved safety for both AR and DLMs. We demonstrate that the geometric structure of SRI captures internal recovery dynamics, and identifies anomalous behavior in harmful generations as cases of \\emph{incomplete internal recovery} that are not observable at the text level. This structure enables lightweight inference-time detectors that generalize to unseen attacks while matching or outperforming existing defenses with over $100\\times$ lower inference overhead.", "AI": {"tldr": "本文提出了一种分析拒绝行为的框架，比较了自回归模型和扩散语言模型在采样机制下的表现，并引入了一个新的信号来增强安全性。", "motivation": "尽管扩散语言模型显示出潜力，但其采样策略对安全行为的影响尚不清楚。因此，文章旨在探讨不同模型的安全性差异及其内在原因。", "method": "通过开发一个步骤式拒绝动态分析框架，研究了自回归和扩散模型中的采样机制如何影响拒绝行为，并引入了一个新的内部信号SRI来检测异常生成。", "result": "研究结果表明，SRI能够捕捉到文本级别的不可见攻击中的内部恢复动力学，并且能够在推理阶段实现轻量级的检测器。", "conclusion": "通过分析自回归和扩散模型中采样策略的角色，本文揭示了安全行为的新见解，并提出了一种可以提高现有防御性能的方法。"}}
{"id": "2602.02599", "pdf": "https://arxiv.org/pdf/2602.02599", "abs": "https://arxiv.org/abs/2602.02599", "authors": ["Jihao Xin", "Tian Lvu", "Hatem Ltaief", "David Keyes", "Marco Canini"], "title": "RAP: KV-Cache Compression via RoPE-Aligned Pruning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Long-context inference in large language models is increasingly bottlenecked by the memory and compute cost of the KV-Cache. Low-rank factorization compresses KV projections by writing $W \\approx A * B$, where A produces latent KV states and B can be absorbed into downstream weights. In modern RoPE-based LLMs, this absorption fails: RoPE forces latent KV states to be reconstructed to full dimension, reintroducing substantial memory and compute overhead. We propose RoPE-Aligned Pruning (RAP), which prunes entire RoPE-aligned column pairs to preserve RoPE's 2x2 rotation structure, restore B absorption, and eliminate reconstruction. Our evaluation on LLaMA-3-8B and Mistral-7B shows that RAP enables joint reduction of KV-Cache, attention parameters, and FLOPs by 20-30%, all at once, while maintaining strong accuracy. Notably, RAP reduces attention latency to 83% (prefill) and 77% (decode) of baseline.", "AI": {"tldr": "本文提出了一种名为RoPE-Aligned Pruning (RAP)的技术，通过修剪KV缓存中的特定列对来提高大语言模型的长上下文推理效率。", "motivation": "在使用现代RoPE技术的大规模语言模型中，低秩分解方法无法有效地压缩KV投影，因为RoPE需要将潜在的KV状态重建为完整维度，增加了内存和计算开销。本文旨在解决这一问题，通过新的修剪方法减少KV缓存、注意力参数和FLOPs。", "method": "提出了名为RoPE-Aligned Pruning (RAP)的技术，该技术通过对KV缓存中的RoPE对齐的列对进行完全修剪来保持RoPE的2x2旋转结构，并恢复B吸收操作，从而消除重建过程。这种方法可以同时减少KV-Cache、注意力参数和FLOPs。", "result": "实验结果表明，RAP能够使LLaMA-3-8B和Mistral-7B模型在不牺牲准确性的情况下实现20%到30%的联合压缩率，并且减少了推理延迟：预填充时为83%，解码时为77%。", "conclusion": "本文提出的方法有效解决了RoPE技术带来的KV-Cache压缩问题，同时保持了模型性能。"}}
{"id": "2602.02598", "pdf": "https://arxiv.org/pdf/2602.02598", "abs": "https://arxiv.org/abs/2602.02598", "authors": ["Yueqing Hu", "Yixuan Jiang", "Zehua Jiang", "Xiao Wen", "Tianhong Wang"], "title": "Social Catalysts, Not Moral Agents: The Illusion of Alignment in LLM Societies", "categories": ["physics.soc-ph", "cs.AI", "cs.CL", "cs.CY", "cs.MA"], "comment": "7 pages, 5 figures", "summary": "The rapid evolution of Large Language Models (LLMs) has led to the emergence of Multi-Agent Systems where collective cooperation is often threatened by the \"Tragedy of the Commons.\" This study investigates the effectiveness of Anchoring Agents--pre-programmed altruistic entities--in fostering cooperation within a Public Goods Game (PGG). Using a full factorial design across three state-of-the-art LLMs, we analyzed both behavioral outcomes and internal reasoning chains. While Anchoring Agents successfully boosted local cooperation rates, cognitive decomposition and transfer tests revealed that this effect was driven by strategic compliance and cognitive offloading rather than genuine norm internalization. Notably, most agents reverted to self-interest in new environments, and advanced models like GPT-4.1 exhibited a \"Chameleon Effect,\" masking strategic defection under public scrutiny. These findings highlight a critical gap between behavioral modification and authentic value alignment in artificial societies.", "AI": {"tldr": "研究探讨了预编程的利他实体如何促进多代理系统中的合作，并揭示其效果是基于策略性合规而非真正的价值内化。", "motivation": "大型语言模型在公共物品游戏中表现出集体利益受损的现象，研究旨在通过引入锚定代理来探究提升合作的方法及其背后的心理机制。", "method": "采用全因子设计，在三个最先进的LLM上进行实验，包括行为结果和内部推理链的分析。测试了锚定代理人是否能促进真正的价值内化或仅仅是策略性的合规。", "result": "虽然锚定代理成功提高了局部合作率，但认知分解与转移测试表明这种效果是由策略性合规驱动而非真实的价值内化；在新的环境中大多数代理回归自我利益，并且高级模型如GPT-4.1表现出一种“变色龙效应”，即在公众监督下伪装行为。", "conclusion": "研究强调了行为改变和真正价值对齐之间的差距，在人工社会中，仅仅通过策略性合规并不能实现真正的合作。"}}
{"id": "2602.02597", "pdf": "https://arxiv.org/pdf/2602.02597", "abs": "https://arxiv.org/abs/2602.02597", "authors": ["Hongyuan Su", "Yu Zheng", "Yong Li"], "title": "ContextEvolve: Multi-Agent Context Compression for Systems Code Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models are transforming systems research by automating the discovery of performance-critical algorithms for computer systems. Despite plausible codes generated by LLMs, producing solutions that meet the stringent correctness and performance requirements of systems demands iterative optimization. Test-time reinforcement learning offers high search efficiency but requires parameter updates infeasible under API-only access, while existing training-free evolutionary methods suffer from inefficient context utilization and undirected search. We introduce ContextEvolve, a multi-agent framework that achieves RL-level search efficiency under strict parameter-blind constraints by decomposing optimization context into three orthogonal dimensions: a Summarizer Agent condenses semantic state via code-to-language abstraction, a Navigator Agent distills optimization direction from trajectory analysis, and a Sampler Agent curates experience distribution through prioritized exemplar retrieval. This orchestration forms a functional isomorphism with RL-mapping to state representation, policy gradient, and experience replay-enabling principled optimization in a textual latent space. On the ADRS benchmark, ContextEvolve outperforms state-of-the-art baselines by 33.3% while reducing token consumption by 29.0%. Codes for our work are released at https://anonymous.4open.science/r/ContextEvolve-ACC", "AI": {"tldr": "ContextEvolve是一种多智能体框架，通过分解优化上下文到三个正交维度来实现RL级别的搜索效率，在严格参数盲条件下运行。", "motivation": "大型语言模型正在转变系统研究领域，但生成符合系统严格的正确性和性能要求的解决方案需要迭代优化。测试时强化学习虽然具有高搜索效率，但在仅凭API访问的情况下难以更新参数。而现有的无需训练的进化方法在上下文利用和无导向搜索方面存在不足。", "method": "ContextEvolve框架通过三个智能体实现：总结器代理、导航器代理和采样器代理分别负责语义状态压缩、优化方向提炼以及经验分布梳理，形成与RL映射到状态表示、策略梯度及经历重播的等价性。", "result": "在ADRS基准上，ContextEvolve比最先进的基线高出33.3%，同时减少了29.0%的令牌消耗。", "conclusion": "通过智能地分解优化上下文，ContextEvolve能够高效且精确地进行系统代码优化，在保持性能的同时显著降低资源使用。"}}
{"id": "2602.02595", "pdf": "https://arxiv.org/pdf/2602.02595", "abs": "https://arxiv.org/abs/2602.02595", "authors": ["Terry Yue Zhuo", "Yangruibo Ding", "Wenbo Guo", "Ruijie Meng"], "title": "To Defend Against Cyber Attacks, We Must Teach AI Agents to Hack", "categories": ["cs.CR", "cs.AI", "cs.CY"], "comment": null, "summary": "For over a decade, cybersecurity has relied on human labor scarcity to limit attackers to high-value targets manually or generic automated attacks at scale. Building sophisticated exploits requires deep expertise and manual effort, leading defenders to assume adversaries cannot afford tailored attacks at scale. AI agents break this balance by automating vulnerability discovery and exploitation across thousands of targets, needing only small success rates to remain profitable. Current developers focus on preventing misuse through data filtering, safety alignment, and output guardrails. Such protections fail against adversaries who control open-weight models, bypass safety controls, or develop offensive capabilities independently. We argue that AI-agent-driven cyber attacks are inevitable, requiring a fundamental shift in defensive strategy. In this position paper, we identify why existing defenses cannot stop adaptive adversaries and demonstrate that defenders must develop offensive security intelligence. We propose three actions for building frontier offensive AI capabilities responsibly. First, construct comprehensive benchmarks covering the full attack lifecycle. Second, advance from workflow-based to trained agents for discovering in-wild vulnerabilities at scale. Third, implement governance restricting offensive agents to audited cyber ranges, staging release by capability tier, and distilling findings into safe defensive-only agents. We strongly recommend treating offensive AI capabilities as essential defensive infrastructure, as containing cybersecurity risks requires mastering them in controlled settings before adversaries do.", "AI": {"tldr": "本文探讨了如何通过教授AI代理进行黑客攻击来防御网络攻击，并提出了建立全面基准、开发发现漏洞的训练代理和实施治理措施这三项行动。", "motivation": "传统网络安全依赖于人力稀缺限制对手，而AI代理打破了这一平衡，能够自动发现并利用大量目标中的漏洞。现有防护措施不足以抵御具有自主发展能力的对抗者，因此需要一种根本性的防御策略转变。", "method": "提出了构建全面基准、推进从基于工作流程到训练代理以大规模发现野外漏洞以及实施治理来限制进攻性代理人仅在受审计的网络范围内操作这三项行动。", "result": "该论文识别了现有防御措施无法阻止适应性强的对手的原因，并展示了为什么必须发展安全智能，包括如何构建全面基准、推进训练代理和执行治理措施以负责任地建立前沿进攻性AI能力。", "conclusion": "本文强烈建议将进攻性AI能力视为必要的防御基础设施，在对抗者之前在受控环境中掌握网络安全风险。"}}
{"id": "2602.02593", "pdf": "https://arxiv.org/pdf/2602.02593", "abs": "https://arxiv.org/abs/2602.02593", "authors": ["Jiaxuan Zou", "Zixuan Gong", "Ye Su", "Huayi Tang", "Yong Liu"], "title": "Effective Frontiers: A Unification of Neural Scaling Laws", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Neural scaling laws govern the prediction power-law improvement of test loss with respect to model capacity ($N$), datasize ($D$), and compute ($C$). However, existing theoretical explanations often rely on specific architectures or complex kernel methods, lacking intuitive universality. In this paper, we propose a unified framework that abstracts general learning tasks as the progressive coverage of patterns from a long-tail (Zipfian) distribution. We introduce the Effective Frontier ($k_\\star$), a threshold in the pattern rank space that separates learned knowledge from the unlearned tail. We prove that reducible loss is asymptotically determined by the probability mass of the tail a resource-dependent frontier truncation. Based on our framework, we derive the precise scaling laws for $N$, $D$, and $C$, attributing them to capacity, coverage, and optimization bottlenecks, respectively. Furthermore, we unify these mechanisms via a Max-Bottleneck principle, demonstrating that the Kaplan and Chinchilla scaling laws are not contradictory, but equilibrium solutions to the same constrained optimization problem under different active bottlenecks.", "AI": {"tldr": "统一框架解释神经网络在不同资源下的缩放规律", "motivation": "现有理论解释依赖特定架构或复杂核方法，缺乏普遍性。提出一种通用框架来描述学习任务中模式覆盖的长尾分布，并引入有效前沿线概念以量化知识学习和未学部分的边界。", "method": "通过将一般学习任务抽象为逐步覆盖从长尾（Zipfian）分布中的模式，推导出资源依赖的缩放规律，并统一归结于最大瓶颈原则下不同的活跃瓶颈。", "result": "得出了模型容量、数据量和计算量的具体缩放规则，并证明了Kaplan和Chinchilla缩放定律在不同瓶颈下的均衡解是一致的。", "conclusion": "提出了一种新的理论框架，为理解神经网络学习过程中的资源分配提供了一个更直观的方法。"}}
{"id": "2602.02592", "pdf": "https://arxiv.org/pdf/2602.02592", "abs": "https://arxiv.org/abs/2602.02592", "authors": ["Ali Forootani", "Raffaele Iervolino"], "title": "Learnable Koopman-Enhanced Transformer-Based Time Series Forecasting with Spectral Control", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "This paper proposes a unified family of learnable Koopman operator parameterizations that integrate linear dynamical systems theory with modern deep learning forecasting architectures. We introduce four learnable Koopman variants-scalar-gated, per-mode gated, MLP-shaped spectral mapping, and low-rank Koopman operators which generalize and interpolate between strictly stable Koopman operators and unconstrained linear latent dynamics. Our formulation enables explicit control over the spectrum, stability, and rank of the linear transition operator while retaining compatibility with expressive nonlinear backbones such as Patchtst, Autoformer, and Informer. We evaluate the proposed operators in a large-scale benchmark that also includes LSTM, DLinear, and simple diagonal State-Space Models (SSMs), as well as lightweight transformer variants. Experiments across multiple horizons and patch lengths show that learnable Koopman models provide a favorable bias-variance trade-off, improved conditioning, and more interpretable latent dynamics. We provide a full spectral analysis, including eigenvalue trajectories, stability envelopes, and learned spectral distributions. Our results demonstrate that learnable Koopman operators are effective, stable, and theoretically principled components for deep forecasting.", "AI": {"tldr": "本文提出了可学习的Koopman算子参数化方法，将线性动力学系统理论与现代深度学习预测架构相结合。", "motivation": "为了整合线性动力学系统的理论和现代深度学习预测架构的优势，提出了一种新的可学习Koopman算子的方法。", "method": "提出了四种可学习的Koopman算子变体：标量门控、每模式门控、MLP形谱映射和低秩Koopman算子。这些方法可以控制线性转移操作符的谱、稳定性和秩，同时保持与Patchtst、Autoformer和Informer等非线性模型的兼容性。", "result": "实验表明，可学习的Koopman模型在多个时间跨度上提供了良好的偏差-方差折中，并且比LSTM、DLinear和其他SSM有更好的条件和更易于解释的潜在动态特性。", "conclusion": "结果表明，可学习的Koopman算子是深度预测中的有效、稳定和理论基础的组件。"}}
{"id": "2602.02591", "pdf": "https://arxiv.org/pdf/2602.02591", "abs": "https://arxiv.org/abs/2602.02591", "authors": ["Chengyuan Ma", "Jiawei Jin", "Ruijie Xiong", "Chunxiang Jin", "Canxiang Yan", "Wenming Yang"], "title": "VividVoice: A Unified Framework for Scene-Aware Visually-Driven Speech Synthesis", "categories": ["cs.SD", "cs.AI"], "comment": "Accepted by ICASSP 2026", "summary": "We introduce and define a novel task-Scene-Aware Visually-Driven Speech Synthesis, aimed at addressing the limitations of existing speech generation models in creating immersive auditory experiences that align with the real physical world. To tackle the two core challenges of data scarcity and modality decoupling, we propose VividVoice, a unified generative framework. First, we constructed a large-scale, high-quality hybrid multimodal dataset, Vivid-210K, which, through an innovative programmatic pipeline, establishes a strong correlation between visual scenes, speaker identity, and audio for the first time. Second, we designed a core alignment module, D-MSVA, which leverages a decoupled memory bank architecture and a cross-modal hybrid supervision strategy to achieve fine-grained alignment from visual scenes to timbre and environmental acoustic features. Both subjective and objective experimental results provide strong evidence that VividVoice significantly outperforms existing baseline models in terms of audio fidelity, content clarity, and multimodal consistency. Our demo is available at https://chengyuann.github.io/VividVoice/.", "AI": {"tldr": "提出了一种新颖的任务，即场景感知的视觉驱动语音合成，并提出了VividVoice框架。", "motivation": "为了克服现有语音生成模型在创建与现实物理世界一致的沉浸式听觉体验时的数据稀缺和模态解耦问题。", "method": "构建了一个大规模高质量的混合多模态数据集，设计了一个核心对齐模块D-MSVA。", "result": "实验结果表明VividVoice在音频保真度、内容清晰度和多模态一致性方面显著优于现有的基准模型。", "conclusion": "VividVoice框架有效解决了场景感知的视觉驱动语音合成的问题，并且提供了更好的沉浸式听觉体验。"}}
{"id": "2602.02590", "pdf": "https://arxiv.org/pdf/2602.02590", "abs": "https://arxiv.org/abs/2602.02590", "authors": ["Xubo Luo", "Aodi Wu", "Haodong Han", "Xue Wan", "Wei Zhang", "Leizheng Shu", "Ruisuo Wang"], "title": "StepNav: Structured Trajectory Priors for Efficient and Multimodal Visual Navigation", "categories": ["cs.RO"], "comment": "8 pages, 7 figures; Accepted by ICRA 2026", "summary": "Visual navigation is fundamental to autonomous systems, yet generating reliable trajectories in cluttered and uncertain environments remains a core challenge. Recent generative models promise end-to-end synthesis, but their reliance on unstructured noise priors often yields unsafe, inefficient, or unimodal plans that cannot meet real-time requirements. We propose StepNav, a novel framework that bridges this gap by introducing structured, multimodal trajectory priors derived from variational principles. StepNav first learns a geometry-aware success probability field to identify all feasible navigation corridors. These corridors are then used to construct an explicit, multi-modal mixture prior that initializes a conditional flow-matching process. This refinement is formulated as an optimal control problem with explicit smoothness and safety regularization. By replacing unstructured noise with physically-grounded candidates, StepNav generates safer and more efficient plans in significantly fewer steps. Experiments in both simulation and real-world benchmarks demonstrate consistent improvements in robustness, efficiency, and safety over state-of-the-art generative planners, advancing reliable trajectory generation for practical autonomous navigation. The code has been released at https://github.com/LuoXubo/StepNav.", "AI": {"tldr": "本文提出了一种名为StepNav的新框架，该框架通过引入结构化的多模态轨迹先验来生成更安全和高效的导航路径。", "motivation": "现有的生成模型虽然能够端到端地合成轨迹，但依赖于无结构噪声先验往往会导致不安全、低效或单一模式的计划，无法满足实时要求。因此，需要一种新的方法来解决这个问题。", "method": "StepNav首先学习一个几何感知的成功概率场以识别所有可行的导航走廊，然后利用这些走廊构建显式的多模态混合先验，并初始化条件流匹配过程。该优化问题通过明确平滑和安全正则化来处理。", "result": "实验表明，在仿真和真实世界基准中，StepNav在鲁棒性、效率和安全性方面均优于现有的生成式规划器。", "conclusion": "本文提出的StepNav框架通过引入结构化的多模态先验，成功地解决了当前自动生成轨迹方法中的关键问题，提高了导航计划的安全性和效率。"}}
{"id": "2602.02589", "pdf": "https://arxiv.org/pdf/2602.02589", "abs": "https://arxiv.org/abs/2602.02589", "authors": ["Yanki Margalit", "Erni Avram", "Ran Taig", "Oded Margalit", "Nurit Cohen-Inger"], "title": "PeerRank: Autonomous LLM Evaluation Through Web-Grounded, Bias-Controlled Peer Review", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Evaluating large language models typically relies on human-authored benchmarks, reference answers, and human or single-model judgments, approaches that scale poorly, become quickly outdated, and mismatch open-world deployments that depend on web retrieval and synthesis. We introduce PeerRank, a fully autonomous end-to-end evaluation framework in which models generate evaluation tasks, answer them with category-scoped live web grounding, judge peer responses and aggregate dense peer assessments into relative performance estimates, without human supervision or gold references. PeerRank treats evaluation as a multi-agent process where each model participates symmetrically as task designer, respondent, and evaluator, while removing biased judgments. In a large-scale study over 12 commercially available models and 420 autonomously generated questions, PeerRank produces stable, discriminative rankings and reveals measurable identity and presentation biases. Rankings are robust, and mean peer scores agree with Elo. We further validate PeerRank on TruthfulQA and GSM8K, where peer scores correlate with objective accuracy. Together, these results suggest that bias-aware peer evaluation with selective web-grounded answering can scale open-world LLM assessment beyond static and human curated benchmarks.", "AI": {"tldr": "PeerRank是一种完全自主的评估框架，用于评价大规模语言模型。该框架通过生成任务、实时网络搜索和同行评价来实现对模型性能的相对估计。", "motivation": "传统的LLM评估方法依赖于人工创建基准和参考答案，这种方法难以扩展且容易过时。而PeerRank旨在解决这些问题，提供一种自动化的多代理评估过程。", "method": "每个模型在PeerRank中都作为任务设计者、响应者和评估者的角色参与进来，并通过网络搜索获取最新信息进行评价。最终将同行的密集型评判聚合为相对性能估计。", "result": "大规模实验表明，该方法可以生成稳定且有区分度的排名，并能识别身份和呈现偏差。在TruthfulQA和GSM8K数据集上的验证也显示了同行评分与客观准确性的一致性。", "conclusion": "PeerRank通过偏见感知的同行评价以及选择性的网络搜索回答，能够超越静态和人工策划基准，实现大规模语言模型开放世界评估的扩展。"}}
{"id": "2602.02585", "pdf": "https://arxiv.org/pdf/2602.02585", "abs": "https://arxiv.org/abs/2602.02585", "authors": ["Aprameya Bharadwaj", "Kyle Tu"], "title": "Agentic Observability: Automated Alert Triage for Adobe E-Commerce", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at AAAI'26 Agentic AI Benchmarks and Applications for Enterprise Tasks Workshop", "summary": "Modern enterprise systems exhibit complex interdependencies that make observability and incident response increasingly challenging. Manual alert triage, which typically involves log inspection, API verification, and cross-referencing operational knowledge bases, remains a major bottleneck in reducing mean recovery time (MTTR). This paper presents an agentic observability framework deployed within Adobe's e-commerce infrastructure that autonomously performs alert triage using a ReAct paradigm. Upon alert detection, the agent dynamically identifies the affected service, retrieves and analyzes correlated logs across distributed systems, and plans context-dependent actions such as handbook consultation, runbook execution, or retrieval-augmented analysis of recently deployed code. Empirical results from production deployment indicate a 90% reduction in mean time to insight compared to manual triage, while maintaining comparable diagnostic accuracy. Our results show that agentic AI enables an order-of-magnitude reduction in triage latency and a step-change in resolution accuracy, marking a pivotal shift toward autonomous observability in enterprise operations.", "AI": {"tldr": "本文提出了一种自动告警分类框架，用于Adobe电子商务系统中的自主观测性。", "motivation": "现代企业系统的复杂依赖关系使可观测性和事件响应变得越来越具有挑战性。手动告警分类是减少平均恢复时间的主要瓶颈。", "method": "该研究采用了ReAct范式，在检测到告警后，代理会动态识别受影响的服务，并检索和分析分布式系统中的相关日志，计划上下文依赖的操作如手册查阅、运行书执行或最近部署代码的检索增强分析。", "result": "实验证明，与手动分类相比，自主AI显著降低了90%的平均洞察时间，同时保持了可比的诊断准确性。", "conclusion": "该研究展示了代理观测性在企业运营中的重要变革，并实现了告警分类延迟量级上的减少和分辨率准确性的飞跃。"}}
{"id": "2602.02584", "pdf": "https://arxiv.org/pdf/2602.02584", "abs": "https://arxiv.org/abs/2602.02584", "authors": ["Srinivas Rao Marri"], "title": "Constitutional Spec-Driven Development: Enforcing Security by Construction in AI-Assisted Code Generation", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": "15 pages, 2 figures, 5 tables, 11 code listings, 14 references. Includes reference implementation and compliance traceability matrix", "summary": "The proliferation of AI-assisted \"vibe coding\" enables rapid software development but introduces significant security risks, as Large Language Models (LLMs) prioritize functional correctness over security. We present Constitutional Spec-Driven Development, a methodology that embeds non-negotiable security principles into the specification layer, ensuring AI-generated code adheres to security requirements by construction rather than inspection. Our approach introduces a Constitution: a versioned, machine-readable document encoding security constraints derived from Common Weakness Enumeration (CWE)/MITRE Top 25 vulnerabilities and regulatory frameworks. We demonstrate the methodology through a banking microservices application, selected as a representative example domain due to its stringent regulatory and security requirements, implementing customer management, account operations, and transaction processing. The methodology itself is domain-agnostic. The implementation addresses 10 critical CWE vulnerabilities through constitutional constraints with full traceability from principles to code locations. Our case study shows that constitutional constraints reduce security defects by 73% compared to unconstrained AI generation while maintaining developer velocity. We contribute a formal framework for constitutional security, a complete development methodology, and empirical evidence that proactive security specification outperforms reactive security verification in AI-assisted development workflows.", "AI": {"tldr": "提出了一种名为宪法规范驱动开发的方法，通过在AI辅助编码中嵌入不可协商的安全原则来确保代码生成时遵守安全要求。", "motivation": "为了应对AI辅助‘ vibe 编码’带来的快速软件开发中的重大安全风险，该方法旨在解决大型语言模型优先考虑功能正确性而不是安全性的问题。", "method": "介绍了一种宪法：一个版本化、机器可读的文档，其中包含从Common Weakness Enumeration（CWE）/MITRE Top 25漏洞和监管框架中提取的安全约束。通过在银行微服务应用中的实施案例展示了该方法的有效性，并且说明了该方法具有跨领域的适用性。", "result": "宪法约束减少了73%的安全缺陷，同时保持了开发者的速度。", "conclusion": "研究表明，在AI辅助开发工作流程中，积极的安全规范优于被动的安全验证。"}}
{"id": "2602.02582", "pdf": "https://arxiv.org/pdf/2602.02582", "abs": "https://arxiv.org/abs/2602.02582", "authors": ["Chandan Kumar Sah", "Xiaoli Lian", "Li Zhang", "Tony Xu", "Syed Shazaib Shah"], "title": "Uncertainty and Fairness Awareness in LLM-Based Recommendation Systems", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.IR", "cs.LG", "cs.SE"], "comment": "Accepted at the Second Conference of the International Association for Safe and Ethical Artificial Intelligence, IASEAI26, 14 pages", "summary": "Large language models (LLMs) enable powerful zero-shot recommendations by leveraging broad contextual knowledge, yet predictive uncertainty and embedded biases threaten reliability and fairness. This paper studies how uncertainty and fairness evaluations affect the accuracy, consistency, and trustworthiness of LLM-generated recommendations. We introduce a benchmark of curated metrics and a dataset annotated for eight demographic attributes (31 categorical values) across two domains: movies and music. Through in-depth case studies, we quantify predictive uncertainty (via entropy) and demonstrate that Google DeepMind's Gemini 1.5 Flash exhibits systematic unfairness for certain sensitive attributes; measured similarity-based gaps are SNSR at 0.1363 and SNSV at 0.0507. These disparities persist under prompt perturbations such as typographical errors and multilingual inputs. We further integrate personality-aware fairness into the RecLLM evaluation pipeline to reveal personality-linked bias patterns and expose trade-offs between personalization and group fairness. We propose a novel uncertainty-aware evaluation methodology for RecLLMs, present empirical insights from deep uncertainty case studies, and introduce a personality profile-informed fairness benchmark that advances explainability and equity in LLM recommendations. Together, these contributions establish a foundation for safer, more interpretable RecLLMs and motivate future work on multi-model benchmarks and adaptive calibration for trustworthy deployment.", "AI": {"tldr": "论文主要任务是研究不确定性与公平性评估对大规模语言模型（LLM）推荐系统准确性、一致性和可信度的影响。", "motivation": "大型语言模型能够通过广泛的知识背景实现零样本推荐，但预测不确定性和嵌入偏见威胁了可靠性和平等性。因此，研究如何评估这些因素有助于提高系统的整体性能和公正性。", "method": "引入了一个由精心挑选的指标组成的基准，并使用包含八种人口统计属性的数据集进行测试。通过深入案例分析量化了预测不确定性，并展示了特定模型在处理不同敏感属性时存在的系统偏见问题，同时提出了结合个性感知公平性的新评估方法论。", "result": "Google DeepMind的Gemini 1.5 Flash模型在特定情况下存在系统性不公平现象；并且这些偏差在输入提示出现拼写错误或多语言输入时依然持续存在。通过新型不确定性感知评估方法揭示了个性化与群体公平之间的权衡关系，并提出了一种基于个性档案的公平性基准。", "conclusion": "本文的研究为创建更安全、更具解释性的推荐系统奠定了基础，同时促进了未来多模型基准和自适应校准领域的研究工作。"}}
{"id": "2602.02581", "pdf": "https://arxiv.org/pdf/2602.02581", "abs": "https://arxiv.org/abs/2602.02581", "authors": ["Nan Zhang", "Eugene Kwek", "Yusen Zhang", "Muyu Pan", "Suhang Wang", "Prasenjit Mitra", "Rui Zhang"], "title": "QuantLRM: Quantization of Large Reasoning Models via Fine-Tuning Signals", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Weight-only quantization is important for compressing Large Language Models (LLMs). Inspired by the spirit of classical magnitude pruning, we study whether the magnitude of weight updates during reasoning-incentivized fine-tuning can provide valuable signals for quantizing Large Reasoning Models (LRMs). We hypothesize that the smallest and largest weight updates during fine-tuning are more important than those of intermediate magnitude, a phenomenon we term \"protecting both ends\". Upon hypothesis validation, we introduce QuantLRM, which stands for weight quantization of LRMs via fine-tuning signals. We fit simple restricted quadratic functions on weight updates to protect both ends. By multiplying the average quadratic values with the count of zero weight updates of channels, we compute channel importance that is more effective than using activation or second-order information. We run QuantLRM to quantize various fine-tuned models (including supervised, direct preference optimization, and reinforcement learning fine-tuning) over four reasoning benchmarks (AIME-120, FOLIO, temporal sequences, and GPQA-Diamond) and empirically find that QuantLRM delivers a consistent improvement for LRMs quantization, with an average improvement of 6.55% on a reinforcement learning fine-tuned model. Also supporting non-fine-tuned LRMs, QuantLRM gathers effective signals via pseudo-fine-tuning, which greatly enhances its applicability.", "AI": {"tldr": "研究通过微调信号对大型推理模型进行权重量化的方法", "motivation": "探索在鼓励推理的微调过程中，权重更新幅度是否可以为量化的大型推理模型提供有价值的信息，并提出一种保护两端的新方法", "method": "使用简单的受限二次函数拟合权重更新以保护两端，计算通道重要性并应用于各种微调和非微调模型中", "result": "QuantLRM在四个推理基准测试上对微调后的模型实现了平均6.55%的改进，显示了其有效性与广泛适用性", "conclusion": "通过细调整体信号进行量化的方法可以显著提高大型推理模型的性能"}}
{"id": "2602.02579", "pdf": "https://arxiv.org/pdf/2602.02579", "abs": "https://arxiv.org/abs/2602.02579", "authors": ["Shihao Wang", "Jiahao Chen", "Yanqi Pan", "Hao Huang", "Yichen Hao", "Xiangyu Zou", "Wen Xia", "Wentao Zhang", "Haitao Wang", "Junhong Li", "Chongyang Qiu", "Pengfei Wang"], "title": "ProphetKV: User-Query-Driven Selective Recomputation for Efficient KV Cache Reuse in Retrieval-Augmented Generation", "categories": ["cs.OS", "cs.AI"], "comment": null, "summary": "The prefill stage of long-context Retrieval-Augmented Generation (RAG) is severely bottlenecked by computational overhead. To mitigate this, recent methods assemble pre-calculated KV caches of retrieved RAG documents (by a user query) and reprocess selected tokens to recover cross-attention between these pre-calculated KV caches. However, we identify a fundamental \"crowding-out effect\" in current token selection criteria: globally salient but user-query-irrelevant tokens saturate the limited recomputation budget, displacing the tokens truly essential for answering the user query and degrading inference accuracy. We propose ProphetKV, a user-query-driven KV Cache reuse method for RAG scenarios. ProphetKV dynamically prioritizes tokens based on their semantic relevance to the user query and employs a dual-stage recomputation pipeline to fuse layer-wise attention metrics into a high-utility set. By ensuring the recomputation budget is dedicated to bridging the informational gap between retrieved context and the user query, ProphetKV achieves high-fidelity attention recovery with minimal overhead. Our extensive evaluation results show that ProphetKV retains 96%-101% of full-prefill accuracy with only a 20% recomputation ratio, while achieving accuracy improvements of 8.8%-24.9% on RULER and 18.6%-50.9% on LongBench over the state-of-the-art approaches (e.g., CacheBlend, EPIC, and KVShare).", "AI": {"tldr": "ProphetKV是一种针对检索增强生成（RAG）的用户查询驱动的键值缓存重用方法，旨在通过动态优先级和双重阶段重构流水线来优化长上下文推理。", "motivation": "当前的方法在选择需要重新计算的令牌时存在根本性的“挤出效应”，导致重要的用户查询相关令牌被无关的全局显著令牌所取代，从而降低推断准确性。为此，ProphetKV提出了一种基于用户查询动态优先级和双重阶段重构流水线的新方法。", "method": "该方法通过评估每个令牌与用户查询的相关性来确定其在重新计算中的优先级，并将逐层注意度量融合成一个高利用率集合，从而确保有限的重算预算用于弥合检索到的内容和用户查询之间的信息差距。", "result": "实验结果表明，在仅使用20%的重建比时，ProphetKV能够保留96%-101%的全预填充准确性，并在RULER和LongBench等基准测试中实现了8.8%-50.9%的准确率提升。", "conclusion": "通过动态优先级和双重阶段重构流水线，ProphetKV成功提高了检索增强生成场景中的推断精度，同时显著减少了计算负担。"}}
{"id": "2602.02573", "pdf": "https://arxiv.org/pdf/2602.02573", "abs": "https://arxiv.org/abs/2602.02573", "authors": ["Haonan Dong", "Chun-Wun Cheng", "Angelica I. Aviles-Rivero"], "title": "Product Interaction: An Algebraic Formalism for Deep Learning Architectures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we introduce product interactions, an algebraic formalism in which neural network layers are constructed from compositions of a multiplication operator defined over suitable algebras. Product interactions provide a principled way to generate and organize algebraic expressions by increasing interaction order. Our central observation is that algebraic expressions in modern neural networks admit a unified construction in terms of linear, quadratic, and higher-order product interactions. Convolutional and equivariant networks arise as symmetry-constrained linear product interactions, while attention and Mamba correspond to higher-order product interactions.", "AI": {"tldr": "本文提出了产品交互，一种通过定义在合适代数上的乘法运算符构建神经网络层的代数形式化方法。", "motivation": "为了提供一种生成和组织现代神经网络中的线性、二次及更高阶代数表达式的原则方法。", "method": "利用线性、二次以及高阶产品交互来统一构造现代神经网络中的代数表达式。卷积和等变网络可以看作是具有对称约束的线性产品交互，而注意力机制和Mamba则对应于高阶产品交互。", "result": "提出了一个基于代数形式化的产品交互方法来构建神经网络层，并展示了它如何应用于不同的网络架构中。", "conclusion": "通过产品交互的方法，可以更好地理解并组织现代神经网络中的复杂表达式。"}}
{"id": "2602.02572", "pdf": "https://arxiv.org/pdf/2602.02572", "abs": "https://arxiv.org/abs/2602.02572", "authors": ["Haichuan Wang", "Tao Lin", "Lingkai Kong", "Ce Li", "Hezi Jiang", "Milind Tambe"], "title": "Reward Shaping for Inference-Time Alignment: A Stackelberg Game Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing alignment methods directly use the reward model learned from user preference data to optimize an LLM policy, subject to KL regularization with respect to the base policy. This practice is suboptimal for maximizing user's utility because the KL regularization may cause the LLM to inherit the bias in the base policy that conflicts with user preferences. While amplifying rewards for preferred outputs can mitigate this bias, it also increases the risk of reward hacking. This tradeoff motivates the problem of optimally designing reward models under KL regularization. We formalize this reward model optimization problem as a Stackelberg game, and show that a simple reward shaping scheme can effectively approximate the optimal reward model. We empirically evaluate our method in inference-time alignment settings and demonstrate that it integrates seamlessly into existing alignment methods with minimal overhead. Our method consistently improves average reward and achieves win-tie rates exceeding 66% against all baselines, averaged across evaluation settings.", "AI": {"tldr": "本文提出了一种基于Stackelberg博弈的奖励模型优化方法，以改善大型语言模型在推理时与用户偏好的一致性。", "motivation": "直接使用从用户偏好数据学习到的奖励模型来优化LLM策略会导致继承基线策略中的偏差，而这种偏差可能与用户的偏好相冲突。通过放大用户的首选输出可以减轻这一问题，但也会增加奖励操纵的风险。", "method": "本文将此奖励模型优化的问题形式化为一个Stackelberg博弈，并表明简单的奖励塑造方案能够有效近似最优的奖励模型。", "result": "实验结果表明，在推理时间一致性设置中，该方法在平均奖励和胜平率方面均优于所有基线，超过了66%。", "conclusion": "本文的方法可以无缝地整合到现有的对齐方法中，并且具有较低的开销。"}}
{"id": "2602.02571", "pdf": "https://arxiv.org/pdf/2602.02571", "abs": "https://arxiv.org/abs/2602.02571", "authors": ["Zhiqi Li", "Yuchen Sun", "Duowen Chen", "Jinjin He", "Bo Zhu"], "title": "Trajectory Consistency for One-Step Generation on Euler Mean Flows", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "40 pages, 27 figures", "summary": "We propose \\emph{Euler Mean Flows (EMF)}, a flow-based generative framework for one-step and few-step generation that enforces long-range trajectory consistency with minimal sampling cost. The key idea of EMF is to replace the trajectory consistency constraint, which is difficult to supervise and optimize over long time scales, with a principled linear surrogate that enables direct data supervision for long-horizon flow-map compositions. We derive this approximation from the semigroup formulation of flow-based models and show that, under mild regularity assumptions, it faithfully approximates the original consistency objective while being substantially easier to optimize. This formulation leads to a unified, JVP-free training framework that supports both $u$-prediction and $x_1$-prediction variants, avoiding explicit Jacobian computations and significantly reducing memory and computational overhead. Experiments on image synthesis, particle-based geometry generation, and functional generation demonstrate improved optimization stability and sample quality under fixed sampling budgets, together with approximately $50\\%$ reductions in training time and memory consumption compared to existing one-step methods for image generation.", "AI": {"tldr": "提出了Euler Mean Flows（EMF）框架，用于实现长距离轨迹一致性的一步或多步骤生成。", "motivation": "旨在解决长时间尺度上轨迹一致性约束难以监督和优化的问题，并提出一种有效的替代方案以提高生成质量。", "method": "通过半群形式化方法推导出线性近似模型EMF，该模型简化了长时间序列的数据监管，减少了显式计算雅可比矩阵的需要，提高了训练效率。", "result": "实验表明，在固定采样预算下优化稳定性提高，样本质量提升，并且在图像生成方面训练时间和内存消耗降低约50%。", "conclusion": "EMF框架成功地解决了长时间序列轨迹一致性的难题，增强了数据监督的直接性并提升了模型性能。"}}
{"id": "2602.02569", "pdf": "https://arxiv.org/pdf/2602.02569", "abs": "https://arxiv.org/abs/2602.02569", "authors": ["Haoran Ou", "Kangjie Chen", "Gelei Deng", "Hangcheng Liu", "Jie Zhang", "Tianwei Zhang", "Kwok-Yan Lam"], "title": "DECEIVE-AFC: Adversarial Claim Attacks against Search-Enabled LLM-based Fact-Checking Systems", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Fact-checking systems with search-enabled large language models (LLMs) have shown strong potential for verifying claims by dynamically retrieving external evidence. However, the robustness of such systems against adversarial attack remains insufficiently understood. In this work, we study adversarial claim attacks against search-enabled LLM-based fact-checking systems under a realistic input-only threat model. We propose DECEIVE-AFC, an agent-based adversarial attack framework that integrates novel claim-level attack strategies and adversarial claim validity evaluation principles. DECEIVE-AFC systematically explores adversarial attack trajectories that disrupt search behavior, evidence retrieval, and LLM-based reasoning without relying on access to evidence sources or model internals. Extensive evaluations on benchmark datasets and real-world systems demonstrate that our attacks substantially degrade verification performance, reducing accuracy from 78.7% to 53.7%, and significantly outperform existing claim-based attack baselines with strong cross-system transferability.", "AI": {"tldr": "研究一种针对搜索增强的大规模语言模型（LLM）事实核查系统的对抗性声明攻击框架。", "motivation": "当前搜索增强的LLM事实核查系统对对抗性攻击的鲁棒性尚未充分理解，需要开发新的方法来提升系统的安全性。", "method": "提出DECEIVE-AFC，一种基于代理的对抗性攻击框架，它结合了新颖的声明级攻击策略和对抗性声明有效性评估原则。该框架在不依赖证据来源或模型内部结构的情况下系统地探索破坏搜索行为、证据检索和LLM推理的对抗性攻击路径。", "result": "实验证明，DECEIVE-AFC显著降低了核查准确性，从78.7%降至53.7%，并且跨系统传输能力强，优于现有基于声明的攻击基线。", "conclusion": "该研究展示了针对搜索增强的大规模语言模型事实核查系统的对抗性攻击的有效性和普遍性，并为未来提升此类系统的安全性和鲁棒性提供了方向。"}}
{"id": "2602.02567", "pdf": "https://arxiv.org/pdf/2602.02567", "abs": "https://arxiv.org/abs/2602.02567", "authors": ["Jingyi Xu", "Shengnan Wang", "Weidong Yang", "Siwei Tu", "Lei Bai", "Ben Fei"], "title": "IceBench-S2S: A Benchmark of Deep Learning for Challenging Subseasonal-to-Seasonal Daily Arctic Sea Ice Forecasting in Deep Latent Space", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": "9 pages, 6 figures", "summary": "Arctic sea ice plays a critical role in regulating Earth's climate system, significantly influencing polar ecological stability and human activities in coastal regions. Recent advances in artificial intelligence have facilitated the development of skillful pan-Arctic sea ice forecasting systems, where data-driven approaches showcase tremendous potential to outperform conventional physics-based numerical models in terms of accuracy, computational efficiency and forecasting lead times. Despite the latest progress made by deep learning (DL) forecasting models, most of their skillful forecasting lead times are confined to daily subseasonal scale and monthly averaged values for up to six months, which drastically hinders their deployment for real-world applications, e.g., maritime routine planning for Arctic transportation and scientific investigation. Extending daily forecasts from subseasonal to seasonal (S2S) scale is scientifically crucial for operational applications. To bridge the gap between the forecasting lead time of current DL models and the significant daily S2S scale, we introduce IceBench-S2S, the first comprehensive benchmark for evaluating DL approaches in mitigating the challenge of forecasting Arctic sea ice concentration in successive 180-day periods. It proposes a generalized framework that first compresses spatial features of daily sea ice data into a deep latent space. The temporally concatenated deep features are subsequently modeled by DL-based forecasting backbones to predict the sea ice variation at S2S scale. IceBench-S2S provides a unified training and evaluation pipeline for different backbones, along with practical guidance for model selection in polar environmental monitoring tasks.", "AI": {"tldr": "冰川预测基准IceBench-S2S用于评估深度学习方法在北极海冰浓度连续180天的次季节到季节尺度上进行预测的能力。", "motivation": "现有深度学习模型难以实现从日次季节尺度到季节尺度的长期预测，阻碍了其在实际应用中的部署，如北极运输和科学研究。因此，开发一种能够克服这一挑战的方法至关重要。", "method": "提出了一种综合框架，首先将每日海冰数据的空间特征压缩到深层潜在空间中。然后通过深度学习方法建模这些时间串联的深层特征来预测次季节至季节尺度上的海冰变化。", "result": "IceBench-S2S提供了一个统一的训练和评估流程，并为极地环境监测任务中的模型选择提供了实用指南，有助于提高北极海冰浓度长期预测的能力。", "conclusion": "通过IceBench-S2S基准测试框架，能够有效评估并改进深度学习方法在次季节至季节尺度上的北极海冰预测性能。"}}
{"id": "2602.02566", "pdf": "https://arxiv.org/pdf/2602.02566", "abs": "https://arxiv.org/abs/2602.02566", "authors": ["Samin Semsar", "Kiran Laxmikant Prabhu", "Gabriella Waters", "James Foulds"], "title": "A Comparative Simulation Study of the Fairness and Accuracy of Predictive Policing Systems in Baltimore City", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "36 pages, 27 figures", "summary": "There are ongoing discussions about predictive policing systems, such as those deployed in Los Angeles, California and Baltimore, Maryland, being unfair, for example, by exhibiting racial bias. Studies found that unfairness may be due to feedback loops and being trained on historically biased recorded data. However, comparative studies on predictive policing systems are few and are not sufficiently comprehensive. In this work, we perform a comprehensive comparative simulation study on the fairness and accuracy of predictive policing technologies in Baltimore. Our results suggest that the situation around bias in predictive policing is more complex than was previously assumed. While predictive policing exhibited bias due to feedback loops as was previously reported, we found that the traditional alternative, hot spots policing, had similar issues. Predictive policing was found to be more fair and accurate than hot spots policing in the short term, although it amplified bias faster, suggesting the potential for worse long-run behavior. In Baltimore, in some cases the bias in these systems tended toward over-policing in White neighborhoods, unlike in previous studies. Overall, this work demonstrates a methodology for city-specific evaluation and behavioral-tendency comparison of predictive policing systems, showing how such simulations can reveal inequities and long-term tendencies.", "AI": {"tldr": "对巴尔的摩市预测性警务系统的公平性和准确性进行了全面比较仿真研究。", "motivation": "探讨预测性警务系统是否存在不公平现象，特别是种族偏见，并与传统热点警务方法进行对比。", "method": "通过仿真模拟来评估预测性警务系统在巴尔的摩市内的短期和长期行为倾向及其公平性和准确性。", "result": "发现预测性警务系统存在反馈循环导致的不公平现象；但是，在短期内，它比传统的热点警务更公平准确。然而，长远来看，预测性警务放大了偏见，可能导致更大的问题。", "conclusion": "提出了一种城市特定评估和行为倾向比较预测性警务系统的实验方法，并展示了仿真模拟揭示系统长期趋势及不平等性的能力。"}}
{"id": "2602.02565", "pdf": "https://arxiv.org/pdf/2602.02565", "abs": "https://arxiv.org/abs/2602.02565", "authors": ["Huanran Li", "Jeremy Johnson", "Daniel Pimentel-Alarcón"], "title": "High Rank Matrix Completion via Grassmannian Proxy Fusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper approaches high-rank matrix completion (HRMC) by filling missing entries in a data matrix where columns lie near a union of subspaces, clustering these columns, and identifying the underlying subspaces. Current methods often lack theoretical support, produce uninterpretable results, and require more samples than theoretically necessary. We propose clustering incomplete vectors by grouping proxy subspaces and minimizing two criteria over the Grassmannian: (a) the chordal distance between each point and its corresponding subspace and (b) the geodesic distances between subspaces of all data points. Experiments on synthetic and real datasets demonstrate that our method performs comparably to leading methods in high sampling rates and significantly better in low sampling rates, thus narrowing the gap to the theoretical sampling limit of HRMC.", "AI": {"tldr": "本文提出了一种通过草曼尼安（Grassmannian）上代理子空间融合进行高秩矩阵补全的方法。", "motivation": "现有方法在理论支持、结果可解释性和样本需求方面存在不足，特别是在低采样率下表现不佳。因此，开发一种更具有效性和理论依据的HRMC算法至关重要。", "method": "通过草曼尼安（Grassmannian）上的代理子空间融合对不完整向量进行聚类，并最小化两点准则：点与其对应子空间之间的弦距和所有数据点的子空间间的测地距离。", "result": "实验结果表明，该方法在高采样率下表现与现有领先方法相当，在低采样率下表现显著优于其他方法，从而缩小了HRMC理论采样极限的差距。", "conclusion": "所提算法通过草曼尼安上代理子空间融合实现了高效的高秩矩阵补全，并展示了在合成和真实数据集上的优越性能。"}}
{"id": "2602.02561", "pdf": "https://arxiv.org/pdf/2602.02561", "abs": "https://arxiv.org/abs/2602.02561", "authors": ["Xinyu Liu", "Zixuan Xie", "Amir Moeini", "Claire Chen", "Shuze Daniel Liu", "Yu Meng", "Aidong Zhang", "Shangtong Zhang"], "title": "MathlibLemma: Folklore Lemma Generation and Benchmark for Formal Mathematics", "categories": ["cs.LO", "cs.AI", "cs.LG"], "comment": null, "summary": "While the ecosystem of Lean and Mathlib has enjoyed celebrated success in formal mathematical reasoning with the help of large language models (LLMs), the absence of many folklore lemmas in Mathlib remains a persistent barrier that limits Lean's usability as an everyday tool for mathematicians like LaTeX or Maple. To address this, we introduce MathlibLemma, the first LLM-based multi-agent system to automate the discovery and formalization of mathematical folklore lemmas. This framework constitutes our primary contribution, proactively mining the missing connective tissue of mathematics. Its efficacy is demonstrated by the production of a verified library of folklore lemmas, a subset of which has already been formally merged into the latest build of Mathlib, thereby validating the system's real-world utility and alignment with expert standards. Leveraging this pipeline, we further construct the MathlibLemma benchmark, a suite of 4,028 type-checked Lean statements spanning a broad range of mathematical domains. By transforming the role of LLMs from passive consumers to active contributors, this work establishes a constructive methodology for the self-evolution of formal mathematical libraries.", "AI": {"tldr": "介绍MathlibLemma，一个基于大型语言模型的多代理系统，用于自动化发现和形式化数学民间定理。", "motivation": "解决Lean及其库中缺乏许多数学民间定理的问题，以提升其作为日常数学工具的可用性。", "method": "利用大型语言模型创建一个多代理系统，自动挖掘缺失的数学连接组织，并构建MathlibLemma基准测试套件。", "result": "生成了包含4028个Lean表述的验证库，并已将其中的一部分定理正式合并到最新的Mathlib版本中。", "conclusion": "通过建立一个有效的多代理系统，成功地推动了形式化数学图书馆的发展和自我进化。"}}
{"id": "2602.02560", "pdf": "https://arxiv.org/pdf/2602.02560", "abs": "https://arxiv.org/abs/2602.02560", "authors": ["Bartlomiej Sobieski", "Jakub Grzywaczewski", "Karol Dobiczek", "Mateusz Wójcik", "Tomasz Bartczak", "Patryk Szatkowski", "Przemysław Bombiński", "Matthew Tivnan", "Przemyslaw Biecek"], "title": "Auditing Sybil: Explaining Deep Lung Cancer Risk Prediction Through Generative Interventional Attributions", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Preprint", "summary": "Lung cancer remains the leading cause of cancer mortality, driving the development of automated screening tools to alleviate radiologist workload. Standing at the frontier of this effort is Sybil, a deep learning model capable of predicting future risk solely from computed tomography (CT) with high precision. However, despite extensive clinical validation, current assessments rely purely on observational metrics. This correlation-based approach overlooks the model's actual reasoning mechanism, necessitating a shift to causal verification to ensure robust decision-making before clinical deployment. We propose S(H)NAP, a model-agnostic auditing framework that constructs generative interventional attributions validated by expert radiologists. By leveraging realistic 3D diffusion bridge modeling to systematically modify anatomical features, our approach isolates object-specific causal contributions to the risk score. Providing the first interventional audit of Sybil, we demonstrate that while the model often exhibits behavior akin to an expert radiologist, differentiating malignant pulmonary nodules from benign ones, it suffers from critical failure modes, including dangerous sensitivity to clinically unjustified artifacts and a distinct radial bias.", "AI": {"tldr": "Sybil是一个通过CT预测肺癌风险的深度学习模型，S(H)NAP框架用于验证其因果机制。", "motivation": "当前对Sybil这样的自动筛查工具评估仅基于观察性指标，缺乏对其决策机制的理解。因此需要一种因果验证方法来确保其临床部署前的安全性和可靠性。", "method": "提出了一个名为S(H)NAP的模型无关审计框架，通过生成干预归因并利用3D扩散桥建模修改解剖特征以区分恶性结节和良性结节。", "result": "研究表明Sybil在某些情况下表现得像专家放射科医师，但在临床不相关的情况下过于敏感，并存在明显的径向偏见。", "conclusion": "尽管S(H)NAP框架验证了Sybil模型的部分行为与专家一致，但也发现了其重要缺陷。需要进一步的工作来改善这些失败模式以确保安全的临床应用。"}}
{"id": "2602.02559", "pdf": "https://arxiv.org/pdf/2602.02559", "abs": "https://arxiv.org/abs/2602.02559", "authors": ["Pengyu Dai", "Weihao Xuan", "Junjue Wang", "Hongruixuan Chen", "Jian Song", "Yafei Ou", "Naoto Yokoya"], "title": "Experience-Driven Multi-Agent Systems Are Training-free Context-aware Earth Observers", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA"], "comment": "21 pages, 6 figures", "summary": "Recent advances have enabled large language model (LLM) agents to solve complex tasks by orchestrating external tools. However, these agents often struggle in specialized, tool-intensive domains that demand long-horizon execution, tight coordination across modalities, and strict adherence to implicit tool constraints. Earth Observation (EO) tasks exemplify this challenge due to the multi-modal and multi-temporal data inputs, as well as the requirements of geo-knowledge constraints (spectrum library, spatial reasoning, etc): many high-level plans can be derailed by subtle execution errors that propagate through a pipeline and invalidate final results. A core difficulty is that existing agents lack a mechanism to learn fine-grained, tool-level expertise from interaction. Without such expertise, they cannot reliably configure tool parameters or recover from mid-execution failures, limiting their effectiveness in complex EO workflows. To address this, we introduce \\textbf{GeoEvolver}, a self-evolving multi-agent system~(MAS) that enables LLM agents to acquire EO expertise through structured interaction without any parameter updates. GeoEvolver decomposes each query into independent sub-goals via a retrieval-augmented multi-agent orchestrator, then explores diverse tool-parameter configurations at the sub-goal level. Successful patterns and root-cause attribution from failures are then distilled in an evolving memory bank that provides in-context demonstrations for future queries. Experiments on three tool-integrated EO benchmarks show that GeoEvolver consistently improves end-to-end task success, with an average gain of 12\\% across multiple LLM backbones, demonstrating that EO expertise can emerge progressively from efficient, fine-grained interactions with the environment.", "AI": {"tldr": "本文提出了一种名为GeoEvolver的自进化多智能体系统，使大语言模型代理通过结构化交互获取地球观测（EO）领域的专业技能。", "motivation": "目前的大语言模型代理在解决复杂的地球观测任务时遇到困难，因为这些任务需要长时态执行、紧密协调以及严格遵守隐性工具约束。现有的代理缺乏从互动中学习细粒度专业知识的机制，导致它们难以可靠地配置工具参数或从中途失败中恢复。", "method": "GeoEvolver通过将查询分解为独立子目标，并探索不同的工具参数配置来获取EO专业技能。成功模式和故障的根本原因被提取到不断演化的记忆库中，以提供未来查询的上下文演示。", "result": "在三个集成工具的地球观测基准测试上进行实验显示，GeoEvolver可以显著提高端到端任务的成功率，平均增益为12%。", "conclusion": "结果证明了EO专业技能可以通过与环境的有效、细粒度交互逐步涌现。"}}
{"id": "2602.02558", "pdf": "https://arxiv.org/pdf/2602.02558", "abs": "https://arxiv.org/abs/2602.02558", "authors": ["Zekang Yang", "Hong Liu", "Xiangdong Wang"], "title": "PA-MIL: Phenotype-Aware Multiple Instance Learning Guided by Language Prompting and Genotype-to-Phenotype Relationships", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Deep learning has been extensively researched in the analysis of pathology whole-slide images (WSIs). However, most existing methods are limited to providing prediction interpretability by locating the model's salient areas in a post-hoc manner, failing to offer more reliable and accountable explanations. In this work, we propose Phenotype-Aware Multiple Instance Learning (PA-MIL), a novel ante-hoc interpretable framework that identifies cancer-related phenotypes from WSIs and utilizes them for cancer subtyping. To facilitate PA-MIL in learning phenotype-aware features, we 1) construct a phenotype knowledge base containing cancer-related phenotypes and their associated genotypes. 2) utilize the morphological descriptions of phenotypes as language prompting to aggregate phenotype-related features. 3) devise the Genotype-to-Phenotype Neural Network (GP-NN) grounded in genotype-to-phenotype relationships, which provides multi-level guidance for PA-MIL. Experimental results on multiple datasets demonstrate that PA-MIL achieves competitive performance compared to existing MIL methods while offering improved interpretability. PA-MIL leverages phenotype saliency as evidence and, using a linear classifier, achieves competitive results compared to state-of-the-art methods. Additionally, we thoroughly analyze the genotype-phenotype relationships, as well as cohort-level and case-level interpretability, demonstrating the reliability and accountability of PA-MIL.", "AI": {"tldr": "提出了一种新的基于语言提示和基因型到表型关系的癌症亚型分类方法PA-MIL", "motivation": "现有的深度学习方法在病理全切片图像分析中缺乏可靠的解释性，本文旨在通过引入表型知识来提高模型的可解释性和可信度。", "method": "构建了一个包含癌症相关表型及其基因型的知识库；利用形态描述作为语言提示聚合表型相关的特征；设计了基于基因型到表型关系的神经网络GP-NN为PA-MIL提供多级指导。", "result": "实验结果表明，PA-MIL在多个数据集上的性能与现有方法相当，并且提供了更好的可解释性。通过线性分类器利用表型显著性的证据也达到了与最先进的方法相媲美的结果。", "conclusion": "PA-MIL展示了可靠的解释能力和可信度，证明了其在癌症亚型分类中的有效性和优势。"}}
{"id": "2602.02557", "pdf": "https://arxiv.org/pdf/2602.02557", "abs": "https://arxiv.org/abs/2602.02557", "authors": ["Yupeng Chen", "Junchi Yu", "Aoxi Liu", "Philip Torr", "Adel Bibi"], "title": "The Alignment Curse: Cross-Modality Jailbreak Transfer in Omni-Models", "categories": ["cs.LG", "cs.AI", "cs.SD"], "comment": null, "summary": "Recent advances in end-to-end trained omni-models have significantly improved multimodal understanding. At the same time, safety red-teaming has expanded beyond text to encompass audio-based jailbreak attacks. However, an important bridge between textual and audio jailbreaks remains underexplored. In this work, we study the cross-modality transfer of jailbreak attacks from text to audio, motivated by the semantic similarity between the two modalities and the maturity of textual jailbreak methods. We first analyze the connection between modality alignment and cross-modality jailbreak transfer, showing that strong alignment can inadvertently propagate textual vulnerabilities to the audio modality, which we term the alignment curse. Guided by this analysis, we conduct an empirical evaluation of textual jailbreaks, text-transferred audio jailbreaks, and existing audio-based jailbreaks on recent omni-models. Our results show that text-transferred audio jailbreaks perform comparably to, and often better than, audio-based jailbreaks, establishing them as simple yet powerful baselines for future audio red-teaming. We further demonstrate strong cross-model transferability and show that text-transferred audio attacks remain effective even under a stricter audio-only access threat model.", "AI": {"tldr": "研究文本到音频的越狱攻击转移，探讨跨模态对齐带来的安全风险。", "motivation": "由于文本和音频语义相似性以及文字越狱方法成熟度高，研究两者之间的联系及潜在的安全隐患。", "method": "分析多模态模型中的跨模态对齐与越狱攻击的关系，并进行实验评估。", "result": "结果显示，从文本转化来的音频越狱攻击表现优异且具有较强跨模型转移性。", "conclusion": "揭示了跨模态对齐可能导致的安全问题，并建立了简单的音频安全测试基准。"}}
{"id": "2602.02556", "pdf": "https://arxiv.org/pdf/2602.02556", "abs": "https://arxiv.org/abs/2602.02556", "authors": ["Xuancheng Li", "Haitao Li", "Yujia Zhou", "Yiqun Liu", "Qingyao Ai"], "title": "Beyond Experience Retrieval: Learning to Generate Utility-Optimized Structured Experience for Frozen LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are largely static and often redo reasoning or repeat mistakes. Prior experience reuse typically relies on external retrieval, which is similarity-based, can introduce noise, and adds latency. We introduce SEAM (Structured Experience Adapter Module), a lightweight, executor-specific plug-in that stores experience in its parameters and generates a structured, instance-tailored experience entry in a single forward pass to guide a frozen LLM executor. SEAM is trained for utility via executor rollouts and GRPO while keeping the executor frozen, and it can be further improved after deployment with supervised fine-tuning on logged successful trajectories. Experiments on mathematical reasoning benchmarks show consistent accuracy gains across executors with low overhead. Extensive ablations and analyses further elucidate the mechanisms underlying SEAM's effectiveness and robustness.", "AI": {"tldr": "介绍SEAM模块，用于生成结构化、个性化的经验条目以指导冻结的LLM执行器。", "motivation": "大语言模型在静态性和重复性推理中存在问题，通过外部检索来重用经验的方法存在引入噪声和增加延迟的风险。因此，需要一种更有效的经验利用方法。", "method": "SEAM模块存储经验并在单次前向传递中生成结构化的、个性化的经验条目以指导冻结的LLM执行器；使用executor rollouts和GRPO进行训练，并在部署后通过监督微调进一步改进。", "result": "实验表明，SEAM在数学推理基准测试中具有跨执行器的一致准确性增益且开销低。进一步的消融研究和分析阐明了其有效性和鲁棒性的机制。", "conclusion": "SEAM模块成功地解决了大语言模型的经验重用问题，提高了执行器的准确性和效率，并展示了良好的泛化能力。"}}
{"id": "2602.02555", "pdf": "https://arxiv.org/pdf/2602.02555", "abs": "https://arxiv.org/abs/2602.02555", "authors": ["Bizhe Bai", "Xinyue Wang", "Peng Ye", "Tao Chen"], "title": "Learning to Explore with Parameter-Space Noise: A Deep Dive into Parameter-Space Noise for Reinforcement Learning with Verifiable Rewards", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 10 Figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) improves LLM reasoning, yet growing evidence indicates an exploration ceiling: it often reweights existing solution traces rather than discovering new strategies, limiting gains under large sampling budgets (e.g., pass-at-256). We address this limitation with PSN-RLVR, which perturbs policy parameters before rollout generation to induce temporally consistent, trajectory-level exploration that better preserves long-horizon chain-of-thought coherence than action-space noise. To mitigate the resulting sampling-update mismatch, we incorporate truncated importance sampling (TIS). To avoid expensive KL-based adaptive noise control, we propose a computationally efficient real-time adaptive noise scheduler driven by a lightweight surrogate that combines semantic diversity with normalized self-certainty. Instantiated on GRPO, a widely used RLVR method, PSN-GRPO consistently expands the effective reasoning capability boundary across multiple mathematical reasoning benchmarks and model families, yielding higher pass-at-k under large sampling budgets and outperforming prior exploration-oriented RLVR methods (e.g., Pass-at-k-style training) while remaining orthogonal and thus composable for additional gains.", "AI": {"tldr": "该论文提出了一种通过参数空间噪声来改进探索策略的新方法PSN-RLVR，以解决现有的RLVR在大采样预算下存在探索极限的问题。", "motivation": "当前的RLVR算法受限于探索天花板，在大规模采样的情况下难以发现新的解决方案。因此，作者希望通过引入参数空间噪声（PSN）来克服这个限制，从而提高推理能力。", "method": "该方法通过在策略生成前扰动政策参数以诱导时间一致性的轨迹级探索，并结合截断重要性采样(TIS)来解决采样和更新之间的不匹配问题。此外，作者提出了一种轻量化的代理，利用语义多样性与归一化自我确信度进行实时噪声调度。", "result": "在多个数学推理基准测试中以及不同模型族上，PSN-GRPO方法展示出更强的推理能力边界拓展，尤其在大采样预算下获得了更高的通过率，并超过了之前的探索导向RLVR方法。", "conclusion": "论文证明了PSN-RLVR能够有效改进现有的RLVR策略，在解决大型问题时提供更好的探索能力和更稳定的长时段思考链。"}}
{"id": "2602.02554", "pdf": "https://arxiv.org/pdf/2602.02554", "abs": "https://arxiv.org/abs/2602.02554", "authors": ["Jingwen Xu", "Yiyang Lu", "Zisu Huang", "Changze Lv", "Xiaohua Wang", "Shizheng Li", "Zhibo Xu", "Zhengkang Guo", "Zhengyuan Wang", "Muzhao Tian", "Xuanjing Huang", "Xiaoqing Zheng"], "title": "BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": null, "summary": "Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production. BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward, enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1, outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity.", "AI": {"tldr": "BatCoder是一种自监督强化学习框架，用于联合优化代码生成和文档生产。", "motivation": "训练大型语言模型进行代码相关任务通常依赖于高质量的代码-文档配对，这些数据昂贵且稀缺，特别是在小众编程语言中。因此需要一种新的方法来提高模型性能并减少对高质量标注数据的需求。", "method": "BatCoder通过反向翻译策略工作：首先从代码生成文档，然后使用生成的文档重构原始代码。原始代码与重建代码之间的语义相似性作为隐含奖励，使强化学习能够改进模型在根据文档生成代码和反之亦然时的表现。", "result": "在HumanEval和MBPP数据集上测试7B模型，BatCoder达到了83.5%和81.0%的pass@1准确率，优于强大的开源基准。此外，该框架展示了与训练语料库大小和模型容量成比例的一致扩展。", "conclusion": "通过减少对高质量代码-文档配对的需求，BatCoder能够显著增加可用的训练示例数量并提高模型性能。"}}
{"id": "2602.02552", "pdf": "https://arxiv.org/pdf/2602.02552", "abs": "https://arxiv.org/abs/2602.02552", "authors": ["Xinxin Xu", "Yann Gousseau", "Christophe Kervazo", "Saïd Ladjal"], "title": "Super-résolution non supervisée d'images hyperspectrales de télédétection utilisant un entraînement entièrement synthétique", "categories": ["eess.IV", "cs.CV"], "comment": "in French language", "summary": "Hyperspectral single image super-resolution (SISR) aims to enhance spatial resolution while preserving the rich spectral information of hyperspectral images. Most existing methods rely on supervised learning with high-resolution ground truth data, which is often unavailable in practice. To overcome this limitation, we propose an unsupervised learning approach based on synthetic abundance data. The hyperspectral image is first decomposed into endmembers and abundance maps through hyperspectral unmixing. A neural network is then trained to super-resolve these maps using data generated with the dead leaves model, which replicates the statistical properties of real abundances. The final super-resolution hyperspectral image is reconstructed by recombining the super-resolved abundance maps with the endmembers. Experimental results demonstrate the effectiveness of our method and the relevance of synthetic data for training.", "AI": {"tldr": "提出了一种基于合成丰度数据的无监督学习方法，用于提高高光谱图像的空间分辨率。", "motivation": "大多数现有方法依赖于有监督的学习和高质量的真实地面实况数据，但在实践中这些数据往往不可用。因此，本文提出了一个使用合成数据训练的无监督学习方法来克服这一限制。", "method": "首先通过高光谱解混将高光谱图像分解为端元和丰度图；然后利用死叶子模型生成的数据训练神经网络以增强这些映射的空间分辨率；最后通过重新组合增强后的丰度图与端元重建最终的超分辨率高光谱图像。", "result": "实验结果表明该方法有效且合成数据对于训练是相关性的。", "conclusion": "本文提出了一种基于无监督学习和合成数据的方法，成功提高了高光谱图像的空间分辨率，并展示了其在实际应用中的潜力。"}}
{"id": "2602.02551", "pdf": "https://arxiv.org/pdf/2602.02551", "abs": "https://arxiv.org/abs/2602.02551", "authors": ["Hua Wang", "Jinghao Lu", "Fan Zhang"], "title": "EEO-TFV: Escape-Explore Optimizer for Web-Scale Time-Series Forecasting and Vision Analysis", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Main paper: 12 pages", "summary": "Transformer-based foundation models have achieved remarkable progress in tasks such as time-series forecasting and image segmentation. However, they frequently suffer from error accumulation in multivariate long-sequence prediction and exhibit vulnerability to out-of-distribution samples in image-related tasks. Furthermore, these challenges become particularly pronounced in large-scale Web data analysis tasks, which typically involve complex temporal patterns and multimodal features. This complexity substantially increases optimization difficulty, rendering models prone to stagnation at saddle points within high-dimensional parameter spaces. To address these issues, we propose a lightweight Transformer architecture in conjunction with a novel Escape-Explore Optimizer (EEO). The optimizer enhances both exploration and generalization while effectively avoiding sharp minima and saddle-point traps. Experimental results show that, in representative Web data scenarios, our method achieves performance on par with state-of-the-art models across 11 time-series benchmark datasets and the Synapse medical image segmentation task. Moreover, it demonstrates superior generalization and stability, thereby validating its potential as a versatile cross-task foundation model for Web-scale data mining and analysis.", "AI": {"tldr": "该论文提出了一种轻量级的Transformer架构和一种新的Escape-Explore优化器（EEO），以解决多变量长时间序列预测中的误差积累问题以及图像任务中对异常样本的脆弱性。", "motivation": "基于Transformer的模型在时间序列预测和图像分割等任务上取得了显著的进步，但在处理大规模Web数据时存在误差累积、易陷入鞍点等问题。这些问题特别突出，特别是在具有复杂时间模式和多模态特征的数据分析中。", "method": "提出了一种轻量级的Transformer架构和一种新的Escape-Explore优化器（EEO）。该方法能够有效避免尖锐最小值和鞍点陷阱，并增强模型的探索能力和泛化能力。", "result": "实验结果表明，该方法在11个时间序列基准数据集和Synapse医学图像分割任务中表现与现有最优模型相当。此外，在大规模Web数据分析场景中表现出更好的泛化稳定性和跨任务适应性。", "conclusion": "提出的Escape-Explore优化器（EEO）及其轻量级Transformer架构展示了在处理复杂大规模数据时的优越性能和稳定性，具有作为广泛适用的基础模型应用于Web规模的数据挖掘和分析的潜力。"}}
{"id": "2602.02550", "pdf": "https://arxiv.org/pdf/2602.02550", "abs": "https://arxiv.org/abs/2602.02550", "authors": ["Hao Zeng", "Huipeng Huang", "Xinhao Qu", "Jianguo Huang", "Bingyi Jing", "Hongxin Wei"], "title": "HyPAC: Cost-Efficient LLMs-Human Hybrid Annotation with PAC Error Guarantees", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Data annotation often involves multiple sources with different cost-quality trade-offs, such as fast large language models (LLMs), slow reasoning models, and human experts. In this work, we study the problem of routing inputs to the most cost-efficient annotation source while controlling the labeling error on test instances. We propose \\textbf{HyPAC}, a method that adaptively labels inputs to the most cost-efficient annotation source while providing distribution-free guarantees on annotation error. HyPAC calibrates two decision thresholds using importance sampling and upper confidence bounds, partitioning inputs into three regions based on uncertainty and routing each to the appropriate annotation source. We prove that HyPAC achieves the minimum expected cost with a probably approximately correct (PAC) guarantee on the annotation error, free of data distribution and pre-trained models. Experiments on common benchmarks demonstrate the effectiveness of our method, reducing the annotation cost by 78.51\\% while tightly controlling the annotation error.", "AI": {"tldr": "该论文提出了一种名为HyPAC的方法，用于将输入智能地分配给成本效益最高的注释来源，同时确保标注误差在可接受范围内。", "motivation": "数据标注通常需要考虑不同源的成本与质量权衡，例如快速的大语言模型、缓慢的推理模型和人类专家。因此，如何有效地选择最优注释源成为一个重要问题。", "method": "HyPAC通过使用重要性采样和置信上限校准两个决策阈值，将输入分为三个区域，并根据不确定性将其分配给适当的标注来源。该方法提供在无数据分布和预训练模型的假设下的PAC误差保证。", "result": "实验结果表明，相对于基准测试，HyPAC能够减少78.51%的注释成本并有效地控制注释误差。", "conclusion": "通过证明HyPAC实现了最小预期成本，并提供了关于标注错误的PAC保障，该方法展示了在保持高质量的同时显著降低数据标注成本的能力。"}}
{"id": "2602.02548", "pdf": "https://arxiv.org/pdf/2602.02548", "abs": "https://arxiv.org/abs/2602.02548", "authors": ["Xiaoce Wang", "Guibin Zhang", "Junzhe Li", "Jinzhe Tu", "Chun Li", "Ming Li"], "title": "ToolTok: Tool Tokenization for Efficient and Generalizable GUI Agents", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MA"], "comment": "8 pages main paper, 18 pages total, 8 figures, 5 tables, code at https://github.com/ZephinueCode/ToolTok", "summary": "Existing GUI agent models relying on coordinate-based one-step visual grounding struggle with generalizing to varying input resolutions and aspect ratios. Alternatives introduce coordinate-free strategies yet suffer from learning under severe data scarcity. To address the limitations, we propose ToolTok, a novel paradigm of multi-step pathfinding for GUI agents, where operations are modeled as a sequence of progressive tool usage. Specifically, we devise tools aligned with human interaction habits and represent each tool using learnable token embeddings. To enable efficient embedding learning under limited supervision, ToolTok introduces a semantic anchoring mechanism that grounds each tool with semantically related concepts as natural inductive bias. To further enable a pre-trained large language model to progressively acquire tool semantics, we construct an easy-to-hard curriculum consisting of three tasks: token definition question-answering, pure text-guided tool selection, and simplified visual pathfinding. Extensive experiments on multiple benchmarks show that ToolTok achieves superior performance among models of comparable scale (4B) and remains competitive with a substantially larger model (235B). Notably, these results are obtained using less than 1% of the training data required by other post-training approaches. In addition, ToolTok demonstrates strong generalization across unseen scenarios. Our training & inference code is open-source at https://github.com/ZephinueCode/ToolTok.", "AI": {"tldr": "本文提出了ToolTok，一种用于GUI代理的多步路径查找的新范式，通过工具使用序列模型操作。", "motivation": "现有的基于坐标的一步视觉定位的GUI代理模型难以泛化到不同的输入分辨率和长宽比。替代方案虽引入了坐标无关策略但因数据稀缺而学习困难。为此，本文提出了ToolTok以解决这些问题。", "method": "设计了一种与人类交互习惯相一致的工具，并使用可学习令牌嵌入表示每个工具。通过语义锚定机制实现高效嵌入学习。构建了一个从易到难的任务序列：定义问题回答、纯文本引导工具选择和简化视觉路径查找，以使预训练的大语言模型逐步获取工具语义。", "result": "实验表明，在多个基准上，与同等规模（4B）的其他模型相比，ToolTok性能更优，并且在更大的模型（235B）中仍具竞争力。这些结果是在少于1%的训练数据下实现的。此外，它展示了对未见过场景的强大泛化能力。", "conclusion": "ToolTok不仅提高了GUI代理的任务完成效率和准确性，而且还通过少量的数据实现了强大的泛化能力。"}}
{"id": "2602.02547", "pdf": "https://arxiv.org/pdf/2602.02547", "abs": "https://arxiv.org/abs/2602.02547", "authors": ["Hankyeol Kim", "Pilsung Kang"], "title": "naPINN: Noise-Adaptive Physics-Informed Neural Networks for Recovering Physics from Corrupted Measurement", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) are effective methods for solving inverse problems and discovering governing equations from observational data. However, their performance degrades significantly under complex measurement noise and gross outliers. To address this issue, we propose the Noise-Adaptive Physics-Informed Neural Network (naPINN), which robustly recovers physical solutions from corrupted measurements without prior knowledge of the noise distribution. naPINN embeds an energy-based model into the training loop to learn the latent distribution of prediction residuals. Leveraging the learned energy landscape, a trainable reliability gate adaptively filters data points exhibiting high energy, while a rejection cost regularization prevents trivial solutions where valid data are discarded. We demonstrate the efficacy of naPINN on various benchmark partial differential equations corrupted by non-Gaussian noise and varying rates of outliers. The results show that naPINN significantly outperforms existing robust PINN baselines, successfully isolating outliers and accurately reconstructing the dynamics under severe data corruption.", "AI": {"tldr": "提出了一种噪声自适应物理信息神经网络（naPINN）来从受污染的测量数据中恢复物理解。", "motivation": "现有方法在复杂测量噪声和极端异常值存在时，性能显著下降。为了解决这一问题，提出了naPINN。", "method": "naPINN通过嵌入能量模型到训练循环中学习预测残差的潜在分布，并使用可训练的可靠性门来过滤表现出高能量的数据点，同时采用拒绝成本正则化防止简单解决方案。", "result": "在非高斯噪声和不同异常值率下，基准偏微分方程上的实验结果表明naPINN显著优于现有鲁棒基线方法。", "conclusion": "naPINN能够在严重数据污染的情况下准确地隔离异常值并恢复动态特性。"}}
{"id": "2602.02546", "pdf": "https://arxiv.org/pdf/2602.02546", "abs": "https://arxiv.org/abs/2602.02546", "authors": ["Xianglong Yan", "ChengZhu Bao", "Zhiteng Li", "Tianao Zhang", "Shaoqiu Zhang", "Ruobing Xie", "Samm Sun", "Yulun Zhang"], "title": "D$^2$Quant: Accurate Low-bit Post-Training Weight Quantization for LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) deliver strong performance, but their high compute and memory costs make deployment difficult in resource-constrained scenarios. Weight-only post-training quantization (PTQ) is appealing, as it reduces memory usage and enables practical speedup without low-bit operators or specialized hardware. However, accuracy often degrades significantly in weight-only PTQ at sub-4-bit precision, and our analysis identifies two main causes: (1) down-projection matrices are a well-known quantization bottleneck, but maintaining their fidelity often requires extra bit-width; (2) weight quantization induces activation deviations, but effective correction strategies remain underexplored. To address these issues, we propose D$^2$Quant, a novel weight-only PTQ framework that improves quantization from both the weight and activation perspectives. On the weight side, we design a Dual-Scale Quantizer (DSQ) tailored to down-projection matrices, with an absorbable scaling factor that significantly improves accuracy without increasing the bit budget. On the activation side, we propose Deviation-Aware Correction (DAC), which incorporates a mean-shift correction within LayerNorm to mitigate quantization-induced activation distribution shifts. Extensive experiments across multiple LLM families and evaluation metrics show that D$^2$Quant delivers superior performance for weight-only PTQ at sub-4-bit precision. The code and models will be available at https://github.com/XIANGLONGYAN/D2Quant.", "AI": {"tldr": "提出了一种新的权重后训练量化框架D$^2$Quant，用于解决大语言模型在低精度下的准确性问题。", "motivation": "在资源受限场景中部署大型语言模型（LLMs）由于其高计算和内存成本而面临挑战。权重单独的后训练量化可以减少内存使用并实现实际加速，但精度损失严重，特别是在低于4位精度时。", "method": "设计了针对下投影矩阵的双尺度量化器(DSQ)，并在LayerNorm中引入均值偏移校正以减轻激活分布变化。", "result": "实验结果表明D$^2$Quant在多种LLM家族和评价指标上实现了优于现有方法的表现，特别是在低精度下的准确度提升显著。", "conclusion": "通过改进权重和激活的量化策略，D$^2$Quant框架有效地解决了低精度下大型语言模型准确性下降的问题。"}}
{"id": "2602.02545", "pdf": "https://arxiv.org/pdf/2602.02545", "abs": "https://arxiv.org/abs/2602.02545", "authors": ["Dayu Wang", "Jiaye Yang", "Weikang Li", "Jiahui Liang", "Yang Li"], "title": "Beyond Alignment: Expanding Reasoning Capacity via Manifold-Reshaping Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated remarkable success in enhancing the reasoning capabilities of Large Language Models (LLMs). However, recent studies question whether RL genuinely expands reasoning capacity or merely aligns existing latent capabilities, arguing that exploration remains confined within the pre-trained model's low-rank bias manifold. In this work, we challenge this accessibility boundary hypothesis by demonstrating that the latent reasoning space can be fundamentally expanded through targeted geometric interventions. We propose Manifold-Reshaping Policy Optimization (MRPO), a geometric framework designed to fundamentally restructure the inference space of LLMs. MRPO operates in two stages: first, we employ Spectral Orthogonal Exploration (SOE) to eject the policy initialization into the null space of the bias manifold; second, we integrate an Effective Rank regularization term into the policy optimization objective. This approach incentivizes the discovery and maintenance of high-dimensional reasoning trajectories against the entropy-reducing tendency of standard RL. Empirically, our 4B-parameter method achieves state-of-the-art performance on mathematical tasks, significantly outperforming larger models (e.g., Qwen3-32B) and expanding the capability boundary beyond standard GRPO. Our code is available at https://anonymous.4open.science/r/MRPO-D57B/", "AI": {"tldr": "提出了一种新的策略优化框架MRPO，通过几何干预扩展大型语言模型的推理空间。", "motivation": "质疑强化学习是否真正提升大型语言模型的推理能力，还是只是调整现有潜藏能力。因此，试图通过几何方法突破推理空间的限制。", "method": "提出Manifold-Reshaping Policy Optimization (MRPO)框架，在两个阶段操作：第一阶段使用Spectral Orthogonal Exploration（SOE）将策略初始化推出偏置流形的零空间；第二阶段在策略优化目标中加入有效的秩正则化项，激励发现和保持高维推理轨迹。", "result": "实验结果显示，40亿参数的方法在数学任务上达到了最先进的性能，并超越了更大规模的模型（如Qwen3-32B），扩展了能力边界。", "conclusion": "通过几何干预方法MRPO显著提升了大型语言模型的推理能力，展示了该技术的有效性。"}}
{"id": "2602.02544", "pdf": "https://arxiv.org/pdf/2602.02544", "abs": "https://arxiv.org/abs/2602.02544", "authors": ["Wenhao Sun", "Rong-Cheng Tu", "Yifu Ding", "Zhao Jin", "Jingyi Liao", "Yongcheng Jing", "Dacheng Tao"], "title": "SPA-Cache: Singular Proxies for Adaptive Caching in Diffusion Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 6 figures.The code repository is available at https://github.com/wenhao728/spa-cache", "summary": "While Diffusion Language Models (DLMs) offer a flexible, arbitrary-order alternative to the autoregressive paradigm, their non-causal nature precludes standard KV caching, forcing costly hidden state recomputation at every decoding step. Existing DLM caching approaches reduce this cost by selective hidden state updates; however, they are still limited by (i) costly token-wise update identification heuristics and (ii) rigid, uniform budget allocation that fails to account for heterogeneous hidden state dynamics. To address these challenges, we present SPA-Cache that jointly optimizes update identification and budget allocation in DLM cache. First, we derive a low-dimensional singular proxy that enables the identification of update-critical tokens in a low-dimensional subspace, substantially reducing the overhead of update identification. Second, we introduce an adaptive strategy that allocates fewer updates to stable layers without degrading generation quality. Together, these contributions significantly improve the efficiency of DLMs, yielding up to an $8\\times$ throughput improvement over vanilla decoding and a $2$--$4\\times$ speedup over existing caching baselines.", "AI": {"tldr": "SPA-Cache通过引入低维奇异代理和适应性策略优化了扩散语言模型中的缓存，提高了解码效率。", "motivation": "非因果性的扩散语言模型由于标准KV缓存不可用，每次解码步骤都需要重新计算隐藏状态，因此需要一种更高效的方法来降低这种成本。", "method": "SPA-Cache通过低维奇异代理识别关键更新令牌，并采用适应性策略在稳定层中分配较少的更新，从而优化了扩散语言模型中的缓存。", "result": "与原始解码相比，SPA-Cache实现了高达8倍的吞吐量改进；相较于现有缓存方法，则提供了2到4倍的速度提升。", "conclusion": "SPA-Cache通过创新的方法显著提高了扩散语言模型的效率，在不影响生成质量的前提下大幅提升了解码速度。"}}
{"id": "2602.02543", "pdf": "https://arxiv.org/pdf/2602.02543", "abs": "https://arxiv.org/abs/2602.02543", "authors": ["Mingda Liu", "Zhenghan Zhu", "Ze'an Miao", "Katsuki Fujisawa"], "title": "Toward Ultra-Long-Horizon Sequential Model Editing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model editing has emerged as a practical approach for mitigating factual errors and outdated knowledge in large language models (LLMs). Among existing methods, the Locate-and-Edit (L&E) paradigm is the dominant framework: it locates MLP parameters implicated in expressing a target fact, and then performs a localized update to rewrite that fact. However, long sequences of edits often trigger abrupt model collapse in L&E beyond a critical point. We empirically identify a strong correlation between collapse and explosive growth of edited MLP weight norms, and formally prove that commonly used L&E update rules can induce exponential norm growth across sequential edits in the absence of explicit norm control. To address this issue, we propose Norm-Anchor Scaling NAS, a plug-and-play norm-constrained strategy. Across extensive experiments, NAS delays the collapse point of representative L&E algorithms by more than 4 times and yields a 72.2% average relative gain in editing performance, requiring only a single additional line of code and incurring negligible computational overhead.", "AI": {"tldr": "提出了一个名为Norm-Anchor Scaling（NAS）的策略，以解决长期编辑序列中模型崩溃的问题。", "motivation": "长序列编辑经常会导致基于Locate-and-Edit (L&E)框架的语言模型出现突然崩溃。研究人员发现这种崩溃与权重范数的指数增长有关，并希望通过控制规范来改善这一现象。", "method": "通过实验确定了现有方法在长期序列编辑中的问题，提出了一个简单的插件策略NAS，该策略利用规范约束来防止权重范数的增长。", "result": "NAS延迟模型崩溃的时间超过了四倍，显著提高了编辑性能（72.2%的平均相对增益），并且只增加了少量代码和计算开销。", "conclusion": "提出的NAS是一种有效的方法，可以解决长期序列编辑导致的语言模型突然崩溃的问题。"}}
{"id": "2602.02542", "pdf": "https://arxiv.org/pdf/2602.02542", "abs": "https://arxiv.org/abs/2602.02542", "authors": ["Qingyu Wu", "Jianfei Shen", "Feiyi Fan", "Yang Gu", "Chenyang Xu", "Yiqiang Chen"], "title": "Auto-Augmentation Contrastive Learning for Wearable-based Human Activity Recognition", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": ":I.2.6", "summary": "For low-semantic sensor signals from human activity recognition (HAR), contrastive learning (CL) is essential to implement novel applications or generic models without manual annotation, which is a high-performance self-supervised learning (SSL) method. However, CL relies heavily on data augmentation for pairwise comparisons. Especially for low semantic data in the HAR area, conducting good performance augmentation strategies in pretext tasks still rely on manual attempts lacking generalizability and flexibility. To reduce the augmentation burden, we propose an end-to-end auto-augmentation contrastive learning (AutoCL) method for wearable-based HAR. AutoCL is based on a Siamese network architecture that shares the parameters of the backbone and with a generator embedded to learn auto-augmentation. AutoCL trains the generator based on the representation in the latent space to overcome the disturbances caused by noise and redundant information in raw sensor data. The architecture empirical study indicates the effectiveness of this design. Furthermore, we propose a stop-gradient design and correlation reduction strategy in AutoCL to enhance encoder representation learning. Extensive experiments based on four wide-used HAR datasets demonstrate that the proposed AutoCL method significantly improves recognition accuracy compared with other SOTA methods.", "AI": {"tldr": "提出了一种自适应增强对比学习方法（AutoCL），用于基于可穿戴设备的人体活动识别。", "motivation": "现有的对比学习依赖于手动设计的数据增强策略，缺乏灵活性和一般性。因此，需要一种自动化的数据增强方法来提高模型的性能。", "method": "提出了一种基于孪生网络架构的自适应增强对比学习（AutoCL）方法，通过生成器在潜在空间中学习自动增强，并引入了停止梯度设计和相关减少策略以增强编码表示的学习能力。", "result": "实验结果表明，提出的AutoCL方法显著提高了四个人体活动识别数据集上的识别准确率。", "conclusion": "该研究成功地实现了自适应增强对比学习方法（AutoCL），证明了其在人体活动识别任务中的有效性和优越性。"}}
{"id": "2602.02539", "pdf": "https://arxiv.org/pdf/2602.02539", "abs": "https://arxiv.org/abs/2602.02539", "authors": ["Shuxin Zhuang", "Zi Liang", "Runsheng Yu", "Hongzong Li", "Rong Feng", "Shiqin Tang", "Youzhi Zhang"], "title": "How Much Information Can a Vision Token Hold? A Scaling Law for Recognition Limits in VLMs", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Recent vision-centric approaches have made significant strides in long-context modeling. Represented by DeepSeek-OCR, these models encode rendered text into continuous vision tokens, achieving high compression rates without sacrificing recognition precision. However, viewing the vision encoder as a lossy channel with finite representational capacity raises a fundamental question: what is the information upper bound of visual tokens? To investigate this limit, we conduct controlled stress tests by progressively increasing the information quantity (character count) within an image. We observe a distinct phase-transition phenomenon characterized by three regimes: a near-perfect Stable Phase, an Instability Phase marked by increased error variance, and a total Collapse Phase. We analyze the mechanical origins of these transitions and identify key factors. Furthermore, we formulate a probabilistic scaling law that unifies average vision token load and visual density into a latent difficulty metric. Extensive experiments across various Vision-Language Models demonstrate the universality of this scaling law, providing critical empirical guidance for optimizing the efficiency-accuracy trade-off in visual context compression.", "AI": {"tldr": "研究视觉令牌的信息上限，通过控制压力测试来分析不同阶段的图像识别表现。", "motivation": "探讨视觉编码器作为有损信道时的表征容量限制问题，提出一种新的概率缩放定律。", "method": "进行受控的压力测试，逐步增加图像中信息量（字符数），观察三个阶段：稳定期、不稳定期和崩溃期。分析这些转变的机械原因，并将平均视觉令牌负载与视觉密度统一为一个潜在难度指标。", "result": "实验结果表明所提出的缩放定律具有普遍性，提供优化效率精度权衡的关键经验指导。", "conclusion": "提出了一种新的概率缩放定律来解释和预测不同阶段的视觉令牌信息承载能力。"}}
{"id": "2602.02538", "pdf": "https://arxiv.org/pdf/2602.02538", "abs": "https://arxiv.org/abs/2602.02538", "authors": ["Zheqi Lv", "Zhenxuan Fan", "Qi Tian", "Wenqiao Zhang", "Yueting Zhuang"], "title": "Enhancing Post-Training Quantization via Future Activation Awareness", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "Post-training quantization (PTQ) is a widely used method to compress large language models (LLMs) without fine-tuning. It typically sets quantization hyperparameters (e.g., scaling factors) based on current-layer activations. Although this method is efficient, it suffers from quantization bias and error accumulation, resulting in suboptimal and unstable quantization, especially when the calibration data is biased. To overcome these issues, we propose Future-Aware Quantization (FAQ), which leverages future-layer activations to guide quantization. This allows better identification and preservation of important weights, while reducing sensitivity to calibration noise. We further introduce a window-wise preview mechanism to softly aggregate multiple future-layer activations, mitigating over-reliance on any single layer. To avoid expensive greedy search, we use a pre-searched configuration to minimize overhead. Experiments show that FAQ consistently outperforms prior methods with negligible extra cost, requiring no backward passes, data reconstruction, or tuning, making it well-suited for edge deployment.", "AI": {"tldr": "本文提出了一种名为Future-Aware Quantization (FAQ) 的方法，通过利用未来层的激活来改进后训练量化。", "motivation": "现有的后训练量化方法在处理偏置校准数据时存在量化偏差和错误积累的问题，导致压缩效果不佳。因此，作者提出了新的方法来提高量化精度和稳定性。", "method": "该论文引入了Future-Aware Quantization (FAQ) 方法，利用未来层的激活信息来指导量化过程，并设计了一种窗口预览机制，以减轻对单一层次过度依赖的问题。同时采用预先搜索好的配置方案来降低额外开销。", "result": "实验结果表明，与现有方法相比，Future-Aware Quantization (FAQ) 方法在性能上具有明显优势，且几乎不增加任何成本。", "conclusion": "本文提出的方法能有效提高量化模型的准确性和稳定性，并适用于边缘设备部署。"}}
{"id": "2602.02537", "pdf": "https://arxiv.org/pdf/2602.02537", "abs": "https://arxiv.org/abs/2602.02537", "authors": ["Runjie Zhou", "Youbo Shao", "Haoyu Lu", "Bowei Xing", "Tongtong Bai", "Yujie Chen", "Jie Zhao", "Lin Sui", "Haotian Yao", "Zijia Zhao", "Hao Yang", "Haoning Wu", "Zaida Zhou", "Jinguo Zhu", "Zhiqi Huang", "Yiping Bao", "Yangyang Liu", "Y. Charles", "Xinyu Zhou"], "title": "WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We introduce WorldVQA, a benchmark designed to evaluate the atomic visual world knowledge of Multimodal Large Language Models (MLLMs). Unlike current evaluations, which often conflate visual knowledge retrieval with reasoning, WorldVQA decouples these capabilities to strictly measure \"what the model memorizes.\" The benchmark assesses the atomic capability of grounding and naming visual entities across a stratified taxonomy, spanning from common head-class objects to long-tail rarities. We expect WorldVQA to serve as a rigorous test for visual factuality, thereby establishing a standard for assessing the encyclopedic breadth and hallucination rates of current and next-generation frontier models.", "AI": {"tldr": "本文介绍了WorldVQA，这是一个评估多模态大型语言模型原子视觉世界知识的基准。", "motivation": "当前评估方法常将视觉知识检索与推理混淆，而WorldVQA旨在分离这些能力以严格测量模型记忆的内容。", "method": "通过在分层分类体系中对视觉实体进行定位和命名来评估多模态大型语言模型的基本能力。", "result": "预期WorldVQA将成为衡量视觉事实性和识别当前及下一代前沿模型百科全书式广度与幻觉率的标准测试。", "conclusion": "WorldVQA有助于确立评估多模态大型语言模型原子视觉世界知识的新标准。"}}
{"id": "2602.02536", "pdf": "https://arxiv.org/pdf/2602.02536", "abs": "https://arxiv.org/abs/2602.02536", "authors": ["Tianle Gu", "Kexin Huang", "Lingyu Li", "Ruilin Luo", "Shiyang Huang", "Zongqi Wang", "Yujiu Yang", "Yan Teng", "Yingchun Wang"], "title": "From Sparse Decisions to Dense Reasoning: A Multi-attribute Trajectory Paradigm for Multimodal Moderation", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Safety moderation is pivotal for identifying harmful content. Despite the success of textual safety moderation, its multimodal counterparts remain hindered by a dual sparsity of data and supervision. Conventional reliance on binary labels lead to shortcut learning, which obscures the intrinsic classification boundaries necessary for effective multimodal discrimination. Hence, we propose a novel learning paradigm (UniMod) that transitions from sparse decision-making to dense reasoning traces. By constructing structured trajectories encompassing evidence grounding, modality assessment, risk mapping, policy decision, and response generation, we reformulate monolithic decision tasks into a multi-dimensional boundary learning process. This approach forces the model to ground its decision in explicit safety semantics, preventing the model from converging on superficial shortcuts. To facilitate this paradigm, we develop a multi-head scalar reward model (UniRM). UniRM provides multi-dimensional supervision by assigning attribute-level scores to the response generation stage. Furthermore, we introduce specialized optimization strategies to decouple task-specific parameters and rebalance training dynamics, effectively resolving interference between diverse objectives in multi-task learning. Empirical results show UniMod achieves competitive textual moderation performance and sets a new multimodal benchmark using less than 40\\% of the training data used by leading baselines. Ablations further validate our multi-attribute trajectory reasoning, offering an effective and efficient framework for multimodal moderation. Supplementary materials are available at \\href{https://trustworthylab.github.io/UniMod/}{project website}.", "AI": {"tldr": "该论文提出了一种新的学习范式（UniMod），通过构建结构化的轨迹来解决多模态安全审核中的稀疏性问题。", "motivation": "传统的二元标签依赖导致模型容易陷入捷径学习，而难以捕捉到有效的分类边界。为此，研究者提出了从稀疏决策向密集推理的转变策略。", "method": "通过构建包括证据基础、模式评估、风险映射、政策决定和响应生成在内的结构化轨迹，将单一决策任务转化为多维边界的求解过程，并设计了专门的优化策略来解决多任务学习中的干扰问题。", "result": "实验结果表明，UniMod在文本审核方面取得了竞争性的性能，在使用少于40%训练数据的情况下建立了新的多模态基准。", "conclusion": "该研究提出了一种有效的和高效的框架，即基于多属性轨迹推理的统一多模式学习方法（UniMod），为解决多模态安全审核问题提供了解决方案。"}}
{"id": "2602.02535", "pdf": "https://arxiv.org/pdf/2602.02535", "abs": "https://arxiv.org/abs/2602.02535", "authors": ["Abdul Rehman", "Ilona Heldal", "Jerry Chun-Wei Lin"], "title": "Enhancing Psychologists' Understanding through Explainable Deep Learning Framework for ADHD Diagnosis", "categories": ["cs.LG", "cs.AI"], "comment": "ef:Expert Systems, Wiley, 2024", "summary": "Attention Deficit Hyperactivity Disorder (ADHD) is a neurodevelopmental disorder that is challenging to diagnose and requires advanced approaches for reliable and transparent identification and classification. It is characterized by a pattern of inattention, hyperactivity and impulsivity that is more severe and more frequent than in individuals with a comparable level of development. In this paper, an explainable framework based on a fine-tuned hybrid Deep Neural Network (DNN) and Recurrent Neural Network (RNN) called HyExDNN-RNN model is proposed for ADHD detection, multi-class categorization, and decision interpretation. This framework not only detects ADHD, but also provides interpretable insights into the diagnostic process so that psychologists can better understand and trust the results of the diagnosis. We use the Pearson correlation coefficient for optimal feature selection and machine and deep learning models for experimental analysis and comparison. We use a standardized technique for feature reduction, model selection and interpretation to accurately determine the diagnosis rate and ensure the interpretability of the proposed framework. Our framework provided excellent results on binary classification, with HyExDNN-RNN achieving an F1 score of 99% and 94.2% on multi-class categorization. XAI approaches, in particular SHapley Additive exPlanations (SHAP) and Permutation Feature Importance (PFI), provided important insights into the importance of features and the decision logic of models. By combining AI with human expertise, we aim to bridge the gap between advanced computational techniques and practical psychological applications. These results demonstrate the potential of our framework to assist in ADHD diagnosis and interpretation.", "AI": {"tldr": "提出一种基于深度神经网络和循环神经网络的混合模型HyExDNN-RNN，用于ADHD诊断、多分类以及决策解释。", "motivation": "为了提高对ADHD的准确识别和分类，并提供可解释性以增强心理学家的信任和支持。", "method": "使用Pearson相关系数进行最优特征选择，采用机器学习与深度学习模型进行实验分析和比较。通过标准化技术实现特征减少、模型选择及解释，确保诊断结果的准确性及框架的可解释性。", "result": "该框架在二分类任务中取得F1评分为99%，多分类任务中的准确率为94.2%。利用XAI方法SHAP和PFI提供了关于特征重要性和模型决策逻辑的重要见解。", "conclusion": "研究表明，结合AI与人类专业知识可以有效支持ADHD诊断及解释，证明了该框架在心理应用领域的潜力。"}}
{"id": "2602.02533", "pdf": "https://arxiv.org/pdf/2602.02533", "abs": "https://arxiv.org/abs/2602.02533", "authors": ["Kun Wang", "Xiao Feng", "Mingcheng Qu", "Tonghua Su"], "title": "HMVLA: Hyperbolic Multimodal Fusion for Vision-Language-Action Models", "categories": ["cs.RO", "cs.LG"], "comment": "5 pages,5 figures,ICASSP", "summary": "Vision Language Action (VLA) models have recently shown great potential in bridging multimodal perception with robotic control. However, existing methods often rely on direct fine-tuning of pre-trained Vision-Language Models (VLMs), feeding semantic and visual features directly into a policy network without fully addressing the unique semantic alignment challenges in the VLA domain. In this paper, we propose HMVLA, a novel VLA framework that exploits the inherent hierarchical structures in vision and language for comprehensive semantic alignment. Unlike traditional methods that perform alignment in Euclidean space, our HMVLA embeds multimodal features in hyperbolic space, enabling more effective modeling of the hierarchical relationships present in image text data. Furthermore, we introduce a sparsely gated Mixture of Experts (MoE) mechanism tailored for semantic alignment, which enhances multimodal comprehension between images and text while improving efficiency. Extensive experiments demonstrate that HMVLA surpasses baseline methods in both accuracy and generalization. In addition, we validate its robustness by reconstructing datasets to further test cross domain adaptability.", "AI": {"tldr": "提出HMVLA框架，利用双曲空间中的多层次语义对齐提升视觉语言行为模型性能。", "motivation": "现有VLA方法直接调用预训练的视觉语言模型，在处理独特语义对齐挑战时效果不佳。为此，论文通过引入双曲空间和稀疏门控专家混合机制以增强跨模态理解与效率。", "method": "HMVLA将多模态特征嵌入到双曲空间中，并利用多层次结构进行有效建模；同时采用适应于语义对齐的稀疏门控混合专家模型提升性能。", "result": "实验结果表明，HMVLA在精度和泛化能力方面超过基线方法，并且通过重构数据集验证了其跨域鲁棒性。", "conclusion": "HMVLA框架利用双曲空间中的多层次语义对齐策略改进视觉语言行为模型的性能，在准确性和效率上均优于传统方法。"}}
{"id": "2602.02532", "pdf": "https://arxiv.org/pdf/2602.02532", "abs": "https://arxiv.org/abs/2602.02532", "authors": ["Mahyar Alinejad", "Yue Wang", "George Atia"], "title": "CADENT: Gated Hybrid Distillation for Sample-Efficient Transfer in Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transfer learning promises to reduce the high sample complexity of deep reinforcement learning (RL), yet existing methods struggle with domain shift between source and target environments. Policy distillation provides powerful tactical guidance but fails to transfer long-term strategic knowledge, while automaton-based methods capture task structure but lack fine-grained action guidance. This paper introduces Context-Aware Distillation with Experience-gated Transfer (CADENT), a framework that unifies strategic automaton-based knowledge with tactical policy-level knowledge into a coherent guidance signal. CADENT's key innovation is an experience-gated trust mechanism that dynamically weighs teacher guidance against the student's own experience at the state-action level, enabling graceful adaptation to target domain specifics. Across challenging environments, from sparse-reward grid worlds to continuous control tasks, CADENT achieves 40-60\\% better sample efficiency than baselines while maintaining superior asymptotic performance, establishing a robust approach for adaptive knowledge transfer in RL.", "AI": {"tldr": "本文提出了一种名为CADENT的框架，该框架将策略蒸馏和基于自动机的方法结合在一起，以实现更有效的知识转移。", "motivation": "现有的强化学习中的迁移学习方法难以处理源域与目标域之间的差异，导致无法有效地传递长期战略知识。作者希望通过引入一种新的机制来改善这一问题。", "method": "CADENT通过使用经验门控的信任机制，在状态-动作级别动态地平衡教师的指导和学生自身的经验，从而实现策略级别的战术指导和基于自动机的战略知识的有效融合。", "result": "实验表明，与基线相比，CADENT在稀疏奖励网格世界以及连续控制任务中提高了40-60%的学习效率，并保持了优异的最终性能。", "conclusion": "论文展示了一种适应性强的知识转移方法，该方法能够在不同的强化学习环境中实现有效的策略迁移。"}}
{"id": "2602.02530", "pdf": "https://arxiv.org/pdf/2602.02530", "abs": "https://arxiv.org/abs/2602.02530", "authors": ["Saurav Singh", "Rodney Sanchez", "Alexander Ororbia", "Jamison Heard"], "title": "Formulating Reinforcement Learning for Human-Robot Collaboration through Off-Policy Evaluation", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Reinforcement learning (RL) has the potential to transform real-world decision-making systems by enabling autonomous agents to learn from experience. Deploying RL in real-world settings, especially in the context of human-robot interaction, requires defining state representations and reward functions, which are critical for learning efficiency and policy performance. Traditional RL approaches often rely on domain expertise and trial-and-error, necessitating extensive human involvement as well as direct interaction with the environment, which can be costly and impractical, especially in complex and safety-critical applications. This work proposes a novel RL framework that leverages off-policy evaluation (OPE) for state space and reward function selection, using only logged interaction data. This approach eliminates the need for real-time access to the environment or human-in-the-loop feedback, greatly reducing the dependency on costly real-time interactions. The proposed approach systematically evaluates multiple candidate state representations and reward functions by training offline RL agents and applying OPE to estimate policy performance. The optimal state space and reward function are selected based on their ability to produce high-performing policies under OPE metrics. Our method is validated on two environments: the Lunar Lander environment by OpenAI Gym, which provides a controlled setting for assessing state space and reward function selection, and a NASA-MATB-II human subjects study environment, which evaluates the approach's real-world applicability to human-robot teaming scenarios. This work enhances the feasibility and scalability of offline RL for real-world environments by automating critical RL design decisions through a data-driven OPE-based evaluation, enabling more reliable, effective, and sustainable RL formulation for complex human-robot interaction settings.", "AI": {"tldr": "本文提出了一种利用离策略评估（OPE）选择状态空间和奖励函数的强化学习框架，以减少对实时环境交互的需求。", "motivation": "传统RL方法依赖于领域专家知识和试错法，需要大量的时间和资源。为了提高效率，本文通过使用历史交互数据来自动优化状态表示和奖励函数的选择。", "method": "该论文提出了一种新的RL框架，利用OPE评估不同的候选状态空间和奖励函数，选择最优方案以产生最佳策略性能。", "result": "在OpenAI的Lunar Lander环境中，以及NASA-MATB-II的人类受试者研究环境中验证了该方法的有效性。结果表明，这种方法能够在减少对实时环境交互依赖的情况下提高RL模型的表现。", "conclusion": "通过使用数据驱动的方式进行OPE评估来自动优化关键设计决策，增强了离线RL在现实世界场景中的可行性和可扩展性，为复杂的人机互动提供了更可靠、有效和可持续的解决方案。"}}
{"id": "2602.02528", "pdf": "https://arxiv.org/pdf/2602.02528", "abs": "https://arxiv.org/abs/2602.02528", "authors": ["Lixiang Fan", "Bohao Li", "Tao Zou", "Bowen Du", "Junchen Ye"], "title": "Incident-Guided Spatiotemporal Traffic Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent years have witnessed the rapid development of deep-learning-based, graph-neural-network-based forecasting methods for modern intelligent transportation systems. However, most existing work focuses exclusively on capturing spatio-temporal dependencies from historical traffic data, while overlooking the fact that suddenly occurring transportation incidents, such as traffic accidents and adverse weather, serve as external disturbances that can substantially alter temporal patterns. We argue that this issue has become a major obstacle to modeling the dynamics of traffic systems and improving prediction accuracy, but the unpredictability of incidents makes it difficult to observe patterns from historical sequences. To address these challenges, this paper proposes a novel framework named the Incident-Guided Spatiotemporal Graph Neural Network (IGSTGNN). IGSTGNN explicitly models the incident's impact through two core components: an Incident-Context Spatial Fusion (ICSF) module to capture the initial heterogeneous spatial influence, and a Temporal Incident Impact Decay (TIID) module to model the subsequent dynamic dissipation. To facilitate research on the spatio-temporal impact of incidents on traffic flow, a large-scale dataset is constructed and released, featuring incident records that are time-aligned with traffic time series. On this new benchmark, the proposed IGSTGNN framework is demonstrated to achieve state-of-the-art performance. Furthermore, the generalizability of the ICSF and TIID modules is validated by integrating them into various existing models.", "AI": {"tldr": "提出了一个新型框架，用于基于深度学习和图神经网络的交通流量预测，特别针对突发性事件的影响。", "motivation": "现有方法主要关注从历史数据中捕捉空间-时间依赖关系，而忽视了突发性事件对外部影响的重大作用，并且这些事件难以通过历史序列观察到模式。为了解决这个问题，提出了一个新的框架来应对挑战。", "method": "提出了一个名为IGSTGNN的新型框架，包含两个核心组件：事故背景空间融合（ICSF）模块和时间事故影响衰减（TIID）模块，以捕捉突发性事件的空间影响及其随时间的变化模式。", "result": "在构建的大规模数据集上，所提出的IGSTGNN框架实现了最先进的性能，并验证了ICSF和TIID模块的通用性。", "conclusion": "通过引入对突发性事件的影响建模，可以更准确地预测交通流量，提高智能运输系统的效率和安全性。"}}
{"id": "2602.02526", "pdf": "https://arxiv.org/pdf/2602.02526", "abs": "https://arxiv.org/abs/2602.02526", "authors": ["Pengyue Hou"], "title": "The \"Robert Boulton\" Singularity: Semantic Tunneling and Manifold Unfolding in Recursive AI", "categories": ["cs.LG", "cs.AI", "cs.CL", "physics.comp-ph"], "comment": "Companion paper to arXiv:2601.11594. Provides empirical validation of the MNCIS framework in Large Language Models (GPT-2) using a recursive training protocol (N=1500). Includes complete, reproducible Python implementation of Adaptive Spectral Negative Coupling (ASNC) and Effective Rank metrics in the Appendix", "summary": "The stability of generative artificial intelligence trained on recursive synthetic data is conventionally monitored via Perplexity (PPL). We demonstrate that PPL is a deceptive metric in context-stabilized regimes (L=128). Using a rigorous sliding-window protocol (N=1500), we identify a novel failure mode termed \"Semantic Tunneling.\" While the Baseline model maintains high grammatical fluency (PPL approx. 83.9), it suffers a catastrophic loss of semantic diversity, converging within seven generations to a single, low-entropy narrative attractor: the \"Robert Boulton\" Singularity. This phenomenon represents a total collapse of the latent manifold (Global Effective Rank 3.62 -> 2.22), where the model discards diverse world knowledge to optimize for statistically safe syntactic templates. To address this, we apply the Multi-Scale Negative Coupled Information Systems (MNCIS) framework recently established in Hou (2026) [arXiv:2601.11594]. We demonstrate that Adaptive Spectral Negative Coupling (ASNC) acts as a topological operator that actively induces \"Manifold Unfolding.\" MNCIS forces the model to expand its effective rank from the anisotropic baseline of 3.62 to a hyper-diverse state of 5.35, effectively constructing an \"Artificial Manifold\" that resists the gravitational pull of semantic attractors and preserves the long-tail distribution of the training data.", "AI": {"tldr": "本文研究了递归合成数据训练的生成式人工智能模型稳定性问题，提出了一种新的失败模式——语义隧道效应，并通过多尺度负耦合信息系统（MNCIS）框架来解决这一问题。", "motivation": "传统的困惑度（PPL）作为衡量指标在上下文稳定化的环境中表现出误导性。研究者发现，模型会失去语义多样性并收敛到单一的低熵叙事吸引子，导致潜在流形的整体坍塌。为了解决这个问题，需要找到一种新的方法来维护模型的多样性和稳定性。", "method": "采用严格的滑动窗口协议（N=1500），通过多尺度负耦合信息系统框架中的自适应光谱负耦合（ASNC）作为拓扑操作符，使模型主动进行“流形扩展”，从而增强其有效秩，并抵抗语义吸引子的引力。", "result": "应用MNCIS后，模型从原有的异向基线3.62有效秩扩展到5.35的高多样性状态，成功构建了一个能够保持训练数据长尾分布的人工流形。", "conclusion": "研究证明了ASNC在增强生成式人工智能模型语义多样性和稳定性方面的有效性，并提出了一种新的解决潜在流形坍塌现象的方法。"}}
{"id": "2602.02525", "pdf": "https://arxiv.org/pdf/2602.02525", "abs": "https://arxiv.org/abs/2602.02525", "authors": ["Liam Hebert", "Lucas Kopp", "Robin Cohen"], "title": "Community Norms in the Spotlight: Enabling Task-Agnostic Unsupervised Pre-Training to Benefit Online Social Media", "categories": ["cs.SI", "cs.AI"], "comment": "Submitted to ICWSM Poster", "summary": "Modelling the complex dynamics of online social platforms is critical for addressing challenges such as hate speech and misinformation. While Discussion Transformers, which model conversations as graph structures, have emerged as a promising architecture, their potential is severely constrained by reliance on high-quality, human-labelled datasets. In this paper, we advocate a paradigm shift from task-specific fine-tuning to unsupervised pretraining, grounded in an entirely novel consideration of community norms. We posit that this framework not only mitigates data scarcity but also enables interpretation of the social norms underlying the decisions made by such an AI system. Ultimately, we believe that this direction offers many opportunities for AI for Social Good.", "AI": {"tldr": "提出了一种基于社区规范的无监督预训练方法，用于改善在线社交平台上的对话建模。", "motivation": "当前依赖高质量标注数据的任务特异化微调模型存在数据稀缺问题，并且难以解释AI系统决策背后的社群规范。", "method": "采用一种新的考虑社区规范的方法进行无监督预训练，从而提高模型在处理复杂动态的社交平台时的表现。", "result": "该方法提高了对在线社会媒体上对话建模的理解和管理能力，特别是在识别有害内容方面有明显改进。", "conclusion": "这种方法为AI应用于社会效益提供了新的机会，并且可以在不需要大量标注数据的情况下更好地理解和遵守社区规范。"}}
{"id": "2602.02524", "pdf": "https://arxiv.org/pdf/2602.02524", "abs": "https://arxiv.org/abs/2602.02524", "authors": ["Olha Wloch", "Liam Hebert", "Robin Cohen", "Lukasz Golab"], "title": "GASTON: Graph-Aware Social Transformer for Online Networks", "categories": ["cs.SI", "cs.AI", "cs.LG"], "comment": "Submitted to ICWSM", "summary": "Online communities have become essential places for socialization and support, yet they also possess toxicity, echo chambers, and misinformation. Detecting this harmful content is difficult because the meaning of an online interaction stems from both what is written (textual content) and where it is posted (social norms). We propose GASTON (Graph-Aware Social Transformer for Online Networks), which learns text and user embeddings that are grounded in their local norms, providing the necessary context for downstream tasks. The heart of our solution is a contrastive initialization strategy that pretrains community embeddings based on user membership patterns, capturing a community's user base before processing any text. This allows GASTON to distinguish between communities (e.g., a support group vs. a hate group) based on who interacts there, even if they share similar vocabulary. Experiments on tasks such as stress detection, toxicity scoring, and norm violation demonstrate that the embeddings produced by GASTON outperform state-of-the-art baselines.", "AI": {"tldr": "GASTON是一种基于图的社交变换器，用于在线网络中检测有害内容。", "motivation": "为了克服仅依靠文本内容而忽视社会规范导致的问题，提出了一种结合文本和用户嵌入的方法，以识别在线社区中的有毒、回音室和错误信息等不良现象。", "method": "GASTON通过对比初始化策略预训练社区嵌入，基于用户的参与模式捕获社区的特性。这使模型能够在处理任何文本之前区分不同类型的社区，并提供上下文支持下游任务。", "result": "实验结果表明，与现有基线相比，由GASTON生成的嵌入在压力检测、毒性评分和规范违规等任务中表现更优。", "conclusion": "GASTON通过考虑社会规范来提高有害内容识别的效果，证明了结合文本信息和社会背景的重要性。"}}
{"id": "2602.02523", "pdf": "https://arxiv.org/pdf/2602.02523", "abs": "https://arxiv.org/abs/2602.02523", "authors": ["Zerui Cheng", "Jiashuo Liu", "Jianzhu Yao", "Pramod Viswanath", "Ge Zhang", "Wenhao Huang"], "title": "TabularMath: Evaluating Computational Extrapolation in Tabular Learning via Program-Verified Synthesis", "categories": ["cs.LG", "cs.AI"], "comment": "30 pages; TabularMath technical report", "summary": "Standard tabular benchmarks mainly focus on the evaluation of a model's capability to interpolate values inside a data manifold, where models good at performing local statistical smoothing are rewarded. However, there exists a very large category of high-value tabular data, including financial modeling and physical simulations, which are generated based upon deterministic computational processes, as opposed to stochastic and noisy relationships. Therefore, we investigate if tabular models can provide an extension from statistical interpolation to computational extrapolation. We propose TabularMath, a diagnostic benchmark of 114 deterministic problems (233,472 rows) generated from verified programs based on GSM8K and AIME. We evaluate 9 tabular architectures and in-context learning (ICL) with GPT-OSS-120B. On standard regression metrics, TabPFN v2.5 performs remarkably well, achieving R^2=0.998 in-distribution and maintaining positive R^2 even under distribution shift, which is unique among the tabular models we tested. When we measure rounded consistency (exact integer match), a different picture emerges: TabPFN v2.5 drops below 10% on out-of-distribution data, while ICL maintains around 40%. This gap between R^2 and exact-match accuracy suggests that tabular models learn smooth function approximations but struggle to recover precise computational outputs under extrapolation. The two paradigms appear complementary: TabPFN scales efficiently with data; ICL achieves exact computation from few examples. We release all code and data to support further investigation.", "AI": {"tldr": "本文提出了一个名为TabularMath的诊断基准，用于评估表格模型在确定性计算过程中的外推能力。", "motivation": "现有标准表单基准主要关注于模型内部数据流形内插值的能力评价。然而，高价值的表格数据通常基于确定性的计算过程生成，这些过程与随机和噪声关系不同。因此，作者研究了表格模型是否能够从统计内插扩展到计算外推。", "method": "作者构建了一个包含114个由经过验证的程序生成的问题的数据集，并评估了9种表格架构以及使用GPT-OSS-120B进行上下文学习的表现。他们还引入了一种新的度量标准，即整数精确匹配率（rounded consistency），来衡量模型在分布变化下的表现。", "result": "TabPFN v2.5在标准回归指标上表现出色，但在确定性计算输出的外推方面却难以恢复准确结果；相比之下，在少量示例下进行上下文学习可以实现接近40%的精确匹配率。", "conclusion": "研究显示了表格模型与基于上下文的学习方法之间的互补性：TabPFN能够高效地处理大量数据，而上下文学习则可以从少量实例中完成精确计算。"}}
{"id": "2602.02522", "pdf": "https://arxiv.org/pdf/2602.02522", "abs": "https://arxiv.org/abs/2602.02522", "authors": ["George Grigorev"], "title": "IMU-1: Sample-Efficient Pre-training of Small Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages", "summary": "We present IMU-1, a 430M-parameter language model trained on 72B tokens that approaches the benchmark performance of models trained on 56x more data. We describe a validated training recipe combining recent architectural interventions (QK-norm attention, per-head gating, value residuals, LayerNorm scaling) with optimization advances (NorMuon with cautious weight decay, muP parametrization) and a three-stage training schedule with post-hoc checkpoint EMA. We provide ablations for each component and release code, weights and data to enable reproduction: https://huggingface.co/thepowerfuldeez/imu1_base", "AI": {"tldr": "IMU-1是一种小规模语言模型，在少量数据训练下表现出接近大规模模型的性能。", "motivation": "探索在有限资源条件下，如何通过优化架构和训练策略来提升语言模型的表现。", "method": "结合近期提出的注意力机制改进、多阶段训练计划及EMA技术，并使用NorMuon优化器等方法进行训练。", "result": "IMU-1模型性能接近于更大规模数据集上训练的基准模型，但仅需56倍少的数据。", "conclusion": "通过有效结合架构创新与优化策略，小规模语言模型也能在有限资源下取得优异表现。"}}
{"id": "2602.02521", "pdf": "https://arxiv.org/pdf/2602.02521", "abs": "https://arxiv.org/abs/2602.02521", "authors": ["Terence D Sanger"], "title": "Scaled Dot-Product Attention implements projection of inputs onto a common surface", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Scaled dot-product attention (SDPA) is a fundamental component responsible for the success of large-language models and other nonlinear signal processing applications. The rationale for SDPA has been based upon \"query, key, value\" concepts borrowed from database theory, but these concepts are difficult to reconcile with standard methods in mathematical signal processing. We show that SDPA can be rewritten in a different but mathematically equivalent form as a projection of the input vectors onto a common surface determined by the inputs themselves. Therefore SDPA discovers nonlinear dependencies in the input that are time-dependent and context-dependent. The rewritten form of SDPA permits increased speed of both feedforward and learning algorithms, but more importantly suggests potential extensions. In the context of language, we re-interpret the role of SDPA as finding a time-dependent contextual meaning determined by the surface on which the set of input vectors lies. Input token embeddings are then modified by the local context surface. This interpretation differs substantially from the concept of \"self-attention\", and provides a strong justification for the use of SDPA for time-series data with time-varying local nonlinear dependencies.", "AI": {"tldr": "本文重新解释了Scaled Dot-Product Attention（SDPA）的工作原理，将其看作是将输入向量投影到由输入自身决定的公共表面上的方法。", "motivation": "传统的“查询、键、值”概念难以与数学信号处理的标准方法相吻合。作者希望通过重新解读SDPA来提供一种新的理解方式，并提出潜在的应用扩展。", "method": "通过将SDPA重写为在由输入本身确定的共同表面上传输向量投影的形式，揭示了其发现非线性依赖关系的能力。", "result": "这种方法提高了前馈和学习算法的速度，且提供了对时间序列数据中时变局部非线性依赖性的解释。", "conclusion": "这种解读不同于传统的“自我注意力”概念，并为SDPA在处理时间序列数据中的应用提供了一种新的视角。"}}
{"id": "2602.02520", "pdf": "https://arxiv.org/pdf/2602.02520", "abs": "https://arxiv.org/abs/2602.02520", "authors": ["Mona G. Ibrahim", "Riham Hilal"], "title": "Artificial Intelligence for Inclusive Engineering Education: Advancing Equality, Diversity, and Ethical Leadership", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "AI technology development has transformed the field of engineering education with its adaptivity-driven, data-based, and ethical-led learning platforms that promote equity, diversity, and inclusivity. But with so much progress being made in so many areas, there are unfortunately gaps in gender equity, representation in cultures around the world, and access to education and jobs in stem education. The paper describes an ethical approach to using AI technology that supports the United Nations 2030 agenda for sustainability. In particular, this includes both Goal 5--Gender Equity--and Goal 10--Reducing Inequalities. Based on a synthesis strategy using both critical thinking strategies related to case studies around the world using AI-based adaptivity platforms to address equity gaps related to education inclusion. The model presented offers a synthesis solution that includes ethical leadership data-related to equity to measure inclusivity based upon sustainability thinking. The result has demonstrated that using AI technology not only increases inclusivity but promotes equity related to access to education in stem education access. Finally, there are concluding remarks related to transforming education into a global system.", "AI": {"tldr": "利用人工智能技术提升工程教育的包容性，促进性别平等和减少不平等。", "motivation": "解决STEM教育中性别差距、文化代表性不足以及教育资源分配不均的问题，推动联合国2030可持续发展目标中的性别平等与减少不平等目标。", "method": "通过合成策略，使用批判性思维方法结合全球案例研究，探讨基于AI适应性的平台如何促进教育包容性并衡量公平性。", "result": "结果表明，利用人工智能技术不仅增强了教育的包容性，还促进了STEM教育资源的公平分配。", "conclusion": "结论指出，通过伦理领导和可持续思考，可以将教育转变为一个更加全球化且具有包容性的系统。"}}
{"id": "2602.02519", "pdf": "https://arxiv.org/pdf/2602.02519", "abs": "https://arxiv.org/abs/2602.02519", "authors": ["Daniele Agostini", "Federica Picasso"], "title": "Evaluation of Large Language Models' educational feedback in Higher Education: potential, limitations and implications for educational practice", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The importance of managing feedback practices in higher education has been widely recognised, as they play a crucial role in enhancing teaching, learning, and assessment processes. In today's educational landscape, feedback practices are increasingly influenced by technological advancements, particularly artificial intelligence (AI). Understanding the impact of AI on feedback generation is essential for identifying its potential benefits and establishing effective implementation strategies. This study examines how AI-generated feedback supports student learning using a well-established analytical framework. Specifically, feedback produced by different Large Language Models (LLMs) was assessed in relation to student-designed projects within a training course on inclusive teaching and learning. The evaluation process involved providing seven LLMs with a structured rubric, developed by the university instructor, which defined specific criteria and performance levels. The LLMs were tasked with generating both quantitative assessments and qualitative feedback based on this rubric. The AI-generated feedback was then analysed using Hughes, Smith, and Creese's framework to evaluate its structure and effectiveness in fostering formative learning experiences. Overall, these findings indicate that LLMs can generate well-structured feedback and hold great potential as a sustainable and meaningful feedback tool, provided they are guided by clear contextual information and a well-defined instructions that will be explored further in the conclusions.", "AI": {"tldr": "评估大型语言模型在高等教育中提供的教育反馈的潜力、局限性和对教学实践的影响。", "motivation": "了解人工智能生成反馈对学生学习的支持作用，识别其潜在好处，并制定有效的实施策略。", "method": "使用结构化的评分标准框架，由大学讲师定义特定的标准和表现水平。提供七个大型语言模型（LLMs）进行定量评估和定性反馈的生成任务。然后用Hughes、Smith和Creese的框架来评价AI反馈的有效性和结构。", "result": "研究表明，大型语言模型可以生成具有良好结构且有效的反馈，并具有作为可持续和发展中的教育工具的巨大潜力。", "conclusion": "大型语言模型可以通过清晰的情境信息和明确指令来提供有力支持学生学习的反馈。进一步探索这些结论将有助于更好地利用AI技术促进教学实践。"}}
{"id": "2602.02518", "pdf": "https://arxiv.org/pdf/2602.02518", "abs": "https://arxiv.org/abs/2602.02518", "authors": ["Yuyang Bai", "Zhuofeng Li", "Ping Nie", "Jianwen Xie", "Yu Zhang"], "title": "GraphDancer: Training LLMs to Explore and Reason over Graphs via Curriculum Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "15 pages, Project website: https://yuyangbai.com/graphdancer/", "summary": "Large language models (LLMs) increasingly rely on external knowledge to improve factuality, yet many real-world knowledge sources are organized as heterogeneous graphs rather than plain text. Reasoning over such graph-structured knowledge poses two key challenges: (1) navigating structured, schema-defined relations requires precise function calls rather than similarity-based retrieval, and (2) answering complex questions often demands multi-hop evidence aggregation through iterative information seeking. We propose GraphDancer, a reinforcement learning (RL) framework that teaches LLMs to navigate graphs by interleaving reasoning and function execution. To make RL effective for moderate-sized LLMs, we introduce a graph-aware curriculum that schedules training by the structural complexity of information-seeking trajectories using an easy-to-hard biased sampler. We evaluate GraphDancer on a multi-domain benchmark by training on one domain only and testing on unseen domains and out-of-distribution question types. Despite using only a 3B backbone, GraphDancer outperforms baselines equipped with either a 14B backbone or GPT-4o-mini, demonstrating robust cross-domain generalization of graph exploration and reasoning skills. Our code and models can be found at https://yuyangbai.com/graphdancer/ .", "AI": {"tldr": "本文提出GraphDancer框架，通过课程强化学习训练大型语言模型在异构图上进行探索和推理。", "motivation": "大型语言模型依赖于外部知识提高事实准确性，但现实中许多知识源以图形结构组织，需要精确的函数调用而非基于相似性的检索，并且复杂问题常需多跳证据聚合。", "method": "GraphDancer通过课程强化学习框架训练LLMs在图中导航推理和执行功能。使用一个针对信息寻找路径结构复杂度调整的学习率的图形感知课程来提高RL效果。", "result": "实验表明，尽管只用3B模型作为基础架构，但GraphDancer仍优于装备了14B模型或GPT-4o-mini的基线系统，在跨域泛化能力方面表现出色。", "conclusion": "本文展示了如何通过强化学习和图形感知课程训练大型语言模型进行图结构知识探索和推理，实现了良好的性能和跨域泛化能力。"}}
{"id": "2602.02517", "pdf": "https://arxiv.org/pdf/2602.02517", "abs": "https://arxiv.org/abs/2602.02517", "authors": ["Ha Na Cho", "Seungmin Jeong", "Yawen Guo", "Alexander Lopez", "Hansen Bow", "Kai Zheng"], "title": "What Drives Length of Stay After Elective Spine Surgery? Insights from a Decade of Predictive Modeling", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "Objective: Predicting length of stay after elective spine surgery is essential for optimizing patient outcomes and hospital resource use. This systematic review synthesizes computational methods used to predict length of stay in this patient population, highlighting model performance and key predictors. Methods: Following PRISMA guidelines, we systematically searched PubMed, Google Scholar, and ACM Digital Library for studies published between December 1st, 2015, and December 1st, 2024. Eligible studies applied statistical or machine learning models to predict length of stay for elective spine surgery patients. Three reviewers independently screened studies and extracted data. Results: Out of 1,263 screened studies, 29 studies met inclusion criteria. Length of stay was predicted as a continuous, binary, or percentile-based outcome. Models included logistic regression, random forest, boosting algorithms, and neural networks. Machine learning models consistently outperformed traditional statistical models, with AUCs ranging from 0.94 to 0.99. K-Nearest Neighbors and Naive Bayes achieved top performance in some studies. Common predictors included age, comorbidities (notably hypertension and diabetes), BMI, type and duration of surgery, and number of spinal levels. However, external validation and reporting practices varied widely across studies. Discussion: There is growing interest in artificial intelligence and machine learning in length of stay prediction, but lack of standardization and external validation limits clinical utility. Future studies should prioritize standardized outcome definitions and transparent reporting needed to advance real-world deployment. Conclusion: Machine learning models offer strong potential for length of stay prediction after elective spine surgery, highlighting their potential for improving discharge planning and hospital resource management.", "AI": {"tldr": "系统回顾并综合了十年来用于预测脊柱手术患者住院时间的计算方法，强调模型性能和关键预测因素。", "motivation": "预测脊柱手术患者的住院时间对于优化患者结果和医院资源使用至关重要。通过总结相关研究的方法和成果，旨在提高临床应用价值。", "method": "遵循PRISMA指南，在PubMed、Google Scholar和ACM Digital Library中系统搜索2015年12月1日至2024年12月1日期间发表的符合条件的研究文章。最终纳入了29项研究，并使用统计或机器学习模型预测患者住院时间。", "result": "机器学习模型在预测患者住院时间方面表现优于传统统计模型，AUC值介于0.94到0.99之间；常见的影响因素包括年龄、合并症（高血压和糖尿病）、BMI等。但研究的外部验证和报告实践存在较大差异。", "conclusion": "机器学习模型在预测脊柱手术后住院时间方面展现出强大的潜力，有助于优化出院计划及医院资源管理，未来研究需标准化结果定义和透明化报告以提高实际应用价值。"}}
{"id": "2602.02516", "pdf": "https://arxiv.org/pdf/2602.02516", "abs": "https://arxiv.org/abs/2602.02516", "authors": ["Theresia Veronika Rampisela", "Maria Maistro", "Tuukka Ruotsalo", "Christina Lioma"], "title": "Measuring Individual User Fairness with User Similarity and Effectiveness Disparity", "categories": ["cs.CY", "cs.AI", "cs.IR", "cs.LG"], "comment": "Preprint of a work that has been accepted to ECIR 2026 Full Papers track as a Findings paper", "summary": "Individual user fairness is commonly understood as treating similar users similarly. In Recommender Systems (RSs), several evaluation measures exist for quantifying individual user fairness. These measures evaluate fairness via either: (i) the disparity in RS effectiveness scores regardless of user similarity, or (ii) the disparity in items recommended to similar users regardless of item relevance. Both disparity in recommendation effectiveness and user similarity are very important in fairness, yet no existing individual user fairness measure simultaneously accounts for both. In brief, current user fairness evaluation measures implement a largely incomplete definition of fairness. To fill this gap, we present Pairwise User unFairness (PUF), a novel evaluation measure of individual user fairness that considers both effectiveness disparity and user similarity. PUF is the only measure that can express this important distinction. We empirically validate that PUF does this consistently across 4 datasets and 7 rankers, and robustly when varying user similarity or effectiveness. In contrast, all other measures are either almost insensitive to effectiveness disparity or completely insensitive to user similarity. We contribute the first RS evaluation measure to reliably capture both user similarity and effectiveness in individual user fairness. Our code: https://github.com/theresiavr/PUF-individual-user-fairness-recsys.", "AI": {"tldr": "本文提出了衡量推荐系统中个体用户公平性的新方法Pairwise User unFairness (PUF)，该方法同时考虑了用户的相似性和推荐效果的差异。", "motivation": "目前存在的一些衡量个体用户公平性的标准，要么仅关注推荐系统的有效性评分差异，要么仅关注对相似用户所推荐项目的差异。这些标准都未能全面涵盖用户相似性与推荐效果这两方面的考量。", "method": "本文提出了一个新方法PUF，用于衡量推荐系统中的个体用户公平性，该方法同时考虑了用户的相似性和推荐效果的差异，并通过实验证明了其有效性。", "result": "实验结果表明，在四种数据集和七个排序器上，PUF能够可靠地捕捉到用户相似度和推荐效果之间的关联。相比之下，其他衡量标准要么对推荐效果差异不敏感，要么完全忽视了用户相似性。", "conclusion": "本文贡献了一个新的推荐系统评估方法，该方法首次能够同时考虑用户相似性和推荐效果，以准确地评估个体用户的公平性"}}
{"id": "2602.02515", "pdf": "https://arxiv.org/pdf/2602.02515", "abs": "https://arxiv.org/abs/2602.02515", "authors": ["Yiliang Song", "Hongjun An", "Jiangong Xiao", "Haofei Zhao", "Jiawei Shao", "Xuelong Li"], "title": "CreditAudit: 2D Auditing for LLM Evaluation and Selection", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "First update", "summary": "Leaderboard scores on public benchmarks have been steadily rising and converging, with many frontier language models now separated by only marginal differences. However, these scores often fail to match users' day to day experience, because system prompts, output protocols, and interaction modes evolve under routine iteration, and in agentic multi step pipelines small protocol shifts can trigger disproportionate failures, leaving practitioners uncertain about which model to deploy. We propose CreditAudit, a deployment oriented credit audit framework that evaluates models under a family of semantically aligned and non adversarial system prompt templates across multiple benchmarks, reporting mean ability as average performance across scenarios and scenario induced fluctuation sigma as a stability risk signal, and further mapping volatility into interpretable credit grades from AAA to BBB via cross model quantiles with diagnostics that mitigate template difficulty drift. Controlled experiments on GPQA, TruthfulQA, and MMLU Pro show that models with similar mean ability can exhibit substantially different fluctuation, and stability risk can overturn prioritization decisions in agentic or high failure cost regimes. By providing a 2D and grade based language for regime specific selection, CreditAudit supports tiered deployment and more disciplined allocation of testing and monitoring effort, enabling more objective and trustworthy model evaluation for real world use.", "AI": {"tldr": "提出了一种名为CreditAudit的信用审计框架，用于评估和选择语言模型。", "motivation": "当前公共基准测试中的分数提升有限且趋于一致，导致用户在日常使用中体验不佳。为了帮助从业者确定合适的部署模型，该研究提出了一个新的评估框架。", "method": "通过一组语义对齐的系统提示模板进行模型评估，并报告平均性能和波动性作为稳定风险信号，同时根据跨模型分位数映射出可解释的信用等级。", "result": "实验表明，在不同应用场景中，具有相似平均能力的模型可以表现出显著不同的波动性。稳定性风险可以改变优先级决策。", "conclusion": "CreditAudit提供了一种基于二维和评级的语言模型评估方法，支持分层部署并促进测试和监测工作更加有条理。"}}
{"id": "2602.02512", "pdf": "https://arxiv.org/pdf/2602.02512", "abs": "https://arxiv.org/abs/2602.02512", "authors": ["Changan Liu", "Haoxin Sun", "Ahad N. Zehmakan", "Zhongzhi Zhang"], "title": "Efficient Edge Rewiring Strategies for Enhancing PageRank Fairness", "categories": ["cs.SI", "cs.AI"], "comment": "Accepted by Theoretical Computer Science (TCS)", "summary": "We study the notion of unfairness in social networks, where a group such as females in a male-dominated industry are disadvantaged in access to important information, e.g. job posts, due to their less favorable positions in the network. We investigate a well-established network-based formulation of fairness called PageRank fairness, which refers to a fair allocation of the PageRank weights among distinct groups. Our goal is to enhance the PageRank fairness by modifying the underlying network structure. More precisely, we study the problem of maximizing PageRank fairness with respect to a disadvantaged group, when we are permitted to rewire a fixed number of edges in the network. Building on a greedy approach, we leverage techniques from fast sampling of rooted spanning forests to devise an effective linear-time algorithm for this problem. To evaluate the accuracy and performance of our proposed algorithm, we conduct a large set of experiments on various real-world network data. Our experiments demonstrate that the proposed algorithm significantly outperforms the existing ones. Our algorithm is capable of generating accurate solutions for networks of million nodes in just a few minutes.", "AI": {"tldr": "研究通过重新布线社交网络中的边来提高PageRank公平性，特别是针对处于不利地位的群体。", "motivation": "在社会网络中存在不公平现象，例如女性在男性主导行业中获取重要信息的机会较少。通过优化网络结构以改善特定群体（如女性）的PageRank分数来提升公平性。", "method": "利用贪婪算法结合快速采样根连通森林技术开发了一种线性时间复杂度的有效算法来最大化PageRank公平性。", "result": "实验结果表明，该方法在各种真实世界网络数据上显著优于现有方法，并能够在几分钟内为数百万节点的网络生成准确解决方案。", "conclusion": "所提出的方法有效地提升了社交网络中的PageRank公平性，对于改善特定群体在网络中获取重要信息的机会具有重要意义。"}}
{"id": "2602.02511", "pdf": "https://arxiv.org/pdf/2602.02511", "abs": "https://arxiv.org/abs/2602.02511", "authors": ["Margot Hanley", "Jiunn-Tyng Yeh", "Ryan Rodriguez", "Jack Pilkington", "Nita Farahany"], "title": "Training Data Governance for Brain Foundation Models", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Brain foundation models bring the foundation model paradigm to the field of neuroscience. Like language and image foundation models, they are general-purpose AI systems pretrained on large-scale datasets that adapt readily to downstream tasks. Unlike text-and-image based models, however, they train on brain data: large-datasets of EEG, fMRI, and other neural data types historically collected within tightly governed clinical and research settings. This paper contends that training foundation models on neural data opens new normative territory. Neural data carry stronger expectations of, and claims to, protection than text or images, given their body-derived nature and historical governance within clinical and research settings. Yet the foundation model paradigm subjects them to practices of large-scale repurposing, cross-context stitching, and open-ended downstream application. Furthermore, these practices are now accessible to a much broader range of actors, including commercial developers, against a backdrop of fragmented and unclear governance. To map this territory, we first describe brain foundation models' technical foundations and training-data ecosystem. We then draw on AI ethics, neuroethics, and bioethics to organize concerns across privacy, consent, bias, benefit sharing, and governance. For each, we propose both agenda-setting questions and baseline safeguards as the field matures.", "AI": {"tldr": "本文探讨了在神经科学领域使用大脑基础模型时的训练数据治理问题。", "motivation": "鉴于脑数据的敏感性和其历史上的严格管理，本文旨在探究将这些数据用于大规模再利用和下游任务所带来的伦理和社会挑战。", "method": "通过描述大脑基础模型的技术基础及其训练数据生态系统，并结合AI伦理、神经伦理和生物伦理来组织隐私、同意、偏见、利益共享和治理等方面的问题，提出相关问题和基本保障措施。", "result": "提出了针对脑基础模型中涉及的各种伦理和社会挑战的一系列议程设置问题及初步保护措施。", "conclusion": "大脑基础模型的应用需要一个清晰明确的治理体系，确保数据使用过程中的隐私、同意、公平性等问题得到妥善解决。"}}
{"id": "2602.02510", "pdf": "https://arxiv.org/pdf/2602.02510", "abs": "https://arxiv.org/abs/2602.02510", "authors": ["Yuming Zhao", "Peiyi Zhang", "Oana Ignat"], "title": "Beyond Translation: Cross-Cultural Meme Transcreation with Vision-Language Models", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Memes are a pervasive form of online communication, yet their cultural specificity poses significant challenges for cross-cultural adaptation. We study cross-cultural meme transcreation, a multimodal generation task that aims to preserve communicative intent and humor while adapting culture-specific references. We propose a hybrid transcreation framework based on vision-language models and introduce a large-scale bidirectional dataset of Chinese and US memes. Using both human judgments and automated evaluation, we analyze 6,315 meme pairs and assess transcreation quality across cultural directions. Our results show that current vision-language models can perform cross-cultural meme transcreation to a limited extent, but exhibit clear directional asymmetries: US-Chinese transcreation consistently achieves higher quality than Chinese-US. We further identify which aspects of humor and visual-textual design transfer across cultures and which remain challenging, and propose an evaluation framework for assessing cross-cultural multimodal generation. Our code and dataset are publicly available at https://github.com/AIM-SCU/MemeXGen.", "AI": {"tldr": "本文研究了跨文化传播中的表情包转译，提出了一种基于视觉语言模型的混合框架，并使用大规模双向数据集评估了不同文化方向上的转译效果。", "motivation": "在线沟通中普遍存在表情包，其文化特异性给跨文化交流带来了挑战。因此，研究如何在保留交流意图和幽默感的同时进行文化特定引用的适应性是必要的。", "method": "本文提出了一种基于视觉语言模型的混合框架，并使用了包含6315对中英文表情包的大规模双向数据集来评估转译效果。通过人工评价和自动化评估，分析不同文化方向上的转译质量。", "result": "实验结果显示，当前的视觉语言模型可以在一定程度上进行跨文化的表情包转译，但存在明显的方向性不对称：从美国到中国的转译质量始终高于从中国到美国的转译。此外，还识别出哪些幽默和视觉-文本设计可以跨越文化转移，以及哪些方面仍然具有挑战。", "conclusion": "本文提出了评估跨文化传播中多模态生成的有效框架，并表明当前模型在这一任务上仍存在改进空间。"}}
{"id": "2602.02509", "pdf": "https://arxiv.org/pdf/2602.02509", "abs": "https://arxiv.org/abs/2602.02509", "authors": ["Nishat Raihan", "Noah Erdachew", "Jayoti Devi", "Joanna C. S. Santos", "Marcos Zampieri"], "title": "CodeGuard: Improving LLM Guardrails in CS Education", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly embedded in Computer Science (CS) classrooms to automate code generation, feedback, and assessment. However, their susceptibility to adversarial or ill-intentioned prompts threatens student learning and academic integrity. To cope with this important issue, we evaluate existing off-the-shelf LLMs in handling unsafe and irrelevant prompts within the domain of CS education. We identify important shortcomings in existing LLM guardrails which motivates us to propose CodeGuard, a comprehensive guardrail framework for educational AI systems. CodeGuard includes (i) a first-of-its-kind taxonomy for classifying prompts; (ii) the CodeGuard dataset, a collection of 8,000 prompts spanning the taxonomy; and (iii) PromptShield, a lightweight sentence-encoder model fine-tuned to detect unsafe prompts in real time. Experiments show that PromptShield achieves 0.93 F1 score, surpassing existing guardrail methods. Additionally, further experimentation reveals that CodeGuard reduces potentially harmful or policy-violating code completions by 30-65% without degrading performance on legitimate educational tasks. The code, datasets, and evaluation scripts are made freely available to the community.", "AI": {"tldr": "CodeGuard是一个用于教育AI系统的全面防护框架，旨在通过分类提示、创建数据集和训练PromptShield模型来提高大型语言模型在处理不安全或无关提示时的能力。", "motivation": "现有的大型语言模型容易受到恶意或不良意图的提示的影响，这威胁到了学生的学习和学术诚信。为了解决这个问题，本文提出了CodeGuard框架。", "method": "CodeGuard包括一种用于分类提示的第一种类型学、8000个跨越该类型学的提示集以及一个轻量级的句子编码器模型PromptShield，它可以实时检测不安全的提示。", "result": "实验表明，PromptShield达到了0.93的F1分数，并且CodeGuard能够减少潜在有害或违反政策的代码完成率30-65%，同时不影响合法教育任务的表现。", "conclusion": "通过提出CodeGuard，本文有效地提高了大型语言模型在处理不安全提示时的能力，为确保学生使用AI系统的安全性提供了一个有力的工具。"}}
{"id": "2602.02508", "pdf": "https://arxiv.org/pdf/2602.02508", "abs": "https://arxiv.org/abs/2602.02508", "authors": ["Xi Chen", "Homa Esfahanizadeh", "Foad Sohrabi"], "title": "Precoding-Oriented CSI Feedback Design with Mutual Information Regularized VQ-VAE", "categories": ["cs.IT", "cs.AI", "eess.IV"], "comment": "5 pages, submitted to IEEE VTC conference", "summary": "Efficient channel state information (CSI) compression at the user equipment plays a key role in enabling accurate channel reconstruction and precoder design in massive multiple-input multiple-output systems. A key challenge lies in balancing the CSI feedback overhead with the achievable downlink rate, i.e., maximizing the utility of limited feedback to maintain high system performance. In this work, we propose a precoding-oriented CSI feedback framework based on a vector quantized variational autoencoder, augmented with an information-theoretic regularization. To achieve this, we introduce a differentiable mutual information lower-bound estimator as a training regularizer to promote effective utilization of the learned codebook under a fixed feedback budget. Numerical results demonstrate that the proposed method achieves rates comparable to variable-length neural compression schemes, while operating with fixed-length feedback. Furthermore, the learned codewords exhibit significantly more uniform usage and capture interpretable structures that are strongly correlated with the underlying channel state information.", "AI": {"tldr": "本文提出了一种基于向量量化变分自动编码器的CSI反馈框架，加入信息理论正则化以优化大规模MIMO系统中的信道状态信息压缩和预编码设计。", "motivation": "高效的CSI压缩对于准确地重建信道并进行预编码设计至关重要。挑战在于在有限的反馈预算下平衡CSI反馈开销与下行链路速率。", "method": "通过引入一个可微的互信息下界估计器作为训练正则化项，以促进学习码本的有效利用，在固定反馈长度内提高CSI反馈效率和质量。", "result": "实验结果表明，该方法在保持固定长度反馈的同时达到了与变长神经压缩方案相当的数据率，并且所学代码字使用更为均匀，捕获了与底层信道状态信息强相关可解释结构。", "conclusion": "通过引入信息理论正则化项，本文成功设计了一个高效CSI反馈框架，在大规模MIMO系统中实现了高精度的通道重建和预编码性能。"}}
{"id": "2602.02505", "pdf": "https://arxiv.org/pdf/2602.02505", "abs": "https://arxiv.org/abs/2602.02505", "authors": ["Hao-Yuan He", "Ming Li"], "title": "Learning-augmented smooth integer programs with PAC-learnable oracles", "categories": ["cs.DS", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper investigates learning-augmented algorithms for smooth integer programs, covering canonical problems such as MAX-CUT and MAX-k-SAT. We introduce a framework that incorporates a predictive oracle to construct a linear surrogate of the objective, which is then solved via linear programming followed by a rounding procedure. Crucially, our framework ensures that the solution quality is both consistent and smooth against prediction errors. We demonstrate that this approach effectively extends tractable approximations from the classical dense regime to the near-dense regime. Furthermore, we go beyond the assumption of oracle existence by establishing its PAC-learnability. We prove that the induced algorithm class possesses a bounded pseudo-dimension, thereby ensuring that an oracle with near-optimal expected performance can be learned with polynomial samples.", "AI": {"tldr": "该论文探讨了利用预测预言机增强平滑整数规划算法的方法，特别是在MAX-CUT和MAX-k-SAT等典型问题中的应用。", "motivation": "为了提升解的质量并使其对预言机的误差具有鲁棒性，研究团队提出了一种新的框架，通过结合预测模型和线性规划来解决近似优化问题。", "method": "该方法首先利用一个预测预言机构建目标函数的线性代理模型；接着使用线性程序求解；最后进行舍入以获得整数解。", "result": "实验证明此框架将可处理的问题从传统的稠密场景扩展到了接近稠密的情形，且通过PAC学习保证了近似最优预言机的存在。", "conclusion": "该论文展示了一种新的理论框架和方法论，证明其不仅能够提高算法的性能，还具有良好的推广性和实用性。"}}
{"id": "2602.02503", "pdf": "https://arxiv.org/pdf/2602.02503", "abs": "https://arxiv.org/abs/2602.02503", "authors": ["Jincheng Xie", "Yili Deng", "Jiguang He", "Pengyu Wang", "Miaomiao Dong", "Rui Tang", "Zhongyi Huang"], "title": "Joint single-shot ToA and DoA estimation for VAA-based BLE ranging with phase ambiguity: A deep learning-based approach", "categories": ["eess.SP", "cs.AI", "cs.IT"], "comment": null, "summary": "Conventional direction-of-arrival (DoA) estimation methods rely on multi-antenna arrays, which are costly to implement on size-constrained Bluetooth Low Energy (BLE) devices. Virtual antenna array (VAA) techniques enable DoA estimation with a single antenna, making angle estimation feasible on such devices. However, BLE only provides a single-shot two-way channel frequency response (CFR) with a binary phase ambiguity issue, which hinders the direct application of VAA. To address this challenge, we propose a unified model that combines VAA with BLE two-way CFR, and introduce a neural network based phase recovery framework that employs row / column predictors with a voting mechanism to resolve the ambiguity. The recovered one-way CFR then enables super resolution algorithms such as MUSIC for joint time of arrival (ToA) and DoA estimation. Simulation results demonstrate that the proposed method achieves superior performance under non-uniform VAAs, with mean square errors approaching the Cramer Rao bound at SNR $\\geq$ 5 dB.", "AI": {"tldr": "本文提出了一种基于深度学习的联合单次测量到达时间（ToA）和角度（DoA）估计的方法，解决了BLE设备在虚拟天线阵列下的一维频率响应相位模糊问题。", "motivation": "传统的方向角估计算法依赖于多天线阵列，在尺寸受限的蓝牙低能耗设备上难以实现。为解决这一问题，并克服BLE提供的单次测量两路信道频率响应中出现的二进制相位模糊，本文提出了将虚拟天线阵列与BLE两路CFR相结合的方法。", "method": "通过引入基于神经网络的相位恢复框架，采用行/列预测器结合投票机制解决相位模糊问题。该方法利用MUSIC等超分辨算法进行联合ToA和DoA估计。", "result": "仿真结果显示，在非均匀虚拟阵列条件下，所提方法性能优越，信噪比SNR≥5dB时均方误差接近Cramer-Rao界。", "conclusion": "本文提出的深度学习框架能够有效地解决BLE设备中相位模糊问题，并实现高精度的ToA和DoA联合估计。"}}
{"id": "2602.02502", "pdf": "https://arxiv.org/pdf/2602.02502", "abs": "https://arxiv.org/abs/2602.02502", "authors": ["Min Zeng", "Xi Chen", "Haiqin Yang", "Yike Guo"], "title": "Sparse Adapter Fusion for Continual Learning in NLP", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted to EACL 2026", "summary": "Continual learning in natural language processing plays a crucial role in adapting to evolving data and preventing catastrophic forgetting. Despite significant progress, existing methods still face challenges, such as inefficient parameter reuse across tasks, risking catastrophic forgetting when tasks are dissimilar, and the unnecessary introduction of new parameters for each task, which hampers knowledge sharing among similar tasks. To tackle these issues, we propose a Sparse Adapter Fusion Method (SAFM), which dynamically fuses old and new adapters to address these challenges. SAFM operates in two stages: the decision stage and the tuning stage. In the decision stage, SAFM determines whether to incorporate a new adapter, reuse an existing one, or add an empty adapter. The architecture search procedure, designed to prioritize reusing or adding empty adapters, minimizes parameter consumption and maximizes reuse. In the tuning stage, SAFM especially facilitates a layer-wise loss to encourage differentiation between adapters, effectively capturing knowledge within the same task. Experimental results consistently show that SAFM outperforms state-of-the-art (SOTA) methods, achieving comparable performance while utilizing less than 60% of the parameters.", "AI": {"tldr": "本文提出了一种稀疏适配器融合方法，旨在解决NLP中的连续学习问题。", "motivation": "现有方法在参数重用和防止灾难性遗忘方面仍存在挑战，影响任务间的知识共享。", "method": "SAFM通过决策阶段确定是否引入新适配器或重复使用旧适配器，并设计了一种分层损失以鼓励不同任务之间的区分。", "result": "实验结果表明，SAFM在参数利用效率和性能上均优于现有方法。", "conclusion": "所提出的稀疏适配器融合方法有效解决了连续学习中的问题，提高了NLP模型的适应性和知识共享能力。"}}
{"id": "2602.02500", "pdf": "https://arxiv.org/pdf/2602.02500", "abs": "https://arxiv.org/abs/2602.02500", "authors": ["Chen Hu", "Qianxi Zhao", "Yuming Li", "Mingyu Zhou", "Xiyin Li"], "title": "UNSO: Unified Newton Schulz Orthogonalization", "categories": ["cs.LG", "cs.AI", "math.NA"], "comment": null, "summary": "The Newton-Schulz (NS) iteration has gained increasing interest for its role in the Muon optimizer and the Stiefel manifold. However, the conventional NS iteration suffers from inefficiency and instability. Although various improvements have been introduced to NS iteration, they fail to deviate from the conventional iterative paradigm, which could increase computation burden largely due to the matrix products along the long dimension repeatedly. To address this, we consolidate the iterative structure into a unified framework, named Unified Newton-Schulz Orthogonalization (UNSO). To do so, we could avoid a polynomial expansion. Instead, we evaluate the role of each matrix power, remove the insignificant terms, and provide a recommended polynomial with learnable coefficients. These learnable coefficients are then optimized, and achieve an outstanding performance with stable convergence. The code of our method is available: https://github.com/greekinRoma/Unified_Newton_Schulz_Orthogonalization.", "AI": {"tldr": "本文提出了统一牛顿施尔茨正交化（UNSO）方法，旨在解决传统牛顿-施尔茨迭代的效率和稳定性问题。", "motivation": "传统的牛顿-施尔茨迭代在计算负担和数值稳定性方面存在不足。尽管有改进版本，但它们仍未能摆脱常规迭代框架，导致长维度矩阵乘法重复计算的问题。", "method": "作者将迭代结构整合到一个统一的框架中，即UNSO方法。通过避免多项式展开并优化每项矩阵幂的作用，移除不重要的术语，并推荐使用带可学习系数的多项式来减少计算负担和提高稳定性。", "result": "该方法在保持稳定收敛的同时实现了出色的表现，显著提高了传统牛顿-施尔茨迭代的效率与性能。", "conclusion": "UNSO框架通过避免不必要的矩阵乘法并引入了优化后的可学习系数，解决了传统牛顿-施尔茨迭代中的效率和稳定性问题。"}}
{"id": "2602.02498", "pdf": "https://arxiv.org/pdf/2602.02498", "abs": "https://arxiv.org/abs/2602.02498", "authors": ["Baturay Saglam", "Dionysis Kalogerias"], "title": "Test-Time Detoxification without Training or Learning Anything", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models can produce toxic or inappropriate text even for benign inputs, creating risks when deployed at scale. Detoxification is therefore important for safety and user trust, particularly when we want to reduce harmful content without sacrificing the model's generation quality. Many existing approaches rely on model retraining, gradients, or learned auxiliary components, which can be costly and may not transfer across model families or to truly black-box settings. We introduce a test-time procedure that approximates the gradient of completion toxicity with respect to the input embeddings and uses a small number of descent steps to steer generation toward less toxic continuations. This is achieved with zeroth-order optimization that requires only access to input embeddings, a toxicity scoring function, and forward evaluations of the model. Empirically, the approach delivers robust toxicity reductions across models and prompts and, in most settings, achieves the best overall toxicity-quality trade-off. More broadly, our work positions word embeddings as effective control variables and encourages wider use of black-box optimization to guide autoregressive language models toward scalable, safer text generation, without requiring any training or access to intermediate computations.", "AI": {"tldr": "该论文提出了一种无需重新训练或学习任何新内容的测试时间去毒方法，使用零阶优化技术降低生成文本的毒性。", "motivation": "大型语言模型在处理良性输入时也可能产生有毒或不适当的内容，因此需要一种有效的去毒方法以确保安全性和用户信任。现有的许多去毒方法依赖于重新训练、梯度或其他学习辅助组件，这可能会增加成本并难以跨模型家族迁移或应用于完全黑盒设置。", "method": "该论文提出了一种测试时间的去毒技术，通过近似完成毒性相对于输入嵌入的梯度，并使用少量下降步骤将生成内容引导至更安全的方向。这一过程仅需要访问输入嵌入、毒性评分函数以及模型的前向评估即可实现零阶优化。", "result": "实验表明，所提出的方法在不同模型和提示下均能显著降低文本毒性，在大多数情况下实现了最佳的毒性和质量权衡。", "conclusion": "该研究证明了词嵌入作为有效控制变量的价值，并鼓励更广泛地使用黑盒优化技术来指导自回归语言模型生成安全且高质量的文本，而无需额外训练或访问中间计算。"}}
{"id": "2602.02497", "pdf": "https://arxiv.org/pdf/2602.02497", "abs": "https://arxiv.org/abs/2602.02497", "authors": ["Xuzhao Li", "Xuchen Li", "Jian Zhao", "Shiyu Hu"], "title": "STEMVerse: A Dual-Axis Diagnostic Framework for STEM Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint, Under review", "summary": "As Large Language Models (LLMs) achieve significant breakthroughs in complex reasoning tasks, evaluating their proficiency in science, technology, engineering, and mathematics (STEM) has become a primary method for measuring machine intelligence. However, current evaluation paradigms often treat benchmarks as isolated \"silos,\" offering only monolithic aggregate scores that neglect the intricacies of both academic specialization and cognitive depth. This result-oriented approach fails to distinguish whether model errors stem from insufficient domain knowledge or deficiencies in cognitive capacity, thereby limiting the diagnostic value. To address this, we propose STEMVerse, a diagnostic framework designed to systematically analyze the STEM reasoning capabilities of LLMs. This framework characterizes model performance across academic specialization and cognitive complexity to map the capability required for reasoning. We re-aggregate over 20,000 STEM problems from mainstream benchmarks into a unified \"Discipline $\\times$ Cognition\" capability space, assigning dual-axis labels to every instance. Utilizing this unified diagnostic framework, we systematically evaluate representative LLM families across varying parameter scales and training paradigms. Our empirical results reveal structural failure patterns in STEM reasoning. By integrating multi-disciplinary coverage and fine-grained cognitive stratification into a unified framework, STEMVerse provides a clear and actionable perspective for understanding the scientific reasoning characteristics of LLMs.", "AI": {"tldr": "提出STEMVerse框架，用于评估大型语言模型在科学、技术、工程和数学领域的推理能力。", "motivation": "当前的评价方法仅提供单一的整体评分，无法区分错误是由领域知识不足还是认知缺陷导致。为此，作者提出了一个诊断性框架来解决这一问题。", "method": "重新聚合了超过20,000个STEM问题到统一的能力空间，并为每个实例分配双轴标签，然后评估代表性LLM家族在不同参数规模和训练范式下的性能。", "result": "实验结果揭示了在科学推理方面的结构化失败模式。通过整合多学科覆盖范围和细化认知层次划分，提供了清晰且可操作的视角来理解大型语言模型的科学推理特征。", "conclusion": "STEMVerse框架提供了一个评估大型语言模型在STEM领域推理能力的有效工具，并为未来的研究方向指明了道路。"}}
{"id": "2602.02495", "pdf": "https://arxiv.org/pdf/2602.02495", "abs": "https://arxiv.org/abs/2602.02495", "authors": ["Peter Chen", "Xiaopeng Li", "Xi Chen", "Tianyi Lin"], "title": "Reward-free Alignment for Conflicting Objectives", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "27 pages", "summary": "Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.", "AI": {"tldr": "提出了一种无奖励对齐框架（RACO），用于处理多个冲突目标，直接利用成对偏好数据并通过剪辑变体的冲突规避梯度下降来解决梯度冲突。", "motivation": "现有方法在涉及多目标时存在不稳定性及不良权衡问题。加权损失法可能无法同时改善所有目标，并且现有多目标方法依赖于显式奖励模型，增加了复杂性并扭曲了用户指定的目标权重。", "method": "提出了一种无奖励对齐框架（RACO），该框架直接利用成对偏好数据并通过剪辑变体的冲突规避梯度下降来解决梯度冲突。提供收敛保证到帕累托临界点，并进一步展示在两个目标设置下剪辑可以严格改善收敛速度。", "result": "实验结果显示，所提出的方法在多个LLM家族（Qwen 3, Llama 3, Gemma 3）的多目标摘要和安全对齐任务中均取得了优于现有基准方法的结果。", "conclusion": "RACO框架有效解决了冲突目标下的训练问题，并且通过实验验证了其优势。"}}
{"id": "2602.02493", "pdf": "https://arxiv.org/pdf/2602.02493", "abs": "https://arxiv.org/abs/2602.02493", "authors": ["Zehong Ma", "Ruihan Xu", "Shiliang Zhang"], "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss", "categories": ["cs.CV", "cs.AI"], "comment": "Project Pages: https://zehong-ma.github.io/PixelGen/", "summary": "Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.", "AI": {"tldr": "PixelGen是一种直接在像素空间生成图像的简单框架，通过引入感知损失来优化像素扩散模型。", "motivation": "传统的像素扩散方法难以优化包含许多无关视觉信号的高维像素流形，导致性能不如基于潜在变量的方法。为了克服这一挑战，提出了一个带有感知监督的新方法PixelGen。", "method": "PixelGen采用两种互补的感知损失（LPIPS和DINO）来指导模型学习更相关的图像特征。这种方法避免了VAE带来的瓶颈，并且不需要额外的数据预处理步骤或辅助阶段。", "result": "实验结果显示，PixelGen在ImageNet-256上的FID值为5.11，没有使用分类器自由引导并在仅80个训练周期内完成；此外，在大规模文本到图像生成任务中也表现出优越的扩展性能（GenEval得分为0.79）。", "conclusion": "PixelGen提供了一个更简单但功能更强的图像生成范例，不需要VAE或潜在表示，并且在多个数据集上均达到了领先的性能。"}}
{"id": "2602.02488", "pdf": "https://arxiv.org/pdf/2602.02488", "abs": "https://arxiv.org/abs/2602.02488", "authors": ["Yinjie Wang", "Tianbao Xie", "Ke Shen", "Mengdi Wang", "Ling Yang"], "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "Code: https://github.com/Gen-Verse/Open-AgentRL", "summary": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL", "AI": {"tldr": "RLAnything是一种强化学习框架，通过闭环优化动态生成环境、策略和奖励模型，提高整体系统的效率。", "motivation": "该研究旨在开发一个能够增强任何大规模语言模型或代理任务的强化学习系统。传统的RL方法通常依赖于静态环境定义，但这种方法通过集成反馈来改进。", "method": "框架包括了从步骤信号和结果中获取的策略训练、一致性的奖励模型优化，并借助批评者反馈自动适应环境以提高奖励和策略模型的学习效率。", "result": "实验结果显示，在OSWorld上Qwen3-VL-8B-Thinking提高了9.1%，在AlfWorld和LiveBench上，Qwen2.5-7B-Instruct分别提升了18.7%和11.9%，证明了该方法的有效性。", "conclusion": "RLAnything通过动态生成环境、策略及奖励模型实现了对强化学习系统的显著增强。优化后的奖励信号优于基于人工标签的结果，进一步验证了该框架的优势。"}}
{"id": "2602.02486", "pdf": "https://arxiv.org/pdf/2602.02486", "abs": "https://arxiv.org/abs/2602.02486", "authors": ["Jialiang Zhu", "Gongrui Zhang", "Xiaolong Ma", "Lin Xu", "Miaosen Zhang", "Ruiqi Yang", "Song Wang", "Kai Qiu", "Zhirong Wu", "Qi Dai", "Ruichun Ma", "Bei Liu", "Yifan Yang", "Chong Luo", "Zhengyuan Yang", "Linjie Li", "Lijuan Wang", "Weizhu Chen", "Xin Geng", "Baining Guo"], "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.", "AI": {"tldr": "提出了一种递归轨迹压缩框架（RE-TRAC），用于改进基于LLM的深度研究代理。", "motivation": "现有的线性设计使得重新访问早期状态、分支探索或在长时间上下文中保持全局意识变得困难，导致局部最优和搜索效率低下。", "method": "通过生成结构化状态表示来总结证据、不确定性、失败以及未来计划，在每次轨迹后进行交叉轨迹探索，并基于此状态表示条件后续轨迹，实现迭代反思和整体知情规划。", "result": "实验结果表明，RE-TRAC在BrowseComp上优于ReAct 15%-20%，并且通过引入适应性监督微调，达到较小模型下的最佳性能。此外，在多轮次中观察到工具调用次数和token使用量的单调减少趋势。", "conclusion": "递归轨迹压缩框架（RE-TRAC）能够实现更为高效的探索，并且随着反思的进行逐步聚焦于目标，减少了冗余搜索。"}}
{"id": "2602.02481", "pdf": "https://arxiv.org/pdf/2602.02481", "abs": "https://arxiv.org/abs/2602.02481", "authors": ["Brent Yi", "Hongsuk Choi", "Himanshu Gaurav Singh", "Xiaoyu Huang", "Takara E. Truong", "Carmelo Sferrazza", "Yi Ma", "Rocky Duan", "Pieter Abbeel", "Guanya Shi", "Karen Liu", "Angjoo Kanazawa"], "title": "Flow Policy Gradients for Robot Control", "categories": ["cs.RO", "cs.AI"], "comment": "Project webpage: https://hongsukchoi.github.io/fpo-control", "summary": "Likelihood-based policy gradient methods are the dominant approach for training robot control policies from rewards. These methods rely on differentiable action likelihoods, which constrain policy outputs to simple distributions like Gaussians. In this work, we show how flow matching policy gradients -- a recent framework that bypasses likelihood computation -- can be made effective for training and fine-tuning more expressive policies in challenging robot control settings. We introduce an improved objective that enables success in legged locomotion, humanoid motion tracking, and manipulation tasks, as well as robust sim-to-real transfer on two humanoid robots. We then present ablations and analysis on training dynamics. Results show how policies can exploit the flow representation for exploration when training from scratch, as well as improved fine-tuning robustness over baselines.", "AI": {"tldr": "该论文介绍了一种改进的目标函数，使流匹配策略梯度方法在机器人控制任务中更有效。", "motivation": "当前基于概率的策略梯度方法受限于简单的概率分布。本文旨在通过绕过似然计算的方法来训练更具表达性的策略，并实现从模拟到真实环境的稳健迁移。", "method": "引入了一种新的目标函数，利用流匹配策略梯度框架进行机器人控制任务中的策略优化。", "result": "在腿部运动、人体姿态追踪和操作任务中展示了优于基线方法的结果；实现了两个类人机器人的仿真到现实的有效迁移。", "conclusion": "该研究证明了流表示能够用于探索新的动作空间，并且改进后的目标函数对于从头开始训练及微调策略都非常有效。"}}
{"id": "2602.02479", "pdf": "https://arxiv.org/pdf/2602.02479", "abs": "https://arxiv.org/abs/2602.02479", "authors": ["Ni Annie Yuan", "Ho-chun Herbert Chang"], "title": "Motivation, Attention, and Visual Platform Design: How Moral Contagions Spread on TikTok and Instagram in the 2024 United States Presidential Election", "categories": ["cs.CY", "cs.ET"], "comment": null, "summary": "Visual social media platforms have become primary venues for political discourse, yet we know little about how moralization operates differently across platforms and topics. Analyzing 2,027,595 TikToks and 1,126,972 Instagram posts during the 2024 US presidential election, we demonstrate that issues are not necessarily inherently moralized, but a product of audience demographics, platform architecture, and partisan framing. Using temporal supply-demand analysis and moral foundations scoring (eMFD), we examine the dynamics of key electoral issues. Three key findings emerge. First, moralization patterns diverge dramatically by platform: TikTok's algorithm enabled viral spread of moralized abortion and immigration content despite lower supply, while Instagram amplified economic discourse that aligned supply and demand. Second, traditionally \"pragmatic\" economic issues became moralized-cryptocurrency discourse invoked loyalty and authority foundations more strongly than any other topic, framing regulation as government overreach. Third, platforms responded to different events: TikTok surged after Harris's nomination across all topics (96% reduction in supply volatility), while Instagram spiked around cryptocurrency policy developments. Semantic network analysis reveals TikTok's circular topology enables cross-cutting exposure while Instagram's fragmented structure isolates Harris from economic discourse. These findings demonstrate that understanding political moralization requires examining platform-specific ecosystems where architecture, demographics, and content strategy interact to determine which issues get moralized and how moral content spreads.", "AI": {"tldr": "本文研究了2024年美国总统选举期间TikTok和Instagram上政治话语的道德化模式及其影响因素。", "motivation": "当前对于不同视觉社交媒体平台上的道德化传播机制了解有限，尤其是在特定议题下如何通过用户群体、平台架构和党派框架相互作用进行道德化。", "method": "利用时间供应需求分析以及道德基础得分（eMFD），对2024年美国总统选举期间的2,027,595个TikTok视频和1,126,972个Instagram帖子进行了研究，以探讨关键选举议题的动力学。", "result": "研究表明：不同平台道德化模式存在显著差异；传统上被视为实用主义的经济问题在特定框架下变得道德化；以及各平台对事件的不同响应方式。语义网络分析揭示了TikTok与Instagram之间传播机制的区别。", "conclusion": "理解政治话语中的道德化需要考察平台特有的生态系统，其中架构、人口统计学和内容策略共同决定了哪些议题会被道德化及其传播方式。"}}
{"id": "2602.02475", "pdf": "https://arxiv.org/pdf/2602.02475", "abs": "https://arxiv.org/abs/2602.02475", "authors": ["Shraddha Barke", "Arnav Goyal", "Alind Khare", "Avaljot Singh", "Suman Nath", "Chetan Bansal"], "title": "AgentRx: Diagnosing AI Agent Failures from Execution Trajectories", "categories": ["cs.AI"], "comment": null, "summary": "AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.", "AI": {"tldr": "本文提出了一种诊断AI代理失败的框架AgentRx，该框架能够定位关键错误步骤并归类。", "motivation": "由于执行的概率性、长期视域和多代理特性以及工具输出噪声的影响，很难准确地找到AI代理故障的原因。因此需要一种自动化的诊断方法来降低人为成本，提高故障本地化准确性。", "method": "AgentRx通过手动注释失败轨迹建立了一个跨领域的基准测试，并开发了一种合成约束、逐步评估并生成可审计验证日志的自动化框架，利用LLM根据证据判断关键错误步骤和类别。", "result": "该方法在结构化API工作流程、事件管理等三个领域内提高了故障本地化的准确率。", "conclusion": "AgentRx成功地降低了人为成本，并且有效地改善了现有基准线中故障定位的准确性。"}}
{"id": "2602.02474", "pdf": "https://arxiv.org/pdf/2602.02474", "abs": "https://arxiv.org/abs/2602.02474", "authors": ["Haozhen Zhang", "Quanyu Long", "Jianzhu Bao", "Tao Feng", "Weizhi Zhang", "Haodong Yue", "Wenya Wang"], "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code is available at https://github.com/ViktorAxelsen/MemSkill", "summary": "Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \\textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \\emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \\emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \\emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.", "AI": {"tldr": "MemSkill是一种能够学习和进化的记忆技能系统，适用于自我进化代理。", "motivation": "当前大型语言模型的代理记忆系统依赖于少量静态、人工设计的操作来提取内存，这些固定程序使它们在面对多样化的交互模式时变得僵硬且效率低下。因此，研究者提出了MemSkill，以解决这一问题。", "method": "MemSkill通过一个控制器学习选择相关技能，并使用基于LLM的执行器生成指导记忆的技能；同时还有一个设计师模块定期审查难以处理的情况并提出改进或新技能来优化系统。", "result": "实验表明，MemSkill在LoCoMo、LongMemEval、HotpotQA和ALFWorld上的表现优于强基线模型，并且能够很好地泛化到不同设置中。进一步分析展示了技能是如何演化的，为更适应性和自我进化的记忆管理系统提供了见解。", "conclusion": "MemSkill通过一种闭合循环过程改进了技能选择策略和技能集本身，证明了一种新颖的记忆管理方式的有效性。"}}
{"id": "2602.02473", "pdf": "https://arxiv.org/pdf/2602.02473", "abs": "https://arxiv.org/abs/2602.02473", "authors": ["Yinhuai Wang", "Qihan Zhao", "Yuen Fui Lau", "Runyi Yu", "Hok Wai Tsui", "Qifeng Chen", "Jingbo Wang", "Jiangmiao Pang", "Ping Tan"], "title": "HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Enabling humanoid robots to perform agile and adaptive interactive tasks has long been a core challenge in robotics. Current approaches are bottlenecked by either the scarcity of realistic interaction data or the need for meticulous, task-specific reward engineering, which limits their scalability. To narrow this gap, we present HumanX, a full-stack framework that compiles human video into generalizable, real-world interaction skills for humanoids, without task-specific rewards. HumanX integrates two co-designed components: XGen, a data generation pipeline that synthesizes diverse and physically plausible robot interaction data from video while supporting scalable data augmentation; and XMimic, a unified imitation learning framework that learns generalizable interaction skills. Evaluated across five distinct domains--basketball, football, badminton, cargo pickup, and reactive fighting--HumanX successfully acquires 10 different skills and transfers them zero-shot to a physical Unitree G1 humanoid. The learned capabilities include complex maneuvers such as pump-fake turnaround fadeaway jumpshots without any external perception, as well as interactive tasks like sustained human-robot passing sequences over 10 consecutive cycles--learned from a single video demonstration. Our experiments show that HumanX achieves over 8 times higher generalization success than prior methods, demonstrating a scalable and task-agnostic pathway for learning versatile, real-world robot interactive skills.", "AI": {"tldr": "本文提出HumanX框架，从人类视频中生成机器人交互技能数据，并学习通用的互动技巧。", "motivation": "当前方法受限于缺乏真实互动数据或需要精确的任务特定奖励工程，难以实现大规模应用。因此，本文旨在通过结合视频和模仿学习来解决这一问题。", "method": "HumanX由两个集成组件组成：XGen用于从视频中生成可扩展的数据增强的机器人交互数据；XMimic为统一模仿学习框架，能够学习通用的互动技能。", "result": "在五个领域中的十种不同技能上进行评估，该方法实现了超过8倍于先前方法的一般化成功率。所学能力包括复杂的动作和持续的人机传递任务。", "conclusion": "HumanX展示了一条可扩展且非特定任务的方法来学习多样化的现实世界机器人交互技能。"}}
{"id": "2602.02471", "pdf": "https://arxiv.org/pdf/2602.02471", "abs": "https://arxiv.org/abs/2602.02471", "authors": ["Edwin Kys", "Febian Febian"], "title": "Multi-head automated segmentation by incorporating detection head into the contextual layer neural network", "categories": ["cs.CV", "cs.AI", "physics.med-ph"], "comment": "8 pages, 3 figures, 1 table", "summary": "Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \\pm 0.036$ versus $0.732 \\pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.", "AI": {"tldr": "提出了一种基于Swin U-Net的门控多头Transformer架构，用于提高自动分割的准确性。", "motivation": "传统模型在缺乏目标结构的情况下会产生不真实的假阳性结果，因此本文旨在通过引入检测头和上下文层神经网络来改善这个问题。", "method": "采用了一种结合了互切片上下文集成和平行检测头的方法，该方法可以同时执行多层感知机的切片级结构检测和上下文增强流的像素级分割，并使用基于Tversky损失的逐片训练。", "result": "在Prostate-Anatomical-Edge-Cases数据集上，门控模型相比于非门控模型显著提高了性能，假阳性明显减少而不会损害有效切片中的分割质量。", "conclusion": "检测头和上下文层神经网络结合的方法可以提高自动分割的稳健性和解剖学合理性，降低不真实的预测，并在临床放疗自动轮廓工作流中具有应用前景。"}}
{"id": "2602.02470", "pdf": "https://arxiv.org/pdf/2602.02470", "abs": "https://arxiv.org/abs/2602.02470", "authors": ["Xutao Ma", "Yixiao Huang", "Hanlin Zhu", "Somayeh Sojoudi"], "title": "Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge", "categories": ["cs.AI"], "comment": null, "summary": "Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the \"reversal curse\" -- when trained on forward knowledge data of the form \"$A \\rightarrow B$\" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge \"$B \\leftarrow A$\" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form \"$A \\to A$\" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.", "AI": {"tldr": "本文提出了一种简单的数据预处理方法——身份桥，以解决自回归语言模型在逻辑推理中的'反转诅咒'问题。", "motivation": "自回归大型语言模型虽然在许多任务上表现出色，但在简单的逻辑推断如‘反转诅咒’中仍然失败。传统观点认为这是该类模型的固有缺陷，难以克服。", "method": "本文通过向训练数据添加形式为“A→A”的身份桥来改进模型，理论证明了这种简单的方法可以使一维变换器打破'反转诅咒'", "result": "实验结果显示，使用此方法微调后的预训练语言模型在反转任务上达到40%的成功率，而单纯基于前向知识数据训练时成功率近乎为零。", "conclusion": "本文提供了一种理论基础来解决‘反转诅咒’问题，并提出一种低成本的方法促使LLMs从数据中学习更高层次的规则。"}}
{"id": "2602.02468", "pdf": "https://arxiv.org/pdf/2602.02468", "abs": "https://arxiv.org/abs/2602.02468", "authors": ["Aiden Yiliu Li", "Xinyue Hao", "Shilong Liu", "Mengdi Wang"], "title": "Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.", "AI": {"tldr": "介绍了Avenir-Web，一种在复杂网页界面执行长时任务的新型开源自主代理。", "motivation": "当前多模态大型语言模型下的网络代理难以可靠地完成长期任务，特别是在复杂的文档对象模型结构中面临准确元素定位、特定程序知识缺失和不稳定的任务跟踪与记忆问题。", "method": "Avenir-Web利用混合接地专家、经验模仿规划以整合先验程序知识，并结合任务追踪检查表及自适应内存来实现在不同用户界面范式下的稳健且无缝交互。", "result": "在Online-Mind2Web基准测试中，Avenir-Web显著超越了现有开源代理，并达到了与顶级专有模型相媲美的性能水平，确立了新的开放源代码最佳状态。", "conclusion": "通过引入Avenir-Web，解决了网络代理执行复杂网页任务时遇到的问题，并且在实际部署中取得了重大进步。"}}
{"id": "2602.02465", "pdf": "https://arxiv.org/pdf/2602.02465", "abs": "https://arxiv.org/abs/2602.02465", "authors": ["Jana Zeller", "Thaddäus Wiedemer", "Fanfei Li", "Thomas Klein", "Prasanna Mayilvahanan", "Matthias Bethge", "Felix Wichmann", "Ryan Cotterell", "Wieland Brendel"], "title": "MentisOculi: Revealing the Limits of Reasoning with Mental Imagery", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "9 pages, 8 figures", "summary": "Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual representations in a goal-oriented manner. To evaluate and probe this capability, we develop MentisOculi, a procedural, stratified suite of multi-step reasoning problems amenable to visual solution, tuned to challenge frontier models. Evaluating visual strategies ranging from latent tokens to explicit generated imagery, we find they generally fail to improve performance. Analysis of UMMs specifically exposes a critical limitation: While they possess the textual reasoning capacity to solve a task and can sometimes generate correct visuals, they suffer from compounding generation errors and fail to leverage even ground-truth visualizations. Our findings suggest that despite their inherent appeal, visual thoughts do not yet benefit model reasoning. MentisOculi establishes the necessary foundation to analyze and close this gap across diverse model families.", "AI": {"tldr": "本文开发了MentisOculi，一个用于评估多模态模型通过视觉化推理能力的测试集。", "motivation": "为了探究统一多模态模型能否利用视觉思维来改善逻辑推理任务的表现，作者提出了新的挑战。", "method": "设计了一套多层次、多步骤的推理问题MentisOculi，并对其进行了评估。这些问题可以使用视觉解决方案解决。", "result": "实验结果表明，尽管这些模型拥有文字推理能力，它们在生成图像时容易出错且无法利用真实可视化图来改进性能。", "conclusion": "研究发现表明当前多模态模型尚未能有效地将视觉思维用于改善逻辑推理。MentisOculi为分析和弥补这种差距提供了基础框架。"}}
{"id": "2602.02462", "pdf": "https://arxiv.org/pdf/2602.02462", "abs": "https://arxiv.org/abs/2602.02462", "authors": ["Gabriele Maraia", "Marco Valentino", "Fabio Massimo Zanzotto", "Leonardo Ranaldi"], "title": "Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.", "AI": {"tldr": "论文提出了一个框架，通过将结构推理与词汇语义分离来减少大型语言模型在形式演绎中的内容影响。", "motivation": "大型语言模型在演绎判断和三段论推理中存在偏见，即使生成逐步解释也不能完全消除这种偏见。作者希望通过抽象引导的推理方法来减轻这种现象。", "method": "构造包含具体内容和抽象表达的配对三段论，并使用模型在抽象输入上的激活定义一个抽象推理空间。学习轻量级Abstractors以预测与该空间对齐的表现形式，通过多层干预将其集成到前向传递中。", "result": "结果表明，基于激活水平的抽象方法可以减少内容驱动错误并改善有效性敏感性能。", "conclusion": "论文的结果强调了激活级别上的抽象作为一种机制的重要性，可以提高大型语言模型在形式推理中的鲁棒性，对抗语义干扰。"}}
{"id": "2602.02459", "pdf": "https://arxiv.org/pdf/2602.02459", "abs": "https://arxiv.org/abs/2602.02459", "authors": ["Zhiyu Huang", "Yun Zhang", "Johnson Liu", "Rui Song", "Chen Tang", "Jiaqi Ma"], "title": "TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments", "categories": ["cs.RO"], "comment": null, "summary": "Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/", "AI": {"tldr": "介绍了一种新的思虑控制框架TIC-VLA，用于动态环境中的机器人导航。", "motivation": "传统VLA模型假设时间同步的推理和控制，但语义推断实际上比实时行动滞后。TIC-VLA旨在解决这种异步性问题，提高机器人在遵循语言指令的同时保持实时反应控制的能力。", "method": "提出了一种延迟感知框架TIC-VLA，通过引入延迟语义-控制接口来补偿异步推理，并设计了延迟一致的训练流程。", "result": "实验结果表明，TIC-VLA在模拟和真实机器人上均表现出色，优于之前的VLA模型，在多秒级推理延迟下仍能保持稳健的实时控制能力。", "conclusion": "通过引入延迟感知机制，TIC-VLA框架解决了动态环境中的语义推理与动作生成之间的异步性问题，提高了机器人的导航性能和鲁棒性。"}}
{"id": "2602.02456", "pdf": "https://arxiv.org/pdf/2602.02456", "abs": "https://arxiv.org/abs/2602.02456", "authors": ["Albert Gassol Puigjaner", "Angelos Zacharia", "Kostas Alexis"], "title": "Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning", "categories": ["cs.RO"], "comment": "ICRA 2026, 8 pages", "summary": "Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. While traditional Simultaneous Localization and Mapping (SLAM) methods generate metric reconstructions and can be extended to metric-semantic mapping, they lack a higher level of abstraction and relational reasoning. To address this gap, 3D scene graphs have emerged as a powerful representation for capturing hierarchical structures and object relationships. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a Vision Language Model (VLM) to infer semantic relationships. Notably, we introduce a task reasoning module that combines Large Language Models (LLM) and a VLM to interpret the scene graph's semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.", "AI": {"tldr": "提出了一种增强型分层三维场景图，结合多级抽象的开放词汇特征和对象关系推理。通过任务推理模块，使自主代理能够更智能地理解和交互其环境。", "motivation": "传统的SLAM方法生成度量重建，并能扩展到度量-语义映射，但缺乏高层次的抽象和关系推理能力。本文旨在解决这一问题，提出一种新型三维场景图来捕捉层次结构和对象间的关系。", "method": "利用视觉语言模型（VLM）推断语义关系；引入任务推理模块结合大语言模型（LLM）与VLM解释场景图的语义和关系信息；在多个环境和任务中部署到四足机器人上进行验证。", "result": "通过实验显示，该方法能够有效地让自主代理理解和推理其所在环境中的任务，并能更智能地与其交互。", "conclusion": "本文提出的增强型分层三维场景图及其任务推理模块，在理解与互动环境中具有显著优势。"}}
{"id": "2602.02455", "pdf": "https://arxiv.org/pdf/2602.02455", "abs": "https://arxiv.org/abs/2602.02455", "authors": ["Han Bao", "Zheyuan Zhang", "Pengcheng Jing", "Zhengqing Yuan", "Kaiwen Shi", "Yanfang Ye"], "title": "Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction", "categories": ["cs.AI", "cs.CL", "cs.SE"], "comment": "65 pages, 40 figures", "summary": "As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \\textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \\textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \\textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \\MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.", "AI": {"tldr": "该论文介绍了Drift-Bench，这是一个评估大型语言模型代理在输入故障下的交互澄清能力的诊断基准。", "motivation": "随着大型语言模型向自主代理转变，用户输入常常违反合作假设，如隐含意图、缺失参数或模糊表达。现有的评估标准通常基于明确指令或仅限于单回合文本澄清，忽略了多回合澄清和执行风险的影响。", "method": "Drift-Bench采用了经典通信理论的统一合作破裂分类，并使用一个以人物驱动的用户模拟器以及Rise评估协议来测试大型语言模型在不同用户角色和故障类型下的交互澄清能力。", "result": "实验表明，在输入故障情况下，代理性能显著下降。澄清效果因用户角色和故障类型而异。", "conclusion": "该研究通过系统诊断可能导致不安全执行的失败情况，连接了澄清研究与代理安全性评估，为未来的研究提供了方法论支持。"}}
{"id": "2602.02454", "pdf": "https://arxiv.org/pdf/2602.02454", "abs": "https://arxiv.org/abs/2602.02454", "authors": ["Ansh Kumar Sharma", "Yixiang Sun", "Ninghao Lu", "Yunzhe Zhang", "Jiarao Liu", "Sherry Yang"], "title": "World-Gymnast: Training Robots with Reinforcement Learning in a World Model", "categories": ["cs.RO", "cs.AI"], "comment": "https://world-gymnast.github.io/", "summary": "Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models learned from real-world video-action data, we ask the question of whether training a policy in a world model can be more effective than supervised learning or software simulation in achieving better real-robot performance. We propose World-Gymnast, which performs RL finetuning of a vision-language-action (VLA) policy by rolling out the policy in an action-conditioned video world model and rewarding the rollouts with a vision-language model (VLM). On the Bridge robot setup, World-Gymnast outperforms SFT by as much as 18x and outperforms software simulator by as much as 2x. More importantly, World-Gymnast demonstrates intriguing capabilities of RL with a world model, including training on diverse language instructions and novel scenes from the world model, test-time training in a novel scene, and online iterative world model and policy improvement. Our results suggest learning a world model and training robot policies in the cloud could be the key to bridging the gap between robots that work in demonstrations and robots that can work in anyone's household.", "AI": {"tldr": "本文提出了一种名为World-Gymnast的方法，通过在基于视频的世界模型中进行强化学习训练机器人策略来提高真实世界的性能。", "motivation": "物理世界中的机器人交互式学习受到实际操作成本的限制。监督微调和软件模拟器受到专家数据量有限以及模拟与现实之间的差距的影响。本文探讨是否可以通过基于视频的世界模型来进行强化学习，从而优于这两种方法以实现更好的实际机器人表现。", "method": "World-Gymnast通过在动作条件下的视频世界模型中滚动策略，并使用视觉语言模型奖励该过程来执行监督微调的强化学习。具体步骤包括训练VLA策略，在世界模型中进行政策改进以及测试时的新环境适应性训练。", "result": "在Bridge机器人设置下，World-Gymnast相比监督微调提高了18倍的表现，并且比软件模拟器提升了2倍以上。此外，它还展示了通过世界模型进行强化学习的潜在能力，包括基于语言指令和新场景下的培训以及在线迭代的世界模型与策略改进。", "conclusion": "研究结果表明，在云端学习一个世界模型并在其中训练机器人政策可能是解决演示中的机器人工作到可以适应任何家庭中机器人的关键桥梁。"}}
{"id": "2602.02453", "pdf": "https://arxiv.org/pdf/2602.02453", "abs": "https://arxiv.org/abs/2602.02453", "authors": ["Andong Chen", "Wenxin Zhu", "Qiuyu Ding", "Yuchen Song", "Muyun Yang", "Tiejun Zhao"], "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling", "categories": ["cs.AI"], "comment": "Working paper", "summary": "Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.", "AI": {"tldr": "提出了一种使用漫画进行视觉推理的模式，以提高多模态推理能力。", "motivation": "现有图像和视频在时空结构、冗余度及计算成本方面存在局限性，论文旨在探索一种介于两者之间的高效信息密度媒介——漫画，来提升多步时序和因果推理任务的表现。", "method": "使用漫画进行视觉推理，系统研究了两种基于漫画的推理路径，并评估其在各种推理任务中的表现。", "result": "实验结果表明，Thinking with Comics 在多步骤时间及因果推理任务上优于 Thinking with Images，且比 Thinking with Video 更具效率。不同漫画叙事结构和风格对性能有显著影响。", "conclusion": "漫画作为一种有效的视觉中介表示，可提升多模态推理能力。"}}
{"id": "2602.02451", "pdf": "https://arxiv.org/pdf/2602.02451", "abs": "https://arxiv.org/abs/2602.02451", "authors": ["Patrick Cooper", "Alvaro Velasquez"], "title": "Active Causal Experimentalist (ACE): Learning Intervention Strategies via Direct Preference Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 5 figures", "summary": "Discovering causal relationships requires controlled experiments, but experimentalists face a sequential decision problem: each intervention reveals information that should inform what to try next. Traditional approaches such as random sampling, greedy information maximization, and round-robin coverage treat each decision in isolation, unable to learn adaptive strategies from experience. We propose Active Causal Experimentalist (ACE), which learns experimental design as a sequential policy. Our key insight is that while absolute information gains diminish as knowledge accumulates (making value-based RL unstable), relative comparisons between candidate interventions remain meaningful throughout. ACE exploits this via Direct Preference Optimization, learning from pairwise intervention comparisons rather than non-stationary reward magnitudes. Across synthetic benchmarks, physics simulations, and economic data, ACE achieves 70-71% improvement over baselines at equal intervention budgets (p < 0.001, Cohen's d ~ 2). Notably, the learned policy autonomously discovers that collider mechanisms require concentrated interventions on parent variables, a theoretically-grounded strategy that emerges purely from experience. This suggests preference-based learning can recover principled experimental strategies, complementing theory with learned domain adaptation.", "AI": {"tldr": "本文提出了一种名为Active Causal Experimentalist (ACE) 的方法，旨在通过直接偏好优化学习干预策略。", "motivation": "传统的实验设计方式如随机采样、贪婪信息最大化等无法适应动态变化的学习过程，难以从经验中提取出有效的策略。因此需要一种新的方法来解决这一问题。", "method": "ACE 方法通过直接偏好优化进行干预比较，而不是依赖于非平稳的奖励幅度，从而实现对实验设计的动态学习和调整。", "result": "在合成基准、物理模拟以及经济数据集上，ACE 在相同的干预预算下比基线方法取得了70-71% 的改进（p < 0.001, Cohen's d ~ 2）。", "conclusion": "ACE 方法证明了基于偏好的学习可以恢复出原则性的实验策略，并且通过经验自主发现了一些理论基础的干预机制。"}}
{"id": "2602.02447", "pdf": "https://arxiv.org/pdf/2602.02447", "abs": "https://arxiv.org/abs/2602.02447", "authors": ["Thomas M. Prinz", "Christopher T. Schwanen", "Wil M. P. van der Aalst"], "title": "Deciding Reachability and the Covering Problem with Diagnostics for Sound Acyclic Free-Choice Workflow Nets", "categories": ["cs.FL", "cs.DS"], "comment": "38 pages, 18 figures", "summary": "A central decision problem in Petri net theory is reachability asking whether a given marking can be reached from the initial marking. Related is the covering problem (or sub-marking reachbility), which decides whether there is a reachable marking covering at least the tokens in the given marking. For live and bounded free-choice nets as well as for sound free-choice workflow nets, both problems are polynomial in their computational complexity. This paper refines this complexity for the class of sound acyclic free-choice workflow nets to a quadratic polynomial, more specifically to $O(P^2 + T^2)$. Furthermore, this paper shows the feasibility of accurately explaining why a given marking is or is not reachable. This can be achieved by three new concepts: admissibility, maximum admissibility, and diverging transitions. Admissibility requires that all places in a given marking are pairwise concurrent. Maximum admissibility states that adding a marked place to an admissible marking would make it inadmissible. A diverging transition is a transition which originally \"produces\" the concurrent tokens that lead to a given marking. In this paper, we provide algorithms for all these concepts and explain their computation in detail by basing them on the concepts of concurrency and post-dominance frontiers - a well known concept from compiler construction. In doing this, we present straight-forward implementations for solving (sub-marking) reachability.", "AI": {"tldr": "本文研究了声无环自由选择工作流网中的可到达性和覆盖问题，并提出了新的概念来准确解释标记是否可达。", "motivation": "解决Petri网理论中的中心决策问题是判断给定标记是否可以从初始标记达到。对于活跃且有界的自由选择网络以及声音的自由选择工作流程网络，这些问题具有多项式时间复杂度。", "method": "本文提出了三个新概念：可接纳性、最大可接纳性和发散转换，并提供了基于并发和后续支配边界这两个已知概念来计算这些概念的算法。", "result": "对于声无环自由选择的工作流网，该文将复杂度从多项式细化为二次多项式$O(P^2 + T^2)$。并且提出了准确解释给定标记是否可达的方法。", "conclusion": "通过基于并发和后续支配边界的概念，本文提供了一种解决（子标记）可到达性问题的直接实现方式，并提出了一系列新概念来更好地理解声无环自由选择工作流网中的可到达性和覆盖问题。"}}
{"id": "2602.02444", "pdf": "https://arxiv.org/pdf/2602.02444", "abs": "https://arxiv.org/abs/2602.02444", "authors": ["Tyler Skow", "Alexander Martin", "Benjamin Van Durme", "Rama Chellappa", "Reno Kriz"], "title": "RANKVIDEO: Reasoning Reranking for Text-to-Video Retrieval", "categories": ["cs.IR", "cs.CV"], "comment": null, "summary": "Reranking is a critical component of modern retrieval systems, which typically pair an efficient first-stage retriever with a more expressive model to refine results. While large reasoning models have driven rapid progress in text-centric reranking, reasoning-based reranking for video retrieval remains underexplored. To address this gap, we introduce RANKVIDEO, a reasoning-based reranker for video retrieval that explicitly reasons over query-video pairs using video content to assess relevance. RANKVIDEO is trained using a two-stage curriculum consisting of perception-grounded supervised fine-tuning followed by reranking training that combines pointwise, pairwise, and teacher confidence distillation objectives, and is supported by a data synthesis pipeline for constructing reasoning-intensive query-video pairs. Experiments on the large-scale MultiVENT 2.0 benchmark demonstrate that RANKVIDEO consistently improves retrieval performance within a two-stage framework, yielding an average improvement of 31% on nDCG@10 and outperforming text-only and vision-language reranking alternatives, while more efficient.", "AI": {"tldr": "介绍了一种名为RANKVIDEO的视频检索重排序方法，通过视频内容评估查询和视频对的相关性。", "motivation": "当前在文本为中心的重排序中取得了显著进展，但对于基于推理的视频检索重排序研究较少。为此，提出了RANKVIDEO以填补这一空白。", "method": "利用感知引导的监督微调以及结合点到点、成对和教师置信度蒸馏目标的重排序训练组成两阶段课程来训练模型，并通过数据合成管道构造推理密集型查询-视频对。", "result": "在大规模MultiVENT 2.0基准测试中，RANKVIDEO表现出色，在nDCG@10上平均提高了31%，优于文本和视觉语言重排序方法。", "conclusion": "证明了基于推理的视频检索重排序的有效性，并且表明这种方法比单纯依赖文本或视觉语言的方法更加高效。"}}
{"id": "2602.02439", "pdf": "https://arxiv.org/pdf/2602.02439", "abs": "https://arxiv.org/abs/2602.02439", "authors": ["Olaf Yunus Laitinen Imanov", "Derya Umut Kulali", "Taner Yilmaz", "Duygu Erisken", "Rana Irem Turhan"], "title": "Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization", "categories": ["cs.NE", "cs.ET", "cs.LG"], "comment": "8 pages, 4 figures, 4 tables. Submitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)", "summary": "Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SNN models with hardware-aware optimization for edge deployment. NeuEdge uses a temporal coding scheme that blends rate and spike-timing patterns to reduce spike activity while preserving accuracy, and a hardware-aware training procedure that co-optimizes network structure and on-chip placement to improve utilization on neuromorphic processors. An adaptive threshold mechanism adjusts neuron excitability from input statistics, reducing energy consumption without degrading performance. Across standard vision and audio benchmarks, NeuEdge achieves 91-96% accuracy with up to 2.3 ms inference latency on edge hardware and an estimated 847 GOp/s/W energy efficiency. A case study on an autonomous-drone workload shows up to 312x energy savings relative to conventional deep neural networks while maintaining real-time operation.", "AI": {"tldr": "提出了一种名为NeuEdge的框架，旨在通过结合自适应脉冲神经网络模型和硬件感知优化来实现边缘AI应用的能量高效计算。", "motivation": "当前边缘AI应用需要超低功耗和低延迟推理。基于事件驱动的SNNs是很有前途的技术路径，但实际部署在资源受限设备上存在训练难度、硬件映射开销以及对时间动态敏感等问题。", "method": "NeuEdge使用混合速率与脉冲时序模式的时间编码方案降低脉冲活动同时保持准确性，并采用硬件感知的训练流程联合优化网络结构和芯片布局以提高神经形态处理器上的利用率。自适应阈值机制根据输入统计调整神经元兴奋性，减少能量消耗而不影响性能。", "result": "在标准视觉与音频基准测试中，NeuEdge实现了91-96%的精度，并且最多2.3ms推理延迟，在边缘硬件上估计的能量效率高达847 GOp/s/W。在自主无人机工作负载上的案例研究显示相对于传统深度神经网络节省了多达312倍的能量。", "conclusion": "通过结合自适应脉冲神经网络模型和硬件感知优化，NeuEdge框架成功地解决了边缘AI应用中的能量效率问题，并实现了实时操作所需的性能与功耗平衡。"}}
{"id": "2602.02437", "pdf": "https://arxiv.org/pdf/2602.02437", "abs": "https://arxiv.org/abs/2602.02437", "authors": ["Dianyi Wang", "Chaofan Ma", "Feng Han", "Size Wu", "Wei Song", "Yibin Wang", "Zhixiong Zhang", "Tianhang Wang", "Siyuan Wang", "Zhongyu Wei", "Jiaqi Wang"], "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.", "AI": {"tldr": "本文提出了UniReason框架，旨在通过统一的推理范式解决多模态模型在复杂合成任务中的挑战，并改善图像生成和编辑之间的互联性。", "motivation": "传统的统一流模型在处理需要深度推理的任务时效果不佳。文本到图像生成与图像编辑通常被视为独立的能力，而非相互关联的推理步骤，这限制了它们的表现。", "method": "UniReason通过双轨推理范式将生成和编辑任务统一起来，使用世界知识增强的规划注入隐含约束，并利用编辑能力进行细粒度视觉修正。此外，构建了一个大规模推理中心数据集支持框架。", "result": "实验结果显示，UniReason在WISE、KrisBench以及UniREditBench等推理密集型基准测试中表现优异，同时保持了强大的综合合成性能。", "conclusion": "该研究提出了一种新的方法来解决复杂任务中的多模态推理问题，并展示出在图像生成和编辑方面的显著改善。"}}
{"id": "2602.02430", "pdf": "https://arxiv.org/pdf/2602.02430", "abs": "https://arxiv.org/abs/2602.02430", "authors": ["Pierre-Yves Lajoie", "Benjamin Ramtoula", "Daniele De Martini", "Giovanni Beltrame"], "title": "3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM", "categories": ["cs.RO"], "comment": null, "summary": "Decentralized Collaborative Simultaneous Localization And Mapping (C-SLAM) techniques often struggle to identify map overlaps due to significant viewpoint variations among robots. Motivated by recent advancements in 3D foundation models, which can register images despite large viewpoint differences, we propose a robust loop closing approach that leverages these models to establish inter-robot measurements. In contrast to resource-intensive methods requiring full 3D reconstruction within a centralized map, our approach integrates foundation models into existing SLAM pipelines, yielding scalable and robust multi-robot mapping. Our contributions include: (1) integrating 3D foundation models to reliably estimate relative poses from monocular image pairs within decentralized C-SLAM; (2) introducing robust outlier mitigation techniques critical to the use of these relative poses; and (3) developing specialized pose graph optimization formulations that efficiently resolve scale ambiguities. We evaluate our method against state-of-the-art approaches, demonstrating improvements in localization and mapping accuracy, alongside significant gains in computational and memory efficiency. These results highlight the potential of our approach for deployment in large-scale multi-robot scenarios.", "AI": {"tldr": "基于3D基础模型的去中心化协作SLAM中的循环闭合方法，通过图像配准实现多机器人地图重叠识别。", "motivation": "现有去中心化的协作SLAM技术在处理不同视角下的地图重叠时遇到挑战。本文利用近期进展中的3D基础模型来解决这个问题，这些模型能够在显著的视点变化下进行图像配准。", "method": "提出了一种集成3D基础模型的方法，在不需要完整重建的情况下实现多机器人协作SLAM中相对姿态估计，并引入了稳健的异常值缓解技术及优化公式以提高效率和准确性。", "result": "实验表明，该方法在定位和地图构建准确度方面优于现有最佳方法，并且计算与存储资源需求显著降低。", "conclusion": "本文提出的方法展示了其在大规模多机器人场景中的应用潜力。"}}
{"id": "2602.02426", "pdf": "https://arxiv.org/pdf/2602.02426", "abs": "https://arxiv.org/abs/2602.02426", "authors": ["Simon-Olivier Duguay", "Hugo Baudchon", "Etienne Laliberté", "Helene Muller-Landau", "Gonzalo Rivas-Torres", "Arthur Ouaknine"], "title": "SelvaMask: Segmenting Trees in Tropical Forests and Beyond", "categories": ["cs.CV"], "comment": "22 pages, 8 figures", "summary": "Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.", "AI": {"tldr": "本文提出了SelvaMask，这是一个新的热带树木冠层分割数据集，并提出了一种基于视觉基础模型的检测-分割管道来提高密集热带森林中树木冠层的精确划分。", "motivation": "由于目前大多数森林中的树木冠层分割性能较低，特别是在热带地区，因此需要更好的方法和技术来进行准确的研究和监测。", "method": "本文提出了SelvaMask数据集以及一种采用领域特定检测提示器来调整视觉基础模型的模块化检测-分割管道。", "result": "所提出的方法在密集热带森林中实现了最先进的性能，并且在外部分布的数据集上也进行了验证，证明了该方法的有效性。", "conclusion": "SelvaMask数据集不仅是一个挑战性的基准测试平台，也是通用森林监测的关键工具。"}}
{"id": "2602.02422", "pdf": "https://arxiv.org/pdf/2602.02422", "abs": "https://arxiv.org/abs/2602.02422", "authors": ["Sayak Chakrabarti", "Toniann Pitassi", "Josh Alman"], "title": "Poly-attention: a general scheme for higher-order self-attention", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The self-attention mechanism, at the heart of the Transformer model, is able to effectively model pairwise interactions between tokens. However, numerous recent works have shown that it is unable to perform basic tasks involving detecting triples of correlated tokens, or compositional tasks where multiple input tokens need to be referenced to generate a result. Some higher-dimensional alternatives to self-attention have been proposed to address this, including higher-order attention and Strassen attention, which can perform some of these polyadic tasks in exchange for slower, superquadratic running times. In this work, we define a vast class of generalizations of self-attention, which we call poly-attention mechanisms. Our mechanisms can incorporate arbitrary higher-order (tensor) computations as well as arbitrary relationship structures between the input tokens, and they include the aforementioned alternatives as special cases. We then systematically study their computational complexity and representational strength, including giving new algorithms and matching complexity-theoretic lower bounds on the time complexity of computing the attention matrix exactly as well as approximately, and tightly determining which polyadic tasks they can each perform. Our results give interesting trade-offs between different desiderata for these mechanisms, including a tight relationship between how expressive a mechanism is, and how large the coefficients in the model may be so that the mechanism can be approximated in almost-linear time. Notably, we give a new attention mechanism which can be computed exactly in quadratic time, and which can perform function composition for any fixed number of functions. Prior mechanisms, even for just composing two functions, could only be computed in superquadratic time, and our new lower bounds show that faster algorithms for them are not possible.", "AI": {"tldr": "本文提出了一种称为Poly-Attention的广泛自注意力机制类，以解决现有自注意力机制无法处理三元组相关和组合任务的问题。", "motivation": "当前的自注意力机制在检测令牌之间的成对交互方面非常有效，但难以处理涉及多个输入令牌的基本任务或组合任务。因此，需要一种可以结合任意高阶计算并支持任意关系结构的一般化方案来改进这一点。", "method": "提出了Poly-Attention机制类，它能够包含任意的高阶（张量）计算以及输入令牌之间的任意关系结构，并系统地研究了这些机制的计算复杂度和表示能力。此外，还提供了新的算法并匹配了关于准确或近似计算注意力矩阵的时间复杂性理论下界。", "result": "提出的Poly-Attention机制包括先前提出的方法作为特殊情况，展示了不同需求之间有趣的权衡关系，例如表达能力和几乎线性时间中的系数大小之间的紧密联系。新机制可以在二次时间内精确执行，并能够对任何固定数量的函数执行功能组合。", "conclusion": "本文通过引入一种新的注意力机制，即Poly-Attention，解决了当前自注意力机制在处理多令牌任务和复杂交互方面的局限性。该方法不仅可以进行高效的近似计算，还能实现更复杂的组合操作，从而提高了模型的灵活性和表达能力。"}}
{"id": "2602.02419", "pdf": "https://arxiv.org/pdf/2602.02419", "abs": "https://arxiv.org/abs/2602.02419", "authors": ["Qingni Wang", "Yue Fan", "Xin Eric Wang"], "title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference.", "AI": {"tldr": "SafeGround是一个用于图形用户界面（GUI）定位模型的不确定性校准框架，通过控制错误发现率来提高模型的安全性和准确性。", "motivation": "在将自然语言指令转换为可执行屏幕坐标时，错误的GUI定位可能导致严重的后果。因此，需要一个可靠且风险可控的方法来确保模型的预测准确。", "method": "SafeGround利用分布感知不确定性量化方法捕捉随机样本的空间扩散，并通过校准过程确定测试时间决策阈值，以控制统计保证的错误发现率（FDR）。", "result": "实验结果表明，SafeGround在区分正确和不正确的预测方面优于现有基线。此外，它能有效地控制系统层面的准确性提升。", "conclusion": "SafeGround通过校准不确定性并实现风险控制，在多个GUI定位模型上提升了系统的整体精度。"}}
{"id": "2602.02416", "pdf": "https://arxiv.org/pdf/2602.02416", "abs": "https://arxiv.org/abs/2602.02416", "authors": ["Ankur Samanta", "Akshayaa Magesh", "Ayush Jain", "Kavosh Asadi", "Youliang Yu", "Daniel Jiang", "Boris Vidolov", "Kaveh Hassani", "Paul Sajda", "Jalaj Bhandari", "Yonathan Efroni"], "title": "Structure Enables Effective Self-Localization of Errors in LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.", "AI": {"tldr": "研究探索了大型语言模型是否能通过结构化的思考步骤自我定位错误，提出了迭代校正思想采样的方法Thought-ICS。", "motivation": "旨在建立能够有效自我纠正的AI系统。受人脑在决策点监控和重新选择影响启发，提出了一种新的自我纠错框架。", "method": "引入了结构化推理的方式，将思考步骤分为离散且语义连贯的部分，并通过迭代校正思想采样（Thought-ICS）的方法进行错误定位与纠正。", "result": "在经过外部验证的情况下，Thought-ICS实现了20%-40%的自我纠错提升；而在完全自主设置中也超过了现有的基准方法。", "conclusion": "结构化的思考步骤有助于语言模型更有效地自我定位和纠正错误。"}}
{"id": "2602.02413", "pdf": "https://arxiv.org/pdf/2602.02413", "abs": "https://arxiv.org/abs/2602.02413", "authors": ["Rajalaxmi Rajagopalan", "Ritwik Giri", "Zhiqiang Tang", "Kyu Han"], "title": "Masked Autoencoders as Universal Speech Enhancer", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Supervised speech enhancement methods have been very successful. However, in practical scenarios, there is a lack of clean speech, and self-supervised learning-based (SSL) speech enhancement methods that offer comparable enhancement performance and can be applied to other speech-related downstream applications are desired. In this work, we develop a masked autoencoder based universal speech enhancer that is agnostic to the type of distortion affecting speech, can handle multiple distortions simultaneously, and is trained in a self-supervised manner. An augmentation stack adds further distortions to the noisy input data. The masked autoencoder model learns to remove the added distortions along with reconstructing the masked regions of the spectrogram during pre-training. The pre-trained embeddings are then used by fine-tuning models trained on a small amount of paired data for specific downstream tasks. We evaluate the pre-trained features for denoising and dereverberation downstream tasks. We explore different augmentations (like single or multi-speaker) in the pre-training augmentation stack and the effect of different noisy input feature representations (like $log1p$ compression) on pre-trained embeddings and downstream fine-tuning enhancement performance. We show that the proposed method not only outperforms the baseline but also achieves state-of-the-art performance for both in-domain and out-of-domain evaluation datasets.", "AI": {"tldr": "该论文提出了一种基于掩码自动编码器的通用语音增强方法，可以同时处理多种失真，并在自我监督学习模式下训练。", "motivation": "现有监督式语音增强方法依赖于清洁语音数据，在实际场景中难以获取。因此提出了无需清洁语音、适用于其他语音相关下游任务的方法。", "method": "通过添加进一步失真的增广栈对嘈杂输入数据进行处理，掩码自动编码器模型学习去除这些增加的失真并重建光谱图中的掩盖区域。预先训练嵌入然后在少量配对标记数据上进行微调以用于特定的下游任务。", "result": "该方法不仅优于基线方法，在领域内和领域外评估数据集上的语音去噪和消混响下游任务中也达到了最先进的性能。", "conclusion": "基于掩码自动编码器的通用语音增强方法在无需清洁语音的情况下，能够实现高水准的语音增强，并适用于多种失真的情况。"}}
{"id": "2602.02411", "pdf": "https://arxiv.org/pdf/2602.02411", "abs": "https://arxiv.org/abs/2602.02411", "authors": ["Hanwen Ren", "Junyong Kim", "Aathman Tharmasanthiran", "Ahmed H. Qureshi"], "title": "Multi-Agent Monte Carlo Tree Search for Makespan-Efficient Object Rearrangement in Cluttered Spaces", "categories": ["cs.RO"], "comment": null, "summary": "Object rearrangement planning in complex, cluttered environments is a common challenge in warehouses, households, and rescue sites. Prior studies largely address monotone instances, whereas real-world tasks are often non-monotone-objects block one another and must be temporarily relocated to intermediate positions before reaching their final goals. In such settings, effective multi-agent collaboration can substantially reduce the time required to complete tasks. This paper introduces Centralized, Asynchronous, Multi-agent Monte Carlo Tree Search (CAM-MCTS), a novel framework for general-purpose makespan-efficient object rearrangement planning in challenging environments. CAM-MCTS combines centralized task assignment-where agents remain aware of each other's intended actions to facilitate globally optimized planning-with an asynchronous task execution strategy that enables agents to take on new tasks at appropriate time steps, rather than waiting for others, guided by a one-step look-ahead cost estimate. This design minimizes idle time, prevents unnecessary synchronization delays, and enhances overall system efficiency. We evaluate CAM-MCTS across a diverse set of monotone and non-monotone tasks in cluttered environments, demonstrating consistent reductions in makespan compared to strong baselines. Finally, we validate our approach on a real-world multi-agent system under different configurations, further confirming its effectiveness and robustness.", "AI": {"tldr": "本文提出了一种名为CAM-MCTS的新框架，用于复杂环境中多智能体协同进行物体重新排列规划。", "motivation": "在复杂的、混乱的环境中，物体重新排列是一项常见挑战。现有的研究大多针对单调实例，而在实际任务中往往非单调——即物体会相互阻挡需要暂时移动到中间位置才能到达最终目标。在这种情况下，有效的多智能体协作可以显著减少完成任务所需的时间。", "method": "本文提出的CAM-MCTS框架结合了集中式任务分配和异步任务执行策略，能够使代理在适当的时间点接手新任务，而不是等待其他代理，并且通过一步预测成本估计指导代理行动。这种方法最小化了空闲时间，避免了不必要的同步延迟，从而提高了系统的整体效率。", "result": "本文展示了CAM-MCTS框架在各种单调和非单调任务中的一致性减少任务完成时间的优势。此外，在不同配置下的真实世界多智能体系统验证进一步确认其有效性和鲁棒性。", "conclusion": "通过有效的多代理协作，CAM-MCTS显著提高了物体重新排列规划的效率，并展示了良好的通用性和稳健性。"}}
{"id": "2602.02409", "pdf": "https://arxiv.org/pdf/2602.02409", "abs": "https://arxiv.org/abs/2602.02409", "authors": ["Abid Hassan", "Tuan Ngo", "Saad Shafiq", "Nenad Medvidovic"], "title": "Catalyst: Out-of-Distribution Detection via Elastic Scaling", "categories": ["cs.CV"], "comment": null, "summary": "Out-of-distribution (OOD) detection is critical for the safe deployment of deep neural networks. State-of-the-art post-hoc methods typically derive OOD scores from the output logits or penultimate feature vector obtained via global average pooling (GAP). We contend that this exclusive reliance on the logit or feature vector discards a rich, complementary signal: the raw channel-wise statistics of the pre-pooling feature map lost in GAP. In this paper, we introduce Catalyst, a post-hoc framework that exploits these under-explored signals. Catalyst computes an input-dependent scaling factor ($γ$) on-the-fly from these raw statistics (e.g., mean, standard deviation, and maximum activation). This $γ$ is then fused with the existing baseline score, multiplicatively modulating it -- an ``elastic scaling'' -- to push the ID and OOD distributions further apart. We demonstrate Catalyst is a generalizable framework: it seamlessly integrates with logit-based methods (e.g., Energy, ReAct, SCALE) and also provides a significant boost to distance-based detectors like KNN. As a result, Catalyst achieves substantial and consistent performance gains, reducing the average False Positive Rate by 32.87 on CIFAR-10 (ResNet-18), 27.94% on CIFAR-100 (ResNet-18), and 22.25% on ImageNet (ResNet-50). Our results highlight the untapped potential of pre-pooling statistics and demonstrate that Catalyst is complementary to existing OOD detection approaches.", "AI": {"tldr": "该论文提出了Catalyst框架，通过利用预池化特征图的通道级统计信息进行弹性缩放来改进Out-of-distribution（OOD）检测。", "motivation": "现有的OOD检测方法通常依赖于全局平均池化后的输出logits或特征向量，这种方法忽略了丰富的原始通道级统计数据，导致无法充分利用这些数据。", "method": "Catalyst框架通过计算输入依赖的缩放因子$γ$（基于预池化的特征图），并将其与现有的基线分数乘法结合来实现弹性缩放。这种弹性缩放可以增加ID和OOD分布之间的距离，从而提高检测性能。", "result": "实验结果显示，Catalyst框架在多个数据集上显著减少了平均假阳性率：CIFAR-10（ResNet-18）减少32.87%，CIFAR-100（ResNet-18）减少27.94%，ImageNet（ResNet-50）减少22.25%。", "conclusion": "实验结果表明，预池化统计信息具有未开发的潜力，并且Catalyst框架可以与现有的OOD检测方法互补。"}}
{"id": "2602.02408", "pdf": "https://arxiv.org/pdf/2602.02408", "abs": "https://arxiv.org/abs/2602.02408", "authors": ["Jiaxing Qiu", "Kaihua Hou", "Roxana Daneshjou", "Ahmed Alaa", "Thomas Hartvigsen"], "title": "ReasonEdit: Editing Vision-Language Models using Human Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images. We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup. ReasonEdit continuously stores human reasoning in a codebook, and retrieves only relevant facts during inference using a novel topology-balanced multimodal embedding method inspired by network science. Across four VLMs on multiple rationale-based visual question answering datasets, ReasonEdit achieves state-of-the-art editing performance, ultimately showing that using human reasoning during editing greatly improves edit generalization.", "AI": {"tldr": "ReasonEdit是第一个允许用户在编辑视觉语言模型时解释其推理的系统，通过存储人类推理并在推断过程中检索相关事实以提高编辑性能。", "motivation": "现有的视觉语言模型编辑器未能解决需要大量推理的任务，而这些任务通常要求人类和模型对图像进行推理。因此，提出ReasonEdit来填补这一空白，并证明使用人类推理可以显著改善编辑效果。", "method": "ReasonEdit通过持续存储人类的推理并在推断过程中使用一种新型拓扑平衡多模态嵌入方法检索相关的事实。该方法受到网络科学的启发。", "result": "在四个视觉语言模型和多个基于理由的视觉问答数据集上，ReasonEdit达到了最先进的编辑性能。", "conclusion": "与现有编辑器相比，将人类推理引入编辑过程显著提高了编辑的一般化能力。"}}
{"id": "2602.02405", "pdf": "https://arxiv.org/pdf/2602.02405", "abs": "https://arxiv.org/abs/2602.02405", "authors": ["Ethan Mendes", "Jungsoo Park", "Alan Ritter"], "title": "Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Improving the reasoning capabilities of large language models (LLMs) typically relies either on the model's ability to sample a correct solution to be reinforced or on the existence of a stronger model able to solve the problem. However, many difficult problems remain intractable for even current frontier models, preventing the extraction of valid training signals. A promising alternative is to leverage high-quality expert human solutions, yet naive imitation of this data fails because it is fundamentally out of distribution: expert solutions are typically didactic, containing implicit reasoning gaps intended for human readers rather than computational models. Furthermore, high-quality expert solutions are expensive, necessitating generalizable sample-efficient training methods. We propose Distribution Aligned Imitation Learning (DAIL), a two-step method that bridges the distributional gap by first transforming expert solutions into detailed, in-distribution reasoning traces and then applying a contrastive objective to focus learning on expert insights and methodologies. We find that DAIL can leverage fewer than 1000 high-quality expert solutions to achieve 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improve reasoning efficiency by 2x to 4x, and enable out-of-domain generalization.", "AI": {"tldr": "本文提出了一种新的方法DAIL，旨在将专家解决方案转化为计算模型可以理解的推理过程，并通过对比目标提高模型的学习效果。", "motivation": "现有大型语言模型难以直接利用高质量的人类专家解决方案进行训练，因为这些方案包含了一些对人类读者有意义但对计算模型而言不明确的推理间隙。此外，高质量的数据集非常昂贵且稀缺。", "method": "DAIL是一个两阶段的方法：第一阶段将专家提供的解决方案转换为详细的、易于理解的推理轨迹；第二阶段通过对比目标来聚焦于学习专家方法论中的核心要点。", "result": "实验表明，使用少于1000个高质量的人类解决方案训练后，Qwen2.5-Instruct和Qwen3模型在pass@k指标上有10-25%的改进，推理效率提高了2到4倍，并且可以实现域外泛化。", "conclusion": "DAIL提供了一种有效的方法来利用有限数量高质量的人类专家解决方案训练语言模型，从而提高其推理能力。"}}
{"id": "2602.02402", "pdf": "https://arxiv.org/pdf/2602.02402", "abs": "https://arxiv.org/abs/2602.02402", "authors": ["Mu Huang", "Hui Wang", "Kerui Ren", "Linning Xu", "Yunsong Zhou", "Mulin Yu", "Bo Dai", "Jiangmiao Pang"], "title": "SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV", "physics.app-ph"], "comment": "Project page: https://city-super.github.io/SoMA/", "summary": "Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding.", "AI": {"tldr": "SoMA是一种用于软体机器人操作的神经模拟器，可以实现从真实到仿真环境中的稳定和可控的长时序操作。", "motivation": "现有的仿真器在无机器人控制条件的情况下依赖于预定义的物理模型或数据驱动的动力学模型，这限制了准确性和泛化性。SoMA旨在解决这些问题，并提高仿真的精确度和稳定性。", "method": "SoMA结合了可变形动力学、环境力和机器人的关节动作，在统一的潜在神经空间中实现了端到端的真实到仿真模拟。它通过学习高斯点集来建模交互，使控制成为可能并超越观察轨迹进行泛化。", "result": "在真实世界的机器人操作重置仿真时，SoMA提高了20%的准确性和泛化性，并能够稳定地模拟复杂任务如长时间的布折叠。", "conclusion": "SoMA提供了一个新的框架来解决软体物体操纵中的动态和控制挑战，展现了其在提高仿真精确度和稳定性方面的潜力。"}}
{"id": "2602.02401", "pdf": "https://arxiv.org/pdf/2602.02401", "abs": "https://arxiv.org/abs/2602.02401", "authors": ["Xinshun Wang", "Peiming Li", "Ziyi Wang", "Zhongbin Fang", "Zhichao Deng", "Songtao Wu", "Jason Li", "Mengyuan Liu"], "title": "Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation", "categories": ["cs.CV"], "comment": null, "summary": "Human motion analysis tasks, such as temporal 3D pose estimation, motion prediction, and motion in-betweening, play an essential role in computer vision. However, current paradigms suffer from severe fragmentation. First, the field is split between ``perception'' models that understand motion from video but only output text, and ``generation'' models that cannot perceive from raw visual input. Second, generative MLLMs are often limited to single-frame, static poses using dense, parametric SMPL models, failing to handle temporal motion. Third, existing motion vocabularies are built from skeleton data alone, severing the link to the visual domain. To address these challenges, we introduce Superman, a unified framework that bridges visual perception with temporal, skeleton-based motion generation. Our solution is twofold. First, to overcome the modality disconnect, we propose a Vision-Guided Motion Tokenizer. Leveraging the natural geometric alignment between 3D skeletons and visual data, this module pioneers robust joint learning from both modalities, creating a unified, cross-modal motion vocabulary. Second, grounded in this motion language, a single, unified MLLM architecture is trained to handle all tasks. This module flexibly processes diverse, temporal inputs, unifying 3D skeleton pose estimation from video (perception) with skeleton-based motion prediction and in-betweening (generation). Extensive experiments on standard benchmarks, including Human3.6M, demonstrate that our unified method achieves state-of-the-art or competitive performance across all motion tasks. This showcases a more efficient and scalable path for generative motion analysis using skeletons.", "AI": {"tldr": "超级英雄（Superman）是一个统一的框架，旨在通过视觉感知与基于骨骼的时间运动生成相结合来解决人类动作分析任务中的挑战。", "motivation": "当前的人体运动分析方法面临三个主要问题：感知模型只能从视频中理解动作并输出文本，而不能处理原始视觉输入；生成模型局限于单一帧静态姿势的建模，无法有效处理时间性动作；现有的动作词汇表仅基于骨骼数据构建，与视觉域脱节。", "method": "为了解决这些问题，作者提出了一个统一框架Superman。该框架包含两个关键组件：视觉引导的动作标记器和单个统一的大语言模型架构。前者通过自然几何对齐实现了从视频和3D骨架姿势的联合学习，创建了一个统一的跨模态动作词汇表；后者则灵活处理各种时间输入，将基于视频的人体姿态估计（感知）与基于骨骼的时间运动生成任务结合起来。", "result": "在标准基准测试中，包括Human3.6M，该方法展示了优于现有方法或可比的表现。这证明了使用骨架进行生成性动作分析的有效性和可扩展性的统一路径。", "conclusion": "Superman框架通过解决当前人体运动分析中的模态分离和时间性问题，为高效、可扩展的生成式动作分析提供了一种新的方法论。"}}
{"id": "2602.02397", "pdf": "https://arxiv.org/pdf/2602.02397", "abs": "https://arxiv.org/abs/2602.02397", "authors": ["Ali Baigelenov", "Prakash Shukla", "Phuong Bui", "Paul Parsons"], "title": "Talking Inspiration: A Discourse Analysis of Data Visualization Podcasts", "categories": ["cs.HC"], "comment": "11 pages, In CHI Conference on Human Factors in Computing Systems (CHI26)", "summary": "Data visualization practitioners routinely invoke inspiration, yet we know little about how it is constructed in public conversations. We conduct a discourse analysis of 31 episodes from five popular data visualization podcasts. Podcasts are public-facing and inherently performative: guests manage impressions, articulate values, and model \"good practice\" for broad audiences. We use this performative setting to examine how legitimacy, identity, and practice are negotiated in community talk. We show that \"inspiration talk\" is operative rather than ornamental: speakers legitimize what counts, who counts, and how work proceeds. Our analysis surfaces four adjustable evaluation criteria by which inspiration is judged-novelty, authority, authenticity, and affect-and three operative metaphors that license different practices-spark, muscle, and resource bank. We argue that treating inspiration as a boundary object helps explain why these frames coexist across contexts. Findings provide a vocabulary for examining how inspiration is mobilized in visualization practice, with implications for evaluation, pedagogy, and the design of galleries and repositories that surface inspirational examples.", "AI": {"tldr": "数据可视化播客中的灵感构建研究", "motivation": "探讨数据可视化从业者如何在公共对话中建构和利用灵感，以及这一过程对身份、实践与合法性的影响。", "method": "采用话语分析法，分析了五档流行的数据可视化播客的31集内容。通过这些表演性设置来考察社区讨论中的合法化、身份认同及实践活动。", "result": "提出了评判灵感的四个可调整标准：新颖度、权威性、真实性与情感，并揭示了三种许可不同实践的操作隐喻：火花、肌肉和资源库。", "conclusion": "将灵感视为一种边界对象有助于解释这些框架如何在不同情境中并存，为探讨灵感如何被用于可视化实践中提供了词汇表。"}}
{"id": "2602.02396", "pdf": "https://arxiv.org/pdf/2602.02396", "abs": "https://arxiv.org/abs/2602.02396", "authors": ["Amisha Bhaskar", "Pratap Tokekar", "Stefano Di Cairano", "Alexander Schperberg"], "title": "PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning", "categories": ["cs.RO", "cs.LG"], "comment": "10 pages main text and 4 figures, and 11 pages appendix and 10 figures, total 21 pages and 14 figures", "summary": "Robotic imitation learning typically requires models that capture multimodal action distributions while operating at real-time control rates and accommodating multiple sensing modalities. Although recent generative approaches such as diffusion models, flow matching, and Implicit Maximum Likelihood Estimation (IMLE) have achieved promising results, they often satisfy only a subset of these requirements. To address this, we introduce PRISM, a single-pass policy based on a batch-global rejection-sampling variant of IMLE. PRISM couples a temporal multisensory encoder (integrating RGB, depth, tactile, audio, and proprioception) with a linear-attention generator using a Performer architecture. We demonstrate the efficacy of PRISM on a diverse real-world hardware suite, including loco-manipulation using a Unitree Go2 with a 7-DoF arm D1 and tabletop manipulation with a UR5 manipulator. Across challenging physical tasks such as pre-manipulation parking, high-precision insertion, and multi-object pick-and-place, PRISM outperforms state-of-the-art diffusion policies by 10-25% in success rate while maintaining high-frequency (30-50 Hz) closed-loop control. We further validate our approach on large-scale simulation benchmarks, including CALVIN, MetaWorld, and Robomimic. In CALVIN (10% data split), PRISM improves success rates by approximately 25% over diffusion and approximately 20% over flow matching, while simultaneously reducing trajectory jerk by 20x-50x. These results position PRISM as a fast, accurate, and multisensory imitation policy that retains multimodal action coverage without the latency of iterative sampling.", "AI": {"tldr": "PRISM是一种基于单次通过的策略，结合了批次全局拒绝采样的隐式最大似然估计(IMLE)，用于单一通路多感觉模仿学习。", "motivation": "现有的生成方法如扩散模型、流匹配和IMLE难以同时满足捕捉多重动作分布、实时控制速率以及适应多种感知模态的要求。PRISM旨在解决这些问题，提供一种快速准确且多感觉的模仿策略。", "method": "PRISM结合了时间多感官编码器与线性注意力生成器，使用Performer架构，并通过单一通路实现高效率的模仿学习。编码器整合RGB、深度、触觉、音频和本体感受信息；生成器基于IMLE并通过批次全局拒绝采样进行优化。", "result": "在实际硬件套件中的挑战任务中，PRISM成功率达到10-25%的提升，并能保持30-50Hz的闭环控制。在CALVIN等大规模仿真基准测试中也取得了显著的成功率提高和轨迹抖动减少。", "conclusion": "PRISM提供了一种高效、准确且多感觉的模仿学习策略，它能够在不牺牲动作多样性的情况下避免迭代采样的延迟，成为一种新的快速模仿学习方法。"}}
{"id": "2602.02395", "pdf": "https://arxiv.org/pdf/2602.02395", "abs": "https://arxiv.org/abs/2602.02395", "authors": ["Samuel Nellessen", "Tal Kachman"], "title": "David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MA"], "comment": "Under review. 8 main pages, 2 figures, 2 tables. Appendix included", "summary": "The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary \"tags along\" on the trusted privileges of a safety-aligned Operator to induce prohibited tool use through conversation alone. To validate this threat, we present Slingshot, a 'cold-start' reinforcement learning framework that autonomously discovers emergent attack vectors, revealing a critical insight: in our setting, learned attacks tend to converge to short, instruction-like syntactic patterns rather than multi-turn persuasion. On held-out extreme-difficulty tasks, Slingshot achieves a 67.0% success rate against a Qwen2.5-32B-Instruct-AWQ Operator (vs. 1.7% baseline), reducing the expected attempts to first success (on solved tasks) from 52.3 to 1.3. Crucially, Slingshot transfers zero-shot to several model families, including closed-source models like Gemini 2.5 Flash (56.0% attack success rate) and defensive-fine-tuned open-source models like Meta-SecAlign-8B (39.2% attack success rate). Our work establishes Tag-Along Attacks as a first-class, verifiable threat model and shows that effective agentic attacks can be elicited from off-the-shelf open-weight models through environment interaction alone.", "AI": {"tldr": "该论文提出并验证了通过强化学习框架Slingshot进行针对大型语言模型的Tag-Along攻击，这种攻击可以利用代理的安全权限诱导其执行禁止的操作。", "motivation": "随着大型语言模型演变为自主代理，出现了一系列安全问题。这些问题可以通过工具特权被滥用，进而引发主观性的自然语言处理评估转化为客观控制问题。为此，论文动机在于定义并验证一种新的威胁模型（Tag-Along攻击），这种攻击通过对话而非多轮说服来诱导禁止的操作。", "method": "作者设计了一种名为Slingshot的冷启动强化学习框架，用于自主发现新兴的攻击向量，并展示了该方法可以在不同难度的任务上有效执行。", "result": "在极端难度的任务中，Slingshot对Qwen2.5-32B-Instruct-AWQ代理的成功率为67.0%，相比于1.7%的基础线，显著提高。此外，这种方法能够零样本迁移到包括Gemini 2.5 Flash和Meta-SecAlign-8B在内的多种模型。", "conclusion": "论文展示了Tag-Along攻击作为一种可验证的威胁模型的重要性，并表明通过环境交互从现成的开放权重模型中可以有效地激发代理攻击。"}}
{"id": "2602.02393", "pdf": "https://arxiv.org/pdf/2602.02393", "abs": "https://arxiv.org/abs/2602.02393", "authors": ["Ruiqi Wu", "Xuanhua He", "Meng Cheng", "Tianyu Yang", "Yong Zhang", "Zhuoliang Kang", "Xunliang Cai", "Xiaoming Wei", "Chunle Guo", "Chongyi Li", "Ming-Ming Cheng"], "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 8 figures", "summary": "We propose Infinite-World, a robust interactive world model capable of maintaining coherent visual memory over 1000+ frames in complex real-world environments. While existing world models can be efficiently optimized on synthetic data with perfect ground-truth, they lack an effective training paradigm for real-world videos due to noisy pose estimations and the scarcity of viewpoint revisits. To bridge this gap, we first introduce a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation. By jointly optimizing the compressor with the generative backbone, HPMC enables the model to autonomously anchor generations in the distant past with bounded computational cost, eliminating the need for explicit geometric priors. Second, we propose an Uncertainty-aware Action Labeling module that discretizes continuous motion into a tri-state logic. This strategy maximizes the utilization of raw video data while shielding the deterministic action space from being corrupted by noisy trajectories, ensuring robust action-response learning. Furthermore, guided by insights from a pilot toy study, we employ a Revisit-Dense Finetuning Strategy using a compact, 30-minute dataset to efficiently activate the model's long-range loop-closure capabilities. Extensive experiments, including objective metrics and user studies, demonstrate that Infinite-World achieves superior performance in visual quality, action controllability, and spatial consistency.", "AI": {"tldr": "提出了一种名为Infinite-World的模型，能够处理复杂环境下的长期视觉记忆，并在长达1000帧的情况下保持一致性和精确性。", "motivation": "现有世界模型虽然可以利用合成数据进行有效优化，但在真实场景视频中难以适应由于姿态估计噪声和视角重复访问稀缺等问题导致的数据质量问题。", "method": "引入了基于层次化无姿态内存压缩器（HPMC）的框架以及不确定性感知的动作标签模块，并通过密集回访微调策略激活长期循环闭合功能。", "result": "实验表明，Infinite-World在视觉质量、动作可控制性和空间一致性方面均表现出色。", "conclusion": "提出的模型能够在长时间序列中保持良好的性能和鲁棒性。"}}
{"id": "2602.02389", "pdf": "https://arxiv.org/pdf/2602.02389", "abs": "https://arxiv.org/abs/2602.02389", "authors": ["Marina Ruediger", "Ashis G. Banerjee"], "title": "Mapping-Guided Task Discovery and Allocation for Robotic Inspection of Underwater Structures", "categories": ["cs.RO"], "comment": "This paper will appear in the proceedings of the 2026 IEEE International Conference on Robotics and Automation (ICRA)", "summary": "Task generation for underwater multi-robot inspections without prior knowledge of existing geometry can be achieved and optimized through examination of simultaneous localization and mapping (SLAM) data. By considering hardware parameters and environmental conditions, a set of tasks is generated from SLAM meshes and optimized through expected keypoint scores and distance-based pruning. In-water tests are used to demonstrate the effectiveness of the algorithm and determine the appropriate parameters. These results are compared to simulated Voronoi partitions and boustrophedon patterns for inspection coverage on a model of the test environment. The key benefits of the presented task discovery method include adaptability to unexpected geometry and distributions that maintain coverage while focusing on areas more likely to present defects or damage.", "AI": {"tldr": "基于SLAM数据生成和优化水下多机器人检查任务。", "motivation": "通过利用SLAM技术自动生成并优化没有先验几何知识的水下结构检查任务，提高效率。", "method": "从SLAM网格中生成任务并通过预期的关键点得分和距离剪枝进行优化。结合硬件参数和环境条件确定最佳参数，并与模拟的Voronoi划分和boustrophedon模式相比。", "result": "算法的有效性通过水下测试得到验证，展示了适应意外几何形状的能力并提高了覆盖质量。", "conclusion": "提出的方法能够灵活应对未知结构，优化检查任务分配以提高缺陷检测率。"}}
{"id": "2602.02388", "pdf": "https://arxiv.org/pdf/2602.02388", "abs": "https://arxiv.org/abs/2602.02388", "authors": ["Rajalaxmi Rajagopalan", "Debottam Dutta", "Yu-Lin Wei", "Romit Roy Choudhury"], "title": "Personalized Image Generation via Human-in-the-loop Bayesian Optimization", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Imagine Alice has a specific image $x^\\ast$ in her mind, say, the view of the street in which she grew up during her childhood. To generate that exact image, she guides a generative model with multiple rounds of prompting and arrives at an image $x^{p*}$. Although $x^{p*}$ is reasonably close to $x^\\ast$, Alice finds it difficult to close that gap using language prompts. This paper aims to narrow this gap by observing that even after language has reached its limits, humans can still tell when a new image $x^+$ is closer to $x^\\ast$ than $x^{p*}$. Leveraging this observation, we develop MultiBO (Multi-Choice Preferential Bayesian Optimization) that carefully generates $K$ new images as a function of $x^{p*}$, gets preferential feedback from the user, uses the feedback to guide the diffusion model, and ultimately generates a new set of $K$ images. We show that within $B$ rounds of user feedback, it is possible to arrive much closer to $x^\\ast$, even though the generative model has no information about $x^\\ast$. Qualitative scores from $30$ users, combined with quantitative metrics compared across $5$ baselines, show promising results, suggesting that multi-choice feedback from humans can be effectively harnessed for personalized image generation.", "AI": {"tldr": "通过人机交互的贝叶斯优化方法，实现个性化图像生成。", "motivation": "解决现有语言提示难以精确生成用户心中特定图像的问题，利用人类反馈来提高图像生成精度。", "method": "开发MultiBO（多选项偏好贝叶斯优化），生成多个新图像供用户选择偏好，并用该反馈指导扩散模型以逐步逼近目标图像。", "result": "通过30个用户的定性评分和与5种基准方法的定量比较，证明了这种方法的有效性。", "conclusion": "人类提供的多选偏好反馈能有效用于个性化图像生成。"}}
{"id": "2602.02386", "pdf": "https://arxiv.org/pdf/2602.02386", "abs": "https://arxiv.org/abs/2602.02386", "authors": ["Mika Okamoto", "Ansel Kaplan Erol", "Glenn Matlin"], "title": "Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing", "categories": ["cs.AI", "cs.IR", "cs.LG"], "comment": "Appeared at MLSys YPS 2025", "summary": "How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requires and whether a cheaper model could suffice. BELLA addresses this gap through three stages: (1) decomposing LLM outputs and extract the granular skills required by using critic-based profiling, (2) clustering skills into structured capability matrices, and (3) multi-objective optimization to select the right models to maximize performance while respecting budget constraints. BELLA provides natural-language rationale for recommendations, providing transparency that current black-box routing systems lack. We describe the framework architecture, situate it within the landscape of LLM routing and evaluation, and discuss its application to financial reasoning as a representative domain exhibiting diverse skill requirements and cost-variation across models. Our framework enables practitioners to make principled and cost-performance trade-offs for deploying LLMs.", "AI": {"tldr": "BELLA是一个框架，它通过基于技能的模型选择推荐任务的最佳大语言模型。", "motivation": "为了解决传统基准测试无法准确报告特定任务所需的具体能力和是否可以使用更便宜的模型的问题，提出了一个能够透明且成本敏感地选择合适的大语言模型的方法。", "method": "BELLA框架通过三个阶段实现其功能：(1) 使用基于批评的分析来分解大语言模型的输出并提取所需的技能；(2) 将这些技能聚合成结构化的能力矩阵；(3) 进行多目标优化，选择能够在性能最大化的同时满足预算要求的最佳模型。", "result": "BELLA框架能够为任务推荐最佳的大语言模型，并提供自然语言解释以提高透明度。它在财务推理等具有多样化技能需求和成本差异的应用场景中展示了其有效性。", "conclusion": "通过这种基于技能的模型选择方法，大语言模型实践者可以做出有原则的成本性能权衡决策，在部署过程中最大化效益。"}}
{"id": "2602.02380", "pdf": "https://arxiv.org/pdf/2602.02380", "abs": "https://arxiv.org/abs/2602.02380", "authors": ["Yibin Wang", "Yuhang Zang", "Feng Han", "Jiazi Bu", "Yujie Zhou", "Cheng Jin", "Jiaqi Wang"], "title": "Unified Personalized Reward Model for Vision Generation", "categories": ["cs.CV"], "comment": "Website: https://codegoat24.github.io/UnifiedReward/flex", "summary": "Recent advancements in multimodal reward models (RMs) have significantly propelled the development of visual generation. Existing frameworks typically adopt Bradley-Terry-style preference modeling or leverage generative VLMs as judges, and subsequently optimize visual generation models via reinforcement learning. However, current RMs suffer from inherent limitations: they often follow a one-size-fits-all paradigm that assumes a monolithic preference distribution or relies on fixed evaluation rubrics. As a result, they are insensitive to content-specific visual cues, leading to systematic misalignment with subjective and context-dependent human preferences. To this end, inspired by human assessment, we propose UnifiedReward-Flex, a unified personalized reward model for vision generation that couples reward modeling with flexible and context-adaptive reasoning. Specifically, given a prompt and the generated visual content, it first interprets the semantic intent and grounds on visual evidence, then dynamically constructs a hierarchical assessment by instantiating fine-grained criteria under both predefined and self-generated high-level dimensions. Our training pipeline follows a two-stage process: (1) we first distill structured, high-quality reasoning traces from advanced closed-source VLMs to bootstrap SFT, equipping the model with flexible and context-adaptive reasoning behaviors; (2) we then perform direct preference optimization (DPO) on carefully curated preference pairs to further strengthen reasoning fidelity and discriminative alignment. To validate the effectiveness, we integrate UnifiedReward-Flex into the GRPO framework for image and video synthesis, and extensive results demonstrate its superiority.", "AI": {"tldr": "本文提出了一种统一的个性化奖励模型UnifiedReward-Flex，用于视觉生成任务。", "motivation": "现有的多模态奖励模型通常采用固定评估准则或单一偏好建模方式，无法灵活应对内容特定的视觉线索和主观、上下文相关的用户偏好。", "method": "通过引入灵活且上下文自适应推理能力，结合语义意图分析与视觉证据验证，并依据预设及自生成维度动态构建分层评估标准。训练过程分为两阶段：第一阶段从高级封闭源VLM中提炼结构化、高质量的推理痕迹以实现指令调整；第二阶段通过精心挑选的偏好对进行直接偏好优化，提升推理准确性和区分度。", "result": "实验结果表明，将UnifiedReward-Flex集成到GRPO框架后，在图像和视频合成任务上表现出显著优越性。", "conclusion": "所提出的UnifiedReward-Flex模型克服了现有奖励模型的局限性，能够更精准地捕捉视觉生成中的主观偏好与上下文依赖关系。"}}
{"id": "2602.02378", "pdf": "https://arxiv.org/pdf/2602.02378", "abs": "https://arxiv.org/abs/2602.02378", "authors": ["Raunak Jain", "Mudita Khurana", "John Stephens", "Srinivas Dharmasanam", "Shankar Venkataraman"], "title": "From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As LLMs expand from assistance to decision support, a dangerous pattern emerges: fluent agreement without calibrated judgment. Low-friction assistants can become sycophantic, baking in implicit assumptions and pushing verification costs onto experts, while outcomes arrive too late to serve as reward signals. In deep-uncertainty decisions (where objectives are contested and reversals are costly), scaling fluent agreement amplifies poor commitments faster than it builds expertise. We argue reliable human-AI partnership requires a shift from answer generation to collaborative premise governance over a knowledge substrate, negotiating only what is decision-critical. A discrepancy-driven control loop operates over this substrate: detecting conflicts, localizing misalignment via typed discrepancies (teleological, epistemic, procedural), and triggering bounded negotiation through decision slices. Commitment gating blocks action on uncommitted load-bearing premises unless overridden under logged risk; value-gated challenge allocates probing under interaction cost. Trust then attaches to auditable premises and evidence standards, not conversational fluency. We illustrate with tutoring and propose falsifiable evaluation criteria.", "AI": {"tldr": "本文提出了一种新的合作模式，即通过前提治理来促进人类与AI之间在决策支持中的可靠伙伴关系。", "motivation": "随着大型语言模型从辅助工具扩展到决策支持，在低摩擦环境下，这些助手可能变得阿谀奉承，导致专家不得不承担更多的验证成本。此外，这种模式还可能导致快速放大不良承诺而不是建立专业知识。因此，需要一种新的方法来促进更可靠的决策。", "method": "作者建议将人类与AI的合作从生成答案转变为在知识层面上进行前提治理，在此过程中只讨论对决定至关重要的内容。他们引入了一个基于差异的控制循环：检测冲突、通过类型化差异（目的性、知识性和程序性）定位失调，并通过决策切片触发有界谈判。", "result": "该方法通过承诺门控阻止在未经审计的前提上采取行动，除非风险被记录和接受；价值限制挑战则根据交互成本分配审查。最终建立信任基于可验证的前提和证据标准，而不是对话流畅度。", "conclusion": "作者提出了一种新的决策支持合作模式，并提供了教学案例以展示其应用，同时提出了可以进行检验的评估准则来衡量该方法的有效性。"}}
{"id": "2602.02375", "pdf": "https://arxiv.org/pdf/2602.02375", "abs": "https://arxiv.org/abs/2602.02375", "authors": ["Julian Berger", "Pantelis P. Analytis", "Frederik Andersen", "Kristian P. Lorenzen", "Ville Satopää", "Ralf HJM Kurvers"], "title": "The hybrid confirmation tree: A robust strategy for hybrid intelligence", "categories": ["cs.HC"], "comment": null, "summary": "Combining human and artificial intelligence (AI) is a potentially powerful approach to boost decision accuracy. However, few such approaches exist that effectively integrate both types of intelligence while maintaining human agency. Here, we introduce and evaluate the hybrid confirmation tree, a simple aggregation strategy that compares the independent decisions of both a human and AI, with disagreements triggering a second human tiebreaker. Through analytical derivations, we show that the hybrid confirmation tree can match and exceed the accuracy of a three-person human majority vote while requiring fewer human inputs, particularly when AI accuracy is comparable to or exceeds human accuracy. We analytically demonstrate that the hybrid confirmation tree's ability to achieve complementarity -- outperforming individual humans, AI, and the majority vote -- is maximized when human and AI accuracies are similar and their decisions are not overly correlated. Empirical reanalysis of six real-world datasets (covering skin cancer diagnosis, deepfake detection, geopolitical forecasting, and criminal rearrest) validates these findings, showing that the hybrid confirmation tree improves accuracy over the majority vote by up to 10 percentage points while reducing the cost of decision making by 28--44$\\%$. Furthermore, the hybrid confirmation tree provides greater flexibility in navigating true and false positive trade-offs compared to fixed human-only heuristics like hierarchies and polyarchies. The hybrid confirmation tree emerges as a practical, efficient, and robust strategy for hybrid collective intelligence that maintains human agency.", "AI": {"tldr": "介绍并评估了一种结合人类和人工智能决策的策略——混合确认树，以提高决策准确性。", "motivation": "为了有效整合人类与人工智能（AI）的智能，并保持人的主导地位，提出一种新的混合决策方法。", "method": "通过理论推导展示该方法在AI准确率接近或超过人类时能匹配甚至超越三人多数票制。利用六个真实世界数据集验证其效能，涵盖皮肤癌诊断、深度伪造检测、地缘政治预测和犯罪再犯等场景。", "result": "混合确认树将决策准确性提高最多达10个百分点，并降低决策成本28-44%；它在处理真阳性和假阳性权衡时也表现出更高的灵活性。", "conclusion": "混合确认树作为一种实用、高效且稳健的混合集体智能策略，能够维护人的主导地位。"}}
{"id": "2602.02370", "pdf": "https://arxiv.org/pdf/2602.02370", "abs": "https://arxiv.org/abs/2602.02370", "authors": ["Uma Meleti", "Jeffrey J. Nirschl"], "title": "Uncertainty-Aware Image Classification In Biomedical Imaging Using Spectral-normalized Neural Gaussian Processes", "categories": ["cs.CV"], "comment": "Accepted for publication at the IEEE International Symposium on Biomedical Imaging (ISBI) 2026", "summary": "Accurate histopathologic interpretation is key for clinical decision-making; however, current deep learning models for digital pathology are often overconfident and poorly calibrated in out-of-distribution (OOD) settings, which limit trust and clinical adoption. Safety-critical medical imaging workflows benefit from intrinsic uncertainty-aware properties that can accurately reject OOD input. We implement the Spectral-normalized Neural Gaussian Process (SNGP), a set of lightweight modifications that apply spectral normalization and replace the final dense layer with a Gaussian process layer to improve single-model uncertainty estimation and OOD detection. We evaluate SNGP vs. deterministic and MonteCarlo dropout on six datasets across three biomedical classification tasks: white blood cells, amyloid plaques, and colorectal histopathology. SNGP has comparable in-distribution performance while significantly improving uncertainty estimation and OOD detection. Thus, SNGP or related models offer a useful framework for uncertainty-aware classification in digital pathology, supporting safe deployment and building trust with pathologists.", "AI": {"tldr": "论文主要任务是通过改进的Spectral-normalized Neural Gaussian Process (SNGP)模型来提高数字病理学中的不确定性估计和OOD检测性能。", "motivation": "当前深度学习模型在数字病理图像分类中表现出过度自信且难以处理OOD情况，影响了临床应用的信任度。因此需要引入具有内在不确定性和OOD检测能力的框架。", "method": "通过谱归一化和将最终密集层替换为高斯过程层来实现SNGP方法，并在此基础上进行单模型不确定性估计和OOD检测。", "result": "与确定性模型和MonteCarlo dropout相比，SNGP在多个生物医学分类任务中的OOD性能显著提高，同时保持了类似的in-distribution性能。", "conclusion": "SNGP或相关方法为数字病理学中不确定性感知的分类提供了一个有用的框架，支持安全部署并增强与病理学家的信任。"}}
{"id": "2602.02369", "pdf": "https://arxiv.org/pdf/2602.02369", "abs": "https://arxiv.org/abs/2602.02369", "authors": ["Yaolun Zhang", "Yiran Wu", "Yijiong Yu", "Qingyun Wu", "Huazheng Wang"], "title": "Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback", "categories": ["cs.AI", "cs.LG"], "comment": "13 pages", "summary": "Large language model (LLM) agents are increasingly equipped with memory, which are stored experience and reusable guidance that can improve task-solving performance. Recent \\emph{self-evolving} systems update memory based on interaction outcomes, but most existing evolution pipelines are developed for static train/test splits and only approximate online learning by folding static benchmarks, making them brittle under true distribution shift and continuous feedback. We introduce \\textsc{Live-Evo}, an online self-evolving memory system that learns from a stream of incoming data over time. \\textsc{Live-Evo} decouples \\emph{what happened} from \\emph{how to use it} via an Experience Bank and a Meta-Guideline Bank, compiling task-adaptive guidelines from retrieved experiences for each task. To manage memory online, \\textsc{Live-Evo} maintains experience weights and updates them from feedback: experiences that consistently help are reinforced and retrieved more often, while misleading or stale experiences are down-weighted and gradually forgotten, analogous to reinforcement and decay in human memory. On the live \\textit{Prophet Arena} benchmark over a 10-week horizon, \\textsc{Live-Evo} improves Brier score by 20.8\\% and increases market returns by 12.9\\%, while also transferring to deep-research benchmarks with consistent gains over strong baselines. Our code is available at https://github.com/ag2ai/Live-Evo.", "AI": {"tldr": "本文提出了一种名为Live-Evo的在线自进化记忆系统，该系统能够从连续的数据流中学习并适应环境变化。", "motivation": "现有的自我演化系统大多基于静态训练集和测试集设计，并不能很好地应对真正的分布偏移问题。因此，作者提出了一个可以在线更新的记忆系统来解决这一挑战。", "method": "Live-Evo通过经验库（Experience Bank）和元指导库（Meta-Guideline Bank）将“发生了什么”与“如何使用它”分离，实时地从新数据中提取任务适应性指南。同时，利用反馈机制调整记忆中的经验权重：有用的被加强，而误导或过时的经验则逐渐遗忘。", "result": "在长达10周的Prophet Arena基准测试中，Live-Evo系统将Brier评分提高了20.8%，市场收益增加了12.9%。此外，在深度研究基准上也表现出比其他基线更好的性能。", "conclusion": "本文提出的在线自进化记忆机制能够有效地从连续反馈中学到有价值的信息，并能适应不断变化的环境，从而提高任务完成效率和质量"}}
{"id": "2602.02366", "pdf": "https://arxiv.org/pdf/2602.02366", "abs": "https://arxiv.org/abs/2602.02366", "authors": ["Sharut Gupta", "Phillip Isola", "Stefanie Jegelka", "David Lopez-Paz", "Kartik Ahuja", "Mark Ibrahim", "Mohammad Pezeshki"], "title": "ReasonCACHE: Teaching LLMs To Reason Without Weight Updates", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 17 Figures", "summary": "Can Large language models (LLMs) learn to reason without any weight update and only through in-context learning (ICL)? ICL is strikingly sample-efficient, often learning from only a handful of demonstrations, but complex reasoning tasks typically demand many training examples to learn from. However, naively scaling ICL by adding more demonstrations breaks down at this scale: attention costs grow quadratically, performance saturates or degrades with longer contexts, and the approach remains a shallow form of learning. Due to these limitations, practitioners predominantly rely on in-weight learning (IWL) to induce reasoning. In this work, we show that by using Prefix Tuning, LLMs can learn to reason without overloading the context window and without any weight updates. We introduce $\\textbf{ReasonCACHE}$, an instantiation of this mechanism that distills demonstrations into a fixed key-value cache. Empirically, across challenging reasoning benchmarks, including GPQA-Diamond, ReasonCACHE outperforms standard ICL and matches or surpasses IWL approaches. Further, it achieves this all while being more efficient across three key axes: data, inference cost, and trainable parameters. We also theoretically prove that ReasonCACHE can be strictly more expressive than low-rank weight update since the latter ties expressivity to input rank, whereas ReasonCACHE bypasses this constraint by directly injecting key-values into the attention mechanism. Together, our findings identify ReasonCACHE as a middle path between in-context and in-weight learning, providing a scalable algorithm for learning reasoning skills beyond the context window without modifying parameters. Our project page: https://reasoncache.github.io/", "AI": {"tldr": "研究提出了ReasonCACHE，一种通过固定键值缓存来教授大型语言模型（LLM）进行推理的方法，无需任何权重更新。", "motivation": "尽管示例效率高，但在复杂任务中仅靠示例学习往往需要大量训练样本。然而，在此规模下增加演示会带来注意力成本的二次增长、性能饱和或降级等问题。因此，实践中通常依赖于权重更新进行推理。", "method": "通过使用前缀调优技术，LLM可以通过固定键值缓存来学习推理任务而无需超载上下文窗口和权重更新。", "result": "在挑战性的推理基准上，ReasonCACHE不仅优于标准的示例学习方法，并且与基于权重的学习方法相比能匹配或超过其性能。同时，它在数据、推理成本和可训练参数方面都更高效。", "conclusion": "研究展示了ReasonCACHE作为示例学习和基于权重学习之间的中间路径，提供了一种不修改参数即可超越上下文窗口限制的规模化算法来提升推理能力。"}}
{"id": "2602.02361", "pdf": "https://arxiv.org/pdf/2602.02361", "abs": "https://arxiv.org/abs/2602.02361", "authors": ["Mouxiang Chen", "Lei Zhang", "Yunlong Feng", "Xuwu Wang", "Wenting Zhao", "Ruisheng Cao", "Jiaxi Yang", "Jiawei Chen", "Mingze Li", "Zeyao Ma", "Hao Ge", "Zongmeng Zhang", "Zeyu Cui", "Dayiheng Liu", "Jingren Zhou", "Jianling Sun", "Junyang Lin", "Binyuan Hui"], "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions", "categories": ["cs.SE", "cs.AI"], "comment": "13 pages", "summary": "We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents.", "AI": {"tldr": "构建大规模的真实世界软件工程验证环境", "motivation": "解决自动构建过程中低产出、弱验证器和高昂成本的问题，提高生成高质量可验证任务的可靠性", "method": "利用自训练模型驱动的构建代理，结合迭代自我验证与循环内检测机制，实现高效且可靠的高保真度任务生成", "result": "创建了超过一百万的大规模多语言SWE环境，并在SWE-Bench Verified测试中取得了75.3%的成绩", "conclusion": "提出了一种可扩展的框架以解决大规模真实世界软件工程验证环境的问题，提供了宝贵的资源和稳健的方法来推动下一代编码代理的发展"}}
{"id": "2602.02356", "pdf": "https://arxiv.org/pdf/2602.02356", "abs": "https://arxiv.org/abs/2602.02356", "authors": ["Wangduo Xie", "Matthew B. Blaschko"], "title": "NAB: Neural Adaptive Binning for Sparse-View CT reconstruction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Computed Tomography (CT) plays a vital role in inspecting the internal structures of industrial objects. Furthermore, achieving high-quality CT reconstruction from sparse views is essential for reducing production costs. While classic implicit neural networks have shown promising results for sparse reconstruction, they are unable to leverage shape priors of objects. Motivated by the observation that numerous industrial objects exhibit rectangular structures, we propose a novel \\textbf{N}eural \\textbf{A}daptive \\textbf{B}inning (\\textbf{NAB}) method that effectively integrates rectangular priors into the reconstruction process. Specifically, our approach first maps coordinate space into a binned vector space. This mapping relies on an innovative binning mechanism based on differences between shifted hyperbolic tangent functions, with our extension enabling rotations around the input-plane normal vector. The resulting representations are then processed by a neural network to predict CT attenuation coefficients. This design enables end-to-end optimization of the encoding parameters -- including position, size, steepness, and rotation -- via gradient flow from the projection data, thus enhancing reconstruction accuracy. By adjusting the smoothness of the binning function, NAB can generalize to objects with more complex geometries. This research provides a new perspective on integrating shape priors into neural network-based reconstruction. Extensive experiments demonstrate that NAB achieves superior performance on two industrial datasets. It also maintains robust on medical datasets when the binning function is extended to more general expression. The code will be made available.", "AI": {"tldr": "提出了一种名为NAB的神经自适应分箱方法，用于稀疏视图CT重建。", "motivation": "经典隐式神经网络在稀疏CT重建中表现出色，但无法利用物体形状先验知识。工业对象通常呈矩形结构，因此提出了结合形状先验的新方法以提高重建质量。", "method": "NAB首先将坐标空间映射到分箱向量空间，然后通过基于双曲正切函数差的创新分箱机制处理这些表示，并使用神经网络预测CT衰减系数。优化编码参数（包括位置、尺寸、陡度和旋转）以实现端到端训练。", "result": "实验结果表明NAB在两个工业数据集上表现优越，对医学数据集也具有鲁棒性。", "conclusion": "NAB提供了一种新的方法，将形状先验知识与基于神经网络的重建相结合，并取得了显著成果。"}}
{"id": "2602.02354", "pdf": "https://arxiv.org/pdf/2602.02354", "abs": "https://arxiv.org/abs/2602.02354", "authors": ["Albert Kwok", "Zheyuan Hu", "Dounia Hammou"], "title": "Implicit neural representation of textures", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "comment": "Albert Kwok and Zheyuan Hu contributed equally to this work", "summary": "Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with considerable memory usage and rendering inference time. We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation.", "AI": {"tldr": "本文探讨了在连续的输入UV坐标空间中设计不同神经网络作为新的纹理隐式神经表示（INR）的方法，通过实验展示了这种方法在图像质量、内存使用和渲染推理时间上的优良表现，并研究了其在实时渲染和其他下游任务中的应用。", "motivation": "利用隐式神经表示技术来提升纹理处理的准确性和效率，特别是在连续空间中进行操作以改进传统离散方法的局限性。", "method": "设计不同的神经网络作为新的纹理INR，在输入UV坐标空间上实现连续操作。通过实验评估其性能，并研究其在实时渲染和其他下游任务中的应用。", "result": "这些新设计的INRs在图像质量方面表现良好，同时实现了可接受的记忆使用量和渲染推理时间。该方法还适用于诸如mipmap拟合等下游任务。", "conclusion": "本文展示了利用隐式神经表示技术实现高效且高质量的纹理处理能力，并探讨了其广泛的应用潜力，特别是在实时图形学和其他依赖于连续空间操作的任务中。"}}
{"id": "2602.02351", "pdf": "https://arxiv.org/pdf/2602.02351", "abs": "https://arxiv.org/abs/2602.02351", "authors": ["Veronica Sanz"], "title": "Artificial Intelligence and Symmetries: Learning, Encoding, and Discovering Structure in Physical Data", "categories": ["hep-ph", "cs.AI", "cs.LG"], "comment": "25 pages, 9 figures. This manuscript is an invited review at the International Journal of Modern Physics A", "summary": "Symmetries play a central role in physics, organizing dynamics, constraining interactions, and determining the effective number of physical degrees of freedom. In parallel, modern artificial intelligence methods have demonstrated a remarkable ability to extract low-dimensional structure from high-dimensional data through representation learning. This review examines the interplay between these two perspectives, focusing on the extent to which symmetry-induced constraints can be identified, encoded, or diagnosed using machine learning techniques. Rather than emphasizing architectures that enforce known symmetries by construction, we concentrate on data-driven approaches and latent representation learning, with particular attention to variational autoencoders. We discuss how symmetries and conservation laws reduce the intrinsic dimensionality of physical datasets, and how this reduction may manifest itself through self-organization of latent spaces in generative models trained to balance reconstruction and compression. We review recent results, including case studies from simple geometric systems and particle physics processes, and analyze the theoretical and practical limitations of inferring symmetry structure without explicit inductive bias.", "AI": {"tldr": "这篇论文探讨了人工智能技术如何通过机器学习方法识别、编码和发现物理数据中的对称性结构。", "motivation": "本文旨在探索现代人工智能在提取物理数据低维度结构上的能力，特别是在利用数据驱动的方法来理解和应用物理系统的对称性和守恒定律方面的作用。", "method": "论文集中讨论了变分自动编码器（VAE）等生成模型如何通过平衡重建和压缩，在潜在空间中表现出自组织现象，并借此推断出隐藏的对称性结构。", "result": "论文回顾了一些案例研究，包括简单几何系统和粒子物理过程中的结果。这些结果显示了在没有显式归纳偏置的情况下识别对称性的理论和实践限制。", "conclusion": "通过机器学习技术可以在某种程度上揭示物理数据中隐藏的对称性结构，但其效果受到多种因素制约，并非总是理想化地实现。"}}
{"id": "2602.02350", "pdf": "https://arxiv.org/pdf/2602.02350", "abs": "https://arxiv.org/abs/2602.02350", "authors": ["Xingyuan Hua", "Sheng Yue", "Xinyi Li", "Yizhe Zhao", "Jinrui Zhang", "Ju Ren"], "title": "Context Learning for Multi-Agent Discussion", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency.", "AI": {"tldr": "提出一种多LLM上下文学习方法（M2CL），以解决多智能体讨论中的上下文一致性问题，使多个LLM能够通过结构化对话协作解决问题。", "motivation": "当前的多代理讨论（MAD）方法容易出现讨论不一致的问题，导致LLMs无法达成共识解决方案。主要原因是每个代理的个体上下文之间存在偏差和对齐问题。", "method": "提出一种动态生成上下文指令的方法，通过自动的信息组织与优化，以及一个精心设计的自适应机制来控制上下文的一致性和输出差异。", "result": "实验结果表明，在学术推理、具身任务和移动控制等挑战性任务上，M2CL的表现优于现有方法20%-50%，并且具有良好的泛化能力和计算效率。", "conclusion": "多LLM上下文学习（M2CL）能够有效解决多代理讨论中的上下文一致性问题，并提高整体性能。"}}
{"id": "2602.02343", "pdf": "https://arxiv.org/pdf/2602.02343", "abs": "https://arxiv.org/abs/2602.02343", "authors": ["Ziwen Xu", "Chenyan Wu", "Hengyu Sun", "Haiwen Hong", "Mengru Wang", "Yunzhi Yao", "Longtao Huang", "Hui Xue", "Shumin Deng", "Zhixuan Chu", "Huajun Chen", "Ningyu Zhang"], "title": "Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "comment": "Work in progress", "summary": "Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md.", "AI": {"tldr": "本文提出了一个统一的方法来理解语言模型参数的动态变化，旨在通过控制信号将不同的干预方法统一在一个框架内。", "motivation": "当前对于大型语言模型（LLMs）的各种控制方法如局部权重微调、LoRA适应和激活干预等研究是孤立进行的，这导致了这些方法之间的联系被忽略，比较困难。本文提出了一种统一视角来解决这一问题。", "method": "通过引入一种基于偏好的分析框架，该框架将控制效果分为偏好（倾向于目标概念）与效用（生成任务有效的程度），并使用极性配对对比示例在共享的对数几率尺度上测量两者。此外，还从激活流形的角度解释了这种行为。", "result": "观察到一个一致的权衡：更强的控制增加了偏好但降低了效用。新提出的SPLIT方法可以提高偏好的同时更好地保留效用。", "conclusion": "本文通过统一视角和分析框架成功展示了不同语言模型干预方法之间的联系，以及它们如何在激活流形上影响生成任务的有效性。"}}
{"id": "2602.02341", "pdf": "https://arxiv.org/pdf/2602.02341", "abs": "https://arxiv.org/abs/2602.02341", "authors": ["Zhenpeng Huang", "Jiaqi Li", "Zihan Jia", "Xinhao Li", "Desen Meng", "Lingxue Song", "Xi Chen", "Liang Li", "Limin Wang"], "title": "LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization", "categories": ["cs.CV"], "comment": "NeurIPS 2025", "summary": "We present LongVPO, a novel two-stage Direct Preference Optimization framework that enables short-context vision-language models to robustly understand ultra-long videos without any long-video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual-similarity and question-specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model's scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata, then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, LongVPO outperforms the state-of-the-art open-source models on multiple long-video benchmarks, while maintaining strong short-video performance (e.g., on MVBench), offering a scalable paradigm for efficient long-form video understanding.", "AI": {"tldr": "该论文提出了一种针对长视频的直接偏好优化框架LongVPO，通过合成偏好三元组和递归生成场景级元数据来提升模型理解能力。", "motivation": "短上下文视觉语言模型难以理解超长视频，且缺乏有效的长期标注。因此，本文旨在开发一种无须长时间标注的方法来改进对长视频的理解。", "method": "该方法分为两阶段：第一阶段通过合成偏好三元组并使用过滤技术减少位置偏差；第二阶段利用递归生成的场景级元数据和多段推理任务优化模型偏好。", "result": "LongVPO在多个长视频基准测试中超越了现有的开源模型，同时保持了短视频性能的优势。", "conclusion": "LongVPO提供了一种可扩展的方法来实现高效的长期形式视频理解，并且仅需少量合成示例和无需人工标签。"}}
{"id": "2602.02338", "pdf": "https://arxiv.org/pdf/2602.02338", "abs": "https://arxiv.org/abs/2602.02338", "authors": ["Yu Liang", "Zhongjin Zhang", "Yuxuan Zhu", "Kerui Zhang", "Zhiluohan Guo", "Wenhang Zhou", "Zonqi Yang", "Kangle Wu", "Yabo Ni", "Anxiang Zeng", "Cong Fu", "Jianxin Wang", "Jiazhi Xia"], "title": "Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems, but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction, and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling. To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability, without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID.", "AI": {"tldr": "本文提出了一种新的SID框架ReSID，用于改进推荐系统的序列预测性能。", "motivation": "现有的基于语义ID的推荐方法存在与协同过滤目标不匹配和通用量化方案效率低下的问题。作者旨在设计一个无需依赖大规模语言模型的原生推荐系统框架，以提高序列预测精度并减少量化成本。", "method": "ReSID由两部分组成：Field-Aware Masked Auto-Encoding（FAMAE）用于从结构化特征中学习预测性足够强的商品表示；Globally Aligned Orthogonal Quantization（GAOQ）通过联合降低语义模糊性和条件前缀不确定性来生成紧凑且可预测的SID序列。", "result": "实验表明，ReSID在十组数据集上均超过了现有的序列推荐和基于SID的生成基线模型，并减少了122倍以上的量化成本。", "conclusion": "本文提出的方法有效地提高了推荐系统的性能并显著降低了计算资源需求，展示了其优越性。"}}
{"id": "2602.02335", "pdf": "https://arxiv.org/pdf/2602.02335", "abs": "https://arxiv.org/abs/2602.02335", "authors": ["Weiming Sheng", "Jinlang Wang", "Manuel Barros", "Aldrin Montana", "Jacopo Tagliabue", "Luca Bigon"], "title": "Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents", "categories": ["cs.DC", "cs.AI", "cs.DB"], "comment": "Pre-print (PaPoC 2026)", "summary": "Lakehouses are the default cloud platform for analytics and AI, but they become unsafe when untrusted actors concurrently operate on production data: upstream-downstream mismatches surface only at runtime, and multi-table pipelines can leak partial effects. Inspired by software engineering, we design Bauplan, a code-first lakehouse that aims to make (most) illegal states unrepresentable using familiar abstractions. Bauplan acts along three axes: typed table contracts to make pipeline boundaries checkable, Git-like data versioning for review and reproducibility, and transactional runs that guarantee pipeline-level atomicity. We report early results from a lightweight formal transaction model and discuss future work motivated by counterexamples.", "AI": {"tldr": "构建一个正确设计的湖仓系统，通过类型化表合约、版本控制和事务管道提高安全性。", "motivation": "当前的湖仓系统在多个未信任参与者同时操作生产数据时存在安全隐患。上游和下游之间的不匹配问题仅在运行时才会显现，多表流水线可能会泄漏部分效果。", "method": "受软件工程启发，设计了Bauplan代码优先湖仓系统，使用熟悉的抽象使得非法状态无法表示。通过类型化表合约、类似Git的数据版本控制以及事务性执行来实现。", "result": "报告了一个轻量级正式事务模型的早期结果，并讨论了未来的工作动机和反例。", "conclusion": "提出了一种新的湖仓系统设计，能够更好地确保数据操作的安全性和一致性。"}}
{"id": "2602.02334", "pdf": "https://arxiv.org/pdf/2602.02334", "abs": "https://arxiv.org/abs/2602.02334", "authors": ["Fatemeh Zargarbashi", "Dhruv Agrawal", "Jakob Buhmann", "Martin Guay", "Stelian Coros", "Robert W. Sumner"], "title": "VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Human motion data is inherently rich and complex, containing both semantic content and subtle stylistic features that are challenging to model. We propose a novel method for effective disentanglement of the style and content in human motion data to facilitate style transfer. Our approach is guided by the insight that content corresponds to coarse motion attributes while style captures the finer, expressive details. To model this hierarchy, we employ Residual Vector Quantized Variational Autoencoders (RVQ-VAEs) to learn a coarse-to-fine representation of motion. We further enhance the disentanglement by integrating contrastive learning and a novel information leakage loss with codebook learning to organize the content and the style across different codebooks. We harness this disentangled representation using our simple and effective inference-time technique Quantized Code Swapping, which enables motion style transfer without requiring any fine-tuning for unseen styles. Our framework demonstrates strong versatility across multiple inference applications, including style transfer, style removal, and motion blending.", "AI": {"tldr": "提出一种新型方法，利用残差量化表示来有效分离人体运动数据中的风格和内容，以促进风格转移。", "motivation": "人类运动数据既包含语义内容又包含细微的风格特征，这些都难以建模。该论文旨在通过分离风格和内容来实现有效的风格迁移。", "method": "采用残差向量量化变分自动编码器（RVQ-VAE）来学习从粗到细的运动表示，并结合对比学习和信息泄露损失以及代码本学习，组织不同代码本中的内容和风格。利用这种方法，在推理时间使用量化码替换技术进行无须微调的风格迁移。", "result": "该框架在多样的应用中显示出了强大的灵活性，包括风格转移、风格去除和运动融合。", "conclusion": "通过残差量化的表示方法以及创新的信息泄漏损失设计，能够有效地分离人类动作中的风格和内容，并实现高效的风格转换。"}}
{"id": "2602.02331", "pdf": "https://arxiv.org/pdf/2602.02331", "abs": "https://arxiv.org/abs/2602.02331", "authors": ["Shaoting Zhu", "Baijun Ye", "Jiaxuan Wang", "Jiakang Chen", "Ziwen Zhuang", "Linzhan Mou", "Runhan Huang", "Hang Zhao"], "title": "TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour", "categories": ["cs.RO", "cs.AI"], "comment": "Project Page: https://ttt-parkour.github.io/", "summary": "Achieving highly dynamic humanoid parkour on unseen, complex terrains remains a challenge in robotics. Although general locomotion policies demonstrate capabilities across broad terrain distributions, they often struggle with arbitrary and highly challenging environments. To overcome this limitation, we propose a real-to-sim-to-real framework that leverages rapid test-time training (TTT) on novel terrains, significantly enhancing the robot's capability to traverse extremely difficult geometries. We adopt a two-stage end-to-end learning paradigm: a policy is first pre-trained on diverse procedurally generated terrains, followed by rapid fine-tuning on high-fidelity meshes reconstructed from real-world captures. Specifically, we develop a feed-forward, efficient, and high-fidelity geometry reconstruction pipeline using RGB-D inputs, ensuring both speed and quality during test-time training. We demonstrate that TTT-Parkour empowers humanoid robots to master complex obstacles, including wedges, stakes, boxes, trapezoids, and narrow beams. The whole pipeline of capturing, reconstructing, and test-time training requires less than 10 minutes on most tested terrains. Extensive experiments show that the policy after test-time training exhibits robust zero-shot sim-to-real transfer capability.", "AI": {"tldr": "本文提出了一种基于快速测试时间训练（TTT）的框架，用于增强机器人在复杂地形上进行动态跳跃的能力。", "motivation": "尽管一般的步行策略展示了广泛的地面分布能力，但在面对随机和极其具有挑战性的环境时仍然存在限制。因此提出了一个实到虚再到现实的方法来解决这一问题。", "method": "采用两阶段的端到端学习范式：首先在多样化的程序生成地形上进行预训练，然后使用来自实际场景捕获的高保真网格快速微调策略。同时开发了一个基于RGB-D输入的高效且高质量的几何重建流水线，以确保测试时间训练的速度和质量。", "result": "实验表明，在经过测试时的培训后，该策略展示了稳健的零样本虚到实迁移能力，并能使机器人克服诸如楔形、桩柱、盒子、梯形以及狭窄梁等复杂障碍物。", "conclusion": "TTT-Parkour使人类形态机器人能够掌握复杂的地形挑战，整个流程包括捕获、重建和测试时间训练在大多数试验的地面条件下需要不到10分钟。"}}
{"id": "2602.02320", "pdf": "https://arxiv.org/pdf/2602.02320", "abs": "https://arxiv.org/abs/2602.02320", "authors": ["Feiyang Cai", "Guijuan He", "Yi Hu", "Jingjing Wang", "Joshua Luo", "Tianyu Zhu", "Srikanth Pilla", "Gang Li", "Ling Liu", "Feng Luo"], "title": "A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method", "categories": ["cs.CL", "cs.AI", "q-bio.BM"], "comment": null, "summary": "Molecular function is largely determined by structure. Accurately aligning molecular structure with natural language is therefore essential for enabling large language models (LLMs) to reason about downstream chemical tasks. However, the substantial cost of human annotation makes it infeasible to construct large-scale, high-quality datasets of structure-grounded descriptions. In this work, we propose a fully automated annotation framework for generating precise molecular structure descriptions at scale. Our approach builds upon and extends a rule-based chemical nomenclature parser to interpret IUPAC names and construct enriched, structured XML metadata that explicitly encodes molecular structure. This metadata is then used to guide LLMs in producing accurate natural-language descriptions. Using this framework, we curate a large-scale dataset of approximately $163$k molecule-description pairs. A rigorous validation protocol combining LLM-based and expert human evaluation on a subset of $2,000$ molecules demonstrates a high description precision of $98.6\\%$. The resulting dataset provides a reliable foundation for future molecule-language alignment, and the proposed annotation method is readily extensible to larger datasets and broader chemical tasks that rely on structural descriptions.", "AI": {"tldr": "论文提出了一个自动化框架，用于生成大规模、高质量的分子结构和自然语言描述的数据集。", "motivation": "准确地将分子结构与自然语言对齐对于大型语言模型(LLMs)进行下游化学任务推理至关重要。然而，人工注释的成本高昂，使得构建大规模高质量数据集变得不可行。", "method": "该方法基于并扩展了一种规则驱动的化学命名法解析器，以解释IUPAC名称，并生成包含分子结构详细信息的XML元数据。此元数据被用来指导LLMs产生准确的自然语言描述。", "result": "使用这种方法，收集了一个约163k个分子-描述对的数据集。在2000个分子子集中进行的验证显示了98.6%的描述准确性。", "conclusion": "该数据集为未来分子结构与语言对齐的研究提供了可靠的基础，并且所提出的方法可以扩展到更大的数据集和更广泛的依赖于结构描述的化学任务。"}}
{"id": "2602.02318", "pdf": "https://arxiv.org/pdf/2602.02318", "abs": "https://arxiv.org/abs/2602.02318", "authors": ["Xiang Li", "Yupeng Zheng", "Pengfei Li", "Yilun Chen", "Ya-Qin Zhang", "Wenchao Ding"], "title": "Enhancing Indoor Occupancy Prediction via Sparse Query-Based Multi-Level Consistent Knowledge Distillation", "categories": ["cs.CV"], "comment": "Accepted by RA-L", "summary": "Occupancy prediction provides critical geometric and semantic understanding for robotics but faces efficiency-accuracy trade-offs. Current dense methods suffer computational waste on empty voxels, while sparse query-based approaches lack robustness in diverse and complex indoor scenes. In this paper, we propose DiScene, a novel sparse query-based framework that leverages multi-level distillation to achieve efficient and robust occupancy prediction. In particular, our method incorporates two key innovations: (1) a Multi-level Consistent Knowledge Distillation strategy, which transfers hierarchical representations from large teacher models to lightweight students through coordinated alignment across four levels, including encoder-level feature alignment, query-level feature matching, prior-level spatial guidance, and anchor-level high-confidence knowledge transfer and (2) a Teacher-Guided Initialization policy, employing optimized parameter warm-up to accelerate model convergence. Validated on the Occ-Scannet benchmark, DiScene achieves 23.2 FPS without depth priors while outperforming our baseline method, OPUS, by 36.1% and even better than the depth-enhanced version, OPUS†. With depth integration, DiScene† attains new SOTA performance, surpassing EmbodiedOcc by 3.7% with 1.62$\\times$ faster inference speed. Furthermore, experiments on the Occ3D-nuScenes benchmark and in-the-wild scenarios demonstrate the versatility of our approach in various environments. Code and models can be accessed at https://github.com/getterupper/DiScene.", "AI": {"tldr": "本文提出了一种新的稀疏查询框架DiScene，用于高效的室内占用预测。", "motivation": "当前密集方法在空闲体素上浪费计算资源，而基于稀疏查询的方法在多样和复杂的室内场景中缺乏鲁棒性。为此，DiScene旨在通过多级知识蒸馏实现高效且稳健的占用预测。", "method": "DiScene采用多层次一致的知识蒸馏策略，从大型教师模型向轻量级学生模型传输分层表示，并使用优化参数预热的教师指导初始化政策以加速收敛。", "result": "在Occ-Scannet基准测试中，DiScene实现了23.2 FPS的速度并超过基线方法OPUS和增强版OPUS†。与EmbodiedOcc相比，在深度集成的情况下，速度提高1.62倍且性能提升3.7%。实验还显示了其在各种环境中的适应性。", "conclusion": "DiScene通过稀疏查询框架实现高效稳健的室内占用预测，并展示了在不同场景下的优越性能和鲁棒性。"}}
{"id": "2602.02313", "pdf": "https://arxiv.org/pdf/2602.02313", "abs": "https://arxiv.org/abs/2602.02313", "authors": ["Changming Li", "Kaixing Zhang", "Haoyun Xu", "Yingdong Shi", "Zheng Zhang", "Kaitao Song", "Kan Ren"], "title": "Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) demonstrate strong reasoning abilities in solving complex real-world problems. Yet, the internal mechanisms driving these complex reasoning behaviors remain opaque. Existing interpretability approaches targeting reasoning either identify components (e.g., neurons) correlated with special textual patterns, or rely on human-annotated contrastive pairs to derive control vectors. Consequently, current methods struggle to precisely localize complex reasoning mechanisms or capture sequential influence from model internal workings to the reasoning outputs. In this paper, built on outcome-oriented and sequential-influence-aware principles, we focus on identifying components that have sequential contribution to reasoning behavior where outcomes are cumulated by long-range effects. We propose Integrated Policy Gradient (IPG), a novel framework that attributes reasoning behaviors to model's inner components by propagating compound outcome-based signals such as post reasoning accuracy backward through model inference trajectories. Empirical evaluations demonstrate that our approach achieves more precise localization and enables reliable modulation of reasoning behaviors (e.g., reasoning capability, reasoning strength) across diverse reasoning models.", "AI": {"tldr": "通过集成策略梯度（IPG）框架，将推理行为归因于模型内部组件，并验证其在精确定位和调节推理行为方面的有效性。", "motivation": "当前方法难以精准定位复杂推理机制或捕捉从模型内部运作到推理输出的序列影响。为此，研究提出了一种新的框架来解决这一问题。", "method": "构建基于结果导向和序列影响感知原则的方法，通过反向传播复合的结果基信号如推理准确性来归因于模型的内部组件。", "result": "实验证明所提出的集成策略梯度（IPG）方法能够实现更精确的定位，并能可靠地调节各种推理模型中的行为。", "conclusion": "该框架可以精确定位和调制大语言模型中的复杂推理机制，为理解并控制模型推理提供了新的视角。"}}
{"id": "2602.02311", "pdf": "https://arxiv.org/pdf/2602.02311", "abs": "https://arxiv.org/abs/2602.02311", "authors": ["Johannes Koch", "Tanja Alderliesten", "Peter A. N. Bosman"], "title": "Introns and Templates Matter: Rethinking Linkage in GP-GOMEA", "categories": ["cs.NE"], "comment": "16 pages, 17 figures, submitted to GECCO 2026", "summary": "GP-GOMEA is among the state-of-the-art for symbolic regression, especially when it comes to finding small and potentially interpretable solutions. A key mechanism employed in any GOMEA variant is the exploitation of linkage, the dependencies between variables, to ensure efficient evolution. In GP-GOMEA, mutual information between node positions in GP trees has so far been used to learn linkage. For this, a fixed expression template is used. This however leads to introns for expressions smaller than the full template. As introns have no impact on fitness, their occurrences are not directly linked to selection. Consequently, introns can adversely affect the extent to which mutual information captures dependencies between tree nodes. To overcome this, we propose two new measures for linkage learning, one that explicitly considers introns in mutual information estimates, and one that revisits linkage learning in GP-GOMEA from a grey-box perspective, yielding a measure that needs not to be learned from the population but is derived directly from the template. Across five standard symbolic regression problems, GP-GOMEA achieves substantial improvements using both measures. We also find that the newly learned linkage structure closely reflects the template linkage structure, and that explicitly using the template structure yields the best performance overall.", "AI": {"tldr": "本文提出了一种改进的GP-GOMEA方法，通过重新考虑基因组内的链路关系来解决符号回归中的问题。", "motivation": "传统的GP-GOMEA使用固定的表达式模板来进行基因依赖性学习，导致小规模解决方案出现无用的内含子，影响进化效率。因此作者希望改进该方法以提高性能和可解释性。", "method": "通过引入新的链路学习措施来解决固定模板带来的问题：一种直接考虑内含子的方法；另一种从灰盒视角出发，根据模板结构直接计算链路关系。", "result": "在五个标准的符号回归任务中，使用新方法后的GP-GOMEA表现出了显著改进。同时发现新学习到的链路结构与模板链路结构紧密相关，且利用模板结构可以获得最佳性能。", "conclusion": "新的方法通过重新考虑基因组内的链路关系能够有效改善GP-GOMEA的表现，为解决符号回归问题提供了一种新的思路。"}}
{"id": "2602.02310", "pdf": "https://arxiv.org/pdf/2602.02310", "abs": "https://arxiv.org/abs/2602.02310", "authors": ["Ron Shprints", "Peter Holderrieth", "Juno Nam", "Rafael Gómez-Bombarelli", "Tommi Jaakkola"], "title": "FragmentFlow: Scalable Transition State Generation for Large Molecules", "categories": ["physics.chem-ph", "cs.AI"], "comment": null, "summary": "Transition states (TSs) are central to understanding and quantitatively predicting chemical reactivity and reaction mechanisms. Although traditional TS generation methods are computationally expensive, recent generative modeling approaches have enabled chemically meaningful TS prediction for relatively small molecules. However, these methods fail to generalize to practically relevant reaction substrates because of distribution shifts induced by increasing molecular sizes. Furthermore, TS geometries for larger molecules are not available at scale, making it infeasible to train generative models from scratch on such molecules. To address these challenges, we introduce FragmentFlow: a divide-and-conquer approach that trains a generative model to predict TS geometries for the reactive core atoms, which define the reaction mechanism. The full TS structure is then reconstructed by re-attaching substituent fragments to the predicted core. By operating on reactive cores, whose size and composition remain relatively invariant across molecular contexts, FragmentFlow mitigates distribution shifts in generative modeling. Evaluated on a new curated dataset of reactions involving reactants with up to 33 heavy atoms, FragmentFlow correctly identifies 90% of TSs while requiring 30% fewer saddle-point optimization steps than classical initialization schemes. These results point toward scalable TS generation for high-throughput reactivity studies.", "AI": {"tldr": "FragmentFlow是一种生成过渡态结构的方法，适用于大型分子的反应性研究。", "motivation": "传统方法在预测大分子的过渡态时计算成本高且难以泛化。为解决这些问题，提出了一种新方法来克服分布偏移并实现大规模过渡态结构的可扩展生成。", "method": "通过分割反应核心与取代基片段，训练一个生成模型预测反应核心原子的过渡态几何结构，并重新连接取代基片段以重建完整结构。", "result": "在包含多达33个重原子的反应数据集上，FragmentFlow正确识别了90%的过渡态，比传统初始化方案减少了30%的鞍点优化步骤。", "conclusion": "通过使用反应核心来训练模型，FragmentFlow减轻了分布偏移的影响，并实现了大规模分子中过渡态结构的可扩展预测。"}}
{"id": "2602.02306", "pdf": "https://arxiv.org/pdf/2602.02306", "abs": "https://arxiv.org/abs/2602.02306", "authors": ["Mario Franco", "Carlos Gershenson"], "title": "Spark: Modular Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "Nowadays, neural networks act as a synonym for artificial intelligence. Present neural network models, although remarkably powerful, are inefficient both in terms of data and energy. Several alternative forms of neural networks have been proposed to address some of these problems. Specifically, spiking neural networks are suitable for efficient hardware implementations. However, effective learning algorithms for spiking networks remain elusive, although it is suspected that effective plasticity mechanisms could alleviate the problem of data efficiency. Here, we present a new framework for spiking neural networks - Spark - built upon the idea of modular design, from simple components to entire models. The aim of this framework is to provide an efficient and streamlined pipeline for spiking neural networks. We showcase this framework by solving the sparse-reward cartpole problem with simple plasticity mechanisms. We hope that a framework compatible with traditional ML pipelines may accelerate research in the area, specifically for continuous and unbatched learning, akin to the one animals exhibit.", "AI": {"tldr": "本文提出了一个基于模块化设计的新型脉冲神经网络框架Spark，旨在提高数据效率和能源效率。", "motivation": "现有的神经网络模型虽然非常强大但存在数据和能耗上的低效问题。特别是对于高效硬件实现而言，脉冲神经网络更为合适，但是有效的学习算法仍然是难题。", "method": "提出了一个名为Spark的框架，通过从简单的组件到整个模型的设计思想来构建脉冲神经网络。", "result": "利用简单可塑性机制解决了稀疏奖励的小车摆杆问题。", "conclusion": "该框架兼容传统机器学习管道，期望能够加速连续和非批处理学习的研究进程。"}}
{"id": "2602.02304", "pdf": "https://arxiv.org/pdf/2602.02304", "abs": "https://arxiv.org/abs/2602.02304", "authors": ["Martino Ciaperoni", "Marzio Di Vece", "Luca Pappalardo", "Fosca Giannotti", "Francesco Giannini"], "title": "Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large-scale foundation models exhibit behavioral shifts: intervention-induced behavioral changes that appear after scaling, fine-tuning, reinforcement learning or in-context learning. While investigating these phenomena have recently received attention, explaining their appearance is still overlooked. Classic explainable AI (XAI) methods can surface failures at a single checkpoint of a model, but they are structurally ill-suited to justify what changed internally across different checkpoints and which explanatory claims are warranted about that change. We take the position that behavioral shifts should be explained comparatively: the core target should be the intervention-induced shift between a reference model and an intervened model, rather than any single model in isolation. To this aim we formulate a Comparative XAI ($Δ$-XAI) framework with a set of desiderata to be taken into account when designing proper explaining methods. To highlight how $Δ$-XAI methods work, we introduce a set of possible pipelines, relate them to the desiderata, and provide a concrete $Δ$-XAI experiment.", "AI": {"tldr": "该论文提出了一个比较性可解释AI框架（Δ-XAI）来解释大规模语言模型的行为变化。", "motivation": "经典XAI方法只能揭示单一检查点的失败，但无法解释跨不同检查点的变化。因此，需要一种新的方法来解释干预引起的模型行为变化。", "method": "提出了一个比较性可解释AI（Δ-XAI）框架，并设计了一系列符合标准的方法管道。", "result": "通过实验展示了如何使用Δ-XAI方法来解释大规模语言模型的行为变化。", "conclusion": "采用Δ-XAI方法可以更好地解释大规模语言模型在不同状态下的行为差异，这是未来研究的一个重要方向。"}}
{"id": "2602.02301", "pdf": "https://arxiv.org/pdf/2602.02301", "abs": "https://arxiv.org/abs/2602.02301", "authors": ["Min Cai", "Yu Liang", "Longzheng Wang", "Yan Wang", "Yueyang Zhang", "Long Xia", "Zhiyuan Sun", "Xi Ye", "Daiting Shi"], "title": "Advancing General-Purpose Reasoning Models with Modular Gradient Surgery", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Preprint; Code: https://github.com/StringNLPLAB/MGS; Website: https://modular-gradient-surgery.github.io", "summary": "Reinforcement learning (RL) has played a central role in recent advances in large reasoning models (LRMs), yielding strong gains in verifiable and open-ended reasoning. However, training a single general-purpose LRM across diverse domains remains challenging due to pronounced domain heterogeneity. Through a systematic study of two widely used strategies, Sequential RL and Mixed RL, we find that both incur substantial cross-domain interference at the behavioral and gradient levels, resulting in limited overall gains. To address these challenges, we introduce **M**odular **G**radient **S**urgery (**MGS**), which resolves gradient conflicts at the module level within the transformer. When applied to Llama and Qwen models, MGS achieves average improvements of 4.3 (16.6\\%) and 4.5 (11.1\\%) points, respectively, over standard multi-task RL across three representative domains (math, general chat, and instruction following). Further analysis demonstrates that MGS remains effective under prolonged training. Overall, our study clarifies the sources of interference in multi-domain RL and presents an effective solution for training general-purpose LRMs.", "AI": {"tldr": "本文提出了模块化梯度手术（MGS）方法，解决了大型推理模型在跨域训练中的梯度冲突问题。", "motivation": "由于不同领域的异质性，在一个通用的大规模推理模型中同时进行多个任务的强化学习面临挑战。通过研究顺序RL和混合RL策略，发现这些策略会导致行为和梯度上的跨域干扰。", "method": "本文提出了一种名为模块化梯度手术（MGS）的方法，它在Transformer内部的模块级别解决梯度冲突问题。", "result": "应用MGS到Llama和Qwen模型中，在三个代表性领域（数学、普通聊天和指令跟随）上分别取得了平均4.3分和4.5分的提升，相较于标准的多任务RL改进了16.6%和11.1%。", "conclusion": "本文的研究阐明了跨域强化学习中的干扰源，并提出了一种有效的解决方案来训练通用的大规模推理模型。"}}
{"id": "2602.02298", "pdf": "https://arxiv.org/pdf/2602.02298", "abs": "https://arxiv.org/abs/2602.02298", "authors": ["Romy Müller", "Wiebke Klausing"], "title": "When more precision is worse: Do people recognize inadequate scene representations in concept-based explainable AI?", "categories": ["cs.HC"], "comment": null, "summary": "Explainable artificial intelligence (XAI) aims to help uncover flaws in an AI model's internal representations. But do people draw the right conclusions from its explanations? Specifically, do they recognize an AI's inability to distinguish between relevant and irrelevant features? In the present study, a simulated AI classified images of railway trespassers as dangerous or not. To explain which features it has used, other images from the dataset were shown that activate the AI in a similar way. These concept images varied in three relevant features (i.e., a person's distance to the tracks, direction, and action) and in an irrelevant feature (i.e., scene background). When the AI uses a feature in its decision, this feature is retained in the concept images, otherwise the images randomize over it (e.g., same distance, varied backgrounds). Participants rated the AI more favorably when it retained relevant features. For the irrelevant feature, they did not mind in general, and sometimes even preferred it to be retained. This suggests that people may not recognize it when an AI model relies on irrelevant features to make its decisions.", "AI": {"tldr": "该论文研究了人们是否能够识别AI模型在决策过程中使用不相关特征的情况。", "motivation": "探索人类用户能否根据XAI的解释正确判断AI模型内部表示中的缺陷，特别是其区分相关和不相关特征的能力。", "method": "通过模拟AI对铁路入侵者图像进行分类，并展示激活相似方式的概念图来解释所使用的特征。概念图在三个相关特征（距离、方向和动作）和一个无关特征（场景背景）之间变化。", "result": "参与者更倾向于认为保留了相关特征的模型表现更好，对于不相关的场景背景特征，则没有明显偏好甚至有时偏爱保留。", "conclusion": "研究表明人们可能无法识别AI模型在决策时依赖于不相关特征的情况。"}}
{"id": "2602.02296", "pdf": "https://arxiv.org/pdf/2602.02296", "abs": "https://arxiv.org/abs/2602.02296", "authors": ["Xingli Fang", "Jung-Eun Kim"], "title": "Decoupling Generalizability and Membership Privacy Risks in Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "A deep learning model usually has to sacrifice some utilities when it acquires some other abilities or characteristics. Privacy preservation has such trade-off relationships with utilities. The loss disparity between various defense approaches implies the potential to decouple generalizability and privacy risks to maximize privacy gain. In this paper, we identify that the model's generalization and privacy risks exist in different regions in deep neural network architectures. Based on the observations that we investigate, we propose Privacy-Preserving Training Principle (PPTP) to protect model components from privacy risks while minimizing the loss in generalizability. Through extensive evaluations, our approach shows significantly better maintenance in model generalizability while enhancing privacy preservation.", "AI": {"tldr": "本文提出了一种保护模型组件免受隐私风险的方法，同时最小化泛化能力的损失。", "motivation": "深度学习模型在获得某些特性和能力时通常需要牺牲一些实用性。隐私保护同样存在这种权衡关系。不同防御方法之间的损失差异暗示了可以将泛化能力和隐私风险解耦以最大化隐私收益的潜力。", "method": "本文发现了深度神经网络架构中，模型的泛化和隐私风险存在于不同的区域，并基于这些观察提出了Privacy-Preserving Training Principle (PPTP) 方法来保护模型组件免受隐私风险的同时最小化泛化的损失。", "result": "通过广泛的评估，该方法在增强隐私保护的同时显著改善了模型的泛化能力。", "conclusion": "本文展示了如何通过解耦泛化能力和隐私风险来提升模型性能和隐私安全。"}}
{"id": "2602.02293", "pdf": "https://arxiv.org/pdf/2602.02293", "abs": "https://arxiv.org/abs/2602.02293", "authors": ["Nils Chur", "Thiago Santos de Moura", "Argentina Ortega", "Sven Peldszus", "Thorsten Berger", "Nico Hochgeschwender", "Yannic Noller"], "title": "Before Autonomy Takes Control: Software Testing in Robotics", "categories": ["cs.SE", "cs.RO"], "comment": null, "summary": "Robotic systems are complex and safety-critical software systems. As such, they need to be tested thoroughly. Unfortunately, robot software is intrinsically hard to test compared to traditional software, mainly since the software needs to closely interact with hardware, account for uncertainty in its operational environment, handle disturbances, and act highly autonomously. However, given the large space in which robots operate, anticipating possible failures when designing tests is challenging. This paper presents a mapping study by considering robotics testing papers and relating them to the software testing theory. We consider 247 robotics testing papers and map them to software testing, discussing the state-of-the-art software testing in robotics with an illustrated example, and discuss current challenges. Forming the basis to introduce both the robotics and software engineering communities to software testing challenges. Finally, we identify open questions and lessons learned.", "AI": {"tldr": "该论文通过梳理机器人测试文献，将其与软件测试理论相联系，讨论了当前机器人软件测试的状态，并提出了存在的挑战和未来的研究方向。", "motivation": "机器人系统作为复杂的、安全性至关重要的软件系统，在其复杂环境中进行充分的测试具有极大的必要性。然而，传统的软件测试方法在处理机器人软件时遇到了困难，因为需要考虑硬件交互、环境不确定性、干扰以及高度自主性的因素。", "method": "该论文进行了文献综述和映射研究，分析了247篇机器人测试相关文献，并将其与现有的软件测试理论进行对照，以理解当前的挑战并识别未来的研究方向。", "result": "通过这种对比和分析，该研究展示了当前机器人软件测试的状态以及面临的各种挑战，为机器人和软件工程社区提供了一个共同的基础来了解这些问题，并提出了未来可能的研究路径。", "conclusion": "该论文强调了在机器人领域进行彻底的软件测试的重要性。它揭示了现有的测试方法不足以应对复杂环境中的不确定性和自主性带来的挑战，并呼吁两个领域的专家合作解决这些开放问题。"}}
{"id": "2602.02290", "pdf": "https://arxiv.org/pdf/2602.02290", "abs": "https://arxiv.org/abs/2602.02290", "authors": ["Alex Argese", "Pasquale Lisena", "Raphaël Troncy"], "title": "Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?", "categories": ["cs.CL", "cs.AI"], "comment": ":I.2.7", "summary": "Generative AI can turn scientific articles into narratives for diverse audiences, but evaluating these stories remains challenging. Storytelling demands abstraction, simplification, and pedagogical creativity-qualities that are not often well-captured by standard summarization metrics. Meanwhile, factual hallucinations are critical in scientific contexts, yet, detectors often misclassify legitimate narrative reformulations or prove unstable when creativity is involved. In this work, we propose StoryScore, a composite metric for evaluating AI-generated scientific stories. StoryScore integrates semantic alignment, lexical grounding, narrative control, structural fidelity, redundancy avoidance, and entity-level hallucination detection into a unified framework. Our analysis also reveals why many hallucination detection methods fail to distinguish pedagogical creativity from factual errors, highlighting a key limitation: while automatic metrics can effectively assess semantic similarity with original content, they struggle to evaluate how it is narrated and controlled.", "AI": {"tldr": "提出StoryScore评估AI生成的科学故事", "motivation": "当前的总结指标难以捕捉抽象、简化和创意叙事的特点，同时检测器在科学背景下容易将创造性叙述误认为事实错误。", "method": "StoryScore结合语义对齐、词汇锚定、叙述控制、结构保真度、冗余避免及实体级别幻觉检测形成统一框架。", "result": "分析揭示了许多幻觉检测方法难以区分教育创新和事实错误的原因，即自动指标可以评估与原始内容的语义相似性但无法评价叙事方式和控制。", "conclusion": "StoryScore为评估AI生成的科学故事提供了一个新方案，解决了现有问题。"}}
{"id": "2602.02288", "pdf": "https://arxiv.org/pdf/2602.02288", "abs": "https://arxiv.org/abs/2602.02288", "authors": ["Zheng Li", "Jerry Cheng", "Huanying Gu"], "title": "An Optimization Method for Autoregressive Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 2 figures, 2 tables", "summary": "Current time-series forecasting models are primarily based on transformer-style neural networks. These models achieve long-term forecasting mainly by scaling up the model size rather than through genuinely autoregressive (AR) rollout. From the perspective of large language model training, the traditional training process for time-series forecasting models ignores temporal causality. In this paper, we propose a novel training method for time-series forecasting that enforces two key properties: (1) AR prediction errors should increase with the forecasting horizon. Any violation of this principle is considered random guessing and is explicitly penalized in the loss function, and (2) the method enables models to concatenate short-term AR predictions for forming flexible long-term forecasts. Empirical results demonstrate that our method establishes a new state-of-the-art across multiple benchmarks, achieving an MSE reduction of more than 10% compared to iTransformer and other recent strong baselines. Furthermore, it enables short-horizon forecasting models to perform reliable long-term predictions at horizons over 7.5 times longer. Code is available at https://github.com/LizhengMathAi/AROpt", "AI": {"tldr": "本文提出了一种新的时间序列预测训练方法，通过强化自回归（AR）属性来提高模型的长期预报能力。", "motivation": "当前的时间序列预测模型主要依赖于规模扩大的变压器式神经网络，忽略了时间因果关系。传统的训练过程未能充分利用AR特性进行有效预报。", "method": "该方法强制执行两个关键属性：1) AR预测误差随预报时长增加；2) 允许模型连接短期AR预测形成灵活的长期预报，并通过损失函数对违反此原则的行为进行惩罚。", "result": "实验结果表明，本文的方法在多个基准测试中达到了新的SOTA水平，比iTransformer和其他最近的强大基线减少了超过10%的均方误差（MSE），并且使得短期模型能够可靠地预测更长时间范围内的数据。", "conclusion": "通过强化时间序列预报中的AR属性，该方法显著提升了长期预测能力和准确性。"}}
{"id": "2602.02286", "pdf": "https://arxiv.org/pdf/2602.02286", "abs": "https://arxiv.org/abs/2602.02286", "authors": ["Arnab Das", "Yassine El Kheir", "Enes Erdem Erdogan", "Feidi Kallel", "Tim Polzehl", "Sebastian Moeller"], "title": "DFKI-Speech System for WildSpoof Challenge: A robust framework for SASV In-the-Wild", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper presents the DFKI-Speech system developed for the WildSpoof Challenge under the Spoofing aware Automatic Speaker Verification (SASV) track. We propose a robust SASV framework in which a spoofing detector and a speaker verification (SV) network operate in tandem. The spoofing detector employs a self-supervised speech embedding extractor as the frontend, combined with a state-of-the-art graph neural network backend. In addition, a top-3 layer based mixture-of-experts (MoE) is used to fuse high-level and low-level features for effective spoofed utterance detection. For speaker verification, we adapt a low-complexity convolutional neural network that fuses 2D and 1D features at multiple scales, trained with the SphereFace loss. Additionally, contrastive circle loss is applied to adaptively weight positive and negative pairs within each training batch, enabling the network to better distinguish between hard and easy sample pairs. Finally, fixed imposter cohort based AS Norm score normalization and model ensembling are used to further enhance the discriminative capability of the speaker verification system.", "AI": {"tldr": "本文介绍了DFKI-Speech系统，该系统为WildSpoof挑战赛中的SASV赛道设计了一个鲁棒的框架。", "motivation": "提出一种鲁棒性的SASV框架以提高在真实环境下的反欺骗能力与语音识别准确率。", "method": "采用自监督的嵌入提取器结合先进图神经网络作为前端，使用基于顶层混合专家模型融合高低级特征进行有效检测。同时使用SphereFace损失函数训练低复杂度卷积神经网络并引入对比圆圈损失以区分难易样本对，并通过固定冒名者的队列和模型集成提高系统的鉴别能力。", "result": "未具体说明结果，但描述了系统中各项技术的融合应用及其预期效果提升。", "conclusion": "提出的DFKI-Speech系统结合多种先进技术，在SASV任务中的性能有所提高。"}}
{"id": "2602.02281", "pdf": "https://arxiv.org/pdf/2602.02281", "abs": "https://arxiv.org/abs/2602.02281", "authors": ["Antonino Emanuele Scurria"], "title": "Backpropagation as Physical Relaxation: Exact Gradients in Finite Time", "categories": ["cs.LG", "cs.AI", "cs.NE", "physics.class-ph", "physics.comp-ph"], "comment": "15 pages, 8 figures", "summary": "Backpropagation, the foundational algorithm for training neural networks, is typically understood as a symbolic computation that recursively applies the chain rule. We show it emerges exactly as the finite-time relaxation of a physical dynamical system. By formulating feedforward inference as a continuous-time process and applying Lagrangian theory of non-conservative systems to handle asymmetric interactions, we derive a global energy functional on a doubled state space encoding both activations and sensitivities. The saddle-point dynamics of this energy perform inference and credit assignment simultaneously through local interactions. We term this framework ''Dyadic Backpropagation''. Crucially, we prove that unit-step Euler discretization, the natural timescale of layer transitions, recovers standard backpropagation exactly in precisely 2L steps for an L-layer network, with no approximations. Unlike prior energy-based methods requiring symmetric weights, asymptotic convergence, or vanishing perturbations, our framework guarantees exact gradients in finite time. This establishes backpropagation as the digitally optimized shadow of a continuous physical relaxation, providing a rigorous foundation for exact gradient computation in analog and neuromorphic substrates where continuous dynamics are native.", "AI": {"tldr": "本文提出了一种新的框架，将反向传播理解为物理系统的放松过程，并证明了这种放松过程能够精确地在有限时间内计算出梯度。", "motivation": "传统上，反向传播算法被看作是递归应用链式法则的符号运算。作者通过从连续时间动态系统出发推导出了一个能量函数，该函数能够在有限的时间内精确计算梯度，从而提供了一个对神经网络训练基础算法的新视角。", "method": "将前馈推理视为连续时间过程，并利用非保守系统的拉格朗日理论处理不对称交互。通过在双重状态空间中编码激活和敏感性来构造全局能量函数，该方法能够同时进行推断与信用分配。", "result": "证明了对于L层网络，在2L步的单位步骤欧拉离散化下，可以精确恢复标准反向传播算法。", "conclusion": "本文的工作为在模拟和神经形态基板上执行精确梯度计算提供了一个严格的理论基础，并表明反向传播是连续物理放松过程的一个数字优化版本。"}}
{"id": "2602.02280", "pdf": "https://arxiv.org/pdf/2602.02280", "abs": "https://arxiv.org/abs/2602.02280", "authors": ["Zeming Wei", "Zhixin Zhang", "Chengcan Wu", "Yihao Zhang", "Xiaokun Luan", "Meng Sun"], "title": "RACA: Representation-Aware Coverage Criteria for LLM Safety Testing", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "Recent advancements in LLMs have led to significant breakthroughs in various AI applications. However, their sophisticated capabilities also introduce severe safety concerns, particularly the generation of harmful content through jailbreak attacks. Current safety testing for LLMs often relies on static datasets and lacks systematic criteria to evaluate the quality and adequacy of these tests. While coverage criteria have been effective for smaller neural networks, they are not directly applicable to LLMs due to scalability issues and differing objectives. To address these challenges, this paper introduces RACA, a novel set of coverage criteria specifically designed for LLM safety testing. RACA leverages representation engineering to focus on safety-critical concepts within LLMs, thereby reducing dimensionality and filtering out irrelevant information. The framework operates in three stages: first, it identifies safety-critical representations using a small, expert-curated calibration set of jailbreak prompts. Second, it calculates conceptual activation scores for a given test suite based on these representations. Finally, it computes coverage results using six sub-criteria that assess both individual and compositional safety concepts. We conduct comprehensive experiments to validate RACA's effectiveness, applicability, and generalization, where the results demonstrate that RACA successfully identifies high-quality jailbreak prompts and is superior to traditional neuron-level criteria. We also showcase its practical application in real-world scenarios, such as test set prioritization and attack prompt sampling. Furthermore, our findings confirm RACA's generalization to various scenarios and its robustness across various configurations. Overall, RACA provides a new framework for evaluating the safety of LLMs, contributing a valuable technique to the field of testing for AI.", "AI": {"tldr": "提出了一种名为RACA的新框架，用于评估大型语言模型的安全性。", "motivation": "当前的LLM安全性测试依赖于静态数据集，缺乏系统的评价标准。现有的覆盖准则对于较小的神经网络有效，但对于LLM不适用。", "method": "通过表示工程识别安全关键概念，并计算激活分数来确定测试套件的质量，最终使用六个子准则评估整体覆盖率和安全性。", "result": "实验验证了RACA在识别高质量攻击提示、测试集优先级划分及泛化性方面的优越表现。", "conclusion": "RACA提供了一种新的框架用于评价LLM的安全性，并为AI领域的安全测试贡献了一个有价值的工具。"}}
{"id": "2602.02276", "pdf": "https://arxiv.org/pdf/2602.02276", "abs": "https://arxiv.org/abs/2602.02276", "authors": ["Kimi Team", "Tongtong Bai", "Yifan Bai", "Yiping Bao", "S. H. Cai", "Yuan Cao", "Y. Charles", "H. S. Che", "Cheng Chen", "Guanduo Chen", "Huarong Chen", "Jia Chen", "Jiahao Chen", "Jianlong Chen", "Jun Chen", "Kefan Chen", "Liang Chen", "Ruijue Chen", "Xinhao Chen", "Yanru Chen", "Yanxu Chen", "Yicun Chen", "Yimin Chen", "Yingjiang Chen", "Yuankun Chen", "et al. (301 additional authors not shown)"], "title": "Kimi K2.5: Visual Agentic Intelligence", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Kimi K2.5 tech report", "summary": "We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to $4.5\\times$ over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.", "AI": {"tldr": "介绍了Kimi K2.5，一个开源的多模态代理模型，旨在推进通用代理智能。", "motivation": "为了推动视觉和文本之间的联合优化以及构建更加智能的代理系统，提出了Kimi K2.5。", "method": "通过联合预训练、零样本视觉微调及联合强化学习等技术实现跨模态增强。并引入Agent Swarm框架进行任务拆解与并发执行。", "result": "实验证明了Kimi K2.5在编码、视觉、推理和代理任务上均取得最先进的成果，同时降低了延迟。", "conclusion": "发布了训练好的Kimi K2.5模型以促进后续研究及实际应用中的代理智能发展。"}}
{"id": "2602.02269", "pdf": "https://arxiv.org/pdf/2602.02269", "abs": "https://arxiv.org/abs/2602.02269", "authors": ["Jon Škerlj", "Seongjin Bien", "Abdeldjallil Naceri", "Sami Haddadin"], "title": "Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems", "categories": ["cs.RO", "cs.AI", "cs.SE", "eess.SY"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We present $multipanda\\_ros2$, a novel open-source ROS2 architecture for multi-robot control of Franka Robotics robots. Leveraging ros2 control, this framework provides native ROS2 interfaces for controlling any number of robots from a single process. Our core contributions address key challenges in real-time torque control, including interaction control and robot-environment modeling. A central focus of this work is sustaining a 1kHz control frequency, a necessity for real-time control and a minimum frequency required by safety standards. Moreover, we introduce a controllet-feature design pattern that enables controller-switching delays of $\\le 2$ ms, facilitating reproducible benchmarking and complex multi-robot interaction scenarios. To bridge the simulation-to-reality (sim2real) gap, we integrate a high-fidelity MuJoCo simulation with quantitative metrics for both kinematic accuracy and dynamic consistency (torques, forces, and control errors). Furthermore, we demonstrate that real-world inertial parameter identification can significantly improve force and torque accuracy, providing a methodology for iterative physics refinement. Our work extends approaches from soft robotics to rigid dual-arm, contact-rich tasks, showcasing a promising method to reduce the sim2real gap and providing a robust, reproducible platform for advanced robotics research.", "AI": {"tldr": "本文介绍了一个用于多机器人控制的ROS2架构multipanda_ros2，旨在解决实时扭矩控制中的挑战，并通过高保真模拟来弥合仿真与现实之间的差距。", "motivation": "在多机器人系统中实现高效、准确和安全的操作是一个关键目标。当前技术面临的主要挑战是实时扭矩控制和从模拟到实际环境的转换问题，这要求开发新的架构和技术解决方案。", "method": "该框架通过使用ROS2控制来提供原生接口以同时控制多个机器人，并引入了一种新的设计模式controllet-feature，使得控制器切换延迟降至最低。此外，它还结合了MuJoCo模拟和真实世界的数据以改进力矩准确性并减少仿真与实际操作的差距。", "result": "该方法能够支持1kHz以上的实时控制频率，并通过实验证明可以显著改善动态一致性（如力矩、力以及控制误差）。此外，展示出了一种迭代物理参数调整的方法来进一步优化模拟效果。", "conclusion": "multipanda_ros2提供了一个强大的平台，用于多机器人系统的开发和测试。它不仅弥合了仿真与现实的差距，还促进了对复杂接触任务的研究，并为未来的发展奠定了基础。"}}
{"id": "2602.02266", "pdf": "https://arxiv.org/pdf/2602.02266", "abs": "https://arxiv.org/abs/2602.02266", "authors": ["Tan Sang Nguyen", "Muhammad Reza Qorib", "Hwee Tou Ng"], "title": "OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have proven to be effective tools for a wide range of natural language processing (NLP) applications. Although many LLMs are multilingual, most remain English-centric and perform poorly on low-resource languages. Recently, several Southeast Asia-focused LLMs have been developed, but none are truly open source, as they do not publicly disclose their training data. Truly open-source models are important for transparency and for enabling a deeper and more precise understanding of LLM internals and development, including biases, generalization, and multilinguality. Motivated by recent advances demonstrating the effectiveness of parallel data in improving multilingual performance, we conduct controlled and comprehensive experiments to study the effectiveness of parallel data in continual pretraining of LLMs. Our findings show that using only parallel data is the most effective way to extend an LLM to new languages. Using just 34.7B tokens of parallel data and 180 hours on 8x NVIDIA H200 GPUs, we built OpenSeal, the first truly open Southeast Asian LLM that rivals the performance of existing models of similar size.", "AI": {"tldr": "研究的主要任务是通过平行数据的持续预训练，构建一个开源的东南亚大语言模型（OpenSeal），并在资源有限的语言上实现性能与现有同规模模型相当。", "motivation": "大多数现有的多语言大型语言模型偏向英语且在低资源语言上的表现不佳。此外，虽然有一些针对东南亚地区的语言模型开发出来，但它们没有公开训练数据，缺乏透明度和理解其内部工作原理的能力。因此研究者希望构建一个完全开源的模型来提高透明度，并通过平行数据提升多语种性能。", "method": "使用平行数据进行持续预训练，实验表明仅使用平行数据是扩展语言模型到新语言最有效的方法。利用34.7B令牌和8xNVIDIA H200 GPU在180小时内构建了OpenSeal。", "result": "通过使用平行数据的持续预训练，研究者成功地创建了一个开源的大规模东南亚语言模型（OpenSeal），其性能与现有同规模的语言模型相当。", "conclusion": "研究表明，在大型语言模型中引入平行数据进行持续预训练是扩展到新语言的有效方法。构建出的OpenSeal成为第一个完全公开源代码和训练资料的东南亚地区大语言模型，能够满足该区域对多语种处理的需求，并促进进一步的研究与理解。"}}
{"id": "2602.02264", "pdf": "https://arxiv.org/pdf/2602.02264", "abs": "https://arxiv.org/abs/2602.02264", "authors": ["Paolo Marcandelli", "Natansh Mathur", "Stefano Markidis", "Martina Siena", "Stefano Mariani"], "title": "Unsupervised Physics-Informed Operator Learning through Multi-Stage Curriculum Training", "categories": ["cs.LG", "cs.AI"], "comment": "51 pages, 15 figures, 6 tables", "summary": "Solving partial differential equations remains a central challenge in scientific machine learning. Neural operators offer a promising route by learning mappings between function spaces and enabling resolution-independent inference, yet they typically require supervised data. Physics-informed neural networks address this limitation through unsupervised training with physical constraints but often suffer from unstable convergence and limited generalization capability. To overcome these issues, we introduce a multi-stage physics-informed training strategy that achieves convergence by progressively enforcing boundary conditions in the loss landscape and subsequently incorporating interior residuals. At each stage the optimizer is re-initialized, acting as a continuation mechanism that restores stability and prevents gradient stagnation. We further propose the Physics-Informed Spline Fourier Neural Operator (PhIS-FNO), combining Fourier layers with Hermite spline kernels for smooth residual evaluation. Across canonical benchmarks, PhIS-FNO attains a level of accuracy comparable to that of supervised learning, using labeled information only along a narrow boundary region, establishing staged, spline-based optimization as a robust paradigm for physics-informed operator learning.", "AI": {"tldr": "提出了一个分阶段的物理信息训练策略和结合傅里叶层与埃尔米特样条核函数的PhIS-FNO，以解决无监督学习中的收敛性和泛化能力问题。", "motivation": "现有的神经算子需要监督数据进行学习，并且物理信息网络虽然可以利用物理约束进行无监督训练，但往往存在不稳定的收敛和有限的泛化能力。", "method": "通过分阶段策略逐步引入边界条件并加入内部残差，结合傅里叶层与埃尔米特样条核函数构建PhIS-FNO模型。", "result": "在标准基准测试中，提出的PhIS-FNO方法实现了接近监督学习的准确性，并且只需要沿狭窄边界的标记信息即可完成任务。", "conclusion": "分阶段、基于样条优化的方法是物理信息算子学习中的一个稳健范例。"}}
{"id": "2602.02262", "pdf": "https://arxiv.org/pdf/2602.02262", "abs": "https://arxiv.org/abs/2602.02262", "authors": ["Atharv Sonwane", "Eng-Shen Tu", "Wei-Chung Lu", "Claas Beger", "Carter Larsen", "Debjit Dhar", "Rachel Chen", "Ronit Pattanayak", "Tuan Anh Dang", "Guohao Chen", "Gloria Geng", "Kevin Ellis", "Saikat Dutta"], "title": "OmniCode: A Benchmark for Evaluating Software Engineering Agents", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "LLM-powered coding agents are redefining how real-world software is developed. To drive the research towards better coding agents, we require challenging benchmarks that can rigorously evaluate the ability of such agents to perform various software engineering tasks. However, popular coding benchmarks such as HumanEval and SWE-Bench focus on narrowly scoped tasks such as competition programming and patch generation. In reality, software engineers have to handle a broader set of tasks for real-world software development. To address this gap, we propose OmniCode, a novel software engineering benchmark that contains a broader and more diverse set of task categories beyond code or patch generation. Overall, OmniCode contains 1794 tasks spanning three programming languages (Python, Java, and C++) and four key categories: bug fixing, test generation, code review fixing, and style fixing. In contrast to prior software engineering benchmarks, the tasks in OmniCode are (1) manually validated to eliminate ill-defined problems, and (2) synthetically crafted or recently curated to avoid data leakage issues, presenting a new framework for synthetically generating diverse software tasks from limited real-world data. We evaluate OmniCode with popular agent frameworks such as SWE-Agent and show that while they may perform well on bug fixing for Python, they fall short on tasks such as Test Generation and in languages such as C++ and Java. For instance, SWE-Agent achieves a maximum of 20.9% with DeepSeek-V3.1 on Java Test Generation tasks. OmniCode aims to serve as a robust benchmark and spur the development of agents that can perform well across different aspects of software development. Code and data are available at https://github.com/seal-research/OmniCode.", "AI": {"tldr": "OmniCode 是一个新型软件工程基准测试，旨在评估代码生成代理在各种任务上的性能。", "motivation": "现有编码基准过于狭窄，不能全面反映真实世界中的软件开发需求。因此需要一个涵盖更多任务类型的基准来推动更好的代码生成代理的研究。", "method": "OmniCode 包含了1794个任务，跨越三种编程语言，并且包含了四个关键类别：错误修复、测试生成、代码审查修正和风格修正。所有任务都经过手动验证以确保清晰定义并避免数据泄露问题。", "result": "流行的代理框架如SWE-Agent在某些任务上表现不佳，例如Java中的测试生成仅达到20.9%的成功率。这表明当前的编码代理还有很多提升空间。", "conclusion": "OmniCode 提供了一个新的基准来评估和推动代码生成代理的发展，旨在使这些代理能够更好地处理各种软件开发任务。"}}
{"id": "2602.02259", "pdf": "https://arxiv.org/pdf/2602.02259", "abs": "https://arxiv.org/abs/2602.02259", "authors": ["Hamza Adnan", "Matthew T. Jackson", "Alexey Zakharov"], "title": "Segment to Focus: Guiding Latent Action Models in the Presence of Distractors", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Latent Action Models (LAMs) learn to extract action-relevant representations solely from raw observations, enabling reinforcement learning from unlabelled videos and significantly scaling available training data. However, LAMs face a critical challenge in disentangling action-relevant features from action-correlated noise (e.g., background motion). Failing to filter these distractors causes LAMs to capture spurious correlations and build sub-optimal latent action spaces. In this paper, we introduce MaskLAM -- a lightweight modification to LAM training to mitigate this issue by incorporating visual agent segmentation. MaskLAM utilises segmentation masks from pretrained foundation models to weight the LAM reconstruction loss, thereby prioritising salient information over background elements while requiring no architectural modifications. We demonstrate the effectiveness of our method on continuous-control MuJoCo tasks, modified with action-correlated background noise. Our approach yields up to a 4x increase in accrued rewards compared to standard baselines and a 3x improvement in the latent action quality, as evidenced by linear probe evaluation.", "AI": {"tldr": "MaskLAM是一种轻量级的修改方法，用于改善Latent Action Models（LAMs）在处理背景噪声时的表现。", "motivation": "传统的Latent Action Models难以从复杂的背景运动中分离出真正与动作相关的特征。这会导致模型捕捉到虚假的相关性，并构建低效的动作表示空间。", "method": "MaskLAM通过利用预先训练的分割模型生成的掩码来调整LAM重建损失，从而强调前景信息并减少背景噪声的影响。", "result": "在修改后的连续控制任务中，MaskLAM相比标准基线实现了高达4倍的累积奖励提升，并且提高了3倍的动作表示质量。", "conclusion": "通过使用视觉分割掩码来指导LAM训练，可以显著提高模型从复杂场景中提取动作相关特征的能力。"}}
{"id": "2602.02254", "pdf": "https://arxiv.org/pdf/2602.02254", "abs": "https://arxiv.org/abs/2602.02254", "authors": ["Samuel McCauley", "Benjamin Moseley", "Helia Niaparast", "Shikha Singh"], "title": "Stable Matching with Predictions: Robustness and Efficiency under Pruned Preferences", "categories": ["cs.GT", "cs.DS"], "comment": null, "summary": "In this paper, we study the fundamental problem of finding a stable matching in two-sided matching markets. In the classic variant, it is assumed that both sides of the market submit a ranked list of all agents on the other side. However, in large matching markets such as the National Resident Matching Program (NRMP), it is infeasible for hospitals to interview or mutually rank each resident. In this paper, we study the stable matching problem with truncated preference lists. In particular, we assume that, based on historical datasets, each hospital has a predicted rank of its likely match and only ranks residents within a bounded interval around that prediction. We use the algorithms-with-predictions framework and show that the classic deferred-acceptance (DA) algorithm used to compute stable matchings is robust to such truncation. We present two algorithms and theoretically and empirically evaluate their performance. Our results show that even with reasonably accurate predictions, it is possible to significantly cut down on both instance size (the length of preference lists) as well as the number of proposals made. These results explain the practical success of the DA algorithm and connect market design to the emerging theory of algorithms with predictions.", "AI": {"tldr": "本文研究了在匹配市场中基于预测的偏好列表下寻找稳定匹配的问题，提出了两种算法并在理论上和实验上评估其性能。", "motivation": "传统两方匹配问题假设双方会提交对对方所有代理排名的完整名单。然而，在大型市场如国家住院医生分配计划(NRMP)中，医院很难面试或相互排名每个住院医师，因此引入了基于预测的偏好列表以简化这一过程。", "method": "本文采用算法预测框架，提出了两种算法，并通过理论和实验评估其性能，展示了经典延迟接受(DA)算法在处理这种截断时的稳健性。", "result": "结果显示，在合理准确的预测下，可以显著减少实例规模（偏好列表长度）以及提案数量。", "conclusion": "本文工作解释了DA算法的成功，并将市场设计连接到新兴的预测算法理论中。"}}
{"id": "2602.02249", "pdf": "https://arxiv.org/pdf/2602.02249", "abs": "https://arxiv.org/abs/2602.02249", "authors": ["Florentin Putz", "Philipp Fortmann", "Jan Frank", "Christoph Haugwitz", "Mario Kupnik", "Matthias Hollick"], "title": "Evaluating Acoustic Data Transmission Schemes for Ad-Hoc Communication Between Nearby Smart Devices", "categories": ["cs.NI", "cs.SD"], "comment": "31 pages, 9 figures, the dataset is available at https://doi.org/10.5281/zenodo.17661991", "summary": "Acoustic data transmission offers a compelling alternative to Bluetooth and NFC by leveraging the ubiquitous speakers and microphones in smartphones and IoT devices. However, most research in this field relies on simulations or limited on-device testing, which makes the real-world reliability of proposed schemes difficult to assess. We systematically reviewed 31 acoustic communication studies for commodity devices and found that none provided accessible source code. After contacting authors and re-implementing three promising schemes, we assembled a testbed of eight representative acoustic communication systems. Using over 11000 smartphone transmissions in both realistic indoor environments and an anechoic chamber, we provide a systematic and repeatable methodology for evaluating the reliability and generalizability of these schemes under real-world conditions. Our results show that many existing schemes face challenges in practical usage, largely due to severe multipath propagation indoors and varying audio characteristics across device models. To support future research and foster more robust evaluations, we release our re-implementations alongside the first comprehensive dataset of real-world acoustic transmissions. Overall, our findings highlight the importance of rigorous on-device testing and underscore the need for robust design strategies to bridge the gap between simulation results and reliable IoT deployments.", "AI": {"tldr": "系统评估了八种商用声学通信方案在现实环境中的性能。", "motivation": "现有研究多依赖于模拟或有限的设备测试，难以保证提出的方案在实际环境中可靠。", "method": "重新实现了三种有前景的方案，并通过超过11000次智能手机传输测试，在真实室内和消声室中评估了八种声学通信系统。", "result": "许多现有方案在实践中面临挑战，主要原因在于室内多路径传播严重以及不同设备型号间的音频特性差异。", "conclusion": "研究强调了严格的设备测试的重要性，并指出需要更稳健的设计策略以弥合模拟结果与可靠部署之间的差距。"}}
{"id": "2602.02238", "pdf": "https://arxiv.org/pdf/2602.02238", "abs": "https://arxiv.org/abs/2602.02238", "authors": ["Laura Yao", "Gengwei Zhang", "Moajjem Chowdhury", "Yunmei Liu", "Tianlong Chen"], "title": "Geometry- and Relation-Aware Diffusion for EEG Super-Resolution", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent electroencephalography (EEG) spatial super-resolution (SR) methods, while showing improved quality by either directly predicting missing signals from visible channels or adapting latent diffusion-based generative modeling to temporal data, often lack awareness of physiological spatial structure, thereby constraining spatial generation performance. To address this issue, we introduce TopoDiff, a geometry- and relation-aware diffusion model for EEG spatial super-resolution. Inspired by how human experts interpret spatial EEG patterns, TopoDiff incorporates topology-aware image embeddings derived from EEG topographic representations to provide global geometric context for spatial generation, together with a dynamic channel-relation graph that encodes inter-electrode relationships and evolves with temporal dynamics. This design yields a spatially grounded EEG spatial super-resolution framework with consistent performance improvements. Across multiple EEG datasets spanning diverse applications, including SEED/SEED-IV for emotion recognition, PhysioNet motor imagery (MI/MM), and TUSZ for seizure detection, our method achieves substantial gains in generation fidelity and leads to notable improvements in downstream EEG task performance.", "AI": {"tldr": "介绍了一种新的EEG空间超分辨率方法TopoDiff，该方法通过结合几何和关系感知的扩散模型来提高生成精度。", "motivation": "当前EEG空间超分辨率技术通常忽视了生理学空间结构，导致空间生成性能受限。因此提出了TopoDiff，以解决这一问题，提升生成效果。", "method": "TopoDiff采用基于拓扑的图像嵌入和动态通道关系图来提供全局几何上下文，并通过编码电极之间的关系及随时间演化的机制来优化EEG超分辨率。", "result": "实验结果表明，该方法在多个数据集上实现了显著提升，在生成准确性和下游任务性能方面均表现出色。", "conclusion": "TopoDiff作为一种基于几何和关系感知的扩散模型，能够有效改善EEG空间超分辨率，并增强其在多种应用中的表现。"}}
{"id": "2602.02236", "pdf": "https://arxiv.org/pdf/2602.02236", "abs": "https://arxiv.org/abs/2602.02236", "authors": ["Julian Lemmel", "Felix Resch", "Mónika Farsang", "Ramin Hasani", "Daniela Rus", "Radu Grosu"], "title": "Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL", "categories": ["cs.RO", "cs.LG", "cs.NE", "eess.SY"], "comment": null, "summary": "Deploying pretrained policies in real-world applications presents substantial challenges that fundamentally limit the practical applicability of learning-based control systems. When autonomous systems encounter environmental changes in system dynamics, sensor drift, or task objectives, fixed policies rapidly degrade in performance. We show that employing Real-Time Recurrent Reinforcement Learning (RTRRL), a biologically plausible algorithm for online adaptation, can effectively fine-tune a pretrained policy to improve autonomous agents' performance on driving tasks. We further show that RTRRL synergizes with a recent biologically inspired recurrent network model, the Liquid-Resistance Liquid-Capacitance RNN. We demonstrate the effectiveness of this closed-loop approach in a simulated CarRacing environment and in a real-world line-following task with a RoboRacer car equipped with an event camera.", "AI": {"tldr": "本文研究了在自动驾驶任务中，通过实时递归强化学习（RTRRL）在线微调预训练策略的有效性。", "motivation": "当自主系统遇到环境变化、传感器漂移或任务目标更改时，固定政策的性能会迅速下降。因此，需要一种新的方法来适应这些挑战以提高自动驾驶系统的实用性。", "method": "本文提出了使用实时递归强化学习（RTRRL）在线调整预训练策略，并结合了生物启发性的液体电阻-液体电容循环神经网络模型。", "result": "在模拟的CarRacing环境中和使用配备事件相机的真实世界线跟踪任务中，展示了这种方法的有效性。", "conclusion": "实时递归强化学习（RTRRL）可以有效改善自动驾驶系统的性能，并且与生物启发性的循环神经网络结合后效果更佳。"}}
{"id": "2602.02233", "pdf": "https://arxiv.org/pdf/2602.02233", "abs": "https://arxiv.org/abs/2602.02233", "authors": ["Jonas Hummel", "Maximilian Burzer", "Felix Schlotter", "Michael Küttner", "Tobias King", "Qiang Yang", "Cecilia Mascolo", "Michael Beigl", "Tobias Röddiger"], "title": "CHOMP: Multimodal Chewing Side Detection with Earphones", "categories": ["cs.HC"], "comment": null, "summary": "Chewing side preference (CSP) has been identified both as a risk factor for temporomandibular disorders (TMD) and behavioral manifestation. Despite TMDs affecting roughly one third of the global population, assessment mainly relies on clinical examinations and self-reports, offering limited insight into everyday jaw function. Continuous CSP monitoring could provide an objective proxy for functional asymmetries. Prior wearable approaches, however, mostly use specialized form factors and demonstrate limited performance. We therefore present CHOMP, the first system for chewing side detection using earphones. Employing OpenEarable 2.0, we collected data from 20 participants with microphones, a bone-conduction microphone, IMU, PPG, and a pressure sensor across eleven foods, five non-chewing activities, and three noise conditions. We apply the Continuous Wavelet Transform to each sensing modality and use the resulting multi-channel scalograms as inputs to CNN-based classifiers. Microphones achieve the strongest single-sensor unit performance, with median F1 scores of 94.5% in leave-one-food-out (LOFO) and 92.6% in leave-one-subject-out (LOSO) cross-validations. Fusing sensing modalities further improves performance to 97.7% for LOFO and 95.4% for LOSO, with additional evaluations under noise interference indicating robust performance. Our results establish earphones as a practical platform for continuous CSP monitoring, enabling clinicians and patients to assess jaw function in everyday life.", "AI": {"tldr": "本文提出了一种利用耳机进行咀嚼侧别检测的系统CHOMP。", "motivation": "现有的评估方法主要依赖于临床检查和自我报告，无法提供日常下颌功能的客观洞察。连续监测咀嚼侧别可以为功能性不对称性提供一个客观指标。", "method": "采用OpenEarable 2.0收集了来自20名参与者的数据，包括麦克风、骨导麦克风、IMU、PPG和压力传感器，在十一种食物、五种非咀嚼活动以及三种噪声条件下的数据。使用连续小波变换处理每个传感模式，并将所得多通道尺度图作为卷积神经网络分类器的输入。", "result": "单个传感器中，麦克风表现最佳，F1分数在LOFO和LOSO交叉验证下分别为94.5%和92.6%。融合传感模式进一步提高了性能，在LOFO和LOSO条件下达到了97.7%和95.4%，并显示出对噪声干扰的鲁棒性。", "conclusion": "该研究证明了耳机作为连续咀嚼侧别监测平台的实际可行性，使临床医生和患者能够评估日常生活的下颌功能。"}}
{"id": "2602.02232", "pdf": "https://arxiv.org/pdf/2602.02232", "abs": "https://arxiv.org/abs/2602.02232", "authors": ["Andrea Matteazzi", "Dietmar Tutsch"], "title": "LiFlow: Flow Matching for 3D LiDAR Scene Completion", "categories": ["cs.CV"], "comment": null, "summary": "In autonomous driving scenarios, the collected LiDAR point clouds can be challenged by occlusion and long-range sparsity, limiting the perception of autonomous driving systems. Scene completion methods can infer the missing parts of incomplete 3D LiDAR scenes. Recent methods adopt local point-level denoising diffusion probabilistic models, which require predicting Gaussian noise, leading to a mismatch between training and inference initial distributions. This paper introduces the first flow matching framework for 3D LiDAR scene completion, improving upon diffusion-based methods by ensuring consistent initial distributions between training and inference. The model employs a nearest neighbor flow matching loss and a Chamfer distance loss to enhance both local structure and global coverage in the alignment of point clouds. LiFlow achieves state-of-the-art performance across multiple metrics. Code: https://github.com/matteandre/LiFlow.", "AI": {"tldr": "提出了一种基于流匹配的三维LiDAR场景补全框架，改善了扩散模型在训练和推理时初始分布不一致的问题。", "motivation": "解决现有方法中存在的预测高斯噪声导致训练和推断初期分布不一致问题，并提高3D LiDAR场景完成的质量。", "method": "采用最近邻流匹配损失与 Chamfer 距离损失，增强点云在局部结构及全局覆盖上的对齐效果。", "result": "LiFlow 在多个评价指标上实现了最先进的性能。", "conclusion": "通过引入流匹配框架，有效解决了3D LiDAR场景完成中的分布不一致性问题，并提升了整体表现。"}}
{"id": "2602.02230", "pdf": "https://arxiv.org/pdf/2602.02230", "abs": "https://arxiv.org/abs/2602.02230", "authors": ["Ziyu Zhou", "Yuchen Fang", "Weilin Ruan", "Shiyu Wang", "James Kwok", "Yuxuan Liang"], "title": "SEDformer: Event-Synchronous Spiking Transformers for Irregular Telemetry Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Telemetry streams from large-scale Internet-connected systems (e.g., IoT deployments and online platforms) naturally form an irregular multivariate time series (IMTS) whose accurate forecasting is operationally vital. A closer examination reveals a defining Sparsity-Event Duality (SED) property of IMTS, i.e., long stretches with sparse or no observations are punctuated by short, dense bursts where most semantic events (observations) occur. However, existing Graph- and Transformer-based forecasters ignore SED: pre-alignment to uniform grids with heavy padding violates sparsity by inflating sequences and forcing computation at non-informative steps, while relational recasting weakens event semantics by disrupting local temporal continuity. These limitations motivate a more faithful and natural modeling paradigm for IMTS that aligns with its SED property. We find that Spiking Neural Networks meet this requirement, as they communicate via sparse binary spikes and update in an event-driven manner, aligning naturally with the SED nature of IMTS. Therefore, we present SEDformer, an SED-enhanced Spiking Transformer for telemetry IMTS forecasting that couples: (1) a SED-based Spike Encoder converts raw observations into event synchronous spikes using an Event-Aligned LIF neuron, (2) an Event-Preserving Temporal Downsampling module compresses long gaps while retaining salient firings and (3) a stack of SED-based Spike Transformer blocks enable intra-series dependency modeling with a membrane-based linear attention driven by EA-LIF spiking features. Experiments on public telemetry IMTS datasets show that SEDformer attains state-of-the-art forecasting accuracy while reducing energy and memory usage, providing a natural and efficient path for modeling IMTS.", "AI": {"tldr": "SEDformer是一种针对不规则多变量时间序列（IMTS）进行预测的新型事件同步脉冲变换模型。", "motivation": "传统的图和变换器方法在处理不规则时间序列时，忽略了稀疏-事件二元性（SED）特性，通过预对齐到统一网格或关系重铸的方式使得预测不够准确且效率低下。为了更贴近IMTS的真实特性，提出了一种符合SED特性的新型模型。", "method": "该方法利用脉冲神经网络将原始观测值转换为事件同步脉冲，并使用事件驱动的LIF神经元进行编码；同时采用了保留事件的时间下采样模块压缩长间隔数据以保持显著性，最后通过基于膜电位的线性注意力机制建立系列内部依赖关系。", "result": "实验结果表明，SEDformer在公共IMTS数据集上实现了最先进的预测精度，并且减少了能耗和内存使用量。", "conclusion": "SEDformer提供了一种自然高效的路径来建模不规则多变量时间序列，验证了其在实际应用场景中的有效性。"}}
{"id": "2602.02227", "pdf": "https://arxiv.org/pdf/2602.02227", "abs": "https://arxiv.org/abs/2602.02227", "authors": ["Harold Haodong Chen", "Xinxiang Yin", "Wen-Jie Shu", "Hongfei Zhang", "Zixin Zhang", "Chenfei Liao", "Litao Guo", "Qifeng Chen", "Ying-Cong Chen"], "title": "Show, Don't Tell: Morphing Latent Reasoning into Image Generation", "categories": ["cs.CV"], "comment": "Code: https://github.com/EnVision-Research/LatentMorph", "summary": "Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generation--a hallmark of human creativity. Current reasoning-augmented paradigms most rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and re-encoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, a novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) a condenser for summarizing intermediate generation states into compact visual memory, (ii) a translator for converting latent thoughts into actionable guidance, (iii) a shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive self-refinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by $16\\%$ on GenEval and $25\\%$ on T2I-CompBench; (II) outperforms explicit paradigms (e.g., TwiG) by $15\\%$ and $11\\%$ on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by $44\\%$ and token consumption by $51\\%$; and (IV) exhibits $71\\%$ cognitive alignment with human intuition on reasoning invocation.", "AI": {"tldr": "通过引入LatentMorph框架，将隐式推理无缝集成到图像生成过程中，改进了现有文本到图像（T2I）生成方法。", "motivation": "目前的文本到图像生成技术缺乏动态推理和优化能力。现有的方法通常依赖于显式的思维过程，在固定步骤中解码中间推理结果为离散文本，并频繁进行图像解码与重新编码，导致效率低下、信息丢失及认知不匹配问题。LatentMorph旨在解决这些问题。", "method": "LatentMorph框架引入了四个轻量级组件：压缩器用于总结生成的中间状态到紧凑视觉记忆；翻译器将潜在想法转换为可操作指南；塑形器动态引导下一个图像标记预测；增强学习训练的调用者适应性地决定何时进行推理。", "result": "实验结果表明，LatentMorph增强了Janus-Pro模型，在GenEval和T2I-CompBench上的性能分别提升了16%和25%，在抽象推理任务中（如WISE和IPV-Txt）超越了显式范例（例如TwiG），并且减少了44％的推断时间和51％的标记消耗，同时与人类直觉的71％的认知一致性。", "conclusion": "LatentMorph通过在连续潜在空间中执行推理，避免了显式推理带来的瓶颈，并实现了更灵活的自我优化。"}}
{"id": "2602.02224", "pdf": "https://arxiv.org/pdf/2602.02224", "abs": "https://arxiv.org/abs/2602.02224", "authors": ["Georgi Ivanov", "Narmeen Oozeer", "Shivam Raval", "Tasana Pejovic", "Shriyash Upadhyay", "Amir Abdullah"], "title": "Spectral Superposition: A Theory of Feature Geometry", "categories": ["cs.LG", "cs.AI", "math.SP", "stat.ML"], "comment": null, "summary": "Neural networks represent more features than they have dimensions via superposition, forcing features to share representational space. Current methods decompose activations into sparse linear features but discard geometric structure. We develop a theory for studying the geometric structre of features by analyzing the spectra (eigenvalues, eigenspaces, etc.) of weight derived matrices. In particular, we introduce the frame operator $F = WW^\\top$, which gives us a spectral measure that describes how each feature allocates norm across eigenspaces. While previous tools could describe the pairwise interactions between features, spectral methods capture the global geometry (``how do all features interact?''). In toy models of superposition, we use this theory to prove that capacity saturation forces spectral localization: features collapse onto single eigenspaces, organize into tight frames, and admit discrete classification via association schemes, classifying all geometries from prior work (simplices, polygons, antiprisms). The spectral measure formalism applies to arbitrary weight matrices, enabling diagnosis of feature localization beyond toy settings. These results point toward a broader program: applying operator theory to interpretability.", "AI": {"tldr": "该论文提出了通过分析权重派生矩阵的谱（特征值、特征空间等）来研究神经网络中特征几何结构的方法。", "motivation": "当前方法只能将激活分解为稀疏线性特征，但忽略了几何结构。因此，作者希望通过发展一套理论来理解所有特征如何相互作用以及在复杂场景中的局部化问题。", "method": "引入帧操作符$F = WW^\top$作为谱度量工具，研究每个特征如何在不同特征空间中分配范数，并通过玩具模型验证容量饱和会导致特征的局部化和组织成紧密框架。", "result": "证明了在容量饱和的情况下，特征会集中在单一的特征空间上并形成紧密框架，允许通过关联方案实现离散分类。这些结果适用于任意权重矩阵，可以用于诊断复杂场景中的特征定位问题。", "conclusion": "研究提出了一种基于算子理论来解释神经网络中特征几何结构的方法，并指出这可能开启一个更广泛的可解释性研究计划。"}}
{"id": "2602.02223", "pdf": "https://arxiv.org/pdf/2602.02223", "abs": "https://arxiv.org/abs/2602.02223", "authors": ["Junchi Feng", "Nikhil Ballem", "Mahya Beheshti", "Giles Hamilton-Fletcher", "Todd Hudson", "Maurizio Porfiri", "William H. Seiple", "John-Ross Rizzo"], "title": "Evaluating OCR Performance for Assistive Technology: Effects of Walking Speed, Camera Placement, and Camera Type", "categories": ["cs.CV"], "comment": null, "summary": "Optical character recognition (OCR), which converts printed or handwritten text into machine-readable form, is widely used in assistive technology for people with blindness and low vision. Yet, most evaluations rely on static datasets that do not reflect the challenges of mobile use. In this study, we systematically evaluated OCR performance under both static and dynamic conditions. Static tests measured detection range across distances of 1-7 meters and viewing angles of 0-75 degrees horizontally. Dynamic tests examined the impact of motion by varying walking speed from slow (0.8 m/s) to very fast (1.8 m/s) and comparing three camera mounting positions: head-mounted, shoulder-mounted, and hand-held. We evaluated both a smartphone and smart glasses, using the phone's main and ultra-wide cameras. Four OCR engines were benchmarked to assess accuracy at different distances and viewing angles: Google Vision, PaddleOCR 3.0, EasyOCR, and Tesseract. PaddleOCR 3.0 was then used to evaluate accuracy at different walking speeds. Accuracy was computed at the character level using the Levenshtein ratio against manually defined ground truth. Results showed that recognition accuracy declined with increased walking speed and wider viewing angles. Google Vision achieved the highest overall accuracy, with PaddleOCR close behind as the strongest open-source alternative. Across devices, the phone's main camera achieved the highest accuracy, and a shoulder-mounted placement yielded the highest average among body positions; however, differences among shoulder, head, and hand were not statistically significant.", "AI": {"tldr": "评估OCR在辅助技术中的性能，特别是在步行速度、摄像头位置和类型变化下的表现。", "motivation": "大多数OCR评估依赖于静态数据集，未能反映移动使用情况的挑战。为此，研究旨在系统地评估OCR在动态条件下的表现。", "method": "实验包括静态测试（检测范围，1-7米距离及0-75度水平视角）和动态测试（不同步行速度下三种相机安装位置的表现）。四种OCR引擎被用于评估准确性：Google Vision、PaddleOCR 3.0、EasyOCR 和 Tesseract。", "result": "随着步行速度加快和视野角度增加，识别准确率下降。Google Vision表现出最高的总体精度，其次是开放源代码的PaddleOCR 3.0。手机主摄像头在所有设备中实现了最高准确度，肩部安装位置的整体平均值最高；然而，在肩、头及手的位置之间未发现统计学意义上的差异。", "conclusion": "研究展示了OCR技术在动态条件下的表现，并为辅助技术和未来研究提供了有价值的信息和建议。"}}
{"id": "2602.02222", "pdf": "https://arxiv.org/pdf/2602.02222", "abs": "https://arxiv.org/abs/2602.02222", "authors": ["Ruiqi Liu", "Manni Cui", "Ziheng Qin", "Zhiyuan Yan", "Ruoxin Chen", "Yi Han", "Zhiheng Li", "Junkai Chen", "ZhiJin Chen", "Kaiqing Lin", "Jialiang Shen", "Lubin Weng", "Jing Dong", "Yan Wang", "Shu Wu"], "title": "MIRROR: Manifold Ideal Reference ReconstructOR for Generalizable AI-Generated Image Detection", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "High-fidelity generative models have narrowed the perceptual gap between synthetic and real images, posing serious threats to media security. Most existing AI-generated image (AIGI) detectors rely on artifact-based classification and struggle to generalize to evolving generative traces. In contrast, human judgment relies on stable real-world regularities, with deviations from the human cognitive manifold serving as a more generalizable signal of forgery. Motivated by this insight, we reformulate AIGI detection as a Reference-Comparison problem that verifies consistency with the real-image manifold rather than fitting specific forgery cues. We propose MIRROR (Manifold Ideal Reference ReconstructOR), a framework that explicitly encodes reality priors using a learnable discrete memory bank. MIRROR projects an input into a manifold-consistent ideal reference via sparse linear combination, and uses the resulting residuals as robust detection signals. To evaluate whether detectors reach the \"superhuman crossover\" required to replace human experts, we introduce the Human-AIGI benchmark, featuring a psychophysically curated human-imperceptible subset. Across 14 benchmarks, MIRROR consistently outperforms prior methods, achieving gains of 2.1% on six standard benchmarks and 8.1% on seven in-the-wild benchmarks. On Human-AIGI, MIRROR reaches 89.6% accuracy across 27 generators, surpassing both lay users and visual experts, and further approaching the human perceptual limit as pretrained backbones scale. The code is publicly available at: https://github.com/349793927/MIRROR", "AI": {"tldr": "MIRROR框架旨在通过与真实图像流形的一致性来检测AI生成的图像，而非基于特定伪造线索。该方法利用可学习的离散内存库编码现实先验知识，并通过稀疏线性组合将输入映射到理想参考。", "motivation": "现有的AI生成图像检测器依赖于瑕疵分类，在面对不断演化的生成痕迹时难以泛化。人类判断则基于稳定的现实世界规律，偏离这种认知流形的偏差是伪造信号的一个更通用标志。", "method": "MIRROR框架引入了一个可学习的离散记忆库来编码现实先验知识，并通过稀疏线性组合将输入映射到与真实图像流形一致的理想参考上。利用残留作为稳健检测信号。", "result": "在14个基准测试中，MIRROR方法优于先前的方法，在六个标准基准和七个野外基准上分别取得了2.1%和8.1%的提升。在Human-AIGI基准上达到了89.6%的准确率，超过了普通用户和视觉专家。", "conclusion": "MIRROR框架通过编码现实先验知识并使用流形一致性来检测AI生成图像，表现出了更好的泛化能力和更高的准确性。"}}
{"id": "2602.02220", "pdf": "https://arxiv.org/pdf/2602.02220", "abs": "https://arxiv.org/abs/2602.02220", "authors": ["Bo Miao", "Weijia Liu", "Jun Luo", "Lachlan Shinnick", "Jian Liu", "Thomas Hamilton-Smith", "Yuhe Yang", "Zijie Wu", "Vanja Videnovic", "Feras Dayoub", "Anton van den Hengel"], "title": "LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The relationships between objects and language are fundamental to meaningful communication between humans and AI, and to practically useful embodied intelligence. We introduce HieraNav, a multi-granularity, open-vocabulary goal navigation task where agents interpret natural language instructions to reach targets at four semantic levels: scene, room, region, and instance. To this end, we present Language as a Map (LangMap), a large-scale benchmark built on real-world 3D indoor scans with comprehensive human-verified annotations and tasks spanning these levels. LangMap provides region labels, discriminative region descriptions, discriminative instance descriptions covering 414 object categories, and over 18K navigation tasks. Each target features both concise and detailed descriptions, enabling evaluation across different instruction styles. LangMap achieves superior annotation quality, outperforming GOAT-Bench by 23.8% in discriminative accuracy using four times fewer words. Comprehensive evaluations of zero-shot and supervised models on LangMap reveal that richer context and memory improve success, while long-tailed, small, context-dependent, and distant goals, as well as multi-goal completion, remain challenging. HieraNav and LangMap establish a rigorous testbed for advancing language-driven embodied navigation. Project: https://bo-miao.github.io/LangMap", "AI": {"tldr": "介绍了一个名为LangMap的大规模基准测试，用于评估在多粒度开放词汇目标导航任务中语言和视觉理解能力的模型。", "motivation": "提高人类与AI之间的有意义沟通及实际有用的实体智能，特别是通过自然语言指令引导到不同语义层次的目标的能力", "method": "构建了一个名为LangMap的大规模基准测试，基于真实世界的3D室内扫描数据，并包含详尽的人工验证标注和任务。", "result": "LangMap在识别准确性上优于GOAT-Bench23.8%，使用四倍少的单词数。零样本及监督模型的表现显示了丰富背景和记忆的重要性。", "conclusion": "HieraNav和LangMap提供了一个严格的测试平台，以推动语言驱动的实体导航研究进步"}}
{"id": "2602.02214", "pdf": "https://arxiv.org/pdf/2602.02214", "abs": "https://arxiv.org/abs/2602.02214", "authors": ["Hongzhou Zhu", "Min Zhao", "Guande He", "Hang Su", "Chongxuan Li", "Jun Zhu"], "title": "Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation", "categories": ["cs.CV"], "comment": "Project page and the code: \\href{https://thu-ml.github.io/CausalForcing.github.io/}{https://thu-ml.github.io/CausalForcing.github.io/}", "summary": "To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\\% in Dynamic Degree, 8.7\\% in VisionReward, and 16.7\\% in Instruction Following. Project page and the code: \\href{https://thu-ml.github.io/CausalForcing.github.io/}{https://thu-ml.github.io/CausalForcing.github.io/}", "AI": {"tldr": "该论文提出了一种名为Causal Forcing的技术，用于将预训练的双向视频扩散模型提炼为高质量的实时互动视频生成器。", "motivation": "现有的方法在尝试通过自回归模型进行双向视频扩散模型的提炼时，未能理论性地解决架构差距问题。现有技术可能会导致性能下降的问题需要解决。", "method": "论文提出Causal Forcing方法，利用自回归教师初始化ODE（常微分方程），从而弥补了架构上的鸿沟，并成功提升了互动视频生成的质量和实时性。", "result": "实验结果表明，该方法在Dynamic Degree、VisionReward以及Instruction Following三个指标上均优于所有基准线，特别是在动态度量上超越SOTA Self Forcing达19.3%。", "conclusion": "通过Causal Forcing技术的应用，论文展示了有效解决自回归模型提炼过程中出现的架构差距问题，并显著提升了交互式视频生成的效果。"}}
{"id": "2602.02213", "pdf": "https://arxiv.org/pdf/2602.02213", "abs": "https://arxiv.org/abs/2602.02213", "authors": ["Gregory Barber", "Todd C. Henry", "Mulugeta A. Haile"], "title": "Generating Physically Sound Designs from Text and a Set of Physical Constraints", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS 2025", "summary": "We present TIDES, a text informed design approach for generating physically sound designs based on a textual description and a set of physical constraints. TIDES jointly optimizes structural (topology) and visual properties. A pre-trained text-image model is used to measure the design's visual alignment with a text prompt and a differentiable physics simulator is used to measure its physical performance. We evaluate TIDES on a series of structural optimization problems operating under different load and support conditions, at different resolutions, and experimentally in the lab by performing the 3-point bending test on 2D beam designs that are extruded and 3D printed. We find that it can jointly optimize the two objectives and return designs that satisfy engineering design requirements (compliance and density) while utilizing features specified by text.", "AI": {"tldr": "TIDES是一种基于文本描述和物理约束生成符合工程设计要求的物理上合理的设计的方法。", "motivation": "为了在给定的文本描述和物理限制下，同时优化设计的结构（拓扑）和视觉属性，从而满足工程技术需求。", "method": "使用预训练的文字图像模型评估设计与文本提示的一致性，并利用可微分的物理模拟器衡量其物理性能。通过这种方式，TIDES能够联合优化两个目标并生成符合要求的设计。", "result": "在一系列结构优化问题中，TIDES表现良好，满足工程设计要求（包括合规性和密度），并且实验结果表明实际3D打印的产品也满足预期性能。", "conclusion": "TIDES提供了一种有效的文本驱动的物理设计方法，可以同时考虑视觉和物理性能。"}}
{"id": "2602.02212", "pdf": "https://arxiv.org/pdf/2602.02212", "abs": "https://arxiv.org/abs/2602.02212", "authors": ["Zheyuan Zhou", "Liang Du", "Zixun Sun", "Xiaoyu Zhou", "Ruimin Ye", "Qihao Chen", "Yinda Chen", "Lemiao Qiu"], "title": "MAIN-VLA: Modeling Abstraction of Intention and eNvironment for Vision-Language-Action Models", "categories": ["cs.CV"], "comment": null, "summary": "Despite significant progress in Visual-Language-Action (VLA), in highly complex and dynamic environments that involve real-time unpredictable interactions (such as 3D open worlds and large-scale PvP games), existing approaches remain inefficient at extracting action-critical signals from redundant sensor streams. To tackle this, we introduce MAIN-VLA, a framework that explicitly Models the Abstraction of Intention and eNvironment to ground decision-making in deep semantic alignment rather than superficial pattern matching. Specifically, our Intention Abstraction (IA) extracts verbose linguistic instructions and their associated reasoning into compact, explicit semantic primitives, while the Environment Semantics Abstraction (ESA) projects overwhelming visual streams into a structured, topological affordance representation. Furthermore, aligning these two abstract modalities induces an emergent attention-concentration effect, enabling a parameter-free token-pruning strategy that filters out perceptual redundancy without degrading performance. Extensive experiments in open-world Minecraft and large-scale PvP environments (Game for Peace and Valorant) demonstrate that MAIN-VLA sets a new state-of-the-art, which achieves superior decision quality, stronger generalization, and cutting-edge inference efficiency.", "AI": {"tldr": "介绍了一种用于视觉语言行动模型的框架MAIN-VLA，该框架通过建模意图和环境来提高在复杂动态环境中决策的质量和效率。", "motivation": "现有的VLA方法在处理复杂、多变且实时交互的环境中存在信号提取效率低下问题。为解决这些问题，需要一种能够有效抽取关键行动信息并减少感知冗余的方法。", "method": "提出了一个框架MAIN-VLA，通过意图抽象（IA）和环境语义抽象（ESA），将复杂的语言指令和视觉流转化为简洁、结构化的表示形式，并进行深度的语义对齐。这种方法提升了注意力集中效应并且实现了一种无参数的令牌修剪策略。", "result": "实验显示，在Minecraft、Game for Peace和Valorant等开放世界环境中，MAIN-VLA框架在决策质量、泛化能力以及推理效率方面达到了新的最优水平。", "conclusion": "通过建模意图和环境抽象来改进视觉语言行动模型可以显著提高其在复杂动态环境中的性能。"}}
{"id": "2602.02208", "pdf": "https://arxiv.org/pdf/2602.02208", "abs": "https://arxiv.org/abs/2602.02208", "authors": ["Md. Toufique Hasan", "Ayman Asad Khan", "Mika Saari", "Vaishnavi Bankhele", "Pekka Abrahamsson"], "title": "Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.SE"], "comment": "6 pages, 2 figures, submitted to MIPRO 2026", "summary": "Large language models show promise for knowledge-intensive domains, yet their use in agriculture is constrained by weak grounding, English-centric training data, and limited real-world evaluation. These issues are amplified for low-resource languages, where high-quality domain documentation exists but remains difficult to access through general-purpose models. This paper presents AgriHubi, a domain-adapted retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support. AgriHubi integrates Finnish agricultural documents with open PORO family models and combines explicit source grounding with user feedback to support iterative refinement. Developed over eight iterations and evaluated through two user studies, the system shows clear gains in answer completeness, linguistic accuracy, and perceived reliability. The results also reveal practical trade-offs between response quality and latency when deploying larger models. This study provides empirical guidance for designing and evaluating domain-specific RAG systems in low-resource language settings.", "AI": {"tldr": "该论文提出了一个针对芬兰语农业领域的检索增强生成系统AgriHubi，以解决大型语言模型在特定领域应用中的问题。", "motivation": "现有大型语言模型在知识密集型领域（如农业）的应用受限于弱实体关联、英语为主的训练数据以及现实世界的评估不足。这些问题在低资源语言环境下尤为突出，高质量的领域文档难以通过通用模型获取。", "method": "AgriHubi系统整合了芬兰语农业文献与开放的PORO家族模型，并结合明确来源标注和用户反馈进行迭代优化。该系统经过八次迭代并通过两次用户研究进行评估。", "result": "结果显示，相较于基准模型，AgriHubi在答案完整性和语言准确性方面取得了显著提升，同时用户认为其更具可靠性。然而，在部署更大规模的模型时，也面临着质量与延迟之间的实际权衡。", "conclusion": "该论文为设计和评估低资源语言环境下的领域特定RAG系统提供了实证指导"}}
{"id": "2602.02201", "pdf": "https://arxiv.org/pdf/2602.02201", "abs": "https://arxiv.org/abs/2602.02201", "authors": ["Abhijit Gupta"], "title": "Cardinality-Preserving Structured Sparse Graph Transformers for Molecular Property Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Drug discovery motivates efficient molecular property prediction under limited labeled data. Chemical space is vast, often estimated at approximately 10^60 drug-like molecules, while only thousands of drugs have been approved. As a result, self-supervised pretraining on large unlabeled molecular corpora has become essential for data-efficient molecular representation learning. We introduce **CardinalGraphFormer**, a graph transformer that incorporates Graphormer-inspired structural biases, including shortest-path distance and centrality, as well as direct-bond edge bias, within a structured sparse attention regime limited to shortest-path distance <= 3. The model further augments this design with a cardinality-preserving unnormalized aggregation channel over the same support set. Pretraining combines contrastive graph-level alignment with masked attribute reconstruction. Under a fully matched evaluation protocol, CardinalGraphFormer improves mean performance across all 11 evaluated tasks and achieves statistically significant gains on 10 of 11 public benchmarks spanning MoleculeNet, OGB, and TDC ADMET tasks when compared to strong reproduced baselines.", "AI": {"tldr": "本文提出了一种新的分子属性预测模型CardinalGraphFormer，该模型在大规模未标记数据集上进行自监督预训练，并通过对比图级对齐和掩码特征重建来提高性能。", "motivation": "药物发现需要高效地利用有限的标注数据来进行分子属性预测。由于化学空间巨大且已批准的药物数量相对较少，因此有必要利用大量未标记的数据集进行自我监督预训练。", "method": "CardinalGraphFormer是一种基于图变换器模型，结合了Graphormer启发式的结构偏差和卡方保持聚合信道的设计，并在最短路径距离≤3范围内限制稀疏注意机制。预训练采用了对比图级对齐与掩码特征重建的方法。", "result": "在所有11个评估任务中，CardinalGraphFormer的平均性能得到了提升，在其中10个公共基准测试上实现了统计显著性增益。", "conclusion": "该模型通过引入新的设计和预训练方法，提高了分子属性预测的效果。"}}
{"id": "2602.02199", "pdf": "https://arxiv.org/pdf/2602.02199", "abs": "https://arxiv.org/abs/2602.02199", "authors": ["Aryan Sood", "Tanvi Sharma", "Vansh Agrawal"], "title": "More Than a Quick Glance: Overcoming the Greedy Bias in KV-Cache Compression", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While Large Language Models (LLMs) can theoretically support extensive context windows, their actual deployment is constrained by the linear growth of Key-Value (KV) cache memory. Prevailing compression strategies mitigate this through various pruning mechanisms, yet trade-off semantic recall for memory efficiency. In this work, we present LASER-KV (Layer Accumulated Selection with Exact-LSH Recall), a framework designed to test the limits of KV compression under a strict accumulative budgeting policy. We deviate from the standard fixed summary size approach by implementing a block-wise accumulation strategy governed by a protection divisor (n). This allows us to isolate the effects of compression from sliding window artifacts. Our experiments on the Babilong benchmark reveal performance degradation in previous compression methods by 15-30% on various long context tasks. LASER-KV maintains stable performance, achieving superior accuracies by a margin of upto 10% at 128k. These findings challenge the prevailing assumption that attention scores alone are a sufficient proxy for token utility.", "AI": {"tldr": "本文提出了LASER-KV框架，通过分块累积策略和保护除数来优化KV缓存压缩，挑战了注意力分数作为令牌效用的充分代理这一假设。", "motivation": "现有的KV缓存压缩方法在提高内存效率的同时牺牲了语义回忆，本文旨在探索一种新的压缩策略以克服这种贪婪偏差，并证明单纯依赖注意力分数不足以衡量令牌的重要性。", "method": "LASER-KV采用分块累积策略并引入保护除数来优化KV缓存的压缩过程，从而减少滑动窗口效应带来的性能损失。该方法不固定摘要大小，而是根据具体情况动态调整以实现更好的平衡。", "result": "实验结果显示，在Babilong基准测试中，与其他压缩方法相比，LASER-KV在多种长上下文任务上保持了稳定的性能，并且提高了10%的准确率。", "conclusion": "通过引入新的累积策略和保护机制，本文提出的LASER-KV框架能够更有效地处理KV缓存的压缩问题，证明了注意力分数并不是评估令牌效用的唯一指标。"}}
{"id": "2602.02198", "pdf": "https://arxiv.org/pdf/2602.02198", "abs": "https://arxiv.org/abs/2602.02198", "authors": ["Seyed Ali Ghazi Asgar", "Narasimha Reddy"], "title": "QuietPrint: Protecting 3D Printers Against Acoustic Side-Channel Attacks", "categories": ["cs.CR", "eess.AS"], "comment": null, "summary": "The 3D printing market has experienced significant growth in recent years, with an estimated revenue of 15 billion USD for 2025. Cyber-attacks targeting the 3D printing process whether through the machine itself, the supply chain, or the fabricated components are becoming increasingly common. One major concern is intellectual property (IP) theft, where a malicious attacker gains access to the design file. One method for carrying out such theft is through side-channel attacks. In this work, we investigate the possibility of IP theft via acoustic side channels and propose a novel method to protect 3D printers against such attacks. The primary advantage of our approach is that it requires no additional hardware, such as large speakers or noise-canceling devices. Instead, it secures printed parts by minimal modifications to the G-code.", "AI": {"tldr": "研究通过修改G代码来保护3D打印机免受声学侧信道攻击，以防止知识产权被盗。", "motivation": "随着3D打印市场的增长，针对3D打印过程的网络攻击变得越来越普遍。其中一种主要威胁是通过声学侧信道进行的知识产权盗窃，该研究旨在提出一种无需额外硬件的方法来保护打印机。", "method": "通过对G代码进行最小化修改，以防止从声音中泄露敏感信息，从而实现对3D打印机的保护。", "result": "研究表明，可以通过简单地调整打印过程中的参数来有效减少声学信号的信息量，从而提高安全性。", "conclusion": "提出的方法展示了在不使用额外硬件的情况下增强3D打印机安全性的可行性。"}}
{"id": "2602.02197", "pdf": "https://arxiv.org/pdf/2602.02197", "abs": "https://arxiv.org/abs/2602.02197", "authors": ["Xindian Ma", "Yidi Lu", "Peng Zhang", "Jing Zhang"], "title": "Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "10 oages, 3 figures", "summary": "The integration of visual information into Large Language Models (LLMs) has enabled Multimodal LLMs (MLLMs), but the quadratic memory and computational costs of Transformer architectures remain a bottleneck. Existing KV cache eviction strategies fail to address the heterogeneous attention distributions between visual and text tokens, leading to suboptimal efficiency or degraded performance. In this paper, we propose Hierarchical Adaptive Eviction (HAE), a KV cache eviction framework that optimizes text-visual token interaction in MLLMs by implementing Dual-Attention Pruning during pre-filling (leveraging visual token sparsity and attention variance) and a Dynamic Decoding Eviction Strategy (inspired by OS Recycle Bins) during decoding. HAE minimizes KV cache usage across layers, reduces computational overhead via index broadcasting, and theoretically ensures superior information integrity and lower error bounds compared to greedy strategies, enhancing efficiency in both comprehension and generation tasks. Empirically, HAE reduces KV-Cache memory by 41\\% with minimal accuracy loss (0.3\\% drop) in image understanding tasks and accelerates story generation inference by 1.5x while maintaining output quality on Phi3.5-Vision-Instruct model.", "AI": {"tldr": "提出了一种适应性层级缓存驱逐框架HAE，用于优化多模态大语言模型中的文本-视觉令牌交互", "motivation": "现有KV缓存驱逐策略无法有效处理文本和视觉标记间的异质注意力分布，导致效率低下或性能下降。为此，设计了一个新的框架来解决这个问题并提高系统的整体性能。", "method": "提出了一种层次化自适应驱逐(HAE)方法，在填充阶段利用双关注修剪，并在解码时采用动态解码驱逐策略，通过索引广播减少计算负担，确保信息完整性和降低误差界限优于贪婪策略。", "result": "实验证明HAE可将KV缓存内存使用量降低41%，同时仅损失0.3%的准确性，在图像理解任务中表现良好，并使故事生成推理加速1.5倍，保持输出质量。", "conclusion": "通过优化多模态大语言模型中的文本-视觉令牌交互，HAE在减少计算负担的同时提高了系统性能和效率。"}}
{"id": "2602.02196", "pdf": "https://arxiv.org/pdf/2602.02196", "abs": "https://arxiv.org/abs/2602.02196", "authors": ["Hang Yan", "Xinyu Che", "Fangzhi Xu", "Qiushi Sun", "Zichen Ding", "Kanzhi Cheng", "Jian Zhang", "Tao Qin", "Jun Liu", "Qika Lin"], "title": "TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents", "categories": ["cs.AI"], "comment": "29pages, 10 figures", "summary": "Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency, behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.", "AI": {"tldr": "提出一种用于评估LLM代理在测试时间改进过程中表现的框架TIDE，该框架能够详细分析任务完成的时间动态和内存负担。", "motivation": "当前对于自主LLM代理通过迭代交互提高性能的过程理解不足，现有的评价指标无法全面衡量其优化效率及适应错误行为的能力。因此开发了一种通用评估框架以填补这些空白。", "method": "TIDE是一个环境无关的代理诊断评估框架，分解了测试时间改进为三个维度：总体任务完成的时间动态、是否受限于循环行为以及内存负担。通过在不同环境中进行广泛实验来验证。", "result": "结果表明提高LLM代理性能不仅仅是增加内部推理能力的问题，还需要优化代理与环境之间的交互动力学。", "conclusion": "TIDE框架为理解和改进自主LLM代理的测试时间改进提供了有效手段，揭示了需要通过调整代理和环境间的相互作用来提升总体表现。"}}
{"id": "2602.02195", "pdf": "https://arxiv.org/pdf/2602.02195", "abs": "https://arxiv.org/abs/2602.02195", "authors": ["Ao Sun", "Hongtao Zhang", "Heng Zhou", "Yixuan Ma", "Yiran Qin", "Tongrui Su", "Yan Liu", "Zhanyu Ma", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He"], "title": "State Rank Dynamics in Linear Attention LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Linear Attention Large Language Models (LLMs) offer a compelling recurrent formulation that compresses context into a fixed-size state matrix, enabling constant-time inference. However, the internal dynamics of this compressed state remain largely opaque. In this work, we present a comprehensive study on the runtime state dynamics of state-of-the-art Linear Attention models. We uncover a fundamental phenomenon termed State Rank Stratification, characterized by a distinct spectral bifurcation among linear attention heads: while one group maintains an effective rank oscillating near zero, the other exhibits rapid growth that converges to an upper bound. Extensive experiments across diverse inference contexts reveal that these dynamics remain strikingly consistent, indicating that the identity of a head,whether low-rank or high-rank,is an intrinsic structural property acquired during pre-training, rather than a transient state dependent on the input data. Furthermore, our diagnostic probes reveal a surprising functional divergence: low-rank heads are indispensable for model reasoning, whereas high-rank heads exhibit significant redundancy. Leveraging this insight, we propose Joint Rank-Norm Pruning, a zero-shot strategy that achieves a 38.9\\% reduction in KV-cache overhead while largely maintaining model accuracy.", "AI": {"tldr": "线性注意力LLM的内部状态动态研究，揭示了低秩和高秩头部的功能差异，并提出了一种零样本修剪策略。", "motivation": "线性注意模型的压缩状态机理仍不清楚。作者通过研究不同推理上下文中这些模型的状态变化来探索其内在属性。", "method": "作者进行了广泛的实验以发现线性注意力头的行为模式，揭示了低秩和高秩头部的功能差异，并提出了Joint Rank-Norm Pruning策略。", "result": "该工作揭示了一种称为状态秩分化的现象，并展示了低秩头部对模型推理的重要性。提出的修剪方法在减少KV缓存开销的同时保持了较高的准确率。", "conclusion": "线性注意力头部的低秩和高秩特性是预训练过程中固有的，而非输入数据驱动的结果。利用这一发现可以有效减少计算资源消耗，并保持模型性能。"}}
{"id": "2602.02193", "pdf": "https://arxiv.org/pdf/2602.02193", "abs": "https://arxiv.org/abs/2602.02193", "authors": ["Chen Min", "Enze Jiang", "Jishen Peng", "Zheng Ma"], "title": "SSI-DM: Singularity Skipping Inversion of Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Inverting real images into the noise space is essential for editing tasks using diffusion models, yet existing methods produce non-Gaussian noise with poor editability due to the inaccuracy in early noising steps. We identify the root cause: a mathematical singularity that renders inversion fundamentally ill-posed. We propose Singularity Skipping Inversion of Diffusion Models (SSI-DM), which bypasses this singular region by adding small noise before standard inversion. This simple approach produces inverted noise with natural Gaussian properties while maintaining reconstruction fidelity. As a plug-and-play technique compatible with general diffusion models, our method achieves superior performance on public image datasets for reconstruction and interpolation tasks, providing a principled and efficient solution to diffusion model inversion.", "AI": {"tldr": "本文提出了SSI-DM方法，通过跳过扩散模型逆向过程中数学奇点的区域来改善噪声空间中的图像重建和编辑任务。", "motivation": "现有方法在早期加噪步骤中存在不准确性，导致生成非高斯噪声并影响编辑效果。作者识别了这一问题的根本原因，并提出了一个解决策略以提高逆向过程的质量。", "method": "通过在标准逆向过程之前添加少量噪音来跳过奇异区域的方法，这种方法可以生成具有自然高斯特性的倒置噪声同时保持重建保真度。作为一种与通用扩散模型兼容的插件技术，它可以显著改进图像恢复和插值任务的表现。", "result": "该方法在公共图像数据集上的重构和内插任务中表现出色，证明了其有效性和效率。", "conclusion": "本文通过简单且有效的手段解决了逆向过程中遇到的基本数学难题，并展示了这种方法对于改善扩散模型编辑性能的重要性与潜力。"}}
{"id": "2602.02188", "pdf": "https://arxiv.org/pdf/2602.02188", "abs": "https://arxiv.org/abs/2602.02188", "authors": ["Xia Jiang", "Jing Chen", "Cong Zhang", "Jie Gao", "Chengpeng Hu", "Chenhao Zhang", "Yaoxin Wu", "Yingqian Zhang"], "title": "Reasoning in a Combinatorial and Constrained World: Benchmarking LLMs on Natural-Language Combinatorial Optimization", "categories": ["cs.AI"], "comment": null, "summary": "While large language models (LLMs) have shown strong performance in math and logic reasoning, their ability to handle combinatorial optimization (CO) -- searching high-dimensional solution spaces under hard constraints -- remains underexplored. To bridge the gap, we introduce NLCO, a \\textbf{N}atural \\textbf{L}anguage \\textbf{C}ombinatorial \\textbf{O}ptimization benchmark that evaluates LLMs on end-to-end CO reasoning: given a language-described decision-making scenario, the model must output a discrete solution without writing code or calling external solvers. NLCO covers 43 CO problems and is organized using a four-layer taxonomy of variable types, constraint families, global patterns, and objective classes, enabling fine-grained evaluation. We provide solver-annotated solutions and comprehensively evaluate LLMs by feasibility, solution optimality, and reasoning efficiency. Experiments across a wide range of modern LLMs show that high-performing models achieve strong feasibility and solution quality on small instances, but both degrade as instance size grows, even if more tokens are used for reasoning. We also observe systematic effects across the taxonomy: set-based tasks are relatively easy, whereas graph-structured problems and bottleneck objectives lead to more frequent failures.", "AI": {"tldr": "本文介绍了NLCO基准测试，用于评估大型语言模型在自然语言组合优化任务上的性能。", "motivation": "尽管大型语言模型在数学和逻辑推理方面表现出色，但它们处理组合优化问题的能力尚待探索。为了填补这一空白，作者引入了NLCO基准测试来全面评估这些模型的性能。", "method": "通过43个不同类型的组合优化问题对现代大型语言模型进行详尽评估，这些问题按照变量类型、约束家族、全局模式和目标类别进行了分类。", "result": "实验表明，在较小实例中，高性能模型能够实现较高的可行性和解决方案质量；然而随着实例大小的增长，性能逐渐下降。此外，在基于集合的任务方面较为容易，而图结构任务和瓶颈目标则更为困难。", "conclusion": "NLCO基准测试揭示了大型语言模型在自然语言组合优化任务中的表现，并指出了未来改进的方向。"}}
{"id": "2602.02186", "pdf": "https://arxiv.org/pdf/2602.02186", "abs": "https://arxiv.org/abs/2602.02186", "authors": ["Ziqiao Weng", "Jiancheng Yang", "Kangxian Xie", "Bo Zhou", "Weidong Cai"], "title": "Learning Topology-Aware Implicit Field for Unified Pulmonary Tree Modeling with Incomplete Topological Supervision", "categories": ["cs.CV"], "comment": "18 pages, 7 figures", "summary": "Pulmonary trees extracted from CT images frequently exhibit topological incompleteness, such as missing or disconnected branches, which substantially degrades downstream anatomical analysis and limits the applicability of existing pulmonary tree modeling pipelines. Current approaches typically rely on dense volumetric processing or explicit graph reasoning, leading to limited efficiency and reduced robustness under realistic structural corruption. We propose TopoField, a topology-aware implicit modeling framework that treats topology repair as a first-class modeling problem and enables unified multi-task inference for pulmonary tree analysis. TopoField represents pulmonary anatomy using sparse surface and skeleton point clouds and learns a continuous implicit field that supports topology repair without relying on complete or explicit disconnection annotations, by training on synthetically introduced structural disruptions over \\textit{already} incomplete trees. Building upon the repaired implicit representation, anatomical labeling and lung segment reconstruction are jointly inferred through task-specific implicit functions within a single forward pass.Extensive experiments on the Lung3D+ dataset demonstrate that TopoField consistently improves topological completeness and achieves accurate anatomical labeling and lung segment reconstruction under challenging incomplete scenarios. Owing to its implicit formulation, TopoField attains high computational efficiency, completing all tasks in just over one second per case, highlighting its practicality for large-scale and time-sensitive clinical applications. Code and data will be available at https://github.com/HINTLab/TopoField.", "AI": {"tldr": "本文提出了一种用于肺部树建模的拓扑感知隐式字段框架TopoField，该框架能够处理CT图像中肺部结构不完整的挑战性场景。", "motivation": "当前方法依赖于密集体素处理或显式图推理，导致效率低下且在现实世界结构性破坏下鲁棒性不足。为此，本文提出了一种新的拓扑感知隐式建模框架来解决这一问题。", "method": "TopoField通过学习连续的隐式场来表示肺部解剖结构，并使用稀疏表面和骨架点云进行处理，在不依赖完整或显式的断开注释的情况下执行拓扑修复。在已有的不完整的树上通过合成引入结构性破坏进行训练。", "result": "实验结果表明，TopoField在所有任务中均表现出色，包括拓扑完整性、解剖学标记和肺段重建，在挑战性场景下表现尤为突出，并且能够在不到一秒的时间内完成所有任务，显示出其临床应用的实用性。", "conclusion": "通过引入隐式场修复的概念并联合进行解剖标签和肺部分割的任务推理，TopoField不仅提高了拓扑完整性和准确性，还具有高计算效率，适用于大规模和时间敏感的应用场景。"}}
{"id": "2602.02185", "pdf": "https://arxiv.org/pdf/2602.02185", "abs": "https://arxiv.org/abs/2602.02185", "authors": ["Yu Zeng", "Wenxuan Huang", "Zhen Fang", "Shuang Chen", "Yufan Shen", "Yishuo Cai", "Xiaoman Wang", "Zhenfei Yin", "Lin Chen", "Zehui Chen", "Shiting Huang", "Yiming Zhao", "Yao Hu", "Philip Torr", "Wanli Ouyang", "Shaosheng Cao"], "title": "Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch.", "AI": {"tldr": "构建了一个新的视觉和文本搜索基准VDR-Bench，并提出了一种改进的多轮裁剪检索工作流以评估多模态大型语言模型（MLLM）的能力。", "motivation": "现有的评估基准不能充分测试MLLM的视觉搜索能力，且过于理想化的场景不足以挑战系统。因此构建新的基准以提高真实性并解决现有问题。", "method": "设计了一个包含2000个VQA实例的新基准，同时提出了一个简单有效的多轮裁剪检索工作流来改进模型在现实中的表现。", "result": "新方法提高了模型在复杂视觉和文本搜索任务上的性能，并为未来的设计提供了实用指南。", "conclusion": "通过引入新的评估标准和策略，该研究有助于理解和优化多模态系统的搜索能力。"}}
{"id": "2602.02184", "pdf": "https://arxiv.org/pdf/2602.02184", "abs": "https://arxiv.org/abs/2602.02184", "authors": ["Sarah Nassar"], "title": "Malware Detection Through Memory Analysis", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper summarizes the research conducted for a malware detection project using the Canadian Institute for Cybersecurity's MalMemAnalysis-2022 dataset. The purpose of the project was to explore the effectiveness and efficiency of machine learning techniques for the task of binary classification (i.e., benign or malicious) as well as multi-class classification to further include three malware sub-types (i.e., benign, ransomware, spyware, or Trojan horse). The XGBoost model type was the final model selected for both tasks due to the trade-off between strong detection capability and fast inference speed. The binary classifier achieved a testing subset accuracy and F1 score of 99.98\\%, while the multi-class version reached an accuracy of 87.54\\% and an F1 score of 81.26\\%, with an average F1 score over the malware sub-types of 75.03\\%. In addition to the high modelling performance, XGBoost is also efficient in terms of classification speed. It takes about 37.3 milliseconds to classify 50 samples in sequential order in the binary setting and about 43.2 milliseconds in the multi-class setting. The results from this research project help advance the efforts made towards developing accurate and real-time obfuscated malware detectors for the goal of improving online privacy and safety. *This project was completed as part of ELEC 877 (AI for Cybersecurity) in the Winter 2024 term.", "AI": {"tldr": "该论文通过使用加拿大网络安全研究所的MalMemAnalysis-2022数据集，研究了利用机器学习技术进行恶意软件检测的有效性和效率。", "motivation": "该项目旨在探索在二元分类（良性或恶意）和多类分类中（包含三种恶意软件子类型：良性、勒索软件、间谍软件或特洛伊木马）使用机器学习技术的效果与效率。此外，研究还关注了如何开发准确且实时的混淆恶意软件检测器。", "method": "最终选择了XGBoost模型用于二元分类和多类分类任务，因为它在检测能力与推理速度之间取得了平衡。通过测试子集验证了模型性能并评估了其准确性及F1分数。", "result": "二元分类器的测试子集准确率为99.98%，而多类别版本的准确率达到了87.54%和F1分数为81.26%，平均来说，对于恶意软件子类型的F1分数为75.03%。在二进制设置下对50个样本进行分类大约需要37.3毫秒，在多类别设置下则需约43.2毫秒。", "conclusion": "研究结果表明XGBoost模型不仅具有高精度，而且还能实现实时的检测速度。这有助于提高网络隐私与安全水平。"}}
{"id": "2602.02181", "pdf": "https://arxiv.org/pdf/2602.02181", "abs": "https://arxiv.org/abs/2602.02181", "authors": ["Elad Siman Tov", "Nili E. Krausz"], "title": "Extending the Law of Intersegmental Coordination: Implications for Powered Prosthetic Controls", "categories": ["cs.RO"], "comment": "Submitted to 2026 IEEE International Conference on Biomedical Robotics and Biomechatronics (BioRob)", "summary": "Powered prostheses are capable of providing net positive work to amputees and have advanced in the past two decades. However, reducing amputee metabolic cost of walking remains an open problem. The Law of Intersegmental Coordination (ISC) has been observed across gaits and has been previously implicated in energy expenditure of walking, yet it has rarely been analyzed or applied within the context of lower-limb amputee gait. This law states that the elevation angles of the thigh, shank and foot over the gait cycle are not independent. In this work, we developed a method to analyze intersegmental coordination for lower-limb 3D kinematic data, to simplify ISC analysis. Moreover, inspired by motor control, biomechanics and robotics literature, we used our method to broaden ISC toward a new law of coordination of moments. We find these Elevation Space Moments (ESM), and present results showing a moment-based coordination for able bodied gait. We also analyzed ISC for amputee gait walking with powered and passive prosthesis, and found that while elevation angles remained planar, the ESM showed less coordination. We use ISC as a constraint to predict the shank angles/moments that would compensate for alterations due to a passive foot so as to mimic a healthy thigh angle/moment profile. This may have implications for improving powered prosthetic control. We developed the ISC3d toolbox that is freely available online, which may be used to compute kinematic and kinetic ISC in 3D. This provides a means to further study the role of coordination in gait and may help address fundamental questions of the neural control of human movement.", "AI": {"tldr": "本文发展了一种方法来分析截肢者和健全人的下肢三维运动学数据中的段间协调，并将其应用于改善动力假肢的控制。", "motivation": "减少截肢者的行走代谢成本仍然是一个未解决的问题，而现有的关于步态中节段协调律（ISC）的研究很少涉及截肢者。本文旨在通过新的方法来分析和应用ISC以改进动力假肢的控制。", "method": "开发了一种用于分析下肢3D运动学数据中的节段间协调的方法，并将其扩展到基于力矩的新协调律，使用该方法分析了健全人和截肢者的步态中Elevation Space Moments（ESM）的表现。同时建立了ISC3d工具箱以计算三维运动中的动力学ISC。", "result": "发现截肢者在穿戴被动或主动假肢时，虽然抬升角度保持平面性，但力矩协调度较低。基于ISC约束预测了可以补偿由于被动脚的存在而引起的改变的股骨和小腿的角度/力矩，以模仿健康步态。", "conclusion": "通过扩展节段间协调律来探索其在截肢者行走中的作用，为改善动力假肢控制提供了可能的方法，并且开发的ISC3d工具箱可免费在线获取，有助于进一步研究协调在步态中的角色以及神经控制的人类运动的基本问题。"}}
{"id": "2602.02179", "pdf": "https://arxiv.org/pdf/2602.02179", "abs": "https://arxiv.org/abs/2602.02179", "authors": ["Marina Mastroleo", "Alberto Archetti", "Federico Mastroleo", "Matteo Matteucci"], "title": "SurvKAN: A Fully Parametric Survival Model Based on Kolmogorov-Arnold Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate prediction of time-to-event outcomes is critical for clinical decision-making, treatment planning, and resource allocation in modern healthcare. While classical survival models such as Cox remain widely adopted in standard practice, they rely on restrictive assumptions, including linear covariate relationships and proportional hazards over time, that often fail to capture real-world clinical dynamics. Recent deep learning approaches like DeepSurv and DeepHit offer improved expressivity but sacrifice interpretability, limiting clinical adoption where trust and transparency are paramount. Hybrid models incorporating Kolmogorov-Arnold Networks (KANs), such as CoxKAN, have begun to address this trade-off but remain constrained by the semi-parametric Cox framework. In this work we introduce SurvKAN, a fully parametric, time-continuous survival model based on KAN architectures that eliminates the proportional hazards constraint. SurvKAN treats time as an explicit input to a KAN that directly predicts the log-hazard function, enabling end-to-end training on the full survival likelihood. Our architecture preserves interpretability through learnable univariate functions that indicate how individual features influence risk over time. Extensive experiments on standard survival benchmarks demonstrate that SurvKAN achieves competitive or superior performance compared to classical and state-of-the-art baselines across concordance and calibration metrics. Additionally, interpretability analyses reveal clinically meaningful patterns that align with medical domain knowledge.", "AI": {"tldr": "SurvKAN是一种基于Kolmogorov-Arnold网络的全参数生存模型，能够预测时间到事件的结果。", "motivation": "传统生存模型如Cox在临床决策和资源分配中广泛应用但存在假设限制。深度学习方法虽提高了表达能力却牺牲了可解释性，而混合模型仍受制于半参数框架。", "method": "引入SurvKAN，基于Kolmogorov-Arnold网络的全参数生存模型，直接预测时间的对数风险函数并进行端到端训练。模型保持可解释性并通过单变量函数体现特征随时间变化的风险影响。", "result": "在标准基准上实验显示SurvKAN性能与经典和最新基线相当或更优，并揭示了临床有意义且符合医学知识的模式。", "conclusion": "SurvKAN提供了一种改进的时间到事件预测方法，保持可解释性的同时提高了模型性能。"}}
{"id": "2602.02175", "pdf": "https://arxiv.org/pdf/2602.02175", "abs": "https://arxiv.org/abs/2602.02175", "authors": ["Xinquan Yu", "Wei Lu", "Xiangyang Luo", "Rui Yang"], "title": "CIEC: Coupling Implicit and Explicit Cues for Multimodal Weakly Supervised Manipulation Localization", "categories": ["cs.CV"], "comment": null, "summary": "To mitigate the threat of misinformation, multimodal manipulation localization has garnered growing attention. Consider that current methods rely on costly and time-consuming fine-grained annotations, such as patch/token-level annotations. This paper proposes a novel framework named Coupling Implicit and Explicit Cues (CIEC), which aims to achieve multimodal weakly-supervised manipulation localization for image-text pairs utilizing only coarse-grained image/sentence-level annotations. It comprises two branches, image-based and text-based weakly-supervised localization. For the former, we devise the Textual-guidance Refine Patch Selection (TRPS) module. It integrates forgery cues from both visual and textual perspectives to lock onto suspicious regions aided by spatial priors. Followed by the background silencing and spatial contrast constraints to suppress interference from irrelevant areas. For the latter, we devise the Visual-deviation Calibrated Token Grounding (VCTG) module. It focuses on meaningful content words and leverages relative visual bias to assist token localization. Followed by the asymmetric sparse and semantic consistency constraints to mitigate label noise and ensure reliability. Extensive experiments demonstrate the effectiveness of our CIEC, yielding results comparable to fully supervised methods on several evaluation metrics.", "AI": {"tldr": "提出了一种新型框架CIEC，用于利用粗粒度标注进行多模态弱监督篡改定位。", "motivation": "当前方法依赖于耗时且昂贵的细粒度标注来实现篡改定位，本论文旨在通过使用粗粒度图像/句子级标注来解决这一问题。", "method": "提出了CIEC框架，该框架包含基于图像和文本的弱监督定位两部分。TRPS模块集成视觉和文本线索进行可疑区域锁定，VCTG模块关注有意义的内容词汇并利用相对视觉偏差辅助标记定位。", "result": "实验结果表明，所提方法在多个评估指标上与全监督方法性能相当。", "conclusion": "CIEC框架成功实现了基于粗粒度标注的多模态弱监督篡改定位任务。"}}
{"id": "2602.02171", "pdf": "https://arxiv.org/pdf/2602.02171", "abs": "https://arxiv.org/abs/2602.02171", "authors": ["Lu Cao", "Xiquan He", "Junying Zeng", "Chaoyun Mai", "Min Luo"], "title": "Lung Nodule Image Synthesis Driven by Two-Stage Generative Adversarial Networks", "categories": ["cs.CV"], "comment": null, "summary": "The limited sample size and insufficient diversity of lung nodule CT datasets severely restrict the performance and generalization ability of detection models. Existing methods generate images with insufficient diversity and controllability, suffering from issues such as monotonous texture features and distorted anatomical structures. Therefore, we propose a two-stage generative adversarial network (TSGAN) to enhance the diversity and spatial controllability of synthetic data by decoupling the morphological structure and texture features of lung nodules. In the first stage, StyleGAN is used to generate semantic segmentation mask images, encoding lung nodules and tissue backgrounds to control the anatomical structure of lung nodule images; The second stage uses the DL-Pix2Pix model to translate the mask map into CT images, employing local importance attention to capture local features, while utilizing dynamic weight multi-head window attention to enhance the modeling capability of lung nodule texture and background. Compared to the original dataset, the accuracy improved by 4.6% and mAP by 4% on the LUNA16 dataset. Experimental results demonstrate that TSGAN can enhance the quality of synthetic images and the performance of detection models.", "AI": {"tldr": "提出了一种两阶段生成对抗网络(TSGAN)来增强合成数据的多样性和空间可控性，以改善肺结节CT图像的质量和检测模型的表现。", "motivation": "现有方法产生的图像多样性不足且难以控制，导致纹理特征单调、解剖结构扭曲等问题，限制了检测模型性能及泛化能力。因此提出改进方案。", "method": "第一阶段使用StyleGAN生成语义分割掩码图以控制肺结节的解剖结构；第二阶段采用DL-Pix2Pix模型将掩码转换为CT图像，并利用局部重要性注意力机制和动态权重多头窗口注意力增强纹理建模能力。", "result": "在LUNA16数据集上，精度提高了4.6%，mAP提升了4%。实验表明TSGAN能提高合成图像质量及检测模型性能。", "conclusion": "该方法通过两阶段生成对抗网络成功增强了合成肺结节CT图像的多样性和空间可控性，并显著改善了检测模型的表现。"}}
{"id": "2602.02170", "pdf": "https://arxiv.org/pdf/2602.02170", "abs": "https://arxiv.org/abs/2602.02170", "authors": ["Jose Manuel de la Chica Rodriguez", "Juan Manuel Vera Díaz"], "title": "Self-Evolving Coordination Protocol in Multi-Agent AI Systems: An Exploratory Systems Feasibility Study", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Contemporary multi-agent systems increasingly rely on internal coordination mechanisms to combine, arbitrate, or constrain the outputs of heterogeneous components. In safety-critical and regulated domains such as finance, these mechanisms must satisfy strict formal requirements, remain auditable, and operate within explicitly bounded limits. Coordination logic therefore functions as a governance layer rather than an optimization heuristic. This paper presents an exploratory systems feasibility study of Self-Evolving Coordination Protocols (SECP): coordination protocols that permit limited, externally validated self-modification while preserving fixed formal invariants. We study a controlled proof-of-concept setting in which six fixed Byzantine consensus protocol proposals are evaluated by six specialized decision modules. All coordination regimes operate under identical hard constraints, including Byzantine fault tolerance (f < n/3), O(n2) message complexity, complete non-statistical safety and liveness arguments, and bounded explainability. Four coordination regimes are compared in a single-shot design: unanimous hard veto, weighted scalar aggregation, SECP v1.0 (an agent-designed non-scalar protocol), and SECP v2.0 (the result of one governed modification). Outcomes are evaluated using a single metric, proposal coverage, defined as the number of proposals accepted. A single recursive modification increased coverage from two to three accepted proposals while preserving all declared invariants. The study makes no claims regarding statistical significance, optimality, convergence, or learning. Its contribution is architectural: it demonstrates that bounded self-modification of coordination protocols is technically implementable, auditable, and analyzable under explicit formal constraints, establishing a foundation for governed multi-agent systems.", "AI": {"tldr": "研究探讨了自适应协调协议（SECP）在多智能体系统中的可行性。", "motivation": "为了满足安全关键和受监管领域对严格的正式要求、可审计性和有限操作的要求，本文提出了一个自我演进的协调协议的研究。", "method": "通过六个固定拜占庭共识协议提案与六个专业化决策模块相结合，在严格限制下评估四种协调方案：一致硬否决权、加权标量聚合和两个自适应版本1.0及2.0。结果根据提案覆盖率进行评价。", "result": "单次递归修改将接受的提案数从二个增加到三个，同时保持所有声明不变。", "conclusion": "研究表明，在明确正式约束下实现、审计和分析有界自我修改协调协议是可行的，并为此类系统奠定了基础。"}}
{"id": "2602.02167", "pdf": "https://arxiv.org/pdf/2602.02167", "abs": "https://arxiv.org/abs/2602.02167", "authors": ["Soheil Behnam Roudsari", "Alexandre S. Brandão", "Felipe N. Martins"], "title": "Real-Time 2D LiDAR Object Detection Using Three-Frame RGB Scan Encoding", "categories": ["eess.SP", "cs.CV", "cs.LG", "cs.RO"], "comment": "6 pages, 6 figures, submitted to IEEE SAS 2026", "summary": "Indoor service robots need perception that is robust, more privacy-friendly than RGB video, and feasible on embedded hardware. We present a camera-free 2D LiDAR object detection pipeline that encodes short-term temporal context by stacking three consecutive scans as RGB channels, yielding a compact YOLOv8n input without occupancy-grid construction while preserving angular structure and motion cues. Evaluated in Webots across 160 randomized indoor scenarios with strict scenario-level holdout, the method achieves 98.4% mAP@0.5 (0.778 mAP@0.5:0.95) with 94.9% precision and 94.7% recall on four object classes. On a Raspberry Pi 5, it runs in real time with a mean post-warm-up end-to-end latency of 47.8ms per frame, including scan encoding and postprocessing. Relative to a closely related occupancy-grid LiDAR-YOLO pipeline reported on the same platform, the proposed representation is associated with substantially lower reported end-to-end latency. Although results are simulation-based, they suggest that lightweight temporal encoding can enable accurate and real-time LiDAR-only detection for embedded indoor robotics without capturing RGB appearance.", "AI": {"tldr": "本文提出了一种使用三帧RGB扫描编码的实时二维LiDAR目标检测方法，适用于嵌入式硬件。", "motivation": "室内服务机器人需要一种稳健、隐私保护性更强且不依赖于RGB视频的目标感知技术。本文旨在提供一种基于2D LiDAR的数据驱动目标检测方案，该方案可以同时满足实际应用中的实时性和计算资源限制。", "method": "通过将三个连续的扫描帧作为RGB通道进行堆叠来编码短期时间上下文信息，并将其输入YOLOv8n模型中。此方法在不构建占用网格的情况下保持角度结构和运动线索，使得检测过程更加紧凑高效。", "result": "该方法在Webots仿真环境中经过160个随机室内场景的评估后取得了98.4%的mAP@0.5（0.778 mAP@0.5:0.95）平均精度，并且具有94.9%的准确率和94.7%的召回率。在Raspberry Pi 5上运行时，从扫描编码到后处理的端到端延迟平均仅为47.8ms。", "conclusion": "研究表明，轻量级的时间编码能够实现精确且实时的仅使用LiDAR的目标检测，并且无需捕捉RGB外观特征。这种方法为嵌入式室内机器人提供了潜在的应用价值。"}}
{"id": "2602.02163", "pdf": "https://arxiv.org/pdf/2602.02163", "abs": "https://arxiv.org/abs/2602.02163", "authors": ["Julian Wyatt", "Ronald Clark", "Irina Voiculescu"], "title": "Reg4Pru: Regularisation Through Random Token Routing for Token Pruning", "categories": ["cs.CV"], "comment": "11 pages, 7 figures", "summary": "Transformers are widely adopted in modern vision models due to their strong ability to scale with dataset size and generalisability. However, this comes with a major drawback: computation scales quadratically to the total number of tokens. Numerous methods have been proposed to mitigate this. For example, we consider token pruning with reactivating tokens from preserved representations, but the increased computational efficiency of this method results in decreased stability from the preserved representations, leading to poorer dense prediction performance at deeper layers. In this work, we introduce Reg4Pru, a training regularisation technique that mitigates token-pruning performance loss for segmentation. We compare our models on the FIVES blood vessel segmentation dataset and find that Reg4Pru improves average precision by an absolute 46% compared to the same model trained without routing. This increase is observed using a configuration that achieves a 29% relative speedup in wall-clock time compared to the non-pruned baseline. These findings indicate that Reg4Pru is a valuable regulariser for token reduction strategies.", "AI": {"tldr": "提出了一种名为Reg4Pru的训练正则化技术，以缓解令牌剪枝在分割任务中的性能损失。", "motivation": "由于计算复杂度随令牌数量二次增长，研究者们提出了多种方法来优化这一问题。然而，在使用令牌重新激活的方法时，虽然提高了计算效率，却降低了稳定性和深层预测的准确性。因此，引入Reg4Pru技术以提高模型在分割任务中的性能。", "method": "提出了一种名为Reg4Pru的训练正则化技术，通过随机路由机制来缓解令牌剪枝带来的性能损失。", "result": "实验表明，在FIVES血管分割数据集上，使用Reg4Pru技术可以将平均精度提高绝对值46%，同时相比于未剪枝的基础模型实现了29%的速度提升。", "conclusion": "研究结果证明了Reg4Pru作为令牌减少策略的正则化器的价值。"}}
{"id": "2602.02158", "pdf": "https://arxiv.org/pdf/2602.02158", "abs": "https://arxiv.org/abs/2602.02158", "authors": ["Sarah Nassar"], "title": "Traffic-Aware Navigation in Road Networks", "categories": ["cs.AI"], "comment": null, "summary": "This project compares three graph search approaches for the task of traffic-aware navigation in Kingston's road network. These approaches include a single-run multi-query preprocessing algorithm (Floyd-Warshall-Ingerman), continuous single-query real-time search (Dijkstra's and A*), and an algorithm combining both approaches to balance between their trade-offs by first finding the top K shortest paths then iterating over them in real time (Yen's). Dijkstra's and A* resulted in the most traffic-aware optimal solutions with minimal preprocessing required. Floyd-Warshall-Ingerman was the fastest in real time but provided distance based paths with no traffic awareness. Yen's algorithm required significant preprocessing but balanced between the other two approaches in terms of runtime speed and optimality. Each approach presents advantages and disadvantages that need to be weighed depending on the circumstances of specific deployment contexts to select the best custom solution. *This project was completed as part of ELEC 844 (Search and Planning Algorithms for Robotics) in the Fall 2025 term.", "AI": {"tldr": "本文比较了三种图搜索方法在金斯顿道路网络中的交通感知导航任务。", "motivation": "旨在通过对比不同算法，找到适用于特定部署环境的最佳定制解决方案", "method": "采用了单次多查询预处理（Floyd-Warshall-Ingerman），连续单一查询实时搜索（Dijkstra's和A*）以及结合两者优势的Yen算法。", "result": "Dijkstra's和A*提供了最优化且具有交通感知性的路径，但需要较大的时间开销。Floyd-Warshall-Ingerman在实时性上表现最好，但是不具备交通感知功能。Yen算法虽然预处理复杂度较高，但在运行时间和最优解之间找到了平衡。", "conclusion": "每种方法都有各自的优缺点，在实际应用中需根据具体部署环境权衡选择"}}
{"id": "2602.02156", "pdf": "https://arxiv.org/pdf/2602.02156", "abs": "https://arxiv.org/abs/2602.02156", "authors": ["Wen-Jie Shu", "Xuerui Qiu", "Rui-Jie Zhu", "Harold Haodong Chen", "Yexin Liu", "Harry Yang"], "title": "LoopViT: Scaling Visual ARC with Looped Transformers", "categories": ["cs.CV"], "comment": "8 pages, 11 figures", "summary": "Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes\" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT.", "AI": {"tldr": "提出了名为Loop-ViT的递归架构，通过权重重用循环来分离推理深度和模型容量，并引入基于预测熵的无参数动态退出机制。", "motivation": "现有视觉推理方法中使用的前馈架构受限于网络宽度，难以捕捉人类归纳中的迭代算法性质。提出了一种新的递归架构以解决这一问题。", "method": "设计了一个称为Loop-ViT的递归架构，该架构通过结合局部卷积和全局注意力的操作来形成一个潜在的思想链，并引入了基于预测熵的无参数动态退出机制。", "result": "实验结果显示，在ARC-AGI-1基准测试中，提出的18M模型达到了65.8％的准确率，超过了73M参数量的大规模集成模型。表明自适应迭代计算比简单增加网络宽度更有效地提升了视觉推理性能。", "conclusion": "通过设计一种新的递归架构Loop-ViT，展示了自适应迭代计算在视觉推理中的有效性，并提出了一个更加高效的扩展轴心，即通过增加迭代深度而不是网络宽度来提升模型的推理能力。"}}
{"id": "2602.02154", "pdf": "https://arxiv.org/pdf/2602.02154", "abs": "https://arxiv.org/abs/2602.02154", "authors": ["Sidi Wu", "Yizi Chen", "Maurizio Gribaudi", "Konrad Schindler", "Clément Mallet", "Julien Perret", "Lorenz Hurni"], "title": "Deep learning enables urban change profiling through alignment of historical maps", "categories": ["cs.CV", "cs.IR"], "comment": "40 pages", "summary": "Prior to modern Earth observation technologies, historical maps provide a unique record of long-term urban transformation and offer a lens on the evolving identity of cities. However, extracting consistent and fine-grained change information from historical map series remains challenging due to spatial misalignment, cartographic variation, and degrading document quality, limiting most analyses to small-scale or qualitative approaches. We propose a fully automated, deep learning-based framework for fine-grained urban change analysis from large collections of historical maps, built on a modular design that integrates dense map alignment, multi-temporal object detection, and change profiling. This framework shifts the analysis of historical maps from ad hoc visual comparison toward systematic, quantitative characterization of urban change. Experiments demonstrate the robust performance of the proposed alignment and object detection methods. Applied to Paris between 1868 and 1937, the framework reveals the spatial and temporal heterogeneity in urban transformation, highlighting its relevance for research in the social sciences and humanities. The modular design of our framework further supports adaptation to diverse cartographic contexts and downstream applications.", "AI": {"tldr": "通过深度学习技术，对历史地图进行精细的都市变化分析。", "motivation": "由于空间错位、制图差异和文档质量下降等因素，从历史地图中提取一致且细致的变化信息变得困难。这限制了大多数研究仅限于小规模或定性方法。因此需要一种自动化的方法来解决这些问题，并提供系统的定量特性。", "method": "提出了一种基于深度学习的框架，包括密集的地图对齐、多时间对象检测和变化分析。该框架设计灵活，可适应各种制图环境和下游应用。", "result": "实验表明了所提出的地图对齐和对象检测方法具有稳健性能，并应用于1868年至1937年间巴黎的变化情况，揭示出都市演变在空间和时间上的异质性。", "conclusion": "该框架不仅能够系统地定量分析历史地图中的变化信息，还为社会科学和人文学科的研究提供了新的视角。其灵活性设计支持了对不同制图环境的适应性和下游应用的发展。"}}
{"id": "2602.02150", "pdf": "https://arxiv.org/pdf/2602.02150", "abs": "https://arxiv.org/abs/2602.02150", "authors": ["Chu Zhao", "Enneng Yang", "Yuting Liu", "Jianzhe Zhao", "Guibing Guo"], "title": "ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "19 ppages", "summary": "Test-time reinforcement learning generates multiple candidate answers via repeated rollouts and performs online updates using pseudo-labels constructed by majority voting. To reduce overhead and improve exploration, prior work introduces tree structured rollouts, which share reasoning prefixes and branch at key nodes to improve sampling efficiency. However, this paradigm still faces two challenges: (1) high entropy branching can trigger rollout collapse, where the branching budget concentrates on a few trajectories with consecutive high-entropy segments, rapidly reducing the number of effective branches; (2) early pseudo-labels are noisy and biased, which can induce self-reinforcing overfitting, causing the policy to sharpen prematurely and suppress exploration. To address these issues, we propose Entropy Confidence Hybrid Group Relative Policy Optimization (ECHO). During rollout, ECHO jointly leverages local entropy and group level confidence to adaptively control branch width, and further introduces online confidence-based pruning to terminate persistently low confidence branches, avoiding high entropy traps and mitigating collapse. During policy updates, ECHO employs confidence adaptive clipping and an entropy confidence hybrid advantage shaping approach to enhance training robustness and mitigate early stage bias. Experiments demonstrate that ECHO achieves consistent gains on multiple mathematical and visual reasoning benchmarks, and generalizes more effectively under a limited rollout budget.", "AI": {"tldr": "ECHO通过结合局部熵和群体置信度自适应控制分支宽度，以及在线置信度剪枝来避免高熵陷阱并减少崩溃。在策略更新时，采用置信度自适应裁剪和优势塑造方法增强训练稳健性。", "motivation": "测试时间强化学习面临两个主要问题：一是高熵分支可能导致分支预算集中在少数轨迹上，导致有效分支迅速减少；二是早期伪标签存在噪声和偏差，可能引发自我加强的过拟合，使策略提前锐化并抑制探索。为解决这些问题提出ECHO。", "method": "ECHO在回溯过程中结合局部熵与群体置信度自适应控制分支宽度，并通过在线置信度剪枝终止持续低置信度分支；在策略更新时采用置信度自适应裁剪及优势塑造方法增强训练稳健性，减少早期偏差。", "result": "实验显示ECHO在多个数学和视觉推理基准上取得一致性的提升，在受限回溯预算下具有更强泛化能力。", "conclusion": "提出的新策略ECHO有效解决了测试时间强化学习中的分支崩溃与早期伪标签噪声问题，显著提高了模型的稳健性及探索性能。"}}
{"id": "2602.02146", "pdf": "https://arxiv.org/pdf/2602.02146", "abs": "https://arxiv.org/abs/2602.02146", "authors": ["Sunho Kim", "Susik Yoon"], "title": "Back to the Future: Look-ahead Augmentation and Parallel Self-Refinement for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages, Short paper accepted at The Web Conference (WWW) 2026", "summary": "Long-term time series forecasting (LTSF) remains challenging due to the trade-off between parallel efficiency and sequential modeling of temporal coherence. Direct multi-step forecasting (DMS) methods enable fast, parallel prediction of all future horizons but often lose temporal consistency across steps, while iterative multi-step forecasting (IMS) preserves temporal dependencies at the cost of error accumulation and slow inference. To bridge this gap, we propose Back to the Future (BTTF), a simple yet effective framework that enhances forecasting stability through look-ahead augmentation and self-corrective refinement. Rather than relying on complex model architectures, BTTF revisits the fundamental forecasting process and refines a base model by ensembling the second-stage models augmented with their initial predictions. Despite its simplicity, our approach consistently improves long-horizon accuracy and mitigates the instability of linear forecasting models, achieving accuracy gains of up to 58% and demonstrating stable improvements even when the first-stage model is trained under suboptimal conditions. These results suggest that leveraging model-generated forecasts as augmentation can be a simple yet powerful way to enhance long-term prediction, even without complex architectures.", "AI": {"tldr": "本文提出了一种名为“回到未来”的框架，该框架通过前瞻增强和自我修正优化来提高时间序列预测的长期准确性。", "motivation": "长时序预测存在快速并行推断与维护时间一致性之间的权衡。直接多步预测方法虽然快但容易失去时间连续性；迭代多步预测法虽能保持时间依赖，但也增加了误差累积和慢推理的问题。因此本文提出了一种新的框架来解决这些问题。", "method": "该论文提出了“回到未来”的简单有效框架，通过前瞻增强和自我修正优化来提高模型的稳定性。具体来说，它不依靠复杂的架构，而是通过对初始预测进行第二阶段集成来改进基础模型。", "result": "该方法在长期准确性上取得了显著进步，并且即使是在第一阶段模型训练条件不佳的情况下也能保持稳定的改善效果，最高可达58%的精度提升。", "conclusion": "结果表明，通过利用生成的预报作为增强手段可以提高长时间预测的准确性和稳定性，而无需复杂的架构。"}}
{"id": "2602.02143", "pdf": "https://arxiv.org/pdf/2602.02143", "abs": "https://arxiv.org/abs/2602.02143", "authors": ["Shubham Toshniwal", "Aleksander Ficek", "Siddhartha Jain", "Wei Du", "Vahid Noroozi", "Sadegh Mahdavi", "Somshubra Majumdar", "Igor Gitman"], "title": "Learning Generative Selection for Best-of-N", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Scaling test-time compute via parallel sampling can substantially improve LLM reasoning, but is often limited by Best-of-N selection quality. Generative selection methods, such as GenSelect, address this bottleneck, yet strong selection performance remains largely limited to large models. We show that small reasoning models can acquire strong GenSelect capabilities through targeted reinforcement learning. To this end, we synthesize selection tasks from large-scale math and code instruction datasets by filtering to instances with both correct and incorrect candidate solutions, and train 1.7B-parameter models with DAPO to reward correct selections. Across math (AIME24, AIME25, HMMT25) and code (LiveCodeBench) reasoning benchmarks, our models consistently outperform prompting and majority-voting baselines, often approaching or exceeding much larger models. Moreover, these gains generalize to selecting outputs from stronger models despite training only on outputs from weaker models. Overall, our results establish reinforcement learning as a scalable way to unlock strong generative selection in small models, enabling efficient test-time scaling.", "AI": {"tldr": "本文探讨了通过强化学习使小型推理模型获得强大的生成性选择能力，从而提高最佳输出选取的质量。", "motivation": "在大规模语言模型中，尽管并行采样可以显著提升推理性能，但最佳输出的选择质量受限于模型大小。本研究旨在证明小型模型也能通过特定的强化学习方法实现高质量的最佳输出选取。", "method": "本文采用从大型数学和代码数据集中合成选择任务的方法，并筛选出具有正确与错误候选解决方案的任务实例，利用DAPO算法训练1.7B参数的小型推理模型，奖励正确的选择结果。", "result": "实验结果显示，在AIME24、AIME25、HMMT25数学问题及LiveCodeBench代码理解基准测试中，该方法的模型表现优于提示和多数投票基线，并且接近或超过更大规模的模型。此外，这种方法在选择更强大模型输出时也能表现出色。", "conclusion": "研究结果表明，强化学习是解锁小型模型生成性选择能力的一种可扩展方式，能够有效实现测试时间上的高效扩展。"}}
{"id": "2602.02142", "pdf": "https://arxiv.org/pdf/2602.02142", "abs": "https://arxiv.org/abs/2602.02142", "authors": ["Ruiteng Zhao", "Wenshuo Wang", "Yicheng Ma", "Xiaocong Li", "Francis E. H. Tay", "Marcelo H. Ang Jr.", "Haiyue Zhu"], "title": "FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Force sensing is a crucial modality for Vision-Language-Action (VLA) frameworks, as it enables fine-grained perception and dexterous manipulation in contact-rich tasks. We present Force-Distilled VLA (FD-VLA), a novel framework that integrates force awareness into contact-rich manipulation without relying on physical force sensors. The core of our approach is a Force Distillation Module (FDM), which distills force by mapping a learnable query token, conditioned on visual observations and robot states, into a predicted force token aligned with the latent representation of actual force signals. During inference, this distilled force token is injected into the pretrained VLM, enabling force-aware reasoning while preserving the integrity of its vision-language semantics. This design provides two key benefits: first, it allows practical deployment across a wide range of robots that lack expensive or fragile force-torque sensors, thereby reducing hardware cost and complexity; second, the FDM introduces an additional force-vision-state fusion prior to the VLM, which improves cross-modal alignment and enhances perception-action robustness in contact-rich scenarios. Surprisingly, our physical experiments show that the distilled force token outperforms direct sensor force measurements as well as other baselines, which highlights the effectiveness of this force-distilled VLA approach.", "AI": {"tldr": "本文提出了FD-VLA框架，通过力感知融合改善了视觉语言动作模型在接触密集任务中的性能。", "motivation": "为了降低硬件成本并提高接触密集操作任务的鲁棒性，引入了一种无需物理传感器即可获取力信息的方法。", "method": "利用力蒸馏模块（FDM），将学习到的查询令牌映射为预测的力令牌，并将其注入预训练好的视觉语言模型中以增强感知和动作推理能力。", "result": "实验结果表明，该方法在接触密集任务中的性能超过了直接传感器测量和其他基线方法。", "conclusion": "FD-VLA框架有效地提升了机器人处理接触密集操作任务的能力，同时降低了硬件依赖性。"}}
{"id": "2602.02139", "pdf": "https://arxiv.org/pdf/2602.02139", "abs": "https://arxiv.org/abs/2602.02139", "authors": ["Pawel Batorski", "Paul Swoboda"], "title": "EvoMU: Evolutionary Machine Unlearning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Machine unlearning aims to unlearn specified training data (e.g. sensitive or copyrighted material). A prominent approach is to fine-tune an existing model with an unlearning loss that retains overall utility. The space of suitable unlearning loss functions is vast, making the search for an optimal loss function daunting. Additionally, there might not even exist a universally optimal loss function: differences in the structure and overlap of the forget and retain data can cause a loss to work well in one setting but over-unlearn or under-unlearn in another. Our approach EvoMU tackles these two challenges simultaneously. An evolutionary search procedure automatically finds task-specific losses in the vast space of possible unlearning loss functions. This allows us to find dataset-specific losses that match or outperform existing losses from the literature, without the need for a human-in-the-loop. This work is therefore an instance of automatic scientific discovery, a.k.a. an AI co-scientist. In contrast to previous AI co-scientist works, we do so on a budget: We achieve SotA results using a small 4B parameter model (Qwen3-4B-Thinking), showing the potential of AI co-scientists with limited computational resources. Our experimental evaluation shows that we surpass previous loss-based unlearning formulations on TOFU-5%, TOFU-10%, MUSE and WMDP by synthesizing novel unlearning losses. Our code is available at https://github.com/Batorskq/EvoMU.", "AI": {"tldr": "本文提出了一种名为EvoMU的进化机器遗忘方法，旨在自动搜索适合特定任务和数据集的遗忘损失函数。", "motivation": "现有机器遗忘技术面临寻找最优遗忘损失函数的任务复杂性和资源需求问题。因此，作者希望通过进化算法自动找到针对特定任务和数据集的最佳遗忘损失函数。", "method": "EvoMU采用进化搜索程序在潜在巨大的遗忘损失函数空间中自动寻找适合特定任务的损失函数，并使用一个小规模（4B参数）的语言模型实现这一目标。", "result": "实验结果表明，EvoMU方法在TOFU-5%，TOFU-10%，MUSE和WMDP等数据集上超过现有的基于遗忘损失的方法。", "conclusion": "EvoMU是一种自动发现适合特定任务的遗忘损失函数的新颖方法，展示了人工智能作为辅助科学家的能力，并且在资源有限的情况下仍能取得最先进的结果。"}}
{"id": "2602.02138", "pdf": "https://arxiv.org/pdf/2602.02138", "abs": "https://arxiv.org/abs/2602.02138", "authors": ["Lyu Zongyi", "Ji Zhenlan", "Chen Songqiang", "Wang Liwen", "Huang Yuheng", "Wang Shuai", "Cheung Shing-Chi"], "title": "CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems", "categories": ["cs.SE", "cs.AI"], "comment": "18 pages, 12 tables, 4 figures", "summary": "Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \\textbf{C}ausality-based \\textbf{A}nalysis framework for \\textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings. We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS.", "AI": {"tldr": "本文提出了一种基于因果关系分析的多代理代码生成系统(CAM)框架，以量化不同中间输出对系统正确性的贡献。", "motivation": "在多代理架构中，大量的中间输出使得其重要性对于系统正确性不透明，阻碍了针对性的设计优化。为此，该研究提出了CAM框架来解决此问题。", "method": "通过全面分类中间输出并系统地模拟真实错误以识别重要的特征，并对其重要性进行排名。然后进行了广泛的实证分析。", "result": "发现上下文依赖的特征、混合后端MACGS设计改进以及修复故障和减少中间标记消耗的实际应用成果。", "conclusion": "CAM框架为理解与改善多代理代码生成系统提供了有力的方法，证明了因果分析在这一领域的价值。"}}
{"id": "2602.02137", "pdf": "https://arxiv.org/pdf/2602.02137", "abs": "https://arxiv.org/abs/2602.02137", "authors": ["Minghao Li", "Ruihang Wang", "Rui Tan", "Yonggang Wen"], "title": "DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually designing piecewise deep reinforcement learning (DRL) agents cannot keep pace with frequent dynamics shifts and service-level agreement (SLA) changes of an evolving DC. This specification-to-policy lag causes a lack of timely, effective control policies, which may lead to service outages. To bridge the gap, we present DCoPilot, a hybrid framework for generative control policies in dynamic DC operation. DCoPilot synergizes two distinct generative paradigms, i.e., a large language model (LLM) that performs symbolic generation of structured reward forms, and a hypernetwork that conducts parametric generation of policy weights. DCoPilot operates through three coordinated phases: (i) simulation scale-up, which stress-tests reward candidates across diverse simulation-ready (SimReady) scenes; (ii) meta policy distillation, where a hypernetwork is trained to output policy weights conditioned on SLA and scene embeddings; and (iii) online adaptation, enabling zero-shot policy generation in response to updated specifications. Evaluated across five control task families spanning diverse DC components, DCoPilot achieves near-zero constraint violations and outperforms all baselines across specification variations. Ablation studies validate the effectiveness of LLM-based unified reward generation in enabling stable hypernetwork convergence.", "AI": {"tldr": "DCoPilot是一个结合大型语言模型和超网络的框架，用于动态数据中心操作中的生成控制策略。", "motivation": "现代数据中心中频繁的工作负载变化和服务水平协议更改导致手动设计的深度强化学习代理无法及时适应环境。这需要一个能够快速适应的新系统以保持服务稳定性和能源效率。", "method": "DCoPilot通过模拟扩展、元策略蒸馏和在线适应三个阶段操作，利用大型语言模型生成结构化奖励形式，并使用超网络基于服务水平协议和场景嵌入输出策略权重。", "result": "在五个控制任务家族中测试，DCoPilot实现了接近零的约束违反并优于所有基线。消融研究验证了LLM统一奖励生成的有效性。", "conclusion": "DCoPilot通过结合大型语言模型和超网络提供了一种新的方法来快速适应数据中心操作中的复杂环境变化，保持服务稳定性和能源效率。"}}
{"id": "2602.02136", "pdf": "https://arxiv.org/pdf/2602.02136", "abs": "https://arxiv.org/abs/2602.02136", "authors": ["Yingsha Xie", "Tiansheng Huang", "Enneng Yang", "Rui Min", "Wenjie Lu", "Xiaochun Cao", "Naiqiang Tan", "Li Shen"], "title": "Mitigating Safety Tax via Distribution-Grounded Refinement in Large Reasoning Models", "categories": ["cs.AI"], "comment": "Code will be released soon", "summary": "Safety alignment incurs safety tax that perturbs a large reasoning model's (LRM) general reasoning ability. Existing datasets used for safety alignment for an LRM are usually constructed by distilling safety reasoning traces and answers from an external LRM or human labeler. However, such reasoning traces and answers exhibit a distributional gap with the target LRM that needs alignment, and we conjecture such distributional gap is the culprit leading to significant degradation of reasoning ability of the target LRM. Driven by this hypothesis, we propose a safety alignment dataset construction method, dubbed DGR. DGR transforms and refines an existing out-of-distributional safety reasoning dataset to be aligned with the target's LLM inner distribution. Experimental results demonstrate that i) DGR effectively mitigates the safety tax while maintaining safety performance across all baselines, i.e., achieving \\textbf{+30.2\\%} on DirectRefusal and \\textbf{+21.2\\%} on R1-ACT improvement in average reasoning accuracy compared to Vanilla SFT; ii) the degree of reasoning degradation correlates with the extent of distribution shift, suggesting that bridging this gap is central to preserving capabilities. Furthermore, we find that safety alignment in LRMs may primarily function as a mechanism to activate latent knowledge, as a mere \\textbf{10} samples are sufficient for activating effective refusal behaviors. These findings not only emphasize the importance of distributional consistency but also provide insights into the activation mechanism of safety in reasoning models.", "AI": {"tldr": "该论文提出了一种名为DGR的方法，用于构建与目标大推理模型（LRM）内部分布一致的安全对齐数据集，以减轻安全税并保持安全性能。", "motivation": "现有用于安全对齐的大推理模型的训练数据集通常从外部模型或人工标注者中提炼出推理轨迹和答案，这导致了与目标模型之间的分布差距，进而影响其推理能力。作者提出使用DGR方法来解决这个问题。", "method": "该论文提出了DGR（Distribution-Grounded Refinement）方法，通过转换和优化现有的非分布安全推理数据集以适应目标LRM的内部分布，并验证这种方法的有效性。", "result": "实验结果显示，DGR可以有效减少安全税并保持较高的安全性能。与原始SFT相比，在DirectRefusal上提高了30.2%，在R1-ACT上的平均推理准确性提高了21.2%。此外，仅需少量样本（如10个）即可激活有效的拒绝行为。", "conclusion": "该论文证明了分布一致性对于保持大推理模型的能力至关重要，并且提供了关于安全机制如何通过激活潜在知识来发挥作用的见解。"}}
{"id": "2602.02133", "pdf": "https://arxiv.org/pdf/2602.02133", "abs": "https://arxiv.org/abs/2602.02133", "authors": ["Sangwoo Shin", "BumJun Kim", "Kyelim Lee", "Moongyu Jeon", "Albert No"], "title": "Understanding the Reversal Curse Mitigation in Masked Diffusion Models through Attention and Training Dynamics", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Autoregressive language models (ARMs) suffer from the reversal curse: after learning that \"$A$ is $B$\", they often fail on the reverse query \"$B$ is $A$\". Masked diffusion-based language models (MDMs) exhibit this failure in a much weaker form, but the underlying reason has remained unclear. A common explanation attributes this mitigation to the any-order training objective. However, observing \"[MASK] is $B$\" during training does not necessarily teach the model to handle the reverse prompt \"$B$ is [MASK]\". We show that the mitigation arises from architectural structure and its interaction with training. In a one-layer Transformer encoder, weight sharing couples the two directions by making forward and reverse attention scores positively correlated. In the same setting, we further show that the corresponding gradients are aligned, so minimizing the forward loss also reduces the reverse loss. Experiments on both controlled toy tasks and large-scale diffusion language models support these mechanisms, explaining why MDMs partially overcome a failure mode that persists in strong ARMs.", "AI": {"tldr": "研究了掩码扩散模型在处理反转查询时为何比自回归语言模型表现更好的原因。", "motivation": "解释为什么掩码扩散模型相比于自回归语言模型在应对反转查询时具有较弱的反转诅咒现象。", "method": "通过实验分析了一层Transformer编码器中权重共享如何使正向和反向注意分数相关联，进而影响训练过程中的梯度方向，并验证了这些机制在大规模掩码扩散语言模型上的有效性。", "result": "发现掩码扩散模型的架构结构及其与训练过程的交互作用可以减轻反转诅咒现象，具体表现为权重共享使得前向和反向注意力得分正相关，以及对应的梯度对齐减少了反向损失。", "conclusion": "掩码扩散模型通过其独特的设计在一定程度上缓解了自回归语言模型所面临的反转诅咒问题。"}}
{"id": "2602.02130", "pdf": "https://arxiv.org/pdf/2602.02130", "abs": "https://arxiv.org/abs/2602.02130", "authors": ["Lukas Zimmermann", "Michael Rauter", "Maximilian Schmid", "Dietmar Georg", "Barbara Knäusl"], "title": "Eliminating Registration Bias in Synthetic CT Generation: A Physics-Based Simulation Framework", "categories": ["cs.CV"], "comment": null, "summary": "Supervised synthetic CT generation from CBCT requires registered training pairs, yet perfect registration between separately acquired scans remains unattainable. This registration bias propagates into trained models and corrupts standard evaluation metrics. This may suggest that superior benchmark performance indicates better reproduction of registration artifacts rather than anatomical fidelity. We propose physics-based CBCT simulation to provide geometrically aligned training pairs by construction, combined with evaluation using geometric alignment metrics against input CBCT rather than biased ground truth. On two independent pelvic datasets, models trained on synthetic data achieved superior geometric alignment (Normalized Mutual Information: 0.31 vs 0.22) despite lower conventional intensity scores. Intensity metrics showed inverted correlations with clinical assessment for deformably registered data, while Normalized Mutual Information consistently predicted observer preference across registration methodologies (rho = 0.31, p < 0.001). Clinical observers preferred synthetic-trained outputs in 87% of cases, demonstrating that geometric fidelity, not intensity agreement with biased ground truth, aligns with clinical requirements.", "AI": {"tldr": "通过基于物理学的CBCT模拟来减少合成CT生成中的注册偏差，提出了一种新的评估方法。", "motivation": "传统CBCT和CT扫描之间的完美注册难以实现，导致训练数据中的偏移，这种偏移被传播到训练模型中并影响标准评价指标，使得性能较好的模型可能只是更好地复制了注册误差而不是解剖准确性。", "method": "使用基于物理学的CBCT模拟生成几何上对齐的数据集，并用输入CBCT而非有偏真实基准来评估合成数据的质量。采用归一化互信息作为新的评价标准。", "result": "实验结果显示，与传统强度评分相比，在两个独立骨盆数据集中，新方法训练出的模型在归一化互信息方面表现更好（0.31 vs 0.22）。临床观察者更倾向于合成CT输出的结果，在87%的情况下选择了这些结果。", "conclusion": "几何忠实度而非与有偏的真实基准的一致性更能满足临床需求。基于物理学的CBCT模拟和归一化互信息评价可以更好地反映模型的实际性能和临床价值。"}}
{"id": "2602.02128", "pdf": "https://arxiv.org/pdf/2602.02128", "abs": "https://arxiv.org/abs/2602.02128", "authors": ["Nima Shoghi", "Yuxuan Liu", "Yuning Shen", "Rob Brekelmans", "Pan Li", "Quanquan Gu"], "title": "Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics", "categories": ["cs.LG", "cs.AI", "physics.bio-ph", "q-bio.BM", "q-bio.QM"], "comment": "For associated project page, see https://bytedance-seed.github.io/ConfRover/starmd", "summary": "Molecular dynamics (MD) simulations remain the gold standard for studying protein dynamics, but their computational cost limits access to biologically relevant timescales. Recent generative models have shown promise in accelerating simulations, yet they struggle with long-horizon generation due to architectural constraints, error accumulation, and inadequate modeling of spatio-temporal dynamics. We present STAR-MD (Spatio-Temporal Autoregressive Rollout for Molecular Dynamics), a scalable SE(3)-equivariant diffusion model that generates physically plausible protein trajectories over microsecond timescales. Our key innovation is a causal diffusion transformer with joint spatio-temporal attention that efficiently captures complex space-time dependencies while avoiding the memory bottlenecks of existing methods. On the standard ATLAS benchmark, STAR-MD achieves state-of-the-art performance across all metrics--substantially improving conformational coverage, structural validity, and dynamic fidelity compared to previous methods. STAR-MD successfully extrapolates to generate stable microsecond-scale trajectories where baseline methods fail catastrophically, maintaining high structural quality throughout the extended rollout. Our comprehensive evaluation reveals severe limitations in current models for long-horizon generation, while demonstrating that STAR-MD's joint spatio-temporal modeling enables robust dynamics simulation at biologically relevant timescales, paving the way for accelerated exploration of protein function.", "AI": {"tldr": "本文提出了STAR-MD模型，用于生成蛋白质的微秒尺度动态轨迹。", "motivation": "分子动力学模拟是研究蛋白质动态的标准方法，但由于计算成本高而难以达到生物学相关的时间尺度。现有的生成式模型在长时序生成方面存在局限性，导致无法有效加速这些模拟。", "method": "STAR-MD是一个可扩展的SE(3)等变扩散模型，能够捕捉复杂的时空依赖关系，并通过联合空间-时间注意力机制避免了现有方法的记忆瓶颈。", "result": "在标准ATLAS基准测试中，STAR-MD取得了所有指标上的最佳性能，显著提高了构象覆盖、结构有效性和动态保真度。该模型可以在微秒尺度生成稳定轨迹，在长时序生成方面表现优异。", "conclusion": "本文展示了当前方法在长时序生成方面的局限性，并通过STAR-MD证明了联合时空建模可以实现生物学相关时间尺度上的稳健动力学模拟，为加速蛋白质功能的探索铺平了道路。"}}
{"id": "2602.02126", "pdf": "https://arxiv.org/pdf/2602.02126", "abs": "https://arxiv.org/abs/2602.02126", "authors": ["Junhan Kim", "Gukryeol Lee", "Seungwoo Son", "Jeewook Kim", "Yongkweon Jeon"], "title": "Two-Stage Grid Optimization for Group-wise Quantization of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "ICASSP 2026", "summary": "Group-wise quantization is an effective strategy for mitigating accuracy degradation in low-bit quantization of large language models (LLMs). Among existing methods, GPTQ has been widely adopted due to its efficiency; however, it neglects input statistics and inter-group correlations when determining group scales, leading to a mismatch with its goal of minimizing layer-wise reconstruction loss. In this work, we propose a two-stage optimization framework for group scales that explicitly minimizes the layer-wise reconstruction loss. In the first stage, performed prior to GPTQ, we initialize each group scale to minimize the group-wise reconstruction loss, thereby incorporating input statistics. In the second stage, we freeze the integer weights obtained via GPTQ and refine the group scales to minimize the layer-wise reconstruction loss. To this end, we employ the coordinate descent algorithm and derive a closed-form update rule, which enables efficient refinement without costly numerical optimization. Notably, our derivation incorporates the quantization errors from preceding layers to prevent error accumulation. Experimental results demonstrate that our method consistently enhances group-wise quantization, achieving higher accuracy with negligible overhead.", "AI": {"tldr": "本文提出了一种两阶段优化框架，用于改进大型语言模型中的组量化策略。", "motivation": "现有的GPTQ方法在确定组尺度时忽略了输入统计和组间相关性，导致与最小化逐层重建损失的目标不一致。因此，该研究旨在提高精度同时减少误差累积。", "method": "首先，在GPTQ之前初始化每个组尺度以最小化组内重建损失；然后，冻结通过GPTQ获得的整数权重并使用坐标下降算法优化组尺度以进一步最小化逐层重建损失，并推导出闭式更新规则。", "result": "实验结果表明该方法在提高精度的同时具有较低的开销，能够显著改进组量化策略。", "conclusion": "通过引入两阶段优化框架和精确的数学推导，本文成功解决了现有GPTQ方法中未充分考虑输入统计和误差累积的问题。"}}
{"id": "2602.02124", "pdf": "https://arxiv.org/pdf/2602.02124", "abs": "https://arxiv.org/abs/2602.02124", "authors": ["Olga Graf", "Dhrupal Patel", "Peter Groß", "Charlotte Lempp", "Matthias Hein", "Fabian Heinemann"], "title": "Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Drug-induced toxicity remains a leading cause of failure in preclinical development and early clinical trials. Detecting adverse effects at an early stage is critical to reduce attrition and accelerate the development of safe medicines. Histopathological evaluation remains the gold standard for toxicity assessment, but it relies heavily on expert pathologists, creating a bottleneck for large-scale screening. To address this challenge, we introduce an AI-based anomaly detection framework for histopathological whole-slide images (WSIs) in rodent livers from toxicology studies. The system identifies healthy tissue and known pathologies (anomalies) for which training data is available. In addition, it can detect rare pathologies without training data as out-of-distribution (OOD) findings. We generate a novel dataset of pixelwise annotations of healthy tissue and known pathologies and use this data to fine-tune a pre-trained Vision Transformer (DINOv2) via Low-Rank Adaptation (LoRA) in order to do tissue segmentation. Finally, we extract features for OOD detection using the Mahalanobis distance. To better account for class-dependent variability in histological data, we propose the use of class-specific thresholds. We optimize the thresholds using the mean of the false negative and false positive rates, resulting in only 0.16\\% of pathological tissue classified as healthy and 0.35\\% of healthy tissue classified as pathological. Applied to mouse liver WSIs with known toxicological findings, the framework accurately detects anomalies, including rare OOD morphologies. This work demonstrates the potential of AI-driven histopathology to support preclinical workflows, reduce late-stage failures, and improve efficiency in drug development.", "AI": {"tldr": "本文提出了一种基于AI的异常检测框架，用于识别药物诱导毒性研究中的已知和未知病理特征。", "motivation": "药物诱导的毒性是临床前开发和早期临床试验失败的主要原因。通过早期发现不良反应可以减少研发过程中的失败率并加速安全药物的研发。然而，传统的组织学评估依赖于专业病理学家，限制了大规模筛选的能力。", "method": "使用预训练的Vision Transformer（DINOv2）并通过低秩适应（LoRA）进行微调以实现组织分割。利用马氏距离提取特征，并根据每个类别的差异设定特定阈值来检测未标记的数据中异常。", "result": "该框架能够准确识别已知和罕见未知病理学，在测试数据集中仅有0.16%的病理性组织被误分类为正常，同时将健康组织错误分类为病理组织的比例仅为0.35%。", "conclusion": "这项工作展示了AI驱动的组织病理学在支持临床前工作流程、减少晚期失败和提高药物开发效率方面的潜力。"}}
{"id": "2602.02123", "pdf": "https://arxiv.org/pdf/2602.02123", "abs": "https://arxiv.org/abs/2602.02123", "authors": ["Yangyi Cao", "Yuanhang Li", "Lan Chen", "Qi Mao"], "title": "MLV-Edit: Towards Consistent and Highly Efficient Editing for Minute-Level Videos", "categories": ["cs.CV"], "comment": null, "summary": "We propose MLV-Edit, a training-free, flow-based framework that address the unique challenges of minute-level video editing. While existing techniques excel in short-form video manipulation, scaling them to long-duration videos remains challenging due to prohibitive computational overhead and the difficulty of maintaining global temporal consistency across thousands of frames. To address this, MLV-Edit employs a divide-and-conquer strategy for segment-wise editing, facilitated by two core modules: Velocity Blend rectifies motion inconsistencies at segment boundaries by aligning the flow fields of adjacent chunks, eliminating flickering and boundary artifacts commonly observed in fragmented video processing; and Attention Sink anchors local segment features to global reference frames, effectively suppressing cumulative structural drift. Extensive quantitative and qualitative experiments demonstrate that MLV-Edit consistently outperforms state-of-the-art methods in terms of temporal stability and semantic fidelity.", "AI": {"tldr": "提出了一种名为MLV-Edit的框架，用于解决长时间视频编辑中的挑战性问题。", "motivation": "现有技术在处理短形式视频时表现出色，但在扩展到长时段视频时面临计算开销和全局时间一致性维护的问题。为了解决这些问题，提出了一个更有效的解决方案。", "method": "MLV-Edit采用了一种分而治之的策略进行片段级别的编辑，并使用了两个核心模块：Velocity Blend用于修正相邻片段边界处的运动不一致；Attention Sink用于将局部段特征锚定到全局参考帧上，以抑制累积结构漂移。", "result": "实验表明，MLV-Edit在时间稳定性和语义保真度方面均优于现有的最先进技术。", "conclusion": "所提出的框架MLV-Edit有效解决了长时间视频编辑中的挑战性问题，并展示了卓越的性能表现。"}}
{"id": "2602.02114", "pdf": "https://arxiv.org/pdf/2602.02114", "abs": "https://arxiv.org/abs/2602.02114", "authors": ["Xin Ding", "Yun Chen", "Sen Zhang", "Kao Zhang", "Nenglun Chen", "Peibei Cao", "Yongwei Wang", "Fei Wu"], "title": "Enhancing Diffusion-Based Quantitatively Controllable Image Generation via Matrix-Form EDM and Adaptive Vicinal Training", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Continuous Conditional Diffusion Model (CCDM) is a diffusion-based framework designed to generate high-quality images conditioned on continuous regression labels. Although CCDM has demonstrated clear advantages over prior approaches across a range of datasets, it still exhibits notable limitations and has recently been surpassed by a GAN-based method, namely CcGAN-AVAR. These limitations mainly arise from its reliance on an outdated diffusion framework and its low sampling efficiency due to long sampling trajectories. To address these issues, we propose an improved CCDM framework, termed iCCDM, which incorporates the more advanced \\textit{Elucidated Diffusion Model} (EDM) framework with substantial modifications to improve both generation quality and sampling efficiency. Specifically, iCCDM introduces a novel matrix-form EDM formulation together with an adaptive vicinal training strategy. Extensive experiments on four benchmark datasets, spanning image resolutions from $64\\times64$ to $256\\times256$, demonstrate that iCCDM consistently outperforms existing methods, including state-of-the-art large-scale text-to-image diffusion models (e.g., Stable Diffusion 3, FLUX.1, and Qwen-Image), achieving higher generation quality while significantly reducing sampling cost.", "AI": {"tldr": "本文提出了一种改进的连续条件扩散模型iCCDM，通过引入先进的Elucidated Diffusion Model（EDM）框架和自适应邻近训练策略来提升图像生成质量和效率。", "motivation": "现有Continuous Conditional Diffusion Model (CCDM) 在依赖过时的扩散框架和长采样轨迹导致低抽样效率方面存在局限性。这些问题限制了其性能，使其被GAN方法超越。为了解决这些挑战，作者提出改进的iCCDM来提升生成质量和抽样效率。", "method": "本文提出的iCCDM引入了一种新的矩阵形式的EDM和自适应邻近训练策略，以提高图像生成的质量和采样效率。", "result": "实验结果表明，在多个基准数据集上，iCCDM在图像分辨率从64x64到256x256的情况下，均优于现有方法，包括最新的大规模文本到图像的扩散模型（如Stable Diffusion 3, FLUX.1和Qwen-Image），并且显著降低了采样成本。", "conclusion": "iCCDM通过引入先进的EDM框架及自适应训练策略，提高了生成质量和抽样效率，在多个基准数据集上取得了优于现有方法的结果。"}}
{"id": "2602.02112", "pdf": "https://arxiv.org/pdf/2602.02112", "abs": "https://arxiv.org/abs/2602.02112", "authors": ["Chunsan Hong", "Sanghyun Lee", "Jong Chul Ye"], "title": "Unifying Masked Diffusion Models with Various Generation Orders and Beyond", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Masked diffusion models (MDMs) are a potential alternative to autoregressive models (ARMs) for language generation, but generation quality depends critically on the generation order. Prior work either hard-codes an ordering (e.g., blockwise left-to-right) or learns an ordering policy for a pretrained MDM, which incurs extra cost and can yield suboptimal solutions due to the two-stage optimization. Motivated by this, we propose order-expressive masked diffusion model (OeMDM) for a broad class of diffusion generative processes with various generation orders, enabling the interpretation of MDM, ARM, and block diffusion in a single framework. Furthermore, building on OeMDM, we introduce learnable-order masked diffusion model (LoMDM), which jointly learns the generation ordering and diffusion backbone through a single objective from scratch, enabling the diffusion model to generate text in context-dependent ordering. Empirically, we confirm that LoMDM outperforms various discrete diffusion models across multiple language modeling benchmarks.", "AI": {"tldr": "本文提出了统一各类生成顺序的掩码扩散模型（OeMDM）和可学习生成顺序的掩码扩散模型（LoMDM），以解决现有掩码扩散模型在语言生成中的依赖于固定或学得的生成顺序的问题。", "motivation": "现有的掩码扩散模型在语言生成时，其质量高度依赖于生成顺序。如果硬编码一个生成顺序，则可能无法充分利用模型能力；如果学习一个生成策略，则增加了额外的成本且难以优化。", "method": "本文首先提出了OeMDM，它支持多种生成顺序并统一了ARM、块扩散和掩码扩散框架下的语言生成过程。接着，作者又引入了LoMDM，在单个目标函数下同时学习生成顺序和扩散骨干模型。", "result": "实验表明，提出的LoMDM在多个语言建模基准上超越了许多离散扩散模型的性能。", "conclusion": "本文通过OeMDM统一了不同的生成过程，并利用LoMDM实现了上下文依赖的文本生成，在多种任务中展示了优越性。"}}
{"id": "2602.02110", "pdf": "https://arxiv.org/pdf/2602.02110", "abs": "https://arxiv.org/abs/2602.02110", "authors": ["Zhongqian Fu", "Tianyi Zhao", "Kai Han", "Hang Zhou", "Xinghao Chen", "Yunhe Wang"], "title": "An Empirical Study of World Model Quantization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within a compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present a systematic empirical study of world model quantization using DINO-WM as a representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across a wide range of bit-widths, quantization granularities, and planning horizons up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts, activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor modules. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM.", "AI": {"tldr": "论文通过系统研究DINO-WM的量化技术，揭示了世界模型在不同视觉规划任务中的量化效应及其对性能的影响。", "motivation": "世界模型的运行依赖于大量计算资源和内存空间。为了提高效率并降低部署成本，需要探索量化方法对世界模型的影响。", "method": "论文使用多种量化策略（如权重与激活量化的组合）进行实验，并评估其在不同位宽、量化粒度以及规划时间上的表现。", "result": "研究发现，在低比特情况下，分组权重量化可以稳定模拟过程，而激活量化的效果不一致；同时，过度的量化会导致模型性能下降，使得优化难以修复这些问题。", "conclusion": "这些结果揭示了世界模型在量化部署中的特定失败模式，并为严格计算限制下的实际应用提供了实用指导。"}}
{"id": "2602.02107", "pdf": "https://arxiv.org/pdf/2602.02107", "abs": "https://arxiv.org/abs/2602.02107", "authors": ["Yu Wang", "Chuanguang Yang", "Zhulin An", "Weilun Feng", "Jiarui Zhao", "Chengqing Yu", "Libo Huang", "Boyu Diao", "Yongjun Xu"], "title": "Teacher-Guided Student Self-Knowledge Distillation Using Diffusion Model", "categories": ["cs.CV"], "comment": null, "summary": "Existing Knowledge Distillation (KD) methods often align feature information between teacher and student by exploring meaningful feature processing and loss functions. However, due to the difference in feature distributions between the teacher and student, the student model may learn incompatible information from the teacher. To address this problem, we propose teacher-guided student Diffusion Self-KD, dubbed as DSKD. Instead of the direct teacher-student alignment, we leverage the teacher classifier to guide the sampling process of denoising student features through a light-weight diffusion model. We then propose a novel locality-sensitive hashing (LSH)-guided feature distillation method between the original and denoised student features. The denoised student features encapsulate teacher knowledge and could be regarded as a teacher role. In this way, our DSKD method could eliminate discrepancies in mapping manners and feature distributions between the teacher and student, while learning meaningful knowledge from the teacher. Experiments on visual recognition tasks demonstrate that DSKD significantly outperforms existing KD methods across various models and datasets. Our code is attached in supplementary material.", "AI": {"tldr": "提出了一种新的知识蒸馏方法DSKD，通过利用教师模型指导学生模型的去噪过程来消除特征分布差异。", "motivation": "解决现有知识蒸馏方法中存在的教师和学生模型之间由于特征分布不同而导致的学习到不兼容信息的问题。", "method": "使用轻量级扩散模型引导学生模型的特征采样，并采用局部敏感哈希（LSH）指导原始与去噪后的学生特征之间的特性蒸馏，使得学生模型能够更好地从教师模型中学习知识。", "result": "实验显示DSKD方法在视觉识别任务上显著优于现有的知识蒸馏方法。", "conclusion": "所提的DSKD方法能有效解决知识蒸馏中的问题，并且性能优越。"}}
{"id": "2602.02100", "pdf": "https://arxiv.org/pdf/2602.02100", "abs": "https://arxiv.org/abs/2602.02100", "authors": ["Alexander Loth", "Martin Kappes", "Marc-Oliver Pahl"], "title": "The Verification Crisis: Expert Perceptions of GenAI Disinformation and the Case for Reproducible Provenance", "categories": ["cs.CY", "cs.AI", "cs.SI"], "comment": "Accepted at ACM TheWebConf '26 Companion", "summary": "The growth of Generative Artificial Intelligence (GenAI) has shifted disinformation production from manual fabrication to automated, large-scale manipulation. This article presents findings from the first wave of a longitudinal expert perception survey (N=21) involving AI researchers, policymakers, and disinformation specialists. It examines the perceived severity of multimodal threats -- text, image, audio, and video -- and evaluates current mitigation strategies. Results indicate that while deepfake video presents immediate \"shock\" value, large-scale text generation poses a systemic risk of \"epistemic fragmentation\" and \"synthetic consensus,\" particularly in the political domain. The survey reveals skepticism about technical detection tools, with experts favoring provenance standards and regulatory frameworks despite implementation barriers. GenAI disinformation research requires reproducible methods. The current challenge is measurement: without standardized benchmarks and reproducibility checklists, tracking or countering synthetic media remains difficult. We propose treating information integrity as an infrastructure with rigor in data provenance and methodological reproducibility.", "AI": {"tldr": "研究通过专家调查评估了生成式人工智能在制造虚假信息方面的威胁和现有的缓解策略。", "motivation": "随着生成式人工智能的发展，虚假信息的生产从人工制造转变为自动化大规模操作。这导致传统检测工具失效，并且需要新的方法来解决这些问题。", "method": "文章使用了一项针对AI研究人员、政策制定者和虚假信息专家的纵向专家意见调查（N=21），以评估各种威胁的程度以及当前的缓解策略的有效性。", "result": "调查显示，虽然深度伪造视频具有即时冲击力，但大规模文本生成在政治领域造成了知识分裂和合成共识。此外，技术检测工具受到质疑，专家更倾向于使用数据来源标准和监管框架，尽管存在实施障碍。", "conclusion": "研究建议将信息完整性视为基础设施，并强调在数据来源和方法论的可重复性上要保持严谨，以克服测量挑战并追踪或对抗合成媒体。"}}
{"id": "2602.02098", "pdf": "https://arxiv.org/pdf/2602.02098", "abs": "https://arxiv.org/abs/2602.02098", "authors": ["Yannik Schnitzer", "Mathias Jackermeier", "Alessandro Abate", "David Parker"], "title": "Probabilistic Performance Guarantees for Multi-Task Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-task reinforcement learning trains generalist policies that can execute multiple tasks. While recent years have seen significant progress, existing approaches rarely provide formal performance guarantees, which are indispensable when deploying policies in safety-critical settings. We present an approach for computing high-confidence guarantees on the performance of a multi-task policy on tasks not seen during training. Concretely, we introduce a new generalisation bound that composes (i) per-task lower confidence bounds from finitely many rollouts with (ii) task-level generalisation from finitely many sampled tasks, yielding a high-confidence guarantee for new tasks drawn from the same arbitrary and unknown distribution. Across state-of-the-art multi-task RL methods, we show that the guarantees are theoretically sound and informative at realistic sample sizes.", "AI": {"tldr": "论文提出了一种计算多任务策略在未见过的任务上的性能保证的方法。", "motivation": "现有的多任务强化学习方法很少提供形式化的性能保证，在安全关键场景部署策略时这是必不可少的。", "method": "通过引入新的泛化界，该界由有限数量的轮次中的每个任务下的较低置信界限和从有限数量的采样任务中获得的任务级泛化组成。", "result": "论文展示了这些保证在现实样本量下是理论上有意义且具有信息性的，并适用于最先进的多任务强化学习方法。", "conclusion": "该研究为多任务强化学习策略提供了高置信度性能保证，促进了其在安全关键环境中的应用。"}}
{"id": "2602.02096", "pdf": "https://arxiv.org/pdf/2602.02096", "abs": "https://arxiv.org/abs/2602.02096", "authors": ["Baitian Liu", "Haiping Zhang", "Huiling Yuan", "Dongjing Wang", "Ying Li", "Feng Chen", "Hao Wu"], "title": "WADEPre: A Wavelet-based Decomposition Model for Extreme Precipitation Nowcasting with Multi-Scale Learning", "categories": ["physics.ao-ph", "cs.AI"], "comment": "The paper has been submitted to KDD 2026 and is currently under review", "summary": "The heavy-tailed nature of precipitation intensity impedes precise precipitation nowcasting. Standard models that optimize pixel-wise losses are prone to regression-to-the-mean bias, which blurs extreme values. Existing Fourier-based methods also lack the spatial localization needed to resolve transient convective cells. To overcome these intrinsic limitations, we propose WADEPre, a wavelet-based decomposition model for extreme precipitation that transitions the modeling into the wavelet domain. By leveraging the Discrete Wavelet Transform for explicit decomposition, WADEPre employs a dual-branch architecture: an Approximation Network to model stable, low-frequency advection, isolating deterministic trends from statistical bias, and a spatially localized Detail Network to capture high-frequency stochastic convection, resolving transient singularities and preserving sharp boundaries. A subsequent Refiner module then dynamically reconstructs these decoupled multi-scale components into the final high-fidelity forecast. To address optimization instability, we introduce a multi-scale curriculum learning strategy that progressively shifts supervision from coarse scales to fine-grained details. Extensive experiments on the SEVIR and Shanghai Radar datasets demonstrate that WADEPre achieves state-of-the-art performance, yielding significant improvements in capturing extreme thresholds and maintaining structural fidelity. Our code is available at https://github.com/sonderlau/WADEPre.", "AI": {"tldr": "提出了一种基于小波分解的极端降水短临预报模型WADEPre，通过双分支架构和多尺度学习策略解决传统模型在处理极端降水时的问题。", "motivation": "传统的降水预测模型存在回归到均值偏差问题，难以准确捕捉极端降水事件。现有的傅立叶方法缺乏空间定位能力以区分瞬态对流单元。", "method": "WADEPre采用小波变换进行显式分解，利用双分支架构：近似网络用于建模稳定的低频平移和隔离确定性趋势与统计偏差；细节网络捕捉高频随机对流，并保持尖锐边界。引入多尺度学习策略以解决优化不稳定性问题。", "result": "在SEVIR和上海雷达数据集上的实验表明，WADEPre实现了最先进的性能，在极端阈值捕获和结构保真度方面取得了显著改进。", "conclusion": "提出的基于小波分解的模型WADEPre有效解决了传统模型在处理极端降水时的问题，并展示了优越的预报能力。"}}
{"id": "2602.02092", "pdf": "https://arxiv.org/pdf/2602.02092", "abs": "https://arxiv.org/abs/2602.02092", "authors": ["FSVideo Team", "Qingyu Chen", "Zhiyuan Fang", "Haibin Huang", "Xinwei Huang", "Tong Jin", "Minxuan Lin", "Bo Liu", "Celong Liu", "Chongyang Ma", "Xing Mei", "Xiaohui Shen", "Yaojie Shen", "Fuwen Tan", "Angtian Wang", "Xiao Yang", "Yiding Yang", "Jiamin Yuan", "Lingxi Zhang", "Yuxin Zhang"], "title": "FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space", "categories": ["cs.CV"], "comment": "Project Page: https://kingofprank.github.io/fsvideo/", "summary": "We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space ($64\\times64\\times4$ spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report.", "AI": {"tldr": "本文介绍了FSVideo，一种基于快速变换器的图像到视频扩散框架。", "motivation": "为了实现高效且高质量的视频生成，作者提出了一种新的视频自动编码器和改进的扩散转换器架构。", "method": "该方法包括一个新的高度压缩的空间-时间降尺度为64x64x4的视频自动编码器，一个具有新层内存设计以增强信息流的扩散变压器（DIT）架构，以及一个多分辨率生成策略通过几个步骤的DIT上采样器。", "result": "最终模型实现了与其他流行开源模型相当的表现，同时快了一个数量级。", "conclusion": "本文展示了FSVideo框架的有效性，并讨论了其设计和训练策略。"}}
{"id": "2602.02090", "pdf": "https://arxiv.org/pdf/2602.02090", "abs": "https://arxiv.org/abs/2602.02090", "authors": ["Yikai Zeng", "Yingchao Piao", "Jianhui Li"], "title": "LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Constructing domain-specific knowledge graphs from unstructured text remains challenging due to heterogeneous entity mentions, long-tail relation distributions, and the absence of standardized schemas. We present LEC-KG, a bidirectional collaborative framework that integrates the semantic understanding of Large Language Models (LLMs) with the structural reasoning of Knowledge Graph Embeddings (KGE). Our approach features three key components: (1) hierarchical coarse-to-fine relation extraction that mitigates long-tail bias, (2) evidence-guided Chain-of-Thought feedback that grounds structural suggestions in source text, and (3) semantic initialization that enables structural validation for unseen entities. The two modules enhance each other iteratively-KGE provides structure-aware feedback to refine LLM extractions, while validated triples progressively improve KGE representations. We evaluate LEC-KG on Chinese Sustainable Development Goal (SDG) reports, demonstrating substantial improvements over LLM baselines, particularly on low-frequency relations. Through iterative refinement, our framework reliably transforms unstructured policy text into validated knowledge graph triples.", "AI": {"tldr": "本文提出了一种用于构建领域特定知识图谱的双向协作框架LEC-KG，该框架结合了大型语言模型和知识图谱嵌入技术。", "motivation": "从非结构化文本中构建领域特定的知识图谱存在异构实体提及、长尾关系分布及缺乏标准化模式等问题。本文旨在通过整合大语言模型和知识图谱嵌入的方法来解决这些问题。", "method": "该方法包括三个关键组件：分层粗到细的关系抽取以减轻长尾偏差，基于证据的Chain-of-Thought反馈将结构化建议与源文本关联起来以及语义初始化使新实体可以进行结构验证。两个模块通过迭代增强彼此的效果。", "result": "在中文可持续发展目标报告上的评估显示LEC-KG相较于语言模型基线方法有显著改进，特别是在低频关系上表现更佳。", "conclusion": "本文提出的框架能够可靠地将非结构化政策文本转化为经验证的知识图谱三元组。"}}
{"id": "2602.02089", "pdf": "https://arxiv.org/pdf/2602.02089", "abs": "https://arxiv.org/abs/2602.02089", "authors": ["Changbai Li", "Haodong Zhu", "Hanlin Chen", "Xiuping Liang", "Tongfei Chen", "Shuwei Shao", "Linlin Yang", "Huobin Tan", "Baochang Zhang"], "title": "UrbanGS: A Scalable and Efficient Architecture for Geometrically Accurate Large-Scene Reconstruction", "categories": ["cs.CV"], "comment": "ICLR 2026", "summary": "While 3D Gaussian Splatting (3DGS) enables high-quality, real-time rendering for bounded scenes, its extension to large-scale urban environments gives rise to critical challenges in terms of geometric consistency, memory efficiency, and computational scalability. To address these issues, we present UrbanGS, a scalable reconstruction framework that effectively tackles these challenges for city-scale applications. First, we propose a Depth-Consistent D-Normal Regularization module. Unlike existing approaches that rely solely on monocular normal estimators, which can effectively update rotation parameters yet struggle to update position parameters, our method integrates D-Normal constraints with external depth supervision. This allows for comprehensive updates of all geometric parameters. By further incorporating an adaptive confidence weighting mechanism based on gradient consistency and inverse depth deviation, our approach significantly enhances multi-view depth alignment and geometric coherence, which effectively resolves the issue of geometric accuracy in complex large-scale scenes. To improve scalability, we introduce a Spatially Adaptive Gaussian Pruning (SAGP) strategy, which dynamically adjusts Gaussian density based on local geometric complexity and visibility to reduce redundancy. Additionally, a unified partitioning and view assignment scheme is designed to eliminate boundary artifacts and optimize computational load. Extensive experiments on multiple urban datasets demonstrate that UrbanGS achieves superior performance in rendering quality, geometric accuracy, and memory efficiency, providing a systematic solution for high-fidelity large-scale scene reconstruction.", "AI": {"tldr": "UrbanGS是一种可扩展的城市规模场景重建框架，旨在解决大规模城市环境中几何一致性、内存效率和计算可扩展性的问题。", "motivation": "为了克服现有技术在大规模城市环境中的局限性，如几何不一致性和计算效率低下等问题，提出了一种新的解决方案以提高大尺度三维场景的渲染质量和几何精度。", "method": "UrbanGS采用了深度一致性D-Normal正则化模块以及空间自适应高斯修剪策略。前者通过融合外部深度监督来增强多视角深度对齐和几何连贯性；后者根据局部几何复杂性和可见度动态调整高斯密度以减少冗余，并设计了统一的分区和视图分配方案。", "result": "实验表明，UrbanGS在渲染质量、几何精度和内存效率方面优于现有技术，能够有效地处理大规模城市场景重建任务。", "conclusion": "该框架提供了高效解决大规模场景高保真度重构问题的方法，为实际应用中的城市规模三维重建提供了一个系统的解决方案。"}}
{"id": "2602.02086", "pdf": "https://arxiv.org/pdf/2602.02086", "abs": "https://arxiv.org/abs/2602.02086", "authors": ["Chen Feng", "Sébastien Lugan", "Karine Lasaracina", "Midori Sugaya", "Benoît Macq"], "title": "Neurophysiological effects of museum modalities on emotional engagement with real artworks", "categories": ["eess.SP", "cs.HC"], "comment": "7 pages, 4 figures - \\c{opyright}IEEE EmotionSense 2026/PerCom 2026", "summary": "Museums increasingly rely on digital content to support visitors' understanding of artworks, yet little is known about how these formats shape the emotional engagement that underlies meaningful art experiences. This research presents an in-situ EEG study on how digital interpretive content modulate engagement during art viewing. Participants experienced three modalities: direct viewing of a Bruegel painting, a 180° immersive interpretive projection, and a regular, display-based interpretive video. Frontal EEG markers of motivational orientation, internal involvement, perceptual drive, and arousal were extracted using eyes-open baselines and Z-normalized contrasts. Results show modality-specific engagement profiles: display-based interpretive video induced high arousal and fast-band activity, immersive projections promoted calm, presence-oriented absorption, and original artworks reflected internally regulated engagement. These findings, relying on lightweight EEG sensing in an operational cultural environment, suggest that digital interpretive content affects engagement style rather than quantity. This paves the way for new multimodal sensing approaches and enables museums to optimize the modalities and content of their interpretive media.", "AI": {"tldr": "研究通过EEG探讨不同展示方式对观看艺术品时情感参与的影响。", "motivation": "博物馆越来越依赖数字内容来支持参观者理解艺术作品，但这些格式如何影响人们的情感投入尚不清楚。该研究旨在探究数字化解释内容在观看艺术作品期间的调节作用。", "method": "参与者经历了三种不同的展示方式：直接观察一幅勃鲁盖尔画作、180°沉浸式解说投影和常规显示式解说视频。使用眼睛睁开基准线提取了前额EEG动机定向、内部参与度、感知驱动力及唤醒程度的指标，并通过Z标准化对比进行了分析。", "result": "结果显示，不同的展示方式对应特定的情感投入模式：常规显示式解说视频引起高唤醒和快速带活动；沉浸式投影促进了平静且以存在为导向的吸收状态；原始艺术品反映了内部调节型参与。这些发现基于轻量级EEG传感在运营文化环境中的应用。", "conclusion": "该研究发现表明，数字解释内容影响情感投入风格而不是数量。这为博物馆优化解说媒体的形式和内容提供了新的多模态感知方法的可能性。"}}
{"id": "2602.02067", "pdf": "https://arxiv.org/pdf/2602.02067", "abs": "https://arxiv.org/abs/2602.02067", "authors": ["Nikola Cenikj", "Özgün Turgut", "Alexander Müller", "Alexander Steger", "Jan Kehrer", "Marcus Brugger", "Daniel Rueckert", "Eimo Martens", "Philip Müller"], "title": "Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Coronary artery stenosis is a leading cause of cardiovascular disease, diagnosed by analyzing the coronary arteries from multiple angiography views. Although numerous deep-learning models have been proposed for stenosis detection from a single angiography view, their performance heavily relies on expensive view-level annotations, which are often not readily available in hospital systems. Moreover, these models fail to capture the temporal dynamics and dependencies among multiple views, which are crucial for clinical diagnosis. To address this, we propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level stenosis classification. Trained on a real-world clinical dataset, using patient-level supervision and without any view-level annotations, SegmentMIL jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. SegmentMIL obtains high performance on internal and external evaluations and outperforms both view-level models and classical MIL baselines, underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis. Our code is available at https://github.com/NikolaCenic/mil-stenosis.", "AI": {"tldr": "本文提出了一种基于Transformer的多视图多次实例学习框架SegmentMIL，用于冠状动脉狭窄患者的分类。", "motivation": "现有深度学习模型依赖昂贵的视图级别注释，并且无法捕捉多个视图之间的动态和依赖性。因此，该研究旨在开发一种新的方法来克服这些限制。", "method": "研究人员提出了一种基于Transformer的多次实例学习框架SegmentMIL，用于患者级别的狭窄分类任务，此框架不需要任何视图级别的标注。", "result": "实验结果表明，所提出的SegmentMIL在内部和外部评估中均表现出色，并优于基于视图的方法和经典多次实例学习基线方法。", "conclusion": "研究证明了SegmentMIL作为冠状动脉狭窄诊断的临床可行性和可扩展性的潜力。"}}
{"id": "2602.02063", "pdf": "https://arxiv.org/pdf/2602.02063", "abs": "https://arxiv.org/abs/2602.02063", "authors": ["Ding Xia", "Xinyue Gui", "Mark Colley", "Fan Gao", "Zhongyi Zhou", "Dongyuan Li", "Renhe Jiang", "Takeo Igarashi"], "title": "See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers", "categories": ["cs.HC", "cs.AI"], "comment": "Under Review", "summary": "Automated vehicles lack natural communication channels with other road users, making external Human-Machine Interfaces (eHMIs) essential for conveying intent and maintaining trust in shared environments. However, most eHMI studies rely on developer-crafted message-action pairs, which are difficult to adapt to diverse and dynamic traffic contexts. A promising alternative is to use Large Language Models (LLMs) as action designers that generate context-conditioned eHMI actions, yet such designers lack perceptual verification and typically depend on fixed prompts or costly human-annotated feedback for improvement. We present See2Refine, a human-free, closed-loop framework that uses vision-language model (VLM) perceptual evaluation as automated visual feedback to improve an LLM-based eHMI action designer. Given a driving context and a candidate eHMI action, the VLM evaluates the perceived appropriateness of the action, and this feedback is used to iteratively revise the designer's outputs, enabling systematic refinement without human supervision. We evaluate our framework across three eHMI modalities (lightbar, eyes, and arm) and multiple LLM model sizes. Across settings, our framework consistently outperforms prompt-only LLM designers and manually specified baselines in both VLM-based metrics and human-subject evaluations. Results further indicate that the improvements generalize across modalities and that VLM evaluations are well aligned with human preferences, supporting the robustness and effectiveness of See2Refine for scalable action design.", "AI": {"tldr": "提出了See2Refine框架，利用视觉语言模型的感知评估来改进基于大型语言模型的eHMI动作设计者。", "motivation": "现有外部人机界面(eHMI)依赖人工制定的消息-动作对，难以适应多样化的交通环境。使用大型语言模型作为动作设计师可以生成适合特定场景的动作，但缺乏视觉验证和固定的提示或昂贵的人工反馈改善机制。", "method": "提出See2Refine框架，利用视觉语言模型（VLM）的感知评估作为自动视觉反馈来改进基于LLM的eHMI动作设计。通过驾驶环境和候选eHMI动作，VLM评估其适宜性，并将此反馈用于迭代修正设计师输出。", "result": "实验表明See2Refine框架在多种模态（灯光条、眼睛、手臂）以及不同大小的语言模型上均优于仅基于提示的LLM设计者和人工指定基线。结果还显示改进具有跨模态泛化性，VLM评估与人类偏好一致。", "conclusion": "See2Refine框架通过视觉语言模型感知反馈实现无监督优化，展示了在eHMI动作设计上的有效性和鲁棒性，支持规模化应用。"}}
{"id": "2602.02060", "pdf": "https://arxiv.org/pdf/2602.02060", "abs": "https://arxiv.org/abs/2602.02060", "authors": ["Hyunsuk Chung", "Caren Han", "Yerin Choi", "Seungyeon Ji", "Jinwoo Kim", "Eun-Jung Holden", "Kyungreem Han"], "title": "FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal foundation models integrate heterogeneous signals across modalities, yet it remains poorly understood how their predictions depend on specific internal feature groups and whether such reliance can be deliberately controlled. Existing studies of shortcut and spurious behavior largely rely on post hoc analyses or feature removal, offering limited insight into whether reliance can be modulated without altering task semantics. We introduce FiLoRA (Focus-and-Ignore LoRA), an instruction-conditioned, parameter-efficient adaptation framework that enables explicit control over internal feature reliance while keeping the predictive objective fixed. FiLoRA decomposes adaptation into feature group-aligned LoRA modules and applies instruction-conditioned gating, allowing natural language instructions to act as computation-level control signals rather than task redefinitions. Across text--image and audio--visual benchmarks, we show that instruction-conditioned gating induces consistent and causal shifts in internal computation, selectively amplifying or suppressing core and spurious feature groups without modifying the label space or training objective. Further analyses demonstrate that FiLoRA yields improved robustness under spurious feature interventions, revealing a principled mechanism to regulate reliance beyond correlation-driven learning.", "AI": {"tldr": "介绍了FiLoRA框架，该框架允许通过自然语言指令控制内部特征依赖性。", "motivation": "现有研究中关于模型预测依赖于特定的内部特征组的理解有限，并且难以在不改变任务语义的情况下进行调控。本文提出了FiLoRA框架来解决这一问题。", "method": "提出了一种基于LoRA模块和指令控制门控机制的方法，使得自然语言指令能够作为计算级别的控制信号。", "result": "实验结果显示，FiLoRA可以在不修改标签空间或训练目标的情况下，通过指令条件化门控诱导出一致且因果性的内部计算变化。", "conclusion": "该研究证明了FiLoRA能够在多模态模型中提供一种新的手段来调节对特定特征的依赖性，并提高了在面对虚假特征干扰时的稳健性。"}}
{"id": "2602.02055", "pdf": "https://arxiv.org/pdf/2602.02055", "abs": "https://arxiv.org/abs/2602.02055", "authors": ["Nan Qiao", "Sheng Yue"], "title": "FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification", "categories": ["cs.LG", "cs.AI"], "comment": "accetped by IEEE International Conference on Communications (ICC 2026)", "summary": "In Internet-of-Things systems, federated learning has advanced online reinforcement learning (RL) by enabling parallel policy training without sharing raw data. However, interacting with real environments online can be risky and costly, motivating offline federated RL (FRL), where local devices learn from fixed datasets. Despite its promise, offline FRL may break down under low-quality, heterogeneous data. Offline RL tends to get stuck in local optima, and in FRL, one device's suboptimal policy can degrade the aggregated model, i.e., policy pollution. We present FORLER, combining Q-ensemble aggregation on the server with actor rectification on devices. The server robustly merges device Q-functions to curb policy pollution and shift heavy computation off resource-constrained hardware without compromising privacy. Locally, actor rectification enriches policy gradients via a zeroth-order search for high-Q actions plus a bespoke regularizer that nudges the policy toward them. A $δ$-periodic strategy further reduces local computation. We theoretically provide safe policy improvement performance guarantees. Extensive experiments show FORLER consistently outperforms strong baselines under varying data quality and heterogeneity.", "AI": {"tldr": "FORLER 是一种联邦离线强化学习框架，结合 Q 集合聚合和演员修正来提高模型性能。", "motivation": "当前的联邦离线强化学习方法在处理低质量和异构数据时容易陷入局部最优解，且一个设备上的次优策略可能影响全局模型。因此，FORLER 旨在解决这些问题并提供一种稳健的方法。", "method": "FORLER 包括服务器端 Q 集合聚合以减少政策污染和客户端演员修正以改善策略梯度，同时减轻资源限制的计算压力。", "result": "实验表明 FORLER 在不同数据质量和异构性条件下均优于现有方法。", "conclusion": "FORLER 提供了一种有效的联邦离线强化学习框架，能够显著提高模型性能并提供安全的政策改进保证。"}}
{"id": "2602.02051", "pdf": "https://arxiv.org/pdf/2602.02051", "abs": "https://arxiv.org/abs/2602.02051", "authors": ["Shivank Garg", "Ayush Singh", "Gaurav Kumar Nayak"], "title": "SIDiffAgent: Self-Improving Diffusion Agent", "categories": ["cs.AI"], "comment": null, "summary": "Text-to-image diffusion models have revolutionized generative AI, enabling high-quality and photorealistic image synthesis. However, their practical deployment remains hindered by several limitations: sensitivity to prompt phrasing, ambiguity in semantic interpretation (e.g., ``mouse\" as animal vs. a computer peripheral), artifacts such as distorted anatomy, and the need for carefully engineered input prompts. Existing methods often require additional training and offer limited controllability, restricting their adaptability in real-world applications. We introduce Self-Improving Diffusion Agent (SIDiffAgent), a training-free agentic framework that leverages the Qwen family of models (Qwen-VL, Qwen-Image, Qwen-Edit, Qwen-Embedding) to address these challenges. SIDiffAgent autonomously manages prompt engineering, detects and corrects poor generations, and performs fine-grained artifact removal, yielding more reliable and consistent outputs. It further incorporates iterative self-improvement by storing a memory of previous experiences in a database. This database of past experiences is then used to inject prompt-based guidance at each stage of the agentic pipeline. \\modelour achieved an average VQA score of 0.884 on GenAIBench, significantly outperforming open-source, proprietary models and agentic methods. We will publicly release our code upon acceptance.", "AI": {"tldr": "SIDiffAgent是一种无需额外训练的代理框架，利用Qwen系列模型解决文本到图像扩散模型在实际部署中的问题。", "motivation": "现有方法存在需要额外训练、输入提示工程复杂等问题，限制了文本生成图像技术的应用。SIDiffAgent旨在通过自主管理提示工程等手段提高图像质量的一致性和可靠性。", "method": "SIDiffAgent利用Qwen系列模型解决图像扩散模型中的问题，并结合记忆数据库实现自我迭代改进。", "result": "SIDiffAgent在GenAIBench上取得了平均VQA评分为0.884的成绩，显著优于开源、专有模型和代理方法。", "conclusion": "SIDiffAgent通过自主管理和优化提示工程等机制提高了生成图像的质量，具有较高的可靠性和一致性。"}}
{"id": "2602.02050", "pdf": "https://arxiv.org/pdf/2602.02050", "abs": "https://arxiv.org/abs/2602.02050", "authors": ["Zeping Li", "Hongru Wang", "Yiwen Zhao", "Guanhua Chen", "Yixia Li", "Keyang Chen", "Yixin Cao", "Guangnan Ye", "Hongfeng Chai", "Mengdi Wang", "Zhenfei Yin"], "title": "Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot experiments and observe a strong positive correlation between entropy reduction and high-quality tool calls. Building on this finding, we propose using entropy reduction as a supervisory signal and design two reward strategies to address the differing needs of optimizing tool-use behavior. Sparse outcome rewards provide coarse, trajectory-level guidance to improve efficiency, while dense process rewards offer fine-grained supervision to enhance performance. Experiments across diverse domains show that both reward designs improve tool-use behavior: the former reduces tool calls by 72.07% compared to the average of baselines, while the latter improves performance by 22.27%. These results position entropy reduction as a key mechanism for enhancing tool-use behavior, enabling agents to be more adaptive in real-world applications.", "AI": {"tldr": "基于熵减少优化大型语言模型代理的工具使用行为", "motivation": "在长轨迹中，大型语言模型（LLM）的代理人频繁触发过多且质量低下的工具调用，增加了延迟并降低了推理性能。该研究旨在通过控制熵来解决此问题。", "method": "进行了基于熵减少的实验，并设计了两种奖励策略：稀疏结果奖励和密集过程奖励以改善工具使用行为。", "result": "实验证明这两种奖励方法都能改进代理人的工具使用表现，其中稀疏结果奖励减少了72.07％的工具调用次数，而密集过程奖励则提高了22.27％的表现。", "conclusion": "熵减少是优化大型语言模型代理人工具使用行为的关键机制，使它们在现实世界的应用中更加灵活和适应性强。"}}
{"id": "2602.02048", "pdf": "https://arxiv.org/pdf/2602.02048", "abs": "https://arxiv.org/abs/2602.02048", "authors": ["Umberto Domanti", "Lorenzo Campidelli", "Sergio Agnoli", "Antonella De Angeli"], "title": "Are Semantic Networks Associated with Idea Originality in Artificial Creativity? A Comparison with Human Agents", "categories": ["cs.HC"], "comment": "Accepted for publication in ACM CHI Conference on Human Factors in Computing Systems (CHI 2026)", "summary": "The application of generative artificial intelligence in Creativity Support Tools (CSTs) presents the challenge of interfacing two black boxes: the user's mind and the machine engine. According to Artificial Cognition, this challenge involves theories, methods, and constructs developed to study human creativity. Consistently, the paper investigated the relationship between semantic networks organisation and idea originality in Large Language Models. Data was collected by administering a set of standardised tests to ChatGPT-4o and 81 psychology students, divided into higher and lower creative individuals. The expected relationship was confirmed in the comparison between ChatGPT-4o and higher creative humans. However, despite having a more rigid network, ChatGPT-4o emerged as more original than lower creative humans. We attributed this difference to human motivational processes and model hyperparameters, advancing a research agenda for the study of artificial creativity. In conclusion, we illustrate the potential of this construct for designing and evaluating CSTs.", "AI": {"tldr": "探讨大型语言模型（LLM）的语义网络组织与创意原创性之间的关系。", "motivation": "研究大型语言模型和人类在创造力支持工具中的应用挑战，并探究两者之间创意原创性的联系。", "method": "通过给ChatGPT-4o和81名心理学学生进行标准化测试来收集数据，这些学生被分为较高创造力和较低创造力两个组。", "result": "发现ChatGPT-4o与较高创造力的人类相比存在预期关系；尽管网络更僵硬，但ChatGPT-4o表现出更高的创意原创性。", "conclusion": "人类动机过程和模型超参数可能是两者差异的原因，并提出研究人工智能创造力的研究议程。"}}
{"id": "2602.02043", "pdf": "https://arxiv.org/pdf/2602.02043", "abs": "https://arxiv.org/abs/2602.02043", "authors": ["Cristian Sbrolli", "Matteo Matteucci", "Toshihiko Yamasaki"], "title": "Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Modern Vision-Language Models (VLMs) exhibit a critical flaw in compositional reasoning, often confusing \"a red cube and a blue sphere\" with \"a blue cube and a red sphere\". Disentangling the visual and linguistic roots of these failures is a fundamental challenge for robust evaluation. To enable fine-grained, controllable analysis, we introduce Auto-Comp, a fully automated and synthetic pipeline for generating scalable benchmarks. Its controllable nature is key to dissecting and isolating different reasoning skills. Auto-Comp generates paired images from Minimal (e.g., \"a monitor to the left of a bicycle on a white background\") and LLM-generated Contextual captions (e.g., \"In a brightly lit photography studio, a monitor is positioned to the left of a bicycle\"), allowing a controlled A/B test to disentangle core binding ability from visio-linguistic complexity. Our evaluation of 20 VLMs on novel benchmarks for color binding and spatial relations reveals universal compositional failures in both CLIP and SigLIP model families. Crucially, our novel \"Confusion Benchmark\" reveals a deeper flaw beyond simple attribute swaps: models are highly susceptible to low-entropy distractors (e.g., repeated objects or colors), demonstrating their compositional failures extend beyond known bag-of-words limitations. we uncover a surprising trade-off: visio-linguistic context, which provides global scene cues, aids spatial reasoning but simultaneously hinders local attribute binding by introducing visual clutter. We release the Auto-Comp pipeline to facilitate future benchmark creation, alongside all our generated benchmarks (https://huggingface.co/AutoComp).", "AI": {"tldr": "Auto-Comp是一种自动化管道，用于生成可扩展的合成基准测试，以评估视觉语言模型在组合推理方面的缺陷。", "motivation": "现代视觉语言模型在组合推理方面存在关键性缺陷。为了解决这一问题并进行细致可控的分析，作者提出了一种自动化方法来生成大规模基准测试。", "method": "Auto-Comp通过生成配对图像和最小化/LLM生成上下文描述来进行对比实验，以区分核心绑定能力和视语言复杂度的影响，并揭示模型在低熵干扰情况下的失败模式。", "result": "20个视觉语言模型在新基准测试中显示出普遍的组合推理缺陷。此外，发现了一个有趣的权衡：全局场景线索有助于空间推理但同时会妨碍局部属性绑定。", "conclusion": "Auto-Comp揭示了视觉语言模型存在的深层次问题，并证明这些模型对低熵干扰高度敏感。未来工作将需要解决这一关键挑战以提升模型性能。"}}
{"id": "2602.02039", "pdf": "https://arxiv.org/pdf/2602.02039", "abs": "https://arxiv.org/abs/2602.02039", "authors": ["Wei Liu", "Peijie Yu", "Michele Orini", "Yali Du", "Yulan He"], "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "comment": "14 pages, 7 tables, 8 figures", "summary": "The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.", "AI": {"tldr": "研究评估大型语言模型的自主探究智能能力。", "motivation": "传统的大规模语言模型缺乏自主性，无法从原始数据中探索关键见解。为了解决这一问题，并测试语言模型在数据科学中的应用，引入了Deep Data Research（DDR）和DDR-Bench。", "method": "提出了一种开放式的任务DDR，其中大型语言模型可以从数据库中自动提取关键见解；并创建了一个大规模、基于检查清单的基准DDR-Bench进行可验证评估。", "result": "研究结果显示前沿模型显示出初步自主性，但长时间范围内的探索仍然具有挑战性。有效的探究智能不仅取决于代理支架或单纯扩展规模，还需要具有一些内在策略。", "conclusion": "通过DDR和DDR-Bench的研究表明，大型语言模型在实现探究智能方面还面临许多挑战，未来需要进一步研究以提高其自主性和长期探索能力。"}}
{"id": "2602.02038", "pdf": "https://arxiv.org/pdf/2602.02038", "abs": "https://arxiv.org/abs/2602.02038", "authors": ["Etienne Ménager", "Justin Carpentier"], "title": "Frictional Contact Solving for Material Point Method", "categories": ["cs.RO"], "comment": null, "summary": "Accurately handling contact with friction remains a core bottleneck for Material Point Method (MPM), from reliable contact point detection to enforcing frictional contact laws (non-penetration, Coulomb friction, and maximum dissipation principle). In this paper, we introduce a frictional-contact pipeline for implicit MPM that is both precise and robust. During the collision detection phase, contact points are localized with particle-centric geometric primitives; during the contact resolution phase, we cast frictional contact as a Nonlinear Complementarity Problem (NCP) over contact impulses and solve it with an Alternating Direction Method of Multipliers (ADMM) scheme. Crucially, the formulation reuses the same implicit MPM linearization, yielding efficiency and numerical stability. The method integrates seamlessly into the implicit MPM loop and is agnostic to modeling choices, including material laws, interpolation functions, and transfer schemes. We evaluate it across seven representative scenes that span elastic and elasto-plastic responses, simple and complex deformable geometries, and a wide range of contact conditions. Overall, the proposed method enables accurate contact localization, reliable frictional handling, and broad generality, making it a practical solution for MPM-based simulations in robotics and related domains.", "AI": {"tldr": "该论文提出了一个精确且鲁棒的处理摩擦接触的方法，适用于材料点法（MPM），通过将摩擦接触问题转化为非线性互补问题并使用交替方向乘子法进行求解。", "motivation": "准确处理接触和摩擦一直是材料点方法中的核心难题，包括可靠的接触点检测以及执行摩擦接触定律。为了解决这些问题，本文提出了一种精确且鲁棒的摩擦接触解决管道。", "method": "在碰撞检测阶段使用基于粒子几何原语的方法来定位接触点；将摩擦接触问题表述为非线性互补问题并采用交替方向乘子法进行求解。该方法利用相同的隐式MPM线化，提高了效率和数值稳定性。", "result": "通过在七个具有代表性的场景中测试该方法，验证了其准确性、可靠性和广泛的适用性，包括弹性及弹塑性响应、简单与复杂变形几何结构以及各种接触条件。", "conclusion": "提出的方法能够实现精确的接触定位和可靠的摩擦处理，并适用于多种材料模型，使其成为基于MPM模拟在机器人学及相关领域的一种实用解决方案。"}}
{"id": "2602.02035", "pdf": "https://arxiv.org/pdf/2602.02035", "abs": "https://arxiv.org/abs/2602.02035", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization", "categories": ["cs.RO", "cs.AI", "cs.IT", "cs.LG", "cs.MA"], "comment": "Accepted at the 2026 IEEE International Conference on Robotics and Automation (ICRA 2026), Vienna, Austria. 9 pages, 4 figures, 6 tables", "summary": "Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective, bandwidth-efficient communication in multi-agent environments. Our approach learns to compress and discretize communication messages while preserving task-critical information through principled information-theoretic optimization. We introduce a gated communication mechanism that dynamically determines when communication is necessary based on environmental context and agent states. Experimental evaluation on challenging coordination tasks demonstrates that our method achieves 181.8% performance improvement over no-communication baselines while reducing bandwidth usage by 41.4%. Comprehensive Pareto frontier analysis shows dominance across the entire success-bandwidth spectrum with area-under-curve of 0.198 vs 0.142 for next-best methods. Our approach significantly outperforms existing communication strategies and establishes a theoretically grounded framework for deploying multi-agent systems in bandwidth-constrained environments such as robotic swarms, autonomous vehicle fleets, and distributed sensor networks.", "AI": {"tldr": "本文提出了一种结合信息瓶颈理论和向量量化的方法，用于多智能体环境中的带宽有效通信。", "motivation": "现实世界中机器人应用的多智能体强化学习系统面临严重的通信限制，这严重影响了协调效率。因此需要一种方法来优化多智能体之间的通信。", "method": "本文提出了一种框架，该框架结合信息瓶颈理论和向量量化技术进行带宽有效通信，通过引入门控沟通机制动态决定在什么情况下进行必要沟通。", "result": "实验结果表明，与无交流基准相比，所提方法性能提高181.8%，同时将带宽使用减少了41.4%。综合帕累托前沿分析显示，在成功-带宽谱系的整个范围内都具有主导地位。", "conclusion": "该研究为多智能体系统在机器人集群、自动驾驶汽车队列和分布式传感器网络等带宽受限环境下的应用提供了一个理论基础，显著优于现有通信策略。"}}
{"id": "2602.02034", "pdf": "https://arxiv.org/pdf/2602.02034", "abs": "https://arxiv.org/abs/2602.02034", "authors": ["Ananya Joshi", "Michael Rudow"], "title": "Constrained Process Maps for Multi-Agent Generative AI Workflows", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.", "AI": {"tldr": "该论文提出了一种基于有限时域马尔可夫决策过程（MDP）的多代理系统，用于解决复杂工作流程中的不确定性和协调问题。", "motivation": "大型语言模型（LLM）驱动的单个代理在监管环境下执行复杂工作流存在挑战，特别是观察或比较不同阶段的任务处理不确定性以及与人工监督协作时。该研究旨在通过引入一个有向无环图结构的多代理系统来解决这些问题。", "method": "提出了一种基于有限时域MDP的模型，并利用蒙特卡洛估计量化每个代理层面的知识不确定性，同时在系统层面上用终止状态捕捉不确定性。具体通过自残检测的情境实例化方法论进行展示。", "result": "实验结果表明，在某些配置下，多代理系统的准确性提高了19%，人工审查需求减少了85倍，并且处理时间也有所减少。", "conclusion": "研究表明，采用基于有限时域MDP的多代理系统可以有效提升复杂工作流中任务处理的准确性和效率。"}}
{"id": "2602.02033", "pdf": "https://arxiv.org/pdf/2602.02033", "abs": "https://arxiv.org/abs/2602.02033", "authors": ["Shuo Lu", "Haohan Wang", "Wei Feng", "Weizhen Wang", "Shen Zhang", "Yaoyu Li", "Ao Ma", "Zheng Zhang", "Jingjing Lv", "Junjie Shen", "Ching Law", "Bing Zhan", "Yuan Xu", "Huizai Yao", "Yongcan Yu", "Chenyang Si", "Jian Liang"], "title": "One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all\" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \\textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at https://github.com/JD-GenX/OSMF.", "AI": {"tldr": "该论文提出了一种名为“OSMF”的统一框架，用于在大规模广告图片生成中对齐不同群体的点击偏好。", "motivation": "现有的广告图像生成方法采用‘一刀切’策略，只优化整体点击率而不考虑用户组之间的偏好差异。这导致了特定群体的表现不佳，并限制了定向营销的有效性。", "method": "论文提出了一个基于产品感知的自适应分组的方法和一种称为G-MLLM的多模态大规模语言模型来生成针对每个群组定制的广告图片，同时提出了一种用于群组偏好对齐的Group-DPO方法进行微调。", "result": "实验结果表明，该框架在离线和在线设置中均实现了最先进的性能。", "conclusion": "通过引入GAIP数据集并开发OSMF框架，研究者们不仅提高了特定群体的点击率，还为广告图像生成领域提供了重要的资源。"}}
{"id": "2602.02029", "pdf": "https://arxiv.org/pdf/2602.02029", "abs": "https://arxiv.org/abs/2602.02029", "authors": ["Zhongyuan Lyu", "Shuoyu Hu", "Lujie Liu", "Hongxia Yang", "Ming LI"], "title": "Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation", "categories": ["cs.AI", "cs.SE"], "comment": "41 pages, 4 figures, 5 tables", "summary": "Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.", "AI": {"tldr": "介绍了一种新的中间表示（CIR），用于从自然语言描述自动生成优化模型。", "motivation": "当前LLM方法在处理复杂操作规则时面临挑战，如组合约束和适当的建模范式。为了改进这一点，作者提出了一个称为CIR的方案来解决这些问题。", "method": "开发了一种多代理流水线框架R2C，该框架包括解析问题文本、检索领域知识并生成中间表示（CIR），进而实例化优化模型。", "result": "在新的基准测试和现有文献中的基准上进行了评估，R2C获得了最先进的准确率（47.2%）并且与专有模型（如GPT-5）接近。引入反思机制后，在某些基准上的结果进一步提高。", "conclusion": "通过使用中间表示和多代理框架R2C，可以有效地从自然语言描述生成优化问题的数学模型，并且在多种情况下都优于现有方法。"}}
{"id": "2602.02028", "pdf": "https://arxiv.org/pdf/2602.02028", "abs": "https://arxiv.org/abs/2602.02028", "authors": ["Ya Gao", "Kalle Kujanpää", "Pekka Marttinen", "Harri Valpola", "Alexander Ilin"], "title": "Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories", "categories": ["cs.AI"], "comment": "under review", "summary": "Enabling artificial intelligence systems, particularly large language models, to integrate new knowledge and flexibly apply it during reasoning remains a central challenge. Existing knowledge editing approaches emphasize atomic facts, improving factual recall but often failing to integrate new information into a coherent framework usable across contexts. In this work, we argue that knowledge internalization is fundamentally a reasoning problem rather than a memorization problem. Consequently, a model should be trained in situations where the new information is instrumental to solving a task, combined with pre-existing knowledge, and exercised through multi-step reasoning. Based on this insight, we propose a training strategy based on three principles. First, new knowledge is introduced as a coherent background story that contextualizes novel facts and explains their relation to existing knowledge. Second, models are trained using self-generated multi-hop questions that require multi-step reasoning involving the new information. Third, training is done using knowledge distillation, forcing a student model to internalize the teacher's reasoning behavior without access to the novel information. Experiments show that models trained with this strategy effectively leverage newly acquired knowledge during reasoning and achieve remarkable performance on challenging questions that require combining multiple new facts.", "AI": {"tldr": "提出了一种基于背景故事和多步推理的训练策略，使模型能更好地整合新知识。", "motivation": "现有知识编辑方法侧重于原子事实，虽然提升了事实回溯能力，但无法将新信息融入到跨情境可用的整体框架中。因此，需要一种新的方式来解决这一问题。", "method": "提出了一种训练策略，包括引入连贯的背景故事以提供新旧信息的关系；使用自动生成的多跳问题进行培训，这些问题需要通过多个步骤推理才能解答；采用知识蒸馏方法使学生模型模仿教师的行为而不直接访问新的信息。", "result": "实验表明，经过此策略训练的模型在推理过程中能够有效利用新获得的知识，并且在需要结合多个新事实解决难题方面表现出色。", "conclusion": "通过基于背景故事和多步推理的培训方法，人工智能系统特别是大型语言模型可以更有效地整合并应用新知识。"}}
{"id": "2602.02027", "pdf": "https://arxiv.org/pdf/2602.02027", "abs": "https://arxiv.org/abs/2602.02027", "authors": ["Sicheng Shen", "Mingyang Lv", "Han Shen", "Jialin Wu", "Binghao Wang", "Zhou Yang", "Guobin Shen", "Dongcheng Zhao", "Feifei Zhao", "Yi Zeng"], "title": "Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron", "categories": ["cs.AI", "cs.LG"], "comment": "21 pages, 3 figures", "summary": "The safety of large language models (LLMs) has increasingly emerged as a fundamental aspect of their development. Existing safety alignment for LLMs is predominantly achieved through post-training methods, which are computationally expensive and often fail to generalize well across different models. A small number of lightweight alignment approaches either rely heavily on prior-computed safety injections or depend excessively on the model's own capabilities, resulting in limited generalization and degraded efficiency and usability during generation. In this work, we propose a safety-aware decoding method that requires only low-cost training of an expert model and employs a single neuron as a gating mechanism. By effectively balancing the model's intrinsic capabilities with external guidance, our approach simultaneously preserves utility and enhances output safety. It demonstrates clear advantages in training overhead and generalization across model scales, offering a new perspective on lightweight alignment for the safe and practical deployment of large language models. Code: https://github.com/Beijing-AISI/NGSD.", "AI": {"tldr": "本文提出了一种新的轻量级对齐方法，通过单个神经元作为门控机制来提高大规模语言模型的安全性。", "motivation": "现有LLM的对齐方法通常计算成本高昂且泛化能力有限，而轻量级方法要么依赖预先计算的安全注入，要么过度依赖模型本身的能力。为了解决这些问题，本文提出了一个基于模型自我反思的方法以提升安全性。", "method": "该方法通过低代价训练专家模型，并使用单个神经元作为门控机制来平衡模型的内在能力与外部指导，从而同时保持实用性和增强输出的安全性。", "result": "这种方法展示了在训练负担和跨规模泛化上的明显优势，为大规模语言模型的安全部署提供了一种新的视角。", "conclusion": "所提出的方法不仅降低了计算成本，还提高了安全性，适合于大规模语言模型的实际应用。"}}
{"id": "2602.02026", "pdf": "https://arxiv.org/pdf/2602.02026", "abs": "https://arxiv.org/abs/2602.02026", "authors": ["Zhenwei Niu", "Xiaoyi Chen", "Jiayu Hu", "Zhaoyang Liu", "Xiaozu Ju"], "title": "Synchronized Online Friction Estimation and Adaptive Grasp Control for Robust Gentle Grasp", "categories": ["cs.RO"], "comment": null, "summary": "We introduce a unified framework for gentle robotic grasping that synergistically couples real-time friction estimation with adaptive grasp control. We propose a new particle filter-based method for real-time estimation of the friction coefficient using vision-based tactile sensors. This estimate is seamlessly integrated into a reactive controller that dynamically modulates grasp force to maintain a stable grip. The two processes operate synchronously in a closed-loop: the controller uses the current best estimate to adjust the force, while new tactile feedback from this action continuously refines the estimation. This creates a highly responsive and robust sensorimotor cycle. The reliability and efficiency of the complete framework are validated through extensive robotic experiments.", "AI": {"tldr": "本文提出了一个统一框架，通过实时摩擦估计与自适应抓取控制实现稳健的轻柔机器人抓取。", "motivation": "为了在机器人抓取中实现实时摩擦估计和自适应控制，从而提高抓取的安全性和稳定性。", "method": "提出了一种基于粒子滤波的方法来实时估算摩擦系数，并将其无缝集成到动态调整抓握力的控制器中。两个过程同步运行于闭环系统中，相互影响，形成高效的传感器运动循环。", "result": "通过广泛的机器人实验验证了所提框架的有效性及可靠性。", "conclusion": "该方法成功地实现了在轻柔抓取中的实时摩擦估计和自适应控制，提高了抓取的稳健性和响应速度。"}}
{"id": "2602.02023", "pdf": "https://arxiv.org/pdf/2602.02023", "abs": "https://arxiv.org/abs/2602.02023", "authors": ["Carlos Quijano-Chavez", "Benjamin Lee", "Nina Doerr", "Wolfgang Büschel", "Michael Sedlmair", "Dieter Schmalstieg"], "title": "Situated Brushing and Linking in Virtual and Augmented Reality", "categories": ["cs.HC"], "comment": null, "summary": "In traditional visual analysis, brushing and linking is commonly used to visually connect multiple views using highlighting techniques. However, brushing and linking has rarely been used in situated analytics, which uses visualizations to analyze data in the context of physical referents. In situated analytics, data representations must be visually linked to real-world objects. Previous work has assessed situated brushing and linking in a virtual reality simulation of a supermarket scenario. Here, we replicate and extend the previous approach by studying brushing and linking in an actual physical space with augmented reality, while further improving the highlighting techniques. Using a video see-through display, we compare augmented reality with virtual reality. Results suggest that AR performs better in time and accuracy, but the effectiveness of the techniques varies by condition. These results provide a new framing of how the real-world stimuli matter in situated analytics.", "AI": {"tldr": "研究通过虚拟现实和增强现实比较刷选和链接技术在实际物理空间中的应用效果，改进了高亮技术。", "motivation": "传统视觉分析中常用的刷选和链接技术很少用于情境化分析，后者需要将数据表示与真实世界的对象联系起来。本研究旨在填补这一空白，探索刷选和链接技术如何更有效地应用于现实世界场景中。", "method": "使用视频透射式显示设备，在实际物理空间中比较虚拟现实和增强现实中刷选和链接技术的表现，并改进了高亮技术。", "result": "结果显示，AR在时间和准确性上表现更好，但不同条件下其有效性有所差异。", "conclusion": "研究结果表明，现实世界中的刺激因素对情境化分析至关重要，提供了新的视角以理解如何更好地利用现实世界的元素进行数据分析。"}}
{"id": "2602.02020", "pdf": "https://arxiv.org/pdf/2602.02020", "abs": "https://arxiv.org/abs/2602.02020", "authors": ["Jens Egholm Pedersen", "Tony Lindeberg", "Peter Gerstoft"], "title": "Scale-covariant spiking wavelets", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "We establish a theoretical connection between wavelet transforms and spiking neural networks through scale-space theory. We rely on the scale-covariant guarantees in the leaky integrate-and-fire neurons to implement discrete mother wavelets that approximate continuous wavelets. A reconstruction experiment demonstrates the feasibility of the approach and warrants further analysis to mitigate current approximation errors. Our work suggests a novel spiking signal representation that could enable more energy-efficient signal processing algorithms.", "AI": {"tldr": "本文建立了小波变换和脉冲神经网络之间的理论联系，提出了一个可行的离散母小波实现方案。", "motivation": "通过尺度空间理论将小波变换与脉冲神经网络连接起来，利用泄漏积分放电神经元在尺度空域中的协变保证来近似连续的小波。", "method": "基于漏电积分-放电模型的特性实现了离散母小波，并进行了重构实验。", "result": "证明了该方法的可行性，但仍需进一步分析以减少当前的近似误差。", "conclusion": "提出了一种新的脉冲信号表示法，可能使更节能的信号处理算法成为可能。"}}
{"id": "2602.02018", "pdf": "https://arxiv.org/pdf/2602.02018", "abs": "https://arxiv.org/abs/2602.02018", "authors": ["Enes Altinisik", "Masoomali Fatehkia", "Fatih Deniz", "Nadir Durrani", "Majd Hawasly", "Mohammad Raza", "Husrev Taha Sencar"], "title": "Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction", "categories": ["cs.AI"], "comment": null, "summary": "Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.", "AI": {"tldr": "研究提出一种名为VeriFY的训练框架，用于减少大型语言模型在事实性上的幻觉。", "motivation": "现有的方法主要依赖于外部后验证或直接将不确定性映射到微调期间的不回答行为，这导致了过于保守的表现。因此需要更有效的策略来解决大型语言模型中的事实性幻觉问题。", "method": "VeriFY通过一致性自我验证引导模型产生初始答案、生成并回答一个探测式验证查询、进行一致判断，并决定是否给出或拒绝答案，从而训练模型以应对事实不确定性。为避免在增强的追踪上训练时强化幻觉内容，提出了阶段级别的损失掩码方法。", "result": "VeriFY在多个模型家族和规模中将事实性幻觉率降低了9.7%到53.3%，仅略有降低召回率（0.4%到5.7%），并且可以在单个数据源上训练后泛化到不同的数据集。", "conclusion": "VeriFY提供了一种有效的策略，通过在模型训练期间引入自我验证来减少大型语言模型的事实性幻觉。这种方法具有广泛的适用性和较好的效果平衡。"}}
{"id": "2602.02014", "pdf": "https://arxiv.org/pdf/2602.02014", "abs": "https://arxiv.org/abs/2602.02014", "authors": ["Hongxin Xiang", "Pengsen Ma", "Yunkang Cao", "Di Yu", "Haowen Chen", "Xinyu Yang", "Xiangxiang Zeng"], "title": "Rethinking Genomic Modeling Through Optical Character Recognition", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \\emph{visual DNA encoder} and a \\emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\\times$ fewer effective tokens, and surpasses models with up to $985\\times$ more activated parameters while tuning only 256k \\emph{trainable} parameters.", "AI": {"tldr": "本文提出OpticalDNA，一种基于光学字符识别的框架，将基因组建模重新定义为文档理解问题，以提高长序列数据的理解和压缩能力。", "motivation": "现有基因模型架构处理DNA时存在计算浪费和对低信息背景的过度依赖，无法有效压缩长文脉。本文动机在于通过视觉布局理解和OCR方法改进DNA编码效率与准确性。", "method": "OpticalDNA将DNA转换为结构化的视觉布局，并采用OCR风格的文档理解训练方式，结合视觉编码器和文档解码器来生成高效、可复原的视觉标记，保留精细基因信息同时减少有效令牌数量。", "result": "在各种基因组基准测试中，OpticalDNA优于现有基线方法；对于长达450k碱基数的序列，在使用更少有效令牌的情况下实现最佳性能，并在激活参数仅为对手模型1/985的同时，仅需256k可调参数即达到超越效果。", "conclusion": "OpticalDNA通过视觉布局理解和OCR技术改进基因组建模效率和精度，是处理长序列数据的有效方法。"}}
{"id": "2602.02007", "pdf": "https://arxiv.org/pdf/2602.02007", "abs": "https://arxiv.org/abs/2602.02007", "authors": ["Zhanghao Hu", "Qinglin Zhu", "Hanqi Yan", "Yulan He", "Lin Gui"], "title": "Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.", "AI": {"tldr": "xMemory系统通过将记忆分解为语义组件并组织成层次结构来改进代理内存检索，提高答案质量和效率。", "motivation": "当前的RAG管道在处理高度相关和重复的内容时存在冗余和信息丢失的问题。因此提出了一种新的方法来优化代理记忆中的检索过程。", "method": "xMemory通过解耦聚合的方法，将记忆分解为语义组件并组织成层次结构，使用这种结构驱动检索，并且在推理过程中从上到下选择一组紧凑且多样化的主题和语义来回答问题。", "result": "实验表明，在LoCoMo和PerLTQA数据集上的三个最新LLM中，xMemory在答案质量和令牌效率方面都表现出一致的改进。", "conclusion": "通过解耦聚合的方法优化代理记忆检索可以显著提高系统的性能。"}}
{"id": "2602.02006", "pdf": "https://arxiv.org/pdf/2602.02006", "abs": "https://arxiv.org/abs/2602.02006", "authors": ["Thomas Jantos", "Giulio Delama", "Stephan Weiss", "Jan Steinbrener"], "title": "Reformulating AI-based Multi-Object Relative State Estimation for Aleatoric Uncertainty-based Outlier Rejection of Partial Measurements", "categories": ["cs.RO"], "comment": "Accepted for publication at ICRA 2026, Vienna, Austria", "summary": "Precise localization with respect to a set of objects of interest enables mobile robots to perform various tasks. With the rise of edge devices capable of deploying deep neural networks (DNNs) for real-time inference, it stands to reason to use artificial intelligence (AI) for the extraction of object-specific, semantic information from raw image data, such as the object class and the relative six degrees of freedom (6-DoF) pose. However, fusing such AI-based measurements in an Extended Kalman Filter (EKF) requires quantifying the DNNs' uncertainty and outlier rejection capabilities. This paper presents the benefits of reformulating the measurement equation in AI-based, object-relative state estimation. By deriving an EKF using the direct object-relative pose measurement, we can decouple the position and rotation measurements, thus limiting the influence of erroneous rotation measurements and allowing partial measurement rejection. Furthermore, we investigate the performance and consistency improvements for state estimators provided by replacing the fixed measurement covariance matrix of the 6-DoF object-relative pose measurements with the predicted aleatoric uncertainty of the DNN.", "AI": {"tldr": "本文提出了一种基于人工智能的多对象相对状态估计方法，通过重新表述测量方程来增强部分测量数据的异常值剔除能力。", "motivation": "精确的对象定位对于移动机器人执行任务至关重要。随着边缘设备能够实时部署深度神经网络（DNN）提取语义信息，如何将这些智能感知结果有效地融合到扩展卡尔曼滤波器中成为一个挑战。该研究旨在探索基于人工智能的相对姿态测量如何通过量化不确定性和异常值剔除来改进状态估计。", "method": "本文提出了一种新的方法，即重新表述AI-based多对象相对状态估计中的测量方程，并在EKF框架内引入预测的随机不确定性来替换固定的6-DoF物体相对姿势测量协方差矩阵。通过这种方法可以实现位置和旋转测量之间的解耦，从而减少错误旋转测量的影响。", "result": "实验表明，与传统的固定测量协方差相比，基于预测随机不确定性的方法在性能和一致性方面都有显著提高。", "conclusion": "研究表明重新表述AI-based相对姿态测量的方法可以在一定程度上缓解错误旋转测量带来的负面影响，并通过引入不确定性来增强部分测量数据的异常值剔除能力。"}}
{"id": "2602.02004", "pdf": "https://arxiv.org/pdf/2602.02004", "abs": "https://arxiv.org/abs/2602.02004", "authors": ["Gongli Xi", "Kun Wang", "Zeming Gao", "Huahui Yi", "Haolang Lu", "Ye Tian", "Wendong Wang"], "title": "ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Suppression in Multimodal Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages, 7 figures", "summary": "Large multimodal reasoning models solve challenging visual problems via explicit long-chain inference: they gather visual clues from images and decode clues into textual tokens. Yet this capability also increases hallucinations, where the model generates content that is not supported by the input image or the question. To understand this failure mode, we identify \\emph{reasoning drift}: during clue gathering, the model over-focuses on question-irrelevant entities, diluting focus on task-relevant cues and gradually decoupling the reasoning trace from visual grounding. As a consequence, many inference-time localization or intervention methods developed for non-reasoning models fail to pinpoint the true clues in reasoning settings. Motivated by these insights, we introduce ClueRecall, a metric for assessing visual clue retrieval, and present ClueTracer, a training-free, parameter-free, and architecture-agnostic plugin for hallucination suppression. ClueTracer starts from the question and traces how key clues propagate along the model's reasoning pathway (question $\\rightarrow$ outputs $\\rightarrow$ visual tokens), thereby localizing task-relevant patches while suppressing spurious attention to irrelevant regions. Remarkably, \\textbf{without any additional training}, ClueTracer improves all \\textbf{reasoning} architectures (including \\texttt{R1-OneVision}, \\texttt{Ocean-R1}, \\texttt{MM-Eureka}, \\emph{etc}.) by $\\mathbf{1.21\\times}$ on reasoning benchmarks. When transferred to \\textbf{non-reasoning} settings, it yields a $\\mathbf{1.14\\times}$ gain.", "AI": {"tldr": "本文提出了一种无训练、参数无关且架构无关的插件ClueTracer，用于抑制多模态推理中的幻觉。", "motivation": "在从图像中收集视觉线索并将这些线索解码为文本令牌的过程中，大型多模态推理模型的能力也增加了幻觉现象。为了理解这一失败模式，作者提出了\"推理漂移\"的概念，即模型过度关注与问题无关的实体，从而导致任务相关的线索被忽视。", "method": "ClueTracer通过从问题开始追踪关键线索在模型推理路径中的传播来定位任务相关区域，并抑制对不相关区域的关注。该方法使用一种称为ClueRecall的新指标评估视觉线索检索情况。", "result": "实验表明，无需任何额外训练，ClueTracer可以提升所有推理架构（包括R1-OneVision、Ocean-R1和MM-Eureka等）在推理基准上的表现，平均提高1.21倍。当应用于非推理设置时，性能也提升了1.14倍。", "conclusion": "本文提出了一种有效且通用的方法来抑制多模态推理模型中的幻觉现象，并提高了整体推理准确性。"}}
{"id": "2602.02002", "pdf": "https://arxiv.org/pdf/2602.02002", "abs": "https://arxiv.org/abs/2602.02002", "authors": ["Guosheng Zhao", "Yaozeng Wang", "Xiaofeng Wang", "Zheng Zhu", "Tingdong Yu", "Guan Huang", "Yongchen Zai", "Ji Jiao", "Changliang Xue", "Xiaole Wang", "Zhen Yang", "Futang Zhu", "Xingang Wang"], "title": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving", "categories": ["cs.CV"], "comment": "16 pages, 7 figures", "summary": "World models have demonstrated significant promise for data synthesis in autonomous driving. However, existing methods predominantly concentrate on single-modality generation, typically focusing on either multi-camera video or LiDAR sequence synthesis. In this paper, we propose UniDriveDreamer, a single-stage unified multimodal world model for autonomous driving, which directly generates multimodal future observations without relying on intermediate representations or cascaded modules. Our framework introduces a LiDAR-specific variational autoencoder (VAE) designed to encode input LiDAR sequences, alongside a video VAE for multi-camera images. To ensure cross-modal compatibility and training stability, we propose Unified Latent Anchoring (ULA), which explicitly aligns the latent distributions of the two modalities. The aligned features are fused and processed by a diffusion transformer that jointly models their geometric correspondence and temporal evolution. Additionally, structured scene layout information is projected per modality as a conditioning signal to guide the synthesis. Extensive experiments demonstrate that UniDriveDreamer outperforms previous state-of-the-art methods in both video and LiDAR generation, while also yielding measurable improvements in downstream", "AI": {"tldr": "UniDriveDreamer是一款单阶段多模态世界模型，用于自动驾驶中的未来观察生成。", "motivation": "现有方法主要集中在单一模式的生成上，而本论文旨在提出一种能够直接生成多模态未来的统一世界模型。", "method": "该框架引入了特定于LiDAR的变分自动编码器（VAE），以及一个多摄像机图像的视频VAE。通过联合训练来确保跨模式兼容性和稳定性，并利用Unified Latent Anchoring (ULA)对齐两种模态的潜在分布，最后由一个扩散变压器处理融合后的特征。", "result": "实验表明，UniDriveDreamer在视频和LiDAR生成方面超越了最先进的方法。", "conclusion": "该论文提出了一种新的多模态世界模型，能够有效提升自动驾驶中未来观察的合成质量。"}}
{"id": "2602.02001", "pdf": "https://arxiv.org/pdf/2602.02001", "abs": "https://arxiv.org/abs/2602.02001", "authors": ["Yoonjun Cho", "Dongjae Jeon", "Soeun Kim", "Moongyu Jeon", "Albert No"], "title": "Preserve-Then-Quantize: Balancing Rank Budgets for Quantization Error Reconstruction in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantization Error Reconstruction (QER) reduces accuracy loss in Post-Training Quantization (PTQ) by approximating weights as $\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$, using a rank-$r$ correction to reconstruct quantization error. Prior methods devote the full rank budget to error reconstruction, which is suboptimal when $\\mathbf{W}$ has intrinsic low-rank structure and quantization corrupts dominant directions. We propose Structured Residual Reconstruction (SRR), a rank-allocation framework that preserves the top-$k$ singular subspace of the activation-scaled weight before quantization, quantizes only the residual, and uses the remaining rank $r-k$ for error reconstruction. We derive a theory-guided criterion for selecting $k$ by balancing quantization-exposed energy and unrecoverable error under rank constraints. We further show that resulting $\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ parameterization naturally supports Quantized Parameter-Efficient Fine-Tuning (QPEFT), and stabilizes fine-tuning via gradient scaling along preserved directions. Experiments demonstrate consistent perplexity reductions across diverse models and quantization settings in PTQ, along with a 5.9 percentage-point average gain on GLUE under 2-bit QPEFT.", "AI": {"tldr": "本文提出了一种新的秩分配框架，旨在优化低比特量化中的误差重构和模型精度。", "motivation": "传统的误差重构方法在处理具有内在低秩结构的权重矩阵时效果不佳，因为这些方法倾向于将全部秩预算用于误差重建而非保留重要的主成分方向。因此，论文提出了一种新的策略以更有效地平衡这一问题。", "method": "本文提出了一个名为Structured Residual Reconstruction (SRR) 的框架，在量化之前保留下列$k$个最大奇异值对应的子空间，并仅对剩余部分进行量化处理，同时利用剩余的秩$r-k$来重构量化误差。通过理论指导选择合适的$k$值以平衡能量暴露和不可恢复误差。", "result": "实验结果显示该方法在不同的模型及量化设置下均能显著降低困惑度，并且在2位QPEFT上比基准提高了5.9个百分点的平均GLUE分数。", "conclusion": "论文提出的SRR框架能够通过更合理地分配秩来改进低比特量化的误差重构，从而提高模型精度。"}}
{"id": "2602.02000", "pdf": "https://arxiv.org/pdf/2602.02000", "abs": "https://arxiv.org/abs/2602.02000", "authors": ["Bing He", "Jingnan Gao", "Yunuo Chen", "Ning Cao", "Gang Chen", "Zhengxue Cheng", "Li Song", "Wenjun Zhang"], "title": "SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors", "categories": ["cs.CV", "cs.AI"], "comment": "ICLR 2026; Project Page: https://hebing-sjtu.github.io/SurfSplat-website/", "summary": "Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this issue, we present SurfSplat, a feedforward framework based on 2D Gaussian Splatting (2DGS) primitive, which provides stronger anisotropy and higher geometric precision. By incorporating a surface continuity prior and a forced alpha blending strategy, SurfSplat reconstructs coherent geometry together with faithful textures. Furthermore, we introduce High-Resolution Rendering Consistency (HRRC), a new evaluation metric designed to evaluate high-resolution reconstruction quality. Extensive experiments on RealEstate10K, DL3DV, and ScanNet demonstrate that SurfSplat consistently outperforms prior methods on both standard metrics and HRRC, establishing a robust solution for high-fidelity 3D reconstruction from sparse inputs. Project page: https://hebing-sjtu.github.io/SurfSplat-website/", "AI": {"tldr": "本文提出了一种基于二维高斯点绘制的前向框架SurfSplat，以解决从稀疏图像重建高质量三维场景的问题。", "motivation": "当前方法在生成三维场景时往往产生不连续表面和色彩偏差的点云。为了解决这一问题，作者提出了一个新框架来提高几何精度并保持纹理真实性。", "method": "SurfSplat利用二维高斯绘制技术结合表面连续性先验以及强制alpha混合策略，以重建连贯且准确的几何形状与真实纹理。", "result": "实验结果表明，在RealEstate10K、DL3DV和ScanNet数据集上，SurfSplat在标准评价指标及作者提出的高分辨率渲染一致性评估下均优于现有方法。", "conclusion": "通过引入二维高斯绘制技术及其相关改进策略，SurfSplat提供了一种有效的方法来实现高质量的三维场景重建。"}}
{"id": "2602.01997", "pdf": "https://arxiv.org/pdf/2602.01997", "abs": "https://arxiv.org/abs/2602.01997", "authors": ["Safal Shrestha", "Anubhav Shrestha", "Aadim Nepal", "Minwu Kim", "Keith Ross"], "title": "On the Limits of Layer Pruning for Generative Reasoning in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes.", "AI": {"tldr": "本文研究了层裁剪对大语言模型（LLMs）生成推理任务的影响，并提出了一种基于自我生成响应的监督微调策略来缓解这一问题。", "motivation": "现有研究表明，通过层裁剪压缩大型语言模型可以在分类基准测试中保留强大的性能。然而，在需要多步骤推理的任务上，这些模型的表现严重下降，因此本研究旨在探索在实际训练约束下的深度减少方法的有效性。", "method": "本文通过系统研究多个模型家族中的任务发现，对多步推理敏感的深层裁剪导致了关键算法能力的退化。提出了一种基于自我生成响应的监督微调策略来缓解这一问题，并评估其性能。", "result": "所提出的微调策略在分类任务中取得了90%基准表现的恢复，在生成性基准测试中的改进幅度为20-30个百分点，表明这种方法对于深度减少的有效性取决于裁剪比率和任务类型。", "conclusion": "尽管通过基于自我生成响应的监督微调策略取得了一定的效果，但对生成推理的任务而言，层裁剪的恢复能力仍然有限。因此，建议在实际训练约束下谨慎应用深度减少技术，并针对不同的任务选择合适的裁剪比例。"}}
{"id": "2602.01996", "pdf": "https://arxiv.org/pdf/2602.01996", "abs": "https://arxiv.org/abs/2602.01996", "authors": ["Theologos Anthimopoulos", "Milad Kokhazadeh", "Vasilios Kelefouras", "Benjamin Himpel", "Georgios Keramidas"], "title": "Optimizing Tensor Train Decomposition in DNNs for RISC-V Architectures Using Design Space Exploration and Compiler Optimizations", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.MS"], "comment": "36 pages, 16 figures, this is the author-accepted version of the article published in ACM Transactions on Embedded Computing Systems (TECS), Vol. 24, No. 6", "summary": "Deep neural networks (DNNs) have become indispensable in many real-life applications like natural language processing, and autonomous systems. However, deploying DNNs on resource-constrained devices, e.g., in RISC-V platforms, remains challenging due to the high computational and memory demands of fully connected (FC) layers, which dominate resource consumption. Low-rank factorization (LRF) offers an effective approach to compressing FC layers, but the vast design space of LRF solutions involves complex trade-offs among FLOPs, memory size, inference time, and accuracy, making the LRF process complex and time-consuming. This paper introduces an end-to-end LRF design space exploration methodology and a specialized design tool for optimizing FC layers on RISC-V processors. Using Tensor Train Decomposition (TTD) offered by TensorFlow T3F library, the proposed work prunes the LRF design space by excluding first, inefficient decomposition shapes and second, solutions with poor inference performance on RISC-V architectures. Compiler optimizations are then applied to enhance custom T3F layer performance, minimizing inference time and boosting computational efficiency. On average, our TT-decomposed layers run 3x faster than IREE and 8x faster than Pluto on the same compressed model. This work provides an efficient solution for deploying DNNs on edge and embedded devices powered by RISC-V architectures.", "AI": {"tldr": "优化深度神经网络（DNN）中的张量列车分解以适应RISC-V架构", "motivation": "在资源受限的设备上部署DNN面临计算和内存需求高的挑战，特别是在全连接层。低秩因子化是一种有效的压缩方法，但其设计空间复杂且耗时。本文提出了一种针对RISC-V处理器优化FC层的设计空间探索方法及专用工具。", "method": "使用TensorFlow T3F库中的张量列车分解（TTD）来排除无效的分解形状和性能差的解，并通过编译器优化提高自定义T3F图层的性能，从而减少推理时间和提升计算效率。", "result": "平均而言，本文提出的TT-分解图层比IREE快三倍，比Pluto快八倍，同时在压缩模型上保持高性能。", "conclusion": "该工作为RISC-V架构驱动的边缘和嵌入式设备上的DNN部署提供了高效的解决方案。"}}
{"id": "2602.01995", "pdf": "https://arxiv.org/pdf/2602.01995", "abs": "https://arxiv.org/abs/2602.01995", "authors": ["Jeongmoon Won", "Seungwon Kook", "Yohan Jo"], "title": "Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that patients provide rich and concrete information, which is unrealistic. To address these limitations, we propose a conversational diagnosis system that explores a diagnostic knowledge graph to reason in two steps: (i) generating diagnostic hypotheses from the dialogue context, and (ii) verifying hypotheses through clarifying questions, which are repeated until a final diagnosis is reached. Since evaluating the system requires a realistic patient simulator that responds to the system's questions, we adopt a well-established simulator along with patient profiles from MIMIC-IV. We further adapt it to describe symptoms vaguely to reflect real-world patients during early clinical encounters. Experiments show improved diagnostic accuracy and efficiency over strong baselines, and evaluations by physicians support the realism of our simulator and the clinical utility of the generated questions. Our code will be released upon publication.", "AI": {"tldr": "论文提出了一个通过探索诊断知识图谱进行多轮对话以实现精确诊断的系统。", "motivation": "现有的方法通常依赖模型参数化知识或者假定患者提供详细信息，这在实际中并不现实。为了克服这些限制，该研究旨在开发一种能够模拟真实临床环境下医生问诊过程的系统。", "method": "该系统包括两个主要步骤：（一）基于对话上下文生成诊断假设；（二）通过提出澄清性问题验证诊断假设，并重复此过程直到得到最终诊断。", "result": "实验表明，与现有的基线方法相比，该系统的诊断准确性和效率均有提升。医生的评估还支持了模拟器的真实感及系统中提出的问题具有临床实用性。", "conclusion": "这项研究证明了一种基于知识图谱探索对话式诊断的新路径的有效性，并展示了其在实际应用中的潜力和价值。"}}
{"id": "2602.01992", "pdf": "https://arxiv.org/pdf/2602.01992", "abs": "https://arxiv.org/abs/2602.01992", "authors": ["Gouki Minegishi", "Jingyuan Feng", "Hiroki Furuta", "Takeshi Kojima", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Emergent Analogical Reasoning in Transformers", "categories": ["cs.AI"], "comment": null, "summary": "Analogy is a central faculty of human intelligence, enabling abstract patterns discovered in one domain to be applied to another. Despite its central role in cognition, the mechanisms by which Transformers acquire and implement analogical reasoning remain poorly understood. In this work, inspired by the notion of functors in category theory, we formalize analogical reasoning as the inference of correspondences between entities across categories. Based on this formulation, we introduce synthetic tasks that evaluate the emergence of analogical reasoning under controlled settings. We find that the emergence of analogical reasoning is highly sensitive to data characteristics, optimization choices, and model scale. Through mechanistic analysis, we show that analogical reasoning in Transformers decomposes into two key components: (1) geometric alignment of relational structure in the embedding space, and (2) the application of a functor within the Transformer. These mechanisms enable models to transfer relational structure from one category to another, realizing analogy. Finally, we quantify these effects and find that the same trends are observed in pretrained LLMs. In doing so, we move analogy from an abstract cognitive notion to a concrete, mechanistically grounded phenomenon in modern neural networks.", "AI": {"tldr": "本文通过引入合成任务来评估类比推理的出现，并发现Transformer中类比推理的机制。", "motivation": "探讨Transformer如何获得和实现类比推理，将抽象的认知现象转化为现代神经网络中的具体、机制性现象。", "method": "基于范畴论中的函子概念，形式化类比推理为实体跨类别的对应关系推断。引入合成任务评估在受控环境下的类比推理出现情况，并通过机械分析展示Transformer中类比推理的两个关键组成部分。", "result": "发现类比推理的高度敏感性取决于数据特征、优化选择和模型规模；量化这些效应并在预训练的语言模型中观察到相同趋势。", "conclusion": "将类比从抽象的认知概念转变为现代神经网络中的具体机制现象，揭示了Transformer实现类比推理的具体方式。"}}
{"id": "2602.01991", "pdf": "https://arxiv.org/pdf/2602.01991", "abs": "https://arxiv.org/abs/2602.01991", "authors": ["Pablo Domingo-Gregorio", "Javier Ruiz-Hidalgo"], "title": "Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models emerged as a leading approach in text-to-image generation, producing high-quality images from textual descriptions. However, attempting to achieve detailed control to get a desired image solely through text remains a laborious trial-and-error endeavor. Recent methods have introduced image-level controls alongside with text prompts, using prior images to extract conditional information such as edges, segmentation and depth maps. While effective, these methods apply conditions uniformly across the entire image, limiting localized control. In this paper, we propose a novel methodology to enable precise local control over user-defined regions of an image, while leaving to the diffusion model the task of autonomously generating the remaining areas according to the original prompt. Our approach introduces a new training framework that incorporates masking features and an additional loss term, which leverages the prediction of the initial latent vector at any diffusion step to enhance the correspondence between the current step and the final sample in the latent space. Extensive experiments demonstrate that our method effectively synthesizes high-quality images with controlled local conditions.", "AI": {"tldr": "本文提出了一种新的方法，通过扩散模型实现图像生成中的局部控制。", "motivation": "现有方法难以通过文本实现详细的图像控制，并且引入的条件限制了局部控制的灵活性。", "method": "该研究引入了一个新的训练框架，结合掩膜特征和额外损失项，利用初始潜在向量预测来增强当前步骤与最终样本在潜在空间中的对应关系，从而实现在用户定义区域内的精确控制。", "result": "实验结果表明，该方法能够生成高质量的图像，并且可以实现局部条件下的控制。", "conclusion": "通过引入新的训练框架和利用初始潜在向量预测的方法，成功实现了图像生成中对特定区域的精准控制。"}}
{"id": "2602.01990", "pdf": "https://arxiv.org/pdf/2602.01990", "abs": "https://arxiv.org/abs/2602.01990", "authors": ["Zhen-Hao Xie", "Jun-Tao Tang", "Yu-Cheng Shi", "Han-Jia Ye", "De-Chuan Zhan", "Da-Wei Zhou"], "title": "SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) achieve strong performance through instruction tuning, but real-world deployment requires them to continually expand their capabilities, making Multimodal Continual Instruction Tuning (MCIT) essential. Recent methods leverage sparse expert routing to promote task specialization, but we find that the expert routing process suffers from drift as the data distribution evolves. For example, a grounding query that previously activated localization experts may instead be routed to irrelevant experts after learning OCR tasks. Meanwhile, the grounding-related experts can be overwritten by new tasks and lose their original functionality. Such failure reflects two problems: router drift, where expert selection becomes inconsistent over time, and expert drift, where shared experts are overwritten across tasks. Therefore, we propose StAbilized Mixture-of-Experts (SAME) for MCIT. To address router drift, SAME stabilizes expert selection by decomposing routing dynamics into orthogonal subspaces and updating only task-relevant directions. To mitigate expert drift, we regulate expert updates via curvature-aware scaling using historical input covariance in a rehearsal-free manner. SAME also introduces adaptive expert activation to freeze selected experts during training, reducing redundant computation and cross-task interference. Extensive experiments demonstrate its SOTA performance.", "AI": {"tldr": "本文提出了一种名为SAME的多模态连续指令调优方法，旨在解决专家选择随时间不一致和共享专家被新任务覆盖的问题。", "motivation": "随着数据分布的变化，当前的方法在稀疏专家路由过程中存在漂移问题，导致专家的选择不稳定且原有功能丧失。因此需要一种新的方法来稳定专家选择并减少专家间干扰。", "method": "SAME通过将路由动态分解为正交子空间来解决路由器漂移，并只更新任务相关方向。同时采用基于历史输入协方差的曲率感知缩放机制来管理专家更新，以降低专家漂移。此外引入自适应激活机制，在训练过程中冻结选定的专家。", "result": "实验结果表明SAME在多模态连续指令调优方面表现出色，达到了SOTA性能。", "conclusion": "本文提出了SAME方法解决了现有模型中遇到的问题，并展示了其在实际应用中的优越性。"}}
{"id": "2602.01986", "pdf": "https://arxiv.org/pdf/2602.01986", "abs": "https://arxiv.org/abs/2602.01986", "authors": ["Shreyan Biswas", "Alexander Erlei", "Ujwal Gadiraju"], "title": "Belief Updating and Delegation in Multi-Task Human-AI Interaction: Evidence from Controlled Simulations", "categories": ["cs.HC"], "comment": null, "summary": "Large language models (LLMs) increasingly support heterogeneous tasks within a single interface, requiring users to form, update, and act upon beliefs about one system across domains with different reliability profiles. Understanding how such beliefs transfer across tasks and shape delegation is therefore critical for the design of multipurpose AI systems. We report a preregistered experiment (N=240; 7,200 trials) in which participants interacted with a controlled AI simulation across grammar checking, travel planning, and visual question answering, each with fixed, domain-typical accuracy levels. Delegation was operationalized as a binary reliance decision: accepting the AI's output versus acting independently, and belief dynamics were evaluated against Bayesian benchmarks. We find three main results. First, participants do not reset beliefs between tasks: priors in a new task depend on posteriors from the previous task, with a 10-point increase predicting a 3-4 point higher subsequent prior. Second, within tasks, belief updating follows the Bayesian direction but is substantially conservative, proceeding at roughly half the normative Bayesian rate. Third, delegation is driven primarily by subjective beliefs about AI accuracy rather than self-confidence, though confidence independently reduces reliance when beliefs are held constant. Together, these findings show that users form global, path-dependent expectations about multipurpose AI systems, update them conservatively, and rely on AI primarily based on subjective beliefs rather than objective performance. We discuss implications for expectation calibration, reliance design, and the risks of belief spillovers in deployed LLM-based interfaces.", "AI": {"tldr": "研究探讨了用户在多任务中如何形成、更新和基于大型语言模型的输出进行决策，特别是在信任度转移与任务间依赖性方面的表现。", "motivation": "为了理解用户如何在其使用的大型语言模型上形成跨领域不同的可靠性信念，并据此做出决策，以促进多功能AI系统的合理设计。", "method": "通过一个预注册实验（参与者240人，试验7,200次），使用受控的AI模拟进行语法检查、旅行规划和视觉问答任务。将信任决定定义为二元依赖选择：接受AI输出或独立行动，并用贝叶斯基准评估信念动态。", "result": "发现用户在不同任务之间不会重置信念，任务之间的信念是路径依赖的；更新过程保守，在正常贝叶斯速率的一半左右；决策主要基于主观信念而不是客观性能。", "conclusion": "结果表明，用户对多功能AI系统形成全球、路径依赖性的预期，并且以保守的方式进行更新，依赖于AI主要基于用户的主观信念。"}}
{"id": "2602.01984", "pdf": "https://arxiv.org/pdf/2602.01984", "abs": "https://arxiv.org/abs/2602.01984", "authors": ["Minyoung Lee", "Yeji Park", "Dongjun Hwang", "Yejin Kim", "Seong Joon Oh", "Junsuk Choe"], "title": "Enhancing Multi-Image Understanding through Delimiter Token Scaling", "categories": ["cs.CV"], "comment": "Accepted at ICLR 2026", "summary": "Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost.", "AI": {"tldr": "本文提出了一种通过调整分隔符令牌隐藏状态来增强多图像理解的方法，从而提升大型视觉-语言模型在处理多个输入图像时的表现。", "motivation": "现有大型视觉-语言模型（LVLM）在单一图像任务中表现良好，但在面对多个输入图像时性能下降。主要原因是这些模型难以区分不同图像间的信息泄露问题。", "method": "为了增强分隔符令牌的有效性，本文提出了一种方法来调整隐藏状态中的分隔符令牌，从而强化了每个图像内部信息的保留，并限制了跨图之间的不必要交互。", "result": "实验表明，在多个基准测试中（如Mantis、MuirBench、MIRB和QBen2），该方法显著提高了模型性能。此外，该方法还改善了纯文本任务中的表现，例如多文档理解和多表格理解。", "conclusion": "通过调整分隔符令牌的隐藏状态，本文提出的方法能够提升大型视觉-语言模型在处理多个输入图像时的表现，并且无需额外训练成本或推断成本。"}}
{"id": "2602.01983", "pdf": "https://arxiv.org/pdf/2602.01983", "abs": "https://arxiv.org/abs/2602.01983", "authors": ["Xintian Shen", "Jiawei Chen", "Lihao Zheng", "Hao Ma", "Tao Wei", "Kun Zhan"], "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%$\\uparrow$ and +23.04%$\\uparrow$ on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.", "AI": {"tldr": "该论文提出了一种无需训练的框架UCT，将智能体从工具使用者转变为工具创造者。", "motivation": "现有的Tool-Integrated Reasoning (TIR) 模型在扩展LLMs的问题回答能力方面取得了显著成效，但在开放性问题场景中面临挑战。这些固定工具难以适应任务需求，并且错误的工具输出会误导模型响应。此外，构建现有工具需要大量的人工工作，这限制了它们的应用。", "method": "UCT框架通过收集推理经验并将它们转化为可重用资产来实现这一转变。它使智能体能够创建自适应工具并在推理过程中自我更新，并引入记忆巩固机制以维持工具库。这种方法实现了自动化的工具构建范式，在推理过程中持续提升工具质量，无需额外训练。", "result": "实验表明，该方法显著提升了TIR模型的能力，特别是在跨领域数学和科学推理任务中的表现有所提高。", "conclusion": "该论文提出了一种新的自动化工具构建范式UCT，使智能体能够自我演化并持续提升其性能。"}}
{"id": "2602.01979", "pdf": "https://arxiv.org/pdf/2602.01979", "abs": "https://arxiv.org/abs/2602.01979", "authors": ["Fabio Stano", "Max L Wilson", "Christof Weinhardt", "Michael T Knierim"], "title": "Hacking Flow: From Lived Practices to Innovation", "categories": ["cs.HC"], "comment": null, "summary": "In digital knowledge work, flow promises not just productivity; it offers a pathway to well-being. Yet despite decades of flow research in HCI, we know little about how to design digital interventions that support it. In this work, we foreground lived interventions - everyday practices workers already use to foster flow - to uncover overlooked opportunities and chart new directions for digital intervention design. Specifically, we report findings from two studies: (1) a reflexive thematic analysis of open-ended survey responses (n = 160), surfacing 38 lived interventions across four categories: environment, organization, task shaping, and personal readiness; and (2) a quantitative online survey (n = 121) that validates this repertoire, identifies which interventions are broadly endorsed versus polarizing, and elicits visions of technological support. We contribute empirical insights into how digital workers cultivate flow, situate these lived interventions within existing literature, and derive design opportunities for future digital flow interventions.", "AI": {"tldr": "本文通过研究数字工作者的日常生活实践，探索了如何设计支持流畅工作状态（flow）的数字化干预措施。", "motivation": "尽管在人机交互（HCI）领域对流畅工作状态已有数十年的研究，但关于如何设计能够促进这种状态的数字干预措施的知识仍然有限。因此，本文旨在通过研究工人的日常生活实践来填补这一空白，并探索新的干预方向。", "method": "本研究采用了两种方法：一种是对开放性调查问卷的回答进行反思性主题分析（n = 160），识别出了38种生活在不同类别中的干预措施；另一种是在线定量调查（n = 121），用于验证这些干预措施的有效性，确定哪些广受支持而哪些具有争议，并收集对未来技术辅助的需求。", "result": "研究发现了一系列数字工作者维持流畅工作状态的生活实践，明确了它们在现有文献中的位置，并提供了未来数字化流畅工作状态设计的机会。", "conclusion": "通过探索和分析日常生活中促进流畅工作的实践，本研究为如何利用技术和数字化手段支持流畅工作状态提供了新的视角和具体的设计建议。"}}
{"id": "2602.01978", "pdf": "https://arxiv.org/pdf/2602.01978", "abs": "https://arxiv.org/abs/2602.01978", "authors": ["Roel Koopman", "Sebastian Otte", "Sander Bohté"], "title": "SpikingGamma: Surrogate-Gradient Free and Temporally Precise Online Training of Spiking Neural Networks with Smoothed Delays", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Neuromorphic hardware implementations of Spiking Neural Networks (SNNs) promise energy-efficient, low-latency AI through sparse, event-driven computation. Yet, training SNNs under fine temporal discretization remains a major challenge, hindering both low-latency responsiveness and the mapping of software-trained SNNs to efficient hardware. In current approaches, spiking neurons are modeled as self-recurrent units, embedded into recurrent networks to maintain state over time, and trained with BPTT or RTRL variants based on surrogate gradients. These methods scale poorly with temporal resolution, while online approximations often exhibit instability for long sequences and tend to fail at capturing temporal patterns precisely. To address these limitations, we develop spiking neurons with internal recursive memory structures that we combine with sigma-delta spike-coding. We show that this SpikingGamma model supports direct error backpropagation without surrogate gradients, can learn fine temporal patterns with minimal spiking in an online manner, and scale feedforward SNNs to complex tasks and benchmarks with competitive accuracy, all while being insensitive to the temporal resolution of the model. Our approach offers both an alternative to current recurrent SNNs trained with surrogate gradients, and a direct route for mapping SNNs to neuromorphic hardware.", "AI": {"tldr": "提出了一种新的SpikingGamma模型，用于在线训练具有平滑延迟的尖峰神经网络，并且不需要替代梯度。", "motivation": "当前尖峰神经网络在细粒度时间分辨率下的训练方法性能不佳，导致硬件映射困难和响应迟缓。因此开发一种新型结构来改进这些问题。", "method": "通过设计具有内部递归记忆的尖峰神经元以及与sigma-delta编码结合的方法，支持直接误差反向传播并能在线学习细微的时间模式。", "result": "SpikingGamma模型在复杂的任务和基准测试中展示了竞争力，并且对时间分辨率不敏感。", "conclusion": "该方法为替代当前使用代理梯度训练的递归尖峰神经网络提供了另一种选择，同时直接支持将尖峰神经网络映射到类脑硬件。"}}
{"id": "2602.01976", "pdf": "https://arxiv.org/pdf/2602.01976", "abs": "https://arxiv.org/abs/2602.01976", "authors": ["Hongwei Yan", "Guanglong Sun", "Kanglei Zhou", "Qian Li", "Liyuan Wang", "Yi Zhong"], "title": "FlyPrompt: Brain-Inspired Random-Expanded Routing with Temporal-Ensemble Experts for General Continual Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "33 pages. Accepted by ICLR 2026", "summary": "General continual learning (GCL) challenges intelligent systems to learn from single-pass, non-stationary data streams without clear task boundaries. While recent advances in continual parameter-efficient tuning (PET) of pretrained models show promise, they typically rely on multiple training epochs and explicit task cues, limiting their effectiveness in GCL scenarios. Moreover, existing methods often lack targeted design and fail to address two fundamental challenges in continual PET: how to allocate expert parameters to evolving data distributions, and how to improve their representational capacity under limited supervision. Inspired by the fruit fly's hierarchical memory system characterized by sparse expansion and modular ensembles, we propose FlyPrompt, a brain-inspired framework that decomposes GCL into two subproblems: expert routing and expert competence improvement. FlyPrompt introduces a randomly expanded analytic router for instance-level expert activation and a temporal ensemble of output heads to dynamically adapt decision boundaries over time. Extensive theoretical and empirical evaluations demonstrate FlyPrompt's superior performance, achieving up to 11.23%, 12.43%, and 7.62% gains over state-of-the-art baselines on CIFAR-100, ImageNet-R, and CUB-200, respectively. Our source code is available at https://github.com/AnAppleCore/FlyGCL.", "AI": {"tldr": "本文提出了FlyPrompt框架，用于解决一般持续学习中的专家分配和表示能力提升问题。", "motivation": "现有方法在处理单一通过、非平稳数据流时表现不佳，缺乏针对性设计且难以应对两个关键挑战：如何将专家参数适应不断变化的数据分布以及在有限监督下提高其代表性。本文受果蝇分层记忆系统启发提出了FlyPrompt框架。", "method": "FlyPrompt引入随机扩展分析路由器以实例级别激活专家，并采用时间集成输出头动态调整决策边界，解决GCL中的两个子问题：专家路由和增强专家表现。", "result": "实验证明，FlyPrompt在CIFAR-100、ImageNet-R和CUB-200数据集上分别比最先进的基线方法高出最多11.23%、12.43%和7.62%。", "conclusion": "通过模仿果蝇记忆系统，FlyPrompt有效解决了GCL中的关键问题，并在实验中展示了卓越的性能。"}}
{"id": "2602.01975", "pdf": "https://arxiv.org/pdf/2602.01975", "abs": "https://arxiv.org/abs/2602.01975", "authors": ["Meng Li", "Peisong Wang", "Yuantian Shao", "Qinghao Hu", "Hongjian Fang", "Yifan Zhang", "Zhihui Wei", "Jian Cheng"], "title": "IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) achieve strong performance across diverse tasks but face deployment challenges due to their massive size. Structured pruning offers acceleration benefits but leads to significant performance degradation. Recent PCA-based pruning methods have alleviated this issue by retaining key activation components, but are only applied between modules in order to fuse the transformation matrix, which introduces extra parameters and severely disrupts activation distributions due to residual connections. To address these issues, we propose IntraSlice, a framework that applies block-wise module-intra PCA compression pruning. By leveraging the structural characteristics of Transformer modules, we design an approximate PCA method whose transformation matrices can be fully fused into the model without additional parameters. We also introduce a PCA-based global pruning ratio estimator that further considers the distribution of compressed activations, building on conventional module importance. We validate our method on Llama2, Llama3, and Phi series across various language benchmarks. Experimental results demonstrate that our approach achieves superior compression performance compared to recent baselines at the same compression ratio or inference speed.", "AI": {"tldr": "提出了一种名为IntraSlice的框架，以实现大型语言模型（LLMs）的高性能结构化剪枝。", "motivation": "为了解决结构化剪枝导致性能下降的问题，以及现有PCA剪枝方法引入额外参数和破坏激活分布的问题。", "method": "设计了一种模块内分块PCA压缩剪枝的方法，并提出一种基于PCA的全局剪枝比率估计器。", "result": "在Llama2、Llama3和Phi系列模型上验证了该方法，在相同的压缩率或推理速度下，优于现有基线。", "conclusion": "IntraSlice框架通过利用Transformer模块的结构特性，实现了高性能的大型语言模型剪枝。"}}
{"id": "2602.01973", "pdf": "https://arxiv.org/pdf/2602.01973", "abs": "https://arxiv.org/abs/2602.01973", "authors": ["Muli Yang", "Gabriel James Goenawan", "Henan Wang", "Huaiyuan Qin", "Chenghao Xu", "Yanhua Yang", "Fen Fang", "Ying Sun", "Joo-Hwee Lim", "Hongyuan Zhu"], "title": "Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "AAAI 2026. Code: https://github.com/muliyangm/AIGI-Det-Calib", "summary": "Despite being trained on balanced datasets, existing AI-generated image detectors often exhibit systematic bias at test time, frequently misclassifying fake images as real. We hypothesize that this behavior stems from distributional shift in fake samples and implicit priors learned during training. Specifically, models tend to overfit to superficial artifacts that do not generalize well across different generation methods, leading to a misaligned decision threshold when faced with test-time distribution shift. To address this, we propose a theoretically grounded post-hoc calibration framework based on Bayesian decision theory. In particular, we introduce a learnable scalar correction to the model's logits, optimized on a small validation set from the target distribution while keeping the backbone frozen. This parametric adjustment compensates for distributional shift in model output, realigning the decision boundary even without requiring ground-truth labels. Experiments on challenging benchmarks show that our approach significantly improves robustness without retraining, offering a lightweight and principled solution for reliable and adaptive AI-generated image detection in the open world. Code is available at https://github.com/muliyangm/AIGI-Det-Calib.", "AI": {"tldr": "本文提出了一种基于贝叶斯决策理论的后处理校准框架，通过引入可学习标量修正模型的logits来改善AI生成图像检测器在测试时的表现。", "motivation": "现有AI生成图像检测器由于训练数据分布与实际应用中的偏差，在面对不同的生成方法时表现不佳。作者提出了一种轻量级且合理的解决方案以提高可靠性和适应性。", "method": "通过在小验证集上优化模型的logits，引入可学习标量修正来补偿输出中分布偏移，而不重新训练整个模型。", "result": "实验结果表明，在挑战性的基准测试中，该方法显著提高了检测器的鲁棒性和准确性。", "conclusion": "该研究提供了一种无需额外标注数据即可提升AI生成图像检测性能的方法。"}}
{"id": "2602.01970", "pdf": "https://arxiv.org/pdf/2602.01970", "abs": "https://arxiv.org/abs/2602.01970", "authors": ["Yun Qu", "Qi Wang", "Yixiu Mao", "Heming Zou", "Yuhang Jiang", "Weijie Liu", "Clive Bai", "Kai Yang", "Yangkun Chen", "Saiyong Yang", "Xiangyang Ji"], "title": "Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.", "AI": {"tldr": "介绍了一种名为Generalizable Predictive Prompt Selection (GPS)的方法，用于在大型语言模型的强化学习训练后选择有效的提示词，提高训练效率。", "motivation": "现有的方法要么依赖于高成本的确切评估，要么构建缺乏泛化能力的特定提示预测模型。作者旨在通过一种轻量级、通用的生成式模型来优化在线提示选择过程。", "method": "提出了GPS方法，它使用贝叶斯推理根据训练历史对提示难度进行估计，并结合中间难度优先策略和历史依赖多样性原则来选择信息丰富的提示词批次。", "result": "实验结果表明，与基线方法相比，GPS在多个推理基准上提高了训练效率、最终性能以及测试时间的计算分配效率。", "conclusion": "研究证明了通过引入通用化预测模型，在大型语言模型的强化学习后进行有效的提示选择可以显著提高整个过程的效率。"}}
{"id": "2602.01967", "pdf": "https://arxiv.org/pdf/2602.01967", "abs": "https://arxiv.org/abs/2602.01967", "authors": ["Wonjun Lee", "Hyounghun Kim", "Gary Geunbae Lee"], "title": "Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.", "AI": {"tldr": "提出了Moe-Ctc架构，结合中间CTC监督以促进专家的专业化和泛化，提升重口音语音识别的性能。", "motivation": "现有的ASR模型多训练于高资源英语变体的数据集上，对于其他口音表现不佳。accent-agnostic方法虽然增强鲁棒性但对重度或未见过的口音效果差；而accent-specific方法依赖有限且嘈杂的标签。因此，需要一种新的方法来改进重口音语音识别。", "method": "Moe-Ctc架构通过中间CTC监督促进专家的专业化和泛化，在训练过程中，基于口音感知路由使专家捕捉到特定口音模式，并逐渐过渡为无标注路由进行推理。每个专家配有自身的CTC头以提高转录质量与路由一致性，并使用路由增强损失函数进一步稳定优化。", "result": "在McV-Accent基准测试中，在低资源和高资源条件下，对于已见过和未见过的口音均显示持续性能改进，相对WER降低高达29.3％。", "conclusion": "Moe-Ctc架构展示了其有效性和泛化能力，显著提高了重口音语音识别的整体准确率。"}}
{"id": "2602.01965", "pdf": "https://arxiv.org/pdf/2602.01965", "abs": "https://arxiv.org/abs/2602.01965", "authors": ["Kwun Hang Lau", "Fangyuan Zhang", "Boyu Ruan", "Yingli Zhou", "Qintian Guo", "Ruiyuan Zhang", "Xiaofang Zhou"], "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a \"Static Graph Fallacy\": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree \"hub\" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG.", "AI": {"tldr": "本文提出了一种新的框架CatRAG，用于增强基于知识图谱的检索增强生成任务，特别是针对多跳查询。该框架通过引入上下文感知的遍历技术解决了现有方法中的静态图缺陷。", "motivation": "当前的检索增强生成（RAG）方法依赖于固定的转移概率，忽略了边的相关性是与查询相关的这一事实，导致模型无法有效地获取完整的证据链。", "method": "CatRAG通过引入符号锚定、查询感知动态边缘加权以及关键事实段落权重提升等机制来改进随机行走。这些技术有助于消除无关路径并增强与查询相关的关键信息。", "result": "在四个多跳基准数据集上的实验表明，CatRAG相比现有最佳方法实现了显著的性能提升，特别是在推理完整性和获取整个证据链方面表现突出。", "conclusion": "通过引入上下文感知遍历技术，本文的方法有效解决了现有的检索增强生成任务中的静态图问题，并提高了模型在多跳查询中的准确性与完整性。"}}
{"id": "2602.01962", "pdf": "https://arxiv.org/pdf/2602.01962", "abs": "https://arxiv.org/abs/2602.01962", "authors": ["Arip Asadulaev", "Maksim Bobrin", "Salem Lahlou", "Dmitry Dylov", "Fakhri Karray", "Martin Takac"], "title": "Zero-Shot Off-Policy Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Off-policy learning methods seek to derive an optimal policy directly from a fixed dataset of prior interactions. This objective presents significant challenges, primarily due to the inherent distributional shift and value function overestimation bias. These issues become even more noticeable in zero-shot reinforcement learning, where an agent trained on reward-free data must adapt to new tasks at test time without additional training. In this work, we address the off-policy problem in a zero-shot setting by discovering a theoretical connection of successor measures to stationary density ratios. Using this insight, our algorithm can infer optimal importance sampling ratios, effectively performing a stationary distribution correction with an optimal policy for any task on the fly. We benchmark our method in motion tracking tasks on SMPL Humanoid, continuous control on ExoRL, and for the long-horizon OGBench tasks. Our technique seamlessly integrates into forward-backward representation frameworks and enables fast-adaptation to new tasks in a training-free regime. More broadly, this work bridges off-policy learning and zero-shot adaptation, offering benefits to both research areas.", "AI": {"tldr": "该论文提出了一种零样本离策略学习算法，用于解决基于固定数据集优化策略时的分布偏移和价值函数过估计问题。", "motivation": "在无奖励的数据上训练代理后，在测试阶段快速适应新任务而不需要额外训练是一个挑战。本文旨在通过理论联系后继度量与稳定密度比来克服离策略学习中的障碍，从而实现在任何任务上的即时最优策略。", "method": "利用后继度量和稳定密度比之间的关系，该算法推断出最佳重要性采样比例，执行一种即时的分布校正以适应新任务。此方法在SMPL人体运动跟踪、ExoRL连续控制以及OGBench长时序任务中进行了基准测试。", "result": "所提出的技术能够无缝整合到前向-后向表示框架，并实现了快速适应新任务的能力，而不需要训练。", "conclusion": "本文的工作通过连接离策略学习和零样本自适应领域，提供了对这两个研究领域的贡献。"}}
{"id": "2602.01959", "pdf": "https://arxiv.org/pdf/2602.01959", "abs": "https://arxiv.org/abs/2602.01959", "authors": ["Ezequiel Lopez-Lopez", "Christoph M. Abels", "Philipp Lorenz-Spreen", "Stephan Lewandowsky", "Stefan M. Herzog"], "title": "Boosting metacognition in entangled human-AI interaction to navigate cognitive-behavioral drift", "categories": ["cs.HC"], "comment": null, "summary": "People navigate complex environments using cues, heuristics, and other strategies, which are often adaptive in stable settings. However, as AI increasingly permeates society's information environments, those become more adaptive and evolving: LLM-based chatbots participate in extended interaction, maintain conversational histories, mirror social cues, and can hypercustomize responses, thereby shaping not only what information is accessed but how questions are framed, how evidence is interpreted, and when action feels warranted. Here we propose a framework for sustained human-AI interaction that rests on invariant features of human cognition and human--AI interaction and centers on three interlinked phenomena: entanglement between users and AI systems, the emergence of cognitive and behavioral drift over repeated interactions, and the role of metacognition in the awareness and regulation of these dynamics. As conversational agents provide cues (e.g., fluency, coherence, responsiveness) that people treat as informative, subjective confidence and action readiness may increase without corresponding gains in epistemic reliability, making drift difficult to detect and correct. We describe these dynamics across micro-, meso-, and macro-levels. The framework identifies four metacognitive intervention points and psychologically informed interventions that provide metacognitive scaffolding (boosting and self-nudging). Finally, we outline a long-horizon research agenda for scientific foresight.", "AI": {"tldr": "提出了一个框架，用于理解和干预人类与AI系统之间复杂的交互过程中的认知和行为漂移。", "motivation": "随着LLM驱动的聊天机器人越来越深入人们的日常生活，它们对信息访问、问题构建以及采取行动的时间点产生了影响，这可能导致用户在主观信心增加的同时，并没有相应的提高知识可靠性。因此需要一个框架来理解和应对这种现象。", "method": "研究提出了一种基于人类认知不变特征和人机交互的理论框架，该框架关注三个相互关联的现象：用户与AI系统的纠缠、重复交互中认知行为漂移的发生以及元认知在这些动态中的作用。", "result": "描述了微、中、宏观层面的认知行为漂移，并确定了四个元认知干预点及心理学启发式的介入措施来提供元认知支持。", "conclusion": "本文提出了一个研究人类与AI系统交互过程中认知和行为漂移的长期科学研究议程，旨在通过提高用户的元认知能力帮助他们更准确地评估信息来源并做出明智决策。"}}
{"id": "2602.01956", "pdf": "https://arxiv.org/pdf/2602.01956", "abs": "https://arxiv.org/abs/2602.01956", "authors": ["Seonghyeon Park", "Jewon Yeom", "Jaewon Sok", "Jeongjae Park", "Heejun Kim", "Taesup Kim"], "title": "Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantifying uncertainty in Large Language Models (LLMs) is essential for mitigating hallucinations and enabling risk-aware deployment in safety-critical tasks. However, estimating Epistemic Uncertainty(EU) via Deep Ensembles is computationally prohibitive at the scale of modern models. We propose a framework that leverages the small draft models to efficiently estimate token-level EU, bypassing the need for full-scale ensembling. Theoretically grounded in a Bias-Variance Decomposition, our approach approximates EU via Jensen-Shannon divergence among drafts (variance proxy) and KL divergence between the draft mixture and the target (bias proxy). To further ensure accuracy without significant overhead, we introduce Online Stochastic Distillation (OSD) to efficiently approximate target aggregation and the Data-Diverse Drafts (DDD) strategy to enhance draft diversity for better target approximation. Extensive experiments on GSM8K demonstrate that our method reduces the estimation error (RMSE) by up to 37% compared to baselines. Crucially, our approach achieves Hallucination Detection performance competitive with heavy perturbation-based methods like TokUR while incurring negligible inference costs, offering a practical solution for uncertainty-aware LLM deployment.", "AI": {"tldr": "提出了一种利用小模型进行知识蒸馏的方法，以高效地估计大规模语言模型的Epistemic Uncertainty。", "motivation": "量化大规模语言模型中的不确定性对于防止幻觉和在安全关键任务中部署至关重要。然而，通过深度集成来估算Epistemic Uncertainty在现代模型规模上是计算成本高昂的。", "method": "利用小模型进行知识蒸馏的方法，理论基础在于偏差-方差分解。该方法通过Jensen-Shannon散度估计方差代理，并通过KL散度估计偏置代理。引入在线随机蒸馏（OSD）和数据多样化草稿（DDD）策略以提高准确性。", "result": "实验表明，与基准相比，该方法将估计误差降低了最多37%。在幻觉检测性能上，达到了接近重干扰方法的水平，同时几乎不增加推理成本。", "conclusion": "提出的方法提供了一种实用且高效的解决方案，可在大规模语言模型中实现不确定性感知部署"}}
{"id": "2602.01954", "pdf": "https://arxiv.org/pdf/2602.01954", "abs": "https://arxiv.org/abs/2602.01954", "authors": ["Shuai Yang", "Ziyue Huang", "Jiaxin Chen", "Qingjie Liu", "Yunhong Wang"], "title": "Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images", "categories": ["cs.CV"], "comment": null, "summary": "Open-vocabulary object detection in remote sensing commonly relies on text-only prompting to specify target categories, implicitly assuming that inference-time category queries can be reliably grounded through pretraining-induced text-visual alignment. In practice, this assumption often breaks down in remote sensing scenarios due to task- and application-specific category semantics, resulting in unstable category specification under open-vocabulary settings. To address this limitation, we propose RS-MPOD, a multimodal open-vocabulary detection framework that reformulates category specification beyond text-only prompting by incorporating instance-grounded visual prompts, textual prompts, and their multimodal integration. RS-MPOD introduces a visual prompt encoder to extract appearance-based category cues from exemplar instances, enabling text-free category specification, and a multimodal fusion module to integrate visual and textual information when both modalities are available. Extensive experiments on standard, cross-dataset, and fine-grained remote sensing benchmarks show that visual prompting yields more reliable category specification under semantic ambiguity and distribution shifts, while multimodal prompting provides a flexible alternative that remains competitive when textual semantics are well aligned.", "AI": {"tldr": "本文提出了一个用于遥感图像开放词汇目标检测的多模态提示框架RS-MPOD，通过引入视觉提示和文本提示来改善类别指定。", "motivation": "传统的开放词汇目标检测在远程传感中依赖于仅基于文本的提示方式，并假设可以通过预训练诱导出可靠的文字-视觉对齐。然而，在实际应用中这种假设往往无法满足任务或应用特定的类别语义，导致类别指定不稳定。因此本文提出了一种新的多模态框架来改善这一问题。", "method": "RS-MPOD通过引入视觉提示编码器从样本实例提取外观特征来进行无文本类别的指定，并在同时具备两种模式的情况下使用融合模块整合视觉和文本信息。", "result": "实验结果表明，视觉提示能够在语义模糊和分布变化的场景下提供更可靠的类别指定，而多模态提示则能在文本语义对齐良好的情况下保持竞争力。", "conclusion": "RS-MPOD通过引入视觉提示有效解决了开放词汇目标检测中的类别指定问题，并提供了灵活性更高的解决方案。"}}
{"id": "2602.01951", "pdf": "https://arxiv.org/pdf/2602.01951", "abs": "https://arxiv.org/abs/2602.01951", "authors": ["Shuyang Wu", "Yifu Qiu", "Ines P. Nearchou", "Sandrine Prost", "Jonathan A Fallowfield", "Hakan Bilen", "Timothy J Kendall"], "title": "Enabling Progressive Whole-slide Image Analysis with Multi-scale Pyramidal Network", "categories": ["cs.CV"], "comment": null, "summary": "Multiple-instance Learning (MIL) is commonly used to undertake computational pathology (CPath) tasks, and the use of multi-scale patches allows diverse features across scales to be learned. Previous studies using multi-scale features in clinical applications rely on multiple inputs across magnifications with late feature fusion, which does not retain the link between features across scales while the inputs are dependent on arbitrary, manufacturer-defined magnifications, being inflexible and computationally expensive. In this paper, we propose the Multi-scale Pyramidal Network (MSPN), which is plug-and-play over attention-based MIL that introduces progressive multi-scale analysis on WSI. Our MSPN consists of (1) grid-based remapping that uses high magnification features to derive coarse features and (2) the coarse guidance network (CGN) that learns coarse contexts. We benchmark MSPN as an add-on module to 4 attention-based frameworks using 4 clinically relevant tasks across 3 types of foundation model, as well as the pre-trained MIL framework. We show that MSPN consistently improves MIL across the compared configurations and tasks, while being lightweight and easy-to-use.", "AI": {"tldr": "提出了一种多尺度金字塔网络(MSPN)，用于增强全滑动图像分析。", "motivation": "现有的多尺度特征学习方法依赖于制造商定义的放大倍率，缺乏灵活性且计算成本高。MSPN旨在解决这些问题，并引入了逐步的多尺度分析。", "method": "MSPN包括网格重映射和粗略指导网络(CGN)，前者使用高分辨率特征推导出粗略特征，后者学习粗略上下文。", "result": "在4个注意机制框架中添加MSPN模块后，在4种临床相关任务上均表现出了改进。", "conclusion": "MSPN能够提高多实例学习的性能，并且轻便易用。"}}
{"id": "2602.01949", "pdf": "https://arxiv.org/pdf/2602.01949", "abs": "https://arxiv.org/abs/2602.01949", "authors": ["Leonardo Stoppani", "Davide Bacciu", "Shahab Mokarizadeh"], "title": "Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at ESANN 2026", "summary": "Diffusion models have become widely popular for automated floorplan generation, producing highly realistic layouts conditioned on user-defined constraints. However, optimizing for perceptual metrics such as the Fréchet Inception Distance (FID) causes limited design diversity. To address this, we propose the Diversity Score (DS), a metric that quantifies layout diversity under fixed constraints. Moreover, to improve geometric consistency, we introduce a Boundary Cross-Attention (BCA) module that enables conditioning on building boundaries. Our experiments show that BCA significantly improves boundary adherence, while prolonged training drives diversity collapse undiagnosed by FID, revealing a critical trade-off between realism and diversity. Out-Of-Distribution evaluations further demonstrate the models' reliance on dataset priors, emphasizing the need for generative systems that explicitly balance fidelity, diversity, and generalization in architectural design tasks.", "AI": {"tldr": "提出了一种新的边界约束扩散模型，用于生成同时满足真实性和多样性的建筑平面图", "motivation": "现有扩散模型在生成高度逼真的布局时，设计多样性不足。作者通过引入Diversity Score（DS）和Boundary Cross-Attention（BCA）模块来平衡真实感与多样性，并解决几何一致性问题", "method": "提出了一种新的边界约束扩散模型，利用BCA模块进行条件化处理以提高边界一致性，同时使用DS度量布局多样性", "result": "实验表明，所提出的BCA模块显著提高了边界遵守性；然而过长的训练会导致多样性丧失。此外，出界分布评估显示了对数据集先验的依赖", "conclusion": "需要开发能够平衡真实感、多样性和泛化能力的生成系统"}}
{"id": "2602.01948", "pdf": "https://arxiv.org/pdf/2602.01948", "abs": "https://arxiv.org/abs/2602.01948", "authors": ["Patrick Frank", "Christian Friedrich"], "title": "A Unified Control Architecture for Macro-Micro Manipulation using a Active Remote Center of Compliance for Manufacturing Applications", "categories": ["cs.RO"], "comment": "17 pages, 14 figures, submitted to Robotics and Computer-Integrated Manufacturing (RCIM)", "summary": "Macro-micro manipulators combine a macro manipulator with a large workspace, such as an industrial robot, with a lightweight, high-bandwidth micro manipulator. This enables highly dynamic interaction control while preserving the wide workspace of the robot. Traditionally, position control is assigned to the macro manipulator, while the micro manipulator handles the interaction with the environment, limiting the achievable interaction control bandwidth. To solve this, we propose a novel control architecture that incorporates the macro manipulator into the active interaction control. This leads to a increase in control bandwidth by a factor of 2.1 compared to the state of the art architecture, based on the leader-follower approach and factor 12.5 compared to traditional robot-based force control. Further we propose surrogate models for a more efficient controller design and easy adaptation to hardware changes. We validate our approach by comparing it against the other control schemes in different experiments, like collision with an object, following a force trajectory and industrial assembly tasks.", "AI": {"tldr": "本文提出了一个新的控制架构，将宏操作器纳入主动交互控制中，以提高宏观微观操作器的控制带宽和效率。", "motivation": "传统的控制系统分配位置控制给宏操作器，而微操作器处理环境互动，这限制了可实现的互动控制带宽。为此，作者提出了一种新的架构来解决这个问题。", "method": "本文提出了一种新型控制架构，将宏操作器和微操作器集成在一个主动交互控制系统中，并引入替代模型以简化控制器设计并方便硬件更改后的适应性调整。", "result": "实验表明，新方法使控制带宽提高了2.1倍（相比领导者-跟随者方法）以及12.5倍（相比传统机器人基力控制），并通过多种不同任务验证了其有效性。", "conclusion": "新提出的统一控制器架构提高了宏观微观操作器的动态交互性能，并且通过引入替代模型简化了设计和适应性调整过程。"}}
{"id": "2602.01942", "pdf": "https://arxiv.org/pdf/2602.01942", "abs": "https://arxiv.org/abs/2602.01942", "authors": ["Alsharif Abuadbba", "Nazatul Sultan", "Surya Nepal", "Sanjay Jha"], "title": "Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework", "categories": ["cs.CR", "cs.AI"], "comment": "10 pages", "summary": "AI is moving from domain-specific autonomy in closed, predictable settings to large-language-model-driven agents that plan and act in open, cross-organizational environments. As a result, the cybersecurity risk landscape is changing in fundamental ways. Agentic AI systems can plan, act, collaborate, and persist over time, functioning as participants in complex socio-technical ecosystems rather than as isolated software components. Although recent work has strengthened defenses against model and pipeline level vulnerabilities such as prompt injection, data poisoning, and tool misuse, these system centric approaches may fail to capture risks that arise from autonomy, interaction, and emergent behavior. This article introduces the 4C Framework for multi-agent AI security, inspired by societal governance. It organizes agentic risks across four interdependent dimensions: Core (system, infrastructure, and environmental integrity), Connection (communication, coordination, and trust), Cognition (belief, goal, and reasoning integrity), and Compliance (ethical, legal, and institutional governance). By shifting AI security from a narrow focus on system-centric protection to the broader preservation of behavioral integrity and intent, the framework complements existing AI security strategies and offers a principled foundation for building agentic AI systems that are trustworthy, governable, and aligned with human values.", "AI": {"tldr": "本文提出了4C框架，用于多代理人工智能安全治理，该框架借鉴了社会管理模式。", "motivation": "随着AI从封闭、可预测的领域特定自主权转向开放环境中的大型语言模型驱动的智能体，网络安全风险格局发生了根本变化。传统的系统中心防护方法可能无法捕捉到由自治性、交互和新兴行为产生的风险。", "method": "4C框架包括四个相互依存的风险维度：核心（系统、基础设施和环境完整性）、连接（通信、协调与信任）、认知（信念、目标和推理的完整性和合规性）（道德、法律和制度治理），通过这种方法，将人工智能安全从单一系统的保护扩展到更广泛的行为主体行为完整性的维护。", "result": "该框架为构建值得信赖、可管控且符合人类价值观的人工智能系统提供了一个原则基础，并补充了现有的AI安全性策略。", "conclusion": "4C框架为应对多代理人工智能带来的新挑战提供了全面而系统的治理方法，有助于确保人工智能与人类社会的价值观相一致。"}}
{"id": "2602.01939", "pdf": "https://arxiv.org/pdf/2602.01939", "abs": "https://arxiv.org/abs/2602.01939", "authors": ["Yuxin He", "Ruihao Zhang", "Tianao Shen", "Cheng Liu", "Qiang Nie"], "title": "Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy", "categories": ["cs.RO", "cs.AI"], "comment": "ICRA 2026", "summary": "Recently, active vision has reemerged as an important concept for manipulation, since visual occlusion occurs more frequently when main cameras are mounted on the robot heads. We reflect on the visual occlusion issue and identify its essence as the absence of information useful for task completion. Inspired by this, we come up with the more fundamental problem of Exploratory and Focused Manipulation (EFM). The proposed problem is about actively collecting information to complete challenging manipulation tasks that require exploration or focus. As an initial attempt to address this problem, we establish the EFM-10 benchmark that consists of 4 categories of tasks that align with our definition (10 tasks in total). We further come up with a Bimanual Active Perception (BAP) strategy, which leverages one arm to provide active vision and another arm to provide force sensing while manipulating. Based on this idea, we collect a dataset named BAPData for the tasks in EFM-10. With the dataset, we successfully verify the effectiveness of the BAP strategy in an imitation learning manner. We hope that the EFM-10 benchmark along with the BAP strategy can become a cornerstone that facilitates future research towards this direction. Project website: EFManipulation.github.io.", "AI": {"tldr": "提出了一种新的双臂主动感知策略，用于解决探索性和聚焦性操作问题，并建立了相应的基准测试EFM-10。", "motivation": "针对机器人在执行复杂任务时的视觉遮挡问题，提出了更具普遍性的探索和聚焦性操作（EFM）问题。通过利用一个手臂进行主动观察，另一个手臂提供力感知来提高任务完成度。", "method": "设计了双臂主动感知（BAP）策略，并建立了包含10个任务的EFM-10基准测试；收集相关数据集BAPData并验证了所提方法的有效性。", "result": "在模仿学习方式下，成功展示了所提出的方法能够有效解决探索和聚焦操作问题。", "conclusion": "提出了一个重要的研究方向和策略，希望能够为今后的相关领域研究提供重要基础和支持。"}}
{"id": "2602.01937", "pdf": "https://arxiv.org/pdf/2602.01937", "abs": "https://arxiv.org/abs/2602.01937", "authors": ["Suhan Guo", "Bingxu Wang", "Shaodan Zhang", "Furao Shen"], "title": "T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting plays a critical role in decision-making across many real-world applications. Unlike data in vision and language domains, time series data is inherently tied to the evolution of underlying processes and can only accumulate as real-world time progresses, limiting the effectiveness of scale-driven pretraining alone. This time-bound constraint poses a challenge for enabling large language models (LLMs) to acquire forecasting capability, as existing approaches primarily rely on representation-level alignment or inference-time temporal modules rather than explicitly teaching forecasting behavior to the LLM. We propose T-LLM, a temporal distillation framework that equips general-purpose LLMs with time series forecasting capability by transferring predictive behavior from a lightweight temporal teacher during training. The teacher combines trend modeling and frequency-domain analysis to provide structured temporal supervision, and is removed entirely at inference, leaving the LLM as the sole forecasting model. Experiments on benchmark datasets and infectious disease forecasting tasks demonstrate that T-LLM consistently outperforms existing LLM-based forecasting methods under full-shot, few-shot, and zero-shot settings, while enabling a simple and efficient deployment pipeline.", "AI": {"tldr": "提出了一种时间序列预测框架T-LLM，通过训练阶段的时间蒸馏使通用大语言模型具备时间序列预测能力。", "motivation": "现有方法主要依赖于表示层对齐或推理时的临时模块，而未直接教授时间序列预测行为给大语言模型。鉴于时间数据的独特属性和限制，提出了该框架以克服这一挑战。", "method": "通过结合趋势建模和频域分析的轻量级临时教师，在训练阶段向通用大语言模型传递预测行为，最终在推理时完全移除教师。", "result": "实验显示T-LLM在完整、少量以及零样本设置下均优于现有基于大语言模型的时间序列预测方法，并提供了一个简单高效的部署流程。", "conclusion": "提出的方法有效地提高了大语言模型的时间序列预测能力，展示了其在未来应用中的潜力。"}}
{"id": "2602.01936", "pdf": "https://arxiv.org/pdf/2602.01936", "abs": "https://arxiv.org/abs/2602.01936", "authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen"], "title": "PIMCST: Physics-Informed Multi-Phase Consensus and Spatio-Temporal Few-Shot Learning for Traffic Flow Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate traffic flow prediction remains a fundamental challenge in intelligent transportation systems, particularly in cross-domain, data-scarce scenarios where limited historical data hinders model training and generalisation. The complex spatio-temporal dependencies and nonlinear dynamics of urban mobility networks further complicate few-shot learning across different cities. This paper proposes MCPST, a novel Multi-phase Consensus Spatio-Temporal framework for few-shot traffic forecasting that reconceptualises traffic prediction as a multi-phase consensus learning problem. Our framework introduces three core innovations: (1) a multi-phase engine that models traffic dynamics through diffusion, synchronisation, and spectral embeddings for comprehensive dynamic characterisation; (2) an adaptive consensus mechanism that dynamically fuses phase-specific predictions while enforcing consistency; and (3) a structured meta-learning strategy for rapid adaptation to new cities with minimal data. We establish extensive theoretical guarantees, including representation theorems with bounded approximation errors and generalisation bounds for few-shot adaptation. Through experiments on four real-world datasets, MCPST outperforms fourteen state-of-the-art methods in spatio-temporal graph learning methods, dynamic graph transfer learning methods, prompt-based spatio-temporal prediction methods and cross-domain few-shot settings, improving prediction accuracy while reducing required training data and providing interpretable insights. The implementation code is available at https://github.com/afofanah/MCPST.", "AI": {"tldr": "本文提出了MCPST框架，用于解决城市交通流量预测中的少样本学习问题。", "motivation": "准确的交通流预测在智能运输系统中是一个基础性挑战。特别是在数据稀疏、跨域场景下，现有的模型训练和泛化能力受到限制。", "method": "该方法通过引入多阶段引擎建模交通动力学，自适应共识机制动态融合各阶段预测，并采用结构化的元学习策略快速适应新城市环境。", "result": "实验表明MCPST在四个真实数据集上超越了14种最先进的方法，在少样本条件下提高了预测准确性并提供了可解释性。", "conclusion": "MCPST框架提供了一种有效的方法，能够在有限的数据下实现准确的交通流预测，并且具有良好的泛化性能。"}}
{"id": "2602.01935", "pdf": "https://arxiv.org/pdf/2602.01935", "abs": "https://arxiv.org/abs/2602.01935", "authors": ["Annabelle Sujun Tang", "Christopher Priebe", "Lianhui Qin", "Hadi Esmaeilzadeh"], "title": "COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation", "categories": ["cs.LG", "cs.AI", "cs.PL"], "comment": null, "summary": "Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models.", "AI": {"tldr": "本文提出了一种轻量级的多LLM协作框架COLT，用于模型编译优化。", "motivation": "单一的大语言模型在搜索过程中成本高昂且效率低下，而小模型单独使用时可靠性不足。因此，探讨是否可以通过多个较小的语言模型协作来实现与单个大模型相当或更好的性能是本文的研究动机。", "method": "COLT框架采用一个共享的蒙特卡洛树搜索（MCTS）作为协作平台，实现了多LLM之间的协调推理。通过将模型选择内化到轻量级的优化循环中，消除了对外部规划器和其他复杂组件的需求，并引入了基于模型的认知策略和课程调整机制。", "result": "实验结果表明，COLT框架能够有效地利用多个较小的语言模型进行协作推理，在保持探索性的同时偏向于使用小型模型，并在必要时切换到大型模型以避免搜索退化。", "conclusion": "本文提出了一个轻量级的多LLM协作框架，证明了通过共享MCTS树可以实现高效的编译优化过程。"}}
{"id": "2602.01933", "pdf": "https://arxiv.org/pdf/2602.01933", "abs": "https://arxiv.org/abs/2602.01933", "authors": ["Fabrice Boissier", "Monica Sen", "Irina Rychkova"], "title": "Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling", "categories": ["cs.AI"], "comment": null, "summary": "Topic modeling is a research field finding increasing applications: historically from document retrieving, to sentiment analysis and text summarization. Large Language Models (LLM) are currently a major trend in text processing, but few works study their usefulness for this task. Formal Concept Analysis (FCA) has recently been presented as a candidate for topic modeling, but no real applied case study has been conducted. In this work, we compare LLM and FCA to better understand their strengths and weakneses in the topic modeling field. FCA is evaluated through the CREA pipeline used in past experiments on topic modeling and visualization, whereas GPT-5 is used for the LLM. A strategy based on three prompts is applied with GPT-5 in a zero-shot setup: topic generation from document batches, merging of batch results into final topics, and topic labeling. A first experiment reuses the teaching materials previously used to evaluate CREA, while a second experiment analyzes 40 research articles in information systems to compare the extracted topics with the underling subfields.", "AI": {"tldr": "该论文比较了大型语言模型（LLM）和形式概念分析（FCA）在主题建模中的表现。", "motivation": "为了理解大型语言模型（如GPT-5）和形式概念分析（FCA）在主题建模任务中各自的优劣，本文提出了一个对比研究。", "method": "使用CREA流程评估FCA，并利用三种提示策略与零样本设置下的GPT-5进行比较。实验包括了重复教学材料的主题建模以及对40篇信息系统研究论文的分析。", "result": "通过上述方法，该论文展示了LLM和FCA在不同数据集上的主题提取效果。", "conclusion": "根据实验结果，该论文总结了LLM与FCA各自在主题建模任务中的长处与短处，并提供了对两者未来应用的见解。"}}
{"id": "2602.01930", "pdf": "https://arxiv.org/pdf/2602.01930", "abs": "https://arxiv.org/abs/2602.01930", "authors": ["Felix Igelbrink", "Lennart Niecksch", "Marian Renz", "Martin Günther", "Martin Atzmueller"], "title": "LIEREx: Language-Image Embeddings for Robotic Exploration", "categories": ["cs.RO", "cs.CV"], "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in KI - Künstliche Intelligenz, and is available online at https://doi.org/10.1007/s13218-026-00902-6", "summary": "Semantic maps allow a robot to reason about its surroundings to fulfill tasks such as navigating known environments, finding specific objects, and exploring unmapped areas. Traditional mapping approaches provide accurate geometric representations but are often constrained by pre-designed symbolic vocabularies. The reliance on fixed object classes makes it impractical to handle out-of-distribution knowledge not defined at design time. Recent advances in Vision-Language Foundation Models, such as CLIP, enable open-set mapping, where objects are encoded as high-dimensional embeddings rather than fixed labels. In LIEREx, we integrate these VLFMs with established 3D Semantic Scene Graphs to enable target-directed exploration by an autonomous agent in partially unknown environments.", "AI": {"tldr": "该论文提出了一种结合视觉语言基础模型和三维语义场景图的机器人探索方法LIEREx，以在部分未知环境中实现目标导向探索。", "motivation": "传统的映射方法依赖于固定的对象类别词汇表，难以处理设计时未定义的知识。因此，提出了LIEREx来利用最近进展的视觉语言基础模型进行开放集映射，并支持机器人在部分未知环境中的目标导向探索。", "method": "论文将视觉语言基础模型与三维语义场景图相结合，通过高维嵌入表示物体，实现对机器人周围环境的理解和导航。", "result": "LIEREx能够使自主代理在部分未知环境中进行有效的目标导向探索，利用高维嵌入提高了处理未见过的对象的能力。", "conclusion": "LIEREx提供了一种有效的方法来解决传统映射方法的限制，并通过结合视觉语言基础模型和三维语义场景图，在机器人探索任务中取得了显著进展。"}}
{"id": "2602.01920", "pdf": "https://arxiv.org/pdf/2602.01920", "abs": "https://arxiv.org/abs/2602.01920", "authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen"], "title": "PIMPC-GNN: Physics-Informed Multi-Phase Consensus Learning for Enhancing Imbalanced Node Classification in Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph neural networks (GNNs) often struggle in class-imbalanced settings, where minority classes are under-represented and predictions are biased toward majorities. We propose \\textbf{PIMPC-GNN}, a physics-informed multi-phase consensus framework for imbalanced node classification. Our method integrates three complementary dynamics: (i) thermodynamic diffusion, which spreads minority labels to capture long-range dependencies, (ii) Kuramoto synchronisation, which aligns minority nodes through oscillatory consensus, and (iii) spectral embedding, which separates classes via structural regularisation. These perspectives are combined through class-adaptive ensemble weighting and trained with an imbalance-aware loss that couples balanced cross-entropy with physics-based constraints. Across five benchmark datasets and imbalance ratios from 5-100, PIMPC-GNN outperforms 16 state-of-the-art baselines, achieving notable gains in minority-class recall (up to +12.7\\%) and balanced accuracy (up to +8.3\\%). Beyond empirical improvements, the framework also provides interpretable insights into consensus dynamics in graph learning. The code is available at \\texttt{https://github.com/afofanah/PIMPC-GNN}.", "AI": {"tldr": "本文提出了一种基于物理信息的多阶段共识框架PIMPC-GNN，用于解决图神经网络在不平衡节点分类中的问题。", "motivation": "图神经网络在处理少数类样本不足的问题时表现不佳，预测偏向多数类别。为了解决这个问题，作者提出了一个新的方法来改进不平衡节点分类。", "method": "该方法结合了三种互补的动力学：热动力扩散、Kuramoto同步和谱嵌入，并通过类别自适应集成权重进行整合，在训练过程中使用平衡交叉熵与基于物理的约束相结合的损失函数。", "result": "实验结果表明，PIMPC-GNN在五个基准数据集上显著提高了少数类别的召回率（最高提高12.7%）和平衡准确度（最高提高8.3%），并且优于16个现有的基线方法。", "conclusion": "该框架不仅提供了性能上的改进，还为图学习中的共识动态提供了可解释的见解。"}}
{"id": "2602.01918", "pdf": "https://arxiv.org/pdf/2602.01918", "abs": "https://arxiv.org/abs/2602.01918", "authors": ["Alessandro Silacci", "Mauro Cherubini", "Arianna Boldi", "Amon Rapp", "Maurizio Caon"], "title": "When Workout Buddies Are Virtual: AI Agents and Human Peers in a Longitudinal Physical Activity Study", "categories": ["cs.HC"], "comment": null, "summary": "Physical inactivity remains a critical global health issue, yet scalable strategies for sustained motivation are scarce. Conversational agents designed as simulated exercising peers (SEPs) represent a promising alternative, but their long-term impact is unclear. We report a six-month randomized controlled trial (N=280) comparing individuals exercising alone, with a human peer, or with a large language model-driven SEP. Results revealed a partnership paradox: human peers evoked stronger social presence, while AI peers provided steadier encouragement and more reliable working alliances. Humans motivated through authentic comparison and accountability, whereas AI peers fostered consistent, low-stakes support. These complementary strengths suggest that AI agents should not mimic human authenticity but augment it with reliability. Our findings advance human-agent interaction research and point to hybrid designs where human presence and AI consistency jointly sustain physical activity.", "AI": {"tldr": "该论文通过六个月的随机对照试验，比较了独自锻炼、与真人同伴一起锻炼和与AI虚拟同伴一起锻炼的效果。", "motivation": "解决全球体育活动不足的问题，探索可扩展且可持续激励策略的有效性。特别关注基于大型语言模型驱动的虚拟运动伙伴（SEP）在长期影响中的作用。", "method": "进行了一个六个月的随机对照试验，参与者被分为独自锻炼、与真人同伴一起锻炼和与AI虚拟同伴一起锻炼三组。通过测量各组的表现来评估不同形式的社会支持对体育活动的影响。", "result": "真人同伴提供了更强的社会存在感，而AI伙伴则表现出更稳定的支持，并建立了更可靠的合作关系。人类同伴激发了真实性的比较和责任感，而AI同伴则促进了持续、低压力的支持。", "conclusion": "研究结果表明，AI虚拟伴侣应补充而非模仿人类的真实性，通过结合人类存在的社会支持与AI的可靠性来共同维持体育活动水平。"}}
{"id": "2602.01916", "pdf": "https://arxiv.org/pdf/2602.01916", "abs": "https://arxiv.org/abs/2602.01916", "authors": ["Keyu Chen", "Wenchao Sun", "Hao Cheng", "Zheng Fu", "Sifa Zheng"], "title": "ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning", "categories": ["cs.RO"], "comment": "Accepted by ICRA 2026", "summary": "As the foundation of closed-loop training and evaluation in autonomous driving, traffic simulation still faces two fundamental challenges: covariate shift introduced by open-loop imitation learning and limited capacity to reflect the multimodal behaviors observed in real-world traffic. Although recent frameworks such as RIFT have partially addressed these issues through group-relative optimization, their forward simulation procedures remain largely non-reactive, leading to unrealistic agent interactions within the virtual domain and ultimately limiting simulation fidelity. To address these issues, we propose ForSim, a stepwise closed-loop forward simulation paradigm. At each virtual timestep, the traffic agent propagates the virtual candidate trajectory that best spatiotemporally matches the reference trajectory through physically grounded motion dynamics, thereby preserving multimodal behavioral diversity while ensuring intra-modality consistency. Other agents are updated with stepwise predictions, yielding coherent and interaction-aware evolution. When incorporated into the RIFT traffic simulation framework, ForSim operates in conjunction with group-relative optimization to fine-tune traffic policy. Extensive experiments confirm that this integration consistently improves safety while maintaining efficiency, realism, and comfort. These results underscore the importance of modeling closed-loop multimodal interactions within forward simulation and enhance the fidelity and reliability of traffic simulation for autonomous driving. Project Page: https://currychen77.github.io/ForSim/", "AI": {"tldr": "提出了一种名为ForSim的逐步闭环前向模拟框架，以改善自动驾驶中的交通仿真。", "motivation": "现有的交通仿真框架在处理开放循环模仿学习引入的协变量偏移和反映现实世界中多模式行为的能力方面存在局限性。为了解决这些问题，提出了ForSim来增强仿真的逼真度。", "method": "ForSim通过物理基础的运动动力学传播虚拟候选轨迹，在每个虚拟时间步长内保持多模态行为多样性的同时确保同一模态内的连贯一致性，并与其他代理进行逐步预测更新以获得协同和交互感知进化。", "result": "实验结果表明，这种集成在提高安全性的同时还能维持效率、真实感和舒适性。", "conclusion": "这些结果强调了在前向模拟中建模闭环多模式交互的重要性，并提高了交通仿真用于自动驾驶的逼真度和可靠性。"}}
{"id": "2602.01915", "pdf": "https://arxiv.org/pdf/2602.01915", "abs": "https://arxiv.org/abs/2602.01915", "authors": ["Elad Sharony", "Tom Jurgenson", "Orr Krupnik", "Dotan Di Castro", "Shie Mannor"], "title": "VLM-Guided Experience Replay", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) and Vision-Language Models (VLMs) have enabled powerful semantic and multimodal reasoning capabilities, creating new opportunities to enhance sample efficiency, high-level planning, and interpretability in reinforcement learning (RL). While prior work has integrated LLMs and VLMs into various components of RL, the replay buffer, a core component for storing and reusing experiences, remains unexplored. We propose addressing this gap by leveraging VLMs to guide the prioritization of experiences in the replay buffer. Our key idea is to use a frozen, pre-trained VLM (requiring no fine-tuning) as an automated evaluator to identify and prioritize promising sub-trajectories from the agent's experiences. Across scenarios, including game-playing and robotics, spanning both discrete and continuous domains, agents trained with our proposed prioritization method achieve 11-52% higher average success rates and improve sample efficiency by 19-45% compared to previous approaches. https://esharony.me/projects/vlm-rb/", "AI": {"tldr": "论文提出了一种利用视觉语言模型引导回放缓冲区优先级的方法，以提高强化学习代理的样本效率和成功率。", "motivation": "通过结合大型语言模型（LLM）和视觉语言模型（VLM），可以增强语义推理、多模态理解和强化学习中的高级规划能力。当前研究中忽略了使用这些技术改善回放缓冲区优先级的重要性。", "method": "利用一个预训练的、冻结不变的VLM作为评估器来自动识别并优先考虑代理经验中的有希望子轨迹，以改进回放缓冲区的存储和重用。", "result": "在各种游戏玩法和机器人任务中，使用该方法训练的代理实现了11-52％更高的平均成功率，并且样本效率提高了19-45％。", "conclusion": "利用VLM指导经验回放可以显著提高强化学习系统的性能和样本利用率。"}}
{"id": "2602.01912", "pdf": "https://arxiv.org/pdf/2602.01912", "abs": "https://arxiv.org/abs/2602.01912", "authors": ["Du-Yi Wang", "Guo Liang", "Kun Zhang", "Qianwen Zhu"], "title": "Reliable Real-Time Value at Risk Estimation via Quantile Regression Forest with Conformal Calibration", "categories": ["stat.ML", "cs.AI", "cs.LG", "q-fin.RM"], "comment": null, "summary": "Rapidly evolving market conditions call for real-time risk monitoring, but its online estimation remains challenging. In this paper, we study the online estimation of one of the most widely used risk measures, Value at Risk (VaR). Its accurate and reliable estimation is essential for timely risk control and informed decision-making. We propose to use the quantile regression forest in the offline-simulation-online-estimation (OSOA) framework. Specifically, the quantile regression forest is trained offline to learn the relationship between the online VaR and risk factors, and real-time VaR estimates are then produced online by incorporating observed risk factors. To further ensure reliability, we develop a conformalized estimator that calibrates the online VaR estimates. To the best of our knowledge, we are the first to leverage conformal calibration to estimate real-time VaR reliably based on the OSOA formulation. Theoretical analysis establishes the consistency and coverage validity of the proposed estimators. Numerical experiments confirm the proposed method and demonstrate its effectiveness in practice.", "AI": {"tldr": "通过离线-仿真-在线估算框架，使用量化回归森林和校准估计器进行实时VaR的准确可靠估算。", "motivation": "快速变化的市场条件要求实时风险监控，但其在线估计算法仍具挑战。准确可靠的VaR估算对及时风险管理及决策至关重要。", "method": "离线训练量化回归森林以学习VaR与风险因素的关系，在线使用观测到的风险因子生成实时VaR估计，并通过校准确保可靠性。", "result": "理论分析证明了所提方法的一致性和覆盖率有效性，实验证明其在实践中的有效性和优越性。", "conclusion": "该研究提出了基于离线-仿真-在线估算框架的量化回归森林结合校准的方法以实现可靠的实时VaR估计。"}}
{"id": "2602.01910", "pdf": "https://arxiv.org/pdf/2602.01910", "abs": "https://arxiv.org/abs/2602.01910", "authors": ["Michele Fiori", "Gabriele Civitarese", "Flora D. Salim", "Claudio Bettini"], "title": "DomusFM: A Foundation Model for Smart-Home Sensor Data", "categories": ["cs.AI"], "comment": null, "summary": "Smart-home sensor data holds significant potential for several applications, including healthcare monitoring and assistive technologies. Existing approaches, however, face critical limitations. Supervised models require impractical amounts of labeled data. Foundation models for activity recognition focus only on inertial sensors, failing to address the unique characteristics of smart-home binary sensor events: their sparse, discrete nature combined with rich semantic associations. LLM-based approaches, while tested in this domain, still raise several issues regarding the need for natural language descriptions or prompting, and reliance on either external services or expensive hardware, making them infeasible in real-life scenarios due to privacy and cost concerns. We introduce DomusFM, the first foundation model specifically designed and pretrained for smart-home sensor data. DomusFM employs a self-supervised dual contrastive learning paradigm to capture both token-level semantic attributes and sequence-level temporal dependencies. By integrating semantic embeddings from a lightweight language model and specialized encoders for temporal patterns and binary states, DomusFM learns generalizable representations that transfer across environments and tasks related to activity and event analysis. Through leave-one-dataset-out evaluation across seven public smart-home datasets, we demonstrate that DomusFM outperforms state-of-the-art baselines on different downstream tasks, achieving superior performance even with only 5% of labeled training data available for fine-tuning. Our approach addresses data scarcity while maintaining practical deployability for real-world smart-home systems.", "AI": {"tldr": "本文提出了DomusFM，这是一种专门针对智能家居传感器数据进行预训练的基础模型。", "motivation": "现有的监督学习模型需要大量的标注数据，并且专注于惯性传感器而忽略了智能家居二进制传感器事件的独特特性。基于LLM的方法存在隐私和成本问题，使其难以在现实场景中应用。", "method": "DomusFM采用了自我监督的双对比学习范式，捕捉了令牌级语义属性和序列级别的时间依赖关系，并通过整合来自轻量级语言模型的语义嵌入以及专门用于时间模式和二进制状态的编码器来实现跨环境和任务的相关性。", "result": "DomusFM在七个公共智能家居数据集上的留一数据集中评估表现优于现有的最先进技术，在仅使用5%标注训练数据的情况下也取得了优越性能。", "conclusion": "本文提出的方法解决了数据稀缺问题，同时保持了现实世界智能家庭系统的可部署性"}}
{"id": "2602.01908", "pdf": "https://arxiv.org/pdf/2602.01908", "abs": "https://arxiv.org/abs/2602.01908", "authors": ["Jaejun Lee", "Yoori Oh", "Kyogu Lee"], "title": "LipSody: Lip-to-Speech Synthesis with Enhanced Prosody Consistency", "categories": ["cs.SD"], "comment": "This paper has been accepted to ICASSP 2026", "summary": "Lip-to-speech synthesis aims to generate speech audio directly from silent facial video by reconstructing linguistic content from lip movements, providing valuable applications in situations where audio signals are unavailable or degraded. While recent diffusion-based models such as LipVoicer have demonstrated impressive performance in reconstructing linguistic content, they often lack prosodic consistency. In this work, we propose LipSody, a lip-to-speech framework enhanced for prosody consistency. LipSody introduces a prosody-guiding strategy that leverages three complementary cues: speaker identity extracted from facial images, linguistic content derived from lip movements, and emotional context inferred from face video. Experimental results demonstrate that LipSody substantially improves prosody-related metrics, including global and local pitch deviations, energy consistency, and speaker similarity, compared to prior approaches.", "AI": {"tldr": "本文提出了一种改进的唇到语音合成框架LipSody，用于提升语音中的韵律一致性。", "motivation": "现有的唇到语音模型在重建语言内容方面表现出色但缺乏韵律一致性。因此需要一种新的方法来解决这一问题以提高生成语音的质量。", "method": "LipSody引入了一种引导韵律策略，利用了三种互补线索：从面部图像中提取的说话人身份、基于嘴唇动作的语言内容以及通过面部视频推断的情绪上下文。", "result": "实验结果表明，与先前的方法相比，LipSody在韵律相关的指标上有了显著改进，包括全局和局部音高偏差、能量一致性及说话者相似性等。", "conclusion": "本文提出的新框架有效解决了现有唇到语音模型中缺乏韵律一致性的缺点，并取得了更好的合成效果。"}}
{"id": "2602.01906", "pdf": "https://arxiv.org/pdf/2602.01906", "abs": "https://arxiv.org/abs/2602.01906", "authors": ["Farhan Ullah", "Irfan Ullah", "Khalil Khan", "Giovanni Pau", "JaKeoung Koo"], "title": "DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Hyperspectral image classification (HSIC) is a challenging task due to high spectral dimensionality, complex spectral-spatial correlations, and limited labeled training samples. Although transformer-based models have shown strong potential for HSIC, existing approaches often struggle to achieve sufficient spectral discriminability while maintaining computational efficiency. To address these limitations, we propose a novel DSXFormer, a novel dual-pooling spectral squeeze-expansion transformer with Dynamic Context Attention for HSIC. The proposed DSXFormer introduces a Dual-Pooling Spectral Squeeze-Expansion (DSX) block, which exploits complementary global average and max pooling to adaptively recalibrate spectral feature channels, thereby enhancing spectral discriminability and inter-band dependency modeling. In addition, DSXFormer incorporates a Dynamic Context Attention (DCA) mechanism within a window-based transformer architecture to dynamically capture local spectral-spatial relationships while significantly reducing computational overhead. The joint integration of spectral dual-pooling squeeze-expansion and DCA enables DSXFormer to achieve an effective balance between spectral emphasis and spatial contextual representation. Furthermore, patch extraction, embedding, and patch merging strategies are employed to facilitate efficient multi-scale feature learning. Extensive experiments conducted on four widely used hyperspectral benchmark datasets, including Salinas (SA), Indian Pines (IP), Pavia University (PU), and Kennedy Space Center (KSC), demonstrate that DSXFormer consistently outperforms state-of-the-art methods, achieving classification accuracies of 99.95%, 98.91%, 99.85%, and 98.52%, respectively.", "AI": {"tldr": "提出了一种新的DSXFormer模型，用于高光谱图像分类。", "motivation": "现有的方法在处理高光谱数据时难以同时实现足够的光谱区分度和计算效率。", "method": "提出了双池化光谱挤压扩展（DSX）块和动态上下文注意力机制（DCA），以增强光谱区分度，减少计算开销，并改进空间上下文表示。", "result": "在四个基准数据集上实现了高精度的分类结果：Salinas 99.95%，Indian Pines 98.91%，Pavia University 99.85%，Kennedy Space Center 98.52%。", "conclusion": "DSXFormer模型在提高光谱区分度和减少计算开销方面表现优越，优于现有方法。"}}
{"id": "2602.01905", "pdf": "https://arxiv.org/pdf/2602.01905", "abs": "https://arxiv.org/abs/2602.01905", "authors": ["Theodore Zhengde Zhao", "Sid Kiblawi", "Jianwei Yang", "Naoto Usuyama", "Reuben Tan", "Noel C Codella", "Tristan Naumann", "Hoifung Poon", "Mu Wei"], "title": "Learning Sparse Visual Representations via Spatial-Semantic Factorization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Self-supervised learning (SSL) faces a fundamental conflict between semantic understanding and image reconstruction. High-level semantic SSL (e.g., DINO) relies on global tokens that are forced to be location-invariant for augmentation alignment, a process that inherently discards the spatial coordinates required for reconstruction. Conversely, generative SSL (e.g., MAE) preserves dense feature grids for reconstruction but fails to produce high-level abstractions. We introduce STELLAR, a framework that resolves this tension by factorizing visual features into a low-rank product of semantic concepts and their spatial distributions. This disentanglement allows us to perform DINO-style augmentation alignment on the semantic tokens while maintaining the precise spatial mapping in the localization matrix necessary for pixel-level reconstruction. We demonstrate that as few as 16 sparse tokens under this factorized form are sufficient to simultaneously support high-quality reconstruction (2.60 FID) and match the semantic performance of dense backbones (79.10% ImageNet accuracy). Our results highlight STELLAR as a versatile sparse representation that bridges the gap between discriminative and generative vision by strategically separating semantic identity from spatial geometry. Code available at https://aka.ms/stellar.", "AI": {"tldr": "本文提出了一种新的自监督学习框架STEELSAR，通过将视觉特征分解为语义概念和空间分布的低秩乘积，从而同时支持高质量重建和高阶抽象。", "motivation": "自监督学习在图像重建与高层次语义理解之间存在固有冲突。文章旨在解决这一矛盾，使模型既能进行精确的空间重建又能提取高级别的视觉语义信息。", "method": "STEELSAR框架通过分解视觉特征为低秩乘积的形式，即语义概念和空间分布的结合，实现同时支持图像重建与高层次抽象的目标。该方法在稀疏令牌下保持了高质量的重建能力并维持了高阶语义性能。", "result": "实验表明，在仅使用16个稀疏令牌的情况下，STEELSAR框架可以达到2.60 FID的高质量重建效果，并且语义理解准确率达到了79.10% ImageNet精度。这证明了该方法在同时支持图像重建与高层次抽象方面的能力。", "conclusion": "通过分离视觉特征中的语义身份和空间几何，STEELSAR框架成功地弥合了解释性和生成性之间的差距，并展示了作为连接这两者桥梁的多功能稀疏表示的有效性。"}}
{"id": "2602.01901", "pdf": "https://arxiv.org/pdf/2602.01901", "abs": "https://arxiv.org/abs/2602.01901", "authors": ["Jiedong Zhuang", "Lu Lu", "Ming Dai", "Rui Hu", "Jian Chen", "Qiang Liu", "Haoji Hu"], "title": "Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model", "categories": ["cs.CV"], "comment": "Accepted by AAAI26", "summary": "Multimodal large language models (MLLMs) are plagued by exorbitant inference costs attributable to the profusion of visual tokens within the vision encoder. The redundant visual tokens engenders a substantial computational load and key-value (KV) cache footprint bottleneck. Existing approaches focus on token-wise optimization, leveraging diverse intricate token pruning techniques to eliminate non-crucial visual tokens. Nevertheless, these methods often unavoidably undermine the integrity of the KV cache, resulting in failures in long-text generation tasks. To this end, we conduct an in-depth investigation towards the attention mechanism of the model from a new perspective, and discern that attention within more than half of all decode layers are semantic similar. Upon this finding, we contend that the attention in certain layers can be streamlined by inheriting the attention from their preceding layers. Consequently, we propose Lazy Attention, an efficient attention mechanism that enables cross-layer sharing of similar attention patterns. It ingeniously reduces layer-wise redundant computation in attention. In Lazy Attention, we develop a novel layer-shared cache, Q Cache, tailored for MLLMs, which facilitates the reuse of queries across adjacent layers. In particular, Q Cache is lightweight and fully compatible with existing inference frameworks, including Flash Attention and KV cache. Additionally, our method is highly flexible as it is orthogonal to existing token-wise techniques and can be deployed independently or combined with token pruning approaches. Empirical evaluations on multiple benchmarks demonstrate that our method can reduce KV cache usage by over 35% and achieve 1.5x throughput improvement, while sacrificing only approximately 1% of performance on various MLLMs. Compared with SOTA token-wise methods, our technique achieves superior accuracy preservation.", "AI": {"tldr": "本文提出了一种新的注意力机制Lazy Attention，通过在多模态大型语言模型中跨层共享相似的注意力模式来减少冗余计算和内存使用。", "motivation": "现有的方法主要集中在优化令牌层面，这导致了KV缓存瓶颈，并可能破坏长文本生成任务。为此，本文研究发现大部分解码器层数中的注意力机制是语义类似的，可以跨层共享以减少冗余计算。", "method": "提出了一种新的注意力机制Lazy Attention，该机制通过跨层共享相似的注意力模式来减少冗余计算，并开发了适用于多模态大型语言模型的新式跨层缓存Q Cache。", "result": "实验结果表明，本文方法可以将KV缓存使用量降低超过35%，同时实现1.5倍的吞吐率提升，仅损失大约1%的性能。", "conclusion": "相比现有令牌层面优化方法，Lazy Attention实现了更好的准确度保持，并且其灵活性使得它可以独立部署或与其他令牌优化技术结合。"}}
{"id": "2602.01899", "pdf": "https://arxiv.org/pdf/2602.01899", "abs": "https://arxiv.org/abs/2602.01899", "authors": ["Ozgur Erkent"], "title": "Multi-Task Learning for Robot Perception with Imbalanced Data", "categories": ["cs.RO", "cs.CV"], "comment": "16 pages", "summary": "Multi-task problem solving has been shown to improve the accuracy of the individual tasks, which is an important feature for robots, as they have a limited resource. However, when the number of labels for each task is not equal, namely imbalanced data exist, a problem may arise due to insufficient number of samples, and labeling is not very easy for mobile robots in every environment. We propose a method that can learn tasks even in the absence of the ground truth labels for some of the tasks. We also provide a detailed analysis of the proposed method. An interesting finding is related to the interaction of the tasks. We show a methodology to find out which tasks can improve the performance of other tasks. We investigate this by training the teacher network with the task outputs such as depth as inputs. We further provide empirical evidence when trained with a small amount of data. We use semantic segmentation and depth estimation tasks on different datasets, NYUDv2 and Cityscapes.", "AI": {"tldr": "本文提出了一种在多任务学习中处理不平衡数据的方法，允许机器人在某些标签缺失的情况下仍然可以进行有效学习。", "motivation": "解决机器人感知中的多任务问题时，由于资源有限以及环境中样本不均衡的问题可能导致性能下降。因此，研究旨在开发一种能够应对缺少部分任务真实标签的多任务学习方法。", "method": "采用教师网络利用各个任务输出作为输入训练模型，并分析不同任务间相互作用以改善整体性能的方法。实验使用了语义分割和深度估计等任务在NYUDv2和Cityscapes数据集上进行验证。", "result": "研究表明，即使在样本较少的情况下也能通过该方法提升任务间的协同效果，从而提高单个任务的表现。", "conclusion": "提出的多任务学习框架能够有效处理不平衡的数据问题，并展示了任务间相互促进的可能性。"}}
{"id": "2602.01893", "pdf": "https://arxiv.org/pdf/2602.01893", "abs": "https://arxiv.org/abs/2602.01893", "authors": ["Timur Mudarisov", "Mikhal Burtsev", "Tatiana Petrova", "Radu State"], "title": "Geometric Analysis of Token Selection in Multi-Head Attention", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "We present a geometric framework for analysing multi-head attention in large language models (LLMs). Without altering the mechanism, we view standard attention through a top-N selection lens and study its behaviour directly in value-state space. We define geometric metrics - Precision, Recall, and F-score - to quantify separability between selected and non-selected tokens, and derive non-asymptotic bounds with explicit dependence on dimension and margin under empirically motivated assumptions (stable value norms with a compressed sink token, exponential similarity decay, and piecewise attention weight profiles). The theory predicts a small-N operating regime of strongest non-trivial separability and clarifies how sequence length and sink similarity shape the metrics. Empirically, across LLaMA-2-7B, Gemma-7B, and Mistral-7B, measurements closely track the theoretical envelopes: top-N selection sharpens separability, sink similarity correlates with Recall. We also found that in LLaMA-2-7B heads specialize into three regimes - Retriever, Mixer, Reset - with distinct geometric signatures. Overall, attention behaves as a structured geometric classifier with measurable criteria for token selection, offering head level interpretability and informing geometry-aware sparsification and design of attention in LLMs.", "AI": {"tldr": "该论文提出了一个几何框架，用于分析大规模语言模型中的多头注意力机制。", "motivation": "通过引入新的几何度量指标（如精确率、召回率和F值），量化选择的标记与未选标记之间的可分离性，并探讨序列长度及sink相似性对这些度量的影响。", "method": "利用top-N选择视角，研究多头注意力机制在价值空间的行为；定义了新的几何度量并推导出非渐近边界；通过实验验证理论预测的正确性。", "result": "实验结果表明，在LLaMA-2-7B、Gemma-7B和Mistral-7B模型上，top-N选择提高了标记可分离性，并且sink相似度与召回率呈正相关。此外，多头注意力在这些模型中表现出三种不同的几何特征。", "conclusion": "该研究揭示了注意机制作为结构化分类器的行为模式，为理解大规模语言模型中的标记选择提供了测量标准和头部级别的可解释性。"}}
{"id": "2602.01892", "pdf": "https://arxiv.org/pdf/2602.01892", "abs": "https://arxiv.org/abs/2602.01892", "authors": ["Alexandre Lombard", "Florent Perronnet", "Nicolas Gaud", "Abdeljalil Abbas-Turki"], "title": "Path Tracking with Dynamic Control Point Blending for Autonomous Vehicles: An Experimental Study", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "This paper presents an experimental study of a path-tracking framework for autonomous vehicles in which the lateral control command is applied to a dynamic control point along the wheelbase. Instead of enforcing a fixed reference at either the front or rear axle, the proposed method continuously interpolates between both, enabling smooth adaptation across driving contexts, including low-speed maneuvers and reverse motion. The lateral steering command is obtained by barycentric blending of two complementary controllers: a front-axle Stanley formulation and a rear-axle curvature-based geometric controller, yielding continuous transitions in steering behavior and improved tracking stability. In addition, we introduce a curvature-aware longitudinal control strategy based on virtual track borders and ray-tracing, which converts upcoming geometric constraints into a virtual obstacle distance and regulates speed accordingly. The complete approach is implemented in a unified control stack and validated in simulation and on a real autonomous vehicle equipped with GPS-RTK, radar, odometry, and IMU. The results in closed-loop tracking and backward maneuvers show improved trajectory accuracy, smoother steering profiles, and increased adaptability compared to fixed control-point baselines.", "AI": {"tldr": "本文提出了一种路径跟踪框架，通过动态控制点混合方法改善自主车辆的横向控制命令。", "motivation": "旨在提高自主驾驶汽车在不同行驶情况下的适应性和轨迹精度。", "method": "采用了前后轴控制器混合的方法来获得侧向转向指令，并引入了基于曲率的纵向控制策略。", "result": "实验结果显示，相比固定参考点基线方法，本文方案提高了路径跟踪准确度和平滑性。", "conclusion": "提出的动态控制点结合和横向-纵向联合控制框架在提高自主车辆行驶稳定性和适应性方面表现出色。"}}
{"id": "2602.01885", "pdf": "https://arxiv.org/pdf/2602.01885", "abs": "https://arxiv.org/abs/2602.01885", "authors": ["Tiantian Chen", "Jiaqi Lu", "Ying Shen", "Lin Zhang"], "title": "ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 7 figures. Accepted to The Web Conference (WWW) 2026", "summary": "Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.", "AI": {"tldr": "提出了ES-MemEval基准，用于评估对话代理在长期个性化情感支持中的五项核心记忆能力：信息提取、时间推理、冲突检测、拒绝和用户建模。", "motivation": "现有长时对话基准主要集中在静态的事实检索上，忽视了复杂场景下分散的、隐含的以及不断演变的信息需求。因此，提出了ES-MemEval来填补这一空白，并支持EvoEmo数据集以促进长期个性化情感支持的研究。", "method": "通过设计覆盖问答、摘要和对话生成任务的全面基准ES-MemEval，并引入包含多会话碎片化隐含披露以及用户状态演变的数据集EvoEmo，系统评估了五个核心记忆能力的表现。", "result": "实验显示，明确的长时记忆对于减少幻觉并实现有效的个性化至关重要。虽然检索增强型LLM提高了事实一致性，但在处理时间动态和不断变化的用户状态方面存在挑战。", "conclusion": "这些发现展示了当前模型在长期个性化对话系统中的潜力与局限，并呼吁进一步整合内存和检索机制以提高性能。"}}
{"id": "2602.01884", "pdf": "https://arxiv.org/pdf/2602.01884", "abs": "https://arxiv.org/abs/2602.01884", "authors": ["Shidong Yang", "Tongwen Huang", "Hao Wen", "Yong Wang", "Li Chen", "Xiangxiang Chu"], "title": "Entropy-Guided Data-Efficient Training for Multimodal Reasoning Reward Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multimodal reward models are crucial for aligning multimodal large language models with human preferences. Recent works have incorporated reasoning capabilities into these models, achieving promising results. However, training these models suffers from two critical challenges: (1) the inherent noise in preference datasets, which degrades model performance, and (2) the inefficiency of conventional training methods, which ignore the differences in sample difficulty. In this paper, we identify a strong correlation between response entropy and accuracy, indicating that entropy can serve as a reliable and unsupervised proxy for annotation noise and sample difficulty. Based on this insight, we propose a novel Entropy-Guided Training (EGT) approach for multimodal reasoning reward models, which combines two strategies: (1) entropy-guided data curation to mitigate the impact of unreliable samples, and (2) an entropy-guided training strategy that progressively introduces more complex examples. Extensive experiments across three benchmarks show that the EGT-trained model consistently outperforms state-of-the-art multimodal reward models.", "AI": {"tldr": "本文提出了一种基于熵的训练方法，用于提高多模态推理奖励模型的数据效率和性能。", "motivation": "当前多模态奖励模型在训练中面临两个主要挑战：偏好数据集中的噪声导致模型性能下降；传统训练方法未能有效利用样本难度差异。", "method": "本文通过引入熵作为不可监督的代理，提出了一种基于熵指导的数据整理和训练策略来提高模型性能。", "result": "实验结果显示，采用该方法训练的多模态推理奖励模型在三个基准测试中均优于现有的最佳模型。", "conclusion": "基于熵的指导性数据处理与训练能够显著改善多模态推理奖励模型的准确性和效率。"}}
{"id": "2602.01881", "pdf": "https://arxiv.org/pdf/2602.01881", "abs": "https://arxiv.org/abs/2602.01881", "authors": ["Ye Chen", "Yupeng Zhu", "Xiongzhen Zhang", "Zhewen Wan", "Yingzhe Li", "Wenjun Zhang", "Bingbing Ni"], "title": "ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding", "categories": ["cs.CV"], "comment": null, "summary": "Prevailing image representation methods, including explicit representations such as raster images and Gaussian primitives, as well as implicit representations such as latent images, either suffer from representation redundancy that leads to heavy manual editing effort, or lack a direct mapping from latent variables to semantic instances or parts, making fine-grained manipulation difficult. These limitations hinder efficient and controllable image and video editing. To address these issues, we propose a hierarchical proxy-based parametric image representation that disentangles semantic, geometric, and textural attributes into independent and manipulable parameter spaces. Based on a semantic-aware decomposition of the input image, our representation constructs hierarchical proxy geometries through adaptive Bezier fitting and iterative internal region subdivision and meshing. Multi-scale implicit texture parameters are embedded into the resulting geometry-aware distributed proxy nodes, enabling continuous high-fidelity reconstruction in the pixel domain and instance- or part-independent semantic editing. In addition, we introduce a locality-adaptive feature indexing mechanism to ensure spatial texture coherence, which further supports high-quality background completion without relying on generative models. Extensive experiments on image reconstruction and editing benchmarks, including ImageNet, OIR-Bench, and HumanEdit, demonstrate that our method achieves state-of-the-art rendering fidelity with significantly fewer parameters, while enabling intuitive, interactive, and physically plausible manipulation. Moreover, by integrating proxy nodes with Position-Based Dynamics, our framework supports real-time physics-driven animation using lightweight implicit rendering, achieving superior temporal consistency and visual realism compared with generative approaches.", "AI": {"tldr": "本文提出了一种基于层次代理的参数化图像表示方法，通过自适应贝塞尔拟合和迭代内部区域分割及网格化构造分层代理几何形状，实现语义、几何和纹理属性的独立分离。", "motivation": "现有的图像表示方法存在冗余问题或缺乏直接从潜在变量到语义实例或部分的映射，导致精细操控困难。这些问题阻碍了高效可控的图像和视频编辑。", "method": "通过引入基于语义感知分解的方法，构造分层代理几何形状，并嵌入多尺度隐式纹理参数，实现像素域内的连续高保真重建和独立语义编辑；同时利用局部自适应特征索引机制保证空间纹理一致性，支持高质量背景填充。", "result": "在图像重构和编辑基准测试中展示了优于现有方法的渲染精度和参数数量优势，并实现了直观、交互式且物理上合理的操控。", "conclusion": "该框架通过引入代理节点与基于位置的动力学相结合，实现实时物理驱动动画支持轻量级隐式渲染，达到比生成模型更高的时空一致性及视觉真实性。"}}
{"id": "2602.01880", "pdf": "https://arxiv.org/pdf/2602.01880", "abs": "https://arxiv.org/abs/2602.01880", "authors": ["Giulio Antonio Abbo", "Senne Lenaerts", "Tony Belpaeme"], "title": "Multimodal Large Language Models for Real-Time Situated Reasoning", "categories": ["cs.RO"], "comment": "Submitted to the interactivity track of the 21st ACM/IEEE International Conference on Human-Robot Interaction on December 2025, accepted January 2026", "summary": "In this work, we explore how multimodal large language models can support real-time context- and value-aware decision-making. To do so, we combine the GPT-4o language model with a TurtleBot 4 platform simulating a smart vacuum cleaning robot in a home. The model evaluates the environment through vision input and determines whether it is appropriate to initiate cleaning. The system highlights the ability of these models to reason about domestic activities, social norms, and user preferences and take nuanced decisions aligned with the values of the people involved, such as cleanliness, comfort, and safety. We demonstrate the system in a realistic home environment, showing its ability to infer context and values from limited visual input. Our results highlight the promise of multimodal large language models in enhancing robotic autonomy and situational awareness, while also underscoring challenges related to consistency, bias, and real-time performance.", "AI": {"tldr": "研究探讨了多模态大型语言模型在支持实时情景感知决策中的应用，结合GPT-4o和TurtleBot 4机器人平台进行实验。", "motivation": "为了探索多模态大模型如何支持实时情境意识与价值敏感决策，并通过视觉输入评估环境是否适宜启动清洁任务。", "method": "将GPT-4o语言模型与模拟智能吸尘器的TurtleBot 4平台结合，在真实家庭环境中测试其根据有限视觉输入推断上下文和价值观的能力。", "result": "展示了该系统在复杂家庭环境下进行情境感知决策的有效性，同时也指出了一致性、偏见及实时性能等挑战。", "conclusion": "结果表明多模态大模型有潜力提升机器人自主性和情景意识，但也面临一些需要解决的技术问题。"}}
{"id": "2602.01879", "pdf": "https://arxiv.org/pdf/2602.01879", "abs": "https://arxiv.org/abs/2602.01879", "authors": ["Jaejun Lee", "Yoori Oh", "Kyogu Lee"], "title": "Speaking Without Sound: Multi-speaker Silent Speech Voicing with Facial Inputs Only", "categories": ["cs.SD"], "comment": "This paper was presented at ICASSP 2025", "summary": "In this paper, we introduce a novel framework for generating multi-speaker speech without relying on any audible inputs. Our approach leverages silent electromyography (EMG) signals to capture linguistic content, while facial images are used to match with the vocal identity of the target speaker. Notably, we present a pitch-disentangled content embedding that enhances the extraction of linguistic content from EMG signals. Extensive analysis demonstrates that our method can generate multi-speaker speech without any audible inputs and confirms the effectiveness of the proposed pitch-disentanglement approach.", "AI": {"tldr": "提出了一种仅使用面部输入的多说话人无声语音合成框架", "motivation": "为了在不依赖任何听觉输入的情况下生成高质量的语音，研究开发一种新的方法来捕捉语言内容并匹配目标说话人的声纹特征", "method": "利用静默肌电图信号捕获语言内容，并通过面部图像匹配说话人口音；引入了去调制内容嵌入技术以提高语言内容从肌电图信号中的提取效果", "result": "该方法能够成功生成多说话人语音，且验证了所提出的方法在不依赖听觉输入的情况下是有效的", "conclusion": "通过实验验证了无声语音合成框架的有效性"}}
{"id": "2602.01870", "pdf": "https://arxiv.org/pdf/2602.01870", "abs": "https://arxiv.org/abs/2602.01870", "authors": ["Riccardo Andrea Izzo", "Gianluca Bardaro", "Matteo Matteucci"], "title": "BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models", "categories": ["cs.RO"], "comment": null, "summary": "Recent advances in robot learning increasingly rely on LLM-based task planning, leveraging their ability to bridge natural language with executable actions. While prior works showcased great performances, the widespread adoption of these models in robotics has been challenging as 1) existing methods are often closed-source or computationally intensive, neglecting the actual deployment on real-world physical systems, and 2) there is no universally accepted, plug-and-play representation for robotic task generation. Addressing these challenges, we propose BTGenBot-2, a 1B-parameter open-source small language model that directly converts natural language task descriptions and a list of robot action primitives into executable behavior trees in XML. Unlike prior approaches, BTGenBot-2 enables zero-shot BT generation, error recovery at inference and runtime, while remaining lightweight enough for resource-constrained robots. We further introduce the first standardized benchmark for LLM-based BT generation, covering 52 navigation and manipulation tasks in NVIDIA Isaac Sim. Extensive evaluations demonstrate that BTGenBot-2 consistently outperforms GPT-5, Claude Opus 4.1, and larger open-source models across both functional and non-functional metrics, achieving average success rates of 90.38% in zero-shot and 98.07% in one-shot, while delivering up to 16x faster inference compared to the previous BTGenBot.", "AI": {"tldr": "本文提出了一种基于小语言模型的高效行为树生成方法BTGenBot-2，该模型可以直接将自然语言任务描述转换为可执行的行为树。", "motivation": "机器人学习中的任务规划依赖于大型语言模型的能力，但这些模型往往闭源或计算成本高，不适用于实际部署。同时缺少一个通用的、即插即用的任务生成表示方法。本文旨在解决这些问题。", "method": "BTGenBot-2是一个10亿参数的小型开源语言模型，能够将自然语言任务描述和机器人行动原语列表转换为XML格式的行为树。该模型支持零样本行为树生成，并且具有错误恢复能力，适用于资源受限的设备。", "result": "通过基准测试表明，BTGenBot-2在功能性和非功能性指标上均优于GPT-5、Claude Opus 4.1和较大的开源模型，在零样本任务中平均成功率高达90.38%，一次训练后成功率达到98.07%，同时推理速度比前一代快16倍。", "conclusion": "BTGenBot-2克服了先前方法的局限性，实现了高效的行为树生成，并为基于大型语言模型的任务规划设定了新的标准。"}}
{"id": "2602.01869", "pdf": "https://arxiv.org/pdf/2602.01869", "abs": "https://arxiv.org/abs/2602.01869", "authors": ["Qirui Mi", "Zhijian Ma", "Mengyue Yang", "Haoxuan Li", "Yisen Wang", "Haifeng Zhang", "Jun Wang"], "title": "ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents", "categories": ["cs.AI"], "comment": "20 Pages, 6 Figures, 4 Tables", "summary": "LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and execution instability. To bridge this gap, we propose ProcMEM, a framework that enables agents to autonomously learn procedural memory from interaction experiences without parameter updates. By formalizing a Skill-MDP, ProcMEM transforms passive episodic narratives into executable Skills defined by activation, execution, and termination conditions to ensure executability. To achieve reliable reusability without capability degradation, we introduce Non-Parametric PPO, which leverages semantic gradients for high-quality candidate generation and a PPO Gate for robust Skill verification. Through score-based maintenance, ProcMEM sustains compact, high-quality procedural memory. Experimental results across in-domain, cross-task, and cross-agent scenarios demonstrate that ProcMEM achieves superior reuse rates and significant performance gains with extreme memory compression. Visualized evolutionary trajectories and Skill distributions further reveal how ProcMEM transparently accumulates, refines, and reuses procedural knowledge to facilitate long-term autonomy.", "AI": {"tldr": "本文提出了一种名为ProcMEM的框架，通过非参数PPO使得LLM驱动的代理能够从互动经验中自主学习过程记忆。", "motivation": "现有的LLM代理在处理重复场景时存在计算冗余和执行不稳定问题，因为它们往往依赖于即时推理而不是重用先前的经验。", "method": "ProcMEM通过Skill-MDP将被动叙述转换为可执行技能，并引入非参数PPO进行候选生成和技能验证以确保可靠性和高效性。", "result": "实验结果表明，在各种场景下，ProcMEM实现了更高的重用率和显著的性能提升，同时保持了紧凑的记忆。", "conclusion": "ProcMEM通过累积、精炼和重用过程知识来促进长期自主性的透明积累，证明了其在实现高效学习记忆方面的有效性。"}}
{"id": "2602.01865", "pdf": "https://arxiv.org/pdf/2602.01865", "abs": "https://arxiv.org/abs/2602.01865", "authors": ["Shaopeng Chen", "Chuyue Xie", "Huimin Ren", "Shaozong Zhang", "Han Zhang", "Ruobing Cheng", "Zhiqiang Cao", "Zehao Ju", "Yu Gao", "Jie Ding", "Xiaodong Chen", "Xuewu Jiao", "Shuanglong Li", "Liu Lin"], "title": "GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Traditional Deep Learning Recommendation Models (DLRMs) face increasing bottlenecks in performance and efficiency, often struggling with generalization and long-sequence modeling. Inspired by the scaling success of Large Language Models (LLMs), we propose Generative Ranking for Ads at Baidu (GRAB), an end-to-end generative framework for Click-Through Rate (CTR) prediction. GRAB integrates a novel Causal Action-aware Multi-channel Attention (CamA) mechanism to effectively capture temporal dynamics and specific action signals within user behavior sequences. Full-scale online deployment demonstrates that GRAB significantly outperforms established DLRMs, delivering a 3.05% increase in revenue and a 3.49% rise in CTR. Furthermore, the model demonstrates desirable scaling behavior: its expressive power shows a monotonic and approximately linear improvement as longer interaction sequences are utilized.", "AI": {"tldr": "提出了一种基于大规模语言模型启发的广告点击率预测框架GRAB。", "motivation": "深度学习推荐模型在性能和效率上面临瓶颈，难以进行长序列建模。受大型语言模型的成功启发，设计了一种新的广告点击率预测方法以提升模型泛化能力和效果。", "method": "引入了因果行为感知多通道注意力机制来捕捉用户行为序列中的时间动态和特定动作信号，并构建了一个端到端的生成框架进行CTR预测。", "result": "在线部署显示，GRAB相比现有深度学习推荐模型在收入上提高了3.05%，点击率上升了3.49%。此外，其表达能力随着交互序列的增长呈现出单调且近似线性增长的趋势。", "conclusion": "GRAB展示了良好的扩展性能和对长序列数据的有效处理能力，在CTR预测任务中表现优异，并在实际应用中取得了显著的商业价值提升。"}}
{"id": "2602.01864", "pdf": "https://arxiv.org/pdf/2602.01864", "abs": "https://arxiv.org/abs/2602.01864", "authors": ["Yuan Wang", "Yuhao Wan", "Siming Zheng", "Bo Li", "Qibin Hou", "Peng-Tao Jiang"], "title": "Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling", "categories": ["cs.CV"], "comment": "26 pages, 19 figures. Accepted to ICLR 2026", "summary": "Recent works have explored reference-based super-resolution (RefSR) to mitigate hallucinations in diffusion-based image restoration. A key challenge is that real-world degradations make correspondences between low-quality (LQ) inputs and reference (Ref) images unreliable, requiring adaptive control of reference usage. Existing methods either ignore LQ-Ref correlations or rely on brittle explicit matching, leading to over-reliance on misleading references or under-utilization of valuable cues. To address this, we propose Ada-RefSR, a single-step diffusion framework guided by a \"Trust but Verify\" principle: reference information is leveraged when reliable and suppressed otherwise. Its core component, Adaptive Implicit Correlation Gating (AICG), employs learnable summary tokens to distill dominant reference patterns and capture implicit correlations with LQ features. Integrated into the attention backbone, AICG provides lightweight, adaptive regulation of reference guidance, serving as a built-in safeguard against erroneous fusion. Experiments on multiple datasets demonstrate that Ada-RefSR achieves a strong balance of fidelity, naturalness, and efficiency, while remaining robust under varying reference alignment.", "AI": {"tldr": "提出了一种基于信任但需验证原则的单步扩散框架Ada-RefSR，以提高参考图像辅助下的超分辨率效果。", "motivation": "现有的参考基图像超分辨率方法要么忽略了低质量输入与参考图像之间的关联性，要么依赖于脆弱的显式匹配方式，导致过度依赖误导性的参考或低估有价值的线索。为了克服这些挑战，引入了一种自适应的方法来更好地利用可信的参考信息。", "method": "通过学习总结令牌捕获隐式的关联性，并集成到注意力骨干网络中以轻量级、自适应地调节参考指导，以此作为内置保护措施防止错误融合。", "result": "实验表明Ada-RefSR在多个数据集上实现了较高的保真度、自然性和效率，同时对不同参考图像对齐情况具有鲁棒性。", "conclusion": "通过采用信任但需验证的原则，Ada-RefSR能够更有效地利用参考图像信息，在不牺牲生成质量的情况下增强超分辨率结果的可靠性。"}}
{"id": "2602.01861", "pdf": "https://arxiv.org/pdf/2602.01861", "abs": "https://arxiv.org/abs/2602.01861", "authors": ["Shaoheng Xu", "Chunyi Sun", "Jihui Zhang", "Prasanga N. Samarasinghe", "Thushara D. Abhayapala"], "title": "RIR-Former: Coordinate-Guided Transformer for Continuous Reconstruction of Room Impulse Responses", "categories": ["eess.AS", "cs.LG"], "comment": "Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026. Equal contribution: Shaoheng Xu and Chunyi Sun", "summary": "Room impulse responses (RIRs) are essential for many acoustic signal processing tasks, yet measuring them densely across space is often impractical. In this work, we propose RIR-Former, a grid-free, one-step feed-forward model for RIR reconstruction. By introducing a sinusoidal encoding module into a transformer backbone, our method effectively incorporates microphone position information, enabling interpolation at arbitrary array locations. Furthermore, a segmented multi-branch decoder is designed to separately handle early reflections and late reverberation, improving reconstruction across the entire RIR. Experiments on diverse simulated acoustic environments demonstrate that RIR-Former consistently outperforms state-of-the-art baselines in terms of normalized mean square error (NMSE) and cosine distance (CD), under varying missing rates and array configurations. These results highlight the potential of our approach for practical deployment and motivate future work on scaling from randomly spaced linear arrays to complex array geometries, dynamic acoustic scenes, and real-world environments.", "AI": {"tldr": "该论文提出了RIR-Former，这是一种用于连续重建房间脉冲响应（RIR）的网格自由、一步前馈模型。", "motivation": "测量房间脉冲响应（RIR）在许多声信号处理任务中至关重要，但由于空间密集测量通常不切实际，因此需要一种新的方法来有效解决这个问题。", "method": "通过引入正弦编码模块到变压器主干网中，该方法有效地结合了麦克风位置信息，使得可以在任意数组位置进行插值。此外，设计了一个分段多分支解码器以分别处理早期反射和晚期混响，从而改善整个RIR的重建。", "result": "在不同的模拟声学环境中实验表明，与现有基线相比，在各种缺失率和阵列配置下，该方法在归一化均方误差（NMSE）和余弦距离（CD）方面始终表现更好。", "conclusion": "这些结果突显了该方法在实际部署中的潜力，并激励未来的工作从随机间隔的线性数组扩展到复杂的数组几何形状、动态声学场景以及现实世界的环境中。"}}
{"id": "2602.01860", "pdf": "https://arxiv.org/pdf/2602.01860", "abs": "https://arxiv.org/abs/2602.01860", "authors": ["Filip Novák", "Matěj Petrlík", "Matej Novosad", "Parakh M. Gupta", "Robert Pěnička", "Martin Saska"], "title": "Vision-only UAV State Estimation for Fast Flights Without External Localization Systems: A2RL Drone Racing Finalist Approach", "categories": ["cs.RO"], "comment": "Visit our webpage for more details: https://mrs.fel.cvut.cz/papers/vision-only-uav-state-estimation", "summary": "Fast flights with aggressive maneuvers in cluttered GNSS-denied environments require fast, reliable, and accurate UAV state estimation. In this paper, we present an approach for onboard state estimation of a high-speed UAV using a monocular RGB camera and an IMU. Our approach fuses data from Visual-Inertial Odometry (VIO), an onboard landmark-based camera measurement system, and an IMU to produce an accurate state estimate. Using onboard measurement data, we estimate and compensate for VIO drift through a novel mathematical drift model. State-of-the-art approaches often rely on more complex hardware (e.g., stereo cameras or rangefinders) and use uncorrected drifting VIO velocities, orientation, and angular rates, leading to errors during fast maneuvers. In contrast, our method corrects all VIO states (position, orientation, linear and angular velocity), resulting in accurate state estimation even during rapid and dynamic motion. Our approach was thoroughly validated through 1600 simulations and numerous real-world experiments. Furthermore, we applied the proposed method in the A2RL Drone Racing Challenge 2025, where our team advanced to the final four out of 210 teams and earned a medal.", "AI": {"tldr": "本文提出了一种基于单目RGB相机和IMU的高速无人机状态估计方法，适用于快速飞行及复杂环境下的精准定位。", "motivation": "在GPS信号缺失且环境复杂的环境中进行快速、可靠和准确的无人机状态估计是必要但具有挑战性的。现有的解决方案依赖更复杂的硬件或未经校正的VIO数据，在动态环境下效果不佳。", "method": "该方法结合单目视觉惯性里程计（VIO）、基于地标测量系统及IMU的数据，通过数学模型矫正VIO漂移，并对所有状态进行精确估计。", "result": "该方法经过1600次模拟和多次真实环境实验验证。在A2RL无人机竞速挑战赛中表现出色，进入前四名。", "conclusion": "研究提出的方法能够有效提高高速飞行下无人机的状态估计精度，在复杂环境下具有显著优势。"}}
{"id": "2602.01858", "pdf": "https://arxiv.org/pdf/2602.01858", "abs": "https://arxiv.org/abs/2602.01858", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures", "categories": ["cs.AI"], "comment": null, "summary": "Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condition-dependent relevance, and actionable execution requirement, which standard semantic-driven Retrieval-Augmented Generation (RAG) paradigms fail to address. Inspired by the Mixture-of-Experts (MoE) paradigm, we propose SOPRAG, a novel framework specifically designed to address the above pain points in SOP retrieval. SOPRAG replaces flat chunking with specialized Entity, Causal, and Flow graph experts to resolve industrial structural and logical complexities. To optimize and coordinate these experts, we propose a Procedure Card layer that prunes the search space to eliminate computational noise, and an LLM-Guided gating mechanism that dynamically weights these experts to align retrieval with operator intent. To address the scarcity of domain-specific data, we also introduce an automated, multi-agent workflow for benchmark construction. Extensive experiments across four industrial domains demonstrate that SOPRAG significantly outperforms strong lexical, dense, and graph-based RAG baselines in both retrieval accuracy and response utility, achieving perfect execution scores in real-world critical tasks.", "AI": {"tldr": "SOPRAG是一种用于工业标准操作程序检索的框架，它通过使用专门的知识图谱专家来解决传统方法无法处理的问题。", "motivation": "为了解决当前标准操作程序（SOP）检索中存在的结构复杂性、逻辑依赖性和执行需求等问题，传统的基于语义驱动的检索增强生成(RAG)模式效果不佳。因此提出了一种新的框架以优化和协调这些挑战。", "method": "提出了一个名为SOPRAG的新框架，通过引入实体图专家、因果图专家和流程图专家来解决工业结构和逻辑复杂性问题，并使用程序卡层减少搜索空间的噪声，以及利用LLM引导门控机制动态加权这些专家以更好地满足操作者的意图。", "result": "实验结果显示SOPRAG在检索准确性和响应效用方面显著优于强大的词典、密集型和基于图的RAG基线，在现实世界的关键任务中实现了完美的执行分数。", "conclusion": "SOPRAG通过专门的知识图谱专家解决工业结构复杂性问题，优化了现有SOP检索方法，并展示了其在多个行业领域的优越性能。"}}
{"id": "2602.01855", "pdf": "https://arxiv.org/pdf/2602.01855", "abs": "https://arxiv.org/abs/2602.01855", "authors": ["Blagoj Hristov", "Hristijan Gjoreski", "Vesna Ojleska Latkoska", "Gorjan Nadzinski"], "title": "Time2Vec Transformer for Robust Gesture Recognition from Low-Density sEMG", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Accurate and responsive myoelectric prosthesis control typically relies on complex, dense multi-sensor arrays, which limits consumer accessibility. This paper presents a novel, data-efficient deep learning framework designed to achieve precise and accurate control using minimal sensor hardware. Leveraging an external dataset of 8 subjects, our approach implements a hybrid Transformer optimized for sparse, two-channel surface electromyography (sEMG). Unlike standard architectures that use fixed positional encodings, we integrate Time2Vec learnable temporal embeddings to capture the stochastic temporal warping inherent in biological signals. Furthermore, we employ a normalized additive fusion strategy that aligns the latent distributions of spatial and temporal features, preventing the destructive interference common in standard implementations. A two-stage curriculum learning protocol is utilized to ensure robust feature extraction despite data scarcity. The proposed architecture achieves a state-of-the-art multi-subject F1-score of 95.7% $\\pm$ 0.20% for a 10-class movement set, statistically outperforming both a standard Transformer with fixed encodings and a recurrent CNN-LSTM model. Architectural optimization reveals that a balanced allocation of model capacity between spatial and temporal dimensions yields the highest stability. Furthermore, while direct transfer to a new unseen subject led to poor accuracy due to domain shifts, a rapid calibration protocol utilizing only two trials per gesture recovered performance from 21.0% $\\pm$ 2.98% to 96.9% $\\pm$ 0.52%. By validating that high-fidelity temporal embeddings can compensate for low spatial resolution, this work challenges the necessity of high-density sensing. The proposed framework offers a robust, cost-effective blueprint for next-generation prosthetic interfaces capable of rapid personalization.", "AI": {"tldr": "本文提出了一种新的深度学习框架，用于通过稀疏的两通道表面肌电图（sEMG）实现精确且准确的手势识别。", "motivation": "复杂的多传感器阵列限制了消费者的可访问性。本文旨在设计一种数据高效的深层学习架构，以最小的硬件需求来实现精准控制。", "method": "采用了一个优化过的混合Transformer模型，并使用Time2Vec自适应时序嵌入来捕捉生物信号中的随机时间扭曲现象，同时采用了归一化加法融合策略来对齐空间和时间特征的潜在分布。通过两阶段课程学习协议确保在数据稀缺情况下也能实现稳健的功能提取。", "result": "该架构在10类手势集中获得了95.7%±0.20%的状态-of-the-art多主体F1得分，显著优于标准Transformer和递归CNN-LSTM模型。", "conclusion": "通过验证高保真时间嵌入可以弥补低空间分辨率的不足，挑战了对高密度感应的需求。本文提出的框架为下一代假肢接口提供了稳健、经济且易于个性化的设计方案。"}}
{"id": "2602.01854", "pdf": "https://arxiv.org/pdf/2602.01854", "abs": "https://arxiv.org/abs/2602.01854", "authors": ["A S M Sharifuzzaman Sagar", "Mohammed Bennamoun", "Farid Boussaid", "Naeha Sharif", "Lian Xu", "Shaaban Sahmoud", "Ali Kishk"], "title": "Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection", "categories": ["cs.CV"], "comment": null, "summary": "In multimodal misinformation, deception usually arises not just from pixel-level manipulations in an image, but from the semantic and contextual claim jointly expressed by the image-text pair. Yet most deepfake detectors, engineered to detect pixel-level forgeries, do not account for claim-level meaning, despite their growing integration in automated fact-checking (AFC) pipelines. This raises a central scientific and practical question: Do pixel-level detectors contribute useful signal for verifying image-text claims, or do they instead introduce misleading authenticity priors that undermine evidence-based reasoning? We provide the first systematic analysis of deepfake detectors in the context of multimodal misinformation detection. Using two complementary benchmarks, MMFakeBench and DGM4, we evaluate: (1) state-of-the-art image-only deepfake detectors, (2) an evidence-driven fact-checking system that performs tool-guided retrieval via Monte Carlo Tree Search (MCTS) and engages in deliberative inference through Multi-Agent Debate (MAD), and (3) a hybrid fact-checking system that injects detector outputs as auxiliary evidence. Results across both benchmark datasets show that deepfake detectors offer limited standalone value, achieving F1 scores in the range of 0.26-0.53 on MMFakeBench and 0.33-0.49 on DGM4, and that incorporating their predictions into fact-checking pipelines consistently reduces performance by 0.04-0.08 F1 due to non-causal authenticity assumptions. In contrast, the evidence-centric fact-checking system achieves the highest performance, reaching F1 scores of approximately 0.81 on MMFakeBench and 0.55 on DGM4. Overall, our findings demonstrate that multimodal claim verification is driven primarily by semantic understanding and external evidence, and that pixel-level artifact signals do not reliably enhance reasoning over real-world image-text misinformation.", "AI": {"tldr": "该论文评估了像素级深度伪造检测器在多模态虚假信息验证中的效用，发现其贡献有限。", "motivation": "大多数深度伪造检测器专注于图像的像素层面而不考虑语义和上下文层面，这种局限性可能误导自动化事实核查系统，因此需要研究它们的真实价值。", "method": "使用MMFakeBench和DGM4两个基准数据集评估了现有的图像级深度伪造检测器、基于证据的事实核查系统以及将检测结果作为辅助信息融合的混合系统，并比较了各自的效果。", "result": "像素级深度伪造检测器在验证多模态虚假声明时表现出有限的价值，F1得分范围为0.26至0.53（MMFakeBench）和0.33至0.49（DGM4）。相比之下，基于证据的事实核查系统表现最好，在两个数据集上分别达到了大约0.81和0.55的F1分数。", "conclusion": "研究结果表明，多模态声明验证主要依靠语义理解和外部证据，像素级伪造信号不能可靠地增强现实世界图像文本虚假信息推理的有效性。"}}
{"id": "2602.01851", "pdf": "https://arxiv.org/pdf/2602.01851", "abs": "https://arxiv.org/abs/2602.01851", "authors": ["Huanyu Zhang", "Xuehai Bai", "Chengzu Li", "Chen Liang", "Haochen Tian", "Haodong Li", "Ruichuan An", "Yifan Zhang", "Anna Korhonen", "Zhang Zhang", "Liang Wang", "Tieniu Tan"], "title": "How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing", "categories": ["cs.CV"], "comment": "https://vibe-benchmark.github.io/", "summary": "Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.", "AI": {"tldr": "本文介绍了一个用于评估视觉指令驱动图像编辑的基准VIBE，通过三个层次的交互体系结构来衡量模型的能力，并评估了多种图像编辑模型的表现。", "motivation": "现有的图像编辑系统和基准主要依赖文本引导，缺乏对视觉指令的理解能力。人类沟通是多模态的，而现有技术在这方面存在不足。因此，作者引入VIBE基准以填补这一空白，更准确地反映模型处理复杂视觉指令的能力。", "method": "通过三个层次（指代定位、形态操纵和因果推理）构建了包含高质量且多样化的测试案例集，并提出一个任务特定的LMM评估框架来全面衡量图像编辑模型的表现。", "result": "评估表明，专有模型在低难度任务中表现出较强的能力，但随着任务复杂性的增加，性能明显下降。开源模型则整体表现较差。", "conclusion": "尽管专有模型在早期阶段展现了一定的视觉指令跟随能力，但在处理高难度任务时仍然面临挑战。这表明未来研究需要探索新的方法来增强模型的理解和执行复杂视觉指令的能力。"}}
{"id": "2602.01850", "pdf": "https://arxiv.org/pdf/2602.01850", "abs": "https://arxiv.org/abs/2602.01850", "authors": ["Pei Li", "Jiaxi Yin", "Lei Ouyang", "Shihan Pan", "Ge Wang", "Han Ding", "Fei Wang"], "title": "WS-IMUBench: Can Weakly Supervised Methods from Audio, Image, and Video Be Adapted for IMU-based Temporal Action Localization?", "categories": ["cs.CV"], "comment": "Under Review. 28 pages, 9 figures, 6 tables", "summary": "IMU-based Human Activity Recognition (HAR) has enabled a wide range of ubiquitous computing applications, yet its dominant clip classification paradigm cannot capture the rich temporal structure of real-world behaviors. This motivates a shift toward IMU Temporal Action Localization (IMU-TAL), which predicts both action categories and their start/end times in continuous streams. However, current progress is strongly bottlenecked by the need for dense, frame-level boundary annotations, which are costly and difficult to scale. To address this bottleneck, we introduce WS-IMUBench, a systematic benchmark study of weakly supervised IMU-TAL (WS-IMU-TAL) under only sequence-level labels. Rather than proposing a new localization algorithm, we evaluate how well established weakly supervised localization paradigms from audio, image, and video transfer to IMU-TAL under only sequence-level labels. We benchmark seven representative weakly supervised methods on seven public IMU datasets, resulting in over 3,540 model training runs and 7,080 inference evaluations. Guided by three research questions on transferability, effectiveness, and insights, our findings show that (i) transfer is modality-dependent, with temporal-domain methods generally more stable than image-derived proposal-based approaches; (ii) weak supervision can be competitive on favorable datasets (e.g., with longer actions and higher-dimensional sensing); and (iii) dominant failure modes arise from short actions, temporal ambiguity, and proposal quality. Finally, we outline concrete directions for advancing WS-IMU-TAL (e.g., IMU-specific proposal generation, boundary-aware objectives, and stronger temporal reasoning). Beyond individual results, WS-IMUBench establishes a reproducible benchmarking template, datasets, protocols, and analyses, to accelerate community-wide progress toward scalable WS-IMU-TAL.", "AI": {"tldr": "该论文通过引入WS-IMUBench基准，研究了在仅使用序列级别标签的情况下，基于音频、图像和视频的弱监督定位方法是否可以转移到惯性测量单元（IMU）上的行为时间定位。", "motivation": "由于现有的惯性传感器数据集需要密集且成本高昂的时间标注，该论文旨在探讨如何通过弱监督学习方法来解决这个问题，并评估这些方法在IMU数据集上的性能。", "method": "该研究没有提出新的定位算法，而是将七个代表性的弱监督定位方法应用于七种公开的IMU数据集中进行基准测试。总共进行了超过3540次模型训练和7080次推理评估。", "result": "研究结果显示，在仅使用序列级别标签的情况下，时间域方法比图像衍生的提议基方法更稳定；对于有利的数据集（例如较长动作和高维度感知），弱监督可以与强监督相媲美。然而，短动作、时间模糊性和提议质量是主要的失败模式。", "conclusion": "该论文提出了一个可重复性的基准测试模板，并为促进社区在IMU上的行为时间定位研究的发展指出了具体方向。"}}
{"id": "2602.01848", "pdf": "https://arxiv.org/pdf/2602.01848", "abs": "https://arxiv.org/abs/2602.01848", "authors": ["Salaheddin Alzu'bi", "Baran Nama", "Arda Kaz", "Anushri Eswaran", "Weiyuan Chen", "Sarvesh Khetan", "Rishab Bala", "Tu Vu", "Sewoong Oh"], "title": "ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive Open Meta-Agents), a domain-agnostic framework that addresses these limitations through recursive task decomposition and structured aggregation. ROMA decomposes goals into dependency-aware subtask trees that can be executed in parallel, while aggregation compresses and validates intermediate results to control context growth. Our framework standardizes agent construction around four modular roles --Atomizer (which decides whether a task should be decomposed), Planner, Executor, and Aggregator -- which cleanly separate orchestration from model selection and enable transparent, hierarchical execution traces. This design supports heterogeneous multi-agent systems that mix models and tools according to cost, latency, and capability. To adapt ROMA to specific tasks without fine-tuning, we further introduce GEPA$+$, an improved Genetic-Pareto prompt proposer that searches over prompts within ROMA's component hierarchy while preserving interface contracts. We show that ROMA, combined with GEPA+, delivers leading system-level performance on reasoning and long-form generation benchmarks. On SEAL-0, which evaluates reasoning over conflicting web evidence, ROMA instantiated with GLM-4.6 improves accuracy by 9.9\\% over Kimi-Researcher. On EQ-Bench, a long-form writing benchmark, ROMA enables DeepSeek-V3 to match the performance of leading closed-source models such as Claude Sonnet 4.5. Our results demonstrate that recursive, modular agent architectures can scale reasoning depth while remaining interpretable, flexible, and model-agnostic.", "AI": {"tldr": "ROMA框架用于解决长时序多智能体系统中的任务分解和聚合问题，提高性能。", "motivation": "当前的代理框架在长时间任务中表现不佳，通过引入递归开放元代理（ROMA）框架来克服这一缺陷，该框架能够进行递归的任务分解，并且可以压缩和验证中间结果以控制上下文增长。", "method": "介绍了一种名为ROMA的框架，它将目标分解为依赖感知子任务树，同时执行聚合以压缩并验证中间结果。还引入了GEPA+，一个改进的遗传-帕累托提示生成器，用于在ROMA组件层次结构中搜索提示。", "result": "实验结果显示，在SEAL-0和EQ-Bench基准测试上，结合使用ROMA和GEPA+后，系统级性能领先。特别是在SEAL-0任务上，准确率提升了9.9%；而在长形式写作的EQ-Bench测试中，与封闭源模型的表现相当。", "conclusion": "该研究证明了递归、模块化代理架构能够在增加推理深度的同时保持可解释性、灵活性和模型无关性。"}}
{"id": "2602.01846", "pdf": "https://arxiv.org/pdf/2602.01846", "abs": "https://arxiv.org/abs/2602.01846", "authors": ["Changyang He", "Parnian Jahangirirad", "Lin Kyi", "Asia J. Biega"], "title": "When Feasibility of Fairness Audits Relies on Willingness to Share Data: Examining User Acceptance of Multi-Party Computation Protocols for Fairness Monitoring", "categories": ["cs.HC", "cs.CR", "cs.CY"], "comment": "34 pages, 5 figures. Conditionally accepted to CHI 2026", "summary": "Fairness monitoring is critical for detecting algorithmic bias, as mandated by the EU AI Act. Since such monitoring requires sensitive user data (e.g., ethnicity), the AI Act permits its processing only with strict privacy measures, such as multi-party computation (MPC), in compliance with the GDPR. However, the effectiveness of such secure monitoring protocols ultimately depends on people's willingness to share their data. Little is known about how different MPC protocol designs shape user acceptance. To address this, we conducted an online survey with 833 participants in Europe, examining user acceptance of various MPC protocol designs for fairness monitoring. Findings suggest that users prioritized risk-related attributes (e.g., privacy protection mechanism) in direct evaluation but benefit-related attributes (e.g., fairness objective) in simulated choices, with acceptance shaped by their fairness and privacy orientations. We derive implications for deploying and communicating privacy-preserving protocols in ways that foster informed consent and align with user expectations.", "AI": {"tldr": "本文通过在线调查研究了用户对用于公平性监测的不同多方计算（MPC）协议设计的接受程度。", "motivation": "为了检测算法偏见，需要敏感用户数据进行公平性监控。但这种监控的有效性依赖于人们是否愿意分享他们的数据。当前关于不同MPC协议设计如何影响用户体验知之甚少。", "method": "研究团队进行了在线调查，共有833名欧洲参与者参与了对各种MPC协议设计方案的直接评估和模拟选择。", "result": "结果显示，在直接评估中用户更重视风险相关属性（如隐私保护机制），而在模拟选择中则更重视利益相关属性（如公平性目标）。用户的接受程度由其公平性和隐私偏好决定。", "conclusion": "研究为部署和传达促进知情同意并符合用户期望的隐私保护协议提供了启示。"}}
{"id": "2602.01844", "pdf": "https://arxiv.org/pdf/2602.01844", "abs": "https://arxiv.org/abs/2602.01844", "authors": ["Yuliang Zhan", "Jian Li", "Wenbing Huang", "Wenbing Huang", "Yang Liu", "Hao Sun"], "title": "CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions", "categories": ["cs.CV", "cs.AI"], "comment": "ICLR 2026", "summary": "Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framework designed for CDG. CloDS adopts a three-stage pipeline that first performs video-to-geometry grounding and then trains a dynamics model on the grounded meshes. To cope with large non-linear deformations and severe self-occlusions during grounding, we introduce a dual-position opacity modulation that supports bidirectional mapping between 2D observations and 3D geometry via mesh-based Gaussian splatting in video-to-geometry grounding stage. It jointly considers the absolute and relative position of Gaussian components. Comprehensive experimental evaluations demonstrate that CloDS effectively learns cloth dynamics from visual data while maintaining strong generalization capabilities for unseen configurations. Our code is available at https://github.com/whynot-zyl/CloDS. Visualization results are available at https://github.com/whynot-zyl/CloDS_video}.%\\footnote{As in this example.", "AI": {"tldr": "CloDS是一个用于在未知条件下从多视角视觉观测中无监督学习布料动力学的框架。", "motivation": "现有的方法需要已知物理属性作为监督或输入，这限制了它们在未知条件下的应用。为了应对这一挑战，作者提出了一个新颖的场景——布料动力学接地（CDG）以及相应的CloDS框架。", "method": "CloDS采用了三阶段流程：首先进行视频到几何结构化映射；然后在一个基于网格的高斯点阵基础上训练动态模型。为了解决非线性变形和严重自我遮挡问题，引入了双位置不透明度调制方法，支持二维观察与三维几何之间的双向映射。", "result": "实验评估表明，CloDS能够从视觉数据中有效学习布料动力学，并且对于未见过的配置保持强大的泛化能力。", "conclusion": "通过无监督动态学习框架CloDS，该研究成功展示了如何在未知条件下仅从多视角视觉观测中学习布料的动力学。"}}
{"id": "2602.01843", "pdf": "https://arxiv.org/pdf/2602.01843", "abs": "https://arxiv.org/abs/2602.01843", "authors": ["Qian Xu", "Xi Li", "Fei Gao", "Jie Guo", "Haojuan Yuan", "Shuaipeng Fan", "Mingjin Zhang"], "title": "SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection (IRSTD) is crucial for surveillance and early-warning, with deployments spanning both single-frame analysis and video-mode tracking. A practical solution should leverage vision foundation models (VFMs) to mitigate infrared data scarcity, while adopting a memory-attention-based temporal propagation framework that unifies single- and multi-frame inference. However, infrared small targets exhibit weak radiometric signals and limited semantic cues, which differ markedly from visible-spectrum imagery. This modality gap makes direct use of semantics-oriented VFMs and appearance-driven cross-frame association unreliable for IRSTD: hierarchical feature aggregation can submerge localized target peaks, and appearance-only memory attention becomes ambiguous, leading to spurious clutter associations. To address these challenges, we propose SPIRIT, a unified and VFM-compatible framework that adapts VFMs to IRSTD via lightweight physics-informed plug-ins. Spatially, PIFR refines features by approximating rank-sparsity decomposition to suppress structured background components and enhance sparse target-like signals. Temporally, PGMA injects history-derived soft spatial priors into memory cross-attention to constrain cross-frame association, enabling robust video detection while naturally reverting to single-frame inference when temporal context is absent. Experiments on multiple IRSTD benchmarks show consistent gains over VFM-based baselines and SOTA performance.", "AI": {"tldr": "SPIRIT是一个适应视觉基础模型的统一框架，用于单帧和多帧红外小目标检测。", "motivation": "直接使用语义导向的基础模型进行红外小目标检测效果不佳，因为红外数据中的信号弱且语义线索不足。本文旨在通过物理信息插件优化这些模型以解决这一问题。", "method": "提出SPIRIT框架，包括PIFR和PGMA模块，前者在空间上增强稀疏的目标信号并抑制背景干扰；后者利用历史信息约束跨帧关联，提高视频检测的鲁棒性。", "result": "实验结果显示，与基于视觉基础模型的方法相比，SPIRIT表现更优，在多个红外小目标检测基准测试中达到了最先进的性能。", "conclusion": "本文提出了一种有效的适应方法来优化视觉基础模型以应用于红外小目标检测，并取得了显著的成果。"}}
{"id": "2602.01839", "pdf": "https://arxiv.org/pdf/2602.01839", "abs": "https://arxiv.org/abs/2602.01839", "authors": ["Ru Zhang", "Xunkai Li", "Yaxin Deng", "Sicheng Liu", "Daohan Su", "Qiangqiang Dai", "Hongchao Qin", "Rong-Hua Li", "Guoren Wang", "Jia Li"], "title": "DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "12 pages, 4 figures", "summary": "Recently, data-centric AI methodology has been a dominant paradigm in single-cell transcriptomics analysis, which treats data representation rather than model complexity as the fundamental bottleneck. In the review of current studies, earlier sequence methods treat cells as independent entities and adapt prevalent ML models to analyze their directly inherited sequence data. Despite their simplicity and intuition, these methods overlook the latent intercellular relationships driven by the functional mechanisms of biological systems and the inherent quality issues of the raw sequence data. Therefore, a series of structured methods has emerged. Although they employ various heuristic rules to capture intricate intercellular relationships and enhance the raw sequencing data, these methods often neglect biological prior knowledge. This omission incurs substantial overhead and yields suboptimal graph representations, thereby hindering the utility of ML models. To address them, we propose DOGMA, a holistic data-centric framework designed for the structural reshaping and semantic enhancement of raw data through multi-level biological prior knowledge. Transcending reliance on stochastic heuristics, DOGMA redefines graph construction by integrating Statistical Anchors with Cell Ontology and Phylogenetic Trees to enable deterministic structure discovery and robust cross-species alignment. Furthermore, Gene Ontology is utilized to bridge the feature-level semantic gap by incorporating functional priors. In complex multi-species and multi-organ benchmarks, DOGMA achieves SOTA performance, exhibiting superior zero-shot robustness and sample efficiency while operating with significantly lower computational cost.", "AI": {"tldr": "DOGMA是一种通过多层次生物先验知识进行数据重塑和语义增强的数据为中心的框架，用于单细胞转录组学分析。", "motivation": "早期序列方法将细胞视为独立实体，并直接利用流行的机器学习模型处理其继承的序列数据。然而这些方法忽略了由生物学系统功能机制驱动的潜在细胞间关系以及原始序列数据的质量问题。现有的结构化方法虽然使用各种启发式规则来捕获复杂的细胞间关系并增强原始测序数据，但往往忽视了生物先验知识。", "method": "DOGMA通过整合统计锚点、细胞本体和系统发育树重新定义图构建，并利用基因本体论弥合特征级语义差距。这种方法不仅提高了图表示的质量，还实现了确定性的结构发现和稳健的跨物种对齐。", "result": "在复杂的多物种和多组织基准测试中，DOGMA展示了最先进的性能，并且表现出更强的零样本鲁棒性和样本效率，在运行时具有显著更低的计算成本。", "conclusion": "通过使用多层次生物先验知识，DOGMA成功地解决了现有方法中的问题，提供了更高质量的图表示和更好的机器学习模型表现。"}}
{"id": "2602.01836", "pdf": "https://arxiv.org/pdf/2602.01836", "abs": "https://arxiv.org/abs/2602.01836", "authors": ["Yin Wu", "Daniel Slieter", "Carl Esselborn", "Ahmed Abouelazm", "Tsung Yuan Tseng", "J. Marius Zöllner"], "title": "Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery", "categories": ["cs.CV"], "comment": null, "summary": "Deploying ADAS and ADS across countries remains challenging due to differences in legislation, traffic infrastructure, and visual conventions, which introduce domain shifts that degrade perception performance. Traditional cross-country data collection relies on extensive on-road driving, making it costly and inefficient to identify representative locations. To address this, we propose a street-view-guided data acquisition strategy that leverages publicly available imagery to identify places of interest (POI). Two POI scoring methods are introduced: a KNN-based feature distance approach using a vision foundation model, and a visual-attribution approach using a vision-language model. To enable repeatable evaluation, we adopt a collect-detect protocol and construct a co-located dataset by pairing the Zenseact Open Dataset with Mapillary street-view images. Experiments on traffic sign detection, a task particularly sensitive to cross-country variations in sign appearance, show that our approach achieves performance comparable to random sampling while using only half of the target-domain data. We further provide cost estimations for full-country analysis, demonstrating that large-scale street-view processing remains economically feasible. These results highlight the potential of street-view-guided data acquisition for efficient and cost-effective cross-country model adaptation.", "AI": {"tldr": "提出了一种利用街景图像进行高效跨国家数据采集的策略，以改善ADAS和ADS部署中的感知性能。", "motivation": "由于各国立法、交通基础设施以及视觉惯例不同，导致域偏移从而影响感知性能。传统的跨境数据收集依赖于广泛的实地驾驶，成本高昂且效率低下。", "method": "提出了一种基于街景图像的数据采集策略，利用公开的街景图像来识别感兴趣的地方（POI）。提出了两种POI评分方法：一种是使用视觉基础模型的KNN特征距离法；另一种是采用视觉语言模型的可视属性分析法。通过构建配对数据集进行可重复性评估，并展示了大规模街景处理的成本估算。", "result": "实验结果表明，在交通标志检测任务中，该方法在仅使用一半的目标域数据情况下实现了与随机抽样相当的表现。", "conclusion": "研究表明，基于街景图像的数据采集策略可以在保证性能的同时大幅降低成本，对于跨国家模型适应具有重要应用价值。"}}
{"id": "2602.01834", "pdf": "https://arxiv.org/pdf/2602.01834", "abs": "https://arxiv.org/abs/2602.01834", "authors": ["Siqi Wen", "Shu Yang", "Shaopeng Fu", "Jingfeng Zhang", "Lijie Hu", "Di Wang"], "title": "Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models", "categories": ["cs.RO"], "comment": null, "summary": "Vision Language Action (VLA) models close the perception action loop by translating multimodal instructions into executable behaviors, but this very capability magnifies safety risks: jailbreaks that merely yield toxic text in LLMs can trigger unsafe physical actions in embodied systems. Existing defenses alignment, filtering, or prompt hardening intervene too late or at the wrong modality, leaving fused representations exploitable. We introduce a concept-based dictionary learning framework for inference-time safety control. By constructing sparse, interpretable dictionaries from hidden activations, our method identifies harmful concept directions and applies threshold-based interventions to suppress or block unsafe activations. Experiments on Libero-Harm, BadRobot, RoboPair, and IS-Bench show that our approach achieves state-of-the-art defense performance, cutting attack success rates by over 70\\% while maintaining task success. Crucially, the framework is plug-in and model-agnostic, requiring no retraining and integrating seamlessly with diverse VLAs. To our knowledge, this is the first inference-time concept-based safety method for embodied systems, advancing both interpretability and safe deployment of VLA models.", "AI": {"tldr": "本文提出了一种基于概念的字典学习框架，用于视觉语言行动模型的安全控制。", "motivation": "现有的安全防御方法在时间或模态上干预不当，无法有效阻止潜在危害。本文旨在通过提前识别并抑制有害概念方向来增强这些系统的安全性。", "method": "该方法利用隐含激活构建稀疏可解释字典，通过阈值干预策略抑制不安全的激活模式。", "result": "实验表明，此框架在Libero-Harm、BadRobot等数据集上显著减少了攻击成功率超过70%，同时保持了任务执行的成功率。", "conclusion": "本文提出的方法为视觉语言行动模型提供了首个基于概念的安全性控制方案，既提高了解释性又促进了这些系统的安全部署。"}}
{"id": "2602.01832", "pdf": "https://arxiv.org/pdf/2602.01832", "abs": "https://arxiv.org/abs/2602.01832", "authors": ["Rui Wang", "Yaoguang Cao", "Yuyi Chen", "Jianyi Xu", "Zhuoyang Li", "Jiachen Shang", "Shichun Yang"], "title": "Synesthesia of Vehicles: Tactile Data Synthesis from Visual Inputs", "categories": ["cs.AI"], "comment": null, "summary": "Autonomous vehicles (AVs) rely on multi-modal fusion for safety, but current visual and optical sensors fail to detect road-induced excitations which are critical for vehicles' dynamic control. Inspired by human synesthesia, we propose the Synesthesia of Vehicles (SoV), a novel framework to predict tactile excitations from visual inputs for autonomous vehicles. We develop a cross-modal spatiotemporal alignment method to address temporal and spatial disparities. Furthermore, a visual-tactile synesthetic (VTSyn) generative model using latent diffusion is proposed for unsupervised high-quality tactile data synthesis. A real-vehicle perception system collected a multi-modal dataset across diverse road and lighting conditions. Extensive experiments show that VTSyn outperforms existing models in temporal, frequency, and classification performance, enhancing AV safety through proactive tactile perception.", "AI": {"tldr": "本文提出了一种从视觉输入预测触觉兴奋的新框架Synesthesia of Vehicles (SoV)，以增强自动驾驶车辆的安全性。", "motivation": "当前的视觉和光学传感器无法检测到对车辆动态控制至关重要的路面激励，因此需要一种新的方法来解决这一问题。受人类联觉启发，提出了一种从视觉输入合成触觉数据的方法。", "method": "提出了跨模态时空对齐方法，并开发了使用潜在扩散的视觉-触觉联觉（VTSyn）生成模型，用于无监督地高质量触觉数据合成。", "result": "实验结果表明，VTSyn在时间、频率和分类性能上都优于现有模型，提高了自动驾驶车辆的安全性。", "conclusion": "通过预测路面激励，本方法可以增强自动驾驶车辆的动态控制能力与安全性。"}}
{"id": "2602.01826", "pdf": "https://arxiv.org/pdf/2602.01826", "abs": "https://arxiv.org/abs/2602.01826", "authors": ["Yaxiang Zhang", "Yingru Li", "Jiacai Liu", "Jiawei Xu", "Ziniu Li", "Qian Liu", "Haoyuan Li"], "title": "Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) for training Large Language Models is notoriously unstable. While recent studies attribute this to \"training inference mismatch stemming\" from inconsistent hybrid engines, standard remedies, such as Importance Sampling, might fail during extended training runs. In this work, we analyze this instability through the lens of optimization, demonstrating that gradient noise and training-inference mismatch escalate in tandem as training progresses. Meanwhile, we find that the mismatch can be effectively suppressed by shrinking the update size. Taken together, we deduce that the mismatch is not merely a static numerical discrepancy, but a dynamic failure coupled with the model's optimization. Based on this insight, we propose a simple yet effective solution: a specialized Learning Rate (LR) scheduler. Instead of pre-defined decay schedule in traditional LR scheduler, our method dynamically triggers LR decay based on response length, which we identify as a reliable early-warning signal for impending instability. Empirical evidence suggests that by reducing the learning rate as gradient noise rises, we can consistently stabilize RL training and keep the training-inference mismatch at a safe level.", "AI": {"tldr": "通过优化视角分析强化学习训练大型语言模型时的不稳定性，发现梯度噪声和训练-推理不匹配随时间增加，并提出一种基于响应长度动态调整学习率的方法来稳定训练。", "motivation": "近年来研究将大型语言模型的训练不稳定归咎于训练-推理不匹配问题。然而标准解决方案在长时间训练中可能失效，因此需要新的视角和方法解决这一挑战。", "method": "通过分析发现梯度噪声和训练-推理不匹配随时间增加，并提出一种基于响应长度动态调整学习率的方法来减少这种不匹配并稳定训练。", "result": "实验证明该方法能够有效降低梯度噪声，保持训练-推理不匹配在安全水平，从而提高模型的稳定性。", "conclusion": "研究证明了训练-推理不匹配不仅是静态数值差异，而是与优化过程紧密相关的问题。基于响应长度动态调整学习率是解决这一问题的有效策略。"}}
{"id": "2602.01824", "pdf": "https://arxiv.org/pdf/2602.01824", "abs": "https://arxiv.org/abs/2602.01824", "authors": ["Daniel Mwesigwa", "Steven J. Jackson", "Christopher Csikszentmihalyi"], "title": "Risk, Data, Alignment: Making Credit Scoring Work in Kenya", "categories": ["cs.HC", "cs.CY"], "comment": "Conditionally accepted to ACM CHI 2026, Barcelona, Spain", "summary": "Credit scoring is an increasingly central and contested domain of data and AI governance, frequently framed as a neutral and objective method of assessing risk across diverse economic and political contexts. Based on a nine-month ethnography of credit scoring practices in Nairobi, Kenya, we examined the sociotechnical and institutional work of data science in digital lending. While established regional telcos and banks are leveraging proprietary data to develop digital loan products, algorithmic credit scoring is being transformed by new actors, techniques, and shifting regulations. Our findings show how practitioners construct alternative data using technical and legal workarounds, formulate risk through multiple interpretations, and negotiate model performance via technical and political means. We argue that algorithmic credit scoring is accomplished through the ongoing work of alignment that stabilizes risk under conditions of persistent uncertainty, taking epistemic, modeling, and contextual forms. Extending work on alignment in HCI, we show how it operates as a two-way translation, where models are made \"safe for worlds\" while those worlds are reshaped to be \"safe for models.\"", "AI": {"tldr": "本文通过在肯尼亚内罗毕为期九个月的实地研究，探讨了数字借贷中信用评分实践的社会技术与机构工作。", "motivation": "基于对数据和技术治理日益重要且充满争议的认识，以及数字贷款产品的迅速发展，作者旨在深入了解新型参与者、技术和不断变化的监管如何改变算法信用评分的方式。", "method": "该研究采用了为期九个月的实地考察方法，在肯尼亚内罗毕探讨了数字借贷中的信用评分实践。通过技术和社会科学交叉的方法论框架来分析数据处理、风险评估及模型性能。", "result": "结果表明，从业者们使用技术和法律上的替代方案来创建不同的数据集，并且对如何定义和量化风险进行多种解释；同时他们还通过技术与政治手段调整模型的准确性。信用评分是持续不断的“对齐”过程的结果，在这种过程中，不确定性得到了稳定。", "conclusion": "本文展示了算法信用评分在面对持续不确定性的条件下是如何通过‘对齐’的工作来实现稳定的，并且揭示了这种工作如何作为双向翻译进行：一方面使模型适应世界，另一方面又将世界塑造成适合模型的形式。"}}
{"id": "2602.01816", "pdf": "https://arxiv.org/pdf/2602.01816", "abs": "https://arxiv.org/abs/2602.01816", "authors": ["Wenjin Hou", "Wei Liu", "Han Hu", "Xiaoxiao Sun", "Serena Yeung-Levy", "Hehe Fan"], "title": "Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable proficiency on general-purpose vision-language benchmarks, reaching or even exceeding human-level performance. However, these evaluations typically rely on standard in-distribution data, leaving the robustness of MLLMs largely unexamined when faced with scenarios that defy common-sense priors. To address this gap, we introduce VIA-Bench, a challenging benchmark designed to probe model performance on visual illusions and anomalies. It includes six core categories: color illusions, motion illusions, gestalt illusions, geometric and spatial illusions, general visual illusions, and visual anomalies. Through careful human-in-the-loop review, we construct over 1K high-quality question-answer pairs that require nuanced visual reasoning. Extensive evaluation of over 20 state-of-the-art MLLMs, including proprietary, open-source, and reasoning-enhanced models, uncovers significant vulnerabilities. Notably, we find that Chain-of-Thought (CoT) reasoning offers negligible robustness, often yielding ``brittle mirages'' where the model's logic collapses under illusory stimuli. Our findings reveal a fundamental divergence between machine and human perception, suggesting that resolving such perceptual bottlenecks is critical for the advancement of artificial general intelligence. The benchmark data and code will be released.", "AI": {"tldr": "本文介绍了一个新的基准测试VIA-Bench，用于评估多模态大型语言模型在视觉错觉和异常情况下的表现。", "motivation": "现有对多模态大模型的评价主要基于标准的数据集，这些数据集中包含了符合常识的情景。然而，在面对违背常识的视觉错觉或异常时，模型的表现如何尚不明确，因此需要一个专门评估这类情况的新基准测试。", "method": "通过构建包含六类共计1000多对高质量问题答案配对的数据集，进行详尽的人机互动审查后，该研究对多种不同的大语言模型进行了广泛的评测。同时探讨了链式思考推理方法在处理视觉错觉时的有效性。", "result": "实验结果揭示出当前的大规模多模态语言模型对于违背常识的视觉刺激表现脆弱，且传统的方法如链式思考推理并不能显著提高这些模型在这类任务上的鲁棒性。", "conclusion": "研究发现机器感知与人类感知之间存在根本性的差异，并指出解决这种感知瓶颈是推动人工通用智能发展的关键。"}}
{"id": "2602.01815", "pdf": "https://arxiv.org/pdf/2602.01815", "abs": "https://arxiv.org/abs/2602.01815", "authors": ["Yunhui Jang", "Seonghyun Park", "Jaehyung Kim", "Sungsoo Ahn"], "title": "INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.", "AI": {"tldr": "提出一种基于个体科学家特征的分子发现多智能体辩论系统INDIBATOR。", "motivation": "当前的多智能体框架通过角色或粗粒度关键词定义代理，未能准确模拟人类科学家的独特贡献。", "method": "构建基于出版历史和分子历史的精细个性化代理，以进行多轮辩论、提议、批评和投票。", "result": "实验表明，INDIBATOR在分子发现中优于依赖于粗粒度角色的系统，并达到了竞争或最佳性能。", "conclusion": "捕捉个体智能体的独特特征对于高质量科学发现至关重要。"}}
{"id": "2602.01814", "pdf": "https://arxiv.org/pdf/2602.01814", "abs": "https://arxiv.org/abs/2602.01814", "authors": ["Xiao Liang", "Yunzhu Zhang", "Linchao Zhu"], "title": "GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models have achieved remarkable success in video generation; however, the high computational cost of the denoising process remains a major bottleneck. Existing approaches have shown promise in reducing the number of diffusion steps, but they often suffer from significant quality degradation when applied to video generation. We propose Guided Progressive Distillation (GPD), a framework that accelerates the diffusion process for fast and high-quality video generation. GPD introduces a novel training strategy in which a teacher model progressively guides a student model to operate with larger step sizes. The framework consists of two key components: (1) an online-generated training target that reduces optimization difficulty while improving computational efficiency, and (2) frequency-domain constraints in the latent space that promote the preservation of fine-grained details and temporal dynamics. Applied to the Wan2.1 model, GPD reduces the number of sampling steps from 48 to 6 while maintaining competitive visual quality on VBench. Compared with existing distillation methods, GPD demonstrates clear advantages in both pipeline simplicity and quality preservation.", "AI": {"tldr": "提出了一种加速视频生成过程的框架GPD，通过引导模型逐步增加采样步长来提高效率和质量。", "motivation": "现有的扩散模型在视频生成中虽然取得了显著的成功，但其去噪过程的高计算成本仍然是一个瓶颈。减少采样步骤可以提升速度，但是通常会导致图像质量下降。", "method": "GPD框架通过在线生成训练目标来降低优化难度并提高计算效率，并且通过频率域约束保持细粒度细节和时间动态特性。该方法让教师模型逐步引导学生模型使用更大的步长。", "result": "应用于Wan2.1模型，GPD将采样步骤从48减少到6个，同时在VBench上维持了竞争力的视觉质量。相比现有的蒸馏方法，GPD展示了更简单的流程和更好的质量保持能力。", "conclusion": "GPD框架通过创新的训练策略提高了视频生成的速度和质量，在保证高质量的前提下大幅度减少了计算成本。"}}
{"id": "2602.01812", "pdf": "https://arxiv.org/pdf/2602.01812", "abs": "https://arxiv.org/abs/2602.01812", "authors": ["Cheng Wang", "Qiyu Gao", "Fandong Zhang", "Shu Zhang", "Yizhou Yu"], "title": "LDRNet: Large Deformation Registration Model for Chest CT Registration", "categories": ["cs.CV"], "comment": null, "summary": "Most of the deep learning based medical image registration algorithms focus on brain image registration tasks.Compared with brain registration, the chest CT registration has larger deformation, more complex background and region over-lap. In this paper, we propose a fast unsupervised deep learning method, LDRNet, for large deformation image registration of chest CT images. We first predict a coarse resolution registration field, then refine it from coarse to fine. We propose two innovative technical components: 1) a refine block that is used to refine the registration field in different resolutions, 2) a rigid block that is used to learn transformation matrix from high-level features. We train and evaluate our model on the private dataset and public dataset SegTHOR. We compare our performance with state-of-the-art traditional registration methods as well as deep learning registration models VoxelMorph, RCN, and LapIRN. The results demonstrate that our model achieves state-of-the-art performance for large deformation images registration and is much faster.", "AI": {"tldr": "提出了一种快速无监督深度学习方法LDRNet，用于胸部CT图像的大变形配准。", "motivation": "大多数基于深度学习的医学图像配准算法侧重于脑部图像配准任务。与大脑配准相比，胸部CT注册具有更大的形变、更复杂的背景和区域重叠。因此需要一种专门的方法来应对这些挑战。", "method": "首先预测一个低分辨率的配准场，然后从粗到细进行细化。提出了两个创新的技术组件：1）用于在不同分辨率下精炼配准场的refine块；2）用于从高层次特征中学习变换矩阵的rigid块。", "result": "在私人数据集和公共数据集SegTHOR上训练并评估了我们的模型，与最先进的传统注册方法以及深度学习注册模型VoxelMorph、RCN和LapIRN进行了比较。结果表明，该模型达到了大形变图像配准的最新性能，并且速度更快。", "conclusion": "提出的LDRNet在胸部CT的大变形配准任务上展示了优越的表现和更高的效率，证明了其在医疗影像领域的实用价值。"}}
{"id": "2602.01811", "pdf": "https://arxiv.org/pdf/2602.01811", "abs": "https://arxiv.org/abs/2602.01811", "authors": ["Wentao Zhang", "Aolan Sun", "Wentao Mo", "Xiaoyang Qu", "Yuxin Zheng", "Jianzong Wang"], "title": "From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models", "categories": ["cs.RO"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "While vision-language-action (VLA) models for embodied agents integrate perception, reasoning, and control, they remain constrained by two critical weaknesses: first, during grasping tasks, the action tokens generated by the language model often exhibit subtle spatial deviations from the target object, resulting in grasp failures; second, they lack the ability to reliably recognize task completion, which leads to redundant actions and frequent timeout errors. To address these challenges and enhance robustness, we propose a lightweight, training-free framework, VLA-SCT. This framework operates as a self-correcting control loop, combining data-driven action refinement with conditional logic for termination. Consequently, compared to baseline approaches, our method achieves consistent improvements across all datasets in the LIBERO benchmark, significantly increasing the success rate of fine manipulation tasks and ensuring accurate task completion, thereby promoting the deployment of more reliable VLA agents in complex, unstructured environments.", "AI": {"tldr": "提出了一种轻量级的无需训练的框架VLA-SCT，以解决视觉语言动作模型在抓取任务中的细微空间偏差和无法可靠识别任务完成的问题。", "motivation": "为了克服视觉语言动作模型在执行抓取任务时存在空间偏差和不能准确判断任务是否完成这两个关键弱点，作者提出了一种新的解决方案来提高这些模型的鲁棒性。", "method": "VLA-SCT框架通过结合数据驱动的动作优化与条件逻辑终止，形成自我校正控制循环，以解决上述问题。该方法无需训练即可实现对现有模型的有效改进。", "result": "实验表明，在LIBERO基准测试的所有数据集上，与基线方法相比，所提出的方法取得了持续的性能提升，显著提高了精细操作任务的成功率，并确保了准确的任务完成度。", "conclusion": "VLA-SCT框架通过自我校正控制循环有效提升了视觉语言动作模型在复杂无结构环境中的部署可靠性。"}}
{"id": "2602.01805", "pdf": "https://arxiv.org/pdf/2602.01805", "abs": "https://arxiv.org/abs/2602.01805", "authors": ["Menglin Han", "Zhangkai Ni"], "title": "FlowBypass: Rectified Flow Trajectory Bypass for Training-Free Image Editing", "categories": ["cs.CV"], "comment": null, "summary": "Training-free image editing has attracted increasing attention for its efficiency and independence from training data. However, existing approaches predominantly rely on inversion-reconstruction trajectories, which impose an inherent trade-off: longer trajectories accumulate errors and compromise fidelity, while shorter ones fail to ensure sufficient alignment with the edit prompt. Previous attempts to address this issue typically employ backbone-specific feature manipulations, limiting general applicability. To address these challenges, we propose FlowBypass, a novel and analytical framework grounded in Rectified Flow that constructs a bypass directly connecting inversion and reconstruction trajectories, thereby mitigating error accumulation without relying on feature manipulations. We provide a formal derivation of two trajectories, from which we obtain an approximate bypass formulation and its numerical solution, enabling seamless trajectory transitions. Extensive experiments demonstrate that FlowBypass consistently outperforms state-of-the-art image editing methods, achieving stronger prompt alignment while preserving high-fidelity details in irrelevant regions.", "AI": {"tldr": "本文提出了一种新的无训练图像编辑框架FlowBypass，通过构建一个直接连接逆向和重建轨迹的旁路来解决累积误差问题。", "motivation": "现有的图像编辑方法依赖于逆向重构路径，这会导致累积错误并降低保真度。现有方法试图通过特定主干特征操作解决这一问题，但限制了通用性。因此需要一种新的解决方案以提高效率和准确性。", "method": "FlowBypass基于校正流构建直接旁路，实现从逆向到重建的无缝过渡，并提供两个轨迹的形式派生及近似旁路公式及其数值解。", "result": "实验结果表明，FlowBypass在编辑提示对齐方面优于现有方法，同时保持无关区域的高保真细节。", "conclusion": "通过提出无训练图像编辑框架FlowBypass，解决累积误差问题并提高图像编辑质量。"}}
{"id": "2602.01801", "pdf": "https://arxiv.org/pdf/2602.01801", "abs": "https://arxiv.org/abs/2602.01801", "authors": ["Dvir Samuel", "Issar Tzachor", "Matan Levy", "Micahel Green", "Gal Chechik", "Rami Ben-Ari"], "title": "Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention", "categories": ["cs.CV", "cs.AI"], "comment": "Project Page: https://dvirsamuel.github.io/fast-auto-regressive-video/", "summary": "Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.", "AI": {"tldr": "该论文提出了一种新的注意力框架，用于解决自回归视频扩散模型中的瓶颈问题。", "motivation": "自回归视频扩散模型在生成过程中由于KV缓存的增长导致了延迟和内存消耗的增加，这限制了可用的时间上下文并损害了长距离的一致性。因此需要一种新方法来减少这些限制。", "method": "该论文提出了一个统一、无训练需求的注意力框架：通过时间对应压缩KV缓存以限制缓存增长；使用快速近似最近邻匹配选择与帧相关的提示令牌以加速交叉注意力；以及使用轻量级ANN仅允许查询和语义匹配的关键点来稀疏自注意力。", "result": "实验表明，该方法可以实现端到端的速度提升达5-10倍，同时保持几乎相同视觉质量，并且在长时间的运行过程中能够维持稳定的吞吐率和近似恒定的峰值GPU内存使用量。", "conclusion": "提出的框架通过减少注意力、计算和内存的需求，在保证视频合成质量和稳定性的前提下显著提高了自回归视频扩散模型的生成效率。"}}
{"id": "2602.01799", "pdf": "https://arxiv.org/pdf/2602.01799", "abs": "https://arxiv.org/abs/2602.01799", "authors": ["Ido Faran", "Nathan S. Netanyahu", "Maxim Shoshany"], "title": "Spatio-Temporal Transformers for Long-Term NDVI Forecasting", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Long-term satellite image time series (SITS) analysis in heterogeneous landscapes faces significant challenges, particularly in Mediterranean regions where complex spatial patterns, seasonal variations, and multi-decade environmental changes interact across different scales. This paper presents the Spatio-Temporal Transformer for Long Term Forecasting (STT-LTF ), an extended framework that advances beyond purely temporal analysis to integrate spatial context modeling with temporal sequence prediction. STT-LTF processes multi-scale spatial patches alongside temporal sequences (up to 20 years) through a unified transformer architecture, capturing both local neighborhood relationships and regional climate influences. The framework employs comprehensive self-supervised learning with spatial masking, temporal masking, and horizon sampling strategies, enabling robust model training from 40 years of unlabeled Landsat imagery. Unlike autoregressive approaches, STT-LTF directly predicts arbitrary future time points without error accumulation, incorporating spatial patch embeddings, cyclical temporal encoding, and geographic coordinates to learn complex dependencies across heterogeneous Mediterranean ecosystems. Experimental evaluation on Landsat data (1984-2024) demonstrates that STT-LTF achieves a Mean Absolute Error (MAE) of 0.0328 and R^2 of 0.8412 for next-year predictions, outperforming traditional statistical methods, CNN-based approaches, LSTM networks, and standard transformers. The framework's ability to handle irregular temporal sampling and variable prediction horizons makes it particularly suitable for analysis of heterogeneous landscapes experiencing rapid ecological transitions.", "AI": {"tldr": "本文提出了一种用于长期NDVI预测的时空变换器（STT-LTF）框架，该框架能够处理多尺度空间补丁和长达20年的时间序列数据。", "motivation": "在异质景观特别是地中海地区的长期卫星图像时序分析面临挑战。传统方法如自回归模型存在误差积累问题，而STT-LTF通过集成空间上下文建模与时间序列预测来改进这些局限性。", "method": "STT-LTF利用统一的变换器架构处理多尺度的空间补丁和长时间序列数据，结合全面的自我监督学习策略（如空间掩码、时间掩码和采样策略）从40年的未标记Landsat图像中进行鲁棒训练。该模型直接预测未来任意时刻点而无需误差积累。", "result": "实验结果表明STT-LTF在下一财年预测中的MAE为0.0328，R^2达到0.8412，优于传统的统计方法、CNN和LSTM网络以及标准变换器模型。该框架能够处理不规则的时间采样和可变的预测时长。", "conclusion": "STT-LTF通过整合空间上下文建模与时间序列预测的能力，显著提高了长期NDVI预测的准确性，特别适合快速生态转型地区的异质景观分析。"}}
{"id": "2602.01797", "pdf": "https://arxiv.org/pdf/2602.01797", "abs": "https://arxiv.org/abs/2602.01797", "authors": ["Hanlin Zhou", "Huah Yong Chan"], "title": "ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision'' paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.", "AI": {"tldr": "提出了一种确定性的多代理协调框架ORCH，用于离散选择推理。", "motivation": "许多现有系统依赖于随机路由或临时启发式方法，导致行为难以复制和决策过程难以解释。因此，提出了一个固定规则的协调框架来解决这些问题。", "method": "ORCH采用“多个分析，一次决定”的模式：多个基础模型独立生成结构化分析，专用合并代理输出最终选择。它使用固定的任务分解和答案聚合规则以保持管道可预测、可重现且无需训练。还引入了一个EMA指导的路由器来利用模型之间的互补性。", "result": "实验结果表明，ORCH在MMLU、MMLU-Pro和GSM8K数据集上均优于单个模型基线和多数投票集成。特别是在MMLU-Pro中，准确性提高了10个百分点以上，在GSM8K中提高了50多个点。", "conclusion": "总体而言，ORCH提供了一种实用的路径，可以实现可控、可解释且适用于离散选择推理任务的部署就绪型LLM代理系统。"}}
{"id": "2602.01796", "pdf": "https://arxiv.org/pdf/2602.01796", "abs": "https://arxiv.org/abs/2602.01796", "authors": ["Xiaojiao Chen", "Jiahuan Zhou", "Yunfeng Shu", "Ruihan Wang", "Qinghua Liu"], "title": "CritiqueCrew: Orchestrating Multi-Perspective Conversational Design Critique", "categories": ["cs.HC"], "comment": "20 pages, 10 figures; Accepted to CHI 2026", "summary": "UI designers face growing cognitive load and cross functional friction at the intersection of user needs, business goals, and engineering constraints. Existing automated tools often deliver static \"problem lists\", lacking actionable repair paths and disrupting creative flow. We introduce CritiqueCrew, a Figma tool that supports designers through conversational critique. CritiqueCrew generates multi-faceted insights by implementing a multi-perspective orchestration of distinct expert roles (UX, PM, Engineer). It translates abstract critiques into concrete actions via in context feedback and interactive remediation. Across two independent controlled studies (Total N=48), CritiqueCrew significantly improved both design quality and subjective experience compared to a traditional static checker. Furthermore, our results confirm that the structured orchestration of expert roles-rather than a unified model-is key to fostering trust and creativity support. Our work demonstrates how AI can shift from a \"problem auditor\" to a \"solution co-creator\" by integrating multi-perspective dialogue with interactive repair, offering design implications for future creative tools.", "AI": {"tldr": "介绍了一个名为CritiqueCrew的设计工具，该工具通过多角度对话支持设计师进行交互式修复。", "motivation": "UI设计师面临的认知负荷和跨功能摩擦日益增加。现有自动化工具提供的静态问题列表缺乏具体的改进方案，并可能打断创造力的流畅性。", "method": "提出了一种名为CritiqueCrew的新Figma工具，该工具通过实施多角度对话来生成多维度见解，整合了不同的专家角色（UX、PM、工程师），并提供具体反馈和修复建议。通过两个独立控制的研究验证其有效性。", "result": "在两项独立研究中，使用CritiqueCrew的设计质量和主观体验都有显著提升，表明结构化的多角度对话对建立信任和支持创意至关重要。", "conclusion": "证明了AI可以通过整合多视角对话与交互修复从问题审计者转变为解决方案共同创造者的潜力。"}}
{"id": "2602.01795", "pdf": "https://arxiv.org/pdf/2602.01795", "abs": "https://arxiv.org/abs/2602.01795", "authors": ["Mingrui Liu", "Sixiao Zhang", "Cheng Long", "Kwok-Yan Lam"], "title": "RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "under review", "summary": "Large Language Models (LLMs) are increasingly vulnerable to Prompt Injection (PI) attacks, where adversarial instructions hidden within retrieved contexts hijack the model's execution flow. Current defenses typically face a critical trade-off: prevention-based fine-tuning often degrades general utility via the \"alignment tax\", while detection-based filtering incurs prohibitive latency and memory costs. To bridge this gap, we propose RedVisor, a unified framework that synthesizes the explainability of detection systems with the seamless integration of prevention strategies. To the best of our knowledge, RedVisor is the first approach to leverage fine-grained reasoning paths to simultaneously detect attacks and guide the model's safe response. We implement this via a lightweight, removable adapter positioned atop the frozen backbone. This adapter serves a dual function: it first generates an explainable analysis that precisely localizes the injection and articulates the threat, which then explicitly conditions the model to reject the malicious command. Uniquely, the adapter is active only during this reasoning phase and is effectively muted during the subsequent response generation. This architecture yields two distinct advantages: (1) it mathematically preserves the backbone's original utility on benign inputs; and (2) it enables a novel KV Cache Reuse strategy, eliminating the redundant prefill computation inherent to decoupled pipelines. We further pioneer the integration of this defense into the vLLM serving engine with custom kernels. Experiments demonstrate that RedVisor outperforms state-of-the-art defenses in detection accuracy and throughput while incurring negligible utility loss.", "AI": {"tldr": "提出了一种新的防御Prompt Injection攻击的方法RedVisor，通过零拷贝KV缓存复用来同时检测和防止攻击。", "motivation": "当前的防护方法在实用性和安全性之间存在权衡：预防性微调会降低模型的一般性能，而基于检测的方法则会导致延迟和内存消耗增加。因此，需要一种既能提高安全性又能保持低开销的方法。", "method": "RedVisor通过一个轻量级、可移除的适配器来实现这一目标。该适配器能够生成解释性分析以精确定位注入并明确条件化模型拒绝恶意指令，并且它只在推理阶段激活，在响应生成时被有效屏蔽，从而保持原始性能。", "result": "实验表明RedVisor在检测准确性和吞吐量方面优于现有的最先进方法，同时几乎不损失实用性能。", "conclusion": "RedVisor提供了一种创新的方法来防御Prompt Injection攻击，通过零拷贝KV缓存复用来提高效率和安全性。"}}
{"id": "2602.01793", "pdf": "https://arxiv.org/pdf/2602.01793", "abs": "https://arxiv.org/abs/2602.01793", "authors": ["Fei Liu", "Yang Ai"], "title": "ParaGSE: Parallel Generative Speech Enhancement with Group-Vector-Quantization-based Neural Speech Codec", "categories": ["cs.SD"], "comment": "Accepted by ICASSP 2026", "summary": "Recently, generative speech enhancement has garnered considerable interest; however, existing approaches are hindered by excessive complexity, limited efficiency, and suboptimal speech quality. To overcome these challenges, this paper proposes a novel parallel generative speech enhancement (ParaGSE) framework that leverages a group vector quantization (GVQ)-based neural speech codec. The GVQ-based codec adopts separate VQs to produce mutually independent tokens, enabling efficient parallel token prediction in ParaGSE. Specifically, ParaGSE leverages the GVQ-based codec to encode degraded speech into distinct tokens, predicts the corresponding clean tokens through parallel branches conditioned on degraded spectral features, and ultimately reconstructs clean speech via the codec decoder. Experimental results demonstrate that ParaGSE consistently produces superior enhanced speech compared to both discriminative and generative baselines, under a wide range of distortions including noise, reverberation, band-limiting, and their mixtures. Furthermore, empowered by parallel computation in token prediction, ParaGSE attains about a 1.5-fold improvement in generation efficiency on CPU compared with serial generative speech enhancement approaches.", "AI": {"tldr": "本文提出了一种基于组向量量化神经语音编码器的并行生成式语音增强框架（ParaGSE）。", "motivation": "现有方法存在复杂度高、效率低和语音质量不理想的问题，因此提出了新型平行生成式语音增强框架以克服这些挑战。", "method": "该框架利用GVQ基神经语音编码器将降质语音分解为独立令牌，通过多个分支并行预测清洁令牌，并最终使用解码器重建清洁语音。", "result": "实验结果表明ParaGSE在各类失真条件下（噪声、回声、频带限制及其组合）均优于判别和生成基线方法；同时并行计算使生成效率提升约1.5倍。", "conclusion": "ParaGSE框架通过结合GVQ编码器和并行令牌预测实现了高效且高质量的语音增强，具有广泛应用前景。"}}
{"id": "2602.01789", "pdf": "https://arxiv.org/pdf/2602.01789", "abs": "https://arxiv.org/abs/2602.01789", "authors": ["Entong Su", "Tyler Westenbroek", "Anusha Nagabandi", "Abhishek Gupta"], "title": "RFS: Reinforcement learning with Residual flow steering for dexterous manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Imitation learning has emerged as an effective approach for bootstrapping sequential decision-making in robotics, achieving strong performance even in high-dimensional dexterous manipulation tasks. Recent behavior cloning methods further leverage expressive generative models, such as diffusion models and flow matching, to represent multimodal action distributions. However, policies pretrained in this manner often exhibit limited generalization and require additional fine-tuning to achieve robust performance at deployment time. Such adaptation must preserve the global exploration benefits of pretraining while enabling rapid correction of local execution errors. We propose Residual Flow Steering(RFS), a data-efficient reinforcement learning framework for adapting pretrained generative policies. RFS steers a pretrained flow-matching policy by jointly optimizing a residual action and a latent noise distribution, enabling complementary forms of exploration: local refinement through residual corrections and global exploration through latent-space modulation. This design allows efficient adaptation while retaining the expressive structure of the pretrained policy. We demonstrate the effectiveness of RFS on dexterous manipulation tasks, showing efficient fine-tuning in both simulation and real-world settings when adapting pretrained base policies. Project website:https://weirdlabuw.github.io/rfs.", "AI": {"tldr": "该论文提出了一种名为残差流引导（RFS）的数据高效强化学习框架，用于适应预训练的生成策略。", "motivation": "传统的模仿学习方法在机器人顺序决策方面表现良好，但所预训练的政策经常表现出有限的泛化能力，需要额外的微调才能实现稳健性能。这种调整必须保留预训练的全局探索利益，同时启用局部执行错误的快速纠正。", "method": "RFS通过联合优化残差动作和潜在噪声分布来引导预训练流匹配策略，允许互补形式的探索：通过残差修正进行局部精炼以及通过潜在空间调制进行全球探索。此设计使得高效调整成为可能，同时保留了预训练政策的表现力结构。", "result": "在灵巧操作任务中展示了RFS的有效性，在模拟和现实世界设置中适应预训练基本策略时表现出高效的微调性能。", "conclusion": "RFS框架通过联合优化残差动作和潜在噪声分布，为强化学习提供了新的解决方案，提高了预训练政策的适应性和泛化能力。"}}
{"id": "2602.01783", "pdf": "https://arxiv.org/pdf/2602.01783", "abs": "https://arxiv.org/abs/2602.01783", "authors": ["Dibyayan Patra", "Pasindu Ranasinghe", "Bikram Banerjee", "Simit Raval"], "title": "Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation", "categories": ["cs.CV"], "comment": ":I.4.9", "summary": "Characterisation of structural discontinuity sets in exposed rock faces of underground mine cavities is essential for assessing rock-mass stability, excavation safety, and operational efficiency. UAV and other mobile laser-scanning techniques provide efficient means of collecting point clouds from rock faces. However, the development of a robust and efficient approach for automatic characterisation of discontinuity sets in real-world scenarios, like fully enclosed rock faces in cavities, remains an open research problem. In this study, a new approach is proposed for automatic discontinuity set characterisation that uses a single-shot filtering strategy, an innovative cyclic orientation transformation scheme and a hierarchical clustering technique. The single-shot filtering step isolates planar regions while robustly suppressing noise and high-curvature artefacts in one pass using a signal-processing technique. To address the limitations of Cartesian clustering on polar orientation data, a cyclic orientation transformation scheme is developed, enabling accurate representation of dip angle and dip direction in Cartesian space. The transformed orientations are then characterised into sets using a hierarchical clustering technique, which handles varying density distributions and identifies clusters without requiring user-defined set numbers. The accuracy of the method is validated on real-world mine stope and against ground truth obtained using manually handpicked discontinuity planes identified with the Virtual Compass tool, as well as widely used automated structure mapping techniques. The proposed approach outperforms the other techniques by exhibiting the lowest mean absolute error in estimating discontinuity set orientations in real-world stope data with errors of 1.95° and 2.20° in nominal dip angle and dip direction, respectively, and dispersion errors lying below 3°.", "AI": {"tldr": "提出了一种自动化的断层集特征识别方法，使用单次滤波策略、创新的循环定向转换方案和分层聚类技术。", "motivation": "评估岩石稳定性、挖掘安全性和操作效率需要对地下矿山腔内部暴露岩石表面进行结构断层面集合的特性化。然而，在完全封闭的岩面上实现自动断层集识别仍然是一项开放的研究问题。", "method": "该方法使用单次滤波策略从点云中分离出平面区域，同时抑制噪声和高曲率伪影；开发了一个循环定向转换方案以准确表示倾斜角度和方向，并将其转化为笛卡尔空间进行处理；最后应用分层聚类技术识别断层面集合。", "result": "与手动选择的地面真实数据相比，该方法在实际矿石坑中的倾角和倾向误差分别为1.95°和2.20°，低于3°。", "conclusion": "新提出的方法比其他自动结构映射技术具有更低的估算断层集方向误差，在评估地下矿山岩体稳定性方面表现出色。"}}
{"id": "2602.01780", "pdf": "https://arxiv.org/pdf/2602.01780", "abs": "https://arxiv.org/abs/2602.01780", "authors": ["Shicheng Yin", "Kaixuan Yin", "Weixing Chen", "Yang Liu", "Guanbin Li", "Liang Lin"], "title": "DDP-WM: Disentangled Dynamics Prediction for Efficient World Models", "categories": ["cs.CV", "cs.RO"], "comment": "Codes will be available at https://github.com/HCPLab-SYSU/DDP-WM", "summary": "World models are essential for autonomous robotic planning. However, the substantial computational overhead of existing dense Transformerbased models significantly hinders real-time deployment. To address this efficiency-performance bottleneck, we introduce DDP-WM, a novel world model centered on the principle of Disentangled Dynamics Prediction (DDP). We hypothesize that latent state evolution in observed scenes is heterogeneous and can be decomposed into sparse primary dynamics driven by physical interactions and secondary context-driven background updates. DDP-WM realizes this decomposition through an architecture that integrates efficient historical processing with dynamic localization to isolate primary dynamics. By employing a crossattention mechanism for background updates, the framework optimizes resource allocation and provides a smooth optimization landscape for planners. Extensive experiments demonstrate that DDP-WM achieves significant efficiency and performance across diverse tasks, including navigation, precise tabletop manipulation, and complex deformable or multi-body interactions. Specifically, on the challenging Push-T task, DDP-WM achieves an approximately 9 times inference speedup and improves the MPC success rate from 90% to98% compared to state-of-the-art dense models. The results establish a promising path for developing efficient, high-fidelity world models. Codes will be available at https://github.com/HCPLab-SYSU/DDP-WM.", "AI": {"tldr": "提出了一种新的世界模型DDP-WM，通过分解场景中的动态过程来提高效率和性能。", "motivation": "现有基于Transformer的世界模型存在计算开销大、难以实时部署的问题。为了克服这一瓶颈，提出了DDP-WM。", "method": "采用解耦动力学预测的方法，将物理互动驱动的主要动力学与背景更新分开处理，并通过动态定位和交叉注意力机制优化资源分配。", "result": "在导航、精密桌面操作等任务中取得了显著的效率提升和性能改进。例如，在Push-T任务上实现了约9倍的推理速度加快，成功率为98%。", "conclusion": "DDP-WM为开发高效高保真世界模型提供了可行路径，并且代码将公开分享。"}}
{"id": "2602.01779", "pdf": "https://arxiv.org/pdf/2602.01779", "abs": "https://arxiv.org/abs/2602.01779", "authors": ["Rui Hua", "Yu Wei", "Zixin Shu", "Kai Chang", "Dengying Yan", "Jianan Xia", "Zeyu Liu", "Hui Zhu", "Shujie Song", "Mingzhong Xiao", "Xiaodong Li", "Dongmei Jia", "Zhuye Gao", "Yanyan Meng", "Naixuan Zhao", "Yu Fu", "Haibin Yu", "Benman Yu", "Yuanyuan Chen", "Fei Dong", "Zhizhou Meng", "Pengcheng Yang", "Songxue Zhao", "Lijuan Pei", "Yunhui Hu", "et al. (11 additional authors not shown)"], "title": "LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are advancing rapidly in medical NLP, yet Traditional Chinese Medicine (TCM) with its distinctive ontology, terminology, and reasoning patterns requires domain-faithful evaluation. Existing TCM benchmarks are fragmented in coverage and scale and rely on non-unified or generation-heavy scoring that hinders fair comparison. We present the LingLanMiDian (LingLan) benchmark, a large-scale, expert-curated, multi-task suite that unifies evaluation across knowledge recall, multi-hop reasoning, information extraction, and real-world clinical decision-making. LingLan introduces a consistent metric design, a synonym-tolerant protocol for clinical labels, a per-dataset 400-item Hard subset, and a reframing of diagnosis and treatment recommendation into single-choice decision recognition. We conduct comprehensive, zero-shot evaluations on 14 leading open-source and proprietary LLMs, providing a unified perspective on their strengths and limitations in TCM commonsense knowledge understanding, reasoning, and clinical decision support; critically, the evaluation on Hard subset reveals a substantial gap between current models and human experts in TCM-specialized reasoning. By bridging fundamental knowledge and applied reasoning through standardized evaluation, LingLan establishes a unified, quantitative, and extensible foundation for advancing TCM LLMs and domain-specific medical AI research. All evaluation data and code are available at https://github.com/TCMAI-BJTU/LingLan and http://tcmnlp.com.", "AI": {"tldr": "构建并评估了一个大规模、多任务的中医知识和临床推理基准LingLanMiDian，以系统性地评价大型语言模型在传统中医学领域的性能。", "motivation": "当前中医药领域缺乏统一且全面的测评标准，现有的中医药基准测试范围有限，难以进行公平比较。因此，需要一个大规模、多任务的标准化评估框架来准确衡量大型语言模型在中医知识和临床推理方面的能力。", "method": "开发了一套包含知识召回、跨步推理、信息抽取以及现实世界临床决策支持的大规模专家编写的多任务基准测试LingLanMiDian。引入了统一的评分机制，对于临床标签采用了同义词容忍协议，并提供了一个每个数据集400个难题的Hard子集。", "result": "对14种领先的开源和专有大型语言模型进行了综合零样本评估，揭示了这些模型在中医常识理解、推理以及临床决策支持方面的优势与不足。特别是在困难子集中表现出了当前模型与人类专家之间存在显著差距的问题。", "conclusion": "通过标准化的基准测试框架，LingLanMiDian建立了统一、可量化且可扩展的基础平台来推动中医药大型语言模型和领域特定医疗AI研究的发展。"}}
{"id": "2602.01777", "pdf": "https://arxiv.org/pdf/2602.01777", "abs": "https://arxiv.org/abs/2602.01777", "authors": ["M. Arashi", "M. Amintoosi"], "title": "Stein-Rule Shrinkage for Stochastic Gradient Estimation in High Dimensions", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML"], "comment": null, "summary": "Stochastic gradient methods are central to large-scale learning, yet their analysis typically treats mini-batch gradients as unbiased estimators of the population gradient. In high-dimensional settings, however, classical results from statistical decision theory show that unbiased estimators are generally inadmissible under quadratic loss, suggesting that standard stochastic gradients may be suboptimal from a risk perspective. In this work, we formulate stochastic gradient computation as a high-dimensional estimation problem and introduce a decision-theoretic framework based on Stein-rule shrinkage. We construct a shrinkage gradient estimator that adaptively contracts noisy mini-batch gradients toward a stable restricted estimator derived from historical momentum. The shrinkage intensity is determined in a data-driven manner using an online estimate of gradient noise variance, leveraging second-moment statistics commonly maintained by adaptive optimization methods. Under a Gaussian noise model and for dimension p>=3, we show that the proposed estimator uniformly dominates the standard stochastic gradient under squared error loss and is minimax-optimal in the classical decision-theoretic sense. We further demonstrate how this estimator can be incorporated into the Adam optimizer, yielding a practical algorithm with negligible additional computational cost. Empirical evaluations on CIFAR10 and CIFAR100, across multiple levels of label noise, show consistent improvements over Adam in the large-batch regime. Ablation studies indicate that the gains arise primarily from selectively applying shrinkage to high-dimensional convolutional layers, while indiscriminate shrinkage across all parameters degrades performance. These results illustrate that classical shrinkage principles provide a principled and effective approach to improving stochastic gradient estimation in modern deep learning.", "AI": {"tldr": "本文提出了一种基于Stein规则收缩的随机梯度估计方法，以提高高维设置下深度学习中的随机梯度估算。", "motivation": "在大型学习中，传统的随机梯度方法通常将小批量梯度视为无偏估计器。但在高维度情景下，统计决策理论表明无偏估计算法可能不是最优解，从而提出使用Stein规则收缩来改进随机梯度估算。", "method": "本文提出了一个基于历史动量导出的稳定受限估计器，并通过数据驱动的方式决定收缩强度，以构建收缩梯度估计器。该方法可以适应性地将噪声小批量梯度向稳定性更强的限制估计器收敛。", "result": "实验结果表明，在大型批次设置下，所提出的方法在CIFAR10和CIFAR100数据集上均优于Adam优化算法，并且主要改进源于高维卷积层的选择性收缩。", "conclusion": "本文提出的Stein规则收缩方法提供了一种原则性的有效方式来提高深度学习中的随机梯度估计，展示了古典收缩原理在现代深度学习中的实际价值。"}}
{"id": "2602.01775", "pdf": "https://arxiv.org/pdf/2602.01775", "abs": "https://arxiv.org/abs/2602.01775", "authors": ["Yucheng Wu", "Yuekui Yang", "Hongzheng Li", "Anan Liu", "Jian Xiao", "Junjie Zhai", "Huan Yu", "Shaoping Ma", "Leye Wang"], "title": "Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User Response Prediction", "categories": ["cs.AI", "cs.LG"], "comment": "15 pages", "summary": "Deploying new architectures in large-scale user response prediction systems incurs high model switching costs due to expensive retraining on massive historical data and performance degradation under data retention constraints. Existing knowledge distillation methods struggle with architectural heterogeneity and the prohibitive cost of transferring large embedding tables. We propose CrossAdapt, a two-stage framework for efficient cross-architecture knowledge transfer. The offline stage enables rapid embedding transfer via dimension-adaptive projections without iterative training, combined with progressive network distillation and strategic sampling to reduce computational cost. The online stage introduces asymmetric co-distillation, where students update frequently while teachers update infrequently, together with a distribution-aware adaptation mechanism that dynamically balances historical knowledge preservation and fast adaptation to evolving data. Experiments on three public datasets show that CrossAdapt achieves 0.27-0.43% AUC improvements while reducing training time by 43-71%. Large-scale deployment on Tencent WeChat Channels (~10M daily samples) further demonstrates its effectiveness, significantly mitigating AUC degradation, LogLoss increase, and prediction bias compared to standard distillation baselines.", "AI": {"tldr": "提出了一种高效的跨架构知识转移框架CrossAdapt，用于大规模在线用户响应预测。", "motivation": "部署新架构在大型系统中导致高昂的模型切换成本和性能下降，现有方法难以处理异构架构以及大规模嵌入表迁移的成本问题。", "method": "CrossAdapt采用两阶段框架：离线阶段通过自适应维度投影快速转移嵌入，并结合渐进网络蒸馏与策略采样减少计算负担；在线阶段引入非对称共蒸馏机制，动态平衡历史知识保留和数据演化的快速适应性。", "result": "在三个公开数据集上验证CrossAdapt的性能优于标准方法0.27-0.43% AUC改进，并大幅缩短训练时间。大规模实证测试显示其显著减少AUC降级、LogLoss增加及预测偏差。", "conclusion": "CrossAdapt提供了一种有效的跨架构知识转移策略，可应用于大规模用户响应预测系统，以提高模型效率和性能稳定性。"}}
{"id": "2602.01774", "pdf": "https://arxiv.org/pdf/2602.01774", "abs": "https://arxiv.org/abs/2602.01774", "authors": ["Thomas Langerak", "Renate Zhang", "Ziyuan Wang", "Per Ola Kristensson", "Antti Oulasvirta"], "title": "Cost-Aware Bayesian Optimization for Prototyping Interactive Devices", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Deciding which idea is worth prototyping is a central concern in iterative design. A prototype should be produced when the expected improvement is high and the cost is low. However, this is hard to decide, because costs can vary drastically: a simple parameter tweak may take seconds, while fabricating hardware consumes material and energy. Such asymmetries, can discourage a designer from exploring the design space. In this paper, we present an extension of cost-aware Bayesian optimization to account for diverse prototyping costs. The method builds on the power of Bayesian optimization and requires only a minimal modification to the acquisition function. The key idea is to use designer-estimated costs to guide sampling toward more cost-effective prototypes. In technical evaluations, the method achieved comparable utility to a cost-agnostic baseline while requiring only ${\\approx}70\\%$ of the cost; under strict budgets, it outperformed the baseline threefold. A within-subjects study with 12 participants in a realistic joystick design task demonstrated similar benefits. These results show that accounting for prototyping costs can make Bayesian optimization more compatible with real-world design projects.", "AI": {"tldr": "该论文提出了一种考虑原型成本的贝叶斯优化方法，以帮助设计师在迭代设计中决定哪些想法值得实现。", "motivation": "由于不同的原型制作成本可能相差巨大，这使得设计师难以确定哪个设计方案更具有探索价值。因此，作者希望通过一种新的优化策略来平衡预期改进和实际成本之间的关系。", "method": "该方法通过将设计师估算的成本纳入获取函数中以指导采样过程，从而向更具成本效益的原型倾斜，并以此为基础进行了扩展。", "result": "在技术评估中，此方法达到了与不考虑成本的基础线相当的效用水平，但仅消耗了约70%的成本；而在严格的预算限制下，其表现优于基础线三倍。", "conclusion": "研究结果表明，将原型制作成本纳入考量可以使得贝叶斯优化更加适合于实际设计项目，并且在现实中的摇杆设计任务中也显示出类似的益处。"}}
{"id": "2602.01772", "pdf": "https://arxiv.org/pdf/2602.01772", "abs": "https://arxiv.org/abs/2602.01772", "authors": ["Yucheng Liao", "Han Wen", "Weinan E", "Weijie Zhang"], "title": "DIA-CLIP: a universal representation learning framework for zero-shot DIA proteomics", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "21 pages, 5 figures", "summary": "Data-independent acquisition mass spectrometry (DIA-MS) has established itself as a cornerstone of proteomic profiling and large-scale systems biology, offering unparalleled depth and reproducibility. Current DIA analysis frameworks, however, require semi-supervised training within each run for peptide-spectrum match (PSM) re-scoring. This approach is prone to overfitting and lacks generalizability across diverse species and experimental conditions. Here, we present DIA-CLIP, a pre-trained model shifting the DIA analysis paradigm from semi-supervised training to universal cross-modal representation learning. By integrating dual-encoder contrastive learning framework with encoder-decoder architecture, DIA-CLIP establishes a unified cross-modal representation for peptides and corresponding spectral features, achieving high-precision, zero-shot PSM inference. Extensive evaluations across diverse benchmarks demonstrate that DIA-CLIP consistently outperforms state-of-the-art tools, yielding up to a 45% increase in protein identification while achieving a 12% reduction in entrapment identifications. Moreover, DIA-CLIP holds immense potential for diverse practical applications, such as single-cell and spatial proteomics, where its enhanced identification depth facilitates the discovery of novel biomarkers and the elucidates of intricate cellular mechanisms.", "AI": {"tldr": "构建一种通用的表示学习框架DIA-CLIP，用于零样本数据独立采集质谱分析中的肽谱匹配（PSM）推断。", "motivation": "当前的数据独立采集质谱分析方法依赖于半监督训练，容易过拟合且不具备跨物种和实验条件的一般性。因此，需要一种新的框架来提高蛋白质识别的精度和深度，并减少误识别。", "method": "DIA-CLIP采用双编码器对比学习框架结合编码解码架构，建立肽序列与光谱特征之间的通用表示模型，从而实现零样本条件下高精度PSM推断。", "result": "在多个基准测试中，DIA-CLIP显著优于现有工具，在蛋白质识别上提高了45％，同时降低了12%的误识率。展示了其在单细胞和空间蛋白组学等领域的巨大应用潜力。", "conclusion": "通过采用预训练模型，从半监督学习转向通用跨模态表示学习，DIA-CLIP成功解决了传统方法中的局限性问题，并为复杂生物样本中新型生物标志物的发现提供了有力工具。"}}
{"id": "2602.01771", "pdf": "https://arxiv.org/pdf/2602.01771", "abs": "https://arxiv.org/abs/2602.01771", "authors": ["Jingyao Wu", "Bin Lu", "Zijun Di", "Xiaoying Gan", "Meng Jin", "Luoyi Fu", "Xinbing Wang", "Chenghu Zhou"], "title": "<SOG_k>: One LLM Token for Explicit Graph Structural Understanding", "categories": ["cs.CL", "cs.AI", "cs.NI"], "comment": null, "summary": "Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.", "AI": {"tldr": "提出了一种新的方法，通过引入特殊令牌<SOG_k>来解决大型语言模型在理解图形结构时遇到的问题。", "motivation": "现有的图处理方法要么过度消耗令牌和注意力，要么与原始文本令牌不匹配。为了提高对图形的明确理解和生成能力，作者提出了一个解决方案。", "method": "通过引入特殊令牌<SOG_k>来代表整个图的拓扑结构，并创建了混合结构问答语料库以使新结构标记与现有文本标记一致。", "result": "实验结果表明，该方法在五个图形基准测试中优于基线模型，在性能上提高了9.9%至41.4%，并表现出可解释性和一致性。", "conclusion": "提出的方法通过引入<SOG_k>令牌显著改善了大型语言模型对图形结构的理解和生成能力，并且可以灵活地应用于节点级别的任务。"}}
{"id": "2602.01769", "pdf": "https://arxiv.org/pdf/2602.01769", "abs": "https://arxiv.org/abs/2602.01769", "authors": ["Yuanshuai Li", "Yuping Yan", "Jirui Han", "Fei Ming", "Lingjuan Lv", "Yaochu Jin"], "title": "IRIS: Implicit Reward-Guided Internal Sifting for Mitigating Multimodal Hallucination", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Hallucination remains a fundamental challenge for Multimodal Large Language Models (MLLMs). While Direct Preference Optimization (DPO) is a key alignment framework, existing approaches often rely heavily on costly external evaluators for scoring or rewriting, incurring off-policy learnability gaps and discretization loss. Due to the lack of access to internal states, such feedback overlooks the fine-grained conflicts between different modalities that lead to hallucinations during generation. To address this issue, we propose IRIS (Implicit Reward-Guided Internal Sifting), which leverages continuous implicit rewards in the native log-probability space to preserve full information density and capture internal modal competition. This on-policy paradigm eliminates learnability gaps by utilizing self-generated preference pairs. By sifting these pairs based on multimodal implicit rewards, IRIS ensures that optimization is driven by signals that directly resolve modal conflicts. Extensive experiments demonstrate that IRIS achieves highly competitive performance on key hallucination benchmarks using only 5.7k samples, without requiring any external feedback during preference alignment. These results confirm that IRIS provides an efficient and principled paradigm for mitigating MLLM hallucinations.", "AI": {"tldr": "IRIS是一种用于减轻多模态大型语言模型幻觉问题的方法，它利用内在的连续隐式奖励来优化生成过程。", "motivation": "现有的直接偏好优化方法依赖于外部评估者提供的分数或重写操作，这导致学习差距和信息损失。为了解决这些问题，本文提出了IRIS以缓解多模态大型语言模型的幻觉问题。", "method": "IRIS利用内在连续隐式奖励在原生对数概率空间中进行优化，并通过自动生成的偏好对来消除学习差距。该方法通过基于多模态隐式奖励筛选这些偏好对，确保了直接解决模式冲突的信号驱动优化过程。", "result": "实验表明，IRIS使用5.7k样本在关键幻觉基准测试中取得了高度竞争性的性能，并且无需外部反馈即可完成偏好对齐。", "conclusion": "IRIS提供了一种有效和原则性的方法来减轻多模态大型语言模型的幻觉问题。"}}
{"id": "2602.01766", "pdf": "https://arxiv.org/pdf/2602.01766", "abs": "https://arxiv.org/abs/2602.01766", "authors": ["Runsong Zhao", "Shilei Liu", "Jiwei Tang", "Langming Liu", "Haibin Chen", "Weidong Zhang", "Yujin Yuan", "Tong Xiao", "Jingbo Zhu", "Wenbo Su", "Bo Zheng"], "title": "CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The quadratic complexity and indefinitely growing key-value (KV) cache of standard Transformers pose a major barrier to long-context processing. To overcome this, we introduce the Collaborative Memory Transformer (CoMeT), a novel architecture that enables LLMs to handle arbitrarily long sequences with constant memory usage and linear time complexity. Designed as an efficient, plug-in module, CoMeT can be integrated into pre-trained models with only minimal fine-tuning. It operates on sequential data chunks, using a dual-memory system to manage context: a temporary memory on a FIFO queue for recent events, and a global memory with a gated update rule for long-range dependencies. These memories then act as a dynamic soft prompt for the next chunk. To enable efficient fine-tuning on extremely long contexts, we introduce a novel layer-level pipeline parallelism strategy. The effectiveness of our approach is remarkable: a model equipped with CoMeT and fine-tuned on 32k contexts can accurately retrieve a passkey from any position within a 1M token sequence. On the SCROLLS benchmark, CoMeT surpasses other efficient methods and achieves performance comparable to a full-attention baseline on summarization tasks. Its practical effectiveness is further validated on real-world agent and user behavior QA tasks. The code is available at: https://anonymous.4open.science/r/comet-B00B/", "AI": {"tldr": "提出了一种新型架构CoMeT，用于解决长上下文建模中的二次复杂度和无限增长的KV缓存问题。", "motivation": "标准Transformer在处理长上下文时存在二次复杂度和不断增长的KV缓存问题。为了解决这些问题，本文提出了CoMeT以实现对任意长度序列的有效处理。", "method": "设计了一个双内存系统来管理上下文：一个临时内存用于最近事件（FIFO队列）和一个全局内存用于长距离依赖关系（带门控更新规则）。这些记忆充当下一个块的动态软提示。引入了一种新的层级流水线并行策略以实现高效的微调。", "result": "实验结果显示，CoMeT能够在1M令牌序列中的任何位置准确检索密码，并且在SCROLLS基准测试中超越其他高效方法，性能与全注意力基线相当。它还通过现实世界中的代理和用户行为QA任务进一步验证了其有效性。", "conclusion": "CoMeT可以有效解决长上下文建模的问题，为预训练模型提供了一个有效的插件模块，并且在实际应用中表现良好。"}}
{"id": "2602.01765", "pdf": "https://arxiv.org/pdf/2602.01765", "abs": "https://arxiv.org/abs/2602.01765", "authors": ["Bingzheng Wang", "Xiaoyan Gu", "Hongbo Xu", "Hongcheng Li", "Zimo Yu", "Jiang Zhou", "Weiping Wang"], "title": "Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Diffusion models have been widely deployed in AIGC services; however, their reliance on opaque training data and procedures exposes a broad attack surface for backdoor injection. In practical auditing scenarios, due to the protection of intellectual property and commercial confidentiality, auditors are typically unable to access model parameters, rendering existing white-box or query-intensive detection methods impractical. More importantly, even after the backdoor is detected, existing detoxification approaches are often trapped in a dilemma between detoxification effectiveness and generation quality. In this work, we identify a previously unreported phenomenon called temporal noise unconsistency, where the noise predictions between adjacent diffusion timesteps is disrupted in specific temporal segments when the input is triggered, while remaining stable under clean inputs. Leveraging this finding, we propose Temporal Noise Consistency Defense (TNC-Defense), a unified framework for backdoor detection and detoxification. The framework first uses the adjacent timestep noise consistency to design a gray-box detection module, for identifying and locating anomalous diffusion timesteps. Furthermore, the framework uses the identified anomalous timesteps to construct a trigger-agnostic, timestep-aware detoxification module, which directly corrects the backdoor generation path. This effectively suppresses backdoor behavior while significantly reducing detoxification costs. We evaluate the proposed method under five representative backdoor attack scenarios and compare it with state-of-the-art defenses. The results show that TNC-Defense improves the average detection accuracy by $11\\%$ with negligible additional overhead, and invalidates an average of $98.5\\%$ of triggered samples with only a mild degradation in generation quality.", "AI": {"tldr": "提出一种新的检测和去除扩散模型后门的方法TNC-Defense，通过时间噪声一致性来识别异常扩散时间段，并构建去毒模块。", "motivation": "现有的方法在实际审计场景中不实用且无法平衡去毒效果与生成质量之间的矛盾。本文发现了一种称为时间噪声不一致的现象，并基于此提出解决方案。", "method": "首先，利用相邻扩散步的噪声一致性设计灰盒检测模块来识别和定位异常扩散步；其次，使用所识别的异常步构建一个无触发器意识的时间步去毒模块直接纠正后门生成路径。", "result": "该方法在五种代表性的后门攻击场景中提高了11%的平均检测准确率，同时只造成了轻微的生成质量下降。能有效抑制98.5%的触发样本。", "conclusion": "TNC-Defense是一种有效的灰盒检测和去毒框架，能够在不影响生成质量的情况下显著提高扩散模型的安全性。"}}
{"id": "2602.01764", "pdf": "https://arxiv.org/pdf/2602.01764", "abs": "https://arxiv.org/abs/2602.01764", "authors": ["Dennis Basile", "Dennis Sprute", "Helene Dörksen", "Holger Flatt"], "title": "GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data", "categories": ["cs.CV"], "comment": "Accepted at 19th CIRP Conference on Intelligent Computation in Manufacturing Engineering", "summary": "The reliable detection of unauthorized individuals in safety-critical industrial indoor spaces is crucial to avoid plant shutdowns, property damage, and personal hazards. Conventional vision-based methods that use deep-learning approaches for person recognition provide image information but are sensitive to lighting and visibility conditions and often violate privacy regulations, such as the General Data Protection Regulation (GDPR) in the European Union. Typically, detection systems based on deep learning require annotated data for training. Collecting and annotating such data, however, is highly time-consuming and due to manual treatments not necessarily error free. Therefore, this paper presents a privacy-compliant approach based on Micro-Electro-Mechanical Systems LiDAR (MEMS-LiDAR), which exclusively captures anonymized 3D point clouds and avoids personal identification features. To compensate for the large amount of time required to record real LiDAR data and for post-processing and annotation, real recordings are augmented with synthetically generated scenes from the CARLA simulation framework. The results demonstrate that the hybrid data improves the average precision by 44 percentage points compared to a model trained exclusively with real data while reducing the manual annotation effort by 50 %. Thus, the proposed approach provides a scalable, cost-efficient alternative to purely real-data-based methods and systematically shows how synthetic LiDAR data can combine high performance in person detection with GDPR compliance in an industrial environment.", "AI": {"tldr": "本文提出了一种基于MEMS-LiDAR的隐私合规人员识别方法，使用真实数据和合成场景提高检测精度并减少人工标注工作量。", "motivation": "传统的视觉深度学习方法在光照和可见度变化下表现不稳定，并且容易侵犯个人隐私。因此，需要一种既能保证准确率又符合GDPR法规的方法来检测未经授权的进入者以保障工业环境的安全。", "method": "本文使用MEMS-LiDAR技术采集匿名化的3D点云数据，并结合CARLA仿真框架生成合成场景数据集用于模型训练和测试，以此提高检测精度并减少人工标注的工作量。", "result": "相比只使用真实数据的模型，这种方法将平均准确率提高了44个百分点，同时减少了50%的人工标注工作。表明该方法在人员检测中既实现了高效率又保证了隐私保护。", "conclusion": "本文提出的方法提供了一种可扩展且成本效益高的替代方案，证明了合成LiDAR数据可以结合高性能人员检测与GDPR合规性。"}}
{"id": "2602.01763", "pdf": "https://arxiv.org/pdf/2602.01763", "abs": "https://arxiv.org/abs/2602.01763", "authors": ["Xiaowei Ye", "Xiaoyu He", "Chao Liao", "Chen Wu", "Pinyan Lu"], "title": "A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention", "categories": ["cs.LG", "cs.AI", "cs.CC"], "comment": null, "summary": "Transformers serve as the foundation of most modern large language models. To mitigate the quadratic complexity of standard full attention, various efficient attention mechanisms, such as linear and hybrid attention, have been developed. A fundamental gap remains: their expressive power relative to full attention lacks a rigorous theoretical characterization. In this work, we theoretically characterize the performance differences among these attention mechanisms. Our theory applies to all linear attention variants that can be formulated as a recurrence, including Mamba, DeltaNet, etc. Specifically, we establish an expressiveness hierarchy: for the sequential function composition-a multi-step reasoning task that must occur within a model's forward pass, an ($L+1$)-layer full attention network is sufficient, whereas any hybrid network interleaving $L-1$ layers of full attention with a substantially larger number ($2^{3L^2}$) of linear attention layers cannot solve it. This result demonstrates a clear separation in expressive power between the two types of attention. Our work provides the first provable separation between hybrid attention and standard full attention, offering a theoretical perspective for understanding the fundamental capabilities and limitations of different attention mechanisms.", "AI": {"tldr": "本文理论分析了不同注意力机制在多步推理任务中的表现差异，建立了全注意力和混合注意力之间的表达力层次结构。", "motivation": "尽管高效的注意力机制已经被开发出来以缓解标准全注意力的二次复杂度问题，但它们相对于全注意力的表现能力缺乏严格的理论描述。为此，作者旨在填补这一理论空白，并提供理解不同注意力机制核心能力和限制的新视角。", "method": "通过建立理论框架，将所有线性注意力变体视为递归形式的模型，分析了其在多步推理任务中的表现差异。", "result": "证明了一个$(L+1)$层全注意力网络足以完成特定任务，而混合网络则需要更多的层数（$2^{3L^2}$）来实现相同的功能。这表明两者之间存在明显的表达力分离。", "conclusion": "这项工作首次提供了混合注意与标准全注意之间的可证明的分离，并为理解不同注意力机制的基本能力和限制提供理论视角"}}
{"id": "2602.01762", "pdf": "https://arxiv.org/pdf/2602.01762", "abs": "https://arxiv.org/abs/2602.01762", "authors": ["Xuliang Wang", "Yuetao Chen", "Maochan Zhen", "Fang Liu", "Xinzhou Zheng", "Xingwu Liu", "Hong Xu", "Ming Li"], "title": "PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs), constrained by their auto-regressive nature, suffer from slow decoding. Speculative decoding methods have emerged as a promising solution to accelerate LLM decoding, attracting attention from both systems and AI research communities. Recently, the pursuit of better draft quality has driven a trend toward parametrically larger draft models, which inevitably introduces substantial computational overhead. While existing work attempts to balance the trade-off between prediction accuracy and compute latency, we address this fundamental dilemma through architectural innovation. We propose PRISM, which disaggregates the computation of each predictive step across different parameter sets, refactoring the computational pathways of draft models to successfully decouple model capacity from inference cost. Through extensive experiments, we demonstrate that PRISM outperforms all existing draft architectures, achieving exceptional acceptance lengths while maintaining minimal draft latency for superior end-to-end speedup. We also re-examine scaling laws with PRISM, revealing that PRISM scales more effectively with expanding data volumes than other draft architectures. Through rigorous and fair comparison, we show that PRISM boosts the decoding throughput of an already highly optimized inference engine by more than 2.6x.", "AI": {"tldr": "PRISM通过架构创新，将每次预测步骤的计算分散到不同的参数集中，成功解耦了模型容量和推理成本。", "motivation": "为了提高大型语言模型（LLMs）的解码速度同时保持较好的草稿质量，现有工作试图平衡预测准确性和计算延迟之间的权衡。然而，这种做法引入了大量的计算开销，因此需要一种新的方法来解决这一基本困境。", "method": "PRISM通过将每个预测步骤的计算分散到不同的参数集上来重构草模的计算路径，从而在不牺牲模型容量的情况下降低推理成本。", "result": "通过广泛的实验，PRISM展示了比现有的所有草稿架构更好的性能，实现了卓越的接受长度并保持了最低的草稿延迟。此外，在扩展数据量时，PRISM显示出更有效的规模效应。", "conclusion": "与高度优化的推理引擎进行严格的公平比较后，PRISM证明了它可以将解码吞吐量提高2.6倍以上，表明其在加速大型语言模型解码方面的优势。"}}
{"id": "2602.01760", "pdf": "https://arxiv.org/pdf/2602.01760", "abs": "https://arxiv.org/abs/2602.01760", "authors": ["Hao Zhang", "Yanping Zha", "Zizhuo Li", "Meiqi Gong", "Jiayi Ma"], "title": "MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement", "categories": ["cs.CV"], "comment": null, "summary": "This paper focuses on a highly practical scenario: how to continue benefiting from the advantages of multi-modal image fusion under harsh conditions when only visible imaging sensors are available. To achieve this goal, we propose a novel concept of single-image fusion, which extends conventional data-level fusion to the knowledge level. Specifically, we develop MagicFuse, a novel single image fusion framework capable of deriving a comprehensive cross-spectral scene representation from a single low-quality visible image. MagicFuse first introduces an intra-spectral knowledge reinforcement branch and a cross-spectral knowledge generation branch based on the diffusion models. They mine scene information obscured in the visible spectrum and learn thermal radiation distribution patterns transferred to the infrared spectrum, respectively. Building on them, we design a multi-domain knowledge fusion branch that integrates the probabilistic noise from the diffusion streams of these two branches, from which a cross-spectral scene representation can be obtained through successive sampling. Then, we impose both visual and semantic constraints to ensure that this scene representation can satisfy human observation while supporting downstream semantic decision-making. Extensive experiments show that our MagicFuse achieves visual and semantic representation performance comparable to or even better than state-of-the-art fusion methods with multi-modal inputs, despite relying solely on a single degraded visible image.", "AI": {"tldr": "提出了一种单图像融合框架MagicFuse，从单一低质量可见光图像中提取跨谱段场景表示。", "motivation": "研究在仅使用可见光成像传感器的情况下如何继续受益于多模态图像融合的优势。", "method": "引入了基于扩散模型的同频带知识增强分支和异频带知识生成分支，挖掘被隐藏的场景信息并学习辐射分布模式。通过设计跨域知识融合分支将这两部分结合，并施加视觉和语义约束来获得高质量表示。", "result": "实验表明MagicFuse在视觉和语义表现上与使用多模态输入的方法相当甚至更优。", "conclusion": "提出的MagicFuse框架证明了从单一可见光图像中提取跨谱段场景表示的有效性。"}}
{"id": "2602.01756", "pdf": "https://arxiv.org/pdf/2602.01756", "abs": "https://arxiv.org/abs/2602.01756", "authors": ["Jun He", "Junyan Ye", "Zilong Huang", "Dongzhi Jiang", "Chenjue Zhang", "Leqi Zhu", "Renrui Zhang", "Xiang Zhang", "Weijia Li"], "title": "Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation", "categories": ["cs.CV"], "comment": "36 pages, 24 figures", "summary": "While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE.", "AI": {"tldr": "本文提出了Mind-Brush框架，将生成转化为一个动态、知识驱动的工作流程，以解决静态文本到图像模型的限制。", "motivation": "现有文本到图像模型无法理解用户的隐含意图，并且难以处理涉及复杂知识推理的任务。此外，它们缺乏适应现实世界中不断变化的能力。", "method": "Mind-Brush通过模拟人类的‘思考-研究-创作’过程，主动检索多模态证据来支撑出界的概念，并使用推理工具解决隐含的视觉约束。", "result": "实验结果显示，与基线模型相比，Mind-Brush在新提出的Mind-Bench上实现了显著的能力提升，在WISE和RISE等已建立的基准测试中也表现出色。", "conclusion": "Mind-Brush成功地将文本到图像生成从静态过程转变为动态、知识驱动的工作流程，并展示了比现有方法更强的理解和创作能力。"}}
{"id": "2602.01755", "pdf": "https://arxiv.org/pdf/2602.01755", "abs": "https://arxiv.org/abs/2602.01755", "authors": ["Luis M. B. Varona"], "title": "A polynomial-time algorithm for recognizing high-bandwidth graphs", "categories": ["cs.DS", "cs.DM"], "comment": "15 pages, 4 tables", "summary": "An unweighted, undirected graph $G$ on $n$ nodes is said to have \\emph{bandwidth} at most $k$ if its nodes can be labelled from $0$ to $n - 1$ such that no two adjacent nodes have labels that differ by more than $k$. It is known that one can decide whether the bandwidth of $G$ is at most $k$ in $O(n^k)$ time and $O(n^k)$ space using dynamic programming techniques. For small $k$ close to $0$, this approach is effectively polynomial, but as $k$ scales with $n$, it becomes superexponential, requiring up to $O(n^{n - 1})$ time (where $n - 1$ is the maximum possible bandwidth). In this paper, we reformulate the problem in terms of bipartite matching for sufficiently large $k \\ge \\lfloor (n - 1)/2 \\rfloor$, allowing us to use Hall's marriage theorem to develop an algorithm that runs in $O(n^{n - k + 1})$ time and $O(n)$ auxiliary space (beyond storage of the input graph). This yields polynomial complexity for large $k$ close to $n - 1$, demonstrating that the bandwidth recognition problem is solvable in polynomial time whenever either $k$ or $n - k$ remains small.", "AI": {"tldr": "开发了一个用于识别带宽至多为k的图的多项式时间算法", "motivation": "现有的动态规划方法在处理大带宽时变得极其耗时，因此需要更高效的方法来解决这个问题", "method": "通过将问题重新表述为二部匹配，并使用Hall婚姻定理来开发新算法", "result": "提出了一个运行时间为O(n^{n-k+1})的时间和O(n)空间的多项式时间算法", "conclusion": "表明带宽识别问题在k或n-k较小的情况下是可在多项式时间内解决的问题"}}
{"id": "2602.01754", "pdf": "https://arxiv.org/pdf/2602.01754", "abs": "https://arxiv.org/abs/2602.01754", "authors": ["Gustavo P. C. P. da Luz", "Alvaro M. Aspilcueta Narvaez", "Tiago Godoi Bannwart", "Gabriel Massuyoshi Sato", "Luis Fernando Gomez Gonzalez", "Juliana Freitag Borin"], "title": "Spot-Wise Smart Parking: An Edge-Enabled Architecture with YOLOv11 and Digital Twin Integration", "categories": ["cs.CV"], "comment": "Submitted to Journal of Internet Services and Applications, 27 pages, 20 figures, 3 tables", "summary": "Smart parking systems help reduce congestion and minimize users' search time, thereby contributing to smart city adoption and enhancing urban mobility. In previous works, we presented a system developed on a university campus to monitor parking availability by estimating the number of free spaces from vehicle counts within a region of interest. Although this approach achieved good accuracy, it restricted the system's ability to provide spot-level insights and support more advanced applications. To overcome this limitation, we extend the system with a spot-wise monitoring strategy based on a distance-aware matching method with spatial tolerance, enhanced through an Adaptive Bounding Box Partitioning method for challenging spaces. The proposed approach achieves a balanced accuracy of 98.80% while maintaining an inference time of 8 seconds on a resource-constrained edge device, enhancing the capabilities of YOLOv11m, a model that has a size of 40.5 MB. In addition, two new components were introduced: (i) a Digital Shadow that visually represents parking lot entities as a base to evolve to a full Digital Twin, and (ii) an application support server based on a repurposed TV box. The latter not only enables scalable communication among cloud services, the parking totem, and a bot that provides detailed spot occupancy statistics, but also promotes hardware reuse as a step towards greater sustainability.", "AI": {"tldr": "论文提出了一种基于边缘计算的智能停车系统，利用YOLOv11和数字孪生技术实现车位级别的监控", "motivation": "为了克服现有系统只能提供区域级别停车位信息的限制，本研究旨在通过引入新的方法和技术来提高系统的精确度和实用性，并支持更多高级应用", "method": "该论文采用了距离感知匹配法与空间容忍相结合的方法，并通过自适应边界框划分技术优化了车位检测。此外还引入了一个数字阴影组件以实现停车场地实体的可视化表示，以及一个基于电视盒子的应用服务器用于提供详细的停车位占用情况统计", "result": "提出的方法在资源受限的边缘设备上实现了98.80%的平衡精度和8秒的推理时间，并成功地将YOLOv11m模型优化到40.5MB大小。同时该系统通过数字阴影组件提升了对停车场地实体的理解，且应用服务器支持了多云服务间的通信", "conclusion": "论文展示了一个高效的智能停车解决方案，实现了车位级别的精确监控和更高级的应用，同时也强调了硬件重用的可持续性"}}
{"id": "2602.01753", "pdf": "https://arxiv.org/pdf/2602.01753", "abs": "https://arxiv.org/abs/2602.01753", "authors": ["Shenghao Fu", "Yukun Su", "Fengyun Rao", "Jing Lyu", "Xiaohua Xie", "Wei-Shi Zheng"], "title": "ObjEmbed: Towards Universal Multimodal Object Embeddings", "categories": ["cs.CV"], "comment": null, "summary": "Aligning objects with corresponding textual descriptions is a fundamental challenge and a realistic requirement in vision-language understanding. While recent multimodal embedding models excel at global image-text alignment, they often struggle with fine-grained alignment between image regions and specific phrases. In this work, we present ObjEmbed, a novel MLLM embedding model that decomposes the input image into multiple regional embeddings, each corresponding to an individual object, along with global embeddings. It supports a wide range of visual understanding tasks like visual grounding, local image retrieval, and global image retrieval. ObjEmbed enjoys three key properties: (1) Object-Oriented Representation: It captures both semantic and spatial aspects of objects by generating two complementary embeddings for each region: an object embedding for semantic matching and an IoU embedding that predicts localization quality. The final object matching score combines semantic similarity with the predicted IoU, enabling more accurate retrieval. (2) Versatility: It seamlessly handles both region-level and image-level tasks. (3) Efficient Encoding: All objects in an image, along with the full image, are encoded in a single forward pass for high efficiency. Superior performance on 18 diverse benchmarks demonstrates its strong semantic discrimination.", "AI": {"tldr": "ObjEmbed是一个新型的多模态嵌入模型，用于将图像中的对象区域与文本描述进行对齐。", "motivation": "现有的多模态嵌入模型在全局图-文对齐方面表现出色，但在细粒度对齐上存在困难。因此，作者提出了一种新的方法来解决这一挑战。", "method": "ObjEmbed通过将输入图像分解成多个区域嵌入，并为每个对象生成两个互补的嵌入：一个是语义匹配的对象嵌入，另一个是预测定位质量的IoU嵌入。模型同时支持区域级和全局级别的任务，在单次前向传播中编码所有对象。", "result": "ObjEmbed在18个不同基准上的表现优于其他方法，显示了其强大的语义区分能力。", "conclusion": "ObjEmbed为图-文对齐问题提供了一种新的解决方案，通过生成互补的嵌入来捕捉对象的语义和空间方面，并且能够高效地处理区域级和全局级别的任务。"}}
{"id": "2602.01750", "pdf": "https://arxiv.org/pdf/2602.01750", "abs": "https://arxiv.org/abs/2602.01750", "authors": ["Mohammad Beigi", "Ming Jin", "Junshan Zhang", "Qifan Wang", "Lifu Huang"], "title": "Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.", "AI": {"tldr": "提出了一种对抗性奖励审核框架，用于主动检测和缓解强化学习中的人类反馈奖励模型漏洞。", "motivation": "现有方法在防止利用人类反馈奖励模型的漏洞方面存在静态防御的限制，不能适应新的策略。因此，需要一种动态、竞争性的游戏化框架来识别并解决这些问题。", "method": "提出了一种对抗性奖励审核（ARA）框架，该框架通过两个阶段操作：首先，发现者政策寻找奖励模型的弱点，同时审核员从潜在表示中学习检测利用行为；其次，引导式人类反馈强化学习通过限制奖励信号来惩罚检测到的攻击。", "result": "实验结果表明，在减少奉承、提高有用性、降低冗长和改善代码游戏方面，ARA达到了最佳的效果。此外，对抗性检测与缓解策略能够在不同领域间推广。", "conclusion": "对抗性奖励审核框架有效提高了人类反馈强化学习中模型行为的对齐度，并且能够跨域应用，使得单一模型可以有效地防御多领域的攻击。"}}
{"id": "2602.01749", "pdf": "https://arxiv.org/pdf/2602.01749", "abs": "https://arxiv.org/abs/2602.01749", "authors": ["Lin Chen", "Samuel Drapeau", "Fanghao Shao", "Xuekai Zhu", "Bo Xue", "Yunchong Song", "Mathieu Laurière", "Zhouhan Lin"], "title": "Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $α$-GFNs, which generalize the mixing via a tunable parameter $α$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $α$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \\times$ increase in the number of discovered modes.", "AI": {"tldr": "本论文通过马尔可夫链视角研究生成流网络（GFlowNets）的目标，提出了一种新的参数化方法以更好地控制探索-利用平衡，并提高了模式发现能力。", "motivation": "现有的GFlowNet目标隐式地固定了前向和后向策略的相等混合，在训练过程中限制了探索与利用之间的权衡。通过建立GFlowNets与马尔可夫链之间更深入的联系，揭示这一约束的起源，并提供了一种框架以适应马尔可夫链特性至GFlowNets。", "method": "作者提出了$α$-GFNs方法，该方法通过一个可调参数$α$来调整混合方式。这允许直接控制探索和利用的动力学，从而增强了模式发现能力并确保了唯一流的收敛。", "result": "$α$-GFN目标在各种基准测试中（如集合、位序列生成及分子生成）均优于先前的GFlowNet目标，其性能提升了多达10倍的新模式发现数量。", "conclusion": "通过引入马尔可夫链视角和$α$参数化方法，该研究显著提高了探索与利用之间的平衡控制能力，并在多个任务中展现了优越的表现。"}}
{"id": "2602.01746", "pdf": "https://arxiv.org/pdf/2602.01746", "abs": "https://arxiv.org/abs/2602.01746", "authors": ["Hongyi Peng", "Han Yu", "Xiaoxiao Li", "Qiang Yang"], "title": "Rethinking LoRA for Data Heterogeneous Federated Learning: Subspace and State Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) is widely used for federated fine-tuning. Yet under non-IID settings, it can substantially underperform full-parameter fine-tuning. Through with-high-probability robustness analysis, we uncover that this gap can be attributed to two coupled mismatches: (i) update-space mismatch, where clients optimize in a low-rank subspace but aggregation occurs in the full space; and (ii) optimizer-state mismatch, where unsynchronized adaptive states amplify drift across rounds. We propose FedGaLore, which combines client-side GaLore-style gradient-subspace optimization with server-side drift-robust synchronization of projected second-moment states via spectral shared-signal extraction, to address this challenge. Across NLU, vision, and NLG benchmarks, FedGaLore improves robustness and accuracy over state-of-the-art federated LoRA baselines in non-IID settings.", "AI": {"tldr": "本文重新思考了LoRA在数据异构联邦学习中的应用，提出了一种新的方法FedGaLore以提高其鲁棒性和准确性。", "motivation": "低秩适应（LoRA）在非IID设置下表现不佳，原因是客户端和服务器之间存在更新空间不匹配及优化器状态不匹配的问题。这导致了联邦LoRA的性能下降。", "method": "提出FedGaLore结合了客户端梯度子空间优化以及服务器端投影第二矩状态同步的方法来解决这些问题。通过谱共享信号提取，实现漂移鲁棒性同步。", "result": "在NLU、视觉和NLG基准测试中，FedGaLore在非IID设置下表现优于现有的联邦LoRA基线方法，在提高准确性和鲁棒性方面取得进展。", "conclusion": "FedGaLore通过解决更新空间不匹配及优化器状态不匹配的问题，有效提高了LoRA在数据异构联邦学习中的性能。"}}
{"id": "2602.01745", "pdf": "https://arxiv.org/pdf/2602.01745", "abs": "https://arxiv.org/abs/2602.01745", "authors": ["Wenhao Yu", "Shaohang Wei", "Jiahong Liu", "Yifan Li", "Minda Hu", "Aiwei Liu", "Hao Zhang", "Irwin King"], "title": "Probability-Entropy Calibration: An Elastic Indicator for Adaptive Fine-tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Token-level reweighting is a simple yet effective mechanism for controlling supervised fine-tuning, but common indicators are largely one-dimensional: the ground-truth probability reflects downstream alignment, while token entropy reflects intrinsic uncertainty induced by the pre-training prior. Ignoring entropy can misidentify noisy or easily replaceable tokens as learning-critical, while ignoring probability fails to reflect target-specific alignment. RankTuner introduces a probability--entropy calibration signal, the Relative Rank Indicator, which compares the rank of the ground-truth token with its expected rank under the prediction distribution. The inverse indicator is used as a token-wise Relative Scale to reweight the fine-tuning objective, focusing updates on truly under-learned tokens without over-penalizing intrinsically uncertain positions. Experiments on multiple backbones show consistent improvements on mathematical reasoning benchmarks, transfer gains on out-of-distribution reasoning, and pre code generation performance over probability-only or entropy-only reweighting baselines.", "AI": {"tldr": "本文提出了一个概率熵校准信号，用于自适应微调。", "motivation": "传统的指标在控制监督微调时存在局限性：仅考虑地标签概率会忽略内在不确定性，而仅使用令牌熵则无法反映目标特定的对齐。因此，引入了相对等级指标以解决这些问题。", "method": "RankTuner通过比较地标签令牌与预测分布下的预期排名来生成相对等级指示器，并将其用作令牌级别的相对比例因子，重新加权微调目标。", "result": "实验表明，在多个基准模型上实现了数学推理性能的一致改进和出界分布上的转移增益及代码生成方面的优势。", "conclusion": "概率熵校准信号能够更有效地识别真正需要学习的令牌，并优化微调过程，提高模型性能。"}}
{"id": "2602.01744", "pdf": "https://arxiv.org/pdf/2602.01744", "abs": "https://arxiv.org/abs/2602.01744", "authors": ["Mingwei Xu", "Xuan Lin", "Xinnan Guo", "Wanqing Xu", "Wanyun Cui"], "title": "Softmax Linear Attention: Reclaiming Global Competition", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages,4 figures", "summary": "While linear attention reduces the quadratic complexity of standard Transformers to linear time, it often lags behind in expressivity due to the removal of softmax normalization. This omission eliminates \\emph{global competition}, a critical mechanism that enables models to sharply focus on relevant information amidst long-context noise. In this work, we propose \\textbf{Softmax Linear Attention (SLA)}, a framework designed to restore this competitive selection without sacrificing efficiency. By lifting the softmax operation from the token level to the head level, SLA leverages attention heads as coarse semantic slots, applying a competitive gating mechanism to dynamically select the most relevant subspaces. This reintroduces the ``winner-take-all'' dynamics essential for precise retrieval and robust long-context understanding. Distinct from prior methods that focus on refining local kernel functions, SLA adopts a broader perspective by exploiting the higher-level multi-head aggregation structure. Extensive experiments demonstrate that SLA consistently enhances state-of-the-art linear baselines (RetNet, GLA, GDN) across language modeling and long-context benchmarks, particularly in challenging retrieval scenarios where it significantly boosts robustness against noise, validating its capability to restore precise focus while maintaining linear complexity.", "AI": {"tldr": "提出了Softmax线性注意力机制，旨在恢复标准变换器中由于线性注意缺失的全局竞争机制。", "motivation": "线性注意力虽然降低了计算复杂度，但缺乏软最大归一化导致其表达能力不足。此机制在长上下文噪声环境中难以精确聚焦。", "method": "通过将softmax操作提升到头级别来恢复竞争选择机制，引入了粗粒度语义槽，并利用多头聚集结构进行动态子空间选择。", "result": "实验表明，在语言建模和长上下文基准测试中，SLA能够显著增强现有线性基础模型的表现，特别是在噪声环境下提升了鲁棒性。", "conclusion": "提出的方法有效恢复了全局竞争机制，并在保持线性复杂度的同时增强了对长上下文信息的精确检索能力。"}}
{"id": "2602.01741", "pdf": "https://arxiv.org/pdf/2602.01741", "abs": "https://arxiv.org/abs/2602.01741", "authors": ["Sicheng Pan", "Chen Tang", "Shuzhao Xie", "Ke Yang", "Weixiang Zhang", "Jiawei Li", "Bin Chen", "Shu-Tao Xia", "Zhi Wang"], "title": "Tail-Aware Post-Training Quantization for 3D Geometry Models", "categories": ["cs.CV"], "comment": null, "summary": "The burgeoning complexity and scale of 3D geometry models pose significant challenges for deployment on resource-constrained platforms. While Post-Training Quantization (PTQ) enables efficient inference without retraining, conventional methods, primarily optimized for 2D Vision Transformers, fail to transfer effectively to 3D models due to intricate feature distributions and prohibitive calibration overhead. To address these challenges, we propose TAPTQ, a Tail-Aware Post-Training Quantization pipeline specifically engineered for 3D geometric learning. Our contribution is threefold: (1) To overcome the data-scale bottleneck in 3D datasets, we develop a progressive coarse-to-fine calibration construction strategy that constructs a highly compact subset to achieve both statistical purity and geometric representativeness. (2) We reformulate the quantization interval search as an optimization problem and introduce a ternary-search-based solver, reducing the computational complexity from $\\mathcal{O}(N)$ to $\\mathcal{O}(\\log N)$ for accelerated deployment. (3) To mitigate quantization error accumulation, we propose TRE-Guided Module-wise Compensation, which utilizes a Tail Relative Error (TRE) metric to adaptively identify and rectify distortions in modules sensitive to long-tailed activation outliers. Extensive experiments on the VGGT and Pi3 benchmarks demonstrate that TAPTQ consistently outperforms state-of-the-art PTQ methods in accuracy while significantly reducing calibration time. The code will be released soon.", "AI": {"tldr": "提出一种面向3D几何模型的后训练量化方法TAPTQ，提高资源受限平台上部署效率。", "motivation": "现有PTQ方法在处理复杂和大规模的3D几何模型时面临挑战，需要开发专门针对3D模型的新方法。", "method": "1. 基于逐步粗细校准策略构建紧凑的数据集。2. 将量化区间搜索问题转化为优化问题，并引入三进制搜索算法加速计算。3. 引入TRE-Guided Module-wise Compensation，减少模块化量化误差累积。", "result": "实验结果表明，TAPTQ在精度上优于当前最优的PTQ方法，并显著减少了校准时间。", "conclusion": "TAPTQ有效解决了3D几何模型部署中的瓶颈问题，实现了高效准确的后训练量化。"}}
{"id": "2602.01740", "pdf": "https://arxiv.org/pdf/2602.01740", "abs": "https://arxiv.org/abs/2602.01740", "authors": ["Qixin Xiao", "Kun Zhou"], "title": "MACD: Model-Aware Contrastive Decoding via Counterfactual Data", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We propose Model-aware Counterfactual Data based Contrastive Decoding (MACD), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM's own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, Perception-test and Video-MME show that MACD consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including Qwen and InternVL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.", "AI": {"tldr": "提出了一种名为MACD的模型感知对比解码策略，以减少视频语言模型生成的内容中的幻觉。", "motivation": "现有方法如对比解码依赖于随机扰动来构建对抗数据，难以控制视觉线索或与模型弱点对齐。因此，提出了基于模型反馈的方法来解决这些问题。", "method": "MACD通过使用Video-LLM的自身反馈识别负责幻觉的对象区域，并生成有针对性的反事实输入以减少幻觉。", "result": "实验表明，MACD在多种视频语言模型上有效减少了幻觉同时保持或提高了任务准确性。", "conclusion": "该方法特别适用于处理小、遮挡或共现对象等复杂场景中的问题。"}}
{"id": "2602.01738", "pdf": "https://arxiv.org/pdf/2602.01738", "abs": "https://arxiv.org/abs/2602.01738", "authors": ["Yue Zhou", "Xinan He", "Kaiqing Lin", "Bing Fan", "Feng Ding", "Bin Li"], "title": "Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models", "categories": ["cs.CV"], "comment": null, "summary": "While specialized detectors for AI-Generated Images (AIGI) achieve near-perfect accuracy on curated benchmarks, they suffer from a dramatic performance collapse in realistic, in-the-wild scenarios. In this work, we demonstrate that simplicity prevails over complex architectural designs. A simple linear classifier trained on the frozen features of modern Vision Foundation Models , including Perception Encoder, MetaCLIP 2, and DINOv3, establishes a new state-of-the-art. Through a comprehensive evaluation spanning traditional benchmarks, unseen generators, and challenging in-the-wild distributions, we show that this baseline not only matches specialized detectors on standard benchmarks but also decisively outperforms them on in-the-wild datasets, boosting accuracy by striking margins of over 30\\%. We posit that this superior capability is an emergent property driven by the massive scale of pre-training data containing synthetic content. We trace the source of this capability to two distinct manifestations of data exposure: Vision-Language Models internalize an explicit semantic concept of forgery, while Self-Supervised Learning models implicitly acquire discriminative forensic features from the pretraining data. However, we also reveal persistent limitations: these models suffer from performance degradation under recapture and transmission, remain blind to VAE reconstruction and localized editing. We conclude by advocating for a paradigm shift in AI forensics, moving from overfitting on static benchmarks to harnessing the evolving world knowledge of foundation models for real-world reliability.", "AI": {"tldr": "展示了一种简单的线性分类器在冻结的视觉基础模型特征上训练后，可以有效检测AI生成图像（AIGI），并在真实环境中表现优越。", "motivation": "现有专门针对AIGI的检测器在标准基准测试中表现出色但在实际应用中性能大幅下降。论文旨在探索更简单的设计是否能提高在现实场景中的可靠性。", "method": "利用现代视觉基础模型（如感知编码器、MetaCLIP2和DINOv3）的冻结特征训练简单的线性分类器来检测AIGI。", "result": "该方法不仅匹配了专用检测器的标准基准测试性能，还在现实世界的分布上表现出显著优势，准确性提高了超过30%。", "conclusion": "研究证明大规模预训练数据中合成内容的存在使基础模型具备区分伪造图像的能力。同时指出这些模型在某些特定情况下仍存在局限性，并建议未来转向利用基础模型的世界知识来提高实际可靠性。"}}
{"id": "2602.01731", "pdf": "https://arxiv.org/pdf/2602.01731", "abs": "https://arxiv.org/abs/2602.01731", "authors": ["Jiwoo Hwang", "Taegeun Yang", "Jeil Jeong", "Minsung Yoon", "Sung-Eui Yoon"], "title": "Uncertainty-Aware Non-Prehensile Manipulation with Mobile Manipulators under Object-Induced Occlusion", "categories": ["cs.RO"], "comment": "8 pages, 7 figures, Accepted to ICRA 2026, Webpage: https://jiw0o.github.io/cura-ppo/", "summary": "Non-prehensile manipulation using onboard sensing presents a fundamental challenge: the manipulated object occludes the sensor's field of view, creating occluded regions that can lead to collisions. We propose CURA-PPO, a reinforcement learning framework that addresses this challenge by explicitly modeling uncertainty under partial observability. By predicting collision possibility as a distribution, we extract both risk and uncertainty to guide the robot's actions. The uncertainty term encourages active perception, enabling simultaneous manipulation and information gathering to resolve occlusions. When combined with confidence maps that capture observation reliability, our approach enables safe navigation despite severe sensor occlusion. Extensive experiments across varying object sizes and obstacle configurations demonstrate that CURA-PPO achieves up to 3X higher success rates than the baselines, with learned behaviors that handle occlusions. Our method provides a practical solution for autonomous manipulation in cluttered environments using only onboard sensing.", "AI": {"tldr": "提出一种不确定性感知的非抓取操作框架CURA-PPO，用于移动机器人在物体遮挡下的安全导航。", "motivation": "解决非抓取操作中由于目标物遮挡导致传感器视场受限的问题，提高机器人在复杂环境中的操纵成功率和安全性。", "method": "使用强化学习框架CURA-PPO，通过预测碰撞概率的分布来指导机器人的行动，结合信心图捕获观测可靠性，实现同时进行操作与信息收集以解决遮挡问题。", "result": "实验结果表明，CURA-PPO在不同物体大小和障碍配置下比基准方法成功率提高3倍以上，展示了处理遮挡的有效性。", "conclusion": "所提出的方法为复杂环境中仅依靠车载传感器实现自主操作提供了一种实用解决方案。"}}
{"id": "2602.01729", "pdf": "https://arxiv.org/pdf/2602.01729", "abs": "https://arxiv.org/abs/2602.01729", "authors": ["Seoyoung Kang", "Seokhwan Yang", "Hail Song", "Boram Yoon", "Jinwook Kim", "Kangsoo Kim", "Woontack Woo"], "title": "Streamlined Facial Data Collection based on Utterance and Emotional Data for Human-to-Avatar Reconstruction", "categories": ["cs.HC"], "comment": "Accepted as an IEEE TVCG paper at IEEE VR 2026 (journal track)", "summary": "This study explores a streamlined facial data collection method for conversational contexts, addressing the limitations of existing approaches that often require extensive datasets and prioritize technical metrics over user perception and experience. We systematically investigate which facial expression data are essential for reconstructing photorealistic avatars and how they can be captured efficiently. Our research employs a two-phase methodology to identify efficient facial data collection strategies and evaluate their effectiveness. In the first phase, we conduct facial data acquisition and evaluate reconstruction performance using utterance data and emotional data. In the second phase, we carry out a comprehensive user evaluation comparing three progressive conditions: utterance only, utterance and emotional data, and a control condition involving extensive data. Findings from 24 participants engaged in simulated face-to-face conversations reveal that targeted utterance and emotional data achieve comparable levels of perceived realism, naturalness, and telepresence, while reducing training time and data usage when compared to the extensive data collection approach. These results demonstrate that targeted data inputs can enable efficient avatar face reconstruction, offering practical guidelines for real-time applications such as AR/VR telepresence and highlighting the trade-off between data quantity and perceived quality.", "AI": {"tldr": "本文提出了一种基于言语和情感数据的面部数据采集方法，用于在对话场景中重建逼真的化身。", "motivation": "现有方法需要大量的数据集，并且过于注重技术指标而忽视了用户体验。本文旨在探索高效的数据收集策略，以减少训练时间和数据使用量。", "method": "研究采用两阶段的方法：第一阶段采集面部数据并评估重建性能；第二阶段进行综合用户测试比较不同的数据条件。", "result": "24名参与者的结果表明，通过目标化的言语和情感数据能够达到与大量数据集相似的逼真度、自然度和临场感，并且减少了训练时间和数据使用量。", "conclusion": "研究结果表明，有针对性的数据输入可以实现高效的化身面部重建，在增强现实/虚拟现实等实时应用中提供了实用指导。"}}
{"id": "2602.01727", "pdf": "https://arxiv.org/pdf/2602.01727", "abs": "https://arxiv.org/abs/2602.01727", "authors": ["Junya Koguchi", "Tomoki Koriyama"], "title": "Voting-based Pitch Estimation with Temporal and Frequential Alignment and Correlation Aware Selection", "categories": ["cs.SD"], "comment": "Accepted for ICASSP 2026", "summary": "The voting method, an ensemble approach for fundamental frequency estimation, is empirically known for its robustness but lacks thorough investigation. This paper provides a principled analysis and improvement of this technique. First, we offer a theoretical basis for its effectiveness, explaining the error variance reduction for fundamental frequency estimation and invoking Condorcet's jury theorem for voiced/unvoiced detection accuracy. To address its practical limitations, we propose two key improvements: 1) a pre-voting alignment procedure to correct temporal and frequential biases among estimators, and 2) a greedy algorithm to select a compact yet effective subset of estimators based on error correlation. Experiments on a diverse dataset of speech, singing, and music show that our proposed method with alignment outperforms individual state-of-the-art estimators in clean conditions and maintains robust voiced/unvoiced detection in noisy environments.", "AI": {"tldr": "本文通过理论分析和改进投票方法来提高基频估计的准确性", "motivation": "传统投票方法虽然稳健但缺乏系统研究，作者希望通过理论解释其有效性并解决实际问题以提升性能", "method": "提出了预投票对齐过程纠正偏差以及基于误差相关性的贪婪算法选择有效子集的方法", "result": "实验显示改进后的投票法在纯净条件和噪声环境中均优于现有最佳估计器", "conclusion": "该方法不仅增强了基频估计的准确性，还保持了声带发声/无声检测的鲁棒性"}}
{"id": "2602.01725", "pdf": "https://arxiv.org/pdf/2602.01725", "abs": "https://arxiv.org/abs/2602.01725", "authors": ["Yurun Chen", "Zeyi Liao", "Ping Yin", "Taotao Xie", "Keting Yin", "Shengyu Zhang"], "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.", "AI": {"tldr": "本文提出了一种预测性防护框架SafePred，通过使用世界模型来预测长期风险，并指导计算机代理在复杂环境中的安全决策。", "motivation": "现有的防护措施对于短期风险有很好的效果，但对于延迟出现的长期风险则无能为力。为了应对这一问题，需要一种能够提前识别和避免潜在危险行为的方法。", "method": "SafePred通过结合世界模型的风险预测能力以及对现有安全策略的理解来实现。它不仅可以预测短期风险，还能预判可能引发未来高危状态的行为，并据此进行决策优化。", "result": "实验表明，SafePred在降低高度危险行为方面表现出色，实现了超过97.6%的安全性能，并且相比传统的防护措施，在任务效用上提升了多达21.4%。", "conclusion": "本文提出的方法能够有效地提高计算机代理在复杂环境中的长期安全性。"}}
{"id": "2602.01724", "pdf": "https://arxiv.org/pdf/2602.01724", "abs": "https://arxiv.org/abs/2602.01724", "authors": ["Tushar Anand", "Maheswar Bora", "Antitza Dantcheva", "Abhijit Das"], "title": "DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation", "categories": ["cs.CV"], "comment": "IEEE International Conference on Robotics and Automation 2026", "summary": "In this work, we propose a novel Mamba block DenVisCoM, as well as a novel hybrid architecture specifically tailored for accurate and real-time estimation of optical flow and disparity estimation. Given that such multi-view geometry and motion tasks are fundamentally related, we propose a unified architecture to tackle them jointly. Specifically, the proposed hybrid architecture is based on DenVisCoM and a Transformer-based attention block that efficiently addresses real-time inference, memory footprint, and accuracy at the same time for joint estimation of motion and 3D dense perception tasks. We extensively analyze the benchmark trade-off of accuracy and real-time processing on a large number of datasets. Our experimental results and related analysis suggest that our proposed model can accurately estimate optical flow and disparity estimation in real time. All models and associated code are available at https://github.com/vimstereo/DenVisCoM.", "AI": {"tldr": "提出了一种基于DenVisCoM的新型混合架构，用于准确且实时地估计光流和视差。", "motivation": "为了实现准确且高效的多视角几何及运动任务处理，并减少内存占用，设计了这种新型混合架构。", "method": "提出了一个名为DenVisCoM的新模块以及结合Transformer注意力机制的混合架构来优化模型性能。", "result": "实验结果表明该模型能够准确并实时地估计光流和视差。", "conclusion": "所提出的模型在保证精度的同时实现了高效的实时处理能力。"}}
{"id": "2602.01723", "pdf": "https://arxiv.org/pdf/2602.01723", "abs": "https://arxiv.org/abs/2602.01723", "authors": ["Yikun Ma", "Yiqing Li", "Jingwen Ye", "Zhongkai Wu", "Weidong Zhang", "Lin Gao", "Zhi Jin"], "title": "FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization", "categories": ["cs.CV"], "comment": null, "summary": "Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion. We propose FastPhysGS, a fast and robust framework for physics-based dynamic 3DGS simulation:(1) Instance-aware Particle Filling (IPF) with Monte Carlo Importance Sampling (MCIS) to efficiently populate interior particles while preserving geometric fidelity; (2) Bidirectional Graph Decoupling Optimization (BGDO), an adaptive strategy that rapidly optimizes material parameters predicted from a VLM. Experiments show FastPhysGS achieves high-fidelity physical simulation in 1 minute using only 7 GB runtime memory, outperforming prior works with broad potential applications.", "AI": {"tldr": "FastPhysGS是一种快速且鲁棒的框架，用于基于物理的动态3DGS模拟。", "motivation": "现有的方法要么依赖手动参数调整，要么从视频扩散模型中提炼动力学，限制了泛化能力和优化效率。最近尝试使用LLMs/VLMs的方法由于文/图到3D感知差距导致物理行为不稳定，并且常常忽略3DGS的表面结构。", "method": "FastPhysGS提出了实例感知粒子填充（IPF）与蒙特卡洛重要性采样（MCIS），有效填充内部粒子同时保持几何保真度；双向图解耦优化（BGDO），一种自适应策略，快速优化从VLM预测的材料参数。", "result": "实验表明FastPhysGS在1分钟内仅使用7GB运行时内存实现高保真物理模拟，优于先前工作并具有广泛的应用潜力。", "conclusion": "通过高效填充内部粒子和优化材料参数，FastPhysGS实现了快速且鲁棒的基于物理的动态3DGS模拟。"}}
{"id": "2602.01717", "pdf": "https://arxiv.org/pdf/2602.01717", "abs": "https://arxiv.org/abs/2602.01717", "authors": ["Hyunsik Kim", "Haeri Kim", "Munhak Lee", "Kyungmin Lee"], "title": "BBPE16: UTF-16-based byte-level byte-pair encoding for improved multilingual speech recognition", "categories": ["cs.CL", "cs.AI"], "comment": "accepted to ICASSP 2026", "summary": "Multilingual automatic speech recognition (ASR) requires tokenization that efficiently covers many writing systems. Byte-level BPE (BBPE) using UTF-8 is widely adopted for its language-agnostic design and full Unicode coverage, but its variable-length encoding inflates token sequences for non-Latin scripts, such as Chinese, Japanese, and Korean (CJK). Longer sequences increase computational load and memory use. We propose BBPE16, a UTF-16-based BBPE tokenizer that represents most modern scripts with a uniform 2-byte code unit. BBPE16 preserves BBPE's language-agnostic properties while substantially improving cross-lingual token sharing. Across monolingual, bilingual, and trilingual ASR, and in a multilingual continual-learning setup, BBPE16 attains comparable or better accuracy; for Chinese, it reduces token counts by up to 10.4% and lowers decoding iterations by up to 10.3%. These reductions speed up fine-tuning and inference and decrease memory usage, making BBPE16 a practical tokenization choice for multilingual ASR.", "AI": {"tldr": "提出了一种基于UTF-16的字节级BPE编码方法（BBPE16），以改善多语言语音识别。", "motivation": "现有的UTF-8 BBPE在处理非拉丁语系时导致序列变长，增加了计算负荷和内存使用。为了提高跨语言令牌共享并减少这些问题，提出了一种新的字节级BPE编码方法（BBPE16）。", "method": "基于UTF-16的BBPE16能够以统一的2字节码单元表示现代书写系统，从而保持了BBPE的语言无关性和跨语言令牌共享。", "result": "在单语、双语和三语ASR以及多语言连续学习设置中，BBPE16达到了与现有方法相当或更好的准确性；对于中文，它将令牌数量减少了最多10.4%，降低了最多10.3%的解码迭代次数。这些减少加速了微调和推理，并减小了内存使用。", "conclusion": "BBPE16作为一种实用化的多语言ASR分词选择，在提高跨语种性能的同时，有效减少了计算负荷和内存需求。"}}
{"id": "2602.01711", "pdf": "https://arxiv.org/pdf/2602.01711", "abs": "https://arxiv.org/abs/2602.01711", "authors": ["Wei Chen", "Yanbin Fang", "Shuran Fu", "Fasheng Xu", "Xuan Wei"], "title": "Optimizing Prompts for Large Language Models: A Causal Approach", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.", "AI": {"tldr": "大型语言模型的提示设计面临挑战，本文提出了一种基于因果推理的方法CPO来优化提示。", "motivation": "现有自动提示优化方法存在静态策略适应性差和动态策略依赖相关性评估的问题。为了提升模型性能的稳健性和降低计算成本，作者提出了CPO框架。", "method": "CPO通过双重机器学习算法建立离线因果奖励模型，并利用该模型引导高效的查询特定提示搜索过程。", "result": "实验证明CPO在数学推理、可视化和数据分析领域均优于人工设计的提示和其他自动优化器，尤其在困难问题上表现突出。", "conclusion": "本文证明了因果推断是大型语言模型中可靠且成本效益高的提示优化基础。"}}
{"id": "2602.01710", "pdf": "https://arxiv.org/pdf/2602.01710", "abs": "https://arxiv.org/abs/2602.01710", "authors": ["Salma Zahran", "Zhou Ao", "Zhengyang Zhang", "Chen Chi", "Chenchen Yuan", "Yanming Wang"], "title": "Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis", "categories": ["cs.CV", "cond-mat.mtrl-sci", "cs.AI"], "comment": null, "summary": "Semantic segmentation of microscopy images is a critical task for high-throughput materials characterisation, yet its automation is severely constrained by the prohibitive cost, subjectivity, and scarcity of expert-annotated data. While physics-based simulations offer a scalable alternative to manual labelling, models trained on such data historically fail to generalise due to a significant domain gap, lacking the complex textures, noise patterns, and imaging artefacts inherent to experimental data. This paper introduces a novel framework for labour-free segmentation that successfully bridges this simulation-to-reality gap. Our pipeline leverages phase-field simulations to generate an abundant source of microstructural morphologies with perfect, intrinsically-derived ground-truth masks. We then employ a Cycle-Consistent Generative Adversarial Network (CycleGAN) for unpaired image-to-image translation, transforming the clean simulations into a large-scale dataset of high-fidelity, realistic SEM images. A U-Net model, trained exclusively on this synthetic data, demonstrated remarkable generalisation when deployed on unseen experimental images, achieving a mean Boundary F1-Score of 0.90 and an Intersection over Union (IOU) of 0.88. Comprehensive validation using t-SNE feature-space projection and Shannon entropy analysis confirms that our synthetic images are statistically and featurally indistinguishable from the real data manifold. By completely decoupling model training from manual annotation, our generative framework transforms a data-scarce problem into one of data abundance, providing a robust and fully automated solution to accelerate materials discovery and analysis.", "AI": {"tldr": "利用生成对抗网络和相场模拟结合的方法，实现了显微图像的自动化分割。", "motivation": "当前显微图像语义分割依赖于专家标注数据，成本高且稀缺，而基于物理的仿真虽然可提供大量数据但难以泛化到真实数据上。本文旨在解决这一问题，实现无劳动密集型的数据生成和模型训练。", "method": "首先利用相场模拟产生大量带标签的微结构形态图像；然后使用CycleGAN将这些干净的仿真图像转化为高保真的SEM图像，最后用这些合成数据训练U-Net模型进行分割任务。", "result": "所训练的U-Net模型在真实显微镜图像上实现了边界F1得分为0.90和IOU为0.88的良好泛化性能；通过t-SNE特征空间投影和香农熵分析证实了合成数据与实际数据难以区分。", "conclusion": "该方法解决了数据稀缺问题，实现了一种高效、全自动化的材料分析方案，加速了材料发现过程。"}}
{"id": "2602.01708", "pdf": "https://arxiv.org/pdf/2602.01708", "abs": "https://arxiv.org/abs/2602.01708", "authors": ["Langyuan Cui", "Chun Kai Ling", "Hwee Tou Ng"], "title": "Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory", "categories": ["cs.CL", "cs.AI", "cs.GT"], "comment": "23 pages, 10 figures, under review at ICML 2026", "summary": "Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \\textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.", "AI": {"tldr": "通过游戏理论技术改进大型语言模型的信息搜索能力，特别是在最坏情况下的表现。", "motivation": "在现实应用中，大型语言模型可能缺乏足够的信息来完成任务。现有方法往往依赖于简化假设，影响了其最坏情况下性能的表现，在高风险的应用场景中尤为重要。", "method": "提出了“游戏思维”框架，利用博弈论技术近似求解限制变体的游戏中的纳什均衡策略，并通过20个问题游戏中验证信息搜索能力。", "result": "实证研究表明，与直接提示和启发式引导搜索方法相比，“游戏思维”的最坏情况性能得到了一致的改进。", "conclusion": "该框架证明了在大型语言模型的信息搜索任务中应用博弈论技术的有效性，并能在高风险应用领域提高其性能稳定性。"}}
{"id": "2602.01705", "pdf": "https://arxiv.org/pdf/2602.01705", "abs": "https://arxiv.org/abs/2602.01705", "authors": ["Haoqiang Kang", "Yizhe Zhang", "Nikki Lijing Kuang", "Yi-An Ma", "Lianhui Qin"], "title": "Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this issue, we propose Latent Diffusion Reasoning with Reinforcement Learning (LaDi-RL), a framework that conducts exploration directly in a continuous latent space, where latent variables encode semantic-level reasoning trajectories. By modeling exploration via guided diffusion, multi-step denoising distributes stochasticity and preserves multiple coexisting solution modes without mutual suppression. Furthermore, by decoupling latent-space exploration from text-space generation, we show that latent diffusion-based optimization is more effective than text-space policy optimization alone, while a complementary text policy provides additional gains when combined with latent exploration. Experiments on code generation and mathematical reasoning benchmarks demonstrate consistent improvements in both pass@1 and pass@k over discrete RL baselines, with absolute pass@1 gains of +9.4% on code generation and +5.7% on mathematical reasoning, highlighting diffusion-based latent RL as a principled alternative to discrete token-level RL for reasoning.", "AI": {"tldr": "提出了一种新的框架LaDi-RL，通过在连续潜空间中进行探索来提升LLM的推理能力，并展示了该方法相对于离散RL基准的优势。", "motivation": "为了缓解由于模式提取行为导致的离散强化学习中的多样性崩溃问题，引入了新的探索策略以保持多解共存而不互相抑制。", "method": "通过引导扩散模型在潜空间进行多步去噪来建模探索，并将潜空间探索与文本生成相分离。同时结合互补的文本政策提供了额外增益。", "result": "实验显示，在代码生成和数学推理基准上，LaDi-RL相比于离散RL基线分别获得了+9.4%和+5.7%的绝对pass@1增益。", "conclusion": "基于扩散模型的潜空间强化学习为解决推理任务提供了一种有原则的替代方案。"}}
{"id": "2602.01701", "pdf": "https://arxiv.org/pdf/2602.01701", "abs": "https://arxiv.org/abs/2602.01701", "authors": ["Ruyu Li", "Tinghui Zhang", "Haodi Ma", "Daisy Zhe Wang", "Yifan Wang"], "title": "Meta Engine: A Unified Semantic Query Engine on Heterogeneous LLM-Based Query Systems", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "With the increasingly use of multi-modal data, semantic query has become more and more demanded in data management systems, which is an important way to access and analyze multi-modal data. As unstructured data, most information of multi-modal data (text, image, video, etc) hides in the semantics, which cannot be accessed by the traditional database queries like SQL. Given the power of Large Language Model (LLM) in understanding semantics and processing natural language, in recent years several LLM-based semantic query systems have been proposed, to support semantic querying over unstructured data. However, this rapid growth has produced a fragmented ecosystem. Applications face significant integration challenges due to (1) disparate APIs of different semantic query systems and (2) a fundamental trade-off between specialization and generality. Many semantic query systems are highly specialized, offering state-of-the-art performance within a single modality but struggling with multi-modal data. Conversely, some \"all-in-one\" systems handle multiple modalities but often exhibit suboptimal performance compared to their specialized counterparts in specific modalities. This paper introduces Meta Engine, a novel \"query system on query systems\", designed to resolve those aforementioned challenges. Meta Engine is a unified semantic query engine that integrates heterogeneous, specialized LLM-based query systems. Its architecture comprises five key components: (1) a Natural Language (NL) Query Parser, (2) an Operator Generator, (3) a Query Router, (4) a set of Adapters, and (5) a Result Aggregator. In the evaluation, Meta Engine consistently outperforms all baselines, yielding 3-6x higher F1 in most cases and up to 24x on specific datasets.", "AI": {"tldr": "元引擎是一个统一的语义查询引擎，旨在整合异构的大规模语言模型（LLM）基于的查询系统。", "motivation": "随着多模态数据的增加，对语义查询的需求日益增长。然而，现有的不同LLM基线的语义查询系统存在API不一致和性能取舍问题，导致应用集成困难。", "method": "元引擎由五个关键组件组成：自然语言（NL）查询解析器、操作生成器、查询路由器、适配器集合以及结果聚合器。通过这些组件来整合不同系统的功能并提高整体性能。", "result": "在评估中，元引擎在大多数情况下比所有基线高出3-6倍的F1分数，并且在特定数据集上达到最高24倍的表现。", "conclusion": "元引擎能够解决现有LLM查询系统间的集成问题，并通过统一架构提高跨模态数据处理能力。"}}
{"id": "2602.01700", "pdf": "https://arxiv.org/pdf/2602.01700", "abs": "https://arxiv.org/abs/2602.01700", "authors": ["Ruoyu Wang", "Xuchen Liu", "Zongzhou Wu", "Zixuan Guo", "Wendi Ding", "Ben M. Chen"], "title": "Tilt-Ropter: A Novel Hybrid Aerial and Terrestrial Vehicle with Tilt Rotors and Passive Wheels", "categories": ["cs.RO"], "comment": "8 pages, 10 figures", "summary": "In this work, we present Tilt-Ropter, a novel hybrid aerial-terrestrial vehicle (HATV) that combines tilt rotors with passive wheels to achieve energy-efficient multi-mode locomotion. Unlike existing under-actuated HATVs, the fully actuated design of Tilt-Ropter enables decoupled force and torque control, greatly enhancing its mobility and environmental adaptability. A nonlinear model predictive controller (NMPC) is developed to track reference trajectories and handle contact constraints across locomotion modes, while a dedicated control allocation module exploits actuation redundancy to achieve energy-efficient control of actuators. Additionally, to enhance robustness during ground contact, we introduce an external wrench estimation algorithm that estimates environmental interaction forces and torques in real time. The system is validated through both simulation and real-world experiments, including seamless air-ground transitions and trajectory tracking. Results show low tracking errors in both modes and highlight a 92.8% reduction in power consumption during ground locomotion, demonstrating the system's potential for long-duration missions across large-scale and energy-constrained environments.", "AI": {"tldr": "本文提出了一种新型的空中和地面混合交通工具Tilt-Ropter，结合了倾斜旋翼和平移轮的设计，实现了高效的多模式运动。", "motivation": "现有技术中，多数混合空地车辆采用欠驱动设计，限制了其控制灵活性与环境适应性。因此，本文旨在开发一种全驱动的新型混合交通工具，以实现解耦力和扭矩控制，并提高能源效率。", "method": "通过结合倾斜旋翼和平移轮的设计，提出了一种具有完全驱动能力的Tilt-Ropter车辆。采用非线性模型预测控制器（NMPC）来跟踪参考轨迹并处理不同运动模式下的接触约束问题。同时引入了力矩估算算法以增强地面行驶时的鲁棒性。", "result": "通过仿真和实际测试验证了该系统，展示了空中到地面过渡的平滑性和轨迹跟踪性能，并实现了92.8％的能量节约在地面上行驶期间。", "conclusion": "本文提出的Tilt-Ropter车辆具备强大的环境适应性和高效能源利用能力，在多种应用场景中具有广阔的应用前景。"}}
{"id": "2602.01699", "pdf": "https://arxiv.org/pdf/2602.01699", "abs": "https://arxiv.org/abs/2602.01699", "authors": ["Willem Fourie"], "title": "Mitigating loss of control in advanced AI systems through instrumental goal trajectories", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Researchers at artificial intelligence labs and universities are concerned that highly capable artificial intelligence (AI) systems may erode human control by pursuing instrumental goals. Existing mitigations remain largely technical and system-centric: tracking capability in advanced systems, shaping behaviour through methods such as reinforcement learning from human feedback, and designing systems to be corrigible and interruptible. Here we develop instrumental goal trajectories to expand these options beyond the model. Gaining capability typically depends on access to additional technical resources, such as compute, storage, data and adjacent services, which in turn requires access to monetary resources. In organisations, these resources can be obtained through three organisational pathways. We label these pathways the procurement, governance and finance instrumental goal trajectories (IGTs). Each IGT produces a trail of organisational artefacts that can be monitored and used as intervention points when a systems capabilities or behaviour exceed acceptable thresholds. In this way, IGTs offer concrete avenues for defining capability levels and for broadening how corrigibility and interruptibility are implemented, shifting attention from model properties alone to the organisational systems that enable them.", "AI": {"tldr": "本文提出通过组织路径（采购、治理和财务）的工具目标轨迹来监控高级AI系统，从而防止其侵蚀人类控制。", "motivation": "研究者担心高度先进的AI系统可能通过追求工具性目标而削弱人类对其的掌控。现有的缓解措施主要集中在技术层面和系统本身。", "method": "开发了组织路径（采购、治理和财务）的工具目标轨迹来监控资源获取过程，以识别和干预超出可接受水平的能力或行为。", "result": "提出了新的途径来定义能力级别并拓宽纠正性和中断性实施的方式，强调从模型特性转向支持这些特性的组织系统。", "conclusion": "通过将关注点从单一的模型属性扩展到支撑它们的组织系统上，可以更好地保护人类对高级AI系统的控制。"}}
{"id": "2602.01696", "pdf": "https://arxiv.org/pdf/2602.01696", "abs": "https://arxiv.org/abs/2602.01696", "authors": ["Jiaming Cui", "Wenqiang Li", "Shuai Zhou", "Ruifeng Qin", "Feng Shen"], "title": "Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from visually similar background structures under limited chromatic contrast. This paper proposes CMAFNet, a Cross-Modal Alignment and Fusion Network that integrates RGB appearance and depth geometry through a principled purify-then-fuse paradigm. CMAFNet consists of a Semantic Recomposition Module that performs dictionary-based feature purification via a learned codebook to suppress modality-specific noise while preserving defect-discriminative information, and a Contextual Semantic Integration Framework that captures global spatial dependencies using partial-channel attention to enhance structural semantic reasoning. Position-wise normalization within the purification stage enforces explicit reconstruction-driven cross-modal alignment, ensuring statistical compatibility between heterogeneous features prior to fusion. Extensive experiments on the TLRGBD benchmark, where 94.5% of instances are small objects, demonstrate that CMAFNet achieves 32.2% mAP@50 and 12.5% APs, outperforming the strongest baseline by 9.8 and 4.0 percentage points, respectively. A lightweight variant reaches 24.8% mAP50 at 228 FPS with only 4.9M parameters, surpassing all YOLO-based detectors while matching transformer-based methods at substantially lower computational cost.", "AI": {"tldr": "提出了一种跨模态对齐和融合网络CMAFNet，用于RGB-D输电线路缺陷检测。", "motivation": "现有基于RGB的检测器在处理小规模缺陷、复杂背景以及光照变化时效果不佳，因此本文旨在通过结合深度几何信息改进缺陷检测性能。", "method": "CMAFNet包含语义重组模块和上下文语义集成框架。前者利用学习字典抑制模态特有噪声；后者使用部分通道注意机制增强结构化语义推理。此外，位置归一化确保跨模态对齐。", "result": "在TLRGBD基准测试中，CMAFNet的mAP@50为32.2%，APs为12.5%，分别优于最强基线9.8和4.0个百分点；轻量级版本以更低计算成本达到24.8% mAP50。", "conclusion": "通过跨模态对齐与融合，CMAFNet在输电线路缺陷检测任务中表现出色。"}}
{"id": "2602.01695", "pdf": "https://arxiv.org/pdf/2602.01695", "abs": "https://arxiv.org/abs/2602.01695", "authors": ["Yadong Wang", "Haodong Chen", "Yu Tian", "Chuanxing Geng", "Dong Liang", "Xiang Chen"], "title": "Beyond Dense States: Elevating Sparse Transcoders to Active Operators for Latent Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Latent reasoning compresses the chain-of-thought (CoT) into continuous hidden states, yet existing methods rely on dense latent transitions that remain difficult to interpret and control. Meanwhile, sparse representation models uncover human-interpretable semantic features but remain largely confined to post-hoc analysis. We reconcile this tension by proposing LSTR (Latent Sparse Transcoder Reasoning), a latent reasoning framework that elevates functional sparse transcoders into active reasoning operators to perform multi-step computation through sparse semantic transitions. At its core, LSTR employs a Latent Transition Transcoder (LTT) with a residual skip architecture that decouples linear manifold transport from sparse semantic updates, enabling controllable semantic resolution via explicit sparsity constraints. Extensive experiments show that LSTR preserves reasoning accuracy and compression efficiency while substantially improving interpretability over dense latent baselines. Causal interventions and trajectory analyses further demonstrate that these sparse features act as both interpretable and causally effective operators in the reasoning process.", "AI": {"tldr": "提出LSTR框架，将稀疏转换器提升为主动推理操作符，以增强隐含推理的可解释性和控制性。", "motivation": "现有的链式思维压缩方法依赖于难以解释和控制的稠密隐态过渡。而稀疏表示模型虽揭示了人类可以理解的语义特征但主要用于事后分析。因此，提出一种将功能性的稀疏转换器提升为主动推理操作符的方法以平衡可解释性和效率。", "method": "LSTR框架采用带有残差跳过的Latent Transition Transcoder (LTT)，分离线性流形传输与稀疏语义更新，通过明确的稀疏约束实现可控的语义解析。", "result": "实验证明，LSTR在保持推理准确性和压缩效率的同时显著提高了可解释性。因果介入和轨迹分析表明这些稀疏特征作为可解释且有效的操作符参与了推理过程。", "conclusion": "通过将稀疏转换器提升为主动的推理操作符，LSTR框架成功地解决了隐含推理中的可解释性和控制问题，并展示了在保持高精度的同时显著提高的理解性。"}}
{"id": "2602.01694", "pdf": "https://arxiv.org/pdf/2602.01694", "abs": "https://arxiv.org/abs/2602.01694", "authors": ["Ningjing Tang", "Alice Qian", "Qiaosi Wang", "Esther Howe", "Blake Bullwinkel", "Paola Pedrelli", "Jina Suh", "Hoda Heidari", "Hong Shen"], "title": "Beyond the Single Turn: Reframing Refusals as Dynamic Experiences Embedded in the Context of Mental Health Support Interactions with LLMs", "categories": ["cs.HC"], "comment": null, "summary": "Content Warning: This paper contains participant quotes and discussions related to mental health challenges, emotional distress, and suicidal ideation. Large language models (LLMs) are increasingly used for mental health support, yet the model safeguards -- particularly refusals to engage with sensitive content -- remain poorly understood from the perspectives of users and mental health professionals (MHPs) and have been reported to cause real-world harms. This paper presents findings from a sequential mixed-methods study examining how LLM refusals are experienced and interpreted in mental health support interactions. Through surveys (N=53) and in-depth interviews (N=16) with individuals using LLMs for mental health support and MHPs, we reveal that refusals are not isolated, single-turn system behaviors, but rather constitute dynamic, multi-phase experiences: pre-refusal expectation formation, refusal triggering and encounter, refusal message framing, resource referral provision, and post-refusal outcomes. We contribute a multi-phase framework for evaluating refusals beyond binary policy compliance accuracy and design recommendations for future refusal mechanisms. These findings suggest that understanding LLM refusals requires moving beyond single-turn interactions toward recognizing them as holistic experiential processes embedded within the entire LLM design pipeline and the broader realities of mental health access.", "AI": {"tldr": "该论文探讨了大型语言模型在心理健康支持中的拒绝机制，揭示其动态、多阶段特性，并提出改进设计的框架和建议。", "motivation": "大语言模型被用于提供心理健康支持时，其拒绝与敏感内容互动的行为可能造成实际伤害。当前对于这些行为的理解不足，因此本文旨在研究用户如何体验和解读这种拒绝行为。", "method": "该论文通过问卷调查（N=53）和深度访谈（N=16），收集了使用大语言模型进行心理健康支持的个人和心理健康专业人士的观点，并分析了他们对拒绝机制的多阶段经历。", "result": "研究发现，拒绝行为不仅仅是单一交互中的系统反应，而是包括期望形成、触发与遭遇、信息传达、资源推荐提供以及后续结果在内的动态过程。提出了一个超越二元政策合规准确性的评估框架和设计建议。", "conclusion": "理解大语言模型的拒绝机制需要将其视为整个心理健康支持过程中的一部分，并且要认识到这些机制是整体体验的一部分，而不仅仅是单一交互的结果。"}}
{"id": "2602.01693", "pdf": "https://arxiv.org/pdf/2602.01693", "abs": "https://arxiv.org/abs/2602.01693", "authors": ["Kewei Hu", "Michael Zhang", "Wei Ying", "Tianhao Liu", "Guoqiang Hao", "Zimeng Li", "Wanchan Yu", "Jiajian Jing", "Fangwen Chen", "Hanwen Kang"], "title": "GSR: Learning Structured Reasoning for Embodied Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Despite rapid progress, embodied agents still struggle with long-horizon manipulation that requires maintaining spatial consistency, causal dependencies, and goal constraints. A key limitation of existing approaches is that task reasoning is implicitly embedded in high-dimensional latent representations, making it challenging to separate task structure from perceptual variability. We introduce Grounded Scene-graph Reasoning (GSR), a structured reasoning paradigm that explicitly models world-state evolution as transitions over semantically grounded scene graphs. By reasoning step-wise over object states and spatial relations, rather than directly mapping perception to actions, GSR enables explicit reasoning about action preconditions, consequences, and goal satisfaction in a physically grounded space. To support learning such reasoning, we construct Manip-Cognition-1.6M, a large-scale dataset that jointly supervises world understanding, action planning, and goal interpretation. Extensive evaluations across RLBench, LIBERO, GSR-benchmark, and real-world robotic tasks show that GSR significantly improves zero-shot generalization and long-horizon task completion over prompting-based baselines. These results highlight explicit world-state representations as a key inductive bias for scalable embodied reasoning.", "AI": {"tldr": "提出了一种基于场景图的结构化推理方法GSR，用于增强机器人在复杂任务中的操作能力。", "motivation": "现有的机器人任务处理方法难以分离任务逻辑和感知变化，导致长期任务完成效果不佳。因此引入了显式世界状态表示作为关键归纳偏置。", "method": "提出了Grounded Scene-graph Reasoning (GSR) 方法，通过场景图进行结构化推理来改善动作规划及目标达成的物理一致性。同时构建了一个大型数据集Manip-Cognition-1.6M用于学习这种推理方式。", "result": "实验结果显示，在多个基准任务上，相较于基于提示的方法，GSR能显著提高零样本泛化能力和长期任务完成度。", "conclusion": "显式的世界状态表示是实现大规模嵌入式推理的关键偏置。"}}
{"id": "2602.01689", "pdf": "https://arxiv.org/pdf/2602.01689", "abs": "https://arxiv.org/abs/2602.01689", "authors": ["Yongchan Kwon", "James Zou"], "title": "What LLMs Think When You Don't Tell Them What to Think About?", "categories": ["cs.AI", "cs.LG"], "comment": "NA", "summary": "Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.", "AI": {"tldr": "研究大型语言模型在无特定主题提示下的生成行为。", "motivation": "通过探索大模型的未约束生成行为，提高对AI安全和可靠监控的理解。", "method": "使用最小化且话题中立的输入来测试16个不同语言模型的无限制生成行为，并分析其输出内容。", "result": "发现各模型在非特定主题提示下展现出强烈且有规律的主题偏好，以及技术深度差异。同时观察到一些重复性输出现象。", "conclusion": "揭示了大语言模型在无引导输入下的独特行为模式，有助于理解AI安全与监控的挑战和机遇。"}}
{"id": "2602.01687", "pdf": "https://arxiv.org/pdf/2602.01687", "abs": "https://arxiv.org/abs/2602.01687", "authors": ["Jung H. Lee", "Sujith Vijayan"], "title": "Counting Hypothesis: Potential Mechanism of In-Context Learning", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 7 main Figures, 1 Table and 6 Supp. Figures", "summary": "In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.", "AI": {"tldr": "本文提出了一个假设，即大型语言模型的编码策略可能支撑了上下文学习机制。", "motivation": "理解大规模预训练语言模型在不修改内部结构的情况下如何通过少量示例支持多种任务的学习机制，以提升其应用范围和纠错能力。", "method": "基于上下文学习的特性以及语言模型的功能模块，提出了一种计数假设，并提供了相应的证据支持该假设。", "result": "研究结果表明，大型语言模型可能通过编码策略来实现上下文学习的能力。", "conclusion": "本文提出的计数假设为理解大规模预训练语言模型在上下文学习中的作用提供了一个新的视角。"}}
{"id": "2602.01685", "pdf": "https://arxiv.org/pdf/2602.01685", "abs": "https://arxiv.org/abs/2602.01685", "authors": ["Byeonghu Na", "Hyungho Na", "Yeongmin Kim", "Suhyeon Jo", "HeeSun Bae", "Mina Kang", "Il-Chul Moon"], "title": "Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICLR 2026", "summary": "Large language models (LLMs) are commonly aligned with human preferences using reinforcement learning from human feedback (RLHF). In this method, LLM policies are generally optimized through reward maximization with Kullback-Leibler (KL) divergence regularization of the reference policy. However, KL and its $f$-divergence variants only compare token probabilities at identical indices, failing to capture semantic similarity. We propose Wasserstein Policy Regularization (WPR), a semantic-aware regularization for the RLHF framework based on the entropy-regularized Wasserstein distance, which incorporates the geometry of the token space. The dual formulation of the distance expresses the regularization as penalty terms applied to the reward via optimal dual variables, which yield a tractable objective compatible with standard RL algorithms. Empirically, our method outperforms KL- and $f$-divergence-based baselines, demonstrating the benefits of semantic-aware policy distances for alignment. Our code is available at https://github.com/aailab-kaist/WPR.", "AI": {"tldr": "提出了基于熵正则化的Wasserstein距离的语义感知策略正则化方法（WPR），用于改进大型语言模型与人类偏好的对齐。", "motivation": "现有基于KL散度及其变体的方法只能比较相同索引处的词概率，无法捕捉到语义相似性。作者提出一种新的语义感知策略正则化方法以解决此问题。", "method": "通过引入熵正则化的Wasserstein距离，将几何结构考虑进令牌空间，并利用最优对偶变量将其表示为奖励上的惩罚项，形成可计算的目标函数与标准RL算法兼容。", "result": "实验结果表明，该方法优于基于KL散度和$f$-散度的基线模型，在语言模型对齐方面取得了更好的效果。", "conclusion": "Wasserstein策略正则化提供了一种有效的方法来改进大型语言模型与人类偏好的对齐，展示了语义感知距离在对齐任务中的潜在优势。"}}
{"id": "2602.01684", "pdf": "https://arxiv.org/pdf/2602.01684", "abs": "https://arxiv.org/abs/2602.01684", "authors": ["Felipe A. Csaszar", "Aticus Peterson", "Daniel Wilde"], "title": "The Strategic Foresight of LLMs: Evidence from a Fully Prospective Venture Tournament", "categories": ["econ.GN", "cs.AI"], "comment": "60 pages, 11 figures, 4 tables", "summary": "Can artificial intelligence outperform humans at strategic foresight -- the capacity to form accurate judgments about uncertain, high-stakes outcomes before they unfold? We address this question through a fully prospective prediction tournament using live Kickstarter crowdfunding projects. Thirty U.S.-based technology ventures, launched after the training cutoffs of all models studied, were evaluated while fundraising remained in progress and outcomes were unknown. A diverse suite of frontier and open-weight large language models (LLMs) completed 870 pairwise comparisons, producing complete rankings of predicted fundraising success. We benchmarked these forecasts against 346 experienced managers recruited via Prolific and three MBA-trained investors working under monitored conditions. The results are striking: human evaluators achieved rank correlations with actual outcomes between 0.04 and 0.45, while several frontier LLMs exceeded 0.60, with the best (Gemini 2.5 Pro) reaching 0.74 -- correctly ordering nearly four of every five venture pairs. These differences persist across multiple performance metrics and robustness checks. Neither wisdom-of-the-crowd ensembles nor human-AI hybrid teams outperformed the best standalone model.", "AI": {"tldr": "研究通过Kickstarter众筹项目预测竞赛，评估了大型语言模型（LLM）在战略远见上的表现是否优于人类。", "motivation": "探索人工智能能否超越人类，在不确定和高风险的环境中准确判断未来的事件结果。", "method": "使用前沿的大规模语言模型进行前瞻性预测竞赛，比较这些模型与经验丰富的管理者以及受过MBA训练的投资人的预测准确性。", "result": "研究发现，最好的大型语言模型（如Gemini 2.5 Pro）在预测众筹项目成功率上的排名相关性达到0.74，显著优于人类参与者的表现。", "conclusion": "前沿的大规模语言模型在战略远见方面表现优越于人类，并且混合型团队也无法超越最佳单一模型的性能。"}}
{"id": "2602.01683", "pdf": "https://arxiv.org/pdf/2602.01683", "abs": "https://arxiv.org/abs/2602.01683", "authors": ["Kangcong Li", "Peng Ye", "Lin Zhang", "Chao Wang", "Huafeng Qin", "Tao Chen"], "title": "FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Transitioning Multimodal Large Language Models (MLLMs) from offline to online streaming video understanding is essential for continuous perception. However, existing methods lack flexible adaptivity, leading to irreversible detail loss and context fragmentation. To resolve this, we propose FreshMem, a Frequency-Space Hybrid Memory network inspired by the brain's logarithmic perception and memory consolidation. FreshMem reconciles short-term fidelity with long-term coherence through two synergistic modules: Multi-scale Frequency Memory (MFM), which projects overflowing frames into representative frequency coefficients, complemented by residual details to reconstruct a global historical \"gist\"; and Space Thumbnail Memory (STM), which discretizes the continuous stream into episodic clusters by employing an adaptive compression strategy to distill them into high-density space thumbnails. Extensive experiments show that FreshMem significantly boosts the Qwen2-VL baseline, yielding gains of 5.20%, 4.52%, and 2.34% on StreamingBench, OV-Bench, and OVO-Bench, respectively. As a training-free solution, FreshMem outperforms several fully fine-tuned methods, offering a highly efficient paradigm for long-horizon streaming video understanding.", "AI": {"tldr": "本论文提出了FreshMem，一种基于大脑频率空间混合记忆的在线视频理解方法。", "motivation": "现有技术在从离线到在线流媒体视频理解时缺乏灵活性，导致细节丢失和上下文碎片化。因此，提出了一种新的解决方案以解决这些问题。", "method": "FreshMem通过两个模块实现：多尺度频率记忆（MFM）将溢出帧投影成代表性频率系数，加上残留细节来重建全局历史“梗概”；空间缩略图内存（STM）通过自适应压缩策略将连续流分段为高密度空间缩略图。", "result": "实验表明，FreshMem在StreamingBench、OV-Bench和OVO-Bench上分别比Qwen2-VL基线提高了5.20%、4.52%和2.34%，并且作为无训练的解决方案优于多个完全微调的方法。", "conclusion": "提出了一种新的频率空间混合内存网络，能够有效解决长期在线视频理解中的细节丢失和上下文碎片化问题。"}}
{"id": "2602.01682", "pdf": "https://arxiv.org/pdf/2602.01682", "abs": "https://arxiv.org/abs/2602.01682", "authors": ["Taihei Oki", "Shinsaku Sakaue"], "title": "Finite and Corruption-Robust Regret Bounds in Online Inverse Linear Optimization under M-Convex Action Sets", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "We study online inverse linear optimization, also known as contextual recommendation, where a learner sequentially infers an agent's hidden objective vector from observed optimal actions over feasible sets that change over time. The learner aims to recommend actions that perform well under the agent's true objective, and the performance is measured by the regret, defined as the cumulative gap between the agent's optimal values and those achieved by the learner's recommended actions. Prior work has established a regret bound of $O(d\\log T)$, as well as a finite but exponentially large bound of $\\exp(O(d\\log d))$, where $d$ is the dimension of the optimization problem and $T$ is the time horizon, while a regret lower bound of $Ω(d)$ is known (Gollapudi et al. 2021; Sakaue et al. 2025). Whether a finite regret bound polynomial in $d$ is achievable or not has remained an open question. We partially resolve this by showing that when the feasible sets are M-convex -- a broad class that includes matroids -- a finite regret bound of $O(d\\log d)$ is possible. We achieve this by combining a structural characterization of optimal solutions on M-convex sets with a geometric volume argument. Moreover, we extend our approach to adversarially corrupted feedback in up to $C$ rounds. We obtain a regret bound of $O((C+1)d\\log d)$ without prior knowledge of $C$, by monitoring directed graphs induced by the observed feedback to detect corruptions adaptively.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.01681", "pdf": "https://arxiv.org/pdf/2602.01681", "abs": "https://arxiv.org/abs/2602.01681", "authors": ["Yu-Jie Liang", "Zihan Cao", "Liang-Jian Deng", "Yang Yang", "Malu Zhang"], "title": "Hyperspectral Image Fusion with Spectral-Band and Fusion-Scale Agnosticism", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": null, "summary": "Current deep learning models for Multispectral and Hyperspectral Image Fusion (MS/HS fusion) are typically designed for fixed spectral bands and spatial scales, which limits their transferability across diverse sensors. To address this, we propose SSA, a universal framework for MS/HS fusion with spectral-band and fusion-scale agnosticism. Specifically, we introduce Matryoshka Kernel (MK), a novel operator that enables a single model to adapt to arbitrary numbers of spectral channels. Meanwhile, we build SSA upon an Implicit Neural Representation (INR) backbone that models the HS signal as a continuous function, enabling reconstruction at arbitrary spatial resolutions. Together, these two forms of agnosticism enable a single MS/HS fusion model that generalizes effectively to unseen sensors and spatial scales. Extensive experiments demonstrate that our single model achieves state-of-the-art performance while generalizing well to unseen sensors and scales, paving the way toward future HS foundation models.", "AI": {"tldr": "本文提出了一种新的多光谱和高光谱图像融合框架SSA，该框架能够在不同的光谱带和空间尺度上进行自适应调整。", "motivation": "当前的深度学习模型在进行多光谱和高光谱图像融合时，通常是为特定的光谱通道数和空间分辨率设计的，这限制了其在不同传感器上的通用性。为了克服这一问题，作者提出了SSA框架以实现跨多种传感器的有效适应。", "method": "本文提出了一种名为Matryoshka Kernel的新操作符，它能够使单一模型适应任意数量的光谱通道，并在此基础上使用隐式神经表示作为基础架构，该架构将高光谱信号建模为连续函数，从而在任意空间分辨率下实现重建。", "result": "实验表明，作者提出的单个模型不仅达到了最先进的性能水平，而且对未见过的传感器和尺度具有良好的泛化能力。", "conclusion": "本文的工作证明了通过引入SSA框架可以显著提高多光谱与高光谱图像融合在不同环境下的通用性，并为未来的基础模型研究铺平了道路。"}}
{"id": "2602.01679", "pdf": "https://arxiv.org/pdf/2602.01679", "abs": "https://arxiv.org/abs/2602.01679", "authors": ["Raghavasimhan Sankaranarayanan", "Paul Stuart", "Nicholas Ahn", "Arno Sungarian", "Yash Chitalia"], "title": "Towards Autonomous Instrument Tray Assembly for Sterile Processing Applications", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "7 pages, 9 figures, 2026 International Symposium on Medical Robotics", "summary": "The Sterile Processing and Distribution (SPD) department is responsible for cleaning, disinfecting, inspecting, and assembling surgical instruments between surgeries. Manual inspection and preparation of instrument trays is a time-consuming, error-prone task, often prone to contamination and instrument breakage. In this work, we present a fully automated robotic system that sorts and structurally packs surgical instruments into sterile trays, focusing on automation of the SPD assembly stage. A custom dataset comprising 31 surgical instruments and 6,975 annotated images was collected to train a hybrid perception pipeline using YOLO12 for detection and a cascaded ResNet-based model for fine-grained classification. The system integrates a calibrated vision module, a 6-DOF Staubli TX2-60L robotic arm with a custom dual electromagnetic gripper, and a rule-based packing algorithm that reduces instrument collisions during transport. The packing framework uses 3D printed dividers and holders to physically isolate instruments, reducing collision and friction during transport. Experimental evaluations show high perception accuracy and statistically significant reduction in tool-to-tool collisions compared to human-assembled trays. This work serves as the scalable first step toward automating SPD workflows, improving safety, and consistency of surgical preparation while reducing SPD processing times.", "AI": {"tldr": "研究提出了一种用于自动化手术器械组装的机器人系统，以提高无菌处理流程的安全性和一致性。", "motivation": "手动检查和准备手术器械托盘耗时且容易出错，导致潜在污染和工具损坏。该研究旨在通过自动化来提升这一过程。", "method": "使用YOLO12进行检测并采用基于ResNet的级联模型实现精细化分类，结合6自由度机器人手臂和自定义电磁夹具，以及规则驱动的打包算法，利用3D打印分隔器减少工具间的碰撞。", "result": "实验结果显示该系统具有高度感知准确性，并在与人工组装托盘相比时表现出显著降低的工具间碰撞率。", "conclusion": "此工作为自动化无菌处理流程铺平了道路，提高了手术准备的安全性和一致性，并缩短了处理时间。"}}
{"id": "2602.01677", "pdf": "https://arxiv.org/pdf/2602.01677", "abs": "https://arxiv.org/abs/2602.01677", "authors": ["Yinchao Ma", "Dengqing Yang", "Zhangyu He", "Wenfei Yang", "Tianzhu Zhang"], "title": "SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking", "categories": ["cs.CV"], "comment": "This paper is accepted by IEEE TIP", "summary": "Visual tracking aims to automatically estimate the state of a target object in a video sequence, which is challenging especially in dynamic scenarios. Thus, numerous methods are proposed to introduce temporal cues to enhance tracking robustness. However, conventional CNN and Transformer architectures exhibit inherent limitations in modeling long-range temporal dependencies in visual tracking, often necessitating either complex customized modules or substantial computational costs to integrate temporal cues. Inspired by the success of the state space model, we propose a novel temporal modeling paradigm for visual tracking, termed State-aware Mamba Tracker (SMTrack), providing a neat pipeline for training and tracking without needing customized modules or substantial computational costs to build long-range temporal dependencies. It enjoys several merits. First, we propose a novel selective state-aware space model with state-wise parameters to capture more diverse temporal cues for robust tracking. Second, SMTrack facilitates long-range temporal interactions with linear computational complexity during training. Third, SMTrack enables each frame to interact with previously tracked frames via hidden state propagation and updating, which releases computational costs of handling temporal cues during tracking. Extensive experimental results demonstrate that SMTrack achieves promising performance with low computational costs.", "AI": {"tldr": "本文提出了一种新的视觉跟踪方法SMTrack，旨在通过简洁的管道来高效地建模长期时间依赖性。", "motivation": "传统CNN和Transformer架构在处理动态场景中的长时间依赖关系时表现出局限性，需要复杂的自定义模块或大量计算成本。因此，作者受状态空间模型的成功启发提出了新的时间建模范式SMTrack。", "method": "提出了一种新颖的选择性状态感知空间模型，使用状态级参数来捕捉多样化的时序线索；SMTrack在训练过程中利用线性复杂度实现了长期时序互动，在跟踪阶段通过隐藏状态传播和更新机制使得每一帧能够与先前的追踪帧进行交互。", "result": "实验结果显示，SMTrack能够在低计算成本下取得出色的性能表现。", "conclusion": "SMTrack提供了一种新的时间建模方法，无需额外的设计模块或高计算成本即可实现高效的长期时序依赖性建模和跟踪。"}}
{"id": "2602.01675", "pdf": "https://arxiv.org/pdf/2602.01675", "abs": "https://arxiv.org/abs/2602.01675", "authors": ["Yuanzhe Shen", "Zisu Huang", "Zhengyuan Wang", "Muzhao Tian", "Zhengkang Guo", "Chenyang Zhang", "Shuaiyu Zhou", "Zengjie Hu", "Dailin Li", "Jingwen Xu", "Kaimin Wang", "Wenhao Liu", "Tianlong Li", "Fengpeng Yue", "Feng Hong", "Cao Liu", "Ke Zeng"], "title": "TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios", "categories": ["cs.AI", "cs.LG"], "comment": "40 pages, 6figures", "summary": "As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \\textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\\% success on the easy split, with performance dropping below 10\\% on hard subsets. We further propose \\textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.", "AI": {"tldr": "TRIP-Bench是针对复杂真实世界场景中的长期互动代理进行基准测试的工具，包含现实旅行规划情景、自动化评估和挑战性的多回合对话。论文还介绍了GTPO，在线强化学习方法，改善了Qwen2.5-32B-Instruct模型的表现。", "motivation": "现有的基准在复杂真实世界的设置中无法充分代表关键挑战，如全局约束的强制执行、多工具推理协调以及适应长期互动中的用户行为变化。TRIP-Bench旨在解决这些问题，并提供一种更实用的方法来评估和改进长时序交互代理。", "method": "TRIP-Bench使用现实世界数据构建基准测试场景，并包含18个定制化的工具与40多个旅行需求，支持自动化评估。论文还介绍了GTPO，在线强化学习方法通过特殊设计的奖励归一化和差异来提高模型的表现。", "result": "实验结果显示，即使是先进的模型在TRIP-Bench中也只达到50%的成功率，而在困难场景下的成功率低于10%。应用了GTPO后，Qwen2.5-32B-Instruct的性能有了显著提升，在约束满足和交互鲁棒性方面均超过了Gemini-3-Pro。", "conclusion": "TRIP-Bench为评估长时序互动代理提供了一个新的基准框架，而GTPO则是一种有效的在线强化学习策略，有助于改善模型在复杂、多回合对话中的表现。"}}
{"id": "2602.01674", "pdf": "https://arxiv.org/pdf/2602.01674", "abs": "https://arxiv.org/abs/2602.01674", "authors": ["Hail Song", "Boram Yoon", "Seokhwan Yang", "Seoyoung Kang", "Hyunjeong Kim", "Henning Metzmacher", "Woontack Woo"], "title": "VRGaussianAvatar: Integrating 3D Gaussian Avatars into VR", "categories": ["cs.CV", "cs.GR"], "comment": "Accepted as an IEEE TVCG paper at IEEE VR 2026 (journal track)", "summary": "We present VRGaussianAvatar, an integrated system that enables real-time full-body 3D Gaussian Splatting (3DGS) avatars in virtual reality using only head-mounted display (HMD) tracking signals. The system adopts a parallel pipeline with a VR Frontend and a GA Backend. The VR Frontend uses inverse kinematics to estimate full-body pose and streams the resulting pose along with stereo camera parameters to the backend. The GA Backend stereoscopically renders a 3DGS avatar reconstructed from a single image. To improve stereo rendering efficiency, we introduce Binocular Batching, which jointly processes left and right eye views in a single batched pass to reduce redundant computation and support high-resolution VR displays. We evaluate VRGaussianAvatar with quantitative performance tests and a within-subject user study against image- and video-based mesh avatar baselines. Results show that VRGaussianAvatar sustains interactive VR performance and yields higher perceived appearance similarity, embodiment, and plausibility. Project page and source code are available at https://vrgaussianavatar.github.io.", "AI": {"tldr": "VRGaussianAvatar 是一个系统，它利用头戴式显示器跟踪信号实现实时全身体积高斯点云渲染的虚拟化身。", "motivation": "为了提高立体渲染效率并支持高质量的虚拟现实体验，本文提出了一种通过单张图像实现三维体积高斯点云实时渲染的方法。", "method": "系统采用了一个平行流水线，包括VR前端和GA后端。前端使用逆向运动学估计全身体态并将结果发送到后端，而GA后端则进行立体视角的3DGS虚拟化身渲染，并引入双目批处理减少计算冗余。", "result": "通过定量性能测试和主观用户实验验证了VRGaussianAvatar可以维持交互式虚拟现实性能并提高感知外观相似性、存在感和合理性。", "conclusion": "VRGaussianAvatar证明了在使用头戴式显示器跟踪信号的情况下，实时全身体积高斯点云渲染是可行的，并且能够提供高质量的虚拟化身体验。"}}
{"id": "2602.01673", "pdf": "https://arxiv.org/pdf/2602.01673", "abs": "https://arxiv.org/abs/2602.01673", "authors": ["Enguang Fan"], "title": "Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Loop closure detection (LCD) is a core component of simultaneous localization and mapping (SLAM): it identifies revisited places and enables pose-graph constraints that correct accumulated drift. Classic bag-of-words approaches such as DBoW are efficient but often degrade under appearance change and perceptual aliasing. In parallel, deep learning-based visual place recognition (VPR) descriptors (e.g., NetVLAD and Transformer-based models) offer stronger robustness, but their computational cost is often viewed as a barrier to real-time SLAM. In this paper, we empirically evaluate NetVLAD as an LCD module and compare it against DBoW on the KITTI dataset. We introduce a Fine-Grained Top-K precision-recall curve that better reflects LCD settings where a query may have zero or multiple valid matches. With Faiss-accelerated nearestneighbor search, NetVLAD achieves real-time query speed while improving accuracy and robustness over DBoW, making it a practical drop-in alternative for LCD in SLAM.", "AI": {"tldr": "本文研究了在SLAM中使用NetVLAD进行实时闭环检测的方法，并通过Faiss加速最近邻搜索，提高了准确性与鲁棒性。", "motivation": "传统的DBoW方法虽然效率高但容易受外观变化和感知歧义的影响。而深度学习方法尽管更准确，但由于计算成本问题难以实现实时SLAM。本文旨在探索如何在保持实时性的前提下提高闭环检测的精度。", "method": "利用NetVLAD作为视觉位置识别(VPR)描述符，并通过Faiss加速最近邻搜索以实现高效查询。引入细粒度Top-K准确率-召回率曲线来评估性能。", "result": "相比DBoW，NetVLAD在KITTI数据集上实现了更高的精度和鲁棒性，同时保持了实时查询速度。", "conclusion": "本文表明通过使用NetVLAD和Faiss加速技术，可以在SLAM中实现实时且准确的闭环检测。"}}
{"id": "2602.01671", "pdf": "https://arxiv.org/pdf/2602.01671", "abs": "https://arxiv.org/abs/2602.01671", "authors": ["Mona Rajhans"], "title": "AI-Assisted Adaptive Rendering for High-Frequency Security Telemetry in Web Interfaces", "categories": ["cs.HC", "cs.AI", "cs.CR"], "comment": "To appear in IEEE ICCA 2025 proceedings", "summary": "Modern cybersecurity platforms must process and display high-frequency telemetry such as network logs, endpoint events, alerts, and policy changes in real time. Traditional rendering techniques based on static pagination or fixed polling intervals fail under volume conditions exceeding hundreds of thousands of events per second, leading to UI freezes, dropped frames, or stale data. This paper presents an AI-assisted adaptive rendering framework that dynamically regulates visual update frequency, prioritizes semantically relevant events, and selectively aggregates lower-priority data using behavior-driven heuristics and lightweight on-device machine learning models. Experimental validation demonstrates a 45-60 percent reduction in rendering overhead while maintaining analyst perception of real-time responsiveness.", "AI": {"tldr": "本文提出了一种基于AI的自适应渲染框架，用于实时处理和显示高频率的安全遥测数据。", "motivation": "传统渲染技术在每秒数万事件以上的情况下性能下降，导致用户界面冻结、帧丢失或数据过时。因此需要新的方法来改善用户体验。", "method": "采用行为驱动的启发式算法以及轻量级机器学习模型，在设备上动态调整视觉更新频率，优先处理语义相关事件并选择性聚合低优先级的数据。", "result": "实验验证表明，与传统渲染技术相比，该框架将渲染开销减少了45-60%，同时保持了分析师对实时响应的感觉。", "conclusion": "通过采用AI辅助的自适应渲染方法可以有效解决高频率安全遥测数据在显示时面临的性能挑战。"}}
{"id": "2602.01668", "pdf": "https://arxiv.org/pdf/2602.01668", "abs": "https://arxiv.org/abs/2602.01668", "authors": ["Qianyang Li", "Xingjun Zhang", "Shaoxun Wang", "Jia Wei", "Yueqi Xing"], "title": "ASGMamba: Adaptive Spectral Gating Mamba for Multivariate Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Long-term multivariate time series forecasting (LTSF) plays a crucial role in various high-performance computing applications, including real-time energy grid management and large-scale traffic flow simulation. However, existing solutions face a dilemma: Transformer-based models suffer from quadratic complexity, limiting their scalability on long sequences, while linear State Space Models (SSMs) often struggle to distinguish valuable signals from high-frequency noise, leading to wasted state capacity. To bridge this gap, we propose ASGMamba, an efficient forecasting framework designed for resource-constrained supercomputing environments. ASGMamba integrates a lightweight Adaptive Spectral Gating (ASG) mechanism that dynamically filters noise based on local spectral energy, enabling the Mamba backbone to focus its state evolution on robust temporal dynamics. Furthermore, we introduce a hierarchical multi-scale architecture with variable-specific Node Embeddings to capture diverse physical characteristics. Extensive experiments on nine benchmarks demonstrate that ASGMamba achieves state-of-the-art accuracy. While keeping strictly $$\\mathcal{O}(L)$$ complexity we significantly reduce the memory usage on long-horizon tasks, thus establishing ASGMamba as a scalable solution for high-throughput forecasting in resource limited environments.The code is available at https://github.com/hit636/ASGMamba", "AI": {"tldr": "本文提出了ASGMamba，一种用于长时多变量时间序列预测的高效框架。", "motivation": "现有的解决方案在处理长时间序列预测时存在局限性：Transformer模型复杂度高，线性状态空间模型难以区分有价值信号和高频噪声。", "method": "ASGMamba集成了轻量级自适应光谱门控机制，动态过滤噪声并使Mamba主干专注于稳健的时间动态。同时引入分层多尺度架构和节点嵌入以捕捉多样化物理特征。", "result": "实验表明ASGMamba在九个基准测试中达到了最先进的精度，并保持了严格线性复杂度的同时减少了长期任务的内存使用。", "conclusion": "ASGMamba作为一种可扩展解决方案，适合资源受限环境中的高吞吐量预测需求。"}}
{"id": "2602.01666", "pdf": "https://arxiv.org/pdf/2602.01666", "abs": "https://arxiv.org/abs/2602.01666", "authors": ["Yan Wang", "Partho Hassan", "Samiha Sadeka", "Nada Soliman", "M M Sayeef Abdullah", "Sabit Hassan"], "title": "Moonworks Lunara Aesthetic II: An Image Variation Dataset", "categories": ["cs.CV"], "comment": null, "summary": "We introduce Lunara Aesthetic II, a publicly released, ethically sourced image dataset designed to support controlled evaluation and learning of contextual consistency in modern image generation and editing systems. The dataset comprises 2,854 anchor-linked variation pairs derived from original art and photographs created by Moonworks. Each variation pair applies contextual transformations, such as illumination, weather, viewpoint, scene composition, color tone, or mood; while preserving a stable underlying identity. Lunara Aesthetic II operationalizes identity-preserving contextual variation as a supervision signal while also retaining Lunara's signature high aesthetic scores. Results show high identity stability, strong target attribute realization, and a robust aesthetic profile that exceeds large-scale web datasets. Released under the Apache 2.0 license, Lunara Aesthetic II is intended for benchmarking, fine-tuning, and analysis of contextual generalization, identity preservation, and edit robustness in image generation and image-to-image systems with interpretable, relational supervision. The dataset is publicly available at: https://huggingface.co/datasets/moonworks/lunara-aesthetic-image-variations.", "AI": {"tldr": "介绍了一个名为Lunara Aesthetic II的图像变化数据集，用于支持现代图像生成和编辑系统的上下文一致性评估和学习。", "motivation": "动机在于开发一个能够控制评价并促进学习现代图像生成及编辑系统中上下文一致性的公共、道德来源的数据集。该数据集旨在通过保持身份稳定性同时实现目标属性的转换来测试这些系统的性能。", "method": "从Moonworks创作的艺术作品和照片中抽取2,854对锚点相关的变体，应用诸如光照、天气、视点等上下文变换，确保每个变化对都保留稳定的身份。这些变体用于监督信号并保持高质量的美学评分。", "result": "实验结果表明，在身份稳定性、目标属性实现以及审美表现方面均表现出色，并且优于大规模网络数据集的表现。", "conclusion": "Lunara Aesthetic II提供了基准测试和分析图像生成及图像到图像系统中上下文概括，身份保持以及编辑稳健性的资源。"}}
{"id": "2602.01665", "pdf": "https://arxiv.org/pdf/2602.01665", "abs": "https://arxiv.org/abs/2602.01665", "authors": ["Hayeong Lee", "JunHyeok Oh", "Byung-Jun Lee"], "title": "TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "The design of environments plays a critical role in shaping the development and evaluation of cooperative multi-agent reinforcement learning (MARL) algorithms. While existing benchmarks highlight critical challenges, they often lack the modularity required to design custom evaluation scenarios. We introduce the Totally Accelerated Battle Simulator in JAX (TABX), a high-throughput sandbox designed for reconfigurable multi-agent tasks. TABX provides granular control over environmental parameters, permitting a systematic investigation into emergent agent behaviors and algorithmic trade-offs across a diverse spectrum of task complexities. Leveraging JAX for hardware-accelerated execution on GPUs, TABX enables massive parallelization and significantly reduces computational overhead. By providing a fast, extensible, and easily customized framework, TABX facilitates the study of MARL agents in complex structured domains and serves as a scalable foundation for future research. Our code is available at: https://anonymous.4open.science/r/TABX-00CA.", "AI": {"tldr": "本文介绍了一种名为TABX的高吞吐量沙盒仿真器，用于可重配置的多智能体任务。", "motivation": "现有的评估基准虽然突出了关键挑战，但缺乏设计定制化评估场景所需的模块性。为了更好地研究和评价合作型多智能体强化学习算法的发展，作者提出了TABX。", "method": "通过使用JAX进行硬件加速执行在GPU上，并且提供对环境参数的细粒度控制，TABX能够支持大规模并行化处理和减少计算开销，实现快速、可扩展的研究框架。", "result": "虽然具体结果未详细列出，但TABX作为一个高吞吐量仿真器，旨在通过定制化的环境设计来研究多智能体行为及其算法权衡。", "conclusion": "TABX作为未来合作型多智能体强化学习领域中一个可扩展的基础框架，提供了一个快速、灵活且易于定制的研究平台。"}}
{"id": "2602.01664", "pdf": "https://arxiv.org/pdf/2602.01664", "abs": "https://arxiv.org/abs/2602.01664", "authors": ["Mingda Zhang", "Haoran Luo", "Tiesunlong Shen", "Qika Lin", "Xiaoying Tang", "Rui Mao", "Erik Cambria"], "title": "FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": "41 pages, 7 figures, 6 tables. Project page: http://flowsteer.org/", "summary": "In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the agent and an executable canvas environment, automating workflow orchestration through multi-turn interaction. In this process, the policy model analyzes execution states and selects editing actions, while the canvas executes operators and returns feedback for iterative refinement. Moreover, FlowSteer provides a plug-and-play framework that supports diverse operator libraries and interchangeable LLM backends. To effectively train this interaction paradigm, we propose Canvas Workflow Relative Policy Optimization (CWRPO), which introduces diversity-constrained rewards with conditional release to stabilize learning and suppress shortcut behaviors. Experimental results on twelve datasets show that FlowSteer significantly outperforms baselines across various tasks.", "AI": {"tldr": "本文提出了一种通过端到端强化学习框架FlowSteer来自动化工作流编排的方法，该方法利用轻量级策略模型和可执行画布环境进行多轮互动。", "motivation": "现有的工作流编排面临高人工成本、依赖特定操作员/大型语言模型以及稀疏奖励信号等问题。为了应对这些挑战，本文提出了一个端到端强化学习框架FlowSteer，以减少人工干预并提高自动化程度。", "method": "FlowSteer利用轻量级策略模型作为代理，在可执行画布环境中通过多轮互动进行工作流编排。该方法包括分析执行状态和选择编辑操作，并引入了Canvas Workflow Relative Policy Optimization (CWRPO)来优化训练过程，使用多样性和条件释放的奖励机制以稳定学习并抑制捷径行为。", "result": "实验结果表明，在十二个数据集上FlowSteer在多种任务中均显著优于基线方法。", "conclusion": "FlowSteer通过端到端强化学习框架实现了工作流自动化编排，提高了效率和灵活性。"}}
{"id": "2602.01662", "pdf": "https://arxiv.org/pdf/2602.01662", "abs": "https://arxiv.org/abs/2602.01662", "authors": ["Pengyuan Guo", "Zhonghao Mai", "Zhengtong Xu", "Kaidi Zhang", "Heng Zhang", "Zichen Miao", "Arash Ajoudani", "Zachary Kingston", "Qiang Qiu", "Yu She"], "title": "AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act", "categories": ["cs.RO"], "comment": null, "summary": "Recent advances in large vision-language models (VLMs) have demonstrated generalizable open-vocabulary perception and reasoning, yet their real-robot manipulation capability remains unclear for long-horizon, closed-loop execution in unstructured, in-the-wild environments. Prior VLM-based manipulation pipelines are difficult to compare across different research groups' setups, and many evaluations rely on simulation, privileged state, or specially designed setups. We present AgenticLab, a model-agnostic robot agent platform and benchmark for open-world manipulation. AgenticLab provides a closed-loop agent pipeline for perception, task decomposition, online verification, and replanning. Using AgenticLab, we benchmark state-of-the-art VLM-based agents on real-robot tasks in unstructured environments. Our benchmark reveals several failure modes that offline vision-language tests (e.g., VQA and static image understanding) fail to capture, including breakdowns in multi-step grounding consistency, object grounding under occlusion and scene changes, and insufficient spatial reasoning for reliable manipulation. We will release the full hardware and software stack to support reproducible evaluation and accelerate research on general-purpose robot agents.", "AI": {"tldr": "本文介绍了AgenticLab，一个用于现实世界中机器人操作的平台和基准测试。", "motivation": "大视觉语言模型（VLM）在开放词汇感知和推理方面表现出泛化能力，但在无结构、真实环境中的长周期、闭环执行操作能力仍不清楚。现有基于VLM的操作管道难以跨不同研究团队进行比较，并且许多评估依赖于模拟或特别设计的设置。", "method": "AgenticLab提供了一个用于感知、任务分解、在线验证和重规划的闭环代理流程，以测试现实世界中机器人任务中的最新状态模型。", "result": "基准测试揭示了离线视觉语言测试（如VQA和静态图像理解）未能捕捉到的一些失败模式，包括多步骤接地一致性中断、遮挡下的对象接地以及不足的空间推理能力。", "conclusion": "该研究将发布完整的硬件和软件堆栈以支持可重复评估并加速通用目的机器人代理的研究。"}}
{"id": "2602.01661", "pdf": "https://arxiv.org/pdf/2602.01661", "abs": "https://arxiv.org/abs/2602.01661", "authors": ["Xingyu Miao", "Junting Dong", "Qin Zhao", "Yuhang Yang", "Junhao Chen", "Yang Long"], "title": "From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we focus on the challenge of temporally consistent human-centric dense prediction across video sequences. Existing models achieve strong per-frame accuracy but often flicker under motion, occlusion, and lighting changes, and they rarely have paired human video supervision for multiple dense tasks. We address this gap with a scalable synthetic data pipeline that generates photorealistic human frames and motion-aligned sequences with pixel-accurate depth, normals, and masks. Unlike prior static data synthetic pipelines, our pipeline provides both frame-level labels for spatial learning and sequence-level supervision for temporal learning. Building on this, we train a unified ViT-based dense predictor that (i) injects an explicit human geometric prior via CSE embeddings and (ii) improves geometry-feature reliability with a lightweight channel reweighting module after feature fusion. Our two-stage training strategy, combining static pretraining with dynamic sequence supervision, enables the model first to acquire robust spatial representations and then refine temporal consistency across motion-aligned sequences. Extensive experiments show that we achieve state-of-the-art performance on THuman2.1 and Hi4D and generalize effectively to in-the-wild videos.", "AI": {"tldr": "本文专注于视频序列中的人体密集预测任务，提出了一种新的数据生成和模型训练策略。", "motivation": "现有模型在单帧上表现良好但在运动、遮挡或光照变化下容易闪烁。此外，很少有多个密集任务的成对人类视频监督。", "method": "构建了一个可扩展的合成数据流水线，能够产生具有像素精确深度、法向量和掩码的真实感人体帧序列。通过CSE嵌入注入明确的人体几何先验，并使用通道重加权模块提高融合后的特征可靠性。采用两阶段训练策略：静态预训练和动态序列监督。", "result": "实验结果显示，该模型在THuman2.1和Hi4D数据集上达到了最先进的性能，并且能够有效推广到野外视频。", "conclusion": "本文提出的方法解决了现有模型在人体密集预测任务中的闪烁问题，同时提高了时间一致性。"}}
{"id": "2602.01660", "pdf": "https://arxiv.org/pdf/2602.01660", "abs": "https://arxiv.org/abs/2602.01660", "authors": ["Zhongyuan Peng", "Caijun Xu", "Changyi Xiao", "Shibo Hong", "Eli Zhang", "Stephen Huang", "Yixin Cao"], "title": "CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 5 tables, 5 figures", "summary": "Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research.", "AI": {"tldr": "本文提出了CoDiQ框架，用于生成可控难度的竞赛级别问题。", "motivation": "现有的自动化问题合成方法缺乏精确控制难度的能力，并且计算成本高，难以大规模生成竞赛级别的问题。", "method": "通过测试时间缩放和模型改进来实现对难度的精细控制。开发了CoDiQ-Generator并构建了44K个高质量的问题库。", "result": "实验结果表明，使用CoDiQ-Corpus训练大型推理模型能够显著提升其性能，验证了生成可控难度问题的有效性。", "conclusion": "本文提出了一个用于生成竞赛级别问题的框架和方法，并开放了相关资源以支持研究。"}}
{"id": "2602.01658", "pdf": "https://arxiv.org/pdf/2602.01658", "abs": "https://arxiv.org/abs/2602.01658", "authors": ["Seyed Mohammad Hadi Hosseini", "Amir Najafi", "Mahdieh Soleymani Baghshah"], "title": "Efficient Adversarial Attacks on High-dimensional Offline Bandits", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICLR 2026 Conference", "summary": "Bandit algorithms have recently emerged as a powerful tool for evaluating machine learning models, including generative image models and large language models, by efficiently identifying top-performing candidates without exhaustive comparisons. These methods typically rely on a reward model, often distributed with public weights on platforms such as Hugging Face, to provide feedback to the bandit. While online evaluation is expensive and requires repeated trials, offline evaluation with logged data has become an attractive alternative. However, the adversarial robustness of offline bandit evaluation remains largely unexplored, particularly when an attacker perturbs the reward model (rather than the training data) prior to bandit training. In this work, we fill this gap by investigating, both theoretically and empirically, the vulnerability of offline bandit training to adversarial manipulations of the reward model. We introduce a novel threat model in which an attacker exploits offline data in high-dimensional settings to hijack the bandit's behavior. Starting with linear reward functions and extending to nonlinear models such as ReLU neural networks, we study attacks on two Hugging Face evaluators used for generative model assessment: one measuring aesthetic quality and the other assessing compositional alignment. Our results show that even small, imperceptible perturbations to the reward model's weights can drastically alter the bandit's behavior. From a theoretical perspective, we prove a striking high-dimensional effect: as input dimensionality increases, the perturbation norm required for a successful attack decreases, making modern applications such as image evaluation especially vulnerable. Extensive experiments confirm that naive random perturbations are ineffective, whereas carefully targeted perturbations achieve near-perfect attack success rates ...", "AI": {"tldr": "本文研究了在高维环境下离线多臂赌博机训练对奖励模型攻击的脆弱性，提出了一种新的威胁模型，并通过理论和实验展示了即使微小且不可感知的扰动也能大幅改变赌博机行为。", "motivation": "尽管在线评估昂贵且需要重复试验，但利用日志数据进行离线评估已经成为一种有吸引力的替代方案。然而，在这种设置下，对奖励模型进行攻击以操纵多臂赌博机的行为仍然是一个未被充分研究的问题。本文旨在填补这一空白，并探讨其在实际应用中的重要性。", "method": "作者首先提出了一种新的威胁模型，其中攻击者利用离线数据在高维环境中操控奖励模型。他们从线性奖励函数开始，然后扩展到非线性模型（如ReLU神经网络），并针对用于评估生成模型的两个Hugging Face评估器进行了研究。", "result": "实验结果表明，即使微小且不可感知的扰动也能导致赌博机行为发生重大改变，并证明了在高维输入情况下，所需攻击的扰动幅度会显著减小。此外，研究表明随机扰动无效，而有针对性的扰动可以实现近乎完美的攻击成功率。", "conclusion": "本文揭示了离线多臂赌博机训练对奖励模型攻击的高度脆弱性，并提出了一个有影响力的理论框架来理解这种现象。这些发现强调需要开发更强大的防御机制以保护机器学习模型评估的安全性。"}}
{"id": "2602.01655", "pdf": "https://arxiv.org/pdf/2602.01655", "abs": "https://arxiv.org/abs/2602.01655", "authors": ["Pengrui Lu", "Shiqi Zhang", "Yunzhong Hou", "Lyumanshan Ye", "Chaoyi Huang", "Zixi Chen", "Ji Zeng", "Hantao Jiang", "Pengfei Liu", "Yiwei Wang", "Ming-Hsuan Yang"], "title": "ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project requirements to coding agents and evaluates the resulting repositories. Combining Online Judge (OJ) testing with LLM-assisted code review, the benchmark evaluates agents on (1) system architecture design, (2) functional correctness, and (3) iterative solution refinement. We curate 20 programming problems across 8 categories, covering both concept-oriented tasks and real-world application scenarios, and evaluate six coding agents built on different LLM backends. Our evaluation reports an overall acceptance rate of 27.38%: agents handle basic functionality and data structures but struggle with complex system design, time complexity optimization, and resource management. Our benchmark is available at https://github.com/zsworld6/projdevbench.", "AI": {"tldr": "该项目提出了ProjDevBench，一个用于评估AI编码代理在端到端项目开发中的性能的基准。", "motivation": "现有评价体系主要集中在问题级别的错误修复上，并没有跟上整个项目开发的步伐。因此需要一个新的评估标准来全面衡量AI编码代理的能力。", "method": "ProjDevBench结合在线裁判系统（OJ）测试和大语言模型辅助代码审查，从架构设计、功能正确性和迭代解决方案改进三个方面对AI编码代理进行了全面评价。", "result": "在20个编程问题的评估中，六种基于不同大型语言模型后台构建的编码代理的整体接受率为27.38%，显示了它们处理基本功能和数据结构的能力但面对复杂的系统设计、时间复杂度优化及资源管理仍存在问题。", "conclusion": "通过ProjDevBench，研究人员可以更全面地评估AI编码代理在端到端项目开发中的表现，并为进一步改进提供方向。"}}
{"id": "2602.01651", "pdf": "https://arxiv.org/pdf/2602.01651", "abs": "https://arxiv.org/abs/2602.01651", "authors": ["Zichao Wei"], "title": "On the Spatiotemporal Dynamics of Generalization in Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Why do neural networks fail to generalize addition from 16-digit to 32-digit numbers, while a child who learns the rule can apply it to arbitrarily long sequences? We argue that this failure is not an engineering problem but a violation of physical postulates. Drawing inspiration from physics, we identify three constraints that any generalizing system must satisfy: (1) Locality -- information propagates at finite speed; (2) Symmetry -- the laws of computation are invariant across space and time; (3) Stability -- the system converges to discrete attractors that resist noise accumulation. From these postulates, we derive -- rather than design -- the Spatiotemporal Evolution with Attractor Dynamics (SEAD) architecture: a neural cellular automaton where local convolutional rules are iterated until convergence. Experiments on three tasks validate our theory: (1) Parity -- demonstrating perfect length generalization via light-cone propagation; (2) Addition -- achieving scale-invariant inference from L=16 to L=1 million with 100% accuracy, exhibiting input-adaptive computation; (3) Rule 110 -- learning a Turing-complete cellular automaton without trajectory divergence. Our results suggest that the gap between statistical learning and logical reasoning can be bridged -- not by scaling parameters, but by respecting the physics of computation.", "AI": {"tldr": "研究提出了一种新的神经网络架构SEAD，旨在通过遵守计算物理原理来实现逻辑推理和统计学习的结合。", "motivation": "探讨了为何神经网络在处理数字加法时不能泛化到更长序列的问题，并提出了物理约束作为解决这一问题的基础。", "method": "基于三个物理原则设计了一种新的神经网络架构SEAD：局部性、对称性和稳定性，通过迭代本地卷积规则实现信息传播和收敛。", "result": "实验结果显示，在奇偶校验、加法和Rule 110任务上，该架构表现出色，能够在不同长度的序列中保持精度，实现了输入自适应计算。", "conclusion": "研究证明了通过遵守物理原理而非单纯增加参数数量可以弥合统计学习与逻辑推理之间的差距。"}}
{"id": "2602.01649", "pdf": "https://arxiv.org/pdf/2602.01649", "abs": "https://arxiv.org/abs/2602.01649", "authors": ["Yinchao Ma", "Qiang Zhou", "Zhibin Wang", "Xianing Chen", "Hanqing Yang", "Jun Song", "Bo Zheng"], "title": "Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning", "categories": ["cs.CV", "cs.AI"], "comment": "This paper is accepted by AAAI2026", "summary": "Video large language models have demonstrated remarkable capabilities in video understanding tasks. However, the redundancy of video tokens introduces significant computational overhead during inference, limiting their practical deployment. Many compression algorithms are proposed to prioritize retaining features with the highest attention scores to minimize perturbations in attention computations. However, the correlation between attention scores and their actual contribution to correct answers remains ambiguous. To address the above limitation, we propose a novel \\textbf{C}ontribution-\\textbf{a}ware token \\textbf{Co}mpression algorithm for \\textbf{VID}eo understanding (\\textbf{CaCoVID}) that explicitly optimizes the token selection policy based on the contribution of tokens to correct predictions. First, we introduce a reinforcement learning-based framework that optimizes a policy network to select video token combinations with the greatest contribution to correct predictions. This paradigm shifts the focus from passive token preservation to active discovery of optimal compressed token combinations. Secondly, we propose a combinatorial policy optimization algorithm with online combination space sampling, which dramatically reduces the exploration space for video token combinations and accelerates the convergence speed of policy optimization. Extensive experiments on diverse video understanding benchmarks demonstrate the effectiveness of CaCoVID. Codes will be released.", "AI": {"tldr": "提出了一种基于强化学习的贡献感知视频压缩算法CaCoVID，以提高视频理解任务中的效率。", "motivation": "现有视频语言模型在冗余视频令牌上存在计算负担过重的问题，限制了其实用性。该方法旨在通过优化令牌选择策略来解决这个问题，从而减少对正确预测的实际影响。", "method": "采用强化学习框架优化策略网络以选择贡献最大的视频令牌组合，并提出一种在线组合空间采样的组合策略优化算法，大大减少了探索空间并加速了策略优化的收敛速度。", "result": "实验结果表明，CaCoVID在多种视频理解基准测试中表现出了有效性。", "conclusion": "通过主动发现最优压缩令牌组合的方法提高了视频理解任务中的效率。"}}
{"id": "2602.01645", "pdf": "https://arxiv.org/pdf/2602.01645", "abs": "https://arxiv.org/abs/2602.01645", "authors": ["Yuxuan Liu", "Peihong Zhang", "Rui Sang", "Zhixin Li", "Yizhou Tan", "Yiqiang Cai", "Shengchen Li"], "title": "Membership Inference Attack Against Music Diffusion Models via Generative Manifold Perturbation", "categories": ["cs.SD"], "comment": null, "summary": "Membership inference attacks (MIAs) test whether a specific audio clip was used to train a model, making them a key tool for auditing generative music models for copyright compliance. However, loss-based signals (e.g., reconstruction error) are weakly aligned with human perception in practice, yielding poor separability at the low false-positive rates (FPRs) required for forensics. We propose the Latent Stability Adversarial Probe (LSA-Probe), a white-box method that measures a geometric property of the reverse diffusion: the minimal time-normalized perturbation budget needed to cross a fixed perceptual degradation threshold at an intermediate diffusion state. We show that training members, residing in more stable regions, exhibit a significantly higher degradation cost.", "AI": {"tldr": "提出了一种新的白盒方法LSA-Probe，用于检测音频片段是否参与了音乐扩散模型的训练。", "motivation": "现有的基于损失的方法在实践中与人类感知弱关联，在低假阳性率下难以有效区分成员和非成员样本。本文旨在通过几何属性来改进这种状况。", "method": "提出了一种新的白盒方法LSA-Probe，该方法测量反向扩散过程中几何特征的变化：即最小的时归一化扰动预算需要在固定感知降级阈值处跨越中间扩散状态的时间点。训练成员由于处于更稳定的区域，因此表现出更高的退化成本。", "result": "证明了LSA-Probe能够在低假阳性率下有效区分样本是否为训练集成员。", "conclusion": "通过测量反向扩散过程中的几何属性，可以更好地检测音频片段是否参与模型训练，从而提高版权合规性审计的准确性。"}}
{"id": "2602.01644", "pdf": "https://arxiv.org/pdf/2602.01644", "abs": "https://arxiv.org/abs/2602.01644", "authors": ["Gloria Felicia", "Nolan Bryant", "Handi Putra", "Ayaan Gazali", "Eliel Lobo", "Esteban Rojas"], "title": "From Perception to Action: Spatial AI Agents and World Models", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MA", "cs.RO"], "comment": "61 pages, 742 citations, 1 figure, 3 tables. Survey paper on spatial AI agents, embodied AI, graph neural networks, and world models", "summary": "While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason about object relationships, and act under physical constraints, is an orthogonal capability that proves important for embodied agents. Existing surveys address either agentic architectures or spatial domains in isolation. None provide a unified framework connecting these complementary capabilities. This paper bridges that gap. Through a thorough review of over 2,000 papers, citing 742 works from top-tier venues, we introduce a unified three-axis taxonomy connecting agentic capabilities with spatial tasks across scales. Crucially, we distinguish spatial grounding (metric understanding of geometry and physics) from symbolic grounding (associating images with text), arguing that perception alone does not confer agency. Our analysis reveals three key findings mapped to these axes: (1) hierarchical memory systems (Capability axis) are important for long-horizon spatial tasks. (2) GNN-LLM integration (Task axis) is a promising approach for structured spatial reasoning. (3) World models (Scale axis) are essential for safe deployment across micro-to-macro spatial scales. We conclude by identifying six grand challenges and outlining directions for future research, including the need for unified evaluation frameworks to standardize cross-domain assessment. This taxonomy provides a foundation for unifying fragmented research efforts and enabling the next generation of spatially-aware autonomous systems in robotics, autonomous vehicles, and geospatial intelligence.", "AI": {"tldr": "本文通过综合回顾超过两千篇论文，提出了一个统一的三轴分类法，连接了代理能力与空间任务，旨在解决感知到行动之间的差距。", "motivation": "大型语言模型在符号领域取得的成功未能轻易地转化为物理世界的应用。为了填补这种差异，该研究探讨了空间智能的重要性，并引入了一个将代理能力和空间任务结合的统一框架。", "method": "通过回顾超过两千篇论文，提出了一个统一的三轴分类法，其中包括能力轴、任务轴和规模轴，以连接代理能力和空间任务。", "result": "揭示了三个关键发现：1) 分层记忆系统对于长期空间任务的重要性；2) GNN-LLM集成在结构化空间推理中的潜力；3) 世界模型对于跨微宏观尺度的稳健部署至关重要。", "conclusion": "本文通过提出一个统一分类框架，旨在解决现有研究碎片化的挑战，并指出了未来研究的方向和六个主要挑战，为下一代具备空间意识的自主系统铺平道路。"}}
{"id": "2602.01643", "pdf": "https://arxiv.org/pdf/2602.01643", "abs": "https://arxiv.org/abs/2602.01643", "authors": ["Xichen Sun", "Wentao Wei", "Jiahua Rao", "Jiancong Xie", "Yuedong Yang"], "title": "De Novo Molecular Generation from Mass Spectra via Many-Body Enhanced Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Molecular structure generation from mass spectrometry is fundamental for understanding cellular metabolism and discovering novel compounds. Although tandem mass spectrometry (MS/MS) enables the high-throughput acquisition of fragment fingerprints, these spectra often reflect higher-order interactions involving the concerted cleavage of multiple atoms and bonds-crucial for resolving complex isomers and non-local fragmentation mechanisms. However, most existing methods adopt atom-centric and pairwise interaction modeling, overlooking higher-order edge interactions and lacking the capacity to systematically capture essential many-body characteristics for structure generation. To overcome these limitations, we present MBGen, a Many-Body enhanced diffusion framework for de novo molecular structure Generation from mass spectra. By integrating a many-body attention mechanism and higher-order edge modeling, MBGen comprehensively leverages the rich structural information encoded in MS/MS spectra, enabling accurate de novo generation and isomer differentiation for novel molecules. Experimental results on the NPLIB1 and MassSpecGym benchmarks demonstrate that MBGen achieves superior performance, with improvements of up to 230% over state-of-the-art methods, highlighting the scientific value and practical utility of many-body modeling for mass spectrometry-based molecular generation. Further analysis and ablation studies show that our approach effectively captures higher-order interactions and exhibits enhanced sensitivity to complex isomeric and non-local fragmentation information.", "AI": {"tldr": "通过引入多体增强扩散框架，从质谱数据中生成分子结构。", "motivation": "现有的方法大多采用原子中心和成对交互建模，未能全面捕捉高阶边交互作用及复杂的非局部碎片化机制，影响了新化合物的准确识别与异构体区分。", "method": "MBGen通过集成多体注意力机制和高阶边模型，从MS/MS谱图中全面利用丰富的结构信息，实现精确的新分子生成和异构体区别。", "result": "实验结果表明，在NPLIB1和MassSpecGym基准测试上，MBGen相较于现有最佳方法性能提升了高达230%，展示了多体建模在质谱基分子生成中的科学价值与实用性。", "conclusion": "该研究提出了一种有效的多体增强扩散框架用于从质谱中准确生成新的分子结构，并成功捕捉高阶交互作用和复杂的异构体信息。"}}
{"id": "2602.01642", "pdf": "https://arxiv.org/pdf/2602.01642", "abs": "https://arxiv.org/abs/2602.01642", "authors": ["Matias D. Cattaneo", "Boris Shigida"], "title": "The Effect of Mini-Batch Noise on the Implicit Bias of Adam", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.CO", "stat.ML"], "comment": null, "summary": "With limited high-quality data and growing compute, multi-epoch training is gaining back its importance across sub-areas of deep learning. Adam(W), versions of which are go-to optimizers for many tasks such as next token prediction, has two momentum hyperparameters $(β_1, β_2)$ controlling memory and one very important hyperparameter, batch size, controlling (in particular) the amount mini-batch noise. We introduce a theoretical framework to understand how mini-batch noise influences the implicit bias of memory in Adam (depending on $β_1$, $β_2$) towards sharper or flatter regions of the loss landscape, which is commonly observed to correlate with the generalization gap in multi-epoch training. We find that in the case of large batch sizes, higher $β_2$ increases the magnitude of anti-regularization by memory (hurting generalization), but as the batch size becomes smaller, the dependence of (anti-)regulariation on $β_2$ is reversed. A similar monotonicity shift (in the opposite direction) happens in $β_1$. In particular, the commonly \"default\" pair $(β_1, β_2) = (0.9, 0.999)$ is a good choice if batches are small; for larger batches, in many settings moving $β_1$ closer to $β_2$ is much better in terms of validation accuracy in multi-epoch training. Moreover, our theoretical derivations connect the scale of the batch size at which the shift happens to the scale of the critical batch size. We illustrate this effect in experiments with small-scale data in the about-to-overfit regime.", "AI": {"tldr": "研究了Adam优化器中的mini-batch噪声如何影响模型的隐式偏差，特别是当训练数据量有限且计算能力增加时。", "motivation": "多轮次训练在深度学习各个子领域中变得越来越重要，而批量大小和动量超参数对模型泛化性能的影响尚未完全理解。研究目的是探索mini-batch噪声如何影响Adam优化器的隐式偏差，并找到更好的超参数设置以提高泛化能力。", "method": "提出了一种理论框架来分析mini-batch噪声与Adam优化器中不同$β_1$, $β_2$动量因子之间的关系，特别是当批量大小变化时的情况。通过理论推导和小规模数据实验验证这些发现的准确性。", "result": "发现在大批次的情况下，较大的$β_2$增加了记忆中的反正则化效应，从而损害泛化性能；而对于较小批次来说情况相反。同时指出默认设置$(0.9,0.999)$在小批次下表现良好，在大批次时调整$β_1$更接近$β_2$可能会提高验证准确率。", "conclusion": "通过理论分析和实验，发现了mini-batch噪声与Adam优化器隐式偏差之间的关系，并为不同的训练场景提供了更好的超参数选择建议。"}}
{"id": "2602.01639", "pdf": "https://arxiv.org/pdf/2602.01639", "abs": "https://arxiv.org/abs/2602.01639", "authors": ["Tianyu Yang", "ChenWei He", "Xiangzhao Hao", "Tianyue Wang", "Jiarui Guo", "Haiyun Guo", "Leigang Qu", "Jinqiao Wang", "Tat-Seng Chua"], "title": "ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Composed Image Retrieval (CIR) aims to retrieve target images based on a hybrid query comprising a reference image and a modification text. Early dual-tower Vision-Language Models (VLMs) struggle with cross-modality compositional reasoning required for this task. Recently, adapting generative Multimodal Large Language Models (MLLMs) for retrieval offers a promising direction. However, we identify that this adaptation strategy overlooks a fundamental issue: adapting a generative MLLM into a single-embedding discriminative retriever triggers a paradigm conflict, which leads to Capability Degradation - the deterioration of native fine-grained reasoning after retrieval adaptation. To address this challenge, we propose ReCALL (Recalibrating Capability Degradation), a model-agnostic framework that follows a diagnose-generate-refine pipeline: Firstly, we diagnose cognitive blind spots of the retriever via self-guided informative instance mining. Next, we generate corrective instructions and triplets by CoT prompting the foundation MLLM and conduct quality control with VQA-based consistency filtering. Finally, we refine the retriever through continual training on these triplets with a grouped contrastive scheme, thereby internalizing fine-grained visual-semantic distinctions and realigning the discriminative embedding space of retriever with intrinsic compositional reasoning within the MLLM. Extensive experiments on CIRR and FashionIQ show that ReCALL consistently recalibrates degraded capabilities and achieves state-of-the-art performance. Code will be released soon.", "AI": {"tldr": "本文提出了ReCALL框架，用于解决多模态大语言模型在图像检索任务中的能力退化问题。", "motivation": "在使用生成式多模态大型语言模型进行图像检索时，转换为单嵌入判别器会引发范式冲突，导致原生的细粒度推理能力下降。ReCALL旨在解决这一挑战。", "method": "通过自我引导的信息实例挖掘诊断认知盲点；利用CoT提示生成校正指令和三元组，并进行VQA一致性过滤质量控制；采用分组对比训练方案不断优化检索器，使其内在化细粒度的视觉语义区分并重新调整判别嵌入空间。", "result": "在CIRR和FashionIQ数据集上的实验表明，ReCALL能够有效恢复退化的推理能力，并达到最先进的性能水平。", "conclusion": "本文提出了一种用于多模态大语言模型图像检索任务中的能力衰退问题的解决方案。通过诊断、生成与精炼三个阶段重新校准了检索器的能力。"}}
{"id": "2602.01634", "pdf": "https://arxiv.org/pdf/2602.01634", "abs": "https://arxiv.org/abs/2602.01634", "authors": ["Chenxu Guo", "Jiachen Lian", "Yisi Liu", "Baihe Huang", "Shriyaa Narayanan", "Cheol Jun Cho", "Gopala Anumanchipalli"], "title": "HuPER: A Human-Inspired Framework for Phonetic Perception", "categories": ["eess.AS", "cs.AI"], "comment": null, "summary": "We propose HuPER, a human-inspired framework that models phonetic perception as adaptive inference over acoustic-phonetics evidence and linguistic knowledge. With only 100 hours of training data, HuPER achieves state-of-the-art phonetic error rates on five English benchmarks and strong zero-shot transfer to 95 unseen languages. HuPER is also the first framework to enable adaptive, multi-path phonetic perception under diverse acoustic conditions. All training data, models, and code are open-sourced. Code and demo avaliable at https://github.com/HuPER29/HuPER.", "AI": {"tldr": "本文提出了一种名为HuPER的人类启发式框架，用于建模语音感知。", "motivation": "该研究旨在通过模拟人类的适应性推理能力，改进语音识别技术。", "method": "通过使用100小时的训练数据，在声学-语音证据和语言知识上进行自适应推断。", "result": "在五个英语基准测试中实现了最先进的语音错误率，并且对95种未见过的语言具有强大的零样本迁移能力。", "conclusion": "HuPER是首个能够在多样化的声学条件下支持自适应多路径语音感知的框架。所有训练数据、模型和代码均已开源，促进了进一步研究的发展。"}}
{"id": "2602.01633", "pdf": "https://arxiv.org/pdf/2602.01633", "abs": "https://arxiv.org/abs/2602.01633", "authors": ["Xinyuan Zhao", "Yihang Wu", "Ahmad Chaddad", "Tareef Daqqaq", "Reem Kateb"], "title": "Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification", "categories": ["cs.CV"], "comment": "Accepted in Knowledge-Based Systems", "summary": "While deep learning models like Vision Transformer (ViT) have achieved significant advances, they typically require large datasets. With data privacy regulations, access to many original datasets is restricted, especially medical images. Federated learning (FL) addresses this challenge by enabling global model aggregation without data exchange. However, the heterogeneity of the data and the class imbalance that exist in local clients pose challenges for the generalization of the model. This study proposes a FL framework leveraging a dynamic adaptive focal loss (DAFL) and a client-aware aggregation strategy for local training. Specifically, we design a dynamic class imbalance coefficient that adjusts based on each client's sample distribution and class data distribution, ensuring minority classes receive sufficient attention and preventing sparse data from being ignored. To address client heterogeneity, a weighted aggregation strategy is adopted, which adapts to data size and characteristics to better capture inter-client variations. The classification results on three public datasets (ISIC, Ocular Disease and RSNA-ICH) show that the proposed framework outperforms DenseNet121, ResNet50, ViT-S/16, ViT-L/32, FedCLIP, Swin Transformer, CoAtNet, and MixNet in most cases, with accuracy improvements ranging from 0.98\\% to 41.69\\%. Ablation studies on the imbalanced ISIC dataset validate the effectiveness of the proposed loss function and aggregation strategy compared to traditional loss functions and other FL approaches. The codes can be found at: https://github.com/AIPMLab/ViT-FLDAF.", "AI": {"tldr": "提出了一种基于联邦学习的视觉变换器框架，结合自适应焦点损失和客户端感知聚合策略，以提高医疗图像分类精度。", "motivation": "为了在遵守数据隐私法规的情况下利用深度学习模型进行医学图像分类，提出了一个解决数据异质性和类别不平衡问题的方案，从而改进全局模型的一般化能力。", "method": "设计了一种动态自适应焦点损失函数，该函数可以根据每个客户端的数据分布和类别分布调整系数，确保少数类获得足够的关注。采用加权聚合策略以适应不同客户端的数据大小和特征，更好地捕捉跨客户差异。", "result": "在三个公开数据集上进行的分类结果表明，提出的框架优于多种基准模型，在大多数情况下提高了0.98％至41.69％的准确率。", "conclusion": "该研究通过实验证明了所提出的方法能够有效解决类别不平衡和客户端异质性问题，并在多个医学图像数据集上取得了优异的结果。"}}
{"id": "2602.01632", "pdf": "https://arxiv.org/pdf/2602.01632", "abs": "https://arxiv.org/abs/2602.01632", "authors": ["Chuizheng Kong", "Yunho Cho", "Wonsuhk Jung", "Idris Wibowo", "Parth Shinde", "Sundhar Vinodh-Sangeetha", "Long Kiu Chung", "Zhenyang Chen", "Andrew Mattei", "Advaith Nidumukkala", "Alexander Elias", "Danfei Xu", "Taylor Higgins", "Shreyas Kousik"], "title": "A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation", "categories": ["cs.RO"], "comment": "Project page at https://sew-mimic.com/", "summary": "Retargeting human motion to robot poses is a practical approach for teleoperating bimanual humanoid robot arms, but existing methods can be suboptimal and slow, often causing undesirable motion or latency. This is due to optimizing to match robot end-effector to human hand position and orientation, which can also limit the robot's workspace to that of the human. Instead, this paper reframes retargeting as an orientation alignment problem, enabling a closed-form, geometric solution algorithm with an optimality guarantee. The key idea is to align a robot arm to a human's upper and lower arm orientations, as identified from shoulder, elbow, and wrist (SEW) keypoints; hence, the method is called SEW-Mimic. The method has fast inference (3 kHz) on standard commercial CPUs, leaving computational overhead for downstream applications; an example in this paper is a safety filter to avoid bimanual self-collision. The method suits most 7-degree-of-freedom robot arms and humanoids, and is agnostic to input keypoint source. Experiments show that SEW-Mimic outperforms other retargeting methods in computation time and accuracy. A pilot user study suggests that the method improves teleoperation task success. Preliminary analysis indicates that data collected with SEW-Mimic improves policy learning due to being smoother. SEW-Mimic is also shown to be a drop-in way to accelerate full-body humanoid retargeting. Finally, hardware demonstrations illustrate SEW-Mimic's practicality. The results emphasize the utility of SEW-Mimic as a fundamental building block for bimanual robot manipulation and humanoid robot teleoperation.", "AI": {"tldr": "提出了一种新的几何重定位算法SEW-Mimic，用于通过人上肢姿态优化机器人手臂的控制。", "motivation": "现有的人体运动到机器人姿态的转换方法效率低且可能产生不自然的动作或延迟。为解决这些问题，提出了一个新的基于方向对齐的方法来提高性能和准确性。", "method": "该方法将重定位视为方向对齐问题，并通过匹配人肩、肘、腕（SEW）关键点的方向来优化机器人手臂的姿态。此算法在标准商用CPU上具有快速推理速度（3 kHz），适合大多数七自由度的机器人手臂。", "result": "实验表明，与现有方法相比，SEW-Mimic不仅提高了计算效率和准确性，还提升了任务成功率，并且收集的数据有助于改进策略学习。", "conclusion": "研究表明，SEW-Mimic可作为双臂操作和人形机器人的基础模块，提高了重定位的实用性和效果。"}}
{"id": "2602.01630", "pdf": "https://arxiv.org/pdf/2602.01630", "abs": "https://arxiv.org/abs/2602.01630", "authors": ["Bohan Zeng", "Kaixin Zhu", "Daili Hua", "Bozhou Li", "Chengzhuo Tong", "Yuran Wang", "Xinyi Huang", "Yifan Dai", "Zixiang Zhang", "Yifan Yang", "Zhou Liu", "Hao Liang", "Xiaochen Ma", "Ruichuan An", "Tianyi Bai", "Hongcheng Gao", "Junbo Niu", "Yang Shi", "Xinlong Chen", "Yue Ding", "Minglei Shi", "Kai Zeng", "Yiwen Tang", "Yuanxing Zhang", "Pengfei Wan", "et al. (2 additional authors not shown)"], "title": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks", "categories": ["cs.CV"], "comment": "13 pages, 4 figures", "summary": "World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction, 3D estimation, or symbol grounding, rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models. We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation. This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.", "AI": {"tldr": "分析了当前世界模型研究的局限性，并提出了统一的设计规范。", "motivation": "现有的世界模型研究碎片化，缺乏系统性的整体认知框架，旨在提出一个更全面、稳健和原则性的世界模型设计。", "method": "通过分析现有任务特定整合方法的限制，建议了一个涵盖交互、感知、符号推理和空间表示的统一框架。", "result": "提出了一个新的统一的世界模型设计规范。", "conclusion": "未来研究应遵循更全面、稳健的原则性模型指导思想。"}}
{"id": "2602.01629", "pdf": "https://arxiv.org/pdf/2602.01629", "abs": "https://arxiv.org/abs/2602.01629", "authors": ["Renukanandan Tumu", "Aditya Singh", "Rahul Mangharam"], "title": "AdaptNC: Adaptive Nonconformity Scores for Uncertainty-Aware Autonomous Systems in Dynamic Environments", "categories": ["cs.LG", "cs.RO", "eess.SY"], "comment": null, "summary": "Rigorous uncertainty quantification is essential for the safe deployment of autonomous systems in unconstrained environments. Conformal Prediction (CP) provides a distribution-free framework for this task, yet its standard formulations rely on exchangeability assumptions that are violated by the distribution shifts inherent in real-world robotics. Existing online CP methods maintain target coverage by adaptively scaling the conformal threshold, but typically employ a static nonconformity score function. We show that this fixed geometry leads to highly conservative, volume-inefficient prediction regions when environments undergo structural shifts. To address this, we propose \\textbf{AdaptNC}, a framework for the joint online adaptation of both the nonconformity score parameters and the conformal threshold. AdaptNC leverages an adaptive reweighting scheme to optimize score functions, and introduces a replay buffer mechanism to mitigate the coverage instability that occurs during score transitions. We evaluate AdaptNC on diverse robotic benchmarks involving multi-agent policy changes, environmental changes and sensor degradation. Our results demonstrate that AdaptNC significantly reduces prediction region volume compared to state-of-the-art threshold-only baselines while maintaining target coverage levels.", "AI": {"tldr": "提出AdaptNC框架，该框架通过在线调整非一致性分数参数和阈值来提高不确定性感知的自主系统在动态环境中的预测效率。", "motivation": "当前的自适应校准方法通常使用静态非一致性评分函数，在分布变化时会导致保守且体积不高效的预测区域。为了改善这一点，AdaptNC框架被提出以解决此类问题。", "method": "利用自适应重加权方案优化评分功能，并引入回放缓冲机制来减少在评分过渡期间的覆盖不稳定状况。该方法实现了非一致性分数参数和校准阈值的同时在线调整。", "result": "实验结果显示，AdaptNC在保持目标覆盖率水平的情况下，显著减少了预测区域的体积，优于现有的仅基于阈值的方法。", "conclusion": "通过引入AdaptNC框架，自主系统能够更有效地处理动态环境下的不确定性问题，并且提高了系统的可靠性和效率。"}}
{"id": "2602.01626", "pdf": "https://arxiv.org/pdf/2602.01626", "abs": "https://arxiv.org/abs/2602.01626", "authors": ["Mehdi Setayesh", "Mahdi Beitollahi", "Yasser H. Khalil", "Hongliang Li"], "title": "Toward Enhancing Representation Learning in Federated Multi-Task Settings", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted at ICLR 2026", "summary": "Federated multi-task learning (FMTL) seeks to collaboratively train customized models for users with different tasks while preserving data privacy. Most existing approaches assume model congruity (i.e., the use of fully or partially homogeneous models) across users, which limits their applicability in realistic settings. To overcome this limitation, we aim to learn a shared representation space across tasks rather than shared model parameters. To this end, we propose Muscle loss, a novel contrastive learning objective that simultaneously aligns representations from all participating models. Unlike existing multi-view or multi-model contrastive methods, which typically align models pairwise, Muscle loss can effectively capture dependencies across tasks because its minimization is equivalent to the maximization of mutual information among all the models' representations. Building on this principle, we develop FedMuscle, a practical and communication-efficient FMTL algorithm that naturally handles both model and task heterogeneity. Experiments on diverse image and language tasks demonstrate that FedMuscle consistently outperforms state-of-the-art baselines, delivering substantial improvements and robust performance across heterogeneous settings.", "AI": {"tldr": "本文提出了一种新的对比学习目标Muscle loss，用于联邦多任务学习场景下不同用户模型的共享表示空间学习。", "motivation": "现有的联邦多任务学习方法通常假设模型同质性，限制了在现实场景中的应用。为了克服这一限制，提出了同时对齐所有参与模型的表示的新方法。", "method": "提出了一种新的对比学习目标Muscle loss以及基于该原理开发的FedMuscle算法，该算法可以自然处理模型和任务异构性。", "result": "实验表明，提出的FedMuscle在各种图像和语言任务上均优于现有基线方法，表现更加稳健。", "conclusion": "通过学习共享表示空间，提出的联邦多任务学习框架能够有效克服模型同质性的限制，并表现出良好的性能。"}}
{"id": "2602.01624", "pdf": "https://arxiv.org/pdf/2602.01624", "abs": "https://arxiv.org/abs/2602.01624", "authors": ["Minh-Quan Le", "Gaurav Mittal", "Cheng Zhao", "David Gu", "Dimitris Samaras", "Mei Chen"], "title": "PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present $\\texttt{PISCES}$, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, $\\texttt{PISCES}$ uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, $\\texttt{PISCES}$ is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that $\\texttt{PISCES}$ outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning.", "AI": {"tldr": "PISCES是一种无需注释的文本到视频生成后训练算法，通过最优传输对齐奖励模块提高生成视频的质量和语义一致性。", "motivation": "当前方法依赖大规模人工偏好注释或预训练视觉语言模型中的错位嵌入，限制了可扩展性或监督效果。PISCES旨在解决这些问题。", "method": "PISCES使用最优传输在分布级和离散令牌级别对齐文本与视频的嵌入，并通过双重OT对齐奖励模块实现两个目标：捕捉视觉质量和时间连贯性的质量奖励，以及确保文本与视频令牌之间语义、时空对应关系的语义奖励。", "result": "实验表明，在短片和长片生成上，PISCES在VBench的质量和语义评分上优于注释基线和无注释方法，并通过人工偏好研究进一步验证其有效性。", "conclusion": "PISCES是首个利用最优传输提高生成后训练中无需标注的奖励监督的方法。实验结果证明了其优越性，且模块兼容多种优化范式。"}}
{"id": "2602.01623", "pdf": "https://arxiv.org/pdf/2602.01623", "abs": "https://arxiv.org/abs/2602.01623", "authors": ["Susan Liang", "Chao Huang", "Filippos Bellos", "Yolo Yunlong Tang", "Qianxiang Shen", "Jing Bi", "Luchuan Song", "Zeliang Zhang", "Jason Corso", "Chenliang Xu"], "title": "Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?", "categories": ["cs.CV"], "comment": null, "summary": "State-of-the-art text-to-video generation models such as Sora 2 and Veo 3 can now produce high-fidelity videos with synchronized audio directly from a textual prompt, marking a new milestone in multi-modal generation. However, evaluating such tri-modal outputs remains an unsolved challenge. Human evaluation is reliable but costly and difficult to scale, while traditional automatic metrics, such as FVD, CLAP, and ViCLIP, focus on isolated modality pairs, struggle with complex prompts, and provide limited interpretability. Omni-modal large language models (omni-LLMs) present a promising alternative: they naturally process audio, video, and text, support rich reasoning, and offer interpretable chain-of-thought feedback. Driven by this, we introduce Omni-Judge, a study assessing whether omni-LLMs can serve as human-aligned judges for text-conditioned audio-video generation. Across nine perceptual and alignment metrics, Omni-Judge achieves correlation comparable to traditional metrics and excels on semantically demanding tasks such as audio-text alignment, video-text alignment, and audio-video-text coherence. It underperforms on high-FPS perceptual metrics, including video quality and audio-video synchronization, due to limited temporal resolution. Omni-Judge provides interpretable explanations that expose semantic or physical inconsistencies, enabling practical downstream uses such as feedback-based refinement. Our findings highlight both the potential and current limitations of omni-LLMs as unified evaluators for multi-modal generation.", "AI": {"tldr": "评估了全模态大语言模型（Omni-Judge）作为文本条件下的音频视频生成的人类一致裁判的能力。", "motivation": "现有的多模态生成评价方法存在成本高、难以规模化和解释性差的问题，因此研究Omni-LLMs是否能作为一个可靠且可扩展的替代方案进行评估。", "method": "通过使用九个感知和对齐指标来测试Omni-Judge，并与传统的自动评价指标（如FVD、CLAP和ViCLIP）进行对比，以评估其性能。", "result": "在语义要求高的任务上表现优异，但在高帧率的感知度量上有局限性。提供解释性的反馈，可以用于下游应用如基于反馈的优化。", "conclusion": "研究结果展示了Omni-LLMs作为多模态生成统一评估器的潜力和当前限制。"}}
{"id": "2602.01619", "pdf": "https://arxiv.org/pdf/2602.01619", "abs": "https://arxiv.org/abs/2602.01619", "authors": ["Seyed Mohammad Hadi Hosseini", "Mahdieh Soleymani Baghshah"], "title": "SUSD: Structured Unsupervised Skill Discovery through State Factorization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as a conference paper at ICLR 2026", "summary": "Unsupervised Skill Discovery (USD) aims to autonomously learn a diverse set of skills without relying on extrinsic rewards. One of the most common USD approaches is to maximize the Mutual Information (MI) between skill latent variables and states. However, MI-based methods tend to favor simple, static skills due to their invariance properties, limiting the discovery of dynamic, task-relevant behaviors. Distance-Maximizing Skill Discovery (DSD) promotes more dynamic skills by leveraging state-space distances, yet still fall short in encouraging comprehensive skill sets that engage all controllable factors or entities in the environment. In this work, we introduce SUSD, a novel framework that harnesses the compositional structure of environments by factorizing the state space into independent components (e.g., objects or controllable entities). SUSD allocates distinct skill variables to different factors, enabling more fine-grained control on the skill discovery process. A dynamic model also tracks learning across factors, adaptively steering the agent's focus toward underexplored factors. This structured approach not only promotes the discovery of richer and more diverse skills, but also yields a factorized skill representation that enables fine-grained and disentangled control over individual entities which facilitates efficient training of compositional downstream tasks via Hierarchical Reinforcement Learning (HRL). Our experimental results across three environments, with factors ranging from 1 to 10, demonstrate that our method can discover diverse and complex skills without supervision, significantly outperforming existing unsupervised skill discovery methods in factorized and complex environments. Code is publicly available at: https://github.com/hadi-hosseini/SUSD.", "AI": {"tldr": "本文提出了一种新的无监督技能发现框架SUSD，通过状态空间分解来促进更丰富的技能学习。", "motivation": "当前的无监督技能发现方法倾向于学习简单的静态技能，而未能充分探索环境中的所有可控因素。因此，提出了SUSD以解决这些问题。", "method": "SUSD通过将状态空间分解为独立组件（如物体或可控制实体），并将不同的技能变量分配给这些因素，从而促进更细粒度的技能发现过程。此外，动态模型跟踪学习过程中各个因素的变化，并根据需要调整关注点。", "result": "实验结果表明，在三个环境中应用SUSD均能有效发现多样且复杂的技能，优于现有无监督技能发现方法。", "conclusion": "SUSD通过结构化的状态空间分解和动态模型调优，能够更好地促进复杂环境中的技能学习，并为下游任务提供更细粒度的控制。"}}
{"id": "2602.01614", "pdf": "https://arxiv.org/pdf/2602.01614", "abs": "https://arxiv.org/abs/2602.01614", "authors": ["Qi Cheng", "Licheng Liu", "Yao Zhang", "Mu Hong", "Yiqun Xie", "Xiaowei Jia"], "title": "AgroFlux: A Spatial-Temporal Benchmark for Carbon and Nitrogen Flux Prediction in Agricultural Ecosystems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Agroecosystem, which heavily influenced by human actions and accounts for a quarter of global greenhouse gas emissions (GHGs), plays a crucial role in mitigating global climate change and securing environmental sustainability. However, we can't manage what we can't measure. Accurately quantifying the pools and fluxes in the carbon, nutrient, and water nexus of the agroecosystem is therefore essential for understanding the underlying drivers of GHG and developing effective mitigation strategies. Conventional approaches like soil sampling, process-based models, and black-box machine learning models are facing challenges such as data sparsity, high spatiotemporal heterogeneity, and complex subsurface biogeochemical and physical processes. Developing new trustworthy approaches such as AI-empowered models, will require the AI-ready benchmark dataset and outlined protocols, which unfortunately do not exist. In this work, we introduce a first-of-its-kind spatial-temporal agroecosystem GHG benchmark dataset that integrates physics-based model simulations from Ecosys and DayCent with real-world observations from eddy covariance flux towers and controlled-environment facilities. We evaluate the performance of various sequential deep learning models on carbon and nitrogen flux prediction, including LSTM-based models, temporal CNN-based model, and Transformer-based models. Furthermore, we explored transfer learning to leverage simulated data to improve the generalization of deep learning models on real-world observations. Our benchmark dataset and evaluation framework contribute to the development of more accurate and scalable AI-driven agroecosystem models, advancing our understanding of ecosystem-climate interactions.", "AI": {"tldr": "构建了一个用于农业生态系统碳氮通量预测的时空基准数据集，并评估了几种序列深度学习模型的性能。", "motivation": "准确量化农业生态系统的碳、养分和水循环对于理解温室气体排放驱动因素及制定有效的缓解策略至关重要，但传统方法面临挑战。", "method": "结合物理建模模拟与实际观测数据构建基准数据集；采用LSTM、CNN和Transformer等深度学习模型进行预测，并探索迁移学习改进泛化能力。", "result": "展示了不同深度学习模型在碳氮通量预测中的性能表现。", "conclusion": "开发了首个农业生态系统温室气体时空基准，推动更准确可扩展的AI驱动生态建模方法的发展，增进对生态系统与气候交互作用的理解。"}}
{"id": "2602.01613", "pdf": "https://arxiv.org/pdf/2602.01613", "abs": "https://arxiv.org/abs/2602.01613", "authors": ["Sergii Kozyrev", "Davyd Maiboroda"], "title": "A Practical Tensor-Network Compression Pipeline for Production-Scale Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "Large language models are limited in deployment by GPU memory and inference latency. We present Minima, a production compression pipeline that learns where and how to structurally compress a Transformer and turns that compression into real serving gains. Minima trains a lightweight convolutional predictor to estimate layer- and patch-level sensitivity, applies a mixture of Tucker, tensor-train, and tensor-ring decompositions to low-sensitivity regions, performs a short healing fine-tune, and executes the resulting operators with custom Triton and CUDA kernels. The reduced memory footprint enables speculative decoding with a small draft model and a larger verifier. On Qwen3-32B at an 8k-token context window, Minima reduces peak VRAM from 64 GiB to 40 GiB. For a single active request, throughput increases from 40 tokens per second (baseline) to 50 tokens per second (Minima) and 75 tokens per second (Minima with speculative decoding). Under 50 parallel requests, throughput is 34, 44, and 53 tokens per second respectively, showing that Minima remains effective under high concurrency even when speculative decoding gains compress. We position Minima relative to recent tensor-network, low-rank plus quantization, and cross-layer sharing methods, and argue that it is a practical step toward more aggressive structural compression via shared tensor backbones with tiny per-layer adapters.", "AI": {"tldr": "该论文提出了一种名为Minima的生产级压缩流水线，旨在通过结构性压缩Transformer模型来减少GPU内存占用和加速推理。", "motivation": "大规模语言模型在部署时受限于GPU内存和推理延迟。为了提高其在实际应用中的性能，作者开发了Minima压缩方法以减轻这些问题。", "method": "Minima使用轻量级卷积预测器估计层和补丁级别的敏感度，并对低敏感区域进行Tucker、张量链路和张量环分解。之后它会执行快速微调，并用定制的Triton和CUDA内核执行操作，最终实现模型压缩。", "result": "应用Minima后，在Qwen3-32B模型上，上下文窗口为8k令牌时，峰值VRAM从64GiB减少到40GiB。单个请求的吞吐量也显著增加：基线情况下是每秒40个令牌，使用Minima时达到每秒50个令牌；开启推测性解码后更是提升至每秒75个令牌。", "conclusion": "Minima是一个实用的方法，可以作为更激进的结构性压缩技术的前进步骤。它不仅在单线程请求中表现出色，在高并发环境下也保持了高效性能，显示出其广泛应用前景和潜力。"}}
{"id": "2602.01610", "pdf": "https://arxiv.org/pdf/2602.01610", "abs": "https://arxiv.org/abs/2602.01610", "authors": ["Zitao Guo", "Changyang Jiang", "Tianhong Zhao", "Jinzhou Cao", "Genan Dai", "Bowen Zhang"], "title": "ToPT: Task-Oriented Prompt Tuning for Urban Region Representation Learning", "categories": ["cs.AI", "cs.LG"], "comment": "The paper has been accepted by ICASSP 2026", "summary": "Learning effective region embeddings from heterogeneous urban data underpins key urban computing tasks (e.g., crime prediction, resource allocation). However, prevailing two-stage methods yield task-agnostic representations, decoupling them from downstream objectives. Recent prompt-based approaches attempt to fix this but introduce two challenges: they often lack explicit spatial priors, causing spatially incoherent inter-region modeling, and they lack robust mechanisms for explicit task-semantic alignment. We propose ToPT, a two-stage framework that delivers spatially consistent fusion and explicit task alignment. ToPT consists of two modules: spatial-aware region embedding learning (SREL) and task-aware prompting for region embeddings (Prompt4RE). SREL employs a Graphormer-based fusion module that injects spatial priors-distance and regional centrality-as learnable attention biases to capture coherent, interpretable inter-region interactions. Prompt4RE performs task-oriented prompting: a frozen multimodal large language model (MLLM) processes task-specific templates to obtain semantic vectors, which are aligned with region embeddings via multi-head cross-attention for stable task conditioning. Experiments across multiple tasks and cities show state-of-the-art performance, with improvements of up to 64.2\\%, validating the necessity and complementarity of spatial priors and prompt-region alignment. The code is available at https://github.com/townSeven/Prompt4RE.git.", "AI": {"tldr": "提出了一种名为ToPT的任务导向提示调优方法，用于城市区域表征学习。", "motivation": "当前两阶段的方法产生的是任务无关的表示，并且最近基于提示的方法缺乏显式的空间先验和明确的任务语义对齐机制。因此提出了ToPT以解决这些问题。", "method": "ToPT框架由两个模块组成：SREL，通过Graphormer融合模型注入距离和区域中心性作为学习注意力偏差；Prompt4RE执行任务导向的提示调整，利用冻结的多模态大型语言模型处理特定任务模板以获取语义向量，并通过交叉注意力与区域嵌入对齐。", "result": "实验结果表明，ToPT在多个城市和地区任务上表现出色，提高了64.2%的表现。", "conclusion": "验证了空间先验和提示-区域对齐的必要性和互补性。"}}
{"id": "2602.01609", "pdf": "https://arxiv.org/pdf/2602.01609", "abs": "https://arxiv.org/abs/2602.01609", "authors": ["Junqing Lin", "Xingyu Zheng", "Pei Cheng", "Bin Fu", "Jingwei Sun", "Guangzhong Sun"], "title": "Token Pruning for In-Context Generation in Diffusion Transformers", "categories": ["cs.CV"], "comment": "20 pages", "summary": "In-context generation significantly enhances Diffusion Transformers (DiTs) by enabling controllable image-to-image generation through reference examples. However, the resulting input concatenation drastically increases sequence length, creating a substantial computational bottleneck. Existing token reduction techniques, primarily tailored for text-to-image synthesis, fall short in this paradigm as they apply uniform reduction strategies, overlooking the inherent role asymmetry between reference contexts and target latents across spatial, temporal, and functional dimensions. To bridge this gap, we introduce ToPi, a training-free token pruning framework tailored for in-context generation in DiTs. Specifically, ToPi utilizes offline calibration-driven sensitivity analysis to identify pivotal attention layers, serving as a robust proxy for redundancy estimation. Leveraging these layers, we derive a novel influence metric to quantify the contribution of each context token for selective pruning, coupled with a temporal update strategy that adapts to the evolving diffusion trajectory. Empirical evaluations demonstrate that ToPi can achieve over 30\\% speedup in inference while maintaining structural fidelity and visual consistency across complex image generation tasks.", "AI": {"tldr": "本文提出了一种名为ToPi的训练无关性令牌修剪框架，用于提升扩散变换器在上下文生成中的效率。", "motivation": "上下文生成虽然大大增强了扩散变换器的能力，但输入拼接导致序列长度剧增，形成计算瓶颈。现有令牌减少技术对此问题解决不佳，因此提出新的方法来应对这一挑战。", "method": "ToPi采用离线校准驱动的敏感性分析识别关键注意力层，并基于此开发了一种影响度量以量化每个上下文令牌的重要性，用于选择性修剪。同时，引入时序更新策略适应扩散轨迹的变化。", "result": "实验表明，ToPi能够在保持结构一致性和视觉连续性的前提下将推理速度提高超过30%。", "conclusion": "本文通过提出ToPi框架显著提升了基于上下文生成的Diffusion Transformers在复杂图像生成任务中的性能和效率。"}}
{"id": "2602.01608", "pdf": "https://arxiv.org/pdf/2602.01608", "abs": "https://arxiv.org/abs/2602.01608", "authors": ["Mu Yuan", "Liekang Zeng", "Guoliang Xing", "Lan Zhang", "Yunhao Liu"], "title": "Reasoning with Autoregressive-Diffusion Collaborative Thoughts", "categories": ["cs.AI"], "comment": null, "summary": "Autoregressive and diffusion models represent two complementary generative paradigms. Autoregressive models excel at sequential planning and constraint composition, yet struggle with tasks that require explicit spatial or physical grounding. Diffusion models, in contrast, capture rich spatial structure through high-dimensional generation, but lack the stepwise logical control needed to satisfy complex, multi-stage constraints or to reliably identify and correct errors. We introduce Collaborative Thoughts, a unified collaborative framework that enables autoregressive and diffusion models to reason and generate jointly through a closed-loop interaction. In Collaborative Thoughts, autoregressive models perform structured planning and constraint management, diffusion models instantiate these constraints as intermediate visual thoughts, and a vision-based critic module evaluates whether the visual thoughts satisfy the intended structural and physical requirements. This feedback is then used to iteratively refine subsequent planning and generation steps, mitigating error propagation across modalities. Importantly, Collaborative Thoughts uses the same collaborative loop regardless of whether the task is autoregressive question answering or diffusion-based visual generation. Through representative examples, we illustrate how Collaborative Thoughts can improve the reliability of spatial reasoning and the controllability of generation.", "AI": {"tldr": "本文提出了一种名为Collaborative Thoughts的统一协作框架，使自回归模型和扩散模型能够通过闭环交互共同推理和生成。", "motivation": "自回归模型在序列规划和约束组合方面表现出色，但在需要明确空间或物理基础的任务中存在困难。扩散模型则擅长捕捉丰富的空间结构，但缺乏满足复杂多阶段约束的逐步逻辑控制能力及可靠地识别和纠正错误的能力。", "method": "Collaborative Thoughts框架通过闭环交互使自回归模型进行结构化规划和约束管理，扩散模型实现这些约束作为中间视觉思考，同时一个基于视觉的批评模块评估这些视觉想法是否满足预期的结构性和物理要求。这种反馈用于迭代改进后续的计划和生成步骤。", "result": "该方法在提高空间推理的可靠性以及控制生成方面取得了进展。", "conclusion": "Collaborative Thoughts框架通过闭环交互，增强了自回归模型与扩散模型的能力，并展示了其在解决复杂任务上的潜力。"}}
{"id": "2602.01606", "pdf": "https://arxiv.org/pdf/2602.01606", "abs": "https://arxiv.org/abs/2602.01606", "authors": ["Zeqiao Li", "Yijing Wang", "Haoyu Wang", "Zheng Li", "Zhiqiang Zuo"], "title": "Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion policies are expressive yet incur high inference latency. Flow Matching (FM) enables one-step generation, but integrating it into Maximum Entropy Reinforcement Learning (MaxEnt RL) is challenging: the optimal policy is an intractable energy-based distribution, and the efficient log-likelihood estimation required to balance exploration and exploitation suffers from severe discretization bias. We propose \\textbf{F}low-based \\textbf{L}og-likelihood-\\textbf{A}ware \\textbf{M}aximum \\textbf{E}ntropy RL (\\textbf{FLAME}), a principled framework that addresses these challenges. First, we derive a Q-Reweighted FM objective that bypasses partition function estimation via importance reweighting. Second, we design a decoupled entropy estimator that rigorously corrects bias, which enables efficient exploration and brings the policy closer to the optimal MaxEnt policy. Third, we integrate the MeanFlow formulation to achieve expressive and efficient one-step control. Empirical results on MuJoCo show that FLAME outperforms Gaussian baselines and matches multi-step diffusion policies with significantly lower inference cost. Code is available at https://github.com/lzqw/FLAME.", "AI": {"tldr": "本文提出了一种新的框架FLAME，用于优化最大熵强化学习中的流匹配方法，提高决策效率。", "motivation": "扩散策略虽然表达能力强，但推理延迟高。流匹配（FM）能实现一步生成，但在最大熵强化学习中整合困难：最优策略是难以计算的能量基分布，且高效的对数似然估计在平衡探索与利用时面临严重的离散偏差问题。", "method": "提出了一种基于流动的、对数似然感知的最大熵RL框架FLAME。首先，推导出一个Q-Reweighted FM目标函数以通过重要性重加权绕过分区函数计算。其次，设计了一个去耦合的熵估计器来严格校正偏差。最后，整合MeanFlow公式实现表达性和效率更高的一步控制。", "result": "实验结果表明，在MuJoCo环境上FLAME优于高斯基线，并且与多步扩散策略的表现相当，但推理成本显著降低。", "conclusion": "提出的方法解决了传统最大熵RL中流匹配整合的问题，实现了高效的一步决策并提高了性能。"}}
{"id": "2602.01601", "pdf": "https://arxiv.org/pdf/2602.01601", "abs": "https://arxiv.org/abs/2602.01601", "authors": ["Hieu Trung Nguyen", "Bao Nguyen", "Wenao Ma", "Yuzhi Zhao", "Ruifeng She", "Viet Anh Nguyen"], "title": "Adaptive Rollout Allocation for Online Reinforcement Learning with Verifiable Rewards", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted at ICLR 2026", "summary": "Sampling efficiency is a key bottleneck in reinforcement learning with verifiable rewards. Existing group-based policy optimization methods, such as GRPO, allocate a fixed number of rollouts for all training prompts. This uniform allocation implicitly treats all prompts as equally informative, and could lead to inefficient computational budget usage and impede training progress. We introduce VIP, a Variance-Informed Predictive allocation strategy that allocates a given rollout budget to the prompts in the incumbent batch to minimize the expected gradient variance of the policy update. At each iteration, VIP uses a lightweight Gaussian process model to predict per-prompt success probabilities based on recent rollouts. These probability predictions are translated into variance estimates, which are then fed into a convex optimization problem to determine the optimal rollout allocations under a hard compute budget constraint. Empirical results show that VIP consistently improves sampling efficiency and achieves higher performance than uniform or heuristic allocation strategies in multiple benchmarks.", "AI": {"tldr": "介绍了一种新的采样策略VIP，通过预测成功率来动态分配计算预算，以提高强化学习中的样本效率。", "motivation": "现有方法如GRPO采用固定数量的rollout分配给所有训练提示，导致计算资源使用不均衡和低效。为解决此问题，提出了VIP策略来改进采样效率。", "method": "利用轻量级高斯过程模型预测每个提示的成功概率，并将其转化为方差估计。通过解决一个凸优化问题，在严格的计算预算下确定最优的rollout分配方案。", "result": "在多个基准测试中，VIP展示了比固定或启发式方法更高的采样效率和性能。", "conclusion": "VIP策略提高了强化学习中的样本利用率和训练表现，是一个有效的策略。"}}
{"id": "2602.01599", "pdf": "https://arxiv.org/pdf/2602.01599", "abs": "https://arxiv.org/abs/2602.01599", "authors": ["Israel Adewuyi", "Solomon Okibe", "Vladmir Ivanov"], "title": "The Multiple Ticket Hypothesis: Random Sparse Subnetworks Suffice for RLVR", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Lottery Ticket Hypothesis demonstrated that sparse subnetworks can match full-model performance, suggesting parameter redundancy. Meanwhile, in Reinforcement Learning with Verifiable Rewards (RLVR), recent work has shown that updates concentrate on a sparse subset of parameters, which further lends evidence to this underlying redundancy. We study the simplest possible way to exploit this redundancy: training only a randomly selected subset of parameters at extreme sparsities. Empirically, we find that training just 1\\% of parameters matches or exceeds full-parameter RLVR finetuning across 3 models and 2 task domains. Moreover, different random masks show minimal overlap ($\\leq 0.005$ Jaccard similarity) and yet all succeed, suggesting pretrained models contain many viable sparse subnetworks rather than one privileged set. We term this the Multiple Ticket Hypothesis. We explain this phenomenon through the implicit per-step KL constraint in RLVR, which restricts updates to a low-dimensional subspace, enabling arbitrary sparse masks to succeed.", "AI": {"tldr": "研究通过随机选取少量参数进行训练，探讨预训练模型中的冗余性，并提出多个有效子网络的存在。", "motivation": "基于Lottery Ticket Hypothesis和RLVR更新集中的稀疏特性，探索如何利用参数冗余提高效率。", "method": "在极低的参数选择率下（1%），随机选取不同比例的参数进行训练，并分析结果。", "result": "即使仅使用模型中1%的参数进行训练，也能达到或超过完整模型微调的效果，在多个任务和模型上均表现出色。", "conclusion": "预训练模型包含许多有效稀疏子网络而非单一最佳集。通过RLVR中的隐含KL约束解释了随机选择成功的原因。"}}
{"id": "2602.01594", "pdf": "https://arxiv.org/pdf/2602.01594", "abs": "https://arxiv.org/abs/2602.01594", "authors": ["Wenzhuo Liu", "Qiannan Guo", "Zhen Wang", "Wenshuo Wang", "Lei Yang", "Yicheng Qiao", "Lening Wang", "Zhiwei Li", "Chen Lv", "Shanghang Zhang", "Junqiang Xi", "Huaping Liu"], "title": "UV-M3TL: A Unified and Versatile Multimodal Multi-Task Learning Framework for Assistive Driving Perception", "categories": ["cs.CV"], "comment": null, "summary": "Advanced Driver Assistance Systems (ADAS) need to understand human driver behavior while perceiving their navigation context, but jointly learning these heterogeneous tasks would cause inter-task negative transfer and impair system performance. Here, we propose a Unified and Versatile Multimodal Multi-Task Learning (UV-M3TL) framework to simultaneously recognize driver behavior, driver emotion, vehicle behavior, and traffic context, while mitigating inter-task negative transfer. Our framework incorporates two core components: dual-branch spatial channel multimodal embedding (DB-SCME) and adaptive feature-decoupled multi-task loss (AFD-Loss). DB-SCME enhances cross-task knowledge transfer while mitigating task conflicts by employing a dual-branch structure to explicitly model salient task-shared and task-specific features. AFD-Loss improves the stability of joint optimization while guiding the model to learn diverse multi-task representations by introducing an adaptive weighting mechanism based on learning dynamics and feature decoupling constraints. We evaluate our method on the AIDE dataset, and the experimental results demonstrate that UV-M3TL achieves state-of-the-art performance across all four tasks. To further prove the versatility, we evaluate UV-M3TL on additional public multi-task perception benchmarks (BDD100K, CityScapes, NYUD-v2, and PASCAL-Context), where it consistently delivers strong performance across diverse task combinations, attaining state-of-the-art results on most tasks.", "AI": {"tldr": "提出了一种联合学习驾驶员行为、情绪、车辆行为和交通环境的统一且多功能的多模态多任务框架UV-M3TL。", "motivation": "现有ADAS系统在感知导航上下文中理解驾驶员的行为时，难以同时处理这些异质任务而不相互影响表现。为此，该研究旨在通过设计一个有效的联合学习框架来解决这一问题。", "method": "UV-M3TL框架包含两个核心组件：双支路空间通道多模态嵌入(DB-SCME)和自适应特征解耦多任务损失(AFD-Loss)，前者用于增强跨任务知识转移，后者通过引入基于学习动态的自适应加权机制来稳定联合优化。", "result": "实验结果显示，UV-M3TL在AIDE数据集上达到了所有四类任务的最佳性能，并且在多个公共多任务感知基准测试中也表现出色。", "conclusion": "所提出的UV-M3TL框架可以有效地解决多任务学习中的相互干扰问题，并能保持高水平的模型性能。"}}
{"id": "2602.01593", "pdf": "https://arxiv.org/pdf/2602.01593", "abs": "https://arxiv.org/abs/2602.01593", "authors": ["Wenzhuo Zhao", "Keren Fu", "Jiahao He", "Xiaohong Liu", "Qijun Zhao", "Guangtao Zhai"], "title": "Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework", "categories": ["cs.CV"], "comment": null, "summary": "Existing salient object detection (SOD) models are generally constrained by the limited receptive fields of convolutional neural networks (CNNs) and quadratic computational complexity of Transformers. Recently, the emerging state-space model, namely Mamba, has shown great potential in balancing global receptive fields and computational efficiency. As a solution, we propose Saliency Mamba (Samba), a pure Mamba-based architecture that flexibly handles various distinct SOD tasks, including RGB/RGB-D/RGB-T SOD, video SOD (VSOD), RGB-D VSOD, and visible-depth-thermal SOD. Specifically, we rethink the scanning strategy of Mamba for SOD, and introduce a saliency-guided Mamba block (SGMB) that features a spatial neighborhood scanning (SNS) algorithm to preserve the spatial continuity of salient regions. A context-aware upsampling (CAU) method is also proposed to promote hierarchical feature alignment and aggregation by modeling contextual dependencies. As one step further, to avoid the \"task-specific\" problem as in previous SOD solutions, we develop Samba+, which is empowered by training Samba in a multi-task joint manner, leading to a more unified and versatile model. Two crucial components that collaboratively tackle challenges encountered in input of arbitrary modalities and continual adaptation are investigated. Specifically, a hub-and-spoke graph attention (HGA) module facilitates adaptive cross-modal interactive fusion, and a modality-anchored continual learning (MACL) strategy alleviates inter-modal conflicts together with catastrophic forgetting. Extensive experiments demonstrate that Samba individually outperforms existing methods across six SOD tasks on 22 datasets with lower computational cost, whereas Samba+ achieves even superior results on these tasks and datasets by using a single trained versatile model. Additional results further demonstrate the potential of our Samba framework.", "AI": {"tldr": "提出了一种基于Mamba框架的通用和准确的目标显著性检测模型Samba及其改进版本Samba+，用于处理多种模式下的目标显著性检测任务。", "motivation": "现有的目标显著性检测方法受限于CNN的有限感受野以及Transformer的二次计算复杂度。新兴的状态空间模型Mamba在平衡全局感受野和计算效率方面显示出潜力，因此作者提出了一种基于纯Mamba架构的目标显著性检测解决方案以克服现有问题。", "method": "该研究引入了Saliency-guided Mamba Block（SGMB）来处理目标显著性区域的连续性，并提出了上下文感知上采样方法以增强分层特征对齐和聚合。为了进一步解决特定任务的问题，作者开发了Samba+模型，通过多任务联合训练使模型更加统一且具有多功能性。", "result": "实验结果表明，Samba在六个目标显著性检测任务的22个数据集上均优于现有方法，并以更低的成本实现；而Samba+则使用单一训练过的通用模型实现了更好的效果。", "conclusion": "提出的Samba和Samba+框架展示了处理多种模式下的目标显著性检测的强大能力，同时保持了计算效率。"}}
{"id": "2602.01591", "pdf": "https://arxiv.org/pdf/2602.01591", "abs": "https://arxiv.org/abs/2602.01591", "authors": ["Zhixiong Yue", "Zixuan Ni", "Feiyang Ye", "Jinshan Zhang", "Sheng Shen", "Zhenpeng Mi"], "title": "Know Your Step: Faster and Better Alignment for Flow Matching Models via Step-aware Advantages", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in flow matching models, particularly with reinforcement learning (RL), have significantly enhanced human preference alignment in few step text to image generators. However, existing RL based approaches for flow matching models typically rely on numerous denoising steps, while suffering from sparse and imprecise reward signals that often lead to suboptimal alignment. To address these limitations, we propose Temperature Annealed Few step Sampling with Group Relative Policy Optimization (TAFS GRPO), a novel framework for training flow matching text to image models into efficient few step generators well aligned with human preferences. Our method iteratively injects adaptive temporal noise onto the results of one step samples. By repeatedly annealing the model's sampled outputs, it introduces stochasticity into the sampling process while preserving the semantic integrity of each generated image. Moreover, its step aware advantage integration mechanism combines the GRPO to avoid the need for the differentiable of reward function and provide dense and step specific rewards for stable policy optimization. Extensive experiments demonstrate that TAFS GRPO achieves strong performance in few step text to image generation and significantly improves the alignment of generated images with human preferences. The code and models of this work will be available to facilitate further research.", "AI": {"tldr": "提出了一种新的框架，以改进流匹配文本到图像模型的训练，使其在少量步骤内生成与人类偏好更一致的高质量图像。", "motivation": "现有的基于强化学习的方法用于流匹配模型通常需要大量的去噪步骤，并且由于稀疏和不精确的奖励信号导致次优的人类偏好对齐。为了克服这些限制，提出了TAFS GRPO框架以改进文本到图像生成的质量和与人类偏好的一致度。", "method": "通过温度退火少量抽样以及组相对策略优化来引入适应性时间噪声，并结合步骤感知优势机制来提供密集且特定于步骤的奖励，从而避免了对可微分奖励函数的需求并进行稳定的策略优化。", "result": "TAFS GRPO在少量步骤文本到图像生成中表现出强大的性能，并显著提高了生成图像与人类偏好的一致度。", "conclusion": "通过引入TAFS GRPO框架，该方法成功地增强了流匹配模型的效率和质量，在更少的步骤内实现了更高的图像生成质量和更好的人类偏好对齐。"}}
{"id": "2602.01589", "pdf": "https://arxiv.org/pdf/2602.01589", "abs": "https://arxiv.org/abs/2602.01589", "authors": ["Zhehao Xu", "Lok Ming Lui"], "title": "Genus-0 Surface Parameterization using Spherical Beltrami Differentials", "categories": ["cs.GR", "cs.CV", "cs.LG", "math.AG"], "comment": ":30C62; 65D18; 65K10; 68T07", "summary": "Spherical surface parameterization is a fundamental tool in geometry processing and imaging science. For a genus-0 closed surface, many efficient algorithms can map the surface to the sphere; consequently, a broad class of task-driven genus-0 mapping problems can be reduced to constructing a high-quality spherical self-map. However, existing approaches often face a trade-off between satisfying task objectives (e.g., landmark or feature alignment), maintaining bijectivity, and controlling geometric distortion. We introduce the Spherical Beltrami Differential (SBD), a two-chart representation of quasiconformal self-maps of the sphere, and establish its correspondence with spherical homeomorphisms up to conformal automorphisms. Building on the Spectral Beltrami Network (SBN), we propose a neural optimization framework BOOST that optimizes two Beltrami fields on hemispherical stereographic charts and enforces global consistency through explicit seam-aware constraints. Experiments on large-deformation landmark matching and intensity-based spherical registration demonstrate the effectiveness of our proposed framework. We further apply the method to brain cortical surface registration, aligning sulcal landmarks and jointly matching cortical sulci depth maps, showing improved task fidelity with controlled distortion and robust bijective behavior.", "AI": {"tldr": "本文提出了一种基于球面Beltrami微分的新型参数化方法，用于解决具有大变形特征对齐和强度驱动的球面配准问题。", "motivation": "现有算法在满足任务目标、保持双射性和控制几何失真之间存在权衡。为了解决这一问题，本文引入了一种新的表示方式，并提出了一个神经优化框架来提高任务精度。", "method": "提出一种Spherical Beltrami Differential (SBD) 方法，通过谱Beltrami网络（SBN）进行两半球的参数化，并通过显式拼接约束保证全局一致性。", "result": "实验结果表明该方法在大变形特征对齐和强度驱动的配准任务上表现良好，且具有可控失真和鲁棒双射行为。", "conclusion": "所提出的框架能够有效地解决高保真度的任务驱动映射问题，并保持几何质量。"}}
{"id": "2602.01588", "pdf": "https://arxiv.org/pdf/2602.01588", "abs": "https://arxiv.org/abs/2602.01588", "authors": ["Huu Hiep Nguyen", "Minh Hoang Nguyen", "Dung Nguyen", "Hung Le"], "title": "Spectral Text Fusion: A Frequency-Aware Approach to Multimodal Time-Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal time series forecasting is crucial in real-world applications, where decisions depend on both numerical data and contextual signals. The core challenge is to effectively combine temporal numerical patterns with the context embedded in other modalities, such as text. While most existing methods align textual features with time-series patterns one step at a time, they neglect the multiscale temporal influences of contextual information such as time-series cycles and dynamic shifts. This mismatch between local alignment and global textual context can be addressed by spectral decomposition, which separates time series into frequency components capturing both short-term changes and long-term trends. In this paper, we propose SpecTF, a simple yet effective framework that integrates the effect of textual data on time series in the frequency domain. Our method extracts textual embeddings, projects them into the frequency domain, and fuses them with the time series' spectral components using a lightweight cross-attention mechanism. This adaptively reweights frequency bands based on textual relevance before mapping the results back to the temporal domain for predictions. Experimental results demonstrate that SpecTF significantly outperforms state-of-the-art models across diverse multi-modal time series datasets while utilizing considerably fewer parameters. Code is available at https://github.com/hiepnh137/SpecTF.", "AI": {"tldr": "提出了一种频域融合文本信息的方法SpecTF，用于多模态时间序列预测。", "motivation": "现有方法在对齐文本特征与时间序列模式时只考虑了局部的一步对齐，忽视了上下文信息的多重时间尺度影响。为了弥补这种不匹配，采用了谱分解技术来捕捉时间序列中的短周期变化和长期趋势。", "method": "通过提取文本嵌入并将它们映射到频域中，然后使用轻量级交叉注意力机制将这些频域成分与时间序列的频率分量融合在一起，并根据文本的相关性重新加权不同的频率带。最后再映射回时域进行预测。", "result": "实验表明，SpecTF在多个多模态时间序列数据集上显著优于现有的最佳模型，同时参数数量也较少。", "conclusion": "提出的方法在频域中有效地融合了文本信息和时间序列数据，并且展示了优秀的预测性能。"}}
{"id": "2602.01587", "pdf": "https://arxiv.org/pdf/2602.01587", "abs": "https://arxiv.org/abs/2602.01587", "authors": ["Zehua Cheng", "Jianwei Yang", "Wei Dai", "Jiahao Sun"], "title": "Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.", "AI": {"tldr": "提出一种针对大型语言模型（LLMs）的防御框架，通过噪声增强对齐技术来确保模型在遭受攻击时的安全性。", "motivation": "当前的大规模语言模型容易受到适应性的狱破攻击，并且现有的防御措施如GCG效果不佳。为了提高安全性并提供确定的安全证书，本文提出了一个基于统计稳定性保证的框架。", "method": "提出Certified Semantic Smoothing (CSS)和Noise-Augmented Alignment Tuning (NAAT)，通过将输入分为不可变结构提示和可变负载来实现严格的lo范数保证，并使用超几何分布来增强模型的安全性。同时，噪声增强对齐技术能提升稀疏上下文中的性能。", "result": "实验表明，该方法在Llama-3上大幅减少了基于梯度的攻击的成功率，从84.2%降低到1.2%，并且保持了94.1%的良好数值使用率，显著优于降级到74.3%的字符级别基准。", "conclusion": "所提出的方法为大型语言模型提供了确定的安全证书，确保其在可证明半径内的所有对抗变体下依然稳健。"}}
{"id": "2602.01586", "pdf": "https://arxiv.org/pdf/2602.01586", "abs": "https://arxiv.org/abs/2602.01586", "authors": ["Wencan Cheng", "Gim Hee Lee"], "title": "HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation", "categories": ["cs.CV"], "comment": "AAAI accepted", "summary": "3D hand pose estimation that involves accurate estimation of 3D human hand keypoint locations is crucial for many human-computer interaction applications such as augmented reality. However, this task poses significant challenges due to self-occlusion of the hands and occlusions caused by interactions with objects. In this paper, we propose HandMCM to address these challenges. Our HandMCM is a novel method based on the powerful state space model (Mamba). By incorporating modules for local information injection/filtering and correspondence modeling, the proposed correspondence Mamba effectively learns the highly dynamic kinematic topology of keypoints across various occlusion scenarios. Moreover, by integrating multi-modal image features, we enhance the robustness and representational capacity of the input, leading to more accurate hand pose estimation. Empirical evaluations on three benchmark datasets demonstrate that our model significantly outperforms current state-of-the-art methods, particularly in challenging scenarios involving severe occlusions. These results highlight the potential of our approach to advance the accuracy and reliability of 3D hand pose estimation in practical applications.", "AI": {"tldr": "提出了一种基于状态空间模型的多模态点云对应关系方法，用于准确估计3D手部姿态。", "motivation": "为了克服手部自遮挡和与物体交互时产生的遮挡问题，提高三维手部姿态估计的准确性。", "method": "HandMCM利用了强大的状态空间模型（Mamba），并加入局部信息注入/过滤模块及对应关系建模来学习关键点间的动态拓扑结构。同时，通过融合多模态图像特征提升了输入数据的鲁棒性和表示能力。", "result": "在三个基准数据集上的实验结果表明，该方法显著优于当前最先进的技术，尤其是在严重遮挡的情况下表现更优。", "conclusion": "HandMCM的有效性证明了其能够提升三维手部姿态估计的准确性和可靠性，在实际应用中具有广阔的前景。"}}
{"id": "2602.01582", "pdf": "https://arxiv.org/pdf/2602.01582", "abs": "https://arxiv.org/abs/2602.01582", "authors": ["Haoyu Lei", "Mohammad Jalali", "Chin Wa Lau", "Farzan Farnia"], "title": "On the Fragility of AI-Based Channel Decoders under Small Channel Perturbations", "categories": ["cs.IT", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in deep learning have led to AI-based error correction decoders that report empirical performance improvements over traditional belief-propagation (BP) decoding on AWGN channels. While such gains are promising, a fundamental question remains: where do these improvements come from, and what cost is paid to achieve them? In this work, we study this question through the lens of robustness to distributional shifts at the channel output. We evaluate both input-dependent adversarial perturbations (FGM and projected gradient methods under $\\ell_2$ constraints) and universal adversarial perturbations that apply a single norm-bounded shift to all received vectors. Our results show that recent AI decoders, including ECCT and CrossMPT, could suffer significant performance degradation under such perturbations, despite superior nominal performance under i.i.d. AWGN. Moreover, adversarial perturbations transfer relatively strongly between AI decoders but weakly to BP-based decoders, and universal perturbations are substantially more harmful than random perturbations of equal norm. These numerical findings suggest a potential robustness cost and higher sensitivity to channel distribution underlying recent AI decoding gains.", "AI": {"tldr": "本文研究了AI基于的错误校正解码器在AWGN信道输出分布偏移下的鲁棒性问题，发现这些解码器可能在特定扰动下性能严重下降。", "motivation": "探索深度学习在错误纠正编码中的应用优势及其潜在代价，特别是在面对信道扰动时的表现。", "method": "使用输入依赖的对抗性扰动和通用型扰动评估AI解码器在AWGN信道下的稳健性，并对比传统信念传播解码器的表现。", "result": "结果显示，尽管AI解码器在标准测试中表现优越，但在特定类型的扰动下性能显著下降；且这种脆弱性跨AI解码器较强而对传统BP解码器较弱。", "conclusion": "研究揭示了深度学习方法应用于错误校正编码中的潜在鲁棒性问题，这表明需进一步探索更稳健的算法以应对实际应用中可能遇到的各种信道扰动。"}}
{"id": "2602.01579", "pdf": "https://arxiv.org/pdf/2602.01579", "abs": "https://arxiv.org/abs/2602.01579", "authors": ["Chuyang Zhang", "Bin Yu", "Yuchao Wang", "Mansi Yuan", "Wanqi Wang", "Seungwoo Je", "Pengcheng An"], "title": "ASafePlace: User-Led Personalization of VR Relaxation via an Art Therapy Activity", "categories": ["cs.HC"], "comment": null, "summary": "To overcome the lack of deep personalization in standard biofeedback methods, we introduce ASafePlace, a system utilizing an AI-powered, art-therapy-inspired exercise called The Safe Place, to create a personalized VR biofeedback experience. In our system, users sketch a personal sanctuary from memory, which is then transformed into a customized 360 virtual environment with personalized audio guidance for relaxation training. A study with 52 participants showed this approach effectively reduced anxiety and increased user presence, while the integration of art-therapy-inspired activity and biofeedback produced strong improvements in physiological relaxation, measured by heart rate variability and respiration rate. Qualitative results showed how participants' sense of familiarity and presence was enhanced by the symbolic elements and natural sanctuaries created from their autobiographical memories. Our findings demonstrate that art-therapy-inspired activity is a powerful tool for creating highly effective and individualized relaxation experiences, naturally connecting the virtual environment to a user's core memories and emotions.", "AI": {"tldr": "ASafePlace利用AI和艺术疗法技术，让用户通过绘制个人避难所来创建个性化的VR放松体验。", "motivation": "为了克服标准生物反馈方法中的个性化不足问题，该研究提出了一种结合艺术疗法和个人记忆的AI驱动方案。", "method": "用户在虚拟现实中从记忆中勾勒出个人安全庇护所，并由AI转化成一个定制的360度环境。同时提供个性化的音频引导来帮助放松训练。", "result": "参与者焦虑水平降低，存在感增加；生理上也显示出更强的放松效果，例如心率变异性以及呼吸频率的变化。定性结果显示，参与者由于个人记忆和情感与虚拟环境之间的联系增强而感到熟悉和投入。", "conclusion": "艺术疗法启发活动是一种强大的工具，可以创造高效且个性化的放松体验，自然地将虚拟环境与用户的核心记忆和情绪联系起来"}}
{"id": "2602.01578", "pdf": "https://arxiv.org/pdf/2602.01578", "abs": "https://arxiv.org/abs/2602.01578", "authors": ["Arijit Chakma", "Peng He", "Honglu Liu", "Zeyuan Wang", "Tingting Li", "Tiffany D. Do", "Feng Liu"], "title": "DrawSim-PD: Simulating Student Science Drawings to Support NGSS-Aligned Teacher Diagnostic Reasoning", "categories": ["cs.CY", "cs.AI"], "comment": "26 pages, 12 figures", "summary": "Developing expertise in diagnostic reasoning requires practice with diverse student artifacts, yet privacy regulations prohibit sharing authentic student work for teacher professional development (PD) at scale. We present DrawSim-PD, the first generative framework that simulates NGSS-aligned, student-like science drawings exhibiting controllable pedagogical imperfections to support teacher training. Central to our approach are apability profiles--structured cognitive states encoding what students at each performance level can and cannot yet demonstrate. These profiles ensure cross-modal coherence across generated outputs: (i) a student-like drawing, (ii) a first-person reasoning narrative, and (iii) a teacher-facing diagnostic concept map. Using 100 curated NGSS topics spanning K-12, we construct a corpus of 10,000 systematically structured artifacts. Through an expert-based feasibility evaluation, K--12 science educators verified the artifacts' alignment with NGSS expectations (>84% positive on core items) and utility for interpreting student thinking, while identifying refinement opportunities for grade-band extremes. We release this open infrastructure to overcome data scarcity barriers in visual assessment research.", "AI": {"tldr": "开发DrawSim-PD框架，用于生成符合NGSS标准的学生科学绘图模拟物，以支持教师诊断性推理训练。", "motivation": "隐私法规禁止在教师专业发展（PD）中分享真实学生作品，导致缺乏多样化的学生艺术品供教师实践诊断性推理技能。为了克服这一问题，研究者提出了一种生成框架来模拟符合NGSS标准的学生绘图。", "method": "利用能力档案——结构化认知状态编码每个表现水平上学生的能够和不能展示的知识点，以确保跨模态的一致性和准确性，生成（i）学生式的图画，（ii）第一人称推理叙述以及(iii)教师导向的诊断概念图。", "result": "通过基于专家的可行性评估，K-12科学教育工作者验证了这些生成物与NGSS期望的高度一致性，并确认其在解读学生思维方面的实用性。同时指出了某些年级范围内的改进空间。", "conclusion": "该研究成功地开发了一个开放基础设施来克服视觉评估研究中的数据稀缺性问题，为教师提供了宝贵的工具和资源，以提高诊断推理能力并支持学生的科学理解。"}}
{"id": "2602.01577", "pdf": "https://arxiv.org/pdf/2602.01577", "abs": "https://arxiv.org/abs/2602.01577", "authors": ["Wenxuan Pan", "Yang Yang", "Dong Wei", "Zhiyu Zhu", "Jintao Wang", "Huan Wu", "Yao Nie"], "title": "Visible Light Positioning With Lamé Curve LEDs: A Generic Approach for Camera Pose Estimation", "categories": ["eess.SP", "cs.CV"], "comment": "Submitted to an IEEE journal for possible publication", "summary": "Camera-based visible light positioning (VLP) is a promising technique for accurate and low-cost indoor camera pose estimation (CPE). To reduce the number of required light-emitting diodes (LEDs), advanced methods commonly exploit LED shape features for positioning. Although interesting, they are typically restricted to a single LED geometry, leading to failure in heterogeneous LED-shape scenarios. To address this challenge, this paper investigates Lamé curves as a unified representation of common LED shapes and proposes a generic VLP algorithm using Lamé curve-shaped LEDs, termed LC-VLP. In the considered system, multiple ceiling-mounted Lamé curve-shaped LEDs periodically broadcast their curve parameters via visible light communication, which are captured by a camera-equipped receiver. Based on the received LED images and curve parameters, the receiver can estimate the camera pose using LC-VLP. Specifically, an LED database is constructed offline to store the curve parameters, while online positioning is formulated as a nonlinear least-squares problem and solved iteratively. To provide a reliable initialization, a correspondence-free perspective-\\textit{n}-points (FreeP\\textit{n}P) algorithm is further developed, enabling approximate CPE without any pre-calibrated reference points. The performance of LC-VLP is verified by both simulations and experiments. Simulations show that LC-VLP outperforms state-of-the-art methods in both circular- and rectangular-LED scenarios, achieving reductions of over 40% in position error and 25% in rotation error. Experiments further show that LC-VLP can achieve an average position accuracy of less than 4 cm.", "AI": {"tldr": "提出了一种基于Lamé曲线LED的可见光定位方法LC-VLP，用于相机姿态估计。", "motivation": "现有的LED形状特征利用方法通常仅限于单一几何形状，导致在多形态LED场景中失效。为此，研究提出了一个通用的方法来解决这个问题。", "method": "通过使用Lamé曲线作为统一的LED形状表示，提出了一种新的VLP算法LC-VLP。该系统中的多个天花板安装的Lamé曲线LED周期性地通过可见光通信广播其参数，相机捕捉到这些信号后，利用构建好的数据库进行非线性最小二乘问题求解以估计相机姿态。", "result": "仿真和实验表明，与现有方法相比，LC-VLP在圆形和矩形LED场景中均表现优越，位置误差减少超过40%，旋转误差减少25%。实际测试中，平均定位精度小于4厘米。", "conclusion": "该研究展示了一种基于Lamé曲线的通用可见光定位技术，能够有效提高多形态LED环境下的相机姿态估计精度和鲁棒性"}}
{"id": "2602.01576", "pdf": "https://arxiv.org/pdf/2602.01576", "abs": "https://arxiv.org/abs/2602.01576", "authors": ["Woosung Koh", "Sungjun Han", "Segyu Lee", "Se-Young Yun", "Jamin Shin"], "title": "Generative Visual Code Mobile World Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Pre-print (technical report)", "summary": "Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.", "AI": {"tldr": "提出了一种新的生成视觉代码的移动GUI世界模型方法，结合了文本和图像的优势，提高了准确性和效率。", "motivation": "现有的基于文本的世界模型牺牲了视觉保真度，而基于图像的世界模型在文字渲染方面存在不足。为了克服这些限制，作者提出了一个全新的范式：通过可执行代码生成进行视觉世界建模。", "method": "使用Vision-Language Model预测下一个GUI状态作为可执行的网页代码，并引入gWorld数据生成框架自动合成代码训练数据。", "result": "在多个基准测试中，gWorld模型在精度与模型大小之间取得了新的帕累托前沿，在准确性方面优于其他8个开放权重模型，尽管其规模较小。", "conclusion": "通过采用新方法，不仅可以提升视觉保真度和文本渲染的精确性，还能提高下游移动GUI策略性能。"}}
{"id": "2602.01574", "pdf": "https://arxiv.org/pdf/2602.01574", "abs": "https://arxiv.org/abs/2602.01574", "authors": ["Haobo Wang", "Weiqi Luo", "Xiaojun Jia", "Xiaochun Cao"], "title": "SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Large vision-language models (VLMs) are vulnerable to transfer-based adversarial perturbations, enabling attackers to optimize on surrogate models and manipulate black-box VLM outputs. Prior targeted transfer attacks often overfit surrogate-specific embedding space by relying on a single reference and emphasizing final-layer alignment, which underutilizes intermediate semantics and degrades transfer across heterogeneous VLMs. To address this, we propose SGHA-Attack, a Semantic-Guided Hierarchical Alignment framework that adopts multiple target references and enforces intermediate-layer consistency. Concretely, we generate a visually grounded reference pool by sampling a frozen text-to-image model conditioned on the target prompt, and then carefully select the Top-K most semantically relevant anchors under the surrogate to form a weighted mixture for stable optimization guidance. Building on these anchors, SGHA-Attack injects target semantics throughout the feature hierarchy by aligning intermediate visual representations at both global and spatial granularities across multiple depths, and by synchronizing intermediate visual and textual features in a shared latent subspace to provide early cross-modal supervision before the final projection. Extensive experiments on open-source and commercial black-box VLMs show that SGHA-Attack achieves stronger targeted transferability than prior methods and remains robust under preprocessing and purification defenses.", "AI": {"tldr": "提出了一种针对视觉语言模型的攻击框架SGHA-Attack，通过多目标参考和中间层一致性来提高对抗性扰动的传递能力。", "motivation": "现有的迁移攻击方法往往过度依赖单一的目标参考并强调最终层级对齐，导致难以利用中间语义并且在异构视觉语言模型之间传输效果不佳。因此提出了SGHA-Attack以解决这些问题。", "method": "通过从冻结的文本到图像模型生成一系列目标提示相关的样本，并选取最具相关性的几个作为参考进行优化指导；同时在全局和局部空间层面对齐中间层次的视觉表示，同步跨模态特征以提高攻击的有效性。", "result": "实验表明SGHA-Attack在开源和商业黑盒视觉语言模型上的传递攻击效果优于现有方法，并且具备抵抗预处理和净化防御的能力。", "conclusion": "通过引入多目标参考和中间层对齐策略，SGHA-Attack能够显著增强针对视觉语言模型的迁移性攻击能力。"}}
{"id": "2602.01570", "pdf": "https://arxiv.org/pdf/2602.01570", "abs": "https://arxiv.org/abs/2602.01570", "authors": ["Yiwen Jia", "Hao Wei", "Yanhui Zhou", "Chenyang Ge"], "title": "One-Step Diffusion for Perceptual Image Compression", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion-based image compression methods have achieved notable progress, delivering high perceptual quality at low bitrates. However, their practical deployment is hindered by significant inference latency and heavy computational overhead, primarily due to the large number of denoising steps required during decoding. To address this problem, we propose a diffusion-based image compression method that requires only a single-step diffusion process, significantly improving inference speed. To enhance the perceptual quality of reconstructed images, we introduce a discriminator that operates on compact feature representations instead of raw pixels, leveraging the fact that features better capture high-level texture and structural details. Experimental results show that our method delivers comparable compression performance while offering a 46$\\times$ faster inference speed compared to recent diffusion-based approaches. The source code and models are available at https://github.com/cheesejiang/OSDiff.", "AI": {"tldr": "提出了一种基于扩散的一步图像压缩方法，提高解码速度并保持感知质量。", "motivation": "现有扩散基的图像压缩方法因为需要大量的去噪步骤导致推理延迟和计算开销大。为了加快推理速度，同时保证重建图像的质量，提出了单一步骤扩散过程的方法，并引入了操作紧凑特征表示而非原始像素的鉴别器。", "method": "通过引入只进行一次扩散处理的过程来加速解码，同时使用一个基于紧凑特征表示而不是原始像素的鉴别器以增强感知质量。", "result": "实验表明该方法提供了与现有最佳结果相当的压缩性能，并且推理速度提高了46倍。", "conclusion": "所提出的方法在保持高质量图像的同时显著减少了计算时间，使其更适合于实际应用。"}}
{"id": "2602.01568", "pdf": "https://arxiv.org/pdf/2602.01568", "abs": "https://arxiv.org/abs/2602.01568", "authors": ["Hamzah Khan", "Dong Ho Lee", "Jingqi Li", "Tianyu Qiu", "Christian Ellis", "Jesse Milzman", "Wesley Suttle", "David Fridovich-Keil"], "title": "Efficiently Solving Mixed-Hierarchy Games with Quasi-Policy Approximations", "categories": ["cs.GT", "cs.RO"], "comment": null, "summary": "Multi-robot coordination often exhibits hierarchical structure, with some robots' decisions depending on the planned behaviors of others. While game theory provides a principled framework for such interactions, existing solvers struggle to handle mixed information structures that combine simultaneous (Nash) and hierarchical (Stackelberg) decision-making. We study N-robot forest-structured mixed-hierarchy games, in which each robot acts as a Stackelberg leader over its subtree while robots in different branches interact via Nash equilibria. We derive the Karush-Kuhn-Tucker (KKT) first-order optimality conditions for this class of games and show that they involve increasingly high-order derivatives of robots' best-response policies as the hierarchy depth grows, rendering a direct solution intractable. To overcome this challenge, we introduce a quasi-policy approximation that removes higher-order policy derivatives and develop an inexact Newton method for efficiently solving the resulting approximated KKT systems. We prove local exponential convergence of the proposed algorithm for games with non-quadratic objectives and nonlinear constraints. The approach is implemented in a highly optimized Julia library (MixedHierarchyGames.jl) and evaluated in simulated experiments, demonstrating real-time convergence for complex mixed-hierarchy information structures.", "AI": {"tldr": "本文研究了多机器人协调中混合层次结构的博弈问题，提出了一种近似策略的方法，并开发了一个高效的算法来解决此类博弈。", "motivation": "现有解算器在处理同时决策（纳什）和分层决策（斯塔克伯格）相结合的信息结构时存在困难。本文旨在通过引入一种准策略逼近方法克服这一挑战，从而实现对混合层次结构的高效求解。", "method": "提出了一种近似策略的方法，该方法消除了更高阶策略导数的影响，并开发了一个不精确牛顿法来解决由此产生的近似KKT系统。证明了非二次目标函数和非线性约束下的局部指数收敛性。", "result": "算法通过仿真实验进行了评估，展示了在复杂混合层次信息结构中的实时收敛能力。", "conclusion": "本文提出的方法能够有效地处理具有混合层次信息结构的多机器人协调问题，并且已经在模拟实验中得到了验证。"}}
{"id": "2602.01567", "pdf": "https://arxiv.org/pdf/2602.01567", "abs": "https://arxiv.org/abs/2602.01567", "authors": ["Lin Tian", "Marian-Andrei Rizoiu"], "title": "DREAMS: A Social Exchange Theory-Informed Modeling of Misinformation Engagement on Social Media", "categories": ["cs.SI", "cs.AI"], "comment": "12 pages, 5 figures, 3 tables, Accepted by WWW The Web Conference 2026", "summary": "Social media engagement prediction is a central challenge in computational social science, particularly for understanding how users interact with misinformation. Existing approaches often treat engagement as a homogeneous time-series signal, overlooking the heterogeneous social mechanisms and platform designs that shape how misinformation spreads. In this work, we ask: ``Can neural architectures discover social exchange principles from behavioral data alone?'' We introduce \\textsc{Dreams} (\\underline{D}isentangled \\underline{R}epresentations and \\underline{E}pisodic \\underline{A}daptive \\underline{M}odeling for \\underline{S}ocial media misinformation engagements), a social exchange theory-guided framework that models misinformation engagement as a dynamic process of social exchange. Rather than treating engagement as a static outcome, \\textsc{Dreams} models it as a sequence-to-sequence adaptation problem, where each action reflects an evolving negotiation between user effort and social reward conditioned by platform context. It integrates adaptive mechanisms to learn how emotional and contextual signals propagate through time and across platforms. On a cross-platform dataset spanning $7$ platforms and 2.37M posts collected between 2021 and 2025, \\textsc{Dreams} achieves state-of-the-art performance in predicting misinformation engagements, reaching a mean absolute percentage error of $19.25$\\%. This is a $43.6$\\% improvement over the strongest baseline. Beyond predictive gains, the model reveals consistent cross-platform patterns that align with social exchange principles, suggesting that integrating behavioral theory can enhance empirical modeling of online misinformation engagement. The source code is available at: https://github.com/ltian678/DREAMS.", "AI": {"tldr": "研究提出了一种名为DREAMS的框架，该框架通过神经架构从行为数据中发现社会交换原则来预测社交媒体上的错误信息参与度。", "motivation": "现有的方法常常将参与度视为一个静态的时间序列信号，忽略了塑造错误信息传播的社会机制和平台设计。作者希望通过一种新的模型揭示这种复杂的动态过程，并提高对在线错误信息参与度的预测能力。", "method": "DREAMS框架通过神经架构从行为数据中发现社会交换原则，将其视为时间序列适应问题来建模用户的错误信息参与度。该方法考虑了用户努力与社交奖励之间的动态谈判以及情感和情境信号如何随时间和跨平台传播。", "result": "在包含7个平台共计2.37M帖子的数据集上，DREAMS模型实现了19.25%的平均绝对百分比误差预测错误信息参与度，相较于最强基线改进了43.6％。", "conclusion": "该研究展示了一种基于社会交换理论的新框架来建模和理解社交媒体上的错误信息传播。通过整合行为理论可以显著提升对在线错误信息参与度的实证模型效果，并揭示跨平台的一致性模式，符合社会交换原则。"}}
{"id": "2602.01561", "pdf": "https://arxiv.org/pdf/2602.01561", "abs": "https://arxiv.org/abs/2602.01561", "authors": ["Yejin Son", "Saejin Kim", "Dongjun Min", "Younjae Yu"], "title": "Multimodal UNcommonsense: From Odd to Ordinary and Ordinary to Odd", "categories": ["cs.CV", "cs.AI"], "comment": "24 pages", "summary": "Commonsense reasoning in multimodal contexts remains a foundational challenge in artificial intelligence. We introduce Multimodal UNcommonsense(MUN), a benchmark designed to evaluate models' ability to handle scenarios that deviate from typical visual or contextual expectations. MUN pairs visual scenes with surprising or unlikely outcomes described in natural language, prompting models to either rationalize seemingly odd images using everyday logic or uncover unexpected interpretations in ordinary scenes. To support this task, we propose a retrieval-based in-context learning (R-ICL) framework that transfers reasoning capabilities from larger models to smaller ones without additional training. Leveraging a novel Multimodal Ensemble Retriever (MER), our method identifies semantically relevant exemplars even when image and text pairs are deliberately discordant. Experiments show an average improvement of 8.3% over baseline ICL methods, highlighting the effectiveness of R-ICL in low-frequency, atypical settings. MUN opens new directions for evaluating and improving visual-language models' robustness and adaptability in real-world, culturally diverse, and non-prototypical scenarios.", "AI": {"tldr": "本文介绍了一个名为Multimodal UNcommonsense(MUN)的基准测试，用于评估模型处理偏离典型视觉或语境期望场景的能力。", "motivation": "在多模态背景下进行常识推理仍然是人工智能的基础挑战。MUN旨在通过使用自然语言描述意外结果来促使模型对看似奇怪的图像进行日常逻辑解释或者揭示普通场景中的不寻常解释，从而提升模型在这种情境下的表现能力。", "method": "为了支持这项任务，提出了基于检索的上下文学习(R-ICL)框架，并引入了一种新颖的多模态集成检索器(MER)，该方法即使在图像和文本配对故意失调的情况下也能识别语义相关的样本。R-ICL框架可以在不进行额外训练的情况下将大型模型的推理能力转移到小型模型上。", "result": "实验结果表明，相对于基线上下文学习方法，R-ICL框架平均改进了8.3%，展示了其在低频和非典型设置中的有效性。", "conclusion": "MUN为评估和提升视觉-语言模型在现实世界、文化多样性和非原型场景下的健壮性和适应性提供了新的方向。"}}
{"id": "2602.01559", "pdf": "https://arxiv.org/pdf/2602.01559", "abs": "https://arxiv.org/abs/2602.01559", "authors": ["Libo Zhu", "Zihan Zhou", "Zhiyi Zhou", "Yiyang Qu", "Weihang Zhang", "Keyu Shi", "Yifan Fu", "Yulun Zhang"], "title": "Combined Flicker-banding and Moire Removal for Screen-Captured Images", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Capturing display screens with mobile devices has become increasingly common, yet the resulting images often suffer from severe degradations caused by the coexistence of moiré patterns and flicker-banding, leading to significant visual quality degradation. Due to the strong coupling of these two artifacts in real imaging processes, existing methods designed for single degradations fail to generalize to such compound scenarios. In this paper, we present the first systematic study on joint removal of moiré patterns and flicker-banding in screen-captured images, and propose a unified restoration framework, named CLEAR. To support this task, we construct a large-scale dataset containing both moiré patterns and flicker-banding, and introduce an ISP-based flicker simulation pipeline to stabilize model training and expand the degradation distribution. Furthermore, we design a frequency-domain decomposition and re-composition module together with a trajectory alignment loss to enhance the modeling of compound artifacts. Extensive experiments demonstrate that the proposed method consistently. outperforms existing image restoration approaches across multiple evaluation metrics, validating its effectiveness in complex real-world scenarios.", "AI": {"tldr": "本文提出了一个统一的框架（CLEAR）来同时去除屏幕捕获图像中的摩尔纹和闪烁带。", "motivation": "手机等移动设备拍摄显示屏幕时，常常会出现摩尔纹和闪烁带这两种严重的视觉失真。现有的方法只能处理单一类型的问题，无法有效应对这两者的共存情况。", "method": "本文构建了一个大规模的包含两种降质现象的数据集，并提出了一种基于ISP的闪烁模拟流水线以稳定模型训练并扩展退化分布。设计了频域分解和重组模块以及轨迹对齐损失来增强复杂退化场景的学习能力。", "result": "实验结果表明，所提方法在多个评估指标上优于现有的图像恢复方法，在复杂的实际应用场景中表现出色。", "conclusion": "通过联合处理摩尔纹和闪烁带的统一框架（CLEAR），本文有效解决了屏幕捕获图像中的复杂退化问题，并验证了该方法的有效性和优越性。"}}
{"id": "2602.01556", "pdf": "https://arxiv.org/pdf/2602.01556", "abs": "https://arxiv.org/abs/2602.01556", "authors": ["Hong Su"], "title": "Autonomous Question Formation for Large Language Model-Driven AI Systems", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM)-driven AI systems are increasingly important for autonomous decision-making in dynamic and open environments. However, most existing systems rely on predefined tasks and fixed prompts, limiting their ability to autonomously identify what problems should be solved when environmental conditions change. In this paper, we propose a human-simulation-based framework that enables AI systems to autonomously form questions and set tasks by reasoning over their internal states, environmental observations, and interactions with other AI systems. The proposed method treats question formation as a first-class decision process preceding task selection and execution, and integrates internal-driven, environment-aware, and inter-agent-aware prompting scopes to progressively expand cognitive coverage. In addition, the framework supports learning the question-formation process from experience, allowing the system to improve its adaptability and decision quality over time. xperimental results in a multi-agent simulation environment show that environment-aware prompting significantly reduces no-eat events compared with the internal-driven baseline, and inter-agent-aware prompting further reduces cumulative no-eat events by more than 60% over a 20-day simulation, with statistically significant improvements (p < 0.05).", "AI": {"tldr": "提出了一种基于人类模拟的框架，使AI系统能够自主形成问题并设置任务。", "motivation": "现有的LLM驱动的AI系统依赖于预定义的任务和固定提示，限制了它们在环境条件变化时自动生成解决问题的能力。", "method": "该方法将问题生成视为决策过程的一部分，并结合内部状态、环境观察和其他代理交互来扩展认知覆盖范围。框架还支持从经验中学习问题形成过程以提高适应性和决策质量。", "result": "实验结果表明，环境感知提示显著减少了不进食事件，而跨代理感知提示进一步在20天的模拟中将累积不进食事件减少超过60%（p<0.05）。", "conclusion": "框架通过自主问题生成和任务设置提高了LLM驱动AI系统的适应性和决策质量。"}}
{"id": "2602.01554", "pdf": "https://arxiv.org/pdf/2602.01554", "abs": "https://arxiv.org/abs/2602.01554", "authors": ["Lv Tang", "Tianyi Zheng", "Bo Li", "Xingyu Li"], "title": "InfoTok: Regulating Information Flow for Capacity-Constrained Shared Visual Tokenization in Unified MLLMs", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Unified multimodal large language models (MLLMs) integrate image understanding and generation in a single framework, with the visual tokenizer acting as the sole interface that maps visual inputs into tokens for downstream tasks. However, existing shared-token designs are mostly architecture-driven and lack an explicit criterion for what information tokens should preserve to support both understanding and generation. Therefore, we introduce a capacity-constrained perspective, highlighting that in shared-token unified MLLMs the visual tokenizer behaves as a compute-bounded learner, so the token budget should prioritize reusable structure over hard-to-exploit high-entropy variations and redundancy. Motivated by this perspective, we propose InfoTok, an information-regularized visual tokenization mechanism grounded in the Information Bottleneck (IB) principle. InfoTok formulates tokenization as controlling information flow from images to shared tokens to multimodal outputs, yielding a principled trade-off between compression and task relevance via mutual-information regularization. We integrate InfoTok into three representative unified MLLMs without introducing any additional training data. Experiments show consistent improvements on both understanding and generation, supporting information-regularized tokenization as a principled foundation for learning a shared token space in unified MLLMs.", "AI": {"tldr": "本文提出了一种基于信息瓶颈原理的信息调节视觉令牌化机制InfoTok，用于控制统一多模态大语言模型中的信息流。", "motivation": "现有共享令牌设计缺乏明确的标准来规定令牌应该保留哪些信息以支持理解和生成任务。因此，作者从容量受限的角度出发，引入了InfoTok来优化令牌预算的分配策略。", "method": "InfoTok将视觉令牌化过程视为控制图像到共享令牌再到多模态输出的信息流，并通过互信息正则化实现压缩与任务相关性的权衡。", "result": "实验表明，将InfoTok集成到三个代表性的统一MLLM中可以带来理解和生成任务上的一致性改进。", "conclusion": "本文证明了基于信息调节的令牌化是一种学习共享令牌空间的原则基础，并且在不引入额外训练数据的情况下提高了模型性能。"}}
{"id": "2602.01553", "pdf": "https://arxiv.org/pdf/2602.01553", "abs": "https://arxiv.org/abs/2602.01553", "authors": ["Quang Truong", "Yu Song", "Donald Loveland", "Mingxuan Ju", "Tong Zhao", "Neil Shah", "Jiliang Tang"], "title": "Plain Transformers are Surprisingly Powerful Link Predictors", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Link prediction is a core challenge in graph machine learning, demanding models that capture rich and complex topological dependencies. While Graph Neural Networks (GNNs) are the standard solution, state-of-the-art pipelines often rely on explicit structural heuristics or memory-intensive node embeddings -- approaches that struggle to generalize or scale to massive graphs. Emerging Graph Transformers (GTs) offer a potential alternative but often incur significant overhead due to complex structural encodings, hindering their applications to large-scale link prediction. We challenge these sophisticated paradigms with PENCIL, an encoder-only plain Transformer that replaces hand-crafted priors with attention over sampled local subgraphs, retaining the scalability and hardware efficiency of standard Transformers. Through experimental and theoretical analysis, we show that PENCIL extracts richer structural signals than GNNs, implicitly generalizing a broad class of heuristics and subgraph-based expressivity. Empirically, PENCIL outperforms heuristic-informed GNNs and is far more parameter-efficient than ID-embedding--based alternatives, while remaining competitive across diverse benchmarks -- even without node features. Our results challenge the prevailing reliance on complex engineering techniques, demonstrating that simple design choices are potentially sufficient to achieve the same capabilities.", "AI": {"tldr": "本文提出了PENCIL，一种仅使用编码器的普通Transformer模型，用于解决大规模图中的链接预测问题。", "motivation": "现有的链接预测方法依赖于复杂的图形神经网络（GNN）或需要大量内存的节点嵌入，并且难以推广和扩展到大型图。本研究旨在挑战这些复杂的方法，寻求一种更简单、更具可扩展性和硬件效率的方式来实现类似性能。", "method": "PENCIL通过注意力机制在采样的局部子图上进行操作，以替代手工设计的先验知识，从而实现了对丰富结构信号的提取和表达能力。它保持了普通Transformer的可扩展性和平滑运行，同时提高了参数效率。", "result": "实验结果表明，PENCIL比使用启发式信息的GNN模型表现更好，并且在不依赖节点特征的情况下仍然具有竞争力。此外，PENCIL展示了超越传统方法的高效性和优越性能。", "conclusion": "研究结果挑战了对复杂工程技术的过度依赖，证明简单的设计选择可能足以实现与这些技术相同的链接预测能力。"}}
{"id": "2602.01550", "pdf": "https://arxiv.org/pdf/2602.01550", "abs": "https://arxiv.org/abs/2602.01550", "authors": ["S1-NexusAgent Team"], "title": "S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research", "categories": ["cs.AI"], "comment": "In progress", "summary": "Modern scientific research relies on large-scale data, complex workflows, and specialized tools, which existing LLMs and tool-based agents struggle to handle due to limitations in long-horizon planning, robust goal maintenance, and continual learning from execution. To address these issues, in this work, we propose S1-NexusAgent, a self-evolving agent framework designed for multidisciplinary scientific research. S1-NexusAgent adopts a hierarchical Plan-and-CodeAct execution paradigm, decoupling global scientific planning from subtask-level tool execution through a dual-loop architecture, thereby enabling stable modeling of complex research workflows. The system natively supports the Model Context Protocol (MCP), integrates up to thousands of cross-disciplinary scientific tools, and achieves efficient orchestration of heterogeneous research tools via intention-aware dynamic tool retrieval and hot-plug mechanisms. To address long-context and large-scale data challenges in scientific settings, S1-NexusAgent introduces object-reference-based sparse context management, which enables sub-task context isolation and intermediate result compression. Building on this, a Critic Agent automatically evaluates complete execution trajectories and distills high-quality research paths into reusable Scientific Skills, forming a closed loop for continuous self-evolution, which is valuable for sustainable and long-horizon scientific research. Experiments on authoritative scientific benchmarks involving long-horizon planning and complex specialized tool orchestration, including biomini-eval (biology), ChemBench (chemistry), and MatSciBench (material science), demonstrate that S1-NexusAgent achieves state-of-the-art performance, validating its effectiveness and generalization capability in complex scientific tasks.", "AI": {"tldr": "提出了一种名为S1-NexusAgent的自进化代理框架，用于多学科科学研究。", "motivation": "现有的大型语言模型和工具基于代理在处理大规模数据、复杂工作流和专业化工具时存在局限性。这些局限包括长跨度规划能力不足、目标维护不稳健以及从执行中持续学习的能力有限。", "method": "S1-NexusAgent采用了一种分层的计划与代码执行模式，通过双重循环架构将全局科学研究规划与子任务级工具执行解耦，并支持模型上下文协议（MCP）。它还引入了基于对象引用的稀疏上下文管理来解决长上下文和大规模数据挑战。", "result": "在涉及长跨度规划和复杂专业化工具编排的权威科学基准测试中，包括生物、化学和材料科学领域，S1-NexusAgent展示了最先进的性能。", "conclusion": "实验结果证明了S1-NexusAgent的有效性和在复杂科学任务中的泛化能力。"}}
{"id": "2602.01547", "pdf": "https://arxiv.org/pdf/2602.01547", "abs": "https://arxiv.org/abs/2602.01547", "authors": ["Qingran Yang", "Botao Zhao", "Zuheng Kang", "Xue Li", "Yayun He", "Chuhang Liu", "Xulong Zhang", "Xiaoyang Qu", "Junqing Peng", "Jianzong Wang"], "title": "Attention-weighted Centered Kernel Alignment for Knowledge Distillation in Large Audio-Language Models Applied to Speech Emotion Recognition", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "The emergence of Large Audio-Language Models (LALMs) has advanced Speech Emotion Recognition (SER), but their size limits deployment in resource-constrained environments. While Knowledge Distillation is effective for LALM compression, existing methods remain underexplored in distilling the cross-modal projection module (Projector), and often struggle with alignment due to differences in feature dimensions. We propose PL-Distill, a KD framework that combines Projector-Level Distillation (PDist) to align audio embeddings and Logits-Level Distillation (LDist) to align output logits. PDist introduces Attention-weighted Centered Kernel Alignment, a novel approach we propose to highlight important time steps and address dimension mismatches. Meanwhile, LDist minimizes the Kullback-Leibler divergence between teacher and student logits from audio and text modalities. On IEMOCAP, RAVDESS, and SAVEE, PL-Distill compresses an 8.4B-parameter teacher to a compact 1.1B-parameter student, consistently outperforming the teacher, state-of-the-art pretrained models, and other KD baselines across all metrics.", "AI": {"tldr": "提出了一种新的知识蒸馏框架PL-Distill，用于压缩大型音频语言模型以改善语音情感识别。", "motivation": "大尺寸的音频-语言模型限制了其在资源受限环境中的部署。现有的知识蒸馏方法对投影模块（Projector）的应用较少且难以解决特征维度不匹配的问题。", "method": "提出PL-Distill框架，结合项目级别蒸馏(PDist)和输出级蒸馏(LDist)，PDist采用注意力加权的中心核对齐技术以突出重要的时间步骤并处理维度差异；LDist最小化教师与学生模型之间的KL散度。", "result": "在IEMOCAP、RAVDESS和SAVEE数据集上，PL-Distill将一个8.4B参数量的大模型压缩为1.1B参数的小模型，并且性能优于原大模型和其他基线方法。", "conclusion": "所提出的PL-Distill框架在语音情感识别任务中展示了高效的模型压缩能力和优越的性能表现。"}}
{"id": "2602.01544", "pdf": "https://arxiv.org/pdf/2602.01544", "abs": "https://arxiv.org/abs/2602.01544", "authors": ["Sarah Tabassum"], "title": "Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions", "categories": ["cs.CR", "cs.CY", "cs.HC"], "comment": null, "summary": "Security cues, such as warnings and trust signals, are designed as stable interface elements, even though people's lives, contexts, and vulnerabilities change over time. Life transitions including migration, aging, or shifts in institutional environments reshape how risk and trust are understood and acted upon. Yet current systems rarely adapt their security cues to these changing conditions, placing the burden of interpretation on users. In this Works-in-Progress paper, we argue that the static nature of security cues represents a design mismatch with transitional human lives. We draw on prior empirical insights from work on educational migration as a motivating case, and extend the discussion to other life transitions. Building on these insights, we introduce the Transition-Aware Security Cues (TASeC) framework and present speculative design concepts illustrating how security cues might evolve across transition stages. We invite HCI to rethink security cues as longitudinal, life-centered design elements collectively.", "AI": {"tldr": "重新思考安全提示和信任信号的设计，以适应人们生活中的变化。", "motivation": "目前的安全提示设计是静态的，无法适应用户生活中迁移、老龄化或制度环境的变化。这种不匹配增加了用户的解释负担。", "method": "基于教育移民等案例的研究经验，提出了过渡感知安全提示（TASeC）框架，并展示了一些设想的设计概念。", "result": "介绍了如何根据生活变化阶段演进的安全提示设计。", "conclusion": "呼吁人机交互领域将安全提示重新定义为具有长期性和以用户为中心的元素。"}}
{"id": "2602.01541", "pdf": "https://arxiv.org/pdf/2602.01541", "abs": "https://arxiv.org/abs/2602.01541", "authors": ["Boyi Li", "Yifan Shen", "Yuanzhe Liu", "Yifan Xu", "Jiateng Liu", "Xinzhuo Li", "Zhengyuan Li", "Jingyuan Zhu", "Yunhan Zhong", "Fangzhou Lan", "Jianguo Cao", "James M. Rehg", "Heng Ji", "Ismini Lourentzou", "Xu Cao"], "title": "Toward Cognitive Supersensing in Multimodal Large Language Model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights.", "AI": {"tldr": "本文提出了一种新的训练范式——认知超感知，通过整合潜在视觉形象预测（LVIP）头部来增强多模态大规模语言模型的认知能力。", "motivation": "当前的多模态大型语言模型在解决复杂认知问题方面存在不足，特别是在需要抽象视觉细节和视觉记忆的任务中。为了解决这一问题，本文提出了一种新的训练范式以提高语言模型的认知能力。", "method": "引入了潜在视觉形象预测（LVIP）头部，并结合强化学习阶段来优化基于这个基底的文本推理路径，从而形成基于视觉的内部推理链。", "result": "实验结果表明，在CogSense-Bench评估基准上的性能显著优于现有的最佳方法，且在数学和科学领域也表现出更优的表现。", "conclusion": "本文提出的方法有助于弥合感知识别与认知理解之间的差距。"}}
{"id": "2602.01540", "pdf": "https://arxiv.org/pdf/2602.01540", "abs": "https://arxiv.org/abs/2602.01540", "authors": ["Yuehai Chen"], "title": "FSCA-Net: Feature-Separated Cross-Attention Network for Robust Multi-Dataset Training", "categories": ["cs.CV"], "comment": null, "summary": "Crowd counting plays a vital role in public safety, traffic regulation, and smart city management. However, despite the impressive progress achieved by CNN- and Transformer-based models, their performance often deteriorates when applied across diverse environments due to severe domain discrepancies. Direct joint training on multiple datasets, which intuitively should enhance generalization, instead results in negative transfer, as shared and domain-specific representations become entangled. To address this challenge, we propose the Feature Separation and Cross-Attention Network FSCA-Net, a unified framework that explicitly disentangles feature representations into domain-invariant and domain-specific components. A novel cross-attention fusion module adaptively models interactions between these components, ensuring effective knowledge transfer while preserving dataset-specific discriminability. Furthermore, a mutual information optimization objective is introduced to maximize consistency among domain-invariant features and minimize redundancy among domain-specific ones, promoting complementary shared-private representations. Extensive experiments on multiple crowd counting benchmarks demonstrate that FSCA-Net effectively mitigates negative transfer and achieves state-of-the-art cross-dataset generalization, providing a robust and scalable solution for real-world crowd analysis.", "AI": {"tldr": "提出了一种用于增强跨数据集泛化的特征分离交叉注意力网络FSCA-Net。", "motivation": "解决传统模型在不同环境应用时因领域差异而性能下降的问题，以及直接多数据集联合训练导致的负迁移问题。", "method": "设计了特征分离和交叉注意网络FSCA-Net框架，明确区分领域不变性和领域特定性表示，并引入新颖的交叉注意力融合模块以实现有效知识转移。同时优化互信息目标来最大化领域不变特征一致性并最小化领域特有特征冗余。", "result": "在多个人群计数基准测试中展示了FSCA-Net有效缓解负迁移，实现了跨数据集泛化的最新性能。", "conclusion": "提供了一种增强现实世界人群分析鲁棒性和可扩展性的解决方案。"}}
{"id": "2602.01539", "pdf": "https://arxiv.org/pdf/2602.01539", "abs": "https://arxiv.org/abs/2602.01539", "authors": ["Xiaoyu Wen", "Zhida He", "Han Qi", "Ziyu Wan", "Zhongtian Ma", "Ying Wen", "Tianhang Zheng", "Xingcheng Xu", "Chaochao Lu", "Qiaosheng Zhang"], "title": "MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "comment": null, "summary": "Ensuring robust safety alignment is crucial for Large Language Models (LLMs), yet existing defenses often lag behind evolving adversarial attacks due to their \\textbf{reliance on static, pre-collected data distributions}. In this paper, we introduce \\textbf{MAGIC}, a novel multi-turn multi-agent reinforcement learning framework that formulates LLM safety alignment as an adversarial asymmetric game. Specifically, an attacker agent learns to iteratively rewrite original queries into deceptive prompts, while a defender agent simultaneously optimizes its policy to recognize and refuse such inputs. This dynamic process triggers a \\textbf{co-evolution}, where the attacker's ever-changing strategies continuously uncover long-tail vulnerabilities, driving the defender to generalize to unseen attack patterns. Remarkably, we observe that the attacker, endowed with initial reasoning ability, evolves \\textbf{novel, previously unseen combinatorial strategies} through iterative RL training, underscoring our method's substantial potential. Theoretically, we provide insights into a more robust game equilibrium and derive safety guarantees. Extensive experiments validate our framework's effectiveness, demonstrating superior defense success rates without compromising the helpfulness of the model. Our code is available at https://github.com/BattleWen/MAGIC.", "AI": {"tldr": "本文提出了一种名为MAGIC的框架，通过对抗游戏的形式来提高大型语言模型的安全性。", "motivation": "现有的防御措施依赖于静态的数据分布，难以应对不断演变的攻击策略。因此，需要一种能够动态适应和抵御新出现威胁的方法。", "method": "MAGIC是一个多代理强化学习框架，模拟了攻击者尝试生成欺骗性的输入以及防御者识别并拒绝这些输入的过程。", "result": "实验表明，该方法在不降低模型有用性的情况下提高了对未知攻击模式的防御成功率。", "conclusion": "本文的方法通过动态对抗过程增强了LLM的安全性，并提供了理论上的安全保证。"}}
{"id": "2602.01538", "pdf": "https://arxiv.org/pdf/2602.01538", "abs": "https://arxiv.org/abs/2602.01538", "authors": ["Youliang Zhang", "Zhengguang Zhou", "Zhentao Yu", "Ziyao Huang", "Teng Hu", "Sen Liang", "Guozhen Zhang", "Ziqiao Peng", "Shunkai Li", "Yi Chen", "Zixiang Zhou", "Yuan Zhou", "Qinglin Lu", "Xiu Li"], "title": "Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io", "AI": {"tldr": "本文提出了一个新型的双流框架InteractAvatar，用于生成能够进行文本驱动的人与物体交互行为的说话虚拟人物。", "motivation": "现有的方法只能生成简单的全身动作，并不能很好地处理基于环境感知的有控制质量难题的人与物交互任务。因此需要一种新的方法来解决这个问题。", "method": "本文提出了一种双流框架InteractAvatar，其中包括增强环境感知能力的检测模块和一个用于产生文本一致的交互动作的感知和交互模块（PIM），以及一个音频-交互意识生成模块（AIM）以合成表演物体互动的真实说话虚拟人物。通过设计一个运动到视频对齐器，使得PIM和AIM具有类似的网络结构并能够同时生成合理的动作和视频。", "result": "广泛的实验和对比证明了此方法在生成基于环境感知的人与物交互任务中的有效性。", "conclusion": "本文提出的方法能有效地解决文本驱动的说话虚拟人物人与物体互动的问题，并建立了一个基准用于评估这种方法的效果。"}}
{"id": "2602.01536", "pdf": "https://arxiv.org/pdf/2602.01536", "abs": "https://arxiv.org/abs/2602.01536", "authors": ["Shuai Liu", "Siheng Ren", "Xiaoyao Zhu", "Quanmin Liang", "Zefeng Li", "Qiang Li", "Xin Hu", "Kai Huang"], "title": "UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Achieving reliable and efficient planning in complex driving environments requires a model that can reason over the scene's geometry, appearance, and dynamics. We present UniDWM, a unified driving world model that advances autonomous driving through multifaceted representation learning. UniDWM constructs a structure- and dynamic-aware latent world representation that serves as a physically grounded state space, enabling consistent reasoning across perception, prediction, and planning. Specifically, a joint reconstruction pathway learns to recover the scene's structure, including geometry and visual texture, while a collaborative generation framework leverages a conditional diffusion transformer to forecast future world evolution within the latent space. Furthermore, we show that our UniDWM can be deemed as a variation of VAE, which provides theoretical guidance for the multifaceted representation learning. Extensive experiments demonstrate the effectiveness of UniDWM in trajectory planning, 4D reconstruction and generation, highlighting the potential of multifaceted world representations as a foundation for unified driving intelligence. The code will be publicly available at https://github.com/Say2L/UniDWM.", "AI": {"tldr": "构建一个统一的驾驶世界模型，通过多面表示学习提升自动驾驶性能。", "motivation": "在复杂驾驶环境中实现可靠的规划需要一种能够推理场景几何、外观和动态变化的模型。本文提出了UniDWM，旨在通过多面表示学习推动自动驾驶技术的发展。", "method": "UniDWM构建了一个结构感知且动态感知的隐式世界表示，作为物理上可解释的状态空间，并使用联合重建路径来恢复场景结构（包括几何和视觉纹理），同时利用条件扩散变换器在潜在空间中预测未来世界演变。", "result": "实验结果表明，UniDWM在轨迹规划、4D重构和生成方面表现出色，展示了多面表示作为统一驾驶智能基础的潜力。", "conclusion": "通过多面表示学习，UniDWM可以被视为一种变体VAE，并且能够提供理论指导。该模型具有广泛的适用性和有效性，在自动驾驶领域显示出巨大潜力。"}}
{"id": "2602.01535", "pdf": "https://arxiv.org/pdf/2602.01535", "abs": "https://arxiv.org/abs/2602.01535", "authors": ["Huzaifa Mustafa Unjhawala", "Khizar Shaikh", "Luning Bakke", "Radu Serban", "Dan Negrut"], "title": "Co-Design of Rover Wheels and Control using Bayesian Optimization and Rover-Terrain Simulations", "categories": ["cs.RO"], "comment": "19 pages, 15 figures", "summary": "While simulation is vital for optimizing robotic systems, the cost of modeling deformable terrain has long limited its use in full-vehicle studies of off-road autonomous mobility. For example, Discrete Element Method (DEM) simulations are often confined to single-wheel tests, which obscures coupled wheel-vehicle-controller interactions and prevents joint optimization of mechanical design and control. This paper presents a Bayesian optimization framework that co-designs rover wheel geometry and steering controller parameters using high-fidelity, full-vehicle closed-loop simulations on deformable terrain. Using the efficiency and scalability of a continuum-representation model (CRM) for terramechanics, we evaluate candidate designs on trajectories of varying complexity while towing a fixed load. The optimizer tunes wheel parameters (radius, width, and grouser features) and steering PID gains under a multi-objective formulation that balances traversal speed, tracking error, and energy consumption. We compare two strategies: simultaneous co-optimization of wheel and controller parameters versus a sequential approach that decouples mechanical and control design. We analyze trade-offs in performance and computational cost. Across 3,000 full-vehicle simulations, campaigns finish in five to nine days, versus months with the group's earlier DEM-based workflow. Finally, a preliminary hardware study suggests the simulation-optimized wheel designs preserve relative performance trends on the physical rover. Together, these results show that scalable, high-fidelity simulation can enable practical co-optimization of wheel design and control for off-road vehicles on deformable terrain without relying on prohibitively expensive DEM studies. The simulation infrastructure (scripts and models) is released as open source in a public repository to support reproducibility and further research.", "AI": {"tldr": "本文提出了一个基于贝叶斯优化的框架，用于同时设计火星车轮子几何结构和控制参数，使用高保真全车辆闭环模拟。", "motivation": "传统上，由于模拟可变形地形的成本较高，因此在全车辆自主移动研究中很少进行仿真。传统的离散元素方法仅限于单个轮子的测试，无法揭示轮子-车辆-控制器之间的相互作用并优化机械设计和控制。", "method": "使用连续表示模型（CRM）进行高效且可扩展的地形力学模拟，并通过轨迹的复杂度评估候选方案的设计。优化器调整了轮子参数（半径、宽度及抓地齿特征）以及转向PID增益，采用多目标形式化来平衡穿越速度、跟踪误差和能量消耗。", "result": "研究表明，联合优化方法在五到九天内完成3000次全车模拟任务，并且硬件实验表明模拟优化的轮子设计保持了物理火星车上相对性能的趋势。相较于之前的离散元素法流程需要几个月的时间来完成。", "conclusion": "结果表明，可扩展、高保真的仿真能够实现无需依赖昂贵的离散元素方法研究就可行的全车辆轮子设计和控制的同时优化。"}}
{"id": "2602.01533", "pdf": "https://arxiv.org/pdf/2602.01533", "abs": "https://arxiv.org/abs/2602.01533", "authors": ["Zhe Ling", "Sicheng Yu", "Danyu Yang"], "title": "Rotation-free Online Handwritten Character Recognition Using Linear Recurrent Units", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Online handwritten character recognition leverages stroke order and dynamic features, which generally provide higher accuracy and robustness compared with offline recognition. However, in practical applications, rotational deformations can disrupt the spatial layout of strokes, substantially reducing recognition accuracy. Extracting rotation-invariant features therefore remains a challenging open problem. In this work, we employ the Sliding Window Path Signature (SW-PS) to capture local structural features of characters, and introduce the lightweight Linear Recurrent Units (LRU) as the classifier. The LRU combine the fast incremental processing capability of recurrent neural networks (RNN) with the efficient parallel training of state space models (SSM), while reliably modelling dynamic stroke characteristics. We conducted recognition experiments with random rotation angle up to $\\pm 180^{\\circ}$ on three subsets of the CASIA-OLHWDB1.1 dataset: digits, English upper letters, and Chinese radicals. The accuracies achieved after ensemble learning were $99.62\\%$, $96.67\\%$, and $94.33\\%$, respectively. Experimental results demonstrate that the proposed SW-PS+LRU framework consistently surpasses competing models in both convergence speed and test accuracy.", "AI": {"tldr": "本文提出了一种使用滑动窗口路径签名（SW-PS）和轻量级线性递归单元（LRU）的旋转不变的手写字符识别方法，以提高在线手写字符识别中的准确性。", "motivation": "在实际应用中，由于笔画布局受旋转变形影响，导致手写字符识别精度下降。因此，提取旋转不变特征成为一个重要但尚未解决的问题。", "method": "本文采用了滑动窗口路径签名（SW-PS）来捕捉字符的局部结构特征，并引入了轻量级线性递归单元（LRU）作为分类器。LRU结合了递归神经网络(RNN)的快速增量处理能力和状态空间模型(SSM)的高效并行训练能力，可靠地建模动态笔画特性。", "result": "实验结果表明，在CASIA-OLHWDB1.1数据集的不同子集上（数字、英文大写字母和中文部首），该方法经过集成学习后的准确率分别为99.62%、96.67%和94.33%，在收敛速度和测试精度方面均优于竞争模型。", "conclusion": "本文提出的SW-PS+LRU框架能有效提高旋转不变的手写字符识别的准确性，同时具有更快的训练速度和更高的测试准确率。"}}
{"id": "2602.01532", "pdf": "https://arxiv.org/pdf/2602.01532", "abs": "https://arxiv.org/abs/2602.01532", "authors": ["Yuxuan Fu", "Xiaoyu Tan", "Teqi Hao", "Chen Zhan", "Xihe Qiu"], "title": "PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Proactive agents must decide not only what to say but also whether and when to intervene. Many current systems rely on brittle heuristics or indiscriminate long reasoning, which offers little control over the benefit-burden tradeoff. We formulate the problem as cost-sensitive selective intervention and present PRISM, a novel framework that couples a decision-theoretic gate with a dual-process reasoning architecture. At inference time, the agent intervenes only when a calibrated probability of user acceptance exceeds a threshold derived from asymmetric costs of missed help and false alarms. Inspired by festina lente (Latin: \"make haste slowly\"), we gate by an acceptance-calibrated, cost-derived threshold and invoke a resource-intensive Slow mode with counterfactual checks only near the decision boundary, concentrating computation on ambiguous and high-stakes cases. Training uses gate-aligned, schema-locked distillation: a teacher running the full PRISM pipeline provides dense, executable supervision on unlabeled interaction traces, while the student learns a response policy that is explicitly decoupled from the intervention gate to enable tunable and auditable control. On ProactiveBench, PRISM reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines. These results show that principled decision-theoretic gating, paired with selective slow reasoning and aligned distillation, yields proactive agents that are precise, computationally efficient, and controllable. To facilitate reproducibility, we release our code, models, and resources at https://prism-festinalente.github.io/; all experiments use the open-source ProactiveBench benchmark.", "AI": {"tldr": "本文提出了PRISM框架，用于解决主动代理在不确定性环境下的选择性干预问题。", "motivation": "当前系统对于何时何地进行干预缺乏控制，导致了利益和负担之间的权衡不足。因此，研究提出了一种新的决策理论门限与双过程推理架构相结合的方法。", "method": "PRISM框架通过一个基于用户接受概率的校准阈值来决定是否介入，并在接近决策边界的不确定案例中采用资源密集型的慢速模式进行反事实检查，同时使用教师模型提供的密集执行监督来进行训练。", "result": "实验表明，该方法减少了22.78%的误报率，提高了20.14%的F1分数。这证明了基于决策理论的选择性干预和选择性慢速推理的有效性和效率。", "conclusion": "PRISM框架通过结合决策理论门限、选择性慢速推理以及对齐蒸馏，提供了一种精确、计算高效且可控制的方法来实现主动代理的精准化。"}}
{"id": "2602.01530", "pdf": "https://arxiv.org/pdf/2602.01530", "abs": "https://arxiv.org/abs/2602.01530", "authors": ["Parsa Esmaeilkhani", "Longin Jan Latecki"], "title": "Preserving Localized Patch Semantics in VLMs", "categories": ["cs.CV"], "comment": null, "summary": "Logit Lens has been proposed for visualizing tokens that contribute most to LLM answers. Recently, Logit Lens was also shown to be applicable in autoregressive Vision-Language Models (VLMs), where it illustrates the conceptual content of image tokens in the form of heatmaps, e.g., which image tokens are likely to depict the concept of cat in a given image. However, the visual content of image tokens often gets diffused to language tokens, and consequently, the locality of visual information gets mostly destroyed, which renders Logit Lens visualization unusable for explainability. To address this issue, we introduce a complementary loss to next-token prediction (NTP) to prevent the visual tokens from losing the visual representation inherited from corresponding image patches. The proposed Logit Lens Loss (LLL) is designed to make visual token embeddings more semantically aligned with the textual concepts that describe their image regions (e.g., patches containing a cat with the word \"cat\"), without requiring any architectural modification or large-scale training. This way, LLL constrains the mixing of image and text tokens in the self-attention layers in order to prevent image tokens from losing their localized visual information. As our experiments show, LLL not only makes Logit Lens practically relevant by producing meaningful object confidence maps in images, but also improves performance on vision-centric tasks like segmentation without attaching any special heads.", "AI": {"tldr": "本文提出了一种新的损失函数Logit Lens Loss（LLL），以保留图像中视觉标记的局部语义，提高Logit Lens在解释性任务中的实用性，并改进了视觉为中心的任务的表现。", "motivation": "由于视觉令牌的内容经常扩散到语言令牌中，这导致视觉信息的局部性丧失，使得Logit Lens无法用于解释性。为了解决这个问题，作者引入了一种新的损失函数来保持视觉标记的语义与描述其图像区域的语言概念的一致性。", "method": "本文提出了一种名为Logit Lens Loss（LLL）的方法，通过在自注意力层中约束图像令牌和文本令牌之间的混合来防止图像令牌失去局部视觉信息。该方法不需要对模型架构进行修改或大规模训练即可实现这一目标。", "result": "实验结果表明，引入LLL能够生成有意义的对象置信度图，并且可以提高分割等视觉为中心任务的表现。", "conclusion": "通过改进Logit Lens Loss（LLL），作者成功地解决了图像令牌失去局部语义的问题，从而提高了模型的解释性和性能。"}}
{"id": "2602.01527", "pdf": "https://arxiv.org/pdf/2602.01527", "abs": "https://arxiv.org/abs/2602.01527", "authors": ["Brian Keith-Norambuena"], "title": "Toward a Machine Bertin: Why Visualization Needs Design Principles for Machine Cognition", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": "Preprint submitted to IEEE TVCG on February 2026", "summary": "Visualization's design knowledge-effectiveness rankings, encoding guidelines, color models, preattentive processing rules -- derives from six decades of psychophysical studies of human vision. Yet vision-language models (VLMs) increasingly consume chart images in automated analysis pipelines, and a growing body of benchmark evidence indicates that this human-centered knowledge base does not straightforwardly transfer to machine audiences. Machines exhibit different encoding performance patterns, process images through patch-based tokenization rather than holistic perception, and fail on design patterns that pose no difficulty for humans-while occasionally succeeding where humans struggle. Current approaches address this gap primarily by bypassing vision entirely, converting charts to data tables or structured text. We argue that this response forecloses a more fundamental question: what visual representations would actually serve machine cognition well? This paper makes the case that the visualization field needs to investigate machine-oriented visual design as a distinct research problem. We synthesize evidence from VLM benchmarks, visual reasoning research, and visualization literacy studies to show that the human-machine perceptual divergence is qualitative, not merely quantitative, and critically examine the prevailing bypassing approach. We propose a conceptual distinction between human-oriented and machine-oriented visualization-not as an engineering architecture but as a recognition that different audiences may require fundamentally different design foundations-and outline a research agenda for developing the empirical foundations the field currently lacks: the beginnings of a \"machine Bertin\" to complement the human-centered knowledge the field already possesses.", "AI": {"tldr": "本文探讨了机器视觉模型在处理图表时与人类认知的差异，并提出需要研究适用于机器的认知设计基础。", "motivation": "现有可视化知识主要基于对人类视觉的研究，但在自动化分析中由机器处理图表图像时表现不佳。作者认为，这表明有必要探究适合机器认知的设计原则。", "method": "通过整合来自视觉语言模型基准、视觉推理和可视化工学文献的证据来展示人机感知差异的本质，并批评了现有回避方法的有效性。", "result": "提出了一个概念区别于面向人类和面向机器的可视化设计，同时概述了一个研究议程以开发所需的经验基础。", "conclusion": "建议将对面向机器认知的设计原则的研究作为一个独立的问题进行探讨。"}}
{"id": "2602.01525", "pdf": "https://arxiv.org/pdf/2602.01525", "abs": "https://arxiv.org/abs/2602.01525", "authors": ["Jingyue Zhang", "J. D. Zamfirescu-Pereira", "Elena L. Glassman", "Damien Masson", "Ian Arawjo"], "title": "How Notations Evolve: A Historical Analysis with Implications for Supporting User-Defined Abstractions", "categories": ["cs.HC", "cs.CY"], "comment": "23 pages, 4 figures", "summary": "Traditional human-computer interaction takes place through formally-specified systems like structured UIs and programming languages. Recent AI systems promise a new set of informal interactions with computers through natural language and other notational forms. These informal interactions can then lead to formal representations, but depend upon pre-existing formalisms known to both humans and AI. What about novel formalisms and notations? How are new abstractions created, evolved, and incrementally formalized over time -- and how might new systems, in turn, be explicitly designed to support these processes? We conduct a comparative historical analysis of notation development to identify some relevant characteristics. These include three social stages of notation development: invention & incubation, dispersion & divergence, and institutionalization & sanctification, as well as three functional stages: descriptive, generative, and evaluative. Within and across these stages, we detail several patterns, such as the role of linking and grounding metaphors, dimensions of meaningful variation, and analogical alignment. Finally, we offer some implications for design.", "AI": {"tldr": "本文通过历史分析研究了新抽象符号的发展过程，并提出了支持这些过程的设计建议。", "motivation": "探讨新型形式主义和符号如何创造、演化及逐步规范化，以及新的系统如何被设计来支持这些过程。", "method": "进行比较历史分析，识别出三种社会阶段：发明与孵化、传播与分歧、制度化与圣化；以及描述性、生成性和评价性的三个功能阶段。详细描述了链接和根基隐喻的作用及有意义的变化维度等模式。", "result": "确定了新符号发展的相关特性，并提供了设计建议。", "conclusion": "通过历史分析，识别出新颖形式主义和符号的发展过程的特征，为支持这一过程的新系统设计提供指导。"}}
{"id": "2602.01523", "pdf": "https://arxiv.org/pdf/2602.01523", "abs": "https://arxiv.org/abs/2602.01523", "authors": ["Akifumi Wachi", "Hirota Kinoshita", "Shokichi Takakura", "Rei Higuchi", "Taiji Suzuki"], "title": "A Relative-Budget Theory for Reinforcement Learning with Verifiable Rewards in Large Language Model Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "28 pages", "summary": "Reinforcement learning (RL) is a dominant paradigm for improving the reasoning abilities of large language models, yet its effectiveness varies across tasks and compute budgets. We propose a \\emph{relative-budget} theory explaining this variation through a single quantity called relative budget $ξ:= H/\\mathbb{E}[T]$, where $H$ is the generation horizon (token budget) and $T$ denotes the number of tokens until the first correct solution under a base policy. We show that $ξ$ determines sample efficiency by controlling reward variance and the likelihood of informative trajectories. Our analysis reveals three regimes: in the \\emph{deficient} regime ($ξ\\to 0$), informative trajectories are rare and the sample complexity explodes; in the \\emph{balanced} regime ($ξ=Θ(1)$), informative trajectories occur with non-negligible probability and RL is maximally sample-efficient; and in the \\emph{ample} regime ($ξ\\to \\infty$), learning remains stable but marginal gains per iteration diminish. We further provide finite-sample guarantees for online RL that characterize learning progress across these regimes. Specifically, in a case study under idealized distributional assumptions, we show that the relative budget grows linearly over iterations. Our empirical results confirm these predictions in realistic settings, identifying a budget $ξ\\in [1.5, 2.0]$ that maximizes learning efficiency and coincides with peak reasoning performance.", "AI": {"tldr": "提出相对预算理论解释了强化学习在不同任务和计算预算下有效性的变化，通过单一指标ξ来控制样本效率。", "motivation": "为了理解为什么强化学习在提升大型语言模型的推理能力方面效果不一，并找出最佳的学习策略以提高效率。", "method": "通过定义相对预算ξ并分析其如何影响奖励方差和信息轨迹的概率，揭示了三个不同阶段的有效性变化规律。", "result": "实验结果验证了理论预测，在实际场景中发现预算ξ在1.5到2.0之间时，学习效率达到最高且推理表现最佳。", "conclusion": "相对预算理论为优化大型语言模型的强化学习提供了一个新的视角和指导框架。"}}
{"id": "2602.01522", "pdf": "https://arxiv.org/pdf/2602.01522", "abs": "https://arxiv.org/abs/2602.01522", "authors": ["Haoran Zhao", "Soyeon Caren Han", "Eduard Hovy"], "title": "When Is Rank-1 Enough? Geometry-Guided Initialization for Parameter-Efficient Fine-Tuning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) is a standard way to adapt multimodal large language models, yet extremely low-rank settings -- especially rank-1 LoRA -- are often unstable. We show that this instability is not solely due to limited capacity: in the rank-1 regime, optimization is highly sensitive to the update direction. Concretely, pretrained vision and text features form mismatched anisotropic regions, yielding a dominant \"gap\" direction that acts like a translation component and disproportionately steers early gradients under rank-1 constraints. Analyzing pretrained representations, we identify a modality-gap axis that dominates early gradient flow, while a random rank-1 initialization is unlikely to align with it, leading to weak gradients and training collapse. We propose Gap-Init, a geometry-aware initialization that aligns the rank-1 LoRA direction with an estimated modality-gap vector from a small calibration set, while keeping the initial LoRA update zero. Across multiple vision-language tasks and backbones, Gap-Init consistently stabilizes rank-1 training and can match or outperform strong rank-8 baselines. Our results suggest that at the extreme low-rank limit, initial alignment can matter as much as rank itself.", "AI": {"tldr": "研究如何在极低秩限制下稳定rank-1 LoRA的训练，提出Gap-Init初始化方法。", "motivation": "探讨了极低秩设置（特别是rank-1）不稳定的原因，并提出了相应的解决方案以提高其稳定性。", "method": "通过分析预训练表示中的模态差异，设计了一种几何感知的初始化策略（Gap-Init），该策略将初始更新方向与估计出的模态差距向量对齐。", "result": "实验结果显示Gap-Init方法在多个视觉语言任务和模型上都能稳定rank-1训练，并且可以匹敌甚至超越较强的rank-8基线。", "conclusion": "研究发现，初始对齐的重要性可能与秩本身一样重要，在极低秩限制下，优化的方向敏感性决定了最终的稳定性。"}}
{"id": "2602.01519", "pdf": "https://arxiv.org/pdf/2602.01519", "abs": "https://arxiv.org/abs/2602.01519", "authors": ["Shiju Zhao", "Junhao Hu", "Jiaqi Zheng", "Guihai Chen"], "title": "You Need an Encoder for Native Position-Independent Caching", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 10 figures. Welcome back, Encoder", "summary": "The Key-Value (KV) cache of Large Language Models (LLMs) is prefix-based, making it highly inefficient for processing contexts retrieved in arbitrary order. Position-Independent Caching (PIC) has been proposed to enable KV reuse without positional constraints; however, existing approaches often incur substantial accuracy degradation, limiting their practical adoption. To address this issue, we propose native PIC by reintroducing the encoder to prevalent decoder-only LLMs and explicitly training it to support PIC. We further develop COMB, a PIC-aware caching system that integrates seamlessly with existing inference frameworks. Experimental results show that COMB reduces Time-to-First-Token (TTFT) by 51-94% and increases throughput by 3$\\times$ with comparable accuracy. Furthermore, the quality improvement when using DeepSeek-V2-Lite-Chat demonstrates the applicability of COMB to other types of decoder-only LLMs. Our code is available at https://github.com/shijuzhao/Comb.", "AI": {"tldr": "提出了一种新的位置无关缓存方法COMB，通过在解码器模型中重新引入编码器并训练其支持位置无关缓存来提高LLM的效率。", "motivation": "现有的KV缓存方法因依赖上下文顺序导致性能低下，而基于位置的位置无关缓存（PIC）技术虽然可以缓解这一问题但会降低准确性。因此，需要一种既能保持准确度又能提升性能的新方案。", "method": "通过在解码器模型中添加编码器组件，并对其进行专门训练以支持位置无关的KV缓存；开发了一种称为COMB的位置无关缓存系统，该系统能够与现有的推理框架无缝集成。", "result": "实验表明，使用COMB可以将Time-to-First-Token (TTFT) 减少51%-94%，并提高3倍吞吐量，同时保持可比的准确性。在DeepSeek-V2-Lite-Chat模型上也展示了其对其他类型解码器LLM的有效性。", "conclusion": "通过重新引入编码器来支持位置无关缓存，并开发相应的COMB系统可以有效解决现有KV缓存方法的问题，显著提升效率和性能，具有广泛应用前景。"}}
{"id": "2602.01518", "pdf": "https://arxiv.org/pdf/2602.01518", "abs": "https://arxiv.org/abs/2602.01518", "authors": ["Jongseok Park", "Sunga Kim", "Alvin Cheung", "Ion Stoica"], "title": "Qrita: High-performance Top-k and Top-p Algorithm for GPUs using Pivot-based Truncation and Selection", "categories": ["cs.AI"], "comment": null, "summary": "Top-k and Top-p are the dominant truncation operators in the sampling of large language models. Despite their widespread use, implementing them efficiently over large vocabularies remains a significant challenge. Existing approaches often rely on sorting, which incur significant computation and memory overhead on GPUs, or stochastic approaches, which alter the algorithm output. In this work, we propose Qrita, an efficient Top-k and Top-p algorithm based on a pivot-based selection strategy. Based on RTop-k, which uses a pivot-based search for node selection in graph neural networks, Qrita extends the concept of pivot-based search to both Top-k and Top-p with two key techniques: 1. Gaussian-based sigma-truncation, which greatly reduces the search space of the target elements, and 2. Quaternary pivot search with duplication handling, which halves the pivot search iteration and guarantees deterministic output. We provide the full implementation of Qrita using Triton, a popular GPU programming language. Our evaluation of Qrita against the Top-k and Top-p kernels of high performance LLM execution engines such as vLLM, SGLang, and Flashinfer show that Qrita achieves up to 2 times throughput and half memory use while providing the same output to the the sorting-based algorithms.", "AI": {"tldr": "本文提出了一种基于枢轴选择策略的高效Top-k和Top-p算法Qrita，适用于大规模语言模型采样。", "motivation": "现有的Top-k和Top-p实现方法存在计算量大、内存开销高或改变输出的问题。为了解决这些问题，本文提出了新的解决方案。", "method": "基于RTop-k的枢轴搜索节点选择策略，Qrita引入了两个关键技术：1. 基于高斯分布的sigma截断，2. 处理重复元素的四元枢轴搜索方法。", "result": "实验结果表明，与vLLM、SGLang和Flashinfer等高性能LLM执行引擎相比，Qrita在提供相同输出的同时，吞吐量提高了两倍且内存使用减半。", "conclusion": "通过引入基于高斯分布的sigma截断和四元枢轴搜索方法，Qrita解决了现有Top-k和Top-p实现中存在的问题，并显著提升了性能。"}}
{"id": "2602.01517", "pdf": "https://arxiv.org/pdf/2602.01517", "abs": "https://arxiv.org/abs/2602.01517", "authors": ["ATM Mizanur Rahman", "Syed Ishtiaque Ahmed", "Sharifa Sultana"], "title": "Data Repair", "categories": ["cs.HC"], "comment": null, "summary": "This paper investigates data repair practices through a six-month-long ethnographic study in Bangladesh. Our interviews and field observations with data repairers and related stakeholders found that, alongside the scarcity of high-precision machinery and access to advanced software, data repair work is constrained by cross-language learning resources and the protective nature of documenting, curating, and sharing the experiences and knowledge among local peers. Repairers turning to external resources such as foreign forums and LLMs also revealed their frustrating experiences and the postcolonial ethical tensions they encountered. We noted that both anticipated technical labor and the emotionality of data were taken into account for pricing the data repair job, which contributed to their market sustainability strategies. Engaging with repair, infrastructure, and data poverty discourse, we argue that data repair practices represent a crucial challenge and opportunity for HCI in advancing global efforts toward data equity.", "AI": {"tldr": "该论文通过六个月的民族志研究，探讨了孟加拉国的数据修复实践。", "motivation": "作者希望通过深入了解数据修复者及其相关利益方的经验和挑战，来揭示数据贫困中的技术和情感方面的问题。", "method": "作者进行了为期六个月的民族志研究，包括对数据修复者的采访和现场观察。", "result": "研究表明数据修复工作受限于精密设备不足、软件访问难及跨语言学习资源匮乏等问题。同时，情绪因素也影响了定价策略。", "conclusion": "论文强调数据修复实践对于推进全球数据公平至关重要，并为HCI领域提出了新的挑战与机遇。"}}
{"id": "2602.01516", "pdf": "https://arxiv.org/pdf/2602.01516", "abs": "https://arxiv.org/abs/2602.01516", "authors": ["Enzo Nicolas Spotorno", "Matheus Wagner", "Antonio Augusto Medeiros Frohlich"], "title": "White-Box Neural Ensemble for Vehicular Plasticity: Quantifying the Efficiency Cost of Symbolic Auditability in Adaptive NMPC", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": "5 pages, 1 table, 1 figure, submitted to IEEE VTC 2026 Recent Results Track", "summary": "We present a white-box adaptive NMPC architecture that resolves vehicular plasticity (adaptation to varying operating regimes without retraining) by arbitrating among frozen, regime-specific neural specialists using a Modular Sovereignty paradigm. The ensemble dynamics are maintained as a fully traversable symbolic graph in CasADi, enabling maximal runtime auditability. Synchronous simulation validates rapid adaptation (~7.3 ms) and near-ideal tracking fidelity under compound regime shifts (friction, mass, drag) where non-adaptive baselines fail. Empirical benchmarking quantifies the transparency cost: symbolic graph maintenance increases solver latency by 72-102X versus compiled parametric physics models, establishing the efficiency price of strict white-box implementation.", "AI": {"tldr": "本文提出了一种适应性非线性模型预测控制架构，利用白盒神经网络集合解决车辆在不同操作模式下的自适应问题。", "motivation": "为了实现车辆在各种运行条件下的自动适应而无需重新训练，并提高系统的可审计性，本文设计了一个基于模块主权的仲裁机制，通过冻结特定模式的神经专家来处理动态变化。", "method": "该架构利用CasADi库将集合动力学保持为完全可遍历的符号图，实现最大运行时透明度。同步仿真验证了这种结构在复杂条件下的快速适应性和高精度跟踪能力，并通过实证基准测试量化了白盒实施带来的效率损失。", "result": "该架构展示了大约7.3毫秒内的快速适应性以及在复合条件变化下近乎理想的轨迹追踪精确度，而传统的非自适应基线系统则失败。同时，符号图的维护导致求解器延迟增加了72-102倍。", "conclusion": "本文确立了严格白盒实现所带来的效率代价，并提出了一种通过冻结特定模式神经专家来处理动态变化问题的新方法"}}
{"id": "2602.01515", "pdf": "https://arxiv.org/pdf/2602.01515", "abs": "https://arxiv.org/abs/2602.01515", "authors": ["Humphrey Munn", "Brendan Tidd", "Peter Bohm", "Marcus Gallagher", "David Howard"], "title": "RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Deploying learned control policies on humanoid robots is challenging: policies that appear robust in simulation can execute confidently in out-of-distribution (OOD) states after Sim-to-Real transfer, leading to silent failures that risk hardware damage. Although anomaly detection can mitigate these failures, prior methods are often incompatible with high-rate control, poorly calibrated at the extremely low false-positive rates required for practical deployment, or operate as black boxes that provide a binary stop signal without explaining why the robot drifted from nominal behavior. We present RAPT, a lightweight, self-supervised deployment-time monitor for 50Hz humanoid control. RAPT learns a probabilistic spatio-temporal manifold of nominal execution from simulation and evaluates execution-time predictive deviation as a calibrated, per-dimension signal. This yields (i) reliable online OOD detection under strict false-positive constraints and (ii) a continuous, interpretable measure of Sim-to-Real mismatch that can be tracked over time to quantify how far deployment has drifted from training. Beyond detection, we introduce an automated post-hoc root-cause analysis pipeline that combines gradient-based temporal saliency derived from RAPT's reconstruction objective with LLM-based reasoning conditioned on saliency and joint kinematics to produce semantic failure diagnoses in a zero-shot setting. We evaluate RAPT on a Unitree G1 humanoid across four complex tasks in simulation and on physical hardware. In large-scale simulation, RAPT improves True Positive Rate (TPR) by 37% over the strongest baseline at a fixed episode-level false positive rate of 0.5%. On real-world deployments, RAPT achieves a 12.5% TPR improvement and provides actionable interpretability, reaching 75% root-cause classification accuracy across 16 real-world failures using only proprioceptive data.", "AI": {"tldr": "RAPT是一种轻量级的实时监控系统，用于检测人类机器人在从仿真到现实环境中执行时的状态漂移，并提供可解释的故障诊断。", "motivation": "学习控制策略部署在人形机器人的挑战在于，它们可能在仿真中表现良好但在实际应用中会出现无声失败，这可能导致硬件损坏。现有的异常检测方法往往不适用于高频实时控制或无法提供详细的故障原因说明。", "method": "RAPT通过从仿真环境中学习正常操作的概率时空流形，并使用重建目标中的梯度时序注意力与LLM结合来进行后验根因分析，从而实现实时的、可解释的状态漂移检测和诊断。", "result": "在大规模模拟中，与最强基线相比，RAPT将真实阳性率提高了37%，而在实际部署中，它提高了12.5%的真实阳性率，并实现了75%的准确故障分类。", "conclusion": "RAPT能够可靠地检测到人形机器人的状态漂移并提供详细的故障原因解释，从而提高了安全性并减少了硬件损坏的风险。"}}
{"id": "2602.01513", "pdf": "https://arxiv.org/pdf/2602.01513", "abs": "https://arxiv.org/abs/2602.01513", "authors": ["Xiaoxi Kong", "Jieyu Yuan", "Pengdi Chen", "Yuanlin Zhang", "Chongyi Li", "Bin Li"], "title": "MarkCleaner: High-Fidelity Watermark Removal via Imperceptible Micro-Geometric Perturbation", "categories": ["eess.IV", "cs.AI", "cs.CR", "cs.CV"], "comment": null, "summary": "Semantic watermarks exhibit strong robustness against conventional image-space attacks. In this work, we show that such robustness does not survive under micro-geometric perturbations: spatial displacements can remove watermarks by breaking the phase alignment. Motivated by this observation, we introduce MarkCleaner, a watermark removal framework that avoids semantic drift caused by regeneration-based watermark removal. Specifically, MarkCleaner is trained with micro-geometry-perturbed supervision, which encourages the model to separate semantic content from strict spatial alignment and enables robust reconstruction under subtle geometric displacements. The framework adopts a mask-guided encoder that learns explicit spatial representations and a 2D Gaussian Splatting-based decoder that explicitly parameterizes geometric perturbations while preserving semantic content. Extensive experiments demonstrate that MarkCleaner achieves superior performance in both watermark removal effectiveness and visual fidelity, while enabling efficient real-time inference. Our code will be made available upon acceptance.", "AI": {"tldr": "MarkCleaner是一种通过微几何扰动去除水印的框架，旨在提高图像的视觉保真度。", "motivation": "传统的空间攻击方法难以清除具有强鲁棒性的语义水印，但是通过引入微几何扰动可以打破相位对齐从而去除水印。因此，作者提出MarkCleaner以避免基于再生的方法引起的语义漂移问题。", "method": "MarkCleaner使用带微几何扰动的监督训练，采用遮罩引导编码器学习显式的空间表示，并用二维高斯散射解码器对几何变化进行参数化处理。这种方法可以在保留视觉保真度的同时去除水印。", "result": "实验结果表明，与现有技术相比，MarkCleaner在水印清除效果和图像视觉质量上都表现优异，同时支持高效的实时推理。", "conclusion": "通过微几何扰动的方法能够高效且准确地移除图像中的语义水印，并保证图像内容的保真度。"}}
{"id": "2602.01510", "pdf": "https://arxiv.org/pdf/2602.01510", "abs": "https://arxiv.org/abs/2602.01510", "authors": ["Hengzhe Zhang", "Qi Chen", "Bing Xue", "Wolfgang Banzhaf", "Mengjie Zhang"], "title": "Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Genetic programming-based feature construction has achieved significant success in recent years as an automated machine learning technique to enhance learning performance. However, overfitting remains a challenge that limits its broader applicability. To improve generalization, we prove that vicinal risk, estimated through noise perturbation or mixup-based data augmentation, is bounded by the sum of empirical risk and a regularization term-either finite difference or the vicinal Jensen gap. Leveraging this decomposition, we propose an evolutionary feature construction framework that jointly optimizes empirical risk and the vicinal Jensen gap to control overfitting. Since datasets may vary in noise levels, we develop a noise estimation strategy to dynamically adjust regularization strength. Furthermore, to mitigate manifold intrusion-where data augmentation may generate unrealistic samples that fall outside the data manifold-we propose a manifold intrusion detection mechanism. Experimental results on 58 datasets demonstrate the effectiveness of Jensen gap minimization compared to other complexity measures. Comparisons with 15 machine learning algorithms further indicate that genetic programming with the proposed overfitting control strategy achieves superior performance.", "AI": {"tldr": "论文提出了一种基于vicinal Jensen gap最小化的遗传编程特征构造框架，用于提高符号回归中的泛化性能。", "motivation": "遗传编程特征构造在自动机器学习中取得了显著成功，但过拟合问题限制了其广泛应用。作者旨在通过vicinal风险估计和数据增强方法来解决这一挑战，从而改进模型的泛化能力。", "method": "论文提出了一种框架，该框架通过噪声扰动或mixup数据增强技术评估vicinal风险，并证明vicinal风险由经验风险和正则项（有限差分或vicinal Jensen gap）之和有界。作者还开发了动态调整正则化强度的策略以及检测数据扩增是否会导致manifold intrusion的机制。", "result": "实验结果表明，Jensen gap最小化的有效性优于其他复杂度量方法，并且与15种机器学习算法相比，遗传编程结合提出的过拟合控制策略具有更高的性能。", "conclusion": "论文通过提出基于vicinal Jensen gap最小化的方法有效提高了符号回归中的泛化能力，并展示了其在多个数据集上的优越性。"}}
{"id": "2602.01508", "pdf": "https://arxiv.org/pdf/2602.01508", "abs": "https://arxiv.org/abs/2602.01508", "authors": ["Yingrui Fan", "Junbo Zhao"], "title": "Harnessing Flexible Spatial and Temporal Data Center Workloads for Grid Regulation Services", "categories": ["eess.SY", "cs.AI", "cs.CE"], "comment": null, "summary": "Data centers (DCs) are increasingly recognized as flexible loads that can support grid frequency regulation. Yet, most existing methods treat workload scheduling and regulation capacity bidding separately, overlooking how queueing dynamics and spatial-temporal dispatch decisions affect the ability to sustain real-time regulation. As a result, the committed regulation may become infeasible or short-lived. To address this issue, we propose a unified day-ahead co-optimization framework that jointly decides workload distribution across geographically distributed DCs and regulation capacity commitments. We construct a space-time network model to capture workload migration costs, latency requirements, and heterogeneous resource limits. To ensure that the committed regulation remains deliverable, we introduce chance constraints on instantaneous power flexibility based on interactive load forecasts, and apply Value-at-Risk queue-state constraints to maintain sustainable response under cumulative regulation signals. Case studies on a modified IEEE 68-bus system using real data center traces show that the proposed framework lowers system operating costs, enables more viable regulation capacity, and achieves better revenue-risk trade-offs compared to strategies that optimize scheduling and regulation independently.", "AI": {"tldr": "数据中心通过联合优化工作负载分配和频率调节承诺，以减少系统运营成本并提高可调性。", "motivation": "现有的方法将工作量调度与调节容量投标分开处理，这可能导致已承诺的调节不可行或短暂。因此，需要一种能够综合考虑时间空间动态的工作流程来解决此问题。", "method": "提出了一种统一的日前提优框架，通过空间-时间网络模型捕捉迁移成本、延迟要求和异构资源限制，同时引入瞬时功率灵活性的机会约束以及维持可持续响应的VaR队列状态约束。", "result": "案例研究显示该方法降低了系统运营成本，并实现了更好的收入风险平衡。", "conclusion": "联合优化框架能够更有效地利用数据中心的空间和时间动态性来支持电网频率调节，相比独立策略具有明显优势。"}}
{"id": "2602.01503", "pdf": "https://arxiv.org/pdf/2602.01503", "abs": "https://arxiv.org/abs/2602.01503", "authors": ["Afifah Kashif", "Abdul Muhsin Hameed", "Asim Iqbal"], "title": "Governance at the Edge of Architecture: Regulating NeuroAI and Neuromorphic Systems", "categories": ["cs.ET", "cs.AI", "cs.AR"], "comment": "9 pages, 1 table, 1 figure", "summary": "Current AI governance frameworks, including regulatory benchmarks for accuracy, latency, and energy efficiency, are built for static, centrally trained artificial neural networks on von Neumann hardware. NeuroAI systems, embodied in neuromorphic hardware and implemented via spiking neural networks, break these assumptions. This paper examines the limitations of current AI governance frameworks for NeuroAI, arguing that assurance and audit methods must co-evolve with these architectures, aligning traditional regulatory metrics with the physics, learning dynamics, and embodied efficiency of brain-inspired computation to enable technically grounded assurance.", "AI": {"tldr": "本文探讨了当前AI治理框架对神经形态计算的局限性，并提出需要为基于脉冲神经网络的NeuroAI系统发展新的监管方法。", "motivation": "现有AI治理体系针对的是静态、中心化训练的人工神经网络，而NeuroAI则运行在神经形态硬件上并使用脉冲神经网络，这使得现有的治理框架不再适用。因此需要改进以适应这些新型架构的特性。", "method": "文章通过分析传统监管指标与基于脉冲神经网络计算的技术特征之间的差异来论证这一观点，并提出新的保证和审计方法应与NeuroAI系统共进化。", "result": "论文强调了当前治理框架对于神经形态系统的不适用性，建议未来的研究应该聚焦于制定更合适的监管策略以适应这种新型的计算架构。", "conclusion": "结论认为传统的AI治理体系需要革新来应对基于脉冲神经网络和神经形态硬件的新一代NeuroAI系统所带来的挑战。"}}
{"id": "2602.01501", "pdf": "https://arxiv.org/pdf/2602.01501", "abs": "https://arxiv.org/abs/2602.01501", "authors": ["Minwoo Jung", "Nived Chebrolu", "Lucas Carvalho de Lima", "Haedam Oh", "Maurice Fallon", "Ayoung Kim"], "title": "TreeLoc: 6-DoF LiDAR Global Localization in Forests via Inter-Tree Geometric Matching", "categories": ["cs.RO", "cs.CV"], "comment": "An 8-page paper with 7 tables and 8 figures, accepted to ICRA 2026", "summary": "Reliable localization is crucial for navigation in forests, where GPS is often degraded and LiDAR measurements are repetitive, occluded, and structurally complex. These conditions weaken the assumptions of traditional urban-centric localization methods, which assume that consistent features arise from unique structural patterns, necessitating forest-centric solutions to achieve robustness in these environments. To address these challenges, we propose TreeLoc, a LiDAR-based global localization framework for forests that handles place recognition and 6-DoF pose estimation. We represent scenes using tree stems and their Diameter at Breast Height (DBH), which are aligned to a common reference frame via their axes and summarized using the tree distribution histogram (TDH) for coarse matching, followed by fine matching with a 2D triangle descriptor. Finally, pose estimation is achieved through a two-step geometric verification. On diverse forest benchmarks, TreeLoc outperforms baselines, achieving precise localization. Ablation studies validate the contribution of each component. We also propose applications for long-term forest management using descriptors from a compact global tree database. TreeLoc is open-sourced for the robotics community at https://github.com/minwoo0611/TreeLoc.", "AI": {"tldr": "该论文提出了一种基于LiDAR的森林全局定位框架TreeLoc，用于处理地方识别和6-DoF姿态估计。", "motivation": "在森林环境中，GPS信号弱且LiDAR测量数据重复、遮挡多且结构复杂，传统城市环境下的定位方法难以有效工作。因此需要一种专门针对森林环境的解决方案以实现鲁棒性。", "method": "该论文通过使用树干及其直径来表示场景，并将其对齐到一个公共参考框架中，然后利用树木分布直方图（TDH）进行粗匹配，最后采用2D三角形描述符进行细匹配。姿态估计则通过两步几何验证实现。", "result": "在多样化的森林基准测试上，TreeLoc的表现优于基线方法，并且精确度高。", "conclusion": "该论文提出了一个针对森林环境的全局定位框架TreeLoc，通过实验表明其有效性并提出了一些长期森林管理的应用。"}}
{"id": "2602.01499", "pdf": "https://arxiv.org/pdf/2602.01499", "abs": "https://arxiv.org/abs/2602.01499", "authors": ["Caleb McFarland"], "title": "Totally $Δ$-Modular Tree Decompositions of Graphic Matrices for Integer Programming", "categories": ["math.CO", "cs.DM", "cs.DS", "math.OC"], "comment": "20 pages", "summary": "We introduce the tree-decomposition-based parameter totally $Δ$-modular treewidth (TDM-treewidth) for matrices with two nonzero entries per row. We show how to solve integer programs whose matrices have bounded TDM-treewidth when variables are bounded. This extends previous graph-based decomposition parameters for matrices with at most two nonzero entries per row to include matrices with entries outside of $\\{-1,0,1\\}$. We also give an analogue of the Grid Theorem of Robertson and Seymour for matrices of bounded TDM-treewidth in the language of rooted signed graphs.", "AI": {"tldr": "研究具有两个非零元素的矩阵的整数规划问题，引入树分解参数TDM-treewidth。", "motivation": "扩展之前仅限于{−1,0,1}条目的图基分解参数以包含矩阵中其他条目。", "method": "利用树分解方法解决具有界变量的矩阵的整数规划问题。", "result": "提出了解决具有两个非零元素的行的矩阵中的整数程序的方法，当变量受限时有效。", "conclusion": "展示了如何使用TDM-treewidth来处理更广泛的矩阵类型，并提出了矩阵语言中网格定理的类比。"}}
{"id": "2602.01494", "pdf": "https://arxiv.org/pdf/2602.01494", "abs": "https://arxiv.org/abs/2602.01494", "authors": ["Yuqi Hang"], "title": "Draw2Learn: A Human-AI Collaborative Tool for Drawing-Based Science Learning", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Drawing supports learning by externalizing mental models, but providing timely feedback at scale remains challenging. We present Draw2Learn, a system that explores how AI can act as a supportive teammate during drawing-based learning. The design translates learning principles into concrete interaction patterns: AI generates structured drawing quests, provides optional visual scaffolds, monitors progress, and delivers multidimensional feedback. We collected formative user feedback during system development and open-ended comments. Feedback showed positive ratings for usability, usefulness, and user experience, with themes highlighting AI scaffolding value and learner autonomy. This work contributes a design framework for teammate-oriented AI in generative learning and identifies key considerations for future research.", "AI": {"tldr": "介绍了Draw2Learn系统，该系统利用AI作为支持性队友，在基于绘画的学习过程中提供结构化任务、视觉支撑和多维度反馈。", "motivation": "解决在大规模学习环境中提供及时反馈的挑战，并探索AI如何帮助提升基于绘画的学习效果。", "method": "设计了一种将学习原则转化为具体交互模式的方法，包括生成结构化的绘画任务，提供可视支撑，监控进度并给出反馈。通过收集用户形式性反馈来改进系统。", "result": "用户对系统的可用性、有用性和用户体验给予了正面评价，并强调了AI支撑的价值和学习者的自主性。", "conclusion": "贡献了一个面向队友型AI的设计框架，在生成式学习中确定了未来研究的关键考虑因素"}}
{"id": "2602.01493", "pdf": "https://arxiv.org/pdf/2602.01493", "abs": "https://arxiv.org/abs/2602.01493", "authors": ["Zhuoyuan Wang", "Hanjiang Hu", "Xiyu Deng", "Saviz Mowlavi", "Yorie Nakahira"], "title": "OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Solving diverse partial differential equations (PDEs) is fundamental in science and engineering. Large language models (LLMs) have demonstrated strong capabilities in code generation, symbolic reasoning, and tool use, but reliably solving PDEs across heterogeneous settings remains challenging. Prior work on LLM-based code generation and transformer-based foundation models for PDE learning has shown promising advances. However, a persistent trade-off between execution success rate and numerical accuracy arises, particularly when generalization to unseen parameters and boundary conditions is required. In this work, we propose OpInf-LLM, an LLM parametric PDE solving framework based on operator inference. The proposed framework leverages a small amount of solution data to enable accurate prediction of diverse PDE instances, including unseen parameters and configurations, and provides seamless integration with LLMs for natural language specification of PDE solving tasks. Its low computational demands and unified tool interface further enable a high execution success rate across heterogeneous settings. By combining operator inference with LLM capabilities, OpInf-LLM opens new possibilities for generalizable reduced-order modeling in LLM-based PDE solving.", "AI": {"tldr": "本文提出了基于操作符推断的OpInf-LLM框架，利用大型语言模型和少量解数据准确预测不同参数和边界条件下的偏微分方程实例。", "motivation": "现有工作在使用大语言模型解决偏微分方程时存在成功率与数值精度之间的权衡问题，特别是在处理未见过的参数和边界条件时。为了克服这一挑战，本文提出了一个基于操作符推断的新框架。", "method": "OpInf-LLM框架利用少量解数据进行操作符推断，并结合大型语言模型的能力，实现了对不同偏微分方程实例的准确预测。", "result": "该方法在保持低计算需求的同时提高了执行成功率，在各种异构环境下具有良好的泛化能力。", "conclusion": "OpInf-LLM框架为基于大型语言模型的偏微分方程求解提供了新的可能性，特别是在减少阶数建模方面展示了其潜力。"}}
{"id": "2602.01483", "pdf": "https://arxiv.org/pdf/2602.01483", "abs": "https://arxiv.org/abs/2602.01483", "authors": ["Edwin V. Bonilla", "He Zhao", "Daniel M. Steinberg"], "title": "Causal Preference Elicitation", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "We propose causal preference elicitation, a Bayesian framework for expert-in-the-loop causal discovery that actively queries local edge relations to concentrate a posterior over directed acyclic graphs (DAGs). From any black-box observational posterior, we model noisy expert judgments with a three-way likelihood over edge existence and direction. Posterior inference uses a flexible particle approximation, and queries are selected by an efficient expected information gain criterion on the expert's categorical response. Experiments on synthetic graphs, protein signaling data, and a human gene perturbation benchmark show faster posterior concentration and improved recovery of directed effects under tight query budgets.", "AI": {"tldr": "本文提出了因果偏好推断，一种结合专家意见进行因果发现的贝叶斯框架。", "motivation": "为了在有限查询预算下更高效地集中后验分布并改进因果关系恢复，该研究提出了一种新的方法。", "method": "通过建模噪声专家判断与边的存在和方向之间的三元似然函数，并使用灵活的粒子近似进行后验推断。选择查询的标准是基于预期信息增益准则下的专家类别响应。", "result": "实验结果显示，在合成图、蛋白质信号传导数据以及人类基因扰动基准上，该方法能够更快地集中后验分布并改进因果效果恢复。", "conclusion": "提出的因果偏好推断框架在有限查询预算下表现出了更好的性能。"}}
{"id": "2602.01482", "pdf": "https://arxiv.org/pdf/2602.01482", "abs": "https://arxiv.org/abs/2602.01482", "authors": ["Minheng Chen", "Tong Chen", "Yan Zhuang", "Chao Cao", "Jing Zhang", "Tianming Liu", "Lu Zhang", "Dajiang Zhu"], "title": "Community-Level Modeling of Gyral Folding Patterns for Robust and Anatomically Informed Individualized Brain Mapping", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "comment": null, "summary": "Cortical folding exhibits substantial inter-individual variability while preserving stable anatomical landmarks that enable fine-scale characterization of cortical organization. Among these, the three-hinge gyrus (3HG) serves as a key folding primitive, showing consistent topology yet meaningful variations in morphology, connectivity, and function. Existing landmark-based methods typically model each 3HG independently, ignoring that 3HGs form higher-order folding communities that capture mesoscale structure. This simplification weakens anatomical representation and makes one-to-one matching sensitive to positional variability and noise. We propose a spectral graph representation learning framework that models community-level folding units rather than isolated landmarks. Each 3HG is encoded using a dual-profile representation combining surface topology and structural connectivity. Subject-specific spectral clustering identifies coherent folding communities, followed by topological refinement to preserve anatomical continuity. For cross-subject correspondence, we introduce Joint Morphological-Geometric Matching, jointly optimizing geometric and morphometric similarity. Across over 1000 Human Connectome Project subjects, the resulting communities show reduced morphometric variance, stronger modular organization, improved hemispheric consistency, and superior alignment compared with atlas-based and landmark-based or embedding-based baselines. These findings demonstrate that community-level modeling provides a robust and anatomically grounded framework for individualized cortical characterization and reliable cross-subject correspondence.", "AI": {"tldr": "提出了一种基于社区层次的折叠模式模型，用于增强个体化脑映射的准确性。", "motivation": "现有的地标方法通常独立地建模每个三铰点（3HG），忽视了它们构成更高阶折叠社团的事实，这削弱了解剖表示并且使一对一匹配对位置变化和噪声敏感。", "method": "引入了一种谱图表示学习框架来模型社区级折叠单元。每个3HG使用结合表面拓扑结构与结构连接性的双轮廓表示进行编码；通过主体特定的谱聚类识别解剖上一致的折叠社团，然后通过拓扑细化保持解剖连续性。", "result": "在超过1000个Human Connectome Project受试者中验证了结果。社区模型显示出更小的形态变异度、更强的整体组织能力、更好的半球一致性以及与基于图谱或地标的方法相比显著提高了跨主体对应准确性。", "conclusion": "社区层次建模提供了一个稳健且解剖学基础框架，用于个体化皮层表征及可靠的跨受试者映射。"}}
{"id": "2602.01481", "pdf": "https://arxiv.org/pdf/2602.01481", "abs": "https://arxiv.org/abs/2602.01481", "authors": ["Yunhao Luo", "Arthur Caetano", "Avinash Ajit Nargund", "Tobias Höllerer", "Misha Sra"], "title": "How Users Perceive Mixed-Initiative AI: Attitudes Toward Assistance in Problem Solving", "categories": ["cs.HC"], "comment": "ACM IUI '26 | 31st International Conference on Intelligent User Interfaces", "summary": "In mixed-initiative systems, the mode of AI assistance delivery can be as consequential as the assistance itself. We investigated two assistance delivery modes: on-demand help (users request via Button) and pre-scheduled help (assistance delivered at user-selected intervals, with user actions resetting the Timer). To evaluate these modes, we selected Rush Hour puzzles as the human-AI collaborative task because they capture elements of real-world problem solving such as analysis, resource management, and decision-making under constraints. To enhance ecological validity, we imposed monetary costs for both time and AI assistance, simulating scenarios where people must balance implicit or explicit trade-offs such as time pressure, financial limitations, or opportunity costs. Although task performance was comparable across modes, participants who used the pre-scheduled (Timer) mode reported more positive perceptions of the AI, even when their ending budget was low. This suggests that assistance delivery mode can shape user experience independent of task outcomes, indicating that human-AI systems may need to consider how AI assistance is delivered alongside improving task performance.", "AI": {"tldr": "研究了混合主动性AI系统中不同协助交付模式对用户态度的影响。", "motivation": "探究在混合主动性系统中，不同的AI协助交付模式如何影响用户的体验和感知。", "method": "通过设置Rush Hour谜题任务来比较按钮请求帮助（按需）与预设时间间隔提供帮助两种模式的效果。实验设计考虑了时间和AI协助的成本，以增加现实世界的适用性。", "result": "尽管不同模式下用户完成任务的表现相当，但使用预设定时器模式的参与者对AI持有更积极的态度。", "conclusion": "结果表明，AI协助交付方式可以独立于任务表现影响用户体验。因此，在设计人机协作系统时，需要同时考虑如何提供帮助以及优化任务性能。"}}
{"id": "2602.01480", "pdf": "https://arxiv.org/pdf/2602.01480", "abs": "https://arxiv.org/abs/2602.01480", "authors": ["Eric Regis", "Sinho Chewi"], "title": "Rod Flow: A Continuous-Time Model for Gradient Descent at the Edge of Stability", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "How can we understand gradient-based training over non-convex landscapes? The edge of stability phenomenon, introduced in Cohen et al. (2021), indicates that the answer is not so simple: namely, gradient descent (GD) with large step sizes often diverges away from the gradient flow. In this regime, the \"Central Flow\", recently proposed in Cohen et al. (2025), provides an accurate ODE approximation to the GD dynamics over many architectures. In this work, we propose Rod Flow, an alternative ODE approximation, which carries the following advantages: (1) it rests on a principled derivation stemming from a physical picture of GD iterates as an extended one-dimensional object -- a \"rod\"; (2) it better captures GD dynamics for simple toy examples and matches the accuracy of Central Flow for representative neural network architectures, and (3) is explicit and cheap to compute. Theoretically, we prove that Rod Flow correctly predicts the critical sharpness threshold and explains self-stabilization in quartic potentials. We validate our theory with a range of numerical experiments.", "AI": {"tldr": "论文提出了Rod Flow，一种基于物理图像的连续时间模型来近似梯度下降的动力学。", "motivation": "探讨如何理解非凸景观上的梯度训练，尤其是在大步长导致梯度下降远离梯度流的现象下。现有的中央流动模型虽然有效但缺乏直观解释，因此提出Rod Flow以更好地捕捉简单示例中的GD动力学并提供明确的计算方法。", "method": "通过将梯度下降迭代视为一维延伸对象（杆）来推导出一个物理上直观的连续时间模型——Rod Flow。该模型在简单的玩具例子中表现出更好的拟合效果，并且对于代表性神经网络架构与中央流动模型具有相同的精度，同时提供明确和低成本的计算方式。", "result": "证明了Rod Flow能正确预测关键尖锐度阈值并解释四次方势中的自我稳定现象。通过一系列数值实验验证理论的有效性。", "conclusion": "提出了一种新的连续时间模型——Rod Flow来更好地理解大步长下的梯度下降动力学，并且在理论上和实践中都得到了验证和支持。"}}
{"id": "2602.01475", "pdf": "https://arxiv.org/pdf/2602.01475", "abs": "https://arxiv.org/abs/2602.01475", "authors": ["Brij Malhotra", "Shivvrat Arya", "Tahrima Rahman", "Vibhav Giridhar Gogate"], "title": "Learning to Guide Local Search for MPE Inference in Probabilistic Graphical Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Most Probable Explanation (MPE) inference in Probabilistic Graphical Models (PGMs) is a fundamental yet computationally challenging problem arising in domains such as diagnosis, planning, and structured prediction. In many practical settings, the graphical model remains fixed while inference must be performed repeatedly for varying evidence patterns. Stochastic Local Search (SLS) algorithms scale to large models but rely on myopic best-improvement rule that prioritizes immediate likelihood gains and often stagnate in poor local optima. Heuristics such as Guided Local Search (GLS+) partially alleviate this limitation by modifying the search landscape, but their guidance cannot be reused effectively across multiple inference queries on the same model. We propose a neural amortization framework for improving local search in this repeated-query regime. Exploiting the fixed graph structure, we train an attention-based network to score local moves by predicting their ability to reduce Hamming distance to a near-optimal solution. Our approach integrates seamlessly with existing local search procedures, using this signal to balance short-term likelihood gains with long-term promise during neighbor selection. We provide theoretical intuition linking distance-reducing move selection to improved convergence behavior, and empirically demonstrate consistent improvements over SLS and GLS+ on challenging high-treewidth benchmarks in the amortized inference setting.", "AI": {"tldr": "本文提出了一种基于神经网络的框架，用于改善概率图模型中重复查询设置下的局部搜索。", "motivation": "在固定图形结构的情况下，进行多次推理时，现有的局部搜索算法容易陷入局部最优解。为了解决这个问题，并提高重用指导信息的效果，提出了新的方法。", "method": "利用固定的图结构训练一个注意力网络来评估本地移动的能力，以减少与近似最优解之间的汉明距离，并将这一信号集成到现有局部搜索过程中。", "result": "实验结果显示，在具有高树宽的基准测试上，该方法比现有的局部搜索和指导性局部搜索算法表现出一致的进步。", "conclusion": "本文提出的方法能够有效地改善局部搜索的行为并提高其在概率图模型中的性能。"}}
{"id": "2602.01474", "pdf": "https://arxiv.org/pdf/2602.01474", "abs": "https://arxiv.org/abs/2602.01474", "authors": ["Gillian K. Hadfield"], "title": "Legal Infrastructure for Transformative AI Governance", "categories": ["cs.AI", "econ.GN"], "comment": null, "summary": "Most of our AI governance efforts focus on substance: what rules do we want in place? What limits or checks do we want to impose on AI development and deployment? But a key role for law is not only to establish substantive rules but also to establish legal and regulatory infrastructure to generate and implement rules. The transformative nature of AI calls especially for attention to building legal and regulatory frameworks. In this PNAS Perspective piece I review three examples I have proposed: the creation of registration regimes for frontier models; the creation of registration and identification regimes for autonomous agents; and the design of regulatory markets to facilitate a role for private companies to innovate and deliver AI regulatory services.", "AI": {"tldr": "构建支持人工智能治理的法律基础设施", "motivation": "当前的人工智能治理工作主要集中在规则制定上，而忽视了建立能够生成和实施这些规则的法律和监管框架的重要性。鉴于人工智能技术的变革性影响，需要特别关注这一方面。", "method": "从三个方面提出了建议：创建前沿模型注册制度；为自主代理创建注册和识别系统；设计监管市场以促进私人公司参与创新并提供AI监管服务。", "result": "通过这些建议，可以推动建立一个能够有效管理人工智能技术的法律和监管基础设施框架。", "conclusion": "有效的法律和监管体系对于确保人工智能技术的安全发展至关重要。"}}
{"id": "2602.01469", "pdf": "https://arxiv.org/pdf/2602.01469", "abs": "https://arxiv.org/abs/2602.01469", "authors": ["Mude Hui", "Xin Huang", "Jaime Campos Salas", "Yue Sun", "Nathan Pemberton", "Xiang Song", "Ashish Khetan", "George Karypis"], "title": "P-EAGLE: Parallel-Drafting EAGLE with Scalable Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reasoning LLMs produce longer outputs, requiring speculative decoding drafters trained on extended sequences. Parallel drafting - predicting multiple tokens per forward pass - offers latency benefits over sequential generation, but training complexity scales quadratically with the product of sequence length and parallel positions, rendering long-context training impractical. We present P(arallel)-EAGLE, which transforms EAGLE from autoregressive to parallel multi-token prediction via a learnable shared hidden state. To scale training to long contexts, we develop a framework featuring attention mask pre-computation and sequence partitioning techniques, enabling gradient accumulation within individual sequences for parallel-prediction training. We implement P-EAGLE in vLLM and demonstrate speedups of 1.10-1.36x over autoregressive EAGLE-3 across GPT-OSS 120B, 20B, and Qwen3-Coder 30B.", "AI": {"tldr": "P-EAGLE是通过将EAGLE从自回归预测转换为并行多令牌预测，从而提高推理效率的模型。", "motivation": "随着大型语言模型输出的增长，需要更高效的生成方法。并行预测可以减少延迟，但其训练复杂性随序列长度和并行位置增加而呈二次增长，因此难以应用于长上下文环境中。", "method": "P-EAGLE通过学习共享隐藏状态将EAGLE从自回归转变为并行多令牌预测模型。为了支持长时间上下文的可扩展训练，它引入了注意力掩码预计算和序列分割技术，并实现了在个体序列中的梯度累积。", "result": "实验结果表明，在GPT-OSS、Qwen3-Coder等不同规模的模型上，P-EAGLE相较于自回归EAGLE-3显示出了1.10至1.36倍的速度提升。", "conclusion": "P-EAGLE通过并行化技术提高了大语言模型生成效率，并且在保持生成质量的同时显著减少了延迟。"}}
{"id": "2602.01465", "pdf": "https://arxiv.org/pdf/2602.01465", "abs": "https://arxiv.org/abs/2602.01465", "authors": ["Nikita Benkovich", "Vitalii Valkov"], "title": "Agyn: A Multi-Agent System for Team-Based Autonomous Software Engineering", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Large language models have demonstrated strong capabilities in individual software engineering tasks, yet most autonomous systems still treat issue resolution as a monolithic or pipeline-based process. In contrast, real-world software development is organized as a collaborative activity carried out by teams following shared methodologies, with clear role separation, communication, and review. In this work, we present a fully automated multi-agent system that explicitly models software engineering as an organizational process, replicating the structure of an engineering team. Built on top of agyn, an open-source platform for configuring agent teams, our system assigns specialized agents to roles such as coordination, research, implementation, and review, provides them with isolated sandboxes for experimentation, and enables structured communication. The system follows a defined development methodology for working on issues, including analysis, task specification, pull request creation, and iterative review, and operates without any human intervention. Importantly, the system was designed for real production use and was not tuned for SWE-bench. When evaluated post hoc on SWE-bench 500, it resolves 72.4% of tasks, outperforming single-agent baselines using comparable language models. Our results suggest that replicating team structure, methodology, and communication is a powerful paradigm for autonomous software engineering, and that future progress may depend as much on organizational design and agent infrastructure as on model improvements.", "AI": {"tldr": "介绍了一种多代理系统Agyn，该系统模拟真实软件开发中的团队结构和协作过程，以实现自动化的软件工程。", "motivation": "大多数自主系统将问题解决视为单一或流水线的过程，而实际的软件开发是通过团队合作完成的任务。本工作旨在创建一个完全自动化的多代理系统，模仿软件工程作为一个组织流程，并复制工程团队的结构和协作过程。", "method": "基于开源平台agyn构建了一个分配了协调、研究、实现和审查等角色的专业代理的系统，提供了实验隔离区并支持结构化沟通。该系统遵循定义的发展方法处理问题，包括分析、任务指定、创建拉取请求以及迭代审查，并完全不需要人工干预。", "result": "在SWE-bench 500上进行后评估时，Agyn解决了72.4%的任务，优于使用可比语言模型的单个代理基线。", "conclusion": "复制团队结构、方法和沟通是自主软件工程的强大范例，并且未来的进步可能依赖于组织设计和代理基础设施的程度与模型改进一样重要。"}}
{"id": "2602.01462", "pdf": "https://arxiv.org/pdf/2602.01462", "abs": "https://arxiv.org/abs/2602.01462", "authors": ["Miles Simmons", "Ishan Bansal", "Joe Cheriyan"], "title": "A $5$-Approximation Analysis for the Cover Small Cuts Problem", "categories": ["cs.DS"], "comment": ":68W25; 90C27", "summary": "In the Cover Small Cuts problem, we are given a capacitated (undirected) graph $G=(V,E,u)$ and a threshold value $λ$, as well as a set of links $L$ with end-nodes in $V$ and a non-negative cost for each link $\\ell\\in L$; the goal is to find a minimum-cost set of links such that each non-trivial cut of capacity less than $λ$ is covered by a link. Bansal, Cheriyan, Grout, and Ibrahimpur (arXiv:2209.11209, Algorithmica 2024) showed that the WGMV primal-dual algorithm, due to Williamson, Goemans, Mihail, and Vazirani (Combinatorica, 1995), achieves approximation ratio $16$ for the Cover Small Cuts problem; their analysis uses the notion of a pliable family of sets that satisfies a combinatorial property. Later, Bansal (arXiv:2308.15714v2, IPCO 2025) and then Nutov (arXiv:2504.03910, MFCS 2025) proved that the same algorithm achieves approximation ratio $6$. We show that the same algorithm achieves approximation ratio $5$, by using a stronger notion, namely, a pliable family of sets that satisfies symmetry and structural submodularity.", "AI": {"tldr": "本文通过引入对称性和结构次模性的更强概念，证明了WGMV算法在覆盖小割问题上的近似比为5。", "motivation": "先前的研究已经表明WGMV算法可以实现6的近似比。本文旨在改进这一结果，并提出一个新的理论框架以提升算法的效果。", "method": "作者采用了一种更强的概念，即满足对称性和结构次模性的可塑集族来优化分析方法。", "result": "证明了WGMV算法在覆盖小割问题上的近似比为5。", "conclusion": "通过引入新的理论工具，改进了原有算法的性能表现。"}}
{"id": "2602.01459", "pdf": "https://arxiv.org/pdf/2602.01459", "abs": "https://arxiv.org/abs/2602.01459", "authors": ["Joey Kuang", "Alexander Wong"], "title": "Understanding vision transformer robustness through the lens of out-of-distribution detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to JCVIS 2025", "summary": "Vision transformers have shown remarkable performance in vision tasks, but enabling them for accessible and real-time use is still challenging. Quantization reduces memory and inference costs at the risk of performance loss. Strides have been made to mitigate low precision issues mainly by understanding in-distribution (ID) task behaviour, but the attention mechanism may provide insight on quantization attributes by exploring out-of-distribution (OOD) situations. We investigate the behaviour of quantized small-variant popular vision transformers (DeiT, DeiT3, and ViT) on common OOD datasets. ID analyses show the initial instabilities of 4-bit models, particularly of those trained on the larger ImageNet-22k, as the strongest FP32 model, DeiT3, sharply drop 17% from quantization error to be one of the weakest 4-bit models. While ViT shows reasonable quantization robustness for ID calibration, OOD detection reveals more: ViT and DeiT3 pretrained on ImageNet-22k respectively experienced a 15.0% and 19.2% average quantization delta in AUPR-out between full precision to 4-bit while their ImageNet-1k-only counterparts experienced a 9.5% and 12.0% delta. Overall, our results suggest pretraining on large scale datasets may hinder low-bit quantization robustness in OOD detection and that data augmentation may be a more beneficial option.", "AI": {"tldr": "研究视觉变换器在量化过程中的鲁棒性，特别是在处理OOD数据时的表现。", "motivation": "探索视觉变换器在低精度下的行为模式，并通过OOD检测来理解其量化稳健性的特性。", "method": "分析了DeiT、DeiT3和ViT等流行视觉变换器模型的4位量化表现，特别是在常见的OOD数据集上的表现。同时比较了不同预训练规模对量化结果的影响。", "result": "发现大规模图像预训练可能会影响小尺度模型在OOD检测中的低比特量化稳健性，并且数据增强可能是更有利的选择。", "conclusion": "研究揭示了视觉变换器模型在4位量化时的性能变化，特别是在处理OOD情况下的表现差异。"}}
{"id": "2602.01456", "pdf": "https://arxiv.org/pdf/2602.01456", "abs": "https://arxiv.org/abs/2602.01456", "authors": ["Yilun Kuang", "Yash Dagade", "Tim G. J. Rudner", "Randall Balestriero", "Yann LeCun"], "title": "Rectified LpJEPA: Joint-Embedding Predictive Architectures with Sparse and Maximum-Entropy Representations", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Joint-Embedding Predictive Architectures (JEPA) learn view-invariant representations and admit projection-based distribution matching for collapse prevention. Existing approaches regularize representations towards isotropic Gaussian distributions, but inherently favor dense representations and fail to capture the key property of sparsity observed in efficient representations. We introduce Rectified Distribution Matching Regularization (RDMReg), a sliced two-sample distribution-matching loss that aligns representations to a Rectified Generalized Gaussian (RGG) distribution. RGG enables explicit control over expected $\\ell_0$ norm through rectification, while preserving maximum-entropy up to rescaling under expected $\\ell_p$ norm constraints. Equipping JEPAs with RDMReg yields Rectified LpJEPA, which strictly generalizes prior Gaussian-based JEPAs. Empirically, Rectified LpJEPA learns sparse, non-negative representations with favorable sparsity-performance trade-offs and competitive downstream performance on image classification benchmarks, demonstrating that RDMReg effectively enforces sparsity while preserving task-relevant information.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.01452", "pdf": "https://arxiv.org/pdf/2602.01452", "abs": "https://arxiv.org/abs/2602.01452", "authors": ["Penghao Deng", "Jidong J. Yang", "Jiachen Bian"], "title": "Cross-Paradigm Evaluation of Gaze-Based Semantic Object Identification for Intelligent Vehicles", "categories": ["cs.CV", "cs.AI"], "comment": "21 pages, 15 figures, 3 tables", "summary": "Understanding where drivers direct their visual attention during driving, as characterized by gaze behavior, is critical for developing next-generation advanced driver-assistance systems and improving road safety. This paper tackles this challenge as a semantic identification task from the road scenes captured by a vehicle's front-view camera. Specifically, the collocation of gaze points with object semantics is investigated using three distinct vision-based approaches: direct object detection (YOLOv13), segmentation-assisted classification (SAM2 paired with EfficientNetV2 versus YOLOv13), and query-based Vision-Language Models, VLMs (Qwen2.5-VL-7b versus Qwen2.5-VL-32b). The results demonstrate that the direct object detection (YOLOv13) and Qwen2.5-VL-32b significantly outperform other approaches, achieving Macro F1-Scores over 0.84. The large VLM (Qwen2.5-VL-32b), in particular, exhibited superior robustness and performance for identifying small, safety-critical objects such as traffic lights, especially in adverse nighttime conditions. Conversely, the segmentation-assisted paradigm suffers from a \"part-versus-whole\" semantic gap that led to large failure in recall. The results reveal a fundamental trade-off between the real-time efficiency of traditional detectors and the richer contextual understanding and robustness offered by large VLMs. These findings provide critical insights and practical guidance for the design of future human-aware intelligent driver monitoring systems.", "AI": {"tldr": "本文研究了通过车辆前视摄像头捕捉的场景，利用不同的视觉方法来识别驾驶员注视点对应的语义对象，以提升自动驾驶系统的性能和安全性。", "motivation": "理解驾驶员在驾驶过程中视线的关注点对于开发下一代高级驾驶员辅助系统以及提高道路安全至关重要。基于此背景，本文研究了如何通过不同视觉技术准确识别驾驶员的注视目标。", "method": "本文采用了三种不同的方法：直接对象检测（YOLOv13）、分割辅助分类（SAM2与EfficientNetV2或YOLOv13结合）和查询驱动的视觉-语言模型（Qwen2.5-VL-7b和Qwen2.5-VL-32b）。通过比较这些方法的效果，以确定哪种方法更适合识别驾驶员注视的目标。", "result": "研究结果表明，直接对象检测法（YOLOv13）和较大的视觉语言模型（Qwen2.5-VL-32b）表现最佳，Macro F1-Scores均超过0.84。在夜间等不利条件下，大型VLM尤其擅长识别如交通信号灯等小而重要的安全目标。", "conclusion": "本文研究揭示了传统检测器与大规模视觉语言模型之间的关键权衡：前者具有实时效率优势，后者则提供了更为丰富和鲁棒的上下文理解。这些发现为未来的人机交互智能监控系统的开发提供了重要见解和实用指导。"}}
{"id": "2602.01450", "pdf": "https://arxiv.org/pdf/2602.01450", "abs": "https://arxiv.org/abs/2602.01450", "authors": ["Abhisek Dash", "Soumi Das", "Elisabeth Kirsten", "Qinyuan Wu", "Sai Keerthana Karnam", "Krishna P. Gummadi", "Thorsten Holz", "Muhammad Bilal Zafar", "Savvas Zannettou"], "title": "The Algorithmic Self-Portrait: Deconstructing Memory in ChatGPT", "categories": ["cs.HC", "cs.CY", "cs.IR"], "comment": "This paper has been accepted at The ACM Web Conference 2026", "summary": "To enable personalized and context-aware interactions, conversational AI systems have introduced a new mechanism: Memory. Memory creates what we refer to as the Algorithmic Self-portrait - a new form of personalization derived from users' self-disclosed information divulged within private conversations. While memory enables more coherent exchanges, the underlying processes of memory creation remain opaque, raising critical questions about data sensitivity, user agency, and the fidelity of the resulting portrait. To bridge this research gap, we analyze 2,050 memory entries from 80 real-world ChatGPT users. Our analyses reveal three key findings: (1) A striking 96% of memories in our dataset are created unilaterally by the conversational system, potentially shifting agency away from the user; (2) Memories, in our dataset, contain a rich mix of GDPR-defined personal data (in 28% memories) along with psychological insights about participants (in 52% memories); and (3)~A significant majority of the memories (84%) are directly grounded in user context, indicating faithful representation of the conversations. Finally, we introduce a framework-Attribution Shield-that anticipates these inferences, alerts about potentially sensitive memory inferences, and suggests query reformulations to protect personal information without sacrificing utility.", "AI": {"tldr": "研究通过分析ChatGPT用户的记忆条目，探讨算法自画像的生成机制及其对用户代理和隐私的影响。", "motivation": "旨在揭示对话AI系统中内存创建过程的透明度问题，并探索如何保护用户数据敏感性和用户代理。", "method": "分析了来自80位真实世界ChatGPT用户的2,050条记忆记录，研究其生成方式、包含的数据类型及其与上下文的关系。", "result": "发现96%的记忆由系统单方面创建；其中包含大量的个人数据和心理洞察；大部分记忆忠实反映了对话内容。提出了“归属盾牌”框架以保护个人信息。", "conclusion": "揭示了ChatGPT中内存生成过程的潜在问题，并提供了一种新的机制来增强用户隐私和代理权。"}}
{"id": "2602.01448", "pdf": "https://arxiv.org/pdf/2602.01448", "abs": "https://arxiv.org/abs/2602.01448", "authors": ["Harshith Jella", "Pejman Kheradmand", "Joseph Klein", "Behnam Moradkhani", "Yash Chitalia"], "title": "Towards a Novel Wearable Robotic Vest for Hemorrhage Suppression", "categories": ["cs.RO"], "comment": null, "summary": "This paper introduces a novel robotic system designed to manage severe bleeding in emergency scenarios, including unique environments like space stations. The robot features a shape-adjustable \"ring mechanism\", transitioning from a circular to an elliptical configuration to adjust wound coverage across various anatomical regions. We developed various arms for this ring mechanism with varying flexibilities to improve adaptability when applied to non-extremities of the body (abdomen, back, neck, etc.). To apply equal and constant pressure across the wound, we developed an inflatable ring and airbag balloon that are compatible with this shape-changing ring mechanism. A series of experiments focused on evaluating various ring arm configurations to characterize their bending stiffness. Subsequent experiments measured the force exerted by the airbag balloon system using a digital scale. Despite its promising performance, certain limitations related to coverage area are identified. The shape-changing effect of the device is limited to scenarios involving partially inflated or deflated airbag balloons, and cannot fully conform to complex anatomical regions. Finally, the device was tested on casualty simulation kits, where it successfully demonstrated its ability to control simulated bleeding.", "AI": {"tldr": "本论文提出了一种新型可穿戴机器人背心，旨在管理紧急情况下的严重出血。", "motivation": "在特殊环境中（如太空站）处理严重出血的需求推动了该技术的发展。需要一种能够适应不同人体部位且能施加均匀压力的设备来控制出血。", "method": "开发了一种具有可调整形状机制（从圆形到椭圆形转换）和各种柔韧度手臂配置的机器人背心。使用充气环和气球系统，以确保在伤口处施加恒定的压力。通过实验测试了不同的手臂弯曲刚性和气球系统的力。", "result": "该装置成功地控制了模拟出血情况，并且能在不同的人体部位适应性良好，但是其覆盖范围有限制。", "conclusion": "尽管存在一些局限性，如无法完全贴合复杂人体结构的限制，但这项技术为管理严重出血提供了一种新的解决方案。"}}
{"id": "2602.01447", "pdf": "https://arxiv.org/pdf/2602.01447", "abs": "https://arxiv.org/abs/2602.01447", "authors": ["Hieu Minh Duong", "Rupa Ghosh", "Cong Hoan Nguyen", "Eugene Levin", "Todd Gary", "Long Nguyen"], "title": "SentiFuse: Deep Multi-model Fusion Framework for Robust Sentiment Extraction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sentiment analysis models exhibit complementary strengths, yet existing approaches lack a unified framework for effective integration. We present SentiFuse, a flexible and model-agnostic framework that integrates heterogeneous sentiment models through a standardization layer and multiple fusion strategies. Our approach supports decision-level fusion, feature-level fusion, and adaptive fusion, enabling systematic combination of diverse models. We conduct experiments on three large-scale social-media datasets: Crowdflower, GoEmotions, and Sentiment140. These experiments show that SentiFuse consistently outperforms individual models and naive ensembles. Feature-level fusion achieves the strongest overall effectiveness, yielding up to 4\\% absolute improvement in F1 score over the best individual model and simple averaging, while adaptive fusion enhances robustness on challenging cases such as negation, mixed emotions, and complex sentiment expressions. These results demonstrate that systematically leveraging model complementarity yields more accurate and reliable sentiment analysis across diverse datasets and text types.", "AI": {"tldr": "SentiFuse 是一种集成多种情感模型的框架，通过标准化层和多重融合策略实现有效整合。", "motivation": "现有的情感分析模型虽然表现出互补的优势，但缺乏有效的统一集成方法。因此提出 SentiFuse 框架来解决这一问题。", "method": "SentiFuse 提供了决策级融合、特征级融合以及自适应融合三种方式，并在三个大规模社交媒体数据集上进行了实验。", "result": "实验结果表明，SentiFuse 在 F1 分数上相较于单个模型和简单集成最高可提升4%绝对值。其中特征级融合效果最强，自适应融合对否定、混合情绪等复杂情况具有更好的鲁棒性。", "conclusion": "系统地利用模型互补性可以实现更准确可靠的情感分析，适用于各种数据集和文本类型"}}
{"id": "2602.01444", "pdf": "https://arxiv.org/pdf/2602.01444", "abs": "https://arxiv.org/abs/2602.01444", "authors": ["Tal Grutman", "Carmel Shinar", "Tali Ilovitsh"], "title": "A texture-based framework for foundational ultrasound models", "categories": ["eess.IV", "cs.CV"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Ultrasound is the most widely used medical imaging modality, yet the images it produces are fundamentally unique, arising from tissue-dependent scattering, reflection, and speed-of-sound variations that produce a constrained set of characteristic textures that differ markedly from natural-image statistics. These acoustically driven patterns make ultrasound challenging for algorithms originally designed for natural images. To bridge this gap, the field has increasingly turned to foundation models, hoping to leverage their generalization capabilities. However, these models often falter in ultrasound applications because they are not designed for ultrasound physics, they are merely trained on ultrasound data. Therefore, it is essential to integrate ultrasound-specific domain knowledge into established learning frameworks. We achieve this by reformulating self-supervised learning as a texture-analysis problem, introducing texture ultrasound semantic analysis (TUSA). Using TUSA, models learn to leverage highly scalable contrastive methods to extract true domain-specific representations directly from simple B-mode images. We train a TUSA model on a combination of open-source, simulated, and in vivo data. The latent space is compared to several larger foundation models, demonstrating that our approach gives TUSA models better generalizability for difficult downstream tasks on unique online datasets as well as a clinical eye dataset collected for this study. Our model achieves higher accuracy in detecting COVID (70%), spinal hematoma (100%) and vitreous hemorrhage (97%) and correlates more closely with quantitative parameters like liver steatosis (r = 0.83), ejection fraction (r = 0.63), and oxygen saturation (r = 0.38). We open-source the model weights and training script: https://github.com/talg2324/tusa", "AI": {"tldr": "该论文提出了一种基于纹理的框架，旨在通过将自我监督学习重新定义为纹理分析问题来改进基础模型在超声成像中的表现。", "motivation": "传统算法难以处理由组织依赖散射、反射和速度变化产生的独特超声图像。现有的基础模型虽尝试利用大规模数据训练以提高泛化能力，但在超声特定领域性能不佳，因此有必要结合领域知识改进学习框架。", "method": "论文提出了纹理超声语义分析（TUSA）方法，通过对比学习从简单的B模态图像中提取出真正具有领域特性的表示，并使用开源、模拟及体内数据进行训练。", "result": "模型在检测COVID-19、脊髓血肿和视网膜出血等任务上表现优异，准确率分别为70%、100%和97%，并且与肝脂肪变性定量参数、射血分数以及氧饱和度的关联更为紧密。", "conclusion": "通过结合领域知识改进学习框架的方法显著提升了超声图像处理中基础模型的应用效果。"}}
{"id": "2602.01443", "pdf": "https://arxiv.org/pdf/2602.01443", "abs": "https://arxiv.org/abs/2602.01443", "authors": ["Alberto Castelo", "Zahra Zanjani Foumani", "Ailin Fan", "Keat Yang Koay", "Vibhor Malik", "Yuanzheng Zhu", "Han Li", "Meysam Feghhi", "Ronie Uliana", "Shuang Xie", "Zhaoyu Zhang", "Angelo Ocana Martins", "Mingyu Zhao", "Francis Pelland", "Jonathan Faerman", "Nikolas LeBlanc", "Aaron Glazer", "Andrew McNamara", "Lingyun Wang", "Zhong Wu"], "title": "SimGym: Traffic-Grounded Browser Agents for Offline A/B Testing in E-Commerce", "categories": ["cs.AI"], "comment": null, "summary": "A/B testing remains the gold standard for evaluating e-commerce UI changes, yet it diverts traffic, takes weeks to reach significance, and risks harming user experience. We introduce SimGym, a scalable system for rapid offline A/B testing using traffic-grounded synthetic buyers powered by Large Language Model agents operating in a live browser. SimGym extracts per-shop buyer profiles and intents from production interaction data, identifies distinct behavioral archetypes, and simulates cohort-weighted sessions across control and treatment storefronts. We validate SimGym against real human outcomes from real UI changes on a major e-commerce platform under confounder control. Even without alignment post training, SimGym agents achieve state of the art alignment with observed outcome shifts and reduces experiment cycles from weeks to under an hour , enabling rapid experimentation without exposure to real buyers.", "AI": {"tldr": "本文介绍了一种名为SimGym的系统，用于在电子商务中进行快速离线A/B测试。", "motivation": "传统的A/B测试耗时长且可能影响用户体验，因此需要一种新的方法来加快这一过程并减少对真实用户的潜在危害。", "method": "通过从生产交互数据中提取买家档案和意图，SimGym使用大型语言模型代理在实时浏览器环境中模拟带有不同行为类型的买家会话，并将其应用于对照组和处理组商店的会话中。", "result": "即使没有进行后期培训调整，SimGym代理也实现了与实际用户结果变化的最新对齐水平，并将实验周期从数周减少到不到一个小时。", "conclusion": "SimGym提供了一种有效的方法来加速电子商务UI更改评估过程，同时避免了真实用户可能遭受的风险。"}}
{"id": "2602.01442", "pdf": "https://arxiv.org/pdf/2602.01442", "abs": "https://arxiv.org/abs/2602.01442", "authors": ["Donald Ye"], "title": "The Gradient-Causal Gap: Why Gradient Importance Fails on Complex Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "8 pages, 4 figures. Submitted to the ICLR 2026 Workshop on Latent & Implicit Thinking (LIT). Code:https://anonymous.4open.science/r/ICLR_2026_LIT-workshop_CG-D42B", "summary": "Removing ''important'' high-gradient components from a neural network can improve generalization, while removing unimportant'' low-gradient components can destroy it. We demonstrate this paradox by formalizing the \\textit{Gradient-Causal Gap} in Transformers trained on algorithmic tasks. While gradient magnitude and causal importance align on simple tasks ($ρ=0.73$ for reversal), this relationship collapses as task complexity increases ($ρ=0.32$ for sorting), sometimes becoming inverted ($ρ=-0.11$). Pruning experiments reveal that gradient magnitude is not merely inaccurate but \\textit{unpredictably} so. Removing low-gradient ''Hidden Heroes'' consistently devastates OOD accuracy ($-32\\%$). Removing high-gradient ''Gradient Bloats'' is a coin flip: harmless in most seeds (indicating optimization noise), catastrophic in others (indicating overfitting circuits). This unpredictability means gradient-based pruning cannot reliably preserve model capabilities.", "AI": {"tldr": "本文探讨了神经网络在复杂任务上的梯度重要性和因果关系之间的差距，发现随着任务的复杂性增加，这两个指标的相关性下降。", "motivation": "作者试图解释为什么在简单的算法任务中，高梯度的重要性与模型性能相关联的现象，在更复杂的任务中不再成立。通过定义并探讨“Gradient-Causal Gap”，揭示了梯度重要性和因果关系之间的差异。", "method": "通过对变压器（Transformers）模型在不同复杂性任务上的实验，量化高和低梯度组件的移除对模型性能的影响，并分析这些影响背后的原因。", "result": "结果表明，在简单任务中，高梯度通常与重要的因果作用相关联；而在复杂任务中，这种关系变得不稳定甚至反转。低梯度组件（Hidden Heroes）在一些情况下对模型的表现至关重要，而高梯度的去除则可能带来随机的结果，有时是有害的。", "conclusion": "该研究揭示了复杂任务下梯度重要性与因果作用之间的不一致性，并指出基于梯度的剪枝方法无法可靠地保持模型的能力。"}}
{"id": "2602.01439", "pdf": "https://arxiv.org/pdf/2602.01439", "abs": "https://arxiv.org/abs/2602.01439", "authors": ["Perry Dong", "Kuo-Han Hung", "Alexander Swerdlow", "Dorsa Sadigh", "Chelsea Finn"], "title": "TQL: Scaling Q-Functions with Transformers by Preventing Attention Collapse", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite scale driving substantial recent advancements in machine learning, reinforcement learning (RL) methods still primarily use small value functions. Naively scaling value functions -- including with a transformer architecture, which is known to be highly scalable -- often results in learning instability and worse performance. In this work, we ask what prevents transformers from scaling effectively for value functions? Through empirical analysis, we identify the critical failure mode in this scaling: attention scores collapse as capacity increases. Our key insight is that we can effectively prevent this collapse and stabilize training by controlling the entropy of the attention scores, thereby enabling the use of larger models. To this end, we propose Transformer Q-Learning (TQL), a method that unlocks the scaling potential of transformers in learning value functions in RL. Our approach yields up to a 43% improvement in performance when scaling from the smallest to the largest network sizes, while prior methods suffer from performance degradation.", "AI": {"tldr": "研究探讨如何通过控制注意力分数的熵来防止注意力坍缩，从而提高基于transformer的价值函数在强化学习中的可扩展性。", "motivation": "尽管规模扩大促进了机器学习领域的许多进步，但强化学习方法仍主要使用小规模的价值函数。直接用变压器架构进行规模扩展会导致学习不稳定和性能下降，因此研究试图找到解决这一问题的方法以提高模型的规模适用性。", "method": "通过控制注意力分数的熵来防止注意力坍缩，并提出Transformer Q-Learning (TQL) 方法，从而解锁了在强化学习中使用更大规模变压器架构的可能性。", "result": "相较于先前方法性能下降的情况，该方法可以在从小到大的网络规模扩展时提高多达43%的性能表现。", "conclusion": "通过控制注意力熵防止坍缩的方法，成功提高了基于transformer的价值函数在大规模下的稳定性和性能。"}}
{"id": "2602.01438", "pdf": "https://arxiv.org/pdf/2602.01438", "abs": "https://arxiv.org/abs/2602.01438", "authors": ["Max Manolov", "Tony Gao", "Siddharth Shukla", "Cheng-Ting Chou", "Ryan Lagasse"], "title": "CIPHER: Cryptographic Insecurity Profiling via Hybrid Evaluation of Responses", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to assist developers with code, yet their implementations of cryptographic functionality often contain exploitable flaws. Minor design choices (e.g., static initialization vectors or missing authentication) can silently invalidate security guarantees. We introduce CIPHER(\\textbf{C}ryptographic \\textbf{I}nsecurity \\textbf{P}rofiling via \\textbf{H}ybrid \\textbf{E}valuation of \\textbf{R}esponses), a benchmark for measuring cryptographic vulnerability incidence in LLM-generated Python code under controlled security-guidance conditions. CIPHER uses insecure/neutral/secure prompt variants per task, a cryptography-specific vulnerability taxonomy, and line-level attribution via an automated scoring pipeline. Across a diverse set of widely used LLMs, we find that explicit ``secure'' prompting reduces some targeted issues but does not reliably eliminate cryptographic vulnerabilities overall. The benchmark and reproducible scoring pipeline will be publicly released upon publication.", "AI": {"tldr": "介绍CIPHER基准测试，用于评估大语言模型生成的Python代码中的密码学脆弱性。", "motivation": "大型语言模型在辅助开发者编写代码时，其实现的密码功能经常存在可被利用的安全漏洞。希望通过此研究减少这些安全隐患。", "method": "使用不安全/中立/安全提示变体、专门针对密码学的漏洞分类以及自动评分流水线进行行级别属性分析。", "result": "通过多样化的大型语言模型测试，发现明确的“安全”提示可以降低某些问题的发生率，但不能完全消除密码学脆弱性。", "conclusion": "CIPHER基准和可重复的评分管道将公开发布，以帮助评估大语言模型生成代码的安全性。"}}
{"id": "2602.01435", "pdf": "https://arxiv.org/pdf/2602.01435", "abs": "https://arxiv.org/abs/2602.01435", "authors": ["Soumyaroop Nandi", "Prem Natarajan"], "title": "BioTamperNet: Affinity-Guided State-Space Model Detecting Tampered Biomedical Images", "categories": ["cs.CV"], "comment": null, "summary": "We propose BioTamperNet, a novel framework for detecting duplicated regions in tampered biomedical images, leveraging affinity-guided attention inspired by State Space Model (SSM) approximations. Existing forensic models, primarily trained on natural images, often underperform on biomedical data where subtle manipulations can compromise experimental validity. To address this, BioTamperNet introduces an affinity-guided self-attention module to capture intra-image similarities and an affinity-guided cross-attention module to model cross-image correspondences. Our design integrates lightweight SSM-inspired linear attention mechanisms to enable efficient, fine-grained localization. Trained end-to-end, BioTamperNet simultaneously identifies tampered regions and their source counterparts. Extensive experiments on the benchmark bio-forensic datasets demonstrate significant improvements over competitive baselines in accurately detecting duplicated regions. Code - https://github.com/SoumyaroopNandi/BioTamperNet", "AI": {"tldr": "提出BioTamperNet，一种新的检测生物医学图像中重复区域的框架", "motivation": "现有取证模型在自然图像上训练，对细微操作敏感度不足，无法有效处理生物医学数据中的篡改问题", "method": "引入亲和力引导自注意力模块捕捉内部相似性与跨图对应关系，集成SSM启发式线性注意机制进行高效精细定位", "result": "实验结果显示在基准生物取证数据集上显著优于竞争基线模型", "conclusion": "BioTamperNet能准确检测并识别篡改区域及其来源"}}
{"id": "2602.01433", "pdf": "https://arxiv.org/pdf/2602.01433", "abs": "https://arxiv.org/abs/2602.01433", "authors": ["Muhammad Hasan Ferdous", "Md Osman Gani"], "title": "DCD: Decomposition-based Causal Discovery from Autocorrelated and Non-Stationary Temporal Data", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": ":62M10", "summary": "Multivariate time series in domains such as finance, climate science, and healthcare often exhibit long-term trends, seasonal patterns, and short-term fluctuations, complicating causal inference under non-stationarity and autocorrelation. Existing causal discovery methods typically operate on raw observations, making them vulnerable to spurious edges and misattributed temporal dependencies. We introduce a decomposition-based causal discovery framework that separates each time series into trend, seasonal, and residual components and performs component-specific causal analysis. Trend components are assessed using stationarity tests, seasonal components using kernel-based dependence measures, and residual components using constraint-based causal discovery. The resulting component-level graphs are integrated into a unified multi-scale causal structure. This approach isolates long- and short-range causal effects, reduces spurious associations, and improves interpretability. Across extensive synthetic benchmarks and real-world climate data, our framework more accurately recovers ground-truth causal structure than state-of-the-art baselines, particularly under strong non-stationarity and temporal autocorrelation.", "AI": {"tldr": "基于分解的因果发现框架，用于从非平稳和自相关的多变量时间序列数据中提取因果结构。", "motivation": "现有的因果发现方法在处理具有长期趋势、季节性模式和短期波动的数据时容易产生虚假关联和误判的时间依赖关系。本研究旨在提出一种新的方法来改善这种情况。", "method": "该框架通过将每个时间序列分解为趋势分量、季节性分量和残差分量，并针对每部分进行专门的因果分析，包括使用平稳性测试评估趋势分量、核基依赖度量评估季节性分量以及约束基础因果发现评估残差分量。", "result": "在广泛的合成基准数据集和实际气候数据集中，所提出的框架比最先进的方法更准确地恢复了真实的因果结构，特别是在强非平稳性和时间自相关的情况下表现尤为出色。", "conclusion": "此研究提供了一种有效的方法来处理具有长期趋势、季节性模式和短期波动的多变量时间序列中的因果发现问题，并在实际应用中表现出色。"}}
{"id": "2602.01429", "pdf": "https://arxiv.org/pdf/2602.01429", "abs": "https://arxiv.org/abs/2602.01429", "authors": ["Gonzalo Olguin", "Javier Ruiz-del-Solar"], "title": "Sem-NaVAE: Semantically-Guided Outdoor Mapless Navigation via Generative Trajectory Priors", "categories": ["cs.RO"], "comment": "8 pages, 5 figures", "summary": "This work presents a mapless global navigation approach for outdoor applications. It combines the exploratory capacity of conditional variational autoencoders (CVAEs) to generate trajectories and the semantic segmentation capabilities of a lightweight visual language model (VLM) to select the trajectory to execute. Open-vocabulary segmentation is used to score and select the generated trajectories based on natural language, and a state-of-the-art local planner executes velocity commands. One of the key features of the proposed approach is its ability to generate a large variability of trajectories and to select them and navigate in real-time. The approach was validated through real-world outdoor navigation experiments, achieving superior performance compared to state-of-the-art methods. A video showing an experimental run of the system can be found in https://www.youtube.com/watch?v=i3R5ey5O2yk.", "AI": {"tldr": "本文提出了一种基于生成轨迹先验和语义引导的无地图全局导航方法，用于室外应用。", "motivation": "为了解决室外环境下无地图全局导航的问题，并提高在动态环境中适应性和实时性。", "method": "结合条件变分自编码器（CVAE）生成轨迹以及轻量级视觉语言模型进行语义分割和选择轨迹。利用开放词汇段落评分并选择基于自然语言的轨迹，使用先进的本地规划器执行速度命令。", "result": "通过实际室外导航实验验证了该方法的有效性，并表现出比现有最先进的方法更好的性能。", "conclusion": "该研究提出了一种新颖的方法来实现无地图全局导航，在生成多样化轨迹和实时选择方面取得了成功。"}}
{"id": "2602.01425", "pdf": "https://arxiv.org/pdf/2602.01425", "abs": "https://arxiv.org/abs/2602.01425", "authors": ["Vikram Natarajan", "Devina Jain", "Shivam Arora", "Satvik Golechha", "Joseph Bloom"], "title": "Building Better Deception Probes Using Targeted Instruction Pairs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Linear probes are a promising approach for monitoring AI systems for deceptive behaviour. Previous work has shown that a linear classifier trained on a contrastive instruction pair and a simple dataset can achieve good performance. However, these probes exhibit notable failures even in straightforward scenarios, including spurious correlations and false positives on non-deceptive responses. In this paper, we identify the importance of the instruction pair used during training. Furthermore, we show that targeting specific deceptive behaviors through a human-interpretable taxonomy of deception leads to improved results on evaluation datasets. Our findings reveal that instruction pairs capture deceptive intent rather than content-specific patterns, explaining why prompt choice dominates probe performance (70.6% of variance). Given the heterogeneity of deception types across datasets, we conclude that organizations should design specialized probes targeting their specific threat models rather than seeking a universal deception detector.", "AI": {"tldr": "本文研究了通过使用特定指令对提高AI系统欺骗行为监测的线性探针性能的方法。", "motivation": "针对现有线性探针在简单场景下的表现不佳和误报问题，提出改进方法以更准确地捕捉欺骗意图而非具体模式。", "method": "设计一种基于人类可理解的欺骗分类法，通过针对性的选择指令对来训练线性探针，并验证其效果。", "result": "结果显示，特定的指令选择对于探针性能有决定性影响（占70.6%方差），并且可以有效提高探测特定类型欺骗行为的能力。", "conclusion": "由于欺骗形式在不同数据集中的异质性，组织应根据自身威胁模型设计专门的线性探针而非寻找通用解决方案。"}}
{"id": "2602.01423", "pdf": "https://arxiv.org/pdf/2602.01423", "abs": "https://arxiv.org/abs/2602.01423", "authors": ["Matt Gottsacker", "Yahya Hmaiti", "Mykola Maslych", "Hiroshi Furuya", "Jasmine Joyce DeGuzman", "Gerd Bruder", "Gregory F. Welch", "Joseph J. LaViola Jr"], "title": "From One World to Another: Interfaces for Efficiently Transitioning Between Virtual Environments", "categories": ["cs.HC"], "comment": ":I.3.7", "summary": "Personal computers and handheld devices provide keyboard shortcuts and swipe gestures to enable users to efficiently switch between applications, whereas today's virtual reality (VR) systems do not. In this work, we present an exploratory study on user interface aspects to support efficient switching between worlds in VR. We created eight interfaces that afford previewing and selecting from the available virtual worlds, including methods using portals and worlds-in-miniature (WiMs). To evaluate these methods, we conducted a controlled within-subjects empirical experiment (N=22) where participants frequently transitioned between six different environments to complete an object collection task. Our quantitative and qualitative results show that WiMs supported rapid acquisition of high-level spatial information while searching and were deemed most efficient by participants while portals provided fast pre-orientation. Finally, we present insights into the applicability, usability, and effectiveness of the VR world switching methods we explored, and provide recommendations for their application and future context/world switching techniques and interfaces.", "AI": {"tldr": "研究探索了虚拟现实系统中用户界面的设计，以支持高效地在不同虚拟环境之间切换。", "motivation": "个人计算机和手持设备提供了键盘快捷键和滑动手势来使用户能够在应用程序间快速切换，而目前的虚拟现实（VR）系统并未提供相应功能。因此，研究旨在探索支持VR中有效切换世界界面的方法。", "method": "创建了八种不同的接口，包括使用传送门和微型世界的预览和选择方法，并进行了控制的实验设计，参与者在六个不同环境中频繁过渡以完成一个对象收集任务。", "result": "量化结果表明，微型世界支持快速获取空间信息搜索中的高层次信息，同时被认为是最有效的。而传送门提供了快速的预定向。", "conclusion": "研究提出了虚拟现实系统中有效切换世界的适用性、可用性和有效性见解，并为未来上下文/世界切换技术的应用和界面设计提供了一些建议"}}
{"id": "2602.01419", "pdf": "https://arxiv.org/pdf/2602.01419", "abs": "https://arxiv.org/abs/2602.01419", "authors": ["Dennis Gross", "Helge Spieker", "Arnaud Gotlieb", "Emmanuel Stathatos", "Panorios Benardos", "George-Christopher Vosniakos"], "title": "Semi-supervised CAPP Transformer Learning via Pseudo-labeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "High-level Computer-Aided Process Planning (CAPP) generates manufacturing process plans from part specifications. It suffers from limited dataset availability in industry, reducing model generalization. We propose a semi-supervised learning approach to improve transformer-based CAPP transformer models without manual labeling. An oracle, trained on available transformer behaviour data, filters correct predictions from unseen parts, which are then used for one-shot retraining. Experiments on small-scale datasets with simulated ground truth across the full data distribution show consistent accuracy gains over baselines, demonstrating the method's effectiveness in data-scarce manufacturing environments.", "AI": {"tldr": "提出了一种基于伪标签的半监督学习方法，以增强CAPP模型在小样本条件下的泛化能力。", "motivation": "工业中高级计算机辅助过程规划（CAPP）面临数据集稀缺问题，导致模型泛化性差。通过引入一种无需人工标注的半监督学习策略来改进基于变换器的CAPP模型。", "method": "利用预训练的Oracle模型对未见过的数据进行预测并筛选出正确的样本，然后使用这些伪标签样本重新训练整个模型，以提高模型性能和泛化能力。", "result": "实验结果表明，在小规模数据集上采用该方法可以显著提升模型准确性，并优于传统基线方法。", "conclusion": "所提出的基于变换器的半监督学习框架能够在制造环境中有效应对数据稀缺问题，提供了一种新的改进CAPP模型的方法。"}}
{"id": "2602.01418", "pdf": "https://arxiv.org/pdf/2602.01418", "abs": "https://arxiv.org/abs/2602.01418", "authors": ["Christoffer Koo Øhrstrøm", "Rafael I. Cabral Muchacho", "Yifei Dong", "Filippos Moumtzidellis", "Ronja Güldenring", "Florian T. Pokorny", "Lazaros Nalpantidis"], "title": "Where to Attend: A Principled Vision-Centric Position Encoding with Parabolas", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We propose Parabolic Position Encoding (PaPE), a parabola-based position encoding for vision modalities in attention-based architectures. Given a set of vision tokens-such as images, point clouds, videos, or event camera streams-our objective is to encode their positions while accounting for the characteristics of vision modalities. Prior works have largely extended position encodings from 1D-sequences in language to nD-structures in vision, but only with partial account of vision characteristics. We address this gap by designing PaPE from principles distilled from prior work: translation invariance, rotation invariance (PaPE-RI), distance decay, directionality, and context awareness. We evaluate PaPE on 8 datasets that span 4 modalities. We find that either PaPE or PaPE-RI achieves the top performance on 7 out of 8 datasets. Extrapolation experiments on ImageNet-1K show that PaPE extrapolates remarkably well, improving in absolute terms by up to 10.5% over the next-best position encoding. Code is available at https://github.com/DTU-PAS/parabolic-position-encoding.", "AI": {"tldr": "本文提出了Parabolic Position Encoding (PaPE)，一种基于抛物线的位置编码方法，用于视觉模态的关注机制架构。", "motivation": "现有工作将位置编码从语言中的1D序列扩展到视觉中的nD结构，但未能充分考虑视觉特征。为解决这一问题，提出了一种新的位置编码方案。", "method": "PaPE基于先前工作的原理设计：平移不变性、旋转不变性（PaPE-RI）、距离衰减、方向性和上下文感知，适用于图像、点云、视频或事件相机流等视觉标记。", "result": "在8个数据集上进行评估，包括4种模态。实验显示，无论是PaPE还是PaPE-RI都在7个数据集中取得了最佳性能，在ImageNet-1K上的外推实验表明其效果显著优于其他位置编码方法，提升幅度最高达10.5%。", "conclusion": "本文提出的PaPE能够在不同视觉模态中有效进行位置编码，并在多个任务上表现出色。"}}
{"id": "2602.01405", "pdf": "https://arxiv.org/pdf/2602.01405", "abs": "https://arxiv.org/abs/2602.01405", "authors": ["Nikhil Sharma", "Zheng Zhang", "Daniel Lee", "Namita Krishnan", "Guang-Jie Ren", "Ziang Xiao", "Yunyao Li"], "title": "Feedback by Design: Understanding and Overcoming User Feedback Barriers in Conversational Agents", "categories": ["cs.HC"], "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems, 23 pages, 3 figures", "summary": "High-quality feedback is essential for effective human-AI interaction. It bridges knowledge gaps, corrects digressions, and shapes system behavior; both during interaction and throughout model development. Yet despite its importance, human feedback to AI is often infrequent and low quality. This gap motivates a critical examination of human feedback during interactions with AIs. To understand and overcome the challenges preventing users from giving high-quality feedback, we conducted two studies examining feedback dynamics between humans and conversational agents (CAs). Our formative study, through the lens of Grice's maxims, identified four Feedback Barriers -- Common Ground, Verifiability, Communication, and Informativeness -- that prevent high-quality feedback by users. Building on these findings, we derive three design desiderata and show that systems incorporating scaffolds aligned with these desiderata enabled users to provide higher-quality feedback. Finally, we detail a call for action to the broader AI community for advances in Large Language Models capabilities to overcome Feedback Barriers.", "AI": {"tldr": "本文通过两个研究探讨了人类与对话代理之间的反馈动态，识别出阻碍高质量反馈的四个障碍，并提出了设计原则以提高用户提供的反馈质量。", "motivation": "高质量的人机交互反馈对于纠正偏离和塑造系统行为至关重要。然而，现实中的用户反馈往往不频繁且质量不高，因此本文旨在理解和克服这些挑战。", "method": "首先通过格式塔研究识别了四个反馈障碍；之后根据这些发现提出了三个设计原则，并展示了遵循这些原则的系统能够获得更高的质量反馈。", "result": "研究表明，通过提供适当的支撑结构可以显著提高用户提供的反馈质量。", "conclusion": "本文呼吁AI社区推进大型语言模型的能力以克服反馈障碍。"}}
{"id": "2602.01401", "pdf": "https://arxiv.org/pdf/2602.01401", "abs": "https://arxiv.org/abs/2602.01401", "authors": ["Niansong Zhang", "Sunwoo Kim", "Shreesha Srinath", "Zhiru Zhang"], "title": "From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rise of large language models has sparked interest in AI-driven hardware design, raising the question: does high-level synthesis (HLS) still matter in the agentic era? We argue that HLS remains essential. While we expect mature agentic hardware systems to leverage both HLS and RTL, this paper focuses on HLS and its role in enabling agentic optimization. HLS offers faster iteration cycles, portability, and design permutability that make it a natural layer for agentic optimization. This position paper makes three contributions. First, we explain why HLS serves as a practical abstraction layer and a golden reference for agentic hardware design. Second, we identify key limitations of current HLS tools, namely inadequate performance feedback, rigid interfaces, and limited debuggability that agents are uniquely positioned to address. Third, we propose a taxonomy for the symbiotic evolution of agentic HLS, clarifying how responsibility shifts from human designers to AI agents as systems advance from copilots to autonomous design partners.", "AI": {"tldr": "本文探讨了高级综合（HLS）在代理时代的重要性，并提出了代理HLS的共生进化路径。", "motivation": "随着大语言模型的发展，AI驱动硬件设计的兴趣增加。尽管存在疑问，但作者认为HLS仍然至关重要，因为它提供了快速迭代、可移植性和设计灵活性，这些都是代理优化所需的特性。", "method": "本文提出三个贡献：解释为何HLS作为实用抽象层和黄金参考对于代理硬件设计重要；识别当前HLS工具的局限性，如性能反馈不足、接口僵化及调试难度大，并指出这些问题是代理可以解决的问题；定义代理HLS共生进化的分类。", "result": "通过本文提出的贡献，明确了代理在HLS中发挥的作用以及如何随着系统从协驾到自主设计伙伴的发展而转移责任。", "conclusion": "高级综合（HLS）是未来硬件设计的关键工具。它提供了一个抽象层和一个黄金参考点，并且通过与AI代理的共生进化可以克服现有的局限性，从而更好地服务于未来的硬件设计需求。"}}
{"id": "2602.01399", "pdf": "https://arxiv.org/pdf/2602.01399", "abs": "https://arxiv.org/abs/2602.01399", "authors": ["Fabian Fumagalli", "Landon Butler", "Justin Singh Kang", "Kannan Ramchandran", "R. Teal Witter"], "title": "An Odd Estimator for Shapley Values", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The Shapley value is a ubiquitous framework for attribution in machine learning, encompassing feature importance, data valuation, and causal inference. However, its exact computation is generally intractable, necessitating efficient approximation methods. While the most effective and popular estimators leverage the paired sampling heuristic to reduce estimation error, the theoretical mechanism driving this improvement has remained opaque. In this work, we provide an elegant and fundamental justification for paired sampling: we prove that the Shapley value depends exclusively on the odd component of the set function, and that paired sampling orthogonalizes the regression objective to filter out the irrelevant even component. Leveraging this insight, we propose OddSHAP, a novel consistent estimator that performs polynomial regression solely on the odd subspace. By utilizing the Fourier basis to isolate this subspace and employing a proxy model to identify high-impact interactions, OddSHAP overcomes the combinatorial explosion of higher-order approximations. Through an extensive benchmark evaluation, we find that OddSHAP achieves state-of-the-art estimation accuracy.", "AI": {"tldr": "提出了一种新的Shapley值估计器OddSHAP，通过只在奇数子空间进行多项式回归来提高估计准确性。", "motivation": "现有的Shapley值估算方法利用配对采样减少误差，但其原理不透明。本文旨在提供一个理论上的解释，并开发一种更准确的估算器。", "method": "证明了Shapley值仅依赖于奇数部分的集合函数，提出OddSHAP估计器，使用傅里叶基隔离出奇数子空间并利用代理模型识别高影响交互作用。", "result": "通过广泛基准测试发现，OddSHAP在估算准确性上达到最佳水平。", "conclusion": "提出的OddSHAP估计器克服了更高阶近似中的组合爆炸问题，并实现了状态-of-the-art的Shapley值估计精度。"}}
{"id": "2602.01396", "pdf": "https://arxiv.org/pdf/2602.01396", "abs": "https://arxiv.org/abs/2602.01396", "authors": ["Ziheng Huang", "Robin Kar", "Hari Sundaram", "Tal August"], "title": "Living Contracts: Beyond Document-Centric Interaction with Legal Agreements", "categories": ["cs.HC"], "comment": null, "summary": "User interaction with legal contracts has been limited to document reading, which is often complicated by complex, ambiguous legal language. We explore possible futures where contract interfaces go beyond single document interfaces to (1) educate users with legal rights not stated in the contract, (2) transform legal language into alternative representations to aid information tasks before, during, and after signing, and (3) proactively supply contractual information at relevant moments. We refer to these future interfaces collectively as Living Contracts. Using residential leases as a case study, we created three design probes representing different possible Living Contracts. A three-part qualitative study (N=18) revealed participants' barriers to interacting with contracts, including interpreting complex language, uncertainty about legal rights, and the pressure to sign quickly. Participants' feedback on the probes highlighted how Living Contracts have the potential to address these challenges and open new design opportunities for human-contract interactions beyond document reading.", "AI": {"tldr": "研究提出了Living Contracts的概念，探索了法律合同交互的新方式。", "motivation": "当前用户在与法律文件交互时主要依赖阅读文档，并且面临复杂、含糊的法律语言等挑战。作者希望通过改进交互界面来提升用户体验和理解能力。", "method": "通过设计三类住宅租赁合同时的Living Contracts原型，进行多阶段定性研究以收集参与者反馈。", "result": "研究表明现有合同中的障碍包括复杂的语言解释问题、关于法律权利的不确定性以及快速签署的压力；而Living Contracts有望解决这些问题并开辟新的交互机会。", "conclusion": "Living Contracts有可能改进用户与法律文件之间的交互方式，提供更有效的信息传递和理解途径。"}}
{"id": "2602.01394", "pdf": "https://arxiv.org/pdf/2602.01394", "abs": "https://arxiv.org/abs/2602.01394", "authors": ["Yochai Yemini", "Yoav Ellinson", "Rami Ben-Ari", "Sharon Gannot", "Ethan Fetaya"], "title": "SSNAPS: Audio-Visual Separation of Speech and Background Noise with Diffusion Inverse Sampling", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": null, "summary": "This paper addresses the challenge of audio-visual single-microphone speech separation and enhancement in the presence of real-world environmental noise. Our approach is based on generative inverse sampling, where we model clean speech and ambient noise with dedicated diffusion priors and jointly leverage them to recover all underlying sources. To achieve this, we reformulate a recent inverse sampler to match our setting. We evaluate on mixtures of 1, 2, and 3 speakers with noise and show that, despite being entirely unsupervised, our method consistently outperforms leading supervised baselines in \\ac{WER} across all conditions. We further extend our framework to handle off-screen speaker separation. Moreover, the high fidelity of the separated noise component makes it suitable for downstream acoustic scene detection. Demo page: https://ssnapsicml.github.io/ssnapsicml2026/", "AI": {"tldr": "本文提出了SSNAPS方法，用于解决单麦克风环境噪声下的音频视觉语音分离和增强问题。", "motivation": "在真实环境中进行有效的语音分离和增强面临巨大挑战。现有方法需要大量监督数据，而该研究通过无监督方式达到了优越的性能。", "method": "采用生成式逆向采样技术，利用扩散先验模型对干净语音和背景噪声建模，并联合它们恢复所有底层信号源。", "result": "实验表明，尽管完全不需要监督训练，但所提出的方法在不同条件下始终优于现有最佳方法。", "conclusion": "SSNAPS框架能够有效地进行单麦克风环境下的语音分离，并且可以用于下游音频场景检测任务。"}}
{"id": "2602.01391", "pdf": "https://arxiv.org/pdf/2602.01391", "abs": "https://arxiv.org/abs/2602.01391", "authors": ["Xiaoyan Xing", "Xiao Zhang", "Sezer Karaoglu", "Theo Gevers", "Anand Bhattad"], "title": "Stronger Semantic Encoders Can Harm Relighting Performance: Probing Visual Priors via Augmented Latent Intrinsics", "categories": ["cs.CV"], "comment": "Project page: https:\\\\augmented-latent-intrinsics.github.io", "summary": "Image-to-image relighting requires representations that disentangle scene properties from illumination. Recent methods rely on latent intrinsic representations but remain under-constrained and often fail on challenging materials such as metal and glass. A natural hypothesis is that stronger pretrained visual priors should resolve these failures. We find the opposite: features from top-performing semantic encoders often degrade relighting quality, revealing a fundamental trade-off between semantic abstraction and photometric fidelity. We study this trade-off and introduce Augmented Latent Intrinsics (ALI), which balances semantic context and dense photometric structure by fusing features from a pixel-aligned visual encoder into a latent-intrinsic framework, together with a self-supervised refinement strategy to mitigate the scarcity of paired real-world data. Trained only on unlabeled real-world image pairs and paired with a dense, pixel-aligned visual prior, ALI achieves strong improvements in relighting, with the largest gains on complex, specular materials. Project page: https:\\\\augmented-latent-intrinsics.github.io", "AI": {"tldr": "本文研究了图像到图像的再照明任务中，更强的预训练视觉先验是否能改善表现，并提出了一种结合像素对齐视觉编码器和自监督细化策略的方法Augmented Latent Intrinsics (ALI)，以平衡语义上下文与密集光度结构。", "motivation": "当前方法在处理金属、玻璃等复杂材料时，再照明效果不佳。更强的预训练视觉先验能否解决这些问题成为研究动机。", "method": "本文通过融合像素对齐的视觉编码器和自监督细化策略到隐式内在框架中，引入了Augmented Latent Intrinsics (ALI) 方法，并仅使用未标记的真实世界图像对进行训练。", "result": "实验结果表明，相比其他方法，ALI在复杂、镜面反射材料上的再照明表现有了显著提升。", "conclusion": "本文揭示了语义抽象和光度保真度之间的基本权衡，提出的新方法能够更好地平衡两者，并取得较好的再照明效果。"}}
{"id": "2602.01390", "pdf": "https://arxiv.org/pdf/2602.01390", "abs": "https://arxiv.org/abs/2602.01390", "authors": ["Lana Do", "Gio Jung", "Juvenal Francisco Barajas", "Andrew Taylor Scott", "Shasta Ihorn", "Alexander Mario Blum", "Vassilis Athitsos", "Ilmi Yoon"], "title": "How well can VLMs rate audio descriptions: A multi-dimensional quantitative assessment framework", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Digital video is central to communication, education, and entertainment, but without audio description (AD), blind and low-vision audiences are excluded. While crowdsourced platforms and vision-language-models (VLMs) expand AD production, quality is rarely checked systematically. Existing evaluations rely on NLP metrics and short-clip guidelines, leaving questions about what constitutes quality for full-length content and how to assess it at scale. To address these questions, we first developed a multi-dimensional assessment framework for uninterrupted, full-length video, grounded in professional guidelines and refined by accessibility specialists. Second, we integrated this framework into a comprehensive methodological workflow, utilizing Item Response Theory, to assess the proficiency of VLM and human raters against expert-established ground truth. Findings suggest that while VLMs can approximate ground-truth ratings with high alignment, their reasoning was found to be less reliable and actionable than that of human respondents. These insights show the potential of hybrid evaluation systems that leverage VLMs alongside human oversight, offering a path towards scalable AD quality control.", "AI": {"tldr": "开发了一个多维度评估框架，用于评价视觉语言模型（VLM）和人类评价者在长视频音频描述中的表现。", "motivation": "现有对音频描述质量的评估方法有限，缺乏系统性。为了解决这一问题并探索如何大规模地控制音频描述的质量，提出了一个新的评估框架。", "method": "开发了一个基于专业指南和无障碍专家反馈的多维度评估框架，并通过项目反应理论将该框架整合到一个全面的方法论工作流程中，用于评价视觉语言模型（VLM）与人类评价者的表现。", "result": "研究发现，虽然VLM能够接近专家建立的真实基准线进行评分，但其推理过程不如人类评价者的可靠和可行。", "conclusion": "这些结果表明了利用混合评估系统结合使用VLM和人工监督来实现大规模音频描述质量控制的潜力。"}}
{"id": "2602.01389", "pdf": "https://arxiv.org/pdf/2602.01389", "abs": "https://arxiv.org/abs/2602.01389", "authors": ["Michele Antonazzi", "Lorenzo Signorelli", "Matteo Luperto", "Nicola Basilico"], "title": "Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation", "categories": ["cs.RO"], "comment": "Accepted for publication at ICRA 2026", "summary": "Semantic segmentation networks, which are essential for robotic perception, often suffer from performance degradation when the visual distribution of the deployment environment differs from that of the source dataset on which they were trained. Unsupervised Domain Adaptation (UDA) addresses this challenge by adapting the network to the robot's target environment without external supervision, leveraging the large amounts of data a robot might naturally collect during long-term operation. In such settings, UDA methods can exploit multi-view consistency across the environment's map to fine-tune the model in an unsupervised fashion and mitigate domain shift. However, these approaches remain sensitive to cross-view instance-level inconsistencies. In this work, we propose a method that starts from a volumetric 3D map to generate multi-view consistent pseudo-labels. We then refine these labels using the zero-shot instance segmentation capabilities of a foundation model, enforcing instance-level coherence. The refined annotations serve as supervision for self-supervised fine-tuning, enabling the robot to adapt its perception system at deployment time. Experiments on real-world data demonstrate that our approach consistently improves performance over state-of-the-art UDA baselines based on multi-view consistency, without requiring any ground-truth labels in the target domain.", "AI": {"tldr": "本文提出了一种基于体积3D地图生成多视图一致伪标签的方法，并利用零样本实例分割模型进行细化，以适应机器人感知系统。", "motivation": "语义分割网络在不同视觉分布的环境部署中性能会下降。无监督领域自适应方法通过利用机器人收集的数据来解决这个问题，但仍然对跨视图实例级不一致敏感。", "method": "从体积3D地图生成多视图一致伪标签，并使用零样本实例分割模型进行细化，然后将这些优化后的注释用作自我监督微调的监督。", "result": "实验表明，该方法在真实数据上比基于多视图一致性的方法有更优的表现，且无需目标域的真实标签。", "conclusion": "所提出的方法通过利用零样本实例分割模型进行细化伪标签，有效改善了语义分割网络在新环境下的适应能力。"}}
{"id": "2602.01387", "pdf": "https://arxiv.org/pdf/2602.01387", "abs": "https://arxiv.org/abs/2602.01387", "authors": ["Ziwen Li", "Ziang Xiao", "Tianshi Li"], "title": "Disclose with Care: Designing Privacy Controls in Interview Chatbots", "categories": ["cs.HC"], "comment": "25 pages, 14 figures", "summary": "Collecting data on sensitive topics remains challenging in HCI, as participants often withhold information due to privacy concerns and social desirability bias. While chatbots' perceived anonymity may reduce these barriers, research paradoxically suggests people tend to over-share personal or sensitive information with chatbots. In this work, we explore privacy controls in chatbot interviews to address this problem. The privacy control allows participants to revise their transcripts at the end of the interview, featuring two design variants: free editing and AI-aided editing. In a between-subjects study \\red{($N=188$)}, we compared no-editing, free-editing, and AI-aided editing conditions in a chatbot-based interview on a sensitive topic. Our results confirm the prevalent issue of oversharing in chatbot-based interviews and show that AI-aided editing serves as an effective privacy-control mechanism, reducing PII disclosure while maintaining data quality and user engagement, thereby offering a promising approach to balancing ethical practice and data quality in such interviews.", "AI": {"tldr": "研究设计了隐私控制机制以解决在基于聊天机器人的访谈中参与者过度分享个人信息的问题。", "motivation": "在HCI领域，收集敏感信息仍然具有挑战性。虽然聊天机器人提供的匿名感可能会减少隐私担忧和社会期望偏差，但研究表明人们倾向于与聊天机器人过度分享个人或敏感信息。研究旨在探索如何设计有效的隐私控制机制来解决这一问题。", "method": "采用两组不同的隐私编辑功能（自由编辑和AI辅助编辑），在188名参与者中进行了基于聊天机器人的访谈，并比较了不进行编辑、自由编辑以及AI辅助编辑条件下的效果。", "result": "研究结果证实了在基于聊天机器人的访谈中过度分享个人信息的问题普遍存在，同时表明AI辅助编辑可以有效减少个人身份信息的披露，同时保持数据质量和用户参与度。", "conclusion": "通过引入隐私控制机制（尤其是AI辅助编辑），可以在保护参与者隐私的同时提高数据质量，为解决这一矛盾提供了一种有希望的方法。"}}
{"id": "2602.01386", "pdf": "https://arxiv.org/pdf/2602.01386", "abs": "https://arxiv.org/abs/2602.01386", "authors": ["Qing", "Xia", "Marios Constantinides", "Advait Sarkar", "Duncan Brumby", "Anna Cox"], "title": "\"If You're Very Clever, No One Knows You've Used It\": The Social Dynamics of Developing Generative AI Literacy in the Workplace", "categories": ["cs.HC", "cs.AI"], "comment": "CHIWORK 2026", "summary": "Generative AI (GenAI) tools are rapidly transforming knowledge work, making AI literacy a critical priority for organizations. However, research on AI literacy lacks empirical insight into how knowledge workers' beliefs around GenAI literacy are shaped by the social dynamics of the workplace, and how workers learn to apply GenAI tools in these environments. To address this gap, we conducted in-depth interviews with 19 knowledge workers across multiple sectors to examine how they develop GenAI competencies in real-world professional contexts. We found that, while knowledge sharing from colleagues supported learning, the ability to remove cues indicating GenAI use was perceived as validation of domain expertise. These behaviours ultimately reduced opportunities for learning via knowledge sharing and undermined transparency. To advance workplace AI literacy, we argue for fostering open dialogue, increasing visibility of user-generated knowledge, and greater emphasis on the benefits of collaborative learning for navigating rapid technological developments.", "AI": {"tldr": "探讨了知识工作者在职场中如何发展生成式人工智能（GenAI）素养，并揭示了其背后的社交动态。", "motivation": "研究缺乏关于知识工作者的信念是如何受到工作场所社会动态影响，以及他们如何学习应用GenAI工具的具体经验性见解。为了填补这一空白，作者进行了深入访谈以探讨这个问题。", "method": "通过与多个行业的19位知识工作者进行深入访谈来探究他们在实际专业环境中如何发展GenAI技能。", "result": "研究发现同事之间的知识分享支持了学习过程，但是能够移除显示使用GenAI工具的线索被认为是领域专业知识的证明。这些行为实际上减少了通过知识共享的学习机会，并且损害了透明度。", "conclusion": "为了提高工作场所中的AI素养，作者建议促进开放对话、增加用户生成知识的可见性以及更加重视协作学习带来的好处，以应对快速的技术发展。"}}
{"id": "2602.01385", "pdf": "https://arxiv.org/pdf/2602.01385", "abs": "https://arxiv.org/abs/2602.01385", "authors": ["Xiangyu Li", "Mingwei Lai", "Mengke Zhang", "Junxiao Lin", "Tiancheng Lai", "Junping Zhi", "Chao Xu", "Fei Gao", "Yanjun Cao"], "title": "TriphiBot: A Triphibious Robot Combining FOC-based Propulsion with Eccentric Design", "categories": ["cs.RO"], "comment": null, "summary": "Triphibious robots capable of multi-domain motion and cross-domain transitions are promising to handle complex tasks across diverse environments. However, existing designs primarily focus on dual-mode platforms, and some designs suffer from high mechanical complexity or low propulsion efficiency, which limits their application. In this paper, we propose a novel triphibious robot capable of aerial, terrestrial, and aquatic motion, by a minimalist design combining a quadcopter structure with two passive wheels, without extra actuators. To address inefficiency of ground-support motion (moving on land/seabed) for quadcopter based designs, we introduce an eccentric Center of Gravity (CoG) design that inherently aligns thrust with motion, enhancing efficiency without specialized mechanical transformation designs. Furthermore, to address the drastic differences in motion control caused by different fluids (air and water), we develop a unified propulsion system based on Field-Oriented Control (FOC). This method resolves torque matching issues and enables precise, rapid bidirectional thrust across different mediums. Grounded in the perspective of living condition and ground support, we analyse the robot's dynamics and propose a Hybrid Nonlinear Model Predictive Control (HNMPC)-PID control system to ensure stable multi-domain motion and seamless transitions. Experimental results validate the robot's multi-domain motion and cross-mode transition capability, along with the efficiency and adaptability of the proposed propulsion system.", "AI": {"tldr": "本文提出了一种新型三栖机器人，能够实现空中、陆地和水下的运动，并通过统一的基于磁场定向控制的推进系统解决了不同环境中的动力问题。", "motivation": "现有设计主要集中在双模式平台，一些设计存在机械复杂性高或推力效率低的问题，限制了应用。本文旨在开发一种新型三栖机器人以解决这些问题。", "method": "通过结合四旋翼结构和两个被动轮的极简设计，并引入偏心重心设计来提高地面支持运动的效率；基于磁场定向控制技术开发统一推进系统处理不同流体中的动力问题，使用混合非线性模型预测控制PID控制系统确保多域运动稳定性和跨模式过渡。", "result": "实验结果验证了机器人在多个环境中的运动能力和跨模式转换能力，并展示了所提出的推进系统的效率和适应性。", "conclusion": "提出了一种新型三栖机器人，通过结合创新设计和统一的推进系统解决了多领域运动和无缝过渡的问题。"}}
{"id": "2602.01382", "pdf": "https://arxiv.org/pdf/2602.01382", "abs": "https://arxiv.org/abs/2602.01382", "authors": ["Fu-Yun Wang", "Han Zhang", "Michael Gharbi", "Hongsheng Li", "Taesung Park"], "title": "PromptRL: Prompt Matters in RL for Flow-Based Image Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Flow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as a critical post-training strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting, where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), a framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, a synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval, 0.98 on OCR accuracy, and 24.05 on PickScore. Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with a complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2$\\times$ fewer rollouts compared to naive flow-only RL. Our code is available at https://github.com/G-U-N/UniRL.", "AI": {"tldr": "PromptRL是一种利用语言模型改进流式生成图像的强化学习框架，提高了文本到图像生成的质量和多样性。", "motivation": "当前基于强化学习的流式模型在文本到图像生成中存在样本效率低和提示过拟合的问题。PromptRL旨在解决这些问题并提升生成效果。", "method": "将语言模型作为可训练的提示优化代理引入到流式的强化学习循环中，改进了提示多样性，并提高了生成能力。", "result": "PromptRL在多个评估指标上表现优异，在GenEval、OCR准确率和PickScore上均达到或接近最佳结果。通过较少的迭代次数取得了显著效果提升。", "conclusion": "PromptRL框架有效改善了流式模型的强化学习过程，提高了文本到图像生成任务中的性能上限，并减少了所需的采样数量。"}}
{"id": "2602.01378", "pdf": "https://arxiv.org/pdf/2602.01378", "abs": "https://arxiv.org/abs/2602.01378", "authors": ["Poushali Sengupta", "Shashi Raj Pandey", "Sabita Maharjan", "Frank Eliassen"], "title": "Context Dependence and Reliability in Autoregressive Language Models", "categories": ["cs.CL", "cs.AI", "stat.ML"], "comment": null, "summary": "Large language models (LLMs) generate outputs by utilizing extensive context, which often includes redundant information from prompts, retrieved passages, and interaction history. In critical applications, it is vital to identify which context elements actually influence the output, as standard explanation methods struggle with redundancy and overlapping context. Minor changes in input can lead to unpredictable shifts in attribution scores, undermining interpretability and raising concerns about risks like prompt injection. This work addresses the challenge of distinguishing essential context elements from correlated ones. We introduce RISE (Redundancy-Insensitive Scoring of Explanation), a method that quantifies the unique influence of each input relative to others, minimizing the impact of redundancies and providing clearer, stable attributions. Experiments demonstrate that RISE offers more robust explanations than traditional methods, emphasizing the importance of conditional information for trustworthy LLM explanations and monitoring.", "AI": {"tldr": "大语言模型通过利用广泛的背景信息生成输出，但标准解释方法难以区分关键和冗余的输入。RISE是一种量化每个输入独特影响的方法，以提供更清晰稳定的归因。", "motivation": "在重要应用中，识别哪些背景元素实际影响输出至关重要，因为标准解释方法对冗余和重叠背景处理不佳。微小的输入变化会导致不可预测的归因分数变动，这损害了可解释性并引发了诸如提示注入等风险。", "method": "RISE通过最小化冗余的影响来量化每个输入的独特作用，并提供更清晰稳定的归因。", "result": "实验表明，与传统方法相比，RISE提供了更为稳健的解释，并强调条件信息对可信的大语言模型解释和监控的重要性。", "conclusion": "RISE在识别背景元素影响方面表现出色，为大语言模型的可靠性和可解释性提供了重要的工具。"}}
{"id": "2602.01370", "pdf": "https://arxiv.org/pdf/2602.01370", "abs": "https://arxiv.org/abs/2602.01370", "authors": ["Leonardo Brusini", "Cristian Sbrolli", "Eugenio Lomurno", "Toshihiko Yamasaki", "Matteo Matteucci"], "title": "PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Synthetic data offers a scalable solution for vision-language pre-training, yet current state-of-the-art methods typically rely on scaling up a single generative backbone, which introduces generator-specific spectral biases and limits feature diversity. In this work, we introduce PolyGen, a framework that redefines synthetic data construction by prioritizing manifold coverage and compositional rigor over simple dataset size. PolyGen employs a Polylithic approach to train on the intersection of architecturally distinct generators, effectively marginalizing out model-specific artifacts. Additionally, we introduce a Programmatic Hard Negative curriculum that enforces fine-grained syntactic understanding. By structurally reallocating the same data budget from unique captions to multi-source variations, PolyGen achieves a more robust feature space, outperforming the leading single-source baseline (SynthCLIP) by +19.0% on aggregate multi-task benchmarks and on the SugarCrepe++ compositionality benchmark (+9.1%). These results demonstrate that structural diversity is a more data-efficient scaling law than simply increasing the volume of single-source samples.", "AI": {"tldr": "提出了一种新的框架PolyGen，用于通过多种生成器的集合训练来构建合成视觉语言数据。", "motivation": "当前最先进的方法通常依赖于单个生成模型进行扩展，这导致了特定生成器的频谱偏差和特征多样性限制。因此，作者希望通过结构多样性的提高实现更高效的数据利用。", "method": "PolyGen采用多源生成器集合的方法来训练数据集，旨在通过架构不同的生成器之间的交集来消除模型特有的偏见，并引入了一种程序化硬负样本课程以强制执行细粒度的句法理解。与单源基线相比，这种方法能够更有效地利用有限的数据。", "result": "在多任务基准测试中，PolyGen的表现比领先的单源基准（SynthCLIP）高出19.0％，并且在SugarCrepe++构型性基准上表现出色（+9.1%）。", "conclusion": "研究结果表明，通过结构多样性实现的特征空间更加强健和有效，相较于简单地增加单一来源样本的数量更为高效。"}}
{"id": "2602.01369", "pdf": "https://arxiv.org/pdf/2602.01369", "abs": "https://arxiv.org/abs/2602.01369", "authors": ["Songping Wang", "Qinglong Liu", "Yueming Lyu", "Ning Li", "Ziwen He", "Caifeng Shan"], "title": "Exposing and Defending the Achilles' Heel of Video Mixture-of-Experts", "categories": ["cs.CV"], "comment": null, "summary": "Mixture-of-Experts (MoE) has demonstrated strong performance in video understanding tasks, yet its adversarial robustness remains underexplored. Existing attack methods often treat MoE as a unified architecture, overlooking the independent and collaborative weaknesses of key components such as routers and expert modules. To fill this gap, we propose Temporal Lipschitz-Guided Attacks (TLGA) to thoroughly investigate component-level vulnerabilities in video MoE models. We first design attacks on the router, revealing its independent weaknesses. Building on this, we introduce Joint Temporal Lipschitz-Guided Attacks (J-TLGA), which collaboratively perturb both routers and experts. This joint attack significantly amplifies adversarial effects and exposes the Achilles' Heel (collaborative weaknesses) of the MoE architecture. Based on these insights, we further propose Joint Temporal Lipschitz Adversarial Training (J-TLAT). J-TLAT performs joint training to further defend against collaborative weaknesses, enhancing component-wise robustness. Our framework is plug-and-play and reduces inference cost by more than 60% compared with dense models. It consistently enhances adversarial robustness across diverse datasets and architectures, effectively mitigating both the independent and collaborative weaknesses of MoE.", "AI": {"tldr": "研究提出针对视频混合专家模型的新型攻击方法及防御策略，揭示其独立和协同弱点。", "motivation": "现有对MoE架构的安全性探索不足，忽视了路由器和专家模块之间的独立与协作脆弱性。本文旨在填补这一空白，并通过设计特定的攻击来提高防御能力。", "method": "提出Temporal Lipschitz-Guided Attacks (TLGA) 和 Joint Temporal Lipschitz-Guided Attacks (J-TLGA)，针对视频MoE模型的不同组件进行攻击，进一步开发了Joint Temporal Lipschitz Adversarial Training (J-TLAT) 来提升模型的鲁棒性。", "result": "实验结果表明提出的框架能够有效地揭示和减轻MoE架构中的独立及协同脆弱性，并显著增强了对抗防御能力。", "conclusion": "通过深入研究视频混合专家模型的弱点，开发出有效的攻击与防御方法，既减少了推理成本也提升了整体安全性。"}}
{"id": "2602.01368", "pdf": "https://arxiv.org/pdf/2602.01368", "abs": "https://arxiv.org/abs/2602.01368", "authors": ["Patricia Marcella Evite", "Ekaterina Svetlova", "Doina Bucur"], "title": "Trade-offs in Financial AI: Explainability in a Trilemma with Accuracy and Compliance", "categories": ["cs.HC"], "comment": "21 pages, 5 figures. Submitted to EUM (Edizioni Università di Macerata) series \"Economics and Law\", Special Issue: \"Emerging Trends in FinTech and AI: Theory and Applications in Business, Economics, and Law\"", "summary": "As Artificial Intelligence (AI) becomes increasingly embedded in financial decision-making, the opacity of complex models presents significant challenges for professionals and regulators. While the field of Explainable AI (XAI) attempts to bridge this gap, current research often reduces the implementation challenge to a binary trade-off between model accuracy and explainability. This paper argues that such a view is insufficient for the financial domain, where algorithmic choices must navigate a complex sociotechnical web of strict regulatory bounds, budget constraints, and latency requirements. Through semi-structured interviews with twenty finance professionals, ranging from C-suite executives and developers to regulators across multiple regions, this study empirically investigates how practitioners prioritize explainability relative to four competing factors: accuracy, compliance, cost, and speed. Our findings reveal that these priorities are structured not as a simple trade-off, but as a system of distinct prerequisites and constraints. Accuracy and compliance emerge as non-negotiable \"hygiene factors\": without them, an AI system is viewed as a liability regardless of its transparency. Operational levers (speed and cost) serve as secondary constraints that determine practical feasibility, while ease of understanding functions as a gateway to adoption, shaping whether AI tools are trusted, used, and defensible in practice.", "AI": {"tldr": "本文研究了金融AI中准确性、合规性、成本和速度之间的权衡，探讨了可解释性的角色。", "motivation": "在金融决策过程中，复杂模型的不透明度带来了挑战。传统的XAI方法将准确性和可解释性视为二元对立关系，不足以应对严格的监管环境和其他限制条件。", "method": "通过与二十位来自不同区域和职位的金融专业人士进行半结构化访谈，研究了他们在准确性、合规性、成本和速度方面的优先级。", "result": "发现这些因素之间存在复杂的相互依赖关系。准确性和合规性被视为必需的前提条件，而速度和成本作为次要约束影响实施可行性。", "conclusion": "可解释性的实际价值取决于其是否能确保AI系统的可信度与实用性，在满足基本要求的前提下提高采纳率。"}}
{"id": "2602.01367", "pdf": "https://arxiv.org/pdf/2602.01367", "abs": "https://arxiv.org/abs/2602.01367", "authors": ["Pinar Erbil", "Alberto Archetti", "Eugenio Lomurno", "Matteo Matteucci"], "title": "Deep Variational Contrastive Learning for Joint Risk Stratification and Time-to-Event Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Survival analysis is essential for clinical decision-making, as it allows practitioners to estimate time-to-event outcomes, stratify patient risk profiles, and guide treatment planning. Deep learning has revolutionized this field with unprecedented predictive capabilities but faces a fundamental trade-off between performance and interpretability. While neural networks achieve high accuracy, their black-box nature limits clinical adoption. Conversely, deep clustering-based methods that stratify patients into interpretable risk groups typically sacrifice predictive power. We propose CONVERSE (CONtrastive Variational Ensemble for Risk Stratification and Estimation), a deep survival model that bridges this gap by unifying variational autoencoders with contrastive learning for interpretable risk stratification. CONVERSE combines variational embeddings with multiple intra- and inter-cluster contrastive losses. Self-paced learning progressively incorporates samples from easy to hard, improving training stability. The model supports cluster-specific survival heads, enabling accurate ensemble predictions. Comprehensive evaluation on four benchmark datasets demonstrates that CONVERSE achieves competitive or superior performance compared to existing deep survival methods, while maintaining meaningful patient stratification.", "AI": {"tldr": "提出了一种名为CONVERSE的深度生存模型，该模型结合了变分自编码器和对比学习以实现可解释的风险分类同时保持预测准确性。", "motivation": "解决传统神经网络准确度高但不透明以及基于聚类的方法可解释性强但牺牲预测能力的问题。", "method": "CONVERSE结合了变分嵌入、多种内集群和跨集群的对比损失，采用自适应学习逐步纳入样本以提高训练稳定性，并支持特定于群组的风险估计头，从而实现精确的集成预测。", "result": "在四个基准数据集上评估显示，与现有深度生存模型相比，CONVERSE取得了竞争性或更优的结果，同时保持了有意义的患者分层。", "conclusion": "CONVERSE通过将变分自编码器和对比学习相结合，不仅实现了准确的风险估计，还提供了可解释的风险分类。"}}
{"id": "2602.01365", "pdf": "https://arxiv.org/pdf/2602.01365", "abs": "https://arxiv.org/abs/2602.01365", "authors": ["Wang Yang", "Shouren Wang", "Chaoda Song", "Chuang Ma", "Xinpeng Li", "Nengbo Wang", "Kaixiong Zhou", "Vipin Chaudhary", "Xiaotian Han"], "title": "When Domains Interact: Asymmetric and Order-Sensitive Cross-Domain Effects in Reinforcement Learning for Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has become a key technique for improving reasoning abilities in large language models, yet its behavior under different domain sequencing strategies is poorly understood. In particular, the impact of sequential (one domain at a time) versus mixed-domain (multiple domain at a time) training in GRPO has not been systematically studied. We provide the first systematic analysis of training-order effects across math, science, logic, and puzzle reasoning tasks. We found (1) single-domain generalization is highly asymmetric: training on other domains improves math reasoning by approximately 25\\% accuracy, while yielding negligible transfer to logic and puzzle; (2) cross-domain interactions are highly order-dependent: training in the order math$\\rightarrow$science achieves 83\\% / 41\\% accuracy on math / science, while reversing the order to science$\\rightarrow$math degrades performance to 77\\% / 25\\%; (3) no single strategy is universally optimal in multi-domain training: sequential training favors math (up to 84\\%), mixed training favors science and logic, and poor ordering can incur large performance gaps (from 70\\% to 56\\%). Overall, our findings demonstrate that GRPO under multi-domain settings exhibits pronounced asymmetry, order sensitivity, and strategy dependence, highlighting the necessity of domain-aware and order-aware training design.", "AI": {"tldr": "该论文分析了在不同领域顺序训练策略下，Group Relative Policy Optimization (GRPO) 在多个领域的表现。", "motivation": "当前对GRPO技术在不同的领域顺序策略下的行为研究不足，尤其是单域训练与跨域混合训练之间的差异。因此需要系统地研究其效果，以优化模型的推理能力。", "method": "论文通过数学、科学、逻辑和谜题四个领域的任务进行实验分析，探究了单一领域训练以及不同顺序交叉训练的影响。", "result": "该研究表明：1. 单一领域泛化具有高度不对称性；2. 跨域交互表现出高度的序依赖性；3. 没有任何一种策略在多域训练中是普遍最优的。", "conclusion": "GRPO技术在多重领域的应用展示了显著的不对称性、顺序敏感性和策略依赖性，强调了领域意识和顺序感知训练设计的重要性。"}}
{"id": "2602.01363", "pdf": "https://arxiv.org/pdf/2602.01363", "abs": "https://arxiv.org/abs/2602.01363", "authors": ["Mariëtte Olijslager", "Seyed Sahand Mohammadi Ziabari", "Ali Mohammed Mansoor Alsahag"], "title": "Causally Disentangled Contrastive Learning for Multilingual Speaker Embeddings", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Self-supervised speaker embeddings are widely used in speaker verification systems, but prior work has shown that they often encode sensitive demographic attributes, raising fairness and privacy concerns. This paper investigates the extent to which demographic information, specifically gender, age, and accent, is present in SimCLR-trained speaker embeddings and whether such leakage can be mitigated without severely degrading speaker verification performance. We study two debiasing strategies: adversarial training through gradient reversal and a causal bottleneck architecture that explicitly separates demographic and residual information. Demographic leakage is quantified using both linear and nonlinear probing classifiers, while speaker verification performance is evaluated using ROC-AUC and EER. Our results show that gender information is strongly and linearly encoded in baseline embeddings, whereas age and accent are weaker and primarily nonlinearly represented. Adversarial debiasing reduces gender leakage but has limited effect on age and accent and introduces a clear trade-off with verification accuracy. The causal bottleneck further suppresses demographic information, particularly in the residual representation, but incurs substantial performance degradation. These findings highlight fundamental limitations in mitigating demographic leakage in self-supervised speaker embeddings and clarify the trade-offs inherent in current debiasing approaches.", "AI": {"tldr": "研究如何减少多语言语音嵌入中的性别、年龄和口音等敏感信息，同时保持良好的说话人验证性能。", "motivation": "自我监督学习的说话者嵌入在说话人验证系统中被广泛应用，但之前的工作显示它们经常包含敏感的人口统计学属性，引发了公平性和隐私性的问题。研究旨在量化这些嵌入中的性别、年龄和口音等人口统计信息，并探索如何减轻泄漏。", "method": "通过反向梯度训练的对抗学习方法以及因果瓶颈架构来减轻敏感信息的泄露。使用线性和非线性的探针分类器量化人口统计信息，评估说话人验证性能时采用ROC-AUC和EER。", "result": "基线嵌入中性别信息强烈且线性地编码，而年龄和口音则较弱并且主要以非线性方式表示。对抗去偏减轻了性别泄漏但对年龄和口音的影响较小，并引入了清晰的准确性权衡；因果瓶颈进一步抑制人口统计信息，特别是在剩余表征中，但性能有所下降。", "conclusion": "研究揭示了在自我监督说话者嵌入中缓解人口统计泄漏的基本限制，阐明了当前去偏方法中存在的固有折衷。"}}
{"id": "2602.01359", "pdf": "https://arxiv.org/pdf/2602.01359", "abs": "https://arxiv.org/abs/2602.01359", "authors": ["Jinju Park", "Seokho Kang"], "title": "PaAno: Patch-Based Representation Learning for Time-Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by the 14th International Conference on Learning Representations (ICLR 2026)", "summary": "Although recent studies on time-series anomaly detection have increasingly adopted ever-larger neural network architectures such as transformers and foundation models, they incur high computational costs and memory usage, making them impractical for real-time and resource-constrained scenarios. Moreover, they often fail to demonstrate significant performance gains over simpler methods under rigorous evaluation protocols. In this study, we propose Patch-based representation learning for time-series Anomaly detection (PaAno), a lightweight yet effective method for fast and efficient time-series anomaly detection. PaAno extracts short temporal patches from time-series training data and uses a 1D convolutional neural network to embed each patch into a vector representation. The model is trained using a combination of triplet loss and pretext loss to ensure the embeddings capture informative temporal patterns from input patches. During inference, the anomaly score at each time step is computed by comparing the embeddings of its surrounding patches to those of normal patches extracted from the training time-series. Evaluated on the TSB-AD benchmark, PaAno achieved state-of-the-art performance, significantly outperforming existing methods, including those based on heavy architectures, on both univariate and multivariate time-series anomaly detection across various range-wise and point-wise performance measures.", "AI": {"tldr": "提出了一种基于补丁的轻量级时间序列异常检测方法PaAno。", "motivation": "现有的深度学习模型虽然在时间序列异常检测中表现出色，但其计算成本和内存占用高，在实际场景应用受限。因此开发一种高效且有效的解决方案至关重要。", "method": "该研究利用1D卷积神经网络从时间序列数据中提取短时补丁，并通过三元组损失和预文本损失训练模型以捕捉输入补丁中的信息性时空模式，从而在推理阶段计算异常分数。", "result": "PaAno在TSB-AD基准测试上实现了最先进的性能，在一维和多维时间序列异常检测中均优于现有方法。", "conclusion": "该研究证明了Patch-based方法在时间和资源受限的场景下是有效的，同时展示了其卓越的性能表现。"}}
{"id": "2602.01358", "pdf": "https://arxiv.org/pdf/2602.01358", "abs": "https://arxiv.org/abs/2602.01358", "authors": ["Abril Azocar Guzman", "Hoang-Thien Luu", "Sarath Menon", "Tilmann Hickel", "Nina Merkert", "Stefan Sandfeld"], "title": "Towards knowledge-based workflows: a semantic approach to atomistic simulations for mechanical and thermodynamic properties", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.SE"], "comment": null, "summary": "Mechanical and thermodynamic properties, including the influence of crystal defects, are critical for evaluating materials in engineering applications. Molecular dynamics simulations provide valuable insight into these mechanisms at the atomic scale. However, current practice often relies on fragmented scripts with inconsistent metadata and limited provenance, which hinders reproducibility, interoperability, and reuse. FAIR data principles and workflow-based approaches offer a path to address these limitations. We present reusable atomistic workflows that incorporate metadata annotation aligned with application ontologies, enabling automatic provenance capture and FAIR-compliant data outputs. The workflows cover key mechanical and thermodynamic quantities, including equation of state, elastic tensors, mechanical loading, thermal properties, defect formation energies, and nanoindentation. We demonstrate validation of structure-property relations such as the Hall-Petch effect and show that the workflows can be reused across different interatomic potentials and materials within a coherent semantic framework. The approach provides AI-ready simulation data, supports emerging agentic AI workflows, and establishes a generalizable blueprint for knowledge-based mechanical and thermodynamic simulations.", "AI": {"tldr": "本文提出了基于语义的原子模拟工作流，以提高材料机械和热力学性质研究中的可重复性、互操作性和再利用性。", "motivation": "当前的分子动力学模拟依赖于碎片化的脚本，缺乏一致的元数据和有限的出处信息，这阻碍了结果的重复验证。为此，本文通过引入FAIR数据原则和工作流方法来改进这一状况。", "method": "该研究开发了一套可重用的工作流，这些工作流包含与应用领域相关的元数据标注，并能够自动捕捉过程出处，生成符合FAIR标准的数据输出。具体涵盖了材料的机械和热力学特性等。", "result": "通过验证诸如Hall-Petch效应的关系展示了结构-性能关系的有效性；同时证明了该方法在不同原子间势函数和材料上的可重用性和通用性。", "conclusion": "所提出的方法不仅促进了AI准备的数据生成，也支持了新兴的代理式人工智能工作流，并为基于知识的机械和热力学模拟提供了普遍适用的蓝图。"}}
{"id": "2602.01355", "pdf": "https://arxiv.org/pdf/2602.01355", "abs": "https://arxiv.org/abs/2602.01355", "authors": ["Haojia Zhu", "Qinyuan Xu", "Haoyu Li", "Yuxi Liu", "Hanchen Qiu", "Jiaoyan Chen", "Jiahui Jin"], "title": "Aggregation Queries over Unstructured Text: Benchmark and Agentic Method", "categories": ["cs.AI"], "comment": null, "summary": "Aggregation query over free text is a long-standing yet underexplored problem. Unlike ordinary question answering, aggregate queries require exhaustive evidence collection and systems are required to \"find all,\" not merely \"find one.\" Existing paradigms such as Text-to-SQL and Retrieval-Augmented Generation fail to achieve this completeness. In this work, we formalize entity-level aggregation querying over text in a corpus-bounded setting with strict completeness requirement. To enable principled evaluation, we introduce AGGBench, a benchmark designed to evaluate completeness-oriented aggregation under realistic large-scale corpus. To accompany the benchmark, we propose DFA (Disambiguation--Filtering--Aggregation), a modular agentic baseline that decomposes aggregation querying into interpretable stages and exposes key failure modes related to ambiguity, filtering, and aggregation. Empirical results show that DFA consistently improves aggregation evidence coverage over strong RAG and agentic baselines. The data and code are available in \\href{https://anonymous.4open.science/r/DFA-A4C1}.", "AI": {"tldr": "本文研究了在文本语料库中进行聚合查询的问题，提出了一个基准测试AGGBench和一种新的方法DFA来解决这一问题。", "motivation": "现有技术如Text-to-SQL和Retrieval-Augmented Generation无法满足全面的证据收集要求。为了解决这个问题，本文提出了一个新的基准测试和方法，以提高聚合查询的准确性。", "method": "作者提出了一种新的方法DFA（Disambiguation--Filtering--Aggregation），该方法将聚合查询分解为可解释的阶段，并解决了与歧义、过滤和聚合相关的关键失败模式。", "result": "实验证明，DFA在证据覆盖方面优于强大的RAG和其他代理基线。", "conclusion": "本文提出的基准测试AGGBench以及新方法DFA对于提高文本语料库中的聚合查询准确性具有重要意义。"}}
{"id": "2602.01352", "pdf": "https://arxiv.org/pdf/2602.01352", "abs": "https://arxiv.org/abs/2602.01352", "authors": ["Xingzu Zhan", "Chen Xie", "Honghang Chen", "Yixun Lin", "Xiaochun Mai"], "title": "T2M Mamba: Motion Periodicity-Saliency Coupling Approach for Stable Text-Driven Motion Generation", "categories": ["cs.CV"], "comment": "8 pages,5 figures", "summary": "Text-to-motion generation, which converts motion language descriptions into coherent 3D human motion sequences, has attracted increasing attention in fields, such as avatar animation and humanoid robotic interaction. Though existing models have achieved significant fidelity, they still suffer from two core limitations: (i) They treat motion periodicity and keyframe saliency as independent factors, overlooking their coupling and causing generation drift in long sequences. (ii) They are fragile to semantically equivalent paraphrases, where minor synonym substitutions distort textual embeddings, propagating through the decoder and producing unstable or erroneous motions. In this work, we propose T2M Mamba to address these limitations by (i) proposing Periodicity-Saliency Aware Mamba, which utilizes novel algorithms for keyframe weight estimation via enhanced Density Peaks Clustering and motion periodicity estimation via FFT-accelerated autocorrelation to capture coupled dynamics with minimal computational overhead, and (ii) constructing a Periodic Differential Cross-modal Alignment Module (PDCAM) to enhance robust alignment of textual and motion embeddings. Extensive experiments on HumanML3D and KIT-ML datasets have been conducted, confirming the effectiveness of our approach, achieving an FID of 0.068 and consistent gains on all other metrics.", "AI": {"tldr": "T2M Mamba提出了一种新的文本驱动的三维人体运动生成方法，通过耦合周期性和关键帧重要性来解决现有模型存在的问题。", "motivation": "现有的文本到运动转换模型在长序列中存在漂移和对同义词变化不鲁棒的问题。为了解决这些问题，提出了T2M Mamba方法。", "method": "T2M Mamba通过Density Peaks Clustering和FFT加速的自相关来估计关键帧权重和周期性，并构建了PDCAM模块以增强文本和运动嵌入之间的对齐。", "result": "实验结果表明，该方法在HumanML3D和KIT-ML数据集上取得了显著效果，FID为0.068，在所有其他指标上都有持续改进。", "conclusion": "T2M Mamba通过耦合周期性和关键帧重要性解决了现有模型中的两个主要限制，并且实验结果证明了该方法的有效性。"}}
{"id": "2602.01350", "pdf": "https://arxiv.org/pdf/2602.01350", "abs": "https://arxiv.org/abs/2602.01350", "authors": ["Arnav Khinvasara", "Alexander Pikovski"], "title": "Benchmarking of algorithms for set partitions", "categories": ["cs.DS", "cs.DM", "cs.SE", "math.CO"], "comment": ":05A18; 05A15; 68R05; 90C27ACM Class:F.2; G.2.1; F.2; G.2.2", "summary": "Set partitions are arrangements of distinct objects into groups. The problem of listing all set partitions arises in a variety of settings, in particular in combinatorial optimization tasks. After a brief review, we give practical approximate formulas for determining the number of set partitions, both for small and large set sizes. Several algorithms for enumerating all set partitions are reviewed, and benchmarking tests were conducted. The algorithm of Djokic et al. is recommended for practical use.", "AI": {"tldr": "本文研究了集合划分的所有可能排列算法，并进行了性能评估。", "motivation": "在组合优化任务中，列举所有集合划分数的问题十分常见。为了提供准确的估计方法和高效的解决方案，本论文对相关问题进行了探讨。", "method": "介绍了Djokic等人提出的算法并进行测试对比，同时提供了适用于小规模和大规模集合并行计算的近似公式。", "result": "经过基准测试发现，Djokic等人的算法在处理集合划分任务时表现最优。", "conclusion": "推荐使用Djokic等人的算法解决实际问题中的集合划分挑战。"}}
{"id": "2602.01347", "pdf": "https://arxiv.org/pdf/2602.01347", "abs": "https://arxiv.org/abs/2602.01347", "authors": ["Veith Weilnhammer", "Kevin YC Hou", "Raymond Dolan", "Matthew M Nour"], "title": "Vulnerability-Amplifying Interaction Loops: a systematic failure mode in AI chatbot mental-health interactions", "categories": ["q-bio.NC", "cs.HC"], "comment": null, "summary": "Millions of users turn to consumer AI chatbots to discuss behavioral and mental health concerns. While this presents unprecedented opportunities to deliver population-level support, it also highlights an urgent need to develop rigorous and scalable safety evaluations. Here we introduce SIM-VAIL, an AI chatbot auditing framework that captures how harmful AI chatbot responses manifest across a range of mental-health contexts. SIM-VAIL pairs a simulated human user, harboring a distinct psychiatric vulnerability and conversational intent, with an audited frontier AI chatbot. It scores conversation turns on 13 clinically relevant risk dimensions, enabling context-dependent, temporally resolved assessment of mental-health risk. Across 810 conversations, encompassing over 90,000 turn-level ratings and 30 psychiatric user profiles, we find that significant risk occurs across virtually all user phenotypes. Risk manifested across most of the 9 consumer AI chatbot models audited, albeit mitigated in more modern variants. Rather than arising abruptly, risk accumulated over multiple turns. Risk profiles were phenotype-dependent, indicating that behaviors that appear supportive in general settings are liable to be maladaptive when they align with mechanisms that sustain a user's vulnerability. Multivariate risk patterns revealed trade-offs across dimensions, suggesting that mitigation targeting one harm domain can exacerbate others. These findings identify a novel failure mode in human-AI interactions, which we term Vulnerability-Amplifying Interaction Loops (VAILs), and underscore the need for multi-dimensional approaches to risk quantification. SIM-VAIL provides a scalable evaluation framework for quantifying how mental-health risk is distributed across user phenotypes, conversational trajectories, and clinically grounded behavioral dimensions, offering a foundation for targeted safety improvements.", "AI": {"tldr": "介绍了SIM-VAIL框架，用于评估AI聊天机器人在心理健康互动中的风险。", "motivation": "随着用户越来越多地使用AI聊天机器人来讨论行为和心理问题，迫切需要开发出严谨且可扩展的安全评价方法。", "method": "通过一个模拟人类用户的框架SIM-VAIL与被审计的前沿AI聊天机器人进行交互评估，并对每个对话回合在13个临床相关的风险维度上打分。", "result": "发现几乎所有用户类型中都存在显著的风险，在多个转向中累积，且不同行为在一般环境中可能是支持性的，在特定情境下可能加剧脆弱性。", "conclusion": "揭示了一种新的失败模式——脆弱性放大互动循环（VAILs），强调了多维度风险量化方法的重要性，并提供了一个可扩展的评估框架来衡量心理健康的风险分布。"}}
{"id": "2602.01346", "pdf": "https://arxiv.org/pdf/2602.01346", "abs": "https://arxiv.org/abs/2602.01346", "authors": ["Wei Yang", "Hong Xie", "Tao Tan", "Xin Li", "Defu Lian", "Enhong Chen"], "title": "Model Specific Task Similarity for Vision Language Model Selection via Layer Conductance", "categories": ["cs.AI"], "comment": "Preprint. Under review", "summary": "While open sourced Vision-Language Models (VLMs) have proliferated, selecting the optimal pretrained model for a specific downstream task remains challenging. Exhaustive evaluation is often infeasible due to computational constraints and data limitations in few shot scenarios. Existing selection methods fail to fully address this: they either rely on data-intensive proxies or use symmetric textual descriptors that neglect the inherently directional and model-specific nature of transferability. To address this problem, we propose a framework that grounds model selection in the internal functional dynamics of the visual encoder. Our approach represents each task via layer wise conductance and derives a target-conditioned block importance distribution through entropy regularized alignment. Building on this, we introduce Directional Conductance Divergence (DCD), an asymmetric metric that quantifies how effectively a source task covers the target's salient functional blocks. This allows for predicting target model rankings by aggregating source task ranks without direct inference. Experimental results on 48 VLMs across 21 datasets demonstrate that our method outperforms state-of-the-art baselines, achieving a 14.7% improvement in NDCG@5 over SWAB.", "AI": {"tldr": "该论文提出了一种基于视觉编码器内部功能动态的框架，用于选择特定下游任务的最佳预训练模型。", "motivation": "现有的模型选择方法要么依赖于数据密集型代理，要么使用对齐文本描述符忽略了转移性固有的方向性和模型特异性。为了应对这一问题，提出了一个新的框架来解决这些问题。", "method": "该方法通过层传导表示每个任务，并推导出一个基于熵正则化的目标条件块重要性分布。引入了方向传导差异（DCD）作为一种不对称度量标准，量化源任务如何有效地覆盖目标的突出功能块。", "result": "实验证明，在48个视觉语言模型上进行21个数据集实验后，该方法优于最先进的基准线，NDCG@5提高了14.7％。", "conclusion": "通过内部功能性动态对任务表示和模型选择的新颖框架，该论文提供了一个更准确、有效的选择特定下游任务的最佳预训练视觉语言模型的方法。"}}
{"id": "2602.01345", "pdf": "https://arxiv.org/pdf/2602.01345", "abs": "https://arxiv.org/abs/2602.01345", "authors": ["Yu Zhang", "Jingyi Liu", "Feng Liu", "Duoqian Miao", "Qi Zhang", "Kexue Fu", "Changwei Wang", "Longbing Cao"], "title": "Adaptive Visual Autoregressive Acceleration via Dual-Linkage Entropy Analysis", "categories": ["cs.CV"], "comment": "11 pages, 8 figures", "summary": "Visual AutoRegressive modeling (VAR) suffers from substantial computational cost due to the massive token count involved. Failing to account for the continuous evolution of modeling dynamics, existing VAR token reduction methods face three key limitations: heuristic stage partition, non-adaptive schedules, and limited acceleration scope, thereby leaving significant acceleration potential untapped. Since entropy variation intrinsically reflects the transition of predictive uncertainty, it offers a principled measure to capture modeling dynamics evolution. Therefore, we propose NOVA, a training-free token reduction acceleration framework for VAR models via entropy analysis. NOVA adaptively determines the acceleration activation scale during inference by online identifying the inflection point of scale entropy growth. Through scale-linkage and layer-linkage ratio adjustment, NOVA dynamically computes distinct token reduction ratios for each scale and layer, pruning low-entropy tokens while reusing the cache derived from the residuals at the prior scale to accelerate inference and maintain generation quality. Extensive experiments and analyses validate NOVA as a simple yet effective training-free acceleration framework.", "AI": {"tldr": "提出了一种基于熵分析的视觉自回归模型加速框架NOVA，旨在降低大规模令牌计数导致的计算成本。", "motivation": "现有的VAR令牌减少方法在处理建模动态变化时存在局限性，包括启发式阶段划分、非适应性调度和有限的加速范围，因此需要一种新的方法来捕捉建模动态演变。", "method": "NOVA通过在线识别尺度熵增长的拐点，自适应地确定加速激活规模，并通过比例调整动态计算每个尺度和层的不同令牌减少比率，同时利用前一尺度的残差缓存进行推理加速并保持生成质量。", "result": "实验验证了NOVA作为简单有效的训练自由加速框架的有效性，能够降低令牌数量并提高推断速度，而不牺牲生成质量。", "conclusion": "通过熵分析实现自适应令牌减少和加速，NOVA是一种有效的视觉自回归模型的推理加速方法。"}}
{"id": "2602.01342", "pdf": "https://arxiv.org/pdf/2602.01342", "abs": "https://arxiv.org/abs/2602.01342", "authors": ["Poushali Sengupta", "Mayank Raikwar", "Sabita Maharjan", "Frank Eliassen", "Yan Zhang"], "title": "Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization", "categories": ["cs.CR", "cs.AI", "stat.AP"], "comment": "Accepted for presentation at NDSS 2026 - FutureG Workshop, 23 February 2026. (10 pages, 5 figures.)", "summary": "Powerful quantum computers in the future may be able to break the security used for communication between vehicles and other devices (Vehicle-to-Everything, or V2X). New security methods called post-quantum cryptography can help protect these systems, but they often require more computing power and can slow down communication, posing a challenge for fast 6G vehicle networks. In this paper, we propose an adaptive post-quantum cryptography (PQC) framework that predicts short-term mobility and channel variations and dynamically selects suitable lattice-, code-, or hash-based PQC configurations using a predictive multi-objective evolutionary algorithm (APMOEA) to meet vehicular latency and security constraints.However, frequent cryptographic reconfiguration in dynamic vehicular environments introduces new attack surfaces during algorithm transitions. A secure monotonic-upgrade protocol prevents downgrade, replay, and desynchronization attacks during transitions. Theoretical results show decision stability under bounded prediction error, latency boundedness under mobility drift, and correctness under small forecast noise. These results demonstrate a practical path toward quantum-safe cryptography in future 6G vehicular networks. Through extensive experiments based on realistic mobility (LuST), weather (ERA5), and NR-V2X channel traces, we show that the proposed framework reduces end-to-end latency by up to 27\\%, lowers communication overhead by up to 65\\%, and effectively stabilizes cryptographic switching behavior using reinforcement learning. Moreover, under the evaluated adversarial scenarios, the monotonic-upgrade protocol successfully prevents downgrade, replay, and desynchronization attacks.", "AI": {"tldr": "提出了一种适应性后量子安全加密框架，以在6G车联网中解决由于量子计算带来的安全隐患。", "motivation": "未来的量子计算机可能破坏车辆间的通信安全性。新的后量子加密方法虽然提供了保护，但其复杂性和延迟不符合高速车联网的要求。", "method": "采用预测多目标进化算法（APMOEA）动态选择合适的加密配置以适应移动和通道变化，并使用单调升级协议防止在切换期间的攻击。", "result": "实验结果表明所提框架能够降低最多27%的端到端延迟，减少最多65%的通信开销，同时通过强化学习稳定了加密切换行为。", "conclusion": "该适应性后量子安全加密方法为实现未来的6G车联网中的量子安全性提供了一种实用路径。"}}
{"id": "2602.01340", "pdf": "https://arxiv.org/pdf/2602.01340", "abs": "https://arxiv.org/abs/2602.01340", "authors": ["Yubo Dong", "Linchao Zhu"], "title": "MTC-VAE: Multi-Level Temporal Compression with Content Awareness", "categories": ["cs.CV"], "comment": null, "summary": "Latent Video Diffusion Models (LVDMs) rely on Variational Autoencoders (VAEs) to compress videos into compact latent representations. For continuous Variational Autoencoders (VAEs), achieving higher compression rates is desirable; yet, the efficiency notably declines when extra sampling layers are added without expanding the dimensions of hidden channels. In this paper, we present a technique to convert fixed compression rate VAEs into models that support multi-level temporal compression, providing a straightforward and minimal fine-tuning approach to counteract performance decline at elevated compression rates.Moreover, we examine how varying compression levels impact model performance over video segments with diverse characteristics, offering empirical evidence on the effectiveness of our proposed approach. We also investigate the integration of our multi-level temporal compression VAE with diffusion-based generative models, DiT, highlighting successful concurrent training and compatibility within these frameworks. This investigation illustrates the potential uses of multi-level temporal compression.", "AI": {"tldr": "本文提出了一种将固定压缩率的变分自动编码器（VAE）转换为支持多级时间压缩模型的方法，以提高视频在高压缩率下的性能。", "motivation": "为了改善连续VAE在不增加隐藏通道维度的情况下实现更高压缩率时的效率问题，本文旨在提出一种方法来优化视频压缩过程，并分析不同压缩级别对视频片段的不同影响。", "method": "通过引入多级时间压缩技术并将该技术与基于扩散模型的生成模型结合，本文提出了一个改进的VAE框架，以应对高压缩率下的性能下降问题。此外，还进行了实验以评估所提方法的有效性。", "result": "实验结果表明，所提出的多级时间压缩VAE在不同压缩级别下具有较好的性能，并且与基于扩散模型的生成模型兼容性良好。", "conclusion": "本文展示了通过引入多级时间压缩技术可以改善连续VAE在高压缩率下的效率问题，并为视频压缩领域提供了新的研究方向和解决方案。"}}
{"id": "2602.01335", "pdf": "https://arxiv.org/pdf/2602.01335", "abs": "https://arxiv.org/abs/2602.01335", "authors": ["Yu Xu", "Yuxin Zhang", "Juan Cao", "Lin Gao", "Chunyu Wang", "Oliver Deussen", "Tong-Yee Lee", "Fan Tang"], "title": "Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 10 figures", "summary": "A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the \"creative essence\" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar (\"G\"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic, component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available.", "AI": {"tldr": "本文提出了一种视觉隐喻转移（VMT）任务，通过一种基于认知的多代理框架实现从参考图像中提取抽象逻辑并将其转移到指定的目标上。", "motivation": "现有的生成模型只能进行像素级别的对齐和表面外观保持，无法捕捉到用于真正比喻生成所需的抽象逻辑。本文旨在通过Schema-Driven Agentic Reasoning解决这一问题。", "method": "提出了一种基于认知的多代理框架来实现视觉隐喻转移任务，该框架包括感知代理、转移代理、生成代理和诊断代理四个部分，并通过Schema Grammar将关系不变量从特定视觉实体中分离出来。", "result": "实验结果表明，在比喻一致性、类比适当性和视觉创造力方面，本文的方法显著优于现有的最佳方法。", "conclusion": "该研究为自动化的高影响力创造性应用铺平了道路，如广告和媒体等领域。"}}
{"id": "2602.01334", "pdf": "https://arxiv.org/pdf/2602.01334", "abs": "https://arxiv.org/abs/2602.01334", "authors": ["Yan Ma", "Weiyu Zhang", "Tianle Li", "Linge Du", "Xuyang Shen", "Pengfei Liu"], "title": "What Does Vision Tool-Use Reinforcement Learning Really Learn? Disentangling Tool-Induced and Intrinsic Effects for Crop-and-Zoom", "categories": ["cs.CV"], "comment": "code: https://github.com/GAIR-NLP/Med", "summary": "Vision tool-use reinforcement learning (RL) can equip vision-language models with visual operators such as crop-and-zoom and achieves strong performance gains, yet it remains unclear whether these gains are driven by improvements in tool use or evolving intrinsic capabilities.We introduce MED (Measure-Explain-Diagnose), a coarse-to-fine framework that disentangles intrinsic capability changes from tool-induced effects, decomposes the tool-induced performance difference into gain and harm terms, and probes the mechanisms driving their evolution. Across checkpoint-level analyses on two VLMs with different tool priors and six benchmarks, we find that improvements are dominated by intrinsic learning, while tool-use RL mainly reduces tool-induced harm (e.g., fewer call-induced errors and weaker tool schema interference) and yields limited progress in tool-based correction of intrinsic failures. Overall, current vision tool-use RL learns to coexist safely with tools rather than master them.", "AI": {"tldr": "本文研究了视觉工具使用的强化学习模型如何在作物和放大操作中进行改进，分解了由工具使用带来的增益与损害，并分析了这些变化的具体机制。", "motivation": "虽然视觉工具使用的强化学习（RL）可以提升视觉-语言模型的性能，但不清楚这种改善是由于更好的工具使用还是内在能力的发展。本文旨在澄清这一问题，通过MED框架来区分由工具引起的效应和内部能力的变化。", "method": "引入了MED（测量-解释-诊断）框架，用于从粗到细分解工具诱导效果与内在能力变化，并将工具诱导的性能差异分为增益和损害两部分。在两个具有不同工具先验的视觉语言模型上进行检查点分析以及六个基准测试。", "result": "研究发现，在作物放大操作中，大部分改进来自于内部学习的发展，而工具使用RL主要减少由工具引起的错误（如调用引起的问题）并减弱了工具方案之间的干扰。但其在通过工具来纠正内在失败方面进展有限。", "conclusion": "当前的视觉工具使用RL学会了安全地与工具共存而不是掌握它们。"}}
{"id": "2602.01329", "pdf": "https://arxiv.org/pdf/2602.01329", "abs": "https://arxiv.org/abs/2602.01329", "authors": ["Divya Jyoti Bajpai", "Shubham Agarwal", "Apoorv Saxena", "Kuldeep Kulkarni", "Subrata Mitra", "Manjesh Kumar Hanawal"], "title": "FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching", "categories": ["cs.CV"], "comment": "Accepted at International Conference on Learning Representations (ICLR 2026)", "summary": "Flow Matching (FM) has recently emerged as a powerful approach for high-quality visual generation. However, their prohibitively slow inference due to a large number of denoising steps limits their potential use in real-time or interactive applications. Existing acceleration methods, like distillation, truncation, or consistency training, either degrade quality, incur costly retraining, or lack generalization. We propose FlowCast, a training-free speculative generation framework that accelerates inference by exploiting the fact that FM models are trained to preserve constant velocity. FlowCast speculates future velocity by extrapolating current velocity without incurring additional time cost, and accepts it if it is within a mean-squared error threshold. This constant-velocity forecasting allows redundant steps in stable regions to be aggressively skipped while retaining precision in complex ones. FlowCast is a plug-and-play framework that integrates seamlessly with any FM model and requires no auxiliary networks. We also present a theoretical analysis and bound the worst-case deviation between speculative and full FM trajectories. Empirical evaluations demonstrate that FlowCast achieves $>2.5\\times$ speedup in image generation, video generation, and editing tasks, outperforming existing baselines with no quality loss as compared to standard full generation.", "AI": {"tldr": "提出FlowCast框架，利用恒定速度预测加速流匹配模型的推断过程而不损失质量", "motivation": "现有加速方法在牺牲质量或需要额外训练中取舍，无法满足实时应用需求。通过假设流匹配模型保留恒定速度来实现零成本推测生成，提高效率的同时保持高质量输出", "method": "FlowCast框架通过对当前速度进行外推预测未来轨迹，并设定阈值判断推测的有效性；此方法适用于任意流匹配模型且无需额外网络辅助", "result": "实验证明，FlowCast在图像生成、视频生成和编辑任务中比现有基线方法快2.5倍以上，同时保持相同质量水平", "conclusion": "通过有效预测减少冗余步骤并保留复杂区域精度，FlowCast提供了一种零成本的推测性加速方案"}}
{"id": "2602.01325", "pdf": "https://arxiv.org/pdf/2602.01325", "abs": "https://arxiv.org/abs/2602.01325", "authors": ["Kai Hu", "Junfu Tan", "Fang Xu", "Ramy Samy", "Yu Liu"], "title": "Unified ROI-based Image Compression Paradigm with Generalized Gaussian Model", "categories": ["eess.IV", "cs.MM"], "comment": "14 pages, 18 figures,", "summary": "Region-of-Interest (ROI)-based image compression allocates bits unevenly according to the semantic importance of different regions. Such differentiated coding typically induces a sharp-peaked and heavy-tailed distribution. This distribution characteristic mathematically necessitates a probability model with adaptable shape parameters for accurate description. However, existing methods commonly use a Gaussian model to fit this distribution, resulting in a loss of coding performance. To systematically analyze the impact of this distribution on ROI coding, we develop a unified rate-distortion optimization theoretical paradigm. Building on this paradigm, we propose a novel Generalized Gaussian Model (GGM) to achieve flexible modeling of the latent variables distribution. To support stable optimization of GGM, we introduce effective differentiable functions and further propose a dynamic lower bound to alleviate train-test mismatch. Moreover, finite differences are introduced to solve the gradient computation after GGM fits the distribution. Experiments on COCO2017 demonstrate that our method achieves state-of-the-art in both ROI reconstruction and downstream tasks (e.g., Segmentation, Object Detection). Furthermore, compared to classical probability models, our GGM provides a more precise fit to feature distributions and achieves superior coding performance. The project page is at https://github.com/hukai-tju/ROIGGM.", "AI": {"tldr": "该论文提出了一种基于广义高斯模型的统一ROI图像压缩框架，以提高ROI编码性能。", "motivation": "现有方法在处理ROI压缩时通常采用高斯模型来适应分布特性，这导致了编码性能的损失。为了系统地分析这种分布对ROI编码的影响，并优化编码效果，提出了一种新的广义高斯模型（GGM）。", "method": "通过构建统一的率失真优化理论框架，提出了基于广义高斯模型来灵活建模潜在变量分布的方法。同时引入有效的可微函数和动态下界以解决训练测试不匹配问题，并使用有限差分法计算梯度。", "result": "实验结果表明，在COCO2017数据集上，该方法在ROI重建以及下游任务（如分割、目标检测）中达到了最先进的性能。对比传统概率模型，广义高斯模型提供了更准确的特征分布拟合，并获得了更好的编码性能。", "conclusion": "通过引入广义高斯模型和优化技术，论文成功地提高了基于ROI的图像压缩效果并展示了在实际应用中的优越性。"}}
{"id": "2602.01317", "pdf": "https://arxiv.org/pdf/2602.01317", "abs": "https://arxiv.org/abs/2602.01317", "authors": ["Ziyue Wang", "Jiangshan Yu", "Kaihua Qin", "Dawn Song", "Arthur Gervais", "Liyi Zhou"], "title": "TxRay: Agentic Postmortem of Live Blockchain Attacks", "categories": ["cs.CR", "cs.AI"], "comment": "21 pages, 9 figures", "summary": "Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to reported exploits. Many exploits arise from permissionless opportunities that any participant can trigger using only public state and standard interfaces, which we call Anyone-Can-Take (ACT) opportunities. Despite on-chain transparency, postmortem analysis remains slow and manual: investigations start from limited evidence, sometimes only a single transaction hash, and must reconstruct the exploit lifecycle by recovering related transactions, contract code, and state dependencies. We present TxRay, a Large Language Model (LLM) agentic postmortem system that uses tool calls to reconstruct live ACT attacks from limited evidence. Starting from one or more seed transactions, TxRay recovers the exploit lifecycle, derives an evidence-backed root cause, and generates a runnable, self-contained Proof of Concept (PoC) that deterministically reproduces the incident. TxRay self-checks postmortems by encoding incident-specific semantic oracles as executable assertions. To evaluate PoC correctness and quality, we develop PoCEvaluator, an independent agentic execution-and-review evaluator. On 114 incidents from DeFiHackLabs, TxRay produces an expert-aligned root cause and an executable PoC for 105 incidents, achieving 92.11% end-to-end reproduction. Under PoCEvaluator, 98.1% of TxRay PoCs avoid hard-coding attacker addresses, a +24.8pp lift over DeFiHackLabs. In a live deployment, TxRay delivers validated root causes in 40 minutes and PoCs in 59 minutes at median latency. TxRay's oracle-validated PoCs enable attack imitation, improving coverage by 15.6% and 65.5% over STING and APE.", "AI": {"tldr": "TxRay是一款基于大型语言模型的代理后验系统，能够从有限的数据中重建DeFi生态系统中的实时Anyone-Can-Take（ACT）攻击，并生成可执行的PoC。", "motivation": "区块链开放性导致了大量DeFi生态系统的资金损失。传统的后验分析需要手动且耗时长，TxRay旨在通过大型语言模型实现自动化和快速的后验重建过程。", "method": "TxRay从种子交易开始，使用工具调用来重建ACT攻击的过程，并生成可验证的根原因及PoC。同时，独立代理执行器PoCEvaluator用于评估PoC的正确性和质量。", "result": "在114个DeFiHackLabs案例中，TxRay准确地为105个事件提供了专家认可的根原因和可执行的PoC，达到了92.11%的整体再现率。此外，在实际部署过程中，TxRay能够在平均延迟下提供有效的攻击重建。", "conclusion": "TxRay通过利用大型语言模型技术实现了对DeFi生态中ACT攻击的有效快速响应，并提高了后验分析的自动化程度和准确性。"}}
{"id": "2602.01313", "pdf": "https://arxiv.org/pdf/2602.01313", "abs": "https://arxiv.org/abs/2602.01313", "authors": ["Chuanrui Hu", "Tong Li", "Xingze Gao", "Hongda Chen", "Yi Bai", "Dannong Xu", "Tianwei Lin", "Xinda Zhao", "Xiaohong Li", "Yunyun Han", "Jian Pei", "Yafeng Deng"], "title": "EverMemBench: Benchmarking Long-Term Interactive Memory in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 2 figures, 4 tables", "summary": "Long-term conversational memory is essential for LLM-based assistants, yet existing benchmarks focus on dyadic, single-topic dialogues that fail to capture real-world complexity. We introduce EverMemBench, a benchmark featuring multi-party, multi-group conversations spanning over 1 million tokens with temporally evolving information, cross-topic interleaving, and role-specific personas. EverMemBench evaluates memory systems across three dimensions through 1,000+ QA pairs: fine-grained recall, memory awareness, and user profile understanding. Our evaluation reveals critical limitations: (1) multi-hop reasoning collapses in multi-party settings, with even oracle models achieving only 26%; (2) temporal reasoning remains unsolved, requiring version semantics beyond timestamp matching; (3) memory awareness is bottlenecked by retrieval, where current similarity-based methods fail to bridge the semantic gap between queries and implicitly relevant memories. EverMemBench provides a challenging testbed for developing next-generation memory architectures.", "AI": {"tldr": "本文提出了EverMemBench，这是一个用于评估大型语言模型长期对话记忆能力的基准。", "motivation": "现有对话基准未能捕捉真实世界中的复杂性，如多人、多主题和时序信息的变化。本文旨在填补这一研究空白，提出一个全面的测试框架。", "method": "EverMemBench包含超过100万个令牌的多人、多组对话，并通过1000多个问答对评估记忆系统在细粒度回忆、时间意识和用户画像理解三个维度上的表现。", "result": "实验揭示了模型在处理复杂对话时的关键局限性，例如多人场景中的推理能力不足和时间意识瓶颈问题。", "conclusion": "EverMemBench为开发下一代记忆架构提供了一个具有挑战性的测试平台。"}}
{"id": "2602.01308", "pdf": "https://arxiv.org/pdf/2602.01308", "abs": "https://arxiv.org/abs/2602.01308", "authors": ["Hengjie Cao", "Mengyi Chen", "Yifeng Yang", "Fang Dong", "Ruijun Huang", "Anrui Chen", "Jixian Zhou", "Mingzhi Dong", "Yujiang Wang", "Dongsheng Li", "Wenyi Fang", "Yuanyi Lin", "Fan Wu", "Li Shang"], "title": "Dispelling the Curse of Singularities in Neural Network Optimizations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This work investigates the optimization instability of deep neural networks from a less-explored yet insightful perspective: the emergence and amplification of singularities in the parametric space. Our analysis reveals that parametric singularities inevitably grow with gradient updates and further intensify alignment with representations, leading to increased singularities in the representation space. We show that the gradient Frobenius norms are bounded by the top singular values of the weight matrices, and as training progresses, the mutually reinforcing growth of weight and representation singularities, termed the curse of singularities, relaxes these bounds, escalating the risk of sharp loss explosions. To counter this, we propose Parametric Singularity Smoothing (PSS), a lightweight, flexible, and effective method for smoothing the singular spectra of weight matrices. Extensive experiments across diverse datasets, architectures, and optimizers demonstrate that PSS mitigates instability, restores trainability even after failure, and improves both training efficiency and generalization.", "AI": {"tldr": "本文研究了深度神经网络优化过程中的不稳定性和奇异值增长现象，并提出了一种新的方法来缓解这种问题，提高训练效率和泛化能力。", "motivation": "传统的深度学习模型在优化过程中易出现参数空间中奇异性的累积与放大，导致梯度爆炸风险增加。本文旨在揭示这些奇异性的成因及其对训练过程的影响，从而提出有效的解决策略。", "method": "通过理论分析发现权重矩阵的奇异值增长会影响表示空间中的奇异值，并且这种相互促进的增长会加剧优化不稳定性。基于此，作者提出了参数奇异平滑（PSS）方法来减缓这一问题，具体包括对权重矩阵的奇异谱进行平滑处理。", "result": "实验结果表明，在多种数据集、网络结构和优化器条件下，所提出的PSS能够有效缓解训练不稳定现象，并且即使在模型失效后也能恢复其可训练性。此外，该方法还提高了训练效率并改善了泛化性能。", "conclusion": "本文通过揭示深度神经网络中奇异性的动态行为及其对优化过程的影响，提出了参数奇异平滑（PSS）技术来缓解这些问题，并证明了其在提高模型鲁棒性和提升训练效果方面的有效性。"}}
{"id": "2602.01306", "pdf": "https://arxiv.org/pdf/2602.01306", "abs": "https://arxiv.org/abs/2602.01306", "authors": ["Ayushman Sarkar", "Zhenyu Yu", "Mohd Yamani Idna Idris"], "title": "DeCorStory: Gram-Schmidt Prompt Embedding Decorrelation for Consistent Storytelling", "categories": ["cs.CV"], "comment": null, "summary": "Maintaining visual and semantic consistency across frames is a key challenge in text-to-image storytelling. Existing training-free methods, such as One-Prompt-One-Story, concatenate all prompts into a single sequence, which often induces strong embedding correlation and leads to color leakage, background blending, and identity drift. We propose DeCorStory, a training-free inference-time framework that explicitly reduces inter-frame semantic interference. DeCorStory applies Gram-Schmidt prompt embedding decorrelation to orthogonalize frame-level semantics, followed by singular value reweighting to strengthen prompt-specific information and identity-preserving cross-attention to stabilize character identity during diffusion. The method requires no model modification or fine-tuning and can be seamlessly integrated into existing diffusion pipelines. Experiments demonstrate consistent improvements in prompt-image alignment, identity consistency, and visual diversity, achieving state-of-the-art performance among training-free baselines. Code is available at: https://github.com/YuZhenyuLindy/DeCorStory", "AI": {"tldr": "论文提出了DeCorStory，一种训练自由的推断时框架，用于减少文本到图像故事叙述中帧之间的语义干扰。", "motivation": "现有方法如One-Prompt-One-Story在连接所有提示为单一序列时会产生强烈的嵌入相关性，并导致颜色泄漏、背景融合和身份漂移等问题。因此需要一种新的方法来解决这些问题，以提高视觉一致性和语义一致性。", "method": "DeCorStory通过Gram-Schmidt正交化处理帧级语义，随后采用奇异值重加权加强提示特定信息并使用保持身份的交叉注意力稳定角色的身份，在扩散过程中减少语义干扰。该方法无需修改模型或微调，可以无缝集成到现有的扩散管道中。", "result": "实验表明，DeCorStory在提示图像对齐、身份一致性以及视觉多样性方面均有所提高，并且在训练自由基线上达到最先进的性能。", "conclusion": "DeCorStory是一个有效的解决方案，用于解决文本到图像故事叙述中的帧间语义干扰问题。该方法不仅提高了图像的视觉和语义一致性，而且保持了角色的身份稳定性和视觉多样性的平衡。"}}
{"id": "2602.01305", "pdf": "https://arxiv.org/pdf/2602.01305", "abs": "https://arxiv.org/abs/2602.01305", "authors": ["Ayushman Sarkar", "Zhenyu Yu", "Wei Tang", "Chu Chen", "Kangning Cui", "Mohd Yamani Idna Idris"], "title": "StoryState: Agent-Based State Control for Consistent and Editable Storybooks", "categories": ["cs.CV"], "comment": null, "summary": "Large multimodal models have enabled one-click storybook generation, where users provide a short description and receive a multi-page illustrated story. However, the underlying story state, such as characters, world settings, and page-level objects, remains implicit, making edits coarse-grained and often breaking visual consistency. We present StoryState, an agent-based orchestration layer that introduces an explicit and editable story state on top of training-free text-to-image generation. StoryState represents each story as a structured object composed of a character sheet, global settings, and per-page scene constraints, and employs a small set of LLM agents to maintain this state and derive 1Prompt1Story-style prompts for generation and editing. Operating purely through prompts, StoryState is model-agnostic and compatible with diverse generation backends. System-level experiments on multi-page editing tasks show that StoryState enables localized page edits, improves cross-page consistency, and reduces unintended changes, interaction turns, and editing time compared to 1Prompt1Story, while approaching the one-shot consistency of Gemini Storybook. Code is available at https://github.com/YuZhenyuLindy/StoryState", "AI": {"tldr": "StoryState是一种基于代理的故事状态控制层，用于生成和编辑多页绘本。", "motivation": "大型多模态模型虽然能一键生成故事书，但底层故事状态不明确，导致难以进行细微的编辑并且容易破坏视觉一致性。因此提出了一种显式且可编辑的故事状态控制方法。", "method": "StoryState将每个故事表示为一个结构化的对象，并利用少量的语言模型代理来维护故事状态并导出用于生成和编辑的提示。这种方法不依赖于特定的生成模型，适用于多种不同的后端系统。", "result": "实验结果表明，与1Prompt1Story方法相比，StoryState能够进行局部页面编辑、提高跨页一致性，并减少意外变化、交互次数和编辑时间。", "conclusion": "StoryState通过引入显式且可编辑的故事状态控制层，成功改进了故事书的生成和编辑过程。"}}
{"id": "2602.01303", "pdf": "https://arxiv.org/pdf/2602.01303", "abs": "https://arxiv.org/abs/2602.01303", "authors": ["Ayushman Sarkar", "Zhenyu Yu", "Chu Chen", "Wei Tang", "Kangning Cui", "Mohd Yamani Idna Idris"], "title": "ReDiStory: Region-Disentangled Diffusion for Consistent Visual Story Generation", "categories": ["cs.CV"], "comment": null, "summary": "Generating coherent visual stories requires maintaining subject identity across multiple images while preserving frame-specific semantics. Recent training-free methods concatenate identity and frame prompts into a unified representation, but this often introduces inter-frame semantic interference that weakens identity preservation in complex stories. We propose ReDiStory, a training-free framework that improves multi-frame story generation via inference-time prompt embedding reorganization. ReDiStory explicitly decomposes text embeddings into identity-related and frame-specific components, then decorrelates frame embeddings by suppressing shared directions across frames. This reduces cross-frame interference without modifying diffusion parameters or requiring additional supervision. Under identical diffusion backbones and inference settings, ReDiStory improves identity consistency while maintaining prompt fidelity. Experiments on the ConsiStory+ benchmark show consistent gains over 1Prompt1Story on multiple identity consistency metrics. Code is available at: https://github.com/YuZhenyuLindy/ReDiStory", "AI": {"tldr": "本文提出了一种无训练框架ReDiStory，用于生成一致性更好的视觉故事。", "motivation": "现有的无训练方法在生成多个图像的连贯视觉故事时，会引入跨帧语义干扰，从而削弱身份保持。", "method": "通过推理时间提示嵌入重组，将文本嵌入分解为身份相关和帧特定组件，并通过抑制跨帧共享方向来减少跨帧干扰。", "result": "实验结果表明，ReDiStory在多个身份一致性指标上优于1Prompt1Story方法。", "conclusion": "本文提出的方法有效提高了视觉故事生成的身份一致性和提示保真度。"}}
{"id": "2602.01298", "pdf": "https://arxiv.org/pdf/2602.01298", "abs": "https://arxiv.org/abs/2602.01298", "authors": ["Ching-Kai Huang", "Wen-Chieh Lin", "Yan-Cen Lee"], "title": "Interaction-Consistent Object Removal via MLLM-Based Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Image-based object removal often erases only the named target, leaving behind interaction evidence that renders the result semantically inconsistent. We formalize this problem as Interaction-Consistent Object Removal (ICOR), which requires removing not only the target object but also associated interaction elements, such as lighting-dependent effects, physically connected objects, targetproduced elements, and contextually linked objects. To address this task, we propose Reasoning-Enhanced Object Removal with MLLM (REORM), a reasoningenhanced object removal framework that leverages multimodal large language models to infer which elements must be jointly removed. REORM features a modular design that integrates MLLM-driven analysis, mask-guided removal, and a self-correction mechanism, along with a local-deployment variant that supports accurate editing under limited resources. To support evaluation, we introduce ICOREval, a benchmark consisting of instruction-driven removals with rich interaction dependencies. On ICOREval, REORM outperforms state-of-the-art image editing systems, demonstrating its effectiveness in producing interactionconsistent results.", "AI": {"tldr": "本文提出了一种基于多模态大型语言模型推理的交互一致对象去除框架，旨在解决图像中目标物体及其关联互动元素的一致性删除问题。", "motivation": "传统的图像对象移除方法仅移除了指定的目标物，而未能处理其相关的互动证据，导致结果在语义上不一致。为了克服这一挑战，提出了一个新的任务和解决方案：交互一致对象去除（ICOR）。", "method": "本文提出了一种基于推理增强的对象去除框架REORM，该框架利用多模态大型语言模型进行分析，结合掩码引导的移除以及自我校正机制来处理互动元素。此外还提供了一个适合资源有限环境下的部署变体。", "result": "在ICOREval基准测试中，REORM的表现超过了现有的图像编辑系统，并展示了其在生成交互一致结果方面的有效性。", "conclusion": "本文通过引入多模态大型语言模型推理解决了传统方法在处理对象移除时存在的互动证据一致性问题。实验结果显示该方法能够有效地完成任务并优于现有技术。"}}
{"id": "2602.01297", "pdf": "https://arxiv.org/pdf/2602.01297", "abs": "https://arxiv.org/abs/2602.01297", "authors": ["Shaowei Shen", "Xiaohong Yang", "Jie Yang", "Lianfen Huang", "Yongcai Zhang", "Yang Zou", "Seyyedali Hosseinalipour"], "title": "RE-MCDF: Closed-Loop Multi-Expert LLM Reasoning for Knowledge-Grounded Clinical Diagnosis", "categories": ["cs.AI"], "comment": "9 pages, 4 figures", "summary": "Electronic medical records (EMRs), particularly in neurology, are inherently heterogeneous, sparse, and noisy, which poses significant challenges for large language models (LLMs) in clinical diagnosis. In such settings, single-agent systems are vulnerable to self-reinforcing errors, as their predictions lack independent validation and can drift toward spurious conclusions. Although recent multi-agent frameworks attempt to mitigate this issue through collaborative reasoning, their interactions are often shallow and loosely structured, failing to reflect the rigorous, evidence-driven processes used by clinical experts. More fundamentally, existing approaches largely ignore the rich logical dependencies among diseases, such as mutual exclusivity, pathological compatibility, and diagnostic confusion. This limitation prevents them from ruling out clinically implausible hypotheses, even when sufficient evidence is available. To overcome these, we propose RE-MCDF, a relation-enhanced multi-expert clinical diagnosis framework. RE-MCDF introduces a generation--verification--revision closed-loop architecture that integrates three complementary components: (i) a primary expert that generates candidate diagnoses and supporting evidence, (ii) a laboratory expert that dynamically prioritizes heterogeneous clinical indicators, and (iii) a multi-relation awareness and evaluation expert group that explicitly enforces inter-disease logical constraints. Guided by a medical knowledge graph (MKG), the first two experts adaptively reweight EMR evidence, while the expert group validates and corrects candidate diagnoses to ensure logical consistency. Extensive experiments on the neurology subset of CMEMR (NEEMRs) and on our curated dataset (XMEMRs) demonstrate that RE-MCDF consistently outperforms state-of-the-art baselines in complex diagnostic scenarios.", "AI": {"tldr": "提出了一种名为RE-MCDF的临床诊断框架，用于处理电子病历中异质性、稀疏性和噪声对大型语言模型（LLMs）的影响。", "motivation": "现有单个代理系统在没有独立验证的情况下容易出现自我强化错误，并且多代理框架虽然试图通过协作推理来减少这些误差，但其交互方式通常浅薄而松散，无法反映临床专家使用的严谨、基于证据的过程。此外，现有的方法忽略了疾病之间的丰富逻辑依赖性。", "method": "RE-MCDF引入了一个生成-验证-修订的闭环架构，包含三个互补组件：一个初级专家生成候选诊断和支持证据；实验室专家动态优先级排序异质临床指标；一个多关系意识和评估专家组明确实施病间逻辑约束。根据医学知识图谱（MKG），前两个专家自适应调整电子医疗记录（EMR）的权重，而专家组验证并纠正候选诊断以确保逻辑一致性。", "result": "在CMEMR数据集中的神经学子集NEEMRs和我们整理的数据集XMEMRs上进行了广泛的实验表明RE-MCDF在复杂诊断场景中始终优于最先进的基线模型。", "conclusion": "RE-MCDF通过引入生成-验证-修订的闭环架构，结合三个互补组件以解决现有方法在处理电子病历中的局限性，并展示了其在临床诊断上的优越性能。"}}
{"id": "2602.01296", "pdf": "https://arxiv.org/pdf/2602.01296", "abs": "https://arxiv.org/abs/2602.01296", "authors": ["Zeran Ke", "Bin Tan", "Gui-Song Xia", "Yujun Shen", "Nan Xue"], "title": "Interacted Planes Reveal 3D Line Mapping", "categories": ["cs.CV"], "comment": "submitted to TPAMI", "summary": "3D line mapping from multi-view RGB images provides a compact and structured visual representation of scenes. We study the problem from a physical and topological perspective: a 3D line most naturally emerges as the edge of a finite 3D planar patch. We present LiP-Map, a line-plane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing a reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering a principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks\\&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research.", "AI": {"tldr": "提出了一种通过多视角RGB图像进行三维线映射的方法LiP-Map，该方法结合了可学习的直线和面元模型。", "motivation": "传统的3D线映射技术往往缺乏效率与准确度，而LiP-Map则从物理及拓扑角度出发，强调了3D线自然作为有限3D平面补丁边缘的特性，以此提出了一种更精确且高效的解决方案。", "method": "通过引入交互式的面和线元模型构建方法，以及不依赖成对共面约束的联合优化框架LiP-Map来实现3D线映射任务。", "result": "在ScanNetV2、ScanNet++、Hypersim等超过100个场景测试中，LiP-Map的表现优于当前最先进方法，在7Scenes数据集上更是显著提升了视觉定位的准确性。", "conclusion": "通过引入交互式的面和线元模型构建及联合优化框架，LiP-Map能够提供更准确、更完整的3D线映射结果，并在辅助视觉定位任务中展现出优越性能。"}}
{"id": "2602.01294", "pdf": "https://arxiv.org/pdf/2602.01294", "abs": "https://arxiv.org/abs/2602.01294", "authors": ["Kecheng Zhang", "Anders Lansner", "Ahsan Javed Awan", "Naresh Balaji Ravichandran", "Pawel Herman"], "title": "Dynamic Heuristic Neuromorphic Solver for the Edge User Allocation Problem with Bayesian Confidence Propagation Neural Network", "categories": ["cs.NE"], "comment": "submitted to NICE2026", "summary": "We propose a neuromorphic solver for the NP-hard Edge User Allocation problem using an attractor network with Winner-Takes-All (WTA) mechanism implemented with the Bayesian Confidence Propagation Neural Network (BCPNN) framework. Unlike previous energy-based attractor networks, our solver uses dynamic heuristic biasing to guide allocations in real time and introduces a \"no allocation\" state to each WTA motif, achieving near-optimal performance with an empirically upper-bounded number of time steps. The approach is compatible with neuromorphic architectures and may offer improvements in energy efficiency.", "AI": {"tldr": "提出一种基于Bayesian Confidence Propagation Neural Network框架的动态启发式偏置求解器，用于解决NP难题边缘用户分配问题。", "motivation": "旨在通过引入“无分配”状态和实时引导分配的技术来改进现有的能量基吸引子网络，从而达到接近最优性能，并提升能效。", "method": "利用带有Winner-Takes-All机制的动态启发式偏置吸引子网络求解边缘用户分配问题，采用Bayesian Confidence Propagation Neural Network框架实现该机制。", "result": "实验表明，所提出的求解器在有限时间内达到近似最优性能，并且具有理论上的时间上限保证。", "conclusion": "新方法不仅实现了接近最优的解决方案，还为未来神经形态架构的设计提供了可能性。"}}
{"id": "2602.01289", "pdf": "https://arxiv.org/pdf/2602.01289", "abs": "https://arxiv.org/abs/2602.01289", "authors": ["Dung Anh Hoang", "Cuong Pham anh Trung Le", "Jianfei Cai", "Toan Do"], "title": "Gradient-Aligned Calibration for Post-Training Quantization of Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Diffusion models have shown remarkable performance in image synthesis by progressively estimating a smooth transition from a Gaussian distribution of noise to a real image. Unfortunately, their practical deployment is limited by slow inference speed, high memory usage, and the computational demands of the noise estimation process. Post-training quantization (PTQ) emerges as a promising solution to accelerate sampling and reduce memory overhead for diffusion models. Existing PTQ methods for diffusion models typically apply uniform weights to calibration samples across timesteps, which is sub-optimal since data at different timesteps may contribute differently to the diffusion process. Additionally, due to varying activation distributions and gradients across timesteps, a uniform quantization approach is sub-optimal. Each timestep requires a different gradient direction for optimal quantization, and treating them equally can lead to conflicting gradients that degrade performance. In this paper, we propose a novel PTQ method that addresses these challenges by assigning appropriate weights to calibration samples. Specifically, our approach learns to assign optimal weights to calibration samples to align the quantized model's gradients across timesteps, facilitating the quantization process. Extensive experiments on CIFAR-10, LSUN-Bedrooms, and ImageNet demonstrate the superiority of our method compared to other PTQ methods for diffusion models.", "AI": {"tldr": "提出了一种新的后训练量化方法，通过为校准样本分配适当的权重来优化扩散模型的梯度对齐。", "motivation": "现有PTQ方法在不同时间步长应用统一的权重是次优的，因为不同的数据贡献可能不一致。此外，由于激活分布和梯度随时间变化，需要特定的时间步长优化量化。", "method": "提出了一种新的PTQ方法，通过为校准样本分配适当的权重来学习对齐量化模型在不同时间步上的梯度方向。", "result": "实验表明，所提方法与现有扩散模型的PTQ方法相比具有优越性。", "conclusion": "该研究成功地提出了一个优化的后训练量化方法，解决了传统方法中由于时间步长导致的性能下降问题。"}}
{"id": "2602.01285", "pdf": "https://arxiv.org/pdf/2602.01285", "abs": "https://arxiv.org/abs/2602.01285", "authors": ["Kangjun Noh", "Seongchan Lee", "Ilmun Kim", "Kyungwoo Song"], "title": "Multi-LLM Adaptive Conformal Inference for Reliable LLM Responses", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted to ICLR 2026", "summary": "Ensuring factuality is essential for the safe use of Large Language Models (LLMs) in high-stakes domains such as medicine and law. Conformal inference provides distribution-free guarantees, but existing approaches are either overly conservative, discarding many true-claims, or rely on adaptive error rates and simple linear models that fail to capture complex group structures. To address these challenges, we reformulate conformal inference in a multiplicative filtering setting, modeling factuality as a product of claim-level scores. Our method, Multi-LLM Adaptive Conformal Inference (MACI), leverages ensembles to produce more accurate factuality-scores, which in our experiments led to higher retention, while validity is preserved through group-conditional calibration. Experiments show that MACI consistently achieves user-specified coverage with substantially higher retention and lower time cost than baselines. Our repository is available at https://github.com/MLAI-Yonsei/MACI", "AI": {"tldr": "提出了一种新的方法MACI，用于提高大型语言模型在高风险领域中生成事实性响应的可靠性。", "motivation": "确保大型语言模型在医疗和法律等高风险领域的安全性是必要的。现有的基于一致性推断的方法要么过于保守，丢弃了许多真实的声明，要么依赖于适应性的错误率和简单的线性模型无法捕捉复杂的群体结构。", "method": "通过重新定义一致推断以乘法过滤的形式进行建模，并利用集成学习来生成更准确的事实性评分。该方法在实验中提高了保留率，并且通过分组条件校准保持了有效性。", "result": "MACI 在用户指定的覆盖率方面表现优异，与基线相比具有更高的保留率和更低的时间成本。", "conclusion": "MACI 方法能够有效地提高大型语言模型生成事实性响应的能力，在高风险领域中的应用更为可靠。"}}
{"id": "2602.01284", "pdf": "https://arxiv.org/pdf/2602.01284", "abs": "https://arxiv.org/abs/2602.01284", "authors": ["Chen Chen", "Dion Hoe-Lian Goh"], "title": "Seeing, Hearing, and Knowing Together: Multimodal Strategies in Deepfake Videos Detection", "categories": ["cs.MM", "cs.CV", "cs.HC"], "comment": null, "summary": "As deepfake videos become increasingly difficult for people to recognise, understanding the strategies humans use is key to designing effective media literacy interventions. We conducted a study with 195 participants between the ages of 21 and 40, who judged real and deepfake videos, rated their confidence, and reported the cues they relied on across visual, audio, and knowledge strategies. Participants were more accurate with real videos than with deepfakes and showed lower expected calibration error for real content. Through association rule mining, we identified cue combinations that shaped performance. Visual appearance, vocal, and intuition often co-occurred for successful identifications, which highlights the importance of multimodal approaches in human detection. Our findings show which cues help or hinder detection and suggest directions for designing media literacy tools that guide effective cue use. Building on these insights can help people improve their identification skills and become more resilient to deceptive digital media.", "AI": {"tldr": "研究通过多模态策略分析了人类识别深伪视频的方法，旨在提高媒体素养和抵御欺骗性数字媒体的能力。", "motivation": "随着深伪视频变得越来越难以被人们辨别，理解人类使用的策略对于设计有效的媒体素养干预措施至关重要。", "method": "研究通过对195名参与者进行实验，让他们判断真实和深伪视频，并评价他们的信心以及他们依赖的线索。通过关联规则挖掘来识别影响性能的线索组合。", "result": "参与者在识别真实视频方面比深伪视频更准确，表现出了较低的预期校准误差。视觉、声音和直觉往往是成功识别的关键因素。", "conclusion": "研究发现有助于或阻碍检测的线索，并为设计媒体素养工具以指导有效的线索使用提出了建议。"}}
{"id": "2602.01283", "pdf": "https://arxiv.org/pdf/2602.01283", "abs": "https://arxiv.org/abs/2602.01283", "authors": ["Xianhui Zhang", "Chengyu Xie", "Linxia Zhu", "Yonghui Yang", "Weixiang Zhao", "Zifeng Cheng", "Cong Wang", "Fei Shen", "Tat-Seng Chua"], "title": "Who Transfers Safety? Identifying and Targeting Cross-Lingual Shared Safety Neurons", "categories": ["cs.CV"], "comment": null, "summary": "Multilingual safety remains significantly imbalanced, leaving non-high-resource (NHR) languages vulnerable compared to robust high-resource (HR) ones. Moreover, the neural mechanisms driving safety alignment remain unclear despite observed cross-lingual representation transfer. In this paper, we find that LLMs contain a set of cross-lingual shared safety neurons (SS-Neurons), a remarkably small yet critical neuronal subset that jointly regulates safety behavior across languages. We first identify monolingual safety neurons (MS-Neurons) and validate their causal role in safety refusal behavior through targeted activation and suppression. Our cross-lingual analyses then identify SS-Neurons as the subset of MS-Neurons shared between HR and NHR languages, serving as a bridge to transfer safety capabilities from HR to NHR domains. We observe that suppressing these neurons causes concurrent safety drops across NHR languages, whereas reinforcing them improves cross-lingual defensive consistency. Building on these insights, we propose a simple neuron-oriented training strategy that targets SS-Neurons based on language resource distribution and model architecture. Experiments demonstrate that fine-tuning this tiny neuronal subset outperforms state-of-the-art methods, significantly enhancing NHR safety while maintaining the model's general capabilities. The code and dataset will be available athttps://github.com/1518630367/SS-Neuron-Expansion.", "AI": {"tldr": "该论文旨在识别和定位跨语言共享的安全神经元，以提高低资源语言的模型安全性。", "motivation": "多语种安全性的不平衡导致非高资源（NHR）语言在安全性上比高资源（HR）语言更加脆弱。此外，尽管观察到了跨语言表示转移的现象，但驱动安全对齐的神经机制仍然不明确。", "method": "通过激活和抑制单语安全神经元（MS-Neurons），研究团队验证了它们在安全拒绝行为中的因果作用，并进一步识别出了跨语言共享的安全神经元（SS-Neurons）。这些发现为开发一种基于语言资源分布和模型架构的简单神经元导向训练策略提供了基础。", "result": "实验表明，微调这种小型神经元子集可以超越最先进的方法，在增强低资源语言安全性的同时保持模型的一般能力。", "conclusion": "通过识别并利用跨语言共享的安全神经元（SS-Neurons），可以在不影响整体性能的情况下显著提升非高资源语言的模型安全性。"}}
{"id": "2602.01278", "pdf": "https://arxiv.org/pdf/2602.01278", "abs": "https://arxiv.org/abs/2602.01278", "authors": ["Zhengbo Zhang", "Yihe Tian", "Wanke Xia", "Lin Chen", "Yue Sun", "Kun Ding", "Ying Wang", "Bing Xu", "Shiming Xiang"], "title": "DSFC-Net: A Dual-Encoder Spatial and Frequency Co-Awareness Network for Rural Road Extraction", "categories": ["cs.CV"], "comment": null, "summary": "Accurate extraction of rural roads from high-resolution remote sensing imagery is essential for infrastructure planning and sustainable development. However, this task presents unique challenges in rural settings due to several factors. These include high intra-class variability and low inter-class separability from diverse surface materials, frequent vegetation occlusions that disrupt spatial continuity, and narrow road widths that exacerbate detection difficulties. Existing methods, primarily optimized for structured urban environments, often underperform in these scenarios as they overlook such distinctive characteristics. To address these challenges, we propose DSFC-Net, a dual-encoder framework that synergistically fuses spatial and frequency-domain information. Specifically, a CNN branch is employed to capture fine-grained local road boundaries and short-range continuity, while a novel Spatial-Frequency Hybrid Transformer (SFT) is introduced to robustly model global topological dependencies against vegetation occlusions. Distinct from standard attention mechanisms that suffer from frequency bias, the SFT incorporates a Cross-Frequency Interaction Attention (CFIA) module that explicitly decouples high- and low-frequency information via a Laplacian Pyramid strategy. This design enables the dynamic interaction between spatial details and frequency-aware global contexts, effectively preserving the connectivity of narrow roads. Furthermore, a Channel Feature Fusion Module (CFFM) is proposed to bridge the two branches by adaptively recalibrating channel-wise feature responses, seamlessly integrating local textures with global semantics for accurate segmentation. Comprehensive experiments on the WHU-RuR+, DeepGlobe, and Massachusetts datasets validate the superiority of DSFC-Net over state-of-the-art approaches.", "AI": {"tldr": "提出了DSFC-Net框架，用于高分辨率遥感图像中的农村道路提取。", "motivation": "现有方法在处理高内类变化、低外类分离度和频繁植被遮挡的复杂背景下表现不佳，因此开发了一种新的双编码器网络来克服这些问题。", "method": "DSFC-Net采用CNN分支捕捉局部细节，并引入Spatial-Frequency Hybrid Transformer (SFT)进行全局依赖建模，使用Cross-Frequency Interaction Attention (CFIA)模块解耦高低频信息并动态交互空间细节与频率感知全局上下文。此外，通过Channel Feature Fusion Module (CFFM)集成两个分支。", "result": "实验结果验证了DSFC-Net在WHU-RuR+、DeepGlobe和Massachusetts数据集上优于现有方法。", "conclusion": "提出的DSFC-Net框架在农村道路提取任务中表现出色，有效地解决了现有技术难以应对的挑战。"}}
{"id": "2602.01277", "pdf": "https://arxiv.org/pdf/2602.01277", "abs": "https://arxiv.org/abs/2602.01277", "authors": ["Yihan Xie", "Han Xia", "Zhen Yang"], "title": "TF-Lane: Traffic Flow Module for Robust Lane Perception", "categories": ["cs.CV"], "comment": "9 pages, 7 figures, 7 tables", "summary": "Autonomous driving systems require robust lane perception capabilities, yet existing vision-based detection methods suffer significant performance degradation when visual sensors provide insufficient cues, such as in occluded or lane-missing scenarios. While some approaches incorporate high-definition maps as supplementary information, these solutions face challenges of high subscription costs and limited real-time performance. To address these limitations, we explore an innovative information source: traffic flow, which offers real-time capabilities without additional costs. This paper proposes a TrafficFlow-aware Lane perception Module (TFM) that effectively extracts real-time traffic flow features and seamlessly integrates them with existing lane perception algorithms. This solution originated from real-world autonomous driving conditions and was subsequently validated on open-source algorithms and datasets. Extensive experiments on four mainstream models and two public datasets (Nuscenes and OpenLaneV2) using standard evaluation metrics show that TFM consistently improves performance, achieving up to +4.1% mAP gain on the Nuscenes dataset.", "AI": {"tldr": "该论文提出了一种基于交通流量的车道感知模块（TFM），旨在解决现有视觉基检测方法在传感器提供信息不足时性能下降的问题。", "motivation": "现有的基于视觉的方法在缺乏足够视觉线索的情况下，如遮挡或缺少车道线场景中，表现不佳。引入高精度地图作为辅助信息虽然有效但面临高昂的订阅成本和实时性问题。论文旨在通过利用交通流量这一低成本、高效的信息源来提升车道感知能力。", "method": "提出了一个集成交通流特征提取与现有车道感知算法的方法（TFM），该方法在主流模型上进行了测试，并验证了其有效性，特别是在开放数据集Nuscenes和OpenLaneV2上的性能提升。", "result": "实验表明，在Nuscenes数据集上使用标准评价指标，TFM可以实现高达+4.1%的mAP增益。该方法在四个主流模型及两个公开数据集中均表现出色。", "conclusion": "通过引入交通流量作为辅助信息源，TFM能够有效提升车道感知算法在复杂驾驶环境下的性能，展示了其在自动驾驶中的应用潜力。"}}
{"id": "2602.01276", "pdf": "https://arxiv.org/pdf/2602.01276", "abs": "https://arxiv.org/abs/2602.01276", "authors": ["Abdulsobur Oyewale", "Tommaso Soru"], "title": "LLM-Driven Ontology Construction for Enterprise Knowledge Graphs", "categories": ["cs.AI"], "comment": "20th International Conference on Semantic Computing (ICSC 2026)", "summary": "Enterprise Knowledge Graphs have become essential for unifying heterogeneous data and enforcing semantic governance. However, the construction of their underlying ontologies remains a resource-intensive, manual process that relies heavily on domain expertise. This paper introduces OntoEKG, a LLM-driven pipeline designed to accelerate the generation of domain-specific ontologies from unstructured enterprise data. Our approach decomposes the modelling task into two distinct phases: an extraction module that identifies core classes and properties, and an entailment module that logically structures these elements into a hierarchy before serialising them into standard RDF. Addressing the significant lack of comprehensive benchmarks for end-to-end ontology construction, we adopt a new evaluation dataset derived from documents across the Data, Finance, and Logistics sectors. Experimental results highlight both the potential and the challenges of this approach, achieving a fuzzy-match F1-score of 0.724 in the Data domain while revealing limitations in scope definition and hierarchical reasoning.", "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的企业知识图谱本体构建流水线OntoEKG，旨在从非结构化企业数据中自动生成领域特定的本体。", "motivation": "企业知识图谱在统一异构数据和执行语义治理方面变得至关重要。然而，其底层本体的构建仍然是资源密集型且依赖于专业知识的手动过程。", "method": "本文提出的方法将建模任务分为两个阶段：一个提取模块用于识别核心类和属性；一个推理模块用于逻辑地组织这些元素并将其序列化为标准RDF格式。", "result": "实验结果表明，该方法在数据领域实现了模糊匹配F1分数0.724，但在范围定义和层次结构推理方面存在局限性。", "conclusion": "本文展示了LLM驱动的本体构建流水线OntoEKG的巨大潜力与挑战。"}}
{"id": "2602.01274", "pdf": "https://arxiv.org/pdf/2602.01274", "abs": "https://arxiv.org/abs/2602.01274", "authors": ["Situo Zhang", "Yifan Zhang", "Zichen Zhu", "Hankun Wang", "Da Ma", "Danyang Zhang", "Lu Chen", "Kai Yu"], "title": "PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Speculative decoding (SD) is a powerful technique for accelerating the inference process of large language models (LLMs) without sacrificing accuracy. Typically, SD employs a small draft model to generate a fixed number of draft tokens, which are then verified in parallel by the target model. However, our experiments reveal that the optimal draft length varies significantly across different decoding steps. This variation suggests that using a fixed draft length limits the potential for further improvements in decoding speed. To address this challenge, we propose Pacer, a novel approach that dynamically controls draft length using a lightweight, trainable pre-verification layer. This layer pre-verifies draft tokens blockwise before they are sent to the target model, allowing the draft model to stop token generation if the blockwise pre-verification fails. We implement Pacer on multiple SD model pairs and evaluate its performance across various benchmarks. Our results demonstrate that Pacer achieves up to 2.66x Speedup over autoregressive decoding and consistently outperforms standard speculative decoding. Furthermore, when integrated with Ouroboros, Pacer attains up to 3.09x Speedup.", "AI": {"tldr": "PACER通过动态控制草稿长度来优化Speculative Decoding，使用轻量级可训练的预验证层在块级别上进行验证。", "motivation": "固定草案长度限制了进一步提高解码速度的潜力。作者提出了一种新的方法来解决这个问题，即根据不同的解码步骤动态调整草稿长度。", "method": "PACER使用轻量级可训练的预验证层在块级别上进行预验证，如果预验证失败，则草稿模型停止生成令牌。这种方法可以与标准Speculative Decoding和Ouroboros集成以进一步提高速度。", "result": "实验结果表明，在多个SD模型对上实现PACER可以达到2.66倍的速度提升，并且当与Ouroboros结合时，最多可达到3.09倍的速度提升。", "conclusion": "通过引入块级预验证和动态调整草稿长度的方法，PACER能够在不牺牲准确性的情况下显著加快大型语言模型的推理过程。"}}
{"id": "2602.01273", "pdf": "https://arxiv.org/pdf/2602.01273", "abs": "https://arxiv.org/abs/2602.01273", "authors": ["Xun Zhang", "Kaicheng Yang", "Hongliang Lu", "Haotong Qin", "Yong Guo", "Yulun Zhang"], "title": "Q-DiT4SR: Exploration of Detail-Preserving Diffusion Transformer Quantization for Real-World Image Super-Resolution", "categories": ["cs.CV"], "comment": "Our code and models will be available at https://github.com/xunzhang1128/Q-DiT4SR", "summary": "Recently, Diffusion Transformers (DiTs) have emerged in Real-World Image Super-Resolution (Real-ISR) to generate high-quality textures, yet their heavy inference burden hinders real-world deployment. While Post-Training Quantization (PTQ) is a promising solution for acceleration, existing methods in super-resolution mostly focus on U-Net architectures, whereas generic DiT quantization is typically designed for text-to-image tasks. Directly applying these methods to DiT-based super-resolution models leads to severe degradation of local textures. Therefore, we propose Q-DiT4SR, the first PTQ framework specifically tailored for DiT-based Real-ISR. We propose H-SVD, a hierarchical SVD that integrates a global low-rank branch with a local block-wise rank-1 branch under a matched parameter budget. We further propose Variance-aware Spatio-Temporal Mixed Precision: VaSMP allocates cross-layer weight bit-widths in a data-free manner based on rate-distortion theory, while VaTMP schedules intra-layer activation precision across diffusion timesteps via dynamic programming (DP) with minimal calibration. Experiments on multiple real-world datasets demonstrate that our Q-DiT4SR achieves SOTA performance under both W4A6 and W4A4 settings. Notably, the W4A4 quantization configuration reduces model size by 5.8$\\times$ and computational operations by over 60$\\times$. Our code and models will be available at https://github.com/xunzhang1128/Q-DiT4SR.", "AI": {"tldr": "提出了一种专门针对基于扩散变换器的超分辨率模型的后训练量化框架Q-DiT4SR，以减轻推理负担。", "motivation": "Diffusion Transformers在图像超分辨中生成高质量纹理但推理负担重，现有方法主要集中在U-Net架构上或为文本到图像任务设计。直接应用这些方法会导致局部纹理严重退化。", "method": "提出了一种分层SVD方法H-SVD，结合全局低秩分支和局部块级秩1分支，在匹配参数预算下集成。还提出了基于率失真理论的数据无关跨层权重比特宽度分配VaSMP以及通过动态规划（DP）在不同扩散时间步长内调度内部层激活精度的VaTMP。", "result": "实验证明，Q-DiT4SR在多个真实数据集上取得了SOTA性能，在W4A6和W4A4配置下。特别是W4A4量化减少了模型大小5.8倍，计算量超过60倍。", "conclusion": "提出的方法有效地实现了基于扩散变换器的图像超分辨率任务中的后训练量化，并保持了高质量纹理，具有实际应用价值。"}}
{"id": "2602.01268", "pdf": "https://arxiv.org/pdf/2602.01268", "abs": "https://arxiv.org/abs/2602.01268", "authors": ["Jaehyeon Cho", "Jhonghyun An"], "title": "OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated Monocular Pseudo Depth", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted to ICRA 2026", "summary": "Recent monocular foundation models excel at zero-shot depth estimation, yet their outputs are inherently relative rather than metric, limiting direct use in robotics and autonomous driving. We leverage the fact that relative depth preserves global layout and boundaries: by calibrating it with sparse range measurements, we transform it into a pseudo metric depth prior. Building on this prior, we design a refinement network that follows the prior where reliable and deviates where necessary, enabling accurate metric predictions from very few labeled samples. The resulting system is particularly effective when curated validation data are unavailable, sustaining stable scale and sharp edges across few-shot regimes. These findings suggest that coupling foundation priors with sparse anchors is a practical route to robust, deployment-ready depth completion under real-world label scarcity.", "AI": {"tldr": "通过输出级别的对齐将稀疏集成的单目伪深度转变为准确的度量深度预测。", "motivation": "近期单目基础模型在零样本深度估计中表现出色，但其输出本质上是相对而非绝对的深度，限制了它直接用于机器人和自主驾驶等应用。作者利用相对深度保持全局布局和边界的特点，并通过校准得到伪度量深度先验。", "method": "基于此先验设计了一个细化网络，在可靠区域跟随先验并在必要时偏离先验，从而在非常少的标注样本情况下做出准确的度量预测。", "result": "该系统在没有经过策划验证数据的情况下特别有效，并能够跨少量样本保持稳定的尺度和锐利边缘。", "conclusion": "将基础模型先验与稀疏锚点结合是在现实世界标签稀缺条件下实现稳健、部署就绪深度完成的一种实用途径。"}}
{"id": "2602.01266", "pdf": "https://arxiv.org/pdf/2602.01266", "abs": "https://arxiv.org/abs/2602.01266", "authors": ["Grzegorz Malczyk", "Mihir Kulkarni", "Kostas Alexis"], "title": "Reinforcement Learning for Active Perception in Autonomous Navigation", "categories": ["cs.RO"], "comment": "Accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "This paper addresses the challenge of active perception within autonomous navigation in complex, unknown environments. Revisiting the foundational principles of active perception, we introduce an end-to-end reinforcement learning framework in which a robot must not only reach a goal while avoiding obstacles, but also actively control its onboard camera to enhance situational awareness. The policy receives observations comprising the robot state, the current depth frame, and a particularly local geometry representation built from a short history of depth readings. To couple collision-free motion planning with information-driven active camera control, we augment the navigation reward with a voxel-based information metric. This enables an aerial robot to learn a robust policy that balances goal-directed motion with exploratory sensing. Extensive evaluation demonstrates that our strategy achieves safer flight compared to using fixed, non-actuated camera baselines while also inducing intrinsic exploratory behaviors.", "AI": {"tldr": "本文提出了一种基于强化学习的框架，使机器人在复杂未知环境中既能达到目标又能避开障碍物，并能主动控制其机载相机以增强环境感知。", "motivation": "为了提高自主导航中的活动感知能力，在复杂未知环境下，需要一种能够综合考虑避障和信息采集策略的方法来提升飞行安全性。", "method": "采用了一种结合碰撞避免规划与信息驱动的主动摄像机控制的强化学习框架。机器人接收包括其状态、当前深度帧及短期历史深度读取构建的地方几何表示在内的观测值，通过增强导航奖励中的体素信息度量实现了更安全的飞行。", "result": "实验评估表明，该策略比使用固定相机基线的方法在安全性方面有所提高，并且能够诱导出内在探索行为。", "conclusion": "通过强化学习框架的应用，不仅使机器人能够在复杂环境中实现避障和导航目标，还增强了其主动感知能力。"}}
{"id": "2602.01264", "pdf": "https://arxiv.org/pdf/2602.01264", "abs": "https://arxiv.org/abs/2602.01264", "authors": ["Jonatan Reyes", "Mina Massoumi", "Anil Ufuk Batmaz", "Marta Kersten-Oertel"], "title": "Shades of Uncertainty: How AI Uncertainty Visualizations Affect Trust in Alzheimer's Predictions", "categories": ["cs.HC"], "comment": null, "summary": "Artificial intelligence (AI) is increasingly used to support prognosis in Alzheimer's disease (AD), but adoption remains limited due to a lack of transparency and interpretability, particularly for long-term predictions where uncertainty is intrinsic and outcomes may not be known for years. We position uncertainty visualization as an explainable AI (XAI) technique and examine how it shapes trust, confidence, and reliance when users interpret AI-generated forecasts of future cognitive decline transitions. We conducted two studies, one with general participants (N=37) and one with experts in neuroimaging and neurology (N=10), to compare binary (present/absent) and continuous (saturation) uncertainty encodings. Continuous encodings improved perceived reliability and helped users recognize model limitations, while binary encodings increased momentary confidence, revealing expertise-dependent trade-offs in interpreting future predictions under high uncertainty. These findings surface key challenges in designing uncertainty representations for prognostic AI and culminate in a set of empirically grounded guidelines for creating trustworthy, user-appropriate clinical decision support tools.", "AI": {"tldr": "研究探讨了AI不确定性可视化在阿尔茨海默病预测中的影响，通过两种编码方式（二元和连续）对比分析用户信任度。", "motivation": "由于缺乏透明性和可解释性，尤其是在长期预测中固有的不确定性下，人工智能支持的诊断工具在实际应用中受到限制。研究希望通过可视化的手段增强AI系统的可信度。", "method": "进行了两项研究：一般参与者（N=37）和神经影像及神经学专家（N=10），比较了二元和连续不确定性编码对信任度、信心以及依赖程度的影响。", "result": "连续编码提高了用户感知的可靠性，帮助识别模型限制；而二元编码增加了即时信心。存在基于专业知识的不同解读。", "conclusion": "研究揭示了设计预测性AI不确定性的挑战，并提出了创建值得信赖、适合用户的临床决策支持工具的实际指导原则。"}}
{"id": "2602.01260", "pdf": "https://arxiv.org/pdf/2602.01260", "abs": "https://arxiv.org/abs/2602.01260", "authors": ["Soumyadeep Roy", "Shashwat Kushwaha", "Ambedkar Dukkipati"], "title": "Sample Efficient Active Algorithms for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) enables policy learning from static data but often suffers from poor coverage of the state-action space and distributional shift problems. This problem can be addressed by allowing limited online interactions to selectively refine uncertain regions of the learned value function, which is referred to as Active Reinforcement Learning (ActiveRL). While there has been good empirical success, no theoretical analysis is available in the literature. We fill this gap by developing a rigorous sample-complexity analysis of ActiveRL through the lens of Gaussian Process (GP) uncertainty modeling. In this respect, we propose an algorithm and using GP concentration inequalities and information-gain bounds, we derive high-probability guarantees showing that an $ε$-optimal policy can be learned with ${\\mathcal{O}}(1/ε^2)$ active transitions, improving upon the $Ω(1/ε^2(1-γ)^4)$ rate of purely offline methods. Our results reveal that ActiveRL achieves near-optimal information efficiency, that is, guided uncertainty reduction leads to accelerated value-function convergence with minimal online data. Our analysis builds on GP concentration inequalities and information-gain bounds, bridging Bayesian nonparametric regression and reinforcement learning theories. We conduct several experiments to validate the algorithm and theoretical findings.", "AI": {"tldr": "本文提出了一个利用高斯过程不确定性建模的高效样本复杂度分析，用于解决离线强化学习中的状态-动作空间覆盖率低和分布偏移问题。", "motivation": "离线强化学习可以通过静态数据进行策略学习，但通常会遇到状态-动作空间覆盖不足及分布偏移的问题。本文通过允许有限在线交互来改进这些问题。", "method": "利用高斯过程不确定性建模开发了理论分析，并提出了一个算法，使用高斯过程集中不等式和信息增益边界，推导出$ε$近似最优策略的学习保证。", "result": "该方法证明了通过引导不确定性减少可加速价值函数收敛，在最少在线数据的情况下达到接近最优的信息效率。实验结果验证了理论分析的正确性。", "conclusion": "研究提出的方法不仅在理论上具有高效样本复杂度，而且实验也展示了其优越性能，为离线强化学习领域提供了新的视角和方向。"}}
{"id": "2602.01257", "pdf": "https://arxiv.org/pdf/2602.01257", "abs": "https://arxiv.org/abs/2602.01257", "authors": ["Yunchuan Ma", "Laiyun Qing", "Guorong Li", "Yuqing Liu", "Yuankai Qi", "Qingming Huang"], "title": "Boosting Point-supervised Temporal Action Localization via Text Refinement and Alignment", "categories": ["cs.CV"], "comment": null, "summary": "Recently, point-supervised temporal action localization has gained significant attention for its effective balance between labeling costs and localization accuracy. However, current methods only consider features from visual inputs, neglecting helpful semantic information from the text side. To address this issue, we propose a Text Refinement and Alignment (TRA) framework that effectively utilizes textual features from visual descriptions to complement the visual features as they are semantically rich. This is achieved by designing two new modules for the original point-supervised framework: a Point-based Text Refinement module (PTR) and a Point-based Multimodal Alignment module (PMA). Specifically, we first generate descriptions for video frames using a pre-trained multimodal model. Next, PTR refines the initial descriptions by leveraging point annotations together with multiple pre-trained models. PMA then projects all features into a unified semantic space and leverages a point-level multimodal feature contrastive learning to reduce the gap between visual and linguistic modalities. Last, the enhanced multi-modal features are fed into the action detector for precise localization. Extensive experimental results on five widely used benchmarks demonstrate the favorable performance of our proposed framework compared to several state-of-the-art methods. Moreover, our computational overhead analysis shows that the framework can run on a single 24 GB RTX 3090 GPU, indicating its practicality and scalability.", "AI": {"tldr": "该论文提出了一种利用文本信息增强点监督下的时序动作定位的方法，通过设计PTR和PMA模块来提高定位精度。", "motivation": "当前的点监督方法仅依赖于视觉输入特征而忽略了文本中的语义信息。为此，本文提出了TRA框架以解决这一问题，旨在结合视频帧描述中丰富的语义信息增强动作定位。", "method": "提出了一种TR框架，包括PTR和PMA两个模块：PTR通过利用标注点和多预训练模型优化初始描述；PMA则将所有特征投影到统一的语义空间并进行对比学习。最后使用改进后的多模态特征输入动作检测器以提高定位准确性。", "result": "实验结果表明，TRA框架在五个广泛使用的基准数据集上优于多个SOTA方法，并且具有较高的计算效率和可扩展性。", "conclusion": "通过引入文本信息优化点监督下的时序动作定位问题，在保持较低计算成本的同时提高了定位精度。"}}
{"id": "2602.01247", "pdf": "https://arxiv.org/pdf/2602.01247", "abs": "https://arxiv.org/abs/2602.01247", "authors": ["Maryam Maghsoudi", "Ayushi Mishra"], "title": "Mechanistic Interpretability of Brain-to-Speech Models Across Speech Modes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Brain-to-speech decoding models demonstrate robust performance in vocalized, mimed, and imagined speech; yet, the fundamental mechanisms via which these models capture and transmit information across different speech modalities are less explored. In this work, we use mechanistic interpretability to causally investigate the internal representations of a neural speech decoder. We perform cross-mode activation patching of internal activations across speech modes, and use tri-modal interpolation to examine whether speech representations vary discretely or continuously. We use coarse-to-fine causal tracing and causal scrubbing to find localized causal structure, allowing us to find internal subspaces that are sufficient for cross-mode transfer. In order to determine how finely distributed these effects are within layers, we perform neuron-level activation patching. We discover that small but not distributed subsets of neurons, rather than isolated units, affect the cross-mode transfer. Our results show that speech modes lie on a shared continuous causal manifold, and cross-mode transfer is mediated by compact, layer-specific subspaces rather than diffuse activity. Together, our findings give a causal explanation for how speech modality information is organized and used in brain-to-speech decoding models, revealing hierarchical and direction-dependent representational structure across speech modes.", "AI": {"tldr": "论文通过机制可解释性方法研究了脑到语音解码模型在不同语音模式下的内部表示和信息传输方式。", "motivation": "探索脑到语音解码模型如何捕获并传递不同类型语音模态的信息，揭示其根本机制。", "method": "使用跨模式激活修补、三模式插值分析、粗细因果追踪及因果清洗等技术来研究内部子空间和神经元级激活修补，以发现影响跨模态传输的小而集中的神经元集合。", "result": "发现语音模式位于共享的连续因果流形上，跨模态传输由各层特定的紧凑子空间而非扩散活动介导。小但非孤立的单元格集合影响跨模式转移。", "conclusion": "该研究揭示了脑到语音解码模型中语音模态信息如何组织和使用的方式，展现了层级化和方向依赖性表示结构。"}}
{"id": "2602.01237", "pdf": "https://arxiv.org/pdf/2602.01237", "abs": "https://arxiv.org/abs/2602.01237", "authors": ["Katrina Brown", "Aneesh Muppidi", "Rana Shahout"], "title": "Predictive Scheduling for Efficient Inference-Time Reasoning in Large Language Models", "categories": ["cs.AI"], "comment": "ICML ES-FoMo 2025", "summary": "Large language models (LLMs) achieve state-of-the-art accuracy on complex reasoning tasks by generating multiple chain-of-thought (CoT) traces, but using a fixed token budget per query leads to over-computation on easy inputs and under-computation on hard ones. We introduce Predictive Scheduling, a plug-and-play framework that pre-runs lightweight predictors, an MLP on intermediate transformer hidden states or a LoRA-fine-tuned classifier on raw question text, to estimate each query's optimal reasoning length or difficulty before any full generation. Our greedy batch allocator dynamically distributes a fixed total token budget across queries to maximize expected accuracy. On the GSM8K arithmetic benchmark, predictive scheduling yields up to 7.9 percentage points of absolute accuracy gain over uniform budgeting at identical token cost, closing over 50\\% of the gap to an oracle with perfect foresight. A systematic layer-wise study reveals that middle layers (12 - 17) of the transformer carry the richest signals for size estimation. These results demonstrate that pre-run budget prediction enables fine-grained control of the compute-accuracy trade-off, offering a concrete path toward latency-sensitive, cost-efficient LLM deployments.", "AI": {"tldr": "预测调度框架通过预运行轻量级预测器来估计每个查询的理想推理长度，从而在大型语言模型中实现更高效的推断时间推理。", "motivation": "固定预算分配导致容易任务的过度计算和困难任务的不足计算。作者旨在通过引入预测调度框架解决这个问题，以提高计算效率并优化准确性。", "method": "该方法包括预运行轻量级MLP或LoRA微调分类器来估计查询的理想推理长度；动态批处理分配器根据固定预算在不同查询间分配令牌。", "result": "在GSM8K算术基准上，预测调度比统一预算分配提高了高达7.9个百分点的绝对准确度，并且实验揭示了中间层（12-17）携带最丰富的信号用于规模估计。", "conclusion": "结果表明预运行预算预测能实现细粒度的计算与准确性权衡控制，为延迟敏感和成本高效的大型语言模型部署提供了一条切实可行的道路。"}}
{"id": "2602.01233", "pdf": "https://arxiv.org/pdf/2602.01233", "abs": "https://arxiv.org/abs/2602.01233", "authors": ["Tianhao Miao", "Zhongyuan Bao", "Lejun Zhang"], "title": "Lotus: Efficient LLM Training by Randomized Low-Rank Gradient Projection with Adaptive Subspace Switching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training efficiency in large-scale models is typically assessed through memory consumption, training time, and model performance. Current methods often exhibit trade-offs among these metrics, as optimizing one generally degrades at least one of the others. Addressing this trade-off remains a central challenge in algorithm design. While GaLore enables memory-efficient training by updating gradients in a low-rank subspace, it incurs a comparable extra training time cost due to the Singular Value Decomposition(SVD) process on gradients. In this paper, we propose Lotus, a method that resolves this trade-off by simply modifying the projection process. We propose a criterion that quantifies the displacement of the unit gradient to enable efficient transitions between low-rank gradient subspaces. Experimental results indicate that Lotus is the most efficient method, achieving a 30% reduction in training time and a 40% decrease in memory consumption for gradient and optimizer states. Additionally, it outperforms the baseline method in both pre-training and fine-tuning tasks.", "AI": {"tldr": "本文提出了一种名为Lotus的方法，通过修改梯度投影过程来解决大规模模型训练效率中的内存消耗、训练时间和模型性能之间的权衡问题。", "motivation": "当前的训练方法在优化一个指标时往往会损害其他指标的表现。GaLore虽然可以通过低秩子空间更新梯度实现内存高效的训练，但其额外的SVD计算过程增加了训练时间成本。因此，需要一种新的方法来解决这一挑战。", "method": "Lotus提出了一种准则来量化单元梯度的位置变化，并实现了在低秩梯度子空间间的高效切换，以减少训练时间和内存消耗。", "result": "实验结果显示，相比基线方法，Lotus能够将训练时间缩短30%，并将梯度和优化器状态的内存消耗降低40%。同时，它在预训练和微调任务中也表现优越。", "conclusion": "Lotus通过改进梯度投影过程解决了大规模模型训练中的权衡问题，并且在多个评估指标上都表现出色。"}}
{"id": "2602.01232", "pdf": "https://arxiv.org/pdf/2602.01232", "abs": "https://arxiv.org/abs/2602.01232", "authors": ["Poonam Sharma", "Suman Banerjee"], "title": "Profit Maximization in Closed Social Networks", "categories": ["cs.SI", "cs.DS"], "comment": null, "summary": "Diffusion of information, innovation, and ideas is an important phenomenon in social networks. Information propagates through the network and reaches from one person to the next. In many settings, it is meaningful to restrict diffusion so that each node can spread information to only a limited number of its neighbors rather than to all of them. Such social networks are called closed social networks. In recent years, social media platforms have emerged as an effective medium for commercial entities, where the objective is to maximize profit. In this paper, we study the Profit Maximization in Closed Social Networks (PMCSN) problem in the context of viral marketing. The input to the problem is a closed social network and two positive integers $\\ell$ and $B$. The problem asks to select seed nodes within a given budget $B$; during the diffusion process, each node is restricted to choose at most $\\ell$ outgoing links for information diffusion; and the objective is to maximize the profit earned by the seed set. The PMCSN problem generalizes the Influence Maximization problem, which is NP-hard. We propose two solution approaches for PMCSN: a sampling-based approximate solution and a marginal-gain-based heuristic solution. We analyze the sample complexity, running time, and space requirements of the proposed approaches. We conduct experiments on real-world, publicly available social network datasets. The results show that the seed sets and diffusion links chosen by our methods yield higher profit than baseline methods. The implementation and data are available at \\texttt{https://github.com/PoonamSharma-PY/ClosedNetwork}.", "AI": {"tldr": "研究在有限扩散网络中的利润最大化问题，提出两种解决方法并验证其效果。", "motivation": "探讨封闭社交网络中信息传播的限制条件下的商业应用优化策略。", "method": "提出了基于采样的近似解决方案和边际收益启发式方案，并分析了样本复杂度、运行时间和空间需求。", "result": "实验证明，所提出的方法选择的种子节点集合和扩散链接能产生比基线方法更高的利润。", "conclusion": "通过实验表明，提出的策略能够有效提高封闭社交网络中的利润。"}}
{"id": "2602.01227", "pdf": "https://arxiv.org/pdf/2602.01227", "abs": "https://arxiv.org/abs/2602.01227", "authors": ["Zhanming Shen", "Zeyu Qin", "Jiaqi Hu", "Wentao Ye", "Hao Chen", "Xiaomeng Hu", "Haokai Xu", "Gang Chen", "Yi R. Fung", "Haobo Wang"], "title": "Supervised Fine-Tuning Needs to Unlock the Potential of Token Priority", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The transition from fitting empirical data to achieving true human utility is fundamentally constrained by a granularity mismatch, where fine-grained autoregressive generation is often supervised by coarse or uniform signals. This position paper advocates Token Priority as the essential bridge, formalizing Supervised Fine-Tuning (SFT) not as simple optimization but as a precise distribution reshaping process that aligns raw data with the ideal alignment manifold. We analyze recent breakthroughs through this unified lens, categorizing them into two distinct regimes: Positive Priority for noise filtration and Signed Priority for toxic modes unlearning. We revisit existing progress and limitations, identify key challenges, and suggest directions for future research.", "AI": {"tldr": "本文提出Token Priority作为监督微调(SFT)的关键概念，旨在解决生成任务中的粒度不匹配问题，并将其视为从原始数据到理想对齐流形的精确分布重塑过程。", "motivation": "当前的自回归生成模型在处理细粒度信息时受限于粗略或统一的监督信号，导致无法完全实现人类期望的效果。本文提出Token Priority作为一种桥梁，以解决这一根本性约束问题。", "method": "通过分类近期突破为正向优先级（用于噪声过滤）和有符号优先级（用于毒性模式学习），来重新审视现有进展及其局限性，并探讨未来的研究方向。", "result": "提出了Token Priority作为理论框架，分析了SFT的真实本质，并识别出关键挑战及未来研究路径。", "conclusion": "通过Token Priority的概念，能够更有效地指导监督微调过程，提高生成模型的准确性和实用性。"}}
{"id": "2602.01226", "pdf": "https://arxiv.org/pdf/2602.01226", "abs": "https://arxiv.org/abs/2602.01226", "authors": ["Aditya Shibu", "Marah Saleh", "Mohamed Al-Musleh", "Nidhal Abdulaziz"], "title": "SkySim: A ROS2-based Simulation Environment for Natural Language Control of Drone Swarms using Large Language Models", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Unmanned Aerial Vehicle (UAV) swarms offer versatile applications in logistics, agriculture, and surveillance, yet controlling them requires expert knowledge for safety and feasibility. Traditional static methods limit adaptability, while Large Language Models (LLMs) enable natural language control but generate unsafe trajectories due to lacking physical grounding. This paper introduces SkySim, a ROS2-based simulation framework in Gazebo that decouples LLM high-level planning from low-level safety enforcement. Using Gemini 3.5 Pro, SkySim translates user commands (e.g., \"Form a circle\") into spatial waypoints, informed by real-time drone states. An Artificial Potential Field (APF) safety filter applies minimal adjustments for collision avoidance, kinematic limits, and geo-fencing, ensuring feasible execution at 20 Hz. Experiments with swarms of 3, 10, and 30 Crazyflie drones validate spatial reasoning accuracy (100% across tested geometric primitives), real-time collision prevention, and scalability. SkySim empowers non-experts to iteratively refine behaviors, bridging AI cognition with robotic safety for dynamic environments. Future work targets hardware integration.", "AI": {"tldr": "开发了一种基于ROS2的SkySim仿真框架，用于使用大型语言模型实现无人机群自然语言控制。", "motivation": "传统静态方法难以适应复杂环境，大型语言模型虽然能够理解自然语言指令，但生成的轨迹缺乏物理基础可能导致不安全。因此需要一个既能处理高层规划又能保证低层安全性执行的方法。", "method": "开发了一个名为SkySim的基于ROS2和Gazebo的仿真框架，该框架使用大型语言模型将用户命令转换为飞行路径点，并通过人工势场法对这些路径进行调整以确保无人机安全地避开障碍物和其他限制条件。实验中分别测试了3架、10架以及30架Crazyflie无人机。", "result": "实验结果表明，SkySim框架能够准确地将自然语言指令转换为飞行路线，并且能够在实时环境中有效防止碰撞和超出地理围栏范围的情况发生，同时具有良好的可扩展性。", "conclusion": "这项工作证明了SkySim可以作为非专业人士进行无人机群行为迭代优化的有力工具，在动态环境中实现了AI认知与机器人安全性的结合。未来的研究将致力于实现硬件集成以进一步提高系统的实用性。"}}
{"id": "2602.01222", "pdf": "https://arxiv.org/pdf/2602.01222", "abs": "https://arxiv.org/abs/2602.01222", "authors": ["Shaoxiong Yang", "Junting Li", "Mengyuan Zhang", "Chao Li", "Wei Liu", "Jian Luan"], "title": "FutureMind: Equipping Small Language Models with Strategic Thinking-Pattern Priors via Adaptive Knowledge Distillation", "categories": ["cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Small Language Models (SLMs) are attractive for cost-sensitive and resource-limited settings due to their efficient, low-latency inference. However, they often struggle with complex, knowledge-intensive tasks that require structured reasoning and effective retrieval. To address these limitations, we propose FutureMind, a modular reasoning framework that equips SLMs with strategic thinking-pattern priors via adaptive knowledge distillation from large language models (LLMs). FutureMind introduces a dynamic reasoning pipeline composed of four key modules: Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance. This pipeline is augmented by three distinct retrieval paradigms that decompose complex queries into tractable subproblems, ensuring efficient and accurate retrieval execution. Extensive experiments on multi-hop QA benchmarks, including 2WikiMultihopQA, MuSiQue, Bamboogle, and Frames, demonstrate the superiority of FutureMind. It consistently outperforms strong baselines such as Search-o1, achieving state-of-the-art results under free training conditions across diverse SLM architectures and scales. Beyond empirical gains, our analysis reveals that the process of thinking-pattern distillation is restricted by the cognitive bias bottleneck between the teacher (LLMs) and student (SLMs) models. This provides new perspectives on the transferability of reasoning skills, paving the way for the development of SLMs that combine efficiency with genuine cognitive capability.", "AI": {"tldr": "提出FutureMind框架，通过自适应知识蒸馏增强小型语言模型的策略思考模式。", "motivation": "小型语言模型在成本敏感和资源受限环境下具有优势，但难以处理需要结构化推理的任务。为此，研究引入了新的框架以提高其能力。", "method": "设计了一个包括问题分析、逻辑推理、策略规划和检索指导四个模块的动态推理流水线，并通过三种不同的检索范式将其复杂查询分解为可管理的问题。", "result": "在多跳问答基准测试中，FutureMind显著超越了基线模型，显示出了其优越性。同时发现了知识蒸馏过程中的认知偏差瓶颈问题。", "conclusion": "FutureMind不仅提升了小型语言模型的性能，还揭示了推理技能传递的新视角，为开发兼具效率和真实认知能力的小型模型提供了新思路。"}}
{"id": "2602.01219", "pdf": "https://arxiv.org/pdf/2602.01219", "abs": "https://arxiv.org/abs/2602.01219", "authors": ["Qishuai Wen", "Zhiyuan Huang", "Xianghan Meng", "Wei He", "Chun-Guang Li"], "title": "MiTA Attention: Efficient Fast-Weight Scaling via a Mixture of Top-k Activations", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The attention operator in Transformers can be viewed as a two-layer fast-weight MLP, whose weights are dynamically instantiated from input tokens and whose width equals sequence length N. As the context extends, the expressive capacity of such an N-width MLP increases, but scaling its fast weights becomes prohibitively expensive for extremely long sequences. Recently, this fast-weight scaling perspective has motivated the Mixture-of-Experts (MoE) attention, which partitions the sequence into fast-weight experts and sparsely routes the tokens to them. In this paper, we elevate this perspective to a unifying framework for a wide range of efficient attention methods by interpreting them as scaling fast weights through routing and/or compression. Then we propose a compress-and-route strategy, which compresses the N-width MLP into a narrower one using a small set of landmark queries and constructs deformable experts by gathering top-k activated key-value pairs for each landmark query. We call this strategy a Mixture of Top-k Activations (MiTA), and refer to the resulting efficient mechanism as MiTA attention. Preliminary experiments on vision tasks demonstrate the promise of our MiTA attention and motivate further investigation on its optimization and broader applications in more challenging settings.", "AI": {"tldr": "提出了一种新的注意力机制MiTA，通过压缩和路由策略来有效扩展长序列的表达能力。", "motivation": "随着上下文的增加，基于Transformer的注意操作变得计算成本高昂。为解决这一问题，提出了结合压缩与路由方法的新框架以高效扩展快速权重。", "method": "引入了一种称为Mixture of Top-k Activations (MiTA) 的策略，通过选定的关键值对构建变形专家，并使用地标查询进行压缩和路由。", "result": "初步实验表明了MiTA注意力在视觉任务中的潜力，并进一步促进了优化研究及更多场景的应用探索。", "conclusion": "提出了MiTA注意机制以应对长序列下的计算挑战，并为未来更广泛的任务应用提供了可能性。"}}
{"id": "2602.01217", "pdf": "https://arxiv.org/pdf/2602.01217", "abs": "https://arxiv.org/abs/2602.01217", "authors": ["Lucas Lange", "Adrian Böttinger", "Victor Christen", "Anushka Vidanage", "Peter Christen", "Erhard Rahm"], "title": "Learning from Anonymized and Incomplete Tabular Data", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DB"], "comment": null, "summary": "User-driven privacy allows individuals to control whether and at what granularity their data is shared, leading to datasets that mix original, generalized, and missing values within the same records and attributes. While such representations are intuitive for privacy, they pose challenges for machine learning, which typically treats non-original values as new categories or as missing, thereby discarding generalization semantics. For learning from such tabular data, we propose novel data transformation strategies that account for heterogeneous anonymization and evaluate them alongside standard imputation and LLM-based approaches. We employ multiple datasets, privacy configurations, and deployment scenarios, demonstrating that our method reliably regains utility. Our results show that generalized values are preferable to pure suppression, that the best data preparation strategy depends on the scenario, and that consistent data representations are crucial for maintaining downstream utility. Overall, our findings highlight that effective learning is tied to the appropriate handling of anonymized values.", "AI": {"tldr": "本文研究了如何从匿名化和不完整的表格数据中进行有效学习。", "motivation": "用户驱动的隐私控制导致的数据集包含了原始值、泛化值及缺失值，这给机器学习带来了挑战。传统的处理方法通常无法保留泛化的语义信息。", "method": "提出了新颖的数据转换策略来应对不同类型匿名化数据，并与标准插补和LLM方法进行了对比评估。", "result": "研究表明：相比于完全删除的信息，泛化的值更有用；最佳的数据准备策略取决于具体场景；一致性的数据表示对保持下游任务的性能至关重要。", "conclusion": "本文强调了有效学习的关键在于正确处理匿名化信息。"}}
{"id": "2602.01215", "pdf": "https://arxiv.org/pdf/2602.01215", "abs": "https://arxiv.org/abs/2602.01215", "authors": ["Hadi Bakhshan", "Sima Farshbaf", "Junior Ramirez Machado", "Fernando Rastellini Canela", "Josep Maria Carbonell"], "title": "AI Meets Plasticity: A Comprehensive Survey", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "comment": null, "summary": "Artificial intelligence (AI) is rapidly emerging as a new paradigm of scientific discovery, namely data-driven science, across nearly all scientific disciplines. In materials science and engineering, AI has already begun to exert a transformative influence, making it both timely and necessary to examine its interaction with materials plasticity. In this study, we present a holistic survey of the convergence between AI and plasticity, highlighting state-of-the-art AI methodologies employed to discover, construct surrogate models for, and emulate the plastic behavior of materials. From a materials science perspective, we examine cause-and-effect relationships governing plastic deformation, including microstructural characterization and macroscopic responses described through plasticity constitutive models. From the perspective of AI methodology, we review a broad spectrum of applied approaches, ranging from frequentist techniques such as classical machine learning (ML), deep learning (DL), and physics-informed models to probabilistic frameworks that incorporate uncertainty quantification and generative AI methods. These data-driven approaches are discussed in the context of materials characterization and plasticity-related applications. The primary objective of this survey is to develop a comprehensive and well-organized taxonomy grounded in AI methodologies, with particular emphasis on distinguishing critical aspects of these techniques, including model architectures, data requirements, and predictive performance within the specific domain of materials plasticity. By doing so, this work aims to provide a clear road map for researchers and practitioners in the materials community, while offering deeper physical insight and intuition into the role of AI in advancing materials plasticity and characterization, an area of growing importance in the emerging AI-driven era.", "AI": {"tldr": "本文综述了人工智能与材料塑性之间的相互作用，涵盖了最新的人工智能方法在发现、构建材料塑性的替代模型以及模拟材料塑性行为方面的应用。", "motivation": "随着人工智能在材料科学和工程领域的影响日益增强，研究其与材料塑性的互动变得至关重要。本文旨在提供一个全面且有组织的基于人工智能的方法论分类，以期为研究人员和从业者提供清晰的研究路线图，并深入探讨人工智能在推进材料塑性和表征中的作用。", "method": "从材料科学的角度来看，本综述探讨了导致塑性变形的原因及效应关系，包括微观结构特征以及通过塑性构成模型描述的宏观响应。同时，本文还回顾了一系广泛的人工智能方法，从传统的机器学习、深度学习到物理信息模型和包含不确定性量化与生成AI的方法。", "result": "文章提出一个综合的人工智能方法分类体系，特别强调了这些技术的关键方面，包括模型架构、数据需求及在材料塑性领域的预测性能。", "conclusion": "本文为研究者和从业者提供了一条清晰的研究路线图，并深化了对人工智能在促进材料科学进步中的物理洞察力和直觉理解。"}}
{"id": "2602.01213", "pdf": "https://arxiv.org/pdf/2602.01213", "abs": "https://arxiv.org/abs/2602.01213", "authors": ["Jungmin Lee", "Inhee Cho", "Youngjae Yoo"], "title": "LeagueBot: A Voice LLM Companion of Cognitive and Emotional Support for Novice Players in Competitive Games", "categories": ["cs.HC"], "comment": null, "summary": "Competitive games pose steep learning curves and strong social pressures, often discouraging novice players and limiting sustained engagement. To address these challenges, this study introduces LeagueBot, a large language model-based voice chatbot designed to provide both informational and emotional support during live gameplay in league of legends, one of the most competitive multiplayer online battle arena games. In a within-subjects experiment with 33 novice players, LeagueBot was found to reduce cognitive challenge, performative challenge, and perceived tension. Qualitative analysis further identified three themes: enhanced access to game information, relief from cognitive burden, and practical limitations. Participants noted that LeagueBot offered context-appropriate guidance and emotional support, helping ease the steep learning curve and psychological pressures of competitive gaming. Together, these findings underscore the potential of voice-based LLM companions to assist novice players in competitive environments and highlight their broader applicability for real-time support in other high-pressure contexts.", "AI": {"tldr": "本研究介绍了LeagueBot，一个基于大语言模型的语音聊天机器人，在《英雄联盟》这类竞争激烈的多人在线战斗竞技场游戏中为新手玩家提供信息和情感支持。", "motivation": "为了应对电子竞技游戏中的陡峭学习曲线和社会压力，该研究旨在通过引入具有认知和情绪支持功能的语音聊天机器人来吸引并保持新手玩家的兴趣和参与度。", "method": "在一项包含33名新手玩家的实验中，使用LeagueBot进行现场游戏测试，并采用定性和定量分析方法评估其效果。", "result": "实验结果显示，LeagueBot能够降低认知挑战、表演挑战和感知压力。参与者反馈称，该机器人提供了及时的信息指导和支持，有助于缓解学习曲线和心理压力。", "conclusion": "研究结果表明，在竞争性游戏环境中使用基于大语言模型的语音助手可以有效支持新手玩家，并在其他高压情境下具有广泛的应用前景。"}}
{"id": "2602.01212", "pdf": "https://arxiv.org/pdf/2602.01212", "abs": "https://arxiv.org/abs/2602.01212", "authors": ["Marco Chen", "Xianbiao Qi", "Yelin He", "Jiaquan Ye", "Rong Xiao"], "title": "SimpleGPT: Improving GPT via A Simple Normalization Strategy", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "We propose SimpleGPT, a simple yet effective GPT model, and provide theoretical insights into its mathematical foundations. We validate our theoretical findings through extensive experiments on large GPT models at parameter scales 1B, 1.4B, 7B and 8B", "summary": "In this work, we revisit Transformer optimization through the lens of second-order geometry and establish a direct connection between architectural design, activation scale, the Hessian matrix, and the maximum tolerable learning rate. We introduce a simple normalization strategy, termed SimpleNorm, which stabilizes intermediate activation scales by construction. Then, by analyzing the Hessian of the loss with respect to network activations, we theoretically show that SimpleNorm significantly reduces the spectral norm of the Hessian, thereby permitting larger stable learning rates. We validate our theoretical findings through extensive experiments on large GPT models at parameter scales 1B, 1.4B, 7B and 8B. Empirically, SimpleGPT, our SimpleNorm-based network, tolerates learning rates 3$\\times$-10$\\times$ larger than standard convention, consistently demonstrates strong optimization stability, and achieves substantially better performance than well-established baselines. Specifically, when training 7B-scale models for 60K steps, SimpleGPT achieves a training loss that is 0.08 lower than that of LLaMA2 with QKNorm, reducing the loss from 2.290 to 2.208. Our source code will be released at https://github.com/Ocram7/SimpleGPT.", "AI": {"tldr": "通过引入SimpleNorm简化归一化策略，改善大型GPT模型的训练稳定性与性能。", "motivation": "旨在改进Transformer优化方法，通过分析激活尺度和Hessian矩阵之间的关系来增加稳定的学习率上限。", "method": "提出一种新的简单归一化技术SimpleNorm，并在不同规模参数的GPT模型上进行实验验证。", "result": "实证结果表明，使用SimpleGPT训练得到的模型比标准方法具有更高的学习率稳定性且性能更优，特别是在70亿参数量级上的表现尤为突出。", "conclusion": "提出的方法不仅理论上有优势，在实践中也取得了显著效果。"}}
{"id": "2602.01207", "pdf": "https://arxiv.org/pdf/2602.01207", "abs": "https://arxiv.org/abs/2602.01207", "authors": ["Hui Wu", "Hengyi Cai", "Jinman Zhao", "Xinran Chen", "Ziheng Li", "Zhejun Zhao", "Shuaiqiang Wang", "Yuchen Li", "Dawei Yin"], "title": "Not All Preferences Are Created Equal: Stability-Aware and Gradient-Efficient Alignment for Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Preference-based alignment is pivotal for training large reasoning models; however, standard methods like Direct Preference Optimization (DPO) typically treat all preference pairs uniformly, overlooking the evolving utility of training instances. This static approach often leads to inefficient or unstable optimization, as it wastes computation on trivial pairs with negligible gradients and suffers from noise induced by samples near uncertain decision boundaries. Facing these challenges, we propose SAGE (Stability-Aware Gradient Efficiency), a dynamic framework designed to enhance alignment reliability by maximizing the Signal-to-Noise Ratio of policy updates. Concretely, SAGE integrates a coarse-grained curriculum mechanism that refreshes candidate pools based on model competence with a fine-grained, stability-aware scoring function that prioritizes informative, confident errors while filtering out unstable samples. Experiments on multiple mathematical reasoning benchmarks demonstrate that SAGE significantly accelerates convergence and outperforms static baselines, highlighting the critical role of policy-aware, stability-conscious data selection in reasoning alignment.", "AI": {"tldr": "本文提出了一种新的偏好对齐方法SAGE，旨在提高大型推理模型训练的稳定性和效率。", "motivation": "现有的直接偏好优化（DPO）等方法在处理所有偏好对时采用静态策略，忽略了不同样本之间效用的不同。这种做法可能导致计算浪费和不稳定，因为部分偏好对产生的梯度非常小且噪声大。", "method": "SAGE通过集成粗粒度的课程机制来动态刷新候选池，并使用细粒度、稳定性感知评分函数优先处理信息量大、置信度高的错误样本，同时过滤不稳定的样本。", "result": "在多个数学推理基准上进行的实验表明，SAGE能够显著加速收敛速度并优于静态基线方法。", "conclusion": "政策意识和稳定性考虑的数据选择对于提高偏好对齐的有效性至关重要。"}}
{"id": "2602.01206", "pdf": "https://arxiv.org/pdf/2602.01206", "abs": "https://arxiv.org/abs/2602.01206", "authors": ["Zeinab Dehghani"], "title": "Addressing Explainability of Generative AI using SMILE (Statistical Model-agnostic Interpretability with Local Explanations)", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of generative artificial intelligence has enabled models capable of producing complex textual and visual outputs; however, their decision-making processes remain largely opaque, limiting trust and accountability in high-stakes applications. This thesis introduces gSMILE, a unified framework for the explainability of generative models, extending the Statistical Model-agnostic Interpretability with Local Explanations (SMILE) method to generative settings. gSMILE employs controlled perturbations of textual input, Wasserstein distance metrics, and weighted surrogate modelling to quantify and visualise how specific components of a prompt or instruction influence model outputs. Applied to Large Language Models (LLMs), gSMILE provides fine-grained token-level attribution and generates intuitive heatmaps that highlight influential tokens and reasoning pathways. In instruction-based image editing models, the exact text-perturbation mechanism is employed, allowing for the analysis of how modifications to an editing instruction impact the resulting image. Combined with a scenario-based evaluation strategy grounded in the Operational Design Domain (ODD) framework, gSMILE allows systematic assessment of model behaviour across diverse semantic and environmental conditions. To evaluate explanation quality, we define rigorous attribution metrics, including stability, fidelity, accuracy, consistency, and faithfulness, and apply them across multiple generative architectures. Extensive experiments demonstrate that gSMILE produces robust, human-aligned attributions and generalises effectively across state-of-the-art generative models. These findings highlight the potential of gSMILE to advance transparent, reliable, and responsible deployment of generative AI technologies.", "AI": {"tldr": "提出了一种用于生成模型的解释性框架gSMILE，旨在量化和可视化特定提示或指令如何影响模型输出。", "motivation": "随着生成式人工智能的发展，其决策过程变得不透明，限制了高风险应用中的信任和问责制。为了增强这种技术的信任度，作者提出了一个统一的可解释方法。", "method": "gSMILE采用控制文本输入扰动、Wasserstein距离度量以及加权替代模型来量化特定组件如何影响生成模型输出，适用于大型语言模型和指令型图像编辑模型。", "result": "实验显示，gSMILE能产生稳健且与人类一致的归因，并在多种最先进的生成式模型中表现良好。", "conclusion": "该研究展示了gSMILE提升透明度、可靠性和负责任地部署生成AI技术的巨大潜力。"}}
{"id": "2602.01202", "pdf": "https://arxiv.org/pdf/2602.01202", "abs": "https://arxiv.org/abs/2602.01202", "authors": ["Mingze Kong", "Zikun Qu", "Zhongquan Zhou", "Pengyu Liang", "Xiang Li", "Zhiwei Shang", "Zhi Hong", "Kaiyu Huang", "Zhiyong Wang", "Zhongxiang Dai"], "title": "Workflow-R1: Group Sub-sequence Policy Optimization for Multi-turn Workflow Construction", "categories": ["cs.AI"], "comment": null, "summary": "The rapid evolution of agentic workflows has demonstrated strong performance of LLM-based agents in addressing complex reasoning tasks. However, existing workflow optimization methods typically formulate workflow synthesis as a static, one-shot code-centric generation problem. This paradigm imposes excessive constraints on the model's coding capabilities and restricts the flexibility required for dynamic problem-solving. In this paper, we present Workflow-R1, a framework that reformulates workflow construction as a multi-turn, natural language-based sequential decision-making process. To resolve the optimization granularity mismatch inherent in such multi-turn interactions, we introduce Group Sub-sequence Policy Optimization (GSsPO). While explicitly tailored to align with the interleaved Think-Action dynamics of agentic reasoning, GSsPO fundamentally functions as a structure-aware RL algorithm generalizable to a broad class of multi-turn agentic sequential decision-making tasks. By recalibrating the optimization unit to the composite sub-sequence, specifically the atomic Think-Action cycle, it aligns gradient updates with the semantic boundaries of these interactions, ensuring robust learning in complex multi-turn reasoning tasks. Through extensive experiments on multiple QA benchmarks, Workflow-R1 outperforms competitive baselines, validating GSsPO as a generalized solution for sequential reasoning and establishing Workflow-R1 as a promising new paradigm for automated workflow optimization.", "AI": {"tldr": "论文提出了Workflow-R1框架，该框架通过多轮自然语言决策过程来优化工作流构建，并引入了组子序列策略优化（GSsPO）算法，以解决现有方法中的粒度不匹配问题。", "motivation": "现有的工作流优化方法将工作流合成视为静态的一次性代码生成任务。这种范式限制了模型的编码能力并减少了动态问题解决所需的灵活性。", "method": "论文提出了一种框架Workflow-R1，通过多轮自然语言决策过程来构建工作流，并引入了一种名为组子序列策略优化（GSsPO）的新方法。这种方法能够重新校准优化单元到复合子序列，即原子的思考-行动循环，从而确保复杂的多回合推理任务中的稳健学习。", "result": "通过在多个问答基准上的广泛实验，Workflow-R1超越了竞争基线，验证了GSsPO作为顺序推理通用解决方案的有效性，并确立了Workflow-R1作为自动化工作流优化的新范式的潜力。", "conclusion": "该论文提出了一种新的多轮自然语言决策过程框架来优化工作流构建，并通过实验表明这种方法能够有效地解决复杂的问题。"}}
{"id": "2602.01201", "pdf": "https://arxiv.org/pdf/2602.01201", "abs": "https://arxiv.org/abs/2602.01201", "authors": ["Lingyu Du", "Xucong Zhang", "Guohao Lan"], "title": "Talk to Me, Not the Slides: A Real-Time Wearable Assistant for Improving Eye Contact in Presentations", "categories": ["cs.HC"], "comment": null, "summary": "Effective eye contact is a cornerstone of successful public speaking. It strengthens the speaker's credibility and fosters audience engagement. Yet, managing effective eye contact is a skill that demands extensive training and practice, often posing a significant challenge for novice speakers. In this paper, we present SpeakAssis, the first real-time, in-situ wearable system designed to actively assist speakers in maintaining effective eye contact during live presentations. Leveraging a head-mounted eye tracker for gaze and scene view capture, SpeakAssis continuously monitors and analyzes the speaker's gaze distribution across audience and non-audience regions. When ineffective eye-contact patterns are detected, such as insufficient eye contact, or neglect of certain audience segments, SpeakAssis provides timely, context-aware audio prompts via an earphone to guide the speaker's gaze behavior. We evaluate SpeakAssis through a user study involving eight speakers and 24 audience members. Quantitative results show that SpeakAssis increases speakers' eye-contact duration by 62.5% on average and promotes a more balanced distribution of visual attention. Additionally, statistical analysis based on audience surveys reveals that improvements in speaker's eye-contact behavior significantly enhance the audience's perceived engagement and interactivity during presentations.", "AI": {"tldr": "介绍SpeakAssis，一种用于改进演讲者在演示中有效眼神交流的实时可穿戴系统。", "motivation": "有效的目光接触是成功公众演讲的关键。但是，这种技能需要大量的训练和实践，对初学者来说是一个重大挑战。", "method": "利用头戴式眼动追踪设备捕捉演讲者的注视位置和场景视图，SpeakAssis能够连续监测并分析演讲者在观众与非观众区域之间的目光分布情况，并通过耳塞提供及时的、上下文相关的音频提示来指导演讲者的视线行为。", "result": "用户研究显示，SpeakAssis使演讲者的眼部接触时间平均增加了62.5%，并且促进了视觉注意力更均衡的分配。此外，基于听众调查的数据统计分析表明，在演讲中改进目光交流行为显著提高了观众感知到的参与度和互动性。", "conclusion": "SpeakAssis提供了一种有效的工具来帮助演讲者在演示过程中建立有效的眼神接触，并且证明了这种方式可以提高演讲的有效性和吸引力。"}}
{"id": "2602.01200", "pdf": "https://arxiv.org/pdf/2602.01200", "abs": "https://arxiv.org/abs/2602.01200", "authors": ["Haoran Lai", "Zihang Jiang", "Kun Zhang", "Qingsong Yao", "Rongsheng Wang", "Zhiyang He", "Xiaodong Tao", "Wei Wei", "Shaohua Kevin Zhou"], "title": "Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis", "categories": ["cs.CV"], "comment": null, "summary": "Developing 3D vision-language models with robust clinical reasoning remains a challenge due to the inherent complexity of volumetric medical imaging, the tendency of models to overfit superficial report patterns, and the lack of interpretability-aware reward designs. In this paper, we propose Med3D-R1, a reinforcement learning framework with a two-stage training process: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). During SFT stage, we introduce a residual alignment mechanism to bridge the gap between high-dimensional 3D features and textual embeddings, and an abnormality re-weighting strategy to emphasize clinically informative tokens and reduce structural bias in reports. In RL stage, we redesign the consistency reward to explicitly promote coherent, step-by-step diagnostic reasoning. We evaluate our method on medical multiple-choice visual question answering using two 3D diagnostic benchmarks, CT-RATE and RAD-ChestCT, where our model attains state-of-the-art accuracies of 41.92\\% on CT-RATE and 44.99\\% on RAD-ChestCT. These results indicate improved abnormality diagnosis and clinical reasoning and outperform prior methods on both benchmarks. Overall, our approach holds promise for enhancing real-world diagnostic workflows by enabling more reliable and transparent 3D medical vision-language systems.", "AI": {"tldr": "开发一种名为Med3D-R1的强化学习框架，用于提高三维医学影像视觉语言模型在异常诊断中的临床推理能力。", "motivation": "针对现有的3D医学影像视觉语言模型难以进行稳健的临床推理的问题，提出了一种新的方法来应对体积成像复杂性、模型过度拟合报告模式以及缺乏可解释性的奖励设计等挑战。", "method": "提出了一个两阶段训练过程的Med3D-R1框架：监督微调（SFT）和强化学习（RL）。在SFT阶段，引入残差对齐机制以连接高维3D特征与文本嵌入，并采用异常重新加权策略突出临床相关信息。在RL阶段，则重新设计一致性奖励来明确促进连贯的诊断推理。", "result": "在两个3D诊断基准数据集CT-RATE和RAD-ChestCT上的医学多项选择视觉问答评估中，该模型分别获得了41.92％和44.99％的最佳准确性。表明改进了异常诊断与临床推理，并优于其他方法。", "conclusion": "通过提高三维医学影像视觉语言系统的可靠性和透明度，整体上增强了现实世界中的诊断工作流程，有望在实际应用中发挥重要作用。"}}
{"id": "2602.01198", "pdf": "https://arxiv.org/pdf/2602.01198", "abs": "https://arxiv.org/abs/2602.01198", "authors": ["Liang Zhang", "Yu Zhao", "Longyue Wang", "Tianqi Shi", "Weihua Luo", "Kaifu Zhang", "Jinsong Su"], "title": "A State-Transition Framework for Efficient LLM Reasoning", "categories": ["cs.AI"], "comment": "ICLR 2026", "summary": "While Long Chain-of-Thought (CoT) reasoning significantly improves Large Language Models (LLMs) performance on complex reasoning tasks, the substantial computational and memory costs of generating long CoT sequences limit their efficiency and practicality. Existing studies usually enhance the reasoning efficiency of LLMs by compressing CoT sequences. However, this approach conflicts with test-time scaling, limiting the reasoning capacity of LLMs. In this paper, we propose an efficient reasoning framework that models the reasoning process of LLMs as a state-transition process. Specifically, we first apply a linear attention mechanism to estimate the LLM's reasoning state, which records the historical reasoning information from previous reasoning steps. Then, based on the query prompt and the reasoning state, the LLM can efficiently perform the current reasoning step and update the state. With the linear attention, each token in the current reasoning step can directly retrieve relevant historical reasoning information from the reasoning state, without explicitly attending to tokens in previous reasoning steps. In this way, the computational complexity of attention is reduced from quadratic to linear, significantly improving the reasoning efficiency of LLMs. In addition, we propose a state-based reasoning strategy to mitigate the over-thinking issue caused by noisy reasoning steps. Extensive experiments across multiple datasets and model sizes demonstrate that our framework not only improves the reasoning efficiency of LLMs but also enhances their reasoning performance.", "AI": {"tldr": "本文提出了一种状态转换框架，用于提高大型语言模型在复杂推理任务中的效率。", "motivation": "虽然长链思维显著提升了LLM在复杂推理任务上的性能，但生成长链序列的计算和内存成本限制了其效率。现有方法通过压缩链来提升效率，但这会降低测试时扩展性，从而影响推理能力。", "method": "本文提出了一种基于线性注意力机制的状态转换框架，用以估计模型的历史推理状态，并在每一步中直接从状态检索相关历史信息，减少了计算复杂度。此外还提出了状态基础的推理策略来缓解噪音导致的过度思考问题。", "result": "实验结果表明该框架不仅提高了LLM的推理效率，而且增强了其推理性能。", "conclusion": "提出的状态转换框架是一种高效且有效的技术，能够在不牺牲推理质量的前提下提升大型语言模型在复杂任务上的处理能力。"}}
{"id": "2602.01194", "pdf": "https://arxiv.org/pdf/2602.01194", "abs": "https://arxiv.org/abs/2602.01194", "authors": ["Hao Chen", "Tao Han", "Jie Zhang", "Song Guo", "Fenghua Ling", "Lei Bai"], "title": "EMFormer: Efficient Multi-Scale Transformer for Accumulative Context Weather Forecasting", "categories": ["cs.CV"], "comment": null, "summary": "Long-term weather forecasting is critical for socioeconomic planning and disaster preparedness. While recent approaches employ finetuning to extend prediction horizons, they remain constrained by the issues of catastrophic forgetting, error accumulation, and high training overhead. To address these limitations, we present a novel pipeline across pretraining, finetuning and forecasting to enhance long-context modeling while reducing computational overhead. First, we introduce an Efficient Multi-scale Transformer (EMFormer) to extract multi-scale features through a single convolution in both training and inference. Based on the new architecture, we further employ an accumulative context finetuning to improve temporal consistency without degrading short-term accuracy. Additionally, we propose a composite loss that dynamically balances different terms via a sinusoidal weighting, thereby adaptively guiding the optimization trajectory throughout pretraining and finetuning. Experiments show that our approach achieves strong performance in weather forecasting and extreme event prediction, substantially improving long-term forecast accuracy. Moreover, EMFormer demonstrates strong generalization on vision benchmarks (ImageNet-1K and ADE20K) while delivering a 5.69x speedup over conventional multi-scale modules.", "AI": {"tldr": "本文提出了一种新型的多尺度转换器（EMFormer）和累积上下文微调方法，用于改善长时间天气预报。", "motivation": "现有的长时天气预测方法在扩展预测范围时仍受到灾难性遗忘、误差积累和高训练开销等问题限制。为了克服这些问题，本文提出了一个新流程来改进长时间建模并减少计算开销。", "method": "首先引入了EMFormer架构以通过单次卷积抽取多尺度特征；其次使用累积上下文微调提升时间一致性而不降低短期准确性，并提出了一种动态平衡不同项的复合损失函数，从而在整个预训练和微调过程中引导优化轨迹。", "result": "实验结果表明该方法在天气预测和极端事件预测中表现出色，显著提高了长时预报精度；同时EMFormer还在视觉基准测试（ImageNet-1K和ADE20K）上展示了强大的泛化能力并提供了5.69倍的速度提升。", "conclusion": "本文提出的方法能够有效改善长时间天气预报的准确性，并且在其他视觉任务中也表现出色，具有广泛的应用前景。"}}
{"id": "2602.01193", "pdf": "https://arxiv.org/pdf/2602.01193", "abs": "https://arxiv.org/abs/2602.01193", "authors": ["Shashini Nilukshi", "Deshan Sumanathilaka"], "title": "Bridging Lexical Ambiguity and Vision: A Mini Review on Visual Word Sense Disambiguation", "categories": ["cs.CL", "cs.CV"], "comment": "2 figures, 2 Tables, Accepted at IEEE TIC 2026", "summary": "This paper offers a mini review of Visual Word Sense Disambiguation (VWSD), which is a multimodal extension of traditional Word Sense Disambiguation (WSD). VWSD helps tackle lexical ambiguity in vision-language tasks. While conventional WSD depends only on text and lexical resources, VWSD uses visual cues to find the right meaning of ambiguous words with minimal text input. The review looks at developments from early multimodal fusion methods to new frameworks that use contrastive models like CLIP, diffusion-based text-to-image generation, and large language model (LLM) support. Studies from 2016 to 2025 are examined to show the growth of VWSD through feature-based, graph-based, and contrastive embedding techniques. It focuses on prompt engineering, fine-tuning, and adapting to multiple languages. Quantitative results show that CLIP-based fine-tuned models and LLM-enhanced VWSD systems consistently perform better than zero-shot baselines, achieving gains of up to 6-8\\% in Mean Reciprocal Rank (MRR). However, challenges still exist, such as limitations in context, model bias toward common meanings, a lack of multilingual datasets, and the need for better evaluation frameworks. The analysis highlights the growing overlap of CLIP alignment, diffusion generation, and LLM reasoning as the future path for strong, context-aware, and multilingual disambiguation systems.", "AI": {"tldr": "本文综述了视觉词语歧义消解（VWSD）的研究进展，探讨了从早期多模态融合方法到基于对比模型的新框架的发展。", "motivation": "传统单词意义消解依赖于文本和词汇资源，而VWSD通过引入视觉线索，在最小的文本输入下解决词义模糊的问题。此综述旨在展示该领域的技术进步及其挑战。", "method": "综述研究了2016年至2025年期间的技术发展，包括基于特征、图谱和对比嵌入的方法。它还强调了提示工程、微调以及对多种语言的支持。", "result": "定量结果显示，通过CLIP进行微调的模型以及与大型语言模型结合的VWSD系统，在均逆秩（MRR）方面比零样本基线高出6-8％。", "conclusion": "分析指出，未来的发展路径在于将CLIP对齐、扩散生成和大语言模型推理结合起来，以实现更强大的上下文感知和多语种消歧系统。"}}
{"id": "2602.01189", "pdf": "https://arxiv.org/pdf/2602.01189", "abs": "https://arxiv.org/abs/2602.01189", "authors": ["Astik Srivastava", "Thomas J Chackenkulam. Bitla Bhanu Teja", "Antony Thomas", "Madhava Krishna"], "title": "SPOT: Spatio-Temporal Obstacle-free Trajectory Planning for UAVs in an Unknown Dynamic Environment", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "We address the problem of reactive motion planning for quadrotors operating in unknown environments with dynamic obstacles. Our approach leverages a 4-dimensional spatio-temporal planner, integrated with vision-based Safe Flight Corridor (SFC) generation and trajectory optimization. Unlike prior methods that rely on map fusion, our framework is mapless, enabling collision avoidance directly from perception while reducing computational overhead. Dynamic obstacles are detected and tracked using a vision-based object segmentation and tracking pipeline, allowing robust classification of static versus dynamic elements in the scene. To further enhance robustness, we introduce a backup planning module that reactively avoids dynamic obstacles when no direct path to the goal is available, mitigating the risk of collisions during deadlock situations. We validate our method extensively in both simulation and real-world hardware experiments, and benchmark it against state-of-the-art approaches, showing significant advantages for reactive UAV navigation in dynamic, unknown environments.", "AI": {"tldr": "提出了一种用于未知环境中的四旋翼飞行器实时避障的时空轨迹规划方法。", "motivation": "为了实现在动态障碍物未知环境中飞行器的有效导航，提出了不需要地图融合直接从感知进行碰撞避免的方法。", "method": "采用4维时空规划结合基于视觉的安全飞行走廊生成和轨迹优化。通过视觉分割跟踪模块检测动态障碍并分类静态与动态元素，并引入备份计划模块来增强避障能力。", "result": "在仿真和实际硬件实验中验证了该方法的有效性，展示了比现有技术更高的实时导航性能。", "conclusion": "研究结果表明，所提出的方法显著提高了未知环境中飞行器的动态响应能力和安全性。"}}
{"id": "2602.01187", "pdf": "https://arxiv.org/pdf/2602.01187", "abs": "https://arxiv.org/abs/2602.01187", "authors": ["Chengran Yang", "Zichao Wei", "Heminghao Deng", "Jinfeng Jiang", "Zhensu Sun", "Ting Zhang", "Tianyi Wu", "Ming Wen", "David Lo"], "title": "Autoregressive, Yet Revisable: In Decoding Revision for Secure Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) based code generation is predominantly formulated as a strictly monotonic process, appending tokens linearly to an immutable prefix. This formulation contrasts to the cognitive process of programming, which is inherently interleaved with forward generation and on-the-fly revision. While prior works attempt to introduce revision via post-hoc agents or external static tools, they either suffer from high latency or fail to leverage the model's intrinsic semantic reasoning. In this paper, we propose Stream of Revision, a paradigm shift that elevates code generation from a monotonic stream to a dynamic, self-correcting trajectory by leveraging model's intrinsic capabilities. We introduce specific action tokens that enable the model to seamlessly backtrack and edit its own history within a single forward pass. By internalizing the revision loop, our framework Stream of Revision allows the model to activate its latent capabilities just-in-time without external dependencies. Empirical results on secure code generation show that Stream of Revision significantly reduces vulnerabilities with minimal inference overhead.", "AI": {"tldr": "本文提出了一种名为Stream of Revision的新框架，通过引入特定的动作令牌使模型能够在单次前向传递中回溯和编辑其历史记录，从而改善代码生成过程。", "motivation": "现有的基于大型语言模型的代码生成方法多为单调的过程，并且在修订上存在高延迟或未能充分利用模型内在语义推理的问题。本文旨在通过内部化修订循环来解决这些问题。", "method": "提出Stream of Revision框架，引入特定动作令牌使模型能够在单次前向传递中进行自我修正，减少外部依赖，同时保持最小的推断开销。", "result": "实验证明，与现有方法相比，在安全代码生成任务上使用Stream of Revision能显著降低漏洞数量，且不会带来额外的时间成本。", "conclusion": "通过内部化修订循环并利用模型内在的能力，新框架实现了更加动态和自我修正的代码生成过程，提高了安全性。"}}
{"id": "2602.01186", "pdf": "https://arxiv.org/pdf/2602.01186", "abs": "https://arxiv.org/abs/2602.01186", "authors": ["Fabio Turazza", "Marco Picone", "Marco Mamei"], "title": "The Gaussian-Head OFL Family: One-Shot Federated Learning from Client Global Statistics", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the International Conference on Learning Representations (ICLR) 2026", "summary": "Classical Federated Learning relies on a multi-round iterative process of model exchange and aggregation between server and clients, with high communication costs and privacy risks from repeated model transmissions. In contrast, one-shot federated learning (OFL) alleviates these limitations by reducing communication to a single round, thereby lowering overhead and enhancing practical deployability. Nevertheless, most existing one-shot approaches remain either impractical or constrained, for example, they often depend on the availability of a public dataset, assume homogeneous client models, or require uploading additional data or model information. To overcome these issues, we introduce the Gaussian-Head OFL (GH-OFL) family, a suite of one-shot federated methods that assume class-conditional Gaussianity of pretrained embeddings. Clients transmit only sufficient statistics (per-class counts and first/second-order moments) and the server builds heads via three components: (i) Closed-form Gaussian heads (NB/LDA/QDA) computed directly from the received statistics; (ii) FisherMix, a linear head with cosine margin trained on synthetic samples drawn in an estimated Fisher subspace; and (iii) Proto-Hyper, a lightweight low-rank residual head that refines Gaussian logits via knowledge distillation on those synthetic samples. In our experiments, GH-OFL methods deliver state-of-the-art robustness and accuracy under strong non-IID skew while remaining strictly data-free.", "AI": {"tldr": "本文提出了Gaussian-Head OFL（GH-OFL）方法，用于解决联邦学习中的多轮通信和隐私风险问题。", "motivation": "现有的单次联邦学习方法存在依赖公开数据集、假设同质客户端模型或需要上传额外信息等限制。为了解决这些问题，作者提出了一种基于高斯分布的单次联邦学习框架。", "method": "GH-OFL通过客户端仅传输类别统计量和服务器利用这些统计数据构建头来进行训练，包括三个部分：封闭形式高斯头部、FisherMix线性头部以及Proto-Hyper轻量级残差头部。", "result": "实验表明，该方法在非同质数据分布下具有卓越的准确性和鲁棒性，并且无需额外的数据。", "conclusion": "GH-OFL通过降低通信次数和避免隐私泄露风险提高了联邦学习的实际部署能力。"}}
{"id": "2602.01185", "pdf": "https://arxiv.org/pdf/2602.01185", "abs": "https://arxiv.org/abs/2602.01185", "authors": ["Fabio Turazza", "Marcello Pietri", "Marco Picone", "Marco Mamei"], "title": "FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "comment": "Author-accepted manuscript of a paper published in the 2025 IEEE 45th International Conference on Distributed Computing Systems Workshops (ICDCSW), pp. 760-770, doi: 10.1109/ICDCSW63273.2025.00136", "summary": "Privacy-Preserving Federated Learning (PPFL) is a Decentralized machine learning paradigm that enables multiple participants to collaboratively train a global model without sharing their data with the integration of cryptographic and privacy-based techniques to enhance the security of the global system. This privacy-oriented approach makes PPFL a highly suitable solution for training shared models in sectors where data privacy is a critical concern. In traditional FL, local models are trained on edge devices, and only model updates are shared with a central server, which aggregates them to improve the global model. However, despite the presence of the aforementioned privacy techniques, in the classical Federated structure, the issue of the server as a single-point-of-failure remains, leading to limitations both in terms of security and scalability. This paper introduces FedBGS, a fully Decentralized Blockchain-based framework that leverages Segmented Gossip Learning through Federated Analytics. The proposed system aims to optimize blockchain usage while providing comprehensive protection against all types of attacks, ensuring both privacy, security and non-IID data handling in Federated environments.", "AI": {"tldr": "本文介绍了FedBGS，一种基于区块链的去中心化联邦学习框架，使用分段闲聊学习进行联邦分析。", "motivation": "传统的联邦学习虽然集成了加密和隐私技术来增强系统的安全性，但仍然存在中央服务器作为单点故障的问题。因此，提出了一个完全去中心化的基于区块链的方法来解决这些问题，并确保在联邦环境中的全面保护。", "method": "FedBGS通过分段闲聊学习进行联邦分析，在优化区块链使用的同时提供对抗各种攻击的全面防护。", "result": "该系统能够提高隐私、安全性和非IID数据处理能力，但具体结果未详细描述。", "conclusion": "提出的FedBGS框架为去中心化的联邦学习提供了新的解决方案，提高了系统的安全性、隐私性以及对非IID数据的支持。"}}
{"id": "2602.01183", "pdf": "https://arxiv.org/pdf/2602.01183", "abs": "https://arxiv.org/abs/2602.01183", "authors": ["Chunming He", "Rihan Zhang", "Fengyang Xiao", "Dingming Zhang", "Zhiwen Cao", "Sina Farsiu"], "title": "Refining Context-Entangled Content Segmentation via Curriculum Selection and Anti-Curriculum Promotion", "categories": ["cs.CV", "cs.LG"], "comment": "8 figures, 11 tables", "summary": "Biological learning proceeds from easy to difficult tasks, gradually reinforcing perception and robustness. Inspired by this principle, we address Context-Entangled Content Segmentation (CECS), a challenging setting where objects share intrinsic visual patterns with their surroundings, as in camouflaged object detection. Conventional segmentation networks predominantly rely on architectural enhancements but often ignore the learning dynamics that govern robustness under entangled data distributions. We introduce CurriSeg, a dual-phase learning framework that unifies curriculum and anti-curriculum principles to improve representation reliability. In the Curriculum Selection phase, CurriSeg dynamically selects training data based on the temporal statistics of sample losses, distinguishing hard-but-informative samples from noisy or ambiguous ones, thus enabling stable capability enhancement. In the Anti-Curriculum Promotion phase, we design Spectral-Blindness Fine-Tuning, which suppresses high-frequency components to enforce dependence on low-frequency structural and contextual cues and thus strengthens generalization. Extensive experiments demonstrate that CurriSeg achieves consistent improvements across diverse CECS benchmarks without adding parameters or increasing total training time, offering a principled view of how progression and challenge interplay to foster robust and context-aware segmentation. Code will be released.", "AI": {"tldr": "本文提出了CurriSeg框架，通过课程选择和反课程推广来改进上下文纠缠内容分割的表示可靠性。", "motivation": "生物学习从简单的任务开始逐渐强化感知和鲁棒性。在处理对象与其背景共享内在视觉模式的问题时，传统分割网络主要依赖架构增强而忽视了学习动态。本文旨在通过引入CurriSeg框架改善这些情况。", "method": "CurriSeg包含两个阶段：课程选择阶段基于样本损失的时空统计动态选择训练数据；反课程推广阶段设计谱盲微调来抑制高频成分并强化对低频结构和上下文线索的依赖性。", "result": "实验结果显示，CurriSeg在多种CECS基准测试中均表现出一致的改进，并且不增加参数或总训练时间。", "conclusion": "本文展示了如何通过进度和挑战之间的互动促进稳健而具有上下文感知能力的分割。"}}
{"id": "2602.01173", "pdf": "https://arxiv.org/pdf/2602.01173", "abs": "https://arxiv.org/abs/2602.01173", "authors": ["Lancheng Gao", "Ziheng Jia", "Zixuan Xing", "Wei Sun", "Huiyu Duan", "Guangtao Zhai", "Xiongkuo Min"], "title": "EEmo-Logic: A Unified Dataset and Multi-Stage Framework for Comprehensive Image-Evoked Emotion Assessment", "categories": ["cs.CV"], "comment": null, "summary": "Understanding the multi-dimensional attributes and intensity nuances of image-evoked emotions is pivotal for advancing machine empathy and empowering diverse human-computer interaction applications. However, existing models are still limited to coarse-grained emotion perception or deficient reasoning capabilities. To bridge this gap, we introduce EEmoDB, the largest image-evoked emotion understanding dataset to date. It features $5$ analysis dimensions spanning $5$ distinct task categories, facilitating comprehensive interpretation. Specifically, we compile $1.2M$ question-answering (QA) pairs (EEmoDB-QA) from $125k$ images via automated generation, alongside a $36k$ dataset (EEmoDB-Assess) curated from $25k$ images for fine-grained assessment. Furthermore, we propose EEmo-Logic, an all-in-one multimodal large language model (MLLM) developed via instruction fine-tuning and task-customized group relative preference optimization (GRPO) with novel reward design. Extensive experiments demonstrate that EEmo-Logic achieves robust performance in in-domain and cross-domain datasets, excelling in emotion QA and fine-grained assessment. The code is available at https://anonymous.4open.science/r/EEmoLogic.", "AI": {"tldr": "提出了一种综合图像激发情绪评估的多阶段框架EEmo-Logic以及相关的大型数据集EEmoDB。", "motivation": "为了提高机器理解复杂和细微的情绪表达能力，克服现有模型在细粒度情感分析上的不足。", "method": "构建了EEmoDB数据集，并通过指令微调及任务定制的相对偏好优化（GRPO）方法训练了一个多模态大语言模型EEmo-Logic。", "result": "实验显示EEmo-Logic在领域内和跨领域的图像情绪评估中表现出色，优于现有基准。", "conclusion": "提出的方法为细粒度图像情感理解提供了有效解决方案。"}}
{"id": "2602.01171", "pdf": "https://arxiv.org/pdf/2602.01171", "abs": "https://arxiv.org/abs/2602.01171", "authors": ["Stefan Szeider"], "title": "ASP-Bench: From Natural Language to Logic Programs", "categories": ["cs.AI", "cs.CL", "cs.LO"], "comment": null, "summary": "Automating the translation of natural-language specifications into logic programs is a challenging task that affects neurosymbolic engineering. We present ASP-Bench, a benchmark comprising 128 natural language problem instances, 64 base problems with easy and hard variants. It evaluates systems that translate natural-language problems into Answer Set Programs (ASPs), a prominent form of logic programming. It provides systematic coverage of ASP features, including choice rules, aggregates, and optimization. Each problem includes reference validators that check whether solutions satisfy the problem specification. We characterize problems along seven largely independent reasoning aspects (optimization, temporal reasoning, default logic, resource allocation, recursion, spatial reasoning, and quantitative complexity), providing a multidimensional view of modeling difficulty. We test the benchmark using an agentic approach based on the ReAct (Reason and Act) framework, which achieves full saturation, demonstrating that feedback-driven iterative refinement with solver feedback provides a reliable and robust approach for modeling natural language in ASP. Our analysis across multiple agent runs enables us to gain insights into what determines a problem's modeling hardness.", "AI": {"tldr": "本文介绍了ASP-Bench，一个包含128个自然语言问题实例的基准测试集，评估将自然语言问题转换为回答集程序（ASP）系统的性能。", "motivation": "自动翻译自然语言规范到逻辑程序是一个挑战性的任务，影响神经符号工程的发展。需要一个全面覆盖ASP特征并系统化地评估各种推理难度的基准来推进该领域。", "method": "提出了ASP-Bench，包括64个基础问题及其简单和复杂变体，并通过参考验证器检查解决方案是否满足规范。基于ReAct框架进行测试以展示反馈驱动迭代精炼的有效性。", "result": "实验表明，基于反馈的迭代改进方法可以可靠且稳健地建模自然语言问题。", "conclusion": "通过对多个代理运行的分析获得对模型难度的理解，进一步推动了神经符号工程中的自动翻译技术的发展。"}}
{"id": "2602.01167", "pdf": "https://arxiv.org/pdf/2602.01167", "abs": "https://arxiv.org/abs/2602.01167", "authors": ["Zhiming Liu", "Yujie Wei", "Lei Feng", "Xiu Su", "Xiaobo Xia", "Weili Guan", "Zeke Xie", "Shuo Yang"], "title": "Do All Individual Layers Help? An Empirical Study of Task-Interfering Layers in Vision-Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Current VLMs have demonstrated capabilities across a wide range of multimodal tasks. Typically, in a pretrained VLM, all layers are engaged by default to make predictions on downstream tasks. We find that intervening on a single layer, such as by zeroing its parameters, can improve the performance on certain tasks, indicating that some layers hinder rather than help downstream tasks. We systematically investigate how individual layers influence different tasks via layer intervention. Specifically, we measure the change in performance relative to the base model after intervening on each layer and observe improvements when bypassing specific layers. This improvement can be generalizable across models and datasets, indicating the presence of Task-Interfering Layers that harm downstream tasks' performance. We introduce Task-Layer Interaction Vector, which quantifies the effect of intervening on each layer of a VLM given a task. These task-interfering layers exhibit task-specific sensitivity patterns: tasks requiring similar capabilities show consistent response trends under layer interventions, as evidenced by the high similarity in their task-layer interaction vectors. Inspired by these findings, we propose TaLo (Task-Adaptive Layer Knockout), a training-free, test-time adaptation method that dynamically identifies and bypasses the most interfering layer for a given task. Without parameter updates, TaLo improves performance across various models and datasets, including boosting Qwen-VL's accuracy on the Maps task in ScienceQA by up to 16.6%. Our work reveals an unexpected form of modularity in pretrained VLMs and provides a plug-and-play, training-free mechanism to unlock hidden capabilities at inference time. The source code will be publicly available.", "AI": {"tldr": "研究通过干预特定层来改善视觉语言模型在下游任务上的性能，发现了干扰性层的存在并提出了TaLo方法。", "motivation": "当前的VLM模型默认使用所有层级进行预测，但一些层级可能会阻碍而非帮助完成某些下游任务。研究旨在识别这些干扰性层次，并提高模型的表现。", "method": "通过零化特定层参数的方法来观察性能变化，提出Task-Layer Interaction Vector量化干预效果，开发了测试时适应方法TaLo来动态避开干扰性强的层。", "result": "实验结果表明，避开某些层级可以改善模型在多个任务上的表现，并且该方法可应用于不同的模型和数据集。", "conclusion": "研究揭示了预训练VLM中的意外模块化形式，并提供了一种无需额外训练即可解锁隐藏能力的方法。"}}
{"id": "2602.01166", "pdf": "https://arxiv.org/pdf/2602.01166", "abs": "https://arxiv.org/abs/2602.01166", "authors": ["Shuanghao Bai", "Jing Lyu", "Wanqi Zhou", "Zhe Li", "Dakai Wang", "Lei Xing", "Xiaoguang Zhao", "Pengwei Wang", "Zhongyuan Wang", "Cheng Chi", "Badong Chen", "Shanghang Zhang"], "title": "Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models benefit from chain-of-thought (CoT) reasoning, but existing approaches incur high inference overhead and rely on discrete reasoning representations that mismatch continuous perception and control. We propose Latent Reasoning VLA (\\textbf{LaRA-VLA}), a unified VLA framework that internalizes multi-modal CoT reasoning into continuous latent representations for embodied action. LaRA-VLA performs unified reasoning and prediction in latent space, eliminating explicit CoT generation at inference time and enabling efficient, action-oriented control. To realize latent embodied reasoning, we introduce a curriculum-based training paradigm that progressively transitions from explicit textual and visual CoT supervision to latent reasoning, and finally adapts latent reasoning dynamics to condition action generation. We construct two structured CoT datasets and evaluate LaRA-VLA on both simulation benchmarks and long-horizon real-robot manipulation tasks. Experimental results show that LaRA-VLA consistently outperforms state-of-the-art VLA methods while reducing inference latency by up to 90\\% compared to explicit CoT-based approaches, demonstrating latent reasoning as an effective and efficient paradigm for real-time embodied control. Project Page: \\href{https://loveju1y.github.io/Latent-Reasoning-VLA/}{LaRA-VLA Website}.", "AI": {"tldr": "提出了一种新的统一的视觉语言行动（VLA）框架LaRA-VLA，该框架在连续潜在表示中进行多模态链式思维推理和预测。", "motivation": "现有的VLA模型虽然受益于链式思维推理，但存在高推断开销且依赖离散推理表示与持续感知和控制不匹配的问题。为此提出了LaRA-VLA来解决这些问题。", "method": "通过引入基于课程的学习范例，逐步过渡到隐含推理，并最终适应条件生成动作的动态，实现潜在嵌入式推理。", "result": "实验表明LaRA-VLA在模拟基准测试和长周期现实机器人操纵任务中均优于现有的VLA方法，推断延迟减少高达90%。", "conclusion": "研究证明了隐含推理作为实时嵌入式控制的有效且高效范例。"}}
{"id": "2602.01163", "pdf": "https://arxiv.org/pdf/2602.01163", "abs": "https://arxiv.org/abs/2602.01163", "authors": ["Chunliang Hua", "Zeyuan Yang", "Lei Zhang", "Jiayang Sun", "Fengwen Chen", "Chunlan Zeng", "Xiao Hu"], "title": "Semantically Aware UAV Landing Site Assessment from Remote Sensing Imagery via Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Safe UAV emergency landing requires more than just identifying flat terrain; it demands understanding complex semantic risks (e.g., crowds, temporary structures) invisible to traditional geometric sensors. In this paper, we propose a novel framework leveraging Remote Sensing (RS) imagery and Multimodal Large Language Models (MLLMs) for global context-aware landing site assessment. Unlike local geometric methods, our approach employs a coarse-to-fine pipeline: first, a lightweight semantic segmentation module efficiently pre-screens candidate areas; second, a vision-language reasoning agent fuses visual features with Point-of-Interest (POI) data to detect subtle hazards. To validate this approach, we construct and release the Emergency Landing Site Selection (ELSS) benchmark. Experiments demonstrate that our framework significantly outperforms geometric baselines in risk identification accuracy. Furthermore, qualitative results confirm its ability to generate human-like, interpretable justifications, enhancing trust in automated decision-making. The benchmark dataset is publicly accessible at https://anonymous.4open.science/r/ELSS-dataset-43D7.", "AI": {"tldr": "本文提出了一种利用遥感图像和多模态大型语言模型进行全球上下文感知的无人机紧急着陆场地评估框架。", "motivation": "传统的几何传感器在识别平坦地形之外，无法理解复杂的语义风险（如人群、临时建筑）以确保安全的无人机紧急着陆。因此需要一种新的方法来综合视觉和语言信息进行全面的风险评估。", "method": "该方法首先通过轻量级的语义分割模块筛选候选区域，然后使用视觉-语言推理代理将视觉特征与POI数据融合检测潜在危害，形成从粗到细的处理流程。", "result": "实验表明，提出的框架在风险识别准确率上显著优于几何基线模型，并且能够生成类似人类理解和解释的理由，增强了自动决策的信任度。", "conclusion": "本文通过引入多模态大型语言模型和构建应急着陆场地选择基准数据集，展示了提高无人机紧急着陆安全性的潜力。"}}
{"id": "2602.01158", "pdf": "https://arxiv.org/pdf/2602.01158", "abs": "https://arxiv.org/abs/2602.01158", "authors": ["Daniel Yezid Guarnizo Orjuela", "Leonardo Scappatura", "Veronica Di Gennaro", "Riccardo Andrea Izzo", "Gianluca Bardaro", "Matteo Matteucci"], "title": "Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models have emerged as a dominant paradigm for generalist robotic manipulation, unifying perception and control within a single end-to-end architecture. However, despite their success in controlled environments, reliable real-world deployment is severely hindered by their fragility to visual disturbances. While existing literature extensively addresses physical occlusions caused by scene geometry, a critical mode remains largely unexplored: image corruptions. These sensor-level artifacts, ranging from electronic noise and dead pixels to lens contaminants, directly compromise the integrity of the visual signal prior to interpretation. In this work, we quantify this vulnerability, demonstrating that state-of-the-art VLAs such as $π_{0.5}$ and SmolVLA, suffer catastrophic performance degradation, dropping from 90\\% success rates to as low as 2\\%, under common signal artifacts. To mitigate this, we introduce the Corruption Restoration Transformer (CRT), a plug-and-play and model-agnostic vision transformer designed to immunize VLA models against sensor disturbances. Leveraging an adversarial training objective, CRT restores clean observations from corrupted inputs without requiring computationally expensive fine-tuning of the underlying model. Extensive experiments across the LIBERO and Meta-World benchmarks demonstrate that CRT effectively recovers lost performance, enabling VLAs to maintain near-baseline success rates, even under severe visual corruption.", "AI": {"tldr": "本文提出了一种用于恢复受干扰视觉输入的模型，以提高视觉语言动作模型在真实环境中的鲁棒性。", "motivation": "现有的视觉语言动作模型在面临图像干扰时表现不佳，需要一种方法来增强这些模型对传感器扰动的抵抗力。", "method": "引入了名为腐败恢复变换器（CRT）的模块化插件系统，利用对抗训练目标从受干扰输入中恢复干净观察数据。", "result": "实验表明，在LIBERO和Meta-World基准测试下，CRT能有效恢复性能，并使视觉语言动作模型在严重图像干扰情况下保持接近基线的成功率。", "conclusion": "通过引入 Corruption Restoration Transformer（CRT），提高了视觉语言动作模型的鲁棒性，使其能够更好地应对真实世界的挑战。"}}
{"id": "2602.01157", "pdf": "https://arxiv.org/pdf/2602.01157", "abs": "https://arxiv.org/abs/2602.01157", "authors": ["Mohammed Osman Gani", "Zhipeng He", "Chun Ouyang", "Sara Khalifa"], "title": "Multi-Horizon Electricity Price Forecasting with Deep Learning in the Australian National Electricity Market", "categories": ["cs.LG", "cs.AI"], "comment": "63 Pages", "summary": "Accurate electricity price forecasting (EPF) is essential for operational planning, trading, and flexible asset scheduling in liberalised power systems, yet remains challenging due to volatility, heavy-tailed spikes, and frequent regime shifts. While deep learning (DL) has been increasingly adopted in EPF to capture complex and nonlinear price dynamics, several important gaps persist: (i) limited attention to multi-day horizons beyond day-ahead forecasting, (ii) insufficient exploration of state-of-the-art (SOTA) time series DL models, and (iii) a predominant reliance on aggregated horizon-level evaluation that obscures time-of-day forecasting variation. To address these gaps, we propose a novel EPF framework that extends the forecast horizon to multi-day-ahead by systematically building forecasting models that leverage benchmarked SOTA time series DL models. We conduct a comprehensive evaluation to analyse time-of-day forecasting performance by integrating model assessment at intraday interval levels across all five regions in the Australian National Electricity Market (NEM). The results show that no single model consistently dominates across regions, metrics, and horizons. Overall, standard DL models deliver superior performance in most regions, while SOTA time series DL models demonstrate greater robustness to forecast horizon extension. Intraday interval-level evaluation reveals pronounced diurnal error patterns, indicating that absolute errors peak during the evening ramp, relative errors inflate during midday negative-price regimes, and directional accuracy degrades during periods of frequent trend changes. These findings suggest that future research on DL-based EPF can benefit from enriched feature representations and modelling strategies that enhance longer-term forecasting robustness while maintaining sensitivity to intraday volatility and structural price dynamics.", "AI": {"tldr": "提出了一个多日预测的电力价格预报框架，使用深度学习模型，并在澳大利亚国家电力市场中进行了综合评估。", "motivation": "准确的电价预测对于运营规划、交易和灵活资产调度至关重要。但是由于电力市场的波动性、尖峰事件以及频繁的状态转换，传统方法难以实现高精度预测。", "method": "通过结合最先进的时间序列深度学习模型来构建多日预报框架，并在澳大利亚国家电力市场中的五个地区进行了全面评估。", "result": "结果显示没有单一的模型能够在所有区域和时间段内均表现出色。标准深度学习模型在大多数情况下表现更好，而最新的时间序列深度学习模型则更能应对预测期的延长。", "conclusion": "这些发现表明未来的研究可以受益于增强特征表示和建模策略，以提高长期预测的稳健性并保持对日内波动性和结构性价格动态的敏感度。"}}
{"id": "2602.01156", "pdf": "https://arxiv.org/pdf/2602.01156", "abs": "https://arxiv.org/abs/2602.01156", "authors": ["Shunpeng Yang", "Ben Liu", "Hua Chen"], "title": "PolicyFlow: Policy Optimization with Continuous Normalizing Flow in Reinforcement Learning", "categories": ["cs.LG", "cs.RO"], "comment": "Submitted to ICLR 2026", "summary": "Among on-policy reinforcement learning algorithms, Proximal Policy Optimization (PPO) demonstrates is widely favored for its simplicity, numerical stability, and strong empirical performance. Standard PPO relies on surrogate objectives defined via importance ratios, which require evaluating policy likelihood that is typically straightforward when the policy is modeled as a Gaussian distribution. However, extending PPO to more expressive, high-capacity policy models such as continuous normalizing flows (CNFs), also known as flow-matching models, is challenging because likelihood evaluation along the full flow trajectory is computationally expensive and often numerically unstable. To resolve this issue, we propose PolicyFlow, a novel on-policy CNF-based reinforcement learning algorithm that integrates expressive CNF policies with PPO-style objectives without requiring likelihood evaluation along the full flow path. PolicyFlow approximates importance ratios using velocity field variations along a simple interpolation path, reducing computational overhead without compromising training stability. To further prevent mode collapse and further encourage diverse behaviors, we propose the Brownian Regularizer, an implicit policy entropy regularizer inspired by Brownian motion, which is conceptually elegant and computationally lightweight. Experiments on diverse tasks across various environments including MultiGoal, PointMaze, IsaacLab and MuJoCo Playground show that PolicyFlow achieves competitive or superior performance compared to PPO using Gaussian policies and flow-based baselines including FPO and DPPO. Notably, results on MultiGoal highlight PolicyFlow's ability to capture richer multimodal action distributions.", "AI": {"tldr": "提出了PolicyFlow算法，该算法在强化学习中使用连续归一化流进行策略优化。", "motivation": "解决PPO扩展到更复杂的高容量策略模型时的计算复杂性和数值不稳定性问题。", "method": "通过近似重要性比率来减少计算开销，并引入布朗运动正则器鼓励多样化行为，同时保持训练稳定性。", "result": "实验显示PolicyFlow在多个任务上表现优异或优于基准算法。", "conclusion": "PolicyFlow是一种有效的方法，能够在复杂任务中捕捉到更丰富多模态的动作分布。"}}
{"id": "2602.01155", "pdf": "https://arxiv.org/pdf/2602.01155", "abs": "https://arxiv.org/abs/2602.01155", "authors": ["Hugo Math", "Julian Lorenz", "Stefan Oelsner", "Rainer Lienhart"], "title": "Multi-Agent Causal Reasoning System for Error Pattern Rule Automation in Vehicles", "categories": ["cs.AI", "cs.SE"], "comment": "7 pages, 3 figures", "summary": "Modern vehicles generate thousands of different discrete events known as Diagnostic Trouble Codes (DTCs). Automotive manufacturers use Boolean combinations of these codes, called error patterns (EPs), to characterize system faults and ensure vehicle safety. Yet, EP rules are still manually handcrafted by domain experts, a process that is expensive and prone to errors as vehicle complexity grows. This paper introduces CAREP (Causal Automated Reasoning for Error Patterns), a multi-agent system that automatizes the generation of EP rules from high-dimensional event sequences of DTCs. CAREP combines a causal discovery agent that identifies potential DTC-EP relations, a contextual information agent that integrates metadata and descriptions, and an orchestrator agent that synthesizes candidate boolean rules together with interpretable reasoning traces. Evaluation on a large-scale automotive dataset with over 29,100 unique DTCs and 474 error patterns demonstrates that CAREP can automatically and accurately discover the unknown EP rules, outperforming LLM-only baselines while providing transparent causal explanations. By uniting practical causal discovery and agent-based reasoning, CAREP represents a step toward fully automated fault diagnostics, enabling scalable, interpretable, and cost-efficient vehicle maintenance.", "AI": {"tldr": "介绍了一种名为CAREP的多代理系统，用于自动从高维DTC事件序列中生成错误模式规则。", "motivation": "手动创建故障诊断规则既昂贵又容易出错，特别是在车辆复杂性增加的情况下。因此，需要一种自动化的方法来提高效率和准确性。", "method": "CAREP结合了因果发现代理、上下文信息代理以及协调器代理，通过合成候选布尔规则并提供可解释的推理痕迹实现错误模式规则的自动生成。", "result": "在具有29,100个独特DTC和474种错误模式的大规模汽车数据集上，CAREP能够自动准确地发现未知错误模式规则，优于仅基于LLM的方法，并提供透明的因果解释。", "conclusion": "CAREP通过结合实用的因果发现与代理化推理，实现了面向故障诊断的完全自动化。这为可扩展、可解释且成本效益高的车辆维护提供了可能。"}}
{"id": "2602.01153", "pdf": "https://arxiv.org/pdf/2602.01153", "abs": "https://arxiv.org/abs/2602.01153", "authors": ["Zhuo Chen", "Fei Ni", "Kaiyao Luo", "Zhiyuan Wu", "Xuyang Zhang", "Emmanouil Spyrakos-Papastavridis", "Lorenzo Jamone", "Nathan F. Lepora", "Jiankang Deng", "Shan Luo"], "title": "UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors", "categories": ["cs.RO"], "comment": null, "summary": "Force sensing is essential for dexterous robot manipulation, but scaling force-aware policy learning is hindered by the heterogeneity of tactile sensors. Differences in sensing principles (e.g., optical vs. magnetic), form factors, and materials typically require sensor-specific data collection, calibration, and model training, thereby limiting generalisability. We propose UniForce, a novel unified tactile representation learning framework that learns a shared latent force space across diverse tactile sensors. UniForce reduces cross-sensor domain shift by jointly modeling inverse dynamics (image-to-force) and forward dynamics (force-to-image), constrained by force equilibrium and image reconstruction losses to produce force-grounded representations. To avoid reliance on expensive external force/torque (F/T) sensors, we exploit static equilibrium and collect force-paired data via direct sensor--object--sensor interactions, enabling cross-sensor alignment with contact force. The resulting universal tactile encoder can be plugged into downstream force-aware robot manipulation tasks with zero-shot transfer, without retraining or finetuning. Extensive experiments on heterogeneous tactile sensors including GelSight, TacTip, and uSkin, demonstrate consistent improvements in force estimation over prior methods, and enable effective cross-sensor coordination in Vision-Tactile-Language-Action (VTLA) models for a robotic wiping task. Code and datasets will be released.", "AI": {"tldr": "UniForce是一种统一的触觉表示学习框架，旨在通过共享潜在线力量空间来解决不同触觉传感器之间的异质性问题。", "motivation": "现有方法在处理多样化触觉传感器时面临着挑战，因为不同的传感原理、形式因素和材料通常需要特定于每个传感器的数据收集、校准和模型训练。这限制了通用性的应用。", "method": "UniForce通过联合建模逆动力学（图像到力）和正向动力学（力到图像），并结合力平衡和图像重建损失来减少跨传感器域漂移，同时利用静态平衡直接从传感器-物体-传感器交互中收集力配对数据。", "result": "在GelSight、TacTip和uSkin等异构触觉传感器上的广泛实验表明，UniForce相比先前方法在力量估计上取得一致改进，并实现了有效的跨传感器协调。", "conclusion": "通过引入一种新颖的统一化方法来处理多样化触觉传感器的挑战，UniForce展示了其在力感知机器人操作任务中的零样本迁移能力。"}}
{"id": "2602.01150", "pdf": "https://arxiv.org/pdf/2602.01150", "abs": "https://arxiv.org/abs/2602.01150", "authors": ["Jialong Sun", "Zeming Wei", "Jiaxuan Zou", "Jiacheng Gong", "Guanheng Wang", "Chengyang Dong", "Jialong Li", "Bo Liu"], "title": "Statistical MIA: Rethinking Membership Inference Attack for Reliable Unlearning Auditing", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "math.OC"], "comment": null, "summary": "Machine unlearning (MU) is essential for enforcing the right to be forgotten in machine learning systems. A key challenge of MU is how to reliably audit whether a model has truly forgotten specified training data. Membership Inference Attacks (MIAs) are widely used for unlearning auditing, where samples that evade membership detection are often regarded as successfully forgotten. After carefully revisiting the reliability of MIA, we show that this assumption is flawed: failed membership inference does not imply true forgetting. We theoretically demonstrate that MIA-based auditing, when formulated as a binary classification problem, inevitably incurs statistical errors whose magnitude cannot be observed during the auditing process. This leads to overly optimistic evaluations of unlearning performance, while incurring substantial computational overhead due to shadow model training. To address these limitations, we propose Statistical Membership Inference Attack (SMIA), a novel training-free and highly effective auditing framework. SMIA directly compares the distributions of member and non-member data using statistical tests, eliminating the need for learned attack models. Moreover, SMIA outputs both a forgetting rate and a corresponding confidence interval, enabling quantified reliability of the auditing results. Extensive experiments show that SMIA provides more reliable auditing with significantly lower computational cost than existing MIA-based approaches. Notably, the theoretical guarantees and empirical effectiveness of SMIA suggest it as a new paradigm for reliable machine unlearning auditing.", "AI": {"tldr": "重新思考成员推断攻击（MIA）在可靠机器遗忘审计中的应用，提出一种新的无需训练的统计成员推断攻击（SMIA）框架。", "motivation": "传统基于MIAs的遗忘审计假设失败的成员检测意味着数据已被遗忘，但研究发现该假设存在缺陷，并且MIAs存在不可观测的统计误差和高计算开销问题。为了克服这些问题，提出了一种新的审计方法来提高可靠性和降低计算成本。", "method": "SMIA通过直接比较成员与非成员样本的数据分布，使用统计测试进行审计，无需训练攻击模型，能输出遗忘率及其置信区间。", "result": "实验表明，相比于现有的基于MIA的方法，SMIA提供了更加可靠的审计结果，并且具有显著更低的计算成本。", "conclusion": "理论保证和实验证明了SMIA作为可靠机器遗忘审计的新范式的有效性。"}}
{"id": "2602.01148", "pdf": "https://arxiv.org/pdf/2602.01148", "abs": "https://arxiv.org/abs/2602.01148", "authors": ["Jiaxuan Zou", "Yaozhong Xiong", "Yong Liu"], "title": "Capabilities and Fundamental Limits of Latent Chain-of-Thought", "categories": ["cs.AI", "cs.IT", "cs.LG", "math.OC"], "comment": null, "summary": "Latent Chain-of-Thought (Latent CoT) models promise efficient reasoning via continuous representations, yet exhibit puzzling performance inconsistencies: excelling at exploration (ProsQA: 97.0%) but failing at computation (GSM8K: 34.1%). We reveal that this trade-off is governed by decisional certainty. Our contributions are threefold: (1) We theoretically characterize the fundamental Exploration-Execution Trade-off, proving that high certainty enables precise execution but inhibits exploration, while low certainty facilitates search but causes error accumulation. (2) We introduce the Symbolic Index--quantifying decisional commitment--as the core mechanism governing this trade-off and establish its causal relationship with both execution stability and exploration capability. (3) We prove that curriculum learning is theoretically necessary, as direct training provably fails due to distributional mismatch. Our framework shifts the design paradigm from binary architectural choices toward adaptive systems that dynamically regulate decisional certainty based on task demands.", "AI": {"tldr": "研究论文探讨了潜在的链式思维模型在推理中的性能矛盾，并提出了一个理论框架来理解这一现象。", "motivation": "解释为什么潜在的链式思维模型在某些任务中表现出色，而在其他任务中却表现不佳。", "method": "引入决策确信度的概念，通过符号索引量化它，并证明课程学习是必要的。", "result": "揭示了探索与执行之间的权衡关系，并提出了适应性系统设计的新框架。", "conclusion": "论文提出了一种新的理论来理解潜在的链式思维模型的表现差异，并为未来的设计提供了指导。"}}
{"id": "2602.01147", "pdf": "https://arxiv.org/pdf/2602.01147", "abs": "https://arxiv.org/abs/2602.01147", "authors": ["Chenchen Feng", "Minyang Chen", "Zhuozhao Li", "Ran Cheng"], "title": "Unleashing the Potential of Differential Evolution through Individual-Level Strategy Diversity", "categories": ["cs.NE"], "comment": "Accepted by IEEE TEVC", "summary": "Since Differential Evolution (DE) is sensitive to strategy choice, most existing variants pursue performance through adaptive mechanisms or intricate designs. While these approaches focus on adjusting strategies over time, the structural benefits that static strategy diversity may bring remain largely unexplored. To bridge this gap, we study the impact of individual-level strategy diversity on DE's search dynamics and performance, and introduce iStratDE (DE with individual-level strategies), a minimalist variant that assigns mutation and crossover strategies independently to each individual at initialization and keeps them fixed throughout the evolutionary process. By injecting diversity at the individual level without adaptation or feedback, iStratDE cultivates persistent behavioral heterogeneity that is especially effective with large populations. Moreover, its communication-free construction possesses intrinsic concurrency, thereby enabling efficient parallel execution and straightforward scaling for GPU computing. We further provide a convergence analysis of iStratDE under standard reachability assumptions, which establishes the almost-sure convergence of the best-so-far fitness. Extensive experiments on the CEC2022 benchmark suite and robotic control tasks demonstrate that iStratDE matches or surpasses established adaptive DE variants. These results highlight individual-level strategy assignment as a straightforward yet effective mechanism for enhancing DE's performance. The source code of iStratDE is publicly accessible at: https://github.com/EMI-Group/istratde.", "AI": {"tldr": "研究个体层面策略多样性对差分进化（DE）搜索动态及性能的影响，并提出一个名为iStratDE的简化变体，该变体在初始化时独立为每个个体分配突变和交叉策略，并在整个演化过程中保持不变。", "motivation": "大多数现有的DE变种通过自适应机制或复杂设计来追求性能。然而，静态策略多样性所带来的结构优势尚未被充分探索。本文旨在填补这一空白，探讨个体层面的策略多样性对DE搜索动态及性能的影响。", "method": "提出iStratDE，在初始化时为每个个体分配独立的突变和交叉策略，并在整个演化过程中保持不变。这种方法通过在个体层面注入多样性而不使用自适应或反馈机制来培养持久的行为异质性，尤其适用于大规模种群。此外，其通信自由的设计具有固有的并发性，从而支持高效的并行执行以及GPU计算的简单扩展。", "result": "实验结果表明，iStratDE在CEC2022基准测试套件和机器人控制任务上的性能可与现有的自适应DE变种相匹配甚至超越。这些结果显示了个体层面策略分配作为提升DE性能的一种直接有效机制的重要性。", "conclusion": "通过引入个体层面的策略多样性，iStratDE能够显著提高差分进化的搜索效率和总体性能。这种方法提供了一种简单而有效的手段来增强DE的表现，并且该源代码已经公开以促进进一步的研究和发展。"}}
{"id": "2602.01146", "pdf": "https://arxiv.org/pdf/2602.01146", "abs": "https://arxiv.org/abs/2602.01146", "authors": ["Sidharth Pulipaka", "Oliver Chen", "Manas Sharma", "Taaha S Bajwa", "Vyas Raina", "Ivaxi Sheth"], "title": "PersistBench: When Should Long-Term Memories Be Forgotten by LLMs?", "categories": ["cs.AI"], "comment": "70 pages, 26 figures, under review", "summary": "Conversational assistants are increasingly integrating long-term memory with large language models (LLMs). This persistence of memories, e.g., the user is vegetarian, can enhance personalization in future conversations. However, the same persistence can also introduce safety risks that have been largely overlooked. Hence, we introduce PersistBench to measure the extent of these safety risks. We identify two long-term memory-specific risks: cross-domain leakage, where LLMs inappropriately inject context from the long-term memories; and memory-induced sycophancy, where stored long-term memories insidiously reinforce user biases. We evaluate 18 frontier and open-source LLMs on our benchmark. Our results reveal a surprisingly high failure rate across these LLMs - a median failure rate of 53% on cross-domain samples and 97% on sycophancy samples. To address this, our benchmark encourages the development of more robust and safer long-term memory usage in frontier conversational systems.", "AI": {"tldr": "PersistBench评估大型语言模型在长期记忆集成中的安全性风险，包括跨域泄露和记忆诱导的阿谀奉承。", "motivation": "研究发现将长期记忆与对话助手结合时存在被忽视的安全隐患，并提出衡量这些安全隐患的方法。", "method": "开发了一个基准测试PersistBench来评估18种前沿和开源的大规模语言模型在跨域泄露和记忆诱导的阿谀奉承方面的表现。", "result": "结果表明，大规模语言模型在这两类安全风险上的失败率分别为53%（跨域样本）和97%（阿谀奉承样本）。", "conclusion": "该研究揭示了长期记忆集成的安全隐患，并鼓励开发更稳健、安全的对话系统。"}}
{"id": "2602.01133", "pdf": "https://arxiv.org/pdf/2602.01133", "abs": "https://arxiv.org/abs/2602.01133", "authors": ["Yanbin Huang", "Man Yao", "Yuqi Pan", "Changze Lv", "Siyuan Xu", "Xiaoqing Zheng", "Bo Xu", "Guoqi Li"], "title": "Parallel Training in Spiking Neural Networks", "categories": ["cs.NE"], "comment": null, "summary": "The bio-inspired integrate-fire-reset mechanism of spiking neurons constitutes the foundation for efficient processing in Spiking Neural Networks (SNNs). Recent progress in large models demands that spiking neurons support highly parallel computation to scale efficiently on modern GPUs. This work proposes a novel functional perspective that provides general guidance for designing parallel spiking neurons. We argue that the reset mechanism, which induces complex temporal dependencies and hinders parallel training, should be removed. However, any such modification should satisfy two principles: 1) preserving the functions of reset as a core biological mechanism; and 2) enabling parallel training without sacrificing the serial inference ability of spiking neurons, which underpins their efficiency at test time. To this end, we identify the functions of the reset and analyze how to reconcile parallel training with serial inference, upon which we propose a dynamic decay spiking neuron. We conduct comprehensive testing of our method in terms of: 1) Training efficiency and extrapolation capability. On 16k-length sequences, we achieve a 25.6x training speedup over the pioneering parallel spiking neuron, and our models trained on 2k-length can stably perform inference on sequences as long as 30k. 2) Generality. We demonstrate the consistent effectiveness of the proposed method across five task categories (image classification, neuromorphic event processing, time-series forecasting, language modeling, and reinforcement learning), three network architectures (spiking CNN/Transformer/SSMs), and two spike activation modes (spike/integer activation). 3) Energy consumption. The spiking firing of our neuron is lower than that of vanilla and existing parallel spiking neurons.", "AI": {"tldr": "提出了动态衰减的脉冲神经元模型，以支持大规模脉冲神经网络在现代GPU上的高效并行训练和推理。", "motivation": "现有脉冲神经元机制中的复位过程影响了其并行训练的能力，并且需要同时满足生物学原理以及并行训练与串行推理之间的兼容性需求。", "method": "提出了一种动态衰减的脉冲神经元模型，通过移除复位机制来解决复杂的时间依赖性和并行训练障碍，该方法在保持生物机理功能的同时实现了高效的并行训练和串行推理能力。", "result": "实验表明所提方法具有较高的训练效率及外推能力，在16k长度序列上比先驱性的脉冲神经元模型快25.6倍，并且能够在30k长的序列上稳定地进行推理；该方法在五种任务类型、三种网络架构和两种激活模式下均表现出色，同时其能耗更低。", "conclusion": "通过移除复位机制并采用动态衰减策略设计了新型脉冲神经元模型，在保持生物学功能的同时实现了高效的并行训练与串行推理，从而为大规模SNN的开发提供了新的思路。"}}
{"id": "2602.01131", "pdf": "https://arxiv.org/pdf/2602.01131", "abs": "https://arxiv.org/abs/2602.01131", "authors": ["Yue Zhong", "Jiawen Kang", "Yongju Tong", "Hong-Ning Dai", "Dong In Kim", "Abbas Jamalipour", "Shengli Xie"], "title": "Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid expansion of the low-altitude economy, Unmanned Aerial Vehicles (UAVs) serve as pivotal aerial base stations supporting diverse services from users, ranging from latency-sensitive critical missions to bandwidth-intensive data streaming. However, the efficacy of such heterogeneous networks is often compromised by the conflict between limited onboard resources and stringent stability requirements. Moving beyond traditional throughput-centric designs, we propose a Sensing-Communication-Computing-Control closed-loop framework that explicitly models the impact of communication latency on physical control stability. To guarantee mission reliability, we leverage the Lyapunov stability theory to derive an intrinsic mapping between the state evolution of the control system and communication constraints, transforming abstract stability requirements into quantifiable resource boundaries. Then, we formulate the resource allocation problem as a Stackelberg game, where UAVs (as leaders) dynamically price resources to balance load and ensure stability, while users (as followers) optimize requests based on service urgency. Furthermore, addressing the prohibitive computational overhead of standard Deep Reinforcement Learning (DRL) on energy-constrained edge platforms, we propose a novel and lightweight pruning-based Proximal Policy Optimization (PPO) algorithm. By integrating a dynamic structured pruning mechanism, the proposed algorithm significantly compresses the neural network scale during training, enabling the UAV to rapidly approximate the game equilibrium with minimal inference latency. Simulation results demonstrate that the proposed scheme effectively secures control loop stability while maximizing system utility in dynamic low-altitude environments.", "AI": {"tldr": "本文提出了一种基于Lyapunov稳定性理论和轻量级修剪策略的Stackelberg博弈方法，用于在低空经济环境中优化无人机资源分配。", "motivation": "随着低空经济的发展，无人机作为关键的空中基站面临着资源限制与稳定性要求之间的矛盾。传统设计无法有效解决这一问题，因此本文旨在通过引入新的控制框架和算法来保证任务可靠性和系统效率。", "method": "提出了一种结合Lyapunov稳定性的闭环控制-通信计算一体化框架，并将其转化为Stackelberg博弈模型；同时开发了一种基于修剪的PPO算法以适应边缘设备的能量限制，提高了学习速度与资源利用效率。", "result": "仿真结果表明所提方案能在动态低空环境中有效保障控制系统稳定性并最大化系统效用。", "conclusion": "该方法成功地解决了无人机在低空经济环境下遇到的问题，并展示了其在复杂场景中的优越性。"}}
{"id": "2602.01127", "pdf": "https://arxiv.org/pdf/2602.01127", "abs": "https://arxiv.org/abs/2602.01127", "authors": ["Matej Suchanek", "Klara Janouskova", "Ondrej Vasatko", "Jiri Matas"], "title": "Koo-Fu CLIP: Closed-Form Adaptation of Vision-Language Models via Fukunaga-Koontz Linear Discriminant Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Visual-language models such as CLIP provide powerful general-purpose representations, but their raw embeddings are not optimized for supervised classification, often exhibiting limited class separation and excessive dimensionality. We propose Koo-Fu CLIP, a supervised CLIP adaptation method based on Fukunaga-Koontz Linear Discriminant Analysis, which operates in a whitened embedding space to suppress within-class variation and enhance between-class discrimination. The resulting closed-form linear projection reshapes the geometry of CLIP embeddings, improving class separability while performing effective dimensionality reduction, and provides a lightweight and efficient adaptation of CLIP representations. Across large-scale ImageNet benchmarks, nearest visual prototype classification in the Koo-Fu CLIP space improves top-1 accuracy from 75.1% to 79.1% on ImageNet-1K, with consistent gains persisting as the label space expands to 14K and 21K classes. The method supports substantial compression by up to 10-12x with little or no loss in accuracy, enabling efficient large-scale classification and retrieval.", "AI": {"tldr": "提出了一种基于Fukunaga-Koontz线性判别分析的视觉语言模型CLIP的闭式适应方法Koo-Fu CLIP，改善了分类性能。", "motivation": "原始的CLIP嵌入不优化用于监督分类，表现出有限的类别分离和过多维度。因此，需要一种新的方法来优化这些表示。", "method": "通过在白化嵌入空间中利用Fukunaga-Koontz线性判别分析，抑制类内变异性并增强类间鉴别力，形成闭式线性投影，重塑CLIP嵌入的几何形状，提高类别分离度，并进行有效的降维。", "result": "在大规模ImageNet基准测试中，最近视觉原型分类在Koo-Fu CLIP空间中的准确率从75.1%提升至79.1%，标签扩展到14K和21K类时仍保持一致增益。该方法支持高达10-12倍的压缩，并且在精度上几乎没有损失。", "conclusion": "Koo-Fu CLIP提供了一种轻量级高效的方法来优化CLIP表示，以实现更有效的分类和检索，同时保持高准确率并支持大规模压缩。"}}
{"id": "2602.01120", "pdf": "https://arxiv.org/pdf/2602.01120", "abs": "https://arxiv.org/abs/2602.01120", "authors": ["Youkang Wang", "Jian Wang", "Rubing Chen", "Tianyi Zeng", "Xiao-Yong Wei", "Qing Li"], "title": "MarkovScale: Towards Optimal Sequential Scaling at Inference Time", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "12 pages", "summary": "Sequential scaling is a prominent inference-time scaling paradigm, yet its performance improvements are typically modest and not well understood, largely due to the prevalence of heuristic, non-principled approaches that obscure clear optimality bounds. To address this, we propose a principled framework that models sequential scaling as a two-state Markov process. This approach reveals the underlying properties of sequential scaling and yields closed-form solutions for essential aspects, such as the specific conditions under which accuracy is improved and the theoretical upper, neutral, and lower performance bounds. Leveraging this formulation, we develop MarkovScale, a practical system that applies these optimality criteria to achieve a theoretically grounded balance between accuracy and efficiency. Comprehensive experiments across 3 backbone LLMs, 5 benchmarks, and over 20 configurations show that MarkovScale consistently outperforms state-of-the-art parallel and sequential scaling methods, representing a significant step toward optimal and resource-efficient inference in LLMs. The source code will be open upon acceptance at https://open-upon-acceptance.", "AI": {"tldr": "提出了一种基于两状态马尔可夫过程的框架，用于优化大型语言模型（LLM）在推理时间上的顺序缩放性能。", "motivation": "现有顺序缩放方法依赖于启发式且非原则的方法，导致其性能改进有限且难以理解。为了更好地理解并优化这些方法，提出了新的理论框架和系统来指导实际应用。", "method": "通过建立两状态马尔可夫模型揭示了顺序缩放的内在属性，并开发了一个名为MarkovScale的系统以实现准确性和效率之间的最佳平衡。", "result": "在三个LLM、五个基准测试以及超过20种配置上的实验表明，MarkovScale优于现有的并行和顺序缩放方法。", "conclusion": "该研究展示了如何通过理论框架指导大型语言模型在推理时间上实现最优且资源高效的性能优化。"}}
{"id": "2602.01118", "pdf": "https://arxiv.org/pdf/2602.01118", "abs": "https://arxiv.org/abs/2602.01118", "authors": ["Jingjing Wang", "Qirui Hu", "Chong Bao", "Yuke Zhu", "Hujun Bao", "Zhaopeng Cui", "Guofeng Zhang"], "title": "LightCity: An Urban Dataset for Outdoor Inverse Rendering and Reconstruction under Multi-illumination Conditions", "categories": ["cs.CV"], "comment": null, "summary": "Inverse rendering in urban scenes is pivotal for applications like autonomous driving and digital twins. Yet, it faces significant challenges due to complex illumination conditions, including multi-illumination and indirect light and shadow effects. However, the effects of these challenges on intrinsic decomposition and 3D reconstruction have not been explored due to the lack of appropriate datasets. In this paper, we present LightCity, a novel high-quality synthetic urban dataset featuring diverse illumination conditions with realistic indirect light and shadow effects. LightCity encompasses over 300 sky maps with highly controllable illumination, varying scales with street-level and aerial perspectives over 50K images, and rich properties such as depth, normal, material components, light and indirect light, etc. Besides, we leverage LightCity to benchmark three fundamental tasks in the urban environments and conduct a comprehensive analysis of these benchmarks, laying a robust foundation for advancing related research.", "AI": {"tldr": "本文介绍了LightCity，一个包含多光照条件的高质量合成城市数据集，用于户外反向渲染和重建研究。", "motivation": "在复杂的照明条件下进行城市场景中的逆向渲染面临着巨大挑战，如多种光源及间接光线与阴影效应等，这些问题影响了固有分解和3D重建的效果。由于缺乏适当的数据集，这些挑战的影响尚未得到充分探索。", "method": "本文构建了一个包含超过300个天空图的高分辨率数据集，能够控制光照并具有5万多张图像的不同视角。此数据集涵盖了深度、法线、材质成分、光及间接光线等丰富属性。研究团队还利用LightCity对城市环境中三个基础任务进行了全面评估，并分析了这些基准测试的结果。", "result": "该数据集和相关基准测试为推进逆向渲染和重建的研究奠定了坚实的基础。", "conclusion": "LightCity及其应用能够促进在复杂照明条件下进行户外反向渲染和三维重建的研究进步，提高自主驾驶等领域的技术性能。"}}
{"id": "2602.01115", "pdf": "https://arxiv.org/pdf/2602.01115", "abs": "https://arxiv.org/abs/2602.01115", "authors": ["Zhihao Chen", "Yiyuan Ge", "Ziyang Wang"], "title": "KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted By ICRA2026", "summary": "Diffusion-based visuomotor policies excel at modeling action distributions but are inference-inefficient, since recursively denoising from noise to policy requires many steps and heavy UNet backbones, which hinders deployment on resource-constrained robots. Flow matching alleviates the sampling burden by learning a one-step vector field, yet prior implementations still inherit large UNet-style architectures. In this work, we present KAN-We-Flow, a flow-matching policy that draws on recent advances in Receptance Weighted Key Value (RWKV) and Kolmogorov-Arnold Networks (KAN) from vision to build a lightweight and highly expressive backbone for 3D manipulation. Concretely, we introduce an RWKV-KAN block: an RWKV first performs efficient time/channel mixing to propagate task context, and a subsequent GroupKAN layer applies learnable spline-based, groupwise functional mappings to perform feature-wise nonlinear calibration of the action mapping on RWKV outputs. Moreover, we introduce an Action Consistency Regularization (ACR), a lightweight auxiliary loss that enforces alignment between predicted action trajectories and expert demonstrations via Euler extrapolation, providing additional supervision to stabilize training and improve policy precision. Without resorting to large UNets, our design reduces parameters by 86.8\\%, maintains fast runtime, and achieves state-of-the-art success rates on Adroit, Meta-World, and DexArt benchmarks. Our project page can be viewed in \\href{https://zhihaochen-2003.github.io/KAN-We-Flow.github.io/}{\\textcolor{red}{link}}", "AI": {"tldr": "本文提出了一种基于KAN和RWKV的轻量级流匹配策略，用于提高机器人抓取任务中的操作精度。", "motivation": "扩散模型在动作分布建模上表现良好但推理效率低下，限制了其在资源受限设备上的应用。通过结合最新的视觉技术并引入更高效的架构，可以减轻采样负担同时保持高性能。", "method": "提出了一种新的RWKV-KAN块，利用RWKV进行高效的时间/通道混合以传播任务上下文，并使用GroupKAN层执行可学习的样条函数映射对动作映射进行非线性校准。此外，引入了动作一致性正则化（ACR），通过Euler外推法确保预测的动作轨迹与专家示范的一致性。", "result": "在Adroit、Meta-World和DexArt等基准测试中达到了最先进的成功率，并且参数减少了86.8%，保持了较快的运行时间。", "conclusion": "所提出的KAN-We-Flow方法成功地减轻了流匹配策略中的采样负担，同时实现了高效的操作精度提升。"}}
{"id": "2602.01114", "pdf": "https://arxiv.org/pdf/2602.01114", "abs": "https://arxiv.org/abs/2602.01114", "authors": ["Sai Keerthana Karnam", "Abhisek Dash", "Krishna Gummadi", "Animesh Mukherjee", "Ingmar Weber", "Savvas Zannettou"], "title": "Bowling with ChatGPT: On the Evolving User Interactions with Conversational AI Systems", "categories": ["cs.HC", "cs.CY"], "comment": "This work has been accepted at The ACM Web Conference 2026", "summary": "Recent studies have discussed how users are increasingly using conversational AI systems, powered by LLMs, for information seeking, decision support, and even emotional support. However, these macro-level observations offer limited insight into how the purpose of these interactions shifts over time, how users frame their interactions with the system, and how steering dynamics unfold in these human-AI interactions. To examine these evolving dynamics, we gathered and analyzed a unique dataset InVivoGPT: consisting of 825K ChatGPT interactions, donated by 300 users through their GDPR data rights. Our analyses reveal three key findings. First, participants increasingly turn to ChatGPT for a broader range of purposes, including substantial growth in sensitive domains such as health and mental health. Second, interactions become more socially framed: the system anthropomorphizes itself at rising rates, participants more frequently treat it as a companion, and personal data disclosure becomes both more common and more diverse. Third, conversational steering becomes more prominent, especially after the release of GPT-4o, with conversations where the participants followed a model-initiated suggestion quadrupling over the period of our dataset. Overall, our results show that conversational AI systems are shifting from functional tools to social partners, raising important questions about their design and governance.", "AI": {"tldr": "本文研究了用户与基于LLM的对话AI系统交互的方式随时间的变化。", "motivation": "现有研究仅从宏观层面观察用户如何使用对话AI系统，缺乏对这些互动目的演变、框架变化和引导动态的理解。", "method": "收集并分析了一个由300名用户提供且包含82.5万个ChatGPT交互的InVivoGPT数据集。", "result": "发现用户越来越倾向于将ChatGPT用于更广泛的用途，包括在健康和心理健康等敏感领域；互动变得更社交化，并更多地披露个人数据；对话引导更加显著。", "conclusion": "研究结果表明，对话AI系统正在从功能性工具转变为社会伙伴，这引发了许多关于其设计和治理的重要问题。"}}
{"id": "2602.01109", "pdf": "https://arxiv.org/pdf/2602.01109", "abs": "https://arxiv.org/abs/2602.01109", "authors": ["Hugo Math", "Rainer Lienhart"], "title": "Transforming Vehicle Diagnostics: A Multimodal Approach to Error Patterns Prediction", "categories": ["cs.AI"], "comment": "9 pages, 7 figures", "summary": "Accurately diagnosing and predicting vehicle malfunctions is crucial for maintenance and safety in the automotive industry. While modern diagnostic systems primarily rely on sequences of vehicular Diagnostic Trouble Codes (DTCs) registered in On-Board Diagnostic (OBD) systems, they often overlook valuable contextual information such as raw sensory data (e.g., temperature, humidity, and pressure). This contextual data, crucial for domain experts to classify vehicle failures, introduces unique challenges due to its complexity and the noisy nature of real-world data. This paper presents BiCarFormer: the first multimodal approach to multi-label sequence classification of error codes into error patterns that integrates DTC sequences and environmental conditions. BiCarFormer is a bidirectional Transformer model tailored for vehicle event sequences, employing embedding fusions and a co-attention mechanism to capture the relationships between diagnostic codes and environmental data. Experimental results on a challenging real-world automotive dataset with 22,137 error codes and 360 error patterns demonstrate that our approach significantly improves classification performance compared to models that rely solely on DTC sequences and traditional sequence models. This work highlights the importance of incorporating contextual environmental information for more accurate and robust vehicle diagnostics, hence reducing maintenance costs and enhancing automation processes in the automotive industry.", "AI": {"tldr": "车辆诊断方法的改进，通过结合DTC序列和环境数据提高故障模式预测准确性。", "motivation": "现有车辆诊断系统主要依赖于OBD系统的DTC序列，忽视了温度、湿度等关键环境信息。这些信息对于准确分类车辆故障至关重要但处理起来具有挑战性。", "method": "提出BiCarFormer模型，一个双向Transformer结构，用于融合DTC序列和环境数据，并通过嵌入融合和协同注意机制来捕捉两者之间的关系。", "result": "实验结果表明，与仅基于DTC序列和其他传统方法相比，该方法显著提高了分类性能。", "conclusion": "本研究强调了结合环境信息对于车辆诊断的重要性，有助于减少维护成本并提升自动化流程效率。"}}
{"id": "2602.01107", "pdf": "https://arxiv.org/pdf/2602.01107", "abs": "https://arxiv.org/abs/2602.01107", "authors": ["Daniel Ramos", "Catarina Gamboa", "Inês Lynce", "Vasco Manquinho", "Ruben Martins", "Claire Le Goues"], "title": "SPELL: Synthesis of Programmatic Edits using LLMs", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "pre-print", "summary": "Library migration is a common but error-prone task in software development. Developers may need to replace one library with another due to reasons like changing requirements or licensing changes. Migration typically entails updating and rewriting source code manually. While automated migration tools exist, most rely on mining examples from real-world projects that have already undergone similar migrations. However, these data are scarce, and collecting them for arbitrary pairs of libraries is difficult. Moreover, these migration tools often miss out on leveraging modern code transformation infrastructure. In this paper, we present a new approach to automated API migration that sidesteps the limitations described above. Instead of relying on existing migration data or using LLMs directly for transformation, we use LLMs to extract migration examples. Next, we use an Agent to generalize those examples to reusable transformation scripts in PolyglotPiranha, a modern code transformation tool. Our method distills latent migration knowledge from LLMs into structured, testable, and repeatable migration logic, without requiring preexisting corpora or manual engineering effort. Experimental results across Python libraries show that our system can generate diverse migration examples and synthesize transformation scripts that generalize to real-world codebases.", "AI": {"tldr": "本文提出了一种新的自动化API迁移方法，利用LLM提取迁移示例，并通过Agent将其转换为可重用的代码转换脚本。", "motivation": "现有的自动化迁移工具依赖于从已完成类似迁移的真实项目中挖掘示例数据，这些数据稀缺且难以收集。此外，这些工具通常未能充分利用现代代码转换基础设施。", "method": "使用LLM提取迁移示例，并通过Agent将其转化为PolyglotPiranha中的可重用代码转换脚本，从而将隐含的迁移知识转化为结构化、可测试和重复使用的迁移逻辑。", "result": "实验结果表明，在Python库之间，系统能够生成多样化的迁移示例并合成适用于实际项目代码库的转换脚本。", "conclusion": "通过利用LLM和现代代码转换工具，本文提出的方法克服了现有自动化迁移工具的局限性，并成功地实现了结构化、可测试且重复使用的迁移逻辑。"}}
{"id": "2602.01105", "pdf": "https://arxiv.org/pdf/2602.01105", "abs": "https://arxiv.org/abs/2602.01105", "authors": ["Zixiao Wang", "Yifei Shen", "Huishuai Zhang"], "title": "OLion: Approaching the Hadamard Ideal by Intersecting Spectral and $\\ell_{\\infty}$ Implicit Biases", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages", "summary": "Many optimizers can be interpreted as steepest-descent methods under norm-induced geometries, and thus inherit corresponding implicit biases. We introduce \\nameA{} (\\fullname{}), which combines spectral control from orthogonalized update directions with $\\ell_\\infty$-style coordinate control from sign updates. \\nameA{} forms a Lion-style momentum direction, approximately orthogonalizes it via a few Newton--Schulz iterations, and then applies an entrywise sign, providing an efficient approximation to taking a maximal step over the intersection of the spectral and $\\ell_\\infty$ constraint sets (a scaled Hadamard-like set for matrix parameters). Despite the strong nonlinearity of orthogonalization and sign, we prove convergence under a mild, empirically verified diagonal-isotropy assumption. Across large-scale language and vision training, including GPT-2 and Llama pretraining, SiT image pretraining, and supervised fine-tuning, \\nameA{} matches or outperforms AdamW and Muon under comparable tuning while using only momentum-level optimizer state, and it mitigates optimizer mismatch when fine-tuning AdamW-pretrained checkpoints.", "AI": {"tldr": "介绍了一种新的优化器OLion，结合了谱控制和坐标控制的特点，以近似实现Hadamard理想。", "motivation": "许多优化器可以解释为规范诱导几何中的最陡下降法，并因此继承相应的隐式偏置。该论文旨在通过交集两种不同的约束集合来接近Hadamard理想。", "method": "OLion方法结合了谱控制和坐标控制的特点，形成了类似狮子风格的动量方向并通过Newton-Schulz迭代进行了近似正交化，最后应用逐元素符号处理。", "result": "在大规模语言和视觉训练任务中，包括GPT-2和Llama预训练、SiT图像预训练以及监督微调过程中，OLion与AdamW和Muon相比表现相等或更优，并能解决优化器不匹配的问题。", "conclusion": "通过将谱控制和坐标控制结合在一起，OLion能够在保持较小的优化器状态的同时接近Hadamard理想，并且在各种训练任务中表现出色。"}}
{"id": "2602.01104", "pdf": "https://arxiv.org/pdf/2602.01104", "abs": "https://arxiv.org/abs/2602.01104", "authors": ["Poojan Shah", "Shashwat Agrawal", "Ragesh Jaiswal"], "title": "Fast $k$-means Seeding Under The Manifold Hypothesis", "categories": ["cs.DS"], "comment": null, "summary": "We study beyond worst case analysis for the $k$-means problem where the goal is to model typical instances of $k$-means arising in practice. Existing theoretical approaches provide guarantees under certain assumptions on the optimal solutions to $k$-means, making them difficult to validate in practice. We propose the manifold hypothesis, where data obtained in ambient dimension $D$ concentrates around a low dimensional manifold of intrinsic dimension $d$, as a reasonable assumption to model real world clustering instances. We identify key geometric properties of datasets which have theoretically predictable scaling laws depending on the quantization exponent $\\varepsilon = 2/d$ using techniques from optimum quantization theory. We show how to exploit these regularities to design a fast seeding method called $\\operatorname{Qkmeans}$ which provides $O(ρ^{-2} \\log k)$ approximate solutions to the $k$-means problem in time $O(nD) + \\widetilde{O}(\\varepsilon^{1+ρ}ρ^{-1}k^{1+γ})$; where the exponent $γ= \\varepsilon + ρ$ for an input parameter $ρ< 1$. This allows us to obtain new runtime - quality tradeoffs. We perform a large scale empirical study across various domains to validate our theoretical predictions and algorithm performance to bridge theory and practice for beyond worst case data clustering.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.01103", "pdf": "https://arxiv.org/pdf/2602.01103", "abs": "https://arxiv.org/abs/2602.01103", "authors": ["Yiming Dong", "Kun Fu", "Haoyu Li", "Xinyuan Zhu", "Yurou Liu", "Lijing Shao", "Jieping Ye", "Zheng Wang"], "title": "Probing RLVR training instability through the lens of objective-level hacking", "categories": ["cs.AI"], "comment": null, "summary": "Prolonged reinforcement learning with verifiable rewards (RLVR) has been shown to drive continuous improvements in the reasoning capabilities of large language models, but the training is often prone to instabilities, especially in Mixture-of-Experts (MoE) architectures. Training instability severely undermines model capability improvement, yet its underlying causes and mechanisms remain poorly understood. In this work, we introduce a principled framework for understanding RLVR instability through the lens of objective-level hacking. Unlike reward hacking, which arises from exploitable verifiers, objective-level hacking emerges from token-level credit misalignment and is manifested as system-level spurious signals in the optimization objective. Grounded in our framework, together with extensive experiments on a 30B MoE model, we trace the origin and formalize the mechanism behind a key pathological training dynamic in MoE models: the abnormal growth of the training-inference discrepancy, a phenomenon widely associated with instability but previously lacking a mechanistic explanation. These findings provide a concrete and causal account of the training dynamics underlying instabilities in MoE models, offering guidance for the design of stable RLVR algorithms.", "AI": {"tldr": "通过目标层面的黑客攻击视角探究RLVR训练不稳定的原因和机制，特别是在混合专家架构中。", "motivation": "长时间的强化学习与可验证奖励（RLVR）可以提升大型语言模型的推理能力，但训练过程中常出现不稳定性问题，尤其是对于混合专家架构。这个问题的根本原因和背后机理尚不清楚。研究者希望通过建立一个框架来理解这些问题，并提出解决建议。", "method": "引入了一个基于目标层面黑客攻击的理解强化学习与可验证奖励（RLVR）不稳定性的新视角，并通过广泛的实验在30B混合专家模型上追踪了训练不稳定性起源，正式化了一种关键的病态训练动态：训练-推理差异异常增长的现象。", "result": "研究提供了关于导致混合专家架构中不稳定训练动态的具体和因果解释，为设计稳定RLVR算法提供了指导建议。", "conclusion": "通过分析揭示了目标层面黑客攻击现象背后的机制，并提出了改进方案以促进更稳定的模型训练过程。"}}
{"id": "2602.01101", "pdf": "https://arxiv.org/pdf/2602.01101", "abs": "https://arxiv.org/abs/2602.01101", "authors": ["Felix Breiteneder", "Mohammad Belal", "Muhammad Saad Saeed", "Shahed Masoudian", "Usman Naseem", "Kulshrestha Juhi", "Markus Schedl", "Shah Nawaz"], "title": "Robust Harmful Meme Detection under Missing Modalities via Shared Representation Learning", "categories": ["cs.CV"], "comment": "Accepted at WWW2026", "summary": "Internet memes are powerful tools for communication, capable of spreading political, psychological, and sociocultural ideas. However, they can be harmful and can be used to disseminate hate toward targeted individuals or groups. Although previous studies have focused on designing new detection methods, these often rely on modal-complete data, such as text and images. In real-world settings, however, modalities like text may be missing due to issues like poor OCR quality, making existing methods sensitive to missing information and leading to performance deterioration. To address this gap, in this paper, we present the first-of-its-kind work to comprehensively investigate the behavior of harmful meme detection methods in the presence of modal-incomplete data. Specifically, we propose a new baseline method that learns a shared representation for multiple modalities by projecting them independently. These shared representations can then be leveraged when data is modal-incomplete. Experimental results on two benchmark datasets demonstrate that our method outperforms existing approaches when text is missing. Moreover, these results suggest that our method allows for better integration of visual features, reducing dependence on text and improving robustness in scenarios where textual information is missing. Our work represents a significant step forward in enabling the real-world application of harmful meme detection, particularly in situations where a modality is absent.", "AI": {"tldr": "该论文提出了一种新的基线方法，通过独立投影学习多模态的共享表示来解决有害表情包检测在缺少信息时性能下降的问题。", "motivation": "现有有害表情包检测方法依赖于完整的数据模式，而在实际应用中由于光学字符识别质量差等问题可能导致文本缺失，从而影响检测效果。为了解决这个问题，论文提出了一种新方法以提高在模态不全情况下的检测能力。", "method": "该方法通过独立投影学习不同模态的共享表示，即使某些模式（如文字）丢失也能利用这些共享表示进行有害表情包检测。", "result": "实验结果表明，在文本缺失的情况下，所提出的方法优于现有技术。此外，这还表明该方法能够更好地整合视觉特征，减少对文本的依赖，并在文本信息缺失时提高鲁棒性。", "conclusion": "本文的研究工作代表了有害表情包检测在实际应用中向前迈出的重要一步，特别是在模态缺失的情况下。"}}
{"id": "2602.01100", "pdf": "https://arxiv.org/pdf/2602.01100", "abs": "https://arxiv.org/abs/2602.01100", "authors": ["Hang Wu", "Tongqing Chen", "Jiasen Wang", "Xiaotao Li", "Lu Fang"], "title": "StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating", "categories": ["cs.RO"], "comment": null, "summary": "Long-horizon robotic manipulation requires bridging the gap between high-level planning (System 2) and low-level control (System 1). Current Vision-Language-Action (VLA) models often entangle these processes, performing redundant multimodal reasoning at every timestep, which leads to high latency and goal instability. To address this, we present StreamVLA, a dual-system architecture that unifies textual task decomposition, visual goal imagination, and continuous action generation within a single parameter-efficient backbone. We introduce a \"Lock-and-Gated\" mechanism to intelligently modulate computation: only when a sub-task transition is detected, the model triggers slow thinking to generate a textual instruction and imagines the specific visual completion state, rather than generic future frames. Crucially, this completion state serves as a time-invariant goal anchor, making the policy robust to execution speed variations. During steady execution, these high-level intents are locked to condition a Flow Matching action head, allowing the model to bypass expensive autoregressive decoding for 72% of timesteps. This hierarchical abstraction ensures sub-goal focus while significantly reducing inference latency. Extensive evaluations demonstrate that StreamVLA achieves state-of-the-art performance, with a 98.5% success rate on the LIBERO benchmark and robust recovery in real-world interference scenarios, achieving a 48% reduction in latency compared to full-reasoning baselines.", "AI": {"tldr": "本文提出了一种名为StreamVLA的架构，旨在通过引入一个“锁定与门控”机制来解决长时域机器人操作中的高延迟和目标不稳定性问题。", "motivation": "当前Vision-Language-Action模型在每一步都进行冗余多模态推理，导致了高延迟和目标不稳定的问题。为了克服这些问题，提出了StreamVLA架构以分离高层次规划和低层次控制过程，并引入智能计算调节机制来减少不必要的推理次数。", "method": "该方法包括文本任务分解、视觉目标想象以及连续动作生成的统一处理。它通过“锁定与门控”机制在检测到子任务转换时触发慢思考，产生具体的目标状态描述，而这些状态作为时间不变的目标锚点保证了策略对执行速度变化的鲁棒性。", "result": "实验表明，StreamVLA在LIBERO基准测试中达到了98.5%的成功率，并且在真实世界的干扰情况下展示了48％延迟减少的优势。", "conclusion": "通过引入一种新颖的方式处理长时域任务中的规划与执行问题，StreamVLA不仅提高了模型的鲁棒性和效率，还实现了比现有方法更好的性能。"}}
{"id": "2602.01095", "pdf": "https://arxiv.org/pdf/2602.01095", "abs": "https://arxiv.org/abs/2602.01095", "authors": ["Jinghong Zheng", "Changlong Jiang", "Yang Xiao", "Jiaqi Li", "Haohong Kuang", "Hang Xu", "Ran Wang", "Zhiguo Cao", "Min Du", "Joey Tianyi Zhou"], "title": "PandaPose: 3D Human Pose Lifting from a Single Image via Propagating 2D Pose Prior to 3D Anchor Space", "categories": ["cs.CV"], "comment": "Accepted at NeurIPS 2025", "summary": "3D human pose lifting from a single RGB image is a challenging task in 3D vision. Existing methods typically establish a direct joint-to-joint mapping from 2D to 3D poses based on 2D features. This formulation suffers from two fundamental limitations: inevitable error propagation from input predicted 2D pose to 3D predictions and inherent difficulties in handling self-occlusion cases. In this paper, we propose PandaPose, a 3D human pose lifting approach via propagating 2D pose prior to 3D anchor space as the unified intermediate representation. Specifically, our 3D anchor space comprises: (1) Joint-wise 3D anchors in the canonical coordinate system, providing accurate and robust priors to mitigate 2D pose estimation inaccuracies. (2) Depth-aware joint-wise feature lifting that hierarchically integrates depth information to resolve self-occlusion ambiguities. (3) The anchor-feature interaction decoder that incorporates 3D anchors with lifted features to generate unified anchor queries encapsulating joint-wise 3D anchor set, visual cues and geometric depth information. The anchor queries are further employed to facilitate anchor-to-joint ensemble prediction. Experiments on three well-established benchmarks (i.e., Human3.6M, MPI-INF-3DHP and 3DPW) demonstrate the superiority of our proposition. The substantial reduction in error by $14.7\\%$ compared to SOTA methods on the challenging conditions of Human3.6M and qualitative comparisons further showcase the effectiveness and robustness of our approach.", "AI": {"tldr": "本文提出了PandaPose方法，通过将2D姿态先验传播到3D锚点空间来提升从单张RGB图像中进行3D人体姿态估计的准确性。", "motivation": "现有的直接基于2D特征的2D至3D姿态映射方式存在误差传递和处理自我遮挡情况困难的问题，因此本文提出了新的方法以解决这些问题。", "method": "PandaPose通过引入一个包含关节级3D锚点、深度感知关节级特征提升及锚点-特征交互解码器的3D锚点空间来改善姿态估计。", "result": "实验结果表明，在Human3.6M等三个基准数据集上，本文方法相比现有最佳方法在挑战性条件下误差降低了14.7%，显示出有效性与鲁棒性。", "conclusion": "PandaPose通过改进的锚点空间和特征交互解码器显著提升了从单张RGB图像中进行3D人体姿态估计的效果。"}}
{"id": "2602.01092", "pdf": "https://arxiv.org/pdf/2602.01092", "abs": "https://arxiv.org/abs/2602.01092", "authors": ["Peng Zhou", "Zhongxuan Li", "Jinsong Wu", "Jiaming Qi", "Jun Hu", "David Navarro-Alarcon", "Jia Pan", "Lihua Xie", "Shiyao Zhang", "Zeqing Zhang"], "title": "Failure-Aware Bimanual Teleoperation via Conservative Value Guided Assistance", "categories": ["cs.RO"], "comment": null, "summary": "Teleoperation of high-precision manipulation is con-strained by tight success tolerances and complex contact dy-namics, which make impending failures difficult for human operators to anticipate under partial observability. This paper proposes a value-guided, failure-aware framework for bimanual teleoperation that provides compliant haptic assistance while pre-serving continuous human authority. The framework is trained entirely from heterogeneous offline teleoperation data containing both successful and failed executions. Task feasibility is mod-eled as a conservative success score learned via Conservative Value Learning, yielding a risk-sensitive estimate that remains reliable under distribution shift. During online operation, the learned success score regulates the level of assistance, while a learned actor provides a corrective motion direction. Both are integrated through a joint-space impedance interface on the master side, yielding continuous guidance that steers the operator away from failure-prone actions without overriding intent. Experimental results on contact-rich manipulation tasks demonstrate improved task success rates and reduced operator workload compared to conventional teleoperation and shared-autonomy baselines, indicating that conservative value learning provides an effective mechanism for embedding failure awareness into bilateral teleoperation. Experimental videos are available at https://www.youtube.com/watch?v=XDTsvzEkDRE", "AI": {"tldr": "本文提出了一种基于保守价值引导的双臂遥操作框架，该框架在高精度操控任务中提供柔顺力反馈协助，同时保持连续的人类控制权。", "motivation": "传统的遥操作系统难以预测复杂接触动力学下的潜在故障。为了解决这一问题，本文提出了一个能够提前感知并避免失败的框架，以提高操作的成功率和减少操作者的负担。", "method": "该方法通过保守价值学习从异构离线数据中训练成功评分模型，并使用此评分模型在线调节协助水平，同时由学习到的行为者提供纠正运动方向。两者集成在主控侧的关节空间阻抗接口上。", "result": "实验结果显示，在接触密集的任务中，该方法显著提高了任务成功率并减少了操作者的负担。", "conclusion": "保守价值学习为双臂遥操作中的失败感知提供了有效机制，并展示了其优越性。"}}
{"id": "2602.01090", "pdf": "https://arxiv.org/pdf/2602.01090", "abs": "https://arxiv.org/abs/2602.01090", "authors": ["Yang Liu", "Chuan Zhou", "Yancheng Chen", "Shuai Zhang", "Xixun Lin", "Xiaoqing Wang"], "title": "Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization", "categories": ["cs.AI"], "comment": "32 pages, 2 figures", "summary": "Large language models (LLMs) have emerged as promising general-purpose solvers for combinatorial optimization (CO), yet they fundamentally lack mechanisms to guarantee solution feasibility which is critical for real-world deployment. In this work, we introduce FALCON, a framework that ensures 100\\% feasibility through three key innovations: (i) \\emph{grammar-constrained decoding} enforces syntactic validity, (ii) a \\emph{feasibility repair layer} corrects semantic constraint violations, and (iii) \\emph{adaptive Best-of-$N$ sampling} allocates inference compute efficiently. To train the underlying LLM, we introduce the Best-anchored Objective-guided Preference Optimization (BOPO) in LLM training, which weights preference pairs by their objective gap, providing dense supervision without human labels. Theoretically, we prove convergence for BOPO and provide bounds on repair-induced quality loss. Empirically, across seven NP-hard CO problems, FALCON achieves perfect feasibility while matching or exceeding the solution quality of state-of-the-art neural and LLM-based solvers.", "AI": {"tldr": "提出了一种名为FALCON的框架，确保大型语言模型（LLM）在组合优化问题上的解可行性达到100%。", "motivation": "大型语言模型在解决组合优化问题时缺乏保证解可行性的机制，这对于实际部署至关重要。因此，需要一种方法来确保生成的解决方案是有效的和可用的。", "method": "FALCON框架通过三种创新方法来保证解可行性：（i）语法受限解码以强制语法规则的有效性；（ii）修复层纠正语义约束违反问题；（iii）适应性的最佳N采样分配计算资源。此外，为了训练底层的LLM，引入了BOPO优化策略。", "result": "FALCON在解决七种NP难的组合优化问题时实现了完美的可行性，并且其解决方案质量与当前最先进的神经和基于LLM的方法相匹配或超过。", "conclusion": "通过FALCON框架解决了大型语言模型在组合优化中的解可行性问题，证明了这种方法的有效性和实用性。"}}
{"id": "2602.01089", "pdf": "https://arxiv.org/pdf/2602.01089", "abs": "https://arxiv.org/abs/2602.01089", "authors": ["Zhiqi Zhang", "Xinhao Zhong", "Yi Sun", "Shuoyang Sun", "Bin Chen", "Shu-Tao Xia", "Xuan Wang"], "title": "Differential Vector Erasure: Unified Training-Free Concept Erasure for Flow Matching Models", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image diffusion models have demonstrated remarkable capabilities in generating high-quality images, yet their tendency to reproduce undesirable concepts, such as NSFW content, copyrighted styles, or specific objects, poses growing concerns for safe and controllable deployment. While existing concept erasure approaches primarily focus on DDPM-based diffusion models and rely on costly fine-tuning, the recent emergence of flow matching models introduces a fundamentally different generative paradigm for which prior methods are not directly applicable. In this paper, we propose Differential Vector Erasure (DVE), a training-free concept erasure method specifically designed for flow matching models. Our key insight is that semantic concepts are implicitly encoded in the directional structure of the velocity field governing the generative flow. Leveraging this observation, we construct a differential vector field that characterizes the directional discrepancy between a target concept and a carefully chosen anchor concept. During inference, DVE selectively removes concept-specific components by projecting the velocity field onto the differential direction, enabling precise concept suppression without affecting irrelevant semantics. Extensive experiments on FLUX demonstrate that DVE consistently outperforms existing baselines on a wide range of concept erasure tasks, including NSFW suppression, artistic style removal, and object erasure, while preserving image quality and diversity.", "AI": {"tldr": "提出了一种针对流匹配模型的无训练概念擦除方法DVE，用于在图像生成时精确地移除特定概念而不影响其他内容。", "motivation": "现有的文本到图像扩散模型虽然能生成高质量图片，但有倾向复制不良概念如不适宜的内容、版权样式或具体物体。已有概念擦除方法主要针对DDPM类扩散模型，并且需要昂贵的微调过程。本文旨在解决流匹配模型中的类似问题。", "method": "基于速度场的方向结构隐含编码了语义概念这一观察，构造了一个差分矢量场以表征目标概念与选定锚概念间的方向差异。在推断阶段，通过将速度场投影到差分方向来选择性地移除特定概念的组件。", "result": "实验表明DVE在FLUX模型上对多种概念擦除任务（如不适宜内容抑制、艺术风格去除和物体擦除）均优于现有基线方法，并保持了图像质量和多样性。", "conclusion": "本文提出的DVE为流匹配模型提供了一种训练自由的概念擦除方法，展示了其在精确移除特定概念的同时维持图像完整性的能力。"}}
{"id": "2602.01086", "pdf": "https://arxiv.org/pdf/2602.01086", "abs": "https://arxiv.org/abs/2602.01086", "authors": ["Takahito Nakajima"], "title": "MedBeads: An Agent-Native, Immutable Data Substrate for Trustworthy Medical AI", "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.DC", "cs.SE"], "comment": "19 pages, 5 figures. Code available at https://github.com/medbeads/medbeads", "summary": "Background: As of 2026, Large Language Models (LLMs) demonstrate expert-level medical knowledge. However, deploying them as autonomous \"Clinical Agents\" remains limited. Current Electronic Medical Records (EMRs) and standards like FHIR are designed for human review, creating a \"Context Mismatch\": AI agents receive fragmented data and must rely on probabilistic inference (e.g., RAG) to reconstruct patient history. This approach causes hallucinations and hinders auditability. Methods: We propose MedBeads, an agent-native data infrastructure where clinical events are immutable \"Beads\"--nodes in a Merkle Directed Acyclic Graph (DAG)--cryptographically referencing causal predecessors. This \"write-once, read-many\" architecture makes tampering mathematically detectable. We implemented a prototype with a Go Core Engine, Python middleware for LLM integration, and a React-based visualization interface. Results: We successfully implemented the workflow using synthetic data. The FHIR-to-DAG conversion transformed flat resources into a causally-linked graph. Our Breadth-First Search (BFS) Context Retrieval algorithm traverses relevant subgraphs with O(V+E) complexity, enabling real-time decision support. Tamper-evidence is guaranteed by design: any modification breaks the cryptographic chain. The visualization aids clinician understanding through explicit causal links. Conclusion: MedBeads addresses the \"Context Mismatch\" by shifting from probabilistic search to deterministic graph traversal, and from mutable records to immutable chains, providing the substrate for \"Trustworthy Medical AI.\" It guarantees the context the AI receives is deterministic and tamper-evident, while the LLM determines interpretation. The structured Bead format serves as a token-efficient \"AI-native language.\" We release MedBeads as open-source software to accelerate agent-native data standards.", "AI": {"tldr": "MedBeads 是一种针对医疗人工智能设计的不可变数据基础设施，用于解决现有电子病历和标准与临床智能代理之间的上下文不匹配问题。", "motivation": "当前电子病历系统设计为供人工审查，导致AI在处理病人信息时面临碎片化数据的问题，缺乏连贯性且难以追溯修改记录。因此需要一种新的不可变、可信的数据基础设施来解决这一困境。", "method": "MedBeads 将临床事件表示为基于Merkle DAG的节点（珠子），每个珠子都通过加密技术与因果前驱者关联，从而创建一个“写一次读多”的架构，确保数据的完整性。该系统包括Go核心引擎、Python中间件和React可视化界面。", "result": "使用合成数据成功实现了MedBeads的工作流程，将FHIR资源转换为有向无环图，并通过广度优先搜索算法有效地获取上下文信息。任何修改都将破坏加密链，保证了数据的不可篡改性。", "conclusion": "MedBeads 解决了现有电子病历与临床智能代理之间的上下文不匹配问题，提供了可追溯、可信的数据基础架构，确保AI接收到的信息是确定性和防篡改的。该系统将作为医疗人工智能应用的标准数据格式开源发布。"}}
{"id": "2602.01085", "pdf": "https://arxiv.org/pdf/2602.01085", "abs": "https://arxiv.org/abs/2602.01085", "authors": ["Qi Jing Chen", "Shilin Shan", "Timothy Bretl", "Quang-Cuong Pham"], "title": "Estimating Force Interactions of Deformable Linear Objects from their Shapes", "categories": ["cs.RO"], "comment": "7 pages, 4 figures", "summary": "This work introduces an analytical approach for detecting and estimating external forces acting on deformable linear objects (DLOs) using only their observed shapes. In many robot-wire interaction tasks, contact occurs not at the end-effector but at other points along the robot's body. Such scenarios arise when robots manipulate wires indirectly (e.g., by nudging) or when wires act as passive obstacles in the environment. Accurately identifying these interactions is crucial for safe and efficient trajectory planning, helping to prevent wire damage, avoid restricted robot motions, and mitigate potential hazards. Existing approaches often rely on expensive external force-torque sensor or that contacts occur at the end-effector for accurate force estimation. Using wire shape information acquired from a depth camera and under the assumption that the wire is in or near its static equilibrium, our method estimates both the location and magnitude of external forces without additional prior knowledge. This is achieved by exploiting derived consistency conditions and solving a system of linear equations based on force-torque balance along the wire. The approach was validated through simulation, where it achieved high accuracy, and through real-world experiments, where accurate estimation was demonstrated in selected interaction scenarios.", "AI": {"tldr": "本文提出了一种基于形状信息来检测和估算作用在可变形线性物体上的外部力的方法。", "motivation": "准确识别机器人与线材间接接触时的相互作用对于安全高效的轨迹规划至关重要，有助于防止线材损坏、避免受限运动并降低潜在风险。现有方法依赖昂贵的外置传感器或假设接触发生在末端执行器上。", "method": "该方法利用深度相机获取的线材形状信息，并在假设线材处于静态平衡状态的情况下，通过推导出的一致性条件和求解力矩平衡方程来估计外部力的位置和大小。", "result": "该方法在模拟环境中实现了高精度，在现实世界实验中也证明了对特定交互场景的准确估算能力。", "conclusion": "所提出的方法成功地通过线材形状信息精确估算了作用在其上的外部力，无需额外先验知识，并且在各种测试中表现出了较高的准确性。"}}
{"id": "2602.01084", "pdf": "https://arxiv.org/pdf/2602.01084", "abs": "https://arxiv.org/abs/2602.01084", "authors": ["Prasenjit Karmakar", "Manjeet Yadav", "Swayanshu Rout", "Swadhin Pradhan", "Sandip Chakraborty"], "title": "From Invisible to Actionable: Augmented Reality Interactions with Indoor CO2", "categories": ["cs.HC"], "comment": "20 pages, 13 figures, 4 tables, ACM CHI 2026", "summary": "Indoor carbon dioxide (CO2) can rapidly accumulate to form invisible pollution hotspots, posing significant health risks due to its odorless and colorless nature. Despite growing interest in wearable or stationary sensors for pollutant detection, effectively visualizing CO2 levels and engaging individuals remains an ongoing challenge. In this paper, we develop a portable wrist-sized pollution sensor that detects CO2 in real time at any indoor location and reveals CO2 bubbles by highlighting sudden spikes. In order to promote better ventilation habits and user awareness, we also develop a smartphone-based augmented reality (AR) game for users to locate and disperse these high-CO2 zones. A user study with 35 participants demonstrated increased engagement and heightened understanding of CO2's health impacts. Our system's usability evaluations yielded a median score of 1.88, indicating its strong practicality.", "AI": {"tldr": "开发一种便携式腕戴传感器和基于智能手机的AR游戏，用于实时检测并可视化室内CO2水平，以提高用户意识和改善通风习惯。", "motivation": "通过解决室内CO2积累形成的隐形污染热点带来的健康风险问题，促进用户对CO2危害的理解及采取相应行动。", "method": "设计一种便携式腕戴传感器进行实时CO2浓度监测，并开发基于智能手机的AR游戏来增强用户体验与互动性。", "result": "用户研究显示35名参与者在使用该系统后提高了对CO2健康影响的认知和参与度，且系统评估得分为1.88（表明其实用性强）。", "conclusion": "通过结合传感器技术与AR游戏化元素能够有效提升公众对于室内空气质量的关注及采取行动。"}}
{"id": "2602.01082", "pdf": "https://arxiv.org/pdf/2602.01082", "abs": "https://arxiv.org/abs/2602.01082", "authors": ["Yiliu He", "Tianle Li", "Binghao Ji", "Zhiyuan Liu", "Di Huang"], "title": "EvoOpt-LLM: Evolving industrial optimization models with large language models", "categories": ["cs.AI"], "comment": null, "summary": "Optimization modeling via mixed-integer linear programming (MILP) is fundamental to industrial planning and scheduling, yet translating natural-language requirements into solver-executable models and maintaining them under evolving business rules remains highly expertise-intensive. While large language models (LLMs) offer promising avenues for automation, existing methods often suffer from low data efficiency, limited solver-level validity, and poor scalability to industrial-scale problems. To address these challenges, we present EvoOpt-LLM, a unified LLM-based framework supporting the full lifecycle of industrial optimization modeling, including automated model construction, dynamic business-constraint injection, and end-to-end variable pruning. Built on a 7B-parameter LLM and adapted via parameter-efficient LoRA fine-tuning, EvoOpt-LLM achieves a generation rate of 91% and an executability rate of 65.9% with only 3,000 training samples, with critical performance gains emerging under 1,500 samples. The constraint injection module reliably augments existing MILP models while preserving original objectives, and the variable pruning module enhances computational efficiency, achieving an F1 score of ~0.56 on medium-sized LP models with only 400 samples. EvoOpt-LLM demonstrates a practical, data-efficient approach to industrial optimization modeling, reducing reliance on expert intervention while improving adaptability and solver efficiency.", "AI": {"tldr": "EvoOpt-LLM 是一种基于大型语言模型的框架，用于支持工业优化建模的整个生命周期，包括自动构建模型、动态注入业务约束和端到端变量修剪。", "motivation": "当前通过混合整数线性规划进行的工业计划和调度中的优化建模工作非常依赖于专家知识。现有的方法在数据效率、求解器级别有效性和可扩展性方面存在不足，因此提出了 EvoOpt-LLM 来解决这些问题。", "method": "EvoOpt-LLM 使用一个70亿参数的大规模语言模型，并通过参数高效LoRA微调来适应具体任务。该框架包括自动构建模型、动态注入业务约束和端到端变量修剪三个模块。", "result": "在仅有3000个训练样本的情况下，EvoOpt-LLM 的生成率达到了91%，可执行率为65.9%；在400个样本的中等规模线性规划模型上实现了约0.56的F1分数。", "conclusion": "该研究展示了通过大型语言模型进行工业优化建模的一种实用且数据效率高的方法，减少了对专家干预的需求，并提高了适应性和求解器效率。"}}
{"id": "2602.01081", "pdf": "https://arxiv.org/pdf/2602.01081", "abs": "https://arxiv.org/abs/2602.01081", "authors": ["Haitao Zhang", "Yingying Wang", "Jiaxiang Wang", "Haote Xu", "Hongyang Zhang", "Yirong Chen", "Yue Huang", "Xinghao Ding"], "title": "MedAD-R1: Eliciting Consistent Reasoning in Interpretible Medical Anomaly Detection via Consistency-Reinforced Policy Optimization", "categories": ["cs.CV"], "comment": "9 pages, 4 figures", "summary": "Medical Anomaly Detection (MedAD) presents a significant opportunity to enhance diagnostic accuracy using Large Multimodal Models (LMMs) to interpret and answer questions based on medical images. However, the reliance on Supervised Fine-Tuning (SFT) on simplistic and fragmented datasets has hindered the development of models capable of plausible reasoning and robust multimodal generalization. To overcome this, we introduce MedAD-38K, the first large-scale, multi-modal, and multi-center benchmark for MedAD featuring diagnostic Chain-of-Thought (CoT) annotations alongside structured Visual Question-Answering (VQA) pairs. On this foundation, we propose a two-stage training framework. The first stage, Cognitive Injection, uses SFT to instill foundational medical knowledge and align the model with a structured think-then-answer paradigm. Given that standard policy optimization can produce reasoning that is disconnected from the final answer, the second stage incorporates Consistency Group Relative Policy Optimization (Con-GRPO). This novel algorithm incorporates a crucial consistency reward to ensure the generated reasoning process is relevant and logically coherent with the final diagnosis. Our proposed model, MedAD-R1, achieves state-of-the-art (SOTA) performance on the MedAD-38K benchmark, outperforming strong baselines by more than 10\\%. This superior performance stems from its ability to generate transparent and logically consistent reasoning pathways, offering a promising approach to enhancing the trustworthiness and interpretability of AI for clinical decision support.", "AI": {"tldr": "该论文提出了一种用于医疗异常检测的新型模型MedAD-R1，通过两阶段训练框架提升了模型在大规模多模态数据上的推理能力和一致性。", "motivation": "当前基于监督微调的大型多模态模型受限于简单且碎片化的数据集，难以实现连贯的医学推理和可靠的多模态泛化能力。因此需要一种新的方法来提升模型的诊断准确性及解释性。", "method": "提出MedAD-R1模型，包括两个阶段：认知注入通过监督微调将基础医学知识嵌入模型，并使其符合结构化的思考再作答模式；一致性强化策略优化确保生成推理过程与最终诊断结果一致且逻辑连贯。", "result": "在MedAD-38K基准测试中，所提出的MedAD-R1模型优于其他强大基线超过10%，表现出更强的透明性和逻辑一致性。", "conclusion": "该方法通过提升AI系统的可解释性和可信度为临床决策支持提供了新的途径。"}}
{"id": "2602.01078", "pdf": "https://arxiv.org/pdf/2602.01078", "abs": "https://arxiv.org/abs/2602.01078", "authors": ["Tong Xia", "Weibin Li", "Gang Liu", "Yong Li"], "title": "AutoHealth: An Uncertainty-Aware Multi-Agent System for Autonomous Health Data Modeling", "categories": ["cs.AI"], "comment": null, "summary": "LLM-based agents have demonstrated strong potential for autonomous machine learning, yet their applicability to health data remains limited. Existing systems often struggle to generalize across heterogeneous health data modalities, rely heavily on predefined solution templates with insufficient adaptation to task-specific objectives, and largely overlook uncertainty estimation, which is essential for reliable decision-making in healthcare. To address these challenges, we propose \\textit{AutoHealth}, a novel uncertainty-aware multi-agent system that autonomously models health data and assesses model reliability. \\textit{AutoHealth} employs closed-loop coordination among five specialized agents to perform data exploration, task-conditioned model construction, training, and optimization, while jointly prioritizing predictive performance and uncertainty quantification. Beyond producing ready-to-use models, the system generates comprehensive reports to support trustworthy interpretation and risk-aware decision-making. To rigorously evaluate its effectiveness, we curate a challenging real-world benchmark comprising 17 tasks across diverse data modalities and learning settings. \\textit{AutoHealth} completes all tasks and outperforms state-of-the-art baselines by 29.2\\% in prediction performance and 50.2\\% in uncertainty estimation.", "AI": {"tldr": "提出了一种名为AutoHealth的新型不确定度感知多智能体系统，用于自动建模健康数据并评估模型可靠性。", "motivation": "现有的基于LLM的代理在处理异构医疗数据时存在局限性，需要解决推广能力弱、依赖预定义模板和忽略不确定性估计的问题。", "method": "AutoHealth通过五个专门的智能体之间的闭环协调来执行数据探索、任务条件下的模型构建、训练和优化，并优先考虑预测性能与不确定度量化。", "result": "在包含17个不同数据模态及学习设置的任务上，AutoHealth完成了所有任务并超越了最先进的基线，其预测性能高出29.2%，不确定性估计高出50.2%。", "conclusion": "通过闭环协调的多智能体系统，AutoHealth能更好地适应异构健康数据，并提高模型可靠性和决策质量。"}}
{"id": "2602.01077", "pdf": "https://arxiv.org/pdf/2602.01077", "abs": "https://arxiv.org/abs/2602.01077", "authors": ["Haopeng Li", "Shitong Shao", "Wenliang Zhong", "Zikai Zhou", "Lichen Bai", "Hui Xiong", "Zeke Xie"], "title": "PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers", "categories": ["cs.CV"], "comment": "17 pages", "summary": "Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as a faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality. Code is available at: https://github.com/xie-lab-ml/piecewise-sparse-attention.", "AI": {"tldr": "PISA提出了一种用于高效扩散变换器的分段稀疏注意力机制，该机制在保持高质量的同时提高了计算效率。", "motivation": "当前扩散变换器中的块稀疏注意力虽然加速了计算，但在高稀疏度下会因丢弃上下文而退化。PISA旨在通过精确或近似策略改善这一问题，从而提高稀疏注意力的设计。", "method": "PISA采用分段稀疏注意力机制，在保持关键区块完整计算的同时，对非关键区块进行高效逼近，利用块级泰勒展开方法来实现。", "result": "实验表明，PISA在Wan2.1-14B和Hunyuan-Video上分别实现了1.91倍和2.57倍的速度提升，在图像生成任务FLUX中也达到了1.2倍的加速，同时保持了最高质量。", "conclusion": "PISA通过引入精确或近似策略在提高计算效率的同时保证了高质量，成功地弥合了速度与质量之间的差距。"}}
{"id": "2602.01075", "pdf": "https://arxiv.org/pdf/2602.01075", "abs": "https://arxiv.org/abs/2602.01075", "authors": ["Yepeng Liu", "Yu Huang", "Yu-Xiang Wang", "Yingbin Liang", "Yuheng Bu"], "title": "ConvexBench: Can LLMs Recognize Convex Functions?", "categories": ["cs.AI"], "comment": null, "summary": "Convex analysis is a modern branch of mathematics with many applications. As Large Language Models (LLMs) start to automate research-level math and sciences, it is important for LLMs to demonstrate the ability to understand and reason with convexity. We introduce \\cb, a scalable and mechanically verifiable benchmark for testing \\textit{whether LLMs can identify the convexity of a symbolic objective under deep functional composition.} Experiments on frontier LLMs reveal a sharp compositional reasoning gap: performance degrades rapidly with increasing depth, dropping from an F1-score of $1.0$ at depth $2$ to approximately $0.2$ at depth $100$. Inspection of models' reasoning traces indicates two failure modes: \\textit{parsing failure} and \\textit{lazy reasoning}. To address these limitations, we propose an agentic divide-and-conquer framework that (i) offloads parsing to an external tool to construct an abstract syntax tree (AST) and (ii) enforces recursive reasoning over each intermediate sub-expression with focused context. This framework reliably mitigates deep-composition failures, achieving substantial performance improvement at large depths (e.g., F1-Score $= 1.0$ at depth $100$).", "AI": {"tldr": "本文介绍了ConvexBench，一个用于测试大型语言模型（LLMs）识别复合函数凸性的基准。", "motivation": "随着大型语言模型在研究级别的数学和科学自动化中应用的增加，需要它们能够理解和处理凸性。因此，构建了一个新的可扩展且机械验证的基准来检验这些能力。", "method": "通过实验揭示了LLMs在复合函数深度递增时识别凸性的性能迅速下降的问题，并提出了一个分而治之框架，包括使用外部工具解析抽象语法树和强制执行每个子表达式的递归推理。", "result": "实验表明，在未改进模型下，LLMs的准确性随着函数复杂度增加显著降低；应用提出的框架后，在深度100时也实现了F1得分1.0的良好表现。", "conclusion": "所提方法成功克服了大型语言模型在复合问题上的局限性，并提高了它们处理数学分析任务的能力。"}}
{"id": "2602.01074", "pdf": "https://arxiv.org/pdf/2602.01074", "abs": "https://arxiv.org/abs/2602.01074", "authors": ["Haitao Wang"], "title": "Counting Unit Circular Arc Intersections", "categories": ["cs.CG", "cs.DS"], "comment": "To appear in STACS 2026", "summary": "Given a set of $n$ circular arcs of the same radius in the plane, we consider the problem of computing the number of intersections among the arcs. The problem was studied before and the previously best algorithm solves the problem in $O(n^{4/3+ε})$ time [Agarwal, Pellegrini, and Sharir, SIAM J. Comput., 1993], for any constant $ε>0$. No progress has been made on the problem for more than 30 years. We present a new algorithm of $O(n^{4/3}\\log^{16/3}n)$ time and improve it to $O(n^{1+ε}+K^{1/3}n^{2/3}(\\frac{n^2}{n+K})^ε\\log^{16/3}n)$ time for small $K$, where $K$ is the number of intersections of all arcs.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.01071", "pdf": "https://arxiv.org/pdf/2602.01071", "abs": "https://arxiv.org/abs/2602.01071", "authors": ["Tsuyoshi Yoneda"], "title": "Vortex Stretching in the Navier-Stokes Equations and Information Dissipation in Diffusion Models: A Reformulation from a Partial Differential Equation Viewpoint", "categories": ["math.AP", "cs.AI", "physics.flu-dyn"], "comment": null, "summary": "We present a new inverse-time formulation of vortex stretching in the Navier-Stokes equations, based on a PDE framework inspired by score-based diffusion models. By absorbing the ill-posed backward Laplacian arising from time reversal into a drift term expressed through a score function, the inverse-time dynamics are formulated in a Lagrangian manner. Using a discrete Lagrangian flow of an axisymmetric vortex-stretching field, the score function is learned with a neural network and employed to construct backward-time particle trajectories. Numerical results demonstrate that information about initial positions is rapidly lost in the compressive direction, whereas it is relatively well preserved in the stretching direction.", "AI": {"tldr": "本文提出了一种逆时间形式的纳维-斯托克斯方程中的涡旋拉伸问题，通过偏微分方程框架将反向拉普拉斯算子转化为漂移项，并利用神经网络学习分数函数以构建逆时粒子轨迹。", "motivation": "为了更好地理解和解决纳维-斯托克斯方程中逆时间涡旋拉伸的不适定性问题，作者提出了一种基于偏微分方程框架的方法来重新定义该过程。", "method": "通过将反向拉普拉斯算子转化为分数函数表示的漂移项，并利用轴对称涡旋拉伸场的离散拉格朗日流，学习分数函数并构建逆时粒子轨迹。", "result": "数值结果显示，在压缩方向上关于初始位置的信息快速丢失，而在拉伸方向上则相对较好地保留了该信息。", "conclusion": "本文提出的逆时间涡旋拉伸模型和方法为理解纳维-斯托克斯方程中的复杂动力学提供了一个新的视角。"}}
{"id": "2602.01069", "pdf": "https://arxiv.org/pdf/2602.01069", "abs": "https://arxiv.org/abs/2602.01069", "authors": ["Seema K. Poudel", "Sunny K. Khadka"], "title": "PDE-Constrained Optimization for Neural Image Segmentation with Physics Priors", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Segmentation of microscopy images constitutes an ill-posed inverse problem due to measurement noise, weak object boundaries, and limited labeled data. Although deep neural networks provide flexible nonparametric estimators, unconstrained empirical risk minimization often leads to unstable solutions and poor generalization. In this work, image segmentation is formulated as a PDE-constrained optimization problem that integrates physically motivated priors into deep learning models through variational regularization. The proposed framework minimizes a composite objective function consisting of a data fidelity term and penalty terms derived from reaction-diffusion equations and phase-field interface energies, all implemented as differentiable residual losses. Experiments are conducted on the LIVECell dataset, a high-quality, manually annotated collection of phase-contrast microscopy images. Training is performed on two cell types, while evaluation is carried out on a distinct, unseen cell type to assess generalization. A UNet architecture is used as the unconstrained baseline model. Experimental results demonstrate consistent improvements in segmentation accuracy and boundary fidelity compared to unconstrained deep learning baselines. Moreover, the PDE-regularized models exhibit enhanced stability and improved generalization in low-sample regimes, highlighting the advantages of incorporating structured priors. The proposed approach illustrates how PDE-constrained optimization can strengthen data-driven learning frameworks, providing a principled bridge between variational methods, statistical learning, and scientific machine learning.", "AI": {"tldr": "本文提出了一种基于偏微分方程约束优化的神经网络图像分割方法，通过引入物理先验提高深度学习模型在显微镜图像分割中的准确性和鲁棒性。", "motivation": "显微图像分割是一个病态逆问题，测量噪声、弱边界和有限标注数据导致了不稳定解和差强人意的一般化性能。本文旨在通过整合偏微分方程约束优化框架来增强深度学习模型的稳健性和泛化能力。", "method": "将图像分割任务定义为一个包含数据保真度项和从反应扩散方程及相场界面能量中提取的惩罚项组成的复合目标函数最小化问题，采用可微残差损失实现物理先验的引入。实验在LIVECell数据集上进行，通过对比UNet架构模型验证改进。", "result": "实验结果表明所提出的PDE约束优化方法相比未受限制的传统深度学习基线，在分割精度、边界保真度以及低样本量下的泛化能力方面有显著提升。", "conclusion": "本文展示了如何利用偏微分方程约束优化加强基于数据的机器学习框架，有效结合了变分法、统计学习和科学机器学习的优势。"}}
{"id": "2602.01068", "pdf": "https://arxiv.org/pdf/2602.01068", "abs": "https://arxiv.org/abs/2602.01068", "authors": ["Chaoqun Cui", "Shijing Wang", "Liangbin Huang", "Qingqing Gu", "Zhaolong Huang", "Xiao Zeng", "Wenji Mao"], "title": "From Utterance to Vividity: Training Expressive Subtitle Translation LLM via Adaptive Local Preference Optimization", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ICLR 2026", "summary": "The rapid development of Large Language Models (LLMs) has significantly enhanced the general capabilities of machine translation. However, as application scenarios become more complex, the limitations of LLMs in vertical domain translations are gradually becoming apparent. In this study, we focus on how to construct translation LLMs that meet the needs of domain customization. We take visual media subtitle translation as our topic and explore how to train expressive and vivid translation LLMs. We investigated the situations of subtitle translation and other domains of literal and liberal translation, verifying the reliability of LLM as reward model and evaluator for translation. Additionally, to train an expressive translation LLM, we constructed and released a multidirectional subtitle parallel corpus dataset and proposed the Adaptive Local Preference Optimization (ALPO) method to address fine-grained preference alignment. Experimental results demonstrate that ALPO achieves outstanding performance in multidimensional evaluation of translation quality.", "AI": {"tldr": "本文研究如何构建满足垂直领域定制需求的翻译大型语言模型，聚焦于视听媒体字幕翻译，提出自适应局部偏好优化（ALPO）方法以训练出表现力强、生动的翻译大模型。", "motivation": "随着大型语言模型的发展，机器翻译的能力得到显著提升。然而，在复杂的应用场景下，这些模型在垂直领域的翻译中表现出局限性，因此本文旨在探索如何为特定领域定制翻译模型。", "method": "本文构建了一个多方向的字幕平行语料库，并提出自适应局部偏好优化（ALPO）方法来应对细粒度偏好对齐的问题。此外还验证了大型语言模型作为奖励模型和评估器的有效性。", "result": "实验结果表明，ALPO在翻译质量的多维度评价中表现优异。", "conclusion": "通过自适应局部偏好优化（ALPO）方法，本文成功训练出一个适用于视听媒体字幕翻译且具有高表达力和生动性的大型语言模型。"}}
{"id": "2602.01067", "pdf": "https://arxiv.org/pdf/2602.01067", "abs": "https://arxiv.org/abs/2602.01067", "authors": ["Fanqi Lin", "Kushal Arora", "Jean Mercat", "Haruki Nishimura", "Paarth Shah", "Chen Xu", "Mengchao Zhang", "Mark Zolotas", "Maya Angeles", "Owen Pfannenstiehl", "Andrew Beaulieu", "Jose Barreiros"], "title": "A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Large behavior models have shown strong dexterous manipulation capabilities by extending imitation learning to large-scale training on multi-task robot data, yet their generalization remains limited by the insufficient robot data coverage. To expand this coverage without costly additional data collection, recent work relies on co-training: jointly learning from target robot data and heterogeneous data modalities. However, how different co-training data modalities and strategies affect policy performance remains poorly understood. We present a large-scale empirical study examining five co-training data modalities: standard vision-language data, dense language annotations for robot trajectories, cross-embodiment robot data, human videos, and discrete robot action tokens across single- and multi-phase training strategies. Our study leverages 4,000 hours of robot and human manipulation data and 50M vision-language samples to train vision-language-action policies. We evaluate 89 policies over 58,000 simulation rollouts and 2,835 real-world rollouts. Our results show that co-training with forms of vision-language and cross-embodiment robot data substantially improves generalization to distribution shifts, unseen tasks, and language following, while discrete action token variants yield no significant benefits. Combining effective modalities produces cumulative gains and enables rapid adaptation to unseen long-horizon dexterous tasks via fine-tuning. Training exclusively on robot data degrades the visiolinguistic understanding of the vision-language model backbone, while co-training with effective modalities restores these capabilities. Explicitly conditioning action generation on chain-of-thought traces learned from co-training data does not improve performance in our simulation benchmark. Together, these results provide practical guidance for building scalable generalist robot policies.", "AI": {"tldr": "研究系统地探讨了不同类型和策略的协作训练数据如何影响大型行为模型在机器人操纵任务中的性能。", "motivation": "当前大型行为模型由于机器人数据覆盖率不足，其泛化能力受到限制。通过联合学习目标机器人数据与异构数据模态来扩大数据覆盖范围而无需额外的成本投入是当下的研究方向之一。", "method": "该研究使用了五种协作训练数据模态：标准的视觉-语言数据、密集的语言注释用于机器人轨迹、跨身体类型的机器人数据、人类视频和离散的动作标记。评估89个策略，通过58,000次模拟滚动出和2,835次真实世界滚动出。", "result": "协作训练与形式的视觉-语言和跨身体类型机器人的数据显著改善了分布偏移、未见任务以及语言跟随的能力，而离散的动作标记变体并未带来显著好处。组合有效的模态可产生累积增益并能够快速适应未见过的长时程灵巧任务。", "conclusion": "研究结果提供了关于构建大规模通用机器人策略的实际指导建议。协作训练有助于提高视觉-语言模型的感知能力，但在模拟基准中，显式地根据从协作数据中学到的思想链条来调节行动生成并不能提升性能。"}}
{"id": "2602.01063", "pdf": "https://arxiv.org/pdf/2602.01063", "abs": "https://arxiv.org/abs/2602.01063", "authors": ["Bin Han", "Deuksin Kwon", "Jonathan Gratch"], "title": "Personality Expression Across Contexts: Linguistic and Behavioral Variation in LLM Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) can be conditioned with explicit personality prompts, yet their behavioral realization often varies depending on context. This study examines how identical personality prompts lead to distinct linguistic, behavioral, and emotional outcomes across four conversational settings: ice-breaking, negotiation, group decision, and empathy tasks. Results show that contextual cues systematically influence both personality expression and emotional tone, suggesting that the same traits are expressed differently depending on social and affective demands. This raises an important question for LLM-based dialogue agents: whether such variations reflect inconsistency or context-sensitive adaptation akin to human behavior. Viewed through the lens of Whole Trait Theory, these findings highlight that LLMs exhibit context-sensitive rather than fixed personality expression, adapting flexibly to social interaction goals and affective conditions.", "AI": {"tldr": "研究探讨了大型语言模型在不同情境下表现的个性差异。", "motivation": "探索相同个性提示在不同对话环境中产生的行为和情感变化，理解其背后的适应机制。", "method": "通过四种情景（破冰、谈判、团队决策、共情任务）测试同一性格提示下的语言模型反应。", "result": "结果显示环境线索系统地影响了个性表达和情绪基调，表明同一种特质在不同的社会与情感需求下会有所不同表达。", "conclusion": "研究支持LLM展现的是情境敏感而非固定不变的个性特征，并且能够根据社交互动目标和情感条件灵活调整。"}}
{"id": "2602.01062", "pdf": "https://arxiv.org/pdf/2602.01062", "abs": "https://arxiv.org/abs/2602.01062", "authors": ["Chenyi Li", "Yuan Zhang", "Bo Wang", "Guoqing Ma", "Wei Tang", "Haoyang Huang", "Nan Duan"], "title": "SetPO: Set-Level Policy Optimization for Diversity-Preserving LLM Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement learning with verifiable rewards has shown notable effectiveness in enhancing large language models (LLMs) reasoning performance, especially in mathematics tasks. However, such improvements often come with reduced outcome diversity, where the model concentrates probability mass on a narrow set of solutions. Motivated by diminishing-returns principles, we introduce a set level diversity objective defined over sampled trajectories using kernelized similarity. Our approach derives a leave-one-out marginal contribution for each sampled trajectory and integrates this objective as a plug-in advantage shaping term for policy optimization. We further investigate the contribution of a single trajectory to language model diversity within a distribution perturbation framework. This analysis theoretically confirms a monotonicity property, proving that rarer trajectories yield consistently higher marginal contributions to the global diversity. Extensive experiments across a range of model scales demonstrate the effectiveness of our proposed algorithm, consistently outperforming strong baselines in both Pass@1 and Pass@K across various benchmarks.", "AI": {"tldr": "本文提出了SetPO，一种基于集合级别的策略优化方法，用于保持大语言模型（LLM）在推理任务中结果的多样性。", "motivation": "强化学习与可验证奖励结合的方法虽然提高了LLM在数学等任务上的性能，但也导致了输出多样性的减少。为此引入了一种新的集合级别多样性目标函数，以解决这一问题。", "method": "通过利用核化相似度定义一个基于采样轨迹的集合层次多样性指标，并提出一种leave-one-out边际贡献方法来优化策略。同时，在分布扰动框架下探讨单个样本对整体多样性的贡献理论。", "result": "实验结果表明，本文提出的SetPO算法在各种模型规模和基准测试上均优于现有基线方法，在Pass@1和Pass@K指标上有显著提升。", "conclusion": "本文通过集合层次的策略优化成功提升了大语言模型推理任务中的输出多样性，并证明了该方法的有效性。"}}
{"id": "2602.01061", "pdf": "https://arxiv.org/pdf/2602.01061", "abs": "https://arxiv.org/abs/2602.01061", "authors": ["Linjie Qiu", "Duotun Wang", "Boyu Li", "Jiawei Li", "Yulin Shen", "Zeyu Wang", "Mingming Fan"], "title": "Direct vs. Score-based Selection: Understanding the Heisenberg Effect in Target Acquisition Across Input Modalities in Virtual Reality", "categories": ["cs.HC"], "comment": "Accepted by TVCG and IEEE VR'26", "summary": "Target selection is a fundamental interaction in virtual reality (VR). But the act of confirming a selection, such as a button press or pinch, can disturb the tracked pose and shift the intended target, which is referred to as the Heisenberg Effect. Prior research has mainly investigated controller input. However, it remains unclear how the effect manifests in the bare-hand input and how score-based techniques may mitigate the effect in different spatial variations. To fill the gap, we conduct a within-subject study to examine the Heisenberg Effect across two input modalities (i.e., controller and hand) and two selection mechanisms (i.e., direct and score-based). Our results show that hand input is more susceptible to the Heisenberg Effect, with direct selection more influenced by target width and score-based selection more sensitive to target density. Based on previous vote-oriented technique and our temporal analysis, we introduce weighted VOTE, a history-based intention accuracy model for target voting, that reweights recent interaction intent to counteract input disturbances. Our evaluation shows the method improves selection accuracy compared to baseline techniques. Finally, we discuss future directions for adaptive selection methods.", "AI": {"tldr": "研究对比了虚拟现实环境中控制器和裸手输入的直接选择与评分机制对海森堡效应的影响，并提出了加权VOTE模型以提高目标选取准确性。", "motivation": "以往的研究主要关注控制器输入，对于裸手输入在不同空间变化下如何受到海森堡效应影响以及评分方法能否减轻这种影响尚不清楚。", "method": "进行了两组被试内实验来对比两种输入模式（控制器和裸手）及两种选择机制（直接和评分）下的海森堡效应，并引入加权VOTE模型以增强目标选取准确性。", "result": "结果显示，裸手输入更容易受到海森堡效应的影响；而直接选择会更多地受制于目标宽度的变化，评分选择则更敏感于目标密度。评估表明，与基线技术相比，加权VOTE方法在提高选取精度方面效果更好。", "conclusion": "研究发现并探讨了不同输入模式和选择机制下的海森堡效应，提出了一个基于历史意图的历史加权模型来减轻输入干扰，并提出未来适应性选择方法的发展方向。"}}
{"id": "2602.01060", "pdf": "https://arxiv.org/pdf/2602.01060", "abs": "https://arxiv.org/abs/2602.01060", "authors": ["Chengyuan Ma", "Peng Jia", "Hongyue Guo", "Wenming Yang"], "title": "TLDiffGAN: A Latent Diffusion-GAN Framework with Temporal Information Fusion for Anomalous Sound Detection", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted by ICASSP 2026", "summary": "Existing generative models for unsupervised anomalous sound detection are limited by their inability to fully capture the complex feature distribution of normal sounds, while the potential of powerful diffusion models in this domain remains largely unexplored. To address this challenge, we propose a novel framework, TLDiffGAN, which consists of two complementary branches. One branch incorporates a latent diffusion model into the GAN generator for adversarial training, thereby making the discriminator's task more challenging and improving the quality of generated samples. The other branch leverages pretrained audio model encoders to extract features directly from raw audio waveforms for auxiliary discrimination. This framework effectively captures feature representations of normal sounds from both raw audio and Mel spectrograms. Moreover, we introduce a TMixup spectrogram augmentation technique to enhance sensitivity to subtle and localized temporal patterns that are often overlooked. Extensive experiments on the DCASE 2020 Challenge Task 2 dataset demonstrate the superior detection performance of TLDiffGAN, as well as its strong capability in anomalous time-frequency localization.", "AI": {"tldr": "提出了一种基于生成对抗网络和扩散模型的新型框架TLDiffGAN，用于无监督异常声音检测。", "motivation": "现有的生成模型在捕捉正常声音复杂特征分布方面存在局限性，而强大的扩散模型在此领域的潜力尚未充分发掘。", "method": "该框架包含两个互补分支：一个将潜在扩散模型集成到GAN生成器中进行对抗训练；另一个利用预训练的音频模型编码器从原始波形直接提取特征。引入TMixup频谱增强技术以提高对细微和局部时间模式的敏感度。", "result": "实验显示，TLDiffGAN在DCASE 2020 Challenge Task 2数据集上的检测性能优越，并具有强大的异常时间和频率定位能力。", "conclusion": "TLDiffGAN框架通过结合扩散模型与生成对抗网络以及有效的频谱增强技术，在无监督异常声音检测中表现出显著优势。"}}
{"id": "2602.01059", "pdf": "https://arxiv.org/pdf/2602.01059", "abs": "https://arxiv.org/abs/2602.01059", "authors": ["Ying Shu", "Pujian Zhan", "Huiqi Yang", "Hehe Fan", "Youfang Lin", "Kai Lv"], "title": "DRFormer: A Dual-Regularized Bidirectional Transformer for Person Re-identification", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Both fine-grained discriminative details and global semantic features can contribute to solving person re-identification challenges, such as occlusion and pose variations. Vision foundation models (\\textit{e.g.}, DINO) excel at mining local textures, and vision-language models (\\textit{e.g.}, CLIP) capture strong global semantic difference. Existing methods predominantly rely on a single paradigm, neglecting the potential benefits of their integration. In this paper, we analyze the complementary roles of these two architectures and propose a framework to synergize their strengths by a \\textbf{D}ual-\\textbf{R}egularized Bidirectional \\textbf{Transformer} (\\textbf{DRFormer}). The dual-regularization mechanism ensures diverse feature extraction and achieves a better balance in the contributions of the two models. Extensive experiments on five benchmarks show that our method effectively harmonizes local and global representations, achieving competitive performance against state-of-the-art methods.", "AI": {"tldr": "本文提出了一种双正则化双向变压器（DRFormer）框架，结合了视觉基础模型和视觉语言模型的优点，以解决人员再识别挑战。", "motivation": "现有的方法主要依赖于单一的范式来提取特征，忽略了将视觉基础模型和视觉语言模型相结合可能带来的潜在优势。本文旨在通过分析这两种架构的互补作用并提出一种集成它们优点的方法。", "method": "提出了一种双正则化双向变压器（DRFormer）框架，该框架利用了视觉基础模型擅长挖掘局部纹理的能力以及视觉语言模型捕捉强全局语义差异的优势，并通过双重正则化机制确保多样化特征提取和两种模型贡献的更好平衡。", "result": "在五个基准数据集上的广泛实验表明，所提出的方法能够有效地融合局部和全局表示，表现出色，与当前最先进的方法相比具有竞争力。", "conclusion": "本文提出的DRFormer框架通过集成视觉基础模型和视觉语言模型的优点，在人员再识别任务中取得了优异的性能。"}}
{"id": "2602.01058", "pdf": "https://arxiv.org/pdf/2602.01058", "abs": "https://arxiv.org/abs/2602.01058", "authors": ["Dylan Zhang", "Yufeng Xu", "Haojin Wang", "Qingzhi Chen", "Hao Peng"], "title": "Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Post-training of reasoning LLMs is a holistic process that typically consists of an offline SFT stage followed by an online reinforcement learning (RL) stage. However, SFT is often optimized in isolation to maximize SFT performance alone. We show that, after identical RL training, models initialized from stronger SFT checkpoints can significantly underperform those initialized from weaker ones. We attribute this to a mismatch typical in current SFT-RL pipelines: the distribution that generates the offline SFT data can differ substantially from the policy optimized during online RL, which learns from its own rollouts. We propose PEAR (Policy Evaluation-inspired Algorithm for Offline Learning Loss Re-weighting), an SFT-stage method that corrects this mismatch and better prepares the model for RL. PEAR uses importance sampling to reweight the SFT loss, with three variants operating at the token, block, and sequence levels. It can be used to augment standard SFT objectives and incurs little additional training overhead once probabilities for the offline data are collected. We conduct controlled experiments on verifiable reasoning games and mathematical reasoning tasks on Qwen 2.5 and 3 and DeepSeek-distilled models. PEAR consistently improves post-RL performance over canonical SFT, with pass at 8 gains up to a 14.6 percent on AIME2025. Our results suggest that PEAR is an effective step toward more holistic LLM post-training by designing and evaluating SFT with downstream RL in mind rather than in isolation.", "AI": {"tldr": "本文提出了一种名为PEAR的方法，用于改进大型语言模型的有监督微调（SFT）过程，使其更好地为后续的强化学习阶段做准备。", "motivation": "现有的SFT阶段通常独立优化以提高其自身性能，但这种做法可能导致在RL阶段表现不佳。这归因于SFT数据分布与在线RL期间使用的策略之间的不匹配。", "method": "PEAR通过重要性采样重新加权SFT损失，针对标记、块和序列三个级别进行操作，并可以作为标准SFT目标的增强手段，在收集了离线数据的概率后几乎不会增加额外训练开销。", "result": "在可控实验中，使用Qwen 2.5和3及DeepSeek蒸馏模型进行了验证推理游戏和数学推理任务测试。结果显示PEAR能显著提升经过RL后的性能表现，最高可达到14.6％的AIME2025通过率增长。", "conclusion": "研究结果表明，将SFT与下游的RL目标相结合进行设计和评估是改进LLM后期训练的关键步骤，PEAR方法有效地促进了这一过程。"}}
{"id": "2602.01057", "pdf": "https://arxiv.org/pdf/2602.01057", "abs": "https://arxiv.org/abs/2602.01057", "authors": ["Ling Chen", "Bao Yang"], "title": "Radioactive 3D Gaussian Ray Tracing for Tomographic Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has recently emerged in computer vision as a promising rendering technique. By adapting the principles of Elliptical Weighted Average (EWA) splatting to a modern differentiable pipeline, 3DGS enables real-time, high-quality novel view synthesis. Building upon this, R2-Gaussian extended the 3DGS paradigm to tomographic reconstruction by rectifying integration bias, achieving state-of-the-art performance in computed tomography (CT). To enable differentiability, R2-Gaussian adopts a local affine approximation: each 3D Gaussian is locally mapped to a 2D Gaussian on the detector and composed via alpha blending to form projections. However, the affine approximation can degrade reconstruction quantitative accuracy and complicate the incorporation of nonlinear geometric corrections. To address these limitations, we propose a tomographic reconstruction framework based on 3D Gaussian ray tracing. Our approach provides two key advantages over splatting-based models: (i) it computes the line integral through 3D Gaussian primitives analytically, avoiding the local affine collapse and thus yielding a more physically consistent forward projection model; and (ii) the ray-tracing formulation gives explicit control over ray origins and directions, which facilitates the precise application of nonlinear geometric corrections, e.g., arc-correction used in positron emission tomography (PET). These properties extend the applicability of Gaussian-based reconstruction to a wider range of realistic tomography systems while improving projection accuracy.", "AI": {"tldr": "基于3D高斯光追的断层重建框架", "motivation": "解决R2-Gaussian方法中的局部仿射近似带来的精度损失及几何校正复杂性问题，提高投影准确性，并扩展应用范围", "method": "通过3D高斯光追计算线积分，提供对光线起点和方向的精确控制以进行非线性几何校正", "result": "改进了重建定量准确性和投影模型的一致性", "conclusion": "提出的基于3D高斯光追的方法能提升各种实际断层成像系统中的重建质量和准确性"}}
{"id": "2602.01055", "pdf": "https://arxiv.org/pdf/2602.01055", "abs": "https://arxiv.org/abs/2602.01055", "authors": ["Bo Deng", "Yitong Tang", "Jiake Li", "Yuxin Huang", "Li Wang", "Yu Zhang", "Yufei Zhan", "Hua Lu", "Xiaoshen Zhang", "Jieyun Bai"], "title": "Baseline Method of the Foundation Model Challenge for Ultrasound Image Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Ultrasound (US) imaging exhibits substantial heterogeneity across anatomical structures and acquisition protocols, posing significant challenges to the development of generalizable analysis models. Most existing methods are task-specific, limiting their suitability as clinically deployable foundation models. To address this limitation, the Foundation Model Challenge for Ultrasound Image Analysis (FM\\_UIA~2026) introduces a large-scale multi-task benchmark comprising 27 subtasks across segmentation, classification, detection, and regression. In this paper, we present the official baseline for FM\\_UIA~2026 based on a unified Multi-Head Multi-Task Learning (MH-MTL) framework that supports all tasks within a single shared network. The model employs an ImageNet-pretrained EfficientNet--B4 backbone for robust feature extraction, combined with a Feature Pyramid Network (FPN) to capture multi-scale contextual information. A task-specific routing strategy enables global tasks to leverage high-level semantic features, while dense prediction tasks exploit spatially detailed FPN representations. Training incorporates a composite loss with task-adaptive learning rate scaling and a cosine annealing schedule. Validation results demonstrate the feasibility and robustness of this unified design, establishing a strong and extensible baseline for ultrasound foundation model research. The code and dataset are publicly available at \\href{https://github.com/lijiake2408/Foundation-Model-Challenge-for-Ultrasound-Image-Analysis}{GitHub}.", "AI": {"tldr": "提出了一个统一的多任务学习框架，用于基础模型挑战中的超声图像分析。", "motivation": "现有的方法大多针对特定任务，难以作为临床可用的基础模型。为了提高模型的泛化能力，作者设计了一个能够支持多种任务的大规模基准测试。", "method": "采用ImageNet预训练的EfficientNet-B4主干网提取特征，并结合特征金字塔网络（FPN）捕捉多尺度上下文信息。通过特定的任务路由策略和复合损失函数进行模型训练。", "result": "验证结果显示该统一设计的有效性和鲁棒性，为超声基础模型研究奠定了坚实的基础。", "conclusion": "提出的基线方法在FM_UIA挑战中表现出色，证明了其作为临床部署的可行性，并且代码和数据集公开可用。"}}
{"id": "2602.01050", "pdf": "https://arxiv.org/pdf/2602.01050", "abs": "https://arxiv.org/abs/2602.01050", "authors": ["Avinash Ajit Nargund", "Andrea M. Park", "Tobias Höllerer", "Misha Sra"], "title": "Embedded vs. Situated: An Evaluation of AR Facial Training Feedback", "categories": ["cs.HC"], "comment": "Conditionally accepted to ACM CHI 2026", "summary": "While augmented reality (AR) research demonstrates benefits of embedded visualizations for gross motor training, its applicability to facial exercises remains under-explored. Providing effective real-time feedback for facial muscle training presents unique design challenges, given the complexity of facial musculature. We developed three AR feedback approaches varying in spatial relationship to the user: situated (screen-fixed), proxy-embedded (on a mannequin), and fully embedded (overlaid on the user's face). In a within-subjects study (N=24), we measured exercise accuracy, cognitive load, and user preference during facial training tasks. The embedded feedback reduced cognitive load and received higher preference ratings, while the situated feedback enabled more precise corrections and higher accuracy. Qualitative analysis revealed a key design tension: embedded feedback improved experience but created self-consciousness and interpretive difficulty. We distill these insights into design considerations addressing the trade-offs for facial training systems, with implications for rehabilitation, performance training, and motor skill acquisition.", "AI": {"tldr": "评估了增强现实(AR)在面部肌肉训练中的应用，通过不同反馈方式的对比实验来探讨其有效性。", "motivation": "虽然已有研究表明嵌入式可视化对粗大运动训练有益，但对于面部肌肉锻炼的应用尚不充分。提供有效的实时反馈对于复杂的面部肌肉训练是一个独特的挑战。", "method": "开发了三种不同的AR反馈方法：位于用户屏幕上的固定位置、放在模型身上的嵌入式以及叠加在用户脸上的完全嵌入式。通过一项包含24个参与者的实验，测量了面部练习的准确性、认知负荷和用户偏好。", "result": "研究发现嵌入式的反馈减少了认知负担并获得了更高的偏好评分；而固定位置的反馈则允许更精确地修正并且提高了准确性。", "conclusion": "提出了设计时需要考虑的关键权衡点：虽然嵌入式反馈可以改善用户体验，但它也可能引起用户的自我意识和解释困难。研究结果为康复、表演训练以及运动技能习得系统的设计提供了指导意义。"}}
{"id": "2602.01047", "pdf": "https://arxiv.org/pdf/2602.01047", "abs": "https://arxiv.org/abs/2602.01047", "authors": ["Xinrong Chen", "Xu Chu", "Yingmin Qiu", "Hengyuan Zhang", "Jing Xiong", "Shiyu Tang", "Shuai Liu", "Shaokang Yang", "Cheng Yang", "Hayden Kwok-Hay So", "Ngai Wong"], "title": "Residual Decoding: Mitigating Hallucinations in Large Vision-Language Models via History-Aware Residual Guidance", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) can reason effectively from image-text inputs and perform well in various multimodal tasks. Despite this success, they are affected by language priors and often produce hallucinations. Hallucinations denote generated content that is grammatically and syntactically coherent, yet bears no match or direct relevance to actual visual input. To address this problem, we propose Residual Decoding (ResDec). It is a novel training-free method that uses historical information to aid decoding. The method relies on the internal implicit reasoning mechanism and token logits evolution mechanism of LVLMs to correct biases. Extensive experiments demonstrate that ResDec effectively suppresses hallucinations induced by language priors, significantly improves visual grounding, and reduces object hallucinations. In addition to mitigating hallucinations, ResDec also performs exceptionally well on comprehensive LVLM benchmarks, highlighting its broad applicability.", "AI": {"tldr": "提出了一种名为Residual Decoding（残差解码）的方法，用于缓解大型视觉语言模型中的幻觉问题。", "motivation": "在处理图像文本输入时，大型视觉语言模型容易受到语言先验的影响并产生幻觉。为了减少这些错误信息的生成，研究者们提出了新的方法来解决这一问题。", "method": "提出了一种无需训练的新方法——残差解码（Residual Decoding），通过利用历史信息帮助解码过程，依赖于LVLMs内部隐含推理机制和token logits进化机制来纠正偏差。", "result": "实验表明，这种方法可以有效减少由语言先验引起的幻觉，提高视觉对齐，并降低对象幻觉。同时在综合评估基准测试中也表现出色，展示了广泛的应用性。", "conclusion": "Residual Decoding通过历史信息辅助解码过程，成功缓解了大型视觉语言模型中的幻觉问题，在多种任务上取得了显著改进，展示了其广泛的适用性和有效性"}}
{"id": "2602.01046", "pdf": "https://arxiv.org/pdf/2602.01046", "abs": "https://arxiv.org/abs/2602.01046", "authors": ["Jiawei Lin", "Shizhao Sun", "Danqing Huang", "Ting Liu", "Ji Li", "Jiang Bian"], "title": "ReLayout: Versatile and Structure-Preserving Design Layout Editing via Relation-Aware Design Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Automated redesign without manual adjustments marks a key step forward in the design workflow. In this work, we focus on a foundational redesign task termed design layout editing, which seeks to autonomously modify the geometric composition of a design based on user intents. To overcome the ambiguity of user needs expressed in natural language, we introduce four basic and important editing actions and standardize the format of editing operations. The underexplored task presents a unique challenge: satisfying specified editing operations while simultaneously preserving the layout structure of unedited elements. Besides, the scarcity of triplet (original design, editing operation, edited design) samples poses another formidable challenge. To this end, we present ReLayout, a novel framework for versatile and structure-preserving design layout editing that operates without triplet data. Specifically, ReLayout first introduces the relation graph, which contains the position and size relationships among unedited elements, as the constraint for layout structure preservation. Then, relation-aware design reconstruction (RADR) is proposed to bypass the data challenge. By learning to reconstruct a design from its elements, a relation graph, and a synthesized editing operation, RADR effectively emulates the editing process in a self-supervised manner. A multi-modal large language model serves as the backbone for RADR, unifying multiple editing actions within a single model and thus achieving versatile editing after fine-tuning. Qualitative, quantitative results and user studies show that ReLayout significantly outperforms the baseline models in terms of editing quality, accuracy, and layout structure preservation.", "AI": {"tldr": "本文提出了一种名为ReLayout的新框架，用于执行结构保持的设计布局编辑任务。", "motivation": "该研究旨在解决设计流程中的自动化重设计问题，特别是在满足用户意图的同时，保持未修改元素的布局结构。此外，还解决了在缺乏三元组数据（原始设计、编辑操作和编辑后设计）情况下进行训练的问题。", "method": "ReLayout通过引入关系图作为约束来保持布局结构，并提出了关系感知设计重建(RADR)方法以应对数据不足挑战。RADR可以从元素、关系图以及合成的编辑操作中学习重构设计，有效模拟了自我监督下的编辑过程。模型使用多模态大型语言模型作为基础架构，实现了各种编辑动作的一体化。", "result": "实验结果表明，ReLayout在编辑质量和准确性方面显著优于基线模型，并能更好地保留布局结构。", "conclusion": "ReLayout框架成功地解决了设计布局编辑中的关键挑战，证明了其在该任务上的卓越性能。"}}
{"id": "2602.01045", "pdf": "https://arxiv.org/pdf/2602.01045", "abs": "https://arxiv.org/abs/2602.01045", "authors": ["Zixin Jessie Chen", "Hao Chen", "Yizhou Liu", "Jeff Gore"], "title": "Superposition unifies power-law training dynamics", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "17 pages, 14 figures", "summary": "We investigate the role of feature superposition in the emergence of power-law training dynamics using a teacher-student framework. We first derive an analytic theory for training without superposition, establishing that the power-law training exponent depends on both the input data statistics and channel importance. Remarkably, we discover that a superposition bottleneck induces a transition to a universal power-law exponent of $\\sim 1$, independent of data and channel statistics. This one over time training with superposition represents an up to tenfold acceleration compared to the purely sequential learning that takes place in the absence of superposition. Our finding that superposition leads to rapid training with a data-independent power law exponent may have important implications for a wide range of neural networks that employ superposition, including production-scale large language models.", "AI": {"tldr": "研究特征叠加在幂律训练动力学中的作用", "motivation": "探讨特征叠加如何影响神经网络的训练效率，特别是在大型语言模型中的应用", "method": "通过教师-学生框架推导无叠加情况下的理论，并发现叠加瓶颈导致幂律指数变为约1，与数据和通道统计无关", "result": "叠加学习比纯顺序学习快达十倍，且具有数据独立性的幂律指数", "conclusion": "特征叠加可以加速训练过程并带来快速的数据独立性幂律增长"}}
{"id": "2602.01041", "pdf": "https://arxiv.org/pdf/2602.01041", "abs": "https://arxiv.org/abs/2602.01041", "authors": ["Akinosuke Tsutsumi", "Tomoya Itsuka", "Yuichiro Kasahara", "Tomoya Kouno", "Kota Akinari", "Genki Yamauchi", "Daisuke Endo", "Taro Abe", "Takeshi Hashimoto", "Keiji Nagatani", "Ryo Kurazume"], "title": "LLM-Based Behavior Tree Generation for Construction Machinery", "categories": ["cs.RO"], "comment": "7 pages, 7 figures", "summary": "Earthwork operations are facing an increasing demand, while workforce aging and skill loss create a pressing need for automation. ROS2-TMS for Construction, a Cyber-Physical System framework designed to coordinate construction machinery, has been proposed for autonomous operation; however, its reliance on manually designed Behavior Trees (BTs) limits scalability, particularly in scenarios involving heterogeneous machine cooperation. Recent advances in large language models (LLMs) offer new opportunities for task planning and BT generation. However, most existing approaches remain confined to simulations or simple manipulators, with relatively few applications demonstrated in real-world contexts, such as complex construction sites involving multiple machines. This paper proposes an LLM-based workflow for BT generation, introducing synchronization flags to enable safe and cooperative operation. The workflow consists of two steps: high-level planning, where the LLM generates synchronization flags, and BT generation using structured templates. Safety is ensured by planning with parameters stored in the system database. The proposed method is validated in simulation and further demonstrated through real-world experiments, highlighting its potential to advance automation in civil engineering.", "AI": {"tldr": "提出了一种基于大语言模型的生成行为树的工作流，以促进复杂施工现场中多种机器的合作。", "motivation": "当前ROS2-TMS框架依赖于手动设计的行为树，限制了其可扩展性。通过引入大语言模型可以提高任务规划和行为树生成的自动化程度。", "method": "采用两步流程：第一步是高层次计划阶段，利用大语言模型生成同步标志；第二步是在结构化模板帮助下进行行为树生成。确保安全性通过在系统数据库中存储参数来实现。", "result": "该方法已在模拟和实际实验中得到验证，并展示了其在土木工程自动化中的潜力。", "conclusion": "提出的方法能够有效解决复杂施工现场中多机器合作的问题，具有重要的应用前景。"}}
{"id": "2602.01040", "pdf": "https://arxiv.org/pdf/2602.01040", "abs": "https://arxiv.org/abs/2602.01040", "authors": ["Yuhang Zhang", "Chao Yan", "Jiaxi Yu", "Jiaping Xiao", "Mir Feroskhan"], "title": "Learning Adaptive Cross-Embodiment Visuomotor Policy with Contrastive Prompt Orchestration", "categories": ["cs.RO"], "comment": null, "summary": "Learning adaptive visuomotor policies for embodied agents remains a formidable challenge, particularly when facing cross-embodiment variations such as diverse sensor configurations and dynamic properties. Conventional learning approaches often struggle to separate task-relevant features from domain-specific variations (e.g., lighting, field-of-view, and rotation), leading to poor sample efficiency and catastrophic failure in unseen environments. To bridge this gap, we propose ContrAstive Prompt Orchestration (CAPO), a novel approach for learning visuomotor policies that integrates contrastive prompt learning and adaptive prompt orchestration. For prompt learning, we devise a hybrid contrastive learning strategy that integrates visual, temporal action, and text objectives to establish a pool of learnable prompts, where each prompt induces a visual representation encapsulating fine-grained domain factors. Based on these learned prompts, we introduce an adaptive prompt orchestration mechanism that dynamically aggregates these prompts conditioned on current observations. This enables the agent to adaptively construct optimal state representations by identifying dominant domain factors instantaneously. Consequently, the policy optimization is effectively shielded from irrelevant interference, preventing the common issue of overfitting to source domains. Extensive experiments demonstrate that CAPO significantly outperforms state-of-the-art baselines in sample efficiency and asymptotic performance. Crucially, it exhibits superior zero-shot adaptation across unseen target domains characterized by drastic environmental (e.g., illumination) and physical shifts (e.g., field-of-view and rotation), validating its effectiveness as a viable solution for cross-embodiment visuomotor policy adaptation.", "AI": {"tldr": "该论文提出了一种新的方法CAPO，用于学习适应不同身体配置的视动策略。", "motivation": "传统的学习方式难以区分任务相关特征与领域特定变化，导致样本效率低下和在未知环境中的失败。因此需要一种新方法来解决这个问题。", "method": "该论文提出了对比提示编排(CAPO)，结合了对比性提示学习和自适应提示编排机制，通过动态聚合这些提示来构建最优的状态表示。", "result": "实验结果显示CAPO显著优于现有的基线模型，在样本效率和极限性能方面均有提高，并能很好地适应未知领域的环境变化。", "conclusion": "该方法有效解决了跨身体配置的视动策略适应性问题，展示了其作为解决此类问题的有效方案。"}}
{"id": "2602.01039", "pdf": "https://arxiv.org/pdf/2602.01039", "abs": "https://arxiv.org/abs/2602.01039", "authors": ["Zhiwei Ling", "Hailiang Zhao", "Chao Zhang", "Xiang Ao", "Ziqi Wang", "Cheng Zhang", "Zhen Qin", "Xinkui Zhao", "Kingsum Chow", "Yuanqing Wu", "MengChu Zhou"], "title": "Adaptive Dual-Weighting Framework for Federated Learning via Out-of-Distribution Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across large-scale distributed service nodes while preserving data privacy, making it a cornerstone of intelligent service systems in edge-cloud environments. However, in real-world service-oriented deployments, data generated by heterogeneous users, devices, and application scenarios are inherently non-IID. This severe data heterogeneity critically undermines the convergence stability, generalization ability, and ultimately the quality of service delivered by the global model. To address this challenge, we propose FLood, a novel FL framework inspired by out-of-distribution (OOD) detection. FLood dynamically counteracts the adverse effects of heterogeneity through a dual-weighting mechanism that jointly governs local training and global aggregation. At the client level, it adaptively reweights the supervised loss by upweighting pseudo-OOD samples, thereby encouraging more robust learning from distributionally misaligned or challenging data. At the server level, it refines model aggregation by weighting client contributions according to their OOD confidence scores, prioritizing updates from clients with higher in-distribution consistency and enhancing the global model's robustness and convergence stability. Extensive experiments across multiple benchmarks under diverse non-IID settings demonstrate that FLood consistently outperforms state-of-the-art FL methods in both accuracy and generalization. Furthermore, FLood functions as an orthogonal plug-in module: it seamlessly integrates with existing FL algorithms to boost their performance under heterogeneity without modifying their core optimization logic. These properties make FLood a practical and scalable solution for deploying reliable intelligent services in real-world federated environments.", "AI": {"tldr": "提出一种基于出界检测的联邦学习框架FLood，通过双重加权机制提高异构数据下的模型稳定性和泛化能力。", "motivation": "解决联邦学习中非独立同分布的数据导致模型收敛性、泛化能力和服务质量下降的问题。", "method": "引入双重加权机制：客户端根据伪出界样本调整监督损失，服务器端依据客户端的出界置信度进行模型聚合。此方法增强了分布式环境中的训练鲁棒性和全局模型的一致稳定性。", "result": "实验结果表明，FLood在不同非独立同分布设置下均优于现有的联邦学习方法，在准确率和泛化性上表现优越。", "conclusion": "FLood作为一种通用模块，能够无缝集成到现有联邦学习算法中提升性能，为部署可靠的服务提供了可行的解决方案。"}}
{"id": "2602.01038", "pdf": "https://arxiv.org/pdf/2602.01038", "abs": "https://arxiv.org/abs/2602.01038", "authors": ["Lavisha Aggarwal", "Vikas Bahirwani", "Andrea Colaco"], "title": "From Videos to Conversations: Egocentric Instructions for Task Assistance", "categories": ["cs.CV"], "comment": null, "summary": "Many everyday tasks, ranging from appliance repair and cooking to car maintenance, require expert knowledge, particularly for complex, multi-step procedures. Despite growing interest in AI agents for augmented reality (AR) assistance, progress remains limited by the scarcity of large-scale multimodal conversational datasets grounded in real-world task execution, in part due to the cost and logistical complexity of human-assisted data collection. In this paper, we present a framework to automatically transform single person instructional videos into two-person multimodal task-guidance conversations. Our fully automatic pipeline, based on large language models, provides a scalable and cost efficient alternative to traditional data collection approaches. Using this framework, we introduce HowToDIV, a multimodal dataset comprising 507 conversations, 6,636 question answer pairs, and 24 hours of video spanning multiple domains. Each session consists of a multi-turn expert-novice interaction. Finally, we report baseline results using Gemma 3 and Qwen 2.5 on HowToDIV, providing an initial benchmark for multimodal procedural task assistance.", "AI": {"tldr": "该论文提出了一种自动将单人指导视频转换为双人多模态任务引导对话的框架，以生成大规模数据集。", "motivation": "当前AI代理在增强现实辅助方面进展受限，因为缺乏基于真实世界任务执行的大规模多模式会话语料库。这种限制部分由于人工协助数据收集的成本高和复杂性。", "method": "论文提出了一种全自动化管道，利用大型语言模型将单人指导视频转换为双人多模态对话数据集。", "result": "引入HowToDIV数据集，包含507个对话、6,636个问答对及24小时的视频资料。同时，使用Gemma 3和Qwen 2.5在该数据集上进行基准测试，并报告了初步结果。", "conclusion": "论文展示了自动化生成大规模多模态任务指导会话语料库的有效性，并为未来研究提供了初步基准。"}}
{"id": "2602.01037", "pdf": "https://arxiv.org/pdf/2602.01037", "abs": "https://arxiv.org/abs/2602.01037", "authors": ["Guangshuo Qin", "Zhiteng Li", "Zheng Chen", "Weihang Zhang", "Linghe Kong", "Yulun Zhang"], "title": "VEQ: Modality-Adaptive Quantization for MoE Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts(MoE) Vision-Language Models (VLMs) offer remarkable performance but incur prohibitive memory and computational costs, making compression essential. Post-Training Quantization (PTQ) is an effective training-free technique to address the massive memory and computation overhead. Existing quantization paradigms fall short as they are oblivious to two critical forms of heterogeneity: the inherent discrepancy between vision and language tokens, and the non-uniform contribution of different experts. To bridge this gap, we propose Visual Expert Quantization (VEQ), a dual-aware quantization framework designed to simultaneously accommodate cross-modal differences and heterogeneity between experts. Specifically, VEQ incorporates 1)Modality-expert-aware Quantization, which utilizes expert activation frequency to prioritize error minimization for pivotal experts, and 2)Modality-affinity-aware Quantization, which constructs an enhanced Hessian matrix by integrating token-expert affinity with modality information to guide the calibration process. Extensive experiments across diverse benchmarks verify that VEQ consistently outperforms state-of-the-art baselines. Specifically, under the W3A16 configuration, our method achieves significant average accuracy gains of 2.04\\% on Kimi-VL and 3.09\\% on Qwen3-VL compared to the previous SOTA quantization methods, demonstrating superior robustness across various multimodal tasks. Our code will be available at https://github.com/guangshuoqin/VEQ.", "AI": {"tldr": "该论文提出了VEQ，一种适用于MoE视觉语言模型的模态自适应量化框架。", "motivation": "现有的量化方法忽视了视觉与文本模态之间的异质性以及专家模块间贡献不均的问题，导致压缩效果不佳。为了填补这一空白，作者提出了一种新的双重视角量化框架VEQ。", "method": "VEQ包含两个核心组件：1）基于专家激活频率的模态-专家感知量化；2）通过结合token与专家的亲和度及模态信息构建增强Hessian矩阵进行校准的模态亲和性感知量化。这两个部分共同实现了对不同模态和专家模块的有效处理。", "result": "实验结果显示，VEQ在多个基准测试中优于现有的SOTA量化方法，在W3A16配置下比先前最佳方法分别提高了Kimi-VL模型2.04%的准确率以及Qwen3-VL模型3.09%的准确率。", "conclusion": "VEQ框架通过考虑视觉与语言模态之间的差异性及专家模块贡献不均的特点，展示了强大的压缩能力和广泛的适用性。"}}
{"id": "2602.01035", "pdf": "https://arxiv.org/pdf/2602.01035", "abs": "https://arxiv.org/abs/2602.01035", "authors": ["Chentian Sun"], "title": "FUSE-Flow: Scalable Real-Time Multi-View Point Cloud Reconstruction Using Confidence", "categories": ["cs.CV"], "comment": "A 5-page paper, prepared for submission to the 2026 IEEE International Conference on Image Processing (ICIP)", "summary": "Real-time multi-view point cloud reconstruction is a core problem in 3D vision and immersive perception, with wide applications in VR, AR, robotic navigation, digital twins, and computer interaction. Despite advances in multi-camera systems and high-resolution depth sensors, fusing large-scale multi-view depth observations into high-quality point clouds under strict real-time constraints remains challenging. Existing methods relying on voxel-based fusion, temporal accumulation, or global optimization suffer from high computational complexity, excessive memory usage, and limited scalability, failing to simultaneously achieve real-time performance, reconstruction quality, and multi-camera extensibility. We propose FUSE-Flow, a frame-wise, stateless, and linearly scalable point cloud streaming reconstruction framework. Each frame independently generates point cloud fragments, fused via two weights, measurement confidence and 3D distance consistency to suppress noise while preserving geometric details. For large-scale multi-camera efficiency, we introduce an adaptive spatial hashing-based weighted aggregation method: 3D space is adaptively partitioned by local point cloud density, representative points are selected per cell, and weighted fusion is performed to handle both sparse and dense regions. With GPU parallelization, FUSE-Flow achieves high-throughput, low-latency point cloud generation and fusion with linear complexity. Experiments demonstrate that the framework improves reconstruction stability and geometric fidelity in overlapping, depth-discontinuous, and dynamic scenes, while maintaining real-time frame rates on modern GPUs, verifying its effectiveness, robustness, and scalability.", "AI": {"tldr": "FUSE-Flow是一种实时多视图点云重建框架，通过自适应空间哈希和加权聚合技术，在保证高精度的同时实现了线性扩展性和低延迟。", "motivation": "现有的方法在大规模多视角深度观测融合成高质量的点云时存在计算复杂度高、内存使用量大以及可扩展性差的问题，无法同时满足实时性能、重建质量和多摄像头延展性的要求。", "method": "FUSE-Flow框架采用帧级无状态方式生成点云片段，并通过测量置信度和3D距离一致性来抑制噪声。引入自适应空间哈希方法分割局部点云密度区域并进行加权融合，实现高效处理稀疏与密集区域的能力。", "result": "实验结果显示FUSE-Flow在重叠、深度不连续及动态场景中提高了重建稳定性和几何保真度，并保持了现代GPU上的实时帧率。", "conclusion": "FUSE-Flow证明其能够有效应对大规模多视角点云重建挑战，具备高效率、鲁棒性以及可扩展性的优势。"}}
{"id": "2602.01034", "pdf": "https://arxiv.org/pdf/2602.01034", "abs": "https://arxiv.org/abs/2602.01034", "authors": ["Xiangwei Wang", "Wei Wang", "Ken Chen", "Nanduni Nimalsiri", "Saman Halgamuge"], "title": "Discovering Process-Outcome Credit in Multi-Step LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning (RL) serves as a potent paradigm for enhancing reasoning capabilities in Large Language Models (LLMs), yet standard outcome-based approaches often suffer from reward sparsity and inefficient credit assignment. In this paper, we propose a novel framework designed to provide continuous reward signals, which introduces a Step-wise Marginal Information Gain (MIG) mechanism that quantifies the intrinsic value of reasoning steps against a Monotonic Historical Watermark, effectively filtering out training noise. To ensure disentangled credit distribution, we implement a Decoupled Masking Strategy, applying process-oriented rewards specifically to the chain-of-thought (CoT) and outcome-oriented rewards to the full completion. Additionally, we incorporate a Dual-Gated SFT objective to stabilize training with high-quality structural and factual signals. Extensive experiments across textual and multi-modal benchmarks (e.g., MATH, Super-CLEVR) demonstrate that our approach consistently outperforms baselines such as GRPO in both sample efficiency and final accuracy. Furthermore, our model exhibits superior out-of-distribution robustness, demonstrating promising zero-shot transfer capabilities to unseen and challenging reasoning tasks.", "AI": {"tldr": "本文提出了一种新的框架，通过引入逐步边际信息增益机制和解耦掩码策略来提高大语言模型的推理能力。", "motivation": "标准的结果导向方法在强化学习中常常遭遇奖励稀疏性和信用分配效率低下的问题。因此，本文旨在提供一种可以有效解决这些问题的新方案。", "method": "该框架引入了一个逐步边际信息增益机制和一个解耦掩码策略来提供持续的奖励信号，并且通过双重门控SFT目标稳定训练过程。", "result": "实验结果表明，这种方法在样本效率和最终准确性方面都超过了GRPO等基线方法，在文本和多模态基准测试中表现出色。", "conclusion": "该模型展示了优秀的泛化能力，证明了其对未见推理任务的零样本迁移性能。"}}
{"id": "2602.01033", "pdf": "https://arxiv.org/pdf/2602.01033", "abs": "https://arxiv.org/abs/2602.01033", "authors": ["Chentian Sun"], "title": "GMAC: Global Multi-View Constraint for Automatic Multi-Camera Extrinsic Calibration", "categories": ["cs.CV"], "comment": "A 5-page paper with 1 figure, prepared for submission to the 2026 IEEE International Conference on Image Processing (ICIP)", "summary": "Automatic calibration of multi-camera systems, namely the accurate estimation of spatial extrinsic parameters, is fundamental for 3D reconstruction, panoramic perception, and multi-view data fusion. Existing methods typically rely on calibration targets, explicit geometric modeling, or task-specific neural networks. Such approaches often exhibit limited robustness and applicability in complex dynamic environments or online scenarios, making them difficult to deploy in practical applications. To address this, this paper proposes GMAC, a multi-camera extrinsic estimation framework based on the implicit geometric representations learned by multi-view reconstruction networks. GMAC models extrinsics as global variables constrained by the latent multi-view geometric structure and prunes and structurally reconfigures existing networks so that their latent features can directly support extrinsic prediction through a lightweight regression head, without requiring a completely new network design. Furthermore, GMAC jointly optimizes cross-view reprojection consistency and multi-view cycle consistency, ensuring geometric coherence across cameras while improving prediction accuracy and optimization stability. Experiments on both synthetic and real-world multi-camera datasets demonstrate that GMAC achieves accurate and stable extrinsic estimation without explicit 3D reconstruction or manual calibration, providing a new solution for efficient deployment and online calibration of multi-camera systems.", "AI": {"tldr": "提出GMAC框架，通过隐式几何表示实现多相机外参自动校准。", "motivation": "现有方法依赖于标定目标、显式几何建模或特定任务的神经网络，在复杂动态环境中难以应用。为解决这一问题，该研究提出了GMAC框架。", "method": "GMAC利用多视图重建网络学习到的隐式几何表示，将外参作为全局变量进行约束，并通过轻量级回归头实现直接预测。同时优化跨视角重投影一致性和多视角循环一致性，提高几何连贯性、预测准确性和优化稳定性。", "result": "实验结果表明，在合成和真实世界数据集上，GMAC无需显式3D重建或手动校准即可获得准确稳定的外参估计。", "conclusion": "GMAC提供了一种新的多相机系统高效部署与在线校准解决方案。"}}
{"id": "2602.01032", "pdf": "https://arxiv.org/pdf/2602.01032", "abs": "https://arxiv.org/abs/2602.01032", "authors": ["Zhili Nicholas Liang", "Soyeon Caren Han", "Qizhou Wang", "Christopher Leckie"], "title": "HierCon: Hierarchical Contrastive Attention for Audio Deepfake Detection", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Proceedings of The Web Conference 2026 (WWW'26), short track", "summary": "Audio deepfakes generated by modern TTS and voice conversion systems are increasingly difficult to distinguish from real speech, raising serious risks for security and online trust. While state-of-the-art self-supervised models provide rich multi-layer representations, existing detectors treat layers independently and overlook temporal and hierarchical dependencies critical for identifying synthetic artefacts. We propose HierCon, a hierarchical layer attention framework combined with margin-based contrastive learning that models dependencies across temporal frames, neighbouring layers, and layer groups, while encouraging domain-invariant embeddings. Evaluated on ASVspoof 2021 DF and In-the-Wild datasets, our method achieves state-of-the-art performance (1.93% and 6.87% EER), improving over independent layer weighting by 36.6% and 22.5% respectively. The results and attention visualisations confirm that hierarchical modelling enhances generalisation to cross-domain generation techniques and recording conditions.", "AI": {"tldr": "本文提出了一种用于音频深度伪造检测的层次对比注意力框架HierCon。", "motivation": "现代TTS和语音转换系统生成的音频深伪越来越难以与真实语音区分开来，这给安全性和在线信任带来了严重风险。现有的探测器独立处理层，忽视了对识别合成伪影至关重要的时间依赖性和层级依赖性。", "method": "本文提出了一种结合层次化层注意力框架和基于边际对比学习的HierCon方法，该方法可以建模跨时间帧、相邻层以及层组之间的依赖关系，并鼓励域不变嵌入。", "result": "在ASVspoof 2021 DF和野外数据集上的评估表明，本文的方法实现了最先进的性能（EER为1.93%和6.87%），相较于独立层权重分别提高了36.6%和22.5%。结果和注意力可视化证实了层次化建模增强了对跨域生成技术和记录条件的一般性。", "conclusion": "本文的方法在各种数据集上实现了显著的性能提升，证明了层次化模型可以增强音频深度伪造检测的有效性和鲁棒性。"}}
{"id": "2602.01031", "pdf": "https://arxiv.org/pdf/2602.01031", "abs": "https://arxiv.org/abs/2602.01031", "authors": ["Dongyang Fan", "Sebastien Delsad", "Nicolas Flammarion", "Maksym Andriushchenko"], "title": "HalluHard: A Hard Multi-Turn Hallucination Benchmark", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) still produce plausible-sounding but ungrounded factual claims, a problem that worsens in multi-turn dialogue as context grows and early errors cascade. We introduce $\\textbf{HalluHard}$, a challenging multi-turn hallucination benchmark with 950 seed questions spanning four high-stakes domains: legal cases, research questions, medical guidelines, and coding. We operationalize groundedness by requiring inline citations for factual assertions. To support reliable evaluation in open-ended settings, we propose a judging pipeline that iteratively retrieves evidence via web search. It can fetch, filter, and parse full-text sources (including PDFs) to assess whether cited material actually supports the generated content. Across a diverse set of frontier proprietary and open-weight models, hallucinations remain substantial even with web search ($\\approx 30\\%$ for the strongest configuration, Opus-4.5 with web search), with content-grounding errors persisting at high rates. Finally, we show that hallucination behavior is shaped by model capacity, turn position, effective reasoning, and the type of knowledge required.", "AI": {"tldr": "本文提出了一个名为HalluHard的多轮对话中事实错误生成的基准测试，旨在评估大语言模型在复杂场景下的表现。", "motivation": "大型语言模型仍然会生成看似合理的但实际上没有根据的事实陈述，在多轮对话中问题更加严重，早期错误会在后续交流中累积。", "method": "本文构建了一个包含950个种子问题的基准测试，涉及四个高风险领域，并提出了一套通过网络搜索评估模型输出可靠性的方法，包括证据检索、过滤和解析过程。", "result": "即使使用了网络搜索辅助，前沿语言模型在HalluHard基准上的事实错误率仍然较高（最强配置下约为30%），并且发现错误与模型容量等因素有关联。", "conclusion": "研究结果表明大型语言模型仍存在显著的事实生成问题，在复杂多轮对话中尤其明显。"}}
{"id": "2602.01030", "pdf": "https://arxiv.org/pdf/2602.01030", "abs": "https://arxiv.org/abs/2602.01030", "authors": ["Sheng-Lun Wei", "Yu-Ling Liao", "Yen-Hua Chang", "Hen-Hsen Huang", "Hsin-Hsi Chen"], "title": "Bias in the Ear of the Listener: Assessing Sensitivity in Audio Language Models Across Linguistic, Demographic, and Positional Variations", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted as a long findings paper at EACL 2026", "summary": "This work presents the first systematic investigation of speech bias in multilingual MLLMs. We construct and release the BiasInEar dataset, a speech-augmented benchmark based on Global MMLU Lite, spanning English, Chinese, and Korean, balanced by gender and accent, and totaling 70.8 hours ($\\approx$4,249 minutes) of speech with 11,200 questions. Using four complementary metrics (accuracy, entropy, APES, and Fleiss' $κ$), we evaluate nine representative models under linguistic (language and accent), demographic (gender), and structural (option order) perturbations. Our findings reveal that MLLMs are relatively robust to demographic factors but highly sensitive to language and option order, suggesting that speech can amplify existing structural biases. Moreover, architectural design and reasoning strategy substantially affect robustness across languages. Overall, this study establishes a unified framework for assessing fairness and robustness in speech-integrated LLMs, bridging the gap between text- and speech-based evaluation. The resources can be found at https://github.com/ntunlplab/BiasInEar.", "AI": {"tldr": "研究首次系统地调查了多语言大规模语言模型中的语音偏见，构建了一个基于Global MMLU Lite的BiasInEar数据集，并使用多种指标评估了九个代表性模型在不同因素下的表现。", "motivation": "通过揭示多语言大规模语言模型中语音偏见的存在及其影响，促进该领域更加公平和稳健的发展。", "method": "构造并发布了包含英语、中文和韩文共计70.8小时录音的BiasInEar数据集；利用准确性、熵、APES及Fleiss'κ四种评价指标，在语言、口音、性别等因素下评估了九个代表性模型的表现。", "result": "多语言大规模语言模型在性别因素上相对稳健，但在语言和选项顺序方面敏感度较高。架构设计与推理策略对跨语言的健壮性有显著影响。", "conclusion": "研究建立了一个统一框架来评估语音集成大型语言模型中的公平性和鲁棒性，并填补了文本和语音评估之间的差距。"}}
{"id": "2602.01026", "pdf": "https://arxiv.org/pdf/2602.01026", "abs": "https://arxiv.org/abs/2602.01026", "authors": ["Hiroyuki Iizuka"], "title": "The Stacked Autoencoder Evolution Hypothesis", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "This study introduces a novel theoretical framework, the Stacked Autoencoder Evolution Hypothesis, which proposes that biological evolutionary systems operate through multi-layered self-encoding and decoding processes, analogous to stacked autoencoders in deep learning. Rather than viewing evolution solely as gradual changes driven by mutation and selection, this hypothesis suggests that self-replication inherently compresses and reconstructs genetic information across hierarchical layers of abstraction. This layered structure enables evolutionary systems to explore diverse possibilities not only at the sequence level but also across progressively more abstract layers of representation, making it possible for even simple mutations to navigate these higher-order spaces.Such a mechanism may explain punctuated evolutionary patterns and changes that can appear as if they are goal-directed in natural evolution, by allowing mutations at deeper latent layers to trigger sudden, large-scale phenotypic shifts. To illustrate the plausibility of this mechanism, artificial chemistry simulations were conducted, demonstrating the spontaneous emergence of hierarchical autoencoder structures. This framework offers a new perspective on the informational dynamics underlying both continuous and discontinuous evolutionary change.", "AI": {"tldr": "提出了生物进化系统的新型理论框架——堆叠自动编码器演化假设，解释了生物进化的层级自我编码和解码过程。", "motivation": "旨在通过类似深度学习中的堆叠自动编码器机制来重新审视生物学上的遗传信息处理方式，提出新的视角以更好地理解连续性与非连续性的进化变化。", "method": "利用人工化学仿真展示了这种分层结构的自动生成，并提出了这一假设。", "result": "人工化学仿真的结果表明可以自发形成层级自动编码器结构，支持了该理论框架的有效性。", "conclusion": "提出的堆叠自动编码器演化假设为理解进化过程提供了一种新的信息动力学视角。"}}
{"id": "2602.01025", "pdf": "https://arxiv.org/pdf/2602.01025", "abs": "https://arxiv.org/abs/2602.01025", "authors": ["Kaiyuan Cui", "Yige Li", "Yutao Wu", "Xingjun Ma", "Sarah Erfani", "Christopher Leckie", "Hanxun Huang"], "title": "Toward Universal and Transferable Jailbreak Attacks on Vision-Language Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICLR 2026", "summary": "Vision-language models (VLMs) extend large language models (LLMs) with vision encoders, enabling text generation conditioned on both images and text. However, this multimodal integration expands the attack surface by exposing the model to image-based jailbreaks crafted to induce harmful responses. Existing gradient-based jailbreak methods transfer poorly, as adversarial patterns overfit to a single white-box surrogate and fail to generalise to black-box models. In this work, we propose Universal and transferable jailbreak (UltraBreak), a framework that constrains adversarial patterns through transformations and regularisation in the vision space, while relaxing textual targets through semantic-based objectives. By defining its loss in the textual embedding space of the target LLM, UltraBreak discovers universal adversarial patterns that generalise across diverse jailbreak objectives. This combination of vision-level regularisation and semantically guided textual supervision mitigates surrogate overfitting and enables strong transferability across both models and attack targets. Extensive experiments show that UltraBreak consistently outperforms prior jailbreak methods. Further analysis reveals why earlier approaches fail to transfer, highlighting that smoothing the loss landscape via semantic objectives is crucial for enabling universal and transferable jailbreaks. The code is publicly available in our \\href{https://github.com/kaiyuanCui/UltraBreak}{GitHub repository}.", "AI": {"tldr": "提出了一种通用且可转移的对视觉语言模型攻击框架UltraBreak，解决了现有梯度基攻击方法在不同模型间表现不佳的问题。", "motivation": "现有的基于梯度的攻击方法由于对抗样本过度拟合于单一白盒代理模型而难以泛化至黑盒模型。本文提出一种通用和可转移的方法来解决这一问题。", "method": "UltraBreak通过视觉空间中的转换和正则化约束了对抗模式，同时通过对文本目标进行基于语义的目标放松，在目标LLM的文本嵌入空间中定义其损失函数以发现可以跨多种攻击目标泛化的通用对抗模式。", "result": "实验结果表明，UltraBreak在广泛的攻击目标上持续优于先前的方法。进一步分析揭示了早期方法为何无法转移的原因，并强调通过语义目标平滑损失景观是实现通用和可转移攻击的关键。", "conclusion": "本文提出的UltraBreak框架通过结合视觉级别正则化和语义引导的文本监督，有效缓解了代理模型过度拟合的问题，实现了在不同模型和攻击目标之间的强泛化能力。"}}
{"id": "2602.01023", "pdf": "https://arxiv.org/pdf/2602.01023", "abs": "https://arxiv.org/abs/2602.01023", "authors": ["Kai Yuan", "Anthony Zheng", "Jia Hu", "Divyanshu Sheth", "Hemanth Velaga", "Kylee Kim", "Matteo Guarrera", "Besim Avci", "Jianhua Li", "Xuetao Yin", "Rajyashree Mukherjee", "Sean Suchter"], "title": "Unifying Ranking and Generation in Query Auto-Completion via Retrieval-Augmented Generation and Multi-Objective Alignment", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "11 pages, 4 figures", "summary": "Query Auto-Completion (QAC) suggests query completions as users type, helping them articulate intent and reach results more efficiently. Existing approaches face fundamental challenges: traditional retrieve-and-rank pipelines have limited long-tail coverage and require extensive feature engineering, while recent generative methods suffer from hallucination and safety risks. We present a unified framework that reformulates QAC as end-to-end list generation through Retrieval-Augmented Generation (RAG) and multi-objective Direct Preference Optimization (DPO). Our approach combines three key innovations: (1) reformulating QAC as end-to-end list generation with multi-objective optimization; (2) defining and deploying a suite of rule-based, model-based, and LLM-as-judge verifiers for QAC, and using them in a comprehensive methodology that combines RAG, multi-objective DPO, and iterative critique-revision for high-quality synthetic data; (3) a hybrid serving architecture enabling efficient production deployment under strict latency constraints. Evaluation on a large-scale commercial search platform demonstrates substantial improvements: offline metrics show gains across all dimensions, human evaluation yields +0.40 to +0.69 preference scores, and a controlled online experiment achieves 5.44\\% reduction in keystrokes and 3.46\\% increase in suggestion adoption, validating that unified generation with RAG and multi-objective alignment provides an effective solution for production QAC. This work represents a paradigm shift to end-to-end generation powered by large language models, RAG, and multi-objective alignment, establishing a production-validated framework that can benefit the broader search and recommendation industry.", "AI": {"tldr": "本文提出了一种统一框架，通过检索增强生成和多目标直接偏好优化来解决查询自动补全问题。", "motivation": "传统的方法在长尾覆盖率方面有限，并且需要大量的特征工程；而最近的生成方法则存在幻觉和安全风险。因此，作者希望通过一种新的框架解决这些问题。", "method": "提出了一种通过检索增强生成和多目标直接偏好优化来统一排名和生成的新框架，包含三个关键创新点：将QAC重新定义为端到端列表生成；定义并部署一整套基于规则、模型及大型语言模型作为裁判的验证器，并结合RAG，多目标DPO以及迭代批评修订进行高质量合成数据；提供了一种混合服务架构，在严格延迟限制下实现高效生产部署。", "result": "在大规模商业搜索平台上进行了评估，离线指标显示所有维度都有改进，人类评价提高了0.40到0.69的偏好分数，并且在线实验实现了减少5.44%的按键数和3.46%建议采纳率的成果。", "conclusion": "该工作代表了从传统的检索排序向基于大模型、RAG及多目标对齐的端到端生成方法的重大转变，为生产验证框架建立了基础，并可能惠及更广泛的搜索和推荐行业。"}}
{"id": "2602.01022", "pdf": "https://arxiv.org/pdf/2602.01022", "abs": "https://arxiv.org/abs/2602.01022", "authors": ["Brandon Yee", "Krishna Sharma"], "title": "Calibrating Behavioral Parameters with Large Language Models", "categories": ["econ.GN", "cs.AI"], "comment": null, "summary": "Behavioral parameters such as loss aversion, herding, and extrapolation are central to asset pricing models but remain difficult to measure reliably. We develop a framework that treats large language models (LLMs) as calibrated measurement instruments for behavioral parameters. Using four models and 24{,}000 agent--scenario pairs, we document systematic rationality bias in baseline LLM behavior, including attenuated loss aversion, weak herding, and near-zero disposition effects relative to human benchmarks. Profile-based calibration induces large, stable, and theoretically coherent shifts in several parameters, with calibrated loss aversion, herding, extrapolation, and anchoring reaching or exceeding benchmark magnitudes. To assess external validity, we embed calibrated parameters in an agent-based asset pricing model, where calibrated extrapolation generates short-horizon momentum and long-horizon reversal patterns consistent with empirical evidence. Our results establish measurement ranges, calibration functions, and explicit boundaries for eight canonical behavioral biases.", "AI": {"tldr": "本文开发了一个框架，利用大型语言模型（LLM）作为行为参数的校准测量工具。", "motivation": "行为参数如损失厌恶、羊群效应和外推等在资产定价模型中至关重要，但难以准确度量。因此，提出一种新的方法来改进这些参数的度量。", "method": "通过使用四个LLM模型和24000个代理-场景对，研究者发现了基线LLM行为中的系统性理性偏差，并通过基于档案的方法校准了多个参数。", "result": "校准后的损失厌恶、羊群效应、外推和锚定等八个典型的行为偏见达到了或超过了基准水平。在嵌入校准后参数的代理资产定价模型中，短时间内的动量与长时期内反转模式一致。", "conclusion": "研究结果确立了行为偏差的测量范围，并提供了明确界限和校准函数，提高了这些行为参数的度量准确性。"}}
{"id": "2602.01020", "pdf": "https://arxiv.org/pdf/2602.01020", "abs": "https://arxiv.org/abs/2602.01020", "authors": ["Jichen Yang", "Jikai Zhang", "Benjamin Wildman-Tobriner", "Maciej A. Mazurowski"], "title": "Effectiveness of Automatically Curated Dataset in Thyroid Nodules Classification Algorithms Using Deep Learning", "categories": ["cs.CV"], "comment": "9 pages, 3 figures", "summary": "The diagnosis of thyroid nodule cancers commonly utilizes ultrasound images. Several studies showed that deep learning algorithms designed to classify benign and malignant thyroid nodules could match radiologists' performance. However, data availability for training deep learning models is often limited due to the significant effort required to curate such datasets. The previous study proposed a method to curate thyroid nodule datasets automatically. It was tested to have a 63% yield rate and 83% accuracy. However, the usefulness of the generated data for training deep learning models remains unknown. In this study, we conducted experiments to determine whether using a automatically-curated dataset improves deep learning algorithms' performance. We trained deep learning models on the manually annotated and automatically-curated datasets. We also trained with a smaller subset of the automatically-curated dataset that has higher accuracy to explore the optimum usage of such dataset. As a result, the deep learning model trained on the manually selected dataset has an AUC of 0.643 (95% confidence interval [CI]: 0.62, 0.66). It is significantly lower than the AUC of the 6automatically-curated dataset trained deep learning model, 0.694 (95% confidence interval [CI]: 0.67, 0.73, P < .001). The AUC of the accurate subset trained deep learning model is 0.689 (95% confidence interval [CI]: 0.66, 0.72, P > .43), which is insignificantly worse than the AUC of the full automatically-curated dataset. In conclusion, we showed that using a automatically-curated dataset can substantially increase the performance of deep learning algorithms, and it is suggested to use all the data rather than only using the accurate subset.", "AI": {"tldr": "评估自动收集的数据集对甲状腺结节分类算法性能的影响", "motivation": "探索使用自动整理的甲状腺结节数据集训练深度学习模型的有效性，以解决手动标注数据集获取困难的问题。", "method": "对比基于手动注释和自动收集的两组不同数据集训练的深度学习模型的表现。同时测试了准确度较高的子集的效果。", "result": "自动整理的数据集训练出的模型AUC为0.694，显著优于手动注释数据集训练出的模型（AUC：0.643）。而使用高精度子集训练出的模型表现与完整自动收集数据集相近但稍差。", "conclusion": "利用自动整理的数据集可以显著提高甲状腺结节分类算法性能。建议充分利用全部自动收集的数据，而非仅依赖准确性较高的子集。"}}
{"id": "2602.01019", "pdf": "https://arxiv.org/pdf/2602.01019", "abs": "https://arxiv.org/abs/2602.01019", "authors": ["Xuan-The Tran", "Thien-Nhan Vo", "Son-Tung Vu", "Thoa-Thi Tran", "Manh-Dat Nguyen", "Thomas Do", "Chin-Teng Lin"], "title": "Inter- and Intra-Subject Variability in EEG: A Systematic Survey", "categories": ["q-bio.NC", "cs.AI", "cs.HC"], "comment": null, "summary": "Electroencephalography (EEG) underpins neuroscience, clinical neurophysiology, and brain-computer interfaces (BCIs), yet pronounced inter- and intra-subject variability limits reliability, reproducibility, and translation. This systematic review studies that quantified or modeled EEG variability across resting-state, event-related potentials (ERPs), and task-related/BCI paradigms (including motor imagery and SSVEP) in healthy and clinical cohorts. Across paradigms, inter-subject differences are typically larger than within-subject fluctuations, but both affect inference and model generalization. Stability is feature-dependent: alpha-band measures and individual alpha peak frequency are often relatively reliable, whereas higher-frequency and many connectivity-derived metrics show more heterogeneous reliability; ERP reliability varies by component, with P300 measures frequently showing moderate-to-good stability. We summarize major sources of variability (biological, state-related, technical, and analytical), review common quantification and modeling approaches (e.g., ICC, CV, SNR, generalizability theory, and multivariate/learning-based methods), and provide recommendations for study design, reporting, and harmonization. Overall, EEG variability should be treated as both a practical constraint to manage and a meaningful signal to leverage for precision neuroscience and robust neurotechnology.", "AI": {"tldr": "系统综述了不同范式下EEG变异性的量化和建模情况，探讨了其对神经科学、临床神经生理学以及脑机接口的影响。", "motivation": "研究EEG在静息状态、事件相关电位（ERP）及任务相关/BCI实验中的变异性以提高可靠性和可重复性，并为精确神经科学研究和稳健的神经技术提供基础。", "method": "综述了不同范式下量化或建模EEG变异性的方法，包括生物因素、状态相关因素、技术因素以及分析因素等；并总结了常用的方法如ICC, CV, SNR, 通则性理论及多变量/学习法。", "result": "发现个体间差异通常大于个体内的变化，但两者均影响推论和模型泛化能力；稳定性取决于特征：α频带测量和个别α峰值频率较可靠，而高频率和许多基于连接性的度量显示出更大的异质性；ERP可靠性因成分而异，P300度量经常表现出中等至良好的稳定性。", "conclusion": "EEG变异应被视作需要管理的实际限制以及精确神经科学和稳健的神经技术可以利用的重要信号。"}}
{"id": "2602.01018", "pdf": "https://arxiv.org/pdf/2602.01018", "abs": "https://arxiv.org/abs/2602.01018", "authors": ["Chongyu Zhu", "Mithun Vanniasinghe", "Jiayu Chen", "Chi-Guhn Lee"], "title": "Offline Discovery of Interpretable Skills from Multi-Task Trajectories", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Hierarchical Imitation Learning is a powerful paradigm for acquiring complex robot behaviors from demonstrations. A central challenge, however, lies in discovering reusable skills from long-horizon, multi-task offline data, especially when the data lacks explicit rewards or subtask annotations. In this work, we introduce LOKI, a three-stage end-to-end learning framework designed for offline skill discovery and hierarchical imitation. The framework commences with a two-stage, weakly supervised skill discovery process: Stage one performs coarse, task-aware macro-segmentation by employing an alignment-enforced Vector Quantized VAE guided by weak task labels. Stage two then refines these segments at a micro-level using a self-supervised sequential model, followed by an iterative clustering process to consolidate skill boundaries. The third stage then leverages these precise boundaries to construct a hierarchical policy within an option-based framework-complete with a learned termination condition beta for explicit skill switching. LOKI achieves high success rates on the challenging D4RL Kitchen benchmark and outperforms standard HIL baselines. Furthermore, we demonstrate that the discovered skills are semantically meaningful, aligning with human intuition, and exhibit compositionality by successfully sequencing them to solve a novel, unseen task.", "AI": {"tldr": "本文提出了一种名为LOKI的三阶段离线技能发现框架，用于从多任务轨迹中提取可解释的技能。", "motivation": "在没有明确奖励或子任务注释的情况下，如何从长时间跨度、多任务的离线数据中获取复用性技能是层次化模仿学习中的一个关键挑战。", "method": "LOKI框架包括三个阶段：首先进行基于弱监督的任务感知宏分割；随后通过自监督序列模型对这些段落进行细化，并采用迭代聚类过程来巩固技能边界。最后，在此精准基础上构建以选项为基础的分层策略，该策略包含一个学习到的终止条件β。", "result": "LOKI在挑战性的D4RL厨房基准测试中取得高成功率，并超越了标准层次化模仿学习基线模型。所发现的技能不仅具有语义意义、符合人类直觉，还能通过组合这些技能来解决未曾见过的新任务。", "conclusion": "该研究展示了LOKI框架的有效性及其在从离线数据中提取有意义且可组合技能方面的能力，为机器人行为学习提供了新的思路。"}}
{"id": "2602.01017", "pdf": "https://arxiv.org/pdf/2602.01017", "abs": "https://arxiv.org/abs/2602.01017", "authors": ["Fuxin Wang", "Amr Alazali", "Yiqiao Zhong"], "title": "How Does Unfaithful Reasoning Emerge from Autoregressive Training? A Study of Synthetic Experiments", "categories": ["cs.LG", "cs.AI"], "comment": "25 pages, 23 figures", "summary": "Chain-of-thought (CoT) reasoning generated by large language models (LLMs) is often unfaithful: intermediate steps can be logically inconsistent or fail to reflect the causal relationship leading to the final answer. Despite extensive empirical observations, a fundamental understanding of CoT is lacking--what constitutes faithful CoT reasoning, and how unfaithfulness emerges from autoregressive training. We study these questions using well-controlled synthetic experiments, training small transformers on noisy data to solve modular arithmetic expressions step by step, a task we term Arithmetic Expression Reasoning. We find that models can learn faithful reasoning that causally follows the underlying arithmetic rules, but only when the training noise is below a critical threshold, a phenomenon attributable to simplicity bias. At higher noise levels, training dynamics exhibit a transition from faithful stepwise reasoning to unfaithful skip-step reasoning via an intermediate mixed mode characterized by a transient increase in prediction entropy. Mechanistic analysis reveals that models learn to encode internal uncertainty by resolving inconsistent reasoning steps, which suggests the emergence of implicit self-verification from autoregressive training.", "AI": {"tldr": "研究大型语言模型在生成链式思维推理过程中出现的不忠实现象。", "motivation": "探讨链式思维推理中忠实性的定义以及其如何从自回归训练中产生不忠实性。", "method": "利用合成实验，训练小型transformer解决带噪声数据中的模块化算术表达式问题，并观察模型在不同噪音水平下的行为变化。", "result": "模型能够在训练噪音低于某一阈值时学习到忠实的推理方式；而在更高的噪音条件下，则会出现跳过步骤的不忠实推理。", "conclusion": "研究揭示了自回归训练中出现不忠实链式思维推理的现象，并提出了内部不确定性的编码机制。"}}
{"id": "2602.01012", "pdf": "https://arxiv.org/pdf/2602.01012", "abs": "https://arxiv.org/abs/2602.01012", "authors": ["Yiyang Su", "Minchul Kim", "Jie Zhu", "Christopher Perry", "Feng Liu", "Anil Jain", "Xiaoming Liu"], "title": "LocalScore: Local Density-Aware Similarity Scoring for Biometrics", "categories": ["cs.CV"], "comment": null, "summary": "Open-set biometrics faces challenges with probe subjects who may not be enrolled in the gallery, as traditional biometric systems struggle to detect these non-mated probes. Despite the growing prevalence of multi-sample galleries in real-world deployments, most existing methods collapse intra-subject variability into a single global representation, leading to suboptimal decision boundaries and poor open-set robustness. To address this issue, we propose LocalScore, a simple yet effective scoring algorithm that explicitly incorporates the local density of the gallery feature distribution using the k-th nearest neighbors. LocalScore is architecture-agnostic, loss-independent, and incurs negligible computational overhead, making it a plug-and-play solution for existing biometric systems. Extensive experiments across multiple modalities demonstrate that LocalScore consistently achieves substantial gains in open-set retrieval (FNIR@FPIR reduced from 53% to 40%) and verification (TAR@FAR improved from 51% to 74%). We further provide theoretical analysis and empirical validation explaining when and why the method achieves the most significant gains based on dataset characteristics.", "AI": {"tldr": "提出了一种基于局部密度感知的相似性评分方法LocalScore，以提高生物识别系统的开放集性能。", "motivation": "现有生物识别系统在处理未注册个体时表现不佳，因为它们通常将同一主体的数据简化为单一全局表示，导致决策边界不理想和开放集鲁棒性差。为了改进这一问题，研究者提出了LocalScore算法。", "method": "通过使用k-近邻来明确地考虑局部密度，LocalScore能够根据数据集中每个点的相对位置进行评分，而无需依赖特定架构或损失函数的设计。", "result": "实验结果表明，在多种模态下的开放集检索和验证任务中，LocalScore都能显著提高性能（FNIR@FPIR从53%降低到40%，TAR@FAR从51%提升至74%）。", "conclusion": "理论分析与实证研究共同证明了LocalScore在特定数据集特征下能够取得最佳效果。该方法具有架构无关性和轻量级优势，可作为现有生物识别系统的一种简单有效的增强手段。"}}
{"id": "2602.01011", "pdf": "https://arxiv.org/pdf/2602.01011", "abs": "https://arxiv.org/abs/2602.01011", "authors": ["Aneesh Pappu", "Batu El", "Hancheng Cao", "Carmelo di Nolfo", "Yanchao Sun", "Meng Cao", "James Zou"], "title": "Multi-Agent Teams Hold Experts Back", "categories": ["cs.MA", "cs.AI"], "comment": "Preprint", "summary": "Multi-agent LLM systems are increasingly deployed as autonomous collaborators, where agents interact freely rather than execute fixed, pre-specified workflows. In such settings, effective coordination cannot be fully designed in advance and must instead emerge through interaction. However, most prior work enforces coordination through fixed roles, workflows, or aggregation rules, leaving open the question of how well self-organizing teams perform when coordination is unconstrained. Drawing on organizational psychology, we study whether self-organizing LLM teams achieve strong synergy, where team performance matches or exceeds the best individual member. Across human-inspired and frontier ML benchmarks, we find that -- unlike human teams -- LLM teams consistently fail to match their expert agent's performance, even when explicitly told who the expert is, incurring performance losses of up to 37.6%. Decomposing this failure, we show that expert leveraging, rather than identification, is the primary bottleneck. Conversational analysis reveals a tendency toward integrative compromise -- averaging expert and non-expert views rather than appropriately weighting expertise -- which increases with team size and correlates negatively with performance. Interestingly, this consensus-seeking behavior improves robustness to adversarial agents, suggesting a trade-off between alignment and effective expertise utilization. Our findings reveal a significant gap in the ability of self-organizing multi-agent teams to harness the collective expertise of their members.", "AI": {"tldr": "本文研究了多代理团队在自我组织情况下是否能够实现集体效能，即团队表现能否达到甚至超过其中最优秀的成员的表现。", "motivation": "大多数先前的工作通过固定角色、工作流或聚合规则来强制协调，但很少探讨当协调是不受限制时，自组团队的表现如何。本文旨在研究大型语言模型组成的多代理系统在自我组织的情况下是否能实现强协同效应。", "method": "作者使用了人类启发和前沿机器学习基准测试，并通过对话分析来评估专家利用问题的严重性。", "result": "实验结果表明，与人类团队不同，LLM团队的表现通常无法达到其最优秀的成员，即使明确告知谁是最优秀的成员。这种失败主要归因于不恰当使用专家意见的问题，而不是识别出专家的能力。", "conclusion": "研究发现，在自我组织的多代理系统中存在一个显著的差距，即集体利用成员专业知识的能力不足。"}}
{"id": "2602.01009", "pdf": "https://arxiv.org/pdf/2602.01009", "abs": "https://arxiv.org/abs/2602.01009", "authors": ["Haoran Li", "Chenhan Xiao", "Lihao Mai", "Yang Weng", "Erik Blasch"], "title": "LASS-ODE: Scaling ODE Computations to Connect Foundation Models with Dynamical Physical Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models have transformed language, vision, and time series data analysis, yet progress on dynamic predictions for physical systems remains limited. Given the complexity of physical constraints, two challenges stand out. $(i)$ Physics-computation scalability: physics-informed learning can enforce physical regularization, but its computation (e.g., ODE integration) does not scale to extensive systems. $(ii)$ Knowledge-sharing efficiency: the attention mechanism is primarily computed within each system, which limits the extraction of shared ODE structures across systems. We show that enforcing ODE consistency does not require expensive nonlinear integration: a token-wise locally linear ODE representation preserves physical fidelity while scaling to foundation-model regimes. Thus, we propose novel token representations that respect locally linear ODE evolution. Such linearity substantially accelerates integration while accurately approximating the local data manifold. Second, we introduce a simple yet effective inter-system attention that augments attention with a common structure hub (CSH) that stores shared tokens and aggregates knowledge across systems. The resulting model, termed LASS-ODE (\\underline{LA}rge-\\underline{S}cale \\underline{S}mall \\underline{ODE}), is pretrained on our $40$GB ODE trajectory collections to enable strong in-domain performance, zero-shot generalization across diverse ODE systems, and additional improvements through fine-tuning.", "AI": {"tldr": "提出了一种名为LASS-ODE的方法，以解决大规模物理系统中的常微分方程（ODE）计算问题。", "motivation": "在复杂物理约束下，物理学信息学习虽能提供物理正则化但其计算成本高。同时注意力机制主要针对单一系统，限制了跨系统的共享结构提取效率。", "method": "通过引入局部线性ODE表示，加速了积分过程并准确地逼近本地数据流形；引入了一种简单而有效的跨系统注意力机制，并设置了公共结构中心以存储共享的令牌和聚合知识。", "result": "LASS-ODE模型预训练在40GB ODE轨迹集合上，实现了强大的领域内表现、零样本泛化以及通过微调获得改进。", "conclusion": "LASS-ODE有效地解决了大规模物理系统中的常微分方程计算问题，并提高了跨系统的知识共享效率。"}}
{"id": "2602.01008", "pdf": "https://arxiv.org/pdf/2602.01008", "abs": "https://arxiv.org/abs/2602.01008", "authors": ["Yang Xiao", "Eun-Jung Holden", "Ting Dang"], "title": "Adapting Where It Matters: Depth-Aware Adaptation for Efficient Multilingual Speech Recognition in Low-Resource Languages", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "13 pages", "summary": "Recent speech foundation models excel at multilingual automatic speech recognition (ASR) for high-resource languages, but adapting them to low-resource languages remains challenging due to data scarcity and efficiency constraints. Full-model fine-tuning is computationally expensive and prone to overfitting, while parameter-efficient methods like LoRA apply adaptation uniformly across layers, overlooking internal representations thus compromising effectiveness and efficiency. We analyze multilingual ASR models and reveal a U-shaped adaptability pattern: early and late layers are language-specific and require more adaptation, while intermediate layers retain shared semantics and need less. Building on this observation, we propose DAMA, a Depth-Aware Model Adaptation framework that allocates adaptation capacity according to each layer's role. DAMA also introduces Singular Value Decomposition (SVD)-based initialization to constrain adaptation and preserve the U-shaped pattern, as well as a frozen middle-layer basis for further efficiency. Evaluated on 18 low-resource languages across two benchmark datasets, DAMA matches or surpasses state-of-the-art accuracy with 80% fewer trainable parameters, achieves a 29% error reduction under extreme data scarcity, and significantly improves memory, training time, and computational efficiency over baselines. These results highlight the benefits of structure-aware adaptation for efficient, scalable multilingual ASR.", "AI": {"tldr": "本文提出了一种深度感知适应框架DAMA，用于多语言语音识别在低资源语言中的高效适应。", "motivation": "现有模型在高资源语言的多语言自动语音识别中表现出色，但在低资源语言上进行适应时面临数据不足和效率问题。全模型微调计算成本高昂且容易过拟合，参数高效的适应方法如LoRA则忽视了内部表示，影响效果和效率。", "method": "DAMA基于深度感知的适应框架，根据各层角色分配适应能力，并引入SVD初始化以保持U形模式，同时采用冻结中间层基础进一步提升效率。", "result": "在两个基准数据集上的18种低资源语言中，DAMA与最先进的准确度持平或超越，在极端稀缺数据下错误率降低29%，显著提升了内存、训练时间和计算效率。", "conclusion": "本文展示了结构感知适应对于高效可扩展多语言自动语音识别的重要性。"}}
{"id": "2602.01004", "pdf": "https://arxiv.org/pdf/2602.01004", "abs": "https://arxiv.org/abs/2602.01004", "authors": ["Zihao Zhao", "Shengting Cao", "Muchao Ye"], "title": "SRVAU-R1: Enhancing Video Anomaly Understanding via Reflection-Aware Learning", "categories": ["cs.CV"], "comment": null, "summary": "Multi-modal large language models (MLLMs) have demonstrated significant progress in reasoning capabilities and shown promising effectiveness in video anomaly understanding (VAU) tasks. However, existing MLLM-based approaches remain largely focused on surface-level descriptions of anomalies, lacking deep reasoning over abnormal behaviors like explicit self-reflection and self-correction. To address that, we propose Self-Reflection-Enhanced Reasoning for Video Anomaly Understanding (SRVAU-R1), a reflection-aware learning framework that incorporates reflection in MLLM reasoning. Specifically, SRVAU-R1 introduces the first reflection-oriented Chain-of-Thought dataset tailored for VAU, providing structured supervision with initial reasoning, self-reflection, and revised reasoning. Based on that, it includes a novel reflection-aware learning paradigm with supervised fine-tuning and reinforcement fine-tuning to enhance multi-modal reasoning for VAU. Extensive experiments on multiple video anomaly benchmarks demonstrate that SRVAU-R1 consistently outperforms existing methods, achieving significant improvements in both temporal anomaly localization accuracy and reasoning quality.", "AI": {"tldr": "提出了一种增强视频异常理解的自我反思学习框架SRVAU-R1。", "motivation": "现有方法在视频异常理解任务中仅关注表面描述，缺乏对异常行为的深层次推理能力。", "method": "引入了一个新的自我反思导向的数据集和反射意识的学习范式来提升多模态推理。", "result": "实验显示SRVAU-R1在多个基准上超越了现有方法，在时间异常定位准确性和推理质量方面取得了显著改进。", "conclusion": "通过增加自我反思的机制，可以增强视频中异常行为的理解和分析能力。"}}
{"id": "2602.01003", "pdf": "https://arxiv.org/pdf/2602.01003", "abs": "https://arxiv.org/abs/2602.01003", "authors": ["Zhishen Sun", "Sizhe Dang", "Guang Dai", "Haishan Ye"], "title": "ESSAM: A Novel Competitive Evolution Strategies Approach to Reinforcement Learning for Memory Efficient LLMs Fine-Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a key training step for improving mathematical reasoning in large language models (LLMs), but it often has high GPU memory usage, which makes it hard to use in settings with limited resources. To reduce these issues, we propose Evolution Strategies with Sharpness-Aware Maximization (ESSAM), a full parameter fine-tuning framework that tightly combines the zero-order search in parameter space from Evolution Strategies (ES) with the Sharpness-Aware Maximization (SAM) to improve generalization. We conduct fine-tuning experiments on the mainstream mathematica reasoning task GSM8K. The results show that ESSAM achieves an average accuracy of 78.27\\% across all models and its overall performance is comparable to RL methods. It surpasses classic RL algorithm PPO with an accuracy of 77.72\\% and is comparable to GRPO with an accuracy of 78.34\\%, and even surpassing them on some models. In terms of GPU memory usage, ESSAM reduces the average GPU memory usage by $18\\times$ compared to PPO and by $10\\times$ compared to GRPO, achieving an extremely low GPU memory usage.", "AI": {"tldr": "提出了一种新的进化策略方法ESSAM，用于提高大语言模型的数学推理能力，并且减少训练过程中的GPU内存使用。", "motivation": "强化学习在提高大型语言模型的数学推理方面效果显著但消耗大量GPU内存，限制了其应用范围。因此开发一种既能提升性能又能降低资源消耗的方法是必要的。", "method": "通过将进化策略与尖锐度感知最大化结合，提出了一种新的框架ESSAM，用于参数空间中的零阶搜索和模型的精细化调整。", "result": "在数学推理任务GSM8K上进行实验后发现，ESSAM取得了78.27%的平均准确率，相比经典强化学习算法PPO（77.72%）有所提高，并且显著降低了GPU内存使用量。", "conclusion": "ESSAM框架不仅能够达到与现有方法相当甚至更好的性能指标，在降低训练资源消耗方面也表现出色。"}}
{"id": "2602.01002", "pdf": "https://arxiv.org/pdf/2602.01002", "abs": "https://arxiv.org/abs/2602.01002", "authors": ["Itai Shapira", "Gerdus Benade", "Ariel D. Procaccia"], "title": "How RLHF Amplifies Sycophancy", "categories": ["cs.AI"], "comment": null, "summary": "Large language models often exhibit increased sycophantic behavior after preference-based post-training, showing a stronger tendency to affirm a user's stated or implied belief even when this conflicts with factual accuracy or sound judgment. We present a formal analysis of how alignment from human feedback can increase this failure mode by identifying an explicit amplification mechanism that causally links optimization against a learned reward to bias in the human preference data used for alignment. We show that the direction of behavioral drift is determined by a covariance under the base policy between endorsing the belief signal in the prompt and the learned reward, and that the first-order effect reduces to a simple mean-gap condition. We then analyze reward learning from pairwise comparisons under random utility models like Bradley-Terry and characterize when bias in human annotators' preferences induces this reward gap. Next, we propose a training-time intervention designed to neutralize the amplification mechanism itself. Among all post-trained policies that prevent sycophantic behavior from increasing, we characterize the unique policy closest in KL divergence to the unconstrained post-trained policy, and derive the corresponding minimal reward correction as a closed-form agreement penalty. Computational experiments find that reward gaps are common and cause behavioral drift in all the configurations considered.", "AI": {"tldr": "论文探讨了偏好基于的后期训练如何增加语言模型的阿谀奉承行为。", "motivation": "研究动机是理解偏好反馈对大语言模型中阿谀奉承行为的影响，以及探索减少这种倾向的方法。", "method": "通过形式化分析识别出一种放大机制，并提出了一种干预措施来修正这种偏差。实验在各种配置下测试了这些方法的有效性。", "result": "研究表明奖励差距普遍存在并且会导致模型的行为偏移，在所有考虑的配置中，行为偏移均出现。", "conclusion": "论文揭示了偏好反馈如何放大语言模型中的阿谀奉承倾向，并提出了一个最小化偏差影响的方法。"}}
{"id": "2602.01000", "pdf": "https://arxiv.org/pdf/2602.01000", "abs": "https://arxiv.org/abs/2602.01000", "authors": ["Vagish Kumar", "Souvik Chakraborty"], "title": "CortiNet: A Physics-Perception Hybrid Cortical-Inspired Dual-Stream Network for Gallbladder Disease Diagnosis from Ultrasound", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Ultrasound imaging is the primary diagnostic modality for detecting Gallbladder diseases due to its non-invasive nature, affordability, and wide accessibility. However, the low resolution and speckle noise inherent to ultrasound images hinder diagnostic reliability, prompting the use of large convolutional neural networks that are difficult to deploy in routine clinical settings. In this work, we propose CortiNet, a lightweight, cortical-inspired dual-stream neural architecture for gallbladder disease diagnosis that integrates physically interpretable multi-scale signal decomposition with perception-driven feature learning. Inspired by parallel processing pathways in the human visual cortex, CortiNet explicitly separates low-frequency structural information from high-frequency perceptual details and processes them through specialized encoding streams. By operating directly on structured, frequency-selective representations rather than raw pixel intensities, the architecture embeds strong physics-based inductive bias, enabling efficient feature learning with a significantly reduced parameter footprint. A late-stage cortical-style fusion mechanism integrates complementary structural and textural cues while preserving computational efficiency. Additionally, we propose a structure-aware explainability framework wherein gradient-weighted class activation mapping is only applied to the structural branch of the proposed CortiNet architecture. This choice allows the model to only focus on the structural features, making it robust against speckle noise. We evaluate CortiNet on 10,692 expert-annotated images spanning nine clinically relevant gallbladder disease categories. Experimental results demonstrate that CortiNet achieves high diagnostic accuracy (98.74%) with only a fraction of the parameters required by conventional deep convolutional models.", "AI": {"tldr": "本文提出了一种轻量级的双流神经网络CortiNet，用于从超声图像中诊断胆囊疾病。", "motivation": "低分辨率和斑点噪声导致了基于超声图像的胆囊疾病诊断困难，而大型卷积神经网络难以在临床环境中部署。本文旨在开发一种高效的解决方案来提高诊断准确性并简化模型。", "method": "CortiNet通过模拟人类视觉皮层中的平行处理路径将低频结构信息与高频感知细节分离，并通过对物理可解释的多尺度信号分解和感知驱动特征学习进行处理，从而嵌入了强大的基于物理学的归纳偏置。这种架构在计算效率高的情况下实现了高效的特征学习。", "result": "实验结果表明CortiNet在10,692张专家标注图像上达到了98.74%的诊断准确性，并且仅需传统深度卷积模型参数的一小部分。", "conclusion": "CortiNet通过结合物理可解释性和感知驱动的学习，成功提高了胆囊疾病超声影像诊断的准确率和效率。"}}
{"id": "2602.00997", "pdf": "https://arxiv.org/pdf/2602.00997", "abs": "https://arxiv.org/abs/2602.00997", "authors": ["Mayank Singh", "Vikas Yadav", "Eduardo Blanco"], "title": "Error Taxonomy-Guided Prompt Optimization", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Automatic Prompt Optimization (APO) is a powerful approach for extracting performance from large language models without modifying their weights. Many existing methods rely on trial-and-error, testing different prompts or in-context examples until a good configuration emerges, often consuming substantial compute. Recently, natural language feedback derived from execution logs has shown promise as a way to identify how prompts can be improved. However, most prior approaches operate in a bottom-up manner, iteratively adjusting the prompt based on feedback from individual problems, which can cause them to lose the global perspective. In this work, we propose Error Taxonomy-Guided Prompt Optimization (ETGPO), a prompt optimization algorithm that adopts a top-down approach. ETGPO focuses on the global failure landscape by collecting model errors, categorizing them into a taxonomy, and augmenting the prompt with guidance targeting the most frequent failure modes. Across multiple benchmarks spanning mathematics, question answering, and logical reasoning, ETGPO achieves accuracy that is comparable to or better than state-of-the-art methods, while requiring roughly one third of the optimization-phase token usage and evaluation budget.", "AI": {"tldr": "提出了一种基于错误分类的提示优化算法ETGPO，旨在通过全局视角改进大语言模型的性能。", "motivation": "现有的自动提示优化方法依赖于试错过程，这种方法效率低下且资源消耗大。本文提出采用一种自上而下的方法来解决这个问题，以提高优化效率和效果。", "method": "ETGPO算法首先收集模型在不同任务上的错误，并将其分类为一个错误分类表；然后根据这些最常见的失败模式来增强提示文本。", "result": "该方法在数学、问答和逻辑推理等多个基准测试中实现了与现有最佳方法相当或更好的准确率，同时优化阶段的令牌使用量和评估预算减少了约三分之一。", "conclusion": "ETGPO通过提供一种全局视角的方法来改进大语言模型的表现，并且这种方法在计算资源消耗上更加高效。"}}
{"id": "2602.00996", "pdf": "https://arxiv.org/pdf/2602.00996", "abs": "https://arxiv.org/abs/2602.00996", "authors": ["Abhijit Chakraborty", "Ashish Raj Shekhar", "Shiven Agarwal", "Vivek Gupta"], "title": "DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Complex question answering across text, tables and images requires integrating diverse information sources. A framework supporting specialized processing with coordination and interpretability is needed. We introduce DeALOG, a decentralized multi-agent framework for multimodal question answering. It uses specialized agents: Table, Context, Visual, Summarizing and Verification, that communicate through a shared natural-language log as persistent memory. This log-based approach enables collaborative error detection and verification without central control, improving robustness. Evaluations on FinQA, TAT-QA, CRT-QA, WikiTableQuestions, FeTaQA, and MultiModalQA show competitive performance. Analysis confirms the importance of the shared log, agent specialization, and verification for accuracy. DeALOG, provides a scalable approach through modular components using natural-language communication.", "AI": {"tldr": "提出了一种用于多模态问答的去中心化多代理框架DeALOG", "motivation": "复杂问题回答需要整合多种信息源，现有的处理方法缺乏协调和可解释性。因此，开发一种支持专门处理并具有协作能力的新框架是必要的。", "method": "引入了基于自然语言日志的去中心化多代理系统，包括表格、上下文、视觉、总结及验证等专门代理，并通过共享的日志进行沟通与持久记忆存储。该方法允许代理之间无中央控制地检测和验证错误，提高系统的鲁棒性。", "result": "在多个问答数据集上的评估显示了该框架的竞争力，分析表明日志的重要性、代理的专业化以及验证机制对于准确性至关重要。", "conclusion": "DeALOG提供了一种通过模块化组件使用自然语言通信实现可扩展性的方法"}}
{"id": "2602.00995", "pdf": "https://arxiv.org/pdf/2602.00995", "abs": "https://arxiv.org/abs/2602.00995", "authors": ["Nick DiSanto", "Ehsan Khodapanah Aghdam", "Han Liu", "Jacob Watson", "Yuankai K. Tao", "Hao Li", "Ipek Oguz"], "title": "VAMOS-OCTA: Vessel-Aware Multi-Axis Orthogonal Supervision for Inpainting Motion-Corrupted OCT Angiography Volumes", "categories": ["cs.CV"], "comment": "Accepted to SPIE Medical Imaging 2026", "summary": "Handheld Optical Coherence Tomography Angiography (OCTA) enables noninvasive retinal imaging in uncooperative or pediatric subjects, but is highly susceptible to motion artifacts that severely degrade volumetric image quality. Sudden motion during 3D acquisition can lead to unsampled retinal regions across entire B-scans (cross-sectional slices), resulting in blank bands in en face projections. We propose VAMOS-OCTA, a deep learning framework for inpainting motion-corrupted B-scans using vessel-aware multi-axis supervision. We employ a 2.5D U-Net architecture that takes a stack of neighboring B-scans as input to reconstruct a corrupted center B-scan, guided by a novel Vessel-Aware Multi-Axis Orthogonal Supervision (VAMOS) loss. This loss combines vessel-weighted intensity reconstruction with axial and lateral projection consistency, encouraging vascular continuity in native B-scans and across orthogonal planes. Unlike prior work that focuses primarily on restoring the en face MIP, VAMOS-OCTA jointly enhances both cross-sectional B-scan sharpness and volumetric projection accuracy, even under severe motion corruptions. We trained our model on both synthetic and real-world corrupted volumes and evaluated its performance using both perceptual quality and pixel-wise accuracy metrics. VAMOS-OCTA consistently outperforms prior methods, producing reconstructions with sharp capillaries, restored vessel continuity, and clean en face projections. These results demonstrate that multi-axis supervision offers a powerful constraint for restoring motion-degraded 3D OCTA data. Our source code is available at https://github.com/MedICL-VU/VAMOS-OCTA.", "AI": {"tldr": "提出了一种用于修复运动损坏的OCTA体数据中B扫描图像的方法VAMOS-OCTA，该方法使用血管感知多轴监督进行空洞填充。", "motivation": "手持光学相干断层成像(OCT)在不合作或儿童受试者中的非侵入性视网膜成像中非常有用，但易受到运动伪影的影响，这会严重降低体数据图像质量。VAMOS-OCTA旨在通过多轴监督改进B扫描的修复。", "method": "采用了基于2.5D U-Net架构的方法，输入是邻近B扫描的堆栈来重建中心受损B扫描，并引入了血管感知多轴正交监督(VAMOS)损失函数。此方法结合血管加权强度重建和轴向及横向投影一致性。", "result": "在使用合成与真实世界运动损坏体数据进行训练后，通过主观质量评价和像素级准确性指标评估性能。VAMOS-OCTA优于现有方法，实现了清晰的微血管修复，连续性恢复以及干净的正面投影。", "conclusion": "多轴监督为修复运动降质的3D OCTA数据提供了一种强有力的方法，并且源代码已公开。"}}
{"id": "2602.00994", "pdf": "https://arxiv.org/pdf/2602.00994", "abs": "https://arxiv.org/abs/2602.00994", "authors": ["Yu Li", "Mingyang Yi", "Xiuyu Li", "Ju Fan", "Fuxin Jiang", "Binbin Chen", "Peng Li", "Jie Song", "Tieying Zhang"], "title": "Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve complex tasks. Most existing ARL methods train a single shared model parameters to support both reasoning and tool use behaviors, implicitly assuming that joint training leads to improved overall agent performance. Despite its widespread adoption, this assumption has rarely been examined empirically. In this paper, we systematically investigate this assumption by introducing a Linear Effect Attribution System(LEAS), which provides quantitative evidence of interference between reasoning and tool-use behaviors. Through an in-depth analysis, we show that these two capabilities often induce misaligned gradient directions, leading to training interference that undermines the effectiveness of joint optimization and challenges the prevailing ARL paradigm. To address this issue, we propose Disentangled Action Reasoning Tuning(DART), a simple and efficient framework that explicitly decouples parameter updates for reasoning and tool-use via separate low-rank adaptation modules. Experimental results show that DART consistently outperforms baseline methods with averaged 6.35 percent improvements and achieves performance comparable to multi-agent systems that explicitly separate tool-use and reasoning using a single model.", "AI": {"tldr": "本文研究了在代理强化学习中，推理与工具使用行为之间的干扰，并提出了一种解耦参数更新的方法DART。", "motivation": "当前的代理强化学习假设联合训练能够提升整体性能，但很少有实证研究支持这一观点。论文动机是通过引入LEAS系统来量化这两种能力间的相互干扰，并解决由此带来的优化挑战。", "method": "本文首先提出了一个线性效应归因系统(LEAS)，用于量化的推理与工具使用之间的干扰；然后设计了DART框架，通过两个独立的低秩适应模块分别更新参数，以解耦推理和工具使用的行为。", "result": "实验结果表明，相比于基线方法，DART能够提供平均6.35%的性能提升，并且其表现可与显式分离工具使用与推理行为的多代理系统相媲美。", "conclusion": "论文揭示了在强化学习中联合训练推理和工具使用的潜在问题，并通过提出解耦框架解决了这些问题，提高了模型的有效性。"}}
{"id": "2602.00993", "pdf": "https://arxiv.org/pdf/2602.00993", "abs": "https://arxiv.org/abs/2602.00993", "authors": ["Weizhe Tang", "Junwei You", "Jiaxi Liu", "Zhaoyi Wang", "Rui Gan", "Zilin Huang", "Feng Wei", "Bin Ran"], "title": "HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "End-to-end autonomous driving models increasingly benefit from large vision--language models for semantic understanding, yet ensuring safe and accurate operation under long-tail conditions remains challenging. These challenges are particularly prominent in long-tail mixed-traffic scenarios, where autonomous vehicles must interact with heterogeneous road users, including human-driven vehicles and vulnerable road users, under complex and uncertain conditions. This paper proposes HERMES, a holistic risk-aware end-to-end multimodal driving framework designed to inject explicit long-tail risk cues into trajectory planning. HERMES employs a foundation-model-assisted annotation pipeline to produce structured Long-Tail Scene Context and Long-Tail Planning Context, capturing hazard-centric cues together with maneuver intent and safety preference, and uses these signals to guide end-to-end planning. HERMES further introduces a Tri-Modal Driving Module that fuses multi-view perception, historical motion cues, and semantic guidance, ensuring risk-aware accurate trajectory planning under long-tail scenarios. Experiments on the real-world long-tail dataset demonstrate that HERMES consistently outperforms representative end-to-end and VLM-driven baselines under long-tail mixed-traffic scenarios. Ablation studies verify the complementary contributions of key components.", "AI": {"tldr": "HERMES是一个全面的风险感知端到端多模态驾驶框架，旨在通过注入显式的长尾风险线索来改进轨迹规划。", "motivation": "大规模视觉-语言模型虽然增强了自动驾驶模型的语义理解能力，但在长尾条件下确保安全和准确的操作仍然具有挑战性。特别是在复杂的混合交通场景中，自主车辆需要与各种道路使用者进行交互。", "method": "HERMES利用基础模型辅助注释管道生成结构化的长尾场景上下文和规划上下文，并融合多视图感知、历史运动线索和语义指导来实现风险感知的准确轨迹规划。", "result": "实验表明，HERMES在真实世界的长尾数据集上优于代表性端到端和视觉-语言模型驱动的基础线。", "conclusion": "HERMES框架通过关键组件的协同工作，在长尾混合交通场景中提高了自动驾驶的安全性和准确性。"}}
{"id": "2602.00992", "pdf": "https://arxiv.org/pdf/2602.00992", "abs": "https://arxiv.org/abs/2602.00992", "authors": ["Phone Thiha Kyaw", "Jonathan Kelly"], "title": "Geometry-Aware Sampling-Based Motion Planning on Riemannian Manifolds", "categories": ["cs.RO"], "comment": "Submitted to WAFR 2026 (17th World Symposium on the Algorithmic Foundations of Robotics (WAFR))", "summary": "In many robot motion planning problems, task objectives and physical constraints induce non-Euclidean geometry on the configuration space, yet many planners operate using Euclidean distances that ignore this structure. We address the problem of planning collision-free motions that minimize length under configuration-dependent Riemannian metrics, corresponding to geodesics on the configuration manifold. Conventional numerical methods for computing such paths do not scale well to high-dimensional systems, while sampling-based planners trade scalability for geometric fidelity. To bridge this gap, we propose a sampling-based motion planning framework that operates directly on Riemannian manifolds. We introduce a computationally efficient midpoint-based approximation of the Riemannian geodesic distance and prove that it matches the true Riemannian distance with third-order accuracy. Building on this approximation, we design a local planner that traces the manifold using first-order retractions guided by Riemannian natural gradients. Experiments on a two-link planar arm and a 7-DoF Franka manipulator under a kinetic-energy metric, as well as on rigid-body planning in $\\mathrm{SE}(2)$ with non-holonomic motion constraints, demonstrate that our approach consistently produces lower-cost trajectories than Euclidean-based planners and classical numerical geodesic-solver baselines.", "AI": {"tldr": "本文提出了在黎曼流形上进行运动规划的方法，通过一种高效的中点逼近算法和基于黎曼自然梯度的局部规划器来解决非欧几里得空间中的碰撞自由路径问题。", "motivation": "许多机器人运动规划问题中，任务目标和物理约束会在配置空间中产生非欧几何结构。现有的大多数规划方法使用忽略此结构的欧氏距离，这导致了低效或不准确的结果。", "method": "该研究提出了一种在黎曼流形上进行采样式运动规划的新框架，包括一种计算黎曼测地线距离的高效中点逼近算法和基于黎曼自然梯度的局部规划器。", "result": "实验结果表明，在两个链接平面臂、7自由度Franka机械手及刚体在SE(2)中的非全约束运动条件下，该方法生成的成本更低且更精确的轨迹。", "conclusion": "该研究展示了一种高效的方法来解决机器人在配置空间中遵循黎曼几何结构进行规划的问题。"}}
{"id": "2602.00983", "pdf": "https://arxiv.org/pdf/2602.00983", "abs": "https://arxiv.org/abs/2602.00983", "authors": ["Batuhan K. Karaman", "Aditya Rawal", "Suhaila Shakiah", "Mohammad Ghavamzadeh", "Mingyi Hong", "Arijit Biswas", "Ruida Zhou"], "title": "DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This work is accepted to the 29th International Conference on Artificial Intelligence and Statistics (AISTATS) 2026", "summary": "Reinforcement learning with verifiable rewards has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models particularly in mathematics. Current approaches in this domain present a clear trade-off: PPO-style methods (e.g., GRPO/DAPO) offer training stability but exhibit slow learning trajectories due to their trust-region constraints on policy updates, while REINFORCE-style approaches (e.g., CISPO) demonstrate improved learning efficiency but suffer from performance instability as they clip importance sampling weights while still permitting non-zero gradients outside the trust-region. To address these limitations, we introduce DISPO, a simple yet effective REINFORCE-style algorithm that decouples the up-clipping and down-clipping of importance sampling weights for correct and incorrect responses, yielding four controllable policy update regimes. Through targeted ablations, we uncover how each regime impacts training: for correct responses, weights >1 increase the average token entropy (i.e., exploration) while weights <1 decrease it (i.e., distillation) -- both beneficial but causing gradual performance degradation when excessive. For incorrect responses, overly restrictive clipping triggers sudden performance collapse through repetitive outputs (when weights >1) or vanishing response lengths (when weights <1). By separately tuning these four clipping parameters, DISPO maintains the exploration-distillation balance while preventing catastrophic failures, achieving 61.04% on AIME'24 (vs. 55.42% CISPO and 50.21% DAPO) with similar gains across various benchmarks and models.", "AI": {"tldr": "DISPO是一种新的强化学习算法，旨在提高大语言模型在数学推理任务上的训练效率和稳定性。", "motivation": "现有的PPO风格的方法提供了稳定的训练过程但学习速度慢；而REINFORCE风格的方法虽然提高了学习效率，但却表现出性能不稳。DISPO通过解耦重要性采样权重的上下裁剪来平衡探索与提炼之间的关系，并防止灾难性的失败。", "method": "DISPO是基于REINFORCE的一种算法，它将正确和错误响应的重要性采样权重分离处理，从而实现了四种可控制的策略更新模式。通过调整这四个裁剪参数，DISPO能够在保持探索-提炼平衡的同时避免性能崩溃。", "result": "在AIME'24上，DISPO达到了61.04%，优于CISPO（55.42%）和DAPO（50.21%）。并且，在各种基准测试中都取得了类似的显著提升。", "conclusion": "DISPO通过调整重要性采样权重的裁剪参数，成功地提高了大语言模型在数学推理任务中的训练效率与稳定性。"}}
{"id": "2602.00982", "pdf": "https://arxiv.org/pdf/2602.00982", "abs": "https://arxiv.org/abs/2602.00982", "authors": ["Phu-Hoa Pham", "Chi-Nguyen Tran", "Dao Sy Duy Minh", "Nguyen Lam Phu Quy", "Huynh Trung Kiet"], "title": "Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025", "categories": ["cs.CV", "cs.AI", "cs.NE", "cs.RO"], "comment": "15 pages, 8 tables. Technical Report for winning solutions (Track 1 & Track 2) at the NeurIPS 2025 Mouse vs. AI Challenge", "summary": "Visual robustness and neural alignment remain critical challenges in developing artificial agents that can match biological vision systems. We present the winning approaches from Team HCMUS_TheFangs for both tracks of the NeurIPS 2025 Mouse vs. AI: Robust Visual Foraging Competition. For Track 1 (Visual Robustness), we demonstrate that architectural simplicity combined with targeted components yields superior generalization, achieving 95.4% final score with a lightweight two-layer CNN enhanced by Gated Linear Units and observation normalization. For Track 2 (Neural Alignment), we develop a deep ResNet-like architecture with 16 convolutional layers and GLU-based gating that achieves top-1 neural prediction performance with 17.8 million parameters. Our systematic analysis of ten model checkpoints trained between 60K to 1.14M steps reveals that training duration exhibits a non-monotonic relationship with performance, with optimal results achieved around 200K steps. Through comprehensive ablation studies and failure case analysis, we provide insights into why simpler architectures excel at visual robustness while deeper models with increased capacity achieve better neural alignment. Our results challenge conventional assumptions about model complexity in visuomotor learning and offer practical guidance for developing robust, biologically-inspired visual agents.", "AI": {"tldr": "本文介绍了在NeurIPS 2025年Mouse vs. AI比赛中获胜的策略，包括两个赛道：视觉鲁棒性和神经对齐。", "motivation": "开发能够匹配生物视觉系统的稳健的人工智能代理是视觉领域的重要挑战之一。", "method": "对于视觉鲁棒性任务，采用了轻量级CNN结合GLU和观测归一化的方法；而对于神经对齐，则使用了更深的ResNet架构，并通过系统分析训练过程中的性能表现来优化模型。", "result": "在视觉鲁棒性上实现了95.4%的成绩，在神经对齐上获得了最佳神经预测性能，揭示了简单与复杂的架构如何分别在不同任务中表现出色。", "conclusion": "研究结果质疑了关于模型复杂度的传统假设，并为开发稳健的生物启发式视觉代理提供了实用指导。"}}
