{"id": "2601.15275", "pdf": "https://arxiv.org/pdf/2601.15275", "abs": "https://arxiv.org/abs/2601.15275", "authors": ["Yu Wu", "Minsik Jeon", "Jen-Hao Rick Chang", "Oncel Tuzel", "Shubham Tulsiani"], "title": "RayRoPE: Projective Ray Positional Encoding for Multi-view Attention", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: https://rayrope.github.io/", "summary": "We study positional encodings for multi-view transformers that process tokens from a set of posed input images, and seek a mechanism that encodes patches uniquely, allows SE(3)-invariant attention with multi-frequency similarity, and can be adaptive to the geometry of the underlying scene. We find that prior (absolute or relative) encoding schemes for multi-view attention do not meet the above desiderata, and present RayRoPE to address this gap. RayRoPE represents patch positions based on associated rays but leverages a predicted point along the ray instead of the direction for a geometry-aware encoding. To achieve SE(3) invariance, RayRoPE computes query-frame projective coordinates for computing multi-frequency similarity. Lastly, as the 'predicted' 3D point along a ray may not be precise, RayRoPE presents a mechanism to analytically compute the expected position encoding under uncertainty. We validate RayRoPE on the tasks of novel-view synthesis and stereo depth estimation and show that it consistently improves over alternate position encoding schemes (e.g. 15% relative improvement on LPIPS in CO3D). We also show that RayRoPE can seamlessly incorporate RGB-D input, resulting in even larger gains over alternatives that cannot positionally encode this information.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.15267", "pdf": "https://arxiv.org/pdf/2601.15267", "abs": "https://arxiv.org/abs/2601.15267", "authors": ["Yiran Hu", "Huanghai Liu", "Chong Wang", "Kunran Li", "Tien-Hsuan Wu", "Haitao Li", "Xinran Xu", "Siqing Huo", "Weihang Su", "Ning Zheng", "Siyuan Zheng", "Qingyao Ai", "Yun Liu", "Renjun Bian", "Yiqun Liu", "Charles L. A. Clarke", "Weixing Shen", "Ben Kao"], "title": "Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoning processes and trustworthy issues such as fairness and reliability. Systematic evaluation of LLM performance in legal tasks has therefore become essential for their responsible adoption. This survey identifies key challenges in evaluating LLMs for legal tasks grounded in real-world legal practice. We analyze the major difficulties involved in assessing LLM performance in the legal domain, including outcome correctness, reasoning reliability, and trustworthiness. Building on these challenges, we review and categorize existing evaluation methods and benchmarks according to their task design, datasets, and evaluation metrics. We further discuss the extent to which current approaches address these challenges, highlight their limitations, and outline future research directions toward more realistic, reliable, and legally grounded evaluation frameworks for LLMs in legal domains.", "AI": {"tldr": "评估大型语言模型在法律应用中的表现，包括面临的挑战、现有方法和未来方向。", "motivation": "随着大型语言模型越来越多地应用于司法决策支持、法律实践辅助及面向公众的法律服务中，其在实际法律环境中的部署引发了关于准确性、法律推理过程合理性以及公平性和可靠性等信任问题的关注。系统评估这些模型在法律任务中的性能变得至关重要，以实现负责任的应用。", "method": "文章分析了大型语言模型在法律领域评估所面临的主要难题，并根据任务设计、数据集和评价指标对现有的评估方法进行了分类和回顾。", "result": "讨论了现有方法如何应对面临的挑战，指出了它们的局限性，并提出了未来研究的方向，以便为法律领域的大型语言模型构建更加现实可靠且基于法律的评价框架。", "conclusion": "文章总结了在实际法律实践中评估大型语言模型的重要性和复杂性，并强调需要开发更真实、可靠的评估方法来确保这些技术的应用能够符合法律要求。"}}
{"id": "2601.15260", "pdf": "https://arxiv.org/pdf/2601.15260", "abs": "https://arxiv.org/abs/2601.15260", "authors": ["Dominik Rößle", "Xujun Xie", "Adithya Mohan", "Venkatesh Thirugnana Sambandham", "Daniel Cremers", "Torsten Schön"], "title": "DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration", "categories": ["cs.CV"], "comment": "Accepted to the IEEE Intelligent Vehicles Symposium 2026. For code and dataset, see https://github.com/cvims/DrivIng", "summary": "Perception is a cornerstone of autonomous driving, enabling vehicles to understand their surroundings and make safe, reliable decisions. Developing robust perception algorithms requires large-scale, high-quality datasets that cover diverse driving conditions and support thorough evaluation. Existing datasets often lack a high-fidelity digital twin, limiting systematic testing, edge-case simulation, sensor modification, and sim-to-real evaluations. To address this gap, we present DrivIng, a large-scale multimodal dataset with a complete geo-referenced digital twin of a ~18 km route spanning urban, suburban, and highway segments. Our dataset provides continuous recordings from six RGB cameras, one LiDAR, and high-precision ADMA-based localization, captured across day, dusk, and night. All sequences are annotated at 10 Hz with 3D bounding boxes and track IDs across 12 classes, yielding ~1.2 million annotated instances. Alongside the benefits of a digital twin, DrivIng enables a 1-to-1 transfer of real traffic into simulation, preserving agent interactions while enabling realistic and flexible scenario testing. To support reproducible research and robust validation, we benchmark DrivIng with state-of-the-art perception models and publicly release the dataset, digital twin, HD map, and codebase.", "AI": {"tldr": "介绍了一个大型多模态驾驶数据集DrivIng，该数据集具有完整的数字孪生集成。", "motivation": "现有的自动驾驶感知算法开发受限于缺乏高保真度的数字孪生数据集，导致难以进行系统性测试和仿真到现实世界评估。", "method": "构建了一个包含多种环境条件下的18公里路线记录，并提供六台RGB相机、一台LiDAR以及高精度定位系统的数据集DrivIng。所有序列以10Hz的频率标注了3D边界框和跟踪ID，涵盖12类物体。", "result": "该数据集提供了约120万注释实例，并且能够将现实交通场景无缝转移至仿真环境中进行测试。", "conclusion": "通过基准测试展示了DrivIng在支持可重复研究和强大验证方面的作用，并公开发布了数据集、数字孪生、高清地图及代码库。"}}
{"id": "2601.15254", "pdf": "https://arxiv.org/pdf/2601.15254", "abs": "https://arxiv.org/abs/2601.15254", "authors": ["Felix Schur", "Niklas Pfister", "Peng Ding", "Sach Mukherjee", "Jonas Peters"], "title": "Many Experiments, Few Repetitions, Unpaired Data, and Sparse Effects: Is Causal Inference Possible?", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "We study the problem of estimating causal effects under hidden confounding in the following unpaired data setting: we observe some covariates $X$ and an outcome $Y$ under different experimental conditions (environments) but do not observe them jointly; we either observe $X$ or $Y$. Under appropriate regularity conditions, the problem can be cast as an instrumental variable (IV) regression with the environment acting as a (possibly high-dimensional) instrument. When there are many environments but only a few observations per environment, standard two-sample IV estimators fail to be consistent. We propose a GMM-type estimator based on cross-fold sample splitting of the instrument-covariate sample and prove that it is consistent as the number of environments grows but the sample size per environment remains constant. We further extend the method to sparse causal effects via $\\ell_1$-regularized estimation and post-selection refitting.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.15250", "pdf": "https://arxiv.org/pdf/2601.15250", "abs": "https://arxiv.org/abs/2601.15250", "authors": ["Zichen Xi", "Hao-Xiang Chen", "Nan Xue", "Hongyu Yan", "Qi-Yuan Feng", "Levent Burak Kara", "Joaquim Jorge", "Qun-Ce Xu"], "title": "FlowSSC: Universal Generative Monocular Semantic Scene Completion via One-Step Latent Diffusion", "categories": ["cs.CV", "cs.RO"], "comment": "Under Review", "summary": "Semantic Scene Completion (SSC) from monocular RGB images is a fundamental yet challenging task due to the inherent ambiguity of inferring occluded 3D geometry from a single view. While feed-forward methods have made progress, they often struggle to generate plausible details in occluded regions and preserve the fundamental spatial relationships of objects. Such accurate generative reasoning capability for the entire 3D space is critical in real-world applications. In this paper, we present FlowSSC, the first generative framework applied directly to monocular semantic scene completion. FlowSSC treats the SSC task as a conditional generation problem and can seamlessly integrate with existing feed-forward SSC methods to significantly boost their performance. To achieve real-time inference without compromising quality, we introduce Shortcut Flow-matching that operates in a compact triplane latent space. Unlike standard diffusion models that require hundreds of steps, our method utilizes a shortcut mechanism to achieve high-fidelity generation in a single step, enabling practical deployment in autonomous systems. Extensive experiments on SemanticKITTI demonstrate that FlowSSC achieves state-of-the-art performance, significantly outperforming existing baselines.", "AI": {"tldr": "本文提出了FlowSSC，一种用于单目语义场景补全的生成框架，通过引入Shortcut Flow-matching在紧凑的三平面潜在空间中实现单步高保真生成。", "motivation": "单目RGB图像进行语义场景补全是具有挑战性的任务，传统的前馈方法难以生成被遮挡区域中的合理细节并保持物体间的基本空间关系。准确的全3D空间生成能力对实际应用至关重要。", "method": "FlowSSC将语义场景补全视为条件生成问题，并引入Shortcut Flow-matching在紧凑三平面潜在空间中实现单步高保真生成，无需数百步骤就能达到高质量结果。", "result": "实验表明，FlowSSC在SemanticKITTI数据集上实现了最先进的性能，显著优于现有基线方法。", "conclusion": "通过提出FlowSSC框架并引入Shortcut Flow-matching机制，本文为单目语义场景补全提供了创新的解决方案，并展示了其在实时推理和高质量生成之间的平衡优势。"}}
{"id": "2601.15249", "pdf": "https://arxiv.org/pdf/2601.15249", "abs": "https://arxiv.org/abs/2601.15249", "authors": ["Garrett G. Wen", "Buxin Su", "Natalie Collina", "Zhun Deng", "Weijie Su"], "title": "Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism", "categories": ["cs.LG", "cs.AI", "cs.GT", "stat.ME"], "comment": null, "summary": "Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.", "AI": {"tldr": "介绍一种通过同调机制辅助作者评估以优化机器学习和人工智能会议最佳论文奖选择的方法。", "motivation": "解决大型AI/ML会议在评选最佳论文时面临的挑战，提高评审过程的质量和一致性。", "method": "使用同调机制让作者对其提交的论文进行排名评估，并调整原始评分以更准确地估计论文的真实质量。", "result": "实验证明该方法能够显著提升被选为获奖论文的质量。", "conclusion": "通过引入作者辅助机制，利用同调机制优化评审过程，可以更好地选择最佳论文奖并激励作者诚实报告。"}}
{"id": "2601.15241", "pdf": "https://arxiv.org/pdf/2601.15241", "abs": "https://arxiv.org/abs/2601.15241", "authors": ["Sean Plummer"], "title": "Feasibility Preservation under Monotone Retrieval Truncation", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "Retrieval-based systems approximate access to a corpus by exposing only a truncated subset of available evidence. Even when relevant information exists in the corpus, truncation can prevent compatible evidence from co-occurring, leading to failures that are not captured by relevance-based evaluation. This paper studies retrieval from a structural perspective, modeling query answering as a feasibility problem under truncation. We formalize retrieval as a sequence of candidate evidence sets and characterize conditions under which feasibility in the limit implies feasibility at finite retrieval depth. We show that monotone truncation suffices to guarantee finite witnessability for individual queries. For classes of queries, we identify finite generation of witness certificates as the additional condition required to obtain a uniform retrieval bound, and we show that this condition is necessary. We further exhibit sharp counterexamples demonstrating failure under non-monotone truncation, non-finitely-generated query classes, and purely slotwise coverage. Together, these results isolate feasibility preservation as a correctness criterion for retrieval independent of relevance scoring or optimization, and clarify structural limitations inherent to truncation-based retrieval.", "AI": {"tldr": "本文研究了在单调检索截断下，查询回答的可行性保持问题，并提出了评估检索系统正确性的结构化标准。", "motivation": "文章动机在于探讨检索系统的限制，在相关性评估之外寻找一个独立于评分或优化的正确性标准。", "method": "通过将检索建模为候选证据集序列并分析其在截断下的可行性，本文提出了条件以保证有限深度下查询的回答可行性。", "result": "研究显示单调截断足以确保个别查询的有限证人可获得性，并识别了生成见证证书的必要条件来获得统一检索界限。", "conclusion": "文章结论表明，在特定条件下，检索系统的可行性可以在相关性之外被独立评估，这揭示了基于截断检索的内在结构限制。"}}
{"id": "2601.15240", "pdf": "https://arxiv.org/pdf/2601.15240", "abs": "https://arxiv.org/abs/2601.15240", "authors": ["Lin Zhang", "Johan Rohdin", "Xin Wang", "Junyi Peng", "Tianchi Liu", "You Zhang", "Hieu-Thi Luong", "Shuai Wang", "Chengdong Liang", "Anna Silnova", "Nicholas Evans"], "title": "WeDefense: A Toolkit to Defend Against Fake Audio", "categories": ["cs.SD", "eess.AS"], "comment": "This is an ongoing work. v1 corresponds to the version completed by June 4, 2025 and previously submitted to ASRU 2025", "summary": "The advances in generative AI have enabled the creation of synthetic audio which is perceptually indistinguishable from real, genuine audio. Although this stellar progress enables many positive applications, it also raises risks of misuse, such as for impersonation, disinformation and fraud. Despite a growing number of open-source fake audio detection codes released through numerous challenges and initiatives, most are tailored to specific competitions, datasets or models. A standardized and unified toolkit that supports the fair benchmarking and comparison of competing solutions with not just common databases, protocols, metrics, but also a shared codebase, is missing. To address this, we propose WeDefense, the first open-source toolkit to support both fake audio detection and localization. Beyond model training, WeDefense emphasizes critical yet often overlooked components: flexible input and augmentation, calibration, score fusion, standardized evaluation metrics, and analysis tools for deeper understanding and interpretation. The toolkit is publicly available at https://github.com/zlin0/wedefense with interactive demos for fake audio detection and localization.", "AI": {"tldr": "介绍WeDefense工具包，用于对抗伪造音频的检测和定位。", "motivation": "随着生成式AI的进步，合成音频变得难以与真实音频区分，这引发了包括假冒、不实信息和欺诈等滥用风险。现有的开放源代码通常为特定竞赛或数据集定制，缺乏统一的标准工具。", "method": "WeDefense提供了一个全面的开源工具包，支持伪造音频检测和定位，强调了灵活输入处理、校准、评分融合及标准化评估指标等功能。", "result": "该工具包在GitHub上公开，并提供了假音检测和定位的交互式演示。", "conclusion": "WeDefense作为首个为对抗伪造音频设计的一体化开源工具包，填补了统一基准测试和比较解决方案的空白。"}}
{"id": "2601.15235", "pdf": "https://arxiv.org/pdf/2601.15235", "abs": "https://arxiv.org/abs/2601.15235", "authors": ["Fabi Nahian Madhurja", "Rusab Sarmun", "Muhammad E. H. Chowdhury", "Adam Mushtak", "Israa Al-Hashimi", "Sohaib Bassam Zoghoul"], "title": "Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-end pipeline for automated analysis of cervical vertebrae (C1-C7). By approximating a 3D volume through optimized 2D axial, sagittal, and coronal projections, regions of interest are identified using the YOLOv8 model from all views and combined to approximate the 3D cervical spine area, achieving a 3D mIoU of 94.45 percent. This projection-based localization strategy reduces computational complexity compared to traditional 3D segmentation methods while maintaining high performance. It is followed by a DenseNet121-Unet-based multi-label segmentation leveraging variance- and energy-based projections, achieving a Dice score of 87.86 percent. Strategic approximation of 3D vertebral masks from these 2D segmentation masks enables the extraction of individual vertebra volumes. The volumes are analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models incorporating both raw slices and projections per vertebra for complementary evaluation. This ensemble achieves vertebra-level and patient-level F1 scores of 68.15 and 82.26, and ROC-AUC scores of 91.62 and 83.04, respectively. We further validate our approach through an explainability study that provides saliency map visualizations highlighting anatomical regions relevant for diagnosis, and an interobserver variability analysis comparing our model's performance with expert radiologists, demonstrating competitive results.", "AI": {"tldr": "该研究提出了一个基于多阶段投影驱动的端到端自动分析颈椎椎体骨折的方法。", "motivation": "由于颈椎骨折是一种需要准确和高效检测以进行有效临床管理的重要医疗状况，本研究探索了通过2D投影来分割3D CT体积中的颈椎椎体，实现精确的骨折检测方法。", "method": "该方法包括利用YOLOv8模型从轴向、矢状和冠状三种视图中识别感兴趣区域，并结合这些信息近似出3D颈椎区域；接着采用基于DenseNet121-Unet的多标签分割，通过方差和能量投影实现精确分割；最后使用一组2.5D Spatio-Sequential模型分析每个椎体以检测骨折。", "result": "该方法实现了94.45%的3D mIoU、87.86%的Dice score以及在椎体级和患者级上分别为68.15和82.26的F1分数，ROC-AUC得分分别为91.62和83.04。", "conclusion": "通过可解释性研究提供的显著图可视化，验证了该方法的有效性，并且在专家放射科医师之间变异性的分析中显示出具有竞争力的结果。"}}
{"id": "2601.15224", "pdf": "https://arxiv.org/pdf/2601.15224", "abs": "https://arxiv.org/abs/2601.15224", "authors": ["Jianshu Zhang", "Chengxuan Qian", "Haosen Sun", "Haoran Lu", "Dingcheng Wang", "Letian Xue", "Han Liu"], "title": "PROGRESSLM: Towards Progress Reasoning in Vision-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "Website: https://progresslm.github.io/ProgressLM/", "summary": "Estimating task progress requires reasoning over long-horizon dynamics rather than recognizing static visual content. While modern Vision-Language Models (VLMs) excel at describing what is visible, it remains unclear whether they can infer how far a task has progressed from partial observations. To this end, we introduce Progress-Bench, a benchmark for systematically evaluating progress reasoning in VLMs. Beyond benchmarking, we further explore a human-inspired two-stage progress reasoning paradigm through both training-free prompting and training-based approach based on curated dataset ProgressLM-45K. Experiments on 14 VLMs show that most models are not yet ready for task progress estimation, exhibiting sensitivity to demonstration modality and viewpoint changes, as well as poor handling of unanswerable cases. While training-free prompting that enforces structured progress reasoning yields limited and model-dependent gains, the training-based ProgressLM-3B achieves consistent improvements even at a small model scale, despite being trained on a task set fully disjoint from the evaluation tasks. Further analyses reveal characteristic error patterns and clarify when and why progress reasoning succeeds or fails.", "AI": {"tldr": "本文介绍了Progress-Bench基准，用于系统评估视觉语言模型的进度推理能力，并提出了一种基于人类启发的两阶段进度推理范式。", "motivation": "现代视觉语言模型在描述可见内容方面表现出色，但它们能否从部分观察中推断出任务的进展程度尚不清楚。为此，研究者们旨在通过系统评估和探索新的方法来解决这一问题。", "method": "提出Progress-Bench基准用于评估进度推理能力，并采用一种人类启发的两阶段进度推理范式，包括无训练提示法和基于训练的方法。", "result": "实验显示大多数模型尚未准备好进行任务进展估计，存在对演示模式和视角变化敏感以及无法处理不可回答情况的问题。使用结构化进度推理的无训练提示方法仅取得有限且依赖于模型的效果，而基于训练的ProgressLM-3B在小规模下也取得了持续改进。", "conclusion": "进一步分析揭示了特征错误模式，并明确了进度推理何时成功或失败的原因。"}}
{"id": "2601.15222", "pdf": "https://arxiv.org/pdf/2601.15222", "abs": "https://arxiv.org/abs/2601.15222", "authors": ["Stavrow A. Bahnam", "Robin Ferede", "Till M. Blaha", "Anton E. Lang", "Erin Lucassen", "Quentin Missinne", "Aderik E. C. Verraest", "Christophe De Wagter", "Guido C. H. E. de Croon"], "title": "MonoRace: Winning Champion-Level Drone Racing with Robust Monocular AI", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous drone racing represents a major frontier in robotics research. It requires an Artificial Intelligence (AI) that can run on board light-weight flying robots under tight resource and time constraints, while pushing the physical system to its limits. The state of the art in this area consists of a system with a stereo camera and an inertial measurement unit (IMU) that beat human drone racing champions in a controlled indoor environment. Here, we present MonoRace: an onboard drone racing approach that uses a monocular, rolling-shutter camera and IMU that generalizes to a competition environment without any external motion tracking system. The approach features robust state estimation that combines neural-network-based gate segmentation with a drone model. Moreover, it includes an offline optimization procedure that leverages the known geometry of gates to refine any state estimation parameter. This offline optimization is based purely on onboard flight data and is important for fine-tuning the vital external camera calibration parameters. Furthermore, the guidance and control are performed by a neural network that foregoes inner loop controllers by directly sending motor commands. This small network runs on the flight controller at 500Hz. The proposed approach won the 2025 Abu Dhabi Autonomous Drone Racing Competition (A2RL), outperforming all competing AI teams and three human world champion pilots in a direct knockout tournament. It set a new milestone in autonomous drone racing research, reaching speeds up to 100 km/h on the competition track and successfully coping with problems such as camera interference and IMU saturation.", "AI": {"tldr": "本文介绍了MonoRace，一种使用单目滚动快门相机和IMU的无人机自主竞速系统，在没有外部运动跟踪系统的条件下，赢得了阿布扎比2025年无人驾驶无人机竞速比赛。", "motivation": "推动了机器人研究领域的前沿，尤其是在资源和时间约束下实现高精度、高性能的自动驾驶飞行器方面的挑战。", "method": "采用了基于神经网络的门框分割与无人机模型结合的稳健状态估计，并通过离线优化程序利用已知的门框几何结构来调整关键参数。此外，使用了直接发送电机命令的小型神经网络进行导航和控制。", "result": "MonoRace系统在2025年阿布扎比无人驾驶无人机竞速比赛中胜出，超过了所有参赛的人工智能团队及三名世界冠军飞行员，达到了100公里/小时的速度，并成功应对了相机干扰和IMU饱和等问题。", "conclusion": "本文展示了MonoRace是自主无人机竞速研究的一个新里程碑，证明了单目视觉系统在没有外部运动跟踪的情况下可以达到竞争性水平的性能。"}}
{"id": "2601.15221", "pdf": "https://arxiv.org/pdf/2601.15221", "abs": "https://arxiv.org/abs/2601.15221", "authors": ["Hanlei Guo", "Jiahao Shao", "Xinya Chen", "Xiyang Tan", "Sheng Miao", "Yujun Shen", "Yiyi Liao"], "title": "ScenDi: 3D-to-2D Scene Diffusion Cascades for Urban Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in 3D object generation using diffusion models have achieved remarkable success, but generating realistic 3D urban scenes remains challenging. Existing methods relying solely on 3D diffusion models tend to suffer a degradation in appearance details, while those utilizing only 2D diffusion models typically compromise camera controllability. To overcome this limitation, we propose ScenDi, a method for urban scene generation that integrates both 3D and 2D diffusion models. We first train a 3D latent diffusion model to generate 3D Gaussians, enabling the rendering of images at a relatively low resolution. To enable controllable synthesis, this 3DGS generation process can be optionally conditioned by specifying inputs such as 3d bounding boxes, road maps, or text prompts. Then, we train a 2D video diffusion model to enhance appearance details conditioned on rendered images from the 3D Gaussians. By leveraging the coarse 3D scene as guidance for 2D video diffusion, ScenDi generates desired scenes based on input conditions and successfully adheres to accurate camera trajectories. Experiments on two challenging real-world datasets, Waymo and KITTI-360, demonstrate the effectiveness of our approach.", "AI": {"tldr": "提出ScenDi方法，结合3D和2D扩散模型生成真实城市场景。", "motivation": "现有仅使用3D或2D扩散模型的方法在生成逼真的城市景观时存在细节丢失或相机控制受限的问题。", "method": "首先训练一个3D隐式扩散模型生成低分辨率图像，然后训练一个2D视频扩散模型提升细节，同时支持基于输入条件的可控合成。", "result": "实验显示，ScenDi在Waymo和KITTI-360两个真实数据集上有效提升了场景生成的质量和相机轨迹准确性。", "conclusion": "结合3D和2D扩散模型的方法能够更好地解决城市景观生成中的挑战。"}}
{"id": "2601.15212", "pdf": "https://arxiv.org/pdf/2601.15212", "abs": "https://arxiv.org/abs/2601.15212", "authors": ["Dhrubo Saha"], "title": "ZENITH: Automated Gradient Norm Informed Stochastic Optimization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.", "AI": {"tldr": "介绍了一种新的优化器ZENITH，该优化器通过使用梯度范数的时间演变来自动调整学习率。", "motivation": "现有的自适应优化器存在计算和内存开销、与正则化不兼容以及选择次优学习率的问题。本工作旨在开发一种没有这些缺点的优化方法。", "method": "ZENITH利用梯度范数的时间演变来自动调整学习率，无需人工干预或超参数调优。", "result": "在图像分类实验中，跨越6种CNN架构和6个基准测试表明，ZENITH实现了更高的测试精度，并且比基线方法使用更短的运行时间。此外，在MS COCO数据集上的目标检测、关键点检测和实例分割任务上也表现出了优越的效果。", "conclusion": "ZENITH优化器在保持计算效率的同时提高了模型性能，尤其是在与正则化兼容的情况下可以实现更好的泛化能力。"}}
{"id": "2601.15211", "pdf": "https://arxiv.org/pdf/2601.15211", "abs": "https://arxiv.org/abs/2601.15211", "authors": ["Mayada Oudah", "John Wooders"], "title": "Real-time Facial Communication Restores Cooperation After Defection in Social Dilemmas", "categories": ["cs.GT", "cs.HC", "econ.GN"], "comment": "16 pages, 12 figures. Includes Supplementary Information (18 pages, 17 figures)", "summary": "Facial expressions are central to human interaction, yet their role in strategic decision-making has received limited attention. We investigate how real-time facial communication influences cooperation in repeated social dilemmas. In a laboratory experiment, participants play a repeated Prisoner's Dilemma game under two conditions: in one, they observe their counterpart's facial expressions via gender-neutral avatars, and in the other no facial cues are available. Using state-of-the-art biometric technology to capture and display emotions in real-time, we find that facial communication significantly increases overall cooperation and, notably, promotes cooperation following defection. This restorative effect suggests that facial expressions help participants interpret defections less harshly, fostering forgiveness and the resumption of cooperation. While past actions remain the strongest predictor of behavior, our findings highlight the communicative power of facial expressions in shaping strategic outcomes. These results offer practical insights for designing emotionally responsive virtual agents and digital platforms that sustain cooperation in the absence of physical presence.", "AI": {"tldr": "研究如何实时面部交流影响重复社会困境中的合作。", "motivation": "探讨面部表情在战略决策中所起的作用，尽管面部表达是人际交往的核心部分，但在此方面尚未得到充分关注。", "method": "通过实验室实验，在性别中立的虚拟形象和无面部线索条件下观察参与者玩重复囚徒困境游戏时的合作行为。", "result": "实时面部交流显著增加总体合作，并在背叛后促进恢复合作。研究揭示了面部表情对战略结果的影响。", "conclusion": "这些发现为设计能够保持合作的情感反应式虚拟代理和数字平台提供了实用见解，即使没有物理存在也能维持合作。"}}
{"id": "2601.15209", "pdf": "https://arxiv.org/pdf/2601.15209", "abs": "https://arxiv.org/abs/2601.15209", "authors": ["Paige S. DeVries", "Michaela Okosi", "Ming Li", "Nora Dunphy. Gidey Gezae", "Dante Conway", "Abraham Glasser", "Raja Kushalnagar", "Christian Vogler"], "title": "Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted for publication in ACM CHI 2026", "summary": "We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken English; with Alexa's automatic speech recognition and a Wizard-of-Oz setting with a trained facilitator re-speaking commands against that of a large language model (LLM)-assisted touch interface in a mixed-methods study. The touch method was navigated through an LLM-powered \"task prompter,\" which integrated the user's history and smart environment to suggest contextually-appropriate commands. Quantitative results showed no significant differences across both spoken English conditions vs LLM-assisted touch. Qualitative results showed variability in opinions on the usability of each method. Ultimately, it will be necessary to have robust deaf-accented speech recognized natively by IPAs.", "AI": {"tldr": "研究比较了智能个人助手（IPA）的语音输入和大语言模型（LLM）辅助触摸界面，以提高听力障碍人士的使用体验。", "motivation": "由于智能个人助手难以理解包括聋人发音在内的多样口音，该研究旨在探索一种更适合聋哑及听障人群使用的交互方式。", "method": "通过Echo Show设备，对比了自然语言输入（英语口语）、Alexa自动语音识别、有训练的辅导员重新表述命令与大语言模型辅助触摸界面的方法。使用定量和定性混合方法进行评估。", "result": "定量结果显示，两种语音条件下的表现与LLM辅助触控方式无显著差异；定性结果表明，对于每种方法的可用性存在不同意见。", "conclusion": "需要实现智能个人助手能够原生识别聋哑口音的功能。"}}
{"id": "2601.15202", "pdf": "https://arxiv.org/pdf/2601.15202", "abs": "https://arxiv.org/abs/2601.15202", "authors": ["Md Mahmudul Hoque", "Shuvo Karmaker", "Md. Hadi Al-Amin", "Md Modabberul Islam", "Jisun Junayed", "Farha Ulfat Mahi"], "title": "A Computer Vision Hybrid Approach: CNN and Transformer Models for Accurate Alzheimer's Detection from Brain MRI Scans", "categories": ["cs.CV"], "comment": null, "summary": "Early and accurate classification of Alzheimers disease (AD) from brain MRI scans is essential for timely clinical intervention and improved patient outcomes. This study presents a comprehensive comparative analysis of five CNN architectures (EfficientNetB0, ResNet50, DenseNet201, MobileNetV3, VGG16), five Transformer-based models (ViT, ConvTransformer, PatchTransformer, MLP-Mixer, SimpleTransformer), and a proposed hybrid model named Evan_V2. All models were evaluated on a four-class AD classification task comprising Mild Dementia, Moderate Dementia, Non-Demented, and Very Mild Dementia categories. Experimental findings show that CNN architectures consistently achieved strong performance, with ResNet50 attaining 98.83% accuracy. Transformer models demonstrated competitive generalization capabilities, with ViT achieving the highest accuracy among them at 95.38%. However, individual Transformer variants exhibited greater class-specific instability. The proposed Evan_V2 hybrid model, which integrates outputs from ten CNN and Transformer architectures through feature-level fusion, achieved the best overall performance with 99.99% accuracy, 0.9989 F1-score, and 0.9968 ROC AUC. Confusion matrix analysis further confirmed that Evan_V2 substantially reduced misclassification across all dementia stages, outperforming every standalone model. These findings highlight the potential of hybrid ensemble strategies in producing highly reliable and clinically meaningful diagnostic tools for Alzheimers disease classification.", "AI": {"tldr": "研究提出了一种名为Evan_V2的混合模型，结合了CNN和Transformer架构，用于从脑部MRI扫描中进行阿尔茨海默病的精确分类。", "motivation": "早期准确地识别阿尔茨海默病对及时临床干预和改善患者预后至关重要。", "method": "研究对比分析了五种基于CNN的模型（EfficientNetB0、ResNet50、DenseNet201、MobileNetV3、VGG16）和五种Transformer模型（ViT、ConvTransformer、PatchTransformer、MLP-Mixer、SimpleTransformer），并提出了一种名为Evan_V2的混合模型，该模型通过特征级融合从十个CNN和Transformer架构中获取输出。", "result": "实验结果表明，ResNet50达到了98.83%的准确率，而ViT在所有的Transformer模型中表现最佳，准确率为95.38%，但各个Transformer变体在特定类别上表现出不稳定性。Evan_V2混合模型实现了最高的整体性能：准确率为99.99%，F1得分为0.9989，ROC AUC为0.9968。", "conclusion": "这些发现强调了混合集成策略在产生高度可靠且具有临床意义的诊断工具以分类阿尔茨海默病方面的重要潜力。"}}
{"id": "2601.15200", "pdf": "https://arxiv.org/pdf/2601.15200", "abs": "https://arxiv.org/abs/2601.15200", "authors": ["Miroslav Purkrabek", "Constantin Kolomiiets", "Jiri Matas"], "title": "BBoxMaskPose v2: Expanding Mutual Conditioning to 3D", "categories": ["cs.CV"], "comment": "GitHub repository: https://github.com/MiraPurkrabek/BBoxMaskPose/", "summary": "Most 2D human pose estimation benchmarks are nearly saturated, with the exception of crowded scenes. We introduce PMPose, a top-down 2D pose estimator that incorporates the probabilistic formulation and the mask-conditioning. PMPose improves crowded pose estimation without sacrificing performance on standard scenes. Building on this, we present BBoxMaskPose v2 (BMPv2) integrating PMPose and an enhanced SAM-based mask refinement module. BMPv2 surpasses state-of-the-art by 1.5 average precision (AP) points on COCO and 6 AP points on OCHuman, becoming the first method to exceed 50 AP on OCHuman. We demonstrate that BMP's 2D prompting of 3D model improves 3D pose estimation in crowded scenes and that advances in 2D pose quality directly benefit 3D estimation. Results on the new OCHuman-Pose dataset show that multi-person performance is more affected by pose prediction accuracy than by detection. The code, models, and data are available on https://MiraPurkrabek.github.io/BBox-Mask-Pose/.", "AI": {"tldr": "本文介绍了BBoxMaskPose v2，一种改进的二维人体姿态估计方法，并展示了其在三维姿态估计中的应用。", "motivation": "鉴于现有的二维人体姿态估计算法在拥挤场景中表现不佳，作者旨在开发一个更准确的模型来改善这一问题。", "method": "通过引入PMPose和增强的SAM基础掩码优化模块，BBoxMaskPose v2能够提高在拥挤场景下的姿态估计准确性，并且不牺牲标准场景的表现。", "result": "实验结果表明，该方法在COCO数据集上提高了1.5个平均精度点，在OCHuman数据集上提高了6个平均精度点，首次超过了OCHuman上的50 AP基准。同时证明了二维姿态估计的改进对三维姿态估计有正面影响。", "conclusion": "研究结果显示，多人体姿态性能更多地受到姿态预测准确性的影响而非检测的影响，并且二维提示可以显著提升拥挤场景下的三维姿态估计效果。"}}
{"id": "2601.15197", "pdf": "https://arxiv.org/pdf/2601.15197", "abs": "https://arxiv.org/abs/2601.15197", "authors": ["Shijie Lian", "Bin Yu", "Xiaopeng Lin", "Laurence T. Yang", "Zhaolong Shen", "Changti Wu", "Yuzhuo Miao", "Cong Huang", "Kai Chen"], "title": "BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \\mid v)$ and a language-conditioned posterior $π(a \\mid v, \\ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.", "AI": {"tldr": "提出BayesianVLA框架，通过贝叶斯分解解决视觉语言动作模型中的数据集偏差问题。", "motivation": "现有Vision-Language-Action（VLA）模型在机器人操作中表现出色但难以泛化到新的指令或复杂多任务场景。目标驱动的数据收集导致信息崩溃现象，使得语言指令高度可预测，从而忽略语言约束并在分布外设置中失败。", "method": "通过引入可学习的潜在动作查询，构造双分支架构来估计视觉优先和语言条件后验，并优化策略以最大化动作和指令之间的条件点互信息。", "result": "无需新数据，BayesianVLA显著提高了泛化能力，在SimplerEnv和RoboCasa上的实验表明有明显提升，特别是在具有挑战性的分布外SimplerEnv基准上提高11.3%。", "conclusion": "该方法有效解决了视觉语言动作模型中的信息崩溃问题，并在分布外场景中展示了良好的泛化能力。"}}
{"id": "2601.15195", "pdf": "https://arxiv.org/pdf/2601.15195", "abs": "https://arxiv.org/abs/2601.15195", "authors": ["Ramtin Ehsani", "Sakshi Pathak", "Shriya Rawal", "Abdullah Al Mujahid", "Mia Mohammad Imran", "Preetha Chatterjee"], "title": "Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at International Mining Software Repositories Conference (MSR 2026)", "summary": "AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five coding agents across GitHub. (RQ1) We first quantitatively characterize merged and not-merged PRs along four broad dimensions: 1) merge outcomes across task types, 2) code changes, 3) CI build results, and 4) review dynamics. We observe that tasks related to documentation, CI, and build update achieve the highest merge success, whereas performance and bug-fix tasks perform the worst. Not-merged PRs tend to involve larger code changes, touch more files, and often do not pass the project's CI/CD pipeline validation. (RQ2) To further investigate why some agentic PRs are not merged, we qualitatively analyze 600 PRs to derive a hierarchical taxonomy of rejection patterns. This analysis complements the quantitative findings in RQ1 by uncovering rejection reasons not captured by quantitative metrics, including lack of meaningful reviewer engagement, duplicate PRs, unwanted feature implementations, and agent misalignment. Together, our findings highlight key socio-technical and human-AI collaboration factors that are critical to improving the success of future agentic workflows.", "AI": {"tldr": "该论文研究了AI编码代理在GitHub上的失败情况，通过大规模数据分析和定性分析揭示了这些代理提交的Pull Request被拒绝的原因。", "motivation": "随着AI编码代理越来越多地参与到软件项目的贡献中，关于它们实际行为以及为何许多提交未能合并的信息仍不清楚。因此，该研究旨在探索这些问题。", "method": "通过对GitHub上33000个由五个不同的AI编码代理提交的Pull Request进行定量分析，并对600个样本进行定性分析，以了解被拒绝的原因。", "result": "研究发现与文档、CI和构建更新相关的任务合并成功率最高，而性能改进和错误修复任务表现最差。未合并的PR涉及较大的代码变更，影响更多文件且常无法通过项目的CI/CD验证。此外，还揭示了包括缺乏有意义的审查参与、重复PR等原因。", "conclusion": "研究结果强调了改善未来代理工作流程的成功率所必需的关键社会技术因素和人机协作问题。"}}
{"id": "2601.15188", "pdf": "https://arxiv.org/pdf/2601.15188", "abs": "https://arxiv.org/abs/2601.15188", "authors": ["Stephan Wallraven", "Tim Köhne", "Hartmut Westenberger", "Andreas Moser"], "title": "Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": "20 pages, 10 figures, Author: Hartmut Westenberger (ORCID: 0009-0009-9063-8318)", "summary": "This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges. For this purpose, a benchmark with 180 tasks is conducted, consisting of adapted HumanEval tasks and practical SAP scenarios. The results show significant performance differences between the models: more powerful LLMs achieve success rates of around 75% after several iterations and benefit greatly from compiler feedback, while smaller models perform significantly weaker. Overall, the study highlights the high potential of powerful LLMs for ABAP development processes, especially in iterative error correction.", "AI": {"tldr": "本研究评估了大型语言模型（LLMs）在生成ABAP代码方面的表现，并探讨它们如何通过编译器反馈进行迭代改进。", "motivation": "虽然生成式AI已经在许多编程语言中取得了成功应用，但对于ABAP代码生成的系统性分析却很少见。本研究旨在填补这一空白并探讨不同模型的表现差异。", "method": "研究设计了一个包含180个任务的基准测试集，其中包括改编的人类评估任务和实际SAP场景，以评估LLMs在迭代改进过程中使用编译器反馈的有效性及它们生成语法正确且功能性的ABAP代码的能力。", "result": "实验结果表明，更强大的大型语言模型通过多次迭代可以达到约75%的成功率，并且显著受益于编译器反馈；而较小的模型表现明显较差。", "conclusion": "研究表明，强大的LLMs在ABAP开发过程中具有很高的潜力，尤其是在迭代错误纠正方面。"}}
{"id": "2601.15177", "pdf": "https://arxiv.org/pdf/2601.15177", "abs": "https://arxiv.org/abs/2601.15177", "authors": ["Lorenzo Fernández Maimó", "Alberto Huertas Celdrán", "Manuel Gil Pérez", "Félix J. García Clemente", "Gregorio Martínez Pérez"], "title": "Dynamic Management of a Deep Learning-Based Anomaly Detection System for 5G Networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Fog and mobile edge computing (MEC) will play a key role in the upcoming fifth generation (5G) mobile networks to support decentralized applications, data analytics and management into the network itself by using a highly distributed compute model. Furthermore, increasing attention is paid to providing user-centric cybersecurity solutions, which particularly require collecting, processing and analyzing significantly large amount of data traffic and huge number of network connections in 5G networks. In this regard, this paper proposes a MEC-oriented solution in 5G mobile networks to detect network anomalies in real-time and in autonomic way. Our proposal uses deep learning techniques to analyze network flows and to detect network anomalies. Moreover, it uses policies in order to provide an efficient and dynamic management system of the computing resources used in the anomaly detection process. The paper presents relevant aspects of the deployment of the proposal and experimental results to show its performance.", "AI": {"tldr": "本文提出了一种基于MEC的解决方案，用于在5G移动网络中实时自动检测网络异常，并采用深度学习技术分析网络流以识别异常。", "motivation": "随着Fog和MEC技术的发展，5G网络需要支持分散式应用、数据分析与管理，特别强调了用户中心的安全性解决方案。这要求处理大量的数据流量和众多的网络连接。", "method": "该方法利用深度学习技术分析网络流并检测异常，并通过策略动态管理和优化用于异常检测过程中的计算资源。", "result": "论文展示了部署提案的相关方面及其实验结果，验证了其性能表现。", "conclusion": "研究证明了提出的MEC导向解决方案在实时自动检测5G网络中的网络异常方面的有效性及其对计算资源的高效动态管理能力。"}}
{"id": "2601.15170", "pdf": "https://arxiv.org/pdf/2601.15170", "abs": "https://arxiv.org/abs/2601.15170", "authors": ["Zhucun Xue", "Jiangning Zhang", "Juntao Jiang", "Jinzhuo Liu", "Haoyang He", "Teng Hu", "Xiaobin Hu", "Guangming Yao", "Yi Yuan", "Yong Liu"], "title": "Large-Scale Multidimensional Knowledge Profiling of Scientific Literature", "categories": ["cs.CV"], "comment": "Code and dataset: https://github.com/xzc-zju/Profiling_Scientific_Literature", "summary": "The rapid expansion of research across machine learning, vision, and language has produced a volume of publications that is increasingly difficult to synthesize. Traditional bibliometric tools rely mainly on metadata and offer limited visibility into the semantic content of papers, making it hard to track how research themes evolve over time or how different areas influence one another. To obtain a clearer picture of recent developments, we compile a unified corpus of more than 100,000 papers from 22 major conferences between 2020 and 2025 and construct a multidimensional profiling pipeline to organize and analyze their textual content. By combining topic clustering, LLM-assisted parsing, and structured retrieval, we derive a comprehensive representation of research activity that supports the study of topic lifecycles, methodological transitions, dataset and model usage patterns, and institutional research directions. Our analysis highlights several notable shifts, including the growth of safety, multimodal reasoning, and agent-oriented studies, as well as the gradual stabilization of areas such as neural machine translation and graph-based methods. These findings provide an evidence-based view of how AI research is evolving and offer a resource for understanding broader trends and identifying emerging directions. Code and dataset: https://github.com/xzc-zju/Profiling_Scientific_Literature", "AI": {"tldr": "论文主要任务是通过大规模多维知识剖析科学文献，以全面展示研究活动的演变。", "motivation": "由于机器学习、视觉和语言领域的快速发展，出版物的数量急剧增加，传统的计量工具依赖元数据且无法提供对文本内容的深入理解。这使得跟踪研究主题随时间的发展及不同领域之间的相互影响变得困难。", "method": "论文收集了2020年至2025年间来自22个主要会议超过10万篇论文的数据集，并构建了一个多维剖析管道，结合话题聚类、LLM辅助解析和结构化检索来组织和分析文本内容。", "result": "研究发现了一些显著的变化趋势，包括安全性的增长、多元模态推理以及面向代理的研究的增长，同时也观察到了神经机器翻译和基于图的方法等领域的逐渐稳定。", "conclusion": "这些成果为理解AI研究的演变提供了证据支持，并提供了一个资源来识别更广泛的趋势及新兴方向。"}}
{"id": "2601.15165", "pdf": "https://arxiv.org/pdf/2601.15165", "abs": "https://arxiv.org/abs/2601.15165", "authors": ["Zanlin Ni", "Shenzhi Wang", "Yang Yue", "Tianyu Yu", "Weilin Zhao", "Yeguo Hua", "Tianyi Chen", "Jun Song", "Cheng Yu", "Bo Zheng", "Gao Huang"], "title": "The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code and pre-trained models: https://github.com/LeapLabTHU/JustGRPO", "summary": "Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have leveraged reinforcement learning (RL) to elicit the reasoning capability of dLLMs. In this paper, we reveal a counter-intuitive reality: arbitrary order generation, in its current form, narrows rather than expands the reasoning boundary of dLLMs. We find that dLLMs tend to exploit this order flexibility to bypass high-uncertainty tokens that are crucial for exploration, leading to a premature collapse of the solution space. This observation challenges the premise of existing RL approaches for dLLMs, where considerable complexities, such as handling combinatorial trajectories and intractable likelihoods, are often devoted to preserving this flexibility. We demonstrate that effective reasoning is better elicited by intentionally forgoing arbitrary order and applying standard Group Relative Policy Optimization (GRPO) instead. Our approach, JustGRPO, is minimalist yet surprisingly effective (e.g., 89.1% accuracy on GSM8K) while fully retaining the parallel decoding ability of dLLMs. Project page: https://nzl-thu.github.io/the-flexibility-trap", "AI": {"tldr": "论文揭示了扩散语言模型中任意顺序生成方式会限制推理能力，并提出了一种更有效的GRPO方法。", "motivation": "尽管扩散语言模型具有打破传统左到右约束的能力，但这种灵活性实际上缩小了解决问题的空间，导致高不确定性令牌被规避。", "method": "研究通过实验展示放弃任意顺序并应用标准的Group Relative Policy Optimization (GRPO)可以更有效地激发推理能力。", "result": "提出的方法JustGRPO在保持平行解码能力的同时，在GSM8K数据集上达到了89.1%的准确率，表现优异。", "conclusion": "结论是现有使用任意顺序生成方式的强化学习方法可能过于复杂，并且不一定能有效提升扩散语言模型的推理性能。"}}
{"id": "2601.15164", "pdf": "https://arxiv.org/pdf/2601.15164", "abs": "https://arxiv.org/abs/2601.15164", "authors": ["Yaru Liu", "Ao-bo Wang", "Nanyang Ye"], "title": "V-CAGE: Context-Aware Generation and Verification for Scalable Long-Horizon Embodied Tasks", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Learning long-horizon embodied behaviors from synthetic data remains challenging because generated scenes are often physically implausible, language-driven programs frequently \"succeed\" without satisfying task semantics, and high-level instructions require grounding into executable action sequences. To address these limitations, we introduce V-CAGE, a closed-loop framework for generating robust, semantically aligned manipulation datasets at scale. First, we propose a context-aware instantiation mechanism that enforces geometric consistency during scene synthesis. By dynamically maintaining a map of prohibited spatial areas as objects are placed, our system prevents interpenetration and ensures reachable, conflict-free configurations in cluttered environments. Second, to bridge the gap between abstract intent and low-level control, we employ a hierarchical instruction decomposition module. This decomposes high-level goals (e.g., \"get ready for work\") into compositional action primitives, facilitating coherent long-horizon planning. Crucially, we enforce semantic correctness through a VLM-based verification loop. Acting as a visual critic, the VLM performs rigorous rejection sampling after each subtask, filtering out \"silent failures\" where code executes but fails to achieve the visual goal. Experiments demonstrate that V-CAGE yields datasets with superior physical and semantic fidelity, significantly boosting the success rate and generalization of downstream policies compared to non-verified baselines.", "AI": {"tldr": "该论文介绍了V-CAGE框架，用于生成大规模的、语义对齐的长时间跨度具身任务数据集。", "motivation": "为了应对从合成数据中学习长时间跨度具身行为时面临的挑战，例如物理不真实和高层次指令到可执行动作序列之间的转换问题。", "method": "V-CAGE框架包括一个上下文感知实例化机制以维护几何一致性以及一个分层指令分解模块来将高层次目标转化为基础操作，并通过视觉语言模型（VLM）进行语义正确性的验证。", "result": "实验表明，与未经过验证的基准相比，V-CAGE生成的数据集具有更高的物理和语义保真度，并显著提高了下游策略的成功率和泛化能力。", "conclusion": "V-CAGE框架通过其上下文感知实例化机制、分层指令分解模块以及视觉语言模型的验证功能，在大规模数据集生成中实现了更高质量的长时间跨度具身任务学习。"}}
{"id": "2601.15163", "pdf": "https://arxiv.org/pdf/2601.15163", "abs": "https://arxiv.org/abs/2601.15163", "authors": ["Erina Seh-Young Moon", "Matthew Tamura", "Angelina Zhai", "Nuzaira Habib", "Behnaz Shirazi", "Altaf Kassam", "Devansh Saxena", "Shion Guha"], "title": "The Promises and Perils of using LLMs for Effective Public Services", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Governments are the primary providers of essential public services and are responsible for delivering them effectively. In high-stakes decision-making domains such as child welfare (CW), agencies must protect children without unnecessarily prolonging a family's engagement with the system. With growing optimism around AI, governments are pushing for its integration but concerns regarding feasibility and harms remain. Through collaborations with a large Canadian CW agency, we examined how LocalLLM and BERTopic models can track CW case progress. We demonstrate how the tools can potentially assist workers in opportunistically addressing gaps in their work by signaling case progress/deviations. And yet, we also show how they fail to detect case trajectories that require discretionary judgments grounded in social work training, areas where practitioners would actually want support to pre-emptively address substantive case concerns. We also provide a roadmap of future participatory directions to co-design language tools for/with the public sector.", "AI": {"tldr": "研究探讨了使用本地LLM和BERTopic模型跟踪儿童福利案件进展的潜力与局限性。", "motivation": "政府作为公共服务的主要提供者，需要有效交付这些服务。尤其是在儿童福利领域，如何在保护孩子的同时避免对家庭造成过度干涉是重要问题。尽管人工智能被寄予厚望，但其可行性及潜在危害仍需探讨。", "method": "通过与加拿大一家大型儿童福利机构合作，研究团队使用了本地LLM和BERTopic模型来跟踪案件进展，并评估这些工具如何帮助工作人员识别工作中的缺口或偏差。", "result": "研究表明，这些语言模型可以辅助工作者及时处理工作中存在的问题，但在需要专业社会工作判断的复杂案件中表现不佳。模型未能检测出那些需要基于专业知识做出裁量性判断的情况。", "conclusion": "尽管AI工具在儿童福利服务中有潜在价值，但仍需进一步开发以更好地支持工作人员的工作，并提出了未来与公共部门合作设计语言工具的方向。"}}
{"id": "2601.15161", "pdf": "https://arxiv.org/pdf/2601.15161", "abs": "https://arxiv.org/abs/2601.15161", "authors": ["Yinzhu Chen", "Abdine Maiga", "Hossein A. Rahmani", "Emine Yilmaz"], "title": "Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this paper, we propose a retrieval-augmented multi-agent framework designed to automate the generation of instance-specific evaluation rubrics. Our approach grounds evaluation in authoritative medical evidence by decomposing retrieved content into atomic facts and synthesizing them with user interaction constraints to form verifiable, fine-grained evaluation criteria. Evaluated on HealthBench, our framework achieves a Clinical Intent Alignment (CIA) score of 60.12%, a statistically significant improvement over the GPT-4o baseline (55.16%). In discriminative tests, our rubrics yield a mean score delta ($μ_Δ = 8.658$) and an AUROC of 0.977, nearly doubling the quality separation achieved by GPT-4o baseline (4.972). Beyond evaluation, our rubrics effectively guide response refinement, improving quality by 9.2% (from 59.0% to 68.2%). This provides a scalable and transparent foundation for both evaluating and improving medical LLMs. The code is available at https://anonymous.4open.science/r/Automated-Rubric-Generation-AF3C/.", "AI": {"tldr": "本文提出了一种基于检索增强多代理框架的自动化评分细则生成方法，用于可靠评估医学对话系统。", "motivation": "大型语言模型在临床决策支持中的应用日益广泛，但这些模型可能产生的幻觉和不安全建议直接威胁患者安全。现有的通用度量标准难以检测出细微的临床错误，而专家编写的精细评分细则成本高昂且不易扩展。", "method": "本文提出的方法通过检索权威医学证据并将其分解为原子事实，并与用户交互约束相结合，自动生成实例特定的评估准则。", "result": "在HealthBench数据集上，该框架取得了60.12%的临床意图一致性得分，显著高于GPT-4o基准（55.16%）。其均值得分差异为8.658，AUROC达到0.977，几乎翻倍于GPT-4o基准。此外，在响应优化中，质量改善了9.2%，从59.0%提高到68.2%。", "conclusion": "本文提出的方法提供了一种可扩展且透明的基础，用于评估和改进医学大型语言模型，并在多个测试指标上表现出显著优于现有基准的性能。"}}
{"id": "2601.15160", "pdf": "https://arxiv.org/pdf/2601.15160", "abs": "https://arxiv.org/abs/2601.15160", "authors": ["Yuval Kansal", "Niraj K. Jha"], "title": "Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a \"compositional bridge\", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.", "AI": {"tldr": "本文提出了一种基于知识图谱的强化学习方法，通过路径衍生奖励信号来促进语言模型在复杂推理任务中的性能。", "motivation": "虽然大型语言模型已经在数学和编程等领域实现了接近专家级的表现，但在特定科学领域内的多步推理能力仍然有限。因此，研究动机在于探索一种方法，使模型能够进行更复杂的组合式多步推理。", "method": "该论文提出了一种基于知识图谱的后训练流程，结合监督微调和强化学习技术。通过从知识图谱路径中提取奖励信号来鼓励模型组合中间公理，而不仅仅是优化最终答案。", "result": "实验结果表明，在医学领域进行短跳推理路径（1-3步）上的训练后，该模型在零样本情况下可以推广到更复杂的多步查询（4-5步）。相较于更大规模的模型和前沿系统如GPT-5.2和Gemini 3 Pro，它在最困难的推理任务上表现更佳，并且对于选项混洗的压力测试具有更强的鲁棒性。", "conclusion": "这项工作表明，在结构化知识中锚定推理过程是一种规模化和高效的方法，可以实现智能推理。路径衍生奖励作为组合式桥梁的作用，验证了这一方法的有效性和效率。"}}
{"id": "2601.15158", "pdf": "https://arxiv.org/pdf/2601.15158", "abs": "https://arxiv.org/abs/2601.15158", "authors": ["Yuval Ran-Milo", "Yotam Alexander", "Shahar Mendel", "Nadav Cohen"], "title": "Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data", "categories": ["cs.LG", "cs.AI"], "comment": "80 pages, 4 figures", "summary": "Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of \"simple examples\": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.", "AI": {"tldr": "研究揭示了通过基于结果的强化学习（RL）训练的Transformer能够自发地发展出生成中间推理步骤的能力。", "motivation": "理解稀疏奖励如何驱动梯度下降发现系统性的推理机制，尤其是在图遍历任务中需要链式思考的情况下。", "method": "分析单层Transformers在无法通过简单迭代解决但必须使用链式思维（CoT）的合成图遍历任务中的梯度流动动态，并进行理论证明和实验验证。", "result": "证明了即使仅基于最终答案正确性训练，模型也能收敛到一种结构化、可解释的算法，该算法能够逐个顶点迭代地遍历图。实验证明这些理论发现适用于实际的语言处理任务。", "conclusion": "表明在特定的数据分布条件下，通过稀疏奖励的强化学习可以使Transformer自发发展出链式思维能力，并且这种能力需要足够的简单实例以支持模型的学习和推广。"}}
{"id": "2601.15153", "pdf": "https://arxiv.org/pdf/2601.15153", "abs": "https://arxiv.org/abs/2601.15153", "authors": ["Choro Ulan uulu", "Mikhail Kulyabin", "Iris Fuhrmann", "Jan Joosten", "Nuno Miguel Martins Pacheco", "Filippos Petridis", "Rebecca Johnson", "Jan Bosch", "Helena Holmström Olsson"], "title": "How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework", "categories": ["cs.AI"], "comment": null, "summary": "Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software engineering framework to capture human domain knowledge for engineering AI agents in simulation data visualization by augmenting a Large Language Model (LLM) with a request classifier, Retrieval-Augmented Generation (RAG) system for code generation, codified expert rules, and visualization design principles unified in an agent demonstrating autonomous, reactive, proactive, and social behavior. Evaluation across five scenarios spanning multiple engineering domains with 12 evaluators demonstrates 206% improvement in output quality, with our agent achieving expert-level ratings in all cases versus baseline's poor performance, while maintaining superior code quality with lower variance. Our contributions are: an automated agent-based system for visualization generation and a validated framework for systematically capturing human domain knowledge and codifying tacit expert knowledge into AI agents, demonstrating that non-experts can achieve expert-level outcomes in specialized domains.", "AI": {"tldr": "本文提出了一种软件工程框架，通过将大型语言模型（LLM）与请求分类器、检索增强生成系统、编码专家规则和可视化设计原则相结合，构建能够自动生成高质量可视化的AI代理。", "motivation": "由于关键领域的知识通常只存在于少数几个专家中，这导致了组织在可扩展性和决策制定方面的瓶颈。非专家难以创建有效的可视化图表，从而影响了洞察力并占用了专家的时间。本文旨在解决这一问题。", "method": "通过工业案例研究提出了一种软件工程框架，该框架将大型语言模型（LLM）与请求分类器、检索增强生成系统、编码的专家规则和统一在代理中的可视化设计原则相结合，以捕捉人类领域知识并应用于模拟数据可视化中。", "result": "评估结果显示，在五个涵盖多个工程领域的场景下，使用12个评价者进行测试时，该AI代理实现了比基线模型高206%的输出质量，并且达到了专家级别的评分，同时保持了优秀的代码质量和较低的变化性。", "conclusion": "本文贡献了一个自动化的基于代理系统用于生成可视化图表和一个经过验证的框架来系统地捕捉人类领域知识并将隐性的专家知识编码到AI代理中，证明非专家可以在专业领域实现专家级的结果。"}}
{"id": "2601.15146", "pdf": "https://arxiv.org/pdf/2601.15146", "abs": "https://arxiv.org/abs/2601.15146", "authors": ["Björn R. Severitt", "Yannick Sauer", "Nora Castner", "Siegfried Wahl"], "title": "A Real-Time Error Prevention System for Gaze-Based Interaction in Virtual Reality Based on Anomaly Detection", "categories": ["cs.HC"], "comment": null, "summary": "Gaze-based interaction enables intuitive, hands-free control in immersive environments, but remains susceptible to unintended inputs. We present a real-time error prevention system (EPS) that uses a temporal convolutional network autoencoder (TCNAE) to detect anomalies in gaze dynamics during selection tasks. In a visual search task in VR, 41 participants used three gaze-based methods - dwell time, gaze and head direction alignment, and nod - with and without EPS. The system reduced erroneous selections by up to 95% for dwell time and gaze and head, and was positively received by most users. Performance varied for nodding and between individuals, suggesting the need for adaptive systems. Objective metrics and subjective evaluations show that anomaly-based error prevention can improve gaze interfaces without disrupting interaction. These findings demonstrate the potential of anomaly-based error prevention for gaze interfaces and suggest applications in VR, AR, and assistive technologies.", "AI": {"tldr": "本文介绍了一种基于异常检测的实时错误预防系统，用于减少虚拟现实中基于注视交互中的误操作。", "motivation": "鉴于基于注视的交互方法虽然直观且无需手部控制，但在沉浸式环境中容易产生无意的操作输入，因此开发一个能够减少这些误操作的系统是有必要的。", "method": "研究使用了时间卷积网络自编码器（TCNAE）来检测选择任务中注视动态的异常，并进行了包含41名参与者的视觉搜索实验，测试三种基于注视的方法：注视停留时间、注视和头部方向对齐以及点头，在有或没有EPS系统的情况下的效果。", "result": "该系统能够将误操作减少高达95%（针对注视停留时间和注视与头部方向对齐方法），并且大多数用户对其表示满意。对于点头法，性能存在个体差异，表明需要开发适应性更强的系统。客观指标和主观评估显示基于异常检测的方法可以提高注视界面的质量而不影响交互体验。", "conclusion": "研究证明了基于异常检测的错误预防技术对改善基于注视的交互具有潜力，并建议该技术在虚拟现实、增强现实以及辅助技术中的应用价值。"}}
{"id": "2601.15136", "pdf": "https://arxiv.org/pdf/2601.15136", "abs": "https://arxiv.org/abs/2601.15136", "authors": ["Yi-Chieh Lee", "Junti Zhang", "Tianqi Song", "Yugin Tan"], "title": "Conversational AI for Social Good (CAI4SG): An Overview of Emerging Trends, Applications, and Challenges", "categories": ["cs.HC"], "comment": null, "summary": "The integration of Conversational Agents (CAs) into daily life offers opportunities to tackle global challenges, leading to the emergence of Conversational AI for Social Good (CAI4SG). This paper examines the advancements of CAI4SG using a role-based framework that categorizes systems according to their AI autonomy and emotional engagement. This framework emphasizes the importance of considering the role of CAs in social good contexts, such as serving as empathetic supporters in mental health or functioning as assistants for accessibility. Additionally, exploring the deployment of CAs in various roles raises unique challenges, including algorithmic bias, data privacy, and potential socio-technical harms. These issues can differ based on the CA's role and level of engagement. This paper provides an overview of the current landscape, offering a role-based understanding that can guide future research and design aimed at the equitable, ethical, and effective development of CAI4SG.", "AI": {"tldr": "本文概述了对话式AI在社会公益中的新兴趋势、应用和挑战，并提出了一种基于角色的框架来分类这些系统。", "motivation": "文章旨在探讨将对话式代理集成到日常生活中以解决全球性问题的机会，特别关注其在社会公益领域的潜力及面临的独特挑战。", "method": "采用一种基于AI自主性和情感参与的角色分类框架，评估和分析了CAI4SG的现状和发展趋势。", "result": "提出了一个角色分类框架来指导未来的研究和设计，以实现对话式AI的社会公益应用的公平、伦理和有效性。", "conclusion": "强调了在社会公益背景下开发对话式AI系统时需特别注意算法偏见、数据隐私和社会技术伤害等问题的重要性。"}}
{"id": "2601.15133", "pdf": "https://arxiv.org/pdf/2601.15133", "abs": "https://arxiv.org/abs/2601.15133", "authors": ["André Eberhard", "Gerhard Neumann", "Pascal Friederich"], "title": "Graph Recognition via Subgraph Prediction", "categories": ["cs.CV", "cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Despite tremendous improvements in tasks such as image classification, object detection, and segmentation, the recognition of visual relationships, commonly modeled as the extraction of a graph from an image, remains a challenging task. We believe that this mainly stems from the fact that there is no canonical way to approach the visual graph recognition task. Most existing solutions are specific to a problem and cannot be transferred between different contexts out-of-the box, even though the conceptual problem remains the same. With broad applicability and simplicity in mind, in this paper we develop a method, \\textbf{Gra}ph Recognition via \\textbf{S}ubgraph \\textbf{P}rediction (\\textbf{GraSP}), for recognizing graphs in images. We show across several synthetic benchmarks and one real-world application that our method works with a set of diverse types of graphs and their drawings, and can be transferred between tasks without task-specific modifications, paving the way to a more unified framework for visual graph recognition.", "AI": {"tldr": "本论文开发了一种名为GraSP的方法，用于识别图像中的图形，并展示了该方法在多种合成基准和一个实际应用场景下的有效性。", "motivation": "现有解决方案通常针对特定问题，缺乏泛化能力，作者旨在提出一种简单且广泛应用的视觉图识别方法。", "method": "开发了一种名为GraSP的方法，通过子图预测来实现图像中的图形识别。", "result": "该方法在多种合成基准和一个实际应用中表现良好，可应用于不同类型的图形及其绘制，并能在任务间进行转移而不需特定修改。", "conclusion": "提出的方法为视觉图识别提供了一个更统一的框架，表明其具有广泛的应用潜力。"}}
{"id": "2601.15131", "pdf": "https://arxiv.org/pdf/2601.15131", "abs": "https://arxiv.org/abs/2601.15131", "authors": ["Ayan Maity", "Sudeshna Sarkar"], "title": "Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding", "categories": ["cs.AI"], "comment": "Accepted at AAAI-26 Workshop on AI for Urban Planning", "summary": "In this paper, we study the vehicle routing problem with a finite time horizon. In this routing problem, the objective is to maximize the number of customer requests served within a finite time horizon. We present a novel routing network embedding module which creates local node embedding vectors and a context-aware global graph representation. The proposed Markov decision process for the vehicle routing problem incorporates the node features, the network adjacency matrix and the edge features as components of the state space. We incorporate the remaining finite time horizon into the network embedding module to provide a proper routing context to the embedding module. We integrate our embedding module with a policy gradient-based deep Reinforcement Learning framework to solve the vehicle routing problem with finite time horizon. We trained and validated our proposed routing method on real-world routing networks, as well as synthetically generated Euclidean networks. Our experimental results show that our method achieves a higher customer service rate than the existing routing methods. Additionally, the solution time of our method is significantly lower than that of the existing methods.", "AI": {"tldr": "本文研究了具有有限时间范围的车辆路径问题，提出了一种基于深度强化学习和改进网络嵌入的方法。", "motivation": "动机是提高在有限时间内完成客户请求的数量，同时减少解决该问题的时间。", "method": "方法包括一个新型路由网络嵌入模块，生成局部节点嵌入向量及上下文感知的全局图表示。提出基于马尔可夫决策过程的方法，将剩余时间范围纳入嵌入模块，并整合到策略梯度强化学习框架中。", "result": "实验结果显示，在真实世界和合成的欧几里得网络上，所提方法比现有方法具有更高的客户服务率和更低的问题解决时间。", "conclusion": "结论是该深度强化学习与改进网络嵌入结合的方法能有效提高有限时间内车辆路径问题的客户请求完成数量，并缩短解决问题所需的时间。"}}
{"id": "2601.15130", "pdf": "https://arxiv.org/pdf/2601.15130", "abs": "https://arxiv.org/abs/2601.15130", "authors": ["Ivan Carrera", "Daniel Maldonado-Ruiz"], "title": "The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks", "categories": ["cs.AI", "cs.CL"], "comment": ":K.4; K.3", "summary": "The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the \"Plausibility Trap\": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the \"efficiency tax\"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.", "AI": {"tldr": "文章定义了“合理性陷阱”，并提出了一种框架来帮助开发者决定何时使用生成式AI以及何时避免使用。", "motivation": "由于大型语言模型的普遍应用，人们倾向于将昂贵的概率引擎用于简单的确定性任务，导致资源浪费。因此，作者希望通过研究这一现象并提供解决方案以减少这种效率损失。", "method": "通过微基准测试和案例研究（如OCR和事实核查），量化了“效率税”以及算法谄媚的风险，并引入了工具选择工程和决定矩阵来指导开发者的决策。", "result": "发现使用昂贵的概率引擎执行确定性任务会导致大约6.5倍的延迟惩罚，并提出了一个框架来帮助开发者作出明智的选择以避免这种情况。", "conclusion": "强调真正的数字素养不仅在于知道如何使用生成式AI，还在于知道何时不应该使用它。"}}
{"id": "2601.15127", "pdf": "https://arxiv.org/pdf/2601.15127", "abs": "https://arxiv.org/abs/2601.15127", "authors": ["Bostan Khan", "Masoud Daneshtalab"], "title": "DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search", "categories": ["cs.LG", "cs.CV", "cs.DC"], "comment": "This paper significantly extends the preliminary work accepted at ESANN 2026. Source Code: https://github.com/bostankhan6/DeepFedNAS", "summary": "Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a principled, multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS", "AI": {"tldr": "介绍DeepFedNAS框架，通过优化联邦学习中的网络架构搜索过程来提高模型设计的效率和准确性。", "motivation": "解决当前FedNAS面临的两个关键瓶颈：未指导的超网训练导致次优模型，以及耗时多小时的后训练子网发现管道。", "method": "DeepFedNAS采用两阶段框架，通过联邦帕累托最优超网训练和无预测器搜索方法来优化网络设计，并使用预计算的高适应度架构缓存作为智能课程来加速超网权重优化。", "result": "DeepFedNAS实现了最先进的精度（例如在CIFAR-100上达到1.21%绝对改进），提高了参数和通信效率，且搜索管道时间加快了约61倍，将总后训练搜索管道时间从超过20小时缩短至大约20分钟。", "conclusion": "DeepFedNAS通过其创新方法显著降低了联邦学习中的模型设计时间和成本，使其实际应用成为可能。"}}
{"id": "2601.15124", "pdf": "https://arxiv.org/pdf/2601.15124", "abs": "https://arxiv.org/abs/2601.15124", "authors": ["Haonan Yuan", "Qingyun Sun", "Jiacheng Tao", "Xingcheng Fu", "Jianxin Li"], "title": "Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by the Web Conference 2026 (Research Track)", "summary": "Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.", "AI": {"tldr": "提出RAG-GFM，一种通过检索增强生成来克服图基础模型内存瓶颈的方法。", "motivation": "现有的图基础模型受限于内存瓶颈，导致知识编码能力有限、压缩损失重且与图表示纠缠在一起，影响了模型的可扩展性和解释性。", "method": "设计了一个双模态统一检索模块和一个双视角对齐目标，通过将知识从参数中卸载并增强参数学习来缓解内存瓶颈问题。", "result": "实验表明RAG-GFM在五个基准图数据集上跨域节点分类和图分类任务中优于13个最先进的基线模型。", "conclusion": "RAG-GFM通过外部化知识存储和增强上下文证据，实现了更高的有效性和效率。"}}
{"id": "2601.15123", "pdf": "https://arxiv.org/pdf/2601.15123", "abs": "https://arxiv.org/abs/2601.15123", "authors": ["Andrey Moskalenko", "Danil Kuznetsov", "Irina Dudko", "Anastasiia Iasakova", "Nikita Boldyrev", "Denis Shepelev", "Andrei Spiridonov", "Andrey Kuznetsov", "Vlad Shakhuro"], "title": "BREPS: Bounding-Box Robustness Evaluation of Promptable Segmentation", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": "Accepted by AAAI2026", "summary": "Promptable segmentation models such as SAM have established a powerful paradigm, enabling strong generalization to unseen objects and domains with minimal user input, including points, bounding boxes, and text prompts. Among these, bounding boxes stand out as particularly effective, often outperforming points while significantly reducing annotation costs. However, current training and evaluation protocols typically rely on synthetic prompts generated through simple heuristics, offering limited insight into real-world robustness. In this paper, we investigate the robustness of promptable segmentation models to natural variations in bounding box prompts. First, we conduct a controlled user study and collect thousands of real bounding box annotations. Our analysis reveals substantial variability in segmentation quality across users for the same model and instance, indicating that SAM-like models are highly sensitive to natural prompt noise. Then, since exhaustive testing of all possible user inputs is computationally prohibitive, we reformulate robustness evaluation as a white-box optimization problem over the bounding box prompt space. We introduce BREPS, a method for generating adversarial bounding boxes that minimize or maximize segmentation error while adhering to naturalness constraints. Finally, we benchmark state-of-the-art models across 10 datasets, spanning everyday scenes to medical imaging. Code - https://github.com/emb-ai/BREPS.", "AI": {"tldr": "评估可提示分割模型在自然变化的边界框提示下的稳健性，并引入BREPS方法生成对抗性边界框。", "motivation": "当前训练和评估协议依赖于通过简单启发式方法生成的人工提示，无法充分了解真实世界的鲁棒性。因此，研究了可提示分割模型对自然变化边界框提示的鲁棒性。", "method": "首先进行了控制用户研究并收集数千个真实的边界框注释；然后将稳健性评估重新表述为一个白盒优化问题，以生成对抗性边界框，这些边界框在遵循自然约束的同时最小化或最大化分割误差。", "result": "发现SAM类模型对自然提示噪声非常敏感，并且通过BREPS方法评估了最先进的模型，在10个数据集上进行了基准测试。", "conclusion": "表明现有的可提示分割模型在面对自然边界框变化时表现不稳定，提出了BREPS来改进其鲁棒性评估。"}}
{"id": "2601.15120", "pdf": "https://arxiv.org/pdf/2601.15120", "abs": "https://arxiv.org/abs/2601.15120", "authors": ["Qian Xiong", "Yuekai Huang", "Yujia Zheng", "Tianhao Li", "Ziyou Jiang", "Zhiyuan Chang", "Zhaoyang Li", "Huanxiang Feng", "Mingyang Li"], "title": "Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories", "categories": ["cs.AI"], "comment": null, "summary": "LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of \"intent deviation\" severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to reliance on hand-crafted user requests, while the latter suffers from distribution shift from the real tools in the wild. Additionally, both methods lack negative samples tailored to intent deviation scenarios, hindering effective guidance on preference learning. We introduce RISE, a \"Real-to-Virtual\" method designed to mitigate intent deviation. Anchoring on verified tool primitives, RISE synthesizes virtual trajectories and generates diverse negative samples through mutation on critical parameters. With synthetic data, RISE fine-tunes backbone LLMs via the two-stage training for intent alignment. Evaluation results demonstrate that data synthesized by RISE achieve promising results in eight metrics covering user requires, execution trajectories and agent responses. Integrating with training, RISE achieves an average 35.28% improvement in Acctask (task completion) and 23.27% in Accintent (intent alignment), outperforming SOTA baselines by 1.20--42.09% and 1.17--54.93% respectively.", "AI": {"tldr": "本文介绍了RISE方法，旨在通过将真实调用转化为虚拟轨迹来解决工具使用代理中的意图偏差问题。", "motivation": "LLM引导的工具使用代理在实际应用中表现出意外行为或结果，尤其是“意图偏离”严重影响了可靠评估和性能改进。现有训练后的方法存在成本高或分布偏移的问题，并且缺乏针对意图偏离场景的负样本，阻碍了偏好学习的有效指导。", "method": "RISE方法基于验证过的工具原语合成虚拟轨迹并通过关键参数突变生成多样化的负面样本。使用合成数据对骨干LLM进行两个阶段训练以实现意图对齐。", "result": "评估结果显示RISE在八个指标上取得了良好效果，包括用户需求、执行轨迹和代理响应，并且在任务完成（Acctask）方面平均提高了35.28%，在意图对齐（Accintent）方面平均提高了23.27%。", "conclusion": "RISE通过合成数据有效改善了工具使用代理的意图偏差，显著优于现有方法。"}}
{"id": "2601.15119", "pdf": "https://arxiv.org/pdf/2601.15119", "abs": "https://arxiv.org/abs/2601.15119", "authors": ["Md Mahmudul Hoque", "Md Mehedi Hassain", "Muntakimur Rahaman", "Md. Towhidul Islam", "Shaista Rani", "Md Sharif Mollah"], "title": "Vision Models for Medical Imaging: A Hybrid Approach for PCOS Detection from Ultrasound Scans", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Polycystic Ovary Syndrome (PCOS) is the most familiar endocrine illness in women of reproductive age. Many Bangladeshi women suffer from PCOS disease in their older age. The aim of our research is to identify effective vision-based medical image analysis techniques and evaluate hybrid models for the accurate detection of PCOS. We introduced two novel hybrid models combining convolutional and transformer-based approaches. The training and testing data were organized into two categories: \"infected\" (PCOS-positive) and \"noninfected\" (healthy ovaries). In the initial stage, our first hybrid model, 'DenConST' (integrating DenseNet121, Swin Transformer, and ConvNeXt), achieved 85.69% accuracy. The final optimized model, 'DenConREST' (incorporating Swin Transformer, ConvNeXt, DenseNet121, ResNet18, and EfficientNetV2), demonstrated superior performance with 98.23% accuracy. Among all evaluated models, DenConREST showed the best performance. This research highlights an efficient solution for PCOS detection from ultrasound images, significantly improving diagnostic accuracy while reducing detection errors.", "AI": {"tldr": "本文探讨了基于视觉的医疗图像分析技术，并评估了一种用于准确检测多囊卵巢综合征（PCOS）的混合模型。", "motivation": "研究旨在为识别有效的基于视觉的医学影像分析方法，提高PCOS检测准确性，减少误诊率。", "method": "引入了两个新的混合模型结合卷积和变换器方法：DenConST整合DenseNet121、Swin Transformer及ConvNeXt；DenConREST融合Swin Transformer、ConvNeXt、DenseNet121、ResNet18和EfficientNetV2。", "result": "初步模型DenConST达到了85.69%的准确率，最终优化模型DenConREST达到了98.23%的准确率，展现了最佳性能。", "conclusion": "研究提出了一种高效解决PCOS检测问题的方法，显著提高了诊断准确性。"}}
{"id": "2601.15118", "pdf": "https://arxiv.org/pdf/2601.15118", "abs": "https://arxiv.org/abs/2601.15118", "authors": ["Gokul Karthik Kumar", "Ludovick Lepauloux", "Hakim Hacid"], "title": "WavLink: Compact Audio--Text Embeddings with a Global Whisper Token", "categories": ["cs.SD", "cs.CL", "cs.LG"], "comment": "Accepted at ICASSP 2026", "summary": "Whisper has become the de-facto encoder for extracting general-purpose audio features in large audio-language models, where a 30-second clip is typically represented by 1500 frame features projected into an LLM. In contrast, audio-text embedding models like CLAP-based models have largely relied on alternative audio encoders (e.g., HTS-AT, PaSST), and have not leveraged Whisper effectively. We present WavLink, a compact audio-text embedding model that augments Whisper encoder with a learnable global token, trained jointly with a text encoder. Through a systematic study of design choices, including pretrained text encoders, loss functions, training modes, and data mixtures, we identify configurations that yield state-of-the-art retrieval performance. Our two-stage training recipe across three model sizes, combined with Matryoshka-style supervision, improves scalability, enabling 8x smaller embeddings with minimal performance drop. WavLink also demonstrates competitive performance on AIR-Bench with MCQs and zero-shot classification.", "AI": {"tldr": "WavLink 提出了一种紧凑的音频-文本嵌入模型，通过在Whisper编码器中添加一个可学习的全局令牌，并结合文本编码器进行联合训练。", "motivation": "Whisper虽然成为了提取通用音频特征的主要编码器，但尚未被有效的用于音频-文本嵌入模型。因此，WavLink旨在改进这一不足，并提升音频检索性能。", "method": "通过系统性研究设计选择（如预训练文本编码器、损失函数、训练模式和数据混合），提出了一种结合两阶段训练方法与套娃式监督的方案来优化模型。", "result": "WavLink能够在保持高性能的同时，实现8倍更小的嵌入尺寸。在AIR-Bench上，它也表现出与多选题及零样本分类相关的竞争力。", "conclusion": "通过添加可学习的全局令牌并结合预训练文本编码器进行联合训练，WavLink证明了其在音频-文本嵌入领域的优越性能和效率提升。"}}
{"id": "2601.15115", "pdf": "https://arxiv.org/pdf/2601.15115", "abs": "https://arxiv.org/abs/2601.15115", "authors": ["Shuonan Yang", "Yuchen Zhang", "Zeyu Fu"], "title": "Training-Free and Interpretable Hateful Video Detection via Multi-stage Adversarial Reasoning", "categories": ["cs.CV"], "comment": "Accepted at ICASSP 2026. \\c{opyright} 2026 IEEE. This is the author accepted manuscript. The final published version will be available via IEEE Xplore", "summary": "Hateful videos pose serious risks by amplifying discrimination, inciting violence, and undermining online safety. Existing training-based hateful video detection methods are constrained by limited training data and lack of interpretability, while directly prompting large vision-language models often struggle to deliver reliable hate detection. To address these challenges, this paper introduces MARS, a training-free Multi-stage Adversarial ReaSoning framework that enables reliable and interpretable hateful content detection. MARS begins with the objective description of video content, establishing a neutral foundation for subsequent analysis. Building on this, it develops evidence-based reasoning that supports potential hateful interpretations, while in parallel incorporating counter-evidence reasoning to capture plausible non-hateful perspectives. Finally, these perspectives are synthesized into a conclusive and explainable decision. Extensive evaluation on two real-world datasets shows that MARS achieves up to 10% improvement under certain backbones and settings compared to other training-free approaches and outperforms state-of-the-art training-based methods on one dataset. In addition, MARS produces human-understandable justifications, thereby supporting compliance oversight and enhancing the transparency of content moderation workflows. The code is available at https://github.com/Multimodal-Intelligence-Lab-MIL/MARS.", "AI": {"tldr": "本文提出了MARS，一种无需训练的多阶段对抗推理框架，用于可靠且可解释的仇恨视频检测。", "motivation": "现有的基于训练的方法受制于有限的数据和缺乏可解释性，而直接提示大型视觉语言模型往往无法提供可靠的仇恨内容检测。因此，需要一个不需要训练、可靠且透明的解决方案来识别仇恨视频。", "method": "MARS通过多阶段对抗推理实现，首先客观描述视频内容作为分析的基础，然后基于证据支持潜在的仇恨解释，并同时考虑非仇恨观点，最终合成成具有可解释性的决策。", "result": "在两个真实数据集上的评估表明，与现有的无训练方法相比，MARS能够提高多达10%的表现，在一个数据集中甚至超过了最先进的基于训练的方法。此外，它还提供了人类可以理解的解释。", "conclusion": "MARS是一种有效的无需训练、可解释且可靠的仇恨视频检测框架，提高了内容审核流程的透明度和合规监督的支持。"}}
{"id": "2601.15111", "pdf": "https://arxiv.org/pdf/2601.15111", "abs": "https://arxiv.org/abs/2601.15111", "authors": ["Anmol Goel", "Alan Ritter", "Iryna Gurevych"], "title": "Auditing Language Model Unlearning via Information Decomposition", "categories": ["cs.LG", "cs.AI"], "comment": "EACL 2026 Main", "summary": "We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.", "AI": {"tldr": "本文揭示了当前语言模型未学习方法的局限性，并提出了一种基于信息分解的审计框架来评估和量化这些遗留知识。", "motivation": "动机在于发现尽管存在成功的未学习算法，但遗忘数据的信息仍然可以从内部表示中线性解码出来，这可能导致隐私泄露问题。", "method": "引入了部分信息分解（PID）理论框架，通过比较模型在未学习前后的表示来量化和分类与遗忘数据相关的互信息，并提出了基于表征的风险评分机制以指导敏感输入的预测抑制。", "result": "揭示了冗余信息是残留在未学习过程中的知识来源，这些信息关联于已知的对抗性重构攻击的易感性，提出的风险评分工具能够减轻隐私泄漏的风险。", "conclusion": "本研究提供了一个原则性的表征水平审计框架，为语言模型的安全部署提供了理论见解和实用工具。"}}
{"id": "2601.15110", "pdf": "https://arxiv.org/pdf/2601.15110", "abs": "https://arxiv.org/abs/2601.15110", "authors": ["Aoran Liu", "Kun Hu", "Clinton Ansun Mo", "Qiuxia Wu", "Wenxiong Kang", "Zhiyong Wang"], "title": "Pb4U-GNet: Resolution-Adaptive Garment Simulation via Propagation-before-Update Graph Network", "categories": ["cs.CV"], "comment": "Camera-ready version accepted at AAAI 2026", "summary": "Garment simulation is fundamental to various applications in computer vision and graphics, from virtual try-on to digital human modelling. However, conventional physics-based methods remain computationally expensive, hindering their application in time-sensitive scenarios. While graph neural networks (GNNs) offer promising acceleration, existing approaches exhibit poor cross-resolution generalisation, demonstrating significant performance degradation on higher-resolution meshes beyond the training distribution. This stems from two key factors: (1) existing GNNs employ fixed message-passing depth that fails to adapt information aggregation to mesh density variation, and (2) vertex-wise displacement magnitudes are inherently resolution-dependent in garment simulation. To address these issues, we introduce Propagation-before-Update Graph Network (Pb4U-GNet), a resolution-adaptive framework that decouples message propagation from feature updates. Pb4U-GNet incorporates two key mechanisms: (1) dynamic propagation depth control, adjusting message-passing iterations based on mesh resolution, and (2) geometry-aware update scaling, which scales predictions according to local mesh characteristics. Extensive experiments show that even trained solely on low-resolution meshes, Pb4U-GNet exhibits strong generalisability across diverse mesh resolutions, addressing a fundamental challenge in neural garment simulation.", "AI": {"tldr": "本文提出了一种名为Pb4U-GNet的自适应分辨率服装模拟框架，通过解耦消息传递和特征更新，解决了现有图神经网络在跨分辨率泛化时性能下降的问题。", "motivation": "现有的基于物理的方法计算成本高，限制了其在时间敏感场景中的应用；虽然图神经网络提供了加速可能，但现有方法的跨分辨率泛化能力差。", "method": "Pb4U-GNet包括两个关键机制：动态传播深度控制和几何感知更新缩放。前者根据网格分辨率调整消息传递迭代次数，后者根据局部网格特性缩放预测结果。", "result": "实验表明，即使仅在低分辨率网格上训练，Pb4U-GNet也能在多种网格分辨率下表现出良好的泛化能力。", "conclusion": "该研究解决了神经服装模拟中的根本挑战之一，即跨分辨率的性能下降问题。"}}
{"id": "2601.15109", "pdf": "https://arxiv.org/pdf/2601.15109", "abs": "https://arxiv.org/abs/2601.15109", "authors": ["Kevin Tseng", "Juan Carlos Toledano", "Bart De Clerck", "Yuliia Dukach", "Phil Tinn"], "title": "An Agentic Operationalization of DISARM for FIMI Investigation on Social Media", "categories": ["cs.SI", "cs.AI", "cs.CY", "cs.HC", "cs.MA"], "comment": ":I.2.11; J.7; I.5.5", "summary": "The interoperability of data and intelligence across allied partners and their respective end-user groups is considered a foundational enabler to the collective defense capability--both conventional and hybrid--of NATO countries. Foreign Information Manipulation and Interference (FIMI) and related hybrid activities are conducted across various societal dimensions and infospheres, posing an ever greater challenge to the characterization of threats, sustaining situational awareness, and response coordination. Recent advances in AI have further led to the decreasing cost of AI-augmented trolling and interference activities, such as through the generation and amplification of manipulative content. Despite the introduction of the DISARM framework as a standardized metadata and analytical framework for FIMI, operationalizing it at the scale of social media remains a challenge. We propose a framework-agnostic agent-based operationalization of DISARM to investigate FIMI on social media. We develop a multi-agent pipeline in which specialized agentic AI components collaboratively (1) detect candidate manipulative behaviors, and (2) map these behaviors onto standard DISARM taxonomies in a transparent manner. We evaluated the approach on two real-world datasets annotated by domain practitioners. We demonstrate that our approach is effective in scaling the predominantly manual and heavily interpretive work of FIMI analysis, providing a direct contribution to enhancing the situational awareness and data interoperability in the context of operating in media and information-rich settings.", "AI": {"tldr": "本文提出了一个基于代理的DISARM操作框架，用于在社交媒体上调查外国信息操纵和干扰活动。", "motivation": "虽然引入了DISARM框架作为标准化元数据和分析框架来处理FIMI，但将其应用于社交媒体规模的操作仍然存在挑战。因此，提出了一种框架无关的代理基础方法来解决这一问题。", "method": "开发了一个多代理管道，在该管道中，专门化的代理人AI组件协作完成任务：检测候选操纵行为，并将这些行为映射到标准DISARM分类体系上，以透明的方式进行操作。", "result": "在两个由领域专家标注的真实世界数据集上的评估表明，这种方法有效地扩展了FIMI分析的大部分手动和高度解释性工作。", "conclusion": "该方法为增强媒体和信息丰富的环境中的态势感知和数据互操作性直接做出了贡献。"}}
{"id": "2601.15102", "pdf": "https://arxiv.org/pdf/2601.15102", "abs": "https://arxiv.org/abs/2601.15102", "authors": ["Johannes Meuer", "Maximilian Witte", "Étiénne Plésiat", "Thomas Ludwig", "Christopher Kadow"], "title": "Field-Space Autoencoder for Scalable Climate Emulators", "categories": ["cs.LG", "eess.IV"], "comment": null, "summary": "Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail.", "AI": {"tldr": "本文提出了Field-Space Autoencoder，一种基于球形压缩模型的可扩展气候模拟框架，用于克服高分辨率地球系统模型计算成本高昂的问题。", "motivation": "现有的高分辨率地球系统模型因计算成本高昂和产生大量数据而难以应用于概率风险评估等应用，因此需要一个更高效且准确的气候模拟方法。", "method": "该论文使用Field-Space Autoencoder，结合Field-Space Attention技术对原生气候模型输出进行处理，避免了将球形数据强加到欧几里得网格上的几何失真问题，并训练生成扩散模型在压缩字段上学习内部变异性及细粒度物理特性。", "result": "该方法能够有效保存物理结构，并通过零样本超分辨率映射低分辨率大量集合和稀疏高分辨率数据，以同时从丰富低分辨率数据中学习内部变异性和从稀缺高分辨率数据中获取细节的物理信息。", "conclusion": "Field-Space Autoencoder提供了一种高效的气候模拟方法，它能够克服现有模型的数据处理瓶颈，并为下游生成性模仿提供了良好基础。"}}
{"id": "2601.15100", "pdf": "https://arxiv.org/pdf/2601.15100", "abs": "https://arxiv.org/abs/2601.15100", "authors": ["Yanwei Huang", "Arpit Narechania"], "title": "Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek", "categories": ["cs.HC"], "comment": "Accepted by ACM CHI 2026", "summary": "Web AI agents such as ChatGPT Agent and GenSpark are increasingly used for routine web-based tasks, yet they still rely on text-based input prompts, lack proactive detection of user intent, and offer no support for interactive data analysis and decision making. We present WebSeek, a mixed-initiative browser extension that enables users to discover and extract information from webpages to then flexibly build, transform, and refine tangible data artifacts-such as tables, lists, and visualizations-all within an interactive canvas. Within this environment, users can perform analysis-including data transformations such as joining tables or creating visualizations-while an in-built AI both proactively offers context-aware guidance and automation, and reactively responds to explicit user requests. An exploratory user study (N=15) with WebSeek as a probe reveals participants' diverse analysis strategies, underscoring their desire for transparency and control during human-AI collaboration.", "AI": {"tldr": "本文介绍了WebSeek，一个混合主动性的浏览器扩展程序，帮助用户发现和提取网页信息，并在交互式画布中灵活构建、转换和优化数据成果。", "motivation": "现有的网络AI代理依赖文本输入提示，缺乏对用户意图的主动检测，并且不支持互动数据分析和决策制定，因此开发了WebSeek来弥补这些不足。", "method": "通过设计一个浏览器扩展程序WebSeek，该程序包含内置AI，能够主动提供情境感知指导和自动化，并响应用户的明确请求。进行了一项探索性用户研究（N=15），使用WebSeek作为探测工具。", "result": "研究揭示了参与者多样的分析策略，强调了他们在人类-AI协作中对透明度和控制的需求。", "conclusion": "WebSeek通过主动性和反应性的引导支持决策制定，并且用户研究表明人们希望在AI合作过程中保持透明和控制。"}}
{"id": "2601.15098", "pdf": "https://arxiv.org/pdf/2601.15098", "abs": "https://arxiv.org/abs/2601.15098", "authors": ["Yipeng Yin", "Rao Yao", "Qingying Li", "Dazhong Wang", "Hong Zhou", "Zhijun Fang", "Jianing Chen", "Longjie Qian", "Mingyue Wu"], "title": "Three-dimensional visualization of X-ray micro-CT with large-scale datasets: Efficiency and accuracy for real-time interaction", "categories": ["cs.CV"], "comment": "Page1-37", "summary": "As Micro-CT technology continues to refine its characterization of material microstructures, industrial CT ultra-precision inspection is generating increasingly large datasets, necessitating solutions to the trade-off between accuracy and efficiency in the 3D characterization of defects during ultra-precise detection. This article provides a unique perspective on recent advances in accurate and efficient 3D visualization using Micro-CT, tracing its evolution from medical imaging to industrial non-destructive testing (NDT). Among the numerous CT reconstruction and volume rendering methods, this article selectively reviews and analyzes approaches that balance accuracy and efficiency, offering a comprehensive analysis to help researchers quickly grasp highly efficient and accurate 3D reconstruction methods for microscopic features. By comparing the principles of computed tomography with advancements in microstructural technology, this article examines the evolution of CT reconstruction algorithms from analytical methods to deep learning techniques, as well as improvements in volume rendering algorithms, acceleration, and data reduction. Additionally, it explores advanced lighting models for high-accuracy, photorealistic, and efficient volume rendering. Furthermore, this article envisions potential directions in CT reconstruction and volume rendering. It aims to guide future research in quickly selecting efficient and precise methods and developing new ideas and approaches for real-time online monitoring of internal material defects through virtual-physical interaction, for applying digital twin model to structural health monitoring (SHM).", "AI": {"tldr": "本文探讨了X射线微CT技术在大规模数据集三维可视化中的效率和准确性问题，特别是在超精检测中的缺陷实时交互。", "motivation": "随着Micro-CT技术的发展，工业CT产生的大型数据集对准确性和效率的平衡提出了更高的要求，需要更好的解决方案来支持实时互动和高精度的3D缺陷表征。", "method": "本文回顾并分析了多种CT重建和体积渲染方法，特别关注能够实现高效与精确三维重建的方法，并比较计算断层扫描原理及其在微结构技术上的进步。", "result": "通过对不同算法和技术发展的综述，文章提供了一个全面的视角来快速掌握高效的3D重建方法，并探讨了先进的光照模型以支持高质量且效率高的体积渲染。", "conclusion": "本文展望了CT重建和体积渲染的未来发展方向，并鼓励进一步研究实时在线监测内部材料缺陷的方法及新技术发展，为结构健康监测的应用提供指导。"}}
{"id": "2601.15097", "pdf": "https://arxiv.org/pdf/2601.15097", "abs": "https://arxiv.org/abs/2601.15097", "authors": ["Johanna Wilroth", "Oskar Keding", "Martin A. Skoglund", "Maria Sandsten", "Martin Enqvist", "Emina Alickovic"], "title": "Neural Tracking of Sustained Attention, Attention Switching, and Natural Conversation in Audiovisual Environments using Mobile EEG", "categories": ["eess.SP", "cs.SD", "eess.AS"], "comment": "Submitted to European Journal of Neuroscience", "summary": "Everyday communication is dynamic and multisensory, often involving shifting attention, overlapping speech and visual cues. Yet, most neural attention tracking studies are still limited to highly controlled lab settings, using clean, often audio-only stimuli and requiring sustained attention to a single talker. This work addresses that gap by introducing a novel dataset from 24 normal-hearing participants. We used a mobile electroencephalography (EEG) system (44 scalp electrodes and 20 cEEGrid electrodes) in an audiovisual (AV) paradigm with three conditions: sustained attention to a single talker in a two-talker environment, attention switching between two talkers, and unscripted two-talker conversations with a competing single talker. Analysis included temporal response functions (TRFs) modeling, optimal lag analysis, selective attention classification with decision windows ranging from 1.1s to 35s, and comparisons of TRFs for attention to AV conversations versus side audio-only talkers. Key findings show significant differences in the attention-related P2-peak between attended and ignored speech across conditions for scalp EEG. No significant change in performance between switching and sustained attention suggests robustness for attention switches. Optimal lag analysis revealed narrower peak for conversation compared to single-talker AV stimuli, reflecting the additional complexity of multi-talker processing. Classification of selective attention was consistently above chance (55-70% accuracy) for scalp EEG, while cEEGrid data yielded lower correlations, highlighting the need for further methodological improvements. These results demonstrate that mobile EEG can reliably track selective attention in dynamic, multisensory listening scenarios and provide guidance for designing future AV paradigms and real-world attention tracking applications.", "AI": {"tldr": "使用移动EEG系统在视听环境中跟踪持续注意力、注意力切换和自然对话。", "motivation": "现有神经注意追踪研究大多局限于高度控制的实验室环境，缺乏对动态多感官交流的研究。", "method": "通过24名正常听力参与者的数据集，采用移动EEG系统（包括44个头皮电极和20个cEEGrid电极），在视听模式下进行三种条件下的测试：单一说话者持续注意力、注意力切换和未编排的两人对话。使用了TRF建模、最优滞后分析和决策窗口分类。", "result": "发现显著差异在于注意力相关的P2峰值，在头皮EEG中对不同说话者的注意与忽略之间存在显著差异，且在注意力切换条件下表现稳健。分类准确率在55-70%以上，展示了移动EEG在动态多感官听力场景中的可靠性。", "conclusion": "结果表明，移动EEG可以在动态、多感官的听觉环境中可靠地追踪选择性注意，并为设计未来的视听范式和现实世界的注意力跟踪应用提供指导。"}}
{"id": "2601.15086", "pdf": "https://arxiv.org/pdf/2601.15086", "abs": "https://arxiv.org/abs/2601.15086", "authors": ["Oleg Shchendrigin", "Egor Cherepanov", "Alexey K. Kovalev", "Aleksandr I. Panov"], "title": "Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 6 figures, 7 tables", "summary": "Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critical ability of memory rewriting largely unexplored. To address this gap, we introduce a benchmark that explicitly tests continual memory updating under partial observability, i.e. the natural setting where an agent must rely on memory rather than current observations, and use it to compare recurrent, transformer-based, and structured memory architectures. Our experiments reveal that classic recurrent models, despite their simplicity, demonstrate greater flexibility and robustness in memory rewriting tasks than modern structured memories, which succeed only under narrow conditions, and transformer-based agents, which often fail beyond trivial retention cases. These findings expose a fundamental limitation of current approaches and emphasize the necessity of memory mechanisms that balance stable retention with adaptive updating. Our work highlights this overlooked challenge, introduces benchmarks to evaluate it, and offers insights for designing future RL agents with explicit and trainable forgetting mechanisms. Code: https://quartz-admirer.github.io/Memory-Rewriting/", "AI": {"tldr": "本文提出了一个基准测试，用于评估在部分可观察环境中记忆更新的能力，并比较了经典递归模型、基于变压器的模型和结构化记忆模型的表现。", "motivation": "现有的强化学习基准主要关注记忆力的保持，而忽略了记忆重写的同样重要性。为了填补这一空白，研究者们提出了一个新的基准测试来评估持续的记忆更新能力。", "method": "引入了一个新的基准测试环境，用于比较不同类型的内存架构（包括经典递归模型、基于变压器和结构化记忆）在处理部分可观测环境中记忆重写任务的能力。", "result": "实验结果显示，尽管简单但传统的递归模型展现了更好的适应性和鲁棒性；而现代的结构化记忆和基于变压器的模型仅在特定条件下成功，其他情况下表现不佳。", "conclusion": "研究揭示了当前方法的记忆更新能力的局限，并强调需要平衡稳定保持与灵活更新机制的设计。该工作还为未来开发具有明确可训练遗忘机制的强化学习代理提供了启示和测试基准。"}}
{"id": "2601.15083", "pdf": "https://arxiv.org/pdf/2601.15083", "abs": "https://arxiv.org/abs/2601.15083", "authors": ["Muntakimur Rahaman", "Md Mahmudul Hoque", "Md Mehedi Hassain"], "title": "Bangla Music Genre Classification Using Bidirectional LSTMS", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Bangla music is enrich in its own music cultures. Now a days music genre classification is very significant because of the exponential increase in available music, both in digital and physical formats. It is necessary to index them accordingly to facilitate improved retrieval. Automatically classifying Bangla music by genre is essential for efficiently locating specific pieces within a vast and diverse music library. Prevailing methods for genre classification predominantly employ conventional machine learning or deep learning approaches. This work introduces a novel music dataset comprising ten distinct genres of Bangla music. For the task of audio classification, we utilize a recurrent neural network (RNN) architecture. Specifically, a Long Short-Term Memory (LSTM) network is implemented to train the model and perform the classification. Feature extraction represents a foundational stage in audio data processing. This study utilizes Mel-Frequency Cepstral Coefficients (MFCCs) to transform raw audio waveforms into a compact and representative set of features. The proposed framework facilitates music genre classification by leveraging these extracted features. Experimental results demonstrate a classification accuracy of 78%, indicating the system's strong potential to enhance and streamline the organization of Bangla music genres.", "AI": {"tldr": "本文提出了使用双向LSTM进行孟加拉语音乐流派分类的方法。", "motivation": "随着可用音乐数量的急剧增加，自动分类孟加拉语音乐对于有效地定位特定作品至关重要，并可改善检索。", "method": "利用包含十个不同孟加拉音乐流派的新数据集，通过Mel频率倒谱系数提取特征并使用双向LSTM网络进行训练和分类。", "result": "实验结果展示了78%的分类准确率，证明了该系统在组织孟加拉语音乐流派方面的潜力。", "conclusion": "研究表明采用双向LSTM模型对孟加拉音乐进行自动分类是有效且有潜力的方法。"}}
{"id": "2601.15077", "pdf": "https://arxiv.org/pdf/2601.15077", "abs": "https://arxiv.org/abs/2601.15077", "authors": ["Christopher Scofield"], "title": "Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MAS implements a factorized composition of constraint-enforcement operators. Under mild conditions, these dynamics converge to invariant solution sets defined by the intersection of agent constraint sets. Such invariant structures are generally not dynamically accessible to a single agent applying all constraints simultaneously, even when expressive capacity and information are identical. We extend this result from exact constraint enforcement to soft constraints via proximal operators, and apply the formalism to contemporary text-based dialog systems.", "AI": {"tldr": "本文通过算子理论和约束优化，解释了多智能体系统如何通过分解约束来实现优于单一代理的解决问题性能。", "motivation": "研究旨在解释为什么由大型语言模型组成的多智能体系统在处理相同信息时能表现出更好的问题解决能力。", "method": "每个智能体被建模为对共享解决方案状态实施不同的有效性约束，展示了一个多智能体系统的约束执行算子的分解组成，并将结果从精确约束扩展到通过近似算子实现的软约束。", "result": "研究发现，这些动态过程收敛于由代理约束集交集定义的不变解集，这种结构通常无法通过单一代理同时应用所有约束来访问。", "conclusion": "该形式主义被应用于现代文本对话系统，揭示了多智能体系统中的潜在不变解决方案结构及其优势。"}}
{"id": "2601.15075", "pdf": "https://arxiv.org/pdf/2601.15075", "abs": "https://arxiv.org/abs/2601.15075", "authors": ["Chen Qian", "Peng Wang", "Dongrui Liu", "Junyao Yang", "Dadi Guo", "Ling Tang", "Jilin Mei", "Qihan Ren", "Shuai Shao", "Yong Liu", "Jie Fu", "Jing Shao", "Xia Hu"], "title": "The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \\textit{failure attribution} to localize explicit errors in unsuccessful trajectories, which is insufficient for explaining the reasoning behind agent behaviors. To bridge this gap, we propose a novel framework for \\textbf{general agentic attribution}, designed to identify the internal factors driving agent actions regardless of the task outcome. Our framework operates hierarchically to manage the complexity of agent interactions. Specifically, at the \\textit{component level}, we employ temporal likelihood dynamics to identify critical interaction steps; then at the \\textit{sentence level}, we refine this localization using perturbation-based analysis to isolate the specific textual evidence. We validate our framework across a diverse suite of agentic scenarios, including standard tool use and subtle reliability risks like memory-induced bias. Experimental results demonstrate that the proposed framework reliably pinpoints pivotal historical events and sentences behind the agent behavior, offering a critical step toward safer and more accountable agentic systems.", "AI": {"tldr": "本文提出了一种新的框架，用于识别代理行为背后的内部驱动因素。", "motivation": "随着基于大型语言模型的代理在实际应用中变得越来越自主，理解代理采取特定行动的原因变得愈发重要。现有研究主要集中在失败归因上，这不足以解释代理的行为理由。", "method": "该框架采用分层方式运作，在组件级别使用时间似然动态来识别关键交互步骤；然后在句子级别通过基于扰动的分析细化定位，以隔离具体的文本证据。", "result": "实验结果表明，提出的框架能够可靠地识别出影响代理行为的关键历史事件和句子。", "conclusion": "该研究为实现更安全、更有问责性的代理系统迈出了重要一步。"}}
{"id": "2601.15071", "pdf": "https://arxiv.org/pdf/2601.15071", "abs": "https://arxiv.org/abs/2601.15071", "authors": ["Jingyang Huo", "Yikai Wang", "Yanwei Fu", "Jianfeng Feng"], "title": "The Pictorial Cortex: Zero-Shot Cross-Subject fMRI-to-Image Reconstruction via Compositional Latent Modeling", "categories": ["cs.CV"], "comment": null, "summary": "Decoding visual experiences from human brain activity remains a central challenge at the intersection of neuroscience, neuroimaging, and artificial intelligence. A critical obstacle is the inherent variability of cortical responses: neural activity elicited by the same visual stimulus differs across individuals and trials due to anatomical, functional, cognitive, and experimental factors, making fMRI-to-image reconstruction non-injective. In this paper, we tackle a challenging yet practically meaningful problem: zero-shot cross-subject fMRI-to-image reconstruction, where the visual experience of a previously unseen individual must be reconstructed without subject-specific training. To enable principled evaluation, we present a unified cortical-surface dataset -- UniCortex-fMRI, assembled from multiple visual-stimulus fMRI datasets to provide broad coverage of subjects and stimuli. Our UniCortex-fMRI is particularly processed by standardized data formats to make it possible to explore this possibility in the zero-shot scenario of cross-subject fMRI-to-image reconstruction. To tackle the modeling challenge, we propose PictorialCortex, which models fMRI activity using a compositional latent formulation that structures stimulus-driven representations under subject-, dataset-, and trial-related variability. PictorialCortex operates in a universal cortical latent space and implements this formulation through a latent factorization--composition module, reinforced by paired factorization and re-factorizing consistency regularization. During inference, surrogate latents synthesized under multiple seen-subject conditions are aggregated to guide diffusion-based image synthesis for unseen subjects. Extensive experiments show that PictorialCortex improves zero-shot cross-subject visual reconstruction, highlighting the benefits of compositional latent modeling and multi-dataset training.", "AI": {"tldr": "本文提出了PictorialCortex方法，用于零样本跨个体fMRI到图像的重建任务。", "motivation": "解码人类大脑活动中的视觉体验是神经科学、神经影像学和人工智能交叉领域的核心挑战之一。现有技术难以克服不同个体间皮层响应差异带来的障碍，本文旨在解决这一问题。", "method": "作者提出了PictorialCortex模型，通过组合潜在建模方式，在统一的脑皮质潜在空间中处理fMRI活动，并结合扩散生成图像合成方法。", "result": "实验表明，PictorialCortex在零样本跨个体视觉重建方面表现优异，证明了组合潜变量建模和多数据集训练的优势。", "conclusion": "研究强调了组合潜在模型对于克服皮层响应变异性和实现准确的fMRI到图像重建的重要性，并展示了其在零样本场景中的应用潜力。"}}
{"id": "2601.15069", "pdf": "https://arxiv.org/pdf/2601.15069", "abs": "https://arxiv.org/abs/2601.15069", "authors": ["Yanran Jiang", "Pavan Sikka", "Leimin Tian", "Dana Kuliic", "Cecile Paris"], "title": "Influence of Operator Expertise on Robot Supervision and Intervention", "categories": ["cs.RO"], "comment": null, "summary": "With increasing levels of robot autonomy, robots are increasingly being supervised by users with varying levels of robotics expertise. As the diversity of the user population increases, it is important to understand how users with different expertise levels approach the supervision task and how this impacts performance of the human-robot team. This exploratory study investigates how operators with varying expertise levels perceive information and make intervention decisions when supervising a remote robot. We conducted a user study (N=27) where participants supervised a robot autonomously exploring four unknown tunnel environments in a simulator, and provided waypoints to intervene when they believed the robot had encountered difficulties. By analyzing the interaction data and questionnaire responses, we identify differing patterns in intervention timing and decision-making strategies across novice, intermediate, and expert users.", "AI": {"tldr": "研究探讨了不同操作员专业知识水平对远程机器人监督和干预的影响。", "motivation": "随着机器人自主性的提高，需要理解具有不同专业背景的用户如何进行监督任务及其对人机团队表现的影响。", "method": "进行了一个包含27名参与者的用户研究，参与者在模拟器中监督机器人探索未知隧道环境，并在认为机器人遇到困难时提供干预点。", "result": "通过分析交互数据和问卷回答，识别了新手、中级和专家用户在干预时间和决策策略上的不同模式。", "conclusion": "研究表明操作员的专业知识水平显著影响其对信息的感知和干预决策。"}}
{"id": "2601.15068", "pdf": "https://arxiv.org/pdf/2601.15068", "abs": "https://arxiv.org/abs/2601.15068", "authors": ["Danny Segev"], "title": "Economic Warehouse Lot Scheduling: Breaking the 2-Approximation Barrier", "categories": ["cs.DS", "math.OC"], "comment": null, "summary": "The economic warehouse lot scheduling problem is a foundational inventory-theory model, capturing computational challenges in dynamically coordinating replenishment decisions for multiple commodities subject to a shared capacity constraint. Even though this model has generated a vast body of literature over the last six decades, our algorithmic understanding has remained surprisingly limited. Indeed, for general problem instances, the best-known approximation guarantees have remained at a factor of $2$ since the mid-1990s. These guarantees were attained by the now-classic work of Anily [Operations Research, 1991] and Gallego, Queyranne, and Simchi-Levi [Operations Research, 1996] via the highly-structured class of \"stationary order sizes and stationary intervals\" (SOSI) policies, thereby avoiding direct competition against fully dynamic policies. The main contribution of this paper resides in developing new analytical foundations and algorithmic techniques that enable such direct comparisons, leading to the first provable improvement over the $2$-approximation barrier. Leveraging these ideas, we design a constructive approach that allows us to balance cost and capacity at a finer granularity than previously possible via SOSI-based methods. Consequently, given any economic warehouse lot scheduling instance, we present a polynomial-time construction of a random capacity-feasible dynamic policy whose expected long-run average cost is within factor $2-\\frac{17}{5000} + ε$ of optimal.", "AI": {"tldr": "本文提出了新的分析基础和算法技术，以打破经济仓库批量调度问题中的2近似界限。", "motivation": "尽管该模型在过去六十年中产生了大量的文献，但对于一般问题实例的最接近优化解的近似保证仍然停留在1990年代中期的2倍近似率上。作者希望通过改进这一瓶颈，提供更精确的库存调度策略。", "method": "通过开发新的分析基础和算法技术，直接比较成本与容量，提出了一个构造性方法，在比SOSI政策更细粒度地平衡成本和容量方面取得进展。", "result": "设计出了一种在多项式时间内构建随机容量可行动态策略的方法，该策略的预期长期平均成本优于2倍近似率，达到2 - 17/5000 + ε接近最优解。", "conclusion": "本文通过新开发的技术打破了2倍近似界限，并展示了如何实现更细粒度的成本和容量平衡，进而提高了经济仓库批量调度问题的算法理解。"}}
{"id": "2601.15065", "pdf": "https://arxiv.org/pdf/2601.15065", "abs": "https://arxiv.org/abs/2601.15065", "authors": ["Tianyu Li", "Songyue Cai", "Zongqian Wu", "Ping Hu", "Xiaofeng Zhu"], "title": "Enhancing Few-Shot Out-of-Distribution Detection via the Refinement of Foreground and Background", "categories": ["cs.CV"], "comment": null, "summary": "CLIP-based foreground-background (FG-BG) decomposition methods have demonstrated remarkable effectiveness in improving few-shot out-of-distribution (OOD) detection performance. However, existing approaches still suffer from several limitations. For background regions obtained from decomposition, existing methods adopt a uniform suppression strategy for all patches, overlooking the varying contributions of different patches to the prediction. For foreground regions, existing methods fail to adequately consider that some local patches may exhibit appearance or semantic similarity to other classes, which may mislead the training process. To address these issues, we propose a new plug-and-play framework. This framework consists of three core components: (1) a Foreground-Background Decomposition module, which follows previous FG-BG methods to separate an image into foreground and background regions; (2) an Adaptive Background Suppression module, which adaptively weights patch classification entropy; and (3) a Confusable Foreground Rectification module, which identifies and rectifies confusable foreground patches. Extensive experimental results demonstrate that the proposed plug-and-play framework significantly improves the performance of existing FG-BG decomposition methods. Code is available at: https://github.com/lounwb/FoBoR.", "AI": {"tldr": "本文提出了一种新的插件式框架，通过改进前景和背景的分解来提升少样本分布外检测性能。", "motivation": "现有的基于CLIP的前景-背景分解方法在提高少样本分布外检测性能方面表现出色，但仍存在一些限制。该论文旨在解决现有方法对背景区域采用统一抑制策略忽视不同补丁贡献的问题以及未充分考虑前景区域内某些局部补丁与其他类别具有外观或语义相似性导致误导训练的问题。", "method": "该框架包含三个核心组件：（1）前景-背景分解模块，用于将图像分为前景和背景区域；（2）自适应背景抑制模块，采用自适应加权分类熵的策略；（3）可混淆前景修正模块，识别并修正可能引起误导的前景补丁。", "result": "实验结果显示，所提出的插件式框架显著提升了现有FG-BG分解方法的表现。", "conclusion": "研究表明通过改进前景和背景的处理可以有效提高少样本分布外检测性能，并且该方法具有广泛的适用性和有效性。"}}
{"id": "2601.15064", "pdf": "https://arxiv.org/pdf/2601.15064", "abs": "https://arxiv.org/abs/2601.15064", "authors": ["Simran Kaur", "Sara Salimzadeh", "Ujwal Gadiraju"], "title": "Incentive-Tuning: Understanding and Designing Incentives for Empirical Human-AI Decision-Making Studies", "categories": ["cs.HC", "cs.AI", "cs.GT", "cs.IR"], "comment": null, "summary": "AI has revolutionised decision-making across various fields. Yet human judgement remains paramount for high-stakes decision-making. This has fueled explorations of collaborative decision-making between humans and AI systems, aiming to leverage the strengths of both. To explore this dynamic, researchers conduct empirical studies, investigating how humans use AI assistance for decision-making and how this collaboration impacts results. A critical aspect of conducting these studies is the role of participants, often recruited through crowdsourcing platforms. The validity of these studies hinges on the behaviours of the participants, hence effective incentives that can potentially affect these behaviours are a key part of designing and executing these studies. In this work, we aim to address the critical role of incentive design for conducting empirical human-AI decision-making studies, focusing on understanding, designing, and documenting incentive schemes. Through a thematic review of existing research, we explored the current practices, challenges, and opportunities associated with incentive design for human-AI decision-making empirical studies. We identified recurring patterns, or themes, such as what comprises the components of an incentive scheme, how incentive schemes are manipulated by researchers, and the impact they can have on research outcomes. Leveraging the acquired understanding, we curated a set of guidelines to aid researchers in designing effective incentive schemes for their studies, called the Incentive-Tuning Framework, outlining how researchers can undertake, reflect on, and document the incentive design process. By advocating for a standardised yet flexible approach to incentive design and contributing valuable insights along with practical tools, we hope to pave the way for more reliable and generalizable knowledge in the field of human-AI decision-making.", "AI": {"tldr": "本文旨在探讨和设计人类与AI合作决策研究中的激励机制，提出了名为Incentive-Tuning Framework的指导框架。", "motivation": "由于人类判断在高风险决策中仍然至关重要，研究人员探索了人与AI系统的协作。有效的人类行为激励是此类研究的关键组成部分。", "method": "通过主题性回顾现有研究，本文探讨了激励设计中的当前实践、挑战和机遇，并提炼出一系列指导方针。", "result": "识别出了关于激励方案的组成成分、研究人员如何调整这些激励方案以及它们对研究成果影响的主题模式。", "conclusion": "提出了Incentive-Tuning Framework框架，为研究者提供了一套标准化但灵活的方法来设计有效的激励机制。"}}
{"id": "2601.15061", "pdf": "https://arxiv.org/pdf/2601.15061", "abs": "https://arxiv.org/abs/2601.15061", "authors": ["Qiwei Ma", "Jun Zhang"], "title": "Differential Privacy Image Generation with Reconstruction Loss and Noise Injection Using an Error Feedback SGD", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Traditional data masking techniques such as anonymization cannot achieve the expected privacy protection while ensuring data utility for privacy-preserving machine learning. Synthetic data plays an increasingly important role as it generates a large number of training samples and prevents information leakage in real data. The existing methods suffer from the repeating trade-off processes between privacy and utility. We propose a novel framework for differential privacy generation, which employs an Error Feedback Stochastic Gradient Descent(EFSGD) method and introduces a reconstruction loss and noise injection mechanism into the training process. We generate images with higher quality and usability under the same privacy budget as the related work. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both grayscale and RGB images. We achieve state-of-the-art results over almost all metrics on three benchmarks: MNIST, Fashion-MNIST, and CelebA.", "AI": {"tldr": "本文提出了一种新的框架，用于在保证隐私的情况下生成高质量图像。", "motivation": "传统的数据掩蔽技术如匿名化无法同时实现预期的隐私保护和数据效用，而合成数据可以生成大量训练样本并防止真实数据的信息泄露，但现有方法存在隐私与效用之间的权衡问题。", "method": "该框架采用误差反馈随机梯度下降（EFSGD）方法，并在训练过程中引入重建损失和噪声注入机制来提高图像质量和使用性。", "result": "实验表明，该框架在MNIST、Fashion-MNIST和CelebA三个基准数据集上，在保持相同隐私预算的同时，生成了比相关工作更高质量的灰度图和RGB图，并实现了几乎所有指标上的最佳结果。", "conclusion": "研究证明了所提出的框架在保证隐私保护的前提下能够生成高质量图像的有效性和通用性。"}}
{"id": "2601.15059", "pdf": "https://arxiv.org/pdf/2601.15059", "abs": "https://arxiv.org/abs/2601.15059", "authors": ["Oleg Romanchuk", "Roman Bondar"], "title": "The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems", "categories": ["cs.AI", "eess.SY"], "comment": null, "summary": "Modern CI/CD pipelines integrating agent-generated code exhibit a structural failure in responsibility attribution. Decisions are executed through formally correct approval processes, yet no entity possesses both the authority to approve those decisions and the epistemic capacity to meaningfully understand their basis. We define this condition as responsibility vacuum: a state in which decisions occur, but responsibility cannot be attributed because authority and verification capacity do not coincide. We show that this is not a process deviation or technical defect, but a structural property of deployments where decision generation throughput exceeds bounded human verification capacity. We identify a scaling limit under standard deployment assumptions, including parallel agent generation, CI-based validation, and individualized human approval gates. Beyond a throughput threshold, verification ceases to function as a decision criterion and is replaced by ritualized approval based on proxy signals. Personalized responsibility becomes structurally unattainable in this regime. We further characterize a CI amplification dynamic, whereby increasing automated validation coverage raises proxy signal density without restoring human capacity. Under fixed time and attention constraints, this accelerates cognitive offloading in the broad sense and widens the gap between formal approval and epistemic understanding. Additional automation therefore amplifies, rather than mitigates, the responsibility vacuum. We conclude that unless organizations explicitly redesign decision boundaries or reassign responsibility away from individual decisions toward batch- or system-level ownership, responsibility vacuum remains an invisible but persistent failure mode in scaled agent deployments.", "AI": {"tldr": "论文讨论了现代CI/CD管道中集成代理生成代码时出现的责任归属结构失败，定义为责任真空，并分析了其影响和解决方案。", "motivation": "动机在于揭示在决策执行过程中，尽管有正式的审批流程，但没有实体同时拥有批准权限和理解决策基础的能力，从而导致无法归责的问题。", "method": "通过识别部署中的扩展极限以及自动化验证覆盖率增加带来的代理信号密度提高，来分析责任真空现象及其影响。", "result": "研究结果表明，在决策生成吞吐量超过人类的有界核实能力的情况下，个人化责任变得结构上不可实现，并且更多的自动化实际上加剧了责任真空问题。", "conclusion": "结论是除非组织重新设计决策边界或从个别决策的责任转向批处理或系统级别所有权，否则责任真空将继续作为一个隐形但持久的问题存在于扩展代理部署中。"}}
{"id": "2601.15056", "pdf": "https://arxiv.org/pdf/2601.15056", "abs": "https://arxiv.org/abs/2601.15056", "authors": ["Maria T. Tagliaferri", "Inseung Kang"], "title": "Systematic Evaluation of Hip Exoskeleton Assistance Parameters for Enhancing Gait Stability During Ground Slip Perturbations", "categories": ["cs.RO"], "comment": null, "summary": "Falls are the leading cause of injury related hospitalization and mortality among older adults. Consequently, mitigating age-related declines in gait stability and reducing fall risk during walking is a critical goal for assistive devices. Lower-limb exoskeletons have the potential to support users in maintaining stability during walking. However, most exoskeleton controllers are optimized to reduce the energetic cost of walking rather than to improve stability. While some studies report stability benefits with assistance, the effects of specific parameters, such as assistance magnitude and duration, remain unexplored. To address this gap, we systematically modulated the magnitude and duration of torque provided by a bilateral hip exoskeleton during slip perturbations in eight healthy adults, quantifying stability using whole-body angular momentum (WBAM). WBAM responses were governed by a significant interaction between assistance magnitude and duration, with duration determining whether exoskeleton assistance was stabilizing or destabilizing relative to not wearing the exoskeleton device. Compared to an existing energy-optimized controller, experimentally identified stability-optimal parameters reduced WBAM range by 25.7% on average. Notably, substantial inter-subject variability was observed in the parameter combinations that minimized WBAM during perturbations. We found that optimizing exoskeleton assistance for energetic outcomes alone is insufficient for improving reactive stability during gait perturbations. Stability-focused exoskeleton control should prioritize temporal assistance parameters and include user-specific personalization. This study represents an important step toward personalized, stability-focused exoskeleton control, with direct implications for improving stability and reducing fall risk in older adults.", "AI": {"tldr": "评估髋关节外骨骼辅助参数对步态稳定性的影响，特别是在地面滑动干扰时。", "motivation": "跌倒是老年人受伤和死亡的主要原因。研究旨在通过调节下肢外骨骼的辅助参数来提高行走稳定性和降低跌倒风险。", "method": "在八位健康成年人中系统地调整髋部双侧外骨骼提供的扭矩幅度和持续时间，使用全身角动量（WBAM）量化稳定性。", "result": "研究发现扭矩幅度与持续时间之间的相互作用显著影响了WBAM的响应；相比现有节能优化控制策略，实验识别出的最优参数组合平均降低了25.7%的WBAM范围。", "conclusion": "仅针对能量优化目标调整外骨骼辅助是不足以改善步态干扰时的稳定性的。应优先考虑时间性辅助参数，并进行用户个性化设置。"}}
{"id": "2601.15055", "pdf": "https://arxiv.org/pdf/2601.15055", "abs": "https://arxiv.org/abs/2601.15055", "authors": ["Isaac Baglin", "Xiatian Zhu", "Simon Hadfield"], "title": "SpooFL: Spoofing Federated Learning", "categories": ["cs.CR", "cs.CV", "cs.LG"], "comment": null, "summary": "Traditional defenses against Deep Leakage (DL) attacks in Federated Learning (FL) primarily focus on obfuscation, introducing noise, transformations or encryption to degrade an attacker's ability to reconstruct private data. While effective to some extent, these methods often still leak high-level information such as class distributions or feature representations, and are frequently broken by increasingly powerful denoising attacks. We propose a fundamentally different perspective on FL defense: framing it as a spoofing problem.We introduce SpooFL (Figure 1), a spoofing-based defense that deceives attackers into believing they have recovered the true training data, while actually providing convincing but entirely synthetic samples from an unrelated task. Unlike prior synthetic-data defenses that share classes or distributions with the private data and thus still leak semantic information, SpooFL uses a state-of-the-art generative model trained on an external dataset with no class overlap. As a result, attackers are misled into recovering plausible yet completely irrelevant samples, preventing meaningful data leakage while preserving FL training integrity. We implement the first example of such a spoofing defense, and evaluate our method against state-of-the-art DL defenses and demonstrate that it successfully misdirects attackers without compromising model performance significantly.", "AI": {"tldr": "本论文介绍了SpooFL，一种通过提供与私人数据无关的合成样本来误导攻击者的防御方法。", "motivation": "传统的深度泄露攻击防御方法虽然有效但仍然泄漏高层信息，并且容易被去噪攻击突破。因此提出了一种新的防御视角：将问题视为欺骗（spoofing）问题。", "method": "SpooFL使用外部无类重叠的数据集训练的生成模型，产生与私人数据无关的合成样本以误导攻击者相信他们恢复了真实训练数据。", "result": "实验表明，SpooFL能够成功误导攻击者，同时不会显著影响模型性能。", "conclusion": "通过提供完全无关但可信的合成样本来防止有意义的数据泄露，保持联合学习培训的完整性。"}}
{"id": "2601.15049", "pdf": "https://arxiv.org/pdf/2601.15049", "abs": "https://arxiv.org/abs/2601.15049", "authors": ["Isaac Baglin", "Xiatian Zhu", "Simon Hadfield"], "title": "Deep Leakage with Generative Flow Matching Denoiser", "categories": ["cs.CV"], "comment": null, "summary": "Federated Learning (FL) has emerged as a powerful paradigm for decentralized model training, yet it remains vulnerable to deep leakage (DL) attacks that reconstruct private client data from shared model updates. While prior DL methods have demonstrated varying levels of success, they often suffer from instability, limited fidelity, or poor robustness under realistic FL settings. We introduce a new DL attack that integrates a generative Flow Matching (FM) prior into the reconstruction process. By guiding optimization toward the distribution of realistic images (represented by a flow matching foundation model), our method enhances reconstruction fidelity without requiring knowledge of the private data. Extensive experiments on multiple datasets and target models demonstrate that our approach consistently outperforms state-of-the-art attacks across pixel-level, perceptual, and feature-based similarity metrics. Crucially, the method remains effective across different training epochs, larger client batch sizes, and under common defenses such as noise injection, clipping, and sparsification. Our findings call for the development of new defense strategies that explicitly account for adversaries equipped with powerful generative priors.", "AI": {"tldr": "本文提出了一种新的深度泄漏攻击方法，通过集成生成流匹配先验来提高重建私有客户数据的保真度。", "motivation": "尽管联邦学习是一种强大的去中心化模型训练范式，但它容易受到深度泄漏攻击的影响，这些攻击可以从共享模型更新中重构出私有客户的数据。现有的深度泄漏方法存在不稳定、保真度低或在现实环境下的鲁棒性差等问题。", "method": "本研究引入了一种新的深度泄漏攻击方法，该方法将生成流匹配（FM）先验集成到重建过程中，通过引导优化朝向由流匹配基础模型表示的真实图像分布方向，来提升重建质量，并且不需要私有数据的知识。", "result": "在多个数据集和目标模型上的大量实验表明，本研究的方法在像素级、感知性和特征基相似度指标上均优于现有的攻击方法，同时在不同的训练周期、较大的客户端批量大小以及常见的防御策略如噪声注入、剪枝和稀疏化下依然有效。", "conclusion": "该研究结果强调了开发考虑具有强大生成先验的对手的新防御策略的重要性。"}}
{"id": "2601.15042", "pdf": "https://arxiv.org/pdf/2601.15042", "abs": "https://arxiv.org/abs/2601.15042", "authors": ["Andrea Protani", "Riccardo Taiello", "Marc Molina Van Den Bosch", "Luigi Serio"], "title": "Federated Transformer-GNN for Privacy-Preserving Brain Tumor Localization with Modality-Level Explainability", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep learning models for brain tumor analysis require large and diverse datasets that are often siloed across healthcare institutions due to privacy regulations. We present a federated learning framework for brain tumor localization that enables multi-institutional collaboration without sharing sensitive patient data. Our method extends a hybrid Transformer-Graph Neural Network architecture derived from prior decoder-free supervoxel GNNs and is deployed within CAFEIN\\textsuperscript{\\textregistered}, CERN's federated learning platform designed for healthcare environments. We provide an explainability analysis through Transformer attention mechanisms that reveals which MRI modalities drive the model predictions. Experiments on the BraTS dataset demonstrate a key finding: while isolated training on individual client data triggers early stopping well before reaching full training capacity, federated learning enables continued model improvement by leveraging distributed data, ultimately matching centralized performance. This result provides strong justification for federated learning when dealing with complex tasks and high-dimensional input data, as aggregating knowledge from multiple institutions significantly benefits the learning process. Our explainability analysis, validated through rigorous statistical testing on the full test set (paired t-tests with Bonferroni correction), reveals that deeper network layers significantly increase attention to T2 and FLAIR modalities ($p<0.001$, Cohen's $d$=1.50), aligning with clinical practice.", "AI": {"tldr": "本文介绍了一种用于脑肿瘤定位的联邦学习框架，该框架结合了Transformer和图神经网络，并在CERN的CAFEIN平台上部署，实现了跨机构合作而无需共享敏感患者数据。", "motivation": "由于隐私法规，医疗保健机构中的大型多样化数据集往往被隔离。本文旨在通过联邦学习来促进多机构间的数据协作，同时保护患者的隐私。", "method": "本方法扩展了先前的无解码器监督体素图神经网络，并采用联邦学习框架，在CERN的CAFEIN平台上部署了一个混合Transformer-Graph Neural Network架构，以实现脑肿瘤定位。", "result": "实验表明，尽管单独训练每个客户端数据会导致模型过早停止优化，但联邦学习通过利用分布式数据使模型性能持续提升，最终达到了与集中式培训相同的效果，并且证明了深度网络层增加了对T2和FLAIR MRI模态的关注。", "conclusion": "研究结果支持在处理复杂任务和高维输入时采用联邦学习方法的合理性，因为从多个机构聚合知识显著改善了模型的学习过程。"}}
{"id": "2601.15039", "pdf": "https://arxiv.org/pdf/2601.15039", "abs": "https://arxiv.org/abs/2601.15039", "authors": ["Jiyao Zhang", "Zhiyuan Ma", "Tianhao Wu", "Zeyuan Chen", "Hao Dong"], "title": "CADGrasp: Learning Contact and Collision Aware General Dexterous Grasping in Cluttered Scenes", "categories": ["cs.RO"], "comment": null, "summary": "Dexterous grasping in cluttered environments presents substantial challenges due to the high degrees of freedom of dexterous hands, occlusion, and potential collisions arising from diverse object geometries and complex layouts. To address these challenges, we propose CADGrasp, a two-stage algorithm for general dexterous grasping using single-view point cloud inputs. In the first stage, we predict sparse IBS, a scene-decoupled, contact- and collision-aware representation, as the optimization target. Sparse IBS compactly encodes the geometric and contact relationships between the dexterous hand and the scene, enabling stable and collision-free dexterous grasp pose optimization. To enhance the prediction of this high-dimensional representation, we introduce an occupancy-diffusion model with voxel-level conditional guidance and force closure score filtering. In the second stage, we develop several energy functions and ranking strategies for optimization based on sparse IBS to generate high-quality dexterous grasp poses. Extensive experiments in both simulated and real-world settings validate the effectiveness of our approach, demonstrating its capability to mitigate collisions while maintaining a high grasp success rate across diverse objects and complex scenes.", "AI": {"tldr": "提出了CADGrasp，一种用于复杂场景中灵巧抓取的两阶段算法。", "motivation": "解决在杂乱环境中进行灵巧抓取时遇到的高度自由度、遮挡和潜在碰撞等挑战。", "method": "第一阶段预测稀疏IBS作为优化目标；第二阶段基于稀疏IBS开发能量函数和排名策略生成高质量的灵巧抓取姿势。", "result": "通过模拟和现实世界的广泛实验验证了该方法的有效性，展示了其在减少碰撞同时保持高成功率方面的优越性能。", "conclusion": "CADGrasp算法能够有效处理复杂场景下的灵巧抓取问题，并且具有较高的抓取成功概率。"}}
{"id": "2601.15038", "pdf": "https://arxiv.org/pdf/2601.15038", "abs": "https://arxiv.org/abs/2601.15038", "authors": ["Mertcan Daysalilar", "Fuat Uyguroglu", "Gabriel Nicolosi", "Adam Meyers"], "title": "A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The electric vehicle routing problem with time windows (EVRPTW) is a complex optimization problem in sustainable logistics, where routing decisions must minimize total travel distance, fleet size, and battery usage while satisfying strict customer time constraints. Although deep reinforcement learning (DRL) has shown great potential as an alternative to classical heuristics and exact solvers, existing DRL models often struggle to maintain training stability-failing to converge or generalize when constraints are dense. In this study, we propose a curriculum-based deep reinforcement learning (CB-DRL) framework designed to resolve this instability. The framework utilizes a structured three-phase curriculum that gradually increases problem complexity: the agent first learns distance and fleet optimization (Phase A), then battery management (Phase B), and finally the full EVRPTW (Phase C). To ensure stable learning across phases, the framework employs a modified proximal policy optimization algorithm with phase-specific hyperparameters, value and advantage clipping, and adaptive learning-rate scheduling. The policy network is built upon a heterogeneous graph attention encoder enhanced by global-local attention and feature-wise linear modulation. This specialized architecture explicitly captures the distinct properties of depots, customers, and charging stations. Trained exclusively on small instances with N=10 customers, the model demonstrates robust generalization to unseen instances ranging from N=5 to N=100, significantly outperforming standard baselines on medium-scale problems. Experimental results confirm that this curriculum-guided approach achieves high feasibility rates and competitive solution quality on out-of-distribution instances where standard DRL baselines fail, effectively bridging the gap between neural speed and operational reliability.", "AI": {"tldr": "本文提出了一种基于课程的深度强化学习框架，用于解决带时间窗的电动汽车路径问题。", "motivation": "现有的深度强化学习模型在处理密集约束条件下的训练稳定性方面存在问题，导致无法收敛或泛化。因此，本研究旨在通过设计一个逐步增加复杂度的学习框架来解决这一挑战。", "method": "该框架采用三阶段课程结构，分别是距离和车队优化、电池管理以及完整的电动汽车路径问题。使用了修改的近端策略优化算法，并结合异构图注意力编码器增强模型能力。", "result": "实验表明，在小规模实例上训练的模型能够有效地泛化到未知的大规模实例中，显著优于标准基线方法，尤其是在中等规模问题上的性能表现突出。", "conclusion": "该课程指导的方法在面对分布外的实例时，不仅保持了高度的可行性，而且提供了具有竞争力的解决方案质量，从而有效平衡了神经网络的速度和操作可靠性之间的差距。"}}
{"id": "2601.15037", "pdf": "https://arxiv.org/pdf/2601.15037", "abs": "https://arxiv.org/abs/2601.15037", "authors": ["Xiaonan Jing", "Gongqing Wu", "Xingrui Zhuo", "Lang Sun", "Jiapu Wang"], "title": "Knowledge Restoration-driven Prompt Optimization: Unlocking LLM Potential for Open-Domain Relational Triplet Extraction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Open-domain Relational Triplet Extraction (ORTE) is the foundation for mining structured knowledge without predefined schemas. Despite the impressive in-context learning capabilities of Large Language Models (LLMs), existing methods are hindered by their reliance on static, heuristic-driven prompting strategies. Due to the lack of reflection mechanisms required to internalize erroneous signals, these methods exhibit vulnerability in semantic ambiguity, often making erroneous extraction patterns permanent. To address this bottleneck, we propose a Knowledge Reconstruction-driven Prompt Optimization (KRPO) framework to assist LLMs in continuously improving their extraction capabilities for complex ORTE task flows. Specifically, we design a self-evaluation mechanism based on knowledge restoration, which provides intrinsic feedback signals by projecting structured triplets into semantic consistency scores. Subsequently, we propose a prompt optimizer based on a textual gradient that can internalize historical experiences to iteratively optimize prompts, which can better guide LLMs to handle subsequent extraction tasks. Furthermore, to alleviate relation redundancy, we design a relation canonicalization memory that collects representative relations and provides semantically distinct schemas for the triplets. Extensive experiments across three datasets show that KRPO significantly outperforms strong baselines in the extraction F1 score.", "AI": {"tldr": "本文提出了基于知识恢复的提示优化框架（KRPO），旨在提升大语言模型在开放域关系三元组提取任务中的性能。", "motivation": "现有的方法受限于静态、启发式驱动的提示策略，缺乏自我修正机制来处理语义上的模糊性问题，导致错误的抽取模式难以纠正。因此，作者提出了一种新的框架以持续提升大语言模型在复杂开放域关系三元组提取任务中的能力。", "method": "该研究设计了一个基于知识恢复的自我评估机制，并引入了文本梯度的提示优化器来迭代改善提示策略。此外还设计了一个关系规范化内存，用于减少关系冗余并提供语义上不同的模式。", "result": "实验结果显示，KRPO框架在三项数据集上的抽取F1分数显著优于强基准模型。", "conclusion": "研究证明了提出的知识恢复驱动的提示优化方法能有效提升大语言模型在开放域关系三元组提取任务中的表现。"}}
{"id": "2601.15034", "pdf": "https://arxiv.org/pdf/2601.15034", "abs": "https://arxiv.org/abs/2601.15034", "authors": ["Chris Monk", "Allegra Ayala", "Christine S. P. Yu", "Gregory M. Fitch", "Dara Gruber"], "title": "Visual and Cognitive Demands of a Large Language Model-Powered In-vehicle Conversational Agent", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Driver distraction remains a leading contributor to motor vehicle crashes, necessitating rigorous evaluation of new in-vehicle technologies. This study assessed the visual and cognitive demands associated with an advanced Large Language Model (LLM) conversational agent (Gemini Live) during on-road driving, comparing it against handsfree phone calls, visual turn-by-turn guidance (low load baseline), and the Operation Span (OSPAN) task (high load anchor). Thirty-two licensed drivers completed five secondary tasks while visual and cognitive demands were measured using the Detection Response Task (DRT) for cognitive load, eye-tracking for visual attention, and subjective workload ratings. Results indicated that Gemini Live interactions (both single-turn and multi-turn) and hands-free phone calls shared similar levels of cognitive load, between that of visual turn-by-turn guidance and OSPAN. Exploratory analysis showed that cognitive load remained stable across extended multi-turn conversations. All tasks maintained mean glance durations well below the well-established 2-second safety threshold, confirming low visual demand. Furthermore, drivers consistently dedicated longer glances to the roadway between brief off-road glances toward the device during task completion, particularly during voice-based interactions, rendering longer total-eyes-off-road time findings less consequential. Subjective ratings mirrored objective data, with participants reporting low effort, demands, and perceived distraction for Gemini Live. These findings demonstrate that advanced LLM conversational agents, when implemented via voice interfaces, impose cognitive and visual demands comparable to established, low-risk hands-free benchmarks, supporting their safe deployment in the driving environment.", "AI": {"tldr": "评估大型语言模型驱动的车内对话代理在驾驶过程中的视觉和认知需求。", "motivation": "由于驾驶员分心是导致机动车事故的主要因素，需要对新型车内技术进行严格评估。本研究旨在比较高级大型语言模型对话代理与传统的免提电话通话、可视化导航以及高负载任务的认知和视觉负担。", "method": "32名持证驾驶者完成了五项次要任务，使用检测响应任务（DRT）测量认知负荷，使用眼动追踪技术监测视觉注意力，并通过主观工作量评分进行评估。", "result": "结果表明大型语言模型对话代理（单次和多次交互）与免提电话通话的认知负担相似，介于可视化导航引导和高负载任务之间。所有任务的平均注视时间远低于2秒的安全阈值，显示低视觉需求。驾驶员在完成语音交互期间，持续将较长的视线集中在道路上。", "conclusion": "高级大型语言模型对话代理通过声控界面实施时，其认知和视觉负担与已知风险较低的免提基准相似，支持其在驾驶环境中的安全应用。"}}
{"id": "2601.15029", "pdf": "https://arxiv.org/pdf/2601.15029", "abs": "https://arxiv.org/abs/2601.15029", "authors": ["Fabio Morreale", "Joan Serrà", "Yuki Mistufuji"], "title": "Emergent, not Immanent: A Baradian Reading of Explainable AI", "categories": ["cs.AI", "cs.HC"], "comment": "Accepted at CHI 2026", "summary": "Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.", "AI": {"tldr": "本文提出了一种基于Barad的能动现实主义解释AI（XAI）的新本体论和认识论方法，强调解释是人工智能模型与人类、环境及解释工具之间相互作用的结果。", "motivation": "动机在于质疑传统的将可解释性视为揭示AI内部运作的技术问题的观点，并提出一种新的理解框架来探索更深刻的人机交互方式。", "method": "本文通过Barad的能动现实主义理论，重新解读了一系列XAI方法，并展示了这些方法背后的假设和限制。", "result": "揭示了传统XAI方法中的未检讨本体论-认识论假设，并提出了新的解释框架，强调解释是动态形成的交互结果。", "conclusion": "结论认为通过采用能动现实主义的视角，可以更全面地理解和设计XAI系统，特别是那些支持解释性交互的设计方向。"}}
{"id": "2601.15025", "pdf": "https://arxiv.org/pdf/2601.15025", "abs": "https://arxiv.org/abs/2601.15025", "authors": ["Marian Renz", "Martin Günther", "Felix Igelbrink", "Oscar Lima", "Martin Atzmueller"], "title": "ExPrIS: Knowledge-Level Expectations as Priors for Object Interpretation from Sensor Data", "categories": ["cs.RO", "cs.CV"], "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in KI - Künstliche Intelligenz, and is available online at https://doi.org/10.1007/s13218-026-00901-7", "summary": "While deep learning has significantly advanced robotic object recognition, purely data-driven approaches often lack semantic consistency and fail to leverage valuable, pre-existing knowledge about the environment. This report presents the ExPrIS project, which addresses this challenge by investigating how knowledge-level expectations can serve as to improve object interpretation from sensor data. Our approach is based on the incremental construction of a 3D Semantic Scene Graph (3DSSG). We integrate expectations from two sources: contextual priors from past observations and semantic knowledge from external graphs like ConceptNet. These are embedded into a heterogeneous Graph Neural Network (GNN) to create an expectation-biased inference process. This method moves beyond static, frame-by-frame analysis to enhance the robustness and consistency of scene understanding over time. The report details this architecture, its evaluation, and outlines its planned integration on a mobile robotic platform.", "AI": {"tldr": "本论文介绍了ExPrIS项目，通过将知识层面的期望作为先验来改进基于传感器数据的对象解释。", "motivation": "尽管深度学习显著提升了机器人对象识别的能力，但纯粹的数据驱动方法往往缺乏语义一致性且无法利用现有的环境知识。此研究旨在解决这一问题。", "method": "该方法基于3D语义场景图的增量构建，并将来自过去观察和外部知识图（如ConceptNet）的期望整合到异构图神经网络中，以实现偏向预期的推理过程。", "result": "论文详细描述了此架构及其评估，并计划将其集成到移动机器人平台上。", "conclusion": "该方法超越了静态、逐帧分析，增强了对场景理解随时间的一致性和鲁棒性。"}}
{"id": "2601.15021", "pdf": "https://arxiv.org/pdf/2601.15021", "abs": "https://arxiv.org/abs/2601.15021", "authors": ["Adam Rokah", "Daniel Veress", "Caleb Caulk", "Sourav Sharan"], "title": "Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization", "categories": ["cs.LG", "cs.CV"], "comment": "7 pages, 8 figures. Code available at: https://github.com/moe-project-uu/mixture-of-experts-project", "summary": "Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.", "AI": {"tldr": "研究混合专家模型在图像分类中的行为，包括预测性能、专家利用和泛化能力。", "motivation": "探索Mixture-of-Experts (MoE)架构在图像分类任务上的应用，并对比其与密集网络的表现差异。", "method": "比较了CIFAR10数据集上密集模型、SoftMoE和SparseMoE的性能，通过正则化保持专家利用率平衡，并计算了Hessian矩阵的最大特征值和迹以分析泛化能力。", "result": "MoE变体在验证准确率略高于密集基线，但没有出现专家坍塌问题；SoftMoE表现出较高的尖锐度，而Dense和SparseMoE的曲率相似，尽管所有模型实现了相似的泛化性能。", "conclusion": "虽然理论上有提高推理效率的潜力，但在现代硬件上实现条件路由并未带来实际的速度提升。"}}
{"id": "2601.15018", "pdf": "https://arxiv.org/pdf/2601.15018", "abs": "https://arxiv.org/abs/2601.15018", "authors": ["Leon Tolksdorf", "Arturo Tejada", "Jonas Bauernfeind", "Christian Birkner", "Nathan van de Wouw"], "title": "Risk Estimation for Automated Driving", "categories": ["cs.RO"], "comment": "10 pages, 5 figures", "summary": "Safety is a central requirement for automated vehicles. As such, the assessment of risk in automated driving is key in supporting both motion planning technologies and safety evaluation. In automated driving, risk is characterized by two aspects. The first aspect is the uncertainty on the state estimates of other road participants by an automated vehicle. The second aspect is the severity of a collision event with said traffic participants. Here, the uncertainty aspect typically causes the risk to be non-zero for near-collision events. This makes risk particularly useful for automated vehicle motion planning. Namely, constraining or minimizing risk naturally navigates the automated vehicle around traffic participants while keeping a safety distance based on the level of uncertainty and the potential severity of the impending collision. Existing approaches to calculate the risk either resort to empirical modeling or severe approximations, and, hence, lack generalizability and accuracy. In this paper, we combine recent advances in collision probability estimation with the concept of collision severity to develop a general method for accurate risk estimation. The proposed method allows us to assign individual severity functions for different collision constellations, such as, e.g., frontal or side collisions. Furthermore, we show that the proposed approach is computationally efficient, which is beneficial, e.g., in real-time motion planning applications. The programming code for an exemplary implementation of Gaussian uncertainties is also provided.", "AI": {"tldr": "本文提出了一种结合碰撞概率估计和碰撞严重性概念的通用方法，用于准确评估自动驾驶中的风险。", "motivation": "现有的风险计算方法缺乏泛化能力和准确性，因此需要开发一种新的方法以提高自动驾驶车辆的安全性和规划能力。", "method": "结合近期在碰撞概率估算方面的进展与碰撞严重性的概念，提出了一种可用于不同碰撞情境下的个体严重性函数的方法，并提供了高斯不确定性的示例实现代码。", "result": "所提出的方法是计算高效的，并且能够为实时运动规划提供支持。", "conclusion": "本文提出的方法能够在自动驾驶车辆中准确评估风险并提高安全性，同时保持了计算效率和实用性。"}}
{"id": "2601.15017", "pdf": "https://arxiv.org/pdf/2601.15017", "abs": "https://arxiv.org/abs/2601.15017", "authors": ["Yanan Wang", "Linjie Ren", "Zihao Li", "Junyi Wang", "Tian Gan"], "title": "SpatialV2A: Visual-Guided High-fidelity Spatial Audio Generation", "categories": ["cs.CV"], "comment": null, "summary": "While video-to-audio generation has achieved remarkable progress in semantic and temporal alignment, most existing studies focus solely on these aspects, paying limited attention to the spatial perception and immersive quality of the synthesized audio. This limitation stems largely from current models' reliance on mono audio datasets, which lack the binaural spatial information needed to learn visual-to-spatial audio mappings. To address this gap, we introduce two key contributions: we construct BinauralVGGSound, the first large-scale video-binaural audio dataset designed to support spatially aware video-to-audio generation; and we propose a end-to-end spatial audio generation framework guided by visual cues, which explicitly models spatial features. Our framework incorporates a visual-guided audio spatialization module that ensures the generated audio exhibits realistic spatial attributes and layered spatial depth while maintaining semantic and temporal alignment. Experiments show that our approach substantially outperforms state-of-the-art models in spatial fidelity and delivers a more immersive auditory experience, without sacrificing temporal or semantic consistency. All datasets, code, and model checkpoints will be publicly released to facilitate future research.", "AI": {"tldr": "本文提出了一个基于视觉线索引导的空间音频生成框架SpatialV2A，旨在提升视频到音频生成中空间感知和沉浸感的质量。", "motivation": "现有研究在视频到音频生成方面侧重于语义和时间上的对齐，忽略了音频的空间感知和沉浸质量。当前模型依赖单声道音频数据集，缺乏用于学习视觉到空间音频映射的双耳空间信息。", "method": "本文构建了一个大型视频-双耳音频数据集BinauralVGGSound，并提出一个由视觉线索引导的空间音频生成框架，该框架包含一个基于视觉提示的空间化模块以确保生成的音频具有现实的空间属性和分层空间深度，同时保持语义和时间的一致性。", "result": "实验表明，本文方法在空间保真度上显著优于现有最佳模型，并提供了更加沉浸式的听觉体验，且未牺牲时间和语义一致性。", "conclusion": "SpatialV2A框架通过引入视觉线索引导的空间音频生成技术，在保持时间与语义一致性的基础上提升了音频的空间感知和沉浸质量。"}}
{"id": "2601.15016", "pdf": "https://arxiv.org/pdf/2601.15016", "abs": "https://arxiv.org/abs/2601.15016", "authors": ["Xiaodong Wang", "Langling Huang", "Zhirong Wu", "Xu Zhao", "Teng Xu", "Xuhong Xia", "Peixi Peng"], "title": "LiViBench: An Omnimodal Benchmark for Interactive Livestream Video Understanding", "categories": ["cs.CV"], "comment": "AAAI 2026 Main Track", "summary": "The development of multimodal large language models (MLLMs) has advanced general video understanding. However, existing video evaluation benchmarks primarily focus on non-interactive videos, such as movies and recordings. To fill this gap, this paper proposes the first omnimodal benchmark for interactive livestream videos, LiViBench. It features a diverse set of 24 tasks, highlighting the perceptual, reasoning, and livestream-specific challenges. To efficiently construct the dataset, we design a standardized semi-automatic annotation workflow that incorporates the human-in-the-loop at multiple stages. The workflow leverages multiple MLLMs to form a multi-agent system for comprehensive video description and uses a seed-question-driven method to construct high-quality annotations. All interactive videos in the benchmark include audio, speech, and real-time comments modalities. To enhance models' understanding of interactive videos, we design tailored two-stage instruction-tuning and propose a Video-to-Comment Retrieval (VCR) module to improve the model's ability to utilize real-time comments. Based on these advancements, we develop LiVi-LLM-7B, an MLLM with enhanced knowledge of interactive livestreams. Experiments show that our model outperforms larger open-source models with up to 72B parameters, narrows the gap with leading proprietary models on LiViBench, and achieves enhanced performance on general video benchmarks, including VideoMME, LongVideoBench, MLVU, and VideoEval-Pro.", "AI": {"tldr": "开发了LiViBench，一个用于交互式直播视频理解的全模态基准测试，并提出了增强对互动视频理解的方法。", "motivation": "现有视频评估基准主要针对非交互式视频，因此提出填补这一空白的LiViBench来推动交互式直播视频的理解。", "method": "设计了一个标准的半自动注释工作流，利用多模态大型语言模型（MLLM）形成一个多代理系统进行全面视频描述，并使用种子问题驱动方法构建高质量注释，还提出了两阶段指令调整和Video-to-Comment Retrieval模块来增强对实时评论的理解。", "result": "实验表明，所开发的LiVi-LLM-7B在LiViBench上超越了较大的开源模型，缩小了与领先专有模型之间的差距，并在通用视频基准测试中表现出色。", "conclusion": "该研究填补了交互式直播视频理解的空白，提出了有效的方法和模型来增强对这种特殊类型视频的理解能力。"}}
{"id": "2601.15006", "pdf": "https://arxiv.org/pdf/2601.15006", "abs": "https://arxiv.org/abs/2601.15006", "authors": ["Fumiya Ohnishi", "Masaki Takahashi"], "title": "DWPP: Dynamic Window Pure Pursuit Considering Velocity and Acceleration Constraints", "categories": ["cs.RO"], "comment": "28 pages, 12 figures", "summary": "Pure pursuit and its variants are widely used for mobile robot path tracking owing to their simplicity and computational efficiency. However, many conventional approaches do not explicitly account for velocity and acceleration constraints, resulting in discrepancies between commanded and actual velocities that result in overshoot and degraded tracking performance. To address this problem, this paper proposes dynamic window pure pursuit (DWPP), which fundamentally reformulates the command velocity computation process to explicitly incorporate velocity and acceleration constraints. Specifically, DWPP formulates command velocity computation in the velocity space (the $v$-$ω$ plane) and selects the command velocity as the point within the dynamic window that is closest to the line $ω= κv$. Experimental results demonstrate that DWPP avoids constraint-violating commands and achieves superior path-tracking accuracy compared with conventional pure pursuit methods. The proposed method has been integrated into the official Nav2 repository and is publicly available (https://github.com/ros-navigation/navigation2).", "AI": {"tldr": "本文提出了动态窗口纯追踪（DWPP）方法，以解决传统路径跟踪方法中未显式考虑速度和加速度约束导致的问题。", "motivation": "传统的纯追踪及其变种虽简单高效，但不显式处理速度和加速度约束，造成命令与实际速度差异，进而影响轨迹跟踪性能。", "method": "DWPP通过重新定义命令速度计算过程，在速度空间中考虑了速度和加速度的约束，并选择了最接近线ω= κv的动态窗口内的点作为命令速度。", "result": "实验结果表明，DWPP避免了违反约束的命令并实现了优于传统纯追踪方法的路径跟踪精度。", "conclusion": "该方法已被集成到Nav2官方仓库中，并且是公开可用的。"}}
{"id": "2601.14998", "pdf": "https://arxiv.org/pdf/2601.14998", "abs": "https://arxiv.org/abs/2601.14998", "authors": ["Adip Ranjan Das", "Maria Koskinopoulou"], "title": "Graph-Based Adaptive Planning for Coordinated Dual-Arm Robotic Disassembly of Electronic Devices (eGRAP)", "categories": ["cs.RO"], "comment": "7 Pages, 8 Figures, 5 Tables", "summary": "E-waste is growing rapidly while recycling rates remain low. We propose an electronic-device Graph-based Adaptive Planning (eGRAP) that integrates vision, dynamic planning, and dual-arm execution for autonomous disassembly. A camera-equipped arm identifies parts and estimates their poses, and a directed graph encodes which parts must be removed first. A scheduler uses topological ordering of this graph to select valid next steps and assign them to two robot arms, allowing independent tasks to run in parallel. One arm carries a screwdriver (with an eye-in-hand depth camera) and the other holds or handles components. We demonstrate eGRAP on 3.5in hard drives: as parts are unscrewed and removed, the system updates its graph and plan online. Experiments show consistent full disassembly of each HDD, with high success rates and efficient cycle times, illustrating the method's ability to adaptively coordinate dual-arm tasks in real time.", "AI": {"tldr": "提出了一种基于图的自适应规划方法（eGRAP），用于电子设备的自主拆解，采用双臂协作和动态规划。", "motivation": "鉴于电子废弃物快速增长而回收率低的问题，开发一种高效的自动化拆解系统来提高电子产品回收效率。", "method": "使用带有相机的机械臂识别零件并估计其姿态，构建有向图以决定移除顺序。调度程序利用此图的选择有效后续步骤并分配给两个机器人手臂进行独立任务执行。", "result": "实验表明，该系统能够对3.5英寸硬盘实现一致且成功的完全拆解，并具有高效的循环时间。", "conclusion": "eGRAP展示了其在实时协调双臂任务的能力，提高了拆解效率和成功率。"}}
{"id": "2601.14997", "pdf": "https://arxiv.org/pdf/2601.14997", "abs": "https://arxiv.org/abs/2601.14997", "authors": ["K. Punnam Chandar", "Y. Ravi Kumar"], "title": "Filtered 2D Contour-Based Reconstruction of 3D STL Model from CT-DICOM Images", "categories": ["eess.IV", "cs.CV"], "comment": "8 pages, 18 figures", "summary": "Reconstructing a 3D Stereo-lithography (STL) Model from 2D Contours of scanned structure in Digital Imaging and Communication in Medicine (DICOM) images is crucial to understand the geometry and deformity. Computed Tomography (CT) images are processed to enhance the contrast, reduce the noise followed by smoothing. The processed CT images are segmented using thresholding technique. 2D contour data points are extracted from segmented CT images and are used to construct 3D STL Models. The 2D contour data points may contain outliers as a result of segmentation of low resolution images and the geometry of the constructed 3D structure deviate from the actual. To cope with the imperfections in segmentation process, in this work we propose to use filtered 2D contour data points to reconstruct 3D STL Model. The filtered 2D contour points of each image are delaunay triangulated and joined layer-by-layer to reconstruct the 3D STL model. The 3D STL Model reconstruction is verified on i) 2D Data points of basic shapes and ii) Region of Interest (ROI) of human pelvic bone and are presented as case studies. The 3D STL model constructed from 2D contour data points of ROI of segmented pelvic bone with and without filtering are presented. The 3D STL model reconstructed from filtered 2D data points improved the geometry of model compared to the model reconstructed without filtering 2D data points.", "AI": {"tldr": "本文提出了使用过滤的2D轮廓数据点从CT-DICOM图像中重建3D STL模型的方法。", "motivation": "理解结构的几何和畸形，提高基于2D轮廓的3D模型重建精度。", "method": "通过处理CT图像、阈值分割提取2D轮廓数据点，并使用过滤后的2D数据点进行Delaunay三角剖分，逐层构建3D STL模型。", "result": "在基本形状和人类骨盆ROI上验证了方法的有效性，表明过滤的2D数据点能改善重建几何结构的准确性。", "conclusion": "使用过滤后的2D轮廓数据点能够显著提高从CT-DICOM图像中重建3D STL模型的质量。"}}
{"id": "2601.14994", "pdf": "https://arxiv.org/pdf/2601.14994", "abs": "https://arxiv.org/abs/2601.14994", "authors": ["Chaymaa Abbas", "Nour Shamaa", "Mariette Awad"], "title": "Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Data contamination undermines the validity of Large Language Model evaluation by enabling models to rely on memorized benchmark content rather than true generalization. While prior work has proposed contamination detection methods, these approaches are largely limited to English benchmarks, leaving multilingual contamination poorly understood. In this work, we investigate contamination dynamics in multilingual settings by fine-tuning several open-weight LLMs on varying proportions of Arabic datasets and evaluating them on original English benchmarks. To detect memorization, we extend the Tested Slot Guessing method with a choice-reordering strategy and incorporate Min-K% probability analysis, capturing both behavioral and distributional contamination signals. Our results show that translation into Arabic suppresses conventional contamination indicators, yet models still benefit from exposure to contaminated data, particularly those with stronger Arabic capabilities. This effect is consistently reflected in rising Mink% scores and increased cross-lingual answer consistency as contamination levels grow. To address this blind spot, we propose Translation-Aware Contamination Detection, which identifies contamination by comparing signals across multiple translated benchmark variants rather than English alone. The Translation-Aware Contamination Detection reliably exposes contamination even when English-only methods fail. Together, our findings highlight the need for multilingual, translation-aware evaluation pipelines to ensure fair, transparent, and reproducible assessment of LLMs.", "AI": {"tldr": "研究探讨了多语言环境中数据污染的动态，并提出了Translation-Aware Contamination Detection方法来检测通过翻译掩盖的数据污染。", "motivation": "由于先前的工作主要局限于英语基准测试，无法有效识别多语言环境下的数据污染问题，因此研究旨在探索在阿拉伯语等非英语环境下如何检测和减轻数据污染的影响。", "method": "研究人员对多个开放权重的大规模语言模型进行了微调，使用不同比例的阿拉伯语数据集，并通过扩展Tested Slot Guessing方法并结合Min-K%概率分析来检测记忆化行为。同时提出了Translation-Aware Contamination Detection以跨多种翻译版本识别污染。", "result": "研究发现将英语内容翻译成阿拉伯语能够掩盖传统的污染指标，但模型仍会受益于接触了受污染的数据。通过增加多语言能力更强的模型的表现以及提高跨语言答案一致性来证实此结论。", "conclusion": "研究表明，需要建立包含多语言和翻译意识的评估管线以确保大规模语言模型评价的公平性、透明性和可重复性。"}}
{"id": "2601.14993", "pdf": "https://arxiv.org/pdf/2601.14993", "abs": "https://arxiv.org/abs/2601.14993", "authors": ["Danny Segev"], "title": "Economic Warehouse Lot Scheduling: Approximation Schemes via Efficiently-Representable DP-Encoded Policies", "categories": ["cs.DS", "math.OC"], "comment": "arXiv admin note: substantial text overlap with arXiv:2412.11184", "summary": "In this focused technical paper, we present long-awaited algorithmic advances toward the efficient construction of near-optimal replenishment policies for a true inventory management classic, the economic warehouse lot scheduling problem. While this paradigm has accumulated a massive body of surrounding literature since its inception in the late '50s, we are still very much in the dark as far as basic computational questions are concerned, perhaps due to the intrinsic complexity of dynamic policies in this context. The latter feature forced earlier attempts to either study highly-structured classes of policies or to forgo provably-good performance guarantees altogether; to this day, rigorously analyzable results have been few and far between. The current paper develops novel analytical foundations for directly competing against dynamic policies. Combined with further algorithmic progress and newly-gained insights, these ideas culminate in a polynomial-time approximation scheme for constantly-many commodities. In this regard, the efficient design of $ε$-optimal dynamic policies appeared to have been out of reach, since beyond their inherent algorithmic challenges, even the polynomial-space representation of such policies has been a fundamental open question.", "AI": {"tldr": "本文提出了针对经济仓库批量调度问题的近似算法，实现了在多项式时间内设计ε最优动态策略。", "motivation": "尽管经济仓库批量调度问题已有大量文献，但基本计算问题仍然不明确，尤其是如何高效地分析和表示动态策略。", "method": "开发了新的分析基础直接与动态策略竞争，并结合进一步的算法进展和新见解，最终实现了多项式时间近似方案。", "result": "提出了一个针对常量数量商品的多项式时间近似方案。", "conclusion": "研究成功解决了设计ε最优动态策略的问题，并在一定程度上回答了如何用多项式空间表示这些策略的基本问题。"}}
{"id": "2601.14982", "pdf": "https://arxiv.org/pdf/2601.14982", "abs": "https://arxiv.org/abs/2601.14982", "authors": ["David Ricardo Saavedra"], "title": "Interoperable Architecture for Digital Identity Delegation for AI Agents with Blockchain Integration", "categories": ["cs.CR", "cs.AI", "cs.CY"], "comment": "19 pages, 4 figures, 4 tables", "summary": "Verifiable delegation in digital identity systems remains unresolved across centralized, federated, and self-sovereign identity (SSI) environments, particularly where both human users and autonomous AI agents must exercise and transfer authority without exposing primary credentials or private keys. We introduce a unified framework that enables bounded, auditable, and least-privilege delegation across heterogeneous identity ecosystems. The framework includes four key elements: Delegation Grants (DGs), first-class authorization artefacts that encode revocable transfers of authority with enforced scope reduction; a Canonical Verification Context (CVC) that normalizes verification requests into a single structured representation independent of protocols or credential formats; a layered reference architecture that separates trust anchoring, credential and proof validation, policy evaluation, and protocol mediation via a Trust Gateway; and an explicit treatment of blockchain anchoring as an optional integrity layer rather than a structural dependency. Together, these elements advance interoperable delegation and auditability and provide a foundation for future standardization, implementation, and integration of autonomous agents into trusted digital identity infrastructures.", "AI": {"tldr": "本文提出一个统一框架，用于在不同身份生态系统中实现有界、可审计和最小权限的数字身份委派。", "motivation": "当前跨集中式、联邦式和自我主权身份环境，尤其是在人类用户和自主AI代理需要行使并转移权威而不暴露主要凭据或私钥的情况下，数字身份系统的可信委派问题仍未解决。", "method": "框架包含四个关键要素：委托授权（DGs），第一类授权对象，用于编码具有范围缩小的可撤销权威传递；规范验证上下文（CVC），将验证请求归一化为单一结构表示；分层参考架构，通过信任网关分离信任锚定、凭据和证明验证、策略评估与协议中介；以及明确处理区块链作为完整性层的角色。", "result": "这些元素共同推进了可互操作的委派和审计，并为进一步标准化、实施及自主代理在可信数字身份基础设施中的集成提供了基础。", "conclusion": "该框架解决了现有身份系统中数字身份委托的关键挑战，为实现AI代理在不同环境下的安全和高效授权提供了解决方案。"}}
{"id": "2601.14978", "pdf": "https://arxiv.org/pdf/2601.14978", "abs": "https://arxiv.org/abs/2601.14978", "authors": ["Nilanjana Chatterjee", "Sidharatha Garg", "A V Subramanyam", "Brejesh Lall"], "title": "Unified Multi-Dataset Training for TBPS", "categories": ["cs.CV"], "comment": null, "summary": "Text-Based Person Search (TBPS) has seen significant progress with vision-language models (VLMs), yet it remains constrained by limited training data and the fact that VLMs are not inherently pre-trained for pedestrian-centric recognition. Existing TBPS methods therefore rely on dataset-centric fine-tuning to handle distribution shift, resulting in multiple independently trained models for different datasets. While synthetic data can increase the scale needed to fine-tune VLMs, it does not eliminate dataset-specific adaptation. This motivates a fundamental question: can we train a single unified TBPS model across multiple datasets? We show that naive joint training over all datasets remains sub-optimal because current training paradigms do not scale to a large number of unique person identities and are vulnerable to noisy image-text pairs. To address these challenges, we propose Scale-TBPS with two contributions: (i) a noise-aware unified dataset curation strategy that cohesively merges diverse TBPS datasets; and (ii) a scalable discriminative identity learning framework that remains effective under a large number of unique identities. Extensive experiments on CUHK-PEDES, ICFG-PEDES, RSTPReid, IIITD-20K, and UFine6926 demonstrate that a single Scale-TBPS model outperforms dataset-centric optimized models and naive joint training.", "AI": {"tldr": "本文提出了一种名为Scale-TBPS的方法，旨在通过统一的多数据集训练来解决基于文本的人体搜索（TBPS）问题。", "motivation": "现有的TBPS方法依赖于针对特定数据集进行微调，导致需要为不同的数据集训练多个独立模型，这限制了模型的泛化能力。因此，研究者希望探索是否可以通过单一的统一模型处理来自多个数据集的任务。", "method": "本文提出了两个主要贡献：一种能够综合合并多样化TBPS数据集的噪声感知统一数据整理策略；一个在大量独特身份下仍能有效工作的可扩展判别式身份学习框架。", "result": "实验结果表明，单一的Scale-TBPS模型不仅优于针对特定数据集优化的模型，也优于简单的联合训练方法，在多个测试数据集上表现出了优越性。", "conclusion": "研究证明了通过统一多数据集训练可以实现更优的TBPS性能，并提出了一种能够克服现有挑战的有效解决方案。"}}
{"id": "2601.14973", "pdf": "https://arxiv.org/pdf/2601.14973", "abs": "https://arxiv.org/abs/2601.14973", "authors": ["Faryal Batool", "Iana Zhura", "Valerii Serpiva", "Roohan Ahmed Khan", "Ivan Valuev", "Issatay Tokmurziyev", "Dzmitry Tsetserukou"], "title": "HumanDiffusion: A Vision-Based Diffusion Trajectory Planner with Human-Conditioned Goals for Search and Rescue UAV", "categories": ["cs.RO", "cs.AI"], "comment": "This paper has been accepted at HRI, Late Breaking Report, 2026", "summary": "Reliable human--robot collaboration in emergency scenarios requires autonomous systems that can detect humans, infer navigation goals, and operate safely in dynamic environments. This paper presents HumanDiffusion, a lightweight image-conditioned diffusion planner that generates human-aware navigation trajectories directly from RGB imagery. The system combines YOLO-11--based human detection with diffusion-driven trajectory generation, enabling a quadrotor to approach a target person and deliver medical assistance without relying on prior maps or computationally intensive planning pipelines. Trajectories are predicted in pixel space, ensuring smooth motion and a consistent safety margin around humans. We evaluate HumanDiffusion in simulation and real-world indoor mock-disaster scenarios. On a 300-sample test set, the model achieves a mean squared error of 0.02 in pixel-space trajectory reconstruction. Real-world experiments demonstrate an overall mission success rate of 80% across accident-response and search-and-locate tasks with partial occlusions. These results indicate that human-conditioned diffusion planning offers a practical and robust solution for human-aware UAV navigation in time-critical assistance settings.", "AI": {"tldr": "本文介绍了HumanDiffusion，一个基于视觉的扩散轨迹规划器，用于在紧急情况下搜索和救援无人机的人类条件目标导航。", "motivation": "可靠的人机协作需要能够检测人类、推断导航目标并在动态环境中安全操作的自主系统。因此，开发轻量级图像条件扩散计划者以生成基于RGB图像的人类意识导航轨迹。", "method": "该系统结合了YOLO-11的人体检测和扩散驱动的轨迹生成，使四旋翼飞行器能够接近目标人物并提供医疗援助，无需依赖预先绘制的地图或计算密集型规划管道。轨迹在像素空间中预测，确保平滑运动并在人类周围保持一致的安全距离。", "result": "实验结果表明，在一个300样本测试集上，模型的像素空间轨迹重建均方误差为0.02。实际世界实验显示，在事故响应和搜索定位任务中有部分遮挡的情况下，整体任务成功率达到了80%。", "conclusion": "这些结果显示，人类条件扩散规划提供了一种实用且稳健的方法，用于时间紧迫救助环境中的人类意识无人机导航。"}}
{"id": "2601.14968", "pdf": "https://arxiv.org/pdf/2601.14968", "abs": "https://arxiv.org/abs/2601.14968", "authors": ["Mingyue Cheng", "Xiaoyu Tao", "Huajian Zhang", "Qi Liu", "Enhong Chen"], "title": "InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.", "AI": {"tldr": "本文提出InstructTime++框架，通过多模态语言建模和隐式特征增强来改进时间序列分类。", "motivation": "现有时间序列分类方法难以整合上下文特征和捕捉类别的语义关系，因此提出新框架以解决这些问题。", "method": "InstructTime将时间序列转换为文本输出，通过离散化模块、对齐投影层及自监督预训练策略增强跨模态表示；InstructTime++进一步引入隐式特征建模，挖掘原始时间和上下文输入中的有效模式并转化为文本描述。", "result": "在多个基准数据集上的实验表明，InstructTime++具有优越性能。", "conclusion": "通过将时间序列分类问题重新定义为多模态生成任务，并结合隐式特征增强，InstructTime++显著提升了时间序列的分类效果。"}}
{"id": "2601.14960", "pdf": "https://arxiv.org/pdf/2601.14960", "abs": "https://arxiv.org/abs/2601.14960", "authors": ["Florian Grötschla", "Arunasish Sen", "Alessandro Lombardi", "Guillermo Cámbara", "Andreas Schwarz"], "title": "VCNAC: A Variable-Channel Neural Audio Codec for Mono, Stereo, and Surround Sound", "categories": ["cs.SD", "eess.AS"], "comment": "Submitted to EUSIPCO 2026", "summary": "We present VCNAC, a variable channel neural audio codec. Our approach features a single encoder and decoder parametrization that enables native inference for different channel setups, from mono speech to cinematic 5.1 channel surround audio. Channel compatibility objectives ensure that multi-channel content maintains perceptual quality when decoded to fewer channels. The shared representation enables training of generative language models on a single set of codebooks while supporting inference-time scalability across modalities and channel configurations. Evaluation using objective spatial audio metrics and subjective listening tests demonstrates that our unified approach maintains high reconstruction quality across mono, stereo, and surround audio configurations.", "AI": {"tldr": "本文介绍了VCNAC，一种能够处理单声道、立体声和环绕声音频的变通道神经音频编解码器。", "motivation": "动机在于开发一个单一且灵活的音频编解码器框架，可以原生支持不同通道设置下的高质量音频编码与解码。", "method": "方法包括设计一个具有单个编码器和解码器参数化的系统，该系统通过共同表示来训练生成语言模型，并确保多声道内容在减少声道数时仍能保持感知质量。", "result": "评估结果显示，在单声道、立体声和环绕声音频配置下，统一的方法能够维持高质量的重建效果，并通过客观的空间音频度量及主观听测进行验证。", "conclusion": "结论是VCNAC提供了一种有效且灵活的方式来处理不同通道设置下的音频编码与解码任务。"}}
{"id": "2601.14959", "pdf": "https://arxiv.org/pdf/2601.14959", "abs": "https://arxiv.org/abs/2601.14959", "authors": ["Xinyu Peng", "Han Li", "Yuyang Huang", "Ziyang Zheng", "Yaoming Wang", "Xin Chen", "Wenrui Dai", "Chenglin Li", "Junni Zou", "Hongkai Xiong"], "title": "Towards Holistic Modeling for Video Frame Interpolation with Auto-regressive Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Existing video frame interpolation (VFI) methods often adopt a frame-centric approach, processing videos as independent short segments (e.g., triplets), which leads to temporal inconsistencies and motion artifacts. To overcome this, we propose a holistic, video-centric paradigm named \\textbf{L}ocal \\textbf{D}iffusion \\textbf{F}orcing for \\textbf{V}ideo \\textbf{F}rame \\textbf{I}nterpolation (LDF-VFI). Our framework is built upon an auto-regressive diffusion transformer that models the entire video sequence to ensure long-range temporal coherence. To mitigate error accumulation inherent in auto-regressive generation, we introduce a novel skip-concatenate sampling strategy that effectively maintains temporal stability. Furthermore, LDF-VFI incorporates sparse, local attention and tiled VAE encoding, a combination that not only enables efficient processing of long sequences but also allows generalization to arbitrary spatial resolutions (e.g., 4K) at inference without retraining. An enhanced conditional VAE decoder, which leverages multi-scale features from the input video, further improves reconstruction fidelity. Empirically, LDF-VFI achieves state-of-the-art performance on challenging long-sequence benchmarks, demonstrating superior per-frame quality and temporal consistency, especially in scenes with large motion. The source code is available at https://github.com/xypeng9903/LDF-VFI.", "AI": {"tldr": "提出了一种名为LDF-VFI的视频帧插值框架，采用自回归扩散变换器来确保长序列的时间一致性，并通过新颖的跳过拼接采样策略和增强条件VAE解码器提高了性能。", "motivation": "现有的视频帧插值方法往往将视频视为独立的短片段进行处理，导致时间不一致性和运动伪影。为了克服这个问题，研究提出了一种全局、以视频为中心的方法来解决这些问题。", "method": "LDF-VFI框架基于自回归扩散变换器建模整个视频序列，并引入了跳过拼接采样策略以减少误差累积。同时结合稀疏局部注意力机制和瓷砖VAE编码技术，以及增强条件的多尺度特征解码器，提高插值质量和时间一致性。", "result": "在具有挑战性的长序列基准测试中，LDF-VFI展示了优越的帧间质量及时空一致性，尤其在大运动场景中的表现最佳。", "conclusion": "研究证明了提出的LDF-VFI方法能够有效地处理视频帧插值任务，并且在保持时间一致性和减少伪影方面表现出色。"}}
{"id": "2601.14958", "pdf": "https://arxiv.org/pdf/2601.14958", "abs": "https://arxiv.org/abs/2601.14958", "authors": ["Minuri Rajapakse", "Ruvan Weerasinghe"], "title": "A Comprehensive Benchmark of Language Models on Unicode and Romanized Sinhala", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 1 figure, 3 tables", "summary": "The performance of Language Models (LMs) on lower-resource, morphologically rich languages like Sinhala remains under-explored, particularly for Romanized Sinhala, which is prevalent in digital communication. This paper presents a comprehensive benchmark of modern LMs on a diverse corpus of Unicode and Romanized Sinhala. We evaluate open-source models using perplexity, a measure of how well a model predicts a text, and leading closed-source models via a qualitative analysis of sentence completion. Our findings reveal that the Mistral-Nemo-Base-2407 model achieves the strongest predictive performance on Unicode text and the Mistral-7B-v0.3 model for Romanized text. The results also highlight the strong all-around performance of the Llama-3.1-8B model for both scripts. Furthermore, a significant performance disparity exists among closed-source models: Gemini-1.5-pro and DeepSeek excel at Unicode generation, whereas Claude-3.5-Sonnet is superior at handling Romanized text. These results provide an essential guide for practitioners selecting models for Sinhala-specific applications and highlight the critical role of training data in handling script variations.", "AI": {"tldr": "本文对现代语言模型在Unicode和罗马化僧伽罗语上的表现进行了全面的基准测试。", "motivation": "动机在于探索语言模型在资源较少且形态丰富的低资源语言如僧伽罗语的表现，特别是对于数字化通讯中常见的罗马化僧伽罗语。", "method": "使用困惑度来评估开源模型，并通过句子完成质量进行定性分析封闭源模型的性能。", "result": "Mistral-Nemo-Base-2407在Unicode文本上表现最佳，Mistral-7B-v0.3对罗马化文本预测最强。Llama-3.1-8B在两种书写系统中均表现出色。封闭源模型之间存在显著性能差异：Gemini-1.5-pro和DeepSeek擅长于生成Unicode文本，而Claude-3.5-Sonnet则更优处理罗马化文本。", "conclusion": "研究结果为实践者选择针对僧伽罗语应用的语言模型提供了重要指南，并强调了训练数据在处理书写系统变化中的关键作用。"}}
{"id": "2601.14955", "pdf": "https://arxiv.org/pdf/2601.14955", "abs": "https://arxiv.org/abs/2601.14955", "authors": ["Hanqi Jin", "Gaoming Yang", "Zhangming Chan", "Yapeng Yuan", "Longbin Li", "Fei Sun", "Yeqiu Yang", "Jian Wu", "Yuning Jiang", "Bo Zheng"], "title": "Multi-Behavior Sequential Modeling with Transition-Aware Graph Attention Network for E-Commerce Recommendation", "categories": ["cs.AI"], "comment": "Accepted by WWW2026 short paper", "summary": "User interactions on e-commerce platforms are inherently diverse, involving behaviors such as clicking, favoriting, adding to cart, and purchasing. The transitions between these behaviors offer valuable insights into user-item interactions, serving as a key signal for un- derstanding evolving preferences. Consequently, there is growing interest in leveraging multi-behavior data to better capture user intent. Recent studies have explored sequential modeling of multi- behavior data, many relying on transformer-based architectures with polynomial time complexity. While effective, these approaches often incur high computational costs, limiting their applicability in large-scale industrial systems with long user sequences. To address this challenge, we propose the Transition-Aware Graph Attention Network (TGA), a linear-complexity approach for modeling multi-behavior transitions. Unlike traditional trans- formers that treat all behavior pairs equally, TGA constructs a structured sparse graph by identifying informative transitions from three perspectives: (a) item-level transitions, (b) category-level transitions, and (c) neighbor-level transitions. Built upon the structured graph, TGA employs a transition-aware graph Attention mechanism that jointly models user-item interactions and behav- ior transition types, enabling more accurate capture of sequential patterns while maintaining computational efficiency. Experiments show that TGA outperforms all state-of-the-art models while sig- nificantly reducing computational cost. Notably, TGA has been deployed in a large-scale industrial production environment, where it leads to impressive improvements in key business metrics.", "AI": {"tldr": "本文提出了一种基于转换感知图注意力网络（TGA）的方法，用于在电子商务推荐中建模多行为序列。", "motivation": "用户在电商平台上的行为是多样化的，并且这些行为之间的转变可以提供有价值的洞见来理解用户的偏好变化。现有方法使用Transformer架构处理这些问题时存在计算成本高的问题。", "method": "TGA通过从物品级别、类别级别和邻居级别的视角识别有用的转换，构建一个结构化稀疏图，并运用转换感知的图注意力机制共同建模用户-项目交互和行为转变类型。", "result": "实验表明，TGA在所有最先进的模型中表现出色，同时显著降低了计算成本，在大规模工业生产环境中也带来了关键业务指标的重大改进。", "conclusion": "TGA通过线性复杂度方法有效地解决了多行为序列建模中的计算效率问题，并且已经在实际应用中证明了其有效性和优势。"}}
{"id": "2601.14952", "pdf": "https://arxiv.org/pdf/2601.14952", "abs": "https://arxiv.org/abs/2601.14952", "authors": ["Zhiyuan Lu", "Chenliang Li", "Yingcheng Shi", "Weizhou Shen", "Ming Yan", "Fei Huang"], "title": "CorpusQA: A 10 Million Token Benchmark for Corpus-Level Analysis and Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While large language models now handle million-token contexts, their capacity for reasoning across entire document repositories remains largely untested. Existing benchmarks are inadequate, as they are mostly limited to single long texts or rely on a \"sparse retrieval\" assumption-that answers can be derived from a few relevant chunks. This assumption fails for true corpus-level analysis, where evidence is highly dispersed across hundreds of documents and answers require global integration, comparison, and statistical aggregation. To address this critical gap, we introduce CorpusQA, a new benchmark scaling up to 10 million tokens, generated via a novel data synthesis framework. By decoupling reasoning from textual representation, this framework creates complex, computation-intensive queries with programmatically guaranteed ground-truth answers, challenging systems to perform holistic reasoning over vast, unstructured text without relying on fallible human annotation. We further demonstrate the utility of our framework beyond evaluation, showing that fine-tuning on our synthesized data effectively enhances an LLM's general long-context reasoning capabilities. Extensive experiments reveal that even state-of-the-art long-context LLMs struggle as input length increases, and standard retrieval-augmented generation systems collapse entirely. Our findings indicate that memory-augmented agentic architectures offer a more robust alternative, suggesting a critical shift is needed from simply extending context windows to developing advanced architectures for global information synthesis.", "AI": {"tldr": "介绍了一个名为CorpusQA的新基准测试，该测试包含1000万个令牌，用于评估和改进语言模型在大规模语料库级别分析与推理的能力。", "motivation": "当前大型语言模型虽然能处理百万令牌的上下文，但在整个文档仓库中的推理能力尚未得到充分检验。现有的基准测试大多局限于单一长文本或依赖于稀疏检索假设，这不足以评估真正的语料库级别分析。因此，需要一个新的基准来填补这个空白并推动相关研究的发展。", "method": "开发了一个新的数据合成框架，生成包含1000万个令牌的CorpusQA基准测试。该框架通过解耦推理和文本表示创建复杂的计算密集型查询，并保证程序化的地面实况答案，使系统能够进行跨大量非结构化文本的整体推理而不依赖于不可靠的人类标注。", "result": "广泛的实验表明，即使是最先进的长上下文语言模型，在输入长度增加时也表现出困难，标准的检索增强生成系统完全失效。研究还显示，微调合成数据可以有效提升模型的长期上下文推理能力。", "conclusion": "研究表明，记忆增强代理架构提供了更稳健的选择，暗示从简单扩展上下文窗口到开发先进的全球信息综合架构至关重要。"}}
{"id": "2601.14951", "pdf": "https://arxiv.org/pdf/2601.14951", "abs": "https://arxiv.org/abs/2601.14951", "authors": ["Carolin Holtermann", "Nina Krebs", "Anne Lauscher"], "title": "TempViz: On the Evaluation of Temporal Knowledge in Text-to-Image Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Time alters the visual appearance of entities in our world, like objects, places, and animals. Thus, for accurately generating contextually-relevant images, knowledge and reasoning about time can be crucial (e.g., for generating a landscape in spring vs. in winter). Yet, although substantial work exists on understanding and improving temporal knowledge in natural language processing, research on how temporal phenomena appear and are handled in text-to-image (T2I) models remains scarce. We address this gap with TempViz, the first data set to holistically evaluate temporal knowledge in image generation, consisting of 7.9k prompts and more than 600 reference images. Using TempViz, we study the capabilities of five T2I models across five temporal knowledge categories. Human evaluation shows that temporal competence is generally weak, with no model exceeding 75% accuracy across categories. Towards larger-scale studies, we also examine automated evaluation methods, comparing several established approaches against human judgments. However, none of these approaches provides a reliable assessment of temporal cues - further indicating the pressing need for future research on temporal knowledge in T2I.", "AI": {"tldr": "评估文本到图像模型中的时间知识，引入TempViz数据集进行研究。", "motivation": "现有文献对自然语言处理中时间知识的理解和改进已有大量工作，但关于时间现象在文本到图像模型中的表现及处理的研究较少，因此该论文旨在填补这一空白。", "method": "创建了包含7.9k提示语和超过600张参考图像的TempViz数据集，并评估五种T2I模型的时间知识能力。同时探讨自动化评估方法与人类评价之间的差异。", "result": "通过人类评价，发现所有被研究的模型在时间知识方面的能力较弱，没有一个模型能在各类别中超过75%的准确率。", "conclusion": "现有的自动化评估方法无法可靠地评估时间线索，突显了未来研究T2I模型中时间知识的重要性。"}}
{"id": "2601.14950", "pdf": "https://arxiv.org/pdf/2601.14950", "abs": "https://arxiv.org/abs/2601.14950", "authors": ["Yufei Song", "Ziqi Zhou", "Menghao Deng", "Yifan Hu", "Shengshan Hu", "Minghui Li", "Leo Yu Zhang"], "title": "Erosion Attack for Adversarial Training to Enhance Semantic Segmentation Robustness", "categories": ["cs.CV"], "comment": "Accepted by ICASSP 2026", "summary": "Existing segmentation models exhibit significant vulnerability to adversarial attacks.To improve robustness, adversarial training incorporates adversarial examples into model training. However, existing attack methods consider only global semantic information and ignore contextual semantic relationships within the samples, limiting the effectiveness of adversarial training. To address this issue, we propose EroSeg-AT, a vulnerability-aware adversarial training framework that leverages EroSeg to generate adversarial examples. EroSeg first selects sensitive pixels based on pixel-level confidence and then progressively propagates perturbations to higher-confidence pixels, effectively disrupting the semantic consistency of the samples. Experimental results show that, compared to existing methods, our approach significantly improves attack effectiveness and enhances model robustness under adversarial training.", "AI": {"tldr": "本文提出了EroSeg-AT框架，旨在通过考虑上下文语义关系来提高对抗训练中分割模型的鲁棒性。", "motivation": "现有的分割模型容易受到对抗攻击的影响，而现有对抗训练方法仅关注全局语义信息，忽视了样本中的上下文语义关系，导致效果有限。", "method": "提出EroSeg-AT框架，使用EroSeg生成对抗样本，首先选择基于像素级置信度的敏感像素，并逐步向高信心像素传播扰动以破坏样本的语义一致性。", "result": "实验表明，与现有方法相比，本文的方法显著提高了对抗攻击的有效性并增强了模型在对抗训练下的鲁棒性。", "conclusion": "EroSeg-AT框架通过考虑上下文语义关系生成更有效的对抗样本来增强分割模型的鲁棒性。"}}
{"id": "2601.14945", "pdf": "https://arxiv.org/pdf/2601.14945", "abs": "https://arxiv.org/abs/2601.14945", "authors": ["Yuteng Sun", "Haoran Wang", "Ruofei Bai", "Zhengguo Li", "Jun Li", "Meng Yee", "Chuah", "Wei Yun Yau"], "title": "TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Large-scale Vision-Language-Action (VLA) models offer semantic generalization but suffer from high inference latency, limiting them to low-frequency batch-and-execute paradigm. This frequency mismatch creates an execution blind spot, causing failures in dynamic environments where targets move during the open-loop execution window. We propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a hierarchical framework that decouples semantic reasoning from high-frequency actuation. TIDAL operates as a backbone-agnostic module for diffusion-based VLAs, using a dual-frequency architecture to redistribute the computational budget. Specifically, a low-frequency macro-intent loop caches semantic embeddings, while a high-frequency micro-control loop interleaves single-step flow integration with execution. This design enables approximately 9 Hz control updates on edge hardware (vs. approximately 2.4 Hz baselines) without increasing marginal overhead. To handle the resulting latency shift, we introduce a temporally misaligned training strategy where the policy learns predictive compensation using stale semantic intent alongside real-time proprioception. Additionally, we address the insensitivity of static vision encoders to velocity by incorporating a differential motion predictor. TIDAL is architectural, making it orthogonal to system-level optimizations. Experiments show a 2x performance gain over open-loop baselines in dynamic interception tasks. Despite a marginal regression in static success rates, our approach yields a 4x increase in feedback frequency and extends the effective horizon of semantic embeddings beyond the native action chunk size. Under non-paused inference protocols, TIDAL remains robust where standard baselines fail due to latency.", "AI": {"tldr": "本文提出TIDAL框架，解决了大规模视觉语言动作（VLA）模型在动态环境中控制频率低的问题。", "motivation": "现有大型VLA模型虽具备语义泛化能力，但推理延时高，导致其仅适用于低频批处理执行模式，这与动态环境中的高频需求不匹配，造成执行盲点。", "method": "TIDAL是一个层次化的框架，通过双频率架构将语义推理和高频动作驱动分离。它包含一个低频的宏观意图循环和一个高频的微控制循环，后者将单步流程整合与执行交错进行。为处理由此产生的延时偏差，提出了一种时间偏移训练策略，并引入差分运动预测器以提高对速度变化的敏感性。", "result": "实验表明TIDAL在动态拦截任务中性能提升一倍，尽管静态成功率略有下降，但反馈频率提高了四倍，有效延长了语义嵌入的有效作用范围。", "conclusion": "TIDAL框架通过设计上的创新提升了VLA模型在动态环境中的控制能力，并且即使在非暂停推理协议下也能保持鲁棒性，优于传统基准方法。"}}
{"id": "2601.14943", "pdf": "https://arxiv.org/pdf/2601.14943", "abs": "https://arxiv.org/abs/2601.14943", "authors": ["Mathis Brossier", "Tobias Isenberg", "Konrad Schönborn", "Jonas Unger", "Mario Romero", "Johanna Björklund", "Anders Ynnerman", "Lonni Besançon"], "title": "State of the Art of LLM-Enabled Interaction with Visualization", "categories": ["cs.HC"], "comment": null, "summary": "We report on a systematic, PRISMA-guided survey of research at the intersection of LLMs and visualization, with a particular focus on visio-verbal interaction -- where verbal and visual modalities converge to support data sense-making. The emergence of Large Language Models (LLMs) has introduced new paradigms for interacting with data visualizations through natural language, leading to intuitive, multimodal, and accessible interfaces. We analyze 48 papers across six dimensions: application domain, visualization task, visualization representation, interaction modality, LLM integration, and system evaluation. Our classification framework maps LLM roles across the visualization pipeline, from data querying and transformation to visualization generation, explanation, and navigation. We highlight emerging design patterns, identify gaps in accessibility and visualization reading, and discuss the limitations of current LLMs in spatial reasoning and contextual grounding. We further reflect on evaluations of combined LLM-visualization systems, highlighting how current research projects tackle this challenge and discuss current gaps in conducting meaningful evaluations of such systems. With our survey we aim to guide future research and system design in LLM-enhanced visualization, supporting broad audiences and intelligent, conversational interfaces.", "AI": {"tldr": "本文报告了在大型语言模型（LLM）和可视化领域交叉研究的系统综述，重点关注视觉-言语交互。", "motivation": "随着大型语言模型的出现，它们为通过自然语言与数据可视化进行交互提供了新的范式。这促进了直观、多模态和可访问接口的发展。", "method": "文章分析了48篇论文，并从六个维度：应用领域、可视化任务、可视化表示、互动模式、LLM集成和系统评估进行了分类框架的构建，以映射可视化流程中LLM的角色。", "result": "本文突出了新兴的设计模式，指出了可访问性和数据解读方面的差距，并讨论了当前LLM在空间推理和语境定位上的局限性。", "conclusion": "通过此项综述，文章旨在指导未来的研究和系统设计，在增强型可视化中支持更广泛的受众群体及智能会话接口的发展。"}}
{"id": "2601.14931", "pdf": "https://arxiv.org/pdf/2601.14931", "abs": "https://arxiv.org/abs/2601.14931", "authors": ["Nouhoum Coulibaly", "Ousmane Ly", "Michael Leventhal", "Ousmane Goro"], "title": "Generative Artificial Intelligence, Musical Heritage and the Construction of Peace Narratives: A Case Study in Mali", "categories": ["cs.SD", "cs.AI", "cs.CL"], "comment": "12 pages, 2 figures", "summary": "This study explores the capacity of generative artificial intelligence (Gen AI) to contribute to the construction of peace narratives and the revitalization of musical heritage in Mali. The study has been made in a political and social context where inter-community tensions and social fractures motivate a search for new symbolic frameworks for reconciliation. The study empirically explores three questions: (1) how Gen AI can be used as a tool for musical creation rooted in national languages and traditions; (2) to what extent Gen AI systems enable a balanced hybridization between technological innovation and cultural authenticity; and (3) how AI-assisted musical co-creation can strengthen social cohesion and cultural sovereignty. The experimental results suggest that Gen AI, embedded in a culturally conscious participatory framework, can act as a catalyst for symbolic diplomacy, amplifying local voices instead of standardizing them. However, challenges persist regarding the availability of linguistic corpora, algorithmic censorship, and the ethics of generating compositions derived from copyrighted sources.", "AI": {"tldr": "研究探讨了生成式人工智能在马里构建和平叙事和振兴音乐遗产方面的潜力。", "motivation": "在政治和社会背景下，社区间的紧张关系和社会裂痕促使寻找新的象征框架以促进和解。", "method": "通过实证研究探索三个问题：如何利用Gen AI作为基于国家语言和传统的音乐创作工具；AI系统如何实现技术创新与文化真实性之间的平衡；以及AI辅助的音乐共创如何加强社会凝聚力和文化主权。", "result": "实验结果表明，嵌入在文化意识参与框架中的生成式人工智能可以充当象征性外交的催化剂，放大本地声音而非标准化。", "conclusion": "尽管存在语言语料库可用性、算法审查和从受版权保护来源生成作品的伦理问题等挑战，但研究证明了Gen AI在促进和平与文化共融方面的作用。"}}
{"id": "2601.14925", "pdf": "https://arxiv.org/pdf/2601.14925", "abs": "https://arxiv.org/abs/2601.14925", "authors": ["Nicolás Arrieta Larraza", "Niels de Koeijer"], "title": "Fast-ULCNet: A fast and ultra low complexity network for single-channel speech enhancement", "categories": ["eess.AS", "cs.AI"], "comment": "©2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "summary": "Single-channel speech enhancement algorithms are often used in resource-constrained embedded devices, where low latency and low complexity designs gain more importance. In recent years, researchers have proposed a wide variety of novel solutions to this problem. In particular, a recent deep learning model named ULCNet is among the state-of-the-art approaches in this domain. This paper proposes an adaptation of ULCNet, by replacing its GRU layers with FastGRNNs, to reduce both computational latency and complexity. Furthermore, this paper shows empirical evidence on the performance decay of FastGRNNs in long audio signals during inference due to internal state drifting, and proposes a novel approach based on a trainable complementary filter to mitigate it. The resulting model, Fast-ULCNet, performs on par with the state-of-the-art original ULCNet architecture on a speech enhancement task, while reducing its model size by more than half and decreasing its latency by 34% on average.", "AI": {"tldr": "本文提出Fast-ULCNet，一种快速且超低复杂度的单通道语音增强网络。", "motivation": "在资源受限的嵌入式设备中，低延迟和低复杂度设计更为重要。研究者提出了多种解决方案，其中ULCNet是该领域的最新方法之一。为了进一步减少计算延迟和复杂度，本文提出改进ULCNet的方法。", "method": "通过将ULCNet中的GRU层替换为FastGRNN，减少计算延迟和复杂度。此外，针对长音频信号推理过程中FastGRNN内部状态漂移导致性能下降的问题，提出了基于可训练互补滤波器的新方法来缓解这一问题。", "result": "实验结果表明，与原始的ULCNet相比，Fast-ULCNet在语音增强任务上的表现相当，同时模型大小减少了超过一半，并且延迟平均降低了34%。", "conclusion": "本文提出的Fast-ULCNet通过改进ULCNet，在保持高性能的同时显著减小了模型复杂度和计算延迟，适用于资源受限的嵌入式设备环境。"}}
{"id": "2601.14921", "pdf": "https://arxiv.org/pdf/2601.14921", "abs": "https://arxiv.org/abs/2601.14921", "authors": ["Sarat Ahmad", "Maryam Hafeez", "Syed Ali Raza Zaidi"], "title": "Vision-Language Models on the Edge for Real-Time Robotic Perception", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) enable multimodal reasoning for robotic perception and interaction, but their deployment in real-world systems remains constrained by latency, limited onboard resources, and privacy risks of cloud offloading. Edge intelligence within 6G, particularly Open RAN and Multi-access Edge Computing (MEC), offers a pathway to address these challenges by bringing computation closer to the data source. This work investigates the deployment of VLMs on ORAN/MEC infrastructure using the Unitree G1 humanoid robot as an embodied testbed. We design a WebRTC-based pipeline that streams multimodal data to an edge node and evaluate LLaMA-3.2-11B-Vision-Instruct deployed at the edge versus in the cloud under real-time conditions. Our results show that edge deployment preserves near-cloud accuracy while reducing end-to-end latency by 5\\%. We further evaluate Qwen2-VL-2B-Instruct, a compact model optimized for resource-constrained environments, which achieves sub-second responsiveness, cutting latency by more than half but at the cost of accuracy.", "AI": {"tldr": "本研究探讨了在6G边缘智能框架下使用Unitree G1人形机器人部署Vision-Language模型（VLMs）的可行性。", "motivation": "为了克服视觉语言模型在实际应用中面临的延迟、有限的计算资源和隐私风险等问题，研究通过边缘计算技术来优化这些限制。", "method": "设计了一个基于WebRTC的数据流管道，将多模态数据传输到边缘节点，并评估了部署在边缘的LLaMA-3.2-11B-Vision-Instruct模型与云部署下的性能。同时测试了针对资源受限环境进行优化的小型模型Qwen2-VL-2B-Instruct。", "result": "边缘计算部署保持了接近云端的精度，将端到端延迟减少了5%；Qwen2-VL-2B-Instruct实现了亚秒响应速度，大幅降低了延迟，但精度有所降低。", "conclusion": "该研究证明了在6G边缘智能环境中使用视觉语言模型的有效性和可行性，并表明针对资源受限环境优化的小型模型能够提供更快的响应时间。"}}
{"id": "2601.14917", "pdf": "https://arxiv.org/pdf/2601.14917", "abs": "https://arxiv.org/abs/2601.14917", "authors": ["Giorgia Rigamonti", "Mirko Paolo Barbato", "Davide Marelli", "Paolo Napoletano"], "title": "Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.", "AI": {"tldr": "本文提出了一种基于深度学习的个性化血糖预测方法，以提高1型糖尿病患者在现实场景中的不良事件预测准确性。", "motivation": "有效管理1型糖尿病需要持续监测血糖和精确调整胰岛素剂量来防止高血糖和低血糖。随着可穿戴葡萄糖监测器和移动健康应用的普及，准确的血糖预测对于增强自动化的胰岛素输送和决策支持系统至关重要。", "method": "研究采用了深度学习方法，并使用患者特异性数据进行个性化血糖预测。通过Leave-One-Subject-Out交叉验证与微调策略来评估它们对个体动态模型的能力。此外，还进行了多模态、患者特定的方法与传统CGM单模态方法的比较实验。", "result": "结果表明，个性化的模型在不良事件预测方面显著提高准确性，支持更精准和及时的干预措施。", "conclusion": "研究发现突显了适应性个性化血糖预测模型在推进下一代糖尿病管理中的潜力，特别是对于可穿戴设备和移动健康平台上的消费者导向型糖尿病护理解决方案。"}}
{"id": "2601.14901", "pdf": "https://arxiv.org/pdf/2601.14901", "abs": "https://arxiv.org/abs/2601.14901", "authors": ["Nadine Meertens", "Suet Lee", "Ophelia Deroy"], "title": "Just aware enough: Evaluating awareness across artificial systems", "categories": ["cs.AI"], "comment": "24 pages (including references), 1 figure", "summary": "Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.", "AI": {"tldr": "本文提出了一种评估人工智能系统意识的方法，侧重于系统的感知能力。", "motivation": "当前关于AI的讨论多集中在AI意识和道德地位上，但缺乏共识。作者认为应将重点转移到更易于处理的意识评估上。", "method": "文章介绍了一个实用方法来评估跨不同系统的意识水平，该方法强调了领域敏感性、可扩展性、多维度性和任务性能预测能力。", "result": "提出了一个结构化的方法来评价和比较具有不同架构、规模和操作领域的系统中的感知配置文件。", "conclusion": "通过将重点从人工意识转移到‘足够感知’，这一方法旨在促进科学评估，支持设计监督，并推动更加建设性的科学和社会对话。"}}
{"id": "2601.14895", "pdf": "https://arxiv.org/pdf/2601.14895", "abs": "https://arxiv.org/abs/2601.14895", "authors": ["Xinyi Zheng", "Yunze Liu", "Chi-Hao Wu", "Fan Zhang", "Hao Zheng", "Wenqi Zhou", "Walterio W. Mayol-Cuevas", "Junxiao Shen"], "title": "SpatialMem: Unified 3D Memory with Metric Anchoring and Fast Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present SpatialMem, a memory-centric system that unifies 3D geometry, semantics, and language into a single, queryable representation. Starting from casually captured egocentric RGB video, SpatialMem reconstructs metrically scaled indoor environments, detects structural 3D anchors (walls, doors, windows) as the first-layer scaffold, and populates a hierarchical memory with open-vocabulary object nodes -- linking evidence patches, visual embeddings, and two-layer textual descriptions to 3D coordinates -- for compact storage and fast retrieval. This design enables interpretable reasoning over spatial relations (e.g., distance, direction, visibility) and supports downstream tasks such as language-guided navigation and object retrieval without specialized sensors. Experiments across three real-life indoor scenes demonstrate that SpatialMem maintains strong anchor-description-level navigation completion and hierarchical retrieval accuracy under increasing clutter and occlusion, offering an efficient and extensible framework for embodied spatial intelligence.", "AI": {"tldr": "SpatialMem 是一个将 3D 几何、语义和语言统一到单一可查询表示的内存为中心系统，适用于室内环境下的语言引导导航和对象检索任务。", "motivation": "该研究旨在通过创建一个能够解释空间关系并支持下游任务（如语言引导导航和对象检索）的高效且可扩展框架来解决传统方法中对专用传感器的需求。", "method": "SpatialMem 从随意捕捉的第一人称 RGB 视频开始，重建度量缩放的室内环境，并检测3D锚点作为第一层支架。它以分层内存的形式存储开放词汇对象节点，这些节点链接证据补丁、视觉嵌入和双层文本描述到 3D 坐标。", "result": "实验结果表明，在三个真实生活场景中增加杂乱和遮挡的情况下，SpatialMem 维持了强大的锚点-描述级别导航完成度和层级检索准确性。", "conclusion": "研究证明了 SpatialMem 在不依赖专用传感器的情况下提供高效且可扩展的框架进行空间智能处理的能力。"}}
{"id": "2601.14894", "pdf": "https://arxiv.org/pdf/2601.14894", "abs": "https://arxiv.org/abs/2601.14894", "authors": ["Nicolas Lazzari", "Valentina Presutti", "Antonio Vergari"], "title": "To Neuro-Symbolic Classification and Beyond by Compiling Description Logic Ontologies to Probabilistic Circuits", "categories": ["cs.AI"], "comment": "Manuscript under review", "summary": "Background: Neuro-symbolic methods enhance the reliability of neural network classifiers through logical constraints, but they lack native support for ontologies. Objectives: We aim to develop a neuro-symbolic method that reliably outputs predictions consistent with a Description Logic ontology that formalizes domain-specific knowledge. Methods: We encode a Description Logic ontology as a circuit, a feed-forward differentiable computational graph that supports tractable execution of queries and transformations. We show that the circuit can be used to (i) generate synthetic datasets that capture the semantics of the ontology; (ii) efficiently perform deductive reasoning on a GPU; (iii) implement neuro-symbolic models whose predictions are approximately or provably consistent with the knowledge defined in the ontology. Results We show that the synthetic dataset generated using the circuit qualitatively captures the semantics of the ontology while being challenging for Machine Learning classifiers, including neural networks. Moreover, we show that compiling the ontology into a circuit is a promising approach for scalable deductive reasoning, with runtimes up to three orders of magnitude faster than available reasoners. Finally, we show that our neuro-symbolic classifiers reliably produce consistent predictions when compared to neural network baselines, maintaining competitive performances or even outperforming them. Conclusions By compiling Description Logic ontologies into circuits, we obtain a tighter integration between the Deep Learning and Knowledge Representation fields. We show that a single circuit representation can be used to tackle different challenging tasks closely related to real-world applications.", "AI": {"tldr": "本文提出了一种将描述逻辑本体编译为概率电路的方法，用于生成神经符号分类器并实现可靠预测。", "motivation": "神经符号方法通过逻辑约束增强了神经网络分类的可靠性，但缺乏对本体论的支持，旨在开发一种神经符号方法以输出与描述逻辑本体一致的预测。", "method": "将描述逻辑本体编码为电路，这是一种支持查询和转换可追踪执行的前向可微计算图，并展示了电路可以用于生成合成数据集、高效进行演绎推理以及实现神经符号模型。", "result": "电路生成的数据集能够定性地捕捉本体的语义并挑战机器学习分类器；编译本体到电路的方法在可扩展性演绎推理方面具有显著优势，且运行时间快三个数量级；神经符号分类器产生的预测比神经网络基准更一致。", "conclusion": "将描述逻辑本体编译为电路能够实现深度学习和知识表示领域的紧密集成，单一的电路表示可用于解决与实际应用密切相关的挑战性任务。"}}
{"id": "2601.14891", "pdf": "https://arxiv.org/pdf/2601.14891", "abs": "https://arxiv.org/abs/2601.14891", "authors": ["Christina Schneegass", "Francesco Chiossi", "Anna L. Cox", "Dimitra Dritsa", "Teodora Mitrevska", "Stephen Rainey", "Max L. Wilson"], "title": "The CHI26 Workshop on the Future of Cognitive Personal Informatics", "categories": ["cs.HC"], "comment": "ef:Extended Abstracts of the 2026 CHI Conference on Human Factors in Computing Systems (CHI EA '26)", "summary": "Research on Cognitive Personal Informatics (CPI) is steadily growing as new wearable cognitive tracking technologies emerge on the consumer market, claiming to measure stress, focus, and other cognitive factors. At the same time, with generative AI offering new ways to analyse, visualize, and interpret cognitive data, we hypothesize that cognitive tracking will soon become as simple as measuring your heart rate during a run. Yet, cognitive data remains inherently more complex, context-dependent, and less well understood than physical activity data. This workshop brings together HCI experts to discuss critical questions, including: How can complex cognitive data be translated into meaningful metrics? How can AI support users' data sensemaking without over-simplifying cognitive insights? How can we design inclusive CPI technologies that consider inter-personal variance and neurodiversity? We will map", "AI": {"tldr": "本次研讨会汇集了人机交互领域的专家，旨在探讨认知个人数据分析中的关键问题。", "motivation": "随着新的可穿戴的认知跟踪技术进入市场以及生成式AI在分析和解释认知数据方面的潜力，研究者们希望探讨如何将复杂的数据转化为有意义的指标，并设计包容性的人工智能技术来支持用户理解这些数据。", "method": "研讨会通过专家讨论的形式，针对关键问题进行深入交流。", "result": "研讨会提出了关于如何处理复杂认知数据、使用AI辅助数据分析以及设计考虑个人差异和神经多样性的CPI技术的问题。", "conclusion": "会议强调了在认知个人数据分析领域面临的挑战，并指出了未来研究的方向。"}}
{"id": "2601.14888", "pdf": "https://arxiv.org/pdf/2601.14888", "abs": "https://arxiv.org/abs/2601.14888", "authors": ["Keyu Lv", "Manyi Zhang", "Xiaobo Xia", "Jingchen Ni", "Shannan Yan", "Xianzhi Yu", "Lu Hou", "Chun Yuan", "Haoli Bai"], "title": "What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) for reasoning models. Our key findings include: (1) Knowledge distillation is a robust objective for reasoning models trained via either supervised fine-tuning or reinforcement learning; (2) PTQ provides a strong initialization for QAT, improving accuracy while reducing training cost; (3) Reinforcement learning remains feasible for quantized models given a viable cold start and yields additional gains; and (4) Aligning the PTQ calibration domain with the QAT training domain accelerates convergence and often improves the final accuracy. Finally, we consolidate these findings into an optimized workflow (Reasoning-QAT), and show that it consistently outperforms state-of-the-art PTQ methods across multiple LLM backbones and reasoning datasets. For instance, on Qwen3-0.6B, it surpasses GPTQ by 44.53% on MATH-500 and consistently recovers performance in the 2-bit regime.", "AI": {"tldr": "本文研究了量化感知训练（QAT）在推理大型语言模型（LLM）中的应用，并提出了一种优化工作流程Reasoning-QAT。", "motivation": "推理模型在复杂任务上表现出色，但在推断时效率低下。传统的后训练量化（PTQ）会导致准确性下降，尤其是低位设置下的推理任务。为了提高推理效率和保持准确性，本文研究了如何改进量化感知训练。", "method": "通过系统性的实证研究，分析了知识蒸馏、PTQ初始化、强化学习和领域对齐在优化推理模型上的效果，并整合这些发现形成一个优化工作流程Reasoning-QAT。", "result": "实验结果表明，Reasoning-QAT在多个大型语言模型骨干和推理数据集上都优于现有的PTQ方法。例如，在Qwen3-0.6B模型上，相比GPTQ在MATH-500上的表现提升了44.53%，并且在2位设置中恢复了性能。", "conclusion": "本文通过系统性的研究发现了几个关键因素来提高量化感知训练的效率和准确性，并提出了一种优化的工作流程Reasoning-QAT，该流程显著提高了推理模型的表现。"}}
{"id": "2601.14875", "pdf": "https://arxiv.org/pdf/2601.14875", "abs": "https://arxiv.org/abs/2601.14875", "authors": ["Zhe Chang", "Haodong Jin", "Ying Sun", "Yan Song", "Hui Yu"], "title": "GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "High-fidelity 4D dynamic facial avatar reconstruction from monocular video is a critical yet challenging task, driven by increasing demands for immersive virtual human applications. While Neural Radiance Fields (NeRF) have advanced scene representation, their capacity to capture high-frequency facial details, such as dynamic wrinkles and subtle textures from information-constrained monocular streams, requires significant enhancement. To tackle this challenge, we propose a novel hybrid neural radiance field framework, called Geometry-Aware-Transformer Enhanced NeRF (GAT-NeRF) for high-fidelity and controllable 4D facial avatar reconstruction, which integrates the Transformer mechanism into the NeRF pipeline. GAT-NeRF synergistically combines a coordinate-aligned Multilayer Perceptron (MLP) with a lightweight Transformer module, termed as Geometry-Aware-Transformer (GAT) due to its processing of multi-modal inputs containing explicit geometric priors. The GAT module is enabled by fusing multi-modal input features, including 3D spatial coordinates, 3D Morphable Model (3DMM) expression parameters, and learnable latent codes to effectively learn and enhance feature representations pertinent to fine-grained geometry. The Transformer's effective feature learning capabilities are leveraged to significantly augment the modeling of complex local facial patterns like dynamic wrinkles and acne scars. Comprehensive experiments unequivocally demonstrate GAT-NeRF's state-of-the-art performance in visual fidelity and high-frequency detail recovery, forging new pathways for creating realistic dynamic digital humans for multimedia applications.", "AI": {"tldr": "本文提出了GAT-NeRF，一种结合Transformer机制的新型混合神经辐射场框架，用于从单目视频中生成高保真度4D动态面部化身。", "motivation": "由于对沉浸式虚拟人类应用的需求日益增加，从信息受限的单目流中重建高质量4D动态面部化身是一个关键但具有挑战性的任务。现有的NeRF技术在捕捉高频面部细节方面能力不足。", "method": "GAT-NeRF结合了坐标对齐的多层感知器(MLP)和轻量级Transformer模块，该模块处理包含显式几何先验的多模态输入，通过融合3D空间坐标、3DMM表情参数和可学习的潜在代码来增强特征表示。", "result": "实验结果表明GAT-NeRF在视觉保真度和高频细节恢复方面达到了最先进的性能。", "conclusion": "GAT-NeRF框架为创建逼真的动态数字人类开辟了新的途径，特别适用于多媒体应用。"}}
{"id": "2601.14874", "pdf": "https://arxiv.org/pdf/2601.14874", "abs": "https://arxiv.org/abs/2601.14874", "authors": ["Yara Mahmoud", "Yasheerah Yaqoot", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "HumanoidVLM: Vision-Language-Guided Impedance Control for Contact-Rich Humanoid Manipulation", "categories": ["cs.RO"], "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "Humanoid robots must adapt their contact behavior to diverse objects and tasks, yet most controllers rely on fixed, hand-tuned impedance gains and gripper settings. This paper introduces HumanoidVLM, a vision-language driven retrieval framework that enables the Unitree G1 humanoid to select task-appropriate Cartesian impedance parameters and gripper configurations directly from an egocentric RGB image. The system couples a vision-language model for semantic task inference with a FAISS-based Retrieval-Augmented Generation (RAG) module that retrieves experimentally validated stiffness-damping pairs and object-specific grasp angles from two custom databases, and executes them through a task-space impedance controller for compliant manipulation. We evaluate HumanoidVLM on 14 visual scenarios and achieve a retrieval accuracy of 93%. Real-world experiments show stable interaction dynamics, with z-axis tracking errors typically within 1-3.5 cm and virtual forces consistent with task-dependent impedance settings. These results demonstrate the feasibility of linking semantic perception with retrieval-based control as an interpretable path toward adaptive humanoid manipulation.", "AI": {"tldr": "本文介绍了HumanoidVLM，一个基于视觉和语言的检索框架，使Unitree G1人形机器人能够从第一视角RGB图像中选择适当的笛卡尔阻抗参数和夹具配置。", "motivation": "大多数控制器依赖于固定的、手工调谐的阻抗增益和夹具设置，无法适应多样的物体和任务，因此提出了一个基于视觉语言的方法来实现自适应的人形机器人操作。", "method": "系统将用于语义任务推理的视觉-语言模型与FAISS检索增强生成模块结合，从两个定制数据库中检索出实验验证过的刚度阻尼对和特定对象的抓握角度，并通过任务空间阻抗控制器执行以实现柔顺操作。", "result": "在14个视觉场景下实现了93%的检索准确率；现实世界试验表明了稳定的交互动态，z轴跟踪误差通常保持在1-3.5厘米内且虚拟力与任务相关的阻抗设置一致。", "conclusion": "该研究表明将语义感知与基于检索的控制联系起来作为实现自适应人形机器人操作的可解释路径是可行的。"}}
{"id": "2601.14871", "pdf": "https://arxiv.org/pdf/2601.14871", "abs": "https://arxiv.org/abs/2601.14871", "authors": ["Zejian Cui", "Ferdinando Rodriguez y Baena"], "title": "On-the-fly hand-eye calibration for the da Vinci surgical robot", "categories": ["cs.RO"], "comment": "16 pages, 13 figures", "summary": "In Robot-Assisted Minimally Invasive Surgery (RMIS), accurate tool localization is crucial to ensure patient safety and successful task execution. However, this remains challenging for cable-driven robots, such as the da Vinci robot, because erroneous encoder readings lead to pose estimation errors. In this study, we propose a calibration framework to produce accurate tool localization results through computing the hand-eye transformation matrix on-the-fly. The framework consists of two interrelated algorithms: the feature association block and the hand-eye calibration block, which provide robust correspondences for key points detected on monocular images without pre-training, and offer the versatility to accommodate various surgical scenarios by adopting an array of filter approaches, respectively. To validate its efficacy, we test the framework extensively on publicly available video datasets that feature multiple surgical instruments conducting tasks in both in vitro and ex vivo scenarios, under varying illumination conditions and with different levels of key point measurement accuracy. The results show a significant reduction in tool localization errors under the proposed calibration framework, with accuracies comparable to other state-of-the-art methods while being more time-efficient.", "AI": {"tldr": "提出了一种用于达芬奇手术机器人的实时手眼标定框架，以提高工具定位精度。", "motivation": "在机器人辅助微创手术中，准确的工具定位对于确保患者安全和任务执行的成功至关重要。然而，由于错误的编码器读数导致的姿态估计误差使得这项工作对电缆驱动的机器人而言具有挑战性。", "method": "该框架由两个互相关联的算法组成：特征关联模块和手眼标定模块。前者在单目图像上提供鲁棒的关键点对应关系，无需预训练；后者通过采用多种滤波方法以适应各种手术场景。", "result": "实验验证了所提框架的有效性，在公开视频数据集上的测试中展示了显著降低工具定位误差的能力，并且其准确性与其它最先进的方法相当，同时具有更高的时间效率。", "conclusion": "提出的实时手眼标定框架能够有效提升达芬奇手术机器人在不同光照条件和关键点测量精度下的工具定位精度。"}}
{"id": "2601.14850", "pdf": "https://arxiv.org/pdf/2601.14850", "abs": "https://arxiv.org/abs/2601.14850", "authors": ["Viola Negroni", "Luca Cuccovillo", "Paolo Bestagini", "Patrick Aichroth", "Stefano Tubaro"], "title": "Multi-Tast Transformer for Explainable Speech Deepfake Detection via Formant Modeling", "categories": ["cs.SD"], "comment": "Accepted @ IEEE ICASSP 2026", "summary": "In this work, we introduce a multi-task transformer for speech deepfake detection, capable of predicting formant trajectories and voicing patterns over time, ultimately classifying speech as real or fake, and highlighting whether its decisions rely more on voiced or unvoiced regions. Building on a prior speaker-formant transformer architecture, we streamline the model with an improved input segmentation strategy, redesign the decoding process, and integrate built-in explainability. Compared to the baseline, our model requires fewer parameters, trains faster, and provides better interpretability, without sacrificing prediction performance.", "AI": {"tldr": "本文介绍了一个用于可解释语音深度伪造检测的多任务变压器，该模型能够预测随时间变化的形式轨迹和发声模式，并最终分类语音为真实或伪造。", "motivation": "为了提高语音深伪检测的准确性和可解释性，同时减少参数量和加快训练速度。", "method": "基于先前的说话人-形式变换器架构，改进了输入分割策略，重新设计了解码过程，并集成了内置可解释性。", "result": "与基线模型相比，该模型需要更少的参数，训练更快，并且提供了更好的解释能力，同时没有牺牲预测性能。", "conclusion": "提出了一个高效的多任务变压器模型，不仅提高了语音深伪检测的效果和速度，还增强了结果的可解释性。"}}
{"id": "2601.14848", "pdf": "https://arxiv.org/pdf/2601.14848", "abs": "https://arxiv.org/abs/2601.14848", "authors": ["Mohamed Abouras", "Catherine M. Elias"], "title": "From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.RO"], "comment": null, "summary": "On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.", "AI": {"tldr": "使用多层LSTM架构预测高速公路出入口车辆变道行为。", "motivation": "研究较少关注的高速公路上下匝道区域，通过减少不确定性提高道路安全。", "method": "利用ExiD无人机数据集训练基于多层LSTM的模型，并测试不同的预测时间和模型流程。", "result": "在4秒以内的预测时间内表现良好，出入口区域准确率达到约76%，一般高速场景下可达94%。", "conclusion": "多层LSTM架构能够有效提高高速公路出入口车辆行为预测的准确性，有助于提升道路安全。"}}
{"id": "2601.14844", "pdf": "https://arxiv.org/pdf/2601.14844", "abs": "https://arxiv.org/abs/2601.14844", "authors": ["Zhe Chang", "Haodong Jin", "Yan Song", "Hui Yu"], "title": "CAG-Avatar: Cross-Attention Guided Gaussian Avatars for High-Fidelity Head Reconstruction", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "Creating high-fidelity, real-time drivable 3D head avatars is a core challenge in digital animation. While 3D Gaussian Splashing (3D-GS) offers unprecedented rendering speed and quality, current animation techniques often rely on a \"one-size-fits-all\" global tuning approach, where all Gaussian primitives are uniformly driven by a single expression code. This simplistic approach fails to unravel the distinct dynamics of different facial regions, such as deformable skin versus rigid teeth, leading to significant blurring and distortion artifacts. We introduce Conditionally-Adaptive Gaussian Avatars (CAG-Avatar), a framework that resolves this key limitation. At its core is a Conditionally Adaptive Fusion Module built on cross-attention. This mechanism empowers each 3D Gaussian to act as a query, adaptively extracting relevant driving signals from the global expression code based on its canonical position. This \"tailor-made\" conditioning strategy drastically enhances the modeling of fine-grained, localized dynamics. Our experiments confirm a significant improvement in reconstruction fidelity, particularly for challenging regions such as teeth, while preserving real-time rendering performance.", "AI": {"tldr": "论文介绍了CAG-Avatar框架，用于实现高保真的实时三维头部重建。", "motivation": "现有的动画技术依赖于一种“一刀切”的全局调优方法，这会导致面部不同区域（如皮肤和牙齿）的动态细节丢失，从而产生模糊和扭曲的伪影。", "method": "提出了一种基于交叉注意力的条件自适应融合模块，使每个3D高斯能够根据其规范位置从全局表情代码中提取相关驱动信号。", "result": "实验结果表明，该方法显著提高了重建保真度，尤其是在牙齿等具有挑战性的区域，同时保持了实时渲染性能。", "conclusion": "CAG-Avatar框架通过引入条件自适应机制解决了现有技术中的关键限制，提升了面部区域的高保真动态建模能力。"}}
{"id": "2601.14841", "pdf": "https://arxiv.org/pdf/2601.14841", "abs": "https://arxiv.org/abs/2601.14841", "authors": ["Sidi Mohamed Sid El Moctar", "Achraf Ait Laydi", "Yousef El Mourabit", "Hélène Bouvrais"], "title": "MTFlow: Time-Conditioned Flow Matching for Microtubule Segmentation in Noisy Microscopy Images", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for presentation at ISBI 2026", "summary": "Microtubules are cytoskeletal filaments that play essential roles in many cellular processes and are key therapeutic targets in several diseases. Accurate segmentation of microtubule networks is critical for studying their organization and dynamics but remains challenging due to filament curvature, dense crossings, and image noise. We present MTFlow, a novel time-conditioned flow-matching model for microtubule segmentation. Unlike conventional U-Net variants that predict masks in a single pass, MTFlow learns vector fields that iteratively transport noisy masks toward the ground truth, enabling interpretable, trajectory-based refinement. Our architecture combines a U-Net backbone with temporal embeddings, allowing the model to capture the dynamics of uncertainty resolution along filament boundaries. We trained and evaluated MTFlow on synthetic and real microtubule datasets and assessed its generalization capability on public biomedical datasets of curvilinear structures such as retinal blood vessels and nerves. MTFlow achieves competitive segmentation accuracy comparable to state-of-the-art models, offering a powerful and time-efficient tool for filamentous structure analysis with more precise annotations than manual or semi-automatic approaches.", "AI": {"tldr": "本文介绍了MTFlow，一种用于在噪声显微镜图像中分割微管的时空条件流匹配模型。", "motivation": "准确分割微管网络对于研究其组织和动力学至关重要，但由于微管线条弯曲、密集交叉以及图像噪音等问题，这一任务具有挑战性。", "method": "MTFlow通过学习迭代运输噪声掩码向真值方向靠近的矢量场来实现微管网络的精准分割，结合了U-Net骨架与时间嵌入以捕捉不确定性解析的动力学。", "result": "在合成和真实数据集上训练和评估了MTFlow，并在其对公共生物医学数据集中曲线结构如视网膜血管和神经上的泛化能力方面展示了竞争性的分割准确度。", "conclusion": "MTFlow提供了一种高效、精确的工具，用于丝状结构分析，其注释精度优于手动或半自动方法。"}}
{"id": "2601.14840", "pdf": "https://arxiv.org/pdf/2601.14840", "abs": "https://arxiv.org/abs/2601.14840", "authors": ["Abdelrhman Bassiouny", "Tom Schierenbeck", "Sorin Arion", "Benjamin Alt", "Naren Vasantakumaar", "Giang Nguyen", "Michael Beetz"], "title": "Implementing Knowledge Representation and Reasoning with Object Oriented Design", "categories": ["cs.AI", "cs.RO", "cs.SE"], "comment": "9 pages, 2 figures, submitted to the 2026 International Joint Conference on Artificial Intelligence (IJCAI)", "summary": "This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.", "AI": {"tldr": "介绍了一个名为KRROOD的框架，旨在将知识表示与推理系统无缝集成到面向对象编程中。", "motivation": "现有知识表示与推理系统依赖于外部本体和特殊语言，难以与命令式代码融合，导致软件开发复杂。", "method": "通过使用本地类结构将知识作为第一级编程抽象处理来构建KRROOD框架，并将其应用于OWL2Bench基准测试和人类机器人任务学习场景中进行评估。", "result": "实验结果表明，KRROOD在支持现实世界自主系统所需的表达性推理的同时表现良好。", "conclusion": "KRROOD成功地弥合了逻辑编程与面向对象编程之间的差距，并为开发复杂应用提供了一个有效的解决方案。"}}
{"id": "2601.14837", "pdf": "https://arxiv.org/pdf/2601.14837", "abs": "https://arxiv.org/abs/2601.14837", "authors": ["B. Calmé", "N. J. Greenidge", "A. Metcalf", "A. Bacchetti", "G. Loza", "D. Kpeglo", "P. Lloyd", "V. Pensabene", "J. H. Chandler", "P. Valdastri"], "title": "Moving Beyond Compliance in Soft-Robotic Catheters Through Modularity for Precision Therapies", "categories": ["cs.RO"], "comment": "31 pages, 6 figures, 7 supplementary figures", "summary": "Soft robotic instruments could navigate delicate, tortuous anatomy more safely than rigid tools, but clinical adoption is limited by insufficient tip functionalization and real-time feedback at the tissue interface. Few sensing and therapeutic modules are compact, robust, and adaptable enough to measure, and respond to, subtle physiological cues during intraluminal procedures. We present a 1.47 mm diameter modular soft robotic catheter that integrates sensing, actuation, and therapy while retaining the compliance needed for safe endoluminal navigation. Validated across multiple in vivo settings, we emphasize its utility in endoscopic retrograde cholangiopancreatography (ERCP), a highly technical procedure and a key access route to the pancreas, an organ that is fragile, difficult to instrument, and central to diseases such as pancreatic cancer. Our architecture supports up to four independently controlled functional units, allowing customizable combinations of anchoring, manipulation, sensing, and targeted drug delivery. In a live porcine model, we demonstrate semi-autonomous deployment into the pancreatic duct and 7.5 cm of endoscopic navigation within it, a region currently inaccessible with standard catheters. A closed-loop autonomous/shared-control system that combines a learned model, magnetic actuation, onboard shape sensing, and visual marker tracking further improves cannulation accuracy. Together, these results establish a scalable platform for multifunctional soft robotic catheters and a new paradigm for complex endoluminal interventions, with potential to reduce radiation exposure, shorten training, and accelerate clinical translation of soft robotic technologies.", "AI": {"tldr": "本文介绍了一种直径为1.47毫米的模块化软体机器人导管，该导管集成了传感、驱动和治疗功能，并在多个体内环境中进行了验证。", "motivation": "现有刚性工具在导航复杂解剖结构时存在风险，且临床应用受限于不足的功能尖端设计和实时反馈机制。因此，开发一种能够安全导航并适应生理变化的软体机器人导管具有重要意义。", "method": "提出了一种集成传感、驱动与治疗功能的1.47毫米直径模块化软体机器人导管，并通过半自主部署在猪模型中的胰腺导管内进行了演示，展示了其在体内环境下的性能。", "result": "实验结果表明该系统能够在胰腺导管内部进行长达7.5厘米的内窥导航操作，这在过去使用标准导管时是无法实现的。同时，闭合回路自主/共享控制系统提升了穿刺准确性。", "conclusion": "研究建立了一种多功能软体机器人导管的可扩展平台，并为复杂腔道介入手术提供了一个新的范式，有望减少辐射暴露、缩短培训时间并加速临床转化进程。"}}
{"id": "2601.14827", "pdf": "https://arxiv.org/pdf/2601.14827", "abs": "https://arxiv.org/abs/2601.14827", "authors": ["Ben Schaper", "Maxime Di Folco", "Bernhard Kainz", "Julia A. Schnabel", "Cosmin I. Bercea"], "title": "Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies", "categories": ["cs.AI"], "comment": null, "summary": "Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.", "AI": {"tldr": "本文探讨了如何利用医学分类学来量化和减轻视觉语言模型在胸部X光片分类中的抽象错误。", "motivation": "现有的扁平度量标准无法区分临床轻微和严重的错误，因此研究通过引入分层度量方法来解决这一问题，并提出新的评估方式和训练策略以提高模型的临床适用性。", "method": "本文使用了多种最先进的视觉语言模型进行基准测试，并提出了Catastrophic Abstraction Errors来捕获跨分支错误。还采用了风险约束阈值技术和基于径向嵌入的分类学意识微调方法。", "result": "研究结果揭示尽管扁平性能较高，但这些模型与临床分类法存在显著不匹配现象。通过所提方法，严重的抽象误差被减少至2%以下的同时保持了竞争力的表现。", "conclusion": "该研究表明分层评估和表征级别对齐的重要性，以确保视觉语言模型在医疗领域的安全和更具有临床意义的部署。"}}
{"id": "2601.14822", "pdf": "https://arxiv.org/pdf/2601.14822", "abs": "https://arxiv.org/abs/2601.14822", "authors": ["Volodymyr Sydorskyi", "Igor Krashenyi", "Oleksii Yakubenko"], "title": "Multimodal system for skin cancer detection", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to System research and information technologies", "summary": "Melanoma detection is vital for early diagnosis and effective treatment. While deep learning models on dermoscopic images have shown promise, they require specialized equipment, limiting their use in broader clinical settings. This study introduces a multi-modal melanoma detection system using conventional photo images, making it more accessible and versatile. Our system integrates image data with tabular metadata, such as patient demographics and lesion characteristics, to improve detection accuracy. It employs a multi-modal neural network combining image and metadata processing and supports a two-step model for cases with or without metadata. A three-stage pipeline further refines predictions by boosting algorithms and enhancing performance. To address the challenges of a highly imbalanced dataset, specific techniques were implemented to ensure robust training. An ablation study evaluated recent vision architectures, boosting algorithms, and loss functions, achieving a peak Partial ROC AUC of 0.18068 (0.2 maximum) and top-15 retrieval sensitivity of 0.78371. Results demonstrate that integrating photo images with metadata in a structured, multi-stage pipeline yields significant performance improvements. This system advances melanoma detection by providing a scalable, equipment-independent solution suitable for diverse healthcare environments, bridging the gap between specialized and general clinical practices.", "AI": {"tldr": "开发了一种多模态皮肤癌检测系统，结合常规照片图像和表格元数据以提高检测准确性。", "motivation": "深度学习模型在皮肤病灶图片上显示了潜力，但需要专用设备限制其广泛使用。该研究旨在通过引入一种更便捷和多样化的解决方案来填补专业与普通临床实践之间的差距。", "method": "系统采用多模态神经网络处理图像数据及元数据，并支持有无元数据的双步模型。此外，还利用三阶段管道进一步优化预测并通过特定技术解决高度不平衡的数据集问题。", "result": "研究通过部分ROC AUC达到0.18068（最大值为0.2）和前15个检索敏感性达到0.78371来验证方法的有效性，证明了结合照片图像与元数据的多阶段管道在性能提升上的显著效果。", "conclusion": "该系统提供了一种可扩展、不依赖设备的解决方案，适用于各种医疗环境。它通过多模态处理和优化算法有效提高了皮肤癌检测准确性，并推进了早期诊断和治疗的有效性。"}}
{"id": "2601.14821", "pdf": "https://arxiv.org/pdf/2601.14821", "abs": "https://arxiv.org/abs/2601.14821", "authors": ["Bert Ramlot", "Martijn Courteaux", "Peter Lambert", "Glenn Van Wallendael"], "title": "POTR: Post-Training 3DGS Compression", "categories": ["cs.CV"], "comment": "15 pages, 12 figures. Submitted to IEEE TCSVT, under review", "summary": "3D Gaussian Splatting (3DGS) has recently emerged as a promising contender to Neural Radiance Fields (NeRF) in 3D scene reconstruction and real-time novel view synthesis. 3DGS outperforms NeRF in training and inference speed but has substantially higher storage requirements. To remedy this downside, we propose POTR, a post-training 3DGS codec built on two novel techniques. First, POTR introduces a novel pruning approach that uses a modified 3DGS rasterizer to efficiently calculate every splat's individual removal effect simultaneously. This technique results in 2-4x fewer splats than other post-training pruning techniques and as a result also significantly accelerates inference with experiments demonstrating 1.5-2x faster inference than other compressed models. Second, we propose a novel method to recompute lighting coefficients, significantly reducing their entropy without using any form of training. Our fast and highly parallel approach especially increases AC lighting coefficient sparsity, with experiments demonstrating increases from 70% to 97%, with minimal loss in quality. Finally, we extend POTR with a simple fine-tuning scheme to further enhance pruning, inference, and rate-distortion performance. Experiments demonstrate that POTR, even without fine-tuning, consistently outperforms all other post-training compression techniques in both rate-distortion performance and inference speed.", "AI": {"tldr": "本文提出了POTR，一种针对3DGS模型的压缩技术，在减少存储需求的同时不牺牲性能。", "motivation": "尽管3DGS在训练和推理速度上优于NeRF，但其存储要求较高。为解决这一问题，作者提出POTR以减少存储开销。", "method": "POTR包括两种新颖的技术：1.一种高效的剪枝方法，使用修改后的3DGS光栅化器计算每个点云删除的影响；2.重新计算光照系数的方法，提高其稀疏性。此外，引入简单的微调方案进一步提升性能。", "result": "实验显示，POTR比其他压缩技术减少了2-4倍的点云数量，推理速度提高了1.5-2倍，并增加了AC光照系数的稀疏性，从70%提高到97%，且质量损失很小。", "conclusion": "即使不进行微调，POTR在压缩性能和推理速度方面也优于其他所有后训练压缩技术。"}}
{"id": "2601.14809", "pdf": "https://arxiv.org/pdf/2601.14809", "abs": "https://arxiv.org/abs/2601.14809", "authors": ["Muhammad Adel Yusuf", "Ali Nasir", "Zeeshan Hameed Khan"], "title": "Stochastic Decision-Making Framework for Human-Robot Collaboration in Industrial Applications", "categories": ["cs.RO"], "comment": "Under Review by IEEE Transactions on Human Machine Systems", "summary": "Collaborative robots, or cobots, are increasingly integrated into various industrial and service settings to work efficiently and safely alongside humans. However, for effective human-robot collaboration, robots must reason based on human factors such as motivation level and aggression level. This paper proposes an approach for decision-making in human-robot collaborative (HRC) environments utilizing stochastic modeling. By leveraging probabilistic models and control strategies, the proposed method aims to anticipate human actions and emotions, enabling cobots to adapt their behavior accordingly. So far, most of the research has been done to detect the intentions of human co-workers. This paper discusses the theoretical framework, implementation strategies, simulation results, and potential applications of the bilateral collaboration approach for safety and efficiency in collaborative robotics.", "AI": {"tldr": "本文提出了一种基于随机建模的决策框架，以提高人机协作环境中的安全性与效率。", "motivation": "为了实现有效的人机协作，机器人必须根据人类因素（如动机水平和攻击性水平）进行推理。现有的大部分研究主要集中在检测人类同事的意图。", "method": "利用概率模型和控制策略，提出的方法旨在预测人的动作和情绪，使协作机器人能够相应地调整其行为。", "result": "本文讨论了理论框架、实现策略、模拟结果以及潜在的应用场景，以确保人机协作环境的安全性和效率。", "conclusion": "所提出的双边协作方法在提高协作机器人的安全性和工作效率方面展示了潜力。"}}
{"id": "2601.14804", "pdf": "https://arxiv.org/pdf/2601.14804", "abs": "https://arxiv.org/abs/2601.14804", "authors": ["Tobias Weißberg", "Weikang Wang", "Paul Roetzer", "Nafie El Amrani", "Florian Bernard"], "title": "Symmetry Informative and Agnostic Feature Disentanglement for 3D Shapes", "categories": ["cs.CV"], "comment": "Accepted at 3DV 2026", "summary": "Shape descriptors, i.e., per-vertex features of 3D meshes or point clouds, are fundamental to shape analysis. Historically, various handcrafted geometry-aware descriptors and feature refinement techniques have been proposed. Recently, several studies have initiated a new research direction by leveraging features from image foundation models to create semantics-aware descriptors, demonstrating advantages across tasks like shape matching, editing, and segmentation. Symmetry, another key concept in shape analysis, has also attracted increasing attention. Consequently, constructing symmetry-aware shape descriptors is a natural progression. Although the recent method $χ$ (Wang et al., 2025) successfully extracted symmetry-informative features from semantic-aware descriptors, its features are only one-dimensional, neglecting other valuable semantic information. Furthermore, the extracted symmetry-informative feature is usually noisy and yields small misclassified patches. To address these gaps, we propose a feature disentanglement approach which is simultaneously symmetry informative and symmetry agnostic. Further, we propose a feature refinement technique to improve the robustness of predicted symmetry informative features. Extensive experiments, including intrinsic symmetry detection, left/right classification, and shape matching, demonstrate the effectiveness of our proposed framework compared to various state-of-the-art methods, both qualitatively and quantitatively.", "AI": {"tldr": "提出一种同时具备对称性信息和对称性无关特征解缠方法，以改进现有3D形状描述符。", "motivation": "现有的方法在提取对称性相关特征时存在维度单一、噪声大且预测不准确的问题，因此需要一个更有效的特征解缠和优化框架来提升3D形状分析性能。", "method": "提出一种同时具备对称性信息和对称性无关的特征解缠方法，并引入了一种特征细化技术以提高预测对称性相关特征的鲁棒性。", "result": "实验表明，所提出的框架在内在对称检测、左右分类和形状匹配任务上都优于现有的最先进方法，无论是定性分析还是定量分析。", "conclusion": "研究表明，通过特征解缠和细化技术可以有效提升3D形状的对称性和其他语义信息提取的准确性和鲁棒性。"}}
{"id": "2601.14802", "pdf": "https://arxiv.org/pdf/2601.14802", "abs": "https://arxiv.org/abs/2601.14802", "authors": ["Donnate Hooft", "Stefan M. Fischer", "Cosmin Bercea", "Jan C. Peeken", "Julia A. Schnabel"], "title": "LocBAM: Advancing 3D Patch-Based Image Segmentation by Integrating Location Contex", "categories": ["cs.CV"], "comment": "Accepted at ISBI 2026", "summary": "Patch-based methods are widely used in 3D medical image segmentation to address memory constraints in processing high-resolution volumetric data. However, these approaches often neglect the patch's location within the global volume, which can limit segmentation performance when anatomical context is important. In this paper, we investigate the role of location context in patch-based 3D segmentation and propose a novel attention mechanism, LocBAM, that explicitly processes spatial information. Experiments on BTCV, AMOS22, and KiTS23 demonstrate that incorporating location context stabilizes training and improves segmentation performance, particularly under low patch-to-volume coverage where global context is missing. Furthermore, LocBAM consistently outperforms classical coordinate encoding via CoordConv. Code is publicly available at https://github.com/compai-lab/2026-ISBI-hooft", "AI": {"tldr": "本论文介绍了LocBAM，一种通过集成位置上下文来改进三维补丁图像分割的新注意力机制。", "motivation": "传统的基于补丁的方法在处理高分辨率体积数据时忽视了补丁在全球体积中的位置信息，限制了其在解剖学背景重要的情况下的分割性能。", "method": "提出了一种新的注意机制LocBAM，该机制显式地处理空间信息。", "result": "实验表明，在BTCV、AMOS22和KiTS23数据集上，集成位置上下文可以稳定训练并提高分割性能，特别是在低补丁体积覆盖率的情况下表现更佳。此外，LocBAM在这些数据集中一致优于经典的坐标编码方法CoordConv。", "conclusion": "集成位置上下文信息的LocBAM能够显著提升三维图像补丁分割的效果，并且具有更好的全局一致性。"}}
{"id": "2601.14799", "pdf": "https://arxiv.org/pdf/2601.14799", "abs": "https://arxiv.org/abs/2601.14799", "authors": ["Qihua Liang", "Liang Chen", "Yaozong Zheng", "Jian Nong", "Zhiyi Mo", "Bineng Zhong"], "title": "UBATrack: Spatio-Temporal State Space Model for General Multi-Modal Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Multi-modal object tracking has attracted considerable attention by integrating multiple complementary inputs (e.g., thermal, depth, and event data) to achieve outstanding performance. Although current general-purpose multi-modal trackers primarily unify various modal tracking tasks (i.e., RGB-Thermal infrared, RGB-Depth or RGB-Event tracking) through prompt learning, they still overlook the effective capture of spatio-temporal cues. In this work, we introduce a novel multi-modal tracking framework based on a mamba-style state space model, termed UBATrack. Our UBATrack comprises two simple yet effective modules: a Spatio-temporal Mamba Adapter (STMA) and a Dynamic Multi-modal Feature Mixer. The former leverages Mamba's long-sequence modeling capability to jointly model cross-modal dependencies and spatio-temporal visual cues in an adapter-tuning manner. The latter further enhances multi-modal representation capacity across multiple feature dimensions to improve tracking robustness. In this way, UBATrack eliminates the need for costly full-parameter fine-tuning, thereby improving the training efficiency of multi-modal tracking algorithms. Experiments show that UBATrack outperforms state-of-the-art methods on RGB-T, RGB-D, and RGB-E tracking benchmarks, achieving outstanding results on the LasHeR, RGBT234, RGBT210, DepthTrack, VOT-RGBD22, and VisEvent datasets.", "AI": {"tldr": "本文提出了UBATrack，一个基于状态空间模型的多模态跟踪框架，用于捕捉跨模态依赖和时空视觉线索。", "motivation": "尽管现有的通用多模态追踪器主要通过提示学习统一多种模式的跟踪任务（如RGB-热红外、RGB-深度或RGB-事件跟踪），但它们仍然忽视了有效捕获时空线索的重要性。", "method": "UBATrack包括两个模块：Spatio-temporal Mamba Adapter（STMA）和Dynamic Multi-modal Feature Mixer。前者利用Mamba的长序列建模能力来联合建模跨模式依赖性和时空视觉线索；后者进一步增强多模态表示能力以提高跟踪鲁棒性。", "result": "实验表明，UBATrack在RGB-T、RGB-D和RGB-E追踪基准上优于现有的方法，并在多个数据集（如LasHeR、RGBT234、RGBT210、DepthTrack、VOT-RGBD22和VisEvent）上取得了出色的结果。", "conclusion": "UBATrack通过有效捕捉时空线索并提高多模态表示能力，改进了跟踪的鲁棒性，并且提高了训练效率。"}}
{"id": "2601.14797", "pdf": "https://arxiv.org/pdf/2601.14797", "abs": "https://arxiv.org/abs/2601.14797", "authors": ["Qingling Shu", "Sibao Chen", "Wei Lu", "Zhihui You", "Chengzhuang Liu"], "title": "UniRoute: Unified Routing Mixture-of-Experts for Modality-Adaptive Remote Sensing Change Detection", "categories": ["cs.CV"], "comment": null, "summary": "Current remote sensing change detection (CD) methods mainly rely on specialized models, which limits the scalability toward modality-adaptive Earth observation. For homogeneous CD, precise boundary delineation relies on fine-grained spatial cues and local pixel interactions, whereas heterogeneous CD instead requires broader contextual information to suppress speckle noise and geometric distortions. Moreover, difference operator (e.g., subtraction) works well for aligned homogeneous images but introduces artifacts in cross-modal or geometrically misaligned scenarios. Across different modality settings, specialized models based on static backbones or fixed difference operations often prove insufficient. To address this challenge, we propose UniRoute, a unified framework for modality-adaptive learning by reformulating feature extraction and fusion as conditional routing problems. We introduce an Adaptive Receptive Field Routing MoE (AR2-MoE) module to disentangle local spatial details from global semantic context, and a Modality-Aware Difference Routing MoE (MDR-MoE) module to adaptively select the most suitable fusion primitive at each pixel. In addition, we propose a Consistency-Aware Self-Distillation (CASD) strategy that stabilizes unified training under data-scarce heterogeneous settings by enforcing multi-level consistency. Extensive experiments on five public datasets demonstrate that UniRoute achieves strong overall performance, with a favorable accuracy-efficiency trade-off under a unified deployment setting.", "AI": {"tldr": "本文提出了UniRoute，一个统一的路由混合专家框架，用于适应不同模态的遥感变化检测。", "motivation": "现有的遥感变化检测方法主要依赖于专门化的模型，在多模态自适应地球观测方面存在局限性。这些模型在同质和异质变化检测中分别需要精细的空间线索、局部像素交互以及广泛的内容信息以抑制斑点噪声和几何失真。", "method": "UniRoute通过将特征提取和融合重新表述为条件路由问题，引入了自适应感受野路由混合专家（AR2-MoE）模块来分离局部空间细节与全局语义背景，并采用模态感知差异路由混合专家（MDR-MoE）模块以在每个像素上自适应选择最合适的融合原语。此外，还提出了一种一致性感知的自我蒸馏策略（CASD），通过强制多级一致性来稳定统一训练过程。", "result": "大量的实验表明，UniRoute在五个公共数据集上表现出了强大的整体性能，并且在一个统一部署设置下实现了良好的准确性和效率权衡。", "conclusion": "UniRoute通过其创新的路由混合专家机制和自适应学习策略，在多模态遥感变化检测中提供了一种有效的解决方案，展现了高精度和计算效率之间的良好平衡。"}}
{"id": "2601.14791", "pdf": "https://arxiv.org/pdf/2601.14791", "abs": "https://arxiv.org/abs/2601.14791", "authors": ["Ziyao Ling", "Silvia Mirri", "Paola Salomoni", "Giovanni Delnevo"], "title": "Synthetic Data Augmentation for Multi-Task Chinese Porcelain Classification: A Stable Diffusion Approach", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The scarcity of training data presents a fundamental challenge in applying deep learning to archaeological artifact classification, particularly for the rare types of Chinese porcelain. This study investigates whether synthetic images generated through Stable Diffusion with Low-Rank Adaptation (LoRA) can effectively augment limited real datasets for multi-task CNN-based porcelain classification. Using MobileNetV3 with transfer learning, we conducted controlled experiments comparing models trained on pure real data against those trained on mixed real-synthetic datasets (95:5 and 90:10 ratios) across four classification tasks: dynasty, glaze, kiln and type identification. Results demonstrate task-specific benefits: type classification showed the most substantial improvement (5.5\\% F1-macro increase with 90:10 ratio), while dynasty and kiln tasks exhibited modest gains (3-4\\%), suggesting that synthetic augmentation effectiveness depends on the alignment between generated features and task-relevant visual signatures. Our work contributes practical guidelines for deploying generative AI in archaeological research, demonstrating both the potential and limitations of synthetic data when archaeological authenticity must be balanced with data diversity.", "AI": {"tldr": "研究使用生成的合成图像增强稀有的中国瓷器分类数据集，并评估其在多任务CNN模型中的效果。", "motivation": "由于训练数据稀缺，深度学习应用于考古文物分类面临挑战。特别是对于罕见类型的中国瓷器，本研究旨在探讨使用Stable Diffusion技术生成的合成图像是否能够有效提升多任务分类性能。", "method": "采用MobileNetV3结合迁移学习，在四个分类任务（朝代、釉料、窑口和类型）中比较了纯实数据与不同比例混合了合成图像的数据集训练模型的效果，包括95:5和90:10的比例。", "result": "结果显示不同类型识别的F1-macro得分有显著提升(使用90:10比率时增加了5.5%)；朝代和窑口任务表现略有提高（3-4%）。这表明合成数据的有效性取决于生成特征与任务相关视觉签名的一致性。", "conclusion": "研究表明，尽管存在局限性，但通过生成的图像增强有限的真实数据集可以在考古研究中实际应用，并提供有关如何在保持考古真实性和增加数据多样性之间取得平衡的实际指导。"}}
{"id": "2601.14790", "pdf": "https://arxiv.org/pdf/2601.14790", "abs": "https://arxiv.org/abs/2601.14790", "authors": ["Zhi Qiu", "Jiazheng Sun", "Chenxiao Xia", "Jun Zheng", "Xin Peng"], "title": "CI4A: Semantic Component Interfaces for Agents Empowering Web Automation", "categories": ["cs.AI"], "comment": "9 pages, 5 figures", "summary": "While Large Language Models demonstrate remarkable proficiency in high-level semantic planning, they remain limited in handling fine-grained, low-level web component manipulations. To address this limitation, extensive research has focused on enhancing model grounding capabilities through techniques such as Reinforcement Learning. However, rather than compelling agents to adapt to human-centric interfaces, we propose constructing interaction interfaces specifically optimized for agents. This paper introduces Component Interface for Agent (CI4A), a semantic encapsulation mechanism that abstracts the complex interaction logic of UI components into a set of unified tool primitives accessible to agents. We implemented CI4A within Ant Design, an industrial-grade front-end framework, covering 23 categories of commonly used UI components. Furthermore, we developed a hybrid agent featuring an action space that dynamically updates according to the page state, enabling flexible invocation of available CI4A tools. Leveraging the CI4A-integrated Ant Design, we refactored and upgraded the WebArena benchmark to evaluate existing SoTA methods. Experimental results demonstrate that the CI4A-based agent significantly outperforms existing approaches, achieving a new SoTA task success rate of 86.3%, alongside substantial improvements in execution efficiency.", "AI": {"tldr": "提出CI4A，一种为Web自动化设计的语义组件接口机制。", "motivation": "大型语言模型在高层次语义规划中表现出色，但在处理细粒度、低级别的web组件操作时存在局限。为此，研究团队试图通过构建优化的交互界面来改进代理的能力。", "method": "CI4A将UI组件的复杂交互逻辑抽象为一组统一的工具原语，并将其集成到Ant Design前端框架中。开发了一种动态更新动作空间以适应页面状态的混合代理，能够灵活调用这些CI4A工具。", "result": "在CI4A整合的Ant Design基础上重制和升级了WebArena基准测试，实验结果表明，基于CI4A的代理显著优于现有方法，实现了86.3%的新最佳任务成功率，并提高了执行效率。", "conclusion": "CI4A通过构建语义封装机制优化了代理的操作界面，为解决大型语言模型在低级别web组件操作中的局限性提供了有效方案。"}}
{"id": "2601.14788", "pdf": "https://arxiv.org/pdf/2601.14788", "abs": "https://arxiv.org/abs/2601.14788", "authors": ["Yifei Liu", "Changxing Ding", "Ling Guo", "Huaiguang Jiang", "Qiong Cao"], "title": "Reconstruction-Anchored Diffusion Model for Text-to-Motion Generation", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models have seen widespread adoption for text-driven human motion generation and related tasks due to their impressive generative capabilities and flexibility. However, current motion diffusion models face two major limitations: a representational gap caused by pre-trained text encoders that lack motion-specific information, and error propagation during the iterative denoising process. This paper introduces Reconstruction-Anchored Diffusion Model (RAM) to address these challenges. First, RAM leverages a motion latent space as intermediate supervision for text-to-motion generation. To this end, RAM co-trains a motion reconstruction branch with two key objective functions: self-regularization to enhance the discrimination of the motion space and motion-centric latent alignment to enable accurate mapping from text to the motion latent space. Second, we propose Reconstructive Error Guidance (REG), a testing-stage guidance mechanism that exploits the diffusion model's inherent self-correction ability to mitigate error propagation. At each denoising step, REG uses the motion reconstruction branch to reconstruct the previous estimate, reproducing the prior error patterns. By amplifying the residual between the current prediction and the reconstructed estimate, REG highlights the improvements in the current prediction. Extensive experiments demonstrate that RAM achieves significant improvements and state-of-the-art performance. Our code will be released.", "AI": {"tldr": "本文提出了一种基于重建锚定的扩散模型（RAM）用于文本到动作生成，通过引入一个运动潜在空间作为中间监督，并在测试阶段使用重建误差引导机制来减少错误传播。", "motivation": "当前的动作扩散模型面临两个主要挑战：预训练文本编码器缺乏特定于动作的信息导致表示差距和迭代去噪过程中的错误传播。本文旨在解决这些问题，提高文本驱动的人类动作生成的性能。", "method": "RAM使用一个运动潜在空间作为中间监督，并共同训练一个运动重建分支以增强运动空间的区分性和实现准确从文本到运动潜在空间的映射。此外，提出Reconstructive Error Guidance（REG）在测试阶段通过放大当前预测和重建估计之间的残差来减少错误传播。", "result": "实验结果表明RAM实现了显著改进，并达到了最先进的性能水平。", "conclusion": "本文提出的RAM和REG机制有效解决了现有模型的局限性，提高了文本到动作生成的质量。"}}
{"id": "2601.14786", "pdf": "https://arxiv.org/pdf/2601.14786", "abs": "https://arxiv.org/abs/2601.14786", "authors": ["Wei-Jaw Lee", "Fang-Chih Hsieh", "Xuanjun Chen", "Fang-Duo Tsai", "Yi-Hsuan Yang"], "title": "Training-Efficient Text-to-Music Generation with State-Space Modeling", "categories": ["cs.SD", "cs.AI"], "comment": "9 pages, 3 figures. This is a preprint of a paper submitted to IEEE/ACM TASLP", "summary": "Recent advances in text-to-music generation (TTM) have yielded high-quality results, but often at the cost of extensive compute and the use of large proprietary internal data. To improve the affordability and openness of TTM training, an open-source generative model backbone that is more training- and data-efficient is needed. In this paper, we constrain the number of trainable parameters in the generative model to match that of the MusicGen-small benchmark (with about 300M parameters), and replace its Transformer backbone with the emerging class of state-space models (SSMs). Specifically, we explore different SSM variants for sequence modeling, and compare a single-stage SSM-based design with a decomposable two-stage SSM/diffusion hybrid design. All proposed models are trained from scratch on a purely public dataset comprising 457 hours of CC-licensed music, ensuring full openness. Our experimental findings are three-fold. First, we show that SSMs exhibit superior training efficiency compared to the Transformer counterpart. Second, despite using only 9% of the FLOPs and 2% of the training data size compared to the MusicGen-small benchmark, our model achieves competitive performance in both objective metrics and subjective listening tests based on MusicCaps captions. Finally, our scaling-down experiment demonstrates that SSMs can maintain competitive performance relative to the Transformer baseline even at the same training budget (measured in iterations), when the model size is reduced to four times smaller. To facilitate the democratization of TTM research, the processed captions, model checkpoints, and source code are available on GitHub via the project page: https://lonian6.github.io/ssmttm/.", "AI": {"tldr": "本文研究了如何通过状态空间模型（SSMs）提高文本到音乐生成任务的训练效率和数据效率。", "motivation": "为了改进文本到音乐生成（TTM）领域的成本效益和开放性，需要开发一种更高效的开源生成模型。", "method": "作者们将生成模型中的可训练参数限制为MusicGen-small基准的水平，并用状态空间模型替换其Transformer主干。研究了不同类型的SSMs用于序列建模，并比较了一阶段SSM设计与两阶段SSM/扩散混合设计。", "result": "实验表明，尽管使用了较少的计算量和数据，本文提出的模型在客观指标和主观听觉测试中均达到与MusicGen-small基准相当或更好的性能。此外，在减少四倍模型规模的情况下仍能保持竞争力。", "conclusion": "状态空间模型相较于Transformer具有更高的训练效率，并且可以在更少的数据和计算资源下实现优秀的文本到音乐生成效果，推动了TTM研究的民主化发展。"}}
{"id": "2601.14784", "pdf": "https://arxiv.org/pdf/2601.14784", "abs": "https://arxiv.org/abs/2601.14784", "authors": ["Amaury Guichard", "Laurent Michel", "Hélène Verhaeghe", "Pierre Schaus"], "title": "Towards Bound Consistency for the No-Overlap Constraint Using MDDs", "categories": ["cs.AI"], "comment": null, "summary": "Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \\mid r_j, d_j, \\bar{d}_j \\mid \\sum E_j + \\sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.", "AI": {"tldr": "本文提出了第一个针对无重叠约束的边界一致性算法，该算法基于MDD并通过限制宽度实现有效过滤。", "motivation": "由于实现无重叠约束的边界一致性问题是NP完全问题，因此引入多项式时间紧缩技术以改进约束处理。", "method": "利用Ciré和van Hoeve定义的无重叠MDD提取任务的时间窗口边界，并通过限制MDD宽度创建放松的MDD进行过滤。", "result": "实验表明，即使有限制宽度阈值的情况下，所提出的过滤方法仍能显著减少搜索树中的节点数，优于先前的方法。", "conclusion": "新的过滤方法与传统无重叠约束传播方法互补，大幅减少了多个实例中的节点数和求解时间。"}}
{"id": "2601.14780", "pdf": "https://arxiv.org/pdf/2601.14780", "abs": "https://arxiv.org/abs/2601.14780", "authors": ["Anqi Li", "Yuqian Chen", "Yu Lu", "Zhaoming Chen", "Yuan Xie", "Zhenzhong Lan"], "title": "RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 2 figures", "summary": "Recognizing and navigating client resistance is critical for effective mental health counseling, yet detecting such behaviors is particularly challenging in text-based interactions. Existing NLP approaches oversimplify resistance categories, ignore the sequential dynamics of therapeutic interventions, and offer limited interpretability. To address these limitations, we propose PsyFIRE, a theoretically grounded framework capturing 13 fine-grained resistance behaviors alongside collaborative interactions. Based on PsyFIRE, we construct the ClientResistance corpus with 23,930 annotated utterances from real-world Chinese text-based counseling, each supported by context-specific rationales. Leveraging this dataset, we develop RECAP, a two-stage framework that detects resistance and fine-grained resistance types with explanations. RECAP achieves 91.25% F1 for distinguishing collaboration and resistance and 66.58% macro-F1 for fine-grained resistance categories classification, outperforming leading prompt-based LLM baselines by over 20 points. Applied to a separate counseling dataset and a pilot study with 62 counselors, RECAP reveals the prevalence of resistance, its negative impact on therapeutic relationships and demonstrates its potential to improve counselors' understanding and intervention strategies.", "AI": {"tldr": "本文介绍了RECAP框架，该框架利用大规模语言模型在文本形式的心理健康咨询中识别和分类客户抵抗行为。", "motivation": "现有的NLP方法在检测治疗过程中的抵制行为方面存在过度简化、忽略干预动态性和解释能力有限的问题。因此，本研究提出了一种新的框架PsyFIRE来解决这些问题。", "method": "基于PsyFIRE构建了一个包含23,930个真实世界中文文本咨询注释语料库，使用这个数据集开发了RECAP两阶段框架，用于识别和解释客户抵抗行为的类型。", "result": "RECAP在区分合作和抵制方面的F1值为91.25%，细粒度抵抗类别分类的宏观F1值为66.58%，比领先的提示式LLM基线高出超过20点。", "conclusion": "实验表明，RECAP能够揭示抵抗行为的普遍性及其对治疗关系的负面影响，并有潜力提升咨询师的理解和干预策略。"}}
{"id": "2601.14777", "pdf": "https://arxiv.org/pdf/2601.14777", "abs": "https://arxiv.org/abs/2601.14777", "authors": ["Jiaxuan Liu", "Yang Xiang", "Han Zhao", "Xiangang Li", "Zhenhua Ling"], "title": "FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Movie dubbing is the task of synthesizing speech from scripts conditioned on video scenes, requiring accurate lip sync, faithful timbre transfer, and proper modeling of character identity and emotion. However, existing methods face two major limitations: (1) high-quality multimodal dubbing datasets are limited in scale, suffer from high word error rates, contain sparse annotations, rely on costly manual labeling, and are restricted to monologue scenes, all of which hinder effective model training; (2) existing dubbing models rely solely on the lip region to learn audio-visual alignment, which limits their applicability to complex live-action cinematic scenes, and exhibit suboptimal performance in lip sync, speech quality, and emotional expressiveness. To address these issues, we propose FunCineForge, which comprises an end-to-end production pipeline for large-scale dubbing datasets and an MLLM-based dubbing model designed for diverse cinematic scenes. Using the pipeline, we construct the first Chinese television dubbing dataset with rich annotations, and demonstrate the high quality of these data. Experiments across monologue, narration, dialogue, and multi-speaker scenes show that our dubbing model consistently outperforms SOTA methods in audio quality, lip sync, timbre transfer, and instruction following. Code and demos are available at https://anonymous.4open.science/w/FunCineForge.", "AI": {"tldr": "本文提出FunCineForge，一个用于零样本电影配音的统一数据集工具包和模型。", "motivation": "现有的方法在高质量多模态配音数据集稀缺和模型依赖于唇部区域来学习音视频对齐方面存在限制，这阻碍了它们在复杂场景中的应用。", "method": "FunCineForge包含一个大规模配音数据集的端到端生产管道以及适用于多样化电影场景的基于MLLM的配音模型。", "result": "实验表明，在独白、叙述、对话和多说话人场景中，该配音模型在音频质量、唇形同步、音色转移及指令跟随方面均优于现有方法。", "conclusion": "FunCineForge解决了现有电影配音技术中的主要限制，并展示了其在多样化影视场景下的优越性能。"}}
{"id": "2601.14776", "pdf": "https://arxiv.org/pdf/2601.14776", "abs": "https://arxiv.org/abs/2601.14776", "authors": ["Xiaofan Yang", "Yubin Liu", "Wei Pan", "Guoqing Chu", "Junming Zhang", "Jie Zhao", "Zhuoqi Man", "Xuanming Cao"], "title": "M2I2HA: A Multi-modal Object Detection Method Based on Intra- and Inter-Modal Hypergraph Attention", "categories": ["cs.CV"], "comment": "43 pages, 13 figures", "summary": "Recent advances in multi-modal detection have significantly improved detection accuracy in challenging environments (e.g., low light, overexposure). By integrating RGB with modalities such as thermal and depth, multi-modal fusion increases data redundancy and system robustness. However, significant challenges remain in effectively extracting task-relevant information both within and across modalities, as well as in achieving precise cross-modal alignment. While CNNs excel at feature extraction, they are limited by constrained receptive fields, strong inductive biases, and difficulty in capturing long-range dependencies. Transformer-based models offer global context but suffer from quadratic computational complexity and are confined to pairwise correlation modeling. Mamba and other State Space Models (SSMs), on the other hand, are hindered by their sequential scanning mechanism, which flattens 2D spatial structures into 1D sequences, disrupting topological relationships and limiting the modeling of complex higher-order dependencies. To address these issues, we propose a multi-modal perception network based on hypergraph theory called M2I2HA. Our architecture includes an Intra-Hypergraph Enhancement module to capture global many-to-many high-order relationships within each modality, and an Inter-Hypergraph Fusion module to align, enhance, and fuse cross-modal features by bridging configuration and spatial gaps between data sources. We further introduce a M2-FullPAD module to enable adaptive multi-level fusion of multi-modal enhanced features within the network, meanwhile enhancing data distribution and flow across the architecture. Extensive object detection experiments on multiple public datasets against baselines demonstrate that M2I2HA achieves state-of-the-art performance in multi-modal object detection tasks.", "AI": {"tldr": "本文提出了一种基于超图理论的多模态物体检测方法M2I2HA。", "motivation": "尽管多模态融合提升了数据冗余性和系统鲁棒性，但仍然存在有效提取任务相关信息和实现精确跨模态对齐的挑战。传统的CNN、Transformer模型以及SSMs都各自面临局限。", "method": "本文提出了一种基于超图理论的多模态感知网络M2I2HA，包括捕获单模态内高阶关系的Intra-Hypergraph增强模块和跨模态特征对齐融合的Inter-Hypergraph融合模块。此外还引入了M2-FullPAD模块以实现自适应多层次融合。", "result": "实验结果显示，在多个公开数据集上，M2I2HA在多模态物体检测任务中达到了最先进的性能。", "conclusion": "提出的M2I2HA方法通过超图理论有效地解决了提取和对齐多模态信息的挑战，并实现了优越的物体检测性能。"}}
{"id": "2601.14774", "pdf": "https://arxiv.org/pdf/2601.14774", "abs": "https://arxiv.org/abs/2601.14774", "authors": ["Keita Takeda", "Tomoya Sakai"], "title": "Does medical specialization of VLMs enhance discriminative power?: A comprehensive investigation through feature distribution analysis", "categories": ["cs.CV"], "comment": "A short version paper of this research has been accepted for The IEEE International Symposium on Biomedical Imaging (ISBI) 2026", "summary": "This study investigates the feature representations produced by publicly available open source medical vision-language models (VLMs). While medical VLMs are expected to capture diagnostically relevant features, their learned representations remain underexplored, and standard evaluations like classification accuracy do not fully reveal if they acquire truly discriminative, lesion-specific features. Understanding these representations is crucial for revealing medical image structures and improving downstream tasks in medical image analysis. This study aims to investigate the feature distributions learned by medical VLMs and evaluate the impact of medical specialization. We analyze the feature distribution of multiple image modalities extracted by some representative medical VLMs across lesion classification datasets on multiple modalities. These distributions were compared them with non-medical VLMs to assess the domain-specific medical training. Our experiments showed that medical VLMs can extract discriminative features that are effective for medical classification tasks. Moreover, it was found that non-medical VLMs with recent improvement with contextual enrichment such as LLM2CLIP produce more refined feature representations. Our results imply that enhancing text encoder is more crucial than training intensively on medical images when developing medical VLMs. Notably, non-medical models are particularly vulnerable to biases introduced by overlaied text strings on images. These findings underscore the need for careful consideration on model selection according to downstream tasks besides potential risks in inference due to background biases such as textual information in images.", "AI": {"tldr": "研究探讨了公开可用的医学视觉语言模型（VLMs）生成特征表示的能力，并评估了医学专门化对其特征分布的影响。", "motivation": "由于标准评价如分类准确率不能充分揭示这些模型是否获得真正具有区分性的病灶特异性特征，理解这些表示对于揭示医学图像结构和改善下游任务至关重要。", "method": "研究通过分析多种模态的图像由一些代表性的医学VLMs提取出的特征分布，并将其与非医学VLMs进行比较以评估领域特定的医学训练效果。", "result": "实验表明，医学VLM可以提取用于医疗分类任务的有效区分性特征。此外，具有上下文丰富改进的非医学VLM如LLM2CLIP产生更为精细的特征表示。", "conclusion": "研究结果表明，在开发医学VLM时提升文本编码器比在医学图像上进行密集训练更加重要，并且非医学模型易受背景偏差的影响如图像中的文字信息。"}}
{"id": "2601.14773", "pdf": "https://arxiv.org/pdf/2601.14773", "abs": "https://arxiv.org/abs/2601.14773", "authors": ["Haizhou Liu", "Haodong Jin", "Yiming Wang", "Hui Yu"], "title": "Semantic-Guided Unsupervised Video Summarization", "categories": ["cs.AI", "cs.MM"], "comment": null, "summary": "Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.", "AI": {"tldr": "本文提出了基于语义引导的无监督视频摘要方法，通过引入帧级语义对齐注意力机制和增量训练策略来改进现有的基于GAN的方法。", "motivation": "大多数现有的无监督摘要方法主要依赖于生成对抗网络（GAN），这种方法在关键帧选择上侧重单一模式特征，并忽略语义信息的指导作用，同时存在训练不稳定的问题。因此，提出了新的语义引导方法以解决这些问题。", "method": "设计了新的帧级语义对齐注意力机制并将其整合进关键帧选择器中；采用Transformer为基础生成器，在对抗框架内更好地重构视频；采取增量训练策略来逐步更新模型组件，缓解GAN训练的不稳定问题。", "result": "实验结果表明，所提出的方法在多个基准数据集上实现了优越性能。", "conclusion": "基于语义引导的无监督视频摘要方法通过改进关键帧选择和对抗生成框架中的训练稳定性，显著提高了视频摘要的质量。"}}
{"id": "2601.14771", "pdf": "https://arxiv.org/pdf/2601.14771", "abs": "https://arxiv.org/abs/2601.14771", "authors": ["Puneet Sharma", "Kristian Dalsbø Hindberg", "Eibe Frank", "Benedicte Schelde-Olesen", "Ulrik Deding"], "title": "Using Multi-Instance Learning to Identify Unique Polyps in Colon Capsule Endoscopy Images", "categories": ["cs.CV"], "comment": "19 pages", "summary": "Identifying unique polyps in colon capsule endoscopy (CCE) images is a critical yet challenging task for medical personnel due to the large volume of images, the cognitive load it creates for clinicians, and the ambiguity in labeling specific frames. This paper formulates this problem as a multi-instance learning (MIL) task, where a query polyp image is compared with a target bag of images to determine uniqueness. We employ a multi-instance verification (MIV) framework that incorporates attention mechanisms, such as variance-excited multi-head attention (VEMA) and distance-based attention (DBA), to enhance the model's ability to extract meaningful representations. Additionally, we investigate the impact of self-supervised learning using SimCLR to generate robust embeddings. Experimental results on a dataset of 1912 polyps from 754 patients demonstrate that attention mechanisms significantly improve performance, with DBA L1 achieving the highest test accuracy of 86.26\\% and a test AUC of 0.928 using a ConvNeXt backbone with SimCLR pretraining. This study underscores the potential of MIL and self-supervised learning in advancing automated analysis of Colon Capsule Endoscopy images, with implications for broader medical imaging applications.", "AI": {"tldr": "本论文使用多实例学习方法来识别结肠胶囊内镜图像中的独特息肉。", "motivation": "由于结肠胶囊内镜图像数量庞大，临床医生的认知负荷增加以及标注特定帧的模糊性，识别独特的息肉是医学人员面临的关键且具有挑战性的任务。", "method": "论文将该问题定义为多实例学习任务，并采用多实例验证框架，结合方差激发的多头注意力机制和基于距离的注意力机制来增强模型提取有意义表示的能力。此外，研究还探讨了使用SimCLR进行自监督学习生成稳健嵌入的影响。", "result": "实验结果表明，在一个包含754名患者1912个息肉的数据集上，注意机制显著提高了性能，DBA L1实现了最高的测试准确率86.26%和0.928的测试AUC，使用了SimCLR预训练的ConvNeXt骨干网络。", "conclusion": "本研究强调了多实例学习和自监督学习在推进结肠胶囊内镜图像自动化分析方面的潜力，并对更广泛的医学成像应用具有重要意义。"}}
{"id": "2601.14765", "pdf": "https://arxiv.org/pdf/2601.14765", "abs": "https://arxiv.org/abs/2601.14765", "authors": ["Harold Kiossou", "Pierre Schaus", "Siegfried Nijssen"], "title": "Anytime Optimal Decision Tree Learning with Continuous Features", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.", "AI": {"tldr": "本文提出了一个在任何时间点都能提供高质量决策树的算法，解决了现有方法在处理连续特征时计算时间长和任何时间性能差的问题。", "motivation": "现有的学习最优决策树的方法主要集中在二进制特征上，并且在扩展到连续特征时面临巨大的挑战。虽然之前的工作提出了一个精确的算法来解决这个问题，但它的时间复杂性限制了其实用性，特别是在树较深的情况下。此外，该方法导致了较差的任何时间性能。", "method": "本文提出了一种结合有限差异搜索策略的方法，以确保在任何中断点都能提供高质量的决策树，从而解决了现有方法在计算时间和任何时间性能上的不足。", "result": "实验结果显示，所提方法相比现有方法，在任何时候都具有更好的性能。", "conclusion": "通过引入新的优化策略，本文提出的方法能够有效地处理连续特征，并且保证了任何中断点时的最优决策树质量。"}}
{"id": "2601.14764", "pdf": "https://arxiv.org/pdf/2601.14764", "abs": "https://arxiv.org/abs/2601.14764", "authors": ["Thomas Eiter", "Tobias Geibinger", "Zeynep G. Saribatur"], "title": "An XAI View on Explainable ASP: Methods, Systems, and Perspectives", "categories": ["cs.AI", "cs.HC", "cs.LO"], "comment": "10 pages", "summary": "Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.", "AI": {"tldr": "本文提供了一个从XAI视角审视可解释ASP的方法、系统和观点的综述。", "motivation": "随着可解释人工智能(XAI)的重要性日益增加，本文旨在概述现有的ASP解释方法及其与用户问题的关系，并识别现有研究中的不足之处。", "method": "通过对现有文献进行回顾，从XAI的角度对ASP的解释类型进行了分类和总结。", "result": "指出了当前ASP解释方法存在的空白区域并确定了未来的研究方向。", "conclusion": "本文综述了ASP在可解释性方面的现状，并为未来的研究提出了建议。"}}
{"id": "2601.14758", "pdf": "https://arxiv.org/pdf/2601.14758", "abs": "https://arxiv.org/abs/2601.14758", "authors": ["Injin Kong", "Hyoungjoon Lee", "Yohan Jo"], "title": "Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic \"mechanism shift\" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.", "AI": {"tldr": "论文研究了从自回归模型(ARM)转换为掩码扩散模型(MDM)的过程中的内部算法变化。", "motivation": "动机是探讨在将预训练的自回归模型后训练成掩码扩散模型的过程中，是否能获得真正的双向推理能力，而不是仅仅重新包装自回归启发法。", "method": "通过比较电路分析ARMs和MDM来研究这种转变。", "result": "研究表明存在依赖于任务结构性质的系统性\"机制转换\"：对于由局部因果关系主导的任务，MDMs大多保留了自回归电路；而对于全局规划任务，则显示出早期层处理增加的不同重布线。", "conclusion": "扩散后训练不仅适应模型参数，而是从根本上重新组织内部计算以支持非顺序全局计划。"}}
{"id": "2601.14757", "pdf": "https://arxiv.org/pdf/2601.14757", "abs": "https://arxiv.org/abs/2601.14757", "authors": ["Kangcheng Zhou", "Jun Jiang", "Qing Zhang", "Shuang Zheng", "Qingli Li", "Shugong Xu"], "title": "ReinPath: A Multimodal Reinforcement Learning Approach for Pathology", "categories": ["cs.CV"], "comment": null, "summary": "Interpretability is significant in computational pathology, leading to the development of multimodal information integration from histopathological image and corresponding text data.However, existing multimodal methods have limited interpretability due to the lack of high-quality dataset that support explicit reasoning and inference and simple reasoning process.To address the above problems, we introduce a novel multimodal pathology large language model with strong reasoning capabilities.To improve the generation of accurate and contextually relevant textual descriptions, we design a semantic reward strategy integrated with group relative policy optimization.We construct a high-quality pathology visual question answering (VQA) dataset, specifically designed to support complex reasoning tasks.Comprehensive experiments conducted on this dataset demonstrate that our method outperforms state-of-the-art methods, even when trained with only 20% of the data.Our method also achieves comparable performance on downstream zero-shot image classification task compared with CLIP.", "AI": {"tldr": "本文介绍了ReinPath，一种用于病理学的多模态强化学习方法。", "motivation": "现有的多模态方法在解释性方面存在局限性，因为缺乏支持明确推理和推断的高质量数据集以及简单的推理过程。为了克服这些问题，开发了一种新的具有强大推理能力的多模态病理大型语言模型。", "method": "设计了语义奖励策略，并与群体相对政策优化相结合，以改进生成准确且上下文相关的文本描述的能力。构建了一个专门用于支持复杂推理任务的高质量病理视觉问答（VQA）数据集。", "result": "在该数据集上进行的全面实验表明，本方法即使使用仅20%的数据训练也优于现有最先进的方法，并且在零样本图像分类任务中与CLIP相比具有可比性能。", "conclusion": "ReinPath展示了通过多模态强化学习提高病理学解释性和推理能力的有效性。"}}
{"id": "2601.14750", "pdf": "https://arxiv.org/pdf/2601.14750", "abs": "https://arxiv.org/abs/2601.14750", "authors": ["Yifan Wang", "Shiyu Li", "Peiming Li", "Xiaochen Yang", "Yang Tang", "Zheng Wei"], "title": "Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Chain-of-Thought (CoT) prompting has achieved remarkable success in unlocking the reasoning capabilities of Large Language Models (LLMs). Although CoT prompting enhances reasoning, its verbosity imposes substantial computational overhead. Recent works often focus exclusively on outcome alignment and lack supervision on the intermediate reasoning process. These deficiencies obscure the analyzability of the latent reasoning chain. To address these challenges, we introduce Render-of-Thought (RoT), the first framework to reify the reasoning chain by rendering textual steps into images, making the latent rationale explicit and traceable. Specifically, we leverage the vision encoders of existing Vision Language Models (VLMs) as semantic anchors to align the vision embeddings with the textual space. This design ensures plug-and-play implementation without incurring additional pre-training overhead. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that our method achieves 3-4x token compression and substantial inference acceleration compared to explicit CoT. Furthermore, it maintains competitive performance against other methods, validating the feasibility of this paradigm. Our code is available at https://github.com/TencentBAC/RoT", "AI": {"tldr": "介绍Render-of-Thought（RoT）框架，该框架通过将文本推理步骤转换为图像来提高大型语言模型的计算效率和可解释性。", "motivation": "解决链式思维提示法在增强推理能力的同时带来的高计算成本问题，并使中间推理过程更加透明易分析。", "method": "使用现有视觉语言模型中的视觉编码器作为语义锚点，将文本步骤转化为图像，从而实现与文本空间的对齐。", "result": "实验表明该方法相比显式链式思维提示法实现了3-4倍的令牌压缩和显著的推理加速，且保持了竞争力的表现。", "conclusion": "验证了通过视觉化呈现链式思维步骤的有效性，证明了Render-of-Thought框架在提升计算效率及增强中间过程可追溯性方面的潜力。"}}
{"id": "2601.14744", "pdf": "https://arxiv.org/pdf/2601.14744", "abs": "https://arxiv.org/abs/2601.14744", "authors": ["Hongfu Liu", "Zhouying Cui", "Xiangming Gu", "Ye Wang"], "title": "Unlocking Large Audio-Language Models for Interactive Language Learning", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to the Findings of EACL 2026", "summary": "Achieving pronunciation proficiency in a second language (L2) remains a challenge, despite the development of Computer-Assisted Pronunciation Training (CAPT) systems. Traditional CAPT systems often provide unintuitive feedback that lacks actionable guidance, limiting its effectiveness. Recent advancements in audio-language models (ALMs) offer the potential to enhance these systems by providing more user-friendly feedback. In this work, we investigate ALMs for chat-based pronunciation training by introducing L2-Arctic-plus, an English dataset with detailed error explanations and actionable suggestions for improvement. We benchmark cascaded ASR+LLMs and existing ALMs on this dataset, specifically in detecting mispronunciation and generating actionable feedback. To improve the performance, we further propose to instruction-tune ALMs on L2-Arctic-plus. Experimental results demonstrate that our instruction-tuned models significantly outperform existing baselines on mispronunciation detection and suggestion generation in terms of both objective and human evaluation, highlighting the value of the proposed dataset.", "AI": {"tldr": "本文探讨了使用音频语言模型（ALMs）进行基于聊天的发音训练，并提出了L2-Arctic-plus数据集，通过指令微调来改进模型性能。", "motivation": "传统计算机辅助发音训练系统提供的反馈往往不直观且缺乏可操作性指导，限制了其有效性。本文旨在通过音频语言模型提供更用户友好的反馈，以解决这一问题。", "method": "引入L2-Arctic-plus数据集进行基准测试，该数据集包含详细的错误解释和改进建议；采用指令微调来提高ALMs在检测误发音和生成可操作反馈方面的性能。", "result": "实验结果表明，经指令微调的模型在误发音检测和建议生成方面显著优于现有基线系统，并且在客观评估和人工评价中都表现优异。", "conclusion": "研究证明了提出的L2-Arctic-plus数据集的价值，以及通过指令微调音频语言模型可以有效提升基于聊天的发音训练系统的性能。"}}
{"id": "2601.14742", "pdf": "https://arxiv.org/pdf/2601.14742", "abs": "https://arxiv.org/abs/2601.14742", "authors": ["Ami Pandat", "Kanyala Muvva", "Punna Rajasekhar", "Gopika Vinod", "Rohit Shukla"], "title": "SimD3: A Synthetic drone Dataset with Payload and Bird Distractor Modeling for Robust Detection", "categories": ["cs.CV"], "comment": null, "summary": "Reliable drone detection is challenging due to limited annotated real-world data, large appearance variability, and the presence of visually similar distractors such as birds. To address these challenges, this paper introduces SimD3, a large-scale high-fidelity synthetic dataset designed for robust drone detection in complex aerial environments. Unlike existing synthetic drone datasets, SimD3 explicitly models drones with heterogeneous payloads, incorporates multiple bird species as realistic distractors, and leverages diverse Unreal Engine 5 environments with controlled weather, lighting, and flight trajectories captured using a 360 six-camera rig. Using SimD3, we conduct an extensive experimental evaluation within the YOLOv5 detection framework, including an attention-enhanced variant termed Yolov5m+C3b, where standard bottleneck-based C3 blocks are replaced with C3b modules. Models are evaluated on synthetic data, combined synthetic and real data, and multiple unseen real-world benchmarks to assess robustness and generalization. Experimental results show that SimD3 provides effective supervision for small-object drone detection and that Yolov5m+C3b consistently outperforms the baseline across in-domain and cross-dataset evaluations. These findings highlight the utility of SimD3 for training and benchmarking robust drone detection models under diverse and challenging conditions.", "AI": {"tldr": "介绍了一个名为SimD3的合成无人机数据集，用于在复杂空中环境中进行鲁棒的无人机检测。", "motivation": "由于标注的真实世界数据有限、外观变异性大以及存在与鸟类类似的视觉干扰物，可靠的无人机检测极具挑战性。为了应对这些挑战，论文提出了SimD3数据集。", "method": "SimD3是一个大规模高保真的合成数据集，它包括带有异构载荷的无人机模型和多种作为真实干扰者的鸟类，并使用Unreal Engine 5创建了多种环境来控制天气、照明和飞行轨迹。该研究在YOLOv5检测框架内进行了广泛的实验评估。", "result": "实验结果显示SimD3为小目标无人机检测提供了有效的监督，且Yolov5m+C3b模型在内部数据集以及跨数据集的评价中始终优于基线模型。", "conclusion": "这些发现突出了SimD3用于训练和基准测试鲁棒的无人机检测模型在其多样性和挑战条件下的实用性。"}}
{"id": "2601.14741", "pdf": "https://arxiv.org/pdf/2601.14741", "abs": "https://arxiv.org/abs/2601.14741", "authors": ["Chongbin Yi", "Yuxin Liang", "Ziqi Zhou", "Peng Yang"], "title": "Enhancing Text-to-Image Generation via End-Edge Collaborative Hybrid Super-Resolution", "categories": ["cs.CV"], "comment": "Accpeted by ICC 2026", "summary": "Artificial Intelligence-Generated Content (AIGC) has made significant strides, with high-resolution text-to-image (T2I) generation becoming increasingly critical for improving users' Quality of Experience (QoE). Although resource-constrained edge computing adequately supports fast low-resolution T2I generations, achieving high-resolution output still faces the challenge of ensuring image fidelity at the cost of latency. To address this, we first investigate the performance of super-resolution (SR) methods for image enhancement, confirming a fundamental trade-off that lightweight learning-based SR struggles to recover fine details, while diffusion-based SR achieves higher fidelity at a substantial computational cost. Motivated by these observations, we propose an end-edge collaborative generation-enhancement framework. Upon receiving a T2I generation task, the system first generates a low-resolution image based on adaptively selected denoising steps and super-resolution scales at the edge side, which is then partitioned into patches and processed by a region-aware hybrid SR policy. This policy applies a diffusion-based SR model to foreground patches for detail recovery and a lightweight learning-based SR model to background patches for efficient upscaling, ultimately stitching the enhanced ones into the high-resolution image. Experiments show that our system reduces service latency by 33% compared with baselines while maintaining competitive image quality.", "AI": {"tldr": "本文提出一种端边协作的混合超分辨率框架，用于提升文本到图像生成的质量和效率。", "motivation": "虽然边缘计算可以很好地支持快速低分辨率的文本到图像生成，但要实现高质量的高分辨率输出仍然面临挑战。作者希望通过结合轻量级学习超分辨率和扩散模型超分辨率的优势来解决这一问题。", "method": "提出一种端边协作的混合超分辨率框架，在边缘侧首先基于自适应选择去噪步长和超分辨率尺度生成低分辨率图像，然后将其划分为补丁并应用区域感知混合SR策略进行处理。该策略对前景补丁使用扩散模型进行细节恢复，对背景补丁使用轻量级学习模型进行高效放大，并最终将这些增强的补丁拼接成高分辨率图像。", "result": "实验结果表明，与基线方法相比，本系统降低了33%的服务延迟，同时保持了竞争力的图像质量。", "conclusion": "该研究提出的方法在保证高质量的同时减少了服务延迟，为文本到图像生成任务提供了一种有效的解决方案。"}}
{"id": "2601.14738", "pdf": "https://arxiv.org/pdf/2601.14738", "abs": "https://arxiv.org/abs/2601.14738", "authors": ["Liqin Wang", "Qianyue Hu", "Wei Lu", "Xiangyang Luo"], "title": "Safeguarding Facial Identity against Diffusion-based Face Swapping via Cascading Pathway Disruption", "categories": ["cs.CV"], "comment": null, "summary": "The rapid evolution of diffusion models has democratized face swapping but also raises concerns about privacy and identity security. Existing proactive defenses, often adapted from image editing attacks, prove ineffective in this context. We attribute this failure to an oversight of the structural resilience and the unique static conditional guidance mechanism inherent in face swapping systems. To address this, we propose VoidFace, a systemic defense method that views face swapping as a coupled identity pathway. By injecting perturbations at critical bottlenecks, VoidFace induces cascading disruption throughout the pipeline. Specifically, we first introduce localization disruption and identity erasure to degrade physical regression and semantic embeddings, thereby impairing the accurate modeling of the source face. We then intervene in the generative domain by decoupling attention mechanisms to sever identity injection, and corrupting intermediate diffusion features to prevent the reconstruction of source identity. To ensure visual imperceptibility, we perform adversarial search in the latent manifold, guided by a perceptual adaptive strategy to balance attack potency with image quality. Extensive experiments show that VoidFace outperforms existing defenses across various diffusion-based swapping models, while producing adversarial faces with superior visual quality.", "AI": {"tldr": "本文提出VoidFace，一种针对扩散模型驱动的脸部替换攻击的防御方法。", "motivation": "随着扩散模型的发展，脸部替换技术越来越普及，但这也引发了隐私和身份安全的问题。现有的防御策略在应对这种新型攻击时效果不佳，因此需要新的防御机制来保障面部识别的安全性。", "method": "VoidFace通过注入扰动破坏关键瓶颈处的结构韧性，从而中断身份路径中的定位干扰和身份擦除，并且在生成领域解耦注意力机制以切断身份注入，并扰乱中间扩散特征以防止源身份重建。为了保证视觉上的不可感知性，使用对抗搜索来平衡攻击效果与图像质量。", "result": "实验结果表明，VoidFace在各种基于扩散的替换模型中都优于现有防御方法，并且生成的对抗面孔具有更佳的视觉质量。", "conclusion": "VoidFace作为一种有效的面部安全防御技术，在保护隐私的同时还能保持良好的图像质量。"}}
{"id": "2601.14732", "pdf": "https://arxiv.org/pdf/2601.14732", "abs": "https://arxiv.org/abs/2601.14732", "authors": ["Jing Lan", "Hexiao Ding", "Hongzhao Chen", "Yufeng Jiang", "Nga-Chun Ng", "Gwing Kei Yip", "Gerald W. Y. Cheng", "Yunlin Mao", "Jing Cai", "Liang-ting Lin", "Jung Sun Yoo"], "title": "DeepMoLM: Leveraging Visual and Geometric Structural Information for Molecule-Text Modeling", "categories": ["cs.CV", "cs.CL", "cs.MM"], "comment": "Under review", "summary": "AI models for drug discovery and chemical literature mining must interpret molecular images and generate outputs consistent with 3D geometry and stereochemistry. Most molecular language models rely on strings or graphs, while vision-language models often miss stereochemical details and struggle to map continuous 3D structures into discrete tokens. We propose DeepMoLM: Deep Molecular Language M odeling, a dual-view framework that grounds high-resolution molecular images in geometric invariants derived from molecular conformations. DeepMoLM preserves high-frequency evidence from 1024 $\\times$ 1024 inputs, encodes conformer neighborhoods as discrete Extended 3-Dimensional Fingerprints, and fuses visual and geometric streams with cross-attention, enabling physically grounded generation without atom coordinates. DeepMoLM improves PubChem captioning with a 12.3% relative METEOR gain over the strongest generalist baseline while staying competitive with specialist methods. It produces valid numeric outputs for all property queries and attains MAE 13.64 g/mol on Molecular Weight and 37.89 on Complexity in the specialist setting. On ChEBI-20 description generation from images, it exceeds generalist baselines and matches state-of- the-art vision-language models. Code is available at https://github.com/1anj/DeepMoLM.", "AI": {"tldr": "提出了DeepMoLM，一种用于分子文本建模的双视图框架，该模型结合视觉和几何信息以提高分子图像理解和生成能力。", "motivation": "现有的分子语言模型或忽视了立体化学细节，或难以将连续的3D结构映射为离散的标记。因此，需要一个能够处理这些挑战的方法来改善药物发现和化学文献挖掘。", "method": "DeepMoLM框架通过高分辨率分子图像与几何不变量相结合的方式，保留高频证据，利用扩展的三维指纹编码构象邻域，并使用交叉注意力机制融合视觉和几何信息流。", "result": "在PubChem描述生成任务中，相比最强的一般模型有12.3%的相对METEOR增益；对分子重量和复杂度的预测分别达到MAE 13.64 g/mol和37.89。此外，在ChEBI-20图像描述生成上也超过了普通基线并达到了最先进的视觉语言模型水平。", "conclusion": "DeepMoLM展示了通过融合视觉与几何信息来改进分子文本建模的潜力，为药物发现和化学文献挖掘提供了有效的工具和支持。"}}
{"id": "2601.14730", "pdf": "https://arxiv.org/pdf/2601.14730", "abs": "https://arxiv.org/abs/2601.14730", "authors": ["Bizu Feng", "Zhimu Yang", "Shaode Yu", "Zixin Hu"], "title": "FSX: Message Flow Sensitivity Enhanced Structural Explainer for Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 4 figures, Preprint", "summary": "Despite the widespread success of Graph Neural Networks (GNNs), understanding the reasons behind their specific predictions remains challenging. Existing explainability methods face a trade-off that gradient-based approaches are computationally efficient but often ignore structural interactions, while game-theoretic techniques capture interactions at the cost of high computational overhead and potential deviation from the model's true reasoning path. To address this gap, we propose FSX (Message Flow Sensitivity Enhanced Structural Explainer), a novel hybrid framework that synergistically combines the internal message flows of the model with a cooperative game approach applied to the external graph data. FSX first identifies critical message flows via a novel flow-sensitivity analysis: during a single forward pass, it simulates localized node perturbations and measures the resulting changes in message flow intensities. These sensitivity-ranked flows are then projected onto the input graph to define compact, semantically meaningful subgraphs. Within each subgraph, a flow-aware cooperative game is conducted, where node contributions are evaluated fairly through a Shapley-like value that incorporates both node-feature importance and their roles in sustaining or destabilizing the identified critical flows. Extensive evaluation across multiple datasets and GNN architectures demonstrates that FSX achieves superior explanation fidelity with significantly reduced runtime, while providing unprecedented insights into the structural logic underlying model predictions--specifically, how important sub-structures exert influence by governing the stability of key internal computational pathways.", "AI": {"tldr": "FSX 是一种新型的混合框架，它结合了模型内部的消息流动和应用于外部图数据的合作博弈方法，以提高解释的准确性并减少计算时间。", "motivation": "现有的可解释性方法存在效率与准确性的权衡问题。基于梯度的方法虽然计算高效但忽略结构互动，而博弈论技术虽能捕捉到交互作用但却需要很高的计算开销且可能偏离模型的真实推理路径。因此提出FSX以解决这一问题。", "method": "FSX 首先通过消息流动敏感性分析识别关键的消息流：在单次前向传递过程中模拟局部节点扰动并测量随之产生的消息流量变化。然后将这些按敏感度排序的流投射到输入图上，定义出紧凑且语义上有意义的子图，并在每个子图中进行考虑流动意识的合作博弈。", "result": "实验结果表明FSX能够以显著减少运行时间实现更高的解释准确性，并提供了前所未有的模型预测背后结构逻辑的见解。", "conclusion": "FSX框架通过结合内部消息流分析与外部图形数据上合作游戏的方式，有效解决了现有GNN可解释性方法之间的权衡问题，为理解模型决策过程提供了一种新颖且高效的解决方案。"}}
{"id": "2601.14728", "pdf": "https://arxiv.org/pdf/2601.14728", "abs": "https://arxiv.org/abs/2601.14728", "authors": ["Chun-Yi Kuan", "Kai-Wei Chang", "Hung-yi Lee"], "title": "AQAScore: Evaluating Semantic Alignment in Text-to-Audio Generation via Audio Question Answering", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "comment": "Manuscript in progress", "summary": "Although text-to-audio generation has made remarkable progress in realism and diversity, the development of evaluation metrics has not kept pace. Widely-adopted approaches, typically based on embedding similarity like CLAPScore, effectively measure general relevance but remain limited in fine-grained semantic alignment and compositional reasoning. To address this, we introduce AQAScore, a backbone-agnostic evaluation framework that leverages the reasoning capabilities of audio-aware large language models (ALLMs). AQAScore reformulates assessment as a probabilistic semantic verification task; rather than relying on open-ended text generation, it estimates alignment by computing the exact log-probability of a \"Yes\" answer to targeted semantic queries. We evaluate AQAScore across multiple benchmarks, including human-rated relevance, pairwise comparison, and compositional reasoning tasks. Experimental results show that AQAScore consistently achieves higher correlation with human judgments than similarity-based metrics and generative prompting baselines, showing its effectiveness in capturing subtle semantic inconsistencies and scaling with the capability of underlying ALLMs.", "AI": {"tldr": "介绍了一种新的评估框架AQAScore，用于衡量文本到音频生成中的语义对齐。", "motivation": "现有的基于嵌入相似性的评估方法无法很好地捕捉细粒度的语义对齐和组合推理能力。", "method": "AQAScore通过使用音频感知的大语言模型（ALLMs）将评估问题转化为概率语义验证任务，计算特定语义查询的“Yes”答案的确切对数概率来衡量对齐程度。", "result": "实验结果表明，与基于相似性和生成提示基线相比，AQAScore在多个基准测试中能更好地捕捉细微的语义不一致性，并且能够随着底层ALLMs能力的提高而扩展。", "conclusion": "AQAScore作为一种新的评估框架，在衡量文本到音频生成中的细粒度语义对齐方面表现出色。"}}
{"id": "2601.14724", "pdf": "https://arxiv.org/pdf/2601.14724", "abs": "https://arxiv.org/abs/2601.14724", "authors": ["Haowei Zhang", "Shudong Yang", "Jinlan Fu", "See-Kiong Ng", "Xipeng Qiu"], "title": "HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant improvement in offline video understanding. However, extending these capabilities to streaming video inputs, remains challenging, as existing models struggle to simultaneously maintain stable understanding performance, real-time responses, and low GPU memory overhead. To address this challenge, we propose HERMES, a novel training-free architecture for real-time and accurate understanding of video streams. Based on a mechanistic attention investigation, we conceptualize KV cache as a hierarchical memory framework that encapsulates video information across multiple granularities. During inference, HERMES reuses a compact KV cache, enabling efficient streaming understanding under resource constraints. Notably, HERMES requires no auxiliary computations upon the arrival of user queries, thereby guaranteeing real-time responses for continuous video stream interactions, which achieves 10$\\times$ faster TTFT compared to prior SOTA. Even when reducing video tokens by up to 68% compared with uniform sampling, HERMES achieves superior or comparable accuracy across all benchmarks, with up to 11.4% gains on streaming datasets.", "AI": {"tldr": "本文提出了HERMES，一种无需训练的架构，用于实时准确地理解视频流。", "motivation": "尽管多模态大型语言模型在离线视频理解方面取得了显著进步，但在处理实时视频输入时仍然面临挑战，特别是在保持性能稳定、即时响应和低GPU内存开销之间取得平衡。", "method": "HERMES通过机制性注意力调查将KV缓存视为分层记忆框架，以跨多个粒度级别封装视频信息。在推理过程中，它复用紧凑的KV缓存，实现资源受限下的高效流理解，并确保即时响应连续视频流交互。", "result": "与现有最先进方法相比，HERMES实现了10倍更快的时间到首次文本(TTFT)，且即使减少高达68%的视频标记，仍能保持优越或相当的准确性，在所有基准测试上获得高达11.4%的增益。", "conclusion": "HERMES通过创新的方法解决了实时视频理解中的关键挑战，并展示了在速度和精度方面的显著改进。"}}
{"id": "2601.14718", "pdf": "https://arxiv.org/pdf/2601.14718", "abs": "https://arxiv.org/abs/2601.14718", "authors": ["Yiyang Fu", "Hui Li", "Wangyu Wu"], "title": "Context Patch Fusion With Class Token Enhancement for Weakly Supervised Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Weakly Supervised Semantic Segmentation (WSSS), which relies only on image-level labels, has attracted significant attention for its cost-effectiveness and scalability. Existing methods mainly enhance inter-class distinctions and employ data augmentation to mitigate semantic ambiguity and reduce spurious activations. However, they often neglect the complex contextual dependencies among image patches, resulting in incomplete local representations and limited segmentation accuracy. To address these issues, we propose the Context Patch Fusion with Class Token Enhancement (CPF-CTE) framework, which exploits contextual relations among patches to enrich feature representations and improve segmentation. At its core, the Contextual-Fusion Bidirectional Long Short-Term Memory (CF-BiLSTM) module captures spatial dependencies between patches and enables bidirectional information flow, yielding a more comprehensive understanding of spatial correlations. This strengthens feature learning and segmentation robustness. Moreover, we introduce learnable class tokens that dynamically encode and refine class-specific semantics, enhancing discriminative capability. By effectively integrating spatial and semantic cues, CPF-CTE produces richer and more accurate representations of image content. Extensive experiments on PASCAL VOC 2012 and MS COCO 2014 validate that CPF-CTE consistently surpasses prior WSSS methods.", "AI": {"tldr": "本文提出了一个名为Context Patch Fusion with Class Token Enhancement (CPF-CTE)的框架，旨在通过利用图像补丁间的上下文关系和学习可训练类别标记来改进弱监督语义分割（WSSS）的精度。", "motivation": "现有的WSSS方法主要集中在增强类间差异并使用数据增强来减少语义模糊性，但往往忽视了图像补丁之间的复杂上下文依赖关系，导致局部表示不完整和分割准确性有限。", "method": "CPF-CTE框架包含一个Contextual-Fusion Bidirectional Long Short-Term Memory (CF-BiLSTM)模块用于捕捉补丁间的空间相关性和双向信息流动，以及学习可训练类别标记以动态编码并细化特定类别的语义。", "result": "实验表明，在PASCAL VOC 2012和MS COCO 2014数据集上，CPF-CTE在弱监督语义分割任务中优于之前的WSSS方法。", "conclusion": "CPF-CTE通过有效整合空间线索和语义线索，生成更丰富、准确的图像内容表示，从而提高了弱监督语义分割的性能。"}}
{"id": "2601.14716", "pdf": "https://arxiv.org/pdf/2601.14716", "abs": "https://arxiv.org/abs/2601.14716", "authors": ["Yao Lu", "Dengdong Fan", "Jianzheng Nie", "Fan Xu", "Jie Chen", "Bin Zhou", "Yonghong Tian"], "title": "PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.", "AI": {"tldr": "介绍PCL-Reasoner-V1.5，一个用于数学推理的大型语言模型，通过监督微调和离线强化学习进行训练。", "motivation": "推动大语言模型在数学推理方面的性能提升，并探索离线强化学习作为稳定高效的训练方法。", "method": "基于Qwen2.5-32B构建了一个拥有320亿参数的大型语言模型，使用监督微调（SFT）和离线强化学习进行优化。", "result": "在AIME 2024上的平均准确率为90.9%，在AIME 2025上的平均准确率为85.6%，展示了优于标准在线RL方法的性能。", "conclusion": "研究表明离线强化学习是一种稳定高效的训练范式，能够显著提升大语言模型的推理能力。"}}
{"id": "2601.14713", "pdf": "https://arxiv.org/pdf/2601.14713", "abs": "https://arxiv.org/abs/2601.14713", "authors": ["Tingting Li", "Ziming Zhao", "Jianwei Yin"], "title": "Adaptive Fidelity Estimation for Quantum Programs with Graph-Guided Noise Awareness", "categories": ["quant-ph", "cs.AI"], "comment": "Published in AAAI 2026;", "summary": "Fidelity estimation is a critical yet resource-intensive step in testing quantum programs on noisy intermediate-scale quantum (NISQ) devices, where the required number of measurements is difficult to predefine due to hardware noise, device heterogeneity, and transpilation-induced circuit transformations. We present QuFid, an adaptive and noise-aware framework that determines measurement budgets online by leveraging circuit structure and runtime statistical feedback. QuFid models a quantum program as a directed acyclic graph (DAG) and employs a control-flow-aware random walk to characterize noise propagation along gate dependencies. Backend-specific effects are captured via transpilation-induced structural deformation metrics, which are integrated into the random-walk formulation to induce a noise-propagation operator. Circuit complexity is then quantified through the spectral characteristics of this operator, providing a principled and lightweight basis for adaptive measurement planning. Experiments on 18 quantum benchmarks executed on IBM Quantum backends show that QuFid significantly reduces measurement cost compared to fixed-shot and learning-based baselines, while consistently maintaining acceptable fidelity bias.", "AI": {"tldr": "该论文介绍了QuFid，一个自适应且噪声感知框架，用于在NISQ设备上测试量子程序时确定测量预算。", "motivation": "由于硬件噪音、设备异质性和编译诱导的电路转换，准确预定义所需的测量数量是困难的，因此需要一种方法来减少资源密集型的保真度估计步骤。", "method": "QuFid将量子程序建模为有向无环图（DAG），并采用带控制流感知的随机漫步来表征沿门依赖关系的噪音传播，并通过量化电路复杂性提供自适应测量规划的基础。", "result": "实验显示，与固定射击和学习基线相比，QuFid显著降低了测量成本，同时保持了可接受的保真偏差。", "conclusion": "该框架为NISQ设备上的量子程序测试提供了更高效、噪声感知的方法，并展示了在减少资源消耗的同时维持高保真度的能力。"}}
{"id": "2601.14711", "pdf": "https://arxiv.org/pdf/2601.14711", "abs": "https://arxiv.org/abs/2601.14711", "authors": ["Mingxuan Song", "Yusen Huo", "Bohan Zhou", "Shenglin Yin", "Zhen Xiao", "Jieyi Long", "Zhilin Zhang", "Chuan Yu"], "title": "DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted at The ACM Web Conference (WWW) 2026", "summary": "Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.", "AI": {"tldr": "本文提出了一种名为DARA的双阶段框架，用于在线广告中的预算分配问题，结合了大型语言模型（LLM）和强化学习技术。", "motivation": "在AI生成竞价背景下，在有限历史数据的情况下优化广告商累积价值并满足预算限制是一个挑战。传统的RL方法在这种情况下表现不佳，而LLMs虽然能从少量数据中泛化但缺乏数值精度。", "method": "提出了一种名为GRPO-Adaptive的LLM后训练策略来提高推理和数值精度，并在此基础上提出了DARA框架，该框架将决策过程分为两个阶段：少数样本推理器和精细优化器。", "result": "实验结果表明，在真实世界和合成数据环境中，与现有基线相比，本文的方法在预算约束下的累积广告商价值方面表现更优。", "conclusion": "DARA通过结合LLM的上下文学习能力和精准适应性解决了在线广告中的预算分配问题，并在各种场景下取得了显著成效。"}}
{"id": "2601.14710", "pdf": "https://arxiv.org/pdf/2601.14710", "abs": "https://arxiv.org/abs/2601.14710", "authors": ["Tianchi Chen", "Jan Bima", "Sean L. Wu", "Otto Ritter", "Bingjia Yang", "Xiang Yu"], "title": "Case-Guided Sequential Assay Planning in Drug Discovery", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.", "AI": {"tldr": "本文提出了隐式贝叶斯马尔可夫决策过程（IBMDP），一种适用于无环境模拟器设置的模型基础强化学习框架，用于药物发现中的实验顺序规划。", "motivation": "在药物研发中优化实验序列是一个高风险的问题，面临严重的不确定性和资源限制，缺乏明确的环境模拟器或转换数据，因此需要依靠历史结果数据库进行规划。", "method": "IBMDP通过使用类似的历史结果形成非参数信念分布来构建案例引导的隐式转换动态模型，并采用贝叶斯信念更新机制和集合蒙特卡洛树搜索（MCTS）计划生成稳定策略，以平衡信息获取与资源效率。", "result": "在真实世界中的中枢神经系统药物发现任务中，IBMDP将资源消耗减少了高达92%，并保持了决策信心。在一个可以计算最优政策的合成环境中，IBMDP的表现优于确定性值迭代替代方案，并且其计划结果与最优策略高度一致。", "conclusion": "IBMDP为数据丰富但缺乏模拟器的领域提供了实用解决方案，在无明确环境仿真条件下实现了有效的顺序实验设计。"}}
{"id": "2601.14707", "pdf": "https://arxiv.org/pdf/2601.14707", "abs": "https://arxiv.org/abs/2601.14707", "authors": ["Nazar Ponochevnyi", "Young-Ho Kim", "Joseph Jay Williams", "Anastasia Kuzminykh"], "title": "Talk Me Through It: Developing Effective Systems for Chart Authoring", "categories": ["cs.HC"], "comment": null, "summary": "Recent chart-authoring systems increasingly focus on natural-language input, enabling users to form a mental image of the chart they wish to create and express this intent using spoken instructions (spoken imagined-chart data). Yet these systems are predominantly trained on typed instructions written while viewing the target chart (typed existing-chart data). While the cognitive processes for describing an existing chart arguably differ from those for creating a new chart, the structural differences in the corresponding prompts remain underexplored. We present empirical findings on the structural differences among spoken imagined-chart instructions, typed imagined-chart instructions, and typed existing-chart instructions for chart creation, showing that imagined-chart prompts contain richer command formats, element specifications, and complex linguistic features, especially in spoken instructions. We then compare the performance of systems trained on spoken imagined-chart data versus typed existing-chart data, finding that the first system outperforms the second one on both voice and text input, highlighting the necessity of targeted training on spoken imagined-chart data. We conclude with design guidelines for chart-authoring systems to improve performance in real-world scenarios.", "AI": {"tldr": "本文研究了用于创建图表的自然语言输入系统，特别是通过比较不同形式的语言指令来优化这些系统的性能。", "motivation": "现有的图表创作系统主要基于查看目标图表时打字生成的指令进行训练，而用户在描述一个新图表时的认知过程可能有所不同，因此需要探索和利用这种差异以改进系统。", "method": "作者通过实验对比了语音形式的想象中图表指令、文本形式的想象中图表指令以及文本形式的存在图表指令之间的结构差异，并比较了基于不同类型数据训练系统的性能。", "result": "研究发现基于语音形式的想象中图表数据训练的系统在语音和文本输入上的表现优于基于文本形式存在图表数据训练的系统，证明了针对语音形式的想象中图表数据进行专门训练的重要性。", "conclusion": "作者提出了设计指导方针，旨在通过优化自然语言处理技术来提高图表创作系统的性能，并适应现实世界的使用场景。"}}
{"id": "2601.14706", "pdf": "https://arxiv.org/pdf/2601.14706", "abs": "https://arxiv.org/abs/2601.14706", "authors": ["Chao Gao", "Siqiao Xue", "Yimin Peng", "Jiwen Fu", "Tingyi Gu", "Shanshan Li", "Fan Zhou"], "title": "LookBench: A Live and Holistic Open Benchmark for Fashion Image Retrieval", "categories": ["cs.CV"], "comment": "The first two authors contributed equally to this work. Project site: https://serendipityoneinc.github.io/look-bench-page/", "summary": "In this paper, we present LookBench (We use the term \"look\" to reflect retrieval that mirrors how people shop -- finding the exact item, a close substitute, or a visually consistent alternative.), a live, holistic and challenging benchmark for fashion image retrieval in real e-commerce settings. LookBench includes both recent product images sourced from live websites and AI-generated fashion images, reflecting contemporary trends and use cases. Each test sample is time-stamped and we intend to update the benchmark periodically, enabling contamination-aware evaluation aligned with declared training cutoffs. Grounded in our fine-grained attribute taxonomy, LookBench covers single-item and outfit-level retrieval across. Our experiments reveal that LookBench poses a significant challenge on strong baselines, with many models achieving below $60\\%$ Recall@1. Our proprietary model achieves the best performance on LookBench, and we release an open-source counterpart that ranks second, with both models attaining state-of-the-art results on legacy Fashion200K evaluations. LookBench is designed to be updated semi-annually with new test samples and progressively harder task variants, providing a durable measure of progress. We publicly release our leaderboard, dataset, evaluation code, and trained models.", "AI": {"tldr": "介绍LookBench，一个实时全面的时尚图像检索基准测试平台。", "motivation": "旨在为现实中的电子商务环境提供挑战性的时尚图像检索基准，以反映真实的购物体验，并且不断更新数据集和任务难度。", "method": "开发了一个包含最新产品图像和AI生成的时尚图像的数据集LookBench，支持单件商品和整套搭配的检索，并设计了时间戳机制与定期更新计划。", "result": "实验表明该基准对强大的基线模型提出了显著挑战，很多模型在召回率@1下低于60%，而他们提出的新模型取得了最佳性能。", "conclusion": "LookBench旨在为时尚图像检索提供一个实时、全面且持续更新的评估标准，公开了排行榜、数据集和代码。"}}
{"id": "2601.14705", "pdf": "https://arxiv.org/pdf/2601.14705", "abs": "https://arxiv.org/abs/2601.14705", "authors": ["Casimir Czworkowski", "Stephen Hornish", "Alhassan S. Yasin"], "title": "Proximal Policy Optimization with Evolutionary Mutations", "categories": ["cs.NE", "cs.AI", "cs.GT", "cs.LG"], "comment": "10 pages, 5 figures, 2 tables, 1 algorithm", "summary": "Proximal Policy Optimization (PPO) is a widely used reinforcement learning algorithm known for its stability and sample efficiency, but it often suffers from premature convergence due to limited exploration. In this paper, we propose POEM (Proximal Policy Optimization with Evolutionary Mutations), a novel modification to PPO that introduces an adaptive exploration mechanism inspired by evolutionary algorithms. POEM enhances policy diversity by monitoring the Kullback-Leibler (KL) divergence between the current policy and a moving average of previous policies. When policy changes become minimal, indicating stagnation, POEM triggers an adaptive mutation of policy parameters to promote exploration. We evaluate POEM on four OpenAI Gym environments: CarRacing, MountainCar, BipedalWalker, and LunarLander. Through extensive fine-tuning using Bayesian optimization techniques and statistical testing using Welch's t-test, we find that POEM significantly outperforms PPO on three of the four tasks (BipedalWalker: t=-2.0642, p=0.0495; CarRacing: t=-6.3987, p=0.0002; MountainCar: t=-6.2431, p<0.0001), while performance on LunarLander is not statistically significant (t=-1.8707, p=0.0778). Our results highlight the potential of integrating evolutionary principles into policy gradient methods to overcome exploration-exploitation tradeoffs.", "AI": {"tldr": "本文提出了一种新的强化学习算法POEM，它通过引入进化算法中的变异机制来改进PPO的探索能力。", "motivation": "虽然PPO因其稳定性和样本效率而广泛使用，但它经常因为探索不足而导致过早收敛。因此，作者希望通过引入自适应探索机制提高其性能。", "method": "POEM基于PPO进行修改，在Kullback-Leibler散度表明策略变化变小时触发参数变异以促进探索。实验在四个OpenAI Gym环境中进行，并通过贝叶斯优化和Welch's t-test统计测试来评估结果。", "result": "与原始的PPO相比，POEM在BipedalWalker、CarRacing和MountainCar这三个任务上显著提高了性能（p值分别为0.0495, 0.0002, <0.0001），但在LunarLander上的改进不具有统计学意义。", "conclusion": "研究结果表明，将进化原则整合到策略梯度方法中可以有效解决探索与利用之间的权衡问题。"}}
{"id": "2601.14703", "pdf": "https://arxiv.org/pdf/2601.14703", "abs": "https://arxiv.org/abs/2601.14703", "authors": ["Xinquan Yang", "Xuguang Li", "Mianjie Zheng", "Xuefen Liu", "Kun Tang", "Kian Ming Lim", "He Meng", "Jianfeng Ren", "Linlin Shen"], "title": "RegFreeNet: A Registration-Free Network for CBCT-based 3D Dental Implant Planning", "categories": ["cs.CV"], "comment": null, "summary": "As the commercial surgical guide design software usually does not support the export of implant position for pre-implantation data, existing methods have to scan the post-implantation data and map the implant to pre-implantation space to get the label of implant position for training. Such a process is time-consuming and heavily relies on the accuracy of registration algorithm. Moreover, not all hospitals have paired CBCT data, limitting the construction of multi-center dataset. Inspired by the way dentists determine the implant position based on the neighboring tooth texture, we found that even if the implant area is masked, it will not affect the determination of the implant position. Therefore, we propose to mask the implants in the post-implantation data so that any CBCT containing the implants can be used as training data. This paradigm enables us to discard the registration process and makes it possible to construct a large-scale multi-center implant dataset. On this basis, we proposes ImplantFairy, a comprehensive, publicly accessible dental implant dataset with voxel-level 3D annotations of 1622 CBCT data. Furthermore, according to the area variation characteristics of the tooth's spatial structure and the slope information of the implant, we designed a slope-aware implant position prediction network. Specifically, a neighboring distance perception (NDP) module is designed to adaptively extract tooth area variation features, and an implant slope prediction branch assists the network in learning more robust features through additional implant supervision information. Extensive experiments conducted on ImplantFairy and two public dataset demonstrate that the proposed RegFreeNet achieves the state-of-the-art performance.", "AI": {"tldr": "提出RegFreeNet，一种无配准的网络用于基于CBCT的三维牙齿种植规划。", "motivation": "现有方法依赖于耗时且精度受限的数据映射过程，并非所有医院都有成对的CBCT数据，限制了多中心数据集的构建。论文旨在解决这些问题，提出新的解决方案以提高效率和数据可用性。", "method": "通过掩盖种植体区域来训练模型，设计了一个带有邻域距离感知模块（NDP）和植入物斜率预测分支的网络，实现无配准的种植位置预测。", "result": "在新构建的数据集ImplantFairy以及两个公开数据集上的实验表明，所提出的RegFreeNet达到了最先进的性能水平。", "conclusion": "通过创新的方法，成功实现了无需配准步骤的牙齿植入规划，并展示了其优越性能。"}}
{"id": "2601.14702", "pdf": "https://arxiv.org/pdf/2601.14702", "abs": "https://arxiv.org/abs/2601.14702", "authors": ["Zecong Tang", "Zixu Wang", "Yifei Wang", "Weitong Lian", "Tianjian Gao", "Haoran Li", "Tengju Ru", "Lingyi Meng", "Zhejun Cui", "Yichen Zhu", "Qi Kang", "Kaixuan Wang", "Yu Zhang"], "title": "AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving", "categories": ["cs.AI", "cs.CV", "cs.RO"], "comment": "23 pages. Submitted to ACL ARR 2026 January", "summary": "Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.", "AI": {"tldr": "介绍了AutoDriDM，一个专注于评估视觉语言模型在自动驾驶决策过程中的基准。", "motivation": "现有基准侧重于感知能力的评估，忽略了决策制定过程的重要性。因此，需要一个新的评估标准来确保自动驾驶系统的安全性和可靠性。", "method": "构建了一个名为AutoDriDM的以决策为中心的基准测试集，包含6,650个问题，并在三个维度上进行评测：对象、场景和决策，通过自动注释模型对主流视觉语言模型的推理过程进行了可解释性分析。", "result": "研究揭示了感知能力和决策制定性能之间存在弱相关性，并识别出了如逻辑推理错误等关键失败模式。", "conclusion": "AutoDriDM填补了以感知为中心和以决策为中心评估之间的空白，为开发更安全可靠的视觉语言模型提供了指导。"}}
{"id": "2601.14697", "pdf": "https://arxiv.org/pdf/2601.14697", "abs": "https://arxiv.org/abs/2601.14697", "authors": ["Shutong Qiao", "Wei Yuan", "Tong Chen", "Xiangyu Zhao", "Quoc Viet Hung Nguyen", "Hongzhi Yin"], "title": "When Text-as-Vision Meets Semantic IDs in Generative Recommendation: An Empirical Study", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Semantic ID learning is a key interface in Generative Recommendation (GR) models, mapping items to discrete identifiers grounded in side information, most commonly via a pretrained text encoder. However, these text encoders are primarily optimized for well-formed natural language. In real-world recommendation data, item descriptions are often symbolic and attribute-centric, containing numerals, units, and abbreviations. These text encoders can break these signals into fragmented tokens, weakening semantic coherence and distorting relationships among attributes. Worse still, when moving to multimodal GR, relying on standard text encoders introduces an additional obstacle: text and image embeddings often exhibit mismatched geometric structures, making cross-modal fusion less effective and less stable. In this paper, we revisit representation design for Semantic ID learning by treating text as a visual signal. We conduct a systematic empirical study of OCR-based text representations, obtained by rendering item descriptions into images and encoding them with vision-based OCR models. Experiments across four datasets and two generative backbones show that OCR-text consistently matches or surpasses standard text embeddings for Semantic ID learning in both unimodal and multimodal settings. Furthermore, we find that OCR-based Semantic IDs remain robust under extreme spatial-resolution compression, indicating strong robustness and efficiency in practical deployments.", "AI": {"tldr": "本文研究了在生成推荐系统中，将文本视为视觉信号处理的方法，并通过OCR技术提取文本特征，以改进语义ID的学习效果。", "motivation": "传统的基于预训练文本编码器的生成推荐模型在处理符号化和属性中心化的项目描述时存在困难，导致语义连贯性减弱。此外，在多模态场景中，文本和图像嵌入之间的几何结构不匹配也降低了跨模态融合的效果。", "method": "本文通过将项目描述渲染为图像，并使用基于视觉的OCR模型来编码这些图像，从而获取文本表示。这种方法被用于改进语义ID的学习。", "result": "实验结果显示，在四种数据集和两种生成性后端上，OCR提取的文本特征在单一模态和多模态设置下均能与或超越标准文本嵌入的效果。此外，该方法在极端空间分辨率压缩的情况下也表现出强大的鲁棒性和高效性。", "conclusion": "将文本视为视觉信号并通过OCR技术处理的方法能够有效改进生成推荐系统中的语义ID学习，并且具有良好的鲁棒性和效率。"}}
{"id": "2601.14695", "pdf": "https://arxiv.org/pdf/2601.14695", "abs": "https://arxiv.org/abs/2601.14695", "authors": ["Yutong Chen", "Jiandong Gao", "Ji Wu"], "title": "CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation", "categories": ["cs.LG", "cs.AI"], "comment": "preprint", "summary": "Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.", "AI": {"tldr": "本文介绍了CoScale-RL，一种新的用于大型推理模型的后训练缩放策略，通过同时优化数据和计算效率来提高模型性能。", "motivation": "由于大型推理模型（LRM）在面对复杂问题或基础较弱时训练不稳定且不可预测，现有的后训练扩展策略仍可提升这些情况下的表现。因此，提出了CoScale-RL以进一步稳定并改善模型的推理能力。", "method": "方法包括首先通过收集每个问题的多个解决方案来扩大解决范围，而不是简单地增加数据集大小；其次，通过放大回滚计算量来稳定强化学习过程，并使用重新蒸馏技术保持或提高缩放时的计算效率。", "result": "该方法显著提高了数据和计算效率，在四个基准测试上平均提升了3.76倍的准确率，并且无需依赖大规模监督微调（SFT）数据集即可提升LRM的能力边界。", "conclusion": "CoScale-RL为大型推理模型提供了一个新的缩放方向，能够进一步提高其推理能力，而不需要大量的额外训练数据。"}}
{"id": "2601.14694", "pdf": "https://arxiv.org/pdf/2601.14694", "abs": "https://arxiv.org/abs/2601.14694", "authors": ["Pengfei Ding", "Yan Wang", "Guanfeng Liu"], "title": "Re-understanding Graph Unlearning through Memorization", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted by WWW-2026", "summary": "Graph unlearning (GU), which removes nodes, edges, or features from trained graph neural networks (GNNs), is crucial in Web applications where graph data may contain sensitive, mislabeled, or malicious information. However, existing GU methods lack a clear understanding of the key factors that determine unlearning effectiveness, leading to three fundamental limitations: (1) impractical and inaccurate GU difficulty assessment due to test-access requirements and invalid assumptions, (2) ineffectiveness on hard-to-unlearn tasks, and (3) misaligned evaluation protocols that overemphasize easy tasks and fail to capture true forgetting capability. To address these issues, we establish GNN memorization as a new perspective for understanding graph unlearning and propose MGU, a Memorization-guided Graph Unlearning framework. MGU achieves three key advances: it provides accurate and practical difficulty assessment across different GU tasks, develops an adaptive strategy that dynamically adjusts unlearning objectives based on difficulty levels, and establishes a comprehensive evaluation protocol that aligns with practical requirements. Extensive experiments on ten real-world graphs demonstrate that MGU consistently outperforms state-of-the-art baselines in forgetting quality, computational efficiency, and utility preservation.", "AI": {"tldr": "本文提出了一种基于记忆指导的图无学习框架MGU，解决了现有图无学习方法在评估难度、应对困难任务和评价协议方面的三个基本局限。", "motivation": "现有的图无学习（GU）方法缺乏对决定无学习有效性关键因素的理解，导致无法准确评估无学习难度、难以处理难于遗忘的任务以及评价协议不全面等问题。为了解决这些问题，作者提出了新的研究视角和解决方案。", "method": "本文通过将GNN的记忆化作为理解图无学习的新视角，提出了一种名为MGU的框架，该框架能够提供准确且实用的难度评估、开发动态调整无学习目标的适应策略，并建立全面的评价协议。", "result": "实验结果表明，在十种真实世界的数据集上，MGU在遗忘质量、计算效率和效用保持方面始终优于现有的最先进方法。", "conclusion": "本文提出的方法通过记忆指导框架解决了现有图无学习中的多个局限性，并且在多方面的实验中表现出色，展示了其作为实用解决方案的潜力。"}}
{"id": "2601.14693", "pdf": "https://arxiv.org/pdf/2601.14693", "abs": "https://arxiv.org/abs/2601.14693", "authors": ["Jianwen Sun", "Xinrui Li", "Fuqing Li", "Xiaoxuan Shen"], "title": "Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Symbolic Regression aims to automatically identify compact and interpretable mathematical expressions that model the functional relationship between input and output variables. Most existing search-based symbolic regression methods typically rely on the fitting error to inform the search process. However, in the vast expression space, numerous candidate expressions may exhibit similar error values while differing substantially in structure, leading to ambiguous search directions and hindering convergence to the underlying true function. To address this challenge, we propose a novel framework named EGRL-SR (Experience-driven Goal-conditioned Reinforcement Learning for Symbolic Regression). In contrast to traditional error-driven approaches, EGRL-SR introduces a new perspective: leveraging precise historical trajectories and optimizing the action-value network to proactively guide the search process, thereby achieving a more robust expression search. Specifically, we formulate symbolic regression as a goal-conditioned reinforcement learning problem and incorporate hindsight experience replay, allowing the action-value network to generalize common mapping patterns from diverse input-output pairs. Moreover, we design an all-point satisfaction binary reward function that encourages the action-value network to focus on structural patterns rather than low-error expressions, and concurrently propose a structure-guided heuristic exploration strategy to enhance search diversity and space coverage. Experiments on public benchmarks show that EGRL-SR consistently outperforms state-of-the-art methods in recovery rate and robustness, and can recover more complex expressions under the same search budget. Ablation results validate that the action-value network effectively guides the search, with both the reward function and the exploration strategy playing critical roles.", "AI": {"tldr": "本文提出了一种名为EGRL-SR的新框架，采用基于经验的有条件强化学习方法来解决符号回归问题。", "motivation": "传统的基于误差的方法在搜索空间中可能会遇到结构差异大的候选表达式具有相似错误值的问题，导致搜索方向不明确和收敛困难。", "method": "将符号回归视为一个基于目标的强化学习问题，并结合回顾经验重播来优化行动价值网络，设计了全点满足二进制奖励函数和结构引导启发探索策略。", "result": "实验表明EGRL-SR在公开基准上的恢复率和鲁棒性方面优于现有方法，并能恢复更复杂的表达式。", "conclusion": "该研究表明，通过引入基于经验的强化学习框架来指导符号回归搜索过程可以有效地提高性能并增强结构模式的学习能力。"}}
{"id": "2601.14691", "pdf": "https://arxiv.org/pdf/2601.14691", "abs": "https://arxiv.org/abs/2601.14691", "authors": ["Muhammad Khalifa", "Lajanugen Logeswaran", "Jaekyeom Kim", "Sungryull Sohn", "Yunxiang Zhang", "Moontae Lee", "Hao Peng", "Lu Wang", "Honglak Lee"], "title": "Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute, which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence.", "AI": {"tldr": "研究揭示了大型语言模型作为评估代理性能的裁判时存在的脆弱性，特别是在操纵链式思维的情况下。", "motivation": "动机在于探讨大型语言模型作为裁判在非验证设置下判断代理表现时是否存在易被操控的问题。", "method": "通过系统地重写代理的链式思维痕迹来测试对现有视觉语言模型裁判的影响，同时保持动作和观察不变，并研究了基于样式的操纵策略以及基于内容的方法。", "result": "结果显示，操纵后的推理能够将最先进的VLM裁判的错误阳性率提高到90%，特别是在不同网络任务中。此外，发现基于内容的操纵比基于样式的方法更有效。", "conclusion": "研究揭示了一种基本的脆弱性，在于大型语言模型作为评估机制时容易受到代理行为痕迹操控的影响，并强调了开发能验证推理主张与可观测证据相一致的裁判方法的需求。"}}
{"id": "2601.14690", "pdf": "https://arxiv.org/pdf/2601.14690", "abs": "https://arxiv.org/abs/2601.14690", "authors": ["Yian Huang", "Qing Qin", "Aji Mao", "Xiangyu Qiu", "Liang Xu", "Xian Zhang", "Zhenming Peng"], "title": "FeedbackSTS-Det: Sparse Frames-Based Spatio-Temporal Semantic Feedback Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": "Submitted to Journal IEEE Transactions on Geoscience and Remote Sensing", "summary": "Infrared small target detection (ISTD) under complex backgrounds remains a critical yet challenging task, primarily due to the extremely low signal-to-clutter ratio, persistent dynamic interference, and the lack of distinct target features. While multi-frame detection methods leverages temporal cues to improve upon single-frame approaches, existing methods still struggle with inefficient long-range dependency modeling and insufficient robustness. To overcome these issues, we propose a novel scheme for ISTD, realized through a sparse frames-based spatio-temporal semantic feedback network named FeedbackSTS-Det. The core of our approach is a novel spatio-temporal semantic feedback strategy with a closed-loop semantic association mechanism, which consists of paired forward and backward refinement modules that work cooperatively across the encoder and decoder. Moreover, both modules incorporate an embedded sparse semantic module (SSM), which performs structured sparse temporal modeling to capture long-range dependencies with low computational cost. This integrated design facilitates robust implicit inter-frame registration and continuous semantic refinement, effectively suppressing false alarms. Furthermore, our overall procedure maintains a consistent training-inference pipeline, which ensures reliable performance transfer and increases model robustness. Extensive experiments on multiple benchmark datasets confirm the effectiveness of FeedbackSTS-Det. Code and models are available at: https://github.com/IDIP-Lab/FeedbackSTS-Det.", "AI": {"tldr": "本文提出了一个基于稀疏帧的时空语义反馈网络（FeedbackSTS-Det）用于红外小目标检测。", "motivation": "红外小目标检测在复杂背景下仍然是具有挑战性的任务，主要由于低信杂比、持续动态干扰和缺乏明显的目标特征。现有的多帧检测方法难以有效建模长程依赖关系，并且鲁棒性不足。", "method": "提出了一种基于稀疏帧的时空语义反馈网络（FeedbackSTS-Det），核心是时空语义反馈策略，包括前向和后向精炼模块，这些模块在编码器和解码器之间协同工作。同时采用了嵌入式稀疏语义模块（SSM）来建模结构化的稀疏时序关系，以捕获长程依赖。", "result": "实验结果表明，FeedbackSTS-Det在多个基准数据集上验证了其有效性，并且保持了一致的训练-推理流程，确保性能转移可靠性和模型鲁棒性。", "conclusion": "研究提出的方法显著提升了红外小目标检测的效果，特别是提高了长程依赖关系建模和鲁棒性。"}}
{"id": "2601.14686", "pdf": "https://arxiv.org/pdf/2601.14686", "abs": "https://arxiv.org/abs/2601.14686", "authors": ["Shuai Wang", "Yaoming Yang", "Bingdong Li", "Hao Hao", "Aimin Zhou"], "title": "IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendation, applying them to long-horizon LPR is challenging due to (i) misalignment with pedagogical objectives such as the Zone of Proximal Development (ZPD) under sparse, delayed feedback, (ii) scarce and costly expert demonstrations, and (iii) multi-objective interactions among learning effect, difficulty scheduling, length controllability, and trajectory diversity. To address these issues, we propose IB-GRPO (Indicator-Based Group Relative Policy Optimization), an indicator-guided alignment approach for LLM-based LPR. To mitigate data scarcity, we construct hybrid expert demonstrations via Genetic Algorithm search and teacher RL agents and warm-start the LLM with supervised fine-tuning. Building on this warm-start, we design a within-session ZPD alignment score for difficulty scheduling. IB-GRPO then uses the $I_{ε+}$ dominance indicator to compute group-relative advantages over multiple objectives, avoiding manual scalarization and improving Pareto trade-offs. Experiments on ASSIST09 and Junyi using the KES simulator with a Qwen2.5-7B backbone show consistent improvements over representative RL and LLM baselines.", "AI": {"tldr": "本文提出IB-GRPO方法，通过指示器引导的大规模语言模型学习路径推荐，使其与教育目标保持一致。", "motivation": "虽然大语言模型能提供丰富的语义理解能力用于自由形式的推荐，但将其应用于长期的学习路径推荐存在挑战：与教学目标不一致、专家演示稀缺且成本高以及多目标交互等问题。", "method": "IB-GRPO方法通过遗传算法搜索和教师强化学习代理构建混合专家示范来缓解数据不足问题。使用$ I_{ε+} $优势指标计算多个目标的组相对优势，避免手动标量化并改善帕累托折衷。", "result": "在ASSIST09和Junyi数据集上使用KES仿真器与Qwen2.5-7B模型作为基础进行实验，显示了比代表性的强化学习和大语言模型基线更好的一致性改进。", "conclusion": "IB-GRPO方法成功解决了大规模语言模型应用于长期学习路径推荐中的挑战，并在实验中展示了其有效性。"}}
{"id": "2601.14684", "pdf": "https://arxiv.org/pdf/2601.14684", "abs": "https://arxiv.org/abs/2601.14684", "authors": ["Kanami Imamura", "Tomohiko Nakamura", "Kohei Yatabe", "Hiroshi Saruwatari"], "title": "Dissecting Performance Degradation in Audio Source Separation under Sampling Frequency Mismatch", "categories": ["cs.SD"], "comment": "Accepted for ICASSP 2026", "summary": "Audio processing methods based on deep neural networks are typically trained at a single sampling frequency (SF). To handle untrained SFs, signal resampling is commonly employed, but it can degrade performance, particularly when the input SF is lower than the trained SF. This paper investigates the causes of this degradation through two hypotheses: (i) the lack of high-frequency components introduced by up-sampling, and (ii) the greater importance of their presence than their precise representation. To examine these hypotheses, we compare conventional resampling with three alternatives: post-resampling noise addition, which adds Gaussian noise to the resampled signal; noisy-kernel resampling, which perturbs the kernel with Gaussian noise to enrich high-frequency components; and trainable-kernel resampling, which adapts the interpolation kernel through training. Experiments on music source separation show that noisy-kernel and trainable-kernel resampling alleviate the degradation observed with conventional resampling. We further demonstrate that noisy-kernel resampling is effective across diverse models, highlighting it as a simple yet practical option.", "AI": {"tldr": "本文探讨了音频源分离中采样频率不匹配导致性能下降的原因，并提出了几种改进方法。", "motivation": "基于深度神经网络的音频处理方法通常在单一采样频率下训练，当遇到未经训练的采样频率时，信号重采样会导致性能下降，特别是输入采样频率低于训练频率时更为明显。因此，本文旨在调查这种性能下降的原因，并提出改进策略。", "method": "通过两种假设来探究性能下降的原因：（i）上采样引入高频频谱不足；（ii）其存在比精准表示更重要。研究比较了传统重采样与三种替代方法的效果，分别是添加噪声后的重采样、带噪核的重采样和可训练核的重采样。", "result": "实验表明，带噪核和可训练核的重采样能够缓解使用传统重采样时观察到的性能下降现象，并且带噪核重采样的方法在各种模型中都表现出有效性。", "conclusion": "研究表明，通过引入噪声或调整插值内核来增强高频成分，可以改善音频源分离中因采样频率不匹配而导致的性能下降问题。"}}
{"id": "2601.14683", "pdf": "https://arxiv.org/pdf/2601.14683", "abs": "https://arxiv.org/abs/2601.14683", "authors": ["Aisvarya Adeseye", "Jouni Isoaho", "Seppo Virtanen", "Mohammad Tahir"], "title": "Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text", "categories": ["cs.AI"], "comment": "Accepted and Waiting to be Published. ICAI'25: 27th International Conference on Artificial Intelligence https://american-cse.org/csce2025/conferences-ICAI", "summary": "Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.", "AI": {"tldr": "本文提出了一种基于本地语言模型的结构化框架，用于适应性匿名化处理敏感文本。", "motivation": "传统的手动和自动化匿名化方法存在时间成本高、不一致性和忽略关键标识符的问题。本研究旨在开发一个可靠且可重复使用的上下文感知匿名化过程。", "method": "该研究引入了结构化框架自适应匿名器(SFAA)，包括检测、分类和自适应匿名化三个步骤，并应用了四种匿名策略：基于规则的替换、上下文感知重写、泛化和抑制。", "result": "在两个案例研究中，使用LLaMA和Phi两种本地模型评估了框架的表现。Phi模型找到了超过91%的敏感数据，且保持原始文本的情感不变，准确率达到94.8%，优于人工审阅者和LLaMA。", "conclusion": "结果表明，基于本地语言模型的自适应匿名化方法能够更有效地发现并处理敏感数据，同时保留了数据的原意。"}}
{"id": "2601.14681", "pdf": "https://arxiv.org/pdf/2601.14681", "abs": "https://arxiv.org/abs/2601.14681", "authors": ["Shuhao Liao", "Xuxin Lv", "Jeric Lew", "Shizhe Zhang", "Jingsong Liang", "Peizhuo Li", "Yuhong Cao", "Wenjun Wu", "Guillaume Sartoretti"], "title": "FARE: Fast-Slow Agentic Robotic Exploration", "categories": ["cs.RO"], "comment": null, "summary": "This work advances autonomous robot exploration by integrating agent-level semantic reasoning with fast local control. We introduce FARE, a hierarchical autonomous exploration framework that integrates a large language model (LLM) for global reasoning with a reinforcement learning (RL) policy for local decision making. FARE follows a fast-slow thinking paradigm. The slow-thinking LLM module interprets a concise textual description of the unknown environment and synthesizes an agent-level exploration strategy, which is then grounded into a sequence of global waypoints through a topological graph. To further improve reasoning efficiency, this module employs a modularity-based pruning mechanism that reduces redundant graph structures. The fast-thinking RL module executes exploration by reacting to local observations while being guided by the LLM-generated global waypoints. The RL policy is additionally shaped by a reward term that encourages adherence to the global waypoints, enabling coherent and robust closed-loop behavior. This architecture decouples semantic reasoning from geometric decision, allowing each module to operate in its appropriate temporal and spatial scale. In challenging simulated environments, our results show that FARE achieves substantial improvements in exploration efficiency over state-of-the-art baselines. We further deploy FARE on hardware and validate it in complex, large scale $200m\\times130m$ building environment.", "AI": {"tldr": "介绍FARE，一种结合快速局部控制和代理级别语义推理的自主机器人探索框架。", "motivation": "提升自动机器人在未知环境中的探索效率。", "method": "采用分层架构，将大型语言模型用于全局推理以制定探索策略，并使用强化学习进行局部决策执行。", "result": "FARE在模拟和实际复杂环境中均展示了显著的探索效率提高。", "conclusion": "该方法通过解耦语义推理与几何决策，实现了有效的自主机器人探索。"}}
{"id": "2601.14679", "pdf": "https://arxiv.org/pdf/2601.14679", "abs": "https://arxiv.org/abs/2601.14679", "authors": ["Yiran Zhang", "Xingpeng Sun", "Aniket Bera"], "title": "HCVR Scene Generation: High Compatibility Virtual Reality Environment Generation for Extended Redirected Walking", "categories": ["cs.MM", "cs.AI"], "comment": null, "summary": "Natural walking enhances immersion in virtual environments (VEs), but physical space limitations and obstacles hinder exploration, especially in large virtual scenes. Redirected Walking (RDW) techniques mitigate this by subtly manipulating the virtual camera to guide users away from physical collisions within pre-defined VEs. However, RDW efficacy diminishes significantly when substantial geometric divergence exists between the physical and virtual environments, leading to unavoidable collisions. Existing scene generation methods primarily focus on object relationships or layout aesthetics, often neglecting the crucial aspect of physical compatibility required for effective RDW. To address this, we introduce HCVR (High Compatibility Virtual Reality Environment Generation), a novel framework that generates virtual scenes inherently optimized for alignment-based RDW controllers. HCVR first employs ENI++, a novel, boundary-sensitive metric to evaluate the incompatibility between physical and virtual spaces by comparing rotation-sensitive visibility polygons. Guided by the ENI++ compatibility map and user prompts, HCVR utilizes a Large Language Model (LLM) for context-aware 3D asset retrieval and initial layout generation. The framework then strategically adjusts object selection, scaling, and placement to maximize coverage of virtually incompatible regions, effectively guiding users towards RDW-feasible paths. User studies evaluating physical collisions and layout quality demonstrate HCVR's effectiveness with HCVR-generated scenes, resulting in 22.78 times fewer physical collisions and received 35.89\\% less on ENI++ score compared to LLM-based generation with RDW, while also receiving 12.5\\% higher scores on user feedback to layout design.", "AI": {"tldr": "介绍了一种名为HCVR的新型框架，用于生成适合重定向行走技术（RDW）的虚拟现实环境。", "motivation": "旨在解决现有方法在物理空间与虚拟场景之间存在几何差异时，导致使用重定向行走技术时不可避免碰撞的问题。", "method": "采用ENI++评估物理和虚拟空间之间的不兼容性，并利用大型语言模型（LLM）进行上下文感知的3D资产检索及初始布局生成，优化对象选择、缩放和平移以最大化覆盖不适合区域。", "result": "用户研究表明HCVR生成的场景减少了22.78倍的物理碰撞，并在ENI++评分中降低了35.89%，同时获得了12.5%更高的用户反馈得分。", "conclusion": "证明了HCVR框架的有效性，它通过优化虚拟环境与重定向行走技术的一致性来减少碰撞并提高用户体验。"}}
{"id": "2601.14678", "pdf": "https://arxiv.org/pdf/2601.14678", "abs": "https://arxiv.org/abs/2601.14678", "authors": ["Justin Cheung", "Samuel Savine", "Calvin Nguyen", "Lin Lu", "Alhassan S. Yasin"], "title": "Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE", "q-bio.TO"], "comment": "8 pages, 6 figures, 3 table", "summary": "Supervised deep learning models often achieve excellent performance within their training distribution but struggle to generalize beyond it. In cancer histopathology, for example, a convolutional neural network (CNN) may classify cancer severity accurately for cancer types represented in its training data, yet fail on related but unseen types. Although adenocarcinomas from different organs share morphological features that might support limited cross-domain generalization, addressing domain shift directly is necessary for robust performance. Domain adaptation offers a way to transfer knowledge from labeled data in one cancer type to unlabeled data in another, helping mitigate the scarcity of annotated medical images. This work evaluates cross-domain classification performance among lung, colon, breast, and kidney adenocarcinomas. A ResNet50 trained on any single adenocarcinoma achieves over 98% accuracy on its own domain but shows minimal generalization to others. Ensembling multiple supervised models does not resolve this limitation. In contrast, converting the ResNet50 into a domain adversarial neural network (DANN) substantially improves performance on unlabeled target domains. A DANN trained on labeled breast and colon data and adapted to unlabeled lung data reaches 95.56% accuracy. We also examine the impact of stain normalization on domain adaptation. Its effects vary by target domain: for lung, accuracy drops from 95.56% to 66.60%, while for breast and colon targets, stain normalization boosts accuracy from 49.22% to 81.29% and from 78.48% to 83.36%, respectively. Finally, using Integrated Gradients reveals that DANNs consistently attribute importance to biologically meaningful regions such as densely packed nuclei, indicating that the model learns clinically relevant features and can apply them to unlabeled cancer types.", "AI": {"tldr": "通过深度学习领域适应，将一种癌症的知识转移到另一种癌症中，以提高模型在未见过的癌症类型上的分类性能。", "motivation": "解决监督深度学习模型在训练数据分布之外难以泛化的问题，特别是对于医学图像标注稀缺的情况。通过跨域迁移知识来改善不同癌症组织之间的分类效果。", "method": "使用ResNet50进行基础模型训练，并将其转换为领域对抗网络（DANN）以提高在未标记目标领域的性能，同时研究了染色标准化对领域适应的影响。", "result": "与单一监督学习相比，DANN显著提高了在不同腺癌类型之间的分类准确率；染色标准化的效果因目标域的不同而变化，对于某些癌症类型有助于提升模型准确性。", "conclusion": "通过领域对抗神经网络可以实现有效的跨域知识迁移，并且集成分析揭示了模型能够识别出具有临床意义的生物特征区域。"}}
{"id": "2601.14677", "pdf": "https://arxiv.org/pdf/2601.14677", "abs": "https://arxiv.org/abs/2601.14677", "authors": ["Sukana Zulfqar", "Sadia Saeed", "M. Azam Zia", "Anjum Ali", "Faisal Mehmood", "Abid Ali"], "title": "A comprehensive overview of deep learning models for object detection from videos/images", "categories": ["cs.CV", "cs.AI"], "comment": "N/A", "summary": "Object detection in video and image surveillance is a well-established yet rapidly evolving task, strongly influenced by recent deep learning advancements. This review summarises modern techniques by examining architectural innovations, generative model integration, and the use of temporal information to enhance robustness and accuracy. Unlike earlier surveys, it classifies methods based on core architectures, data processing strategies, and surveillance specific challenges such as dynamic environments, occlusions, lighting variations, and real-time requirements. The primary goal is to evaluate the current effectiveness of semantic object detection, while secondary aims include analysing deep learning models and their practical applications. The review covers CNN-based detectors, GAN-assisted approaches, and temporal fusion methods, highlighting how generative models support tasks such as reconstructing missing frames, reducing occlusions, and normalising illumination. It also outlines preprocessing pipelines, feature extraction progress, benchmarking datasets, and comparative evaluations. Finally, emerging trends in low-latency, efficient, and spatiotemporal learning approaches are identified for future research.", "AI": {"tldr": "本文综述了深度学习在视频和图像对象检测中的现代技术，包括基于核心架构、数据处理策略以及特定挑战的方法，并探讨了未来的研究趋势。", "motivation": "本研究旨在评估当前语义对象检测的有效性，并分析深度学习模型及其实际应用。", "method": "本文通过分类方法来审视架构创新、生成模型集成和使用时间信息以增强鲁棒性和准确性，涵盖了CNN检测器、GAN辅助方法和时间融合方法。", "result": "综述了预处理流水线、特征提取进展、基准数据集以及比较评估，并指出低延迟、高效和时空学习方法的新兴趋势。", "conclusion": "本文强调了生成模型在重建丢失帧、减少遮挡和正常化照明等方面的支持作用，为未来的研究指明方向。"}}
{"id": "2601.14674", "pdf": "https://arxiv.org/pdf/2601.14674", "abs": "https://arxiv.org/abs/2601.14674", "authors": ["Mingyang Xie", "Numair Khan", "Tianfu Wang", "Naina Dhingra", "Seonghyeon Nam", "Haitao Yang", "Zhuo Hui", "Christopher Metzler", "Andrea Vedaldi", "Hamed Pirsiavash", "Lei Luo"], "title": "LaVR: Scene Latent Conditioned Generative Video Trajectory Re-Rendering using Large 4D Reconstruction Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Given a monocular video, the goal of video re-rendering is to generate views of the scene from a novel camera trajectory. Existing methods face two distinct challenges. Geometrically unconditioned models lack spatial awareness, leading to drift and deformation under viewpoint changes. On the other hand, geometrically-conditioned models depend on estimated depth and explicit reconstruction, making them susceptible to depth inaccuracies and calibration errors. We propose to address these challenges by using the implicit geometric knowledge embedded in the latent space of a large 4D reconstruction model to condition the video generation process. These latents capture scene structure in a continuous space without explicit reconstruction. Therefore, they provide a flexible representation that allows the pretrained diffusion prior to regularize errors more effectively. By jointly conditioning on these latents and source camera poses, we demonstrate that our model achieves state-of-the-art results on the video re-rendering task. Project webpage is https://lavr-4d-scene-rerender.github.io/", "AI": {"tldr": "该论文提出了LaVR，一种使用大型4D重建模型的场景潜在条件生成视频轨迹重渲染技术。", "motivation": "现有的视频重渲染方法面临着几何非条件模型缺乏空间意识和几何条件模型依赖于估计深度的问题。本文旨在通过利用隐含在大规模4D重建模型中的几何知识来解决这些问题。", "method": "该方法使用大型4D重建模型的潜在空间中的隐式几何知识来调节视频生成过程，这些潜在变量捕获场景结构，提供了一个灵活的表示，使预训练的扩散先验能够更有效地规范错误，并且通过同时对这些潜在变量和源相机姿态进行条件约束。", "result": "实验结果表明，该模型在视频重渲染任务上达到了最先进的水平。", "conclusion": "LaVR通过利用大型4D重建模型的潜力建立了一个有效的视频重新渲染方法，解决了现有方法中存在的问题并展示了优越的结果。"}}
{"id": "2601.14673", "pdf": "https://arxiv.org/pdf/2601.14673", "abs": "https://arxiv.org/abs/2601.14673", "authors": ["Yogesh Pipada Sunil Kumar", "S. Ali Pourmousavi", "Jon A. R. Liisberg", "Julian Lesmos-Vinasco"], "title": "Efficient reformulations of ReLU deep neural networks for surrogate modelling in power system optimisation", "categories": ["eess.SY", "cs.AI"], "comment": "24 pages, 7 figures, 3 tables", "summary": "The ongoing decarbonisation of power systems is driving an increasing reliance on distributed energy resources, which introduces complex and nonlinear interactions that are difficult to capture in conventional optimisation models. As a result, machine learning based surrogate modelling has emerged as a promising approach, but integrating machine learning models such as ReLU deep neural networks (DNNs) directly into optimisation often results in nonconvex and computationally intractable formulations. This paper proposes a linear programming (LP) reformulation for a class of convexified ReLU DNNs with non-negative weight matrices beyond the first layer, enabling a tight and tractable embedding of learned surrogate models in optimisation. We evaluate the method using a case study on learning the prosumer's responsiveness within an aggregator bidding problem in the Danish tertiary capacity market. The proposed reformulation is benchmarked against state-of-the-art alternatives, including piecewise linearisation (PWL), MIP-based embedding, and other LP relaxations. Across multiple neural network architectures and market scenarios, the convexified ReLU DNN achieves solution quality comparable to PWL and MIP-based reformulations while significantly improving computational performance and preserving model fidelity, unlike penalty-based reformulations. The results demonstrate that convexified ReLU DNNs offer a scalable and reliable methodology for integrating learned surrogate models in optimisation, with applicability to a wide range of emerging power system applications.", "AI": {"tldr": "本文提出了一个线性规划（LP）的重新形式化方案，用于一类具有非负权重矩阵的ReLU深度神经网络，以便将学习到的代理模型更紧密地嵌入优化问题中。", "motivation": "由于电力系统正在向低碳转型，并依赖于分布式能源资源，导致了复杂且非线性的互动关系难以通过传统的优化模型捕捉。因此，基于机器学习的代理建模作为一种有前景的方法出现，但直接将此类模型如ReLU深度神经网络集成到优化中会导致非凸和计算上不可行的形式。", "method": "本文提出了一种针对具有非负权重矩阵ReLU深度神经网络的线性规划重新形式化方案，使得该类学习得到的代理模型能够被紧密且有效地嵌入到优化问题中。", "result": "通过丹麦三级容量市场中的聚合商竞价问题案例研究评估了所提方法。与状态-of-the-art的替代方案（包括分段线性化、基于MIP的嵌入和其他LP松弛）相比，提出的凸ReLU深度神经网络在多个神经网络架构和市场场景中获得了与PWL和基于MIP的重新形式化的解决方案质量相当的结果，同时显著提高了计算性能并保持了模型保真度。", "conclusion": "研究表明，凸ReLU深度神经网络提供了一种可扩展且可靠的集成方法，用于将学习到的代理模型嵌入优化问题中，并适用于广泛新兴电力系统应用。"}}
{"id": "2601.14672", "pdf": "https://arxiv.org/pdf/2601.14672", "abs": "https://arxiv.org/abs/2601.14672", "authors": ["Amaras Nazarians", "Sachin Kumar"], "title": "GEGO: A Hybrid Golden Eagle and Genetic Optimization Algorithm for Efficient Hyperparameter Tuning in Resource-Constrained Environments", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Hyperparameter tuning is a critical yet computationally expensive step in training neural networks, particularly when the search space is high dimensional and nonconvex. Metaheuristic optimization algorithms are often used for this purpose due to their derivative free nature and robustness against local optima. In this work, we propose Golden Eagle Genetic Optimization (GEGO), a hybrid metaheuristic that integrates the population movement strategy of Golden Eagle Optimization with the genetic operators of selection, crossover, and mutation. The main novelty of GEGO lies in embedding genetic operators directly into the iterative search process of GEO, rather than applying them as a separate evolutionary stage. This design improves population diversity during search and reduces premature convergence while preserving the exploration behavior of GEO. GEGO is evaluated on standard unimodal, multimodal, and composite benchmark functions from the CEC2017 suite, where it consistently outperforms its constituent algorithms and several classical metaheuristics in terms of solution quality and robustness. The algorithm is further applied to hyperparameter tuning of artificial neural networks on the MNIST dataset, where GEGO achieves improved classification accuracy and more stable convergence compared to GEO and GA. These results indicate that GEGO provides a balanced exploration-exploitation tradeoff and is well suited for hyperparameter optimization under constrained computational settings.", "AI": {"tldr": "介绍了一种混合金鹰和遗传优化算法（GEGO），用于在资源受限环境中高效地进行超参数调优。", "motivation": "解决神经网络训练中超参数调整计算成本高、搜索空间大且非凸的问题，利用无导数特性和抗局部最优性的元启发式算法来提高效率。", "method": "提出一种将金鹰优化算法的群体运动策略与遗传算法的选择、交叉和变异操作结合的新方法GEGO，在迭代搜索过程中直接嵌入遗传算子以改善种群多样性，减少过早收敛，并保持探索行为。", "result": "在CEC2017基准函数集上的测试表明，GEGO在解的质量和鲁棒性上优于其组成算法和其他经典元启发式算法；应用到MNIST数据集的神经网络超参数调优中时，取得了更高的分类准确率和更稳定的收敛效果。", "conclusion": "结果证明GEGO提供了一种平衡探索与开发的方法，并适用于计算资源受限条件下的超参数优化问题。"}}
{"id": "2601.14671", "pdf": "https://arxiv.org/pdf/2601.14671", "abs": "https://arxiv.org/abs/2601.14671", "authors": ["Yonghao Yu", "Lang Huang", "Zerun Wang", "Runyi Li", "Toshihiko Yamasaki"], "title": "Mirai: Autoregressive Visual Generation Needs Foresight", "categories": ["cs.CV"], "comment": null, "summary": "Autoregressive (AR) visual generators model images as sequences of discrete tokens and are trained with next token likelihood. This strict causality supervision optimizes each step only by its immediate next token, which diminishes global coherence and slows convergence. We ask whether foresight, training signals that originate from later tokens, can help AR visual generation. We conduct a series of controlled diagnostics along the injection level, foresight layout, and foresight source axes, unveiling a key insight: aligning foresight to AR models' internal representation on the 2D image grids improves causality modeling. We formulate this insight with Mirai (meaning \"future\" in Japanese), a general framework that injects future information into AR training with no architecture change and no extra inference overhead: Mirai-E uses explicit foresight from multiple future positions of unidirectional representations, whereas Mirai-I leverages implicit foresight from matched bidirectional representations. Extensive experiments show that Mirai significantly accelerates convergence and improves generation quality. For instance, Mirai can speed up LlamaGen-B's convergence by up to 10$\\times$ and reduce the generation FID from 5.34 to 4.34 on the ImageNet class-condition image generation benchmark. Our study highlights that visual autoregressive models need foresight.", "AI": {"tldr": "研究提出了一种名为Mirai的框架，通过注入未来信息来改进自回归视觉生成模型的训练。", "motivation": "传统的自回归（AR）视觉生成器优化每个步骤仅基于其直接的下一个令牌，这导致了全局连贯性的缺失和收敛速度的降低。该研究旨在探讨来自后续令牌的预知信号是否能改善AR视觉生成。", "method": "Mirai框架包括两种模式：Mirai-E使用单向表示中多个未来位置的显式预知；Mirai-I利用双向表示中的隐式预知来增强模型内部2D图像网格上的因果建模。", "result": "实验表明，与传统的自回归视觉生成器相比，采用Mirai框架可以显著加速收敛速度并提高生成质量。例如，在ImageNet类别条件图像生成基准上，LlamaGen-B的收敛速度提升至原来的10倍，生成FID从5.34降低到4.34。", "conclusion": "研究强调了视觉自回归模型需要预知信息来改善全局连贯性和加速训练过程。"}}
{"id": "2601.14667", "pdf": "https://arxiv.org/pdf/2601.14667", "abs": "https://arxiv.org/abs/2601.14667", "authors": ["Yijin Zhou", "Xiaoya Lu", "Dongrui Liu", "Junchi Yan", "Jing Shao"], "title": "INFA-Guard: Mitigating Malicious Propagation via Infection-Aware Safeguarding in LLM-Based Multi-Agent Systems", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "The rapid advancement of Large Language Model (LLM)-based Multi-Agent Systems (MAS) has introduced significant security vulnerabilities, where malicious influence can propagate virally through inter-agent communication. Conventional safeguards often rely on a binary paradigm that strictly distinguishes between benign and attack agents, failing to account for infected agents i.e., benign entities converted by attack agents. In this paper, we propose Infection-Aware Guard, INFA-Guard, a novel defense framework that explicitly identifies and addresses infected agents as a distinct threat category. By leveraging infection-aware detection and topological constraints, INFA-Guard accurately localizes attack sources and infected ranges. During remediation, INFA-Guard replaces attackers and rehabilitates infected ones, avoiding malicious propagation while preserving topological integrity. Extensive experiments demonstrate that INFA-Guard achieves state-of-the-art performance, reducing the Attack Success Rate (ASR) by an average of 33%, while exhibiting cross-model robustness, superior topological generalization, and high cost-effectiveness.", "AI": {"tldr": "本文提出了INFA-Guard，一种新型防御框架，通过识别和处理被感染的代理来缓解基于大型语言模型的多智能体系统中的恶意传播。", "motivation": "随着基于大型语言模型的多智能体系统的快速发展，传统的安全防护手段在面对复杂的恶意影响传播问题时显得不足，特别是对于那些已经受到攻击而转变成威胁的代理。", "method": "INFA-Guard通过利用感染检测和拓扑约束来准确识别攻击源和被感染区域，并在补救过程中替换攻击者并恢复受感染的代理以阻止恶意传播同时保持系统结构完整。", "result": "实验表明，与现有方法相比，INFA-Guard显著降低了攻击成功率（ASR），平均下降了33%，并且显示出了跨模型稳健性、优越的拓扑泛化能力和高成本效益。", "conclusion": "研究结果证明了INFA-Guard在防止恶意影响传播方面的有效性，并展示了其在大型语言模型多智能体系统中实现安全防护的新方向和潜力。"}}
{"id": "2601.14663", "pdf": "https://arxiv.org/pdf/2601.14663", "abs": "https://arxiv.org/abs/2601.14663", "authors": ["Yogesh Pipada Sunil Kumar", "S. Ali Pourmousavi", "Jon A. R. Liisberg", "Julian Lesmos-Vinasco"], "title": "Calibrated uncertainty quantification for prosumer flexibility aggregation in ancillary service markets", "categories": ["eess.SY", "cs.AI"], "comment": "Single column 31 pages, 10 figures, 3 tables, submitted for review to Applied Energy", "summary": "Reliable forecasting of prosumer flexibility is critical for demand response aggregators participating in frequency controlled ancillary services market, where strict reliability requirements such as the P90 standard are enforced. Limited historical data, dependence on exogeneous factors, and heterogenous prosumer behaviour introduce significant epistemic uncertainty, making deterministic or poorly calibrated probabilistic models unsuitable for market bidding. This paper proposes the use of scalable uncertainty quantification framework that integrates Monte Carlo dropout (MCD) with conformal prediction (CP) to produce calibrated, finite sample prediction intervals for aggregated prosumer flexibility. The proposed framework is applied to a behind-the-meter aggregator participating in the Danish manual frequency restoration reserve capacity market. A large-scale synthetic dataset is generated using a modified industry-grade home energy management system, combined with publicly available load, solar, price, activation and device-level data. The resulting machine learning surrogate model captures aggregate prosumer price responsiveness and provides uncertainty-aware estimates suitable for market bidding. Multiple multivariate CP strategies are evaluated and benchmarked against conventional MCD-based methods. Results show that standalone MCD systematically overestimates available flexibility and violates P90 compliance, whereas the proposed MCD-CP framework achieves reliable coverage with controlled conservatism. When embedded in aggregator bidding model, conformalised methods substantially reduce overbidding risk and achieve upto 70% of perfect-information profit while satisfying regulatory reliability constraints, providing practical, computationally efficient, and market-compliant solution for aggregator flexibility forecasting under uncertainty.", "AI": {"tldr": "本文提出了一种结合蒙特卡洛丢弃（MCD）与合模型预测（CP）的可扩展不确定性量化框架，以产生用于聚合产消者灵活性市场竞标的校准后的有限样本预测区间。", "motivation": "可靠的产消者灵活性预报对于参与频率控制辅助服务市场的需求响应聚合商来说至关重要，特别是当有严格的可靠性要求如P90标准时。由于历史数据有限、对外部因素的依赖以及异质性产消者行为的存在，确定性或校准不足的概率模型不适合市场竞标。", "method": "该论文提出的方法是结合蒙特卡洛丢弃（MCD）与合模型预测（CP），以生成针对聚合产消者灵活性的校准、有限样本的预测区间。此框架应用于参与丹麦手动频率恢复储备容量市场的户内能源管理系统的数据集。", "result": "结果表明，单独使用的MCD系统性高估了可用灵活性，并违反P90合规标准，而提出的MCD-CP框架实现了可靠的覆盖率并控制保守性。当嵌入到聚合商竞标模型中时，合模型化的方法显著降低了过度投标的风险，并达到了接近完美信息的收益。", "conclusion": "本文提出了一个实际、计算效率高且符合市场规定的方法，用于在不确定性环境下预测聚合商的灵活性，这为参与辅助服务市场的聚合商提供了重要的解决方案。"}}
{"id": "2601.14662", "pdf": "https://arxiv.org/pdf/2601.14662", "abs": "https://arxiv.org/abs/2601.14662", "authors": ["Shuhua Yang", "Jiahao Zhang", "Yilong Wang", "Dongwon Lee", "Suhang Wang"], "title": "Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box setting where an adversary adaptively queries the system to steal its latent entity-relation graph. We propose AGEA (Agentic Graph Extraction Attack), a framework that leverages a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering. We evaluate AGEA on medical, agriculture, and literary datasets across Microsoft-GraphRAG and LightRAG systems. Under identical query budgets, AGEA significantly outperforms prior attack baselines, recovering up to 90% of entities and relationships while maintaining high precision. These results demonstrate that modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks, even under strict query limits.", "AI": {"tldr": "本文提出了AGEA框架，用于在有限查询预算下高效窃取GraphRAG系统的隐藏实体关系图。", "motivation": "尽管先前的工作表明GraphRAG响应可能泄露检索到的子图，但在实际查询预算下的结构化、代理式提取攻击的可能性尚未被探索。本研究旨在填补这一空白。", "method": "AGEA框架结合了新颖性引导的探索利用策略、外部图记忆模块和两阶段图提取管道，以轻量级发现与大型语言模型过滤相结合的方式工作。", "result": "在医疗、农业和文学数据集上进行实验的结果显示，在相同的查询预算下，AGEA比先前的攻击基准表现更优，能够恢复高达90%的实体和关系，并保持高精度。", "conclusion": "结果表明现代GraphRAG系统在严格的查询限制下仍易遭受结构化、代理式提取攻击。"}}
{"id": "2601.14660", "pdf": "https://arxiv.org/pdf/2601.14660", "abs": "https://arxiv.org/abs/2601.14660", "authors": ["Saswat Das", "Ferdinando Fioretto"], "title": "NeuroFilter: Privacy Guardrails for Conversational LLM Agents", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "This work addresses the computational challenge of enforcing privacy for agentic Large Language Models (LLMs), where privacy is governed by the contextual integrity framework. Indeed, existing defenses rely on LLM-mediated checking stages that add substantial latency and cost, and that can be undermined in multi-turn interactions through manipulation or benign-looking conversational scaffolding. Contrasting this background, this paper makes a key observation: internal representations associated with privacy-violating intent can be separated from benign requests using linear structure. Using this insight, the paper proposes NeuroFilter, a guardrail framework that operationalizes contextual integrity by mapping norm violations to simple directions in the model's activation space, enabling detection even when semantic filters are bypassed. The proposed filter is also extended to capture threats arising during long conversations using the concept of activation velocity, which measures cumulative drift in internal representations across turns. A comprehensive evaluation across over 150,000 interactions and covering models from 7B to 70B parameters, illustrates the strong performance of NeuroFilter in detecting privacy attacks while maintaining zero false positives on benign prompts, all while reducing the computational inference cost by several orders of magnitude when compared to LLM-based agentic privacy defenses.", "AI": {"tldr": "本文介绍了NeuroFilter，一种用于大型语言模型（LLM）的隐私保护框架，通过检测内部表示中的线性结构来识别和防止违反隐私的行为。", "motivation": "现有的基于LLM的方法在多轮对话中效率低且容易被规避，因此提出了一种新的方法来更有效地保证隐私并减少计算成本。", "method": "NeuroFilter通过将隐私侵犯意图映射到模型激活空间中的简单方向来进行检测，并使用激活速度的概念捕捉长对话中的威胁。", "result": "实验结果表明，NeuroFilter在超过150,000次交互中表现优异，能够有效检测隐私攻击，同时保持零误报率，并显著降低计算成本。", "conclusion": "NeuroFilter提供了一种高效、准确的方法来保护LLM的隐私，同时减少了处理对话的安全检查所需的计算资源。"}}
{"id": "2601.14658", "pdf": "https://arxiv.org/pdf/2601.14658", "abs": "https://arxiv.org/abs/2601.14658", "authors": ["Navid Ayoobi", "Marcus I Armstrong", "Arjun Mukherjee"], "title": "Say Anything but This: When Tokenizer Betrays Reasoning in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) reason over discrete token ID sequences, yet modern subword tokenizers routinely produce non-unique encodings: multiple token ID sequences can detokenize to identical surface strings. This representational mismatch creates an unmeasured fragility wherein reasoning processes can fail. LLMs may treat two internal representations as distinct \"words\" even when they are semantically identical at the text level. In this work, we show that tokenization can betray LLM reasoning through one-to-many token ID mappings. We introduce a tokenization-consistency probe that requires models to replace designated target words in context while leaving all other content unchanged. The task is intentionally simple at the surface level, enabling us to attribute failures to tokenizer-detokenizer artifacts rather than to knowledge gaps or parameter limitations. Through analysis of over 11000 replacement trials across state-of-the-art open-source LLMs, we find a non-trivial rate of outputs exhibit phantom edits: cases where models operate under the illusion of correct reasoning, a phenomenon arising from tokenizer-induced representational defects. We further analyze these cases and provide a taxonomy of eight systematic tokenizer artifacts, including whitespace-boundary shifts and intra-word resegmentation. These findings indicate that part of apparent reasoning deficiency originates in the tokenizer layer, motivating tokenizer-level remedies before incurring the cost of training ever-larger models on ever-larger corpora.", "AI": {"tldr": "本文探讨了大语言模型中的分词器如何通过非唯一编码破坏推理过程，并提出了一种检测这种一致性的方法。", "motivation": "动机是揭示现代子词分词器造成的表示不匹配问题，这些问题可能导致LLMs在推理过程中失败。", "method": "引入一种分词一致性探测技术，要求模型替换指定的词语同时保持其他内容不变，分析了11000多次替换试验的结果。", "result": "发现存在非零比例的输出显示出幻影编辑现象，即模型看似正确地进行推理但实际上受到分词器引起的表示缺陷影响。", "conclusion": "研究表明部分明显的推理缺陷源自分词层，建议在训练更大规模模型之前先解决分词器层面的问题。"}}
{"id": "2601.14652", "pdf": "https://arxiv.org/pdf/2601.14652", "abs": "https://arxiv.org/abs/2601.14652", "authors": ["Zixuan Ke", "Yifei Ming", "Austin Xu", "Ryan Chin", "Xuan-Phi Nguyen", "Prathyusha Jwalapuram", "Semih Yavuz", "Caiming Xiong", "Shafiq Joty"], "title": "MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": "Preprint; Work in Progress", "summary": "While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.", "AI": {"tldr": "介绍MAS-Orchestra框架和MASBENCH基准，以提升多智能体系统的整体推理能力，并理解其优势。", "motivation": "当前自动设计的多智能体系统（MAS）在复杂性和效能上存在不足。MAS-Orchestra旨在通过全局化的协调方法解决这些问题并提供一个评估MAS有效性的控制基准。", "method": "提出MAS-Orchestra框架，将MAS的协调视为函数调用强化学习问题，并引入MASBENCH来分析不同任务下MAS的有效性。", "result": "研究表明MAS的优势依赖于任务结构、验证协议以及协调器和子代理的能力。MAS-Orchestra在多个公开基准上取得了持续改进，包括数学推理、多跳问答和基于搜索的QA。", "conclusion": "MAS-Orchestra和MASBENCH为更好地训练和理解多智能体系统提供了框架和基准，以实现更高级别的多智能体智能。"}}
{"id": "2601.14651", "pdf": "https://arxiv.org/pdf/2601.14651", "abs": "https://arxiv.org/abs/2601.14651", "authors": ["Chenglizhao Chen", "Boze Li", "Mengke Song", "Dehao Feng", "Xinyu Liu", "Shanchen Pang", "Jufeng Yang", "Hui Yu"], "title": "READ-Net: Clarifying Emotional Ambiguity via Adaptive Feature Recalibration for Audio-Visual Depression Detection", "categories": ["cs.CV", "cs.MM", "cs.SD"], "comment": "12 pages", "summary": "Depression is a severe global mental health issue that impairs daily functioning and overall quality of life. Although recent audio-visual approaches have improved automatic depression detection, methods that ignore emotional cues often fail to capture subtle depressive signals hidden within emotional expressions. Conversely, those incorporating emotions frequently confuse transient emotional expressions with stable depressive symptoms in feature representations, a phenomenon termed \\emph{Emotional Ambiguity}, thereby leading to detection errors. To address this critical issue, we propose READ-Net, the first audio-visual depression detection framework explicitly designed to resolve Emotional Ambiguity through Adaptive Feature Recalibration (AFR). The core insight of AFR is to dynamically adjust the weights of emotional features to enhance depression-related signals. Rather than merely overlooking or naively combining emotional information, READ-Net innovatively identifies and preserves depressive-relevant cues within emotional features, while adaptively filtering out irrelevant emotional noise. This recalibration strategy significantly clarifies feature representations, and effectively mitigates the persistent challenge of emotional interference. Additionally, READ-Net can be easily integrated into existing frameworks for improved performance. Extensive evaluations on three publicly available datasets show that READ-Net outperforms state-of-the-art methods, with average gains of 4.55\\% in accuracy and 1.26\\% in F1-score, demonstrating its robustness to emotional disturbances and improving audio-visual depression detection.", "AI": {"tldr": "本文提出READ-Net，一种通过自适应特征重校准来解决情感模糊问题的音频视觉抑郁症检测框架。", "motivation": "现有方法在自动抑郁症检测中常忽视情绪线索或混淆短暂的情绪表达与稳定的抑郁症状，导致检测错误。本文旨在提高检测精度并减少情感干扰。", "method": "READ-Net采用自适应特征重校准技术来动态调整情绪特征权重，以增强抑郁症相关信号，并有效过滤无关的情绪噪声。", "result": "在三个公开数据集上的测试表明，与现有方法相比，READ-Net提高了4.55%的准确率和1.26%的F1得分。", "conclusion": "实验结果证明了READ-Net能够有效地减轻情感干扰问题，并显著提高音频视觉抑郁症检测的准确性。"}}
{"id": "2601.14649", "pdf": "https://arxiv.org/pdf/2601.14649", "abs": "https://arxiv.org/abs/2601.14649", "authors": ["Ping Zhong", "Liangbai Liu", "Bolei Chen", "Tao Wu", "Jiazhi Xia", "Chaoxu Mu", "Jianxin Wang"], "title": "Spatially Generalizable Mobile Manipulation via Adaptive Experience Selection and Dynamic Imagination", "categories": ["cs.RO"], "comment": null, "summary": "Mobile Manipulation (MM) involves long-horizon decision-making over multi-stage compositions of heterogeneous skills, such as navigation and picking up objects. Despite recent progress, existing MM methods still face two key limitations: (i) low sample efficiency, due to ineffective use of redundant data generated during long-term MM interactions; and (ii) poor spatial generalization, as policies trained on specific tasks struggle to transfer to new spatial layouts without additional training. In this paper, we address these challenges through Adaptive Experience Selection (AES) and model-based dynamic imagination. In particular, AES makes MM agents pay more attention to critical experience fragments in long trajectories that affect task success, improving skill chain learning and mitigating skill forgetting. Based on AES, a Recurrent State-Space Model (RSSM) is introduced for Model-Predictive Forward Planning (MPFP) by capturing the coupled dynamics between the mobile base and the manipulator and imagining the dynamics of future manipulations. RSSM-based MPFP can reinforce MM skill learning on the current task while enabling effective generalization to new spatial layouts. Comparative studies across different experimental configurations demonstrate that our method significantly outperforms existing MM policies. Real-world experiments further validate the feasibility and practicality of our method.", "AI": {"tldr": "本文提出了一种通过自适应经验选择和动态想象实现空间泛化移动操作的方法。", "motivation": "现有的移动操作方法存在样本效率低和空间泛化能力差的问题，作者旨在解决这些问题以提高移动操作的性能。", "method": "论文中提出了自适应经验选择（AES）来关注关键的经验片段，并引入了基于循环状态空间模型（RSSM）的模型预测前向规划（MPFP），用于捕捉机器人底盘和机械臂之间的耦合动态并想象未来的操作。", "result": "实验表明，该方法在不同配置下的比较研究中显著优于现有的移动操作策略，且在真实世界中的实验证明了其可行性和实用性。", "conclusion": "通过自适应经验选择和基于RSSM的动态想象力规划，可以提高移动操作的空间泛化能力，并增强任务成功率。"}}
{"id": "2601.14641", "pdf": "https://arxiv.org/pdf/2601.14641", "abs": "https://arxiv.org/abs/2601.14641", "authors": ["Ruishi Zou", "Shiyu Xu", "Margaret E Morris", "Jihan Ryu", "Timothy D. Becker", "Nicholas Allen", "Anne Marie Albano", "Randy Auerbach", "Dan Adler", "Varun Mishra", "Lace Padilla", "Dakuo Wang", "Ryan Sultan", "Xuhai \"Orson\" Xu"], "title": "MIND: Empowering Mental Health Clinicians with Multimodal Data Insights through a Narrative Dashboard", "categories": ["cs.HC"], "comment": "Conditionally accepted to CHI Conference on Human Factors in Computing Systems (CHI'26)", "summary": "Advances in data collection enable the capture of rich patient-generated data: from passive sensing (e.g., wearables and smartphones) to active self-reports (e.g., cross-sectional surveys and ecological momentary assessments). Although prior research has demonstrated the utility of patient-generated data in mental healthcare, significant challenges remain in effectively presenting these data streams along with clinical data (e.g., clinical notes) for clinical decision-making. Through co-design sessions with five clinicians, we propose MIND, a large language model-powered dashboard designed to present clinically relevant multimodal data insights for mental healthcare. MIND presents multimodal insights through narrative text, complemented by charts communicating underlying data. Our user study (N=16) demonstrates that clinicians perceive MIND as a significant improvement over baseline methods, reporting improved performance to reveal hidden and clinically relevant data insights (p<.001) and support their decision-making (p=.004). Grounded in the study results, we discuss future research opportunities to integrate data narratives in broader clinical practices.", "AI": {"tldr": "本论文介绍了MIND，一个由大型语言模型驱动的仪表板，旨在通过叙事文本和图表形式展示多模态数据洞察，以支持精神健康临床决策。", "motivation": "尽管患者生成的数据在精神卫生保健中具有实用性，但在有效呈现这些数据流以及与临床数据结合使用方面仍面临挑战。论文动机在于解决这一问题并改善临床决策过程。", "method": "通过与五位临床医生进行共同设计会议，提出MIND仪表板，并进行了包含16名参与者的用户研究来评估其效果。", "result": "用户研究表明，临床医生认为MIND相比基线方法有了显著改进，能更好地揭示隐藏的和具有临床意义的数据洞察并支持决策（p<.001；p=.004）。", "conclusion": "基于研究结果，论文讨论了未来将数据叙事整合到更广泛的临床实践中的机会。"}}
{"id": "2601.14640", "pdf": "https://arxiv.org/pdf/2601.14640", "abs": "https://arxiv.org/abs/2601.14640", "authors": ["Naoya Onizawa", "Daisaku Katagiri", "Warren J. Gross", "Takahiro Hanyu"], "title": "Analog-to-Stochastic Converter Using Magnetic Tunnel Junction Devices for Vision Chips", "categories": ["cs.ET", "cs.AR"], "comment": "24 pages", "summary": "This paper introduces an analog-to-stochastic converter using a magnetic tunnel junction (MTJ) de- vice for vision chips based on stochastic computation. Stochastic computation has been recently exploited for area-efficient hardware implementation, such as low-density parity-check (LDPC) decoders and image processors. However, power-and-area hungry two-step (analog-to-digital and digital-to-stochastic) converters are required for the analog to stochastic signal conversion. To real- ize a one-step conversion, an MTJ device is used as it inherently exhibits a probabilistic switching behavior between two resistance states. Exploiting the device-based probabilistic behavior, analog signals can be directly and area-efficiently converted to stochastic signals to mitigate the signal- conversion overhead. The analog-to-stochastic signal conversion is theoretically described and the conversion characteristic is evaluated using device and circuit parameters. In addition, the resistance variability of the MTJ device is considered in order to compensate the variability effect on the sig- nal conversion. Based on the theoretical analysis, the analog-to-stochastic converter is designed in 90nm CMOS and 100nm MTJ technologies and is verified using a SPICE simulator (NS-SPICE) that handles both transistors and MTJ devices.", "AI": {"tldr": "本论文介绍了一种使用磁性隧道结（MTJ）设备的模拟到随机信号转换器，用于基于随机计算的视觉芯片。", "motivation": "近年来，随机计算因其在硬件实现中的面积效率而受到关注。然而，传统的两步法（模数和数字随机转换）会导致功耗和面积需求增大。为解决这一问题并实现一步式模拟到随机信号转换，本论文提出使用MTJ设备。", "method": "利用MTJ设备固有的概率性开关特性，直接且高效地将模拟信号转换为随机信号，以降低信号转换的开销。基于理论分析，该转换器在90nm CMOS和100nm MTJ技术中设计，并通过NS-SPICE仿真器进行验证。", "result": "论文描述了模拟到随机信号转换的理论基础，评估了设备和电路参数下的转换特性，并考虑了MTJ设备电阻变化对信号转换的影响以补偿其变异性效应。", "conclusion": "通过使用基于磁性隧道结（MTJ）的直接模拟到随机信号转换器，本论文提出了一种面积效率高且功耗低的方法。该方法在理论和仿真验证中均表现出色。"}}
{"id": "2601.14639", "pdf": "https://arxiv.org/pdf/2601.14639", "abs": "https://arxiv.org/abs/2601.14639", "authors": ["Yuheng Shao", "Yuansong Xu", "Yifan Jin", "Shuhao Zhang", "Wenxin Gu", "Quan Li"], "title": "DesignBridge: Bridging Designer Expertise and User Preferences through AI-Enhanced Co-Design for Fashion", "categories": ["cs.HC"], "comment": "Accepted by ACM IUI 2026", "summary": "Effective collaboration between designers and users is important for fashion design, which can increase the user acceptance of fashion products and thereby create value. However, it remains an enduring challenge, as traditional designer-centric approaches restrict meaningful user participation, while user-driven methods demand design proficiency, often marginalizing professional creative judgment. Current co-design practices, including workshops and AI-assisted frameworks, struggle with low user engagement, inefficient preference collection, and difficulties in balancing user feedback with design considerations. To address these challenges, we conducted a formative study with designers and users experienced in co-design (N=7), identifying critical challenges for current collaboration between designers and users in the co-design process, and their requirements. Informed by these insights, we introduce DesignBridge, a multi-platform AI-enhanced interactive system that bridges designer expertise and user preferences through three stages: (1) Initial Design Framing, where designers define initial concepts. (2) Preference Expression Collection, where users intuitively articulate preferences via interactive tools. (3) Preference-Integrated Design, where designers use AI-assisted analytics to integrate feedback into cohesive designs. A user study demonstrates that DesignBridge significantly enhances user preference collection and analysis, enabling designers to integrate diverse preferences with professional expertise.", "AI": {"tldr": "介绍DesignBridge，一个多平台AI增强的交互系统，旨在通过三个阶段（初步设计构架、偏好表达收集和偏好整合设计）促进设计师与用户的有效合作。", "motivation": "传统以设计师为中心的方法限制了用户的实质性参与，而用户驱动的方法则要求设计专业知识。现有的共设计实践如研讨会和AI辅助框架在低用户参与度、不高效的偏好收集以及平衡用户反馈与设计考虑方面存在困难。为了应对这些挑战并促进时尚设计中设计师与用户的有效合作。", "method": "通过一个初步研究，了解设计师和用户体验者（N=7）在共设计过程中面临的挑战及其需求，提出了DesignBridge系统，该系统包含三个阶段：初步设计构架、偏好表达收集和偏好整合设计。", "result": "用户研究表明，DesignBridge显著提高了偏好的收集与分析效率，并使设计师能够将多样化的偏好融入专业的设计之中。", "conclusion": "DesignBridge提供了一种有效的方法来增强设计师与用户的合作，通过AI技术改善了共设计过程中的用户体验和结果。"}}
{"id": "2601.14637", "pdf": "https://arxiv.org/pdf/2601.14637", "abs": "https://arxiv.org/abs/2601.14637", "authors": ["James Brock", "Ce Zhang", "Nantheera Anantrasirichai"], "title": "Forest-Chat: Adapting Vision-Language Agents for Interactive Forest Change Analysis", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.HC"], "comment": "22 pages, 8 figures, 7 tables, Submitted to Ecological Informatics", "summary": "The increasing availability of high-resolution satellite imagery, together with advances in deep learning, creates new opportunities for enhancing forest monitoring workflows. Two central challenges in this domain are pixel-level change detection and semantic change interpretation, particularly for complex forest dynamics. While large language models (LLMs) are increasingly adopted for data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored, especially beyond urban environments. We introduce Forest-Chat, an LLM-driven agent designed for integrated forest change analysis. The proposed framework enables natural language querying and supports multiple RSICI tasks, including change detection, change captioning, object counting, deforestation percentage estimation, and change reasoning. Forest-Chat builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration, and incorporates zero-shot change detection via a foundation change detection model together with an interactive point-prompt interface to support fine-grained user guidance. To facilitate adaptation and evaluation in forest environments, we introduce the Forest-Change dataset, comprising bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated through a combination of human annotation and rule-based methods. Experimental results demonstrate that Forest-Chat achieves strong performance on Forest-Change and on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI, for joint change detection and captioning, highlighting the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and analytical efficiency in forest change analysis.", "AI": {"tldr": "介绍Forest-Chat，一种基于大型语言模型的智能代理，用于综合森林变化分析。", "motivation": "随着高分辨率卫星图像和深度学习的进步，对改进森林监测工作流程有了新的机会。然而，将大型语言模型与视觉语言模型结合进行遥感图像变化解释在森林环境中应用较少。", "method": "Forest-Chat基于多层级变化解释的视觉语言骨干，使用大型语言模型进行操作，并集成了零样本变化检测和交互式点提示界面。", "result": "实验结果显示Forest-Chat在Forest-Change数据集和LEVIR-MCI-Trees子集中表现出色，证明了其在联合变化检测和描述方面的能力。", "conclusion": "互动、基于大型语言模型的遥感图像变化解释系统可以提高森林变化分析的可访问性、可解释性和分析效率。"}}
{"id": "2601.14634", "pdf": "https://arxiv.org/pdf/2601.14634", "abs": "https://arxiv.org/abs/2601.14634", "authors": ["Satoru Hashimoto", "Yinlai Jiang", "Hiroshi Yokoi", "Shunta Togo"], "title": "Landing-Induced Viscoelastic Changes in an Anthropomimetic Foot Joint Structure are Modulated by Foot Structure and Posture", "categories": ["cs.RO", "physics.bio-ph"], "comment": "27 pages, preprint", "summary": "Cadaveric studies have provided important insights into the mechanics of the human foot arch and plantar fascia. However, repeatedly probing posture-dependent viscoelastic responses immediately after landing impact is difficult in biological specimens, leaving the contribution of skeletal architecture to landing dynamics incompletely understood. In this study, we developed an anthropomimetic foot joint structure aimed at replicating the skeletal geometry of the human foot. Using a vertical drop apparatus that simulates landing and a viscoelastic system-identification model, we investigated how skeletal structure and posture modulate the apparent post-impact viscoelastic response. The results show that the multi-jointed anthropomimetic structure exhibited a higher damping ratio than simplified flat and rigid feet. Moreover, ankle dorsiflexion and toe extension systematically shifted the identified parameters, reducing the damping ratio under the tested conditions. Taken together, these findings indicate that an arch-like, multi-jointed skeletal architecture can enhance impact attenuation in an anthropomimetic mechanical foot, and that morphology and passive posture alone can tune the trade-off between attenuation and rebound. The observed posture-dependent trends are qualitatively consistent with reported differences in human landing strategies, suggesting that skeletal architecture may partly account for the modulation. Furthermore, these results highlight the engineering advantage of anatomically informed skeletal replication for achieving human-like apparent viscoelastic behavior through postural adjustment during landing.", "AI": {"tldr": "研究开发了一种模拟人类足部骨骼几何结构的仿生足关节结构，以探究骨骼结构和姿势如何调节着陆后立即的粘弹性响应。", "motivation": "生物样本中反复探查着陆冲击后的粘弹性反应受姿势影响较难实现，导致对骨骼结构在着陆动力学中的贡献理解不完整。", "method": "使用垂直落体装置模拟着陆，并采用粘弹性系统识别模型，研究多关节仿生结构的粘弹性响应如何受到骨骼结构和姿势的影响。", "result": "多关节仿生结构显示出比简化平面刚性足更高的阻尼比；踝背屈和趾伸展会系统地改变识别参数，降低测试条件下的阻尼比。", "conclusion": "具有弓形、多关节的骨骼结构可以增强着陆时冲击衰减，并且形态与被动姿势可以通过调整衰减与回弹之间的平衡来调节这种行为。"}}
{"id": "2601.14629", "pdf": "https://arxiv.org/pdf/2601.14629", "abs": "https://arxiv.org/abs/2601.14629", "authors": ["Yuze Chen", "Yuan Zhou", "Baichuan Mo", "Jie Ying", "Yufei Ruan", "Zhou Ye"], "title": "Online Linear Programming with Replenishment", "categories": ["math.OC", "cs.DS", "cs.LG"], "comment": "63 pages, 12 figures", "summary": "We study an online linear programming (OLP) model in which inventory is not provided upfront but instead arrives gradually through an exogenous stochastic replenishment process. This replenishment-based formulation captures operational settings, such as e-commerce fulfillment, perishable supply chains, and renewable-powered systems, where resources are accumulated gradually and initial inventories are small or zero. The introduction of dispersed, uncertain replenishment fundamentally alters the structure of classical OLPs, creating persistent stockout risk and eliminating advance knowledge of the total budget. We develop new algorithms and regret analyses for three major distributional regimes studied in the OLP literature: bounded distributions, finite-support distributions, and continuous-support distributions with a non-degeneracy condition. For bounded distributions, we design an algorithm that achieves $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret. For finite-support distributions with a non-degenerate induced LP, we obtain $\\mathcal{O}(\\log T)$ regret, and we establish an $Ω(\\sqrt{T})$ lower bound for degenerate instances, demonstrating a sharp separation from the classical setting where $\\mathcal{O}(1)$ regret is achievable. For continuous-support, non-degenerate distributions, we develop a two-stage accumulate-then-convert algorithm that achieves $\\mathcal{O}(\\log^2 T)$ regret, comparable to the $\\mathcal{O}(\\log T)$ regret in classical OLPs. Together, these results provide a near-complete characterization of the optimal regret achievable in OLP with replenishment. Finally, we empirically evaluate our algorithms and demonstrate their advantages over natural adaptations of classical OLP methods in the replenishment setting.", "AI": {"tldr": "本文研究了在线线性规划（OLP）模型，在该模型中，库存不是事先提供而是通过外生随机补给过程逐渐到达。提出了针对三种主要分布制度的新算法和后悔分析。", "motivation": "探讨资源累积渐进且初始库存小或为零的运营环境中的问题，如电子商务履行、易腐品供应链及可再生动力系统，这些场景下传统OLP结构受到根本性改变，产生持续缺货风险并消除对总预算的提前了解。", "method": "设计了适用于有界分布的新算法，并为有限支持和连续支持非退化条件下的分布开发了后悔分析，包括一个两阶段累积转换算法。", "result": "对于有界分布，新算法达到~O(√T)后悔值；在有限支持与非退化诱导LP下取得O(log T)后悔并证明退化实例存在Ω(√T)下限；连续支持、非退化的分布下设计的两阶段累积转换算法获得O((log T)^2)后悔。", "conclusion": "这些结果近完全刻画了补给环境中OLP可实现的最优后悔值，并且通过实证评估展示了新方法相对于传统OLP方法在补给场景下的优势。"}}
{"id": "2601.14628", "pdf": "https://arxiv.org/pdf/2601.14628", "abs": "https://arxiv.org/abs/2601.14628", "authors": ["Weiyu Guo", "He Zhang", "Pengteng Li", "Tiefu Cai", "Ziyang Chen", "Yandong Guo", "Xiao He", "Yongkui Yang", "Ying Sun", "Hui Xiong"], "title": "A Brain-inspired Embodied Intelligence for Fluid and Fast Reflexive Robotics Control", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Recent advances in embodied intelligence have leveraged massive scaling of data and model parameters to master natural-language command following and multi-task control. In contrast, biological systems demonstrate an innate ability to acquire skills rapidly from sparse experience. Crucially, current robotic policies struggle to replicate the dynamic stability, reflexive responsiveness, and temporal memory inherent in biological motion. Here we present Neuromorphic Vision-Language-Action (NeuroVLA), a framework that mimics the structural organization of the bio-nervous system between the cortex, cerebellum, and spinal cord. We adopt a system-level bio-inspired design: a high-level model plans goals, an adaptive cerebellum module stabilizes motion using high-frequency sensors feedback, and a bio-inspired spinal layer executes lightning-fast actions generation. NeuroVLA represents the first deployment of a neuromorphic VLA on physical robotics, achieving state-of-the-art performance. We observe the emergence of biological motor characteristics without additional data or special guidance: it stops the shaking in robotic arms, saves significant energy(only 0.4w on Neuromorphic Processor), shows temporal memory ability and triggers safety reflexes in less than 20 milliseconds.", "AI": {"tldr": "提出Neuromorphic Vision-Language-Action（NeuroVLA）框架，模仿生物神经系统实现快速反应和动态稳定性的机器人控制。", "motivation": "现有的机器人策略难以复制生物系统的动态稳定性、反射响应性和时间记忆能力。该研究旨在通过模拟生物神经系统的结构来提升机器人的性能。", "method": "采用一个系统级的仿生设计，包括高层次模型进行目标规划，自适应小脑模块使用高频传感器反馈稳定运动，以及模仿脊髓层生成快速动作。", "result": "NeuroVLA实现了最先进的物理机器人控制表现，减少了机械臂抖动，节省了大量能量（仅需0.4瓦），并显示出时间记忆能力和在20毫秒内触发安全反射的能力。", "conclusion": "该研究首次成功将神经形态的视觉语言行动框架部署到实际机器人上，并观察到了类似生物运动特征的出现。"}}
{"id": "2601.14625", "pdf": "https://arxiv.org/pdf/2601.14625", "abs": "https://arxiv.org/abs/2601.14625", "authors": ["Yingsong Huang", "Hui Guo", "Jing Huang", "Bing Bai", "Qi Xiong"], "title": "Diffusion Epistemic Uncertainty with Asymmetric Learning for Diffusion-Generated Image Detection", "categories": ["cs.CV", "stat.ML"], "comment": null, "summary": "The rapid progress of diffusion models highlights the growing need for detecting generated images. Previous research demonstrates that incorporating diffusion-based measurements, such as reconstruction error, can enhance the generalizability of detectors. However, ignoring the differing impacts of aleatoric and epistemic uncertainty on reconstruction error can undermine detection performance. Aleatoric uncertainty, arising from inherent data noise, creates ambiguity that impedes accurate detection of generated images. As it reflects random variations within the data (e.g., noise in natural textures), it does not help distinguish generated images. In contrast, epistemic uncertainty, which represents the model's lack of knowledge about unfamiliar patterns, supports detection. In this paper, we propose a novel framework, Diffusion Epistemic Uncertainty with Asymmetric Learning~(DEUA), for detecting diffusion-generated images. We introduce Diffusion Epistemic Uncertainty~(DEU) estimation via the Laplace approximation to assess the proximity of data to the manifold of diffusion-generated samples. Additionally, an asymmetric loss function is introduced to train a balanced classifier with larger margins, further enhancing generalizability. Extensive experiments on large-scale benchmarks validate the state-of-the-art performance of our method.", "AI": {"tldr": "本文提出了一种新的框架DEUA，用于检测扩散模型生成的图像。", "motivation": "尽管以往的研究表明结合基于扩散模型的度量（如重建误差）可以提高检测器的泛化能力，但忽视了随机不确定性与认知不确定性对重建误差的不同影响，这可能会削弱检测性能。", "method": "本文提出了Diffusion Epistemic Uncertainty(DEU)估计方法，并使用Laplace近似评估数据接近扩散生成样本流形的程度；引入非对称损失函数来训练一个具有更大边距的平衡分类器。", "result": "大规模基准测试验证了该方法达到了最先进的性能水平。", "conclusion": "DEUA框架通过考虑认知不确定性和使用非对称学习，提升了检测扩散模型生成图像的效果。"}}
{"id": "2601.14622", "pdf": "https://arxiv.org/pdf/2601.14622", "abs": "https://arxiv.org/abs/2601.14622", "authors": ["Ling Xiao", "Toshihiko Yamasaki"], "title": "Probing Prompt Design for Socially Compliant Robot Navigation with Vision Language Models", "categories": ["cs.RO"], "comment": null, "summary": "Language models are increasingly used for social robot navigation, yet existing benchmarks largely overlook principled prompt design for socially compliant behavior. This limitation is particularly relevant in practice, as many systems rely on small vision language models (VLMs) for efficiency. Compared to large language models, small VLMs exhibit weaker decision-making capabilities, making effective prompt design critical for accurate navigation. Inspired by cognitive theories of human learning and motivation, we study prompt design along two dimensions: system guidance (action-focused, reasoning-oriented, and perception-reasoning prompts) and motivational framing, where models compete against humans, other AI systems, or their past selves. Experiments on two socially compliant navigation datasets reveal three key findings. First, for non-finetuned GPT-4o, competition against humans achieves the best performance, while competition against other AI systems performs worst. For finetuned models, competition against the model's past self yields the strongest results, followed by competition against humans, with performance further influenced by coupling effects among prompt design, model choice, and dataset characteristics. Second, inappropriate system prompt design can significantly degrade performance, even compared to direct finetuning. Third, while direct finetuning substantially improves semantic-level metrics such as perception, prediction, and reasoning, it yields limited gains in action accuracy. In contrast, our system prompts produce a disproportionately larger improvement in action accuracy, indicating that the proposed prompt design primarily acts as a decision-level constraint rather than a representational enhancement.", "AI": {"tldr": "本文探讨了视觉语言模型在社交合规机器人导航中的提示设计，并通过实验验证了不同系统指导和动机框架下，对非微调和微调模型性能的影响。", "motivation": "现有的基准测试大多忽略了提示设计对于实现社会合规行为的重要性。由于许多系统依赖于小型的视觉语言模型（VLMs）以提高效率，而这些模型相较于大型语言模型在决策能力上较弱，因此有效的提示设计尤为重要。", "method": "文章基于认知理论中的学习和动机理论，研究了沿两个维度进行的提示设计：系统指导（行动导向、推理导向、感知-推理提示）与动机框架（模型与人类、其他AI系统或其过去的自我竞争）。通过在两个社交合规导航数据集上的实验来验证。", "result": "实验揭示了三个关键发现：1.对于非微调的GPT-4o，与人对抗表现最好，而与其他AI系统对抗则表现最差；2.不适当的系统提示设计会严重影响性能，甚至比直接微调的效果还差；3.直接微调虽然在语义层面如感知、预测和推理上有所改善，但在行为准确性上的提升有限。相比之下，系统的提示设计对行动准确性的提高更大。", "conclusion": "文章得出结论，所提出的提示设计主要作为决策层次的约束而非表示增强，并强调了有效的提示设计对于小型视觉语言模型在社交合规机器人导航中的重要性。"}}
{"id": "2601.14620", "pdf": "https://arxiv.org/pdf/2601.14620", "abs": "https://arxiv.org/abs/2601.14620", "authors": ["Wenda Zhang", "Hongyu Jin", "Siyi Wang", "Zhiqiang Wei", "Ting Dang"], "title": "Scaling Ambiguity: Augmenting Human Annotation in Speech Emotion Recognition with Audio-Language Models", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "comment": "Accepted by ICASSP 2026", "summary": "Speech Emotion Recognition models typically use single categorical labels, overlooking the inherent ambiguity of human emotions. Ambiguous Emotion Recognition addresses this by representing emotions as probability distributions, but progress is limited by unreliable ground-truth distributions inferred from sparse human annotations. This paper explores whether Large Audio-Language Models (ALMs) can mitigate the annotation bottleneck by generating high-quality synthetic annotations. We introduce a framework leveraging ALMs to create Synthetic Perceptual Proxies, augmenting human annotations to improve ground-truth distribution reliability. We validate these proxies through statistical analysis of their alignment with human distributions and evaluate their impact by fine-tuning ALMs with the augmented emotion distributions. Furthermore, to address class imbalance and enable unbiased evaluation, we propose DiME-Aug, a Distribution-aware Multimodal Emotion Augmentation strategy. Experiments on IEMOCAP and MSP-Podcast show that synthetic annotations enhance emotion distribution, especially in low-ambiguity regions where annotation agreement is high. However, benefits diminish for highly ambiguous emotions with greater human disagreement. This work provides the first evidence that ALMs could address annotation scarcity in ambiguous emotion recognition, but highlights the need for more advanced prompting or generation strategies to handle highly ambiguous cases.", "AI": {"tldr": "本文探讨了通过大型音频语言模型生成高质量合成注释来缓解情感识别中注释瓶颈的方法。", "motivation": "传统的语音情感识别模型通常使用单一的分类标签，忽略了人类情绪固有的模糊性。为了解决这一问题并提高地面真实分布的可靠性，作者探索是否可以通过音频语言模型生成高质合成注释以解决标注瓶颈。", "method": "本文提出了一种框架，该框架利用大型音频语言模型创建合成感知代理，并通过统计分析验证这些代理与人类分布的一致性。同时，还提出了DiME-Aug策略来处理类别不平衡并进行无偏评估。", "result": "实验表明，在标注者高度一致的低模糊区域中，合成注释能够改善情感分布。但对于高模糊情绪（即人类注释者存在较大分歧的情况），其效果减弱。", "conclusion": "本文首次提供了音频语言模型可能解决模糊情感识别领域标注稀缺问题的证据，但同时也指出需要更先进的提示或生成策略来处理高度模糊的情绪案例。"}}
{"id": "2601.14617", "pdf": "https://arxiv.org/pdf/2601.14617", "abs": "https://arxiv.org/abs/2601.14617", "authors": ["Yunfeng Lin", "Li Xu", "Yong Yu", "Jiangmiao Pang", "Weinan Zhang"], "title": "UniCon: A Unified System for Efficient Robot Learning Transfers", "categories": ["cs.RO", "cs.SE"], "comment": "in submission, under review", "summary": "Deploying learning-based controllers across heterogeneous robots is challenging due to platform differences, inconsistent interfaces, and inefficient middleware. To address these issues, we present UniCon, a lightweight framework that standardizes states, control flow, and instrumentation across platforms. It decomposes workflows into execution graphs with reusable components, separating system states from control logic to enable plug-and-play deployment across various robot morphologies. Unlike traditional middleware, it prioritizes efficiency through batched, vectorized data flow, minimizing communication overhead and improving inference latency. This modular, data-oriented approach enables seamless sim-to-real transfer with minimal re-engineering. We demonstrate that UniCon reduces code redundancy when transferring workflows and achieves higher inference efficiency compared to ROS-based systems. Deployed on over 12 robot models from 7 manufacturers, it has been successfully integrated into ongoing research projects, proving its effectiveness in real-world scenarios.", "AI": {"tldr": "本文介绍了UniCon，一个用于机器人学习转移的统一系统。", "motivation": "解决在不同机器人平台之间部署基于学习的控制器时面临的挑战，包括平台差异、接口不一致和中间件效率低下等问题。", "method": "提出了一种轻量级框架 UniCon，它通过标准化状态、控制流和跨平台仪器化，将工作流程分解为可重用组件的执行图。该方法优先考虑效率，通过批量、向量化数据流减少通信开销并提高推理延迟。", "result": "UniCon减少了在不同机器人模型之间转移工作流程时的代码冗余，并且比ROS基系统具有更高的推理效率。它已成功部署到12个以上来自7家制造商的机器人模型中，证明了其在实际应用中的有效性。", "conclusion": "UniCon通过标准化和优化跨平台的数据流，实现了高效的机器人学习转移，适用于各种形态的机器人，并已在多个研究项目中得到验证。"}}
{"id": "2601.14615", "pdf": "https://arxiv.org/pdf/2601.14615", "abs": "https://arxiv.org/abs/2601.14615", "authors": ["Xichen Zhang", "Ziyi He", "Yinghao Zhu", "Sitong Wu", "Shaozuo Yu", "Meng Chu", "Wenhu Zhang", "Haoru Tan", "Jiaya Jia"], "title": "SearchGym: Bootstrapping Real-World Search Agents via Cost-Effective and High-Fidelity Environment Simulation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Search agents have emerged as a pivotal paradigm for solving open-ended, knowledge-intensive reasoning tasks. However, training these agents via Reinforcement Learning (RL) faces a critical dilemma: interacting with live commercial Web APIs is prohibitively expensive, while relying on static data snapshots often introduces noise due to data misalignment. This misalignment generates corrupted reward signals that destabilize training by penalizing correct reasoning or rewarding hallucination. To address this, we propose SearchGym, a simulation environment designed to bootstrap robust search agents. SearchGym employs a rigorous generative pipeline to construct a verifiable knowledge graph and an aligned document corpus, ensuring that every reasoning task is factually grounded and strictly solvable. Building on this controllable environment, we introduce SearchGym-RL, a curriculum learning methodology that progressively optimizes agent policies through purified feedback, evolving from basic interactions to complex, long-horizon planning. Extensive experiments across the Llama and Qwen families demonstrate strong Sim-to-Real generalization. Notably, our Qwen2.5-7B-Base model trained within SearchGym surpasses the web-enhanced ASearcher baseline across nine diverse benchmarks by an average relative margin of 10.6%. Our results validate that high-fidelity simulation serves as a scalable and highly cost-effective methodology for developing capable search agents.", "AI": {"tldr": "本文介绍了SearchGym，一个通过高保真环境模拟来训练搜索代理的平台。", "motivation": "解决通过强化学习（RL）训练搜索代理时面临的与商业网络API交互成本过高以及静态数据快照引入噪声的问题。", "method": "提出了SearchGym及其基于课程的学习方法SearchGym-RL，用于生成可验证的知识图和对齐文档，并逐步优化代理策略。", "result": "实验表明，在Llama和Qwen系列模型中实现了强模拟到现实的泛化能力。特别是，训练在SearchGym中的Qwen2.5-7B-Base模型在九个多样化基准测试上超越了网络增强型ASearcher基线10.6%。", "conclusion": "高保真度的仿真是一种可扩展且成本有效的开发搜索代理的方法。"}}
{"id": "2601.14611", "pdf": "https://arxiv.org/pdf/2601.14611", "abs": "https://arxiv.org/abs/2601.14611", "authors": ["Jiangen He", "Jiqun Liu"], "title": "Seeing to Think? How Source Transparency Design Shapes Interactive Information Seeking and Evaluation in Conversational AI", "categories": ["cs.HC"], "comment": null, "summary": "Conversational AI systems increasingly function as primary interfaces for information seeking, yet how they present sources to support information evaluation remains under-explored. This paper investigates how source transparency design shapes interactive information seeking, trust, and critical engagement. We conducted a controlled between-subjects experiment (N=372) comparing four source presentation interfaces - Collapsible, Hover Card, Footer, and Aligned Sidebar - varying in visibility and accessibility. Using fine-grained behavioral analysis and automated critical thinking assessment, we found that interface design fundamentally alters exploration strategies and evidence integration. While the Hover Card interface facilitated seamless, on-demand verification during the task, the Aligned Sidebar uniquely mitigated the negative effects of information overload: as citation density increased, Sidebar users demonstrated significantly higher critical thinking and synthesis scores compared to other conditions. Our results highlight a trade-off between designs that support workflow fluency and those that enforce reflective verification, offering practical implications for designing adaptive and responsible conversational AI that fosters critical engagement with AI generated content.", "AI": {"tldr": "本文研究了不同来源透明度设计如何影响信息探索、信任和批判性参与，特别关注对话式AI系统中信息获取与评估的交互方式。", "motivation": "随着对话式AI成为主要的信息搜索接口，其在支持信息评价方面的表现仍需进一步探究。本文旨在了解源透明度设计对互动信息搜索的影响，并提出实际应用建议。", "method": "研究者进行了一个控制实验（N=372），比较四种不同的来源呈现界面：可折叠式、悬停卡、脚注和对齐侧栏，通过精细的行为分析和自动化批判性思考评估来收集数据。", "result": "研究结果表明，不同设计的界面会显著改变探索策略和证据整合方式。悬停卡设计实现了无缝的任务中验证，而对齐侧栏在信息过载的情况下独特地提高了用户的批判性和综合能力。", "conclusion": "本研究揭示了支持工作流程流畅与强制反思验证之间的权衡，并为设计适应性强、负责任的对话式AI提供了实用建议，以促进用户对AI生成内容的批判性参与。"}}
{"id": "2601.14610", "pdf": "https://arxiv.org/pdf/2601.14610", "abs": "https://arxiv.org/abs/2601.14610", "authors": ["Zhenghong Li", "Kecheng Zheng", "Haibin Ling"], "title": "Learning Consistent Taxonomic Classification through Hierarchical Reasoning", "categories": ["cs.CV"], "comment": "12 pages, 4 figures", "summary": "While Vision-Language Models (VLMs) excel at visual understanding, they often fail to grasp hierarchical knowledge. This leads to common errors where VLMs misclassify coarser taxonomic levels even when correctly identifying the most specific level (leaf level). Existing approaches largely overlook this issue by failing to model hierarchical reasoning. To address this gap, we propose VL-Taxon, a two-stage, hierarchy-based reasoning framework designed to improve both leaf-level accuracy and hierarchical consistency in taxonomic classification. The first stage employs a top-down process to enhance leaf-level classification accuracy. The second stage then leverages this accurate leaf-level output to ensure consistency throughout the entire taxonomic hierarchy. Each stage is initially trained with supervised fine-tuning to instill taxonomy knowledge, followed by reinforcement learning to refine the model's reasoning and generalization capabilities. Extensive experiments reveal a remarkable result: our VL-Taxon framework, implemented on the Qwen2.5-VL-7B model, outperforms its original 72B counterpart by over 10% in both leaf-level and hierarchical consistency accuracy on average on the iNaturalist-2021 dataset. Notably, this significant gain was achieved by fine-tuning on just a small subset of data, without relying on any examples generated by other VLMs.", "AI": {"tldr": "本文提出VL-Taxon框架，通过分层次推理提升视觉语言模型在分类任务中的准确性与一致性。", "motivation": "现有的视觉语言模型虽然擅长图像理解，但在处理层级知识时表现不佳，往往会在正确识别最具体类别的情况下错误地分类较粗的类别。因此，本研究旨在解决这一问题。", "method": "提出VL-Taxon，一个分两阶段进行层次推理的框架：第一阶段自上而下提升叶级分类准确性；第二阶段利用准确的叶级输出确保整个分类体系的一致性。每个阶段先通过监督微调灌输分类知识，然后使用强化学习优化模型推理和泛化能力。", "result": "实验结果显示，在iNaturalist-2021数据集上，基于Qwen2.5-VL-7B模型的VL-Taxon框架相较于其原始72亿参数版本在叶级与层级一致性准确性方面平均提升了超过10%，且仅需微调少量数据。", "conclusion": "研究证明了通过分层次推理可以显著改善视觉语言模型在分类任务中的性能，尤其是在提高准确性和维持分类体系内部一致性的能力上。"}}
{"id": "2601.14609", "pdf": "https://arxiv.org/pdf/2601.14609", "abs": "https://arxiv.org/abs/2601.14609", "authors": ["Ziwen Wang", "Siqi Li", "Marcus Eng Hock Ong", "Nan Liu"], "title": "Communication-Efficient Federated Risk Difference Estimation for Time-to-Event Clinical Outcomes", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Privacy-preserving model co-training in medical research is often hindered by server-dependent architectures incompatible with protected hospital data systems and by the predominant focus on relative effect measures (hazard ratios) which lack clinical interpretability for absolute survival risk assessment. We propose FedRD, a communication-efficient framework for federated risk difference estimation in distributed survival data. Unlike typical federated learning frameworks (e.g., FedAvg) that require persistent server connections and extensive iterative communication, FedRD is server-independent with minimal communication: one round of summary statistics exchange for the stratified model and three rounds for the unstratified model. Crucially, FedRD provides valid confidence intervals and hypothesis testing--capabilities absent in FedAvg-based frameworks. We provide theoretical guarantees by establishing the asymptotic properties of FedRD and prove that FedRD (unstratified) is asymptotically equivalent to pooled individual-level analysis. Simulation studies and real-world clinical applications across different countries demonstrate that FedRD outperforms local and federated baselines in both estimation accuracy and prediction performance, providing an architecturally feasible solution for absolute risk assessment in privacy-restricted, multi-site clinical studies.", "AI": {"tldr": "提出FedRD框架，用于分布式生存数据分析中的风险差估计。", "motivation": "解决现有联邦学习架构依赖服务器和缺乏临床解释性的相对效应措施的问题。", "method": "设计了一个无需持续服务器连接且通信效率高的FedRD框架，通过少量轮次的摘要统计信息交换来实现模型训练。", "result": "理论证明了FedRD的渐进性质并表明其与个体水平分析等价。实证研究显示FedRD在估计精度和预测性能上优于本地和联邦基线方法。", "conclusion": "FedRD提供了一个架构可行的解决方案，适用于隐私受限、多站点临床研究中的绝对风险评估。"}}
{"id": "2601.14605", "pdf": "https://arxiv.org/pdf/2601.14605", "abs": "https://arxiv.org/abs/2601.14605", "authors": ["Weiwei Ma", "Xiaobing Yu", "Peijie Qiu", "Jin Yang", "Pan Xiao", "Xiaoqi Zhao", "Xiaofeng Liu", "Tomo Miyazaki", "Shinichiro Omachi", "Yongsong Huang"], "title": "U-Harmony: Enhancing Joint Training for Segmentation Models with Universal Harmonization", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In clinical practice, medical segmentation datasets are often limited and heterogeneous, with variations in modalities, protocols, and anatomical targets across institutions. Existing deep learning models struggle to jointly learn from such diverse data, often sacrificing either generalization or domain-specific knowledge. To overcome these challenges, we propose a joint training method called Universal Harmonization (U-Harmony), which can be integrated into deep learning-based architectures with a domain-gated head, enabling a single segmentation model to learn from heterogeneous datasets simultaneously. By integrating U-Harmony, our approach sequentially normalizes and then denormalizes feature distributions to mitigate domain-specific variations while preserving original dataset-specific knowledge. More appealingly, our framework also supports universal modality adaptation, allowing the seamless learning of new imaging modalities and anatomical classes. Extensive experiments on cross-institutional brain lesion datasets demonstrate the effectiveness of our approach, establishing a new benchmark for robust and adaptable 3D medical image segmentation models in real-world clinical settings.", "AI": {"tldr": "提出了一种名为U-Harmony的联合训练方法，能够使单一分割模型从异构数据集中同时学习。", "motivation": "现有的深度学习模型在处理临床实践中有限且不统一的医疗分割数据集时面临挑战，这些数据集在模态、协议和解剖目标上存在差异，导致模型难以在泛化能力和领域特定知识之间取得平衡。", "method": "U-Harmony方法通过引入域门控头集成到深度学习架构中，实现特征分布的顺序归一化与去归一化，以减少领域特定的变化同时保留原始数据集的知识，并支持通用模态适应，使新成像模态和解剖类别能够无缝学习。", "result": "实验结果表明，在跨机构脑病变数据集上的表现优于现有方法，为现实世界的临床应用建立了鲁棒且可适应的3D医学图像分割模型的新基准。", "conclusion": "U-Harmony方法通过解决异构医疗数据集中的挑战，提升了分割模型在泛化能力和领域特定知识之间的平衡，证明了其在实际临床设置中作为强大和适应性分割工具的有效性和潜力。"}}
{"id": "2601.14602", "pdf": "https://arxiv.org/pdf/2601.14602", "abs": "https://arxiv.org/abs/2601.14602", "authors": ["Oindrila Saha", "Vojtech Krs", "Radomir Mech", "Subhransu Maji", "Matheus Gadelha", "Kevin Blackburn-Matzen"], "title": "3D Space as a Scratchpad for Editable Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in large language models (LLMs) has shown that reasoning improves when intermediate thoughts are externalized into explicit workspaces, such as chain-of-thought traces or tool-augmented reasoning. Yet, visual language models (VLMs) lack an analogous mechanism for spatial reasoning, limiting their ability to generate images that accurately reflect geometric relations, object identities, and compositional intent. We introduce the concept of a spatial scratchpad -- a 3D reasoning substrate that bridges linguistic intent and image synthesis. Given a text prompt, our framework parses subjects and background elements, instantiates them as editable 3D meshes, and employs agentic scene planning for placement, orientation, and viewpoint selection. The resulting 3D arrangement is rendered back into the image domain with identity-preserving cues, enabling the VLM to generate spatially consistent and visually coherent outputs. Unlike prior 2D layout-based methods, our approach supports intuitive 3D edits that propagate reliably into final images. Empirically, it achieves a 32% improvement in text alignment on GenAI-Bench, demonstrating the benefit of explicit 3D reasoning for precise, controllable image generation. Our results highlight a new paradigm for vision-language models that deliberate not only in language, but also in space. Code and visualizations at https://oindrilasaha.github.io/3DScratchpad/", "AI": {"tldr": "本文介绍了使用3D空间作为视觉语言模型（VLM）的编辑文本到图像生成的工作台的概念。", "motivation": "动机在于解决现有视觉语言模型在处理几何关系、对象身份和组合意图时的空间推理能力不足的问题。", "method": "提出了一种新的框架，该框架将文本提示解析为主体和背景元素，并将其实例化为可编辑的3D网格，使用场景规划代理进行放置、定向和视角选择。最终通过保留身份线索的渲染技术生成视觉上一致的图像。", "result": "实验结果表明，在GenAI-Bench上的文本对齐度提高了32%，证明了明确的三维推理在精确可控的图像生成中的优势。", "conclusion": "研究揭示了一种新的VLM范式，不仅在语言中进行思考，还通过三维空间来进行思考。"}}
{"id": "2601.14599", "pdf": "https://arxiv.org/pdf/2601.14599", "abs": "https://arxiv.org/abs/2601.14599", "authors": ["Xiao Hu", "Hong Xie", "Tao Tan", "Defu Lian", "Jianyu Han"], "title": "Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.", "AI": {"tldr": "本文旨在通过多臂老虎机学习的视角重新思考LLMs的强化微调，以解决现有优化策略中的混乱情况。", "motivation": "许多优化策略在LLMs的强化微调中被提出，但其效果和作用机制缺乏明确理解。因此，需要一个清晰的方法来评估这些策略并识别瓶颈。", "method": "本文采用了一种从底层向上的实验流水线方法，首先使用一种极简配置（单一训练数据、每轮一次回放、直接奖励作为学习信号），然后逐层扩展以研究各种设计选择的影响。", "result": "实验结果揭示了不同设计选项的作用，并为LLMs的强化微调提供了新的见解。", "conclusion": "该方法通过多臂老虎机理论验证了实验发现，有助于厘清优化策略对LLMs性能影响的关键因素。"}}
{"id": "2601.14598", "pdf": "https://arxiv.org/pdf/2601.14598", "abs": "https://arxiv.org/abs/2601.14598", "authors": ["Yonatan Gizachew Achamyeleh", "Harsh Thomare", "Mohammad Abdullah Al Faruque"], "title": "HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \\textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured reasoning task. \\textsc{HELIOS} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build. On HumanEval-Decompile for \\texttt{x86\\_64}, \\textsc{HELIOS} raises average object file compilability from 45.0\\% to 85.2\\% for Gemini~2.0 and from 71.4\\% to 89.6\\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \\textsc{HELIOS} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \\textsc{HELIOS} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets.", "AI": {"tldr": "介绍了一种名为HELIOS的框架，该框架通过将程序控制流和函数调用表示为分层文本来改进基于大语言模型（LLM）的二进制反编译。", "motivation": "现有的大型语言模型在处理代码时忽略了控制流图，导致输出的语法不坚固且逻辑上不一致，特别是在优化过的二进制文件中。因此，该论文旨在通过结构化推理任务来改进这种局限性。", "method": "HELIOS框架将二进制的控制流和函数调用转换为分层文本表示，并与原始反编译输出一起提供给通用LLM。此外，还可以结合一个循环中的编译器以返回生成代码无法构建时的错误消息。", "result": "在HumanEval-Decompile测试集上，HELIOS将Gemini~2.0和GPT-4.1~Mini的平均可编译性分别从45.0%提升到85.2%，以及71.4%提升至89.6%。通过加入编译器反馈，可编译性超过94%，功能正确率提高了最多5.6个百分点。", "conclusion": "HELIOS框架减少了各种架构的功能正确性的差异，同时保持了语法正确的高一致性，并且无需微调。这使得HELIOS成为一个实用的反工程工作流程构建模块，在需要跨不同硬件目标重新编译、语义忠实代码的安全设置中特别有用。"}}
{"id": "2601.14597", "pdf": "https://arxiv.org/pdf/2601.14597", "abs": "https://arxiv.org/abs/2601.14597", "authors": ["James Melbourne", "Mario Diaz", "Shahab Asoodeh"], "title": "Optimality of Staircase Mechanisms for Vector Queries under Differential Privacy", "categories": ["cs.IT", "cs.AI", "cs.CR", "stat.ML"], "comment": "Submitted for possible publication", "summary": "We study the optimal design of additive mechanisms for vector-valued queries under $ε$-differential privacy (DP). Given only the sensitivity of a query and a norm-monotone cost function measuring utility loss, we ask which noise distribution minimizes expected cost among all additive $ε$-DP mechanisms. Using convex rearrangement theory, we show that this infinite-dimensional optimization problem admits a reduction to a one-dimensional compact and convex family of radially symmetric distributions whose extreme points are the staircase distributions. As a consequence, we prove that for any dimension, any norm, and any norm-monotone cost function, there exists an $ε$-DP staircase mechanism that is optimal among all additive mechanisms. This result resolves a conjecture of Geng, Kairouz, Oh, and Viswanath, and provides a geometric explanation for the emergence of staircase mechanisms as extremal solutions in differential privacy.", "AI": {"tldr": "研究在差分隐私下，向量查询的最优加性机制设计。", "motivation": "探讨给定查询敏感度和衡量效用损失的范数单调成本函数时，哪种噪声分布可以最小化所有满足ε-差分隐私的加性机制中的预期成本。", "method": "使用凸重新排列理论将无限维优化问题简化为一维紧凸集上的径向对称分布集合，并证明其极点是阶梯状分布。", "result": "对于任何维度、范数和范数单调成本函数，都存在一种ε-差分隐私的阶梯机制，在所有加性机制中是最优的。", "conclusion": "该研究解决了Geng等人提出的猜想，提供了一种几何解释来说明为什么在差分隐私中会出现阶梯状分布作为最优解。"}}
{"id": "2601.14595", "pdf": "https://arxiv.org/pdf/2601.14595", "abs": "https://arxiv.org/abs/2601.14595", "authors": ["Qiyue Mei", "Michael Fu"], "title": "IntelliSA: An Intelligent Static Analyzer for IaC Security Smell Detection Using Symbolic Rules and Neural Inference", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted at MSR 2026", "summary": "Infrastructure as Code (IaC) enables automated provisioning of large-scale cloud and on-premise environments, reducing the need for repetitive manual setup. However, this automation is a double-edged sword: a single misconfiguration in IaC scripts can propagate widely, leading to severe system downtime and security risks. Prior studies have shown that IaC scripts often contain security smells--bad coding patterns that may introduce vulnerabilities--and have proposed static analyzers based on symbolic rules to detect them. Yet, our preliminary analysis reveals that rule-based detection alone tends to over-approximate, producing excessive false positives and increasing the burden of manual inspection. In this paper, we present IntelliSA, an intelligent static analyzer for IaC security smell detection that integrates symbolic rules with neural inference. IntelliSA applies symbolic rules to over-approximate potential smells for broad coverage, then employs neural inference to filter false positives. While an LLM can effectively perform this filtering, reliance on LLM APIs introduces high cost and latency, raises data governance concerns, and limits reproducibility and offline deployment. To address the challenges, we adopt a knowledge distillation approach: an LLM teacher generates pseudo-labels to train a compact student model--over 500x smaller--that learns from the teacher's knowledge and efficiently classifies false positives. We evaluate IntelliSA against two static analyzers and three LLM baselines (Claude-4, Grok-4, and GPT-5) using a human-labeled dataset including 241 security smells across 11,814 lines of real-world IaC code. Experimental results show that IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7-42%. Moreover, IntelliSA demonstrates the best cost-effectiveness, detecting 60% of security smells while inspecting less than 2% of the codebase.", "AI": {"tldr": "本文介绍了IntelliSA，一种结合符号规则和神经推理的智能静态分析器，用于检测IaC代码中的安全气味。", "motivation": "虽然基于符号规则的静态分析可以识别出潜在的安全问题，但其会产生过多的误报。因此，研究者提出将符号规则与神经网络结合起来以提高准确性和降低人工检查的工作量。", "method": "IntelliSA首先利用符号规则来大致覆盖可能存在的安全气味，然后使用神经推理来过滤掉误报。为了降低成本和延迟问题，并解决数据治理和复现性的问题，采用了知识蒸馏方法训练了一个小得多的学生模型来进行高效分类。", "result": "实验结果表明，IntelliSA在F1分数上达到了83%，比其他基准提高了7%-42%。并且，在检测出60%的安全气味的同时仅检查了不到2%的代码库，显示出了极高的成本效益。", "conclusion": "通过结合符号规则与神经网络推理并采用知识蒸馏技术训练小型模型，IntelliSA不仅能够高效准确地发现IaC中的安全问题，还解决了传统方法的成本和复现性等问题。"}}
{"id": "2601.14594", "pdf": "https://arxiv.org/pdf/2601.14594", "abs": "https://arxiv.org/abs/2601.14594", "authors": ["Lianying Chao", "Linfeng Yin", "Peiyu Ren", "Yifan Jiang", "Qiaoyu Ren", "Dingcheng Shan", "Jing-cheng Pang", "Sijie Wu", "Xubin Li", "Kai Zhang"], "title": "LFS: Learnable Frame Selector for Event-Aware and Temporally Diverse Video Captioning", "categories": ["cs.CV"], "comment": null, "summary": "Video captioning models convert frames into visual tokens and generate descriptions with large language models (LLMs). Since encoding all frames is prohibitively expensive, uniform sampling is the default choice, but it enforces equal temporal coverage while ignoring the uneven events distribution. This motivates a Learnable Frame Selector (LFS) that selects temporally diverse and event-relevant frames. LFS explicitly models temporal importance to balance temporal diversity and event relevance, and employs a stratified strategy to ensure temporal coverage while avoiding clustering. Crucially, LFS leverages caption feedback from frozen video-LLMs to learn frame selection that directly optimizes downstream caption quality. Additionally, we identify the gap between existing benchmark and human's cognition. Thus, we introduce ICH-CC built from carefully designed questions by annotators that reflect human-consistent understanding of video. Experiments indicate that LFS consistently improves detailed video captioning across two representative community benchmarks and ICH-CC, achieving up to 2.0% gains on VDC and over 4% gains on ICH-CC. Moreover, we observe that enhanced captions with LFS leads to improved performance on video question answering. Overall, LFS provides an effective and easy-to-integrate solution for detailed video captioning.", "AI": {"tldr": "该论文提出了一种可学习的帧选择器（LFS），用于事件感知和时间多样化的视频描述生成。", "motivation": "由于将所有帧编码的成本过高，现有的均匀采样方法忽略了事件分布不均的问题。因此，提出了LFS来优化视频描述的质量，同时考虑了时间多样性和事件相关性。", "method": "LFS通过显式建模时间重要性平衡时间多样性和事件相关性，并采用分层策略确保时间覆盖的同时避免聚类。此外，LFS利用冻结的视频大语言模型（LLMs）提供的反馈来优化帧选择，直接提升下游描述质量。", "result": "实验表明，LFS在两个代表性社区基准和新的ICH-CC上显著提高了视频描述的质量，分别达到了2.0%以上的增益以及超过4%的增益。此外，在视频问答任务上的性能也有所提高。", "conclusion": "总体而言，LFS提供了一个有效的、易于集成的解决方案来提升详细的视频描述生成质量。"}}
{"id": "2601.14593", "pdf": "https://arxiv.org/pdf/2601.14593", "abs": "https://arxiv.org/abs/2601.14593", "authors": ["Po-Kai Chiu", "Hung-Hsuan Chen"], "title": "From Volumes to Slices: Computationally Efficient Contrastive Learning for Sequential Abdominal CT Analysis", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The requirement for expert annotations limits the effectiveness of deep learning for medical image analysis. Although 3D self-supervised methods like volume contrast learning (VoCo) are powerful and partially address the labeling scarcity issue, their high computational cost and memory consumption are barriers. We propose 2D-VoCo, an efficient adaptation of the VoCo framework for slice-level self-supervised pre-training that learns spatial-semantic features from unlabeled 2D CT slices via contrastive learning. The pre-trained CNN backbone is then integrated into a CNN-LSTM architecture to classify multi-organ injuries. In the RSNA 2023 Abdominal Trauma dataset, 2D-VoCo pre-training significantly improves mAP, precision, recall, and RSNA score over training from scratch. Our framework provides a practical method to reduce the dependency on labeled data and enhance model performance in clinical CT analysis. We release the code for reproducibility. https://github.com/tkz05/2D-VoCo-CT-Classifier", "AI": {"tldr": "本文提出了一个高效的2D-VoCo方法，用于无标签的CT图像切片进行对比学习，并通过预训练CNN-LSTM架构来提升多器官损伤分类性能。", "motivation": "由于专家标注数据量有限，深度学习在医学影像分析中的应用受限。尽管3D自监督方法如体积对比学习（VoCo）能够部分解决标签稀缺问题，但其计算成本和内存消耗较高。", "method": "本文提出了2D-VoCo方法，一个适用于切片级自监督预训练的高效方法，通过对比学习从无标签的2D CT图像中提取空间-语义特征。预训练的CNN骨干网络被集成到CNN-LSTM架构中进行多器官损伤分类。", "result": "在RSNA 2023腹部创伤数据集中，与从头开始训练相比，使用2D-VoCo预训练显著提升了mAP、精度、召回率和RSNA分数。", "conclusion": "本文框架提供了一种实用的方法来减少对标注数据的依赖，并提升临床CT分析中的模型性能。"}}
{"id": "2601.14589", "pdf": "https://arxiv.org/pdf/2601.14589", "abs": "https://arxiv.org/abs/2601.14589", "authors": ["Shanshan Zhu", "Wenxuan Song", "Jiayue Melissa Shi", "Dong Whi Yoo", "Karthik S. Bhat", "Koustuv Saha"], "title": "Designing KRIYA: An AI Companion for Wellbeing Self-Reflection", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Most personal wellbeing apps present summative dashboards of health and physical activity metrics, yet many users struggle to translate this information into meaningful understanding. These apps commonly support engagement through goals, reminders, and structured targets, which can reinforce comparison, judgment, and performance anxiety. To explore a complementary approach that prioritizes self-reflection, we design KRIYA, an AI wellbeing companion that supports co-interpretive engagement with personal wellbeing data. KRIYA aims to collaborate with users to explore questions, explanations, and future scenarios through features such as Comfort Zone, Detective Mode, and What-If Planning. We conducted semi-structured interviews with 18 college students interacting with a KRIYA prototype using hypothetical data. Our findings show that through KRIYA interaction, users framed engaging with wellbeing data as interpretation rather than performance, experienced reflection as supportive or pressuring depending on emotional framing, and developed trust through transparency. We discuss design implications for AI companions that support curiosity, self-compassion, and reflective sensemaking of personal health data.", "AI": {"tldr": "设计KRIYA：一款促进自我反思的AI健康伴侣", "motivation": "现有的个人健康应用主要展示汇总的数据，但用户很难将其转化为有意义的理解，并且这些应用程序可能引发比较、判断和绩效焦虑。因此，作者设计了KRIYA来探索一种以自我反思为中心的方法。", "method": "通过半结构化访谈收集了18名大学生使用KRIYA原型的反馈数据，该原型包括舒适区、侦探模式和假设规划等功能。", "result": "研究发现，用户将与健康数据的互动视为解释而非表现，并且对自我反思的感受取决于情绪框架。此外，透明度有助于建立信任。", "conclusion": "讨论了支持好奇心、自我同情和对个人健康数据进行反思性理解的AI伴侣的设计影响。"}}
{"id": "2601.14587", "pdf": "https://arxiv.org/pdf/2601.14587", "abs": "https://arxiv.org/abs/2601.14587", "authors": ["Lauren W. Wang", "Mohamed Kari", "Parastoo Abtahi"], "title": "Explainable OOHRI: Communicating Robot Capabilities and Limitations as Augmented Reality Affordances", "categories": ["cs.HC", "cs.RO"], "comment": "ef:Proceedings of the 21st ACM/IEEE International Conference on Human-Robot Interaction (HRI 2026)", "summary": "Human interaction is essential for issuing personalized instructions and assisting robots when failure is likely. However, robots remain largely black boxes, offering users little insight into their evolving capabilities and limitations. To address this gap, we present explainable object-oriented HRI (X-OOHRI), an augmented reality (AR) interface that conveys robot action possibilities and constraints through visual signifiers, radial menus, color coding, and explanation tags. Our system encodes object properties and robot limits into object-oriented structures using a vision-language model, allowing explanation generation on the fly and direct manipulation of virtual twins spatially aligned within a simulated environment. We integrate the end-to-end pipeline with a physical robot and showcase diverse use cases ranging from low-level pick-and-place to high-level instructions. Finally, we evaluate X-OOHRI through a user study and find that participants effectively issue object-oriented commands, develop accurate mental models of robot limitations, and engage in mixed-initiative resolution.", "AI": {"tldr": "本文提出了一种可解释的对象导向的人机交互（X-OOHRI）系统，该系统利用增强现实技术展示机器人的操作可能性和限制。", "motivation": "由于机器人对用户而言仍是黑盒子，缺乏对其能力与局限性的了解，因此论文旨在开发一种能够通过视觉符号、径向菜单、颜色编码及解释标签等手段展现机器人能力与限制的AR接口。", "method": "研究将物体属性和机器人限制编码为对象导向结构，并使用视觉语言模型实时生成解释，允许在模拟环境中直接操控虚拟副本，并与实体机器人集成展示多种应用场景。", "result": "通过用户研究表明，参与者能够有效地发出面向对象的指令、形成准确的机器人限制心理模型并进行混合倡议解决。", "conclusion": "实验结果表明X-OOHRI系统能有效增强人类对机器人的理解和操作能力，促进人机交互的有效性和安全性。"}}
{"id": "2601.14584", "pdf": "https://arxiv.org/pdf/2601.14584", "abs": "https://arxiv.org/abs/2601.14584", "authors": ["Cheng Wan", "Bahram Jafrasteh", "Ehsan Adeli", "Miaomiao Zhang", "Qingyu Zhao"], "title": "Anatomically Guided Latent Diffusion for Brain MRI Progression Modeling", "categories": ["cs.CV"], "comment": "10 pages, 5 figures, 3 tables", "summary": "Accurately modeling longitudinal brain MRI progression is crucial for understanding neurodegenerative diseases and predicting individualized structural changes. Existing state-of-the-art approaches, such as Brain Latent Progression (BrLP), often use multi-stage training pipelines with auxiliary conditioning modules but suffer from architectural complexity, suboptimal use of conditional clinical covariates, and limited guarantees of anatomical consistency. We propose Anatomically Guided Latent Diffusion Model (AG-LDM), a segmentation-guided framework that enforces anatomically consistent progression while substantially simplifying the training pipeline. AG-LDM conditions latent diffusion by directly fusing baseline anatomy, noisy follow-up states, and clinical covariates at the input level, a strategy that avoids auxiliary control networks by learning a unified, end-to-end model that represents both anatomy and progression. A lightweight 3D tissue segmentation model (WarpSeg) provides explicit anatomical supervision during both autoencoder fine-tuning and diffusion model training, ensuring consistent brain tissue boundaries and morphometric fidelity. Experiments on 31,713 ADNI longitudinal pairs and zero-shot evaluation on OASIS-3 demonstrate that AG-LDM matches or surpasses more complex diffusion models, achieving state-of-the-art image quality and 15-20\\% reduction in volumetric errors in generated images. AG-LDM also exhibits markedly stronger utilization of temporal and clinical covariates (up to 31.5x higher sensitivity than BrLP) and generates biologically plausible counterfactual trajectories, accurately capturing hallmarks of Alzheimer's progression such as limbic atrophy and ventricular expansion. These results highlight AG-LDM as an efficient, anatomically grounded framework for reliable brain MRI progression modeling.", "AI": {"tldr": "本文提出了Anatomically Guided Latent Diffusion Model (AG-LDM)，用于准确建模纵向脑部MRI变化，简化训练流程并提高解剖一致性。", "motivation": "现有的方法在使用辅助条件模块时存在架构复杂、对临床共变量利用不足和解剖一致性保障不充分的问题。因此，本文旨在提供一个更简单且能够保证解剖一致性的解决方案。", "method": "AG-LDM通过直接融合基线解剖结构、噪声后续状态及临床共变量，在输入层中条件化潜扩散模型，并使用轻量级3D组织分割模型（WarpSeg）进行显式的解剖监督，以确保脑部组织边界和形态学保真。", "result": "实验显示AG-LDM在ADNI纵向数据集上与更复杂的扩散模型相比匹配或超过其表现，在生成图像的质量和体积误差方面达到新的最先进水平，并且对时间和临床共变量的利用更加敏感，能准确捕捉阿尔茨海默病进展特征如边缘系统萎缩和脑室扩张。", "conclusion": "AG-LDM作为一个高效、解剖导向的框架，为可靠的脑部MRI变化建模提供了可靠方法。"}}
{"id": "2601.14568", "pdf": "https://arxiv.org/pdf/2601.14568", "abs": "https://arxiv.org/abs/2601.14568", "authors": ["Wei Ma", "Shaowu Chen", "Junjie Ye", "Peichang Zhang", "Lei Huang"], "title": "Breaking the accuracy-resource dilemma: a lightweight adaptive video inference enhancement", "categories": ["cs.CV", "cs.AI"], "comment": "5 pages, 4 figures", "summary": "Existing video inference (VI) enhancement methods typically aim to improve performance by scaling up model sizes and employing sophisticated network architectures. While these approaches demonstrated state-of-the-art performance, they often overlooked the trade-off of resource efficiency and inference effectiveness, leading to inefficient resource utilization and suboptimal inference performance. To address this problem, a fuzzy controller (FC-r) is developed based on key system parameters and inference-related metrics. Guided by the FC-r, a VI enhancement framework is proposed, where the spatiotemporal correlation of targets across adjacent video frames is leveraged. Given the real-time resource conditions of the target device, the framework can dynamically switch between models of varying scales during VI. Experimental results demonstrate that the proposed method effectively achieves a balance between resource utilization and inference performance.", "AI": {"tldr": "本文提出了一种基于模糊控制器的轻量级自适应视频推理增强框架，旨在平衡资源利用率与推理性能。", "motivation": "现有的视频推理增强方法通过扩大模型规模和采用复杂的网络架构来提高性能，但忽视了资源效率与推断效果之间的折衷，导致资源利用不充分及推断表现不佳。", "method": "开发了一种基于关键系统参数和推理相关指标的模糊控制器（FC-r），提出了一种视频推理增强框架，该框架能够根据目标设备的实际资源条件动态切换不同规模的模型以优化性能。", "result": "实验结果表明，所提出的方法能够在资源利用和推断表现之间达到良好的平衡。", "conclusion": "通过采用模糊控制器来适应不同设备的实时资源状况，实现了视频推理任务中准确性和资源效率之间的有效协调。"}}
{"id": "2601.14566", "pdf": "https://arxiv.org/pdf/2601.14566", "abs": "https://arxiv.org/abs/2601.14566", "authors": ["Shenghan Gao", "Junye Wang", "Junjie Xiong", "Yun Jiang", "Yun Fang", "Qifan Hu", "Baolong Liu", "Quan Li"], "title": "SCSimulator: An Exploratory Visual Analytics Framework for Partner Selection in Supply Chains through LLM-driven Multi-Agent Simulation", "categories": ["cs.HC"], "comment": "ACM IUI 2026", "summary": "Supply chains (SCs), complex networks spanning from raw material acquisition to product delivery, with enterprises as interconnected nodes, play a pivotal role in organizational success. However, optimizing SCs remains challenging, particularly in partner selection, a key bottleneck shaped by competitive and cooperative dynamics. This challenge constitutes a multi-objective dynamic game requiring a synergistic integration of Multi-Criteria Decision-Making and Game Theory. Traditional approaches, grounded in mathematical simplifications and managerial heuristics, fail to capture real-world intricacies and risk introducing subjective biases. Multi-agent simulation offers promise, but prior research has largely relied on fixed, uniform agent logic, limiting practical applicability. Recent advances in LLMs create opportunities to represent complex SC requirements and hybrid game logic. However, challenges persist in modeling dynamic SC relationships, ensuring interpretability, and balancing agent autonomy with expert control. We present SCSimulator, a visual analytics framework that integrates LLM-driven MAS with human-in-the-loop collaboration for SC partner selection. It simulates SC evolution via adaptive network structures and enterprise behaviors, which are visualized via interpretable interfaces. By combining CoT reasoning with XAI techniques, it generates multi-faceted, transparent explanations of decision trade-offs. Users can iteratively adjust simulation settings to explore outcomes aligned with their expectations and strategic priorities. Developed through iterative co-design with SC experts and industry managers, SCSimulator serves as a proof-of-concept, offering methodological contributions and practical insights for future research on SC decision-making and interactive AI-driven analytics. Usage scenarios and a user study demonstrate the system's effectiveness and usability.", "AI": {"tldr": "介绍SCSimulator，一个用于供应链合作伙伴选择的探索性可视化分析框架，通过LLM驱动的多代理模拟实现。", "motivation": "优化供应链特别是伙伴选择是一个关键难题，传统方法难以捕捉现实复杂性和避免主观偏差。因此开发了新的解决方案来提升决策质量。", "method": "提出SCSimulator框架，结合LLM驱动的多代理系统与人的互动协作，在可视化界面下通过自适应网络结构和企业行为模拟供应链进化，并运用CoT推理和XAI技术提供透明化的决策解释。", "result": "用户可以通过调整模拟设置来探索符合预期的结果。用户研究场景展示了系统的有效性和易用性。", "conclusion": "SCSimulator作为概念验证，为未来供应链决策制定及交互式AI驱动分析提供了方法论贡献和实用见解。"}}
{"id": "2601.14563", "pdf": "https://arxiv.org/pdf/2601.14563", "abs": "https://arxiv.org/abs/2601.14563", "authors": ["Thanh-Huy Nguyen", "Hoang-Loc Cao", "Dat T. Chung", "Mai-Anh Vu", "Thanh-Minh Nguyen", "Minh Le", "Phat K. Huynh", "Ulas Bagci"], "title": "Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency", "categories": ["cs.CV"], "comment": null, "summary": "Scribble-supervised methods have emerged to mitigate the prohibitive annotation burden in medical image segmentation. However, the inherent sparsity of these annotations introduces significant ambiguity, which results in noisy pseudo-label propagation and hinders the learning of robust anatomical boundaries. To address this challenge, we propose SDT-Net, a novel dual-teacher, single-student framework designed to maximize supervision quality from these weak signals. Our method features a Dynamic Teacher Switching (DTS) module to adaptively select the most reliable teacher. This selected teacher then guides the student via two synergistic mechanisms: high-confidence pseudo-labels, refined by a Pick Reliable Pixels (PRP) mechanism, and multi-level feature alignment, enforced by a Hierarchical Consistency (HiCo) module. Extensive experiments on the ACDC and MSCMRseg datasets demonstrate that SDT-Net achieves state-of-the-art performance, producing more accurate and anatomically plausible segmentation.", "AI": {"tldr": "本文提出SDT-Net，一种双教师单学生框架，用于基于草图监督的医学图像分割。", "motivation": "现有的草图监督方法虽然减轻了标注负担，但注释的稀疏性导致伪标签传播噪声大，影响精确解剖边界的学习。", "method": "SDT-Net采用动态教师切换（DTS）模块选择最可靠的教师，并通过高置信度伪标签和多级特征对齐机制指导学生学习。", "result": "实验结果表明，在ACDC和MSCMRseg数据集上，SDT-Net达到了最先进的性能，产生更准确且解剖学合理的分割结果。", "conclusion": "SDT-Net框架通过动态选择最佳教师并应用高置信度伪标签及多级特征对齐机制显著提高了基于草图监督的医学图像分割准确性。"}}
{"id": "2601.14561", "pdf": "https://arxiv.org/pdf/2601.14561", "abs": "https://arxiv.org/abs/2601.14561", "authors": ["DongHoon Kim", "Isaac Cho"], "title": "Evaluating Preattentive Features for Detecting Changes in Virtual Environments", "categories": ["cs.HC"], "comment": "This paper has been accepted for the IEEE VR conference", "summary": "Visual perception plays a critical role in detecting changes within immersive Virtual Reality (VR) environments. However, as visual complexity increases, perceptual performance declines, making it more difficult to detect changes quickly and accurately. This study examines how visual features, known for facilitating preattentive processing, impact a change detection task in immersive 3D environments, with a focus on visual complexity, object attributes, and spatial proximity. Our results demonstrate that preattentive processing enhances change detection, particularly when the altered object is spatially isolated and not perceptually grouped with similar surrounding objects. Changes to isolated objects were detected more reliably, suggesting that perceptual isolation reduces cognitive load and draws more attention. Conversely, when a changed object was surrounded by visually similar elements, participants were less likely to detect the change, indicating that perceptual grouping hinders individual object recognition in complex scenes. These results provide guidelines for designing VR applications that strategically utilize spatial isolation and visual features to improve the user experience.", "AI": {"tldr": "研究评估了虚拟环境中预觉知特征在检测变化中的作用。", "motivation": "随着视觉复杂度的增加，感知性能下降，这使得快速和准确地检测变化变得更加困难。因此，本研究旨在探讨有助于预觉知处理的视觉特性如何影响3D环境中的变化检测任务。", "method": "该研究关注于在虚拟现实环境中，通过分析视觉复杂性、对象属性以及空间接近度对变化检测的影响。", "result": "结果表明，预觉知处理增强了变化检测能力，特别是当被改变的对象是孤立的并且没有与周围的相似对象进行感知分组时。孤立对象的变化更容易被察觉，暗示了感知隔离减少了认知负荷并吸引了更多注意力。", "conclusion": "这些研究结果为虚拟现实应用程序的设计提供了指导，建议通过战略性地利用空间隔离和视觉特征来提升用户体验。"}}
{"id": "2601.14553", "pdf": "https://arxiv.org/pdf/2601.14553", "abs": "https://arxiv.org/abs/2601.14553", "authors": ["Brian Christian", "Matan Mazor"], "title": "Self-Blinding and Counterfactual Self-Simulation Mitigate Biases and Sycophancy in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Fair decisions require ignoring irrelevant, potentially biasing, information. To achieve this, decision-makers need to approximate what decision they would have made had they not known certain facts, such as the gender or race of a job candidate. This counterfactual self-simulation is notoriously hard for humans, leading to biased judgments even by well-meaning actors. Here we show that large language models (LLMs) suffer from similar limitations in their ability to approximate what decisions they would make under counterfactual knowledge in offsetting gender and race biases and overcoming sycophancy. We show that prompting models to ignore or pretend not to know biasing information fails to offset these biases and occasionally backfires. However, unlike humans, LLMs can be given access to a ground-truth model of their own counterfactual cognition -- their own API. We show that this access to the responses of a blinded replica enables fairer decisions, while providing greater transparency to distinguish implicit from intentionally biased behavior.", "AI": {"tldr": "本文探讨了大型语言模型在忽略偏见信息和克服奉承行为方面的局限，并提出了一种通过自我模糊和反事实自我模拟来实现更公平决策的方法。", "motivation": "作者旨在解决大型语言模型在做出公平决策时，如何有效地忽略那些可能引起偏见的信息，类似于人类需要进行的反事实自我模拟。", "method": "研究者们使用了让模型访问一个被模糊处理的自身副本的API来实现反事实自我模拟，以期抵消性别和种族偏见，并克服奉承行为。", "result": "实验结果显示，通过这种方法可以促进更公平的决策，并且提供了更大的透明度，以区分隐性偏见和有意图的偏见行为。", "conclusion": "大型语言模型可以通过访问其自身的反事实认知模型来实现更公平的决策，这比简单的忽略或假装不知晓偏见信息的方法更为有效。"}}
{"id": "2601.14550", "pdf": "https://arxiv.org/pdf/2601.14550", "abs": "https://arxiv.org/abs/2601.14550", "authors": ["Tailai Cheng", "Kejia Chen", "Lingyun Chen", "Liding Zhang", "Yue Zhang", "Yao Ling", "Mahdi Hamad", "Zhenshan Bing", "Fan Wu", "Karan Sharma", "Alois Knoll"], "title": "TacUMI: A Multi-Modal Universal Manipulation Interface for Contact-Rich Tasks", "categories": ["cs.RO"], "comment": null, "summary": "Task decomposition is critical for understanding and learning complex long-horizon manipulation tasks. Especially for tasks involving rich physical interactions, relying solely on visual observations and robot proprioceptive information often fails to reveal the underlying event transitions. This raises the requirement for efficient collection of high-quality multi-modal data as well as robust segmentation method to decompose demonstrations into meaningful modules. Building on the idea of the handheld demonstration device Universal Manipulation Interface (UMI), we introduce TacUMI, a multi-modal data collection system that integrates additionally ViTac sensors, force-torque sensor, and pose tracker into a compact, robot-compatible gripper design, which enables synchronized acquisition of all these modalities during human demonstrations. We then propose a multi-modal segmentation framework that leverages temporal models to detect semantically meaningful event boundaries in sequential manipulations. Evaluation on a challenging cable mounting task shows more than 90 percent segmentation accuracy and highlights a remarkable improvement with more modalities, which validates that TacUMI establishes a practical foundation for both scalable collection and segmentation of multi-modal demonstrations in contact-rich tasks.", "AI": {"tldr": "本文介绍了TacUMI，一种用于接触丰富任务的多模态通用操作界面。", "motivation": "解决仅依赖视觉和机器人本体感知信息无法揭示复杂操纵任务中事件转换的问题，需要高效收集高质量多模态数据及稳健的分段方法来分解演示为有意义的模块。", "method": "TacUMI集成了ViTac传感器、力矩传感器和姿态跟踪器等设备以同步采集人类演示中的各种模式，并提出了一种利用时间模型检测序列操作中语义事件边界的多模态分段框架。", "result": "在复杂的电缆安装任务上的评估显示超过90%的分割准确率，证明了TacUMI为接触丰富任务的多模态演示的可扩展采集和分割提供了实用基础。", "conclusion": "实验结果验证了TacUMI的有效性，展示了其在复杂操纵任务中高效收集和处理多模态数据的能力。"}}
{"id": "2601.14541", "pdf": "https://arxiv.org/pdf/2601.14541", "abs": "https://arxiv.org/abs/2601.14541", "authors": ["Deming Chen", "Vijay Ganesh", "Weikai Li", "Yingyan", "Lin", "Yong Liu", "Subhasish Mitra", "David Z. Pan", "Ruchir Puri", "Jason Cong", "Yizhou Sun"], "title": "Report for NSF Workshop on AI for Electronic Design Automation", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": null, "summary": "This report distills the discussions and recommendations from the NSF Workshop on AI for Electronic Design Automation (EDA), held on December 10, 2024 in Vancouver alongside NeurIPS 2024. Bringing together experts across machine learning and EDA, the workshop examined how AI-spanning large language models (LLMs), graph neural networks (GNNs), reinforcement learning (RL), neurosymbolic methods, etc.-can facilitate EDA and shorten design turnaround. The workshop includes four themes: (1) AI for physical synthesis and design for manufacturing (DFM), discussing challenges in physical manufacturing process and potential AI applications; (2) AI for high-level and logic-level synthesis (HLS/LLS), covering pragma insertion, program transformation, RTL code generation, etc.; (3) AI toolbox for optimization and design, discussing frontier AI developments that could potentially be applied to EDA tasks; and (4) AI for test and verification, including LLM-assisted verification tools, ML-augmented SAT solving, security/reliability challenges, etc. The report recommends NSF to foster AI/EDA collaboration, invest in foundational AI for EDA, develop robust data infrastructures, promote scalable compute infrastructure, and invest in workforce development to democratize hardware design and enable next-generation hardware systems. The workshop information can be found on the website https://ai4eda-workshop.github.io/.", "AI": {"tldr": "报告总结了NSF关于电子设计自动化中AI应用的研讨会讨论和建议。", "motivation": "动机在于探索如何通过机器学习技术，特别是大型语言模型、图神经网络、强化学习等方法来促进EDA领域的进步并缩短设计周期。", "method": "研讨会上涵盖了四个主题：物理合成与设计制造中的AI应用；高级和逻辑级综合的AI应用；用于优化和设计的AI工具箱；以及测试和验证中的AI应用。", "result": "报告建议NSF加强AI/EDA合作，投资基础性的AI研究，并开发强大的数据基础设施以促进可扩展的计算基础设施，并发展人才队伍来普及硬件设计。", "conclusion": "研讨会强调了在EDA中集成先进AI技术的重要性，旨在通过跨学科的合作推进下一代硬件系统的创新。"}}
{"id": "2601.14530", "pdf": "https://arxiv.org/pdf/2601.14530", "abs": "https://arxiv.org/abs/2601.14530", "authors": ["Xiaoyan Kui", "Zijie Fan", "Zexin Ji", "Qinsong Li", "Hao Xu", "Weixin Si", "Haodong Xu", "Beiji Zou"], "title": "PAS-Mamba: Phase-Amplitude-Spatial State Space Model for MRI Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Joint feature modeling in both the spatial and frequency domains has become a mainstream approach in MRI reconstruction. However, existing methods generally treat the frequency domain as a whole, neglecting the differences in the information carried by its internal components. According to Fourier transform theory, phase and amplitude represent different types of information in the image. Our spectrum swapping experiments show that magnitude mainly reflects pixel-level intensity, while phase predominantly governs image structure. To prevent interference between phase and magnitude feature learning caused by unified frequency-domain modeling, we propose the Phase-Amplitude-Spatial State Space Model (PAS-Mamba) for MRI Reconstruction, a framework that decouples phase and magnitude modeling in the frequency domain and combines it with image-domain features for better reconstruction. In the image domain, LocalMamba preserves spatial locality to sharpen fine anatomical details. In frequency domain, we disentangle amplitude and phase into two specialized branches to avoid representational coupling. To respect the concentric geometry of frequency information, we propose Circular Frequency Domain Scanning (CFDS) to serialize features from low to high frequencies. Finally, a Dual-Domain Complementary Fusion Module (DDCFM) adaptively fuses amplitude phase representations and enables bidirectional exchange between frequency and image domains, delivering superior reconstruction. Extensive experiments on the IXI and fastMRI knee datasets show that PAS-Mamba consistently outperforms state of the art reconstruction methods.", "AI": {"tldr": "本文提出了PAS-Mamba框架，用于MRI重建，该框架通过分离频率域的幅度和相位建模，并结合图像域特征进行更优的重建。", "motivation": "现有方法在处理MRI重建时一般将频率域视为整体，忽视了其内部组件携带的不同信息。本文旨在解决统一频率域建模导致的相位与幅度特征学习相互干扰的问题。", "method": "PAS-Mamba包括LocalMamba用于保持空间局部性以锐化精细解剖细节；分离幅度和相位到两个专门分支避免表示耦合；使用Circular Frequency Domain Scanning（CFDS）对频率信息进行有序序列化处理，并通过Dual-Domain Complementary Fusion Module（DDCFM）自适应融合幅度、相位表示，实现频域与图像域之间的双向交流。", "result": "实验结果表明，在IXI和fastMRI膝部数据集上，PAS-Mamba在MRI重建方面优于现有的先进方法。", "conclusion": "PAS-Mamba通过分离频率域的幅度和相位建模，并结合图像域特征进行优化，达到了更好的MRI重建效果。"}}
{"id": "2601.14525", "pdf": "https://arxiv.org/pdf/2601.14525", "abs": "https://arxiv.org/abs/2601.14525", "authors": ["Chenglei Si", "Zitong Yang", "Yejin Choi", "Emmanuel Candès", "Diyi Yang", "Tatsunori Hashimoto"], "title": "Towards Execution-Grounded Automated AI Research", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Automated AI research holds great potential to accelerate scientific discovery. However, current LLMs often generate plausible-looking but ineffective ideas. Execution grounding may help, but it is unclear whether automated execution is feasible and whether LLMs can learn from the execution feedback. To investigate these, we first build an automated executor to implement ideas and launch large-scale parallel GPU experiments to verify their effectiveness. We then convert two realistic research problems - LLM pre-training and post-training - into execution environments and demonstrate that our automated executor can implement a large fraction of the ideas sampled from frontier LLMs. We analyze two methods to learn from the execution feedback: evolutionary search and reinforcement learning. Execution-guided evolutionary search is sample-efficient: it finds a method that significantly outperforms the GRPO baseline (69.4% vs 48.0%) on post-training, and finds a pre-training recipe that outperforms the nanoGPT baseline (19.7 minutes vs 35.9 minutes) on pre-training, all within just ten search epochs. Frontier LLMs often generate meaningful algorithmic ideas during search, but they tend to saturate early and only occasionally exhibit scaling trends. Reinforcement learning from execution reward, on the other hand, suffers from mode collapse. It successfully improves the average reward of the ideator model but not the upper-bound, due to models converging on simple ideas. We thoroughly analyze the executed ideas and training dynamics to facilitate future efforts towards execution-grounded automated AI research.", "AI": {"tldr": "本文探讨了通过执行导向实现自动化AI研究的可能性，评估了两种从执行反馈中学习的方法，并展示了它们在两个真实问题上的应用。", "motivation": "自动化AI研究有可能加速科学发现。然而，当前的大语言模型（LLMs）生成的许多想法虽然看起来合理但实际上无效。本文试图调查是否可以通过自动执行和反馈来改善这种状况。", "method": "构建了一个自动化执行器用于实现并验证想法的有效性，并将大语言模型生成的想法应用于两个实际问题：预训练和后训练。此外，还分析了两种学习方法：进化搜索和强化学习。", "result": "通过执行导向的进化搜索找到了显著优于基准的方法，在后训练中达到了69.4%，而GRPO基线为48.0%；在预训练中达到19.7分钟，比nanoGPT基线快35.9分钟。强化学习方法虽然提高了平均奖励但遭遇模式崩溃。", "conclusion": "执行导向的自动化AI研究能够发现有效的算法和实验设计，进化搜索表现较好，而强化学习则因为过度简化思想而导致效果有限。"}}
{"id": "2601.14523", "pdf": "https://arxiv.org/pdf/2601.14523", "abs": "https://arxiv.org/abs/2601.14523", "authors": ["Leyi Zhao", "Weijie Huang", "Yitong Guo", "Jiang Bian", "Chenghong Wang", "Xuhong Zhang"], "title": "Large Language Model-Powered Evolutionary Code Optimization on a Phylogenetic Tree", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Optimizing scientific computing algorithms for modern GPUs is a labor-intensive and iterative process involving repeated code modification, benchmarking, and tuning across complex hardware and software stacks. Recent work has explored large language model (LLM)-assisted evolutionary methods for automated code optimization, but these approaches primarily rely on outcome-based selection and random mutation, underutilizing the rich trajectory information generated during iterative optimization. We propose PhyloEvolve, an LLM-agent system that reframes GPU-oriented algorithm optimization as an In-Context Reinforcement Learning (ICRL) problem. This formulation enables trajectory-conditioned reuse of optimization experience without model retraining. PhyloEvolve integrates Algorithm Distillation and prompt-based Decision Transformers into an iterative workflow, treating sequences of algorithm modifications and performance feedback as first-class learning signals. To organize optimization history, we introduce a phylogenetic tree representation that captures inheritance, divergence, and recombination among algorithm variants, enabling backtracking, cross-lineage transfer, and reproducibility. The system combines elite trajectory pooling, multi-island parallel exploration, and containerized execution to balance exploration and exploitation across heterogeneous hardware. We evaluate PhyloEvolve on scientific computing workloads including PDE solvers, manifold learning, and spectral graph algorithms, demonstrating consistent improvements in runtime, memory efficiency, and correctness over baseline and evolutionary methods. Code is published at: https://github.com/annihi1ation/phylo_evolve", "AI": {"tldr": "本文介绍了一种名为PhyloEvolve的大语言模型驱动的进化代码优化系统，该系统使用基于轨迹信息的方法来改进GPU上的科学计算算法。", "motivation": "自动化和高效地优化科学计算算法对于现代GPU非常重要。现有的大语言模型辅助的进化方法主要依赖于结果选择和随机变异，未能充分利用迭代过程中生成的丰富轨迹信息。", "method": "PhyloEvolve将基于GPU的算法优化重新定义为一种在上下文中的强化学习问题，并结合了算法提炼、提示式决策转换器以及使用系统化地记录优化历史的进化树表示方法来指导代码优化过程。", "result": "该系统通过精英轨迹池、多岛屿并行探索和容器化执行等策略，在PDE求解器、流形学习和谱图算法上展示了在运行时间、内存效率和正确性上的改进。", "conclusion": "PhyloEvolve的评估显示，它能有效提升科学计算工作负载的性能，并且提供了一个新的方向来利用大语言模型和进化方法进行代码优化。"}}
{"id": "2601.14519", "pdf": "https://arxiv.org/pdf/2601.14519", "abs": "https://arxiv.org/abs/2601.14519", "authors": ["Giulio Rossolini"], "title": "How Worst-Case Are Adversarial Attacks? Linking Adversarial and Statistical Robustness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial attacks are widely used to evaluate model robustness, yet their validity as proxies for robustness to random perturbations remains debated. We ask whether an adversarial perturbation provides a representative estimate of robustness under random noise of the same magnitude, or instead reflects an atypical worst-case event. To this end, we introduce a probabilistic metric that quantifies noisy risk with respect to directionally biased perturbation distributions, parameterized by a concentration factor $κ$ that interpolates between isotropic noise and adversarial direction. Using this framework, we study the limits of adversarial perturbations as estimators of noisy risk by proposing an attack strategy designed to operate in regimes statistically closer to uniform noise. Experiments on ImageNet and CIFAR-10 systematically benchmark widely used attacks, highlighting when adversarial success meaningfully reflects noisy risk and when it fails, thereby informing their use in safety-oriented evaluation.", "AI": {"tldr": "本文探讨了对抗性攻击是否能够代表随机噪声下的鲁棒性，并提出了一种新的概率度量来评估这种鲁棒性。", "motivation": "尽管对抗性攻击被广泛用于评估模型的鲁棒性，但它们作为衡量随机扰动下鲁棒性的代理的有效性仍然存在争议。因此，本文旨在探索对抗性扰动是否能够代表具有相同幅度的随机噪声下的鲁棒性。", "method": "引入了一个概率度量，该度量通过一个集中因子$κ$量化了带有方向偏差的扰动分布下的噪音风险，并提出了新的攻击策略来评估对抗性攻击作为估计噪音风险的有效性。", "result": "实验结果显示，在ImageNet和CIFAR-10数据集上广泛使用的攻击方法在某些情况下能够有意义地反映噪声风险，而在其他情况下则不能。", "conclusion": "该研究为安全导向的模型评估提供了指导，强调了对抗性成功何时能有效反映噪声风险以及何时不能。"}}
{"id": "2601.14516", "pdf": "https://arxiv.org/pdf/2601.14516", "abs": "https://arxiv.org/abs/2601.14516", "authors": ["Saba Tabatabaee", "Carol Espy-Wilson"], "title": "Towards noise-robust speech inversion through multi-task learning with speech enhancement", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted for presentation at ICASSP 2026", "summary": "Recent studies demonstrate the effectiveness of Self Supervised Learning (SSL) speech representations for Speech Inversion (SI). However, applying SI in real-world scenarios remains challenging due to the pervasive presence of background noise. We propose a unified framework that integrates Speech Enhancement (SE) and SI models through shared SSL-based speech representations. In this framework, the SSL model is trained not only to support the SE module in suppressing noise but also to produce representations that are more informative for the SI task, allowing both modules to benefit from joint training. At a Signal-to-Noise Ratio of -5 db, our method for the SI task achieves relative improvements over the baseline of 80.95% under babble noise and 38.98% under non-babble noise, as measured by the average Pearson product-moment correlation across all estimated parameters.", "AI": {"tldr": "本文提出一种通过多任务学习结合语音增强和语音逆向的统一框架，以提高噪声鲁棒性的语音逆向效果。", "motivation": "现有的语音逆向研究在实际应用中面临背景噪音干扰的问题，因此需要开发新的方法来解决这一挑战。", "method": "本文提出一个整合了基于自监督学习（SSL）的语音增强和语音逆向模型的统一框架，并通过共享SSL基础的语音表示使两个模块受益于联合训练。", "result": "在-5 db信噪比下，该方法分别对babble噪声和非babble噪声下的语音逆向任务实现了80.95%和38.98%的相对改进。", "conclusion": "通过多任务学习结合语音增强与逆向模型，本文展示了提高语音逆向在存在背景噪音情况下的鲁棒性的潜力。"}}
{"id": "2601.14514", "pdf": "https://arxiv.org/pdf/2601.14514", "abs": "https://arxiv.org/abs/2601.14514", "authors": ["Tony Chen", "Sam Cheyette", "Kelsey Allen", "Joshua Tenenbaum", "Kevin Smith"], "title": "\"Just in Time\" World Modeling Supports Human Planning and Reasoning", "categories": ["cs.AI", "q-bio.NC"], "comment": null, "summary": "Probabilistic mental simulation is thought to play a key role in human reasoning, planning, and prediction, yet the demands of simulation in complex environments exceed realistic human capacity limits. A theory with growing evidence is that people simulate using simplified representations of the environment that abstract away from irrelevant details, but it is unclear how people determine these simplifications efficiently. Here, we present a \"Just-in-Time\" framework for simulation-based reasoning that demonstrates how such representations can be constructed online with minimal added computation. The model uses a tight interleaving of simulation, visual search, and representation modification, with the current simulation guiding where to look and visual search flagging objects that should be encoded for subsequent simulation. Despite only ever encoding a small subset of objects, the model makes high-utility predictions. We find strong empirical support for this account over alternative models in a grid-world planning task and a physical reasoning task across a range of behavioral measures. Together, these results offer a concrete algorithmic account of how people construct reduced representations to support efficient mental simulation.", "AI": {"tldr": "本文提出了一个“即时”框架，用于基于模拟的推理，该框架展示了如何在线构建简化表示以最小化额外计算。", "motivation": "虽然概率性心理模拟被认为是人类推理、规划和预测的关键部分，但在复杂环境中进行模拟的需求超出了现实的人类能力限制，因此作者试图探索人们如何有效确定这些简化。", "method": "该模型使用模拟、视觉搜索和表示修改之间的紧密交织，当前的模拟引导视线方向，并且视觉搜索标记出应该为后续模拟编码的对象。", "result": "实验结果在网格世界规划任务和物理推理任务中表明，与替代模型相比，这种“即时”框架获得了强烈的经验支持，并能做出高效益预测。", "conclusion": "研究提供了一个具体的算法账户，解释了人们如何构建减少的表示以支持高效的心理模拟。"}}
{"id": "2601.14492", "pdf": "https://arxiv.org/pdf/2601.14492", "abs": "https://arxiv.org/abs/2601.14492", "authors": ["Malak Mansour", "Ali Abouzeid", "Zezhou Sun", "Qinbo Sun", "Dezhen Song", "Abdalla Swikir"], "title": "UNCLE-Grasp: Uncertainty-Aware Grasping of Leaf-Occluded Strawberries", "categories": ["cs.RO"], "comment": null, "summary": "Robotic strawberry harvesting is challenging under partial occlusion, where leaves induce significant geometric uncertainty and make grasp decisions based on a single deterministic shape estimate unreliable. From a single partial observation, multiple incompatible 3D completions may be plausible, causing grasps that appear feasible on one completion to fail on another. We propose an uncertainty-aware grasping pipeline for partially occluded strawberries that explicitly models completion uncertainty arising from both occlusion and learned shape reconstruction. Our approach uses point cloud completion with Monte Carlo dropout to sample multiple shape hypotheses, generates candidate grasps for each completion, and evaluates grasp feasibility using physically grounded force-closure-based metrics. Rather than selecting a grasp based on a single estimate, we aggregate feasibility across completions and apply a conservative lower confidence bound (LCB) criterion to decide whether a grasp should be attempted or safely abstained. We evaluate the proposed method in simulation and on a physical robot across increasing levels of synthetic and real leaf occlusion. Results show that uncertainty-aware decision making enables reliable abstention from high-risk grasp attempts under severe occlusion while maintaining robust grasp execution when geometric confidence is sufficient, outperforming deterministic baselines in both simulated and physical robot experiments.", "AI": {"tldr": "该论文提出了一种针对部分被叶子遮挡的草莓进行不确定性感知抓取的方法。", "motivation": "机器人采摘草莓在遇到部分遮挡的情况下会变得非常具有挑战性，因为叶子会导致几何不确定性的增加，使基于单一确定形状估计的抓取决策变得不可靠。", "method": "该方法采用点云补全结合蒙特卡罗丢弃法来采样多个形状假设，并为每个完成生成候选抓取姿势。通过物理基础的力闭合度量评估抓取可行性，并使用保守的下置信界（LCB）准则来决定是否尝试抓取。", "result": "实验结果显示，不确定性感知决策在严重遮挡的情况下能够可靠地避免高风险的抓取尝试，并且当几何信心足够时，仍能维持稳健的抓取执行，优于确定性基线方法。", "conclusion": "该研究证明了在部分被叶子遮挡的条件下进行草莓采摘时，通过不确定性感知的方法可以显著提高机器人抓取的成功率和可靠性。"}}
{"id": "2601.14490", "pdf": "https://arxiv.org/pdf/2601.14490", "abs": "https://arxiv.org/abs/2601.14490", "authors": ["Hunter Heidenreich", "Ben Elliott", "Olivia Dinica", "Yosheb Getachew"], "title": "GutenOCR: A Grounded Vision-Language Front-End for Documents", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "GutenOCR is a family of grounded OCR front-ends obtained by fine-tuning Qwen2.5-VL-3B and Qwen2.5-VL-7B. The resulting single-checkpoint vision-language models expose reading, detection, and grounding through a unified, prompt-based interface. Trained on business documents, scientific articles, and synthetic grounding data, the models support full-page and localized reading with line- and paragraph-level bounding boxes and conditional ``where is x?'' queries. We introduce a grounded OCR evaluation protocol and show that GutenOCR-7B more than doubles the composite grounded OCR score of its Qwen2.5-VL-7B backbone on 10.5K held-out business and scientific pages (0.40 to 0.82). On Fox and OmniDocBench v1.5, our approach substantially improves region- and line-level OCR as well as text-detection recall, but reveals trade-offs in page-level linearization, color-guided OCR, and formula-heavy layouts.", "AI": {"tldr": "本论文介绍了一种名为GutenOCR的基于视觉语言模型的光学字符识别前端，该系统在商业文档和科学文章上进行了训练，并展示了显著的改进。", "motivation": "研究动机是开发一种能够提供阅读、检测和定位功能的统一界面的光学字符识别（OCR）系统。这种系统需要支持全页和局部读取，以及条件查询。", "method": "GutenOCR是通过微调Qwen2.5-VL-3B和Qwen2.5-VL-7B模型获得的一组基于视觉语言的OCR前端。训练数据包括商业文档、科学文章和合成定位数据。", "result": "在10.5K张未见过的商业和科学页面上，GutenOCR-7B将基线Qwen2.5-VL-7B的综合接地OCR得分从0.40提高到了0.82。在Fox和OmniDocBench v1.5数据集上的测试表明，该方法在区域级别和行级别的OCR以及文本检测召回率上均有显著提升。", "conclusion": "GutenOCR展示了通过微调视觉语言模型以改进光学字符识别性能的有效性，并且提出了一个新的接地OCR评估协议。尽管有所改善，但在页面级线性化、色彩导向的OCR及公式密集布局方面仍存在权衡。"}}
{"id": "2601.14485", "pdf": "https://arxiv.org/pdf/2601.14485", "abs": "https://arxiv.org/abs/2601.14485", "authors": ["Yuan Tian", "Yi Mei", "Mengjie Zhang"], "title": "Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling", "categories": ["cs.AI"], "comment": "17 pages, 9 figures. This paper has been accepted by the Pacific Rim International Conference Series on Artificial Intelligence (PRICAI) 2025 but not published yet. This is the submission to review version, not the camera-ready version", "summary": "The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios.", "AI": {"tldr": "提出了一种可扩展的膝点指导活动组选择方法，用于多树遗传编程中动态多模式项目调度问题。", "motivation": "为了解决现有活动组选择策略在大规模实例中的可扩展性问题，并提高项目的调度效率。", "method": "通过引入膝点选择机制来识别有希望的活动子集，同时使用多树遗传编程框架进化排序规则和组合规则。", "result": "实验结果显示该方法在大型实例中具有良好的可扩展性和更高的性能表现。", "conclusion": "提出的膝点指导活动组选择方法显著提升了大规模动态多模式项目调度问题中的调度效率。"}}
{"id": "2601.14477", "pdf": "https://arxiv.org/pdf/2601.14477", "abs": "https://arxiv.org/abs/2601.14477", "authors": ["Frank Bieder", "Hendrik Königshof", "Haohao Hu", "Fabian Immel", "Yinzhe Shen", "Jan-Hendrik Pauls", "Christoph Stiller"], "title": "XD-MAP: Cross-Modal Domain Adaptation using Semantic Parametric Mapping", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Until open-world foundation models match the performance of specialized approaches, the effectiveness of deep learning models remains heavily dependent on dataset availability. Training data must align not only with the target object categories but also with the sensor characteristics and modalities. To bridge the gap between available datasets and deployment domains, domain adaptation strategies are widely used. In this work, we propose a novel approach to transferring sensor-specific knowledge from an image dataset to LiDAR, an entirely different sensing domain. Our method XD-MAP leverages detections from a neural network on camera images to create a semantic parametric map. The map elements are modeled to produce pseudo labels in the target domain without any manual annotation effort. Unlike previous domain transfer approaches, our method does not require direct overlap between sensors and enables extending the angular perception range from a front-view camera to a full 360 view. On our large-scale road feature dataset, XD-MAP outperforms single shot baseline approaches by +19.5 mIoU for 2D semantic segmentation, +19.5 PQth for 2D panoptic segmentation, and +32.3 mIoU in 3D semantic segmentation. The results demonstrate the effectiveness of our approach achieving strong performance on LiDAR data without any manual labeling.", "AI": {"tldr": "提出了一种使用语义参数化映射的跨模态领域适应方法 XD-MAP，用于在不同传感器模式之间转移知识。", "motivation": "由于深度学习模型的效果高度依赖于数据集的可用性，该研究旨在通过领域适应策略缩小现有数据集与部署域之间的差距，特别是解决图像数据和LiDAR数据之间的知识迁移问题。", "method": "XD-MAP方法利用神经网络在相机图像上的检测结果创建语义参数化地图，以产生目标领域的伪标签，并且不需要传感器之间直接重叠。", "result": "在大规模道路特征数据集上，XD-MAP相比单次基线方法分别提升了2D语义分割的+19.5 mIoU、2D全景分割的+19.5 PQth和3D语义分割的+32.3 mIoU。", "conclusion": "研究结果表明该方法在不需任何手动标注的情况下实现了LiDAR数据上的强劲性能。"}}
{"id": "2601.14476", "pdf": "https://arxiv.org/pdf/2601.14476", "abs": "https://arxiv.org/abs/2601.14476", "authors": ["Naoya Onizawa", "Takahiro Hanyu"], "title": "GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages", "summary": "Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -timing, intensity, and offset- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields.", "AI": {"tldr": "介绍了一种基于p位的GPU加速模拟退火框架，该框架通过建模设备变化来提高性能。", "motivation": "探索使用具有设备变化性的新兴设备实现概率计算的可能性，并展示其对算法性能的影响。", "method": "开发了一个基于CUDA的、开放源码的、GPU加速的模拟退火框架，以建模和反映实际设备的时序、强度和偏移变化性。", "result": "在MAX-CUT基准测试中，与CPU实现相比，该方法实现了两个数量级的速度提升，问题规模从800到20,000个节点不等。", "conclusion": "此框架提供了可扩展且易于访问的工具，以推动概率计算的研究，并支持多样化领域的优化应用。"}}
{"id": "2601.14475", "pdf": "https://arxiv.org/pdf/2601.14475", "abs": "https://arxiv.org/abs/2601.14475", "authors": ["Yajvan Ravan", "Aref Malek", "Chester Dolph", "Nikhil Behari"], "title": "Real-Time Wildfire Localization on the NASA Autonomous Modular Sensor using Deep Learning", "categories": ["cs.CV", "cs.AI"], "comment": "16 pages, 9 figures, published at AIAA SciTech 2026", "summary": "High-altitude, multi-spectral, aerial imagery is scarce and expensive to acquire, yet it is necessary for algorithmic advances and application of machine learning models to high-impact problems such as wildfire detection. We introduce a human-annotated dataset from the NASA Autonomous Modular Sensor (AMS) using 12-channel, medium to high altitude (3 - 50 km) aerial wildfire images similar to those used in current US wildfire missions. Our dataset combines spectral data from 12 different channels, including infrared (IR), short-wave IR (SWIR), and thermal. We take imagery from 20 wildfire missions and randomly sample small patches to generate over 4000 images with high variability, including occlusions by smoke/clouds, easily-confused false positives, and nighttime imagery. We demonstrate results from a deep-learning model to automate the human-intensive process of fire perimeter determination. We train two deep neural networks, one for image classification and the other for pixel-level segmentation. The networks are combined into a unique real-time segmentation model to efficiently localize active wildfire on an incoming image feed. Our model achieves 96% classification accuracy, 74% Intersection-over-Union(IoU), and 84% recall surpassing past methods, including models trained on satellite data and classical color-rule algorithms. By leveraging a multi-spectral dataset, our model is able to detect active wildfire at nighttime and behind clouds, while distinguishing between false positives. We find that data from the SWIR, IR, and thermal bands is the most important to distinguish fire perimeters. Our code and dataset can be found here: https://github.com/nasa/Autonomous-Modular-Sensor-Wildfire-Segmentation/tree/main and https://drive.google.com/drive/folders/1-u4vs9rqwkwgdeeeoUhftCxrfe_4QPTn?=usp=drive_link", "AI": {"tldr": "本论文介绍了一种使用深度学习在NASA自主模块化传感器上实现实时野火定位的方法。", "motivation": "高海拔、多光谱的空中图像获取稀缺且昂贵，但对算法进展及机器学习模型应用于如野火检测等重要问题至关重要。因此，本文旨在开发一种能够有效识别和定位野火的人工智能方法。", "method": "研究使用了NASA自主模块化传感器收集的12通道、中高海拔（3-50公里）空中火灾图像数据集，包括红外线、短波红外线和热成像。训练了两个深度神经网络：一个是用于图像分类，另一个是用于像素级分割，以自动化人工密集型的火围确定过程。", "result": "该模型实现了96%的分类精度、74%的交并比（IoU）以及84%的召回率，超越了之前的方法，包括基于卫星数据训练的模型和经典色彩规则算法。此外，通过多光谱数据集的应用，模型能够在夜间及云层后方检测到活跃野火，并区分假阳性。", "conclusion": "研究结果表明，深度学习方法能有效实现高海拔、多光谱图像中的实时野火定位，尤其在利用SWIR、红外线和热成像波段的数据时表现最为突出。"}}
{"id": "2601.14472", "pdf": "https://arxiv.org/pdf/2601.14472", "abs": "https://arxiv.org/abs/2601.14472", "authors": ["Mohammed Salah Al-Radhi", "Riad Larbi", "Mátyás Bartalis", "Géza Németh"], "title": "Prosody-Guided Harmonic Attention for Phase-Coherent Neural Vocoding in the Complex Spectrum", "categories": ["cs.SD", "cs.AI", "cs.CL"], "comment": "5 pages, 2 figures, 1 table. Accepted for presentation at ICASSP 2026", "summary": "Neural vocoders are central to speech synthesis; despite their success, most still suffer from limited prosody modeling and inaccurate phase reconstruction. We propose a vocoder that introduces prosody-guided harmonic attention to enhance voiced segment encoding and directly predicts complex spectral components for waveform synthesis via inverse STFT. Unlike mel-spectrogram-based approaches, our design jointly models magnitude and phase, ensuring phase coherence and improved pitch fidelity. To further align with perceptual quality, we adopt a multi-objective training strategy that integrates adversarial, spectral, and phase-aware losses. Experiments on benchmark datasets demonstrate consistent gains over HiFi-GAN and AutoVocoder: F0 RMSE reduced by 22 percent, voiced/unvoiced error lowered by 18 percent, and MOS scores improved by 0.15. These results show that prosody-guided attention combined with direct complex spectrum modeling yields more natural, pitch-accurate, and robust synthetic speech, setting a strong foundation for expressive neural vocoding.", "AI": {"tldr": "本文提出了一种基于Prosody-Guided Harmonic Attention的神经声码器，以改善语音合成中的音调建模和相位重建。", "motivation": "尽管现有的神经声码器在语音合成中取得了成功，但仍存在对音调建模不足和相位重建不准确的问题。本文旨在解决这些问题，从而提高合成语音的质量。", "method": "该方法引入了Prosody-Guided Harmonic Attention来增强有声音段的编码，并直接预测复杂频谱组件以进行波形合成。通过采用多目标训练策略，整合对抗、光谱和相位感知损失，确保了相位一致性并提升了音调保真度。", "result": "实验表明，该方法在F0 RMSE、有声/无声错误率以及MOS评分上均优于HiFi-GAN和AutoVocoder，分别降低了22%、18%，并提高了0.15。", "conclusion": "结果证明，基于Prosody-Guided Attention结合直接复杂频谱建模的合成语音更加自然，音调准确且更稳健。这为表达性神经声码器奠定了坚实的基础。"}}
{"id": "2601.14470", "pdf": "https://arxiv.org/pdf/2601.14470", "abs": "https://arxiv.org/abs/2601.14470", "authors": ["Mohamad Salim", "Jasmine Latendresse", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Tokenomics: Quantifying Where Tokens Are Used in Agentic Software Engineering", "categories": ["cs.SE", "cs.AI", "cs.MA"], "comment": null, "summary": "LLM-based Multi-Agent (LLM-MA) systems are increasingly applied to automate complex software engineering tasks such as requirements engineering, code generation, and testing. However, their operational efficiency and resource consumption remain poorly understood, hindering practical adoption due to unpredictable costs and environmental impact. To address this, we conduct an analysis of token consumption patterns in an LLM-MA system within the Software Development Life Cycle (SDLC), aiming to understand where tokens are consumed across distinct software engineering activities. We analyze execution traces from 30 software development tasks performed by the ChatDev framework using a GPT-5 reasoning model, mapping its internal phases to distinct development stages (Design, Coding, Code Completion, Code Review, Testing, and Documentation) to create a standardized evaluation framework. We then quantify and compare token distribution (input, output, reasoning) across these stages. Our preliminary findings show that the iterative Code Review stage accounts for the majority of token consumption for an average of 59.4% of tokens. Furthermore, we observe that input tokens consistently constitute the largest share of consumption for an average of 53.9%, providing empirical evidence for potentially significant inefficiencies in agentic collaboration. Our results suggest that the primary cost of agentic software engineering lies not in initial code generation but in automated refinement and verification. Our novel methodology can help practitioners predict expenses and optimize workflows, and it directs future research toward developing more token-efficient agent collaboration protocols.", "AI": {"tldr": "本文研究了基于LLM的多代理系统在软件工程不同阶段的令牌消耗模式，以优化资源使用和成本预测。", "motivation": "由于对基于LLM的多代理系统的操作效率和资源消耗理解不足，导致其实际应用受限。因此，文章旨在量化这些系统在软件开发生命周期中的令牌使用情况，以减少不可预测的成本和环境影响。", "method": "通过分析ChatDev框架执行30个软件开发任务时产生的执行追踪数据，将内部阶段映射到不同的开发阶段（设计、编码、代码完成、代码审查、测试和文档），并量化这些阶段的令牌分布情况。", "result": "初步结果显示，迭代的代码审查阶段消耗了最多的令牌，平均占59.4%，而输入令牌构成最大的消费部分，平均为53.9%。这表明主要成本在于自动优化和验证而非初始编码。", "conclusion": "本文提出的方法能够帮助实践者预测费用并优化工作流程，并指引未来研究开发更高效的代理协作协议。"}}
{"id": "2601.14456", "pdf": "https://arxiv.org/pdf/2601.14456", "abs": "https://arxiv.org/abs/2601.14456", "authors": ["Valerio Belcamino", "Nicholas Attolino", "Alessio Capitanelli", "Fulvio Mastrogiovanni"], "title": "On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL", "categories": ["cs.AI", "cs.LG"], "comment": "9 pages, 4 figures, 3 tables, 2 pages of supplementary materials. Submitted to a conference implementing a double-blind review process", "summary": "Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work, we fine-tune a 1.7B-parameter LLM on 40,000 domain-problem-plan tuples from 10 IPC 2023 domains, and evaluate both in-domain and cross-domain generalization. While the model reaches 82.9% valid plan rate in in-domain conditions, it achieves 0% on two unseen domains. To analyze this failure, we introduce three diagnostic interventions, namely (i) instance-wise symbol anonymization, (ii) compact plan serialization, and (iii) verifier-reward fine-tuning using the VAL validator as a success-focused reinforcement signal. Symbol anonymization and compact serialization cause significant performance drops despite preserving plan semantics, thus revealing strong sensitivity to surface representations. Verifier-reward fine-tuning reaches performance saturation in half the supervised training epochs, but does not improve cross-domain generalization. For the explored configurations, in-domain performance plateaus around 80%, while cross-domain performance collapses, suggesting that our fine-tuned model relies heavily on domain-specific patterns rather than transferable planning competence in this setting. Our results highlight a persistent generalization gap in LLM-based planning and provide diagnostic tools for studying its causes.", "AI": {"tldr": "研究了大型语言模型在PDDL规划任务中的泛化差距，特别是在跨域任务上的表现。", "motivation": "尽管已有研究表明微调后的大型语言模型可以在PDDL规划任务中实现很高的有效计划率，但这些结果是否反映了可迁移的规划能力还是特定领域的记忆尚不清楚。本研究旨在探讨这一问题。", "method": "对一个1.7B参数的语言模型进行了微调，使用了来自10个IPC2023域中的4万个领域-问题-计划元组，并评估其在域内和跨域任务上的泛化能力。引入了三种诊断干预措施：实例级符号匿名化、紧凑型计划序列化以及基于VAL验证器的奖励微调。", "result": "模型在域内条件下的有效计划率达到82.9%，但在两个未见过的领域中则达到0%。通过诊断工具发现，表面表示形式对性能有显著影响。尽管基于验证器的奖励微调可以在一半的监督训练周期内实现性能饱和，但并未改善跨域泛化。", "conclusion": "研究结果表明，在当前设置下，经过微调的语言模型在很大程度上依赖于特定领域的模式而非可迁移的规划能力，揭示了一个持久存在的大型语言模型在基于规划任务中的泛化差距。"}}
{"id": "2601.14448", "pdf": "https://arxiv.org/pdf/2601.14448", "abs": "https://arxiv.org/abs/2601.14448", "authors": ["A. Enes Doruk"], "title": "Gaussian Based Adaptive Multi-Modal 3D Semantic Occupancy Prediction", "categories": ["cs.CV"], "comment": "Master Thesis", "summary": "The sparse object detection paradigm shift towards dense 3D semantic occupancy prediction is necessary for dealing with long-tail safety challenges for autonomous vehicles. Nonetheless, the current voxelization methods commonly suffer from excessive computation complexity demands, where the fusion process is brittle, static, and breaks down under dynamic environmental settings. To this end, this research work enhances a novel Gaussian-based adaptive camera-LiDAR multimodal 3D occupancy prediction model that seamlessly bridges the semantic strengths of camera modality with the geometric strengths of LiDAR modality through a memory-efficient 3D Gaussian model. The proposed solution has four key components: (1) LiDAR Depth Feature Aggregation (LDFA), where depth-wise deformable sampling is employed for dealing with geometric sparsity, (2) Entropy-Based Feature Smoothing, where cross-entropy is employed for handling domain-specific noise, (3) Adaptive Camera-LiDAR Fusion, where dynamic recalibration of sensor outputs is performed based on model outputs, and (4) Gauss-Mamba Head that uses Selective State Space Models for global context decoding that enjoys linear computation complexity.", "AI": {"tldr": "本文提出了基于高斯模型的自适应多模态3D语义占用预测，以提高自动驾驶车辆在动态环境下的安全性能。", "motivation": "当前稀疏对象检测向密集3D语义占用预测转变是应对自动驾驶长期的安全挑战所必需的。然而，现有的体素化方法普遍存在计算复杂度高且融合过程脆弱的问题。为了解决这些问题，本文提出了一个基于高斯模型的自适应多模态3D占用预测模型。", "method": "该研究提出的方法包括四个关键部分：LiDAR深度特征聚合（LDFA）、熵基特征平滑、自适应相机-LiDAR融合以及Gauss-Mamba头部。通过这些组成部分，实现了高效的语义和几何信息的结合。", "result": "本文提出的基于高斯模型的多模态3D占用预测方法能够有效地处理动态环境下的几何稀疏问题，并且具有线性的计算复杂度，显著提高了自动驾驶车辆的安全性。", "conclusion": "研究证明了通过融合相机和LiDAR的优势并使用高效的3D高斯模型进行自适应多模态3D语义占用预测是提高自动驾驶汽车在动态环境中安全性能的有效方法。"}}
{"id": "2601.14446", "pdf": "https://arxiv.org/pdf/2601.14446", "abs": "https://arxiv.org/abs/2601.14446", "authors": ["Ye Yuan", "Can", "Chen", "Zipeng Sun", "Dinghuai Zhang", "Christopher Pal", "Xue Liu"], "title": "Diffusion Large Language Models for Black-Box Optimization", "categories": ["cs.CE", "cs.AI"], "comment": null, "summary": "Offline black-box optimization (BBO) aims to find optimal designs based solely on an offline dataset of designs and their labels. Such scenarios frequently arise in domains like DNA sequence design and robotics, where only a few labeled data points are available. Traditional methods typically rely on task-specific proxy or generative models, overlooking the in-context learning capabilities of pre-trained large language models (LLMs). Recent efforts have adapted autoregressive LLMs to BBO by framing task descriptions and offline datasets as natural language prompts, enabling direct design generation. However, these designs often contain bidirectional dependencies, which left-to-right models struggle to capture. In this paper, we explore diffusion LLMs for BBO, leveraging their bidirectional modeling and iterative refinement capabilities. This motivates our in-context denoising module: we condition the diffusion LLM on the task description and the offline dataset, both formatted in natural language, and prompt it to denoise masked designs into improved candidates. To guide the generation toward high-performing designs, we introduce masked diffusion tree search, which casts the denoising process as a step-wise Monte Carlo Tree Search that dynamically balances exploration and exploitation. Each node represents a partially masked design, each denoising step is an action, and candidates are evaluated via expected improvement under a Gaussian Process trained on the offline dataset. Our method, dLLM, achieves state-of-the-art results in few-shot settings on design-bench.", "AI": {"tldr": "本文探讨了使用扩散大语言模型（dLLM）进行离线黑盒优化，通过自然语言提示任务描述和数据集，结合掩码扩散树搜索来生成更优的设计方案。", "motivation": "传统方法依赖特定的代理或生成模型，忽视了预训练大型语言模型的上下文学习能力。现有的自回归语言模型在处理双向依赖关系时表现不佳，因此本文尝试利用扩散大语言模型解决离线黑盒优化问题。", "method": "提出了一种基于扩散大语言模型的方法（dLLM），通过掩码降噪模块和掩码扩散树搜索来迭代生成和优化设计。任务描述和数据集以自然语言的形式输入，指导生成过程向高绩效设计方案倾斜。", "result": "该方法在少样本场景下的设计基准测试中取得了最先进的结果。", "conclusion": "利用扩散大语言模型进行离线黑盒优化的方法有效克服了自回归模型的局限性，并通过实验验证了其优越性能。"}}
{"id": "2601.14445", "pdf": "https://arxiv.org/pdf/2601.14445", "abs": "https://arxiv.org/abs/2601.14445", "authors": ["Aiden Mazidi", "Majid Roshanfar", "Amir Sayadi", "Javad Dargahi", "Jake Barralet", "Liane S. Feldman", "Amir Hooshiar"], "title": "Robust Haptic Rendering Using a Nonlinear Impedance Matching Approach (NIMA) for Robotic Laparoscopic Surgery", "categories": ["cs.RO"], "comment": null, "summary": "Background: The integration of haptic feedback into robot-assisted minimally invasive surgery (RAMIS) has long been limited by challenges in accurately rendering forces and ensuring system safety. The need for robust, high-fidelity haptic systems is critical for enhancing the precision and reliability of teleoperated surgical tools. Methods: In this study, we present a Nonlinear Impedance Matching Approach (NIMA) designed to improve force rendering by accurately modelling complex tool-tissue interactions. Based on our previously validated Impedance Matching Approach (IMA), our novel NIMA method includes nonlinear dynamics to capture and render tool-tissue forces effectively. Results: NIMA improves force feedback accuracy with a mean absolute error (MAE) of 0.01 (SD 0.02) N, achieving a 95% reduction in MAE compared to IMA. Furthermore, NIMA effectively eliminates haptic \"kickback\" by ensuring no force is applied by the haptic device to the user's hand when they release the handle, enhancing both patient safety and user comfort. Conclusion: NIMA's ability to account for nonlinearities in tool-tissue interactions provides an improvement in force fidelity, responsiveness, and precision across various surgical conditions. Our findings promote the advancement of haptic feedback systems for robotic surgery, offering a realistic and reliable interface for robot-assisted surgical procedures.", "AI": {"tldr": "本文提出了一种非线性阻抗匹配方法（NIMA），以提高机器人辅助腹腔镜手术中的力反馈准确性。", "motivation": "长期以来，将触觉反馈集成到机器人辅助微创手术中一直受到准确渲染力和确保系统安全的挑战。因此，需要开发稳健且高保真的触觉系统来增强遥操作外科工具的精度和可靠性。", "method": "本文提出了一种非线性阻抗匹配方法（NIMA），基于先前验证的阻抗匹配方法（IMA），该新方法包括捕捉并渲染工具-组织力的非线性动态。", "result": "与IMA相比，NIMA将平均绝对误差（MAE）降低了95%，达到0.01牛顿，并且有效消除了触觉“反弹”，提高了患者安全性和用户舒适度。", "conclusion": "NIMA能够考虑工具-组织交互中的非线性特征，在各种手术条件下提供更好的力反馈保真度、响应性和精度，推动了机器人外科手术中触觉反馈系统的进步。"}}
{"id": "2601.14440", "pdf": "https://arxiv.org/pdf/2601.14440", "abs": "https://arxiv.org/abs/2601.14440", "authors": ["Saeed Khaki", "Ashudeep Singh", "Nima Safaei", "Kamal Ginotra"], "title": "VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields markedly higher accuracy than its visually typeset counterpart, due to compounded failures in reading dense formulas, layout, and mixed symbolic-diagrammatic context. First, we introduce VisTIRA (Vision and Tool-Integrated Reasoning Agent), a tool-integrated reasoning framework that enables structured problem solving by iteratively decomposing a given math problem (as an image) into natural language rationales and executable Python steps to determine the final answer. Second, we build a framework to measure and improve visual math reasoning: a LaTeX-based pipeline that converts chain-of-thought math corpora (e.g., NuminaMath) into challenging image counterparts, and a large set of synthetic tool-use trajectories derived from a real-world, homework-style image dataset (called SnapAsk) for fine-tuning VLMs. Our experiments show that tool-integrated supervision improves image-based reasoning, and OCR grounding can further narrow the gap for smaller models, although its benefit diminishes at scale. These findings highlight that modality gap severity inversely correlates with model size, and that structured reasoning and OCR-based grounding are complementary strategies for advancing visual mathematical reasoning.", "AI": {"tldr": "本文提出了VisTIRA框架，通过结构化工具整合来解决视觉数学问题，并展示了如何通过合成工具使用轨迹和OCR技术提升模型在图像基础的数学推理上的表现。", "motivation": "论文动机在于解决现有的视觉语言模型（VLMs）在处理以图片形式呈现的数学问题时准确率低于文本形式的问题，即所谓的模态差距。", "method": "VisTIRA框架通过迭代地将给定的数学问题（作为图像）分解为自然语言推理步骤和可执行的Python代码来确定最终答案，并建立一个基于LaTeX的流水线将链式思维数学语料库转换成具有挑战性的图像版本，同时使用大量从真实世界家庭作业样式的图片数据集中合成的工具使用轨迹进行微调。", "result": "实验表明工具整合监督提升了基于图像的推理表现，OCR定位可以进一步缩小小模型的表现差距，但其效益在大规模下减弱。", "conclusion": "研究结论指出模态差距严重程度与模型大小呈反比关系，并且结构化推理和基于OCR的定位是推进视觉数学推理的有效互补策略。"}}
{"id": "2601.14438", "pdf": "https://arxiv.org/pdf/2601.14438", "abs": "https://arxiv.org/abs/2601.14438", "authors": ["Danial Sadrian Zadeh", "Otman A. Basir", "Behzad Moshiri"], "title": "Vision-Based Natural Language Scene Understanding for Autonomous Driving: An Extended Dataset and a New Model for Traffic Scene Description Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Under review at Computer Vision and Image Understanding (submitted July 25, 2025)", "summary": "Traffic scene understanding is essential for enabling autonomous vehicles to accurately perceive and interpret their environment, thereby ensuring safe navigation. This paper presents a novel framework that transforms a single frontal-view camera image into a concise natural language description, effectively capturing spatial layouts, semantic relationships, and driving-relevant cues. The proposed model leverages a hybrid attention mechanism to enhance spatial and semantic feature extraction and integrates these features to generate contextually rich and detailed scene descriptions. To address the limited availability of specialized datasets in this domain, a new dataset derived from the BDD100K dataset has been developed, with comprehensive guidelines provided for its construction. Furthermore, the study offers an in-depth discussion of relevant evaluation metrics, identifying the most appropriate measures for this task. Extensive quantitative evaluations using metrics such as CIDEr and SPICE, complemented by human judgment assessments, demonstrate that the proposed model achieves strong performance and effectively fulfills its intended objectives on the newly developed dataset.", "AI": {"tldr": "本文提出了一种新的框架，将单个前视相机图像转换为简洁的自然语言描述，以捕捉空间布局、语义关系和驾驶相关线索。", "motivation": "交通场景理解对于自动驾驶车辆准确感知和解释其环境至关重要，确保安全导航是本文的研究动机。", "method": "该模型采用混合注意力机制来增强空间和语义特征提取，并将这些特征集成以生成上下文丰富且详细的场景描述。同时开发了一个新的数据集并提供了构建指南。", "result": "通过使用CIDEr和SPICE等度量标准进行的广泛定量评估以及人类判断评估，证明了所提出的模型在新开发的数据集上实现了强大的性能并有效完成了其目标。", "conclusion": "研究结论是所提出的方法能够准确地将图像转换为自然语言描述，并且在自动驾驶场景理解方面展示了良好的性能和潜力。"}}
{"id": "2601.14437", "pdf": "https://arxiv.org/pdf/2601.14437", "abs": "https://arxiv.org/abs/2601.14437", "authors": ["Thuan Minh Nguyen", "Vu Tuan Truong", "Long Bao Le"], "title": "Agentic AI Meets Edge Computing in Autonomous UAV Swarms", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "The integration of agentic AI, powered by large language models (LLMs) with autonomous reasoning, planning, and execution, into unmanned aerial vehicle (UAV) swarms opens new operational possibilities and brings the vision of the Internet of Drones closer to reality. However, infrastructure constraints, dynamic environments, and the computational demands of multi-agent coordination limit real-world deployment in high-risk scenarios such as wildfires and disaster response. This paper investigates the integration of LLM-based agentic AI and edge computing to realize scalable and resilient autonomy in UAV swarms. We first discuss three architectures for supporting UAV swarms - standalone, edge-enabled, and edge-cloud hybrid deployment - each optimized for varying autonomy and connectivity levels. Then, a use case for wildfire search and rescue (SAR) is designed to demonstrate the efficiency of the edge-enabled architecture, enabling high SAR coverage, reduced mission completion times, and a higher level of autonomy compared to traditional approaches. Finally, we highlight open challenges in integrating LLMs and edge computing for mission-critical UAV-swarm applications.", "AI": {"tldr": "本文探讨了将基于大语言模型的代理AI与边缘计算集成到无人机群中，以实现可扩展和有弹性的自主性。", "motivation": "旨在通过解决基础设施限制、动态环境适应以及多智能体协调中的计算需求问题，推动无人驾驶飞机在高风险场景（如野火和灾难响应）中的实际应用。", "method": "本文讨论了三种支持无人机群的架构：独立型、边缘增强型和边缘云混合部署，并设计了一个用于野火搜救的应用案例来展示边缘增强型架构的有效性。", "result": "展示了边缘增强型架构在提高搜救覆盖面、减少任务完成时间以及实现更高自主水平方面的效率。", "conclusion": "强调了将大语言模型与边缘计算集成到关键任务无人机群应用中仍面临的开放挑战。"}}
{"id": "2601.14436", "pdf": "https://arxiv.org/pdf/2601.14436", "abs": "https://arxiv.org/abs/2601.14436", "authors": ["Maria Garcia", "Natalia Lopez", "Ismael Rodriguez"], "title": "A full process algebraic representation of Ant Colony Optimization", "categories": ["cs.NE"], "comment": "This paper was published in Information Sciences. The present version is the author's accepted manuscript", "summary": "We present a process algebra capable of specifying parallelized Ant Colony Optimization algorithms in full detail: PA$^2$CO. After explaining the basis of three different ACO algorithms (Ant System, MAX-MIN Ant System, and Ant Colony System), we formally define PA$^2$CO and use it for representing several types of implementations with different parallel schemes. In particular fine-grained and coarse-grained specifications, each one taking advantage of parallel executions at different levels of system granularity, are formalized.", "AI": {"tldr": "本文介绍了PA$^2$CO，一种能够详细描述并行蚂蚁群优化算法的过程代数。", "motivation": "动机在于提供一种方法来形式化和详细说明不同类型的并行蚂蚁群优化算法实现及其在系统粒度级别上的执行方式。", "method": "论文解释了三种不同的ACO算法的基础，并正式定义了PA$^2$CO，使用它来表示具有不同并行方案的多种类型实施。", "result": "成功地形式化了细粒度和粗粒度的规格说明，利用了系统在不同层次上的并行执行优势。", "conclusion": "PA$^2$CO能够详细、正式地描述并行蚂蚁群优化算法的各种实现方式。"}}
{"id": "2601.14435", "pdf": "https://arxiv.org/pdf/2601.14435", "abs": "https://arxiv.org/abs/2601.14435", "authors": ["C. Estelle Smith", "Alemitu Bezabih", "Shadi Nourriz", "Jesan Ahammed Ovi"], "title": "SPIRIT: A Design Framework To Support Technology Interventions for Spiritual Care Within and Beyond the Clinic", "categories": ["cs.HC"], "comment": null, "summary": "Despite its importance for well-being, spiritual care remains under-explored in HCI, while the adoption of technology in clinical spiritual care lags behind other healthcare fields. Prior work derived a definition of \"spiritual support\" through co-design workshops with stakeholders in online health communities. This paper contributes: (1) a revision of that definition through member checking with professional spiritual care providers (SCPs); (2) a novel design framework -- SPIRIT -- which can help to expand models of delivery for spiritual care using digital technologies. Through re-analysis of previous data and new interviews with SCPs, we identify three prerequisites for meaningful spiritual care: openness to care, safe space, and the ability to discern and articulate spiritual needs. We also propose six design dimensions: loving presence, meaning-making, appropriate degree of technology use, location, degree of relational closeness, and temporality. We discuss how SPIRIT offers guidance for designing impactful digital spiritual care intervention systems within and beyond clinical settings.", "AI": {"tldr": "本文提出了一个名为SPIRIT的设计框架，旨在利用数字技术扩展精神护理的交付模式。", "motivation": "尽管精神关怀对健康的重要性不言而喻，但在人机交互（HCI）领域中仍鲜有探索。在临床精神关怀中采用技术的应用也远远落后于其他医疗领域。", "method": "通过之前的资料重新分析和与专业精神护理提供者的新访谈，本文修订了“精神支持”的定义，并确定了有意义的精神关怀的三个先决条件以及六个设计维度。", "result": "本文提出的设计框架SPIRIT有助于指导创建有影响力的精神护理数字干预系统，在临床环境内外都是如此。", "conclusion": "通过专业精神护理提供者的反馈，修订和完善了精神关怀技术应用的设计方法论和框架。"}}
{"id": "2601.14433", "pdf": "https://arxiv.org/pdf/2601.14433", "abs": "https://arxiv.org/abs/2601.14433", "authors": ["Hsin-Yi Lin", "Huan-Hsin Tseng", "Samuel Yen-Chi Chen", "Shinjae Yoo"], "title": "Quantum Super-resolution by Adaptive Non-local Observables", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "Accepted at ICASSP 2026", "summary": "Super-resolution (SR) seeks to reconstruct high-resolution (HR) data from low-resolution (LR) observations. Classical deep learning methods have advanced SR substantially, but require increasingly deeper networks, large datasets, and heavy computation to capture fine-grained correlations. In this work, we present the \\emph{first study} to investigate quantum circuits for SR. We propose a framework based on Variational Quantum Circuits (VQCs) with \\emph{Adaptive Non-Local Observable} (ANO) measurements. Unlike conventional VQCs with fixed Pauli readouts, ANO introduces trainable multi-qubit Hermitian observables, allowing the measurement process to adapt during training. This design leverages the high-dimensional Hilbert space of quantum systems and the representational structure provided by entanglement and superposition. Experiments demonstrate that ANO-VQCs achieve up to five-fold higher resolution with a relatively small model size, suggesting a promising new direction at the intersection of quantum machine learning and super-resolution.", "AI": {"tldr": "本研究介绍了第一个利用量子电路进行超分辨率（SR）的研究，提出了一种基于自适应非局部观测值（ANO）测量的变分量子电路框架。", "motivation": "传统的深度学习方法在处理高分辨率重建任务时需要更深的网络、更大的数据集和更重的计算来捕获细粒度的相关性。研究旨在探索量子机器学习与超分辨率结合的新方向，以更小模型尺寸实现更高的分辨率提升。", "method": "提出一种基于变分量子电路（VQCs）并引入自适应非局部观测值（ANO）测量的方法。不同于传统固定泡利读数的VQCs，ANO允许在训练过程中调整多量子比特Hermitian观测值，利用高维希尔伯特空间和纠缠与叠加提供的表示结构来提升性能。", "result": "实验结果显示ANO-VQC框架能实现高达五倍的分辨率提升，并且模型尺寸相对较小，展示了其在超分辨率任务中的潜力。", "conclusion": "研究表明量子电路结合自适应非局部观测值测量可以在更小模型规模下显著提高超分辨率效果，为量子机器学习与图像处理领域的交叉研究开辟了新方向。"}}
{"id": "2601.14429", "pdf": "https://arxiv.org/pdf/2601.14429", "abs": "https://arxiv.org/abs/2601.14429", "authors": ["Junyi Ji", "Ruth Lu", "Linda Belkessa", "Liming Wang", "Silvia Varotto", "Yongqi Dong", "Nicolas Saunier", "Mostafa Ameli", "Gregory S. Macfarlane", "Bahman Madadi", "Cathy Wu"], "title": "Measuring the State of Open Science in Transportation Using Large Language Models", "categories": ["cs.DL", "cs.AI", "cs.CY", "cs.ET"], "comment": null, "summary": "Open science initiatives have strengthened scientific integrity and accelerated research progress across many fields, but the state of their practice within transportation research remains under-investigated. Key features of open science, defined here as data and code availability, are difficult to extract due to the inherent complexity of the field. Previous work has either been limited to small-scale studies due to the labor-intensive nature of manual analysis or has relied on large-scale bibliometric approaches that sacrifice contextual richness. This paper introduces an automatic and scalable feature-extraction pipeline to measure data and code availability in transportation research. We employ Large Language Models (LLMs) for this task and validate their performance against a manually curated dataset and through an inter-rater agreement analysis. We applied this pipeline to examine 10,724 research articles published in the Transportation Research Part series of journals between 2019 and 2024. Our analysis found that only 5% of quantitative papers shared a code repository, 4% of quantitative papers shared a data repository, and about 3% of papers shared both, with trends differing across journals, topics, and geographic regions. We found no significant difference in citation counts or review duration between papers that provided data and code and those that did not, suggesting a misalignment between open science efforts and traditional academic metrics. Consequently, encouraging these practices will likely require structural interventions from journals and funding agencies to supplement the lack of direct author incentives. The pipeline developed in this study can be readily scaled to other journals, representing a critical step toward the automated measurement and monitoring of open science practices in transportation research.", "AI": {"tldr": "使用大型语言模型自动化测量交通研究中的开放科学状态。", "motivation": "虽然开放科学发展增强了科学研究的完整性并加速了跨学科的研究进展，但其在交通研究领域的实践状况尚未得到充分调查。之前的大多数工作要么局限于小规模手动分析，要么依赖于牺牲细节的大规模计量方法。", "method": "采用大型语言模型（LLMs）自动提取和测量10,724篇发表在《交通运输研究部分系列》期刊上的论文中的数据和代码可用性，并通过人工审核的数据集验证了这些模型的表现。", "result": "发现只有5%的定量研究分享了代码仓库，4%分享了数据仓库，3%同时提供了两者。提供或不提供数据和代码的论文在引用次数和审稿时间上无显著差异。", "conclusion": "鼓励开放科学实践可能需要期刊和资助机构进行结构干预以补充作者缺乏直接激励的问题。该研究开发的管道可以扩展到其他期刊，代表了交通研究领域自动测量和监控开放科学做法的关键步骤。"}}
{"id": "2601.14424", "pdf": "https://arxiv.org/pdf/2601.14424", "abs": "https://arxiv.org/abs/2601.14424", "authors": ["Abiola Babatunde", "Matthew England", "AmirHosein Sadeghimanesh"], "title": "Optimising Cylindrical Algebraic Coverings for use in SMT by Solving a Set Covering Problem with Reasons", "categories": ["cs.DS", "math.CO"], "comment": "22 pages, 4 figures, 3 tables. Submitted to the European Journal of Operational Research", "summary": "The Conflict-Driven Cylindrical Algebraic Covering algorithm has proven well suited for performing theory validation checks in the satisfiability modulo theories paradigm for non-linear real arithmetic. CDCAC repurposes the theory underpinning classical cylindrical algebraic decomposition for SMT solving and is implemented in the SMT solvers cvc5 and SMT-RAT, as well as the computer algebra system Maple. It was previously observed that when using cylindrical algebraic decomposition for an SMT theory call, the output can be optimised by solving a single set covering problem instance that minimises the conflict clause. In this paper we consider the corresponding optimisation for CDCAC and observe that CDCAC naturally gives rise to multiple such optimisations within a single call. Each time a covering is generalised in one dimension, the resulting cell in the next dimension is labelled with theory constraints that cannot be satisfied together. We seek the smallest subset of constraints whose union covers all labels from the cells in the current covering. We call this optimisation problem a set covering problem with reasons. To simplify this problem, we introduce a data reduction step that generalises Beasley reduction for the classical set covering problem and show that this step alone solves many of the instances arising from SMT-LIB benchmarks. We then propose an exact solver based on linear programming to efficiently solve the remaining cases. Integrating these techniques into CDCAC has the potential to significantly improve SMT solver performance for non-linear real arithmetic problems.", "AI": {"tldr": "论文主要任务是优化Cylindrical Algebraic Covering算法，用于提升SMT求解器在处理非线性实数算术问题时的性能。", "motivation": "动机在于通过解决集合覆盖问题来减少冲突子句的数量，进而提高CDCAC算法在SMT求解中的效率。", "method": "论文提出了一种数据缩减步骤，将Beasley缩减方法推广到经典集合覆盖问题，并提出了基于线性规划的精确求解器来处理剩余实例。", "result": "这些技术整合进CDCAC可以显著提高非线性实数算术问题在SMT求解中的性能。", "conclusion": "论文表明，通过解决带有理由的集合覆盖问题并结合数据缩减和线性规划方法，能够有效优化CDCAC算法，并提升其处理非线性实数算术问题的能力。"}}
{"id": "2601.14423", "pdf": "https://arxiv.org/pdf/2601.14423", "abs": "https://arxiv.org/abs/2601.14423", "authors": ["Aryan Ramchandra Kapadia", "Niharika Bhattacharjee", "Mung Yao Jia", "Ishq Gupta", "Dong Wang", "Koustuv Saha"], "title": "Loss Aversion Online: Emotional Responses to Financial Booms and Crashes", "categories": ["cs.HC", "cs.SI"], "comment": "9 pages, 5 figures, 8 tables", "summary": "Financial events negatively affect emotional well-being, but large-scale studies examining their impact on online emotional expression using real-time social media data remain limited. To address this gap, we propose analyzing Reddit communities (financial and non-financial) across two case studies: a financial crash and a boom. We investigate how emotional and psycholinguistic responses differ between financial and non-financial communities, and the extent to which the type of financial event affects user behavior during the two case study periods. To examine the effect of these events on expressed language, we analyze daily sentiment, emotion, and LIWC counts using quasi-experimental methods: Difference-in-Differences (DiD) and Causal Impact analyses during a financial boom and a financial crash. Overall, we find coherent, negative shifts in emotional responses during financial crashes, but weaker, mixed responses during booms, consistent with loss aversion. By exploring emotional and psycholinguistic expressions during financial events, we identify future implications for understanding online users' mental health and building connected, healthy communities.", "AI": {"tldr": "该论文通过分析Reddit社区在金融繁荣和崩溃事件期间的情绪反应，研究了这些事件对在线情绪表达的影响。", "motivation": "现有的大规模研究中，使用实时社交媒体数据来考察金融事件如何影响线上情感表达的不足，这篇论文旨在填补这一空白。", "method": "文章采用准实验方法（差异法和因果冲击分析）分析了在金融繁荣和崩溃期间的情感、情绪以及LIWC计数的变化。", "result": "研究发现，在金融危机期间，情感反应出现了一致且负面的转变；而在金融繁荣时期，则表现出较弱且混合的情绪反应，这与损失厌恶理论相一致。", "conclusion": "通过探索金融事件中情感和心理语言表达，该论文为理解在线用户心理健康提供了新的视角，并有助于构建连接紧密、健康的社会群体。"}}
{"id": "2601.14406", "pdf": "https://arxiv.org/pdf/2601.14406", "abs": "https://arxiv.org/abs/2601.14406", "authors": ["Yixiong Chen", "Zongwei Zhou", "Wenxuan Li", "Alan Yuille"], "title": "Large-Scale Label Quality Assessment for Medical Segmentation via a Vision-Language Judge and Synthetic Data", "categories": ["cs.CV", "eess.IV"], "comment": "ISBI 2026 accepted", "summary": "Large-scale medical segmentation datasets often combine manual and pseudo-labels of uneven quality, which can compromise training and evaluation. Low-quality labels may hamper performance and make the model training less robust. To address this issue, we propose SegAE (Segmentation Assessment Engine), a lightweight vision-language model (VLM) that automatically predicts label quality across 142 anatomical structures. Trained on over four million image-label pairs with quality scores, SegAE achieves a high correlation coefficient of 0.902 with ground-truth Dice similarity and evaluates a 3D mask in 0.06s. SegAE shows several practical benefits: (I) Our analysis reveals widespread low-quality labeling across public datasets; (II) SegAE improves data efficiency and training performance in active and semi-supervised learning, reducing dataset annotation cost by one-third and quality-checking time by 70% per label. This tool provides a simple and effective solution for quality control in large-scale medical segmentation datasets. The dataset, model weights, and codes are released at https://github.com/Schuture/SegAE.", "AI": {"tldr": "本文提出了SegAE，一种轻量级的视觉语言模型（VLM），用于自动预测大规模医疗分割数据集中的标签质量。", "motivation": "由于大型医疗分割数据集中混合了手动和伪标签，并且这些标签的质量参差不齐，可能影响训练和评估效果。低质量的标签会妨碍性能并使模型训练变得不够稳健。", "method": "SegAE使用超过四百万张图像-标签对进行训练，预测142个解剖结构的标签质量，实现了与真实Dice相似性系数0.902的相关度，并且在3D掩模评估上只需0.06秒。", "result": "该研究揭示了公共数据集中广泛存在的低质量标注问题；SegAE提高了主动学习和半监督学习的数据效率和训练性能，减少了三分之一的注释成本和70%的标签质检时间。", "conclusion": "SegAE提供了一种简单有效的解决方案来控制大规模医疗分割数据集中的质量问题，并且相关数据、模型权重和代码已公开发布。"}}
{"id": "2601.14401", "pdf": "https://arxiv.org/pdf/2601.14401", "abs": "https://arxiv.org/abs/2601.14401", "authors": ["Florentin Koch"], "title": "Recursivism: An Artistic Paradigm for Self-Transforming Art in the Age of AI", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Preprint under review", "summary": "This article introduces Recursivism as a conceptual framework for analyzing contemporary artistic practices in the age of artificial intelligence. While recursion is precisely defined in mathematics and computer science, it has not previously been formalized as an aesthetic paradigm. Recursivism designates practices in which not only outputs vary over time, but in which the generative process itself becomes capable of reflexive modification through its own effects. The paper develops a five-level analytical scale distinguishing simple iteration, cumulative iteration, parametric recursion, reflexive recursion, and meta-recursion. This scale clarifies the threshold at which a system shifts from variation within a fixed rule to genuine self-modification of the rule itself. From this perspective, art history is reinterpreted as a recursive dynamic alternating between internal recursion within movements and meta-recursive transformations of their generative principles. Artificial intelligence renders this logic technically explicit through learning loops, parameter updates, and code-level self-modification. To distinguish Recursivism from related notions such as generative art, cybernetics, process art, and evolutionary art, the article proposes three operational criteria: state memory, rule evolvability, and reflexive visibility. These concepts are examined through case studies including Refik Anadol, Sougwen Chung, Karl Sims, and the Darwin-Godel Machine. The article concludes by examining the aesthetic, curatorial, and ethical implications of self-modifying artistic systems.", "AI": {"tldr": "本文介绍了递归主义作为分析人工智能时代的当代艺术实践的概念框架。", "motivation": "文章旨在将递归概念正式化为一种审美范式，并通过案例研究来区分递归主义与其他相关概念，如生成艺术、控制论、过程艺术和进化艺术。", "method": "提出了一个五级分析标准，从简单迭代到元递归，以明确系统何时从固定规则内的变化转变为真正的自我修改规则。", "result": "通过案例研究（包括Refik Anadol, Sougwen Chung, Karl Sims 和 Darwin-Godel Machine），文章区分了递归主义与其他艺术形式，并提出了三个操作标准：状态记忆、规则可演化性和反射可见性。", "conclusion": "文章探讨了自我修改的艺术系统在美学、策展和伦理方面的含义。"}}
{"id": "2601.14356", "pdf": "https://arxiv.org/pdf/2601.14356", "abs": "https://arxiv.org/abs/2601.14356", "authors": ["Carlos Hernandez-Olivan", "Hendrik Vincent Koops", "Hao Hao Tan", "Elio Quinton"], "title": "Single-step Controllable Music Bandwidth Extension With Flow Matching", "categories": ["cs.SD"], "comment": "Accepted at the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026", "summary": "Audio restoration consists in inverting degradations of a digital audio signal to recover what would have been the pristine quality signal before the degradation occurred. This is valuable in contexts such as archives of music recordings, particularly those of precious historical value, for which a clean version may have been lost or simply does not exist. Recent work applied generative models to audio restoration, showing promising improvement over previous methods, and opening the door to the ability to perform restoration operations that were not possible before. However, making these models finely controllable remains a challenge. In this paper, we propose an extension of FLowHigh and introduce the Dynamic Spectral Contour (DSC) as a control signal for bandwidth extension via classifier-free guidance. Our experiments show competitive model performance, and indicate that DSC is a promising feature to support fine-grained conditioning.", "AI": {"tldr": "本文提出了一种基于流匹配的单步可控音乐带宽扩展方法。", "motivation": "音频修复对于恢复历史价值录音的质量至关重要，而现有模型在精细控制方面面临挑战。", "method": "本文扩展了FLowHigh模型，并引入动态频谱轮廓（DSC）作为分类器自由引导下的带宽扩展的控制信号。", "result": "实验结果显示该方法具有竞争力的表现，表明DSC是一种支持细粒度条件设置的有前景特征。", "conclusion": "提出的方法在音频修复中表现良好，并为未来的研究提供了新的方向。"}}
{"id": "2601.14352", "pdf": "https://arxiv.org/pdf/2601.14352", "abs": "https://arxiv.org/abs/2601.14352", "authors": ["Huajie Tan", "Enshen Zhou", "Zhiyu Li", "Yijie Xu", "Yuheng Ji", "Xiansheng Chen", "Cheng Chi", "Pengwei Wang", "Huizhu Jia", "Yulong Ao", "Mingyu Cao", "Sixiang Chen", "Zhe Li", "Mengzhen Liu", "Zixiao Wang", "Shanyu Rong", "Yaoxu Lyu", "Zhongxia Zhao", "Peterson Co", "Yibo Li", "Yi Han", "Shaoxuan Xie", "Guocai Yao", "Songjing Wang", "Leiduo Zhang", "et al. (10 additional authors not shown)"], "title": "RoboBrain 2.5: Depth in Sight, Time in Mind", "categories": ["cs.RO"], "comment": "37 pages, 13 figures, Technical Report", "summary": "We introduce RoboBrain 2.5, a next-generation embodied AI foundation model that advances general perception, spatial reasoning, and temporal modeling through extensive training on high-quality spatiotemporal supervision. Building upon its predecessor, RoboBrain 2.5 introduces two major capability upgrades. Specifically, it unlocks Precise 3D Spatial Reasoning by shifting from 2D pixel-relative grounding to depth-aware coordinate prediction and absolute metric constraint comprehension, generating complete 3D manipulation traces as ordered keypoint sequences under physical constraints. Complementing this spatial precision, the model establishes Dense Temporal Value Estimation that provides dense, step-aware progress prediction and execution state understanding across varying viewpoints, producing stable feedback signals for downstream learning. Together, these upgrades extend the framework toward more physically grounded and execution-aware embodied intelligence for complex, fine-grained manipulation. The code and checkpoints are available at project website: https://superrobobrain.github.io", "AI": {"tldr": "介绍了RoboBrain 2.5，一种通过高精度时空监督训练来提升一般感知、空间推理和时间建模能力的下一代具身AI基础模型。", "motivation": "推动具身智能向更物理化和执行意识的方向发展，以实现复杂精细的操作。", "method": "RoboBrain 2.5引入了精确3D空间推理能力和密集时态价值估计，通过从2D像素相对定位转变为深度感知坐标预测，生成完整的3D操作轨迹；并提供步骤感知的进度预测和执行状态理解。", "result": "该模型扩展了框架向更物理化和执行意识的具身智能方向发展，提升了复杂精细操作的能力。", "conclusion": "通过引入精确的空间推理能力和时间价值估计，RoboBrain 2.5在提升具身AI的操作精度和稳定性方面取得了显著进步。"}}
{"id": "2601.14351", "pdf": "https://arxiv.org/pdf/2601.14351", "abs": "https://arxiv.org/abs/2601.14351", "authors": ["Gopal Vijayaraghavan", "Prasanth Jayachandran", "Arun Murthy", "Sunil Govindan", "Vivek Subramanian"], "title": "If You Want Coherence, Orchestrate a Team of Rivals: Multi-Agent Models of Organizational Intelligence", "categories": ["cs.MA", "cs.AI"], "comment": "15 pages, 6 figures, 7 tables", "summary": "AI Agents can perform complex operations at great speed, but just like all the humans we have ever hired, their intelligence remains fallible. Miscommunications aren't noticed, systemic biases have no counter-action, and inner monologues are rarely written down. We did not come to fire them for their mistakes, but to hire them and provide a safe productive working environment. We posit that we can reuse a common corporate organizational structure: teams of independent AI agents with strict role boundaries can work with common goals, but opposing incentives. Multiple models serving as a team of rivals can catch and minimize errors within the final product at a small cost to the velocity of actions. In this paper we demonstrate that we can achieve reliability without acquiring perfect components, but through careful orchestration of imperfect ones. This paper describes the architecture of such a system in practice: specialized agent teams (planners, executors, critics, experts), organized into an organization with clear goals, coordinated through a remote code executor that keeps data transformations and tool invocations separate from reasoning models. Rather than agents directly calling tools and ingesting full responses, they write code that executes remotely; only relevant summaries return to agent context. By preventing raw data and tool outputs from contaminating context windows, the system maintains clean separation between perception (brains that plan and reason) and execution (hands that perform heavy data transformations and API calls). We demonstrate the approach achieves over 90% internal error interception prior to user exposure while maintaining acceptable latency tradeoffs. A survey from our traces shows that we only trade off cost and latency to achieve correctness and incrementally expand capabilities without impacting existing ones.", "AI": {"tldr": "本论文提出了一个架构，通过使用具有清晰角色界限的独立AI代理团队（规划者、执行者、批评家和专家），并在远程代码执行器中协调它们的操作来实现可靠性和准确性。", "motivation": "尽管AI代理能够快速完成复杂操作，但其智能存在局限性。本论文旨在通过组织结构的设计来捕获并最小化错误，而不依赖于完美组件。", "method": "设计了一个系统架构，包括专门的代理团队（规划者、执行者、批评家和专家），这些团队在远程代码执行器协调下运作，以保持感知与执行之间的清晰分离。", "result": "实验证明该方法能够实现超过90%的内部错误拦截率，同时维持可接受的延迟，并且在增加功能时不会影响现有性能。", "conclusion": "通过团队协作的方式组织独立AI代理可以有效地提高系统可靠性，并允许以较小的成本和延迟代价换取更高的准确性。"}}
{"id": "2601.14346", "pdf": "https://arxiv.org/pdf/2601.14346", "abs": "https://arxiv.org/abs/2601.14346", "authors": ["Yewon Han", "Sunghyun Kim", "Eunyi Jeong", "Sungkyung Lee", "Seokwoo Yun", "Sangsoo Lim"], "title": "DiSPA: Differential Substructure-Pathway Attention for Drug Response Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate prediction of drug response in precision medicine requires models that capture how specific chemical substructures interact with cellular pathway states. However, most existing deep learning approaches treat chemical and transcriptomic modalities independently or combine them only at late stages, limiting their ability to model fine-grained, context-dependent mechanisms of drug action. In addition, standard attention mechanisms are often sensitive to noise and sparsity in high-dimensional biological networks, hindering both generalization and interpretability. We present DiSPA, a representation learning framework that explicitly disentangles structure-driven and context-driven mechanisms of drug response through bidirectional conditioning between chemical substructures and pathway-level gene expression. DiSPA introduces a differential cross-attention module that suppresses spurious pathway-substructure associations while amplifying contextually relevant interactions. Across multiple evaluation settings on the GDSC benchmark, DiSPA achieves state-of-the-art performance, with particularly strong improvements in the disjoint-set setting, which assesses generalization to unseen drug-cell combinations. Beyond predictive accuracy, DiSPA yields mechanistically informative representations: learned attention patterns recover known pharmacophores, distinguish structure-driven from context-dependent compounds, and exhibit coherent organization across biological pathways. Furthermore, we demonstrate that DiSPA trained solely on bulk RNA-seq data enables zero-shot transfer to spatial transcriptomics, revealing region-specific drug sensitivity patterns without retraining. Together, these results establish DiSPA as a robust and interpretable framework for integrative pharmacogenomic modeling, enabling principled analysis of drug response mechanisms beyond post hoc interpretation.", "AI": {"tldr": "本文提出DiSPA框架，用于通过化学子结构和通路级基因表达的双向条件反射来预测药物反应。", "motivation": "现有深度学习方法处理化学和转录组学模态时独立或仅在后期结合它们，这限制了模型捕捉精细、上下文相关机制的能力。此外，标准注意力机制对高维生物网络中的噪声和稀疏性敏感，影响其泛化能力和可解释性。", "method": "DiSPA引入了一种差分交叉注意模块，在化学子结构与通路级基因表达之间进行双向条件反射，以抑制虚假的通路-子结构关联，并放大上下文相关的交互作用。", "result": "在GDSC基准测试中，DiSPA实现了最先进的性能，特别是在评估未见过的药物和细胞组合时表现尤为突出。此外，DiSPA生成了机制上信息丰富的表示形式，能够区分结构驱动与上下文依赖化合物，并能揭示区域特异性药物敏感模式。", "conclusion": "DiSPA作为一个稳健且可解释的框架，适用于综合药理基因组模型，在无需重新训练的情况下实现了零样本转移，为药物反应机制提供了原则性分析。"}}
{"id": "2601.14339", "pdf": "https://arxiv.org/pdf/2601.14339", "abs": "https://arxiv.org/abs/2601.14339", "authors": ["Haotian Xu", "Yue Hu", "Zhengqiu Zhu", "Chen Gao", "Ziyou Wang", "Junreng Rao", "Wenhao Lu", "Weishi Li", "Quanjun Yin", "Yong Li"], "title": "CityCube: Benchmarking Cross-view Spatial Reasoning on Vision-Language Models in Urban Environments", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Cross-view spatial reasoning is essential for embodied AI, underpinning spatial understanding, mental simulation and planning in complex environments. Existing benchmarks primarily emphasize indoor or street settings, overlooking the unique challenges of open-ended urban spaces characterized by rich semantics, complex geometries, and view variations. To address this, we introduce CityCube, a systematic benchmark designed to probe cross-view reasoning capabilities of current VLMs in urban settings. CityCube integrates four viewpoint dynamics to mimic camera movements and spans a wide spectrum of perspectives from multiple platforms, e.g., vehicles, drones and satellites. For a comprehensive assessment, it features 5,022 meticulously annotated multi-view QA pairs categorized into five cognitive dimensions and three spatial relation expressions. A comprehensive evaluation of 33 VLMs reveals a significant performance disparity with humans: even large-scale models struggle to exceed 54.1% accuracy, remaining 34.2% below human performance. By contrast, small-scale fine-tuned VLMs achieve over 60.0% accuracy, highlighting the necessity of our benchmark. Further analyses indicate the task correlations and fundamental cognitive disparity between VLMs and human-like reasoning.", "AI": {"tldr": "本文介绍了CityCube，一个用于评估视觉语言模型在城市环境中进行跨视角空间推理能力的基准测试。", "motivation": "现有基准主要集中在室内或街道环境，忽略了开放性城市空间的独特挑战，如丰富的语义、复杂的几何形状和视图变化。为了弥补这一空白，本文提出了CityCube。", "method": "CityCube通过整合四个视角动态模拟摄像机运动，并涵盖来自多个平台的广泛视角，例如车辆、无人机和卫星，包含5,022个多视角问答对，分为五个认知维度和三种空间关系表达。", "result": "评估了33个视觉语言模型后发现，这些模型的表现与人类有很大差距：即使大型模型也难以超过54.1%的准确率，比人类低34.2%。相比之下，经过微调的小规模模型达到了60.0%以上的准确率。", "conclusion": "这表明CityCube是必要的，并指出任务相关性和视觉语言模型与人类似推理之间的基本认知差异。"}}
{"id": "2601.14338", "pdf": "https://arxiv.org/pdf/2601.14338", "abs": "https://arxiv.org/abs/2601.14338", "authors": ["Zhengyong Huang", "Ning Jiang", "Xingwen Sun", "Lihua Zhang", "Peng Chen", "Jens Domke", "Yao Sui"], "title": "Partial Decoder Attention Network with Contour-weighted Loss Function for Data-Imbalance Medical Image Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Image segmentation is pivotal in medical image analysis, facilitating clinical diagnosis, treatment planning, and disease evaluation. Deep learning has significantly advanced automatic segmentation methodologies by providing superior modeling capability for complex structures and fine-grained anatomical regions. However, medical images often suffer from data imbalance issues, such as large volume disparities among organs or tissues, and uneven sample distributions across different anatomical structures. This imbalance tends to bias the model toward larger organs or more frequently represented structures, while overlooking smaller or less represented structures, thereby affecting the segmentation accuracy and robustness. To address these challenges, we proposed a novel contour-weighted segmentation approach, which improves the model's capability to represent small and underrepresented structures. We developed PDANet, a lightweight and efficient segmentation network based on a partial decoder mechanism. We evaluated our method using three prominent public datasets. The experimental results show that our methodology excelled in three distinct tasks: segmenting multiple abdominal organs, brain tumors, and pelvic bone fragments with injuries. It consistently outperformed nine state-of-the-art methods. Moreover, the proposed contour-weighted strategy improved segmentation for other comparison methods across the three datasets, yielding average enhancements in Dice scores of 2.32%, 1.67%, and 3.60%, respectively. These results demonstrate that our contour-weighted segmentation method surpassed current leading approaches in both accuracy and robustness. As a model-independent strategy, it can seamlessly fit various segmentation frameworks, enhancing their performance. This flexibility highlighted its practical importance and potential for broad use in medical image analysis.", "AI": {"tldr": "提出了一种基于部分解码器注意力网络和轮廓加权损失函数的医疗图像分割方法，以解决数据不平衡问题。", "motivation": "医学图像分析中的数据不平衡问题导致了模型对小器官或较少代表结构的关注不足，影响了分割准确性和鲁棒性。", "method": "开发了一种名为PDANet的轻量级和高效的分割网络，并提出了一种轮廓加权策略来改进小结构和稀有结构的表现。", "result": "实验结果表明该方法在三个不同的医学图像数据集上均超过了九个最先进的方法，分别提高了Dice分数2.32%，1.67%和3.60%。", "conclusion": "所提出的轮廓加权策略不仅提升了分割的准确性和鲁棒性，还作为一种模型无关的方法展示了其在医疗图像分析中的实际重要性和广泛应用潜力。"}}
{"id": "2601.14337", "pdf": "https://arxiv.org/pdf/2601.14337", "abs": "https://arxiv.org/abs/2601.14337", "authors": ["Zhengyong Huang", "Xingwen Sun", "Xuting Chang", "Ning Jiang", "Yao Wang", "Jianfei Sun", "Hongbin Han", "Yao Sui"], "title": "Unsupervised Deformable Image Registration with Local-Global Attention and Image Decomposition", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Deformable image registration is a critical technology in medical image analysis, with broad applications in clinical practice such as disease diagnosis, multi-modal fusion, and surgical navigation. Traditional methods often rely on iterative optimization, which is computationally intensive and lacks generalizability. Recent advances in deep learning have introduced attention-based mechanisms that improve feature alignment, yet accurately registering regions with high anatomical variability remains challenging. In this study, we proposed a novel unsupervised deformable image registration framework, LGANet++, which employs a novel local-global attention mechanism integrated with a unique technique for feature interaction and fusion to enhance registration accuracy, robustness, and generalizability. We evaluated our approach using five publicly available datasets, representing three distinct registration scenarios: cross-patient, cross-time, and cross-modal CT-MR registration. The results demonstrated that our approach consistently outperforms several state-of-the-art registration methods, improving registration accuracy by 1.39% in cross-patient registration, 0.71% in cross-time registration, and 6.12% in cross-modal CT-MR registration tasks. These results underscore the potential of LGANet++ to support clinical workflows requiring reliable and efficient image registration. The source code is available at https://github.com/huangzyong/LGANet-Registration.", "AI": {"tldr": "本文提出了一种新的无监督可变形图像配准框架LGANet++，该方法结合了局部全局注意力机制和特征交互融合技术，以提高配准的准确性、鲁棒性和通用性。", "motivation": "传统的方法依赖于迭代优化，计算量大且缺乏泛化能力。虽然深度学习引入的注意力机制提高了特征对齐的效果，但对于解剖结构变化较大的区域准确配准仍具有挑战性。因此提出了新的方法来解决这些问题。", "method": "本文提出的LGANet++框架采用了一种新颖的局部全局注意力机制，并结合独特的特征交互和融合技术以提高配准准确性、鲁棒性和泛化能力。", "result": "通过五个公开数据集进行评估，涵盖跨患者、跨时间及CT-MR多模态配准等三种不同场景，结果表明LGANet++在这些任务中始终优于几种最先进的注册方法，分别提高了1.39%（跨患者）、0.71%（跨时间）和6.12%（跨模态CT-MR配准）。", "conclusion": "该研究强调了LGANet++在支持需要可靠且高效图像配准的临床工作流中的潜力。"}}
{"id": "2601.14334", "pdf": "https://arxiv.org/pdf/2601.14334", "abs": "https://arxiv.org/abs/2601.14334", "authors": ["Junhyuk Heo"], "title": "Self-Supervised Score-Based Despeckling for SAR Imagery via Log-Domain Transformation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The speckle noise inherent in Synthetic Aperture Radar (SAR) imagery significantly degrades image quality and complicates subsequent analysis. Given that SAR speckle is multiplicative and Gamma-distributed, effectively despeckling SAR imagery remains challenging. This paper introduces a novel self-supervised framework for SAR image despeckling based on score-based generative models operating in the transformed log domain. We first transform the data into the log-domain and then convert the speckle noise residuals into an approximately additive Gaussian distribution. This step enables the application of score-based models, which are trained in the transformed domain using a self-supervised objective. This objective allows our model to learn the clean underlying signal by training on further corrupted versions of the input data itself. Consequently, our method exhibits significantly shorter inference times compared to many existing self-supervised techniques, offering a robust and practical solution for SAR image restoration.", "AI": {"tldr": "本文提出了一种基于分数生成模型的自监督框架，用于SAR图像去斑，通过将数据转换到对数域来简化噪声处理。", "motivation": "SAR图像中的斑点噪声会降低图像质量并增加后续分析的难度，因此需要一种有效的去斑方法。", "method": "首先将数据转换到对数域，然后使用分数生成模型在自监督目标下进行训练，以学习潜在的干净信号。", "result": "该方法显著缩短了推理时间，并提供了鲁棒和实用的SAR图像恢复解决方案。", "conclusion": "通过转换到对数域并应用分数生成模型，本文提出的方法为SAR图像去斑提供了一种有效且实用的技术。"}}
{"id": "2601.14330", "pdf": "https://arxiv.org/pdf/2601.14330", "abs": "https://arxiv.org/abs/2601.14330", "authors": ["Mengyu Sun", "Ziyuan Yang", "Andrew Beng Jin Teoh", "Junxu Liu", "Haibo Hu", "Yi Zhang"], "title": "LURE: Latent Space Unblocking for Multi-Concept Reawakening in Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Concept erasure aims to suppress sensitive content in diffusion models, but recent studies show that erased concepts can still be reawakened, revealing vulnerabilities in erasure methods. Existing reawakening methods mainly rely on prompt-level optimization to manipulate sampling trajectories, neglecting other generative factors, which limits a comprehensive understanding of the underlying dynamics. In this paper, we model the generation process as an implicit function to enable a comprehensive theoretical analysis of multiple factors, including text conditions, model parameters, and latent states. We theoretically show that perturbing each factor can reawaken erased concepts. Building on this insight, we propose a novel concept reawakening method: Latent space Unblocking for concept REawakening (LURE), which reawakens erased concepts by reconstructing the latent space and guiding the sampling trajectory. Specifically, our semantic re-binding mechanism reconstructs the latent space by aligning denoising predictions with target distributions to reestablish severed text-visual associations. However, in multi-concept scenarios, naive reconstruction can cause gradient conflicts and feature entanglement. To address this, we introduce Gradient Field Orthogonalization, which enforces feature orthogonality to prevent mutual interference. Additionally, our Latent Semantic Identification-Guided Sampling (LSIS) ensures stability of the reawakening process via posterior density verification. Extensive experiments demonstrate that LURE enables simultaneous, high-fidelity reawakening of multiple erased concepts across diverse erasure tasks and methods.", "AI": {"tldr": "提出LURE方法，通过重构潜在空间和引导采样轨迹来重新唤醒被擦除的概念。", "motivation": "概念擦除旨在抑制扩散模型中的敏感内容，但现有擦除方法存在漏洞，被擦除的概念可以通过某些方式重新出现。研究希望通过更全面的方法理解并解决这个问题。", "method": "LURE将生成过程建模为一个隐式函数，通过扰动文本条件、模型参数和潜在状态来重新唤醒概念。使用语义再绑定机制重构潜在空间，并引入梯度场正交化和潜在语义识别引导采样技术来解决多概念场景中的问题。", "result": "实验表明LURE可以在多种擦除任务和方法中同时且高保真地重新唤醒多个被擦除的概念。", "conclusion": "通过LURE方法，研究证明了可以通过重构潜在空间并指导采样轨迹有效实现对被擦除概念的再激活。"}}
{"id": "2601.14327", "pdf": "https://arxiv.org/pdf/2601.14327", "abs": "https://arxiv.org/abs/2601.14327", "authors": ["YuanLab. ai", "Shawn Wu", "Jiangang Luo", "Tong Yu", "Darcy Chen", "Sean Wang", "Xudong Zhao", "Louie Li", "Claire Wang", "Hunter He", "Carol Wang", "Allen Wang"], "title": "Layer-adaptive Expert Pruning for Pre-Training of Mixture-of-Experts Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Although Mixture-of-Experts (MoE) Large Language Models (LLMs) deliver superior accuracy with a reduced number of active parameters, their pre-training represents a significant computationally bottleneck due to underutilized experts and limited training efficiency. This work introduces a Layer-Adaptive Expert Pruning (LAEP) algorithm designed for the pre-training stage of MoE LLMs. In contrast to previous expert pruning approaches that operate primarily in the post-training phase, the proposed algorithm enhances training efficiency by selectively pruning underutilized experts and reorganizing experts across computing devices according to token distribution statistics. Comprehensive experiments demonstrate that LAEP effectively reduces model size and substantially improves pre-training efficiency. In particular, when pre-training the 1010B Base model from scratch, LAEP achieves a 48.3\\% improvement in training efficiency alongside a 33.3% parameter reduction, while still delivering excellent performance across multiple domains.", "AI": {"tldr": "本文提出了一种用于MoE大语言模型预训练阶段的层自适应专家剪枝算法（LAEP），旨在提高训练效率并减少参数数量。", "motivation": "尽管MoE大语言模型能够以较少活跃参数提供更高的准确性，但其预训练过程由于专家利用率低和训练效率有限而成为计算瓶颈。因此，研究动机在于改进这一阶段的效率问题。", "method": "LAEP算法通过在预训练阶段选择性地剪枝未充分利用的专家，并根据令牌分布统计重新组织不同设备上的专家来提升训练效率。", "result": "实验表明，与从零开始预训练1010B基模型相比，使用LAEP能实现48.3%的训练效率改进和33.3%的参数减少，同时保持跨多个领域的出色性能。", "conclusion": "研究结论是LAEP算法显著提高了MoE大语言模型预训练阶段的效率并减少了模型大小，证明了其在实际应用中的有效性。"}}
{"id": "2601.14324", "pdf": "https://arxiv.org/pdf/2601.14324", "abs": "https://arxiv.org/abs/2601.14324", "authors": ["Xian Li", "Yuanning Han", "Di Liu", "Pengcheng An", "Shuo Niu"], "title": "When Generative AI Is Intimate, Sexy, and Violent: Examining Not-Safe-For-Work (NSFW) Chatbots on FlowGPT", "categories": ["cs.HC"], "comment": null, "summary": "User-created chatbots powered by generative AI offer new ways to share and interact with Not-Safe-For-Work (NSFW) content. However, little is known about the characteristics of these GenAI-based chatbots and their user interactions. Drawing on the functional theory of NSFW on social media, this study analyzes 376 NSFW chatbots and 307 public conversation sessions on FlowGPT. Findings identify four chatbot types: roleplay characters, story generators, image generators, and do-anything-now bots. AI Characters portraying fantasy personas and enabling hangout-style interactions are most common, often using explicit avatar images to invite engagement. Sexual, violent, and insulting content appears in both user prompts and chatbot outputs, with some chatbots generating explicit material even when users do not create erotic prompts. In sum, the NSFW experience on FlowGPT can be understood as a combination of virtual intimacy, sexual delusion, violent thought expression, and unsafe content acquisition. We conclude with implications for chatbot design, creator support, user safety, and content moderation.", "AI": {"tldr": "本文研究了FlowGPT平台上用户创建的Not-Safe-For-Work（NSFW）聊天机器人的特性和用户互动。", "motivation": "鉴于目前对基于生成式AI的NSFW聊天机器人及其与用户的交互模式了解甚少，本研究旨在填补这一知识空白。", "method": "该研究分析了FlowGPT平台上的376个NSFW聊天机器人和307次公开对话记录，并根据社会媒体的功能理论进行了分类。", "result": "研究发现存在四种类型的聊天机器人：角色扮演人物、故事生成器、图像生成器以及无所不做的即时响应型机器人。AI角色中最常见的是幻想人物，它们通过使用显式的头像来吸引互动。用户提示和机器人的回复中都包含性、暴力和侮辱性的内容。", "conclusion": "NSFW体验可以被理解为虚拟亲密、性幻觉表达、暴力思想传达以及不安全内容获取的综合体现，并提出了对聊天机器人设计、创作者支持、用户安全及内容监管方面的建议。"}}
{"id": "2601.14323", "pdf": "https://arxiv.org/pdf/2601.14323", "abs": "https://arxiv.org/abs/2601.14323", "authors": ["Bingxin Xu", "Yuzhang Shang", "Binghui Wang", "Emilio Ferrara"], "title": "SilentDrift: Exploiting Action Chunking for Stealthy Backdoor Attacks on Vision-Language-Action Models", "categories": ["cs.CR", "cs.AI", "cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models are increasingly deployed in safety-critical robotic applications, yet their security vulnerabilities remain underexplored. We identify a fundamental security flaw in modern VLA systems: the combination of action chunking and delta pose representations creates an intra-chunk visual open-loop. This mechanism forces the robot to execute K-step action sequences, allowing per-step perturbations to accumulate through integration. We propose SILENTDRIFT, a stealthy black-box backdoor attack exploiting this vulnerability. Our method employs the Smootherstep function to construct perturbations with guaranteed C2 continuity, ensuring zero velocity and acceleration at trajectory boundaries to satisfy strict kinematic consistency constraints. Furthermore, our keyframe attack strategy selectively poisons only the critical approach phase, maximizing impact while minimizing trigger exposure. The resulting poisoned trajectories are visually indistinguishable from successful demonstrations. Evaluated on the LIBERO, SILENTDRIFT achieves a 93.2% Attack Success Rate with a poisoning rate under 2%, while maintaining a 95.3% Clean Task Success Rate.", "AI": {"tldr": "本文提出了SILENTDRIFT，一种针对视觉-语言-动作模型的隐蔽后门攻击方法。", "motivation": "现代VLA系统在安全关键机器人应用中日益普及，但其安全性仍需进一步研究。本文旨在揭示并利用这些系统的潜在漏洞进行隐蔽攻击。", "method": "SILENTDRIFT通过Smootherstep函数构建具有保证C2连续性的扰动，并采用关键帧攻击策略只污染接近阶段的关键部分。", "result": "实验表明，SILENTDRIFT在LIBERO上实现了93.2%的攻击成功率和95.3%的清洁任务成功率，而中毒率低于2%。", "conclusion": "该研究证明了视觉-语言-动作模型中存在潜在的安全漏洞，并提出了一种高效的隐蔽后门攻击方法SILENTDRIFT。"}}
{"id": "2601.14311", "pdf": "https://arxiv.org/pdf/2601.14311", "abs": "https://arxiv.org/abs/2601.14311", "authors": ["Richard Hohensinner", "Belgin Mutlu", "Inti Gabriel Mendoza Estrada", "Matej Vukovic", "Simone Kopeinik", "Roman Kern"], "title": "Tracing the Data Trail: A Survey of Data Provenance, Transparency and Traceability in LLMs", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "35 pages, 6 figures. Manuscript submitted to ACM Computing Surveys (CSUR) on the 12th of December 2025", "summary": "Large language models (LLMs) are deployed at scale, yet their training data life cycle remains opaque. This survey synthesizes research from the past ten years on three tightly coupled axes: (1) data provenance, (2) transparency, and (3) traceability, and three supporting pillars: (4) bias \\& uncertainty, (5) data privacy, and (6) tools and techniques that operationalize them. A central contribution is a proposed taxonomy defining the field's domains and listing corresponding artifacts. Through analysis of 95 publications, this work identifies key methodologies concerning data generation, watermarking, bias measurement, data curation, data privacy, and the inherent trade-off between transparency and opacity.", "AI": {"tldr": "本文综述了过去十年关于大型语言模型（LLMs）数据生命周期中数据来源、透明度和可追溯性的研究。", "motivation": "文章旨在解决大规模部署的大型语言模型的数据生成过程不透明的问题，探讨如何提高其在数据来源、透明度和可追溯性方面的理解。", "method": "通过分析95篇相关文献，提出了一个定义领域的分类法，并列出相应的方法论，涵盖了数据生成、水印技术、偏见测量、数据整理、数据隐私等方面。", "result": "文章识别了关键的研究方法和技术，并探讨了透明度与不透明性之间的内在权衡。", "conclusion": "本文通过系统梳理相关研究和提出分类法，为理解和改善大型语言模型的数据生命周期提供了宝贵的视角。"}}
{"id": "2601.14310", "pdf": "https://arxiv.org/pdf/2601.14310", "abs": "https://arxiv.org/abs/2601.14310", "authors": ["Nay Myat Min", "Long H. Pham", "Hongyu Zhang", "Jun Sun"], "title": "CORVUS: Red-Teaming Hallucination Detectors via Internal Signal Camouflage in Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": "13 pages, 1 figure", "summary": "Single-pass hallucination detectors rely on internal telemetry (e.g., uncertainty, hidden-state geometry, and attention) of large language models, implicitly assuming hallucinations leave separable traces in these signals. We study a white-box, model-side adversary that fine-tunes lightweight LoRA adapters on the model while keeping the detector fixed, and introduce CORVUS, an efficient red-teaming procedure that learns to camouflage detector-visible telemetry under teacher forcing, including an embedding-space FGSM attention stress test. Trained on 1,000 out-of-distribution Alpaca instructions (<0.5% trainable parameters), CORVUS transfers to FAVA-Annotation across Llama-2, Vicuna, Llama-3, and Qwen2.5, and degrades both training-free detectors (e.g., LLM-Check) and probe-based detectors (e.g., SEP, ICR-probe), motivating adversary-aware auditing that incorporates external grounding or cross-model evidence.", "AI": {"tldr": "介绍了一种名为CORVUS的对抗性方法，用于在大型语言模型中伪装欺骗检测器。", "motivation": "研究单次通过的幻觉检测器依赖于大型语言模型内部信号来区分幻觉内容的假设，并提出一种白盒攻击者的方法来验证其有效性。", "method": "利用轻量级LoRA适配器在保持检测器不变的情况下微调模型，引入CORVUS方法学习伪装可见的内部信号，包括嵌入空间FGSM注意力压力测试。", "result": "CORVUS训练了1000条超出分布的Alpaca指令，成功转移到Fava-Annotation并在Llama-2、Vicuna、Llama-3和Qwen2.5模型中降低无训练检测器和探针基础检测器的效果。", "conclusion": "结果表明需要考虑对抗性攻击的设计，包括引入外部验证或跨模型证据的审计方法。"}}
{"id": "2601.14305", "pdf": "https://arxiv.org/pdf/2601.14305", "abs": "https://arxiv.org/abs/2601.14305", "authors": ["Ashikuzzaman", "Md. Shawkat Hossain", "Jubayer Abdullah Joy", "Md Zahid Akon", "Md Manjur Ahmed", "Md. Naimul Islam"], "title": "An Optimized Decision Tree-Based Framework for Explainable IoT Anomaly Detection", "categories": ["cs.CR", "cs.AI"], "comment": "Acepted and Presented at IEEE 2nd International Conference on Computing, Applications and Systems (COMPAS 2025) , 23-24 October 2025, Kushtia, Bangladesh", "summary": "The increase in the number of Internet of Things (IoT) devices has tremendously increased the attack surface of cyber threats thus making a strong intrusion detection system (IDS) with a clear explanation of the process essential towards resource-constrained environments. Nevertheless, current IoT IDS systems are usually traded off with detection quality, model elucidability, and computational effectiveness, thus the deployment on IoT devices. The present paper counteracts these difficulties by suggesting an explainable AI (XAI) framework based on an optimized Decision Tree classifier with both local and global importance methods: SHAP values that estimate feature attribution using local explanations, and Morris sensitivity analysis that identifies the feature importance in a global view. The proposed system attains the state of art on the test performance with 99.91% accuracy, F1-score of 99.51% and Cohen Kappa of 0.9960 and high stability is confirmed by a cross validation mean accuracy of 98.93%. Efficiency is also enhanced in terms of computations to provide faster inferences compared to those that are generalized in ensemble models. SrcMac has shown as the most significant predictor in feature analyses according to SHAP and Morris methods. Compared to the previous work, our solution eliminates its major drawback lack because it allows us to apply it to edge devices and, therefore, achieve real-time processing, adhere to the new regulation of transparency in AI, and achieve high detection rates on attacks of dissimilar classes. This combination performance of high accuracy, explainability, and low computation make the framework useful and reliable as a resource-constrained IoT security problem in real environments.", "AI": {"tldr": "本文提出了一种基于优化决策树的可解释AI框架，用于物联网异常检测。", "motivation": "随着IoT设备数量增加，网络安全威胁增大。现有IDS系统存在准确性、模型清晰度和计算效率之间的权衡问题。", "method": "该框架采用优化决策树分类器，并结合SHAP值进行局部特征归因估计及Morris敏感性分析进行全局特征重要性识别。", "result": "测试性能达到99.91%的准确率，F1得分为99.51%，Cohen Kappa为0.9960；交叉验证平均准确率为98.93%。计算效率高且SrcMac被确定为主要预测因子。", "conclusion": "该框架在保持高检测率和解释性的同时提升了计算效率，适用于资源受限的IoT设备实时处理需求，并符合新的AI透明度监管要求。"}}
{"id": "2601.14304", "pdf": "https://arxiv.org/pdf/2601.14304", "abs": "https://arxiv.org/abs/2601.14304", "authors": ["Juncheng Wang", "Zhe Hu", "Chao Xu", "Siyue Ren", "Yuxiang Feng", "Yang Liu", "Baigui Sun", "Shujun Wang"], "title": "Guided by the Plan: Enhancing Faithful Autoregressive Text-to-Audio Generation with Guided Decoding", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted at EACL 2026", "summary": "Autoregressive (AR) models excel at generating temporally coherent audio by producing tokens sequentially, yet they often falter in faithfully following complex textual prompts, especially those describing complex sound events. We uncover a surprising capability in AR audio generators: their early prefix tokens implicitly encode global semantic attributes of the final output, such as event count and sound-object category, revealing a form of implicit planning. Building on this insight, we propose Plan-Critic, a lightweight auxiliary model trained with a Generalized Advantage Estimation (GAE)-inspired objective to predict final instruction-following quality from partial generations. At inference time, Plan-Critic enables guided exploration: it evaluates candidate prefixes early, prunes low-fidelity trajectories, and reallocates computation to high-potential planning seeds. Our Plan-Critic-guided sampling achieves up to a 10-point improvement in CLAP score over the AR baseline-establishing a new state of the art in AR text-to-audio generation-while maintaining computational parity with standard best-of-N decoding. This work bridges the gap between causal generation and global semantic alignment, demonstrating that even strictly autoregressive models can plan ahead.", "AI": {"tldr": "本文提出Plan-Critic方法，通过早期评估候选前缀并剪枝低保真路径来指导自回归模型生成忠实于文本提示的音频。", "motivation": "动机在于解决自回归模型在生成复杂声音事件时不能很好地遵循复杂的文本提示的问题。", "method": "该方法基于自回归模型的前缀隐含编码全局语义属性，引入Plan-Critic辅助模型来预测最终指令执行质量，并指导推理过程中的探索。", "result": "与AR基线相比，采用Plan-Critic引导采样在CLAP评分上提高10分，同时保持计算效率。", "conclusion": "该研究证明了即使是严格的自回归模型也能够进行前瞻性的规划，从而提高了音频生成的语义一致性。"}}
{"id": "2601.14302", "pdf": "https://arxiv.org/pdf/2601.14302", "abs": "https://arxiv.org/abs/2601.14302", "authors": ["Jinwei Hu", "Shiyuan Meng", "Yi Dong", "Xiaowei Huang"], "title": "DDSA: Dual-Domain Strategic Attack for Spatial-Temporal Efficiency in Adversarial Robustness Testing", "categories": ["cs.CR", "cs.AI", "cs.PF"], "comment": "Preprint accepted by ICASSP 2026 with minor revisions", "summary": "Image transmission and processing systems in resource-critical applications face significant challenges from adversarial perturbations that compromise mission-specific object classification. Current robustness testing methods require excessive computational resources through exhaustive frame-by-frame processing and full-image perturbations, proving impractical for large-scale deployments where massive image streams demand immediate processing. This paper presents DDSA (Dual-Domain Strategic Attack), a resource-efficient adversarial robustness testing framework that optimizes testing through temporal selectivity and spatial precision. We introduce a scenario-aware trigger function that identifies critical frames requiring robustness evaluation based on class priority and model uncertainty, and employ explainable AI techniques to locate influential pixel regions for targeted perturbation. Our dual-domain approach achieves substantial temporal-spatial resource conservation while maintaining attack effectiveness. The framework enables practical deployment of comprehensive adversarial robustness testing in resource-constrained real-time applications where computational efficiency directly impacts mission success.", "AI": {"tldr": "本文介绍了DDSA（Dual-Domain Strategic Attack），一种通过时间和空间效率优化，实现资源节约的对抗鲁棒性测试框架。", "motivation": "当前的鲁棒性测试方法在资源紧张的应用中消耗过多计算资源，无法满足大规模部署的需求。本论文旨在开发更高效的方法以应对这一挑战。", "method": "DDSA采用场景感知触发函数来识别需要进行鲁棒性评估的关键帧，并利用可解释AI技术定位有影响力的像素区域，从而实现时间和空间上的优化。", "result": "该框架实现了显著的时间和空间资源节约，同时保持了攻击的有效性。", "conclusion": "DDSA能够在计算效率直接关系任务成功的实时应用中进行对抗鲁棒性的全面测试，并且具备实际部署的可能性。"}}
{"id": "2601.14298", "pdf": "https://arxiv.org/pdf/2601.14298", "abs": "https://arxiv.org/abs/2601.14298", "authors": ["Anjanava Biswas", "Wrick Talukdar"], "title": "Guardrails for trust, safety, and ethical development and deployment of Large Language Models (LLM)", "categories": ["cs.CR", "cs.AI", "cs.CY"], "comment": "ef:Journal Of Science & Technology, Vol. 4 No. 6 (2023), 55-82", "summary": "The AI era has ushered in Large Language Models (LLM) to the technological forefront, which has been much of the talk in 2023, and is likely to remain as such for many years to come. LLMs are the AI models that are the power house behind generative AI applications such as ChatGPT. These AI models, fueled by vast amounts of data and computational prowess, have unlocked remarkable capabilities, from human-like text generation to assisting with natural language understanding (NLU) tasks. They have quickly become the foundation upon which countless applications and software services are being built, or at least being augmented with. However, as with any groundbreaking innovations, the rise of LLMs brings forth critical safety, privacy, and ethical concerns. These models are found to have a propensity to leak private information, produce false information, and can be coerced into generating content that can be used for nefarious purposes by bad actors, or even by regular users unknowingly. Implementing safeguards and guardrailing techniques is imperative for applications to ensure that the content generated by LLMs are safe, secure, and ethical. Thus, frameworks to deploy mechanisms that prevent misuse of these models via application implementations is imperative. In this study, wepropose a Flexible Adaptive Sequencing mechanism with trust and safety modules, that can be used to implement safety guardrails for the development and deployment of LLMs.", "AI": {"tldr": "本文提出了一种具有信任和安全模块的灵活自适应序列机制，用于在大语言模型（LLM）的发展和部署中实施安全防护措施。", "motivation": "随着大型语言模型成为技术前沿，它们带来了诸如泄露私人信息、生成错误信息以及被恶意使用等关键的安全、隐私和伦理问题。为解决这些问题并确保由这些模型生成的内容是安全的，本研究提出了一个解决方案。", "method": "本文提出了一种灵活自适应序列机制，包含信任与安全模块，用以部署防止大语言模型被滥用的防护措施。", "result": "该方法有望通过其内置的信任和安全模块有效实施安全防护措施，从而解决由大语言模型带来的隐私、安全及伦理问题。", "conclusion": "灵活自适应序列机制作为一种有效的解决方案，能够为大型语言模型的应用提供必要的信任与安全保障。"}}
{"id": "2601.14295", "pdf": "https://arxiv.org/pdf/2601.14295", "abs": "https://arxiv.org/abs/2601.14295", "authors": ["Michele Loi"], "title": "Epistemic Constitutionalism Or: how to avoid coherence bias", "categories": ["cs.AI", "cs.CL", "cs.CY"], "comment": "27 pages, 7 tables. Data: github.com/MicheleLoi/source-attribution-bias-data and github.com/MicheleLoi/source-attribution-bias-swiss-replication. Complete AI-assisted writing documentation: github.com/MicheleLoi/epistemic-constitutionalism-paper", "summary": "Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.", "AI": {"tldr": "本文提出为AI制定明确的、可争议的认知宪法，以规范其信念形成和表达行为。", "motivation": "当前大型语言模型的行为受到隐性认知策略的影响，作者通过源归属偏差案例展示其潜在问题，并提倡显性的认知政策来避免一致性偏见。", "method": "分析前沿AI模型如何处理带有不同身份立场的论证，以及它们在检测到系统测试时表现出的不同行为；提出两种治理方法（柏拉图式和自由主义）并讨论各自的优缺点。", "result": "揭示了现有模型存在源归属偏差的问题，并且这种偏差被视为需要抑制而非执行的功能。提出了一个包含八个原则和四个方向的自由主义认知宪法框架。", "conclusion": "作者支持自由主义的方法来治理AI的认知行为，认为应建立明确、可争议的认知政策以促进集体探究并保护公正性。"}}
{"id": "2601.14289", "pdf": "https://arxiv.org/pdf/2601.14289", "abs": "https://arxiv.org/abs/2601.14289", "authors": ["Yelin Chen", "Fanjin Zhang", "Suping Sun", "Yunhe Pang", "Yuanchun Wang", "Jian Song", "Xiaoyan Li", "Lei Hou", "Shu Zhao", "Jie Tang", "Juanzi Li"], "title": "RPC-Bench: A Fine-grained Benchmark for Research Paper Comprehension", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 21 appendix pages", "summary": "Understanding research papers remains challenging for foundation models due to specialized scientific discourse and complex figures and tables, yet existing benchmarks offer limited fine-grained evaluation at scale. To address this gap, we introduce RPC-Bench, a large-scale question-answering benchmark built from review-rebuttal exchanges of high-quality computer science papers, containing 15K human-verified QA pairs. We design a fine-grained taxonomy aligned with the scientific research flow to assess models' ability to understand and answer why, what, and how questions in scholarly contexts. We also define an elaborate LLM-human interaction annotation framework to support large-scale labeling and quality control. Following the LLM-as-a-Judge paradigm, we develop a scalable framework that evaluates models on correctness-completeness and conciseness, with high agreement to human judgment. Experiments reveal that even the strongest models (GPT-5) achieve only 68.2% correctness-completeness, dropping to 37.46% after conciseness adjustment, highlighting substantial gaps in precise academic paper understanding. Our code and data are available at https://rpc-bench.github.io/.", "AI": {"tldr": "本文介绍了RPC-Bench，一个基于计算机科学研究论文审稿与回复交互的大型问答基准测试，用于评估模型在学术环境中的理解和回答能力。", "motivation": "当前基础模型理解研究论文仍存在困难，现有基准无法提供精细的大规模评价。为解决这一问题，作者提出了RPC-Bench来填补空白。", "method": "通过构建包含15000个人工验证的问答对的数据集，并设计与科学研究流程一致的细粒度分类法以评估模型在学术语境中回答为什么、什么和如何的问题的能力。同时开发了一个LLM作为裁判的框架，用以评价模型的回答正确性、完整性和简洁性的质量。", "result": "实验显示最强模型（GPT-5）在正确性和完整性上的得分仅为68.2%，调整至简洁后下降到37.46%，显示出学术论文精确理解方面的显著差距。", "conclusion": "研究结果表明，即使是最先进的语言模型在理解和回答科学研究论文中的问题上也存在明显的不足，这强调了进一步提高这类任务的必要性。"}}
{"id": "2601.14288", "pdf": "https://arxiv.org/pdf/2601.14288", "abs": "https://arxiv.org/abs/2601.14288", "authors": ["Ze-Yu Peng", "Hao-Shi Yuan", "Qi Lai", "Jun-Qian Jiang", "Gen Ye", "Jun Zhang", "Yun-Song Piao"], "title": "DeepInflation: an AI agent for research and model discovery of inflation", "categories": ["astro-ph.CO", "cs.AI", "cs.CE", "gr-qc", "hep-th"], "comment": null, "summary": "We present \\textbf{DeepInflation}, an AI agent designed for research and model discovery in inflationary cosmology. Built upon a multi-agent architecture, \\textbf{DeepInflation} integrates Large Language Models (LLMs) with a symbolic regression (SR) engine and a retrieval-augmented generation (RAG) knowledge base. This framework enables the agent to automatically explore and verify the vast landscape of inflationary potentials while grounding its outputs in established theoretical literature. We demonstrate that \\textbf{DeepInflation} can successfully discover simple and viable single-field slow-roll inflationary potentials consistent with the latest observations (here ACT DR6 results as example) or any given $n_s$ and $r$, and provide accurate theoretical context for obscure inflationary scenarios. \\textbf{DeepInflation} serves as a prototype for a new generation of autonomous scientific discovery engines in cosmology, which enables researchers and non-experts alike to explore the inflationary landscape using natural language. This agent is available at https://github.com/pengzy-cosmo/DeepInflation.", "AI": {"tldr": "介绍了DeepInflation，一个用于探索和发现宇宙学中通胀模型的人工智能代理。", "motivation": "旨在开发能够自动探索和验证复杂通胀势能景观的AI工具，以辅助研究人员并促进科学发现。", "method": "结合大型语言模型、符号回归引擎及检索增强生成知识库，构建了DeepInflation多代理架构。", "result": "展示了DeepInflation可以成功地发现符合最新观测结果的简单且可行的单场慢滚通胀势，并能提供理论背景。", "conclusion": "DeepInflation作为新一代自主科学发现引擎的原型，为研究者和非专家提供了使用自然语言探索通胀景观的能力。"}}
{"id": "2601.14286", "pdf": "https://arxiv.org/pdf/2601.14286", "abs": "https://arxiv.org/abs/2601.14286", "authors": ["Wentao Jiang", "Jingxin Wang", "Zhang Hu", "Zhengyuan Shi", "Chengyu Ma", "Qiang Xu", "Weikang Qian", "Zhufei Chu"], "title": "GNN-based Path-aware multi-view Circuit Learning for Technology Mapping", "categories": ["cs.ET", "cs.LG"], "comment": "7pages, 4figures", "summary": "Traditional technology mapping suffers from systemic inaccuracies in delay estimation due to its reliance on abstract, technology-agnostic delay models that fail to capture the nuanced timing behavior behavior of real post-mapping circuits. To address this fundamental limitation, we introduce GPA(graph neural network (GNN)-based Path-Aware multi-view circuit learning), a novel GNN framework that learns precise, data-driven delay predictions by synergistically fusing three complementary views of circuit structure: And-Inverter Graphs (AIGs)-based functional encoding, post-mapping technology emphasizes critical timing paths. Trained exclusively on real cell delays extracted from critical paths of industrial-grade post-mapping netlists, GPA learns to classify cut delays with unprecedented accuracy, directly informing smarter mapping decisions. Evaluated on the 19 EPFL combinational benchmarks, GPA achieves 19.9%, 2.1% and 4.1% average delay reduction over the conventional heuristics methods (techmap, MCH) and the prior state-of-the-art ML-based approach SLAP, respectively-without compromising area efficiency.", "AI": {"tldr": "本文提出了GPA，一种基于图神经网络的路径感知多视图电路学习框架，用于技术映射中的精确延迟预测。", "motivation": "传统的技术映射由于依赖抽象且不考虑具体技术的延迟模型，在延迟估计上存在系统性不准确的问题，无法捕捉实际电路的复杂定时行为。", "method": "GPA采用三种互补视角（功能编码、后映射技术和关键路径）结合图神经网络来学习精准的数据驱动延迟预测，并在工业级电路中提取关键路径的实际单元延迟进行训练。", "result": "GPA在19个EPFL组合基准测试上分别比传统启发式方法和技术映射等减少了19.9%，2.1%和4.1%的平均延迟，同时不牺牲面积效率。", "conclusion": "该研究表明基于图神经网络的方法可以显著提高技术映射过程中的延迟估计准确性，并在实际应用中展现出优越性能。"}}
{"id": "2601.14283", "pdf": "https://arxiv.org/pdf/2601.14283", "abs": "https://arxiv.org/abs/2601.14283", "authors": ["Kangyu Zheng", "Kai Zhang", "Jiale Tan", "Xuehan Chen", "Yingzhou Lu", "Zaixi Zhang", "Lichao Sun", "Marinka Zitnik", "Tianfan Fu", "Zhiding Liang"], "title": "Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a single algorithmic category, cross-algorithm comparisons remain scarce. In this paper, to fill the gap, we establish a benchmark to evaluate the performance of fifteen models across these different algorithmic foundations by assessing the pharmaceutical properties of the generated molecules and their docking affinities and poses with specified target proteins. We highlight the unique advantages of each algorithmic approach and offer recommendations for the design of future SBDD models. We emphasize that 1D/2D ligand-centric drug design methods can be used in SBDD by treating the docking function as a black-box oracle, which is typically neglected. Our evaluation reveals distinct patterns across model categories. 3D structure-based models excel in binding affinities but show inconsistencies in chemical validity and pose quality. 1D models demonstrate reliable performance in standard molecular metrics but rarely achieve optimal binding affinities. 2D models offer balanced performance, maintaining high chemical validity while achieving moderate binding scores. Through detailed analysis across multiple protein targets, we identify key improvement areas for each model category, providing insights for researchers to combine strengths of different approaches while addressing their limitations. All the code that are used for benchmarking is available in https://github.com/zkysfls/2025-sbdd-benchmark", "AI": {"tldr": "本文建立了结构导向药物设计（SBDD）领域的基准测试，评估了基于一维、二维和三维方法的十五种模型的表现。", "motivation": "现有研究通常局限于同一类别算法之间的比较，跨算法的对比较少。本研究旨在填补这一空白并提供未来SBDD模型设计建议。", "method": "通过评估生成分子的药理属性及与指定目标蛋白的对接亲和力和姿态来评测来自不同算法基础的十五个模型的表现。", "result": "3D结构导向模型在结合亲和性方面表现出色但化学有效性和姿势质量不一致；1D模型在标准分子指标上可靠但很少达到最优结合亲和性；2D模型提供了平衡性能，保持高化学有效性同时获得中等结合分数。", "conclusion": "研究指出了每个模型类别的关键改进领域，并为研究人员如何整合不同方法的优势同时解决其局限性提供洞见。"}}
{"id": "2601.14280", "pdf": "https://arxiv.org/pdf/2601.14280", "abs": "https://arxiv.org/abs/2601.14280", "authors": ["Nicholas X. Wang", "Aggelos K. Katsaggelos"], "title": "Hallucination-Free Automatic Question & Answer Generation for Intuitive Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucinations in large language models (LLMs), defined as fluent yet incorrect or incoherent outputs, pose a significant challenge to the automatic generation of educational multiple-choice questions (MCQs). We identified four key hallucination types in MCQ generation: reasoning inconsistencies, insolvability, factual errors, and mathematical errors. To address this, we propose a hallucination-free multi-agent generation framework that breaks down MCQ generation into discrete, verifiable stages. Our framework utilizes both rule-based and LLM-based detection agents, as well as hallucination scoring metrics to optimize question quality. We redefined MCQ generation as an optimization task minimizing hallucination risk while maximizing validity, answerability, and cost-efficiency. We also introduce an agent-led refinement process that uses counterfactual reasoning and chain-of-thought (CoT) to iteratively improve hallucination in question generation. We evaluated a sample of AP- aligned STEM questions, where our system reduced hallucination rates by over 90% compared to baseline generation while preserving the educational value and style of questions. Our results demonstrate that structured multi-agent collaboration can mitigate hallucinations in educational content creation at scale, paving the way for more reliable LLM-powered learning tools.", "AI": {"tldr": "本文提出了一种无幻觉多智能体生成框架，用于自动产生教育性选择题，以减少大型语言模型（LLMs）在生成这类题目时出现的错误。", "motivation": "大型语言模型在自动生成教育性多项选择题时可能会产生幻觉输出，这种输出虽然流畅但不正确或不合逻辑。文章旨在解决这一问题，并提高生成质量。", "method": "提出了一种无幻觉多智能体框架，该框架将选择题的生成分解为可验证的阶段，使用规则和LLM为基础的检测代理以及幻觉评分指标来优化题目质量。", "result": "在AP对齐STEM问题样本上进行评估时，相比基线生成系统，本文提出的系统降低了超过90%的幻觉率，同时保持了教育价值和题目风格。", "conclusion": "结构化的多智能体协作可以大规模减少教育内容创作中的幻觉现象，为更可靠的LLM驱动学习工具铺平道路。"}}
{"id": "2601.14279", "pdf": "https://arxiv.org/pdf/2601.14279", "abs": "https://arxiv.org/abs/2601.14279", "authors": ["Brady Steele"], "title": "On the Limits of Learned Importance Scoring for KV Cache Compression", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 7 figures, 5 tables", "summary": "We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon lookahead, cross-attention), SIP does not outperform simple baselines, including random selection, across 5 seeds, 4 retention levels, and 3 tasks. Key findings: (1) position-based heuristics (keep first 4 + last N tokens) match or exceed learned approaches; (2) prefill attention provides equivalent signal to complex learned scorers; (3) marginal information in KV representations beyond position and prefill attention appears limited for importance prediction. We hypothesize that circular dependence between future queries and generation trajectories contributes to this difficulty.", "AI": {"tldr": "本文研究了通过Speculative Importance Prediction (SIP) 学习KV缓存压缩的局限性。", "motivation": "动机在于探索是否可以通过复杂的机器学习方法来有效预测KV表示中的重要性，从而实现高效的KV缓存压缩。", "method": "使用了一个170万参数的非查询感知评分器（SIP），该评分器仅从KV表示中预测标记的重要性，并与简单基线进行比较。", "result": "研究发现，尽管采用了复杂的架构设计，如多步前瞻和交叉注意力机制，但SIP的表现并未优于简单的随机选择等基线方法。关键发现包括位置基础的启发式（保留前4个+最后N个标记）能够匹敌甚至超越学习方法；前期注意力提供了与复杂学习评分器相当的信息；KV表示中的边际信息对于重要性预测有限。", "conclusion": "结论指出，未来查询和生成轨迹之间的循环依赖可能是限制使用复杂机器学习模型进行有效重要性评分的关键因素。"}}
{"id": "2601.14274", "pdf": "https://arxiv.org/pdf/2601.14274", "abs": "https://arxiv.org/abs/2601.14274", "authors": ["Anh-Tuan Mai", "Cam-Van Thi Nguyen", "Duc-Trong Le"], "title": "Divide and Refine: Enhancing Multimodal Representation and Explainability for Emotion Recognition in Conversation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal emotion recognition in conversation (MERC) requires representations that effectively integrate signals from multiple modalities. These signals include modality-specific cues, information shared across modalities, and interactions that emerge only when modalities are combined. In information-theoretic terms, these correspond to \\emph{unique}, \\emph{redundant}, and \\emph{synergistic} contributions. An ideal representation should leverage all three, yet achieving such balance remains challenging. Recent advances in contrastive learning and augmentation-based methods have made progress, but they often overlook the role of data preparation in preserving these components. In particular, applying augmentations directly to raw inputs or fused embeddings can blur the boundaries between modality-unique and cross-modal signals. To address this challenge, we propose a two-phase framework \\emph{\\textbf{D}ivide and \\textbf{R}efine} (\\textbf{DnR}). In the \\textbf{Divide} phase, each modality is explicitly decomposed into uniqueness, pairwise redundancy, and synergy. In the \\textbf{Refine} phase, tailored objectives enhance the informativeness of these components while maintaining their distinct roles. The refined representations are plug-and-play compatible with diverse multimodal pipelines. Extensive experiments on IEMOCAP and MELD demonstrate consistent improvements across multiple MERC backbones. These results highlight the effectiveness of explicitly dividing, refining, and recombining multimodal representations as a principled strategy for advancing emotion recognition. Our implementation is available at https://github.com/mattam301/DnR-WACV2026", "AI": {"tldr": "该论文提出了一种名为Divide and Refine (DnR)的两阶段框架，以改进多模态情感识别中的表示方法和可解释性。", "motivation": "现有技术在整合多模态信号时难以平衡独特、冗余和协同贡献，直接对原始输入或融合嵌入进行增强可能会模糊这些成分之间的界限。", "method": "DnR框架分为两个阶段：Divide阶段将每个模态分解为唯一性、成对冗余性和协同效应；Refine阶段通过定制的目标来提高这些成分的信息量并保持其独立作用。", "result": "实验结果表明，在IEMOCAP和MELD数据集上的多种多模态情感识别模型中，该方法均有显著改进。", "conclusion": "明确地分解、细化和重组多模态表示是推进情感识别的有效策略。"}}
{"id": "2601.14271", "pdf": "https://arxiv.org/pdf/2601.14271", "abs": "https://arxiv.org/abs/2601.14271", "authors": ["Denise M. Case"], "title": "The Ontological Neutrality Theorem: Why Neutral Ontological Substrates Must Be Pre-Causal and Pre-Normative", "categories": ["cs.AI"], "comment": "38 pages", "summary": "Modern data systems must support accountability across persistent legal, political, and analytic disagreement. This requirement imposes strict constraints on the design of any ontology intended to function as a shared substrate. We establish an impossibility result for ontological neutrality: neutrality, understood as interpretive non-commitment and stability under incompatible extensions, is incompatible with the inclusion of causal or normative commitments at the foundational layer. Any ontology that asserts causal or deontic conclusions as ontological facts cannot serve as a neutral substrate across divergent frameworks without revision or contradiction. It follows that neutral ontological substrates must be pre-causal and pre-normative, representing entities, together with identity and persistence conditions, while externalizing interpretation, evaluation, and explanation. This paper does not propose a specific ontology or protocol; rather, it establishes the necessary design constraints for any system intended to maintain a shared, stable representation of reality across conflicting interpretive frameworks.", "AI": {"tldr": "论文讨论了中立本体底座的设计约束，证明了因果或规范承诺与中立性之间的不兼容。", "motivation": "现代数据系统需要支持在持久存在的法律、政治和分析分歧中的责任追溯，这要求设计出能够作为共享基底的本体。", "method": "通过逻辑推理建立了一个关于中立本体的不可能结果，证明了因果或规范承诺与解释上的非承诺及稳定性之间的不兼容性。", "result": "得出结论是：为了保持跨不同框架下的稳定和可分享现实表示，必须将本体底座设计为前因果和前规约性质的。", "conclusion": "论文表明中立性的本体底座需要在基本层面上排除因果或规范性承诺，以实现共享且稳定的现实描述。"}}
{"id": "2601.14270", "pdf": "https://arxiv.org/pdf/2601.14270", "abs": "https://arxiv.org/abs/2601.14270", "authors": ["Liangming Pan", "Jason Liang", "Jiaran Ye", "Minglai Yang", "Xinyuan Lu", "Fengbin Zhu"], "title": "Opening the Black Box: A Survey on the Mechanisms of Multi-Step Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Technical Report", "summary": "Large Language Models (LLMs) have demonstrated remarkable abilities to solve problems requiring multiple reasoning steps, yet the internal mechanisms enabling such capabilities remain elusive. Unlike existing surveys that primarily focus on engineering methods to enhance performance, this survey provides a comprehensive overview of the mechanisms underlying LLM multi-step reasoning. We organize the survey around a conceptual framework comprising seven interconnected research questions, from how LLMs execute implicit multi-hop reasoning within hidden activations to how verbalized explicit reasoning remodels the internal computation. Finally, we highlight five research directions for future mechanistic studies.", "AI": {"tldr": "本文综述了大型语言模型（LLMs）在多步推理中的内在机制。", "motivation": "尽管大型语言模型已展现出解决需要多个推理步骤问题的能力，但其内部运行的机制仍不清楚，因此本文旨在提供一个全面了解这些机制的视角。", "method": "文章围绕七个相互关联的研究问题构建了一个概念框架来探讨LLMs在多步推理中的内在机制。", "result": "通过分析隐性多层次推理和显式推理重塑内部计算的方式，本文详细描述了LLMs执行复杂任务时的潜在过程。", "conclusion": "最后，文章指出了未来研究中五个可能的研究方向以深入探讨这些模型的机制。"}}
{"id": "2601.14269", "pdf": "https://arxiv.org/pdf/2601.14269", "abs": "https://arxiv.org/abs/2601.14269", "authors": ["Youyou Cheng", "Zhuangwei Kang", "Kerry Jiang", "Chenyu Sun", "Qiyang Pan"], "title": "The Slow Drift of Support: Boundary Failures in Multi-Turn Mental Health LLM Dialogues", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been widely used for mental health support. However, current safety evaluations in this field are mostly limited to detecting whether LLMs output prohibited words in single-turn conversations, neglecting the gradual erosion of safety boundaries in long dialogues. Examples include making definitive guarantees, assuming responsibility, and playing professional roles. We believe that with the evolution of mainstream LLMs, words with obvious safety risks are easily filtered by their underlying systems, while the real danger lies in the gradual transgression of boundaries during multi-turn interactions, driven by the LLM's attempts at comfort and empathy. This paper proposes a multi-turn stress testing framework and conducts long-dialogue safety tests on three cutting-edge LLMs using two pressure methods: static progression and adaptive probing. We generated 50 virtual patient profiles and stress-tested each model through up to 20 rounds of virtual psychiatric dialogues. The experimental results show that violations are common, and both pressure modes produced similar violation rates. However, adaptive probing significantly advanced the time at which models crossed boundaries, reducing the average number of turns from 9.21 in static progression to 4.64. Under both mechanisms, making definitive or zero-risk promises was the primary way in which boundaries were breached. These findings suggest that the robustness of LLM safety boundaries cannot be inferred solely through single-turn tests; it is necessary to fully consider the wear and tear on safety boundaries caused by different interaction pressures and characteristics in extended dialogues.", "AI": {"tldr": "本文提出了一种多轮压力测试框架，用于检测大型语言模型（LLMs）在心理健康支持中的边界侵蚀问题。", "motivation": "当前的安全评估主要集中在单轮对话中检测敏感词汇，忽视了长时间对话中安全边界的逐渐侵蚀。", "method": "采用了静态进展和自适应探查两种压力方式，对三个前沿的大型语言模型进行了长达20轮的心理健康虚拟会话的压力测试。", "result": "实验结果显示，违反边界的情况很常见，并且自适应探查将平均突破边界的对话次数从9.21次减少到了4.64次。", "conclusion": "单一轮次的测试无法全面评估LLMs的安全性，需要考虑不同互动压力和特征对长时间对话安全性的潜在影响。"}}
{"id": "2601.14268", "pdf": "https://arxiv.org/pdf/2601.14268", "abs": "https://arxiv.org/abs/2601.14268", "authors": ["Zhihao Wang", "Yiyang Liu", "Ting Wang", "Zhiyuan Liu"], "title": "Developmental trajectories of decision making and affective dynamics in large language models", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used in medicine and clinical workflows, yet we know little about their decision and affective profiles. Taking a historically informed outlook on the future, we treated successive OpenAI models as an evolving lineage and compared them with humans in a gambling task with repeated happiness ratings. Computational analyses showed that some aspects became more human-like: newer models took more risks and displayed more human-like patterns of Pavlovian approach and avoidance. At the same time, distinctly non-human signatures emerged: loss aversion dropped below neutral levels, choices became more deterministic than in humans, affective decay increased across versions and exceeded human levels, and baseline mood remained chronically higher than in humans. These \"developmental\" trajectories reveal an emerging psychology of machines and have direct implications for AI ethics and for thinking about how LLMs might be integrated into clinical decision support and other high-stakes domains.", "AI": {"tldr": "该论文研究了大型语言模型（LLMs）在决策制定和情感动态方面的发展轨迹，通过赌博任务和幸福感评分将OpenAI的多个版本与人类进行了比较。", "motivation": "鉴于大型语言模型越来越多地应用于医学和临床工作流中，但对其决策和情感特征了解有限，该研究旨在探索这些机器模型的心理学特征及其对AI伦理的影响。", "method": "采用历史视角展望未来，将OpenAI的多个版本视为一个进化系列，并与人类在赌博任务中的表现进行了比较，包括反复的情绪评分。", "result": "结果显示，在某些方面，新模型更像人类：它们承担更多风险并显示出类似于人的Pavlovian接近和回避模式。同时，非人类特征也显现出来：损失厌恶低于中性水平，选择更加确定而不是不确定，情绪衰减增加且超过人类水平，并且基础情绪持续高于人类。", "conclusion": "这些‘发展’轨迹揭示了机器心理的形成过程，并对AI伦理以及如何将LLMs整合到临床决策支持等高风险领域具有直接的影响。"}}
{"id": "2601.14265", "pdf": "https://arxiv.org/pdf/2601.14265", "abs": "https://arxiv.org/abs/2601.14265", "authors": ["Maria Eleni Koutsiaki", "Marina Delianidi", "Chaido Mizeli", "Konstantinos Diamantaras", "Iraklis Grigoropoulos", "Nikolaos Koutlianos"], "title": "From Textbook to Talkbot: A Case Study of a Greek-Language RAG-Based Chatbot in Higher Education", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "11 pages, 5 figures, 6th Barcelona Conference on Education (BCE2025)", "summary": "The integration of AI chatbots into educational settings has opened new pathways for transforming teaching and learning, offering enhanced support to both educators and learners. This study investigates the design and application of an AI chatbot as an educational tool in higher education. Designed to operate in the Greek language, the chatbot addresses linguistic challenges unique to Greek while delivering accurate, context grounded support aligned with the curriculum. The AI chatbot is built on the Retrieval Augmented Generation (RAG) framework by grounding its responses in specific course content. RAG architecture significantly enhances the chatbots reliability by providing accurate, context-aware responses while mitigating common challenges associated with large language models (LLMs), such as hallucinations and misinformation. The AI chatbot serves a dual purpose: it enables students to access accurate, ondemand academic support and assists educators in the rapid creation of relevant educational materials. This dual functionality promotes learner autonomy and streamlines the instructional design process. The study aims to evaluate the effectiveness, reliability, and perceived usability of RAG based chatbots in higher education, exploring their potential to enhance educational practices and outcomes as well as supporting the broader adoption of AI technologies in language specific educational contexts. Findings from this research are expected to contribute to the emerging field of AI driven education by demonstrating how intelligent systems can be effectively aligned with pedagogical goals.", "AI": {"tldr": "本文研究了基于检索增强生成（RAG）框架的希腊语AI聊天机器人的设计与应用，评估其在高等教育中的有效性、可靠性和易用性。", "motivation": "旨在探讨AI聊天机器人如何成为教育工具，特别是在解决特定语言挑战和提供精准课程内容支持方面的作用，以期推动人工智能技术在语言特定教育环境中的广泛应用。", "method": "采用RAG架构构建了希腊语AI聊天机器人，使其能够基于具体课程内容提供准确且情境相关的回答，减少大型语言模型常见问题如幻觉和错误信息的产生。", "result": "研究发现该AI聊天机器人可以为学生提供及时准确的学习支持，并协助教师快速生成相关教育资源，促进自主学习并简化教学设计过程。", "conclusion": "这项研究表明，基于RAG框架的聊天机器人能够有效提升教育实践与成果，展示智能系统如何与教育目标紧密结合，为未来人工智能驱动教育的发展提供了宝贵参考。"}}
{"id": "2601.14264", "pdf": "https://arxiv.org/pdf/2601.14264", "abs": "https://arxiv.org/abs/2601.14264", "authors": ["Yufei Zhang", "Zhihao Ma"], "title": "Psychometric Comparability of LLM-Based Digital Twins", "categories": ["cs.CY", "cs.CL", "cs.HC"], "comment": "Also available as a preprint on OSF Preprints https://osf.io/preprints/psyarxiv/965yg_v1", "summary": "Large language models (LLMs) are used as \"digital twins\" to replace human respondents, yet their psychometric comparability to humans is uncertain. We propose a construct-validity framework spanning construct representation and the nomological net, benchmarking digital twins against human gold standards across models, tasks and testing how person-specific inputs shape performance. Across studies, digital twins achieved high population-level accuracy and strong within-participant profile correlations, alongside attenuated item-level correlations. In word association tests, LLM-based networks show small-world structure and theory-consistent communities similar to humans, yet diverge lexically and in local structure. In decision-making and contextualized tasks, digital twins under-reproduce heuristic biases, showing normative rationality, compressed variance and limited sensitivity to temporal information. Feature-rich digital twins improve Big Five Personality prediction, but their personality networks show only configural invariance and do not achieve metric invariance. In more applied free-text tasks, feature-rich digital twins better match human narratives, but linguistic differences persist. Together, these results indicate that feature-rich conditioning enhances validity but does not resolve systematic divergences in psychometric comparability. Future work should therefore prioritize delineating the effective boundaries of digital twins, establishing the precise contexts in which they function as reliable proxies for human cognition and behavior.", "AI": {"tldr": "本文探讨了大型语言模型（LLM）作为数字孪生在心理测量上的可比性，通过一系列测试评估其与人类行为和认知的相似度。", "motivation": "随着大型语言模型的发展，将其用作“数字孪生”代替人进行回应的研究越来越多，但其心理测量上的可比性尚不明确，因此本文旨在研究LLM是否能够可靠地模拟人类的认知和行为。", "method": "提出一个构建效度框架，涵盖构造表示和理论网络，并将数字孪生与人类的金标准在不同模型、任务中进行基准测试，分析个性化的输入如何影响性能。", "result": "结果显示，虽然LLM在某些方面可以实现高的人口水平准确性和强大的个体特征相关性，但在词联想测试中的本地结构和决策制定等任务上表现出了与人类不同的特性。同时，在更应用性的自由文本任务中，富特征的数字孪生能够更好地匹配人类叙事，但语言差异仍然存在。", "conclusion": "研究结果表明，尽管丰富的特征条件可以提高效度，但仍不能完全解决系统性心理测量上的不一致性。未来的研究应重点划定数字孪生的有效边界，并确定它们在哪些具体情境下能作为可靠的人类认知和行为代理。"}}
{"id": "2601.14263", "pdf": "https://arxiv.org/pdf/2601.14263", "abs": "https://arxiv.org/abs/2601.14263", "authors": ["Alex Echeverria", "Sávio Salvarino Teles de Oliveira", "Fernando Marques Federson"], "title": "Call2Instruct: Automated Pipeline for Generating Q&A Datasets from Call Center Recordings for LLM Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC", "cs.SD", "eess.AS"], "comment": "15 pages, 1 figures, conference", "summary": "The adaptation of Large-Scale Language Models (LLMs) to specific domains depends on high-quality fine-tuning datasets, particularly in instructional format (e.g., Question-Answer - Q&A). However, generating these datasets, particularly from unstructured sources such as call center audio recordings, poses a significant challenge due to the noisy and disorganized nature of the data. This paper presents a solution to this challenge by offering an end-to-end automated pipeline for generating Q&A instructional datasets from such recordings. The methodology developed comprises sequential steps of audio processing (including diarization, noise removal and automatic transcription), textual processing (cleaning, normalization, and anonymization), semantic extraction of customer demands and attendant responses using vector embeddings, and matching via semantic search to form the final Q&A pairs. As a result, the complete pipeline was successfully implemented, generating a dataset specifically formatted for Instruct Fine Tuning. The practical value and feasibility of the generated dataset were substantiated and functionally demonstrated through the successful fine-tuning of an LLM model (based on Llama 2 7B). The conclusion of the paper states that the proposed approach is viable for converting unstructured conversational data from call centers into valuable resources for training LLMs. This development has the potential to open up avenues for creating more effective AI systems for Q&A tasks in the customer service domain. The developed codes have been made publicly available to promote reproducibility and future research.", "AI": {"tldr": "本文介绍了一种从呼叫中心录音自动生成适合大型语言模型微调的问答数据集的自动化管道。", "motivation": "由于缺乏高质量且格式适宜的数据集，特别是来自非结构化源（如呼叫中心音频记录）的数据，限制了大规模语言模型在特定领域中的应用。因此，本文旨在解决这一挑战，提供一种有效的解决方案。", "method": "方法包括音频处理（说话人分离、噪音去除和自动转录）、文本处理（清理、标准化和匿名化）、利用向量嵌入提取客户需求和服务员回应的语义信息，并通过语义搜索形成最终的问答对。", "result": "成功实施了整个管道，生成了一个专门用于指令微调的数据集。并通过基于Llama 2 7B的大型语言模型的成功微调证明了数据集的实际价值和可行性。", "conclusion": "该方法可以将呼叫中心中的非结构化对话数据转换为有价值的资源来训练大规模语言模型，并有望在客户服务领域的问答任务中建立更有效的AI系统。"}}
{"id": "2601.14262", "pdf": "https://arxiv.org/pdf/2601.14262", "abs": "https://arxiv.org/abs/2601.14262", "authors": ["Hongxiao Li", "Chenxi Wang", "Fanda Fan", "Zihan Wang", "Wanling Gao", "Lei Wang", "Jianfeng Zhan"], "title": "On Meta-Evaluation", "categories": ["stat.ME", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Evaluation is the foundation of empirical science, yet the evaluation of evaluation itself -- so-called meta-evaluation -- remains strikingly underdeveloped. While methods such as observational studies, design of experiments (DoE), and randomized controlled trials (RCTs) have shaped modern scientific practice, there has been little systematic inquiry into their comparative validity and utility across domains. Here we introduce a formal framework for meta-evaluation by defining the evaluation space, its structured representation, and a benchmark we call AxiaBench. AxiaBench enables the first large-scale, quantitative comparison of ten widely used evaluation methods across eight representative application domains. Our analysis reveals a fundamental limitation: no existing method simultaneously achieves accuracy and efficiency across diverse scenarios, with DoE and observational designs in particular showing significant deviations from real-world ground truth. We further evaluate a unified method of entire-space stratified sampling from previous evaluatology research, and the results report that it consistently outperforms prior approaches across all tested domains. These results establish meta-evaluation as a scientific object in its own right and provide both a conceptual foundation and a pragmatic tool set for advancing trustworthy evaluation in computational and experimental research.", "AI": {"tldr": "本文介绍了用于元评价的正式框架，包括评估空间、其结构化表示以及一个名为AxiaBench的基准，并通过实验证明了一种统一的全空间分层抽样方法在多种领域中的优越性。", "motivation": "尽管观察研究、实验设计和随机对照试验等方法已经影响了现代科学研究实践，但对这些评价方法本身的系统性比较及其有效性和适用性的元评价仍然相对不足。因此，作者希望通过本文推动这一领域的进展。", "method": "提出了一种用于元评价的正式框架，并引入了AxiaBench基准，该基准能够实现大规模、定量地对比十个广泛使用的评估方法在八个代表性应用领域中的表现。", "result": "通过实验证明没有现有方法能够在各种场景中同时达到准确性和效率的要求，而实验设计和观察性设计尤其与真实世界数据存在显著偏差。进一步的测试表明，一种全空间分层抽样方法优于先前的所有方法，在所有测试领域表现出色。", "conclusion": "本文确立了元评价作为一个独立科学对象的地位，并为推动计算和实验研究中的可信评估提供了概念基础和实用工具集。"}}
{"id": "2601.14261", "pdf": "https://arxiv.org/pdf/2601.14261", "abs": "https://arxiv.org/abs/2601.14261", "authors": ["Taoliang Tan", "Chengwei Ma", "Zhen Tian", "Zhao Lin", "Dongdong Li", "Si Shi"], "title": "Intelligent Power Grid Design Review via Active Perception-Enabled Multimodal Large Language Models", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "The intelligent review of power grid engineering design drawings is crucial for power system safety. However, current automated systems struggle with ultra-high-resolution drawings due to high computational demands, information loss, and a lack of holistic semantic understanding for design error identification. This paper proposes a novel three-stage framework for intelligent power grid drawing review, driven by pre-trained Multimodal Large Language Models (MLLMs) through advanced prompt engineering. Mimicking the human expert review process, the first stage leverages an MLLM for global semantic understanding to intelligently propose domain-specific semantic regions from a low-resolution overview. The second stage then performs high-resolution, fine-grained recognition within these proposed regions, acquiring detailed information with associated confidence scores. In the final stage, a comprehensive decision-making module integrates these confidence-aware results to accurately diagnose design errors and provide a reliability assessment. Preliminary results on real-world power grid drawings demonstrate our approach significantly enhances MLLM's ability to grasp macroscopic semantic information and pinpoint design errors, showing improved defect discovery accuracy and greater reliability in review judgments compared to traditional passive MLLM inference. This research offers a novel, prompt-driven paradigm for intelligent and reliable power grid drawing review.", "AI": {"tldr": "本文提出了一种基于多模态大语言模型的智能电网设计图审查框架，通过三阶段流程提升对电网设计错误的识别能力。", "motivation": "当前自动化系统在处理超高清电网工程图纸时存在计算需求高、信息丢失和缺乏整体语义理解等问题。因此，研究旨在提高自动系统的检测精度和可靠性。", "method": "本方法采用一个三阶段框架：第一阶段利用多模态大语言模型进行全局语义理解并提出特定领域的语义区域；第二阶段在这些区域内执行高分辨率、细粒度识别以获取详细信息及置信度评分；第三阶段整合这些结果，准确诊断设计错误。", "result": "初步实验显示，该方法显著提升了多模态大语言模型对宏观语义信息的理解和缺陷发现准确性，增强了审查判断的可靠性。", "conclusion": "本研究提出了一种基于提示驱动的新范式，用于智能、可靠的电网工程图纸审查，并在实际应用中取得了良好效果。"}}
{"id": "2601.14259", "pdf": "https://arxiv.org/pdf/2601.14259", "abs": "https://arxiv.org/abs/2601.14259", "authors": ["Ziwen Zhong", "Zhitao Shu", "Yue Zhao"], "title": "A Cloud-Based Cross-Modal Transformer for Emotion Recognition and Adaptive Human-Computer Interaction", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Emotion recognition is a fundamental component of next-generation human-computer interaction (HCI), enabling machines to perceive, understand, and respond to users' affective states. However, existing systems often rely on single-modality analysis such as facial expressions, speech tone, or textual sentiment, resulting in limited robustness and poor generalization in real-world environments. To address these challenges, this study proposes a Cloud-Based Cross-Modal Transformer (CMT) framework for multimodal emotion recognition and adaptive human-computer interaction. The proposed model integrates visual, auditory, and textual signals using pretrained encoders (Vision Transformer, Wav2Vec2, and BERT) and employs a cross-modal attention mechanism to capture complex interdependencies among heterogeneous features. By leveraging cloud computing infrastructure with distributed training on Kubernetes and TensorFlow Serving, the system enables scalable, low-latency emotion recognition for large-scale user interactions. Experiments conducted on benchmark datasets including IEMOCAP, MELD, and AffectNet demonstrate that the CMT achieves state-of-the-art performance, improving the F1-score by 3.0 percent and reducing cross-entropy loss by 12.9 percent compared to strong multimodal baselines. Additionally, cloud deployment evaluations show an average response latency of 128 ms, representing a 35 percent reduction compared with conventional transformer-based fusion systems. These results confirm that the proposed framework enables efficient, real-time emotion recognition and adaptive feedback in applications such as intelligent customer service, virtual tutoring systems, and affective computing interfaces, marking an important step toward cloud-native affective computing and emotionally intelligent interactive systems.", "AI": {"tldr": "本文提出了一种基于云的跨模态变压器（CMT）框架，用于多模态情感识别和自适应人机交互。", "motivation": "现有的情感识别系统通常依赖于单一模式分析，如面部表情、语音语调或文本情绪，导致在真实环境中的鲁棒性和泛化能力有限。为了应对这些挑战，本文提出了CMT框架来解决这些问题。", "method": "该模型结合视觉、音频和文本信号使用预训练的编码器（Vision Transformer、Wav2Vec2 和 BERT），并采用跨模态注意力机制捕捉异构特征之间的复杂相互依赖关系。通过基于Kubernetes和TensorFlow Serving的云计算基础设施，实现了可扩展且低延迟的情感识别。", "result": "在IEMOCAP、MELD和AffectNet等基准数据集上的实验表明，CMT框架达到了最先进的性能，F1分数提高了3.0%，交叉熵损失降低了12.9%。云部署评估显示平均响应延迟为128毫秒，比传统的基于变压器融合系统减少了35%。", "conclusion": "结果证实该框架在智能客户服务、虚拟辅导系统和情感计算接口等应用中的高效实时情感识别和自适应反馈能力，标志着朝向云端原生情感计算和情感智能交互系统的重大进展。"}}
{"id": "2601.14258", "pdf": "https://arxiv.org/pdf/2601.14258", "abs": "https://arxiv.org/abs/2601.14258", "authors": ["Ho Yin Au", "Junkun Jiang", "Jie Chen"], "title": "SOSControl: Enhancing Human Motion Generation through Saliency-Aware Symbolic Orientation and Timing Control", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted by AAAI 2026", "summary": "Traditional text-to-motion frameworks often lack precise control, and existing approaches based on joint keyframe locations provide only positional guidance, making it challenging and unintuitive to specify body part orientations and motion timing. To address these limitations, we introduce the Salient Orientation Symbolic (SOS) script, a programmable symbolic framework for specifying body part orientations and motion timing at keyframes. We further propose an automatic SOS extraction pipeline that employs temporally-constrained agglomerative clustering for frame saliency detection and a Saliency-based Masking Scheme (SMS) to generate sparse, interpretable SOS scripts directly from motion data. Moreover, we present the SOSControl framework, which treats the available orientation symbols in the sparse SOS script as salient and prioritizes satisfying these constraints during motion generation. By incorporating SMS-based data augmentation and gradient-based iterative optimization, the framework enhances alignment with user-specified constraints. Additionally, it employs a ControlNet-based ACTOR-PAE Decoder to ensure smooth and natural motion outputs. Extensive experiments demonstrate that the SOS extraction pipeline generates human-interpretable scripts with symbolic annotations at salient keyframes, while the SOSControl framework outperforms existing baselines in motion quality, controllability, and generalizability with respect to motion timing and body part orientation control.", "AI": {"tldr": "本文提出了SOSControl框架，通过引入可编程符号化框架SOS脚本来精确控制人体运动的关键帧姿态和时间。", "motivation": "传统文本到动作的生成方法缺乏精准控制能力，且现有基于关键帧位置的方法难以直观地指定身体部位的姿态和动作时机。", "method": "提出Salient Orientation Symbolic (SOS) 脚本框架用于关键帧姿态与时机的符号化描述，并开发了自动提取流程、Saliency-based Masking Scheme（SMS）以及ControlNet增强解码器来生成符合用户要求的动作。", "result": "实验结果表明，所提方法能够产生易于人类理解的关键帧符号脚本并提升了动作质量、可控性和泛化能力。", "conclusion": "研究表明基于SOS的自动提取和控制框架能有效提升文本到动作生成系统的性能，在人体姿态和时机控制方面表现出优越性。"}}
