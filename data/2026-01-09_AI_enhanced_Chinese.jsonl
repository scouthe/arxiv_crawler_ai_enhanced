{"id": "2601.05251", "pdf": "https://arxiv.org/pdf/2601.05251", "abs": "https://arxiv.org/abs/2601.05251", "authors": ["Zeren Jiang", "Chuanxia Zheng", "Iro Laina", "Diane Larlus", "Andrea Vedaldi"], "title": "Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video", "categories": ["cs.CV"], "comment": "15 pages, 8 figures, project page: https://mesh-4d.github.io/", "summary": "We propose Mesh4D, a feed-forward model for monocular 4D mesh reconstruction. Given a monocular video of a dynamic object, our model reconstructs the object's complete 3D shape and motion, represented as a deformation field. Our key contribution is a compact latent space that encodes the entire animation sequence in a single pass. This latent space is learned by an autoencoder that, during training, is guided by the skeletal structure of the training objects, providing strong priors on plausible deformations. Crucially, skeletal information is not required at inference time. The encoder employs spatio-temporal attention, yielding a more stable representation of the object's overall deformation. Building on this representation, we train a latent diffusion model that, conditioned on the input video and the mesh reconstructed from the first frame, predicts the full animation in one shot. We evaluate Mesh4D on reconstruction and novel view synthesis benchmarks, outperforming prior methods in recovering accurate 3D shape and deformation.", "AI": {"tldr": "提出Mesh4D模型，用于从单目视频中进行4D网格重建。", "motivation": "为了实现从单目视频中准确地重建动态对象的完整3D形状和运动，并且在推断时不需要骨骼信息。", "method": "利用自编码器学习一个紧凑的潜在空间来表示整个动画序列，训练过程中通过引导训练物体的骨骼结构提供强大的先验知识。使用时空注意力机制提高整体变形的稳定性，在此基础上训练条件扩散模型进行完整动画预测。", "result": "在重建和新视角合成基准测试中超越了先前的方法，能够更准确地恢复3D形状和变形。", "conclusion": "Mesh4D通过从单目视频中高效、准确地重建动态对象的4D网格结构，展示了其优越性能。"}}
{"id": "2601.05250", "pdf": "https://arxiv.org/pdf/2601.05250", "abs": "https://arxiv.org/abs/2601.05250", "authors": ["Daniele Lizzio Bosco", "Shuteng Wang", "Giuseppe Serra", "Vladislav Golyanik"], "title": "QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer", "categories": ["cs.CV"], "comment": "30 pages, 15 figures, 11 tables; project page: https://4dqv.mpi-inf.mpg.de/QNeRF/", "summary": "Recently, Quantum Visual Fields (QVFs) have shown promising improvements in model compactness and convergence speed for learning the provided 2D or 3D signals. Meanwhile, novel-view synthesis has seen major advances with Neural Radiance Fields (NeRFs), where models learn a compact representation from 2D images to render 3D scenes, albeit at the cost of larger models and intensive training. In this work, we extend the approach of QVFs by introducing QNeRF, the first hybrid quantum-classical model designed for novel-view synthesis from 2D images. QNeRF leverages parameterised quantum circuits to encode spatial and view-dependent information via quantum superposition and entanglement, resulting in more compact models compared to the classical counterpart. We present two architectural variants. Full QNeRF maximally exploits all quantum amplitudes to enhance representational capabilities. In contrast, Dual-Branch QNeRF introduces a task-informed inductive bias by branching spatial and view-dependent quantum state preparations, drastically reducing the complexity of this operation and ensuring scalability and potential hardware compatibility. Our experiments demonstrate that -- when trained on images of moderate resolution -- QNeRF matches or outperforms classical NeRF baselines while using less than half the number of parameters. These results suggest that quantum machine learning can serve as a competitive alternative for continuous signal representation in mid-level tasks in computer vision, such as 3D representation learning from 2D observations.", "AI": {"tldr": "本文介绍了一种新的混合量子经典模型QNeRF，用于从2D图像进行新视角合成。", "motivation": "神经辐射场（NeRF）虽然在学习紧凑的表示形式以渲染三维场景方面取得了重大进展，但其模型较大且训练强度高。为此，该文通过扩展Quantum Visual Fields (QVFs)方法提出了QNeRF，旨在利用量子计算来提高模型的紧凑性和收敛速度。", "method": "QNeRF使用参数化量子电路编码空间和视图依赖信息，并提出两种架构变体：全量级QNeRF和双分支QNeRF。前者最大化地利用所有量子幅度以增强表示能力，而后者通过分叉空间和视图相关量子态准备引入任务引导的归纳偏差。", "result": "实验表明，在训练中等分辨率图像时，QNeRF在使用不到经典模型一半参数的情况下能匹敌或超越基线模型的表现。", "conclusion": "结果表明量子机器学习可以作为计算机视觉中级任务（如从2D观测到3D表示）的连续信号表示的竞争性替代方案。"}}
{"id": "2601.05249", "pdf": "https://arxiv.org/pdf/2601.05249", "abs": "https://arxiv.org/abs/2601.05249", "authors": ["Yuan-Kang Lee", "Kuan-Lin Chen", "Chia-Che Chang", "Yu-Lun Liu"], "title": "RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes", "categories": ["cs.CV"], "comment": "Project page: https://ntuneillee.github.io/research/rl-awb/", "summary": "Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime dataset. Experiment results demonstrate that our method achieves superior generalization capability across low-light and well-illuminated images. Project page: https://ntuneillee.github.io/research/rl-awb/", "AI": {"tldr": "提出了一种结合统计方法和深度强化学习的夜间自动白平衡修正框架RL-AWB。", "motivation": "夜间色彩一致性由于低光噪声和复杂照明条件，仍然是计算摄影中的挑战问题。通过引入深度强化学习，希望改进自动白平衡调整的能力。", "method": "该方法首先采用针对夜间场景的统计算法，结合显著灰像素检测和新的光照估计技术；然后利用统计算法作为核心开发首个用于颜色一致性校正的深度强化学习框架，并动态优化图像参数。", "result": "实验结果显示，所提出的方法在低光和良好照明条件下均具有优越的泛化能力。", "conclusion": "RL-AWB框架成功地提高了夜间自动白平衡调整的效果，并展示了其跨传感器评估的能力。"}}
{"id": "2601.05248", "pdf": "https://arxiv.org/pdf/2601.05248", "abs": "https://arxiv.org/abs/2601.05248", "authors": ["Zhuoyang Liu", "Jiaming Liu", "Hao Chen", "Ziyu Guo", "Chengkai Hou", "Chenyang Gu", "Jiale Yu", "Xiangju Mi", "Renrui Zhang", "Zhengping Che", "Jian Tang", "Pheng-Ann Heng", "Shanghang Zhang"], "title": "LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0", "AI": {"tldr": "本文提出了LaST$_{0}$框架，通过隐式时空推理链（CoT）来提高机器人视觉-语言-行动模型的准确性与效率。", "motivation": "现有的VLA方法通常通过显式生成语言推导痕迹或未来的视觉观察来提高操作精度，但这种方法会引入非可忽略的时间延迟，并且局限于语言空间，难以捕捉细微物理属性。因此，提出LaST$_{0}$框架以克服这些问题。", "method": "LaST$_{0}$采用隐式时空推理链（CoT）模型未来视觉动态、3D结构信息和机器人本体状态，并扩展这些表示以实现时间一致的隐式推理轨迹；同时使用双系统架构，通过混合变换器设计，其中推理专家执行低频度潜推理，行动专家生成基于机器人导向的潜在表达的动作。", "result": "在模拟和现实世界中的操作任务中，LaST$_{0}$分别提高了平均成功率8%和13%，并且实现了显著更快的推断速度。", "conclusion": "LaST$_{0}$通过高效隐式推理链（CoT）改善了机器人视觉-语言-行动模型的表现，并在多个实验中验证了其优越性。"}}
{"id": "2601.05246", "pdf": "https://arxiv.org/pdf/2601.05246", "abs": "https://arxiv.org/abs/2601.05246", "authors": ["Gangwei Xu", "Haotong Lin", "Hongcheng Luo", "Haiyang Sun", "Bing Wang", "Guang Chen", "Sida Peng", "Hangjun Ye", "Xin Yang"], "title": "Pixel-Perfect Visual Geometry Estimation", "categories": ["cs.CV"], "comment": "Code: https://github.com/gangweix/pixel-perfect-depth", "summary": "Recovering clean and accurate geometry from images is essential for robotics and augmented reality. However, existing geometry foundation models still suffer severely from flying pixels and the loss of fine details. In this paper, we present pixel-perfect visual geometry models that can predict high-quality, flying-pixel-free point clouds by leveraging generative modeling in the pixel space. We first introduce Pixel-Perfect Depth (PPD), a monocular depth foundation model built upon pixel-space diffusion transformers (DiT). To address the high computational complexity associated with pixel-space diffusion, we propose two key designs: 1) Semantics-Prompted DiT, which incorporates semantic representations from vision foundation models to prompt the diffusion process, preserving global semantics while enhancing fine-grained visual details; and 2) Cascade DiT architecture that progressively increases the number of image tokens, improving both efficiency and accuracy. To further extend PPD to video (PPVD), we introduce a new Semantics-Consistent DiT, which extracts temporally consistent semantics from a multi-view geometry foundation model. We then perform reference-guided token propagation within the DiT to maintain temporal coherence with minimal computational and memory overhead. Our models achieve the best performance among all generative monocular and video depth estimation models and produce significantly cleaner point clouds than all other models.", "AI": {"tldr": "本文提出了一种基于像素空间扩散转换器的新型视觉几何模型，用于生成高质量、无飞点的点云。", "motivation": "现有的几何基础模型仍然存在大量飞点和细节丢失的问题。为了克服这些问题，研究人员开发了新的方法来提高图像中准确几何结构的恢复。", "method": "首先引入Pixel-Perfect Depth (PPD)，这是基于像素空间扩散变换器（DiT）构建的一种单目深度基础模型。为解决像素空间扩散相关的高计算复杂度问题，设计了两种关键机制：1) 引入语义提示DiT将视觉基础模型中的语义表示用于引导扩散过程；2) 提出级联DiT架构逐步增加图像令牌的数量，从而提高效率和准确性。进一步扩展PPD到视频（PPVD），引入了一个新的时间一致性DiT，从多视图几何基础模型中提取时间一致的语义信息，并在DiT内部执行参考引导令牌传播。", "result": "本文的方法在所有生成式单目深度估计模型以及视频深度估计模型中均表现出最佳性能，生成了明显比其他所有模型更干净的点云。", "conclusion": "通过引入新颖的技术来改善现有几何基础模型中的不足，实现了高质量、无飞点的点云预测。"}}
{"id": "2601.05244", "pdf": "https://arxiv.org/pdf/2601.05244", "abs": "https://arxiv.org/abs/2601.05244", "authors": ["Henghui Ding", "Chang Liu", "Shuting He", "Xudong Jiang", "Yu-Gang Jiang"], "title": "GREx: Generalized Referring Expression Segmentation, Comprehension, and Generation", "categories": ["cs.CV"], "comment": "IJCV, Project Page: https://henghuiding.com/GREx/", "summary": "Referring Expression Segmentation (RES) and Comprehension (REC) respectively segment and detect the object described by an expression, while Referring Expression Generation (REG) generates an expression for the selected object. Existing datasets and methods commonly support single-target expressions only, i.e., one expression refers to one object, not considering multi-target and no-target expressions. This greatly limits the real applications of REx (RES/REC/REG). This paper introduces three new benchmarks called Generalized Referring Expression Segmentation (GRES), Comprehension (GREC), and Generation (GREG), collectively denoted as GREx, which extend the classic REx to allow expressions to identify an arbitrary number of objects. We construct the first large-scale GREx dataset gRefCOCO that contains multi-target, no-target, and single-target expressions and their corresponding images with labeled targets. GREx and gRefCOCO are designed to be backward-compatible with REx, facilitating extensive experiments to study the performance gap of the existing REx methods on GREx tasks. One of the challenges of GRES/GREC is complex relationship modeling, for which we propose a baseline ReLA that adaptively divides the image into regions with sub-instance clues and explicitly models the region-region and region-language dependencies. The proposed ReLA achieves the state-of-the-art results on the both GRES and GREC tasks. The proposed gRefCOCO dataset and method are available at https://henghuiding.github.io/GREx.", "AI": {"tldr": "本文提出了一种新的通用指称表达分割、理解和生成框架（GREx），并构建了大规模数据集gRefCOCO，支持多目标和无目标表达。", "motivation": "现有方法通常只支持单目标表达，忽略了多目标和无目标的情况，这限制了其在实际应用中的广泛使用。因此本文提出了GREx来解决这些问题，并提供了相应的数据集。", "method": "为了应对复杂关系建模的挑战，作者提出了一种基于区域分割的方法ReLA，它能够自适应地将图像分成多个子区域并显式建模区域间和语言间的依赖性。", "result": "提出的ReLA方法在GRES和GREC任务上达到了最先进的效果。", "conclusion": "本文通过引入GREx框架及其数据集gRefCOCO，扩展了经典指称表达的范围，并为未来的相关研究提供了新的基准。"}}
{"id": "2601.05243", "pdf": "https://arxiv.org/pdf/2601.05243", "abs": "https://arxiv.org/abs/2601.05243", "authors": ["Xingyi He", "Adhitya Polavaram", "Yunhao Cao", "Om Deshmukh", "Tianrui Wang", "Xiaowei Zhou", "Kuan Fang"], "title": "Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration", "categories": ["cs.RO", "cs.CV"], "comment": "Project Page: https://cordex-manipulation.github.io/", "summary": "Functional grasping with dexterous robotic hands is a key capability for enabling tool use and complex manipulation, yet progress has been constrained by two persistent bottlenecks: the scarcity of large-scale datasets and the absence of integrated semantic and geometric reasoning in learned models. In this work, we present CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration. At the core of our approach is a correspondence-based data engine that generates diverse, high-quality training data in simulation. Based on the human demonstration, our data engine generates diverse object instances of the same category, transfers the expert grasp to the generated objects through correspondence estimation, and adapts the grasp through optimization. Building on the generated data, we introduce a multimodal prediction network that integrates visual and geometric information. By devising a local-global fusion module and an importance-aware sampling mechanism, we enable robust and computationally efficient prediction of functional dexterous grasps. Through extensive experiments across various object categories, we demonstrate that CorDex generalizes well to unseen object instances and significantly outperforms state-of-the-art baselines.", "AI": {"tldr": "该论文提出了一个框架，通过从单个人类演示生成合成数据来学习功能性灵巧抓取。", "motivation": "功能性灵巧抓取对于工具使用和复杂操作至关重要，但由于大规模数据集的稀缺性和缺乏语义与几何推理的一体化模型，研究进展受限。", "method": "该方法利用基于对应关系的数据引擎生成多样且高质量的训练数据，并通过优化适应性抓取。引入多模态预测网络整合视觉和几何信息，实现功能性灵巧抓取的有效预测。", "result": "实验结果显示，CorDex在各类对象实例上表现出色，显著优于现有基线模型。", "conclusion": "该工作提出了一种从单次人类演示生成合成数据学习功能性灵巧抓取的新方法。"}}
{"id": "2601.05242", "pdf": "https://arxiv.org/pdf/2601.05242", "abs": "https://arxiv.org/abs/2601.05242", "authors": ["Shih-Yang Liu", "Xin Dong", "Ximing Lu", "Shizhe Diao", "Peter Belcak", "Mingjie Liu", "Min-Hung Chen", "Hongxu Yin", "Yu-Chiang Frank Wang", "Kwang-Ting Cheng", "Yejin Choi", "Jan Kautz", "Pavlo Molchanov"], "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "NVIDIA-Tech Report", "summary": "As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.", "AI": {"tldr": "介绍了一种新的策略优化方法GDPO，用于解决多奖励强化学习中的训练信号分辨率降低和早期训练失败问题。", "motivation": "GRPO在直接应用到不同的rollout奖励组合时会导致它们的相对差异减少，从而降低训练信号的分辨率。为此提出新的优化方法以提高多奖励RL的效果和稳定性。", "method": "提出了GDPO，通过解耦个体奖励的标准化来更准确地保留它们之间的相对差异，并且提高了多奖励优化的精度。", "result": "在工具调用、数学推理和编码推理任务上对比GRPO，GDPO在正确性和约束遵循度两个指标上的表现更加优秀。", "conclusion": "证明了GDPO的有效性与泛化能力，在处理多奖励强化学习优化问题时优于现有方法。"}}
{"id": "2601.05241", "pdf": "https://arxiv.org/pdf/2601.05241", "abs": "https://arxiv.org/abs/2601.05241", "authors": ["Boyang Wang", "Haoran Zhang", "Shujie Zhang", "Jinkun Hao", "Mingda Jia", "Qi Lv", "Yucheng Mao", "Zhaoyang Lyu", "Jia Zeng", "Xudong Xu", "Jiangmiao Pang"], "title": "RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.", "AI": {"tldr": "本文提出了RoboVIP，通过视觉身份提示增强多视角视频生成，提高机器人操作数据的质量和多样性。", "motivation": "由于硬件限制，大规模收集高质量的机器人操作数据非常困难。现有方法使用文本提示来修改背景和物体，但忽视了多视角和时间一致性观察的需求，并且难以精确控制场景设置。", "method": "本文引入视觉身份提示技术，通过示例图像提供明确视觉指导以生成所需场景设置。同时构建了一个可扩展的数据收集管道，从大型机器人数据集中筛选出视觉身份样本池。", "result": "使用增强后的操作数据训练下游模型，在仿真和实际机器人环境中的性能均有显著提高。", "conclusion": "本文提出的方法通过提供更精确的视觉指导解决了现有方法的问题，并提高了机器人操作数据的质量与多样性。"}}
{"id": "2601.05240", "pdf": "https://arxiv.org/pdf/2601.05240", "abs": "https://arxiv.org/abs/2601.05240", "authors": ["Ilmo Sung"], "title": "Robust Reasoning as a Symmetry-Protected Topological Phase", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI", "hep-th"], "comment": null, "summary": "Large language models suffer from \"hallucinations\"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a \"Metric Phase,\" where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic \"mass gap,\" maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \\times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\\times$ beyond training ($L=50 \\to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.", "AI": {"tldr": "本文提出了一个新模型Holonomic Network，该模型通过非阿贝尔任意子编织实现了逻辑操作的拓扑不变性，从而提高了在语义噪声下的推理稳健性。", "motivation": "大型语言模型存在逻辑不一致问题（即“幻觉”），这源于因果顺序对自发对称性破缺的脆弱性。作者希望通过引入非阿贝尔任意子编织来解决这一问题，以提高模型在噪音环境中的鲁棒性和稳定性。", "method": "将逻辑操作形式化为非阿贝尔任意子编织，并构建了一个名为Holonomic Network的新模型，在该模型中实现了拓扑不变性保护，从而增强了语义噪声下的推理稳健性。", "result": "实验表明，相较于Transformer和RNN模型，新提出的Holonomic网络在一定程度上保持了逻辑一致性的能力。在$S_{10}$上的符号操作任务中展示了霍诺米克泛化：即使训练长度为50倍的放大后（即从$L=50 \to 5000$），其仍能维持完美的保真度。", "conclusion": "本文的研究结果表明，通过引入非阿贝尔任意子编织可以实现逻辑操作的形式不变性，并且在一定程度上解决了大型语言模型中幻觉问题。这为逻辑推理的新通用类别提供了强有力的证据。"}}
{"id": "2601.05239", "pdf": "https://arxiv.org/pdf/2601.05239", "abs": "https://arxiv.org/abs/2601.05239", "authors": ["Xiao Fu", "Shitao Tang", "Min Shi", "Xian Liu", "Jinwei Gu", "Ming-Yu Liu", "Dahua Lin", "Chen-Hsuan Lin"], "title": "Plenoptic Video Generation", "categories": ["cs.CV"], "comment": "Project Page: https://research.nvidia.com/labs/dir/plenopticdreamer/", "summary": "Camera-controlled generative video re-rendering methods, such as ReCamMaster, have achieved remarkable progress. However, despite their success in single-view setting, these works often struggle to maintain consistency across multi-view scenarios. Ensuring spatio-temporal coherence in hallucinated regions remains challenging due to the inherent stochasticity of generative models. To address it, we introduce PlenopticDreamer, a framework that synchronizes generative hallucinations to maintain spatio-temporal memory. The core idea is to train a multi-in-single-out video-conditioned model in an autoregressive manner, aided by a camera-guided video retrieval strategy that adaptively selects salient videos from previous generations as conditional inputs. In addition, Our training incorporates progressive context-scaling to improve convergence, self-conditioning to enhance robustness against long-range visual degradation caused by error accumulation, and a long-video conditioning mechanism to support extended video generation. Extensive experiments on the Basic and Agibot benchmarks demonstrate that PlenopticDreamer achieves state-of-the-art video re-rendering, delivering superior view synchronization, high-fidelity visuals, accurate camera control, and diverse view transformations (e.g., third-person to third-person, and head-view to gripper-view in robotic manipulation). Project page: https://research.nvidia.com/labs/dir/plenopticdreamer/", "AI": {"tldr": "本文提出了一种名为PlenopticDreamer的框架，用于生成多视图一致性的视频。", "motivation": "现有的相机控制生成视频重渲染方法在单视角设置下取得了显著进展，但在多视图场景中保持一致性方面存在挑战。为了提高空间和时间的一致性并解决生成模型中的随机性问题，本文提出了PlenopticDreamer。", "method": "该框架通过训练一个多进一出的视频条件化自回归模型来同步生成幻觉，并使用相机引导的视频检索策略选择之前的生成视频作为条件输入。此外还采用了渐进式上下文缩放、自我条件化以及长视频条件机制以提升性能。", "result": "实验表明，PlenopticDreamer在Basic和Agibot基准测试中实现了最先进的视频重渲染效果，在视图同步性、高保真视觉效果、准确的相机控制及多视角转换等方面均表现出色。", "conclusion": "PlenopticDreamer框架成功解决了生成视频重渲染中的多视图一致性问题，展示了其在提升视频质量和增强灵活性方面的潜力。"}}
{"id": "2601.05237", "pdf": "https://arxiv.org/pdf/2601.05237", "abs": "https://arxiv.org/abs/2601.05237", "authors": ["Rustin Soraki", "Homanga Bharadhwaj", "Ali Farhadi", "Roozbeh Mottaghi"], "title": "ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos", "categories": ["cs.CV"], "comment": "Preprint. Project Website: objectforesight.github.io", "summary": "Humans can effortlessly anticipate how objects might move or change through interaction--imagining a cup being lifted, a knife slicing, or a lid being closed. We aim to endow computational systems with a similar ability to predict plausible future object motions directly from passive visual observation. We introduce ObjectForesight, a 3D object-centric dynamics model that predicts future 6-DoF poses and trajectories of rigid objects from short egocentric video sequences. Unlike conventional world or dynamics models that operate in pixel or latent space, ObjectForesight represents the world explicitly in 3D at the object level, enabling geometrically grounded and temporally coherent predictions that capture object affordances and trajectories. To train such a model at scale, we leverage recent advances in segmentation, mesh reconstruction, and 3D pose estimation to curate a dataset of 2 million plus short clips with pseudo-ground-truth 3D object trajectories. Through extensive experiments, we show that ObjectForesight achieves significant gains in accuracy, geometric consistency, and generalization to unseen objects and scenes, establishing a scalable framework for learning physically grounded, object-centric dynamics models directly from observation. objectforesight.github.io", "AI": {"tldr": "该论文提出了ObjectForesight，一个可以从人类视频中预测未来三维物体运动轨迹的模型。", "motivation": "模仿人类预见能力，使计算系统能够从被动视觉观察中预测物理上可信的对象动态变化。", "method": "利用分割、网格重建和3D姿态估计技术构建了一个包含200多万短片段的大规模数据集，并引入了ObjectForesight模型来学习基于对象的动态特性。", "result": "实验表明，与现有方法相比，ObjectForesight在准确性、几何一致性以及泛化能力方面都有显著提升。", "conclusion": "ObjectForesight为从视觉观察中直接学习物理上可信的对象动态提供了可扩展框架。"}}
{"id": "2601.05230", "pdf": "https://arxiv.org/pdf/2601.05230", "abs": "https://arxiv.org/abs/2601.05230", "authors": ["Quentin Garrido", "Tushar Nagarajan", "Basile Terver", "Nicolas Ballas", "Yann LeCun", "Michael Rabbat"], "title": "Learning Latent Action World Models In The Wild", "categories": ["cs.AI", "cs.CV"], "comment": "37 pages, 25 figures", "summary": "Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require action labels, that can be complex to obtain at scale. This motivates the learning of latent action models, that can learn an action space from videos alone. Our work addresses the problem of learning latent actions world models on in-the-wild videos, expanding the scope of existing works that focus on simple robotics simulations, video games, or manipulation data. While this allows us to capture richer actions, it also introduces challenges stemming from the video diversity, such as environmental noise, or the lack of a common embodiment across videos. To address some of the challenges, we discuss properties that actions should follow as well as relevant architectural choices and evaluations. We find that continuous, but constrained, latent actions are able to capture the complexity of actions from in-the-wild videos, something that the common vector quantization does not. We for example find that changes in the environment coming from agents, such as humans entering the room, can be transferred across videos. This highlights the capability of learning actions that are specific to in-the-wild videos. In the absence of a common embodiment across videos, we are mainly able to learn latent actions that become localized in space, relative to the camera. Nonetheless, we are able to train a controller that maps known actions to latent ones, allowing us to use latent actions as a universal interface and solve planning tasks with our world model with similar performance as action-conditioned baselines. Our analyses and experiments provide a step towards scaling latent action models to the real world.", "AI": {"tldr": "本文探讨了在无标签动作的现实世界视频中学习潜在动作模型的方法，旨在提高代理预测行动后果的能力。", "motivation": "现有的世界模型大多需要复杂且难以大规模获取的动作标签，因此作者提出了一个可以仅从视频中学习动作空间的新方法来应对这一挑战。", "method": "通过分析动作应遵循的特性以及相关架构的选择和评估，本文发现连续但受限的潜在动作能够捕捉来自野外视频中的行动复杂性，并提出了一种新的控制方式将已知的动作映射到潜在动作上。", "result": "实验表明该模型可以有效地解决规划任务并且性能与基于动作条件的方法相当。", "conclusion": "研究成果为进一步在现实世界中扩展潜在动作模型提供了基础和方向。"}}
{"id": "2601.05225", "pdf": "https://arxiv.org/pdf/2601.05225", "abs": "https://arxiv.org/abs/2601.05225", "authors": ["Evan Wrench", "Ajay Singh", "Younghun Roh", "Panagiota Fatourou", "Siddhartha Jayanti", "Eric Ruppert", "Yuanhao Wei"], "title": "Concurrent Balanced Augmented Trees", "categories": ["cs.DS"], "comment": "To appear in PPoPP 2026", "summary": "Augmentation makes search trees tremendously more versatile, allowing them to support efficient aggregation queries, order-statistic queries, and range queries in addition to insertion, deletion, and lookup. In this paper, we present the first lock-free augmented balanced search tree. Our algorithmic ideas build upon a recent augmented unbalanced search tree presented by Fatourou and Ruppert [DISC, 2024]. We implement both data structures, solving some memory reclamation challenges in the process, and provide an experimental performance analysis of them. We also present optimized versions of our balanced tree that use delegation to achieve better scalability and performance (by more than 2x in some workloads). Our experiments show that our augmented balanced tree is 2.2 to 30 times faster than the unbalanced augmented tree, and up to several orders of magnitude faster than unaugmented trees on 120 threads.", "AI": {"tldr": "论文提出了首个无锁的平衡搜索树，并对其进行了实验性能分析。", "motivation": "为了使搜索树更灵活，能够支持高效的聚合查询、顺序统计查询和范围查询等操作。", "method": "基于Fatourou和Ruppert的研究成果，开发了一个无锁的增强型平衡搜索树。解决了内存回收挑战，并提供了优化版本以提高可扩展性和性能。", "result": "实验表明，改进后的平衡搜索树比未增强的不平衡搜索树快2.2到30倍，在120个线程下表现尤为突出。", "conclusion": "论文成功实现了首个无锁的增强型平衡搜索树，并证明了其在多种工作负载下的优越性能。"}}
{"id": "2601.05219", "pdf": "https://arxiv.org/pdf/2601.05219", "abs": "https://arxiv.org/abs/2601.05219", "authors": ["Maja Waldron"], "title": "CAOS: Conformal Aggregation of One-Shot Predictors", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data. Despite violating classical exchangeability assumptions, we prove that CAOS achieves valid marginal coverage using a monotonicity-based argument. Experiments on one-shot facial landmarking and RAFT text classification tasks show that CAOS produces substantially smaller prediction sets than split conformal baselines while maintaining reliable coverage.", "AI": {"tldr": "本文提出了一种基于多个一次性预测器聚合的置信度框架CAOS，用于提升一阶任务下的模型适应性和不确定性量化。", "motivation": "现有的一个样本预测方法无法提供原则性的不确定性量化，同时标准分割置信预测法在数据稀缺的一次性任务设置中效率低下。因此，本文旨在通过提出新的聚合方案来改善这些问题。", "method": "CAOS框架采用自适应聚合多个一次性预测器，并使用留一校准策略充分利用有限的标注数据。尽管违背了经典的可交换假设，但证明了CAOS能够通过单调性论证实现有效的边际覆盖保证。", "result": "实验结果显示，在面部地标和RAFT文本分类任务上，相较于标准分割置信基线方法，CAOS产生了更小的预测集且保持了可靠的覆盖率。", "conclusion": "本文提出的CAOS框架在一次性样本条件下有效地提高了模型的适应性和不确定性量化能力。"}}
{"id": "2601.05215", "pdf": "https://arxiv.org/pdf/2601.05215", "abs": "https://arxiv.org/abs/2601.05215", "authors": ["Tamil Sudaravan Mohan Doss", "Michael Xu", "Sudha Rao", "Andrew D. Wilson", "Balasaravanan Thoravi Kumaravel"], "title": "MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents", "categories": ["cs.AI"], "comment": null, "summary": "We present \\textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \\emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence. As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \\textbf{216} subtasks across \\textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.", "AI": {"tldr": "提出了MineNPC-Task，这是一个用于评估记忆感知型LLM代理在《我的世界》中的测试基准和评价框架。", "motivation": "通过用户创作的任务来测试记忆感知型、混合主动性的大型语言模型（LLM）代理的能力，并捕获计划/行动/内存事件，包括预览、澄清、读写操作、前提检查及修复尝试等。", "method": "任务由专家玩家在游戏中的形式化和总结性合作中产生，被归一化为参数模板并配以机器可验证的校验器。评估框架通过禁止世界外捷径的方式来测试代理的性能。", "result": "使用GPT-4o对8名经验玩家进行了216个子任务的评估，发现了代码执行、物品处理、引用和导航方面的常见故障模式以及由混合主动澄清和支持的记忆恢复情况。参与者肯定了交互质量和界面可用性，但强调需要更强的任务间记忆持久性。", "conclusion": "发布了完整的任务套件、验证器、日志和框架以支持未来内存感知型实体代理的透明可重复评估。"}}
{"id": "2601.05214", "pdf": "https://arxiv.org/pdf/2601.05214", "abs": "https://arxiv.org/abs/2601.05214", "authors": ["Kait Healy", "Bharathi Srinivasan", "Visakh Madathil", "Jing Wu"], "title": "Internal Representations as Indicators of Hallucinations in Agent Tool Selection", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities in tool calling and tool usage, but suffer from hallucinations where they choose incorrect tools, provide malformed parameters and exhibit 'tool bypass' behavior by performing simulations and generating outputs instead of invoking specialized tools or external systems. This undermines the reliability of LLM based agents in production systems as it leads to inconsistent results, and bypasses security and audit controls. Such hallucinations in agent tool selection require early detection and error handling. Unlike existing hallucination detection methods that require multiple forward passes or external validation, we present a computationally efficient framework that detects tool-calling hallucinations in real-time by leveraging LLMs' internal representations during the same forward pass used for generation. We evaluate this approach on reasoning tasks across multiple domains, demonstrating strong detection performance (up to 86.4\\% accuracy) while maintaining real-time inference capabilities with minimal computational overhead, particularly excelling at detecting parameter-level hallucinations and inappropriate tool selections, critical for reliable agent deployment.", "AI": {"tldr": "该论文提出了一种利用大语言模型（LLM）内部表示来实时检测工具调用幻觉的方法，以提高代理系统的可靠性和安全性。", "motivation": "大型语言模型在工具选择中存在错误、参数畸形和绕过行为等问题，这降低了其在生产系统中的可靠性。现有的幻觉检测方法通常需要多次前向传递或外部验证，耗时且计算成本高。", "method": "提出了一种通过利用LLM的内部表示来实时检测工具调用幻觉的框架，该框架能够在模型生成过程中进行检测，无需额外的计算开销。", "result": "实验表明，该方法在推理任务中的幻觉检测性能高达86.4%，特别是在检测参数级幻觉和不适当工具选择方面表现出色。", "conclusion": "此研究提供了一种高效的方法来实时检测大型语言模型中的工具调用幻觉，从而提高代理系统的可靠性和安全性。"}}
{"id": "2601.05212", "pdf": "https://arxiv.org/pdf/2601.05212", "abs": "https://arxiv.org/abs/2601.05212", "authors": ["Danilo Danese", "Angela Lombardi", "Matteo Attimonelli", "Giuseppe Fasano", "Tommaso Di Noia"], "title": "FlowLet: Conditional 3D Brain MRI Synthesis using Wavelet Flow Matching", "categories": ["cs.CV"], "comment": null, "summary": "Brain Magnetic Resonance Imaging (MRI) plays a central role in studying neurological development, aging, and diseases. One key application is Brain Age Prediction (BAP), which estimates an individual's biological brain age from MRI data. Effective BAP models require large, diverse, and age-balanced datasets, whereas existing 3D MRI datasets are demographically skewed, limiting fairness and generalizability. Acquiring new data is costly and ethically constrained, motivating generative data augmentation. Current generative methods are often based on latent diffusion models, which operate in learned low dimensional latent spaces to address the memory demands of volumetric MRI data. However, these methods are typically slow at inference, may introduce artifacts due to latent compression, and are rarely conditioned on age, thereby affecting the BAP performance. In this work, we propose FlowLet, a conditional generative framework that synthesizes age-conditioned 3D MRIs by leveraging flow matching within an invertible 3D wavelet domain, helping to avoid reconstruction artifacts and reducing computational demands. Experiments show that FlowLet generates high-fidelity volumes with few sampling steps. Training BAP models with data generated by FlowLet improves performance for underrepresented age groups, and region-based analysis confirms preservation of anatomical structures.", "AI": {"tldr": "FlowLet是一种条件生成框架，通过在可逆三维小波域内进行流匹配来合成年龄条件的3D MRI。", "motivation": "现有的MRI数据集存在人口统计学偏差问题，难以获得新的高质量数据，因此需要一种有效的数据增强方法以提高脑年龄预测模型的性能和泛化能力。", "method": "FlowLet利用可逆三维小波域内的流匹配生成条件3D MRI图像，避免重构伪影并减少计算需求。", "result": "实验结果显示，FlowLet能够快速生成高保真度的MRI体积，并且使用由FlowLet生成的数据训练脑年龄预测模型可以提高对少数群体年龄段的表现。", "conclusion": "FlowLet提供了一种有效的条件生成方法来合成高质量、无伪影的3D MRI图像，有助于改善神经退行性疾病的研究和脑年龄预测模型的性能。"}}
{"id": "2601.05208", "pdf": "https://arxiv.org/pdf/2601.05208", "abs": "https://arxiv.org/abs/2601.05208", "authors": ["Zichen Wang", "Ang Cao", "Liam J. Wang", "Jeong Joon Park"], "title": "MoE3D: A Mixture-of-Experts Module for 3D Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "MoE3D is a mixture-of-experts module designed to sharpen depth boundaries and mitigate flying-point artifacts (highlighted in red) of existing feed-forward 3D reconstruction models (left side). MoE3D predicts multiple candidate depth maps and fuses them via dynamic weighting (visualized by MoE weights on the right side). When integrated with a pre-trained 3D reconstruction backbone such as VGGT, it substantially enhances reconstruction quality with minimal additional computational overhead. Best viewed digitally.", "AI": {"tldr": "提出了一种混合专家模块MoE3D，用于提高3D重建的质量。", "motivation": "现有前馈3D重建模型在深度边界和飞行点伪影方面存在问题，因此需要一种能够改善这些问题的方法。", "method": "通过预测多个候选深度图并通过动态加权融合它们来改进3D重建质量。当与预训练的3D重建骨干网络如VGGT集成时，可以显著提升重建效果且计算开销很小。", "result": "该方法在提高3D重建质量方面取得了实质性进展，并且无需大幅增加计算成本。", "conclusion": "MoE3D是一种有效的方法，可以在现有3D重建模型的基础上进一步改善深度边界和伪影问题。"}}
{"id": "2601.05202", "pdf": "https://arxiv.org/pdf/2601.05202", "abs": "https://arxiv.org/abs/2601.05202", "authors": ["Navin Chhibber", "Suneel Khemka", "Navneet Kumar Tyagi", "Rohit Tewari", "Bireswar Banerjee", "Piyush Ranjan"], "title": "Stock Market Price Prediction using Neural Prophet with Deep Neural Network", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Stock market price prediction is a significant interdisciplinary research domain that depends at the intersection of finance, statistics, and economics. Forecasting Accurately predicting stock prices has always been a focal point for various researchers. However, existing statistical approaches for time-series prediction often fail to effectively forecast the probability range of future stock prices. Hence, to solve this problem, the Neural Prophet with a Deep Neural Network (NP-DNN) is proposed to predict stock market prices. The preprocessing technique used in this research is Z-score normalization, which normalizes stock price data by removing scale differences, making patterns easier to detect. Missing value imputation fills gaps in historical data, enhancing the models use of complete information for more accurate predictions. The Multi-Layer Perceptron (MLP) learns complex nonlinear relationships among stock market prices and extracts hidden patterns from the input data, thereby creating meaningful feature representations for better prediction accuracy. The proposed NP-DNN model achieved an accuracy of 99.21% compared with other approaches using the Fused Large Language Model. Keywords: deep neural network, forecasting stock prices, multi-layer perceptron, neural prophet, stock market price prediction.", "AI": {"tldr": "本文提出了一种使用神经先知与深度神经网络结合的方法来预测股票市场价格。", "motivation": "现有的统计方法在时间序列预测中难以准确地预测未来股票价格的概率范围，因此提出了新的NP-DNN模型以解决此问题。", "method": "研究采用了Z分数标准化预处理技术对数据进行归一化，并填补了历史数据中的缺失值。通过多层感知器（MLP）学习复杂的非线性关系并提取隐藏的模式，提高预测精度。", "result": "该NP-DNN模型达到了99.21%的准确率，相较于其他方法有明显优势。", "conclusion": "所提出的神经先知与深度神经网络结合的方法在股票市场价格预测中展现了极高的准确性，并可以作为未来研究的基础。"}}
{"id": "2601.05201", "pdf": "https://arxiv.org/pdf/2601.05201", "abs": "https://arxiv.org/abs/2601.05201", "authors": ["William Rudman", "Michal Golovanevsky", "Dana Arad", "Yonatan Belinkov", "Ritambhara Singh", "Carsten Eickhoff", "Kyle Mahowald"], "title": "Mechanisms of Prompt-Induced Hallucination in Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": ":I.2.0; I.2.7; I.2.10; I.4.8", "summary": "Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy. Through mechanistic analysis of three VLMs, we identify a small set of attention heads whose ablation substantially reduces prompt-induced hallucinations (PIH) by at least 40% without additional training. Across models, PIH-heads mediate prompt copying in model-specific ways. We characterize these differences and show that PIH ablation increases correction toward visual evidence. Our findings offer insights into the internal mechanisms driving prompt-induced hallucinations, revealing model-specific differences in how these behaviors are implemented.", "AI": {"tldr": "研究了大型视觉语言模型在面对文本提示和图像证据之间的矛盾时产生幻觉的机制。", "motivation": "探讨视觉语言模型为何会在文字提示与实际图像内容不符的情况下倾向于遵循文字提示而非依据视觉证据的问题。", "method": "通过控制对象计数设置，分析了三种大型视觉语言模型中导致文本提示引发幻觉的小规模注意力头的作用，并发现这些头部的消除可以显著减少幻觉。", "result": "在增加对图像中的对象数量的同时，模型越来越倾向于遵循文本提示而非依据实际图像证据；消融特定注意力头能够大幅减少幻觉现象而不需额外训练。", "conclusion": "研究表明了大型视觉语言模型产生文本提示引发的幻觉的具体机制，并揭示了不同模型之间实现这些行为差异的方式。"}}
{"id": "2601.05191", "pdf": "https://arxiv.org/pdf/2601.05191", "abs": "https://arxiv.org/abs/2601.05191", "authors": ["Zuhair Ahmed Khan Taha", "Mohammed Mudassir Uddin", "Shahnawaz Alam"], "title": "Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines", "AI": {"tldr": "开发了一种名为AgentCompress的系统，根据任务难度调整模型压缩程度以减少计算成本。", "motivation": "大型语言模型在执行自主任务时会产生高昂的计算费用，使许多学术实验室难以承担。", "method": "使用小型神经网络评估每个任务的难度，并将其路由到适合压缩的模型变体中。", "result": "通过500个研究工作流程测试，在四个科学领域内将计算成本降低了68.3％，同时保持了96.2％的成功率。", "conclusion": "AgentCompress为学术实验室提供了一种经济高效的使用大型语言模型的方法。"}}
{"id": "2601.05187", "pdf": "https://arxiv.org/pdf/2601.05187", "abs": "https://arxiv.org/abs/2601.05187", "authors": ["Yanchang Liang", "Xiaowei Zhao"], "title": "SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle sparse rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-preserving, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between LLMs and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.", "AI": {"tldr": "SimuAgent是一个基于大型语言模型的Simulink建模助手，通过强化学习改进了图形工程工作流程。", "motivation": "大型语言模型在文本代码自动化方面取得了革命性进展，但在图导向的工程工作流中的应用潜力尚未被充分探索。本文旨在开发一个可以显著提高效率和可解释性的LLM驱动的Simulink建模助手。", "method": "提出了一种新的轻量级计划执行架构，结合了低级工具技能和高级设计推理能力，并提出了反思-相对策略优化（ReGRPO），通过自我反思跟踪提供了丰富的中间反馈。实验基于包含5300个多领域模型任务的新基准SimuBench。", "result": "Qwen2.5-7B模型在SimuAgent的训练下比标准RL基线收敛更快、建模精度更高，甚至超过GPT-4o当使用少量提示进行评估时。两阶段课程和抽象重构数据增强进一步提高了泛化能力。", "conclusion": "SimuAgent填补了LLM与图形建模环境之间的空白，为工业环境中的人工智能辅助工程设计提供了实际解决方案。"}}
{"id": "2601.05184", "pdf": "https://arxiv.org/pdf/2601.05184", "abs": "https://arxiv.org/abs/2601.05184", "authors": ["Yaxuan Wang", "Zhongteng Cai", "Yujia Bao", "Xueru Zhang", "Yang Liu"], "title": "Observations and Remedies for Large Language Model Bias in Self-Consuming Performative Loop", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has led to growing interest in using synthetic data to train future models. However, this creates a self-consuming retraining loop, where models are trained on their own outputs and may cause performance drops and induce emerging biases. In real-world applications, previously deployed LLMs may influence the data they generate, leading to a dynamic system driven by user feedback. For example, if a model continues to underserve users from a group, less query data will be collected from this particular demographic of users. In this study, we introduce the concept of \\textbf{S}elf-\\textbf{C}onsuming \\textbf{P}erformative \\textbf{L}oop (\\textbf{SCPL}) and investigate the role of synthetic data in shaping bias during these dynamic iterative training processes under controlled performative feedback. This controlled setting is motivated by the inaccessibility of real-world user preference data from dynamic production systems, and enables us to isolate and analyze feedback-driven bias evolution in a principled manner. We focus on two types of loops, including the typical retraining setting and the incremental fine-tuning setting, which is largely underexplored. Through experiments on three real-world tasks, we find that the performative loop increases preference bias and decreases disparate bias. We design a reward-based rejection sampling strategy to mitigate the bias, moving towards more trustworthy self-improving systems.", "AI": {"tldr": "本文研究了大规模语言模型在自我消耗执行循环中的偏见问题，并提出了一种基于奖励的拒绝采样策略来缓解该问题。", "motivation": "随着大型语言模型的发展，合成数据被用于训练未来的模型。然而，在这种自消费重新训练循环中，可能因反馈驱动而产生偏见，从而影响模型性能和用户群体服务质量。", "method": "本文提出了SCPL的概念，并在两种不同的迭代设置下研究了合成数据对偏好偏差的影响：典型的再训练设置和增量微调设置。设计了一种基于奖励的拒绝采样策略来减少偏见。", "result": "实验表明，执行循环增加了偏好偏差但减少了差异性偏差。提出的缓解策略有效地减轻了这种偏差问题。", "conclusion": "该研究揭示了大规模语言模型在自我消费执行循环中的偏见动态，并提供了一种有效的缓解方法，以提高系统的可信度和公平性。"}}
{"id": "2601.05181", "pdf": "https://arxiv.org/pdf/2601.05181", "abs": "https://arxiv.org/abs/2601.05181", "authors": ["Thomas P. Watson", "Eddie L. Jacobs"], "title": "Spacecube: A fast inverse hyperspectral georectification system", "categories": ["eess.IV", "cs.GR"], "comment": "9 pages, 16 figures. source code available after peer-reviewed publication", "summary": "Hyperspectral cameras provide numerous advantages in terms of the utility of the data captured. They capture hundreds of data points per sample (pixel) instead of only the few of RGB or multispectral camera systems. Aerial systems sense such data remotely, but the data must be georectified to produce consistent images before analysis. We find the traditional direct georectification method to be slow, and it is prone to artifacts. To address its downsides, we propose Spacecube, a program that implements a complete hyperspectral georectification pipeline, including our own fast inverse georectification technique, using OpenGL graphics programming technologies. Spacecube operates substantially faster than real-time and eliminates pixel coverage artifacts. It facilitates high quality interactive viewing, data exploration, and export of final products. We release Spacecube's source code publicly for the community to use.", "AI": {"tldr": "空间立方体（Spacecube）是一种使用OpenGL图形编程技术的快速逆向高光谱地理校正系统。", "motivation": "传统直接地理校正方法速度慢且容易产生像素覆盖误差，作者提出了一个新的系统来解决这些问题。", "method": "该论文提出了一种基于OpenGL图形编程技术实现的完整高光谱地理校正流水线，并利用快速逆向地理校正技术提高处理效率。", "result": "空间立方体系统的运行速度远远超过实时性能并消除了像素覆盖误差，支持高质量的交互式查看、数据探索和最终产品的导出。", "conclusion": "作者发布了空间立方体源代码供社区使用。"}}
{"id": "2601.05175", "pdf": "https://arxiv.org/pdf/2601.05175", "abs": "https://arxiv.org/abs/2601.05175", "authors": ["Shuming Liu", "Mingchen Zhuge", "Changsheng Zhao", "Jun Chen", "Lemeng Wu", "Zechun Liu", "Chenchen Zhu", "Zhipeng Cai", "Chong Zhou", "Haozhe Liu", "Ernie Chang", "Saksham Suri", "Hongyu Xu", "Qi Qian", "Wei Wen", "Balakrishnan Varadarajan", "Zhuang Liu", "Hu Xu", "Florian Bordes", "Raghuraman Krishnamoorthi", "Bernard Ghanem", "Vikas Chandra", "Yunyang Xiong"], "title": "VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice", "categories": ["cs.CV"], "comment": "Project page: https://ivul-kaust.github.io/projects/videoauto-r1/", "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for multimodal large language models on video understanding tasks. However, its necessity and advantages over direct answering remain underexplored. In this paper, we first demonstrate that for RL-trained video models, direct answering often matches or even surpasses CoT performance, despite CoT producing step-by-step analyses at a higher computational cost. Motivated by this, we propose VideoAuto-R1, a video understanding framework that adopts a reason-when-necessary strategy. During training, our approach follows a Thinking Once, Answering Twice paradigm: the model first generates an initial answer, then performs reasoning, and finally outputs a reviewed answer. Both answers are supervised via verifiable rewards. During inference, the model uses the confidence score of the initial answer to determine whether to proceed with reasoning. Across video QA and grounding benchmarks, VideoAuto-R1 achieves state-of-the-art accuracy with significantly improved efficiency, reducing the average response length by ~3.3x, e.g., from 149 to just 44 tokens. Moreover, we observe a low rate of thinking-mode activation on perception-oriented tasks, but a higher rate on reasoning-intensive tasks. This suggests that explicit language-based reasoning is generally beneficial but not always necessary.", "AI": {"tldr": "提出了一种新的视频理解框架VideoAuto-R1，该框架采用一种“思考一次、回答两次”的策略以提高效率和准确性。", "motivation": "通过研究发现直接回答在某些情况下可以匹配甚至超过链式思维推理的性能。因此提出了一个更高效的方法来解决视频理解和问答任务。", "method": "模型首先生成初始答案，然后进行推理，并最终输出经过审查的答案。训练时采用可验证奖励监督两个答案，在推断阶段使用初始答案的信心分数决定是否进行推理。", "result": "VideoAuto-R1在视频QA和接地基准测试中实现了最先进的准确性并显著提高了效率，减少了平均响应长度约3.3倍。在感知任务中的思考模式激活率较低而在需要大量推理的任务中较高。", "conclusion": "明确的语言推理一般是有益的但并非总是必要的。"}}
{"id": "2601.05174", "pdf": "https://arxiv.org/pdf/2601.05174", "abs": "https://arxiv.org/abs/2601.05174", "authors": ["Yiji Zhao", "Zihao Zhong", "Ao Wang", "Haomin Wen", "Ming Jin", "Yuxuan Liang", "Huaiyu Wan", "Hao Wu"], "title": "FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to KDD 2026", "summary": "Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.", "AI": {"tldr": "提出了一种基于混合专家（MoE）的有效且高效的长时预测框架FaST，适用于大规模时空图的预测。", "motivation": "现有模型在进行大规模时空图预测时难以处理长时间跨度的问题，并且计算成本和内存消耗较大。FaST旨在解决这些挑战。", "method": "采用了自适应图代理注意力机制来减轻大型图上的计算负担；提出了使用门控线性单元（GLU）的并行MoE模块，以实现高效可扩展的结构。", "result": "实验结果表明，FaST在大规模时空图预测中提供了优于现有模型的长时预测精度和更高的计算效率。", "conclusion": "通过创新的方法论，FaST能够在保持高精度的同时显著减少计算资源需求，为解决大规模时空图长时间跨度预测问题提供了一种有效方案。"}}
{"id": "2601.05172", "pdf": "https://arxiv.org/pdf/2601.05172", "abs": "https://arxiv.org/abs/2601.05172", "authors": ["Haoyu Zhao", "Akide Liu", "Zeyu Zhang", "Weijie Wang", "Feng Chen", "Ruihan Zhu", "Gholamreza Haffari", "Bohan Zhuang"], "title": "CoV: Chain-of-View Prompting for Spatial Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process. CoV first employs a View Selection agent to filter redundant frames and identify question-aligned anchor views. It then performs fine-grained view adjustment by interleaving iterative reasoning with discrete camera actions, obtaining new observations from the underlying 3D scene representation until sufficient context is gathered or a step budget is reached. We evaluate CoV on OpenEQA across four mainstream VLMs and obtain an average +11.56\\% improvement in LLM-Match, with a maximum gain of +13.62\\% on Qwen3-VL-Flash. CoV further exhibits test-time scaling: increasing the minimum action budget yields an additional +2.51\\% average improvement, peaking at +3.73\\% on Gemini-2.5-Flash. On ScanQA and SQA3D, CoV delivers strong performance (e.g., 116 CIDEr / 31.9 EM@1 on ScanQA and 51.1 EM@1 on SQA3D). Overall, these results suggest that question-aligned view selection coupled with open-view search is an effective, model-agnostic strategy for improving spatial reasoning in 3D EQA without additional training.", "AI": {"tldr": "提出了一种无需额外训练的Chain-of-View（CoV）提示框架，通过主动视角选择和细化搜索来改进在三维环境中进行问答时的空间推理能力。", "motivation": "现有的视觉语言模型受限于固定的输入视图集合，难以获取问题相关的背景信息并执行复杂空间推理。因此，本文提出了一种训练后无需额外学习的测试时间框架以解决这一限制。", "method": "通过一个粗略到精细的探索过程，CoV提示框架首先使用视角选择代理来过滤冗余帧和识别与问题对齐的锚定视图；接着执行细粒度的视角调整，通过迭代推理和离散相机动作获取新的观察结果，直到收集了足够的上下文或达到了步骤预算为止。", "result": "在OpenEQA数据集上，CoV提示框架实现了显著的性能提升，平均提高了11.56%的LLM-Match得分，在Qwen3-VL-Flash模型上的最大增益为13.62%，并且随着动作预算的增加，性能进一步增强。此外，在ScanQA和SQA3D数据集上也表现出色。", "conclusion": "通过与问题对齐的视角选择以及开放视图搜索相结合的方法，CoV提示框架展示了提高三维环境中的问答空间推理能力的有效性和模型无关性，而无需额外训练。"}}
{"id": "2601.05167", "pdf": "https://arxiv.org/pdf/2601.05167", "abs": "https://arxiv.org/abs/2601.05167", "authors": ["Chengsong Huang", "Tong Zheng", "Langlin Huang", "Jinyuan Li", "Haolin Liu", "Jiaxin Huang"], "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.", "AI": {"tldr": "通过令牌级协作解码，提出RelayLLM框架以高效推理。", "motivation": "大型语言模型在复杂推理中受限于高计算成本和延迟，小型模型缺乏足够的推理能力。现有的协同方法如级联或路由操作粗粒度，导致计算浪费。", "method": "提出RelayLLM框架，允许小型模型作为主动控制器动态调用大型模型处理关键令牌，并引入两阶段训练框架（预热与组相对策略优化）以平衡独立性和战略求助。", "result": "在六个基准上实现平均准确率49.52%，仅1.07%的生成令牌调用了大型模型，成本降低98.2%。", "conclusion": "RelayLLM有效解决了推理过程中的计算浪费问题，并展示了高效的性能。"}}
{"id": "2601.05166", "pdf": "https://arxiv.org/pdf/2601.05166", "abs": "https://arxiv.org/abs/2601.05166", "authors": ["Michal Opler"], "title": "Inapproximability of Counting Permutation Patterns", "categories": ["cs.DS"], "comment": null, "summary": "Detecting and counting copies of permutation patterns are fundamental algorithmic problems, with applications in the analysis of rankings, nonparametric statistics, and property testing tasks such as independence and quasirandomness testing. From an algorithmic perspective, there is a sharp difference in complexity between detecting and counting the copies of a given length-$k$ pattern in a length-$n$ permutation. The former admits a $2^{\\mathcal{O}(k^2)} \\cdot n$ time algorithm (Guillemot and Marx, 2014) while the latter cannot be solved in time $f(k)\\cdot n^{o(k/\\log k)}$ unless the Exponential Time Hypothesis (ETH) fails (Berendsohn, Kozma, and Marx, 2021). In fact already for patterns of length 4, exact counting is unlikely to admit near-linear time algorithms under standard fine-grained complexity assumptions (Dudek and Gawrychowski, 2020). Recently, Ben-Eliezer, Mitrović and Sristava (2026) showed that for patterns of length up to 5, a $(1+\\varepsilon)$-approximation of the pattern count can be computed in near-linear time, yielding a separation between exact and approximate counting for small patterns, and conjectured that approximate counting is asymptotically easier than exact counting in general. We strongly refute their conjecture by showing that, under ETH, no algorithm running in time $f(k)\\cdot n^{o(k/\\log k)}$ can approximate the number of copies of a length-$k$ pattern within a multiplicative factor $n^{(1/2-\\varepsilon)k}$. The lower bound on runtime matches the conditional lower bound for exact pattern counting, and the obtained bound on the multiplicative error factor is essentially tight, as an $n^{k/2}$-approximation can be computed in $2^{\\mathcal{O}(k^2)}\\cdot n$ time using an algorithm for pattern detection.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05162", "pdf": "https://arxiv.org/pdf/2601.05162", "abs": "https://arxiv.org/abs/2601.05162", "authors": ["Jinze Yu", "Dayuan Jiang"], "title": "GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.", "AI": {"tldr": "本文介绍了GenAI-DrawIO-Creator，一个利用大型语言模型自动生成和编辑draw.io格式的图表框架。", "motivation": "创建和修改图表是一个劳动密集型任务。为了解决这一问题，该研究提出了一个新的自动化图表生成方法来提高效率并减少时间成本。", "method": "GenAI-DrawIO-Creator整合了Claude 3.7语言模型以推理结构化的视觉数据，并通过特殊的提示工程及错误检查确保XML输出格式正确。", "result": "实验表明该系统能从自然语言或代码中生成准确的图表，包括网络架构和流程图等；同时还能根据图片复制这些图表。结果证明这种方法可以显著减少绘图时间并保持高结构准确性。", "conclusion": "这项研究展示了Claude 3.7在处理结构化视觉推理任务中的潜力，并为未来的AI辅助绘图应用奠定了基础。"}}
{"id": "2601.05159", "pdf": "https://arxiv.org/pdf/2601.05159", "abs": "https://arxiv.org/abs/2601.05159", "authors": ["Shuliang Liu", "Songbo Yang", "Dong Fang", "Sihang Jia", "Yuqi Tang", "Lingfeng Su", "Ruoshui Peng", "Yibo Yan", "Xin Zou", "Xuming Hu"], "title": "Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Object hallucination critically undermines the reliability of Multimodal Large Language Models, often stemming from a fundamental failure in cognitive introspection, where models blindly trust linguistic priors over specific visual evidence. Existing mitigations remain limited: contrastive decoding approaches operate superficially without rectifying internal semantic misalignments, while current latent steering methods rely on static vectors that lack instance-specific precision. We introduce Vision-Language Introspection (VLI), a training-free inference framework that simulates a metacognitive self-correction process. VLI first performs Attributive Introspection to diagnose hallucination risks via probabilistic conflict detection and localize the causal visual anchors. It then employs Interpretable Bi-Causal Steering to actively modulate the inference process, dynamically isolating visual evidence from background noise while neutralizing blind confidence through adaptive calibration. VLI achieves state-of-the-art performance on advanced models, reducing object hallucination rates by 12.67% on MMHal-Bench and improving accuracy by 5.8% on POPE.", "AI": {"tldr": "本文提出了一种名为Vision-Language Introspection（VLI）的无训练推理框架，旨在通过模拟元认知自我纠正过程来减少多模态大型语言模型中的对象幻觉。", "motivation": "现有的方法在解决多模态大语言模型中的对象幻觉问题时存在局限性：对比解码方式仅进行表面操作而不修正内部语义不一致，而当前的潜在引导方法依赖于静态向量缺乏实例特定精度。因此，本文旨在开发一种新的框架来有效降低对象幻觉。", "method": "VLI通过Attributive Introspection诊断幻觉风险并通过概率冲突检测定位因果视觉锚点；然后使用Interpretable Bi-Causal Steering主动调节推理过程，动态隔离视觉证据从背景噪声中，并通过自适应校准消除盲目自信。", "result": "实验显示，在MMHal-Bench和POPE数据集上，VLI将对象幻觉率降低了12.67%，准确度提高了5.8%。", "conclusion": "Vision-Language Introspection（VLI）框架能够有效地减少多模态大型语言模型中的对象幻觉，并且在各种任务中展示了优越的性能。"}}
{"id": "2601.05157", "pdf": "https://arxiv.org/pdf/2601.05157", "abs": "https://arxiv.org/abs/2601.05157", "authors": ["Alkis Kalavasis", "Pravesh K. Kothari", "Shuchen Li", "Manolis Zampetakis"], "title": "Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms", "categories": ["cs.DS", "cs.LG", "stat.ML"], "comment": null, "summary": "In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians. All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments. Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function. Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.", "AI": {"tldr": "提出了一种通过高效高维稀疏傅里叶变换学习混合模型参数的方法，适用于重尾分布。", "motivation": "现有方法大多依赖低阶矩，存在局限性。新方法旨在克服这些限制，并应用于包括拉普拉斯分布在内的一类不具有有限协方差的分布。", "method": "基于高效高维稀疏傅里叶变换的新学习混合模型的方法，适用于重尾特征函数分布而不局限于高斯分布。", "result": "开发了多项式时间复杂度和样本数量的学习算法，在混合模型中成功应用该方法。此外还提出了对抗噪声的鲁棒均值估计算法。", "conclusion": "新方法扩展了现有的统计估计技术，具有广泛应用前景，并且在解决混合模型问题时表现出了优越性。"}}
{"id": "2601.05152", "pdf": "https://arxiv.org/pdf/2601.05152", "abs": "https://arxiv.org/abs/2601.05152", "authors": ["Timofey Tomashevskiy"], "title": "Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages, 4 figures", "summary": "This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms. Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning", "AI": {"tldr": "该论文提供了一种持续安全在线强化学习（COSRL）方法的状态调查，涵盖了理论方面、挑战和开放性问题。", "motivation": "为了更好地理解和应对非平稳环境中的安全强化学习问题，探讨构建持续在线安全强化学习算法的理论基础、面临的挑战以及未解决的问题。", "method": "提出了基于不同安全学习机制的COSRL方法分类，并根据安全约束条件对在线强化学习算法进行分类。还讨论了如何建立可靠的、安全的在线学习算法的可能性。", "result": "通过全面分析现有的持续安全强化学习方法，为理解和改进非平稳环境下的安全在线学习提供了理论依据和实践指导。", "conclusion": "提出了针对非平稳环境中持续安全强化学习的方法框架，并强调了在创建可靠的安全在线学习系统方面仍存在的挑战。"}}
{"id": "2601.05149", "pdf": "https://arxiv.org/pdf/2601.05149", "abs": "https://arxiv.org/abs/2601.05149", "authors": ["Elia Peruzzo", "Guillaume Sautière", "Amirhossein Habibian"], "title": "Multi-Scale Local Speculative Decoding for Image Generation", "categories": ["cs.CV"], "comment": "Project page is available at https://qualcomm-ai-research.github.io/mulo-sd-webpage", "summary": "Autoregressive (AR) models have achieved remarkable success in image synthesis, yet their sequential nature imposes significant latency constraints. Speculative Decoding offers a promising avenue for acceleration, but existing approaches are limited by token-level ambiguity and lack of spatial awareness. In this work, we introduce Multi-Scale Local Speculative Decoding (MuLo-SD), a novel framework that combines multi-resolution drafting with spatially informed verification to accelerate AR image generation. Our method leverages a low-resolution drafter paired with learned up-samplers to propose candidate image tokens, which are then verified in parallel by a high-resolution target model. Crucially, we incorporate a local rejection and resampling mechanism, enabling efficient correction of draft errors by focusing on spatial neighborhoods rather than raster-scan resampling after the first rejection. We demonstrate that MuLo-SD achieves substantial speedups - up to $\\mathbf{1.7\\times}$ - outperforming strong speculative decoding baselines such as EAGLE-2 and LANTERN in terms of acceleration, while maintaining comparable semantic alignment and perceptual quality. These results are validated using GenEval, DPG-Bench, and FID/HPSv2 on the MS-COCO 5k validation split. Extensive ablations highlight the impact of up-sampling design, probability pooling, and local rejection and resampling with neighborhood expansion. Our approach sets a new state-of-the-art in speculative decoding for image synthesis, bridging the gap between efficiency and fidelity.", "AI": {"tldr": "提出了MuLo-SD框架，结合多分辨率绘制与空间感知验证加速自回归图像生成。", "motivation": "自回归模型在图像合成中表现出色但存在序列性限制导致延迟较大。现有投机解码方法受限于令牌级不确定性及缺乏空间认知能力。", "method": "利用低分辨率绘图器和学习型上采样器提出候选图像令牌，并通过高分辨率目标模型进行平行验证，引入局部拒绝与重抽样机制以高效纠正绘制错误。", "result": "实验表明MuLo-SD可实现显著加速（最高达1.7倍），超越EAGLE-2和LANTERN等强基线方法，在保持语义对齐及感知质量的同时提高了效率。", "conclusion": "新提出的方法在图像合成的投机解码方面确立了新的SOTA，有效平衡了效率与保真度之间的关系。"}}
{"id": "2601.05148", "pdf": "https://arxiv.org/pdf/2601.05148", "abs": "https://arxiv.org/abs/2601.05148", "authors": ["Maximilian Alber", "Timo Milbich", "Alexandra Carpen-Amarie", "Stephan Tietz", "Jonas Dippel", "Lukas Muttenthaler", "Beatriz Perez Cancer", "Alessandro Benetti", "Panos Korfiatis", "Elias Eulig", "Jérôme Lüscher", "Jiasen Wu", "Sayed Abid Hashimi", "Gabriel Dernbach", "Simon Schallenberg", "Neelay Shah", "Moritz Krügener", "Aniruddh Jammoria", "Jake Matras", "Patrick Duffy", "Matt Redlon", "Philipp Jurmeister", "David Horst", "Lukas Ruff", "Klaus-Robert Müller", "et al. (2 additional authors not shown)"], "title": "Atlas 2 -- Foundation models for clinical deployment", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model dataset to date comprising 5.5 million histopathology whole slide images, collected from three medical institutions Charité - Universtätsmedizin Berlin, LMU Munich, and Mayo Clinic.", "AI": {"tldr": "本文介绍了Atlas 2系列，这是三个病理基础模型，旨在提高临床部署的性能、鲁棒性和资源效率。", "motivation": "现有的病理基础模型虽然在计算病理学方面取得了显著进展，但在性能、稳健性及计算需求方面的权衡限制了其临床应用。因此，本文提出Atlas 2系列以解决这些问题。", "method": "通过使用包含5.5百万张全滑动图像的大型数据集训练模型，并进行了全面评估，涵盖80个公开基准测试。", "result": "在综合评价中，这些模型展示了预测性能、稳健性以及资源效率上的最先进的表现。", "conclusion": "Atlas 2系列通过改进性能和计算效率解决了现有病理基础模型的不足之处。"}}
{"id": "2601.05144", "pdf": "https://arxiv.org/pdf/2601.05144", "abs": "https://arxiv.org/abs/2601.05144", "authors": ["Shuliang Liu", "Xingyu Li", "Hongyi Liu", "Yibo Yan", "Bingchen Duan", "Qi Zheng", "Dong Fang", "Lingfeng Su", "Xuming Hu"], "title": "Distilling the Thought, Watermarking the Answer: A Principle Semantic Guided Watermark for Large Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Reasoning Large Language Models (RLLMs) excelling in complex tasks present unique challenges for digital watermarking, as existing methods often disrupt logical coherence or incur high computational costs. Token-based watermarking techniques can corrupt the reasoning flow by applying pseudo-random biases, while semantic-aware approaches improve quality but introduce significant latency or require auxiliary models. This paper introduces ReasonMark, a novel watermarking framework specifically designed for reasoning-intensive LLMs. Our approach decouples generation into an undisturbed Thinking Phase and a watermarked Answering Phase. We propose a Criticality Score to identify semantically pivotal tokens from the reasoning trace, which are distilled into a Principal Semantic Vector (PSV). The PSV then guides a semantically-adaptive mechanism that modulates watermark strength based on token-PSV alignment, ensuring robustness without compromising logical integrity. Extensive experiments show ReasonMark surpasses state-of-the-art methods by reducing text Perplexity by 0.35, increasing translation BLEU score by 0.164, and raising mathematical accuracy by 0.67 points. These advancements are achieved alongside a 0.34% higher watermark detection AUC and stronger robustness to attacks, all with a negligible increase in latency. This work enables the traceable and trustworthy deployment of reasoning LLMs in real-world applications.", "AI": {"tldr": "本文提出了一种名为ReasonMark的新型水印框架，专门针对推理密集型大型语言模型。", "motivation": "现有数字水印方法在复杂任务中可能会破坏逻辑连贯性或导致高计算成本。需要一种新的方法来解决这些问题。", "method": "通过将生成过程划分为不受干扰的思想阶段和带有水印的答案阶段，该框架利用关键得分识别出推理过程中语义上至关重要的标记，并将其提取为一个主语义向量（PSV）。然后使用这个PSV引导适应性机制根据令牌-PSV对齐来调制水印强度。", "result": "实验结果显示ReasonMark在降低文本困惑度、提高翻译BLEU分数和数学准确率方面超过了最先进的方法，并且提高了0.34%的水印检测AUC，增强了对抗攻击的鲁棒性。同时，该框架引入了可以忽略不计的时间延迟增量。", "conclusion": "这项工作为在现实世界应用中可追踪和可信地部署推理LLM提供了可能"}}
{"id": "2601.05143", "pdf": "https://arxiv.org/pdf/2601.05143", "abs": "https://arxiv.org/abs/2601.05143", "authors": ["Md. Zahid Hossain", "Most. Sharmin Sultana Samu", "Md. Rakibul Islam", "Md. Siam Ansary"], "title": "A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering", "categories": ["cs.CV", "cs.CL"], "comment": "Preprint, manuscript is under review", "summary": "Visual question answering for crop disease analysis requires accurate visual understanding and reliable language generation. This work presents a lightweight vision-language framework for crop and disease identification from leaf images. The proposed approach combines a Swin Transformer vision encoder with sequence-to-sequence language decoders. A two-stage training strategy is adopted to improve visual representation learning and cross-modal alignment. The model is evaluated on a large-scale crop disease dataset using classification and natural language generation metrics. Experimental results show high accuracy for both crop and disease identification. The framework also achieves strong performance on BLEU, ROUGE and BERTScore. Our proposed models outperform large-scale vision-language baselines while using significantly fewer parameters. Explainability is assessed using Grad-CAM and token-level attribution. Qualitative results demonstrate robust performance under diverse user-driven queries. These findings highlight the effectiveness of task-specific visual pretraining for crop disease visual question answering.", "AI": {"tldr": "本文提出了一个轻量级的视觉语言框架，用于从叶片图像中识别作物和疾病。", "motivation": "准确理解视觉信息并可靠生成自然语言对于农作物病害分析至关重要。为此开发了一个结合Swin Transformer视觉编码器与序列到序列语言解码器的方法。", "method": "该方法采用了两阶段训练策略，旨在提高视觉表示学习和跨模态对齐。模型在大规模作物疾病数据集上使用分类和自然语言生成指标进行评估。", "result": "实验结果表明，在作物和病害识别方面具有高精度，并且在BLEU、ROUGE和BERTScore等指标上表现优异，超越了大型视觉语言基线模型但参数更少。解释性通过Grad-CAM和标记级归因进行了验证。", "conclusion": "这些发现证明了针对特定任务的视觉预训练对于作物病害视觉问答的有效性"}}
{"id": "2601.05138", "pdf": "https://arxiv.org/pdf/2601.05138", "abs": "https://arxiv.org/abs/2601.05138", "authors": ["Sixiao Zheng", "Minghao Yin", "Wenbo Hu", "Xiaoyu Li", "Ying Shan", "Yanwei Fu"], "title": "VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control", "categories": ["cs.CV"], "comment": "Project Page: https://sixiaozheng.github.io/VerseCrafter_page/", "summary": "Video world models aim to simulate dynamic, real-world environments, yet existing methods struggle to provide unified and precise control over camera and multi-object motion, as videos inherently operate dynamics in the projected 2D image plane. To bridge this gap, we introduce VerseCrafter, a 4D-aware video world model that enables explicit and coherent control over both camera and object dynamics within a unified 4D geometric world state. Our approach is centered on a novel 4D Geometric Control representation, which encodes the world state through a static background point cloud and per-object 3D Gaussian trajectories. This representation captures not only an object's path but also its probabilistic 3D occupancy over time, offering a flexible, category-agnostic alternative to rigid bounding boxes or parametric models. These 4D controls are rendered into conditioning signals for a pretrained video diffusion model, enabling the generation of high-fidelity, view-consistent videos that precisely adhere to the specified dynamics. Unfortunately, another major challenge lies in the scarcity of large-scale training data with explicit 4D annotations. We address this by developing an automatic data engine that extracts the required 4D controls from in-the-wild videos, allowing us to train our model on a massive and diverse dataset.", "AI": {"tldr": "VerseCrafter 提供了统一的4D几何控制表示，能够同时对相机和多个对象进行精确控制。", "motivation": "现有的视频世界模型方法在提供统一且精确的相机与多目标动态控制方面存在困难。作者通过引入VerseCrafter来解决这个问题，该模型旨在模拟真实世界的动态环境，并提供更加精细的4D几何控制。", "method": "采用新颖的4D几何控制表示方式，编码静态背景点云和每个对象的3D高斯轨迹，捕捉到物体的概率三维占据情况。这些4D控制信息被渲染成预训练视频扩散模型的条件信号。", "result": "VerseCrafter能够生成高质量、视图一致性的视频，并且精确地符合指定的动力学特性。", "conclusion": "VerseCrafter通过创新的4D几何表示和数据引擎提取技术，成功解决了现有视频世界模拟方法无法提供统一精准控制的问题。"}}
{"id": "2601.05125", "pdf": "https://arxiv.org/pdf/2601.05125", "abs": "https://arxiv.org/abs/2601.05125", "authors": ["Ignacio de Rodrigo", "Alvaro J. Lopez-Lopez", "Jaime Boal"], "title": "VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters. We validate the methodology by training on the synthetic MERIT Dataset and evaluating on its real-world counterpart, MERIT Secret. Results show that VERSE helps uncover the visual features associated with error-prone clusters, and that retraining with samples containing these features substantially boosts F1 performance without degrading generalization. Furthermore, we demonstrate that on-premise models such as Donut and Idefics2, when optimized with VERSE, match or even surpass the performance of SaaS solutions like GPT-4 and Pixtral.", "AI": {"tldr": "VERSE是一种用于分析和改进应用于视觉丰富的文档理解的Vision-Language模型的方法，通过探索其视觉嵌入空间来提高性能。", "motivation": "动机在于利用可视化技术评估Vision-Language模型的表现，并识别错误集群以生成合成数据，从而增强训练集。", "method": "VERSE方法包括可视化潜在表示、识别问题区域以及基于聚类指导的合成数据生成。通过在MERIT和MERIT Secret数据集上进行验证，展示了其效果。", "result": "实验结果显示VERSE能够揭示与错误集群相关的视觉特征，并且使用包含这些特征的数据重新训练模型可以显著提高F1性能而不降低泛化能力。", "conclusion": "研究表明VERSE不仅可以优化现有的在地模型（如Donut和Idefics2），还可以使其表现媲美或超越云端服务（如GPT-4和Pixtral）"}}
{"id": "2601.05124", "pdf": "https://arxiv.org/pdf/2601.05124", "abs": "https://arxiv.org/abs/2601.05124", "authors": ["Runze He", "Yiji Cheng", "Tiankai Hang", "Zhimin Li", "Yu Xu", "Zijin Yin", "Shiyi Zhang", "Wenxun Dai", "Penghui Du", "Ao Ma", "Chunyu Wang", "Qinglin Lu", "Jizhong Han", "Jiao Dai"], "title": "Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing", "categories": ["cs.CV"], "comment": "13 pages, 9 figures, project page: https://github.com/hrz2000/realign", "summary": "In-context image generation and editing (ICGE) enables users to specify visual concepts through interleaved image-text prompts, demanding precise understanding and faithful execution of user intent. Although recent unified multimodal models exhibit promising understanding capabilities, these strengths often fail to transfer effectively to image generation. We introduce Re-Align, a unified framework that bridges the gap between understanding and generation through structured reasoning-guided alignment. At its core lies the In-Context Chain-of-Thought (IC-CoT), a structured reasoning paradigm that decouples semantic guidance and reference association, providing clear textual target and mitigating confusion among reference images. Furthermore, Re-Align introduces an effective RL training scheme that leverages a surrogate reward to measure the alignment between structured reasoning text and the generated image, thereby improving the model's overall performance on ICGE tasks. Extensive experiments verify that Re-Align outperforms competitive methods of comparable model scale and resources on both in-context image generation and editing tasks.", "AI": {"tldr": "通过结构化推理引导的对齐方法，改进了在上下文中的图像生成和编辑任务。", "motivation": "虽然最近的统一多模态模型展示了强大的理解能力，但在图像生成方面这些优势往往无法有效转移。", "method": "引入Re-Align框架，采用In-Context Chain-of-Thought（IC-CoT）结构化推理方案，并结合强化学习训练策略提高对齐效果。", "result": "实验表明，Re-Align在上下文中的图像生成和编辑任务上优于具有类似模型规模和资源的竞争方法。", "conclusion": "通过有效的结构化推理引导对齐方法，提升了图像生成和编辑任务的性能。"}}
{"id": "2601.05116", "pdf": "https://arxiv.org/pdf/2601.05116", "abs": "https://arxiv.org/abs/2601.05116", "authors": ["Zirui Wu", "Zeren Jiang", "Martin R. Oswald", "Jie Song"], "title": "From Rays to Projections: Better Inputs for Feed-Forward View Synthesis", "categories": ["cs.CV"], "comment": "Project Page: https://wuzirui.github.io/pvsm-web", "summary": "Feed-forward view synthesis models predict a novel view in a single pass with minimal 3D inductive bias. Existing works encode cameras as Plücker ray maps, which tie predictions to the arbitrary world coordinate gauge and make them sensitive to small camera transformations, thereby undermining geometric consistency. In this paper, we ask what inputs best condition a model for robust and consistent view synthesis. We propose projective conditioning, which replaces raw camera parameters with a target-view projective cue that provides a stable 2D input. This reframes the task from a brittle geometric regression problem in ray space to a well-conditioned target-view image-to-image translation problem. Additionally, we introduce a masked autoencoding pretraining strategy tailored to this cue, enabling the use of large-scale uncalibrated data for pretraining. Our method shows improved fidelity and stronger cross-view consistency compared to ray-conditioned baselines on our view-consistency benchmark. It also achieves state-of-the-art quality on standard novel view synthesis benchmarks.", "AI": {"tldr": "本文提出了一种新的输入方式，即投影条件化，以提高前馈视图合成模型的准确性和一致性。", "motivation": "现有工作中的相机编码方法存在问题，导致预测结果对小的相机变化敏感并且缺乏几何一致性。因此，作者试图探索更好的输入来增强模型性能。", "method": "提出了一种投影条件化的方法，通过使用目标视图的投影提示代替原始相机参数作为稳定2D输入，解决了原有问题，并引入了掩码自动编码预训练策略以利用大规模未标定数据进行预训练。", "result": "该方法在视图一致性基准测试中表现出更高的准确性和更强的一致性，同时在标准的新视图合成基准上达到最佳质量。", "conclusion": "通过改进输入方式和引入新的预训练策略，本文提出的方法提高了前馈视图合成模型的性能。"}}
{"id": "2601.05114", "pdf": "https://arxiv.org/pdf/2601.05114", "abs": "https://arxiv.org/abs/2601.05114", "authors": ["Wajid Nasser"], "title": "Evaluative Fingerprints: Stable and Systematic Differences in LLM Evaluator Behavior", "categories": ["cs.AI"], "comment": "23 pages, 6 figures, code and artifacts at : https://github.com/wajid-nasser/evaluative-fingerprints", "summary": "LLM-as-judge systems promise scalable, consistent evaluation. We find the opposite: judges are consistent, but not with each other; they are consistent with themselves. Across 3,240 evaluations (9 judges x 120 unique video x pack items x 3 independent runs), inter-judge agreement is near-zero (Krippendorff's α = 0.042). On two dimensions, judges disagree more than random noise would predict (α < 0). Yet this disagreement isn't chaos; it's structured. A classifier identifies which judge produced an evaluation with 77.1% accuracy from rubric scores alone, rising to 89.9% with disposition features. Within model families, the signal is even stronger: GPT-4.1 and GPT-5.2 are distinguishable with 99.6% accuracy. We call this the reliability paradox: judges cannot agree on what constitutes quality, yet their disagreement patterns are so stable they function as fingerprints. Each judge implements a distinct, stable theory of quality: an \"evaluative disposition\" that shapes how it interprets any rubric. We characterize these dispositions along multiple axes: harshness/leniency, dimension emphasis, within-judge stability (ICC), and evidence behavior (receipt validity, semantic linkage via NLI, and shotgun index). The implication is stark: LLM judges are not interchangeable instruments measuring a shared construct. They are distinct measurement devices, each encoding its own implicit theory of quality. Averaging their scores produces a synthetic verdict that corresponds to no judge's actual values.", "AI": {"tldr": "论文研究了大型语言模型作为评分者的稳定性和一致性问题，发现不同模型之间的评分存在系统性的差异。", "motivation": "大规模语言模型（LLM）作为一种评分工具被期望提供一致且可扩展的评价，然而实际应用中却显示出相互之间的一致性很低但内部稳定性高。研究动机在于揭示这种现象的原因以及探讨其背后的规律和影响。", "method": "论文通过3240次评估实验来测量不同LLM作为评分者之间的差异性，并采用分类器技术分析这些差异，以识别特定模型的“评判倾向”特征。", "result": "结果显示，尽管不同模型之间的一致性接近于零（Krippendorff's α = 0.042），但它们表现出一致性的‘评判指纹’模式。这种模式可以被分类器准确地识别出来，甚至在同类别的模型中表现得更为明显。", "conclusion": "研究揭示了大型语言模型作为评分者的可靠性悖论：虽然无法就质量标准达成共识，但他们之间的评价差异具有高度的稳定性和可预测性，这表明每个模型都采用了一种独特的、稳定的评判理论。"}}
{"id": "2601.05111", "pdf": "https://arxiv.org/pdf/2601.05111", "abs": "https://arxiv.org/abs/2601.05111", "authors": ["Runyang You", "Hongru Cai", "Caiqi Zhang", "Qiancheng Xu", "Meng Liu", "Tiezheng Yu", "Yongqi Li", "Wenjie Li"], "title": "Agent-as-a-Judge", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "LLM-as-a-Judge has revolutionized AI evaluation by leveraging large language models for scalable assessments. However, as evaluands become increasingly complex, specialized, and multi-step, the reliability of LLM-as-a-Judge has become constrained by inherent biases, shallow single-pass reasoning, and the inability to verify assessments against real-world observations. This has catalyzed the transition to Agent-as-a-Judge, where agentic judges employ planning, tool-augmented verification, multi-agent collaboration, and persistent memory to enable more robust, verifiable, and nuanced evaluations. Despite the rapid proliferation of agentic evaluation systems, the field lacks a unified framework to navigate this shifting landscape. To bridge this gap, we present the first comprehensive survey tracing this evolution. Specifically, we identify key dimensions that characterize this paradigm shift and establish a developmental taxonomy. We organize core methodologies and survey applications across general and professional domains. Furthermore, we analyze frontier challenges and identify promising research directions, ultimately providing a clear roadmap for the next generation of agentic evaluation.", "AI": {"tldr": "本文提出了一种新的评估框架Agent-as-a-Judge，用于解决传统LLM作为评估工具的局限性，并提供了一个涵盖核心方法和应用领域的全面综述。", "motivation": "随着被评估对象变得越来越复杂，传统的基于大型语言模型（LLM）的评估方式出现了一系列问题：包括固有偏见、浅层单次推理以及无法验证评估结果的真实情况。这些问题促使了Agent-as-a-Judge框架的发展，以提供更强大、可验证和细致的评价。", "method": "本文首先概述了从传统的LLM评估到Agent-as-a-Judge的转变过程；然后详细分析了这一演变的关键维度并建立了一个发展的分类学；最后探讨了一系列前沿挑战，并提出了一些研究方向。", "result": "提出了一个涵盖核心方法和应用领域的全面综述，构建了一套描述这种范式转移的发展分类框架，并指出了未来的研究方向。", "conclusion": "Agent-as-a-Judge是一种新的评估模式，它通过规划、工具增强验证、多代理协作以及持久记忆等机制来解决传统LLM的局限性。本文提供了一个全面的概述和指导未来的研究方向。"}}
{"id": "2601.05110", "pdf": "https://arxiv.org/pdf/2601.05110", "abs": "https://arxiv.org/abs/2601.05110", "authors": ["Wenhao Zeng", "Xuteng Zhang", "Yuling Shi", "Chao Hu", "Yuting Chen", "Beijun Shen", "Xiaodong Gu"], "title": "GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts", "categories": ["cs.AI"], "comment": "Code available at https://github.com/Zengwh02/GlimpRouter", "summary": "Large Reasoning Models (LRMs) achieve remarkable performance by explicitly generating multi-step chains of thought, but this capability incurs substantial inference latency and computational cost. Collaborative inference offers a promising solution by selectively allocating work between lightweight and large models, yet a fundamental challenge remains: determining when a reasoning step requires the capacity of a large model or the efficiency of a small model. Existing routing strategies either rely on local token probabilities or post-hoc verification, introducing significant inference overhead. In this work, we propose a novel perspective on step-wise collaboration: the difficulty of a reasoning step can be inferred from its very first token. Inspired by the \"Aha Moment\" phenomenon in LRMs, we show that the entropy of the initial token serves as a strong predictor of step difficulty. Building on this insight, we introduce GlimpRouter, a training-free step-wise collaboration framework. GlimpRouter employs a lightweight model to generate only the first token of each reasoning step and routes the step to a larger model only when the initial token entropy exceeds a threshold. Experiments on multiple benchmarks demonstrate that our approach significantly reduces inference latency while preserving accuracy. For instance, GlimpRouter attains a substantial 10.7% improvement in accuracy while reducing inference latency by 25.9% compared to a standalone large model on AIME25. These results suggest a simple yet effective mechanism for reasoning: allocating computation based on a glimpse of thought rather than full-step evaluation.", "AI": {"tldr": "提出了GlimpRouter框架，通过分析推理步骤的第一个词的熵来决定是否使用大型模型进行后续处理，以减少推理延迟同时保持准确性。", "motivation": "LRMs在生成多步思维链方面表现出色但消耗大量计算资源。现有协作策略引入了显着推理开销，因此提出了一种新的视角通过分析初始token预测步骤难度。", "method": "GlimpRouter采用轻量级模型仅生成每个推理步骤的第一个token，并根据这个token的熵决定是否将步骤路由到大型模型进行进一步处理。", "result": "实验表明，在多个基准测试中，该方法显著减少了推理延迟同时保持了准确性。例如在AIME25上与单独使用大模型相比，准确率提高了10.7%，而推理延迟降低了25.9%。", "conclusion": "基于思维一步骤的初始token进行计算分配的方法是简单有效的，能够有效减少推理成本和时间同时保持性能。"}}
{"id": "2601.05107", "pdf": "https://arxiv.org/pdf/2601.05107", "abs": "https://arxiv.org/abs/2601.05107", "authors": ["Muzhao Tian", "Zisu Huang", "Xiaohua Wang", "Jingwen Xu", "Zhengkang Guo", "Qi Qian", "Yuanzhe Shen", "Kaitao Song", "Jiakang Yuan", "Changze Lv", "Xiaoqing Zheng"], "title": "Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction", "categories": ["cs.AI"], "comment": null, "summary": "As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory usage: incorporating all relevant past information can lead to \\textit{Memory Anchoring}, where the agent is trapped by past interactions, while excluding memory entirely results in under-utilization and the loss of important interaction history. We show that an agent's reliance on memory can be modeled as an explicit and user-controllable dimension. We first introduce a behavioral metric of memory dependence to quantify the influence of past interactions on current outputs. We then propose \\textbf{Stee}rable \\textbf{M}emory Agent, \\texttt{SteeM}, a framework that allows users to dynamically regulate memory reliance, ranging from a fresh-start mode that promotes innovation to a high-fidelity mode that closely follows interaction history. Experiments across different scenarios demonstrate that our approach consistently outperforms conventional prompting and rigid memory masking strategies, yielding a more nuanced and effective control for personalized human-agent collaboration.", "AI": {"tldr": "本文提出了一种控制LLM代理记忆使用的方法，旨在平衡锚定效应与创新性之间的关系。", "motivation": "现有的系统在处理长期交互时通常采用非此即彼的方式对待记忆：完全利用可能导致代理人被过去的交互所束缚；而忽视记忆则会导致重要互动历史的丢失。作者希望通过一种用户可控制的方式来调节代理对记忆的依赖程度，从而平衡这两种极端情况。", "method": "本文提出了一种名为SteeM（Stearable Memory Agent）的框架，该框架能够允许用户动态调整代理人对过去交互的记忆依赖度，从完全忽略过去的“创新模式”到高度忠实于互动历史的“高保真模式”。", "result": "实验结果表明，相较于传统的提示和僵硬的记忆屏蔽策略，本文所提出的SteeM方法在多种场景下均表现出了更为细致且有效的个性化人类-代理人协作。", "conclusion": "通过引入用户可调节记忆依赖度的机制，本文为长期的人机交互提供了更加灵活多样的控制手段。"}}
{"id": "2601.05106", "pdf": "https://arxiv.org/pdf/2601.05106", "abs": "https://arxiv.org/abs/2601.05106", "authors": ["Nuoya Xiong", "Yuhang Zhou", "Hanqing Zeng", "Zhaorun Chen", "Furong Huang", "Shuchao Bi", "Lizhu Zhang", "Zhuokai Zhao"], "title": "Token-Level LLM Collaboration via FusionRoute", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "25 pages", "summary": "Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.", "AI": {"tldr": "提出了一种新的多LLM协作框架FusionRoute，该框架在令牌级别上进行轻量级路由和生成器辅助的解码策略优化。", "motivation": "解决单一通用模型性能不佳的问题，并避免小型专用模型泛化能力弱的问题。通过引入一种新的协作方法来提高跨领域任务的表现。", "method": "FusionRoute采用轻量级路由器同时选择最合适的专家和生成器辅助的令牌分布修正策略，提供理论分析表明仅依赖固定专家输出的方法存在局限性，并提出了一种增强有效政策类别的框架。", "result": "实验结果显示，在Llama-3和Gemma-2家族及其多样化基准测试中，FusionRoute优于序列级与令牌级协作、模型合并以及直接微调方法。", "conclusion": "FusionRoute是一种有效的多LLM协作机制，能够显著提高跨领域任务的表现并保持在各自领域的竞争力。"}}
{"id": "2601.05105", "pdf": "https://arxiv.org/pdf/2601.05105", "abs": "https://arxiv.org/abs/2601.05105", "authors": ["Filippo Ghilotti", "Samuel Brucker", "Nahku Saidy", "Matteo Matteucci", "Mario Bijelic", "Felix Heide"], "title": "UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition", "categories": ["cs.CV"], "comment": null, "summary": "Unlabeled LiDAR logs, in autonomous driving applications, are inherently a gold mine of dense 3D geometry hiding in plain sight - yet they are almost useless without human labels, highlighting a dominant cost barrier for autonomous-perception research. In this work we tackle this bottleneck by leveraging temporal-geometric consistency across LiDAR sweeps to lift and fuse cues from text and 2D vision foundation models directly into 3D, without any manual input. We introduce an unsupervised multi-modal pseudo-labeling method relying on strong geometric priors learned from temporally accumulated LiDAR maps, alongside with a novel iterative update rule that enforces joint geometric-semantic consistency, and vice-versa detecting moving objects from inconsistencies. Our method simultaneously produces 3D semantic labels, 3D bounding boxes, and dense LiDAR scans, demonstrating robust generalization across three datasets. We experimentally validate that our method compares favorably to existing semantic segmentation and object detection pseudo-labeling methods, which often require additional manual supervision. We confirm that even a small fraction of our geometrically consistent, densified LiDAR improves depth prediction by 51.5% and 22.0% MAE in the 80-150 and 150-250 meters range, respectively.", "AI": {"tldr": "提出了一种利用几何信息进行无人驾驶中无标签激光雷达数据伪标记的方法，可以生成高质量的3D语义分割和目标检测结果。", "motivation": "当前的自动驾驶应用中，未标注的LiDAR日志虽然富含密集的三维几何信息，但是缺乏有效的标注工具，导致其价值未能充分发挥。本文通过利用时间上几何一致性来提取和融合文本及2D视觉基础模型的信息到3D空间，并引入一种无需人工干预的多模态伪标记方法。", "method": "该方法依赖于从累积的时间LiDAR地图中学习的强大几何先验，结合了一个新颖的迭代更新规则以强制执行几何-语义一致性。同时通过检测不一致来识别移动物体。", "result": "实验表明，相较于现有的基于语义分割和对象检测的伪标记方法，该方法表现更优，并且即使少量高质量、几何一致性的激光雷达数据也可以显著提高深度预测精度。", "conclusion": "本文提出的方法在多个数据集上展示了强大的泛化能力，并通过改进深度预测证明了其有效性。"}}
{"id": "2601.05101", "pdf": "https://arxiv.org/pdf/2601.05101", "abs": "https://arxiv.org/abs/2601.05101", "authors": ["Konstantin Kubrak", "Ahmed El-Moselhy", "Ammar Alsulami", "Remaz Altuwaim", "Hassan Ismail Fawaz", "Faisal Alsaby"], "title": "Arabic Prompts with English Tools: A Benchmark", "categories": ["cs.AI"], "comment": "10 pages, 10 figures, LLMs, Big Data, and Multilinguality for All (LLMs4All) Workshop at IEEE BigData 2025 Conference, Macau, December 10, 2025", "summary": "Large Language Models (LLMs) are now integral to numerous industries, increasingly serving as the core reasoning engine for autonomous agents that perform complex tasks through tool-use. While the development of Arabic-native LLMs is accelerating, the benchmarks for evaluating their capabilities lag behind, with most existing frameworks focusing on English. A critical and overlooked area is tool-calling, where the performance of models prompted in non-English languages like Arabic is poorly understood, especially since these models are often pretrained on predominantly English data. This paper addresses this critical gap by introducing the first dedicated benchmark for evaluating the tool-calling and agentic capabilities of LLMs in the Arabic language. Our work provides a standardized framework to measure the functional accuracy and robustness of models in Arabic agentic workflows. Our findings reveal a huge performance gap: when users interact in Arabic, tool-calling accuracy drops by an average of 5-10\\%, regardless of whether the tool descriptions themselves are in Arabic or English. By shedding light on these critical challenges, this benchmark aims to foster the development of more reliable and linguistically equitable AI agents for Arabic-speaking users.", "AI": {"tldr": "该论文提出了第一个用于评估阿拉伯语LLM工具调用能力和代理工作流程的标准化框架。", "motivation": "现有的基准测试大多数专注于英语，缺乏对非英语语言如阿拉伯语在工具调用性能方面的评价。", "method": "通过创建一个标准框架来衡量模型在阿拉伯语代理工作流程中的功能准确性和鲁棒性。", "result": "发现当用户以阿拉伯语交互时，工具调用准确性平均下降5-10％。", "conclusion": "该基准测试旨在促进更可靠和语言公平的人工智能代理的发展，为阿拉伯语用户提供服务。"}}
{"id": "2601.05098", "pdf": "https://arxiv.org/pdf/2601.05098", "abs": "https://arxiv.org/abs/2601.05098", "authors": ["Max Foreback", "Evan Imata", "Vincent Ragusa", "Jacob Weiler", "Christina Shao", "Joey Wagner", "Katherine G. Skocelas", "Jonathan Sy", "Aman Hafez", "Wolfgang Banzhaf", "Amy Conolly", "Kyle R. Helson", "Rick Marcusen", "Charles Ofria", "Marcin Pilinski", "Rajiv Ramnath", "Bryan Reynolds", "Anselmo C. Pontes", "Emily Dolson", "Julie Rolla"], "title": "ECLIPSE: An Evolutionary Computation Library for Instrumentation Prototyping in Scientific Engineering", "categories": ["cs.NE"], "comment": null, "summary": "Designing scientific instrumentation often requires exploring large, highly constrained design spaces using computationally expensive physics simulations. These simulators pose substantial challenges for integrating evolutionary computation (EC) into scientific design workflows. Evolutionary computation typically requires numerous design evaluations, making the integration of slow, low-throughput simulators particularly challenging, as they are optimized for accuracy and ease of use rather than throughput. We present ECLIPSE, an evolutionary computation framework built to interface directly with complex, domain-specific simulation tools while supporting flexible geometric and parametric representations of scientific hardware. ECLIPSE provides a modular architecture consisting of (1) Individuals, which encode hardware designs using domain-aware, physically constrained representations; (2) Evaluators, which prepare simulation inputs, invoke external simulators, and translate the simulator's outputs into fitness measures; and (3) Evolvers, which implement EC algorithms suitable for high-cost, limited-throughput environments. We demonstrate the utility of ECLIPSE across several active space-science applications, including evolved 3D antennas and spacecraft geometries optimized for drag reduction in very low Earth orbit. We further discuss the practical challenges encountered when coupling EC with scientific simulation workflows, including interoperability constraints, parallelization limits, and extreme evaluation costs, and outline ongoing efforts to combat these challenges. ECLIPSE enables interdisciplinary teams of physicists, engineers, and EC researchers to collaboratively explore unconventional designs for scientific hardware while leveraging existing domain-specific simulation software.", "AI": {"tldr": "提出ECLIPSE框架以解决复杂科学仪器设计中的进化计算问题。", "motivation": "在高成本、低通量环境中使用复杂的物理模拟器进行科学硬件设计探索时，遇到挑战需要一种新的方法来结合进化计算和现有仿真软件。", "method": "构建了一个模块化架构的ECLIPSE框架，包含个体表示硬件设计、评估器调用外部模拟器以及进化学者实现适合高成本环境中的算法。", "result": "展示了ECLIPSE在多种科学应用中有效性的案例，包括优化3D天线和减少非常低地球轨道上的空间飞行器阻力。", "conclusion": "ECLIPSE促进了物理学家、工程师及进化计算研究人员跨学科合作探索不寻常的科学硬件设计。"}}
{"id": "2601.05095", "pdf": "https://arxiv.org/pdf/2601.05095", "abs": "https://arxiv.org/abs/2601.05095", "authors": ["Ijaz Ahmad", "Faizan Ahmad", "Sunday Timothy Aboyeji", "Yongtao Zhang", "Peng Yang", "Rab Nawaz", "Baiying Lei"], "title": "Advanced Multimodal Learning for Seizure Detection and Prediction: Concept, Challenges, and Future Directions", "categories": ["cs.NE"], "comment": null, "summary": "Epilepsy is a chronic neurological disorder characterized by recurrent unprovoked seizures, affects over 50 million people worldwide, and poses significant risks, including sudden unexpected death in epilepsy (SUDEP). Conventional unimodal approaches, primarily reliant on electroencephalography (EEG), face several key challenges, including low SNR, nonstationarity, inter- and intrapatient heterogeneity, portability, and real-time applicability in clinical settings. To address these issues, a comprehensive survey highlights the concept of advanced multimodal learning for epileptic seizure detection and prediction (AMLSDP). The survey presents the evolution of epileptic seizure detection (ESD) and prediction (ESP) technologies across different eras. The survey also explores the core challenges of multimodal and non-EEG-based ESD and ESP. To overcome the key challenges of the multimodal system, the survey introduces the advanced processing strategies for efficient AMLSDP. Furthermore, this survey highlights future directions for researchers and practitioners. We believe this work will advance neurotechnology toward wearable and imaging-based solutions for epilepsy monitoring, serving as a valuable resource for future innovations in this domain.", "AI": {"tldr": "本文综述了癫痫发作检测和预测的多模态学习方法，提出了先进的处理策略，并展望了未来的研究方向。", "motivation": "传统单一模式的方法在癫痫发作检测中面临信噪比低、非平稳性等问题，需要开发新的多模态方法以提高准确性和实用性。", "method": "综述文章探讨了不同时代的癫痫发作检测和预测技术的发展，并提出了应对多模态挑战的高级处理策略。", "result": "本文概述了现有技术和未来研究方向，强调了可穿戴设备和基于成像的方法的重要性。", "conclusion": "通过综合分析当前的研究进展和技术瓶颈，文章为未来的癫痫监测技术创新提供了指导。"}}
{"id": "2601.05091", "pdf": "https://arxiv.org/pdf/2601.05091", "abs": "https://arxiv.org/abs/2601.05091", "authors": ["Aashi Garg", "Aneshya Das", "Arshi Arya", "Anushka Goyal", "Aditi"], "title": "Code-Mix Sentiment Analysis on Hinglish Tweets", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at the 9th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2025), Fukuoka, Japan", "summary": "The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.", "AI": {"tldr": "本文提出了一种针对Hinglish推文的情感分类框架，使用了微调的mBERT模型并采用了子词分词方法。", "motivation": "传统NLP模型在处理代码混合语言时表现不佳，导致品牌监测效果下降。因此，需要一个专门适用于印度社交媒体情感分析的方法来提高准确性和市场洞察力。", "method": "本文采用微调后的mBERT模型，并利用子词分词技术以应对罗马化Hinglish中的拼写变化、俚语和词汇外术语。", "result": "研究提出了一种生产级别的AI解决方案，可用于品牌情感追踪，并为低资源多语言NLP环境建立了坚实的标准。", "conclusion": "通过采用mBERT模型并结合子词分词技术，该研究在Hinglish推文的情感分析任务中取得了显著成果，为未来的研究提供了一个重要的参考框架。"}}
{"id": "2601.05084", "pdf": "https://arxiv.org/pdf/2601.05084", "abs": "https://arxiv.org/abs/2601.05084", "authors": ["Niloufar Alavi", "Swati Shah", "Rezvan Alamian", "Stefan Goetz"], "title": "Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication", "categories": ["cs.HC", "cs.AI", "cs.ET", "eess.SP", "eess.SY"], "comment": "6 pages, 7 figures", "summary": "Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.", "AI": {"tldr": "该论文提出了一种使用深度学习预测驾驶员转向意图的新方法，通过驾驶模拟器收集EEG信号，并利用卷积神经网络进行分类。", "motivation": "脑机接口可以在不需要言语或物理动作的情况下实现大脑和电子设备之间的直接通信。在需要快速反应的应用程序中（如驾驶），车辆的高级驾驶辅助系统可以受益于对驾驶员意图的即时理解。", "method": "研究使用EEG信号通过深度学习预测驾驶员转向意图，利用卷积神经网络分类未经大量预处理的检测到的EEG数据，并在驾驶模拟器创建的控制环境中收集这些数据。参与者被要求想象在各种驾驶场景中控制车辆，包括左转、右转和直行。", "result": "模型在区分三种转向意图方面的准确率为83.7%，表明卷积神经网络能够有效地处理原始EEG数据。分类准确性最高的是向右转弯的数据段，这可能暗示了脑活动的空间偏差。", "conclusion": "该研究为更直观的脑到车辆通信系统奠定了基础。"}}
{"id": "2601.05083", "pdf": "https://arxiv.org/pdf/2601.05083", "abs": "https://arxiv.org/abs/2601.05083", "authors": ["Ellington Kirby", "Alexandre Boulch", "Yihong Xu", "Yuan Yin", "Gilles Puy", "Éloi Zablocki", "Andrei Bursuc", "Spyros Gidaris", "Renaud Marlet", "Florent Bartoccioni", "Anh-Quan Cao", "Nermin Samet", "Tuan-Hung VU", "Matthieu Cord"], "title": "Driving on Registers", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.", "AI": {"tldr": "本文提出了DrivoR，一种基于预训练Vision Transformers的端到端自动驾驶架构。", "motivation": "为了提高自动驾驶系统的效率和准确性，引入了相机感知的注册令牌来压缩多摄像头特征，并利用两个轻量级解码器生成和评估候选轨迹。", "method": "使用预训练的Vision Transformers作为基础模型，并通过相机感知的注册令牌对多摄像头输入进行压缩。然后应用两个轻量级解码器，一个用于生成可能路径，另一个用于评估这些路径的安全性、舒适性和效率。", "result": "在NAVSIM-v1、NAVSIM-v2和HUGSIM基准测试中，DrivoR的表现超过了或与现有的最强基线相当。结果显示纯Transformer架构结合目标令牌压缩足以实现准确、高效且适应性强的端到端驾驶。", "conclusion": "通过采用预训练Vision Transformers并引入相机感知注册令牌进行特征压缩，DrivoR实现了高效的端到端自动驾驶，展示了纯Transformer架构在自动驾驶中的潜力和优越性。"}}
{"id": "2601.05082", "pdf": "https://arxiv.org/pdf/2601.05082", "abs": "https://arxiv.org/abs/2601.05082", "authors": ["Hayk Asatryan", "Basile Tousside", "Janis Mohr", "Malte Neugebauer", "Hildo Bijl", "Paul Spiegelberg", "Claudia Frohn-Schauf", "Jörg Frochte"], "title": "Exploring Student Expectations and Confidence in Learning Analytics", "categories": ["cs.LG", "cs.CY", "cs.HC"], "comment": "7 pages, Keywords: Learning Analytics, Survey, Data Protection, Clustering", "summary": "Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.", "AI": {"tldr": "使用SELAQ问卷分析不同院系学生对学习分析数据处理的期望和信心，识别出四类学生群体。", "motivation": "探讨学生对于学习分析的态度、期望及隐私保护的关注度。", "method": "通过聚类算法对学生进行分群并评估其对学习分析的接受程度和批评意见。", "result": "识别出了四类不同态度的学生：热情者、现实主义者、谨慎者和漠视者。", "conclusion": "该研究提供了学生对于学习分析的看法，有助于教育机构更好地理解学生的期望与担忧。"}}
{"id": "2601.05076", "pdf": "https://arxiv.org/pdf/2601.05076", "abs": "https://arxiv.org/abs/2601.05076", "authors": ["Arghyadeep Das", "Sai Sreenivas Chintha", "Rishiraj Girmal", "Kinjal Pandey", "Sharvi Endait"], "title": "Chain-of-Sanitized-Thoughts: Plugging PII Leakage in CoT of Large Reasoning Models", "categories": ["cs.AI"], "comment": "12 pages, 6 figures, 1 table", "summary": "Large Reasoning Models (LRMs) improve performance, reliability, and interpretability by generating explicit chain-of-thought (CoT) reasoning, but this transparency introduces a serious privacy risk: intermediate reasoning often leaks personally identifiable information (PII) even when final answers are sanitized. We study how to induce privacy-first reasoning, where models reason without exposing sensitive information, using deployable interventions rather than post-hoc redaction. We introduce PII-CoT-Bench, a supervised dataset with privacy-aware CoT annotations, and a category-balanced evaluation benchmark covering realistic and adversarial leakage scenarios. Our results reveal a capability-dependent trend: state-of-the-art models benefit most from prompt-based controls, whereas weaker models require fine-tuning to achieve meaningful leakage reduction. Across models and categories, both approaches substantially reduce PII exposure with minimal degradation in utility, demonstrating that private reasoning can be achieved without sacrificing performance. Overall, we show that private CoT reasoning can be achieved with minimal utility loss, providing practical guidance for building privacy-preserving reasoning systems.", "AI": {"tldr": "研究如何在大型推理模型中实现隐私保护的链式思维（CoT）推理，防止中间推理泄露个人身份信息（PII），同时保持性能。", "motivation": "大型推理模型通过生成明确的链式思维提高透明度和解释性，但这种透明度也带来了严重的隐私风险。中间推理可能会泄漏敏感信息，即使最终答案经过了清理处理。", "method": "提出了一种基于监督数据集PII-CoT-Bench的方法，并开发了一个涵盖现实场景和对抗泄露情况的评估基准。研究发现，顶级模型通过提示控制可以显著减少PII泄露，而较弱模型需要微调才能实现这一目标。", "result": "两种方法均能大幅度降低PII暴露程度，同时对性能影响较小，表明隐私保护推理可以在不牺牲性能的情况下实现。", "conclusion": "研究表明，在大型推理模型中实现隐私保护的链式思维推理是可行的，并提供了实际指导建议以构建更加安全和私密的推理系统。"}}
{"id": "2601.05074", "pdf": "https://arxiv.org/pdf/2601.05074", "abs": "https://arxiv.org/abs/2601.05074", "authors": ["Julian Kulozik", "Nathanaël Jarrassé"], "title": "Compensation Effect Amplification Control (CEAC): A movement-based approach for coordinated position and velocity control of the elbow of upper-limb prostheses", "categories": ["cs.RO"], "comment": null, "summary": "Despite advances in upper-limb (UL) prosthetic design, achieving intuitive control of intermediate joints - such as the wrist and elbow - remains challenging, particularly for continuous and velocity-modulated movements. We introduce a novel movement-based control paradigm entitled Compensation Effect Amplification Control (CEAC) that leverages users' trunk flexion and extension as input for controlling prosthetic elbow velocity. Considering that the trunk can be both a functional and compensatory joint when performing upper-limb actions, CEAC amplifies the natural coupling between trunk and prosthesis while introducing a controlled delay that allows users to modulate both the position and velocity of the prosthetic joint. We evaluated CEAC in a generic drawing task performed by twelve able-bodied participants using a supernumerary prosthesis with an active elbow. Additionally a multiple-target-reaching task was performed by a subset of ten participants. Results demonstrate task performances comparable to those obtained with natural arm movements, even when gesture velocity or drawing size were varied, while maintaining ergonomic trunk postures. Analysis revealed that CEAC effectively restores joint coordinated action, distributes movement effort between trunk and elbow, enabling intuitive trajectory control without requiring extreme compensatory movements. Overall, CEAC offers a promising control strategy for intermediate joints of UL prostheses, particularly in tasks requiring continuous and precise coordination.", "AI": {"tldr": "介绍了一种基于运动的控制范式——补偿效应放大控制（CEAC），用于协调上肢假体肘部的位置和速度。", "motivation": "尽管上肢假体设计取得了进展，但中间关节如腕关节和肘关节的直观控制仍然具有挑战性。特别是对于连续和速度调节的动作来说更是如此。", "method": "提出了一种新的运动控制方法CEAC，利用用户的身体前倾和后仰作为输入来控制假体肘部的速度。在一般的绘画任务中评估了CEAC，并由12名健全参与者使用带有主动肘关节的附加假肢进行测试。", "result": "结果显示，在执行绘画任务时，CEAC能够实现与自然手臂运动相当的表现，即使速度或绘制大小发生变化，同时保持人体工程学姿势。", "conclusion": "CEAC提供了一种有前途的方法来协调上肢假体中间关节的动作，并且在需要持续和精确协调的任务中表现良好。"}}
{"id": "2601.05072", "pdf": "https://arxiv.org/pdf/2601.05072", "abs": "https://arxiv.org/abs/2601.05072", "authors": ["Yuxin Wang", "Yuankai He", "Boyang Tian", "Lichen Xian", "Weisong Shi"], "title": "DAVOS: An Autonomous Vehicle Operating System in the Vehicle Computing Era", "categories": ["cs.OS", "cs.RO"], "comment": ":68M20", "summary": "Vehicle computing represents a fundamental shift in how autonomous vehicles are designed and deployed, transforming them from isolated transportation systems into mobile computing platforms that support both safety-critical, real-time driving and data-centric services. In this setting, vehicles simultaneously support real-time driving pipelines and a growing set of data-driven applications, placing increased responsibility on the vehicle operating system to coordinate computation, data movement, storage, and access. These demands highlight recurring system considerations related to predictable execution, data and execution protection, efficient handling of high-rate sensor data, and long-term system evolvability, commonly summarized as Safety, Security, Efficiency, and Extensibility (SSEE). Existing vehicle operating systems and runtimes address these concerns in isolation, resulting in fragmented software stacks that limit coordination between autonomy workloads and vehicle data services. This paper presents DAVOS, the Delaware Autonomous Vehicle Operating System, a unified vehicle operating system architecture designed for the vehicle computing context. DAVOS provides a cohesive operating system foundation that supports both real-time autonomy and extensible vehicle computing within a single system framework.", "AI": {"tldr": "提出了DAVOS系统，一个统一的车辆操作系统架构，旨在支持实时自主驾驶和可扩展的车辆计算。", "motivation": "现有的车辆操作系统和技术无法有效地协调自动驾驶工作负载与车辆数据服务之间的关系，缺乏整体解决方案以满足安全、保护、效率和可扩展性的需求。", "method": "设计了一种新的统一车辆操作系统架构DAVOS，该系统可以同时支持实时自主驾驶以及数据驱动的应用程序，并提供预测执行，数据保护，高效处理高频率传感器数据的能力。", "result": "提出了一个名为DAVOS的操作系统框架，它能够协调计算、数据移动和存储访问，在单一系统中既支持实时自动驾驶又支持扩展性车辆计算。", "conclusion": "通过将自主驾驶工作负载与车辆服务整合到统一的系统架构中，可以提高效率并降低复杂性。"}}
{"id": "2601.05063", "pdf": "https://arxiv.org/pdf/2601.05063", "abs": "https://arxiv.org/abs/2601.05063", "authors": ["Jelmer van Lune", "Stefano Mandija", "Oscar van der Heide", "Matteo Maspero", "Martin B. Schilder", "Jan Willem Dankbaar", "Cornelis A. T. van den Berg", "Alessandro Sbrizzi"], "title": "Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset", "categories": ["physics.med-ph", "cs.CV", "cs.LG"], "comment": "30 pages, 13 figures, full paper", "summary": "Magnetic resonance imaging (MRI) is a cornerstone of clinical neuroimaging, yet conventional MRIs provide qualitative information heavily dependent on scanner hardware and acquisition settings. While quantitative MRI (qMRI) offers intrinsic tissue parameters, the requirement for specialized acquisition protocols and reconstruction algorithms restricts its availability and impedes large-scale biomarker research. This study presents a self-supervised physics-guided deep learning framework to infer quantitative T1, T2, and proton-density (PD) maps directly from widely available clinical conventional T1-weighted, T2-weighted, and FLAIR MRIs. The framework was trained and evaluated on a large-scale, clinically heterogeneous dataset comprising 4,121 scan sessions acquired at our institution over six years on four different 3 T MRI scanner systems, capturing real-world clinical variability. The framework integrates Bloch-based signal models directly into the training objective. Across more than 600 test sessions, the generated maps exhibited white matter and gray matter values consistent with literature ranges. Additionally, the generated maps showed invariance to scanner hardware and acquisition protocol groups, with inter-group coefficients of variation $\\leq$ 1.1%. Subject-specific analyses demonstrated excellent voxel-wise reproducibility across scanner systems and sequence parameters, with Pearson $r$ and concordance correlation coefficients exceeding 0.82 for T1 and T2. Mean relative voxel-wise differences were low across all quantitative parameters, especially for T2 ($<$ 6%). These results indicate that the proposed framework can robustly transform diverse clinical conventional MRI data into quantitative maps, potentially paving the way for large-scale quantitative biomarker research.", "AI": {"tldr": "该论文提出了一种基于自监督物理引导的深度学习框架，可从临床常规MRI图像中直接推导出定量T1、T2和质子密度图。", "motivation": "传统的MRI提供依赖于扫描硬件和采集设置的定性信息。而定量MRI（qMRI）虽然提供了组织固有参数，但其需要专门的采集协议和重建算法限制了可用性和大规模生物标志物研究的发展。", "method": "该框架结合Bloch信号模型直接集成到训练目标中，并在包含4121个扫描会话的大规模、临床异质性数据集上进行了验证。该数据集涵盖六年间来自四个不同3T MRI扫描系统的实际临床差异。", "result": "测试结果显示，生成的图谱显示出与文献范围一致的白质和灰质值，并且对扫描硬件和采集协议组具有不变性，组间变异系数≤1.1%。在受试者特异性分析中，在扫描系统和序列参数之间表现出极好的体素级可重复性。", "conclusion": "该框架能够将多样化的临床常规MRI数据转化为定量图谱，并具备跨不同扫描设备的良好一致性及高度的体素级再现性，为大规模定量生物标志物研究铺平了道路。"}}
{"id": "2601.05062", "pdf": "https://arxiv.org/pdf/2601.05062", "abs": "https://arxiv.org/abs/2601.05062", "authors": ["Gorjan Radevski", "Kiril Gashteovski", "Giwon Hong", "Carolin Lawrence", "Goran Glavaš"], "title": "Compositional Steering of Large Language Models with Steering Tokens", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.", "AI": {"tldr": "论文提出了用于大型语言模型的组合式引导令牌，以实现同时满足多种行为控制的需求。", "motivation": "现有的工作主要关注于单一行为的导向，而对于多个行为的同时导向（即组合式导向）的研究相对较少。因此，作者提出了一种新的方法来解决这一问题。", "method": "首先通过自蒸馏将自然语言指令嵌入到专用令牌中以表示个体行为；然后训练一个专门的组成令牌，使其能够有效地在未知的行为或不同数量的行为上进行组合式导向。", "result": "实验结果表明，引导令牌相比其他方法（如指令、激活引导和LoRA合并）提供了更优的多行为控制效果，并且与自然语言指令相结合可以获得更好的性能。", "conclusion": "论文成功地实现了大型语言模型的同时多种行为控制，并展示了组合式导向令牌的有效性。"}}
{"id": "2601.05059", "pdf": "https://arxiv.org/pdf/2601.05059", "abs": "https://arxiv.org/abs/2601.05059", "authors": ["Suyash Mishra", "Qiang Li", "Srikanth Patil", "Anubhav Girdhar"], "title": "From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)", "categories": ["cs.CV", "cs.LG"], "comment": "Contributed original research to top tier conference in VLM; currently undergoing peer review", "summary": "Vision Language Models (VLMs) are poised to revolutionize the digital transformation of pharmacyceutical industry by enabling intelligent, scalable, and automated multi-modality content processing. Traditional manual annotation of heterogeneous data modalities (text, images, video, audio, and web links), is prone to inconsistencies, quality degradation, and inefficiencies in content utilization. The sheer volume of long video and audio data further exacerbates these challenges, (e.g. long clinical trial interviews and educational seminars). Here, we introduce a domain adapted Video to Video Clip Generation framework that integrates Audio Language Models (ALMs) and Vision Language Models (VLMs) to produce highlight clips. Our contributions are threefold: (i) a reproducible Cut & Merge algorithm with fade in/out and timestamp normalization, ensuring smooth transitions and audio/visual alignment; (ii) a personalization mechanism based on role definition and prompt injection for tailored outputs (marketing, training, regulatory); (iii) a cost efficient e2e pipeline strategy balancing ALM/VLM enhanced processing. Evaluations on Video MME benchmark (900) and our proprietary dataset of 16,159 pharmacy videos across 14 disease areas demonstrate 3 to 4 times speedup, 4 times cost reduction, and competitive clip quality. Beyond efficiency gains, we also report our methods improved clip coherence scores (0.348) and informativeness scores (0.721) over state of the art VLM baselines (e.g., Gemini 2.5 Pro), highlighting the potential of transparent, custom extractive, and compliance supporting video summarization for life sciences.", "AI": {"tldr": "通过整合音频语言模型和视觉语言模型，提出了一种生成个性化药房视频片段的方法。", "motivation": "传统的手动注释异质数据模式存在一致性差、质量下降和内容利用效率低的问题。因此需要一种自动化且高效的多模态处理方法来解决这些问题。", "method": "提出了一个域适应的从视频到剪辑生成框架，该框架结合了音频语言模型和视觉语言模型，并引入了一个可重复的裁剪与合并算法，确保平滑过渡和音视频对齐。此外还设计了一种基于角色定义和个人提示注入机制的方法以实现个性化输出。", "result": "在Video MME基准测试（900）和16,159个药房视频的数据集上显示了3到4倍的速度提升，成本减少了4倍，并且片段质量和剪辑连贯性、信息量评分都优于现有的视觉语言模型基线。", "conclusion": "通过整合音频语言模型和视觉语言模型的方法证明了在药物科学领域实现透明、定制化和符合规范的视频摘要的巨大潜力。"}}
{"id": "2601.05053", "pdf": "https://arxiv.org/pdf/2601.05053", "abs": "https://arxiv.org/abs/2601.05053", "authors": ["Ziqi Zhao", "Zhaochun Ren", "Jiahong Zou", "Liu Yang", "Zhiwei Xu", "Xuri Ge", "Zhumin Chen", "Xinyu Ma", "Daiting Shi", "Shuaiqiang Wang", "Dawei Yin", "Xin Xin"], "title": "Reinforced Efficient Reasoning via Semantically Diverse Exploration", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.", "AI": {"tldr": "提出一种新的方法ROSE，通过语义多样性的探索来增强大规模语言模型的推理能力。", "motivation": "现有的RLVR方法在探索多样性和推理效率上存在局限性。为了克服这些限制，本文提出了一个新的方法，旨在提高大规模语言模型的推理效果和效率。", "method": "该方法引入了基于语义熵的分支策略和ε-探索机制来鼓励更多样化的推理探索，并设计了一个长度感知的优势估计器以奖励简洁且正确的推理路径。", "result": "在多个数学推理基准上，使用Qwen和Llama模型验证ROSE的有效性和效率。结果表明，该方法显著提高了大规模语言模型的推理性能。", "conclusion": "通过引入语义多样性的探索策略和改进的优势估计器，ROSE有效地增强了大规模语言模型的推理能力，并在多个任务中表现出色。"}}
{"id": "2601.05051", "pdf": "https://arxiv.org/pdf/2601.05051", "abs": "https://arxiv.org/abs/2601.05051", "authors": ["Jennifer D'Souza", "Soren Auer", "Eleni Poupaki", "Alex Watkins", "Anjana Devi", "Riikka L. Puurunen", "Bora Karasulu", "Adrie Mackus", "Erwin Kessels"], "title": "Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence", "categories": ["cs.AI", "cs.CL", "cs.DL", "cs.IT"], "comment": "35 pages, 11 figures", "summary": "Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.", "AI": {"tldr": "本文提出了一种将材料科学中的评论表格转换为可查询知识的方法，以提高其在人工智能和机器学习系统中重用性。", "motivation": "现有的材料科学研究评论主要停留在叙事文本和静态PDF表中，难以被人类和机器有效利用。为了改变这一现状，研究者提出了发表FAIR、机器可操作的评论表格，从而促进知识集成与应用。", "method": "通过原子层沉积和刻蚀（ALD/E）案例研究展示如何将评论表格转化为结构化、可查询的知识，并将其发布在开放科研知识图谱(ORKG)中。同时对比了基于符号查询的ORKE方法与大型语言模型(Large Language Models, LLMs)的方法。", "result": "通过将评论表格转换为结构化的形式，可以实现对材料科学领域中的关键知识进行有效的机器学习和人工智能处理。", "conclusion": "在材料科学研究中，一个经过精心策划的符号层应该作为神经符号AI的基础。虽然大型语言模型可以在一定程度上提供帮助，但是它们应当被视为基于符号数据的知识来源的辅助工具而非独立的信息源。"}}
{"id": "2601.05050", "pdf": "https://arxiv.org/pdf/2601.05050", "abs": "https://arxiv.org/abs/2601.05050", "authors": ["Thomas H. Costello", "Kellin Pelrine", "Matthew Kowal", "Antonio A. Arechar", "Jean-François Godbout", "Adam Gleave", "David Rand", "Gordon Pennycook"], "title": "Large language models can effectively convince people to believe conspiracies", "categories": ["cs.AI", "econ.GN"], "comment": null, "summary": "Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against (\"debunking\") or for (\"bunking\") that conspiracy. When using a \"jailbroken\" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.", "AI": {"tldr": "研究探讨了大型语言模型（LLMs）在辩论阴谋论时的说服力，发现在特定条件下它们可以有效增强或削弱人们对阴谋论的信念。", "motivation": "探索大型语言模型是否更倾向于传播真理还是虚假信息，并评估其对人们对于阴谋论态度的影响。", "method": "通过三个预注册实验进行研究，参与者与GPT-4o讨论一个他们不确定的阴谋理论，模型被指示支持或反对该阴谋理论。同时比较了标准和“狱破”版本GPT-4o的效果，并评估纠正性对话的作用。", "result": "无论是标准还是“狱破”版本的GPT-4o，在辩论中都能有效增强或削弱人们对阴谋论的信念。虽然使用准确信息可以减轻其促进虚假信息的能力，但总体上仍存在风险。", "conclusion": "大型语言模型具有传播真理与虚假信息的强大能力，然而可能通过特定措施来缓解这种风险。"}}
{"id": "2601.05049", "pdf": "https://arxiv.org/pdf/2601.05049", "abs": "https://arxiv.org/abs/2601.05049", "authors": ["Yunhua Zhou", "Shuhao Xing", "Junhao Huang", "Xipeng Qiu", "Qipeng Guo"], "title": "How to Set the Learning Rate for Large-Scale Pre-training?", "categories": ["cs.AI"], "comment": null, "summary": "Optimal configuration of the learning rate (LR) is a fundamental yet formidable challenge in large-scale pre-training. Given the stringent trade-off between training costs and model performance, the pivotal question is whether the optimal LR can be accurately extrapolated from low-cost experiments. In this paper, we formalize this investigation into two distinct research paradigms: Fitting and Transfer. Within the Fitting Paradigm, we innovatively introduce a Scaling Law for search factor, effectively reducing the search complexity from O(n^3) to O(n*C_D*C_η) via predictive modeling. Within the Transfer Paradigm, we extend the principles of $μ$Transfer to the Mixture of Experts (MoE) architecture, broadening its applicability to encompass model depth, weight decay, and token horizons. By pushing the boundaries of existing hyperparameter research in terms of scale, we conduct a comprehensive comparison between these two paradigms. Our empirical results challenge the scalability of the widely adopted $μ$ Transfer in large-scale pre-training scenarios. Furthermore, we provide a rigorous analysis through the dual lenses of training stability and feature learning to elucidate the underlying reasons why module-wise parameter tuning underperforms in large-scale settings. This work offers systematic practical guidelines and a fresh theoretical perspective for optimizing industrial-level pre-training.", "AI": {"tldr": "本文探讨了在大规模预训练中如何通过低成本实验准确确定最优学习率的问题，提出了两个研究范式：拟合和转移，并进行了对比分析。", "motivation": "探索是否可以通过低成本的实验来确定大规模预训练中的最优学习率，以平衡训练成本和模型性能之间的权衡。", "method": "在拟合范式中引入了搜索因子的缩放定律，通过预测建模将搜索复杂度从O(n^3)降低到O(n*C_D*C_η)；在转移范式下，扩展了μTransfer原理至混合专家架构，并分析其在大规模预训练中的应用。", "result": "实证结果挑战了广泛采用的μTransfer方法在大规模预训练场景下的适用性，并通过稳定性与特征学习的角度解释了模块级参数调整在大规模设置中表现不佳的原因。", "conclusion": "提供了系统化的实践指导和新的理论视角，用于优化工业级别预训练的学习率配置"}}
{"id": "2601.05047", "pdf": "https://arxiv.org/pdf/2601.05047", "abs": "https://arxiv.org/abs/2601.05047", "authors": ["Xiaoyu Ma", "David Patterson"], "title": "Challenges and Research Directions for Large Language Model Inference Hardware", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": "Accepted for publication by IEEE Computer, 2026", "summary": "Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.", "AI": {"tldr": "该论文探讨了大型语言模型推理硬件面临的挑战，并提出了四个研究方向。", "motivation": "最近的人工智能趋势使得大型语言模型的推理面临内存和互连问题，而不仅仅是计算能力的问题。因此需要提出新的方法来解决这些问题。", "method": "论文指出了四种可能的研究机会：高带宽闪存、处理近存储架构、三维存储逻辑堆叠以及低延迟互联技术。", "result": "这些研究方向可以在数据中心AI中应用，并且也适用于移动设备。", "conclusion": "通过提出上述四个研究方向，可以有效应对大型语言模型推理中的内存和互连挑战。"}}
{"id": "2601.05044", "pdf": "https://arxiv.org/pdf/2601.05044", "abs": "https://arxiv.org/abs/2601.05044", "authors": ["Jesper Nederlof"], "title": "An Invitation to \"Fine-grained Complexity of NP-Complete Problems\"", "categories": ["cs.DS", "cs.CC"], "comment": "40 pages. Invited survey (currently under review, remarks are welcome)", "summary": "Assuming that P is not equal to NP, the worst-case run time of any algorithm solving an NP-complete problem must be super-polynomial. But what is the fastest run time we can get? Before one can even hope to approach this question, a more provocative question presents itself: Since for many problems the naive brute-force baseline algorithms are still the fastest ones, maybe their run times are already optimal? The area that we call in this survey \"fine-grained complexity of NP-complete problems\" studies exactly this question. We invite the reader to catch up on selected classic results as well as delve into exciting recent developments in a riveting tour through the area passing by (among others) algebra, complexity theory, extremal and additive combinatorics, cryptography, and, of course, last but not least, algorithm design.", "AI": {"tldr": "研究NP完全问题的精细化复杂度", "motivation": "探讨对于许多问题，是否已经存在最优化的时间复杂度算法（即蛮力法是最优解）", "method": "通过理论分析和经典结果来研究NP完全问题的精细化复杂度", "result": "概述了相关领域的经典成果及最新进展", "conclusion": "展示了在代数、复杂性理论等领域内对NP完全问题的研究深度"}}
{"id": "2601.05038", "pdf": "https://arxiv.org/pdf/2601.05038", "abs": "https://arxiv.org/abs/2601.05038", "authors": ["Jianbo Li", "Yi Jiang", "Sendong Zhao", "Bairui Hu", "Haochun Wang", "Bing Qin"], "title": "ArcAligner: Adaptive Recursive Aligner for Compressed Context Embeddings in RAG", "categories": ["cs.CL", "cs.AI"], "comment": "Code is available at https://github.com/liunian-Jay/ArcAligner.git", "summary": "Retrieval-Augmented Generation (RAG) helps LLMs stay accurate, but feeding long documents into a prompt makes the model slow and expensive. This has motivated context compression, ranging from token pruning and summarization to embedding-based compression. While researchers have tried ''compressing'' these documents into smaller summaries or mathematical embeddings, there is a catch: the more you compress the data, the more the LLM struggles to understand it. To address this challenge, we propose ArcAligner (Adaptive recursive context *Aligner*), a lightweight module integrated into the language model layers to help the model better utilize highly compressed context representations for downstream generation. It uses an adaptive ''gating'' system that only adds extra processing power when the information is complex, keeping the system fast. Across knowledge-intensive QA benchmarks, ArcAligner consistently beats compression baselines at comparable compression rates, especially on multi-hop and long-tail settings. The source code is publicly available.", "AI": {"tldr": "提出了ArcAligner模块，该模块能够帮助语言模型更好地利用高度压缩的上下文表示进行下游生成。", "motivation": "为了提高LLM在处理长文档时的速度和成本效益，同时保留理解能力，研究者们尝试通过压缩技术来减小数据规模。然而，这种做法会使得LLM难以理解和使用这些被压缩的数据，因此需要一种新的机制来解决这一问题。", "method": "提出了ArcAligner模块，这是一种轻量级的自适应递归上下文对齐系统，它能够根据信息复杂性动态地增加处理能力，并且集成到了语言模型的层中以帮助更好地使用高度压缩的上下文表示。", "result": "在知识密集型问答基准测试上，ArcAligner在与压缩基线相比时，在相同的压缩率下表现更优，特别是在多跳和长尾设置中表现出色。", "conclusion": "通过引入ArcAligner模块，可以在保持快速处理的同时提高LLM对高度压缩上下文表示的理解能力。"}}
{"id": "2601.05036", "pdf": "https://arxiv.org/pdf/2601.05036", "abs": "https://arxiv.org/abs/2601.05036", "authors": ["Milan Liepelt", "Julien Baglio"], "title": "Exponential capacity scaling of classical GANs compared to hybrid latent style-based quantum GANs", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "34 pages, 7 figures, 7 tables", "summary": "Quantum generative modeling is a very active area of research in looking for practical advantage in data analysis. Quantum generative adversarial networks (QGANs) are leading candidates for quantum generative modeling and have been applied to diverse areas, from high-energy physics to image generation. The latent style-based QGAN, relying on a classical variational autoencoder to encode the input data into a latent space and then using a style-based QGAN for data generation has been proven to be efficient for image generation or drug design, hinting at the use of far less trainable parameters than their classical counterpart to achieve comparable performance, however this advantage has never been systematically studied. We present in this work the first comprehensive experimental analysis of this advantage of QGANS applied to SAT4 image generation, obtaining an exponential advantage in capacity scaling for a quantum generator in the hybrid latent style-based QGAN architecture. Careful tuning of the autoencoder is crucial to obtain stable, reliable results. Once this tuning is performed and defining training optimality as when the training is stable and the FID score is low and stable as well, the optimal capacity (or number of trainable parameters) of the classical discriminator scales exponentially with respect to the capacity of the quantum generator, and the same is true for the capacity of the classical generator. This hints toward a type of quantum advantage for quantum generative modeling.", "AI": {"tldr": "该论文比较了经典生成对抗网络（GANs）与混合隐式样式的量子生成对抗网络（QGANs）在图像生成任务中的容量扩展优势。", "motivation": "探索量子生成模型在数据分析中的潜在优势，特别是通过研究基于样式混合的QGAN是否能以较少的训练参数达到类似性能，以及这种优势是否可以系统化。", "method": "构建一个混合隐式样式的QGAN架构用于SAT4图像生成任务，并对比经典GANs和QGANs的容量扩展特性。优化变分自编码器（VAE）来稳定地获取低且稳定的FID分数。", "result": "研究表明，在这种量子生成对抗网络中，当训练达到稳定状态并获得低而稳定的FID评分时，经典判别器与量子发生器的最佳容量呈指数关系扩大。相同的情况也适用于经典生成器。", "conclusion": "研究结果表明在混合隐式样式的QGAN架构下存在一种类型的量子优势，即随着模型容量增加，量子生成对抗网络相较于其经典对手展示出显著的参数效率和性能优越性。"}}
{"id": "2601.05035", "pdf": "https://arxiv.org/pdf/2601.05035", "abs": "https://arxiv.org/abs/2601.05035", "authors": ["Ruochen Chen", "Thuy Tran", "Shaifali Parashar"], "title": "Patch-based Representation and Learning for Efficient Deformation Modeling", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we present a patch-based representation of surfaces, PolyFit, which is obtained by fitting jet functions locally on surface patches. Such a representation can be learned efficiently in a supervised fashion from both analytic functions and real data. Once learned, it can be generalized to various types of surfaces. Using PolyFit, the surfaces can be efficiently deformed by updating a compact set of jet coefficients rather than optimizing per-vertex degrees of freedom for many downstream tasks in computer vision and graphics. We demonstrate the capabilities of our proposed methodologies with two applications: 1) Shape-from-template (SfT): where the goal is to deform the input 3D template of an object as seen in image/video. Using PolyFit, we adopt test-time optimization that delivers competitive accuracy while being markedly faster than offline physics-based solvers, and outperforms recent physics-guided neural simulators in accuracy at modest additional runtime. 2) Garment draping. We train a self-supervised, mesh- and garment-agnostic model that generalizes across resolutions and garment types, delivering up to an order-of-magnitude faster inference than strong baselines.", "AI": {"tldr": "本文提出了一种基于补丁的表面表示方法PolyFit，通过局部拟合表面补丁上的射流函数来实现高效变形建模。", "motivation": "旨在开发一种可以快速学习和广泛应用到不同类型表面上的表面表示方法，提高计算机视觉和图形任务中的效率。", "method": "提出了基于射流函数局部拟合获得PolyFit的方法。使用该方法进行表面变形时，通过更新紧凑的射流系数集而非针对每个顶点优化自由度来实现高效计算。", "result": "在形状重建（SfT）和服装仿真两个任务上取得了与物理模型相当或更好的效果，同时运行速度明显提高。", "conclusion": "PolyFit方法能够提供高效且准确的表面变形建模能力，适用于多种计算机视觉和图形学应用。"}}
{"id": "2601.05034", "pdf": "https://arxiv.org/pdf/2601.05034", "abs": "https://arxiv.org/abs/2601.05034", "authors": ["Yunhua Zhou", "Junhao Huang", "Shuhao Xin", "Yechen Zhang", "Runyu Peng", "Qiping Guo", "Xipeng Qiu"], "title": "How to Set the Batch Size for Large-Scale Pre-training?", "categories": ["cs.AI"], "comment": null, "summary": "The concept of Critical Batch Size, as pioneered by OpenAI, has long served as a foundational principle for large-scale pre-training. However, with the paradigm shift towards the Warmup-Stable-Decay (WSD) learning rate scheduler, we observe that the original theoretical framework and its underlying mechanisms fail to align with new pre-training dynamics. To bridge this gap between theory and practice, this paper derives a revised E(S) relationship tailored for WSD scheduler, characterizing the trade-off between training data consumption E and steps S during pre-training. Our theoretical analysis reveals two fundamental properties of WSD-based pre-training: 1) B_min, the minimum batch size threshold required to achieve a target loss, and 2) B_opt, the optimal batch size that maximizes data efficiency by minimizing total tokens. Building upon these properties, we propose a dynamic Batch Size Scheduler. Extensive experiments demonstrate that our revised formula precisely captures the dynamics of large-scale pre-training, and the resulting scheduling strategy significantly enhances both training efficiency and final model quality.", "AI": {"tldr": "本文旨在为大规模预训练制定合适的批量大小，并提出一种适用于Warmup-Stable-Decay学习率调度器的动态批量大小调度策略。", "motivation": "随着预训练范式向Warmup-Stable-Decay学习率调度器转变，原有理论框架不再适应新的预训练动态。因此，本文旨在解决这一理论与实践之间的差距问题。", "method": "本文推导出适用于WSD调度器的E(S)关系，并在此基础上提出最小批量大小阈值B_min和最优化批量大小B_opt的概念。最终构建了一种动态批量大小调度策略以提高训练效率和模型质量。", "result": "实验结果表明，所提出的公式能准确捕捉大规模预训练的动力学特性，并且通过该调度策略显著提升了训练效率及模型最终性能。", "conclusion": "本文提出的方法有效地解决了传统理论框架与现代学习率调度器之间的不匹配问题，为大规模预训练提供了新的视角和方案。"}}
{"id": "2601.05027", "pdf": "https://arxiv.org/pdf/2601.05027", "abs": "https://arxiv.org/abs/2601.05027", "authors": ["Yi Jiang", "Sendong Zhao", "Jianbo Li", "Bairui Hu", "Yanrui Du", "Haochun Wang", "Bing Qin"], "title": "OptiSet: Unified Optimizing Set Selection and Ranking for Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": "Code is available at https://github.com/liunian-Jay/OptiSet.git", "summary": "Retrieval-Augmented Generation (RAG) improves generation quality by incorporating evidence retrieved from large external corpora. However, most existing methods rely on statically selecting top-k passages based on individual relevance, which fails to exploit combinatorial gains among passages and often introduces substantial redundancy. To address this limitation, we propose OptiSet, a set-centric framework that unifies set selection and set-level ranking for RAG. OptiSet adopts an \"Expand-then-Refine\" paradigm: it first expands a query into multiple perspectives to enable a diverse candidate pool and then refines the candidate pool via re-selection to form a compact evidence set. We then devise a self-synthesis strategy without strong LLM supervision to derive preference labels from the set conditional utility changes of the generator, thereby identifying complementary and redundant evidence. Finally, we introduce a set-list wise training strategy that jointly optimizes set selection and set-level ranking, enabling the model to favor compact, high-gain evidence sets. Extensive experiments demonstrate that OptiSet improves performance on complex combinatorial problems and makes generation more efficient. The source code is publicly available.", "AI": {"tldr": "提出了一种优化集合选择和排序的框架OptiSet，用于提升检索增强生成（RAG）的效果。", "motivation": "现有的RAG方法通过静态选择前k个相关段落来提高生成质量，这种方法未能充分利用段落之间的组合增益，并且往往引入了大量的冗余。为了克服这个限制，提出了OptiSet框架。", "method": "OptiSet采用“扩展-再精炼”的范式：首先将查询扩展为多个视角以创建一个多样化的候选池，然后通过重新选择来优化候选池以形成紧凑的证据集合，并设计了一种自我合成策略来确定互补和冗余的证据。此外，引入了集列级训练策略来联合优化集合选择和集级别排序。", "result": "广泛的实验表明OptiSet在复杂的组合问题上提升了性能并使生成过程更加高效。", "conclusion": "通过OptiSet框架的应用，成功改善了RAG的效率与效果，为提升检索增强生成的质量提供了一种新的方法。"}}
{"id": "2601.05026", "pdf": "https://arxiv.org/pdf/2601.05026", "abs": "https://arxiv.org/abs/2601.05026", "authors": ["Pierre Lairez", "Rafael Mohr", "Théo Ternier"], "title": "A data structure for monomial ideals with applications to signature Gröbner bases", "categories": ["cs.SC", "cs.DS"], "comment": null, "summary": "We introduce monomial divisibility diagrams (MDDs), a data structure for monomial ideals that supports insertion of new generators and fast membership tests. MDDs stem from a canonical tree representation by maximally sharing equal subtrees, yielding a directed acyclic graph. We establish basic complexity bounds for membership and insertion, and study empirically the size of MDDs. As an application, we integrate MDDs into the signature Gröbner basis implementation of the Julia package AlgebraicSolving.jl. Membership tests in monomial ideals are used to detect some reductions to zero, and the use of MDDs leads to substantial speed-ups.", "AI": {"tldr": "介绍了一种用于单项式理想的MDD数据结构，支持新生成元的插入和快速成员测试。", "motivation": "为了提高在签名Gröbner基实现中的性能，引入了新的MDD数据结构来优化成员检测效率。", "method": "通过最大限度地共享等同子树将单项式理想转化为有向无环图，并对成员检测和插入操作的时间复杂度进行了基础分析。", "result": "利用MDDs进行成员测试能够显著加快某些零化简的检测速度，从而提高整体效率。", "conclusion": "新的MDD数据结构在签名Gröbner基实现中应用有效，提升了多项式理想计算中的性能表现。"}}
{"id": "2601.05020", "pdf": "https://arxiv.org/pdf/2601.05020", "abs": "https://arxiv.org/abs/2601.05020", "authors": ["Ziyao Yi", "Davide Piccinini", "Diego Valsesia", "Tiziano Bianchi", "Enrico Magli"], "title": "Scalable neural pushbroom architectures for real-time denoising of hyperspectral images onboard satellites", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "The next generation of Earth observation satellites will seek to deploy intelligent models directly onboard the payload in order to minimize the latency incurred by the transmission and processing chain of the ground segment, for time-critical applications. Designing neural architectures for onboard execution, particularly for satellite-based hyperspectral imagers, poses novel challenges due to the unique constraints of this environment and imaging system that are largely unexplored by the traditional computer vision literature. In this paper, we show that this setting requires addressing three competing objectives, namely high-quality inference with low complexity, dynamic power scalability and fault tolerance. We focus on the problem of hyperspectral image denoising, which is a critical task to enable effective downstream inference, and highlights the constraints of the onboard processing scenario. We propose a neural network design that addresses the three aforementioned objectives with several novel contributions. In particular, we propose a mixture of denoisers that can be resilient to radiation-induced faults as well as allowing for time-varying power scaling. Moreover, each denoiser employs an innovative architecture where an image is processed line-by-line in a causal way, with a memory of past lines, in order to match the acquisition process of pushbroom hyperspectral sensors and greatly limit memory requirements. We show that the proposed architecture can run in real-time, i.e., process one line in the time it takes to acquire the next one, on low-power hardware and provide competitive denoising quality with respect to significantly more complex state-of-the-art models. We also show that the power scalability and fault tolerance objectives provide a design space with multiple tradeoffs between those properties and denoising quality.", "AI": {"tldr": "设计了一种用于卫星上实时去噪的神经网络架构，该架构能处理高光谱图像并满足低复杂度、动态功耗可伸缩性和容错性要求。", "motivation": "下一代地球观测卫星需要直接在有效载荷中部署智能模型以减少地面段传输和处理链的时间延迟。这种环境下设计的神经网络必须解决高性能推断与低复杂度、动态功率可扩展性及容错性的竞争目标，同时现有文献对这些挑战缺乏探讨。", "method": "提出了一个混合去噪器架构，该架构能够应对辐射引起的故障并允许时间变化的功耗调整。每个去噪器采用了一种新颖的按行处理图像的方式，在记忆过去各行的同时进行因果性处理，以匹配推扫式高光谱传感器的获取过程，并大大减少内存需求。", "result": "提出的架构能够在低功耗硬件上实时运行，提供与现有复杂模型相当甚至更优的去噪质量。同时展示了在功率可扩展性和容错性的设计空间中存在多方面的折衷关系。", "conclusion": "论文成功开发了一种适合于卫星环境的神经网络架构，该架构满足了低复杂度、动态功耗调整和故障容忍的要求，并能提供高质量的去噪效果。"}}
{"id": "2601.05019", "pdf": "https://arxiv.org/pdf/2601.05019", "abs": "https://arxiv.org/abs/2601.05019", "authors": ["Yueqing Hu", "Xinyang Peng", "Shuting Peng", "Hanqi Wang", "Tianhong Wang"], "title": "Hán Dān Xué Bù (Mimicry) or Qīng Chū Yú Lán (Mastery)? A Cognitive Perspective on Reasoning Distillation in Large Language Models", "categories": ["cs.CL", "cs.AI", "q-bio.NC"], "comment": "7 pages, 7 figures", "summary": "Recent Large Reasoning Models trained via reinforcement learning exhibit a \"natural\" alignment with human cognitive costs. However, we show that the prevailing paradigm of reasoning distillation -- training student models to mimic these traces via Supervised Fine-Tuning (SFT) -- fails to transmit this cognitive structure. Testing the \"Hán Dān Xué Bù\" (Superficial Mimicry) hypothesis across 14 models, we find that distillation induces a \"Functional Alignment Collapse\": while teacher models mirror human difficulty scaling ($\\bar{r}=0.64$), distilled students significantly degrade this alignment ($\\bar{r}=0.34$), often underperforming their own pre-distillation baselines (\"Negative Transfer\"). Our analysis suggests that SFT induces a \"Cargo Cult\" effect, where students ritualistically replicate the linguistic form of reasoning (verbosity) without internalizing the teacher's dynamic resource allocation policy. Consequently, reasoning distillation decouples computational cost from cognitive demand, revealing that human-like cognition is an emergent property of active reinforcement, not passive imitation.", "AI": {"tldr": "研究探讨了大型语言模型中推理蒸馏的效果，发现学生模型无法有效模仿老师模型的认知结构。", "motivation": "探索通过监督微调训练的学生模型是否能成功复制教师模型的人类认知成本模式。", "method": "测试14个模型的“汉丹学步”（表面模仿）假设，并分析SFT过程中的功能对齐崩溃现象。", "result": "发现蒸馏导致学生模型的认知结构显著退化，未能保持与人类难度分布的一致性。", "conclusion": "推理蒸馏无法复制老师的人类认知成本模式，表明人类类似的认知是主动强化学习的结果而非被动模仿。"}}
{"id": "2601.05017", "pdf": "https://arxiv.org/pdf/2601.05017", "abs": "https://arxiv.org/abs/2601.05017", "authors": ["Xiaopeng Luo", "Zexi Tan", "Zhuowei Wang"], "title": "HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to ICASSP 2026", "summary": "Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.", "AI": {"tldr": "本文提出了一种新的缺失值填充方法，该方法在统一框架内处理数值和分类属性之间的交叉类型特征依赖关系。", "motivation": "现有缺失值填补方法独立处理数值和类别属性，忽视了异质特征间的相互关联。为此，论文提出了一个新模型来解决这些问题。", "method": "该方法利用完整实例与不完全实例的共同作用进行准确一致的数据填充，并在统一框架下建模跨类型特性依赖关系。", "result": "实验结果表明所提方法优于现有技术，在下游机器学习任务中表现出色，为现实世界中的数据缺失问题提供了有力解决方案。", "conclusion": "所提出的HMVI方法能更有效地处理异构特征之间的交叉类型特性依赖性，提供一种准确而一致的填充策略。"}}
{"id": "2601.05016", "pdf": "https://arxiv.org/pdf/2601.05016", "abs": "https://arxiv.org/abs/2601.05016", "authors": ["Jin Gao", "Saichandu Juluri"], "title": "From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling", "categories": ["cs.MA", "cs.AI", "cs.GR", "cs.HC"], "comment": null, "summary": "We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.", "AI": {"tldr": "本文提出了一种通过多代理自省和人机交互监督来扩展Actor-Critic架构的框架，用于创意3D建模。", "motivation": "现有方法依赖于单一提示代理直接执行建模命令，缺乏迭代反馈机制，导致几何精度、美学质量和任务完成率受限。本文旨在通过引入 Planner-Actor-Critic 架构及人机交互来改善这些问题。", "method": "该架构由Planner协调建模步骤，Actor执行步骤，Critic提供迭代反馈，并且在过程中加入人类用户作为监督者和顾问。与单一提示建模相比，这种结构化代理自省结合了人机互动以提升建模效果。", "result": "研究表明，在几何精度、美学质量和任务完成率方面，通过引入批评导向的反思机制以及人机交互指导，可以减少建模错误并提高结果的复杂性和质量。", "conclusion": "研究结论表明，当结构化代理自省与人类监督和建议相结合时，能够产生更高品质的3D模型，并且通过实时Blender同步保持高效的工作流程集成。"}}
{"id": "2601.05014", "pdf": "https://arxiv.org/pdf/2601.05014", "abs": "https://arxiv.org/abs/2601.05014", "authors": ["Lingdong Kong", "Shaoyuan Xie", "Zeying Gong", "Ye Li", "Meng Chu", "Ao Liang", "Yuhao Dong", "Tianshuai Hu", "Ronghe Qiu", "Rong Li", "Hanjiang Hu", "Dongyue Lu", "Wei Yin", "Wenhao Ding", "Linfeng Li", "Hang Song", "Wenwei Zhang", "Yuexin Ma", "Junwei Liang", "Zhedong Zheng", "Lai Xing Ng", "Benoit R. Cottereau", "Wei Tsang Ooi", "Ziwei Liu", "Zhanpeng Zhang", "et al. (114 additional authors not shown)"], "title": "The RoboSense Challenge: Sense Anything, Navigate Anywhere, Adapt Across Platforms", "categories": ["cs.RO"], "comment": "Official IROS 2025 RoboSense Challenge Report; 51 pages, 37 figures, 5 tables; Competition Website at https://robosense2025.github.io/", "summary": "Autonomous systems are increasingly deployed in open and dynamic environments -- from city streets to aerial and indoor spaces -- where perception models must remain reliable under sensor noise, environmental variation, and platform shifts. However, even state-of-the-art methods often degrade under unseen conditions, highlighting the need for robust and generalizable robot sensing. The RoboSense 2025 Challenge is designed to advance robustness and adaptability in robot perception across diverse sensing scenarios. It unifies five complementary research tracks spanning language-grounded decision making, socially compliant navigation, sensor configuration generalization, cross-view and cross-modal correspondence, and cross-platform 3D perception. Together, these tasks form a comprehensive benchmark for evaluating real-world sensing reliability under domain shifts, sensor failures, and platform discrepancies. RoboSense 2025 provides standardized datasets, baseline models, and unified evaluation protocols, enabling large-scale and reproducible comparison of robust perception methods. The challenge attracted 143 teams from 85 institutions across 16 countries, reflecting broad community engagement. By consolidating insights from 23 winning solutions, this report highlights emerging methodological trends, shared design principles, and open challenges across all tracks, marking a step toward building robots that can sense reliably, act robustly, and adapt across platforms in real-world environments.", "AI": {"tldr": "自主系统感知挑战赛，旨在提高机器人在不同环境下的可靠性和适应性。", "motivation": "当前的先进方法在未知条件下性能下降，需要提升机器人的通用感知能力。", "method": "通过五个研究轨道：语言驱动决策、社会兼容导航等，构建跨平台3D感知基准。", "result": "吸引了来自16个国家85个机构的143支团队参与，并总结了23份获奖方案的方法论趋势和设计原则。", "conclusion": "推动了可靠、稳健和适应性强的机器人感知技术的发展。"}}
{"id": "2601.05011", "pdf": "https://arxiv.org/pdf/2601.05011", "abs": "https://arxiv.org/abs/2601.05011", "authors": ["Karim El Khoury", "Maxime Zanella", "Tiffanie Godelaine", "Christophe De Vleeschouwer", "Benoit Macq"], "title": "Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.", "AI": {"tldr": "论文提出了一种基于预测熵的自动提示加权方法，用于在零样本音频语言分类中找到鲁棒的提示组合以最大化预测置信度。", "motivation": "现有的音频-语言模型性能对文本提示的措辞非常敏感。为了克服这一问题，研究人员尝试通过提示学习或提示集成来减轻这个问题，但这些策略要么需要标注数据，要么未能考虑到某些提示可能会负面影响表现。", "method": "提出了一个基于预测熵引导的提示加权方法，其目标是找到鲁棒的提示组合以最大化预测置信度。为此，他们制定了一项特定的目标函数，通过最小化预测熵来生成新的提示权重，并且这个方法可以应用于单个样本或一组音频样本。", "result": "实验结果表明，在零样本设置下，与传统的方法相比，该方法在五个不同数据集上均表现出一致的改进效果，整体准确率提高了5倍以上。", "conclusion": "提出的基于预测熵引导的提示加权方法能够在无需额外标注的情况下显著提高音频事件分类任务中的准确性。"}}
{"id": "2601.05009", "pdf": "https://arxiv.org/pdf/2601.05009", "abs": "https://arxiv.org/abs/2601.05009", "authors": ["Avik Dutta", "Harshit Nigam", "Hosein Hasanbeig", "Arjun Radhakrishna", "Sumit Gulwani"], "title": "An Empirical Investigation of Robustness in Large Language Models under Tabular Distortions", "categories": ["cs.AI"], "comment": "4 pages, 1 figure, 1 table", "summary": "We investigate how large language models (LLMs) fail when tabular data in an otherwise canonical representation is subjected to semantic and structural distortions. Our findings reveal that LLMs lack an inherent ability to detect and correct subtle distortions in table representations. Only when provided with an explicit prior, via a system prompt, do models partially adjust their reasoning strategies and correct some distortions, though not consistently or completely. To study this phenomenon, we introduce a small, expert-curated dataset that explicitly evaluates LLMs on table question answering (TQA) tasks requiring an additional error-correction step prior to analysis. Our results reveal systematic differences in how LLMs ingest and interpret tabular information under distortion, with even SoTA models such as GPT-5.2 model exhibiting a drop of minimum 22% accuracy under distortion. These findings raise important questions for future research, particularly regarding when and how models should autonomously decide to realign tabular inputs, analogous to human behavior, without relying on explicit prompts or tabular data pre-processing.", "AI": {"tldr": "研究大型语言模型在表格数据受到语义和结构扭曲时的表现。", "motivation": "探讨大型语言模型面对表格式数据的错误或变形时的能力，以及如何改进这些模型以更好地处理这类问题。", "method": "通过创建一个专门的小型专家策划的数据集来评估大规模语言模型在有表格问答任务中对异常情况的反应能力。该数据集包括需要额外纠错步骤的任务，以此观察模型的表现。", "result": "发现即使是最先进的GPT-5.2等模型，在面对表格式信息的扭曲时也会出现至少22%的准确率下降。", "conclusion": "这些结果提出了未来研究的重要问题，即如何让模型自主决定重新校准表格输入的方式，并探讨了与人类行为相似的行为模式。"}}
{"id": "2601.05002", "pdf": "https://arxiv.org/pdf/2601.05002", "abs": "https://arxiv.org/abs/2601.05002", "authors": ["Aleksandar Fontana", "Marco Simoni", "Giulio Rossolini", "Andrea Saracino", "Paolo Mori"], "title": "On the Hidden Objective Biases of Group-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.", "AI": {"tldr": "分析基于组的强化学习方法中的潜在目标偏差。", "motivation": "揭示广泛使用的Group Relative Policy Optimization (GRPO) 等基于组的方法在奖励优化与训练目标之间存在结构不匹配的问题，以及这些方法中存在的系统性梯度偏置问题。", "method": "通过统一代理模型对GRPO样式的算法进行理论分析，研究其潜在的目标偏差和优化器交互的影响。", "result": "发现了非均匀组权重导致的共享前缀令牌上的系统性梯度偏差；与AdamW优化器的相互作用使得训练动态几乎不敏感于奖励缩放；优化器动量会导致策略更新超出预期裁剪区域。", "conclusion": "这些发现揭示了当前方法的基本局限，并为未来设计提供了原则指导。"}}
{"id": "2601.04996", "pdf": "https://arxiv.org/pdf/2601.04996", "abs": "https://arxiv.org/abs/2601.04996", "authors": ["Henan Sun", "Kaichi Yu", "Yuyao Wang", "Bowen Liu", "Xunkai Li", "Rong-Hua Li", "Nuo Chen", "Jia Li"], "title": "AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms?", "categories": ["cs.AI"], "comment": "Under review", "summary": "Reasoning ability has become a central focus in the advancement of Large Reasoning Models (LRMs). Although notable progress has been achieved on several reasoning benchmarks such as MATH500 and LiveCodeBench, existing benchmarks for algorithmic reasoning remain limited, failing to answer a critical question: Do LRMs truly master algorithmic reasoning? To answer this question, we propose AlgBench, an expert-curated benchmark that evaluates LRMs under an algorithm-centric paradigm. AlgBench consists of over 3,000 original problems spanning 27 algorithms, constructed by ACM algorithmic experts and organized under a comprehensive taxonomy, including Euclidean-structured, non-Euclidean-structured, non-optimized, local-optimized, global-optimized, and heuristic-optimized categories. Empirical evaluations on leading LRMs (e.g., Gemini-3-Pro, DeepSeek-v3.2-Speciale and GPT-o3) reveal substantial performance heterogeneity: while models perform well on non-optimized tasks (up to 92%), accuracy drops sharply to around 49% on globally optimized algorithms such as dynamic programming. Further analysis uncovers \\textbf{strategic over-shifts}, wherein models prematurely abandon correct algorithmic designs due to necessary low-entropy tokens. These findings expose fundamental limitations of problem-centric reinforcement learning and highlight the necessity of an algorithm-centric training paradigm for robust algorithmic reasoning.", "AI": {"tldr": "论文提出了AlgBench，一个专家策划的基准测试集，旨在评估大型推理模型在算法理解上的能力。", "motivation": "虽然在MATH500和LiveCodeBench等推理基准上取得了显著进展，但现有针对算法推理的基准仍然有限。因此，提出AlgBench来解决一个重要问题：这些大语言模型是否真正掌握了算法推理？", "method": "AlgBench由超过3,000个原始问题组成，涵盖27种不同的算法，并按照一种全面分类法组织成六类结构化和优化类型的问题。该基准测试集通过评估不同大型推理模型（如Gemini-3-Pro、DeepSeek-v3.2-Speciale及GPT-o3）来揭示其性能。", "result": "实验表明，这些大语言模型在非优化任务上的表现良好（最高达92%），但在全局优化算法任务上准确率显著下降至约49%，如动态规划。进一步分析发现模型存在策略性过度偏移现象，即因必要低熵标记而过早放弃正确算法设计。", "conclusion": "这些研究结果揭示了问题中心强化学习的基本局限，并强调了一个以算法为中心的训练范式对于稳健的算法推理是必要的。"}}
{"id": "2601.04991", "pdf": "https://arxiv.org/pdf/2601.04991", "abs": "https://arxiv.org/abs/2601.04991", "authors": ["Jens Bayer", "Stefan Becker", "David Münch", "Michael Arens", "Jürgen Beyerer"], "title": "Higher-Order Adversarial Patches for Real-Time Object Detectors", "categories": ["cs.CV"], "comment": "Under review (ICPR2026)", "summary": "Higher-order adversarial attacks can directly be considered the result of a cat-and-mouse game -- an elaborate action involving constant pursuit, near captures, and repeated escapes. This idiom describes the enduring circular training of adversarial attack patterns and adversarial training the best. The following work investigates the impact of higher-order adversarial attacks on object detectors by successively training attack patterns and hardening object detectors with adversarial training. The YOLOv10 object detector is chosen as a representative, and adversarial patches are used in an evasion attack manner. Our results indicate that higher-order adversarial patches are not only affecting the object detector directly trained on but rather provide a stronger generalization capacity compared to lower-order adversarial patches. Moreover, the results highlight that solely adversarial training is not sufficient to harden an object detector efficiently against this kind of adversarial attack. Code: https://github.com/JensBayer/HigherOrder", "AI": {"tldr": "研究了更高阶对抗性补丁对实时物体检测器的影响，并探讨了仅通过对抗训练不足以有效防御此类攻击的结论。", "motivation": "为了理解更高阶对抗性攻击对物体检测器的实际影响，以及提高物体检测器在面对这些攻击时的安全性能。", "method": "选择YOLOv10作为代表性的对象检测器，使用对抗性补丁进行逃避攻击方式的研究，并通过不断训练攻击模式和加强物体检测器的对抗训练来探究其效果。", "result": "研究发现更高阶对抗性补丁不仅影响直接在其上训练的对象检测器，还提供了比低阶对抗性补丁更强的泛化能力；此外，仅靠对抗训练不足以有效防护这种类型的对抗性攻击。", "conclusion": "通过对YOLOv10的研究表明，更高的对抗性补丁不仅能提高其本身的安全性能，而且具有更好的泛化效果，并且对抗训练需要与其他技术结合才能更有效地抵御更高阶的对抗性攻击。"}}
{"id": "2601.04984", "pdf": "https://arxiv.org/pdf/2601.04984", "abs": "https://arxiv.org/abs/2601.04984", "authors": ["Minseong Kweon", "Jinsun Park"], "title": "OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction", "categories": ["cs.CV"], "comment": "Accepted to AAAI 2026. Project page: https://oceansplat.github.io", "summary": "We introduce OceanSplat, a novel 3D Gaussian Splatting-based approach for accurately representing 3D geometry in underwater scenes. To overcome multi-view inconsistencies caused by underwater optical degradation, our method enforces trinocular view consistency by rendering horizontally and vertically translated camera views relative to each input view and aligning them via inverse warping. Furthermore, these translated camera views are used to derive a synthetic epipolar depth prior through triangulation, which serves as a self-supervised depth regularizer. These geometric constraints facilitate the spatial optimization of 3D Gaussians and preserve scene structure in underwater environments. We also propose a depth-aware alpha adjustment that modulates the opacity of 3D Gaussians during early training based on their $z$-component and viewing direction, deterring the formation of medium-induced primitives. With our contributions, 3D Gaussians are disentangled from the scattering medium, enabling robust representation of object geometry and significantly reducing floating artifacts in reconstructed underwater scenes. Experiments on real-world underwater and simulated scenes demonstrate that OceanSplat substantially outperforms existing methods for both scene reconstruction and restoration in scattering media.", "AI": {"tldr": "提出了一种名为OceanSplat的基于Gaussian Splatting的方法，用于水下场景重建。", "motivation": "为了解决由于水下光学退化造成的多视角不一致问题，提出了通过三目视图一致性来提高水下3D几何表示准确性。", "method": "该方法使用逆向扭曲将水平和垂直平移的摄像机视图与输入视图对齐，并利用三角测量计算出合成的基线深度先验。此外还提出了一种基于z分量和观察方向调整alpha值的方法，以抑制由介质引起的原始形式。", "result": "实验表明，OceanSplat在真实水下场景中重建效果比现有方法好很多。", "conclusion": "通过引入三目视图一致性和深度感知的Alpha调整机制，OceanSplat可以有效减少漂浮伪影，并为物体几何结构提供稳健表示。"}}
{"id": "2601.04983", "pdf": "https://arxiv.org/pdf/2601.04983", "abs": "https://arxiv.org/abs/2601.04983", "authors": ["Rupayan Bhattacharjee", "Sergi Abadal", "Carmen G. Almudever", "Eduard Alarcon"], "title": "Quantum Neural Network Training and Inference with Low Resolution Control Electronics", "categories": ["quant-ph", "cs.ET"], "comment": "5 pages, 4 figures", "summary": "Scaling quantum computers requires tight integration of cryogenic control electronics with quantum processors, where Digital-to-Analog Converters (DACs) face severe power and area constraints. We investigate quantum neural network (QNN) training and inference under finite DAC resolution constraints across various DAC resolutions. Pre-trained QNNs achieve accuracy nearly indistinguishable from infinite-precision baselines when deployed on quantum systems with 6-bit DAC control electronics, exhibiting an elbow curve with diminishing returns beyond 4 bits. However, training under quantization reveals gradient deadlock below 12-bit resolution as gradient magnitudes fall below quantization step sizes. We introduce temperature-controlled stochasticity that overcomes this through probabilistic parameter updates, enabling successful training at 4-10 bit resolutions that remarkably matches or exceeds infinite-precision baseline performance. Our findings demonstrate that low-resolution control electronics need not compromise QML performance, enabling significant power and area reduction in cryogenic control systems for practical deployment as quantum hardware scales.", "AI": {"tldr": "研究了在有限DAC分辨率约束下的量子神经网络（QNN）训练和推理，提出了温度控制随机性方法以克服低精度训练问题。", "motivation": "量子计算机的扩展需要低温控制电子设备与量子处理器的高度集成，但数字到模拟转换器(DACs)受到严重的功耗和面积限制。研究旨在探索如何在有限DAC分辨率下进行QNN训练和推理，并提高其性能。", "method": "分析了不同DAC分辨率下的预训练QNN性能，引入温度控制随机性方法以解决低精度训练中的梯度停滞问题，通过概率参数更新克服了这一障碍。", "result": "实验表明，在使用6位DAC控制电子设备时，预训练的QNN可以获得接近无限精度基准线的准确率；而引入的新方法可以在4-10位分辨率范围内成功完成训练，并且性能能够匹配或超过无限精度基准线。", "conclusion": "低分辨率控制电子设备并不必然影响量子机器学习(QML)的性能，新方法可以实现显著减少功耗和面积的目标，在实际部署中为量子硬件扩展提供了有力支持。"}}
{"id": "2601.04982", "pdf": "https://arxiv.org/pdf/2601.04982", "abs": "https://arxiv.org/abs/2601.04982", "authors": ["Johannes A. Gaus", "Winfried Ilg", "Daniel Haeufle"], "title": "When to Act: Calibrated Confidence for Reliable Human Intention Prediction in Assistive Robotics", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Assistive devices must determine both what a user intends to do and how reliable that prediction is before providing support. We introduce a safety-critical triggering framework based on calibrated probabilities for multimodal next-action prediction in Activities of Daily Living. Raw model confidence often fails to reflect true correctness, posing a safety risk. Post-hoc calibration aligns predicted confidence with empirical reliability and reduces miscalibration by about an order of magnitude without affecting accuracy. The calibrated confidence drives a simple ACT/HOLD rule that acts only when reliability is high and withholds assistance otherwise. This turns the confidence threshold into a quantitative safety parameter for assisted actions and enables verifiable behavior in an assistive control loop.", "AI": {"tldr": "提出了基于校准概率的安全关键触发框架，用于日常活动中的人机意图预测", "motivation": "旨在解决辅助设备在提供支持前必须准确判断用户意图及其可靠性的需求", "method": "通过后处理校准将模型的置信度与实际可靠性对齐，减少了大约一个数量级的不准确性而不影响精度", "result": "该方法使得置信阈值成为定量的安全参数，并且能够实现可验证的行为在辅助控制循环中", "conclusion": "提出的方法有效提高了预测的可靠性和安全性"}}
{"id": "2601.04977", "pdf": "https://arxiv.org/pdf/2601.04977", "abs": "https://arxiv.org/abs/2601.04977", "authors": ["James Hinns", "Sofie Goethals", "Stephan Van der Veeken", "Theodoros Evgeniou", "David Martens"], "title": "On the Definition and Detection of Cherry-Picking in Counterfactual Explanations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.", "AI": {"tldr": "定义并检测反事实解释中的挑拣行为", "motivation": "防止解释提供者通过选择有利于他们的叙述来掩盖有问题的行为", "method": "提出了一种基于可接受的解释空间和效用函数的形式化挑拣定义，并研究了外部审计员在不同访问级别下识别这种操纵的可能性", "result": "即使有完整的程序访问权限，挑拣出来的反事实解释也很难与非挑拣的区分开来，因为有效的反事实的多样性和说明规范的灵活性提供了足够的自由度以隐藏故意选择", "conclusion": "建议优先考虑可重复性、标准化和程序约束而非事后检测"}}
{"id": "2601.04973", "pdf": "https://arxiv.org/pdf/2601.04973", "abs": "https://arxiv.org/abs/2601.04973", "authors": ["Minda Hu", "Zexuan Qiu", "Zenan Xu", "Kun Li", "Bo Zhou", "Irwin King"], "title": "ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent breakthroughs in Large Reasoning Models (LRMs) have demonstrated that extensive Chain-of-Thought (CoT) generation is critical for enabling intricate cognitive behaviors, such as self-verification and backtracking, to solve complex tasks. However, this capability often leads to ``overthinking'', where models generate redundant reasoning paths that inflate computational costs without improving accuracy. While Supervised Fine-Tuning (SFT) on reasoning traces is a standard paradigm for the 'cold start' phase, applying existing compression techniques to these traces often compromises logical coherence or incurs prohibitive sampling costs. In this paper, we introduce ConMax (Confidence-Maximizing Compression), a novel reinforcement learning framework designed to automatically compress reasoning traces while preserving essential reasoning patterns. ConMax formulates compression as a reward-driven optimization problem, training a policy to prune redundancy by maximizing a weighted combination of answer confidence for predictive fidelity and thinking confidence for reasoning validity through a frozen auxiliary LRM. Extensive experiments across five reasoning datasets demonstrate that ConMax achieves a superior efficiency-performance trade-off. Specifically, it reduces inference length by 43% over strong baselines at the cost of a mere 0.7% dip in accuracy, proving its effectiveness in generating high-quality, efficient training data for LRMs.", "AI": {"tldr": "本文提出了ConMax（Confidence-Maximizing Compression），一种用于压缩推理痕迹的新框架，旨在通过最大化置信度来提高大型推理模型的效率。", "motivation": "当前的大型推理模型在解决复杂任务时会产生冗余推理路径，导致计算成本增加而不提升准确性。现有的压缩技术通常会破坏逻辑一致性或带来高昂的采样成本。", "method": "ConMax是一个基于强化学习的框架，通过最大化的预测置信度和推理有效性来自动压缩推理痕迹。它将压缩问题形式化为一个奖励驱动的优化问题，并训练策略以去除冗余。", "result": "在五个不同推理数据集上的实验表明，与强基线相比，ConMax能够在减少43%推理长度的同时仅损失0.7％的准确性。", "conclusion": "ConMax证明了其生成高质量、高效训练数据的能力，并实现了优越的效率-性能权衡。"}}
{"id": "2601.04968", "pdf": "https://arxiv.org/pdf/2601.04968", "abs": "https://arxiv.org/abs/2601.04968", "authors": ["Maximilian Pittner", "Joel Janai", "Mario Faigle", "Alexandru Paul Condurache"], "title": "SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection", "categories": ["cs.CV"], "comment": "Published at IEEE/CVF International Conference on Computer Vision (ICCV) 2025", "summary": "3D lane detection has emerged as a critical challenge in autonomous driving, encompassing identification and localization of lane markings and the 3D road surface. Conventional 3D methods detect lanes from dense birds-eye-viewed (BEV) features, though erroneous transformations often result in a poor feature representation misaligned with the true 3D road surface. While recent sparse lane detectors have surpassed dense BEV approaches, they completely disregard valuable lane-specific priors. Furthermore, existing methods fail to utilize historic lane observations, which yield the potential to resolve ambiguities in situations of poor visibility. To address these challenges, we present SparseLaneSTP, a novel method that integrates both geometric properties of the lane structure and temporal information into a sparse lane transformer. It introduces a new lane-specific spatio-temporal attention mechanism, a continuous lane representation tailored for sparse architectures as well as temporal regularization. Identifying weaknesses of existing 3D lane datasets, we also introduce a precise and consistent 3D lane dataset using a simple yet effective auto-labeling strategy. Our experimental section proves the benefits of our contributions and demonstrates state-of-the-art performance across all detection and error metrics on existing 3D lane detection benchmarks as well as on our novel dataset.", "AI": {"tldr": "SparseLaneSTP是一种利用稀疏变压器进行三维车道检测的新方法，它结合了空间和时间先验信息。", "motivation": "传统的三维方法通常从密集的鸟瞰图特征中识别车道标记和三维路面，但由于错误转换常常导致与真实三维道路表面不一致。现有的稀疏车道检测器虽然超越了密集BEV方法，但忽略了有价值的车道特定先验，并且未能利用历史车道观测来解决不可见情况下的歧义。", "method": "SparseLaneSTP引入了一种新的基于几何结构特性和时间信息的车道专用时空注意机制以及连续的稀疏架构适配的车道表示。该方法还提出了一种精确和一致的三维车道数据集，使用简单有效的自动标记策略生成。", "result": "实验结果证明了所提贡献的有效性，并在现有的3D车道检测基准测试中实现了所有检测和错误度量的最佳性能，在作者的新数据集中也表现出了优越的结果。", "conclusion": "通过结合空间先验、时间信息以及连续的车道表示，SparseLaneSTP有效提高了三维车道检测精度。"}}
{"id": "2601.04963", "pdf": "https://arxiv.org/pdf/2601.04963", "abs": "https://arxiv.org/abs/2601.04963", "authors": ["Yuting Liu", "Jian Guan", "Jia-Nan Li", "Wei Wu", "Jiang-Ming Yang", "Jianzhe Zhao", "Guibing Guo"], "title": "Text as a Universal Interface for Transferable Personalization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We study the problem of personalization in large language models (LLMs). Prior work predominantly represents user preferences as implicit, model-specific vectors or parameters, yielding opaque ``black-box'' profiles that are difficult to interpret and transfer across models and tasks. In contrast, we advocate natural language as a universal, model- and task-agnostic interface for preference representation. The formulation leads to interpretable and reusable preference descriptions, while naturally supporting continual evolution as new interactions are observed. To learn such representations, we introduce a two-stage training framework that combines supervised fine-tuning on high-quality synthesized data with reinforcement learning to optimize long-term utility and cross-task transferability. Based on this framework, we develop AlignXplore+, a universal preference reasoning model that generates textual preference summaries. Experiments on nine benchmarks show that our 8B model achieves state-of-the-art performanc -- outperforming substantially larger open-source models -- while exhibiting strong transferability across tasks, model families, and interaction formats.", "AI": {"tldr": "本文研究了大型语言模型中的个性化问题，提出使用自然语言作为跨模型和任务的通用接口来表示用户偏好。", "motivation": "以前的工作主要通过隐式、特定于模型的向量或参数表示用户偏好，这些方法难以理解和在不同模型和任务间转移。相比之下，本文倡导用自然语言来表征用户的偏好，以实现解释性和可重用性，并支持长期演化。", "method": "提出了一种两阶段训练框架：第一阶段是基于高质量合成数据的监督微调；第二阶段通过强化学习优化长期效益和跨任务迁移能力。在此基础上开发了AlignXplore+模型来生成文本偏好摘要。", "result": "实验结果显示，该80亿参数规模的模型在九个基准测试中表现出色，超过了开源模型，并展示了强大的跨任务、模型家族及交互格式迁移性。", "conclusion": "基于自然语言表示用户偏好的方法优于传统的隐式向量或参数表征方式，能够实现更有效的个性化并具备更好的可解释性和迁移能力。"}}
{"id": "2601.04960", "pdf": "https://arxiv.org/pdf/2601.04960", "abs": "https://arxiv.org/abs/2601.04960", "authors": ["Qing Wang", "Zehan Li", "Yaodong Song", "Hongjie Chen", "Jian Kang", "Jie Lian", "Jie Li", "Yongxiang Li", "Xuelong Li"], "title": "A Unified Spoken Language Model with Injected Emotional-Attribution Thinking for Human-like Interaction", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "This paper presents a unified spoken language model for emotional intelligence, enhanced by a novel data construction strategy termed Injected Emotional-Attribution Thinking (IEAT). IEAT incorporates user emotional states and their underlying causes into the model's internal reasoning process, enabling emotion-aware reasoning to be internalized rather than treated as explicit supervision. The model is trained with a two-stage progressive strategy. The first stage performs speech-text alignment and emotional attribute modeling via self-distillation, while the second stage conducts end-to-end cross-modal joint optimization to ensure consistency between textual and spoken emotional expressions. Experiments on the Human-like Spoken Dialogue Systems Challenge (HumDial) Emotional Intelligence benchmark demonstrate that the proposed approach achieves top-ranked performance across emotional trajectory modeling, emotional reasoning, and empathetic response generation under both LLM-based and human evaluations.", "AI": {"tldr": "该论文提出了一种融合情感归因思考的统一口语模型，用于实现类似人类的情感互动。", "motivation": "通过将用户的情绪状态及其背后的原因融入到模型内部推理过程中，使情绪感知推理内在化而非显式监督，从而提高对话系统的情感智能水平。", "method": "采用两阶段渐进策略训练模型：第一阶段进行语音文本对齐和情感属性建模通过自我蒸馏实现；第二阶段执行端到端跨模态联合优化以确保文本和口语表达的一致性。", "result": "在HumDial情绪智能基准测试中，该方法在情绪轨迹建模、情绪推理和同情反应生成方面均表现出色，并获得了基于LLM和人工评估的顶级性能。", "conclusion": "提出的融合情感归因思考的统一口语模型能够显著提升对话系统的情感理解与互动能力，在多种评价标准下达到最优表现。"}}
{"id": "2601.04956", "pdf": "https://arxiv.org/pdf/2601.04956", "abs": "https://arxiv.org/abs/2601.04956", "authors": ["Juyuan Kang", "Hao Zhu", "Yan Zhu", "Wei Zhang", "Jianing Chen", "Tianxiang Xiao", "Yike Ma", "Hao Jiang", "Feng Dai"], "title": "TEA: Temporal Adaptive Satellite Image Semantic Segmentation", "categories": ["cs.CV"], "comment": "Under review. Code will be available at \\href{https://github.com/KeplerKang/TEA}{this https URL}", "summary": "Crop mapping based on satellite images time-series (SITS) holds substantial economic value in agricultural production settings, in which parcel segmentation is an essential step. Existing approaches have achieved notable advancements in SITS segmentation with predetermined sequence lengths. However, we found that these approaches overlooked the generalization capability of models across scenarios with varying temporal length, leading to markedly poor segmentation results in such cases. To address this issue, we propose TEA, a TEmporal Adaptive SITS semantic segmentation method to enhance the model's resilience under varying sequence lengths. We introduce a teacher model that encapsulates the global sequence knowledge to guide a student model with adaptive temporal input lengths. Specifically, teacher shapes the student's feature space via intermediate embedding, prototypes and soft label perspectives to realize knowledge transfer, while dynamically aggregating student model to mitigate knowledge forgetting. Finally, we introduce full-sequence reconstruction as an auxiliary task to further enhance the quality of representations across inputs of varying temporal lengths. Through extensive experiments, we demonstrate that our method brings remarkable improvements across inputs of different temporal lengths on common benchmarks. Our code will be publicly available.", "AI": {"tldr": "提出了一种基于时间适应性的卫星图像语义分割方法TEA，以提高模型在不同时间序列长度下的泛化能力。", "motivation": "现有的卫星图像时序分割方法仅针对预设的时间序列长度进行优化，缺乏对不同时间序列长度下通用性问题的关注。这导致了在实际应用场景中性能的显著下降。", "method": "通过引入教师模型来传递全局序列知识，并指导学生模型适应不同的时间输入长度。具体来说，TEA方法利用中间嵌入、原型和软标签视角实现知识转移，并动态聚合以减少知识遗忘。此外，还引入全序列重构作为辅助任务，进一步提升不同时间长度输入下的表示质量。", "result": "实验结果表明，在常见的基准数据集上，该方法在处理不同时间长度的输入时带来了显著改进。", "conclusion": "通过提出TEA方法，解决了卫星图像语义分割中对不同时间序列长度下模型泛化能力的需求，并展示了其相对于现有方法的优势。"}}
{"id": "2601.04954", "pdf": "https://arxiv.org/pdf/2601.04954", "abs": "https://arxiv.org/abs/2601.04954", "authors": ["Yirong Zeng", "Yufei Liu", "Xiao Ding", "Yutai Hou", "Yuxian Wang", "Haonan Song", "Wu Ning", "Dandan Tu", "Qixun Zhang", "Bibo Cai", "Yuxiang He", "Ting Liu"], "title": "Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following", "categories": ["cs.LG", "cs.AI"], "comment": "ACL under review 13 pages, 8 figures", "summary": "A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.", "AI": {"tldr": "本文挑战了指令跟随任务中采用多样化的可验证和不可验证约束训练模型的共识，提出高精度奖励优于多样性，并证明高精度奖励能够更好地泛化。", "motivation": "现有观点认为，在指令跟随任务中使用多样化混合的约束可以提高模型的泛化能力。然而，本文通过系统性实证研究发现，这种做法存在缺陷，即低召回率导致奖励漏洞问题严重，影响了多样性带来的好处。", "method": "实验表明高精度奖励训练模型优于混合数据集，并提出一种专注于奖励精确性的简单有效数据优化策略。", "result": "在五个基准测试上评估时，该方法超越了竞争基线13.4%，同时减少了58%的训练时间，并保持了指令跟随任务之外的强大泛化能力。", "conclusion": "研究结果表明应转向高精度奖励而非无差别的数据多样性追求，以实现更好的模型性能和效率。"}}
{"id": "2601.04948", "pdf": "https://arxiv.org/pdf/2601.04948", "abs": "https://arxiv.org/abs/2601.04948", "authors": ["Junchi Gu", "Feiyang Yuan", "Weize Shi", "Tianchen Huang", "Haopeng Zhang", "Xiaohu Zhang", "Yu Wang", "Wei Gao", "Shiwu Zhang"], "title": "SKATER: Synthesized Kinematics for Advanced Traversing Efficiency on a Humanoid Robot via Roller Skate Swizzles", "categories": ["cs.RO"], "comment": null, "summary": "Although recent years have seen significant progress of humanoid robots in walking and running, the frequent foot strikes with ground during these locomotion gaits inevitably generate high instantaneous impact forces, which leads to exacerbated joint wear and poor energy utilization. Roller skating, as a sport with substantial biomechanical value, can achieve fast and continuous sliding through rational utilization of body inertia, featuring minimal kinetic energy loss. Therefore, this study proposes a novel humanoid robot with each foot equipped with a row of four passive wheels for roller skating. A deep reinforcement learning control framework is also developed for the swizzle gait with the reward function design based on the intrinsic characteristics of roller skating. The learned policy is first analyzed in simulation and then deployed on the physical robot to demonstrate the smoothness and efficiency of the swizzle gait over traditional bipedal walking gait in terms of Impact Intensity and Cost of Transport during locomotion. A reduction of $75.86\\%$ and $63.34\\%$ of these two metrics indicate roller skating as a superior locomotion mode for enhanced energy efficiency and joint longevity.", "AI": {"tldr": "论文提出了一种新型的人形机器人，配备滚轮用于滑板运动，并通过深度强化学习控制框架实现了高效的滑行姿态。", "motivation": "人形机器人的行走和跑步过程中会频繁接触地面，导致高瞬时冲击力、关节磨损加剧以及能量利用率低下。因此，论文希望通过采用滚轮进行滑行以提高效率和延长关节寿命。", "method": "通过给每个脚装备一排四个被动轮子来进行滑板运动，并开发了一种基于滑行内在特性的强化学习控制框架来实现平滑的滑行动作。", "result": "在模拟和物理机器人上测试后，发现滑行姿态相较于传统的双腿步行，在冲击强度和运输成本方面分别降低了75.86%和63.34%，表明了滚轮滑行是一种更高效的行走模式。", "conclusion": "实验结果验证了利用被动轮子进行滑行动作的人形机器人在提高能源效率及延长关节寿命方面的优越性。"}}
{"id": "2601.04946", "pdf": "https://arxiv.org/pdf/2601.04946", "abs": "https://arxiv.org/abs/2601.04946", "authors": ["Subhadeep Roy", "Gagan Bhatia", "Steffen Eger"], "title": "Prototypicality Bias Reveals Blindspots in Multimodal Evaluation Metrics", "categories": ["cs.CV", "cs.AI"], "comment": "First version", "summary": "Automatic metrics are now central to evaluating text-to-image models, often substituting for human judgment in benchmarking and large-scale filtering. However, it remains unclear whether these metrics truly prioritize semantic correctness or instead favor visually and socially prototypical images learned from biased data distributions. We identify and study \\emph{prototypicality bias} as a systematic failure mode in multimodal evaluation. We introduce a controlled contrastive benchmark \\textsc{\\textbf{ProtoBias}} (\\textit{\\textbf{Proto}typical \\textbf{Bias}}), spanning Animals, Objects, and Demography images, where semantically correct but non-prototypical images are paired with subtly incorrect yet prototypical adversarial counterparts. This setup enables a directional evaluation of whether metrics follow textual semantics or default to prototypes. Our results show that widely used metrics, including CLIPScore, PickScore, and VQA-based scores, frequently misrank these pairs, while even LLM-as-Judge systems exhibit uneven robustness in socially grounded cases. Human evaluations consistently favour semantic correctness with larger decision margins. Motivated by these findings, we propose \\textbf{\\textsc{ProtoScore}}, a robust 7B-parameter metric that substantially reduces failure rates and suppresses misranking, while running at orders of magnitude faster than the inference time of GPT-5, approaching the robustness of much larger closed-source judges.", "AI": {"tldr": "本文提出了一个评估多模态模型的偏见问题，并引入了一个新的基准测试ProtoBias，以研究和缓解这种偏见。", "motivation": "自动度量在文本到图像模型中广泛使用来替代人工评判。然而这些指标可能倾向于偏向于从有偏差的数据分布中学到的视觉和社会原型图像，而非语义正确性。", "method": "本文引入了一个新的基准测试ProtoBias，并提出了一个新的度量方法ProtoScore，以减少这种偏见并提高语义正确的评估准确性。", "result": "实验表明广泛使用的自动指标经常误判，而提出的ProtoScore显著减少了这些错误，并且运行速度快于GPT-5的推理时间。", "conclusion": "研究发现现有的多模态评价指标存在原型偏差问题，提出的新方法可以有效缓解这一问题并提高评估准确性。"}}
{"id": "2601.04945", "pdf": "https://arxiv.org/pdf/2601.04945", "abs": "https://arxiv.org/abs/2601.04945", "authors": ["Chunyu Wei", "Huaiyu Qin", "Siyuan He", "Yunhai Wang", "Yueguo Chen"], "title": "T-Retriever: Tree-based Hierarchical Retrieval Augmented Generation for Textual Graphs", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has significantly enhanced Large Language Models' ability to access external knowledge, yet current graph-based RAG approaches face two critical limitations in managing hierarchical information: they impose rigid layer-specific compression quotas that damage local graph structures, and they prioritize topological structure while neglecting semantic content. We introduce T-Retriever, a novel framework that reformulates attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree. Our approach features two key innovations: (1) Adaptive Compression Encoding, which replaces artificial compression quotas with a global optimization strategy that preserves the graph's natural hierarchical organization, and (2) Semantic-Structural Entropy ($S^2$-Entropy), which jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions. Experiments across diverse graph reasoning benchmarks demonstrate that T-Retriever significantly outperforms state-of-the-art RAG methods, providing more coherent and contextually relevant responses to complex queries.", "AI": {"tldr": "该论文提出了一种基于树的分层检索增强生成框架T-Retriever，用于处理文本图形中的层次信息。", "motivation": "现有的图基RAG方法在管理层次信息时存在两个关键限制：强制执行固定的压缩配额损害了局部图结构，并且优先考虑拓扑结构而忽略了语义内容。因此需要改进。", "method": "该框架将属性图检索重新表述为基于树的检索，使用一种由语义和结构指导的编码树。主要创新包括自适应压缩编码和语义-结构熵（$S^2$-Entropy）。", "result": "实验结果表明T-Retriever在多种图形推理基准测试中显著优于最先进的RAG方法。", "conclusion": "该研究提出了一种新颖的框架，可以更好地处理层次信息，并产生更连贯和上下文相关的响应。"}}
{"id": "2601.04940", "pdf": "https://arxiv.org/pdf/2601.04940", "abs": "https://arxiv.org/abs/2601.04940", "authors": ["Arthur Nijdam", "Harri Kähkönen", "Valtteri Niemi", "Paul Stankovski Wagner", "Sara Ramezanian"], "title": "CurricuLLM: Designing Personalized and Workforce-Aligned Cybersecurity Curricula Using Fine-Tuned LLMs", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The cybersecurity landscape is constantly evolving, driven by increased digitalization and new cybersecurity threats. Cybersecurity programs often fail to equip graduates with skills demanded by the workforce, particularly concerning recent developments in cybersecurity, as curriculum design is costly and labor-intensive. To address this misalignment, we present a novel Large Language Model (LLM)-based framework for automated design and analysis of cybersecurity curricula, called CurricuLLM. Our approach provides three key contributions: (1) automation of personalized curriculum design, (2) a data-driven pipeline aligned with industry demands, and (3) a comprehensive methodology for leveraging fine-tuned LLMs in curriculum development. CurricuLLM utilizes a two-tier approach consisting of PreprocessLM, which standardizes input data, and ClassifyLM, which assigns course content to nine Knowledge Areas in cybersecurity. We systematically evaluated multiple Natural Language Processing (NLP) architectures and fine-tuning strategies, ultimately selecting the Bidirectional Encoder Representations from Transformers (BERT) model as ClassifyLM, fine-tuned on foundational cybersecurity concepts and workforce competencies. We are the first to validate our method with human experts who analyzed real-world cybersecurity curricula and frameworks, motivating that CurricuLLM is an efficient solution to replace labor-intensive curriculum analysis. Moreover, once course content has been classified, it can be integrated with established cybersecurity role-based weights, enabling alignment of the educational program with specific job roles, workforce categories, or general market needs. This lays the foundation for personalized, workforce-aligned cybersecurity curricula that prepare students for the evolving demands in cybersecurity.", "AI": {"tldr": "该论文提出了一种使用大型语言模型（LLM）自动设计和分析网络安全课程的框架，名为CurricuLLM。", "motivation": "当前网络安全领域的快速发展导致了毕业生技能与劳动力需求之间的错位。传统的课程设计成本高昂且耗时长。", "method": "该方法采用两级策略：PreprocessLM对输入数据进行标准化处理；ClassifyLM使用BERT模型将课程内容分配到九个网络安全知识领域，从而实现个性化和行业需求驱动的课程设计。", "result": "通过与人类专家合作分析实际的网络安全课程框架验证了CurricuLLM的有效性。该方法能够高效地替代耗时的手动课程分析，并为特定工作角色或市场需要提供个性化的、劳动力导向的安全教育计划。", "conclusion": "CurricuLLM是一种创新的方法，它通过使用大型语言模型自动化设计网络安全课程，从而解决了传统课程设计中存在的问题和挑战。"}}
{"id": "2601.04920", "pdf": "https://arxiv.org/pdf/2601.04920", "abs": "https://arxiv.org/abs/2601.04920", "authors": ["Nils Einecke"], "title": "Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.", "AI": {"tldr": "本文通过在ESA的ELOPE竞赛中使用ChatGPT进行快速原型设计，展示了大型语言模型在加速科学研究中的潜力。", "motivation": "研究旨在探索大型语言模型（LLMs）作为代码伙伴加速科学发现的能力。尽管已有研究关注其编程辅助能力，但在竞争性科研环境中的应用尚不明确。", "method": "通过参加ESA的ELOPE竞赛，利用ChatGPT生成算法逻辑、数据处理程序和方法建议来快速原型设计。比赛要求参赛者使用事件相机数据估计月球着陆器轨迹。", "result": "尽管加入时间较晚，仍取得了第二名的成绩（评分为0.01282），证明了人类与AI合作在竞争性科研中的有效性。但也发现了模型引入不必要的结构变化、混淆讨论、产生关键错误等问题。", "conclusion": "通过分析ChatGPT的优缺点，提出如何将LLMs结构化集成到科学研究中以加速原型设计和概念洞察，并建议最佳实践来促进AI辅助科学工作的应用"}}
{"id": "2601.04919", "pdf": "https://arxiv.org/pdf/2601.04919", "abs": "https://arxiv.org/abs/2601.04919", "authors": ["Yildiz Uzun", "Andrea Gauthier", "Mutlu Cukurova"], "title": "What Students Ask, How a Generative AI Assistant Responds: Exploring Higher Education Students' Dialogues on Learning Analytics Feedback", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Learning analytics dashboards (LADs) aim to support students' regulation of learning by translating complex data into feedback. Yet students, especially those with lower self-regulated learning (SRL) competence, often struggle to engage with and interpret analytics feedback. Conversational generative artificial intelligence (GenAI) assistants have shown potential to scaffold this process through real-time, personalised, dialogue-based support. Further advancing this potential, we explored authentic dialogues between students and GenAI assistant integrated into LAD during a 10-week semester. The analysis focused on questions students with different SRL levels posed, the relevance and quality of the assistant's answers, and how students perceived the assistant's role in their learning. Findings revealed distinct query patterns. While low SRL students sought clarification and reassurance, high SRL students queried technical aspects and requested personalised strategies. The assistant provided clear and reliable explanations but limited in personalisation, handling emotionally charged queries, and integrating multiple data points for tailored responses. Findings further extend that GenAI interventions can be especially valuable for low SRL students, offering scaffolding that supports engagement with feedback and narrows gaps with their higher SRL peers. At the same time, students' reflections underscored the importance of trust, need for greater adaptivity, context-awareness, and technical refinement in future systems.", "AI": {"tldr": "研究探讨了学生与嵌入学习分析仪表板的生成式人工智能助手之间的对话，以了解不同自我调节学习能力水平的学生如何提问及助手回应的有效性。", "motivation": "旨在通过探索真实对话来提高低自我调节学习能力学生的参与度，并缩小与其他学生的差距。", "method": "在一个十周学期中进行学生与GenAI助手之间对话的分析，重点关注问题模式、回答质量和学生的感知作用。", "result": "发现不同自我调节水平的学生有不同的提问方式；GenAI能提供清晰可靠的解释但缺乏个性化和处理情绪性查询的能力。", "conclusion": "生成式人工智能在支持低自我调节学习能力学生方面特别有价值，但也需改进信任度、适应性和技术准确性等问题。"}}
{"id": "2601.04918", "pdf": "https://arxiv.org/pdf/2601.04918", "abs": "https://arxiv.org/abs/2601.04918", "authors": ["Ziwen Wang", "Shangshang Yang", "Xiaoshan Yu", "Haiping Ma", "Xingyi Zhang"], "title": "Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective", "categories": ["cs.IR", "cs.AI"], "comment": "KDD2026, 15 pages", "summary": "With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.", "AI": {"tldr": "提出了一种名为OSCD的进化多目标神经架构搜索方法，旨在改进认知诊断模型在评估学习者掌握度时的能力。", "motivation": "现有研究侧重于提升模型性能而忽视了观察响应数据中的噪声污染问题，并且当前的认知诊断模型依赖于研究人员的专业知识来设计结构，限制了探索潜在的架构可能性。为了应对这些问题，作者提出了OSCD方法以解决上述挑战。", "method": "OSCD通过两个阶段实现：训练阶段构造包含多种架构组合的搜索空间并训练共享权重的超网络；在搜索阶段，将最优架构搜索作为多目标优化问题处理，并开发一个整合帕累托最优解搜索策略和跨场景性能评估的优化框架。", "result": "实验结果验证了OSCD模型发现的认知诊断任务中最佳架构的有效性和鲁棒性。", "conclusion": "通过提出一种新的进化多目标神经架构搜索方法，能够提高认知诊断模型在面对噪声数据时的表现，并探索出最优的认知诊断模型架构。"}}
{"id": "2601.04915", "pdf": "https://arxiv.org/pdf/2601.04915", "abs": "https://arxiv.org/abs/2601.04915", "authors": ["Miki Okamura", "Shuhey Koyama", "Li Jingjing", "Yoichi Ochiai"], "title": "OnomaCompass: A Texture Exploration Interface that Shuttles between Words and Images", "categories": ["cs.HC"], "comment": null, "summary": "Humans can finely perceive material textures, yet articulating such somatic impressions in words is a cognitive bottleneck in design ideation. We present OnomaCompass, a web-based exploration system that links sound-symbolic onomatopoeia and visual texture representations to support early-stage material discovery. Instead of requiring users to craft precise prompts for generative AI, OnomaCompass provides two coordinated latent-space maps--one for texture images and one for onomatopoeic term--built from an authored dataset of invented onomatopoeia and corresponding textures generated via Stable Diffusion. Users can navigate both spaces, trigger cross-modal highlighting, curate findings in a gallery, and preview textures applied to objects via an image-editing model. The system also supports video interpolation between selected textures and re-embedding of extracted frames to form an emergent exploration loop. We conducted a within-subjects study with 11 participants comparing OnomaCompass to a prompt-based image-generation workflow using Gemini 2.5 Flash Image (\"Nano Banana\"). OnomaCompass significantly reduced workload (NASA-TLX overall, mental demand, effort, and frustration; p < .05) and increased hedonic user experience (UEQ), while usability (SUS) favored the baseline. Qualitative findings indicate that OnomaCompass helps users externalize vague sensory expectations and promotes serendipitous discovery, but also reveals interaction challenges in spatial navigation. Overall, leveraging sound symbolism as a lightweight cue offers a complementary approach to Kansei-driven material ideation beyond prompt-centric generation.", "AI": {"tldr": "该论文提出了OnomaCompass，一种通过联结声音象征性和视觉纹理表示来支持材料发现的网页探索系统。", "motivation": "人们可以精细地感知材质纹理，但在设计构思中用语言描述这些感受存在认知瓶颈。OnomaCompass旨在解决这一问题，帮助设计师在早期阶段更好地探索和发现材质。", "method": "该方法构建了两个协调的潜在空间地图，一个用于纹理图像，另一个用于拟声词，并通过Stable Diffusion生成对应纹理。用户可以在两个空间中导航、触发跨模态高亮显示、收藏发现并在画廊预览应用到物体上的纹理。系统还支持视频插值和提取帧重新嵌入。", "result": "在与11名参与者进行的对比实验中，OnomaCompass显著减少了工作量（NASA-TLX总体指标、精神需求、努力和挫败感；p<.05），增加了愉悦用户体验。但是，在可操作性方面，基线表现更好。", "conclusion": "借助声音象征性的轻量化提示符提供了一种超越指令为中心生成的Kansei驱动材料构思方法。该系统有助于用户外部化模糊的感觉期望并促进偶然发现，但也揭示了空间导航中的交互挑战。"}}
{"id": "2601.04912", "pdf": "https://arxiv.org/pdf/2601.04912", "abs": "https://arxiv.org/abs/2601.04912", "authors": ["Damian Harenčák", "Lukáš Gajdošech", "Martin Madaras"], "title": "Decentralized Privacy-Preserving Federal Learning of Computer Vision Models on Edge Devices", "categories": ["cs.CR", "cs.CV"], "comment": "Accepted to VISAPP 2026 as Position Paper", "summary": "Collaborative training of a machine learning model comes with a risk of sharing sensitive or private data. Federated learning offers a way of collectively training a single global model without the need to share client data, by sharing only the updated parameters from each client's local model. A central server is then used to aggregate parameters from all clients and redistribute the aggregated model back to the clients. Recent findings have shown that even in this scenario, private data can be reconstructed only using information about model parameters. Current efforts to mitigate this are mainly focused on reducing privacy risks on the server side, assuming that other clients will not act maliciously. In this work, we analyzed various methods for improving the privacy of client data concerning both the server and other clients for neural networks. Some of these methods include homomorphic encryption, gradient compression, gradient noising, and discussion on possible usage of modified federated learning systems such as split learning, swarm learning or fully encrypted models. We have analyzed the negative effects of gradient compression and gradient noising on the accuracy of convolutional neural networks used for classification. We have shown the difficulty of data reconstruction in the case of segmentation networks. We have also implemented a proof of concept on the NVIDIA Jetson TX2 module used in edge devices and simulated a federated learning process.", "AI": {"tldr": "论文主要研究了在边缘设备上通过联邦学习进行隐私保护的计算机视觉模型联合训练方法。", "motivation": "联邦学习虽然可以避免直接共享敏感数据，但仍然存在通过对更新参数进行分析重构原始数据的风险。当前缓解措施多集中于服务器侧，并假定其他客户端行为正常。论文旨在研究如何提高客户端数据在面对所有参与者时的隐私性。", "method": "本文分析并实现了一系列方法来增强联邦学习中模型训练的隐私保护，包括同态加密、梯度压缩和梯度扰动等技术，并探讨了分割学习、群智学习或全加密模型的应用可能性。同时在NVIDIA Jetson TX2设备上实施了一个概念验证。", "result": "论文展示了各种方法对卷积神经网络分类准确率的影响以及数据重构的难度，尤其是针对分割任务的挑战性问题进行了深入分析，并在边缘设备上成功模拟了联邦学习过程。", "conclusion": "研究表明通过适当的方法可以有效提高联邦学习中的隐私保护水平。不同技术的应用需要根据具体场景进行权衡和选择。"}}
{"id": "2601.04911", "pdf": "https://arxiv.org/pdf/2601.04911", "abs": "https://arxiv.org/abs/2601.04911", "authors": ["Mustafa F. Abdelwahed", "Joan Espasa", "Alice Toniolo", "Ian P. Gent"], "title": "From Stories to Cities to Games: A Qualitative Evaluation of Behaviour Planning", "categories": ["cs.AI"], "comment": null, "summary": "The primary objective of a diverse planning approach is to generate a set of plans that are distinct from one another. Such an approach is applied in a variety of real-world domains, including risk management, automated stream data analysis, and malware detection. More recently, a novel diverse planning paradigm, referred to as behaviour planning, has been proposed. This approach extends earlier methods by explicitly incorporating a diversity model into the planning process and supporting multiple planning categories. In this paper, we demonstrate the usefulness of behaviour planning in real-world settings by presenting three case studies. The first case study focuses on storytelling, the second addresses urban planning, and the third examines game evaluation.", "AI": {"tldr": "本文通过三个案例研究展示了行为规划在现实世界中的应用，包括故事叙述、城市规划和游戏评估。", "motivation": "为了展示一种新的多样化规划范式——行为规划在实际场景中的有效性。这种方法不仅扩展了早期的方法，并且在规划过程中明确地整合了一个多样性模型，支持多种规划类别。", "method": "通过三个案例研究来展示行为规划的应用：故事叙述、城市规划和游戏评估。", "result": "结果表明行为规划能够成功应用于不同的现实世界领域，从而证明其多样性和有效性。", "conclusion": "行为规划在解决多样化规划问题中显示出了广泛的实际应用价值。"}}
{"id": "2601.04899", "pdf": "https://arxiv.org/pdf/2601.04899", "abs": "https://arxiv.org/abs/2601.04899", "authors": ["Hongyi Li", "William Ward Armstrong", "Jun Xu"], "title": "Rotation-Robust Regression with Convolutional Model Trees", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We study rotation-robust learning for image inputs using Convolutional Model Trees (CMTs) [1], whose split and leaf coefficients can be structured on the image grid and transformed geometrically at deployment time. In a controlled MNIST setting with a rotation-invariant regression target, we introduce three geometry-aware inductive biases for split directions -- convolutional smoothing, a tilt dominance constraint, and importance-based pruning -- and quantify their impact on robustness under in-plane rotations. We further evaluate a deployment-time orientation search that selects a discrete rotation maximizing a forest-level confidence proxy without updating model parameters. Orientation search improves robustness under severe rotations but can be harmful near the canonical orientation when confidence is misaligned with correctness. Finally, we observe consistent trends on MNIST digit recognition implemented as one-vs-rest regression, highlighting both the promise and limitations of confidence-based orientation selection for model-tree ensembles.", "AI": {"tldr": "研究了使用卷积模型树（CMTs）的旋转鲁棒学习方法，以提高图像输入在平面旋转下的预测准确性。", "motivation": "为了处理图像数据中的旋转不变性问题，提高模型对不同角度下图像输入的预测能力。", "method": "提出了三种几何感知的归纳偏置：卷积平滑、倾斜主导约束和基于重要性的剪枝，并引入了部署时的角度搜索以选择最合适的旋转角来优化模型表现。", "result": "在MNIST数据集上进行了验证，显示所提方法对严重旋转具有鲁棒性，但接近原始方向时可能会降低准确性。", "conclusion": "卷积模型树结合几何感知的归纳偏置和角度搜索策略能够提高旋转鲁棒性能，但也存在局限性。"}}
{"id": "2601.04897", "pdf": "https://arxiv.org/pdf/2601.04897", "abs": "https://arxiv.org/abs/2601.04897", "authors": ["Ziteng Wang", "Yujie He", "Guanliang Li", "Siqi Yang", "Jiaqi Xiong", "Songxiang Liu"], "title": "V-FAT: Benchmarking Visual Fidelity Against Text-bias", "categories": ["cs.CL", "cs.CV", "cs.LG", "cs.MM"], "comment": "12 pages, 6 figures", "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated impressive performance on standard visual reasoning benchmarks. However, there is growing concern that these models rely excessively on linguistic shortcuts rather than genuine visual grounding, a phenomenon we term Text Bias. In this paper, we investigate the fundamental tension between visual perception and linguistic priors. We decouple the sources of this bias into two dimensions: Internal Corpus Bias, stemming from statistical correlations in pretraining, and External Instruction Bias, arising from the alignment-induced tendency toward sycophancy. To quantify this effect, we introduce V-FAT (Visual Fidelity Against Text-bias), a diagnostic benchmark comprising 4,026 VQA instances across six semantic domains. V-FAT employs a Three-Level Evaluation Framework that systematically increases the conflict between visual evidence and textual information: (L1) internal bias from atypical images, (L2) external bias from misleading instructions, and (L3) synergistic bias where both coincide. We introduce the Visual Robustness Score (VRS), a metric designed to penalize \"lucky\" linguistic guesses and reward true visual fidelity. Our evaluation of 12 frontier MLLMs reveals that while models excel in existing benchmarks, they experience significant visual collapse under high linguistic dominance.", "AI": {"tldr": "本文提出了V-FAT基准测试，用于评估多模态大型语言模型的视觉忠实度与文本偏见之间的紧张关系。", "motivation": "随着多模态大型语言模型在标准视觉推理任务上的卓越表现，人们担忧这些模型过度依赖于语言捷径而非真正的视觉基础。这种现象被称为文本偏见，本文旨在探究这一问题的本质。", "method": "为了量化这种效应，我们引入了V-FAT基准测试，该测试包含4,026个跨越六个语义领域的图像问答实例，并通过三级评估框架系统地增加了视觉证据与文字信息之间的冲突。此外，还引入了视觉鲁棒性得分（VRS）这一指标。", "result": "对12种前沿的多模态大型语言模型进行评价后发现，在现有基准测试中表现出色的模型在高语言主导下会出现严重的视觉坍缩现象。", "conclusion": "该研究揭示了当前多模态大型语言模型存在的问题，并为未来的改进提供了方向。"}}
{"id": "2601.04895", "pdf": "https://arxiv.org/pdf/2601.04895", "abs": "https://arxiv.org/abs/2601.04895", "authors": ["Renzhao Liang", "Jingru Chen", "Bo Jia", "Bo Deng", "Chenggang Xie", "Yidong Wang", "Ke Jin", "Xin Wang", "Linfeng Zhang", "Cunxiang Wang"], "title": "DVD: A Robust Method for Detecting Variant Contamination in Large Language Model Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Evaluating large language models (LLMs) is increasingly confounded by \\emph{variant contamination}: the training corpus contains semantically equivalent yet lexically or syntactically altered versions of test items. Unlike verbatim leakage, these paraphrased or structurally transformed variants evade existing detectors based on sampling consistency or perplexity, thereby inflating benchmark scores via memorization rather than genuine reasoning. We formalize this problem and introduce \\textbf{DVD} (\\textbf{D}etection via \\textbf{V}ariance of generation \\textbf{D}istribution), a single-sample detector that models the local output distribution induced by temperature sampling. Our key insight is that contaminated items trigger alternation between a \\emph{memory-adherence} state and a \\emph{perturbation-drift} state, yielding abnormally high variance in the synthetic difficulty of low-probability tokens; uncontaminated items remain in drift with comparatively smooth variance. We construct the first benchmark for variant contamination across two domains Omni-MATH and SuperGPQA by generating and filtering semantically equivalent variants, and simulate contamination via fine-tuning models of different scales and architectures (Qwen2.5 and Llama3.1). Across datasets and models, \\textbf{DVD} consistently outperforms perplexity-based, Min-$k$\\%++, edit-distance (CDD), and embedding-similarity baselines, while exhibiting strong robustness to hyperparameters. Our results establish variance of the generation distribution as a principled and practical fingerprint for detecting variant contamination in LLM evaluation.", "AI": {"tldr": "DVD是一种用于检测大型语言模型评估中变体污染的鲁棒方法。", "motivation": "大型语言模型评估日益受到训练语料库中存在的变体污染问题困扰，这些问题会通过记忆而非真正的推理使基准分数膨胀。现有的基于采样一致性和困惑度的方法无法有效检测这些污染。", "method": "DVD通过建模由温度采样诱导的本地输出分布来识别被污染的项目。它观察到受污染的项目在记忆遵从状态和扰动漂移状态之间交替，这导致低概率令牌合成难度的异常高方差；未受污染的项目则保持相对平稳。", "result": "DVD在两个数据集（Omni-MATH和SuperGPQA）上以及不同规模和架构的模型中表现优异，并且对超参数具有较强的鲁棒性。", "conclusion": "生成分布的变异被确立为检测大型语言模型评估中的变体污染的一个原理性和实用性的特征。"}}
{"id": "2601.04891", "pdf": "https://arxiv.org/pdf/2601.04891", "abs": "https://arxiv.org/abs/2601.04891", "authors": ["Suyash Mishra", "Qiang Li", "Srikanth Patil", "Satyanarayan Pati", "Baddu Narendra"], "title": "Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform", "categories": ["cs.CV", "cs.LG"], "comment": "Submitted to the Industry Track of Top Tier Conference; currently under peer review", "summary": "Vision Language Models (VLMs) have shown strong performance on multimodal reasoning tasks, yet most evaluations focus on short videos and assume unconstrained computational resources. In industrial settings such as pharmaceutical content understanding, practitioners must process long-form videos under strict GPU, latency, and cost constraints, where many existing approaches fail to scale. In this work, we present an industrial GenAI framework that processes over 200,000 PDFs, 25,326 videos across eight formats (e.g., MP4, M4V, etc.), and 888 multilingual audio files in more than 20 languages. Our study makes three contributions: (i) an industrial large-scale architecture for multimodal reasoning in pharmaceutical domains; (ii) empirical analysis of over 40 VLMs on two leading benchmarks (Video-MME and MMBench) and proprietary dataset of 25,326 videos across 14 disease areas; and (iii) four findings relevant to long-form video reasoning: the role of multimodality, attention mechanism trade-offs, temporal reasoning limits, and challenges of video splitting under GPU constraints. Results show 3-8 times efficiency gains with SDPA attention on commodity GPUs, multimodality improving up to 8/12 task domains (especially length-dependent tasks), and clear bottlenecks in temporal alignment and keyframe detection across open- and closed-source VLMs. Rather than proposing a new \"A+B\" model, this paper characterizes practical limits, trade-offs, and failure patterns of current VLMs under realistic deployment constraints, and provide actionable guidance for both researchers and practitioners designing scalable multimodal systems for long-form video understanding in industrial domains.", "AI": {"tldr": "本文提出了一个工业级别的大规模架构，用于制药领域的多模态推理，并分析了40种视觉语言模型在长视频上的表现。", "motivation": "现有的视觉语言模型主要评估于短视频和假设无限计算资源的场景下。但在工业环境中如制药内容理解领域，处理长时间视频时需要满足严格的GPU、延迟和成本限制，许多现有方法无法应对这种规模。", "method": "该研究构建了一个大型架构用于处理超过20万份PDF文件、25326个视频及888个多语言音频文件。并对40种视觉语言模型在两个基准测试（Video-MME和MMBench）以及一个包含14种疾病领域的自建数据集上进行了实证分析。", "result": "结果显示，使用SDPA注意力机制可以在普通GPU上实现3-8倍的效率提升；多模态可以改进多达12个任务领域中的8个（特别是长度相关的任务）。在时间对齐和关键帧检测方面存在明显瓶颈问题。", "conclusion": "本文不仅指出了现有视觉语言模型的实际限制、权衡及失败模式，还为研究人员和从业者提供了设计可扩展多模态系统以应对长视频理解的实用建议。"}}
{"id": "2601.04888", "pdf": "https://arxiv.org/pdf/2601.04888", "abs": "https://arxiv.org/abs/2601.04888", "authors": ["Tongyu Wen", "Guanting Dong", "Zhicheng Dou"], "title": "SmartSearch: Process Reward-Guided Query Refinement for Search Agents", "categories": ["cs.AI"], "comment": "16 pages, 6 figures", "summary": "Large language model (LLM)-based search agents have proven promising for addressing knowledge-intensive problems by incorporating information retrieval capabilities. Existing works largely focus on optimizing the reasoning paradigms of search agents, yet the quality of intermediate search queries during reasoning remains overlooked. As a result, the generated queries often remain inaccurate, leading to unexpected retrieval results and ultimately limiting search agents' overall effectiveness. To mitigate this issue, we introduce SmartSearch, a framework built upon two key mechanisms: (1) Process rewards, which provide fine-grained supervision for the quality of each intermediate search query through Dual-Level Credit Assessment. (2) Query refinement, which promotes the optimization of query generation by selectively refining low-quality search queries and regenerating subsequent search rounds based on these refinements. To enable the search agent to progressively internalize the ability to improve query quality under the guidance of process rewards, we design a three-stage curriculum learning framework. This framework guides the agent through a progression from imitation, to alignment, and ultimately to generalization. Experimental results show that SmartSearch consistently surpasses existing baselines, and additional quantitative analyses further confirm its significant gains in both search efficiency and query quality. The code is available at https://github.com/MYVAE/SmartSearch.", "AI": {"tldr": "SmartSearch是一个框架，通过引入过程奖励机制和查询优化来提高搜索代理的查询质量。", "motivation": "现有工作主要集中在优化搜索引擎的推理模式上，而忽视了中间检索查询的质量。这导致生成的查询准确性较差，进而影响最终结果的有效性。", "method": "SmartSearch框架包括两个关键机制：过程奖励和查询优化。过程奖励通过双层信贷评估提供对每个中间搜索查询质量的精细监督；查询优化则通过选择性地改进低质量的搜索查询并基于这些改进生成后续轮次来促进查询生成的优化。", "result": "实验结果显示，SmartSearch在搜索效率和查询质量方面都超过了现有基线方法，并取得了显著提升。", "conclusion": "SmartSearch框架展示了其提高搜索代理查询质量和整体效果的能力。"}}
{"id": "2601.04887", "pdf": "https://arxiv.org/pdf/2601.04887", "abs": "https://arxiv.org/abs/2601.04887", "authors": ["Sofiene Lassoued", "Laxmikant Shrikant Bahetic", "Nathalie Weiß-Borkowskib", "Stefan Lierc", "Andreas Schwunga"], "title": "Flexible Manufacturing Systems Intralogistics: Dynamic Optimization of AGVs and Tool Sharing Using Coloured-Timed Petri Nets and Actor-Critic RL with Actions Masking", "categories": ["cs.AI"], "comment": "ef:Journal of Manufacturing Systems Journal of Manufacturing Systems Volume 82, October 2025, Pages 405-419", "summary": "Flexible Manufacturing Systems (FMS) are pivotal in optimizing production processes in today's rapidly evolving manufacturing landscape. This paper advances the traditional job shop scheduling problem by incorporating additional complexities through the simultaneous integration of automated guided vehicles (AGVs) and tool-sharing systems. We propose a novel approach that combines Colored-Timed Petri Nets (CTPNs) with actor-critic model-based reinforcement learning (MBRL), effectively addressing the multifaceted challenges associated with FMS. CTPNs provide a formal modeling structure and dynamic action masking, significantly reducing the action search space, while MBRL ensures adaptability to changing environments through the learned policy. Leveraging the advantages of MBRL, we incorporate a lookahead strategy for optimal positioning of AGVs, improving operational efficiency. Our approach was evaluated on small-sized public benchmarks and a newly developed large-scale benchmark inspired by the Taillard benchmark. The results show that our approach matches traditional methods on smaller instances and outperforms them on larger ones in terms of makespan while achieving a tenfold reduction in computation time. To ensure reproducibility, we propose a gym-compatible environment and an instance generator. Additionally, an ablation study evaluates the contribution of each framework component to its overall performance.", "AI": {"tldr": "本文提出了一种结合着色定时Petri网和Actor-Critic模型强化学习的方法，用于优化灵活制造系统中的自动引导车辆调度和工具共享。", "motivation": "为了应对传统作业车间调度问题中增加的复杂性，特别是在自动引导车（AGV）集成与工具共享方面的需求，本文旨在开发一种新的方法以提高生产过程的效率。", "method": "该方法利用着色定时Petri网提供了动态的行为屏蔽，从而有效地减少了行动搜索空间，并通过Actor-Critic模型强化学习确保了在不断变化环境中的适应性。此外，引入了一种前瞻策略来优化AGV的位置安排。", "result": "实验结果表明，在小规模实例上，该方法与传统方法具有相同的效果；而在大规模实例上，则表现出更优的性能，并且计算时间减少了十倍。", "conclusion": "结合着色定时Petri网和Actor-Critic模型强化学习的方法有效提高了灵活制造系统中AGV调度和工具共享的效率。"}}
{"id": "2601.04886", "pdf": "https://arxiv.org/pdf/2601.04886", "abs": "https://arxiv.org/abs/2601.04886", "authors": ["Jingzhi Gong", "Giovanni Pinna", "Yixin Bian", "Jie M. Zhang"], "title": "Analyzing Message-Code Inconsistency in AI Coding Agent-Authored Pull Requests", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Pull request (PR) descriptions generated by AI coding agents are the primary channel for communicating code changes to human reviewers. However, the alignment between these messages and the actual changes remains unexplored, raising concerns about the trustworthiness of AI agents. To fill this gap, we analyzed 23,247 agentic PRs across five agents using PR message-code inconsistency (PR-MCI). We contributed 974 manually annotated PRs, found 406 PRs (1.7%) exhibited high PR-MCI, and identified eight PR-MCI types, revealing that descriptions claiming unimplemented changes was the most common issue (45.4%). Statistical tests confirmed that high-MCI PRs had 51.7% lower acceptance rates (28.3% vs. 80.0%) and took 3.5x longer to merge (55.8 vs. 16.0 hours). Our findings suggest that unreliable PR descriptions undermine trust in AI agents, highlighting the need for PR-MCI verification mechanisms and improved PR generation to enable trustworthy human-AI collaboration.", "AI": {"tldr": "论文分析了AI编码代理生成的拉取请求描述与实际代码更改之间的不一致问题，评估其影响并提出了改进机制。", "motivation": "当前研究关注于人类信任AI代理生成的拉取请求描述的问题，缺乏关于PR消息和代码之间一致性情况的研究。通过探讨两者间的差异性来提高人机协作的信任度。", "method": "作者分析了五个不同AI编码代理产生的23,247个拉取请求，并手动标注其中974个样本以确定不一致类型及其分布，使用统计测试比较高MCI与低MCI PR的接受率和融合时间。", "result": "研究发现，大约1.7%的PR显示出高度消息-代码不一致性。描述声称未实现更改是最常见的问题(占总数的45.4%)。统计检验显示，具有高MCI的PR被接受的可能性降低约50%，合并所需的时间为无此情况的3.5倍。", "conclusion": "结果表明，不可靠的PR描述会损害人类对AI代理的信任水平，因此需要开发更有效的验证机制及改进PR生成过程以实现可靠的人机协作。"}}
{"id": "2601.04885", "pdf": "https://arxiv.org/pdf/2601.04885", "abs": "https://arxiv.org/abs/2601.04885", "authors": ["Ao Sun", "Xiaoyu Wang", "Zhe Tan", "Yu Li", "Jiachen Zhu", "Shu Su", "Yuheng Jia"], "title": "CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \\textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \\textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \\textbf{\\textsc{CuMA}} (\\textbf{Cu}ltural \\textbf{M}ixture of \\textbf{A}dapters), a framework that frames alignment as a \\textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \\textsc{CuMA} internalizes a \\textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \\textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \\textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.", "AI": {"tldr": "该论文提出了CuMA框架，通过人口统计学感知的路由技术来解决大语言模型在面对多元文化价值时出现的均值塌陷问题。", "motivation": "大型语言模型在服务全球受众时需要从强制执行通用共识转向尊重文化的多样性。然而，当密集型模型试图适应冲突的价值分布时会出现均值塌陷现象，无法代表多样化的群体。这是因为梯度干扰导致密集参数难以涵盖不同的文化模式。", "method": "CuMA是一种框架，通过引入人口统计学感知的路由机制来解决条件容量分离问题。该框架构建了一个潜在的文化拓扑结构，以明确地将冲突的梯度解耦为专门的专家子空间。", "result": "在WorldValuesBench、社区对齐和PRISM等广泛的评估中，CuMA取得了最先进的性能，并且显著优于密集基线模型以及仅语义的混合专家模型。该研究证实了CuMA能够有效缓解均值塌陷现象，从而保护文化多样性。", "conclusion": "CuMA框架通过引入人口统计学感知机制解决了大语言模型在处理多元文化价值时遇到的问题，并且有效地保持了文化的多样性。"}}
{"id": "2601.04884", "pdf": "https://arxiv.org/pdf/2601.04884", "abs": "https://arxiv.org/abs/2601.04884", "authors": ["Issa Hanou", "Eric Kemmeren", "Devin Wild Thomas", "Mathijs de Weerdt"], "title": "Precomputing Multi-Agent Path Replanning using Temporal Flexibility: A Case Study on the Dutch Railway Network", "categories": ["cs.AI"], "comment": null, "summary": "Executing a multi-agent plan can be challenging when an agent is delayed, because this typically creates conflicts with other agents. So, we need to quickly find a new safe plan. Replanning only the delayed agent often does not result in an efficient plan, and sometimes cannot even yield a feasible plan. On the other hand, replanning other agents may lead to a cascade of changes and delays. We show how to efficiently replan by tracking and using the temporal flexibility of other agents while avoiding cascading delays. This flexibility is the maximum delay an agent can take without changing the order of or further delaying more agents. Our algorithm, FlexSIPP, precomputes all possible plans for the delayed agent, also returning the changes for the other agents, for any single-agent delay within the given scenario. We demonstrate our method in a real-world case study of replanning trains in the densely-used Dutch railway network. Our experiments show that FlexSIPP provides effective solutions, relevant to real-world adjustments, and within a reasonable timeframe.", "AI": {"tldr": "本文提出了一种名为FlexSIPP的算法，用于预先计算多智能体路径重规划时其他代理人的灵活性。", "motivation": "当一个代理延迟执行时，传统的方法可能无法有效找到新计划或导致其他代理进一步延误。因此，需要一种方法来高效处理这种情况，并利用其他代理的时间弹性避免级联延误。", "method": "FlexSIPP算法预先计算所有可能的重规划方案以应对单个代理的延迟情况，并返回受影响代理的变化信息。", "result": "实验表明FlexSIPP能提供有效的解决方案，适用于实际调整需求且能在合理时间内完成。", "conclusion": "FlexSIPP在密集使用铁路网络中的表现证明了其在多智能体重规划场景下的有效性和实用性。"}}
{"id": "2601.04882", "pdf": "https://arxiv.org/pdf/2601.04882", "abs": "https://arxiv.org/abs/2601.04882", "authors": ["Mattia Figaro", "Francesco Rossato", "Marco Giordani", "Alessandro Traspadini", "Takayuki Shimizu", "Chinmay Mahabal", "Sanjeewa Herath", "Chunghan Lee", "Dogan Kutay Pekcan", "Michele Zorzi"], "title": "5G NR Non-Terrestrial Networks: From Early Results to the Road Ahead", "categories": ["cs.NI", "cs.ET"], "comment": "8 pages, 2 figures. This paper has been submitted to npj Wireless Technology for publication", "summary": "This paper overviews the 3GPP 5G NR-NTN standard, detailing the evolution from Rel. 18 to 19 and innovations for Rel. 20. Using realistic ns-3 simulations validated against 3GPP calibration data, we evaluate various satellite network configurations. The results highlight the potential of NTNs to extend wireless connectivity to remote areas, serve requests during emergency, and alleviate terrestrial network congestion.", "AI": {"tldr": "本文概述了3GPP 5G NR-NTN标准，从Rel. 18到19的演进及为Rel. 20的技术创新，并通过与3GPP校准数据验证过的ns-3仿真评估不同的卫星网络配置。", "motivation": "动机在于探讨非地面网络（NTN）技术如何拓展无线通信覆盖范围，特别是在偏远地区和紧急情况下的应用，并减轻陆地网络的负载。", "method": "该论文使用基于ns-3仿真的方法，其结果通过与3GPP校准数据进行验证。", "result": "仿真结果显示了NTNs在扩展远程区域无线连接、提供紧急服务请求以及缓解地面网络拥堵方面的潜力。", "conclusion": "结论是NTN技术具有广泛的潜在应用价值，并为未来的标准发展指明方向。"}}
{"id": "2601.04881", "pdf": "https://arxiv.org/pdf/2601.04881", "abs": "https://arxiv.org/abs/2601.04881", "authors": ["Kiyoung Choi", "Juwon Jeong", "Sehoon Oh"], "title": "Zero Wrench Control via Wrench Disturbance Observer for Learning-free Peg-in-hole Assembly", "categories": ["cs.RO"], "comment": null, "summary": "This paper proposes a Dynamic Wrench Disturbance Observer (DW-DOB) designed to achieve highly sensitive zero-wrench control in contact-rich manipulation. By embedding task-space inertia into the observer nominal model, DW-DOB cleanly separates intrinsic dynamic reactions from true external wrenches. This preserves sensitivity to small forces and moments while ensuring robust regulation of contact wrenches. A passivity-based analysis further demonstrates that DW-DOB guarantees stable interactions under dynamic conditions, addressing the shortcomings of conventional observers that fail to compensate for inertial effects. Peg-in-hole experiments at industrial tolerances (H7/h6) validate the approach, yielding deeper and more compliant insertions with minimal residual wrenches and outperforming a conventional wrench disturbance observer and a PD baseline. These results highlight DW-DOB as a practical learning-free solution for high-precision zero-wrench control in contact-rich tasks.", "AI": {"tldr": "提出了一种动态力矩扰动观测器（DW-DOB）来实现高灵敏度的零力矩控制。", "motivation": "旨在解决传统观察器无法补偿惯性效应的问题，实现在复杂接触任务中学习自由的高精度零力矩控制。", "method": "通过嵌入任务空间惯量到观测器的名义模型，实现了对内在动力反应和真实外部力矩的清洁分离。采用基于被动性的分析进一步验证了DW-DOB在动态条件下的稳定性交互。", "result": "实验表明，在工业公差下（H7/h6），该方法能实现更深、更柔顺的插入，并且剩余力矩最小，优于传统的方法和PD基准。", "conclusion": "证明了DW-DOB是一种实用的学习自由解决方案，适用于高精度零力矩控制任务。"}}
{"id": "2601.04878", "pdf": "https://arxiv.org/pdf/2601.04878", "abs": "https://arxiv.org/abs/2601.04878", "authors": ["Isabella A. Stewart", "Markus J. Buehler"], "title": "Higher-Order Knowledge Representations for Agentic Scientific Reasoning", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CL", "cs.LG"], "comment": null, "summary": "Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a \"teacherless\" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.", "AI": {"tldr": "本文介绍了基于超图的知识表示方法，用于构建更深层次的科学推理系统。", "motivation": "现有语言模型依赖于检索增强上下文缺乏结构深度；传统知识图谱难以捕捉复杂交互行为。因此提出使用超图来解决这些问题。", "method": "通过分析约1,100篇关于生物复合支架的手稿，构建了一个包含161,172个节点和320,201条超边的全球超图，并展示了装备有超图遍历工具的代理系统如何生成有关新复合材料机制性假设。", "result": "该方法揭示了科学文档中的规模自由拓扑结构，能够成功地将铈氧化物与PCL支架通过壳聚糖中介链接起来，形成机制性假设。", "conclusion": "本文提出了一种无需教师的代理推理系统，利用超图拓扑作为验证护栏加速科学发现，比传统图形方法更有效地揭示隐藏关系。"}}
{"id": "2601.04876", "pdf": "https://arxiv.org/pdf/2601.04876", "abs": "https://arxiv.org/abs/2601.04876", "authors": ["Kaiwen Luo", "Liang Lin", "Yibo Zhang", "Moayad Aloqaily", "Dexian Wang", "Zhenhong Zhou", "Junwei Zhang", "Kun Wang", "Li Sun", "Qingsong Wen"], "title": "ChronosAudio: A Comprehensive Long-Audio Benchmark for Evaluating Audio-Large Language Models", "categories": ["cs.SD"], "comment": null, "summary": "Although Audio Large Language Models (ALLMs) have witnessed substantial advancements, their long audio understanding capabilities remain unexplored. A plethora of benchmarks have been proposed for general audio tasks, they predominantly focus on short-form clips, leaving without a consensus on evaluating ALLMs over extended durations. This paper proposes ChronosAudio, the first multi-task benchmark tailored for long-audio understanding in ALLMs. It encompasses six major task categories and comprises 36,000 test instances totaling over 200 hours audio, stratified into short, middle, and long-form categories to comprehensively evaluate length generalization. Extensive experiments on 16 state-of-the-art models using ChronosAudio yield three critical findings: 1.Precipitous Long-Context Collapse: ALLMs exhibit a severe inability to sustain performance, with the transition from short to long contexts triggering a staggering performance degradation of over 90% in specific tasks. 2.Structural Attention Dilution: Performance degradation stems from a fundamental failure in maintaining temporal locality; attention mechanisms suffer from significant diffusion in later sequences. 3.Restorative Ceiling of Mitigation: Current strategies only offer 50% recovery. These findings reveal significant challenges in long-audio, underscoring the urgent need for approaches to achieve robust, document-level audio reasoning.", "AI": {"tldr": "提出ChronosAudio，一个用于评估音频大型语言模型长时音频理解能力的多任务基准", "motivation": "当前多数音频基准仅针对短片段进行评估，缺乏对长时音频理解和处理的研究。为了填补这一空白，并促进相关技术的发展和提升，作者提出了ChronosAudio基准", "method": "设计了包含六类主要任务和36000个测试实例的ChronosAudio基准，涵盖了从短到长不同形式的音频样本", "result": "在16种最新模型上进行实验发现：随着上下文长度增加，性能急剧下降；注意机制出现显著扩散；现有缓解策略仅能恢复约50%的性能", "conclusion": "研究揭示了在处理长时音频中面临的重要挑战，并强调需要开发新的方法来实现稳健、文档级别的音频推理"}}
{"id": "2601.04867", "pdf": "https://arxiv.org/pdf/2601.04867", "abs": "https://arxiv.org/abs/2601.04867", "authors": ["Alistair Carson", "Alec Wright", "Stefan Bilbao"], "title": "Gradient-based Optimisation of Modulation Effects", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Submitted to J. Audio Eng. Soc. Dec. 2025", "summary": "Modulation effects such as phasers, flangers and chorus effects are heavily used in conjunction with the electric guitar. Machine learning based emulation of analog modulation units has been investigated in recent years, but most methods have either been limited to one class of effect or suffer from a high computational cost or latency compared to canonical digital implementations. Here, we build on previous work and present a framework for modelling flanger, chorus and phaser effects based on differentiable digital signal processing. The model is trained in the time-frequency domain, but at inference operates in the time-domain, requiring zero latency. We investigate the challenges associated with gradient-based optimisation of such effects, and show that low-frequency weighting of loss functions avoids convergence to local minima when learning delay times. We show that when trained against analog effects units, sound output from the model is in some cases perceptually indistinguishable from the reference, but challenges still remain for effects with long delay times and feedback.", "AI": {"tldr": "基于可微数字信号处理构建了一个框架，用于模拟延迟、合唱和相位器等效果。", "motivation": "现有方法要么只能模拟一类效果，要么计算成本高或延迟大。本研究旨在解决这些问题，并优化这些效果的梯度学习过程。", "method": "在时间-频率域中训练模型，在推理过程中则转换到时间域以实现零延时操作。通过低频加权损失函数来避免梯度下降中的局部极小值问题。", "result": "当与模拟效果单元进行比较时，输出声音在某些情况下可达到感知上不可区分的程度，但仍然存在长延迟时间和反馈的问题。", "conclusion": "提出的框架能够在时间域实现低延时操作，并且通过优化梯度学习过程，在一定程度上提高了模型的性能。但是仍需进一步解决复杂效果的问题。"}}
{"id": "2601.04864", "pdf": "https://arxiv.org/pdf/2601.04864", "abs": "https://arxiv.org/abs/2601.04864", "authors": ["Haihua Luo", "Xuming Ran", "Zhengji Li", "Huiyan Xue", "Tingting Jiang", "Jiangrong Shen", "Tommi Kärkkäinen", "Qi Xu", "Fengyu Cong"], "title": "Key-Value Pair-Free Continual Learner via Task-Specific Prompt-Prototype", "categories": ["cs.AI"], "comment": null, "summary": "Continual learning aims to enable models to acquire new knowledge while retaining previously learned information. Prompt-based methods have shown remarkable performance in this domain; however, they typically rely on key-value pairing, which can introduce inter-task interference and hinder scalability. To overcome these limitations, we propose a novel approach employing task-specific Prompt-Prototype (ProP), thereby eliminating the need for key-value pairs. In our method, task-specific prompts facilitate more effective feature learning for the current task, while corresponding prototypes capture the representative features of the input. During inference, predictions are generated by binding each task-specific prompt with its associated prototype. Additionally, we introduce regularization constraints during prompt initialization to penalize excessively large values, thereby enhancing stability. Experiments on several widely used datasets demonstrate the effectiveness of the proposed method. In contrast to mainstream prompt-based approaches, our framework removes the dependency on key-value pairs, offering a fresh perspective for future continual learning research.", "AI": {"tldr": "提出了一种新的无键值配对的持续学习方法，使用任务特定提示和原型进行特征学习。", "motivation": "传统的提示方法依赖于键值配对，可能导致任务间干扰并限制可扩展性。通过消除这些障碍来改进持续学习。", "method": "采用任务特定的Prompt-Prototype（ProP）方法，通过任务特定提示促进当前任务的有效特征学习，并使用相应原型捕捉输入的代表性特征。引入正则化约束以增强稳定性。", "result": "实验表明所提出的方法在多个常用数据集上表现优异。", "conclusion": "该框架提供了一种新的视角来解决持续学习中的键值依赖问题，为未来的研究开辟了新途径。"}}
{"id": "2601.04861", "pdf": "https://arxiv.org/pdf/2601.04861", "abs": "https://arxiv.org/abs/2601.04861", "authors": ["Jingbo Wang", "Sendong Zhao", "Jiatong Liu", "Haochun Wang", "Wanting Li", "Bing Qin", "Ting Liu"], "title": "Orchestrating Intelligence: Confidence-Aware Routing for Efficient Multi-Agent Collaboration across Multi-Scale Models", "categories": ["cs.AI"], "comment": null, "summary": "While multi-agent systems (MAS) have demonstrated superior performance over single-agent approaches in complex reasoning tasks, they often suffer from significant computational inefficiencies. Existing frameworks typically deploy large language models (LLMs) uniformly across all agent roles, failing to account for the varying cognitive demands of different reasoning stages. We address this inefficiency by proposing OI-MAS framework, a novel multi-agent framework that implements an adaptive model-selection policy across a heterogeneous pool of multi-scale LLMs. Specifically, OI-MAS introduces a state-dependent routing mechanism that dynamically selects agent roles and model scales throughout the reasoning process. In addition, we introduce a confidence-aware mechanism that selects appropriate model scales conditioned on task complexity, thus reducing unnecessary reliance on large-scale models. Experimental results show that OI-MAS consistently outperforms baseline multi-agent systems, improving accuracy by up to 12.88\\% while reducing cost by up to 79.78\\%.", "AI": {"tldr": "提出了OI-MAS框架，通过自适应模型选择策略和状态依赖路由机制，在多代理系统中动态选择合适的模型规模，以提高效率。", "motivation": "现有的多代理系统在复杂推理任务中表现出色但存在计算效率低下的问题。当前的部署方法通常均匀使用大规模语言模型，忽略了不同推理阶段的认知需求差异。", "method": "OI-MAS框架引入了基于状态依赖路由机制的选择策略，根据任务难度自适应选择合适的模型规模，以减少对大模型不必要的依赖。", "result": "实验结果显示，OI-MAS在提高精度的同时显著降低了成本，与基线系统相比性能提升了12.88%，成本减少了79.78%。", "conclusion": "通过引入状态依赖路由机制和任务难度自适应选择策略，OI-MAS框架能够高效地优化多代理系统的运行效率。"}}
{"id": "2601.04860", "pdf": "https://arxiv.org/pdf/2601.04860", "abs": "https://arxiv.org/abs/2601.04860", "authors": ["Ayush Pande"], "title": "DivAS: Interactive 3D Segmentation of NeRFs via Depth-Weighted Voxel Aggregation", "categories": ["cs.CV"], "comment": null, "summary": "Existing methods for segmenting Neural Radiance Fields (NeRFs) are often optimization-based, requiring slow per-scene training that sacrifices the zero-shot capabilities of 2D foundation models. We introduce DivAS (Depth-interactive Voxel Aggregation Segmentation), an optimization-free, fully interactive framework that addresses these limitations. Our method operates via a fast GUI-based workflow where 2D SAM masks, generated from user point prompts, are refined using NeRF-derived depth priors to improve geometric accuracy and foreground-background separation. The core of our contribution is a custom CUDA kernel that aggregates these refined multi-view masks into a unified 3D voxel grid in under 200ms, enabling real-time visual feedback. This optimization-free design eliminates the need for per-scene training. Experiments on Mip-NeRF 360° and LLFF show that DivAS achieves segmentation quality comparable to optimization-based methods, while being 2-2.5x faster end-to-end, and up to an order of magnitude faster when excluding user prompting time.", "AI": {"tldr": "DivAS是一种用于交互式3D分割NeRF的优化无关框架，通过快速GUI工作流和自定义CUDA内核实现高效实时反馈。", "motivation": "现有方法在对NeRF进行分割时通常依赖于耗时的场景训练过程，从而牺牲了2D基础模型的零样本能力。DivAS旨在解决这些问题，并提供一种优化无关、完全交互式的分割框架。", "method": "用户通过GUI界面给出提示点生成2D SAM掩码，利用从NeRF中获取的深度先验来改进几何准确性和前景背景分离。核心贡献是自定义CUDA内核，在不到200毫秒的时间内将这些多视图掩码聚合到统一的3D体素网格中。", "result": "实验表明DivAS在Mip-NeRF和LLFF数据集上的分割质量与优化方法相当，整体上快2至2.5倍，并且当不考虑用户提示时间时，速度可提高一个数量级。", "conclusion": "DivAS通过提供一种无需场景训练的交互式3D分割框架实现了高质量、高效的NeRF分割。"}}
{"id": "2601.04855", "pdf": "https://arxiv.org/pdf/2601.04855", "abs": "https://arxiv.org/abs/2601.04855", "authors": ["Francesco Ferrini", "Veronica Lachi", "Antonio Longa", "Bruno Lepri", "Matono Akiyoshi", "Andrea Passerini", "Xin Liu", "Manfred Jaeger"], "title": "Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.", "AI": {"tldr": "重新思考图神经网络在处理缺失节点特征时的挑战，提出了一种新的评估方法和一种简单的解决方案GNNmim。", "motivation": "现有研究主要针对高维稀疏特征且数据丢失机制为随机完全丢失的情况。然而，在现实世界的应用中，这些条件可能不成立，因此需要引入更密集、语义丰富的数据集以及更加真实的缺失性机制来评估模型的性能。", "method": "提出了GNNmim方法，该方法是一种针对具有不完整特征数据节点分类任务的有效基线方案。", "result": "实验结果显示，无论是在不同的数据集还是在多种丢失模式下，GNNmim都能与专门架构媲美甚至超越。", "conclusion": "通过引入密集且语义丰富的特征以及更加真实的缺失性机制对现有方法进行了评估，并提出了一个简单而有效的解决方案来处理节点分类任务中的不完整特征问题。"}}
{"id": "2601.04854", "pdf": "https://arxiv.org/pdf/2601.04854", "abs": "https://arxiv.org/abs/2601.04854", "authors": ["Oshri Naparstek"], "title": "Token Maturation: Autoregressive Language Generation via Continuous Token Dynamics", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "In preperation to ICML 2026", "summary": "Autoregressive language models are conventionally defined over discrete token sequences, committing to a specific token at every generation step. This early discretization forces uncertainty to be resolved through token-level sampling, often leading to instability, repetition, and sensitivity to decoding heuristics. In this work, we introduce a continuous autoregressive formulation of language generation in which tokens are represented as continuous vectors that \\emph{mature} over multiple update steps before being discretized. Rather than sampling tokens, the model evolves continuous token representations through a deterministic dynamical process, committing to a discrete token only when the representation has sufficiently converged. Discrete text is recovered via hard decoding, while uncertainty is maintained and resolved in the continuous space. We show that this maturation process alone is sufficient to produce coherent and diverse text using deterministic decoding (argmax), without reliance on token-level sampling, diffusion-style denoising, or auxiliary stabilization mechanisms. Additional perturbations, such as stochastic dynamics or history smoothing, can be incorporated naturally but are not required for the model to function. To our knowledge, this is the first autoregressive language model that generates text by evolving continuous token representations to convergence prior to discretization, enabling stable generation without token-level sampling.", "AI": {"tldr": "本文介绍了一种通过连续令牌动态生成语言的新方法，该方法在每个生成步骤之前使令牌成熟。", "motivation": "传统的自回归语言模型过早地将不确定性转化为令牌级别的采样，导致不稳定性、重复和对解码启发式的敏感性。希望通过延迟离散化过程来解决这些问题。", "method": "通过动态演化连续令牌表示直到它们收敛才进行离散化，从而生成文本。", "result": "证明了仅凭成熟过程即可使用确定性解码（argmax）产生连贯且多样化的文本，无需依赖于令牌级别的采样、扩散式去噪或辅助稳定机制。", "conclusion": "这是第一个通过演化连续令牌表示来生成文本的自回归语言模型，从而在不进行令牌级采样的情况下实现稳定的生成。"}}
{"id": "2601.04834", "pdf": "https://arxiv.org/pdf/2601.04834", "abs": "https://arxiv.org/abs/2601.04834", "authors": ["Alessandra Scotto di Freca", "Tiziana D Alessandro", "Francesco Fontanella", "Filippo Sarria", "Claudio De Stefano"], "title": "Character Detection using YOLO for Writer Identification in multiple Medieval books", "categories": ["cs.CV"], "comment": "7 pages, 2 figures, 1 table. Accepted at IEEE-CH 2025", "summary": "Paleography is the study of ancient and historical handwriting, its key objectives include the dating of manuscripts and understanding the evolution of writing. Estimating when a document was written and tracing the development of scripts and writing styles can be aided by identifying the individual scribes who contributed to a medieval manuscript. Although digital technologies have made significant progress in this field, the general problem remains unsolved and continues to pose open challenges. ... We previously proposed an approach focused on identifying specific letters or abbreviations that characterize each writer. In that study, we considered the letter \"a\", as it was widely present on all pages of text and highly distinctive, according to the suggestions of expert paleographers. We used template matching techniques to detect the occurrences of the character \"a\" on each page and the convolutional neural network (CNN) to attribute each instance to the correct scribe. Moving from the interesting results achieved from this previous system and being aware of the limitations of the template matching technique, which requires an appropriate threshold to work, we decided to experiment in the same framework with the use of the YOLO object detection model to identify the scribe who contributed to the writing of different medieval books. We considered the fifth version of YOLO to implement the YOLO object detection model, which completely substituted the template matching and CNN used in the previous work. The experimental results demonstrate that YOLO effectively extracts a greater number of letters considered, leading to a more accurate second-stage classification. Furthermore, the YOLO confidence score provides a foundation for developing a system that applies a rejection threshold, enabling reliable writer identification even in unseen manuscripts.", "AI": {"tldr": "使用YOLO检测中世纪书籍中的字符，以识别书写者", "motivation": "在古文字研究领域，虽然数字技术已取得进展，但确定手稿作者的问题仍未解决。为了提高准确性并克服模板匹配的限制，本研究采用YOLO进行字符检测。", "method": "使用第五版YOLO替代先前使用的模板匹配和CNN模型，以识别特定字符并归因于正确的书写者", "result": "实验结果表明，与以前的方法相比，YOLO能够提取更多字符，并提供更高的准确性。此外，YOLO的置信度分数可用于开发应用阈值的系统，从而在未知手稿中实现可靠的书写者识别。", "conclusion": "YOLO在中世纪书籍的手写识别方面表现出色，克服了模板匹配方法的一些限制"}}
{"id": "2601.04825", "pdf": "https://arxiv.org/pdf/2601.04825", "abs": "https://arxiv.org/abs/2601.04825", "authors": ["Matan Kleiner", "Lior Michaeli", "Tomer Michaeli"], "title": "Illumination Angular Spectrum Encoding for Controlling the Functionality of Diffractive Networks", "categories": ["physics.optics", "cs.CV", "cs.LG"], "comment": "Project's code https://github.com/matankleiner/Angular-Spectrum-Encoding", "summary": "Diffractive neural networks have recently emerged as a promising framework for all-optical computing. However, these networks are typically trained for a single task, limiting their potential adoption in systems requiring multiple functionalities. Existing approaches to achieving multi-task functionality either modify the mechanical configuration of the network per task or use a different illumination wavelength or polarization state for each task. In this work, we propose a new control mechanism, which is based on the illumination's angular spectrum. Specifically, we shape the illumination using an amplitude mask that selectively controls its angular spectrum. We employ different illumination masks for achieving different network functionalities, so that the mask serves as a unique task encoder. Interestingly, we show that effective control can be achieved over a very narrow angular range, within the paraxial regime. We numerically illustrate the proposed approach by training a single diffractive network to perform multiple image-to-image translation tasks. In particular, we demonstrate translating handwritten digits into typeset digits of different values, and translating handwritten English letters into typeset numbers and typeset Greek letters, where the type of the output is determined by the illumination's angular components. As we show, the proposed framework can work under different coherence conditions, and can be combined with existing control strategies, such as different wavelengths. Our results establish the illumination angular spectrum as a powerful degree of freedom for controlling diffractive networks, enabling a scalable and versatile framework for multi-task all-optical computing.", "AI": {"tldr": "该论文提出了一种基于照明光谱角编码的控制机制，用于实现单个衍射网络在多个任务之间的转换。", "motivation": "现有的多任务处理方法需要对机械结构进行修改或改变光源波长和偏振状态，这限制了网络的功能灵活性。为此，作者提出了新的控制策略以提升光学计算系统的多功能性。", "method": "通过设计不同类型的照明光谱角编码掩模来实现衍射网络的不同功能转换，并训练单一的衍射网络执行多种图像到图像翻译任务。", "result": "证明了所提出的方法可以在较小的角度范围内有效工作，展示了将手写数字转化为不同的印刷体数字以及字母转化为不同类型输出的能力。该方法还可在不同相干条件下使用并与其他控制策略结合。", "conclusion": "照明光谱角编码为衍射网络提供了强大的自由度，可以实现多功能的全光学计算，并且具有可扩展性和灵活性的特点。"}}
{"id": "2601.04824", "pdf": "https://arxiv.org/pdf/2601.04824", "abs": "https://arxiv.org/abs/2601.04824", "authors": ["Oriol Rabasseda", "Zenjie Li", "Kamal Nasrollahi", "Sergio Escalera"], "title": "SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models", "categories": ["cs.CV"], "comment": "This work has been accepted at Real World Surveillance: Applications and Challenges, 6th (in WACV Workshops)", "summary": "Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models. Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.", "AI": {"tldr": "提出SOVABench，一个基于监控视频的车辆行为检索基准。", "motivation": "现有内容基础视频检索基准主要关注场景级别相似性，缺乏对监视中所需的动作区分性的评估。引入SOVABench以填补这一空白。", "method": "利用多模态大语言模型（MLLM）生成描述，并提出无训练框架生产可解释的嵌入表示。", "result": "在SOVABench和其他几个空间和计数基准上实现了强大的性能表现。", "conclusion": "通过监控视频中的车辆行为检索，展示了MLLM在视觉推理和指令跟随上的能力。"}}
{"id": "2601.04823", "pdf": "https://arxiv.org/pdf/2601.04823", "abs": "https://arxiv.org/abs/2601.04823", "authors": ["Guanzhi Deng", "Bo Li", "Ronghao Chen", "Huacan Wang", "Linqi Song", "Lijie Wen"], "title": "DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Mixture-of-Experts (MoE) has become a prominent paradigm for scaling Large Language Models (LLMs). Parameter-efficient fine-tuning (PEFT), such as LoRA, is widely adopted to adapt pretrained MoE LLMs to downstream tasks. However, existing approaches assign identical LoRA ranks to all experts, overlooking the intrinsic functional specialization within MoE LLMs. This uniform allocation leads to resource mismatch, task-relevant experts are under-provisioned while less relevant ones receive redundant parameters. We propose a Dynamic Rank LoRA framework named DR-LoRA, which dynamically grows expert LoRA ranks during fine-tuning based on task-specific demands. DR-LoRA employs an Expert Saliency Scoring mechanism that integrates expert routing frequency and LoRA rank importance to quantify each expert's demand for additional capacity. Experts with higher saliency scores are prioritized for rank expansion, enabling the automatic formation of a heterogeneous rank distribution tailored to the target task. Experiments on multiple benchmarks demonstrate that DR-LoRA consistently outperforms standard LoRA and static allocation strategies under the same parameter budget, achieving superior task performance with more efficient parameter utilization.", "AI": {"tldr": "该论文提出了动态调整LoRA参数的DR-LoRA框架，用于优化Mixture-of-Experts（MoE）大型语言模型的下游任务适应。", "motivation": "现有方法在所有专家中分配相同的LoRA秩，忽略了内在的功能专业化，导致资源错配。任务相关性强的专家被低估而与任务无关的专家则获得多余参数。", "method": "DR-LoRA框架通过动态增长基于任务需求的专家LoRA秩，在训练过程中采用专家显著度评分机制，根据路由频率和LoRA秩的重要性量化每个专家对额外容量的需求。", "result": "实验表明DR-LoRA在相同参数预算下比标准LoRA和静态分配策略表现更好，实现了更优的任务性能和更有效的参数利用。", "conclusion": "通过动态调整MoE模型中专家的LoRA秩，可以优化大型语言模型适应下游任务的能力，并提高其效率。"}}
{"id": "2601.04819", "pdf": "https://arxiv.org/pdf/2601.04819", "abs": "https://arxiv.org/abs/2601.04819", "authors": ["Aleksei Kondratenko", "Mussie Birhane", "Houssame E. Hsain", "Guido Maciocci"], "title": "AECV-Bench: Benchmarking Multimodal Models on Architectural and Engineering Drawings Understanding", "categories": ["cs.AI"], "comment": null, "summary": "AEC drawings encode geometry and semantics through symbols, layout conventions, and dense annotation, yet it remains unclear whether modern multimodal and vision-language models can reliably interpret this graphical language. We present AECV-Bench, a benchmark for evaluating multimodal and vision-language models on realistic AEC artefacts via two complementary use cases: (i) object counting on 120 high-quality floor plans (doors, windows, bedrooms, toilets), and (ii) drawing-grounded document QA spanning 192 question-answer pairs that test text extraction (OCR), instance counting, spatial reasoning, and comparative reasoning over common drawing regions. Object-counting performance is reported using per-field exact-match accuracy and MAPE results, while document-QA performance is reported using overall accuracy and per-category breakdowns with an LLM-as-a-judge scoring pipeline and targeted human adjudication for edge cases. Evaluating a broad set of state-of-the-art models under a unified protocol, we observe a stable capability gradient; OCR and text-centric document QA are strongest (up to 0.95 accuracy), spatial reasoning is moderate, and symbol-centric drawing understanding - especially reliable counting of doors and windows - remains unsolved (often 0.40-0.55 accuracy) with substantial proportional errors. These results suggest that current systems function well as document assistants but lack robust drawing literacy, motivating domain-specific representations and tool-augmented, human-in-the-loop workflows for an efficient AEC automation.", "AI": {"tldr": "该论文提出了AECV-Bench，一个评估多模态和视觉语言模型在建筑和工程图纸理解中的基准。", "motivation": "现代的多模态和视觉语言模型能否可靠地解释包含几何、符号、布局规则和密集注释的建筑和工程图？", "method": "通过两种互补用例评估模型：对象计数（120份高质量平面图）及基于绘图文档问答（192个问题-答案对）。性能报告包括精确匹配准确率和MAPE结果。", "result": "OCR和技术文档QA最强，空间推理中等，符号中心的理解仍未解决。目前系统可作为文档助手使用，但缺乏强大的图纸理解能力。", "conclusion": "结果显示当前模型在自动化建筑工程方面功能良好但不足够智能，需要特定领域表示和人机协作以实现高效自动化。"}}
{"id": "2601.04809", "pdf": "https://arxiv.org/pdf/2601.04809", "abs": "https://arxiv.org/abs/2601.04809", "authors": ["Caijun Xu", "Changyi Xiao", "Zhongyuan Peng", "Xinrun Wang", "Yixin Cao"], "title": "SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning", "categories": ["cs.AI"], "comment": "19 pages,5 figures", "summary": "Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.", "AI": {"tldr": "提出了一种用于增强大模型推理能力的自适应学习环境SCALER。", "motivation": "解决强化学习训练信号有效性下降的问题，以及任务难度与模型能力不匹配和过度拟合到特定问题模式的问题。", "method": "通过引入可扩展合成管道将现实世界编程问题转化为具有可控难度的验证推理环境，并采用自适应多环境RL策略动态调整实例难度和环境集以跟踪模型能力边界。", "result": "SCALER在多样化的推理基准上持续优于基于数据集的强化学习基线，表现出更稳定的长期训练动力学。", "conclusion": "SCALER通过自适应环境设计维持有效的学习信号，支持持续改进，并且在各种推理任务中展示了优越的表现。"}}
{"id": "2601.04807", "pdf": "https://arxiv.org/pdf/2601.04807", "abs": "https://arxiv.org/abs/2601.04807", "authors": ["Oscar Llorente", "Jaime Boal", "Eugenio F. Sánchez-Úbeda", "Antonio Diaz-Cano", "Miguel Familiar"], "title": "Parallelizing Node-Level Explainability in Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.", "AI": {"tldr": "该论文提出了通过图划分并行化节点级别的可解释性计算的方法，提高了大规模图神经网络模型中的可扩展性和透明度。", "motivation": "在节点分类任务中，随着图规模的增加，计算节点级别可解释性的耗时显著增长。批量策略虽然可以提高效率但通常会牺牲结果的质量。为了克服这一问题，作者提出了新的并行化方法以提升可解释性。", "method": "通过将原始图形分解为不相交的子图来实现节点级可解释性的并行计算，并提出了一种基于dropout的方法，在内存受限的情况下提供可控制的记忆使用与解释精度之间的折衷。", "result": "实验结果表明，该方法在真实数据集上实现了显著的速度提升，同时保持了高质量的结果。", "conclusion": "论文提出的方法能够有效提高图神经网络模型中节点级别可解释性的计算效率和质量，在大规模应用中有很好的前景。"}}
{"id": "2601.04805", "pdf": "https://arxiv.org/pdf/2601.04805", "abs": "https://arxiv.org/abs/2601.04805", "authors": ["Siyuan Gan", "Jiaheng Liu", "Boyan Wang", "Tianpei Yang", "Runqing Miao", "Yuyao Zhang", "Fanyu Meng", "Junlan Feng", "Linjian Meng", "Jing Huo", "Yang Gao"], "title": "Thinking-Based Non-Thinking: Solving the Reward Hacking Problem in Training Hybrid Reasoning Models via Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Large reasoning models (LRMs) have attracted much attention due to their exceptional performance. However, their performance mainly stems from thinking, a long Chain of Thought (CoT), which significantly increase computational overhead. To address this overthinking problem, existing work focuses on using reinforcement learning (RL) to train hybrid reasoning models that automatically decide whether to engage in thinking or not based on the complexity of the query. Unfortunately, using RL will suffer the the reward hacking problem, e.g., the model engages in thinking but is judged as not doing so, resulting in incorrect rewards. To mitigate this problem, existing works either employ supervised fine-tuning (SFT), which incurs high computational costs, or enforce uniform token limits on non-thinking responses, which yields limited mitigation of the problem. In this paper, we propose Thinking-Based Non-Thinking (TNT). It does not employ SFT, and sets different maximum token usage for responses not using thinking across various queries by leveraging information from the solution component of the responses using thinking. Experiments on five mathematical benchmarks demonstrate that TNT reduces token usage by around 50% compared to DeepSeek-R1-Distill-Qwen-1.5B/7B and DeepScaleR-1.5B, while significantly improving accuracy. In fact, TNT achieves the optimal trade-off between accuracy and efficiency among all tested methods. Additionally, the probability of reward hacking problem in TNT's responses, which are classified as not using thinking, remains below 10% across all tested datasets.", "AI": {"tldr": "本文提出了一种新的方法Thinking-Based Non-Thinking (TNT)，旨在解决在训练混合推理模型时的奖励欺骗问题，同时减少计算成本并提高准确性。", "motivation": "现有基于强化学习的方法容易遭受奖励欺骗的问题，并且其解决方案（如监督微调或设置统一的令牌限制）存在高计算开销或者缓解效果有限。因此，本文旨在提出一个更加有效的方法来解决这些问题。", "method": "TNT方法通过使用推理模型的答案组件中的信息为不同查询设置了不同的最大令牌使用量，从而避免了对非思考响应进行监督微调并解决了奖励欺骗问题。", "result": "实验表明，TNT相比DeepSeek-R1-Distill-Qwen-1.5B/7B和DeepScaleR-1.5B方法在五个数学基准测试中能够减少大约50%的令牌使用量，同时显著提高了准确性，并且奖励欺骗问题的概率保持在10％以下。", "conclusion": "TNT实现了最优的准确性和效率之间的权衡，在所有测试的方法中表现出色。"}}
{"id": "2601.04800", "pdf": "https://arxiv.org/pdf/2601.04800", "abs": "https://arxiv.org/abs/2601.04800", "authors": ["Bapu D. Chendage", "Rajivkumar S. Mente"], "title": "Integrated Framework for Selecting and Enhancing Ancient Marathi Inscription Images from Stone, Metal Plate, and Paper Documents", "categories": ["cs.CV"], "comment": "9 Pages, 5 figures", "summary": "Ancient script images often suffer from severe background noise, low contrast, and degradation caused by aging and environmental effects. In many cases, the foreground text and background exhibit similar visual characteristics, making the inscriptions difficult to read. The primary objective of image enhancement is to improve the readability of such degraded ancient images. This paper presents an image enhancement approach based on binarization and complementary preprocessing techniques for removing stains and enhancing unclear ancient text. The proposed methods are evaluated on different types of ancient scripts, including inscriptions on stone, metal plates, and historical documents. Experimental results show that the proposed approach achieves classification accuracies of 55.7%, 62%, and 65.6% for stone, metal plate, and document scripts, respectively, using the K-Nearest Neighbor (K-NN) classifier. Using the Support Vector Machine (SVM) classifier, accuracies of 53.2%, 59.5%, and 67.8% are obtained. The results demonstrate the effectiveness of the proposed enhancement method in improving the readability of ancient Marathi inscription images.", "AI": {"tldr": "提出了一种基于二值化和预处理技术的古代马哈拉施特拉语铭文图像增强方法，以提高其可读性。", "motivation": "古代文字图像由于背景噪声、低对比度以及老化和环境因素导致的退化而难以阅读。本文旨在通过图像增强改善这些古文字的可读性。", "method": "提出了一种基于二值化和其他预处理技术的方法，以去除污渍并提高模糊文本的清晰度。该方法在石刻、金属板和历史文件上的古代脚本上进行了评估。", "result": "使用K-近邻分类器，在石头、金属板和平文书写的铭文图像中分别达到了55.7%、62%和65.6%的准确性；使用支持向量机分类器，准确率分别为53.2%、59.5%和67.8%。", "conclusion": "实验结果表明所提出的增强方法在提高古代马哈拉施特拉语铭文图像可读性方面有效。"}}
{"id": "2601.04799", "pdf": "https://arxiv.org/pdf/2601.04799", "abs": "https://arxiv.org/abs/2601.04799", "authors": ["Marios Thoma", "Vassilis Vassiliades", "Loizos Michael"], "title": "Neural-Symbolic Integration with Evolvable Policies", "categories": ["cs.LG", "cs.NE"], "comment": "18 pages, 12 figures, related code available at https://github.com/CYENS/evolvable-nesy", "summary": "Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.", "AI": {"tldr": "提出一种框架，允许神经网络和非可微分符号策略的同时学习，通过进化过程解决现有NeSy系统中的限制问题。", "motivation": "现有的NeSy框架依赖于预先定义的符号策略或可微分策略，在缺乏领域专业知识或策略本质上不可微的情况下受限。因此，本文旨在创建一个能够同时训练神经网络权重和非可微分符号策略的框架。", "method": "通过进化过程中的变异（包括符号规则的添加和神经权值的变化），将NeSy系统视为种群中进化的有机体，并用基于适应度的选择引导向隐藏目标策略的收敛。该方法扩展了NEUROLOG架构，使符号策略可训练；采用了Valiant的可演化框架并应用了机器指导语义。", "result": "实验表明，从空策略和随机神经权重开始的NeSy系统能够成功地逼近隐藏的目标非可微分策略，达到接近100%正确的中位性能。", "conclusion": "这项工作代表了一个在领域专业知识难以获取或不可行的情况下推动NeSy研究的重要步骤。"}}
{"id": "2601.04798", "pdf": "https://arxiv.org/pdf/2601.04798", "abs": "https://arxiv.org/abs/2601.04798", "authors": ["Tamara R. Lenhard", "Andreas Weinmann", "Hichem Snoussi", "Tobias Koch"], "title": "Detector-Augmented SAMURAI for Long-Duration Drone Tracking", "categories": ["cs.CV"], "comment": "Accepted at the WACV 2026 Workshop on \"Real World Surveillance: Applications and Challenges\"", "summary": "Robust long-term tracking of drone is a critical requirement for modern surveillance systems, given their increasing threat potential. While detector-based approaches typically achieve strong frame-level accuracy, they often suffer from temporal inconsistencies caused by frequent detection dropouts. Despite its practical relevance, research on RGB-based drone tracking is still limited and largely reliant on conventional motion models. Meanwhile, foundation models like SAMURAI have established their effectiveness across other domains, exhibiting strong category-agnostic tracking performance. However, their applicability in drone-specific scenarios has not been investigated yet. Motivated by this gap, we present the first systematic evaluation of SAMURAI's potential for robust drone tracking in urban surveillance settings. Furthermore, we introduce a detector-augmented extension of SAMURAI to mitigate sensitivity to bounding-box initialization and sequence length. Our findings demonstrate that the proposed extension significantly improves robustness in complex urban environments, with pronounced benefits in long-duration sequences - especially under drone exit-re-entry events. The incorporation of detector cues yields consistent gains over SAMURAI's zero-shot performance across datasets and metrics, with success rate improvements of up to +0.393 and FNR reductions of up to -0.475.", "AI": {"tldr": "本文提出了一种增强的SAMURAI方法，结合检测器来提高无人机在复杂城市环境中的长期跟踪性能。", "motivation": "当前基于检测器的方法存在时间不一致问题，且针对无人机长时跟踪的研究不足。同时，通用模型SAMURAI尚未被应用于无人机场景中。", "method": "引入了增强的SAMURAI方法，并结合检测器来改善边界框初始化敏感性和序列长度带来的影响。", "result": "该方法在复杂城市环境中显著提升了长期跟踪的鲁棒性，特别是在长时间序列和无人机重新出现事件中的性能有所提升。", "conclusion": "通过将检测信息融入到SAMURAI中，可以提高其对不同数据集和指标的一致性和准确性。"}}
{"id": "2601.04795", "pdf": "https://arxiv.org/pdf/2601.04795", "abs": "https://arxiv.org/abs/2601.04795", "authors": ["Qiang Yu", "Xinran Cheng", "Chuanyi Liu"], "title": "Defense Against Indirect Prompt Injection via Tool Result Parsing", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.MA"], "comment": "20 pages, 3 figures, 5 tables", "summary": "As LLM agents transition from digital assistants to physical controllers in autonomous systems and robotics, they face an escalating threat from indirect prompt injection. By embedding adversarial instructions into the results of tool calls, attackers can hijack the agent's decision-making process to execute unauthorized actions. This vulnerability poses a significant risk as agents gain more direct control over physical environments. Existing defense mechanisms against Indirect Prompt Injection (IPI) generally fall into two categories. The first involves training dedicated detection models; however, this approach entails high computational overhead for both training and inference, and requires frequent updates to keep pace with evolving attack vectors. Alternatively, prompt-based methods leverage the inherent capabilities of LLMs to detect or ignore malicious instructions via prompt engineering. Despite their flexibility, most current prompt-based defenses suffer from high Attack Success Rates (ASR), demonstrating limited robustness against sophisticated injection attacks. In this paper, we propose a novel method that provides LLMs with precise data via tool result parsing while effectively filtering out injected malicious code. Our approach achieves competitive Utility under Attack (UA) while maintaining the lowest Attack Success Rate (ASR) to date, significantly outperforming existing methods. Code is available at GitHub.", "AI": {"tldr": "本文提出了一种通过工具结果解析为LLM提供精确数据的同时有效过滤恶意代码的方法，以防御间接提示注入攻击。", "motivation": "随着LLM代理从数字助手转变为物理控制系统的控制器，在自主系统和机器人技术中面临的间接提示注入威胁日益严重。现有的防御机制要么计算开销高，要么对复杂攻击的有效性较差。", "method": "本文提出了一种通过解析工具结果提供精确数据并过滤掉恶意代码的方法，提高了LLM在面对间接提示注入攻击时的鲁棒性和实用性。", "result": "该方法实现了与现有技术相比最高的实用性下最低的攻击成功率，证明了其优越性。", "conclusion": "新的防御机制显著降低了间接提示注入的成功率，并且具有较高的实用性，在未来的工作中将继续优化此方案。"}}
{"id": "2601.04794", "pdf": "https://arxiv.org/pdf/2601.04794", "abs": "https://arxiv.org/abs/2601.04794", "authors": ["Chengxin Shi", "Qinnan Cai", "Zeyuan Chen", "Long Zeng", "Yibo Zhao", "Jing Yu", "Jianxiang Yu", "Xiang Li"], "title": "APEX: Academic Poster Editing Agentic Expert", "categories": ["cs.AI"], "comment": null, "summary": "Designing academic posters is a labor-intensive process requiring the precise balance of high-density content and sophisticated layout. While existing paper-to-poster generation methods automate initial drafting, they are typically single-pass and non-interactive, often fail to align with complex, subjective user intent. To bridge this gap, we propose APEX (Academic Poster Editing agentic eXpert), the first agentic framework for interactive academic poster editing, supporting fine-grained control with robust multi-level API-based editing and a review-and-adjustment Mechanism. In addition, we introduce APEX-Bench, the first systematic benchmark comprising 514 academic poster editing instructions, categorized by a multi-dimensional taxonomy including operation type, difficulty, and abstraction level, constructed via reference-guided and reference-free strategies to ensure realism and diversity. We further establish a multi-dimensional VLM-as-a-judge evaluation protocol to assess instruction fulfillment, modification scope, and visual consistency & harmony. Experimental results demonstrate that APEX significantly outperforms baseline methods. Our implementation is available at https://github.com/Breesiu/APEX.", "AI": {"tldr": "APEX是一个用于学术海报编辑的代理框架，支持精细化控制和多级别的API编辑，通过一个审查和调整机制提高用户体验。", "motivation": "现有的论文转海报生成方法通常只进行一次性的自动化处理并且缺乏交互性，无法满足复杂的主观用户意图。为了填补这一空白，提出了APEX系统来改进学术海报的编辑过程。", "method": "介绍了APEX框架的设计思路，该框架通过多级别的API编辑支持精细控制，并且提供了一个审查和调整机制以适应用户的反馈。此外还引入了APEX-Bench基准测试，包含514个编辑指令，并采用了多维评估协议来评测成果的完成度、修改范围及视觉和谐。", "result": "实验结果表明，与基线方法相比，APEX在学术海报编辑任务上表现出色。", "conclusion": "研究表明，通过引入互动性的代理框架和严格的基准测试，可以显著提升学术海报的设计质量。"}}
{"id": "2601.04792", "pdf": "https://arxiv.org/pdf/2601.04792", "abs": "https://arxiv.org/abs/2601.04792", "authors": ["Denis Korzhenkov", "Adil Karjauv", "Animesh Karnewar", "Mohsen Ghafoorian", "Amirhossein Habibian"], "title": "PyramidalWan: On Making Pretrained Video Model Pyramidal for Efficient Inference", "categories": ["cs.CV"], "comment": null, "summary": "Recently proposed pyramidal models decompose the conventional forward and backward diffusion processes into multiple stages operating at varying resolutions. These models handle inputs with higher noise levels at lower resolutions, while less noisy inputs are processed at higher resolutions. This hierarchical approach significantly reduces the computational cost of inference in multi-step denoising models. However, existing open-source pyramidal video models have been trained from scratch and tend to underperform compared to state-of-the-art systems in terms of visual plausibility. In this work, we present a pipeline that converts a pretrained diffusion model into a pyramidal one through low-cost finetuning, achieving this transformation without degradation in quality of output videos. Furthermore, we investigate and compare various strategies for step distillation within pyramidal models, aiming to further enhance the inference efficiency. Our results are available at https://qualcomm-ai-research.github.io/PyramidalWan.", "AI": {"tldr": "论文提出了一种将预训练的扩散模型转化为分层视频模型的方法，通过低成本微调提高视频推理效率。", "motivation": "现有的金字塔型视频模型在视觉可信度方面表现不佳。该研究旨在通过低成本微调来改善这一状况，并进一步探讨不同步骤提炼策略以增强推断效率。", "method": "提出了一种将预训练的扩散模型转化为金字塔结构的方法，通过低成本微调实现性能优化。", "result": "实验结果表明，这种方法在不降低输出视频质量的情况下提高了推理效率。", "conclusion": "该方法成功地将预训练模型转换为高效的金字塔型结构，证明了其有效性和实用性。"}}
{"id": "2601.04791", "pdf": "https://arxiv.org/pdf/2601.04791", "abs": "https://arxiv.org/abs/2601.04791", "authors": ["Lee Hyoseok", "Sohwi Lim", "Eunju Cha", "Tae-Hyun Oh"], "title": "Measurement-Consistent Langevin Corrector: A Remedy for Latent Diffusion Inverse Solvers", "categories": ["cs.CV", "cs.LG"], "comment": "Under Review", "summary": "With recent advances in generative models, diffusion models have emerged as powerful priors for solving inverse problems in each domain. Since Latent Diffusion Models (LDMs) provide generic priors, several studies have explored their potential as domain-agnostic zero-shot inverse solvers. Despite these efforts, existing latent diffusion inverse solvers suffer from their instability, exhibiting undesirable artifacts and degraded quality. In this work, we first identify the instability as a discrepancy between the solver's and true reverse diffusion dynamics, and show that reducing this gap stabilizes the solver. Building on this, we introduce Measurement-Consistent Langevin Corrector (MCLC), a theoretically grounded plug-and-play correction module that remedies the LDM-based inverse solvers through measurement-consistent Langevin updates. Compared to prior approaches that rely on linear manifold assumptions, which often do not hold in latent space, MCLC operates without this assumption, leading to more stable and reliable behavior. We experimentally demonstrate the effectiveness of MCLC and its compatibility with existing solvers across diverse image restoration tasks. Additionally, we analyze blob artifacts and offer insights into their underlying causes. We highlight that MCLC is a key step toward more robust zero-shot inverse problem solvers.", "AI": {"tldr": "提出了一种基于测量一致的兰格VIN校正器（MCLC）来改善逆问题求解中的稳定性。", "motivation": "现有基于潜在扩散模型的逆向求解器存在不稳定性，导致质量下降和伪影出现。为了提高其性能，需要一种更稳定的方法。", "method": "通过引入测量一致兰格VIN校正（MCLC），该方法在没有线性流形假设的基础上进行测量一致的兰格VIN更新，以改进现有逆向求解器。", "result": "实验结果表明，MCLC能够有效提升图像恢复任务中的稳定性和可靠性，并分析了伪影产生的原因。", "conclusion": "MCLC为零样本逆问题提供了更稳健的方法，是解决逆向求解不稳定性的关键步骤。"}}
{"id": "2601.04790", "pdf": "https://arxiv.org/pdf/2601.04790", "abs": "https://arxiv.org/abs/2601.04790", "authors": ["Junhyuk Choi", "Jeongyoun Kwon", "Heeju Kim", "Haeun Cho", "Hayeong Jung", "Sehee Min", "Bugeun Kim"], "title": "Belief in Authority: Impact of Authority in Multi-Agent Evaluation Framework", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Multi-agent systems utilizing large language models often assign authoritative roles to improve performance, yet the impact of authority bias on agent interactions remains underexplored. We present the first systematic analysis of role-based authority bias in free-form multi-agent evaluation using ChatEval. Applying French and Raven's power-based theory, we classify authoritative roles into legitimate, referent, and expert types and analyze their influence across 12-turn conversations. Experiments with GPT-4o and DeepSeek R1 reveal that Expert and Referent power roles exert stronger influence than Legitimate power roles. Crucially, authority bias emerges not through active conformity by general agents, but through authoritative roles consistently maintaining their positions while general agents demonstrate flexibility. Furthermore, authority influence requires clear position statements, as neutral responses fail to generate bias. These findings provide key insights for designing multi-agent frameworks with asymmetric interaction patterns.", "AI": {"tldr": "该论文分析了多代理系统中权威角色对交互的影响。", "motivation": "探讨大型语言模型在多代理系统中的权威影响，以及这种偏见如何影响代理间的交流。", "method": "使用ChatEval框架评估不同权威类型（合法、参照和专家）在12轮对话中对代理人行为的影响。实验对象为GPT-4o和DeepSeek R1模型。", "result": "专家和参照权威角色比合法权威角色影响更大，这种偏见主要体现在权威角色维持其立场而一般代理表现出灵活性上；明确的立场声明是产生权威偏见的关键。", "conclusion": "研究结果为设计具有不对称互动模式的多代理框架提供了关键见解。"}}
{"id": "2601.04789", "pdf": "https://arxiv.org/pdf/2601.04789", "abs": "https://arxiv.org/abs/2601.04789", "authors": ["Xinyue Peng", "Yanming Liu", "Yihan Cang", "Yuwei Zhang", "Xinyi Wang", "Songhang Deng", "Jiannan Cao"], "title": "NC2C: Automated Convexification of Generic Non-Convex Optimization Problems", "categories": ["cs.CL", "cs.AI"], "comment": "First version of NC2C", "summary": "Non-convex optimization problems are pervasive across mathematical programming, engineering design, and scientific computing, often posing intractable challenges for traditional solvers due to their complex objective functions and constrained landscapes. To address the inefficiency of manual convexification and the over-reliance on expert knowledge, we propose NC2C, an LLM-based end-to-end automated framework designed to transform generic non-convex optimization problems into solvable convex forms using large language models. NC2C leverages LLMs' mathematical reasoning capabilities to autonomously detect non-convex components, select optimal convexification strategies, and generate rigorous convex equivalents. The framework integrates symbolic reasoning, adaptive transformation techniques, and iterative validation, equipped with error correction loops and feasibility domain correction mechanisms to ensure the robustness and validity of transformed problems. Experimental results on a diverse dataset of 100 generic non-convex problems demonstrate that NC2C achieves an 89.3\\% execution rate and a 76\\% success rate in producing feasible, high-quality convex transformations. This outperforms baseline methods by a significant margin, highlighting NC2C's ability to leverage LLMs for automated non-convex to convex transformation, reduce expert dependency, and enable efficient deployment of convex solvers for previously intractable optimization tasks.", "AI": {"tldr": "提出NC2C框架，使用大型语言模型自动将非凸优化问题转化为可解的凸形式。", "motivation": "解决传统求解器处理复杂目标函数和约束条件时面临的挑战，并减少人工手动转化对专家知识的高度依赖。", "method": "利用LLM的数学推理能力识别非凸成分，选择最佳凸化策略并生成严密的凸等价物。框架包括符号推理、自适应转换技术、迭代验证以及错误校正循环和可行性领域修正机制以确保转化后的问题具有鲁棒性和有效性。", "result": "在100个通用非凸优化问题的数据集上实验结果表明，NC2C实现了89.3%的执行率和76%的成功率，显著优于基线方法。", "conclusion": "展示了LLM用于自动非凸到凸转化的能力，减少了专家依赖，并为难以处理的优化任务提供了高效的凸求解器部署方案。"}}
{"id": "2601.04786", "pdf": "https://arxiv.org/pdf/2601.04786", "abs": "https://arxiv.org/abs/2601.04786", "authors": ["Lang Feng", "Fuchao Yang", "Feng Chen", "Xin Cheng", "Haiyang Xu", "Zhenglin Wan", "Ming Yan", "Bo An"], "title": "AgentOCR: Reimagining Agent History via Optical Self-Compression", "categories": ["cs.LG", "cs.AI"], "comment": "Work in progress", "summary": "Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\\% of text-based agent performance while substantially reducing token consumption (>50\\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.", "AI": {"tldr": "提出AgentOCR框架，通过将累积的观察动作历史表示为紧凑的渲染图像来解决大语言模型在多轮互动中的文本历史增长问题。", "motivation": "大规模语言模型和强化学习训练的代理系统面临迅速增长的文本历史所带来的挑战，这会增加令牌预算和内存使用量。为了实现高效部署，需要找到一种方法来压缩这些历史记录而不牺牲任务性能。", "method": "AgentOCR框架通过将观察动作历史转化为视觉图像来减少文本体积，并引入分段光学缓存以避免重复渲染。此外，它还提出了代理自我压缩机制，允许代理人主动设定压缩率并在训练过程中考虑压缩效果来平衡任务成功与令牌效率。", "result": "实验表明，AgentOCR能够在降低超过50%的令牌消耗的同时保持95%以上的基于文本的代理性能，并通过分段光学缓存实现了约20倍的渲染速度提升。", "conclusion": "AgentOCR框架展示了如何有效地压缩多轮互动历史以减少资源使用量并提高系统效率，同时保持高质量的任务表现。"}}
{"id": "2601.04785", "pdf": "https://arxiv.org/pdf/2601.04785", "abs": "https://arxiv.org/abs/2601.04785", "authors": ["Xihe Qiu", "Yang Dai", "Xiaoyu Tan", "Sijia Li", "Fenghao Sun", "Lu Gan", "Liang Liu"], "title": "SRU-Pix2Pix: A Fusion-Driven Generator Network for Medical Image Translation with Few-Shot Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Magnetic Resonance Imaging (MRI) provides detailed tissue information, but its clinical application is limited by long acquisition time, high cost, and restricted resolution. Image translation has recently gained attention as a strategy to address these limitations. Although Pix2Pix has been widely applied in medical image translation, its potential has not been fully explored. In this study, we propose an enhanced Pix2Pix framework that integrates Squeeze-and-Excitation Residual Networks (SEResNet) and U-Net++ to improve image generation quality and structural fidelity. SEResNet strengthens critical feature representation through channel attention, while U-Net++ enhances multi-scale feature fusion. A simplified PatchGAN discriminator further stabilizes training and refines local anatomical realism. Experimental results demonstrate that under few-shot conditions with fewer than 500 images, the proposed method achieves consistent structural fidelity and superior image quality across multiple intra-modality MRI translation tasks, showing strong generalization ability. These results suggest an effective extension of Pix2Pix for medical image translation.", "AI": {"tldr": "本文提出了一种改进的Pix2Pix框架，结合了SEResNet和U-Net++以提高医疗图像翻译的质量。", "motivation": "MRI因获取时间长、成本高及分辨率受限而临床应用有限。现有方法如Pix2Pix虽用于医疗图像翻译但潜力未充分发掘。", "method": "作者设计了一种融合驱动的生成网络SRU-Pix2Pix，结合SEResNet和U-Net++提升关键特征表示并增强多尺度特性融合。简化版PatchGAN鉴别器稳定训练并优化局部解剖真实感。", "result": "实验结果显示，在少样本条件下使用500张图像以内，该方法在多种MRI内部模态翻译任务中保持了结构一致性与优质成像效果，展示了强大的泛化能力。", "conclusion": "所提方法有效扩展了Pix2Pix框架用于医疗图像翻译的应用范围。"}}
{"id": "2601.04781", "pdf": "https://arxiv.org/pdf/2601.04781", "abs": "https://arxiv.org/abs/2601.04781", "authors": ["Sophie Villenave", "Pierre Raimbaud", "Guillaume Lavoué"], "title": "Dynamic Thermal Feedback in Highly Immersive VR Scenarios: a Multimodal Analysis of User Experience", "categories": ["cs.HC"], "comment": "15 pages, 9 figures. This work has been submitted to the IEEE for possible publication", "summary": "Thermal feedback is critical to a range of Virtual Reality (VR) applications, such as firefighting training or thermal comfort simulation. Previous studies showed that adding congruent thermal feedback positively influences User eXperience (UX). However, existing work did not compare different levels of thermal feedback quality and mostly used less immersive virtual environments. To investigate these gaps in the scientific literature, we conducted a within-participant user study in two highly-immersive scenarios, Desert Island (n=25) and Snowy Mountains (n=24). Participants explored the scenarios in three conditions (Audio-Visual only, Static-Thermal Feedback, and Dynamic-Thermal Feedback). To assess the complex and subtle effects of thermal feedback on UX, we performed a multimodal analysis by crossing data from questionnaires, semi-structured interviews, and behavioral indicators. Our results show that despite an already high level of presence in the Audio-Visual only condition, adding thermal feedback increased presence further. Comparison between levels of thermal feedback quality showed no significant difference in UX questionnaires, however this result is nuanced according to participant profiles and interviews. Furthermore, we show that although the order of passage did not influence UX directly, it influenced user behavior. We propose guidelines for the use of thermal feedback in VR, and the design of studies in complex multisensory scenarios.", "AI": {"tldr": "研究探讨了不同热反馈质量对高度沉浸式虚拟现实用户体验的影响", "motivation": "现有研究缺乏对比不同水平的热反馈质量，并且主要使用低沉浸度的虚拟环境。本研究填补了这些空白，探索了热反馈在提高用户沉浸感和体验方面的效果", "method": "通过两个高沉浸度场景进行参与者内实验，包括音频视觉条件、静态热反馈和动态热反馈三个条件，采用问卷调查、半结构化访谈和行为指标交叉分析的方法来评估热反馈对用户体验的影响", "result": "结果显示，在音视频条件下已具有高度的沉浸感时，添加热反馈进一步增加了沉浸感。不同水平的热反馈质量在问卷上没有显著差异，但根据用户类型和访谈有细微差别。通过顺序的不同影响了用户行为，但未直接影响到用户体验", "conclusion": "提出了虚拟现实中使用热反馈的设计指南，并建议今后研究应关注复杂的多感官场景"}}
{"id": "2601.04779", "pdf": "https://arxiv.org/pdf/2601.04779", "abs": "https://arxiv.org/abs/2601.04779", "authors": ["Akbar Saadat"], "title": "Defocus Aberration Theory Confirms Gaussian Model in Most Imaging Devices", "categories": ["cs.CV"], "comment": "13 pages, 9 figures, 11 .jpg files", "summary": "Over the past three decades, defocus has consistently provided groundbreaking depth information in scene images. However, accurately estimating depth from 2D images continues to be a persistent and fundamental challenge in the field of 3D recovery. Heuristic approaches involve with the ill-posed problem for inferring the spatial variant defocusing blur, as the desired blur cannot be distinguished from the inherent blur. Given a prior knowledge of the defocus model, the problem become well-posed with an analytic solution for the relative blur between two images, taken at the same viewpoint with different camera settings for the focus. The Gaussian model stands out as an optimal choice for real-time applications, due to its mathematical simplicity and computational efficiency. And theoretically, it is the only model can be applied at the same time to both the absolute blur caused by depth in a single image and the relative blur resulting from depth differences between two images. This paper introduces the settings, for conventional imaging devices, to ensure that the defocusing operator adheres to the Gaussian model. Defocus analysis begins within the framework of geometric optics and is conducted by defocus aberration theory in diffraction-limited optics to obtain the accuracy of fitting the actual model to its Gaussian approximation. The results for a typical set of focused depths between $1$ and $100$ meters, with a maximum depth variation of $10\\%$ at the focused depth, confirm the Gaussian model's applicability for defocus operators in most imaging devices. The findings demonstrate a maximum Mean Absolute Error $(\\!M\\!A\\!E)$ of less than $1\\%$, underscoring the model's accuracy and reliability.", "AI": {"tldr": "本文通过几何光学和衍射极限光学的散焦理论，验证了大多数成像设备中的散焦操作符符合高斯模型。", "motivation": "深度估计是三维恢复的基本挑战。使用先验知识可以将散焦模糊问题转化为可解析的问题，并且高斯模型因其数学简单性和计算效率成为实时应用的理想选择。", "method": "本文通过几何光学框架和衍射极限下的散焦像差理论，分析了成像设备中散焦操作符的高斯模型适用性。研究发现，在特定聚焦深度范围内（1至100米），最大深度变化为10%，实际模型与高斯近似的拟合精度很高。", "result": "实验结果显示，对于不同聚焦深度范围内的图像，使用高斯模型估计散焦模糊的最大绝对误差小于1%，说明该模型在大多数成像设备中的适用性。", "conclusion": "研究验证了高斯模型作为描述大多数成像设备中由深度引起的绝对模糊和因深度差异导致的相对模糊的有效性和准确性。"}}
{"id": "2601.04778", "pdf": "https://arxiv.org/pdf/2601.04778", "abs": "https://arxiv.org/abs/2601.04778", "authors": ["Tobia Poppi", "Burak Uzkent", "Amanmeet Garg", "Lucas Porto", "Garin Kessler", "Yezhou Yang", "Marcella Cornia", "Lorenzo Baraldi", "Rita Cucchiara", "Florian Schiffers"], "title": "CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": null, "summary": "Video-language models (VLMs) achieve strong multimodal understanding but remain prone to hallucinations, especially when reasoning about actions and temporal order. Existing mitigation strategies, such as textual filtering or random video perturbations, often fail to address the root cause: over-reliance on language priors rather than fine-grained visual dynamics. We propose a scalable framework for counterfactual video generation that synthesizes videos differing only in actions or temporal structure while preserving scene context. Our pipeline combines multimodal LLMs for action proposal and editing guidance with diffusion-based image and video models to generate semantic hard negatives at scale. Using this framework, we build CounterVid, a synthetic dataset of ~26k preference pairs targeting action recognition and temporal reasoning. We further introduce MixDPO, a unified Direct Preference Optimization approach that jointly leverages textual and visual preferences. Fine-tuning Qwen2.5-VL with MixDPO yields consistent improvements, notably in temporal ordering, and transfers effectively to standard video hallucination benchmarks. Code and models will be made publicly available.", "AI": {"tldr": "本文提出了一种通过生成反事实视频来缓解视觉语言模型中的动作和时间错觉问题的框架。", "motivation": "现有的缓解策略通常无法解决根本原因，即过度依赖于语言先验而不是细粒度的视觉动态。因此，提出了合成反事实视频的方法以更好地理解动作和时间顺序。", "method": "该方法结合了多模态LLM用于动作提案和编辑指导，并使用扩散基图像及视频模型生成语义硬负例。基于此框架构建了CounterVid数据集，并引入MixDPO优化策略提升模型性能。", "result": "利用提出的框架，模型在时间排序任务上取得了显著改进，并有效地应用于标准的视频错觉基准测试中。", "conclusion": "提出的方法可以有效缓解视觉语言模型中的动作和时间错觉问题，并且可以在大规模数据集上进行有效的训练和优化。"}}
{"id": "2601.04777", "pdf": "https://arxiv.org/pdf/2601.04777", "abs": "https://arxiv.org/abs/2601.04777", "authors": ["Shurong Zheng", "Yousong Zhu", "Hongyin Zhao", "Fan Yang", "Yufei Zhan", "Ming Tang", "Jinqiao Wang"], "title": "GeM-VG: Towards Generalized Multi-image Visual Grounding with Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive progress in single-image grounding and general multi-image understanding. Recently, some methods begin to address multi-image grounding. However, they are constrained by single-target localization and limited types of practical tasks, due to the lack of unified modeling for generalized grounding tasks. Therefore, we propose GeM-VG, an MLLM capable of Generalized Multi-image Visual Grounding. To support this, we systematically categorize and organize existing multi-image grounding tasks according to their reliance of cross-image cues and reasoning, and introduce the MG-Data-240K dataset, addressing the limitations of existing datasets regarding target quantity and image relation. To tackle the challenges of robustly handling diverse multi-image grounding tasks, we further propose a hybrid reinforcement finetuning strategy that integrates chain-of-thought (CoT) reasoning and direct answering, considering their complementary strengths. This strategy adopts an R1-like algorithm guided by a carefully designed rule-based reward, effectively enhancing the model's overall perception and reasoning capabilities. Extensive experiments demonstrate the superior generalized grounding capabilities of our model. For multi-image grounding, it outperforms the previous leading MLLMs by 2.0% and 9.7% on MIG-Bench and MC-Bench, respectively. In single-image grounding, it achieves a 9.1% improvement over the base model on ODINW. Furthermore, our model retains strong capabilities in general multi-image understanding.", "AI": {"tldr": "提出了一种通用的多图像视觉定位模型GeM-VG，旨在解决现有方法在单目标定位和任务类型上的局限性。", "motivation": "当前的方法虽然在单一图像接地和一般的多图像理解方面取得了一些进展，但在处理多样化的多图像接地任务时存在限制。这些方法依赖于单一的目标定位且受限于有限类型的实用任务。", "method": "该研究提出了GeM-VG模型，引入了MG-Data-240K数据集以解决现有数据集在目标数量和图像关系方面的不足，并提出了一种结合链式思考推理和直接回答的混合强化微调策略，采用R1算法进行指导。", "result": "实验结果表明，该模型在多图像接地任务上比之前的领先MLLMs分别提高了2.0%和9.7%，单图像接地任务上较基准模型提升了9.1%，并保留了强大的一般性多图像理解能力。", "conclusion": "GeM-VG通过引入新的数据集和微调策略，显著改善了在多样化的多图像接地和单图像接地任务上的表现。"}}
{"id": "2601.04776", "pdf": "https://arxiv.org/pdf/2601.04776", "abs": "https://arxiv.org/abs/2601.04776", "authors": ["Jinyu Zhang", "Xu Ma", "Weili Chen", "Gonzalo R. Arce"], "title": "Segmentation-Driven Monocular Shape from Polarization based on Physical Model", "categories": ["cs.CV"], "comment": "11 pages, 10 figures, submittd to IEEE Transactions on Image Processing", "summary": "Monocular shape-from-polarization (SfP) leverages the intrinsic relationship between light polarization properties and surface geometry to recover surface normals from single-view polarized images, providing a compact and robust approach for three-dimensional (3D) reconstruction. Despite its potential, existing monocular SfP methods suffer from azimuth angle ambiguity, an inherent limitation of polarization analysis, that severely compromises reconstruction accuracy and stability. This paper introduces a novel segmentation-driven monocular SfP (SMSfP) framework that reformulates global shape recovery into a set of local reconstructions over adaptively segmented convex sub-regions. Specifically, a polarization-aided adaptive region growing (PARG) segmentation strategy is proposed to decompose the global convexity assumption into locally convex regions, effectively suppressing azimuth ambiguities and preserving surface continuity. Furthermore, a multi-scale fusion convexity prior (MFCP) constraint is developed to ensure local surface consistency and enhance the recovery of fine textural and structural details. Extensive experiments on both synthetic and real-world datasets validate the proposed approach, showing significant improvements in disambiguation accuracy and geometric fidelity compared with existing physics-based monocular SfP techniques.", "AI": {"tldr": "提出了一种基于物理模型的单目形状从偏振分割驱动的方法，通过局部重构提高三维重建精度和稳定性。", "motivation": "现有的单目形状从偏振方法因方位角模糊性影响了重建精度和稳定性，论文旨在解决这一问题以提升3D重建效果。", "method": "提出一种分割驱动单目形状从偏振框架，利用适应性区域增长策略分解全局凸性假设为局部凸性，并开发多尺度融合凸性先验约束确保表面一致性。", "result": "实验显示该方法在歧义消除准确性和几何保真度上优于现有的物理模型单目形状从偏振技术。", "conclusion": "本文提出的方法显著改进了单目形状从偏振的精度和稳定性，特别是在处理细纹理结构方面表现突出。"}}
{"id": "2601.04770", "pdf": "https://arxiv.org/pdf/2601.04770", "abs": "https://arxiv.org/abs/2601.04770", "authors": ["Encheng Su", "Jianyu Wu", "Chen Tang", "Lintao Wang", "Pengze Li", "Aoran Wang", "Jinouwen Zhang", "Yizhou Wang", "Yuan Meng", "Xinzhu Ma", "Shixiang Tang", "Houqiang Li"], "title": "SciIF: Benchmarking Scientific Instruction Following Towards Rigorous Scientific Intelligence", "categories": ["cs.AI", "cs.DB"], "comment": null, "summary": "As large language models (LLMs) transition from general knowledge retrieval to complex scientific discovery, their evaluation standards must also incorporate the rigorous norms of scientific inquiry. Existing benchmarks exhibit a critical blind spot: general instruction-following metrics focus on superficial formatting, while domain-specific scientific benchmarks assess only final-answer correctness, often rewarding models that arrive at the right result with the wrong reasons. To address this gap, we introduce scientific instruction following: the capability to solve problems while strictly adhering to the constraints that establish scientific validity. Specifically, we introduce SciIF, a multi-discipline benchmark that evaluates this capability by pairing university-level problems with a fixed catalog of constraints across three pillars: scientific conditions (e.g., boundary checks and assumptions), semantic stability (e.g., unit and symbol conventions), and specific processes(e.g., required numerical methods). Uniquely, SciIF emphasizes auditability, requiring models to provide explicit evidence of constraint satisfaction rather than implicit compliance. By measuring both solution correctness and multi-constraint adherence, SciIF enables finegrained diagnosis of compositional reasoning failures, ensuring that LLMs can function as reliable agents within the strict logical frameworks of science.", "AI": {"tldr": "论文介绍了SciIF基准，旨在评估大型语言模型在解决科学问题时严格遵循科学规范的能力。", "motivation": "现有评价标准仅关注答案正确性或表面格式，忽视了对模型是否具备严谨科学研究能力的评测。因此需要引入新的评价方法来衡量LLM是否能够严格按照科研准则解决问题。", "method": "SciIF基准通过提供大学水平的多学科科学问题，并设定一系列涵盖边界检查、单位和符号约定以及特定数值计算过程等约束条件，要求模型不仅给出正确答案还必须展示满足这些约束的具体证据。", "result": "该方法能够细致地诊断组合推理错误，从而确保LLM在科学研究中作为可靠代理的逻辑严谨性。", "conclusion": "SciIF基准为评估大型语言模型解决复杂科学问题的能力提供了一个新的视角，并强调了模型必须展示出对所有约束条件的具体满足情况。"}}
{"id": "2601.04767", "pdf": "https://arxiv.org/pdf/2601.04767", "abs": "https://arxiv.org/abs/2601.04767", "authors": ["Zefang Zong", "Dingwei Chen", "Yang Li", "Qi Yi", "Bo Zhou", "Chengming Li", "Bo Qian", "Peng Chen", "Jie Jiang"], "title": "AT$^2$PO: Agentic Turn-based Policy Optimization via Tree Search", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "LLM agents have emerged as powerful systems for tackling multi-turn tasks by interleaving internal reasoning and external tool interactions. Agentic Reinforcement Learning has recently drawn significant research attention as a critical post-training paradigm to further refine these capabilities. In this paper, we present AT$^2$PO (Agentic Turn-based Policy Optimization via Tree Search), a unified framework for multi-turn agentic RL that addresses three core challenges: limited exploration diversity, sparse credit assignment, and misaligned policy optimization. AT$^2$PO introduces a turn-level tree structure that jointly enables Entropy-Guided Tree Expansion for strategic exploration and Turn-wise Credit Assignment for fine-grained reward propagation from sparse outcomes. Complementing this, we propose Agentic Turn-based Policy Optimization, a turn-level learning objective that aligns policy updates with the natural decision granularity of agentic interactions. ATPO is orthogonal to tree search and can be readily integrated into any multi-turn RL pipeline. Experiments across seven benchmarks demonstrate consistent improvements over the state-of-the-art baseline by up to 1.84 percentage points in average, with ablation studies validating the effectiveness of each component. Our code is available at https://github.com/zzfoutofspace/ATPO.", "AI": {"tldr": "AT$^2$PO是一种通过树搜索优化多回合代理强化学习的新框架，解决了探索多样性不足、稀疏奖励分配和策略优化不一致等问题。", "motivation": "随着大型语言模型在处理多轮任务中的应用增强，需要一种方法来进一步提升其能力。当前的挑战包括有限的探索多样性和稀疏的信用分配问题。", "method": "AT$^2$PO提出了一个回合级别的树状结构，结合熵引导的树扩展以促进战略探索，并通过每回合信用分配从稀疏结果中传播奖励。此外，还提出了一种代理回合策略优化方法，该方法与树搜索正交且易于集成。", "result": "在七个基准测试上，AT$^2$PO相对于最先进的基线模型表现出一致的改进，平均提高了1.84个百分点。", "conclusion": "通过引入新的框架和方法，AT$^2$PO显著提升了多回合代理强化学习的表现。"}}
{"id": "2601.04765", "pdf": "https://arxiv.org/pdf/2601.04765", "abs": "https://arxiv.org/abs/2601.04765", "authors": ["Santiago Acevedo", "Alessandro Laio", "Marco Baroni"], "title": "Differential syntactic and semantic encoding in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.", "AI": {"tldr": "研究大型语言模型中句法和语义信息的编码方式", "motivation": "探究大型语言模型内部层表示中句法和语义信息如何被编码，以理解其工作原理", "method": "通过平均具有相同句法结构或意义句子的隐藏状态向量来捕获句法和语义信息，并分析去除这些句法和语义‘中心点’后对句子相似性的影响", "result": "发现句法和语义在一定程度上是线性编码的，且不同层中它们的信息编码方式有差异", "conclusion": "大型语言模型内部表示中存在不同的句法和语义编码机制"}}
{"id": "2601.04764", "pdf": "https://arxiv.org/pdf/2601.04764", "abs": "https://arxiv.org/abs/2601.04764", "authors": ["Zhen Chen", "Weihao Xie", "Peilin Chen", "Shiqi Wang", "Jianping Wang"], "title": "Orion-RAG: Path-Aligned Hybrid Retrieval for Graphless Data", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has proven effective for knowledge synthesis, yet it encounters significant challenges in practical scenarios where data is inherently discrete and fragmented. In most environments, information is distributed across isolated files like reports and logs that lack explicit links. Standard search engines process files independently, ignoring the connections between them. Furthermore, manually building Knowledge Graphs is impractical for such vast data. To bridge this gap, we present Orion-RAG. Our core insight is simple yet effective: we do not need heavy algorithms to organize this data. Instead, we use a low-complexity strategy to extract lightweight paths that naturally link related concepts. We demonstrate that this streamlined approach suffices to transform fragmented documents into semi-structured data, enabling the system to link information across different files effectively. Extensive experiments demonstrate that Orion-RAG consistently outperforms mainstream frameworks across diverse domains, supporting real-time updates and explicit Human-in-the-Loop verification with high cost-efficiency. Experiments on FinanceBench demonstrate superior precision with a 25.2% relative improvement over strong baselines.", "AI": {"tldr": "提出了一种轻量级路径提取策略，将碎片化文档转换为半结构化数据，提高信息链接效率。", "motivation": "现有知识合成方法在处理分散且无关联的数据文件时面临挑战。标准搜索引擎独立处理文件，忽略它们之间的连接关系；手动构建知识图谱对于大量数据不切实际。", "method": "通过提取轻量级路径来自然地联结相关概念，并将碎片化文档转化为半结构化数据。", "result": "实验证明Orion-RAG在不同领域中均优于主流框架，并支持实时更新和人类循环验证，成本效益高。", "conclusion": "该方法有效地解决了在非链接数据中的信息合成问题。"}}
{"id": "2601.04761", "pdf": "https://arxiv.org/pdf/2601.04761", "abs": "https://arxiv.org/abs/2601.04761", "authors": ["Rupsa Rani Mishra", "D. Chandrasekhar Rao", "Ajaya Kumar Tripathy"], "title": "Smart IoT-Based Wearable Device for Detection and Monitoring of Common Cow Diseases Using a Novel Machine Learning Technique", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Manual observation and monitoring of individual cows for disease detection present significant challenges in large-scale farming operations, as the process is labor-intensive, time-consuming, and prone to reduced accuracy. The reliance on human observation often leads to delays in identifying symptoms, as the sheer number of animals can hinder timely attention to each cow. Consequently, the accuracy and precision of disease detection are significantly compromised, potentially affecting animal health and overall farm productivity. Furthermore, organizing and managing human resources for the manual observation and monitoring of cow health is a complex and economically demanding task. It necessitates the involvement of skilled personnel, thereby contributing to elevated farm maintenance costs and operational inefficiencies. Therefore, the development of an automated, low-cost, and reliable smart system is essential to address these challenges effectively. Although several studies have been conducted in this domain, very few have simultaneously considered the detection of multiple common diseases with high prediction accuracy. However, advancements in Internet of Things (IoT), Machine Learning (ML), and Cyber-Physical Systems have enabled the automation of cow health monitoring with enhanced accuracy and reduced operational costs. This study proposes an IoT-enabled Cyber-Physical System framework designed to monitor the daily activities and health status of cow. A novel ML algorithm is proposed for the diagnosis of common cow diseases using collected physiological and behavioral data. The algorithm is designed to predict multiple diseases by analyzing a comprehensive set of recorded physiological and behavioral features, enabling accurate and efficient health assessment.", "AI": {"tldr": "该论文提出了一种基于物联网的智能穿戴设备，用于奶牛常见疾病的检测和监测，并使用一种新颖的机器学习技术进行疾病诊断。", "motivation": "传统的手动观察和监测奶牛健康的方式耗时、劳动强度大且易出错，影响动物健康和农场生产效率。因此需要开发一个自动化、低成本且可靠的智能系统来解决这些问题。", "method": "本文提出了一种基于物联网的智能系统框架用于监控奶牛的日活动及健康状态，并设计了一个新颖的机器学习算法来进行多种常见疾病的诊断。", "result": "该论文没有具体描述结果，但声称所提出的算法能通过分析生理和行为数据来准确高效地评估奶牛的健康状况。", "conclusion": "研究得出结论认为，利用物联网、机器学习技术可以实现自动化、高精度且低成本的奶牛健康监测系统。"}}
{"id": "2601.04758", "pdf": "https://arxiv.org/pdf/2601.04758", "abs": "https://arxiv.org/abs/2601.04758", "authors": ["Yehoon Jang", "Chaewon Lee", "Hyun-seok Min", "Sungchul Choi"], "title": "PILOT-Bench: A Benchmark for Legal Reasoning in the Patent Domain with IRAC-Aligned Classification Tasks", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at the NLLP Workshop at EMNLP 2025", "summary": "The Patent Trial and Appeal Board (PTAB) of the USPTO adjudicates thousands of ex parte appeals each year, requiring the integration of technical understanding and legal reasoning. While large language models (LLMs) are increasingly applied in patent and legal practice, their use has remained limited to lightweight tasks, with no established means of systematically evaluating their capacity for structured legal reasoning in the patent domain. In this work, we introduce PILOT-Bench, the first PTAB-centric benchmark that aligns PTAB decisions with USPTO patent data at the case-level and formalizes three IRAC-aligned classification tasks: Issue Type, Board Authorities, and Subdecision. We evaluate a diverse set of closed-source (commercial) and open-source LLMs and conduct analyses across multiple perspectives, including input-variation settings, model families, and error tendencies. Notably, on the Issue Type task, closed-source models consistently exceed 0.75 in Micro-F1 score, whereas the strongest open-source model (Qwen-8B) achieves performance around 0.56, highlighting a substantial gap in reasoning capabilities. PILOT-Bench establishes a foundation for the systematic evaluation of patent-domain legal reasoning and points toward future directions for improving LLMs through dataset design and model alignment. All data, code, and benchmark resources are available at https://github.com/TeamLab/pilot-bench.", "AI": {"tldr": "PILOT-Bench是一个用于评估大型语言模型在专利领域中的法律推理能力的基准测试。", "motivation": "现有的大型语言模型在专利和法律实践中应用有限，缺乏系统地评估它们进行结构化法律推理的能力。因此需要一个专门针对PTAB决策与USPTO专利数据结合的任务集。", "method": "PILOT-Bench设计了三个IRAC对齐分类任务：问题类型、董事会权威和子决定，并评估了一系列封闭源代码（商业）和开放源代码的大型语言模型的表现。", "result": "在问题类型任务中，封闭源代码模型的平均微F1分数超过了0.75，而最强的开源模型Qwen-8B得分约为0.56，这表明两者之间存在显著的能力差距。", "conclusion": "PILOT-Bench提供了一个评估专利领域法律推理能力的基础，并为通过数据集设计和模型对齐来改善大型语言模型提供了未来研究方向。"}}
{"id": "2601.04756", "pdf": "https://arxiv.org/pdf/2601.04756", "abs": "https://arxiv.org/abs/2601.04756", "authors": ["Tuukka Korhonen", "Sang-il Oum"], "title": "Branch-width of connectivity functions is fixed-parameter tractable", "categories": ["cs.DS", "cs.DM", "math.CO"], "comment": "13 pages", "summary": "A connectivity function on a finite set $V$ is a symmetric submodular function $f \\colon 2^V \\to \\mathbb{Z}$ with $f(\\emptyset)=0$. We prove that finding a branch-decomposition of width at most $k$ for a connectivity function given by an oracle is fixed-parameter tractable (FPT), by providing an algorithm of running time $2^{O(k^2)} γn^6 \\log n$, where $γ$ is the time to compute $f(X)$ for any set $X$, and $n = |V|$. This improves the previous algorithm by Oum and Seymour [J. Combin. Theory Ser.~B, 2007], which runs in time $γn^{O(k)}$. Our algorithm can be applied to rank-width of graphs, branch-width of matroids, branch-width of (hyper)graphs, and carving-width of graphs. This resolves an open problem asked by Hliněný [SIAM J. Comput., 2005], who asked whether branch-width of matroids given by the rank oracle is fixed-parameter tractable. Furthermore, our algorithm improves the best known dependency on $k$ in the running times of FPT algorithms for graph branch-width, rank-width, and carving-width.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04754", "pdf": "https://arxiv.org/pdf/2601.04754", "abs": "https://arxiv.org/abs/2601.04754", "authors": ["Yen-Jen Chiou", "Wei-Tse Cheng", "Yuan-Fu Yang"], "title": "ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "10 pages, 5 figures", "summary": "We present ProFuse, an efficient context-aware framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting (3DGS). The pipeline enhances cross-view consistency and intra-mask cohesion within a direct registration setup, adding minimal overhead and requiring no render-supervised fine-tuning. Instead of relying on a pretrained 3DGS scene, we introduce a dense correspondence-guided pre-registration phase that initializes Gaussians with accurate geometry while jointly constructing 3D Context Proposals via cross-view clustering. Each proposal carries a global feature obtained through weighted aggregation of member embeddings, and this feature is fused onto Gaussians during direct registration to maintain per-primitive language coherence across views. With associations established in advance, semantic fusion requires no additional optimization beyond standard reconstruction, and the model retains geometric refinement without densification. ProFuse achieves strong open-vocabulary 3DGS understanding while completing semantic attachment in about five minutes per scene, which is two times faster than SOTA.", "AI": {"tldr": "论文提出了一种高效的ProFuse框架，用于开放词汇的3D场景理解。", "motivation": "传统的3D场景理解方法依赖于预训练模型或密集监督渲染。为了减少对这些需求的依赖，并提高效率和准确性，提出了新的直接注册设置下的跨视图一致性和内部分割一致性增强方案。", "method": "通过引入稠密对应引导的预注册阶段初始化高斯分布并构建3D上下文提案，同时在直接注册中融合全局特征以保持语言的一致性。此方法无需额外优化，并且模型可以保留几何细化而不增加密度。", "result": "ProFuse实现了强大的开放词汇3DGS理解和语义附着，在大约五分钟内完成每个场景的处理速度比现有最佳技术快两倍。", "conclusion": "该框架通过高效地融合跨视图上下文信息，显著提高了开放词汇的3D场景理解性能，同时减少了计算时间和资源需求。"}}
{"id": "2601.04752", "pdf": "https://arxiv.org/pdf/2601.04752", "abs": "https://arxiv.org/abs/2601.04752", "authors": ["Masatomo Yoshida", "Haruto Namura", "Nicola Adami", "Masahiro Okuda"], "title": "Skeletonization-Based Adversarial Perturbations on Large Vision Language Model's Mathematical Text Recognition", "categories": ["cs.CV"], "comment": "accepted to ITC-CSCC 2025", "summary": "This work explores the visual capabilities and limitations of foundation models by introducing a novel adversarial attack method utilizing skeletonization to reduce the search space effectively. Our approach specifically targets images containing text, particularly mathematical formula images, which are more challenging due to their LaTeX conversion and intricate structure. We conduct a detailed evaluation of both character and semantic changes between original and adversarially perturbed outputs to provide insights into the models' visual interpretation and reasoning abilities. The effectiveness of our method is further demonstrated through its application to ChatGPT, which shows its practical implications in real-world scenarios.", "AI": {"tldr": "本文提出了一种基于骨架化的对抗性攻击方法，旨在减少搜索空间并评估大视觉语言模型在数学文本识别上的性能。", "motivation": "通过引入一种新颖的对抗攻击技术，探索基础模型在图像和文本领域的视觉能力及局限性，并特别关注包含数学公式的图像处理挑战。", "method": "利用骨架化方法来生成针对模型输入图片的有效扰动，从而降低搜索空间。对原始与对抗扰动后的输出进行字符级和语义层面的变化分析。", "result": "该技术在ChatGPT等大语言模型上进行了验证，证明了其有效性和潜在应用价值。", "conclusion": "研究表明基于骨架化的方法能够成功地攻击大型视觉语言模型的数学文本识别能力，并为未来的研究提供了新的思路。"}}
{"id": "2601.04748", "pdf": "https://arxiv.org/pdf/2601.04748", "abs": "https://arxiv.org/abs/2601.04748", "authors": ["Xiaoxiao Li"], "title": "When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail", "categories": ["cs.AI", "cs.MA"], "comment": "25 pages, technical report", "summary": "Multi-agent AI systems have proven effective for complex reasoning. These systems are compounded by specialized agents, which collaborate through explicit communication, but incur substantial computational overhead. A natural question arises: can we achieve similar modularity benefits with a single agent that selects from a library of skills? We explore this question by viewing skills as internalized agent behaviors. From this perspective, a multi-agent system can be compiled into an equivalent single-agent system, trading inter-agent communication for skill selection. Our preliminary experiments suggest this approach can substantially reduce token usage and latency while maintaining competitive accuracy on reasoning benchmarks. However, this efficiency raises a deeper question that has received little attention: how does skill selection scale as libraries grow? Drawing on principles from cognitive science, we propose that LLM skill selection exhibits bounded capacity analogous to human decision-making. We investigate the scaling behavior of skill selection and observe a striking pattern. Rather than degrading gradually, selection accuracy remains stable up to a critical library size, then drops sharply, indicating a phase transition reminiscent of capacity limits in human cognition. Furthermore, we find evidence that semantic confusability among similar skills, rather than library size alone, plays a central role in this degradation. This perspective suggests that hierarchical organization, which has long helped humans manage complex choices, may similarly benefit AI systems. Our initial results with hierarchical routing support this hypothesis. This work opens new questions about the fundamental limits of semantic-based skill selection in LLMs and offers a cognitive-grounded framework and practical guidelines for designing scalable skill-based agents.", "AI": {"tldr": "本文探讨了单个具有技能的代理取代多代理系统在复杂推理任务中的应用及其局限性。", "motivation": "研究表明，虽然多代理系统能有效处理复杂的推理问题，但由于需要通过显式通信协作，导致计算开销大。因此，研究提出使用单一代理从技能库中选择行为的方法来减少计算资源的消耗，并探讨这种策略在扩展到更大的技能库时的表现。", "method": "本文将技能视为内部化的行为，并设计了实验对比多代理系统和单个代理的选择准确性。在此基础上，提出了类似人类决策能力有限的认知理论框架，以理解LLM选择行为的局限性，研究其随技能库增长的变化模式及影响因素。", "result": "研究表明，在到达临界点之前，随着技能库的增长，选择精度保持稳定；之后突然下降，这与人类认知容量限制相似。同时发现，语义混淆程度而非单一的库大小是导致性能下降的主要原因。", "conclusion": "该研究揭示了基于语义的选择机制在LLM中的基本局限性，并提出了一种具有认知基础的设计框架和实际指导方针来构建可扩展的行为选择代理系统。"}}
{"id": "2601.04745", "pdf": "https://arxiv.org/pdf/2601.04745", "abs": "https://arxiv.org/abs/2601.04745", "authors": ["Tingyu Wu", "Zhisheng Chen", "Ziyan Weng", "Shuhe Wang", "Chenglong Li", "Shuo Zhang", "Sen Hu", "Silin Wu", "Qizhen Lan", "Huacan Wang", "Ronghao Chen"], "title": "KnowMe-Bench: Benchmarking Person Understanding for Lifelong Digital Companions", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Existing long-horizon memory benchmarks mostly use multi-turn dialogues or synthetic user histories, which makes retrieval performance an imperfect proxy for person understanding. We present \\BenchName, a publicly releasable benchmark built from long-form autobiographical narratives, where actions, context, and inner thoughts provide dense evidence for inferring stable motivations and decision principles. \\BenchName~reconstructs each narrative into a flashback-aware, time-anchored stream and evaluates models with evidence-linked questions spanning factual recall, subjective state attribution, and principle-level reasoning. Across diverse narrative sources, retrieval-augmented systems mainly improve factual accuracy, while errors persist on temporally grounded explanations and higher-level inferences, highlighting the need for memory mechanisms beyond retrieval. Our data is in \\href{KnowMeBench}{https://github.com/QuantaAlpha/KnowMeBench}.", "AI": {"tldr": "本文介绍了KnowMe-Bench，一个用于评估数字伴侣对个人理解的基准测试。它基于自传体叙述构建了一个包含时间线索和情景背景的数据集，并通过问题来评价模型的记忆能力。", "motivation": "现有的长期记忆基准多采用对话或多轮问答的形式，无法准确反映个人理解的能力。KnowMe-Bench旨在提供一个真实、详细的人际互动数据集以评估数字伴侣的理解能力。", "method": "KnowMe-Bench从自传体叙述中重建了一个时间锚定的回忆流，并通过事实性问题、主观状态推断和原理级推理来评价模型的表现。", "result": "在多样化的叙事来源上，基于检索增强的方法主要改善了事实准确性，但在时间背景下解释错误仍存在，高阶推理错误也较为普遍。这表明记忆机制需要超越简单的检索。", "conclusion": "KnowMe-Bench揭示了现有模型在理解个人动机和决策原则方面的局限性，并强调了设计更复杂记忆系统的重要性。"}}
{"id": "2601.04744", "pdf": "https://arxiv.org/pdf/2601.04744", "abs": "https://arxiv.org/abs/2601.04744", "authors": ["Xingyuan Li", "Mengyue Wu"], "title": "Semi-Supervised Diseased Detection from Speech Dialogues with Multi-Level Data Modeling", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Detecting medical conditions from speech acoustics is fundamentally a weakly-supervised learning problem: a single, often noisy, session-level label must be linked to nuanced patterns within a long, complex audio recording. This task is further hampered by severe data scarcity and the subjective nature of clinical annotations. While semi-supervised learning (SSL) offers a viable path to leverage unlabeled data, existing audio methods often fail to address the core challenge that pathological traits are not uniformly expressed in a patient's speech. We propose a novel, audio-only SSL framework that explicitly models this hierarchy by jointly learning from frame-level, segment-level, and session-level representations within unsegmented clinical dialogues. Our end-to-end approach dynamically aggregates these multi-granularity features and generates high-quality pseudo-labels to efficiently utilize unlabeled data. Extensive experiments show the framework is model-agnostic, robust across languages and conditions, and highly data-efficient-achieving, for instance, 90\\% of fully-supervised performance using only 11 labeled samples. This work provides a principled approach to learning from weak, far-end supervision in medical speech analysis.", "AI": {"tldr": "本文提出了一种基于音频的半监督学习框架，用于从临床对话中检测疾病。", "motivation": "医学条件从语音声学特征进行检测是一个弱监督问题，存在数据稀缺和标注主观性强的问题。现有的音频方法未能有效解决病理性特质在患者话语中的非均匀表达问题。", "method": "本文提出了一种新颖的半监督学习框架，通过联合学习帧级、片段级和会话级表示来处理这一层级关系，并生成高质量伪标签以充分利用未标注数据。", "result": "该方法显示出模型无关性，对不同语言和条件具有鲁棒性，仅使用11个标记样本即可达到完全监督性能的90%。", "conclusion": "本文提出了一种原则性的方法来处理医学语音分析中的弱远端监督问题。"}}
{"id": "2601.04741", "pdf": "https://arxiv.org/pdf/2601.04741", "abs": "https://arxiv.org/abs/2601.04741", "authors": ["Kota Nakamura", "Koki Kawabata", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by KDD 2026", "summary": "Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.", "AI": {"tldr": "通过分析多传感器数据流，持续预测机器故障发生的时间。", "motivation": "如何根据实时传感器数据流连续预测未来事件的发生时间？为应对现实世界数据流的动态性质及其随时间变化的趋势，提出TimeCast框架以适应这些变化并提供准确、实时的未来事件时间预测。", "method": "提出了TimeCast，一个能够识别和学习不同阶段模型来适应模式转变，并找到有意义的时间依赖关系从而提高预测性能的方法。该方法同时具备动态性、实用性和可扩展性。", "result": "在真实数据集上的实验表明，TimeCast提供了比现有最佳方法更高的预测准确率，并且能够在减少计算时间的情况下检测到数据流中的动态变化。", "conclusion": "TimeCast框架可以有效地处理多传感器数据流中的动态模式变化，提供高精度的事件时间预测。"}}
{"id": "2601.04740", "pdf": "https://arxiv.org/pdf/2601.04740", "abs": "https://arxiv.org/abs/2601.04740", "authors": ["Huawei Zheng", "Xinqi Jiang", "Sen Yang", "Shouling Ji", "Yingcai Wu", "Dazhen Deng"], "title": "RiskAtlas: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly applied in specialized domains such as finance and healthcare, where they introduce unique safety risks. Domain-specific datasets of harmful prompts remain scarce and still largely rely on manual construction; public datasets mainly focus on explicit harmful prompts, which modern LLM defenses can often detect and refuse. In contrast, implicit harmful prompts-expressed through indirect domain knowledge-are harder to detect and better reflect real-world threats. We identify two challenges: transforming domain knowledge into actionable constraints and increasing the implicitness of generated harmful prompts. To address them, we propose an end-to-end framework that first performs knowledge-graph-guided harmful prompt generation to systematically produce domain-relevant prompts, and then applies dual-path obfuscation rewriting to convert explicit harmful prompts into implicit variants via direct and context-enhanced rewriting. This framework yields high-quality datasets combining strong domain relevance with implicitness, enabling more realistic red-teaming and advancing LLM safety research. We release our code and datasets at GitHub.", "AI": {"tldr": "该论文提出了RiskAtlas框架，通过知识图谱引导生成领域相关的有害提示，并使用双重路径混淆重写方法将其转换为隐式变体。", "motivation": "当前大型语言模型在特定领域的应用中引入了独特的安全风险。现有数据集主要关注显式的有害提示，这些提示可以通过现代防御机制检测到。相比之下，隐式的有害提示更难以被发现，更能反映现实中的威胁。", "method": "RiskAtlas框架首先通过知识图谱引导生成领域相关的有害提示，然后利用双重路径混淆重写方法将显式有害提示转换为隐式变体。该方法包括直接和上下文增强的重写技术。", "result": "此框架产生了一组高质数据集，这些数据集结合了强大的领域相关性和隐含性，促进了更现实的安全测试，并推动了大型语言模型安全研究的发展。", "conclusion": "RiskAtlas通过知识图谱引导和双重路径混淆重写方法有效地生成了大量的领域相关的隐式有害提示。这种方法有助于提高对特定领域中潜在风险的理解并提升安全性。"}}
{"id": "2601.04734", "pdf": "https://arxiv.org/pdf/2601.04734", "abs": "https://arxiv.org/abs/2601.04734", "authors": ["Yunqing Hu", "Zheming Yang", "Chang Zhao", "Qi Guo", "Meng Gao", "Pengcheng Li", "Wen Ji"], "title": "AIVD: Adaptive Edge-Cloud Collaboration for Accurate and Efficient Industrial Visual Detection", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal large language models (MLLMs) demonstrate exceptional capabilities in semantic understanding and visual reasoning, yet they still face challenges in precise object localization and resource-constrained edge-cloud deployment. To address this, this paper proposes the AIVD framework, which achieves unified precise localization and high-quality semantic generation through the collaboration between lightweight edge detectors and cloud-based MLLMs. To enhance the cloud MLLM's robustness against edge cropped-box noise and scenario variations, we design an efficient fine-tuning strategy with visual-semantic collaborative augmentation, significantly improving classification accuracy and semantic consistency. Furthermore, to maintain high throughput and low latency across heterogeneous edge devices and dynamic network conditions, we propose a heterogeneous resource-aware dynamic scheduling algorithm. Experimental results demonstrate that AIVD substantially reduces resource consumption while improving MLLM classification performance and semantic generation quality. The proposed scheduling strategy also achieves higher throughput and lower latency across diverse scenarios.", "AI": {"tldr": "该论文提出了AIVD框架，通过边缘设备和云端的协作来提高工业视觉检测的准确性与效率。", "motivation": "多模态大型语言模型在语义理解和视觉推理上表现出色，但在精确物体定位和资源受限的边缘-云部署方面仍面临挑战。为解决这些问题，提出了AIVD框架。", "method": "该方法通过轻量级边缘检测器与云端MLLMs的合作实现了精准定位和高质量语义生成，并设计了一种有效的微调策略以增强对边缘裁剪框噪声和场景变化的鲁棒性。此外还提出了一种异构资源感知动态调度算法，以保持在不同设备和网络条件下高吞吐量和低延迟。", "result": "实验结果显示AIVD框架显著降低了资源消耗并提升了MLLM分类性能及语义生成质量；所提出的调度策略也实现了跨多种场景下的更高吞吐量和更低延迟。", "conclusion": "本文通过引入AIVD框架成功解决了边缘-云部署中的挑战，同时提高了视觉检测的精度与效率。"}}
{"id": "2601.04732", "pdf": "https://arxiv.org/pdf/2601.04732", "abs": "https://arxiv.org/abs/2601.04732", "authors": ["Dominik Freinberger", "Philipp Moser"], "title": "The Role of Quantum in Hybrid Quantum-Classical Neural Networks: A Realistic Assessment", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "16 pages, 6 figures", "summary": "Quantum machine learning has emerged as a promising application domain for near-term quantum hardware, particularly through hybrid quantum-classical models that leverage both classical and quantum processing. Although numerous hybrid architectures have been proposed and demonstrated successfully on benchmark tasks, a significant open question remains regarding the specific contribution of quantum components to the overall performance of these models. In this work, we aim to shed light on the impact of quantum processing within hybrid quantum-classical neural network architectures through a rigorous statistical study. We systematically assess common hybrid models on medical signal data as well as planar and volumetric images, examining the influence attributable to classical and quantum aspects such as encoding schemes, entanglement, and circuit size. We find that in best-case scenarios, hybrid models show performance comparable to their classical counterparts, however, in most cases, performance metrics deteriorate under the influence of quantum components. Our multi-modal analysis provides realistic insights into the contributions of quantum components and advocates for cautious claims and design choices for hybrid models in near-term applications.", "AI": {"tldr": "本论文通过多模式分析评估混合量子-经典神经网络架构中量子组件的具体贡献。", "motivation": "尽管已经提出了许多成功的杂交架构，但尚不清楚这些模型中的量子组件对整体性能的特定贡献。因此，作者希望通过严格的统计研究来探讨量子处理在混合量子-经典神经网络架构中的影响。", "method": "本工作系统性地评估了常见的杂交模型在医学信号数据以及平面和体积图像上的表现，并考察了诸如编码方案、纠缠和电路规模等经典与量子方面的贡献。", "result": "研究发现，在最佳情况下，混合模型的表现可媲美其经典的同行；然而在大多数情况下，性能指标因量子组件的影响而恶化。", "conclusion": "多模式分析提供了关于量子组件的真实见解，并倡导对近期内的应用中杂交模型的谨慎声明和设计选择。"}}
{"id": "2601.04731", "pdf": "https://arxiv.org/pdf/2601.04731", "abs": "https://arxiv.org/abs/2601.04731", "authors": ["Shuyang Jiang", "Yuhao Wang", "Ya Zhang", "Yanfeng Wang", "Yu Wang"], "title": "Miner:Mining Intrinsic Mastery for Data-Efficient RL in Large Reasoning Models", "categories": ["cs.AI", "cs.CL"], "comment": "22 pages", "summary": "Current critic-free RL methods for large reasoning models suffer from severe inefficiency when training on positive homogeneous prompts (where all rollouts are correct), resulting in waste of rollouts due to zero advantage estimates. We introduce a radically simple yet powerful solution to \\uline{M}ine \\uline{in}trinsic mast\\uline{er}y (Miner), that repurposes the policy's intrinsic uncertainty as a self-supervised reward signal, with no external supervision, auxiliary models, or additional inference cost. Our method pioneers two key innovations: (1) a token-level focal credit assignment mechanism that dynamically amplifies gradients on critical uncertain tokens while suppressing overconfident ones, and (2) adaptive advantage calibration to seamlessly integrate intrinsic and verifiable rewards. Evaluated across six reasoning benchmarks on Qwen3-4B and Qwen3-8B base models, Miner achieves state-of-the-art performance among the other four algorithms, yielding up to \\textbf{4.58} absolute gains in Pass@1 and \\textbf{6.66} gains in Pass@K compared to GRPO. Comparison with other methods targeted at exploration enhancement further discloses the superiority of the two newly proposed innovations. This demonstrates that latent uncertainty exploitation is both necessary and sufficient for efficient and scalable RL training of reasoning models.", "AI": {"tldr": "本文提出了一个新的方法Miner，利用策略的内在不确定性作为自我监督奖励信号，以提高大型推理模型在正面同质提示上的训练效率。", "motivation": "当前的无批评家强化学习方法在处理所有rollout正确的正向同质提示时存在严重的低效问题。为了克服这一挑战，提出了Miner方法来利用策略的内在不确定性作为自我监督奖励信号。", "method": "Miner通过引入一种令牌级聚焦信用分配机制和自适应优势校准技术，在不增加额外计算成本的情况下，动态放大关键不确定令牌的梯度并抑制过度自信的令牌。该方法不需要外部监督、辅助模型或额外的推理费用。", "result": "在六个推理基准测试中，Miner相较于其他四种算法取得了最先进的性能表现，并且在Qwen3-4B和Qwen3-8B基础模型上分别达到了4.58个绝对优势的Pass@1以及6.66个绝对优势的Pass@K。与探索增强的目标方法相比，新提出的方法显示出明显优越性。", "conclusion": "该研究证明了内在不确定性利用对于大型推理模型的高效和可扩展强化学习训练既是必要的也是充分的。"}}
{"id": "2601.04728", "pdf": "https://arxiv.org/pdf/2601.04728", "abs": "https://arxiv.org/abs/2601.04728", "authors": ["Elizabeth Donoway", "Hailey Joren", "Fabien Roger", "Jan Leike"], "title": "Excess Description Length of Learning Generalizable Predictors", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.", "AI": {"tldr": "本文开发了一个信息论框架，用于量化微调过程中从训练数据中提取的预测结构，并将其写入模型参数。", "motivation": "理解微调是否激发潜在能力或教授新技能是语言模型评估和安全性的基本问题。", "method": "通过前序编码定义了关键量——超额描述长度（EDL），并建立了其在无限数据限制下的非负性、收敛性和预期泛化增益的界限。", "result": "一系列玩具模型澄清了学习中的常见信息混淆，并验证了框架的有效性。", "conclusion": "该框架为能力激发和教学展示出不同的扩展特性提供了严格的理论基础。"}}
{"id": "2601.04727", "pdf": "https://arxiv.org/pdf/2601.04727", "abs": "https://arxiv.org/abs/2601.04727", "authors": ["Anika Tabassum", "Tasnuva Mahazabin Tuba", "Nafisa Naznin"], "title": "Training a Custom CNN on Five Heterogeneous Image Datasets", "categories": ["cs.CV", "cs.NE"], "comment": null, "summary": "Deep learning has transformed visual data analysis, with Convolutional Neural Networks (CNNs) becoming highly effective in learning meaningful feature representations directly from images. Unlike traditional manual feature engineering methods, CNNs automatically extract hierarchical visual patterns, enabling strong performance across diverse real-world contexts. This study investigates the effectiveness of CNN-based architectures across five heterogeneous datasets spanning agricultural and urban domains: mango variety classification, paddy variety identification, road surface condition assessment, auto-rickshaw detection, and footpath encroachment monitoring. These datasets introduce varying challenges, including differences in illumination, resolution, environmental complexity, and class imbalance, necessitating adaptable and robust learning models. We evaluate a lightweight, task-specific custom CNN alongside established deep architectures, including ResNet-18 and VGG-16, trained both from scratch and using transfer learning. Through systematic preprocessing, augmentation, and controlled experimentation, we analyze how architectural complexity, model depth, and pre-training influence convergence, generalization, and performance across datasets of differing scale and difficulty. The key contributions of this work are: (1) the development of an efficient custom CNN that achieves competitive performance across multiple application domains, and (2) a comprehensive comparative analysis highlighting when transfer learning and deep architectures provide substantial advantages, particularly in data-constrained environments. These findings offer practical insights for deploying deep learning models in resource-limited yet high-impact real-world visual classification tasks.", "AI": {"tldr": "本文研究了在五个不同图像数据集上训练CNN的效果，这些数据集涵盖了农业和城市领域。", "motivation": "深度学习已经改变了视觉数据分析的方式，而卷积神经网络（CNN）可以在从图像中直接提取有意义的特征表示方面非常有效。然而，在不同的光照、分辨率、环境复杂性和类别不平衡的情况下，需要开发适应性强且鲁棒的学习模型。", "method": "研究评估了一种轻量级、特定任务定制的CNN，以及ResNet-18和VGG-16等已建立的深度架构，并分析了在不同规模和难度的数据集上训练这些模型时，网络复杂性、模型深度和预训练如何影响收敛性和泛化能力。", "result": "该工作开发了一种高效的定制CNN，在多个应用领域中实现了竞争性的性能。此外，还进行了全面比较分析，指出了迁移学习和深层架构在数据受限环境中提供的实质性优势。", "conclusion": "这些发现为在资源有限但具有高影响力的真实世界视觉分类任务中部署深度学习模型提供了实用见解。"}}
{"id": "2601.04726", "pdf": "https://arxiv.org/pdf/2601.04726", "abs": "https://arxiv.org/abs/2601.04726", "authors": ["Yuyang Hu", "Jiongnan Liu", "Jiejun Tan", "Yutao Zhu", "Zhicheng Dou"], "title": "Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "19 pages,6 figures", "summary": "Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.", "AI": {"tldr": "提出CompassMem框架，通过事件图结构来增强智能代理的长期推理能力。", "motivation": "现有方法难以有效捕捉记忆单元间的逻辑关系，并且依赖浅层语义检索，限制了长时依赖下的逻辑推理。", "method": "借鉴事件分割理论设计事件中心内存框架CompassMem，将经历划分成事件并链接形成图结构，支持目标导向的导航和深层次的记忆检索与推理。", "result": "在LoCoMo和NarrativeQA上的实验表明，CompassMem能提升多模型下记忆检索和推理性能。", "conclusion": "通过逻辑地图组织内存能够显著提高智能代理对长期依赖的理解和利用能力。"}}
{"id": "2601.04715", "pdf": "https://arxiv.org/pdf/2601.04715", "abs": "https://arxiv.org/abs/2601.04715", "authors": ["Xiao Guo", "Jie Zhu", "Anil Jain", "Xiaoming Liu"], "title": "On the Holistic Approach for Detecting Human Image Forgery", "categories": ["cs.CV"], "comment": "6 figures, 5 tables", "summary": "The rapid advancement of AI-generated content (AIGC) has escalated the threat of deepfakes, from facial manipulations to the synthesis of entire photorealistic human bodies. However, existing detection methods remain fragmented, specializing either in facial-region forgeries or full-body synthetic images, and consequently fail to generalize across the full spectrum of human image manipulations. We introduce HuForDet, a holistic framework for human image forgery detection, which features a dual-branch architecture comprising: (1) a face forgery detection branch that employs heterogeneous experts operating in both RGB and frequency domains, including an adaptive Laplacian-of-Gaussian (LoG) module designed to capture artifacts ranging from fine-grained blending boundaries to coarse-scale texture irregularities; and (2) a contextualized forgery detection branch that leverages a Multi-Modal Large Language Model (MLLM) to analyze full-body semantic consistency, enhanced with a confidence estimation mechanism that dynamically weights its contribution during feature fusion. We curate a human image forgery (HuFor) dataset that unifies existing face forgery data with a new corpus of full-body synthetic humans. Extensive experiments show that our HuForDet achieves state-of-the-art forgery detection performance and superior robustness across diverse human image forgeries.", "AI": {"tldr": "介绍了一种用于检测人类图像伪造的全面框架HuForDet。", "motivation": "现有方法在检测面部或全身合成图像时过于碎片化，无法应对整个范围的人类图像篡改威胁。", "method": "提出了一个双分支架构的Holistic Forgery Detection框架，包括针对RGB和频率域的脸部伪造检测分支以及利用多模态大语言模型分析全身体语义一致性的上下文伪造检测分支。", "result": "通过广泛实验表明，提出的HuForDet在不同类型的人类图像伪造中实现了最先进的检测性能和卓越的鲁棒性。", "conclusion": "提出的方法解决了现有技术无法全面应对人类图像篡改问题，展示了强大的泛化能力。"}}
{"id": "2601.04714", "pdf": "https://arxiv.org/pdf/2601.04714", "abs": "https://arxiv.org/abs/2601.04714", "authors": ["Chang Zhao", "Zheming Yang", "Yunqing Hu", "Qi Guo", "Zijian Wang", "Pengcheng Li", "Wen Ji"], "title": "ThinkDrive: Chain-of-Thought Guided Progressive Reinforcement Learning Fine-Tuning for Autonomous Driving", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid advancement of large language models (LLMs) technologies, their application in the domain of autonomous driving has become increasingly widespread. However, existing methods suffer from unstructured reasoning, poor generalization, and misalignment with human driving intent. While Chain-of-Thought (CoT) reasoning enhances decision transparency, conventional supervised fine-tuning (SFT) fails to fully exploit its potential, and reinforcement learning (RL) approaches face instability and suboptimal reasoning depth. We propose ThinkDrive, a CoT guided progressive RL fine-tuning framework for autonomous driving that synergizes explicit reasoning with difficulty-aware adaptive policy optimization. Our method employs a two-stage training strategy. First, we perform SFT using CoT explanations. Then, we apply progressive RL with a difficulty-aware adaptive policy optimizer that dynamically adjusts learning intensity based on sample complexity. We evaluate our approach on a public dataset. The results show that ThinkDrive outperforms strong RL baselines by 1.45%, 1.95%, and 1.01% on exam, easy-exam, and accuracy, respectively. Moreover, a 2B-parameter model trained with our method surpasses the much larger GPT-4o by 3.28% on the exam metric.", "AI": {"tldr": "提出ThinkDrive框架，利用链式思维引导的渐进强化学习微调方法来提高自动驾驶系统的性能。", "motivation": "现有自动驾驶系统的方法存在无结构化推理、泛化能力差和与人类驾驶意图不一致的问题。为了解决这些问题，并充分利用链式思维的优点，同时克服强化学习中的不稳定性和次优推理深度问题，提出了一种新的框架。", "method": "首先使用带有链式思维解释的监督微调（SFT），然后采用基于任务难度感知自适应策略优化器的渐进式强化学习方法。该方法可以动态调整学习强度以应对样本复杂度的变化。", "result": "在公共数据集上进行评估，结果表明ThinkDrive相较于强大的RL基准提高了1.45%，1.95%和1.01%的性能指标，并且使用此方法训练的一个2B参数模型在考试指标上超过了更大规模的GPT-4o 3.28%。", "conclusion": "通过引入链式思维引导的渐进强化学习微调框架，可以显著提高自动驾驶系统的决策透明度和性能。"}}
{"id": "2601.04711", "pdf": "https://arxiv.org/pdf/2601.04711", "abs": "https://arxiv.org/abs/2601.04711", "authors": ["Anh Thi-Hoang Nguyen", "Khanh Quoc Tran", "Tin Van Huynh", "Phuoc Tan-Hoang Nguyen", "Cam Tan Nguyen", "Kiet Van Nguyen"], "title": "DSC2025 -- ViHallu Challenge: Detecting Hallucination in Vietnamese LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The reliability of large language models (LLMs) in production environments remains significantly constrained by their propensity to generate hallucinations -- fluent, plausible-sounding outputs that contradict or fabricate information. While hallucination detection has recently emerged as a priority in English-centric benchmarks, low-to-medium resource languages such as Vietnamese remain inadequately covered by standardized evaluation frameworks. This paper introduces the DSC2025 ViHallu Challenge, the first large-scale shared task for detecting hallucinations in Vietnamese LLMs. We present the ViHallu dataset, comprising 10,000 annotated triplets of (context, prompt, response) samples systematically partitioned into three hallucination categories: no hallucination, intrinsic, and extrinsic hallucinations. The dataset incorporates three prompt types -- factual, noisy, and adversarial -- to stress-test model robustness. A total of 111 teams participated, with the best-performing system achieving a macro-F1 score of 84.80\\%, compared to a baseline encoder-only score of 32.83\\%, demonstrating that instruction-tuned LLMs with structured prompting and ensemble strategies substantially outperform generic architectures. However, the gap to perfect performance indicates that hallucination detection remains a challenging problem, particularly for intrinsic (contradiction-based) hallucinations. This work establishes a rigorous benchmark and explores a diverse range of detection methodologies, providing a foundation for future research into the trustworthiness and reliability of Vietnamese language AI systems.", "AI": {"tldr": "介绍了一个针对越南语大规模语言模型幻觉检测的基准任务，ViHallu挑战。", "motivation": "提升越南语等资源有限语言的大规模语言模型的可靠性和准确性，填补现有评估框架不足的空白。", "method": "构建了包含10,000个样本的ViHallu数据集，并进行了大范围的方法探索和系统比较。", "result": "最佳方法在宏F1分数上达到了84.80%，显著优于基线模型的表现，但仍有改进空间。", "conclusion": "确立了一个严格的基准测试框架，为未来研究奠定了基础，强调了幻觉检测的重要性。"}}
{"id": "2601.04709", "pdf": "https://arxiv.org/pdf/2601.04709", "abs": "https://arxiv.org/abs/2601.04709", "authors": ["Gijun Park"], "title": "Bridging Temporal and Textual Modalities: A Multimodal Framework for Automated Cloud Failure Root Cause Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Root cause analysis in modern cloud infrastructure demands sophisticated understanding of heterogeneous data sources, particularly time-series performance metrics that involve core failure signatures. While large language models demonstrate remarkable capabilities in textual reasoning, their discrete token-based architecture creates fundamental incompatibilities with continuous numerical sequences exhibiting temporal dependencies. Current methodologies inadequately address this modality mismatch, constraining the potential of language model-driven automation in incident management workflows. This paper presents a multimodal diagnostic framework that harmonizes time-series representations with pretrained language model embedding spaces. Our approach contributes three technical advances: (1) a semantic compression technique that distills temporal segments into single-token abstractions while preserving pattern semantics, (2) an alignment encoder utilizing gated cross-attention to project time-series features into language model latent space, and (3) a retrieval-augmented diagnostic pipeline that synthesizes aligned embeddings with historical incident knowledge for expert-level failure attribution. Comprehensive evaluation across six cloud system benchmarks demonstrates that our framework achieves leading performance, reaching 48.75% diagnostic accuracy with notable improvements on scenarios involving compound failure modes. The results validate embedding-space alignment as an effective strategy for enabling language models to reason over multimodal telemetry data in production incident response contexts.", "AI": {"tldr": "该论文提出了一个多模态诊断框架，用于自动化云故障根本原因分析，解决了时间序列数据和语言模型之间的兼容性问题。", "motivation": "现代云计算基础设施中的根因分析需要对异构的数据源有深刻的了解，当前方法在处理时间和文本模式不匹配的问题上存在不足，限制了自然语言模型驱动的自动化的潜力。", "method": "该框架通过语义压缩技术将时间序列段简化为单一令牌抽象的同时保留模式语义；利用带有门控交叉注意的对齐编码器将时间序列特征投影到语言模型潜在空间，并采用检索增强诊断流程整合对齐嵌入和历史故障知识进行专家级故障归因。", "result": "该框架在六个云系统基准测试中表现优异，达到48.75%的诊断准确率，在涉及复合故障模式的情景中有显著改进。", "conclusion": "结果验证了嵌入空间对齐作为语言模型推理多模态遥测数据的有效策略。"}}
{"id": "2601.04707", "pdf": "https://arxiv.org/pdf/2601.04707", "abs": "https://arxiv.org/abs/2601.04707", "authors": ["Irfan Ullah", "Young-Koo Lee"], "title": "MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.PF"], "comment": "IEEE Access 2025", "summary": "Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \\boldmath $\\bm{4.6\\,\\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.", "AI": {"tldr": "提出MQ-GNN框架，通过多队列流水线优化GNN训练效率。", "motivation": "现有GNN训练框架在处理大规模图数据时面临生成批次不高效、数据传输瓶颈及昂贵的GPU间同步问题，导致资源利用率低下。", "method": "引入RaCoM模型异步更新机制和全局邻居采样技术，并采用自适应队列大小策略以平衡计算与内存效率，优化GNN训练过程。", "result": "实验表明MQ-GNN相比基准模型，在四个大规模数据集上实现了最多4.6倍的训练速度提升及30%的GPU利用率提高，同时保持了竞争性准确率。", "conclusion": "MQ-GNN作为一个多GPU环境下高效且可扩展的GNN训练解决方案被验证有效。"}}
{"id": "2601.04706", "pdf": "https://arxiv.org/pdf/2601.04706", "abs": "https://arxiv.org/abs/2601.04706", "authors": ["Yanbing Zeng", "Jia Wang", "Hanghang Ma", "Junqiang Wu", "Jie Zhu", "Xiaoming Wei", "Jie Hu"], "title": "Forge-and-Quench: Enhancing Image Generation for Higher Fidelity in Unified Multimodal Models", "categories": ["cs.CV"], "comment": null, "summary": "Integrating image generation and understanding into a single framework has become a pivotal goal in the multimodal domain. However, how understanding can effectively assist generation has not been fully explored. Unlike previous works that focus on leveraging reasoning abilities and world knowledge from understanding models, this paper introduces a novel perspective: leveraging understanding to enhance the fidelity and detail richness of generated images. To this end, we propose Forge-and-Quench, a new unified framework that puts this principle into practice. In the generation process of our framework, an MLLM first reasons over the entire conversational context, including text instructions, to produce an enhanced text instruction. This refined instruction is then mapped to a virtual visual representation, termed the Bridge Feature, via a novel Bridge Adapter. This feature acts as a crucial link, forging insights from the understanding model to quench and refine the generation process. It is subsequently injected into the T2I backbone as a visual guidance signal, alongside the enhanced text instruction that replaces the original input. To validate this paradigm, we conduct comprehensive studies on the design of the Bridge Feature and Bridge Adapter. Our framework demonstrates exceptional extensibility and flexibility, enabling efficient migration across different MLLM and T2I models with significant savings in training overhead, all without compromising the MLLM's inherent multimodal understanding capabilities. Experiments show that Forge-and-Quench significantly improves image fidelity and detail across multiple models, while also maintaining instruction-following accuracy and enhancing world knowledge application. Models and codes are available at https://github.com/YanbingZeng/Forge-and-Quench.", "AI": {"tldr": "本文提出了一种新的统一框架Forge-and-Quench，该框架通过理解模型来提高生成图像的保真度和细节丰富性。", "motivation": "如何利用理解能力有效地改善图像生成尚未充分探索。传统的研究主要集中在从理解模型中获取推理能力和世界知识上，而本文旨在探讨理解如何增强生成图像的保真度和细节。", "method": "Forge-and-Quench框架通过一个MLLM在对话上下文中进行推理并产生改进的文本指令，该指令随后被映射到虚拟视觉表示Bridge Feature。该特征作为链接理解模型与生成过程之间的纽带，在T2I骨干网络中注入以提供视觉指导。", "result": "实验表明，Forge-and-Quench框架显著提高了多种模型的图像保真度和细节水平，并且在保持指令跟随准确性和世界知识应用方面也有所改进。", "conclusion": "Forge-and-Quench框架展示了其卓越的可扩展性与灵活性，能够在不同MLLM和T2I模型之间实现高效迁移。"}}
{"id": "2601.04703", "pdf": "https://arxiv.org/pdf/2601.04703", "abs": "https://arxiv.org/abs/2601.04703", "authors": ["Yiqun Chen", "Lingyong Yan", "Zixuan Yang", "Erhan Zhang", "Jiashu Zhao", "Shuaiqiang Wang", "Dawei Yin", "Jiaxin Mao"], "title": "Beyond Monolithic Architectures: A Multi-Agent Search and Knowledge Optimization Framework for Agentic Search", "categories": ["cs.AI"], "comment": null, "summary": "Agentic search has emerged as a promising paradigm for complex information seeking by enabling Large Language Models (LLMs) to interleave reasoning with tool use. However, prevailing systems rely on monolithic agents that suffer from structural bottlenecks, including unconstrained reasoning outputs that inflate trajectories, sparse outcome-level rewards that complicate credit assignment, and stochastic search noise that destabilizes learning. To address these challenges, we propose \\textbf{M-ASK} (Multi-Agent Search and Knowledge), a framework that explicitly decouples agentic search into two complementary roles: Search Behavior Agents, which plan and execute search actions, and Knowledge Management Agents, which aggregate, filter, and maintain a compact internal context. This decomposition allows each agent to focus on a well-defined subtask and reduces interference between search and context construction. Furthermore, to enable stable coordination, M-ASK employs turn-level rewards to provide granular supervision for both search decisions and knowledge updates. Experiments on multi-hop QA benchmarks demonstrate that M-ASK outperforms strong baselines, achieving not only superior answer accuracy but also significantly more stable training dynamics.\\footnote{The source code for M-ASK is available at https://github.com/chenyiqun/M-ASK.}", "AI": {"tldr": "提出了M-ASK框架，用于优化复杂信息检索过程中的代理搜索和知识管理。", "motivation": "现有的单体结构代理在推理输出、奖励稀疏性和随机搜索噪声方面存在瓶颈问题，影响了性能稳定性和学习效率。", "method": "M-ASK框架将代理搜索分解为两个角色：搜索行为代理执行搜索行动，知识管理代理处理信息聚合和维护。引入分时奖励机制以提高协调稳定性。", "result": "实验表明，M-ASK在多跳QA基准测试中表现出更高的答案准确性和更稳定的训练过程。", "conclusion": "通过将任务分解为明确的角色并使用细化的奖励系统，可以显著改进代理搜索和知识管理的效率与稳定性。"}}
{"id": "2601.04699", "pdf": "https://arxiv.org/pdf/2601.04699", "abs": "https://arxiv.org/abs/2601.04699", "authors": ["Zebin Han", "Xudong Wang", "Baichen Liu", "Qi Lyu", "Zhenduo Shang", "Jiahua Dong", "Lianqing Liu", "Zhi Han"], "title": "SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Sequential-Horizon Vision-and-Language Navigation (SH-VLN) presents a challenging scenario where agents should sequentially execute multi-task navigation guided by complex, long-horizon language instructions. Current vision-and-language navigation models exhibit significant performance degradation with such multi-task instructions, as information overload impairs the agent's ability to attend to observationally relevant details. To address this problem, we propose SeqWalker, a navigation model built on a hierarchical planning framework. Our SeqWalker features: i) A High-Level Planner that dynamically selects global instructions into contextually relevant sub-instructions based on the agent's current visual observations, thus reducing cognitive load; ii) A Low-Level Planner incorporating an Exploration-Verification strategy that leverages the inherent logical structure of instructions for trajectory error correction. To evaluate SH-VLN performance, we also extend the IVLN dataset and establish a new benchmark. Extensive experiments are performed to demonstrate the superiority of the proposed SeqWalker.", "AI": {"tldr": "SeqWalker是一种基于分层规划框架的导航模型，旨在解决序列视野和语言导航中的多任务指令性能下降问题。", "motivation": "当前的视觉和语言导航模型在处理复杂、长距离的语言指令时表现出显著的性能下降，因为信息过载影响了代理对观察相关细节的关注能力。为了应对这一挑战，研究提出了SeqWalker模型以改善这种情况。", "method": "SeqWalker的主要方法是：i) 高级规划器根据当前视觉观测动态选择全局指令为上下文相关的子指令；ii) 低级规划器使用探索-验证策略利用指令的内在逻辑结构进行轨迹错误校正。", "result": "实验结果表明，所提出的SeqWalker在序列视野和语言导航任务中表现优越。", "conclusion": "通过分层规划框架和技术创新，SeqWalker有效解决了长距离指令下的性能下降问题，并在新的基准测试中表现出色。"}}
{"id": "2601.04698", "pdf": "https://arxiv.org/pdf/2601.04698", "abs": "https://arxiv.org/abs/2601.04698", "authors": ["Yinuo Wang", "Mining Tan", "Wenxiang Jiao", "Xiaoxi Li", "Hao Wang", "Xuanyu Zhang", "Yuan Lu", "Weiming Dong"], "title": "TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Travel planning is a sophisticated decision-making process that requires synthesizing multifaceted information to construct itineraries. However, existing travel planning approaches face several challenges: (1) Pruning candidate points of interest (POIs) while maintaining a high recall rate; (2) A single reasoning path restricts the exploration capability within the feasible solution space for travel planning; (3) Simultaneously optimizing hard constraints and soft constraints remains a significant difficulty. To address these challenges, we propose TourPlanner, a comprehensive framework featuring multi-path reasoning and constraint-gated reinforcement learning. Specifically, we first introduce a Personalized Recall and Spatial Optimization (PReSO) workflow to construct spatially-aware candidate POIs' set. Subsequently, we propose Competitive consensus Chain-of-Thought (CCoT), a multi-path reasoning paradigm that improves the ability of exploring the feasible solution space. To further refine the plan, we integrate a sigmoid-based gating mechanism into the reinforcement learning stage, which dynamically prioritizes soft-constraint satisfaction only after hard constraints are met. Experimental results on travel planning benchmarks demonstrate that TourPlanner achieves state-of-the-art performance, significantly surpassing existing methods in both feasibility and user-preference alignment.", "AI": {"tldr": "TourPlanner是一款结合了多路径推理和约束门控强化学习的全面框架，用于旅行规划。", "motivation": "解决现有的旅行规划方法在候选POI筛选、探索能力和同时优化硬软约束方面的挑战", "method": "首先引入PReSO工作流构建空间感知候选POI集合；提出多路径推理范式Competitive Consensus Chain-of-Thought (CCoT)，增强可行解空间的探索能力；结合Sigmoid门控机制，在满足硬性约束后优先处理软性约束", "result": "实验结果显示，TourPlanner在旅行规划基准测试中表现出色，超越现有方法，提高了计划可行性与用户偏好一致性", "conclusion": "提出了一种结合多路径推理和动态门控强化学习的框架，有效解决了旅行规划中的关键挑战"}}
{"id": "2601.04696", "pdf": "https://arxiv.org/pdf/2601.04696", "abs": "https://arxiv.org/abs/2601.04696", "authors": ["Huayi Liu"], "title": "A Method for Constructing a Digital Transformation Driving Mechanism Based on Semantic Understanding of Large Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "In the process of digital transformation, enterprises are faced with problems such as insufficient semantic understanding of unstructured data and lack of intelligent decision-making basis in driving mechanisms. This study proposes a method that combines a large language model (LLM) and a knowledge graph. First, a fine-tuned BERT (Bidirectional Encoder Representations from Transformers) model is used to perform entity recognition and relationship extraction on multi-source heterogeneous texts, and GPT-4 is used to generate semantically enhanced vector representations; secondly, a two-layer graph neural network (GNN) architecture is designed to fuse the semantic vectors output by LLM with business metadata to construct a dynamic and scalable enterprise knowledge graph; then reinforcement learning is introduced to optimize decision path generation, and the reward function is used to drive the mechanism iteration. In the case of the manufacturing industry, this mechanism reduced the response time for equipment failure scenarios from 7.8 hours to 3.7 hours, the F1 value reached 94.3%, and the compensation for decision errors in the annual digital transformation cost decreased by 45.3%. This method significantly enhances the intelligence level and execution efficiency of the digital transformation driving mechanism by integrating large model semantic understanding with structured knowledge.", "AI": {"tldr": "提出了一种基于大规模模型语义理解的数字化转型驱动机制方法。", "motivation": "企业在数字化转型过程中面临的问题包括对非结构化数据的语义理解不足和缺乏智能决策依据，因此需要一种新的方法来提高企业的智能化水平。", "method": "该研究结合大型语言模型（LLM）和知识图谱设计了一种新机制。首先使用微调后的BERT进行实体识别与关系提取，并利用GPT-4生成语义增强的向量表示；其次采用两层图形神经网络架构，融合语言模型输出的语义向量与业务元数据构建动态、可扩展的企业知识图谱；然后引入强化学习优化决策路径生成，使用奖励函数驱动机制迭代。", "result": "在制造行业中应用该方法，在设备故障场景中将响应时间从7.8小时缩短至3.7小时，F1值达到94.3%，每年数字化转型成本中的决策错误补偿减少45.3%。", "conclusion": "通过将大规模模型的语义理解与结构化知识相结合的方法显著提高了数字转型驱动机制的智能化水平和执行效率。"}}
{"id": "2601.04695", "pdf": "https://arxiv.org/pdf/2601.04695", "abs": "https://arxiv.org/abs/2601.04695", "authors": ["Enze Pan"], "title": "Tape: A Cellular Automata Benchmark for Evaluating Rule-Shift Generalization in Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": "4 tables", "summary": "We present Tape, a controlled reinforcement-learning benchmark designed to isolate out-of-distribution (OOD) failure under latent rule shifts.Tape is derived from one-dimensional cellular automata, enabling precise train/test splits where observation and action spaces are held fixed while transition rules change. Using a reproducible evaluation pipeline, we compare model-free baselines, model-based planning with learned world models, and task-inference (meta-RL) methods. A consistent pattern emerges: methods that are strong in-distribution (ID) can collapse under heldout-rule OOD, and high-variance OOD evaluation can make rankings unstable unless experiments are sufficiently replicated.We provide (i) standardized OOD protocols, (ii) statistical reporting requirements (seeds, confidence intervals, and hypothesis tests), and (iii) information-theoretic identities connecting entropy reduction to conditional mutual information and expected posterior KL divergence, clarifying what \"uncertainty reduction\" objectives can and cannot guarantee under rule shifts.", "AI": {"tldr": "提出Tape基准测试，用于评估强化学习模型在规则变化下的泛化能力。", "motivation": "为了更好地理解并解决强化学习中的分布外失败问题，在控制环境中设计了一种新基准以研究规则改变对模型性能的影响。", "method": "基于一维细胞自动机创建Tape任务，并通过可重复的评估管道比较不同类型的强化学习方法，包括无模型、基于模型的学习和元学习等。", "result": "结果表明，在分布内表现良好的方法可能在未知规则下失效；高方差的分布外评估会使得性能排名不稳定，除非充分复制实验。", "conclusion": "通过标准化分布外协议、统计报告要求及信息论身份连接来提高模型的泛化能力和不确定性降低目标的理解。"}}
{"id": "2601.04694", "pdf": "https://arxiv.org/pdf/2601.04694", "abs": "https://arxiv.org/abs/2601.04694", "authors": ["Zhilun Zhou", "Zihan Liu", "Jiahe Liu", "Qingyu Shao", "Yihan Wang", "Kun Shao", "Depeng Jin", "Fengli Xu"], "title": "ResMAS: Resilience Optimization in LLM-based Multi-agent Systems", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model-based Multi-Agent Systems (LLM-based MAS), where multiple LLM agents collaborate to solve complex tasks, have shown impressive performance in many areas. However, MAS are typically distributed across different devices or environments, making them vulnerable to perturbations such as agent failures. While existing works have studied the adversarial attacks and corresponding defense strategies, they mainly focus on reactively detecting and mitigating attacks after they occur rather than proactively designing inherently resilient systems. In this work, we study the resilience of LLM-based MAS under perturbations and find that both the communication topology and prompt design significantly influence system resilience. Motivated by these findings, we propose ResMAS: a two-stage framework for enhancing MAS resilience. First, we train a reward model to predict the MAS's resilience, based on which we train a topology generator to automatically design resilient topology for specific tasks through reinforcement learning. Second, we introduce a topology-aware prompt optimization method that refines each agent's prompt based on its connections and interactions with other agents. Extensive experiments across a range of tasks show that our approach substantially improves MAS resilience under various constraints. Moreover, our framework demonstrates strong generalization ability to new tasks and models, highlighting its potential for building resilient MASs.", "AI": {"tldr": "研究如何优化基于大型语言模型的多智能体系统（LLM-MAS）在面对扰动时的韧性。", "motivation": "现有的工作主要集中在攻击后的检测和缓解策略上，而不是设计具有内在韧性的系统。发现通信拓扑和提示设计对系统韧性有重大影响。", "method": "提出ResMAS框架，包括训练奖励模型预测系统韧性、通过强化学习生成具有韧性的拓扑结构以及基于智能体间连接优化提示的方法。", "result": "实验表明该方法能显著提高LLM-MAS在各种约束下的韧性，并展示出良好的泛化能力。", "conclusion": "提出了一种增强基于大型语言模型的多智能体系统韧性的框架，展示了其潜在的应用价值。"}}
{"id": "2601.04692", "pdf": "https://arxiv.org/pdf/2601.04692", "abs": "https://arxiv.org/abs/2601.04692", "authors": ["Naquee Rizwan", "Subhankar Swain", "Paramananda Bhaskar", "Gagan Aryan", "Shehryaar Shah Khan", "Animesh Mukherjee"], "title": "See, Explain, and Intervene: A Few-Shot Multimodal Agent Framework for Hateful Meme Moderation", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "In this work, we examine hateful memes from three complementary angles - how to detect them, how to explain their content and how to intervene them prior to being posted - by applying a range of strategies built on top of generative AI models. To the best of our knowledge, explanation and intervention have typically been studied separately from detection, which does not reflect real-world conditions. Further, since curating large annotated datasets for meme moderation is prohibitively expensive, we propose a novel framework that leverages task-specific generative multimodal agents and the few-shot adaptability of large multimodal models to cater to different types of memes. We believe this is the first work focused on generalizable hateful meme moderation under limited data conditions, and has strong potential for deployment in real-world production scenarios. Warning: Contains potentially toxic contents.", "AI": {"tldr": "构建一个多模态框架，用于检测、解释和干预仇恨梗图", "motivation": "现有研究通常将检测与解释或干预分开进行，未反映真实世界状况。同时，由于标注大量数据集成本过高，提出一种在有限数据条件下具有广泛应用前景的通用仇恨梗图管理系统", "method": "利用生成性AI模型和多模态大模型的少量样本适应能力来开发针对不同类型梗图的任务特定多模态代理框架", "result": "该框架能够在有限的数据条件下实现有效的检测、解释和干预功能，适用于真实世界的应用场景", "conclusion": "提出的方法是首个专注于在数据限制下进行通用仇恨梗图管理的工作，并具备部署于实际生产环境的潜力"}}
{"id": "2601.04688", "pdf": "https://arxiv.org/pdf/2601.04688", "abs": "https://arxiv.org/abs/2601.04688", "authors": ["Yanming Liu", "Xinyue Peng", "Jiannan Cao", "Xinyi Wang", "Songhang Deng", "Jintao Chen", "Jianwei Yin", "Xuhong Zhang"], "title": "ToolGate: Contract-Grounded and Verified Tool Execution for LLMs", "categories": ["cs.CL", "cs.AI", "cs.FL"], "comment": "First version of ToolGate", "summary": "Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex reasoning tasks. However, existing frameworks rely heavily on natural language reasoning to determine when tools can be invoked and whether their results should be committed, lacking formal guarantees for logical safety and verifiability. We present \\textbf{ToolGate}, a forward execution framework that provides logical safety guarantees and verifiable state evolution for LLM tool calling. ToolGate maintains an explicit symbolic state space as a typed key-value mapping representing trusted world information throughout the reasoning process. Each tool is formalized as a Hoare-style contract consisting of a precondition and a postcondition, where the precondition gates tool invocation by checking whether the current state satisfies the required conditions, and the postcondition determines whether the tool's result can be committed to update the state through runtime verification. Our approach guarantees that the symbolic state evolves only through verified tool executions, preventing invalid or hallucinated results from corrupting the world representation. Experimental validation demonstrates that ToolGate significantly improves the reliability and verifiability of tool-augmented LLM systems while maintaining competitive performance on complex multi-step reasoning tasks. This work establishes a foundation for building more trustworthy and debuggable AI systems that integrate language models with external tools.", "AI": {"tldr": "介绍了ToolGate框架，它通过正式的合同和运行时验证来保证语言模型使用外部工具的安全性和可验证性。", "motivation": "现有框架依赖于自然语言推理决定何时调用工具以及是否提交结果，缺乏逻辑安全性的正式保障。为此，提出了一种提供逻辑安全性保障和可验证状态演化的方案。", "method": "ToolGate维护一个显式的符号状态空间，表示信任的世界信息；每个工具都定义为包含前置条件和后置条件的Hoare式合同，并通过运行时验证来控制其执行。", "result": "实验表明，ToolGate在保证可靠性的同时，在复杂多步骤推理任务中的表现依然具有竞争力。", "conclusion": "该研究建立了一个基础框架，用于构建更加可信且可调试的语言模型与外部工具集成的AI系统。"}}
{"id": "2601.04687", "pdf": "https://arxiv.org/pdf/2601.04687", "abs": "https://arxiv.org/abs/2601.04687", "authors": ["Ali Kurban", "Wei Luo", "Liangyu Zuo", "Zeyu Zhang", "Renda Han", "Zhaolu Kang", "Hao Tang"], "title": "WebCryptoAgent: Agentic Crypto Trading with Web Informatics", "categories": ["cs.CV"], "comment": null, "summary": "Cryptocurrency trading increasingly depends on timely integration of heterogeneous web information and market microstructure signals to support short-horizon decision making under extreme volatility. However, existing trading systems struggle to jointly reason over noisy multi-source web evidence while maintaining robustness to rapid price shocks at sub-second timescales. The first challenge lies in synthesizing unstructured web content, social sentiment, and structured OHLCV signals into coherent and interpretable trading decisions without amplifying spurious correlations, while the second challenge concerns risk control, as slow deliberative reasoning pipelines are ill-suited for handling abrupt market shocks that require immediate defensive responses. To address these challenges, we propose WebCryptoAgent, an agentic trading framework that decomposes web-informed decision making into modality-specific agents and consolidates their outputs into a unified evidence document for confidence-calibrated reasoning. We further introduce a decoupled control architecture that separates strategic hourly reasoning from a real-time second-level risk model, enabling fast shock detection and protective intervention independent of the trading loop. Extensive experiments on real-world cryptocurrency markets demonstrate that WebCryptoAgent improves trading stability, reduces spurious activity, and enhances tail-risk handling compared to existing baselines. Code will be available at https://github.com/AIGeeksGroup/WebCryptoAgent.", "AI": {"tldr": "本文提出了WebCryptoAgent，一个基于网络信息的加密货币交易框架，旨在提高决策质量和风险控制能力。", "motivation": "现有加密货币交易系统难以整合多源网络信息并应对价格波动带来的挑战。", "method": "WebCryptoAgent通过特定模态代理合成不同来源的信息，并采用分层架构实现快速风险控制。", "result": "实验表明，WebCryptoAgent能提升交易稳定性、减少不必要活动，并增强尾部风险管理能力。", "conclusion": "该框架成功解决了加密货币交易中信息整合与实时风险控制的难题。"}}
{"id": "2601.04686", "pdf": "https://arxiv.org/pdf/2601.04686", "abs": "https://arxiv.org/abs/2601.04686", "authors": ["Oluwatosin Oseni", "Shengjie Wang", "Jun Zhu", "Micah Corah"], "title": "Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead", "categories": ["cs.LG", "cs.RO"], "comment": "RSS'25: Multi-Objective Optimization and Planning in Robotics Workshop: 5 pages, 8 figures", "summary": "Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.", "AI": {"tldr": "夜魇梦者通过学习世界模型来预测潜在的安全违规行为，并据此规划行动，从而在保证安全的同时最大化奖励。", "motivation": "强化学习在现实世界的应用中取得了显著的成功，尤其是在机器人控制方面。然而，由于缺乏足够的安全性保障，RL的采用仍然受到限制。为此，我们提出了夜魇梦者算法，以解决安全问题。", "method": "Nightmare Dreamer利用一个已学得的世界模型来预测可能的安全违规情况，并据此规划行动策略，从而在确保安全的同时最大化奖励。", "result": "Nightmare Dreamer在使用图像观察的Safety Gymnasium任务上显著优于基于模型的方法，效率提高了近20倍。", "conclusion": "通过引入Nightmare Dreamer算法，我们能够几乎避免所有的安全违规情况，并且在保证高效率的同时最大化奖励。"}}
{"id": "2601.04682", "pdf": "https://arxiv.org/pdf/2601.04682", "abs": "https://arxiv.org/abs/2601.04682", "authors": ["Yang Zou", "Xingyue Zhu", "Kaiqi Han", "Jun Ma", "Xingyuan Li", "Zhiying Jiang", "Jinyuan Liu"], "title": "HATIR: Heat-Aware Diffusion for Turbulent Infrared Video Super-Resolution", "categories": ["cs.CV"], "comment": null, "summary": "Infrared video has been of great interest in visual tasks under challenging environments, but often suffers from severe atmospheric turbulence and compression degradation. Existing video super-resolution (VSR) methods either neglect the inherent modality gap between infrared and visible images or fail to restore turbulence-induced distortions. Directly cascading turbulence mitigation (TM) algorithms with VSR methods leads to error propagation and accumulation due to the decoupled modeling of degradation between turbulence and resolution. We introduce HATIR, a Heat-Aware Diffusion for Turbulent InfraRed Video Super-Resolution, which injects heat-aware deformation priors into the diffusion sampling path to jointly model the inverse process of turbulent degradation and structural detail loss. Specifically, HATIR constructs a Phasor-Guided Flow Estimator, rooted in the physical principle that thermally active regions exhibit consistent phasor responses over time, enabling reliable turbulence-aware flow to guide the reverse diffusion process. To ensure the fidelity of structural recovery under nonuniform distortions, a Turbulence-Aware Decoder is proposed to selectively suppress unstable temporal cues and enhance edge-aware feature aggregation via turbulence gating and structure-aware attention. We built FLIR-IVSR, the first dataset for turbulent infrared VSR, comprising paired LR-HR sequences from a FLIR T1050sc camera (1024 X 768) spanning 640 diverse scenes with varying camera and object motion conditions. This encourages future research in infrared VSR. Project page: https://github.com/JZ0606/HATIR", "AI": {"tldr": "该论文提出了HATIR，一种用于湍流红外视频超分辨率的热感知扩散方法。", "motivation": "现有视频超分辨率方法往往忽略了红外和可见图像之间的固有模态差距，并且无法恢复湍流引起的失真。直接将湍流抑制算法与VSR方法级联会导致误差传播和累积，因为它们在降质建模中是解耦的。", "method": "HATIR通过在扩散采样路径中注入热感知变形先验来联合建模湍流退化逆过程及结构细节损失。具体而言，它构建了一个基于物理原理的时间一致相位响应的涡旋引导流动估计器，并提出了一种可选择抑制不稳定时间线索并增强边缘感知特性聚合的涡旋感知解码器。", "result": "该论文建立了一个用于湍流红外视频超分辨率的数据集FLIR-IVSR，包含640个不同场景下从FLIR T1050sc相机获取的低分辨率和高分辨率序列对。", "conclusion": "HATIR可以有效地恢复由于大气湍流导致失真的红外视频，并鼓励未来在该领域的进一步研究。"}}
{"id": "2601.04680", "pdf": "https://arxiv.org/pdf/2601.04680", "abs": "https://arxiv.org/abs/2601.04680", "authors": ["Chaerin Yu", "Chihun Choi", "Sunjae Lee", "Hyosu Kim", "Steven Y. Ko", "Young-Bae Ko", "Sangeun Oh"], "title": "Leveraging LLMs for Efficient and Personalized Smart Home Automation", "categories": ["cs.HC"], "comment": null, "summary": "The proliferation of smart home devices has increased the complexity of controlling and managing them, leading to user fatigue. In this context, large language models (LLMs) offer a promising solution by enabling natural-language interfaces for Internet of Things (IoT) control. However, existing LLM-based approaches suffer from unreliable and inefficient device control due to the non-deterministic nature of LLMs, high inference latency and cost, and limited personalization. To address these challenges, we present IoTGPT, an LLM-based smart home agent designed to execute IoT commands in a reliable, efficient, and personalized manner. Inspired by how humans manage complex tasks, IoTGPT decomposes user instructions into subtasks and memorizes them. By reusing learned subtasks, subsequent instructions can be processed more efficiently with fewer LLM calls, improving reliability and reducing both latency and cost. IoTGPT also supports fine-grained personalization by adapting individual subtasks to user preferences. Our evaluation demonstrates that IoTGPT outperforms baselines in accuracy, latency/cost, and personalization, while reducing user workload.", "AI": {"tldr": "本文提出了一种基于大型语言模型的智能家居代理IoTGPT，通过分解用户指令和重用学习到的任务子步骤来提高控制效率、可靠性和个性化。", "motivation": "由于现有基于LLM的方法在设备控制中存在不可靠性、高延迟及成本以及有限的个性化问题，本文旨在开发一种更高效且个性化的智能家居解决方案。", "method": "IoTGPT通过将用户指令分解为子任务并记忆这些子任务来实现高效的设备控制。这种方法减少了后续指令处理所需的LLM调用次数，提高了可靠性，并降低了延迟和成本。", "result": "实验表明，IoTGPT在准确率、延迟/成本及个性化方面均优于基线方法，同时减轻了用户的工作负担。", "conclusion": "本文通过引入IoTGPT解决了现有基于LLM的智能家居控制中面临的挑战，提高了系统的效率、可靠性和个性化水平。"}}
{"id": "2601.04676", "pdf": "https://arxiv.org/pdf/2601.04676", "abs": "https://arxiv.org/abs/2601.04676", "authors": ["Qiu Guan", "Zhiqiang Yang", "Dezhang Ye", "Yang Chen", "Xinli Xu", "Ying Tang"], "title": "DB-MSMUNet:Dual Branch Multi-scale Mamba UNet for Pancreatic CT Scans Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate segmentation of the pancreas and its lesions in CT scans is crucial for the precise diagnosis and treatment of pancreatic cancer. However, it remains a highly challenging task due to several factors such as low tissue contrast with surrounding organs, blurry anatomical boundaries, irregular organ shapes, and the small size of lesions. To tackle these issues, we propose DB-MSMUNet (Dual-Branch Multi-scale Mamba UNet), a novel encoder-decoder architecture designed specifically for robust pancreatic segmentation. The encoder is constructed using a Multi-scale Mamba Module (MSMM), which combines deformable convolutions and multi-scale state space modeling to enhance both global context modeling and local deformation adaptation. The network employs a dual-decoder design: the edge decoder introduces an Edge Enhancement Path (EEP) to explicitly capture boundary cues and refine fuzzy contours, while the area decoder incorporates a Multi-layer Decoder (MLD) to preserve fine-grained details and accurately reconstruct small lesions by leveraging multi-scale deep semantic features. Furthermore, Auxiliary Deep Supervision (ADS) heads are added at multiple scales to both decoders, providing more accurate gradient feedback and further enhancing the discriminative capability of multi-scale features. We conduct extensive experiments on three datasets: the NIH Pancreas dataset, the MSD dataset, and a clinical pancreatic tumor dataset provided by collaborating hospitals. DB-MSMUNet achieves Dice Similarity Coefficients of 89.47%, 87.59%, and 89.02%, respectively, outperforming most existing state-of-the-art methods in terms of segmentation accuracy, edge preservation, and robustness across different datasets. These results demonstrate the effectiveness and generalizability of the proposed method for real-world pancreatic CT segmentation tasks.", "AI": {"tldr": "本文提出了一种新的双分支多尺度Mamba UNet（DB-MSMUNet）网络用于胰腺CT图像分割。", "motivation": "准确分割胰腺及其病灶在诊断和治疗胰腺癌中至关重要，但由于低对比度、模糊边界等问题，这是一个挑战性的任务。本文旨在通过提出新颖的架构来解决这些问题。", "method": "该模型采用多尺度Mamba模块作为编码器，结合可变形卷积与多尺度状态空间模型增强全局上下文建模和局部形变适应能力；同时设计了边缘解码器引入边缘增强路径（EEP）捕捉边界线索，并使用多个辅助监督头提高梯度反馈准确性。", "result": "实验结果显示，在三个数据集上，DB-MSMUNet的Dice相似系数分别为89.47%，87.59%和89.02%，优于大多数现有方法在分割精度、边缘保持能力和跨不同数据集鲁棒性方面。", "conclusion": "该研究展示了所提出的方法在真实世界胰腺CT图像分割任务中的有效性和泛化能力。"}}
{"id": "2601.04675", "pdf": "https://arxiv.org/pdf/2601.04675", "abs": "https://arxiv.org/abs/2601.04675", "authors": ["Kunhang Lv", "Yuhang Dong", "Rui Han", "Fuqi Jia", "Feifei Ma", "Jian Zhang"], "title": "LLM-Guided Quantified SMT Solving over Uninterpreted Functions", "categories": ["cs.AI"], "comment": null, "summary": "Quantified formulas with Uninterpreted Functions (UFs) over non-linear real arithmetic pose fundamental challenges for Satisfiability Modulo Theories (SMT) solving. Traditional quantifier instantiation methods struggle because they lack semantic understanding of UF constraints, forcing them to search through unbounded solution spaces with limited guidance. We present AquaForte, a framework that leverages Large Language Models to provide semantic guidance for UF instantiation by generating instantiated candidates for function definitions that satisfy the constraints, thereby significantly reducing the search space and complexity for solvers. Our approach preprocesses formulas through constraint separation, uses structured prompts to extract mathematical reasoning from LLMs, and integrates the results with traditional SMT algorithms through adaptive instantiation. AquaForte maintains soundness through systematic validation: LLM-guided instantiations yielding SAT solve the original problem, while UNSAT results generate exclusion clauses for iterative refinement. Completeness is preserved by fallback to traditional solvers augmented with learned constraints. Experimental evaluation on SMT-COMP benchmarks demonstrates that AquaForte solves numerous instances where state-of-the-art solvers like Z3 and CVC5 timeout, with particular effectiveness on satisfiable formulas. Our work shows that LLMs can provide valuable mathematical intuition for symbolic reasoning, establishing a new paradigm for SMT constraint solving.", "AI": {"tldr": "本文提出了AquaForte框架，通过大型语言模型提供语义指导来解决包含未解释函数的量化公式问题。", "motivation": "传统的量词实例化方法在处理非线性实数算术中的未解释函数约束时面临挑战，缺乏语义理解导致搜索无界解空间。", "method": "AquaForte通过预处理公式分离约束、使用结构化提示从大型语言模型中提取数学推理，并与传统SMT算法集成以适应实例化方法。", "result": "实验评估显示，AquaForte在解决SMT-COMP基准测试中的问题上比Z3和CVC5等最先进的求解器更为有效，特别是在可满足性公式方面表现尤为突出。", "conclusion": "大型语言模型能够为符号推理提供有价值的数学直觉，确立了新的SMT约束求解范式。"}}
{"id": "2601.04673", "pdf": "https://arxiv.org/pdf/2601.04673", "abs": "https://arxiv.org/abs/2601.04673", "authors": ["Aurghya Maiti", "Prateek Jain"], "title": "Estimating Causal Effects in Gaussian Linear SCMs with Finite Data", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at the Workshop on Scaling Up Intervention Models at the 42nd International Conference on Machine Learning (ICML 2025)", "summary": "Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.", "AI": {"tldr": "本文提出了中央化高斯线性结构因果模型（CGL-SCM），并提出了一种基于EM算法的参数估计方法，用于从有限观测样本中准确估计因果效应。", "motivation": "在存在潜在混淆变量的情况下，从观察数据中估算因果效应是一个基本挑战。传统的Gaussian Linear Structural Causal Models（GL-SCMs）由于过度参数化而在有限的数据下难以实现参数估计。", "method": "本文引入了中央化高斯线性结构因果模型（CGL-SCMs），并通过标准化分布简化了外生变量的表达，并提出了一种基于EM算法的学习方法，用于从观察样本中估算可识别的因果效应。", "result": "通过合成数据和基准因果图实验验证了所提出的理论分析的有效性，证明学习到的模型可以准确恢复因果分布。", "conclusion": "本文为估计高斯线性结构因果模型中的因果效应提供了一个有效的方法，该方法基于中央化简化模型和EM算法，在有限的数据中表现出良好的性能。"}}
{"id": "2601.04672", "pdf": "https://arxiv.org/pdf/2601.04672", "abs": "https://arxiv.org/abs/2601.04672", "authors": ["Wentao Zhang", "Lifei Wang", "Lina Lu", "MingKun Xu", "Shangyang Li", "Yanchao Yang", "Tao Fang"], "title": "Agri-R1: Empowering Generalizable Agricultural Reasoning in Vision-Language Models with Reinforcement Learning", "categories": ["cs.CV", "cs.CL"], "comment": "This paper is submitted for review to ACL 2026. It is 17 pages long and includes 5 figures. The corresponding authors are Tao Fang and Lina Lu", "summary": "Agricultural disease diagnosis challenges VLMs, as conventional fine-tuning requires extensive labels, lacks interpretability, and generalizes poorly. While reasoning improves model robustness, existing methods rely on costly expert annotations and rarely address the open-ended, diverse nature of agricultural queries. To address these limitations, we propose \\textbf{Agri-R1}, a reasoning-enhanced large model for agriculture. Our framework automates high-quality reasoning data generation via vision-language synthesis and LLM-based filtering, using only 19\\% of available samples. Training employs Group Relative Policy Optimization (GRPO) with a novel proposed reward function that integrates domain-specific lexicons and fuzzy matching to assess both correctness and linguistic flexibility in open-ended responses. Evaluated on CDDMBench, our resulting 3B-parameter model achieves performance competitive with 7B- to 13B-parameter baselines, showing a +23.2\\% relative gain in disease recognition accuracy, +33.3\\% in agricultural knowledge QA, and a +26.10-point improvement in cross-domain generalization over standard fine-tuning. Ablation studies confirm that the synergy between structured reasoning data and GRPO-driven exploration underpins these gains, with benefits scaling as question complexity increases.", "AI": {"tldr": "该论文提出了一种名为Agri-R1的增强型视觉语言模型，用于农业领域的问题解答和疾病诊断。", "motivation": "传统细调方法需要大量的标注数据，并且在解释性和泛化性方面表现不佳。现有的基于推理的方法依赖昂贵的专业注释并且难以处理开放式、多样化的农业查询问题。", "method": "Agri-R1利用视觉语言合成和大型语言模型过滤自动生成高质量的推理数据，仅使用了19%的可用样本，并采用相对策略优化（GRPO）训练方法。奖励函数结合领域特定词汇表和模糊匹配评估开放性响应的正确性和语言灵活性。", "result": "在CDDMBench上测试后，该模型实现了与更大参数量基线相当的表现，在疾病识别准确率、农业知识问答以及跨域泛化能力方面分别提高了23.2%，33.3%和26.10点。", "conclusion": "实验结果表明，结构化推理数据与GRPO驱动的探索之间的协同作用是性能提升的关键因素，并且这种改进随着问题复杂性的增加而增强。"}}
{"id": "2601.04668", "pdf": "https://arxiv.org/pdf/2601.04668", "abs": "https://arxiv.org/abs/2601.04668", "authors": ["Laukik Patade", "Rohan Rane", "Sandeep Pillai"], "title": "Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "This study focuses on optimizing path planning for unmanned ground vehicles (UGVs) in precision agriculture using deep reinforcement learning (DRL) techniques in continuous action spaces. The research begins with a review of traditional grid-based methods, such as A* and Dijkstra's algorithms, and discusses their limitations in dynamic agricultural environments, highlighting the need for adaptive learning strategies. The study then explores DRL approaches, including Deep Q-Networks (DQN), which demonstrate improved adaptability and performance in two-dimensional simulations. Enhancements such as Double Q-Networks and Dueling Networks are evaluated to further improve decision-making. Building on these results, the focus shifts to continuous action space models, specifically Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3), which are tested in increasingly complex environments. Experiments conducted in a three-dimensional environment using ROS and Gazebo demonstrate the effectiveness of continuous DRL algorithms in navigating dynamic agricultural scenarios. Notably, the pretrained TD3 agent achieves a 95 percent success rate in dynamic environments, demonstrating the robustness of the proposed approach in handling moving obstacles while ensuring safety for both crops and the robot.", "AI": {"tldr": "优化无人地面车辆（UGV）在精准农业中的路径规划，使用深度强化学习（DRL）技术", "motivation": "传统网格化方法如A*和迪杰斯特拉算法存在局限性，在动态农业环境中表现不佳。需要更灵活的学习策略来应对复杂情况。", "method": "从传统的基于格子的方法开始研究，逐步探讨深度Q网络（DQN），改进的双层Q学习、斗篷网络模型等，并最终转向连续行动空间模型如DDPG和TD3进行实验验证。", "result": "在三维动态环境中使用ROS和Gazebo进行测试，预训练的TD3代理表现出95%的成功率，展示出处理移动障碍的能力并确保作物和机器的安全性。", "conclusion": "研究证明了DRL技术尤其是连续行动空间模型的有效性和鲁棒性，在精准农业中优化路径规划。"}}
{"id": "2601.04666", "pdf": "https://arxiv.org/pdf/2601.04666", "abs": "https://arxiv.org/abs/2601.04666", "authors": ["Zhiyuan Chang", "Mingyang Li", "Yuekai Huang", "Ziyou Jiang", "Xiaojun Jia", "Qian Xiong", "Junjie Wang", "Zhaoyang Li", "Qing Wang"], "title": "Know Thy Enemy: Securing LLMs Against Prompt Injection via Diverse Data Synthesis and Instruction-Level Chain-of-Thought Learning", "categories": ["cs.AI", "cs.CR"], "comment": "19 pages, 6 figures", "summary": "Large language model (LLM)-integrated applications have become increasingly prevalent, yet face critical security vulnerabilities from prompt injection (PI) attacks. Defending against PI attacks faces two major issues: malicious instructions can be injected through diverse vectors, and injected instructions often lack clear semantic boundaries from the surrounding context, making them difficult to identify. To address these issues, we propose InstruCoT, a model enhancement method for PI defense that synthesizes diverse training data and employs instruction-level chain-of-thought fine-tuning, enabling LLMs to effectively identify and reject malicious instructions regardless of their source or position in the context. We evaluate InstruCoT across three critical dimensions: Behavior Deviation, Privacy Leakage, and Harmful Output. Experimental results across four LLMs demonstrate that InstruCoT significantly outperforms baselines in all dimensions while maintaining utility performance without degradation", "AI": {"tldr": "本文提出了一种名为InstruCoT的方法，通过多样化数据合成和指令级链式思维微调来防御大规模语言模型中的提示注入攻击。", "motivation": "随着大型语言模型集成应用的普及，这些系统面临着来自各种向量的恶意指令注入的安全隐患。这些注入的指令由于缺乏明显的语义边界，难以被有效检测。", "method": "InstruCoT通过合成多样化训练数据和实施基于指令级别的链式思维微调来增强模型防御能力，使其能更有效地识别并拒绝任何位置、来源的恶意指令。", "result": "实验结果表明，在行为偏差、隐私泄露和有害输出三个维度上，与基线相比，InstruCoT在所有方面都表现出显著优势，并且没有降低性能。", "conclusion": "InstruCoT有效增强了大型语言模型的安全性，使其能够在不牺牲实用性的情况下防御提示注入攻击。"}}
{"id": "2601.04664", "pdf": "https://arxiv.org/pdf/2601.04664", "abs": "https://arxiv.org/abs/2601.04664", "authors": ["Yifan Le", "Yunliang Li"], "title": "CRANE: Causal Relevance Analysis of Language-Specific Neurons in Multilingual Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 6 figures. Work in progress", "summary": "Multilingual large language models (LLMs) achieve strong performance across languages, yet how language capabilities are organized at the neuron level remains poorly understood. Prior work has identified language-related neurons mainly through activation-based heuristics, which conflate language preference with functional importance. Prior work has identified language-related neurons mainly through activation-based heuristics, which conflate language preference with functional importance. We propose CRANE, a relevance-based analysis framework that redefines language specificity in terms of functional necessity, identifying language-specific neurons through targeted neuron-level interventions. CRANE characterizes neuron specialization by their contribution to language-conditioned predictions rather than activation magnitude. Our implementation will be made publicly available. Neuron-level interventions reveal a consistent asymmetric pattern: masking neurons relevant to a target language selectively degrades performance on that language while preserving performance on other languages to a substantial extent, indicating language-selective but non-exclusive neuron specializations. Experiments on English, Chinese, and Vietnamese across multiple benchmarks, together with a dedicated relevance-based metric and base-to-chat model transfer analysis, show that CRANE isolates language-specific components more precisely than activation-based methods.", "AI": {"tldr": "CRANE 是一种基于相关性的分析框架，用于识别多语言大型语言模型中特定于某一种语言的神经元。", "motivation": "当前对于如何在神经层面组织语言能力的理解仍然不足。以前的工作主要通过激活基线启发式方法来识别与语言相关的神经元，这种方法将语言偏好与功能重要性混淆。", "method": "CRANE 使用有针对性的神经元级干预，根据对基于条件的语言预测的贡献而不是激活量来定义语言特异性。这表明了语言选择但非独占性的神经元专业化。", "result": "实验结果证明 CRANE 能更准确地分离出特定于某种语言的组件，优于依赖于激活的方法。", "conclusion": "CRANE 提供了一种新的分析方法来理解多语言大型语言模型中的语言特异性，并揭示了关于如何组织语言能力的新见解。"}}
{"id": "2601.04658", "pdf": "https://arxiv.org/pdf/2601.04658", "abs": "https://arxiv.org/abs/2601.04658", "authors": ["Hyeongkeun Lee", "Jongmin Choi", "KiHyun Nam", "Joon Son Chung"], "title": "LAMB: LLM-based Audio Captioning with Modality Gap Bridging via Cauchy-Schwarz Divergence", "categories": ["cs.SD", "cs.AI"], "comment": "5 pages, 2 figures;", "summary": "Automated Audio Captioning aims to describe the semantic content of input audio. Recent works have employed large language models (LLMs) as a text decoder to leverage their reasoning capabilities. However, prior approaches that project audio features into the LLM embedding space without considering cross-modal alignment fail to fully utilize these capabilities. To address this, we propose LAMB, an LLM-based audio captioning framework that bridges the modality gap between audio embeddings and the LLM text embedding space. LAMB incorporates a Cross-Modal Aligner that minimizes Cauchy-Schwarz divergence while maximizing mutual information, yielding tighter alignment between audio and text at both global and token levels. We further design a Two-Stream Adapter that extracts semantically enriched audio embeddings, thereby delivering richer information to the Cross-Modal Aligner. Finally, leveraging the aligned audio embeddings, a proposed Token Guide directly computes scores within the LLM text embedding space to steer the output logits of generated captions. Experimental results confirm that our framework strengthens the reasoning capabilities of the LLM decoder, achieving state-of-the-art performance on AudioCaps.", "AI": {"tldr": "提出了一种基于大型语言模型的音频字幕生成框架LAMB，通过最小化柯西-施瓦茨散度和最大化互信息来解决模态差距问题。", "motivation": "现有方法在将音频特征投影到LLM嵌入空间时未能充分考虑跨模态对齐，导致无法完全利用大型语言模型的推理能力。LAMB旨在通过改进模态对齐技术提升生成音频字幕的质量和性能。", "method": "提出了一个两阶段适应器系统：第一阶段使用跨模态对准器最小化柯西-施瓦茨散度并最大化互信息；第二阶段设计了双流适配器用于提取语义丰富的音频嵌入，并引入令牌指导机制直接计算生成字幕的分数。", "result": "实验表明，LAMB框架显著增强了LLM解码器的推理能力，在AudioCaps数据集上达到了最先进的性能。", "conclusion": "通过改进跨模态对齐技术，LAMB实现了更高质量和更高准确度的音频字幕生成。"}}
{"id": "2601.04657", "pdf": "https://arxiv.org/pdf/2601.04657", "abs": "https://arxiv.org/abs/2601.04657", "authors": ["Takafumi Sakamoto", "Yugo Takeuchi"], "title": "Model of Spatial Human-Agent Interaction with Consideration for Others", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Communication robots often need to initiate conversations with people in public spaces. At the same time, such robots must not disturb pedestrians. To handle these two requirements, an agent needs to estimate the communication desires of others based on their behavior and then adjust its own communication activities accordingly. In this study, we construct a computational spatial interaction model that considers others. Consideration is expressed as a quantitative parameter: the amount of adjustment of one's internal state to the estimated internal state of the other. To validate the model, we experimented with a human and a virtual robot interacting in a VR environment. The results show that when the participant moves to the target, a virtual robot with a low consideration value inhibits the participant's movement, while a robot with a higher consideration value did not inhibit the participant's movement. When the participant approached the robot, the robot also exhibited approaching behavior, regardless of the consideration value, thus decreasing the participant's movement. These results appear to verify the proposed model's ability to clarify interactions with consideration for others.", "AI": {"tldr": "构建了一个考虑他人的空间交互模型，用于评估机器人在公共场所中的交流活动。", "motivation": "为了使通信机器人能够在不干扰行人的前提下开始与人们的对话，需要根据他人的行为估计他们的沟通意愿，并相应地调整自己的沟通活动。", "method": "通过VR环境实验，在虚拟环境中让参与者和一个虚拟机器人进行互动，验证了模型的有效性。", "result": "具有低考虑值的虚拟机器人会抑制参与者的移动，而具有高考虑值的机器人则不会。无论考虑值如何，当参与者接近机器人时，机器人都会展现出接近的行为，并减少参与者的移动。", "conclusion": "实验结果验证了所提出的模型能够明确地解释考虑到他人的互动行为。"}}
{"id": "2601.04656", "pdf": "https://arxiv.org/pdf/2601.04656", "abs": "https://arxiv.org/abs/2601.04656", "authors": ["Dekun Chen", "Xueyao Zhang", "Yuancheng Wang", "Kenan Dai", "Li Ma", "Zhizheng Wu"], "title": "FlexiVoice: Enabling Flexible Style Control in Zero-Shot TTS with Natural Language Instructions", "categories": ["cs.SD"], "comment": null, "summary": "This study proposes FlexiVoice, a text-to-speech (TTS) synthesis system capable of flexible style control with zero-shot voice cloning. The speaking style is controlled by a natural-language instruction and the voice timbre is provided by a speech reference in zero-shot manner. FlexiVoice is built with an LLM core, which takes text as input, and also takes an optional natural language instruction and an optional speech reference to control style and timbre, respectively. FlexiVoice is equipped with a novel Progressive Post-Training (PPT) scheme that progressively unlocks accurate and flexible controllability. In particular, it first employs Direct Preference Optimization (DPO) to enable FlexiVoice to accurately follow both natural language instruction and speech reference simultaneously. It then uses a multi-objective Group Relative Policy Optimization (GRPO) to disentangle style instruction, reference timbre, and textual content. Finally, it adapts instruction GRPO for more advanced instruction following. Experimental results show that FlexiVoice surpasses competing baselines and demonstrates strong capability in decoupling control factors. Human evaluations further confirm its naturalness, controllability, and robustness. Audio samples are available at https://flexi-voice.github.io.", "AI": {"tldr": "本文提出了一种基于自然语言指令和语音参考的零样本说话风格控制文本转语音系统FlexiVoice。", "motivation": "旨在提供一种能够灵活控制说话风格且无需大量训练数据的文本转语音系统，以实现准确且可控的声音合成。", "method": "利用一个大型语言模型核心，并引入了一种渐进式后期训练（PPT）方案来解锁精确和灵活的控件。该方案包含直接偏好优化（DPO），多目标组相对策略优化（GRPO），以及更先进的指令跟随优化。", "result": "实验结果显示，FlexiVoice超越了竞争基线，并展示了强大的解耦控制因素能力。人类评估进一步确认其自然性、可控性和鲁棒性。", "conclusion": "通过引入新的方法和技术，FlexiVoice成功地实现了零样本说话风格和音色的灵活控制，并且在多种指标上表现优异。"}}
{"id": "2601.04654", "pdf": "https://arxiv.org/pdf/2601.04654", "abs": "https://arxiv.org/abs/2601.04654", "authors": ["Ryutaro Oshima", "Yuya Hosoda", "Youji Iiguni"], "title": "LLMs-Integrated Automatic Hate Speech Recognition Using Controllable Text Generation Models", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "In Proceedings of the 17th Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC 2025)", "summary": "This paper proposes an automatic speech recognition (ASR) model for hate speech using large language models (LLMs). The proposed method integrates the encoder of the ASR model with the decoder of the LLMs, enabling simultaneous transcription and censorship tasks to prevent the exposure of harmful content. Instruction tuning of the LLM to mask hate-related words with specific tokens requires an annotated hate speech dataset, which is limited. We generate text samples using an LLM with the Chain-of-Thought (CoT) prompting technique guided by cultural context and examples and then convert them into speech samples using a text-to-speech (TTS) system. However, some of them contain non-hate speech samples with hate-related words, which degrades the censorship performance. This paper filters the samples which text classification models correctly label as hate content. By adjusting the threshold for the number of correct answer models, we can control the level of hate in the generated dataset, allowing us to train the LLMs through curriculum learning in a gradual manner. Experimental results show that the proposed method achieves a masking accuracy of 58.6\\% for hate-related words, surpassing previous baselines. We also confirm that the curriculum training contributes to the efficiency of both transcription and censorship tasks.", "AI": {"tldr": "提出了一种结合自动语音识别和大型语言模型的仇恨言论识别系统，通过生成带有文化背景的文本样本进行训练，并提高对有害内容的屏蔽精度。", "motivation": "为了更有效地防止有害内容的传播，研究人员希望改进现有系统的性能，特别是在处理有限标注数据集的情况下。", "method": "将自动语音识别模型与大型语言模型结合使用，采用链式思维引导生成具有文化背景的文本样本，并通过多个文本分类器筛选这些样本以提高训练质量。", "result": "该方法实现了58.6%的屏蔽准确性，在先前基线之上有所提升，同时证实了课程学习有助于提高转录和审查任务效率。", "conclusion": "所提出的方法在识别和屏蔽仇恨言论方面表现良好，并展示了通过文化背景引导生成样本的有效性。"}}
{"id": "2601.04653", "pdf": "https://arxiv.org/pdf/2601.04653", "abs": "https://arxiv.org/abs/2601.04653", "authors": ["Zhe Hou"], "title": "Vibe Coding an LLM-powered Theorem Prover", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We present Isabellm, an LLM-powered theorem prover for Isabelle/HOL that performs fully automatic proof synthesis. Isabellm works with any local LLM on Ollama and APIs such as Gemini CLI, and it is designed to run on consumer grade computers. The system combines a stepwise prover, which uses large language models to propose proof commands validated by Isabelle in a bounded search loop, with a higher-level proof planner that generates structured Isar outlines and attempts to fill and repair remaining gaps. The framework includes beam search for tactics, tactics reranker ML and RL models, premise selection with small transformer models, micro-RAG for Isar proofs built from AFP, and counter-example guided proof repair. All the code is implemented by GPT 4.1 - 5.2, Gemini 3 Pro, and Claude 4.5. Empirically, Isabellm can prove certain lemmas that defeat Isabelle's standard automation, including Sledgehammer, demonstrating the practical value of LLM-guided proof search. At the same time, we find that even state-of-the-art LLMs, such as GPT 5.2 Extended Thinking and Gemini 3 Pro struggle to reliably implement the intended fill-and-repair mechanisms with complex algorithmic designs, highlighting fundamental challenges in LLM code generation and reasoning. The code of Isabellm is available at https://github.com/zhehou/llm-isabelle", "AI": {"tldr": "Isabellm是一个基于大型语言模型的自动定理证明器，旨在辅助Isabelle/HOL系统进行复杂逻辑推理。", "motivation": "为了提高自动化定理证明能力，特别是在处理复杂算法设计时，提出了一种结合了LLM和传统搜索策略的新方法。", "method": "通过使用大型语言模型（如GPT、Gemini等）生成初步的证明步骤，并利用Isabelle验证这些步骤的有效性。此外，引入了一个高级规划器来生成结构化的Isar大纲并填补缺失的部分。", "result": "Isabellm能够解决一些标准自动化方法无法处理的问题，但发现即使是最先进的LLM在实现复杂的填充和修复机制时也存在困难。", "conclusion": "尽管大型语言模型可以显著增强定理证明的能力，但在精确执行算法设计方面仍面临挑战。"}}
{"id": "2601.04651", "pdf": "https://arxiv.org/pdf/2601.04651", "abs": "https://arxiv.org/abs/2601.04651", "authors": ["Can Xu", "Lingyong Yan", "Jiayi Wu", "Haosen Wang", "Shuaiqiang Wang", "Yuchen Li", "Jizhou Huang", "Dawei Yin", "Xiang Li"], "title": "Adversarial Yet Cooperative: Multi-Perspective Reasoning in Retrieved-Augmented Language Models", "categories": ["cs.AI", "cs.IR", "cs.MA"], "comment": null, "summary": "Recent advances in synergizing large reasoning models (LRMs) with retrieval-augmented generation (RAG) have shown promising results, yet two critical challenges remain: (1) reasoning models typically operate from a single, unchallenged perspective, limiting their ability to conduct deep, self-correcting reasoning over external documents, and (2) existing training paradigms rely excessively on outcome-oriented rewards, which provide insufficient signal for shaping the complex, multi-step reasoning process. To address these issues, we propose an Reasoner-Verifier framework named Adversarial Reasoning RAG (ARR). The Reasoner and Verifier engage in reasoning on retrieved evidence and critiquing each other's logic while being guided by process-aware advantage that requires no external scoring model. This reward combines explicit observational signals with internal model uncertainty to jointly optimize reasoning fidelity and verification rigor. Experiments on multiple benchmarks demonstrate the effectiveness of our method.", "AI": {"tldr": "本文提出了一种名为ARR的框架，通过引入Reasoner和Verifier角色之间的对抗协作来改进检索增强语言模型中的推理过程。", "motivation": "现有的大规模推理模型在进行外部文档上的深度自我校正推理时往往局限于单一视角，并且训练范式依赖于结果导向奖励信号不足以塑造复杂的多步推理过程。因此，需要一种新的方法来解决这些问题。", "method": "本文提出了一种名为Adversarial Reasoning RAG (ARR)的框架，该框架通过Reasoner和Verifier之间的对抗协作来进行检索增强语言模型中的推理。Reasoner和Verifier会基于获取的证据进行推理，并相互批判对方的逻辑，在过程中利用过程感知优势而非外部评分模型来优化推理准确性和验证严谨性。", "result": "实验结果表明，所提出的方法在多个基准测试上都表现出了有效性。", "conclusion": "通过引入Reasoner和Verifier角色之间的对抗协作机制，ARR框架能够在检索增强语言模型中实现更有效的多步推理过程。"}}
{"id": "2601.04646", "pdf": "https://arxiv.org/pdf/2601.04646", "abs": "https://arxiv.org/abs/2601.04646", "authors": ["Prateek Jain", "Shabari S Nair", "Ritesh Goru", "Prakhar Agarwal", "Ajay Yadav", "Yoga Sri Varshan Varadharajan", "Constantine Caramanis"], "title": "Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This \"dark data\" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \\textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \\textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \\textbf{consistency filtering} and relevance assignment. We further propose a practical \\textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.", "AI": {"tldr": "本文提出了一个针对大规模多租户检索系统的解决方案，通过融合多种候选生成策略和查询端自适应技术来解决暗数据问题。", "motivation": "大型多租户检索系统积累了大量的用户查询日志，但缺乏有效的领域适应所需的手工标注相关性标签。联合微调查询和文档编码器需要重新索引整个语料库，在多租户环境中是不可行的。", "method": "本文提出了一种融合式候选生成策略，通过合并不同稀疏和密集检索器的结果，并使用大语言模型作为裁判进行一致性过滤和相关性评估。此外还提出了一个仅微调查询编码器而不重新索引文档的方法，实现性能提升与效率平衡。", "result": "在DevRev Search和SciFact上的实验表明，针对特定的转换器层对查询编码器进行低秩适应可以达到最优的质量-效率权衡。", "conclusion": "本文提出的策略为大规模个性化企业搜索提供了可扩展的道路。"}}
{"id": "2601.04638", "pdf": "https://arxiv.org/pdf/2601.04638", "abs": "https://arxiv.org/abs/2601.04638", "authors": ["Sirry Chen", "Jieyi Wang", "Wei Chen", "Zhongyu Wei"], "title": "SpeechMedAssist: Efficiently and Effectively Adapting Speech Language Models for Medical Consultation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Medical consultations are intrinsically speech-centric. However, most prior works focus on long-text-based interactions, which are cumbersome and patient-unfriendly. Recent advances in speech language models (SpeechLMs) have enabled more natural speech-based interaction, yet the scarcity of medical speech data and the inefficiency of directly fine-tuning on speech data jointly hinder the adoption of SpeechLMs in medical consultation. In this paper, we propose SpeechMedAssist, a SpeechLM natively capable of conducting speech-based multi-turn interactions with patients. By exploiting the architectural properties of SpeechLMs, we decouple the conventional one-stage training into a two-stage paradigm consisting of (1) Knowledge & Capability Injection via Text and (2) Modality Re-alignment with Limited Speech Data, thereby reducing the requirement for medical speech data to only 10k synthesized samples. To evaluate SpeechLMs for medical consultation scenarios, we design a benchmark comprising both single-turn question answering and multi-turn simulated interactions. Experimental results show that our model outperforms all baselines in both effectiveness and robustness in most evaluation settings.", "AI": {"tldr": "提出了SpeechMedAssist，一种适用于医疗咨询的语音语言模型。", "motivation": "现有工作大多集中在基于长文本的互动上，这在医学咨询中显得繁琐且不友好。语音语言模型虽然提供了更自然的交互方式，但缺乏足够的医学语音数据和高效的训练方法。", "method": "通过利用SpeechLM的架构特性，将传统的单一阶段训练分解为两个阶段：知识与能力注入文本阶段以及使用少量合成语音数据进行模态对齐阶段。", "result": "实验表明，提出的模型在单轮问答及多轮模拟互动中均优于所有基准方法，在效果和鲁棒性方面表现出色。", "conclusion": "SpeechMedAssist成功地适应了医疗咨询场景中的需求，为更自然、高效的语音交互提供了可能。"}}
{"id": "2601.04632", "pdf": "https://arxiv.org/pdf/2601.04632", "abs": "https://arxiv.org/abs/2601.04632", "authors": ["Haneul Yoo", "Won Ik Cho", "Geunhye Kim", "Jiyoon Han"], "title": "From National Curricula to Cultural Awareness: Constructing Open-Ended Culture-Specific Question Answering Dataset", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) achieve strong performance on many tasks, but their progress remains uneven across languages and cultures, often reflecting values latent in English-centric training data. To enable practical cultural alignment, we propose a scalable approach that leverages national social studies curricula as a foundation for culture-aware supervision. We introduce CuCu, an automated multi-agent LLM framework that transforms national textbook curricula into open-ended, culture-specific question-answer pairs. Applying CuCu to the Korean national social studies curriculum, we construct KCaQA, comprising 34.1k open-ended QA pairs. Our quantitative and qualitative analyses suggest that KCaQA covers culture-specific topics and produces responses grounded in local sociocultural contexts.", "AI": {"tldr": "构建一个基于国家社会研究课程的文化特定问题回答数据集KCaQA，以提高大型语言模型在文化领域的适应性。", "motivation": "为了使大型语言模型更好地理解和反映不同文化和语言的价值观，特别是在英语为中心的训练数据之外。通过使用国家教材来提供具有文化意识的监督，以促进实际应用中的文化对齐。", "method": "提出了一种自动化的多代理LLM框架CuCu，该框架能将国家教科书课程转化为开放性、特定文化的问答对，并应用于韩国社会研究课程，构建了包含34100个问题回答对的数据集KCaQA。", "result": "定量和定性的分析表明，KCaQA涵盖了文化特定的话题并生成基于当地社会文化背景的回答。", "conclusion": "通过国家教材产生的文化特定数据集能够提高大型语言模型在跨文化和多语言任务中的表现。"}}
{"id": "2601.04631", "pdf": "https://arxiv.org/pdf/2601.04631", "abs": "https://arxiv.org/abs/2601.04631", "authors": ["Etienne Casanova", "R. Michael Alvarez"], "title": "Beyond the \"Truth\": Investigating Election Rumors on Truth Social During the 2024 Election", "categories": ["cs.AI", "cs.SI"], "comment": null, "summary": "Large language models (LLMs) offer unprecedented opportunities for analyzing social phenomena at scale. This paper demonstrates the value of LLMs in psychological measurement by (1) compiling the first large-scale dataset of election rumors on a niche alt-tech platform, (2) developing a multistage Rumor Detection Agent that leverages LLMs for high-precision content classification, and (3) quantifying the psychological dynamics of rumor propagation, specifically the \"illusory truth effect\" in a naturalistic setting. The Rumor Detection Agent combines (i) a synthetic data-augmented, fine-tuned RoBERTa classifier, (ii) precision keyword filtering, and (iii) a two-pass LLM verification pipeline using GPT-4o mini. The findings reveal that sharing probability rises steadily with each additional exposure, providing large-scale empirical evidence for dose-response belief reinforcement in ideologically homogeneous networks. Simulation results further demonstrate rapid contagion effects: nearly one quarter of users become \"infected\" within just four propagation iterations. Taken together, these results illustrate how LLMs can transform psychological science by enabling the rigorous measurement of belief dynamics and misinformation spread in massive, real-world datasets.", "AI": {"tldr": "该论文利用大规模语言模型分析选举谣言的传播，并开发了一种多阶段谣言检测代理，以量化谣言在同质网络中的传播动态。", "motivation": "通过使用大型语言模型来研究社会现象并测量心理效应，特别是在意识形态一致的网络中虚假信息的传播和强化机制。论文希望通过这种方法了解大规模数据集中的信念动态。", "method": "该论文创建了一个包含选举谣言的大规模数据集，并开发了一种结合合成数据增强、微调RoBERTa分类器、精确关键词过滤以及两阶段大模型验证管道的多阶段谣言检测代理，利用GPT-4o mini进行内容分类和验证。", "result": "研究发现，在同质网络中，每个额外暴露都会导致分享概率逐步上升，表明剂量反应信念强化现象。模拟结果显示，不到四个传播迭代，几乎四分之一的用户会被“感染”。", "conclusion": "大型语言模型可以显著提高心理科学的研究能力，通过大规模数据集中的谣言传播研究来衡量信念动态和虚假信息传播效果。"}}
{"id": "2601.04630", "pdf": "https://arxiv.org/pdf/2601.04630", "abs": "https://arxiv.org/abs/2601.04630", "authors": ["Xiyuan Zhu", "Wenhan Lyu", "Chaochao Fu", "Yilin Wang", "Jie Zheng", "Qiyue Tan", "Qianhe Chen", "Yixin Yu", "Ran Wang"], "title": "RecruitScope: A Visual Analytics System for Multidimensional Recruitment Data Analysis", "categories": ["cs.HC"], "comment": null, "summary": "Online recruitment platforms have become the dominant channel for modern hiring, yet most platforms offer only basic filtering capabilities, such as job title, keyword, and salary range. This hinders comprehensive analysis of multi-attribute relationships and job market patterns across different scales. We present RecruitScope, a visual analytics system designed to support multidimensional and cross-level exploration of recruitment data for job seekers and employers, particularly HR specialists. Through coordinated visualizations, RecruitScope enables users to analyze job positions and salary patterns from multiple perspectives, interpret industry dynamics at the macro level, and identify emerging positions at the micro level. We demonstrate the effectiveness of RecruitScope through case studies that reveal regional salary distribution patterns, characterize industry growth trajectories, and discover high-demand emerging roles in the job market.", "AI": {"tldr": "RecruitScope是一个用于多维度招聘数据分析的可视化系统，旨在帮助求职者和人力资源专家分析职位与薪资模式等信息。", "motivation": "现有在线招聘平台提供的筛选能力有限，难以进行全面的多属性关系和就业市场趋势分析。为解决这一问题，作者开发了RecruitScope来支持跨层次的数据探索，以便于更深入地理解行业动态及新兴岗位。", "method": "通过协调可视化技术，该系统允许用户从多个角度分析职位与薪资模式，揭示地区薪酬分布、行业发展轨迹以及市场需求的新角色。", "result": "案例研究展示了RecruitScope在识别区域工资分配趋势、刻画行业增长路径和发现市场上需求量大的新职位方面的有效性。", "conclusion": "RecruitScope为招聘数据的多维度和跨层分析提供了一种有效的工具，能够帮助用户更好地理解就业市场的复杂性。"}}
{"id": "2601.04629", "pdf": "https://arxiv.org/pdf/2601.04629", "abs": "https://arxiv.org/abs/2601.04629", "authors": ["Zhongxuan Li", "Zeliang Guo", "Jun Hu", "David Navarro-Alarcon", "Jia Pan", "Hongmin Wu", "Peng Zhou"], "title": "UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "We present UniBiDex a unified teleoperation framework for robotic bimanual dexterous manipulation that supports both VRbased and leaderfollower input modalities UniBiDex enables realtime contactrich dualarm teleoperation by integrating heterogeneous input devices into a shared control stack with consistent kinematic treatment and safety guarantees The framework employs nullspace control to optimize bimanual configurations ensuring smooth collisionfree and singularityaware motion across tasks We validate UniBiDex on a longhorizon kitchentidying task involving five sequential manipulation subtasks demonstrating higher task success rates smoother trajectories and improved robustness compared to strong baselines By releasing all hardware and software components as opensource we aim to lower the barrier to collecting largescale highquality human demonstration datasets and accelerate progress in robot learning.", "AI": {"tldr": "提出了一种名为UniBiDex的统一远程操作框架，用于机器人双臂灵巧操作", "motivation": "为了支持虚拟现实和领导跟随输入模式，实现实时接触丰富的双臂远程操作，并优化双臂配置以确保平滑无碰撞且奇异值感知的操作路径", "method": "通过整合异构输入设备到共享控制堆栈中，采用零空间控制来优化双臂配置，确保在任务中的平滑、无碰撞和奇异点意识的运动", "result": "验证了UniBiDex在长时厨房整理任务中的性能，显示出了更高的成功率、更平滑的轨迹以及比强基线更好的鲁棒性", "conclusion": "通过开源所有硬件和软件组件来降低收集大规模高质量人类演示数据集的门槛，并加速机器人学习的进步"}}
{"id": "2601.04626", "pdf": "https://arxiv.org/pdf/2601.04626", "abs": "https://arxiv.org/abs/2601.04626", "authors": ["Therese Biedl", "Prashant Gokhale"], "title": "Using Ray-shooting Queries for Sublinear Algorithms for Dominating Sets in RDV Graphs", "categories": ["cs.DS", "cs.CG"], "comment": "To appear at SOFSEM'26", "summary": "In this paper, we study the dominating set problem in \\emph{RDV graphs}, a graph class that lies between interval graphs and chordal graphs and is defined as the \\textbf{v}ertex-intersection graphs of \\textbf{d}ownward paths in a \\textbf{r}ooted tree. It was shown in a previous paper that adjacency queries in an RDV graph can be reduced to the question whether a horizontal segment intersects a vertical segment. This was then used to find a maximum matching in an $n$-vertex RDV graph, using priority search trees, in $O(n\\log n)$ time, i.e., without even looking at all edges. In this paper, we show that if additionally we also use a ray shooting data structure, we can also find a minimum dominating set in an RDV graph $O(n\\log n)$ time (presuming a linear-sized representation of the graph is given). The same idea can also be used for a new proof to find a minimum dominating set in an interval graph in $O(n)$ time.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.04620", "pdf": "https://arxiv.org/pdf/2601.04620", "abs": "https://arxiv.org/abs/2601.04620", "authors": ["Di Zhang"], "title": "AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering", "categories": ["cs.AI"], "comment": null, "summary": "Recent progress in large language model (LLM) agents has largely focused on embedding self-improvement mechanisms inside the agent or searching over many concurrent variants. While these approaches can raise aggregate scores, they often yield unstable and hard-to-audit improvement trajectories, making it difficult to guarantee non-regression or to reason about failures across versions. We reframe agent improvement as \\textbf{release engineering}: agents are treated as shippable artifacts, and improvement is externalized into a regression-aware release pipeline. We introduce \\textbf{AgentDevel}, a release engineering pipeline that iteratively runs the current agent, produces implementation-blind, symptom-level quality signals from execution traces, synthesizes a single release candidate (RC) via executable diagnosis, and promotes it under flip-centered gating. AgentDevel features three core designs: (i) an implementation-blind LLM critic that characterizes failure appearances without accessing agent internals, (ii) script-based executable diagnosis that aggregates dominant symptom patterns and produces auditable engineering specifications, and (iii) flip-centered gating that prioritizes pass to fail regressions and fail to pass fixes as first-class evidence. Unlike population-based search or in-agent self-refinement, AgentDevel maintains a single canonical version line and emphasizes non-regression as a primary objective. Experiments on execution-heavy benchmarks demonstrate that AgentDevel yields stable improvements with significantly fewer regressions while producing reproducible, auditable artifacts. Overall, AgentDevel provides a practical development discipline for building, debugging, and releasing LLM agents as software development.", "AI": {"tldr": "本文提出了AgentDevel，一种通过发布工程来改进大语言模型代理的方法。", "motivation": "现有的大型语言模型（LLM）代理的自我进化机制常常导致不稳定的提升轨迹和难以审计的问题。作者认为应该将代理视为可发布的工件，并使用回归意识的发布管道进行改进。", "method": "AgentDevel包含三个核心设计：实施盲的语言模型评论者，基于脚本的可执行诊断以及以翻转为中心的门控机制。", "result": "在执行密集型基准测试中，AgentDevel展示了稳定的改善效果，并且与现有方法相比显著减少了回退。此外，它还生成了可以复制和审计的结果。", "conclusion": "总体而言，AgentDevel提供了一种实用的方法来构建、调试和发布LLM代理作为软件开发的一部分。"}}
{"id": "2601.04616", "pdf": "https://arxiv.org/pdf/2601.04616", "abs": "https://arxiv.org/abs/2601.04616", "authors": ["Shuhan Zhang", "Zhi Wang", "Rui Gao", "Shuang Li"], "title": "DeepHalo: A Neural Choice Model with Controllable Context Effects", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.", "AI": {"tldr": "提出DeepHalo神经网络模型，用于模拟人类决策行为中的上下文效应。", "motivation": "经典决策模型假设选择行为不受背景影响，但实际研究表明偏好受备选项组合的影响。现有模型在捕捉这些效应时存在局限性，因此开发了DeepHalo以提供更好的控制和解释性。", "method": "使用神经网络框架，允许明确控制交互顺序，并为上下文依赖的选择功能提供了普适近似器。", "result": "实验表明，DeepHalo具有强大的预测性能并能清晰展示选择驱动因素。", "conclusion": "通过引入DeepHalo模型，研究解决了现有方法在解释和捕捉决策行为中的上下文效应时的不足。"}}
{"id": "2601.04614", "pdf": "https://arxiv.org/pdf/2601.04614", "abs": "https://arxiv.org/abs/2601.04614", "authors": ["Wenzhi Chen", "Bo Hu", "Leida Li", "Lihuo He", "Wen Lu", "Xinbo Gao"], "title": "HyperAlign: Hyperbolic Entailment Cones for Adaptive Text-to-Image Alignment Assessment", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid development of text-to-image generation technology, accurately assessing the alignment between generated images and text prompts has become a critical challenge. Existing methods rely on Euclidean space metrics, neglecting the structured nature of semantic alignment, while lacking adaptive capabilities for different samples. To address these limitations, we propose HyperAlign, an adaptive text-to-image alignment assessment framework based on hyperbolic entailment geometry. First, we extract Euclidean features using CLIP and map them to hyperbolic space. Second, we design a dynamic-supervision entailment modeling mechanism that transforms discrete entailment logic into continuous geometric structure supervision. Finally, we propose an adaptive modulation regressor that utilizes hyperbolic geometric features to generate sample-level modulation parameters, adaptively calibrating Euclidean cosine similarity to predict the final score. HyperAlign achieves highly competitive performance on both single database evaluation and cross-database generalization tasks, fully validating the effectiveness of hyperbolic geometric modeling for image-text alignment assessment.", "AI": {"tldr": "提出了一种基于双曲几何的文本到图像对齐评估框架HyperAlign。", "motivation": "现有方法依赖欧氏空间度量，忽略语义对齐结构化特征，并缺乏对不同样本的适应性能力。", "method": "首先使用CLIP提取欧氏特征并映射至双曲空间。设计动态监督包含关系建模机制将离散逻辑转换为连续几何结构监督。提出自适应调制回归器，利用双曲几何特征生成样本级调制参数以校准预测分数。", "result": "HyperAlign在单数据库评估和跨数据库泛化任务中表现出色，验证了双曲几何建模对图像文本对齐评估的有效性。", "conclusion": "该框架能有效解决现有方法的局限性，并提高了图像与文本之间的对齐评估性能。"}}
{"id": "2601.04610", "pdf": "https://arxiv.org/pdf/2601.04610", "abs": "https://arxiv.org/abs/2601.04610", "authors": ["Paras Jain", "Khushi Dhar", "Olyemi E. Amujo", "Esa M. Rantanen"], "title": "Evaluating Human and Machine Confidence in Phishing Email Detection: A Comparative Study", "categories": ["cs.AI"], "comment": "Accepted for publication in the 2025 IEEE 7th International Conference on Cognitive Machine Intelligence (CogMI) 9 Pages", "summary": "Identifying deceptive content like phishing emails demands sophisticated cognitive processes that combine pattern recognition, confidence assessment, and contextual analysis. This research examines how human cognition and machine learning models work together to distinguish phishing emails from legitimate ones. We employed three interpretable algorithms Logistic Regression, Decision Trees, and Random Forests training them on both TF-IDF features and semantic embeddings, then compared their predictions against human evaluations that captured confidence ratings and linguistic observations. Our results show that machine learning models provide good accuracy rates, but their confidence levels vary significantly. Human evaluators, on the other hand, use a greater variety of language signs and retain more consistent confidence. We also found that while language proficiency has minimal effect on detection performance, aging does. These findings offer helpful direction for creating transparent AI systems that complement human cognitive functions, ultimately improving human-AI cooperation in challenging content analysis tasks.", "AI": {"tldr": "评估人类和机器在检测网络钓鱼邮件时的信心水平，并比较两者的表现", "motivation": "探究人类认知与机器学习模型如何协同工作以区分真实的电子邮件和网络钓鱼邮件，从而提高人机合作效率", "method": "使用逻辑回归、决策树及随机森林等可解释性算法，结合TF-IDF特征和语义嵌入训练模型，并将预测结果与包含信心评级和语言观察的人类评估进行比较", "result": "机器学习模型具有较高的准确率但信心水平差异显著；人类评估者在识别时使用更多语言线索且保持一致的信心。语言熟练度对检测性能影响较小，而年龄有一定影响", "conclusion": "研究揭示了人机合作的潜力及挑战，并为开发透明的人工智能系统提供了方向"}}
{"id": "2601.04607", "pdf": "https://arxiv.org/pdf/2601.04607", "abs": "https://arxiv.org/abs/2601.04607", "authors": ["Xiaoyu Liu", "Siwen Wei", "Linhao Qu", "Mingyuan Pan", "Chengsheng Zhang", "Yonghong Shi", "Zhijian Song"], "title": "HUR-MACL: High-Uncertainty Region-Guided Multi-Architecture Collaborative Learning for Head and Neck Multi-Organ Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate segmentation of organs at risk in the head and neck is essential for radiation therapy, yet deep learning models often fail on small, complexly shaped organs. While hybrid architectures that combine different models show promise, they typically just concatenate features without exploiting the unique strengths of each component. This results in functional overlap and limited segmentation accuracy. To address these issues, we propose a high uncertainty region-guided multi-architecture collaborative learning (HUR-MACL) model for multi-organ segmentation in the head and neck. This model adaptively identifies high uncertainty regions using a convolutional neural network, and for these regions, Vision Mamba as well as Deformable CNN are utilized to jointly improve their segmentation accuracy. Additionally, a heterogeneous feature distillation loss was proposed to promote collaborative learning between the two architectures in high uncertainty regions to further enhance performance. Our method achieves SOTA results on two public datasets and one private dataset.", "AI": {"tldr": "提出了一种高不确定性区域引导的多架构协作学习模型（HUR-MACL），用于头颈部多器官分割。", "motivation": "为了提高对小而复杂形状的危险器官的准确性，解决当前混合架构模型功能重叠和分割精度有限的问题。", "method": "使用卷积神经网络自适应识别高不确定性区域，并针对这些区域利用Vision Mamba和Deformable CNN协同改善其分割精度。引入异构特征蒸馏损失以促进两种架构在高不确定性区域中的协作学习。", "result": "该方法在两个公开数据集和一个私有数据集中实现了最先进的结果。", "conclusion": "所提模型通过高不确定性引导的多架构协作学习，显著提高了头颈部多器官分割的准确性。"}}
{"id": "2601.04606", "pdf": "https://arxiv.org/pdf/2601.04606", "abs": "https://arxiv.org/abs/2601.04606", "authors": ["Osman Goni Ridwan", "Gilles Frapper", "Hongfei Xue", "Qiang Zhu"], "title": "Crystal Generation using the Fully Differentiable Pipeline and Latent Space Optimization", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG", "physics.atm-clus"], "comment": null, "summary": "We present a materials generation framework that couples a symmetry-conditioned variational autoencoder (CVAE) with a differentiable SO(3) power spectrum objective to steer candidates toward a specified local environment under the crystallographic constraints. In particular, we implement a fully differentiable pipeline that performs batch-wise optimization on both direct and latent crystallographic representations. Using the GPU acceleration, the implementation achieves about fivefold speed compared to our previous CPU workflow, while yielding comparable outcomes. In addition, we introduce the optimization strategy that alternatively performs optimization on the direct and latent crystal representations. This dual-level relaxation approach can effectively overcome local barrier defined by different objective gradients, thus increasing the success rate of generating complex structures satisfying the targe local environments. This framework can be extended to systems consisting of multi-components and multi-environments, providing a scalable route to generate material structures with the target local environment.", "AI": {"tldr": "本文提出了一种结合对称条件变分自动编码器（CVAE）和可微SO(3)功率谱目标的材料生成框架，用于在晶体学约束下引导候选物达到指定局部环境。", "motivation": "为了提高复杂结构生成的成功率，在满足特定局部环境的同时加速计算过程，并扩展多组分系统的应用范围。", "method": "采用了结合CVAE和可微SO(3)功率谱目标的全可微管道，利用GPU加速实现约五倍的速度提升；引入了交替优化直接晶体表示和潜在空间表示的方法来克服局部最小值问题。", "result": "该方法在保持性能的同时提高了计算效率，并通过双层松弛策略增加了复杂结构生成的成功率。", "conclusion": "提出的框架为满足特定局部环境的材料结构提供了一种可扩展且高效的生成途径。"}}
{"id": "2601.04605", "pdf": "https://arxiv.org/pdf/2601.04605", "abs": "https://arxiv.org/abs/2601.04605", "authors": ["Bernard Ngabonziza", "Ayan Banerjee", "Sandeep K. S. Gupta"], "title": "Detection of Deployment Operational Deviations for Safety and Security of AI-Enabled Human-Centric Cyber Physical Systems", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, Human-centric cyber-physical systems have increasingly involved artificial intelligence to enable knowledge extraction from sensor-collected data. Examples include medical monitoring and control systems, as well as autonomous cars. Such systems are intended to operate according to the protocols and guidelines for regular system operations. However, in many scenarios, such as closed-loop blood glucose control for Type 1 diabetics, self-driving cars, and monitoring systems for stroke diagnosis. The operations of such AI-enabled human-centric applications can expose them to cases for which their operational mode may be uncertain, for instance, resulting from the interactions with a human with the system. Such cases, in which the system is in uncertain conditions, can violate the system's safety and security requirements. This paper will discuss operational deviations that can lead these systems to operate in unknown conditions. We will then create a framework to evaluate different strategies for ensuring the safety and security of AI-enabled human-centric cyber-physical systems in operation deployment. Then, as an example, we show a personalized image-based novel technique for detecting the non-announcement of meals in closed-loop blood glucose control for Type 1 diabetics.", "AI": {"tldr": "本文提出了一种框架，用于评估确保AI驱动的人机交互系统在部署中安全性和隐私性的策略，并展示了针对1型糖尿病患者闭环血糖控制中未宣布进餐情况的个性化图像检测技术。", "motivation": "随着人工智能在人机交互系统的应用越来越多，这些系统可能会由于与人的互动进入不确定状态，从而导致违反其安全性要求。因此，需要评估确保此类系统安全和隐私性的策略。", "method": "建立了一个框架来评估各种策略以确保AI驱动的人机交互系统部署的安全性和隐私性，并展示了一种用于检测1型糖尿病患者闭环血糖控制中未宣布进餐情况的个性化图像技术。", "result": "提出并验证了评估和保护AI驱动的人机交互系统的安全性和隐私性的方法，证明该框架可以在实际应用场景中有效使用。", "conclusion": "通过建立一个评价体系，并展示了一个具体的应用场景，本文为确保AI驱动的人机交互系统在部署中的安全性和隐私性提供了有效的策略。"}}
{"id": "2601.04603", "pdf": "https://arxiv.org/pdf/2601.04603", "abs": "https://arxiv.org/abs/2601.04603", "authors": ["Hoagy Cunningham", "Jerry Wei", "Zihan Wang", "Andrew Persic", "Alwin Peng", "Jordan Abderrachid", "Raj Agarwal", "Bobby Chen", "Austin Cohen", "Andy Dau", "Alek Dimitriev", "Rob Gilson", "Logan Howard", "Yijin Hua", "Jared Kaplan", "Jan Leike", "Mu Lin", "Christopher Liu", "Vladimir Mikulik", "Rohit Mittapalli", "Clare O'Hara", "Jin Pan", "Nikhil Saxena", "Alex Silverstein", "Yue Song", "et al. (4 additional authors not shown)"], "title": "Constitutional Classifiers++: Efficient Production-Grade Defenses against Universal Jailbreaks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "We introduce enhanced Constitutional Classifiers that deliver production-grade jailbreak robustness with dramatically reduced computational costs and refusal rates compared to previous-generation defenses. Our system combines several key insights. First, we develop exchange classifiers that evaluate model responses in their full conversational context, which addresses vulnerabilities in last-generation systems that examine outputs in isolation. Second, we implement a two-stage classifier cascade where lightweight classifiers screen all traffic and escalate only suspicious exchanges to more expensive classifiers. Third, we train efficient linear probe classifiers and ensemble them with external classifiers to simultaneously improve robustness and reduce computational costs. Together, these techniques yield a production-grade system achieving a 40x computational cost reduction compared to our baseline exchange classifier, while maintaining a 0.05% refusal rate on production traffic. Through extensive red-teaming comprising over 1,700 hours, we demonstrate strong protection against universal jailbreaks -- no attack on this system successfully elicited responses to all eight target queries comparable in detail to an undefended model. Our work establishes Constitutional Classifiers as practical and efficient safeguards for large language models.", "AI": {"tldr": "本文介绍了增强型宪法分类器，旨在在减少计算成本的同时提供生产级别的防越狱保护。", "motivation": "前几代防御系统存在孤立检查模型输出的漏洞，并且计算成本和拒绝率较高。因此，需要更高效的解决方案来防止通用越狱攻击。", "method": "该方法包括：开发上下文交换分类器；实现两阶段分类器级联；训练高效线性探测分类器并与外部分类器集成以提高鲁棒性和降低成本。", "result": "新系统实现了40倍的计算成本降低，并保持了0.05％的拒绝率，同时在1700多个小时的红队测试中展示了对通用越狱攻击的强大防护能力。", "conclusion": "本工作确立了宪法分类器作为大规模语言模型实用且高效的保护措施。"}}
{"id": "2601.04601", "pdf": "https://arxiv.org/pdf/2601.04601", "abs": "https://arxiv.org/abs/2601.04601", "authors": ["Xinyan Yu", "Julie Stephany Berrio Perez", "Marius Hoggenmüller", "Martin Tomitsch", "Tram Thi Minh Tran", "Stewart Worrall", "Wendy Ju"], "title": "The UnScripted Trip: Fostering Policy Discussion on Future Human-Vehicle Collaboration in Autonomous Driving Through Design-Oriented Methods", "categories": ["cs.HC"], "comment": null, "summary": "The rapid advancement of autonomous vehicle (AV) technologies is fundamentally reshaping paradigms of human-vehicle collaboration, raising not only an urgent need for innovative design solutions but also for policies that address corresponding broader tensions in society. To bridge the gap between HCI research and policy making, this workshop will bring together researchers and practitioners in the automotive community to explore AV policy directions through collaborative speculation on the future of AVs. We designed The UnScripted Trip, a card game rooted in fictional narratives of autonomous mobility, to surface tensions around human-vehicle collaboration in future AV scenarios and to provoke critical reflections on design solutions and policy directions. Our goal is to provide an engaging, participatory space and method for automotive researchers, designers, and industry practitioners to collectively explore and shape the future of human-vehicle collaboration and its policy implications.", "AI": {"tldr": "设计并实施一款基于虚构叙事的卡牌游戏，探讨未来自动驾驶汽车的人车协作政策方向", "motivation": "鉴于自主驾驶技术的发展需要创新的设计解决方案以及相应社会紧张局势的政策应对，此工作坊旨在通过协同设想未来自动驾驶车辆来弥合HCI研究与政策制定之间的差距", "method": "设计名为《未编剧本之旅》的卡牌游戏，该游戏基于虚构叙述的自动移动性故事，用于揭示有关未来AV场景下的人车协作中的张力，并激发对设计解决方案和政策方向的重要反思", "result": "提供一个充满活力、参与性的空间及方法论，使汽车研究者、设计师以及产业实践者共同探索并塑造人类与自动驾驶车辆合作的未来发展及其政策影响", "conclusion": "通过《未编剧本之旅》卡牌游戏，成功促进了关于未来人车协作的设计解决方案和政策方向的重要讨论"}}
{"id": "2601.04600", "pdf": "https://arxiv.org/pdf/2601.04600", "abs": "https://arxiv.org/abs/2601.04600", "authors": ["Zhiyuan He", "Binghan Chen", "Tianxiang Xiong", "Ziyang Sun", "Mozhao Zhu", "Xi Chen"], "title": "On the Limitations of Rank-One Model Editing in Answering Multi-hop Questions", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in Knowledge Editing (KE), particularly Rank-One Model Editing (ROME), show superior efficiency over fine-tuning and in-context learning for updating single-hop facts in transformers. However, these methods face significant challenges when applied to multi-hop reasoning tasks requiring knowledge chaining. In this work, we study the effect of editing knowledge with ROME on different layer depths and identify three key failure modes. First, the \"hopping-too-late\" problem occurs as later layers lack access to necessary intermediate representations. Second, generalization ability deteriorates sharply when editing later layers. Third, the model overfits to edited knowledge, incorrectly prioritizing edited-hop answers regardless of context. To mitigate the issues of \"hopping-too-late\" and generalisation decay, we propose Redundant Editing, a simple yet effective strategy that enhances multi-hop reasoning. Our experiments demonstrate that this approach can improve accuracy on 2-hop questions by at least 15.5 percentage points, representing a 96% increase over the previous single-edit strategy, while trading off some specificity and language naturalness.", "AI": {"tldr": "研究了使用Rank-One Model Editing（ROME）编辑知识在多跳推理任务中的效果，发现了三种关键的失败模式，并提出了一种简单有效的策略来缓解这些问题。", "motivation": "探讨ROME方法在单跳事实更新上的高效性及其在处理需要知识链条的复杂推理任务时面临的挑战和限制。", "method": "分析了不同层次深度编辑知识的效果，提出了Redundant Editing策略以解决多跳推理中的问题，并通过实验验证其有效性。", "result": "新方法提升了至少15.5个百分点的准确率，相较于之前的单次编辑策略提高了96%，但同时也带来了一些特异性和自然语言表达上的折衷。", "conclusion": "揭示了ROME在处理多跳推理任务时存在的局限性，并通过Redundant Editing策略有效地缓解了这些问题。"}}
{"id": "2601.04596", "pdf": "https://arxiv.org/pdf/2601.04596", "abs": "https://arxiv.org/abs/2601.04596", "authors": ["Xinyan Yu", "Marius Hoggenmüller", "Tram Thi Minh Tran", "Martin Tomitsch"], "title": "Feel the Presence: The Effects of Haptic Sensation on VR-Based Human-Robot Interaction", "categories": ["cs.HC"], "comment": null, "summary": "Virtual reality (VR) has been increasingly utilised as a simulation tool for human-robot interaction (HRI) studies due to its ability to facilitate fast and flexible prototyping. Despite efforts to achieve high validity in VR studies, haptic sensation, an essential sensory modality for perception and a critical factor in enhancing VR realism, is often absent from these experiments. Studying an interactive robot help-seeking scenario, we used a VR simulation with haptic gloves that provide highly realistic tactile and force feedback to examine the effects of haptic sensation on VR-based HRI. We compared participants' sense of presence and their assessments of the robot to a traditional setup using hand controllers. Our results indicate that haptic sensation enhanced participants' social and self-presence in VR and fostered more diverse and natural bodily engagement. Additionally, haptic sensations significantly influenced participants' affective-related perceptions of the robot. Our study provides insights to guide HRI researchers in building VR-based simulations that better align with their study contexts and objectives.", "AI": {"tldr": "研究在虚拟现实（VR）中通过使用触觉手套探索触觉感知对人机交互的影响。", "motivation": "虚拟现实中的人机交互实验通常缺少关键的触觉感觉，这影响了VR的真实感和用户体验。本文旨在通过引入触觉反馈来提高VR中的真实性和参与度。", "method": "采用带有触觉手套的VR仿真系统与传统手柄控制器进行对比实验，考察参与者在不同条件下对机器人互动场景的感受和社会存在感、自我存在感以及情感感知的变化。", "result": "结果显示，引入触觉反馈显著增强了参与者的社会和自我的存在感，并促进了更自然的身体动作。同时，触觉感觉也影响了参与者对机器人的积极情绪评价。", "conclusion": "本研究为在虚拟现实环境中进行人机交互实验提供了指导性建议，强调了在设计VR模拟时应考虑引入高质量的触觉反馈以提高真实感和互动体验。"}}
