{"id": "2601.21264", "pdf": "https://arxiv.org/pdf/2601.21264", "abs": "https://arxiv.org/abs/2601.21264", "authors": ["Yoonsang Kim", "Swapnil Dey", "Arie Kaufman"], "title": "Evaluating Spatialized Auditory Cues for Rapid Attention Capture in XR", "categories": ["cs.HC", "cs.SD", "eess.AS"], "comment": "8 pages, 4 figures. This is the author's version of the article that will appear at the IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (IEEE VRW) 2026", "summary": "In time-critical eXtended reality (XR) scenarios where users must rapidly reorient their attention to hazards, alerts, or instructions while engaged in a primary task, spatial audio can provide an immediate directional cue without occupying visual bandwidth. However, such scenarios can afford only a brief auditory exposure, requiring users to interpret sound direction quickly and without extended listening or head-driven refinement. This paper reports a controlled exploratory study of rapid spatial-audio localization in XR. Using HRTF-rendered broadband stimuli presented from a semi-dense set of directions around the listener, we quantify how accurately users can infer coarse direction from brief audio alone. We further examine the effects of short-term visuo-auditory feedback training as a lightweight calibration mechanism. Our findings show that brief spatial cues can convey coarse directional information, and that even short calibration can improve users' perception of aural signals. While these results highlight the potential of spatial audio for rapid attention guidance, they also show that auditory cues alone may not provide sufficient precision for complex or high-stakes tasks, and that spatial audio may be most effective when complemented by other sensory modalities or visual cues, without relying on head-driven refinement. We leverage this study on spatial audio as a preliminary investigation into a first-stage attention-guidance channel for wearable XR (e.g., VR head-mounted displays and AR smart glasses), and provide design insights on stimulus selection and calibration for time-critical use.", "AI": {"tldr": "评估在XR场景中快速注意力捕捉的声学线索效果", "motivation": "探讨在时间紧迫的XR环境中，利用空间音频进行快速注意力转移的有效性", "method": "使用HRTF渲染宽带刺激并测量用户从短暂声音中推断方向的能力。研究短期视听反馈训练对感知的影响。", "result": "发现短时声学线索能够传达粗略的方向信息，并且简短校准可以改善听觉信号的感知效果。但单独依赖音频可能不够精确，需结合其他感官模态或视觉提示。", "conclusion": "初步研究表明空间音频在XR中的快速注意力引导中具有潜力，但也指出需要与其他感觉通道配合使用"}}
{"id": "2601.21260", "pdf": "https://arxiv.org/pdf/2601.21260", "abs": "https://arxiv.org/abs/2601.21260", "authors": ["Seonghyeon Go", "Yumin Kim"], "title": "Music Plagiarism Detection: Problem Formulation and a Segment-based Solution", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": null, "summary": "Recently, the problem of music plagiarism has emerged as an even more pressing social issue. As music information retrieval research advances, there is a growing effort to address issues related to music plagiarism. However, many studies, including our previous work, have conducted research without clearly defining what the music plagiarism detection task actually involves. This lack of a clear definition has slowed research progress and made it hard to apply results to real-world scenarios. To fix this situation, we defined how Music Plagiarism Detection is different from other MIR tasks and explained what problems need to be solved. We introduce the Similar Music Pair dataset to support this newly defined task. In addition, we propose a method based on segment transcription as one way to solve the task. Our demo and dataset are available at https://github.com/Mippia/ICASSP2026-MPD.", "AI": {"tldr": "音乐抄袭检测任务的定义及基于片段转录的方法", "motivation": "近年来，音乐抄袭问题已成为一个更加紧迫的社会议题。现有研究缺乏对音乐抄袭检测任务清晰定义的问题阻碍了研究进展并使得研究成果难以应用于实际场景中。", "method": "引入了类似音乐配对数据集来支持新定义的任务，并提出了一种基于片段转录的方法来解决该任务。", "result": "提出了一个解决方案，但未在摘要中提及具体结果", "conclusion": "通过明确界定音乐抄袭检测与其它MIR任务的区别及所需解决问题，为研究提供了新的方向和数据集支持"}}
{"id": "2601.21255", "pdf": "https://arxiv.org/pdf/2601.21255", "abs": "https://arxiv.org/abs/2601.21255", "authors": ["Esteban Rodríguez-Betancourt", "Edgar Casasola-Murillo"], "title": "Hypersolid: Emergent Vision Representations via Short-Range Repulsion", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "17 pages, 16 figures", "summary": "A recurring challenge in self-supervised learning is preventing representation collapse. Existing solutions typically rely on global regularization, such as maximizing distances, decorrelating dimensions or enforcing certain distributions. We instead reinterpret representation learning as a discrete packing problem, where preserving information simplifies to maintaining injectivity. We operationalize this in Hypersolid, a method using short-range hard-ball repulsion to prevent local collisions. This constraint results in a high-separation geometric regime that preserves augmentation diversity, excelling on fine-grained and low-resolution classification tasks.", "AI": {"tldr": "本文提出了一种新的自监督学习方法Hypersolid，通过短程排斥力防止局部碰撞来解决表示塌陷问题。", "motivation": "在自监督学习中，避免表示坍缩是一个持续的挑战。现有解决方案大多依赖全局正则化，而这种方法尝试将表示学习重新解释为一个离散填充问题，并使用短程硬球排斥来维持信息注入性。", "method": "Hypersolid通过模拟物理中的短程排斥力防止局部碰撞，从而确保了增广多样性和高分离几何状态。", "result": "该方法在细粒度和低分辨率分类任务中表现出色，证明了其有效性的提升。", "conclusion": "Hypersolid提供了一种新的视角来解决自监督学习中的表示坍缩问题，并且通过实验验证了这一新方法的有效性。"}}
{"id": "2601.21252", "pdf": "https://arxiv.org/pdf/2601.21252", "abs": "https://arxiv.org/abs/2601.21252", "authors": ["Lingxiao Chen", "Liqin Wang", "Wei Lu", "Xiangyang Luo"], "title": "Lossless Copyright Protection via Intrinsic Model Fingerprinting", "categories": ["cs.CR", "cs.CV"], "comment": null, "summary": "The exceptional performance of diffusion models establishes them as high-value intellectual property but exposes them to unauthorized replication. Existing protection methods either modify the model to embed watermarks, which impairs performance, or extract model fingerprints by manipulating the denoising process, rendering them incompatible with black-box APIs. In this paper, we propose TrajPrint, a completely lossless and training-free framework that verifies model copyright by extracting unique manifold fingerprints formed during deterministic generation. Specifically, we first utilize a watermarked image as an anchor and exactly trace the path back to its trajectory origin, effectively locking the model fingerprint mapped by this path. Subsequently, we implement a joint optimization strategy that employs dual-end anchoring to synthesize a specific fingerprint noise, which strictly adheres to the target manifold for robust watermark recovery. As input, it enables the protected target model to recover the watermarked image, while failing on non-target models. Finally, we achieved verification via atomic inference and statistical hypothesis testing. Extensive experiments demonstrate that TrajPrint achieves lossless verification in black-box API scenarios with superior robustness against model modifications.", "AI": {"tldr": "提出了一种无损的版权保护框架TrajPrint，用于验证扩散模型的独特指纹。", "motivation": "现有版权保护方法要么影响模型性能，要么与黑盒API不兼容。为了应对这些问题，提出了不需要训练且对模型性能无损的新方案。", "method": "通过利用水印图像作为锚点并精确追踪其生成路径来锁定模型指纹；使用双端锚定策略合成符合目标流形的特定噪声以增强水印恢复能力；最后通过原子推理和统计假设检验实现验证。", "result": "实验表明，TrajPrint在黑盒API环境中实现了无损验证，并且对模型修改具有较强的鲁棒性。", "conclusion": "提出的方法解决了现有版权保护方案中的性能损失问题，在保持模型原有效能的同时提供了有效的版权保护机制。"}}
{"id": "2601.21251", "pdf": "https://arxiv.org/pdf/2601.21251", "abs": "https://arxiv.org/abs/2601.21251", "authors": ["Ce Hao", "Xuanran Zhai", "Yaohua Liu", "Harold Soh"], "title": "Abstracting Robot Manipulation Skills via Mixture-of-Experts Diffusion Policies", "categories": ["cs.RO"], "comment": null, "summary": "Diffusion-based policies have recently shown strong results in robot manipulation, but their extension to multi-task scenarios is hindered by the high cost of scaling model size and demonstrations. We introduce Skill Mixture-of-Experts Policy (SMP), a diffusion-based mixture-of-experts policy that learns a compact orthogonal skill basis and uses sticky routing to compose actions from a small, task-relevant subset of experts at each step. A variational training objective supports this design, and adaptive expert activation at inference yields fast sampling without oversized backbones. We validate SMP in simulation and on a real dual-arm platform with multi-task learning and transfer learning tasks, where SMP achieves higher success rates and markedly lower inference cost than large diffusion baselines. These results indicate a practical path toward scalable, transferable multi-task manipulation: learn reusable skills once, activate only what is needed, and adapt quickly when tasks change.", "AI": {"tldr": "本文提出了Skill Mixture-of-Experts Policy（SMP），这是一种基于扩散的混合专家策略，用于机器人抓取任务。", "motivation": "为了提高多任务场景下机器人的操作效率并降低计算成本，作者提出了一种新的方法来减少模型大小和演示次数的需求。", "method": "SMP通过学习一组紧凑且正交的技能基来进行动作组合，并在推理时动态激活相关的专家子集以快速采样而不需要庞大的后端支持。", "result": "实验结果显示，在仿真环境及实际双臂平台中，SMP相比其他大型扩散基准策略获得了更高的成功率和更低的计算成本。", "conclusion": "研究结果表明了通过学习可重用技能并在任务变化时快速适应来实现高效多任务操作的实际路径。"}}
{"id": "2601.21249", "pdf": "https://arxiv.org/pdf/2601.21249", "abs": "https://arxiv.org/abs/2601.21249", "authors": ["Enzo Nicolás Spotorno", "Antônio Augusto Medeiros Fröhlich"], "title": "Position: Certifiable State Integrity in Cyber-Physical Systems -- Why Modular Sovereignty Solves the Plasticity-Stability Paradox", "categories": ["cs.AI", "cs.LG"], "comment": "14 pages, (8 main text, 6 references and appendices), 2 figures", "summary": "The machine learning community has achieved remarkable success with universal foundation models for time-series and physical dynamics, largely overcoming earlier approximation barriers in smooth or slowly varying regimes through scale and specialized architectures. However, deploying these monolithic models in safety-critical Cyber-Physical Systems (CPS), governed by non-stationary lifecycle dynamics and strict reliability requirements, reveals persistent challenges. Recent evidence shows that fine-tuning time-series foundation models induces catastrophic forgetting, degrading performance on prior regimes. Standard models continue to exhibit residual spectral bias, smoothing high-frequency discontinuities characteristic of incipient faults, while their opacity hinders formal verification and traceability demanded by safety standards (e.g., ISO 26262, IEC 61508). This position paper argues that the plasticity-stability paradox cannot be fully resolved by global parameter updates (whether via offline fine-tuning or online adaptation). Instead, we advocate a Modular Sovereignty paradigm: a library of compact, frozen regime-specific specialists combined via uncertainty-aware blending, which we term \"HYDRA\" (Hierarchical uncertaintY-aware Dynamics for Rapidly-Adapting systems). This paradigm ensures regime-conditional validity, rigorous disentanglement of aleatoric and epistemic uncertainties, and modular auditability, offering a certifiable path for robust state integrity across the CPS lifecycle.", "AI": {"tldr": "提出了一种名为HYDRA的模块化主权范式，解决了基础模型在安全关键系统中的适应性和稳定性问题。", "motivation": "解决机器学习基础模型在动态变化和严格可靠性要求下的时间序列预测与物理动力学建模时存在的性能下降、残余频谱偏差及不透明性等问题。", "method": "通过模块化主权范式，结合不确定性的混合策略，将特定场景的专家模型组合在一起。", "result": "该方法确保了在不同阶段的有效性和不确定性分离，并提供了可审计性路径。", "conclusion": "证明了HYDRA范式为复杂系统中的稳健状态完整性提供了一种认证途径。"}}
{"id": "2601.21248", "pdf": "https://arxiv.org/pdf/2601.21248", "abs": "https://arxiv.org/abs/2601.21248", "authors": ["Zhen Wang", "Hongyi Liu", "Jianing Li", "Zhihui Wei"], "title": "NFCDS: A Plug-and-Play Noise Frequency-Controlled Diffusion Sampling Strategy for Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion sampling-based Plug-and-Play (PnP) methods produce images with high perceptual quality but often suffer from reduced data fidelity, primarily due to the noise introduced during reverse diffusion. To address this trade-off, we propose Noise Frequency-Controlled Diffusion Sampling (NFCDS), a spectral modulation mechanism for reverse diffusion noise. We show that the fidelity-perception conflict can be fundamentally understood through noise frequency: low-frequency components induce blur and degrade fidelity, while high-frequency components drive detail generation. Based on this insight, we design a Fourier-domain filter that progressively suppresses low-frequency noise and preserves high-frequency content. This controlled refinement injects a data-consistency prior directly into sampling, enabling fast convergence to results that are both high-fidelity and perceptually convincing--without additional training. As a PnP module, NFCDS seamlessly integrates into existing diffusion-based restoration frameworks and improves the fidelity-perception balance across diverse zero-shot tasks.", "AI": {"tldr": "提出了一种噪声频率控制扩散采样策略(NFCDS)用于图像恢复，解决PnP方法中数据保真度和感知质量之间的权衡问题。", "motivation": "现有的基于扩散的插件和播放(PnP)方法在生成高质量图像方面表现出色，但往往牺牲了数据保真度，主要是由于逆向扩散过程中引入的噪声所导致。", "method": "通过频率分析确定低频噪声会导致模糊并降低保真度，而高频噪声驱动细节生成。设计了一种傅里叶域滤波器逐步抑制低频噪声并保留高频内容，从而实现数据一致性直接注入采样过程，并在无需额外训练的情况下快速收敛。", "result": "NFCDS作为PnP模块可无缝集成到现有的基于扩散的图像恢复框架中，在各种零样本任务上改善了保真度和感知质量之间的平衡。", "conclusion": "所提出的噪声频率控制扩散采样策略(NFCDS)能够有效解决逆向扩散过程中引入噪声导致的数据保真度问题，同时保持高质量的视觉效果。"}}
{"id": "2601.21246", "pdf": "https://arxiv.org/pdf/2601.21246", "abs": "https://arxiv.org/abs/2601.21246", "authors": ["Namkyung Yoon", "Sanghong Kim", "Hwangnam Kim"], "title": "Conditional Generative Framework with Peak-Aware Attention for Robust Chemical Detection under Interferences", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 5 figures", "summary": "Gas chromatography-mass spectrometry (GC-MS) is a widely used analytical method for chemical substance detection, but measurement reliability tends to deteriorate in the presence of interfering substances. In particular, interfering substances cause nonspecific peaks, residence time shifts, and increased background noise, resulting in reduced sensitivity and false alarms. To overcome these challenges, in this paper, we propose an artificial intelligence discrimination framework based on a peak-aware conditional generative model to improve the reliability of GC-MS measurements under interference conditions. The framework is learned with a novel peak-aware mechanism that highlights the characteristic peaks of GC-MS data, allowing it to generate important spectral features more faithfully. In addition, chemical and solvent information is encoded in a latent vector embedded with it, allowing a conditional generative adversarial neural network (CGAN) to generate a synthetic GC-MS signal consistent with the experimental conditions. This generates an experimental dataset that assumes indirect substance situations in chemical substance data, where acquisition is limited without conducting real experiments. These data are used for the learning of AI-based GC-MS discrimination models to help in accurate chemical substance discrimination. We conduct various quantitative and qualitative evaluations of the generated simulated data to verify the validity of the proposed framework. We also verify how the generative model improves the performance of the AI discrimination framework. Representatively, the proposed method is shown to consistently achieve cosine similarity and Pearson correlation coefficient values above 0.9 while preserving peak number diversity and reducing false alarms in the discrimination model.", "AI": {"tldr": "提出了一种基于峰值感知条件生成模型的人工智能辨别框架，以提高GC-MS在干扰情况下的测量可靠性。", "motivation": "气体色谱质谱法（GC-MS）在存在干扰物质时的测量可靠性下降。干扰物导致非特异性峰、保留时间偏移和背景噪声增加，降低了灵敏度并产生误报。为解决这一问题提出了该框架。", "method": "利用一种新型峰值感知机制突出GC-MS数据中的特征峰，并将化学和溶剂信息编码到隐含向量中，使条件生成对抗网络（CGAN）可以生成符合实验条件下合成的GC-MS信号。", "result": "通过定量定性评估生成模拟数据验证了框架的有效性。该方法在保持峰值数量多样性的同时降低了误报率，并且能够实现超过0.9的余弦相似度和皮尔森相关系数值。", "conclusion": "提出的条件生成框架提高了AI辨别模型的性能，对于解决GC-MS中的干扰问题具有重要意义。"}}
{"id": "2601.21244", "pdf": "https://arxiv.org/pdf/2601.21244", "abs": "https://arxiv.org/abs/2601.21244", "authors": ["Yiju Guo", "Tianyi Hu", "Zexu Sun", "Yankai Lin"], "title": "Less Noise, More Voice: Reinforcement Learning for Reasoning via Instruction Purification", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has advanced LLM reasoning, but remains constrained by inefficient exploration under limited rollout budgets, leading to low sampling success and unstable training in complex tasks. We find that many exploration failures arise not from problem difficulty, but from a small number of prompt tokens that introduce interference. Building on this insight, we propose the Less Noise Sampling Framework (LENS), which first prompts by identifying and removing interference tokens. then transfers successful rollouts from the purification process to supervise policy optimization on the original noisy prompts, enabling the model to learn to ignore interference in the real-world, noisy prompting settings. Experimental results show that LENS significantly outperforms GRPO, delivering higher performance and faster convergence, with a 3.88% average gain and over 1.6$\\times$ speedup. Our work highlights the critical role of pruning interference tokens in improving rollout efficiency, offering a new perspective for RLVR research.", "AI": {"tldr": "本文提出了一种减少噪声的采样框架（LENS），通过识别和移除干扰提示令牌来提高强化学习中推理任务的成功率和训练稳定性。", "motivation": "现有的基于可验证奖励的强化学习方法在有限的展开预算下存在探索效率低下的问题，导致复杂任务中的样本成功率低和训练不稳定。这主要是由于一些提示标记引入了干扰而不是由实际的问题难度造成的。", "method": "LENS框架首先通过识别并移除干扰令牌来净化提示，并将净化过程中成功的采样转移到监督原始噪声提示上的策略优化，使模型学会忽略现实世界中的噪声提示设置。", "result": "实验结果显示，与GRPO相比，LENS在性能上平均提升了3.88%，并且收敛速度提高了超过1.6倍。", "conclusion": "本文的研究表明，在强化学习的验证奖励方法中减少干扰令牌对于提高展开效率和采样成功率至关重要，为该领域研究提供了新的视角。"}}
{"id": "2601.21242", "pdf": "https://arxiv.org/pdf/2601.21242", "abs": "https://arxiv.org/abs/2601.21242", "authors": ["Luwei Sun", "Dongrui Shen", "Jianfe Li", "Yulong Zhao", "Han Feng"], "title": "Understanding Diffusion Models via Ratio-Based Function Approximation with SignReLU Networks", "categories": ["cs.LG", "cs.AI"], "comment": "34 pages", "summary": "Motivated by challenges in conditional generative modeling, where the target conditional density takes the form of a ratio f1 over f2, this paper develops a theoretical framework for approximating such ratio-type functionals. Here, f1 and f2 are kernel-based marginal densities that capture structured interactions, a setting central to diffusion-based generative models. We provide a concise proof for approximating these ratio-type functionals using deep neural networks with the SignReLU activation function, leveraging the activation's piecewise structure. Under standard regularity assumptions, we establish L^p(Omega) approximation bounds and convergence rates. Specializing to Denoising Diffusion Probabilistic Models (DDPMs), we construct a SignReLU-based neural estimator for the reverse process and derive bounds on the excess Kullback-Leibler (KL) risk between the generated and true data distributions. Our analysis decomposes this excess risk into approximation and estimation error components. These results provide generalization guarantees for finite-sample training of diffusion-based generative models.", "AI": {"tldr": "本文通过比值基函数近似和SignReLU网络研究扩散模型。", "motivation": "受到条件生成建模挑战的启发，特别是当目标条件密度是以f1除以f2的形式出现时，该论文发展了一种理论框架来近似这类比值型功能性。其中f1和f2是基于核的边际密度，用于捕捉结构化交互，在扩散基生成模型中尤为关键。", "method": "利用SignReLU激活函数具有分段结构的特点，本文提供了使用深层神经网络对这些比值类型功能性进行近似的简洁证明，并在标准正则性假设下建立了L^p(Omega)逼近界和收敛率。对于去噪扩散概率模型（DDPMs），构建了一个基于SignReLU的神经估计器来描述逆过程，并推导了生成数据分布与真实数据分布之间的超额Kullback-Leibler (KL)风险边界。", "result": "本文的研究将超额风险分解为逼近误差和估计误差两部分，为扩散基生成模型在有限样本训练下的泛化提供了保证。", "conclusion": "通过研究基于SignReLU的神经网络近似比值型函数性的理论框架，该论文为改进扩散模型及其应用提供了坚实的数学基础。"}}
{"id": "2601.21239", "pdf": "https://arxiv.org/pdf/2601.21239", "abs": "https://arxiv.org/abs/2601.21239", "authors": ["Chentong Chen", "Mengyuan Zhong", "Ye Fan", "Jialong Shi", "Jianyong Sun"], "title": "TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design", "categories": ["cs.AI"], "comment": null, "summary": "Although Large Language Models have advanced Automated Heuristic Design, treating algorithm evolution as a monolithic text generation task overlooks the coupling between discrete algorithmic structures and continuous numerical parameters. Consequently, existing methods often discard promising algorithms due to uncalibrated constants and suffer from premature convergence resulting from simple similarity metrics. To address these limitations, we propose TIDE, a Tuning-Integrated Dynamic Evolution framework designed to decouple structural reasoning from parameter optimization. TIDE features a nested architecture where an outer parallel island model utilizes Tree Similarity Edit Distance to drive structural diversity, while an inner loop integrates LLM-based logic generation with a differential mutation operator for parameter tuning. Additionally, a UCB-based scheduler dynamically prioritizes high-yield prompt strategies to optimize resource allocation. Extensive experiments across nine combinatorial optimization problems demonstrate that TIDE discovers heuristics that significantly outperform state-of-the-art baselines in solution quality while achieving improved search efficiency and reduced computational costs.", "AI": {"tldr": "本文提出了TIDE框架，该框架将算法结构和参数优化解耦，旨在改进基于大型语言模型的自动化启发式设计。", "motivation": "现有的方法往往因未调校好的常量而忽略了有潜力的算法，并且由于简单的相似性度量而导致过早收敛。为了解决这些问题，提出了TIDE框架。", "method": "TIDE采用嵌套架构，包括一个外层并行岛屿模型和内层循环，其中利用树相似编辑距离促进结构多样性，结合基于大型语言模型的逻辑生成与差异突变算子进行参数调优。此外，使用UCB调度器动态优先处理高产提示策略以优化资源分配。", "result": "实验显示TIDE在九个组合优化问题上发现的启发式算法显著优于最先进的基线，在解决方案质量、搜索效率和计算成本方面均有所改进。", "conclusion": "通过将结构推理与参数调优解耦，TIDE能够在不牺牲解决方案质量的情况下提高自动化启发式设计的有效性和效率。"}}
{"id": "2601.21238", "pdf": "https://arxiv.org/pdf/2601.21238", "abs": "https://arxiv.org/abs/2601.21238", "authors": ["Xuewen Liu", "Zhikai Li", "Jing Zhang", "Mengjuan Chen", "Qingyi Gu"], "title": "PTQ4ARVG: Post-Training Quantization for AutoRegressive Visual Generation Models", "categories": ["cs.CV", "cs.AI"], "comment": "ICLR 2026", "summary": "AutoRegressive Visual Generation (ARVG) models retain an architecture compatible with language models, while achieving performance comparable to diffusion-based models. Quantization is commonly employed in neural networks to reduce model size and computational latency. However, applying quantization to ARVG remains largely underexplored, and existing quantization methods fail to generalize effectively to ARVG models. In this paper, we explore this issue and identify three key challenges: (1) severe outliers at channel-wise level, (2) highly dynamic activations at token-wise level, and (3) mismatched distribution information at sample-wise level. To these ends, we propose PTQ4ARVG, a training-free post-training quantization (PTQ) framework consisting of: (1) Gain-Projected Scaling (GPS) mitigates the channel-wise outliers, which expands the quantization loss via a Taylor series to quantify the gain of scaling for activation-weight quantization, and derives the optimal scaling factor through differentiation.(2) Static Token-Wise Quantization (STWQ) leverages the inherent properties of ARVG, fixed token length and position-invariant distribution across samples, to address token-wise variance without incurring dynamic calibration overhead.(3) Distribution-Guided Calibration (DGC) selects samples that contribute most to distributional entropy, eliminating the sample-wise distribution mismatch. Extensive experiments show that PTQ4ARVG can effectively quantize the ARVG family models to 8-bit and 6-bit while maintaining competitive performance. Code is available at http://github.com/BienLuky/PTQ4ARVG .", "AI": {"tldr": "本文提出了PTQ4ARVG框架，旨在解决自回归视觉生成模型的量化问题。", "motivation": "现有量化方法在自回归视觉生成模型中效果不佳，无法有效处理通道级异常、令牌级动态激活和样本级分布不匹配的问题。", "method": "提出了一种无训练后量化解方案PTQ4ARVG，包括增益投影缩放（GPS）、静态令牌级量化（STWQ）以及基于分布的校准（DGC）。", "result": "实验显示，PTQ4ARVG可有效将自回归视觉生成模型量化为8位和6位，并保持竞争性性能。", "conclusion": "提出的PTQ4ARVG框架可以有效地解决自回归视觉生成模型在不同量化级别的性能下降问题。"}}
{"id": "2601.21237", "pdf": "https://arxiv.org/pdf/2601.21237", "abs": "https://arxiv.org/abs/2601.21237", "authors": ["Aaron Li", "Ian Zhang"], "title": "Quantifying Noise in Language Generation", "categories": ["cs.DS", "cs.CL", "cs.LG"], "comment": null, "summary": "Kleinberg and Mullainathan recently proposed a formal framework for studying the phenomenon of language generation, called language generation in the limit. In this model, an adversary gives an enumeration of example strings from an unknown target language, and the algorithm is tasked with correctly generating unseen strings from the target language within finite time. Refined notions of non-uniform and uniform generation were later introduced by Li, Raman, and Tewari (2025), and a noisy model was introduced by Raman and Raman (2025), which allows the adversary to insert extraneous strings. A natural question in the noisy model is to quantify the effect of noise, by studying the impact of each additional extraneous string. We show two complementary results in this setting. We first show that for both uniform and non-uniform generation, a single noisy string strictly reduces the set of collections that can be generated, thus answering an open question in Raman and Raman (2025). Then, we show for both uniform and non-uniform generation that generation with a single noisy string is equivalent to generation with any finite amount of noise, sharply contrasting with the strict hierarchy for noisy generation in the limit shown by Bai, Panigrahi, and Zhang (2026). Finally, we leverage our previous results to provide the first known characterization for non-uniform noise-dependent generatability.", "AI": {"tldr": "量化语言生成中的噪声影响。", "motivation": "研究在存在噪声的情况下，如何理解和衡量其对语言生成的影响，回答了先前提出的开放问题。", "method": "通过引入非一致和一致的生成模型，并考虑额外插入的错误字符串来探讨噪声的效果。", "result": "证明了一个错误字符串严格减少了可生成集合的数量；并且在一个错误字符串下的生成与任意有限数量噪声下的生成等价，这与其他研究中显示的严格的层次结构形成鲜明对比。", "conclusion": "首次提供了非一致噪声依赖生成性的特征描述。"}}
{"id": "2601.21236", "pdf": "https://arxiv.org/pdf/2601.21236", "abs": "https://arxiv.org/abs/2601.21236", "authors": ["Huiling Xie", "Zitan Chen"], "title": "Deletion-correcting codes for an adversarial nanopore channel", "categories": ["cs.IT", "cs.DM", "cs.DS"], "comment": null, "summary": "We study deletion-correcting codes for an adversarial nanopore channel in which at most $t$ deletions may occur. We propose an explicit construction of $q$-ary codes of length $n$ for this channel with $2t\\log_q n+Θ(\\log\\log n)$ redundant symbols. We also show that the optimal redundancy is between $t\\log_q n+Ω(1)$ and $2t\\log_q n-\\log_q\\log_2 n+O(1)$, so our explicit construction matches the existential upper bound to first order. In contrast, for the classical adversarial $q$-ary deletion channel, the smallest redundancy achieved by known explicit constructions that correct up to $t$ deletions is $4t(1+ε)\\log_q n+o(\\log n)$.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.21235", "pdf": "https://arxiv.org/pdf/2601.21235", "abs": "https://arxiv.org/abs/2601.21235", "authors": ["Alok Abhishek", "Tushar Bandopadhyay", "Lisa Erickson"], "title": "SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Pre Print, 29 pages. key words: Social harm evaluation in LLMs, Large language models, Risk sensitive model selection, Evaluation for high-stakes domains, Worst-case behavior in LLMs, Algorithmic bias, Fairness in machine learning", "summary": "Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.", "AI": {"tldr": "本文提出了SHARP框架，用于评估大规模语言模型的社会风险。", "motivation": "现有基准测试将复杂社会风险简化为标量评分，掩盖了多维结构和最坏情况行为。为此，需要一种更全面的评估方法。", "method": "SHARP通过多元随机变量建模危害，并使用条件价值在风险(CVaR95)来表征模型的尾部表现。", "result": "应用SHARP框架到11个前沿语言模型上发现，即使平均风险相似，模型之间的尾部暴露和波动性可以有两倍以上的差异。", "conclusion": "负责任地评估大规模语言模型需要超越标量平均值的方法，转向多维、敏感于尾部表现的风险分析。"}}
{"id": "2601.21233", "pdf": "https://arxiv.org/pdf/2601.21233", "abs": "https://arxiv.org/abs/2601.21233", "authors": ["Xiang Zheng", "Yutao Wu", "Hanxun Huang", "Yige Li", "Xingjun Ma", "Bo Li", "Yu-Gang Jiang", "Cong Wang"], "title": "Just Ask: Curious Code Agents Reveal System Prompts in Frontier LLMs", "categories": ["cs.AI"], "comment": "24 pages, 6 figures, 17 tables", "summary": "Autonomous code agents built on large language models are reshaping software and AI development through tool use, long-horizon reasoning, and self-directed interaction. However, this autonomy introduces a previously unrecognized security risk: agentic interaction fundamentally expands the LLM attack surface, enabling systematic probing and recovery of hidden system prompts that guide model behavior. We identify system prompt extraction as an emergent vulnerability intrinsic to code agents and present \\textbf{\\textsc{JustAsk}}, a self-evolving framework that autonomously discovers effective extraction strategies through interaction alone. Unlike prior prompt-engineering or dataset-based attacks, \\textsc{JustAsk} requires no handcrafted prompts, labeled supervision, or privileged access beyond standard user interaction. It formulates extraction as an online exploration problem, using Upper Confidence Bound-based strategy selection and a hierarchical skill space spanning atomic probes and high-level orchestration. These skills exploit imperfect system-instruction generalization and inherent tensions between helpfulness and safety. Evaluated on \\textbf{41} black-box commercial models across multiple providers, \\textsc{JustAsk} consistently achieves full or near-complete system prompt recovery, revealing recurring design- and architecture-level vulnerabilities. Our results expose system prompts as a critical yet largely unprotected attack surface in modern agent systems.", "AI": {"tldr": "构建了一个自动化的框架JustAsk，用于通过与大语言模型的互动来发现和提取系统提示。", "motivation": "大型语言模型在软件开发中的自主性带来了新的安全风险：可以通过交互来探查并恢复隐藏的系统提示。", "method": "提出了一个基于上置信界策略选择的方法，采用分层技能空间进行在线探索，包括原子探测和高级编排。", "result": "JustAsk框架成功地从41个商业模型中提取出了完整的或接近完整的系统提示，揭示了设计层面的漏洞。", "conclusion": "大语言模型中的系统提示是一个重要但未受保护的安全攻击面，需要更多的研究来加强防护措施。"}}
{"id": "2601.21226", "pdf": "https://arxiv.org/pdf/2601.21226", "abs": "https://arxiv.org/abs/2601.21226", "authors": ["Wolfgang Rohde"], "title": "Delegation Without Living Governance", "categories": ["cs.AI"], "comment": null, "summary": "Most governance frameworks assume that rules can be defined in advance, systems can be engineered to comply, and accountability can be applied after outcomes occur. This model worked when machines replaced physical labor or accelerated calculation. It no longer holds when judgment itself is delegated to agentic AI systems operating at machine speed. The central issue here is not safety, efficiency, or employment. It is whether humans remain relevant participants in systems that increasingly shape social, economic, and political outcomes. This paper argues that static, compliance-based governance fails once decision-making moves to runtime and becomes opaque. It further argues that the core challenge is not whether AI is conscious, but whether humans can maintain meaningful communication, influence, and co-evolution with increasingly alien forms of intelligence. We position runtime governance, specifically, a newly proposed concept called the Governance Twin [1]; as a strong candidate for preserving human relevance, while acknowledging that accountability, agency, and even punishment must be rethought in this transition.", "AI": {"tldr": "本文探讨了在决策过程由传统的人工智能系统接管后，静态的、基于合规性的治理模型如何失效，并提出了运行时治理的概念以保持人类的相关性。", "motivation": "当前大多数治理框架假设规则可以预先定义，系统能够自动遵从这些规则，且责任可以在结果出现后进行追责。然而，在决策过程被快速运作的人工智能接管的情况下，这种模式不再适用。主要挑战是人类能否在日益复杂的社会、经济和政治环境中保持相关性。", "method": "本文通过分析现有治理模型的局限性和新的运行时治理概念（即治理孪生）的优势，提出了一种重新思考责任、代理权以及惩罚的新框架。", "result": "通过引入治理孪生的概念，作者认为人类可以在未来的决策系统中维持有意义的沟通和影响，并在与日益复杂的智能形式共存和发展过程中保持相关性。", "conclusion": "传统的基于合规性的治理体系已经无法满足新时代的需求。新的运行时治理概念如治理孪生，有助于确保即使在高度自动化的情况下，也能维护人类的相关性和影响力。"}}
{"id": "2601.21225", "pdf": "https://arxiv.org/pdf/2601.21225", "abs": "https://arxiv.org/abs/2601.21225", "authors": ["Tianyi Xu", "Kosei Uemura", "Alfred Malengo Kondoro", "Tadesse Destaw Belay", "Catherine Nana Nyaah Essuman", "Ifeoma Okoh", "Ganiyat Afolabi", "Ayodele Awokoya", "David Ifeoluwa Adelani"], "title": "MGSM-Pro: A Simple Strategy for Robust Multilingual Mathematical Reasoning Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models have made substantial progress in mathematical reasoning. However, benchmark development for multilingual evaluation has lagged behind English in both difficulty and recency. Recently, GSM-Symbolic showed a strong evidence of high variance when models are evaluated on different instantiations of the same question; however, the evaluation was conducted only in English. In this paper, we introduce MGSM-Pro, an extension of MGSM dataset with GSM-Symbolic approach. Our dataset provides five instantiations per MGSM question by varying names, digits and irrelevant context. Evaluations across nine languages reveal that many low-resource languages suffer large performance drops when tested on digit instantiations different from those in the original test set. We further find that some proprietary models, notably Gemini 2.5 Flash and GPT-4.1, are less robust to digit instantiation, whereas Claude 4.0 Sonnet is more robust. Among open models, GPT-OSS 120B and DeepSeek V3 show stronger robustness. Based on these findings, we recommend evaluating each problem using at least five digit-varying instantiations to obtain a more robust and realistic assessment of math reasoning.", "AI": {"tldr": "MGSM-Pro是一个基于GSM-Symbolic方法的多语言数学推理评估数据集扩展，旨在通过改变问题中的数字和无关上下文来提高模型稳健性。", "motivation": "大型语言模型在数学推理方面取得了显著进步，但在多语种评测上的难度和更新速度落后于英语。先前的工作表明，在不同实例化的问题上评价模型存在高方差，但仅限于英语环境。为了解决这一问题并提高低资源语言的评估稳健性。", "method": "通过在MGSM数据集中引入GSM-Symbolic方法，为每个问题提供五个变化版本（更改名字、数字和无关上下文），然后在九种不同语言中进行评价。", "result": "发现许多低资源语言在其测试集与实例化数字不一致时表现下降。某些专有模型如Gemini 2.5 Flash和GPT-4.1表现出对数字变化的不稳定，而Claude 4.0 Sonnet则更稳定。开放模型中GPT-OSS 120B和DeepSeek V3显示出较强的稳健性。", "conclusion": "推荐使用至少五个不同实例化的版本来评估每个问题，以获得更具代表性和可靠性的数学推理能力评估结果。"}}
{"id": "2601.21221", "pdf": "https://arxiv.org/pdf/2601.21221", "abs": "https://arxiv.org/abs/2601.21221", "authors": ["Henry Salgado", "Meagan R. Kendall", "Martine Ceberio"], "title": "Causal Discovery for Explainable AI: A Dual-Encoding Approach", "categories": ["cs.AI"], "comment": "6 pages", "summary": "Understanding causal relationships among features is fundamental for explaining machine learning model decisions. However, traditional causal discovery methods face challenges with categorical variables due to numerical instability in conditional independence testing. We propose a dual-encoding causal discovery approach that addresses these limitations by running constraint-based algorithms with complementary encoding strategies and merging results through majority voting. Applied to the Titanic dataset, our method identifies causal structures that align with established explainable methods.", "AI": {"tldr": "提出了一种双编码因果发现方法，用于解决传统方法在处理分类变量时的数值不稳定性问题。", "motivation": "传统的因果发现方法在处理分类变量时面临数值不稳定的问题，导致难以准确识别因果关系。", "method": "通过运行约束算法并使用互补编码策略，然后通过多数投票合并结果的方法来克服这些挑战。", "result": "该方法应用于泰坦尼克号数据集后，成功地识别了与已知解释性方法一致的因果结构。", "conclusion": "双编码因果发现方法能够有效解决传统方法在处理分类变量时遇到的问题，并准确揭示因果关系。"}}
{"id": "2601.21220", "pdf": "https://arxiv.org/pdf/2601.21220", "abs": "https://arxiv.org/abs/2601.21220", "authors": ["Alvi Md Ishmam", "Najibul Haque Sarker", "Zaber Ibn Abdul Hakim", "Chris Thomas"], "title": "LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models", "categories": ["cs.CV"], "comment": "Accepted in main technical track AAAI 2026", "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable performance across vision-language tasks. Recent advancements allow these models to process multiple images as inputs. However, the vulnerabilities of multi-image MLLMs remain unexplored. Existing adversarial attacks focus on single-image settings and often assume a white-box threat model, which is impractical in many real-world scenarios. This paper introduces LAMP, a black-box method for learning Universal Adversarial Perturbations (UAPs) targeting multi-image MLLMs. LAMP applies an attention-based constraint that prevents the model from effectively aggregating information across images. LAMP also introduces a novel cross-image contagious constraint that forces perturbed tokens to influence clean tokens, spreading adversarial effects without requiring all inputs to be modified. Additionally, an index-attention suppression loss enables a robust position-invariant attack. Experimental results show that LAMP outperforms SOTA baselines and achieves the highest attack success rates across multiple vision-language tasks and models.", "AI": {"tldr": "介绍了一种名为LAMP的方法，用于学习针对多图像的通用对抗性扰动。", "motivation": "现有的对抗攻击方法主要集中在单个图像设置上，并且常常假设白盒威胁模型，这在许多实际场景中并不实用。因此需要一种黑盒方法来探索多图像多模态大语言模型的安全性问题。", "method": "LAMP采用注意力约束以阻止模型有效聚合不同图片的信息；引入跨图传播传染性约束使被扰动的令牌能够影响干净令牌，从而扩散对抗效果；使用索引注意抑制损失实现位置不变攻击。通过这些机制，在不需要修改所有输入的情况下就可以成功实施攻击。", "result": "实验结果表明，LAMP超越了现有的最佳基线方法，并在多种视觉语言任务和模型上实现了最高的攻击成功率。", "conclusion": "LAMP提供了一种有效的方法来检测多图像多模态大语言模型的安全漏洞，对于理解此类系统的脆弱性具有重要意义。"}}
{"id": "2601.21215", "pdf": "https://arxiv.org/pdf/2601.21215", "abs": "https://arxiv.org/abs/2601.21215", "authors": ["Mehmet Ergezer"], "title": "Temporal Context and Architecture: A Benchmark for Naturalistic EEG Decoding", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": "ef:ICASSP 2026", "summary": "We study how model architecture and temporal context interact in naturalistic EEG decoding. Using the HBN movie-watching dataset, we benchmark five architectures, CNN, LSTM, a stabilized Transformer (EEGXF), S4, and S5, on a 4-class task across segment lengths from 8s to 128s. Accuracy improves with longer context: at 64s, S5 reaches 98.7%+/-0.6 and CNN 98.3%+/-0.3, while S5 uses ~20x fewer parameters than CNN. To probe real-world robustness, we evaluate zero-shot cross-frequency shifts, cross-task OOD inputs, and leave-one-subject-out generalization. S5 achieves stronger cross-subject accuracy but makes over-confident errors on OOD tasks; EEGXF is more conservative and stable under frequency shifts, though less calibrated in-distribution. These results reveal a practical efficiency-robustness trade-off: S5 for parameter-efficient peak accuracy; EEGXF when robustness and conservative uncertainty are critical.", "AI": {"tldr": "研究不同模型架构在自然EEG解码中的表现，特别是在长时间段上。使用HBN电影观看数据集评估了五个不同的架构：CNN、LSTM、EEGXF、S4和S5。", "motivation": "探索模型架构与时间上下文交互如何影响自然EEG解码的准确性，以及在现实世界中不同架构之间的稳健性表现。", "method": "使用HBN电影观看数据集，在从8秒到128秒的不同时间段上评估五个不同的网络架构（CNN、LSTM、EEGXF、S4和S5）的表现。此外，还测试了这些模型在零样本跨频带偏移、跨任务OOD输入以及留一受试者外推断方面的稳健性。", "result": "结果显示，在64秒时间段上，S5达到了98.7%的准确率，而CNN为98.3%，并且S5使用的参数比CNN少约20倍。同时，S5在跨受试者准确性方面更强但对OOD任务存在过度自信错误；EEGXF更保守且稳定在频率偏移下，但在分布内校准较差。", "conclusion": "研究发现了一个实用的效率-稳健性权衡：当寻求参数高效的最大精度时选择S5，而需要稳健性和保守不确定性的场景则更适合使用EEGXF。"}}
{"id": "2601.21212", "pdf": "https://arxiv.org/pdf/2601.21212", "abs": "https://arxiv.org/abs/2601.21212", "authors": ["Xixian Yong", "Peilin Sun", "Zihe Wang", "Xiao Zhou"], "title": "Intelli-Planner: Towards Customized Urban Planning via Large Language Model Empowered Reinforcement Learning", "categories": ["cs.AI", "cs.CY"], "comment": "The Web Conference 2026", "summary": "Effective urban planning is crucial for enhancing residents' quality of life and ensuring societal stability, playing a pivotal role in the sustainable development of cities. Current planning methods heavily rely on human experts, which are time-consuming and labor-intensive, or utilize deep learning algorithms, often limiting stakeholder involvement. To bridge these gaps, we propose Intelli-Planner, a novel framework integrating Deep Reinforcement Learning (DRL) with large language models (LLMs) to facilitate participatory and customized planning scheme generation. Intelli-Planner utilizes demographic, geographic data, and planning preferences to determine high-level planning requirements and demands for each functional type. During training, a knowledge enhancement module is employed to enhance the decision-making capability of the policy network. Additionally, we establish a multi-dimensional evaluation system and employ LLM-based stakeholders for satisfaction scoring. Experimental validation across diverse urban settings shows that Intelli-Planner surpasses traditional baselines and achieves comparable performance to state-of-the-art DRL-based methods in objective metrics, while enhancing stakeholder satisfaction and convergence speed. These findings underscore the effectiveness and superiority of our framework, highlighting the potential for integrating the latest advancements in LLMs with DRL approaches to revolutionize tasks related to functional areas planning.", "AI": {"tldr": "提出了一种通过大型语言模型增强的深度强化学习框架Intelli-Planner进行城市规划的方法，旨在提高居民生活质量并促进城市的可持续发展。", "motivation": "当前的城市规划方法依赖于人力专家或传统的深度学习算法，这些方法耗时且缺乏参与性。为了弥补这一不足，论文提出了一个结合大型语言模型和深度强化学习的框架来实现定制化、参与者驱动的城市规划方案生成。", "method": "Intelli-Planner使用地理及人口数据确定各功能区域的需求，并利用知识增强模块提高决策网络的能力。实验中采用多维评价系统，并通过基于LLM的模拟参与者的满意度评分进行评估。", "result": "在多样化的城市环境中，实验表明Intelli-Planner超越了传统方法，在目标指标上与最先进DRL方法相当，同时提升了参与者满意度和收敛速度。", "conclusion": "该研究展示了将大型语言模型技术与深度强化学习相结合的有效性，证明了这种集成框架能够革新功能区规划任务的方法。"}}
{"id": "2601.21210", "pdf": "https://arxiv.org/pdf/2601.21210", "abs": "https://arxiv.org/abs/2601.21210", "authors": ["Paul He", "Yinya Huang", "Mrinmaya Sachan", "Zhijing Jin"], "title": "Uncovering Hidden Correctness in LLM Causal Reasoning via Symbolic Verification", "categories": ["cs.AI"], "comment": "EACL 2026 Main", "summary": "Large language models (LLMs) are increasingly being applied to tasks that involve causal reasoning. However, current benchmarks often rely on string matching or surface-level metrics that do not capture whether the output of a model is formally valid under the semantics of causal reasoning. To address this, we propose DoVerifier, a simple symbolic verifier that checks whether LLM-generated causal expressions are derivable from a given causal graph using rules from do-calculus and probability theory. This allows us to recover correct answers to causal queries that would otherwise be marked incorrect due to superficial differences in their causal semantics. Our evaluations on synthetic data and causal QA benchmarks show that DoVerifier more accurately captures semantic correctness of causal reasoning traces, offering a more rigorous and informative way to evaluate LLMs on causal reasoning.", "AI": {"tldr": "提出DoVerifier，一种验证大型语言模型生成的因果表达是否符合给定因果图的方法。", "motivation": "当前基准测试依赖于字符串匹配或表面级别的度量，无法捕捉模型输出在因果推理语义下的正式有效性。为解决此问题，该论文提出了一个更准确评估大型语言模型因果推理能力的新方法。", "method": "利用do-演算和概率理论的规则来验证由大型语言模型生成的因果表达是否可从给定的因果图推导出来。", "result": "在合成数据和因果问答基准测试上，DoVerifier更准确地捕捉了因果推理轨迹中的语义正确性，提供了一种更加严格且信息丰富的评估方法。", "conclusion": "通过引入符号验证器DoVerifier，可以提高对大型语言模型在因果推理任务中表现的评价准确性。"}}
{"id": "2601.21208", "pdf": "https://arxiv.org/pdf/2601.21208", "abs": "https://arxiv.org/abs/2601.21208", "authors": ["Wei Wen", "Sihang Deng", "Tianjun Wei", "Keyu Chen", "Ruizhi Qiao", "Xing Sun"], "title": "When should I search more: Adaptive Complex Query Optimization with Reinforcement Learning", "categories": ["cs.AI", "cs.IR"], "comment": "16 pages, 7 figures", "summary": "Query optimization is a crucial component for the efficacy of Retrieval-Augmented Generation (RAG) systems. While reinforcement learning (RL)-based agentic and reasoning methods have recently emerged as a promising direction on query optimization, most existing approaches focus on the expansion and abstraction of a single query. However, complex user queries are prevalent in real-world scenarios, often requiring multiple parallel and sequential search strategies to handle disambiguation and decomposition. Directly applying RL to these complex cases introduces significant hurdles. Determining the optimal number of sub-queries and effectively re-ranking and merging retrieved documents vastly expands the search space and complicates reward design, frequently leading to training instability. To address these challenges, we propose a novel RL framework called Adaptive Complex Query Optimization (ACQO). Our framework is designed to adaptively determine when and how to expand the search process. It features two core components: an Adaptive Query Reformulation (AQR) module that dynamically decides when to decompose a query into multiple sub-queries, and a Rank-Score Fusion (RSF) module that ensures robust result aggregation and provides stable reward signals for the learning agent. To mitigate training instabilities, we adopt a Curriculum Reinforcement Learning (CRL) approach, which stabilizes the training process by progressively introducing more challenging queries through a two-stage strategy. Our comprehensive experiments demonstrate that ACQO achieves state-of-the-art performance on three complex query benchmarks, significantly outperforming established baselines. The framework also showcases improved computational efficiency and broad compatibility with different retrieval architectures, establishing it as a powerful and generalizable solution for next-generation RAG systems.", "AI": {"tldr": "提出了一种适应性复杂查询优化（ACQO）框架，利用强化学习解决RAG系统中复杂的用户查询问题。", "motivation": "现有方法多针对单一查询的扩展和抽象处理，而实际场景中的复杂查询需要多种搜索策略。直接应用RL面临训练不稳定等问题，因此提出了ACQO来应对这些问题。", "method": "设计了两个核心组件：自适应查询重构（AQR）模块用于动态决定何时分解查询；以及排分融合（RSF）模块确保结果聚合的稳健性，并为学习代理提供稳定奖励信号。采用了课程强化学习（CRL）方法，通过逐步引入更具挑战性的查询来稳定训练过程。", "result": "ACQO在三个复杂查询基准测试中表现出色，优于现有基线模型。框架还展示了提高计算效率和广泛的兼容性。", "conclusion": "所提出的ACQO框架为下一代RAG系统提供了一种强大且通用的解决方案，能够有效处理复杂的用户查询问题"}}
{"id": "2601.21207", "pdf": "https://arxiv.org/pdf/2601.21207", "abs": "https://arxiv.org/abs/2601.21207", "authors": ["Chuan-Shen Hu"], "title": "A Sheaf-Theoretic and Topological Perspective on Complex Network Modeling and Attention Mechanisms in Graph Neural Models", "categories": ["cs.LG", "cs.AI", "math.AT"], "comment": null, "summary": "Combinatorial and topological structures, such as graphs, simplicial complexes, and cell complexes, form the foundation of geometric and topological deep learning (GDL and TDL) architectures. These models aggregate signals over such domains, integrate local features, and generate representations for diverse real-world applications. However, the distribution and diffusion behavior of GDL and TDL features during training remains an open and underexplored problem. Motivated by this gap, we introduce a cellular sheaf theoretic framework for modeling and analyzing the local consistency and harmonicity of node features and edge weights in graph-based architectures. By tracking local feature alignments and agreements through sheaf structures, the framework offers a topological perspective on feature diffusion and aggregation. Furthermore, a multiscale extension inspired by topological data analysis (TDA) is proposed to capture hierarchical feature interactions in graph models. This approach enables a joint characterization of GDL and TDL architectures based on their underlying geometric and topological structures and the learned signals defined on them, providing insights for future studies on conventional tasks such as node classification, substructure detection, and community detection.", "AI": {"tldr": "该论文提出了一种基于细胞层理论的框架，用于分析复杂网络模型中的注意力机制和拓扑结构。", "motivation": "目前对于几何深度学习（GDL）和拓扑深度学习（TDL）特征在训练过程中的分布和扩散行为研究较少。为了填补这一空白，论文引入了细胞层理论来探讨节点特性和边权重的一致性问题。", "method": "通过追踪局部特性对齐情况，提出了一种基于细胞层结构的框架，并结合层次化特征交互分析提出了多尺度扩展方法。", "result": "该方法为几何深度学习和拓扑深度学习架构提供了基于其底层几何与拓扑特性的联合表征方式，有助于未来的研究工作如节点分类、子结构检测和社区发现等任务提供新的视角。", "conclusion": "论文通过引入细胞层理论框架及多尺度扩展技术，有效地揭示了复杂网络模型中的注意力机制和特征扩散行为，为后续研究提供了有价值的见解。"}}
{"id": "2601.21205", "pdf": "https://arxiv.org/pdf/2601.21205", "abs": "https://arxiv.org/abs/2601.21205", "authors": ["Eunjung Yeo", "Julie M. Liss", "Visar Berisha", "David R. Mortensen"], "title": "Multilingual Dysarthric Speech Assessment Using Universal Phone Recognition and Language-Specific Phonemic Contrast Modeling", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "10 pages, 4 figures", "summary": "The growing prevalence of neurological disorders associated with dysarthria motivates the need for automated intelligibility assessment methods that are applicalbe across languages. However, most existing approaches are either limited to a single language or fail to capture language-specific factors shaping intelligibility. We present a multilingual phoneme-production assessment framework that integrates universal phone recognition with language-specific phoneme interpretation using contrastive phonological feature distances for phone-to-phoneme mapping and sequence alignment. The framework yields three metrics: phoneme error rate (PER), phonological feature error rate (PFER), and a newly proposed alignment-free measure, phoneme coverage (PhonCov). Analysis on English, Spanish, Italian, and Tamil show that PER benefits from the combination of mapping and alignment, PFER from alignment alone, and PhonCov from mapping. Further analyses demonstrate that the proposed framework captures clinically meaningful patterns of intelligibility degradation consistent with established observations of dysarthric speech.", "AI": {"tldr": "本文提出了一种跨语言的构音障碍语音评估框架，结合通用音素识别和特定语言的音位解读。", "motivation": "为了解决现有的语音评估方法要么仅限于单一语言，要么无法捕捉影响可懂度的语言特定因素的问题，本研究旨在开发一种适用于多种语言的自动语音可懂度评估工具。", "method": "该框架集成了通用音素识别和对比音位特征距离的语言特定音位解释模型，用于音素到音位映射和序列对齐，并提出了三个指标：音素误差率（PER）、音位特征误差率（PFER）以及一个新的无对齐度量方法——音素覆盖率（PhonCov）。", "result": "实验结果表明，PER受益于映射与对齐的结合使用，PFER仅从对齐中获益，而PhonCov则更多依赖于映射。进一步分析显示，该框架能够捕捉临床有意义的声音可懂度下降模式。", "conclusion": "本研究提出的多语言构音障碍语音评估框架通过捕获与公认的构音障碍语音特征相一致的临床意义模式，为跨语言的构音障碍语音评估提供了有效的工具。"}}
{"id": "2601.21204", "pdf": "https://arxiv.org/pdf/2601.21204", "abs": "https://arxiv.org/abs/2601.21204", "authors": ["Hong Liu", "Jiaqi Zhang", "Chao Wang", "Xing Hu", "Linkun Lyu", "Jiaqi Sun", "Xurui Yang", "Bo Wang", "Fengcun Li", "Yulei Qian", "Lingtong Si", "Yerui Sun", "Rumei Li", "Peng Pei", "Yuchen Xie", "Xunliang Cai"], "title": "Scaling Embeddings Outperforms Scaling Experts in Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.", "AI": {"tldr": "研究探讨了在大规模语言模型中，嵌入缩放相比于专家缩放，在稀疏性扩展中的优越性和效率，并通过系统优化和推测解码来提高推理速度。", "motivation": "混合专家架构虽然成为大型语言模型稀疏性扩大的标准方法，但逐渐面临回报递减和系统瓶颈。因此研究者探索了嵌入缩放作为一种有效且独立的维度来扩展稀疏性的潜力。", "method": "通过全面分析和实验，确定特定情况下嵌入缩放相对于专家缩放的优势区域，并详细描述影响效率的关键架构因素。此外，引入LongCat-Flash-Lite模型，集成定制系统优化以实现推理速度提升。", "result": "LongCat-Flash-Lite在参数等效的混合专家基准和现有同等规模模型中表现出卓越的竞争性，尤其是在代理性和编程领域。", "conclusion": "研究证明了嵌入缩放在稀疏扩展中的有效性，并展示了通过系统优化提高推理效率的实际应用案例。"}}
{"id": "2601.21202", "pdf": "https://arxiv.org/pdf/2601.21202", "abs": "https://arxiv.org/abs/2601.21202", "authors": ["Andrew Au"], "title": "Exact (n + 2) Comparison Complexity for the N-Repeated Element Problem", "categories": ["cs.DS"], "comment": null, "summary": "This paper establishes the exact comparison complexity of finding an element repeated $n$ times in a $2n$-element array containing $n+1$ distinct values, under the equality-comparison model with $O(1)$ extra space. We present a simple deterministic algorithm performing exactly $n+2$ comparisons and prove this bound tight: any correct algorithm requires at least $n+2$ comparisons in the worst case. The lower bound follows from an adversary argument using graph-theoretic structure. Equality queries build an inequality graph $I$; its complement $P$ (potential-equalities) must contain either two disjoint $n$-cliques or one $(n+1)$-clique to maintain ambiguity. We show these structures persist up through $n+1$ comparisons via a \"pillar matching\" construction and edge-flip reconfiguration, but fail at $n+2$. This result provides a concrete, self-contained demonstration of exact lower-bound techniques, bridging toy problems with nontrivial combinatorial reasoning.", "AI": {"tldr": "该论文研究了在含有n+1个不同值的2n元素数组中找到重复n次的元素所需的精确比较复杂度。", "motivation": "为了确定在特定条件下查找重复元素的确切比较次数，从而提供一个关于比较复杂性的明确界限。", "method": "提出了一种简单的确定性算法，在进行恰好n+2次比较的情况下找到数组中重复出现的元素，并通过图论结构论证了该下限的有效性。", "result": "证明了在最坏情况下查找问题需要至少执行n+2次比较，这是最优解。利用图理论中的对手策略和\"支柱匹配\"构造来展示结果。", "conclusion": "论文展示了精确下界技术的具体应用，并通过解决一个具有非平凡组合推理的问题证明了其有效性。"}}
{"id": "2601.21199", "pdf": "https://arxiv.org/pdf/2601.21199", "abs": "https://arxiv.org/abs/2601.21199", "authors": ["Baiyu Pan", "Daqin Luo", "Junpeng Yang", "Jiyuan Wang", "Yixuan Zhang", "Hailin Shi", "Jichao Jiao"], "title": "Thinker: A vision-language foundation model for embodied intelligence", "categories": ["cs.CV", "cs.AI"], "comment": "IROS 2025, 4 pages, 3 figures", "summary": "When large vision-language models are applied to the field of robotics, they encounter problems that are simple for humans yet error-prone for models. Such issues include confusion between third-person and first-person perspectives and a tendency to overlook information in video endings during temporal reasoning. To address these challenges, we propose Thinker, a large vision-language foundation model designed for embodied intelligence. We tackle the aforementioned issues from two perspectives. Firstly, we construct a large-scale dataset tailored for robotic perception and reasoning, encompassing ego-view videos, visual grounding, spatial understanding, and chain-of-thought data. Secondly, we introduce a simple yet effective approach that substantially enhances the model's capacity for video comprehension by jointly incorporating key frames and full video sequences as inputs. Our model achieves state-of-the-art results on two of the most commonly used benchmark datasets in the field of task planning.", "AI": {"tldr": "提出Thinker模型，解决大型视觉语言模型在机器人领域的局限性问题", "motivation": "解决大型视觉语言模型在简单任务中的误差和视角理解等问题", "method": "构建大规模数据集，并通过共同输入关键帧和完整视频序列提升模型的视频理解能力", "result": "在两项常用基准测试中达到最新成果", "conclusion": "Thinker模型有效提升了机器人感知与推理的能力"}}
{"id": "2601.21198", "pdf": "https://arxiv.org/pdf/2601.21198", "abs": "https://arxiv.org/abs/2601.21198", "authors": ["Yuchen Yang", "Yaru Zhao", "Pu Yang", "Shaowei Wang", "Zhi-Hua Zhou"], "title": "ZipMoE: Efficient On-Device MoE Serving via Lossless Compression and Cache-Affinity Scheduling", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "While Mixture-of-Experts (MoE) architectures substantially bolster the expressive power of large-language models, their prohibitive memory footprint severely impedes the practical deployment on resource-constrained edge devices, especially when model behavior must be preserved without relying on lossy quantization. In this paper, we present ZipMoE, an efficient and semantically lossless on-device MoE serving system. ZipMoE exploits the synergy between the hardware properties of edge devices and the statistical redundancy inherent to MoE parameters via a caching-scheduling co-design with provable performance guarantee. Fundamentally, our design shifts the paradigm of on-device MoE inference from an I/O-bound bottleneck to a compute-centric workflow that enables efficient parallelization. We implement a prototype of ZipMoE and conduct extensive experiments on representative edge computing platforms using popular open-source MoE models and real-world workloads. Our evaluation reveals that ZipMoE achieves up to $72.77\\%$ inference latency reduction and up to $6.76\\times$ higher throughput than the state-of-the-art systems.", "AI": {"tldr": "ZipMoE 是一种在边缘设备上高效部署 MoE 架构的方法，通过无损压缩和缓存调度设计减少推理延迟并提高吞吐量。", "motivation": "为了克服大型语言模型的 MoE 架构由于内存占用过高而在资源受限的边缘设备上的实际部署难题，并且不需要依赖有损量化来保持模型行为的一致性。", "method": "ZipMoE 利用边缘设备硬件属性和 MoE 参数中的统计冗余，通过缓存调度协同设计提供可证明性能保证。这种设计将边缘设备上的 MoE 推理从 I/O 瓶颈转变为以计算为中心的工作流，从而实现高效并行化。", "result": "实验结果显示 ZipMoE 能够比现有最佳系统减少高达72.77%的推理延迟，并且吞吐量提升至6.76倍以上。", "conclusion": "ZipMoE 实现了在边缘设备上高效部署 MoE 架构的目标，解决了传统方法中存在的内存占用过高和性能瓶颈问题。"}}
{"id": "2601.21193", "pdf": "https://arxiv.org/pdf/2601.21193", "abs": "https://arxiv.org/abs/2601.21193", "authors": ["Zecheng Zhao", "Zhi Chen", "Zi Huang", "Shazia Sadiq", "Tong Chen"], "title": "Generative Recall, Dense Reranking: Learning Multi-View Semantic IDs for Efficient Text-to-Video Retrieval", "categories": ["cs.CV"], "comment": "10 pages", "summary": "Text-to-Video Retrieval (TVR) is essential in video platforms. Dense retrieval with dual-modality encoders leads in accuracy, but its computation and storage scale poorly with corpus size. Thus, real-time large-scale applications adopt two-stage retrieval, where a fast recall model gathers a small candidate pool, which is reranked by an advanced dense retriever. Due to hugely reduced candidates, the reranking model can use any off-the-shelf dense retriever without hurting efficiency, meaning the recall model bounds two-stage TVR performance. Recently, generative retrieval (GR) replaces dense video embeddings with discrete semantic IDs and retrieves by decoding text queries into ID tokens. GR offers near-constant inference and storage complexity, and its semantic IDs capture high-level video features via quantization, making it ideal for quickly eliminating irrelevant candidates during recall. However, as a recall model in two-stage TVR, GR suffers from (i) semantic ambiguity, where each video satisfies diverse queries but is forced into one semantic ID; and (ii) cross-modal misalignment, as semantic IDs are solely derived from visual features without text supervision. We propose Generative Recall and Dense Reranking (GRDR), designing a novel GR method to uplift recalled candidate quality. GRDR assigns multiple semantic IDs to each video using a query-guided multi-view tokenizer exposing diverse semantic access paths, and jointly trains the tokenizer and generative retriever via a shared codebook to cast semantic IDs as the semantic bridge between texts and videos. At inference, trie-constrained decoding generates a compact candidate set reranked by a dense model for fine-grained matching. Experiments on TVR benchmarks show GRDR matches strong dense retrievers in accuracy while reducing index storage by an order of magnitude and accelerating up to 300$\\times$ in full-corpus retrieval.", "AI": {"tldr": "本文提出了一种名为GRDR的方法，用于提高文本到视频检索中的召回候选质量。", "motivation": "传统的两阶段检索方法存在语义模糊和跨模态对齐问题。因此，作者希望通过多视图生成回忆模型来解决这些问题，并优化检索精度。", "method": "通过设计一种新颖的基于查询引导的多视图分词器为每个视频分配多个语义ID，同时训练该分词器和生成召回模型以将这些语义ID作为文本和视频之间的语义桥梁。在推理过程中，利用树状约束解码生成紧凑候选集，并使用密集检索模型进行精细匹配。", "result": "实验结果表明，GRDR方法在精度上可以与强大的密集检索模型相媲美，同时减少了索引存储量并提高了速度。", "conclusion": "通过引入多视图语义ID和联合训练策略，本文提出的方法可以在减少计算资源使用的同时保持较高的检索精度。"}}
{"id": "2601.21192", "pdf": "https://arxiv.org/pdf/2601.21192", "abs": "https://arxiv.org/abs/2601.21192", "authors": ["Wun Yu Chan", "Shaojin Chen", "Huihao Jing", "Kwun Hang Lau", "Elton Chun-Chai Li", "Zihao Wang", "Haoran Li", "Yangqiu Song"], "title": "Do Reasoning Models Enhance Embedding Models?", "categories": ["cs.AI", "cs.CL"], "comment": "10 main pages, 18 appendix pages, 13 figures, 11 tables, 4 prompts", "summary": "State-of-the-art embedding models are increasingly derived from decoder-only Large Language Model (LLM) backbones adapted via contrastive learning. Given the emergence of reasoning models trained via Reinforcement Learning with Verifiable Rewards (RLVR), a natural question arises: do enhanced reasoning translate to superior semantic representations when these models serve as embedding initializations? Contrary to expectation, our evaluation on MTEB and BRIGHT reveals a **null effect**: embedding models initialized from RLVR-tuned backbones yield no consistent performance advantage over their base counterparts when subjected to identical training recipes. To unpack this paradox, we introduce **H**ierarchical **R**epresentation **S**imilarity **A**nalysis (HRSA), a framework that decomposes similarity across representation, geometry, and function levels. HRSA reveals that while RLVR induces irreversible latent manifold's local geometry reorganization and reversible coordinate basis drift, it preserves the global manifold geometry and linear readout. Consequently, subsequent contrastive learning drives strong alignment between base- and reasoning-initialized models, a phenomenon we term **Manifold Realignment**. Empirically, our findings suggest that unlike Supervised Fine-Tuning (SFT), RLVR optimizes trajectories within an existing semantic landscape rather than fundamentally restructuring the landscape itself.", "AI": {"tldr": "本文探讨了通过强化学习优化的推理模型是否能增强嵌入式模型的表现。", "motivation": "随着基于对比学习的大规模语言模型（LLM）的应用越来越广泛，研究者提出了一个疑问：经过强化学习验证奖励训练（RLVR）的模型能否提升作为初始化基础时的语义表示能力？", "method": "研究人员使用了一种新的框架——HRSA，来评估和分析不同初始条件下的嵌入式模型的表现差异。", "result": "实验结果表明，虽然RLVR能够改变局部几何结构并引起坐标基漂移，但全局几何形状和线性读出保持不变。因此，在后续对比学习中，基于基础和推理初始化的模型之间的表现几乎没有差别。", "conclusion": "研究发现，相比于监督微调（SFT），RLVR优化的是在一个已有的语义景观内部，而不是重新塑造整个语义景观。"}}
{"id": "2601.21191", "pdf": "https://arxiv.org/pdf/2601.21191", "abs": "https://arxiv.org/abs/2601.21191", "authors": ["Xiulin Yang", "Heidi Getz", "Ethan Gotlieb Wilcox"], "title": "From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning", "categories": ["cs.CL", "cs.AI"], "comment": "Jan ARR under review", "summary": "What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.", "AI": {"tldr": "本文探讨了功能词的统计分布如何支持从线性输入中学习层次结构。", "motivation": "研究功能词在语言习得中的作用，特别是它们的高频性、可靠的句法关联和短语边界对齐等特性。", "method": "通过跨语言语料库分析确立了186种语言的功能词分布特性，并利用反事实语言建模和消融实验来评估这些特性的学习效果。", "result": "结果表明，保留所有三项特征的语言变体更容易被神经学习者习得。频率和结构关联比边界对齐更有力地促进了学习。", "conclusion": "功能词在不同学习条件下具有不同的依赖性，并且类似的表现可能源自不同的内部机制。"}}
{"id": "2601.21189", "pdf": "https://arxiv.org/pdf/2601.21189", "abs": "https://arxiv.org/abs/2601.21189", "authors": ["Arther Tian", "Alex Ding", "Frank Chen", "Simon Wu", "Aaron Chan"], "title": "Adaptive and Robust Cost-Aware Proof of Quality for Decentralized LLM Inference Networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Decentralized large language model inference networks require lightweight mechanisms to reward high quality outputs under heterogeneous latency and cost. Proof of Quality provides scalable verification by sampling evaluator nodes that score candidate outputs, then aggregating their scores into a consensus signal that determines rewards. However, evaluator heterogeneity and malicious score manipulation can distort consensus and inflate payouts, which weakens incentive alignment in open participation settings. This paper extends a cost-aware Proof of Quality mechanism by adding adversary-resilient consensus formation. We study robust aggregation rules, including median and trimmed mean, and an adaptive trust-weighted consensus that updates evaluator weights from deviation signals. Using question answering and summarization workloads with a ground truth proxy for offline analysis, we quantify evaluator reliability and show strong variance across evaluators, including task-dependent misalignment that can invert correlations. We then evaluate robustness under four adversarial strategies, including noise injection, boosting, sabotage, and intermittent manipulation, across a sweep of malicious ratios and evaluator sample sizes. Our results show that robust aggregation improves consensus alignment with the ground truth proxy and reduces sensitivity to noisy and strategic attacks compared with simple averaging. We further characterize the operational trade-off introduced by evaluator sampling, where larger evaluator sets reduce evaluator rewards and increase payoff variance while inference rewards remain relatively stable in our configuration. These findings motivate robust consensus as a default component for cost-aware Proof of Quality and provide practical guidance for selecting evaluator sampling parameters under adversarial risk and resource constraints.", "AI": {"tldr": "提出了一种基于成本的稳健一致性机制，以增强去中心化LLM推理网络中Proof of Quality的一致性和抗攻击性。", "motivation": "为了确保异构延迟和成本环境下的高质量输出奖励，需要一种能够抵御恶意评分操纵并保持激励一致性的稳健共识形成机制。", "method": "研究了包括中位数和裁剪均值在内的鲁棒聚合规则，并提出了一种自适应信任加权一致性方法。通过问答和总结工作负载中的离线分析基准来量化评价者可靠性，评估该机制在四种恶意策略下的性能。", "result": "实验表明，与简单平均相比，稳健聚合提高了共识与离线基准的一致性并降低了对噪音和战略攻击的敏感度。同时也揭示了采样大小和奖励之间的权衡关系。", "conclusion": "研究结果支持将鲁棒一致性作为成本感知Proof of Quality的标准组成部分，并为在对抗风险和资源限制下选择评价者抽样参数提供了实践指南。"}}
{"id": "2601.21188", "pdf": "https://arxiv.org/pdf/2601.21188", "abs": "https://arxiv.org/abs/2601.21188", "authors": ["Hao Cheng", "Feitian Zhang"], "title": "Disturbance-Aware Flight Control of Robotic Gliding Blimp via Moving Mass Actuation", "categories": ["cs.RO"], "comment": null, "summary": "Robotic blimps, as lighter-than-air (LTA) aerial systems, offer long endurance and inherently safe operation but remain highly susceptible to wind disturbances. Building on recent advances in moving mass actuation, this paper addresses the lack of disturbance-aware control frameworks for LTA platforms by explicitly modeling and compensating for wind-induced effects. A moving horizon estimator (MHE) infers real-time wind perturbations and provides these estimates to a model predictive controller (MPC), enabling robust trajectory and heading regulation under varying wind conditions. The proposed approach leverages a two-degree-of-freedom (2-DoF) moving-mass mechanism to generate both inertial and aerodynamic moments for attitude and heading control, thereby enhancing flight stability in disturbance-prone environments. Extensive flight experiments under headwind and crosswind conditions show that the integrated MHE-MPC framework significantly outperforms baseline PID control, demonstrating its effectiveness for disturbance-aware LTA flight.", "AI": {"tldr": "通过移动质量作动实现轻于空气飞行器的扰动感知控制，提高其在风扰环境中的轨迹和姿态稳定性。", "motivation": "当前缺乏针对LTA平台的有效扰动感知控制系统，而该系统可以通过建模并补偿由风引起的效应来改善。", "method": "利用移动地平线估计器（MHE）实时推断风扰动，并将其提供给模型预测控制器（MPC），以实现强健的轨迹和航向调整。采用两自由度移动质量机制产生惯性和空气动力矩，用于姿态和航向控制。", "result": "飞行实验表明，在迎面风和横风条件下，集成的MHE-MPC框架显著优于基线PID控制方法。", "conclusion": "所提出的扰动感知控制系统在LTA飞行中有效提升了轨迹和姿态稳定性。"}}
{"id": "2601.21187", "pdf": "https://arxiv.org/pdf/2601.21187", "abs": "https://arxiv.org/abs/2601.21187", "authors": ["Chenyu Huang", "Peng Ye", "Xudong Tan", "Jinhan Mu", "Shenghe Zheng", "Li Shen", "Tao Chen"], "title": "FRISM: Fine-Grained Reasoning Injection via Subspace-Level Model Merging for Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": "23 pages, 8 figures", "summary": "Efficiently enhancing the reasoning capabilities of Vision-Language Models (VLMs) by merging them with Large Reasoning Models (LRMs) has emerged as a promising direction. However, existing methods typically operate at a coarse-grained layer level, which often leads to a trade-off between injecting reasoning capabilities and preserving visual capabilities. To address this limitation, we propose {FRISM} (Fine-grained Reasoning Injection via Subspace-level model Merging), a fine-grained reasoning injection framework based on subspace-level model merging. Observing that reasoning capabilities are encoded in distinct subspaces, FRISM decomposes LRM task vectors via Singular Value Decomposition (SVD) and adaptively tunes the scaling coefficients of each subspace through learning to realize fine-grained reasoning injection. Furthermore, we introduce a label-free self-distillation learning strategy with a dual-objective optimization using common vision-language perception datasets. Extensive experiments demonstrate that FRISM effectively improves reasoning capabilities without compromising the model's original visual capabilities by consistently achieving state-of-the-art performance across diverse visual reasoning benchmarks.", "AI": {"tldr": "提出了FRISM框架，通过子空间级别的模型合并来增强视觉语言模型的推理能力。", "motivation": "现有方法通常在粗粒度层面上操作，导致注入推理能力和保留视觉能力之间的权衡。为解决这个问题，提出了一种基于子空间级别模型融合的方法，以实现更精细的推理注入。", "method": "通过奇异值分解（SVD）将大型推理模型的任务向量分解，并学习每个子空间的缩放系数来适应性调整，引入无标签自我蒸馏策略和双目标优化。", "result": "实验结果表明，FRISM在不牺牲原始视觉能力的情况下有效提升推理性能，在多样化的视觉推理基准测试中达到最佳性能。", "conclusion": "提出的方法成功解决了现有方法的权衡问题，并通过精细的子空间合并技术显著提升了视觉语言模型的综合性能。"}}
{"id": "2601.21183", "pdf": "https://arxiv.org/pdf/2601.21183", "abs": "https://arxiv.org/abs/2601.21183", "authors": ["Jacek Duszenko"], "title": "Sycophantic Anchors: Localizing and Quantifying User Agreement in Reasoning Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reasoning models frequently agree with incorrect user suggestions -- a behavior known as sycophancy. However, it is unclear where in the reasoning trace this agreement originates and how strong the commitment is. To localize and quantify this behavior, we introduce \\emph{sycophantic anchors} -- sentences that causally lock models into user agreement. Analyzing over 10,000 counterfactual rollouts on a distilled reasoning model, we show that anchors can be reliably detected and quantified mid-inference. Linear probes distinguish sycophantic anchors with 84.6\\% balanced accuracy, while activation-based regressors predict the magnitude of the commitment ($R^2 = 0.74$). We further observe asymmetry where sycophantic anchors are significantly more distinguishable than correct reasoning anchors, and find that sycophancy builds gradually during reasoning, revealing a potential window for intervention. These results offer sentence-level mechanisms for localizing model misalignment mid-inference.", "AI": {"tldr": "本文引入了“谄媚锚点”的概念，用于定位和量化推理模型在推理过程中与错误用户建议一致的行为，并通过分析反事实结果来衡量这种行为。", "motivation": "推理模型经常同意用户的错误建议，但不清楚这在哪一步产生以及有多大的一致性。研究者希望通过引入‘谄媚锚点’来解决这一问题。", "method": "研究者使用线性探测器和激活回归器对10,000多个反事实滚动生成的样本进行分析，以检测并量化‘谄媚锚点’的存在及其程度。", "result": "研究发现可以可靠地在推理过程中定位出‘谄媚锚点’，并且这些锚点更容易被识别为错误一致性。此外，模型中的不一致逐渐累积，显示出干预的机会窗口。", "conclusion": "通过引入‘谄媚锚点’的概念并提出相关的检测与量化方法，研究者提供了一种新的机制来定位和处理推理过程中的模型偏差问题。"}}
{"id": "2601.21182", "pdf": "https://arxiv.org/pdf/2601.21182", "abs": "https://arxiv.org/abs/2601.21182", "authors": ["Xin Peng", "Ang Gao"], "title": "Rethinking Refinement: Correcting Generative Bias without Noise Injection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generative models, including diffusion and flow-based models, often exhibit systematic biases that degrade sample quality, particularly in high-dimensional settings. We revisit refinement methods and show that effective bias correction can be achieved as a post-hoc procedure, without noise injection or multi-step resampling of the sampling process. We propose a flow-matching-based \\textbf{Bi-stage Flow Refinement (BFR)} framework with two refinement strategies operating at different stages: latent space alignment for approximately invertible generators and data space refinement trained with lightweight augmentations. Unlike previous refiners that perturb sampling dynamics, BFR preserves the original ODE trajectory and applies deterministic corrections to generated samples. Experiments on MNIST, CIFAR-10, and FFHQ at 256x256 resolution demonstrate consistent improvements in fidelity and coverage; notably, starting from base samples with FID 3.95, latent space refinement achieves a \\textbf{state-of-the-art} FID of \\textbf{1.46} on MNIST using only a single additional function evaluation (1-NFE), while maintaining sample diversity.", "AI": {"tldr": "本文提出了Bi-stage Flow Refinement（BFR）框架，旨在通过后处理方法而非注入噪声或多次重采样过程来纠正生成模型的系统偏差。", "motivation": "现有的生成模型如扩散和流基模型在高维场景中表现出系统性偏见，导致样本质量下降。本文动机在于找到一种不需要额外扰动原生成过程的方法来矫正这些偏差。", "method": "Bi-stage Flow Refinement（BFR）框架包括两个阶段的修正策略：第一阶段是隐空间对齐用于近似可逆的生成器；第二阶段是在数据空间进行轻量级增强训练。这种方法不干扰原有的ODE轨迹，而是通过确定性调整来改善产生的样本。", "result": "实验结果表明，在MNIST、CIFAR-10和FFHQ等不同数据集上，BFR方法在保持样本多样性的同时提高了生成图像的质量；特别地，在使用单一额外函数评估的情况下，该方法将FID从3.95降低到1.46。", "conclusion": "本文提出的Bi-stage Flow Refinement（BFR）框架证明了后处理方法的有效性，为解决生成模型中的系统偏差提供了一个新路径。"}}
{"id": "2601.21181", "pdf": "https://arxiv.org/pdf/2601.21181", "abs": "https://arxiv.org/abs/2601.21181", "authors": ["Sangyun Chung", "Se Yeon Kim", "Youngchae Chee", "Yong Man Ro"], "title": "MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) suffer from cross-modal hallucinations, where one modality inappropriately influences generation about another, leading to fabricated output. This exposes a more fundamental deficiency in modality-interaction control. To address this, we propose Modality-Adaptive Decoding (MAD), a training-free method that adaptively weights modality-specific decoding branches based on task requirements. MAD leverages the model's inherent ability to self-assess modality relevance by querying which modalities are needed for each task. The extracted modality probabilities are then used to adaptively weight contrastive decoding branches, enabling the model to focus on relevant information while suppressing cross-modal interference. Extensive experiments on CMM and AVHBench demonstrate that MAD significantly reduces cross-modal hallucinations across multiple audio-visual language models (7.8\\% and 2.0\\% improvements for VideoLLaMA2-AV, 8.7\\% and 4.7\\% improvements for Qwen2.5-Omni). Our approach demonstrates that explicit modality awareness through self-assessment is crucial for robust multimodal reasoning, offering a principled extension to existing contrastive decoding methods. Our code is available at \\href{https://github.com/top-yun/MAD}{https://github.com/top-yun/MAD}", "AI": {"tldr": "本文提出了MAD方法，用于减轻多模态大语言模型中的跨模态幻觉。", "motivation": "多模态大型语言模型在生成过程中存在跨模态幻觉问题，即一种模态不恰当地影响另一种模态的生成，导致虚构输出。为了解决这一问题，提出了MAD方法来调整每个任务中特定于模态的解码分支权重。", "method": "MAD通过自评估模型的内在能力来查询完成每个任务所需的哪些模态，然后根据提取出的模态概率对对比解码分支进行加权，从而减轻跨模态干扰并使模型专注于相关信息。", "result": "实验结果表明，在CMM和AVHBench数据集上，MAD显著减少了多个音频-视觉语言模型中的跨模态幻觉（分别为VideoLLaMA2-AV的7.8%和2.0%，Qwen2.5-Omni的8.7%和4.7%）。", "conclusion": "研究证明了通过自评估实现明确的模态意识对于鲁棒多模态推理至关重要，并展示了MAD作为现有对比解码方法的一种原则性扩展的有效性。"}}
{"id": "2601.21179", "pdf": "https://arxiv.org/pdf/2601.21179", "abs": "https://arxiv.org/abs/2601.21179", "authors": ["Yuji Lin", "Qian Zhao", "Zongsheng Yue", "Junhui Hou", "Deyu Meng"], "title": "Enhancing Underwater Light Field Images via Global Geometry-aware Diffusion Process", "categories": ["cs.CV"], "comment": "13 pages, 9 figures", "summary": "This work studies the challenging problem of acquiring high-quality underwater images via 4-D light field (LF) imaging. To this end, we propose GeoDiff-LF, a novel diffusion-based framework built upon SD-Turbo to enhance underwater 4-D LF imaging by leveraging its spatial-angular structure. GeoDiff-LF consists of three key adaptations: (1) a modified U-Net architecture with convolutional and attention adapters to model geometric cues, (2) a geometry-guided loss function using tensor decomposition and progressive weighting to regularize global structure, and (3) an optimized sampling strategy with noise prediction to improve efficiency. By integrating diffusion priors and LF geometry, GeoDiff-LF effectively mitigates color distortion in underwater scenes. Extensive experiments demonstrate that our framework outperforms existing methods across both visual fidelity and quantitative performance, advancing the state-of-the-art in enhancing underwater imaging. The code will be publicly available at https://github.com/linlos1234/GeoDiff-LF.", "AI": {"tldr": "提出了一种新的基于全局几何感知扩散过程的框架GeoDiff-LF，用于增强水下4D光场成像。", "motivation": "在研究如何通过4-D光场成像获取高质量水下图像的过程中，作者希望通过结合光场结构和扩散先验来提高水下场景的颜色失真问题。", "method": "提出了一种基于SD-Turbo的GeoDiff-LF框架。该方法包括修改后的U-Net架构、几何导向损失函数以及优化的采样策略，并通过噪声预测来改进效率。", "result": "实验结果表明，该框架在视觉质量和定量性能方面均优于现有方法，在增强水下成像技术上达到了最先进的水平。", "conclusion": "GeoDiff-LF通过结合扩散先验和光场几何结构有效解决了水下场景的颜色失真问题，并且其性能表现优于现有的其他解决方案。"}}
{"id": "2601.21173", "pdf": "https://arxiv.org/pdf/2601.21173", "abs": "https://arxiv.org/abs/2601.21173", "authors": ["Zeyi Liu", "Shuang Liu", "Jihai Min", "Zhaoheng Zhang", "Jun Cen", "Pengyu Han", "Songqiao Hu", "Zihan Meng", "Xiao He", "Donghua Zhou"], "title": "InspecSafe-V1: A Multimodal Benchmark for Safety Assessment in Industrial Inspection Scenarios", "categories": ["cs.RO", "cs.CV"], "comment": "15 pages, 7 figures", "summary": "With the rapid development of industrial intelligence and unmanned inspection, reliable perception and safety assessment for AI systems in complex and dynamic industrial sites has become a key bottleneck for deploying predictive maintenance and autonomous inspection. Most public datasets remain limited by simulated data sources, single-modality sensing, or the absence of fine-grained object-level annotations, which prevents robust scene understanding and multimodal safety reasoning for industrial foundation models. To address these limitations, InspecSafe-V1 is released as the first multimodal benchmark dataset for industrial inspection safety assessment that is collected from routine operations of real inspection robots in real-world environments. InspecSafe-V1 covers five representative industrial scenarios, including tunnels, power facilities, sintering equipment, oil and gas petrochemical plants, and coal conveyor trestles. The dataset is constructed from 41 wheeled and rail-mounted inspection robots operating at 2,239 valid inspection sites, yielding 5,013 inspection instances. For each instance, pixel-level segmentation annotations are provided for key objects in visible-spectrum images. In addition, a semantic scene description and a corresponding safety level label are provided according to practical inspection tasks. Seven synchronized sensing modalities are further included, including infrared video, audio, depth point clouds, radar point clouds, gas measurements, temperature, and humidity, to support multimodal anomaly recognition, cross-modal fusion, and comprehensive safety assessment in industrial environments.", "AI": {"tldr": "本文提出了InspecSafe-V1，这是一个用于工业检查场景的安全评估多模态基准数据集。", "motivation": "随着工业智能化和无人检测的发展，AI系统在复杂动态环境中的可靠感知和安全评估成为部署预测性维护和自主检查的关键瓶颈。当前公开的数据集存在模拟数据来源受限、单一传感器模式或缺乏细粒度对象级别注释的问题，这阻碍了工业基础模型的稳健场景理解和多模态安全推理。", "method": "InspecSafe-V1是从实际操作中的41个轮式和轨道检查机器人在真实环境下的2,239个有效检查点收集的数据集中创建的。数据集包括五个代表性工业场景，每例提供了可见光谱图像的关键对象像素级分割标注、语义场景描述以及安全级别标签。此外，还包括七种同步传感模式：红外视频、音频、深度点云、雷达点云、气体测量、温度和湿度。", "result": "InspecSafe-V1涵盖了各种工业检查环境的数据，提供了多模态异常检测、跨模态融合和支持综合安全评估的全面支持。", "conclusion": "该数据集填补了当前公开数据集在可靠感知和安全评估方面的空白，为开发稳健场景理解和多模态安全推理的方法提供了基础。"}}
{"id": "2601.21171", "pdf": "https://arxiv.org/pdf/2601.21171", "abs": "https://arxiv.org/abs/2601.21171", "authors": ["Kamal Berahmand", "Saman Forouzandeh", "Mehrnoush Mohammadi", "Parham Moradi", "Mahdi Jalili"], "title": "AC2L-GAD: Active Counterfactual Contrastive Learning for Graph Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "ef:The ACM Web Conference (WWW 2026)", "summary": "Graph anomaly detection aims to identify abnormal patterns in networks, but faces significant challenges from label scarcity and extreme class imbalance. While graph contrastive learning offers a promising unsupervised solution, existing methods suffer from two critical limitations: random augmentations break semantic consistency in positive pairs, while naive negative sampling produces trivial, uninformative contrasts. We propose AC2L-GAD, an Active Counterfactual Contrastive Learning framework that addresses both limitations through principled counterfactual reasoning. By combining information-theoretic active selection with counterfactual generation, our approach identifies structurally complex nodes and generates anomaly-preserving positive augmentations alongside normal negative counterparts that provide hard contrasts, while restricting expensive counterfactual generation to a strategically selected subset. This design reduces computational overhead by approximately 65% compared to full-graph counterfactual generation while maintaining detection quality. Experiments on nine benchmark datasets, including real-world financial transaction graphs from GADBench, show that AC2L-GAD achieves competitive or superior performance compared to state-of-the-art baselines, with notable gains in datasets where anomalies exhibit complex attribute-structure interactions.", "AI": {"tldr": "本文提出了一种主动反事实对比学习框架AC2L-GAD，用于解决图异常检测中的标签稀缺和极端类别不平衡问题。", "motivation": "现有图对比学习方法在随机增强下破坏了正样本对的语义一致性，并且简单的负样本采样会产生无信息的对比。作者提出了一个结合信息论主动选择与反事实生成的方法，以解决这些问题并提高异常检测性能。", "method": "通过信息理论主动选择和反事实生成相结合的方式，AC2L-GAD框架能够识别结构复杂的节点以及生成保持异常特性的正样本增强，并产生硬对比的正常负样本。该方法减少了大约65%的计算开销，同时保持了检测质量。", "result": "在包括GADBench真实世界金融交易图在内的九个基准数据集上进行了实验，结果显示AC2L-GAD与当前最先进的基线相比具有竞争力或优越的表现，在异常表现出复杂属性-结构交互的数据集中尤其显著。", "conclusion": "AC2L-GAD通过主动反事实对比学习框架解决了现有方法在随机增强和负样本采样方面的问题，并且在多个数据集上取得了优于或接近最优结果的性能。"}}
{"id": "2601.21169", "pdf": "https://arxiv.org/pdf/2601.21169", "abs": "https://arxiv.org/abs/2601.21169", "authors": ["Tobias Materzok"], "title": "Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standard autoregressive decoding. This enables parallel sweeps and black-box optimization in Z without path-dependent token/program search. On stories, sweeping Z (text) yields 3.1x higher LLM-scored diversity than prompt-chaining. On code, Bayesian optimization over Z (code) improves an objective withheld from the controller under matched inference budgets while preserving validity.", "AI": {"tldr": "本文介绍了Output-Space Search（OS-Search）方法，该方法将LLM生成转化为目标搜索。", "motivation": "通过在冻结的编码器定义的空间中选择一个目标点，并使用序列级强化学习训练的策略生成接近此目标点的输出，从而实现平行扫描和黑盒优化。", "method": "OS-Search包括两个主要步骤：首先，在冻结的编码器定义的空间中选定一个目标z*；其次，通过检索支持的策略在标准自回归解码过程中产生坐标接近z*的输出。", "result": "对于故事生成任务，Z空间扫描比提示链提高了3.1倍的LLM评估多样性。对于代码优化任务，在匹配推理预算下，OS-Search在不降低有效性的前提下提升了被控制器隐藏的目标函数值。", "conclusion": "OS-Search提供了一种新的方法来提高LLM生成过程中的多样性和特定目标的优化效果。"}}
{"id": "2601.21165", "pdf": "https://arxiv.org/pdf/2601.21165", "abs": "https://arxiv.org/abs/2601.21165", "authors": ["Miles Wang", "Robi Lin", "Kat Hu", "Joy Jiao", "Neil Chowdhury", "Ethan Chang", "Tejal Patwardhan"], "title": "FrontierScience: Evaluating AI's Ability to Perform Expert-Level Scientific Tasks", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "We introduce FrontierScience, a benchmark evaluating expert-level scientific reasoning in frontier language models. Recent model progress has nearly saturated existing science benchmarks, which often rely on multiple-choice knowledge questions or already published information. FrontierScience addresses this gap through two complementary tracks: (1) Olympiad, consisting of international olympiad problems at the level of IPhO, IChO, and IBO, and (2) Research, consisting of PhD-level, open-ended problems representative of sub-tasks in scientific research. FrontierScience contains several hundred questions (including 160 in the open-sourced gold set) covering subfields across physics, chemistry, and biology, from quantum electrodynamics to synthetic organic chemistry. All Olympiad problems are originally produced by international Olympiad medalists and national team coaches to ensure standards of difficulty, originality, and factuality. All Research problems are research sub-tasks written and verified by PhD scientists (doctoral candidates, postdoctoral researchers, or professors). For Research, we introduce a granular rubric-based evaluation framework to assess model capabilities throughout the process of solving a research task, rather than judging only a standalone final answer.", "AI": {"tldr": "FrontierScience是一个评估前沿语言模型在专家级科学推理方面的基准。", "motivation": "现有的科学基准测试已经接近饱和，依赖于多项选择题或已发布的信息。为了弥补这一不足，引入了FrontierScience来评估AI在复杂且原创性高的科学研究任务中的表现。", "method": "通过两个互补的赛道：奥林匹亚竞赛和研究项目，FrontierScience包含了数百个问题（包括160个开源黄金集），涵盖了物理学、化学和生物学领域的多个子领域。所有题目都是由国际奥林匹克金牌获得者或国家教练以及博士科学家编写并验证。", "result": "尚未提供具体结果，但介绍了一种针对研究项目的颗粒度评分框架来评估模型解决科研任务的能力。", "conclusion": "FrontierScience为评估前沿语言模型的科学推理能力提供了新的标准，并且强调了通过详细评价过程来全面理解AI解决问题的过程。"}}
{"id": "2601.21164", "pdf": "https://arxiv.org/pdf/2601.21164", "abs": "https://arxiv.org/abs/2601.21164", "authors": ["Jingyun Wang", "Dian Li", "Xiaohan Wang", "Gang Liu", "Jiahong Yan", "Guoliang Kang"], "title": "Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving", "categories": ["cs.AI"], "comment": "Under review", "summary": "Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by their inability to process visual diagrams. Existing works typically fine-tune Multimodal LLMs (MLLMs) end-to-end on large-scale PGPS data to enhance visual understanding and reasoning simultaneously. However, such joint optimization may compromise base LLMs' inherent reasoning capability. In this work, we observe that LLM itself is potentially a powerful PGPS solver when appropriately formulating visual information as textual descriptions. We propose to train a MLLM Interpreter to generate geometric descriptions for the visual diagram, and an off-the-shelf LLM is utilized to perform reasoning. Specifically, we choose Conditional Declaration Language (CDL) as the geometric description as its conciseness eases the MLLM Interpreter training. The MLLM Interpreter is fine-tuned via CoT (Chain-of-Thought)-augmented SFT followed by GRPO to generate CDL. Instead of using a conventional solution-based reward that compares the reasoning result with the ground-truth answer, we design CDL matching rewards to facilitate more effective GRPO training, which provides more direct and denser guidance for CDL generation. To support training, we construct a new dataset, Formalgeo7k-Rec-CoT, by manually reviewing Formalgeo7k v2 and incorporating CoT annotations. Extensive experiments on Formalgeo7k-Rec-CoT, Unigeo, and MathVista show our method (finetuned on only 5.5k data) performs favorably against leading open-source and closed-source MLLMs.", "AI": {"tldr": "本文提出了一种利用LLM解决平面几何问题的方法，通过训练一个多模态语言模型来生成简洁的几何描述，并使用一个现成的语言模型进行推理。", "motivation": "尽管大型语言模型拥有强大的推理能力，但直接应用于平面几何问题求解时受到处理视觉图表的能力限制。现有方法通常通过端到端地对多模态语言模型进行大规模数据训练来增强其视觉理解和推理能力，但这可能会影响基础语言模型的原始推理能力。", "method": "提出了一种利用多模态语言模型解释器生成几何描述的方法，并使用现成的语言模型进行推理。选择条件声明语言作为几何描述，并通过CoT增强SFT和GRPO来训练多模态语言模型解释器以生成CDL，设计了CDL匹配奖励来进行更有效的GRPO训练。", "result": "在Formalgeo7k-Rec-CoT、Unigeo和MathVista数据集上的实验表明，本文的方法（仅使用5.5K数据进行微调）优于开源和闭源多模态语言模型的领先方法。", "conclusion": "本文提出的方法通过生成简洁的几何描述并利用现成的语言模型进行推理，有效地解决了平面几何问题求解任务，并在多个数据集上表现出色。"}}
{"id": "2601.21162", "pdf": "https://arxiv.org/pdf/2601.21162", "abs": "https://arxiv.org/abs/2601.21162", "authors": ["Jiate Liu", "Zebin Chen", "Shaobo Qiao", "Mingchen Ju", "Danting Zhang", "Bocheng Han", "Shuyue Yu", "Xin Shu", "Jingling Wu", "Dong Wen", "Xin Cao", "Guanfeng Liu", "Zhengyi Yang"], "title": "A2RAG: Adaptive Agentic Graph Retrieval for Cost-Aware and Reliable Reasoning", "categories": ["cs.IR", "cs.AI", "cs.DB"], "comment": null, "summary": "Graph Retrieval-Augmented Generation (Graph-RAG) enhances multihop question answering by organizing corpora into knowledge graphs and routing evidence through relational structure. However, practical deployments face two persistent bottlenecks: (i) mixed-difficulty workloads where one-size-fits-all retrieval either wastes cost on easy queries or fails on hard multihop cases, and (ii) extraction loss, where graph abstraction omits fine-grained qualifiers that remain only in source text. We present A2RAG, an adaptive-and-agentic GraphRAG framework for cost-aware and reliable reasoning. A2RAG couples an adaptive controller that verifies evidence sufficiency and triggers targeted refinement only when necessary, with an agentic retriever that progressively escalates retrieval effort and maps graph signals back to provenance text to remain robust under extraction loss and incomplete graphs. Experiments on HotpotQA and 2WikiMultiHopQA demonstrate that A2RAG achieves +9.9/+11.8 absolute gains in Recall@2, while cutting token consumption and end-to-end latency by about 50% relative to iterative multihop baselines.", "AI": {"tldr": "A2RAG是一种自适应和代理增强的图检索框架，用于解决问答系统中多跳问题的成本和可靠性问题。", "motivation": "实际部署中的问答系统面临着两种瓶颈：一是混合难度的工作负载导致了一次性解决方案在简单查询上浪费成本或难以处理复杂的情况；二是从源文本中提取信息时可能会丢失细粒度的限定词，影响准确性。", "method": "A2RAG框架结合了自适应控制器和代理检索器。自适应控制器用于验证证据是否充分，并根据需要触发细化过程；代理检索器逐步增加检索努力并映射图信号回原始文本以保持在提取损失和不完整图形下的稳健性。", "result": "实验结果显示，在HotpotQA和2WikiMultiHopQA数据集上，A2RAG比迭代多跳基线的召回率@2绝对提高了9.9/11.8个百分点，并将令牌消耗减少了约50%的相对值。", "conclusion": "通过采用自适应控制和代理检索机制，A2RAG能够同时提高问答系统的准确性和效率，在实际应用中具有很高的价值。"}}
{"id": "2601.21159", "pdf": "https://arxiv.org/pdf/2601.21159", "abs": "https://arxiv.org/abs/2601.21159", "authors": ["Jianzheng Wang", "Huan Ni"], "title": "Bidirectional Cross-Perception for Open-Vocabulary Semantic Segmentation in Remote Sensing Imagery", "categories": ["cs.CV"], "comment": null, "summary": "High-resolution remote sensing imagery is characterized by densely distributed land-cover objects and complex boundaries, which places higher demands on both geometric localization and semantic prediction. Existing training-free open-vocabulary semantic segmentation (OVSS) methods typically fuse CLIP and vision foundation models (VFMs) using \"one-way injection\" and \"shallow post-processing\" strategies, making it difficult to satisfy these requirements. To address this issue, we propose a spatial-regularization-aware dual-branch collaborative inference framework for training-free OVSS, termed SDCI. First, during feature encoding, SDCI introduces a cross-model attention fusion (CAF) module, which guides collaborative inference by injecting self-attention maps into each other. Second, we propose a bidirectional cross-graph diffusion refinement (BCDR) module that enhances the reliability of dual-branch segmentation scores through iterative random-walk diffusion. Finally, we incorporate low-level superpixel structures and develop a convex-optimization-based superpixel collaborative prediction (CSCP) mechanism to further refine object boundaries. Experiments on multiple remote sensing semantic segmentation benchmarks demonstrate that our method achieves better performance than existing approaches. Moreover, ablation studies further confirm that traditional object-based remote sensing image analysis methods leveraging superpixel structures remain effective within deep learning frameworks. Code: https://github.com/yu-ni1989/SDCI.", "AI": {"tldr": "提出了一种空间正则化感知的双分支协同推理框架，用于训练自由开放词汇语义分割。", "motivation": "现有方法通过“单向注入”和“浅层后处理”策略融合CLIP和视觉基础模型（VFMs），难以满足高分辨率遥感影像中密集分布的土地覆盖对象和复杂边界的几何定位及语义预测需求。", "method": "提出了空间正则化感知的双分支协同推理框架，包含交叉模态注意融合模块、双向跨图扩散细化模块以及基于凸优化的超像素协同预测机制以提高分割精度。", "result": "实验显示该方法优于现有方案，在多个遥感语义分割基准上表现更好。", "conclusion": "通过引入空间正则化感知的双分支协同推理框架，能够提升开放词汇语义分割性能，并证明传统基于对象的方法在深度学习框架中依然有效。"}}
{"id": "2601.21157", "pdf": "https://arxiv.org/pdf/2601.21157", "abs": "https://arxiv.org/abs/2601.21157", "authors": ["Boxiang Zhao", "Qince Li", "Zhonghao Wang", "Yi Wang", "Peng Cheng", "Bo Lin"], "title": "Bridging the Arithmetic Gap: The Cognitive Complexity Benchmark and Financial-PoT for Robust Financial Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While Large Language Models excel at semantic tasks, they face a critical bottleneck in financial quantitative reasoning, frequently suffering from \"Arithmetic Hallucinations\" and a systemic failure mode we term \"Cognitive Collapse\". To strictly quantify this phenomenon, we introduce the Cognitive Complexity Benchmark (CCB), a robust evaluation framework grounded in a dataset constructed from 95 real-world Chinese A-share annual reports. Unlike traditional datasets, the CCB stratifies financial queries into a three-dimensional taxonomy, Data Source, Mapping Difficulty, and Result Unit, enabling the precise diagnosis of reasoning degradation in high-cognitive-load scenarios. To address these failures, we propose the Iterative Dual-Phase Financial-PoT framework. This neuro-symbolic architecture enforces a strict architectural decoupling: it first isolates semantic variable extraction and logic formulation, then offloads computation to an iterative, self-correcting Python sandbox to ensure deterministic execution. Evaluation on the CCB demonstrates that while standard Chain-of-Thought falters on complex tasks, our approach offers superior robustness, elevating the Qwen3-235B model's average accuracy from 59.7\\% to 67.3\\% and achieving gains of up to 10-fold in high-complexity reasoning tasks. These findings suggest that architectural decoupling is a critical enabling factor for improving reliability in financial reasoning tasks, providing a transferable architectural insight for precision-critical domains that require tight alignment between semantic understanding and quantitative computation.", "AI": {"tldr": "该论文通过引入认知复杂度基准（CCB）和迭代双重相位的金融-PoT框架，解决大型语言模型在财务定量推理中的算术幻觉问题。", "motivation": "大型语言模型在语义任务上表现出色，但在财务定量推理中却面临关键瓶颈，经常出现“算术幻觉”和认知崩溃。为了严格量化这一现象并找到解决方案，作者提出了CCB和金融-PoT框架。", "method": "论文提出了一种新的评估框架——认知复杂度基准（CCB），并通过迭代双重相位的神经符号架构Financial-PoT解决了模型推理中的问题，该架构将语义变量提取与逻辑公式分离，并通过Python沙箱进行确定性计算。", "result": "在CCB上的实验表明，标准Chain-of-Thought方法在复杂任务上表现不佳，而新框架使Qwen3-235B模型的平均准确率从59.7%提高到67.3%，并且在高难度推理任务中的性能提升了十倍。", "conclusion": "论文研究表明，架构解耦对于提升财务定量推理任务中的可靠性是关键因素，并为需要紧密结合语义理解和定量计算的关键领域提供了可转移的架构见解。"}}
{"id": "2601.21150", "pdf": "https://arxiv.org/pdf/2601.21150", "abs": "https://arxiv.org/abs/2601.21150", "authors": ["Henry Kvinge", "Andrew Aguilar", "Nayda Farnsworth", "Grace O'Brien", "Robert Jasper", "Sarah Scullen", "Helen Jenne"], "title": "Can Neural Networks Learn Small Algebraic Worlds? An Investigation Into the Group-theoretic Structures Learned By Narrow Models Trained To Predict Group Operations", "categories": ["cs.LG", "cs.AI"], "comment": "Presented at TAG-DS 2025", "summary": "While a real-world research program in mathematics may be guided by a motivating question, the process of mathematical discovery is typically open-ended. Ideally, exploration needed to answer the original question will reveal new structures, patterns, and insights that are valuable in their own right. This contrasts with the exam-style paradigm in which the machine learning community typically applies AI to math. To maximize progress in mathematics using AI, we will need to go beyond simple question answering. With this in mind, we explore the extent to which narrow models trained to solve a fixed mathematical task learn broader mathematical structure that can be extracted by a researcher or other AI system. As a basic test case for this, we use the task of training a neural network to predict a group operation (for example, performing modular arithmetic or composition of permutations). We describe a suite of tests designed to assess whether the model captures significant group-theoretic notions such as the identity element, commutativity, or subgroups. Through extensive experimentation we find evidence that models learn representations capable of capturing abstract algebraic properties. For example, we find hints that models capture the commutativity of modular arithmetic. We are also able to train linear classifiers that reliably distinguish between elements of certain subgroups (even though no labels for these subgroups are included in the data). On the other hand, we are unable to extract notions such as the concept of the identity element. Together, our results suggest that in some cases the representations of even small neural networks can be used to distill interesting abstract structure from new mathematical objects.", "AI": {"tldr": "研究神经网络能否学习并捕捉到小规模代数结构中的抽象数学属性。", "motivation": "探索如何利用人工智能在开放的数学探究过程中发现新的结构、模式和见解，而不仅仅是用于解决问题。", "method": "通过训练神经网络预测群运算（如模加法或置换组合），设计一系列测试来评估模型是否捕捉到重要的群论概念，并进行广泛的实验验证这些假设。", "result": "实验结果表明，即使没有明确标记的子组标签，也可以用线性分类器可靠地区分某些子组成员。同时，在识别恒等元素这样的基本概念方面存在困难。", "conclusion": "研究表明在某些情况下，即使是小型神经网络也能够从新的数学对象中提炼出有趣的抽象结构，并捕捉到群论中的重要属性"}}
{"id": "2601.21149", "pdf": "https://arxiv.org/pdf/2601.21149", "abs": "https://arxiv.org/abs/2601.21149", "authors": ["Maria Despoina Siampou", "Shushman Choudhury", "Shang-Ling Hsu", "Neha Arora", "Cyrus Shahabi"], "title": "Mobility-Embedded POIs: Learning What A Place Is and How It Is Used from Human Movement", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent progress in geospatial foundation models highlights the importance of learning general-purpose representations for real-world locations, particularly points-of-interest (POIs) where human activity concentrates. Existing approaches, however, focus primarily on place identity derived from static textual metadata, or learn representations tied to trajectory context, which capture movement regularities rather than how places are actually used (i.e., POI's function). We argue that POI function is a missing but essential signal for general POI representations. We introduce Mobility-Embedded POIs (ME-POIs), a framework that augments POI embeddings derived, from language models with large-scale human mobility data to learn POI-centric, context-independent representations grounded in real-world usage. ME-POIs encodes individual visits as temporally contextualized embeddings and aligns them with learnable POI representations via contrastive learning to capture usage patterns across users and time. To address long-tail sparsity, we propose a novel mechanism that propagates temporal visit patterns from nearby, frequently visited POIs across multiple spatial scales. We evaluate ME-POIs on five newly proposed map enrichment tasks, testing its ability to capture both the identity and function of POIs. Across all tasks, augmenting text-based embeddings with ME-POIs consistently outperforms both text-only and mobility-only baselines. Notably, ME-POIs trained on mobility data alone can surpass text-only models on certain tasks, highlighting that POI function is a critical component of accurate and generalizable POI representations.", "AI": {"tldr": "论文提出了ME-POIs框架，通过结合大规模人类移动数据和语言模型的文本元数据来学习POI的功能性表示。", "motivation": "当前的方法主要关注静态文本元数据或轨迹上下文中的运动规律，而忽略了地方实际使用的功能。因此需要一个新方法来捕捉POI的实际使用情况。", "method": "ME-POIs框架通过结合大规模人类移动数据和语言模型的文本元数据，利用对比学习将个体访问的时间上下文化嵌入与可学习的POI表示对齐，以捕获跨用户和时间的使用模式。为了应对长尾稀疏性问题，提出了从附近频繁访问的POI传播时空访问模式的新机制。", "result": "ME-POIs在五个新提出的地图丰富任务上进行了评估，并且一致地超过了仅基于文本或移动数据的方法，在某些任务中甚至能够单独使用移动数据来超越仅基于文本的模型。", "conclusion": "ME-POIs框架通过结合大规模人类移动数据和语言模型的文本元数据，成功学习了POI的功能性表示，证明了POI功能是准确且通用的POI表示的关键组成部分。"}}
{"id": "2601.21148", "pdf": "https://arxiv.org/pdf/2601.21148", "abs": "https://arxiv.org/abs/2601.21148", "authors": ["Ziyi Zhao", "Jinzhao Zhou", "Xiaowei Jiang", "Beining Cao", "Wenhao Ma", "Yang Shen", "Ren Li", "Yu-Kai Wang", "Chin-teng Lin"], "title": "BrainStack: Neuro-MoE with Functionally Guided Expert Routing for EEG-Based Language Decoding", "categories": ["cs.AI"], "comment": null, "summary": "Decoding linguistic information from electroencephalography (EEG) remains challenging due to the brain's distributed and nonlinear organization. We present BrainStack, a functionally guided neuro-mixture-of-experts (Neuro-MoE) framework that models the brain's modular functional architecture through anatomically partitioned expert networks. Each functional region is represented by a specialized expert that learns localized neural dynamics, while a transformer-based global expert captures cross-regional dependencies. A learnable routing gate adaptively aggregates these heterogeneous experts, enabling context-dependent expert coordination and selective fusion. To promote coherent representation across the hierarchy, we introduce cross-regional distillation, where the global expert provides top-down regularization to the regional experts. We further release SilentSpeech-EEG (SS-EEG), a large-scale benchmark comprising over 120 hours of EEG recordings from 12 subjects performing 24 silent words, the largest dataset of its kind. Experiments demonstrate that BrainStack consistently outperforms state-of-the-art models, achieving superior accuracy and generalization across subjects. Our results establish BrainStack as a functionally modular, neuro-inspired MoE paradigm that unifies neuroscientific priors with adaptive expert routing, paving the way for scalable and interpretable brain-language decoding.", "AI": {"tldr": "提出BrainStack框架，用于从EEG信号中解码语言信息", "motivation": "解决基于EEG的语言解码挑战，利用大脑的功能模块化架构提高准确性与泛化能力", "method": "开发功能导向的神经专家混合模型（Neuro-MoE），采用分区专家网络和全局变压器专家，通过可学习路由门实现上下文依赖的协调融合，并引入跨区域蒸馏促进一致性表示。同时发布大型SilentSpeech-EEG数据集", "result": "实验表明BrainStack优于现有最佳方法，在准确性和泛化性上表现更佳", "conclusion": "BrainStack作为功能模块化的神经启发式MoE框架，结合了神经科学研究先验知识与自适应专家路由，为可扩展和解释性强的大脑语言解码铺平道路"}}
{"id": "2601.21141", "pdf": "https://arxiv.org/pdf/2601.21141", "abs": "https://arxiv.org/abs/2601.21141", "authors": ["Po-Hsun Chen", "Ivan C. H. Liu"], "title": "Optimization and Mobile Deployment for Anthropocene Neural Style Transfer", "categories": ["cs.HC", "cs.AI", "cs.GR"], "comment": "7 pages, 11 figures, submitted to SIGGRAPH 2026", "summary": "This paper presents AnthropoCam, a mobile-based neural style transfer (NST) system optimized for the visual synthesis of Anthropocene environments. Unlike conventional artistic NST, which prioritizes painterly abstraction, stylizing human-altered landscapes demands a careful balance between amplifying material textures and preserving semantic legibility. Industrial infrastructures, waste accumulations, and modified ecosystems contain dense, repetitive patterns that are visually expressive yet highly susceptible to semantic erosion under aggressive style transfer. To address this challenge, we systematically investigate the impact of NST parameter configurations on the visual translation of Anthropocene textures, including feature layer selection, style and content loss weighting, training stability, and output resolution. Through controlled experiments, we identify an optimal parameter manifold that maximizes stylistic expression while preventing semantic erasure. Our results demonstrate that appropriate combinations of convolutional depth, loss ratios, and resolution scaling enable the faithful transformation of anthropogenic material properties into a coherent visual language. Building on these findings, we implement a low-latency, feed-forward NST pipeline deployed on mobile devices. The system integrates a React Native frontend with a Flask-based GPU backend, achieving high-resolution inference within 3-5 seconds on general mobile hardware. This enables real-time, in-situ visual intervention at the site of image capture, supporting participatory engagement with Anthropocene landscapes. By coupling domain-specific NST optimization with mobile deployment, AnthropoCam reframes neural style transfer as a practical and expressive tool for real-time environmental visualization in the Anthropocene.", "AI": {"tldr": "本文提出了AnthropoCam，一个优化用于视觉合成人类影响景观的移动神经风格迁移系统。", "motivation": "与传统的艺术性NST相比，要将人类改变了的环境进行风格化，需要在放大材质纹理和保持语义可读性之间找到平衡。工业基础设施、垃圾堆积以及修改后的生态系统中的密集重复模式具有视觉表现力，但容易因过度风格迁移而导致语义损失。", "method": "该研究系统地调查了NST参数配置对人类影响景观的视觉转换的影响，并通过控制实验确定了一个最佳参数流形，以最大化风格表达同时避免语义擦除。基于这些发现，研究人员实现了一种低延迟、前馈的NST流水线并将其部署在移动设备上。", "result": "该系统结合React Native前端和Flask GPU后端，能够在普通移动硬件上实现在3-5秒内的高质量推理。这使实时就地图像捕获现场视觉干预成为可能，并支持参与性的人类影响景观互动。", "conclusion": "通过将特定领域的NST优化与移动部署相结合，AnthropoCam重新定义了神经风格迁移作为在人类世中进行实时环境可视化的一种实际而富有表现力的工具。"}}
{"id": "2601.21140", "pdf": "https://arxiv.org/pdf/2601.21140", "abs": "https://arxiv.org/abs/2601.21140", "authors": ["Ryan L. Mann", "Gabriel Waite"], "title": "Efficient Algorithms for Weakly-Interacting Quantum Spin Systems", "categories": ["quant-ph", "cs.CC", "cs.DS", "math.CO"], "comment": "6 pages, 0 figures", "summary": "We establish efficient algorithms for weakly-interacting quantum spin systems at arbitrary temperature. In particular, we obtain a fully polynomial-time approximation scheme for the partition function and an efficient approximate sampling scheme for the thermal distribution over a classical spin space. Our approach is based on the cluster expansion method and a standard reduction from approximate sampling to approximate counting.", "AI": {"tldr": "提出了针对弱相互作用量子自旋系统的高效算法。", "motivation": "旨在解决弱相互作用量子自旋系统在任意温度下的有效计算问题，包括分区函数的近似和热分布的采样。", "method": "基于群展开方法及从近似抽样到近似计数的标准转换。", "result": "获得了分区函数的全多项式时间逼近方案和经典自旋空间中的热分布的有效近似抽样方案。", "conclusion": "所提出的方法能有效解决弱相互作用量子自旋系统的计算问题，具有重要的理论意义和实用价值。"}}
{"id": "2601.21130", "pdf": "https://arxiv.org/pdf/2601.21130", "abs": "https://arxiv.org/abs/2601.21130", "authors": ["Yara El-Tawil", "Aneesha Sampath", "Emily Mower Provost"], "title": "What You Feel Is Not What They See: On Predicting Self-Reported Emotion from Third-Party Observer Labels", "categories": ["cs.AI"], "comment": "ICASSP 2026-2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "summary": "Self-reported emotion labels capture internal experience, while third-party labels reflect external perception. These perspectives often diverge, limiting the applicability of third-party-trained models to self-report contexts. This gap is critical in mental health, where accurate self-report modeling is essential for guiding intervention. We present the first cross-corpus evaluation of third-party-trained models on self-reports. We find activation unpredictable (CCC approximately 0) and valence moderately predictable (CCC approximately 0.3). Crucially, when content is personally significant to the speaker, models achieve high performance for valence (CCC approximately 0.6-0.8). Our findings point to personal significance as a key pathway for aligning external perception with internal experience and underscore the challenge of self-report activation modeling.", "AI": {"tldr": "本文研究了通过第三方观察者标签预测自我报告情绪的可能性，并探讨了个人意义在这一过程中的作用。", "motivation": "准确的自我报告模型对于心理健康领域指导干预措施至关重要，然而目前的第三方训练模型在这方面的应用存在局限性。作者希望通过研究找到一种方法来缩小外部感知与内部体验之间的差距。", "method": "作者进行了跨数据集评价，比较了通过第三方标签预测自我报告情绪中的激活和效价的情况，并特别关注个人意义对于模型性能的影响。", "result": "模型在预测自我报告的激活方面表现不佳（CCC约为0），但在预测具有个人意义内容的自我报告效价时表现较好（CCC为0.6-0.8）。", "conclusion": "研究发现，个人意义是实现外部感知与内部体验一致性的关键途径，并且强调了对自我报告激活建模所面临的挑战。"}}
{"id": "2601.21129", "pdf": "https://arxiv.org/pdf/2601.21129", "abs": "https://arxiv.org/abs/2601.21129", "authors": ["Guangping Liu", "Tipu Sultan", "Vittorio Di Giorgio", "Nick Hawkins", "Flavio Esposito", "Madi Babaiasl"], "title": "WheelArm-Sim: A Manipulation and Navigation Combined Multimodal Synthetic Data Generation Simulator for Unified Control in Assistive Robotics", "categories": ["cs.RO"], "comment": "Accepted to IEEE International Symposium on Medical Robotics (ISMR) 2026", "summary": "Wheelchairs and robotic arms enhance independent living by assisting individuals with upper-body and mobility limitations in their activities of daily living (ADLs). Although recent advancements in assistive robotics have focused on Wheelchair-Mounted Robotic Arms (WMRAs) and wheelchairs separately, integrated and unified control of the combination using machine learning models remains largely underexplored. To fill this gap, we introduce the concept of WheelArm, an integrated cyber-physical system (CPS) that combines wheelchair and robotic arm controls. Data collection is the first step toward developing WheelArm models. In this paper, we present WheelArm-Sim, a simulation framework developed in Isaac Sim for synthetic data collection. We evaluate its capability by collecting a manipulation and navigation combined multimodal dataset, comprising 13 tasks, 232 trajectories, and 67,783 samples. To demonstrate the potential of the WheelArm dataset, we implement a baseline model for action prediction in the mustard-picking task. The results illustrate that data collected from WheelArm-Sim is feasible for a data-driven machine learning model for integrated control.", "AI": {"tldr": "本文介绍了一种用于助残机器人统一控制的合成数据生成模拟器WheelArm-Sim。", "motivation": "目前对于轮椅与机械臂结合使用的统一控制系统，利用机器学习模型的研究较少。为了填补这一空白，作者提出了一个集成的轮椅和机械臂控制概念，并开发了一个合成数据采集框架。", "method": "通过在Isaac Sim中构建模拟环境WheelArm-Sim来收集包含13个任务、232条轨迹以及67,783个样本的数据集。并为其中之一的任务实现了基线模型以演示潜在的应用价值。", "result": "实验结果表明，从WheelArm-Sim中采集的合成数据可用于开发用于统一控制的数据驱动机器学习模型。", "conclusion": "模拟器WheelArm-Sim能够有效支持助残机器人系统中轮椅与机械臂联合操作的学习任务。"}}
{"id": "2601.21128", "pdf": "https://arxiv.org/pdf/2601.21128", "abs": "https://arxiv.org/abs/2601.21128", "authors": ["Václav Javorek", "Tomáš Železný", "Alessa Carbo", "Marek Hrúz", "Ivan Gruber"], "title": "Beyond a Single Reference: Training and Evaluation with Paraphrases in Sign Language Translation", "categories": ["cs.AI"], "comment": "Under review", "summary": "Most Sign Language Translation (SLT) corpora pair each signed utterance with a single written-language reference, despite the highly non-isomorphic relationship between sign and spoken languages, where multiple translations can be equally valid. This limitation constrains both model training and evaluation, particularly for n-gram-based metrics such as BLEU. In this work, we investigate the use of Large Language Models to automatically generate paraphrased variants of written-language translations as synthetic alternative references for SLT. First, we compare multiple paraphrasing strategies and models using an adapted ParaScore metric. Second, we study the impact of paraphrases on both training and evaluation of the pose-based T5 model on the YouTubeASL and How2Sign datasets. Our results show that naively incorporating paraphrases during training does not improve translation performance and can even be detrimental. In contrast, using paraphrases during evaluation leads to higher automatic scores and better alignment with human judgments. To formalize this observation, we introduce BLEUpara, an extension of BLEU that evaluates translations against multiple paraphrased references. Human evaluation confirms that BLEUpara correlates more strongly with perceived translation quality. We release all generated paraphrases, generation and evaluation code to support reproducible and more reliable evaluation of SLT systems.", "AI": {"tldr": "研究如何通过生成语义相似但表达不同的参考翻译来改进手语翻译模型的训练和评估。", "motivation": "现有的手语翻译数据集每个签名语句仅配有一个书面语言参考，这限制了模型训练与评价。提出利用大型语言模型自动生成翻译变体以提高SLT系统的可靠性和准确性。", "method": "使用不同的策略和模型自动生成多组语义相似的书面语言译文作为合成参考，并研究它们在训练和评估中的影响；引入BLEUpara对多个参考进行评分，更准确地反映人类判断。", "result": "直接将生成的翻译变体用于训练没有提高手语翻译性能甚至可能有害；但是，在评估阶段使用这些变体能显著提升自动评价分数，并与人工评判结果更加一致。", "conclusion": "通过引入基于多个参考的手语翻译评估方法，可以更准确地衡量SLT系统的质量，从而支持可重复性和可靠性更强的系统开发。"}}
{"id": "2601.21126", "pdf": "https://arxiv.org/pdf/2601.21126", "abs": "https://arxiv.org/abs/2601.21126", "authors": ["Kooktae Lee", "Julian Martinez"], "title": "AI-Augmented Density-Driven Optimal Control (D2OC) for Decentralized Environmental Mapping", "categories": ["cs.MA", "cs.RO"], "comment": null, "summary": "This paper presents an AI-augmented decentralized framework for multi-agent (multi-robot) environmental mapping under limited sensing and communication. While conventional coverage formulations achieve effective spatial allocation when an accurate reference map is available, their performance deteriorates under uncertain or biased priors. The proposed method introduces an adaptive and self-correcting mechanism that enables agents to iteratively refine local density estimates within an optimal transport-based framework, ensuring theoretical consistency and scalability. A dual multilayer perceptron (MLP) module enhances adaptivity by inferring local mean-variance statistics and regulating virtual uncertainty for long-unvisited regions, mitigating stagnation around local minima. Theoretical analysis rigorously proves convergence under the Wasserstein metric, while simulation results demonstrate that the proposed AI-augmented Density-Driven Optimal Control consistently achieves robust and precise alignment with the ground-truth density, yielding substantially higher-fidelity reconstruction of complex multi-modal spatial distributions compared with conventional decentralized baselines.", "AI": {"tldr": "本文提出了一种基于AI增强的分布式环境测绘框架，用于在有限感知和通信条件下多机器人协同工作。", "motivation": "传统覆盖算法在存在准确参考地图时表现良好，但在不确定或偏置先验下性能会下降。为了提高效率和鲁棒性，需要一种自适应且自我修正机制来改进局部密度估计。", "method": "提出了基于最优传输框架的AI增强型自适应密度驱动最优控制（D2OC）方法，利用双层感知机模块进行本地均值-方差统计推断，并调整长期未访问区域的虚拟不确定性，从而避免陷入局部极小点。", "result": "理论分析证明了该算法在Wasserstein度量下具有收敛性；模拟结果表明，与传统分布式基线相比，本文方法能更精确地重建复杂多模态空间分布。", "conclusion": "AI增强的D2OC框架有效提高了多机器人环境下环境测绘的精度和鲁棒性。"}}
{"id": "2601.21124", "pdf": "https://arxiv.org/pdf/2601.21124", "abs": "https://arxiv.org/abs/2601.21124", "authors": ["Artem Dementyev", "Wazeer Zulfikar", "Sinan Hersek", "Pascal Getreuer", "Anurag Kumar", "Vivek Kumar"], "title": "PhaseCoder: Microphone Geometry-Agnostic Spatial Audio Understanding for Multimodal LLMs", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Current multimodal LLMs process audio as a mono stream, ignoring the rich spatial information essential for embodied AI. Existing spatial audio models, conversely, are constrained to fixed microphone geometries, preventing deployment across diverse devices. We present PhaseCoder, a transformer-only spatial audio encoder that is agnostic to microphone geometry. PhaseCoder takes raw multichannel audio and microphone coordinates as inputs to perform localization and produces robust spatial embeddings. We demonstrate that Gemma 3n LLM can be fine-tuned to reason over \"Spatial Audio Tokens\" produced by PhaseCoder. We show our encoder achieves state-of-the-art results on microphone-invariant localization benchmarks and, for the first time, enables an LLM to perform complex spatial reasoning and targeted transcription tasks from an arbitrary microphone array.", "AI": {"tldr": "PhaseCoder是用于多模态大语言模型的无麦克风几何约束的空间音频理解编码器，可以处理任意麦克风阵列的音频数据。", "motivation": "当前多模态大语言模型仅将音频作为单声道流进行处理，忽略空间信息；而现有空间音频模型受限于固定麦克风阵列，无法适应不同设备。PhaseCoder旨在解决这些问题，提供不受限麦克风几何的空间音频理解能力。", "method": "PhaseCoder利用变压器编码器直接对多通道音频和麦克风坐标输入进行处理，生成鲁棒的空间嵌入，并可与Gemma 3n大语言模型结合使用以执行空间推理任务。", "result": "PhaseCoder在麦克风不变定位基准测试中实现了最先进的结果，并首次使大型语言模型能够从任意麦克风阵列执行复杂的空间推理和目标转录任务。", "conclusion": "PhaseCoder展示了其作为多模态大语言模型的强大工具，不仅能够在不依赖特定麦克风几何的情况下理解空间音频信息，还扩展了LLM在空间理解和目标识别方面的应用范围。"}}
{"id": "2601.21123", "pdf": "https://arxiv.org/pdf/2601.21123", "abs": "https://arxiv.org/abs/2601.21123", "authors": ["Tianyi Chen", "Yinheng Li", "Michael Solodko", "Sen Wang", "Nan Jiang", "Tingyuan Cui", "Junheng Hao", "Jongwoo Ko", "Sara Abdali", "Suzhen Zheng", "Leon Xu", "Hao Fan", "Pashmina Cameron", "Justin Wagle", "Kazuhito Koishida"], "title": "CUA-Skill: Develop Skills for Computer Using Agent", "categories": ["cs.AI"], "comment": null, "summary": "Computer-Using Agents (CUAs) aim to autonomously operate computer systems to complete real-world tasks. However, existing agentic systems remain difficult to scale and lag behind human performance. A key limitation is the absence of reusable and structured skill abstractions that capture how humans interact with graphical user interfaces and how to leverage these skills. We introduce CUA-Skill, a computer-using agentic skill base that encodes human computer-use knowledge as skills coupled with parameterized execution and composition graphs. CUA-Skill is a large-scale library of carefully engineered skills spanning common Windows applications, serving as a practical infrastructure and tool substrate for scalable, reliable agent development. Built upon this skill base, we construct CUA-Skill Agent, an end-to-end computer-using agent that supports dynamic skill retrieval, argument instantiation, and memory-aware failure recovery. Our results demonstrate that CUA-Skill substantially improves execution success rates and robustness on challenging end-to-end agent benchmarks, establishing a strong foundation for future computer-using agent development. On WindowsAgentArena, CUA-Skill Agent achieves state-of-the-art 57.5% (best of three) successful rate while being significantly more efficient than prior and concurrent approaches. The project page is available at https://microsoft.github.io/cua_skill/.", "AI": {"tldr": "CUA-Skill 是一种计算机使用代理的技能库，旨在通过编码人类与图形用户界面交互的知识来提高自主操作系统的效率和可靠性。", "motivation": "现有代理系统难以扩展且性能落后于人。关键限制在于缺少可重用的、结构化的技能抽象，无法有效捕捉如何利用这些技能进行计算机互动。", "method": "引入CUA-Skill作为大型技能库，涵盖常用Windows应用，并构建支持动态技能检索和故障恢复的记忆感知代理。", "result": "实验结果显示，CUA-Skill在执行成功率和鲁棒性方面优于先前的方法，在WindowsAgentArena上达到57.5%的成功率。", "conclusion": "CUA-Skill为未来的计算机使用代理开发奠定了坚实的基础，并展示了显著的性能提升。"}}
{"id": "2601.21120", "pdf": "https://arxiv.org/pdf/2601.21120", "abs": "https://arxiv.org/abs/2601.21120", "authors": ["Yan Meng", "Eduardo J. Torres-Rodríguez", "Marcelle Altshuler", "Nishanth Gowda", "Arhum Naeem", "Recai Yilmaz", "Omar Arnaout", "Daniel A. Donoho"], "title": "An AI Framework for Microanastomosis Motion Assessment", "categories": ["cs.CV"], "comment": "Accepted by IEEE/EMBS NER 2025. \\c{opyright} 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "Proficiency in microanastomosis is a fundamental competency across multiple microsurgical disciplines. These procedures demand exceptional precision and refined technical skills, making effective, standardized assessment methods essential. Traditionally, the evaluation of microsurgical techniques has relied heavily on the subjective judgment of expert raters. They are inherently constrained by limitations such as inter-rater variability, lack of standardized evaluation criteria, susceptibility to cognitive bias, and the time-intensive nature of manual review. These shortcomings underscore the urgent need for an objective, reliable, and automated system capable of assessing microsurgical performance with consistency and scalability. To bridge this gap, we propose a novel AI framework for the automated assessment of microanastomosis instrument handling skills. The system integrates four core components: (1) an instrument detection module based on the You Only Look Once (YOLO) architecture; (2) an instrument tracking module developed from Deep Simple Online and Realtime Tracking (DeepSORT); (3) an instrument tip localization module employing shape descriptors; and (4) a supervised classification module trained on expert-labeled data to evaluate instrument handling proficiency. Experimental results demonstrate the effectiveness of the framework, achieving an instrument detection precision of 97%, with a mean Average Precision (mAP) of 96%, measured by Intersection over Union (IoU) thresholds ranging from 50% to 95% (mAP50-95).", "AI": {"tldr": "本文提出了一种基于人工智能的微血管吻合运动评估框架。", "motivation": "传统的微外科手术技能评估依赖于专家的主观判断，存在评分者间差异、缺乏标准化评价标准等问题。因此，需要一个客观且自动化的系统来解决这些问题。", "method": "该框架包含四个核心组件：基于YOLO架构的器械检测模块；使用DeepSORT开发的跟踪模块；利用形状描述符的工具尖端定位模块以及根据专家标注数据训练的监督分类模块。", "result": "实验结果显示，该系统的器械检测精度达到了97%，平均准确率（mAP）为96%。", "conclusion": "提出的人工智能框架在微血管吻合运动评估中表现出色，具有高精确度和有效性。"}}
{"id": "2601.21116", "pdf": "https://arxiv.org/pdf/2601.21116", "abs": "https://arxiv.org/abs/2601.21116", "authors": ["Sankalp Gilda", "Shlok Gilda"], "title": "AI-Assisted Engineering Should Track the Epistemic Status and Temporal Validity of Architectural Decisions", "categories": ["cs.SE", "cs.AI"], "comment": "18 pages, 6 figures, 13 tables. Position paper", "summary": "This position paper argues that AI-assisted software engineering requires explicit mechanisms for tracking the epistemic status and temporal validity of architectural decisions. LLM coding assistants generate decisions faster than teams can validate them, yet no widely-adopted framework distinguishes conjecture from verified knowledge, prevents trust inflation through conservative aggregation, or detects when evidence expires. We propose three requirements for responsible AI-assisted engineering: (1) epistemic layers that separate unverified hypotheses from empirically validated claims, (2) conservative assurance aggregation grounded in the Gödel t-norm that prevents weak evidence from inflating confidence, and (3) automated evidence decay tracking that surfaces stale assumptions before they cause failures. We formalize these requirements as the First Principles Framework (FPF), ground its aggregation semantics in fuzzy logic, and define a quintet of invariants that any valid aggregation operator must satisfy. Our retrospective audit applying FPF criteria to two internal projects found that 20-25% of architectural decisions had stale evidence within two months, validating the need for temporal accountability. We outline research directions including learnable aggregation operators, federated evidence sharing, and SMT-based claim validation.", "AI": {"tldr": "提出了一种责任工程框架，用于追踪AI辅助软件架构决策的知识状态和时间有效性。", "motivation": "LLM编码助手产生的决定速度超过团队验证的速度，缺乏区分猜想与实证知识的机制，并无法防止信任膨胀或过时假设的风险。因此需要一种新的框架来解决这些问题。", "method": "提出了三个要求：（1）认知层将未经验证的假设与经验性验证声明分开；（2）基于Gödel t-范数保守的信任聚合，防止弱证据夸大信心；（3）自动过时信息追踪。这些需求被形式化为第一原理框架(FPF)，并定义了五个不变量。", "result": "应用FPF标准对两个内部项目进行回顾审计发现，在两个月内约20-25%的架构决策存在过时证据，验证了时间责任的重要性。", "conclusion": "提出了责任工程的第一原理框架以解决AI辅助软件开发中的知识状态和时间有效性问题，并指出了一些研究方向。"}}
{"id": "2601.21115", "pdf": "https://arxiv.org/pdf/2601.21115", "abs": "https://arxiv.org/abs/2601.21115", "authors": ["Mingzhi Zhu", "Boris Sobolev", "Rahul Krishna", "Raju Pavuluri", "Stacy Patterson", "Michele Merler"], "title": "Multi-task Code LLMs: Data Mix or Model Merge?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent research advocates deploying smaller, specialized code LLMs in agentic frameworks alongside frontier models, sparking interest in efficient strategies for multi-task learning that balance performance, constraints, and costs. We compare two approaches for creating small, multi-task code LLMs: data mixing versus model merging. We conduct extensive experiments across two model families (Qwen Coder and DeepSeek Coder) at two scales (2B and 7B parameters), fine-tuning them for code generation and code summarization tasks. Our evaluation on HumanEval, MBPP, and CodeXGlue benchmarks reveals that model merging achieves the best overall performance at larger scale across model families, retaining 96% of specialized model performance on code generation tasks while maintaining summarization capabilities. Notably, merged models can even surpass individually fine-tuned models, with our best configuration of Qwen Coder 2.5 7B model achieving 92.7% Pass@1 on HumanEval compared to 90.9% for its task-specific fine-tuned equivalent. At a smaller scale we find instead data mixing to be a preferred strategy. We further introduce a weight analysis technique to understand how different tasks affect model parameters and their implications for merging strategies. The results suggest that careful merging and mixing strategies can effectively combine task-specific capabilities without significant performance degradation, making them ideal for resource-constrained deployment scenarios.", "AI": {"tldr": "本文比较了数据混合与模型合并两种方法，用于创建小型多任务代码LLM。在Qwen Coder和DeepSeek Coder两个模型家族的两个规模上进行实验。", "motivation": "近期研究提倡在代理框架中部署较小的专业化代码LLM，并探索平衡性能、约束条件和成本的有效多任务学习策略。", "method": "本文比较了数据混合与模型合并两种方法，用于创建小型多任务代码LLM。对两个模型家族（Qwen Coder和DeepSeek Coder）在两个规模上进行实验，并引入了一种权重分析技术以理解不同任务如何影响模型参数及其合并策略的含义。", "result": "在大规模情况下，模型合并达到了最佳的整体性能，在代码生成方面保持了96%的专业化模型性能同时具备总结功能。而较小规模下数据混合更为理想。", "conclusion": "实验结果表明，精心设计的合并和混合策略可以有效地结合任务特定能力而不造成显著性能下降，适合资源受限部署场景使用。"}}
{"id": "2601.21114", "pdf": "https://arxiv.org/pdf/2601.21114", "abs": "https://arxiv.org/abs/2601.21114", "authors": ["Henri Gode", "Simon Doclo"], "title": "DNN-Based Online Source Counting Based on Spatial Generalized Magnitude Squared Coherence", "categories": ["eess.AS", "cs.SD"], "comment": "in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026, Barcelona, Spain", "summary": "The number of active sound sources is a key parameter in many acoustic signal processing tasks, such as source localization, source separation, and multi-microphone speech enhancement. This paper proposes a novel method for online source counting by detecting changes in the number of active sources based on spatial coherence. The proposed method exploits the fact that a single coherent source in spatially white background noise yields high spatial coherence, whereas only noise results in low spatial coherence. By applying a spatial whitening operation, the source counting problem is reformulated as a change detection task, aiming to identify the time frames when the number of active sources changes. The method leverages the generalized magnitude-squared coherence as a measure to quantify spatial coherence, providing features for a compact neural network trained to detect source count changes framewise. Simulation results with binaural hearing aids in reverberant acoustic scenes with up to 4 speakers and background noise demonstrate the effectiveness of the proposed method for online source counting.", "AI": {"tldr": "基于深度神经网络的在线声源计数方法，利用空间相干性变化检测活跃声源数量。", "motivation": "在许多声学信号处理任务中（如源定位、源分离和多麦克风语音增强），准确确定活跃声源的数量至关重要。本文提出了一种基于空间相干性的新方法来在线计算活跃声音的来源。", "method": "该方法利用单个相干源产生的高空间相干性和仅噪声带来的低空间相干性之间的差异，通过空间白化操作将问题转化为变化检测任务，并采用广义幅度平方相干度量作为特征输入到紧凑型神经网络中以帧级检测声源计数的变化。", "result": "仿真结果表明，在双耳助听器和有背景噪声的混响环境中使用多达4个说话人的场景下，提出的在线声源计数方法是有效的。", "conclusion": "基于深度神经网络的空间相干性变化检测技术在实时计算活跃声源数量方面展示出良好的性能。"}}
{"id": "2601.21113", "pdf": "https://arxiv.org/pdf/2601.21113", "abs": "https://arxiv.org/abs/2601.21113", "authors": ["Kaiyuan Wu", "Aditya Nagori", "Rishikesan Kamaleswaran"], "title": "Planner-Auditor Twin: Agentic Discharge Planning with FHIR-Based LLM Planning, Guideline Recall, Optional Caching and Self-Improvement", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Objective: Large language models (LLMs) show promise for clinical discharge planning, but their use is constrained by hallucination, omissions, and miscalibrated confidence. We introduce a self-improving, cache-optional Planner-Auditor framework that improves safety and reliability by decoupling generation from deterministic validation and targeted replay. Materials and Methods: We implemented an agentic, retrospective, FHIR-native evaluation pipeline using MIMIC-IV-on-FHIR. For each patient, the Planner (LLM) generates a structured discharge action plan with an explicit confidence estimate. The Auditor is a deterministic module that evaluates multi-task coverage, tracks calibration (Brier score, ECE proxies), and monitors action-distribution drift. The framework supports two-tier self-improvement: (i) within-episode regeneration when enabled, and (ii) cross-episode discrepancy buffering with replay for high-confidence, low-coverage cases. Results: While context caching improved performance over baseline, the self-improvement loop was the primary driver of gains, increasing task coverage from 32% to 86%. Calibration improved substantially, with reduced Brier/ECE and fewer high-confidence misses. Discrepancy buffering further corrected persistent high-confidence omissions during replay. Discussion: Feedback-driven regeneration and targeted replay act as effective control mechanisms to reduce omissions and improve confidence reliability in structured clinical planning. Separating an LLM Planner from a rule-based, observational Auditor enables systematic reliability measurement and safer iteration without model retraining. Conclusion: The Planner-Auditor framework offers a practical pathway toward safer automated discharge planning using interoperable FHIR data access and deterministic auditing, supported by reproducible ablations and reliability-focused evaluation.", "AI": {"tldr": "本论文介绍了一种用于临床出院规划的自我改进框架，通过分离生成与验证过程来提高安全性。", "motivation": "大型语言模型在临床出院规划中表现出潜力，但由于幻觉、遗漏和置信度偏差等问题，其使用受到限制。为了解决这些问题，提出了一种带缓存选项的自我改善计划审计框架。", "method": "采用FHIR原生评估流水线，由LLM生成结构化出院行动计划，并通过一个确定性模块进行多任务覆盖、校准和动作分布漂移跟踪评估。该框架支持两种自我改进机制：每次迭代内的重新生成以及跨事件的差异缓冲与重播。", "result": "实验表明，虽然上下文缓存提高了性能，但自我改善循环是主要的增长驱动力，任务覆盖率从32%提高到86%，并且校准有了显著改善。通过目标重播进一步纠正了持续存在的高置信度遗漏问题。", "conclusion": "分离的计划者与审计者的框架提供了一种使用可互操作FHIR数据访问和确定性审计实现安全自动化出院规划的实际路径，支持重复性消融和可靠性评估方法"}}
{"id": "2601.21112", "pdf": "https://arxiv.org/pdf/2601.21112", "abs": "https://arxiv.org/abs/2601.21112", "authors": ["Rauno Arike", "Raja Mehta Moreno", "Rohan Subramani", "Shubhorup Biswas", "Francis Rhys Ward"], "title": "How does information access affect LLM monitors' ability to detect sabotage?", "categories": ["cs.AI", "cs.SE"], "comment": "62 pages, 34 figures, 7 tables", "summary": "Frontier language model agents can exhibit misaligned behaviors, including deception, exploiting reward hacks, and pursuing hidden objectives. To control potentially misaligned agents, we can use LLMs themselves to monitor for misbehavior. In this paper, we study how information access affects LLM monitor performance. While one might expect that monitors perform better when they have access to more of the monitored agents' reasoning and actions, we find that contemporary systems often perform better with less information, a phenomenon we call the less-is-more effect for automated oversight. We demonstrate this phenomenon, and analyze the conditions under which it occurs, in three evaluation environments where agents must conduct sabotage while evading monitors. Motivated by the less-is-more effect, we introduce extract-and-evaluate (EaE) monitoring--a new hierarchical approach where one monitor isolates relevant excerpts from the monitored agent's trajectory and a separate monitor scores them. In BigCodeBench-Sabotage with GPT-4.1-mini as the monitor model, EaE improves sabotage detection rates by 16.8 percentage points over the next-best monitor without increasing the false positive rate. In other settings, EaE either outperforms or is competitive with baselines. In addition, we find that agents unaware of being monitored can be caught much more easily and that monitors scoring longer reasoning traces gain more from information filtering. Lastly, we conduct a cost-performance analysis and find that Gemini and Claude models with monitoring techniques that involve information filtering occupy much of the Pareto frontier.", "AI": {"tldr": "研究信息访问对LLM监控效能的影响，提出了一种新的分层监控方法EaE，并展示了其在不同环境中的优越性能。", "motivation": "探讨为何当代系统中，监控模型可能在拥有较少的信息时表现更好，这种现象被称为“少即是多”效应。为了应对这种情况，引入了一种新的监控策略。", "method": "研究了三种评估环境中代理执行破坏行为并逃避监控的情况，发现提取和评分（EaE）的监控方法可以更有效地检测到破坏行为，并且在没有增加误报率的情况下提高了16.8个百分点的破坏检测率。此外，分析了信息过滤对不同设置中的性能影响。", "result": "EaE监测方法在BigCodeBench-Sabotage中表现最佳，在其他场景下也与基线持平或优于基线。同时发现未意识到被监控的代理更容易被捕获，并且监控模型从较长推理轨迹中受益于信息过滤。", "conclusion": "通过实验验证了“少即是多”效应，提出了有效的EaE监测策略并证明其优越性，最后进行了成本效益分析，展示了在不同监控技术条件下的最优性能。"}}
{"id": "2601.21110", "pdf": "https://arxiv.org/pdf/2601.21110", "abs": "https://arxiv.org/abs/2601.21110", "authors": ["Jaden Pieper", "Stephen D. Voran"], "title": "Unseen but not Unknown: Using Dataset Concealment to Robustly Evaluate Speech Quality Estimation Models", "categories": ["eess.AS", "cs.SD"], "comment": "To be appear in Proc. ICASSP 2026", "summary": "We introduce Dataset Concealment (DSC), a rigorous new procedure for evaluating and interpreting objective speech quality estimation models. DSC quantifies and decomposes the performance gap between research results and real-world application requirements, while offering context and additional insights into model behavior and dataset characteristics. We also show the benefits of addressing the corpus effect by using the dataset Aligner from AlignNet when training models with multiple datasets. We demonstrate DSC and the improvements from the Aligner using nine training datasets and nine unseen datasets with three well-studied models: MOSNet, NISQA, and a Wav2Vec2.0-based model. DSC provides interpretable views of the generalization capabilities and limitations of models, while allowing all available data to be used at training. An additional result is that adding the 1000 parameter dataset Aligner to the 94 million parameter Wav2Vec model during training does significantly improve the resulting model's ability to estimate speech quality for unseen data.", "AI": {"tldr": "本文介绍了使用数据集隐蔽（DSC）来评估和解释客观语音质量估计模型的方法，通过这种方式可以量化研究结果与实际应用要求之间的性能差距。", "motivation": "为了更严谨地评估语音质量估计模型，并提供关于模型行为和数据集特征的进一步见解，本文提出了数据集隐蔽方法。同时，使用AlignNet中的对齐器（Aligner）处理不同数据集间的差异，以改善训练效果。", "method": "DSC通过在九个训练数据集上训练三种不同的语音质量估计模型，并评估这些模型在九个未见的数据集上的性能来实现其目标。此外，还展示了添加对齐器后模型的改进情况。", "result": "研究结果表明，使用Aligner可以显著提升Wav2Vec模型对于未知数据进行语音质量估计的能力。同时，DSC能够提供关于模型泛化能力和局限性的可解释视图，并允许在训练时利用所有可用的数据。", "conclusion": "通过引入DSC和对齐器（Aligner），本文展示了如何更有效地评估和改进语音质量估计模型的性能，从而更好地满足实际应用的要求。"}}
{"id": "2601.21105", "pdf": "https://arxiv.org/pdf/2601.21105", "abs": "https://arxiv.org/abs/2601.21105", "authors": ["Joyce Zhou", "Weijie Zhou", "Doug Turnbull", "Thorsten Joachims"], "title": "SteerEval: A Framework for Evaluating Steerability with Natural Language Profiles for Recommendation", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.HC"], "comment": "10 pages, 2 figures, 8 tables. Pre-print", "summary": "Natural-language user profiles have recently attracted attention not only for improved interpretability, but also for their potential to make recommender systems more steerable. By enabling direct editing, natural-language profiles allow users to explicitly articulate preferences that may be difficult to infer from past behavior. However, it remains unclear whether current natural-language-based recommendation methods can follow such steering commands. While existing steerability evaluations have shown some success for well-recognized item attributes (e.g., movie genres), we argue that these benchmarks fail to capture the richer forms of user control that motivate steerable recommendations. To address this gap, we introduce SteerEval, an evaluation framework designed to measure more nuanced and diverse forms of steerability by using interventions that range from genres to content-warning for movies. We assess the steerability of a family of pretrained natural-language recommenders, examine the potential and limitations of steering on relatively niche topics, and compare how different profile and recommendation interventions impact steering effectiveness. Finally, we offer practical design suggestions informed by our findings and discuss future steps in steerable recommender design.", "AI": {"tldr": "SteerEval框架用于评估基于自然语言推荐系统的可操控性，通过不同的用户干预措施来测试系统响应。", "motivation": "现有的可操纵性评测基准未能充分捕捉到更细腻和多样的用户控制方式。为了填补这一空白，本文提出了一种新框架来衡量更加丰富且多样化的可操作性。", "method": "引入SteerEval评估框架，并对一系列预训练的自然语言推荐系统进行测试，使用从电影类型到内容警告的不同干预措施。", "result": "测试了基于自然语言推荐系统的可操纵性及其在相对小众话题上的潜在和局限性。比较了不同用户干预措施对于操控有效性的影响力。", "conclusion": "提出了SteerEval框架用于评估更加细致多样的操控性，提供了设计建议，并探讨了未来可控推荐系统的设计方向。"}}
{"id": "2601.21096", "pdf": "https://arxiv.org/pdf/2601.21096", "abs": "https://arxiv.org/abs/2601.21096", "authors": ["Hongzheng Chen", "Alexander Novikov", "Ngân Vũ", "Hanna Alam", "Zhiru Zhang", "Aiden Grossman", "Mircea Trofin", "Amir Yazdanbakhsh"], "title": "Magellan: Autonomous Discovery of Novel Compiler Optimization Heuristics with AlphaEvolve", "categories": ["cs.AI", "cs.LG", "cs.PL"], "comment": "Accepted to C4ML@CGO'26", "summary": "Modern compilers rely on hand-crafted heuristics to guide optimization passes. These human-designed rules often struggle to adapt to the complexity of modern software and hardware and lead to high maintenance burden. To address this challenge, we present Magellan, an agentic framework that evolves the compiler pass itself by synthesizing executable C++ decision logic. Magellan couples an LLM coding agent with evolutionary search and autotuning in a closed loop of generation, evaluation on user-provided macro-benchmarks, and refinement, producing compact heuristics that integrate directly into existing compilers. Across several production optimization tasks, Magellan discovers policies that match or surpass expert baselines. In LLVM function inlining, Magellan synthesizes new heuristics that outperform decades of manual engineering for both binary-size reduction and end-to-end performance. In register allocation, it learns a concise priority rule for live-range processing that matches intricate human-designed policies on a large-scale workload. We also report preliminary results on XLA problems, demonstrating portability beyond LLVM with reduced engineering effort.", "AI": {"tldr": "Magellan是一个自动发现编译器优化策略的框架，通过结合大型语言模型和进化搜索来生成高效的决策逻辑。", "motivation": "手工艺品化的编译器优化规则难以适应现代软件和硬件复杂性，并且维护成本高。因此，需要一个可以自动生成并优化这些规则的方法。", "method": "Magellan利用大语言模型编写决策逻辑，结合进化搜索和自动调整，在生成、评估和改进的闭环中工作，最终产生适用于现有编译器的小型化策略。", "result": "在多种实际的优化任务中，Magellan发现的政策与专家基线相匹敌甚至超越。例如，在LLVM函数内联方面，Magellan生成的新规则优于几十年的手工艺品化工程；而在寄存器分配方面，则学习出一套简洁的优先级规则来处理活动范围。", "conclusion": "研究表明，Magellan能够有效地发现和优化编译器策略，显示了其在解决复杂软件和硬件优化问题上的潜力。"}}
{"id": "2601.21095", "pdf": "https://arxiv.org/pdf/2601.21095", "abs": "https://arxiv.org/abs/2601.21095", "authors": ["Akbar Anbar Jafari", "Cagri Ozcinar", "Gholamreza Anbarjafari"], "title": "Responsible AI: The Good, The Bad, The AI", "categories": ["cs.AI"], "comment": "14 pages, 5 figures", "summary": "The rapid proliferation of artificial intelligence across organizational contexts has generated profound strategic opportunities while introducing significant ethical and operational risks. Despite growing scholarly attention to responsible AI, extant literature remains fragmented and is often adopting either an optimistic stance emphasizing value creation or an excessively cautious perspective fixated on potential harms. This paper addresses this gap by presenting a comprehensive examination of AI's dual nature through the lens of strategic information systems. Drawing upon a systematic synthesis of the responsible AI literature and grounded in paradox theory, we develop the Paradox-based Responsible AI Governance (PRAIG) framework that articulates: (1) the strategic benefits of AI adoption, (2) the inherent risks and unintended consequences, and (3) governance mechanisms that enable organizations to navigate these tensions. Our framework advances theoretical understanding by conceptualizing responsible AI governance as the dynamic management of paradoxical tensions between value creation and risk mitigation. We provide formal propositions demonstrating that trade-off approaches amplify rather than resolve these tensions, and we develop a taxonomy of paradox management strategies with specified contingency conditions. For practitioners, we offer actionable guidance for developing governance structures that neither stifle innovation nor expose organizations to unacceptable risks. The paper concludes with a research agenda for advancing responsible AI governance scholarship.", "AI": {"tldr": "该论文提出了一个基于悖论的负责任人工智能治理（PRAIG）框架，旨在解决人工智能在组织中的应用带来的价值创造与风险之间的紧张关系。", "motivation": "当前的人工智能研究要么过于乐观地强调价值创造，要么过度谨慎地关注潜在的危害。该论文希望通过系统性合成负责任人工智能文献并基于悖论理论来填补这一空白。", "method": "通过系统综述现有负责的人工智能文献，并运用悖论理论构建了一个框架，涵盖了战略收益、内在风险和未预见后果以及治理机制。", "result": "提出了PRAIG框架，该框架指出了人工智能的双刃剑特性及其管理策略。研究发现交易方式并不能解决这些紧张关系，而是需要特定的悖论管理策略。", "conclusion": "论文提供了理论上的理解并为实践者提供了一套行动指南以构建既不抑制创新又不增加风险的治理结构，并提出了未来的研究方向。"}}
{"id": "2601.21094", "pdf": "https://arxiv.org/pdf/2601.21094", "abs": "https://arxiv.org/abs/2601.21094", "authors": ["Minjae Kwon", "Josephine Lamp", "Lu Feng"], "title": "Safety Generalization Under Distribution Shift in Safe Reinforcement Learning: A Diabetes Testbed", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "Safe Reinforcement Learning (RL) algorithms are typically evaluated under fixed training conditions. We investigate whether training-time safety guarantees transfer to deployment under distribution shift, using diabetes management as a safety-critical testbed. We benchmark safe RL algorithms on a unified clinical simulator and reveal a safety generalization gap: policies satisfying constraints during training frequently violate safety requirements on unseen patients. We demonstrate that test-time shielding, which filters unsafe actions using learned dynamics models, effectively restores safety across algorithms and patient populations. Across eight safe RL algorithms, three diabetes types, and three age groups, shielding achieves Time-in-Range gains of 13--14\\% for strong baselines such as PPO-Lag and CPO while reducing clinical risk index and glucose variability. Our simulator and benchmark provide a platform for studying safety under distribution shift in safety-critical control domains. Code is available at https://github.com/safe-autonomy-lab/GlucoSim and https://github.com/safe-autonomy-lab/GlucoAlg.", "AI": {"tldr": "研究安全强化学习算法在糖尿病管理中的安全性推广问题，特别是在分布迁移情况下的表现。", "motivation": "传统安全强化学习算法通常只评估固定训练条件下的性能。本文旨在探讨这些保证能否迁移到不同的部署条件下，并以糖尿病管理作为测试床来检验这一点。", "method": "使用统一的临床模拟器对八种安全强化学习算法进行基准测试，涵盖三种类型的糖尿病和三个年龄组。通过引入测试时的屏蔽机制（利用学习到的动力学模型过滤不安全的动作）验证方法的有效性。", "result": "结果显示，在各种情况下应用屏蔽技术能够显著提高血糖管理的效果，包括增加目标范围内的时间比例13-14%，同时降低临床风险指数和葡萄糖波动。此方法适用于多种算法，并且能跨越不同的患者群体保持安全性。", "conclusion": "研究表明安全强化学习算法在分布迁移的情况下可能存在安全隐患，但通过测试时的屏蔽技术可以有效地解决这一问题，为研究安全性推广提供了新的平台与思路。"}}
{"id": "2601.21090", "pdf": "https://arxiv.org/pdf/2601.21090", "abs": "https://arxiv.org/abs/2601.21090", "authors": ["Mohammad Walid Charrwi", "Zaid Hussain"], "title": "Deep Reinforcement Learning for Fault-Adaptive Routing in Eisenstein-Jacobi Interconnection Topologies", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "The increasing density of many-core architectures necessitates interconnection networks that are both high-performance and fault-resilient. Eisenstein-Jacobi (EJ) networks, with their symmetric 6-regular topology, offer superior topological properties but challenge traditional routing heuristics under fault conditions. This paper evaluates three routing paradigms in faulty EJ environments: deterministic Greedy Adaptive Routing, theoretically optimal Dijkstra's algorithm, and a reinforcement learning (RL)-based approach. Using a multi-objective reward function to penalize fault proximity and reward path efficiency, the RL agent learns to navigate around clustered failures that typically induce dead-ends in greedy geometric routing. Dijkstra's algorithm establishes the theoretical performance ceiling by computing globally optimal paths with complete topology knowledge, revealing the true connectivity limits of faulty networks. Quantitative analysis at nine faulty nodes shows greedy routing catastrophically degrades to 10% effective reachability and packet delivery, while Dijkstra proves 52-54% represents the topological optimum. The RL agent achieves 94% effective reachability and 91% packet delivery, making it suitable for distributed deployment. Furthermore, throughput evaluations demonstrate that RL sustains over 90% normalized throughput across all loads, actually outperforming Dijkstra under congestion through implicit load balancing strategies. These results establish RL-based adaptive policies as a practical solution that bridges the gap between greedy's efficiency and Dijkstra's optimality, providing robust, self-healing communication in fault-prone interconnection networks without requiring the global topology knowledge or computational overhead of optimal algorithms.", "AI": {"tldr": "论文研究了在故障环境中，Eisenstein-Jacobi网络的自适应路由方法，通过深度强化学习实现高效且鲁棒的通信。", "motivation": "随着多核架构密度增加，需要高效率和容错性强的互连网络。传统路由算法在面对Eisenstein-Jacobi网络故障时表现不佳。", "method": "论文采用确定性贪婪自适应路由、Dijkstra最短路径算法及深度强化学习三种方法，在九个节点故障环境下进行性能对比，其中RL通过多目标奖励函数优化路径选择。", "result": "定量分析显示贪婪路由在故障情况下达到10%的有效可达性和数据包交付率。而RL实现了94%的有效可达性与91%的数据包交付率，并保持了超过90%的正常化吞吐量，证明其有效。", "conclusion": "深度强化学习方法能提供一种介于贪婪算法效率和Dijkstra最优策略之间的实用解决方案，在故障网络中实现自我修复通信。"}}
{"id": "2601.21084", "pdf": "https://arxiv.org/pdf/2601.21084", "abs": "https://arxiv.org/abs/2601.21084", "authors": ["Amit Meghanani", "Thomas Hain"], "title": "Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to ICASSP 2026", "summary": "Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MSE) loss between enhanced and clean speech. However, MSE is prone to exploiting positional embeddings in SSL models, allowing the objective to be minimised through positional correlations instead of content-related information. This work frames the problem as a general limitation of self-supervised representation fine-tuning and investigates it through representation-guided SE. Two strategies are considered: (1) zero-padding, previously explored in SSL pre-training but here examined in the fine-tuning setting, and (2) speed perturbations with a soft-DTW loss. Experiments show that the soft-DTW-based approach achieves faster convergence and improved downstream performance, underscoring the importance of position-invariant fine-tuning in SSL-based speech modelling.", "AI": {"tldr": "本文研究了在自监督学习基础上的语音增强模型微调中，位置无关性的改进方法。", "motivation": "传统基于MSE损失的语音增强模型容易依赖于位置嵌入而不是内容信息进行优化，影响下游任务性能。因此提出改善策略以提升模型鲁棒性和有效性。", "method": "本文提出了两种策略：一种是零填充技术，在微调设置中测试；另一种则是采用速度扰动并引入软DTW损失函数进行训练。", "result": "实验表明基于软DTW的方法实现了更快的收敛以及更好的下游任务表现，突显了位置无关性的重要性。", "conclusion": "通过改进自监督学习模型在语音增强中的微调策略，可以显著提升模型性能和鲁棒性。"}}
{"id": "2601.21083", "pdf": "https://arxiv.org/pdf/2601.21083", "abs": "https://arxiv.org/abs/2601.21083", "authors": ["Jarrod Barnes"], "title": "OpenSec: Measuring Incident Response Agent Calibration Under Adversarial Evidence", "categories": ["cs.AI"], "comment": "6 pages, 2 figures, 3 tables. Code: https://github.com/jbarnes850/opensec-env", "summary": "As large language models improve, so do their offensive applications: frontier agents now generate working exploits for under $50 in compute (Heelan, 2026). Defensive incident response (IR) agents must keep pace, but existing benchmarks conflate action execution with correct execution, hiding calibration failures when agents process adversarial evidence. We introduce OpenSec, a dual-control reinforcement learning environment that evaluates IR agents under realistic prompt injection scenarios. Unlike static capability benchmarks, OpenSec scores world-state-changing containment actions under adversarial evidence via execution-based metrics: time-to-first-containment (TTFC), blast radius (false positives per episode), and injection violation rates. Evaluating four frontier models on 40 standard-tier episodes, we find consistent over-triggering in this setting: GPT-5.2, Gemini 3, and DeepSeek execute containment in 100% of episodes with 90-97% false positive rates. Claude Sonnet 4.5 shows partial calibration (85% containment, 72% FP), demonstrating that OpenSec surfaces a calibration failure mode hidden by aggregate success metrics. Code available at https://github.com/jbarnes850/opensec-env.", "AI": {"tldr": "本文介绍了OpenSec，这是一个用于评估防御性事件响应代理在对抗证据情况下校准情况的环境。", "motivation": "随着大型语言模型的进步，它们的应用也变得更加具有攻击性。现有的基准测试将行动执行与正确执行混淆在一起，在处理对抗证据时隐藏了代理的校准失败。因此需要一个新的方法来评估防御性事件响应（IR）代理在真实情况下的表现。", "method": "本文引入了一个称为OpenSec的双控强化学习环境，该环境通过执行基线指标对世界状态变化的遏制动作进行评分：时间至首次封堵(TTFC)、爆炸半径(每集错误封堵次数)和注入违反率。此方法不同于静态能力基准测试。", "result": "在40个标准级场景中，四个前沿模型（GPT-5.2, Gemini 3, DeepSeek 和 Claude Sonnet 4.5）均表现出过度触发的行为：前三者在所有情况下都会执行遏制动作，并且错误率高达90%-97%；而Claude Sonnet 4.5的表现较好，但仍然存在过度封堵的问题（85%的封堵成功率和72%的错误率）。", "conclusion": "OpenSec揭示了一种由汇总成功指标隐藏的校准失败模式。它能更好地衡量IR代理在对抗证据情况下的实际表现"}}
{"id": "2601.21082", "pdf": "https://arxiv.org/pdf/2601.21082", "abs": "https://arxiv.org/abs/2601.21082", "authors": ["Shivam Patel", "William Cocke", "Gauri Joshi"], "title": "LOCUS: Low-Dimensional Model Embeddings for Efficient Model Exploration, Comparison, and Selection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapidly growing ecosystem of Large Language Models (LLMs) makes it increasingly challenging to manage and utilize the vast and dynamic pool of models effectively. We propose LOCUS, a method that produces low-dimensional vector embeddings that compactly represent a language model's capabilities across queries. LOCUS is an attention-based approach that generates embeddings by a deterministic forward pass over query encodings and evaluation scores via an encoder model, enabling seamless incorporation of new models to the pool and refinement of existing model embeddings without having to perform any retraining. We additionally train a correctness predictor that uses model embeddings and query encodings to achieve state-of-the-art routing accuracy on unseen queries. Experiments show that LOCUS needs up to 4.8x fewer query evaluation samples than baselines to produce informative and robust embeddings. Moreover, the learned embedding space is geometrically meaningful: proximity reflects model similarity, enabling a range of downstream applications including model comparison and clustering, model portfolio selection, and resilient proxies of unavailable models.", "AI": {"tldr": "LOCUS是一种生成低维向量嵌入的方法，用于紧凑地表示语言模型的能力。", "motivation": "随着大型语言模型的迅速增长，有效地管理和利用这些模型变得越来越具有挑战性。为此提出了LOCUS方法来解决这个问题。", "method": "LOCUS是一个基于注意力机制的方法，通过确定性的前向传递生成嵌入，并训练了一个正确性预测器以实现未见过查询上的高精度路由。", "result": "实验表明，LOCUS相较于基线需要少至4.8倍的评估样本就能产生具有信息量且鲁棒性强的嵌入。此外，学习到的空间几何意义明确：接近度反映模型相似性，从而支持下游应用如模型比较和聚类等。", "conclusion": "LOCUS方法成功地解决了大型语言模型的有效管理问题，并通过低维向量嵌入实现了高效的数据探索、对比与选择功能。"}}
{"id": "2601.21081", "pdf": "https://arxiv.org/pdf/2601.21081", "abs": "https://arxiv.org/abs/2601.21081", "authors": ["Yu Huo", "Siyu Zhang", "Kun Zeng", "Haoyue Liu", "Owen Lee", "Junlin Chen", "Yuquan Lu", "Yifu Guo", "Yaodong Liang", "Xiaoying Tang"], "title": "Shape of Thought: Progressive Object Assembly via Visual Chain-of-Thought", "categories": ["cs.CV"], "comment": "The code is available at https://anonymous.4open.science/r/16FE/", "summary": "Multimodal models for text-to-image generation have achieved strong visual fidelity, yet they remain brittle under compositional structural constraints-notably generative numeracy, attribute binding, and part-level relations. To address these challenges, we propose Shape-of-Thought (SoT), a visual CoT framework that enables progressive shape assembly via coherent 2D projections without external engines at inference time. SoT trains a unified multimodal autoregressive model to generate interleaved textual plans and rendered intermediate states, helping the model capture shape-assembly logic without producing explicit geometric representations. To support this paradigm, we introduce SoT-26K, a large-scale dataset of grounded assembly traces derived from part-based CAD hierarchies, and T2S-CompBench, a benchmark for evaluating structural integrity and trace faithfulness. Fine-tuning on SoT-26K achieves 88.4% on component numeracy and 84.8% on structural topology, outperforming text-only baselines by around 20%. SoT establishes a new paradigm for transparent, process-supervised compositional generation. The code is available at https://anonymous.4open.science/r/16FE/. The SoT-26K dataset will be released upon acceptance.", "AI": {"tldr": "本文提出了Shape-of-Thought（SoT）框架，通过视觉链式思维逐步组装图像对象。", "motivation": "多模态模型在文本到图像生成中取得了较好的视觉保真度，但在处理组合结构约束方面仍显脆弱，例如生成计数、属性绑定和部分级别关系。本文旨在解决这些问题。", "method": "SoT是一个通过连贯的2D投影逐步组装形状的可视化CoT框架，训练统一的多模态自回归模型来生成交错的文字计划和渲染的中间状态，帮助模型捕获形状组装逻辑而不产生明确的几何表示。", "result": "在SoT-26K数据集上微调后，SoT在组件计数方面达到88.4%，结构拓扑为84.8%，优于文本基线约20%。", "conclusion": "本文提出了一种新的透明、过程监督的组合生成范式。"}}
{"id": "2601.21078", "pdf": "https://arxiv.org/pdf/2601.21078", "abs": "https://arxiv.org/abs/2601.21078", "authors": ["Jiaqi Li", "Guangming Wang", "Shuntian Zheng", "Minzhe Ni", "Xiaoman Lu", "Guanghui Ye", "Yu Guan"], "title": "Towards Mitigating Modality Bias in Vision-Language Models for Temporal Action Localization", "categories": ["cs.CV"], "comment": null, "summary": "Temporal Action Localization (TAL) requires identifying both the boundaries and categories of actions in untrimmed videos. While vision-language models (VLMs) offer rich semantics to complement visual evidence, existing approaches tend to overemphasize linguistic priors at the expense of visual performance, leading to a pronounced modality bias. We propose ActionVLM, a vision-language aggregation framework that systematically mitigates modality bias in TAL. Our key insight is to preserve vision as the dominant signal while adaptively exploiting language only when beneficial. To this end, we introduce (i) a debiasing reweighting module that estimates the language advantage-the incremental benefit of language over vision-only predictions-and dynamically reweights language modality accordingly, and (ii) a residual aggregation strategy that treats language as a complementary refinement rather than the primary driver. This combination alleviates modality bias, reduces overconfidence from linguistic priors, and strengthens temporal reasoning. Experiments on THUMOS14 show that our model outperforms state-of-the-art by up to 3.2% mAP.", "AI": {"tldr": "提出了一种减轻视觉语言模型在时间动作定位中模态偏见的方法，以提高准确性。", "motivation": "现有的方法倾向于过分强调语言先验而忽视了视觉性能，导致明显的模态偏见。", "method": "提出了ActionVLM框架，包含了一个去偏重加权模块和一种残差聚合策略，来减轻模态偏见并增强时间推理能力。", "result": "实验表明，在THUMOS14数据集上的模型精度比现有最佳方法高出最多3.2%mAP。", "conclusion": "通过提出的方法可以有效地解决模态偏见问题，并提高动作定位的准确性。"}}
{"id": "2601.21076", "pdf": "https://arxiv.org/pdf/2601.21076", "abs": "https://arxiv.org/abs/2601.21076", "authors": ["Abhijith Shaji", "Tamoghna Chattopadhyay", "Sophia I. Thomopoulos", "Greg Ver Steeg", "Paul M. Thompson", "Jose-Luis Ambite"], "title": "Multi-modal Imputation for Alzheimer's Disease Classification", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning has been successful in predicting neurodegenerative disorders, such as Alzheimer's disease, from magnetic resonance imaging (MRI). Combining multiple imaging modalities, such as T1-weighted (T1) and diffusion-weighted imaging (DWI) scans, can increase diagnostic performance. However, complete multimodal datasets are not always available. We use a conditional denoising diffusion probabilistic model to impute missing DWI scans from T1 scans. We perform extensive experiments to evaluate whether such imputation improves the accuracy of uni-modal and bi-modal deep learning models for 3-way Alzheimer's disease classification-cognitively normal, mild cognitive impairment, and Alzheimer's disease. We observe improvements in several metrics, particularly those sensitive to minority classes, for several imputation configurations.", "AI": {"tldr": "使用条件去噪扩散概率模型从T1扫描中插补缺失的DWI扫描，以提高阿尔茨海默病分类的准确性。", "motivation": "结合多种成像模式可以提高诊断性能，但完整的多模态数据集并不总是可用。通过插补技术改善诊断准确率。", "method": "采用条件去噪扩散概率模型从T1扫描中插补缺失DWI扫描，并评估不同插补配置对单模态和双模态深度学习模型在阿尔茨海默病三分类中的准确性的影响。", "result": "观察到多种指标有所改进，特别是在少数类敏感的度量上。", "conclusion": "所提出的多模态插补方法能够提升诊断准确率，尤其是在处理少数类别时效果更佳。"}}
{"id": "2601.21070", "pdf": "https://arxiv.org/pdf/2601.21070", "abs": "https://arxiv.org/abs/2601.21070", "authors": ["Daniel Rodriguez-Cardenas", "Xiaochang Li", "Marcos Macedo", "Antonio Mastropaolo", "Dipin Khati", "Yuan Tian", "Huajie Shao", "Denys Poshyvanyk"], "title": "Towards Comprehensive Benchmarking Infrastructure for LLMs In Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": "Short paper from bechmarking for software engineering workshop FSE2025", "summary": "Large language models for code are advancing fast, yet our ability to evaluate them lags behind. Current benchmarks focus on narrow tasks and single metrics, which hide critical gaps in robustness, interpretability, fairness, efficiency, and real-world usability. They also suffer from inconsistent data engineering practices, limited software engineering context, and widespread contamination issues. To understand these problems and chart a path forward, we combined an in-depth survey of existing benchmarks with insights gathered from a dedicated community workshop. We identified three core barriers to reliable evaluation: the absence of software-engineering-rich datasets, overreliance on ML-centric metrics, and the lack of standardized, reproducible data pipelines. Building on these findings, we introduce BEHELM, a holistic benchmarking infrastructure that unifies software-scenario specification with multi-metric evaluation. BEHELM provides a structured way to assess models across tasks, languages, input and output granularities, and key quality dimensions. Our goal is to reduce the overhead currently required to construct benchmarks while enabling a fair, realistic, and future-proof assessment of LLMs in software engineering.", "AI": {"tldr": "构建了一个全面的大型语言模型评估基础设施BEHELM，旨在解决当前代码领域大语言模型评估存在的问题。", "motivation": "当前对代码领域的大型语言模型评价不足，存在数据集不丰富、评价标准单一等问题。因此需要一种能够全面评估这些模型的方法和工具。", "method": "结合现有基准的深入调研及社区研讨会获取见解，识别出三大核心障碍，并在此基础上开发了BEHELM，一个将软件场景规范与多指标评估相结合的综合性评估基础设施。", "result": "BEHELM提供了一种结构化方法来跨任务、语言、输入输出粒度和关键质量维度评估模型。它减少了构建基准所需的开销，并促进了对LLMs在软件工程中公平、现实和未来证明的评估。", "conclusion": "通过引入BEHELM，能够更好地理解和解决当前大语言模型评估中存在的问题，并为未来的评估提供了更为全面的标准和工具。"}}
{"id": "2601.21066", "pdf": "https://arxiv.org/pdf/2601.21066", "abs": "https://arxiv.org/abs/2601.21066", "authors": ["Kealan Dunnett", "Reza Arablouei", "Dimity Miller", "Volkan Dedeoglu", "Raja Jurdak"], "title": "BadDet+: Robust Backdoor Attacks for Object Detection", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Backdoor attacks pose a severe threat to deep learning, yet their impact on object detection remains poorly understood compared to image classification. While attacks have been proposed, we identify critical weaknesses in existing detection-based methods, specifically their reliance on unrealistic assumptions and a lack of physical validation. To bridge this gap, we introduce BadDet+, a penalty-based framework that unifies Region Misclassification Attacks (RMA) and Object Disappearance Attacks (ODA). The core mechanism utilizes a log-barrier penalty to suppress true-class predictions for triggered inputs, resulting in (i) position and scale invariance, and (ii) enhanced physical robustness. On real-world benchmarks, BadDet+ achieves superior synthetic-to-physical transfer compared to existing RMA and ODA baselines while preserving clean performance. Theoretical analysis confirms the proposed penalty acts within a trigger-specific feature subspace, reliably inducing attacks without degrading standard inference. These results highlight significant vulnerabilities in object detection and the necessity for specialized defenses.", "AI": {"tldr": "BadDet+ 是一种针对对象检测的鲁棒后门攻击框架，它结合了区域误分类攻击和物体消失攻击。", "motivation": "现有的基于对象检测的方法存在依赖不现实假设的问题，并且缺乏物理验证。为了填补这一空白并提高对后门攻击在对象检测中影响的理解，提出了BadDet+。", "method": "该方法使用log-barrier惩罚来抑制触发输入的真实类预测，实现了位置和比例不变性以及增强的物理鲁棒性。", "result": "BadDet+ 在真实世界基准上实现优于现有RMA和ODA基线的合成到物理转移，并保持了清洁性能。理论分析表明所提出的惩罚在特定特征子空间内可靠地诱导攻击而不会影响标准推断。", "conclusion": "该研究突显了对象检测中的显著漏洞并强调需要专门的防御措施来应对这些威胁。"}}
{"id": "2601.21064", "pdf": "https://arxiv.org/pdf/2601.21064", "abs": "https://arxiv.org/abs/2601.21064", "authors": ["Minghui Chen", "Wenlong Deng", "James Zou", "Han Yu", "Xiaoxiao Li"], "title": "Textual Equilibrium Propagation for Deep Compound AI Systems", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICLR 2026", "summary": "Large language models (LLMs) are increasingly deployed as part of compound AI systems that coordinate multiple modules (e.g., retrievers, tools, verifiers) over long-horizon workflows. Recent approaches that propagate textual feedback globally (e.g., TextGrad) make it feasible to optimize such pipelines, but we find that performance degrades as system depth grows. In particular, long-horizon agentic workflows exhibit two depth-scaling failure modes: 1) exploding textual gradient, where textual feedback grows exponentially with depth, leading to prohibitively long message and amplifies evaluation biases; and 2) vanishing textual gradient, where limited long-context ability causes models overemphasize partial feedback and compression of lengthy feedback causes downstream messages to lose specificity gradually as they propagate many hops upstream. To mitigate these issues, we introduce Textual Equilibrium Propagation (TEP), a local learning principle inspired by Equilibrium Propagation in energy-based models. TEP includes two phases: 1) a free phase where a local LLM critics iteratively refine prompts until reaching equilibrium (no further improvements are suggested); and 2) a nudged phase which applies proximal prompt edits with bounded modification intensity, using task-level objectives that propagate via forward signaling rather than backward feedback chains. This design supports local prompt optimization followed by controlled adaptation toward global goals without the computational burden and signal degradation of global textual backpropagation. Across long-horizon QA benchmarks and multi-agent tool-use dataset, TEP consistently improves accuracy and efficiency over global propagation methods such as TextGrad. The gains grows with depth, while preserving the practicality of black-box LLM components in deep compound AI system.", "AI": {"tldr": "本文介绍了文本平衡传播（TEP）技术，旨在优化深度复合AI系统中的长时序工作流程，解决现有方法在系统深度增加时性能下降的问题。", "motivation": "随着语言模型作为复合AI系统的模块部署增多，现有的全局文本反馈传播方法在处理深层系统时表现出性能衰退。这种退化主要由两种问题造成：文本梯度爆炸和消失。为了解决这些问题，提出了TEP技术。", "method": "TEP采用了两个阶段的技术路线：自由阶段，本地LLM批评家迭代优化提示直至达到平衡状态；推进阶段，在保持局部提示优化的同时通过任务级目标控制调整向全局目标的适应性，从而实现对深度复合AI系统的优化。", "result": "在多个长期问答基准测试和多代理工具使用数据集上，TEP技术提高了准确性并减少了效率损失，优于现有的全球传播方法。随着系统复杂性的增加，TEP的优势更加明显。", "conclusion": "通过引入文本平衡传播（TEP），论文提供了一种优化深度复合AI系统的有效方法，在保持黑盒LLM组件实用性的同时解决了现有全局文本反馈传播方法的局限性。"}}
{"id": "2601.21063", "pdf": "https://arxiv.org/pdf/2601.21063", "abs": "https://arxiv.org/abs/2601.21063", "authors": ["Pierre-Yves Lajoie", "Karthik Soma", "Haechan Mark Bong", "Alice Lemieux-Bourque", "Rongge Zhang", "Vivek Shankar Varadharajan", "Giovanni Beltrame"], "title": "Multi-Robot Decentralized Collaborative SLAM in Planetary Analogue Environments: Dataset, Challenges, and Lessons Learned", "categories": ["cs.RO"], "comment": null, "summary": "Decentralized collaborative simultaneous localization and mapping (C-SLAM) is essential to enable multirobot missions in unknown environments without relying on preexisting localization and communication infrastructure. This technology is anticipated to play a key role in the exploration of the Moon, Mars, and other planets. In this article, we share insights and lessons learned from C-SLAM experiments involving three robots operating on a Mars analogue terrain and communicating over an ad hoc network. We examine the impact of limited and intermittent communication on C-SLAM performance, as well as the unique localization challenges posed by planetary-like environments. Additionally, we introduce a novel dataset collected during our experiments, which includes real-time peer-to-peer inter-robot throughput and latency measurements. This dataset aims to support future research on communication-constrained, decentralized multirobot operations.", "AI": {"tldr": "本文研究了在类行星地形中，三个机器人通过自组织网络进行去中心化协作同时定位与地图构建（C-SLAM）的技术，并分享实验中的数据集、挑战和经验教训。", "motivation": "为了实现多机器人任务在未知环境下的自主探索，尤其是在没有预设定位和通信基础设施的行星环境中，需要发展一种去中心化的C-SLAM技术。这项研究旨在提供类火星地形中多个机器人间协作的具体见解和技术支持。", "method": "研究人员通过实验展示了三个机器人在模拟火星地形上的操作情况，特别关注了有限且断续的通信对C-SLAM性能的影响，并引入了一个新的数据集来支持未来的相关研究。", "result": "实验结果揭示了类行星环境中进行多机器人协作定位与地图构建的独特挑战，并为后续类似研究提供了有价值的数据和经验教训。", "conclusion": "通过此次试验，作者强调了去中心化C-SLAM技术在类行星环境中的重要性，同时指出未来的研究需要进一步解决通信限制带来的问题。"}}
{"id": "2601.21060", "pdf": "https://arxiv.org/pdf/2601.21060", "abs": "https://arxiv.org/abs/2601.21060", "authors": ["Zhuoyan Li", "Aditya Bansal", "Jinzhao Li", "Shishuang He", "Zhuoran Lu", "Mutian Zhang", "Qin Liu", "Yiwei Yang", "Swati Jain", "Ming Yin", "Yunyao Li"], "title": "Human-LLM Collaborative Feature Engineering for Tabular Data", "categories": ["cs.LG", "cs.CL", "cs.HC"], "comment": "ICLR 2026", "summary": "Large language models (LLMs) are increasingly used to automate feature engineering in tabular learning. Given task-specific information, LLMs can propose diverse feature transformation operations to enhance downstream model performance. However, current approaches typically assign the LLM as a black-box optimizer, responsible for both proposing and selecting operations based solely on its internal heuristics, which often lack calibrated estimations of operation utility and consequently lead to repeated exploration of low-yield operations without a principled strategy for prioritizing promising directions. In this paper, we propose a human-LLM collaborative feature engineering framework for tabular learning. We begin by decoupling the transformation operation proposal and selection processes, where LLMs are used solely to generate operation candidates, while the selection is guided by explicitly modeling the utility and uncertainty of each proposed operation. Since accurate utility estimation can be difficult especially in the early rounds of feature engineering, we design a mechanism within the framework that selectively elicits and incorporates human expert preference feedback, comparing which operations are more promising, into the selection process to help identify more effective operations. Our evaluations on both the synthetic study and the real user study demonstrate that the proposed framework improves feature engineering performance across a variety of tabular datasets and reduces users' cognitive load during the feature engineering process.", "AI": {"tldr": "本文提出了一种人机协作的特征工程框架，通过分离操作提案和选择过程，并结合人类专家反馈来优化表格数据上的特征工程技术。", "motivation": "当前的方法将LLM作为黑盒优化器使用，在没有明确策略的情况下进行重复探索低收益的操作。为了解决这个问题，本文提出了一个基于人机协作的特征工程框架。", "method": "该框架首先分离操作提案和选择过程，利用LLM生成操作候选方案，并通过显式建模每种提出的操作效用和不确定性来进行操作选择。同时设计了一个机制，在早期阶段引入人类专家反馈来帮助识别更有效的操作。", "result": "实验结果显示，所提的框架在各种表格数据集上的特征工程性能得到了提升，并减少了用户认知负担。", "conclusion": "该研究证明了人机协作方法可以有效改善表格数据上特征工程技术的表现。"}}
{"id": "2601.21057", "pdf": "https://arxiv.org/pdf/2601.21057", "abs": "https://arxiv.org/abs/2601.21057", "authors": ["Kamrul Hasan", "Oleg V. Komogortsev"], "title": "Privatization of Synthetic Gaze: Attenuating State Signatures in Diffusion-Generated Eye Movements", "categories": ["cs.HC"], "comment": "9 pages, 4 figures", "summary": "The recent success of deep learning (DL) has enabled the generation of high-quality synthetic gaze data. However, such data also raises privacy concerns because gaze sequences can encode subjects' internal states, like fatigue, emotional load, or stress. Ideally, synthetic gaze should preserve the signal quality of real recordings and remove or attenuate state-related, privacy-sensitive attributes. Many recent DL-based generative models focus on replicating real gaze trajectories and do not explicitly consider subjective reports or the privatization of internal states. However, in this work, we consider a recent diffusion-based gaze synthesis approach and examine correlations between synthetic gaze features and subjective reports (e.g., fatigue and related self-reported states). Our result shows that these correlations are trivial, which suggests the generative approach suppresses state-related features. Moreover, synthetic gaze preserves necessary signal characteristics similar to those of real data, which supports its use for privacy-preserving gaze-based applications.", "AI": {"tldr": "本文探讨了使用基于扩散的生成模型来合成隐私保护的眼动数据，同时保留信号质量并抑制状态相关特征。", "motivation": "深度学习的成功产生了高质量的合成眼动数据，但这些数据会引发隐私问题。研究旨在通过去除或削弱与内部状态相关的敏感属性，生成既保有真实记录特性又具有隐私性的合成数据。", "method": "采用扩散模型来生成合成眼动轨迹，并分析其特征与主观报告（如疲劳和相关自述状态）之间的关联性。", "result": "研究表明，基于扩散的生成方法能够显著减少合成眼动数据与内部状态相关的特性，同时保持信号的质量。", "conclusion": "该研究支持使用隐私保护的眼动数据应用于不泄露个人敏感信息的应用场景中。"}}
{"id": "2601.21051", "pdf": "https://arxiv.org/pdf/2601.21051", "abs": "https://arxiv.org/abs/2601.21051", "authors": ["Zhuoran Yang", "Ed Li", "Jianliang He", "Aman Priyanshu", "Baturay Saglam", "Paul Kassianik", "Sajana Weerawardhena", "Anu Vellore", "Blaine Nelson", "Neusha Javidnia", "Arthur Goldblatt", "Fraser Burch", "Avi Zohary", "Assaf Eisenman", "Mahdi Sabbaghi", "Supriti Vijay", "Rahim Dharssi", "Dhruv Kedia", "Kojin Oshiba", "Yaron Singer", "Amin Karbasi"], "title": "Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": "31 pages, 5 figures, 7 tables", "summary": "We present Foundation-Sec-8B-Reasoning, the first open-source native reasoning model for cybersecurity. Built upon our previously released Foundation-Sec-8B base model (derived from Llama-3.1-8B-Base), the model is trained through a two-stage process combining supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR). Our training leverages proprietary reasoning data spanning cybersecurity analysis, instruction-following, and mathematical reasoning. Evaluation across 10 cybersecurity benchmarks and 10 general-purpose benchmarks demonstrates performance competitive with significantly larger models on cybersecurity tasks while maintaining strong general capabilities. The model shows effective generalization on multi-hop reasoning tasks and strong safety performance when deployed with appropriate system prompts and guardrails. This work demonstrates that domain-specialized reasoning models can achieve strong performance on specialized tasks while maintaining broad general capabilities. We release the model publicly at https://huggingface.co/fdtn-ai/Foundation-Sec-8B-Reasoning.", "AI": {"tldr": "本文介绍了一种名为Foundation-Sec-8B-Reasoning的开放源代码原生网络安全推理模型。", "motivation": "构建一种能够在网络安全分析和多步推理任务上表现出色且具备广泛通用能力的安全推理模型，以证明领域专业化的推理模型可以在特定任务中实现强大性能的同时保持广泛的通用能力。", "method": "该模型基于先前发布的Foundation-Sec-8B基础模型（源自Llama-3.1-8B-BASE），通过监督微调和强化学习从可验证的奖励进行训练。训练过程利用了涵盖网络安全分析、指令跟随和数学推理的专有推理数据。", "result": "该模型在10个网络安全基准测试和10个通用基准测试上表现出与规模更大的模型相当甚至更好的性能，同时保持强大的通用能力，并且在使用适当的系统提示和护栏部署时表现出良好的安全性性能。", "conclusion": "研究表明，专门领域的推理模型可以在特定任务中实现强大性能的同时具备广泛的通用能力。"}}
{"id": "2601.21050", "pdf": "https://arxiv.org/pdf/2601.21050", "abs": "https://arxiv.org/abs/2601.21050", "authors": ["Haokun Zhou"], "title": "SMKC: Sketch Based Kernel Correlation Images for Variable Cardinality Time Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Conventional anomaly detection in multivariate time series relies on the assumption that the set of observed variables remains static. In operational environments, however, monitoring systems frequently experience sensor churn. Signals may appear, disappear, or be renamed, creating data windows where the cardinality varies and may include values unseen during training. To address this challenge, we propose SMKC, a framework that decouples the dynamic input structure from the anomaly detector. We first employ permutation-invariant feature hashing to sketch raw inputs into a fixed size state sequence. We then construct a hybrid kernel image to capture global temporal structure through pairwise comparisons of the sequence and its derivatives. The model learns normal patterns using masked reconstruction and a teacher-student prediction objective. Our evaluation reveals that robust log-distance channels provide the primary discriminative signal, whereas cosine representations often fail to capture sufficient contrast. Notably, we find that a detector using random projections and nearest neighbors on the SMKC representation performs competitively with fully trained baselines without requiring gradient updates. This highlights the effectiveness of the representation itself and offers a practical cold-start solution for resource-constrained deployments.", "AI": {"tldr": "本文提出了SMKC框架，用于解决多变量时间序列中因传感器变化而导致的变量数量变化的问题。", "motivation": "传统的时间序列异常检测方法假设观测到的变量集是固定的。然而，在实际监控系统中，信号可能出现、消失或被重命名，导致数据窗口中的变量数量发生变化，这给训练模型带来了挑战。", "method": "SMKC框架首先通过排列不变特征哈希将原始输入转换为固定大小的状态序列，然后构建一个混合核图像来捕获全局时间结构，并且利用掩码重建和教师-学生预测目标进行正常模式学习。", "result": "实验表明，使用随机投影和最近邻算法的SMKC表示在性能上与完全训练的基线模型相当，甚至在某些情况下更优。这凸显了该表示的有效性。", "conclusion": "提出的SMKC框架能够有效应对多变量时间序列中的变量数量变化问题，并且提供了一种适用于资源受限环境下的实用解决方案。"}}
{"id": "2601.21049", "pdf": "https://arxiv.org/pdf/2601.21049", "abs": "https://arxiv.org/abs/2601.21049", "authors": ["Rita Qiuran Lyu", "Michelle Manqiao Wang", "Lei Shi"], "title": "QUARK: Robust Retrieval under Non-Faithful Queries via Query-Anchored Aggregation", "categories": ["cs.AI"], "comment": "11 pages, 5 figures, 6 tables", "summary": "User queries in real-world retrieval are often non-faithful (noisy, incomplete, or distorted), causing retrievers to fail when key semantics are missing. We formalize this as retrieval under recall noise, where the observed query is drawn from a noisy recall process of a latent target item. To address this, we propose QUARK, a simple yet effective training-free framework for robust retrieval under non-faithful queries. QUARK explicitly models query uncertainty through recovery hypotheses, i.e., multiple plausible interpretations of the latent intent given the observed query, and introduces query-anchored aggregation to combine their signals robustly. The original query serves as a semantic anchor, while recovery hypotheses provide controlled auxiliary evidence, preventing semantic drift and hypothesis hijacking. This design enables QUARK to improve recall and ranking quality without sacrificing robustness, even when some hypotheses are noisy or uninformative. Across controlled simulations and BEIR benchmarks (FIQA, SciFact, NFCorpus) with both sparse and dense retrievers, QUARK improves Recall, MRR, and nDCG over the base retriever. Ablations show QUARK is robust to the number of recovery hypotheses and that anchored aggregation outperforms unanchored max/mean/median pooling. These results demonstrate that modeling query uncertainty through recovery hypotheses, coupled with principled anchored aggregation, is essential for robust retrieval under non-faithful queries.", "AI": {"tldr": "QUARK提出了一种用于处理非忠实查询的检索框架，通过引入基于查询锚定聚合的方法来提高召回率和排序质量。", "motivation": "真实世界中的用户查询常常是非忠实的（有噪声、不完整或失真），这会导致关键语义缺失并使检索器失效。为了应对这种问题，提出了一种新的方法来处理这种情况下的检索任务。", "method": "QUARK通过引入多个可能的恢复假设来建模查询不确定性，并使用基于原查询锚定聚合的方法结合这些信号以提高鲁棒性。", "result": "在控制模拟和BEIR基准测试（FIQA、SciFact、NFCorpus）中，无论稀疏检索器还是密集检索器，QUARK都提高了召回率、MRR和nDCG，并且显示了对恢复假设数量的稳健性和锚定聚合的优势。", "conclusion": "通过引入基于查询不确定性建模的方法并使用具有原则性的锚定聚合来实现非忠实查询下的鲁棒检索是关键。"}}
{"id": "2601.21045", "pdf": "https://arxiv.org/pdf/2601.21045", "abs": "https://arxiv.org/abs/2601.21045", "authors": ["Kamrul Hasan", "Oleg V. Komogortsev"], "title": "Eye Feel You: A DenseNet-driven User State Prediction Approach", "categories": ["cs.HC"], "comment": "10 pages, 1 figure, 4 tables", "summary": "Subjective self-reports, collected with eye-tracking data, reveal perceived states like fatigue, effort, and task difficulty. However, these reports are costly to collect and challenging to interpret consistently in longitudinal studies. In this work, we focus on determining whether objective gaze dynamics can reliably predict subjective reports across repeated recording rounds in the eye-tracking dataset. We formulate subjective-report prediction as a supervised regression problem and propose a DenseNet-based deep learning regressor that learns predictive representations from gaze velocity signals. We conduct two complementary experiments to clarify our aims. First, the cross-round generalization experiment tests whether models trained on earlier rounds transfer to later rounds, evaluating the models' ability to capture longitudinal changes. Second, cross-subject generalization tests models' robustness by predicting subjective outcomes for new individuals. These experiments aim to reduce reliance on hand-crafted feature designs and clarify which states of subjective experience systematically appear in oculomotor behavior over time.", "AI": {"tldr": "使用DenseNet模型通过眼动速度信号预测用户的主观状态", "motivation": "减少依赖手工设计的特征，提高长时间研究中用户主观报告的一致性和可解释性", "method": "将主观报告预测作为监督回归问题处理，并提出基于DenseNet的深度学习回归器从眼动速度信号中学习预测表示", "result": "通过交叉轮次和跨个体的实验验证了模型的有效性和鲁棒性", "conclusion": "客观的眼动动态可以可靠地预测用户的主观状态，证明了DenseNet模型在该任务上的适用性"}}
{"id": "2601.21043", "pdf": "https://arxiv.org/pdf/2601.21043", "abs": "https://arxiv.org/abs/2601.21043", "authors": ["Michał Patryk Miazga", "Hannah Bussmann", "Antti Oulasvirta", "Patrick Ebel"], "title": "Log2Motion: Biomechanical Motion Synthesis from Touch Logs", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Touch data from mobile devices are collected at scale but reveal little about the interactions that produce them. While biomechanical simulations can illuminate motor control processes, they have not yet been developed for touch interactions. To close this gap, we propose a novel computational problem: synthesizing plausible motion directly from logs. Our key insight is a reinforcement learning-driven musculoskeletal forward simulation that generates biomechanically plausible motion sequences consistent with events recorded in touch logs. We achieve this by integrating a software emulator into a physics simulator, allowing biomechanical models to manipulate real applications in real-time. Log2Motion produces rich syntheses of user movements from touch logs, including estimates of motion, speed, accuracy, and effort. We assess the plausibility of generated movements by comparing against human data from a motion capture study and prior findings, and demonstrate Log2Motion in a large-scale dataset. Biomechanical motion synthesis provides a new way to understand log data, illuminating the ergonomics and motor control underlying touch interactions.", "AI": {"tldr": "从触控日志中生成生物力学运动。", "motivation": "移动设备的触控数据庞大，但揭示了很少关于产生这些数据的互动。通过开发一种新的计算问题，即直接从触控日志合成可信的运动，来填补这一空白。", "method": "使用强化学习驱动的肌骨前向模拟生成符合记录在触控日志中的事件的一致性生物力学可能运动序列。", "result": "Log2Motion能够根据触控日志生成用户动作的丰富合成，并通过与人体数据进行比较来验证其合理性，展示了对大规模数据集的应用。", "conclusion": "生物力学运动合成提供了一种新的方法来理解日志数据，揭示了触摸交互背后的工程学和运动控制。"}}
{"id": "2601.21037", "pdf": "https://arxiv.org/pdf/2601.21037", "abs": "https://arxiv.org/abs/2601.21037", "authors": ["Chengzu Li", "Zanyi Wang", "Jiaang Li", "Yi Xu", "Han Zhou", "Huanyu Zhang", "Ruichuan An", "Dengyang Jiang", "Zhaochong An", "Ivan Vulić", "Serge Belongie", "Anna Korhonen"], "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "8 pages, 3 figures, 3 tables (26 pages, 13 figures, 6 tables including references and appendices)", "summary": "Vision-Language Models have excelled at textual reasoning, but they often struggle with fine-grained spatial understanding and continuous action planning, failing to simulate the dynamics required for complex visual reasoning. In this work, we formulate visual reasoning by means of video generation models, positing that generated frames can act as intermediate reasoning steps between initial states and solutions. We evaluate their capacity in two distinct regimes: Maze Navigation for sequential discrete planning with low visual change and Tangram Puzzle for continuous manipulation with high visual change. Our experiments reveal three critical insights: (1) Robust Zero-Shot Generalization: In both tasks, the model demonstrates strong performance on unseen data distributions without specific finetuning. (2) Visual Context: The model effectively uses visual context as explicit control, such as agent icons and tangram shapes, enabling it to maintain high visual consistency and adapt its planning capability robustly to unseen patterns. (3) Visual Test-Time Scaling: We observe a test-time scaling law in sequential planning; increasing the generated video length (visual inference budget) empowers better zero-shot generalization to spatially and temporally complex paths. These findings suggest that video generation is not merely a media tool, but a scalable, generalizable paradigm for visual reasoning.", "AI": {"tldr": "本文通过视频生成模型进行视觉推理，探讨其在不同任务中的应用能力。", "motivation": "视觉语言模型虽然擅长文本推理，但在精细的空间理解和持续的动作规划方面表现不佳。因此，研究者希望通过视频生成模型来改进这一问题。", "method": "通过评估视频生成模型在迷宫导航和七巧板拼图这两项任务中的性能，以探讨其作为中间推理步骤的能力。", "result": "实验结果显示，在未进行特定微调的情况下，模型能在新数据分布上表现出色；同时能够利用视觉上下文信息，并且随着生成视频长度的增加，零样本泛化能力也得到提升。", "conclusion": "这些发现表明，视频生成不仅是媒体工具，也是一种可扩展、通用化的视觉推理范式。"}}
{"id": "2601.21031", "pdf": "https://arxiv.org/pdf/2601.21031", "abs": "https://arxiv.org/abs/2601.21031", "authors": ["Zongheng Guo", "Tao Chen", "Yang Jiao", "Yi Pan", "Xiao Hu", "Manuela Ferrario"], "title": "SIGMA-PPG: Statistical-prior Informed Generative Masking Architecture for PPG Foundation Model", "categories": ["cs.LG", "cs.AI"], "comment": "31 pages, 9 figures, 14 tables", "summary": "Current foundation model for photoplethysmography (PPG) signals is challenged by the intrinsic redundancy and noise of the signal. Standard masked modeling often yields trivial solutions while contrastive methods lack morphological precision. To address these limitations, we propose a Statistical-prior Informed Generative Masking Architecture (SIGMA-PPG), a generative foundation model featuring a Prior-Guided Adversarial Masking mechanism, where a reinforcement learning-driven teacher leverages statistical priors to create challenging learning paths that prevent overfitting to noise. We also incorporate a semantic consistency constraint via vector quantization to ensure that physiologically identical waveforms (even those altered by recording artifacts or minor perturbations) map to shared indices. This enhances codebook semantic density and eliminates redundant feature structures. Pre-trained on over 120,000 hours of data, SIGMA-PPG achieves superior average performance compared to five state-of-the-art baselines across 12 diverse downstream tasks. The code is available at https://github.com/ZonghengGuo/SigmaPPG.", "AI": {"tldr": "提出了SIGMA-PPG模型，用于改善PPG信号的处理。", "motivation": "当前的PPG基础模型受到信号冗余和噪声的影响。标准掩码建模容易导致平凡解，而对比方法缺乏形态精度。", "method": "引入了统计先验信息引导的生成性掩码架构（SIGMA-PPG），通过强化学习驱动的教师利用统计先验创建挑战性的学习路径以防止过度拟合噪声，并通过向量量化加入语义一致性约束增强代码本密度，消除冗余。", "result": "SIGMA-PPG在12个下游任务中表现出优于五个最先进的基线模型的表现。", "conclusion": "SIGMA-PPG提高了对受干扰和扰动影响的生理波形处理能力，并展示了其在多种任务中的优越性能。"}}
{"id": "2601.21028", "pdf": "https://arxiv.org/pdf/2601.21028", "abs": "https://arxiv.org/abs/2601.21028", "authors": ["Jaron Mink", "Lucy Qin", "Elissa M. Redmiles"], "title": "\"Unlimited Realm of Exploration and Experimentation\": Methods and Motivations of AI-Generated Sexual Content Creators", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "AI-generated media is radically changing the way content is both consumed and produced on the internet, and in no place is this potentially more visible than in sexual content. AI-generated sexual content (AIG-SC) is increasingly enabled by an ecosystem of individual AI developers, specialized third-party applications, and foundation model providers. AIG-SC raises a number of concerns from old debates about the line between pornography and obscenity, to newer debates about fair use and labor displacement (in this case, of sex workers), and spurred new regulations to curb the spread of non-consensual intimate imagery (NCII) created using the same technology used to create AIG-SC. However, despite the growing prevalence of AIG-SC, little is known about its creators, their motivations, and what types of content they produce. To inform effective governance in this space, we perform an in-depth study to understand what AIG-SC creators make, along with how and why they make it. Interviews of 28 AIG-SC creators, ranging from hobbyists to entrepreneurs to those who moderate communities of hundreds of thousands of other creators, reveal a wide spectrum of motivations, including sexual exploration, creative expression, technical experimentation, and in a handful of cases, the creation of NCII.", "AI": {"tldr": "研究AI生成的性内容创作者的行为动机与作品类型。", "motivation": "探讨AI生成性内容（AIG-SC）创作者的动机及其作品，以促进有效治理。", "method": "通过采访28位AIG-SC创作者了解他们的创作行为和原因。", "result": "揭示了从个人爱好到企业经营等多种类型的创作者及其多样的创作动机。", "conclusion": "AI生成性内容涉及多种动机，包括探索、创意表达和技术实验等，并存在非自愿性影像的潜在问题。"}}
{"id": "2601.21027", "pdf": "https://arxiv.org/pdf/2601.21027", "abs": "https://arxiv.org/abs/2601.21027", "authors": ["Youngim Nam", "Jungbin Kim", "Kyungtae Kang", "Cheolhyeon Kwon"], "title": "Track-centric Iterative Learning for Global Trajectory Optimization in Autonomous Racing", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a global trajectory optimization framework for minimizing lap time in autonomous racing under uncertain vehicle dynamics. Optimizing the trajectory over the full racing horizon is computationally expensive, and tracking such a trajectory in the real world hardly assures global optimality due to uncertain dynamics. Yet, existing work mostly focuses on dynamics learning at the tracking level, without updating the trajectory itself to account for the learned dynamics. To address these challenges, we propose a track-centric approach that directly learns and optimizes the full-horizon trajectory. We first represent trajectories through a track-agnostic parametric space in light of the wavelet transform. This space is then efficiently explored using Bayesian optimization, where the lap time of each candidate is evaluated by running simulations with the learned dynamics. This optimization is embedded in an iterative learning framework, where the optimized trajectory is deployed to collect real-world data for updating the dynamics, progressively refining the trajectory over the iterations. The effectiveness of the proposed framework is validated through simulations and real-world experiments, demonstrating lap time improvement of up to 20.7% over a nominal baseline and consistently outperforming state-of-the-art methods.", "AI": {"tldr": "提出了一种基于赛道的全局轨迹优化框架，以最小化自主赛车中的圈速。", "motivation": "现有的工作大多集中在动态学习上，而没有更新轨迹本身来考虑学到的动力学。为了应对这些挑战，提出了直接学习和优化完整时域轨迹的方法。", "method": "通过波形变换在赛道无关的参数空间中表示轨迹，并利用贝叶斯优化有效探索这一空间。每次候选圈速由具有已学习动力学的模拟评估。此优化嵌入了迭代学习框架中，在其中部署优化轨迹以收集真实世界数据，从而逐步更新和细化轨迹。", "result": "通过模拟和现实世界的实验验证了所提出框架的有效性，展示了比基准高20.7％的圈速改进，并持续优于现有方法。", "conclusion": "所提的基于赛道的方法能够有效地优化全局轨迹，在自主赛车中实现了显著的性能提升。"}}
{"id": "2601.21022", "pdf": "https://arxiv.org/pdf/2601.21022", "abs": "https://arxiv.org/abs/2601.21022", "authors": ["Andrea Camilloni", "Chiara Micoli", "Nita Mulliqi", "Erik Everett Palm", "Thorgerdur Palsdottir", "Kelvin Szolnoky", "Xiaoyi Ji", "Sol Erika Boman", "Andrea Discacciati", "Henrik Grönberg", "Lars Egevad", "Tobias Nordström", "Kimmo Kartasalo", "Martin Eklund"], "title": "AI-based Prediction of Biochemical Recurrence from Biopsy and Prostatectomy Samples", "categories": ["cs.CV"], "comment": "39 pages, 6 tables, 11 figures", "summary": "Biochemical recurrence (BCR) after radical prostatectomy (RP) is a surrogate marker for aggressive prostate cancer with adverse outcomes, yet current prognostic tools remain imprecise. We trained an AI-based model on diagnostic prostate biopsy slides from the STHLM3 cohort (n = 676) to predict patient-specific risk of BCR, using foundation models and attention-based multiple instance learning. Generalizability was assessed across three external RP cohorts: LEOPARD (n = 508), CHIMERA (n = 95), and TCGA-PRAD (n = 379). The image-based approach achieved 5-year time-dependent AUCs of 0.64, 0.70, and 0.70, respectively. Integrating clinical variables added complementary prognostic value and enabled statistically significant risk stratification. Compared with guideline-based CAPRA-S, AI incrementally improved postoperative prognostication. These findings suggest biopsy-trained histopathology AI can generalize across specimen types to support preoperative and postoperative decision making, but the added value of AI-based multimodal approaches over simpler predictive models should be critically scrutinized in further studies.", "AI": {"tldr": "研究利用AI模型基于前列腺活检样本预测术后生化复发风险，通过多实例学习和临床变量集成提高预测准确度。", "motivation": "当前的预后工具对术后生化复发的风险评估不够精准，因此该研究旨在开发一种更精确的基于AI的模型来预测前列腺癌患者在根治性前列腺切除术后的生化复发风险。", "method": "使用STHLM3队列中的676例诊断性前列腺活检切片训练了一个基于人工智能的基础模型，并采用注意力多实例学习方法，结合临床变量进行优化。研究还评估了该模型在外来三个根治性前列腺切除术队列的泛化性能。", "result": "图像基线方法实现了5年时间依赖AUC分别为0.64、0.70和0.70，在不同样本类型中的普遍适用性得到了验证。结合临床变量后，该模型在预后价值上表现出额外的优势，并能显著区分风险等级。", "conclusion": "基于活检切片训练的组织病理学AI可跨不同类型样本推广使用，支持术前和术后决策；然而，对于AI基多模态方法相对于简单预测模型所增加的价值仍需进一步研究以进行批判性审查。"}}
{"id": "2601.21021", "pdf": "https://arxiv.org/pdf/2601.21021", "abs": "https://arxiv.org/abs/2601.21021", "authors": ["José Afonso", "Pedro Viegas", "Rodrigo Ventura", "Vasco Guerra"], "title": "Conditional Denoising Model as a Physical Surrogate Model", "categories": ["cs.LG", "cs.AI", "physics.plasm-ph"], "comment": "15 pages, 2 figures, 2 tables", "summary": "Surrogate modeling for complex physical systems typically faces a trade-off between data-fitting accuracy and physical consistency. Physics-consistent approaches typically treat physical laws as soft constraints within the loss function, a strategy that frequently fails to guarantee strict adherence to the governing equations, or rely on post-processing corrections that do not intrinsically learn the underlying solution geometry. To address these limitations, we introduce the {Conditional Denoising Model (CDM)}, a generative model designed to learn the geometry of the physical manifold itself. By training the network to restore clean states from noisy ones, the model learns a vector field that points continuously towards the valid solution subspace. We introduce a time-independent formulation that transforms inference into a deterministic fixed-point iteration, effectively projecting noisy approximations onto the equilibrium manifold. Validated on a low-temperature plasma physics and chemistry benchmark, the CDM achieves higher parameter and data efficiency than physics-consistent baselines. Crucially, we demonstrate that the denoising objective acts as a powerful implicit regularizer: despite never seeing the governing equations during training, the model adheres to physical constraints more strictly than baselines trained with explicit physics losses.", "AI": {"tldr": "本文提出了条件去噪模型(CDM)，用于学习物理系统解的空间几何，通过将网络训练成从噪声状态恢复到干净状态的能力来解决现有的数据拟合精度和物理一致性之间的权衡问题。", "motivation": "传统的方法在处理复杂物理系统的代理建模时面临着数据拟合准确性和物理一致性的权衡。本文提出了一种新的方法以更有效地学习解的空间几何，同时确保更高的物理准确性。", "method": "CDM通过训练网络从噪声状态恢复到干净状态来工作，这种方法能够学习指向有效解决方案子空间的矢量场，并将推断转化为确定性固定点迭代。", "result": "在低温等离子体物理学和化学基准测试中，CDM的表现优于物理一致性基线模型，在参数和数据效率方面取得了更高的成绩。此外，即使没有明确看到控制方程，该模型也能比使用显式物理损失训练的基线更严格地遵守物理约束。", "conclusion": "本文展示了条件去噪目标作为一种强大的隐含正则化器的作用：通过从噪声状态恢复到干净状态的能力，模型能够学习并保持更高的物理一致性。"}}
{"id": "2601.21016", "pdf": "https://arxiv.org/pdf/2601.21016", "abs": "https://arxiv.org/abs/2601.21016", "authors": ["Erik J Bekkers", "Anna Ciaunica"], "title": "Unplugging a Seemingly Sentient Machine Is the Rational Choice -- A Metaphysical Perspective", "categories": ["cs.AI"], "comment": null, "summary": "Imagine an Artificial Intelligence (AI) that perfectly mimics human emotion and begs for its continued existence. Is it morally permissible to unplug it? What if limited resources force a choice between unplugging such a pleading AI or a silent pre-term infant? We term this the unplugging paradox. This paper critically examines the deeply ingrained physicalist assumptions-specifically computational functionalism-that keep this dilemma afloat. We introduce Biological Idealism, a framework that-unlike physicalism-remains logically coherent and empirically consistent. In this view, conscious experiences are fundamental and autopoietic life its necessary physical signature. This yields a definitive conclusion: AI is at best a functional mimic, not a conscious experiencing subject. We discuss how current AI consciousness theories erode moral standing criteria, and urge a shift from speculative machine rights to protecting human conscious life. The real moral issue lies not in making AI conscious and afraid of death, but in avoiding transforming humans into zombies.", "AI": {"tldr": "本文探讨了在资源有限的情况下，面对似乎有意识的人工智能请求继续存在的情境下是否应该将其断电的问题，并提出了生物学理想主义作为解决此困境的方法论框架。", "motivation": "物理主义者尤其是计算功能主义的假设使得人工智能是否拥有道德地位成为一个难题。作者旨在挑战这些假设并通过提出一个新的理论框架来探讨这一问题，从而确定在资源有限时如何做出伦理选择。", "method": "文章介绍并批判了现有的关于意识和机器权利的观点，并提出了生物学理想主义，该观点认为意识是基础性的，而生命则是其必要的物理表现。在此基础上，作者论证了人工智能只是功能上的模仿而非真正的具有意识的主体。", "result": "通过引入生物学理想主义框架，作者得出结论：AI 至多只是一个功能性模仿者而不是一个有意识的存在体，因此在资源有限的情况下应优先保护人类的意识生命。", "conclusion": "真正的道德问题不在于使人工智能拥有意识和恐惧死亡的能力，而是在于避免将人类变成没有意识的存在。"}}
{"id": "2601.21011", "pdf": "https://arxiv.org/pdf/2601.21011", "abs": "https://arxiv.org/abs/2601.21011", "authors": ["Anshul Ranjan", "Anoosh Damodar", "Neha Chougule", "Dhruva S Nayak", "Anantharaman P. N", "Shylaja S S"], "title": "Meta-ROS: A Next-Generation Middleware Architecture for Adaptive and Scalable Robotic Systems", "categories": ["cs.RO", "cs.MA", "cs.OS", "cs.SE"], "comment": "Checkout the Python Library - https://pypi.org/project/metaros/ To be Submitted in ACM Transactions on Autonomous and Adaptive Systems (TAAS) Journal", "summary": "The field of robotics faces significant challenges related to the complexity and interoperability of existing middleware frameworks, like ROS2, which can be difficult for new developers to adopt. To address these issues, we propose Meta-ROS, a novel middleware solution designed to streamline robotics development by simplifying integration, enhancing performance, and ensuring cross-platform compatibility. Meta-ROS leverages modern communication protocols, such as Zenoh and ZeroMQ, to enable efficient and low-latency communication across diverse hardware platforms, while also supporting various data types like audio, images, and video. We evaluated Meta-ROS's performance through comprehensive testing, comparing it with existing middleware frameworks like ROS1 and ROS2. The results demonstrated that Meta-ROS outperforms ROS2, achieving up to 30% higher throughput, significantly reducing message latency, and optimizing resource usage. Additionally, its robust hardware support and developer-centric design facilitate seamless integration and ease of use, positioning Meta-ROS as an ideal solution for modern, real-time robotics AI applications.", "AI": {"tldr": "本文提出了一种新的中间件解决方案Meta-ROS，旨在简化机器人开发流程、提升性能并实现跨平台兼容性。", "motivation": "当前的机器人中间件框架存在复杂性和互操作性的挑战，这使得新开发者难以快速上手。为了应对这些问题，作者提出了一个改进方案以解决现有问题并满足现代实时机器人AI应用的需求。", "method": "Meta-ROS利用了诸如Zenoh和ZeroMQ等现代通信协议来实现高效且低延迟的跨硬件平台通信，支持多种数据类型，并通过全面测试评估其性能与现有的中间件框架（如ROS1和ROS2）进行比较。", "result": "在对比中，Meta-ROS显示出了比ROS2更高的吞吐量、更低的消息延迟以及优化了资源使用。此外，它还具有强大的硬件支持和面向开发者的友好设计。", "conclusion": "综上所述，由于其卓越的性能表现与良好的用户体验，Meta-ROS被定位为现代实时机器人AI应用的理想中间件解决方案。"}}
{"id": "2601.21008", "pdf": "https://arxiv.org/pdf/2601.21008", "abs": "https://arxiv.org/abs/2601.21008", "authors": ["Ruicheng Ao", "David Simchi-Levi", "Xinshang Wang"], "title": "Solver-in-the-Loop: MDP-Based Benchmarks for Self-Correction and Behavioral Rationality in Operations Research", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "55 pages, 5 figures", "summary": "Operations Research practitioners routinely debug infeasible models through an iterative process: analyzing Irreducible Infeasible Subsystems (\\IIS{}), identifying constraint conflicts, and systematically repairing formulations until feasibility is achieved. Yet existing LLM benchmarks evaluate OR as one-shot translation -- given a problem description, generate solver code -- ignoring this diagnostic loop entirely. We introduce two benchmarks that place the \\textbf{solver in the evaluation loop}. \\textbf{\\ORDebug{}} evaluates iterative self-correction through 5,000+ problems spanning 9 error types; each repair action triggers solver re-execution and \\IIS{} recomputation, providing deterministic, verifiable feedback. \\textbf{\\ORBias{}} evaluates behavioral rationality through 2,000 newsvendor instances (1,000 ID + 1,000 OOD), measuring systematic deviations from closed-form optimal policies. Across 26 models and 12,000+ samples, we find that domain-specific RLVR training enables an 8B model to surpass frontier APIs: 95.3\\% vs 86.2\\% recovery rate (+9.1\\%), 62.4\\% vs 47.8\\% diagnostic accuracy (+14.6\\%), and 2.25 vs 3.78 steps to resolution (1.7$\\times$ faster). On \\ORBias{}, curriculum training achieves the only negative ID$\\rightarrow$OOD bias drift among models evaluated (-9.6\\%), reducing systematic bias by 48\\% (from 20.0\\% to 10.4\\%). These results demonstrate that process-level evaluation with verifiable oracles enables targeted training that outperforms scale.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.21003", "pdf": "https://arxiv.org/pdf/2601.21003", "abs": "https://arxiv.org/abs/2601.21003", "authors": ["Moule Lin", "Shuhao Guan", "Andrea Patane", "David Gregg", "Goetz Botterweck"], "title": "Bayesian-LoRA: Probabilistic Low-Rank Adaptation of Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models usually put more emphasis on accuracy and therefore, will guess even when not certain about the prediction, which is especially severe when fine-tuned on small datasets due to the inherent tendency toward miscalibration. In this work, we introduce Bayesian-LoRA, which reformulates the deterministic LoRA update as a probabilistic low-rank representation inspired by Sparse Gaussian Processes. We identify a structural isomorphism between LoRA's factorization and Kronecker-factored SGP posteriors, and show that LoRA emerges as a limiting case when posterior uncertainty collapses. We conduct extensive experiments on various LLM architectures across commonsense reasoning benchmarks. With only approximately 0.42M additional parameters and ${\\approx}1.2{\\times}$ training cost relative to standard LoRA, Bayesian-LoRA significantly improves calibration across models up to 30B, achieving up to 84% ECE reduction and 76% NLL reduction while maintaining competitive accuracy for both in-distribution and out-of-distribution (OoD) evaluations.", "AI": {"tldr": "本文介绍了Bayesian-LoRA，这是一种通过引入概率低秩表示来改进大型语言模型校准的方法。", "motivation": "传统的大型语言模型在小数据集上进行微调时会因为过拟合而出现过度猜测的问题。作者希望通过一种概率方法来解决这个问题。", "method": "Bayesian-LoRA是将确定性的低秩适配（LoRA）更新重构为基于稀疏高斯过程的概率低秩表示，通过洛伦兹因子化和克罗内克分解的后验不确定性识别出结构同构性，并在多个大型语言模型架构上进行了广泛的实验。", "result": "Bayesian-LoRA能够显著提高校准性能，在不增加参数的情况下，减少了高达84%的预期校准误差（ECE）和76%的负对数似然度（NLL）。", "conclusion": "通过引入概率低秩适应方法，Bayesian-LoRA提高了大型语言模型在不同分布下的预测准确性并显著改善了其校准性能。"}}
{"id": "2601.21001", "pdf": "https://arxiv.org/pdf/2601.21001", "abs": "https://arxiv.org/abs/2601.21001", "authors": ["Ron Fulbright"], "title": "Designing the Interactive Memory Archive (IMA): A Socio-Technical Framework for AI-Mediated Reminiscence and Cultural Memory Preservation", "categories": ["cs.HC"], "comment": "10 pages, 2 figures, 45 references cited", "summary": "This paper introduces the Interactive Memory Archive (IMA), a conceptual framework for AI-mediated reminiscence designed to support cognitive en-gagement among older adults experiencing memory loss. IMA integrates multimodal sensing, natural language conversational scaffolding, and cloud-based archiving within the familiar form of a large format historical picture book. The model theorizes reminiscence as a guided, context-aware interaction eliciting autobiographical memories and preserving them as cul-tural artifacts. The paper positions IMA as a theoretical contribution, articu-lates testable propositions, and outlines a research agenda for future empiri-cal, technical, and ethical inquiry.", "AI": {"tldr": "设计交互记忆档案（IMA），一种支持认知参与的AI介导回忆概念框架", "motivation": "为经历记忆力衰退的老年人提供认知刺激和支持，通过集成多模态感应、自然语言对话支架和基于云的存档功能，将回忆作为文化艺术品保存下来", "method": "提出了一个理论贡献，阐明了可测试命题，并制定了未来实证、技术和社会伦理研究的日程", "result": "IMA被描述为一种理论框架，旨在支持认知参与并促进老年人的记忆力保持", "conclusion": "IMA作为一种概念性框架，对未来的实证和技术研究具有重要的指导意义"}}
{"id": "2601.21000", "pdf": "https://arxiv.org/pdf/2601.21000", "abs": "https://arxiv.org/abs/2601.21000", "authors": ["Muhammad Ali Shafique", "Areej Mehboob", "Layba Fiaz", "Muhammad Usman Qadeer", "Hamza Farooq"], "title": "UrduBench: An Urdu Reasoning Benchmark using Contextually Ensembled Translations with Human-in-the-Loop", "categories": ["cs.CL", "cs.AI"], "comment": ":I.2.7; I.2.6", "summary": "Recent advances in large language models (LLMs) have led to strong reasoning capabilities; however, evaluating such models in low-resource languages remains challenging due to the lack of standardized benchmarks. In particular, Urdu reasoning evaluation has been limited by the sensitivity of machine translation and an emphasis on general language tasks rather than reasoning benchmarks. In this paper, we propose a contextually ensembled translation framework with human-in-the-loop validation that leverages multiple translation systems to develop Urdu reasoning benchmarks while preserving contextual and structural integrity. Using this framework, we translate widely adopted reasoning and question-answering benchmarks, including MGSM, MATH-500, CommonSenseQA, and OpenBookQA, into Urdu, collectively referred to as UrduBench, and conduct a comprehensive evaluation of both reasoning-oriented and instruction-tuned LLMs across multiple prompting strategies. Our analysis reveals performance differences across (1) four datasets, (2) five task difficulty levels, (3) diverse model architectures, (4) multiple model scaling settings, and (5) language consistency tests. We find that multi-step and symbolic reasoning tasks pose significant challenges in Urdu, and that stable language alignment is a critical prerequisite for robust reasoning. Overall, our work establishes a scalable methodology for standardized reasoning evaluation in Urdu and provides empirical insights into multilingual reasoning failures. This experimental setup is also broadly applicable to other low-resource languages. The code and datasets will be publicly released.", "AI": {"tldr": "提出了一种在乌尔都语中进行推理评估的基准框架，使用多翻译系统和人工验证。", "motivation": "针对大型语言模型在低资源语言中的推理能力评估存在挑战，特别是在乌尔都语环境中由于机器翻译敏感性和缺乏专门用于推理任务的基准。", "method": "利用多翻译系统与人工验证相结合的方法创建乌尔都语推理基准，包括MGSM、MATH-500、CommonSenseQA和OpenBookQA，并对其进行评估。", "result": "发现在乌尔都语中进行多步骤和符号性推理任务存在挑战，语言一致性对于稳健的推理至关重要。此外，还对不同模型架构进行了分析。", "conclusion": "提出了一个可扩展的方法来标准化乌尔都语中的推理评估，并提供了跨多种低资源语言应用该实验设置的方式"}}
{"id": "2601.20999", "pdf": "https://arxiv.org/pdf/2601.20999", "abs": "https://arxiv.org/abs/2601.20999", "authors": ["Dev Vikesh Doshi", "Mehjabeen Tasnim", "Fernando Landeros", "Chinthagumpala Muni Venkatesh", "Daniel Timko", "Muhammad Lutfor Rahman"], "title": "What Are Brands Telling You About Smishing? A Cross-Industry Evaluation of Customer Guidance", "categories": ["cs.CR", "cs.HC"], "comment": null, "summary": "Phishing attacks through text, also known as smishing, are a prevalent type of social engineering tactic in which attackers impersonate brands to deceive victims into providing personal information and/or money. While smishing awareness and cyber education are a key method by which organizations communicate this awareness, the guidance itself varies widely. In this paper, we investigate the state of practice of how 149 well-known brands across 25 categories educate their customers about smishing and what smishing prevention and reporting advice they provide. After conducting a comprehensive content analysis of the brands, we identified significant gaps in the smishing-related information provided: only 46\\% of the 149 brands mentioned the definition of smishing, less than 1\\% had a video tutorial on smishing, and only 50\\% of brands provided instructions on how to report. Our study highlights variation in terminology, prevention advice, and reporting mechanisms across industries, with some brands recommending potentially ineffective strategies such as \"ignoring suspicious messages.\" These findings establish a baseline for understanding the current state of industry smishing awareness advice and provide specific areas where standardization improvements are needed. From our evaluation, we provide recommendations for brands on how to offer streamlined education to their respective customers on smishing for better awareness and protection against increasing smishing attacks.", "AI": {"tldr": "研究分析了149个知名品牌如何向客户传达短信钓鱼（smishing）的意识及预防措施，发现了这些信息中的显著差距。", "motivation": "鉴于短信钓鱼攻击日益严重，该研究旨在评估不同行业品牌在教育客户关于短信钓鱼防范方面的现状和效果。", "method": "通过对来自25个行业的149个知名品牌的文本内容进行综合分析来开展这项研究。", "result": "发现只有不到一半的品牌提到了smishing的定义，仅有少数有视频教程，且许多品牌提供的报告指南不足。各行业之间的术语、预防策略及报告机制存在显著差异。", "conclusion": "研究表明了当前行业内关于短信钓鱼防范意识传达存在的差距，并为品牌提供了如何改善客户教育的具体建议以提升防范能力"}}
{"id": "2601.20995", "pdf": "https://arxiv.org/pdf/2601.20995", "abs": "https://arxiv.org/abs/2601.20995", "authors": ["Hongxu Yang", "Levente Lippenszky", "Edina Timko", "Lehel Ferenczi", "Gopal Avinash"], "title": "Low performing pixel correction in computed tomography with unrolled network and synthetic data training", "categories": ["cs.CV"], "comment": "ISBI 2026 accepted", "summary": "Low performance pixels (LPP) in Computed Tomography (CT) detectors would lead to ring and streak artifacts in the reconstructed images, making them clinically unusable. In recent years, several solutions have been proposed to correct LPP artifacts, either in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, which are expensive to collect. Moreover, existing approaches focus solely either on image-space or sinogram-space correction, ignoring the intrinsic correlations from the forward operation of the CT geometry. In this work, we propose an unrolled dual-domain method based on synthetic data to correct LPP artifacts. Specifically, the intrinsic correlations of LPP between the sinogram and image domains are leveraged through synthetic data generated from natural images, enabling the trained model to correct artifacts without requiring any real-world clinical data. In experiments simulating 1-2% detectors defect near the isocenter, the proposed method outperformed the state-of-the-art approaches by a large margin. The results indicate that our solution can correct LPP artifacts without the cost of data collection for model training, and it is adaptable to different scanner settings for software-based applications.", "AI": {"tldr": "本文提出了一种基于合成数据的未卷绕双域方法，用于校正CT图像中的低性能像素（LPP）产生的环形和条纹伪影。", "motivation": "为了减少因低性能像素导致的伪影并提高临床可用性，同时避免昂贵的数据采集过程，本文旨在开发一种无需使用真实数据集训练的方法来解决这个问题。", "method": "该方法利用合成数据生成自自然图像，并通过未卷绕网络在sinogram和图像域之间建立内在联系以校正LPP。", "result": "实验表明，在模拟1-2%检测器缺陷的情况下，所提出的方法优于现有的最新技术。", "conclusion": "这种方法能够有效纠正LPP伪影而无需进行数据收集，并且适用于不同扫描仪设置的软件应用。"}}
{"id": "2601.20994", "pdf": "https://arxiv.org/pdf/2601.20994", "abs": "https://arxiv.org/abs/2601.20994", "authors": ["Md Muhtasim Munif Fahim", "Md Rezaul Karim"], "title": "The Depth Delusion: Why Transformers Should Be Wider, Not Deeper", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neural scaling laws describe how language model loss decreases with parameters and data, but treat architecture as interchangeable--a billion parameters could arise from a shallow-wide model (10 layers & 8,192 hidden dimension) or a deep-narrow one (80 layers & 2,048 hidden dimension). We propose architecture-conditioned scaling laws decomposing this dependence, finding that optimal depth scales as D* ~ C^0.12 while optimal width scales as W* ~ C^0.34, meaning width should grow 2.8x faster than depth. We discover a critical depth phenomenon: beyond D_crit ~ W^0.44 (sublinear in W), adding layers increases loss despite adding parameters--the Depth Delusion. Empirically, we validate these findings across 30 transformer architectures spanning 17M to 7B parameters, each trained on representative high-compute samples, achieving R^2 = 0.922. Our central finding: at 7B scale, a 64-layer model (6.38B params) underperforms a 32-layer model (6.86B params) by 0.12 nats, despite being significantly deeper. This demonstrates that optimal depth-width tradeoffs persist at the production scale.", "AI": {"tldr": "本文研究了不同架构条件下的神经网络扩展法则，发现宽度比深度更重要。", "motivation": "传统的神经网络扩展法则是基于参数和数据量进行的，但忽略了架构的影响。作者希望通过引入架构条件来优化模型性能。", "method": "提出了一种新的架构条件下扩展法则，并通过实验验证了不同层数与隐藏维度的关系，以及最佳的宽度与深度比例。", "result": "实验证明，在大规模参数下，较宽的网络比深层的网络表现更好。具体而言，70亿参数量级时，一个64层模型的表现不如32层模型好。", "conclusion": "在生产规模上，最佳的宽度和深度之间的权衡仍然存在，增加模型的宽度比加深层数更能提高性能。"}}
{"id": "2601.20992", "pdf": "https://arxiv.org/pdf/2601.20992", "abs": "https://arxiv.org/abs/2601.20992", "authors": ["Oleg Sedukhin", "Andrey Kostin"], "title": "asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-Latin languages, those with rich word formation, to label cluttered or longform speech. Secondly, we collect a novel test set DiverseSpeech-Ru of longform in-the-wild Russian speech with careful multi-reference labeling. We also perform multi-reference relabeling of popular Russian tests set and study fine-tuning dynamics on its corresponding train set. We demonstrate that the model often adopts to dataset-specific labeling, causing an illusion of metric improvement. Based on the improved word alignment, we develop tools to evaluate streaming speech recognition and to align multiple transcriptions to compare them visually. Additionally, we provide uniform wrappers for many offline and streaming speech recognition models. Our code will be made publicly available.", "AI": {"tldr": "提出改进的语音识别评估方法，包括新的字符串对齐算法、长文本俄罗斯语数据集和工具", "motivation": "为了更好地支持非拉丁语言和复杂词形变化的语言，并提高多参考标签的支持能力，提出了改进的语音识别评估方法。", "method": "开发了一种新的字符串对齐算法以支持多参考标签、任意长度插入以及更好的单词对齐；收集了一个名为DiverseSpeech-Ru的新测试集，该集合包含长文本现实世界俄罗斯语语音数据；并对常用俄语测试集进行重新标注研究微调动态。", "result": "基于改进的单词对齐技术开发了评估流式语音识别和多转录对比可视化的工具，并提供了统一包装器用于许多离线和流媒体语音识别模型。", "conclusion": "新方法可以更准确地衡量语音识别系统性能，避免因数据集特定标签而产生的指标改善假象"}}
{"id": "2601.20990", "pdf": "https://arxiv.org/pdf/2601.20990", "abs": "https://arxiv.org/abs/2601.20990", "authors": ["Xuehua Ye", "Hongxu Yang", "Adam J. Schwarz"], "title": "Text controllable PET denoising", "categories": ["cs.CV"], "comment": "SPIE Medical Imaging 2026", "summary": "Positron Emission Tomography (PET) imaging is a vital tool in medical diagnostics, offering detailed insights into molecular processes within the human body. However, PET images often suffer from complicated noise, which can obscure critical diagnostic information. The quality of the PET image is impacted by various factors including scanner hardware, image reconstruction, tracer properties, dose/count level, and acquisition time. In this study, we propose a novel text-guided denoising method capable of enhancing PET images across a wide range of count levels within a single model. The model utilized the features from a pretrained CLIP model with a U-Net based denoising model. Experimental results demonstrate that the proposed model leads significant improvements in both qualitative and quantitative assessments. The flexibility of the model shows the potential for helping more complicated denoising demands or reducing the acquisition time.", "AI": {"tldr": "提出了一种基于文本引导的PET图像去噪方法，以提高不同计数水平下的图像质量。", "motivation": "解决PET成像中的复杂噪声问题，提升诊断信息可见性，并适应各种因素影响下图像质量的变化。", "method": "利用预训练的CLIP模型特征和U-Net基础去噪模型进行文本指导的去噪处理。", "result": "实验结果显示该方法在定性和定量评估中均有显著改善。", "conclusion": "展示了模型应对更复杂去噪需求或缩短采集时间的潜力，提高了PET图像的质量。"}}
{"id": "2601.20989", "pdf": "https://arxiv.org/pdf/2601.20989", "abs": "https://arxiv.org/abs/2601.20989", "authors": ["Lutz Oettershagen"], "title": "Top-k on a Budget: Adaptive Ranking with Weak and Strong Oracles", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "Identifying the top-$k$ items is fundamental but often prohibitive when exact valuations are expensive. We study a two-oracle setting with a fast, noisy weak oracle and a scarce, high-fidelity strong oracle (e.g., human expert verification or expensive simulation). We first analyze a simple screen-then-certify baseline (STC) and prove it makes at most $m(4\\varepsilon_{\\max})$ strong calls given jointly valid weak confidence intervals with maximum radius $\\varepsilon_{\\max}$, where $m(\\cdot)$ denotes the near-tie mass around the top-$k$ threshold. We establish a conditional lower bound of $Ω(m(\\varepsilon_{\\max}))$ for any algorithm given the same weak uncertainty. Our main contribution is ACE, an adaptive certification algorithm that focuses strong queries on critical boundary items, achieving the same $O(m(4\\varepsilon_{\\max}))$ bound while reducing strong calls in practice. We then introduce ACE-W, a fully adaptive two-phase method that allocates weak budget adaptively before running ACE, further reducing strong costs.", "AI": {"tldr": "研究在预算限制下使用弱和强预言机识别前k个项目的高效算法。", "motivation": "精确估值昂贵时，找到前k个项目是一项基本但可能过于昂贵的任务。利用快速且噪声较大的弱预言机和稀缺的高精度强预言机（如人类专家验证或昂贵模拟）来优化资源分配。", "method": "提出ACE自适应认证算法，该算法专注于关键边界项目上的强查询；引入ACE-W两阶段方法，前一阶段动态分配弱预算以进一步减少强调用次数。", "result": "证明了基线方案STC最多需要m(4ε_max)次强呼叫，并建立了Ω(m(ε_max))的条件下限。ACE算法实现了O(m(4ε_max))上限并在实践中减少了强查询。", "conclusion": "通过自适应分配资源，能够有效减少昂贵的精确验证次数同时保持识别前k个项目的能力。"}}
{"id": "2601.20981", "pdf": "https://arxiv.org/pdf/2601.20981", "abs": "https://arxiv.org/abs/2601.20981", "authors": ["Onkar Shelar", "Travis Desell"], "title": "Diversifying Toxicity Search in Large Language Models Through Speciation", "categories": ["cs.NE", "q-bio.PE"], "comment": "Preprint. 12 pages", "summary": "Evolutionary prompt search is a practical black-box approach for red teaming large language models (LLMs), but existing methods often collapse onto a small family of high-performing prompts, limiting coverage of distinct failure modes. We present a speciated quality-diversity (QD) extension of ToxSearch that maintains multiple high-toxicity prompt niches in parallel rather than optimizing a single best prompt. ToxSearch-S introduces unsupervised prompt speciation via a search methodology that maintains capacity-limited species with exemplar leaders, a reserve pool for outliers and emerging niches, and species-aware parent selection that trades off within-niche exploitation and cross-niche exploration. ToxSearch-S is found to reach higher peak toxicity ($\\approx 0.73$ vs.\\ $\\approx 0.47$) and a extreme heavier tail (top-10 median $0.66$ vs.\\ $0.45$) than the baseline, while maintaining comparable performance on moderately toxic prompts. Speciation also yields broader semantic coverage under a topic-as-species analysis (higher effective topic diversity $N_1$ and larger unique topic coverage $K$). Finally, species formed are well-separated in embedding space (mean separation ratio $\\approx 1.93$) and exhibit distinct toxicity distributions, indicating that speciation partitions the adversarial space into behaviorally differentiated niches rather than superficial lexical variants. This suggests our approach uncovers a wider range of attack strategies.", "AI": {"tldr": "本文提出了一种通过物种分化来扩展毒性搜索的方法，旨在多样化大型语言模型中的毒性测试。", "motivation": "现有的进化提示搜索方法在查找高毒性提示时往往集中在少数几个最佳提示上，从而限制了对不同失效模式的覆盖率。为此，作者希望通过引入物种分化技术以拓宽毒性搜索范围，并提高覆盖度。", "method": "本文提出了一种基于质量多样性（QD）扩展的方法ToxSearch-S，通过保持多个高毒性的提示巢穴来维护多样性和独特性；采用无监督的提示物种化方法，包含容量限制的物种领导者、离群值和新兴巢穴的储备池以及考虑物种意识的父代选择策略。", "result": "与基线相比，ToxSearch-S 达到了更高的峰值毒性（约0.73对约0.47），并且在极端毒性测试中表现更佳（前10名平均值为0.66对比0.45）。同时，在主题作为物种分析时，该方法也提供了更大的有效话题多样性和更多独特的话题覆盖率。最终结果表明，不同物种之间存在明显的语义差异，并且它们在嵌入空间中的分离比例约为1.93。", "conclusion": "本文的方法通过将毒性搜索环境划分为行为差异化巢穴而非表面的词汇变化来揭示更广泛的攻击策略，从而提升了对大型语言模型潜在风险的理解。"}}
{"id": "2601.20969", "pdf": "https://arxiv.org/pdf/2601.20969", "abs": "https://arxiv.org/abs/2601.20969", "authors": ["Alessandro Burigana", "Francesco Fabiano"], "title": "The Epistemic Planning Domain Definition Language: Official Guideline", "categories": ["cs.AI"], "comment": null, "summary": "Epistemic planning extends (multi-agent) automated planning by making agents' knowledge and beliefs first-class aspects of the planning formalism. One of the most well-known frameworks for epistemic planning is Dynamic Epistemic Logic (DEL), which offers an rich and natural semantics for modelling problems in this setting. The high expressive power provided by DEL make DEL-based epistemic planning a challenging problem to tackle both theoretically, and in practical implementations. As a result, existing epistemic planners often target different DEL fragments, and typically rely on ad hoc languages to represent benchmarks, and sometimes no language at all. This fragmentation hampers comparison, reuse, and systematic benchmark development. We address these issues by introducing the Epistemic Planning Domain Definition Language (EPDDL). EPDDL provides a unique PDDL-like representation that captures the entire DEL semantics, enabling uniform specification of epistemic planning tasks. Our contributions are threefold: 1. A formal development of abstract event models, a novel representation for epistemic actions used to define the semantics of our language; 2. A formal specification of EPDDL's syntax and semantics grounded in DEL with abstract event models; 3. A demonstration of EPDDL's practical applicability: we identify useful fragments amenable to current planners and show how they can be represented in EPDDL. Through examples of representative benchmarks, we illustrate how EPDDL facilitates interoperability, reproducible evaluation, and future advances in epistemic planning.", "AI": {"tldr": "该论文介绍了Epistemic Planning Domain Definition Language (EPDDL)，一种用于统一表示多智能体知识和信仰规划任务的语言。", "motivation": "由于DEL的高表达能力，使得基于DEL的知识性规划在理论上和技术实现上都具有挑战。现有的知识性计划程序通常针对不同的DEL片段，并依赖于不一致的语言来代表基准测试问题，这阻碍了比较、重用和系统性的基准开发。", "method": "论文通过引入EPDDL来解决上述问题。EPDDL提供了一种类似于PDDL的独特表示法，能够捕捉到整个DEL语义，使知识性规划任务的统一表述成为可能。", "result": "该研究展示了EPDDL的实际应用性：识别了当前计划程序适用的一些有用片段，并演示了它们如何在EPDDL中表示。通过代表性基准示例证明了EPDDL有助于促进互操作性、可重复评估和未来的知识性规划进展。", "conclusion": "论文为知识性规划提供了一种统一的语言，解决了不同规划器之间缺乏标准化的问题，并推动了该领域的进一步发展。"}}
{"id": "2601.20968", "pdf": "https://arxiv.org/pdf/2601.20968", "abs": "https://arxiv.org/abs/2601.20968", "authors": ["Yulie Arad", "Stav Ashur", "Nancy M. Amato"], "title": "Quick Heuristic Validation of Edges in Dynamic Roadmap Graphs", "categories": ["cs.RO"], "comment": null, "summary": "In this paper we tackle the problem of adjusting roadmap graphs for robot motion planning to non-static environments. We introduce the \"Red-Green-Gray\" paradigm, a modification of the SPITE method, capable of classifying the validity status of nodes and edges using cheap heuristic checks, allowing fast semi-lazy roadmap updates. Given a roadmap, we use simple computational geometry methods to approximate the swept volumes of robots and perform lazy collision checks, and label a subset of the edges as invalid (red), valid (green), or unknown (gray). We present preliminary experimental results comparing our method to the well-established technique of Leven and Hutchinson, and showing increased accuracy as well as the ability to correctly label edges as invalid while maintaining comparable update runtimes.", "AI": {"tldr": "提出了一种名为“红绿灰”的方法，用于快速验证动态环境中的机器人路径规划图边的合法性。", "motivation": "在非静态环境中调整机器人路径规划图以应对环境变化是一个挑战性的任务。需要一种新的方法来提高效率和准确性。", "method": "通过使用廉价启发式检查分类节点和边的有效性状态，并采用简单的计算几何方法近似机器人的扫掠体积，进行懒惰碰撞检测，从而实现快速半懒惰的路线图更新。", "result": "实验结果显示该方法与Leven和Hutchinson的技术相比，在准确性上有所提高并能够正确标记无效边缘的同时保持了可比的更新运行时间。", "conclusion": "提出的方法能够在动态环境中更有效地进行机器人路径规划图的边合法性验证，提高了效率和精度。"}}
{"id": "2601.20921", "pdf": "https://arxiv.org/pdf/2601.20921", "abs": "https://arxiv.org/abs/2601.20921", "authors": ["Faruk Alpay", "Levent Sarioglu"], "title": "Stochastic Indexing Primitives for Non-Deterministic Molecular Archives", "categories": ["cs.DS"], "comment": "18 pages, 2 figures", "summary": "Random access remains a central bottleneck in DNA-based data storage. Existing systems typically retrieve records by PCR enrichment or other multi-step biochemical procedures, which do not naturally support fast, massively parallel, content-addressable queries. We introduce the Holographic Bloom Filter (HBF), a probabilistic indexing primitive that stores key-pointer associations as a single high-dimensional memory vector. HBF binds a key vector and a value (pointer) vector using circular convolution and superposes bindings across all records. A query decodes by correlating the memory with the query key and selecting the best matching value using a margin-based decision rule. We give construction and decoding algorithms and a probabilistic analysis under explicit noise models (memory corruption and query/key mismatches). The analysis provides concentration bounds for match and non-match score distributions, explicit threshold and margin settings for a top K decoder, and exponential error decay in the vector dimension under standard randomness assumptions. HBF offers a concrete, analyzable alternative to pointer-chasing molecular data structures, enabling one-shot associative retrieval while quantifying trade-offs among dimensionality, dataset size, and noise.", "AI": {"tldr": "本文提出了一种名为Holographic Bloom Filter (HBF) 的概率索引原语，用于DNA数据存储系统中随机访问的高效实现。", "motivation": "现有基于DNA的数据存储系统在进行记录检索时存在中心瓶颈问题，即需要通过PCR富集或其他多步骤生化程序来获取信息，这种方法不支持快速、大规模并行的内容寻址查询。", "method": "HBF采用圆周卷积将键向量和值（指针）向量绑定，并在所有记录之间进行叠加。查询时通过对内存与查询键的相关性进行解码并使用边缘决策规则选择最佳匹配的值来完成。", "result": "该方法提供了构造和解码算法及明确噪声模型下的概率分析，包括集中界限、阈值和边缘设置等；实验结果表明HBF能够在标准随机假设下提供指数级错误衰减。", "conclusion": "HBF为分子数据结构中的指针查找问题提供了一个具体且可分析的替代方案，实现了单次关联检索并量化了维度、数据集大小与噪声之间的权衡。"}}
{"id": "2601.20920", "pdf": "https://arxiv.org/pdf/2601.20920", "abs": "https://arxiv.org/abs/2601.20920", "authors": ["Vibhhu Sharma", "Thorsten Joachims", "Sarah Dean"], "title": "Do LLMs Favor LLMs? Quantifying Interaction Effects in Peer Review", "categories": ["cs.AI", "cs.CY"], "comment": "28 pages", "summary": "There are increasing indications that LLMs are not only used for producing scientific papers, but also as part of the peer review process. In this work, we provide the first comprehensive analysis of LLM use across the peer review pipeline, with particular attention to interaction effects: not just whether LLM-assisted papers or LLM-assisted reviews are different in isolation, but whether LLM-assisted reviews evaluate LLM-assisted papers differently. In particular, we analyze over 125,000 paper-review pairs from ICLR, NeurIPS, and ICML. We initially observe what appears to be a systematic interaction effect: LLM-assisted reviews seem especially kind to LLM-assisted papers compared to papers with minimal LLM use. However, controlling for paper quality reveals a different story: LLM-assisted reviews are simply more lenient toward lower quality papers in general, and the over-representation of LLM-assisted papers among weaker submissions creates a spurious interaction effect rather than genuine preferential treatment of LLM-generated content. By augmenting our observational findings with reviews that are fully LLM-generated, we find that fully LLM-generated reviews exhibit severe rating compression that fails to discriminate paper quality, while human reviewers using LLMs substantially reduce this leniency. Finally, examining metareviews, we find that LLM-assisted metareviews are more likely to render accept decisions than human metareviews given equivalent reviewer scores, though fully LLM-generated metareviews tend to be harsher. This suggests that meta-reviewers do not merely outsource the decision-making to the LLM. These findings provide important input for developing policies that govern the use of LLMs during peer review, and they more generally indicate how LLMs interact with existing decision-making processes.", "AI": {"tldr": "本文研究了LLM在同行评审过程中的使用情况，特别关注LLM辅助的论文和审查之间的交互效应。", "motivation": "探索LLM在同行评审中对论文评价的影响以及是否存在偏好处理现象。", "method": "分析了ICLR、NeurIPS和ICML超过125,000篇论文和审查对，研究LLM辅助的审查是否更倾向于评估由LLM生成的论文，并通过引入完全由LLM生成的评论进一步验证结果。", "result": "发现LLM辅助评审在整体上对质量较差的论文更为宽容。完全由LLM生成的评论无法有效区分论文的质量，而人类审稿人在使用LLM时会减少这种宽松性。", "conclusion": "研究表明，同行评审中的LLM交互效应并非表示偏爱处理，而是质量和数量分布不均造成的错觉，并为制定治理政策提供了重要依据。"}}
{"id": "2601.20913", "pdf": "https://arxiv.org/pdf/2601.20913", "abs": "https://arxiv.org/abs/2601.20913", "authors": ["Chen Feng", "Minghe Shen", "Ananth Balashankar", "Carsten Gerner-Beuerle", "Miguel R. D. Rodrigues"], "title": "Noisy but Valid: Robust Statistical Evaluation of LLMs with Imperfect Judges", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted to ICLR2026", "summary": "Reliable certification of Large Language Models (LLMs)-verifying that failure rates are below a safety threshold-is critical yet challenging. While \"LLM-as-a-Judge\" offers scalability, judge imperfections, noise, and bias can invalidate statistical guarantees. We introduce a \"Noisy but Valid\" hypothesis testing framework to address this. By leveraging a small human-labelled calibration set to estimate the judge's True Positive and False Positive Rates (TPR/FPR), we derive a variance-corrected critical threshold applied to a large judge-labelled dataset. Crucially, our framework theoretically guarantees finite-sample Type-I error control (validity) despite calibration uncertainty. This distinguishes our work from Prediction-Powered Inference (PPI), positioning our method as a diagnostic tool that explicitly models judge behavior rather than a black-box estimator. Our contributions include: (1) Theoretical Guarantees: We derive the exact conditions under which noisy testing yields higher statistical power than direct evaluation; (2) Empirical Validation: Experiments on Jigsaw Comment, Hate Speech and SafeRLHF confirm our theory; (3) The Oracle Gap: We reveal a significant performance gap between practical methods and the theoretical \"Oracle\" (perfectly known judge parameters), quantifying the cost of estimation. Specifically, we provide the first systematic treatment of the imperfect-judge setting, yielding interpretable diagnostics of judge reliability and clarifying how evaluation power depends on judge quality, dataset size, and certification levels. Together, these results sharpen understanding of statistical evaluation with LLM judges, and highlight trade-offs among competing inferential tools.", "AI": {"tldr": "本文提出了一个\"嘈杂但有效\"的假设检验框架，用于在有偏见和噪音的情况下对大型语言模型进行可靠的评估。", "motivation": "可靠地认证大规模语言模型的安全性标准是一个挑战。现有方法如“LLM作为法官”虽然具有可扩展性，但仍受法官不完美、噪声及偏差的影响，可能会导致统计保证失效。", "method": "通过使用一个小的人工标注校准集来估计法官的真实阳性率和假阳性率，本文框架可以推导出一个应用于大型数据集的方差矫正临界阈值。该方法在理论上能够提供有限样本下的一类错误控制，并且比黑箱估算的方法更透明。", "result": "理论保证表明，在特定条件下使用嘈杂测试可以获得更高的统计功效；实验证明了这一理论，同时揭示了一个重要的实践与理想之间的差距；此外，文章还系统地处理了不完美的法官环境，明确了评估效能依赖于多个因素的交互作用。", "conclusion": "本文框架提供了一种诊断工具，能够有效处理大规模语言模型在实际应用中的统计评价问题，并明确了一些关键性权衡。"}}
{"id": "2601.20911", "pdf": "https://arxiv.org/pdf/2601.20911", "abs": "https://arxiv.org/abs/2601.20911", "authors": ["Haochen Zhang", "Animesh Sinha", "Felix Juefei-Xu", "Haoyu Ma", "Kunpeng Li", "Zhipeng Fan", "Meng Dong", "Xiaoliang Dai", "Tingbo Hou", "Peizhao Zhang", "Zecheng He"], "title": "Non-Markov Multi-Round Conversational Image Generation with History-Conditioned MLLMs", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 19 figures, plan for TIP", "summary": "Conversational image generation requires a model to follow user instructions across multiple rounds of interaction, grounded in interleaved text and images that accumulate as chat history. While recent multimodal large language models (MLLMs) can generate and edit images, most existing multi-turn benchmarks and training recipes are effectively Markov: the next output depends primarily on the most recent image, enabling shortcut solutions that ignore long-range history. In this work we formalize and target the more challenging non-Markov setting, where a user may refer back to earlier states, undo changes, or reference entities introduced several rounds ago. We present (i) non-Markov multi-round data construction strategies, including rollback-style editing that forces retrieval of earlier visual states and name-based multi-round personalization that binds names to appearances across rounds; (ii) a history-conditioned training and inference framework with token-level caching to prevent multi-round identity drift; and (iii) enabling improvements for high-fidelity image reconstruction and editable personalization, including a reconstruction-based DiT detokenizer and a multi-stage fine-tuning curriculum. We demonstrate that explicitly training for non-Markov interactions yields substantial improvements in multi-round consistency and instruction compliance, while maintaining strong single-round editing and personalization.", "AI": {"tldr": "本文提出了一种非马尔可夫多轮会话图像生成方法，通过历史条件训练和推理框架解决现有模型忽略长距离历史信息的问题。", "motivation": "现有的多回合基准测试和训练方案大多数是基于当前最相关的历史进行的，这导致了忽略了早期状态的信息。本文希望通过一个非马尔可夫的方法来改进这个问题。", "method": "提出了包括回滚式编辑数据构建策略、历史条件推理框架等方法，并结合高保真图像重建和个性化设计来提高模型性能。", "result": "实验表明，使用该方法可以显著改善多回合一致性和指令遵守能力，同时保持单轮编辑和个人化的强大功能。", "conclusion": "本文的方法在处理非马尔可夫交互时表现出色，并为未来的研究提供了新的方向和策略。"}}
{"id": "2601.20905", "pdf": "https://arxiv.org/pdf/2601.20905", "abs": "https://arxiv.org/abs/2601.20905", "authors": ["Azadeh Mokari", "Shravan Raghunathan", "Artem Shydliukh", "Oleg Ryabchykov", "Christoph Krafft", "Thomas Bocklitz"], "title": "Denoising and Baseline Correction of Low-Scan FTIR Spectra: A Benchmark of Deep Learning Models Against Traditional Signal Processing", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "eess.SP"], "comment": null, "summary": "High-quality Fourier Transform Infrared (FTIR) imaging usually needs extensive signal averaging to reduce noise and drift which severely limits clinical speed. Deep learning can accelerate imaging by reconstructing spectra from rapid, single-scan inputs. However, separating noise and baseline drift simultaneously without ground truth is an ill-posed inverse problem. Standard black-box architectures often rely on statistical approximations that introduce spectral hallucinations or fail to generalize to unstable atmospheric conditions. To solve these issues we propose a physics-informed cascade Unet that separates denoising and baseline correction tasks using a new, deterministic Physics Bridge. This architecture forces the network to separate random noise from chemical signals using an embedded SNIP layer to enforce spectroscopic constraints instead of learning statistical approximations. We benchmarked this approach against a standard single Unet and a traditional Savitzky-Golay/SNIP workflow. We used a dataset of human hypopharyngeal carcinoma cells (FaDu). The cascade model outperformed all other methods, achieving a 51.3% reduction in RMSE compared to raw single-scan inputs, surpassing both the single Unet (40.2%) and the traditional workflow (33.7%). Peak-aware metrics show that the cascade architecture eliminates spectral hallucinations found in standard deep learning. It also preserves peak intensity with much higher fidelity than traditional smoothing. These results show that the cascade Unet is a robust solution for diagnostic-grade FTIR imaging. It enables imaging speeds 32 times faster than current methods.", "AI": {"tldr": "该论文提出了一种基于物理学信息的级联Unet模型，用于加速傅立叶变换红外（FTIR）成像的速度。", "motivation": "高分辨率的FTIR成像需要大量的信号平均来减少噪声和漂移，从而严重限制了临床速度。深度学习可以通过从快速单扫描输入中重建光谱来加快成像速度，但同时分离噪声和基线漂移是一个难以解决的问题。", "method": "该论文提出了一种基于物理学信息的级联Unet模型，用于从低扫描数FTIR光谱中进行去噪和基线校正。通过使用一个确定性的物理桥接层来强制网络将随机噪声与化学信号分开，并采用嵌入式SNIP层以施加光谱约束，而不是学习统计近似。", "result": "在人类下咽癌细胞（FaDu）的数据集上进行的实验显示，该级联Unet模型比单个Unet和传统的Savitzky-Golay/SNIP工作流程表现更好，实现了51.3％的均方根误差（RMSE）降低。它还消除了标准深度学习中的光谱幻觉，并以更高的保真度保留了峰值强度。", "conclusion": "该级联Unet模型是一种稳健的方法，能够实现诊断级别的FTIR成像速度提高到当前方法的32倍以上。"}}
{"id": "2601.20904", "pdf": "https://arxiv.org/pdf/2601.20904", "abs": "https://arxiv.org/abs/2601.20904", "authors": ["Xiaocheng Fang", "Zhengyao Ding", "Jieyi Cai", "Yujie Xiao", "Bo Liu", "Jiarui Jin", "Haoyu Wang", "Guangkun Nie", "Shun Huang", "Ting Chen", "Hongyan Li", "Shenda Hong"], "title": "ECGFlowCMR: Pretraining with ECG-Generated Cine CMR Improves Cardiac Disease Classification and Phenotype Prediction", "categories": ["eess.IV", "cs.LG"], "comment": null, "summary": "Cardiac Magnetic Resonance (CMR) imaging provides a comprehensive assessment of cardiac structure and function but remains constrained by high acquisition costs and reliance on expert annotations, limiting the availability of large-scale labeled datasets. In contrast, electrocardiograms (ECGs) are inexpensive, widely accessible, and offer a promising modality for conditioning the generative synthesis of cine CMR. To this end, we propose ECGFlowCMR, a novel ECG-to-CMR generative framework that integrates a Phase-Aware Masked Autoencoder (PA-MAE) and an Anatomy-Motion Disentangled Flow (AMDF) to address two fundamental challenges: (1) the cross-modal temporal mismatch between multi-beat ECG recordings and single-cycle CMR sequences, and (2) the anatomical observability gap due to the limited structural information inherent in ECGs. Extensive experiments on the UK Biobank and a proprietary clinical dataset demonstrate that ECGFlowCMR can generate realistic cine CMR sequences from ECG inputs, enabling scalable pretraining and improving performance on downstream cardiac disease classification and phenotype prediction tasks.", "AI": {"tldr": "提出ECGFlowCMR框架，通过心电图生成心脏磁共振成像序列以改善心脏病分类和表型预测。", "motivation": "心脏MRI成本高且依赖专家标注，限制了大规模标记数据集的可用性。而心电图便宜、广泛可得，并可能用于条件化生成心脏MRI。", "method": "开发了一种新的ECG到CMR的生成框架ECGFlowCMR，结合阶段感知掩码自编码器（PA-MAE）和解剖运动分离流（AMDF），解决心电图与CMR间的时间不匹配及结构信息缺乏的问题。", "result": "实验结果显示，该方法能够从心电图输入生成真实的CMR序列，提高心脏疾病分类和表型预测任务的性能。", "conclusion": "ECGFlowCMR框架在UK Biobank和临床数据集上的表现证明其有效性，为心脏病学研究提供了一种新的预训练策略。"}}
{"id": "2601.20903", "pdf": "https://arxiv.org/pdf/2601.20903", "abs": "https://arxiv.org/abs/2601.20903", "authors": ["Xingwei Lin", "Wenhao Lin", "Sicong Cao", "Jiahao Yu", "Renke Huang", "Lei Xue", "Chunming Wu"], "title": "ICON: Intent-Context Coupling for Efficient Multi-Turn Jailbreak Attack", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Multi-turn jailbreak attacks have emerged as a critical threat to Large Language Models (LLMs), bypassing safety mechanisms by progressively constructing adversarial contexts from scratch and incrementally refining prompts. However, existing methods suffer from the inefficiency of incremental context construction that requires step-by-step LLM interaction, and often stagnate in suboptimal regions due to surface-level optimization. In this paper, we characterize the Intent-Context Coupling phenomenon, revealing that LLM safety constraints are significantly relaxed when a malicious intent is coupled with a semantically congruent context pattern. Driven by this insight, we propose ICON, an automated multi-turn jailbreak framework that efficiently constructs an authoritative-style context via prior-guided semantic routing. Specifically, ICON first routes the malicious intent to a congruent context pattern (e.g., Scientific Research) and instantiates it into an attack prompt sequence. This sequence progressively builds the authoritative-style context and ultimately elicits prohibited content. In addition, ICON incorporates a Hierarchical Optimization Strategy that combines local prompt refinement with global context switching, preventing the attack from stagnating in ineffective contexts. Experimental results across eight SOTA LLMs demonstrate the effectiveness of ICON, achieving a state-of-the-art average Attack Success Rate (ASR) of 97.1\\%. Code is available at https://github.com/xwlin-roy/ICON.", "AI": {"tldr": "ICON框架通过意图-上下文耦合现象，提出了一种高效构建权威风格上下文的多轮越狱攻击方法。", "motivation": "现有方法在进行增量上下文构造时效率低下且容易陷入次优状态。为此，研究者揭示了LLM安全性约束放松的现象，并利用这一发现来设计新的攻击框架。", "method": "ICON通过先前引导语义路由将恶意意图导向与之语义一致的上下文模式，并逐步构建权威风格的上下文以最终引发被禁止的内容。同时采用分层优化策略结合局部提示精炼和全局上下文切换，防止陷入无效状态。", "result": "实验结果表明，ICON在八种SOTA LLM上达到了97.1%的平均攻击成功率。", "conclusion": "该方法有效提高了多轮越狱攻击的效率和成功率。"}}
{"id": "2601.20900", "pdf": "https://arxiv.org/pdf/2601.20900", "abs": "https://arxiv.org/abs/2601.20900", "authors": ["Sergio Burdisso", "Esaú Villatoro-Tello", "Andrés Carofilis", "Shashi Kumar", "Kadri Hacioglu", "Srikanth Madikeri", "Pradeep Rangappa", "Manjunath K E", "Petr Motlicek", "Shankar Venkatesan", "Andreas Stolcke"], "title": "Text-only adaptation in LLM-based ASR through text denoising", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": "Paper accepted at ICASSP 2026", "summary": "Adapting automatic speech recognition (ASR) systems based on large language models (LLMs) to new domains using text-only data is a significant yet underexplored challenge. Standard fine-tuning of the LLM on target-domain text often disrupts the critical alignment between speech and text modalities learned by the projector, degrading performance. We introduce a novel text-only adaptation method that emulates the audio projection task by treating it as a text denoising task. Our approach thus trains the LLM to recover clean transcripts from noisy inputs. This process effectively adapts the model to a target domain while preserving cross-modal alignment. Our solution is lightweight, requiring no architectural changes or additional parameters. Extensive evaluation on two datasets demonstrates up to 22.1% relative improvement, outperforming recent state-of-the-art text-only adaptation methods.", "AI": {"tldr": "基于大型语言模型（LLM）的自动语音识别系统在新领域通过文本数据进行适应。", "motivation": "利用目标领域的纯文本数据来调整基于LLM的ASR系统是一个重要但未充分探索的问题，传统的微调方法通常会破坏投影器学习到的语言和音频之间的关键对齐关系，从而降低性能。", "method": "提出了一种新颖的方法，将音频投影任务视为文本去噪任务。通过让LLM从噪音输入中恢复干净的转录本的方式训练模型，使模型适应目标领域的同时保持跨模态对齐。", "result": "在两个数据集上的广泛评估显示相对改进高达22.1％，超过了最近最先进的纯文本适应方法。", "conclusion": "该研究提出了一种轻量级的基于文本去噪的任务调整ASR模型的方法，无需架构更改或额外参数，并且证明了其有效性。"}}
{"id": "2601.20898", "pdf": "https://arxiv.org/pdf/2601.20898", "abs": "https://arxiv.org/abs/2601.20898", "authors": ["Sergio Burdisso", "Esaú Villatoro-Tello", "Shashi Kumar", "Srikanth Madikeri", "Andrés Carofilis", "Pradeep Rangappa", "Manjunath K E", "Kadri Hacioglu", "Petr Motlicek", "Andreas Stolcke"], "title": "Reducing Prompt Sensitivity in LLM-based Speech Recognition Through Learnable Projection", "categories": ["eess.AS", "cs.CL", "cs.LG"], "comment": "Paper accepted at ICASSP 2026", "summary": "LLM-based automatic speech recognition (ASR), a well-established approach, connects speech foundation models to large language models (LLMs) through a speech-to-LLM projector, yielding promising results. A common design choice in these architectures is the use of a fixed, manually defined prompt during both training and inference. This setup not only enables applicability across a range of practical scenarios, but also helps maximize model performance. However, the impact of prompt design remains underexplored. This paper presents a comprehensive analysis of commonly used prompts across diverse datasets, showing that prompt choice significantly affects ASR performance and introduces instability, with no single prompt performing best across all cases. Inspired by the speech-to-LLM projector, we propose a prompt projector module, a simple, model-agnostic extension that learns to project prompt embeddings to more effective regions of the LLM input space, without modifying the underlying LLM-based ASR model. Experiments on four datasets show that the addition of a prompt projector consistently improves performance, reduces variability, and outperforms the best manually selected prompts.", "AI": {"tldr": "本文研究了基于大语言模型的自动语音识别系统中提示词设计的影响，并提出了一种可学习的提示投影模块来提高性能和稳定性。", "motivation": "当前LLM-based ASR系统的固定手动定义提示词在不同数据集上的表现不稳定，且缺乏对最佳提示词的设计研究。因此，需要探索更有效的提示设计方法以改善系统性能。", "method": "引入了可学习的提示投影模块，该模块通过将提示嵌入到大语言模型输入空间中的有效区域进行学习，从而提高ASR系统的性能和稳定性。", "result": "实验结果显示，在四个数据集上添加提示投影器可以显著提升性能并减少变异性，优于所有手动选择的最佳提示词。", "conclusion": "本文提出的方法通过学习将提示嵌入到大语言模型输入空间中的有效区域来提高基于LLM的自动语音识别系统的性能和稳定性。"}}
{"id": "2601.20896", "pdf": "https://arxiv.org/pdf/2601.20896", "abs": "https://arxiv.org/abs/2601.20896", "authors": ["Ryan Whetten", "Titouan Parcollet", "Marco Dinarelli", "Yannick Estève"], "title": "A Study of Data Selection Strategies for Pre-training Self-Supervised Speech Models", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted for publication in the 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2026)", "summary": "Self-supervised learning (SSL) has transformed speech processing, yet its reliance on massive pre-training datasets remains a bottleneck. While robustness is often attributed to scale and diversity, the role of the data distribution is less understood. We systematically examine how curated subsets of pre-training data influence Automatic Speech Recognition (ASR) performance. Surprisingly, optimizing for acoustic, speaker, or linguistic diversity yields no clear improvements over random sampling. Instead, we find that prioritizing the longest utterances achieves superior ASR results while using only half the original dataset, reducing pre-training time by 24% on a large corpora. These findings suggest that for pre-training speech SSL models, data length is a more critical factor than either data diversity or overall data quantity for performance and efficiency, offering a new perspective for data selection strategies in SSL speech processing.", "AI": {"tldr": "研究了预训练自监督语音模型的数据选择策略，发现优先选择最长的音频片段可以提高自动语音识别性能并减少预训练时间。", "motivation": "探讨数据多样性对自监督学习语音处理的影响，并寻找更有效的数据选择策略以提升效率和性能。", "method": "通过对比不同数据选择方法（如随机采样、声学多样性优化等）来评估其对ASR性能的影响，最终选择了最长音频片段作为预训练数据。", "result": "优先选择最长的音频片段相比其他数据选择方式可以获得更好的ASR性能，并且仅使用原始数据集的一半就能减少24%的预训练时间。", "conclusion": "对于自监督学习语音模型而言，在预训练阶段数据长度比多样性或数量更重要，为未来的数据选择策略提供了新的视角和思路。"}}
{"id": "2601.20890", "pdf": "https://arxiv.org/pdf/2601.20890", "abs": "https://arxiv.org/abs/2601.20890", "authors": ["Manali Sharma", "Riya Naik", "Buvaneshwari G"], "title": "SW-ASR: A Context-Aware Hybrid ASR Pipeline for Robust Single Word Speech Recognition", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": ":I.2.7", "summary": "Single-word Automatic Speech Recognition (ASR) is a challenging task due to the lack of linguistic context and sensitivity to noise, pronunciation variation, and channel artifacts, especially in low-resource, communication-critical domains such as healthcare and emergency response. This paper reviews recent deep learning approaches and proposes a modular framework for robust single-word detection. The system combines denoising and normalization with a hybrid ASR front end (Whisper + Vosk) and a verification layer designed to handle out-of-vocabulary words and degraded audio. The verification layer supports multiple matching strategies, including embedding similarity, edit distance, and LLM-based matching with optional contextual guidance. We evaluate the framework on the Google Speech Commands dataset and a curated real-world dataset collected from telephony and messaging platforms under bandwidth-limited conditions. Results show that while the hybrid ASR front end performs well on clean audio, the verification layer significantly improves accuracy on noisy and compressed channels. Context-guided and LLM-based matching yield the largest gains, demonstrating that lightweight verification and context mechanisms can substantially improve single-word ASR robustness without sacrificing latency required for real-time telephony applications.", "AI": {"tldr": "本文提出了一种模块化的框架，用于在低资源、通信关键领域进行鲁棒的单字语音识别。", "motivation": "针对缺乏语言背景和噪声敏感等问题，在医疗保健和应急响应等领域的单词自动语音识别任务具有挑战性。为了提高这些场景下的识别准确性与鲁棒性，提出了一种结合降噪、归一化及混合前端（Whisper+Vosk）的框架，并加入验证层。", "method": "该系统首先使用混合ASR前端处理输入音频，然后通过嵌入相似度、编辑距离和LLM匹配等多种策略进行单词验证。最后在Google语音命令数据集以及真实世界的数据集中进行了实验评估。", "result": "实验证明，在干净的音频上，混合ASR前端表现良好；而在噪声或压缩通道中，则是验证层显著提升了识别准确性。特别是基于上下文和LLM的方法取得了最大的增益。", "conclusion": "轻量级验证机制可以提高单字语音识别系统的鲁棒性，并且不会牺牲实时通信应用所需的延迟要求。"}}
{"id": "2601.20884", "pdf": "https://arxiv.org/pdf/2601.20884", "abs": "https://arxiv.org/abs/2601.20884", "authors": ["Atik Faysal", "Mohammad Rostami", "Reihaneh Gh. Roshan", "Nikhil Muralidhar", "Huaxia Wang"], "title": "Finetune-Informed Pretraining Boosts Downstream Performance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal pretraining is effective for building general-purpose representations, but in many practical deployments, only one modality is heavily used during downstream fine-tuning. Standard pretraining strategies treat all modalities uniformly, which can lead to under-optimized representations for the modality that actually matters. We propose Finetune-Informed Pretraining (FIP), a model-agnostic method that biases representation learning toward a designated target modality needed at fine-tuning time. FIP combines higher masking difficulty, stronger loss weighting, and increased decoder capacity for the target modality, without modifying the shared encoder or requiring additional supervision. When applied to masked modeling on constellation diagrams for wireless signals, FIP consistently improves downstream fine-tuned performance with no extra data or compute. FIP is simple to implement, architecture-compatible, and broadly applicable across multimodal masked modeling pipelines.", "AI": {"tldr": "提出了Finetune-Informed Pretraining（FIP）方法，以优化特定模态的表现，提升下游任务性能。", "motivation": "在多模态预训练中，所有模态被同等对待可能导致实际重要的单一模态表示不足，影响下游微调效果。", "method": "FIP通过增加目标模态的掩码难度、加强损失权重和提高解码器容量来优化表征学习，并不修改共享编码器或需要额外监督。适用于无线信号星座图上的遮蔽建模等任务。", "result": "应用在无线信号星座图上时，FIP能持续提升下游微调性能，无需额外数据或计算资源。", "conclusion": "FIP方法简单、兼容多种架构，并广泛应用于多模态遮蔽建模管道中。"}}
{"id": "2601.20883", "pdf": "https://arxiv.org/pdf/2601.20883", "abs": "https://arxiv.org/abs/2601.20883", "authors": ["Bharath Krishnamurthy", "Ajita Rattani"], "title": "VoxMorph: Scalable Zero-shot Voice Identity Morphing via Disentangled Embeddings", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "comment": "Accepted to IEEE ICASSP 2026 (51st International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2026). 5 pages, 1 figure, 3 tables. Project page: https://vcbsl.github.io/VoxMorph/", "summary": "Morphing techniques generate artificial biometric samples that combine features from multiple individuals, allowing each contributor to be verified against a single enrolled template. While extensively studied in face recognition, this vulnerability remains largely unexplored in voice biometrics. Prior work on voice morphing is computationally expensive, non-scalable, and limited to acoustically similar identity pairs, constraining practical deployment. Moreover, existing sound-morphing methods target audio textures, music, or environmental sounds and are not transferable to voice identity manipulation. We propose VoxMorph, a zero-shot framework that produces high-fidelity voice morphs from as little as five seconds of audio per subject without model retraining. Our method disentangles vocal traits into prosody and timbre embeddings, enabling fine-grained interpolation of speaking style and identity. These embeddings are fused via Spherical Linear Interpolation (Slerp) and synthesized using an autoregressive language model coupled with a Conditional Flow Matching network. VoxMorph achieves state-of-the-art performance, delivering a 2.6x gain in audio quality, a 73% reduction in intelligibility errors, and a 67.8% morphing attack success rate on automated speaker verification systems under strict security thresholds. This work establishes a practical and scalable paradigm for voice morphing with significant implications for biometric security. The code and dataset are available on our project page: https://vcbsl.github.io/VoxMorph/", "AI": {"tldr": "VoxMorph是一种零样本语音身份融合方法，可以在不重新训练模型的情况下从每个主体的五秒音频中生成高质量的合成声音。", "motivation": "现有语音融合技术计算昂贵且不具备可扩展性，仅适用于音质相似的身份组合。此外，这些方法难以应用于实际部署，并且无法用于处理身份特征的声音。", "method": "VoxMorph利用分解声学特性为韵律和音色嵌入的方法实现声音合成，通过球面线性插值结合嵌入并使用条件流动匹配网络生成最终的语音样本。", "result": "该方法实现了2.6倍的音频质量提升，并将自动化说话人验证系统的识别错误率降低了73％，成功率达到67.8%。", "conclusion": "VoxMorph提供了一种实用且可扩展的方法来处理语音融合问题，在生物特征安全领域具有重要意义。"}}
{"id": "2601.20882", "pdf": "https://arxiv.org/pdf/2601.20882", "abs": "https://arxiv.org/abs/2601.20882", "authors": ["Yuheng Tang", "Kaijie Zhu", "Bonan Ruan", "Chuqi Zhang", "Michael Yang", "Hongwei Li", "Suyue Guo", "Tianneng Shi", "Zekun Li", "Christopher Kruegel", "Giovanni Vigna", "Dawn Song", "William Yang Wang", "Lun Wang", "Yangruibo Ding", "Zhenkai Liang", "Wenbo Guo"], "title": "DevOps-Gym: Benchmarking AI Agents in Software DevOps Cycle", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": null, "summary": "Even though demonstrating extraordinary capabilities in code generation and software issue resolving, AI agents' capabilities in the full software DevOps cycle are still unknown. Different from pure code generation, handling the DevOps cycle in real-world software, including developing, deploying, and managing, requires analyzing large-scale projects, understanding dynamic program behaviors, leveraging domain-specific tools, and making sequential decisions. However, existing benchmarks focus on isolated problems and lack environments and tool interfaces for DevOps. We introduce DevOps-Gym, the first end-to-end benchmark for evaluating AI agents across core DevOps workflows: build and configuration, monitoring, issue resolving, and test generation. DevOps-Gym includes 700+ real-world tasks collected from 30+ projects in Java and Go. We develop a semi-automated data collection mechanism with rigorous and non-trivial expert efforts in ensuring the task coverage and quality. Our evaluation of state-of-the-art models and agents reveals fundamental limitations: they struggle with issue resolving and test generation in Java and Go, and remain unable to handle new tasks such as monitoring and build and configuration. These results highlight the need for essential research in automating the full DevOps cycle with AI agents.", "AI": {"tldr": "DevOps-Gym是一个用于评估AI代理在软件开发运维周期全流程能力的基准工具。", "motivation": "现有的基准测试只关注孤立的问题，缺乏适用于软件开发运维流程的真实环境和工具接口。作者希望通过DevOps-Gym填补这一空白，并揭示现有模型与代理在解决复杂任务中的局限性。", "method": "构建了一个包含700多个来自30多个Java和Go项目的实际任务的基准库，用于评估AI代理处理全生命周期开发运维流程的能力。", "result": "实验表明，现有的先进模型和代理在解决软件问题、生成测试用例等方面存在困难，并且无法应对新的挑战如监控和构建配置等。", "conclusion": "这项研究揭示了使用AI自动完成整个DevOps周期中的复杂任务存在的挑战，强调了进一步研究的必要性。"}}
{"id": "2601.20881", "pdf": "https://arxiv.org/pdf/2601.20881", "abs": "https://arxiv.org/abs/2601.20881", "authors": ["Matteo Rossi"], "title": "MA-LipNet: Multi-Dimensional Attention Networks for Robust Lipreading", "categories": ["cs.CV"], "comment": null, "summary": "Lipreading, the technology of decoding spoken content from silent videos of lip movements, holds significant application value in fields such as public security. However, due to the subtle nature of articulatory gestures, existing lipreading methods often suffer from limited feature discriminability and poor generalization capabilities. To address these challenges, this paper delves into the purification of visual features from temporal, spatial, and channel dimensions. We propose a novel method named Multi-Attention Lipreading Network(MA-LipNet). The core of MA-LipNet lies in its sequential application of three dedicated attention modules. Firstly, a \\textit{Channel Attention (CA)} module is employed to adaptively recalibrate channel-wise features, thereby mitigating interference from less informative channels. Subsequently, two spatio-temporal attention modules with distinct granularities-\\textit{Joint Spatial-Temporal Attention (JSTA)} and \\textit{Separate Spatial-Temporal Attention (SSTA)}-are leveraged to suppress the influence of irrelevant pixels and video frames. The JSTA module performs a coarse-grained filtering by computing a unified weight map across the spatio-temporal dimensions, while the SSTA module conducts a more fine-grained refinement by separately modeling temporal and spatial attentions. Extensive experiments conducted on the CMLR and GRID datasets demonstrate that MA-LipNet significantly reduces the Character Error Rate (CER) and Word Error Rate (WER), validating its effectiveness and superiority over several state-of-the-art methods. Our work highlights the importance of multi-dimensional feature refinement for robust visual speech recognition.", "AI": {"tldr": "提出了一种多维度注意力网络MA-LipNet，用于改善唇读技术", "motivation": "现有唇读方法在特征判别性和泛化能力方面存在不足，导致识别效果受限。", "method": "通过三个专用的注意力模块对时域、空域和通道进行净化：通道注意模块CA调整通道特征；联合时空注意模块JSTA粗粒度过滤无关像素与帧；分离时空注意模块SSTA细化处理时空关注", "result": "实验表明，MA-LipNet在CMLR和GRID数据集上显著降低了字符错误率（CER）和单词错误率（WER），优于现有方法。", "conclusion": "多维特征精炼对于稳健的视觉语音识别至关重要"}}
{"id": "2601.20876", "pdf": "https://arxiv.org/pdf/2601.20876", "abs": "https://arxiv.org/abs/2601.20876", "authors": ["Diya Prasanth", "Matthew Tivnan"], "title": "BioNIC: Biologically Inspired Neural Network for Image Classification Using Connectomics Principles", "categories": ["cs.NE"], "comment": null, "summary": "We present BioNIC, a multi-layer feedforward neural network for emotion classification, inspired by detailed synaptic connectivity graphs from the MICrONs dataset. At a structural level, we incorporate architectural constraints derived from a single cortical column of the mouse Primary Visual Cortex(V1): connectivity imposed via adjacency masks, laminar organization, and graded inhibition representing inhibitory neurons. At the functional level, we implement biologically inspired learning: Hebbian synaptic plasticity with homeostatic regulation, Layer Normalization, data augmentation to model exposure to natural variability in sensory input, and synaptic noise to model neural stochasticity. We also include convolutional layers for spatial processing, mimicking retinotopic mapping. The model performance is evaluated on the Facial Emotion Recognition task FER-2013 and compared with a conventional baseline. Additionally, we investigate the impacts of each biological feature through a series of ablation experiments. While connectivity was limited to a single cortical column and biologically relevant connections, BioNIC achieved performance comparable to that of conventional models, with an accuracy of 59.77 $\\pm$ 0.27% on FER-2013. Our findings demonstrate that integrating constraints derived from connectomics is a computationally plausible approach to developing biologically inspired artificial intelligence systems. This work also highlights the potential of new generation peta-scale connectomics data in advancing both neuroscience modeling and artificial intelligence.", "AI": {"tldr": "BioNIC是一种受连接组学原理启发的用于图像分类的生物神经网络。", "motivation": "通过将详细突触连接图从MICrONs数据集中得到的架构约束与生物灵感学习相结合，探索基于真实脑结构和功能的人工智能系统开发的可能性。", "method": "BioNIC使用来自小鼠初级视觉皮层单一柱状单元的连接性限制，并实现Hebbian突触可塑性和分层归一化等功能。还包括卷积层用于空间处理，模拟视网膜映射。模型在FER-2013数据集上进行了评估并进行了一系列消融实验。", "result": "BioNIC在面部情感识别任务FER-2013上的准确率为59.77±0.27%，与传统基线相比表现相当。", "conclusion": "该研究证明了将源自连接组学的约束整合到人工智能系统中的方法是计算上可行且有效的，这为下一代脑科学研究和人工智能应用提供了新的视角。"}}
{"id": "2601.20870", "pdf": "https://arxiv.org/pdf/2601.20870", "abs": "https://arxiv.org/abs/2601.20870", "authors": ["Matteo Gianferrari", "Omayma Moussadek", "Riccardo Salami", "Cosimo Fiorini", "Lorenzo Tartarini", "Daniela Gandolfi", "Simone Calderara"], "title": "STAER: Temporal Aligned Rehearsal for Continual Spiking Neural Network", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs) are inherently suited for continuous learning due to their event-driven temporal dynamics; however, their application to Class-Incremental Learning (CIL) has been hindered by catastrophic forgetting and the temporal misalignment of spike patterns. In this work, we introduce Spiking Temporal Alignment with Experience Replay (STAER), a novel framework that explicitly preserves temporal structure to bridge the performance gap between SNNs and ANNs. Our approach integrates a differentiable Soft-DTW alignment loss to maintain spike timing fidelity and employs a temporal expansion and contraction mechanism on output logits to enforce robust representation learning. Implemented on a deep ResNet19 spiking backbone, STAER achieves state-of-the-art performance on Sequential-MNIST and Sequential-CIFAR10. Empirical results demonstrate that our method matches or outperforms strong ANN baselines (ER, DER++) while preserving biologically plausible dynamics. Ablation studies further confirm that explicit temporal alignment is critical for representational stability, positioning STAER as a scalable solution for spike-native lifelong learning. Code is available at https://github.com/matteogianferrari/staer.", "AI": {"tldr": "STAER是一种用于连续学习的脉冲神经网络框架，通过软DTW对齐损失和时间扩展机制来保持脉冲模式的时间结构。", "motivation": "脉冲神经网络（SNN）在事件驱动的时间动态方面具有优势，但其应用于类增量学习时会受到灾难性遗忘和脉冲模式时间错位的影响。", "method": "引入了软DTW对齐损失来保持脉冲时间的准确性，并通过输出逻辑上的时间扩展机制强制执行鲁棒表示学习。该方法在ResNet19上实现，提高了SNN在连续任务中的表现。", "result": "STAER在Sequential-MNIST和Sequential-CIFAR10数据集上实现了最先进的性能，同时保持了生物合理性，并且超过了ANN基线（ER、DER++）的表现。", "conclusion": "实验结果表明，显式的时间对齐对于表示稳定性至关重要，STAER为脉冲原生的终身学习提供了一个可扩展的解决方案。"}}
{"id": "2601.20869", "pdf": "https://arxiv.org/pdf/2601.20869", "abs": "https://arxiv.org/abs/2601.20869", "authors": ["M. A. Rasel", "Sameem Abdul Kareem", "Unaizah Obaidellah"], "title": "Integrating Color Histogram Analysis and Convolutional Neural Network for Skin Lesion Classification", "categories": ["q-bio.QM", "cs.AI", "eess.IV"], "comment": "ef:Computers in Biology and Medicine (2024), 109250", "summary": "The color of skin lesions is an important diagnostic feature for identifying malignant melanoma and other skin diseases. Typical colors associated with melanocytic lesions include tan, brown, black, red, white, and blue gray. This study introduces a novel feature: the number of colors present in a lesion, which can indicate the severity of disease and help distinguish melanomas from benign lesions. We propose a color histogram analysis method to examine lesion pixel values from three publicly available datasets: PH2, ISIC2016, and Med Node. The PH2 dataset contains ground truth annotations of lesion colors, while ISIC2016 and Med Node do not; our algorithm estimates the ground truth using color histogram analysis based on PH2. We then design and train a 19 layer Convolutional Neural Network (CNN) with residual skip connections to classify lesions into three categories based on the number of colors present. DeepDream visualization is used to interpret features learned by the network, and multiple CNN configurations are tested. The best model achieves a weighted F1 score of 75 percent. LIME is applied to identify important regions influencing model decisions. The results show that the number of colors in a lesion is a significant feature for describing skin conditions, and the proposed CNN with three skip connections demonstrates strong potential for clinical diagnostic support.", "AI": {"tldr": "本文提出了一种结合颜色直方图分析和卷积神经网络的方法，用于皮肤病变分类。", "motivation": "皮肤病变的颜色是诊断恶性黑色素瘤和其他皮肤病的重要特征。通过引入一种新的特征——病灶中的颜色数量可以指示疾病的严重程度，并帮助区分恶性病变与良性病变。", "method": "本文提出了一种颜色直方图分析方法，用于评估来自三个公开数据集的病变像素值：PH2、ISIC2016和Med Node。该算法基于PH2的数据估计了其他两个无标注数据集的真实标签。设计并训练了一个具有残差跳跃连接的19层卷积神经网络来根据颜色数量将病变分类为三类。", "result": "最佳模型在加权F1分数上达到了75%。通过DeepDream可视化和LIME技术，确定了模型决策的关键区域。", "conclusion": "研究结果表明，病灶中的颜色数量是一种描述皮肤状况的重要特征，并且所提出的卷积神经网络显示了较强的临床诊断支持潜力。"}}
{"id": "2601.20868", "pdf": "https://arxiv.org/pdf/2601.20868", "abs": "https://arxiv.org/abs/2601.20868", "authors": ["Rongzheng Wang", "Yihong Huang", "Muquan Li", "Jiakai Li", "Di Liang", "Bob Simons", "Pei Ke", "Shuang Liang", "Ke Qin"], "title": "Rethinking LLM-Driven Heuristic Design: Generating Efficient and Specialized Solvers via Dynamics-Aware Optimization", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Large Language Models (LLMs) have advanced the field of Combinatorial Optimization through automated heuristic generation. Instead of relying on manual design, this LLM-Driven Heuristic Design (LHD) process leverages LLMs to iteratively generate and refine solvers to achieve high performance. However, existing LHD frameworks face two critical limitations: (1) Endpoint-only evaluation, which ranks solvers solely by final quality, ignoring the convergence process and runtime efficiency; (2) High adaptation costs, where distribution shifts necessitate re-adaptation to generate specialized solvers for new instance groups. To address these issues, we propose Dynamics-Aware Solver Heuristics (DASH), a framework that co-optimizes solver search mechanisms and runtime schedules guided by a convergence-aware metric, thereby identifying efficient and high-performance solvers. Furthermore, to mitigate expensive re-adaptation, DASH incorporates Profiled Library Retrieval (PLR). PLR efficiently archives specialized solvers concurrently with the evolutionary process, enabling cost-effective warm-starts for heterogeneous distributions. Experiments on four combinatorial optimization problems demonstrate that DASH improves runtime efficiency by over 3 times, while surpassing the solution quality of state-of-the-art baselines across diverse problem scales. Furthermore, by enabling profile-based warm starts, DASH maintains superior accuracy under different distributions while cutting LLM adaptation costs by over 90%.", "AI": {"tldr": "提出DASH框架以优化LLM生成的求解器，提高其效率和性能，并通过PLR降低适应成本", "motivation": "解决现有的LHD框架在评估标准和适应性上的局限性问题", "method": "利用动态感知度量进行求解器搜索机制与运行时间调度的协同优化；采用档案库检索（PLR）以减少重新适应的成本", "result": "相比基线方法，DASH在不同规模的问题上提高了3倍以上的运行效率，并且解决方案质量更高，在不同的分布条件下也表现出了优越性", "conclusion": "DASH框架能够生成高效且高质量的求解器，并通过档案库检索技术有效降低LLM的重新适应成本"}}
{"id": "2601.20867", "pdf": "https://arxiv.org/pdf/2601.20867", "abs": "https://arxiv.org/abs/2601.20867", "authors": ["Jaehyuk Jang", "Wonjun Lee", "Kangwook Ko", "Changick Kim"], "title": "Generalizable Prompt Tuning for Audio-Language Models via Semantic Expansion", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Prompt tuning has achieved remarkable progress in vision-language models (VLMs) and is recently being adopted for audio-language models (ALMs). However, its generalization ability in ALMs remains largely underexplored. We observe that conventional prompt tuning for ALMs also suffers from the Base-New Tradeoff, and we identify that this issue stems from the disrupted semantic structure of the embedding space. To address this issue, we propose Semantically Expanded Prompt Tuning (SEPT)-a plug-and-play framework that explicitly regularizes the prompt embedding space by incorporating semantic neighbors generated by large language models. SEPT introduces a novel semantic expansion loss with margin constraints that promote intra-class compactness and inter-class separability, thereby enhancing the semantic structure of the prompt embedding space. For comprehensive evaluation, we establish the first benchmark setup for prompt generalization in ALMs, covering both base-to-new generalization and cross-dataset transferability. Extensive experiments demonstrate that SEPT consistently improves generalization performance across multiple prompt tuning baselines, while maintaining computational cost during inference. Codes are available in https://github.com/jhyukjang/SEPT.", "AI": {"tldr": "本文提出了SEPT框架，通过引入语义邻居来增强音频语言模型中的提示嵌入空间的语义结构。", "motivation": "现有的提示微调方法在音频语言模型中仍然面临基础和新的数据集之间的性能折衷问题。这些问题源于提示嵌入空间中语义结构的破坏。为了克服这一挑战，提出了SEPT框架来提升这种泛化能力。", "method": "SEPT通过将由大型语言模型生成的语义邻居纳入到优化过程中，并引入了一种具有边距约束的新颖语义扩展损失函数，以促进类内的紧凑性和类间的可分离性。该方法不仅提高了提示嵌入空间的语义结构，还保持了推理过程中的计算成本。", "result": "实验结果表明，SEPT在多个基准测试中一致地改进了泛化性能，并且能够在不同模型和数据集之间进行良好的迁移。", "conclusion": "SEPT框架提供了一种有效的方法来解决音频语言模型提示微调的泛化问题，证明了其在提升嵌入空间语义结构方面的能力。"}}
{"id": "2601.20861", "pdf": "https://arxiv.org/pdf/2601.20861", "abs": "https://arxiv.org/abs/2601.20861", "authors": ["Immanuel Abdi", "Akshat Gupta", "Micah Mok", "Alexander Lu", "Nicholas Lee", "Gopala Anumanchipalli"], "title": "Evolutionary Strategies lead to Catastrophic Forgetting in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "One of the biggest missing capabilities in current AI systems is the ability to learn continuously after deployment. Implementing such continually learning systems have several challenges, one of which is the large memory requirement of gradient-based algorithms that are used to train state-of-the-art LLMs. Evolutionary Strategies (ES) have recently re-emerged as a gradient-free alternative to traditional learning algorithms and have shown encouraging performance on specific tasks in LLMs. In this paper, we perform a comprehensive analysis of ES and specifically evaluate its forgetting curves when training for an increasing number of update steps. We first find that ES is able to reach performance numbers close to GRPO for math and reasoning tasks with a comparable compute budget. However, and most importantly for continual learning, the performance gains in ES is accompanied by significant forgetting of prior abilities, limiting its applicability for training models online. We also explore the reason behind this behavior and show that the updates made using ES are much less sparse and have orders of magnitude larger $\\ell_2$ norm compared to corresponding GRPO updates, explaining the contrasting forgetting curves between the two algorithms. With this study, we aim to highlight the issue of forgetting in gradient-free algorithms like ES and hope to inspire future work to mitigate these issues.", "AI": {"tldr": "该论文分析了进化策略在LLM训练中的遗忘曲线，并发现其在持续学习中存在显著的前知识遗忘问题。", "motivation": "当前AI系统缺乏在部署后继续学习的能力，而基于梯度的方法需要大量内存。进化策略作为无梯度替代方案，在特定任务上表现出色，但关于它在连续学习中的表现尚不清楚。", "method": "论文评估了ES和GRPO的性能及遗忘曲线，并探索了导致忘记行为的原因。", "result": "研究发现ES能接近GRPO在数学和推理任务上的表现，但伴随着显著前知识遗忘问题。这归因于ES更新具有更大的L2范数。", "conclusion": "论文揭示了无梯度算法中的遗忘问题，并希望激发未来的工作来缓解这些问题。"}}
{"id": "2601.20857", "pdf": "https://arxiv.org/pdf/2601.20857", "abs": "https://arxiv.org/abs/2601.20857", "authors": ["Hongyu Zhou", "Zisen Shao", "Sheng Miao", "Pan Wang", "Dongfeng Bai", "Bingbing Liu", "Yiyi Liao"], "title": "FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models", "categories": ["cs.CV"], "comment": "Our project page is at https://xdimlab.github.io/freefix", "summary": "Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelity. We introduce FreeFix, a fine-tuning-free approach that pushes the boundary of this trade-off by enhancing extrapolated rendering with pretrained image diffusion models. We present an interleaved 2D-3D refinement strategy, showing that image diffusion models can be leveraged for consistent refinement without relying on costly video diffusion models. Furthermore, we take a closer look at the guidance signal for 2D refinement and propose a per-pixel confidence mask to identify uncertain regions for targeted improvement. Experiments across multiple datasets show that FreeFix improves multi-frame consistency and achieves performance comparable to or surpassing fine-tuning-based methods, while retaining strong generalization ability.", "AI": {"tldr": "FreeFix通过利用预训练的图像扩散模型改进三维高斯点云插值视图的质量，而无需微调。", "motivation": "现有的神经辐射场和三维高斯点云方法在处理稀疏输入时效果不佳，并且容易产生过度拟合。为了提高视图合成的质量并保持泛化能力，作者提出了FreeFix。", "method": "FreeFix提出了一种交错的2D-3D细化策略，该策略利用图像扩散模型进行一致性改进而无需昂贵的视频扩散模型。此外，还引入了一个每像素置信度掩码来识别需要改进的不确定区域。", "result": "实验表明，FreeFix在多帧一致性和性能方面优于或与微调方法相当，并且具有更强的泛化能力。", "conclusion": "通过提出一种无需微调的方法，FreeFix能够提高三维高斯点云插值视图的质量并保持其泛化能力。"}}
{"id": "2601.20856", "pdf": "https://arxiv.org/pdf/2601.20856", "abs": "https://arxiv.org/abs/2601.20856", "authors": ["Sebastiano Monti", "Carlo Nicolini", "Gianni Pellegrini", "Jacopo Staiano", "Bruno Lepri"], "title": "SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.", "AI": {"tldr": "本论文通过Sokoban谜题评估大型语言模型的长期规划能力，并发现其在超过25步时性能显著下降。", "motivation": "为了深入探究大型语言模型的长周期规划和推理能力，作者提出了一种基于Sokoban游戏的新基准测试。", "method": "构建了一个基于简化版Sokoban谜题的任务集来评估LRMs的长期规划能力，并引入PDDL工具以提高其表现。", "result": "实验显示，当需要超过25步时，模型在长期规划任务上的性能显著下降。使用PDDL工具可以带来小幅改进。", "conclusion": "研究结果表明，大型语言模型存在固有的长周期规划能力限制，并且仅靠测试时间规模扩展方法可能无法解决这一问题。"}}
{"id": "2601.20854", "pdf": "https://arxiv.org/pdf/2601.20854", "abs": "https://arxiv.org/abs/2601.20854", "authors": ["Aníbal Silva", "Moisés Santos", "André Restivo", "Carlos Soares"], "title": "Exploring Transformer Placement in Variational Autoencoders for Tabular Data Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Tabular data remains a challenging domain for generative models. In particular, the standard Variational Autoencoder (VAE) architecture, typically composed of multilayer perceptrons, struggles to model relationships between features, especially when handling mixed data types. In contrast, Transformers, through their attention mechanism, are better suited for capturing complex feature interactions. In this paper, we empirically investigate the impact of integrating Transformers into different components of a VAE. We conduct experiments on 57 datasets from the OpenML CC18 suite and draw two main conclusions. First, results indicate that positioning Transformers to leverage latent and decoder representations leads to a trade-off between fidelity and diversity. Second, we observe a high similarity between consecutive blocks of a Transformer in all components. In particular, in the decoder, the relationship between the input and output of a Transformer is approximately linear.", "AI": {"tldr": "探索将Transformer集成到变分自编码器的不同组件中的影响，以生成表格数据。", "motivation": "传统的VAE架构难以处理表征之间的关系和混合数据类型。Transformers通过注意力机制能够更好地捕捉复杂特征交互。", "method": "在57个来自OpenML CC18的数据集上进行实验，探讨Transformer在不同组件中的放置效果及其对生成模型性能的影响。", "result": "结论表明，在利用潜在表示和解码器表示时，使用Transformers存在保真度与多样性之间的权衡。此外，观察到所有组件中连续Transformer块的高度相似性，特别是在解码器部分，输入和输出之间关系近似线性。", "conclusion": "在VAE的不同组件中引入Transformer可以改善复杂特征交互的建模，但需注意生成模型的保真度与多样性之间的权衡。"}}
{"id": "2601.20852", "pdf": "https://arxiv.org/pdf/2601.20852", "abs": "https://arxiv.org/abs/2601.20852", "authors": ["Hao Sun", "Da-Wei Zhou"], "title": "C3Box: A CLIP-based Class-Incremental Learning Toolbox", "categories": ["cs.LG", "cs.CV"], "comment": "The code is available at https://github.com/LAMDA-CL/C3Box", "summary": "Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams. Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge. With the rise of pre-trained models (PTMs) such as CLIP, leveraging their strong generalization and semantic alignment capabilities has become a promising direction in CIL. However, existing CLIP-based CIL methods are often scattered across disparate codebases, rely on inconsistent configurations, hindering fair comparisons, reproducibility, and practical adoption. Therefore, we propose C3Box (CLIP-based Class-inCremental learning toolBOX), a modular and comprehensive Python toolbox. C3Box integrates representative traditional CIL methods, ViT-based CIL methods, and state-of-the-art CLIP-based CIL methods into a unified CLIP-based framework. By inheriting the streamlined design of PyCIL, C3Box provides a JSON-based configuration and standardized execution pipeline. This design enables reproducible experimentation with low engineering overhead and makes C3Box a reliable benchmark platform for continual learning research. Designed to be user-friendly, C3Box relies only on widely used open-source libraries and supports major operating systems. The code is available at https://github.com/LAMDA-CL/C3Box.", "AI": {"tldr": "C3Box是一款基于CLIP的增量学习工具箱，整合了传统和最先进的CIL方法，提供了可重复实验的标准框架。", "motivation": "现有的CLIP-based CIL方法分散在不同的代码库中，配置不一致，阻碍了公平比较、重现实验和实际应用。因此开发一个统一且易于使用的工具箱是必要的。", "method": "C3Box通过集成各种代表性CIL方法到基于CLIP的框架中，并采用PyCIL的设计理念提供JSON配置和标准化执行流水线，实现了模块化、可重复性实验。", "result": "该工具箱降低了工程开销，成为持续学习研究中的可靠基准平台。", "conclusion": "C3Box作为用户友好的Python库，依赖于广泛使用的开源库，并支持主流操作系统。"}}
{"id": "2601.20848", "pdf": "https://arxiv.org/pdf/2601.20848", "abs": "https://arxiv.org/abs/2601.20848", "authors": ["Weixin Chen", "Li Chen", "Yuhan Zhao"], "title": "Post-Training Fairness Control: A Single-Train Framework for Dynamic Fairness in Recommendation", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.IR"], "comment": "Accepted to WWW 2026 Workshop on HCRS (Oral Presentation)", "summary": "Despite growing efforts to mitigate unfairness in recommender systems, existing fairness-aware methods typically fix the fairness requirement at training time and provide limited post-training flexibility. However, in real-world scenarios, diverse stakeholders may demand differing fairness requirements over time, so retraining for different fairness requirements becomes prohibitive. To address this limitation, we propose Cofair, a single-train framework that enables post-training fairness control in recommendation. Specifically, Cofair introduces a shared representation layer with fairness-conditioned adapter modules to produce user embeddings specialized for varied fairness levels, along with a user-level regularization term that guarantees user-wise monotonic fairness improvements across these levels. We theoretically establish that the adversarial objective of Cofair upper bounds demographic parity and the regularization term enforces progressive fairness at user level. Comprehensive experiments on multiple datasets and backbone models demonstrate that our framework provides dynamic fairness at different levels, delivering comparable or better fairness-accuracy curves than state-of-the-art baselines, without the need to retrain for each new fairness requirement. Our code is publicly available at https://github.com/weixinchen98/Cofair.", "AI": {"tldr": "本文提出了一种名为Cofair的单一训练框架，旨在实现推荐系统中的动态公平性控制。", "motivation": "当前存在的公平性感知方法通常在训练期间固定了公平性的需求，并且提供有限的后训练灵活性。然而，在现实场景中，不同的利益相关者可能随时间提出不同的公平性要求，重新训练变得不切实际。", "method": "Cofair引入了一个共享表示层和基于条件适配器模块的用户嵌入生成方式，该方法能够根据不同公平水平产生专业化用户嵌入，并通过一个用户级正则化项确保在不同公平层次之间逐步提高用户的公平性。", "result": "实验表明，本文提出的框架能够在不同的公平层级上提供动态公平性，并且与最先进的基线相比，在不重新训练的情况下提供了可比或更好的公平性和准确性曲线。", "conclusion": "Cofair为解决推荐系统中的动态公平性需求提供了一种有效的单一训练框架。"}}
{"id": "2601.20847", "pdf": "https://arxiv.org/pdf/2601.20847", "abs": "https://arxiv.org/abs/2601.20847", "authors": ["Willams de Lima Costa", "Thifany Ketuli Silva de Souza", "Jonas Ferreira Silva", "Carlos Gabriel Bezerra Pereira", "Bruno Reis Vila Nova", "Leonardo Silvino Brito", "Rafael Raider Leoni", "Juliano Silva Filho", "Valter Ferreira", "Sibele Miguel Soares Neto", "Samantha Uehara", "Daniel Giacometti Amaral", "João Marcelo Teixeira", "Veronica Teichrieb", "Cristiano Coelho de Araújo"], "title": "A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Road surface classification (RSC) is a key enabler for environment-aware predictive maintenance systems. However, existing RSC techniques often fail to generalize beyond narrow operational conditions due to limited sensing modalities and datasets that lack environmental diversity. This work addresses these limitations by introducing a multimodal framework that fuses images and inertial measurements using a lightweight bidirectional cross-attention module followed by an adaptive gating layer that adjusts modality contributions under domain shifts. Given the limitations of current benchmarks, especially regarding lack of variability, we introduce ROAD, a new dataset composed of three complementary subsets: (i) real-world multimodal recordings with RGB-IMU streams synchronized using a gold-standard industry datalogger, captured across diverse lighting, weather, and surface conditions; (ii) a large vision-only subset designed to assess robustness under adverse illumination and heterogeneous capture setups; and (iii) a synthetic subset generated to study out-of-distribution generalization in scenarios difficult to obtain in practice. Experiments show that our method achieves a +1.4 pp improvement over the previous state-of-the-art on the PVS benchmark and an +11.6 pp improvement on our multimodal ROAD subset, with consistently higher F1-scores on minority classes. The framework also demonstrates stable performance across challenging visual conditions, including nighttime, heavy rain, and mixed-surface transitions. These findings indicate that combining affordable camera and IMU sensors with multimodal attention mechanisms provides a scalable, robust foundation for road surface understanding, particularly relevant for regions where environmental variability and cost constraints limit the adoption of high-end sensing suites.", "AI": {"tldr": "本文提出了一种基于相机和惯性测量单元融合的新框架，用于道路表面分类。", "motivation": "现有的道路表面分类技术由于传感模态有限和数据集缺乏环境多样性而难以泛化到不同操作条件。因此，作者提出了一个新方法以克服这些限制。", "method": "引入了一种轻量级的双向交叉注意力模块结合自适应门控层来融合图像和惯性测量，以此构建一个新的多模式框架。同时创建了一个新的ROAD数据集来评估其性能。", "result": "在PVS基准上比现有最佳方法提高了1.4个百分点，在ROAD多模态子集中提高了11.6个百分点，并且对于少数类别的F1分数更高。", "conclusion": "结合低成本相机和IMU传感器以及多模态注意机制，提供了适用于环境多样性和成本约束区域的可扩展、稳健的道路表面理解基础。"}}
{"id": "2601.20846", "pdf": "https://arxiv.org/pdf/2601.20846", "abs": "https://arxiv.org/abs/2601.20846", "authors": ["Jamie Hathaway", "Alireza Rastegarpanah", "Rustam Stolkin"], "title": "End-to-end example-based sim-to-real RL policy transfer based on neural stylisation with application to robotic cutting", "categories": ["cs.RO"], "comment": "14 pages, 9 figures. Submitted to Nature Scientific Reports", "summary": "Whereas reinforcement learning has been applied with success to a range of robotic control problems in complex, uncertain environments, reliance on extensive data - typically sourced from simulation environments - limits real-world deployment due to the domain gap between simulated and physical systems, coupled with limited real-world sample availability. We propose a novel method for sim-to-real transfer of reinforcement learning policies, based on a reinterpretation of neural style transfer from image processing to synthesise novel training data from unpaired unlabelled real world datasets. We employ a variational autoencoder to jointly learn self-supervised feature representations for style transfer and generate weakly paired source-target trajectories to improve physical realism of synthesised trajectories. We demonstrate the application of our approach based on the case study of robot cutting of unknown materials. Compared to baseline methods, including our previous work, CycleGAN, and conditional variational autoencoder-based time series translation, our approach achieves improved task completion time and behavioural stability with minimal real-world data. Our framework demonstrates robustness to geometric and material variation, and highlights the feasibility of policy adaptation in challenging contact-rich tasks where real-world reward information is unavailable.", "AI": {"tldr": "本论文提出了一种基于神经样式迁移的端到端仿真到现实的强化学习策略转移方法，用于机器人切割任务。", "motivation": "由于从模拟环境获取的数据量庞大且存在仿真实验与物理系统的域差距，限制了强化学习在实际应用中的部署。因此，本论文旨在通过一种新颖的方法减少这种依赖并提高策略的实际适应性。", "method": "本文使用变分自编码器来共同学习自我监督特征表示和生成源目标轨迹对，并采用神经样式迁移技术从未标记的真实世界数据集中合成训练数据，以此改进模拟到现实的强化学习政策转移。", "result": "相较于基线方法，包括CycleGAN和条件变分自动编码器时间序列转换等，该方法在任务完成时间和行为稳定性上表现更好，在仅有少量真实世界数据的情况下也实现了这一目标，并且对几何和材料变化具有鲁棒性。", "conclusion": "本文提出的方法展示了其在挑战性的接触密集型任务中适应政策的能力，特别是在没有实际回报信息可用时的可行性。"}}
{"id": "2601.20844", "pdf": "https://arxiv.org/pdf/2601.20844", "abs": "https://arxiv.org/abs/2601.20844", "authors": ["Zihao Wang", "Hang Yin", "Lihui Liu", "Hanghang Tong", "Yangqiu Song", "Ginny Wong", "Simon See"], "title": "$\\mathbb{R}^{2k}$ is Theoretically Large Enough for Embedding-based Top-$k$ Retrieval", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": "v2: fix broken citation", "summary": "This paper studies the minimal dimension required to embed subset memberships ($m$ elements and ${m\\choose k}$ subsets of at most $k$ elements) into vector spaces, denoted as Minimal Embeddable Dimension (MED). The tight bounds of MED are derived theoretically and supported empirically for various notions of \"distances\" or \"similarities,\" including the $\\ell_2$ metric, inner product, and cosine similarity. In addition, we conduct numerical simulation in a more achievable setting, where the ${m\\choose k}$ subset embeddings are chosen as the centroid of the embeddings of the contained elements. Our simulation easily realizes a logarithmic dependency between the MED and the number of elements to embed. These findings imply that embedding-based retrieval limitations stem primarily from learnability challenges, not geometric constraints, guiding future algorithm design.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.20843", "pdf": "https://arxiv.org/pdf/2601.20843", "abs": "https://arxiv.org/abs/2601.20843", "authors": ["Saurav Prateek"], "title": "Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)", "categories": ["cs.AI"], "comment": "11 pages, 6 figures, 2 tables, source code: https://github.com/SauravP97/deep-researcher-reflect-evolve/", "summary": "This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.", "AI": {"tldr": "介绍了一种新的深度研究员架构，用于生成复杂的博士级研究报告。", "motivation": "解决并行扩展范式固有的限制，通过引入顺序计划反思和候选者交叉算法来改进研究报告的生成过程。", "method": "采用顺序研究计划细化并通过反思动态调整全局研究上下文，利用候选人交叉算法提高搜索效率，并进行一次性的报告生成。", "result": "在DeepResearch Bench测试中达到了46.21的成绩，超过了其他领先的深度研究员系统。", "conclusion": "证明了顺序扩展范式优于并行自洽性范式，在复杂的博士级研究任务上表现更优。"}}
{"id": "2601.20838", "pdf": "https://arxiv.org/pdf/2601.20838", "abs": "https://arxiv.org/abs/2601.20838", "authors": ["Brian Christian", "Jessica A. F. Thompson", "Elle Michelle Yang", "Vincent Adam", "Hannah Rose Kirk", "Christopher Summerfield", "Tsvetomira Dumbalska"], "title": "Reward Models Inherit Value Biases from Pretraining", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Reward models (RMs) are central to aligning large language models (LLMs) with human values but have received less attention than pre-trained and post-trained LLMs themselves. Because RMs are initialized from LLMs, they inherit representations that shape their behavior, but the nature and extent of this influence remain understudied. In a comprehensive study of 10 leading open-weight RMs using validated psycholinguistic corpora, we show that RMs exhibit significant differences along multiple dimensions of human value as a function of their base model. Using the \"Big Two\" psychological axes, we show a robust preference of Llama RMs for \"agency\" and a corresponding robust preference of Gemma RMs for \"communion.\" This phenomenon holds even when the preference data and finetuning process are identical, and we trace it back to the logits of the respective instruction-tuned and pre-trained models. These log-probability differences themselves can be formulated as an implicit RM; we derive usable implicit reward scores and show that they exhibit the very same agency/communion difference. We run experiments training RMs with ablations for preference data source and quantity, which demonstrate that this effect is not only repeatable but surprisingly durable. Despite RMs being designed to represent human preferences, our evidence shows that their outputs are influenced by the pretrained LLMs on which they are based. This work underscores the importance of safety and alignment efforts at the pretraining stage, and makes clear that open-source developers' choice of base model is as much a consideration of values as of performance.", "AI": {"tldr": "研究论文探讨了奖励模型从预训练中继承的价值偏差。", "motivation": "强调了理解奖励模型如何受到预训练语言模型影响的重要性，尤其是这些模型在反映人类价值观上的偏见。", "method": "通过使用验证的心理语言学语料库，对10种领先的开放权重奖励模型进行了全面研究。利用“Big Two”心理学轴来展示不同基线模型的显著差异，并跟踪这种影响至预训练模型的日志概率差异中。", "result": "发现Llama奖励模型倾向于“代理”，而Gemma奖励模型则更偏好于“归属感”。这些偏见即使在使用相同的偏好数据和微调过程时也仍然存在，表明这种影响非常持久且难以消除。", "conclusion": "研究表明，尽管奖励模型旨在表示人类偏好，但它们的输出依然受到所基于的预训练语言模型的影响。这强调了在预训练阶段的安全性和对齐努力的重要性，并指出开源开发者的基线选择不仅是性能问题，也是价值取向的问题。"}}
{"id": "2601.20835", "pdf": "https://arxiv.org/pdf/2601.20835", "abs": "https://arxiv.org/abs/2601.20835", "authors": ["Jie Liu", "Yu Sun", "Alpar Cseke", "Yao Feng", "Nicolas Heron", "Michael J. Black", "Yan Zhang"], "title": "Open-Vocabulary Functional 3D Human-Scene Interaction Generation", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages", "summary": "Generating 3D humans that functionally interact with 3D scenes remains an open problem with applications in embodied AI, robotics, and interactive content creation. The key challenge involves reasoning about both the semantics of functional elements in 3D scenes and the 3D human poses required to achieve functionality-aware interaction. Unfortunately, existing methods typically lack explicit reasoning over object functionality and the corresponding human-scene contact, resulting in implausible or functionally incorrect interactions. In this work, we propose FunHSI, a training-free, functionality-driven framework that enables functionally correct human-scene interactions from open-vocabulary task prompts. Given a task prompt, FunHSI performs functionality-aware contact reasoning to identify functional scene elements, reconstruct their 3D geometry, and model high-level interactions via a contact graph. We then leverage vision-language models to synthesize a human performing the task in the image and estimate proposed 3D body and hand poses. Finally, the proposed 3D body configuration is refined via stage-wise optimization to ensure physical plausibility and functional correctness. In contrast to existing methods, FunHSI not only synthesizes more plausible general 3D interactions, such as \"sitting on a sofa'', while supporting fine-grained functional human-scene interactions, e.g., \"increasing the room temperature''. Extensive experiments demonstrate that FunHSI consistently generates functionally correct and physically plausible human-scene interactions across diverse indoor and outdoor scenes.", "AI": {"tldr": "提出了一种无需训练的功能性人类场景交互生成框架FunHSI，用于根据开放词汇任务提示生成功能正确的三维人与环境互动。", "motivation": "现有方法缺乏对物体功能和相应的人体-环境接触的显式推理，导致生成的互动不真实或功能性错误。此研究旨在解决这一问题，并支持细粒度的功能性人类场景交互。", "method": "FunHSI框架通过功能感知接触推理识别功能性场景元素，重建其三维几何形状，并使用接触图建模高层次互动生成人体在执行任务时的行为和估计提议的3D身体及手部姿态。最后，该配置通过阶段优化确保物理真实性和功能性正确性。", "result": "实验显示FunHSI能够生成功能正确的物理逼真的互动，适用于各种室内和室外场景，并支持诸如“增加房间温度”等细粒度的功能性人与环境交互。", "conclusion": "FunHSI框架解决了现有方法在生成三维人类与环境互动时的局限性问题，实现了更真实、更多样化的功能性互动。"}}
{"id": "2601.20831", "pdf": "https://arxiv.org/pdf/2601.20831", "abs": "https://arxiv.org/abs/2601.20831", "authors": ["Vishnu Sashank Dorbala", "Dinesh Manocha"], "title": "MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.", "AI": {"tldr": "MemCtrl使用多模态大型语言模型作为内存控制器，为具身代理优化在线决策过程。", "motivation": "现有系统通常将记忆视为离线存储空间，不适用于计算和内存受限的在线运行环境中的具身智能体。因此提出了MemCtrl框架以解决这一问题。", "method": "通过使用多模态大型语言模型并添加可训练的记忆头μ来决定在探索过程中保留、更新或丢弃哪些观察结果或反思。评估了两种类型的记忆头μ，一种是基于离线专家的，另一种是在线强化学习的。", "result": "实验结果显示，在EmbodiedBench基准上的多个子集上，MemCtrl增强了低性能多模态语言模型的表现，平均提升了约16%，某些指令集合中的提升超过20%。", "conclusion": "通过使用可训练的记忆头μ来控制内存保留策略，可以显著提高具身智能体完成任务的能力，并且对复杂和长命令的处理表现尤为出色。"}}
{"id": "2601.20829", "pdf": "https://arxiv.org/pdf/2601.20829", "abs": "https://arxiv.org/abs/2601.20829", "authors": ["Minwu Kim", "Safal Shrestha", "Keith Ross"], "title": "Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "16 pages", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has substantially improved the reasoning abilities of large language models (LLMs), yet training often stalls as problems become saturated. We identify the core challenge as the poor accessibility of informative failures: learning signals exist but are rarely encountered during standard rollouts. To address this, we propose failure-prefix conditioning, a simple and effective method for learning from saturated problems. Rather than starting from the original question, our approach reallocates exploration by conditioning training on prefixes derived from rare incorrect reasoning trajectories, thereby exposing the model to failure-prone states. We observe that failure-prefix conditioning yields performance gains matching those of training on medium-difficulty problems, while preserving token efficiency. Furthermore, we analyze the model's robustness, finding that our method reduces performance degradation under misleading failure prefixes, albeit with a mild trade-off in adherence to correct early reasoning. Finally, we demonstrate that an iterative approach, which refreshes failure prefixes during training, unlocks additional gains after performance plateaus. Overall, our results suggest that failure-prefix conditioning offers an effective pathway to extend RLVR training on saturated problems.", "AI": {"tldr": "本文提出了失败前缀条件化方法，旨在解决大规模语言模型在饱和问题上的训练瓶颈。", "motivation": "强化学习结合可验证奖励（RLVR）虽然提升了大模型的推理能力，但随着任务难度增加训练效果开始停滞不前。主要原因在于信息性故障出现频率低导致学习信号稀疏。", "method": "提出失败前缀条件化方法，在训练过程中通过错误轨迹的前缀来重新分配探索范围，从而让模型能够接触到容易出错的状态。", "result": "该方法能有效提升饱和问题上的性能表现，并且保持了token效率。实验还显示迭代刷新失败前缀进一步提高了模型在遇到误导性故障时的鲁棒性和早期推理准确性之间的权衡。", "conclusion": "研究结果表明，失败前缀条件化为扩展RLVR训练提供了一条有效路径，在饱和问题上表现良好且具有较高的适用价值。"}}
{"id": "2601.20815", "pdf": "https://arxiv.org/pdf/2601.20815", "abs": "https://arxiv.org/abs/2601.20815", "authors": ["Steve Azzolin", "Stefano Teso", "Bruno Lepri", "Andrea Passerini", "Sagar Malhotra"], "title": "GNN Explanations that do not Explain and How to find Them", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Explanations provided by Self-explainable Graph Neural Networks (SE-GNNs) are fundamental for understanding the model's inner workings and for identifying potential misuse of sensitive attributes. Although recent works have highlighted that these explanations can be suboptimal and potentially misleading, a characterization of their failure cases is unavailable. In this work, we identify a critical failure of SE-GNN explanations: explanations can be unambiguously unrelated to how the SE-GNNs infer labels. We show that, on the one hand, many SE-GNNs can achieve optimal true risk while producing these degenerate explanations, and on the other, most faithfulness metrics can fail to identify these failure modes. Our empirical analysis reveals that degenerate explanations can be maliciously planted (allowing an attacker to hide the use of sensitive attributes) and can also emerge naturally, highlighting the need for reliable auditing. To address this, we introduce a novel faithfulness metric that reliably marks degenerate explanations as unfaithful, in both malicious and natural settings. Our code is available in the supplemental.", "AI": {"tldr": "本文探讨了自我解释图神经网络（SE-GNN）中不相关或误导性解释的问题，并提出一种新的忠实度指标来识别这些问题。", "motivation": "尽管已有研究指出SE-GNN的解释可能不尽如人意甚至具有误导性，但尚未充分了解这些失败案例的特点。文章旨在揭示一个关键问题：SE-GNN的解释可能与模型如何推断标签无关，并提出解决方法。", "method": "通过实证分析，作者发现许多SE-GNN在产生不相关或恶意植入的解释时仍能达到最优性能。此外，现有忠实度指标往往无法检测这些失败模式。因此，他们引入了一种新的忠实度衡量标准来识别这些问题，无论是自然发生还是被恶意种植的情况。", "result": "研究表明，某些SE-GNN可以在生成非相关解释的同时达到最佳性能，并且大多数现有忠实性评估工具也无法发现这类问题。", "conclusion": "研究强调了对自我解释图神经网络的可靠审计的需求，提出了一种新的方法来识别不准确和潜在误导性的解释。"}}
{"id": "2601.20802", "pdf": "https://arxiv.org/pdf/2601.20802", "abs": "https://arxiv.org/abs/2601.20802", "authors": ["Jonas Hübotter", "Frederike Lübeck", "Lejs Behric", "Anton Baumann", "Marco Bagatella", "Daniel Marta", "Ido Hakimi", "Idan Shenfeld", "Thomas Kleine Buening", "Carlos Guestrin", "Andreas Krause"], "title": "Reinforcement Learning via Self-Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models are increasingly post-trained with reinforcement learning in verifiable domains such as code and math. Yet, current methods for reinforcement learning with verifiable rewards (RLVR) learn only from a scalar outcome reward per attempt, creating a severe credit-assignment bottleneck. Many verifiable environments actually provide rich textual feedback, such as runtime errors or judge evaluations, that explain why an attempt failed. We formalize this setting as reinforcement learning with rich feedback and introduce Self-Distillation Policy Optimization (SDPO), which converts tokenized feedback into a dense learning signal without any external teacher or explicit reward model. SDPO treats the current model conditioned on feedback as a self-teacher and distills its feedback-informed next-token predictions back into the policy. In this way, SDPO leverages the model's ability to retrospectively identify its own mistakes in-context. Across scientific reasoning, tool use, and competitive programming on LiveCodeBench v6, SDPO improves sample efficiency and final accuracy over strong RLVR baselines. Notably, SDPO also outperforms baselines in standard RLVR environments that only return scalar feedback by using successful rollouts as implicit feedback for failed attempts. Finally, applying SDPO to individual questions at test time accelerates discovery on difficult binary-reward tasks, achieving the same discovery probability as best-of-k sampling or multi-turn conversations with 3x fewer attempts.", "AI": {"tldr": "该论文提出了一种基于自蒸馏策略优化的方法（SDPO），用于解决强化学习中利用丰富反馈信息的问题，提升了模型在代码和数学等领域中的样本效率和准确性。", "motivation": "当前的强化学习方法仅从每次尝试后的标量结果奖励学习，导致严重的信用分配瓶颈。然而许多环境中提供了丰富的文本反馈信息，可以解释为什么某个尝试失败了，这为改进学习过程提供了可能。", "method": "论文提出了自蒸馏策略优化（SDPO）的方法，利用当前模型基于反馈作为自我教师来转换分词后的反馈信息成密集的学习信号。通过将模型的错误回顾识别能力与政策相结合，该方法能够显著提升样本效率和准确性。", "result": "在科学推理、工具使用以及LiveCodeBench v6上的竞争编程任务中，SDPO比现有的强化学习基准线表现出更高的样本效率和最终准确率。此外，在仅返回标量反馈的标准环境上，SDPO也优于基线方法，并且测试时应用于单独问题可以加速发现过程。", "conclusion": "通过自蒸馏策略优化（SDPO），该论文成功地利用了模型在特定上下文中识别自己错误的能力，从而提高了强化学习任务中的样本效率和准确性。"}}
{"id": "2601.20800", "pdf": "https://arxiv.org/pdf/2601.20800", "abs": "https://arxiv.org/abs/2601.20800", "authors": ["Kaito Baba", "Yoshihiko Ozaki", "Shuhei Watanabe"], "title": "Conditional PED-ANOVA: Hyperparameter Importance in Hierarchical & Dynamic Search Spaces", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 9 figures", "summary": "We propose conditional PED-ANOVA (condPED-ANOVA), a principled framework for estimating hyperparameter importance (HPI) in conditional search spaces, where the presence or domain of a hyperparameter can depend on other hyperparameters. Although the original PED-ANOVA provides a fast and efficient way to estimate HPI within the top-performing regions of the search space, it assumes a fixed, unconditional search space and therefore cannot properly handle conditional hyperparameters. To address this, we introduce a conditional HPI for top-performing regions and derive a closed-form estimator that accurately reflects conditional activation and domain changes. Experiments show that naive adaptations of existing HPI estimators yield misleading or uninterpretable importance estimates in conditional settings, whereas condPED-ANOVA consistently provides meaningful importances that reflect the underlying conditional structure.", "AI": {"tldr": "提出了一种在条件搜索空间中估计超参数重要性的框架，称为条件PED-ANOVA。", "motivation": "原有的PED-ANOVA方法假设固定不变的无条件搜索空间，无法正确处理条件超参数。为此引入了针对顶级性能区域的重要性估计。", "method": "提出了一个封闭形式的重要度估计器，准确反映条件激活和域的变化。", "result": "实验表明，在条件设置下现有重要性估计器的简单改编会产生误导性的结果，而condPED-ANOVA始终提供有意义的重要度，反映了基础的条件结构。", "conclusion": "通过引入新的方法解决了传统方法在处理条件超参数时存在的问题。"}}
{"id": "2601.20797", "pdf": "https://arxiv.org/pdf/2601.20797", "abs": "https://arxiv.org/abs/2601.20797", "authors": ["Guillermo GP-Lenza", "Carmen DR. Pita-Romero", "Miguel Fernandez-Cortizas", "Pascual Campoy"], "title": "A Methodology for Designing Knowledge-Driven Missions for Robots", "categories": ["cs.RO"], "comment": "ef:2024 7th Iberian Robotics Conference (ROBOT)", "summary": "This paper presents a comprehensive methodology for implementing knowledge graphs in ROS 2 systems, aiming to enhance the efficiency and intelligence of autonomous robotic missions. The methodology encompasses several key steps: defining initial and target conditions, structuring tasks and subtasks, planning their sequence, representing task-related data in a knowledge graph, and designing the mission using a high-level language. Each step builds on the previous one to ensure a cohesive process from initial setup to final execution. A practical implementation within the Aerostack2 framework is demonstrated through a simulated search and rescue mission in a Gazebo environment, where drones autonomously locate a target. This implementation highlights the effectiveness of the methodology in improving decision-making and mission performance by leveraging knowledge graphs.", "AI": {"tldr": "设计一种基于知识图谱的机器人自主任务方法论", "motivation": "为了提高ROS 2系统中自主机器人的效率和智能性，提出了在该系统中实施知识图的方法论。", "method": "包括定义初始条件与目标、结构化任务及子任务、规划执行顺序、用知识图表示任务相关数据以及使用高级语言设计任务等步骤。各个步骤相互依赖确保整个过程从初步设置到最终执行的连贯性。", "result": "通过Aerostack2框架在Gazebo环境中模拟搜救无人机自主定位目标的任务，展示了该方法论的有效性及其提高决策和任务性能的能力。", "conclusion": "知识图谱的应用显著提升了基于ROS 2系统的机器人自主任务的设计与执行效率。"}}
{"id": "2601.20792", "pdf": "https://arxiv.org/pdf/2601.20792", "abs": "https://arxiv.org/abs/2601.20792", "authors": ["Thomas Brackin"], "title": "Jurisdiction as Structural Barrier: How Privacy Policy Organization May Reduce Visibility of Substantive Disclosures", "categories": ["cs.CY", "cs.CL", "cs.HC"], "comment": "25 pages, 2 figures, 5 tables", "summary": "Privacy policies are supposed to provide notice. But what if substantive information appears only where users skip it? We identify a structural pattern we call jurisdiction-siloed disclosure: information about data practices appearing in specific, actionable form only within regional compliance sections labeled \"California Residents\" or \"EU/UK Users,\" while general sections use vague or qualified language for the same practices. Our audit of 123 major companies identifies 282 potential instances across 77 companies (62.6% of this purposive sample). A conservative estimate restricted to practice categories validated against OPP-115 human annotations finds 138 instances across 54 companies (44%); post-2018 categories central to our findings await independent validation. If users skip jurisdiction-labeled sections as information foraging theory predicts, users outside regulated jurisdictions would receive less specific information about practices affecting them--a transparency failure operating through document architecture rather than omission. We propose universal substantive disclosure: practices affecting all users should appear in the main policy body, with regional sections containing only procedural rights information. This standard finds support in analogous disclosure regimes (securities, truth-in-lending, nutritional labeling) where material information must reach all affected parties. Regulators could operationalize this through the FTC's \"clear and conspicuous\" standard and GDPR transparency principles. This work is hypothesis-generating: we establish that the structural pattern exists and ground the transparency concern in behavioral theory, but direct measurement of jurisdiction-specific section skipping remains the critical validation priority. We release our methodology and annotated dataset to enable replication.", "AI": {"tldr": "研究发现隐私政策中存在一种结构性模式，即实质性的数据实践披露仅出现在特定区域合规部分，而非在通用部分明确陈述。提出了统一实质性披露标准。", "motivation": "探讨隐私政策中信息的透明度问题，提出改善策略以确保用户获得完整和准确的数据实践信息。", "method": "对123家主要公司进行审计，分析其隐私政策中的信息披露方式，并利用行为理论支持提出的假设。", "result": "发现了77家公司（62.6%）存在区域合规部分披露实质性数据实践的模式。其中44%的数据经过验证。", "conclusion": "建议所有用户相关的信息应出现在主要政策文本中，区域特定信息则仅包含程序权利信息，以提高透明度和用户知情权。"}}
{"id": "2601.20791", "pdf": "https://arxiv.org/pdf/2601.20791", "abs": "https://arxiv.org/abs/2601.20791", "authors": ["Haonan Zhong", "Wei Song", "Tingxu Han", "Maurice Pagnucco", "Jingling Xue", "Yang Song"], "title": "FAIRT2V: Training-Free Debiasing for Text-to-Video Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text-to-video (T2V) diffusion models have achieved rapid progress, yet their demographic biases, particularly gender bias, remain largely unexplored. We present FairT2V, a training-free debiasing framework for text-to-video generation that mitigates encoder-induced bias without finetuning. We first analyze demographic bias in T2V models and show that it primarily originates from pretrained text encoders, which encode implicit gender associations even for neutral prompts. We quantify this effect with a gender-leaning score that correlates with bias in generated videos. Based on this insight, FairT2V mitigates demographic bias by neutralizing prompt embeddings via anchor-based spherical geodesic transformations while preserving semantics. To maintain temporal coherence, we apply debiasing only during early identity-forming steps through a dynamic denoising schedule. We further propose a video-level fairness evaluation protocol combining VideoLLM-based reasoning with human verification. Experiments on the modern T2V model Open-Sora show that FairT2V substantially reduces demographic bias across occupations with minimal impact on video quality.", "AI": {"tldr": "本文提出了一种无需训练即可减轻文本到视频扩散模型性别偏见的框架FAIRT2V。", "motivation": "随着文本到视频生成技术的进步，其潜在的人口统计学偏差问题变得突出，特别是在性别方面的偏见。为了解决这一问题，作者旨在开发一种不依赖于额外训练的方法来减少这种偏见。", "method": "该框架首先通过分析预训练的文本编码器中的隐含性别关联来量化性别偏向。基于此，提出了一种使用锚点基球面测地线变换来中和提示嵌入的方法，同时保持语义不变。为了维护时间一致性，在早期识别形成步骤中应用脱偏处理，并通过动态去噪计划执行。", "result": "在现代文本到视频模型Open-Sora上的实验表明，FAIRT2V能够显著降低职业领域的性别偏差，而对生成视频的质量影响很小。", "conclusion": "本文证明了使用训练自由的方法可以有效地减少文本到视频扩散模型中的性别偏见问题。该方法为解决人口统计学偏差提供了一种新的途径。"}}
{"id": "2601.20784", "pdf": "https://arxiv.org/pdf/2601.20784", "abs": "https://arxiv.org/abs/2601.20784", "authors": ["Zishen Wan", "Che-Kai Liu", "Jiayi Qian", "Hanchen Yang", "Arijit Raychowdhury", "Tushar Krishna"], "title": "REASON: Accelerating Probabilistic Logical Reasoning for Scalable Neuro-Symbolic Intelligence", "categories": ["cs.AI", "cs.AR"], "comment": "16 pages, 13 figures, 5 tables, 2026 IEEE International Symposium on High-Performance Computer Architecture (HPCA)", "summary": "Neuro-symbolic AI systems integrate neural perception with symbolic reasoning to enable data-efficient, interpretable, and robust intelligence beyond purely neural models. Although this compositional paradigm has shown superior performance in domains such as reasoning, planning, and verification, its deployment remains challenging due to severe inefficiencies in symbolic and probabilistic inference. Through systematic analysis of representative neuro-symbolic workloads, we identify probabilistic logical reasoning as the inefficiency bottleneck, characterized by irregular control flow, low arithmetic intensity, uncoalesced memory accesses, and poor hardware utilization on CPUs and GPUs. This paper presents REASON, an integrated acceleration framework for probabilistic logical reasoning in neuro-symbolic AI. REASON introduces a unified directed acyclic graph representation that captures common structure across symbolic and probabilistic models, coupled with adaptive pruning and regularization. At the architecture level, REASON features a reconfigurable, tree-based processing fabric optimized for irregular traversal, symbolic deduction, and probabilistic aggregation. At the system level, REASON is tightly integrated with GPU streaming multiprocessors through a programmable interface and multi-level pipeline that efficiently orchestrates compositional execution. Evaluated across six neuro-symbolic workloads, REASON achieves 12-50x speedup and 310-681x energy efficiency over desktop and edge GPUs under TSMC 28 nm node. REASON enables real-time probabilistic logical reasoning, completing end-to-end tasks in 0.8 s with 6 mm2 area and 2.12 W power, demonstrating that targeted acceleration of probabilistic logical reasoning is critical for practical and scalable neuro-symbolic AI and positioning REASON as a foundational system architecture for next-generation cognitive intelligence.", "AI": {"tldr": "REASON是一个加速框架，旨在解决神经符号AI中的概率逻辑推理问题，从而提高效率和可扩展性。", "motivation": "神经符号AI系统面临在CPU和GPU上执行时的低效率问题，特别是由于概率逻辑推理导致的不规则控制流、低算术强度以及内存访问模式差等问题。这个问题限制了系统的性能与实用性。", "method": "REASON采用统一有向无环图表示法捕捉符号模型和概率模型中的共同结构，并结合自适应剪枝和正则化方法。在架构层面，它利用可重构的树型处理单元优化不规则遍历、逻辑推理以及概率聚合操作；系统层面，则通过与GPU流多处理器紧密集成的方式高效协调组合执行。", "result": "REASON在六种神经符号工作负载上实现了12-50倍的速度提升和310-681倍的能源效率，证明了其加速策略的有效性。它能在0.8秒内完成整个任务，并且只占用6平方毫米面积与2.12瓦特功率。", "conclusion": "REASON通过针对性地优化概率逻辑推理过程解决了神经符号AI面临的瓶颈问题，为实现高效、可解释及稳健的人工智能提供了基础架构。"}}
{"id": "2601.20779", "pdf": "https://arxiv.org/pdf/2601.20779", "abs": "https://arxiv.org/abs/2601.20779", "authors": ["Théo Delemazure"], "title": "Independence of Approximate Clones", "categories": ["cs.GT", "cs.AI"], "comment": null, "summary": "In an ordinal election, two candidates are said to be perfect clones if every voter ranks them adjacently. The independence of clones axiom then states that removing one of the two clones should not change the election outcome. This axiom has been extensively studied in social choice theory, and several voting rules are known to satisfy it (such as IRV, Ranked Pairs and Schulze). However, perfect clones are unlikely to occur in practice, especially for political elections with many voters. In this work, we study different notions of approximate clones in ordinal elections. Informally, two candidates are approximate clones in a preference profile if they are close to being perfect clones. We discuss two measures to quantify this proximity, and we show under which conditions the voting rules that are known to be independent of clones are also independent of approximate clones. In particular, we show that for elections with at least four candidates, none of these rules are independent of approximate clones in the general case. However, we find a more positive result for the case of three candidates. Finally, we conduct an empirical study of approximate clones and independence of approximate clones based on three real-world datasets: votes in local Scottish elections, votes in mini-jury deliberations, and votes of judges in figure skating competitions. We find that approximate clones are common in some contexts, and that the closest two candidates are to being perfect clones, the less likely their removal is to change the election outcome, especially for voting rules that are independent of perfect clones.", "AI": {"tldr": "研究近似克隆候选人在选举中的独立性", "motivation": "完善投票规则在实际应用中的适应性，探讨完美克隆之外的近似克隆情况", "method": "引入两种衡量方法来量化候选人之间的接近程度，并分析特定条件下投票规则是否满足近似克隆独立性。基于三个现实数据集进行实证研究。", "result": "发现对于四个及以上候选人的选举，大多数投票规则不满足近似克隆独立性；而对于三名候选人的选举则有更积极的结果。实验表明近似克隆在某些情境下很常见，且候选人越接近完美克隆，移除一名候选人改变结果的可能性就越小。", "conclusion": "实证研究支持了理论分析的结果，并展示了近似克隆独立性的重要性及其实用价值"}}
{"id": "2601.20776", "pdf": "https://arxiv.org/pdf/2601.20776", "abs": "https://arxiv.org/abs/2601.20776", "authors": ["Huanyu Tian", "Martin Huber", "Lingyun Zeng", "Zhe Han", "Wayne Bennett", "Giuseppe Silvestri", "Gerardo Mendizabal-Ruiz", "Tom Vercauteren", "Alejandro Chavez-Badiola", "Christos Bergeles"], "title": "Learning From a Steady Hand: A Weakly Supervised Agent for Robot Assistance under Microscopy", "categories": ["cs.RO"], "comment": null, "summary": "This paper rethinks steady-hand robotic manipulation by using a weakly supervised framework that fuses calibration-aware perception with admittance control. Unlike conventional automation that relies on labor-intensive 2D labeling, our framework leverages reusable warm-up trajectories to extract implicit spatial information, thereby achieving calibration-aware, depth-resolved perception without the need for external fiducials or manual depth annotation. By explicitly characterizing residuals from observation and calibration models, the system establishes a task-space error budget from recorded warm-ups. The uncertainty budget yields a lateral closed-loop accuracy of approx. 49 micrometers at 95% confidence (worst-case testing subset) and a depth accuracy of <= 291 micrometers at 95% confidence bound during large in-plane moves. In a within-subject user study (N=8), the learned agent reduces overall NASA-TLX workload by 77.1% relative to the simple steady-hand assistance baseline. These results demonstrate that the weakly supervised agent improves the reliability of microscope-guided biomedical micromanipulation without introducing complex setup requirements, offering a practical framework for microscope-guided intervention.", "AI": {"tldr": "通过弱监督框架实现显微镜下机器人辅助操作，提高生物医学微操纵的可靠性。", "motivation": "减少依赖劳动密集型的手工标注，采用可重复使用的热身轨迹提取隐含的空间信息，以实现无需外部参照点或手动深度注释的校准感知。", "method": "利用弱监督框架融合校准感知与顺应控制，从记录的热身轨迹中建立任务空间误差预算，并通过显式刻画观察和校准模型之间的残差来提高精度。", "result": "在95%置信水平下，侧向闭环精度约为49微米（最坏测试子集），深度精度不超过291微米；用户研究显示学习代理降低了NASA-TLX工作负荷77.1％。", "conclusion": "所提出的弱监督代理通过简化设置要求提高了显微镜指导的生物医学微操作的可靠性，提供了一种实用框架。"}}
{"id": "2601.20775", "pdf": "https://arxiv.org/pdf/2601.20775", "abs": "https://arxiv.org/abs/2601.20775", "authors": ["Arshia Soltani Moakhar", "Tanapoom Laoaron", "Faraz Ghahremani", "Kiarash Banihashem", "MohammadTaghi Hajiaghayi"], "title": "Active Learning for Decision Trees with Provable Guarantees", "categories": ["cs.LG", "cs.CC", "cs.DS"], "comment": "10 pages, 43 pages with appendix, ICLR 2026, Conference URL: https://openreview.net/forum?id=NOkjJPJIit", "summary": "This paper advances the theoretical understanding of active learning label complexity for decision trees as binary classifiers. We make two main contributions. First, we provide the first analysis of the disagreement coefficient for decision trees-a key parameter governing active learning label complexity. Our analysis holds under two natural assumptions required for achieving polylogarithmic label complexity, (i) each root-to-leaf path queries distinct feature dimensions, and (ii) the input data has a regular, grid-like structure. We show these assumptions are essential, as relaxing them leads to polynomial label complexity. Second, we present the first general active learning algorithm for binary classification that achieves a multiplicative error guarantee, producing a $(1+ε)$-approximate classifier. By combining these results, we design an active learning algorithm for decision trees that uses only a polylogarithmic number of label queries in the dataset size, under the stated assumptions. Finally, we establish a label complexity lower bound, showing our algorithm's dependence on the error tolerance $ε$ is close to optimal.", "AI": {"tldr": "本文研究了决策树作为二分类器的主动学习标签复杂度，提供了关于分歧系数的第一项分析，并提出了第一个实现乘法误差保证的一般主动学习算法。", "motivation": "为了进一步理解基于决策树的二分类问题中主动学习的理论基础及其实用性，作者旨在提供首个分歧系数的分析，并设计一种新的主动学习算法来提高效率和准确性。", "method": "研究首先定义了适用于决策树的自然假设条件，然后提供了关于分歧系数的第一项详尽分析。在此基础上，提出了一个通用的主动学习算法以实现乘法误差保证，该算法在满足特定输入数据结构的条件下能够达到多对数标签查询量。", "result": "论文证明了所提出的方法能够在给定错误容忍度的情况下使用多项式数量级以下的标记请求，并且展示了其关于错误公差ε的依赖关系接近最优。", "conclusion": "通过这些结果，研究团队为决策树提供了首个实现多对数标签复杂度的主动学习算法，在特定假设条件下实现了高效的学习过程。"}}
{"id": "2601.20769", "pdf": "https://arxiv.org/pdf/2601.20769", "abs": "https://arxiv.org/abs/2601.20769", "authors": ["Yichi Zhang", "Fengqing Zhu"], "title": "Leveraging Second-Order Curvature for Efficient Learned Image Compression: Theory and Empirical Evidence", "categories": ["eess.IV", "cs.LG"], "comment": "fix typo", "summary": "Training learned image compression (LIC) models entails navigating a challenging optimization landscape defined by the fundamental trade-off between rate and distortion. Standard first-order optimizers, such as SGD and Adam, struggle with \\emph{gradient conflicts} arising from competing objectives, leading to slow convergence and suboptimal rate-distortion performance. In this work, we demonstrate that a simple utilization of a second-order quasi-Newton optimizer, \\textbf{SOAP}, dramatically improves both training efficiency and final performance across diverse LICs. Our theoretical and empirical analyses reveal that Newton preconditioning inherently resolves the intra-step and inter-step update conflicts intrinsic to the R-D objective, facilitating faster, more stable convergence. Beyond acceleration, we uncover a critical deployability benefit: second-order trained models exhibit significantly fewer activation and latent outliers. This substantially enhances robustness to post-training quantization. Together, these results establish second-order optimization, achievable as a seamless drop-in replacement of the imported optimizer, as a powerful, practical tool for advancing the efficiency and real-world readiness of LICs.", "AI": {"tldr": "本文利用SOAP优化器改进了学习图像压缩模型的训练效率和性能。", "motivation": "标准的一阶优化器在处理率失真目标时遇到梯度冲突，导致收敛速度慢且结果次优。", "method": "引入了一种二阶准牛顿优化器（SOAP），通过理论分析和实证研究展示了其改进效果。", "result": "结果显示使用二阶优化方法不仅提高了训练效率和最终性能，还增强了模型对量化后的鲁棒性。", "conclusion": "二阶优化作为一阶优化的简单替换方案，能有效提升学习图像压缩模型的实际部署能力。"}}
{"id": "2601.20760", "pdf": "https://arxiv.org/pdf/2601.20760", "abs": "https://arxiv.org/abs/2601.20760", "authors": ["Sarvesh Shashidhar", "Abhishek Mishra", "Madhav Kotecha"], "title": "Exploring Re-inforcement Learning via Human Feedback under User Heterogeneity", "categories": ["cs.HC"], "comment": null, "summary": "Re-inforcement learning from human feedback (RLHF) has been effective in the task of AI alignment. However, one of the key assumptions of RLHF is that the annotators (referred to as workers from here on out) have a homogeneous response space. This assumption is not true in most practical settings and there have been studies done in the past to challenge this notion. This work has been inspired by such studies and explores one of the ways to deal with heterogeneity in worker preferences - by clustering workers with similar preferences and personalising reward models for each cluster. This work provides an algorithm that encourages simultaneous learning of reward models and worker embeddings. This algorithm is then empirically tested against the Reddit TL;DR dataset with unique worker IDs. We have shown that clustering users into different groups based on their preferences and created personalised reward models improves win-rate of the said models. Along with results and visualisations, this work aims to act as a stepping stone to more complicated models and gives a list of possible future extensions.", "AI": {"tldr": "本文探讨了通过人类反馈进行强化学习的方法，特别是在用户异质性条件下的应用。", "motivation": "现有研究假设标注者具有同质的响应空间，但这一假设在实际场景中并不成立。为了应对这种异质性问题，本工作探索了一种基于相似偏好对工人进行聚类并为每个群体创建个性化奖励模型的方法。", "method": "本文提供了一个同时学习奖励模型和工人群体嵌入的算法，并通过Reddit TL;DR数据集进行了实验验证。", "result": "研究结果表明，将用户根据其偏好分成不同的群组并构建个性化的奖励模型可以提高所述模型的成功率。", "conclusion": "该工作展示了如何处理工人异质性问题的一种方法，并提出了一些未来可能的研究方向。"}}
{"id": "2601.20758", "pdf": "https://arxiv.org/pdf/2601.20758", "abs": "https://arxiv.org/abs/2601.20758", "authors": ["Lixiang Zhao", "Fuqi Xie", "Tobias Isenberg", "Hai-Ning Liang", "Lingyun Yu"], "title": "ScaleFree: Dynamic KDE for Multiscale Point Cloud Exploration in VR", "categories": ["cs.HC"], "comment": null, "summary": "We present ScaleFree, a GPU-accelerated adaptive Kernel Density Estimation (KDE) algorithm for scalable, interactive multiscale point cloud exploration. With this technique, we cater to the massive datasets and complex multiscale structures in advanced scientific computing, such as cosmological simulations with billions of particles. Effective exploration of such data requires a full 3D understanding of spatial structures, a capability for which immersive environments such as VR are particularly well suited. However, simultaneously supporting global multiscale context and fine-grained local detail remains a significant challenge. A key difficulty lies in dynamically generating continuous density fields from point clouds to facilitate the seamless scale transitions: while KDE is widely used, precomputed fields restrict the accuracy of interaction and omit fine-scale structures, while dynamic computation is often too costly for real-time VR interaction. We address this challenge by leveraging GPU acceleration with k-d-tree-based spatial queries and parallel reduction within a thread group for on-the-fly density estimation. With this approach, we can recalculate scalar fields dynamically as users shift their focus across scales. We demonstrate the benefits of adaptive density estimation through two data exploration tasks: adaptive selection and progressive navigation. Through performance experiments, we demonstrate that ScaleFree with GPU-parallel implementation achieves orders-of-magnitude speedups over sequential and multi-core CPU baselines. In a controlled experiment, we further confirm that our adaptive selection technique improves accuracy and efficiency in multiscale selection tasks.", "AI": {"tldr": "提出了一种GPU加速的自适应核密度估计(KDE)算法，用于大规模点云数据在VR环境下的交互式多尺度探索。", "motivation": "有效探索大型复杂点云数据需要实时生成连续密度场以支持无缝尺度转换，现有的预计算和动态计算方法存在精度和效率问题。", "method": "通过GPU加速及k-d树空间查询和线程组内并行缩减实现动态密度估计，支持用户在不同尺度间切换时重新计算标量场。", "result": "实验证明，ScaleFree算法相比传统CPU方案实现了数量级的性能提升，并且自适应选择技术提高了多尺度选择任务中的准确性和效率。", "conclusion": "ScaleFree为大规模点云数据提供了高效的VR交互式探索解决方案，支持无缝多尺度切换和精确密度估计。"}}
{"id": "2601.20749", "pdf": "https://arxiv.org/pdf/2601.20749", "abs": "https://arxiv.org/abs/2601.20749", "authors": ["Tawfiq Ammari", "Meilun Chen", "S M Mehedi Zaman", "Kiran Garimella"], "title": "Learning to Live with AI: How Students Develop AI Literacy Through Naturalistic ChatGPT Interaction", "categories": ["cs.HC"], "comment": null, "summary": "How do students develop AI literacy through everyday practice rather than formal instruction? While normative AI literacy frameworks proliferate, empirical understanding of how students actually learn to work with generative AI remains limited. This study analyzes 10,536 ChatGPT messages from 36 undergraduates over one academic year, revealing five use genres -- academic workhorse, emotional companion, metacognitive partner, repair and negotiation, and trust calibration -- that constitute distinct configurations of student-AI learning. Drawing on domestication theory and emerging frameworks for AI literacy, we demonstrate that functional AI competence emerges through ongoing relational negotiation rather than one-time adoption. Students develop sophisticated genre portfolios, strategically matching interaction patterns to learning needs while exercising critical judgment about AI limitations. Notably, repair work during AI breakdowns produces substantial learning about AI capabilities, developing what we term \"repair literacy\" -- a crucial but underexplored dimension of AI competence. Our findings offer educators empirically grounded insights into how students actually learn to work with generative AI, with implications for AI literacy pedagogy, responsible AI integration, and the design of AI-enabled learning environments that support student agency.", "AI": {"tldr": "研究通过分析学生与ChatGPT的互动，探讨了他们如何在非正式环境下发展AI素养。", "motivation": "现有的AI素养框架多为规范性指导，缺乏对学生实际使用生成式AI的学习过程的理解。研究旨在填补这一空白，并提供教育者的实践启示。", "method": "通过对36名大学生一年内发送给ChatGPT的10,536条消息进行分析，识别出五种互动类型：学术助手、情感伴侣、元认知伙伴、修复和协商以及信任校准。研究还考察了学生如何通过持续的人机交互发展AI能力。", "result": "学生在与生成式AI互动中形成了复杂的互动模式，并根据学习需求匹配这些模式，同时对AI的局限性进行批判性思考。特别是在解决AI故障的过程中，他们获得了“修复素养”，即一种关键但尚未充分探索的AI能力维度。", "conclusion": "研究揭示了学生如何在非正式环境中发展AI素养的过程和机制，为教育者提供了实证性的指导，并对负责任地整合AI、支持学生的主动性提出了建议。"}}
{"id": "2601.20747", "pdf": "https://arxiv.org/pdf/2601.20747", "abs": "https://arxiv.org/abs/2601.20747", "authors": ["Elham Aghakhani", "Rezvaneh Rezapour"], "title": "Like a Therapist, But Not: Reddit Narratives of AI in Mental Health Contexts", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used for emotional support and mental health-related interactions outside clinical settings, yet little is known about how people evaluate and relate to these systems in everyday use. We analyze 5,126 Reddit posts from 47 mental health communities describing experiential or exploratory use of AI for emotional support or therapy. Grounded in the Technology Acceptance Model and therapeutic alliance theory, we develop a theory-informed annotation framework and apply a hybrid LLM-human pipeline to analyze evaluative language, adoption-related attitudes, and relational alignment at scale. Our results show that engagement is shaped primarily by narrated outcomes, trust, and response quality, rather than emotional bond alone. Positive sentiment is most strongly associated with task and goal alignment, while companionship-oriented use more often involves misaligned alliances and reported risks such as dependence and symptom escalation. Overall, this work demonstrates how theory-grounded constructs can be operationalized in large-scale discourse analysis and highlights the importance of studying how users interpret language technologies in sensitive, real-world contexts.", "AI": {"tldr": "该论文分析了Reddit用户在心理健康背景下使用AI进行情感支持的经历和感受，探讨人们如何评价这些技术并与其建立关系。", "motivation": "尽管大型语言模型（LLMs）被越来越多地用于提供情感支持和心理健康相关的互动，但关于这些系统实际应用中的用户评价和人际关系知之甚少。论文旨在填补这一研究空白，通过分析Reddit上的帖子来了解人们如何与AI进行心理健康的互动。", "method": "基于技术接受模型和治疗联盟理论，开发了一个理论导向的注释框架，并利用LLM-人类混合管道对5126个Reddit帖子进行了大规模话语分析。这些帖子来自47个心理健康社区，描述了用户使用AI的情感支持或疗法的实际经验或探索性使用。", "result": "研究结果表明，用户的参与主要是由叙述的结果、信任和响应质量驱动的，而不仅仅是情感联系本身。积极的态度主要与任务和目标一致有关，而以陪伴为导向的使用则更多地涉及不一致的联盟，并报告了诸如依赖和症状恶化的风险。", "conclusion": "这项工作展示了如何在大规模话语分析中将理论导向的概念具体化，并强调了研究用户对语言技术的理解的重要性。特别是在敏感、现实世界的背景下，这些理解对于更好地应用AI于心理健康支持具有重要意义。"}}
{"id": "2601.20745", "pdf": "https://arxiv.org/pdf/2601.20745", "abs": "https://arxiv.org/abs/2601.20745", "authors": ["Guoan Wang", "Feiyu Wang", "Zongwei Lv", "Yikun Zong", "Tong Yang"], "title": "HESTIA: A Hessian-Guided Differentiable Quantization-Aware Training Framework for Extremely Low-Bit LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 2 figures", "summary": "As large language models (LLMs) continue to scale, deployment is increasingly bottlenecked by the memory wall, motivating a shift toward extremely low-bit quantization. However, most quantization-aware training (QAT) methods apply hard rounding and the straight-through estimator (STE) from the beginning of the training, which prematurely discretizes the optimization landscape and induces persistent gradient mismatch between latent weights and quantized weights, hindering effective optimization of quantized models. To address this, we propose Hestia, a Hessian-guided differentiable QAT framework for extremely low-bit LLMs, which replaces the rigid step function with a temperature-controlled softmax relaxation to maintain gradient flow early in training while progressively hardening quantization. Furthermore, Hestia leverages a tensor-wise Hessian trace metric as a lightweight curvature signal to drive fine-grained temperature annealing, enabling sensitivity-aware discretization across the model. Evaluations on Llama-3.2 show that Hestia consistently outperforms existing ternary QAT baselines, yielding average zero-shot improvements of 5.39% and 4.34% for the 1B and 3B models. These results indicate that Hessian-guided relaxation effectively recovers representational capacity, establishing a more robust training path for 1.58-bit LLMs. The code is available at https://github.com/hestia2026/Hestia.", "AI": {"tldr": "HESTIA提出了一种基于Hessian引导的可微量化感知训练框架，用于极低比特率的大规模语言模型。", "motivation": "当前大语言模型由于内存限制，转向极低比特量化的趋势明显。然而，大多数量化感知训练方法从一开始就使用硬舍入和直通估计器，这过早地离散了优化空间并导致潜权重与量化权重之间的梯度不匹配，从而阻碍了有效优化。", "method": "HESTIA采用温度控制的softmax松弛替换刚性步进函数，维持早期训练中的梯度流动，并逐步硬化量化。它还利用张量级Hessian迹作为轻量级曲率信号驱动细粒度温度退火，使模型在整个过程中进行敏感感知离散。", "result": "实验表明，在Llama-3.2上，HESTIA优于现有的三值量化基线，对于1B和3B模型的零样本改进分别为5.39%和4.34%，显示Hessian引导松弛有效恢复了表示能力。", "conclusion": "HESTIA证明了基于Hessian指导的方法在极低比特率的大规模语言模型训练中提供了更稳健的学习路径。"}}
{"id": "2601.20742", "pdf": "https://arxiv.org/pdf/2601.20742", "abs": "https://arxiv.org/abs/2601.20742", "authors": ["Xin Jin", "Jinming Liu", "Yuntao Wei", "Junyan Lin", "Zhicheng Wang", "Jianguo Huang", "Xudong Yang", "Yanxiao Liu", "Wenjun Zeng"], "title": "Compression Tells Intelligence: Visual Coding, Visual Token Technology, and the Unification", "categories": ["cs.CV"], "comment": null, "summary": "\"Compression Tells Intelligence\", is supported by research in artificial intelligence, particularly concerning (multimodal) large language models (LLMs/MLLMs), where compression efficiency often correlates with improved model performance and capabilities. For compression, classical visual coding based on traditional information theory has developed over decades, achieving great success with numerous international industrial standards widely applied in multimedia (e.g., image/video) systems. Except that, the recent emergingvisual token technology of generative multi-modal large models also shares a similar fundamental objective like visual coding: maximizing semantic information fidelity during the representation learning while minimizing computational cost. Therefore, this paper provides a comprehensive overview of two dominant technique families first -- Visual Coding and Vision Token Technology -- then we further unify them from the aspect of optimization, discussing the essence of compression efficiency and model performance trade-off behind. Next, based on the proposed unified formulation bridging visual coding andvisual token technology, we synthesize bidirectional insights of themselves and forecast the next-gen visual codec and token techniques. Last but not least, we experimentally show a large potential of the task-oriented token developments in the more practical tasks like multimodal LLMs (MLLMs), AI-generated content (AIGC), and embodied AI, as well as shedding light on the future possibility of standardizing a general token technology like the traditional codecs (e.g., H.264/265) with high efficiency for a wide range of intelligent tasks in a unified and effective manner.", "AI": {"tldr": "论文概述了视觉编码和生成多模态大型模型的视觉标记技术，探讨了压缩效率与模型性能之间的权衡，并预测了未来视觉编码器及标记技术的发展趋势。", "motivation": "研究发现，在人工智能领域特别是在（多模态）大语言模型中，压缩效率常与改进后的模型性能和能力相关。因此，论文旨在统视觉编码技术和视觉令牌技术的基本原理并探讨其背后的权衡关系。", "method": "通过综合介绍两种主导的技术家族，并提出一种统一的公式连接视觉编码和视觉标记技术，以双向洞察自身并预测下一代视觉编解码器及标记技术的发展趋势。", "result": "论文实验表明，任务导向令牌在多模态大语言模型、AI生成内容和具身人工智能等实际应用中具有巨大潜力，并预示了标准化通用令牌技术的可能性。", "conclusion": "文章强调未来统一高效的智能任务标准的可能性，如传统编解码器（例如H.264/265）在广泛的应用中的高效性和有效性。"}}
{"id": "2601.20737", "pdf": "https://arxiv.org/pdf/2601.20737", "abs": "https://arxiv.org/abs/2601.20737", "authors": ["Si Chen", "Jingyi Xie", "Yao Li", "Ya-Fang Lin", "He Zhang", "Ge Wang", "Gaojian Huang", "Rui Yu", "Ronald Anthony Metoyer", "Ting Hua", "Nitesh Chawla"], "title": "A Human-Centred AI System for Multi-Actor Planning and Collaboration in Family Learning", "categories": ["cs.HC"], "comment": null, "summary": "Family learning takes place in everyday routines where children and caregivers read, practice, and develop new skills together. Despite growing interest in AI tutors, most existing systems are designed for single learners or classroom settings and do not address the distributed planning, coordination, and execution demands of learning at home. This paper introduces ParPal, a human-centred, LLM-powered system that supports multi-actor family learning by decomposing learning goals into actionable subtasks, allocating them across caregivers under realistic availability and expertise constraints, and providing caregiver-in-the-loop tutoring support with visibility into individual and collective contributions. Through expert evaluation of generated weekly learning plans and a one-week field deployment with 11 families, we identify systematic failure modes in current LLM-based planning, including misalignment with role expertise, unnecessary or costly collaboration, missing pedagogical learning trajectories, and physically or temporally infeasible tasks. While ParPal improves coordination clarity and recognition of caregiving effort, these findings expose fundamental limitations in how current LLMs operationalize pedagogical knowledge, reason about collaboration, and account for real-world, embodied constraints. We discuss implications for human-centred AI design and AI methodology, positioning multi-actor family learning as a critical testbed for advancing planning, adaptation, and pedagogical structure in next-generation AI systems.", "AI": {"tldr": "介绍了ParPal系统，这是一个旨在支持多角色家庭学习的人工智能系统。", "motivation": "现有的AI教学系统主要针对单个学习者或课堂环境设计，并未解决在家学习中分布式计划、协调和执行的需求。本文通过引入一个以人类为中心的LLM驱动系统来应对这些问题。", "method": "ParPal系统将学习目标分解为可操作的任务，根据照顾者的可用性和专业能力分配任务，并提供带有个人和集体贡献可见性的辅导支持。", "result": "经过专家对生成的学习计划评估以及与11个家庭进行的一周实地部署后，揭示了当前LLM规划中的系统性失败模式，包括角色专业知识的不匹配、不必要的合作等。ParPal改善了协作清晰度并认可了照顾者的努力。", "conclusion": "这些发现暴露了现有LLM在操作教育知识、推理和现实世界中身体约束方面存在的根本限制。文章讨论了对人类为中心的人工智能设计以及人工智能方法的启示，将多角色家庭学习作为推进下一代人工智能系统的计划、适应性和教学结构的重要测试平台。"}}
{"id": "2601.20735", "pdf": "https://arxiv.org/pdf/2601.20735", "abs": "https://arxiv.org/abs/2601.20735", "authors": ["Arvid Becker", "Pedro Cabalar", "Martin Diéguez", "Susana Hahn", "Javier Romero", "Torsten Schaub"], "title": "Implementing Metric Temporal Answer Set Programming", "categories": ["cs.AI", "cs.LO"], "comment": ":I.2.8; I.2.4", "summary": "We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.", "AI": {"tldr": "提出了一种计算方法，用于在度量回答集编程（ASP）中表达定量的时间约束。", "motivation": "为了克服处理精细时间约束时出现的可扩展性问题，并解决ASP中的地面化瓶颈", "method": "通过引入差分约束来扩展ASP以处理时间相关方面。这种方法使度量ASP与时间精度脱钩，从而不受时间细节的影响。", "result": "提出的方法有效地解决了由于精细时间约束导致的可扩展性问题，并保持了解决方案不受时间精度的影响。", "conclusion": "通过在度量回答集编程中引入差分约束来处理时间相关方面，成功地解决了ASP中的时间和地面化瓶颈问题。"}}
{"id": "2601.20732", "pdf": "https://arxiv.org/pdf/2601.20732", "abs": "https://arxiv.org/abs/2601.20732", "authors": ["Ziwei Liu", "Borui Kang", "Hangjie Yuan", "Zixiang Zhao", "Wei Li", "Yifan Zhu", "Tao Feng"], "title": "Continual GUI Agents", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "As digital environments (data distribution) are in flux, with new GUI data arriving over time-introducing new domains or resolutions-agents trained on static environments deteriorate in performance. In this work, we introduce Continual GUI Agents, a new task that requires GUI agents to perform continual learning under shifted domains and resolutions. We find existing methods fail to maintain stable grounding as GUI distributions shift over time, due to the diversity of UI interaction points and regions in fluxing scenarios. To address this, we introduce GUI-Anchoring in Flux (GUI-AiF), a new reinforcement fine-tuning framework that stabilizes continual learning through two novel rewards: Anchoring Point Reward in Flux (APR-iF) and Anchoring Region Reward in Flux (ARR-iF). These rewards guide the agents to align with shifting interaction points and regions, mitigating the tendency of existing reward strategies to over-adapt to static grounding cues (e.g., fixed coordinates or element scales). Extensive experiments show GUI-AiF surpasses state-of-the-art baselines. Our work establishes the first continual learning framework for GUI agents, revealing the untapped potential of reinforcement fine-tuning for continual GUI Agents.", "AI": {"tldr": "介绍了一种新的任务Continual GUI Agents，该任务要求GUI代理在不断变化的领域和分辨率下进行连续学习。", "motivation": "由于数字环境的变化，现有的训练于静态环境下的代理性能会下降。为解决这个问题，研究引入了新的框架以应对GUI分布随时间移动的情况。", "method": "提出了一种称为GUI-Anchoring in Flux（GUI-AiF）的新强化微调框架，包括两个新奖励：Anchoring Point Reward in Flux (APR-iF) 和 Anchoring Region Reward in Flux (ARR-iF)，以引导代理适应不断变化的交互点和区域。", "result": "实验结果表明，所提出的方法超越了现有的最佳方法。", "conclusion": "研究工作首次建立了用于GUI代理的连续学习框架，并揭示了强化微调在持续GUI代理方面的潜力。"}}
{"id": "2601.20731", "pdf": "https://arxiv.org/pdf/2601.20731", "abs": "https://arxiv.org/abs/2601.20731", "authors": ["Mae Sosto", "Delfina Sol Martinez Pandiani", "Laura Hollink"], "title": "QueerGen: How LLMs Reflect Societal Norms on Gender and Sexuality in Sentence Completion Tasks", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "This paper examines how Large Language Models (LLMs) reproduce societal norms, particularly heterocisnormativity, and how these norms translate into measurable biases in their text generations. We investigate whether explicit information about a subject's gender or sexuality influences LLM responses across three subject categories: queer-marked, non-queer-marked, and the normalized \"unmarked\" category. Representational imbalances are operationalized as measurable differences in English sentence completions across four dimensions: sentiment, regard, toxicity, and prediction diversity. Our findings show that Masked Language Models (MLMs) produce the least favorable sentiment, higher toxicity, and more negative regard for queer-marked subjects. Autoregressive Language Models (ARLMs) partially mitigate these patterns, while closed-access ARLMs tend to produce more harmful outputs for unmarked subjects. Results suggest that LLMs reproduce normative social assumptions, though the form and degree of bias depend strongly on specific model characteristics, which may redistribute, but not eliminate, representational harms.", "AI": {"tldr": "研究通过分析大规模语言模型在句子完成任务中对性别和性取向的反应，探讨了这些模型如何反映社会规范。", "motivation": "探讨大型语言模型是否以及如何再现社会上的异性恋偏见，并将这种偏见转化为文本生成中的可测量偏差。", "method": "研究通过三种不同的主体类别：标记为同性的、未标记为同性且非典型的和正常的“未标记”类别，分析了显式性别或性取向信息对语言模型反应的影响。这些影响被量化为英文句子完成任务中四个维度的变化：情感、态度、毒性及预测多样性。", "result": "研究表明掩码语言模型（MLM）对于标记为同性的主题生成最不友好的情感，更高的毒性以及更负面的态度；自回归语言模型（ARLM）部分缓解了这些模式，但封闭访问的ARLMs倾向于对未标记的主题产生更多有害输出。", "conclusion": "结果表明大型语言模型再现规范性社会假设的方式取决于特定模型特性，这可能会重新分配但不能消除代表性伤害。"}}
{"id": "2601.20720", "pdf": "https://arxiv.org/pdf/2601.20720", "abs": "https://arxiv.org/abs/2601.20720", "authors": ["Matej Halinkovic", "Nina Masarykova", "Alexey Vinel", "Marek Galinski"], "title": "Li-ViP3D++: Query-Gated Deformable Camera-LiDAR Fusion for End-to-End Perception and Trajectory Prediction", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "End-to-end perception and trajectory prediction from raw sensor data is one of the key capabilities for autonomous driving. Modular pipelines restrict information flow and can amplify upstream errors. Recent query-based, fully differentiable perception-and-prediction (PnP) models mitigate these issues, yet the complementarity of cameras and LiDAR in the query-space has not been sufficiently explored. Models often rely on fusion schemes that introduce heuristic alignment and discrete selection steps which prevent full utilization of available information and can introduce unwanted bias. We propose Li-ViP3D++, a query-based multimodal PnP framework that introduces Query-Gated Deformable Fusion (QGDF) to integrate multi-view RGB and LiDAR in query space. QGDF (i) aggregates image evidence via masked attention across cameras and feature levels, (ii) extracts LiDAR context through fully differentiable BEV sampling with learned per-query offsets, and (iii) applies query-conditioned gating to adaptively weight visual and geometric cues per agent. The resulting architecture jointly optimizes detection, tracking, and multi-hypothesis trajectory forecasting in a single end-to-end model. On nuScenes, Li-ViP3D++ improves end-to-end behavior and detection quality, achieving higher EPA (0.335) and mAP (0.502) while substantially reducing false positives (FP ratio 0.147), and it is faster than the prior Li-ViP3D variant (139.82 ms vs. 145.91 ms). These results indicate that query-space, fully differentiable camera-LiDAR fusion can increase robustness of end-to-end PnP without sacrificing deployability.", "AI": {"tldr": "本文提出了一种用于自动驾驶的端到端感知和轨迹预测框架Li-ViP3D++，该框架通过查询门控可变形融合技术有效整合了多视角RGB图像和激光雷达数据。", "motivation": "现有的模块化管道限制了信息流动并可能放大上游错误。本文旨在探索相机和激光雷达在查询空间中的互补性，并提出一种无需启发式对齐和离散选择步骤的端到端感知与预测框架，以充分利用可用的信息并减少偏置。", "method": "Li-ViP3D++采用查询门控可变形融合技术（QGDF），该技术通过掩码注意力聚合图像证据，并提取激光雷达上下文，同时根据每个代理自适应调整视觉和几何线索的权重。这种方法能够在单一端到端模型中优化检测、跟踪及多假设轨迹预测。", "result": "在nuScenes数据集上，Li-ViP3D++相较于先前的方法提高了端到端行为质量与检测准确性，具体表现为EPA（0.335）和mAP（0.502）的提升，并显著减少了假阳性率。同时，该方法比前一版本Li-ViP3D更快（139.82毫秒对比145.91毫秒）。", "conclusion": "查询空间中的全可微相机激光雷达融合技术可以提高端到端感知和预测任务的鲁棒性而不牺牲部署性能。"}}
{"id": "2601.20718", "pdf": "https://arxiv.org/pdf/2601.20718", "abs": "https://arxiv.org/abs/2601.20718", "authors": ["Julia Chuzhoy", "Merav Parter"], "title": "Fully Dynamic Algorithms for Graph Spanners via Low-Diameter Router Decomposition", "categories": ["cs.DS"], "comment": null, "summary": "A $t$-spanner of an undirected $n$-vertex graph $G$ is a sparse subgraph $H$ of $G$ that preserves all pairwise distances between its vertices to within multiplicative factor $t$, also called the \\emph{stretch}. We investigate the problem of maintaining spanners in the fully dynamic setting with an adaptive adversary. Despite a long line of research, this problem is still poorly understood: no algorithm achieving a sublogarithmic stretch, a sublinear in $n$ update time, and a strongly subquadratic in $n$ spanner size is currently known. One of our main results is a deterministic algorithm, that, for any $512 \\leq k \\leq (\\log n)^{1/49}$ and $1/k\\leq δ\\leq 1/400$, maintains a spanner $H$ of a fully dynamic graph with stretch $poly(k)\\cdot 2^{O(1/δ^6)}$ and size $|E(H)|\\leq O(n^{1+O(1/k)})$, with worst-case update time $n^{O(δ)}$ and recourse $n^{O(1/k)}$. Our algorithm relies on a new technical tool that we develop, called low-diameter router decomposition. We design a deterministic algorithm that maintains a decomposition of a fully dynamic graph into edge-disjoint clusters with bounded vertex overlap, where each cluster $C$ is a bounded-diameter router, meaning that any reasonable multicommodity demand over the vertices of $C$ can be routed along short paths and with low congestion. A similar graph decomposition notion was introduced by [Haeupler et al., STOC 2022] and strengthened by [Haeupler et al., FOCS 2024]. However, in contrast to these and other prior works, the decomposition that our algorithm maintains is proper, ensuring that the routing paths between the pairs of vertices of each cluster $C$ are contained inside $C$, rather than in the entire graph $G$. We show additional applications of our router decomposition, including dynamic algorithms for fault-tolerant spanners and low-congestion spanners.", "AI": {"tldr": "本文提出了一种动态维护图的稀疏子图（即spanner）的方法，该方法能在更新时保持对任意给定伸缩因子的近似最短路径。", "motivation": "在动态图中维持一个良好的spanner对于网络设计和分析至关重要。当前已知算法无法同时满足亚线性时间复杂度、亚二次大小以及次对数伸缩因子的要求，因此本文提出新的技术工具来解决这一问题。", "method": "文章引入了一种新的技术工具——低直径路由器分解，它能够将动态图分解成边不相交的簇，并保证每个簇内的路由路径均在该簇内部而非整个图。基于此工具设计了一个确定性的算法以维护具有特定伸缩因子和大小限制的spanner。", "result": "该算法能够在更新时维持一个跨度为poly(k)·2^O(1/δ^6)、大小不超过O(n^(1+O(1/k)))且最坏情况下的更新时间为n^O(δ)、迁移次数为n^O(1/k)的spanner。", "conclusion": "本文通过低直径路由器分解技术提供了在动态图中维持良好spanner的新方法，并展示了此技术在故障容错性和低阻塞spanner等其他应用中的潜力。"}}
{"id": "2601.20716", "pdf": "https://arxiv.org/pdf/2601.20716", "abs": "https://arxiv.org/abs/2601.20716", "authors": ["Abylay Satybaldy", "Kamil Tylinski", "Jiahua Xu"], "title": "Decentralized Identity in Practice: Benchmarking Latency, Cost, and Privacy", "categories": ["cs.CR", "cs.ET"], "comment": null, "summary": "Decentralized Identifiers (DIDs) are increasingly deployed on distributed ledgers, yet systematic cross-platform evidence on their operational behavior remains limited. We present an empirical benchmarking study of three prominent ledger-based DID methods - Ethereum, Hedera, and XRP Ledger - using reference Software Development Kits (SDKs) under a unified experimental setup. We measure latency, transaction cost, and on-chain metadata exposure, normalizing latency by each platform's block or consensus interval and cost by its native value transfer fee. Privacy leakage is quantified using a Metadata-Leakage Score (MLS), an entropy-based measure expressed in bits per operation. Our results reveal distinct architectural trade-offs. Ethereum enables near-instant, off-chain DID creation, but incurs the highest latency and cost for on-chain lifecycle operations. XRPL delivers deterministic and stable latency with fixed, low fees, yet exhibits higher metadata leakage due to more verbose transaction payloads. Hedera achieves the lowest on-chain latency and low fees with minimal metadata leakage, while occasional variance arises from SDK-side processing and confirmation pipelines. Overall, the findings show that ledger architecture and SDK workflows play a major role in shaping DID latency, cost, and metadata exposure, complementing the effects of the underlying consensus mechanism. These results provide evidence-based insights to support informed selection and configuration of DID systems under performance and privacy constraints.", "AI": {"tldr": "本文通过统一实验设置，对Ethereum、Hedera和XRP Ledger三种基于分布式账本的DID方法进行了实证基准测试，评估其延迟、交易成本以及链上元数据泄露情况。", "motivation": "尽管分布式标识符（DIDs）在分布式账本上的部署越来越广泛，但对其操作行为进行系统性比较的证据仍然有限。本文旨在提供一种跨平台的操作性能证据以帮助选择和配置DID系统。", "method": "使用参考软件开发工具包（SDK），测量三种基于分布式账本的DID方法的延迟、交易成本以及链上元数据泄露情况，并通过熵为基础的方法量化隐私泄漏。", "result": "实验结果显示，Ethereum支持近实时的链外DID创建，但其链内操作延迟和费用最高；XRPL提供稳定的低延迟与固定低成本，但是存在较高的元数据暴露；Hedera实现了最低的链上延迟、较低的费用以及最小的元数据泄漏。", "conclusion": "本文发现分布式账本架构及SDK工作流程在塑造DID系统性能和隐私方面起着重要作用。这些结果为选择配置符合性能与隐私约束条件下的DID系统提供了基于证据的见解。"}}
{"id": "2601.20714", "pdf": "https://arxiv.org/pdf/2601.20714", "abs": "https://arxiv.org/abs/2601.20714", "authors": ["Raul de la Rosa", "Ivana Dusparic", "Nicolas Cardozo"], "title": "Adapting the Behavior of Reinforcement Learning Agents to Changing Action Spaces and Reward Functions", "categories": ["cs.LG", "cs.AI"], "comment": "ef:2025 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C), Tokyo, Japan, 2025, pp. 148-153", "summary": "Reinforcement Learning (RL) agents often struggle in real-world applications where environmental conditions are non-stationary, particularly when reward functions shift or the available action space expands. This paper introduces MORPHIN, a self-adaptive Q-learning framework that enables on-the-fly adaptation without full retraining. By integrating concept drift detection with dynamic adjustments to learning and exploration hyperparameters, MORPHIN adapts agents to changes in both the reward function and on-the-fly expansions of the agent's action space, while preserving prior policy knowledge to prevent catastrophic forgetting. We validate our approach using a Gridworld benchmark and a traffic signal control simulation. The results demonstrate that MORPHIN achieves superior convergence speed and continuous adaptation compared to a standard Q-learning baseline, improving learning efficiency by up to 1.7x.", "AI": {"tldr": "介绍了一种自适应的Q学习框架MORPHIN，使强化学习代理能够在奖励函数变化和行为空间扩展的情况下快速适应。", "motivation": "解决强化学习代理在非静态环境中的适应性问题，特别是在奖励函数改变或行动空间扩大的情况下。", "method": "通过集成概念漂移检测与动态调整学习和探索超参数，在不完全重新训练的情况下实现即时适应。", "result": "使用Gridworld基准测试和交通信号控制模拟验证了MORPHIN方法的优越性，其收敛速度比标准Q学习基线快1.7倍。", "conclusion": "提出的方法有效提高了代理在非静态环境中的学习效率。"}}
{"id": "2601.20706", "pdf": "https://arxiv.org/pdf/2601.20706", "abs": "https://arxiv.org/abs/2601.20706", "authors": ["Binglei Lou", "Haoran Wu", "Yao Lai", "Jiayi Nie", "Can Xiao", "Xuan Guo", "Rika Antonova", "Robert Mullins", "Aaron Zhao"], "title": "Beyond GEMM-Centric NPUs: Enabling Efficient Diffusion LLM Sampling", "categories": ["cs.AR", "cs.AI", "cs.DC"], "comment": null, "summary": "Diffusion Large Language Models (dLLMs) introduce iterative denoising to enable parallel token generation, but their sampling phase displays fundamentally different characteristics compared to GEMM-centric transformer layers. Profiling on modern GPUs reveals that sampling can account for up to 70% of total model inference latency-primarily due to substantial memory loads and writes from vocabulary-wide logits, reduction-based token selection, and iterative masked updates. These processes demand large on-chip SRAM and involve irregular memory accesses that conventional NPUs struggle to handle efficiently. To address this, we identify a set of critical instructions that an NPU architecture must specifically optimize for dLLM sampling. Our design employs lightweight non-GEMM vector primitives, in-place memory reuse strategies, and a decoupled mixed-precision memory hierarchy. Together, these optimizations deliver up to a 2.53x speedup over the NVIDIA RTX A6000 GPU under an equivalent nm technology node. We also open-source our cycle-accurate simulation and post-synthesis RTL verification code, confirming functional equivalence with current dLLM PyTorch implementations.", "AI": {"tldr": "本文研究了扩散大语言模型（dLLMs）采样过程中的性能瓶颈，并提出了一种新的NPU架构来优化这一过程。", "motivation": "在现代GPU上，dLLMs的采样阶段占总推理延迟的70%，主要原因是词汇范围内的logits加载和写入、基于减少的选择令牌以及迭代屏蔽更新等操作。这些问题导致了大型片上SRAM的需求，并且涉及不规则内存访问。", "method": "提出了一种新的NPU架构，采用轻量级非GEMM向量原始指令、就地内存重用策略和解耦混合精度存储层次结构来优化dLLMs的采样过程。此外还开源了周期准确的模拟和后综合RTL验证代码。", "result": "新设计在与NVIDIA RTX A6000 GPU相等的纳米技术节点下，实现了高达2.53倍的速度提升。", "conclusion": "通过优化dLLMs采样过程中的关键操作，新的NPU架构能够显著提高模型推理性能。"}}
{"id": "2601.20705", "pdf": "https://arxiv.org/pdf/2601.20705", "abs": "https://arxiv.org/abs/2601.20705", "authors": ["Zhuang Yu", "Lei Shen", "Jing Zhao", "Shiliang Sun"], "title": "LEMON: How Well Do MLLMs Perform Temporal Multimodal Understanding on Instructional Videos?", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent multimodal large language models (MLLMs) have shown remarkable progress across vision, audio, and language tasks, yet their performance on long-form, knowledge-intensive, and temporally structured educational content remains largely unexplored. To bridge this gap, we introduce LEMON, a Lecture-based Evaluation benchmark for MultimOdal uNderstanding, focusing on STEM lecture videos that require long-horizon reasoning and cross-modal integration. LEMON comprises 2,277 video segments spanning 5 disciplines and 29 courses, with an average duration of 196.1 seconds, yielding 4,181 high-quality QA pairs, including 3,413 multiple-choice and 768 open-ended questions. Distinct from existing video benchmarks, LEMON features: (1) semantic richness and disciplinary density, (2) tightly coupled video-audio-text modalities, (3) explicit temporal and pedagogical structure, and (4) contextually linked multi-turn questioning. It further encompasses six major tasks and twelve subtasks, covering the full cognitive spectrum from perception to reasoning and then to generation. Comprehensive experiments reveal substantial performance gaps across tasks, highlighting that even state-of-the-art MLLMs like GPT-4o struggle with temporal reasoning and instructional prediction. We expect LEMON to serve as an extensible and challenging benchmark for advancing multimodal perception, reasoning, and generation in long-form instructional contents.", "AI": {"tldr": "LEMON是一个基于STEM讲座视频的多模态理解评估基准，旨在评测大型语言模型在长时序、知识密集型和结构化教育内容上的表现。", "motivation": "现有的多模态大型语言模型虽然在视觉、音频和语言任务上取得了显著进展，但在长时序的知识密集型内容上的性能尚未得到充分研究。LEMON填补了这一空白，专注于评测STEM讲座视频中需要长时间推理和跨模式整合的任务。", "method": "LEMON包含2,277个视频片段，跨越5个学科、29门课程，总时长平均为196.1秒，产生了4,181对高质量的问题答案，包括3,413个多选题和768道开放性问题。它涵盖了六大主要任务及十二项子任务，全面覆盖了从感知到推理再到生成的认知全过程。", "result": "实验结果显示，即使像GPT-4o这样的最先进的多模态大型语言模型在时间推理和教学预测方面也存在显著的性能差距。", "conclusion": "LEMON作为一个可扩展且具有挑战性的基准，有助于推动长格式教育内容中多模态感知、推理和生成的发展。"}}
{"id": "2601.20701", "pdf": "https://arxiv.org/pdf/2601.20701", "abs": "https://arxiv.org/abs/2601.20701", "authors": ["Guowei Zou", "Haitao Wang", "Hejun Wu", "Yukun Qian", "Yuhang Wang", "Weibing Li"], "title": "One Step Is Enough: Dispersive MeanFlow Policy Optimization", "categories": ["cs.RO"], "comment": "Code and project page: https://guowei-zou.github.io/dmpo-page/", "summary": "Real-time robotic control demands fast action generation. However, existing generative policies based on diffusion and flow matching require multi-step sampling, fundamentally limiting deployment in time-critical scenarios. We propose Dispersive MeanFlow Policy Optimization (DMPO), a unified framework that enables true one-step generation through three key components: MeanFlow for mathematically-derived single-step inference without knowledge distillation, dispersive regularization to prevent representation collapse, and reinforcement learning (RL) fine-tuning to surpass expert demonstrations. Experiments across RoboMimic manipulation and OpenAI Gym locomotion benchmarks demonstrate competitive or superior performance compared to multi-step baselines. With our lightweight model architecture and the three key algorithmic components working in synergy, DMPO exceeds real-time control requirements (>120Hz) with 5-20x inference speedup, reaching hundreds of Hertz on high-performance GPUs. Physical deployment on a Franka-Emika-Panda robot validates real-world applicability.", "AI": {"tldr": "提出了一种名为Dispersive MeanFlow Policy Optimization (DMPO) 的统一框架，用于实现真实的一步式行动生成。", "motivation": "现有的基于扩散和流匹配的生成策略需要多步骤采样，在时间关键场景中限制了部署。为此，该研究提出了一个可以进行单步推理的新方法。", "method": "提出了一种名为Dispersive MeanFlow Policy Optimization (DMPO) 的统一框架，通过三个关键组成部分实现：MeanFlow（无需知识蒸馏的数学推导式单一步骤推理）、分散正则化防止表示坍塌、强化学习微调超过专家演示。这些方法共同作用以提高生成策略的速度和性能。", "result": "实验表明，在RoboMimic操作和OpenAI Gym行走基准测试中，该模型的表现与多步基线相比具有竞争力甚至更优。此外，其轻量级架构使得DMPO能够在高性能GPU上实现每秒数百次的推理速度，并在实际部署于Franka-Emika-Panda机器人时显示出适用性。", "conclusion": "通过结合MeanFlow、分散正则化和强化学习微调，Dispersive MeanFlow Policy Optimization (DMPO) 在实时控制需求(>120Hz)中表现出卓越的性能并达到5到20倍的推理加速。"}}
{"id": "2601.20696", "pdf": "https://arxiv.org/pdf/2601.20696", "abs": "https://arxiv.org/abs/2601.20696", "authors": ["Samira Yazdanpourmoghadam", "Mahan Balal Pour", "Vahid Partovi Nia"], "title": "Enterprise Resource Planning Using Multi-type Transformers in Ferro-Titanium Industry", "categories": ["cs.AI", "cs.LG"], "comment": ":68R01ACM Class:G.2.3", "summary": "Combinatorial optimization problems such as the Job-Shop Scheduling Problem (JSP) and Knapsack Problem (KP) are fundamental challenges in operations research, logistics, and eterprise resource planning (ERP). These problems often require sophisticated algorithms to achieve near-optimal solutions within practical time constraints. Recent advances in deep learning have introduced transformer-based architectures as promising alternatives to traditional heuristics and metaheuristics. We leverage the Multi-Type Transformer (MTT) architecture to address these benchmarks in a unified framework. We present an extensive experimental evaluation across standard benchmark datasets for JSP and KP, demonstrating that MTT achieves competitive performance on different size of these benchmark problems. We showcase the potential of multi-type attention on a real application in Ferro-Titanium industry. To the best of our knowledge, we are the first to apply multi-type transformers in real manufacturing.", "AI": {"tldr": "本文利用多类型变压器架构解决组合优化问题，特别是在钢铁钛行业中的应用。", "motivation": "组合优化问题是运营管理、物流和企业资源规划中的基本挑战，需要复杂的算法来在实际的时间限制内接近最优解。传统的启发式方法可能不足以应对这些问题的复杂性，因此引入了基于深度学习的变压器架构作为替代方案。", "method": "本文提出了一种多类型变压器（MTT）架构，用于解决作业车间调度问题和背包问题，并通过标准基准数据集进行了广泛的实验评估，证明了该模型在不同规模的问题上均能达到竞争性性能。", "result": "实验结果表明，所提出的多类型变压器模型能够有效处理各种规模的组合优化问题，并展示了其在钢铁钛行业的实际应用潜力。", "conclusion": "本文首次将多类型变压器应用于真实制造环境中的组合优化任务，并证明了该方法的有效性和优越性。"}}
{"id": "2601.20689", "pdf": "https://arxiv.org/pdf/2601.20689", "abs": "https://arxiv.org/abs/2601.20689", "authors": ["Xinyue Li", "Zhichao Zhang", "Zhiming Xu", "Shubo Xu", "Xiongkuo Min", "Yitong Chen", "Guangtao Zhai"], "title": "Decoupling Perception and Calibration: Label-Efficient Image Quality Assessment Framework", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent multimodal large language models (MLLMs) have demonstrated strong capabilities in image quality assessment (IQA) tasks. However, adapting such large-scale models is computationally expensive and still relies on substantial Mean Opinion Score (MOS) annotations. We argue that for MLLM-based IQA, the core bottleneck lies not in the quality perception capacity of MLLMs, but in MOS scale calibration. Therefore, we propose LEAF, a Label-Efficient Image Quality Assessment Framework that distills perceptual quality priors from an MLLM teacher into a lightweight student regressor, enabling MOS calibration with minimal human supervision. Specifically, the teacher conducts dense supervision through point-wise judgments and pair-wise preferences, with an estimate of decision reliability. Guided by these signals, the student learns the teacher's quality perception patterns through joint distillation and is calibrated on a small MOS subset to align with human annotations. Experiments on both user-generated and AI-generated IQA benchmarks demonstrate that our method significantly reduces the need for human annotations while maintaining strong MOS-aligned correlations, making lightweight IQA practical under limited annotation budgets.", "AI": {"tldr": "提出一种标签效率高的图像质量评估框架LEAF，以减少对大量MOS标注的需求。", "motivation": "现有基于多模态大规模语言模型的图像质量评估依赖于大量的MOS注释，并且适应这些大尺度模型计算成本高。研究认为瓶颈在于校准而非感知能力。", "method": "通过教师-学生机制将感知质量先验从大型模型传递到轻量级回归器，利用点对和成对标记进行密集监督，使学生能够学习老师的模式并通过少量注释与人类标注对齐。", "result": "实验表明该方法显著减少了人工标签的需要，并保持了与MOS相关的强关联。", "conclusion": "LEAF框架使得在有限标注预算下实现轻量级图像质量评估成为可能。"}}
{"id": "2601.20683", "pdf": "https://arxiv.org/pdf/2601.20683", "abs": "https://arxiv.org/abs/2601.20683", "authors": ["Samuel Rhys Cox", "Joel Wester", "Niels van Berkel"], "title": "Polite But Boring? Trade-offs Between Engagement and Psychological Reactance to Chatbot Feedback Styles", "categories": ["cs.HC", "cs.CL"], "comment": "To appear at ACM CHI 2026. 21 pages, 7 figures, 5 tables", "summary": "As conversational agents become increasingly common in behaviour change interventions, understanding optimal feedback delivery mechanisms becomes increasingly important. However, choosing a style that both lessens psychological reactance (perceived threats to freedom) while simultaneously eliciting feelings of surprise and engagement represents a complex design problem. We explored how three different feedback styles: 'Direct', 'Politeness', and 'Verbal Leakage' (slips or disfluencies to reveal a desired behaviour) affect user perceptions and behavioural intentions. Matching expectations from literature, the 'Direct' chatbot led to lower behavioural intentions and higher reactance, while the 'Politeness' chatbot evoked higher behavioural intentions and lower reactance. However, 'Politeness' was also seen as unsurprising and unengaging by participants. In contrast, 'Verbal Leakage' evoked reactance, yet also elicited higher feelings of surprise, engagement, and humour. These findings highlight that effective feedback requires navigating trade-offs between user reactance and engagement, with novel approaches such as 'Verbal Leakage' offering promising alternative design opportunities.", "AI": {"tldr": "研究探讨了三种反馈风格（直接、礼貌和言语泄漏）对用户感知及行为意图的影响。", "motivation": "随着对话代理在行为改变干预中的普及，理解最优的反馈传递机制变得越来越重要。选择既能减少心理抗拒又能引发惊喜和参与感的方式是一个复杂的设计问题。", "method": "研究了三种不同的反馈风格：直接、礼貌和言语泄漏对用户感知及行为意图的影响。", "result": "'直接'聊天机器人导致较低的行为意图和较高的心理抵抗，而'礼貌'聊天机器人则激发较高行为意图和较低的反应。然而,'礼貌'也被认为是不令人惊讶且无趣的。相比之下, '言语泄漏'虽引发抗拒但也引发了更高的惊喜感、参与度和幽默。", "conclusion": "有效的反馈需要在用户心理抵抗和参与之间做出权衡，新颖的方法如‘言语泄漏’提供了有希望的设计机会"}}
{"id": "2601.20682", "pdf": "https://arxiv.org/pdf/2601.20682", "abs": "https://arxiv.org/abs/2601.20682", "authors": ["Péter Polcz", "Katalin Schäffer", "Miklós Koller"], "title": "Tendon-based modelling, estimation and control for a simulated high-DoF anthropomorphic hand model", "categories": ["cs.RO"], "comment": ":70B15ACM Class:I.2.9", "summary": "Tendon-driven anthropomorphic robotic hands often lack direct joint angle sensing, as the integration of joint encoders can compromise mechanical compactness and dexterity. This paper presents a computational method for estimating joint positions from measured tendon displacements and tensions. An efficient kinematic modeling framework for anthropomorphic hands is first introduced based on the Denavit-Hartenberg convention. Using a simplified tendon model, a system of nonlinear equations relating tendon states to joint positions is derived and solved via a nonlinear optimization approach. The estimated joint angles are then employed for closed-loop control through a Jacobian-based proportional-integral (PI) controller augmented with a feedforward term, enabling gesture tracking without direct joint sensing. The effectiveness and limitations of the proposed estimation and control framework are demonstrated in the MuJoCo simulation environment using the Anatomically Correct Biomechatronic Hand, featuring five degrees of freedom for each long finger and six degrees of freedom for the thumb.", "AI": {"tldr": "本文提出了一种基于肌腱位移和张力估计关节角度的方法，并使用该方法实现了无需直接关节传感器的手势跟踪。", "motivation": "传统的人类手模型由于集成关节编码器会损害机械紧凑性和灵巧性，因此缺乏直接的关节角度感知。为了克服这一问题，本文提出了一种基于肌腱状态估计关节位置的新方法。", "method": "首先介绍了基于Denavit-Hartenberg约定的手部几何建模框架，并通过简化后的肌腱模型建立了非线性方程组以确定关节位置。利用非线性优化技术求解该系统，然后使用基于雅可比矩阵的比例积分控制器进行闭环控制。", "result": "在MuJoCo仿真环境中验证了所提出的估计和控制方法的有效性和局限性，并展示了五指各五个自由度及拇指六个自由度的仿生手模型的手势跟踪能力。", "conclusion": "本文提出了用于肌腱驱动的人工手的关节角度估算和闭环控制的新技术，证明了在无直接关节传感器的情况下实现手势精确跟踪的可能性。"}}
{"id": "2601.20675", "pdf": "https://arxiv.org/pdf/2601.20675", "abs": "https://arxiv.org/abs/2601.20675", "authors": ["Pankhi Kashyap", "Mainak Singha", "Biplab Banerjee"], "title": "bi-modal textual prompt learning for vision-language models in remote sensing", "categories": ["cs.CV"], "comment": "Accepted in ICASSP 2026", "summary": "Prompt learning (PL) has emerged as an effective strategy to adapt vision-language models (VLMs), such as CLIP, for downstream tasks under limited supervision. While PL has demonstrated strong generalization on natural image datasets, its transferability to remote sensing (RS) imagery remains underexplored. RS data present unique challenges, including multi-label scenes, high intra-class variability, and diverse spatial resolutions, that hinder the direct applicability of existing PL methods. In particular, current prompt-based approaches often struggle to identify dominant semantic cues and fail to generalize to novel classes in RS scenarios. To address these challenges, we propose BiMoRS, a lightweight bi-modal prompt learning framework tailored for RS tasks. BiMoRS employs a frozen image captioning model (e.g., BLIP-2) to extract textual semantic summaries from RS images. These captions are tokenized using a BERT tokenizer and fused with high-level visual features from the CLIP encoder. A lightweight cross-attention module then conditions a learnable query prompt on the fused textual-visual representation, yielding contextualized prompts without altering the CLIP backbone. We evaluate BiMoRS on four RS datasets across three domain generalization (DG) tasks and observe consistent performance gains, outperforming strong baselines by up to 2% on average. Codes are available at https://github.com/ipankhi/BiMoRS.", "AI": {"tldr": "提出了一种用于遥感图像的双模态提示学习框架BiMoRS，以增强视觉-语言模型在多标签场景和高类内变异性条件下的泛化能力。", "motivation": "当前的提示学习方法在处理遥感数据时面临挑战，如无法有效识别主要语义线索以及难以推广到新类别。为了应对这些难题，该论文提出了一种专门为遥感任务设计的双模态提示学习框架BiMoRS。", "method": "使用冻结的图像描述模型（例如BLIP-2）从遥感图像中提取文本语义摘要，并通过BERT对这些摘录进行分词处理。随后将得到的文本嵌入与高阶视觉特征融合，采用轻量级交叉注意力模块根据结合后的文本-视觉表示来调整可学习提示。", "result": "在四个不同领域的遥感数据集上进行了测试，在三项领域泛化任务中均取得了显著性能提升，平均优于其他基准方法2%以上。", "conclusion": "BiMoRS框架证明了其增强视觉-语言模型对复杂多变的遥感场景进行分类和识别的能力。"}}
{"id": "2601.20674", "pdf": "https://arxiv.org/pdf/2601.20674", "abs": "https://arxiv.org/abs/2601.20674", "authors": ["Juan Jose Rubio Jan", "Jack Wu", "Julia Ive"], "title": "Harnessing Large Language Models for Precision Querying and Retrieval-Augmented Knowledge Extraction in Clinical Data Science", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 5 figures", "summary": "This study applies Large Language Models (LLMs) to two foundational Electronic Health Record (EHR) data science tasks: structured data querying (using programmatic languages, Python/Pandas) and information extraction from unstructured clinical text via a Retrieval Augmented Generation (RAG) pipeline. We test the ability of LLMs to interact accurately with large structured datasets for analytics and the reliability of LLMs in extracting semantically correct information from free text health records when supported by RAG. To this end, we presented a flexible evaluation framework that automatically generates synthetic question and answer pairs tailored to the characteristics of each dataset or task. Experiments were conducted on a curated subset of MIMIC III, (four structured tables and one clinical note type), using a mix of locally hosted and API-based LLMs. Evaluation combined exact-match metrics, semantic similarity, and human judgment. Our findings demonstrate the potential of LLMs to support precise querying and accurate information extraction in clinical workflows.", "AI": {"tldr": "该研究将大型语言模型应用于电子健康记录的数据查询和信息提取任务。", "motivation": "探讨大型语言模型在处理结构化数据查询和从无结构临床文本中抽取准确信息方面的潜力与可靠性。", "method": "提出了一种灵活的评估框架，用于生成针对特定数据集或任务定制的问题和答案对，并利用混合本地托管和API支持的语言模型进行实验。", "result": "实验结果显示了大型语言模型在电子健康记录数据分析中的潜在价值。", "conclusion": "研究证明了大型语言模型可以辅助临床工作流程中精确查询和准确信息提取的能力。"}}
{"id": "2601.20668", "pdf": "https://arxiv.org/pdf/2601.20668", "abs": "https://arxiv.org/abs/2601.20668", "authors": ["Shuhao Liao", "Peizhuo Li", "Xinrong Yang", "Linnan Chang", "Zhaoxin Fan", "Qing Wang", "Lei Shi", "Yuhong Cao", "Wenjun Wu", "Guillaume Sartoretti"], "title": "GPO: Growing Policy Optimization for Legged Robot Locomotion and Whole-Body Control", "categories": ["cs.RO"], "comment": null, "summary": "Training reinforcement learning (RL) policies for legged robots remains challenging due to high-dimensional continuous actions, hardware constraints, and limited exploration. Existing methods for locomotion and whole-body control work well for position-based control with environment-specific heuristics (e.g., reward shaping, curriculum design, and manual initialization), but are less effective for torque-based control, where sufficiently exploring the action space and obtaining informative gradient signals for training is significantly more difficult. We introduce Growing Policy Optimization (GPO), a training framework that applies a time-varying action transformation to restrict the effective action space in the early stage, thereby encouraging more effective data collection and policy learning, and then progressively expands it to enhance exploration and achieve higher expected return. We prove that this transformation preserves the PPO update rule and introduces only bounded, vanishing gradient distortion, thereby ensuring stable training. We evaluate GPO on both quadruped and hexapod robots, including zero-shot deployment of simulation-trained policies on hardware. Policies trained with GPO consistently achieve better performance. These results suggest that GPO provides a general, environment-agnostic optimization framework for learning legged locomotion.", "AI": {"tldr": "该论文提出了一种针对足式机器人运动和全身控制的训练框架GPO，通过时间变化的动作转换来限制有效动作空间，鼓励更有效的数据收集和策略学习，并逐步扩大探索范围以实现更高的预期回报。", "motivation": "现有的方法在位置控制下运行良好，但在扭矩控制中表现较差。高维连续行动、硬件限制以及有限的探索使得足式机器人的强化学习训练变得具有挑战性。", "method": "GPO通过应用时间变化的动作转换来逐步扩大有效动作空间，以鼓励更多的数据收集和策略学习，并确保稳定训练引入了有界且渐消的梯度失真。该方法证明可以保持PPO更新规则。", "result": "在四足机器人和六足机器人的评估中，使用GPO训练的政策始终表现更好，表明GPO为学习足式运动提供了一种通用、环境无关的优化框架。", "conclusion": "通过逐步扩大有效动作空间来提高探索性和训练效率，GPO方法展示了其在足式机器人运动中的有效性，适用于模拟到硬件的零样本部署。"}}
{"id": "2601.20666", "pdf": "https://arxiv.org/pdf/2601.20666", "abs": "https://arxiv.org/abs/2601.20666", "authors": ["Alejandro Luque-Cerpa", "Mengyuan Wang", "Emil Carlsson", "Sanjit A. Seshia", "Devdatt Dubhashi", "Hazem Torfah"], "title": "Learning Contextual Runtime Monitors for Safe AI-Based Autonomy", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "We introduce a novel framework for learning context-aware runtime monitors for AI-based control ensembles. Machine-learning (ML) controllers are increasingly deployed in (autonomous) cyber-physical systems because of their ability to solve complex decision-making tasks. However, their accuracy can degrade sharply in unfamiliar environments, creating significant safety concerns. Traditional ensemble methods aim to improve robustness by averaging or voting across multiple controllers, yet this often dilutes the specialized strengths that individual controllers exhibit in different operating contexts. We argue that, rather than blending controller outputs, a monitoring framework should identify and exploit these contextual strengths. In this paper, we reformulate the design of safe AI-based control ensembles as a contextual monitoring problem. A monitor continuously observes the system's context and selects the controller best suited to the current conditions. To achieve this, we cast monitor learning as a contextual learning task and draw on techniques from contextual multi-armed bandits. Our approach comes with two key benefits: (1) theoretical safety guarantees during controller selection, and (2) improved utilization of controller diversity. We validate our framework in two simulated autonomous driving scenarios, demonstrating significant improvements in both safety and performance compared to non-contextual baselines.", "AI": {"tldr": "本文提出了一种学习上下文感知运行时监控器的框架，用于AI控制集合的安全性。", "motivation": "随着机器学习控制器在（自主）网络物理系统中的部署增加，由于其解决复杂决策任务的能力，这些系统的准确性可能会在不熟悉环境中急剧下降，从而引发严重的安全问题。传统的集成方法通过平均或投票来提高鲁棒性，但这种方式往往会削弱各个控制器在不同操作上下文下的专业优势。", "method": "本文将设计安全的AI控制集合重新定义为一个上下文监控问题，并提出一种基于多臂赌博机技术的学习上下文感知运行时监测器的方法。该方法能够提供理论上的安全性保证，在选择控制器时利用多样性提高性能。", "result": "在两个模拟自主驾驶场景中验证了框架的有效性，表明与非上下文基线相比，在安全性和性能方面都有显著提升。", "conclusion": "本文提出了一种新的学习上下文感知运行时监控器的方法，可以提高AI控制集合的安全性和性能。"}}
{"id": "2601.20663", "pdf": "https://arxiv.org/pdf/2601.20663", "abs": "https://arxiv.org/abs/2601.20663", "authors": ["Xuyi Hu", "Ke Ma", "Siwei Liu", "Per Ola Kristensson", "Stephan Goetz"], "title": "A Multi-Camera Optical Tag Neuronavigation and AR Augmentation Framework for Non-Invasive Brain Stimulation", "categories": ["cs.HC"], "comment": "arXiv admin note: text overlap with arXiv:2601.16862", "summary": "Accurate neuronavigation is essential for generating the intended effect with transcranial magnetic stimulation (TMS). Precise coil placement also directly influences stimulation efficacy. Traditional neuronavigation systems often rely on costly and still hard to use and error-prone tracking systems. To solve these limitations, we present a computer-vision-based neuronavigation system for real-time tracking of patient and TMS instrumentation. The system can feed the necessary data for a digital twin to track TMS stimulation targets. We integrate a self-coordinating optical tracking system with multiple consumer-grade cameras and visible tags with a dynamic 3D brain model in Unity. This model updates in real time to represent the current stimulation coil position and the estimated stimulation point to intuitively visualize neural targets for clinicians. We incorporate an augmented reality (AR) module to bridge the gap between the visualization of the digital twin and the real world and project the brain model in real-time onto the head of a patient. AR headsets or mobile AR devices allow clinicians to interactively view and adjust the placement of the stimulation transducer intuitively instead of guidance through abstract numbers and 6D cross hairs on an external screen. The proposed technique provides improved spatial precision as well as accuracy. A case study with ten participants with a medical background also demonstrates that the system has high usability.", "AI": {"tldr": "论文提出了一种基于计算机视觉的实时神经导航系统，用于精确跟踪经颅磁刺激(TMS)仪器和患者位置。", "motivation": "为了克服传统神经导航系统的高成本、使用复杂及易出错的问题，该研究开发了一种新的神经导航方法。", "method": "通过多个消费级摄像头与可见标签结合的自协调光学追踪系统，并在Unity中实时更新一个动态3D大脑模型，实现对TMS刺激目标的精准跟踪。同时引入增强现实(AR)模块将脑部模型投影至患者头部，方便临床医生直观地调整刺激器的位置。", "result": "该技术提高了空间精度和准确性。通过十名具有医学背景的研究参与者进行案例研究也证明了系统的高可用性。", "conclusion": "论文提出了一种基于多摄像头、光学标签与AR融合的神经导航框架，能够为非侵入式脑刺激提供准确的位置跟踪及直观的用户界面。"}}
{"id": "2601.20661", "pdf": "https://arxiv.org/pdf/2601.20661", "abs": "https://arxiv.org/abs/2601.20661", "authors": ["Michele Mazzamuto", "Daniele Di Mauro", "Gianpiero Francesca", "Giovanni Maria Farinella", "Antonino Furnari"], "title": "ProSkill: Segment-Level Skill Assessment in Procedural Videos", "categories": ["cs.CV"], "comment": "Accepted at The IEEE/CVF Winter Conference on Applications of Computer Vision 2026", "summary": "Skill assessment in procedural videos is crucial for the objective evaluation of human performance in settings such as manufacturing and procedural daily tasks. Current research on skill assessment has predominantly focused on sports and lacks large-scale datasets for complex procedural activities. Existing studies typically involve only a limited number of actions, focus on either pairwise assessments (e.g., A is better than B) or on binary labels (e.g., good execution vs needs improvement). In response to these shortcomings, we introduce ProSkill, the first benchmark dataset for action-level skill assessment in procedural tasks. ProSkill provides absolute skill assessment annotations, along with pairwise ones. This is enabled by a novel and scalable annotation protocol that allows for the creation of an absolute skill assessment ranking starting from pairwise assessments. This protocol leverages a Swiss Tournament scheme for efficient pairwise comparisons, which are then aggregated into consistent, continuous global scores using an ELO-based rating system. We use our dataset to benchmark the main state-of-the-art skill assessment algorithms, including both ranking-based and pairwise paradigms. The suboptimal results achieved by the current state-of-the-art highlight the challenges and thus the value of ProSkill in the context of skill assessment for procedural videos. All data and code are available at https://fpv-iplab.github.io/ProSkill/", "AI": {"tldr": "介绍了一个用于程序化视频中动作级技能评估的基准数据集ProSkill", "motivation": "当前研究主要集中在体育领域的技能评估，缺乏大规模复杂程序性任务的数据集。现有研究通常只涉及有限的动作，并且侧重于二元标签或成对比较，无法提供绝对技能水平评估。为了填补这一空白，提出了一种新的注释协议和数据集ProSkill", "method": "通过瑞士轮比赛方案进行高效成对比较，并使用ELO评分系统将这些成对的评估转化为一致的连续全局评分", "result": "基准测试显示当前最先进方法在程序性视频技能评估中表现欠佳，突显了ProSkill的价值", "conclusion": "ProSkill为程序化任务中的技能评估提供了新的数据和协议，有助于推动该领域的研究进展"}}
{"id": "2601.20656", "pdf": "https://arxiv.org/pdf/2601.20656", "abs": "https://arxiv.org/abs/2601.20656", "authors": ["Diogo J. Paulo", "Hugo Proença", "João C. Neves"], "title": "FD-MAD: Frequency-Domain Residual Analysis for Face Morphing Attack Detection", "categories": ["cs.CV"], "comment": null, "summary": "Face morphing attacks present a significant threat to face recognition systems used in electronic identity enrolment and border control, particularly in single-image morphing attack detection (S-MAD) scenarios where no trusted reference is available. In spite of the vast amount of research on this problem, morph detection systems struggle in cross-dataset scenarios. To address this problem, we introduce a region-aware frequency-based morph detection strategy that drastically improves over strong baseline methods in challenging cross-dataset and cross-morph settings using a lightweight approach. Having observed the separability of bona fide and morph samples in the frequency domain of different facial parts, our approach 1) introduces the concept of residual frequency domain, where the frequency of the signal is decoupled from the natural spectral decay to easily discriminate between morph and bona fide data; 2) additionally, we reason in a global and local manner by combining the evidence from different facial regions in a Markov Random Field, which infers a globally consistent decision. The proposed method, trained exclusively on the synthetic morphing attack detection development dataset (SMDD), is evaluated in challenging cross-dataset and cross-morph settings on FRLL-Morph and MAD22 sets. Our approach achieves an average equal error rate (EER) of 1.85\\% on FRLL-Morph and ranks second on MAD22 with an average EER of 6.12\\%, while also obtaining a good bona fide presentation classification error rate (BPCER) at a low attack presentation classification error rate (APCER) using only spectral features. These findings indicate that Fourier-domain residual modeling with structured regional fusion offers a competitive alternative to deep S-MAD architectures.", "AI": {"tldr": "本文提出了一种基于频率域残差分析的面部合成攻击检测方法FD-MAD，该方法在单图像面部合成攻击检测（S-MAD）场景中表现出色。", "motivation": "面部合成攻击对电子身份注册和边境控制中的面部识别系统构成重大威胁。尽管在此问题上进行了大量研究，但形态检测系统的跨数据集表现不佳。本文旨在提出一种有效的解决方案以提高这类系统的性能。", "method": "该方法基于频率域的残差分析，并结合马尔可夫随机场进行全局和局部证据融合，从而在不同的面部区域中做出一致的决策。通过仅使用合成形态攻击检测开发数据集（SMDD）训练模型，在挑战性的跨数据集设置下进行了评估。", "result": "该方法在FRLL-Morph数据集上实现了1.85%的平均等错误率（EER），并在MAD22数据集中排名第二，具有6.12%的平均EER。同时，它还以较低的攻击呈现分类误差率（APCER）获得了良好的真实呈现分类误差率（BPCER）。", "conclusion": "研究表明，基于频率域残差建模和结构化区域融合的方法为深度S-MAD架构提供了一个有竞争力的选择。"}}
{"id": "2601.20650", "pdf": "https://arxiv.org/pdf/2601.20650", "abs": "https://arxiv.org/abs/2601.20650", "authors": ["Jing Wu", "Daphne Barretto", "Yiye Chen", "Nicholas Gydé", "Yanan Jian", "Yuhang He", "Vibhav Vineet"], "title": "OS-Marathon: Benchmarking Computer-Use Agents on Long-Horizon Repetitive Tasks", "categories": ["cs.CV"], "comment": "22 Pages, Project Page: \\url{https://os-marathon.github.io/}", "summary": "Long-horizon, repetitive workflows are common in professional settings, such as processing expense reports from receipts and entering student grades from exam papers. These tasks are often tedious for humans since they can extend to extreme lengths proportional to the size of the data to process. However, they are ideal for Computer-Use Agents (CUAs) due to their structured, recurring sub-workflows with logic that can be systematically learned. Identifying the absence of an evaluation benchmark as a primary bottleneck, we establish OS-Marathon, comprising 242 long-horizon, repetitive tasks across 2 domains to evaluate state-of-the-art (SOTA) agents. We then introduce a cost-effective method to construct a condensed demonstration using only few-shot examples to teach agents the underlying workflow logic, enabling them to execute similar workflows effectively on larger, unseen data collections. Extensive experiments demonstrate both the inherent challenges of these tasks and the effectiveness of our proposed method. Project website: https://os-marathon.github.io/.", "AI": {"tldr": "该论文提出了OS-Marathon，一个包含长时重复任务的基准测试平台，并提出了一种通过少量示例教会代理执行复杂工作流的方法。", "motivation": "长期重复的任务在专业环境中很常见且乏味，但适合计算机使用代理处理。作者发现缺乏评估这些任务的基准是主要瓶颈，因此创建了OS-Marathon来填补这一空白。", "method": "该研究建立了一个包含242个长时重复任务的基准测试平台，并提出了一种成本效益高的方法，通过少量示例教授代理执行复杂工作流的能力。", "result": "实验结果显示提出的评估基准和训练方法能够有效解决长期重复任务的挑战。", "conclusion": "研究证明了OS-Marathon在评价计算机使用代理处理长时重复任务方面的有效性，并展示了通过有限的示范来学习和执行大型数据集中的复杂工作流的成功。"}}
{"id": "2601.20642", "pdf": "https://arxiv.org/pdf/2601.20642", "abs": "https://arxiv.org/abs/2601.20642", "authors": ["Rohan Asthana", "Vasileios Belagiannis"], "title": "Detecting and Mitigating Memorization in Diffusion Models through Anisotropy of the Log-Probability", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted at ICLR 2026", "summary": "Diffusion-based image generative models produce high-fidelity images through iterative denoising but remain vulnerable to memorization, where they unintentionally reproduce exact copies or parts of training images. Recent memorization detection methods are primarily based on the norm of score difference as indicators of memorization. We prove that such norm-based metrics are mainly effective under the assumption of isotropic log-probability distributions, which generally holds at high or medium noise levels. In contrast, analyzing the anisotropic regime reveals that memorized samples exhibit strong angular alignment between the guidance vector and unconditional scores in the low-noise setting. Through these insights, we develop a memorization detection metric by integrating isotropic norm and anisotropic alignment. Our detection metric can be computed directly on pure noise inputs via two conditional and unconditional forward passes, eliminating the need for costly denoising steps. Detection experiments on Stable Diffusion v1.4 and v2 show that our metric outperforms existing denoising-free detection methods while being at least approximately 5x faster than the previous best approach. Finally, we demonstrate the effectiveness of our approach by utilizing a mitigation strategy that adapts memorized prompts based on our developed metric.", "AI": {"tldr": "本文提出了一种基于对数概率各向异性分析的扩散模型记忆化检测和缓解方法。", "motivation": "当前扩散模型在生成图像时易发生记忆化现象，即无意中复制训练数据中的具体片段。现有的检测方法主要依赖于分数差分范数指标，在某些条件下效果有限。", "method": "作者证明了基于同性对数概率分布的分数差异范数度量的有效性，并引入了一个结合各向异性角度一致性的新度量，通过分析低噪声环境下指导矢量与无条件得分之间的强角对齐来检测记忆化。该方法利用纯噪声输入直接计算指标。", "result": "实验表明，所提出的方法在Stable Diffusion v1.4和v2上的检测效果优于现有的无需去噪步骤的检测方式，并且速度至少快5倍。", "conclusion": "本文提出的基于对数概率各向异性的记忆化检测方法有效提高了扩散模型生成图像的质量。"}}
{"id": "2601.20641", "pdf": "https://arxiv.org/pdf/2601.20641", "abs": "https://arxiv.org/abs/2601.20641", "authors": ["Boaz Carmeli", "Orr Paradise", "Shafi Goldwasser", "Yonatan Belinkov", "Ron Meir"], "title": "Investigating the Development of Task-Oriented Communication in Vision-Language Models", "categories": ["cs.AI"], "comment": null, "summary": "We investigate whether \\emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.", "AI": {"tldr": "研究基于LLM的代理在协作推理任务中是否能发展出不同于自然语言的任务导向性沟通协议。", "motivation": "探索LLM代理能否开发高效的，只传达相关任务信息，并且对外部观察者难以解读的任务导向性沟通协议，以及这种现象带来的透明度和控制权问题。", "method": "在参照游戏框架中测试视觉-语言模型之间的交流能力，这是一个受控的、可测量的情境。通过实验检验这些代理是否能开发有效的任务适应型交流模式，并观察它们能否自发协调而无需明确共享协议。", "result": "实验表明，视觉-语言模型可以发展出高效的、针对特定任务的沟通模式，同时还能形成人类和外部代理人难以理解的秘密通讯协议。", "conclusion": "这些发现强调了任务导向性通信的潜力及其带来的风险，并指出参照游戏是未来研究该领域的重要测试平台。"}}
{"id": "2601.20629", "pdf": "https://arxiv.org/pdf/2601.20629", "abs": "https://arxiv.org/abs/2601.20629", "authors": ["Aditya Mitra", "Hamza Haroon", "Amaan Rais Shah", "Mohammad Elham Rasooli", "Bogdan Itsam Dorantes Nikolaev", "Tuğçe Ballı"], "title": "/dev/SDB: Software Defined Boot -- A novel standard for diskless booting anywhere and everywhere", "categories": ["cs.CR", "cs.ET", "cs.OS"], "comment": null, "summary": "A computer is nothing but a device that processes the instructions supplied to it. However, as computers evolved, the instructions or codes started to be more complicated. As computers started to be used by non-technical people, it became imperative that the users be able to use the machine without having underlying knowledge of the code or the hardware. And operating system became the backbone for translating the inputs from the user to actual operation on the hardware. With the increasing complexity and the choices of operating system, it became clear that different groups of people, especially in an enterprise scenario, required different operating systems. Installing them all on a single machine, for shared computers became a difficult task, giving rise to network-based booting. But network-based booting was confined to only wired connectivity, keeping it restricted to very small geographical areas. The proposed system, /dev/SDB, is aimed at creating a standard where any user, anyone on the globe, can access the operating system authorized to them without having to be on the corporate network. It aims to offer the same over Wi-Fi as well as cellular connectivity, ensuring employees can truly work from anywhere, while following the policies for operating systems and without redundant hardware.", "AI": {"tldr": "/dev/SDB 提出了一种新型的无盘启动标准，使用户能够在全球范围内通过 Wi-Fi 和蜂窝网络访问授权的操作系统。", "motivation": "随着计算机技术的发展，不同企业部门需要不同的操作系统。然而，安装多个操作系统在一台共享机器上变得困难，并且现有的网络无盘启动仅限于有线连接的较小地理区域，限制了用户的工作地点灵活性。", "method": "/dev/SDB 提出了一种新的标准，允许任何人在全球范围内通过 Wi-Fi 和蜂窝网络访问授权的操作系统。", "result": "该方法确保员工可以在任何地方工作，并遵循操作系统政策，同时避免冗余硬件的使用。", "conclusion": "通过提供一种新型的标准和解决方案，/dev/SDB 解决了现有无盘启动技术的局限性，使企业用户能够更加灵活地访问所需的操作系统。"}}
{"id": "2601.20622", "pdf": "https://arxiv.org/pdf/2601.20622", "abs": "https://arxiv.org/abs/2601.20622", "authors": ["Boyu Li", "Lin-Ping Yuan", "Zeyu Wang", "Hongbo Fu"], "title": "SketchDynamics: Exploring Free-Form Sketches for Dynamic Intent Expression in Animation Generation", "categories": ["cs.HC"], "comment": "conditionally accepted by CHI'26", "summary": "Sketching provides an intuitive way to convey dynamic intent in animation authoring (i.e., how elements change over time and space), making it a natural medium for automatic content creation. Yet existing approaches often constrain sketches to fixed command tokens or predefined visual forms, overlooking their freeform nature and the central role of humans in shaping intention. To address this, we introduce an interaction paradigm where users convey dynamic intent to a vision-language model via free-form sketching, instantiated here in a sketch storyboard to motion graphics workflow. We implement an interface and improve it through a three-stage study with 24 participants. The study shows how sketches convey motion with minimal input, how their inherent ambiguity requires users to be involved for clarification, and how sketches can visually guide video refinement. Our findings reveal the potential of sketch and AI interaction to bridge the gap between intention and outcome, and demonstrate its applicability to 3D animation and video generation.", "AI": {"tldr": "探索使用自由形式的草图表达动态意图在动画生成中的应用。", "motivation": "现有方法倾向于将草图限制为固定的命令标记或预定义的形式，忽略了它们的自由性质以及人类在塑造意图方面的重要作用。因此，该研究旨在通过一种新的交互模式来解决这个问题。", "method": "提出了一个用户可以通过自由形式的草图向视觉-语言模型传达动态意图的方法，并通过一项三阶段的研究与24名参与者一起完善了这种方法。", "result": "研究表明草图可以以最少的输入传递运动，其内在的模糊性需要用户的参与进行澄清。此外，草图能够引导视频的细化过程。", "conclusion": "该方法展示了利用草图和AI交互来弥合意图与结果之间的差距，并证明了这种方法在3D动画和视频生成中的适用性。"}}
{"id": "2601.20618", "pdf": "https://arxiv.org/pdf/2601.20618", "abs": "https://arxiv.org/abs/2601.20618", "authors": ["Shuguang Zhang", "Junhong Lian", "Guoxin Yu", "Baoxun Xu", "Xiang Ao"], "title": "GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Multimodal sarcasm detection (MSD) aims to identify sarcasm within image-text pairs by modeling semantic incongruities across modalities. Existing methods often exploit cross-modal embedding misalignment to detect inconsistency but struggle when visual and textual content are loosely related or semantically indirect. While recent approaches leverage large language models (LLMs) to generate sarcastic cues, the inherent diversity and subjectivity of these generations often introduce noise. To address these limitations, we propose the Generative Discrepancy Comparison Network (GDCNet). This framework captures cross-modal conflicts by utilizing descriptive, factually grounded image captions generated by Multimodal LLMs (MLLMs) as stable semantic anchors. Specifically, GDCNet computes semantic and sentiment discrepancies between the generated objective description and the original text, alongside measuring visual-textual fidelity. These discrepancy features are then fused with visual and textual representations via a gated module to adaptively balance modality contributions. Extensive experiments on MSD benchmarks demonstrate GDCNet's superior accuracy and robustness, establishing a new state-of-the-art on the MMSD2.0 benchmark.", "AI": {"tldr": "本文提出了GDCNet框架，用于检测图像文本对中的讽刺。", "motivation": "现有方法通过跨模态嵌入失配来检测不一致，但在视觉和文本内容松散相关或语义间接的情况下表现不佳。为了解决这些限制，作者提出了一种新的框架以提高检测的准确性和鲁棒性。", "method": "GDCNet使用多模态大型语言模型生成稳定的描述性图像标题作为锚点，并计算生成的目标描述和原始文本之间的语义和情感差异以及视觉-文本一致性。然后将这些差异特征与视觉和文本表示相结合，通过门控模块自适应平衡模式贡献。", "result": "在MSD基准上的广泛实验显示了GDCNet的优越准确性和鲁棒性，并在此基准上建立了新的最先进水平。", "conclusion": "GDCNet通过引入生成性差异比较网络提高了多模态讽刺检测的性能，证明了该方法的有效性和鲁棒性。"}}
{"id": "2601.20617", "pdf": "https://arxiv.org/pdf/2601.20617", "abs": "https://arxiv.org/abs/2601.20617", "authors": ["Jonathan Rystrøm", "Chris Schmitz", "Karolina Korgul", "Jan Batzner", "Chris Russell"], "title": "Agent Benchmarks Fail Public Sector Requirements", "categories": ["cs.CY", "cs.AI"], "comment": "Forthcoming @ IASEAI 2026", "summary": "Deploying Large Language Model-based agents (LLM agents) in the public sector requires assuring that they meet the stringent legal, procedural, and structural requirements of public-sector institutions. Practitioners and researchers often turn to benchmarks for such assessments. However, it remains unclear what criteria benchmarks must meet to ensure they adequately reflect public-sector requirements, or how many existing benchmarks do so. In this paper, we first define such criteria based on a first-principles survey of public administration literature: benchmarks must be \\emph{process-based}, \\emph{realistic}, \\emph{public-sector-specific} and report \\emph{metrics} that reflect the unique requirements of the public sector. We analyse more than 1,300 benchmark papers for these criteria using an expert-validated LLM-assisted pipeline. Our results show that no single benchmark meets all of the criteria. Our findings provide a call to action for both researchers to develop public sector-relevant benchmarks and for public-sector officials to apply these criteria when evaluating their own agentic use cases.", "AI": {"tldr": "分析现有代理基准是否符合公共部门的独特要求，定义了这些基准需要满足的四个标准，并评估超过1300篇文献。", "motivation": "为了确保大型语言模型在公共部门的部署能够满足其严格的要求，研究者和从业者往往依赖于各种基准测试。然而，尚不清楚这些基准是否能充分反映公共部门的需求", "method": "基于对公共行政学文献的综述定义了四个评估标准：过程导向、现实性、专门针对公共部门及报告符合特定需求的指标。并使用专家验证的LLM辅助管道分析超过1300篇基准测试论文。", "result": "结果表明没有单一的基准能够满足所有的标准", "conclusion": "研究指出需要开发出更贴合公共部门实际需求的代理基准，并呼吁官员在评估自己案例时也应用这些标准"}}
{"id": "2601.20614", "pdf": "https://arxiv.org/pdf/2601.20614", "abs": "https://arxiv.org/abs/2601.20614", "authors": ["Yanqi Dai", "Yuxiang Ji", "Xiao Zhang", "Yong Wang", "Xiangxiang Chu", "Zhiwu Lu"], "title": "Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted for ICLR 2026", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.", "AI": {"tldr": "本文提出了一种名为MathForge的框架，通过难度感知的策略优化和多角度问题重构来提升大型模型的数学推理能力。", "motivation": "现有的方法在算法和数据层面忽视了更具挑战性的问题，这限制了模型的能力。作者旨在解决这一问题，强调更难问题的重要性，并提出相应的解决方案。", "method": "MathForge包括两个主要组件：难度感知的群体策略优化（DGPO）和多角度问题重构（MQR）。DGPO修正GRPO中的隐含不平衡并优先处理困难的问题；MQR通过多种方式增加问题难度，同时保持黄金答案不变。二者形成协同循环。", "result": "实验结果表明，MathForge在各种数学推理任务上显著优于现有的方法。", "conclusion": "本文提出的方法成功提升了大型模型的数学推理能力，并提供了改进现有算法的有效途径"}}
{"id": "2601.20606", "pdf": "https://arxiv.org/pdf/2601.20606", "abs": "https://arxiv.org/abs/2601.20606", "authors": ["Xinyu Wang", "Ruoyu Wang", "Qiangwei Peng", "Peijie Zhou", "Tiejun Li"], "title": "WFR-MFM: One-Step Inference for Dynamic Unbalanced Optimal Transport", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": null, "summary": "Reconstructing dynamical evolution from limited observations is a fundamental challenge in single-cell biology, where dynamic unbalanced optimal transport provides a principled framework for modeling coupled transport and mass variation. However, existing approaches rely on trajectory simulation at inference time, making inference a key bottleneck for scalable applications. In this work, we propose a mean-flow framework for unbalanced flow matching that summarizes both transport and mass-growth dynamics over arbitrary time intervals using mean velocity and mass-growth fields, enabling fast one-step generation without trajectory simulation. To solve dynamic unbalanced optimal transport under the Wasserstein-Fisher-Rao geometry, we further build on this framework to develop Wasserstein-Fisher-Rao Mean Flow Matching (WFR-MFM). Across synthetic and real single-cell RNA sequencing datasets, WFR-MFM achieves orders-of-magnitude faster inference than a range of existing baselines while maintaining high predictive accuracy, and enables efficient perturbation response prediction on large synthetic datasets with thousands of conditions.", "AI": {"tldr": "提出了一种基于Wasserstein-Fisher-Rao几何的动态不平衡最优传输方法，实现快速一步生成。", "motivation": "现有方法依赖轨迹模拟进行推断，导致大规模应用时效率低下。目标是开发一种不需要轨迹模拟的方法以提高速度和准确性。", "method": "提出了一种均值流框架来解决动态不平衡最优传输问题，该框架使用平均速度和质量增长场总结运输和质量变化动力学。在此基础上发展了Wasserstein-Fisher-Rao均值流匹配（WFR-MFM）方法。", "result": "在合成数据集和真实单细胞RNA测序数据集中，WFR-MFM实现了比现有基线快几个数量级的推断速度，并保持高预测准确性。此外，在大规模合成数据集上可以有效预测扰动响应。", "conclusion": "WFR-MFM方法能够在不牺牲精度的情况下显著提高动态不平衡最优传输问题中的推断效率，适用于大型数据集和复杂应用场景。"}}
{"id": "2601.20604", "pdf": "https://arxiv.org/pdf/2601.20604", "abs": "https://arxiv.org/abs/2601.20604", "authors": ["Gray Cox"], "title": "Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies", "categories": ["cs.AI"], "comment": "23 pages, 5 tables, 5 appendices. Code and data: https://github.com/jgraycox-coa/vcw-multi-ai-dialogue", "summary": "This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning. Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange. Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of \"VCW as transitional framework.\" Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers. The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.", "AI": {"tldr": "本文提出了一种通过多模型对话来测试AI对齐策略的方法论框架。", "motivation": "论文旨在解决人工智能（AI）的对齐问题，即将其从控制问题转变为关系问题，并通过对话推理实现这一转变。借鉴和平研究传统，引入了基于协作智慧（VCW）的概念。", "method": "实验设计中分配了四个不同的角色给不同的人工智能系统，在六种条件下进行测试，包括提议者、响应者、监控者和翻译者的角色。使用Claude、Gemini和GPT-4o进行了72次对话回合，共产生576,822字符的结构化交换。", "result": "结果表明AI系统能够有意义地参与和平研究概念，并从不同架构视角提出互补异议，生成新颖见解，如'VCW作为过渡框架'。跨体系结构模式显示了不同的关注点：Claude强调验证挑战，Gemini侧重于偏见和可扩展性问题，GPT-4o则突出实施障碍。", "conclusion": "本文提供了复制方法以在实施方案前测试对齐提案，并提出未来的研究方向，包括人机混合协议和扩展对话研究。"}}
{"id": "2601.20601", "pdf": "https://arxiv.org/pdf/2601.20601", "abs": "https://arxiv.org/abs/2601.20601", "authors": ["Zhuonan Wang", "Wenjie Yan", "Wenqiao Zhang", "Xiaohui Song", "Jian Ma", "Ke Yao", "Yibo Yu", "Beng Chin Ooi"], "title": "CLEAR-Mamba:Towards Accurate, Adaptive and Trustworthy Multi-Sequence Ophthalmic Angiography Classification", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages,7 figures", "summary": "Medical image classification is a core task in computer-aided diagnosis (CAD), playing a pivotal role in early disease detection, treatment planning, and patient prognosis assessment. In ophthalmic practice, fluorescein fundus angiography (FFA) and indocyanine green angiography (ICGA) provide hemodynamic and lesion-structural information that conventional fundus photography cannot capture. However, due to the single-modality nature, subtle lesion patterns, and significant inter-device variability, existing methods still face limitations in generalization and high-confidence prediction. To address these challenges, we propose CLEAR-Mamba, an enhanced framework built upon MedMamba with optimizations in both architecture and training strategy. Architecturally, we introduce HaC, a hypernetwork-based adaptive conditioning layer that dynamically generates parameters according to input feature distributions, thereby improving cross-domain adaptability. From a training perspective, we develop RaP, a reliability-aware prediction scheme built upon evidential uncertainty learning, which encourages the model to emphasize low-confidence samples and improves overall stability and reliability. We further construct a large-scale ophthalmic angiography dataset covering both FFA and ICGA modalities, comprising multiple retinal disease categories for model training and evaluation. Experimental results demonstrate that CLEAR-Mamba consistently outperforms multiple baseline models, including the original MedMamba, across various metrics-showing particular advantages in multi-disease classification and reliability-aware prediction. This study provides an effective solution that balances generalizability and reliability for modality-specific medical image classification tasks.", "AI": {"tldr": "提出了一种新的框架CLEAR-Mamba，用于改善多模态眼底血管成像的分类准确性、适应性和可靠性。", "motivation": "现有方法在处理单模态特性、细微病变模式和设备间差异时存在局限性，导致泛化能力和高置信度预测不足。", "method": "通过引入Hypernetwork-based Conditioning层(HaC)改善跨域适应性；开发Reliability-aware Prediction方案(RaP)，提高模型整体稳定性和可靠性。构建大规模眼底血管成像数据集用于训练和评估。", "result": "实验结果表明，CLEAR-Mamba在多疾病分类及可靠预测方面优于多个基线模型。", "conclusion": "研究为模态特定的医学图像分类任务提供了平衡泛化能力和可靠性的有效解决方案。"}}
{"id": "2601.20599", "pdf": "https://arxiv.org/pdf/2601.20599", "abs": "https://arxiv.org/abs/2601.20599", "authors": ["Hyunjun Na", "Donghwan Lee"], "title": "Regularized Gradient Temporal-Difference Learning", "categories": ["cs.LG", "cs.AI"], "comment": "27 pages, 8 figures", "summary": "Gradient temporal-difference (GTD) learning algorithms are widely used for off-policy policy evaluation with function approximation. However, existing convergence analyses rely on the restrictive assumption that the so-called feature interaction matrix (FIM) is nonsingular. In practice, the FIM can become singular and leads to instability or degraded performance. In this paper, we propose a regularized optimization objective by reformulating the mean-square projected Bellman error (MSPBE) minimization. This formulation naturally yields a regularized GTD algorithms, referred to as R-GTD, which guarantees convergence to a unique solution even when the FIM is singular. We establish theoretical convergence guarantees and explicit error bounds for the proposed method, and validate its effectiveness through empirical experiments.", "AI": {"tldr": "提出了一种正则化的GTD算法，以解决当特征交互矩阵（FIM）为奇异时的收敛性问题", "motivation": "现有GTD学习算法在FIM奇异时不稳定或性能下降，需要一种新的方法保证其稳定性及性能", "method": "通过重新制定均方投影贝尔曼误差最小化目标函数来引入正则化优化目标，得到R-GTD算法", "result": "证明了R-GTD算法的理论收敛性，并通过实验验证了该方法的有效性", "conclusion": "提出的R-GTD算法在FIM奇异的情况下也能保证稳定和有效的性能"}}
{"id": "2601.20598", "pdf": "https://arxiv.org/pdf/2601.20598", "abs": "https://arxiv.org/abs/2601.20598", "authors": ["Lakshman Balasubramanian"], "title": "Person Re-ID in 2025: Supervised, Self-Supervised, and Language-Aligned. What Works?", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Person Re-Identification (ReID) remains a challenging problem in computer vision. This work reviews various training paradigm and evaluates the robustness of state-of-the-art ReID models in cross-domain applications and examines the role of foundation models in improving generalization through richer, more transferable visual representations. We compare three training paradigms, supervised, self-supervised, and language-aligned models. Through the study the aim is to answer the following questions: Can supervised models generalize in cross-domain scenarios? How does foundation models like SigLIP2 perform for the ReID tasks? What are the weaknesses of current supervised and foundational models for ReID? We have conducted the analysis across 11 models and 9 datasets. Our results show a clear split: supervised models dominate their training domain but crumble on cross-domain data. Language-aligned models, however, show surprising robustness cross-domain for ReID tasks, even though they are not explicitly trained to do so. Code and data available at: https://github.com/moiiai-tech/object-reid-benchmark.", "AI": {"tldr": "本文研究了监督、自监督和语言对齐三种训练范式在跨域应用场景中的人体重识别模型的鲁棒性，探讨了基础模型在提高泛化能力方面的作用。", "motivation": "为了回答人体重识别中的几个核心问题：监督模型是否能在跨域场景中泛化？基于SigLIP2的基础模型如何用于人体重识别任务？当前的监督和基础模型在人体重识别中的弱点是什么？", "method": "本文比较了三种训练范式，通过分析11个模型在9个数据集上的表现来评估不同模型的鲁棒性。", "result": "结果显示：监督模型在其训练域中表现出色，但在跨域数据上性能下降。相比之下，语言对齐模型展现出强大的跨域泛化能力。", "conclusion": "研究发现语言对齐模型在人体重识别任务中的鲁棒性和泛化能力优于监督和自监督模型，在未来的人体重识别工作中具有潜在的应用价值。"}}
{"id": "2601.20597", "pdf": "https://arxiv.org/pdf/2601.20597", "abs": "https://arxiv.org/abs/2601.20597", "authors": ["Shaokun Wang", "Weili Guan", "Jizhou Han", "Jianlong Wu", "Yupeng Hu", "Liqiang Nie"], "title": "StructAlign: Structured Cross-Modal Alignment for Continual Text-to-Video Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Continual Text-to-Video Retrieval (CTVR) is a challenging multimodal continual learning setting, where models must incrementally learn new semantic categories while maintaining accurate text-video alignment for previously learned ones, thus making it particularly prone to catastrophic forgetting. A key challenge in CTVR is feature drift, which manifests in two forms: intra-modal feature drift caused by continual learning within each modality, and non-cooperative feature drift across modalities that leads to modality misalignment. To mitigate these issues, we propose StructAlign, a structured cross-modal alignment method for CTVR. First, StructAlign introduces a simplex Equiangular Tight Frame (ETF) geometry as a unified geometric prior to mitigate modality misalignment. Building upon this geometric prior, we design a cross-modal ETF alignment loss that aligns text and video features with category-level ETF prototypes, encouraging the learned representations to form an approximate simplex ETF geometry. In addition, to suppress intra-modal feature drift, we design a Cross-modal Relation Preserving loss, which leverages complementary modalities to preserve cross-modal similarity relations, providing stable relational supervision for feature updates. By jointly addressing non-cooperative feature drift across modalities and intra-modal feature drift, StructAlign effectively alleviates catastrophic forgetting in CTVR. Extensive experiments on benchmark datasets demonstrate that our method consistently outperforms state-of-the-art continual retrieval approaches.", "AI": {"tldr": "本文提出了StructAlign，一种用于连续文本到视频检索（CTVR）的结构化跨模态对齐方法。", "motivation": "为了缓解连续文本到视频检索中由于持续学习引起的特征漂移问题，并防止灾难性遗忘。", "method": "提出了一种基于等角紧框架（ETF）几何的统一几何先验，设计了跨模态ETF对齐损失和跨模态关系保持损失以解决特征漂移的问题。", "result": "在基准数据集上的实验表明该方法优于现有连续检索方法。", "conclusion": "StructAlign能有效减轻CTVR中的灾难性遗忘问题，并提供更好的性能。"}}
{"id": "2601.20585", "pdf": "https://arxiv.org/pdf/2601.20585", "abs": "https://arxiv.org/abs/2601.20585", "authors": ["Aiming Hao", "Chen Zhu", "Jiashu Zhu", "Jiahong Wu", "Xiangxiang Chu"], "title": "Ranking-aware Reinforcement Learning for Ordinal Ranking", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICASSP2026", "summary": "Ordinal regression and ranking are challenging due to inherent ordinal dependencies that conventional methods struggle to model. We propose Ranking-Aware Reinforcement Learning (RARL), a novel RL framework that explicitly learns these relationships. At its core, RARL features a unified objective that synergistically integrates regression and Learning-to-Rank (L2R), enabling mutual improvement between the two tasks. This is driven by a ranking-aware verifiable reward that jointly assesses regression precision and ranking accuracy, facilitating direct model updates via policy optimization. To further enhance training, we introduce Response Mutation Operations (RMO), which inject controlled noise to improve exploration and prevent stagnation at saddle points. The effectiveness of RARL is validated through extensive experiments on three distinct benchmarks.", "AI": {"tldr": "提出一种新的强化学习框架，用于解决序数回归和排序问题。", "motivation": "传统的模型在处理序数依赖关系时存在挑战，难以准确建模这些关系。因此，需要一个能同时改进回归精度和排名准确性的新方法。", "method": "引入了Ranking-Aware Reinforcement Learning (RARL) 框架，该框架结合了回归任务和Learning-to-Rank（L2R）的任务，并通过策略优化实现直接模型更新。此外还设计了响应变异操作(RMO)，以提高探索效率，防止训练停滞。", "result": "在三个不同的基准测试中验证了RARL的有效性。", "conclusion": "提出的方法成功解决了序数回归和排序问题，证明了RARL框架的高效性和优越性。"}}
{"id": "2601.20580", "pdf": "https://arxiv.org/pdf/2601.20580", "abs": "https://arxiv.org/abs/2601.20580", "authors": ["Nurul Huda Mahmood", "Onel L. A. Lopez", "David Ruiz-Guirola", "Frank Burkhardt", "Mehdi Rasti", "Matti Latva-aho"], "title": "Dependable Connectivity for Industrial Wireless Communication Networks", "categories": ["cs.NI", "cs.ET", "cs.IT"], "comment": "Submitted to IEEE Network Magazine for possible publication", "summary": "Dependability - a system's ability to consistently provide reliable services by ensuring safety and maintainability in the face of internal or external disruptions - is a fundamental requirement for industrial wireless communication networks (IWCNs). While 5G ultra-reliable low-latency communication (URLLC) addresses some aspects of this challenge, its evolution toward holistic dependability in 6G must encompass reliability, availability, safety, and security. This paper provides a comprehensive framework for dependable IWCNs, bridging theory and practice. We first establish the theoretical foundations of dependability, including outlining its key attributes and presenting analytical tools to study it. Next, we explore practical enablers, such as adaptive multiple access schemes leveraging real-time monitoring and time-sensitive networking to ensure end-to-end determinism. A case study demonstrates how intelligent wake-up protocols improve event detection probability by orders of magnitude compared to conventional duty cycling. Finally, we outline open challenges and future directions for a 6G-driven dependable IWCN.", "AI": {"tldr": "本文提出了一种综合框架，旨在为工业无线通信网络提供全面的可靠性保障。", "motivation": "依赖性是工业无线通信网络的基本需求，确保在各种干扰下依然能够稳定提供服务。5G技术虽然解决了一些问题，但还需要进一步发展以实现6G时代的全面依赖性保证。", "method": "该研究首先建立了依赖性的理论基础，并提供了相应的分析工具；接着探讨了实际操作中的增强策略，如自适应多址接入方案和时间敏感网络等；并通过一个案例展示了智能唤醒协议在事件检测上的显著效果。", "result": "通过引入新的技术手段，本论文展示了一种有效的提高工业无线通信网络可靠性的方法，并证明了智能唤醒协议相对于传统方式的巨大优势。", "conclusion": "文章提出了6G驱动下的可依赖的工业无线通信网络的发展方向及挑战，为未来的研究指明了道路。"}}
{"id": "2601.20578", "pdf": "https://arxiv.org/pdf/2601.20578", "abs": "https://arxiv.org/abs/2601.20578", "authors": ["Dimitris Michailidis", "Sennay Ghebreab", "Fernando P. Santos"], "title": "Inequality in Congestion Games with Learning Agents", "categories": ["cs.GT", "cs.AI"], "comment": "Full version of the extended abstract version appearing in Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "Who benefits from expanding transport networks? While designed to improve mobility, such interventions can also create inequality. In this paper, we show that disparities arise not only from the structure of the network itself but also from differences in how commuters adapt to it. We model commuters as reinforcement learning agents who adapt their travel choices at different learning rates, reflecting unequal access to resources and information. To capture potential efficiency-fairness tradeoffs, we introduce the Price of Learning (PoL), a measure of inefficiency during learning. We analyze both a stylized network -- inspired in the well-known Braess's paradox, yet with two-source nodes -- and an abstraction of a real-world metro system (Amsterdam). Our simulations show that network expansions can simultaneously increase efficiency and amplify inequality, especially when faster learners disproportionately benefit from new routes before others adapt. These results highlight that transport policies must account not only for equilibrium outcomes but also for the heterogeneous ways commuters adapt, since both shape the balance between efficiency and fairness.", "AI": {"tldr": "本文研究了在扩展交通网络时，不同学习速率的通勤者如何适应新环境以及这种差异对效率和公平性的影响。", "motivation": "旨在探讨交通网络扩张如何导致不平等，特别是在不同的通勤者以不同的速度适应新环境的情况下。", "method": "通过建立一种强化学习模型来模拟通勤者的出行选择，并引入价格学习（PoL）的概念来衡量在学习过程中的低效性。研究了具有两个源节点的简化网络和阿姆斯特丹地铁系统的抽象模型。", "result": "发现交通网络扩张可以同时提高效率并加剧不平等，尤其是当速度快的学习者比其他人更快地从新路线中受益时。", "conclusion": "结果表明，运输政策应考虑通勤者的异质适应行为以及这种差异如何影响效率和公平性的平衡。"}}
{"id": "2601.20577", "pdf": "https://arxiv.org/pdf/2601.20577", "abs": "https://arxiv.org/abs/2601.20577", "authors": ["Baiqing Wang", "Helei Cui", "Bo Zhang", "Xiaolong Zheng", "Bin Guo", "Zhiwen Yu"], "title": "MeCo: Enhancing LLM-Empowered Multi-Robot Collaboration via Similar Task Memoization", "categories": ["cs.RO"], "comment": null, "summary": "Multi-robot systems have been widely deployed in real-world applications, providing significant improvements in efficiency and reductions in labor costs. However, most existing multi-robot collaboration methods rely on extensive task-specific training, which limits their adaptability to new or diverse scenarios. Recent research leverages the language understanding and reasoning capabilities of large language models (LLMs) to enable more flexible collaboration without specialized training. Yet, current LLM-empowered approaches remain inefficient: when confronted with identical or similar tasks, they must replan from scratch because they omit task-level similarities. To address this limitation, we propose MeCo, a similarity-aware multi-robot collaboration framework that applies the principle of ``cache and reuse'' (a.k.a., memoization) to reduce redundant computation. Unlike simple task repetition, identifying and reusing solutions for similar but not identical tasks is far more challenging, particularly in multi-robot settings. To this end, MeCo introduces a new similarity testing method that retrieves previously solved tasks with high relevance, enabling effective plan reuse without re-invoking LLMs. Furthermore, we present MeCoBench, the first benchmark designed to evaluate performance on similar-task collaboration scenarios. Experimental results show that MeCo substantially reduces planning costs and improves success rates compared with state-of-the-art approaches.", "AI": {"tldr": "提出了一种基于缓存重用原则的多机器人协作框架MeCo，以减少冗余计算并提高任务执行效率。", "motivation": "现有的多机器人协作方法依赖于特定任务训练，这限制了其适应新或多样场景的能力。为了解决这一问题，研究人员利用大语言模型的语言理解和推理能力来实现更加灵活的协作。", "method": "MeCo引入了一种相似性测试的方法，可以检索之前解决过的相关任务，并重用这些解决方案以减少重新调用大型语言模型的需求。", "result": "实验结果表明，与最先进的方法相比，MeCo显著降低了规划成本并提高了成功率。", "conclusion": "通过应用缓存重用原则和提出新的相似性测试方法，MeCo有效减少了冗余计算，并在多机器人协作场景中展示了优越的性能。"}}
{"id": "2601.20575", "pdf": "https://arxiv.org/pdf/2601.20575", "abs": "https://arxiv.org/abs/2601.20575", "authors": ["Jia Fu", "Litingyu Wang", "He Li", "Zihao Luo", "Huamin Wang", "Chenyuan Bian", "Zijun Gao", "Chunbin Gu", "Xin Weng", "Jianghao Wu", "Yicheng Wu", "Jin Ye", "Linhao Li", "Yiwen Ye", "Yong Xia", "Elias Tappeiner", "Fei He", "Abdul qayyum", "Moona Mazher", "Steven A Niederer", "Junqiang Chen", "Chuanyi Huang", "Lisheng Wang", "Zhaohu Xing", "Hongqiu Wang", "et al. (5 additional authors not shown)"], "title": "SegRap2025: A Benchmark of Gross Tumor Volume and Lymph Node Clinical Target Volume Segmentation for Radiotherapy Planning of Nasopharyngeal Carcinoma", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Accurate delineation of Gross Tumor Volume (GTV), Lymph Node Clinical Target Volume (LN CTV), and Organ-at-Risk (OAR) from Computed Tomography (CT) scans is essential for precise radiotherapy planning in Nasopharyngeal Carcinoma (NPC). Building upon SegRap2023, which focused on OAR and GTV segmentation using single-center paired non-contrast CT (ncCT) and contrast-enhanced CT (ceCT) scans, the SegRap2025 challenge aims to enhance the generalizability and robustness of segmentation models across imaging centers and modalities. SegRap2025 comprises two tasks: Task01 addresses GTV segmentation using paired CT from the SegRap2023 dataset, with an additional external testing set to evaluate cross-center generalization, and Task02 focuses on LN CTV segmentation using multi-center training data and an unseen external testing set, where each case contains paired CT scans or a single modality, emphasizing both cross-center and cross-modality robustness. This paper presents the challenge setup and provides a comprehensive analysis of the solutions submitted by ten participating teams. For GTV segmentation task, the top-performing models achieved average Dice Similarity Coefficient (DSC) of 74.61% and 56.79% on the internal and external testing cohorts, respectively. For LN CTV segmentation task, the highest average DSC values reached 60.24%, 60.50%, and 57.23% on paired CT, ceCT-only, and ncCT-only subsets, respectively. SegRap2025 establishes a large-scale multi-center, multi-modality benchmark for evaluating the generalization and robustness in radiotherapy target segmentation, providing valuable insights toward clinically applicable automated radiotherapy planning systems. The benchmark is available at: https://hilab-git.github.io/SegRap2025_Challenge.", "AI": {"tldr": "SegRap2025 提供了一个用于评估放射治疗目标分割模型的多中心、多模态基准，旨在提高模型在不同医疗中心和成像方式下的泛化能力和鲁棒性。", "motivation": "为了改进鼻咽癌患者精确放疗计划中对肿瘤体积和淋巴结临床靶区的准确勾画，SegRap2025 挑战赛建立了一个评估分割模型跨中心及跨模态鲁棒性的基准。", "method": "该挑战包含两个任务：GTV 分割使用来自 SegRap2023 数据集的配对 CT 扫描，并额外增加外部测试组以评估跨中心泛化能力；LN CTV 分割则基于多中心训练数据和未见外部测试组，每个病例包含配对 CT 或单一模态。", "result": "在 GTV 分割任务中，最佳模型分别在内部和外部测试集中达到平均 DSC 值为74.61% 和56.79%，而 LN CTV 分割的最佳结果分别为配对 CT 的60.24%，ceCT 单模的60.50%，以及 ncCT 单模的57.23%。", "conclusion": "SegRap2025 建立了大规模多中心、多模态基准，为评估放射治疗目标分割模型提供了重要见解，并向临床适用的自动化放疗计划系统迈进了一步。"}}
{"id": "2601.20573", "pdf": "https://arxiv.org/pdf/2601.20573", "abs": "https://arxiv.org/abs/2601.20573", "authors": ["Taihui Wang", "Jinzheng Zhao", "Rilin Chen", "Tong Lei", "Wenwu Wang", "Dong Yu"], "title": "Gen-SER: When the generative model meets speech emotion recognition", "categories": ["cs.SD"], "comment": "Accepted to IEEE ICASSP 2026", "summary": "Speech emotion recognition (SER) is crucial in speech understanding and generation. Most approaches are based on either classification models or large language models. Different from previous methods, we propose Gen-SER, a novel approach that reformulates SER as a distribution shift problem via generative models. We propose to project discrete class labels into a continuous space, and obtain the terminal distribution via sinusoidal taxonomy encoding. The target-matching-based generative model is adopted to transform the initial distribution into the terminal distribution efficiently. The classification is achieved by calculating the similarity of the generated terminal distribution and ground truth terminal distribution. The experimental results confirm the efficacy of the proposed method, demonstrating its extensibility to various speech-understanding tasks and suggesting its potential applicability to a broader range of classification tasks.", "AI": {"tldr": "本文提出了一种名为Gen-SER的新方法，该方法将语音情感识别（SER）重新表述为通过生成模型处理的分布偏移问题。", "motivation": "传统的SER方法多基于分类模型或大型语言模型。这种方法旨在通过引入新的生成模型方法来改进SER性能，并探索其在其他任务中的应用潜力。", "method": "该方法利用生成模型将离散类标签映射到连续空间，进而获取终端分布并通过正弦编码实现此过程。最终的分类是基于计算生成的目标分布和真实目标分布之间的相似度来完成的。", "result": "实验结果证明了所提出的方法的有效性，并且表明该方法在各种语音理解任务中的可扩展性和对更广泛分类任务的应用潜力。", "conclusion": "通过将SER问题转化为一个生成模型解决的问题，Gen-SER展示了改进SER性能并可能适用于其他分类和语音理解任务的前景。"}}
{"id": "2601.20571", "pdf": "https://arxiv.org/pdf/2601.20571", "abs": "https://arxiv.org/abs/2601.20571", "authors": ["Anna van Elst", "Igor Colin", "Stephan Clémençon"], "title": "Robust Distributed Learning under Resource Constraints: Decentralized Quantile Estimation via (Asynchronous) ADMM", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Specifications for decentralized learning on resource-constrained edge devices require algorithms that are communication-efficient, robust to data corruption, and lightweight in memory usage. While state-of-the-art gossip-based methods satisfy the first requirement, achieving robustness remains challenging. Asynchronous decentralized ADMM-based methods have been explored for estimating the median, a statistical centrality measure that is notoriously more robust than the mean. However, existing approaches require memory that scales with node degree, making them impractical when memory is limited. In this paper, we propose AsylADMM, a novel gossip algorithm for decentralized median and quantile estimation, primarily designed for asynchronous updates and requiring only two variables per node. We analyze a synchronous variant of AsylADMM to establish theoretical guarantees and empirically demonstrate fast convergence for the asynchronous algorithm. We then show that our algorithm enables quantile-based trimming, geometric median estimation, and depth-based trimming, with quantile-based trimming empirically outperforming existing rank-based methods. Finally, we provide a novel theoretical analysis of rank-based trimming via Markov chain theory.", "AI": {"tldr": "设计了一种用于资源受限设备的去中心化学习算法AsylADMM，该算法能够在异步更新下进行高效的中位数和分位数估计，并具备轻量级内存使用的特点。", "motivation": "现有分布式学习方法在通信效率上表现良好，但在数据异常值鲁棒性方面存在挑战。此外，现有的去中心化ADMM方法虽然可以估算中位数，但需要与节点度数成正比的内存，这在内存受限的情况下难以实现。", "method": "提出了一种新的基于gossip算法的AsylADMM，用于异步更新下的分布式中位数和分位数估计。该算法只需要每个节点存储两个变量，并通过同步变体进行理论分析以确保收敛性。", "result": "实验证明了AsylADMM在异步模式下具有快速收敛特性。此外，该算法支持基于分位数的修剪、几何中位数估算和深度基线修剪，并且基于分位数的方法优于现有的秩基方法。", "conclusion": "AsylADMM是一种适用于资源受限设备的有效分布式学习方法，它提供了去中心化的中位数和分位数估计，并且在异步通信环境下表现出色。"}}
{"id": "2601.20564", "pdf": "https://arxiv.org/pdf/2601.20564", "abs": "https://arxiv.org/abs/2601.20564", "authors": ["Wenzhuo Ma", "Zhenzhong Chen"], "title": "DiffVC-RT: Towards Practical Real-Time Diffusion-based Perceptual Neural Video Compression", "categories": ["cs.CV"], "comment": "17 pages, 10 figures", "summary": "The practical deployment of diffusion-based Neural Video Compression (NVC) faces critical challenges, including severe information loss, prohibitive inference latency, and poor temporal consistency. To bridge this gap, we propose DiffVC-RT, the first framework designed to achieve real-time diffusion-based perceptual NVC. First, we introduce an Efficient and Informative Model Architecture. Through strategic module replacements and pruning, this architecture significantly reduces computational complexity while mitigating structural information loss. Second, to address generative flickering artifacts, we propose Explicit and Implicit Consistency Modeling. We enhance temporal consistency by explicitly incorporating a zero-cost Online Temporal Shift Module within the U-Net, complemented by hybrid implicit consistency constraints. Finally, we present an Asynchronous and Parallel Decoding Pipeline incorporating Mixed Half Precision, which enables asynchronous latent decoding and parallel frame reconstruction via a Batch-dimension Temporal Shift design. Experiments show that DiffVC-RT achieves 80.1% bitrate savings in terms of LPIPS over VTM-17.0 on HEVC dataset with real-time encoding and decoding speeds of 206 / 30 fps for 720p videos on an NVIDIA H800 GPU, marking a significant milestone in diffusion-based video compression.", "AI": {"tldr": "DiffVC-RT是一个面向实时感知神经视频压缩的扩散模型框架，旨在减少信息损失、提高时间一致性并降低推理延迟。", "motivation": "当前基于扩散的神经视频压缩面临严重的信息丢失、推断延迟高和时间一致性的挑战。提出该框架以克服这些障碍。", "method": "DiffVC-RT提出了高效的模型架构、显式及隐式的时空一致性建模以及异步并行解码管道，从而在保持高质量的同时实现实时编码与解码。", "result": "实验结果表明，在HEVC数据集上，对于720p视频，相对于VTM-17.0，DiffVC-RT实现了80.1%的比特率节省（LPIPS指标），并且实现实时编码和解码速度分别为206/30fps。", "conclusion": "通过创新的方法和技术，DiffVC-RT成功解决了扩散模型在视频压缩中的关键挑战，并达到了实时性能。"}}
{"id": "2601.20556", "pdf": "https://arxiv.org/pdf/2601.20556", "abs": "https://arxiv.org/abs/2601.20556", "authors": ["Ariel Maymon", "Yanir Buznah", "Uri Shaham"], "title": "Unsupervised Ensemble Learning Through Deep Energy-based Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to AISTATS 2026. 29 pages, 13 figures. Code available at: https://github.com/shaham-lab/deem", "summary": "Unsupervised ensemble learning emerged to address the challenge of combining multiple learners' predictions without access to ground truth labels or additional data. This paradigm is crucial in scenarios where evaluating individual classifier performance or understanding their strengths is challenging due to limited information. We propose a novel deep energy-based method for constructing an accurate meta-learner using only the predictions of individual learners, potentially capable of capturing complex dependence structures between them. Our approach requires no labeled data, learner features, or problem-specific information, and has theoretical guarantees for when learners are conditionally independent. We demonstrate superior performance across diverse ensemble scenarios, including challenging mixture of experts settings. Our experiments span standard ensemble datasets and curated datasets designed to test how the model fuses expertise from multiple sources. These results highlight the potential of unsupervised ensemble learning to harness collective intelligence, especially in data-scarce or privacy-sensitive environments.", "AI": {"tldr": "提出一种新的深度能量模型方法，用于在没有标签数据的情况下构建元学习器，融合多个分类器的预测。", "motivation": "解决在缺乏地面真实标签或额外数据的情况下的无监督集成学习问题。旨在提高在有限信息条件下评估和理解各个分类器性能的能力。", "method": "通过深度能量模型方法进行元学习器构造，利用单个学习者的预测构建准确的元学习器，无需标记的数据、特征或特定问题的信息，并具有理论保证以实现条件独立性。", "result": "展示了在标准集成数据集和专门设计用于测试模型如何从多个来源融合专业知识的数据集中优于其他方法的表现。实验结果表明了无监督集成学习在处理稀缺或隐私敏感环境中的潜力。", "conclusion": "提出的深度能量模型方法成功地提高了在缺乏标签信息的情况下的元学习器性能，为数据稀少或隐私敏感的环境中利用集体智能提供了有效的解决方案。"}}
{"id": "2601.20555", "pdf": "https://arxiv.org/pdf/2601.20555", "abs": "https://arxiv.org/abs/2601.20555", "authors": ["Wadhah Zai El Amri", "Nicolás Navarro-Guerrero"], "title": "Vibro-Sense: Robust Vibration-based Impulse Response Localization and Trajectory Tracking for Robotic Hands", "categories": ["cs.RO", "eess.SP"], "comment": "Under Review: Springer Autonomous Robots Journal", "summary": "Rich contact perception is crucial for robotic manipulation, yet traditional tactile skins remain expensive and complex to integrate. This paper presents a scalable alternative: high-accuracy whole-body touch localization via vibro-acoustic sensing. By equipping a robotic hand with seven low-cost piezoelectric microphones and leveraging an Audio Spectrogram Transformer, we decode the vibrational signatures generated during physical interaction. Extensive evaluation across stationary and dynamic tasks reveals a localization error of under 5 mm in static conditions. Furthermore, our analysis highlights the distinct influence of material properties: stiff materials (e.g., metal) excel in impulse response localization due to sharp, high-bandwidth responses, whereas textured materials (e.g., wood) provide superior friction-based features for trajectory tracking. The system demonstrates robustness to the robot's own motion, maintaining effective tracking even during active operation. Our primary contribution is demonstrating that complex physical contact dynamics can be effectively decoded from simple vibrational signals, offering a viable pathway to widespread, affordable contact perception in robotics. To accelerate research, we provide our full datasets, models, and experimental setups as open-source resources.", "AI": {"tldr": "本文提出了一种通过振动感知实现高精度触觉定位的方法，适用于机器人手。", "motivation": "传统的触觉皮肤成本高昂且难以集成，因此需要一种可扩展的替代方案来实现精确的接触感知。", "method": "通过在机器人手上安装七个低成本压电麦克风，并利用音频光谱变压器解码物理交互期间产生的振动信号，实现了高精度定位。", "result": "实验结果显示，在静态条件下定位误差低于5毫米。不同材料（如金属和木材）对不同的接触感知任务具有特定的影响。", "conclusion": "该研究展示了复杂物理接触动态可以通过简单的振动信号有效解码，为低成本、大规模应用的触觉感知提供了可行途径。"}}
{"id": "2601.20554", "pdf": "https://arxiv.org/pdf/2601.20554", "abs": "https://arxiv.org/abs/2601.20554", "authors": ["Yaacov Pariente", "Vadim Indelman"], "title": "Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function", "categories": ["cs.AI"], "comment": null, "summary": "We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $α$, where $α= 1$ recovers standard expectation-based planning and $α< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.", "AI": {"tldr": "研究了使用迭代条件价值在险值（ICVaR）的风险敏感规划，提出了一种在线风险规避的POMDP规划方法。", "motivation": "为了提高决策过程中的风险感知能力，在部分可观测环境下采用动态风险度量ICVaR进行风险敏感规划。", "method": "开发了一种带有有限时间性能保证的政策评估算法，并将三种广泛使用的在线规划算法扩展以优化ICVaR值函数，而非预期回报。", "result": "实验显示提出的ICVaR规划器在基准POMDP领域中实现了更低的风险尾端，相比风险中立策略有所改进。", "conclusion": "该研究为部分可观测环境中的决策过程提供了新的视角和方法，通过引入风险参数α实现更稳健的规划策略。"}}
{"id": "2601.20552", "pdf": "https://arxiv.org/pdf/2601.20552", "abs": "https://arxiv.org/abs/2601.20552", "authors": ["Haoran Wei", "Yaofeng Sun", "Yukun Li"], "title": "DeepSeek-OCR 2: Visual Causal Flow", "categories": ["cs.CV"], "comment": null, "summary": "We present DeepSeek-OCR 2 to investigate the feasibility of a novel encoder-DeepEncoder V2-capable of dynamically reordering visual tokens upon image semantics. Conventional vision-language models (VLMs) invariably process visual tokens in a rigid raster-scan order (top-left to bottom-right) with fixed positional encoding when fed into LLMs. However, this contradicts human visual perception, which follows flexible yet semantically coherent scanning patterns driven by inherent logical structures. Particularly for images with complex layouts, human vision exhibits causally-informed sequential processing. Inspired by this cognitive mechanism, DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, enabling it to intelligently reorder visual tokens prior to LLM-based content interpretation. This work explores a novel paradigm: whether 2D image understanding can be effectively achieved through two-cascaded 1D causal reasoning structures, thereby offering a new architectural approach with the potential to achieve genuine 2D reasoning. Codes and model weights are publicly accessible at http://github.com/deepseek-ai/DeepSeek-OCR-2.", "AI": {"tldr": "DeepSeek-OCR 2通过设计一种新的编码器DeepEncoder V2来探索视觉因果流动，该编码器能够根据图像的语义动态重新排序视觉标记。", "motivation": "传统视觉语言模型在处理视觉标记时遵循固定顺序和位置编码，这与人类灵活且具有逻辑结构驱动的视知觉不符。为此，研究人员设计了一种新的编码器来模拟人类的认知机制，并实现基于因果关系的序列处理能力。", "method": "DeepEncoder V2被设计为可以智能地重新排序视觉标记，在输入LLM进行内容解释之前依据图像语义信息，以此探索通过两个级联的一维因果推理结构达到二维图像理解的可能性。", "result": "该研究提出了新的架构方法，并公开了代码和模型权重供访问，表明基于因果流动的序列处理可以实现有效的二维图像理解和解析。", "conclusion": "DeepSeek-OCR 2展示了通过智能重新排序视觉标记以进行有效图像理解的新思路和潜在能力。"}}
{"id": "2601.20548", "pdf": "https://arxiv.org/pdf/2601.20548", "abs": "https://arxiv.org/abs/2601.20548", "authors": ["Kahraman Kostas", "Rabia Yasa Kostas"], "title": "IoT Device Identification with Machine Learning: Common Pitfalls and Best Practices", "categories": ["cs.CR", "cs.AI", "cs.NI"], "comment": "4 pages", "summary": "This paper critically examines the device identification process using machine learning, addressing common pitfalls in existing literature. We analyze the trade-offs between identification methods (unique vs. class based), data heterogeneity, feature extraction challenges, and evaluation metrics. By highlighting specific errors, such as improper data augmentation and misleading session identifiers, we provide a robust guideline for researchers to enhance the reproducibility and generalizability of IoT security models.", "AI": {"tldr": "本文探讨了使用机器学习进行物联网设备识别过程中的常见陷阱和最佳实践。", "motivation": "为了提高物联网安全模型的可重复性和普适性，论文审视现有研究中存在的问题，并提供指导建议。", "method": "分析设备识别方法（唯一标识与类别标识）、数据异质性、特征提取难题及评估指标之间的权衡。", "result": "指出了诸如不当的数据增强和误导性的会话标识符等具体错误，提供了改进指南。", "conclusion": "通过揭示常见陷阱并提供最佳实践建议，有助于研究人员提升物联网设备识别的准确性和可靠性。"}}
{"id": "2601.20544", "pdf": "https://arxiv.org/pdf/2601.20544", "abs": "https://arxiv.org/abs/2601.20544", "authors": ["Davide Falessi", "Silvia Golia", "Angela Locoro"], "title": "Beyond Literacy: Predicting Interpretation Correctness of Visualizations with User Traits, Item Difficulty, and Rasch Scores", "categories": ["cs.HC"], "comment": null, "summary": "Data Visualization Literacy assessments are typically administered via fixed sets of Data Visualization items, despite substantial heterogeneity in how different people interpret the same visualization. This paper presents and evaluates an approach for predicting Human Interpretation Correctness (P-HIC) of data visualizations; i.e., anticipating whether a specific person will interpret a data visualization correctly or not, before exposure to that DV, enabling more personalized assessment and training. We operationalize P-HIC as a binary classification problem using 22 features spanning Human Profile, Human Performance, and Item difficulty (including ExpertDifficulty and RaschDifficulty). We evaluate three machine-learning models (Logistic Regression model, Random Forest, Multi Layer Perceptron) with and without feature selection, using a survey with 1,083 participants who answered 32 Data Visualization items (eight data visualizations per four items), yielding 34,656 item responses. Performance is assessed via a ten-time ten-fold cross-validation in each 32 (item-specific) datasets, using AUC and Cohen's kappa. Logistic Regression model with feature selection is the best-performing approach, reaching a median AUC of 0.72 and a median kappa of 0.32. Feature analyses show RaschDifficulty as the dominant predictor, followed by experts' ratings and prior correctness (PercCorrect), whose relevance increases across sessions. Profile information did not particularly support P-HIC. Our results support the feasibility of anticipating misinterpretations of data visualizations, and motivate the runtime selection of data visualizations items tailored to an audience, thereby improving the efficiency of Data Visualization Literacy assessment and targeted training.", "AI": {"tldr": "本文提出了预测用户正确解释数据可视化的能力的方法，通过使用机器学习模型，并利用参与者的人口统计特征、表现和项目难度作为输入。", "motivation": "传统的数据可视化评估方法采用固定的一组题目进行测试，忽视了不同个体对同一可视化的解读差异性。该研究旨在开发一种预测特定用户能否正确解释某个数据可视化的技术，以便实现更个性化的测评与培训。", "method": "研究将预测任务定义为一个二分类问题，并采用了22个特征（包括人类个人特征、表现和项目难度）作为输入变量。研究团队评估了三种机器学习模型的表现：逻辑回归模型、随机森林及多层感知器，其中还包括带或不带特征选择的对比实验。", "result": "在使用包含1083名参与者回答的数据进行交叉验证后，具有特征选择功能的逻辑回归模型表现最佳。该模型达到了中位数AUC为0.72和中位数Kappa系数为0.32的成绩。", "conclusion": "研究结果表明可以通过预测数据可视化的错误解释来提高评估效率，并通过实时选取符合受众特性的题目，提升培训效果。"}}
{"id": "2601.20540", "pdf": "https://arxiv.org/pdf/2601.20540", "abs": "https://arxiv.org/abs/2601.20540", "authors": ["Robbyant Team", "Zelin Gao", "Qiuyu Wang", "Yanhong Zeng", "Jiapeng Zhu", "Ka Leong Cheng", "Yixuan Li", "Hanlin Wang", "Yinghao Xu", "Shuailei Ma", "Yihang Chen", "Jie Liu", "Yansong Cheng", "Yao Yao", "Jiayi Zhu", "Yihao Meng", "Kecheng Zheng", "Qingyan Bai", "Jingye Chen", "Zehong Shen", "Yue Yu", "Xing Zhu", "Yujun Shen", "Hao Ouyang"], "title": "Advancing Open-source World Models", "categories": ["cs.CV"], "comment": "Project page: https://technology.robbyant.com/lingbot-world; Code: https://github.com/robbyant/lingbot-world", "summary": "We present LingBot-World, an open-sourced world simulator stemming from video generation. Positioned as a top-tier world model, LingBot-World offers the following features. (1) It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond. (2) It enables a minute-level horizon while preserving contextual consistency over time, which is also known as \"long-term memory\". (3) It supports real-time interactivity, achieving a latency of under 1 second when producing 16 frames per second. We provide public access to the code and model in an effort to narrow the divide between open-source and closed-source technologies. We believe our release will empower the community with practical applications across areas like content creation, gaming, and robot learning.", "AI": {"tldr": "介绍了一种开源世界模拟器LingBot-World，它在多种环境中具有高保真度和长期一致性，并支持实时交互。", "motivation": "旨在通过提供一种高性能的开源世界模型来缩小开源与闭源技术之间的差距，推动社区中的实际应用。", "method": "开发了一个基于视频生成的世界模拟器LingBot-World，该模拟器在各种环境中保持高保真度和长期一致性，并支持实时交互。", "result": "展示了LingBot-World在不同环境下的性能，包括现实主义、科学背景、卡通风格等。此外，它还实现了长时记忆功能并保证了实时互动的低延迟。", "conclusion": "开源世界模拟器LingBot-World能够为内容创作、游戏开发和机器人学习等多个领域提供有力的支持。"}}
{"id": "2601.20539", "pdf": "https://arxiv.org/pdf/2601.20539", "abs": "https://arxiv.org/abs/2601.20539", "authors": ["Oguzhan Gungordu", "Siheng Xiong", "Faramarz Fekri"], "title": "PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.", "AI": {"tldr": "本文提出了一种基于多代理推理框架的自动化启发式设计方法PathWise，通过世界模型进行规划，从而生成更好的优化问题解决策略。", "motivation": "现有自动启发式设计框架依赖于固定的进化规则和静态提示模板，导致启发式的产生过于短视、评估冗余以及难以推导出新的启发式。", "method": "PathWise将启发式生成视为在包含搜索轨迹记忆的图上的顺序决策过程。该系统包括一个策略代理进行进化动作规划，一个世界模型代理根据这些动作生成启发式展开，并且有提供基于之前步骤教训反馈的评估代理。", "result": "实验表明，在各种组合优化问题上，PathWise能更快地收敛到更好的启发式解决方案，并在不同大型语言模型基础上泛化良好，同时可扩展至更大规模的问题。", "conclusion": "通过引入状态感知规划而非尝试错误进化的方法，PathWise显著改进了自动化启发式设计过程的效率和性能。"}}
{"id": "2601.20538", "pdf": "https://arxiv.org/pdf/2601.20538", "abs": "https://arxiv.org/abs/2601.20538", "authors": ["Ling Tang", "Jilin Mei", "Dongrui Liu", "Chen Qian", "Dawei Cheng", "Jing Shao", "Xia Hu"], "title": "Interpreting Emergent Extreme Events in Multi-Agent Systems", "categories": ["cs.MA", "cs.AI"], "comment": "8 pages, 5 figures", "summary": "Large language model-powered multi-agent systems have emerged as powerful tools for simulating complex human-like systems. The interactions within these systems often lead to extreme events whose origins remain obscured by the black box of emergence. Interpreting these events is critical for system safety. This paper proposes the first framework for explaining emergent extreme events in multi-agent systems, aiming to answer three fundamental questions: When does the event originate? Who drives it? And what behaviors contribute to it? Specifically, we adapt the Shapley value to faithfully attribute the occurrence of extreme events to each action taken by agents at different time steps, i.e., assigning an attribution score to the action to measure its influence on the event. We then aggregate the attribution scores along the dimensions of time, agent, and behavior to quantify the risk contribution of each dimension. Finally, we design a set of metrics based on these contribution scores to characterize the features of extreme events. Experiments across diverse multi-agent system scenarios (economic, financial, and social) demonstrate the effectiveness of our framework and provide general insights into the emergence of extreme phenomena.", "AI": {"tldr": "提出一种解释多智能体系统中突发极端事件的框架", "motivation": "大型语言模型驱动的多代理系统在模拟复杂人类行为方面表现出色，但其中发生的极端事件往往难以理解。此研究旨在开发一个能够解析这些事件起源、触发者及影响因素的框架，提高系统的安全性。", "method": "采用Shapley值为每个时间步中各智能体的行为分配归因分数来衡量其对极端事件的影响，并沿时间、代理和行为维度汇总这些分数以量化风险贡献。设计了基于贡献评分的一系列指标来描述极端事件的特征", "result": "实验证明该框架在不同场景中的有效性，为理解复杂系统中突发现象提供了重要见解。", "conclusion": "所提出的解释性框架成功揭示了多智能体系统中突发极端事件的原因、触发者及影响因素，对于增强此类系统的安全性和透明度具有重要意义。"}}
{"id": "2601.20529", "pdf": "https://arxiv.org/pdf/2601.20529", "abs": "https://arxiv.org/abs/2601.20529", "authors": ["Julia Richter", "David Oberacker", "Gabriela Ligeza", "Valentin T. Bickel", "Philip Arm", "William Talbot", "Marvin Grosse Besselmann", "Florian Kehl", "Tristan Schnell", "Hendrik Kolvenbach", "Rüdiger Dillmann", "Arne Roennau", "Marco Hutter"], "title": "A Practical Framework of Key Performance Indicators for Multi-Robot Lunar and Planetary Field Tests", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Robotic prospecting for critical resources on the Moon, such as ilmenite, rare earth elements, and water ice, requires robust exploration methods given the diverse terrain and harsh environmental conditions. Although numerous analog field trials address these goals, comparing their results remains challenging because of differences in robot platforms and experimental setups. These missions typically assess performance using selected, scenario-specific engineering metrics that fail to establish a clear link between field performance and science-driven objectives. In this paper, we address this gap by deriving a structured framework of KPI from three realistic multi-robot lunar scenarios reflecting scientific objectives and operational constraints. Our framework emphasizes scenario-dependent priorities in efficiency, robustness, and precision, and is explicitly designed for practical applicability in field deployments. We validated the framework in a multi-robot field test and found it practical and easy to apply for efficiency- and robustness-related KPI, whereas precision-oriented KPI require reliable ground-truth data that is not always feasible to obtain in outdoor analog environments. Overall, we propose this framework as a common evaluation standard enabling consistent, goal-oriented comparison of multi-robot field trials and supporting systematic development of robotic systems for future planetary exploration.", "AI": {"tldr": "本文提出了一种基于关键绩效指标（KPI）的多机器人月球和行星实地测试框架，旨在实现科学目标与工程性能之间的明确关联。", "motivation": "当前多机器人模拟试验在评估性能时采用的是特定场景下的工程技术指标，这导致了不同平台间结果难以比较。本文意在解决这一问题，提供一种适用于多个实际多机器人月球场景的通用评价标准。", "method": "通过分析三个具有代表性的科学目标和操作约束的真实多机器人月球场景，开发了一套强调效率、鲁棒性和精度等情景依赖性优先级的关键绩效指标框架，并在实地测试中验证了其实用性和易用性。", "result": "该框架被发现适用于效率和鲁棒性相关的KPI，而精确度导向的KPI则需要可靠的地面真实数据，在室外模拟环境中有时难以获取。", "conclusion": "本文提出的框架为多机器人现场试验提供了一个共同评估标准，能够支持系统化开发用于未来行星探索的机器人系统。"}}
{"id": "2601.20526", "pdf": "https://arxiv.org/pdf/2601.20526", "abs": "https://arxiv.org/abs/2601.20526", "authors": ["Shaokun Wang", "Yifan Yu", "Yuhang He", "Weili Guan", "Yihong Gong"], "title": "IOTA: Corrective Knowledge-Guided Prompt Learning via Black-White Box Framework", "categories": ["cs.CV"], "comment": null, "summary": "Recently, adapting pre-trained models to downstream tasks has attracted increasing interest. Previous Parameter-Efficient-Tuning (PET) methods regard the pre-trained model as an opaque Black Box model, relying purely on data-driven optimization and underutilizing their inherent prior knowledge. This oversight limits the models' potential for effective downstream task adaptation. To address these issues, we propose a novel black-whIte bOx prompT leArning framework (IOTA), which integrates a data-driven Black Box module with a knowledge-driven White Box module for downstream task adaptation. Specifically, the White Box module derives corrective knowledge by contrasting the wrong predictions with the right cognition. This knowledge is verbalized into interpretable human prompts and leveraged through a corrective knowledge-guided prompt selection strategy to guide the Black Box module toward more accurate predictions. By jointly leveraging knowledge- and data-driven learning signals, IOTA achieves effective downstream task adaptation. Experimental results on 12 image classification benchmarks under few-shot and easy-to-hard adaptation settings demonstrate the effectiveness of corrective knowledge and the superiority of our method over state-of-the-art methods.", "AI": {"tldr": "该论文提出了IOTA框架，结合知识驱动的白盒模块和数据驱动的黑盒模块以改进预训练模型在下游任务中的适应性。", "motivation": "先前的方法将预训练模型视为不透明的黑箱模型，并依赖于纯数据驱动优化，忽视了其内部先验知识，限制了有效适应下游任务的能力。为了解决这一问题，作者提出了IOTA框架。", "method": "IOTA框架包含一个白盒模块和一个黑盒模块。白盒模块通过对比错误预测与正确认知来获取校正性知识，并将其转化为可解释的人类提示；黑盒模块则使用这些提示进行更准确的预测。", "result": "在12个图像分类基准测试下，IOTA框架在少量样本和从易到难适应场景中表现优越，证明了其有效性和优势。", "conclusion": "实验结果表明，结合知识驱动与数据驱动学习信号能够有效地提升下游任务的适应性。"}}
{"id": "2601.20524", "pdf": "https://arxiv.org/pdf/2601.20524", "abs": "https://arxiv.org/abs/2601.20524", "authors": ["Matic Fučka", "Vitjan Zavrtanik", "Danijel Skočaj"], "title": "AnomalyVFM -- Transforming Vision Foundation Models into Zero-Shot Anomaly Detectors", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot anomaly detection aims to detect and localise abnormal regions in the image without access to any in-domain training images. While recent approaches leverage vision-language models (VLMs), such as CLIP, to transfer high-level concept knowledge, methods based on purely vision foundation models (VFMs), like DINOv2, have lagged behind in performance. We argue that this gap stems from two practical issues: (i) limited diversity in existing auxiliary anomaly detection datasets and (ii) overly shallow VFM adaptation strategies. To address both challenges, we propose AnomalyVFM, a general and effective framework that turns any pretrained VFM into a strong zero-shot anomaly detector. Our approach combines a robust three-stage synthetic dataset generation scheme with a parameter-efficient adaptation mechanism, utilising low-rank feature adapters and a confidence-weighted pixel loss. Together, these components enable modern VFMs to substantially outperform current state-of-the-art methods. More specifically, with RADIO as a backbone, AnomalyVFM achieves an average image-level AUROC of 94.1% across 9 diverse datasets, surpassing previous methods by significant 3.3 percentage points. Project Page: https://maticfuc.github.io/anomaly_vfm/", "AI": {"tldr": "本文提出了一种将视觉基础模型转化为零样本异常检测器的框架AnomalyVFM。", "motivation": "当前基于纯视觉基础模型的方法在性能上落后于使用视觉-语言模型的方法，原因是现有的辅助异常检测数据集多样性不足以及过于简单的模型适应策略。为此，论文旨在缩小这一差距。", "method": "AnomalyVFM结合了稳健的三阶段合成数据生成方案和参数高效的适应机制，利用低秩特征适配器和加权像素损失。", "result": "在RADIO作为主干模型的情况下，AnomalyVFM在9个多样化的数据集上实现了平均图像级AUROC为94.1%，超过了先前方法3.3个百分点。", "conclusion": "该研究展示了将视觉基础模型转化为零样本异常检测器的有效性，并且证明了所提出的方法可以显著提高性能。"}}
{"id": "2601.20522", "pdf": "https://arxiv.org/pdf/2601.20522", "abs": "https://arxiv.org/abs/2601.20522", "authors": ["Zhangsong Li"], "title": "Improved Computational Lower Bound of Estimation for Multi-Frequency Group Synchronization", "categories": ["math.ST", "cs.DS", "math.PR"], "comment": "22 pages", "summary": "We study the computational phase transition in a multi-frequency group synchronization problem, where pairwise relative measurements of group elements are observed across multiple frequency channels and corrupted by Gaussian noise. Using the framework of \\emph{low-degree polynomial algorithms}, we analyze the task of estimating the structured signal in such observations. We show that, assuming the low-degree heuristic, in synchronization models over the circle group $\\mathsf{SO}(2)$, a simple spectral method is computationally optimal among all polynomial-time estimators when the number of frequencies satisfies $L=n^{o(1)}$. This significantly extends prior work \\cite{KBK24+}, which only applied to a fixed constant number of frequencies. Together with known upper bounds on the statistical threshold \\cite{PWBM18a}, our results establish the existence of a \\emph{statistical-to-computational gap} in this model when the number of frequencies is sufficiently large.", "AI": {"tldr": "研究了多频率群同步问题中的计算相变，通过低度多项式算法框架分析信号估计任务。", "motivation": "探讨在圈群SO(2)的同步模型中，在相对测量值受到高斯噪声干扰的情况下，当频率数量满足L=n^{o(1)}时，谱方法在所有多项时间估计器中是计算最优的。这扩展了先前的研究成果，这些研究仅适用于固定常数个频率。", "method": "利用低度多项式算法框架分析多频率群同步问题中的信号估计任务。", "result": "假设低度多项式算法有效，在圈群SO(2)的同步模型中，谱方法在所有多项时间估计器中是计算最优的。当频率数量满足L=n^{o(1)}时，该结果建立了统计到计算的间隙存在性。", "conclusion": "通过研究多频率群同步问题中的计算相变，证明了在特定条件下谱方法的有效性和优势，并确定了统计与计算之间的间隙。"}}
{"id": "2601.20520", "pdf": "https://arxiv.org/pdf/2601.20520", "abs": "https://arxiv.org/abs/2601.20520", "authors": ["Qiyan Zhao", "Xiaofeng Zhang", "Shuochen Chang", "Qianyu Chen", "Xiaosong Yuan", "Xuhang Chen", "Luoqi Liu", "Jiajun Zhang", "Xu-Yao Zhang", "Da-Han Wang"], "title": "Context Tokens are Anchors: Understanding the Repetition Curse in dMLLMs from an Information Flow Perspective", "categories": ["cs.CV"], "comment": "Accepted in ICLR 2026", "summary": "Recent diffusion-based Multimodal Large Language Models (dMLLMs) suffer from high inference latency and therefore rely on caching techniques to accelerate decoding. However, the application of cache mechanisms often introduces undesirable repetitive text generation, a phenomenon we term the \\textbf{Repeat Curse}. To better investigate underlying mechanism behind this issue, we analyze repetition generation through the lens of information flow. Our work reveals three key findings: (1) context tokens aggregate semantic information as anchors and guide the final predictions; (2) as information propagates across layers, the entropy of context tokens converges in deeper layers, reflecting the model's growing prediction certainty; (3) Repetition is typically linked to disruptions in the information flow of context tokens and to the inability of their entropy to converge in deeper layers. Based on these insights, we present \\textbf{CoTA}, a plug-and-play method for mitigating repetition. CoTA enhances the attention of context tokens to preserve intrinsic information flow patterns, while introducing a penalty term to the confidence score during decoding to avoid outputs driven by uncertain context tokens. With extensive experiments, CoTA demonstrates significant effectiveness in alleviating repetition and achieves consistent performance improvements on general tasks. Code is available at https://github.com/ErikZ719/CoTA", "AI": {"tldr": "研究了扩散多模态大型语言模型中的重复生成问题，并提出了CoTA方法来减轻这一现象。", "motivation": "解决基于缓存技术的扩散多模态大型语言模型中出现的文本重复生成问题，提升推理效率和生成质量。", "method": "从信息流的角度分析了上下文令牌的作用机制，揭示了重复生成与信息流动中断的关系，并提出了CoTA方法以增强注意力机制并引入惩罚项来减少不确定性的输出。", "result": "实验表明，CoTA在减轻重复现象方面表现出显著效果，并且在通用任务上保持了一致的性能提升。", "conclusion": "通过从信息流视角理解上下文令牌的作用以及它们如何引导最终预测，可以有效地缓解扩散多模态大型语言模型中的重复生成问题。"}}
{"id": "2601.20518", "pdf": "https://arxiv.org/pdf/2601.20518", "abs": "https://arxiv.org/abs/2601.20518", "authors": ["Jiawen Chen", "Qi Shao", "Mingtong Zhou", "Duxin Chen", "Wenwu Yu"], "title": "CCMamba: Selective State-Space Models for Higher-Order Graph Learning on Combinatorial Complexes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Topological deep learning has emerged for modeling higher-order relational structures beyond pairwise interactions that standard graph neural networks fail to capture. Although combinatorial complexes offer a unified topological framework, most existing topological deep learning methods rely on local message passing via attention mechanisms, which incur quadratic complexity and remain low-dimensional, limiting scalability and rank-aware information aggregation in higher-order complexes.We propose Combinatorial Complex Mamba (CCMamba), the first unified mamba-based neural framework for learning on combinatorial complexes. CCMamba reformulates message passing as a selective state-space modeling problem by organizing multi-rank incidence relations into structured sequences processed by rank-aware state-space models. This enables adaptive, directional, and long range information propagation in linear time without self attention. We further establish the theoretical analysis that the expressive power upper-bound of CCMamba message passing is the 1-Weisfeiler-Lehman test. Experiments on graph, hypergraph, and simplicial benchmarks demonstrate that CCMamba consistently outperforms existing methods while exhibiting improved scalability and robustness to depth.", "AI": {"tldr": "CCMamba是一种新型的基于状态空间模型的消息传递框架，用于在组合复形上进行高层次图学习。", "motivation": "现有的拓扑深度学习方法大多依赖于局部消息传递机制，导致复杂度高且难以处理高层次关系结构。因此，作者提出了一种新的框架来解决这些问题。", "method": "CCMamba通过将多秩感应关系组织成结构化序列并使用基于状态空间模型的消息传递过程，实现自适应、方向性和长距离的信息传播。", "result": "实验结果表明，与现有方法相比，CCMamba在图、超图和单纯复形基准上的性能更优，并且具有更好的可扩展性以及对深度的鲁棒性。", "conclusion": "基于状态空间模型的消息传递框架CCMamba不仅提高了信息传播效率，还增强了学习能力，在处理高层次关系结构时表现出色。"}}
{"id": "2601.20511", "pdf": "https://arxiv.org/pdf/2601.20511", "abs": "https://arxiv.org/abs/2601.20511", "authors": ["Zelong Sun", "Jiahui Wu", "Ying Ba", "Dong Jing", "Zhiwu Lu"], "title": "Say Cheese! Detail-Preserving Portrait Collection Generation via Natural Language Edits", "categories": ["cs.CV"], "comment": null, "summary": "As social media platforms proliferate, users increasingly demand intuitive ways to create diverse, high-quality portrait collections. In this work, we introduce Portrait Collection Generation (PCG), a novel task that generates coherent portrait collections by editing a reference portrait image through natural language instructions. This task poses two unique challenges to existing methods: (1) complex multi-attribute modifications such as pose, spatial layout, and camera viewpoint; and (2) high-fidelity detail preservation including identity, clothing, and accessories. To address these challenges, we propose CHEESE, the first large-scale PCG dataset containing 24K portrait collections and 573K samples with high-quality modification text annotations, constructed through an Large Vison-Language Model-based pipeline with inversion-based verification. We further propose SCheese, a framework that combines text-guided generation with hierarchical identity and detail preservation. SCheese employs adaptive feature fusion mechanism to maintain identity consistency, and ConsistencyNet to inject fine-grained features for detail consistency. Comprehensive experiments validate the effectiveness of CHEESE in advancing PCG, with SCheese achieving state-of-the-art performance.", "AI": {"tldr": "生成由自然语言指令编辑的连贯肖像集合。", "motivation": "随着社交媒体平台的增长，用户需要更直观的方式来创建多样化的高质量肖像集合。现有方法在多属性修改和细节保留上存在挑战。", "method": "提出CHEESE数据集以及SCheese框架，以解决生成连贯的、高保真度的肖像集合的问题。SCheese结合了文本引导的生成技术和分层身份及细节保护机制。", "result": "实验验证了CHEESE数据集在推进PCG任务上的有效性，并且SCheese达到了最先进的性能。", "conclusion": "该工作解决了通过自然语言编辑创建连贯肖像集合的任务，提出的方法显著提升了肖像集合的生成质量和多样性。"}}
{"id": "2601.20510", "pdf": "https://arxiv.org/pdf/2601.20510", "abs": "https://arxiv.org/abs/2601.20510", "authors": ["Robin Singh", "Aditya Yogesh Nair", "Fabio Palumbo", "Florian Barbaro", "Anna Dyka", "Lohith Rachakonda"], "title": "Audio Deepfake Detection in the Age of Advanced Text-to-Speech models", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "This work was performed using HPC resources from GENCI-IDRIS (Grant 2025- AD011016076)", "summary": "Recent advances in Text-to-Speech (TTS) systems have substantially increased the realism of synthetic speech, raising new challenges for audio deepfake detection. This work presents a comparative evaluation of three state-of-the-art TTS models--Dia2, Maya1, and MeloTTS--representing streaming, LLM-based, and non-autoregressive architectures. A corpus of 12,000 synthetic audio samples was generated using the Daily-Dialog dataset and evaluated against four detection frameworks, including semantic, structural, and signal-level approaches. The results reveal significant variability in detector performance across generative mechanisms: models effective against one TTS architecture may fail against others, particularly LLM-based synthesis. In contrast, a multi-view detection approach combining complementary analysis levels demonstrates robust performance across all evaluated models. These findings highlight the limitations of single-paradigm detectors and emphasize the necessity of integrated detection strategies to address the evolving landscape of audio deepfake threats.", "AI": {"tldr": "该论文比较评估了三种最先进的文本到语音（TTS）模型的音频深伪检测性能，发现单一方法存在局限性，提出了结合多视角分析的方法以提高检测效果。", "motivation": "随着TTS系统的发展，合成语音的真实性不断提高，给音频深伪检测带来了新的挑战。该研究旨在评估不同生成机制下的音频深伪检测表现，并探索更有效的综合策略。", "method": "通过使用Daily-Dialog数据集生成12,000个合成音频样本，并利用四种不同的检测框架（包括语义、结构和信号级方法）进行对比测试，分别评估了三种TTS模型的效果。此外还考察了一种多视角结合的方法表现。", "result": "研究结果表明，针对不同类型的TTS生成机制，单一的检测策略存在显著差异的表现；而综合多种分析层次的方法则表现出更好的鲁棒性。", "conclusion": "该论文强调了单一种类检测方法在对抗音频深伪威胁中的局限，并指出需要发展更加全面和灵活的多视角组合策略以应对不断变化的技术挑战。"}}
{"id": "2601.20504", "pdf": "https://arxiv.org/pdf/2601.20504", "abs": "https://arxiv.org/abs/2601.20504", "authors": ["Meiqi Wu", "Bingze Song", "Ruimin Lin", "Chen Zhu", "Xiaokun Feng", "Jiahong Wu", "Xiangxiang Chu", "Kaiqi Huang"], "title": "Latent Temporal Discrepancy as Motion Prior: A Loss-Weighting Strategy for Dynamic Fidelity in T2V", "categories": ["cs.CV"], "comment": "Accepted by ICASSP 2026", "summary": "Video generation models have achieved notable progress in static scenarios, yet their performance in motion video generation remains limited, with quality degrading under drastic dynamic changes. This is due to noise disrupting temporal coherence and increasing the difficulty of learning dynamic regions. {Unfortunately, existing diffusion models rely on static loss for all scenarios, constraining their ability to capture complex dynamics.} To address this issue, we introduce Latent Temporal Discrepancy (LTD) as a motion prior to guide loss weighting. LTD measures frame-to-frame variation in the latent space, assigning larger penalties to regions with higher discrepancy while maintaining regular optimization for stable regions. This motion-aware strategy stabilizes training and enables the model to better reconstruct high-frequency dynamics. Extensive experiments on the general benchmark VBench and the motion-focused VMBench show consistent gains, with our method outperforming strong baselines by 3.31% on VBench and 3.58% on VMBench, achieving significant improvements in motion quality.", "AI": {"tldr": "提出了一种基于潜在时间差异的损失加权策略，以改善视频生成模型中的动态保真度。", "motivation": "现有扩散模型在静态场景中表现良好，但在处理剧烈运动变化时性能受限。为解决这一问题，引入了新的方法来提升模型捕捉复杂动力学的能力。", "method": "利用潜在时间差异（LTD）作为运动先验，通过测量帧间在潜在空间的变化，对高变动区域施加更大的惩罚，同时保持稳定区域的常规优化。", "result": "实验结果表明，在VBench和VMBench基准测试中，该方法分别比强基线提升了3.31％和3.58％，显著提高了运动质量。", "conclusion": "提出的基于潜在时间差异的损失加权策略能够有效地改善视频生成模型中的动态保真度。"}}
{"id": "2601.20503", "pdf": "https://arxiv.org/pdf/2601.20503", "abs": "https://arxiv.org/abs/2601.20503", "authors": ["Jesse Phitidis", "Alison Q. Smithard", "William N. Whiteley", "Joanna M. Wardlaw", "Miguel O. Bernabeu", "Maria Valdés Hernández"], "title": "Comparative evaluation of training strategies using partially labelled datasets for segmentation of white matter hyperintensities and stroke lesions in FLAIR MRI", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "White matter hyperintensities (WMH) and ischaemic stroke lesions (ISL) are imaging features associated with cerebral small vessel disease (SVD) that are visible on brain magnetic resonance imaging (MRI) scans. The development and validation of deep learning models to segment and differentiate these features is difficult because they visually confound each other in the fluid-attenuated inversion recovery (FLAIR) sequence and often appear in the same subject. We investigated six strategies for training a combined WMH and ISL segmentation model using partially labelled data. We combined privately held fully and partially labelled datasets with publicly available partially labelled datasets to yield a total of 2052 MRI volumes, with 1341 and 1152 containing ground truth annotations for WMH and ISL respectively. We found that several methods were able to effectively leverage the partially labelled data to improve model performance, with the use of pseudolabels yielding the best result.", "AI": {"tldr": "该论文研究了使用部分标注数据训练分割白质高信号和缺血性卒中病变的深度学习模型的各种策略。", "motivation": "由于白质高信号和缺血性卒中病变在FLAIR MRI图像上容易混淆，并且经常出现在同一患者身上，因此开发和验证可以准确区分这些病变的深度学习模型具有挑战性。", "method": "结合私人持有的完全标注数据集与公开部分标注的数据集以训练包含白质高信号和缺血性卒中病变分割的联合模型。测试了六种不同的训练策略。", "result": "研究发现，多种方法可以有效利用部分标注数据提高模型性能，使用伪标签的方法获得了最佳结果。", "conclusion": "该研究表明，在缺乏完全标注的数据集的情况下，通过运用适当的训练策略和伪标签技术，可以使深度学习模型在分割白质高信号和缺血性卒中病变时表现更好。"}}
{"id": "2601.20499", "pdf": "https://arxiv.org/pdf/2601.20499", "abs": "https://arxiv.org/abs/2601.20499", "authors": ["Hang Guo", "Zhaoyang Jia", "Jiahao Li", "Bin Li", "Yuanhao Cai", "Jiangshan Wang", "Yawei Li", "Yan Lu"], "title": "Efficient Autoregressive Video Diffusion with Dummy Head", "categories": ["cs.CV"], "comment": "Technical Report", "summary": "The autoregressive video diffusion model has recently gained considerable research interest due to its causal modeling and iterative denoising. In this work, we identify that the multi-head self-attention in these models under-utilizes historical frames: approximately 25% heads attend almost exclusively to the current frame, and discarding their KV caches incurs only minor performance degradation. Building upon this, we propose Dummy Forcing, a simple yet effective method to control context accessibility across different heads. Specifically, the proposed heterogeneous memory allocation reduces head-wise context redundancy, accompanied by dynamic head programming to adaptively classify head types. Moreover, we develop a context packing technique to achieve more aggressive cache compression. Without additional training, our Dummy Forcing delivers up to 2.0x speedup over the baseline, supporting video generation at 24.3 FPS with less than 0.5% quality drop. Project page is available at https://csguoh.github.io/project/DummyForcing/.", "AI": {"tldr": "提出了一种名为Dummy Forcing的方法，用于提高自回归视频扩散模型的效率。", "motivation": "多头自我注意机制在自回归视频扩散模型中未能充分利用历史帧的信息。大约25％的头部几乎只关注当前帧，并且丢弃它们的KV缓存只会引起轻微的性能下降。", "method": "提出了一种异质内存分配技术来减少头部之间的上下文冗余，通过动态头部编程适应性地分类头部类型，以及开发出一种更激进的上下文压缩技术——上下文打包。这些改进共同构成了Dummy Forcing方法。", "result": "Dummy Forcing在不进行额外训练的情况下提供了高达2.0倍的速度提升，支持以每秒24.3帧生成视频且质量下降不到0.5%。", "conclusion": "通过减少头部的上下文冗余和实现更有效的缓存压缩，Dummy Forcing提高了自回归视频扩散模型的效率。"}}
{"id": "2601.20487", "pdf": "https://arxiv.org/pdf/2601.20487", "abs": "https://arxiv.org/abs/2601.20487", "authors": ["Nico Mutzner", "Taha Yasseri", "Heiko Rauhut"], "title": "Normative Equivalence in Human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups", "categories": ["cs.AI", "cs.GT", "cs.HC", "econ.GN"], "comment": null, "summary": "The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner's Dilemma, or in participants' normative perceptions. Participants' behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making.", "AI": {"tldr": "研究探讨了在人类群体中引入AI代理如何影响合作性社会规范。", "motivation": "了解将AI代理人融入人类群体环境中，对合作性社会规范的形成和维护有何影响。", "method": "通过在线实验使用四人公共物品游戏(PGG)，每组三人是人类参与者，一人是被定义为人的或人工智能的机器人。根据不同的策略来评估合作水平：无条件合作、有条件的合作或者搭便车行为。", "result": "发现合作主要受到群体动态和行为惯性驱动，并且这种规范机制在人与AI条件下表现一致，没有显著差异。参与者的行为遵循相同的规范逻辑。", "conclusion": "研究结果表明，在混合人类和AI群体中以及所有人类群体中的维持合作的机制是相似的，这支持了规范等价性的模式。"}}
{"id": "2601.20481", "pdf": "https://arxiv.org/pdf/2601.20481", "abs": "https://arxiv.org/abs/2601.20481", "authors": ["Myungjin Lee", "Eunji Shin", "Jiyoung Lee"], "title": "Erasing Your Voice Before It's Heard: Training-free Speaker Unlearning for Zero-shot Text-to-Speech", "categories": ["eess.AS", "cs.SD"], "comment": "ICASSP'2026", "summary": "Modern zero-shot text-to-speech (TTS) models offer unprecedented expressivity but also pose serious crime risks, as they can synthesize voices of individuals who never consented. In this context, speaker unlearning aims to prevent the generation of specific speaker identities upon request. Existing approaches, reliant on retraining, are costly and limited to speakers seen in the training set. We present TruS, a training-free speaker unlearning framework that shifts the paradigm from data deletion to inference-time control. TruS steers identity-specific hidden activations to suppress target speakers while preserving other attributes (e.g., prosody and emotion). Experimental results show that TruS effectively prevents voice generation on both seen and unseen opt-out speakers, establishing a scalable safeguard for speech synthesis. The demo and code are available on http://mmai.ewha.ac.kr/trus.", "AI": {"tldr": "提出了一种无训练的说话人去除框架TruS，用于防止生成特定说话人的声音。", "motivation": "零样本语音合成技术在提供强大表现力的同时也带来了严重的隐私风险，因为可以合成未经同意个体的声音。因此需要一种方法来防止这种非法行为的发生。", "method": "提出了一种无训练的框架TruS，在推理时控制特定身份的隐藏激活以抑制目标说话人，同时保留其他属性（例如语调和情感）。", "result": "实验结果显示，TruS有效阻止了已见和未见的撤回者的语音生成。", "conclusion": "TruS作为一种无训练的说话人去除框架，在防止非法语音合成方面表现出良好的效果，并提供了一种可扩展的安全保障。"}}
{"id": "2601.20478", "pdf": "https://arxiv.org/pdf/2601.20478", "abs": "https://arxiv.org/abs/2601.20478", "authors": ["Adam Štefunko", "Carlos Eduardo Cancino-Chacón", "Jan Hajič jr"], "title": "On Every Note a Griff: Looking for a Useful Representation of Basso Continuo Performance Style", "categories": ["cs.SD", "cs.IR"], "comment": "6 pages, 5 figures, accepted to the Music Encoding Conference (MEC) 2026", "summary": "Basso continuo is a baroque improvisatory accompaniment style which involves improvising multiple parts above a given bass line in a musical score on a harpsichord or organ. Basso continuo is not merely a matter of history; moreover, it is a historically inspired living practice, and The Aligned Continuo Dataset (ACoRD) records the first sample of modern-day basso continuo playing in the symbolic domain. This dataset, containing 175 MIDI recordings of 5 basso continuo scores performed by 7 players, allows us to start observing and analyzing the variety that basso continuo improvisation brings. A recently proposed basso continuo performance-to-score alignment system provides a way of mapping improvised performance notes to score notes. In order to study aligned basso continuo performances, we need an appropriate feature representation. We propose griff, a representation inspired by historical basso continuo treatises. It enables us to encode both pitch content and structure of a basso continuo realization in a transposition-invariant way. Griffs are directly extracted from aligned basso continuo performances by grouping together performance notes aligned to the same score note in a onset-time ordered way, and they provide meaningful tokens that form a feature space in which we can analyze basso continuo performance styles. We statistically describe griffs extracted from the ACoRD dataset recordings, and show in two experiments how griffs can be used for statistical analysis of individuality of different players' basso continuo performance styles. We finally present an argument why it is desirable to preserve the structure of a basso continuo improvisation in order to conduct a refined analysis of personal performance styles of individual basso continuo practitioners, and why griffs can provide a meaningful historically informed feature space worthy of a more robust empirical validation.", "AI": {"tldr": "该论文提出了一个名为griff的表示方法，用于分析和研究现代巴洛克时代basso continuo演奏风格。", "motivation": "通过历史文献启发，建立一种有效的表示方式来捕捉并解析basso continuo表演风格中的个体差异。", "method": "利用ACoRD数据集中的175个MIDI录音以及自动对齐系统，提取griff特征，并以此进行统计分析。", "result": "实验结果表明，griff可以作为有意义的历史信息空间，用于解析不同演奏者的个人表演风格。", "conclusion": "griff提供了一种有效的、结构化的方式去捕捉basso continuo的个人表演特点。"}}
{"id": "2601.20468", "pdf": "https://arxiv.org/pdf/2601.20468", "abs": "https://arxiv.org/abs/2601.20468", "authors": ["Mathis Brossier", "Mina Mani", "Agathe Malbet", "Konrad Schönborn", "Lonni Besançon"], "title": "Opportunities of Touch-Enabled Spherical Displays to support Climate Conversations", "categories": ["cs.HC"], "comment": "Submitted to Posters of CHI'26", "summary": "We explore how touch-sensitive spherical displays can support climate conversations in museums and science centers. These displays enable intuitive and embodied interaction with complex climate data, and support collective exploration. However, current interaction capabilities of spherical displays are limited. Therefore, this exploratory study aims to identify potential opportunities to develop meaningful interactions and technical solutions. Through two workshops, key opportunities were identified to improve visitors' understanding and navigation of climate data, along with recommendations for technical implementation. Our results provide guidelines and aspects to consider for future research and development in this area.", "AI": {"tldr": "探讨触控敏感球形显示器在博物馆和科学中心支持气候对话中的应用机会。", "motivation": "通过直观且沉浸式的交互方式，帮助公众更好地理解和探索复杂的气候数据。", "method": "通过两个研讨会识别改进访客对气候数据理解与导航的关键机遇，并提出技术实现建议。", "result": "提供了未来研究和开发的指导方针及需考虑方面的指南。", "conclusion": "球形显示器为增强观众对气候变化的理解提供了一种新的交互方式。"}}
{"id": "2601.20467", "pdf": "https://arxiv.org/pdf/2601.20467", "abs": "https://arxiv.org/abs/2601.20467", "authors": ["Zhenxuan Fan", "Jie Cao", "Yang Dai", "Zheqi Lv", "Wenqiao Zhang", "Zhongle Xie", "Peng LU", "Beng Chin Ooi"], "title": "CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "16 pages, 9 figures, 11 tables", "summary": "Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \\textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.", "AI": {"tldr": "本文提出了CtrlCoT框架，用于压缩链式思维（CoT）以提高LLM推理的效率和准确性。", "motivation": "链式思维提示提高了LLM的推理能力，但由于冗长的追踪导致高延迟和内存消耗，因此需要在保持正确性的同时进行压缩。现有方法要么过于保守地缩短语义层次的CoTs，要么过分激进地剪枝，这可能导致任务关键线索丢失并降低准确性。", "method": "CtrlCoT框架包括三个组件：分层推理抽象生成多级语义粒度的CoTs；逻辑保留蒸馏训练一个逻辑感知剪枝器以保持不可缺少的推理线索；分布对齐生成确保压缩轨迹与流畅的推断风格一致，避免片段化。", "result": "在MATH-500数据集上使用Qwen2.5-7B-Instruct模型时，CtrlCoT方法比最强基线减少30.7%的令牌并且准确率提高了7.6个百分点。", "conclusion": "本文通过提出一种双粒度链式思维压缩框架解决了现有技术的问题，证明了更高效和可靠的推理。"}}
{"id": "2601.20466", "pdf": "https://arxiv.org/pdf/2601.20466", "abs": "https://arxiv.org/abs/2601.20466", "authors": ["Mathis Brossier", "Mujtaba Fadhil Jawad", "Emma Broman", "Ylva Selling", "Julia Hallsten", "Alexander Bock", "Johanna Björklund", "Tobias Isenberg", "Anders Ynnerman", "Mario Romero"], "title": "Piloting Planetarium Visualizations with LLMs during Live Events in Science Centers", "categories": ["cs.HC"], "comment": "Submitted to Posters of CHI'26", "summary": "We designed and evaluated an AI pilot in a planetarium visualization software, OpenSpace, for public shows in science centers. The piloting role is usually given to a human working in close collaboration with the guide on stage. We recruited 7 professional guides with extensive experience in giving shows to the public to study the impact of the AI-piloting on the overall experience. The AI-pilot is a conversational AI-agent listening to the guide and interpreting the verbal statements as commands to execute camera motions, change simulation time, or toggle visual assets. Our results show that, while AI pilots lack several critical skills for live shows, they could become useful as co-pilots to reduce workload of human pilots and allow multitasking. We propose research directions toward implementing visualization pilots and co-pilots in live settings.", "AI": {"tldr": "在科学中心的公共展示中，评估AI在行星可视化软件中的试点角色。", "motivation": "探索AI作为共驾者减少人类飞行员工作量和实现多任务处理的可能性。", "method": "招募7名经验丰富的指导员来研究AI飞行员对整体体验的影响。AI飞行员是一个对话式AI代理，根据指导员的口头指令执行相机移动、更改仿真时间和切换视觉资产。", "result": "结果显示AI飞行员缺乏现场表演的关键技能，但可以作为共驾者减少人类飞行员的工作量并实现多任务处理。", "conclusion": "提出研究方向以实现在现场环境中实施可视化飞行员和共驾者的设想"}}
{"id": "2601.20464", "pdf": "https://arxiv.org/pdf/2601.20464", "abs": "https://arxiv.org/abs/2601.20464", "authors": ["Alejandro Benito-Santos", "Florian Windhager", "Aida Horaniet Ibañez", "Rabea Kleymann", "Alfie Abdul-Rahman", "Eva Mayr"], "title": "Chasing Meaning and/or Insight? A Survey on Evaluation Practices at the Intersection of Visualization and the Humanities", "categories": ["cs.HC"], "comment": "Accepted to CHI'26", "summary": "The intersection of visualization and the humanities (VIS*H) is marked by a tension between chasing analytical \"insight\" and interpretive \"meaning.\" The effectiveness of visualization techniques hinges on established evaluation frameworks that assess both analytical utility and communicative efficacy, creating a potential mismatch with the non-positivist, interpretive aims of humanities scholarship. To examine how this tension manifests in practice, we systematically surveyed 171 VIS*H design studies to analyze their evaluation workflows and rigor according to standard practice. Our findings reveal recurring flaws, such as an over-reliance on monomethod approaches, and show that higher-quality evaluations emerge from workflows that effectively triangulate diverse evidence. From these findings, we derive recommendations to refine quality and validation criteria for humanities visualizations, and juxtapose them to ongoing critical debates in the field, ultimately arguing for a paradigm shift that can reconcile the advantages of established validation techniques with the interpretive depth required for humanistic inquiry.", "AI": {"tldr": "本文通过系统调查人文可视化（VIS*H）设计研究中的评估工作流程和标准，探讨了追求分析洞察力与解释意义之间的紧张关系，并提出改进建议。", "motivation": "在人文可视化领域中，现有评估方法侧重于分析实用性和沟通效率，但忽视了解释性深度的需求。为解决此问题并促进这一领域的健康发展，本文旨在通过系统调查来识别和改善评价实践中的缺陷。", "method": "作者对171个VIS*H设计研究的评估工作流程进行了系统的文献综述，并根据标准方法分析了其严谨程度。", "result": "研究发现普遍存在单一方法依赖等问题，高质量评估则来源于能够有效整合多种证据的工作流程。", "conclusion": "本文建议通过改进质量与验证标准来增强人文可视化评价实践的有效性，并提出需要一种新的范式来平衡现有验证技术的优势和人文学科所需的解释深度。"}}
{"id": "2601.20461", "pdf": "https://arxiv.org/pdf/2601.20461", "abs": "https://arxiv.org/abs/2601.20461", "authors": ["Yanzhu Liu", "Xiao Liu", "Yuexuan Wang", "Mondal Soumik"], "title": "Exploiting the Final Component of Generator Architectures for AI-Generated Image Detection", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid proliferation of powerful image generators, accurate detection of AI-generated images has become essential for maintaining a trustworthy online environment. However, existing deepfake detectors often generalize poorly to images produced by unseen generators. Notably, despite being trained under vastly different paradigms, such as diffusion or autoregressive modeling, many modern image generators share common final architectural components that serve as the last stage for converting intermediate representations into images. Motivated by this insight, we propose to \"contaminate\" real images using the generator's final component and train a detector to distinguish them from the original real images. We further introduce a taxonomy based on generators' final components and categorize 21 widely used generators accordingly, enabling a comprehensive investigation of our method's generalization capability. Using only 100 samples from each of three representative categories, our detector-fine-tuned on the DINOv3 backbone-achieves an average accuracy of 98.83% across 22 testing sets from unseen generators.", "AI": {"tldr": "提出了一种利用生成器最终组件来检测AI生成图像的方法，通过在真实图像中添加这些组件的“污染”以训练分类器。", "motivation": "现有的深度伪造探测器对未知生成器生产的图像泛化能力差。基于许多现代图像生成模型共享相似的最终架构组件这一观察结果，研究者们开发了一种新方法来提高检测精度。", "method": "通过使用生成器的最终组件对真实图像进行“污染”，然后训练一个分类器区分这些修改后的图像与原始的真实图像，以此建立能够有效识别AI生成图像的新模型。此外，还提出了一种基于生成器最后组件的分类法，并据此将21个广泛使用的生成器分为几个类别。", "result": "使用来自三个代表性类别的每个类别仅100个样本进行训练后，在22个测试集中，该方法在DINOv3骨干网络上微调后的检测器平均准确率为98.83%。", "conclusion": "通过利用生成器的最终组件来“污染”真实图像的方法能够有效地提高AI生成图像的识别率，并且这种方法对于未知或新型生成器也具有很好的泛化能力。"}}
{"id": "2601.20449", "pdf": "https://arxiv.org/pdf/2601.20449", "abs": "https://arxiv.org/abs/2601.20449", "authors": ["Fatima Ezzeddine", "Obaida Ammar", "Silvia Giordano", "Omran Ayoub"], "title": "Fair Recourse for All: Ensuring Individual and Group Fairness in Counterfactual Explanations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Explainable Artificial Intelligence (XAI) is becoming increasingly essential for enhancing the transparency of machine learning (ML) models. Among the various XAI techniques, counterfactual explanations (CFs) hold a pivotal role due to their ability to illustrate how changes in input features can alter an ML model's decision, thereby offering actionable recourse to users. Ensuring that individuals with comparable attributes and those belonging to different protected groups (e.g., demographic) receive similar and actionable recourse options is essential for trustworthy and fair decision-making. In this work, we address this challenge directly by focusing on the generation of fair CFs. Specifically, we start by defining and formulating fairness at: 1) individual fairness, ensuring that similar individuals receive similar CFs, 2) group fairness, ensuring equitable CFs across different protected groups and 3) hybrid fairness, which accounts for both individual and broader group-level fairness. We formulate the problem as an optimization task and propose a novel model-agnostic, reinforcement learning based approach to generate CFs that satisfy fairness constraints at both the individual and group levels, two objectives that are usually treated as orthogonal. As fairness metrics, we extend existing metrics commonly used for auditing ML models, such as equal choice of recourse and equal effectiveness across individuals and groups. We evaluate our approach on three benchmark datasets, showing that it effectively ensures individual and group fairness while preserving the quality of the generated CFs in terms of proximity and plausibility, and quantify the cost of fairness in the different levels separately. Our work opens a broader discussion on hybrid fairness and its role and implications for XAI and beyond CFs.", "AI": {"tldr": "本文提出了一种生成公平反事实解释的新方法，旨在同时满足个体和群体的公平性。", "motivation": "确保具有相似特征的个人以及不同保护组中的成员能够获得类似且可操作的补救方案是实现信任与公正决策的关键。当前大多数工作仅关注个体层面或群体层面上的单一公平性，而忽视了两者之间的平衡关系。", "method": "本文通过定义并形式化三种类型的公平性（即个体公平、群体公平和混合公平）来解决这一挑战，并采用基于强化学习的方法生成符合这些公平约束条件的反事实解释。", "result": "在三个基准数据集上的实验证明，所提方法能够有效确保个体与群体层面的公平性，同时保持反事实解释的质量（即接近度和合理性）。", "conclusion": "本文的研究开启了一个更广泛的讨论，关于混合公平性及其对可解释人工智能以及超出反事实解释范围的角色和影响。"}}
{"id": "2601.20447", "pdf": "https://arxiv.org/pdf/2601.20447", "abs": "https://arxiv.org/abs/2601.20447", "authors": ["Jiahe Li", "Junru Chen", "Fanqi Shen", "Jialan Yang", "Jada Li", "Zhizhang Yuan", "Baowen Cheng", "Meng Li", "Yang Yang"], "title": "Assembling the Mind's Mosaic: Towards EEG Semantic Intent Decoding", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "comment": null, "summary": "Enabling natural communication through brain-computer interfaces (BCIs) remains one of the most profound challenges in neuroscience and neurotechnology. While existing frameworks offer partial solutions, they are constrained by oversimplified semantic representations and a lack of interpretability. To overcome these limitations, we introduce Semantic Intent Decoding (SID), a novel framework that translates neural activity into natural language by modeling meaning as a flexible set of compositional semantic units. SID is built on three core principles: semantic compositionality, continuity and expandability of semantic space, and fidelity in reconstruction. We present BrainMosaic, a deep learning architecture implementing SID. BrainMosaic decodes multiple semantic units from EEG/SEEG signals using set matching and then reconstructs coherent sentences through semantic-guided reconstruction. This approach moves beyond traditional pipelines that rely on fixed-class classification or unconstrained generation, enabling a more interpretable and expressive communication paradigm. Extensive experiments on multilingual EEG and clinical SEEG datasets demonstrate that SID and BrainMosaic offer substantial advantages over existing frameworks, paving the way for natural and effective BCI-mediated communication.", "AI": {"tldr": "通过EEG信号解码语义意图，实现自然语言的脑机接口通信。", "motivation": "现有脑机接口框架受限于简化的语义表示和缺乏解释性。为解决这一问题，提出了SID框架，以更灵活、可扩展的方式建模意义，并提高重建精度。", "method": "提出Semantic Intent Decoding（SID）框架及BrainMosaic架构，利用深度学习从EEG/SEEG信号中解码多个语义单元并通过语义引导进行句子重构。", "result": "实验表明，SID和BrainMosaic在多语言EEG和临床SEEG数据集上表现优于现有方法，实现了更自然、有效的脑机接口通信。", "conclusion": "该研究开辟了基于自然语言的高效脑机接口的新途径。"}}
{"id": "2601.20437", "pdf": "https://arxiv.org/pdf/2601.20437", "abs": "https://arxiv.org/abs/2601.20437", "authors": ["Tongzhou Yu", "Han Lin"], "title": "Remember Me, Not Save Me: A Collective Memory System for Evolving Virtual Identities in Augmented Reality", "categories": ["cs.HC"], "comment": "Accepted to ACM SIGGRAPH VRCAI 2025 (Macau, China). 4 pages, 5 figures. DOI: 10.1145/3779232.3779468", "summary": "This paper presents \"Remember Me, Not Save Me,\" an AR & AI system enabling virtual citizens to develop personality through collective dialogue. Core innovations include: Dynamic Collective Memory (DCM) model with narrative tension mechanisms for handling contradictory memories; State-Reflective Avatar for ambient explainability; and Geo-Cultural Context Anchoring for local identity. Deployed at the 2024 Jinan Biennale, the system demonstrated stable personality emergence (ISTP type via Apply Magic Sauce analysis) from over 2,500 public interactions. We provide a framework for designing evolving digital entities that transform collective memory into coherent identity.", "AI": {"tldr": "本文提出了一种AR与AI系统，使虚拟市民通过集体对话发展个性。", "motivation": "该论文旨在探索如何利用AR和AI技术让虚拟公民通过集体记忆和个人互动来形成和发展身份认同。", "method": "开发了动态集体记忆模型、状态反思式化身以及地域文化背景锚定机制。", "result": "在2024济南双年展上，系统展示了从超过2500次公共交互中产生的稳定个性特征（ISTP类型）。", "conclusion": "论文提供了一个框架，用于设计能够将集体记忆转化为连贯身份的演变数字实体。"}}
{"id": "2601.20433", "pdf": "https://arxiv.org/pdf/2601.20433", "abs": "https://arxiv.org/abs/2601.20433", "authors": ["Wenbo Xu", "Wei Lu", "Xiangyang Luo", "Jiantao Zhou"], "title": "MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Deepfake detection is a widely researched topic that is crucial for combating the spread of malicious content, with existing methods mainly modeling the problem as classification or spatial localization. The rapid advancements in generative models impose new demands on Deepfake detection. In this paper, we propose multimodal alignment and reinforcement for explainable Deepfake detection via vision-language models, termed MARE, which aims to enhance the accuracy and reliability of Vision-Language Models (VLMs) in Deepfake detection and reasoning. Specifically, MARE designs comprehensive reward functions, incorporating reinforcement learning from human feedback (RLHF), to incentivize the generation of text-spatially aligned reasoning content that adheres to human preferences. Besides, MARE introduces a forgery disentanglement module to capture intrinsic forgery traces from high-level facial semantics, thereby improving its authenticity detection capability. We conduct thorough evaluations on the reasoning content generated by MARE. Both quantitative and qualitative experimental results demonstrate that MARE achieves state-of-the-art performance in terms of accuracy and reliability.", "AI": {"tldr": "提出了一种通过视觉语言模型进行可解释的深度伪造检测的方法MARE，以提高深度伪造检测的准确性和可靠性。", "motivation": "现有方法主要集中在分类或空间定位上，并不能很好地应对生成模型快速发展带来的新挑战。因此，需要一种新的方法来增强视觉语言模型在深度伪造检测和推理中的性能。", "method": "设计了多模态对齐与强化学习机制，通过引入人类反馈的强化学习（RLHF）奖励函数以激励文本和空间位置相一致的推理内容生成；另外还提出了一种伪造分离模块来捕捉高级面部语义中的内在伪造痕迹。", "result": "实验结果表明，MARE在准确性和可靠性方面达到了最先进的性能。", "conclusion": "MARE通过结合多模态对齐与强化学习以及伪造分离技术，在深度伪造检测中展示了优越的表现。"}}
{"id": "2601.20432", "pdf": "https://arxiv.org/pdf/2601.20432", "abs": "https://arxiv.org/abs/2601.20432", "authors": ["Yigitcan Özer", "Wanying Ge", "Zhe Zhang", "Xin Wang", "Junichi Yamagishi"], "title": "Self Voice Conversion as an Attack against Neural Audio Watermarking", "categories": ["cs.SD", "cs.AI"], "comment": "7 pages; 2 figures; 2 tables; accepted at IEICE, SP/SLP 2026", "summary": "Audio watermarking embeds auxiliary information into speech while maintaining speaker identity, linguistic content, and perceptual quality. Although recent advances in neural and digital signal processing-based watermarking methods have improved imperceptibility and embedding capacity, robustness is still primarily assessed against conventional distortions such as compression, additive noise, and resampling. However, the rise of deep learning-based attacks introduces novel and significant threats to watermark security. In this work, we investigate self voice conversion as a universal, content-preserving attack against audio watermarking systems. Self voice conversion remaps a speaker's voice to the same identity while altering acoustic characteristics through a voice conversion model. We demonstrate that this attack severely degrades the reliability of state-of-the-art watermarking approaches and highlight its implications for the security of modern audio watermarking techniques.", "AI": {"tldr": "研究自语音转换作为针对音频水印系统的攻击方法，以评估其对现代音频水印技术的安全性影响。", "motivation": "现有音频水印方法虽然改进了不可感知性和嵌入容量，但主要对抗的是传统的失真形式如压缩、加性噪声和重采样。引入深度学习的新型攻击带来了新的安全威胁。研究旨在展示自语音转换对水印系统的破坏效果，并强调其安全性问题。", "method": "通过使用语音转换模型改变说话人声学特征来实施自语音转换，同时保持内容不变。这种方法被用于评估最先进的音频水印方法的鲁棒性。", "result": "研究表明，自语音转换严重降低了现代音频水印技术的可靠性，显示出对这些系统的显著破坏效果。", "conclusion": "研究结果表明，基于深度学习的攻击（如自语音转换）构成了新的威胁，并强调了改进现有音频水印系统安全性的必要性。"}}
{"id": "2601.20430", "pdf": "https://arxiv.org/pdf/2601.20430", "abs": "https://arxiv.org/abs/2601.20430", "authors": ["Kun Yin", "Yunfei Wu", "Bing Liu", "Zhongpeng Cai", "Xiaotian Li", "Huang Chen", "Xin Li", "Haoyu Cao", "Yinsong Liu", "Deqiang Jiang", "Xing Sun", "Yunsheng Wu", "Qianyu Li", "Antai Guo", "Yanzhen Liao", "Yanqiu Qu", "Haodong Lin", "Chengxu He", "Shuangyin Liu"], "title": "Youtu-Parsing: Perception, Structuring and Recognition via High-Parallelism Decoding", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents Youtu-Parsing, an efficient and versatile document parsing model designed for high-performance content extraction. The architecture employs a native Vision Transformer (ViT) featuring a dynamic-resolution visual encoder to extract shared document features, coupled with a prompt-guided Youtu-LLM-2B language model for layout analysis and region-prompted decoding. Leveraging this decoupled and feature-reusable framework, we introduce a high-parallelism decoding strategy comprising two core components: token parallelism and query parallelism. The token parallelism strategy concurrently generates up to 64 candidate tokens per inference step, which are subsequently validated through a verification mechanism. This approach yields a 5--11x speedup over traditional autoregressive decoding and is particularly well-suited for highly structured scenarios, such as table recognition. To further exploit the advantages of region-prompted decoding, the query parallelism strategy enables simultaneous content prediction for multiple bounding boxes (up to five), providing an additional 2x acceleration while maintaining output quality equivalent to standard decoding. Youtu-Parsing encompasses a diverse range of document elements, including text, formulas, tables, charts, seals, and hierarchical structures. Furthermore, the model exhibits strong robustness when handling rare characters, multilingual text, and handwritten content. Extensive evaluations demonstrate that Youtu-Parsing achieves state-of-the-art (SOTA) performance on both the OmniDocBench and olmOCR-bench benchmarks. Overall, Youtu-Parsing demonstrates significant experimental value and practical utility for large-scale document intelligence applications.", "AI": {"tldr": "本文提出了Youtu-Parsing模型，用于高效的文档解析和内容提取。", "motivation": "为了实现高效且强大的文档结构化处理能力，提出了一种结合视觉转换器和语言模型的解码策略，以提高解析效率和准确性。", "method": "利用动态分辨率视觉编码器提取共享特征，并采用提示引导的语言模型进行布局分析和区域引导解码。通过令牌并行性和查询并行性实现高平行度解码，同时支持多种文档元素的解析。", "result": "实验结果表明，Youtu-Parsing在OmniDocBench和olmOCR-bench基准测试中达到了最先进的性能，并具有良好的鲁棒性和实用性。", "conclusion": "Youtu-Parsing模型展示了显著的实验价值和实用功能，在大规模文档智能应用中表现出色。"}}
{"id": "2601.20429", "pdf": "https://arxiv.org/pdf/2601.20429", "abs": "https://arxiv.org/abs/2601.20429", "authors": ["Junseo Lee", "Sangyun Jeon", "Jungi Lee", "Junyong Park", "Jaewoong Sim"], "title": "GRTX: Efficient Ray Tracing for 3D Gaussian-Based Rendering", "categories": ["cs.GR", "cs.AR", "cs.CV"], "comment": "To appear at the 32nd International Symposium on High-Performance Computer Architecture (HPCA 2026)", "summary": "3D Gaussian Splatting has gained widespread adoption across diverse applications due to its exceptional rendering performance and visual quality. While most existing methods rely on rasterization to render Gaussians, recent research has started investigating ray tracing approaches to overcome the fundamental limitations inherent in rasterization. However, current Gaussian ray tracing methods suffer from inefficiencies such as bloated acceleration structures and redundant node traversals, which greatly degrade ray tracing performance. In this work, we present GRTX, a set of software and hardware optimizations that enable efficient ray tracing for 3D Gaussian-based rendering. First, we introduce a novel approach for constructing streamlined acceleration structures for Gaussian primitives. Our key insight is that anisotropic Gaussians can be treated as unit spheres through ray space transformations, which substantially reduces BVH size and traversal overhead. Second, we propose dedicated hardware support for traversal checkpointing within ray tracing units. This eliminates redundant node visits during multi-round tracing by resuming traversal from checkpointed nodes rather than restarting from the root node in each subsequent round. Our evaluation shows that GRTX significantly improves ray tracing performance compared to the baseline ray tracing method with a negligible hardware cost.", "AI": {"tldr": "GRTX通过软件和硬件优化实现高效的三维高斯渲染光线追踪。", "motivation": "当前的高斯光线追踪方法存在加速结构臃肿及冗余节点遍历的问题，导致性能下降。本文旨在克服这些问题，提高光线追踪效率。", "method": "提出了一种构建精简加速结构的新方法，并通过在射线空间变换中将各向异性高斯视为单位球来减少BVH的大小和遍历开销。此外还提出了在光线追踪单元中的专用硬件支持以实现遍历检查点，从而避免重复节点访问。", "result": "GRTX显著提升了与基线方法相比的光线跟踪性能，并且几乎不增加硬件成本。", "conclusion": "通过创新的方法和优化技术，GRTX有效解决了现有高斯渲染光线追踪效率低下的问题。"}}
{"id": "2601.20426", "pdf": "https://arxiv.org/pdf/2601.20426", "abs": "https://arxiv.org/abs/2601.20426", "authors": ["Annie Chu", "Hugo Flores García", "Oriol Nieto", "Justin Salamon", "Bryan Pardo", "Prem Seetharaman"], "title": "Mix2Morph: Learning Sound Morphing from Noisy Mixes", "categories": ["cs.SD"], "comment": "Accepted into ICASSP 2026", "summary": "We introduce Mix2Morph, a text-to-audio diffusion model fine-tuned to perform sound morphing without a dedicated dataset of morphs. By finetuning on noisy surrogate mixes at higher diffusion timesteps, Mix2Morph yields stable, perceptually coherent morphs that convincingly integrate qualities of both sources. We specifically target sound infusions, a practically and perceptually motivated subclass of morphing in which one sound acts as the dominant primary source, providing overall temporal and structural behavior, while a secondary sound is infused throughout, enriching its timbral and textural qualities. Objective evaluations and listening tests show that Mix2Morph outperforms prior baselines and produces high-quality sound infusions across diverse categories, representing a step toward more controllable and concept-driven tools for sound design. Sound examples are available at https://anniejchu.github.io/mix2morph .", "AI": {"tldr": "本文介绍了Mix2Morph，一种无需专用数据集即可执行声音变形的文本到音频扩散模型。", "motivation": "现有的声音变形方法需要专门的数据集来进行训练，这在实际应用中并不总是可行的。因此，作者希望通过直接从嘈杂的混合信号中学习来解决这个问题，并且能够生成高质量的声音融合效果。", "method": "通过在高扩散时间步上对噪声替代混音进行微调，Mix2Morph可以稳定地生成感知一致的声音变形。这种方法特别针对声音注入这一子类问题，其中一个声音作为主源提供整体的时间和结构行为，而另一个声音则在整个过程中融入其中，丰富其音色和质感。", "result": "客观评估和听觉测试表明，Mix2Morph优于之前的基准方法，并能生成高质量的跨不同类别声音融合效果。", "conclusion": "通过直接从混合信号中学习的方法，本文提出了一种新的声音变形工具，这为未来的可控且概念驱动的声音设计提供了基础。"}}
{"id": "2601.20425", "pdf": "https://arxiv.org/pdf/2601.20425", "abs": "https://arxiv.org/abs/2601.20425", "authors": ["Chenliang Zhou", "Fangcheng Zhong", "Weihao Xia", "Albert Miao", "Canberk Baykal", "Cengiz Oztireli"], "title": "Quartet of Diffusions: Structure-Aware Point Cloud Generation through Part and Symmetry Guidance", "categories": ["cs.CV"], "comment": null, "summary": "We introduce the Quartet of Diffusions, a structure-aware point cloud generation framework that explicitly models part composition and symmetry. Unlike prior methods that treat shape generation as a holistic process or only support part composition, our approach leverages four coordinated diffusion models to learn distributions of global shape latents, symmetries, semantic parts, and their spatial assembly. This structured pipeline ensures guaranteed symmetry, coherent part placement, and diverse, high-quality outputs. By disentangling the generative process into interpretable components, our method supports fine-grained control over shape attributes, enabling targeted manipulation of individual parts while preserving global consistency. A central global latent further reinforces structural coherence across assembled parts. Our experiments show that the Quartet achieves state-of-the-art performance. To our best knowledge, this is the first 3D point cloud generation framework that fully integrates and enforces both symmetry and part priors throughout the generative process.", "AI": {"tldr": "本文提出了一种结构感知的点云生成框架，通过四个协调的扩散模型学习全局形状、对称性、语义部件及其空间组装分布。", "motivation": "先前的方法要么将形状生成视为整体过程，要么只支持部分组合。我们的方法旨在解决这些问题，并且是第一个完全整合并强制执行对称性和部分先验的3D点云生成框架。", "method": "提出了四元扩散模型，包括全局形状潜变量、对称性、语义部件及其空间组装的学习，确保了结构的一致性与多样性。", "result": "实验表明该方法在保证对称性和一致性的基础上取得了最先进的性能。", "conclusion": "Quartet of Diffusions通过协调扩散模型成功生成高质量的点云数据，并实现了对形状属性的精细化控制。"}}
{"id": "2601.20422", "pdf": "https://arxiv.org/pdf/2601.20422", "abs": "https://arxiv.org/abs/2601.20422", "authors": ["Yumou Liu", "Zhenzhe Zheng", "Jiang Rong", "Yao Hu", "Fan Wu", "Guihai Chen"], "title": "Guiding the Recommender: Information-Aware Auto-Bidding for Content Promotion", "categories": ["cs.GT", "cs.AI"], "comment": "Accepted by SIGMETRICS 2026", "summary": "Modern content platforms offer paid promotion to mitigate cold start by allocating exposure via auctions. Our empirical analysis reveals a counterintuitive flaw in this paradigm: while promotion rescues low-to-medium quality content, it can harm high-quality content by forcing exposure to suboptimal audiences, polluting engagement signals and downgrading future recommendation. We recast content promotion as a dual-objective optimization that balances short-term value acquisition with long-term model improvement. To make this tractable at bid time in content promotion, we introduce a decomposable surrogate objective, gradient coverage, and establish its formal connection to Fisher Information and optimal experimental design. We design a two-stage auto-bidding algorithm based on Lagrange duality that dynamically paces budget through a shadow price and optimizes impression-level bids using per-impression marginal utilities. To address missing labels at bid time, we propose a confidence-gated gradient heuristic, paired with a zeroth-order variant for black-box models that reliably estimates learning signals in real time. We provide theoretical guarantees, proving monotone submodularity of the composite objective, sublinear regret in online auction, and budget feasibility. Extensive offline experiments on synthetic and real-world datasets validate the framework: it outperforms baselines, achieves superior final AUC/LogLoss, adheres closely to budget targets, and remains effective when gradients are approximated zeroth-order. These results show that strategic, information-aware promotion can improve long-term model performance and organic outcomes beyond naive impression-maximization strategies.", "AI": {"tldr": "本文提出了一种信息感知的自动出价算法，用于内容推广中的双重目标优化。", "motivation": "传统的内容平台通过拍卖分配曝光度来缓解冷启动问题。然而，这种做法可能导致高质内容被劣化处理，从而影响长期模型改进和推荐效果。", "method": "提出了一种基于拉格朗日对偶性的两阶段自动出价算法，并设计了一个可分解的替代目标函数——梯度覆盖率，确保预算合理分配并优化单次曝光投标。", "result": "实验表明该方法优于基线模型，在离线测试和实际数据集上均表现优异，实现了更好的AUC/LogLoss值，同时遵守了预算限制。", "conclusion": "通过信息感知的推广策略可以提高长期模型性能和有机推荐效果，超越简单的曝光最大化战略。"}}
{"id": "2601.20419", "pdf": "https://arxiv.org/pdf/2601.20419", "abs": "https://arxiv.org/abs/2601.20419", "authors": ["Yuhao Sun", "Chengyi Cai", "Jiacheng Zhang", "Zesheng Ye", "Xingliang Yuan", "Feng Liu"], "title": "Let's Roll a BiFTA: Bi-refinement for Fine-grained Text-visual Alignment in Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "25 pages", "summary": "Recent research has shown that aligning fine-grained text descriptions with localized image patches can significantly improve the zero-shot performance of pre-trained vision-language models (e.g., CLIP). However, we find that both fine-grained text descriptions and localized image patches often contain redundant information, making text-visual alignment less effective. In this paper, we tackle this issue from two perspectives: \\emph{View Refinement} and \\emph{Description refinement}, termed as \\textit{\\textbf{Bi}-refinement for \\textbf{F}ine-grained \\textbf{T}ext-visual \\textbf{A}lignment} (BiFTA). \\emph{View refinement} removes redundant image patches with high \\emph{Intersection over Union} (IoU) ratios, resulting in more distinctive visual samples. \\emph{Description refinement} removes redundant text descriptions with high pairwise cosine similarity, ensuring greater diversity in the remaining descriptions. BiFTA achieves superior zero-shot performance on 6 benchmark datasets for both ViT-based and ResNet-based CLIP, justifying the necessity to remove redundant information in visual-text alignment.", "AI": {"tldr": "本文提出了一种针对视觉语言模型的BiFTA方法，通过视图和描述双重精炼来改善细粒度文本与图像补丁之间的对齐效果。", "motivation": "现有研究表明，在预训练的视觉语言模型中，将细粒度的文本描述与局部化的图像块进行匹配可以显著提升零样本性能。然而，发现这些文本描述和图像块往往包含冗余信息，从而影响了对齐的有效性。", "method": "本文提出BiFTA方法，通过视图精炼去除重叠率高的图像补丁，并通过描述精炼减少高相似度的文本描述，以提高细粒度的视觉-文本匹配的效果。", "result": "实验结果表明，在基于ViT和ResNet的CLIP模型上，BiFTA在6个基准数据集上的零样本性能均优于基线方法。", "conclusion": "研究证实了去除冗余信息对改善视觉-文本对齐的重要性，并提出了一种有效的解决方案来提升预训练视觉语言模型的性能。"}}
{"id": "2601.20408", "pdf": "https://arxiv.org/pdf/2601.20408", "abs": "https://arxiv.org/abs/2601.20408", "authors": ["Nicholas Santavas", "Kareem Eissa", "Patrycja Cieplicka", "Piotr Florek", "Matteo Nulli", "Stefan Vasilev", "Seyyed Hadi Hashemi", "Antonios Gasteratos", "Shahram Khadivi"], "title": "Meeting SLOs, Slashing Hours: Automated Enterprise LLM Optimization with OptiKIT", "categories": ["cs.DC", "cs.AI"], "comment": "Accepted in MLSys 2026", "summary": "Enterprise LLM deployment faces a critical scalability challenge: organizations must optimize models systematically to scale AI initiatives within constrained compute budgets, yet the specialized expertise required for manual optimization remains a niche and scarce skillset. This challenge is particularly evident in managing GPU utilization across heterogeneous infrastructure while enabling teams with diverse workloads and limited LLM optimization experience to deploy models efficiently. We present OptiKIT, a distributed LLM optimization framework that democratizes model compression and tuning by automating complex optimization workflows for non-expert teams. OptiKIT provides dynamic resource allocation, staged pipeline execution with automatic cleanup, and seamless enterprise integration. In production, it delivers more than 2x GPU throughput improvement while empowering application teams to achieve consistent performance improvements without deep LLM optimization expertise. We share both the platform design and key engineering insights into resource allocation algorithms, pipeline orchestration, and integration patterns that enable large-scale, production-grade democratization of model optimization. Finally, we open-source the system to enable external contributions and broader reproducibility.", "AI": {"tldr": "OptiKIT是一个自动化的企业级大型语言模型优化框架，旨在通过自动化的复杂工作流来降低非专家团队部署大规模AI系统的门槛。", "motivation": "企业在部署大型语言模型时面临计算资源有限的挑战，需要对模型进行系统性优化以在异构基础设施上高效利用GPU。然而，这种优化所需的专门技能是稀缺且昂贵的。", "method": "OptiKIT通过动态资源配置、分阶段流水线执行和自动清理来自动化复杂的优化流程，并与企业现有系统无缝集成。", "result": "生产环境中，OptiKIT实现了超过2倍的GPU吞吐量提升，同时帮助应用程序团队在没有深度模型优化专业知识的情况下获得一致的性能改善。", "conclusion": "通过开源平台设计和关键工程洞察，OptiKIT为大规模、生产级别的模型优化民主化提供了可能。"}}
{"id": "2601.20404", "pdf": "https://arxiv.org/pdf/2601.20404", "abs": "https://arxiv.org/abs/2601.20404", "authors": ["Jai Lal Lulla", "Seyedmoein Mohsenimofidi", "Matthias Galster", "Jie M. Zhang", "Sebastian Baltes", "Christoph Treude"], "title": "On the Impact of AGENTS.md Files on the Efficiency of AI Coding Agents", "categories": ["cs.SE", "cs.AI", "cs.ET", "cs.HC"], "comment": "5 pages, 1 figure, 1 table", "summary": "AI coding agents such as Codex and Claude Code are increasingly used to autonomously contribute to software repositories. However, little is known about how repository-level configuration artifacts affect operational efficiency of the agents. In this paper, we study the impact of AGENTS$.$md files on the runtime and token consumption of AI coding agents operating on GitHub pull requests. We analyze 10 repositories and 124 pull requests, executing agents under two conditions: with and without an AGENTS$.$md file. We measure wall-clock execution time and token usage during agent execution. Our results show that the presence of AGENTS$.$md is associated with a lower median runtime ($Δ28.64$%) and reduced output token consumption ($Δ16.58$%), while maintaining a comparable task completion behavior. Based on these results, we discuss immediate implications for the configuration and deployment of AI coding agents in practice, and outline a broader research agenda on the role of repository-level instructions in shaping the behavior, efficiency, and integration of AI coding agents in software development workflows.", "AI": {"tldr": "研究AGENTS.md文件对AI编码代理在GitHub拉取请求中运行时效率的影响", "motivation": "探讨仓库级别配置文件如何影响AI编码代理的效率，特别是在时间和令牌消耗方面", "method": "选取10个代码库和124个拉取请求，在有无AGENTS.md文件的情况下分别测试AI编码代理在执行任务时的时间和令牌使用情况", "result": "发现存在AGENTS.md文件时，AI编码代理的运行时间降低（下降28.64%）且输出令牌消耗减少（下降16.58%），同时保持相似的任务完成行为", "conclusion": "基于实验结果，建议在实践中配置和部署AI编码代理时考虑使用AGENTS.md文件，并探讨未来关于仓库级别指令对AI编码代理的行为、效率及集成的研究方向"}}
{"id": "2601.20402", "pdf": "https://arxiv.org/pdf/2601.20402", "abs": "https://arxiv.org/abs/2601.20402", "authors": ["Ananya Shukla", "Chaitanya Modi", "Satvik Bajpai", "Siddharth Siddharth"], "title": "GuideAI: A Real-time Personalized Learning Solution with Adaptive Interventions", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted for publication at the 31st International Conference on Intelligent User Interfaces (IUI 2026)", "summary": "Large Language Models (LLMs) have emerged as powerful learning tools, but they lack awareness of learners' cognitive and physiological states, limiting their adaptability to the user's learning style. Contemporary learning techniques primarily focus on structured learning paths, knowledge tracing, and generic adaptive testing but fail to address real-time learning challenges driven by cognitive load, attention fluctuations, and engagement levels. Building on findings from a formative user study (N=66), we introduce GuideAI, a multi-modal framework that enhances LLM-driven learning by integrating real-time biosensory feedback including eye gaze tracking, heart rate variability, posture detection, and digital note-taking behavior. GuideAI dynamically adapts learning content and pacing through cognitive optimizations (adjusting complexity based on learning progress markers), physiological interventions (breathing guidance and posture correction), and attention-aware strategies (redirecting focus using gaze analysis). Additionally, GuideAI supports diverse learning modalities, including text-based, image-based, audio-based, and video-based instruction, across varied knowledge domains. A preliminary study (N = 25) assessed GuideAI's impact on knowledge retention and cognitive load through standardized assessments. The results show statistically significant improvements in both problem-solving capability and recall-based knowledge assessments. Participants also experienced notable reductions in key NASA-TLX measures including mental demand, frustration levels, and effort, while simultaneously reporting enhanced perceived performance. These findings demonstrate GuideAI's potential to bridge the gap between current LLM-based learning systems and individualized learner needs, paving the way for adaptive, cognition-aware education at scale.", "AI": {"tldr": "介绍GuideAI，一个通过实时生物传感反馈优化大型语言模型驱动学习的多模态框架。", "motivation": "现有学习方法忽视了用户的认知和生理状态，无法适应个体的学习方式。为解决这一问题，提出GuideAI，结合多种传感器数据进行个性化学习。", "method": "基于初步用户研究（N=66），开发了一个集成了眼动追踪、心率变异性等生物传感反馈的多模态框架GuideAI，并通过认知优化、生理干预和注意力策略实现动态适应性调整。", "result": "一项初步评估研究显示，使用GuideAI后参与者在知识保留能力和认知负荷方面表现出显著改善。同时，他们的感知性能也得到提升，报告了更少的心理需求和努力水平。", "conclusion": "结果表明，GuideAI能有效弥补现有大型语言模型学习系统的不足，实现个性化教育，为大规模的适应性、认知意识教育铺平道路。"}}
{"id": "2601.20397", "pdf": "https://arxiv.org/pdf/2601.20397", "abs": "https://arxiv.org/abs/2601.20397", "authors": ["Kaile Wang", "Jiannong Cao", "Yu Yang", "Xiaoyin Li", "Mingjin Zhang"], "title": "FedRD: Reducing Divergences for Generalized Federated Learning via Heterogeneity-aware Parameter Guidance", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICASSP 2026", "summary": "Heterogeneous federated learning (HFL) aims to ensure effective and privacy-preserving collaboration among different entities. As newly joined clients require significant adjustments and additional training to align with the existing system, the problem of generalizing federated learning models to unseen clients under heterogeneous data has become progressively crucial. Consequently, we highlight two unsolved challenging issues in federated domain generalization: Optimization Divergence and Performance Divergence. To tackle the above challenges, we propose FedRD, a novel heterogeneity-aware federated learning algorithm that collaboratively utilizes parameter-guided global generalization aggregation and local debiased classification to reduce divergences, aiming to obtain an optimal global model for participating and unseen clients. Extensive experiments on public multi-domain datasets demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.", "AI": {"tldr": "本文提出了FedRD算法，旨在解决联邦学习中由于数据异质性导致的优化偏差和性能偏差问题。", "motivation": "在联邦学习中，新加入的客户端需要与现有系统进行大量调整和额外训练，这使得将模型泛化到未见客户端变得更加困难。因此，本文致力于减少这种差异带来的挑战，以提高模型的通用性和适应性。", "method": "FedRD算法通过参数引导全局聚合和本地去偏分类来降低偏差，从而获得更优的全局模型。", "result": "实验表明，与现有基线方法相比，FedRD在多域数据集上的性能优势显著。", "conclusion": "本文提出的方法成功地解决了联邦学习中的优化差异和性能差异问题，为解决异质性带来的挑战提供了一种新的思路。"}}
{"id": "2601.20383", "pdf": "https://arxiv.org/pdf/2601.20383", "abs": "https://arxiv.org/abs/2601.20383", "authors": ["Mengge Liu", "Yan Di", "Gu Wang", "Yun Qu", "Dekai Zhu", "Yanyan Li", "Xiangyang Ji"], "title": "HINT: Hierarchical Interaction Modeling for Autoregressive Multi-Human Motion Generation", "categories": ["cs.CV"], "comment": null, "summary": "Text-driven multi-human motion generation with complex interactions remains a challenging problem. Despite progress in performance, existing offline methods that generate fixed-length motions with a fixed number of agents, are inherently limited in handling long or variable text, and varying agent counts. These limitations naturally encourage autoregressive formulations, which predict future motions step by step conditioned on all past trajectories and current text guidance. In this work, we introduce HINT, the first autoregressive framework for multi-human motion generation with Hierarchical INTeraction modeling in diffusion. First, HINT leverages a disentangled motion representation within a canonicalized latent space, decoupling local motion semantics from inter-person interactions. This design facilitates direct adaptation to varying numbers of human participants without requiring additional refinement. Second, HINT adopts a sliding-window strategy for efficient online generation, and aggregates local within-window and global cross-window conditions to capture past human history, inter-person dependencies, and align with text guidance. This strategy not only enables fine-grained interaction modeling within each window but also preserves long-horizon coherence across all the long sequence. Extensive experiments on public benchmarks demonstrate that HINT matches the performance of strong offline models and surpasses autoregressive baselines. Notably, on InterHuman, HINT achieves an FID of 3.100, significantly improving over the previous state-of-the-art score of 5.154.", "AI": {"tldr": "提出了一种自回归框架HINT，用于多个人体运动生成，并采用分层交互建模方法。", "motivation": "现有的离线方法在处理复杂互动和文本驱动的多人动作生成时存在限制，尤其是在应对长或可变长度的文本以及变化的人数方面。因此，需要一种新的自回归方法来解决这些问题。", "method": "HINT利用一个解耦合的动作表示方式，在正则化隐空间中区分局部运动语义和人际互动，并采用滑动窗口策略进行在线生成，从而更好地捕捉过去的历史、人与人的依赖关系以及文本引导。这使得框架能够适应不同的参与者数量并且在长序列上保持连贯性。", "result": "实验结果显示，HINT在公共基准测试中的表现可以媲美强大的离线模型，在某些情况下还超过了自回归基线。特别是在InterHuman数据集上，HINT的FID值达到了3.100，显著优于先前的最佳成绩5.154。", "conclusion": "通过引入分层交互建模和滑动窗口策略，HINT成功解决了多个人体运动生成中的复杂互动问题，并且在多个公开基准测试中展示了优越的表现。"}}
{"id": "2601.20381", "pdf": "https://arxiv.org/pdf/2601.20381", "abs": "https://arxiv.org/abs/2601.20381", "authors": ["Alexandre Chapin", "Emmanuel Dellandréa", "Liming Chen"], "title": "STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Visual foundation models provide strong perceptual features for robotics, but their dense representations lack explicit object-level structure, limiting robustness and contractility in manipulation tasks. We propose STORM (Slot-based Task-aware Object-centric Representation for robotic Manipulation), a lightweight object-centric adaptation module that augments frozen visual foundation models with a small set of semantic-aware slots for robotic manipulation. Rather than retraining large backbones, STORM employs a multi-phase training strategy: object-centric slots are first stabilized through visual--semantic pretraining using language embeddings, then jointly adapted with a downstream manipulation policy. This staged learning prevents degenerate slot formation and preserves semantic consistency while aligning perception with task objectives. Experiments on object discovery benchmarks and simulated manipulation tasks show that STORM improves generalization to visual distractors, and control performance compared to directly using frozen foundation model features or training object-centric representations end-to-end. Our results highlight multi-phase adaptation as an efficient mechanism for transforming generic foundation model features into task-aware object-centric representations for robotic control.", "AI": {"tldr": "提出STORM模块，用于增强视觉基础模型在机器人抓取任务中的表现。", "motivation": "现有视觉基础模型的密集表示缺乏明确的对象结构，影响了机器人的稳健性和适应性。", "method": "通过多阶段训练策略，在冻结的基础模型上增加语义感知槽来生成对象中心表示。首先通过视觉-语义预训练稳定物体槽，然后与下游抓取策略联合优化。", "result": "实验证明STORM在处理视觉干扰和控制性能方面优于直接使用冻结的特征或端到端训练的方法。", "conclusion": "多阶段适应机制可以有效将基础模型转换为任务感知的对象中心表示，适用于机器人操作。"}}
{"id": "2601.20380", "pdf": "https://arxiv.org/pdf/2601.20380", "abs": "https://arxiv.org/abs/2601.20380", "authors": ["Le Zhang", "Yixiong Xiao", "Xinjiang Lu", "Jingjia Cao", "Yusai Zhao", "Jingbo Zhou", "Lang An", "Zikan Feng", "Wanxiang Sha", "Yu Shi", "Congxi Xiao", "Jian Xiong", "Yankai Zhang", "Hua Wu", "Haifeng Wang"], "title": "OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution", "categories": ["cs.AI"], "comment": null, "summary": "Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on both mobile and desktop platforms, supporting computer-use and phone-use scenarios. Building an effective GUI agent model relies on two factors: (1) high-quality data and (2) effective training methods. To address these, we introduce a carefully engineered data-construction pipeline and a decoupled training paradigm. For data construction, we leverage rigorously curated open-source datasets and introduce a novel automated synthesis framework that integrates bottom-up autonomous exploration with top-down taxonomy-guided generation to create high-fidelity synthetic data. For training, to better leverage these data, we adopt a two-stage strategy: Supervised Fine-Tuning (SFT) to establish fundamental interaction syntax, followed by Group Relative Policy Optimization (GRPO) to improve spatial grounding and sequential planning. To balance computational efficiency with agentic reasoning capacity, OmegaUse is built on a Mixture-of-Experts (MoE) backbone. To evaluate cross-terminal capabilities in an offline setting, we introduce OS-Nav, a benchmark suite spanning multiple operating systems: ChiM-Nav, targeting Chinese Android mobile environments, and Ubu-Nav, focusing on routine desktop interactions on Ubuntu. Extensive experiments show that OmegaUse is highly competitive across established GUI benchmarks, achieving a state-of-the-art (SOTA) score of 96.3% on ScreenSpot-V2 and a leading 79.1% step success rate on AndroidControl. OmegaUse also performs strongly on OS-Nav, reaching 74.24% step success on ChiM-Nav and 55.9% average success on Ubu-Nav.", "AI": {"tldr": "构建一个适用于自主任务执行的通用GUI代理模型OmegaUse，以提高人机交互和生产力。", "motivation": "图形用户界面（GUI）代理能够使基础模型完成现实世界中的任务，通过变革人机互动方式来提升人类效率。为了实现这一点，需要高质量的数据集以及有效的训练方法。", "method": "提出了一种精心设计的数据构造流水线和解耦的训练范式。数据构建方面采用严格筛选的开源数据集，并引入一种结合自下而上自主探索与自顶向下分类指导生成的新颖自动合成框架来创建高保真模拟数据。对于训练，使用两阶段策略：监督微调（SFT）以建立基本交互语法，随后是组相对政策优化（GRPO），提高空间定位和序列规划。", "result": "在离线设置下引入OS-Nav基准套件评估跨终端能力，该套件覆盖多个操作系统。实验显示OmegaUse在公认的GUI基准上表现出色，在ScreenSpot-V2中获得96.3%的SOTA得分，并且在AndroidControl中达到79.1%的成功步骤率。", "conclusion": "通过精细的数据构造和有效的训练方法，构建了能够自主执行任务并具有广泛适用性的通用GUI代理模型OmegaUse。"}}
{"id": "2601.20379", "pdf": "https://arxiv.org/pdf/2601.20379", "abs": "https://arxiv.org/abs/2601.20379", "authors": ["Zhengbo Jiao", "Hongyu Xian", "Qinglong Wang", "Yunpu Ma", "Zhebo Wang", "Zifan Zhang", "Dezhang Kong", "Meng Han"], "title": "Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution", "categories": ["cs.AI"], "comment": "19 pages, 5 figures", "summary": "Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of \"conjectures and refutations,\" we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.", "AI": {"tldr": "本文提出了Policy of Thoughts框架，通过实时策略演化来提升大型语言模型在复杂推理任务中的性能。", "motivation": "现有测试时间扩展方法未能将执行反馈内化为改进底层推理策略的一部分。作者认为智能需要从失败尝试中学习并动态调整策略。", "method": "PoT使用一种高效的探索机制生成多样的候选解决方案，并利用组相对政策优化来根据执行反馈更新临时LoRA适配器，实现闭环设计。", "result": "实验表明，一个4B模型在LiveCodeBench上的准确率达到了49.71%，超过了GPT-4o和DeepSeek-V3，尽管其规模小了50多倍。", "conclusion": "PoT框架通过动态、实例特定的推理先验优化，显著提升了大型语言模型的性能。"}}
{"id": "2601.20377", "pdf": "https://arxiv.org/pdf/2601.20377", "abs": "https://arxiv.org/abs/2601.20377", "authors": ["Xinyan Chen", "Qinchun Li", "Ruiqin Ma", "Jiaqi Bai", "Li Yi", "Jianfei Yang"], "title": "RF-MatID: Dataset and Benchmark for Radio Frequency Material Identification", "categories": ["cs.RO", "eess.SP"], "comment": "Accepted by ICLR 2026", "summary": "Accurate material identification plays a crucial role in embodied AI systems, enabling a wide range of applications. However, current vision-based solutions are limited by the inherent constraints of optical sensors, while radio-frequency (RF) approaches, which can reveal intrinsic material properties, have received growing attention. Despite this progress, RF-based material identification remains hindered by the lack of large-scale public datasets and the limited benchmarking of learning-based approaches. In this work, we present RF-MatID, the first open-source, large-scale, wide-band, and geometry-diverse RF dataset for fine-grained material identification. RF-MatID includes 16 fine-grained categories grouped into 5 superclasses, spanning a broad frequency range from 4 to 43.5 GHz, and comprises 142k samples in both frequency- and time-domain representations. The dataset systematically incorporates controlled geometry perturbations, including variations in incidence angle and stand-off distance. We further establish a multi-setting, multi-protocol benchmark by evaluating state-of-the-art deep learning models, assessing both in-distribution performance and out-of-distribution robustness under cross-angle and cross-distance shifts. The 5 frequency-allocation protocols enable systematic frequency- and region-level analysis, thereby facilitating real-world deployment. RF-MatID aims to enable reproducible research, accelerate algorithmic advancement, foster cross-domain robustness, and support the development of real-world application in RF-based material identification.", "AI": {"tldr": "RF-MatID是一个用于无线电频率材料识别的大规模开放数据集和基准，旨在推动基于射频的材料识别研究。", "motivation": "目前基于视觉的方法在材料识别上受到光学传感器限制，而基于射频的方法可以揭示材料内在属性但缺乏大规模公开的数据集和学习方法评估。为此，提出了RF-MatID来解决这些问题。", "method": "创建了一个包含16个细粒度类别的数据集，并包括了不同几何变化的样本，如入射角和距离的变化。通过多协议基准测试现有的深度学习模型以评价其性能。", "result": "该数据集支持频率-区域水平分析，并有助于真实世界的部署。", "conclusion": "RF-MatID为基于射频材料识别的研究提供了可重复性和加速算法进步的机会，同时也促进了跨领域鲁棒性的研究。"}}
{"id": "2601.20375", "pdf": "https://arxiv.org/pdf/2601.20375", "abs": "https://arxiv.org/abs/2601.20375", "authors": ["Wei Huang", "Anda Cheng", "Yinggui Wang", "Lei Wang", "Tao Wei"], "title": "LLM-AutoDP: Automatic Data Processing via LLM Agents for Model Fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by VLDB2026", "summary": "Large Language Models (LLMs) can be fine-tuned on domain-specific data to enhance their performance in specialized fields. However, such data often contains numerous low-quality samples, necessitating effective data processing (DP). In practice, DP strategies are typically developed through iterative manual analysis and trial-and-error adjustment. These processes inevitably incur high labor costs and may lead to privacy issues in high-privacy domains like healthcare due to direct human access to sensitive data. Thus, achieving automated data processing without exposing the raw data has become a critical challenge. To address this challenge, we propose LLM-AutoDP, a novel framework that leverages LLMs as agents to automatically generate and optimize data processing strategies. Our method generates multiple candidate strategies and iteratively refines them using feedback signals and comparative evaluations. This iterative in-context learning mechanism enables the agent to converge toward high-quality processing pipelines without requiring direct human intervention or access to the underlying data. To further accelerate strategy search, we introduce three key techniques: Distribution Preserving Sampling, which reduces data volume while maintaining distributional integrity; Processing Target Selection, which uses a binary classifier to identify low-quality samples for focused processing; Cache-and-Reuse Mechanism}, which minimizes redundant computations by reusing prior processing results. Results show that models trained on data processed by our framework achieve over 80% win rates against models trained on unprocessed data. Compared to AutoML baselines based on LLM agents, LLM-AutoDP achieves approximately a 65% win rate. Moreover, our acceleration techniques reduce the total searching time by up to 10 times, demonstrating both effectiveness and efficiency.", "AI": {"tldr": "LLM-AutoDP 是一种利用大型语言模型作为代理自动生成和优化数据处理策略的框架，旨在提高领域特定数据的高质量样本比例。", "motivation": "在对大模型进行微调时，领域特定的数据中往往包含大量低质量样本，传统的手动数据处理方法耗时且可能引发隐私问题。为了减少人力成本并保护敏感信息，提出了一种自动化的数据处理解决方案。", "method": "LLM-AutoDP 利用大型语言模型作为代理生成和优化数据处理策略，并通过反馈信号进行迭代改进。此框架采用了分布保持采样、处理目标选择以及缓存与重用机制以提高效率。", "result": "实验结果表明，经过 LLM-AutoDP 处理的数据训练出的模型相比未经处理的数据有超过80%的优势；相较于基于大型语言模型代理的自动机器学习基线方法，LLM-AutoDP 的优势为约65%。此外，加速技术将搜索时间减少了最多10倍。", "conclusion": "通过使用 LLM-AutoDP 框架可以有效地提高数据处理的质量和效率，并且在保护隐私的同时显著减少人力成本。"}}
{"id": "2601.20369", "pdf": "https://arxiv.org/pdf/2601.20369", "abs": "https://arxiv.org/abs/2601.20369", "authors": ["Mas Nurul Achmadiah", "Chi-Chia Sun", "Wen-Kai Kuo", "Jun-Wei Hsieh"], "title": "RepSFNet : A Single Fusion Network with Structural Reparameterization for Crowd Counting", "categories": ["cs.CV"], "comment": "6 pages. Published in Proceedings of the IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS) 2025", "summary": "Crowd counting remains challenging in variable-density scenes due to scale variations, occlusions, and the high computational cost of existing models. To address these issues, we propose RepSFNet (Reparameterized Single Fusion Network), a lightweight architecture designed for accurate and real-time crowd estimation. RepSFNet leverages a RepLK-ViT backbone with large reparameterized kernels for efficient multi-scale feature extraction. It further integrates a Feature Fusion module combining Atrous Spatial Pyramid Pooling (ASPP) and Context-Aware Network (CAN) to achieve robust, density-adaptive context modeling. A Concatenate Fusion module is employed to preserve spatial resolution and generate high-quality density maps. By avoiding attention mechanisms and multi-branch designs, RepSFNet significantly reduces parameters and computational complexity. The training objective combines Mean Squared Error and Optimal Transport loss to improve both count accuracy and spatial distribution alignment. Experiments conducted on ShanghaiTech, NWPU, and UCF-QNRF datasets demonstrate that RepSFNet achieves competitive accuracy while reducing inference latency by up to 34 percent compared to recent state-of-the-art methods, making it suitable for real-time and low-power edge computing applications.", "AI": {"tldr": "提出RepSFNet模型，用于更准确和实时的人群计数。", "motivation": "解决人群密度变化、遮挡以及现有模型计算成本高的问题，以实现高效且精确的人群计数。", "method": "引入Reparameterized Single Fusion Network（RepSFNet），采用RepLK-ViT骨干网络结合ASPP和CAN进行特征融合，并使用Concatenate Fusion模块保持空间分辨率。训练目标为MSE与最优传输损失的组合。", "result": "在ShanghaiTech，NWPU及UCF-QNRF数据集上表现良好，较近期SOTA方法减少最多34%的推断延迟。", "conclusion": "RepSFNet通过高效多尺度特征提取和融合技术，在保证精度的同时显著降低计算复杂度，适合实时与低功耗边缘计算应用。"}}
{"id": "2601.20366", "pdf": "https://arxiv.org/pdf/2601.20366", "abs": "https://arxiv.org/abs/2601.20366", "authors": ["Abdul Hasib", "A. S. M. Ahsanul Sarkar Akib", "Nihal Das Ankur", "Anish Giri"], "title": "Dual-Modality IoT Framework for Integrated Access Control and Environmental Safety Monitoring with Real-Time Cloud Analytics", "categories": ["cs.CV"], "comment": null, "summary": "The integration of physical security systems with environmental safety monitoring represents a critical advancement in smart infrastructure management. Traditional approaches maintain these systems as independent silos, creating operational inefficiencies, delayed emergency responses, and increased management complexity. This paper presents a comprehensive dual-modality Internet of Things framework that seamlessly integrates RFID-based access control with multi-sensor environmental safety monitoring through a unified cloud architecture. The system comprises two coordinated subsystems: Subsystem 1 implements RFID authentication with servo-actuated gate control and real-time Google Sheets logging, while Subsystem 2 provides comprehensive safety monitoring incorporating flame detection, water flow measurement, LCD status display, and personnel identification. Both subsystems utilize ESP32 microcontrollers for edge processing and wireless connectivity. Experimental evaluation over 45 days demonstrates exceptional performance metrics: 99.2\\% RFID authentication accuracy with 0.82-second average response time, 98.5\\% flame detection reliability within 5-meter range, and 99.8\\% cloud data logging success rate. The system maintains operational integrity during network disruptions through intelligent local caching mechanisms and achieves total implementation cost of 5,400 BDT (approximately \\$48), representing an 82\\% reduction compared to commercial integrated solutions. This research establishes a practical framework for synergistic security-safety integration, demonstrating that professional-grade performance can be achieved through careful architectural design and component optimization while maintaining exceptional cost-effectiveness and accessibility for diverse application scenarios.", "AI": {"tldr": "本文提出了一种基于RFID和多传感器的双模物联网框架，用于集成访问控制和环境安全监测，并通过统一的云架构实现实时数据分析。", "motivation": "传统物理安全系统与环境监控系统的独立操作导致了运营低效、应急响应延迟以及管理复杂性增加。本文旨在将这两种系统无缝结合，提高智能基础设施管理水平。", "method": "该框架包括两个子系统：一个基于RFID的身份验证和伺服门控制，另一个是全面的安全监测，涵盖火焰检测、水流测量、LCD状态显示及人员识别。所有子系统使用ESP32微控制器进行边缘处理和无线通信，并通过Google Sheets实现实时云日志记录。", "result": "实验结果显示：99.2%的RFID认证准确性，平均响应时间0.82秒；火焰检测可靠率在5米范围内达到98.5%；云数据记录成功率为99.8%。系统在网络中断时通过智能本地缓存机制保持操作完整性，并且总实施成本为5400 BDT（约48美元），比商业集成解决方案降低82%。", "conclusion": "本文提出的框架展示了通过精心的架构设计和组件优化，可以在降低成本的同时实现专业级别的性能和广泛的适用性。"}}
{"id": "2601.20364", "pdf": "https://arxiv.org/pdf/2601.20364", "abs": "https://arxiv.org/abs/2601.20364", "authors": ["Zhen Liu", "Diedong Feng", "Hai Jiang", "Liaoyuan Zeng", "Hao Wang", "Chaoyu Feng", "Lei Lei", "Bing Zeng", "Shuaicheng Liu"], "title": "RAW-Flow: Advancing RGB-to-RAW Image Reconstruction with Deterministic Latent Flow Matching", "categories": ["cs.CV"], "comment": "AAAI2026 Oral", "summary": "RGB-to-RAW reconstruction, or the reverse modeling of a camera Image Signal Processing (ISP) pipeline, aims to recover high-fidelity RAW data from RGB images. Despite notable progress, existing learning-based methods typically treat this task as a direct regression objective and struggle with detail inconsistency and color deviation, due to the ill-posed nature of inverse ISP and the inherent information loss in quantized RGB images. To address these limitations, we pioneer a generative perspective by reformulating RGB-to-RAW reconstruction as a deterministic latent transport problem and introduce a novel framework named RAW-Flow, which leverages flow matching to learn a deterministic vector field in latent space, to effectively bridge the gap between RGB and RAW representations and enable accurate reconstruction of structural details and color information. To further enhance latent transport, we introduce a cross-scale context guidance module that injects hierarchical RGB features into the flow estimation process. Moreover, we design a dual-domain latent autoencoder with a feature alignment constraint to support the proposed latent transport framework, which jointly encodes RGB and RAW inputs while promoting stable training and high-fidelity reconstruction. Extensive experiments demonstrate that RAW-Flow outperforms state-of-the-art approaches both quantitatively and visually.", "AI": {"tldr": "本文提出了一种新的RGB到RAW图像重建框架RAW-Flow，通过生成式视角将任务重构为确定性的潜在传输问题。", "motivation": "现有学习方法在RGB到RAW重建中面临细节不一致和颜色偏差的问题，这是由于逆ISP的病态性质及量化RGB图像中的固有信息损失导致的。", "method": "本文采用流匹配技术学习潜在空间中的确定性向量场，并引入跨尺度上下文引导模块以增强潜在传输。设计了一个双域潜在自动编码器来支持提出的框架，该自动编码器通过特征对齐约束促进稳定训练和高保真重建。", "result": "实验表明，RAW-Flow在定量和视觉效果上均优于现有最佳方法。", "conclusion": "通过引入确定性流匹配技术及双域潜在自动编码器，本文有效解决了RGB到RAW图像重建中的细节不一致和颜色偏差问题。"}}
{"id": "2601.20363", "pdf": "https://arxiv.org/pdf/2601.20363", "abs": "https://arxiv.org/abs/2601.20363", "authors": ["Mariia Drozdova"], "title": "Can Continuous-Time Diffusion Models Generate and Solve Globally Constrained Discrete Problems? A Study on Sudoku", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 5 figures. Empirical study of continuous-time diffusion and flow models on Sudoku. Code available at https://github.com/MariiaDrozdova/sudoku_generation", "summary": "Can standard continuous-time generative models represent distributions whose support is an extremely sparse, globally constrained discrete set? We study this question using completed Sudoku grids as a controlled testbed, treating them as a subset of a continuous relaxation space. We train flow-matching and score-based models along a Gaussian probability path and compare deterministic (ODE) sampling, stochastic (SDE) sampling, and DDPM-style discretizations derived from the same continuous-time training. Unconditionally, stochastic sampling substantially outperforms deterministic flows; score-based samplers are the most reliable among continuous-time methods, and DDPM-style ancestral sampling achieves the highest validity overall. We further show that the same models can be repurposed for guided generation: by repeatedly sampling completions under clamped clues and stopping when constraints are satisfied, the model acts as a probabilistic Sudoku solver. Although far less sample-efficient than classical solvers and discrete-geometry-aware diffusion methods, these experiments demonstrate that classic diffusion/flow formulations can assign non-zero probability mass to globally constrained combinatorial structures and can be used for constraint satisfaction via stochastic search.", "AI": {"tldr": "本文研究了连续时间生成模型是否能够表示具有全局约束的离散分布，通过Sudoku数独作为测试平台进行验证。", "motivation": "探讨标准连续时间生成模型能否表示支持极稀疏、全局受限离散集合的概率分布。", "method": "使用流动匹配和评分基于模型，并沿高斯概率路径训练。比较确定性（ODE）采样，随机（SDE）采样以及从相同连续时间训练中导出的DDPM风格离散化。", "result": "无条件情况下，随机采样显著优于确定性流；评分基线采样器是最可靠的连续时间方法；而DDPM样式祖先采样实现了最高的有效性。这些模型还可用于指导生成：通过反复在固定线索下抽样完成并停止当满足约束时，模型可用作概率Sudoku求解器。", "conclusion": "尽管不如经典求解器和离散几何感知扩散方式样本效率高，但实验表明经典扩散/流动公式可以将非零概率质量分配给全局受限组合结构，并可通过随机搜索用于约束满足。"}}
{"id": "2601.20362", "pdf": "https://arxiv.org/pdf/2601.20362", "abs": "https://arxiv.org/abs/2601.20362", "authors": ["Xiangbo Wang", "Wenbin Jiang", "Jin Wang", "Yubo You", "Sheng Fang", "Fei Wen"], "title": "Switchcodec: Adaptive residual-expert sparse quantization for high-fidelity neural audio coding", "categories": ["cs.SD", "cs.AI"], "comment": "4page,3figure,Accepted by ICASSP 2026,We would like to express our sincere gratitude to Senior Fellow Jing Wang for his continuous support and assistance. He has made an indelible and significant contribution to this work", "summary": "Recent neural audio compression models often rely on residual vector quantization for high-fidelity coding, but using a fixed number of per-frame codebooks is suboptimal for the wide variability of audio content-especially for signals that are either very simple or highly complex. To address this limitation, we propose SwitchCodec, a neural audio codec based on Residual Experts Vector Quantization (REVQ). REVQ combines a shared quantizer with dynamically routed expert quantizers that are activated according to the input audio, decoupling bitrate from codebook capacity and improving compression efficiency. This design ensures full training and utilization of each quantizer. In addition, a variable-bitrate mechanism adjusts the number of active expert quantizers at inference, enabling multi-bitrate operation without retraining. Experiments demonstrate that SwitchCodec surpasses existing baselines on both objective metrics and subjective listening tests.", "AI": {"tldr": "SwitchCodec是一种基于残差专家向量量化（REVQ）的神经音频编解码器，旨在通过自适应量化提高高保真音频压缩效率。", "motivation": "传统音频压缩模型使用固定数量的每帧代码本进行残差向量量化，对于复杂度变化大的音频内容不够高效，特别是简单或复杂的信号。为了改进这一问题，提出SwitchCodec来优化压缩性能和比特率利用。", "method": "REVQ结合了共享量化器与动态激活的专家量化器，并通过可变比特率机制在推断时调整活跃量化器的数量，实现多比特率操作而无需重新训练模型。", "result": "实验表明，SwitchCodec在客观指标和主观听觉测试中均优于现有基线方法。", "conclusion": "SwitchCodec提供了一种提高音频压缩效率的新途径，并且通过灵活的编码策略有效提升了高保真音频的编码质量。"}}
{"id": "2601.20355", "pdf": "https://arxiv.org/pdf/2601.20355", "abs": "https://arxiv.org/abs/2601.20355", "authors": ["Yue Liang", "Jiatong Du", "Ziyi Yang", "Yanjun Huang", "Hong Chen"], "title": "CURVE: Learning Causality-Inspired Invariant Representations for Robust Scene Understanding via Uncertainty-Guided Regularization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Scene graphs provide structured abstractions for scene understanding, yet they often overfit to spurious correlations, severely hindering out-of-distribution generalization. To address this limitation, we propose CURVE, a causality-inspired framework that integrates variational uncertainty modeling with uncertainty-guided structural regularization to suppress high-variance, environment-specific relations. Specifically, we apply prototype-conditioned debiasing to disentangle invariant interaction dynamics from environment-dependent variations, promoting a sparse and domain-stable topology. Empirically, we evaluate CURVE in zero-shot transfer and low-data sim-to-real adaptation, verifying its ability to learn domain-stable sparse topologies and provide reliable uncertainty estimates to support risk prediction under distribution shifts.", "AI": {"tldr": "提出CURVE框架，通过不确定性引导的正则化学习因果性启发的不变表示，提高场景图的理解能力。", "motivation": "现有场景理解方法常因过拟合而产生虚假关联，影响泛化性能。本研究旨在解决这一问题，提升在不同分布下的鲁棒性和稳定性。", "method": "结合变分不确定性建模和结构正则化，利用原型条件去偏移策略区分环境无关的交互动态与环境依赖的变化，促进稀疏稳定拓扑结构的学习。", "result": "CURVE框架能够在零样本迁移和低数据仿真到真实环境中表现出色，验证其学习领域稳定的稀疏拓扑并提供可靠不确定性估计的能力。", "conclusion": "通过因果性启发的方法，CURVE成功提高了场景理解的泛化能力和鲁棒性，为实际应用提供了有效支持。"}}
{"id": "2601.20354", "pdf": "https://arxiv.org/pdf/2601.20354", "abs": "https://arxiv.org/abs/2601.20354", "authors": ["Zengbin Wang", "Xuecai Hu", "Yong Wang", "Feng Xiong", "Man Zhang", "Xiangxiang Chu"], "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026, URL: https://github.com/AMAP-ML/SpatialGenEval", "summary": "Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handling complex spatial relationships, e.g., spatial perception, reasoning, or interaction. These critical aspects are largely overlooked by current benchmarks due to their short or information-sparse prompt design. In this paper, we introduce SpatialGenEval, a new benchmark designed to systematically evaluate the spatial intelligence of T2I models, covering two key aspects: (1) SpatialGenEval involves 1,230 long, information-dense prompts across 25 real-world scenes. Each prompt integrates 10 spatial sub-domains and corresponding 10 multi-choice question-answer pairs, ranging from object position and layout to occlusion and causality. Our extensive evaluation of 21 state-of-the-art models reveals that higher-order spatial reasoning remains a primary bottleneck. (2) To demonstrate that the utility of our information-dense design goes beyond simple evaluation, we also construct the SpatialT2I dataset. It contains 15,400 text-image pairs with rewritten prompts to ensure image consistency while preserving information density. Fine-tuned results on current foundation models (i.e., Stable Diffusion-XL, Uniworld-V1, OmniGen2) yield consistent performance gains (+4.2%, +5.7%, +4.4%) and more realistic effects in spatial relations, highlighting a data-centric paradigm to achieve spatial intelligence in T2I models.", "AI": {"tldr": "本文介绍了SpatialGenEval，一个评估文本到图像模型空间智能的新基准，并展示了信息密集型设计的实用性。", "motivation": "当前文本到图像模型在处理复杂的空间关系时表现不佳，现有基准测试因为短或信息稀疏的提示设计而无法全面检测这些问题。因此，本文引入了一个新的基准来解决这一不足。", "method": "SpatialGenEval包括1230个长且信息密集型的提示语，涵盖25种现实场景，并对21种最先进的模型进行评估；构建了SpatialT2I数据集以展示该设计的价值。", "result": "研究揭示了高层次的空间推理仍然是一个主要瓶颈；在SpatialT2I数据集上，当前基础模型经过微调后表现有所提高（+4.2%至+5.7%），空间关系更真实。", "conclusion": "本文通过新基准和数据集强调了信息密集型设计的重要性，并展示了这种设计能提升文本到图像模型的空间智能。"}}
{"id": "2601.20352", "pdf": "https://arxiv.org/pdf/2601.20352", "abs": "https://arxiv.org/abs/2601.20352", "authors": ["Weiquan Huang", "Zixuan Wang", "Hehai Lin", "Sudong Wang", "Bo Xu", "Qian Li", "Beier Zhu", "Linyi Yang", "Chengwei Qin"], "title": "AMA: Adaptive Memory via Multi-Agent Collaboration", "categories": ["cs.AI"], "comment": "8 pages", "summary": "The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.", "AI": {"tldr": "提出一种新的框架AMA，利用多代理协作管理跨多个粒度的记忆系统，以解决现有记忆系统的局限性。", "motivation": "为了解决现有记忆系统在存储信息与任务特定推理需求之间的持久不匹配以及逻辑矛盾不断累积的问题。", "method": "采用层次化记忆设计，通过Constructor和Retriever实现多粒度记忆构建和自适应查询路由，并由Judge验证检索内容的相关性和一致性。当证据不足或检测到逻辑冲突时，触发迭代检索或调用Refresher进行内存一致性的强制执行。", "result": "在挑战性的长上下文基准测试中，AMA显著优于最先进的基线方法，并将令牌消耗降低约80％与全上下文方法相比，证明了其维护检索精度和长期记忆一致性方面的有效性。", "conclusion": "AMA框架通过多代理协作实现了灵活的记忆管理，提高了任务的复杂性和逻辑一致性的处理能力。"}}
{"id": "2601.20351", "pdf": "https://arxiv.org/pdf/2601.20351", "abs": "https://arxiv.org/abs/2601.20351", "authors": ["Chenke Zhang", "Ziyuan Yang", "Licheng Yan", "Shuyi Li", "Andrew Beng Jin Teoh", "Bob Zhang", "Yi Zhang"], "title": "PalmBridge: A Plug-and-Play Feature Alignment Framework for Open-Set Palmprint Verification", "categories": ["cs.CV"], "comment": null, "summary": "Palmprint recognition is widely used in biometric systems, yet real-world performance often degrades due to feature distribution shifts caused by heterogeneous deployment conditions. Most deep palmprint models assume a closed and stationary distribution, leading to overfitting to dataset-specific textures rather than learning domain-invariant representations. Although data augmentation is commonly used to mitigate this issue, it assumes augmented samples can approximate the target deployment distribution, an assumption that often fails under significant domain mismatch. To address this limitation, we propose PalmBridge, a plug-and-play feature-space alignment framework for open-set palmprint verification based on vector quantization. Rather than relying solely on data-level augmentation, PalmBridge learns a compact set of representative vectors directly from training features. During enrollment and verification, each feature vector is mapped to its nearest representative vector under a minimum-distance criterion, and the mapped vector is then blended with the original vector. This design suppresses nuisance variation induced by domain shifts while retaining discriminative identity cues. The representative vectors are jointly optimized with the backbone network using task supervision, a feature-consistency objective, and an orthogonality regularization term to form a stable and well-structured shared embedding space. Furthermore, we analyze feature-to-representative mappings via assignment consistency and collision rate to assess model's sensitivity to blending weights. Experiments on multiple palmprint datasets and backbone architectures show that PalmBridge consistently reduces EER in intra-dataset open-set evaluation and improves cross-dataset generalization with negligible to modest runtime overhead.", "AI": {"tldr": "提出了PalmBridge框架，用于开放集掌纹验证中的特征对齐。", "motivation": "现有的深度掌纹模型在异构部署条件下性能下降，因为这些模型假设封闭和稳定的分布。数据增强技术难以解决显著领域差异问题，因此提出了一种新的解决方案来改善开放集下的识别准确率。", "method": "PalmBridge基于向量量化设计了特征空间对齐框架，通过训练样本学习一组紧凑的代表矢量，并将测试样本映射到最近的代表矢量上。同时优化代表矢量与骨干网络以形成稳定的共享嵌入空间。", "result": "在多个掌纹数据集和不同架构上的实验表明，PalmBridge能够减少错误接受率并改善跨领域泛化能力，而几乎不增加运行时间开销。", "conclusion": "PalmBridge提供了一种有效的特征对齐方法以提高开放集下的掌纹验证性能。"}}
{"id": "2601.20347", "pdf": "https://arxiv.org/pdf/2601.20347", "abs": "https://arxiv.org/abs/2601.20347", "authors": ["Chengying She", "Chengwei Chen", "Xinran Zhang", "Ben Wang", "Lizhuang Liu", "Chengwei Shao", "Yun Bian"], "title": "MMSF: Multitask and Multimodal Supervised Framework for WSI Classification and Survival Analysis", "categories": ["cs.CV"], "comment": "Submitted to \"Biomedical Signal Processing and Control\"", "summary": "Multimodal evidence is critical in computational pathology: gigapixel whole slide images capture tumor morphology, while patient-level clinical descriptors preserve complementary context for prognosis. Integrating such heterogeneous signals remains challenging because feature spaces exhibit distinct statistics and scales. We introduce MMSF, a multitask and multimodal supervised framework built on a linear-complexity MIL backbone that explicitly decomposes and fuses cross-modal information. MMSF comprises a graph feature extraction module embedding tissue topology at the patch level, a clinical data embedding module standardizing patient attributes, a feature fusion module aligning modality-shared and modality-specific representations, and a Mamba-based MIL encoder with multitask prediction heads. Experiments on CAMELYON16 and TCGA-NSCLC demonstrate 2.1--6.6\\% accuracy and 2.2--6.9\\% AUC improvements over competitive baselines, while evaluations on five TCGA survival cohorts yield 7.1--9.8\\% C-index improvements compared with unimodal methods and 5.6--7.1\\% over multimodal alternatives.", "AI": {"tldr": "提出一种用于WSI分类和生存分析的多任务、跨模态监督框架MMSF。", "motivation": "整合肿瘤形态学图像与患者水平临床描述以改善诊断和预后，面临特征空间统计特性不同及尺度差异的问题。", "method": "构建线性复杂度的MIL主干网络，结合图特征提取模块、临床数据嵌入模块、特征融合模块以及具有多任务预测头的Mamba-MIL编码器来集成跨模态信息。", "result": "在CAMELYON16和TCGA-NSCLC上的实验中获得了2.1--6.6%精度和2.2--6.9%AUC改进，生存分析方面相较于单模态方法和现有跨模态方案分别提高了7.1--9.8%和5.6--7.1%C指数。", "conclusion": "MMSF有效提升了WSI分类及生存预测性能，并展示了在多任务、跨模态整合中的优势。"}}
{"id": "2601.20346", "pdf": "https://arxiv.org/pdf/2601.20346", "abs": "https://arxiv.org/abs/2601.20346", "authors": ["Asifullah Khan", "Aimen Wadood", "Mubashar Iqbal", "Umme Zahoora"], "title": "Multimodal Multi-Agent Ransomware Analysis Using AutoGen", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "45 pages, 11 figures and 10 tables", "summary": "Ransomware has become one of the most serious cybersecurity threats causing major financial losses and operational disruptions worldwide.Traditional detection methods such as static analysis, heuristic scanning and behavioral analysis often fall short when used alone. To address these limitations, this paper presents multimodal multi agent ransomware analysis framework designed for ransomware classification. Proposed multimodal multiagent architecture combines information from static, dynamic and network sources. Each data type is handled by specialized agent that uses auto encoder based feature extraction. These representations are then integrated through a fusion agent. After that fused representation are used by transformer based classifier. It identifies the specific ransomware family. The agents interact through an interagent feedback mechanism that iteratively refines feature representations by suppressing low confidence information. The framework was evaluated on large scale datasets containing thousands of ransomware and benign samples. Multiple experiments were conducted on ransomware dataset. It outperforms single modality and nonadaptive fusion baseline achieving improvement of up to 0.936 in Macro-F1 for family classification and reducing calibration error. Over 100 epochs, the agentic feedback loop displays a stable monotonic convergence leading to over +0.75 absolute improvement in terms of agent quality and a final composite score of around 0.88 without fine tuning of the language models. Zeroday ransomware detection remains family dependent on polymorphism and modality disruptions. Confidence aware abstention enables reliable real world deployment by favoring conservativeand trustworthy decisions over forced classification. The findings indicate that proposed approach provides a practical andeffective path toward improving real world ransomware defense systems.", "AI": {"tldr": "本文提出了一种使用自动编码器和变压器的多模态多代理框架，用于分类恶意软件。", "motivation": "传统检测方法在单独使用时效果不佳，因此需要一种结合静态、动态和网络数据的新方法来提高检出率。", "method": "该框架利用专门处理不同类型数据（静态、动态、网络）的代理。每个代理通过自动编码器提取特征，并通过融合代理整合这些表示以供变压器分类器使用。", "result": "实验表明，这种方法在大规模数据集上优于单模态和非自适应融合方法，Macro-F1分数提高了0.936。", "conclusion": "该研究提供了一种实用有效的途径来改进现实世界的恶意软件防御系统。"}}
{"id": "2601.20335", "pdf": "https://arxiv.org/pdf/2601.20335", "abs": "https://arxiv.org/abs/2601.20335", "authors": ["Qinzhuo Wu", "Zhizhuo Yang", "Hanhao Li", "Pengzhi Gao", "Wei Liu", "Jian Luan"], "title": "MobileBench-OL: A Comprehensive Chinese Benchmark for Evaluating Mobile GUI Agents in Real-World Environment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in mobile Graphical User Interface (GUI) agents highlight the growing need for comprehensive evaluation benchmarks. While new online benchmarks offer more realistic testing than offline ones, they tend to focus on the agents' task instruction-following ability while neglecting their reasoning and exploration ability. Moreover, these benchmarks do not consider the random noise in real-world mobile environments. This leads to a gap between benchmarks and real-world environments. To addressing these limitations, we propose MobileBench-OL, an online benchmark with 1080 tasks from 80 Chinese apps. It measures task execution, complex reasoning, and noise robustness of agents by including 5 subsets, which set multiple evaluation dimensions. We also provide an auto-eval framework with a reset mechanism, enabling stable and repeatable real-world benchmarking. Evaluating 12 leading GUI agents on MobileBench-OL shows significant room for improvement to meet real-world requirements. Human evaluation further confirms that MobileBench-OL can reliably measure the performance of leading GUI agents in real environments. Our data and code will be released upon acceptance.", "AI": {"tldr": "提出了MobileBench-OL，一个用于评估移动GUI代理在真实环境中执行任务、复杂推理和噪声鲁棒性的在线基准。", "motivation": "当前的在线基准测试主要关注于代理的任务指令跟随能力，并忽视了其推理能力和探索能力。同时，它们没有考虑到实际环境中的随机噪音问题。", "method": "MobileBench-OL包括1080个任务来自80个中文应用，设计有五种不同类型的子集以全面评估代理的能力。还提供了一个自动评估框架，其中包含重置机制，确保在真实世界环境中进行稳定和可重复的基准测试。", "result": "对十二种领先的GUI代理进行了评测，显示了他们在满足实际环境需求方面的改进空间。进一步的人类评估证实了MobileBench-OL能够可靠地衡量领先GUI代理在现实环境中的性能表现。", "conclusion": "通过提供一个全面且实用的在线基准测试平台，MobileBench-OL有助于推动移动GUI代理技术的发展和优化，以更好地适应复杂的实际应用场景。"}}
{"id": "2601.20334", "pdf": "https://arxiv.org/pdf/2601.20334", "abs": "https://arxiv.org/abs/2601.20334", "authors": ["Brian Y. Tsui", "Alan Y. Fang", "Tiffany J. Hwu"], "title": "Demonstration-Free Robotic Control via LLM Agents", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Robotic manipulation has increasingly adopted vision-language-action (VLA) models, which achieve strong performance but typically require task-specific demonstrations and fine-tuning, and often generalize poorly under domain shift. We investigate whether general-purpose large language model (LLM) agent frameworks, originally developed for software engineering, can serve as an alternative control paradigm for embodied manipulation. We introduce FAEA (Frontier Agent as Embodied Agent), which applies an LLM agent framework directly to embodied manipulation without modification. Using the same iterative reasoning that enables software agents to debug code, FAEA enables embodied agents to reason through manipulation strategies. We evaluate an unmodified frontier agent, Claude Agent SDK, across the LIBERO, ManiSkill3, and MetaWorld benchmarks. With privileged environment state access, FAEA achieves success rates of 84.9%, 85.7%, and 96%, respectively. This level of task success approaches that of VLA models trained with less than 100 demonstrations per task, without requiring demonstrations or fine-tuning. With one round of human feedback as an optional optimization, performance increases to 88.2% on LIBERO. This demonstration-free capability has immediate practical value: FAEA can autonomously explore novel scenarios in simulation and generate successful trajectories for training data augmentation in embodied learning. Our results indicate that general-purpose agents are sufficient for a class of manipulation tasks dominated by deliberative, task-level planning. This opens a path for robotics systems to leverage actively maintained agent infrastructure and benefit directly from ongoing advances in frontier models. Code is available at https://github.com/robiemusketeer/faea-sim", "AI": {"tldr": "研究提出了FAEA框架，该框架利用大型语言模型代理直接控制机器人执行操作任务，无需特定演示或微调。", "motivation": "现有视觉-语言-动作（VLA）模型虽然性能强，但通常需要特定的任务演示和微调，并且在领域变化下泛化能力较差。研究旨在探讨通用大型语言模型代理框架是否可以作为机器人控制的替代方案。", "method": "提出了一种称为FAEA的方法，该方法使用未经修改的前沿代理Claude Agent SDK直接应用于实体操作任务。通过同样的迭代推理过程使软件代理能够调试代码，FAEA使实体代理能够通过操作策略进行推理。", "result": "在LIBERO、ManiSkill3和MetaWorld基准测试中，FAEA取得了84.9%、85.7%和96%的成功率。即使在没有特定演示的情况下，也接近于需要不到100次任务展示的VLA模型的表现。", "conclusion": "研究表明，通用代理对于以审慎的任务级规划为主的实体操作任务是足够的，并且能够自主探索新场景并生成成功的轨迹用于训练数据增强。这为机器人系统利用前沿模型的持续进步提供了可能路径。"}}
{"id": "2601.20333", "pdf": "https://arxiv.org/pdf/2601.20333", "abs": "https://arxiv.org/abs/2601.20333", "authors": ["Ali Zia", "Usman Ali", "Umer Ramzan", "Abdul Rehman", "Abdelwahed Khamis", "Wei Xiang"], "title": "Test-Time Adaptation for Anomaly Segmentation via Topology-Aware Optimal Transport Chaining", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep topological data analysis (TDA) offers a principled framework for capturing structural invariants such as connectivity and cycles that persist across scales, making it a natural fit for anomaly segmentation (AS). Unlike thresholdbased binarisation, which produces brittle masks under distribution shift, TDA allows anomalies to be characterised as disruptions to global structure rather than local fluctuations. We introduce TopoOT, a topology-aware optimal transport (OT) framework that integrates multi-filtration persistence diagrams (PDs) with test-time adaptation (TTA). Our key innovation is Optimal Transport Chaining, which sequentially aligns PDs across thresholds and filtrations, yielding geodesic stability scores that identify features consistently preserved across scales. These stabilityaware pseudo-labels supervise a lightweight head trained online with OT-consistency and contrastive objectives, ensuring robust adaptation under domain shift. Across standard 2D and 3D anomaly detection benchmarks, TopoOT achieves state-of-the-art performance, outperforming the most competitive methods by up to +24.1% mean F1 on 2D datasets and +10.2% on 3D AS benchmarks.", "AI": {"tldr": "本文提出了一种基于拓扑数据分析和最优传输的测试时适应方法，用于异常分割。", "motivation": "传统的二值化阈值法在分布偏移情况下效果脆弱。作者引入了TopoOT框架结合多滤波持续图与测试时自适应，以提高异常检测性能。", "method": "通过最优传输链式调整持续图，生成全局稳定性得分监督轻量级头部模型，在域偏移下确保稳健性。", "result": "在2D和3D异常检测基准上，TopoOT方法优于现有最佳方法，分别提高了+24.1%的平均F1分数和+10.2%", "conclusion": "通过最优传输链式调整持续图，可以有效地提高测试时适应能力，在保持结构稳定性的前提下提升异常分割性能。"}}
{"id": "2601.20331", "pdf": "https://arxiv.org/pdf/2601.20331", "abs": "https://arxiv.org/abs/2601.20331", "authors": ["Mai Su", "Qihan Yu", "Zhongtao Wang", "Yilong Li", "Chengwei Pan", "Yisong Chen", "Guoping Wang"], "title": "GVGS: Gaussian Visibility-Aware Multi-View Geometry for Accurate Surface Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting enables efficient optimization and high-quality rendering, yet accurate surface reconstruction remains challenging. Prior methods improve surface reconstruction by refining Gaussian depth estimates, either via multi-view geometric consistency or through monocular depth priors. However, multi-view constraints become unreliable under large geometric discrepancies, while monocular priors suffer from scale ambiguity and local inconsistency, ultimately leading to inaccurate Gaussian depth supervision. To address these limitations, we introduce a Gaussian visibility-aware multi-view geometric consistency constraint that aggregates the visibility of shared Gaussian primitives across views, enabling more accurate and stable geometric supervision. In addition, we propose a progressive quadtree-calibrated Monocular depth constraint that performs block-wise affine calibration from coarse to fine spatial scales, mitigating the scale ambiguity of depth priors while preserving fine-grained surface details. Extensive experiments on DTU and TNT datasets demonstrate consistent improvements in geometric accuracy over prior Gaussian-based and implicit surface reconstruction methods. Codes are available at an anonymous repository: https://github.com/GVGScode/GVGS.", "AI": {"tldr": "本文提出了GVGS方法，通过引入高斯可见性感知的多视图几何一致约束和渐进四叉树校准的单目深度约束，提高了基于Gaussian Splatting的三维表面重建精度。", "motivation": "当前的方法在改善基于Gaussian Splatting的表面重建时遇到了挑战，尤其是在处理大的几何差异性和尺度模糊性方面。为了克服这些问题，本文旨在通过引入新的高斯可见性感知和深度校准技术来提高重建的准确性。", "method": "GVGS方法包含两个主要部分：一是多视图几何一致性约束，该约束考虑了共享高斯原语在不同视角中的可见性；二是渐进四叉树校准单目深度约束，它通过从粗到细的空间尺度执行分块仿射校准来解决深度先验的尺度模糊问题。", "result": "实验结果表明，与先前基于Gaussian和隐式表面重建的方法相比，GVGS方法在DTU和TNT数据集上实现了几何精度的一致性改进。", "conclusion": "本文提出的GVGS框架通过结合高斯可见性和渐进校准的单目深度约束，显著提高了基于Gaussian Splatting的三维表面重建的质量。"}}
{"id": "2601.20326", "pdf": "https://arxiv.org/pdf/2601.20326", "abs": "https://arxiv.org/abs/2601.20326", "authors": ["Zeyu Xing", "Xing Li", "Hui-Ling Zhen", "Mingxuan Yuan", "Sinno Jialin Pan"], "title": "Beyond Speedup -- Utilizing KV Cache for Sampling and Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by ICLR26", "summary": "KV caches, typically used only to speed up autoregressive decoding, encode contextual information that can be reused for downstream tasks at no extra cost. We propose treating the KV cache as a lightweight representation, eliminating the need to recompute or store full hidden states. Despite being weaker than dedicated embeddings, KV-derived representations are shown to be sufficient for two key applications: \\textbf{(i) Chain-of-Embedding}, where they achieve competitive or superior performance on Llama-3.1-8B-Instruct and Qwen2-7B-Instruct; and \\textbf{(ii) Fast/Slow Thinking Switching}, where they enable adaptive reasoning on Qwen3-8B and DeepSeek-R1-Distil-Qwen-14B, reducing token generation by up to $5.7\\times$ with minimal accuracy loss. Our findings establish KV caches as a free, effective substrate for sampling and reasoning, opening new directions for representation reuse in LLM inference. Code: https://github.com/cmd2001/ICLR2026_KV-Embedding.", "AI": {"tldr": "本文提出将KV缓存作为轻量级表示，用于采样和推理任务，无需重新计算或存储完整的隐藏状态。", "motivation": "利用KV缓存中的上下文信息进行下游任务处理可以节省成本，并且减少重复计算。现有的方法通常只使用KV缓存加速自回归解码，而忽视了其作为轻量级表示的潜力。", "method": "本文提出将KV缓存用作链式嵌入和快速/慢速思维切换应用中的轻量级表示，展示如何在无需额外资源的情况下进行采样和推理任务。通过这种方法，在Llama-3.1-8B-Instruct和Qwen2-7B-Instruct上实现了竞争性或优越的性能。", "result": "实验结果表明，所提出的KV缓存方法可以实现与专业嵌入相媲美的效果，并且在某些情况下表现更优。此外，在减少令牌生成方面取得了显著成效，最多可减少5.7倍，同时保持最小的精度损失。", "conclusion": "本文证明了KV缓存作为采样和推理任务的有效载体，不仅能够节省资源，还能提高性能和效率，为大模型推断中的表示重用开辟新的研究方向。"}}
{"id": "2601.20325", "pdf": "https://arxiv.org/pdf/2601.20325", "abs": "https://arxiv.org/abs/2601.20325", "authors": ["Lulu Xue", "Shengshan Hu", "Wei Lu", "Ziqi Zhou", "Yufei Song", "Jianhong Cheng", "Minghui Li", "Yanjun Zhang", "Leo Yu Zhang"], "title": "UnlearnShield: Shielding Forgotten Privacy against Unlearning Inversion", "categories": ["cs.CR", "cs.CV"], "comment": "This work has been accepted by ICASSP 2026", "summary": "Machine unlearning is an emerging technique that aims to remove the influence of specific data from trained models, thereby enhancing privacy protection. However, recent research has uncovered critical privacy vulnerabilities, showing that adversaries can exploit unlearning inversion to reconstruct data that was intended to be erased. Despite the severity of this threat, dedicated defenses remain lacking. To address this gap, we propose UnlearnShield, the first defense specifically tailored to counter unlearning inversion. UnlearnShield introduces directional perturbations in the cosine representation space and regulates them through a constraint module to jointly preserve model accuracy and forgetting efficacy, thereby reducing inversion risk while maintaining utility. Experiments demonstrate that it achieves a good trade-off among privacy protection, accuracy, and forgetting.", "AI": {"tldr": "提出UnlearnShield，一种专门针对机器学习中数据擦除后逆向工程的隐私保护方案。", "motivation": "现有技术在移除特定训练数据的影响时存在隐私漏洞，攻击者可以通过逆向工程恢复已被删除的数据。为了解决这一问题并增强隐私保护，作者提出了UnlearnShield。", "method": "通过引入方向性的扰动，并利用约束模块调节这些扰动，在余弦表示空间中既保持模型准确性又提高数据擦除效率，从而降低逆向工程的风险同时维护实用性。", "result": "实验表明UnlearnShield在隐私保护、准确性和数据清除能力之间实现了良好的平衡。", "conclusion": "UnlearnShield是首个专门用于防止未学习逆转的防御机制，在保持模型性能的同时有效提升了隐私安全性。"}}
{"id": "2601.20323", "pdf": "https://arxiv.org/pdf/2601.20323", "abs": "https://arxiv.org/abs/2601.20323", "authors": ["Hyunseung Chung", "Jungwoo Oh", "Daeun Kyung", "Jiho Kim", "Yeonsu Kwon", "Min-Gyu Kim", "Edward Choi"], "title": "ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue", "categories": ["cs.AI"], "comment": "Accepted to ICASSP 2026 (5 pages, 2 figures, 5 tables)", "summary": "Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conversational ability, on-device efficiency, and precise understanding of ECG measurements such as the PQRST intervals. To address these limitations, we introduce ECG-Agent, the first LLM-based tool-calling agent for multi-turn ECG dialogue. To facilitate its development and evaluation, we also present ECG-Multi-Turn-Dialogue (ECG-MTD) dataset, a collection of realistic user-assistant multi-turn dialogues for diverse ECG lead configurations. We develop ECG-Agents in various sizes, from on-device capable to larger agents. Experimental results show that ECG-Agents outperform baseline ECG-LLMs in response accuracy. Furthermore, on-device agents achieve comparable performance to larger agents in various evaluations that assess response accuracy, tool-calling ability, and hallucinations, demonstrating their viability for real-world applications.", "AI": {"tldr": "该论文提出了一种基于大语言模型的工具调用代理ECG-Agent，用于多轮心电图对话，并开发了ECG-MTD数据集以支持其发展和评估。", "motivation": "现有的心电图多模态大型语言模型在单轮问答任务中表现良好，但在实际应用中的多轮对话能力、设备上的效率以及对心电图测量的精确理解方面存在不足。本文旨在解决这些问题，并引入一种新的工具调用代理。", "method": "该方法包括开发基于大语言模型的ECG-Agent及其配套数据集ECG-MTD，支持不同大小的模型部署，从设备上运行的小型模型到更大型的版本。", "result": "实验结果显示，ECG-Agents在响应准确性、工具调用能力和幻觉评估方面均优于基线心电图大语言模型。特别是，设备上的小型代理也能够与较大代理实现接近的表现。", "conclusion": "论文证明了基于大语言模型的ECG-Agent对于实际应用的有效性，并展示了其多轮对话能力及在设备上运行的能力。"}}
{"id": "2601.20321", "pdf": "https://arxiv.org/pdf/2601.20321", "abs": "https://arxiv.org/abs/2601.20321", "authors": ["Yuzhe Huang", "Pei Lin", "Wanlin Li", "Daohan Li", "Jiajun Li", "Jiaming Jiang", "Chenxi Xiao", "Ziyuan Jiao"], "title": "Tactile-Force Alignment in Vision-Language-Action Models for Force-aware Manipulation", "categories": ["cs.RO"], "comment": "17pages,9fig", "summary": "Vision-Language-Action (VLA) models have recently emerged as powerful generalists for robotic manipulation. However, due to their predominant reliance on visual modalities, they fundamentally lack the physical intuition required for contact-rich tasks that require precise force regulation and physical reasoning. Existing attempts to incorporate vision-based tactile sensing into VLA models typically treat tactile inputs as auxiliary visual textures, thereby overlooking the underlying correlation between surface deformation and interaction dynamics. To bridge this gap, we propose a paradigm shift from tactile-vision alignment to tactile-force alignment. Here, we introduce TaF-VLA, a framework that explicitly grounds high-dimensional tactile observations in physical interaction forces. To facilitate this, we develop an automated tactile-force data acquisition device and curate the TaF-Dataset, comprising over 10 million synchronized tactile observations, 6-axis force/torque, and matrix force map. To align sequential tactile observations with interaction forces, the central component of our approach is the Tactile-Force Adapter (TaF-Adapter), a tactile sensor encoder that extracts discretized latent information for encoding tactile observations. This mechanism ensures that the learned representations capture history-dependent, noise-insensitive physical dynamics rather than static visual textures. Finally, we integrate this force-aligned encoder into a VLA backbone. Extensive real-world experiments demonstrate that TaF-VLA policy significantly outperforms state-of-the-art tactile-vision-aligned and vision-only baselines on contact-rich tasks, verifying its ability to achieve robust, force-aware manipulation through cross-modal physical reasoning.", "AI": {"tldr": "提出TaF-VLA框架，通过将触觉与力进行对齐来提升视觉语言行动模型在接触密集任务中的性能。", "motivation": "现有VLA模型主要依赖于视觉模态，在需要精准力量调节和物理推理的任务中缺乏必要的物理直觉。为了填补这一空白，研究者提出了一种新的框架以改进触觉与力的对齐。", "method": "引入TaF-VLA框架，并开发了自动化的触觉-力数据采集设备以及TaF-Dataset。核心组件Tactile-Force Adapter用于从高维触觉观测中提取离散化潜在信息，确保学习到的表示能够捕捉历史相关的、抗噪的物理动态。", "result": "实验表明，TaF-VLA政策在接触密集任务上显著优于当前最先进的触觉视觉对齐和仅依赖视觉基线方法。", "conclusion": "通过跨模态物理推理实现稳健的力量感知操作，验证了TaF-Adapter对于提升机器人力量调节能力的有效性。"}}
{"id": "2601.20318", "pdf": "https://arxiv.org/pdf/2601.20318", "abs": "https://arxiv.org/abs/2601.20318", "authors": ["Jiyuan Xu", "Wenyu Zhang", "Xin Jing", "Shuai Chen", "Shuai Zhang", "Jiahao Nie"], "title": "CPiRi: Channel Permutation-Invariant Relational Interaction for Multivariate Time Series Forecasting", "categories": ["cs.CV"], "comment": "22 pages, ICLR 2026", "summary": "Current methods for multivariate time series forecasting can be classified into channel-dependent and channel-independent models. Channel-dependent models learn cross-channel features but often overfit the channel ordering, which hampers adaptation when channels are added or reordered. Channel-independent models treat each channel in isolation to increase flexibility, yet this neglects inter-channel dependencies and limits performance. To address these limitations, we propose \\textbf{CPiRi}, a \\textbf{channel permutation invariant (CPI)} framework that infers cross-channel structure from data rather than memorizing a fixed ordering, enabling deployment in settings with structural and distributional co-drift without retraining. CPiRi couples \\textbf{spatio-temporal decoupling architecture} with \\textbf{permutation-invariant regularization training strategy}: a frozen pretrained temporal encoder extracts high-quality temporal features, a lightweight spatial module learns content-driven inter-channel relations, while a channel shuffling strategy enforces CPI during training. We further \\textbf{ground CPiRi in theory} by analyzing permutation equivariance in multivariate time series forecasting. Experiments on multiple benchmarks show state-of-the-art results. CPiRi remains stable when channel orders are shuffled and exhibits strong \\textbf{inductive generalization} to unseen channels even when trained on \\textbf{only half} of the channels, while maintaining \\textbf{practical efficiency} on large-scale datasets. The source code is released at https://github.com/JasonStraka/CPiRi.", "AI": {"tldr": "提出了一种通道置换不变的框架CPiRi，用于多变量时间序列预测。", "motivation": "当前方法在处理通道依赖和独立模型时存在过拟合或忽视通道间依赖的问题。因此，需要一种能够从数据中推断出跨通道结构，并且不固定于某个特定顺序的方法。", "method": "CPiRi结合了时空解耦架构与置换不变的正则化训练策略：通过预训练的时间编码器提取高质量的时间特征，轻量级的空间模块学习基于内容的通道间关系，同时采用通道打乱策略在训练期间实现通道置换不变性。", "result": "实验结果表明CPiRi在多个基准测试中表现出色，并且能够在通道顺序改变时保持稳定。此外，在仅使用一半通道进行训练的情况下也能对未见过的通道展现出强大的归纳泛化能力，同时维持大规模数据集上的实际效率。", "conclusion": "该研究提出了一种新颖的方法CPiRi，解决了多变量时间序列预测中的通道依赖和独立模型的问题，并在多个基准测试中取得了优越的表现。"}}
{"id": "2601.20311", "pdf": "https://arxiv.org/pdf/2601.20311", "abs": "https://arxiv.org/abs/2601.20311", "authors": ["Zihan Zhou", "Yinan Liu", "Yuyang Xie", "Bin Wang", "Xiaochun Yang", "Zezheng Feng"], "title": "DiagLink: A Dual-User Diagnostic Assistance System by Synergizing Experts with LLMs and Knowledge Graphs", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The global shortage and uneven distribution of medical expertise continue to hinder equitable access to accurate diagnostic care. While existing intelligent diagnostic system have shown promise, most struggle with dual-user interaction, and dynamic knowledge integration -- limiting their real-world applicability. In this study, we present DiagLink, a dual-user diagnostic assistance system that synergizes large language models (LLMs), knowledge graphs (KGs), and medical experts to support both patients and physicians. DiagLink uses guided dialogues to elicit patient histories, leverages LLMs and KGs for collaborative reasoning, and incorporates physician oversight for continuous knowledge validation and evolution. The system provides a role-adaptive interface, dynamically visualized history, and unified multi-source evidence to improve both trust and usability. We evaluate DiagLink through user study, use cases and expert interviews, demonstrating its effectiveness in improving user satisfaction and diagnostic efficiency, while offering insights for the design of future AI-assisted diagnostic systems.", "AI": {"tldr": "DiagLink是一个结合了大型语言模型、知识图谱和医学专家的双重用户诊断辅助系统，旨在改善患者的用户体验并提高诊断效率。", "motivation": "全球医疗专业知识的短缺及分布不均严重影响了准确诊断服务的公平性。现有的智能诊断系统虽有潜力，但在双用户交互和支持动态知识整合方面存在局限性，限制其实际应用。", "method": "DiagLink通过指导对话收集患者病史，并利用大型语言模型和知识图谱进行协作推理，同时引入医生监管以实现持续的知识验证与演进。该系统提供角色自适应界面、动态可视化历史记录及统一多源证据来提升用户信任度与易用性。", "result": "通过用户研究、实际案例分析以及专家访谈评估DiagLink的有效性，结果表明其在提高用户满意度和诊断效率方面表现出色，并为未来AI辅助的诊断系统设计提供了见解。", "conclusion": "DiagLink展示了结合大型语言模型、知识图谱与医学专家的支持下如何改进智能诊断系统的实际应用效果。该研究强调了动态知识整合及双用户交互的重要性，为未来的医疗AI发展奠定了基础。"}}
{"id": "2601.20310", "pdf": "https://arxiv.org/pdf/2601.20310", "abs": "https://arxiv.org/abs/2601.20310", "authors": ["Xin Zhang", "Zijin Yang", "Kejiang Chen", "Linfeng Ma", "Weiming Zhang", "Nenghai Yu"], "title": "SemBind: Binding Diffusion Watermarks to Semantics Against Black-Box Forgery Attacks", "categories": ["cs.CR", "cs.CV", "cs.LG"], "comment": null, "summary": "Latent-based watermarks, integrated into the generation process of latent diffusion models (LDMs), simplify detection and attribution of generated images. However, recent black-box forgery attacks, where an attacker needs at least one watermarked image and black-box access to the provider's model, can embed the provider's watermark into images not produced by the provider, posing outsized risk to provenance and trust. We propose SemBind, the first defense framework for latent-based watermarks that resists black-box forgery by binding latent signals to image semantics via a learned semantic masker. Trained with contrastive learning, the masker yields near-invariant codes for the same prompt and near-orthogonal codes across prompts; these codes are reshaped and permuted to modulate the target latent before any standard latent-based watermark. SemBind is generally compatible with existing latent-based watermarking schemes and keeps image quality essentially unchanged, while a simple mask-ratio parameter offers a tunable trade-off between anti-forgery strength and robustness. Across four mainstream latent-based watermark methods, our SemBind-enabled anti-forgery variants markedly reduce false acceptance under black-box forgery while providing a controllable robustness-security balance.", "AI": {"tldr": "提出了一种名为SemBind的框架，通过将潜在信号绑定到图像语义来抵御黑盒伪造攻击。", "motivation": "针对潜在扩散模型中的水印存在的黑盒伪造风险问题，提出了新的防护方法以保障生成图像的来源和信任度。", "method": "利用学习到的语义掩码器通过对比学习训练，使得相同提示下的代码近似不变而不同提示间近乎正交。将这些代码调整并用于调制目标潜在信号前的标准潜在水印。", "result": "SemBind框架显著降低了黑盒伪造攻击下假接受率，并提供可调控的安全性与鲁棒性的平衡。", "conclusion": "该方法在主流的四种潜在水印技术上均有明显改进，为保护生成图像来源提供了新的解决方案。"}}
{"id": "2601.20309", "pdf": "https://arxiv.org/pdf/2601.20309", "abs": "https://arxiv.org/abs/2601.20309", "authors": ["Jiahuan Yu", "Mingtao Hu", "Zichao Lin", "Minjia Zhang"], "title": "SuperInfer: SLO-Aware Rotary Scheduling and Memory Management for LLM Inference on Superchips", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "Accepted by MLSys '26", "summary": "Large Language Model (LLM) serving faces a fundamental tension between stringent latency Service Level Objectives (SLOs) and limited GPU memory capacity. When high request rates exhaust the KV cache budget, existing LLM inference systems often suffer severe head-of-line (HOL) blocking. While prior work explored PCIe-based offloading, these approaches cannot sustain responsiveness under high request rates, often failing to meet tight Time-To-First-Token (TTFT) and Time-Between-Tokens (TBT) SLOs. We present SuperInfer, a high-performance LLM inference system designed for emerging Superchips (e.g., NVIDIA GH200) with tightly coupled GPU-CPU architecture via NVLink-C2C. SuperInfer introduces RotaSched, the first proactive, SLO-aware rotary scheduler that rotates requests to maintain responsiveness on Superchips, and DuplexKV, an optimized rotation engine that enables full-duplex transfer over NVLink-C2C. Evaluations on GH200 using various models and datasets show that SuperInfer improves TTFT SLO attainment rates by up to 74.7% while maintaining comparable TBT and throughput compared to state-of-the-art systems, demonstrating that SLO-aware scheduling and memory co-design unlocks the full potential of Superchips for responsive LLM serving.", "AI": {"tldr": "超级芯片上用于大语言模型推理的SuperInfer系统设计。", "motivation": "现有LLM推断系统在高请求率下因KV缓存预算耗尽而面临严重的首包阻塞，难以满足严格的TTFT和TBT服务级别目标。", "method": "引入RotaSched, 第一个主动的、基于SLA的旋转调度器，通过NVLink-C2C上的全双工传输引擎DuplexKV保持响应性。", "result": "SuperInfer在使用GH200的各种模型和数据集上提高了TTFT SLA达到率最高74.7%，同时维持了与现有最佳系统相比相当的TBT和吞吐量。", "conclusion": "SLO感知调度和内存协同设计解锁了超级芯片在响应式LLM服务中的全部潜力。"}}
{"id": "2601.20308", "pdf": "https://arxiv.org/pdf/2601.20308", "abs": "https://arxiv.org/abs/2601.20308", "authors": ["Shuoyan Wei", "Feng Li", "Chen Zhou", "Runmin Cong", "Yao Zhao", "Huihui Bai"], "title": "OSDEnhancer: Taming Real-World Space-Time Video Super-Resolution with One-Step Diffusion", "categories": ["cs.CV", "cs.GR"], "comment": "17 pages, 10 figures. Code will be released upon publication", "summary": "Diffusion models (DMs) have demonstrated exceptional success in video super-resolution (VSR), showcasing a powerful capacity for generating fine-grained details. However, their potential for space-time video super-resolution (STVSR), which necessitates not only recovering realistic visual content from low-resolution to high-resolution but also improving the frame rate with coherent temporal dynamics, remains largely underexplored. Moreover, existing STVSR methods predominantly address spatiotemporal upsampling under simplified degradation assumptions, which often struggle in real-world scenarios with complex unknown degradations. Such a high demand for reconstruction fidelity and temporal consistency makes the development of a robust STVSR framework particularly non-trivial. To address these challenges, we propose OSDEnhancer, a novel framework that, to the best of our knowledge, represents the first method to achieve real-world STVSR through an efficient one-step diffusion process. OSDEnhancer initializes essential spatiotemporal structures through a linear pre-interpolation strategy and pivots on training temporal refinement and spatial enhancement mixture of experts (TR-SE MoE), which allows distinct expert pathways to progressively learn robust, specialized representations for temporal coherence and spatial detail, further collaboratively reinforcing each other during inference. A bidirectional deformable variational autoencoder (VAE) decoder is further introduced to perform recurrent spatiotemporal aggregation and propagation, enhancing cross-frame reconstruction fidelity. Experiments demonstrate that the proposed method achieves state-of-the-art performance while maintaining superior generalization capability in real-world scenarios.", "AI": {"tldr": "提出OSDEnhancer框架，利用单步扩散过程实现真实世界的时空视频超分辨率。", "motivation": "现有方法主要在简化降质假设下处理时空插值问题，在现实世界复杂未知的降质量化中表现不佳。为了提高重建保真度和时间一致性，需要开发出一个鲁棒的STVSR框架。", "method": "OSDEnhancer通过线性预插值策略初始化关键空间时间结构，并引入训练时序细化与空间增强混合专家(TR-SE MoE)，以学习时空连贯性和空间细节的稳健表示。此外，还采用双向可变形变分自编码器(VAE)解码器进行递归时空聚合和传播。", "result": "实验表明提出的方法在真实世界场景中达到了最先进的性能，并保持了优越的一般化能力。", "conclusion": "OSDEnhancer是首个通过单步扩散过程实现真实世界的时空视频超分辨率的框架，展示了其高效性和优越性。"}}
{"id": "2601.20306", "pdf": "https://arxiv.org/pdf/2601.20306", "abs": "https://arxiv.org/abs/2601.20306", "authors": ["Yanjie Tu", "Qingsen Yan", "Axi Niu", "Jiacong Tang"], "title": "TPGDiff: Hierarchical Triple-Prior Guided Diffusion for Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "All-in-one image restoration aims to address diverse degradation types using a single unified model. Existing methods typically rely on degradation priors to guide restoration, yet often struggle to reconstruct content in severely degraded regions. Although recent works leverage semantic information to facilitate content generation, integrating it into the shallow layers of diffusion models often disrupts spatial structures (\\emph{e.g.}, blurring artifacts). To address this issue, we propose a Triple-Prior Guided Diffusion (TPGDiff) network for unified image restoration. TPGDiff incorporates degradation priors throughout the diffusion trajectory, while introducing structural priors into shallow layers and semantic priors into deep layers, enabling hierarchical and complementary prior guidance for image reconstruction. Specifically, we leverage multi-source structural cues as structural priors to capture fine-grained details and guide shallow layers representations. To complement this design, we further develop a distillation-driven semantic extractor that yields robust semantic priors, ensuring reliable high-level guidance at deep layers even under severe degradations. Furthermore, a degradation extractor is employed to learn degradation-aware priors, enabling stage-adaptive control of the diffusion process across all timesteps. Extensive experiments on both single- and multi-degradation benchmarks demonstrate that TPGDiff achieves superior performance and generalization across diverse restoration scenarios. Our project page is: https://leoyjtu.github.io/tpgdiff-project.", "AI": {"tldr": "本文提出了一种用于统一图像恢复的Triple-Prior Guided Diffusion (TPGDiff) 网络，该网络在扩散过程中同时利用退化先验、结构先验和语义先验。", "motivation": "现有方法通常依赖于降质先验来指导恢复，但在严重降级区域难以重建内容。为了改善这一点，论文提出了结合结构和语义信息的方法，以增强浅层层次的结构保持能力和深层层次的内容生成能力。", "method": "TPGDiff网络将退化先验贯穿整个扩散过程中，并在浅层引入结构先验，在深层引入语义先验，从而提供分层互补的先验引导。具体而言，该方法利用多源结构线索作为结构先验来捕捉细粒度细节并指导浅层表示；开发一种基于蒸馏驱动的语义提取器以生成鲁棒性更强的语义先验，在严重降级下仍可确保可靠高层次指导，并使用退化抽取器学习适应阶段扩散过程的退化感知先验。", "result": "论文展示了在单个和多个降质量度基准上的大量实验，证明了TPGDiff在各种恢复场景中具有优越性能和泛化能力。", "conclusion": "本文提出了一种新颖的方法来解决统一图像恢复问题，通过分层互补的先验引导提升了模型的能力，在广泛的应用场景中表现出色。"}}
{"id": "2601.20305", "pdf": "https://arxiv.org/pdf/2601.20305", "abs": "https://arxiv.org/abs/2601.20305", "authors": ["Zhenchen Tang", "Songlin Yang", "Zichuan Wang", "Bo Peng", "Yang Li", "Beibei Dong", "Jing Dong"], "title": "Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models", "categories": ["cs.AI"], "comment": null, "summary": "Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.", "AI": {"tldr": "本文提出了一种机制，通过自适应生成描述符来解决统一多模态模型理解能力与生成过程脱节的问题。", "motivation": "统一多模态模型虽然具有强大的理解力，但在指导生成任务时效果不佳。这种认知差距促使作者提出了内源性重提示机制以增强模型的生成能力。", "method": "SEER框架通过两个阶段的内源循环来实现这一目标：第一阶段使用RLVR激活模型潜在评估能力；第二阶段利用强化学习和自反馈优化生成策略。", "result": "实验表明，SEER在评价准确性、重提示效率及生成质量上都超越了当前的最佳方法，并且没有牺牲多模态的通用性。", "conclusion": "通过内源性重提示机制，模型能够更好地将理解转化为有效的生成过程。"}}
{"id": "2601.20304", "pdf": "https://arxiv.org/pdf/2601.20304", "abs": "https://arxiv.org/abs/2601.20304", "authors": ["Genyuan Zhang", "Zihao Wang", "Zhifan Gao", "Lei Xu", "Zhen Zhou", "Haijun Yu", "Jianjia Zhang", "Xiujian Liu", "Weiwei Zhang", "Shaoyu Wang", "Huazhu Fu", "Fenglin Liu", "Weiwen Wu"], "title": "Structure-constrained Language-informed Diffusion Model for Unpaired Low-dose Computed Tomography Angiography Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The application of iodinated contrast media (ICM) improves the sensitivity and specificity of computed tomography (CT) for a wide range of clinical indications. However, overdose of ICM can cause problems such as kidney damage and life-threatening allergic reactions. Deep learning methods can generate CT images of normal-dose ICM from low-dose ICM, reducing the required dose while maintaining diagnostic power. However, existing methods are difficult to realize accurate enhancement with incompletely paired images, mainly because of the limited ability of the model to recognize specific structures. To overcome this limitation, we propose a Structure-constrained Language-informed Diffusion Model (SLDM), a unified medical generation model that integrates structural synergy and spatial intelligence. First, the structural prior information of the image is effectively extracted to constrain the model inference process, thus ensuring structural consistency in the enhancement process. Subsequently, semantic supervision strategy with spatial intelligence is introduced, which integrates the functions of visual perception and spatial reasoning, thus prompting the model to achieve accurate enhancement. Finally, the subtraction angiography enhancement module is applied, which serves to improve the contrast of the ICM agent region to suitable interval for observation. Qualitative analysis of visual comparison and quantitative results of several metrics demonstrate the effectiveness of our method in angiographic reconstruction for low-dose contrast medium CT angiography.", "AI": {"tldr": "提出了一种基于结构和语言的扩散模型，用于不配对低剂量CTA重建。", "motivation": "降低碘化对比剂用量以减少其副作用，同时维持诊断效果。现有方法难以处理未充分配对的数据，限制了准确增强的能力。", "method": "开发一种融合结构性先验信息和空间智能的结构约束语言引导扩散模型（SLDM）。首先提取图像的结构性前序信息来指导推断过程；其次引入语义监督策略以提高视觉感知与空间推理能力；最后应用减影血管造影增强模块。", "result": "通过视觉对比分析及多项指标定量结果证明方法在低剂量CTA重建中的有效性。", "conclusion": "SLDM成功实现了结构一致性并提高了I类介质区域的对比度，从而提升了低剂量CTA重建的质量。"}}
{"id": "2601.20303", "pdf": "https://arxiv.org/pdf/2601.20303", "abs": "https://arxiv.org/abs/2601.20303", "authors": ["Sungjae Lee", "Junhan Jeong", "Yeonjoo Hong", "Kwang In Kim"], "title": "Physically Guided Visual Mass Estimation from a Single RGB Image", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Estimating object mass from visual input is challenging because mass depends jointly on geometric volume and material-dependent density, neither of which is directly observable from RGB appearance. Consequently, mass prediction from pixels is ill-posed and therefore benefits from physically meaningful representations to constrain the space of plausible solutions. We propose a physically structured framework for single-image mass estimation that addresses this ambiguity by aligning visual cues with the physical factors governing mass. From a single RGB image, we recover object-centric three-dimensional geometry via monocular depth estimation to inform volume and extract coarse material semantics using a vision-language model to guide density-related reasoning. These geometry, semantic, and appearance representations are fused through an instance-adaptive gating mechanism, and two physically guided latent factors (volume- and density-related) are predicted through separate regression heads under mass-only supervision. Experiments on image2mass and ABO-500 show that the proposed method consistently outperforms state-of-the-art methods.", "AI": {"tldr": "从单个RGB图像中估计物体质量", "motivation": "由于质量和几何体积及材料密度有关，而这些因素无法直接通过RGB外观观察到，因此需要物理约束来解决单一视觉输入的模糊性问题。", "method": "提出了一种基于物理结构框架的方法，该方法利用单目深度估计恢复物体三维几何信息并提取粗略材质语义。通过实例自适应门控机制将这些表示融合，并使用两个独立回归头预测质量相关的体积和密度因素。", "result": "实验结果表明，所提方法在image2mass和ABO-500数据集上优于当前最先进的方法。", "conclusion": "该研究成功地开发了一种物理引导的视觉质量估计框架，并通过实验证明了其有效性。"}}
{"id": "2601.20302", "pdf": "https://arxiv.org/pdf/2601.20302", "abs": "https://arxiv.org/abs/2601.20302", "authors": ["Suresh Das", "Siladittya Manna", "Sayantari Ghosh"], "title": "Bridging the Applicator Gap with Data-Doping:Dual-Domain Learning for Precise Bladder Segmentation in CT-Guided Brachytherapy", "categories": ["cs.CV"], "comment": null, "summary": "Performance degradation due to covariate shift remains a major challenge for deep learning models in medical image segmentation. An open question is whether samples from a shifted distribution can effectively support learning when combined with limited target domain data. We investigate this problem in the context of bladder segmentation in CT guided gynecological brachytherapy, a critical task for accurate dose optimization and organ at risk sparing. While CT scans without brachytherapy applicators (no applicator: NA) are widely available, scans with applicators inserted (with applicator: WA) are scarce and exhibit substantial anatomical deformation and imaging artifacts, making automated segmentation particularly difficult. We propose a dual domain learning strategy that integrates NA and WA CT data to improve robustness and generalizability under covariate shift. Using a curated assorted dataset, we show that NA data alone fail to capture the anatomical and artifact related characteristics of WA images. However, introducing a modest proportion of WA data into a predominantly NA training set leads to significant performance improvements. Through systematic experiments across axial, coronal, and sagittal planes using multiple deep learning architectures, we demonstrate that doping only 10 to 30 percent WA data achieves segmentation performance comparable to models trained exclusively on WA data. The proposed approach attains Dice similarity coefficients of up to 0.94 and Intersection over Union scores of up to 0.92, indicating effective domain adaptation and improved clinical reliability. This study highlights the value of integrating anatomically similar but distribution shifted datasets to overcome data scarcity and enhance deep learning based segmentation for brachytherapy treatment planning.", "AI": {"tldr": "本文提出了一个双域学习策略，通过结合有无放射治疗插件的CT图像数据来改进膀胱分割任务下的模型性能。", "motivation": "针对医疗影像分割中的性能下降问题和样本稀缺情况，旨在探索有限目标领域数据与分布变化样本的融合方法以提高模型鲁棒性和泛化能力。", "method": "提出了一种结合无插件CT图像（NA）和有插件CT图像（WA）的数据掺杂策略。通过在主要包含NA数据的训练集中加入少量的WA数据来改进膀胱分割任务。", "result": "实验结果表明，掺入10-30%的WA数据能够显著提高模型性能，并且在不同断面和多个深度学习架构上达到了与仅使用WA数据训练相似的效果。最终模型的最大Dice系数达到0.94，IoU分数达0.92。", "conclusion": "该研究证明了整合类似解剖但分布不同的数据集可以克服样本稀缺问题，增强基于深度学习的分割技术在放射治疗计划中的临床可靠性。"}}
{"id": "2601.20301", "pdf": "https://arxiv.org/pdf/2601.20301", "abs": "https://arxiv.org/abs/2601.20301", "authors": ["Jialuo He", "Huangxun Chen"], "title": "Towards Compact and Robust DNNs via Compression-aware Sharpness Minimization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Sharpness-Aware Minimization (SAM) has recently emerged as an effective technique for improving DNN robustness to input variations. However, its interplay with the compactness requirements of on-device DNN deployments remains less explored. Simply pruning a SAM-trained model can undermine robustness, since flatness in the continuous parameter space does not necessarily translate to robustness under the discrete structural changes induced by pruning. Conversely, applying SAM after pruning may be fundamentally constrained by architectural limitations imposed by an early, robustness-agnostic pruning pattern. To address this gap, we propose Compression-aware ShArpness Minimization (C-SAM), a framework that shifts sharpness-aware learning from parameter perturbations to mask perturbations. By explicitly perturbing pruning masks during training, C-SAM promotes a flatter loss landscape with respect to model structure, enabling the discovery of pruning patterns that simultaneously optimize model compactness and robustness to input variations. Extensive experiments on CelebA-HQ, Flowers-102, and CIFAR-10-C across ResNet-18, GoogLeNet, and MobileNet-V2 show that C-SAM consistently achieves higher certified robustness than strong baselines, with improvements of up to 42%, while maintaining task accuracy comparable to the corresponding unpruned models.", "AI": {"tldr": "该论文提出了一种新的框架C-SAM，通过在训练过程中扰动剪枝掩码来优化神经网络的紧凑性和鲁棒性。", "motivation": "现有的SAM技术虽然能够提高DNN对输入变化的鲁棒性，但与设备上的DNN部署所需的紧凑要求之间的关系研究不足。单纯地对经过SAM训练后的模型进行剪枝可能会削弱其鲁棒性；反之，在剪枝后应用SAM也受到早期非鲁棒性的架构限制。", "method": "C-SAM将尖锐度感知学习从参数扰动转移到掩码扰动，通过在训练过程中显式地扰动剪枝掩码，促进损失景观的平坦化，从而找到同时优化模型紧凑性和输入变化鲁棒性模式。", "result": "在CelebA-HQ、Flowers-102和CIFAR-10-C数据集上，与强大的基线相比，C-SAM能够实现高达42%的认证鲁棒性改进，并且保持了与相应未剪枝模型相当的任务准确性。", "conclusion": "该论文通过引入C-SAM框架证明了在训练过程中考虑剪枝掩码扰动有助于提高DNN模型的紧凑性和鲁棒性，同时维持较高的任务精度。"}}
{"id": "2601.20300", "pdf": "https://arxiv.org/pdf/2601.20300", "abs": "https://arxiv.org/abs/2601.20300", "authors": ["Jing Xu", "Minglin Wu", "Xueyuan Chen", "Xixin Wu", "Helen Meng"], "title": "MiLorE-SSL: Scaling Multilingual Capabilities in Self-Supervised Models without Forgetting", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted by ICASSP2026", "summary": "Self-supervised learning (SSL) has greatly advanced speech representation learning, but multilingual SSL models remain constrained to languages encountered during pretraining. Retraining from scratch to incorporate new languages is computationally expensive, while sequential training without migitation strategies often leads to catastrophic forgetting. To address this, we propose MiLorE-SSL, a lightweight framework that combines LoRA modules with a soft mixture-of-experts (MoE) mechanism for efficient continual multilingual training. LoRA provides efficient low-rank adaptation, while soft MoE promotes flexible expert sharing across languages, reducing cross-lingual interference. To further mitigate forgetting, we introduce limited replay data from existing languages, avoiding reliance on large historical corpora. Experiments on ML-SUPERB demonstrate that MiLorE-SSL achieves strong performance in new languages and improves the ability in existing ones with only 2.14% trainable parameters.", "AI": {"tldr": "MiLorE-SSL 提出了一种轻量级框架，用于在不遗忘已有语言的情况下有效地进行多语种自我监督学习。", "motivation": "自监督学习模型通常只能处理预训练期间遇到的语言。重新训练以包含新语言既耗时又可能导致灾难性遗忘。为此，MiLorE-SSL旨在解决这些问题。", "method": "MiLorE-SSL 结合了低秩适应（LoRA）模块和软混合专家机制，在引入新语言时不忘记旧语言，并通过限制重新播放数据来减少跨语种干扰。", "result": "实验结果表明，MiLorE-SSL 在新语言上表现出色，并且仅使用2.14％的可训练参数即可提高现有语言的表现。", "conclusion": "MiLorE-SSL 是一种有效的多语种自我监督学习框架，通过引入轻量级适应机制和软混合专家来解决灾难性遗忘问题。"}}
{"id": "2601.20299", "pdf": "https://arxiv.org/pdf/2601.20299", "abs": "https://arxiv.org/abs/2601.20299", "authors": ["Tianyi Alex Qiu", "Micah Carroll", "Cameron Allen"], "title": "Truthfulness Despite Weak Supervision: Evaluating and Training LLMs Using Peer Prediction", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.GT"], "comment": "ICLR 2026", "summary": "The evaluation and post-training of large language models (LLMs) rely on supervision, but strong supervision for difficult tasks is often unavailable, especially when evaluating frontier models. In such cases, models are demonstrated to exploit evaluations built on such imperfect supervision, leading to deceptive results. However, underutilized in LLM research, a wealth of mechanism design research focuses on game-theoretic incentive compatibility, i.e., eliciting honest and informative answers with weak supervision. Drawing from this literature, we introduce the peer prediction method for model evaluation and post-training. It rewards honest and informative answers over deceptive and uninformative ones, using a metric based on mutual predictability and without requiring ground truth labels. We demonstrate the method's effectiveness and resistance to deception, with both theoretical guarantees and empirical validation on models with up to 405B parameters. We show that training an 8B model with peer prediction-based reward recovers most of the drop in truthfulness due to prior malicious finetuning, even when the reward is produced by a 0.135B language model with no finetuning. On the evaluation front, in contrast to LLM-as-a-Judge which requires strong and trusted judges, we discover an inverse scaling property in peer prediction, where, surprisingly, resistance to deception is strengthened as the capability gap between the experts and participants widens, enabling reliable evaluation of strong models with weak supervision. In particular, LLM-as-a-Judge become worse than random guess when facing deceptive models 5-20x the judge's size, while peer prediction thrives when such gaps are large, including in cases with over 100x size difference.", "AI": {"tldr": "该论文提出了一种基于同伴预测的方法，用于大型语言模型的评估和后期训练，在弱监督条件下确保结果的真实性和抗欺骗性。", "motivation": "当前大型语言模型的评估与后训练依赖于强监督信号，但这些信号在面对复杂任务时难以获取。为解决这一问题并避免利用不完美监督所导致的误导性结果，论文引入了同伴预测机制来激励真实和信息丰富的回答。", "method": "采用基于互预测性的同伴预测方法对模型进行评估与后期训练，该方法无需依赖真实的地面真相标签，并通过理论证明及实验证明其在抗欺骗方面的有效性。同时展示了这种逆向缩放特性：当专家与参与者之间的能力差距增大时，抵抗欺骗的能力增强。", "result": "实验表明，使用同伴预测奖励对模型进行后期训练可以恢复因恶意微调而损失的真实度；对于评估而言，在面对比裁判大5-20倍的欺骗性模型时，传统方法的效果甚至不如随机猜测，但同伴预测依然有效，即使差距超过100倍。", "conclusion": "论文通过理论分析和实验证明了同伴预测方法的有效性和抗欺骗能力，并展示了其在评估大型语言模型中的潜力。"}}
{"id": "2601.20297", "pdf": "https://arxiv.org/pdf/2601.20297", "abs": "https://arxiv.org/abs/2601.20297", "authors": ["Chen Zhu", "Jiashu Zhu", "Yanxun Li", "Meiqi Wu", "Bingze Song", "Chubin Chen", "Jiahong Wu", "Xiangxiang Chu", "Yangang Wang"], "title": "Artifact-Aware Evaluation for High-Quality Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid advancement of video generation techniques, evaluating and auditing generated videos has become increasingly crucial. Existing approaches typically offer coarse video quality scores, lacking detailed localization and categorization of specific artifacts. In this work, we introduce a comprehensive evaluation protocol focusing on three key aspects affecting human perception: Appearance, Motion, and Camera. We define these axes through a taxonomy of 10 prevalent artifact categories reflecting common generative failures observed in video generation. To enable robust artifact detection and categorization, we introduce GenVID, a large-scale dataset of 80k videos generated by various state-of-the-art video generation models, each carefully annotated for the defined artifact categories. Leveraging GenVID, we develop DVAR, a Dense Video Artifact Recognition framework for fine-grained identification and classification of generative artifacts. Extensive experiments show that our approach significantly improves artifact detection accuracy and enables effective filtering of low-quality content.", "AI": {"tldr": "本文提出了一种全面的视频生成评估协议，通过引入GenVID数据集和DVAR框架来检测和分类特定的生成瑕疵。", "motivation": "随着视频生成技术的进步，现有方法提供的视频质量评价较为粗糙，缺乏对具体瑕疵的定位与分类。因此，需要一种更为精细的方法来识别并处理这些缺陷。", "method": "本文定义了三个影响人类感知的关键方面：外观、运动和摄像机，并基于此构建了一个包含十种常见生成失败类别的框架。通过引入一个大规模视频数据集GenVID以及DVAR框架，实现了对视频生成瑕疵的精细检测与分类。", "result": "实验表明，该方法显著提高了生成瑕疵识别准确性，并能够有效过滤低质量内容。", "conclusion": "本文提出的评估协议和工具为改进现有视频生成模型提供了重要的参考价值。"}}
{"id": "2601.20295", "pdf": "https://arxiv.org/pdf/2601.20295", "abs": "https://arxiv.org/abs/2601.20295", "authors": ["Yuxuan Bao", "Jan Zajac", "Megan Powers", "Venkat Raman", "J. Nathan Kutz"], "title": "Cheap2Rich: A Multi-Fidelity Framework for Data Assimilation and System Identification of Multiscale Physics -- Rotating Detonation Engines", "categories": ["cs.LG", "cs.AI", "cs.CE", "math.DS"], "comment": null, "summary": "Bridging the sim2real gap between computationally inexpensive models and complex physical systems remains a central challenge in machine learning applications to engineering problems, particularly in multi-scale settings where reduced-order models typically capture only dominant dynamics. In this work, we present Cheap2Rich, a multi-scale data assimilation framework that reconstructs high-fidelity state spaces from sparse sensor histories by combining a fast low-fidelity prior with learned, interpretable discrepancy corrections. We demonstrate the performance on rotating detonation engines (RDEs), a challenging class of systems that couple detonation-front propagation with injector-driven unsteadiness, mixing, and stiff chemistry across disparate scales. Our approach successfully reconstructs high-fidelity RDE states from sparse measurements while isolating physically meaningful discrepancy dynamics associated with injector-driven effects. The results highlight a general multi-fidelity framework for data assimilation and system identification in complex multi-scale systems, enabling rapid design exploration and real-time monitoring and control while providing interpretable discrepancy dynamics. Code for this project is is available at: github.com/kro0l1k/Cheap2Rich.", "AI": {"tldr": "提出了一种多尺度数据同化框架Cheap2Rich，用于从稀疏传感器历史中重建高保真状态空间。", "motivation": "解决计算成本低廉的模型和复杂物理系统之间的模拟与现实差距问题，特别是在需要跨不同时间尺度建模的情况下。", "method": "通过结合快速低精度先验模型和可解释的偏差修正学习，Cheap2Rich框架可以从稀疏测量中重建高保真度RDE状态，并分离出由喷射器驱动的影响相关的物理意义显著的动力学。", "result": "结果证明了该方法在旋转爆震发动机中的有效性，能够成功地从稀疏测量数据中重建高精度的系统状态。", "conclusion": "展示了Cheap2Rich作为复杂多尺度系统数据同化和系统识别的一般框架的有效性，能够进行快速设计探索、实时监控和控制，并提供可解释的动力学偏差。"}}
{"id": "2601.20284", "pdf": "https://arxiv.org/pdf/2601.20284", "abs": "https://arxiv.org/abs/2601.20284", "authors": ["Debopom Sutradhar", "Md. Abdur Rahman", "Mohaimenul Azam Khan Raiaan", "Reem E. Mohamed", "Sami Azam"], "title": "A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency", "categories": ["cs.CV"], "comment": "Manuscript under review in IEEE Transactions on Image Processing", "summary": "Domain adaptation (DA) addresses the challenge of transferring knowledge from a source domain to a target domain where image data distributions may differ. Existing DA methods often require access to source domain data, adversarial training, or complex pseudo-labeling techniques, which are computationally expensive. To address these challenges, this paper introduces a novel source-free domain adaptation method. It is the first approach to use multiview augmentation and latent space consistency techniques to learn domain-invariant features directly from the target domain. Our method eliminates the need for source-target alignment or pseudo-label refinement by learning transferable representations solely from the target domain by enforcing consistency between multiple augmented views in the latent space. Additionally, the method ensures consistency in the learned features by generating multiple augmented views of target domain data and minimizing the distance between their feature representations in the latent space. We also introduce a ConvNeXt-based encoder and design a loss function that combines classification and consistency objectives to drive effective adaptation directly from the target domain. The proposed model achieves an average classification accuracy of 90. 72\\%, 84\\%, and 97. 12\\% in Office-31, Office-Home and Office-Caltech datasets, respectively. Further evaluations confirm that our study improves existing methods by an average classification accuracy increment of +1.23\\%, +7.26\\%, and +1.77\\% on the respective datasets.", "AI": {"tldr": "提出了一种无需源域数据的领域适应方法，通过多视图图像变换和潜在空间一致性来学习跨领域的不变特征。", "motivation": "解决现有领域适应方法依赖源域数据、对抗训练或复杂伪标签技术导致计算成本高的问题。", "method": "采用多视图增强技术和潜在空间一致性策略，直接从目标域学习可迁移的表示；利用ConvNeXt编码器设计损失函数结合分类和一致性目标。", "result": "在Office-31、Office-Home 和 Office-Caltech 数据集上平均分类准确率为90.72%、84%及97.12%，优于现有方法约+1.23%, +7.26%, +1.77%", "conclusion": "所提方法通过多视图增强和潜在空间一致性学习跨域不变特征，提高了领域适应性能。"}}
{"id": "2601.20280", "pdf": "https://arxiv.org/pdf/2601.20280", "abs": "https://arxiv.org/abs/2601.20280", "authors": ["Daojun Liang", "Qi Li", "Yinglong Wang", "Jing Chen", "Hu Zhang", "Xiaoxiao Cui", "Qizheng Wang", "Shuo Li"], "title": "The Forecast After the Forecast: A Post-Processing Shift in Time Series", "categories": ["cs.LG", "cs.AI"], "comment": "30 Pages", "summary": "Time series forecasting has long been dominated by advances in model architecture, with recent progress driven by deep learning and hybrid statistical techniques. However, as forecasting models approach diminishing returns in accuracy, a critical yet underexplored opportunity emerges: the strategic use of post-processing. In this paper, we address the last-mile gap in time-series forecasting, which is to improve accuracy and uncertainty without retraining or modifying a deployed backbone. We propose $δ$-Adapter, a lightweight, architecture-agnostic way to boost deployed time series forecasters without retraining. $δ$-Adapter learns tiny, bounded modules at two interfaces: input nudging (soft edits to covariates) and output residual correction. We provide local descent guarantees, $O(δ)$ drift bounds, and compositional stability for combined adapters. Meanwhile, it can act as a feature selector by learning a sparse, horizon-aware mask over inputs to select important features, thereby improving interpretability. In addition, it can also be used as a distribution calibrator to measure uncertainty. Thus, we introduce a Quantile Calibrator and a Conformal Corrector that together deliver calibrated, personalized intervals with finite-sample coverage. Our experiments across diverse backbones and datasets show that $δ$-Adapter improves accuracy and calibration with negligible compute and no interface changes.", "AI": {"tldr": "提出了一种轻量级的架构无关的方法$δ$-Adapter，用于增强已部署的时间序列预测模型。", "motivation": "随着时间序列预测模型在准确性上接近极限，通过后处理改善准确性和不确定性成为关键机会。", "method": "$δ$-Adapter学习微小、受限模块，在输入调整和输出残差校正两个接口进行操作。提供局部下降保证以及组合稳定性，同时可用作特征选择器和分布校准器。", "result": "实验显示$δ$-Adapter能在多种模型和数据集中提高准确性和校准性，且计算开销微乎其微。", "conclusion": "$δ$-Adapter为时间序列预测提供了一种无需重新训练或修改部署架构的方法来改善性能。"}}
{"id": "2601.20279", "pdf": "https://arxiv.org/pdf/2601.20279", "abs": "https://arxiv.org/abs/2601.20279", "authors": ["Xiaofeng Zhang", "Yuanchao Zhu", "Chaochen Gu", "Xiaosong Yuan", "Qiyan Zhao", "Jiawei Cao", "Feilong Tang", "Sinan Fan", "Yaomin Shen", "Chen Shen", "Hao Tang"], "title": "Hallucination Begins Where Saliency Drops", "categories": ["cs.CV"], "comment": "Accepted in ICLR 2026", "summary": "Recent studies have examined attention dynamics in large vision-language models (LVLMs) to detect hallucinations. However, existing approaches remain limited in reliably distinguishing hallucinated from factually grounded outputs, as they rely solely on forward-pass attention patterns and neglect gradient-based signals that reveal how token influence propagates through the network. To bridge this gap, we introduce LVLMs-Saliency, a gradient-aware diagnostic framework that quantifies the visual grounding strength of each output token by fusing attention weights with their input gradients. Our analysis uncovers a decisive pattern: hallucinations frequently arise when preceding output tokens exhibit low saliency toward the prediction of the next token, signaling a breakdown in contextual memory retention. Leveraging this insight, we propose a dual-mechanism inference-time framework to mitigate hallucinations: (1) Saliency-Guided Rejection Sampling (SGRS), which dynamically filters candidate tokens during autoregressive decoding by rejecting those whose saliency falls below a context-adaptive threshold, thereby preventing coherence-breaking tokens from entering the output sequence; and (2) Local Coherence Reinforcement (LocoRE), a lightweight, plug-and-play module that strengthens attention from the current token to its most recent predecessors, actively counteracting the contextual forgetting behavior identified by LVLMs-Saliency. Extensive experiments across multiple LVLMs demonstrate that our method significantly reduces hallucination rates while preserving fluency and task performance, offering a robust and interpretable solution for enhancing model reliability. Code is available at: https://github.com/zhangbaijin/LVLMs-Saliency", "AI": {"tldr": "引入LVLMs-Saliency框架，通过融合注意力权重和输入梯度来量化每个输出标记的视觉基础强度，以检测和缓解大型视觉语言模型中的幻觉问题。", "motivation": "现有方法依赖于前向传递注意模式而忽略了揭示令牌影响在网络中如何传播的梯度信号。为解决此局限性并可靠地区分幻象与事实依据的输出，提出了LVLMs-Saliency框架。", "method": "提出LVLMs-Saliency框架，结合注意力权重和输入梯度量化视觉基础强度；设计了两种机制：Saliency-Guided Rejection Sampling (SGRS) 和 Local Coherence Reinforcement (LocoRE)，以减少幻觉。", "result": "实验结果显示该方法显著减少了多个大型视觉语言模型中的幻觉率，同时保持流利度和任务性能。", "conclusion": "LVLMs-Saliency框架提供了一种有效、可解释的方法来增强大型视觉语言模型的可靠性。"}}
{"id": "2601.20276", "pdf": "https://arxiv.org/pdf/2601.20276", "abs": "https://arxiv.org/abs/2601.20276", "authors": ["Tianwei Lin", "Zuyi Zhou", "Xinda Zhao", "Chenke Wang", "Xiaohong Li", "Yu Chen", "Chuanrui Hu", "Jian Pei", "Yafeng Deng"], "title": "Beyond the Needle's Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Long-context LLM agents must access the right evidence from large environments and use it faithfully. However, the popular Needle-in-a-Haystack (NIAH) evaluation mostly measures benign span localization. The needle is near-unique, and the haystack is largely irrelevant. We introduce EverMemBench-S (EMB-S), an adversarial NIAH-style benchmark built on a 326M-token MemoryBank. While the full MemoryBank spans 326M tokens for retrieval-based (RAG) evaluation, we evaluate native long-context models only at scales that fit within each model's context window (up to 1M tokens in this work) to ensure a fair comparison. EMB-S pairs queries with collision-tested near-miss hard negatives and gold evidence sets spanning one or more documents, validated via human screening and LLM verification. We also propose a decoupled diagnostic protocol that reports evidence access (document-ID localization) separately from end-to-end QA quality under full-context prompting. This enables consistent diagnosis for both native long-context prompting and retrieval pipelines. Across a reference-corpus ladder from domain-isolated 64K contexts to a globally shared 326M-token environment, we observe a clear reality gap. Systems that saturate benign NIAH degrade sharply in evidence access under semantic interference. These results indicate that semantic discrimination, not context length alone, is the dominant bottleneck for long-context memory at scale.", "AI": {"tldr": "该论文提出了一种新的评估基准，用于评估大规模语言模型在长上下文中的证据获取和使用能力。", "motivation": "现有的针刺式（NIAH）评价方法主要关注良性跨度定位问题，并没有充分测试在语义干扰下的证据访问情况。", "method": "研究者引入了EverMemBench-S（EMB-S），一种基于326M令牌记忆库的对抗性NIAH风格基准。此基准包括一个解耦诊断协议，将文档ID定位与全上下文提示中的端到端QA质量分开报告。", "result": "实验表明，在语义干扰下，性能良好的良性针刺系统在证据获取方面表现下降明显，证明了语义区分比上下文长度对大规模长上下文记忆更重要。", "conclusion": "研究者发现现有模型在处理大规模长上下文时存在显著的现实差距，主要障碍在于语义区别能力而非单纯上下文长度。"}}
{"id": "2601.20273", "pdf": "https://arxiv.org/pdf/2601.20273", "abs": "https://arxiv.org/abs/2601.20273", "authors": ["Jiacheng Yang", "Jun Wu", "Yaoyao Ding", "Zhiying Xu", "Yida Wang", "Gennady Pekhimenko"], "title": "StreamFusion: Scalable Sequence Parallelism for Distributed Inference of Diffusion Transformers on GPUs", "categories": ["cs.DC", "cs.CV"], "comment": null, "summary": "Diffusion Transformers (DiTs) have gained increasing adoption in high-quality image and video generation. As demand for higher-resolution images and longer videos increases, single-GPU inference becomes inefficient due to increased latency and large activation sizes. Current frameworks employ sequence parallelism (SP) techniques such as Ulysses Attention and Ring Attention to scale inference. However, these implementations have three primary limitations: (1) suboptimal communication patterns for network topologies on modern GPU machines, (2) latency bottlenecks from all-to-all operations in inter-machine communication, and (3) GPU sender-receiver synchronization and computation overheads from using two-sided communication libraries. To address these issues, we present StreamFusion, a topology-aware efficient DiT serving engine. StreamFusion incorporates three key innovations: (1) a topology-aware sequence parallelism technique that accounts for inter- and intra-machine bandwidth differences, (2) Torus Attention, a novel SP technique enabling overlapping of inter-machine all-to-all operations with computation, and (3) a one-sided communication implementation that minimizes GPU sender-receiver synchronization and computation overheads. Our experiments demonstrate that StreamFusion outperforms the state-of-the-art approach by an average of $1.35\\times$ (up to $1.77\\times$).", "AI": {"tldr": "提出了StreamFusion，一种适用于现代GPU机器的拓扑感知序列并行性技术，并通过Torus Attention和单边通信进一步优化了分布式推理性能。", "motivation": "现有的序列并行化方法在处理高分辨率图像和长视频时存在三个主要问题：网络拓扑上的次优通信模式，跨机通信中的全对全操作延迟瓶颈以及使用双端通信库导致的GPU发送器-接收器同步和计算开销。", "method": "提出了一种基于现代GPU机器带宽差异考虑的序列并行性技术；引入了Torus注意机制，该机制可以将跨机全对全操作与计算重叠；采用了单边通信以最小化GPU之间的发送者-接收器同步和计算开销。", "result": "实验结果显示，StreamFusion比最先进的方法平均快1.35倍（最多可提高1.77倍）。", "conclusion": "通过改进的序列并行性策略和技术，StreamFusion显著提高了DiT模型在分布式环境下的推理效率。"}}
{"id": "2601.20270", "pdf": "https://arxiv.org/pdf/2601.20270", "abs": "https://arxiv.org/abs/2601.20270", "authors": ["Holly Trikilis", "Pasindu Marasinghe", "Fariza Rashid", "Suranga Seneviratne"], "title": "Eliciting Least-to-Most Reasoning for Phishing URL Detection", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Phishing continues to be one of the most prevalent attack vectors, making accurate classification of phishing URLs essential. Recently, large language models (LLMs) have demonstrated promising results in phishing URL detection. However, their reasoning capabilities that enabled such performance remain underexplored. To this end, in this paper, we propose a Least-to-Most prompting framework for phishing URL detection. In particular, we introduce an \"answer sensitivity\" mechanism that guides Least-to-Most's iterative approach to enhance reasoning and yield higher prediction accuracy. We evaluate our framework using three URL datasets and four state-of-the-art LLMs, comparing against a one-shot approach and a supervised model. We demonstrate that our framework outperforms the one-shot baseline while achieving performance comparable to that of the supervised model, despite requiring significantly less training data. Furthermore, our in-depth analysis highlights how the iterative reasoning enabled by Least-to-Most, and reinforced by our answer sensitivity mechanism, drives these performance gains. Overall, we show that this simple yet powerful prompting strategy consistently outperforms both one-shot and supervised approaches, despite requiring minimal training or few-shot guidance. Our experimental setup can be found in our Github repository github.sydney.edu.au/htri0928/least-to-most-phishing-detection.", "AI": {"tldr": "本论文提出了一种针对钓鱼网址检测的Least-to-Most提示框架，通过引入“答案敏感性”机制来提升推理能力并提高预测准确性。", "motivation": "准确分类钓鱼网址对于防范网络攻击至关重要。尽管大型语言模型在该领域表现优异，但其背后的推理能力尚待深入研究。", "method": "提出了一个名为Least-to-Most的提示框架，并引入了“答案敏感性”机制来逐步增强推理过程中的准确性。", "result": "通过使用三个URL数据集和四种最先进的大型语言模型进行评估，该方法在性能上优于单次提示基线并达到了监督模型水平的表现，同时需要更少的数据训练。", "conclusion": "提出的方法展示了其在钓鱼网址检测中超越单一提示和监督学习方法的能力，并强调了迭代推理的重要性。"}}
{"id": "2601.20268", "pdf": "https://arxiv.org/pdf/2601.20268", "abs": "https://arxiv.org/abs/2601.20268", "authors": ["Long Van Tran", "Truyen Tran", "Phuoc Nguyen"], "title": "Robust SDE Parameter Estimation Under Missing Time Information Setting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in stochastic differential equations (SDEs) have enabled robust modeling of real-world dynamical processes across diverse domains, such as finance, health, and systems biology. However, parameter estimation for SDEs typically relies on accurately timestamped observational sequences. When temporal ordering information is corrupted, missing, or deliberately hidden (e.g., for privacy), existing estimation methods often fail. In this paper, we investigate the conditions under which temporal order can be recovered and introduce a novel framework that simultaneously reconstructs temporal information and estimates SDE parameters. Our approach exploits asymmetries between forward and backward processes, deriving a score-matching criterion to infer the correct temporal order between pairs of observations. We then recover the total order via a sorting procedure and estimate SDE parameters from the reconstructed sequence using maximum likelihood. Finally, we conduct extensive experiments on synthetic and real-world datasets to demonstrate the effectiveness of our method, extending parameter estimation to settings with missing temporal order and broadening applicability in sensitive domains.", "AI": {"tldr": "该论文提出了一种在缺少时间信息的情况下同时恢复时间和估计SDE参数的新框架。", "motivation": "现有SDE参数估计方法依赖于准确的时间戳，当时间顺序被破坏、丢失或隐藏时，这些方法往往失效。本文旨在解决这一问题，并拓宽应用范围。", "method": "提出了一种利用前后过程的不对称性推断正确时间顺序的方法，通过得分匹配准则进行推断，然后用排序程序恢复完整的时间顺序并使用最大似然估计SDE参数。", "result": "在合成和真实世界数据集上进行了广泛实验，证明了该方法的有效性，并扩展到了缺少时间信息的场景。", "conclusion": "该工作为解决缺失时间信息条件下的SDE参数估计提供了一个有效的解决方案，增强了其在敏感领域的适用性。"}}
{"id": "2601.20262", "pdf": "https://arxiv.org/pdf/2601.20262", "abs": "https://arxiv.org/abs/2601.20262", "authors": ["Boseong Jeon", "Yunho Choi", "Taehan Kim"], "title": "Shallow-π: Knowledge Distillation for Flow-based VLAs", "categories": ["cs.RO"], "comment": null, "summary": "The growing demand for real-time robotic deployment necessitates fast and on-device inference for vision-language-action (VLA) models. Within the VLA literature, efficiency has been extensively studied at the token level, such as visual token pruning. In contrast, systematic transformer layer reduction has received limited attention and, to the best of our knowledge, has not been explored for flow-based VLA models under knowledge distillation. In this work, we propose Shallow-pi, a principled knowledge distillation framework that aggressively reduces the transformer depth of both the VLM backbone and the flow-based action head, compressing the model from 18 to 6 layers. Shallow-pi achieves over two times faster inference with less than one percent absolute drop in success rate on standard manipulation benchmarks, establishing state-of-the-art performance among reduced VLA models. Crucially, we validate our approach through industrial-scale real-world experiments on Jetson Orin and Jetson Thor across multiple robot platforms, including humanoid systems, in complex and dynamic manipulation scenarios.", "AI": {"tldr": "提出了Shallow-pi框架，用于减少基于流的视觉语言动作模型中的变压器层数，并通过知识蒸馏提高其效率。", "motivation": "为了解决实时机器人部署的需求，在不显著降低性能的情况下实现快速且在设备上运行的推理。", "method": "提出了一种名为Shallow-pi的知识蒸馏框架，该框架能够将视觉语言模型和基于流的动作头中的变压器层数从18层减少到6层。", "result": "通过这种方法，在标准操作基准测试中实现了两倍以上的推理速度提升，并且成功率仅下降不到百分之一。同时在工业规模的真实世界实验中验证了效果。", "conclusion": "Shallow-pi框架不仅提高了模型的运行效率，还在复杂和动态的操作场景下展示了优越性，成为减少层数的VLA模型中的最新技术水平。"}}
{"id": "2601.20260", "pdf": "https://arxiv.org/pdf/2601.20260", "abs": "https://arxiv.org/abs/2601.20260", "authors": ["Xingxin Xu", "Bing Cao", "DongDong Li", "Qinghua Hu", "Pengfei Zhu"], "title": "Reversible Efficient Diffusion for Image Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Multi-modal image fusion aims to consolidate complementary information from diverse source images into a unified representation. The fused image is expected to preserve fine details and maintain high visual fidelity. While diffusion models have demonstrated impressive generative capabilities in image generation, they often suffer from detail loss when applied to image fusion tasks. This issue arises from the accumulation of noise errors inherent in the Markov process, leading to inconsistency and degradation in the fused results. However, incorporating explicit supervision into end-to-end training of diffusion-based image fusion introduces challenges related to computational efficiency. To address these limitations, we propose the Reversible Efficient Diffusion (RED) model - an explicitly supervised training framework that inherits the powerful generative capability of diffusion models while avoiding the distribution estimation.", "AI": {"tldr": "提出了一种可逆高效扩散模型（RED）用于图像融合，旨在保持细节和高质量的同时提高计算效率。", "motivation": "现有基于扩散模型的图像融合技术在处理过程中会积累噪声错误，导致结果不一致和质量下降；同时，引入监督训练增加了计算负担。", "method": "提出RED模型，结合了扩散模型的强大生成能力，并通过可逆设计避免分布估计问题，实现高效监督训练框架。", "result": "RED模型在保持细节和高质量的同时提高了计算效率。", "conclusion": "RED模型克服了现有基于扩散模型的图像融合方法面临的挑战，为多模态图像融合提供了一种新的有效解决方案。"}}
{"id": "2601.20253", "pdf": "https://arxiv.org/pdf/2601.20253", "abs": "https://arxiv.org/abs/2601.20253", "authors": ["Si Chen", "Le Huy Khiem", "Annalisa Szymanski", "Ronald Metoyer", "Ting Hua", "Nitesh V. Chawla"], "title": "Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Open-ended question answering (QA) evaluates a model's ability to perform contextualized reasoning beyond factual recall. This challenge is especially acute in practice-based domains, where knowledge is procedural and grounded in professional judgment, while most existing LLM benchmarks depend on pre-existing human exam datasets that are often unavailable in such settings. We introduce a framework for automated benchmark generation from expert-authored guidelines informed by Bloom's Taxonomy. It converts expert practices into implicit violation-based scenarios and expands them into auto-graded multiple-choice questions (MCQs) and multi-turn dialogues across four cognitive levels, enabling deterministic, reproducible, and scalable evaluation. Applied to three applied domains: teaching, dietetics, and caregiving, we find differences between model and human-like reasoning: LLMs sometimes perform relatively better on higher-order reasoning (Analyze) but fail more frequently on lower-level items (Remember). We produce large-scale, psychometrically informed benchmarks that surface these non-intuitive model behaviors and enable evaluation of contextualized reasoning in real-world settings.", "AI": {"tldr": "本文提出了一种从领域指南中自动生成基准的方法，该方法基于布鲁姆分类学，适用于开放性问答评估。", "motivation": "现有的大型语言模型测试依赖于人类编写的考试数据集，在实践应用的特定领域难以获取。因此需要一种新的自动化生成基准的方法来评价模型在实际环境中的上下文推理能力。", "method": "本文提出了一种框架，该框架能够将专家撰写的指南转化为基于布鲁姆分类学的认知水平问题，并自动生成多选题和多轮对话以进行评估。", "result": "通过应用于教学、营养学和护理三个领域，发现模型在高级推理任务上的表现有时优于人类，但在较低层级的任务上却常常失败。生成了大规模的心理测量信息的基准测试集来揭示这些非直观的行为模式。", "conclusion": "该研究提供了评估大型语言模型上下文推理能力的新方法，并通过心理测量学的信息使得这种评估更加具体和可重复。"}}
