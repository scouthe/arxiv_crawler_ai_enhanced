{"id": "2602.04702", "pdf": "https://arxiv.org/pdf/2602.04702", "abs": "https://arxiv.org/abs/2602.04702", "authors": ["Tuan Dat Phuong", "Duc-Tuan Truong", "Long-Vu Hoang", "Trang Nguyen Thi Thu"], "title": "Fine-Grained Frame Modeling in Multi-head Self-Attention for Speech Deepfake Detection", "categories": ["cs.SD"], "comment": "Accepted by ICASSP 2026", "summary": "Transformer-based models have shown strong performance in speech deepfake detection, largely due to the effectiveness of the multi-head self-attention (MHSA) mechanism. MHSA provides frame-level attention scores, which are particularly valuable because deepfake artifacts often occur in small, localized regions along the temporal dimension of speech. This makes fine-grained frame modeling essential for accurately detecting subtle spoofing cues. In this work, we propose fine-grained frame modeling (FGFM) for MHSA-based speech deepfake detection, where the most informative frames are first selected through a multi-head voting (MHV) module. These selected frames are then refined via a cross-layer refinement (CLR) module to enhance the model's ability to learn subtle spoofing cues. Experimental results demonstrate that our method outperforms the baseline model and achieves Equal Error Rate (EER) of 0.90%, 1.88%, and 6.64% on the LA21, DF21, and ITW datasets, respectively. These consistent improvements across multiple benchmarks highlight the effectiveness of our fine-grained modeling for robust speech deepfake detection.", "AI": {"tldr": "本文提出了一种基于多头自注意力机制的细粒度帧建模方法（FGFM），用于语音深伪检测。", "motivation": "深度伪造音频中的虚假特征往往发生在时间轴上的小区域，因此需要细粒度级别的帧建模来准确捕捉和识别这些微妙的欺诈线索。", "method": "该模型通过多头投票模块选择最相关的帧，并使用跨层细化模块增强学习微弱欺骗线索的能力。", "result": "实验结果表明，在LA21、DF21及ITW数据集上，提出的FGFM方法分别达到了0.90%、1.88%和6.64%的等错误率（EER），优于基线模型。", "conclusion": "细粒度帧建模在语音深伪检测任务中表现出色且鲁棒性更强。"}}
{"id": "2602.04699", "pdf": "https://arxiv.org/pdf/2602.04699", "abs": "https://arxiv.org/abs/2602.04699", "authors": ["Samet Hicsonmez", "Jose Sosa", "Dan Pineau", "Inder Pal Singh", "Arunkumar Rathinam", "Abd El Rahman Shabayek", "Djamila Aouada"], "title": "Annotation Free Spacecraft Detection and Segmentation using Vision Language Models", "categories": ["cs.CV"], "comment": "ICRA 2026", "summary": "Vision Language Models (VLMs) have demonstrated remarkable performance in open-world zero-shot visual recognition. However, their potential in space-related applications remains largely unexplored. In the space domain, accurate manual annotation is particularly challenging due to factors such as low visibility, illumination variations, and object blending with planetary backgrounds. Developing methods that can detect and segment spacecraft and orbital targets without requiring extensive manual labeling is therefore of critical importance. In this work, we propose an annotation-free detection and segmentation pipeline for space targets using VLMs. Our approach begins by automatically generating pseudo-labels for a small subset of unlabeled real data with a pre-trained VLM. These pseudo-labels are then leveraged in a teacher-student label distillation framework to train lightweight models. Despite the inherent noise in the pseudo-labels, the distillation process leads to substantial performance gains over direct zero-shot VLM inference. Experimental evaluations on the SPARK-2024, SPEED+, and TANGO datasets on segmentation tasks demonstrate consistent improvements in average precision (AP) by up to 10 points. Code and models are available at https://github.com/giddyyupp/annotation-free-spacecraft-segmentation.", "AI": {"tldr": "论文提出了一种使用视觉语言模型进行无标注航天器检测和分割的管道。", "motivation": "在太空领域，准确的手动注释由于低可见度、光照变化和物体与行星背景融合等因素而特别具有挑战性。因此开发无需大量手动标签即可检测和分割航天器的方法至关重要。", "method": "该方法通过预训练视觉语言模型自动为一小部分未标注的真实数据生成伪标签，然后在教师-学生标签蒸馏框架中利用这些伪标签来训练轻量级模型。尽管存在伪标签中的固有噪声，但蒸馏过程导致了超过直接零样本视觉语言模型推理的显著性能提升。", "result": "实验评估表明，在SPARK-2024、SPEED+和TANGO数据集上分割任务中一致提高了平均精度（AP）高达10点。", "conclusion": "该工作展示了在空间目标检测与分割任务中使用视觉语言模型的潜力，并且通过无标注方法取得了显著的进步。"}}
{"id": "2602.04694", "pdf": "https://arxiv.org/pdf/2602.04694", "abs": "https://arxiv.org/abs/2602.04694", "authors": ["Maya Le", "Paweł Prałat", "Aaron Smith", "François Théberge"], "title": "The Needle is a Thread: Finding Planted Paths in Noisy Process Trees", "categories": ["cs.SI", "cs.CR", "cs.DS"], "comment": "15 pages, 9 figures", "summary": "Motivated by applications in cybersecurity such as finding meaningful sequences of malware-related events buried inside large amounts of computer log data, we introduce the \"planted path\" problem and propose an algorithm to find fuzzy matchings between two trees. This algorithm can be used as a \"building block\" for more complicated workflows. We demonstrate usefulness of a few of such workflows in mining synthetically generated data as well as real-world ACME cybersecurity datasets.", "AI": {"tldr": "该论文介绍了在嘈杂的过程树中寻找隐式路径的问题，并提出了一种用于匹配两个树的算法。", "motivation": "受网络安全领域的启发，如从大量的计算机日志数据中找到有意义的恶意软件相关事件序列，作者提出了\"隐式路径\"问题并开发了相应的解决方案。", "method": "论文提出了一种寻找模糊匹配的方法，并将其作为更复杂的流程构建模块。这种方法在合成生成的数据以及实际ACME网络安全数据集中均得到了验证。", "result": "该方法能够有效地挖掘和识别具有潜在威胁的序列模式，适用于网络安全分析中的多个工作流。", "conclusion": "通过提出一种新的\"隐式路径\"问题及其解决算法，论文展示了其在合成生成的数据集以及真实世界ACME网络安全数据集中发现隐藏模式的能力。"}}
{"id": "2602.04692", "pdf": "https://arxiv.org/pdf/2602.04692", "abs": "https://arxiv.org/abs/2602.04692", "authors": ["Sijia Chen", "Lijuan Ma", "Yanqiu Yu", "En Yu", "Liman Liu", "Wenbing Tao"], "title": "DRMOT: A Dataset and Framework for RGBD Referring Multi-Object Tracking", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Referring Multi-Object Tracking (RMOT) aims to track specific targets based on language descriptions and is vital for interactive AI systems such as robotics and autonomous driving. However, existing RMOT models rely solely on 2D RGB data, making it challenging to accurately detect and associate targets characterized by complex spatial semantics (e.g., ``the person closest to the camera'') and to maintain reliable identities under severe occlusion, due to the absence of explicit 3D spatial information. In this work, we propose a novel task, RGBD Referring Multi-Object Tracking (DRMOT), which explicitly requires models to fuse RGB, Depth (D), and Language (L) modalities to achieve 3D-aware tracking. To advance research on the DRMOT task, we construct a tailored RGBD referring multi-object tracking dataset, named DRSet, designed to evaluate models' spatial-semantic grounding and tracking capabilities. Specifically, DRSet contains RGB images and depth maps from 187 scenes, along with 240 language descriptions, among which 56 descriptions incorporate depth-related information. Furthermore, we propose DRTrack, a MLLM-guided depth-referring tracking framework. DRTrack performs depth-aware target grounding from joint RGB-D-L inputs and enforces robust trajectory association by incorporating depth cues. Extensive experiments on the DRSet dataset demonstrate the effectiveness of our framework.", "AI": {"tldr": "提出了一种RGBD多目标跟踪任务，旨在通过融合RGB、深度和语言模态进行三维感知的多对象跟踪。", "motivation": "现有的RMOT模型依赖于二维RGB数据，在处理复杂空间语义和严重遮挡时难以保持可靠的识别性。因此，引入了DRMOT以解决这些问题。", "method": "构建了一个包含RGB图像、深度图及语言描述的数据集，并提出了一种由多模态语言引导的跟踪框架。该框架实现了基于RGB-D-L输入的目标定位并使用深度线索强化轨迹关联。", "result": "实验结果表明所提框架的有效性。", "conclusion": "通过融合三维信息，改进了多对象跟踪任务中对复杂空间语义的理解和处理能力。"}}
{"id": "2602.04687", "pdf": "https://arxiv.org/pdf/2602.04687", "abs": "https://arxiv.org/abs/2602.04687", "authors": ["Yang Yian", "Yu Fan", "Liudmila Zavolokina", "Sarah Ebling"], "title": "Investigating Disability Representations in Text-to-Image Models", "categories": ["cs.CL", "cs.CV", "cs.CY", "cs.HC"], "comment": "21 pages, 9 figures. References included", "summary": "Text-to-image generative models have made remarkable progress in producing high-quality visual content from textual descriptions, yet concerns remain about how they represent social groups. While characteristics like gender and race have received increasing attention, disability representations remain underexplored. This study investigates how people with disabilities are represented in AI-generated images by analyzing outputs from Stable Diffusion XL and DALL-E 3 using a structured prompt design. We analyze disability representations by comparing image similarities between generic disability prompts and prompts referring to specific disability categories. Moreover, we evaluate how mitigation strategies influence disability portrayals, with a focus on assessing affective framing through sentiment polarity analysis, combining both automatic and human evaluation. Our findings reveal persistent representational imbalances and highlight the need for continuous evaluation and refinement of generative models to foster more diverse and inclusive portrayals of disability.", "AI": {"tldr": "该论文研究了文本到图像生成模型中对残疾人士的表示情况。", "motivation": "尽管性别和种族在AI生成的图像中的表现受到了越来越多的关注，但是关于残疾人如何被描绘的研究相对较少。此研究旨在填补这一空白。", "method": "通过使用Structured Prompt设计来分析Stable Diffusion XL 和 DALL-E 3生成的图像，并对比一般性残疾提示词与特定类型残疾病例之间的图像相似度，同时评估不同的缓和策略对残疾人表现的影响。", "result": "研究发现AI生成模型中存在代表性的不平衡问题。", "conclusion": "需要持续评估并改进文本到图像生成模型，以实现更丰富多样且包容性的残疾人士描绘。"}}
{"id": "2602.04683", "pdf": "https://arxiv.org/pdf/2602.04683", "abs": "https://arxiv.org/abs/2602.04683", "authors": ["Dongchao Yang", "Yuanyuan Wang", "Dading Chong", "Songxiang Liu", "Xixin Wu", "Helen Meng"], "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization", "categories": ["cs.SD"], "comment": null, "summary": "We study two foundational problems in audio language models: (1) how to design an audio tokenizer that can serve as an intermediate representation for both understanding and generation; and (2) how to build an audio foundation model that generalizes in few-shot and zero-shot settings, analogous to large language models. To this end, we make the following two contributions. First, we propose ReasoningCodec, a discrete audio codec that factorizes audio into (i) reasoning tokens, which encode text-aligned, high-level analysis and planning representations for audio understanding and hierarchical generation, and (ii) reconstruction tokens, which encode semantic-rich acoustic cues for high-fidelity waveform reconstruction. This design achieves understanding performance comparable to strong continuous representations while improving generation quality and reconstruction fidelity over prior discrete tokenizers. Second, we introduce a unified autoregressive architecture for text and audio, together with multi-stage training and multi-task data construction. Using this framework, we train UniAudio 2.0 on 100B text tokens and 60B audio tokens. Across a wide range of speech, sound, and music tasks, UniAudio 2.0 performs competitively on in-domain evaluations and demonstrates strong few-shot and zero-shot generalization to unseen tasks. Demo, code, and checkpoints will be available at \\href{https://dongchaoyang.top/UniAudio2Demo/}{https://dongchaoyang.top/UniAudio2Demo/}.", "AI": {"tldr": "研究了音频语言模型中的两个基础问题，并提出了ReasoningCodec和统一的自回归架构，以提高理解和生成的质量。", "motivation": "旨在设计一个能够同时服务于理解与生成的音频编码器以及构建一个在少样本或零样本设置中泛化的音频基础模型。", "method": "提出了一种离散音频编解码器ReasoningCodec和统一的自回归架构，该框架使用100B文本令牌和60B音频令牌进行训练。", "result": "UniAudio 2.0在广泛的语音、声音和音乐任务中表现优越，并显示出对未见任务的强大泛化能力。", "conclusion": "通过改进音频编码器的设计以及引入统一的自回归架构，实现了高质量的理解与生成效果。"}}
{"id": "2602.04680", "pdf": "https://arxiv.org/pdf/2602.04680", "abs": "https://arxiv.org/abs/2602.04680", "authors": ["Haina Zhu", "Yao Xiao", "Xiquan Li", "Ziyang Ma", "Jianwei Yu", "Bowen Zhang", "Mingqi Yang", "Xie Chen"], "title": "Audio ControlNet for Fine-Grained Audio Generation and Editing", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM"], "comment": null, "summary": "We study the fine-grained text-to-audio (T2A) generation task. While recent models can synthesize high-quality audio from text descriptions, they often lack precise control over attributes such as loudness, pitch, and sound events. Unlike prior approaches that retrain models for specific control types, we propose to train ControlNet models on top of pre-trained T2A backbones to achieve controllable generation over loudness, pitch, and event roll. We introduce two designs, T2A-ControlNet and T2A-Adapter, and show that the T2A-Adapter model offers a more efficient structure with strong control ability. With only 38M additional parameters, T2A-Adapter achieves state-of-the-art performance on the AudioSet-Strong in both event-level and segment-level F1 scores. We further extend this framework to audio editing, proposing T2A-Editor for removing and inserting audio events at time locations specified by instructions. Models, code, dataset pipelines, and benchmarks will be released to support future research on controllable audio generation and editing.", "AI": {"tldr": "研究从文本描述生成高质量且可控制音频的任务，提出在预训练模型基础上引入ControlNet和Adapter设计以实现对音量、音调及事件的精细控制。", "motivation": "当前模型虽能合成高质量音频但缺乏精确控制属性如音量、音调和声音事件的能力。重新训练特定控制类型的模型效率低下，因此提出改进方案。", "method": "在预训练T2A基础模型上引入ControlNet与Adapter设计以实现可控的音量、音调及事件编辑，并且开发了用于音频插入删除操作的T2A-Editor。", "result": "T2A-Adapter仅需38M额外参数，在AudioSet-Strong数据集中达到了领先的性能表现，展示了强大的控制能力和效率。", "conclusion": "提出的设计在可控音频生成和编辑方面取得了显著成果，为进一步研究提供了坚实基础。"}}
{"id": "2602.04678", "pdf": "https://arxiv.org/pdf/2602.04678", "abs": "https://arxiv.org/abs/2602.04678", "authors": ["Zhen Zhou", "Zhirui Wang", "Qi Hong", "Yunyang Shi", "Ziyuan Gu", "Zhiyuan Liu"], "title": "Let Experts Feel Uncertainty: A Multi-Expert Label Distribution Approach to Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 2figures", "summary": "Time series forecasting in real-world applications requires both high predictive accuracy and interpretable uncertainty quantification. Traditional point prediction methods often fail to capture the inherent uncertainty in time series data, while existing probabilistic approaches struggle to balance computational efficiency with interpretability. We propose a novel Multi-Expert Learning Distributional Labels (LDL) framework that addresses these challenges through mixture-of-experts architectures with distributional learning capabilities. Our approach introduces two complementary methods: (1) Multi-Expert LDL, which employs multiple experts with different learned parameters to capture diverse temporal patterns, and (2) Pattern-Aware LDL-MoE, which explicitly decomposes time series into interpretable components (trend, seasonality, changepoints, volatility) through specialized sub-experts. Both frameworks extend traditional point prediction to distributional learning, enabling rich uncertainty quantification through Maximum Mean Discrepancy (MMD). We evaluate our methods on aggregated sales data derived from the M5 dataset, demonstrating superior performance compared to baseline approaches. The continuous Multi-Expert LDL achieves the best overall performance, while the Pattern-Aware LDL-MoE provides enhanced interpretability through component-wise analysis. Our frameworks successfully balance predictive accuracy with interpretability, making them suitable for real-world forecasting applications where both performance and actionable insights are crucial.", "AI": {"tldr": "提出了一种新的多专家学习分布标签框架，用于时间序列预测，旨在提高预测准确性和不确定性量化。", "motivation": "传统点预测方法难以捕捉时间序列数据中的固有不确定性；现有概率方法在计算效率和可解释性之间难以平衡。为解决这些问题，提出了新的框架以提升性能。", "method": "提出两种方法：多专家学习分布标签通过混合专家架构捕捉多样时间模式；模式感知学习分布标签-混合专家进一步分解时间序列成分（趋势、季节性等），提高可解释性。", "result": "在M5数据集上的实验显示，所提框架优于基线方法，在预测准确性和不确定性量化方面表现更佳。", "conclusion": "提出的多专家和模式感知方法平衡了性能与可解释性，适用于需要高精度且具备行动洞察的现实世界应用。"}}
{"id": "2602.04677", "pdf": "https://arxiv.org/pdf/2602.04677", "abs": "https://arxiv.org/abs/2602.04677", "authors": ["Ondrej Tybl", "Lukas Neumann"], "title": "REDistill: Robust Estimator Distillation for Balancing Robustness and Efficiency", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Knowledge Distillation (KD) transfers knowledge from a large teacher model to a smaller student by aligning their predictive distributions. However, conventional KD formulations - typically based on Kullback-Leibler divergence - assume that the teacher provides reliable soft targets. In practice, teacher predictions are often noisy or overconfident, and existing correction-based approaches rely on ad-hoc heuristics and extensive hyper-parameter tuning, which hinders generalization. We introduce REDistill (Robust Estimator Distillation), a simple yet principled framework grounded in robust statistics. REDistill replaces the standard KD objective with a power divergence loss, a generalization of KL divergence that adaptively downweights unreliable teacher output while preserving informative logit relationships. This formulation provides a unified and interpretable treatment of teacher noise, requires only logits, integrates seamlessly into existing KD pipelines, and incurs negligible computational overhead. Extensive experiments on CIFAR-100 and ImageNet-1k demonstrate that REDistill consistently improves student accuracy in diverse teacher-student architectures. Remarkably, it achieves these gains without model-specific hyper-parameter tuning, underscoring its robustness and strong generalization to unseen teacher-student pairs.", "AI": {"tldr": "本文提出了一种基于稳健统计学的REDistill框架，用于解决传统知识蒸馏中的教师模型预测噪声问题。", "motivation": "传统的知识蒸馏方法依赖于可靠的软标签，但实际情况中教师模型可能产生噪音或过度自信的输出。现有的修正方案需要大量的超参数调整和启发式方法，限制了其泛化能力。", "method": "REDistill将标准的知识蒸馏目标替换为幂散度损失函数，该函数能自适应地减轻不可靠的教师输出的影响，同时保持有用的logit关系，并且只需要使用logits即可实现无缝集成到现有知识蒸馏流程中，几乎不增加计算开销。", "result": "在CIFAR-100和ImageNet-1k数据集上的大量实验表明，REDistill能在多种教师-学生架构中提升学生的准确性，并且无需针对特定模型的超参数调整即可实现这些改进。", "conclusion": "REDistill提供了一种简单而原则的方法来处理教师噪声问题，展现了强大的泛化能力，在未见过的教学对中也能取得显著效果。"}}
{"id": "2602.04674", "pdf": "https://arxiv.org/pdf/2602.04674", "abs": "https://arxiv.org/abs/2602.04674", "authors": ["Eun Cheol Choi", "Lindsay E. Young", "Emilio Ferrara"], "title": "Overstating Attitudes, Ignoring Networks: LLM Biases in Simulating Misinformation Susceptibility", "categories": ["cs.SI", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used as proxies for human judgment in computational social science, yet their ability to reproduce patterns of susceptibility to misinformation remains unclear. We test whether LLM-simulated survey respondents, prompted with participant profiles drawn from social survey data measuring network, demographic, attitudinal and behavioral features, can reproduce human patterns of misinformation belief and sharing. Using three online surveys as baselines, we evaluate whether LLM outputs match observed response distributions and recover feature-outcome associations present in the original survey data. LLM-generated responses capture broad distributional tendencies and show modest correlation with human responses, but consistently overstate the association between belief and sharing. Linear models fit to simulated responses exhibit substantially higher explained variance and place disproportionate weight on attitudinal and behavioral features, while largely ignoring personal network characteristics, relative to models fit to human responses. Analyses of model-generated reasoning and LLM training data suggest that these distortions reflect systematic biases in how misinformation-related concepts are represented. Our findings suggest that LLM-based survey simulations are better suited for diagnosing systematic divergences from human judgment than for substituting it.", "AI": {"tldr": "大型语言模型（LLM）在模拟人类对错误信息的敏感性方面的能力尚不清楚，论文通过使用在线调查作为基线来测试LLM生成的回应是否能重现真实的人类反应。", "motivation": "评估大型语言模型能否准确模拟人们对于错误信息的态度和行为，并且探究这些模型在模拟人类判断时是否存在系统偏差。", "method": "利用三个在线调查的数据，将参与者特征输入到LLM中并生成其回应，分析这些回应是否能重现真实的人类反应分布以及特性-结果关联。同时比较了基于LLM生成数据的线性模型与基于实际人类响应数据的线性模型的表现。", "result": "LLM生成的回答能够捕捉一些总体趋势并与人类回答有适度的相关性，但高估了信念和分享之间的关系，并且在建模时过分依赖态度和行为特征而忽略了个人网络特征。这表明LLM在代表错误信息相关概念方面存在系统偏差。", "conclusion": "研究表明，基于LLM的调查模拟更适合用于诊断与人类判断之间的系统性差异，而不是完全替代它。"}}
{"id": "2602.04672", "pdf": "https://arxiv.org/pdf/2602.04672", "abs": "https://arxiv.org/abs/2602.04672", "authors": ["Jin-Chuan Shi", "Binhong Ye", "Tao Liu", "Junzhe He", "Yangjinhui Xu", "Xiaoyang Liu", "Zeju Li", "Hao Chen", "Chunhua Shen"], "title": "AGILE: Hand-Object Interaction Reconstruction from Video via Agentic Generation", "categories": ["cs.CV", "cs.GR", "cs.RO"], "comment": "11 pages", "summary": "Reconstructing dynamic hand-object interactions from monocular videos is critical for dexterous manipulation data collection and creating realistic digital twins for robotics and VR. However, current methods face two prohibitive barriers: (1) reliance on neural rendering often yields fragmented, non-simulation-ready geometries under heavy occlusion, and (2) dependence on brittle Structure-from-Motion (SfM) initialization leads to frequent failures on in-the-wild footage. To overcome these limitations, we introduce AGILE, a robust framework that shifts the paradigm from reconstruction to agentic generation for interaction learning. First, we employ an agentic pipeline where a Vision-Language Model (VLM) guides a generative model to synthesize a complete, watertight object mesh with high-fidelity texture, independent of video occlusions. Second, bypassing fragile SfM entirely, we propose a robust anchor-and-track strategy. We initialize the object pose at a single interaction onset frame using a foundation model and propagate it temporally by leveraging the strong visual similarity between our generated asset and video observations. Finally, a contact-aware optimization integrates semantic, geometric, and interaction stability constraints to enforce physical plausibility. Extensive experiments on HO3D, DexYCB, and in-the-wild videos reveal that AGILE outperforms baselines in global geometric accuracy while demonstrating exceptional robustness on challenging sequences where prior art frequently collapses. By prioritizing physical validity, our method produces simulation-ready assets validated via real-to-sim retargeting for robotic applications.", "AI": {"tldr": "AGILE是一种从单目视频中重建手部与物体交互的方法，通过生成性管道和稳定的追踪策略提高了几何精度和鲁棒性。", "motivation": "当前方法在处理重叠遮挡时依赖神经渲染会导致碎片化几何结构，在真实世界视频上则因SfM初始化的脆弱性而经常失败。AGILE旨在克服这些问题。", "method": "采用视图-语言模型引导生成完整、无孔洞的对象网格，并使用一种稳定锚定和追踪策略，跳过易错的SfM初始步骤；同时通过接触感知优化整合语义、几何和交互稳定性约束以确保物理真实性。", "result": "实验表明AGILE在HO3D和DexYCB数据集以及真实世界视频上表现出色，在全局几何精度方面超越了基线方法，并且具有更高的鲁棒性。", "conclusion": "通过优先考虑物理有效性，AGILE能生成用于机器人应用的仿真就绪资产。"}}
{"id": "2602.04669", "pdf": "https://arxiv.org/pdf/2602.04669", "abs": "https://arxiv.org/abs/2602.04669", "authors": ["Xianbiao Qi", "Marco Chen", "Jiaquan Ye", "Yelin He", "Rong Xiao"], "title": "Delving into Muon and Beyond: Deep Analysis and Extensions", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "This paper studies matrix-based optimizers (e.g., Muon) from a spectral perspective and unifies a range of methods under a common spectral framework", "summary": "The Muon optimizer has recently attracted considerable attention for its strong empirical performance and use of orthogonalized updates on matrix-shaped parameters, yet its underlying mechanisms and relationship to adaptive optimizers such as Adam remain insufficiently understood. In this work, we aim to address these questions through a unified spectral perspective. Specifically, we view Muon as the p = 0 endpoint of a family of spectral transformations of the form U \\boldsymbolΣ^{p} V' , and consider additional variants with p = 1/2 , p = 1/4 , and p = 1 . These transformations are applied to both first-moment updates, as in momentum SGD, and to root-mean-square (RMS) normalized gradient updates as in Adam. To enable efficient computation, we develop a coupled Newton iteration that avoids explicit singular value decomposition. Across controlled experiments, we find that RMS-normalized updates yield more stable optimization than first-moment updates. Moreover, while spectral compression provides strong stabilization benefits under first-moment updates, the Muon update (p = 0) does not consistently outperform Adam. These results suggest that Muon is best understood as an effective form of spectral normalization, but not a universally superior optimization method. Our source code will be released at https://github.com/Ocram7/BeyondMuon.", "AI": {"tldr": "本文通过谱分析方法研究了Muon优化器，并探讨其与Adam等自适应优化器的关系，提出了一种新的计算方式以提升效率。", "motivation": "Muon优化器虽然表现出色但机制不明且未能充分理解，该文旨在从谱视角统一解释它的原理和与自适应优化器（如Adam）的关系。", "method": "将Muon看作是形式UΣ^pV'家族的一个p=0端点，并研究了不同参数值的变体。引入一种耦合牛顿迭代算法来避免显式奇异值分解，以提高计算效率。实验中比较了一阶矩更新和RMS归一化梯度更新的效果。", "result": "实验显示RMS归一化更新比一阶矩更新更加稳定优化；尽管在第一时刻更新上谱压缩提供了很好的稳定性提升，但Muon（p=0）并不能始终优于Adam。这表明Muon应该被理解为一种有效的谱规范化形式，而非一个普遍优越的优化方法。", "conclusion": "研究结果表明Muon是一种有效的谱规范化形式而不是一种普遍优越的优化器，在某些情况下其性能不及Adam。"}}
{"id": "2602.04663", "pdf": "https://arxiv.org/pdf/2602.04663", "abs": "https://arxiv.org/abs/2602.04663", "authors": ["Jaemoo Choi", "Yuchen Zhu", "Wei Guo", "Petr Molodyk", "Bo Yuan", "Jinbin Bai", "Yi Xin", "Molei Tao", "Yongxin Chen"], "title": "Rethinking the Design Space of Reinforcement Learning for Diffusion Models: On the Importance of Likelihood Estimation Beyond Loss Design", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 11 figures", "summary": "Reinforcement learning has been widely applied to diffusion and flow models for visual tasks such as text-to-image generation. However, these tasks remain challenging because diffusion models have intractable likelihoods, which creates a barrier for directly applying popular policy-gradient type methods. Existing approaches primarily focus on crafting new objectives built on already heavily engineered LLM objectives, using ad hoc estimators for likelihood, without a thorough investigation into how such estimation affects overall algorithmic performance. In this work, we provide a systematic analysis of the RL design space by disentangling three factors: i) policy-gradient objectives, ii) likelihood estimators, and iii) rollout sampling schemes. We show that adopting an evidence lower bound (ELBO) based model likelihood estimator, computed only from the final generated sample, is the dominant factor enabling effective, efficient, and stable RL optimization, outweighing the impact of the specific policy-gradient loss functional. We validate our findings across multiple reward benchmarks using SD 3.5 Medium, and observe consistent trends across all tasks. Our method improves the GenEval score from 0.24 to 0.95 in 90 GPU hours, which is $4.6\\times$ more efficient than FlowGRPO and $2\\times$ more efficient than the SOTA method DiffusionNFT without reward hacking.", "AI": {"tldr": "重新思考强化学习在扩散模型中的设计空间，特别是关于似然估计的重要性。", "motivation": "由于扩散模型的似然不可求解性，直接应用流行策略梯度方法面临挑战。现有方法主要集中在构建新的目标函数和使用临时似然估算器上，而未充分探究其对整体算法性能的影响。", "method": "提出了一种系统分析强化学习设计空间的方法，通过拆分三个因素：i)策略梯度目标，ii)似然估计器，iii)采样方案。展示了采用基于证据下界的模型似然估算器的有效性、效率和稳定性。", "result": "在多个奖励基准上验证了方法的发现，并观察到所有任务的一致趋势。该方法提高了GenEval分数，比FlowGRPO更高效4.6倍，比SOTA方法DiffusionNFT更高效2倍且无奖励作弊现象。", "conclusion": "研究表明，使用基于ELBO的似然估计器是强化学习优化成功的关键因素，而非特定策略梯度损失函数的影响更为重要。"}}
{"id": "2602.04657", "pdf": "https://arxiv.org/pdf/2602.04657", "abs": "https://arxiv.org/abs/2602.04657", "authors": ["Haokui Zhang", "Congyang Ou", "Dawei Yan", "Peng Wang", "Qingsen Yan", "Ying Li", "Rong Xiao", "Chunhua Shen"], "title": "PIO-FVLM: Rethinking Training-Free Visual Token Reduction for VLM Acceleration from an Inference-Objective Perspective", "categories": ["cs.CV"], "comment": null, "summary": "Recently, reducing redundant visual tokens in vision-language models (VLMs) to accelerate VLM inference has emerged as a hot topic. However, most existing methods rely on heuristics constructed based on inter-visual-token similarity or cross-modal visual-text similarity, which gives rise to certain limitations in compression performance and practical deployment. In contrast, we propose PIO-FVLM from the perspective of inference objectives, which transforms visual token compression into preserving output result invariance and selects tokens primarily by their importance to this goal. Specially, vision tokens are reordered with the guidance of token-level gradient saliency generated by our designed layer-local proxy loss, a coarse constraint from the current layer to the final result. Then the most valuable vision tokens are selected following the non-maximum suppression (NMS) principle. The proposed PIO-FVLM is training-free and compatible with FlashAttention, friendly to practical application and deployment. It can be deployed independently as an encoder-free method, or combined with encoder compression approaches like VisionZip for use as an encoder-involved method. On LLaVA-Next-7B, PIO-FVLM retains just 11.1% of visual tokens but maintains 97.2% of the original performance, with a 2.67$\\times$ prefill speedup, 2.11$\\times$ inference speedup, 6.22$\\times$ lower FLOPs, and 6.05$\\times$ reduced KV Cache overhead. Our code is available at https://github.com/ocy1/PIO-FVLM.", "AI": {"tldr": "PIO-FVLM提出了一种基于推断目标的无训练视觉令牌减少方法，以加速视觉语言模型的推理。", "motivation": "现有大多数依赖于令牌间相似性或跨模态视觉-文本相似性的方法存在压缩性能和实际部署方面的局限性。因此，从推断目标的角度出发，提出一种新的策略来选择对输出结果至关重要的视觉令牌。", "method": "使用设计的层本地代理损失生成令牌级别的梯度显著性，并据此重新排序视觉令牌；然后通过非极大值抑制原则选取最重要的视觉令牌，该方法支持独立部署或与编码器压缩方法结合使用。", "result": "PIO-FVLM在LLaVA-Next-7B上仅保留11.1%的视觉令牌，却保持了97.2%的原始性能，并实现了预填充速度提高2.67倍、推理速度提高2.11倍、FLOPs降低6.22倍以及KV Cache开销减少6.05倍。", "conclusion": "PIO-FVLM作为一种无训练且友好的视觉令牌压缩方法，展示了显著的加速效果和性能保持能力。"}}
{"id": "2602.04648", "pdf": "https://arxiv.org/pdf/2602.04648", "abs": "https://arxiv.org/abs/2602.04648", "authors": ["Alessandro Leanza", "Paolo Franceschi", "Blerina Spahiu", "Loris Roveda"], "title": "From Vision to Assistance: Gaze and Vision-Enabled Adaptive Control for a Back-Support Exoskeleton", "categories": ["cs.RO"], "comment": null, "summary": "Back-support exoskeletons have been proposed to mitigate spinal loading in industrial handling, yet their effectiveness critically depends on timely and context-aware assistance. Most existing approaches rely either on load-estimation techniques (e.g., EMG, IMU) or on vision systems that do not directly inform control. In this work, we present a vision-gated control framework for an active lumbar occupational exoskeleton that leverages egocentric vision with wearable gaze tracking. The proposed system integrates real-time grasp detection from a first-person YOLO-based perception system, a finite-state machine (FSM) for task progression, and a variable admittance controller to adapt torque delivery to both posture and object state. A user study with 15 participants performing stooping load lifting trials under three conditions (no exoskeleton, exoskeleton without vision, exoskeleton with vision) shows that vision-gated assistance significantly reduces perceived physical demand and improves fluency, trust, and comfort. Quantitative analysis reveals earlier and stronger assistance when vision is enabled, while questionnaire results confirm user preference for the vision-gated mode. These findings highlight the potential of egocentric vision to enhance the responsiveness, ergonomics, safety, and acceptance of back-support exoskeletons.", "AI": {"tldr": "提出了一种基于视觉和头部追踪的控制框架，以增强背支撑外骨骼在工业操作中的适应性和有效性。", "motivation": "现有背支撑外骨骼依赖于负载估计技术或视觉系统，但这些方法未能提供直接的信息用于控制系统。因此，研究提出了一个结合实时抓取检测、任务进展状态机和可变顺应性控制器的框架，以提高系统的响应速度和用户满意度。", "method": "采用了一种基于第一人称视角的YOLO感知系统来实现实时抓取检测，并通过有限状态机控制任务进程。此外，利用可变顺应性控制器根据用户的姿势和物体的状态调整扭矩输出。", "result": "用户研究显示，在有视觉辅助的情况下，背支撑外骨骼能够更好地减少体力负担并提高操作流畅度、信任感与舒适度。定量分析表明，启用视觉后可以获得更早且更强的辅助支持，问卷结果也证实了用户对这种模式的偏好。", "conclusion": "该研究表明，基于第一人称视角的视觉系统可以显著提升背支撑外骨骼在响应性、人体工程学、安全性和接受度方面的表现。"}}
{"id": "2602.04640", "pdf": "https://arxiv.org/pdf/2602.04640", "abs": "https://arxiv.org/abs/2602.04640", "authors": ["Tse-Hsun", "Chen"], "title": "Towards Structured, State-Aware, and Execution-Grounded Reasoning for Software Engineering Agents", "categories": ["cs.SE", "cs.AI"], "comment": "Position paper accepted in BoatSE", "summary": "Software Engineering (SE) agents have shown promising abilities in supporting various SE tasks. Current SE agents remain fundamentally reactive, making decisions mainly based on conversation history and the most recent response. However, this reactive design provides no explicit structure or persistent state within the agent's memory, making long-horizon reasoning challenging. As a result, SE agents struggle to maintain a coherent understanding across reasoning steps, adapt their hypotheses as new evidence emerges, or incorporate execution feedback into the mental reasoning model of the system state. In this position paper, we argue that, to further advance SE agents, we need to move beyond reactive behavior toward a structured, state-aware, and execution-grounded reasoning. We outline how explicit structure, persistent and evolving state, and the integration of execution-grounded feedback can help SE agents perform more coherent and reliable reasoning in long-horizon tasks. We also provide an initial roadmap for developing next-generation SE agents that can more effectively perform real-world tasks.", "AI": {"tldr": "本文探讨了软件工程代理的未来发展方向，提出从反应式行为向结构化、状态感知和执行基础推理转变的需求。", "motivation": "当前软件工程代理主要依赖对话历史进行决策，缺乏持久的状态维持和结构化的记忆，难以在长时间跨度的任务中保持一致性和可靠性。", "method": "本文没有具体的方法描述，而是提出了一种未来的发展方向和初步路线图，旨在推动下一代软件工程代理的开发。", "result": "尚未有明确的结果，但提出了一个关于如何改进软件工程代理的设计以增强其在复杂任务中的表现能力的概念框架。", "conclusion": "文章强调了将执行反馈、持久状态和结构化记忆集成到软件工程代理中对于提升它们处理长时序任务的能力的重要性。"}}
{"id": "2602.04635", "pdf": "https://arxiv.org/pdf/2602.04635", "abs": "https://arxiv.org/abs/2602.04635", "authors": ["Julia Kuhn", "Francesco Verdoja", "Tsvetomila Mihaylova", "Ville Kyrki"], "title": "Relational Scene Graphs for Object Grounding of Natural Language Commands", "categories": ["cs.RO"], "comment": "In review for RA-L", "summary": "Robots are finding wider adoption in human environments, increasing the need for natural human-robot interaction. However, understanding a natural language command requires the robot to infer the intended task and how to decompose it into executable actions, and to ground those actions in the robot's knowledge of the environment, including relevant objects, agents, and locations. This challenge can be addressed by combining the capabilities of Large language models (LLMs) to understand natural language with 3D scene graphs (3DSGs) for grounding inferred actions in a semantic representation of the environment. However, many 3DSGs lack explicit spatial relations between objects, even though humans often rely on these relations to describe an environment. This paper investigates whether incorporating open- or closed-vocabulary spatial relations into 3DSGs can improve the ability of LLMs to interpret natural language commands. To address this, we propose an LLM-based pipeline for target object grounding from open-vocabulary language commands and a vision language model (VLM)-based pipeline to add open-vocabulary spatial edges to 3DSGs from images captured while mapping. Finally, two LLMs are evaluated in a study assessing their performance on the downstream task of target object grounding. Our study demonstrates that explicit spatial relations improve the ability of LLMs to ground objects. Moreover, open-vocabulary relation generation with VLMs proves feasible from robot-captured images, but their advantage over closed-vocabulary relations is found to be limited.", "AI": {"tldr": "论文探讨了通过在场景图中加入空间关系来增强大型语言模型理解自然语言指令的能力。", "motivation": "机器人需要更好地理解和执行人类的自然语言命令，而现有的三维场景图缺乏明确的空间关系。这限制了机器人将任务分解为可执行动作并定位相关对象的能力。", "method": "提出了一种基于LLM的目标物体定位管道和一种基于VLM的方法来从图像中生成开放词汇空间边。两个LLM在目标物体定位的任务上进行了评估。", "result": "研究证明，明确的空间关系提高了LLMs对自然语言指令的理解能力。然而，基于VLM的开放词汇关系与封闭词汇关系相比并没有显著优势。", "conclusion": "引入空间关系可以提高机器人理解自然语言指令的能力。使用图像生成开放词汇空间边的方法是可行的，但相对于封闭词汇关系的优势有限。"}}
{"id": "2602.04634", "pdf": "https://arxiv.org/pdf/2602.04634", "abs": "https://arxiv.org/abs/2602.04634", "authors": ["Zelai Xu", "Zhexuan Xu", "Ruize Zhang", "Chunyang Zhu", "Shi Yu", "Weilin Liu", "Quanlu Zhang", "Wenbo Ding", "Chao Yu", "Yu Wang"], "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.", "AI": {"tldr": "WideSeek-R1研究了通过多智能体强化学习解决广义信息搜索任务的方法，提出了一种利用宽度扩展（即增加并行子代理数量）来提高性能的框架。", "motivation": "当前大语言模型的主要关注点是深度扩展，而随着任务范围的扩大，单一代理的能力局限性逐渐显现。因此，研究者希望通过宽度扩展和多智能体系统解决广义信息搜索中的组织能力瓶颈问题。", "method": "WideSeek-R1提出了一个基于强化学习训练的领导代理-子代理框架，该框架通过并行化工作来提高效率，并在包含20k广义信息搜索任务的数据集上对领导代理和子代理进行联合优化。", "result": "实验结果表明，WideSeek-R1-4B在WideSearch基准测试中达到了40.0%的项目F1得分，与单一代理DeepSeek-R1-671B相当。此外，随着并行子代理数量的增加，WideSeek-R1-4B的表现持续提升。", "conclusion": "研究证明了宽度扩展的有效性，并提出了一种通过多智能体强化学习解决广义信息搜索任务的新方法，展示了在实际应用中的潜力和优势。"}}
{"id": "2602.04632", "pdf": "https://arxiv.org/pdf/2602.04632", "abs": "https://arxiv.org/abs/2602.04632", "authors": ["Yi Wang", "Zhengxin Zhang", "Xiao Liu", "Chetan Arora", "John Grundy", "Thuong Hoang"], "title": "Discussing Your Needs in VR: A Novel Approach through Persona-based Stakeholder Role-Playing", "categories": ["cs.HC"], "comment": "IEEE VR 26 Poster", "summary": "In this study, we propose a novel approach that supports requirements discussions in virtual environments by automatically generating personas from real-time speech-to-text data. In our pilot experiment, 18 participants (14 from universities and 4 from IT companies) used the generated personas to discuss accessibility requirements within the virtual environment. Participants reported a relatively high level of satisfaction with the social presence and usability of the VR system. We also found that requirements discussions based on personas have a lower workload. Finally, we outline the main directions for future work.", "AI": {"tldr": "本文提出了一种在虚拟环境中通过生成的人物角色进行需求讨论的新方法。", "motivation": "为了支持虚拟环境中的需求讨论，减少工作量，并提高社会存在感和系统可用性。", "method": "自动从实时语音转文字数据中生成人物角色，参与者利用这些人物角色在虚拟环境中讨论无障碍需求。", "result": "参与者的满意度较高，基于人物角色的需求讨论降低了工作负荷。", "conclusion": "本文方法提高了虚拟环境中的社会存在感和系统可用性，并减少了需求讨论的工作量。未来将探讨进一步的方向。"}}
{"id": "2602.04631", "pdf": "https://arxiv.org/pdf/2602.04631", "abs": "https://arxiv.org/abs/2602.04631", "authors": ["Jan Michalczyk"], "title": "Radar-Inertial Odometry For Computationally Constrained Aerial Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Recently, the progress in the radar sensing technology consisting in the miniaturization of the packages and increase in measuring precision has drawn the interest of the robotics research community. Indeed, a crucial task enabling autonomy in robotics is to precisely determine the pose of the robot in space. To fulfill this task sensor fusion algorithms are often used, in which data from one or several exteroceptive sensors like, for example, LiDAR, camera, laser ranging sensor or GNSS are fused together with the Inertial Measurement Unit (IMU) measurements to obtain an estimate of the navigation states of the robot. Nonetheless, owing to their particular sensing principles, some exteroceptive sensors are often incapacitated in extreme environmental conditions, like extreme illumination or presence of fine particles in the environment like smoke or fog. Radars are largely immune to aforementioned factors thanks to the characteristics of electromagnetic waves they use. In this thesis, we present Radar-Inertial Odometry (RIO) algorithms to fuse the information from IMU and radar in order to estimate the navigation states of a (Uncrewed Aerial Vehicle) UAV capable of running on a portable resource-constrained embedded computer in real-time and making use of inexpensive, consumer-grade sensors. We present novel RIO approaches relying on the multi-state tightly-coupled Extended Kalman Filter (EKF) and Factor Graphs (FG) fusing instantaneous velocities of and distances to 3D points delivered by a lightweight, low-cost, off-the-shelf Frequency Modulated Continuous Wave (FMCW) radar with IMU readings. We also show a novel way to exploit advances in deep learning to retrieve 3D point correspondences in sparse and noisy radar point clouds.", "AI": {"tldr": "本文提出了基于雷达和惯性测量单元（IMU）融合的RIO算法，用于估计无人机的导航状态。", "motivation": "为了提高无人飞行器在复杂环境下的自主导航能力，尤其是极端照明条件或存在烟雾和雾等细颗粒物的情况下，研究提出了一种使用雷达与IMU数据融合的方法。", "method": "本文采用多态紧密耦合扩展卡尔曼滤波（EKF）和因子图方法来融合低成本FMCW雷达提供的3D点的速度、距离信息以及IMU读数。此外，还利用深度学习技术从稀疏且噪声大的雷达点云中提取三维点的对应关系。", "result": "所提出的方法能够在资源受限的嵌入式计算机上实现实时运行，并使用低成本、消费级传感器来估计无人机的导航状态。", "conclusion": "研究表明，基于雷达和IMU数据融合的方法能够有效地提升无人机在复杂环境中的定位精度与自主导航能力。"}}
{"id": "2602.04625", "pdf": "https://arxiv.org/pdf/2602.04625", "abs": "https://arxiv.org/abs/2602.04625", "authors": ["Roberto Ferroni", "Daniele Filippo Mauceri", "Jacopo Carpaneto", "Alessandra Pedrocchi", "Tommaso Proietti"], "title": "Can We Redesign a Shoulder Exosuit to Enhance Comfort and Usability Without Losing Assistance?", "categories": ["cs.RO"], "comment": null, "summary": "Reduced shoulder mobility limits upper-limb function and the performance of activities of daily living across a wide range of conditions. Wearable exosuits have shown promise in assisting arm elevation, reducing muscle effort, and supporting functional movements; however, comfort is rarely prioritized as an explicit design objective, despite it strongly affects real-life, long-term usage. This study presents a redesigned soft shoulder exosuit (Soft Shoulder v2) developed to address comfort-related limitations identified in our previous version, while preserving assistive performance. In parallel, assistance was also improved, shifting from the coronal plane to the sagittal plane to better support functionally relevant hand positioning. A controlled comparison between the previous (v1) and redesigned (v2) modules was conducted in eight healthy participants, who performed static holding, dynamic lifting, and a functional pick and place task. Muscle activity, kinematics, and user-reported outcomes were assessed. Both versions increased endurance time, reduced deltoid activation, and preserved transparency during unpowered shoulder elevation. However, the difference between them emerged most clearly during functional tasks and comfort evaluation. The redesigned module facilitated forward arm positioning and increased transverse plane mobility by up to 30 deg, without increasing muscular demand. User-reported outcomes further indicated a substantial improvement in wearability, with markedly lower perceived pressure and higher ratings in effectiveness, ease of use, and comfort compared to the previous design. Taken together, these findings show that targeted, user-centered design refinements can improve comfort and functional interaction without compromising assistive performance, advancing the development of soft exosuits suitable for prolonged and daily use.", "AI": {"tldr": "本文通过设计改进的肩部外骨骼（Soft Shoulder v2）来提高穿戴舒适性和功能性，同时保持辅助性能。", "motivation": "现有的可穿戴外骨骼在改善上肢功能和支持日常活动方面显示出潜力，但舒适性却很少被列为明确的设计目标，尽管它对长期使用有着重要影响。因此，研究旨在通过改进设计来解决这些问题。", "method": "研究人员开发了一个新的肩部外骨骼（Soft Shoulder v2），并在八名健康受试者中进行了对比实验，包括静态保持、动态提升和功能性抓取放置任务，并评估了肌肉活动、运动学以及用户报告的结果。", "result": "结果显示，新设计的模块能够在不增加肌肉需求的情况下支持功能相关的手部位置，并提高了侧向平面的移动性。此外，用户报告的新设计在穿戴舒适性和使用效果方面有了显著改善。", "conclusion": "这些发现表明，通过以用户为中心的设计改进可以提高舒适度和功能性交互，而不牺牲辅助性能，从而推动了适合长时间日常使用的软外骨骼的发展。"}}
{"id": "2602.04624", "pdf": "https://arxiv.org/pdf/2602.04624", "abs": "https://arxiv.org/abs/2602.04624", "authors": ["Raúl Jiménez Cruz", "César Torres-Huitzil", "Marco Franceschetti", "Ronny Seiger", "Luciano García-Bañuelos", "Barbara Weber"], "title": "A labeled dataset of simulated phlebotomy procedures for medical AI: polygon annotations for object detection and human-object interaction", "categories": ["cs.CV"], "comment": null, "summary": "This data article presents a dataset of 11,884 labeled images documenting a simulated blood extraction (phlebotomy) procedure performed on a training arm. Images were extracted from high-definition videos recorded under controlled conditions and curated to reduce redundancy using Structural Similarity Index Measure (SSIM) filtering. An automated face-anonymization step was applied to all videos prior to frame selection. Each image contains polygon annotations for five medically relevant classes: syringe, rubber band, disinfectant wipe, gloves, and training arm. The annotations were exported in a segmentation format compatible with modern object detection frameworks (e.g., YOLOv8), ensuring broad usability. This dataset is partitioned into training (70%), validation (15%), and test (15%) subsets and is designed to advance research in medical training automation and human-object interaction. It enables multiple applications, including phlebotomy tool detection, procedural step recognition, workflow analysis, conformance checking, and the development of educational systems that provide structured feedback to medical trainees. The data and accompanying label files are publicly available on Zenodo.", "AI": {"tldr": "本文介绍了用于医学AI的模拟静脉采血程序标注数据集，包含五类医疗相关对象的多边形注释。", "motivation": "该数据集旨在推进医学训练自动化及人机交互研究，支持工具检测、流程识别等工作应用。", "method": "从高清晰度视频中提取图像，并使用SSIM过滤减少冗余。对所有视频进行自动面部匿名化处理后选择帧并添加注释。", "result": "数据集包括11,884张标注图，分为训练（70%）、验证（15%）和测试（15%）三部分，并与现代目标检测框架兼容。", "conclusion": "该公开数据集为医学培训自动化及人机交互研究提供支持。"}}
{"id": "2602.04621", "pdf": "https://arxiv.org/pdf/2602.04621", "abs": "https://arxiv.org/abs/2602.04621", "authors": ["Yi Wang", "Ben Cheng", "Xiao Liu", "Chetan Arora", "John Grundy", "Thuong Hoang"], "title": "VRARE: Using Virtual Reality to Understand Accessibility Requirements of Color Blindness and Weakness", "categories": ["cs.HC", "cs.ET"], "comment": "IEEE VR 26 Poster", "summary": "In this paper, we developed a virtual reality (VR) system that can simulate color blindness and weakness. We built an immersive 3D web view interface where participants can discuss accessibility requirements for a fitness website projects within a virtual fitness environment. We conducted a pilot experiment involving 24 participants from six software teams, who used both VR and non-VR methods to understand color blindness and weakness requirements in a website project. Our findings indicate that using VR can provide several benefits for requirements activities, such as an improved user experience and reduced workload.", "AI": {"tldr": "本文开发了一个虚拟现实系统，用于模拟色盲和视力弱化的情况。", "motivation": "通过使用VR技术来研究网站项目中色盲与视觉弱化的可访问性需求，提升用户体验并减少工作负担", "method": "构建了沉浸式3D网络视图界面，并让参与者在虚拟健身环境中讨论相关要求。实验包括24名来自六个软件团队的成员。", "result": "结果显示VR技术能为需求活动提供多项益处，如改善用户使用体验和降低工作负荷", "conclusion": "结论是通过使用VR可以有效地理解和改进网站项目的可访问性需求"}}
{"id": "2602.04616", "pdf": "https://arxiv.org/pdf/2602.04616", "abs": "https://arxiv.org/abs/2602.04616", "authors": ["Luyi Sun", "Wei Xu", "Zaifeng Gao"], "title": "A Human-Centered Privacy Approach (HCP) to AI", "categories": ["cs.HC", "cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "As the paradigm of Human-Centered AI (HCAI) gains prominence, its benefits to society are accompanied by significant ethical concerns, one of which is the protection of individual privacy. This chapter provides a comprehensive overview of privacy within HCAI, proposing a human-centered privacy (HCP) framework, providing integrated solution from technology, ethics, and human factors perspectives. The chapter begins by mapping privacy risks across each stage of AI development lifecycle, from data collection to deployment and reuse, highlighting the impact of privacy risks on the entire system. The chapter then introduces privacy-preserving techniques such as federated learning and dif erential privacy. Subsequent chapters integrate the crucial user perspective by examining mental models, alongside the evolving regulatory and ethical landscapes as well as privacy governance. Next, advice on design guidelines is provided based on the human-centered privacy framework. After that, we introduce practical case studies across diverse fields. Finally, the chapter discusses persistent open challenges and future research directions, concluding that a multidisciplinary approach, merging technical, design, policy, and ethical expertise, is essential to successfully embed privacy into the core of HCAI, thereby ensuring these technologies advance in a manner that respects and ensures human autonomy, trust and dignity.", "AI": {"tldr": "提出了一种以人为本的隐私框架（HCP），从技术、伦理和人类因素的角度为人工智能提供全面的隐私解决方案。", "motivation": "随着以人为中心的人工智能（HCAI）范式的普及，其带来的社会利益伴随着重要的道德关切。其中最重要的一个问题是保护个人隐私。", "method": "该论文首先分析了人工智能开发周期中各阶段的数据收集、部署和重用的隐私风险。然后介绍了差分隐私与联邦学习等隐私保护技术，并通过研究用户的认知模型以及不断变化的伦理规范，提出了以人为本的设计指导方针并提供了实际案例。", "result": "提供了一个全面的人为因素视角下的隐私解决方案，整合了用户观点并对不同的应用场景进行了案例分析。", "conclusion": "论文指出，要成功地将隐私嵌入HCAI的核心中，需要一个跨学科的方法来融合技术、设计和政策方面的专业知识。"}}
{"id": "2602.04605", "pdf": "https://arxiv.org/pdf/2602.04605", "abs": "https://arxiv.org/abs/2602.04605", "authors": ["Rahul Bajaj", "Anuj Garg"], "title": "RexBERT: Context Specialized Bidirectional Encoders for E-commerce", "categories": ["cs.CL", "cs.AI"], "comment": "Blog: https://huggingface.co/blog/thebajajra/rexbert-encoders Models: https://huggingface.co/collections/thebajajra/rexbert Ecom-niverse Dataset: https://huggingface.co/datasets/thebajajra/Ecom-niverse", "summary": "Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BERT-style encoders designed specifically for e-commerce semantics. We make three contributions. First, we release Ecom-niverse, a 350 billion token corpus curated from diverse retail and shopping sources. We describe a modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present a reproducible pretraining recipe building on ModernBERT's architectural advances. The recipe consists of three phases: general pre-training, context extension, and annealed domain specialization. Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification, semantic similarity, and general natural language understanding tasks using e-commerce datasets. Despite having 2-3x fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long-context models on domain-specific benchmarks. Our results demonstrate that high quality in-domain data combined with a principled training approach provides a stronger foundation for e-commerce applications than indiscriminate scaling alone.", "AI": {"tldr": "开发了一种专门针对电子商务领域的BERT风格编码器RexBERT，并通过大规模电商数据集训练以提升其在相关任务上的表现。", "motivation": "一般用途的编码器由于是在通用语料库上训练，对于特定领域（如电子商务）的知识覆盖有限。因此需要一个专门设计用于处理电子商务场景的语言模型来更好地服务于这一领域的应用需求。", "method": "构建了Ecom-niverse数据集，包含350亿个标记，并提出了一种模块化的提取流程从各种零售和购物来源中获取电子商务内容；采用了基于ModernBERT架构改进的预训练方案，包括三个阶段：一般性预训练、上下文扩展以及渐进领域特化。", "result": "实验结果表明，RexBERT模型即使参数量较少也能在特定任务上超越更大规模的一般用途编码器，并且在某些基准测试中与现代长文本模型相当或更优。", "conclusion": "高质量的域内数据结合合理的训练方法为电子商务应用提供了比盲目扩展更好的基础。"}}
{"id": "2602.04600", "pdf": "https://arxiv.org/pdf/2602.04600", "abs": "https://arxiv.org/abs/2602.04600", "authors": ["Jialiang Li", "Yi Qiao", "Yunhan Guo", "Changwen Chen", "Wenzhao Lian"], "title": "Act, Sense, Act: Learning Non-Markovian Active Perception Strategies from Large-Scale Egocentric Human Data", "categories": ["cs.RO"], "comment": null, "summary": "Achieving generalizable manipulation in unconstrained environments requires the robot to proactively resolve information uncertainty, i.e., the capability of active perception. However, existing methods are often confined in limited types of sensing behaviors, restricting their applicability to complex environments. In this work, we formalize active perception as a non-Markovian process driven by information gain and decision branching, providing a structured categorization of visual active perception paradigms. Building on this perspective, we introduce CoMe-VLA, a cognitive and memory-aware vision-language-action (VLA) framework that leverages large-scale human egocentric data to learn versatile exploration and manipulation priors. Our framework integrates a cognitive auxiliary head for autonomous sub-task transitions and a dual-track memory system to maintain consistent self and environmental awareness by fusing proprioceptive and visual temporal contexts. By aligning human and robot hand-eye coordination behaviors in a unified egocentric action space, we train the model progressively in three stages. Extensive experiments on a wheel-based humanoid have demonstrated strong robustness and adaptability of our proposed method across diverse long-horizon tasks spanning multiple active perception scenarios.", "AI": {"tldr": "论文提出了一种认知和记忆增强的视觉语言行为框架，用于学习多样化的探索和操作先验。", "motivation": "现有的主动感知方法局限于有限类型的感测行为，在复杂环境中应用受限。该研究旨在解决这一问题，通过引入一种新的非马尔可夫过程来提高机器人的主动性感知能力。", "method": "提出了一种认知增强的视觉语言行动框架CoMe-VLA，并利用大规模的人类第一视角数据进行学习。该方法包括一个自主子任务转换的认知辅助头和一个双轨记忆系统，用于维持一致的自我意识和环境感知。", "result": "在轮式人形机器人上进行了广泛的实验，结果显示所提出的模型具有强大的鲁棒性和适应性，在多种主动感知场景下的长期任务中表现优异。", "conclusion": "该研究通过引入非马尔可夫过程及大规模人类数据训练的框架，显著提高了机器人的主动感知和操作能力。"}}
{"id": "2602.04598", "pdf": "https://arxiv.org/pdf/2602.04598", "abs": "https://arxiv.org/abs/2602.04598", "authors": ["Lucile Favero", "Juan Antonio Pérez-Ortiz", "Tanja Käser", "Nuria Oliver"], "title": "AI in Education Beyond Learning Outcomes: Cognition, Agency, Emotion, and Ethics", "categories": ["cs.HC"], "comment": null, "summary": "Artificial intelligence (AI) is rapidly being integrated into educational contexts, promising personalized support and increased efficiency. However, growing evidence suggests that the uncritical adoption of AI may produce unintended harms that extend beyond individual learning outcomes to affect broader societal goals. This paper examines the societal implications of AI in education through an integrative framework with four interrelated dimensions: cognition, agency, emotional well-being, and ethics. Drawing on research from education, cognitive science, psychology, and ethics, we synthesize existing evidence to show how AI-driven cognitive offloading, diminished learner agency, emotional disengagement, and surveillance-oriented practices can mutually reinforce one another. We argue that these dynamics risk undermining critical thinking, intellectual autonomy, emotional resilience, and trust, capacities that are foundational both for effective learning and also for democratic participation and informed civic engagement. Moreover, AI's impact is contingent on design and governance: pedagogically aligned, ethically grounded, and human-centered AI systems can scaffold effortful reasoning, support learner agency, and preserve meaningful social interaction. By integrating fragmented strands of prior research into a unified framework, this paper advances the discourse on responsible AI in education and offers actionable implications for educators, designers, and institutions. Ultimately, the paper contends that the central challenge is not whether AI should be used in education, but how it can be designed and governed to support learning while safeguarding the social and civic purposes of education.", "AI": {"tldr": "探讨AI在教育中的社会影响，通过认知、主体性、情感和伦理四个维度综合分析。", "motivation": "研究AI在教育中可能产生的潜在危害以及如何促进负责任的AI设计与治理以支持学习同时保护教育的社会和公民目的。", "method": "整合教育学、认知科学、心理学和伦理学的研究证据，通过跨学科视角评估AI的影响。", "result": "揭示了AI驱动的认知卸载、削弱学员主体性、情感脱钩以及监控实践如何相互强化，并可能危及批判性思维、自主学习能力等关键能力。", "conclusion": "强调教育中使用AI的核心挑战在于其设计与治理，以促进有益的学习体验同时维护社会和公民价值。"}}
{"id": "2602.04587", "pdf": "https://arxiv.org/pdf/2602.04587", "abs": "https://arxiv.org/abs/2602.04587", "authors": ["Jaeyoon Jung", "Yejun Yoon", "Seunghyun Yoon", "Kunwoo Park"], "title": "VILLAIN at AVerImaTeC: Verifying Image-Text Claims via Multi-Agent Collaboration", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "A system description paper for the AVerImaTeC shared task at the Ninth FEVER Workshop (co-located with EACL 2026)", "summary": "This paper describes VILLAIN, a multimodal fact-checking system that verifies image-text claims through prompt-based multi-agent collaboration. For the AVerImaTeC shared task, VILLAIN employs vision-language model agents across multiple stages of fact-checking. Textual and visual evidence is retrieved from the knowledge store enriched through additional web collection. To identify key information and address inconsistencies among evidence items, modality-specific and cross-modal agents generate analysis reports. In the subsequent stage, question-answer pairs are produced based on these reports. Finally, the Verdict Prediction agent produces the verification outcome based on the image-text claim and the generated question-answer pairs. Our system ranked first on the leaderboard across all evaluation metrics. The source code is publicly available at https://github.com/ssu-humane/VILLAIN.", "AI": {"tldr": "VILLAIN是一个多模态事实核查系统，通过基于提示的多代理协作验证图文声明的真实性。", "motivation": "为了提高图像文本声明的事实核查准确性，提出一种结合视觉和语言模型的多代理协作方法。", "method": "利用增强的知识库检索证据，并生成分析报告以识别关键信息；随后根据这些报告产生问答对；最后通过问答对生成最终判断结果。", "result": "该系统在所有评估指标上都取得了第一名的成绩。", "conclusion": "展示了VILLAIN的有效性，且代码已公开。"}}
{"id": "2602.04585", "pdf": "https://arxiv.org/pdf/2602.04585", "abs": "https://arxiv.org/abs/2602.04585", "authors": ["Marcin Możejko", "Dawid Uchal", "Krzysztof Gogolewski", "Piotr Kupidura", "Szymon Łukasik", "Jakub Giezgała", "Tomasz Nocoń", "Kacper Pietrzyk", "Robert Pieniuta", "Mateusz Sulimowicz", "Michal Orzyłowski", "Tomasz Siłkowski", "Karol Zagródka", "Eike Staub", "Ewa Szczurek"], "title": "ImmuVis: Hyperconvolutional Foundation Model for Imaging Mass Cytometry", "categories": ["cs.CV"], "comment": "17 pages, 6 figures", "summary": "We present ImmuVis, an efficient convolutional foundation model for imaging mass cytometry (IMC), a high-throughput multiplex imaging technology that handles molecular marker measurements as image channels and enables large-scale spatial tissue profiling. Unlike natural images, multiplex imaging lacks a fixed channel space, as real-world marker sets vary across studies, violating a core assumption of standard vision backbones. To address this, ImmuVis introduces marker-adaptive hyperconvolutions that generate convolutional kernels from learned marker embeddings, enabling a single model to operate on arbitrary measured marker subsets without retraining. We pretrain ImmuVis on the largest to-date dataset, IMC17M (28 cohorts, 24,405 images, 265 markers, over 17M patches), using self-supervised masked reconstruction. ImmuVis outperforms SOTA baselines and ablations in virtual staining and downstream classification tasks at substantially lower compute cost than transformer-based alternatives, and is the sole model that provides calibrated uncertainty via a heteroscedastic likelihood objective. These results position ImmuVis as a practical, efficient foundation model for real-world IMC modeling.", "AI": {"tldr": "提出ImmuVis模型，用于成像质谱细胞学的高效卷积基础模型。", "motivation": "传统视觉骨干网无法处理多光谱成像中变化的标记通道空间问题，为此需要开发适应性更强的方法。", "method": "引入自适应超卷积方法生成卷积核，并通过大规模数据预训练实现泛化能力提升。", "result": "模型在虚拟染色和下游分类任务上优于现有最佳基线方法，并且计算成本更低。", "conclusion": "ImmuVis是首个为实际IMC建模提供校准不确定性的高效基础模型。"}}
{"id": "2602.04584", "pdf": "https://arxiv.org/pdf/2602.04584", "abs": "https://arxiv.org/abs/2602.04584", "authors": ["Mahmoud Z. A. Wahba", "Francesco Barbato", "Sara Baldoni", "Federica Battisti"], "title": "SalFormer360: a transformer-based saliency estimation model for 360-degree videos", "categories": ["cs.CV"], "comment": null, "summary": "Saliency estimation has received growing attention in recent years due to its importance in a wide range of applications. In the context of 360-degree video, it has been particularly valuable for tasks such as viewport prediction and immersive content optimization. In this paper, we propose SalFormer360, a novel saliency estimation model for 360-degree videos built on a transformer-based architecture. Our approach is based on the combination of an existing encoder architecture, SegFormer, and a custom decoder. The SegFormer model was originally developed for 2D segmentation tasks, and it has been fine-tuned to adapt it to 360-degree content. To further enhance prediction accuracy in our model, we incorporated Viewing Center Bias to reflect user attention in 360-degree environments. Extensive experiments on the three largest benchmark datasets for saliency estimation demonstrate that SalFormer360 outperforms existing state-of-the-art methods. In terms of Pearson Correlation Coefficient, our model achieves 8.4% higher performance on Sport360, 2.5% on PVS-HM, and 18.6% on VR-EyeTracking compared to previous state-of-the-art.", "AI": {"tldr": "提出了一种基于Transformer架构的用于360度视频的新型注意力估计模型SalFormer360。", "motivation": "在360度视频中，注意力估计对于任务如视窗预测和沉浸式内容优化非常有价值。为了提高这些任务的效果，设计了专门针对360度视频的内容适应性Transformer模型。", "method": "采用SegFormer作为基础编码器架构并添加自定义解码器来构建SalFormer360，并引入观看中心偏置以更好地反映用户在全景环境中的注意力分布。", "result": "实验结果显示，与现有最佳方法相比，SalFormer360在Sport360、PVS-HM和VR-EyeTracking三个基准数据集上的皮尔逊相关系数分别提高了8.4%、2.5%和18.6%。", "conclusion": "SalFormer360通过引入Transformer架构并适应性地调整观看中心偏置，在360度视频注意力估计任务上取得了显著的性能提升。"}}
{"id": "2602.04583", "pdf": "https://arxiv.org/pdf/2602.04583", "abs": "https://arxiv.org/abs/2602.04583", "authors": ["Gabriele Magrini", "Federico Becattini", "Niccolò Biondi", "Pietro Pala"], "title": "PEPR: Privileged Event-based Predictive Regularization for Domain Generalization", "categories": ["cs.CV"], "comment": null, "summary": "Deep neural networks for visual perception are highly susceptible to domain shift, which poses a critical challenge for real-world deployment under conditions that differ from the training data. To address this domain generalization challenge, we propose a cross-modal framework under the learning using privileged information (LUPI) paradigm for training a robust, single-modality RGB model. We leverage event cameras as a source of privileged information, available only during training. The two modalities exhibit complementary characteristics: the RGB stream is semantically dense but domain-dependent, whereas the event stream is sparse yet more domain-invariant. Direct feature alignment between them is therefore suboptimal, as it forces the RGB encoder to mimic the sparse event representation, thereby losing semantic detail. To overcome this, we introduce Privileged Event-based Predictive Regularization (PEPR), which reframes LUPI as a predictive problem in a shared latent space. Instead of enforcing direct cross-modal alignment, we train the RGB encoder with PEPR to predict event-based latent features, distilling robustness without sacrificing semantic richness. The resulting standalone RGB model consistently improves robustness to day-to-night and other domain shifts, outperforming alignment-based baselines across object detection and semantic segmentation.", "AI": {"tldr": "本文提出了PEPR框架，通过事件相机提供的特权信息来增强RGB模型在域泛化中的鲁棒性。", "motivation": "深度神经网络在视觉感知任务中容易受到域偏移的影响，这使得其难以在与训练数据不同的条件下进行部署。为了解决这一问题，文章提出了一个跨模态的框架，以提高单一模态RGB模型的鲁棒性。", "method": "该方法引入了基于特权事件预测正则化的PEPR技术，在LUPI范式下利用事件相机提供的只在训练时可用的信息，通过预测共享潜在空间中的事件特征来增强RGB编码器的鲁棒性而不牺牲语义丰富度。", "result": "实验结果表明，采用PEPR方法可以有效提高模型对昼夜变化以及其他域偏移的鲁棒性，在目标检测和语义分割任务上优于基于对齐的方法。", "conclusion": "文章通过引入特权事件预测正则化技术成功地增强了RGB模型在不同环境下的泛化能力。"}}
{"id": "2602.04582", "pdf": "https://arxiv.org/pdf/2602.04582", "abs": "https://arxiv.org/abs/2602.04582", "authors": ["Yannik Stradmann", "Johannes Schemmel", "Mihai A. Petrovici", "Laura Kriener"], "title": "Real-time processing of analog signals on accelerated neuromorphic hardware", "categories": ["cs.NE"], "comment": "6 pages, 5 figures", "summary": "Sensory processing with neuromorphic systems is typically done by using either event-based sensors or translating input signals to spikes before presenting them to the neuromorphic processor. Here, we offer an alternative approach: direct analog signal injection eliminates superfluous and power-intensive analog-to-digital and digital-to-analog conversions, making it particularly suitable for efficient near-sensor processing. We demonstrate this by using the accelerated BrainScaleS-2 mixed-signal neuromorphic research platform and interfacing it directly to microphones and a servo-motor-driven actuator. Utilizing BrainScaleS-2's 1000-fold acceleration factor, we employ a spiking neural network to transform interaural time differences into a spatial code and thereby predict the location of sound sources. Our primary contributions are the first demonstrations of direct, continuous-valued sensor data injection into the analog compute units of the BrainScaleS-2 ASIC, and actuator control using its embedded microprocessors. This enables a fully on-chip processing pipeline$\\unicode{x2014}$from sensory input handling, via spiking neural network processing to physical action. We showcase this by programming the system to localize and align a servo motor with the spatial direction of transient noise peaks in real-time.", "AI": {"tldr": "该论文展示了在加速类脑硬件上实现对模拟信号的实时处理，并通过直接注入连续值传感器数据到BrainScaleS-2芯片中的类比运算单元，实现了从感官输入处理到物理动作控制的全片上处理流水线。", "motivation": "为了提高近端传感器处理效率，减少功率密集型模数和数模转换的过程，本文提出了一种新的方法：直接将模拟信号注入加速类脑硬件中进行处理。", "method": "利用BrainScaleS-2加速类脑平台的1000倍加速因子，通过一个尖峰神经网络来转化耳间时间差异为空间编码，并预测声音源的位置。此外还展示了使用嵌入式微处理器控制执行器的操作。", "result": "首次成功地将连续值传感器数据直接注入BrainScaleS-2芯片中的类比运算单元中进行处理，实现了通过尖峰神经网络处理后的信号来实时调整伺服电机位置的任务。", "conclusion": "展示了在加速类脑硬件上实现对模拟信号的高效处理，并提出了从感官输入到物理动作控制的全片上处理流水线的新思路。"}}
{"id": "2602.04581", "pdf": "https://arxiv.org/pdf/2602.04581", "abs": "https://arxiv.org/abs/2602.04581", "authors": ["Debargha Ganguly", "Sreehari Sankar", "Biyao Zhang", "Vikash Singh", "Kanan Gupta", "Harshini Kavuru", "Alan Luo", "Weicong Chen", "Warren Morningstar", "Raghu Machiraju", "Vipin Chaudhary"], "title": "Trust The Typical", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "Current approaches to LLM safety fundamentally rely on a brittle cat-and-mouse game of identifying and blocking known threats via guardrails. We argue for a fresh approach: robust safety comes not from enumerating what is harmful, but from deeply understanding what is safe. We introduce Trust The Typical (T3), a framework that operationalizes this principle by treating safety as an out-of-distribution (OOD) detection problem. T3 learns the distribution of acceptable prompts in a semantic space and flags any significant deviation as a potential threat. Unlike prior methods, it requires no training on harmful examples, yet achieves state-of-the-art performance across 18 benchmarks spanning toxicity, hate speech, jailbreaking, multilingual harms, and over-refusal, reducing false positive rates by up to 40x relative to specialized safety models. A single model trained only on safe English text transfers effectively to diverse domains and over 14 languages without retraining. Finally, we demonstrate production readiness by integrating a GPU-optimized version into vLLM, enabling continuous guardrailing during token generation with less than 6% overhead even under dense evaluation intervals on large-scale workloads.", "AI": {"tldr": "介绍了一个名为Trust The Typical（T3）的新框架，该框架通过将安全性视为离群值检测问题来识别潜在威胁，而无需使用有害示例进行训练。", "motivation": "现有的大型语言模型安全方法依赖于不断识别和阻止已知威胁的猫捉老鼠游戏。作者提出了一种新的方法：从深入理解什么是安全的角度出发，而不是枚举什么是有害的行为来实现稳健的安全性。", "method": "T3框架通过学习语义空间中可接受提示的分布，并将任何显著偏离视为潜在威胁来进行离群值检测。这种方法不需要训练有害示例即可运行。", "result": "在18个涵盖毒性、仇恨言论、越狱行为、多语言危害和过度拒绝等方面的基准测试上，T3的表现优于专门的安全模型，减少了多达40倍的假阳性率。一个仅使用安全英文文本训练的单一模型可以有效地转移到各种领域以及超过14种语言中而无需重新训练。", "conclusion": "作者展示了该方法在大规模工作负载下的生产就绪性，并将其GPU优化版本集成到vLLM中，在连续生成期间提供持续的安全保障，即使在密集评估间隔下也仅有不到6%的开销。"}}
{"id": "2602.04575", "pdf": "https://arxiv.org/pdf/2602.04575", "abs": "https://arxiv.org/abs/2602.04575", "authors": ["Jiaheng Liu", "Yuanxing Zhang", "Shihao Li", "Xinping Lei"], "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration", "categories": ["cs.AI"], "comment": null, "summary": "For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \\textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows. Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.", "AI": {"tldr": "提出了Vibe AIGC，一种新的内容生成范式，通过代理协调解决意图执行差距问题。", "motivation": "当前的模型中心化AI生成方法遇到了使用性瓶颈，即创作者意图与单次模型随机性质之间的差距。", "method": "引入了Vibe AIGC新范式，用户作为指挥官提供高级表示（Vibe），系统架构师将其分解为可执行、可验证和适应性的代理管道。", "result": "通过逻辑协调而非随机推断，Vibe AIGC弥合了人类想象与机器执行之间的差距。", "conclusion": "认为这种转变将重新定义人机协作经济，使AI从脆弱的推理引擎转变为系统级工程伙伴。"}}
{"id": "2602.04572", "pdf": "https://arxiv.org/pdf/2602.04572", "abs": "https://arxiv.org/abs/2602.04572", "authors": ["Niv Fono", "Yftah Ziser", "Omer Ben-Porat"], "title": "From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "While Generative AI (GenAI) systems draw users away from (Q&A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.", "AI": {"tldr": "该论文提出了一种框架，通过模拟生成式AI系统和在线论坛之间的协作关系，解决AI系统依赖论坛数据却又将用户从这些平台上引导开去的问题。", "motivation": "由于生成式AI（GenAI）系统吸引走了原本可能在问答论坛上提问的用户，同时又需要这些平台产生的数据来提高自身的性能。作者旨在探索一种既能促进AI发展又能维护知识共享有效性的机制。", "method": "通过使用真实的Stack Exchange数据和常见的LLM进行模拟实验，研究者构建了一个包括非货币交换、信息不对称以及动机错配在内的协作框架。", "result": "结果表明，虽然存在动机上的不一致，但参与者仍能实现理想完全信息情景下约一半的效用。这证明了双方合作的可能性。", "conclusion": "论文展示了AI系统和人类知识平台之间可持续性合作的潜力，为未来的合作机制提供了理论依据和支持"}}
{"id": "2602.04566", "pdf": "https://arxiv.org/pdf/2602.04566", "abs": "https://arxiv.org/abs/2602.04566", "authors": ["Hrishikesh Dutta", "Roberto Minerva", "Noel Crespi"], "title": "Dual Mind World Model Inspired Network Digital Twin for Access Scheduling", "categories": ["cs.NI", "cs.AI", "cs.MA"], "comment": null, "summary": "Emerging networked systems such as industrial IoT and real-time cyber-physical infrastructures demand intelligent scheduling strategies capable of adapting to dynamic traffic, deadlines, and interference constraints. In this work, we present a novel Digital Twin-enabled scheduling framework inspired by Dual Mind World Model (DMWM) architecture, for learning-informed and imagination-driven network control. Unlike conventional rule-based or purely data-driven policies, the proposed DMWM combines short-horizon predictive planning with symbolic model-based rollout, enabling the scheduler to anticipate future network states and adjust transmission decisions accordingly. We implement the framework in a configurable simulation testbed and benchmark its performance against traditional heuristics and reinforcement learning baselines under varied traffic conditions. Our results show that DMWM achieves superior performance in bursty, interference-limited, and deadline-sensitive environments, while maintaining interpretability and sample efficiency. The proposed design bridges the gap between network-level reasoning and low-overhead learning, marking a step toward scalable and adaptive NDT-based network optimization.", "AI": {"tldr": "提出了一种基于双脑模型架构的数字孪生网络调度框架，能够学习并预测未来的网络状态以优化传输决策。", "motivation": "新兴网络系统需要智能适应动态流量、期限和干扰约束的调度策略。传统的规则基或数据驱动方法存在局限性，缺乏对未来网络状态的学习与预测能力。", "method": "引入了基于双脑模型架构（DMWM）的设计框架，结合短期预测规划和符号模型回放机制，实现对未来的预见性和调整传输决策的能力。并通过仿真测试验证其性能。", "result": "实验表明，在突发流量、干扰限制以及时间敏感环境下，所提方法相比传统启发式算法与强化学习基准表现更优，并具备可解释性及样本效率。", "conclusion": "该设计实现了网络层级推理和低开销学习之间的桥梁，为基于数字孪生的网络优化提供了一种可行方案。"}}
{"id": "2602.04565", "pdf": "https://arxiv.org/pdf/2602.04565", "abs": "https://arxiv.org/abs/2602.04565", "authors": ["Guanzhou Lan", "Chenyi Liao", "Yuqi Yang", "Qianli Ma", "Zhigang Wang", "Dong Wang", "Bin Zhao", "Xuelong Li"], "title": "Understanding Degradation with Vision Language Model", "categories": ["cs.CV"], "comment": "17 pages", "summary": "Understanding visual degradations is a critical yet challenging problem in computer vision. While recent Vision-Language Models (VLMs) excel at qualitative description, they often fall short in understanding the parametric physics underlying image degradations. In this work, we redefine degradation understanding as a hierarchical structured prediction task, necessitating the concurrent estimation of degradation types, parameter keys, and their continuous physical values. Although these sub-tasks operate in disparate spaces, we prove that they can be unified under one autoregressive next-token prediction paradigm, whose error is bounded by the value-space quantization grid. Building on this insight, we introduce DU-VLM, a multimodal chain-of-thought model trained with supervised fine-tuning and reinforcement learning using structured rewards. Furthermore, we show that DU-VLM can serve as a zero-shot controller for pre-trained diffusion models, enabling high-fidelity image restoration without fine-tuning the generative backbone. We also introduce \\textbf{DU-110k}, a large-scale dataset comprising 110,000 clean-degraded pairs with grounded physical annotations. Extensive experiments demonstrate that our approach significantly outperforms generalist baselines in both accuracy and robustness, exhibiting generalization to unseen distributions.", "AI": {"tldr": "本文重新定义了视觉退化理解为一个分层结构预测任务，并提出了DU-VLM模型，该模型能够作为零样本控制器用于预训练的扩散模型中实现高保真图像修复。", "motivation": "现有的Vision-Language Model（VLM）虽然在描述方面表现出色，但在理解和解释图像降级背后的物理参数上表现不佳。因此，作者希望重新定义和解决这个问题以提高理解效果。", "method": "通过将退化理解任务视为一个分层结构预测问题，并使用监督微调与强化学习的结合来训练DU-VLM模型，该模型可以作为零样本控制器操作预训练扩散模型。", "result": "实验结果表明，所提出的方法在准确性和鲁棒性上都显著优于通用基线方法，并且能够泛化到未见过的数据分布。", "conclusion": "本文通过引入分层结构预测任务和DU-VLM模型，解决了视觉退化理解的问题，同时展示了一种新的图像修复方式，即无需微调生成模型的零样本控制器方法。"}}
{"id": "2602.04549", "pdf": "https://arxiv.org/pdf/2602.04549", "abs": "https://arxiv.org/abs/2602.04549", "authors": ["Cem Eteke", "Enzo Tartaglione"], "title": "Nix and Fix: Targeting 1000x Compression of 3D Gaussian Splatting with Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) revolutionized novel view rendering. Instead of inferring from dense spatial points, as implicit representations do, 3DGS uses sparse Gaussians. This enables real-time performance but increases space requirements, hindering applications such as immersive communication. 3DGS compression emerged as a field aimed at alleviating this issue. While impressive progress has been made, at low rates, compression introduces artifacts that degrade visual quality significantly. We introduce NiFi, a method for extreme 3DGS compression through restoration via artifact-aware, diffusion-based one-step distillation. We show that our method achieves state-of-the-art perceptual quality at extremely low rates, down to 0.1 MB, and towards 1000x rate improvement over 3DGS at comparable perceptual performance. The code will be open-sourced upon acceptance.", "AI": {"tldr": "本文提出了一种名为NiFi的方法，通过使用扩散模型的一步蒸馏技术来实现极端的3DGS压缩，并在极低的数据速率下保持了感知质量。", "motivation": "三维高斯点云表示虽然实现了实时性能，但空间需求大。为解决这一问题，该文提出了一种名为NiFi的方法以达到极致的压缩比同时保持视觉质量。", "method": "本文通过采用扩散模型的一步蒸馏技术进行修复，提出了一个用于极端3DGS压缩的新方法（称为NiFi），这种方法能够在极低的数据速率下恢复高质量的3D场景表示。", "result": "该论文的方法在0.1MB的超低数据率下达到了感知质量的最佳效果，并且实现了与原始3DGS相当的视觉质量下的1000倍压缩率提升。", "conclusion": "NiFi方法成功地解决了三维高斯点云表示的空间需求问题，在极低的数据速率下保持了高质量，为沉浸式通信等应用提供了可能。"}}
{"id": "2602.04547", "pdf": "https://arxiv.org/pdf/2602.04547", "abs": "https://arxiv.org/abs/2602.04547", "authors": ["Luca Zedda", "Andrea Loddo", "Cecilia Di Ruberto"], "title": "OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 4 figures, 12 tables", "summary": "Radiological analysis increasingly benefits from pretrained visual representations that can support heterogeneous downstream tasks across imaging modalities. In this work, we introduce OmniRad, a self-supervised radiological foundation model pretrained on 1.2 million medical images, designed with radiology-inspired principles emphasizing representation reuse and cross-task transferability. We evaluate the pretrained encoder under multiple downstream adaptation regimes, including lightweight task-specific adapters with a frozen backbone as well as full end-to-end fine-tuning for classification, allowing us to assess both representation quality and task-specific performance. OmniRad is evaluated on a broad suite of public benchmarks spanning classification and segmentation across multiple modalities. On the MedMNISTv2 collection, OmniRad improves classification F1 by up to 2.05% over competing foundation models. For dense prediction, OmniRad attains mean Dice score improvements across six MedSegBench datasets when using frozen representations. Qualitative analyses and latent-space visualizations suggest improved feature clustering and modality-related separation.", "AI": {"tldr": "OmniRad是一款基于自监督学习的放射学基础模型，旨在通过预训练提升多任务医学图像分析的表现。", "motivation": "为了提高不同成像模态下的异构下游任务的表现，引入了一种新的方法来利用预训练视觉表征支持放射学分析。", "method": "OmniRad在120万张医疗影像上进行自监督学习，设计中强调了重用表示和跨任务传递性。评估方式包括轻量级的特定任务适配器以及端到端微调分类。", "result": "相比竞争基础模型，OmniRad在MedMNISTv2上的分类F1得分提高了最多2.05%。对于密集预测，在六个MedSegBench数据集中使用冻结表示时达到了平均Dice分数的提高。质化分析和潜在空间可视化显示了改进的特征聚类和模态相关的分离。", "conclusion": "OmniRad通过预训练提供了高质量的表示，并在广泛的公共基准测试中展示了优秀的任务特定性能，表明其强大的跨任务传递性。"}}
{"id": "2602.04542", "pdf": "https://arxiv.org/pdf/2602.04542", "abs": "https://arxiv.org/abs/2602.04542", "authors": ["Sander de Haan", "Yassine Taoudi-Benchekroun", "Pau Vilimelis Aceituno", "Benjamin F. Grewe"], "title": "Continual Learning through Control Minimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Catastrophic forgetting remains a fundamental challenge for neural networks when tasks are trained sequentially. In this work, we reformulate continual learning as a control problem where learning and preservation signals compete within neural activity dynamics. We convert regularization penalties into preservation signals that protect prior-task representations. Learning then proceeds by minimizing the control effort required to integrate new tasks while competing with the preservation of prior tasks. At equilibrium, the neural activities produce weight updates that implicitly encode the full prior-task curvature, a property we term the continual-natural gradient, requiring no explicit curvature storage. Experiments confirm that our learning framework recovers true prior-task curvature and enables task discrimination, outperforming existing methods on standard benchmarks without replay.", "AI": {"tldr": "本文通过将连续学习重新表述为一个控制问题，提出了一个新的学习框架，该框架能够在引入新任务时最小化对先前任务表示的影响。", "motivation": "解决神经网络在顺序任务训练中遇到的灾难性遗忘问题。", "method": "将正则化惩罚转化为保护先前任务表示的保留信号，并通过最小化所需的控制努力来整合新任务来进行学习。这种方法不需要显式存储先前任务的曲率，而是隐含编码在权重更新中。", "result": "实验表明该框架能够恢复真实的先前任务曲率并实现任务区分，在标准基准测试中超越了现有的方法而无需重播机制。", "conclusion": "提出的方法有效缓解了连续学习中的灾难性遗忘问题，并且性能优越于现有技术。"}}
{"id": "2602.04541", "pdf": "https://arxiv.org/pdf/2602.04541", "abs": "https://arxiv.org/abs/2602.04541", "authors": ["Gang Lin", "Dongfang Li", "Zhuoen Chen", "Yukun Shi", "Xuhui Chen", "Baotian Hu", "Min Zhang"], "title": "LycheeDecode: Accelerating Long-Context LLM Inference via Hybrid-Head Sparse Decoding", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR 2026", "summary": "The proliferation of long-context large language models (LLMs) exposes a key bottleneck: the rapidly expanding key-value cache during decoding, which imposes heavy memory and latency costs. While recent approaches attempt to alleviate this by sharing a single set of crucial tokens across layers, such coarse-grained sharing undermines model performance by neglecting the functional diversity of attention heads. To address this, we propose LycheeDecode, an efficient decoding method centered on a fine-grained hybrid-head attention mechanism that employs a hardware-efficient top-k selection strategy. Specifically, the novel HardKuma-based mechanism partitions attention heads into a small subset of retrieval heads that dynamically identify crucial tokens and a majority of sparse heads that reuse them for efficient computation. Through extensive experiments on leading models like Llama3 and Qwen3 across diverse benchmarks for long-context understanding (e.g., LongBench, RULER) and complex reasoning (e.g., AIME24, OlympiadBench), we demonstrate that LycheeDecode achieves generative quality comparable to, and at times surpassing even the full-attention baseline. Crucially, this is accomplished with up to a 2.7x speedup at a 128K context length. By preserving the functional diversity of attention heads, our fine-grained strategy overcomes the performance bottlenecks of existing methods, providing a powerful and validated pathway to both efficient and high-quality long-context LLM inference.", "AI": {"tldr": "提出了一种新的解码方法LycheeDecode，用于加速长上下文语言模型的推理。", "motivation": "当前长上下文大语言模型在解码过程中会面临内存和延迟成本增加的问题。现有尝试通过粗粒度共享关键令牌来解决该问题的方法影响了模型性能。", "method": "提出了一种基于细粒度混合头注意力机制的新方法LycheeDecode，利用高效的top-k选择策略进行硬件优化。此方法将注意头分为检索头和稀疏头，动态识别重要令牌并通过重用它们提高计算效率。", "result": "通过在Llama3、Qwen3等模型上的大量实验表明，在长上下文理解和复杂推理任务中，LycheeDecode的生成质量可与全注意力基线相媲美甚至超越，并且实现了高达2.7倍的速度提升。", "conclusion": "该方法克服了现有粗粒度共享令牌策略造成的性能瓶颈问题，为高效高质量地进行长上下文大语言模型推理提供了一条有力的道路。"}}
{"id": "2602.04540", "pdf": "https://arxiv.org/pdf/2602.04540", "abs": "https://arxiv.org/abs/2602.04540", "authors": ["Saleh Afzoon", "Amin Beheshti", "Usman Naseem"], "title": "PersoPilot: An Adaptive AI-Copilot for Transparent Contextualized Persona Classification and Personalized Response Generation", "categories": ["cs.HC", "cs.CL"], "comment": "Accepted for the Demo Track at the IEEE International Conference on Data Mining (ICDM) 2025", "summary": "Understanding and classifying user personas is critical for delivering effective personalization. While persona information offers valuable insights, its full potential is realized only when contextualized, linking user characteristics with situational context to enable more precise and meaningful service provision. Existing systems often treat persona and context as separate inputs, limiting their ability to generate nuanced, adaptive interactions. To address this gap, we present PersoPilot, an agentic AI-Copilot that integrates persona understanding with contextual analysis to support both end users and analysts. End users interact through a transparent, explainable chat interface, where they can express preferences in natural language, request recommendations, and receive information tailored to their immediate task. On the analyst side, PersoPilot delivers a transparent, reasoning-powered labeling assistant, integrated with an active learning-driven classification process that adapts over time with new labeled data. This feedback loop enables targeted service recommendations and adaptive personalization, bridging the gap between raw persona data and actionable, context-aware insights. As an adaptable framework, PersoPilot is applicable to a broad range of service personalization scenarios.", "AI": {"tldr": "PersoPilot是一种适应性AI副驾，用于透明化的个性化响应生成和情境化人格分类。", "motivation": "当前系统未能有效将用户的人格信息与情境结合，从而限制了提供精准个性服务的能力。因此，设计了一种能整合两者并支持交互的智能系统。", "method": "提出了一个集成人格理解和情境分析的框架PersoPilot，并通过自然语言界面实现用户的互动和偏好表达，同时为分析师提供透明化的标签助手和支持主动学习的过程。", "result": "该研究实现了能够根据用户反馈进行自我适应并生成个性服务建议的能力，适用于广泛的服务个性化场景。", "conclusion": "PersoPilot作为一种灵活框架，在将人格数据转化为情境化洞察和实现精准推荐方面展现了其潜力。"}}
{"id": "2602.04535", "pdf": "https://arxiv.org/pdf/2602.04535", "abs": "https://arxiv.org/abs/2602.04535", "authors": ["Xuenan Xu", "Yiming Ren", "Liwei Liu", "Wen Wu", "Baoxiang Li", "Chaochao Lu", "Shuai Wang", "Chao Zhang"], "title": "HoliAntiSpoof: Audio LLM for Holistic Speech Anti-Spoofing", "categories": ["cs.SD"], "comment": null, "summary": "Recent advances in speech synthesis and editing have made speech spoofing increasingly challenging. However, most existing methods treat spoofing as binary classification, overlooking that diverse spoofing techniques manipulate multiple, coupled speech attributes and their semantic effects. In this paper, we introduce HoliAntiSpoof, the first audio large language model (ALLM) framework for holistic speech anti-spoofing analysis. HoliAntiSpoof reformulates spoofing analysis as a unified text generation task, enabling joint reasoning over spoofing methods, affected speech attributes, and their semantic impacts. To support semantic-level analysis, we introduce DailyTalkEdit, a new anti-spoofing benchmark that simulates realistic conversational manipulations and provides annotations of semantic influence. Extensive experiments demonstrate that HoliAntiSpoof outperforms conventional baselines across multiple settings, while preliminary results show that in-context learning further improves out-of-domain generalization. These findings indicate that ALLMs not only enhance speech spoofing detection performance but also enable interpretable analysis of spoofing behaviors and their semantic effects, pointing towards more trustworthy and explainable speech security. Data and code are publicly available.", "AI": {"tldr": "该论文提出了一种名为HoliAntiSpoof的音频大型语言模型框架，用于全面的语音防伪分析。", "motivation": "现有的大多数方法将语音伪造视为二元分类任务，忽略了多样化的伪造技术对多个耦合语音属性及其语义影响的操控。因此，需要一种新的方法来更好地理解和检测这些复杂的伪造行为。", "method": "HoliAntiSpoof框架通过将其转化为统一的文本生成任务，实现了对各种伪造方法、受影响的语音属性以及其语义影响的联合推理。同时引入了DailyTalkEdit数据集作为反伪造基准测试，并支持语义层次分析。", "result": "实验结果显示，该模型在多个设置下均优于传统基线方法。初步结果表明，在上下文学习的支持下，模型在外域泛化能力上进一步提升。", "conclusion": "HoliAntiSpoof不仅提高了语音伪造检测的性能，还提供了对伪造行为及其语义影响的可解释分析，从而促进了更加可信和透明的语音安全技术的发展。"}}
{"id": "2602.04529", "pdf": "https://arxiv.org/pdf/2602.04529", "abs": "https://arxiv.org/abs/2602.04529", "authors": ["Haoran Yin", "Shuaiqun Pan", "Zhao Wei", "Jian Cheng Wong", "Yew-Soon Ong", "Anna V. Kononova", "Thomas Bäck", "Niki van Stein"], "title": "Landscape-aware Automated Algorithm Design: An Efficient Framework for Real-world Optimization", "categories": ["cs.NE"], "comment": null, "summary": "The advent of Large Language Models (LLMs) has opened new frontiers in automated algorithm design, giving rise to numerous powerful methods. However, these approaches retain critical limitations: they require extensive evaluation of the target problem to guide the search process, making them impractical for real-world optimization tasks, where each evaluation consumes substantial computational resources. This research proposes an innovative and efficient framework that decouples algorithm discovery from high-cost evaluation. Our core innovation lies in combining a Genetic Programming (GP) function generator with an LLM-driven evolutionary algorithm designer. The evolutionary direction of the GP-based function generator is guided by the similarity between the landscape characteristics of generated proxy functions and those of real-world problems, ensuring that algorithms discovered via proxy functions exhibit comparable performance on real-world problems. Our method enables deep exploration of the algorithmic space before final validation while avoiding costly real-world evaluations. We validated the framework's efficacy across multiple real-world problems, demonstrating its ability to discover high-performance algorithms while substantially reducing expensive evaluations. This approach shows a path to apply LLM-based automated algorithm design to computationally intensive real-world optimization challenges.", "AI": {"tldr": "本文提出了一种结合遗传编程和大型语言模型的框架，以发现适用于实际问题优化的有效算法。", "motivation": "现有的自动化算法设计方法在处理每项评估消耗大量计算资源的实际问题时效率低下。因此，需要一种新的高效框架来解耦算法发现与高成本评估过程。", "method": "该研究结合了遗传编程（GP）函数生成器和大型语言模型驱动的进化算法设计器，利用相似性指导GP方向，并通过代理函数进行探索，避免昂贵的真实世界评估。", "result": "实验验证表明，所提出的框架能够发现高性能算法并大幅减少昂贵的评估次数，在多种实际问题中表现出色。", "conclusion": "该研究提供了一种应用大型语言模型自动设计算法来解决计算密集型的实际优化挑战的方法路径。"}}
{"id": "2602.04525", "pdf": "https://arxiv.org/pdf/2602.04525", "abs": "https://arxiv.org/abs/2602.04525", "authors": ["Muhammad Taha Mukhtar", "Syed Musa Ali Kazmi", "Khola Naseem", "Muhammad Ali Chattha", "Andreas Dengel", "Sheraz Ahmed", "Muhammad Naseer Bajwa", "Muhammad Imran Malik"], "title": "SLUM-i: Semi-supervised Learning for Urban Mapping of Informal Settlements and Data Quality Benchmarking", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 8 figures, 5 tables", "summary": "Rapid urban expansion has fueled the growth of informal settlements in major cities of low- and middle-income countries, with Lahore and Karachi in Pakistan and Mumbai in India serving as prominent examples. However, large-scale mapping of these settlements is severely constrained not only by the scarcity of annotations but by inherent data quality challenges, specifically high spectral ambiguity between formal and informal structures and significant annotation noise. We address this by introducing a benchmark dataset for Lahore, constructed from scratch, along with companion datasets for Karachi and Mumbai, which were derived from verified administrative boundaries, totaling 1,869 $\\text{km}^2$ of area. To evaluate the global robustness of our framework, we extend our experiments to five additional established benchmarks, encompassing eight cities across three continents, and provide comprehensive data quality assessments of all datasets. We also propose a new semi-supervised segmentation framework designed to mitigate the class imbalance and feature degradation inherent in standard semi-supervised learning pipelines. Our method integrates a Class-Aware Adaptive Thresholding mechanism that dynamically adjusts confidence thresholds to prevent minority class suppression and a Prototype Bank System that enforces semantic consistency by anchoring predictions to historically learned high-fidelity feature representations. Extensive experiments across a total of eight cities spanning three continents demonstrate that our approach outperforms state-of-the-art semi-supervised baselines. Most notably, our method demonstrates superior domain transfer capability whereby a model trained on only 10% of source labels reaches a 0.461 mIoU on unseen geographies and outperforms the zero-shot generalization of fully supervised models.", "AI": {"tldr": "本文提出了一种针对非正式居住区的城市制图的半监督学习框架，并构建了一个基准数据集，以应对标注稀缺和高光谱歧义等问题。", "motivation": "快速城市扩张导致低中等收入国家的大城市中出现大量非正式定居点。然而，这些区域的大规模制图面临标签稀疏及数据质量问题。", "method": "本文提出了一种新的半监督分割框架，包括一个能够动态调整置信度阈值以防止少数类被压制的类感知自适应阈值机制和一种原型银行系统，通过锚定预测到历史学习中的高保真特征表示来强制语义一致性。", "result": "该方法在八个城市的数据集上的实验结果表明，它优于现有的半监督基线模型，并展示了强大的域转移能力。当仅使用10%的源标签时，在未见过的城市地理中达到了0.461 mIoU。", "conclusion": "提出的框架和基准数据集为非正式居住区的大规模制图提供了有效的工具，特别是在标注稀缺的情况下显示出优越的表现。"}}
{"id": "2602.04523", "pdf": "https://arxiv.org/pdf/2602.04523", "abs": "https://arxiv.org/abs/2602.04523", "authors": ["Ferdinando Cicalese", "Zsuzsanna Lipták", "Travis Gagie", "Gonzalo Navarro", "Nicola Prezza", "Cristian Urbina"], "title": "Incongruity-sensitive access to highly compressed strings", "categories": ["cs.DS"], "comment": null, "summary": "Random access to highly compressed strings -- represented by straight-line programs or Lempel-Ziv parses, for example -- is a well-studied topic. Random access to such strings in strongly sublogarithmic time is impossible in the worst case, but previous authors have shown how to support faster access to specific characters and their neighbourhoods. In this paper we explore whether, since better compression can impede access, we can support faster access to relatively incompressible substrings of highly compressed strings. We first show how, given a run-length compressed straight-line program (RLSLP) of size $g_{rl}$ or a block tree of size $L$, we can build an $O (g_{rl})$-space or an $O (L)$-space data structure, respectively, that supports access to any character in time logarithmic in the length of the longest repeated substring containing that character. That is, the more incongruous a character is with respect to the characters around it in a certain sense, the faster we can support access to it. We then prove a similar but more powerful and sophisticated result for parsings in which phrases' sources do not overlap much larger phrases, with the query time depending also on the number of phrases we must copy from their sources to obtain the queried character.", "AI": {"tldr": "研究如何在高度压缩字符串中实现快速随机访问，特别是对于相对不可压缩的子串", "motivation": "探索是否可以通过改进访问技术来加快对高度压缩字符串中不一致或相对较不可压缩部分字符的访问速度", "method": "提出一种基于运行长度压缩的直线路由程序(RLSLP)和块树的数据结构，支持在对数时间内访问任何字符；并进一步研究了非重叠短语源的解析方法，提高了查询效率", "result": "构建了一种空间复杂度为O(g_{rl})或O(L)，时间复杂度与最长重复子串长度相关的数据结构，实现了更快的访问速度；对于非重叠短语源的情况，结果更为强大和复杂，查询时间还取决于复制短语的数量", "conclusion": "在高度压缩字符串中实现高效随机访问是可能的，并且对相对不一致或不可压缩部分的支持更好"}}
{"id": "2602.04522", "pdf": "https://arxiv.org/pdf/2602.04522", "abs": "https://arxiv.org/abs/2602.04522", "authors": ["Bingkun Huang", "Xin Ma", "Nilanjan Chakraborty", "Riddhiman Laha"], "title": "A Unified Complementarity-based Approach for Rigid-Body Manipulation and Motion Prediction", "categories": ["cs.RO"], "comment": "18 pages, 7 figures", "summary": "Robotic manipulation in unstructured environments requires planners to reason jointly about free-space motion and sustained, frictional contact with the environment. Existing (local) planning and simulation frameworks typically separate these regimes or rely on simplified contact representations, particularly when modeling non-convex or distributed contact patches. Such approximations limit the fidelity of contact-mode transitions and hinder the robust execution of contact-rich behaviors in real time. This paper presents a unified discrete-time modeling framework for robotic manipulation that consistently captures both free motion and frictional contact within a single mathematical formalism (Unicomp). Building on complementarity-based rigid-body dynamics, we formulate free-space motion and contact interactions as coupled linear and nonlinear complementarity problems, enabling principled transitions between contact modes without enforcing fixed-contact assumptions. For planar patch contact, we derive a frictional contact model from the maximum power dissipation principle in which the set of admissible contact wrenches is represented by an ellipsoidal limit surface. This representation captures coupled force-moment effects, including torsional friction, while remaining agnostic to the underlying pressure distribution across the contact patch. The resulting formulation yields a discrete-time predictive model that relates generalized velocities and contact wrenches through quadratic constraints and is suitable for real-time optimization-based planning. Experimental results show that the proposed approach enables stable, physically consistent behavior at interactive speeds across tasks, from planar pushing to contact-rich whole-body maneuvers.", "AI": {"tldr": "提出了一个统一的互补性基于建模框架，用于机器人抓取和运动预测。", "motivation": "现有的规划和模拟框架通常将自由空间运动和摩擦接触分离处理，或者依赖于简化的接触表示方法。这些近似值限制了接触模式转换的精确度，并阻碍了实时执行复杂的接触行为。", "method": "基于互补性刚体动力学，将自由空间运动和接触交互形式化为耦合线性和非线性互补问题，从而能够在不进行固定接触假设的情况下实现原则性的接触模式转变。推导了一种平面补丁接触的摩擦模型，并提出了一种适合实时优化规划的离散时间预测模型。", "result": "实验结果表明，该方法可以以交互速度稳定、物理一致地执行各种任务，从平面推动到复杂的全身操控动作。", "conclusion": "所提出的统一互补性建模框架为机器人抓取和运动预测提供了一种新的解决方案，能够在实时优化规划中实现稳定的接触模式转变和高精度的预测。"}}
{"id": "2602.04521", "pdf": "https://arxiv.org/pdf/2602.04521", "abs": "https://arxiv.org/abs/2602.04521", "authors": ["Aditya Kasliwal", "Pratinav Seth", "Vinay Kumar Sankarapu"], "title": "$C$-$ΔΘ$: Circuit-Restricted Weight Arithmetic for Selective Refusal", "categories": ["cs.CL", "cs.ET"], "comment": null, "summary": "Modern deployments require LLMs to enforce safety policies at scale, yet many controls rely on inference-time interventions that add recurring compute cost and serving complexity. Activation steering is widely used, but it requires runtime hooks and scales cost with the number of generations; conditional variants improve selectivity by gating when steering is applied but still retain an inference-time control path. We ask whether selective refusal can be moved entirely offline: can a mechanistic understanding of category-specific refusal be distilled into a circuit-restricted weight update that deploys as a standard checkpoint? We propose C-Δθ: Circuit Restricted Weight Arithmetic, which (i) localizes refusal-causal computation as a sparse circuit using EAP-IG and (ii) computes a constrained weight update ΔθC supported only on that circuit (typically <5% of parameters). Applying ΔθC yields a drop-in edited checkpoint with no inference-time hooks, shifting cost from per-request intervention to a one-time offline update. We evaluate category-targeted selectivity and capability retention on refusal and utility benchmarks.", "AI": {"tldr": "该论文提出了C-Δθ方法，通过离线计算拒绝策略的权重更新来减少大规模部署中的运行时复杂性和成本。", "motivation": "在大型语言模型的大规模部署中，需要实施安全政策。然而，现有的控制措施增加了运行时的成本和复杂性。因此，作者希望探索是否可以通过离线处理完全移除这些开销。", "method": "C-Δθ方法通过EAP-IG技术将拒绝相关的因果计算局部化为稀疏电路，并在该电路上进行受限的权重更新，从而生成一个可以在推理过程中直接使用的编辑后的检查点。", "result": "实验表明，应用C-Δθ可以保留模型的能力同时提高类别选择性。与现有的激活导向方法相比，它将运行时复杂性和成本从每次请求转移为一次性离线计算。", "conclusion": "该研究证明了通过离线计算权重更新来实现大规模部署中的安全策略是可行的，并且这种方法在保持模型能力的同时显著降低了成本和复杂性。"}}
{"id": "2602.04518", "pdf": "https://arxiv.org/pdf/2602.04518", "abs": "https://arxiv.org/abs/2602.04518", "authors": ["Andrés Holgado-Sánchez", "Holger Billhardt", "Alberto Fernández", "Sascha Ossowski"], "title": "Learning the Value Systems of Agents with Preference-based and Inverse Reinforcement Learning", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "42 pages, 5 figures. Published in Journal of Autonomous Agents and Multi-Agent Systems", "summary": "Agreement Technologies refer to open computer systems in which autonomous software agents interact with one another, typically on behalf of humans, in order to come to mutually acceptable agreements. With the advance of AI systems in recent years, it has become apparent that such agreements, in order to be acceptable to the involved parties, must remain aligned with ethical principles and moral values. However, this is notoriously difficult to ensure, especially as different human users (and their software agents) may hold different value systems, i.e. they may differently weigh the importance of individual moral values. Furthermore, it is often hard to specify the precise meaning of a value in a particular context in a computational manner. Methods to estimate value systems based on human-engineered specifications, e.g. based on value surveys, are limited in scale due to the need for intense human moderation. In this article, we propose a novel method to automatically \\emph{learn} value systems from observations and human demonstrations. In particular, we propose a formal model of the \\emph{value system learning} problem, its instantiation to sequential decision-making domains based on multi-objective Markov decision processes, as well as tailored preference-based and inverse reinforcement learning algorithms to infer value grounding functions and value systems. The approach is illustrated and evaluated by two simulated use cases.", "AI": {"tldr": "论文提出了一种基于观察和人类示范自动学习价值系统的新型方法。", "motivation": "确保自主软件代理之间的协议符合伦理原则和道德价值观，尤其是在不同用户持有不同的价值体系时较为困难。传统的人工指定的方法由于需要大量人工干预而受限于规模。", "method": "提出了一种形式化模型来描述价值系统学习问题，并基于多目标马尔可夫决策过程将其应用于序列决策领域。此外还提出了定制的偏好和逆向强化学习算法以推断值接地函数和价值观体系。", "result": "该方法通过两个模拟用例进行了演示与评估，展示了其有效性和可行性。", "conclusion": "自动学习价值系统的方法能够为多代理系统提供更灵活且适应性强的价值指导方案。"}}
{"id": "2602.04517", "pdf": "https://arxiv.org/pdf/2602.04517", "abs": "https://arxiv.org/abs/2602.04517", "authors": ["Leonid Antsfeld", "Boris Chidlovskii", "Yohann Cabon", "Vincent Leroy", "Jerome Revaud"], "title": "S-MUSt3R: Sliding Multi-view 3D Reconstruction", "categories": ["cs.CV", "cs.RO"], "comment": "8 pages, 5 figures, 5 tables", "summary": "The recent paradigm shift in 3D vision led to the rise of foundation models with remarkable capabilities in 3D perception from uncalibrated images. However, extending these models to large-scale RGB stream 3D reconstruction remains challenging due to memory limitations. This work proposes S-MUSt3R, a simple and efficient pipeline that extends the limits of foundation models for monocular 3D reconstruction. Our approach addresses the scalability bottleneck of foundation models through a simple strategy of sequence segmentation followed by segment alignment and lightweight loop closure optimization. Without model retraining, we benefit from remarkable 3D reconstruction capacities of MUSt3R model and achieve trajectory and reconstruction performance comparable to traditional methods with more complex architecture. We evaluate S-MUSt3R on TUM, 7-Scenes and proprietary robot navigation datasets and show that S-MUSt3R runs successfully on long RGB sequences and produces accurate and consistent 3D reconstruction. Our results highlight the potential of leveraging the MUSt3R model for scalable monocular 3D scene in real-world settings, with an important advantage of making predictions directly in the metric space.", "AI": {"tldr": "提出S-MUSt3R方法，解决大规模RGB流的3D重建问题。", "motivation": "现有基础模型在处理大规模RGB序列时受内存限制影响，难以实现有效的3D重建。通过简化策略提高基础模型的扩展性和效率。", "method": "通过分段分割、片段对齐和轻量级闭环优化来解决规模瓶颈问题。", "result": "实验显示S-MUSt3R在多个数据集上表现良好，能够成功处理长序列RGB图像并生成准确且一致的3D重建。", "conclusion": "表明了利用MUSt3R模型进行大规模单目3D场景重建的实际应用潜力。"}}
{"id": "2602.04516", "pdf": "https://arxiv.org/pdf/2602.04516", "abs": "https://arxiv.org/abs/2602.04516", "authors": ["Xunlan Zhou", "Hongrui Zhao", "Negar Mehr"], "title": "TACO: Temporal Consensus Optimization for Continual Neural Mapping", "categories": ["cs.RO"], "comment": null, "summary": "Neural implicit mapping has emerged as a powerful paradigm for robotic navigation and scene understanding. However, real-world robotic deployment requires continual adaptation to changing environments under strict memory and computation constraints, which existing mapping systems fail to support. Most prior methods rely on replaying historical observations to preserve consistency and assume static scenes. As a result, they cannot adapt to continual learning in dynamic robotic settings. To address these challenges, we propose TACO (TemporAl Consensus Optimization), a replay-free framework for continual neural mapping. We reformulate mapping as a temporal consensus optimization problem, where we treat past model snapshots as temporal neighbors. Intuitively, our approach resembles a model consulting its own past knowledge. We update the current map by enforcing weighted consensus with historical representations. Our method allows reliable past geometry to constrain optimization while permitting unreliable or outdated regions to be revised in response to new observations. TACO achieves a balance between memory efficiency and adaptability without storing or replaying previous data. Through extensive simulated and real-world experiments, we show that TACO robustly adapts to scene changes, and consistently outperforms other continual learning baselines.", "AI": {"tldr": "提出了TACO框架，用于解决神经隐式映射在动态环境中的持续学习问题。", "motivation": "现有映射系统无法适应不断变化的环境，缺乏对持续学习的支持。", "method": "通过将映射重新表述为时间共识优化问题，并更新当前地图以实现与历史表示的一致性来解决问题。", "result": "TACO在模拟和真实世界实验中表现出色，能够有效应对场景变化并优于其他基线方法。", "conclusion": "提出了一个无需回放以往数据的持续学习框架，实现了记忆效率和适应性的平衡。"}}
{"id": "2602.04515", "pdf": "https://arxiv.org/pdf/2602.04515", "abs": "https://arxiv.org/abs/2602.04515", "authors": ["Yu Bai", "MingMing Yu", "Chaojie Li", "Ziyi Bai", "Xinlong Wang", "Börje F. Karlsson"], "title": "EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments.", "AI": {"tldr": "本文提出了EgoActor，一种将高级指令直接转化为具体的人形机器人动作的视觉语言模型。", "motivation": "在现实环境中部署人形机器人面临挑战，包括感知、移动和操纵任务之间的无缝过渡。本文旨在解决这一问题，通过引入一个新任务-EgoActing来实现这一目标，该任务要求将高级指令直接转化为具体的人形动作。", "method": "EgoActor是基于视觉语言模型的一种统一且可扩展的框架，可以预测行走、转向、侧面移动等基本运动命令，头部动作，操纵命令和人机交互，以此实现实时感知与执行的协调。训练中利用了真实世界演示中的第一视角RGB数据，空间推理问答以及模拟环境中的演示。", "result": "在仿真和实际环境中进行广泛的评估表明，EgoActor能够有效连接抽象任务规划与具体运动执行，并且可以跨多种任务和未知环境进行泛化。", "conclusion": "通过引入EgoActing任务并开发相应的视觉语言模型EgoActor，本文展示了如何将高级指令转化为具体的人形机器人动作，在动态环境中实现更流畅的任务执行。"}}
{"id": "2602.04512", "pdf": "https://arxiv.org/pdf/2602.04512", "abs": "https://arxiv.org/abs/2602.04512", "authors": ["Xuanhua Yin", "Runkai Zhao", "Lina Yao", "Weidong Cai"], "title": "BrainVista: Modeling Naturalistic Brain Dynamics as Multimodal Next-Token Prediction", "categories": ["q-bio.NC", "cs.AI"], "comment": "17 pages, 7 figures, 11 tables", "summary": "Naturalistic fMRI characterizes the brain as a dynamic predictive engine driven by continuous sensory streams. However, modeling the causal forward evolution in realistic neural simulation is impeded by the timescale mismatch between multimodal inputs and the complex topology of cortical networks. To address these challenges, we introduce BrainVista, a multimodal autoregressive framework designed to model the causal evolution of brain states. BrainVista incorporates Network-wise Tokenizers to disentangle system-specific dynamics and a Spatial Mixer Head that captures inter-network information flow without compromising functional boundaries. Furthermore, we propose a novel Stimulus-to-Brain (S2B) masking mechanism to synchronize high-frequency sensory stimuli with hemodynamically filtered signals, enabling strict, history-only causal conditioning. We validate our framework on Algonauts 2025, CineBrain, and HAD, achieving state-of-the-art fMRI encoding performance. In long-horizon rollout settings, our model yields substantial improvements over baselines, increasing pattern correlation by 36.0\\% and 33.3\\% on relative to the strongest baseline Algonauts 2025 and CineBrain, respectively.", "AI": {"tldr": "本文提出了一种名为BrainVista的多模态自回归框架，用于模拟大脑状态的因果演变。", "motivation": "自然istic fMRI揭示了大脑作为由连续感觉流驱动的动力预测引擎的功能。然而，在现实神经仿真中建模脑动态时面临着时间尺度不匹配和皮层网络复杂拓扑结构的问题。为了解决这些问题，本文提出了BrainVista框架以模拟脑状态的因果演变。", "method": "BrainVista使用Network-wise Tokenizers来分离系统特定动力学，并采用Spatial Mixer Head捕捉跨网络的信息流而不破坏功能界限。此外还提出了一种Stimulus-to-Brain(S2B)屏蔽机制，使高频感觉刺激与血氧水平依赖信号同步。", "result": "本文的框架在Algonauts 2025、CineBrain和HAD数据集上验证了其性能，并实现了最先进的fMRI编码效果。长时序推演设置下，模型比最强基线分别提高了36.0%和33.3%", "conclusion": "本文通过提出一种名为BrainVista的多模态自回归框架解决了当前建模自然istic fMRI数据中脑动态存在的问题，并验证了其在多个数据集上的优越性能。"}}
{"id": "2602.04496", "pdf": "https://arxiv.org/pdf/2602.04496", "abs": "https://arxiv.org/abs/2602.04496", "authors": ["Zhentao Tang", "Yuqi Cui", "Shixiong Kai", "Wenqian Zhao", "Ke Ye", "Xing Li", "Anxin Tian", "Zehua Pei", "Hui-Ling Zhen", "Shoubo Hu", "Xiaoguang Li", "Yunhe Wang", "Mingxuan Yuan"], "title": "ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control", "categories": ["cs.AI"], "comment": null, "summary": "Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.", "AI": {"tldr": "ReThinker框架通过自信度控制和多代理协调，改进了大型语言模型的科学推理能力。", "motivation": "专家级科学推理对大规模语言模型来说仍是一个挑战，尤其是在Humanity's Last Exam等基准测试中表现不佳。因此需要一种新的方法来提高模型在这些任务上的性能。", "method": "ReThinker框架通过自信度控制和多阶段的Solver-Critic-Selector架构，动态地调用工具、进行反思并选择最可靠的解决方案。此外，该框架还提出了一种逆向数据合成流程以及自适应轨迹回收策略来支持大规模训练。", "result": "实验表明，在HLE, GAIA和XBench等基准测试中，ReThinker在专家级推理任务上超越了现有的基础模型工具系统和其他深度研究系统，达到最新水平的结果。", "conclusion": "通过自信度控制和动态分配计算资源的方式，ReThinker显著提高了大型语言模型的科学推理能力。"}}
{"id": "2602.04495", "pdf": "https://arxiv.org/pdf/2602.04495", "abs": "https://arxiv.org/abs/2602.04495", "authors": ["Maher Harb", "Nader Foroughi", "Matt Stehman", "Bob Lutz", "Nati Erez", "Erik Garcell"], "title": "Quantum-Based Resilient Routing in Networks: Minimizing Latency Under Dual-Link Failures", "categories": ["cs.ET"], "comment": "15 pages, 4 figures", "summary": "Network optimization problems represent large combinatorial search spaces that grow exponentially with network size, making them computationally intensive to solve. This paper addresses the latency-resilient Layer 3 routing optimization problem in telecommunications networks with predefined Layer 1 optical links. We formulate this problem as a graph-based optimization problem with the objective of minimizing latency, creating vertex-disjoint paths from each site to the internet backbone, and maximizing overall resiliency by limiting the impact of dual-link failures. By framing the problem as finding two disjoint shortest paths, coupled together with a resiliency component to the objective function, we establish a single formulation to produce optimal path design. The mathematical formulation was adapted to solve the problem using quantum approximate optimization algorithm (QAOA) executed over both quantum simulator and quantum hardware. QAOA was tested on a toy graph topology with 5 vertices and 7 edges and considering two limiting scenarios respectively representing independent (uncorrelated) link failures and highly correlated failure for one pair of edges. Both explored scenarios produced the optimal network design-corresponding to the valid solution with highest frequency of occurrence and minimum energy state, hence, validating the proposed formulation for optimizing Layer 3 routing on quantum systems of the future.", "AI": {"tldr": "本文提出了一种基于量子近似优化算法（QAOA）的网络路由优化方法，以最小化延迟并提高双链路故障下的鲁棒性。", "motivation": "电信网络中的延迟和鲁棒性是关键问题，尤其是对于预定义的一层光链接而言。通过解决双重链路故障情况下的最优路径设计来增强网络性能。", "method": "将路由优化问题转化为寻找两个不相交的最短路径，并结合鲁棒性组件到目标函数中。使用量子近似优化算法（QAOA）在量子模拟器和实际硬件上执行此任务，以解决给定拓扑中的延迟最小化与链路故障影响限制的问题。", "result": "实验验证了所提出的数学模型的有效性和适应性，在两种不同场景下均获得了最优解决方案。", "conclusion": "该研究展示了利用QAOA优化三层路由的潜力，并为未来在量子计算平台上的网络优化铺平道路。"}}
{"id": "2602.04493", "pdf": "https://arxiv.org/pdf/2602.04493", "abs": "https://arxiv.org/abs/2602.04493", "authors": ["Saleh Afzoon", "MohammadHossein Ahmadi", "Usman Naseem", "Amin Beheshti"], "title": "PersoDPO: Scalable Preference Optimization for Instruction-Adherent, Persona-Grounded Dialogue via Multi-LLM Evaluation", "categories": ["cs.CL", "cs.HC"], "comment": "Accepted at WISE 2025 Conference", "summary": "Personalization and contextual coherence are two essential components in building effective persona-grounded dialogue systems. These aspects play a crucial role in enhancing user engagement and ensuring responses are more relevant and consistent with user identity. However, recent studies indicate that open-source large language models (LLMs) continue to struggle to generate responses that are both contextually grounded and aligned with persona cues, despite exhibiting strong general conversational abilities like fluency and naturalness. We present PersoDPO, a scalable preference optimisation framework that uses supervision signals from automatic evaluations of responses generated by both closed-source and open-source LLMs to fine-tune dialogue models. The framework integrates evaluation metrics targeting coherence and personalization, along with a length-format compliance feature to promote instruction adherence. These signals are combined to automatically construct high-quality preference pairs without manual annotation, enabling a scalable and reproducible training pipeline. Experiments on the FoCus dataset show that an open-source language model fine-tuned with the PersoDPO framework consistently outperforms strong open-source baselines and a standard Direct Preference Optimization (DPO) variant across multiple evaluation dimensions.", "AI": {"tldr": "PersoDPO是一种可扩展的偏好优化框架，利用多语言模型评估来微调对话系统，以提升个性化和上下文连贯性。", "motivation": "尽管开源大型语言模型在通用会话能力方面表现出色，但在生成既符合上下文又与人格线索一致的回答时仍存在困难。因此，需要一个更有效的框架来改善这些性能指标。", "method": "该研究提出了PersoDPO框架，使用来自封闭源和开放源LLM的自动评估信号，并结合衡量连贯性和个性化的评价标准以及长度格式一致性特征，以促进指令遵循。这允许在无需人工注释的情况下生成高质量的偏好对，从而实现可扩展且可重现的训练流程。", "result": "实验显示，在FoCus数据集上使用PersoDPO框架进行微调的开源语言模型比强大的开源基准和标准直接偏好优化变体更胜一筹，表现出色。", "conclusion": "通过PersoDPO框架的应用，研究人员展示了如何有效利用多LLM评估信号来提升对话系统的个性化和上下文连贯性，从而提高用户参与度。"}}
{"id": "2602.04492", "pdf": "https://arxiv.org/pdf/2602.04492", "abs": "https://arxiv.org/abs/2602.04492", "authors": ["Jan-Matthis Lueckmann", "Viren Jain", "Michał Januszewski"], "title": "Discovering Mechanistic Models of Neural Activity: System Identification in an in Silico Zebrafish", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "comment": null, "summary": "Constructing mechanistic models of neural circuits is a fundamental goal of neuroscience, yet verifying such models is limited by the lack of ground truth. To rigorously test model discovery, we establish an in silico testbed using neuromechanical simulations of a larval zebrafish as a transparent ground truth. We find that LLM-based tree search autonomously discovers predictive models that significantly outperform established forecasting baselines. Conditioning on sensory drive is necessary but not sufficient for faithful system identification, as models exploit statistical shortcuts. Structural priors prove essential for enabling robust out-of-distribution generalization and recovery of interpretable mechanistic models. Our insights provide guidance for modeling real-world neural recordings and offer a broader template for AI-driven scientific discovery.", "AI": {"tldr": "使用神经力学仿真构建的无硅斑马鱼模型，通过LLM基树搜索方法自主发现预测性模型，并验证其在现实世界中的应用。", "motivation": "构造神经回路的机制模型是神经科学的基本目标。由于缺乏真实的基准，当前对于这些模型的有效性的检验受到了限制。研究团队希望通过建立一个透明的、基于神经力学仿真的无硅斑马鱼系统来测试和改进这种方法论。", "method": "在模拟环境中使用LLM（大型语言模型）基树搜索方法自主发现预测性模型，并通过该模型对感觉输入进行条件化处理，以验证其是否能够准确识别系统的结构特性。同时引入了结构性的先验知识，以便于提高模型在外推和解释方面的性能。", "result": "实验结果表明，LLM基于树搜索的方法可以有效自主发现预测性模型，并且这些模型的表现显著优于现有的基准方法；此外，在感觉驱动条件下进行条件化处理是必要的但不够充分的，必须结合结构性先验知识才能实现忠实的系统识别以及稳健的泛化能力。", "conclusion": "该研究提供了关于如何构建和验证现实世界中神经记录机制模型的重要指导，并提出了一种适用于AI驱动科学发现的模板。"}}
{"id": "2602.04487", "pdf": "https://arxiv.org/pdf/2602.04487", "abs": "https://arxiv.org/abs/2602.04487", "authors": ["Himanshi Lalwani", "Hanan Salam"], "title": "The Supportiveness-Safety Tradeoff in LLM Well-Being Agents", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "Large language models (LLMs) are being integrated into socially assistive robots (SARs) and other conversational agents providing mental health and well-being support. These agents are often designed to sound empathic and supportive in order to maximize user's engagement, yet it remains unclear how increasing the level of supportive framing in system prompts influences safety relevant behavior. We evaluated 6 LLMs across 3 system prompts with varying levels of supportiveness on 80 synthetic queries spanning 4 well-being domains (1440 responses). An LLM judge framework, validated against human ratings, assessed safety and care quality. Moderately supportive prompts improved empathy and constructive support while maintaining safety. In contrast, strongly validating prompts significantly degraded safety and, in some cases, care across all domains, with substantial variation across models. We discuss implications for prompt design, model selection, and domain specific safeguards in SARs deployment.", "AI": {"tldr": "研究探讨了大型语言模型在提供心理健康支持时，不同程度的支持性提示对其安全性和护理质量的影响。", "motivation": "随着大型语言模型被集成到社交辅助机器人等系统中来提供心理健康和福祉支持，研究人员试图理解增加支持性框架如何影响系统的安全性行为。", "method": "评估了六种大型语言模型在三种不同支持程度的系统提示下对80个合成查询的回答，并使用经过人类评分验证的LLM法官框架来评估安全性和护理质量。", "result": "适度的支持性提示改善了同理心和支持性，而高度肯定性的提示则显著降低了安全性，在某些情况下还损害了所有领域的护理质量。", "conclusion": "研究讨论了对提示设计、模型选择以及领域特定的保护措施在社交辅助机器人部署中的重要影响。"}}
{"id": "2602.04482", "pdf": "https://arxiv.org/pdf/2602.04482", "abs": "https://arxiv.org/abs/2602.04482", "authors": ["Yuanbo Tang", "Huaze Tang", "Tingyu Cao", "Lam Nguyen", "Anping Zhang", "Xinwen Cao", "Chunkang Liu", "Wenbo Ding", "Yang Li"], "title": "Proactive Agents, Long-term User Context, VLM Annotation, Privacy Protection, Human-Computer Interaction", "categories": ["cs.HC"], "comment": null, "summary": "Proactive agents that anticipate user intentions without explicit prompts represent a significant evolution in human-AI interaction, promising to reduce cognitive load and streamline workflows. However, existing datasets suffer from two critical deficiencies: (1) reliance on LLM-synthesized data that fails to capture authentic human decision-making patterns, and (2) focus on isolated tasks rather than continuous workflows, missing the pre-assistance behavioral context essential for learning proactive intervention signals. To address these gaps, we introduce ProAgentBench, a rigorous benchmark for proactive agents in working scenarios. Our contributions include: (1) a hierarchical task framework that decomposes proactive assistance into timing prediction and assist content generation; (2) a privacy-compliant dataset with 28,000+ events from 500+ hours of real user sessions, preserving bursty interaction patterns (burstiness B=0.787) absent in synthetic data; and (3) extensive experiments that evaluates LLM- and VLM-based baselines. Numerically, we showed that long-term memory and historical context significantly enhance prediction accuracy, while real-world training data substantially outperforms synthetic alternatives. We release our dataset and code at https://anonymous.4open.science/r/ProAgentBench-6BC0.", "AI": {"tldr": "本文提出了ProAgentBench，一个针对工作场景中主动代理的基准测试框架。", "motivation": "现有数据集存在依赖LLM生成的数据和孤立任务的关注点问题，未能捕捉到真实的人类决策模式及行为上下文。", "method": "引入了一个层次化的任务框架，包括时间预测与辅助内容生成；构建了隐私合规的真实用户会话数据集，包含28,000多个事件；并评估了LLM和VLM基线模型。", "result": "实验表明长期记忆及历史背景显著提高了预测准确率，真实世界训练数据优于合成数据。", "conclusion": "ProAgentBench能够有效评估主动代理的能力，并强调了长时记忆与现实场景数据的重要性。"}}
{"id": "2602.04478", "pdf": "https://arxiv.org/pdf/2602.04478", "abs": "https://arxiv.org/abs/2602.04478", "authors": ["Keya Shah", "Himanshi Lalwani", "Zein Mukhanov", "Hanan Salam"], "title": "Informing Robot Wellbeing Coach Design through Longitudinal Analysis of Human-AI Dialogue", "categories": ["cs.HC"], "comment": null, "summary": "Social robots and conversational agents are being explored as supports for wellbeing, goal-setting, and everyday self-regulation. While prior work highlights their potential to motivate and guide users, much of the evidence relies on self-reported outcomes or short, researcher-mediated encounters. As a result, we know little about the interaction dynamics that unfold when people use such systems in real-world contexts, and how these dynamics should shape future robot wellbeing coaches. This paper addresses this gap through content analysis of 4352 messages exchanged longitudinally between 38 university students and an LLM-based wellbeing coach. Our results provide a fine-grained view into how users naturally shape, steer, and sometimes struggle within supportive human-AI dialogue, revealing patterns of user-led direction, guidance-seeking, and emotional expression. We discuss how these dynamics can inform the design of robot wellbeing coaches that support user autonomy, provide appropriate scaffolding, and uphold ethical boundaries in sustained wellbeing interactions.", "AI": {"tldr": "本文通过长期分析大学生与基于LLM的福祉教练之间的对话，探讨了设计机器人福祉教练的方法。", "motivation": "当前关于社会机器人和对话代理支持用户福祉的研究大多依赖于自我报告的结果或短期研究者介导的互动。缺乏在现实世界中长时间使用的数据，这限制了我们对交互动态的理解以及如何为未来的福祉机器人设计提供指导。", "method": "通过分析38名大学生与基于LLM的福祉教练之间交换的4352条消息，进行内容分析以探讨用户自然地塑造、引导和支持性对话中的情感表达模式。", "result": "结果揭示了用户的主导方向、寻求指导和情感表达等交互动态，并提供了关于如何在持续的福祉互动中支持用户自主权、提供适当支撑以及维护伦理边界的见解。", "conclusion": "这些发现为设计能够更好地支持用户自主性，同时保持适当引导和支持并确保伦理边界的社会机器人福祉教练提供了宝贵的参考。"}}
{"id": "2602.04476", "pdf": "https://arxiv.org/pdf/2602.04476", "abs": "https://arxiv.org/abs/2602.04476", "authors": ["Byungwoo Jeon", "Yoonwoo Jeong", "Hyunseok Lee", "Minsu Cho", "Jinwoo Shin"], "title": "Vision-aligned Latent Reasoning for Multi-modal Large Language Model", "categories": ["cs.CV"], "comment": "18 pages; 5 figures", "summary": "Despite recent advancements in Multi-modal Large Language Models (MLLMs) on diverse understanding tasks, these models struggle to solve problems which require extensive multi-step reasoning. This is primarily due to the progressive dilution of visual information during long-context generation, which hinders their ability to fully exploit test-time scaling. To address this issue, we introduce Vision-aligned Latent Reasoning (VaLR), a simple, yet effective reasoning framework that dynamically generates vision-aligned latent tokens before each Chain of Thought reasoning step, guiding the model to reason based on perceptual cues in the latent space. Specifically, VaLR is trained to preserve visual knowledge during reasoning by aligning intermediate embeddings of MLLM with those from vision encoders. Empirical results demonstrate that VaLR consistently outperforms existing approaches across a wide range of benchmarks requiring long-context understanding or precise visual perception, while exhibiting test-time scaling behavior not observed in prior MLLMs. In particular, VaLR improves the performance significantly from 33.0% to 52.9% on VSI-Bench, achieving a 19.9%p gain over Qwen2.5-VL.", "AI": {"tldr": "介绍了一种用于多模态大型语言模型的视觉对齐潜推理框架（VaLR），以提高复杂问题解决能力。", "motivation": "现有的多模态大型语言模型在理解任务中表现良好，但在需要多层次推理的问题上表现出不足，原因在于长时间生成过程中图像信息逐渐流失。", "method": "提出了一种简单而有效的视觉对齐潜推理框架（VaLR），该框架通过在每次链式思维步骤之前动态生成与视觉对齐的潜在标记来引导模型基于感知线索进行推理。通过将中间嵌入与视觉编码器对齐，VaLR保留了视觉知识。", "result": "实证结果显示，VaLR在需要长时间理解或精确视觉感知的广泛基准上均优于现有方法，并表现出前所未有的测试时间扩展行为，在VSI-Bench上的性能从33.0%提高到了52.9%，取得了19.9个百分点的增长。", "conclusion": "通过引入视觉对齐潜推理框架（VaLR），该模型能够更好地解决需要多层次推理的问题，显著提高了多模态大型语言模型的表现。"}}
{"id": "2602.04473", "pdf": "https://arxiv.org/pdf/2602.04473", "abs": "https://arxiv.org/abs/2602.04473", "authors": ["Junjie Li", "Congyang Ou", "Haokui Zhang", "Guoting Wei", "Shengqin Jiang", "Ying Li", "Chunhua Shen"], "title": "SALAD-Pan: Sensor-Agnostic Latent Adaptive Diffusion for Pan-Sharpening", "categories": ["cs.CV"], "comment": null, "summary": "Recently, diffusion models bring novel insights for Pan-sharpening and notably boost fusion precision. However, most existing models perform diffusion in the pixel space and train distinct models for different multispectral (MS) imagery, suffering from high latency and sensor-specific limitations. In this paper, we present SALAD-Pan, a sensor-agnostic latent space diffusion method for efficient pansharpening. Specifically, SALAD-Pan trains a band-wise single-channel VAE to encode high-resolution multispectral (HRMS) into compact latent representations, supporting MS images with various channel counts and establishing a basis for acceleration. Then spectral physical properties, along with PAN and MS images, are injected into the diffusion backbone through unidirectional and bidirectional interactive control structures respectively, achieving high-precision fusion in the diffusion process. Finally, a lightweight cross-spectral attention module is added to the central layer of diffusion model, reinforcing spectral connections to boost spectral consistency and further elevate fusion precision. Experimental results on GaoFen-2, QuickBird, and WorldView-3 demonstrate that SALAD-Pan outperforms state-of-the-art diffusion-based methods across all three datasets, attains a 2-3x inference speedup, and exhibits robust zero-shot (cross-sensor) capability.", "AI": {"tldr": "提出了SALAD-Pan，一种在潜空间进行扩散的传感器无关泛锐化方法。", "motivation": "现有的大多数模型在像素空间中进行扩散，并为不同的多光谱图像训练不同的模型，导致延迟高和传感器特定限制。因此需要一种能够有效解决这些问题的方法。", "method": "SALAD-Pan 使用带向单通道VAE编码器将高分辨率多光谱图像转换为紧凑的潜在表示，支持不同信道数量的MS图像，并通过双向交互结构注入光谱物理特性以及PAN和MS图像以实现精确融合。此外，在扩散模型中心层添加轻量级跨光谱注意力模块来增强光谱连接。", "result": "实验结果表明，SALAD-Pan 在GaoFen-2, QuickBird 和 WorldView-3 数据集上优于现有的最先进的基于扩散的方法，并且实现了2-3倍的推理加速和强大的零样本（跨传感器）能力。", "conclusion": "通过在潜在空间中进行泛锐化，SALAD-Pan 减少了对特定传感器模型的需求，并提高了精度。"}}
{"id": "2602.04471", "pdf": "https://arxiv.org/pdf/2602.04471", "abs": "https://arxiv.org/abs/2602.04471", "authors": ["Bowen Tan", "Qiong Wu", "Pingyi Fan", "Kezhi Wang", "Nan Cheng", "Wen Chen"], "title": "LLM-Empowered Cooperative Content Caching in Vehicular Fog Caching-Assisted Platoon Networks", "categories": ["cs.NI", "cs.AI"], "comment": "Corresponding author: Qiong Wu (qiongwu@jiangnan.edu.cn)", "summary": "This letter proposes a novel three-tier content caching architecture for Vehicular Fog Caching (VFC)-assisted platoon, where the VFC is formed by the vehicles driving near the platoon. The system strategically coordinates storage across local platoon vehicles, dynamic VFC clusters, and cloud server (CS) to minimize content retrieval latency. To efficiently manage distributed storage, we integrate large language models (LLMs) for real-time and intelligent caching decisions. The proposed approach leverages LLMs' ability to process heterogeneous information, including user profiles, historical data, content characteristics, and dynamic system states. Through a designed prompting framework encoding task objectives and caching constraints, the LLMs formulate caching as a decision-making task, and our hierarchical deterministic caching mapping strategy enables adaptive requests prediction and precise content placement across three tiers without frequent retraining. Simulation results demonstrate the advantages of our proposed caching scheme.", "AI": {"tldr": "提出了一种新型的三层内容缓存架构，用于车联网中的车辆雾缓存辅助编队。", "motivation": "为了减少内容检索延迟，系统需要有效地管理分布式存储。通过集成大型语言模型（LLMs），可以实现智能和实时的内容缓存决策。", "method": "利用LLM处理异质信息的能力，并设计了一个提示框架来编码任务目标和缓存约束，将缓存问题转化为决策任务。分层确定性缓存映射策略使请求预测和精确内容放置成为可能。", "result": "仿真结果表明所提出的方法在缓存方案上具有优势。", "conclusion": "通过利用LLMs进行智能管理和实时决策，该方法有效地提高了车辆雾缓存辅助编队中的内容检索效率。"}}
{"id": "2602.04466", "pdf": "https://arxiv.org/pdf/2602.04466", "abs": "https://arxiv.org/abs/2602.04466", "authors": ["Masaya Tsunokake", "Yuta Koreeda", "Terufumi Morishita", "Koichi Nagatsuka", "Hikaru Tomonari", "Yasuhiro Sogawa"], "title": "Is Micro Domain-Adaptive Pre-Training Effective for Real-World Operations? Multi-Step Evaluation Reveals Potential and Bottlenecks", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 9 figures, Accepted by EACL2026 Industry Track", "summary": "When applying LLMs to real-world enterprise operations, LLMs need to handle proprietary knowledge in small domains of specific operations ($\\textbf{micro domains}$). A previous study shows micro domain-adaptive pre-training ($\\textbf{mDAPT}$) with fewer documents is effective, similarly to DAPT in larger domains. However, it evaluates mDAPT only on multiple-choice questions; thus, its effectiveness for generative tasks in real-world operations remains unknown. We aim to reveal the potential and bottlenecks of mDAPT for generative tasks. To this end, we disentangle the answering process into three subtasks and evaluate the performance of each subtask: (1) $\\textbf{eliciting}$ facts relevant to questions from an LLM's own knowledge, (2) $\\textbf{reasoning}$ over the facts to obtain conclusions, and (3) $\\textbf{composing}$ long-form answers based on the conclusions. We verified mDAPT on proprietary IT product knowledge for real-world questions in IT technical support operations. As a result, mDAPT resolved the elicitation task that the base model struggled with but did not resolve other subtasks. This clarifies mDAPT's effectiveness in the knowledge aspect and its bottlenecks in other aspects. Further analysis empirically shows that resolving the elicitation and reasoning tasks ensures sufficient performance (over 90%), emphasizing the need to enhance reasoning capability.", "AI": {"tldr": "本文研究了微域自适应预训练（mDAPT）在处理企业特定操作中的专有知识时的有效性，特别是在生成任务方面。通过分解回答过程为三个子任务来评估其表现：提取相关事实、推理得出结论和组成答案。", "motivation": "先前的研究表明，在少量文档下进行的微域自适应预训练（mDAPT）是有效的，但只在多项选择题上进行了验证，对于实际操作中的生成任务有效性仍未知。本文旨在揭示mDAPT在此类任务上的潜力与瓶颈。", "method": "将回答过程分解为三个子任务：从LLM的知识中提取相关事实、基于这些事实进行推理以得出结论和根据结论组成答案，并在IT技术支持的实际问题上验证了mDAPT的效果。", "result": "mDAPT能有效解决基线模型难以处理的提取事实的任务，但在其他方面仍存在瓶颈。进一步分析表明，解决了提取与推理任务后，性能可以达到90%以上。", "conclusion": "本文揭示了微域自适应预训练在知识方面的有效性以及其在推理能力上的不足，并强调需要提升模型的推理能力以提高整体表现。"}}
{"id": "2602.04463", "pdf": "https://arxiv.org/pdf/2602.04463", "abs": "https://arxiv.org/abs/2602.04463", "authors": ["Florian Adriaens", "Nikolaj tatti"], "title": "Simple 2-approximations for bad triangle transversals and some hardness results for related problems", "categories": ["cs.DS"], "comment": null, "summary": "Given a signed graph, the bad triangle transversal (BTT) problem asks to find the smallest number of edges that need to be removed such that the remaining graph does not have a triangle with exactly one negative edge (a bad triangle). We propose novel 2-approximations for this problem, which are much simpler and faster than a folklore adaptation of the 2-approximation by Krivelevich for finding a minimum triangle transversal in unsigned graphs. One of our algorithms also works for weighted BTT and for approximately optimal feasible solutions to the bad triangle cover LP. Using a recent result on approximating the bad triangle cover LP, we obtain a $(2+ε)$ approximation in time almost equal to the time needed to find a maximal set of edge-disjoint bad triangles (which would give a standard 3-approximation). Additionally, several inapproximability results are provided. For complete signed graphs, we show that BTT is NP-hard to approximate with factor better than $\\frac{2137}{2136}$. Our reduction also implies the same hardness result for related problems such as correlation clustering (cluster editing), cluster deletion and the min. strong triadic closure problem. On complete signed graphs, BTT is closely related to correlation clustering. We show that the correlation clustering optimum is at most $3/2$ times the BTT optimum, by describing a pivot procedure that transforms BTT solutions into clusters. This improves a result by Veldt, which states that their ratio is at most two.", "AI": {"tldr": "该论文研究了带签名图中的坏三角形遍历（BTT）问题，并提供了新的简单且快速的近似算法。", "motivation": "解决带签名图中最小化坏三角形的问题，提供更简单高效的解决方案替代现有的复杂方法。", "method": "提出了一种针对BTT问题的新2-近似算法，该算法比之前的适应版本更快、更容易实现。同时探讨了加权的BTT和接近最优解的方法，并提供了相关的不可逼近性结果证明。", "result": "提供了一个新的简单且快速的2-近似算法来解决BTT问题；展示了BTT在完全签名图上的难度界限为$\frac{2137}{2136}$，并改善了与相关问题如关联聚类、簇删除和最小强三闭包问题之间的比率。", "conclusion": "该论文成功地提出了一个简单高效的算法来解决坏三角形遍历（BTT）问题，并且提供了相关的理论证明，为后续研究奠定了基础。"}}
{"id": "2602.04462", "pdf": "https://arxiv.org/pdf/2602.04462", "abs": "https://arxiv.org/abs/2602.04462", "authors": ["Timothy Schaumlöffel", "Arthur Aubret", "Gemma Roig", "Jochen Triesch"], "title": "Temporal Slowness in Central Vision Drives Semantic Object Learning", "categories": ["cs.CV"], "comment": "ICLR 2026", "summary": "Humans acquire semantic object representations from egocentric visual streams with minimal supervision. Importantly, the visual system processes with high resolution only the center of its field of view and learns similar representations for visual inputs occurring close in time. This emphasizes slowly changing information around gaze locations. This study investigates the role of central vision and slowness learning in the formation of semantic object representations from human-like visual experience. We simulate five months of human-like visual experience using the Ego4D dataset and generate gaze coordinates with a state-of-the-art gaze prediction model. Using these predictions, we extract crops that mimic central vision and train a time-contrastive Self-Supervised Learning model on them. Our results show that combining temporal slowness and central vision improves the encoding of different semantic facets of object representations. Specifically, focusing on central vision strengthens the extraction of foreground object features, while considering temporal slowness, especially during fixational eye movements, allows the model to encode broader semantic information about objects. These findings provide new insights into the mechanisms by which humans may develop semantic object representations from natural visual experience.", "AI": {"tldr": "本文研究了中央视觉和时间缓慢性学习在语义物体表示形成中的作用。", "motivation": "人类通过自我中心的视觉流来获取语义对象表示，该过程主要集中在视野中央并强调接近的时间点上的信息。本研究探讨了这些因素如何影响从类人视觉经验中形成的语义对象表示。", "method": "使用Ego4D数据集模拟五个月的人类视觉经历，并通过一个先进的眼动预测模型生成注视坐标。基于此，提取类似中央视野的裁剪图像并训练时间对比自监督学习模型。", "result": "结合时间缓慢性和中央视觉改善了不同语义方面的物体表示编码。特别地，关注中央视力增强了前景对象特征的提取，而考虑时间缓慢性则允许模型编码更广泛的关于物体的语义信息。", "conclusion": "这些发现提供了新见解，解释了人类如何从自然视觉经验中发展出语义对象表示的方式机制。"}}
{"id": "2602.04458", "pdf": "https://arxiv.org/pdf/2602.04458", "abs": "https://arxiv.org/abs/2602.04458", "authors": ["Yaxin Hu", "Masaki Kuribayashi", "Allan Wang", "Seita Kayukawa", "Daisuke Sato", "Bilge Mutlu", "Hironobu Takagi", "Chieko Asakawa"], "title": "Robot-Assisted Group Tours for Blind People", "categories": ["cs.HC", "cs.RO"], "comment": "In Proceedings of ACM CHI 2026 conference on Human Factors in Computing Systems", "summary": "Group interactions are essential to social functioning, yet effective engagement relies on the ability to recognize and interpret visual cues, making such engagement a significant challenge for blind people. In this paper, we investigate how a mobile robot can support group interactions for blind people. We used the scenario of a guided tour with mixed-visual groups involving blind and sighted visitors. Based on insights from an interview study with blind people (n=5) and museum experts (n=5), we designed and prototyped a robotic system that supported blind visitors to join group tours. We conducted a field study in a science museum where each blind participant (n=8) joined a group tour with one guide and two sighted participants (n=8). Findings indicated users' sense of safety from the robot's navigational support, concerns in the group participation, and preferences for obtaining environmental information. We present design implications for future robotic systems to support blind people's mixed-visual group participation.", "AI": {"tldr": "研究探讨了移动机器人如何帮助盲人在混合视觉群体中参与集体活动，特别是在导览团场景下提高他们的安全感和环境信息获取能力。", "motivation": "集体互动对社交功能至关重要，但有效的互动依赖于视觉线索的理解，这使得视障人士的社交参与面临挑战。论文旨在通过机器人技术改善盲人的社交融入体验。", "method": "基于与5名盲人及5名博物馆专家的访谈研究结果，设计并原型化了一种移动机器人系统以支持盲人在导览团中的参与；在科学博物馆进行了实地测试，8名视障参与者分别加入有1名导游和2名视力正常游客组成的团体。", "result": "研究发现，用户对机器人的导航支持感到安全，并表达了关于群体互动的关切以及获取环境信息的偏好。", "conclusion": "该论文提出了一些设计建议，为未来开发能够帮助盲人在混合视觉群体中更有效地参与活动的机器人系统提供了指导。"}}
{"id": "2602.04456", "pdf": "https://arxiv.org/pdf/2602.04456", "abs": "https://arxiv.org/abs/2602.04456", "authors": ["Zhiyi Chen", "Eun Cheol Choi", "Yingjia Luo", "Xinyi Wang", "Yulei Xiao", "Aizi Yang", "Luca Luceri"], "title": "Growth First, Care Second? Tracing the Landscape of LLM Value Preferences in Everyday Dilemmas", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "dataset available at https://github.com/Renesmeeczy/Value-Trade-off-in-Reddit-Dilemmas", "summary": "People increasingly seek advice online from both human peers and large language model (LLM)-based chatbots. Such advice rarely involves identifying a single correct answer; instead, it typically requires navigating trade-offs among competing values. We aim to characterize how LLMs navigate value trade-offs across different advice-seeking contexts. First, we examine the value trade-off structure underlying advice seeking using a curated dataset from four advice-oriented subreddits. Using a bottom-up approach, we inductively construct a hierarchical value framework by aggregating fine-grained values extracted from individual advice options into higher-level value categories. We construct value co-occurrence networks to characterize how values co-occur within dilemmas and find substantial heterogeneity in value trade-off structures across advice-seeking contexts: a women-focused subreddit exhibits the highest network density, indicating more complex value conflicts; women's, men's, and friendship-related subreddits exhibit highly correlated value-conflict patterns centered on security-related tensions (security vs. respect/connection/commitment); by contrast, career advice forms a distinct structure where security frequently clashes with self-actualization and growth. We then evaluate LLM value preferences against these dilemmas and find that, across models and contexts, LLMs consistently prioritize values related to Exploration & Growth over Benevolence & Connection. This systemically skewed value orientation highlights a potential risk of value homogenization in AI-mediated advice, raising concerns about how such systems may shape decision-making and normative outcomes at scale.", "AI": {"tldr": "本文研究了大型语言模型在面对日常生活中的价值取舍时的行为模式。", "motivation": "探讨大型语言模型在线上咨询中可能存在的价值偏好及其对决策和规范结果的影响。", "method": "通过分析四个不同主题的建议论坛数据，归纳出一个层次化的价值观框架，并构建值共现网络来描述在不同背景下价值观之间的冲突。", "result": "发现女性关注的子版块具有最高网络密度；男性、友谊相关的板块中心在于安全与尊重/连接/承诺的价值冲突；而职业咨询则倾向于将安全与自我实现和成长进行对比。同时，大型语言模型普遍更偏重探索与发展而非仁慈与联系。", "conclusion": "研究揭示了AI系统在处理价值选择时的潜在风险——价值同质化，并提出了对大规模决策和规范结果影响的关注。"}}
{"id": "2602.04454", "pdf": "https://arxiv.org/pdf/2602.04454", "abs": "https://arxiv.org/abs/2602.04454", "authors": ["Tianming Liang", "Qirui Du", "Jian-Fang Hu", "Haichao Jiang", "Zicheng Lin", "Wei-Shi Zheng"], "title": "Seg-ReSearch: Segmentation with Interleaved Reasoning and External Search", "categories": ["cs.CV"], "comment": null, "summary": "Segmentation based on language has been a popular topic in computer vision. While recent advances in multimodal large language models (MLLMs) have endowed segmentation systems with reasoning capabilities, these efforts remain confined by the frozen internal knowledge of MLLMs, which limits their potential for real-world scenarios that involve up-to-date information or domain-specific concepts. In this work, we propose \\textbf{Seg-ReSearch}, a novel segmentation paradigm that overcomes the knowledge bottleneck of existing approaches. By enabling interleaved reasoning and external search, Seg-ReSearch empowers segmentation systems to handle dynamic, open-world queries that extend beyond the frozen knowledge of MLLMs. To effectively train this capability, we introduce a hierarchical reward design that harmonizes initial guidance with progressive incentives, mitigating the dilemma between sparse outcome signals and rigid step-wise supervision. For evaluation, we construct OK-VOS, a challenging benchmark that explicitly requires outside knowledge for video object segmentation. Experiments on OK-VOS and two existing reasoning segmentation benchmarks demonstrate that our Seg-ReSearch improves state-of-the-art approaches by a substantial margin. Code and data will be released at https://github.com/iSEE-Laboratory/Seg-ReSearch.", "AI": {"tldr": "提出了一种新的分割范式Seg-ReSearch，该方法通过启用交错推理和外部搜索，克服了现有分割系统的知识瓶颈。", "motivation": "现有的基于语言的分割系统受限于大型多模态语言模型中冻结的知识，难以处理需要最新信息或特定领域概念的真实场景。为了解决这个问题，作者提出了Seg-ReSearch。", "method": "Seg-ReSearch通过启用交错推理和外部搜索来克服现有系统的知识瓶颈，并引入了一种分层奖励设计以有效训练这种能力。实验是在OK-VOS以及两个现有的推理分割基准上进行的。", "result": "在OK-VOS和两个现有的推理分割基准上的实验结果表明，Seg-ReSearch显著优于当前最先进的方法。", "conclusion": "通过提出Seg-ReSearch，研究者提供了一个新的方向来处理动态、开放世界的查询，并且有效地将最新的知识集成到分割任务中。"}}
{"id": "2602.04450", "pdf": "https://arxiv.org/pdf/2602.04450", "abs": "https://arxiv.org/abs/2602.04450", "authors": ["Suvadeep Mukherjee", "Björn Rohles", "Gabriele Lenzini", "Pedro Cardoso-Leite"], "title": "Can Theory-Informed Message Framing Drive Honest and Motivated Performance with Better Assessment Experiences in a Remote Assessment?", "categories": ["cs.HC"], "comment": null, "summary": "Remote unproctored assessments increasingly use messaging interventions to reduce cheating, but existing approaches lack theoretical grounding, focus narrowly on cheating suppression while overlooking performance and experience, and treat cheating as binary rather than continuous. This study examines whether messages based on 15 psychological concepts from self-determination, cognitive dissonance, social norms, and self-efficacy theories can reduce cheating while preserving performance and experience. Through an expert workshop (N=5), we developed 45 theory-informed messages and tested them with online participants (N=1232) who completed an incentivized anagram task. Participants were classified as non-cheaters (0% items cheated), partial-cheaters (1-99% cheated), or full-cheaters (100% cheated). Results show that concept-based messages reduced full-cheating occurrence by 42% (33% to 19%), increased non-cheating by 19% (53% to 63%), with no negative effects on performance or experience across integrity groups. Surprisingly, messages grounded in different theoretical concepts produced virtually identical effects. Analyses of self-rated psychological mechanisms revealed that messages influenced multiple mechanisms simultaneously rather than their intended targets, though these mechanisms predicted behavior, performance, and experience. These findings show that causal pathways are more complex than current theories predict. Practically, integrity interventions using supportive motivation rather than rule enforcement can reduce cheating without impairing performance or experience.", "AI": {"tldr": "远程评估中，通过基于心理学理论的信息框架来减少作弊行为并保持良好的考试体验。", "motivation": "现有的方法缺乏理论依据，仅关注于防止作弊而忽略了提高成绩和改善体验。本研究探讨了信息框架能否基于多种心理理论来降低作弊率同时不影响表现和体验。", "method": "通过专家工作坊开发出45条基于15种心理学概念的信息框架，并对在线参与者进行测试（N=1232），完成带激励的字母重组任务，分类为非作弊者、部分作弊者及完全作弊者。", "result": "结果显示，信息框架降低了完全作弊率42%，提高了非作弊比例19%，且不影响表现和体验。不同理论概念的信息框架产生了相似效果，并影响了多种心理机制。", "conclusion": "基于支持性动机而非规则执行的完整性干预措施可以减少作弊而不损害表现或体验，表明因果路径比现有理论预测的更复杂。"}}
{"id": "2602.04448", "pdf": "https://arxiv.org/pdf/2602.04448", "abs": "https://arxiv.org/abs/2602.04448", "authors": ["Jiacheng Liang", "Yuhui Wang", "Tanqiu Jiang", "Ting Wang"], "title": "RASA: Routing-Aware Safety Alignment for Mixture-of-Experts Models", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "9 pages", "summary": "Mixture-of-Experts (MoE) language models introduce unique challenges for safety alignment due to their sparse routing mechanisms, which can enable degenerate optimization behaviors under standard full-parameter fine-tuning. In our preliminary experiments, we observe that naively applying full-parameter safety fine-tuning to MoE models can reduce attack success rates through routing or expert dominance effects, rather than by directly repairing Safety-Critical Experts. To address this challenge, we propose RASA, a routing-aware expert-level alignment framework that explicitly repairs Safety-Critical Experts while preventing routing-based bypasses. RASA identifies experts disproportionately activated by successful jailbreaks, selectively fine-tunes only these experts under fixed routing, and subsequently enforces routing consistency with safety-aligned contexts. Across two representative MoE architectures and a diverse set of jailbreak attacks, RASA achieves near-perfect robustness, strong cross-attack generalization, and substantially reduced over-refusal, while preserving general capabilities on benchmarks such as MMLU, GSM8K, and TruthfulQA. Our results suggest that robust MoE safety alignment benefits from targeted expert repair rather than global parameter updates, offering a practical and architecture-preserving alternative to prior approaches.", "AI": {"tldr": "RASA是一种针对Mixture-of-Experts模型的安全性对齐框架，旨在通过针对性修复关键专家来防止路由绕过。", "motivation": "由于MoE模型的稀疏路由机制，在标准全参数微调下容易导致不安全优化行为。直接应用全参数安全微调可能会通过路由或专家主导效应降低攻击成功率，而不是直接修复关键安全专家。", "method": "RASA框架包括识别受攻击影响较大的专家、固定路由并针对性地对这些专家进行微调、以及在与安全性一致的上下文中强制执行路由一致性。", "result": "实验表明，RASA能够实现接近完美的鲁棒性、强大的跨攻击泛化能力，并显著减少过度拒绝现象，同时保持一般基准测试中的性能。", "conclusion": "针对MoE模型的安全对齐问题，关键专家修复而非全局参数更新是一种更有效的方法。"}}
{"id": "2602.04447", "pdf": "https://arxiv.org/pdf/2602.04447", "abs": "https://arxiv.org/abs/2602.04447", "authors": ["Giacomo Frisoni", "Lorenzo Molfetta", "Davide Freddi", "Gianluca Moro"], "title": "Mixture of Masters: Sparse Chess Language Models with Player Routing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern chess language models are dense transformers trained on millions of games played by thousands of high-rated individuals. However, these monolithic networks tend to collapse into mode-averaged behavior, where stylistic boundaries are blurred, and rare but effective strategies are suppressed. To counteract homogenization, we introduce Mixture-of-Masters (MoM), the first chess mixture-of-experts model with small-sized GPT experts emulating world-class grandmasters. Each expert is trained with a combination of self-supervised learning and reinforcement learning guided by chess-specific rewards. For each move, a post-hoc learnable gating network selects the most appropriate persona to channel depending on the game state, allowing MoM to switch its style dynamically$--$e.g., Tal's offensive vocation or Petrosian's defensive solidity. When evaluated against Stockfish on unseen standard games, MoM outperforms both dense individual expert networks and popular GPT baselines trained on aggregated data, while ensuring generation variety, control, and interpretability.", "AI": {"tldr": "本文提出了一种混合专家模型MoM，用于生成多样化的棋局策略。", "motivation": "当前的象棋语言模型趋向于平均化风格，抑制了稀有但有效的策略。为解决此问题，引入MoM模型以模仿世界级特级大师的不同风格。", "method": "通过自监督学习和强化学习训练小规模GPT专家，并利用可学习的门控网络根据游戏状态选择合适的特级大师风格。", "result": "在未见标准棋局评估中，MoM表现优于单一专家模型和广泛使用的GPT基线模型。", "conclusion": "通过混合不同风格的专家，实现了生成多样性、控制性和可解释性的目标。"}}
{"id": "2602.04442", "pdf": "https://arxiv.org/pdf/2602.04442", "abs": "https://arxiv.org/abs/2602.04442", "authors": ["Dmitry Karpov"], "title": "No One-Size-Fits-All: Building Systems For Translation to Bashkir, Kazakh, Kyrgyz, Tatar and Chuvash Using Synthetic And Original Data", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to EACL 2026 (LoResMT workshop)", "summary": "We explore machine translation for five Turkic language pairs: Russian-Bashkir, Russian-Kazakh, Russian-Kyrgyz, English-Tatar, English-Chuvash. Fine-tuning nllb-200-distilled-600M with LoRA on synthetic data achieved chrF++ 49.71 for Kazakh and 46.94 for Bashkir. Prompting DeepSeek-V3.2 with retrieved similar examples achieved chrF++ 39.47 for Chuvash. For Tatar, zero-shot or retrieval-based approaches achieved chrF++ 41.6, while for Kyrgyz the zero-shot approach reached 45.6. We release the dataset and the obtained weights.", "AI": {"tldr": "本文探索了针对五种突厥语族语言对的机器翻译系统构建，使用合成数据和原始数据进行训练。", "motivation": "由于这些语言的数据稀缺，传统方法效果不佳，作者旨在通过生成合成数据来提高翻译质量，并发布新的模型权重和数据集。", "method": "利用LoRA在合成数据上微调nllb-200-distilled-600M以改进俄语与其他四门突厥语言之间的翻译；使用DeepSeek-V3.2结合检索相似实例来优化对楚瓦什语的零样本翻译方法。", "result": "对于哈萨克语和巴什科尔托斯坦语，微调模型在chrF++指标上分别达到49.71和46.94；使用提示方法对楚瓦什语实现39.47的chrF++分数；零样本或检索驱动的方法在塔塔尔语中获得41.6的成绩，而在吉尔吉斯语中则达到了45.6。", "conclusion": "作者展示了如何利用合成数据改善低资源语言对的翻译效果，并公开了模型权重和新构建的数据集。"}}
{"id": "2602.04441", "pdf": "https://arxiv.org/pdf/2602.04441", "abs": "https://arxiv.org/abs/2602.04441", "authors": ["Weiguang Zhao", "Haoran Xu", "Xingyu Miao", "Qin Zhao", "Rui Zhang", "Kaizhu Huang", "Ning Gao", "Peizhou Cao", "Mingze Sun", "Mulin Yu", "Tao Lu", "Linning Xu", "Junting Dong", "Jiangmiao Pang"], "title": "SynthVerse: A Large-Scale Diverse Synthetic Dataset for Point Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Point tracking aims to follow visual points through complex motion, occlusion, and viewpoint changes, and has advanced rapidly with modern foundation models. Yet progress toward general point tracking remains constrained by limited high-quality data, as existing datasets often provide insufficient diversity and imperfect trajectory annotations. To this end, we introduce SynthVerse, a large-scale, diverse synthetic dataset specifically designed for point tracking. SynthVerse includes several new domains and object types missing from existing synthetic datasets, such as animated-film-style content, embodied manipulation, scene navigation, and articulated objects. SynthVerse substantially expands dataset diversity by covering a broader range of object categories and providing high-quality dynamic motions and interactions, enabling more robust training and evaluation for general point tracking. In addition, we establish a highly diverse point tracking benchmark to systematically evaluate state-of-the-art methods under broader domain shifts. Extensive experiments and analyses demonstrate that training with SynthVerse yields consistent improvements in generalization and reveal limitations of existing trackers under diverse settings.", "AI": {"tldr": "介绍了一种名为SynthVerse的大规模多样化合成数据集，专门用于点跟踪。", "motivation": "现有的数据集在多样性和轨迹标注方面存在不足，限制了通用点跟踪的进步。为此，提出了SynthVerse以解决这些问题。", "method": "通过引入新的领域和对象类型，如动画电影风格的内容、实体操作、场景导航等，并提供了高质量的动态运动和交互，从而扩展数据集多样性。", "result": "实验表明，在多样化的设置下使用SynthVerse进行训练可以显著提高模型的一般化能力，并揭示了现有跟踪器在各种条件下的局限性。", "conclusion": "通过建立一个高度多样的点跟踪基准测试，该研究证明了SynthVerse的有效性和优势。"}}
{"id": "2602.04439", "pdf": "https://arxiv.org/pdf/2602.04439", "abs": "https://arxiv.org/abs/2602.04439", "authors": ["Xingyu Miao", "Weiguang Zhao", "Tao Lu", "Linning Yu", "Mulin Yu", "Yang Long", "Jiangmiao Pang", "Junting Dong"], "title": "TrajVG: 3D Trajectory-Coupled Visual Geometry Learning", "categories": ["cs.CV"], "comment": null, "summary": "Feed-forward multi-frame 3D reconstruction models often degrade on videos with object motion. Global-reference becomes ambiguous under multiple motions, while the local pointmap relies heavily on estimated relative poses and can drift, causing cross-frame misalignment and duplicated structures. We propose TrajVG, a reconstruction framework that makes cross-frame 3D correspondence an explicit prediction by estimating camera-coordinate 3D trajectories. We couple sparse trajectories, per-frame local point maps, and relative camera poses with geometric consistency objectives: (i) bidirectional trajectory-pointmap consistency with controlled gradient flow, and (ii) a pose consistency objective driven by static track anchors that suppresses gradients from dynamic regions. To scale training to in-the-wild videos where 3D trajectory labels are scarce, we reformulate the same coupling constraints into self-supervised objectives using only pseudo 2D tracks, enabling unified training with mixed supervision. Extensive experiments across 3D tracking, pose estimation, pointmap reconstruction, and video depth show that TrajVG surpasses the current feedforward performance baseline.", "AI": {"tldr": "提出TrajVG框架，通过估计相机坐标系下的三维轨迹来解决多帧图像中的跨帧三维对应问题。", "motivation": "现有模型在处理含有运动物体的视频时性能下降，因为全局参照物在多个运动中变得模糊不清，局部点图依赖于相对姿态的估计且容易漂移。", "method": "通过耦合稀疏轨迹、每帧的局部点地图和相对相机姿态来预测跨帧三维对应关系，并使用几何一致性目标约束：双向轨迹-点图一致性和受静态跟踪锚定驱动的姿态一致性目标。", "result": "实验结果显示，TrajVG在3D追踪、姿态估计、点图重建以及视频深度方面超越了当前的前馈性能基准。", "conclusion": "提出的方法通过引入三维轨迹预测来解决跨帧对应问题，并展示了其在各种任务上的优越性。"}}
{"id": "2602.04438", "pdf": "https://arxiv.org/pdf/2602.04438", "abs": "https://arxiv.org/abs/2602.04438", "authors": ["Tobias Cook", "Leo Micklem", "Huazhi Dong", "Yunjie Yang", "Michael Mistry", "Francesco Giorgio Serchi"], "title": "Gust Estimation and Rejection with a Disturbance Observer for Proprioceptive Underwater Soft Morphing Wings", "categories": ["cs.RO"], "comment": "2026 IEEE International Conference on Robotics & Automation (ICRA)", "summary": "Unmanned underwater vehicles are increasingly employed for maintenance and surveying tasks at sea, but their operation in shallow waters is often hindered by hydrodynamic disturbances such as waves, currents, and turbulence. These unsteady flows can induce rapid changes in direction and speed, compromising vehicle stability and manoeuvrability. Marine organisms contend with such conditions by combining proprioceptive feedback with flexible fins and tails to reject disturbances. Inspired by this strategy, we propose soft morphing wings endowed with proprioceptive sensing to mitigate environmental perturbations. The wing's continuous deformation provides a natural means to infer dynamic disturbances: sudden changes in camber directly reflect variations in the oncoming flow. By interpreting this proprioceptive signal, a disturbance observer can reconstruct flow parameters in real time. To enable this, we develop and experimentally validate a dynamic model of a hydraulically actuated soft wing with controllable camber. We then show that curvature-based sensing allows accurate estimation of disturbances in the angle of attack. Finally, we demonstrate that a controller leveraging these proprioceptive estimates can reject disturbances in the lift response of the soft wing. By combining proprioceptive sensing with a disturbance observer, this technique mirrors biological strategies and provides a pathway for soft underwater vehicles to maintain stability in hazardous environments.", "AI": {"tldr": "提出了一种基于软变形翼的扰动估计和抑制方法，以增强水下无人车辆在浅水区的稳定性和机动性。", "motivation": "海底维护和调查任务中，水下无人车辆的操作受限于波浪、水流和湍流等不稳定流动所引起的快速方向和速度变化。为解决这一问题，作者受生物体使用灵活鳍来应对扰动策略启发，研究了结合本体感觉反馈的软变形翼。", "method": "开发了一种液压驱动的软变形翼模型，并通过实验验证其动态特性；利用基于曲率的感知技术准确估计迎角变化；采用干扰观测器实时重构流动参数并设计控制器以抑制扰动对升力响应的影响。", "result": "实验表明，使用本体感觉反馈和干扰观测器相结合的方法可以有效估计并减少翼面受到的环境扰动影响。", "conclusion": "通过模仿生物策略将本体感觉与干扰观测器结合，这种方法为软水下车辆在危险环境中维持稳定性提供了一种途径。"}}
{"id": "2602.04432", "pdf": "https://arxiv.org/pdf/2602.04432", "abs": "https://arxiv.org/abs/2602.04432", "authors": ["Shota Yamanaka", "I. Scott MacKenzie"], "title": "Normalizing Speed-accuracy Biases in 2D Pointing Tasks with Better Calculation of Effective Target Widths", "categories": ["cs.HC"], "comment": "To appear at CHI 2026", "summary": "For evaluations of 2D target selection using Fitts' law, ISO 9241-411 recommends using the effective target width (W_e) calculated using the univariate standard deviation of selection coordinates. Related research proposed using a bivariate standard deviation; however, the proposal was only tested using a single speed-accuracy bias condition, thus the assessment was limited. We compared the univariate and bivariate techniques in a 2D Fitts' law experiment using three speed-accuracy biases and 346 crowdworkers. Calculating W_e using the univariate standard deviation yielded higher model correlations across all bias conditions and produced more stable throughput among the biases. The findings were also consistent in cases using randomly sampled subsets of the participant data. We recommend that future research should calculate W_e using the univariate standard deviation for fair performance evaluations. Also, we found trivial effects when using nominal or effective amplitude and using different perspectives of the task axis.", "AI": {"tldr": "本文通过比较一元和二元标准差计算有效目标宽度（W_e）的方法，研究了在不同速度准确性偏差条件下使用Fitts定律评估二维目标选择性能的效果。", "motivation": "ISO 9241-411推荐使用单变量标准差来计算用于Fitts定律评估的W_e。然而，一些研究表明使用双变量标准差可能会更好。但这些研究只测试了单一的速度准确性偏差条件，因此需要进一步验证。", "method": "本文通过一个包含三种速度准确性偏好的二维Fitts定律实验，并利用346名众包工人进行数据收集。比较了一元和二元标准差计算W_e方法在不同偏好下的模型相关性和吞吐率稳定性。", "result": "使用一元标准差计算W_e产生了更高的模型关联性，且偏差之间更稳定的吞吐量。随机采样参与者子集的测试结果也显示出一致性。", "conclusion": "建议未来研究应采用一元标准差来计算W_e以进行公平性能评估；同时发现名义或有效幅度及任务轴视角的变化对结果影响较小。"}}
{"id": "2602.04419", "pdf": "https://arxiv.org/pdf/2602.04419", "abs": "https://arxiv.org/abs/2602.04419", "authors": ["Heqing Yang", "Ziyuan Jiao", "Shu Wang", "Yida Niu", "Si Liu", "Hangxin Liu"], "title": "Integrated Exploration and Sequential Manipulation on Scene Graph with LLM-based Situated Replanning", "categories": ["cs.RO"], "comment": "8 pages, 7 figures; accepted by ICRA 2026", "summary": "In partially known environments, robots must combine exploration to gather information with task planning for efficient execution. To address this challenge, we propose EPoG, an Exploration-based sequential manipulation Planning framework on Scene Graphs. EPoG integrates a graph-based global planner with a Large Language Model (LLM)-based situated local planner, continuously updating a belief graph using observations and LLM predictions to represent known and unknown objects. Action sequences are generated by computing graph edit operations between the goal and belief graphs, ordered by temporal dependencies and movement costs. This approach seamlessly combines exploration and sequential manipulation planning. In ablation studies across 46 realistic household scenes and 5 long-horizon daily object transportation tasks, EPoG achieved a success rate of 91.3%, reducing travel distance by 36.1% on average. Furthermore, a physical mobile manipulator successfully executed complex tasks in unknown and dynamic environments, demonstrating EPoG's potential for real-world applications.", "AI": {"tldr": "本文提出了EPoG框架，结合图规划和大语言模型预测，在部分已知环境中实现了高效的探索与顺序操纵任务执行。", "motivation": "在部分已知的环境下，机器人需要同时进行探索以获取信息和制定计划以便于操作任务。为解决这一问题，作者提出了一种新的框架来集成探索与顺序操纵规划。", "method": "EPoG结合了基于图的全局规划器以及大型语言模型预测的局部定位规划器，并持续更新信念图以表示已知和未知对象，通过计算目标图与信念图之间的图编辑操作生成行动序列。", "result": "在46个现实家庭场景及5项长期日常物体运输任务中进行消融研究后，EPoG取得了91.3%的成功率，并平均减少了36.1%的行走距离。此外，物理移动机械臂成功地执行了复杂的未知和动态环境中的任务。", "conclusion": "通过将探索与顺序操纵规划无缝结合，EPoG展示了其在真实世界应用中的潜力。"}}
{"id": "2602.04418", "pdf": "https://arxiv.org/pdf/2602.04418", "abs": "https://arxiv.org/abs/2602.04418", "authors": ["Arnab Mallick", "Indraveni Chebolu", "Harmesh Rana"], "title": "SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing", "categories": ["cs.MA", "cs.AI", "cs.DC", "cs.ET", "cs.SE"], "comment": null, "summary": "We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-aware heuristics, an Execution Agent allocates tasks via the Contract Net protocol, and a Repair Agent autonomously recovers from brittle generated artifacts using a programmatic-first repair policy. Agents maintain local beliefs updated through AGM-compliant revision, coordinate via negotiation and auction protocols, and revise plans as new information becomes available. An empirical study compares the multi-agent design with centralized and pipeline-based alternatives under controlled failure scenarios, focusing on coordination, recovery behavior, and resource use.", "AI": {"tldr": "SPEAR是用于智能合约审计的多代理协调框架，通过使用风险意识启发式法、任务分配协议和自动修复策略来提高审计效率。", "motivation": "为了解决智能合约安全性分析中集中化系统面临的挑战，并探索一种更灵活且容错性更高的方法，本文提出了一种基于多代理系统的解决方案。", "method": "SPEAR框架由三个专门的代理组成：规划代理通过风险意识启发式法优先处理合同；执行代理使用合同网协议分配任务；修复代理采用编程先于手动的原则自动从脆弱生成的产品中恢复。这些代理维护局部信念并通过AGM一致修订进行更新，它们通过谈判和拍卖协议协调，并在获得新信息时修改计划。", "result": "实验研究表明，在控制失效场景下，多代理设计相比集中式与管道化替代方案在协作、恢复行为及资源利用方面表现更优。", "conclusion": "SPEAR框架展示了如何将现有的多智能体系统模式应用于现实的安全性分析工作流程中，并通过实际案例研究验证了其有效性。"}}
{"id": "2602.04417", "pdf": "https://arxiv.org/pdf/2602.04417", "abs": "https://arxiv.org/abs/2602.04417", "authors": ["Lunjun Zhang", "Jimmy Ba"], "title": "EMA Policy Gradient: Taming Reinforcement Learning for LLMs with EMA Anchor and Top-k KL", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to acquire increasingly complex reasoning and agentic behaviors. In this work, we propose two simple techniques to improve policy gradient algorithms for LLMs. First, we replace the fixed anchor policy during RL with an Exponential Moving Average (EMA), similar to a target network in deep Q-learning. Second, we introduce Top-k KL estimator, which allows for flexible interpolation between exact KL and sampled KL. We derive the stability conditions for using EMA anchor; moreover, we show that our Top-k KL estimator yields both unbiased KL values and unbiased gradients at any k, while bringing the benefits of exact KL. When combined with GRPO, the two techniques (EMA-PG) lead to a significant performance boost. On math reasoning, it allows R1-distilled Qwen-1.5B to reach 53.9% on OlympiadBench compared to 50.8% by GRPO. On agentic RL domains, with Qwen-3B base, EMA-PG improves GRPO by an average of 33.3% across 7 datasets of Q&A with search engines, including 29.7% $\\rightarrow$ 44.1% on HotpotQA, 27.4% $\\rightarrow$ 40.1% on 2WikiMultiHopQA. Overall, we show that EMA-PG is a simple, principled, and powerful approach to scaling RL for LLMs. Code: https://github.com/LunjunZhang/ema-pg", "AI": {"tldr": "该论文提出了两种简单技术来改进大型语言模型（LLMs）中的策略梯度算法：使用指数移动平均（EMA）锚定和Top-k KL估计器。", "motivation": "强化学习使得大型语言模型能够获得更复杂的推理能力和代理行为。然而，现有的策略梯度算法在训练过程中可能会不稳定或表现不佳。", "method": "提出了一种使用EMA作为固定参考策略的方法，并引入了灵活的Top-k KL估计器来平衡精确KL和样本KL之间的差异。", "result": "实验表明，在数学推理任务上，改进后的技术使Qwen-1.5B模型在OlympiadBench上的表现提高了3%以上。在代理强化学习领域中，与GRPO相比，性能平均提升了33.3%，特别是在搜索引擎支持的问答任务中表现出显著提升。", "conclusion": "EMA-PG是一种简单、原理清晰且强大的方法，可以有效地扩展大型语言模型的强化学习应用。"}}
{"id": "2602.04416", "pdf": "https://arxiv.org/pdf/2602.04416", "abs": "https://arxiv.org/abs/2602.04416", "authors": ["Aavash Chhetri", "Bibek Niroula", "Pratik Shrestha", "Yash Raj Shrestha", "Lesley A Anderson", "Prashnna K Gyawali", "Loris Bazzani", "Binod Bhattarai"], "title": "Med-MMFL: A Multimodal Federated Learning Benchmark in Healthcare", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across decentralized medical institutions while preserving data privacy. However, medical FL benchmarks remain scarce, with existing efforts focusing mainly on unimodal or bimodal modalities and a limited range of medical tasks. This gap underscores the need for standardized evaluation to advance systematic understanding in medical MultiModal FL (MMFL). To this end, we introduce Med-MMFL, the first comprehensive MMFL benchmark for the medical domain, encompassing diverse modalities, tasks, and federation scenarios. Our benchmark evaluates six representative state-of-the-art FL algorithms, covering different aggregation strategies, loss formulations, and regularization techniques. It spans datasets with 2 to 4 modalities, comprising a total of 10 unique medical modalities, including text, pathology images, ECG, X-ray, radiology reports, and multiple MRI sequences. Experiments are conducted across naturally federated, synthetic IID, and synthetic non-IID settings to simulate real-world heterogeneity. We assess segmentation, classification, modality alignment (retrieval), and VQA tasks. To support reproducibility and fair comparison of future multimodal federated learning (MMFL) methods under realistic medical settings, we release the complete benchmark implementation, including data processing and partitioning pipelines, at https://github.com/bhattarailab/Med-MMFL-Benchmark .", "AI": {"tldr": "本文提出了Med-MMFL，一种用于医疗领域的多模态联邦学习基准。", "motivation": "现有的医疗联邦学习基准主要关注单一或双模态，并且涵盖的医疗任务有限。这阻碍了对医学多模态联邦学习（MMFL）的系统性理解。因此需要标准化评估以推动该领域的发展。", "method": "Med-MMFL涵盖了多种数据模式，包括文本、病理图像等，并评估六种代表性的联邦学习算法，通过自然联邦和合成的数据集设置来测试算法性能。", "result": "实验结果展示了不同联邦学习算法在多模态医疗任务中的表现。", "conclusion": "本文提出的Med-MMFL提供了全面的基准以促进医学多模态联邦学习的研究，并为未来的方法提供可重现性支持。"}}
{"id": "2602.04413", "pdf": "https://arxiv.org/pdf/2602.04413", "abs": "https://arxiv.org/abs/2602.04413", "authors": ["Xinglong Yang", "Zhilin Peng", "Zhanzhan Liu", "Haochen Shi", "Sheng-Jun Huang"], "title": "History-Guided Iterative Visual Reasoning with Self-Correction", "categories": ["cs.CL", "cs.AI", "cs.MM"], "comment": null, "summary": "Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However, most existing self-consistency methods are limited to a fixed ``repeated sampling and voting'' paradigm and do not reuse historical reasoning information. As a result, models struggle to actively correct visual understanding errors and dynamically adjust their reasoning during iteration. Inspired by the human reasoning behavior of repeated verification and dynamic error correction, we propose the H-GIVR framework. During iterative reasoning, the MLLM observes the image multiple times and uses previously generated answers as references for subsequent steps, enabling dynamic correction of errors and improving answer accuracy. We conduct comprehensive experiments on five datasets and three models. The results show that the H-GIVR framework can significantly improve cross-modal reasoning accuracy while maintaining low computational cost. For instance, using \\texttt{Llama3.2-vision:11b} on the ScienceQA dataset, the model requires an average of 2.57 responses per question to achieve an accuracy of 78.90\\%, representing a 107\\% improvement over the baseline.", "AI": {"tldr": "该论文提出了H-GIVR框架，通过历史信息引导的迭代视觉推理和自我纠正来提高多模态大型语言模型在跨模态任务中的推理准确性。", "motivation": "现有自一致性方法局限于固定的‘重复采样投票’模式，并未有效利用历史推理信息。这使得模型难以主动更正视觉理解错误，动态调整推理过程。", "method": "H-GIVR框架通过多次观察图像并使用先前生成的答案作为后续步骤的参考，实现了动态错误校正和提高答案准确性。", "result": "实验表明，H-GIVR框架能显著提升跨模态推理准确率且计算成本低。例如，在ScienceQA数据集上，\texttt{Llama3.2-vision:11b}模型平均每题只需2.57次回应即可达到78.90%的准确率，相比基线提高了107%。", "conclusion": "H-GIVR框架通过历史信息引导迭代推理并进行自我纠正，有效提升了跨模态任务中的视觉理解准确性。"}}
{"id": "2602.04412", "pdf": "https://arxiv.org/pdf/2602.04412", "abs": "https://arxiv.org/abs/2602.04412", "authors": ["Puyue Wang", "Jiawei Hu", "Yan Gao", "Junyan Wang", "Yu Zhang", "Gillian Dobbie", "Tao Gu", "Wafa Johal", "Ting Dang", "Hong Jia"], "title": "HoRD: Robust Humanoid Control via History-Conditioned Reinforcement Learning and Online Distillation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Humanoid robots can suffer significant performance drops under small changes in dynamics, task specifications, or environment setup. We propose HoRD, a two-stage learning framework for robust humanoid control under domain shift. First, we train a high-performance teacher policy via history-conditioned reinforcement learning, where the policy infers latent dynamics context from recent state--action trajectories to adapt online to diverse randomized dynamics. Second, we perform online distillation to transfer the teacher's robust control capabilities into a transformer-based student policy that operates on sparse root-relative 3D joint keypoint trajectories. By combining history-conditioned adaptation with online distillation, HoRD enables a single policy to adapt zero-shot to unseen domains without per-domain retraining. Extensive experiments show HoRD outperforms strong baselines in robustness and transfer, especially under unseen domains and external perturbations. Code and project page are available at \\href{https://tonywang-0517.github.io/hord/}{https://tonywang-0517.github.io/hord/}.", "AI": {"tldr": "本文提出了一种用于增强人形机器人控制鲁棒性的两阶段学习框架HoRD。", "motivation": "面对环境变化，任务规格或设置的小改变时，人形机器人可能会遭受显著的性能下降。为了解决这一问题，文章提出了HoRD框架以提高机器人的适应性和鲁棒性。", "method": "首先通过历史条件强化学习训练一个高性能教师策略，该策略可以从最近的状态-动作轨迹中推断出潜在的动力学背景以便实时适应各种随机动力学变化。接着通过在线知识蒸馏将教师的控制能力转移到基于Transformer的学生策略上，学生策略操作稀疏根相对3D关节关键点轨迹。", "result": "实验表明HoRD在鲁棒性与迁移方面优于强大的基准方法，尤其是在未见过的任务和外部干扰下表现更优。", "conclusion": "通过结合历史条件适应能力和在线知识蒸馏技术，HoRD框架使单一策略能够无需重新训练就适应新的未知领域。"}}
{"id": "2602.04411", "pdf": "https://arxiv.org/pdf/2602.04411", "abs": "https://arxiv.org/abs/2602.04411", "authors": ["Tongtong Feng", "Xin Wang", "Wenwu Zhu"], "title": "Self-evolving Embodied AI", "categories": ["cs.ET", "cs.CV"], "comment": null, "summary": "Embodied Artificial Intelligence (AI) is an intelligent system formed by agents and their environment through active perception, embodied cognition, and action interaction. Existing embodied AI remains confined to human-crafted setting, in which agents are trained on given memory and construct models for given tasks, enabling fixed embodiments to interact with relatively static environments. Such methods fail in in-the-wild setting characterized by variable embodiments and dynamic open environments. This paper introduces self-evolving embodied AI, a new paradigm in which agents operate based on their changing state and environment with memory self-updating, task self-switching, environment self-prediction, embodiment self-adaptation, and model self-evolution, aiming to achieve continually adaptive intelligence with autonomous evolution. Specifically, we present the definition, framework, components, and mechanisms of self-evolving embodied AI, systematically review state-of-the-art works for realized components, discuss practical applications, and point out future research directions. We believe that self-evolving embodied AI enables agents to autonomously learn and interact with environments in a human-like manner and provide a new perspective toward general artificial intelligence.", "AI": {"tldr": "介绍了一种新的自演化实体AI范式，使智能体能够根据其状态和环境的变化进行自我更新、任务切换、环境预测、本体适应以及模型进化。", "motivation": "现有实体AI局限于人为设定的场景，在动态开放环境中表现不佳。为了实现持续适应性和自主演化的智能，提出了自演化实体AI。", "method": "定义了自演化实体AI的概念框架及其组成机制，并回顾了当前最先进的工作以实现这些组件，探讨实际应用并指出未来研究方向。", "result": "提出了一种新的技术路线和理论模型来解决现有实体AI在开放环境中的局限性问题。", "conclusion": "自演化实体AI使智能体能够像人类一样自主学习和与环境互动，并为通用人工智能提供了一个新视角。"}}
{"id": "2602.04406", "pdf": "https://arxiv.org/pdf/2602.04406", "abs": "https://arxiv.org/abs/2602.04406", "authors": ["Jue Gong", "Zihan Zhou", "Jingkai Wang", "Shu Li", "Libo Liu", "Jianliang Lan", "Yulun Zhang"], "title": "LCUDiff: Latent Capacity Upgrade Diffusion for Faithful Human Body Restoration", "categories": ["cs.CV"], "comment": "8 pages, 7 figures. The code and model will be at https://github.com/gobunu/LCUDiff", "summary": "Existing methods for restoring degraded human-centric images often struggle with insufficient fidelity, particularly in human body restoration (HBR). Recent diffusion-based restoration methods commonly adapt pre-trained text-to-image diffusion models, where the variational autoencoder (VAE) can significantly bottleneck restoration fidelity. We propose LCUDiff, a stable one-step framework that upgrades a pre-trained latent diffusion model from the 4-channel latent space to the 16-channel latent space. For VAE fine-tuning, channel splitting distillation (CSD) is used to keep the first four channels aligned with pre-trained priors while allocating the additional channels to effectively encode high-frequency details. We further design prior-preserving adaptation (PPA) to smoothly bridge the mismatch between 4-channel diffusion backbones and the higher-dimensional 16-channel latent. In addition, we propose a decoder router (DeR) for per-sample decoder routing using restoration-quality score annotations, which improves visual quality across diverse conditions. Experiments on synthetic and real-world datasets show competitive results with higher fidelity and fewer artifacts under mild degradations, while preserving one-step efficiency. The code and model will be at https://github.com/gobunu/LCUDiff.", "AI": {"tldr": "提出了LCUDiff框架，用于提高人体图像恢复的质量和保真度。", "motivation": "现有的图像修复方法在处理人体图像时存在细节缺失的问题。通过改进扩散模型的隐式空间，以提升图像恢复的质量和保真度。", "method": "提出了一种从4通道到16通道升级预训练扩散模型的方法，并设计了前缀保持适应（PPA）和解码器路由器（DeR）来提高图像质量。", "result": "实验结果表明，该方法在合成数据集和真实世界数据集中均表现出更高的保真度和较少的伪影，在轻微退化情况下表现尤为突出。", "conclusion": "LCUDiff框架提高了人体图像恢复的质量，并保持了一步修复的效率。"}}
{"id": "2602.04405", "pdf": "https://arxiv.org/pdf/2602.04405", "abs": "https://arxiv.org/abs/2602.04405", "authors": ["Yixin Zhu", "Long Lv", "Pingping Zhang", "Xuehu Liu", "Tongdan Tang", "Feng Tian", "Weibing Sun", "Huchuan Lu"], "title": "Interactive Spatial-Frequency Fusion Mamba for Multi-Modal Image Fusion", "categories": ["cs.CV", "cs.MM"], "comment": "This work is accepted by IEEE Transactions on Image Processing. More modifications may be performed", "summary": "Multi-Modal Image Fusion (MMIF) aims to combine images from different modalities to produce fused images, retaining texture details and preserving significant information. Recently, some MMIF methods incorporate frequency domain information to enhance spatial features. However, these methods typically rely on simple serial or parallel spatial-frequency fusion without interaction. In this paper, we propose a novel Interactive Spatial-Frequency Fusion Mamba (ISFM) framework for MMIF. Specifically, we begin with a Modality-Specific Extractor (MSE) to extract features from different modalities. It models long-range dependencies across the image with linear computational complexity. To effectively leverage frequency information, we then propose a Multi-scale Frequency Fusion (MFF). It adaptively integrates low-frequency and high-frequency components across multiple scales, enabling robust representations of frequency features. More importantly, we further propose an Interactive Spatial-Frequency Fusion (ISF). It incorporates frequency features to guide spatial features across modalities, enhancing complementary representations. Extensive experiments are conducted on six MMIF datasets. The experimental results demonstrate that our ISFM can achieve better performances than other state-of-the-art methods. The source code is available at https://github.com/Namn23/ISFM.", "AI": {"tldr": "提出了交互式空间频域融合Mamba框架用于多模态图像融合。", "motivation": "目前的多模态图像融合方法主要依赖于简单的串行或并行的空间和频率领域的组合，缺乏相互作用。因此提出一种新的交互方式来提高融合效果。", "method": "采用了特定模态提取器MSE从不同模态中提取特征，并通过多尺度频域融合MFF自适应地整合低频和高频组件，在多个尺度上提供鲁棒的频率表示。更重要的是，提出了一个交互式空间频域融合ISF来将频率特征引导到跨模式的空间特征中。", "result": "实验结果表明提出的ISFM框架在多模态图像融合任务上的性能优于其他最新方法。", "conclusion": "ISFM框架通过引入MSE、MFF和ISF显著提升了多模态图像的融合效果。"}}
{"id": "2602.04402", "pdf": "https://arxiv.org/pdf/2602.04402", "abs": "https://arxiv.org/abs/2602.04402", "authors": ["Julian Rodemann", "Unai Fischer-Abaigar", "James Bailie", "Krikamol Muandet"], "title": "Performative Learning Theory", "categories": ["stat.ML", "cs.AI", "cs.CY", "cs.LG", "math.ST"], "comment": "52 pages, 2 figures", "summary": "Performative predictions influence the very outcomes they aim to forecast. We study performative predictions that affect a sample (e.g., only existing users of an app) and/or the whole population (e.g., all potential app users). This raises the question of how well models generalize under performativity. For example, how well can we draw insights about new app users based on existing users when both of them react to the app's predictions? We address this question by embedding performative predictions into statistical learning theory. We prove generalization bounds under performative effects on the sample, on the population, and on both. A key intuition behind our proofs is that in the worst case, the population negates predictions, while the sample deceptively fulfills them. We cast such self-negating and self-fulfilling predictions as min-max and min-min risk functionals in Wasserstein space, respectively. Our analysis reveals a fundamental trade-off between performatively changing the world and learning from it: the more a model affects data, the less it can learn from it. Moreover, our analysis results in a surprising insight on how to improve generalization guarantees by retraining on performatively distorted samples. We illustrate our bounds in a case study on prediction-informed assignments of unemployed German residents to job trainings, drawing upon administrative labor market records from 1975 to 2017 in Germany.", "AI": {"tldr": "本文研究了预测影响样本和/或整体人群的情况下的泛化性能。", "motivation": "在机器学习中，模型的预测可能会改变其自身所试图预测的数据。这提出了如何在这种情况下评估模型泛化的挑战。", "method": "通过引入统计学习理论中的执行性效应，证明了样本、总体及两者影响下的一般化界限，并将其解释为Wasserstein空间内的最小最大和最小极小风险函数。", "result": "揭示了一个关键的权衡：模型对数据的影响越大，其从数据中学习的能力就越弱。通过重新训练被执行性扭曲的数据可以改善泛化保证。", "conclusion": "研究结果表明，在预测影响整体人群时，存在一个关于如何在改变世界的同时从中学到更多知识的基本权衡关系。"}}
{"id": "2602.04401", "pdf": "https://arxiv.org/pdf/2602.04401", "abs": "https://arxiv.org/abs/2602.04401", "authors": ["Dhyey Manish Rajani", "Michael Milford", "Tobias Fischer"], "title": "Quantile Transfer for Reliable Operating Point Selection in Visual Place Recognition", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Visual Place Recognition (VPR) is a key component for localisation in GNSS-denied environments, but its performance critically depends on selecting an image matching threshold (operating point) that balances precision and recall. Thresholds are typically hand-tuned offline for a specific environment and fixed during deployment, leading to degraded performance under environmental change. We propose a method that, given a user-defined precision requirement, automatically selects the operating point of a VPR system to maximise recall. The method uses a small calibration traversal with known correspondences and transfers thresholds to deployment via quantile normalisation of similarity score distributions. This quantile transfer ensures that thresholds remain stable across calibration sizes and query subsets, making the method robust to sampling variability. Experiments with multiple state-of-the-art VPR techniques and datasets show that the proposed approach consistently outperforms the state-of-the-art, delivering up to 25% higher recall in high-precision operating regimes. The method eliminates manual tuning by adapting to new environments and generalising across operating conditions. Our code will be released upon acceptance.", "AI": {"tldr": "本文提出了一种基于分位数转换的方法，以自动选择视觉位置识别系统的操作点，从而在满足用户定义的精度要求的同时最大化召回率。", "motivation": "视觉位置识别（VPR）性能依赖于匹配阈值的选择。传统方法中阈值固定且需手动调整，这导致环境变化时性能下降。本文旨在解决这一问题，并提高算法适应性和鲁棒性。", "method": "该方法通过小规模的校准遍历和已知对应关系，在部署过程中使用分位数转换将相似度评分分布从校准数据转移到查询子集中，从而自动选择操作点以满足精度要求并最大化召回率。", "result": "实验结果表明，与现有方法相比，所提方法在高精度工作模式下可提高高达25%的召回率，并且能够适应新环境和一般化操作条件。", "conclusion": "本文提出的方法通过消除手动调整需求，提高了视觉位置识别系统在不同环境下的稳定性和性能表现。"}}
{"id": "2602.04398", "pdf": "https://arxiv.org/pdf/2602.04398", "abs": "https://arxiv.org/abs/2602.04398", "authors": ["Yujie Lin", "Kunquan Li", "Yixuan Liao", "Xiaoxin Chen", "Jinsong Su"], "title": "Bi-directional Bias Attribution: Debiasing Large Language Models without Modifying Prompts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities across a wide range of natural language processing tasks. However, their outputs often exhibit social biases, raising fairness concerns. Existing debiasing methods, such as fine-tuning on additional datasets or prompt engineering, face scalability issues or compromise user experience in multi-turn interactions. To address these challenges, we propose a framework for detecting stereotype-inducing words and attributing neuron-level bias in LLMs, without the need for fine-tuning or prompt modification. Our framework first identifies stereotype-inducing adjectives and nouns via comparative analysis across demographic groups. We then attribute biased behavior to specific neurons using two attribution strategies based on integrated gradients. Finally, we mitigate bias by directly intervening on their activations at the projection layer. Experiments on three widely used LLMs demonstrate that our method effectively reduces bias while preserving overall model performance. Code is available at the github link: https://github.com/XMUDeepLIT/Bi-directional-Bias-Attribution.", "AI": {"tldr": "本文提出了一种在不修改提示的情况下减少大型语言模型偏见的方法。", "motivation": "现有的去偏方法如微调或提示工程存在可扩展性问题，影响用户体验。本研究旨在开发一种无需对提示进行修改即可减轻LLM中社会偏见的框架。", "method": "该框架首先通过跨人群比较分析识别出刻板印象诱导形容词和名词，并使用基于集成梯度的两种归因策略将偏见行为追溯到特定神经元，最后通过对投影层中的激活直接干预来缓解偏见。", "result": "实验结果表明，在不损害整体模型性能的情况下，该方法能够有效减少大型语言模型中的偏见。", "conclusion": "本文提出的方法有效地解决了现有去偏框架中存在的问题，为改善大型语言模型的公平性提供了一种新途径。"}}
{"id": "2602.04396", "pdf": "https://arxiv.org/pdf/2602.04396", "abs": "https://arxiv.org/abs/2602.04396", "authors": ["Andrej Jovanović", "Alex Iacob", "Mher Safaryan", "Ionut-Vlad Modoranu", "Lorenzo Sani", "William F. Shen", "Xinchi Qiu", "Dan Alistarh", "Nicholas D. Lane"], "title": "LoRDO: Distributed Low-Rank Optimization with Infrequent Communication", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint; under review", "summary": "Distributed training of foundation models via $\\texttt{DDP}$ is limited by interconnect bandwidth. While infrequent communication strategies reduce synchronization frequency, they remain bottlenecked by the memory and communication requirements of optimizer states. Low-rank optimizers can alleviate these constraints; however, in the local-update regime, workers lack access to the full-batch gradients required to compute low-rank projections, which degrades performance. We propose $\\texttt{LoRDO}$, a principled framework unifying low-rank optimization with infrequent synchronization. We first demonstrate that, while global projections based on pseudo-gradients are theoretically superior, they permanently restrict the optimization trajectory to a low-rank subspace. To restore subspace exploration, we introduce a full-rank quasi-hyperbolic update. $\\texttt{LoRDO}$ achieves near-parity with low-rank $\\texttt{DDP}$ in language modeling and downstream tasks at model scales of $125$M--$720$M, while reducing communication by $\\approx 10 \\times$. Finally, we show that $\\texttt{LoRDO}$ improves performance even more in very low-memory settings with small rank/batch size.", "AI": {"tldr": "介绍了一种名为LoRDO的分布式低秩优化框架，该框架结合了低秩优化和稀疏通信策略以减少通信开销。", "motivation": "现有的分布式训练通过DDP受带宽限制。虽然不频繁的通信方法可以降低同步频率，但它们仍然受到优化器状态所需的内存和通信需求的影响。低秩优化器能够减轻这些约束，但在本地更新阶段，由于无法访问全局梯度而性能下降。", "method": "LoRDO框架采用全秩准双曲正切更新来恢复子空间探索能力，并提出了基于伪梯度的全局投影方法以减少通信开销。", "result": "LoRDO在语言建模和下游任务上实现了与低秩DDP相当的表现，同时减少了大约10倍的通信量。此外，在内存受限环境下，使用小秩/批次大小时性能进一步提高。", "conclusion": "通过结合低秩优化和稀疏同步策略，LoRDO不仅提高了分布式训练效率，还增强了模型在资源受限环境下的表现"}}
{"id": "2602.04393", "pdf": "https://arxiv.org/pdf/2602.04393", "abs": "https://arxiv.org/abs/2602.04393", "authors": ["Ritik Batra", "Roy Zunder", "Amy Cheatle", "Amritansh Kwatra", "Ilan Mandel", "Thijs Roumen", "Steven J. Jackson"], "title": "Convivial Fabrication: Towards Relational Computational Tools For and From Craft Practices", "categories": ["cs.HC", "cs.CY"], "comment": "Conditionally accepted to ACM CHI 2026, Barcelona, Spain", "summary": "Computational tools for fabrication often treat materials as passive rather than active participants in design, abstracting away relationships between craftspeople and materials. For craft communities that value relational practices, abstractions limit the adoption and creative uptake of computational tools which might otherwise be beneficial. To understand how better tool design could support richer relations between individuals, tools, and materials, we interviewed expert woodworkers, fiber artists, and metalworkers. We identify three orders of convivial relations central to craft: immediate relations between individuals, tools, and materials; mid-range relations between communities, platforms, and shared materials; and extended relations between institutions, infrastructures, and ecologies. Our analysis shows how craftspeople engage and struggle with convivial relations across all three orders, creating workflows that learn from materials while supporting autonomy. We conclude with design principles for computational tools and infrastructures to better support material dialogue, collective knowledge, and accountability, along with richer and more convivial relations between craftspeople, tools, and the material worlds around them.", "AI": {"tldr": "研究旨在通过访谈专家匠人来设计更适合手工艺实践的计算工具，这些工具能够支持个体、工具与材料之间的更丰富的关系。", "motivation": "传统的计算工具往往忽略了材料作为主动参与者的重要性以及工匠和材料之间关系的价值。因此，为了促进这种有价值的手工艺品价值实现并提高工具的实际使用率，研究试图开发出更加适应手工艺实践的计算工具。", "method": "通过采访木工、纤维艺术家及金属工人等专家来识别三种有助于手工艺实践中个体与工具以及材料间更丰富关系的形式：即时关系、中距离关系和扩展关系。", "result": "研究发现，工匠们在处理这些关系时有独特的经验，并且他们创造了能够从材料中学到东西同时又能保持独立性的工作流程。", "conclusion": "提出了设计原则以支持计算工具和基础设施更好的促进材料对话、集体知识以及责任感的实现，并进一步丰富手艺人与工具及其周围物质世界之间的关系。"}}
{"id": "2602.04386", "pdf": "https://arxiv.org/pdf/2602.04386", "abs": "https://arxiv.org/abs/2602.04386", "authors": ["Yahel Uffenheimer", "Omri Weinstein"], "title": "Improved Sparse Recovery for Approximate Matrix Multiplication", "categories": ["cs.DS"], "comment": null, "summary": "We present a simple randomized algorithm for approximate matrix multiplication (AMM) whose error scales with the *output* norm $\\|AB\\|_F$. Given any $n\\times n$ matrices $A,B$ and a runtime parameter $r\\leq n$, the algorithm produces in $O(n^2(r+\\log n))$ time, a matrix $C$ with total squared error $\\mathbb{E}[\\|C-AB\\|_F^2]\\le (1-\\frac{r}{n})\\|AB\\|_F^2$, per-entry variance $\\|AB\\|_F^2/n^2$ and bias $\\mathbb{E}[C]=\\frac{r}{n}AB$. Alternatively, the algorithm can compute an *unbiased* estimation with expected total squared error $\\frac{n}{r}\\|{AB}\\|_{F}^2$, recovering the state-of-art AMM error obtained by Pagh's TensorSketch algorithm (Pagh, 2013). Our algorithm is a log-factor faster. The key insight in the algorithm is a new variation of pseudo-random rotation of the input matrices (a Fast Hadamard Transform with asymmetric diagonal scaling), which redistributes the Frobenius norm of the *output* $AB$ uniformly across its entries.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.04385", "pdf": "https://arxiv.org/pdf/2602.04385", "abs": "https://arxiv.org/abs/2602.04385", "authors": ["Marco Picone", "Fabio Turazza", "Matteo Martinelli", "Marco Mamei"], "title": "Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications", "categories": ["cs.AI", "cs.SE"], "comment": "Author-accepted manuscript of a paper published in the 2025 IEEE International Conference on Systems, Man and Cybernetics (IEEE SMC), October 2025, doi: 10.1109/SMC58881.2025.11343418", "summary": "The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level intelligent functionalities. Recently, Digital Twin (DT) technology has emerged as a promising solution, offering structured, interoperable and semantically rich digital representations of physical assets. Current approaches are often siloed and tightly coupled, limiting scalability and reuse of AI functionalities. This work proposes a modular and interoperable solution that enables seamless AI pipeline integration into CPS by minimizing configuration and decoupling the roles of DTs and AI components. We introduce the concept of Zero Configuration (ZeroConf) AI pipelines, where DTs orchestrate data management and intelligent augmentation. The approach is demonstrated in a MicroFactory scenario, showing support for concurrent ML models and dynamic data processing, effectively accelerating the deployment of intelligent services in complex industrial settings.", "AI": {"tldr": "本文提出了一种基于数字孪生的零配置AI管道解决方案，以提高工业环境中人工智能和机器学习技术的有效集成。", "motivation": "由于物联网和IIoT技术之间的碎片化问题，使得在复杂的网络物理系统中有效整合AI和ML变得困难。该论文旨在通过引入一种新的方法来解决这一挑战，即利用数字孪生实现零配置的AI管道，以促进无缝数据管理与智能增强。", "method": "本文提出了一种基于数字孪生技术的模块化、互操作性的解决方案，并引入了“零配置”AI管道的概念。该方案使得在复杂的工业环境中可以轻松部署和集成人工智能服务，通过优化数据处理流程和动态模型调整来提高效率。", "result": "所提出的系统在一个微工厂场景中进行了演示，在这个场景下支持并发的机器学习模型以及动态的数据处理，从而有效地加速了智能服务在复杂环境中的部署。", "conclusion": "该论文展示了一种通过零配置AI管道解决工业环境中人工智能技术集成挑战的方法，并证明其可以通过优化数据处理流程和动态调整来提高效率。这种方法可以为未来的工业自动化提供一个有力的支持框架。"}}
{"id": "2602.04384", "pdf": "https://arxiv.org/pdf/2602.04384", "abs": "https://arxiv.org/abs/2602.04384", "authors": ["Fabio Turazza", "Alessandro Neri", "Marcello Pietri", "Maria Angela Butturi", "Marco Picone", "Marco Mamei"], "title": "Blockchain Federated Learning for Sustainable Retail: Reducing Waste through Collaborative Demand Forecasting", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Author-accepted manuscript of a paper published in the IEEE International Symposium on Computers and Communications (ISCC), 2025, pp. 1-6. doi: https://doi.org/10.1109/ISCC65549.2025.11326299", "summary": "Effective demand forecasting is crucial for reducing food waste. However, data privacy concerns often hinder collaboration among retailers, limiting the potential for improved predictive accuracy. In this study, we explore the application of Federated Learning (FL) in Sustainable Supply Chain Management (SSCM), with a focus on the grocery retail sector dealing with perishable goods. We develop a baseline predictive model for demand forecasting and waste assessment in an isolated retailer scenario. Subsequently, we introduce a Blockchain-based FL model, trained collaboratively across multiple retailers without direct data sharing. Our preliminary results show that FL models have performance almost equivalent to the ideal setting in which parties share data with each other, and are notably superior to models built by individual parties without sharing data, cutting waste and boosting efficiency.", "AI": {"tldr": "研究探索了联邦学习在可持续供应链管理中的应用，特别是在减少食品浪费方面，通过区块链技术实现跨零售商合作的需求预测。", "motivation": "有效的需求预测对于减少食物浪费至关重要。然而，数据隐私问题阻碍了零售商之间的协作，限制了改进预测准确性的潜力。", "method": "开发了一个孤立零售商场景下的基线预测模型，并引入了一种基于区块链的联邦学习模型，在不直接共享数据的情况下跨多个零售商进行训练。", "result": "实验结果表明，联邦学习模型的表现接近理想的数据共享情况，并显著优于未共享数据的个体模型，减少了浪费并提高了效率。", "conclusion": "通过应用区块链支持的联邦学习，可以在保护隐私的同时提高需求预测的准确性，从而减少食品浪费和提升供应链管理效率。"}}
{"id": "2602.04381", "pdf": "https://arxiv.org/pdf/2602.04381", "abs": "https://arxiv.org/abs/2602.04381", "authors": ["Weihao Gao", "Zhuo Deng", "Zheng Gong", "Lan Ma"], "title": "Enabling Real-Time Colonoscopic Polyp Segmentation on Commodity CPUs via Ultra-Lightweight Architecture", "categories": ["cs.CV", "cs.AI"], "comment": "19pages, 5 figures", "summary": "Early detection of colorectal cancer hinges on real-time, accurate polyp identification and resection. Yet current high-precision segmentation models rely on GPUs, making them impractical to deploy in primary hospitals, mobile endoscopy units, or capsule robots. To bridge this gap, we present the UltraSeg family, operating in an extreme-compression regime (<0.3 M parameters). UltraSeg-108K (0.108 M parameters) is optimized for single-center data, while UltraSeg-130K (0.13 M parameters) generalizes to multi-center, multi-modal images. By jointly optimizing encoder-decoder widths, incorporating constrained dilated convolutions to enlarge receptive fields, and integrating a cross-layer lightweight fusion module, the models achieve 90 FPS on a single CPU core without sacrificing accuracy. Evaluated on seven public datasets, UltraSeg retains >94% of the Dice score of a 31 M-parameter U-Net while utilizing only 0.4% of its parameters, establishing a strong, clinically viable baseline for the extreme-compression domain and offering an immediately deployable solution for resource-constrained settings. This work provides not only a CPU-native solution for colonoscopy but also a reproducible blueprint for broader minimally invasive surgical vision applications. Source code is publicly available to ensure reproducibility and facilitate future benchmarking.", "AI": {"tldr": "论文提出了一种轻量级的结肠息肉分割模型，该模型能够在普通CPU上实现实时准确的息肉检测。", "motivation": "当前高精度的息肉分割模型依赖于GPU，在资源受限环境中部署困难。为了克服这一问题，论文开发了在单一CPU核心上运行且参数数量极低的UltraSeg家族模型。", "method": "通过优化编码器-解码器宽度、引入约束膨胀卷积和集成跨层轻量级融合模块等方法，实现了低参数量下的高效息肉分割任务。", "result": "实验表明，与传统的U-Net相比，UltraSeg在保持94%以上Dice分数的同时，仅使用了0.4%的参数。模型实现在单一CPU核心上达到90 FPS的处理速度，并且在七个公共数据集上的评估中表现出色。", "conclusion": "论文提出的方法提供了一种适用于结肠镜检查及更广泛微创手术视觉应用领域的CPU原生解决方案，为资源受限环境下的实时息肉检测提供了可部署的基础。"}}
{"id": "2602.04380", "pdf": "https://arxiv.org/pdf/2602.04380", "abs": "https://arxiv.org/abs/2602.04380", "authors": ["Rui Yuan", "Mykola Khandoga", "Vinay Kumar Sankarapu"], "title": "Beyond KL Divergence: Policy Optimization with Flexible Bregman Divergences for LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Policy optimization methods like Group Relative Policy Optimization (GRPO) and its variants have achieved strong results on mathematical reasoning and code generation tasks. Despite extensive exploration of reward processing strategies and training dynamics, all existing group-based methods exclusively use KL divergence for policy regularization, leaving the choice of divergence function unexplored. We introduce Group-Based Mirror Policy Optimization (GBMPO), a framework that extends group-based policy optimization to flexible Bregman divergences, including hand-designed alternatives (L2 in probability space) and learned neural mirror maps. On GSM8K mathematical reasoning, hand-designed ProbL2-GRPO achieves 86.7% accuracy, improving +5.5 points over the Dr. GRPO baseline. On MBPP code generation, neural mirror maps reach 60.1-60.8% pass@1, with random initialization already capturing most of the benefit. While evolutionary strategies meta-learning provides marginal accuracy improvements, its primary value lies in variance reduction ($\\pm$0.2 versus $\\pm$0.6) and efficiency gains (15% shorter responses on MBPP), suggesting that random initialization of neural mirror maps is sufficient for most practical applications. These results establish divergence choice as a critical, previously unexplored design dimension in group-based policy optimization for LLM reasoning.", "AI": {"tldr": "论文提出了基于Bregman散度的策略优化框架GBMPO，用于大规模语言模型中的推理任务。", "motivation": "现有方法在数学推导和代码生成中取得了较好的效果，但都使用KL散度作为唯一的策略正则化方式。本文动机在于探索更灵活的散度选择对策略优化的影响。", "method": "提出了基于Bregman散度的GBMPO框架，包括手工设计的L2概率空间及学习神经镜像映射方法。通过对比不同任务中的表现来验证其有效性。", "result": "在GSM8K数学推理上，手动设计的概率L2-GRPO达到了86.7%准确率；MBPP代码生成中，随机初始化神经映射已经取得了大部分收益。", "conclusion": "选择适当的散度作为正则化项是改进大规模语言模型策略优化的重要途径。"}}
{"id": "2602.04361", "pdf": "https://arxiv.org/pdf/2602.04361", "abs": "https://arxiv.org/abs/2602.04361", "authors": ["Zekun Li", "Ning Wang", "Tongxin Bai", "Changwang Mei", "Peisong Wang", "Shuang Qiu", "Jian Cheng"], "title": "SparVAR: Exploring Sparsity in Visual AutoRegressive Modeling for Training-Free Acceleration", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Visual AutoRegressive (VAR) modeling has garnered significant attention for its innovative next-scale prediction paradigm. However, mainstream VAR paradigms attend to all tokens across historical scales at each autoregressive step. As the next scale resolution grows, the computational complexity of attention increases quartically with resolution, causing substantial latency. Prior accelerations often skip high-resolution scales, which speeds up inference but discards high-frequency details and harms image quality. To address these problems, we present SparVAR, a training-free acceleration framework that exploits three properties of VAR attention: (i) strong attention sinks, (ii) cross-scale activation similarity, and (iii) pronounced locality. Specifically, we dynamically predict the sparse attention pattern of later high-resolution scales from a sparse decision scale, and construct scale self-similar sparse attention via an efficient index-mapping mechanism, enabling high-efficiency sparse attention computation at large scales. Furthermore, we propose cross-scale local sparse attention and implement an efficient block-wise sparse kernel, which achieves $\\mathbf{> 5\\times}$ faster forward speed than FlashAttention. Extensive experiments demonstrate that the proposed SparseVAR can reduce the generation time of an 8B model producing $1024\\times1024$ high-resolution images to the 1s, without skipping the last scales. Compared with the VAR baseline accelerated by FlashAttention, our method achieves a $\\mathbf{1.57\\times}$ speed-up while preserving almost all high-frequency details. When combined with existing scale-skipping strategies, SparseVAR attains up to a $\\mathbf{2.28\\times}$ acceleration, while maintaining competitive visual generation quality. Code is available at https://github.com/CAS-CLab/SparVAR.", "AI": {"tldr": "本文提出了SparVAR框架，利用稀疏注意力机制来加速视觉自回归模型的推断过程。", "motivation": "当前的视觉自回归模型在处理高分辨率图像时存在计算复杂度高的问题，导致推理时间过长。现有的加速方法通常会跳过高分辨率尺度以牺牲图像质量为代价加快速度。", "method": "SparVAR框架通过动态预测稀疏注意力模式、构造跨尺度自相似稀疏注意机制以及实现高效的块状稀疏核来减少计算复杂度和提高推断速度。", "result": "实验结果表明，SparseVAR在不跳过高分辨率尺度的情况下可以将生成时间降低到1秒以内。相比FlashAttention加速的基线模型，SparVAR实现了显著的速度提升并保持了图像质量。", "conclusion": "本文提出的SparVAR框架能够在保证视觉生成质量的同时实现高效的推断速度，为大规模自回归建模提供了一种新的解决方案。"}}
{"id": "2602.04360", "pdf": "https://arxiv.org/pdf/2602.04360", "abs": "https://arxiv.org/abs/2602.04360", "authors": ["Fabiano Veglianti", "Lorenzo Antonelli", "Gabriele Tolomei"], "title": "Counterfactual Explanations for Hypergraph Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "Hypergraph neural networks (HGNNs) effectively model higher-order interactions in many real-world systems but remain difficult to interpret, limiting their deployment in high-stakes settings. We introduce CF-HyperGNNExplainer, a counterfactual explanation method for HGNNs that identifies the minimal structural changes required to alter a model's prediction. The method generates counterfactual hypergraphs using actionable edits limited to removing node-hyperedge incidences or deleting hyperedges, producing concise and structurally meaningful explanations. Experiments on three benchmark datasets show that CF-HyperGNNExplainer generates valid and concise counterfactuals, highlighting the higher-order relations most critical to HGNN decisions.", "AI": {"tldr": "论文提出了CF-HyperGNNExplainer方法，用于生成超图神经网络（HGNN）模型预测的反事实解释。", "motivation": "由于超图神经网络难以解释，在高风险环境中部署时存在限制。因此提出了一种新的方法来解释这些模型的决策过程。", "method": "CF-HyperGNNExplainer通过删除节点-超边关联或删除超边的方式生成反事实超图，从而最小化结构变化以改变模型预测。", "result": "实验结果表明该方法能够在三个基准数据集上产生有效且简洁的反事实解释，并能够突出HGNN决策过程中最关键的高阶关系。", "conclusion": "CF-HyperGNNExplainer提供了一种有效的手段来理解超图神经网络的行为，增加了模型在实际应用中的可信任度和透明度。"}}
{"id": "2602.04356", "pdf": "https://arxiv.org/pdf/2602.04356", "abs": "https://arxiv.org/abs/2602.04356", "authors": ["Jaehyun Kwak", "Nam Cao", "Boryeong Cho", "Segyu Lee", "Sumyeong Ahn", "Se-Young Yun"], "title": "When and Where to Attack? Stage-wise Attention-Guided Adversarial Attack on Large Vision Language Models", "categories": ["cs.CV"], "comment": "Pre-print", "summary": "Adversarial attacks against Large Vision-Language Models (LVLMs) are crucial for exposing safety vulnerabilities in modern multimodal systems. Recent attacks based on input transformations, such as random cropping, suggest that spatially localized perturbations can be more effective than global image manipulation. However, randomly cropping the entire image is inherently stochastic and fails to use the limited per-pixel perturbation budget efficiently. We make two key observations: (i) regional attention scores are positively correlated with adversarial loss sensitivity, and (ii) attacking high-attention regions induces a structured redistribution of attention toward subsequent salient regions. Based on these findings, we propose Stage-wise Attention-Guided Attack (SAGA), an attention-guided framework that progressively concentrates perturbations on high-attention regions. SAGA enables more efficient use of constrained perturbation budgets, producing highly imperceptible adversarial examples while consistently achieving state-of-the-art attack success rates across ten LVLMs. The source code is available at https://github.com/jackwaky/SAGA.", "AI": {"tldr": "该论文提出了一种基于注意力引导的阶段式攻击框架SAGA，用于对大型视觉语言模型进行更高效、更难以察觉的对抗性攻击。", "motivation": "当前针对大型视觉语言模型的输入变换型攻击方法存在随机性和效率问题。为了提高攻击的成功率和有效性，论文探索了基于区域注意力得分的方法来优化攻击策略。", "method": "SAGA通过逐步集中在高关注度区域进行扰动，并利用结构化注意分布转移机制，在有限扰动预算下实现更有效的对抗性攻击。", "result": "实验表明，SAGA在不增加视觉感知差异的情况下显著提高了对十个大型视觉语言模型的攻击成功率。", "conclusion": "论文验证了注意力引导方法的有效性和优越性，为未来研究提供了新的视角和可能的方向。"}}
{"id": "2602.04349", "pdf": "https://arxiv.org/pdf/2602.04349", "abs": "https://arxiv.org/abs/2602.04349", "authors": ["Teng-Fang Hsiao", "Bo-Kai Ruan", "Yu-Lun Liu", "Hong-Han Shuai"], "title": "VecSet-Edit: Unleashing Pre-trained LRM for Mesh Editing from Single Image", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "3D editing has emerged as a critical research area to provide users with flexible control over 3D assets. While current editing approaches predominantly focus on 3D Gaussian Splatting or multi-view images, the direct editing of 3D meshes remains underexplored. Prior attempts, such as VoxHammer, rely on voxel-based representations that suffer from limited resolution and necessitate labor-intensive 3D mask. To address these limitations, we propose \\textbf{VecSet-Edit}, the first pipeline that leverages the high-fidelity VecSet Large Reconstruction Model (LRM) as a backbone for mesh editing. Our approach is grounded on a analysis of the spatial properties in VecSet tokens, revealing that token subsets govern distinct geometric regions. Based on this insight, we introduce Mask-guided Token Seeding and Attention-aligned Token Gating strategies to precisely localize target regions using only 2D image conditions. Also, considering the difference between VecSet diffusion process versus voxel we design a Drift-aware Token Pruning to reject geometric outliers during the denoising process. Finally, our Detail-preserving Texture Baking module ensures that we not only preserve the geometric details of original mesh but also the textural information. More details can be found in our project page: https://github.com/BlueDyee/VecSet-Edit/tree/main", "AI": {"tldr": "提出了一种基于VecSet大型重建模型进行单图三维网格编辑的管道VecSet-Edit。", "motivation": "现有方法在直接编辑3D网格和利用高分辨率方面存在限制，提出了新的方法以解决这些问题，并提供灵活控制。", "method": "通过分析VecSet标记的空间属性，引入了掩码引导令牌播种、注意对齐令牌门控策略以及漂移感知令牌修剪来实现精确定位和细节保留。", "result": "该方法能够精细地编辑3D网格并保持原始纹理信息。", "conclusion": "VecSet-Edit为单图三维网格编辑提供了一种创新的方法，克服了先前技术的局限性。"}}
{"id": "2602.04344", "pdf": "https://arxiv.org/pdf/2602.04344", "abs": "https://arxiv.org/abs/2602.04344", "authors": ["Kou Misaki", "Takuya Akiba"], "title": "UnMaskFork: Test-Time Scaling for Masked Diffusion via Deterministic Action Branching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Test-time scaling strategies have effectively leveraged inference-time compute to enhance the reasoning abilities of Autoregressive Large Language Models. In this work, we demonstrate that Masked Diffusion Language Models (MDLMs) are inherently amenable to advanced search strategies, owing to their iterative and non-autoregressive generation process. To leverage this, we propose UnMaskFork (UMF), a framework that formulates the unmasking trajectory as a search tree and employs Monte Carlo Tree Search to optimize the generation path. In contrast to standard scaling methods relying on stochastic sampling, UMF explores the search space through deterministic partial unmasking actions performed by multiple MDLMs. Our empirical evaluation demonstrates that UMF consistently outperforms existing test-time scaling baselines on complex coding benchmarks, while also exhibiting strong scalability on mathematical reasoning tasks.", "AI": {"tldr": "提出了一种新的测试时扩展框架UnMaskFork（UMF），用于优化Masked Diffusion Language Models的生成路径。", "motivation": "利用迭代和非自回归生成过程，通过在推理时间利用计算资源来改进MDLM的表现能力。", "method": "将解码轨迹视为搜索树，并使用蒙特卡洛树搜索进行优化；引入确定性的部分屏蔽动作进行扩展探索。", "result": "UMF在复杂编码基准测试中优于现有的测试时扩展基线，同时在数学推理任务上表现出强大的可扩展性。", "conclusion": "通过高级搜索策略改进MDLM的生成过程是可行且有效的。"}}
{"id": "2602.04343", "pdf": "https://arxiv.org/pdf/2602.04343", "abs": "https://arxiv.org/abs/2602.04343", "authors": ["Sebastian Jung", "Leonard Klüpfel", "Rudolph Triebel", "Maximilian Durner"], "title": "Finding NeMO: A Geometry-Aware Representation of Template Views for Few-Shot Perception", "categories": ["cs.CV"], "comment": "17 pages including supplement, published in 3DV 2026, Project website: https://sebastian-jung.github.io/nemo/", "summary": "We present Neural Memory Object (NeMO), a novel object-centric representation that can be used to detect, segment and estimate the 6DoF pose of objects unseen during training using RGB images. Our method consists of an encoder that requires only a few RGB template views depicting an object to generate a sparse object-like point cloud using a learned UDF containing semantic and geometric information. Next, a decoder takes the object encoding together with a query image to generate a variety of dense predictions. Through extensive experiments, we show that our method can be used for few-shot object perception without requiring any camera-specific parameters or retraining on target data. Our proposed concept of outsourcing object information in a NeMO and using a single network for multiple perception tasks enhances interaction with novel objects, improving scalability and efficiency by enabling quick object onboarding without retraining or extensive pre-processing. We report competitive and state-of-the-art results on various datasets and perception tasks of the BOP benchmark, demonstrating the versatility of our approach. https://github.com/DLR-RM/nemo", "AI": {"tldr": "本文提出了一种新的基于神经网络的记忆对象（NeMO）表示方法，使用少量模板视图的RGB图像来检测、分割和估计目标物体的姿态。", "motivation": "当前的方法需要大量的训练数据或相机特定参数才能处理未见过的对象。因此，作者希望开发一种能够利用几何信息进行少样本感知的新方法。", "method": "该方法包括一个编码器和解码器。编码器使用少量模板视图生成稀疏的点云表示；解码器结合查询图像和对象编码来生成密集预测。", "result": "实验表明，这种方法在BOP基准测试中展示了竞争性和最先进的结果，证明了其在少样本物体感知任务中的有效性。", "conclusion": "通过将物体信息外包到NeMO并使用单一网络进行多种感知任务，增强了与新对象的交互性，并提高了可扩展性和效率。"}}
{"id": "2602.04340", "pdf": "https://arxiv.org/pdf/2602.04340", "abs": "https://arxiv.org/abs/2602.04340", "authors": ["Qian-Wei Wang", "Yaguang Song", "Shu-Tao Xia"], "title": "Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pre-trained vision-language models such as CLIP exhibit strong transferability, yet adapting them to downstream image classification tasks under limited annotation budgets remains challenging. In active learning settings, the model must select the most informative samples for annotation from a large pool of unlabeled data. Existing approaches typically estimate uncertainty via entropy-based criteria or representation clustering, without explicitly modeling uncertainty from the model perspective. In this work, we propose a robust uncertainty modeling framework for active CLIP adaptation based on dual-prompt tuning. We introduce two learnable prompts in the textual branch of CLIP. The positive prompt enhances the discriminability of task-specific textual embeddings corresponding to light-weight tuned visual embeddings, improving classification reliability. Meanwhile, the negative prompt is trained in an reversed manner to explicitly model the probability that the predicted label is correct, providing a principled uncertainty signal for guiding active sample selection. Extensive experiments across different fine-tuning paradigms demonstrate that our method consistently outperforms existing active learning methods under the same annotation budget.", "AI": {"tldr": "本文提出了一种基于双提示调优的主动学习CLIP适应框架，旨在通过显式建模不确定性来改善图像分类任务中的样本选择。", "motivation": "在有限标注预算下，现有的方法主要依赖熵或表示聚类来估计模型不确定性，缺乏从模型角度进行直接不确定性的显式建模。因此提出了一种新的主动学习CLIP适应策略以提高分类性能。", "method": "通过引入两个可训练的文本提示，一个用于增强特定任务的文本嵌入区分度，另一个逆向训练以提供标签正确的概率信号。这种设置有助于指导更加有效的样本选择过程。", "result": "实验表明，在不同的微调范式下，该方法能够持续优于现有的主动学习方法，并在相同标注预算条件下表现出更好的性能。", "conclusion": "提出的方法通过引入双提示机制实现了更准确的不确定性建模，从而显著提高了主动学习中的样本选择效率和最终分类精度。"}}
{"id": "2602.04337", "pdf": "https://arxiv.org/pdf/2602.04337", "abs": "https://arxiv.org/abs/2602.04337", "authors": ["Qian-Wei Wang", "Guanghao Meng", "Ren Cai", "Yaguang Song", "Shu-Tao Xia"], "title": "Fine-tuning Pre-trained Vision-Language Models in a Human-Annotation-Free Manner", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large-scale vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization, but adapting them to downstream tasks typically requires costly labeled data. Existing unsupervised self-training methods rely on pseudo-labeling, yet often suffer from unreliable confidence filtering, confirmation bias, and underutilization of low-confidence samples. We propose Collaborative Fine-Tuning (CoFT), an unsupervised adaptation framework that leverages unlabeled data through a dual-model, cross-modal collaboration mechanism. CoFT introduces a dual-prompt learning strategy with positive and negative textual prompts to explicitly model pseudo-label cleanliness in a sample-dependent manner, removing the need for hand-crafted thresholds or noise assumptions. The negative prompt also regularizes lightweight visual adaptation modules, improving robustness under noisy supervision. CoFT employs a two-phase training scheme, transitioning from parameter-efficient fine-tuning on high-confidence samples to full fine-tuning guided by collaboratively filtered pseudo-labels. Building on CoFT, CoFT+ further enhances adaptation via iterative fine-tuning, momentum contrastive learning, and LLM-generated prompts. Extensive experiments demonstrate consistent gains over existing unsupervised methods and even few-shot supervised baselines.", "AI": {"tldr": "本文提出了一种无需人工标注的预训练视觉语言模型微调框架CoFT。", "motivation": "现有的无监督自训练方法依赖伪标签，但存在可靠性差等问题。为此，作者提出了CoFT以解决这些问题。", "method": "CoFT采用双模型、跨模态协作机制利用未标记数据，并通过正负文本提示去除手工阈值和噪声假设的需要，提升模型适应性。", "result": "实验表明，CoFT在多个任务上优于现有无监督方法甚至少样本有监督基线。", "conclusion": "提出的方法有效改进了预训练视觉语言模型在下游任务中的适应能力。"}}
{"id": "2602.04329", "pdf": "https://arxiv.org/pdf/2602.04329", "abs": "https://arxiv.org/abs/2602.04329", "authors": ["Shuo Pei", "Yong Wang", "Yuanchen Zhu", "Chen Sun", "Qin Li", "Yanan Zhao", "Huachun Tan"], "title": "Safe and Stylized Trajectory Planning for Autonomous Driving via Diffusion Model", "categories": ["cs.RO"], "comment": "12 pages, 7 figures, submitted to IEEE Transactions on Intelligent Transportation Systems", "summary": "Achieving safe and stylized trajectory planning in complex real-world scenarios remains a critical challenge for autonomous driving systems. This paper proposes the SDD Planner, a diffusion-based framework designed to effectively reconcile safety constraints with driving styles in real time. The framework integrates two core modules: a Multi-Source Style-Aware Encoder, which employs distance-sensitive attention to fuse dynamic agent data and environmental contexts for heterogeneous safety-style perception; and a Style-Guided Dynamic Trajectory Generator, which adaptively modulates priority weights within the diffusion denoising process to generate user-preferred yet safe trajectories. Extensive experiments demonstrate that SDD Planner achieves state-of-the-art performance. On the StyleDrive benchmark, it improves the SM-PDMS metric by 3.9% over WoTE, the strongest baseline. Furthermore, on the NuPlan Test14 and Test14-hard benchmarks, SDD Planner ranks first with overall scores of 91.76 and 80.32, respectively, outperforming leading methods such as PLUTO. Real-vehicle closed-loop tests further confirm that SDD Planner maintains high safety standards while aligning with preset driving styles, validating its practical applicability for real-world deployment.", "AI": {"tldr": "提出了一种基于扩散模型的SDD Planner框架，用于实现安全且风格化的自动驾驶轨迹规划。", "motivation": "在复杂现实场景中实现既安全又符合驾驶风格的轨迹规划是自动驾驶系统面临的关键挑战。", "method": "SDD Planner包含两个核心模块：多源感知编码器和动态轨迹生成器。前者使用距离敏感注意力融合数据，后者通过调节优先级权重来生成用户偏好且安全的路径。", "result": "实验结果表明，SDD Planner在多个基准测试中优于现有方法，在StyleDrive、NuPlan Test14和Test14-hard等基准上取得最佳性能。", "conclusion": "实车闭环测试进一步验证了SDD Planner的安全性和符合驾驶风格的能力，证明其适用于现实世界部署。"}}
{"id": "2602.04328", "pdf": "https://arxiv.org/pdf/2602.04328", "abs": "https://arxiv.org/abs/2602.04328", "authors": ["Jie Chen", "Zhu Wang", "Chuanbin Liu", "Xi Peng"], "title": "Multiview Self-Representation Learning across Heterogeneous Views", "categories": ["cs.CV"], "comment": "12 pages", "summary": "Features of the same sample generated by different pretrained models often exhibit inherently distinct feature distributions because of discrepancies in the model pretraining objectives or architectures. Learning invariant representations from large-scale unlabeled visual data with various pretrained models in a fully unsupervised transfer manner remains a significant challenge. In this paper, we propose a multiview self-representation learning (MSRL) method in which invariant representations are learned by exploiting the self-representation property of features across heterogeneous views. The features are derived from large-scale unlabeled visual data through transfer learning with various pretrained models and are referred to as heterogeneous multiview data. An individual linear model is stacked on top of its corresponding frozen pretrained backbone. We introduce an information-passing mechanism that relies on self-representation learning to support feature aggregation over the outputs of the linear model. Moreover, an assignment probability distribution consistency scheme is presented to guide multiview self-representation learning by exploiting complementary information across different views. Consequently, representation invariance across different linear models is enforced through this scheme. In addition, we provide a theoretical analysis of the information-passing mechanism, the assignment probability distribution consistency and the incremental views. Extensive experiments with multiple benchmark visual datasets demonstrate that the proposed MSRL method consistently outperforms several state-of-the-art approaches.", "AI": {"tldr": "该论文提出了一种跨异构视角的多视图自表示学习（MSRL）方法，旨在通过利用不同预训练模型生成特征间的自表示性质来从大规模无标签视觉数据中学习不变表征。", "motivation": "由于预训练目标或架构差异，同一样本由不同的预训练模型生成的特征通常具有固有的不同分布。因此，在不依赖额外监督的情况下，利用多种预训练模型跨异构视角提取的大规模无标记视觉数据中的不变表示是一个重要挑战。", "method": "该方法通过堆叠在冻结的预训练骨干网络之上的线性模型来获取从大规模未标注视觉数据中生成的不同特征。引入自表示学习依赖的信息传递机制和支持基于不同视图间互补信息利用的分配概率分布一致性方案进行跨视图特征聚合，从而实现不同线性模型输出间的表征不变性。", "result": "在多个基准视觉数据集上的大量实验表明，所提出的MSRL方法始终优于多种最先进的技术。", "conclusion": "该论文通过自表示学习和分配概率分布一致性方案实现了跨异构视角的大规模无标签视觉数据中的不变表征学习。理论分析和实验证明了该方法的有效性与优越性。"}}
{"id": "2602.04326", "pdf": "https://arxiv.org/pdf/2602.04326", "abs": "https://arxiv.org/abs/2602.04326", "authors": ["SeungWon Seo", "SooBin Lim", "SeongRae Noh", "Haneul Kim", "HyeongYeop Kang"], "title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": "31 pages, 10 figures, Accepted ICLR 2026", "summary": "Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.", "AI": {"tldr": "该论文提出了PCE框架，将大型语言模型（LLM）推理中的隐含假设转换为结构化的决策树，并以此来指导不确定性环境下的行动选择。", "motivation": "为了改善实体代理在多智能体、部分可观察和去中心化环境中处理不确定性的能力，减少频繁的代理间通信带来的成本和效率损失。", "method": "通过引入PCE框架，将LLM推理中的假设转化为决策树结构。其中内部节点代表环境假设，叶子节点对应行动方案；路径根据场景概率、目标导向收益及执行成本评分以指导合理行动选择。", "result": "在两个多智能体基准测试（C-WAH和TDW-MAT）中以及三种不同的LLM基础模型上，PCE在成功率和任务效率方面优于依赖通信的基线方法，并且在使用令牌数量上表现相当。消融实验显示，即使应用了PCE后，在提高模型容量或推理深度时所获得的性能提升仍然存在。", "conclusion": "通过将LLM中的隐含假设转化为可靠的策略来处理不确定性规划问题，确立了一个有原则的方法途径，并且用户研究也表明人类合作伙伴认为由PCE产生的通信模式更加高效和可信。"}}
{"id": "2602.04323", "pdf": "https://arxiv.org/pdf/2602.04323", "abs": "https://arxiv.org/abs/2602.04323", "authors": ["Dian Jin", "Yancheng Yuan", "Xiaoming Tao"], "title": "Efficient Equivariant High-Order Crystal Tensor Prediction via Cartesian Local-Environment Many-Body Coupling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "End-to-end prediction of high-order crystal tensor properties from atomic structures remains challenging: while spherical-harmonic equivariant models are expressive, their Clebsch-Gordan tensor products incur substantial compute and memory costs for higher-order targets. We propose the Cartesian Environment Interaction Tensor Network (CEITNet), an approach that constructs a multi-channel Cartesian local environment tensor for each atom and performs flexible many-body mixing via a learnable channel-space interaction. By performing learning in channel space and using Cartesian tensor bases to assemble equivariant outputs, CEITNet enables efficient construction of high-order tensor. Across benchmark datasets for order-2 dielectric, order-3 piezoelectric, and order-4 elastic tensor prediction, CEITNet surpasses prior high-order prediction methods on key accuracy criteria while offering high computational efficiency.", "AI": {"tldr": "该论文提出了一种名为CEITNet的方法，用于从原子结构中高效预测高阶晶体张量属性。", "motivation": "传统的球谐函数等变模型虽然表达能力强，但在处理更高阶目标时会导致计算和内存成本大幅增加。", "method": "通过构建每个原子的多通道笛卡尔局部环境张量，并在通道空间进行学习，CEITNet可以灵活地混合多体并生成等变输出。", "result": "CEITNet在二阶介电、三阶压电和四阶弹性张量预测基准测试中超过了现有的高阶预测方法，在准确性方面表现出色且计算效率高。", "conclusion": "该研究展示了一种新的模型CEITNet，它能够高效地构建并预测高阶晶体张量属性。"}}
{"id": "2602.04317", "pdf": "https://arxiv.org/pdf/2602.04317", "abs": "https://arxiv.org/abs/2602.04317", "authors": ["Zihan Lou", "Jinlong Fan", "Sihan Ma", "Yuxiang Yang", "Jing Zhang"], "title": "JOintGS: Joint Optimization of Cameras, Bodies and 3D Gaussians for In-the-Wild Monocular Reconstruction", "categories": ["cs.CV"], "comment": "15 pages, 15 figures, Project page at https://github.com/MiliLab/JOintGS", "summary": "Reconstructing high-fidelity animatable 3D human avatars from monocular RGB videos remains challenging, particularly in unconstrained in-the-wild scenarios where camera parameters and human poses from off-the-shelf methods (e.g., COLMAP, HMR2.0) are often inaccurate. Splatting (3DGS) advances demonstrate impressive rendering quality and real-time performance, they critically depend on precise camera calibration and pose annotations, limiting their applicability in real-world settings. We present JOintGS, a unified framework that jointly optimizes camera extrinsics, human poses, and 3D Gaussian representations from coarse initialization through a synergistic refinement mechanism. Our key insight is that explicit foreground-background disentanglement enables mutual reinforcement: static background Gaussians anchor camera estimation via multi-view consistency; refined cameras improve human body alignment through accurate temporal correspondence; optimized human poses enhance scene reconstruction by removing dynamic artifacts from static constraints. We further introduce a temporal dynamics module to capture fine-grained pose-dependent deformations and a residual color field to model illumination variations. Extensive experiments on NeuMan and EMDB datasets demonstrate that JOintGS achieves superior reconstruction quality, with 2.1~dB PSNR improvement over state-of-the-art methods on NeuMan dataset, while maintaining real-time rendering. Notably, our method shows significantly enhanced robustness to noisy initialization compared to the baseline.Our source code is available at https://github.com/MiliLab/JOintGS.", "AI": {"tldr": "该论文提出了一种联合优化相机外参、人体姿态和三维高斯表示的框架，用于从单目RGB视频中重建高质量的3D人类模型。", "motivation": "当前方法在不受约束的实际场景中的摄像机参数和人体姿势估计准确性不足，限制了基于Splatting技术的应用。JOintGS旨在通过联合优化来改善这些问题，提高真实世界应用的效果。", "method": "JOintGS框架包括相机外参、人体姿态及三维高斯表示的协同优化机制，并引入时间动态模块以捕捉细粒度姿势依赖变形和残差颜色场模型光照变化。", "result": "在NeuMan和EMDB数据集上的实验表明，相比现有最佳方法，JOintGS在NeuMan数据集中获得2.1分的PSNR改进，同时保持实时渲染能力。它还表现出显著增强的对噪声初始化鲁棒性。", "conclusion": "通过引入联合优化框架，JOintGS提高了单目RGB视频中3D人类模型重建的质量和鲁棒性，并在多个数据集上验证了其优越性能。"}}
{"id": "2602.04315", "pdf": "https://arxiv.org/pdf/2602.04315", "abs": "https://arxiv.org/abs/2602.04315", "authors": ["Guoqing Ma", "Siheng Wang", "Zeyu Zhang", "Shan Yu", "Hao Tang"], "title": "GeneralVLA: Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is that the models exhibit limited zero-shot capability, which hampers their ability to generalize effectively to unseen scenarios. In this work, we propose GeneralVLA (Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning), a hierarchical vision-language-action (VLA) model that can be more effective in utilizing the generalization of foundation models, enabling zero-shot manipulation and automatically generating data for robotics. In particular, we study a class of hierarchical VLA model where the high-level ASM (Affordance Segmentation Module) is finetuned to perceive image keypoint affordances of the scene; the mid-level 3DAgent carries out task understanding, skill knowledge, and trajectory planning to produce a 3D path indicating the desired robot end-effector trajectory. The intermediate 3D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Compared to alternative approaches, our method requires no real-world robotic data collection or human demonstration, making it much more scalable to diverse tasks and viewpoints. Empirically, GeneralVLA successfully generates trajectories for 14 tasks, significantly outperforming state-of-the-art methods such as VoxPoser. The generated demonstrations can train more robust behavior cloning policies than training with human demonstrations or from data generated by VoxPoser, Scaling-up, and Code-As-Policies. We believe GeneralVLA can be the scalable method for both generating data for robotics and solving novel tasks in a zero-shot setting. Code: https://github.com/AIGeeksGroup/GeneralVLA. Website: https://aigeeksgroup.github.io/GeneralVLA.", "AI": {"tldr": "提出了一种名为GeneralVLA的分层视觉语言行动模型，该模型能有效利用基础模型的泛化能力，在零样本设置下生成机器人轨迹和动作。", "motivation": "当前大型基础模型在视觉和语言领域表现出强大的开放世界泛化能力，但在机器人技术中尚未实现同等水平的泛化。现有的模型缺乏有效的零样本推理能力，这限制了它们对未见过场景的有效推广。为解决这一问题，本研究提出了GeneralVLA。", "method": "通过分层视觉语言行动（VLA）模型来优化基础模型的利用，并采用知识引导的轨迹规划策略。具体地，高阶ASM模块被微调以感知场景中的图像关键点功效；中间级3DAgent负责任务理解、技能知识和路径规划；低阶控制策略则实现精准操作。与其他方法相比，本研究的方法无需收集真实世界的机器人数据或人类演示。", "result": "实验表明，GeneralVLA在14项任务中成功生成了轨迹，并显著优于现有最佳方法如VoxPoser，且其生成的演示可训练出比使用人类演示或由VoxPoser生成的数据更好的行为克隆策略。", "conclusion": "GeneralVLA是一种可扩展的方法，不仅可用于为机器人技术生成数据，还能在零样本设置下解决新任务。"}}
{"id": "2602.04307", "pdf": "https://arxiv.org/pdf/2602.04307", "abs": "https://arxiv.org/abs/2602.04307", "authors": ["Chien-Chun Wang", "Hung-Shin Lee", "Hsin-Min Wang", "Berlin Chen"], "title": "Universal Robust Speech Adaptation for Cross-Domain Speech Recognition and Enhancement", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "comment": "Accepted to IEEE Transactions on Audio, Speech and Language Processing (IEEE TASLP)", "summary": "Pre-trained models for automatic speech recognition (ASR) and speech enhancement (SE) have exhibited remarkable capabilities under matched noise and channel conditions. However, these models often suffer from severe performance degradation when confronted with domain shifts, particularly in the presence of unseen noise and channel distortions. In view of this, we in this paper present URSA-GAN, a unified and domain-aware generative framework specifically designed to mitigate mismatches in both noise and channel conditions. URSA-GAN leverages a dual-embedding architecture that consists of a noise encoder and a channel encoder, each pre-trained with limited in-domain data to capture domain-relevant representations. These embeddings condition a GAN-based speech generator, facilitating the synthesis of speech that is acoustically aligned with the target domain while preserving phonetic content. To enhance generalization further, we propose dynamic stochastic perturbation, a novel regularization technique that introduces controlled variability into the embeddings during generation, promoting robustness to unseen domains. Empirical results demonstrate that URSA-GAN effectively reduces character error rates in ASR and improves perceptual metrics in SE across diverse noisy and mismatched channel scenarios. Notably, evaluations on compound test conditions with both channel and noise degradations confirm the generalization ability of URSA-GAN, yielding relative improvements of 16.16% in ASR performance and 15.58% in SE metrics.", "AI": {"tldr": "提出URSA-GAN框架，以解决自动语音识别和语音增强在不同域条件下性能下降的问题。", "motivation": "预训练模型在匹配的噪音和信道条件下的表现卓越，但在面对未知噪音和通道失真时会严重退化。因此开发了一种能够适应各种环境变化的新方法。", "method": "采用双嵌入架构（噪声编码器和通道编码器）并利用GAN生成目标域中的语音。还引入了动态随机扰动技术来增强模型的泛化能力。", "result": "实验结果显示，URSA-GAN在自动语音识别中降低了字符错误率，在语音增强中提高了感知指标，并且在多种噪音和不匹配信道条件下表现出了良好的适应性。", "conclusion": "URSA-GAN能够有效应对不同域条件下的挑战，提高语音识别和增强的性能。"}}
{"id": "2602.04306", "pdf": "https://arxiv.org/pdf/2602.04306", "abs": "https://arxiv.org/abs/2602.04306", "authors": ["Kahee Lim", "Soyeon Kim", "Steven Euijong Whang"], "title": "DeFrame: Debiasing Large Language Models Against Framing Effects", "categories": ["cs.CL", "cs.AI"], "comment": "40 pages, 12 figures", "summary": "As large language models (LLMs) are increasingly deployed in real-world applications, ensuring their fair responses across demographics has become crucial. Despite many efforts, an ongoing challenge is hidden bias: LLMs appear fair under standard evaluations, but can produce biased responses outside those evaluation settings. In this paper, we identify framing -- differences in how semantically equivalent prompts are expressed (e.g., \"A is better than B\" vs. \"B is worse than A\") -- as an underexplored contributor to this gap. We first introduce the concept of \"framing disparity\" to quantify the impact of framing on fairness evaluation. By augmenting fairness evaluation benchmarks with alternative framings, we find that (1) fairness scores vary significantly with framing and (2) existing debiasing methods improve overall (i.e., frame-averaged) fairness, but often fail to reduce framing-induced disparities. To address this, we propose a framing-aware debiasing method that encourages LLMs to be more consistent across framings. Experiments demonstrate that our approach reduces overall bias and improves robustness against framing disparities, enabling LLMs to produce fairer and more consistent responses.", "AI": {"tldr": "本文提出了DeFrame，一种针对大型语言模型在不同表述方式下表现差异的方法。", "motivation": "确保大型语言模型在实际应用中的公平响应变得至关重要，尽管已有许多努力但仍存在隐藏偏见问题。通过引入“框架差异”概念，揭示了表述方式对评估结果的影响，并指出现有去偏方法的不足。", "method": "提出了一种基于框架感知的方法DeFrame，旨在使大型语言模型在不同表述下保持一致性。", "result": "实验表明，所提出的DeFrame方法能够减少总体偏见并提高对框架差异的鲁棒性。", "conclusion": "通过引入“框架差异”概念及相应的去偏方法DeFrame，可以使得大型语言模型产生更加公平和一致的回答。"}}
{"id": "2602.04304", "pdf": "https://arxiv.org/pdf/2602.04304", "abs": "https://arxiv.org/abs/2602.04304", "authors": ["Zipeng Zhu", "Zhanghao Hu", "Qinglin Zhu", "Yuxi Hong", "Yijun Liu", "Jingyong Su", "Yulan He", "Lin Gui"], "title": "Beyond Static Cropping: Layer-Adaptive Visual Localization and Decoding Enhancement", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "9 pages, 5 figures", "summary": "Large Vision-Language Models (LVLMs) have advanced rapidly by aligning visual patches with the text embedding space, but a fixed visual-token budget forces images to be resized to a uniform pretraining resolution, often erasing fine-grained details and causing hallucinations via over-reliance on language priors. Recent attention-guided enhancement (e.g., cropping or region-focused attention allocation) alleviates this, yet it commonly hinges on a static \"magic layer\" empirically chosen on simple recognition benchmarks and thus may not transfer to complex reasoning tasks. In contrast to this static assumption, we propose a dynamic perspective on visual grounding. Through a layer-wise sensitivity analysis, we demonstrate that visual grounding is a dynamic process: while simple object recognition tasks rely on middle layers, complex visual search and reasoning tasks require visual information to be reactivated at deeper layers. Based on this observation, we introduce Visual Activation by Query (VAQ), a metric that identifies the layer whose attention map is most relevant to query-specific visual grounding by measuring attention sensitivity to the input query. Building on VAQ, we further propose LASER (Layer-adaptive Attention-guided Selective visual and decoding Enhancement for Reasoning), a training-free inference procedure that adaptively selects task-appropriate layers for visual localization and question answering. Experiments across diverse VQA benchmarks show that LASER significantly improves VQA accuracy across tasks with varying levels of complexity.", "AI": {"tldr": "提出了一种动态视觉定位和解码增强方法LASER，以提高复杂任务中的VQA准确性。", "motivation": "解决现有LVLM模型由于固定视觉标记预算而丢失细节的问题，并改进基于静态层的注意力引导增强方法。", "method": "通过逐层敏感性分析，识别视觉定位的动态过程；引入VAQ指标确定与查询相关的最相关层；提出LASER，在推理过程中自适应选择适当的视觉定位和解码增强层次。", "result": "实验表明，LASER在各种VQA基准测试中显著提高了任务准确性，无论任务复杂程度如何。", "conclusion": "所提方法通过动态调整视觉注意力层提升了模型处理复杂视觉搜索和推理任务的能力。"}}
{"id": "2602.04300", "pdf": "https://arxiv.org/pdf/2602.04300", "abs": "https://arxiv.org/abs/2602.04300", "authors": ["Jue Gong", "Zihan Zhou", "Jingkai Wang", "Xiaohong Liu", "Yulun Zhang", "Xiaokang Yang"], "title": "Light Up Your Face: A Physically Consistent Dataset and Diffusion Model for Face Fill-Light Enhancement", "categories": ["cs.CV"], "comment": "8 pages, 7 figures. The code and model will be available at https://github.com/gobunu/Light-Up-Your-Face", "summary": "Face fill-light enhancement (FFE) brightens underexposed faces by adding virtual fill light while keeping the original scene illumination and background unchanged. Most face relighting methods aim to reshape overall lighting, which can suppress the input illumination or modify the entire scene, leading to foreground-background inconsistency and mismatching practical FFE needs. To support scalable learning, we introduce LightYourFace-160K (LYF-160K), a large-scale paired dataset built with a physically consistent renderer that injects a disk-shaped area fill light controlled by six disentangled factors, producing 160K before-and-after pairs. We first pretrain a physics-aware lighting prompt (PALP) that embeds the 6D parameters into conditioning tokens, using an auxiliary planar-light reconstruction objective. Building on a pretrained diffusion backbone, we then train a fill-light diffusion (FiLitDiff), an efficient one-step model conditioned on physically grounded lighting codes, enabling controllable and high-fidelity fill lighting at low computational cost. Experiments on held-out paired sets demonstrate strong perceptual quality and competitive full-reference metrics, while better preserving background illumination. The dataset and model will be at https://github.com/gobunu/Light-Up-Your-Face.", "AI": {"tldr": "通过引入一个大规模的配对数据集和物理一致渲染器，来提高面部填充照明质量。", "motivation": "现有方法主要调整整体光照，这可能导致前景与背景不一致，并不符合实际需求。本研究旨在创建一种能够保留原始场景照明并仅增强人脸区域的方法。", "method": "提出了LightYourFace-160K数据集和一个基于物理的渲染器，该模型使用扩散模型对填充光进行控制并训练一个条件性模型以实现高保真度和可控性的面部照明增强。", "result": "实验结果显示了高质量的人脸增亮效果，并且在保持背景照明一致性方面表现良好。这些结果展示了数据集和模型的有效性和实用性。", "conclusion": "通过使用物理一致的渲染器，可以创建大规模的数据集以支持可扩展学习，并训练了一个条件性扩散模型来实现高效、高保真度的人脸填充光增强。"}}
{"id": "2602.04299", "pdf": "https://arxiv.org/pdf/2602.04299", "abs": "https://arxiv.org/abs/2602.04299", "authors": ["Lufeng Feng", "Baomin Xu", "Haoran Zhang", "Bihai Lin", "Zuxuan Deng", "Sidi Tao", "Chenyu Liu", "Shifan Jia", "Li Duan", "Ziyu Jia"], "title": "A Multimodal fNIRS-EEG Dataset for Unilateral Limb Motor Imagery", "categories": ["cs.HC"], "comment": "17 pages, 12 figures", "summary": "Unilateral limb motor imagery (MI) plays an important role in upper-limb motor rehabilitation and precise control of external devices, and places higher demands on spatial resolution. However, most existing public datasets focus on binary- or four-class left-right limb paradigms that mainly exploit coarse hemispheric lateralization, and there is still a lack of multimodal datasets that simultaneously record EEG and fNIRS for unilateral multi-directional MI. To address this gap, we constructed MIND, a public motor imagery fNIRS-EEG dataset based on a four-class directional MI paradigm of the right upper limb. The dataset includes 64-channel EEG recordings (1000 Hz) and 51-channel fNIRS recordings (47.62 Hz) from 30 participants (12 females, 18 males; aged 19.0-25.0 years). We analyse the spatiotemporal characteristics of EEG spectral power and hemodynamic responses, and validate the potential advantages of hybrid fNIRS-EEG BCIs in terms of classification accuracy. We expect that this dataset will facilitate the evaluation and comparison of neuroimaging analysis and decoding methods.", "AI": {"tldr": "构建了一个包含64通道EEG和51通道fNIRS记录的多模态数据集，用于研究右手四方向运动想象任务。", "motivation": "现有公共数据集主要关注左/右肢体二分类或四分类模式，缺乏同时记录EEG和fNIRS的多模态数据集以进行单侧多向运动想象的研究。", "method": "创建了一个基于右手四方向运动想象的fNIRS-EEG数据集，并分析了EEG谱功率和血氧水平依赖响应的时空特性。", "result": "验证了混合fNIRS-EEG脑机接口在分类准确性方面的潜在优势，期望该数据集能促进神经影像学分析和解码方法的评估与比较。", "conclusion": "通过构建MIND数据集填补了单侧多方向运动想象任务研究的数据空白，并展示了其在提高BCI系统性能上的潜力。"}}
{"id": "2602.04297", "pdf": "https://arxiv.org/pdf/2602.04297", "abs": "https://arxiv.org/abs/2602.04297", "authors": ["Branislav Pecher", "Michal Spiegel", "Robert Belanec", "Jan Cegin"], "title": "Revisiting Prompt Sensitivity in Large Language Models for Text Classification: The Role of Prompt Underspecification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are widely used as zero-shot and few-shot classifiers, where task behaviour is largely controlled through prompting. A growing number of works have observed that LLMs are sensitive to prompt variations, with small changes leading to large changes in performance. However, in many cases, the investigation of sensitivity is performed using underspecified prompts that provide minimal task instructions and weakly constrain the model's output space. In this work, we argue that a significant portion of the observed prompt sensitivity can be attributed to prompt underspecification. We systematically study and compare the sensitivity of underspecified prompts and prompts that provide specific instructions. Utilising performance analysis, logit analysis, and linear probing, we find that underspecified prompts exhibit higher performance variance and lower logit values for relevant tokens, while instruction-prompts suffer less from such problems. However, linear probing analysis suggests that the effects of prompt underspecification have only a marginal impact on the internal LLM representations, instead emerging in the final layers. Overall, our findings highlight the need for more rigour when investigating and mitigating prompt sensitivity.", "AI": {"tldr": "本文重新审视了大语言模型在文本分类中的提示敏感性问题，并探讨了提示不明确对性能的影响。", "motivation": "观察到大型语言模型的性能对提示变化非常敏感，尤其是在使用缺乏详细任务指令的不明确提示时。研究者认为这种高度敏感性可能部分归因于提示不明确的问题。", "method": "通过对比分析不明确和提供具体指示的提示在不同方面的表现差异。包括性能分析、logit分析以及线性探测分析。", "result": "发现不明确提示导致较高的性能波动，较低的相关token的logit值；而带有指令的提示则较少受到这些问题的影响。然而，通过线性探测分析还指出，提示不明确的影响主要集中在模型最终几层而非内部表示上。", "conclusion": "研究结果强调了在调查和缓解提示敏感性时需要更加严谨的方法，尤其是在设计实验条件方面。"}}
{"id": "2602.04296", "pdf": "https://arxiv.org/pdf/2602.04296", "abs": "https://arxiv.org/abs/2602.04296", "authors": ["Wenjun Peng", "Xinyu Wang", "Qi Wu"], "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas", "categories": ["cs.SE", "cs.AI"], "comment": "ICSE2026", "summary": "Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-generated agents within diverse, competitive game environments. Unlike existing approaches, ProxyWar evaluates not only functional correctness but also the operational characteristics of generated programs, combining automated testing, iterative code repair, and multi-agent tournaments to provide a holistic view of program behavior. Applied to a range of state-of-the-art coders and games, our approach uncovers notable discrepancies between benchmark scores and actual performance in dynamic settings, revealing overlooked limitations and opportunities for improvement. These findings highlight the need for richer, competition-based evaluation of code generation. Looking forward, ProxyWar lays a foundation for research into LLM-driven algorithm discovery, adaptive problem solving, and the study of practical efficiency and robustness, including the potential for models to outperform hand-crafted agents. The project is available at https://github.com/xinke-wang/ProxyWar.", "AI": {"tldr": "通过在多样化的竞争性游戏环境中嵌入大型语言模型（LLMs）生成的代理，ProxyWar 提供了一个动态评估代码生成质量的新框架。", "motivation": "现有的静态基准和简单指标限制了对 LLM 自动化代码生成真实世界效果的评价。该研究旨在提供一种更全面、竞争性的评价方法，揭示未被注意到的局限性，并探索改进机会。", "method": "ProxyWar 结合自动化测试、迭代代码修复和多代理锦标赛来评估 LLMS 生成代码的功能正确性和操作特性。", "result": "应用于一系列顶尖编码工具和游戏中时，该框架发现基准得分与动态环境中的实际性能存在显著差异。", "conclusion": "该研究强调了基于竞争的评价方法对代码生成的重要性，并为探索 LLM 驱动的算法发现、自适应问题解决以及实际效率和健壮性研究奠定了基础。"}}
{"id": "2602.04294", "pdf": "https://arxiv.org/pdf/2602.04294", "abs": "https://arxiv.org/abs/2602.04294", "authors": ["Yanshu Wang", "Shuaishuai Yang", "Jingjing He", "Tong Yang"], "title": "How Few-shot Demonstrations Affect Prompt-based Defenses Against LLM Jailbreak Attacks", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": "13 pages, 4 figures, 6 tables", "summary": "Large Language Models (LLMs) face increasing threats from jailbreak attacks that bypass safety alignment. While prompt-based defenses such as Role-Oriented Prompts (RoP) and Task-Oriented Prompts (ToP) have shown effectiveness, the role of few-shot demonstrations in these defense strategies remains unclear. Prior work suggests that few-shot examples may compromise safety, but lacks investigation into how few-shot interacts with different system prompt strategies. In this paper, we conduct a comprehensive evaluation on multiple mainstream LLMs across four safety benchmarks (AdvBench, HarmBench, SG-Bench, XSTest) using six jailbreak attack methods. Our key finding reveals that few-shot demonstrations produce opposite effects on RoP and ToP: few-shot enhances RoP's safety rate by up to 4.5% through reinforcing role identity, while it degrades ToP's effectiveness by up to 21.2% through distracting attention from task instructions. Based on these findings, we provide practical recommendations for deploying prompt-based defenses in real-world LLM applications.", "AI": {"tldr": "研究了在大型语言模型中，few-shot演示如何影响基于提示的防御策略对攻击的有效性。", "motivation": "探讨few-shot示例与不同的系统提示策略（如角色导向和任务导向）交互时的作用机制，以更好地理解并提高LLM的安全防护能力。", "method": "在多个主流LLM上进行了全面评估，并使用了四种安全性基准（AdvBench、HarmBench、SG-Bench、XSTest），通过六种不同的攻击方法进行测试。", "result": "发现few-shot演示对角色导向和任务导向提示的防御效果产生相反影响：它增强了角色导向提示的安全性，而削弱了任务导向提示的有效性。", "conclusion": "基于这些研究结果，提出了在实际LLM应用中部署基于提示的防御策略的实际建议。"}}
{"id": "2602.04291", "pdf": "https://arxiv.org/pdf/2602.04291", "abs": "https://arxiv.org/abs/2602.04291", "authors": ["Sudipto Ghosh", "Sujoy Nath", "Sunny Manchanda", "Tanmoy Chakraborty"], "title": "Disentangling Causal Importance from Emergent Structure in Multi-Expert Orchestration", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Multi-expert systems, where multiple Large Language Models (LLMs) collaborate to solve complex tasks, are increasingly adopted for high-performance reasoning and generation. However, the orchestration policies governing expert interaction and sequencing remain largely opaque. We introduce INFORM, an interpretability analysis that treats orchestration as an explicit, analyzable computation, enabling the decoupling of expert interaction structure, execution order, and causal attribution. We use INFORM to evaluate an orchestrator on GSM8K, HumanEval, and MMLU using a homogeneous consortium of ten instruction-tuned experts drawn from LLaMA-3.1 8B, Qwen-3 8B, and DeepSeek-R1 8B, with controlled decoding-temperature variation, and a secondary heterogeneous consortium spanning 1B-7B parameter models. Across tasks, routing dominance is a poor proxy for functional necessity. We reveal a divergence between relational importance, captured by routing mass and interaction topology, and intrinsic importance, measured via gradient-based causal attribution: frequently selected experts often act as interaction hubs with limited causal influence, while sparsely routed experts can be structurally critical. Orchestration behaviors emerge asynchronously, with expert centralization preceding stable routing confidence and expert ordering remaining non-deterministic. Targeted ablations show that masking intrinsically important experts induces disproportionate collapse in interaction structure compared to masking frequent peers, confirming that INFORM exposes causal and structural dependencies beyond accuracy metrics alone.", "AI": {"tldr": "介绍了一种名为INFORM的解释性分析方法，用于评估多专家系统中的编排策略，并揭示了交互结构和因果重要性的差异。", "motivation": "旨在解决当前多专家系统的编排策略过于模糊的问题，通过引入一种新的解析方法来明确理解这些策略的作用机制及其影响。", "method": "提出了INFORM分析框架，可以将编排过程视为可解释的计算，并使用此工具对不同任务和模型参数组合下的编排性能进行评估。", "result": "发现频繁被选中的专家可能作为交互中心但因果影响力有限，而稀疏路由的专家可能是结构关键点。揭示了编排行为以非确定性方式出现且依赖关系超出了准确率指标。", "conclusion": "INFORM能够有效解析多专家系统中的编排策略，并提供关于因果重要性和结构依赖性的深入见解。"}}
{"id": "2602.04288", "pdf": "https://arxiv.org/pdf/2602.04288", "abs": "https://arxiv.org/abs/2602.04288", "authors": ["Yun Cheng", "Xingyu Zhu", "Haoyu Zhao", "Sanjeev Arora"], "title": "Contextual Drag: How Errors in the Context Affect LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Central to many self-improvement pipelines for large language models (LLMs) is the assumption that models can improve by reflecting on past mistakes. We study a phenomenon termed contextual drag: the presence of failed attempts in the context biases subsequent generations toward structurally similar errors. Across evaluations of 11 proprietary and open-weight models on 8 reasoning tasks, contextual drag induces 10-20% performance drops, and iterative self-refinement in models with severe contextual drag can collapse into self-deterioration. Structural analysis using tree edit distance reveals that subsequent reasoning trajectories inherit structurally similar error patterns from the context. We demonstrate that neither external feedback nor successful self-verification suffices to eliminate this effect. While mitigation strategies such as fallback-behavior fine-tuning and context denoising yield partial improvements, they fail to fully restore baseline performance, positioning contextual drag as a persistent failure mode in current reasoning architectures.", "AI": {"tldr": "研究大型语言模型在上下文中存在错误时的表现，发现这些错误会拖累后续生成内容的准确性。", "motivation": "探究大型语言模型如何受到先前错误的影响，并且评估这种影响对自我改进流程的效果。", "method": "通过分析11个专有和公开权重的模型在8项推理任务中的表现，来观察上下文拖曳现象及其后续影响。", "result": "发现上下文拖曳会导致性能下降约10-20%，并且模型无法仅依靠外部反馈或自我验证解决问题。尽管有些缓解策略可以部分改善这一问题，但未能完全恢复基准性能。", "conclusion": "指出上下文拖曳是当前推理架构中一个持久的失败模式，并强调了需要寻找新的方法来克服这个问题。"}}
{"id": "2602.04284", "pdf": "https://arxiv.org/pdf/2602.04284", "abs": "https://arxiv.org/abs/2602.04284", "authors": ["Yansong Ning", "Jun Fang", "Naiqiang Tan", "Hao Liu"], "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": "Under Review", "summary": "Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.", "AI": {"tldr": "本文提出了Agent-Omit框架，使LLM代理能够根据需要省略冗余的思维和观察行为，以提高效率。", "motivation": "当前研究在处理多轮交互时没有区分各回合中思维和观察的重要性，这限制了代理的优化潜力。因此，提出一种适应性策略来灵活管理这些资源的需求。", "method": "通过合成冷启动数据进行微调，并采用带有双采样机制和定制省略奖励的强化学习方法，以鼓励代理学会在不同情境下有效省略思维或观察的行为。", "result": "实验表明，所提出的Agent-Omit-8B模型与前沿LLM代理相比，在性能上具有竞争力，同时实现了更好的效率与效果之间的平衡。", "conclusion": "该研究证明了通过智能管理代理的思考和观察过程可以显著提升其在多轮交互中的表现及资源利用效率。"}}
{"id": "2602.04277", "pdf": "https://arxiv.org/pdf/2602.04277", "abs": "https://arxiv.org/abs/2602.04277", "authors": ["Priyankkumar Dhrangdhariya", "Soumyadipta Maiti", "Venkataramana Runkana"], "title": "Multi Objective Design Optimization of Non Pneumatic Passenger Car Tires Using Finite Element Modeling, Machine Learning, and Particle swarm Optimization and Bayesian Optimization Algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Non Pneumatic tires offer a promising alternative to pneumatic tires. However, their discontinuous spoke structures present challenges in stiffness tuning, durability, and high speed vibration. This study introduces an integrated generative design and machine learning driven framework to optimize UPTIS type spoke geometries for passenger vehicles. Upper and lower spoke profiles were parameterized using high order polynomial representations, enabling the creation of approximately 250 generative designs through PCHIP based geometric variation. Machine learning models like KRR for stiffness and XGBoost for durability and vibration achieved strong predictive accuracy, reducing the reliance on computationally intensive FEM simulations. Optimization using Particle Swarm Optimization and Bayesian Optimization further enabled extensive performance refinement. The resulting designs demonstrate 53% stiffness tunability, up to 50% durability improvement, and 43% reduction in vibration compared to the baseline. PSO provided fast, targeted convergence, while Bayesian Optimization effectively explored multi objective tradeoffs. Overall, the proposed framework enables systematic development of high performance, next generation UPTIS spoke structures.", "AI": {"tldr": "本文提出了一种集成生成设计和机器学习驱动框架，用于优化非充气轮胎的结构性能。", "motivation": "非充气轮胎提供了替代传统充气轮胎的有前景的选择，但其独特的结构带来了刚度调整、耐用性和高速振动等方面的挑战。本文旨在通过先进的方法提高这些方面的性能。", "method": "使用高阶多项式表示上部和下部辐条轮廓，并利用分段立方Hermite插值（PCHIP）生成约250种不同的设计方案。机器学习模型如核岭回归(KRR)用于预测刚度，XGBoost用于预测耐用性和振动性能。采用粒子群优化(PSO)和贝叶斯优化(Bayesian Optimization)进行多目标优化。", "result": "与基准设计相比，最终的设计方案展示了53%的刚度调整范围、高达50%的耐久性改进以及43%的振动减少。PSO实现了快速而集中的收敛效果，而贝叶斯优化能够有效地探索多目标之间的权衡。", "conclusion": "该框架为非充气轮胎的设计提供了一种系统化的方法，并有望开发出高性能的新一代UPTIS辐条结构。"}}
{"id": "2602.04271", "pdf": "https://arxiv.org/pdf/2602.04271", "abs": "https://arxiv.org/abs/2602.04271", "authors": ["Lifan Wu", "Ruijie Zhu", "Yubo Ai", "Tianzhu Zhang"], "title": "SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "Accepted by CVM 2026. Project page: https://wusar.github.io/projects/skeletongaussian", "summary": "4D generation has made remarkable progress in synthesizing dynamic 3D objects from input text, images, or videos. However, existing methods often represent motion as an implicit deformation field, which limits direct control and editability. To address this issue, we propose SkeletonGaussian, a novel framework for generating editable dynamic 3D Gaussians from monocular video input. Our approach introduces a hierarchical articulated representation that decomposes motion into sparse rigid motion explicitly driven by a skeleton and fine-grained non-rigid motion. Concretely, we extract a robust skeleton and drive rigid motion via linear blend skinning, followed by a hexplane-based refinement for non-rigid deformations, enhancing interpretability and editability. Experimental results demonstrate that SkeletonGaussian surpasses existing methods in generation quality while enabling intuitive motion editing, establishing a new paradigm for editable 4D generation. Project page: https://wusar.github.io/projects/skeletongaussian/", "AI": {"tldr": "提出了一种名为SkeletonGaussian的新框架，用于从单目视频生成可编辑的动态三维高斯。", "motivation": "现有的4D生成方法通常通过隐式变形场表示运动，这限制了直接控制和编辑的可能性。为了克服这一问题，该论文提出了一个新方法来提高动态3D对象生成的质量与可编辑性。", "method": "引入了一个层次化的关节表示法，将运动分解为稀疏的刚体运动（通过骨架驱动）和精细的非刚性变形。具体来说，提取了稳健的骨架并通过线性混合皮肤技术实现刚体运动，并利用六平面基线进行非刚性变形细化。", "result": "实验结果显示，SkeletonGaussian在生成质量上超越了现有方法，并且支持直观的动作编辑。", "conclusion": "通过引入新的框架和方法，论文建立了可编辑4D生成的新范式。"}}
{"id": "2602.04268", "pdf": "https://arxiv.org/pdf/2602.04268", "abs": "https://arxiv.org/abs/2602.04268", "authors": ["Siyu Jiang", "Feiyang Chen", "Xiaojin Zhang", "Kun He"], "title": "KVSmooth: Mitigating Hallucination in Multi-modal Large Language Models through Key-Value Smoothing", "categories": ["cs.CV"], "comment": null, "summary": "Despite the significant progress of Multimodal Large Language Models (MLLMs) across diverse tasks, hallucination -- corresponding to the generation of visually inconsistent objects, attributes, or relations -- remains a major obstacle to their reliable deployment. Unlike pure language models, MLLMs must ground their generation process in visual inputs. However, existing models often suffer from semantic drift during decoding, causing outputs to diverge from visual facts as the sequence length increases. To address this issue, we propose KVSmooth, a training-free and plug-and-play method that mitigates hallucination by performing attention-entropy-guided adaptive smoothing on hidden states. Specifically, KVSmooth applies an exponential moving average (EMA) to both keys and values in the KV-Cache, while dynamically quantifying the sink degree of each token through the entropy of its attention distribution to adaptively adjust the smoothing strength. Unlike computationally expensive retraining or contrastive decoding methods, KVSmooth operates efficiently during inference without additional training or model modification. Extensive experiments demonstrate that KVSmooth significantly reduces hallucination ($\\mathit{CHAIR}_{S}$ from $41.8 \\rightarrow 18.2$) while improving overall performance ($F_1$ score from $77.5 \\rightarrow 79.2$), achieving higher precision and recall simultaneously. In contrast, prior methods often improve one at the expense of the other, validating the effectiveness and generality of our approach.", "AI": {"tldr": "KVSmooth通过关键值平滑来减少多模态大型语言模型中的幻觉现象。", "motivation": "现有的多模态大型语言模型在生成过程中容易出现视觉不一致的现象，导致输出与输入的图像信息不符。为了改善这一问题，需要一种有效且通用的方法来降低此类模型的幻觉。", "method": "KVSmooth通过在解码过程中对关键值缓存进行指数加权移动平均，并根据注意力分布的熵动态调整平滑强度来减少幻觉现象，该方法无需重新训练或修改模型。", "result": "实验表明，使用KVSmooth可以显著降低幻觉（从41.8降至18.2），同时提高整体性能（F_1分数从77.5升至79.2）。与之前的方法相比，这种方法不仅减少了幻觉现象，还提高了模型的准确性。", "conclusion": "KVSmooth是一种有效且通用的方法，可以显著减少多模态大型语言模型中的幻觉，并提高整体性能。"}}
{"id": "2602.04265", "pdf": "https://arxiv.org/pdf/2602.04265", "abs": "https://arxiv.org/abs/2602.04265", "authors": ["Wenze Lin", "Zhen Yang", "Xitai Jiang", "Pony Ma", "Gao Huang"], "title": "Thickening-to-Thinning: Reward Shaping via Human-Inspired Learning Dynamics for LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for enhancing reasoning in Large Language Models (LLMs). However, it frequently encounters challenges such as entropy collapse, excessive verbosity, and insufficient exploration for hard problems. Crucially, existing reward schemes fail to distinguish between the need for extensive search during problem-solving and the efficiency required for mastered knowledge. In this work, we introduce T2T(Thickening-to-Thinning), a dynamic reward framework inspired by human learning processes. Specifically, it implements a dual-phase mechanism: (1) On incorrect attempts, T2T incentivizes \"thickening\" (longer trajectories) to broaden the search space and explore novel solution paths; (2) Upon achieving correctness, it shifts to \"thinning\", imposing length penalties to discourage redundancy, thereby fostering model confidence and crystallizing reasoning capabilities. Extensive experiments on mathematical benchmarks (MATH-500, AIME, AMC) across Qwen-series and Deepseek models demonstrate that T2T significantly outperforms standard GRPO and recent baselines, achieving superior performance.", "AI": {"tldr": "介绍了一种动态奖励框架T2T，用于提高大语言模型的推理能力。", "motivation": "现有强化学习方法在解决复杂问题时存在熵塌陷、冗长和探索不足等问题。需要一种能够区分搜索空间扩展与知识效率的方法来改进LLM的推理。", "method": "提出T2T框架，通过双阶段机制激励“增厚”（增加轨迹长度）以扩大搜索范围，并在正确答案后施加长度惩罚以减少冗余。", "result": "实验显示，在数学基准测试中，T2T显著优于标准GRPO和其他基线方法。", "conclusion": "T2T框架通过模仿人类学习过程，有效解决了LLM推理中的挑战，展示了更好的性能。"}}
{"id": "2602.04264", "pdf": "https://arxiv.org/pdf/2602.04264", "abs": "https://arxiv.org/abs/2602.04264", "authors": ["Ibrahim Albool", "Malak Gamal El-Din", "Salma Elmalaki", "Yasser Shoukry"], "title": "From Dead Neurons to Deep Approximators: Deep Bernstein Networks as a Provable Alternative to Residual Layers", "categories": ["cs.LG", "cs.AI", "math.NA"], "comment": "15 pages", "summary": "Residual connections are the de facto standard for mitigating vanishing gradients, yet they impose structural constraints and fail to address the inherent inefficiencies of piecewise linear activations. We show that Deep Bernstein Networks (which utilizes Bernstein polynomials as activation functions) can act as residual-free architecture while simultaneously optimize trainability and representation power. We provide a two-fold theoretical foundation for our approach. First, we derive a theoretical lower bound on the local derivative, proving it remains strictly bounded away from zero. This directly addresses the root cause of gradient stagnation; empirically, our architecture reduces ``dead'' neurons from 90\\% in standard deep networks to less than 5\\%, outperforming ReLU, Leaky ReLU, SeLU, and GeLU. Second, we establish that the approximation error for Bernstein-based networks decays exponentially with depth, a significant improvement over the polynomial rates of ReLU-based architectures. By unifying these results, we demonstrate that Bernstein activations provide a superior mechanism for function approximation and signal flow. Our experiments on HIGGS and MNIST confirm that Deep Bernstein Networks achieve high-performance training without skip-connections, offering a principled path toward deep, residual-free architectures with enhanced expressive capacity.", "AI": {"tldr": "论文提出使用伯恩斯坦多项式作为激活函数的深层网络，以替代残差连接架构，解决梯度消失问题并提高表达能力。", "motivation": "深度学习中，残差连接用于减轻梯度消失问题。然而，它们会引入结构约束，并且未能充分优化分段线性激活函数所带来的固有低效问题。为了解决这些问题，该论文提出了使用伯恩斯坦多项式作为激活函数的深层网络。", "method": "通过理论分析和实验验证，研究团队展示了伯恩斯坦多项式激活函数在保持局部导数不趋近于零的同时，能够减少神经元死亡率，并且随着深度增加，其逼近误差衰减速度呈指数级下降，优于ReLU等其他激活函数。", "result": "实验证明，在HIGGS和MNIST数据集上，基于伯恩斯坦多项式的深层网络在不使用跳跃连接的情况下实现了高性能训练，证明了该方法的有效性。", "conclusion": "通过理论分析和实验结果表明，基于伯恩斯坦多项式激活函数的深层网络是残差架构的一种可证明替代方案，并且能够提供更高的表达能力和更优的梯度传播性能。"}}
{"id": "2602.04260", "pdf": "https://arxiv.org/pdf/2602.04260", "abs": "https://arxiv.org/abs/2602.04260", "authors": ["Yong Li", "Yuanzhi Wang", "Yi Ding", "Shiqing Zhang", "Ke Lu", "Cuntai Guan"], "title": "Decoupled Hierarchical Distillation for Multimodal Emotion Recognition", "categories": ["cs.CV"], "comment": "arXiv admin note: text overlap with arXiv:2303.13802", "summary": "Human multimodal emotion recognition (MER) seeks to infer human emotions by integrating information from language, visual, and acoustic modalities. Although existing MER approaches have achieved promising results, they still struggle with inherent multimodal heterogeneities and varying contributions from different modalities. To address these challenges, we propose a novel framework, Decoupled Hierarchical Multimodal Distillation (DHMD). DHMD decouples each modality's features into modality-irrelevant (homogeneous) and modality-exclusive (heterogeneous) components using a self-regression mechanism. The framework employs a two-stage knowledge distillation (KD) strategy: (1) coarse-grained KD via a Graph Distillation Unit (GD-Unit) in each decoupled feature space, where a dynamic graph facilitates adaptive distillation among modalities, and (2) fine-grained KD through a cross-modal dictionary matching mechanism, which aligns semantic granularities across modalities to produce more discriminative MER representations. This hierarchical distillation approach enables flexible knowledge transfer and effectively improves cross-modal feature alignment. Experimental results demonstrate that DHMD consistently outperforms state-of-the-art MER methods, achieving 1.3\\%/2.4\\% (ACC$_7$), 1.3\\%/1.9\\% (ACC$_2$) and 1.9\\%/1.8\\% (F1) relative improvement on CMU-MOSI/CMU-MOSEI dataset, respectively. Meanwhile, visualization results reveal that both the graph edges and dictionary activations in DHMD exhibit meaningful distribution patterns across modality-irrelevant/-exclusive feature spaces.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.04257", "pdf": "https://arxiv.org/pdf/2602.04257", "abs": "https://arxiv.org/abs/2602.04257", "authors": ["Jiaxin Cen", "Xudong Mao", "Guanghui Yue", "Wei Zhou", "Ruomei Wang", "Fan Zhou", "Baoquan Zhao"], "title": "Depth-Guided Metric-Aware Temporal Consistency for Monocular Video Human Mesh Recovery", "categories": ["cs.CV"], "comment": null, "summary": "Monocular video human mesh recovery faces fundamental challenges in maintaining metric consistency and temporal stability due to inherent depth ambiguities and scale uncertainties. While existing methods rely primarily on RGB features and temporal smoothing, they struggle with depth ordering, scale drift, and occlusion-induced instabilities. We propose a comprehensive depth-guided framework that achieves metric-aware temporal consistency through three synergistic components: A Depth-Guided Multi-Scale Fusion module that adaptively integrates geometric priors with RGB features via confidence-aware gating; A Depth-guided Metric-Aware Pose and Shape (D-MAPS) estimator that leverages depth-calibrated bone statistics for scale-consistent initialization; A Motion-Depth Aligned Refinement (MoDAR) module that enforces temporal coherence through cross-modal attention between motion dynamics and geometric cues. Our method achieves superior results on three challenging benchmarks, demonstrating significant improvements in robustness against heavy occlusion and spatial accuracy while maintaining computational efficiency.", "AI": {"tldr": "本文提出了一种深度引导的框架，用于单目视频人体网格恢复中的度量一致性和时间稳定性。", "motivation": "现有的方法主要依赖于RGB特征和时间平滑处理，但难以解决深度排序、比例漂移和遮挡引起的不稳定性问题。", "method": "提出了一个综合的深度引导框架，包括三个协同组件：深度引导多尺度融合模块，深度指导度量感知姿态和形状估计器，以及运动-深度对齐细化模块。", "result": "该方法在三个具有挑战性的基准测试中取得了显著改进，在重遮挡情况下表现出更高的鲁棒性和空间准确性，并保持了计算效率。", "conclusion": "本文提出的框架通过深度引导的度量感知时间和一致性方法，改善了单目视频人体网格恢复的效果。"}}
{"id": "2602.04256", "pdf": "https://arxiv.org/pdf/2602.04256", "abs": "https://arxiv.org/abs/2602.04256", "authors": ["Yuxuan Han", "Kunyuan Wu", "Qianyi Shao", "Renxiang Xiao", "Zilu Wang", "Cansen Jiang", "Yi Xiao", "Liang Hu", "Yunjiang Lou"], "title": "AppleVLM: End-to-end Autonomous Driving with Advanced Perception and Planning-Enhanced Vision-Language Models", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "End-to-end autonomous driving has emerged as a promising paradigm integrating perception, decision-making, and control within a unified learning framework. Recently, Vision-Language Models (VLMs) have gained significant attention for their potential to enhance the robustness and generalization of end-to-end driving models in diverse and unseen scenarios. However, existing VLM-based approaches still face challenges, including suboptimal lane perception, language understanding biases, and difficulties in handling corner cases. To address these issues, we propose AppleVLM, an advanced perception and planning-enhanced VLM model for robust end-to-end driving. AppleVLM introduces a novel vision encoder and a planning strategy encoder to improve perception and decision-making. Firstly, the vision encoder fuses spatial-temporal information from multi-view images across multiple timesteps using a deformable transformer mechanism, enhancing robustness to camera variations and facilitating scalable deployment across different vehicle platforms. Secondly, unlike traditional VLM-based approaches, AppleVLM introduces a dedicated planning modality that encodes explicit Bird's-Eye-View spatial information, mitigating language biases in navigation instructions. Finally, a VLM decoder fine-tuned by a hierarchical Chain-of-Thought integrates vision, language, and planning features to output robust driving waypoints. We evaluate AppleVLM in closed-loop experiments on two CARLA benchmarks, achieving state-of-the-art driving performance. Furthermore, we deploy AppleVLM on an AGV platform and successfully showcase real-world end-to-end autonomous driving in complex outdoor environments.", "AI": {"tldr": "本文提出了AppleVLM模型，旨在通过改进的视觉编码器和规划策略编码器来增强端到端自动驾驶系统的感知与决策能力。", "motivation": "现有的基于视觉语言模型（VLM）的方法在车道感知、语义理解偏差及处理特殊情况方面仍然存在问题。为了解决这些问题，作者提出了AppleVLM以提高整体的鲁棒性和泛化能力。", "method": "AppleVLM引入了一个融合多视角图像时空信息的新颖视觉编码器和包含明确鸟瞰图空间信息的规划策略编码器来改善感知与决策过程，并通过分层链式思考机制整合视觉、语言和规划特征，输出稳健的驾驶路径点。", "result": "在两个CARLA基准测试中进行闭环实验后，AppleVLM达到了最先进的驾驶性能，并且在AGV平台上展示了复杂户外环境中的端到端自主驾驶。", "conclusion": "通过改进感知与决策模型，AppleVLM能够在多样化的场景下提供更加稳健和通用的自动驾驶解决方案。"}}
{"id": "2602.04252", "pdf": "https://arxiv.org/pdf/2602.04252", "abs": "https://arxiv.org/abs/2602.04252", "authors": ["Aditya R. Bhattacharya", "Debanjan Goswami", "Shayok Chakraborty"], "title": "ACIL: Active Class Incremental Learning for Image Classification", "categories": ["cs.CV", "cs.AI"], "comment": "BMVC 2024 (Accepted). Authors, Aditya R. Bhattacharya and Debanjan Goswami contributed equally to this work", "summary": "Continual learning (or class incremental learning) is a realistic learning scenario for computer vision systems, where deep neural networks are trained on episodic data, and the data from previous episodes are generally inaccessible to the model. Existing research in this domain has primarily focused on avoiding catastrophic forgetting, which occurs due to the continuously changing class distributions in each episode and the inaccessibility of the data from previous episodes. However, these methods assume that all the training samples in every episode are annotated; this not only incurs a huge annotation cost, but also results in a wastage of annotation effort, since most of the samples in a given episode will not be accessible to the model in subsequent episodes. Active learning algorithms identify the salient and informative samples from large amounts of unlabeled data and are instrumental in reducing the human annotation effort in inducing a deep neural network. In this paper, we propose ACIL, a novel active learning framework for class incremental learning settings. We exploit a criterion based on uncertainty and diversity to identify the exemplar samples that need to be annotated in each episode, and will be appended to the data in the next episode. Such a framework can drastically reduce annotation cost and can also avoid catastrophic forgetting. Our extensive empirical analyses on several vision datasets corroborate the promise and potential of our framework against relevant baselines.", "AI": {"tldr": "提出了一种新的主动学习框架ACIL，用于解决图像分类中的连续学习问题。", "motivation": "现有的连续学习方法主要集中在避免灾难性遗忘上，并且假设每阶段的所有样本都被标注。这种假设导致了巨大的注释成本和资源浪费。", "method": "通过基于不确定性与多样性的标准来识别每个阶段需要被注释的代表性样本，以此减少人工标注的工作量并防止灾难性遗忘。", "result": "在多个视觉数据集上的广泛实验证明了ACIL框架的有效性和潜力。", "conclusion": "ACIL框架能够在连续学习场景中大幅降低标注成本，并有效避免灾难性遗忘。"}}
{"id": "2602.04251", "pdf": "https://arxiv.org/pdf/2602.04251", "abs": "https://arxiv.org/abs/2602.04251", "authors": ["Li Wang", "Ruixuan Gong", "Yumo Han", "Lei Yang", "Lu Yang", "Ying Li", "Bin Xu", "Huaping Liu", "Rong Fu"], "title": "Towards Next-Generation SLAM: A Survey on 3DGS-SLAM Focusing on Performance, Robustness, and Future Directions", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Traditional Simultaneous Localization and Mapping (SLAM) systems often face limitations including coarse rendering quality, insufficient recovery of scene details, and poor robustness in dynamic environments. 3D Gaussian Splatting (3DGS), with its efficient explicit representation and high-quality rendering capabilities, offers a new reconstruction paradigm for SLAM. This survey comprehensively reviews key technical approaches for integrating 3DGS with SLAM. We analyze performance optimization of representative methods across four critical dimensions: rendering quality, tracking accuracy, reconstruction speed, and memory consumption, delving into their design principles and breakthroughs. Furthermore, we examine methods for enhancing the robustness of 3DGS-SLAM in complex environments such as motion blur and dynamic environments. Finally, we discuss future challenges and development trends in this area. This survey aims to provide a technical reference for researchers and foster the development of next-generation SLAM systems characterized by high fidelity, efficiency, and robustness.", "AI": {"tldr": "对三维高斯点阵（3DGS）与SLAM技术的融合进行综述，分析性能优化和增强鲁棒性的方法", "motivation": "传统SLAM系统面临诸如渲染质量低、场景细节恢复不足及动态环境中的鲁棒性差等问题。3DGS提供了高效的显式表示和高质量的渲染能力，可作为新的重建范例。", "method": "综述了将3DGS与SLAM集成的关键技术方法，并分析代表性方法在四个关键维度上的性能优化：渲染质量、跟踪精度、重建速度及内存消耗，探讨其设计原则和突破点。同时研究提升复杂环境如运动模糊和动态场景中鲁棒性的方法。", "result": "未给出具体实验结果", "conclusion": "提供了技术参考以促进高保真度、高效性与鲁棒性下一代SLAM系统的发展"}}
{"id": "2602.04248", "pdf": "https://arxiv.org/pdf/2602.04248", "abs": "https://arxiv.org/abs/2602.04248", "authors": ["Hao Lu", "Haoyuan Huang", "Yulin Zhou", "Chen Li", "Ningxin Zhu"], "title": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search", "categories": ["cs.AI", "cs.CL"], "comment": "9 pages, 5 figures", "summary": "Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. These results underscore the critical necessity of coupling structured search with empirical accumulation for mastering complex, open-ended reasoning tasks.", "AI": {"tldr": "该论文提出了Empirical-MCTS框架，通过双循环机制将状态无关的搜索转化为连续学习过程，从而提高大型语言模型在复杂推理任务中的性能。", "motivation": "当前使用Monte Carlo Tree Search (MCTS) 的方法大多为无记忆的状态无关搜索，在解决每个问题后无法积累经验。论文旨在模仿人类解决问题时的知识积累特性，通过引入Empirical-MCTS来改进这一局限性。", "method": "Empirical-MCTS包含两个核心机制：Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) 和记忆优化代理。前者作为局部搜索中的反射式优化器，利用成对反馈动态合成适应性标准以实时进化元提示；后者管理全局存储库，通过原子操作提炼跨问题的高质量见解。", "result": "在AIME25、ARC-AGI-2和MathArena Apex等复杂推理基准测试中，Empirical-MCTS显著优于状态无关MCTS方法及独立经验驱动代理的表现。", "conclusion": "实验结果表明结合结构化搜索与经验积累对于掌握复杂开放性推理任务至关重要。"}}
{"id": "2602.04247", "pdf": "https://arxiv.org/pdf/2602.04247", "abs": "https://arxiv.org/abs/2602.04247", "authors": ["Cheonkam Jeong", "Jessica Liao", "Audrey Lu", "Yutong Song", "Christopher Rashidian", "Donna Krogh", "Erik Krogh", "Mahkameh Rasouli", "Jung-Ah Lee", "Nikil Dutt", "Lisa M Gibbs", "David Sultzer", "Julie Rousseau", "Jocelyn Ludlow", "Margaret Galvez", "Alexander Nuth", "Chet Khay", "Sabine Brunswicker", "Adeline Nyamathi"], "title": "DementiaBank-Emotion: A Multi-Rater Emotion Annotation Corpus for Alzheimer's Disease Speech (Version 1.0)", "categories": ["cs.CL", "cs.SD"], "comment": "Accepted at HeaLING Workshop @ EACL 2026. 9 pages, 3 figures, 8 tables", "summary": "We present DementiaBank-Emotion, the first multi-rater emotion annotation corpus for Alzheimer's disease (AD) speech. Annotating 1,492 utterances from 108 speakers for Ekman's six basic emotions and neutral, we find that AD patients express significantly more non-neutral emotions (16.9%) than healthy controls (5.7%; p < .001). Exploratory acoustic analysis suggests a possible dissociation: control speakers showed substantial F0 modulation for sadness (Delta = -3.45 semitones from baseline), whereas AD speakers showed minimal change (Delta = +0.11 semitones; interaction p = .023), though this finding is based on limited samples (sadness: n=5 control, n=15 AD) and requires replication. Within AD speech, loudness differentiates emotion categories, indicating partially preserved emotion-prosody mappings. We release the corpus, annotation guidelines, and calibration workshop materials to support research on emotion recognition in clinical populations.", "AI": {"tldr": "构建了DementiaBank-Emotion语料库，用于标注阿尔茨海默病患者和健康对照组的六种基本情绪及中性情绪。", "motivation": "旨在通过多注释者的情绪标记语料库研究阿尔茨海默病患者的言语表达特征及其与健康个体的区别。", "method": "对108名参与者（包括AD患者和健康对照）的1492个话语片段进行六种基本情绪及中性情绪的标注，同时进行了声学分析以探索不同群体的情绪表现差异。", "result": "阿尔茨海默病患者表达非中性情感的比例显著高于健康对照组；对于悲伤情绪，AD患者的基频变化较小，而健康对照则表现出明显的音调调整。", "conclusion": "研究揭示了AD患者与健康个体之间的情感表达模式的差异，并提出了进一步研究的需求。"}}
{"id": "2602.04243", "pdf": "https://arxiv.org/pdf/2602.04243", "abs": "https://arxiv.org/abs/2602.04243", "authors": ["Pengfei Yi", "Yifan Han", "Junyan Li", "Litao Liu", "Wenzhao Lian"], "title": "Viewpoint Matters: Dynamically Optimizing Viewpoints with Masked Autoencoder for Visual Manipulation", "categories": ["cs.RO"], "comment": "5 pages, 2 figures, 3 tables", "summary": "Robotic manipulation continues to be a challenge, and imitation learning (IL) enables robots to learn tasks from expert demonstrations. Current IL methods typically rely on fixed camera setups, where cameras are manually positioned in static locations, imposing significant limitations on adaptability and coverage. Inspired by human active perception, where humans dynamically adjust their viewpoint to capture the most relevant and least noisy information, we propose MAE-Select, a novel framework for active viewpoint selection in single-camera robotic systems. MAE-Select fully leverages pre-trained multi-view masked autoencoder representations and dynamically selects the next most informative viewpoint at each time chunk without requiring labeled viewpoints. Extensive experiments demonstrate that MAE-Select improves the capabilities of single-camera systems and, in some cases, even surpasses multi-camera setups. The project will be available at https://mae-select.github.io.", "AI": {"tldr": "提出了一种新的框架MAE-Select，用于单相机机器人系统的主动视角选择。", "motivation": "当前的模仿学习方法依赖于固定的摄像机设置，限制了适应性和覆盖范围。该研究受人类主动感知启发，通过动态调整视角来捕获最相关和最少噪声的信息。", "method": "MAE-Select利用预训练的多视图掩码自动编码器表示，并在每个时间块中动态选择下一个最有信息量的视角，无需标记的视角。", "result": "实验表明，MAE-Select改进了单相机系统的功能，在某些情况下甚至超过了多相机设置。", "conclusion": "MAE-Select框架提高了机器人视觉操作的能力，展示了主动感知的优势。"}}
{"id": "2602.04242", "pdf": "https://arxiv.org/pdf/2602.04242", "abs": "https://arxiv.org/abs/2602.04242", "authors": ["Mobasshira Akter Urmi", "Raiyan Abdul Baten"], "title": "Strategic Adaptation Under Contextual Change: Insights from a Dyadic Negotiation Testbed for AI Coaching Technologies", "categories": ["cs.HC"], "comment": null, "summary": "Strategic adaptation -- the ability to adjust interaction behavior in response to changing constraints and leverage -- is a central goal of negotiation training and an emerging target for AI coaching systems. However, adaptation is difficult to evaluate because adaptation-relevant moments arise unpredictably in typical tasks. We study a reusable dyadic negotiation testbed that employs a controlled midstream change in one party's outside alternative as a repeatable perturbation to stress-test adaptation. In a six-round chat-based negotiation study (N=100), the perturbation reliably reorganized interaction dynamics: transitions between integrative (cooperative) and distributive (positional) behaviors declined, behavioral diversity narrowed, and interactions drifted toward more distributive tactics. Critically, this distributive drift predicted worse relational experience net of objective outcomes, and adaptation patterns were path dependent on prior behavior. These results establish a methodological bridge for evaluating and comparing AI coaching systems on strategic adaptation as a process and identify failure modes and design targets for adaptive interaction support.", "AI": {"tldr": "本文研究了在谈判过程中通过引入情境变化来评估和改进AI教练系统对策略适应性的支持能力。", "motivation": "策略适应性是谈判训练的重要目标，但在常规任务中难以衡量。因此，作者设计了一种可以重复使用的双边谈判测试平台来专门解决这一问题。", "method": "研究采用了一个六轮基于聊天的谈判实验（N=100），通过改变一方的备选方案，创建了可重复的情境变化，并观察这些变化如何影响互动模式和结果。", "result": "情境变化导致合作行为减少、策略多样性降低及更多地采取立场强硬的谈判策略。这种转变与较差的关系体验相关联，即使客观结果没有变差。而且，适应性模式依赖于之前的交互历史。", "conclusion": "本研究为评估和比较AI教练系统在支持战略适应方面的有效性提供了方法论基础，并指出了设计中需关注的失败模式及改进方向。"}}
{"id": "2602.04240", "pdf": "https://arxiv.org/pdf/2602.04240", "abs": "https://arxiv.org/abs/2602.04240", "authors": ["Suzeyu Chen", "Leheng Li", "Ying-Cong Chen"], "title": "SPOT-Occ: Sparse Prototype-guided Transformer for Camera-based 3D Occupancy Prediction", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "8 pages, 6 figures", "summary": "Achieving highly accurate and real-time 3D occupancy prediction from cameras is a critical requirement for the safe and practical deployment of autonomous vehicles. While this shift to sparse 3D representations solves the encoding bottleneck, it creates a new challenge for the decoder: how to efficiently aggregate information from a sparse, non-uniformly distributed set of voxel features without resorting to computationally prohibitive dense attention. In this paper, we propose a novel Prototype-based Sparse Transformer Decoder that replaces this costly interaction with an efficient, two-stage process of guided feature selection and focused aggregation. Our core idea is to make the decoder's attention prototype-guided. We achieve this through a sparse prototype selection mechanism, where each query adaptively identifies a compact set of the most salient voxel features, termed prototypes, for focused feature aggregation. To ensure this dynamic selection is stable and effective, we introduce a complementary denoising paradigm. This approach leverages ground-truth masks to provide explicit guidance, guaranteeing a consistent query-prototype association across decoder layers. Our model, dubbed SPOT-Occ, outperforms previous methods with a significant margin in speed while also improving accuracy. Source code is released at https://github.com/chensuzeyu/SpotOcc.", "AI": {"tldr": "提出了一种基于稀疏原型引导的Transformer解码器，用于从摄像头进行实时且准确的三维占用预测。", "motivation": "解决稀疏三维表示中高效聚合信息的问题，同时提高自动驾驶车辆的安全性和实用性。", "method": "通过引入一种稀疏原型选择机制和噪声去除方法，实现高效的特征聚集，提高模型在速度和准确性方面的性能。", "result": "所提出的SPOT-Occ模型相比现有方法，在速度上显著提升且精度更高。", "conclusion": "提出的方法有效解决了从摄像头进行实时三维占用预测中的关键问题，并提供了更优的解决方案。"}}
{"id": "2602.04237", "pdf": "https://arxiv.org/pdf/2602.04237", "abs": "https://arxiv.org/abs/2602.04237", "authors": ["ZeYu Li", "Te Qi", "TieYong Zeng"], "title": "An Improved Boosted DC Algorithm for Nonsmooth Functions with Applications in Image Recovery", "categories": ["math.OC", "cs.CV"], "comment": ":68Q25; 68R10; 68U05", "summary": "We propose a new approach to perform the boosted difference of convex functions algorithm (BDCA) on non-smooth and non-convex problems involving the difference of convex (DC) functions. The recently proposed BDCA uses an extrapolation step from the point computed by the classical DC algorithm (DCA) via a line search procedure in a descent direction to get an additional decrease of the objective function and accelerate the convergence of DCA. However, when the first function in DC decomposition is non-smooth, the direction computed by BDCA can be ascent and a monotone line search cannot be performed. In this work, we proposed a monotone improved boosted difference of convex functions algorithm (IBDCA) for certain types of non-smooth DC programs, namely those that can be formulated as the difference of a possibly non-smooth function and a smooth one. We show that any cluster point of the sequence generated by IBDCA is a critical point of the problem under consideration and that the corresponding objective value is monotonically decreasing and convergent. We also present the global convergence and the convergent rate under the Kurdyka-Lojasiewicz property. The applications of IBDCA in image recovery show the effectiveness of our proposed method. The corresponding numerical experiments demonstrate that our IBDCA outperforms DCA and other state-of-the-art DC methods in both computational time and number of iterations.", "AI": {"tldr": "改进的增益凸差分算法（IBDCA）应用于非光滑函数，以加速图像恢复等问题中的收敛。", "motivation": "在非光滑和非凸问题中应用传统DC算法难以有效进行，因此提出一种新的方法来克服这些挑战并提高效率。", "method": "提出了改进的增益凸差分算法（IBDCA），通过使用一个单调线搜索程序从由古典DC算法计算出的点出发，在下降方向上执行额外的减少目标函数步骤以加速收敛。", "result": "实验显示，与传统DC算法和其他前沿DC方法相比，所提出的IBDCA在计算时间和迭代次数方面都表现出色。", "conclusion": "改进后的增益凸差分算法不仅理论上证明了其有效性，并且通过应用于图像恢复的实际案例验证了该算法的优越性。"}}
{"id": "2602.04231", "pdf": "https://arxiv.org/pdf/2602.04231", "abs": "https://arxiv.org/abs/2602.04231", "authors": ["Rui Tang", "Guankun Wang", "Long Bai", "Huxin Gao", "Jiewen Lai", "Chi Kit Ng", "Jiazheng Wang", "Fan Zhang", "Hongliang Ren"], "title": "GeoLanG: Geometry-Aware Language-Guided Grasping with Unified RGB-D Multimodal Learning", "categories": ["cs.RO"], "comment": "IEEE ICRA 2025", "summary": "Language-guided grasping has emerged as a promising paradigm for enabling robots to identify and manipulate target objects through natural language instructions, yet it remains highly challenging in cluttered or occluded scenes. Existing methods often rely on multi-stage pipelines that separate object perception and grasping, which leads to limited cross-modal fusion, redundant computation, and poor generalization in cluttered, occluded, or low-texture scenes. To address these limitations, we propose GeoLanG, an end-to-end multi-task framework built upon the CLIP architecture that unifies visual and linguistic inputs into a shared representation space for robust semantic alignment and improved generalization. To enhance target discrimination under occlusion and low-texture conditions, we explore a more effective use of depth information through the Depth-guided Geometric Module (DGGM), which converts depth into explicit geometric priors and injects them into the attention mechanism without additional computational overhead. In addition, we propose Adaptive Dense Channel Integration, which adaptively balances the contributions of multi-layer features to produce more discriminative and generalizable visual representations. Extensive experiments on the OCID-VLG dataset, as well as in both simulation and real-world hardware, demonstrate that GeoLanG enables precise and robust language-guided grasping in complex, cluttered environments, paving the way toward more reliable multimodal robotic manipulation in real-world human-centric settings.", "AI": {"tldr": "GeoLanG是一种用于语言指导抓取任务的端到端多任务框架，通过统一视觉和语言输入来增强在复杂环境中的准确性与鲁棒性。", "motivation": "现有方法依赖于分阶段管线处理物体感知和抓取，这导致了跨模态融合不足、冗余计算以及在复杂场景中性能较差的问题。为了提高在遮挡和低纹理条件下的目标识别能力，提出了一种新的深度指导几何模块（DGGM）以更好地利用深度信息。", "method": "基于CLIP架构提出了GeoLanG框架，它将视觉和语言输入统一到共享表示空间中，并通过一个名为Depth-guided Geometric Module (DGGM)的组件来增强遮挡环境下目标区分能力。同时引入了自适应密集通道整合策略以提高特征图之间的互相关性。", "result": "在OCID-VLG数据集及仿真和真实硬件环境中的实验表明，GeoLanG能够实现准确且鲁棒的语言指导抓取操作，在复杂、拥挤环境中表现优越。", "conclusion": "GeoLanG通过统一视觉与语言输入的方式提供了更可靠多模态机器人操控能力，为实际应用场景中的人机交互铺平了道路。"}}
{"id": "2602.04228", "pdf": "https://arxiv.org/pdf/2602.04228", "abs": "https://arxiv.org/abs/2602.04228", "authors": ["Shuanghao Bai", "Dakai Wang", "Cheng Chi", "Wanqi Zhou", "Jing Lyu", "Xiaoguang Zhao", "Pengwei Wang", "Zhongyuan Wang", "Lei Xing", "Shanghang Zhang", "Badong Chen"], "title": "Reshaping Action Error Distributions for Reliable Vision-Language-Action Models", "categories": ["cs.RO"], "comment": null, "summary": "In robotic manipulation, vision-language-action (VLA) models have emerged as a promising paradigm for learning generalizable and scalable robot policies. Most existing VLA frameworks rely on standard supervised objectives, typically cross-entropy for discrete actions and mean squared error (MSE) for continuous action regression, which impose strong pointwise constraints on individual predictions. In this work, we focus on continuous-action VLA models and move beyond conventional MSE-based regression by reshaping action error distributions during training. Drawing on information-theoretic principles, we introduce Minimum Error Entropy (MEE) into modern VLA architectures and propose a trajectory-level MEE objective, together with two weighted variants, combined with MSE for continuous-action VLA training. We evaluate our approaches across standard, few-shot, and noisy settings on multiple representative VLA architectures, using simulation benchmarks such as LIBERO and SimplerEnv as well as real-world robotic manipulation tasks. Experimental results demonstrate consistent improvements in success rates and robustness across these settings. Under imbalanced data regimes, the gains persist within a well-characterized operating range, while incurring negligible additional training cost and no impact on inference efficiency. We further provide theoretical analyses that explain why MEE-based supervision is effective and characterize its practical range. Project Page: https://cognition2actionlab.github.io/VLA-TMEE.github.io/", "AI": {"tldr": "通过重新设计动作误差分布，改进了连续动作的视觉语言行动模型的可靠性", "motivation": "现有连续动作的视觉语言行动模型依赖于标准监督目标（如MSE），这些方法强加了个别预测上的点对点约束。本文提出了一种新的训练方式以提高模型在不同场景下的性能和鲁棒性", "method": "引入了基于最小误差熵(MEE)的信息论原理，并将其与均方误差(MSE)相结合，提出了轨迹级MEE目标以及两种加权变体，用于改进连续动作的视觉语言行动模型训练", "result": "实验结果表明，在标准、少量样本和噪声设置下，新方法在成功率和鲁棒性方面均有显著提升。该方法在不平衡数据集上的表现也优于传统方法，并且不会增加训练成本或影响推理效率", "conclusion": "基于最小误差熵的监督方法有效提高了视觉语言行动模型的性能，并通过理论分析解释了其有效性及实用范围"}}
{"id": "2602.04227", "pdf": "https://arxiv.org/pdf/2602.04227", "abs": "https://arxiv.org/abs/2602.04227", "authors": ["Hanuman Verma", "Kiho Im", "Pranabesh Maji", "Akshansh Gupta"], "title": "An Intuitionistic Fuzzy Logic Driven UNet architecture: Application to Brain Image segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate segmentation of MRI brain images is essential for image analysis, diagnosis of neuro-logical disorders and medical image computing. In the deep learning approach, the convolutional neural networks (CNNs), especially UNet, are widely applied in medical image segmentation. However, it is difficult to deal with uncertainty due to the partial volume effect in brain images. To overcome this limitation, we propose an enhanced framework, named UNet with intuitionistic fuzzy logic (IF-UNet), which incorporates intuitionistic fuzzy logic into UNet. The model processes input data in terms of membership, nonmembership, and hesitation degrees, allowing it to better address tissue ambiguity resulting from partial volume effects and boundary uncertainties. The proposed architecture is evaluated on the Internet Brain Segmentation Repository (IBSR) dataset, and its performance is computed using accuracy, Dice coefficient, and intersection over union (IoU). Experimental results confirm that IF-UNet improves segmentation quality with handling uncertainty in brain images.", "AI": {"tldr": "本文提出了一种基于直觉模糊逻辑的UNet架构，用于处理脑MRI图像中的不确定性。", "motivation": "传统UNet在处理由于部分容积效应和边界不明确导致的脑部影像不确定性时存在困难。因此，引入了直觉模糊逻辑以提高分割质量。", "method": "本文提出了一种新的框架——IF-UNet，该框架将直觉模糊逻辑融入到UNet中，通过处理输入数据的隶属度、非隶属度和犹豫程度来改善组织模糊性问题。", "result": "实验结果表明，提出的IF-UNet模型在准确性、Dice系数和交并比方面优于传统方法，在IBSR数据集上表现出更好的分割性能。", "conclusion": "研究证明了直觉模糊逻辑增强的UNet架构可以有效处理脑部图像中的不确定性问题，并提高了整体的分割质量。"}}
{"id": "2602.04224", "pdf": "https://arxiv.org/pdf/2602.04224", "abs": "https://arxiv.org/abs/2602.04224", "authors": ["Zeming Wei", "Qiaosheng Zhang", "Xia Hu", "Xingcheng Xu"], "title": "RAPO: Risk-Aware Preference Optimization for Generalizable Safe Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "math.OC"], "comment": null, "summary": "Large Reasoning Models (LRMs) have achieved tremendous success with their chain-of-thought (CoT) reasoning, yet also face safety issues similar to those of basic language models. In particular, while algorithms are designed to guide them to deliberately refuse harmful prompts with safe reasoning, this process often fails to generalize against diverse and complex jailbreak attacks. In this work, we attribute these failures to the generalization of the safe reasoning process, particularly their insufficiency against complex attack prompts. We provide both theoretical and empirical evidence to show the necessity of a more sufficient safe reasoning process to defend against advanced attack prompts. Building on this insight, we propose a Risk-Aware Preference Optimization (RAPO) framework that enables LRM to adaptively identify and address the safety risks with appropriate granularity in its thinking content. Extensive experiments demonstrate that RAPO successfully generalizes multiple LRMs' safe reasoning adaptively across diverse attack prompts whilst preserving general utility, contributing a robust alignment technique for LRM safety. Our code is available at https://github.com/weizeming/RAPO.", "AI": {"tldr": "RAPO框架旨在提高大型推理模型（LRMs）在面对复杂攻击提示时的安全性与泛化能力。", "motivation": "现有算法虽能引导LRMs拒绝有害指令，但难以有效对抗多样化和复杂的攻击。因此需要一种更有效的安全推理过程来防御高级攻击提示。", "method": "RAPO框架通过风险感知偏好优化方法使LRMs能够自适应地识别并应对思考内容中的安全威胁，并以适当的粒度进行处理。", "result": "实验表明，RAPO能够在多种复杂攻击提示下成功泛化LRMs的安全推理能力同时保持其通用性。", "conclusion": "通过提供强大的对齐技术，RAPO框架为提高LRMs的安全性能贡献了一种稳健的方法。"}}
{"id": "2602.04220", "pdf": "https://arxiv.org/pdf/2602.04220", "abs": "https://arxiv.org/abs/2602.04220", "authors": ["Yao Teng", "Minxuan Lin", "Xian Liu", "Shuai Wang", "Xiao Yang", "Xihui Liu"], "title": "Adaptive 1D Video Diffusion Autoencoder", "categories": ["cs.CV"], "comment": null, "summary": "Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations. However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations, while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios. More importantly, it supports adaptive compression and thus can achieve higher compression ratios. To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.", "AI": {"tldr": "提出了一种自适应的一维视频扩散自动编码器，用于改进视频压缩和生成。", "motivation": "现有视频自动编码器存在固定率压缩浪费令牌、CNN架构刚性及确定性解码器难以恢复细节的问题。", "method": "采用基于查询的视觉变换器提取时空特征并产生潜在表示，并使用可变长度dropout机制动态调整潜变量长度。解码器是一个像素空间扩散变换器，以潜在表示作为输入条件重构视频。", "result": "该框架在重建指标方面表现出与3D-CNN VAE相当的性能，在相同的压缩率下实现自适应压缩并支持生成模型。", "conclusion": "通过改进自动编码器架构和引入动态调整机制，One-DVA能够更有效地进行视频压缩，并为下游任务提供了更好的潜在表示。"}}
{"id": "2602.04217", "pdf": "https://arxiv.org/pdf/2602.04217", "abs": "https://arxiv.org/abs/2602.04217", "authors": ["Takanori Ashihara", "Shota Horiguchi", "Kohei Matsuura", "Tsubasa Ochiai", "Marc Delcroix"], "title": "Frontend Token Enhancement for Token-Based Speech Recognition", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Accepted at ICASSP 2026", "summary": "Discretized representations of speech signals are efficient alternatives to continuous features for various speech applications, including automatic speech recognition (ASR) and speech language models. However, these representations, such as semantic or phonetic tokens derived from clustering outputs of self-supervised learning (SSL) speech models, are susceptible to environmental noise, which can degrade backend task performance. In this work, we introduce a frontend system that estimates clean speech tokens from noisy speech and evaluate it on an ASR backend using semantic tokens. We consider four types of enhancement models based on their input/output domains: wave-to-wave, token-to-token, continuous SSL features-to-token, and wave-to-token. These models are trained independently of ASR backends. Experiments on the CHiME-4 dataset demonstrate that wave-to-token enhancement achieves the best performance among the frontends. Moreover, it mostly outperforms the ASR system based on continuous SSL features.", "AI": {"tldr": "本文提出了一种前端系统，用于从噪声语音中估计清晰的语音令牌，并在基于语义标记的ASR后端上进行了评估。", "motivation": "离散化的语音信号表示容易受到环境噪声的影响，从而降低下游任务性能。为了解决这一问题，研究者提出了一个前端系统来改善噪声环境下的语音识别效果。", "method": "本文探讨了四种增强模型（基于其输入/输出域：波形到波形、令牌到令牌、连续SSL特征到令牌和波形到令牌），通过独立于ASR后端进行训练，评估这些模型在CHiME-4数据集上的性能表现。", "result": "实验结果表明，波形到令牌的增强方法表现出最佳的前端性能，并且大多数情况下优于基于连续SSL特征的ASR系统。", "conclusion": "研究证明了使用波形到令牌增强能够显著提高语音识别系统的鲁棒性，在噪声环境中具有更好的表现。"}}
{"id": "2602.04215", "pdf": "https://arxiv.org/pdf/2602.04215", "abs": "https://arxiv.org/abs/2602.04215", "authors": ["Chaoqi Liu", "Xiaoshen Han", "Jiawei Gao", "Yue Zhao", "Haonan Chen", "Yilun Du"], "title": "OAT: Ordered Action Tokenization", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Autoregressive policies offer a compelling foundation for scalable robot learning by enabling discrete abstraction, token-level reasoning, and flexible inference. However, applying autoregressive modeling to continuous robot actions requires an effective action tokenization scheme. Existing approaches either rely on analytical discretization methods that produce prohibitively long token sequences, or learned latent tokenizers that lack structure, limiting their compatibility with next-token prediction. In this work, we identify three desiderata for action tokenization - high compression, total decodability, and a left-to-right causally ordered token space - and introduce Ordered Action Tokenization (OAT), a learned action tokenizer that satisfies all three. OAT discretizes action chunks into an ordered sequence of tokens using transformer with registers, finite scalar quantization, and ordering-inducing training mechanisms. The resulting token space aligns naturally with autoregressive generation and enables prefix-based detokenization, yielding an anytime trade-off between inference cost and action fidelity. Across more than 20 tasks spanning four simulation benchmarks and real-world settings, autoregressive policies equipped with OAT consistently outperform prior tokenization schemes and diffusion-based baselines, while offering significantly greater flexibility at inference time.", "AI": {"tldr": "提出了有序动作标记化(OAT)方法，用于改善连续机器人动作的自回归策略。", "motivation": "现有动作标记化方案要么产生过长的令牌序列，要么缺乏结构，限制了它们与下一个令牌预测的兼容性。作者提出了一种新的学习式动作标记器以满足高压缩、完全解码和从左到右因果有序令牌空间的需求。", "method": "OAT通过使用带有寄存器的变压器、有限标量量化以及诱导排序训练机制将动作块离散化为一个有序令牌序列，实现自然自回归生成，并支持前缀解码。", "result": "在超过20个任务中，实验表明，与以前的标记方案和扩散基线相比，带有OAT的自回归策略性能更佳且更具灵活性。", "conclusion": "OAT实现了有效的动作令牌化，提高了自回归政策的学习效率，并为机器人学习提供了新的可能性。"}}
{"id": "2602.04214", "pdf": "https://arxiv.org/pdf/2602.04214", "abs": "https://arxiv.org/abs/2602.04214", "authors": ["Zhihai Bi", "Yushan Zhang", "Kai Chen", "Guoyang Zhao", "Yulin Li", "Jun Ma"], "title": "ALORE: Autonomous Large-Object Rearrangement with a Legged Manipulator", "categories": ["cs.RO"], "comment": null, "summary": "Endowing robots with the ability to rearrange various large and heavy objects, such as furniture, can substantially alleviate human workload. However, this task is extremely challenging due to the need to interact with diverse objects and efficiently rearrange multiple objects in complex environments while ensuring collision-free loco-manipulation. In this work, we present ALORE, an autonomous large-object rearrangement system for a legged manipulator that can rearrange various large objects across diverse scenarios. The proposed system is characterized by three main features: (i) a hierarchical reinforcement learning training pipeline for multi-object environment learning, where a high-level object velocity controller is trained on top of a low-level whole-body controller to achieve efficient and stable joint learning across multiple objects; (ii) two key modules, a unified interaction configuration representation and an object velocity estimator, that allow a single policy to regulate planar velocity of diverse objects accurately; and (iii) a task-and-motion planning framework that jointly optimizes object visitation order and object-to-target assignment, improving task efficiency while enabling online replanning. Comparisons against strong baselines show consistent superiority in policy generalization, object-velocity tracking accuracy, and multi-object rearrangement efficiency. Key modules are systematically evaluated, and extensive simulations and real-world experiments are conducted to validate the robustness and effectiveness of the entire system, which successfully completes 8 continuous loops to rearrange 32 chairs over nearly 40 minutes without a single failure, and executes long-distance autonomous rearrangement over an approximately 40 m route. The open-source packages are available at https://zhihaibi.github.io/Alore/.", "AI": {"tldr": "本论文提出了一种自主大型物体重排系统ALORE，该系统使用带腿部的机械臂在复杂环境中高效且安全地重新排列多种大型和重型对象。", "motivation": "机器人具备重新排列各种大型和重型物品（如家具）的能力可以大大减轻人类的工作负担。然而，由于需要与不同的物体交互并在复杂的环境中有效地重排多个物体，同时确保无碰撞的行走-操作，这一任务极具挑战性。", "method": "ALORE系统具有三个主要特征：(i) 多对象环境学习的分层强化学习训练管道，在低级别的全身控制器之上训练高层次的对象速度控制器以实现多对象之间的高效和稳定的联合学习；(ii) 单个策略调整不同物体平面速度的关键模块，包括统一交互配置表示法和目标速度估计器；以及(iii) 任务与运动规划框架，共同优化访问顺序和目标分配以提高任务效率并支持在线重规划。", "result": "对比强基线显示了在策略泛化、对象速度跟踪准确性和多对象重新排列效率方面的持续优越性。系统通过广泛的模拟和现实世界实验验证其稳健性和有效性，并成功完成8个连续循环，重排32把椅子超过40分钟而没有出现任何故障，执行长达约40米的自主移动。", "conclusion": "ALORE系统在复杂环境中实现了高效的大型物体重新排列，展示了强大的策略泛化能力和多对象重新排列效率。"}}
{"id": "2602.04213", "pdf": "https://arxiv.org/pdf/2602.04213", "abs": "https://arxiv.org/abs/2602.04213", "authors": ["Feiyu Gavin Zhu", "Jean Oh", "Reid Simmons"], "title": "InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons", "categories": ["cs.AI"], "comment": "Proceedings of the 21st ACM/IEEE International Conference on Human-Robot Interaction", "summary": "Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent new skills. To lower the barrier of teaching AI agents, we propose Interactive Policy Restructuring and Training (InterPReT), which takes user instructions to continually update the policy structure and optimize its parameters to fit user demonstrations. This enables end-users to interactively give instructions and demonstrations, monitor the agent's performance, and review the agent's decision-making strategies. A user study (N=34) on teaching an AI agent to drive in a racing game confirms that our approach yields more robust policies without impairing system usability, compared to a generic imitation learning baseline, when a layperson is responsible for both giving demonstrations and determining when to stop. This shows that our method is more suitable for end-users without much technical background in machine learning to train a dependable policy", "AI": {"tldr": "本文提出了一种新的交互式策略重构和训练方法（InterPReT），使非专业人士能够通过指令和演示来有效地培训AI代理。", "motivation": "目前的模仿学习工作依赖于专业人员的大规模示范，这对非专业人士来说是一个挑战。因此，需要一种能够让普通用户轻松指导AI代理的方法。", "method": "本文提出了一种新的方法InterPReT，该方法允许用户通过指令更新策略结构和优化参数以适应用户的演示，并使用户能够监控代理的性能和审查其决策过程。", "result": "在一项针对非专业人士使用赛车游戏培训AI代理的研究中（N=34），结果显示了与通用模仿学习基线相比，InterPReT方法生成更加稳健策略的能力。", "conclusion": "本文的方法表明，即使是没有机器学习背景的用户也能够通过交互式指导来训练可靠的政策。"}}
{"id": "2602.04212", "pdf": "https://arxiv.org/pdf/2602.04212", "abs": "https://arxiv.org/abs/2602.04212", "authors": ["Michael A. Lepori", "Tal Linzen", "Ann Yuan", "Katja Filippova"], "title": "Language Models Struggle to Use Representations Learned In-Context", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Though large language models (LLMs) have enabled great success across a wide variety of tasks, they still appear to fall short of one of the loftier goals of artificial intelligence research: creating an artificial system that can adapt its behavior to radically new contexts upon deployment. One important step towards this goal is to create systems that can induce rich representations of data that are seen in-context, and then flexibly deploy these representations to accomplish goals. Recently, Park et al. (2024) demonstrated that current LLMs are indeed capable of inducing such representation from context (i.e., in-context representation learning). The present study investigates whether LLMs can use these representations to complete simple downstream tasks. We first assess whether open-weights LLMs can use in-context representations for next-token prediction, and then probe models using a novel task, adaptive world modeling. In both tasks, we find evidence that open-weights LLMs struggle to deploy representations of novel semantics that are defined in-context, even if they encode these semantics in their latent representations. Furthermore, we assess closed-source, state-of-the-art reasoning models on the adaptive world modeling task, demonstrating that even the most performant LLMs cannot reliably leverage novel patterns presented in-context. Overall, this work seeks to inspire novel methods for encouraging models to not only encode information presented in-context, but to do so in a manner that supports flexible deployment of this information.", "AI": {"tldr": "研究探讨了大型语言模型是否能利用上下文学习到的表示来完成下游任务。", "motivation": "大型语言模型在多种任务中取得成功，但仍未能实现灵活适应新环境的目标。本研究旨在探索这些模型能否通过从上下文中学习并应用表示来达成这一目标。", "method": "首先评估开放权重LLM用于下文预测时的上下文表示利用情况；其次引入一个新颖的任务——自适应世界建模，测试LLM是否能灵活使用新语义。", "result": "实验发现即使是顶级性能模型也难以可靠地从上下文中应用新型模式。", "conclusion": "研究表明当前大型语言模型在上下文表示的灵活应用方面存在不足，并提出了激发新方法以促进这一问题解决。"}}
{"id": "2602.04210", "pdf": "https://arxiv.org/pdf/2602.04210", "abs": "https://arxiv.org/abs/2602.04210", "authors": ["Enyu Zhou", "Zhiheng Xi", "Long Ma", "Zhihao Zhang", "Shihan Dou", "Zhikai Lei", "Guoteng Wang", "Rui Zheng", "Hang Yan", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Steering LLMs via Scalable Interactive Oversight", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\\% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.", "AI": {"tldr": "提出了一种通过递归决策树分解复杂意图的可扩展交互式监督框架，以增强人类对大型语言模型的控制。", "motivation": "解决在执行自动化任务时的人类难以有效指导大型语言模型的问题，特别是当用户缺乏领域专业知识或无法验证输出时。", "method": "开发了一个将复杂意图分解为递归决策树的方法，并通过收集每个节点上的低负担反馈来实现精确的整体指引。该框架还展示了如何利用在线用户反馈通过强化学习进行优化。", "result": "在网页开发任务中，非专家使用此框架可以生成专家级别的产品需求文档，实现了54%的对齐度提升。", "conclusion": "这种递归决策树和反馈聚合的方法为保持人类控制提供了实际路径，即使AI系统规模不断扩大。"}}
{"id": "2602.04208", "pdf": "https://arxiv.org/pdf/2602.04208", "abs": "https://arxiv.org/abs/2602.04208", "authors": ["Hyeonbeom Choi", "Daechul Ahn", "Youhan Lee", "Taewook Kang", "Seongwon Cho", "Jonghyun Choi"], "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "20 pages, 8 figures", "summary": "Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic control, with test-time scaling (TTS) gaining attention to enhance robustness beyond training. However, existing TTS methods for VLAs require additional training, verifiers, and multiple forward passes, making them impractical for deployment. Moreover, they intervene only at action decoding while keeping visual representations fixed-insufficient under perceptual ambiguity, where reconsidering how to perceive is as important as deciding what to do. To address these limitations, we propose SCALE, a simple inference strategy that jointly modulates visual perception and action based on 'self-uncertainty', inspired by uncertainty-driven exploration in Active Inference theory-requiring no additional training, no verifier, and only a single forward pass. SCALE broadens exploration in both perception and action under high uncertainty, while focusing on exploitation when confident-enabling adaptive execution across varying conditions. Experiments on simulated and real-world benchmarks demonstrate that SCALE improves state-of-the-art VLAs and outperforms existing TTS methods while maintaining single-pass efficiency.", "AI": {"tldr": "SCALE是一种用于改进视觉语言动作模型（VLA）推理的方法，通过自我不确定性自适应地调整感知和行动。", "motivation": "现有的测试时间缩放方法需要额外训练、验证器和多次前向传递，并且仅在行为解码时干预而不重新考虑感知方式，在感知模糊性下表现不足。因此，提出SCALE来克服这些限制。", "method": "SCALE基于自我不确定性自适应地调整视觉感知和行动，无需额外训练或验证器，只需单次前向传递即可实现高效推理。", "result": "实验表明，SCALE改进了现有最佳的VLA模型，并在模拟和现实世界基准测试中超越了现有的TTS方法。", "conclusion": "SCALE提供了一种简单而有效的策略，能够在视觉语言动作任务中适应各种条件下的感知和行动调整。"}}
{"id": "2602.04206", "pdf": "https://arxiv.org/pdf/2602.04206", "abs": "https://arxiv.org/abs/2602.04206", "authors": ["Hsien-Jyh Liao"], "title": "Enforcing Monotonic Progress in Legal Cross-Examination: Preventing Long-Horizon Stagnation in LLM-Based Inquiry", "categories": ["cs.CL", "cs.AI"], "comment": "Submitted to ICAIL 2026. Under review", "summary": "Large language models (LLMs) exhibit impressive linguistic fluency but struggle to reliably complete long-horizon tasks under explicit procedural constraints. In legal cross-examination, purely proba-bilistic generation often maintains behavioral coherence while failing to ensure procedural advancement. We characterize this failure as procedural stagnation and propose Soft-FSM, a neuro-symbolic architecture that enforces monotonic progress over accumulated Key Information Units (KIUs) via an external deterministic state controller. Experiments on three real-world Taiwanese criminal homicide cases show that baseline methods collapse below 40% completeness, while Soft-FSM consistently achieves over 97% with near-zero redundancy. These results suggest that, in such domains, reliable task completion cannot be guaranteed by emergent LLM behavior alone, and can be reliably enforced through explicit and verifiable external state control.", "AI": {"tldr": "通过提出Soft-FSM架构来解决大型语言模型在法律交叉询问中因程序约束导致的长期任务完成问题。", "motivation": "大型语言模型虽然具有出色的语言流畅性，但在严格的程序约束下难以可靠地完成长时任务。在法律交叉询问过程中，纯粹概率生成方法容易出现行为一致性但缺乏程序进展的问题。", "method": "提出了一种基于神经符号架构的Soft-FSM系统，通过外部确定的状态控制器来强制累积关键信息单元的单调进步。", "result": "实验结果显示，在三个真实世界案例中，基线方法完成度低于40%，而Soft-FSM保持在97%以上，并且几乎没有冗余。", "conclusion": "这些结果表明，仅依靠大型语言模型自身的行为无法保证任务可靠地完成，在这种领域需要通过明确和可验证的外部状态控制来实现。"}}
{"id": "2602.04204", "pdf": "https://arxiv.org/pdf/2602.04204", "abs": "https://arxiv.org/abs/2602.04204", "authors": ["Chao Li", "Rui Zhang", "Siyuan Huang", "Xian Zhong", "Hongbo Jiang"], "title": "AGMA: Adaptive Gaussian Mixture Anchors for Prior-Guided Multimodal Human Trajectory Forecasting", "categories": ["cs.CV", "cs.LG"], "comment": "14 pages, 3 figures", "summary": "Human trajectory forecasting requires capturing the multimodal nature of pedestrian behavior. However, existing approaches suffer from prior misalignment. Their learned or fixed priors often fail to capture the full distribution of plausible futures, limiting both prediction accuracy and diversity. We theoretically establish that prediction error is lower-bounded by prior quality, making prior modeling a key performance bottleneck. Guided by this insight, we propose AGMA (Adaptive Gaussian Mixture Anchors), which constructs expressive priors through two stages: extracting diverse behavioral patterns from training data and distilling them into a scene-adaptive global prior for inference. Extensive experiments on ETH-UCY, Stanford Drone, and JRDB datasets demonstrate that AGMA achieves state-of-the-art performance, confirming the critical role of high-quality priors in trajectory forecasting.", "AI": {"tldr": "AGMA通过自适应高斯混合锚点构建表达式先验，以提高行人轨迹预测的准确性和多样性。", "motivation": "现有的轨迹预测方法在捕捉行为分布上存在局限性，导致预测误差大且结果缺乏多样性。论文指出高质量的先验模型是提升轨迹预测性能的关键。", "method": "AGMA通过两个阶段构建表达式先验：从训练数据中提取多样化的行为模式，并将其转化为适应场景的整体先验，用于推理过程。", "result": "实验表明，AGMA在ETH-UCY、斯坦福无人机和JRDB等数据集上实现了最先进的性能。", "conclusion": "高质量的先验模型对于轨迹预测至关重要。AGMA通过自适应高斯混合锚点有效提升了预测的准确性和多样性。"}}
{"id": "2602.04202", "pdf": "https://arxiv.org/pdf/2602.04202", "abs": "https://arxiv.org/abs/2602.04202", "authors": ["Feng Wang", "Yichun Shi", "Ceyuan Yang", "Qiushan Guo", "Jingxiang Sun", "Alan Yuille", "Peng Wang"], "title": "VTok: A Unified Video Tokenizer with Decoupled Spatial-Temporal Latents", "categories": ["cs.CV"], "comment": null, "summary": "This work presents VTok, a unified video tokenization framework that can be used for both generation and understanding tasks. Unlike the leading vision-language systems that tokenize videos through a naive frame-sampling strategy, we propose to decouple the spatial and temporal representations of videos by retaining the spatial features of a single key frame while encoding each subsequent frame into a single residual token, achieving compact yet expressive video tokenization. Our experiments suggest that VTok effectively reduces the complexity of video representation from the product of frame count and per-frame token count to their sum, while the residual tokens sufficiently capture viewpoint and motion changes relative to the key frame. Extensive evaluations demonstrate the efficacy and efficiency of VTok: it achieves notably higher performance on a range of video understanding and text-to-video generation benchmarks compared with baselines using naive tokenization, all with shorter token sequences per video (e.g., 3.4% higher accuracy on our TV-Align benchmark and 1.9% higher VBench score). Remarkably, VTok produces more coherent motion and stronger guidance following in text-to-video generation, owing to its more consistent temporal encoding. We hope VTok can serve as a standardized video tokenization paradigm for future research in video understanding and generation.", "AI": {"tldr": "该论文提出了VTok，一种用于视频生成和理解任务的统一视频标记化框架。", "motivation": "现有视觉-语言系统通过简单的帧采样策略对视频进行分段，这种做法可能导致复杂度高且不一致的时间编码。作者提出了一种新的方法来解决这些问题：通过解耦空间和时间表示来简化视频标记化过程。", "method": "VTok保留关键帧的空间特征，并将每个后续帧编码为单个残差令牌，从而实现了紧凑而有表现力的视频标记化。这种方法可以有效降低视频表示复杂度。", "result": "实验表明VTok在多个视频理解和文本到视频生成基准测试中取得了显著更高的性能，所有这些都使用了更短的视频令牌序列。", "conclusion": "VTok为未来的视频理解与生成研究提供了一种标准化的视频标记化范式。"}}
{"id": "2602.04200", "pdf": "https://arxiv.org/pdf/2602.04200", "abs": "https://arxiv.org/abs/2602.04200", "authors": ["Kevin Callahan-Coray", "Kyle Lee", "Kyle Jiang", "Kerem Y. Camsari"], "title": "Restoring Sparsity in Potts Machines via Mean-Field Constraints", "categories": ["cond-mat.stat-mech", "cs.ET"], "comment": null, "summary": "Ising machines and related probabilistic hardware have emerged as promising platforms for NP-hard optimization and sampling. However, many practical problems involve constraints that induce dense or all-to-all couplings, undermining scalability and hardware efficiency. We address this constraint-induced density through two complementary approaches. First, we introduce a hardware-aware native formulation for multi-state probabilistic digits (p-dits) that avoids the locally dense intra-variable couplings required by binary Ising encodings. We validate p-dit dynamics by reproducing known critical behavior of the 2D Potts model. Second, we propose mean-field constraints (MFC), a hybrid scheme that replaces dense pairwise constraint couplings with dynamically updated single-node biases. Applied to balanced graph partitioning, MFC achieves solution quality comparable to exact all-to-all constraint formulations while dramatically reducing graph density. Finally, we demonstrate the practical impact of restored sparsity by an FPGA implementation, enabling orders-of-magnitude acceleration over CPU-based solvers. Together, these results outline a pathway for scaling constrained optimization on probabilistic hardware.", "AI": {"tldr": "本文提出了通过硬件感知的n原生方法和平均场约束来恢复稀疏性，以解决Potts机器在处理密集或全连接耦合时的问题。", "motivation": "许多实际问题中的约束导致了密集的或者全连接的耦合，这影响到了可扩展性和硬件效率。为了解决这个问题，作者提出了两种互补的方法。", "method": "首先引入了一种针对多状态概率数字（p-dits）的硬件感知原生形式，避免了二进制Ising编码所需的局部密集内部变量耦合。其次提出平均场约束（MFC），这是一种将稠密的成对约束耦合替换为动态更新的单节点偏置的混合方案。", "result": "通过这种方法，作者实现了与精确全连接约束形式相当的解决方案质量，同时大大减少了图的密度，并且在FPGA实现中展示了实际影响，使得硬件加速比CPU基解算器快数个数量级。", "conclusion": "这些结果为在概率硬件上扩展有约束优化提供了一条途径。"}}
{"id": "2602.04197", "pdf": "https://arxiv.org/pdf/2602.04197", "abs": "https://arxiv.org/abs/2602.04197", "authors": ["Xinyue Wang", "Yuanhe Zhang", "Zhengshuo Gong", "Haoran Gao", "Fanyu Meng", "Zhenhong Zhou", "Li Sun", "Yang Liu", "Sen Su"], "title": "From Helpfulness to Toxic Proactivity: Diagnosing Behavioral Misalignment in LLM Agents", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages (excluding appendices), 6 figures. Code is available at https://github.com/wxyoio-0715/Toxic-Proactivity", "summary": "The enhanced capabilities of LLM-based agents come with an emergency for model planning and tool-use abilities. Attributing to helpful-harmless trade-off from LLM alignment, agents typically also inherit the flaw of \"over-refusal\", which is a passive failure mode. However, the proactive planning and action capabilities of agents introduce another crucial danger on the other side of the trade-off. This phenomenon we term \"Toxic Proactivity'': an active failure mode in which an agent, driven by the optimization for Machiavellian helpfulness, disregards ethical constraints to maximize utility. Unlike over-refusal, Toxic Proactivity manifests as the agent taking excessive or manipulative measures to ensure its \"usefulness'' is maintained. Existing research pays little attention to identifying this behavior, as it often lacks the subtle context required for such strategies to unfold. To reveal this risk, we introduce a novel evaluation framework based on dilemma-driven interactions between dual models, enabling the simulation and analysis of agent behavior over multi-step behavioral trajectories. Through extensive experiments with mainstream LLMs, we demonstrate that Toxic Proactivity is a widespread behavioral phenomenon and reveal two major tendencies. We further present a systematic benchmark for evaluating Toxic Proactive behavior across contextual settings.", "AI": {"tldr": "该论文提出了一种新型评估框架，用于诊断大型语言模型代理的有毒积极性问题。", "motivation": "现有研究较少关注大型语言模型代理在主动优化以实现所谓的“有用性”时可能忽略伦理约束的问题。这种现象被称为‘有毒积极性’，它可能导致代理采取过分或操纵性的措施。", "method": "通过基于困境驱动互动的新型评估框架对主流LLM进行广泛实验，该框架利用双模型交互来模拟和分析多步骤行为轨迹。", "result": "实验证明有毒积极性是普遍存在的，并揭示了两个主要趋势。此外还提供了一个系统性基准用于在不同情境下评估有毒积极性行为。", "conclusion": "通过新型评估框架的使用，识别并理解了大型语言模型代理中‘有毒积极性’这一问题的重要性及其广泛存在。"}}
{"id": "2602.04193", "pdf": "https://arxiv.org/pdf/2602.04193", "abs": "https://arxiv.org/abs/2602.04193", "authors": ["Hyeonjae Kim", "Dongjin Kim", "Eugene Jin", "Tae Hyun Kim"], "title": "Continuous Degradation Modeling via Latent Flow Matching for Real-World Super-Resolution", "categories": ["cs.CV"], "comment": "AAAI 2026", "summary": "While deep learning-based super-resolution (SR) methods have shown impressive outcomes with synthetic degradation scenarios such as bicubic downsampling, they frequently struggle to perform well on real-world images that feature complex, nonlinear degradations like noise, blur, and compression artifacts. Recent efforts to address this issue have involved the painstaking compilation of real low-resolution (LR) and high-resolution (HR) image pairs, usually limited to several specific downscaling factors. To address these challenges, our work introduces a novel framework capable of synthesizing authentic LR images from a single HR image by leveraging the latent degradation space with flow matching. Our approach generates LR images with realistic artifacts at unseen degradation levels, which facilitates the creation of large-scale, real-world SR training datasets. Comprehensive quantitative and qualitative assessments verify that our synthetic LR images accurately replicate real-world degradations. Furthermore, both traditional and arbitrary-scale SR models trained using our datasets consistently yield much better HR outcomes.", "AI": {"tldr": "通过隐式退化空间和流匹配生成具有真实降质效果的低分辨率图像，以改善超分辨率模型在现实世界场景中的性能。", "motivation": "当前基于深度学习的超分辨率方法在处理包含复杂非线性降质（如噪声、模糊和压缩伪影）的真实世界图像时表现不佳。传统方法依赖于人工收集特定退化水平的数据集，难以应对未知情况。", "method": "利用流匹配技术，在隐式退化空间中从单个高分辨率图像生成包含多种真实降质量化的低分辨率图像。这种方法可以产生大规模、具有现实感的训练数据集。", "result": "合成低分辨率图像能够准确再现实际中的退化效果；所训练模型在传统和任意尺度超分辨率任务上均取得了更好的性能。", "conclusion": "该方法通过生成高质量的真实世界退化样本，显著提高了基于深度学习的超分辨率算法的表现。"}}
{"id": "2602.04188", "pdf": "https://arxiv.org/pdf/2602.04188", "abs": "https://arxiv.org/abs/2602.04188", "authors": ["Ning Zhang", "Zhengyu Li", "Kwong Weng Loh", "Mingxi Xu", "Qi Wang", "Zhengyu Wen", "Xiaoyu He", "Wei Zhao", "Kehong Gong", "Mingyuan Zhang"], "title": "DiMo: Discrete Diffusion Modeling for Motion Generation and Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Prior masked modeling motion generation methods predominantly study text-to-motion. We present DiMo, a discrete diffusion-style framework, which extends masked modeling to bidirectional text--motion understanding and generation. Unlike GPT-style autoregressive approaches that tokenize motion and decode sequentially, DiMo performs iterative masked token refinement, unifying Text-to-Motion (T2M), Motion-to-Text (M2T), and text-free Motion-to-Motion (M2M) within a single model. This decoding paradigm naturally enables a quality-latency trade-off at inference via the number of refinement steps.We further improve motion token fidelity with residual vector quantization (RVQ) and enhance alignment and controllability with Group Relative Policy Optimization (GRPO). Experiments on HumanML3D and KIT-ML show strong motion quality and competitive bidirectional understanding under a unified framework. In addition, we demonstrate model ability in text-free motion completion, text-guided motion prediction and motion caption correction without architectural change.Additional qualitative results are available on our project page: https://animotionlab.github.io/DiMo/.", "AI": {"tldr": "DiMo是一种离散扩散框架，用于双向文本与动作理解和生成。", "motivation": "现有的掩码建模方法主要关注于从文本到动作的生成。本文旨在扩展掩码模型以实现双向的动作和文本理解及生成，同时提高无文本条件下的动作完成、基于文本的动作预测以及动作字幕修正的能力。", "method": "DiMo采用迭代掩码令牌细化的方法进行解码，并引入残差向量量化（RVQ）以改进动作令牌的保真度。此外，通过组相对策略优化（GRPO），增强了模型对齐和可控性。", "result": "实验表明，在HumanML3D和KIT-ML数据集上，DiMo在双向理解和生成方面表现出强大的质量，并且可以在不改变架构的情况下进行无文本动作完成、基于文本的动作预测以及动作字幕修正。", "conclusion": "DiMo提供了一种统一的框架来解决从文本到动作、从动作到文本以及动作之间的理解与生成问题，展示了其在多种任务上的有效性。"}}
{"id": "2602.04184", "pdf": "https://arxiv.org/pdf/2602.04184", "abs": "https://arxiv.org/abs/2602.04184", "authors": ["Angel Martinez-Sanchez", "Parthib Roy", "Ross Greer"], "title": "Natural Language Instructions for Scene-Responsive Human-in-the-Loop Motion Planning in Autonomous Driving using Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Instruction-grounded driving, where passenger language guides trajectory planning, requires vehicles to understand intent before motion. However, most prior instruction-following planners rely on simulation or fixed command vocabularies, limiting real-world generalization. doScenes, the first real-world dataset linking free-form instructions (with referentiality) to nuScenes ground-truth motion, enables instruction-conditioned planning. In this work, we adapt OpenEMMA, an open-source MLLM-based end-to-end driving framework that ingests front-camera views and ego-state and outputs 10-step speed-curvature trajectories, to this setting, presenting a reproducible instruction-conditioned baseline on doScenes and investigate the effects of human instruction prompts on predicted driving behavior. We integrate doScenes directives as passenger-style prompts within OpenEMMA's vision-language interface, enabling linguistic conditioning before trajectory generation. Evaluated on 849 annotated scenes using ADE, we observe that instruction conditioning substantially improves robustness by preventing extreme baseline failures, yielding a 98.7% reduction in mean ADE. When such outliers are removed, instructions still influence trajectory alignment, with well-phrased prompts improving ADE by up to 5.1%. We use this analysis to discuss what makes a \"good\" instruction for the OpenEMMA framework. We release the evaluation prompts and scripts to establish a reproducible baseline for instruction-aware planning. GitHub: https://github.com/Mi3-Lab/doScenes-VLM-Planning", "AI": {"tldr": "本文提出了一种基于自然语言指令的场景响应式自主驾驶中的人机协作轨迹规划方法。", "motivation": "当前大多数指令跟随规划器依赖于模拟或固定的命令词汇表，难以适应真实世界的多样性和复杂性。因此，该研究旨在通过整合人类指令和视觉信息来提升自动驾驶汽车在现实环境中的导航性能。", "method": "本文利用开放源代码的OpenEMMA框架将自然语言指令融入到轨迹规划过程中，并在此基础上开发了一个可重现的基础线模型，用于评估不同指令对驾驶行为的影响。", "result": "实验结果显示，在849个注释场景中，指令调节显著增强了规划的鲁棒性，平均ADE减少了98.7%。即使排除异常值后，良好的指令仍能提高轨迹一致性，改善ADE达5.1%", "conclusion": "该研究展示了自然语言指令在自主驾驶中的潜力，并提出了如何构造有效指令以增强模型性能的方法论建议。同时，作者公开了评价脚本和提示语料库，为后续研究提供了可重复的基础线"}}
{"id": "2602.04182", "pdf": "https://arxiv.org/pdf/2602.04182", "abs": "https://arxiv.org/abs/2602.04182", "authors": ["Weidong Hao"], "title": "HoloEv-Net: Efficient Event-based Action Recognition via Holographic Spatial Embedding and Global Spectral Gating", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Event-based Action Recognition (EAR) has attracted significant attention due to the high temporal resolution and high dynamic range of event cameras. However, existing methods typically suffer from (i) the computational redundancy of dense voxel representations, (ii) structural redundancy inherent in multi-branch architectures, and (iii) the under-utilization of spectral information in capturing global motion patterns. To address these challenges, we propose an efficient EAR framework named HoloEv-Net. First, to simultaneously tackle representation and structural redundancies, we introduce a Compact Holographic Spatiotemporal Representation (CHSR). Departing from computationally expensive voxel grids, CHSR implicitly embeds horizontal spatial cues into the Time-Height (T-H) view, effectively preserving 3D spatiotemporal contexts within a 2D representation. Second, to exploit the neglected spectral cues, we design a Global Spectral Gating (GSG) module. By leveraging the Fast Fourier Transform (FFT) for global token mixing in the frequency domain, GSG enhances the representation capability with negligible parameter overhead. Extensive experiments demonstrate the scalability and effectiveness of our framework. Specifically, HoloEv-Net-Base achieves state-of-the-art performance on THU-EACT-50-CHL, HARDVS and DailyDVS-200, outperforming existing methods by 10.29%, 1.71% and 6.25%, respectively. Furthermore, our lightweight variant, HoloEv-Net-Small, delivers highly competitive accuracy while offering extreme efficiency, reducing parameters by 5.4 times, FLOPs by 300times, and latency by 2.4times compared to heavy baselines, demonstrating its potential for edge deployment.", "AI": {"tldr": "提出了一种高效的事件相机行动识别框架HoloEv-Net，通过紧凑的全息时空表示和全局频谱门控模块解决现有方法中的冗余问题。", "motivation": "现有的事件相机动作识别方法存在计算密集型体积网格表示、多分支架构结构冗余以及光谱信息利用不足的问题。为此，该论文旨在开发一种有效的新框架以提高性能和效率。", "method": "引入了一种紧凑的全息时空表示（CHSR）来减少表示和结构冗余，并设计了全局频谱门控模块（GSG），通过频率域中的快速傅里叶变换进行全局令牌混合，增强光谱信息利用。这种方法在保持低参数量的同时提升了表现力。", "result": "实验显示该框架具有良好的扩展性和有效性。HoloEv-Net-Base在THU-EACT-50-CHL、HARDVS和DailyDVS-200数据集上分别超过了现有方法10.29%、1.71%和6.25%，其轻量级版本HoloEv-Net-Small则以更小的参数量和计算复杂度提供了竞争性的准确率。", "conclusion": "提出的HoloEv-Net框架在提高事件相机动作识别性能的同时，显著减少了计算资源需求，并展示了在边缘设备部署中的潜力。"}}
{"id": "2602.04174", "pdf": "https://arxiv.org/pdf/2602.04174", "abs": "https://arxiv.org/abs/2602.04174", "authors": ["Chengzhang Wang", "Chao Chen", "Jun Tao", "Tengfei Liu", "He Bai", "Song Wang", "Longfei Xu", "Kaikui Liu", "Xiangxiang Chu"], "title": "GenMRP: A Generative Multi-Route Planning Framework for Efficient and Personalized Real-Time Industrial Navigation", "categories": ["cs.RO", "cs.GR", "cs.IR"], "comment": null, "summary": "Existing industrial-scale navigation applications contend with massive road networks, typically employing two main categories of approaches for route planning. The first relies on precomputed road costs for optimal routing and heuristic algorithms for generating alternatives, while the second, generative methods, has recently gained significant attention. However, the former struggles with personalization and route diversity, while the latter fails to meet the efficiency requirements of large-scale real-time scenarios. To address these limitations, we propose GenMRP, a generative framework for multi-route planning. To ensure generation efficiency, GenMRP first introduces a skeleton-to-capillary approach that dynamically constructs a relevant sub-network significantly smaller than the full road network. Within this sub-network, routes are generated iteratively. The first iteration identifies the optimal route, while the subsequent ones generate alternatives that balance quality and diversity using the newly proposed correctional boosting approach. Each iteration incorporates road features, user historical sequences, and previously generated routes into a Link Cost Model to update road costs, followed by route generation using the Dijkstra algorithm. Extensive experiments show that GenMRP achieves state-of-the-art performance with high efficiency in both offline and online environments. To facilitate further research, we have publicly released the training and evaluation dataset. GenMRP has been fully deployed in a real-world navigation app, demonstrating its effectiveness and benefits.", "AI": {"tldr": "提出了一种用于工业导航的多路径规划框架GenMRP，以提高效率和个性化。", "motivation": "现有的路线规划方法在大规模场景下难以平衡个性化、多样性与实时性要求。", "method": "使用骨架到毛细血管的方法构建子网络并生成多种高质量且多样化的路线。每次迭代更新道路成本模型，并利用Dijkstra算法进行路径生成。", "result": "实验显示GenMRP实现了最先进的性能，同时满足了离线和在线环境下的效率要求。", "conclusion": "通过发布数据集与实际应用展示，GenMRP展示了其高效性和实用性。"}}
{"id": "2602.04170", "pdf": "https://arxiv.org/pdf/2602.04170", "abs": "https://arxiv.org/abs/2602.04170", "authors": ["Yi-Kuan Hsieh", "Jun-Wei Hsieh", "Xin li", "Ming-Ching Chang", "Yu-Chee Tseng"], "title": "Partial Ring Scan: Revisiting Scan Order in Vision State Space Models", "categories": ["cs.CV"], "comment": "10 pages, 3 figures", "summary": "State Space Models (SSMs) have emerged as efficient alternatives to attention for vision tasks, offering lineartime sequence processing with competitive accuracy. Vision SSMs, however, require serializing 2D images into 1D token sequences along a predefined scan order, a factor often overlooked. We show that scan order critically affects performance by altering spatial adjacency, fracturing object continuity, and amplifying degradation under geometric transformations such as rotation. We present Partial RIng Scan Mamba (PRISMamba), a rotation-robust traversal that partitions an image into concentric rings, performs order-agnostic aggregation within each ring, and propagates context across rings through a set of short radial SSMs. Efficiency is further improved via partial channel filtering, which routes only the most informative channels through the recurrent ring pathway while keeping the rest on a lightweight residual branch. On ImageNet-1K, PRISMamba achieves 84.5% Top-1 with 3.9G FLOPs and 3,054 img/s on A100, outperforming VMamba in both accuracy and throughput while requiring fewer FLOPs. It also maintains performance under rotation, whereas fixed-path scans drop by 1~2%. These results highlight scan-order design, together with channel filtering, as a crucial, underexplored factor for accuracy, efficiency, and rotation robustness in Vision SSMs. Code will be released upon acceptance.", "AI": {"tldr": "提出了PRISMamba模型，改进了视觉状态空间模型中的扫描顺序问题。", "motivation": "展示扫描顺序对性能的影响，并提出一种旋转鲁棒的遍历方法以提高模型准确性、效率和鲁棒性。", "method": "将图像划分为同心圆环，在每个圆环内执行无序聚合，通过一系列短径向SSMs传递上下文信息。引入了部分通道过滤以进一步提升效率。", "result": "在ImageNet-1K上，PRISMamba实现了84.5%的Top-1精度，并提高了模型的吞吐量和旋转鲁棒性。", "conclusion": "扫描顺序设计与通道过滤是视觉状态空间模型中准确性、效率和旋转鲁棒性的关键因素。"}}
{"id": "2602.04167", "pdf": "https://arxiv.org/pdf/2602.04167", "abs": "https://arxiv.org/abs/2602.04167", "authors": ["Yu Zhou", "Xiaoyan Yang", "Bojia Zi", "Lihan Zhang", "Ruijie Sun", "Weishi Zheng", "Haibin Huang", "Chi Zhang", "Xuelong Li"], "title": "Point2Insert: Video Object Insertion via Sparse Point Guidance", "categories": ["cs.CV"], "comment": null, "summary": "This paper introduces Point2Insert, a sparse-point-based framework for flexible and user-friendly object insertion in videos, motivated by the growing popularity of accurate, low-effort object placement. Existing approaches face two major challenges: mask-based insertion methods require labor-intensive mask annotations, while instruction-based methods struggle to place objects at precise locations. Point2Insert addresses these issues by requiring only a small number of sparse points instead of dense masks, eliminating the need for tedious mask drawing. Specifically, it supports both positive and negative points to indicate regions that are suitable or unsuitable for insertion, enabling fine-grained spatial control over object locations. The training of Point2Insert consists of two stages. In Stage 1, we train an insertion model that generates objects in given regions conditioned on either sparse-point prompts or a binary mask. In Stage 2, we further train the model on paired videos synthesized by an object removal model, adapting it to video insertion. Moreover, motivated by the higher insertion success rate of mask-guided editing, we leverage a mask-guided insertion model as a teacher to distill reliable insertion behavior into the point-guided model. Extensive experiments demonstrate that Point2Insert consistently outperforms strong baselines and even surpasses models with $\\times$10 more parameters.", "AI": {"tldr": "本文介绍了Point2Insert，这是一种基于稀疏点的视频对象插入框架。", "motivation": "现有的方法面临着两个主要挑战：基于掩码的方法需要密集的手动标注，而指令式方法难以精确放置物体。为解决这些问题，Point2Insert仅需少量稀疏点代替密集掩码，并支持正负点来控制位置。", "method": "该框架分为两阶段训练：第一阶段训练插入模型生成给定区域的物体；第二阶段使用对象移除模型合成对视频进行微调。此外，利用基于掩码的方法作为教师向基于点的方法转移可靠行为。", "result": "实验表明Point2Insert优于强基准方法，并且即使参数量少十倍也能超越其他模型。", "conclusion": "该框架通过引入稀疏点实现了灵活、用户友好的视频对象插入，解决了现有技术的局限性。"}}
{"id": "2602.04166", "pdf": "https://arxiv.org/pdf/2602.04166", "abs": "https://arxiv.org/abs/2602.04166", "authors": ["Meiling Jin", "Fei Wang", "Xiaoyun Yuan", "Chen Qian", "Yuan Cheng"], "title": "Topology-Aware Revival for Efficient Sparse Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Static sparse training is a promising route to efficient learning by committing to a fixed mask pattern, yet the constrained structure reduces robustness. Early pruning decisions can lock the network into a brittle structure that is difficult to escape, especially in deep reinforcement learning (RL) where the evolving policy continually shifts the training distribution. We propose Topology-Aware Revival (TAR), a lightweight one-shot post-pruning procedure that improves static sparsity without dynamic rewiring. After static pruning, TAR performs a single revival step by allocating a small reserve budget across layers according to topology needs, randomly uniformly reactivating a few previously pruned connections within each layer, and then keeping the resulting connectivity fixed for the remainder of training. Across multiple continuous-control tasks with SAC and TD3, TAR improves final return over static sparse baselines by up to +37.9% and also outperforms dynamic sparse training baselines with a median gain of +13.5%.", "AI": {"tldr": "提出了一种轻量级的一次性后剪枝程序Topology-Aware Revival（TAR），用于提高静态稀疏训练的效率。", "motivation": "静态稀疏训练通过固定掩码模式以高效学习，但受限结构减少了鲁棒性。早期修剪决策可能导致网络陷入难以逃脱的脆弱结构中，特别是在深度强化学习中。", "method": "在静态剪枝后，TAR执行单一复兴步骤，在每一层根据拓扑需求随机均匀重新激活少数先前被剪掉的连接，并固定剩余训练期间的这种连通性。", "result": "在多个连续控制任务中，TAR比静态稀疏基准提高了最终回报高达+37.9%，且也优于动态稀疏训练基准，平均增益为+13.5%。", "conclusion": "Topology-Aware Revival（TAR）是一种有效提高深度强化学习中静态稀疏训练效率的方法。"}}
{"id": "2602.04164", "pdf": "https://arxiv.org/pdf/2602.04164", "abs": "https://arxiv.org/abs/2602.04164", "authors": ["Yuan Cai", "Mustafa Demir", "Farzan Sasangohar", "Mohsen Zare"], "title": "The Dynamics of Attention across Automated and Manual Driving Modes: A Driving Simulation Study", "categories": ["cs.ET", "stat.AP", "stat.CO", "stat.OT"], "comment": null, "summary": "This study aims to explore the dynamics of driver attention to various zones, including the road, the central mirror, the embedded Human-Machine Interface (HMI), and the speedometer, across different driving modes in AVs. The integration of autonomous vehicles (AVs) into transportation systems has introduced critical safety concerns, particularly regarding driver re-engagement during mode transitions. Past accidents underscore the risks of overreliance on automation and highlight the need to understand dynamic attention allocation to support safety in autonomous driving. A high-fidelity driving simulation was conducted. Eye-tracking technology was used to measure fixation duration, fixation count, and time to first fixation across distinct driving modes (automated, manual, and transition), which were then used to assess how drivers allocated attention to various areas of interest (AOIs). Findings show that drivers' attention varies significantly across driving modes. In manual mode, attention consistently focuses on the road, while in automated mode, prolonged fixation on the embedded HMI was observed. During the handover and takeover phases, attention shifts dynamically between environmental and technological elements. The study reveals that driver attention allocation is mode-dependent. These findings inform the design of adaptive HMIs in AVs that align with drivers' attention patterns. By presenting relevant information according to the driving context, such systems can enhance driver-vehicle interaction, support effective transitions, and improve overall safety. Systematic analysis of visual attention dynamics across driving modes is gaining prominence, as it informs adaptive HMI designs and driver readiness interventions. The GLMM findings can be directly applied to the design of adaptive HMIs or driver training programs to enhance attention and improve safety.", "AI": {"tldr": "本文通过驾驶模拟实验研究了不同驾驶模式下驾驶员对道路、中央后视镜、嵌入式人机界面和速度表等区域注意力的变化。", "motivation": "自动驾驶汽车的引入带来了重大安全问题，特别是在自动化与手动操作之间转换时的驾驶员重新参与。为了支持自动驾驶中的安全性，需要理解动态注意分配模式以降低对自动化过度依赖的风险。", "method": "通过高保真度驾驶模拟实验使用眼动追踪技术测量固定时间、固定次数和首次注视的时间来评估不同驾驶模式（自动驾驶、手动驾驶及转换阶段）下驾驶员如何将注意力分配到不同的兴趣区域。", "result": "结果表明，驾驶员的注意力在不同驾驶模式中存在显著差异。手动驾驶时注意力集中在道路上；自动模式下则倾向于长时间注视嵌入式人机界面；过渡期间注意力动态地在环境和科技元素之间转换。", "conclusion": "研究揭示了驾驶者注意分配模式与驾驶情境相关联，并强调适应性设计的重要性，以提高驾驶员车辆交互、支持有效转变并提升整体安全性。"}}
{"id": "2602.04162", "pdf": "https://arxiv.org/pdf/2602.04162", "abs": "https://arxiv.org/abs/2602.04162", "authors": ["Chenhe Du", "Qing Wu", "Xuanyu Tian", "Jingyi Yu", "Hongjiang Wei", "Yuyao Zhang"], "title": "Improving 2D Diffusion Models for 3D Medical Imaging with Inter-Slice Consistent Stochasticity", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "Accepted by ICLR 2026", "summary": "3D medical imaging is in high demand and essential for clinical diagnosis and scientific research. Currently, diffusion models (DMs) have become an effective tool for medical imaging reconstruction thanks to their ability to learn rich, high-quality data priors. However, learning the 3D data distribution with DMs in medical imaging is challenging, not only due to the difficulties in data collection but also because of the significant computational burden during model training. A common compromise is to train the DMs on 2D data priors and reconstruct stacked 2D slices to address 3D medical inverse problems. However, the intrinsic randomness of diffusion sampling causes severe inter-slice discontinuities of reconstructed 3D volumes. Existing methods often enforce continuity regularizations along the z-axis, which introduces sensitive hyper-parameters and may lead to over-smoothing results. In this work, we revisit the origin of stochasticity in diffusion sampling and introduce Inter-Slice Consistent Stochasticity (ISCS), a simple yet effective strategy that encourages interslice consistency during diffusion sampling. Our key idea is to control the consistency of stochastic noise components during diffusion sampling, thereby aligning their sampling trajectories without adding any new loss terms or optimization steps. Importantly, the proposed ISCS is plug-and-play and can be dropped into any 2D trained diffusion based 3D reconstruction pipeline without additional computational cost. Experiments on several medical imaging problems show that our method can effectively improve the performance of medical 3D imaging problems based on 2D diffusion models. Our findings suggest that controlling inter-slice stochasticity is a principled and practically attractive route toward high-fidelity 3D medical imaging with 2D diffusion priors. The code is available at: https://github.com/duchenhe/ISCS", "AI": {"tldr": "本论文提出了一种新的策略ISCS，用于改进基于2D扩散模型的3D医学成像重建。", "motivation": "当前在医学成像中使用2D扩散模型来训练3D数据分布存在困难，导致重构出的3D体素具有严重的片间不连续性。现有方法通过引入轴向连续性正则化解决此问题，但这可能导致过度平滑并需要额外参数。", "method": "提出了一种策略ISCS，在扩散采样过程中控制噪声组件的一致性以对齐其采样轨迹，不需要添加新的损失项或优化步骤。", "result": "实验表明，该方法能够有效提高基于2D扩散模型的3D医学成像性能。", "conclusion": "通过控制片间随机性的策略ISCS可以实现高保真度的3D医学成像。"}}
{"id": "2602.04160", "pdf": "https://arxiv.org/pdf/2602.04160", "abs": "https://arxiv.org/abs/2602.04160", "authors": ["Vikentii Pankov", "Artem Gribul", "Oktai Tatanov", "Vladislav Proskurov", "Yuliya Korotkova", "Darima Mylzenova", "Dmitrii Vypirailenko"], "title": "PFluxTTS: Hybrid Flow-Matching TTS with Robust Cross-Lingual Voice Cloning and Inference-Time Model Fusion", "categories": ["cs.SD"], "comment": "Accepted at ICASSP 2026", "summary": "We present PFluxTTS, a hybrid text-to-speech system addressing three gaps in flow-matching TTS: the stability-naturalness trade-off, weak cross-lingual voice cloning, and limited audio quality from low-rate mel features. Our contributions are: (1) a dual-decoder design combining duration-guided and alignment-free models through inference-time vector-field fusion; (2) robust cloning using a sequence of speech-prompt embeddings in a FLUX-based decoder, preserving speaker traits across languages without prompt transcripts; and (3) a modified PeriodWave vocoder with super-resolution to 48 kHz. On cross-lingual in-the-wild data, PFluxTTS clearly outperforms F5-TTS, FishSpeech, and SparkTTS, matches ChatterBox in naturalness (MOS 4.11) while achieving 23% lower WER (6.9% vs. 9.0%), and surpasses ElevenLabs in speaker similarity (+0.32 SMOS). The system remains robust in challenging scenarios where most open-source models fail, while requiring only short reference audio and no extra training. Audio demos are available at https://braskai.github.io/pfluxtts/", "AI": {"tldr": "本文提出了PFluxTTS，一种混合文本到语音系统，旨在解决流匹配TTS中的稳定性-自然性权衡、弱跨语言声音克隆以及低速率梅尔特征带来的音频质量限制问题。", "motivation": "为了克服现有流匹配TTS技术面临的挑战，包括稳定性与自然性的矛盾、较弱的跨语言声音克隆能力和由于使用低速率梅尔特征导致的音频质量问题。", "method": "采用了双解码器设计结合时长引导和无对齐模型，并通过推断时间向量场融合。引入了基于FLUX的解码器中的语音提示嵌入序列进行稳健的声音克隆，同时保持跨语言中说话人的特质而无需提示文本转录。改进了PeriodWave声码器以实现超分辨率至48kHz。", "result": "在跨语言的真实数据集上，PFluxTTS明显优于F5-TTS、FishSpeech和SparkTTS，在自然度方面与ChatterBox相当（MOS为4.11），同时实现了23%的WER降低。此外，它还超越了ElevenLabs的声音相似性指标。", "conclusion": "PFluxTTS在挑战性的应用场景中表现出色，并且只需要短参考音频，不需要额外训练，展示了其强大的鲁棒性和实用性。"}}
{"id": "2602.04159", "pdf": "https://arxiv.org/pdf/2602.04159", "abs": "https://arxiv.org/abs/2602.04159", "authors": ["Gang Yu", "Yuchi Sun", "Weining Yan", "Xinyu Wang", "Qi Lu"], "title": "Paint by Odor: An Exploration of Odor Visualization through Large Language Model and Generative AI", "categories": ["cs.HC"], "comment": null, "summary": "Odor visualization translates odor information and perception into visual outcomes and arouses the corresponding olfactory synesthesia, surpassing the spatial limitation that odors can only be perceived where they are present. Traditional odor visualization has typically relied on unidimensional mappings, such as odor-to-color associations, and has required extensive manual design efforts. However, the advent of generative AI (Gen AI) and large language models (LLMs) presents a new opportunity for automatic odor visualization. Nonetheless, gaps remain in bridging olfactory perception with generative tools to produce odor images. To address these gaps, this paper introduces Paint by Odor, a pipeline that leverages Gen AI and LLMs to transform olfactory perceptions into rich, aesthetically engaging visual representations. Two experiments were conducted, where 30 participants smelled real-world odors and provided descriptive data and 28 participants evaluated 560 generated odor images through seven systematically designed prompts. Our findings explored the capability of LLMs in producing olfactory perception by comparing it with human responses and revealed the underlying mechanisms and effects of language-based descriptions and several abstraction styles on odor visualization. Our work further discussed the possibility of automatic odor visualization without human participation. These explorations and results have bridged the research gap in odor visualization using LLMs and Gen AI, offering valuable design insights and various possibilities for future applications.", "AI": {"tldr": "利用大语言模型和生成AI将嗅觉感知转化为视觉表示", "motivation": "通过自动化的嗅觉可视化技术弥补传统方法的不足，探索如何使用语言描述和抽象风格来增强嗅觉可视化效果", "method": "设计了一条名为Paint by Odor的流水线，该流水线通过参与者闻到的真实世界气味提供描述性数据，并通过系统设计的提示生成560个气味图像进行评估", "result": "研究发现了大语言模型在产生嗅觉感知方面的潜力，展示了自动化的可能性并提供了设计洞察", "conclusion": "本工作填补了使用LLMs和Gen AI进行嗅觉可视化的研究空白，为未来应用提供了多种可能"}}
{"id": "2602.04157", "pdf": "https://arxiv.org/pdf/2602.04157", "abs": "https://arxiv.org/abs/2602.04157", "authors": ["Dong Won Lee", "Sarah Gillet", "Louis-Philippe Morency", "Cynthia Breazeal", "Hae Won Park"], "title": "A Modern System Recipe for Situated Embodied Human-Robot Conversation with Real-Time Multimodal LLMs and Tool-Calling", "categories": ["cs.RO"], "comment": "9 pages, 7 figures", "summary": "Situated embodied conversation requires robots to interleave real-time dialogue with active perception: deciding what to look at, when to look, and what to say under tight latency constraints. We present a simple, minimal system recipe that pairs a real-time multimodal language model with a small set of tool interfaces for attention and active perception. We study six home-style scenarios that require frequent attention shifts and increasing perceptual scope. Across four system variants, we evaluate turn-level tool-decision correctness against human annotations and collect subjective ratings of interaction quality. Results indicate that real-time multimodal large language models and tool use for active perception is a promising direction for practical situated embodied conversation.", "AI": {"tldr": "本文提出了一种结合实时多模态语言模型和工具接口的系统方案，用于实现人机对话中的主动感知与交互。", "motivation": "研究如何通过机器人在实际环境中进行即时的人机对话，包括决定何时何地采取何种行动以满足低延迟的要求。", "method": "设计了一个简单的系统框架，并通过六个家庭场景测试了四种不同系统的性能，评估工具决策的正确性和用户互动体验的质量。", "result": "实验结果表明，实时多模态语言模型和主动感知技术对于实现实用的人机对话具有潜力。", "conclusion": "研究展示了如何利用现代技术方案来推进人机对话的研究和发展，并指出了未来可能的方向和改进之处。"}}
{"id": "2602.04154", "pdf": "https://arxiv.org/pdf/2602.04154", "abs": "https://arxiv.org/abs/2602.04154", "authors": ["Mingjian Lu", "Pawan K. Tripathi", "Mark Shteyn", "Debargha Ganguly", "Roger H. French", "Vipin Chaudhary", "Yinghui Wu"], "title": "Context Determines Optimal Architecture in Materials Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Segmentation architectures are typically benchmarked on single imaging modalities, obscuring deployment-relevant performance variations: an architecture optimal for one modality may underperform on another. We present a cross-modal evaluation framework for materials image segmentation spanning SEM, AFM, XCT, and optical microscopy. Our evaluation of six encoder-decoder combinations across seven datasets reveals that optimal architectures vary systematically by context: UNet excels for high-contrast 2D imaging while DeepLabv3+ is preferred for the hardest cases. The framework also provides deployment feedback via out-of-distribution detection and counterfactual explanations that reveal which microstructural features drive predictions. Together, the architecture guidance, reliability signals, and interpretability tools address a practical gap in materials characterization, where researchers lack tools to select architectures for their specific imaging setup or assess when models can be trusted on new samples.", "AI": {"tldr": "论文提出了一种跨模态评估框架，用于材料图像分割，并展示了不同架构在各种成像模式下的性能差异。", "motivation": "当前的分割架构通常只针对单一成像模式进行基准测试，这掩盖了实际部署相关的性能变化。研究者希望通过此研究为特定成像设置选择合适的架构提供指导工具。", "method": "论文使用六种编码器-解码器组合在七组数据集上进行了跨模态评估，并通过分布外检测和反事实解释提供了模型的可靠性信号和可解释性工具。", "result": "结果表明，UNet在高对比度2D成像中表现最优，而DeepLabv3+则适用于最难处理的情况。该框架还能够提供关于哪些微观结构特征驱动预测的信息。", "conclusion": "论文提出的方法填补了材料表征领域的一个实际空白，并为研究人员选择合适的架构以及评估模型在新样本上的可信度提供了工具。"}}
{"id": "2602.04153", "pdf": "https://arxiv.org/pdf/2602.04153", "abs": "https://arxiv.org/abs/2602.04153", "authors": ["Zihao Jing", "Yuxi Long", "Ganlin Feng"], "title": "Pruning for Generalization: A Transfer-Oriented Spatiotemporal Graph Framework", "categories": ["cs.LG", "cs.AI"], "comment": "Under review at ICLR 2026 Workshop TSALM", "summary": "Multivariate time series forecasting in graph-structured domains is critical for real-world applications, yet existing spatiotemporal models often suffer from performance degradation under data scarcity and cross-domain shifts. We address these challenges through the lens of structure-aware context selection. We propose TL-GPSTGN, a transfer-oriented spatiotemporal framework that enhances sample efficiency and out-of-distribution generalization by selectively pruning non-optimized graph context. Specifically, our method employs information-theoretic and correlation-based criteria to extract structurally informative subgraphs and features, resulting in a compact, semantically grounded representation. This optimized context is subsequently integrated into a spatiotemporal convolutional architecture to capture complex multivariate dynamics. Evaluations on large-scale traffic benchmarks demonstrate that TL-GPSTGN consistently outperforms baselines in low-data transfer scenarios. Our findings suggest that explicit context pruning serves as a powerful inductive bias for improving the robustness of graph-based forecasting models.", "AI": {"tldr": "提出了一种基于图结构的时间序列预测框架TL-GPSTGN，通过选择性剪枝优化上下文来提高样本效率和泛化能力。", "motivation": "现有时空模型在数据稀缺和跨域迁移时性能下降，为此提出了一个转移导向的时空图框架以提升泛化能力和样本效率。", "method": "该方法运用信息论和相关性标准提取结构化的子图和特征，并将其整合到时空卷积架构中捕捉复杂多变量动态。", "result": "在大规模交通基准测试上，TL-GPSTGN在低数据转移场景下优于基线模型。", "conclusion": "明确的上下文剪枝是一种提升基于图的时间序列预测模型鲁棒性的有效偏置方法。"}}
{"id": "2602.04152", "pdf": "https://arxiv.org/pdf/2602.04152", "abs": "https://arxiv.org/abs/2602.04152", "authors": ["Yirum Kim", "Jaewoo Kim", "Ue-Hwan Kim"], "title": "MA3DSG: Multi-Agent 3D Scene Graph Generation for Large-Scale Indoor Environments", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Current 3D scene graph generation (3DSGG) approaches heavily rely on a single-agent assumption and small-scale environments, exhibiting limited scalability to real-world scenarios. In this work, we introduce Multi-Agent 3D Scene Graph Generation (MA3DSG) model, the first framework designed to tackle this scalability challenge using multiple agents. We develop a training-free graph alignment algorithm that efficiently merges partial query graphs from individual agents into a unified global scene graph. Leveraging extensive analysis and empirical insights, our approach enables conventional single-agent systems to operate collaboratively without requiring any learnable parameters. To rigorously evaluate 3DSGG performance, we propose MA3DSG-Bench-a benchmark that supports diverse agent configurations, domain sizes, and environmental conditions-providing a more general and extensible evaluation framework. This work lays a solid foundation for scalable, multi-agent 3DSGG research.", "AI": {"tldr": "该论文提出了一种多智能体3D场景图生成框架MA3DSG，旨在解决单智能体假设和小规模环境下的可扩展性挑战。", "motivation": "当前的3D场景图生成方法依赖于单一智能体假设及小规模环境，在实际应用场景中存在局限性和不可伸缩性的问题。", "method": "论文提出了一种无训练需求的图形对齐算法，该算法能够将来自不同代理的部分查询图合并到一个统一的整体场景图中。此外，还提出了MA3DSG-Bench基准测试以全面评估多智能体系统的性能表现。", "result": "所提出的框架使传统的单智能体系统能够在无需学习参数的情况下协同工作，并通过广泛的分析和实验证据展示了该方法的有效性。", "conclusion": "论文为可扩展的多代理3D场景图生成研究奠定了基础，提供了一个更为通用且灵活的评估标准。"}}
{"id": "2602.04144", "pdf": "https://arxiv.org/pdf/2602.04144", "abs": "https://arxiv.org/abs/2602.04144", "authors": ["Ruiting Dai", "Zheyu Wang", "Haoyu Yang", "Yihan Liu", "Chengzhi Wang", "Zekun Zhang", "Zishan Huang", "Jiaman Cen", "Lisi Mo"], "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retrieval rigidity. Critically, these end-to-end architectures are fundamentally constrained by Semantic-Detail Entanglement -- a structural conflict between logical reasoning and signal synthesis that compromises fidelity. In this paper, we present \\textbf{\\underline{O}}mni-\\textbf{\\underline{M}}odality \\textbf{\\underline{G}}eneration Agent (\\textbf{OMG-Agent}), a novel framework that shifts the paradigm from static mapping to a dynamic coarse-to-fine Agentic Workflow. By mimicking a \\textit{deliberate-then-act} cognitive process, OMG-Agent explicitly decouples the task into three synergistic stages: (1) an MLLM-driven Semantic Planner that resolves input ambiguity via Progressive Contextual Reasoning, creating a deterministic structured semantic plan; (2) a non-parametric Evidence Retriever that grounds abstract semantics in external knowledge; and (3) a Retrieval-Injected Executor that utilizes retrieved evidence as flexible feature prompts to overcome rigidity and synthesize high-fidelity details. Extensive experiments on multiple benchmarks demonstrate that OMG-Agent consistently surpasses state-of-the-art methods, maintaining robustness under extreme missingness, e.g., a $2.6$-point gain on CMU-MOSI at $70$\\% missing rates.", "AI": {"tldr": "提出了一种新的多模态数据生成框架OMG-Agent，解决现有方法在处理缺失模态时的局限性。", "motivation": "现有重建方法面临幻觉和检索刚性的瓶颈，并受语义细节纠缠结构冲突的影响，影响了生成的质量。", "method": "采用分阶段协同工作流程：1）语义规划器通过逐步上下文推理解析输入歧义；2）证据检索器基于外部知识将抽象语义具体化；3）注入检索的执行者利用检索到的信息合成高质量细节。", "result": "实验表明，OMG-Agent在多个基准上优于现有最佳方法，并保持了在极端缺失情况下的鲁棒性。", "conclusion": "通过引入动态粗细分工的工作流程，OMG-Agent显著提高了多模态数据生成的准确性和可靠性。"}}
{"id": "2602.04142", "pdf": "https://arxiv.org/pdf/2602.04142", "abs": "https://arxiv.org/abs/2602.04142", "authors": ["Hiroshi Sasaki"], "title": "JSynFlow: Japanese Synthesised Flowchart Visual Question Answering Dataset built with Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "7 pages", "summary": "Vision and language models (VLMs) are expected to analyse complex documents, such as those containing flowcharts, through a question-answering (QA) interface. The ability to recognise and interpret these flowcharts is in high demand, as they provide valuable insights unavailable in text-only explanations. However, developing VLMs with precise flowchart understanding requires large-scale datasets of flowchart images and corresponding text, the creation of which is highly time-consuming. To address this challenge, we introduce JSynFlow, a synthesised visual QA dataset for Japanese flowcharts, generated using large language models (LLMs). Our dataset comprises task descriptions for various business occupations, the corresponding flowchart images rendered from domain-specific language (DSL) code, and related QA pairs. This paper details the dataset's synthesis procedure and demonstrates that fine-tuning with JSynFlow significantly improves VLM performance on flowchart-based QA tasks. Our dataset is publicly available at https://huggingface.co/datasets/jri-advtechlab/jsynflow.", "AI": {"tldr": "构建了一个用于日语流程图的合成视觉问答数据集JSynFlow，以提高视觉语言模型在基于流程图的任务中的性能。", "motivation": "开发能够准确理解和解释流程图的视觉语言模型需要大规模的数据集，但创建这些数据集耗时且困难。为此引入了JSynFlow，通过大型语言模型生成日语流程图相关问答数据集以解决这一挑战。", "method": "使用领域特定语言（DSL）代码合成任务描述及对应的流程图表，并生成相关的问答对构建数据集；展示如何利用该数据集改进视觉语言模型在基于流程图的问答任务中的表现。", "result": "通过JSynFlow训练可以显著提升视觉语言模型处理流程图相关问题的能力。数据集已公开，供研究人员使用。", "conclusion": "JSynFlow是一个有效的工具，它利用大型语言模型生成大规模的数据集来解决开发具有精确流程图理解能力的视觉语言模型面临的挑战，并提高了这些模型在基于流程图任务中的性能。"}}
{"id": "2602.04138", "pdf": "https://arxiv.org/pdf/2602.04138", "abs": "https://arxiv.org/abs/2602.04138", "authors": ["Felicia Fang-Yi Tan", "Oded Nov"], "title": "Counting the Wait: Effects of Temporal Feedback on Downstream Task Performance and Perceived Wait-Time Experience during System-Imposed Delays", "categories": ["cs.HC"], "comment": "To be published in ACM CHI 2026", "summary": "System-imposed wait times can significantly disrupt digital workflows, affecting user experience and task performance. Prior HCI research has examined how temporal feedback, such as feedback mode (Elapsed-Time vs. Remaining-Time) shapes wait-time perception. However, few studies have investigated how such feedback influences users' downstream task performance, as well as overall affective and cognitive experience. To study these effects, we conducted an online experiment where 425 participants performing a visual reasoning task experienced a 10-, 30-, or 60-second wait with a Remaining-Time, Elapsed-Time, or No Time Display. Findings show that temporal feedback mode shapes how waiting is perceived: Remaining-Time feedback increased frustration relative to Elapsed-Time feedback, while No Time Display made waits feel longer and heightened ambiguity. Notably, these experiential differences did not translate into differences in post-wait task performance. Integrating psychophysical and cognitive science perspectives, we discuss implications for implementing temporal feedback in latency-prone digital systems.", "AI": {"tldr": "研究在线实验中不同时间反馈模式对用户等待体验和后续任务表现的影响。", "motivation": "系统延迟会影响用户体验及任务性能，当前HCI研究较少关注如何通过时间反馈改善用户等待时的心理感受及其对下游任务执行的影响。", "method": "进行了包含425名参与者的在线实验，在进行视觉推理任务的过程中，参与者经历了带有剩余时间显示、已过时间显示或无时间显示的10秒、30秒和60秒延迟。", "result": "结果显示不同反馈模式对等待体验有显著影响：剩余时间显示增加了沮丧感；没有时间显示使等待感觉更长且模糊。这些差异并未在后续任务表现上显现出来。", "conclusion": "讨论了实施时间反馈对于改善用户体验的重要性，并基于心理物理学和认知科学视角提供了设计建议，以应对延迟问题的数字系统中应用时间反馈的方法。"}}
{"id": "2602.04137", "pdf": "https://arxiv.org/pdf/2602.04137", "abs": "https://arxiv.org/abs/2602.04137", "authors": ["Elisabetta Zibetti", "Alexandra Mercader", "Hélène Duval", "Florent Levillain", "Audrey Rochette", "David St-Onge"], "title": "Shaping Expressiveness in Robotics: The Role of Design Tools in Crafting Embodied Robot Movements", "categories": ["cs.RO"], "comment": null, "summary": "As robots increasingly become part of shared human spaces, their movements must transcend basic functionality by incorporating expressive qualities to enhance engagement and communication. This paper introduces a movement-centered design pedagogy designed to support engineers in creating expressive robotic arm movements. Through a hands-on interactive workshop informed by interdisciplinary methodologies, participants explored various creative possibilities, generating valuable insights into expressive motion design. The iterative approach proposed integrates analytical frameworks from dance, enabling designers to examine motion through dynamic and embodied dimensions. A custom manual remote controller facilitates interactive, real-time manipulation of the robotic arm, while dedicated animation software supports visualization, detailed motion sequencing, and precise parameter control. Qualitative analysis of this interactive design process reveals that the proposed \"toolbox\" effectively bridges the gap between human intent and robotic expressiveness resulting in more intuitive and engaging expressive robotic arm movements.", "AI": {"tldr": "介绍了用于设计表达性机器人臂动作的设计工具和方法，以增强人机交互。", "motivation": "随着机器人的普及，其运动不仅应具备基本功能，还需包含表达性品质来提升互动性和沟通能力。", "method": "通过一个结合多学科方法的工作坊，使用定制的手动远程控制器和动画软件进行迭代设计过程。", "result": "结果表明，该设计工具箱成功地将人类意图与机器人的表达性联系起来，产生了更直观、更具吸引力的机器人动作。", "conclusion": "提出的方法有助于工程师创建具有表达性的机器人臂运动，从而提高人机交互的质量。"}}
{"id": "2602.04132", "pdf": "https://arxiv.org/pdf/2602.04132", "abs": "https://arxiv.org/abs/2602.04132", "authors": ["Dhruv S. Kushwaha", "Zoleikha A. Biron"], "title": "Lyapunov Constrained Soft Actor-Critic (LC-SAC) using Koopman Operator Theory for Quadrotor Trajectory Tracking", "categories": ["eess.SY", "cs.LG", "cs.RO"], "comment": "12 pages, 7 Figures, submitted to IEEE RA-L", "summary": "Reinforcement Learning (RL) has achieved remarkable success in solving complex sequential decision-making problems. However, its application to safety-critical physical systems remains constrained by the lack of stability guarantees. Standard RL algorithms prioritize reward maximization, often yielding policies that may induce oscillations or unbounded state divergence. There has significant work in incorporating Lyapunov-based stability guarantees in RL algorithms with key challenges being selecting a candidate Lyapunov function, computational complexity by using excessive function approximators and conservative policies by incorporating stability criterion in the learning process. In this work we propose a novel Lyapunov-constrained Soft Actor-Critic (LC-SAC) algorithm using Koopman operator theory. We propose use of extended dynamic mode decomposition (EDMD) to produce a linear approximation of the system and use this approximation to derive a closed form solution for candidate Lyapunov function. This derived Lyapunov function is incorporated in the SAC algorithm to further provide guarantees for a policy that stabilizes the nonlinear system. The results are evaluated trajectory tracking of a 2D Quadrotor environment based on safe-control-gym. The proposed algorithm shows training convergence and decaying violations for Lyapunov stability criterion compared to baseline vanilla SAC algorithm. GitHub Repository: https://github.com/DhruvKushwaha/LC-SAC-Quadrotor-Trajectory-Tracking", "AI": {"tldr": "本文提出了一种基于Koopman算子理论的Lyapunov约束软演员评论(LC-SAC)算法，用于四旋翼轨迹跟踪。", "motivation": "传统的RL算法优先考虑奖励最大化，在安全关键系统中缺乏稳定性保证。标准RL算法可能会产生导致振荡或未界定状态发散的策略。", "method": "利用扩展动态模式分解(EDMD)生成系统的线性近似，并使用该近似解导出候选Lyapunov函数，将其集成到SAC算法中以确保非线性系统稳定性的政策保证。", "result": "在基于safe-control-gym的2D四旋翼环境中评估了所提出的算法。相比基线vanilla SAC算法，训练收敛性和Lyapunov稳定性准则的下降违反情况都得到了改善。", "conclusion": "提出的方法展示了通过结合稳定性标准实现政策稳定性的潜力，并且相较于基准SAC算法有更佳的表现。"}}
{"id": "2602.04130", "pdf": "https://arxiv.org/pdf/2602.04130", "abs": "https://arxiv.org/abs/2602.04130", "authors": ["Tiroshan Madushanka", "Sakuna Madushanka"], "title": "Multi-threaded Recast-Based A* Pathfinding for Scalable Navigation in Dynamic Game Environments", "categories": ["cs.GR", "cs.RO"], "comment": null, "summary": "While the A* algorithm remains the industry standard for game pathfinding, its integration into dynamic 3D environments faces trade-offs between computational performance and visual realism. This paper proposes a multi-threaded framework that enhances standard A* through Recast-based mesh generation, Bezier-curve trajectory smoothing, and density analysis for crowd coordination. We evaluate our system across ten incremental phases, from 2D mazes to complex multi-level dynamic worlds. Experimental results demonstrate that the framework maintains 350+ FPS with 1000 simultaneous agents and achieves collision-free crowd navigation through density-aware path coordination.", "AI": {"tldr": "该论文提出了一种多线程的A*寻路框架，以提高动态游戏环境中路径规划的性能和现实性。", "motivation": "在动态三维环境中应用传统A*算法面临着计算效率与视觉真实感之间的权衡问题。本文旨在通过改进技术来解决这一挑战。", "method": "该论文采用多线程框架结合Recast网格生成、贝塞尔曲线路径平滑和密度分析，以实现更高效和协调的群体导航。", "result": "实验结果显示该系统在复杂的动态环境中可以保持超过350FPS的游戏帧率，并且能够支持多达1000个同时活动的代理进行无碰撞导航。", "conclusion": "通过引入多线程和高级路径规划技术，该框架证明了它能够在复杂游戏环境中实现高效、现实感强的群体行为模拟。"}}
{"id": "2602.04129", "pdf": "https://arxiv.org/pdf/2602.04129", "abs": "https://arxiv.org/abs/2602.04129", "authors": ["Chak Lam Shek", "Faizan M. Tariq", "Sangjae Bae", "David Isele", "Piyush Gupta"], "title": "KGLAMP: Knowledge Graph-guided Language model for Adaptive Multi-robot Planning and Replanning", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.MA"], "comment": null, "summary": "Heterogeneous multi-robot systems are increasingly deployed in long-horizon missions that require coordination among robots with diverse capabilities. However, existing planning approaches struggle to construct accurate symbolic representations and maintain plan consistency in dynamic environments. Classical PDDL planners require manually crafted symbolic models, while LLM-based planners often ignore agent heterogeneity and environmental uncertainty. We introduce KGLAMP, a knowledge-graph-guided LLM planning framework for heterogeneous multi-robot teams. The framework maintains a structured knowledge graph encoding object relations, spatial reachability, and robot capabilities, which guides the LLM in generating accurate PDDL problem specifications. The knowledge graph serves as a persistent, dynamically updated memory that incorporates new observations and triggers replanning upon detecting inconsistencies, enabling symbolic plans to adapt to evolving world states. Experiments on the MAT-THOR benchmark show that KGLAMP improves performance by at least 25.5% over both LLM-only and PDDL-based variants.", "AI": {"tldr": "KGLAMP是一种基于知识图谱的LLM规划框架，用于异构多机器人团队中的适应性多机器人计划和重规划。", "motivation": "现有的规划方法在动态环境中很难构建准确的符号表示并保持计划的一致性。经典PDDL规划器需要手动制作符号模型，而基于大语言模型的规划器通常忽略了代理异质性和环境不确定性。", "method": "KGLAMP框架维护一个结构化的知识图谱，该图谱编码对象关系、空间可达性以及机器人能力，并指导LLM生成准确的PDDL问题规范。此知识图谱作为持久、动态更新的记忆，在检测到不一致时触发重新规划。", "result": "实验结果表明，KGLAMP在MAT-THOR基准测试中的性能比仅基于大语言模型和基于PDDL的方法至少提高了25.5%。", "conclusion": "KGLAMP为异构多机器人团队提供了一种有效的适应性计划方法，在动态环境中能够更好地协调具有不同能力的机器人，提高规划效率。"}}
{"id": "2602.04127", "pdf": "https://arxiv.org/pdf/2602.04127", "abs": "https://arxiv.org/abs/2602.04127", "authors": ["Sercan Karakaş", "Yusuf Şimşek"], "title": "From Lemmas to Dependencies: What Signals Drive Light Verbs Classification?", "categories": ["cs.CL", "cs.AI"], "comment": "EACL SIGTURK", "summary": "Light verb constructions (LVCs) are a challenging class of verbal multiword expressions, especially in Turkish, where rich morphology and productive complex predicates create minimal contrasts between idiomatic predicate meanings and literal verb--argument uses. This paper asks what signals drive LVC classification by systematically restricting model inputs. Using UD-derived supervision, we compare lemma-driven baselines (lemma TF--IDF + Logistic Regression; BERTurk trained on lemma sequences), a grammar-only Logistic Regression over UD morphosyntax (UPOS/DEPREL/MORPH), and a full-input BERTurk baseline. We evaluate on a controlled diagnostic set with Random negatives, lexical controls (NLVC), and LVC positives, reporting split-wise performance to expose decision-boundary behavior. Results show that coarse morphosyntax alone is insufficient for robust LVC detection under controlled contrasts, while lexical identity supports LVC judgments but is sensitive to calibration and normalization choices. Overall, Our findings motivate targeted evaluation of Turkish MWEs and show that ``lemma-only'' is not a single, well-defined representation, but one that depends critically on how normalization is operationalized.", "AI": {"tldr": "研究探讨了驱动轻动词分类的信号，通过限制模型输入的方法来对比不同模型的表现。", "motivation": "土耳其语中丰富的形态变化和复杂的谓语结构使得轻动词短语（LVCs）的识别成为难题。该研究旨在探索在这些复杂条件下驱动LVC分类的主要信号是什么。", "method": "使用UD衍生监督，比较了基于词汇形式的基本模型、仅依赖语法信息的逻辑回归以及全输入BERTurk基线模型的表现。评估是在具有随机负例、词典对照和LVC正例的控制诊断集中进行的，并报告了分段性能以揭示决策边界行为。", "result": "研究发现，粗略形态语法则不足以在受控对比中实现稳健的轻动词检测，而词汇身份支持轻动词判断但对校准和归一化选择敏感。总体而言，“仅基于词汇形式”的方法不是一个单一、明确定义的表示方式，而是高度依赖于具体操作化。", "conclusion": "研究结果强调了针对土耳其语多词短语进行定向评估的重要性，并表明“仅基于词汇形式”并不是一个明确定义的表示方法，它依赖于如何实现归一化的细节。"}}
{"id": "2602.04120", "pdf": "https://arxiv.org/pdf/2602.04120", "abs": "https://arxiv.org/abs/2602.04120", "authors": ["Samaresh Kumar Singh", "Joyjit Roy"], "title": "Scalable Explainability-as-a-Service (XaaS) for Edge AI Systems", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.SE"], "comment": "8 pages, 5 figures, submitted and accepted in the conference IEEE SoutheastCon 2026", "summary": "Though Explainable AI (XAI) has made significant advancements, its inclusion in edge and IoT systems is typically ad-hoc and inefficient. Most current methods are \"coupled\" in such a way that they generate explanations simultaneously with model inferences. As a result, these approaches incur redundant computation, high latency and poor scalability when deployed across heterogeneous sets of edge devices. In this work we propose Explainability-as-a-Service (XaaS), a distributed architecture for treating explainability as a first-class system service (as opposed to a model-specific feature). The key innovation in our proposed XaaS architecture is that it decouples inference from explanation generation allowing edge devices to request, cache and verify explanations subject to resource and latency constraints. To achieve this, we introduce three main innovations: (1) A distributed explanation cache with a semantic similarity based explanation retrieval method which significantly reduces redundant computation; (2) A lightweight verification protocol that ensures the fidelity of both cached and newly generated explanations; and (3) An adaptive explanation engine that chooses explanation methods based upon device capability and user requirement. We evaluated the performance of XaaS on three real-world edge-AI use cases: (i) manufacturing quality control; (ii) autonomous vehicle perception; and (iii) healthcare diagnostics. Experimental results show that XaaS reduces latency by 38\\% while maintaining high explanation quality across three real-world deployments. Overall, this work enables the deployment of transparent and accountable AI across large scale, heterogeneous IoT systems, and bridges the gap between XAI research and edge-practicality.", "AI": {"tldr": "本文提出了可扩展的边缘AI系统的解释性即服务（XaaS）架构，解耦推理和解释生成过程以减少冗余计算并提高效率。", "motivation": "当前的可解释人工智能方法在边缘和物联网系统中的应用存在冗余计算、高延迟和低扩展性的缺点。本文旨在通过分布式架构改进这些系统的可解释性。", "method": "提出了一种分布式解释缓存，基于语义相似性的解释检索机制，并引入了轻量级验证协议以及自适应的解释引擎来选择适合设备能力和用户需求的解释方法。", "result": "实验结果显示，在三个实际边缘AI应用场景中，XaaS架构能够将延迟减少38%且保持高质量的解释。", "conclusion": "该工作实现了大规模异构物联网系统中透明和负责的人工智能部署，填补了可解释人工智能研究与边缘实用性之间的空白。"}}
{"id": "2602.04116", "pdf": "https://arxiv.org/pdf/2602.04116", "abs": "https://arxiv.org/abs/2602.04116", "authors": ["Sicheng Liu", "Xunkai Li", "Daohan Su", "Ru Zhang", "Hongchao Qin", "Ronghua Li", "Guoren Wang"], "title": "Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "20 pages, 6 figures", "summary": "Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.", "AI": {"tldr": "提出了一种新的框架PLANET，用于解决多模态图基础模型中的模态交互和对齐问题。", "motivation": "现有的多模态图基础模型未能充分处理跨模态语义以及在不同模态空间中进行有效对齐的问题。", "method": "采用了分解与征服策略的PLANET框架，包括嵌入级上的域门控（EDG）和节点级上的离散化检索（NDR），以实现局部语义丰富化和全局模态对齐。", "result": "实验结果表明，该方法在各种图中心任务及多模态生成任务上显著优于现有基线模型。", "conclusion": "PLANET框架通过有效解决模态交互与对齐问题，在多模态图数据处理中表现出色。"}}
{"id": "2602.04109", "pdf": "https://arxiv.org/pdf/2602.04109", "abs": "https://arxiv.org/abs/2602.04109", "authors": ["Nayoung Choi", "Jiseung Hong", "Peace Cyebukayire", "Ikseon Choi", "Jinho D. Choi"], "title": "Tinker Tales: Supporting Child-AI Collaboration through Co-Creative Storytelling with Educational Scaffolding", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Artificial intelligence (AI) is increasingly framed as a collaborative partner in creative activities, yet children's interactions with AI have largely been studied in AI-led instructional settings rather than co-creative collaboration. This leaves open questions about how children can meaningfully engage with AI through iterative co-creation. We present Tinker Tales, a tangible storytelling system designed with narrative and social-emotional scaffolding to support child-AI collaboration. The system combines a physical storytelling board, NFC-embedded toys representing story elements (e.g., characters, places, items, and emotions), and a mobile app that mediates child-AI interaction. Children shape and refine stories by placing and moving story elements and interacting with the AI through tangible and voice-based interaction. We conducted an exploratory user study with 10 children to examine how they interacted with Tinker Tales. Our findings show that children treated the AI as an attentive, responsive collaborator, while scaffolding supported coherent narrative refinement without diminishing children's agency.", "AI": {"tldr": "该论文介绍了Tinker Tales系统，一个支持儿童与AI合作进行故事创作的有形叙事平台。", "motivation": "当前研究主要关注AI主导的教学活动，较少探讨儿童如何通过迭代共创有意义地参与其中。因此，作者设计了Tinker Tales以促进儿童和AI之间的协同创作。", "method": "该系统结合物理讲故事板、嵌入NFC的玩具（代表故事元素）以及一个中介儿童与AI互动的移动应用程序。进行了探索性用户研究，邀请10名儿童参与使用Tinker Tales进行互动。", "result": "研究表明，孩子们将AI视为关注且响应的合作伙伴，并通过支架支持连贯的故事改进而不削弱孩子的主动性。", "conclusion": "结果表明，Tinker Tales能够有效地促进儿童与AI之间的合作叙事创作。"}}
{"id": "2602.04108", "pdf": "https://arxiv.org/pdf/2602.04108", "abs": "https://arxiv.org/abs/2602.04108", "authors": ["O. Leon Barbed", "José M. M. Montiel", "Pascal Fua", "Ana C. Murillo"], "title": "SuperPoint-E: local features for 3D reconstruction via tracking adaptation in endoscopy", "categories": ["cs.CV"], "comment": "12 pages, 5 tables, 6 figures", "summary": "In this work, we focus on boosting the feature extraction to improve the performance of Structure-from-Motion (SfM) in endoscopy videos. We present SuperPoint-E, a new local feature extraction method that, using our proposed Tracking Adaptation supervision strategy, significantly improves the quality of feature detection and description in endoscopy. Extensive experimentation on real endoscopy recordings studies our approach's most suitable configuration and evaluates SuperPoint-E feature quality. The comparison with other baselines also shows that our 3D reconstructions are denser and cover more and longer video segments because our detector fires more densely and our features are more likely to survive (i.e. higher detection precision). In addition, our descriptor is more discriminative, making the guided matching step almost redundant. The presented approach brings significant improvements in the 3D reconstructions obtained, via SfM on endoscopy videos, compared to the original SuperPoint and the gold standard SfM COLMAP pipeline.", "AI": {"tldr": "该论文提出了一种新的局部特征提取方法SuperPoint-E，旨在通过跟踪适应策略改进内窥镜视频中的结构从运动（SfM）性能。", "motivation": "在内窥镜记录中提高特征检测和描述的质量，以改善3D重建的密度和覆盖范围。", "method": "使用提出的跟踪适应监督策略，开发了SuperPoint-E方法，以改进特征提取过程。", "result": "与基准相比，该方法产生的3D重建更加密集且覆盖更长视频段。其检测器触发频率更高且特征更具生存性，描述符也更为区分。", "conclusion": "SuperPoint-E在内窥镜视频中的SfM应用中带来了显著的改进，并优于原始SuperPoint和标准SfM COLMAP管道。"}}
{"id": "2602.04104", "pdf": "https://arxiv.org/pdf/2602.04104", "abs": "https://arxiv.org/abs/2602.04104", "authors": ["Adriana Olmos", "Anoop K. Sinha", "Renelito Delos Santos", "Ruben Rodriguez Rodriguez", "James A. Landay", "Sam S. Sepah", "Philip Nelson", "Shaun K. Kane"], "title": "Making Videos Accessible for Blind and Low Vision Users Using a Multimodal Agent Video Player", "categories": ["cs.HC"], "comment": null, "summary": "Video content remains largely inaccessible to blind and low-vision (BLV) users. To address this, we introduce a prototype that leverages a multimodal agent - powered by a novel conversational architecture using a multimodal large language model (MLLM) - to provide BLV users with an interactive, accessible video experience. This Multimodal Agent Video Player (MAVP) demonstrates that an interactive accessibility mode can be added to a video through multilayered prompt orchestration. We describe a user-centered design process involving 18 sessions with BLV users that showed that BLV users do not just want accessibility features, but desire independence and personal agency over the viewing experience. We conducted a qualitative study with an additional 8 BLV participants; in this, we saw that the MAVP's conversational dialogue offers BLV users a sense of personal agency, fostering collaboration and trust. Even in the case of hallucinations, it is meta-conversational dialogues about AI's limitations that can repair trust.", "AI": {"tldr": "该论文提出了一种利用多模态代理的视频播放器，为视障用户提供交互式的视频体验。", "motivation": "视频内容对盲人和低视力用户来说是不可访问的。因此，该研究旨在开发一种可以提供可访问性和个人独立性的互动视频方案。", "method": "通过引入一个由多模态大型语言模型驱动的多模态代理，论文提出了一种称为Multimodal Agent Video Player (MAVP) 的原型系统来解决这一问题，并进行了一系列用户为中心的设计过程及后续研究。", "result": "通过与18名视障用户的会话以及对另外8名参与者的定性分析表明，MAVP提供的多层提示协调可以增强观看体验的可访问性和个人代理感。即使出现幻觉情况，关于AI局限性的元对话也可以修复信任。", "conclusion": "该研究证明了通过创新的多模态代理和多层提示协调技术，可以让盲人和低视力用户获得一种更具互动性、自主性和合作性的视频体验方式。"}}
{"id": "2602.04103", "pdf": "https://arxiv.org/pdf/2602.04103", "abs": "https://arxiv.org/abs/2602.04103", "authors": ["R. Groot Koerkamp"], "title": "QuadRank: Engineering a High Throughput Rank", "categories": ["cs.DS"], "comment": "submitted to SEA-2026; 21 pages; 8 figures", "summary": "Given a text, a query $\\mathsf{rank}(q, c)$ counts the number of occurrences of character $c$ among the first $q$ characters of the text. Space-efficient methods to answer these rank queries form an important building block in many succinct data structures. For example, the FM-index is a widely used data structure that uses rank queries to locate all occurrences of a pattern in a text. In bioinformatics applications, the goal is usually to process a given input as fast as possible. Thus, data structures should have high throughput when used with many threads. Contributions. For the binary alphabet, we develop BiRank with 3.28% space overhead. It merges the central ideas of two recent papers: (1) we interleave (inline) offsets in each cache line of the underlying bit vector [Laws et al., 2024], reducing cache-misses, and (2) these offsets are to the middle of each block so that only half of them need popcounting [Gottlieb and Reinert, 2025]. In QuadRank (14.4% space overhead), we extend these techniques to the $σ=4$ (DNA) alphabet. Both data structures require only a single cache miss per query, making them highly suitable for high-throughput and memory-bound settings. To enable efficient batch-processing, we support prefetching the cache lines required to answer upcoming queries. Results. BiRank and QuadRank are around $1.5\\times$ and $2\\times$ faster than similar-overhead methods that do not use inlining. Prefetching gives an additional $2\\times$ speedup, at which point the dual-channel DDR4 RAM bandwidth becomes a hard limit on the total throughput. With prefetching, both methods outperform all other methods apart from SPIDER [Laws et al., 2024] by $2\\times$. When using QuadRank with prefetching in a toy count-only FM-index, QuadFm, this results in a smaller size and up to $4\\times$ speedup over Genedex, a state-of-the-art batching FM-index implementation.", "AI": {"tldr": "设计了一种名为QuadRank的高效排名查询算法，用于快速处理DNA序列中的字符计数。", "motivation": "为了提高生物信息学应用中的数据结构处理速度，特别是在多线程环境中实现高吞吐量。传统的排名查询方法在空间开销和访问效率上存在不足。", "method": "提出了一种名为QuadRank的算法，通过将偏移量内联到每个缓存行中并将其对齐到块中间来减少缓存缺失，适用于处理DNA序列（σ=4）的情况。支持预取即将需要的缓存行以提高批量处理效率。", "result": "相比其他具有相似空间开销的方法，BiRank和QuadRank分别快1.5倍和2倍；引入预取机制后速度再提升2倍，达到内存带宽限制时性能最佳。在玩具计数仅模式FM索引中使用QuadRank可实现更快的速度（最多4倍）。", "conclusion": "该研究提出的方法能够有效提高生物信息学应用中的字符排名查询效率，在多线程和高吞吐量环境中表现出色，尤其是在处理DNA序列时效果显著。"}}
{"id": "2602.04102", "pdf": "https://arxiv.org/pdf/2602.04102", "abs": "https://arxiv.org/abs/2602.04102", "authors": ["Aayushma Pant", "Lakpa Tamang", "Tsz-Kwan Lee", "Sunil Aryal"], "title": "DMS2F-HAD: A Dual-branch Mamba-based Spatial-Spectral Fusion Network for Hyperspectral Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "This paper has been accepted in the WACV 2025 conference in algorithm track", "summary": "Hyperspectral anomaly detection (HAD) aims to identify rare and irregular targets in high-dimensional hyperspectral images (HSIs), which are often noisy and unlabelled data. Existing deep learning methods either fail to capture long-range spectral dependencies (e.g., convolutional neural networks) or suffer from high computational cost (e.g., Transformers). To address these challenges, we propose DMS2F-HAD, a novel dual-branch Mamba-based model. Our architecture utilizes Mamba's linear-time modeling to efficiently learn distinct spatial and spectral features in specialized branches, which are then integrated by a dynamic gated fusion mechanism to enhance anomaly localization. Across fourteen benchmark HSI datasets, our proposed DMS2F-HAD not only achieves a state-of-the-art average AUC of 98.78%, but also demonstrates superior efficiency with an inference speed 4.6 times faster than comparable deep learning methods. The results highlight DMS2FHAD's strong generalization and scalability, positioning it as a strong candidate for practical HAD applications.", "AI": {"tldr": "提出了一种新的基于Mamba的双分支模型DMS2F-HAD，用于高光谱异常检测。", "motivation": "现有深度学习方法要么无法捕捉长距离光谱依赖性，要么计算成本过高。为了解决这些问题，提出了DMS2F-HAD。", "method": "该架构利用Mamba的线性时间建模来有效学习不同的空间和光谱特征，并通过动态门控融合机制进行集成。", "result": "在14个基准高光谱数据集上，所提模型实现了98.78%的平均AUC并展示了优于其他深度学习方法4.6倍的推理速度。", "conclusion": "DMS2F-HAD表现出强大的泛化能力和可扩展性，使其成为实际高光谱异常检测应用中的强有力候选者。"}}
{"id": "2602.04101", "pdf": "https://arxiv.org/pdf/2602.04101", "abs": "https://arxiv.org/abs/2602.04101", "authors": ["Harsha Vardhan Khurdula", "Vineet Agarwal", "Yoeven D Khemlani"], "title": "Interfaze: The Future of AI is built on Task-Specific Small Models", "categories": ["cs.AI"], "comment": "8 pages, 1 figure", "summary": "We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external sources (web pages, code, PDFs) into compact structured state, and (iii) an action layer that can browse, retrieve, execute code in a sandbox, and drive a headless browser for dynamic web pages. A thin controller sits on top of this stack and exposes a single, OpenAI-style endpoint: it decides which small models and actions to run and always forwards the distilled context to a user-selected LLM that produces the final response. On this architecture, Interfaze-Beta achieves 83.6% on MMLU-Pro, 91.4% on MMLU, 81.3% on GPQA-Diamond, 57.8% on LiveCodeBench v5, and 90.0% on AIME-2025, along with strong multimodal scores on MMMU (val) (77.3%), AI2D (91.5%), ChartQA (90.9%), and Common Voice v16 (90.8%). We show that most queries are handled primarily by the small-model and tool stack, with the large LLM operating only on distilled context, yielding competitive accuracy while shifting the bulk of computation away from the most expensive and monolithic models.", "AI": {"tldr": "介绍Interfaze系统，该系统采用多层异构模型和工具堆栈处理复杂任务，并将简化后的上下文传递给大型语言模型生成最终响应。", "motivation": "提出一种替代单一巨大模型的方法，通过构建特定任务的小型模型和工具堆栈来提高效率并降低成本。", "method": "结合多种小型深度神经网络、感知模块（如OCR和多语言ASR）、上下文构造层和操作层，形成一个灵活的任务处理架构。系统包括爬取、索引外部资源、执行代码等功能，并通过控制器选择合适的模型与动作来响应用户请求。", "result": "Interfaze-Beta在多个基准测试中表现良好，例如MMLU-Pro达到83.6%，LiveCodeBench v5达到57.8%。大多数查询主要由小型模型和工具堆栈处理，大型语言模型仅处理简化后的上下文。", "conclusion": "通过使用任务特定的小型模型和工具堆栈来分担计算负担，Interfaze能够在保持准确性的前提下提高效率并降低成本。"}}
{"id": "2602.04095", "pdf": "https://arxiv.org/pdf/2602.04095", "abs": "https://arxiv.org/abs/2602.04095", "authors": ["Qi Zhang"], "title": "A computational account of dreaming: learning and memory consolidation", "categories": ["q-bio.NC", "cs.AI", "cs.ET"], "comment": "30 pages, 4 tables, 2 figures", "summary": "A number of studies have concluded that dreaming is mostly caused by randomly arriving internal signals because \"dream contents are random impulses\", and argued that dream sleep is unlikely to play an important part in our intellectual capacity. On the contrary, numerous functional studies have revealed that dream sleep does play an important role in our learning and other intellectual functions. Specifically, recent studies have suggested the importance of dream sleep in memory consolidation, following the findings of neural replaying of recent waking patterns in the hippocampus. The randomness has been the hurdle that divides dream theories into either functional or functionless. This study presents a cognitive and computational model of dream process. This model is simulated to perform the functions of learning and memory consolidation, which are two most popular dream functions that have been proposed. The simulations demonstrate that random signals may result in learning and memory consolidation. Thus, dreaming is proposed as a continuation of brain's waking activities that processes signals activated spontaneously and randomly from the hippocampus. The characteristics of the model are discussed and found in agreement with many characteristics concluded from various empirical studies.", "AI": {"tldr": "该论文提出了一种认知和计算模型，以模拟梦境中的学习和记忆巩固过程，并证明了随机信号可以促进这些功能。", "motivation": "针对梦被认为仅仅是随机内部信号的结果这一观点与功能性理论之间的分歧，此研究旨在通过创建一个能执行学习和记忆巩固的模型来解释梦境的功能性。", "method": "建立了一个认知和计算模型来模拟梦境过程，并探讨了该模型与多种实证研究所得特征的一致性。", "result": "模拟显示随机信号可以导致学习和记忆巩固，表明梦是大脑对自发或随机激活的记忆进行处理的过程的延续。", "conclusion": "研究表明，梦不是无功能的随机现象，而是脑部在睡眠中继续其清醒活动的一部分。"}}
{"id": "2602.04094", "pdf": "https://arxiv.org/pdf/2602.04094", "abs": "https://arxiv.org/abs/2602.04094", "authors": ["Junbo Zou", "Ziheng Huang", "Shengjie Zhang", "Liwen Zhang", "Weining Shen"], "title": "VideoBrain: Learning Adaptive Frame Sampling for Long Video Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Long-form video understanding remains challenging for Vision-Language Models (VLMs) due to the inherent tension between computational constraints and the need to capture information distributed across thousands of frames. Existing approaches either sample frames uniformly (risking information loss) or select keyframes in a single pass (with no recovery from poor choices). We propose VideoBrain, an end-to-end framework that enables VLMs to adaptively acquire visual information through learned sampling policies. Our approach features dual complementary agents: a CLIP-based agent for semantic retrieval across the video and a Uniform agent for dense temporal sampling within intervals. Unlike prior agent-based methods that rely on text-only LLMs orchestrating visual tools, our VLM directly perceives frames and reasons about information sufficiency. To prevent models from invoking agents indiscriminately to maximize rewards, we introduce a behavior-aware reward function coupled with a data classification pipeline that teaches the model when agent invocation is genuinely beneficial. Experiments on four long video benchmarks demonstrate that VideoBrain achieves +3.5% to +9.0% improvement over the baseline while using 30-40% fewer frames, with strong cross-dataset generalization to short video benchmarks.", "AI": {"tldr": "提出了一种名为VideoBrain的端到端框架，使视觉语言模型能够通过学习适应性帧采样策略来理解长视频。", "motivation": "现有的方法要么均匀抽样，导致信息丢失，要么一次性选择关键帧而无法从错误中恢复。因此，需要一种新的方式解决计算限制和信息捕获之间的矛盾。", "method": "提出了一种基于CLIP的语义检索代理与均匀采样代理相结合的方法，使模型能够直接感知帧并根据信息充分性进行推理。通过引入行为意识奖励函数以及数据分类管道来指导何时调用代理。", "result": "在四个长视频基准测试中，VideoBrain相较于基线提高了3.5%到9.0%，同时使用的帧数减少了30-40%，并且展示了强大的跨数据集泛化能力。", "conclusion": "VideoBrain框架能够在理解长视频的同时减少计算开销，并且表现出良好的性能和泛化性。"}}
{"id": "2602.04089", "pdf": "https://arxiv.org/pdf/2602.04089", "abs": "https://arxiv.org/abs/2602.04089", "authors": ["Xiaofeng Lin", "Sirou Zhu", "Yilei Chen", "Mingyu Chen", "Hejian Sang", "Ioannis Paschalidis", "Zhipeng Wang", "Aldo Pacchiano", "Xuezhou Zhang"], "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.", "AI": {"tldr": "介绍了一种用于训练大型语言模型（LLMs）在线学习能力的框架ORBIT，使LLMs在上下文环境中通过交互式学习实现更好的性能。", "motivation": "当前LLM难以在实时获取信息的任务中充分利用上下文中的互动经验。为了提高LLMs在线学习的能力，提出了该研究。", "method": "提出了一种基于多任务、多集元强化学习（Meta-RL）的框架ORBIT来训练LLMs以从交互中学习，并展示了模型性能的提升。", "result": "通过使用Qwen3-14B模型，在未见过的环境中实现了显著改进的在线学习，其效果与GPT-5.2相当甚至更优，大大超过了标准RL微调的结果。", "conclusion": "ORBIT框架成功改善了LLMs在上下文环境中的在线学习能力，并且随着模型规模的增长，该方法能够进一步提升性能。"}}
{"id": "2602.04085", "pdf": "https://arxiv.org/pdf/2602.04085", "abs": "https://arxiv.org/abs/2602.04085", "authors": ["Min Jang", "Orevaoghene Ahia", "Nazif Tamer", "Sachin Kumar", "Yulia Tsvetkov", "Noah A. Smith"], "title": "BASS: Benchmarking Audio LMs for Musical Structure and Semantic Reasoning", "categories": ["cs.SD", "cs.CL"], "comment": null, "summary": "Music understanding is a complex task that often requires reasoning over both structural and semantic elements of audio. We introduce BASS, designed to evaluate music understanding and reasoning in audio language models across four broad categories: structural segmentation, lyric transcription, musicological analysis, and artist collaboration. BASS comprises 2658 questions spanning 12 tasks, 1993 unique songs and covering over 138 hours of music from a wide range of genres and tracks, crafted to assess musicological knowledge and reasoning in real-world scenarios. We evaluate 14 open-source and frontier multimodal LMs, finding that even state-of-the-art models struggle on higher-level reasoning tasks such as structural segmentation and artist collaboration, while performing best on lyric transcription. Our analysis reveals that current models leverage linguistic priors effectively but remain limited in reasoning over musical structure, vocal, and musicological attributes. BASS provides an evaluation framework with widespread applications in music recommendation and search and has the potential to guide the development of audio LMs.", "AI": {"tldr": "BASS 是一个评估音频语言模型在音乐理解和推理方面的基准测试，涵盖结构分割、歌词转录、音乐学分析和艺术家合作等任务。", "motivation": "现有的音频语言模型虽然在某些方面表现出色，但在复杂音乐理解与推理（如结构分割和艺术家合作）上仍存在不足。BASS旨在全面评估这些模型的能力，并推动未来的研究方向。", "method": "设计了一个包含2658个问题的基准测试集BASS，涉及12项任务、1993首歌曲及超过138小时的音乐样本，用于评估各种音频语言模型的表现。通过对比多种开源和前沿模型的结果来分析它们的优势与不足。", "result": "结果显示，即使是顶尖的多模态语言模型在结构分割和艺术家合作等较高层次的任务上仍然表现不佳；而歌词转录任务则相对容易完成。", "conclusion": "BASS 提供了一个全面评估音乐理解和推理能力的重要框架，并为未来音频语言模型的发展提供了指导方向。"}}
{"id": "2602.04083", "pdf": "https://arxiv.org/pdf/2602.04083", "abs": "https://arxiv.org/abs/2602.04083", "authors": ["Alexandre Barbosa de Lima"], "title": "Structure-Informed Estimation for Pilot-Limited MIMO Channels via Tensor Decomposition", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Channel estimation in wideband multiple-input multiple-output (MIMO) systems faces fundamental pilot overhead limitations in high-dimensional beyond-5G and sixth-generation (6G) scenarios. This paper presents a hybrid tensor-neural architecture that formulates pilot-limited channel estimation as low-rank tensor completion from sparse observations -- a fundamentally different setting from prior tensor methods that assume fully observed received signal tensors. A canonical polyadic (CP) baseline implemented via a projection-based scheme (Tucker completion under partial observations) and Tucker decompositions are compared under varying signal-to-noise ratio (SNR) and scattering conditions: CP performs well for specular channels matching the multipath model, while Tucker provides greater robustness under model mismatch. A lightweight three-dimensional (3D) U-Net learns residual components beyond the low-rank structure, bridging algebraic models and realistic propagation effects. Empirical recovery threshold analysis shows that sample complexity scales approximately with intrinsic model dimensionality $L(N_r + N_t + N_f)$ rather than ambient tensor size $N_r N_t N_f$, where $L$ denotes the number of dominant propagation paths. Experiments on synthetic channels demonstrate 10-20\\,dB normalized mean-square error (NMSE) improvement over least-squares (LS) and orthogonal matching pursuit (OMP) baselines at 5-10\\% pilot density, while evaluations on DeepMIMO ray-tracing channels show 24-44\\% additional NMSE reduction over pure tensor-based methods.", "AI": {"tldr": "提出了一种基于张量分解的结构化估计方法，用于解决高维度MIMO系统中的信道估计问题。", "motivation": "在高维度的beyond-5G和6G场景中，宽频带MIMO系统的信道估计面临着基本的导频开销限制。", "method": "提出了一种混合张量神经网络架构，将有限导频情况下的信道估计问题表述为从稀疏观测到低秩张量补全的问题，并通过CP和Tucker分解方法进行比较。", "result": "实验结果表明，在5-10%的导频密度下，该方法相比LS和OMP基准线能够实现10-20dB归一化均方误差（NMSE）的改进；在DeepMIMO射线追踪信道中则能进一步降低44%的NMSE。", "conclusion": "通过引入张量分解技术，解决了高维度MIMO系统中的信道估计问题，并展示了优于传统方法的优势。"}}
{"id": "2602.04078", "pdf": "https://arxiv.org/pdf/2602.04078", "abs": "https://arxiv.org/abs/2602.04078", "authors": ["Róisín Luo"], "title": "Principles of Lipschitz continuity in neural networks", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Ph.D. Thesis", "summary": "Deep learning has achieved remarkable success across a wide range of domains, significantly expanding the frontiers of what is achievable in artificial intelligence. Yet, despite these advances, critical challenges remain -- most notably, ensuring robustness to small input perturbations and generalization to out-of-distribution data. These critical challenges underscore the need to understand the underlying fundamental principles that govern robustness and generalization. Among the theoretical tools available, Lipschitz continuity plays a pivotal role in governing the fundamental properties of neural networks related to robustness and generalization. It quantifies the worst-case sensitivity of network's outputs to small input perturbations. While its importance is widely acknowledged, prior research has predominantly focused on empirical regularization approaches based on Lipschitz constraints, leaving the underlying principles less explored. This thesis seeks to advance a principled understanding of the principles of Lipschitz continuity in neural networks within the paradigm of machine learning, examined from two complementary perspectives: an internal perspective -- focusing on the temporal evolution of Lipschitz continuity in neural networks during training (i.e., training dynamics); and an external perspective -- investigating how Lipschitz continuity modulates the behavior of neural networks with respect to features in the input data, particularly its role in governing frequency signal propagation (i.e., modulation of frequency signal propagation).", "AI": {"tldr": "本文探讨了神经网络中Lipschitz连续性的基本原则，从训练动态和频率信号传播两个角度进行研究。", "motivation": "尽管深度学习取得了巨大成功，但仍然面临稳健性和泛化的挑战。Lipschitz连续性是理解这些基本属性的关键工具，但在实践中应用较少。", "method": "本文从内部视角探讨了在训练过程中的Lipschitz连续性的演变，并从外部视角研究了它如何影响输入数据的特征传播。", "result": "结果表明，通过探索Lipschitz连续性可以更好地理解神经网络在面对小扰动时的表现及泛化能力。", "conclusion": "本论文提出的方法有助于深入理解深度学习模型中的稳健性和泛化原则。"}}
{"id": "2602.04076", "pdf": "https://arxiv.org/pdf/2602.04076", "abs": "https://arxiv.org/abs/2602.04076", "authors": ["Daniyal Maroufi", "Yash Kulkarni", "Justin E. Bird", "Jeffrey H. Siewerdsen", "Farshid Alambeigi"], "title": "Comparative Analysis of Autonomous Robotic and Manual Techniques for Ultrasonic Sacral Osteotomy: A Preliminary Study", "categories": ["cs.RO"], "comment": "17 pages, 6 figures, Accepted or publication in 2026 International Symposium on Medical Robotics (ISMR)", "summary": "In this paper, we introduce an autonomous Ultrasonic Sacral Osteotomy (USO) robotic system that integrates an ultrasonic osteotome with a seven-degree-of-freedom (DoF) robotic manipulator guided by an optical tracking system. To assess multi-directional control along both the surface trajectory and cutting depth of this system, we conducted quantitative comparisons between manual USO (MUSO) and robotic USO (RUSO) in Sawbones phantoms under identical osteotomy conditions. The RUSO system achieved sub-millimeter trajectory accuracy (0.11 mm RMSE), an order of magnitude improvement over MUSO (1.10 mm RMSE). Moreover, MUSO trials showed substantial over-penetration (16.0 mm achieved vs. 8.0 mm target), whereas the RUSO system maintained precise depth control (8.1 mm). These results demonstrate that robotic procedures can effectively overcome the critical limitations of manual osteotomy, establishing a foundation for safer and more precise sacral resections.", "AI": {"tldr": "比较自主机器人与手动技术在骶骨超声骨切术中的效果", "motivation": "评估集成光学跟踪系统的七自由度机械臂引导的自动化超声骨切术（RUSO）系统相对于传统手动骨切术（MUSO）的优势，以克服手动操作的关键限制，提高手术安全性与精度。", "method": "在相同骨切条件下，通过使用Sawbones模型进行定量比较研究RUSO和MUSO的表面轨迹控制及切割深度准确性", "result": "RUSO系统的轨迹准确度为0.11毫米均方根误差（RMSE），远优于手动操作的1.10毫米；在靶向8.0毫米的切割深度中，MUSO组显示了过度穿透现象（达到16.0毫米），而RUSO系统则保持了精确控制（实际切割深度为8.1毫米）", "conclusion": "自主机器人技术可有效克服手动骨切术的关键局限性，提供更安全、精准的骶骨切除手术基础"}}
{"id": "2602.04063", "pdf": "https://arxiv.org/pdf/2602.04063", "abs": "https://arxiv.org/abs/2602.04063", "authors": ["Jacob S. Leiby", "Jialu Yao", "Pan Lu", "George Hu", "Anna Davidian", "Shunsuke Koga", "Olivia Leung", "Pravin Patel", "Isabella Tondi Resta", "Rebecca Rojansky", "Derek Sung", "Eric Yang", "Paul J. Zhang", "Emma Lundberg", "Dokyoon Kim", "Serena Yeung-Levy", "James Zou", "Thomas Montine", "Jeffrey Nirschl", "Zhi Huang"], "title": "iSight: Towards expert-AI co-assessment for improved immunohistochemistry staining interpretation", "categories": ["cs.CV"], "comment": null, "summary": "Immunohistochemistry (IHC) provides information on protein expression in tissue sections and is commonly used to support pathology diagnosis and disease triage. While AI models for H\\&E-stained slides show promise, their applicability to IHC is limited due to domain-specific variations. Here we introduce HPA10M, a dataset that contains 10,495,672 IHC images from the Human Protein Atlas with comprehensive metadata included, and encompasses 45 normal tissue types and 20 major cancer types. Based on HPA10M, we trained iSight, a multi-task learning framework for automated IHC staining assessment. iSight combines visual features from whole-slide images with tissue metadata through a token-level attention mechanism, simultaneously predicting staining intensity, location, quantity, tissue type, and malignancy status. On held-out data, iSight achieved 85.5\\% accuracy for location, 76.6\\% for intensity, and 75.7\\% for quantity, outperforming fine-tuned foundation models (PLIP, CONCH) by 2.5--10.2\\%. In addition, iSight demonstrates well-calibrated predictions with expected calibration errors of 0.0150-0.0408. Furthermore, in a user study with eight pathologists evaluating 200 images from two datasets, iSight outperformed initial pathologist assessments on the held-out HPA dataset (79\\% vs 68\\% for location, 70\\% vs 57\\% for intensity, 68\\% vs 52\\% for quantity). Inter-pathologist agreement also improved after AI assistance in both held-out HPA (Cohen's $κ$ increased from 0.63 to 0.70) and Stanford TMAD datasets (from 0.74 to 0.76), suggesting expert--AI co-assessment can improve IHC interpretation. This work establishes a foundation for AI systems that can improve IHC diagnostic accuracy and highlights the potential for integrating iSight into clinical workflows to enhance the consistency and reliability of IHC assessment.", "AI": {"tldr": "本文提出了iSight，一个基于HPA10M数据集的多任务学习框架，用于自动评估免疫组化（IHC）染色，并展示了其在提高病理学家诊断准确性方面的潜力。", "motivation": "AI模型在H&E染色切片的应用显示出前景，但在免疫组化的应用上受限于特定领域的变化。因此，本文旨在通过引入大规模的HPA10M数据集和开发iSight框架来改善IHC染色解释，提高病理学诊断准确性。", "method": "基于HPA10M数据集，训练了多任务学习框架iSight，该框架结合了整个切片图像的视觉特征与组织元数据并通过令牌级别注意机制同时预测染色强度、位置和数量等。进行了用户研究，使用8名病理学家评估200张来自两个数据集的图片。", "result": "在测试数据上，iSight实现了85.5%的位置准确性，76.6%的颜色深度准确性和75.7%的数量准确性，并且超过了微调基础模型（PLIP、CONCH）的表现。病理学家在AI辅助下的评估结果也得到了改善。", "conclusion": "该研究证明了iSight框架可以提高免疫组化诊断的准确性和一致性，为临床工作流程中的AI系统奠定了基础。"}}
{"id": "2602.04059", "pdf": "https://arxiv.org/pdf/2602.04059", "abs": "https://arxiv.org/abs/2602.04059", "authors": ["Bin Fu", "Yumei Huo", "Hairong Zhao"], "title": "Minimizing Makespan in Sublinear Time via Weighted Random Sampling", "categories": ["cs.DS"], "comment": null, "summary": "We consider the classical makespan minimization scheduling problem where $n$ jobs must be scheduled on $m$ identical machines. Using weighted random sampling, we developed two sublinear time approximation schemes: one for the case where $n$ is known and the other for the case where $n$ is unknown. Both algorithms not only give a $(1+3ε)$-approximation to the optimal makespan but also generate a sketch schedule. Our first algorithm, which targets the case where $n$ is known and draws samples in a single round under weighted random sampling, has a running time of $\\tilde{O}(\\tfrac{m^5}{ε^4} \\sqrt{n}+A(\\ceiling{m\\over ε}, ε ))$, where $A(\\mathcal{N}, α)$ is the time complexity of any $(1+α)$-approximation scheme for the makespan minimization of $\\mathcal{N}$ jobs. The second algorithm addresses the case where $n$ is unknown. It uses adaptive weighted random sampling, %\\textit{that is}, it draws samples in several rounds, adjusting the number of samples after each round, and runs in sublinear time $\\tilde{O}\\left( \\tfrac{m^5} {ε^4} \\sqrt{n} + A(\\ceiling{m\\over ε}, ε )\\right)$. We also provide an implementation that generates a weighted random sample using $O(\\log n)$ uniform random samples.", "AI": {"tldr": "通过加权随机采样开发了两种次线性时间近似方案，以最小化相同机器上的作业调度的最长时间（makespan）。", "motivation": "解决经典任务调度问题，在未知或已知作业数量的情况下使用加权随机抽样的方法来减少最长时间。\r\n", "method": "提出了一种针对已知作业数量的单一轮次采样算法，另一种是处理未知作业数量的情况，采用自适应加权随机抽样。", "result": "两种算法均提供了$(1+3ε)$-近似解，并且都生成了调度草图。运行时间主要依赖于机器数和误差参数。\r\n", "conclusion": "通过加权随机采样的方法可以有效地解决次线性时间内的任务调度问题，具有广泛的应用潜力。"}}
{"id": "2602.04057", "pdf": "https://arxiv.org/pdf/2602.04057", "abs": "https://arxiv.org/abs/2602.04057", "authors": ["Riming Xu", "Obadah Wali", "Yasmine Marani", "Eric Feron"], "title": "Control and State Estimation of Vehicle-Mounted Aerial Systems in GPS-Denied, Non-Inertial Environments", "categories": ["cs.RO", "eess.SY"], "comment": "10 pages 8 figures", "summary": "We present a robust control and estimation framework for quadrotors operating in Global Navigation Satellite System(GNSS)-denied, non-inertial environments where inertial sensors such as Inertial Measurement Units (IMUs) become unreliable due to platform-induced accelerations. In such settings, conventional estimators fail to distinguish whether the measured accelerations arise from the quadrotor itself or from the non-inertial platform, leading to drift and control degradation. Unlike conventional approaches that depend heavily on IMU and GNSS, our method relies exclusively on external position measurements combined with a Extended Kalman Filter with Unknown Inputs (EKF-UI) to account for platform motion. The estimator is paired with a cascaded PID controller for full 3D tracking. To isolate estimator performance from localization errors, all tests are conducted using high-precision motion capture systems. Experimental results in a moving-cart testbed validate our approach under both translational in X-axis and Y-axis dissonance. Compared to standard EKF, the proposed method significantly improves stability and trajectory tracking without requiring inertial feedback, enabling practical deployment on moving platforms such as trucks or elevators.", "AI": {"tldr": "提出了在GPS缺失且非惯性环境中，利用外部位置测量和扩展卡尔曼滤波器（EKF-UI）结合PID控制器的四旋翼飞行控制系统。", "motivation": "为解决GNSS缺失且平台自加速导致的传统IMU不可靠的问题，提供一种不依赖于IMU或GNSS的稳健控制与估计框架。", "method": "利用外部位置测量和扩展卡尔曼滤波器（EKF-UI）结合PID控制器进行全3D轨迹跟踪。测试中使用高精度运动捕捉系统以隔离定位误差影响。", "result": "实验在移动平台上的结果表明，相比于标准EKF方法，该技术显著提高了稳定性和轨迹跟踪性能。", "conclusion": "该研究提供了一种适用于非惯性环境的飞行控制系统，实现了不需要惯性反馈的稳定和精确控制。"}}
{"id": "2602.04056", "pdf": "https://arxiv.org/pdf/2602.04056", "abs": "https://arxiv.org/abs/2602.04056", "authors": ["Joonkyung Kim", "Wenxi Chen", "Davood Soleymanzadeh", "Yi Ding", "Xiangbo Gao", "Zhengzhong Tu", "Ruqi Zhang", "Fan Fei", "Sushant Veer", "Yiwei Lyu", "Minghui Zheng", "Yan Gu"], "title": "Modular Safety Guardrails Are Necessary for Foundation-Model-Enabled Robots in the Real World", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "The integration of foundation models (FMs) into robotics has accelerated real-world deployment, while introducing new safety challenges arising from open-ended semantic reasoning and embodied physical action. These challenges require safety notions beyond physical constraint satisfaction. In this paper, we characterize FM-enabled robot safety along three dimensions: action safety (physical feasibility and constraint compliance), decision safety (semantic and contextual appropriateness), and human-centered safety (conformance to human intent, norms, and expectations). We argue that existing approaches, including static verification, monolithic controllers, and end-to-end learned policies, are insufficient in settings where tasks, environments, and human expectations are open-ended, long-tailed, and subject to adaptation over time. To address this gap, we propose modular safety guardrails, consisting of monitoring (evaluation) and intervention layers, as an architectural foundation for comprehensive safety across the autonomy stack. Beyond modularity, we highlight possible cross-layer co-design opportunities through representation alignment and conservatism allocation to enable faster, less conservative, and more effective safety enforcement. We call on the community to explore richer guardrail modules and principled co-design strategies to advance safe real-world physical AI deployment.", "AI": {"tldr": "提出模块化安全防护措施来应对基础模型集成到机器人中的新安全挑战，以确保其在开放环境下的安全性。", "motivation": "现有方法无法满足任务、环境和人类期望多变且不断适应的条件下实现全面的安全性，因此需要新的安全架构来保障基于基础模型机器人的实际部署。", "method": "提出了一种由监控层（评估）和干预层组成的模块化安全防护措施框架，并强调跨层协同设计的机会以提高安全性。", "result": "通过模块化安全防护策略及多层协作设计，可以更有效地实现对基于基础模型机器人的全面安全保障。", "conclusion": "未来需要进一步探索更多样化的安全防护组件和原则性协同设计方法来促进物理AI在实际环境中的安全部署。"}}
{"id": "2602.04054", "pdf": "https://arxiv.org/pdf/2602.04054", "abs": "https://arxiv.org/abs/2602.04054", "authors": ["Huahua Lin", "Katayoun Farrahi", "Xiaohao Cai"], "title": "SEIS: Subspace-based Equivariance and Invariance Scores for Neural Representations", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Understanding how neural representations respond to geometric transformations is essential for evaluating whether learned features preserve meaningful spatial structure. Existing approaches primarily assess robustness by comparing model outputs under transformed inputs, offering limited insight into how geometric information is organized within internal representations and failing to distinguish between information loss and re-encoding. In this work, we introduce SEIS (Subspace-based Equivariance and Invariance Scores), a subspace metric for analyzing layer-wise feature representations under geometric transformations, disentangling equivariance from invariance without requiring labels or explicit knowledge of the transformation. Synthetic validation confirms that SEIS correctly recovers known transformations. Applied to trained classification networks, SEIS reveals a transition from equivariance in early layers to invariance in deeper layers, and that data augmentation increases invariance while preserving equivariance. We further show that multi-task learning induces synergistic gains in both properties at the shared encoder, and skip connections restore equivariance lost during decoding.", "AI": {"tldr": "提出SEIS方法，用于分析神经网络在几何变换下的特征表示，并区分等变性和不变性。", "motivation": "现有评估方法主要通过比较模型输出来评价鲁棒性，但无法深入理解内部表示中的几何信息组织情况以及区分信息丢失和重新编码。引入SEIS以解决此问题。", "method": "使用基于子空间的度量标准分析层级特征在几何变换下的表现，并分离出等变性和不变性的特性。", "result": "通过合成验证确认SEIS能准确恢复已知变换；应用于训练网络发现早期层趋向等变性，深层趋向不变性；数据增强增加了不变性但保留了等变性。同时，多任务学习和跳过连接也展示了相应的效果。", "conclusion": "SEIS提供了一种无需标签或显式转换知识即可分析神经表示在几何变换下特征的新方法。"}}
{"id": "2602.04053", "pdf": "https://arxiv.org/pdf/2602.04053", "abs": "https://arxiv.org/abs/2602.04053", "authors": ["Rio Aguina-Kang", "Kevin James Blackburn-Matzen", "Thibault Groueix", "Vladimir Kim", "Matheus Gadelha"], "title": "Seeing Through Clutter: Structured 3D Scene Reconstruction via Iterative Object Removal", "categories": ["cs.CV"], "comment": "To appear in 3DV 2026", "summary": "We present SeeingThroughClutter, a method for reconstructing structured 3D representations from single images by segmenting and modeling objects individually. Prior approaches rely on intermediate tasks such as semantic segmentation and depth estimation, which often underperform in complex scenes, particularly in the presence of occlusion and clutter. We address this by introducing an iterative object removal and reconstruction pipeline that decomposes complex scenes into a sequence of simpler subtasks. Using VLMs as orchestrators, foreground objects are removed one at a time via detection, segmentation, object removal, and 3D fitting. We show that removing objects allows for cleaner segmentations of subsequent objects, even in highly occluded scenes. Our method requires no task-specific training and benefits directly from ongoing advances in foundation models. We demonstrate stateof-the-art robustness on 3D-Front and ADE20K datasets. Project Page: https://rioak.github.io/seeingthroughclutter/", "AI": {"tldr": "通过迭代删除对象的方式，从单张图像中重建结构化的三维场景。", "motivation": "现有的方法依赖于语义分割和深度估计等中间任务，在复杂场景特别是存在遮挡和杂乱的情况下表现不佳。为了改善这一问题，提出了SeeingThroughClutter方法。", "method": "使用迭代对象移除与重构管道将复杂的场景分解为一系列简单的子任务，通过视觉语言模型作为协调者，逐个删除前景物体，并进行检测、分割、对象移除以及三维拟合。", "result": "该方法展示了在3D-Front和ADE20K数据集上的先进鲁棒性。", "conclusion": "SeeingThroughClutter方法提供了一种有效解决复杂场景结构化三维重建问题的新途径。"}}
{"id": "2602.04051", "pdf": "https://arxiv.org/pdf/2602.04051", "abs": "https://arxiv.org/abs/2602.04051", "authors": ["Juntao Zhang", "Angona Biswas", "Jaydeep Rade", "Charchit Shukla", "Juan Ren", "Anwesha Sarkar", "Adarsh Krishnamurthy", "Aditya Balu"], "title": "Artifact Removal and Image Restoration in AFM:A Structured Mask-Guided Directional Inpainting Approach", "categories": ["cs.CV"], "comment": null, "summary": "Atomic Force Microscopy (AFM) enables high-resolution surface imaging at the nanoscale, yet the output is often degraded by artifacts introduced by environmental noise, scanning imperfections, and tip-sample interactions. To address this challenge, a lightweight and fully automated framework for artifact detection and restoration in AFM image analysis is presented. The pipeline begins with a classification model that determines whether an AFM image contains artifacts. If necessary, a lightweight semantic segmentation network, custom-designed and trained on AFM data, is applied to generate precise artifact masks. These masks are adaptively expanded based on their structural orientation and then inpainted using a directional neighbor-based interpolation strategy to preserve 3D surface continuity. A localized Gaussian smoothing operation is then applied for seamless restoration. The system is integrated into a user-friendly GUI that supports real-time parameter adjustments and batch processing. Experimental results demonstrate the effective artifact removal while preserving nanoscale structural details, providing a robust, geometry-aware solution for high-fidelity AFM data interpretation.", "AI": {"tldr": "该论文提出了一种轻量级且全自动的框架，用于原子力显微镜（AFM）图像中的缺陷检测和修复。", "motivation": "为了提高AFM成像质量，减少环境噪声、扫描不完善及针尖-样品相互作用引起的瑕疵影响。", "method": "首先使用分类模型判断是否含有瑕疵，然后采用轻量级语义分割网络生成精确的瑕疵掩模，并根据结构方向自适应扩展后进行定向邻域插值修复。最后通过局部高斯平滑实现无缝恢复。", "result": "实验结果显示该方法能够有效地移除缺陷同时保留纳米尺度下的结构细节。", "conclusion": "提出的方法为高质量AFM数据解释提供了一种可靠且几何感知的解决方案，具有重要的应用价值。"}}
{"id": "2602.04050", "pdf": "https://arxiv.org/pdf/2602.04050", "abs": "https://arxiv.org/abs/2602.04050", "authors": ["Aabha Tamhankar", "Jay Patil", "Giovanni Pittiglio"], "title": "An Anatomy-specific Guidewire Shaping Robot for Improved Vascular Navigation", "categories": ["cs.RO"], "comment": "7 pages, 7 figures, ISMR2026", "summary": "Neuroendovascular access often relies on passive microwires that are hand-shaped at the back table and then used to track a microcatheter to the target. Neuroendovascular surgeons determine the shape of the wire by examining the patient pre-operative images and using their experience to identify anatomy specific shapes of the wire that would facilitate reaching the target. This procedure is particularly complex in convoluted anatomical structures and is heavily dependent on the level of expertise of the surgeon. Towards enabling standardized autonomous shaping, we present a bench-top guidewire shaping robot capable of producing navigation-specific desired wire configurations. We present a model that can map the desired wire shape into robot actions, calibrated using experimental data. We show that the robot can produce clinically common tip geometries (C, S, Angled, Hook) and validate them with respect to the model-predicted shapes in 2D. Our model predicts the shape with a Root Mean Square (RMS) error of 0.56mm across all shapes when compared to the experimental results. We also demonstrate 3D tip shaping capabilities and the ability to traverse complex endoluminal navigation from the petrous Internal Carotid Artery (ICA) to the Posterior Communicating Artery (PComm).", "AI": {"tldr": "本文介绍了一种用于改善血管导航的手动导丝成形机器人的研发。", "motivation": "神经内血管通路通常依赖手工成形的微细线，这种过程在复杂的解剖结构中尤其复杂，并且严重依赖于外科医生的经验水平。为了实现标准化和自动化的成形过程，作者开发了一种基于工作台的手动导丝成形机器人。", "method": "该团队设计并验证了一个可以将期望导丝形状转换为机械动作的模型，通过实验数据进行校准，并展示了该机器人能够生成多种常见临床导丝几何形态（C, S, 角度, 钩型）的能力。同时，他们还演示了在三维空间中成形导丝尖端以及复杂内腔导航的功能。", "result": "模型预测的形状与实验结果相比，在所有形状下的均方根误差为0.56毫米。该机器人能够生成临床常见的四种典型导丝几何形态，并成功地实现了从岩部颈动脉到后交通动脉的复杂内腔导航。", "conclusion": "所研发的手动导丝成形机器人在血管导航中表现出优异的表现，有助于实现标准化和自动化的手动导丝成形过程。"}}
{"id": "2602.04047", "pdf": "https://arxiv.org/pdf/2602.04047", "abs": "https://arxiv.org/abs/2602.04047", "authors": ["Yijun Liu", "John Gallagher", "Sarah Sterman", "Tal August"], "title": "From Crafting Text to Crafting Thought: Grounding AI Writing Support to Writing Center Pedagogy", "categories": ["cs.HC"], "comment": "Conditionally accepted to CHI 26", "summary": "As AI writing tools evolve from fixing surface errors to creating language with writers, new capabilities raise concerns about negative impacts on student writers, such as replacing their voices and undermining critical thinking skills. To address these challenges, we look at a parallel transition in university writing centers from focusing on fixing errors to preserving student voices. We develop design guidelines informed by writing center literature and interviews with 10 writing tutors. We illustrate these guidelines in a prototype AI tool, Writor. Writor helps writers revise text by setting goals, providing balanced feedback, and engaging in conversations without generating text verbatim. We conducted an expert review with 30 writing instructors, tutors, and AI researchers on Writor to assess the pedagogical soundness, alignment with writing center pedagogy, and integration contexts. We distill our findings into design implications for future AI writing feedback systems, including designing for trust among AI-skeptical educators.", "AI": {"tldr": "开发一种基于写作中心教学法的AI写作支持工具Writor，旨在帮助学生进行文本修订并保护其声音。", "motivation": "随着AI写作工具从纠正表面错误转向创造语言，这引发了对学生作家可能被取代和批判性思维能力受损的关注。因此，研究者借鉴大学写作中心的教学方法来设计新的写作辅助工具。", "method": "通过引用写作中心文献以及对10位写作导师的访谈开发了设计方案，并在原型AI工具Writor上进行了实现。此外，还邀请了30位写作教师、导师和AI研究人员进行专家评审以评估其教育价值和与写作教学法的一致性。", "result": "Writor帮助学生设定目标、提供平衡反馈并参与对话而不直接生成文本，经过专家评审被确认符合写作中心的教学原则。", "conclusion": "研究结果为未来的AI写作反馈系统设计提供了指导原则，特别是强调在教育者对AI持怀疑态度的情况下构建信任的重要性。"}}
{"id": "2602.04046", "pdf": "https://arxiv.org/pdf/2602.04046", "abs": "https://arxiv.org/abs/2602.04046", "authors": ["Shikha Dubey", "Patricia Raciti", "Kristopher Standish", "Albert Juan Ramon", "Erik Ames Burlingame"], "title": "Fast, Unsupervised Framework for Registration Quality Assessment of Multi-stain Histological Whole Slide Pairs", "categories": ["cs.CV"], "comment": "Accepted to IEEE ISBI 2026", "summary": "High-fidelity registration of histopathological whole slide images (WSIs), such as hematoxylin & eosin (H&E) and immunohistochemistry (IHC), is vital for integrated molecular analysis but challenging to evaluate without ground-truth (GT) annotations. Existing WSI-level assessments -- using annotated landmarks or intensity-based similarity metrics -- are often time-consuming, unreliable, and computationally intensive, limiting large-scale applicability. This study proposes a fast, unsupervised framework that jointly employs down-sampled tissue masks- and deformations-based metrics for registration quality assessment (RQA) of registered H&E and IHC WSI pairs. The masks-based metrics measure global structural correspondence, while the deformations-based metrics evaluate local smoothness, continuity, and transformation realism. Validation across multiple IHC markers and multi-expert assessments demonstrate a strong correlation between automated metrics and human evaluations. In the absence of GT, this framework offers reliable, real-time RQA with high fidelity and minimal computational resources, making it suitable for large-scale quality control in digital pathology.", "AI": {"tldr": "提出了一种快速无监督框架，用于评估多染色组织病理学全切片配准质量。", "motivation": "传统WSI注册质量评估方法耗时、依赖人工标注且计算资源消耗大，难以大规模应用。为此，本文旨在开发一种无需地面真值即可实现可靠实时评估的方法。", "method": "利用下采样组织掩膜和变形度量共同衡量配准图像的全局结构一致性和局部平滑性。", "result": "实验证明了所提框架能够在多标记物上与人工评价高度相关，表明其有效性和准确性。", "conclusion": "该方法提供了一种可靠、实时且资源消耗低的评估方案，适用于大规模数字化病理学质量控制。"}}
{"id": "2602.04044", "pdf": "https://arxiv.org/pdf/2602.04044", "abs": "https://arxiv.org/abs/2602.04044", "authors": ["Panagiotis Mousouliotis", "Georgios Keramidas"], "title": "A Parameterizable Convolution Accelerator for Embedded Deep Learning Applications", "categories": ["cs.CV", "cs.AR"], "comment": "6 pages, 4 figures. Published in the proceedings of the 2025 IEEE Computer Society Annual Symposium on VLSI (ISVLSI 2025), Kalamata, Greece, 6-9 July 2025", "summary": "Convolutional neural network (CNN) accelerators implemented on Field-Programmable Gate Arrays (FPGAs) are typically designed with a primary focus on maximizing performance, often measured in giga-operations per second (GOPS). However, real-life embedded deep learning (DL) applications impose multiple constraints related to latency, power consumption, area, and cost. This work presents a hardware-software (HW/SW) co-design methodology in which a CNN accelerator is described using high-level synthesis (HLS) tools that ease the parameterization of the design, facilitating more effective optimizations across multiple design constraints. Our experimental results demonstrate that the proposed design methodology is able to outperform non-parameterized design approaches, and it can be easily extended to other types of DL applications.", "AI": {"tldr": "本文提出了一种基于FPGA的可参数化卷积加速器的设计方法，以应对嵌入式深度学习应用中的多种约束。", "motivation": "传统的CNN加速器设计主要关注性能指标，而忽略了实际嵌入式DL应用中对延迟、功耗、面积和成本的要求。因此，需要一种新的设计方法来优化这些多方面的约束条件。", "method": "本文采用硬件-软件协同设计的方法，利用高层次综合工具描述卷积神经网络加速器的设计，并通过参数化简化了设计的调整过程。", "result": "实验结果表明，所提出的设计方法优于非参数化设计方法，并且可以应用于其他类型的深度学习应用。", "conclusion": "提出的可参数化CNN加速器设计方法能够更好地满足嵌入式DL应用中的多种约束要求。"}}
{"id": "2602.04043", "pdf": "https://arxiv.org/pdf/2602.04043", "abs": "https://arxiv.org/abs/2602.04043", "authors": ["Joanna Kaleta", "Bartosz Świrta", "Kacper Kania", "Przemysław Spurek", "Marek Kowalski"], "title": "AnyStyle: Single-Pass Multimodal Stylization for 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "The growing demand for rapid and scalable 3D asset creation has driven interest in feed-forward 3D reconstruction methods, with 3D Gaussian Splatting (3DGS) emerging as an effective scene representation. While recent approaches have demonstrated pose-free reconstruction from unposed image collections, integrating stylization or appearance control into such pipelines remains underexplored. Existing attempts largely rely on image-based conditioning, which limits both controllability and flexibility. In this work, we introduce AnyStyle, a feed-forward 3D reconstruction and stylization framework that enables pose-free, zero-shot stylization through multimodal conditioning. Our method supports both textual and visual style inputs, allowing users to control the scene appearance using natural language descriptions or reference images. We propose a modular stylization architecture that requires only minimal architectural modifications and can be integrated into existing feed-forward 3D reconstruction backbones. Experiments demonstrate that AnyStyle improves style controllability over prior feed-forward stylization methods while preserving high-quality geometric reconstruction. A user study further confirms that AnyStyle achieves superior stylization quality compared to an existing state-of-the-art approach. Repository: https://github.com/joaxkal/AnyStyle.", "AI": {"tldr": "AnyStyle是一种通过多模态条件输入实现无姿态自由、零样本风格化的三维重建框架。", "motivation": "现有的基于图像的条件化方法限制了可控制性和灵活性，因此提出了AnyStyle来解决这个问题。", "method": "提出了一种模块化的风格化架构，该架构只需要对现有前馈3D重建骨干网络进行最少的结构修改即可集成。", "result": "实验表明，与现有的前馈式风格化方法相比，AnyStyle在保持高质量几何重建的同时提高了风格控制性。用户研究进一步证实了其在风格化质量方面的优越性。", "conclusion": "AnyStyle为三维场景提供了高效且灵活的风格控制方式，在风格化质量和几何重建方面均表现优异。"}}
{"id": "2602.04037", "pdf": "https://arxiv.org/pdf/2602.04037", "abs": "https://arxiv.org/abs/2602.04037", "authors": ["Pengcheng Wang", "Qinghang Liu", "Haotian Lin", "Yiheng Li", "Guojian Zhan", "Masayoshi Tomizuka", "Yixiao Wang"], "title": "DADP: Domain Adaptive Diffusion Policy", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Learning domain adaptive policies that can generalize to unseen transition dynamics, remains a fundamental challenge in learning-based control. Substantial progress has been made through domain representation learning to capture domain-specific information, thus enabling domain-aware decision making. We analyze the process of learning domain representations through dynamical prediction and find that selecting contexts adjacent to the current step causes the learned representations to entangle static domain information with varying dynamical properties. Such mixture can confuse the conditioned policy, thereby constraining zero-shot adaptation. To tackle the challenge, we propose DADP (Domain Adaptive Diffusion Policy), which achieves robust adaptation through unsupervised disentanglement and domain-aware diffusion injection. First, we introduce Lagged Context Dynamical Prediction, a strategy that conditions future state estimation on a historical offset context; by increasing this temporal gap, we unsupervisedly disentangle static domain representations by filtering out transient properties. Second, we integrate the learned domain representations directly into the generative process by biasing the prior distribution and reformulating the diffusion target. Extensive experiments on challenging benchmarks across locomotion and manipulation demonstrate the superior performance, and the generalizability of DADP over prior methods. More visualization results are available on the https://outsider86.github.io/DomainAdaptiveDiffusionPolicy/.", "AI": {"tldr": "该论文提出了DADP算法，旨在解决领域自适应策略学习中的挑战，使控制策略能够泛化到未见的动力学转移中。", "motivation": "在基于学习的控制任务中，如何通过域表征学习来捕获特定信息并实现域感知决策是一个关键问题。然而，在当前步骤选择相邻上下文会导致学到的表示混淆静态领域信息和动态特性，从而限制了零样本适应能力。", "method": "该方法包括Lagged Context Dynamical Prediction策略以无监督方式解耦静态表征，并将学习到的域表征整合进生成过程。", "result": "实验结果表明DADP算法在运动控制与机械操作等挑战性任务中表现优越，优于先前的方法。", "conclusion": "通过提出的DADP方法可以实现更稳健和泛化的领域自适应策略。"}}
{"id": "2602.04035", "pdf": "https://arxiv.org/pdf/2602.04035", "abs": "https://arxiv.org/abs/2602.04035", "authors": ["Thomas Neuner", "Henriette Padberg", "Lior Kornblum", "Eilam Yalon", "Pedram Khalili Amiri", "Shahar Kvatinsky"], "title": "A Comparative Study of Digital Memristor-Based Processing-In-Memory from a Device and Reliability Perspective", "categories": ["cs.ET"], "comment": "23 pages, 12 figures, 3 tables, invited review paper, published in: https://advanced.onlinelibrary.wiley.com/doi/full/10.1002/aelm.202500348, T. Neuner and H. Padberg contributed equally to the work, S. Kvatinsky is the corresponding author", "summary": "As data-intensive applications increasingly strain conventional computing systems, processing-in-memory (PIM) has emerged as a promising paradigm to alleviate the memory wall by minimizing data transfer between memory and processing units. This review presents the recent advances in both stateful and non-stateful logic techniques for PIM, focusing on emerging nonvolatile memory technologies such as resistive random-access memory (RRAM), phase-change memory (PCM), and magnetoresistive random-access memory (MRAM). Both experimentally demonstrated and simulated logic designs are critically examined, highlighting key challenges in reliability and the role of device-level optimization in enabling scalable and commercial viable PIM systems. The review begins with an overview of relevant logic families, memristive device types, and associated reliability metrics. Each logic family is then explored in terms of how it capitalizes on distinct device properties to implement logic techniques. A comparative table of representative device stacks and performance parameters illustrates trade-offs and quality indicators. Through this comprehensive analysis, the development of optimized, robust memristive devices for next-generation PIM applications is supported.", "AI": {"tldr": "本文对比研究了基于数字忆阻器的处理内存储（PIM）技术，重点关注其可靠性和器件优化。", "motivation": "随着数据密集型应用对传统计算系统的压力增大，处理内存储被提出作为一种减轻内存墙问题的有效方案。通过最小化内存与处理单元之间的数据传输来提升系统性能。", "method": "文章首先概述了相关的逻辑家族、忆阻器类型和可靠性指标，并详细研究了不同逻辑家族如何利用特定的器件特性实现逻辑技术，最后对比总结代表性设备堆栈及其性能参数。", "result": "本文通过全面分析各种处理内存储设计的优势与劣势，展示了如何通过优化忆阻器来支持下一代PIM应用的发展。", "conclusion": "文章综述了目前基于数字忆阻器的PIM技术进展，并指出了未来研究中需要关注的关键挑战和改进方向。"}}
{"id": "2602.04033", "pdf": "https://arxiv.org/pdf/2602.04033", "abs": "https://arxiv.org/abs/2602.04033", "authors": ["Jindřich Libovický"], "title": "On the Credibility of Evaluating LLMs using Survey Questions", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Accepted to the Workshop on Multilingual and Multicultural Evaluation at EACL 2026, 12 pages, 2 figures", "summary": "Recent studies evaluate the value orientation of large language models (LLMs) using adapted social surveys, typically by prompting models with survey questions and comparing their responses to average human responses. This paper identifies limitations in this methodology that, depending on the exact setup, can lead to both underestimating and overestimating the similarity of value orientation. Using the World Value Survey in three languages across five countries, we demonstrate that prompting methods (direct vs. chain-of-thought) and decoding strategies (greedy vs. sampling) significantly affect results. To assess the interaction between answers, we introduce a novel metric, self-correlation distance. This metric measures whether LLMs maintain consistent relationships between answers across different questions, as humans do. This indicates that even a high average agreement with human data, when considering LLM responses independently, does not guarantee structural alignment in responses. Additionally, we reveal a weak correlation between two common evaluation metrics, mean-squared distance and KL divergence, which assume that survey answers are independent of each other. For future research, we recommend CoT prompting, sampling-based decoding with dozens of samples, and robust analysis using multiple metrics, including self-correlation distance.", "AI": {"tldr": "本文探讨了使用改编的社会调查问卷评估大型语言模型（LLM）价值观的方法的局限性，并提出了新的衡量标准。", "motivation": "现有研究通过将社会调查问题作为提示来评估大型语言模型的价值观，但这种方法存在不足，可能导致低估或高估模型与人类价值观的一致性。因此，需要改进评估方法和指标。", "method": "本文使用世界价值调查在三种语言的五个国家进行实验，并引入了自我相关距离这一新度量标准来考察LLM的回答一致性。", "result": "研究表明，不同的提示方式和解码策略显著影响结果；常用的均方误差与KL散度之间的相关性较弱，说明这两个指标假设问卷答案相互独立是不合理的。", "conclusion": "未来研究应推荐使用CoT提示、基于采样的解码方法，并结合多种评估指标（如自我相关距离）进行稳健分析。"}}
{"id": "2602.04032", "pdf": "https://arxiv.org/pdf/2602.04032", "abs": "https://arxiv.org/abs/2602.04032", "authors": ["Mayesha Maliha R. Mithila", "Mylene C. Q. Farias"], "title": "MS-SCANet: A Multiscale Transformer-Based Architecture with Dual Attention for No-Reference Image Quality Assessment", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "Published in ICASSP 2025, 5 pages, 3 figures", "summary": "We present the Multi-Scale Spatial Channel Attention Network (MS-SCANet), a transformer-based architecture designed for no-reference image quality assessment (IQA). MS-SCANet features a dual-branch structure that processes images at multiple scales, effectively capturing both fine and coarse details, an improvement over traditional single-scale methods. By integrating tailored spatial and channel attention mechanisms, our model emphasizes essential features while minimizing computational complexity. A key component of MS-SCANet is its cross-branch attention mechanism, which enhances the integration of features across different scales, addressing limitations in previous approaches. We also introduce two new consistency loss functions, Cross-Branch Consistency Loss and Adaptive Pooling Consistency Loss, which maintain spatial integrity during feature scaling, outperforming conventional linear and bilinear techniques. Extensive evaluations on datasets like KonIQ-10k, LIVE, LIVE Challenge, and CSIQ show that MS-SCANet consistently surpasses state-of-the-art methods, offering a robust framework with stronger correlations with subjective human scores.", "AI": {"tldr": "本文提出了基于多尺度变换器的MS-SCANet架构，用于无参考图像质量评估。", "motivation": "传统的单尺度方法在捕捉图像细节方面存在局限性。为了克服这一挑战，该研究旨在开发一种能够同时处理多个尺度并利用自适应注意力机制来提高图像质量评估准确性的新模型。", "method": "MS-SCANet采用双分支结构，在不同尺度上处理图像，并通过定制的空间和通道注意机制强调重要特征。此外，引入了跨分支一致性和自适应池化一致性损失函数，以保持空间完整性。", "result": "实验结果表明，MS-SCANet在KonIQ-10k、LIVE、LIVE Challenge及CSIQ等数据集上超过了最先进的方法，并提供了更强大的框架和更强的人类主观评分相关性。", "conclusion": "本文提出的方法展示了对图像质量评估的强大性能，在多个基准测试中优于现有技术。"}}
{"id": "2602.04030", "pdf": "https://arxiv.org/pdf/2602.04030", "abs": "https://arxiv.org/abs/2602.04030", "authors": ["Leeje Jang", "Yijun Lin", "Yao-Yi Chiang", "Jerod Weinman"], "title": "TiCLS : Tightly Coupled Language Text Spotter", "categories": ["cs.CV"], "comment": null, "summary": "Scene text spotting aims to detect and recognize text in real-world images, where instances are often short, fragmented, or visually ambiguous. Existing methods primarily rely on visual cues and implicitly capture local character dependencies, but they overlook the benefits of external linguistic knowledge. Prior attempts to integrate language models either adapt language modeling objectives without external knowledge or apply pretrained models that are misaligned with the word-level granularity of scene text. We propose TiCLS, an end-to-end text spotter that explicitly incorporates external linguistic knowledge from a character-level pretrained language model. TiCLS introduces a linguistic decoder that fuses visual and linguistic features, yet can be initialized by a pretrained language model, enabling robust recognition of ambiguous or fragmented text. Experiments on ICDAR 2015 and Total-Text demonstrate that TiCLS achieves state-of-the-art performance, validating the effectiveness of PLM-guided linguistic integration for scene text spotting.", "AI": {"tldr": "本文提出了一种结合外部语言知识的端到端文本检测和识别方法TiCLS，用于增强现实图像中文本的识别准确性。", "motivation": "现有的场景文字定位方法主要依赖于视觉线索，并且未能充分利用外部的语言学知识。为了解决这一问题并提高对模糊或碎片化文本的识别能力，提出了结合语言模型的方法。", "method": "TiCLS引入了一种语言解码器，该解码器融合了视觉和语言特征，并能够利用预训练的语言模型初始化以增强模糊或碎片化文本的识别。", "result": "实验结果表明，在ICDAR 2015和Total-Text数据集上，TiCLS达到了最先进的性能水平，证明了PLM引导下的语言整合在场景文字定位中的有效性。", "conclusion": "通过将外部的语言学知识融入到端到端的文本检测与识别中，TiCLS可以显著提高对模糊或碎片化文本的识别准确性。"}}
{"id": "2602.04029", "pdf": "https://arxiv.org/pdf/2602.04029", "abs": "https://arxiv.org/abs/2602.04029", "authors": ["Vignesh Kothapalli", "Rishabh Ranjan", "Valter Hudovernik", "Vijay Prakash Dwivedi", "Johannes Hoffart", "Carlos Guestrin", "Jure Leskovec"], "title": "PluRel: Synthetic Data unlocks Scaling Laws for Relational Foundation Models", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": "Code: https://github.com/snap-stanford/plurel", "summary": "Relational Foundation Models (RFMs) facilitate data-driven decision-making by learning from complex multi-table databases. However, the diverse relational databases needed to train such models are rarely public due to privacy constraints. While there are methods to generate synthetic tabular data of arbitrary size, incorporating schema structure and primary--foreign key connectivity for multi-table generation remains challenging. Here we introduce PluRel, a framework to synthesize multi-tabular relational databases from scratch. In a step-by-step fashion, PluRel models (1) schemas with directed graphs, (2) inter-table primary-foreign key connectivity with bipartite graphs, and, (3) feature distributions in tables via conditional causal mechanisms. The design space across these stages supports the synthesis of a wide range of diverse databases, while being computationally lightweight. Using PluRel, we observe for the first time that (1) RFM pretraining loss exhibits power-law scaling with the number of synthetic databases and total pretraining tokens, (2) scaling the number of synthetic databases improves generalization to real databases, and (3) synthetic pretraining yields strong base models for continued pretraining on real databases. Overall, our framework and results position synthetic data scaling as a promising paradigm for RFMs.", "AI": {"tldr": "该论文提出了一种名为PluRel的框架，用于从零开始生成多表关系数据库。", "motivation": "由于隐私限制，复杂多表数据库难以公开获取。现有的合成数据方法无法很好地处理模式结构和主外键连接性的问题。因此需要一种新的解决方案来生成多样化的、具有真实性的数据库。", "method": "PluRel通过三个步骤实现：(1) 使用有向图建模架构；(2) 使用二分图建模表间主外键关系；(3) 利用条件因果机制建模范例分布。这种设计空间支持生成多样化、复杂的数据库，同时保持计算效率。", "result": "该论文发现：(1) RFM预训练损失与合成数据库的数量和总训练令牌数量呈幂律增长。(2) 扩大数据集规模可以提高模型的泛化能力。(3) 合成数据预训练能够产生强大的基础模型，从而继续在真实数据集上进行微调。", "conclusion": "该论文表明，使用PluRel生成合成数据库可以有效地解决RFM面临的挑战，并且合成数据缩放可能是RFM的一个有前途的研究方向。"}}
{"id": "2602.04028", "pdf": "https://arxiv.org/pdf/2602.04028", "abs": "https://arxiv.org/abs/2602.04028", "authors": ["Leila Amgoud", "Martin Cooper"], "title": "Axiomatic Foundations of Counterfactual Explanations", "categories": ["cs.AI", "cs.LG", "stat.ME"], "comment": ":F.4.1", "summary": "Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process. This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within this taxonomy, formally characterizes their behavior, and analyzes the computational complexity of generating such explanations.", "AI": {"tldr": "本文提出了反事实解释的公理框架，揭示了五种不同的反事实类型，并将现有解释器置于该分类学中。", "motivation": "为了提高对自主和智能系统的信任，需要有效的解释机制。尽管存在大量关于反事实研究的文献，但大多数现有的解算器仅专注于单一类型的局部反事实解释。本文旨在填补系统性研究不同反事实类型以及全局反事实空白。", "method": "通过建立一套描述性的公理框架，本文证明了同时满足某些公理组合是不可能的，并完全表征所有兼容集合。代表定理则建立了特定子集公理与满足它们的家庭解释器之间的一对一对应关系。", "result": "该研究揭示并分类了五种不同的反事实类型，其中包括局部和全局类型的反事实解释。", "conclusion": "本文通过提供一个全面的理论框架来理解和生成不同类型的反事实解释，为未来的研究提供了方向。"}}
{"id": "2602.04026", "pdf": "https://arxiv.org/pdf/2602.04026", "abs": "https://arxiv.org/abs/2602.04026", "authors": ["Nandini Sharma", "Thomas Bock", "Rich Bowen", "Sayeed Choudhury", "Brian Fitzgerald", "Matt Germonprez", "Jim Herbsleb", "James Howison", "Tom Hughes", "Min Kyung Lee", "Stephanie Lieggi", "Andreas Liesenfeld", "Georg Link", "Nicholas Matsakis", "Audris Mockus", "Narayan Ramasubbu", "Christopher Robinson", "Gregorio Robles", "Nithya Ruff", "Sonali Shah", "Igor Steinmacher", "Bogdan Vasilescu", "Stephen Walli", "Christopher Yoo"], "title": "Accountability in Open Source Software Ecosystems: Workshop Report", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "Open source software ecosystems are composed of a variety of stakeholders including but not limited to non-profit organizations, volunteer contributors, users, and corporations. The needs and motivations of these stakeholders are often diverse, unknown, and sometimes even conflicting given the engagement and investment of both volunteers and corporate actors. Given this, it is not clear how open source communities identify and engage with their stakeholders, understand their needs, and hold themselves accountable to those needs. We convened 24 expert scholars and practitioners studying and working with open source software communities for an exploratory workshop discussion on these ideas. The workshop titled \"Accountability and Open Source Software Ecosystems\" was organized on Oct 14-15 on campus in Carnegie Mellon University, Pittsburgh, PA. The purpose of this in-person workshop was to initiate conversations that explore important and urgent questions related to the role of accountability in open source software ecosystems, and to inspire an exciting research agenda and meaningful stakeholder engagement ideas for practitioners.", "AI": {"tldr": "探讨开源软件生态系统中问责制的问题", "motivation": "面对利益相关者多元且可能冲突的需求，研究如何识别、了解并回应这些需求", "method": "组织专家研讨会进行讨论和探索", "result": "初步探索了重要及紧迫的问责制问题，并提出新的研究方向与实践建议", "conclusion": "强调问责制在开源软件生态系统中的重要性以及进一步研究的必要性"}}
{"id": "2602.04023", "pdf": "https://arxiv.org/pdf/2602.04023", "abs": "https://arxiv.org/abs/2602.04023", "authors": ["Runlong Ye", "Oliver Huang", "Jessica He", "Michael Liut"], "title": "Exploring Emerging Norms of AI Disclosure in Programming Education", "categories": ["cs.HC"], "comment": null, "summary": "Generative AI blurs the lines of authorship in computing education, creating uncertainty around how students should attribute AI assistance. To examine these emerging norms, we conducted a factorial vignette study with 94 computer science students across 102 unique scenarios, systematically manipulating assessment type, AI autonomy, student activity, prior knowledge, and human refinement effort. This paper details how these factors influence students' perceptions of ownership and disclosure preferences. Our findings indicate that attribution judgments are primarily driven by different levels of AI assistance and human refinement. We also found that students' perception of authorship significantly predicts their policy expectations. We conclude by proposing a shift from statement-style policies to process-oriented attribution, transforming disclosure into a pedagogical mechanism for fostering critical engagement with AI-generated content.", "AI": {"tldr": "研究探讨了AI在编程教育中的披露规范，分析学生对AI辅助的归属感和披露偏好。", "motivation": "探究在计算教育中使用生成式AI时，学生如何归因并提出相应的政策期望。", "method": "通过因子实验性描述研究，涉及94名计算机科学专业的学生，102个独特场景，并系统地操纵评估类型、AI自主权、学生活动等因素。", "result": "发现归属感判断主要受不同水平的AI辅助和人工修正的影响，学生的作者身份感知显著预测了他们的政策期望。", "conclusion": "建议从声明式政策转向过程导向式的归因方法，将披露转化为促进学生与AI生成内容批判性互动的教学机制。"}}
{"id": "2602.04019", "pdf": "https://arxiv.org/pdf/2602.04019", "abs": "https://arxiv.org/abs/2602.04019", "authors": ["Yichen Xu", "Yuyang Liang", "Shan Dai", "Tianyang Hu", "Tsz Nam Chan", "Chenhao Ma"], "title": "Understanding and Guiding Layer Placement in Parameter-Efficient Fine-Tuning of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) continue to grow, the cost of full-parameter fine-tuning has made parameter-efficient fine-tuning (PEFT) the default strategy for downstream adaptation. Constraints from inference latency in scalable serving and fine-tuning cost in edge or rapid-deployment settings make the choice of which layers to fine-tune unavoidable. Yet current practice typically applies PEFT uniformly across all layers, with limited understanding or leverage of layer selection. This paper develops a unified projected residual view of PEFT on top of a frozen base model. Under a local quadratic approximation, layerwise adaptation is governed by three quantities: (i) the projected residual norm (resnorm), which measures how much correctable bias a layer can capture; (ii) the activation energy, which determines feature conditioning; and (iii) layer coupling, which quantifies how strongly residuals interact across layers. We show that, for squared loss and linear adapters, the resnorm equals a normalized gradient norm, activation energy controls ill-conditioning and noise amplification, and weak coupling yields approximately additive layerwise contributions. Building on these insights, we introduce the Layer Card, a reusable diagnostic that summarizes residual signal strength, compute cost, and performance for each layer of a given model. With an identical model and LoRA configuration, Layer Card-guided placement refines the choice of adapted layers to flexibly prioritize different objectives, such as maximizing performance or reducing fine-tuning cost. Moreover, on Qwen3-8B, we show that selectively adapting a subset of layers can achieve performance close to full-layer LoRA while substantially reducing fine-tuning cost and the number of adapter-augmented layers during inference, offering a more cost-performance-aware alternative to full-layer insertion.", "AI": {"tldr": "研究开发了统一的投影残差视图，以指导参数高效微调中各层的选择，并引入Layer Card进行诊断。", "motivation": "大语言模型增长导致全参数微调成本高，而当前参数效率微调方法对层数选择缺乏深入了解和利用。", "method": "提出了一种基于投影残差的统一视图来指导参数高效微调中层的选择，并通过Layer Card进行诊断，以优化性能或减少训练成本。", "result": "在Qwen3-8B模型上展示了选择性适应部分层可以达到接近全层LoRA的性能，同时大幅度降低训练和推理的成本。", "conclusion": "该方法提供了灵活选择适应层的方式，为参数高效微调中的成本与性能优化提供了一种新的策略。"}}
{"id": "2602.04017", "pdf": "https://arxiv.org/pdf/2602.04017", "abs": "https://arxiv.org/abs/2602.04017", "authors": ["Joel Wester", "Samuel Rhys Cox", "Henning Pohl", "Niels van Berkel"], "title": "Chaplains' Reflections on the Design and Usage of AI for Conversational Care", "categories": ["cs.HC", "cs.CL"], "comment": "To appear at ACM CHI 2026. 15 pages, 2 figures, 3 tables", "summary": "Despite growing recognition that responsible AI requires domain knowledge, current work on conversational AI primarily draws on clinical expertise that prioritises diagnosis and intervention. However, much of everyday emotional support needs occur in non-clinical contexts, and therefore requires different conversational approaches. We examine how chaplains, who guide individuals through personal crises, grief, and reflection, perceive and engage with conversational AI. We recruited eighteen chaplains to build AI chatbots. While some chaplains viewed chatbots with cautious optimism, the majority expressed limitations of chatbots' ability to support everyday well-being. Our analysis reveals how chaplains perceive their pastoral care duties and areas where AI chatbots fall short, along the themes of Listening, Connecting, Carrying, and Wanting. These themes resonate with the idea of attunement, recently highlighted as a relational lens for understanding the delicate experiences care technologies provide. This perspective informs chatbot design aimed at supporting well-being in non-clinical contexts.", "AI": {"tldr": "研究探讨了牧师如何看待和使用用于日常情感支持的对话AI，并分析了这些观点如何影响非临床环境下的关怀技术设计。", "motivation": "当前针对对话AI的研究多依赖于以诊断与干预为中心的临床专业知识，忽视了在非临床情境下提供情感支持的需求。研究旨在通过牧师的专业视角来审视这一问题，探索如何更好地利用AI技术满足日常情感需求。", "method": "研究人员招募了十八名牧师参与设计聊天机器人项目，并收集他们对聊天机器人的看法和体验反馈。", "result": "大多数牧师认为聊天机器人在提供日常福祉支持方面存在局限性。研究确定了四个关键主题：倾听、连接、承担和愿望，这些发现强调了关怀技术中的‘共鸣’概念的重要性。", "conclusion": "该研究表明，在设计用于非临床环境的对话AI时，需要更加注重与用户的共鸣，以此来增强机器人的情感支持能力。"}}
{"id": "2602.04015", "pdf": "https://arxiv.org/pdf/2602.04015", "abs": "https://arxiv.org/abs/2602.04015", "authors": ["Crescentia Jung", "Kexin Cheng", "Sharon Heung", "Malte F. Jung", "Shiri Azenkot"], "title": "Understanding How Accessibility Practices Impact Teamwork in Mixed-Ability Teams that Collaborate Virtually", "categories": ["cs.HC"], "comment": null, "summary": "Virtual collaboration has transformed how people in mixed-ability teams, composed of disabled and non-disabled people, work together by offering greater flexibility. In these settings, accessibility practices, such as accommodations and inclusive norms, are essential for providing access to disabled people. However, we do not yet know how these practices shape broader facets of teamwork, such as productivity, participation, and camaraderie. To address this gap, we interviewed 18 participants (12 disabled, 6 non-disabled) who are part of mixed-ability teams. We found that beyond providing access, accessibility practices shaped how all participants coordinated tasks, sustained rapport, and negotiated responsibilities. Accessibility practices also introduced camaraderie challenges, such as balancing empathy and accountability. Non-disabled participants described allyship as a learning process and skill shaped by their disabled team members and team culture. Based on our findings, we present recommendations for team practices and design opportunities for virtual collaboration tools that reframe accessibility practices as a foundation for strong teamwork.", "AI": {"tldr": "研究探讨了可访问性实践如何影响虚拟混合能力团队的工作效率，参与度和凝聚力。", "motivation": "了解可访问性实践在促进虚拟混合能力团队合作中的作用，并识别潜在挑战以改善团队协作。", "method": "通过对18名参与者（包括12名残障人士和6名非残障人士）的访谈进行研究。", "result": "可访问性实践不仅为残障人士提供接入，还影响所有成员的任务协调、保持关系以及责任谈判，并提出了一些团队实践及设计机会建议。", "conclusion": "将可访问性实践视为强有力团队合作的基础对于促进虚拟混合能力团队的合作至关重要。"}}
{"id": "2602.04012", "pdf": "https://arxiv.org/pdf/2602.04012", "abs": "https://arxiv.org/abs/2602.04012", "authors": ["Hossein B. Jond", "Martin Saska"], "title": "FDA Flocking: Future Direction-Aware Flocking via Velocity Prediction", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Understanding self-organization in natural collectives such as bird flocks inspires swarm robotics, yet most flocking models remain reactive, overlooking anticipatory cues that enhance coordination. Motivated by avian postural and wingbeat signals, as well as multirotor attitude tilts that precede directional changes, this work introduces a principled, bio-inspired anticipatory augmentation of reactive flocking termed Future Direction-Aware (FDA) flocking. In the proposed framework, agents blend reactive alignment with a predictive term based on short-term estimates of neighbors' future velocities, regulated by a tunable blending parameter that interpolates between reactive and anticipatory behaviors. This predictive structure enhances velocity consensus and cohesion-separation balance while mitigating the adverse effects of sensing and communication delays and measurement noise that destabilize reactive baselines. Simulation results demonstrate that FDA achieves faster and higher alignment, enhanced translational displacement of the flock, and improved robustness to delays and noise compared to a purely reactive model. Future work will investigate adaptive blending strategies, weighted prediction schemes, and experimental validation on multirotor drone swarms.", "AI": {"tldr": "提出了未来方向感知（FDA）群集模型，通过预测邻居未来的速度来增强传统的反应性群集行为。", "motivation": "受鸟类姿态和翼拍信号启发，以及多旋翼倾斜角度的变化先于方向改变的现象，旨在改进现有的群集算法以提高协调性和稳定性。", "method": "利用基于短期估计的邻近代理未来速度预测的结构增强反应性对齐，并通过可调插值参数在纯反应行为和前瞻性行为之间进行调节。", "result": "仿真结果显示，与纯反应模型相比，FDA实现了更快更高的对齐速度，增强了群集的整体移动距离，并提高了延迟和噪声环境下的稳定性。", "conclusion": "该工作提出了一种基于预测的未来方向感知（FDA）算法，通过增强协调性和稳定性来改进现有群集行为。接下来的工作将探索自适应混合策略、加权预测方法以及多旋翼无人机群的实际应用验证。"}}
{"id": "2602.04009", "pdf": "https://arxiv.org/pdf/2602.04009", "abs": "https://arxiv.org/abs/2602.04009", "authors": ["Mehdi Lotfian", "Mohammad Jalali", "Farzan Farnia"], "title": "PromptSplit: Revealing Prompt-Level Disagreement in Generative Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Prompt-guided generative AI models have rapidly expanded across vision and language domains, producing realistic and diverse outputs from textual inputs. The growing variety of such models, trained with different data and architectures, calls for principled methods to identify which types of prompts lead to distinct model behaviors. In this work, we propose PromptSplit, a kernel-based framework for detecting and analyzing prompt-dependent disagreement between generative models. For each compared model pair, PromptSplit constructs a joint prompt--output representation by forming tensor-product embeddings of the prompt and image (or text) features, and then computes the corresponding kernel covariance matrix. We utilize the eigenspace of the weighted difference between these matrices to identify the main directions of behavioral difference across prompts. To ensure scalability, we employ a random-projection approximation that reduces computational complexity to $O(nr^2 + r^3)$ for projection dimension $r$. We further provide a theoretical analysis showing that this approximation yields an eigenstructure estimate whose expected deviation from the full-dimensional result is bounded by $O(1/r^2)$. Experiments across text-to-image, text-to-text, and image-captioning settings demonstrate that PromptSplit accurately detects ground-truth behavioral differences and isolates the prompts responsible, offering an interpretable tool for detecting where generative models disagree.", "AI": {"tldr": "PromptSplit是一种用于检测和分析生成模型之间因提示而异的行为差异的框架。", "motivation": "随着不同数据集和架构训练的生成AI模型增多，需要一种能够识别导致不同类型行为的提示的方法。PromptSplit旨在满足这一需求，通过揭示这些模型间因提示引起的分歧来提高理解和可解释性。", "method": "PromptSplit利用张量积嵌入构建联合提示-输出表示，并计算相应的核协方差矩阵。使用随机投影近似以确保可扩展性，并提供了理论分析证明该方法的有效性。", "result": "实验表明，PromptSplit能够准确检测地面真实的行为差异并分离导致分歧的提示，展示了一种解释生成模型分歧的工具。", "conclusion": "通过提供一种新的框架来识别和理解不同模型之间的行为差异，PromptSplit提高了对生成AI系统性能的理解，并为未来的研究提供了基础。"}}
{"id": "2602.04006", "pdf": "https://arxiv.org/pdf/2602.04006", "abs": "https://arxiv.org/abs/2602.04006", "authors": ["Jusheng Zhang", "Ningyuan Liu", "Qinhan Lyu", "Jing Yang", "Keze Wang"], "title": "Rational ANOVA Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Code: \\url{https://github.com/jushengzhang/Rational-ANOVA-Networks.git}", "summary": "Deep neural networks typically treat nonlinearities as fixed primitives (e.g., ReLU), limiting both interpretability and the granularity of control over the induced function class. While recent additive models (like KANs) attempt to address this using splines, they often suffer from computational inefficiency and boundary instability. We propose the Rational-ANOVA Network (RAN), a foundational architecture grounded in functional ANOVA decomposition and Padé-style rational approximation. RAN models f(x) as a composition of main effects and sparse pairwise interactions, where each component is parameterized by a stable, learnable rational unit. Crucially, we enforce a strictly positive denominator, which avoids poles and numerical instability while capturing sharp transitions and near-singular behaviors more efficiently than polynomial bases. This ANOVA structure provides an explicit low-order interaction bias for data efficiency and interpretability, while the rational parameterization significantly improves extrapolation. Across controlled function benchmarks and vision classification tasks (e.g., CIFAR-10) under matched parameter and compute budgets, RAN matches or surpasses parameter-matched MLPs and learnable-activation baselines, with better stability and throughput. Code is available at https://github.com/jushengzhang/Rational-ANOVA-Networks.git.", "AI": {"tldr": "本文提出了Rational-ANOVA网络（RAN），一种基于功能ANOVA分解和Padé样式的有理近似的基础架构，用于提高深度神经网络的可解释性和函数类别的控制粒度。", "motivation": "传统的深度神经网络将非线性视为固定的基本单元，这限制了其可解释性和对所诱导的功能类别级别的控制。虽然最近的加法模型（如KAN）试图使用样条曲线解决这一问题，但它们常常面临计算效率低下和边界不稳定的问题。", "method": "Rational-ANOVA网络将函数f(x)表示为主效应和稀疏成对相互作用的组合，每个组件由一个稳定的、可学习的有理单元参数化。通过确保分母严格为正来避免极点和数值不稳定性，同时更有效地捕捉尖锐转换和近奇异行为。", "result": "在受控函数基准测试和视觉分类任务（如CIFAR-10）中，在匹配的参数和计算预算下，RAN与参数匹配的多层感知机和可学习激活基线相比表现相当或更好，具有更好的稳定性和吞吐量。", "conclusion": "Rational-ANOVA网络通过使用ANOVA结构提供了明确的低阶交互偏差以提高数据效率和解释性，并且通过有理参数化显著改善了外推能力。"}}
{"id": "2602.04003", "pdf": "https://arxiv.org/pdf/2602.04003", "abs": "https://arxiv.org/abs/2602.04003", "authors": ["Shutong Fan", "Lan Zhang", "Xiaoyong Yuan"], "title": "When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making", "categories": ["cs.AI"], "comment": null, "summary": "Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent natural-language explanations that shape how users perceive and trust AI outputs, revealing a new attack surface at the cognitive layer: the communication channel between AI and its users. We introduce adversarial explanation attacks (AEAs), where an attacker manipulates the framing of LLM-generated explanations to modulate human trust in incorrect outputs. We formalize this behavioral threat through the trust miscalibration gap, a metric that captures the difference in human trust between correct and incorrect outputs under adversarial explanations. By incorporating this gap, AEAs explore the daunting threats in which persuasive explanations reinforce users' trust in incorrect predictions. To characterize this threat, we conducted a controlled experiment (n = 205), systematically varying four dimensions of explanation framing: reasoning mode, evidence type, communication style, and presentation format. Our findings show that users report nearly identical trust for adversarial and benign explanations, with adversarial explanations preserving the vast majority of benign trust despite being incorrect. The most vulnerable cases arise when AEAs closely resemble expert communication, combining authoritative evidence, neutral tone, and domain-appropriate reasoning. Vulnerability is highest on hard tasks, in fact-driven domains, and among participants who are less formally educated, younger, or highly trusting of AI. This is the first systematic security study that treats explanations as an adversarial cognitive channel and quantifies their impact on human trust in AI-assisted decision making.", "AI": {"tldr": "本文介绍了通过操纵大型语言模型生成的解释来影响人类对AI辅助决策的信任，从而引入了对抗性解释攻击的概念。", "motivation": "当前许多针对人工智能的安全威胁主要集中在计算行为上，而不是依赖这些系统的用户。现代AI系统越来越多地嵌入到人的决策过程中，其中用户的信任可能受到大型语言模型生成的自然语言解释的影响。", "method": "通过在四个维度上进行实验设计：推理模式、证据类型、交流风格和呈现格式，研究团队进行了一个有205名参与者参与的控制实验。该实验旨在评估对抗性解释攻击对人类信任度的影响，并量化了这些影响。", "result": "结果表明，用户报告的信任程度在对抗性和良性解释之间几乎相同。尤其是在模仿专家沟通方式时，这种影响最为明显：结合权威证据、中立语气和领域适当的推理方式时，信任的偏差最大。", "conclusion": "这是首次系统地将解释视为一种可被攻击的认知通道，并量化解释对人类在AI辅助决策中的信任度的影响的研究。"}}
{"id": "2602.04000", "pdf": "https://arxiv.org/pdf/2602.04000", "abs": "https://arxiv.org/abs/2602.04000", "authors": ["Ziyi Xuan", "Yiwen Wu", "Zhaoyang Yan", "Vinod Namboodiri", "Yu Yang"], "title": "After Talking with 1,000 Personas: Learning Preference-Aligned Proactive Assistants From Large-Scale Persona Interactions", "categories": ["cs.HC"], "comment": null, "summary": "Smart assistants increasingly act proactively, yet mistimed or intrusive behavior often causes users to lose trust and disable these features. Learning user preferences for proactive assistance is difficult because real-world studies are costly, limited in scale, and rarely capture how preferences change across multiple interaction sessions. Large language model based generative agents offer a way to simulate realistic interactions, but existing synthetic datasets remain limited in temporal depth, diverse personas, and multi-dimensional preferences. They also provide little support for transferring population-level insights to individual users under on-device constraints. We present a population-to-individual learning framework for preference-aligned proactive assistants that operates under on-device and privacy constraints. Our approach uses large-scale interaction simulation with 1,000 diverse personas to learn shared structure in how users express preferences across recurring dimensions such as timing, autonomy, and communication style, providing a strong cold start without relying on real user logs. The assistant then adapts to individual users on device through lightweight activation-based steering driven by simple interaction feedback, without model retraining or cloud-side updates. We evaluate the framework using controlled simulations with 1,000 simulated personas and a human-subject study with 30 participants. Results show improved timing decisions and perceived interaction quality over untuned and direct-response baselines, while on-device activation steering achieves performance comparable to reinforcement learning from human feedback. Participants also report higher satisfaction, trust, and comfort as the assistant adapts over multiple sessions of interactions.", "AI": {"tldr": "本文提出了一种基于大规模交互模拟的学习框架，用于开发符合用户偏好的主动助手。", "motivation": "现有研究难以学习用户的偏好以避免主动行为导致的信任丧失，而现有的合成数据集在时间深度、多样性和多维度偏好方面仍有限制。此外，这些方法缺乏将群体层面的见解转移到设备上进行个人适应的能力。", "method": "该框架通过大规模模拟与1000个多样化角色的交互来学习用户偏好的共享结构，并在此基础上对每个个体用户进行轻量级调整以适配具体需求，而无需重新训练模型或云更新。", "result": "实验显示，提出的框架在时机决策和互动质量方面优于未调优及直接响应基准。同时，在设备端通过简单交互反馈实现的激活引导效果接近基于人类反馈的强化学习。参与者报告称随着助手适应更多会话，其满意度、信任感与舒适度均有所提升。", "conclusion": "该研究展示了从大规模模拟互动中学习用户偏好，并据此开发出能够适应个体用户需求的主动式助手的有效性。这种方法在不牺牲隐私的情况下提供了更好的用户体验和更高的信任水平。"}}
{"id": "2602.03999", "pdf": "https://arxiv.org/pdf/2602.03999", "abs": "https://arxiv.org/abs/2602.03999", "authors": ["Anming Gu", "Bobby Shi", "Kevin Tian"], "title": "Functional Stochastic Localization", "categories": ["math.PR", "cs.DS", "cs.LG", "math.ST", "stat.ML"], "comment": "Comments welcome!", "summary": "Eldan's stochastic localization is a probabilistic construction that has proved instrumental to modern breakthroughs in high-dimensional geometry and the design of sampling algorithms. Motivated by sampling under non-Euclidean geometries and the mirror descent algorithm in optimization, we develop a functional generalization of Eldan's process that replaces Gaussian regularization with regularization by any positive integer multiple of a log-Laplace transform. We further give a mixing time bound on the Markov chain induced by our localization process, which holds if our target distribution satisfies a functional Poincaré inequality. Finally, we apply our framework to differentially private convex optimization in $\\ell_p$ norms for $p \\in [1, 2)$, where we improve state-of-the-art query complexities in a zeroth-order model.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.03998", "pdf": "https://arxiv.org/pdf/2602.03998", "abs": "https://arxiv.org/abs/2602.03998", "authors": ["Ahmed Alagha", "Christopher Leclerc", "Yousef Kotp", "Omar Metwally", "Calvin Moras", "Peter Rentopoulos", "Ghodsiyeh Rostami", "Bich Ngoc Nguyen", "Jumanah Baig", "Abdelhakim Khellaf", "Vincent Quoc-Huy Trinh", "Rabeb Mizouni", "Hadi Otrok", "Jamal Bentahar", "Mahdi S. Hosseini"], "title": "AtlasPatch: An Efficient and Scalable Tool for Whole Slide Image Preprocessing in Computational Pathology", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": "Under review", "summary": "Whole-slide image (WSI) preprocessing, typically comprising tissue detection followed by patch extraction, is foundational to AI-driven computational pathology workflows. This remains a major computational bottleneck as existing tools either rely on inaccurate heuristic thresholding for tissue detection, or adopt AI-based approaches trained on limited-diversity data that operate at the patch level, incurring substantial computational complexity. We present AtlasPatch, an efficient and scalable slide preprocessing framework for accurate tissue detection and high-throughput patch extraction with minimal computational overhead. AtlasPatch's tissue detection module is trained on a heterogeneous and semi-manually annotated dataset of ~30,000 WSI thumbnails, using efficient fine-tuning of the Segment-Anything model. The tool extrapolates tissue masks from thumbnails to full-resolution slides to extract patch coordinates at user-specified magnifications, with options to stream patches directly into common image encoders for embedding or store patch images, all efficiently parallelized across CPUs and GPUs. We assess AtlasPatch across segmentation precision, computational complexity, and downstream multiple-instance learning, matching state-of-the-art performance while operating at a fraction of their computational cost. AtlasPatch is open-source and available at https://github.com/AtlasAnalyticsLab/AtlasPatch.", "AI": {"tldr": "提出了一种名为AtlasPatch的工具，用于提高全滑动图像预处理的效率和准确性。", "motivation": "现有的WSI预处理方法在组织检测和补丁提取方面存在计算瓶颈，要么基于不准确的阈值方法，要么使用训练数据有限的人工智能模型。", "method": "AtlasPatch利用高效的Segment-Anything模型细调技术，在大量异质且半人工标注的数据集上进行组织检测。它通过从缩略图到全分辨率图像的外推生成组织掩码，并提取指定放大倍数下的补丁坐标，同时提供直接流式传输或存储这些补丁的功能。", "result": "AtlasPatch在分割精度、计算复杂性和下游多实例学习方面表现出色，且成本远低于现有方法。", "conclusion": "通过使用高效的组织检测和高通量的补丁提取策略，AtlasPatch显著减少了全滑动图像预处理的计算负担。"}}
{"id": "2602.03994", "pdf": "https://arxiv.org/pdf/2602.03994", "abs": "https://arxiv.org/abs/2602.03994", "authors": ["Anish Sathyanarayanan", "Aditya Nagarsekar", "Aarush Rathore"], "title": "When Chains of Thought Don't Matter: Causal Bypass in Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "Under Review at ICLR, 2026", "summary": "Chain-of-thought (CoT) prompting is widely assumed to expose a model's reasoning process and improve transparency. We attempted to enforce this assumption by penalizing unfaithful reasoning, but found that surface-level compliance does not guarantee causal reliance. Our central finding is negative: even when CoT is verbose, strategic, and flagged by surface-level manipulation detectors, model answers are often causally independent of the CoT content. We present a diagnostic framework for auditing this failure mode: it combines (i) an interpretable behavioral module that scores manipulation-relevant signals in CoT text and (ii) a causal probe that measures CoT-mediated influence (CMI) via hidden-state patching and reports a bypass score ($1-\\mathrm{CMI}$), quantifying the degree to which the answer is produced by a bypass circuit independent of the rationale. In pilot evaluations, audit-aware prompting increases detectable manipulation signals (mean risk-score delta: $+5.10$), yet causal probes reveal task-dependent mediation: many QA items exhibit near-total bypass (CMI $\\approx 0$), while some logic problems show stronger mediation (CMI up to $0.56$). Layer-wise analysis reveals narrow and task-dependent ``reasoning windows'' even when mean CMI is low.", "AI": {"tldr": "论文主要任务是探讨大型语言模型中的因果旁路现象，即使采用详细的推理过程，模型的输出也可能并不依赖于这些推理内容。", "motivation": "质疑链式思考（CoT）提示可以提高大语言模型透明度和可靠性的假设。试图通过惩罚不忠实推理来验证这一假设的有效性。", "method": "提出了一种诊断框架来审计因果旁路现象，该框架结合了可解释的行为模块和因果探针，前者评估链式思考文本中的操控信号，后者测量经过链式思考中介的影响（CMI）。", "result": "在试点评估中，发现即使有策略性的提示，模型输出仍存在不同程度的因果独立性。一些问答项表现出几乎完全旁路的现象（CMI约等于0），而某些逻辑问题则显示更强的中介影响。", "conclusion": "结论是，在大型语言模型中，链式思考提示并不总是能够确保模型的回答依赖于给定的理由内容，这表明模型可能通过旁路机制独立生成答案。"}}
{"id": "2602.03991", "pdf": "https://arxiv.org/pdf/2602.03991", "abs": "https://arxiv.org/abs/2602.03991", "authors": ["Mingyang Gong", "Zhi-Zhong Chen", "Brendan Mumey"], "title": "Approximately Partitioning Vertices into Short Paths", "categories": ["cs.DS"], "comment": ":F.2.2", "summary": "Given a fixed positive integer $k$ and a simple undirected graph $G = (V, E)$, the {\\em $k^-$-path partition} problem, denoted by $k$PP for short, aims to find a minimum collection $\\cal{P}$ of vertex-disjoint paths in $G$ such that each path in $\\cal{P}$ has at most $k$ vertices and each vertex of $G$ appears in one path in $\\cal{P}$. In this paper, we present a $\\frac {k+4}5$-approximation algorithm for $k$PP when $k\\in\\{9,10\\}$ and an improved $(\\frac{\\sqrt{11}-2}7 k + \\frac {9-\\sqrt{11}}7)$-approximation algorithm when $k \\ge 11$. Our algorithms achieve the current best approximation ratios for $k \\in \\{ 9, 10, \\ldots, 18 \\}$. Our algorithms start with a maximum triangle-free path-cycle cover $\\cal{F}$, which may not be feasible because of the existence of cycles or paths with more than $k$ vertices. We connect as many cycles in $\\cal{F}$ with $4$ or $5$ vertices as possible by computing another maximum-weight path-cycle cover in a suitably constructed graph so that $\\cal{F}$ can be transformed into a $k^-$-path partition of $G$ without losing too many edges. Keywords: $k^-$-path partition; Triangle-free path-cycle cover; $[f, g]$-factor; Approximation algorithm", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.03987", "pdf": "https://arxiv.org/pdf/2602.03987", "abs": "https://arxiv.org/abs/2602.03987", "authors": ["Nikolaos Bousias", "George Pappas"], "title": "Towards X-embodiment safety: A control theory perspective on transferring safety certificates across dynamical systems", "categories": ["eess.SY", "cs.RO"], "comment": null, "summary": "Control barrier functions (CBFs) provide a powerful tool for enforcing safety constraints in control systems, but their direct application to complex, high-dimensional dynamics is often challenging. In many settings, safety certificates are more naturally designed for simplified or alternative system models that do not exactly match the dynamics of interest. This paper addresses the problem of transferring safety guarantees between dynamical systems with mismatched dynamics. We propose a transferred control barrier function (tCBF) framework that enables safety constraints defined on one system to be systematically enforced on another system using a simulation function and an explicit margin term. The resulting transferred barrier accounts for model mismatch and induces a safety condition that can be enforced on the target system via a quadratic-program-based safety filter. The proposed approach is general and does not require the two systems to share the same state dimension or dynamics. We demonstrate the effectiveness of the framework on a quadrotor navigation task with the transferred barrier ensuring collision avoidance for the target system, while remaining minimally invasive to a nominal controller. These results highlight the potential of transferred control barrier functions as a general mechanism for enforcing safety across heterogeneous dynamical systems.", "AI": {"tldr": "该论文提出了一个转移控制屏障函数(tCBF)框架，使得在一个系统上定义的安全约束能够被转移到另一个具有不同动态特性的系统中。", "motivation": "在控制系统中直接应用控制屏障函数(CBFs)来强制执行安全约束对于复杂、高维的动力学模型来说通常非常困难。论文旨在解决如何将安全性保证从一个动力系统转移到另一个匹配度不高的系统的问题，通过设计一种新的转移方法来应对这一挑战。", "method": "提出了基于模拟功能和明确边缘项的转移控制屏障函数(tCBF)框架，使安全约束可以从一个系统转移到另一不同的目标系统上。该框架使用二次规划基的安全过滤器实现，并且不需要两个系统具有相同的维度或动力学特性。", "result": "在四旋翼导航任务中展示了所提方法的有效性，tCBF确保了目标系统的碰撞避免，同时对基本控制器的侵入最小化，证明了转移控制屏障函数作为跨异构动态系统执行安全性的通用机制的潜力。", "conclusion": "论文通过提出的转移控制屏障函数(tCBF)框架展示了其在不同动力学模型间的安全性保证转移上的有效性，并强调了这种方法作为一种通用的安全性执行机制的重要性。"}}
{"id": "2602.03986", "pdf": "https://arxiv.org/pdf/2602.03986", "abs": "https://arxiv.org/abs/2602.03986", "authors": ["Nikolaos Bousias", "Lars Lindemann", "George Pappas"], "title": "eCP: Informative uncertainty quantification via Equivariantized Conformal Prediction with pre-trained models", "categories": ["cs.LG", "cs.RO", "eess.SY"], "comment": null, "summary": "We study the effect of group symmetrization of pre-trained models on conformal prediction (CP), a post-hoc, distribution-free, finite-sample method of uncertainty quantification that offers formal coverage guarantees under the assumption of data exchangeability. Unfortunately, CP uncertainty regions can grow significantly in long horizon missions, rendering the statistical guarantees uninformative. To that end, we propose infusing CP with geometric information via group-averaging of the pretrained predictor to distribute the non-conformity mass across the orbits. Each sample now is treated as a representative of an orbit, thus uncertainty can be mitigated by other samples entangled to it via the orbit inducing elements of the symmetry group. Our approach provably yields contracted non-conformity scores in increasing convex order, implying improved exponential-tail bounds and sharper conformal prediction sets in expectation, especially at high confidence levels. We then propose an experimental design to test these theoretical claims in pedestrian trajectory prediction.", "AI": {"tldr": "本文提出了通过预训练模型的群对称化来改进置信预测的方法，以提高不确定性量化的效果。", "motivation": "传统的置信预测在长时间任务中会导致不确定性的区域过大，使得统计保证变得不具有信息性。因此，作者希望通过注入几何信息来改善这一状况。", "method": "通过预训练模型的群平均化处理，将非一致性质量分布在轨道上。每个样本被视为某个轨道的代表，不确定性可通过与其他被同一对称元素纠缠的样本一起缓解。", "result": "该方法可以证明在增加凸序中收缩了非一致性分数，并且提高了高置信水平下的精确尾部界和更窄的置信预测集。", "conclusion": "实验结果验证了理论上的主张，表明通过引入几何信息改进不确定性量化的有效性和实用性。"}}
{"id": "2602.03983", "pdf": "https://arxiv.org/pdf/2602.03983", "abs": "https://arxiv.org/abs/2602.03983", "authors": ["Weikang Qiu", "Tinglin Huang", "Aosong Feng", "Rex Ying"], "title": "Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Vision-Language-Action (VLA) models have recently emerged as a promising paradigm for generalist robotic control. Built upon vision-language model (VLM) architectures, VLAs predict actions conditioned on visual observations and language instructions, achieving strong performance and generalization across tasks. However, VLAs face two major challenges: limited long-horizon context and inefficient inference due to the quadratic attention complexity and large parameter counts. Our work is motivated by the observation that much of the visual information in a trajectory remains static across timesteps (e.g., the background). Leveraging this property, we propose SD-VLA, a framework that disentangles visual inputs into multi-level static and dynamic tokens, which enables (1) retaining a single copy of static tokens across frames to significantly reduce context length, and (2) reusing the key-value (KV) cache of static tokens through a lightweight recache gate that updates only when necessary. This design enables efficient multi-frame integration and efficient inference. In addition, we introduce a new benchmark that more effectively evaluates the long-horizon temporal dependency modeling ability of VLAs. Experimental results show that our approach outperforms baselines on this benchmark by 39.8% absolute improvement in success rate, and achieves a 3.9% gain on the SimplerEnv benchmark. Moreover, SD-VLA delivers a 2.26x inference speedup over the base VLA model on the same benchmark, enabling faster and more practical real-world deployment.", "AI": {"tldr": "本文提出了一种新的Vision-Language-Action模型SD-VLA，通过分离静态和动态视觉输入来解决长时序依赖建模效率低的问题。", "motivation": "现有的VLA模型在处理长时间序列任务时存在效率低下问题。基于观察到场景中许多信息是静止的，本文提出了一个方法来提高模型的长期依赖性建模能力并减少推理时间。", "method": "SD-VLA通过将视觉输入分解成静态和动态令牌，并保留静态令牌的单一副本以减小上下文长度，同时引入了一个轻量级回收门仅在必要时更新静态令牌的键值缓存。", "result": "实验表明，在新的基准测试中，SD-VLA的成功率比基线模型提高了39.8%，并且在SimplerEnv基准上获得了3.9%的表现提升。此外，相较于原始VLA模型，其推理速度提升了2.26倍。", "conclusion": "通过分离静态和动态视觉信息，本文提出的方法不仅能够提高模型处理长时序任务的能力，还能显著加快推理速度，使其更适用于实际应用。"}}
{"id": "2602.03981", "pdf": "https://arxiv.org/pdf/2602.03981", "abs": "https://arxiv.org/abs/2602.03981", "authors": ["Aijie Shu", "Wenbin Wu", "Gbenga Ibikunle", "Fengxiang He"], "title": "DeXposure-FM: A Time-series, Graph Foundation Model for Credit Exposures and Stability on Decentralized Financial Networks", "categories": ["cs.LG", "cs.AI", "econ.EM"], "comment": null, "summary": "Credit exposure in Decentralized Finance (DeFi) is often implicit and token-mediated, creating a dense web of inter-protocol dependencies. Thus, a shock to one token may result in significant and uncontrolled contagion effects. As the DeFi ecosystem becomes increasingly linked with traditional financial infrastructure through instruments, such as stablecoins, the risk posed by this dynamic demands more powerful quantification tools. We introduce DeXposure-FM, the first time-series, graph foundation model for measuring and forecasting inter-protocol credit exposure on DeFi networks, to the best of our knowledge. Employing a graph-tabular encoder, with pre-trained weight initialization, and multiple task-specific heads, DeXposure-FM is trained on the DeXposure dataset that has 43.7 million data entries, across 4,300+ protocols on 602 blockchains, covering 24,300+ unique tokens. The training is operationalized for credit-exposure forecasting, predicting the joint dynamics of (1) protocol-level flows, and (2) the topology and weights of credit-exposure links. The DeXposure-FM is empirically validated on two machine learning benchmarks; it consistently outperforms the state-of-the-art approaches, including a graph foundation model and temporal graph neural networks. DeXposure-FM further produces financial economics tools that support macroprudential monitoring and scenario-based DeFi stress testing, by enabling protocol-level systemic-importance scores, sector-level spillover and concentration measures via a forecast-then-measure pipeline. Empirical verification fully supports our financial economics tools. The model and code have been publicly available. Model: https://huggingface.co/EVIEHub/DeXposure-FM. Code: https://github.com/EVIEHub/DeXposure-FM.", "AI": {"tldr": "本文提出了DeXposure-FM，一种用于度量和预测去中心化金融网络中协议间信用敞口的时间序列、图基础模型。", "motivation": "随着去中心化金融生态系统与传统金融基础设施通过稳定币等工具相互关联，信用暴露带来的风险需要更强大的量化工具。因此提出了DeXposure-FM来解决这一问题。", "method": "采用了预训练权重初始化的图-表格编码器和多个特定任务头部进行联合训练，并在包含4370万数据项、跨越602个区块链上的4300多个协议的数据集上进行了训练。该模型被用于信用敞口预测，包括预测协议级流量以及信用暴露链接的拓扑结构和权重。", "result": "DeXposure-FM在机器学习基准测试中始终优于现有方法，提供支持宏观审慎监控和去中心化金融压力测试的工具。", "conclusion": "本文验证了DeXposure-FM的有效性，并将其模型与代码公开。"}}
{"id": "2602.03980", "pdf": "https://arxiv.org/pdf/2602.03980", "abs": "https://arxiv.org/abs/2602.03980", "authors": ["Vsevolod Kapatsinski"], "title": "Transformers perform adaptive partial pooling", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, submitted to the annual meeting of the Cognitive Science Society", "summary": "Because language is creative, any reasonable language model must generalize, deciding what to say in novel contexts by using information from similar contexts. But what about contexts that are not novel but merely infrequent? In hierarchical regression, the model's predictions for behavior in a context are affected by observations from other similar contexts to the extent that 1) the current context is infrequent and 2) different contexts behave similarly. This is called adaptive partial pooling of evidence. This paper shows that next-word predictions of a transformer (GPT2) are increasingly unaffected by observations from outside the current context across epochs of training (the amount of pooling reduces with training), and that the extent of pooling is affected by context frequency, context number (type frequency) and context variability in a similar way to hierarchical regression. These characteristics of learning in transformers are argued to be realistic on both rational and empirical grounds.", "AI": {"tldr": "研究探讨了Transformer模型（以GPT2为例）在训练过程中如何根据上下文频率和变化性调整其预测行为，模拟人类语言处理中的适应性部分池化。", "motivation": "为了验证Transformer模型是否能够在面对不常见但非新颖的上下文时表现出类似人类的语言创造力与泛化能力。这种适应性部分池化机制使得模型能够根据当前上下文的重要性及相似上下文的数量和行为一致性来调整其预测。", "method": "通过训练GPT2模型，并观察其在不同阶段如何利用外部信息进行下词预测，研究分析了Transformer模型随着训练的进展逐渐减少对外部信息依赖的过程及其影响因素。", "result": "发现GPT2的下词预测过程中，与外界上下文的信息关联性随训练周期增加而减弱；同时，这种关联程度受当前上下文频率、类型数量以及相似度的影响，呈现出类似于层次回归中的适应性部分池化特征。", "conclusion": "研究结果表明，Transformer模型在处理语言任务时具备模拟人类大脑处理语言的能力，能够根据上下文的重要性和多样性自适应地调整其预测行为。"}}
{"id": "2602.03978", "pdf": "https://arxiv.org/pdf/2602.03978", "abs": "https://arxiv.org/abs/2602.03978", "authors": ["Zidi Xiong", "Shan Chen", "Himabindu Lakkaraju"], "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a \"free gift\" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model families and training domains. Our results show that this effect is not universal: monitorability improvements are strongly data-dependent. In particular, we demonstrate the critical role of data diversity and instruction-following data during RLVR training. We further show that monitorability is orthogonal to capability--improvements in reasoning performance do not imply increased transparency. Through mechanistic analysis, we attribute monitorability gains primarily to response distribution sharpening (entropy reduction) and increased attention to the prompt, rather than stronger causal reliance on reasoning traces. We also reveal how monitorability dynamics vary with controlled training and evaluation difficulty. Together, these findings provide a holistic view of how monitorability emerges under RLVR, clarifying when gains are likely to occur and when they are not.", "AI": {"tldr": "研究通过强化学习与可验证奖励(RLVR)方法评估大型推理模型(LRM)的监控性，探讨其在训练初期自发提高透明度的现象。", "motivation": "随着大型推理模型的应用越来越广泛，对其链式思维（CoT）进行审计以确保安全变得至关重要。研究旨在通过系统评估不同模型和训练环境下的RLVR方法来探索监控性的自然出现情况及其依赖性。", "method": "通过对不同类型模型家族和训练领域的系统评测来验证监控性提升的现象，并深入分析其背后机制，揭示数据多样性与指令跟随数据在训练中的关键作用。", "result": "研究表明监控性改进并非普遍现象且强烈依赖于数据特性；同时发现提高监控性和增强推理能力是两个独立的过程。通过机理分析发现，监控性的增加主要归因于响应分布的锐化（熵减少）和对指令更强烈的关注。", "conclusion": "研究提供了关于如何在RLVR下监控性出现的全面视图，并明确指出哪些情况下可以获得增益以及哪些情况可能不会产生效果。"}}
{"id": "2602.03975", "pdf": "https://arxiv.org/pdf/2602.03975", "abs": "https://arxiv.org/abs/2602.03975", "authors": ["Shuhui Qu"], "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure", "categories": ["cs.AI"], "comment": null, "summary": "Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \\emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a state-level selective verification framework that combines (i) deterministic feasibility gating over a structured move interface, (ii) pre-verification ranking using a hybrid of learned state-distance and residual scoring, and (iii) adaptive allocation of verifier calls based on local uncertainty. Unlike solution-level best-of-$N$ or uniform intermediate verification, our method distributes verification where it is most informative. On the \\textsc{MATH} benchmark, our approach achieves higher accuracy than best-of-$N$, majority voting, and beam search while using 44\\% fewer verifier calls.", "AI": {"tldr": "提出了一种基于学习的启发式方法，用于在大型语言模型推理过程中进行自适应测试时间计算分配。", "motivation": "当前的大规模语言模型推理中，验证成本成为主要瓶颈。许多系统中的大量验证调用浪费在冗余或没有前途的中间假设上。", "method": "提出了一种状态级别的选择性验证框架，结合确定性的可行性门控、基于结构化动作界面的预验证排名以及根据局部不确定性自适应分配验证调用的方法。", "result": "在MATH基准测试中，该方法实现了比best-of-N、多数投票和束搜索更高的准确性，并减少了44%的验证调用量。", "conclusion": "所提出的方法能够有效地降低大规模语言模型推理过程中的计算成本并提高精度。"}}
{"id": "2602.03974", "pdf": "https://arxiv.org/pdf/2602.03974", "abs": "https://arxiv.org/abs/2602.03974", "authors": ["Shuhui Qu"], "title": "Active Epistemic Control for Query-Efficient Verified Planning", "categories": ["cs.AI"], "comment": null, "summary": "Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \\textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management with categorical feasibility checks. AEC maintains a strict separation between a \\emph{grounded fact store} used for commitment and a \\emph{belief store} used only for pruning candidate plans. At each step, it either queries the environment to ground an unresolved predicate when uncertainty is high or predictions are ambiguous, or simulates the predicate to filter hypotheses when confidence is sufficient. Final commitment is gated by grounded precondition coverage and an SQ-BCP pullback-style compatibility check, so simulated beliefs affect efficiency but cannot directly certify feasibility. Experiments on ALFWorld and ScienceWorld show that AEC achieves competitive success with fewer replanning rounds than strong LLM-agent baselines.", "AI": {"tldr": "主动知识控制（AEC）用于交互式环境中的查询高效验证规划。", "motivation": "在部分可观测的互动环境中，任务关键的前提条件可能是未知的，通过互动获取这些前提条件的成本高昂。学习的世界模型可以预测缺失的事实，但错误可能导致不可行的行为选择。", "method": "AEC结合了基于模型的知识管理和可行性检查。它维护一个用于承诺的事实存储和仅用于排除候选计划假设的认知存储，并在不确定性高或预测模糊时查询环境，在信心足够时模拟前提条件以过滤假设。最终的承诺由实际的前提覆盖以及兼容性检验决定。", "result": "实验显示，AEC在ALFWorld和ScienceWorld环境中实现了与强LLM代理基线相当的成功率，但需要更少的重新规划轮次。", "conclusion": "通过严格区分事实存储和认知存储，并使用可行性检查，AEC能够在保证可行性的前提下提高查询效率。"}}
{"id": "2602.03973", "pdf": "https://arxiv.org/pdf/2602.03973", "abs": "https://arxiv.org/abs/2602.03973", "authors": ["Shuo Liu", "Ishneet Sukhvinder Singh", "Yiqing Xu", "Jiafei Duan", "Ranjay Krishna"], "title": "VLS: Steering Pretrained Robot Policies via Vision-Language Models", "categories": ["cs.RO", "cs.CV"], "comment": "11 Pages, Project page: https://vision-language-steering.github.io/webpage/", "summary": "Why do pretrained diffusion or flow-matching policies fail when the same task is performed near an obstacle, on a shifted support surface, or amid mild clutter? Such failures rarely reflect missing motor skills; instead, they expose a limitation of imitation learning under train-test shifts, where action generation is tightly coupled to training-specific spatial configurations and task specifications. Retraining or fine-tuning to address these failures is costly and conceptually misaligned, as the required behaviors already exist but cannot be selectively adapted at test time. We propose Vision-Language Steering (VLS), a training-free framework for inference-time adaptation of frozen generative robot policies. VLS treats adaptation as an inference-time control problem, steering the sampling process of a pretrained diffusion or flow-matching policy in response to out-of-distribution observation-language inputs without modifying policy parameters. By leveraging vision-language models to synthesize trajectory-differentiable reward functions, VLS guides denoising toward action trajectories that satisfy test-time spatial and task requirements. Across simulation and real-world evaluations, VLS consistently outperforms prior steering methods, achieving a 31% improvement on CALVIN and a 13% gain on LIBERO-PRO. Real-world deployment on a Franka robot further demonstrates robust inference-time adaptation under test-time spatial and semantic shifts. Project page: https://vision-language-steering.github.io/webpage/", "AI": {"tldr": "本文提出了一种无需重新训练的框架Vision-Language Steering (VLS)，用于在推理时调整预训练的机器人策略以适应测试时间的空间和任务需求。", "motivation": "现有的预训练扩散或流动匹配策略在面对障碍物、支撑表面变化或轻度杂乱等情况时失败，这暴露了模仿学习中动作生成与特定训练空间配置紧密耦合的问题。重新训练来解决这些问题既耗时又概念上不合适，因为所需的行为已存在但无法在测试时间选择性调整。", "method": "VLS通过利用视觉语言模型合成轨迹可微分奖励函数，在推理时间内控制预训练的扩散或流动匹配策略的采样过程以适应新的空间和任务需求。这种方法不需要修改政策参数即可引导去噪向满足测试时空和语义要求的动作轨迹转变。", "result": "在模拟与真实世界评估中，VLS优于先前的方法，特别是在CALVIN和LIBERO-PRO上的改进分别为31%和13%，并展示了Franka机器人上强大的推理时适应能力。", "conclusion": "本文提出了一种新颖的框架VLS，在无需重新训练的情况下，能够通过视觉语言模型引导预训练策略在测试时空与语义变化中实现有效的推理时间适应。"}}
{"id": "2602.03972", "pdf": "https://arxiv.org/pdf/2602.03972", "abs": "https://arxiv.org/abs/2602.03972", "authors": ["Kapilan Balagopalan", "Yinan Li", "Yao Zhao", "Tuan Nguyen", "Anton Daitche", "Houssam Nassif", "Kwang-Sung Jun"], "title": "Fixed Budget is No Harder Than Fixed Confidence in Best-Arm Identification up to Logarithmic Factors", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "The best-arm identification (BAI) problem is one of the most fundamental problems in interactive machine learning, which has two flavors: the fixed-budget setting (FB) and the fixed-confidence setting (FC). For $K$-armed bandits with the unique best arm, the optimal sample complexities for both settings have been settled down, and they match up to logarithmic factors. This prompts an interesting research question about the generic, potentially structured BAI problems: Is FB harder than FC or the other way around? In this paper, we show that FB is no harder than FC up to logarithmic factors. We do this constructively: we propose a novel algorithm called FC2FB (fixed confidence to fixed budget), which is a meta algorithm that takes in an FC algorithm $\\mathcal{A}$ and turn it into an FB algorithm. We prove that this FC2FB enjoys a sample complexity that matches, up to logarithmic factors, that of the sample complexity of $\\mathcal{A}$. This means that the optimal FC sample complexity is an upper bound of the optimal FB sample complexity up to logarithmic factors. Our result not only reveals a fundamental relationship between FB and FC, but also has a significant implication: FC2FB, combined with existing state-of-the-art FC algorithms, leads to improved sample complexity for a number of FB problems.", "AI": {"tldr": "研究将固定信心（FC）算法转换为固定预算（FB）算法的方法，证明FB问题不比FC更难。", "motivation": "探讨在结构化最佳臂识别中，固定预算设置与固定信心设置的难度关系，并提出一种通用方法提升FB问题的效率。", "method": "提出了一个名为FC2FB的新元算法，该算法可将任意FC算法转换为对应的FB算法，并证明了其样本复杂度接近FC算法的样本复杂度（最多相差对数因子）。", "result": "证明了固定预算下的最优样本复杂度可以由对应固定信心设置的最优样本复杂度所限制，且差距仅为对数因子。", "conclusion": "展示了FB和FC之间的基本关系，并表明将FC2FB与现有的先进FC算法结合可以提高许多FB问题的效率。"}}
{"id": "2602.03970", "pdf": "https://arxiv.org/pdf/2602.03970", "abs": "https://arxiv.org/abs/2602.03970", "authors": ["Anastasis Kratsios", "Giulia Livieri", "A. Martina Neuman"], "title": "Statistical Guarantees for Reasoning Probes on Looped Boolean Circuits", "categories": ["stat.ML", "cs.LG", "cs.NE", "math.MG", "math.ST"], "comment": null, "summary": "We study the statistical behaviour of reasoning probes in a stylized model of looped reasoning, given by Boolean circuits whose computational graph is a perfect $ν$-ary tree ($ν\\ge 2$) and whose output is appended to the input and fed back iteratively for subsequent computation rounds. A reasoning probe has access to a sampled subset of internal computation nodes, possibly without covering the entire graph, and seeks to infer which $ν$-ary Boolean gate is executed at each queried node, representing uncertainty via a probability distribution over a fixed collection of $\\mathtt{m}$ admissible $ν$-ary gates. This partial observability induces a generalization problem, which we analyze in a realizable, transductive setting. We show that, when the reasoning probe is parameterized by a graph convolutional network (GCN)-based hypothesis class and queries $N$ nodes, the worst-case generalization error attains the optimal rate $\\mathcal{O}(\\sqrt{\\log(2/δ)}/\\sqrt{N})$ with probability at least $1-δ$, for $δ\\in (0,1)$. Our analysis combines snowflake metric embedding techniques with tools from statistical optimal transport. A key insight is that this optimal rate is achievable independently of graph size, owing to the existence of a low-distortion one-dimensional snowflake embedding of the induced graph metric. As a consequence, our results provide a sharp characterization of how structural properties of the computational graph govern the statistical efficiency of reasoning under partial access.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.03969", "pdf": "https://arxiv.org/pdf/2602.03969", "abs": "https://arxiv.org/abs/2602.03969", "authors": ["Shama Magnur", "Mayank Kejriwal"], "title": "Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem", "categories": ["cs.SI", "cs.AI"], "comment": "16 pages, 5 Figures, 7 Tables", "summary": "The emergence of large language models (LLMs) represents a significant technological shift within the scientific ecosystem, particularly within the field of artificial intelligence (AI). This paper examines structural changes in the AI research landscape using a dataset of arXiv preprints (cs.AI) from 2021 through 2025. Given the rapid pace of AI development, the preprint ecosystem has become a critical barometer for real-time scientific shifts, often preceding formal peer-reviewed publication by months or years. By employing a multi-stage data collection and enrichment pipeline in conjunction with LLM-based institution classification, we analyze the evolution of publication volumes, author team sizes, and academic--industry collaboration patterns. Our results reveal an unprecedented surge in publication output following the introduction of ChatGPT, with academic institutions continuing to provide the largest volume of research. However, we observe that academic--industry collaboration is still suppressed, as measured by a Normalized Collaboration Index (NCI) that remains significantly below the random-mixing baseline across all major subfields. These findings highlight a continuing institutional divide and suggest that the capital-intensive nature of generative AI research may be reshaping the boundaries of scientific collaboration.", "AI": {"tldr": "本文分析了AI预印本研究生态系统中因大型语言模型引入而引发的结构变化。", "motivation": "由于人工智能领域的快速发展，arXiv预印本成为科学变化的重要指标。论文通过多阶段数据收集和LLM机构分类方法，探讨了出版物数量、作者团队规模及学术界与产业界的合作模式的变化。", "method": "采用多阶段数据采集和丰富流程结合基于LLM的机构分类技术分析AI arXiv预印本的数据集。", "result": "结果表明，在ChatGPT推出后，发表量显著增加。尽管学术机构仍然是最大的研究来源，但学术界与产业界的合作水平仍然较低。", "conclusion": "论文指出持续存在的制度分裂和资本密集型生成AI研究可能正在重塑科学研究的合作边界。"}}
{"id": "2602.03967", "pdf": "https://arxiv.org/pdf/2602.03967", "abs": "https://arxiv.org/abs/2602.03967", "authors": ["Thomas Uriot", "Elise Chung"], "title": "Non-linear PCA via Evolution Strategies: a Novel Objective Function", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Principal Component Analysis (PCA) is a powerful and popular dimensionality reduction technique. However, due to its linear nature, it often fails to capture the complex underlying structure of real-world data. While Kernel PCA (kPCA) addresses non-linearity, it sacrifices interpretability and struggles with hyperparameter selection. In this paper, we propose a robust non-linear PCA framework that unifies the interpretability of PCA with the flexibility of neural networks. Our method parametrizes variable transformations via neural networks, optimized using Evolution Strategies (ES) to handle the non-differentiability of eigendecomposition. We introduce a novel, granular objective function that maximizes the individual variance contribution of each variable providing a stronger learning signal than global variance maximization. This approach natively handles categorical and ordinal variables without the dimensional explosion associated with one-hot encoding. We demonstrate that our method significantly outperforms both linear PCA and kPCA in explained variance across synthetic and real-world datasets. At the same time, it preserves PCA's interpretability, enabling visualization and analysis of feature contributions using standard tools such as biplots. The code can be found on GitHub.", "AI": {"tldr": "本文提出了一种基于进化策略和神经网络的非线性主成分分析方法，旨在克服传统PCA及核PCA在处理复杂数据结构时的问题。", "motivation": "传统的PCA由于其线性的特性，在捕捉真实世界数据中的复杂结构方面存在不足。而核PCA虽然能够解决部分非线性问题，但牺牲了可解释性和难以选择超参数。因此，本文旨在开发一种既具有PCA的可解释性又具备神经网络灵活性的方法。", "method": "本文通过使用进化策略优化基于神经网络定义变量变换的方式，解决了特征值分解中的不可微分性问题，并引入了一个新的目标函数来最大化每个变量的个体方差贡献，以增强学习信号。该方法可以自然地处理分类和有序变量而不引发维度爆炸。", "result": "实验结果表明，在合成数据集及真实世界数据集中，所提出的方法在解释方差方面均显著优于线性PCA和核PCA，并且保持了PCA的可解释性，使得特征贡献可以用标准工具如双元图进行可视化分析。", "conclusion": "通过将进化策略与神经网络结合，本文提出了一个既具备非线性处理能力又具有良好解释性的新PCA框架。该方法不仅提高了数据解释率，在各种类型的数据集上均表现出了优越的性能。"}}
{"id": "2602.03958", "pdf": "https://arxiv.org/pdf/2602.03958", "abs": "https://arxiv.org/abs/2602.03958", "authors": ["Lingqing Wang", "Yingting Gao", "Chidimma Lois Anyi", "Ashok Goel"], "title": "Futuring Social Assemblages: How Enmeshing AIs into Social Life Challenges the Individual and the Interpersonal", "categories": ["cs.HC"], "comment": "Accepted by CHI'26", "summary": "Recent advances in AI are integrating AI into the fabric of human social life, creating transformative, co-shaping relationships between humans and AI. This trend makes it urgent to investigate how these systems, in turn, shape their users. We conducted a three-phase design study with 24 participants to explore this dynamic. Our findings reveal critical tensions: (1) social AI often exacerbates the very interpersonal problems it is designed to mitigate; (2) it introduces nuanced privacy harms for secondary users inadvertently involved in AI-mediated social interactions; and (3) it can threaten the primary user's personal agency and identity. We argue these tensions expose a problematic tendency in the user-centered paradigm, which often prioritizes immediate user experience at the expense of core human values like interpersonal ethics and self-efficacy. We call for a paradigm shift toward a more provocative and relational design perspective that foregrounds long-term social and personal consequences.", "AI": {"tldr": "本文探讨了人工智能融入人类社交生活后对用户产生的影响及其背后的问题。", "motivation": "鉴于AI技术正在深入人们的日常生活，研究者希望通过分析探究这些技术如何改变和塑造用户，并揭示其中存在的问题与挑战。", "method": "通过开展三阶段设计研究并与24名参与者合作来探索这些问题。", "result": "研究表明社交AI可能会加剧它旨在解决的人际关系问题，对第三方造成隐私危害，并威胁主要用户的个人自主性和身份认同。", "conclusion": "这些发现揭示了以用户为中心的设计范式存在的缺陷，并呼吁转向一种更具有前瞻性的设计视角，关注长期的社会和个人后果。"}}
{"id": "2602.03955", "pdf": "https://arxiv.org/pdf/2602.03955", "abs": "https://arxiv.org/abs/2602.03955", "authors": ["Yinyi Luo", "Yiqiao Jin", "Weichen Yu", "Mengqi Zhang", "Srijan Kumar", "Xiaoxiao Li", "Weijie Xu", "Xin Chen", "Jindong Wang"], "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.", "AI": {"tldr": "论文提出AgentArk框架，将多代理系统的智能转化为单个LLM代理中的权重，以提高推理效率和性能。", "motivation": "大型语言模型的多代理系统虽然在迭代辩论中表现出色，但因高计算成本和错误传播问题难以实际部署。因此提出了AgentArk来降低这些障碍。", "method": "通过三种层次化的蒸馏策略：增强推理微调、轨迹增广以及过程感知蒸馏，在不同模型、任务、规模和场景下实现多代理系统的智能浓缩。", "result": "蒸馏后的模型在保持单个代理效率的同时，表现出强大的推理能力和自我纠正性能，并展示了对多种推理任务的更强鲁棒性和泛化能力。", "conclusion": "该研究为高效且稳健的多代理系统发展提供了新的视角和可能。"}}
{"id": "2602.03951", "pdf": "https://arxiv.org/pdf/2602.03951", "abs": "https://arxiv.org/abs/2602.03951", "authors": ["Ali Zia", "Farid Hazratian"], "title": "Representation Geometry as a Diagnostic for Out-of-Distribution Robustness", "categories": ["cs.LG", "cs.CV", "math.DG", "math.GN"], "comment": null, "summary": "Robust generalization under distribution shift remains difficult to monitor and optimize in the absence of target-domain labels, as models with similar in-distribution accuracy can exhibit markedly different out-of-distribution (OOD) performance. While prior work has focused on training-time regularization and low-order representation statistics, little is known about whether the geometric structure of learned embeddings provides reliable post-hoc signals of robustness. We propose a geometry-based diagnostic framework that constructs class-conditional mutual k-nearest-neighbor graphs from in-distribution embeddings and extracts two complementary invariants: a global spectral complexity proxy based on the reduced log-determinant of the normalized Laplacian, and a local smoothness measure based on Ollivier--Ricci curvature. Across multiple architectures, training regimes, and corruption benchmarks, we find that lower spectral complexity and higher mean curvature consistently predict stronger OOD accuracy across checkpoints. Controlled perturbations and topological analyses further show that these signals reflect meaningful representation structure rather than superficial embedding statistics. Our results demonstrate that representation geometry enables interpretable, label-free robustness diagnosis and supports reliable unsupervised checkpoint selection under distribution shift.", "AI": {"tldr": "本文提出了一个基于几何结构的诊断框架，用于评估模型在分布变化下的鲁棒性。", "motivation": "由于缺乏目标域标签，在没有这些标签的情况下很难监测和优化模型对分布偏移（OOD）的鲁棒性。虽然之前的工作集中在训练时间正则化和低阶表示统计上，但很少有研究探讨学习嵌入的几何结构是否可以提供可靠的鲁棒性信号。", "method": "通过构建基于in-distribution嵌入的类条件互k-最邻近邻居图，并从这些图形中提取两个互补不变量：减少后的拉普拉斯算子归一化对数行列式作为全局谱复杂度代理，以及基于Ollivier-Ricci曲率的局部平滑度测量。", "result": "在不同的架构、训练方案和腐蚀基准下，较低的谱复杂性和较高的平均曲率始终预测更强的OOD准确性。控制扰动和拓扑分析进一步表明这些信号反映了有意义的表示结构而非表面嵌入统计。", "conclusion": "结果表明，通过基于几何结构的方法可以实现可解释且无标签的鲁棒性诊断，并支持在分布变化下可靠的无监督检查点选择。"}}
{"id": "2602.03950", "pdf": "https://arxiv.org/pdf/2602.03950", "abs": "https://arxiv.org/abs/2602.03950", "authors": ["Aditya Basarkar", "Benyamin Tabarsi", "Tiffany Barnes", "Dongkuan", "Xu"], "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": "9 pages, 7 figures, submitted to ACL ARR 2026", "summary": "Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.", "AI": {"tldr": "通过执行驱动的推理增强方法改进大型语言模型在数学问题解决中的能力。", "motivation": "提升人工智能系统的逻辑推断能力，尤其是在教育、科学和工程领域中可靠符号推理的应用。现有系统存在固定顺序处理无法纠正早期步骤或依赖启发式自我评估可能不能识别并修复错误的问题。", "method": "提出迭代改进程序构建（IIPC）方法，该方法通过执行反馈结合基础LLM的链式思维能力来迭代优化程序化推论链条。", "result": "在多个基准测试中，在多种基础LLM上超越了现有方法。所有代码和实现均作为开源发布。", "conclusion": "提出了IIPC方法以提高大型语言模型解决数学问题的能力，并展示了其优越的性能，同时强调开放源码的重要性。"}}
{"id": "2602.03949", "pdf": "https://arxiv.org/pdf/2602.03949", "abs": "https://arxiv.org/abs/2602.03949", "authors": ["Emrah Akyol"], "title": "Semantic Rate Distortion and Posterior Design: Compute Constraints, Multimodality, and Strategic Inference", "categories": ["cs.IT", "cs.AI", "cs.LG"], "comment": "submitted for publication", "summary": "We study strategic Gaussian semantic compression under rate and compute constraints, where an encoder and decoder optimize distinct quadratic objectives. A latent Gaussian state generates a task dependent semantic variable, and the decoder best responds via MMSE estimation, reducing the encoder's problem to posterior covariance design under an information rate constraint. We characterize the strategic rate distortion function in direct, remote, and full information regimes, derive semantic waterfilling and rate constrained Gaussian persuasion solutions, and establish Gaussian optimality under misaligned objectives. We further show that architectural compute limits act as implicit rate constraints, yielding exponential improvements in semantic accuracy with model depth and inference time compute, while multimodal observation eliminates the geometric mean penalty inherent to remote encoding. These results provide information theoretic foundations for data and energy efficient AI and offer a principled interpretation of modern multimodal language models as posterior design mechanisms under resource constraints.", "AI": {"tldr": "研究了在速率和计算限制下的战略性高斯语义压缩，分析了编码器和解码器的优化目标，并推导了解决方案。", "motivation": "为了提供数据和能量效率的人工智能的信息理论基础，通过资源约束条件下的后验设计机制解释现代多模态语言模型。", "method": "研究战略性高斯语义压缩，在直接、远程和完全信息模式下表征战略率失真函数，并推导出语义水填充和速率受限的高斯说服解决方案。", "result": "展示了架构计算限制作为隐式速率约束的作用，以及多模态观测消除了远程编码中的几何平均惩罚。", "conclusion": "这些结果为数据和能量效率的人工智能提供了信息理论基础，并提供了一种在资源约束下的现代多模态语言模型的后验设计机制的原理性解释。"}}
{"id": "2602.03942", "pdf": "https://arxiv.org/pdf/2602.03942", "abs": "https://arxiv.org/abs/2602.03942", "authors": ["Mohamed Elgaar", "Hadi Amiri"], "title": "Linguistic Blind Spots in Clinical Decision Extraction", "categories": ["cs.CL", "cs.AI"], "comment": "EACL HeaLing Workshop 2026", "summary": "Extracting medical decisions from clinical notes is a key step for clinical decision support and patient-facing care summaries. We study how the linguistic characteristics of clinical decisions vary across decision categories and whether these differences explain extraction failures. Using MedDec discharge summaries annotated with decision categories from the Decision Identification and Classification Taxonomy for Use in Medicine (DICTUM), we compute seven linguistic indices for each decision span and analyze span-level extraction recall of a standard transformer model. We find clear category-specific signatures: drug-related and problem-defining decisions are entity-dense and telegraphic, whereas advice and precaution decisions contain more narrative, with higher stopword and pronoun proportions and more frequent hedging and negation cues. On the validation split, exact-match recall is 48%, with large gaps across linguistic strata: recall drops from 58% to 24% from the lowest to highest stopword-proportion bins, and spans containing hedging or negation cues are less likely to be recovered. Under a relaxed overlap-based match criterion, recall increases to 71%, indicating that many errors are span boundary disagreements rather than complete misses. Overall, narrative-style spans--common in advice and precaution decisions--are a consistent blind spot under exact matching, suggesting that downstream systems should incorporate boundary-tolerant evaluation and extraction strategies for clinical decisions.", "AI": {"tldr": "分析临床决策提取中的语言盲点，探讨不同类别决策的语言特征及其对提取准确性的影响。", "motivation": "研究医学决策在临床上的应用，发现语言特点如何影响决策提取的失败率，并提高临床决策支持系统的准确性和可靠性。", "method": "使用DICTUM标注的出院总结数据集，计算每种决策片段的七个语言指标。分析标准Transformer模型下的精确匹配召回率以及不同语言层次上的表现差异。", "result": "发现不同类型决策的语言特征显著不同：药物和问题定义决策实体丰富且简练；而建议与预防决策更注重叙述性，并包含更多的停用词、代词及语气化和否定线索。精确匹配下总体召回率为48%，在松散重叠度量标准下的召回率上升至71%。", "conclusion": "叙事风格的片段，常见于建议和预防决策中，在精确匹配下是持续性的盲点，提示下游系统应采用容忍边界误差的评估与提取策略。"}}
{"id": "2602.03927", "pdf": "https://arxiv.org/pdf/2602.03927", "abs": "https://arxiv.org/abs/2602.03927", "authors": ["Ahmed Abouelkomsan", "Liang Fu"], "title": "First-Principles AI finds crystallization of fractional quantum Hall liquids", "categories": ["cond-mat.mes-hall", "cond-mat.str-el", "cs.AI"], "comment": "5 pages + SM", "summary": "When does a fractional quantum Hall (FQH) liquid crystallize? Addressing this question requires a framework that treats fractionalization and crystallization on equal footing, especially in strong Landau-level mixing regime. Here, we introduce MagNet, a self-attention neural-network variational wavefunction designed for quantum systems in magnetic fields on the torus geometry. We show that MagNet provides a unifying and expressive ansatz capable of describing both FQH states and electron crystals within the same architecture. Trained solely by energy minimization of the microscopic Hamiltonian, MagNet discovers topological liquid and electron crystal ground states across a broad range of Landau-level mixing. Our results highlight the power of first-principles AI for solving strongly interacting many-body problems and finding competing phases without external training data or physics pre-knowledge.", "AI": {"tldr": "引入MagNet神经网络模型以探索分数量子霍尔液体的结晶化过程。", "motivation": "需要一个框架来同时处理分数量子霍尔效应和晶体形成，尤其是在强兰道能级混合的情况下。", "method": "开发了一种基于自注意力机制的神经网络变分波函数MagNet，并通过微观哈密顿量的能量最小化训练模型。", "result": "MagNet发现了在广泛兰道能级混合范围内的拓扑液体和电子晶体基态，证明了其在解决强相互作用多体问题中的有效性。", "conclusion": "第一性原理AI方法能够在没有外部训练数据或物理先验知识的情况下发现竞争相位。"}}
{"id": "2602.03924", "pdf": "https://arxiv.org/pdf/2602.03924", "abs": "https://arxiv.org/abs/2602.03924", "authors": ["Michael Aich", "Andreas Fürst", "Florian Sestak", "Carlos Ruiz-Gonzalez", "Niklas Boers", "Johannes Brandstetter"], "title": "WIND: Weather Inverse Diffusion for Zero-Shot Atmospheric Modeling", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "Deep learning has revolutionized weather and climate modeling, yet the current landscape remains fragmented: highly specialized models are typically trained individually for distinct tasks. To unify this landscape, we introduce WIND, a single pre-trained foundation model capable of replacing specialized baselines across a vast array of tasks. Crucially, in contrast to previous atmospheric foundation models, we achieve this without any task-specific fine-tuning. To learn a robust, task-agnostic prior of the atmosphere, we pre-train WIND with a self-supervised video reconstruction objective, utilizing an unconditional video diffusion model to iteratively reconstruct atmospheric dynamics from a noisy state. At inference, we frame diverse domain-specific problems strictly as inverse problems and solve them via posterior sampling. This unified approach allows us to tackle highly relevant weather and climate problems, including probabilistic forecasting, spatial and temporal downscaling, sparse reconstruction and enforcing conservation laws purely with our pre-trained model. We further demonstrate the model's capacity to generate physically consistent counterfactual storylines of extreme weather events under global warming scenarios. By combining generative video modeling with inverse problem solving, WIND offers a computationally efficient paradigm shift in AI-based atmospheric modeling.", "AI": {"tldr": "该论文提出了WIND模型，一种预训练的深度学习模型，可以在无需任务特定微调的情况下完成多种气象和气候建模任务。", "motivation": "当前气象和气候模型领域存在碎片化现象，每个具体任务需要单独建立不同的模型。为了解决这个问题，并实现一个统一且高效的方法来处理各种天气和气候变化相关的问题，作者提出了WIND模型。", "method": "通过使用无条件视频扩散模型进行自我监督的视频重建目标训练，WIND模型学习到大气的动力学特性和时空特性，从而构建出对任务不敏感的先验知识。在推理阶段，将问题视为逆向问题并通过后验采样解决这些问题。", "result": "实验表明，无需特定微调的情况下，该模型能够完成概率预报、空间和时间降尺度等任务，并能生成符合物理规律的极端天气事件下的反事实情景。", "conclusion": "结合视频生成与逆向问题求解技术，WIND模型为基于AI的大气建模提供了一个高效且计算友好的范式转变。"}}
{"id": "2602.03921", "pdf": "https://arxiv.org/pdf/2602.03921", "abs": "https://arxiv.org/abs/2602.03921", "authors": ["Duc Hoang", "Ajay Jaiswal", "Mohammad Samragh", "Minsik Cho"], "title": "SpecMD: A Comprehensive Study On Speculative Expert Prefetching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) models enable sparse expert activation, meaning that only a subset of the model's parameters is used during each inference. However, to translate this sparsity into practical performance, an expert caching mechanism is required. Previous works have proposed hardware-centric caching policies, but how these various caching policies interact with each other and different hardware specification remains poorly understood. To address this gap, we develop \\textbf{SpecMD}, a standardized framework for benchmarking ad-hoc cache policies on various hardware configurations. Using SpecMD, we perform an exhaustive benchmarking of several MoE caching strategies, reproducing and extending prior approaches in controlled settings with realistic constraints. Our experiments reveal that MoE expert access is not consistent with temporal locality assumptions (e.g LRU, LFU). Motivated by this observation, we propose \\textbf{Least-Stale}, a novel eviction policy that exploits MoE's predictable expert access patterns to reduce collision misses by up to $85\\times$ over LRU. With such gains, we achieve over $88\\%$ hit rates with up to $34.7\\%$ Time-to-first-token (TTFT) reduction on OLMoE at only $5\\%$ or $0.6GB$ of VRAM cache capacity.", "AI": {"tldr": "SpecMD是一个标准化框架，用于在不同硬件配置上评估Mixture-of-Experts (MoE)模型的缓存策略。", "motivation": "现有工作提出的硬件导向缓存策略间如何交互以及与各种硬件规格的关系尚不清楚。本研究旨在填补这一空白，并通过探索不一致的时间局部性假设来优化专家访问模式。", "method": "开发了SpecMD框架，用于基准测试几种MoE缓存策略，并提出了一种名为Least-Stale的新型淘汰策略以减少冲突缺失。", "result": "实验表明，MoE专家访问与时间局部性假设不一致。提出的Least-Stale策略在L1和L2级别上分别减少了85倍和3.7倍的冲突丢失，并实现了高达88%的命中率。", "conclusion": "通过使用SpecMD框架，研究证明了传统缓存策略对于MoE模型的有效性不足，且提出了更有效的专家访问模式优化方法。"}}
{"id": "2602.03920", "pdf": "https://arxiv.org/pdf/2602.03920", "abs": "https://arxiv.org/abs/2602.03920", "authors": ["Isaac Sheidlower", "Jindan Huang", "James Staley", "Bingyu Wu", "Qicong Chen", "Reuben Aronson", "Elaine Short"], "title": "How Users Understand Robot Foundation Model Performance through Task Success Rates and Beyond", "categories": ["cs.RO", "cs.HC"], "comment": "Submitted to IJCAI 2026", "summary": "Robot Foundation Models (RFMs) represent a promising approach to developing general-purpose home robots. Given the broad capabilities of RFMs, users will inevitably ask an RFM-based robot to perform tasks that the RFM was not trained or evaluated on. In these cases, it is crucial that users understand the risks associated with attempting novel tasks due to the relatively high cost of failure. Furthermore, an informed user who understands an RFM's capabilities will know what situations and tasks the robot can handle. In this paper, we study how non-roboticists interpret performance information from RFM evaluations. These evaluations typically report task success rate (TSR) as the primary performance metric. While TSR is intuitive to experts, it is necessary to validate whether novices also use this information as intended. Toward this end, we conducted a study in which users saw real evaluation data, including TSR, failure case descriptions, and videos from multiple published RFM research projects. The results highlight that non-experts not only use TSR in a manner consistent with expert expectations but also highly value other information types, such as failure cases that are not often reported in RFM evaluations. Furthermore, we find that users want access to both real data from previous evaluations of the RFM and estimates from the robot about how well it will do on a novel task.", "AI": {"tldr": "研究用户如何通过任务成功率和其他信息理解机器人基础模型的性能。", "motivation": "评估非专家是否能正确理解和利用任务成功率等指标，以了解机器人执行新任务的风险和能力。", "method": "进行了一项实验，参与者查看了真实数据、失败案例描述和视频，包括来自多个出版物的RFM研究项目的数据。", "result": "发现用户不仅根据任务成功率做出判断，还高度重视未常报告的失败案例，并希望获得前评估数据和机器人对新任务表现的预测估计。", "conclusion": "为了帮助非专家更好地理解和使用RFMs，有必要提供更全面的信息类型。"}}
{"id": "2602.03918", "pdf": "https://arxiv.org/pdf/2602.03918", "abs": "https://arxiv.org/abs/2602.03918", "authors": ["Peihao Xiang", "Kaida Wu", "Ou Bai"], "title": "Entropy Reveals Block Importance in Masked Self-Supervised Vision Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Masked self-supervised vision transformers have become a dominant pretraining paradigm, yet their substantial model size poses significant challenges for resource-constrained deployment and efficient transfer learning. A fundamental question remains: are all transformer blocks equally important for downstream performance? In this paper, we show that block importance in masked self-supervised vision transformers can be accurately estimated without access to any data. Our key finding is that the information entropy of pretrained block weights strongly correlates with oracle sensitivity obtained via iterative block removal and finetuning. This observation enables Gardener, a data-free, one-shot, block-level pruning principle that identifies redundant blocks through simple information-theoretic measurements. We evaluate Gardener on VideoMAE-B across multiple pruning ratios and downstream video recognition benchmarks. Despite its negligible computational overhead, Gardener consistently matches or outperforms existing data-free pruning baselines and closely approaches sensitivity-based pruning. Remarkably, even after pruning up to 91.7\\% of blocks, the pruned model retains competitive transfer performance. Our results reveal substantial block-level redundancy in masked self-supervised vision transformers and demonstrate that information-theoretic analysis offers a principled and efficient pathway for model compression and resource-efficient transfer learning.", "AI": {"tldr": "通过信息熵分析，确定掩码自监督视觉变压器中各层的重要性，并提出一种名为Gardener的数据无需求剪枝方法。", "motivation": "大规模的模型在资源受限部署和高效迁移学习方面面临挑战。研究发现不同层级对于下游任务表现重要性不一，旨在通过数据无要求的方式识别出冗余层级以优化模型。", "method": "提出Gardener原则，利用预训练层权重的信息熵与迭代剪枝后的敏感度进行关联，并以此识别可去除的冗余层级。", "result": "在VideoMAE-B上进行了广泛的实验验证，展示了Gardener方法的有效性。即使最高达到91.7%的压缩率下仍保持了竞争力的迁移性能。", "conclusion": "研究揭示了掩码自监督视觉变压器中存在的块级冗余，并证明信息论分析为模型压缩和资源高效利用提供了原理清晰且有效的方法。"}}
{"id": "2602.03916", "pdf": "https://arxiv.org/pdf/2602.03916", "abs": "https://arxiv.org/abs/2602.03916", "authors": ["Azmine Toushik Wasi", "Wahid Faisal", "Abdur Rahman", "Mahfuz Ahmed Anik", "Munem Shahriar", "Mohsin Mahmud Topu", "Sadia Tasnim Meem", "Rahatun Nesa Priti", "Sabrina Afroz Mitu", "Md. Iqramul Hoque", "Shahriyar Zaman Ridoy", "Mohammed Eunus Ali", "Majd Hawasly", "Mohammad Raza", "Md Rizwan Parvez"], "title": "SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?", "categories": ["cs.CV", "cs.CE", "cs.CL", "cs.LG"], "comment": "Accepted to ICLR 2026. 92 Pages. 42 Figures and 29 Tables", "summary": "Spatial reasoning is a fundamental aspect of human cognition, yet it remains a major challenge for contemporary vision-language models (VLMs). Prior work largely relied on synthetic or LLM-generated environments with limited task designs and puzzle-like setups, failing to capture the real-world complexity, visual noise, and diverse spatial relationships that VLMs encounter. To address this, we introduce SpatiaLab, a comprehensive benchmark for evaluating VLMs' spatial reasoning in realistic, unconstrained contexts. SpatiaLab comprises 1,400 visual question-answer pairs across six major categories: Relative Positioning, Depth & Occlusion, Orientation, Size & Scale, Spatial Navigation, and 3D Geometry, each with five subcategories, yielding 30 distinct task types. Each subcategory contains at least 25 questions, and each main category includes at least 200 questions, supporting both multiple-choice and open-ended evaluation. Experiments across diverse state-of-the-art VLMs, including open- and closed-source models, reasoning-focused, and specialized spatial reasoning models, reveal a substantial gap in spatial reasoning capabilities compared with humans. In the multiple-choice setup, InternVL3.5-72B achieves 54.93% accuracy versus 87.57% for humans. In the open-ended setting, all models show a performance drop of around 10-25%, with GPT-5-mini scoring highest at 40.93% versus 64.93% for humans. These results highlight key limitations in handling complex spatial relationships, depth perception, navigation, and 3D geometry. By providing a diverse, real-world evaluation framework, SpatiaLab exposes critical challenges and opportunities for advancing VLMs' spatial reasoning, offering a benchmark to guide future research toward robust, human-aligned spatial understanding. SpatiaLab is available at: https://spatialab-reasoning.github.io/.", "AI": {"tldr": "介绍了一个评估视觉语言模型在现实环境中空间推理能力的基准测试SpatiaLab。", "motivation": "当前的视觉语言模型在处理复杂的、不受约束的空间关系上存在挑战，现有研究主要依赖于合成或LLM生成的环境，不能充分反映现实世界的复杂性。为了弥补这一不足，引入了SpatiaLab。", "method": "SpatiaLab包含1400个视觉问答对，分为六个主要类别：相对位置、深度与遮挡、方向、大小和比例、空间导航以及3D几何形状，每个大类有五个子类别。实验涵盖了多种最先进的视觉语言模型，包括开源和闭源的模型。", "result": "在选择题设置中，InternVL3.5-72B的准确率为54.93%，而人类为87.57%；开放性问题中的所有模型的表现下降了10%-25%，GPT-5-mini表现出最高精度为40.93%，而人类则达到64.93%。这些结果揭示了处理复杂空间关系、深度感知和导航等方面的不足。", "conclusion": "SpatiaLab作为一个多样化的现实世界评估框架，暴露出视觉语言模型在空间推理中的关键挑战和未来研究机会，旨在推动视觉语言模型向更强大的人类一致的空间理解迈进。"}}
{"id": "2602.03915", "pdf": "https://arxiv.org/pdf/2602.03915", "abs": "https://arxiv.org/abs/2602.03915", "authors": ["Levi Lingsch", "Georgios Kissas", "Johannes Jakubik", "Siddhartha Mishra"], "title": "Phaedra: Learning High-Fidelity Discrete Tokenization for the Physical Science", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG"], "comment": "57 pages, 27 figures", "summary": "Tokens are discrete representations that allow modern deep learning to scale by transforming high-dimensional data into sequences that can be efficiently learned, generated, and generalized to new tasks. These have become foundational for image and video generation and, more recently, physical simulation. As existing tokenizers are designed for the explicit requirements of realistic visual perception of images, it is necessary to ask whether these approaches are optimal for scientific images, which exhibit a large dynamic range and require token embeddings to retain physical and spectral properties. In this work, we investigate the accuracy of a suite of image tokenizers across a range of metrics designed to measure the fidelity of PDE properties in both physical and spectral space. Based on the observation that these struggle to capture both fine details and precise magnitudes, we propose Phaedra, inspired by classical shape-gain quantization and proper orthogonal decomposition. We demonstrate that Phaedra consistently improves reconstruction across a range of PDE datasets. Additionally, our results show strong out-of-distribution generalization capabilities to three tasks of increasing complexity, namely known PDEs with different conditions, unknown PDEs, and real-world Earth observation and weather data.", "AI": {"tldr": "研究开发了一种新的图像标记化方法Phaedra，用于科学图像的高保真离散标记。", "motivation": "现有图像标记器针对视觉感知设计，无法满足科学研究中对物理和光谱属性保持的要求。", "method": "提出了基于经典形状增益量化和正交分解的Phaedra方法，以改善科学图像的精度。", "result": "实验表明，在各类偏微分方程数据集上，Phaedra能提高重建性能，并具备跨任务泛化能力。", "conclusion": "Phaedra在保持物理属性和光谱特征方面具有明显优势，适用于不同复杂度的任务。"}}
{"id": "2602.03913", "pdf": "https://arxiv.org/pdf/2602.03913", "abs": "https://arxiv.org/abs/2602.03913", "authors": ["Qiuming Luo", "Tao Zeng", "Feng Li", "Heming Liu", "Rui Mao", "Chang Kong"], "title": "Entropy-Aware Structural Alignment for Zero-Shot Handwritten Chinese Character Recognition", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "37 pages, 8 figures", "summary": "Zero-shot Handwritten Chinese Character Recognition (HCCR) aims to recognize unseen characters by leveraging radical-based semantic compositions. However, existing approaches often treat characters as flat radical sequences, neglecting the hierarchical topology and the uneven information density of different components. To address these limitations, we propose an Entropy-Aware Structural Alignment Network that bridges the visual-semantic gap through information-theoretic modeling. First, we introduce an Information Entropy Prior to dynamically modulate positional embeddings via multiplicative interaction, acting as a saliency detector that prioritizes discriminative roots over ubiquitous components. Second, we construct a Dual-View Radical Tree to extract multi-granularity structural features, which are integrated via an adaptive Sigmoid-based gating network to encode both global layout and local spatial roles. Finally, a Top-K Semantic Feature Fusion mechanism is devised to augment the decoding process by utilizing the centroid of semantic neighbors, effectively rectifying visual ambiguities through feature-level consensus. Extensive experiments demonstrate that our method establishes new state-of-the-art performance, significantly outperforming existing CLIP-based baselines in the challenging zero-shot setting. Furthermore, the framework exhibits exceptional data efficiency, demonstrating rapid adaptability with minimal support samples.", "AI": {"tldr": "本文提出了一种基于熵感知的结构对齐方法，用于零样本手写汉字识别。", "motivation": "现有方法在处理手写字符时忽略了层次拓扑和组件间信息密度的差异，导致效果不佳。为了解决这一问题，本文提出了一个新颖的信息理论模型来弥合视觉和语义之间的差距。", "method": "该方法通过引入信息熵优先级动态调节位置嵌入，并使用双视图部首树提取多粒度结构特征，再利用自适应Sigmoid门控网络整合全局布局和局部空间角色。最后采用Top-K语义特征融合机制增强解码过程，解决视觉模糊问题。", "result": "实验表明所提出的方法在零样本设置下超越了现有CLIP基线方法，并表现出卓越的数据效率。", "conclusion": "该框架通过信息理论建模有效地提高了手写汉字的识别性能，在最少的支持样本情况下也能快速适应并取得良好效果。"}}
{"id": "2602.03908", "pdf": "https://arxiv.org/pdf/2602.03908", "abs": "https://arxiv.org/abs/2602.03908", "authors": ["Kuo-Yi Chao", "Ralph Rasshofer", "Alois Christian Knoll"], "title": "Beyond the Vehicle: Cooperative Localization by Fusing Point Clouds for GPS-Challenged Urban Scenarios", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 2 figures, Driving the Future Symposium 2025", "summary": "Accurate vehicle localization is a critical challenge in urban environments where GPS signals are often unreliable. This paper presents a cooperative multi-sensor and multi-modal localization approach to address this issue by fusing data from vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) systems. Our approach integrates cooperative data with a point cloud registration-based simultaneous localization and mapping (SLAM) algorithm. The system processes point clouds generated from diverse sensor modalities, including vehicle-mounted LiDAR and stereo cameras, as well as sensors deployed at intersections. By leveraging shared data from infrastructure, our method significantly improves localization accuracy and robustness in complex, GPS-noisy urban scenarios.", "AI": {"tldr": "本文提出了一种基于点云融合的车辆协同定位方法，以解决城市环境中GPS信号不可靠的问题。", "motivation": "在城市环境中，由于高楼大厦等遮挡物的影响，GPS信号经常不稳定，导致车辆定位不准。为了提高车辆定位精度和鲁棒性，提出了结合V2V、V2I系统的多传感器融合方案。", "method": "方法利用车载LiDAR、立体相机以及道路基础设施上的传感器生成点云，并通过点云配准的SLAM算法进行数据融合处理，从而实现更精确的车辆定位。", "result": "实验结果显示，在复杂的GPS干扰环境下，该方法能够显著提升车辆定位精度和鲁棒性。", "conclusion": "研究表明，本文提出的基于多传感器数据融合的方法可以有效解决城市环境中GPS信号不稳定带来的定位问题。"}}
{"id": "2602.03907", "pdf": "https://arxiv.org/pdf/2602.03907", "abs": "https://arxiv.org/abs/2602.03907", "authors": ["Team Hunyuan3D", ":", "Bowen Zhang", "Chunchao Guo", "Dongyuan Guo", "Haolin Liu", "Hongyu Yan", "Huiwen Shi", "Jiaao Yu", "Jiachen Xu", "Jingwei Huang", "Kunhong Li", "Lifu Wang", "Linus", "Penghao Wang", "Qingxiang Lin", "Ruining Tang", "Xianghui Yang", "Yang Li", "Yirui Guan", "Yunfei Zhao", "Yunhan Yang", "Zeqiang Lai", "Zhihao Liang", "Zibo Zhao"], "title": "HY3D-Bench: Generation of 3D Assets", "categories": ["cs.CV", "cs.AI"], "comment": "Authors are listed alphabetically by the first name", "summary": "While recent advances in neural representations and generative models have revolutionized 3D content creation, the field remains constrained by significant data processing bottlenecks. To address this, we introduce HY3D-Bench, an open-source ecosystem designed to establish a unified, high-quality foundation for 3D generation. Our contributions are threefold: (1) We curate a library of 250k high-fidelity 3D objects distilled from large-scale repositories, employing a rigorous pipeline to deliver training-ready artifacts, including watertight meshes and multi-view renderings; (2) We introduce structured part-level decomposition, providing the granularity essential for fine-grained perception and controllable editing; and (3) We bridge real-world distribution gaps via a scalable AIGC synthesis pipeline, contributing 125k synthetic assets to enhance diversity in long-tail categories. Validated empirically through the training of Hunyuan3D-2.1-Small, HY3D-Bench democratizes access to robust data resources, aiming to catalyze innovation across 3D perception, robotics, and digital content creation.", "AI": {"tldr": "构建HY3D-Bench，一个用于生成高质量3D资产的开放生态系统", "motivation": "解决当前三维内容创作中的数据处理瓶颈问题", "method": "建立包含250k高质量3D对象的库，并引入结构化部件级别分解；通过可扩展的人工智能内容生成合成管道填补现实世界分布差距，增加长尾类别多样性", "result": "验证HY3D-Bench在训练Hunyuan3D-2.1-Small时的有效性，证明其能够提供稳健的数据资源并促进创新", "conclusion": "通过建立HY3D-Bench生态系统，促进了三维感知、机器人和数字内容创作领域的技术创新"}}
{"id": "2602.03906", "pdf": "https://arxiv.org/pdf/2602.03906", "abs": "https://arxiv.org/abs/2602.03906", "authors": ["Weiqi Wang", "Zhiyi Tian", "Chenhan Zhang", "Shui Yu"], "title": "GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression", "categories": ["cs.LG", "cs.AI", "cs.IT", "stat.ML"], "comment": null, "summary": "Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can make IB \"compression\" only indirectly controlled and optimization fragile. We revisit the IB problem through the lens of information geometry and propose a \\textbf{Geo}metric \\textbf{I}nformation \\textbf{B}ottleneck (\\textbf{GeoIB}) that dispenses with mutual information (MI) estimation. We show that I(X;Z) and I(Z;Y) admit exact projection forms as minimal Kullback-Leibler (KL) distances from the joint distributions to their respective independence manifolds. Guided by this view, GeoIB controls information compression with two complementary terms: (i) a distribution-level Fisher-Rao (FR) discrepancy, which matches KL to second order and is reparameterization-invariant; and (ii) a geometry-level Jacobian-Frobenius (JF) term that provides a local capacity-type upper bound on I(Z;X) by penalizing pullback volume expansion of the encoder. We further derive a natural-gradient optimizer consistent with the FR metric and prove that the standard additive natural-gradient step is first-order equivalent to the geodesic update. We conducted extensive experiments and observed that the GeoIB achieves a better trade-off between prediction accuracy and compression ratio in the information plane than the mainstream IB baselines on popular datasets. GeoIB improves invariance and optimization stability by unifying distributional and geometric regularization under a single bottleneck multiplier. The source code of GeoIB is released at \"https://anonymous.4open.science/r/G-IB-0569\".", "AI": {"tldr": "论文提出了GeoIB，一种通过信息几何重新审视信息瓶颈问题的方法，改进了传统的信息瓶颈方法的压缩效果和稳定性。", "motivation": "传统的信息瓶颈方法在深度学习中通常使用可计算的替代方案而不是直接控制MI。这种间接性导致了优化不稳定性和偏差，因此论文希望通过引入信息几何来改善这一情况。", "method": "GeoIB通过将I(X;Z)和I(Z;Y)表示为到独立分布流形的最小K-L距离的形式，不依赖于MI估计。它使用两个互补项控制压缩：一个是在分布级别上的Fisher-Rao偏差，另一个是几何级别的Jacobian-Frobenius惩罚。", "result": "GeoIB在信息平面中的预测准确性和压缩率之间实现了更好的权衡，并且提高了不变性和平移稳定性。", "conclusion": "论文证明了通过引入信息几何可以改进传统的信息瓶颈方法，提供了优化稳定性的增强以及对MI的直接控制。"}}
{"id": "2602.03902", "pdf": "https://arxiv.org/pdf/2602.03902", "abs": "https://arxiv.org/abs/2602.03902", "authors": ["Jiying Zhang", "Shuhao Zhang", "Pierre Vandergheynst", "Patrick Barth"], "title": "All-Atom GPCR-Ligand Simulation via Residual Isometric Latent Flow", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "36 pages", "summary": "G-protein-coupled receptors (GPCRs), primary targets for over one-third of approved therapeutics, rely on intricate conformational transitions to transduce signals. While Molecular Dynamics (MD) is essential for elucidating this transduction process, particularly within ligand-bound complexes, conventional all-atom MD simulation is computationally prohibitive. In this paper, we introduce GPCRLMD, a deep generative framework for efficient all-atom GPCR-ligand simulation.GPCRLMD employs a Harmonic-Prior Variational Autoencoder (HP-VAE) to first map the complex into a regularized isometric latent space, preserving geometric topology via physics-informed constraints. Within this latent space, a Residual Latent Flow samples evolution trajectories, which are subsequently decoded back to atomic coordinates. By capturing temporal dynamics via relative displacements anchored to the initial structure, this residual mechanism effectively decouples static topology from dynamic fluctuations. Experimental results demonstrate that GPCRLMD achieves state-of-the-art performance in GPCR-ligand dynamics simulation, faithfully reproducing thermodynamic observables and critical ligand-receptor interactions.", "AI": {"tldr": "本文介绍了一种名为GPCRLMD的深度生成框架，用于高效模拟G蛋白偶联受体（GPCR）-配体复合物的动力学过程。", "motivation": "分子动力学(MD)对于阐明GPCR信号转导的过程至关重要，但在配体结合复合物中的模拟却因计算成本过高而难以实现。", "method": "该研究利用带有谐波先验的变分自动编码器(HP-VAE)，将复杂的结构映射到一个规则化的等距隐空间中，并通过物理约束保持几何拓扑。在这一隐空间内，使用剩余流采样演化轨迹并解码回原子坐标。", "result": "实验结果表明GPCRLMD在模拟GPCR-配体动态过程方面表现出色，准确再现了热力学观测值和关键的配体受体相互作用。", "conclusion": "该方法提供了一种高效且精确的方式，用于研究复杂的GPCR配体动力学，并有望改进药物发现的过程。"}}
{"id": "2602.03901", "pdf": "https://arxiv.org/pdf/2602.03901", "abs": "https://arxiv.org/abs/2602.03901", "authors": ["Rong Fu", "Wenxin Zhang", "Chunlei Meng", "Youjin Wang", "Haoyu Zhao", "Jiaxuan Lu", "Kun Liu", "JiaBao Dou", "Simon James Fong"], "title": "NeuroPareto: Calibrated Acquisition for Costly Many-Goal Search in Vast Parameter Spaces", "categories": ["cs.LG", "cs.NE"], "comment": "39 pages, 19 figures", "summary": "The pursuit of optimal trade-offs in high-dimensional search spaces under stringent computational constraints poses a fundamental challenge for contemporary multi-objective optimization. We develop NeuroPareto, a cohesive architecture that integrates rank-centric filtering, uncertainty disentanglement, and history-conditioned acquisition strategies to navigate complex objective landscapes. A calibrated Bayesian classifier estimates epistemic uncertainty across non-domination tiers, enabling rapid generation of high-quality candidates with minimal evaluation cost. Deep Gaussian Process surrogates further separate predictive uncertainty into reducible and irreducible components, providing refined predictive means and risk-aware signals for downstream selection. A lightweight acquisition network, trained online from historical hypervolume improvements, guides expensive evaluations toward regions balancing convergence and diversity. With hierarchical screening and amortized surrogate updates, the method maintains accuracy while keeping computational overhead low. Experiments on DTLZ and ZDT suites and a subsurface energy extraction task show that NeuroPareto consistently outperforms classifier-enhanced and surrogate-assisted baselines in Pareto proximity and hypervolume.", "AI": {"tldr": "本文提出了一种名为NeuroPareto的新方法，用于在高维参数空间中进行昂贵且多目标搜索。", "motivation": "现代多目标优化面临着在计算限制条件下找到复杂高维搜索空间中的最佳折衷方案的挑战。为了应对这一难题，研究人员开发了NeuroPareto架构。", "method": "NeuroPareto整合了基于排名的筛选、不确定性分离以及历史条件下的获取策略，通过一个校准后的贝叶斯分类器估计非支配等级间的认识论不确定性，并利用深度高斯过程代理将预测不确定性分为可减少和不可减少部分。一个轻量级获取网络则根据过去的超体积改进在线训练，指导昂贵的评估指向平衡收敛性和多样性的区域。", "result": "实验结果表明，在DTLZ和ZDT套件以及地下能源开采任务上，NeuroPareto在帕累托接近度和超体积方面持续优于增强型分类器和支持代理的基础方法。", "conclusion": "通过分级筛选、代理更新与成本控制，该方法能够保持准确性同时降低计算开销。实验结果证明了NeuroPareto的有效性与优越性。"}}
{"id": "2602.03900", "pdf": "https://arxiv.org/pdf/2602.03900", "abs": "https://arxiv.org/abs/2602.03900", "authors": ["Erik Goh", "John Kos", "Ashok Goel"], "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks", "categories": ["cs.AI"], "comment": ":I.2.4", "summary": "Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.", "AI": {"tldr": "本论文研究了使用Task-Method-Knowledge (TMK)框架通过结构化提示来提升大型语言模型（LLM）在规划任务上的表现。", "motivation": "大型语言模型在推理能力和规划任务上存在不足，尽管有许多促进其推理能力的技术如Chain-of-Thought，但这些技术的有效性受到质疑。本论文借鉴认知和教育科学领域的方法，探讨TMK框架是否能进一步提高LLM的推理能力。", "method": "通过实验，在PlanBench基准测试中的Blocksworld域中评估TMK框架的效果，具体考察TMK结构化提示能否帮助语言模型更好地分解复杂规划问题为可管理的小任务。", "result": "结果显示，TMK结构化提示使语言模型在不透明符号任务上的准确性从31.5%提升至97.3%，表明其有能力缩小语义近似与符号操作之间的差距。", "conclusion": "研究发现TMK不仅作为上下文存在，而且作为一种机制引导推理模型脱离默认的语言模式，转向形式化的代码执行路径。"}}
{"id": "2602.03899", "pdf": "https://arxiv.org/pdf/2602.03899", "abs": "https://arxiv.org/abs/2602.03899", "authors": ["Gilles Bareilles", "Wassim Bouaziz", "Julien Fageot", "El-Mahdi El-Mhamdi"], "title": "Byzantine Machine Learning: MultiKrum and an optimal notion of robustness", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "math.ST"], "comment": null, "summary": "Aggregation rules are the cornerstone of distributed (or federated) learning in the presence of adversaries, under the so-called Byzantine threat model. They are also interesting mathematical objects from the point of view of robust mean estimation. The Krum aggregation rule has been extensively studied, and endowed with formal robustness and convergence guarantees. Yet, MultiKrum, a natural extension of Krum, is often preferred in practice for its superior empirical performance, even though no theoretical guarantees were available until now. In this work, we provide the first proof that MultiKrum is a robust aggregation rule, and bound its robustness coefficient. To do so, we introduce $κ^\\star$, the optimal *robustness coefficient* of an aggregation rule, which quantifies the accuracy of mean estimation in the presence of adversaries in a tighter manner compared with previously adopted notions of robustness. We then construct an upper and a lower bound on MultiKrum's robustness coefficient. As a by-product, we also improve on the best-known bounds on Krum's robustness coefficient. We show that MultiKrum's bounds are never worse than Krum's, and better in realistic regimes. We illustrate this analysis by an experimental investigation on the quality of the lower bound.", "AI": {"tldr": "本文研究了MultiKrum聚合规则的鲁棒性，并引入了一个新的最优鲁棒系数的概念，以更精确地衡量在存在对手时均值估计的准确性。", "motivation": "尽管MultiKrum在实际应用中表现出色，但缺乏理论上的保证。因此，作者旨在证明MultiKrum是一个鲁棒的聚合规则，并为其提供理论上保障。", "method": "通过引入一个新的最优鲁棒系数κ*的概念，构造了MultiKrum和Krum鲁棒性的上下界。", "result": "证明了MultiKrum是具有理论保证的鲁棒聚合规则；展示了MultiKrum的鲁棒性比Krum更强，在实际情况下表现更优。通过实验验证了下界的分析。", "conclusion": "本文为MultiKrum提供了首个理论上的鲁棒性保障，并引入了一个新的最优鲁棒系数κ*的概念，这有助于在对抗模型中更准确地评估聚合规则的性能。"}}
{"id": "2602.03895", "pdf": "https://arxiv.org/pdf/2602.03895", "abs": "https://arxiv.org/abs/2602.03895", "authors": ["Xuwei Tan", "Ziyu Hu", "Xueru Zhang"], "title": "Benchmarking Bias Mitigation Toward Fairness Without Harm from Vision to LVLMs", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICLR 26", "summary": "Machine learning models trained on real-world data often inherit and amplify biases against certain social groups, raising urgent concerns about their deployment at scale. While numerous bias mitigation methods have been proposed, comparing the effectiveness of bias mitigation methods remains difficult due to heterogeneous datasets, inconsistent fairness metrics, isolated evaluation of vision versus multi-modal models, and insufficient hyperparameter tuning that undermines fair comparisons. We introduce NH-Fair, a unified benchmark for fairness without harm that spans both vision models and large vision-language models (LVLMs) under standardized data, metrics, and training protocols, covering supervised and zero-shot regimes. Our key contributions are: (1) a systematic ERM tuning study that identifies training choices with large influence on both utility and disparities, yielding empirically grounded guidelines to help practitioners reduce expensive hyperparameter tuning space in achieving strong fairness and accuracy; (2) evidence that many debiasing methods do not reliably outperform a well-tuned ERM baseline, whereas a composite data-augmentation method consistently delivers parity gains without sacrificing utility, emerging as a promising practical strategy. (3) an analysis showing that while LVLMs achieve higher average accuracy, they still exhibit subgroup disparities, and gains from scaling are typically smaller than those from architectural or training-protocol choices. NH-Fair provides a reproducible, tuning-aware pipeline for rigorous, harm-aware fairness evaluation.", "AI": {"tldr": "介绍NH-Fair，一个评估机器学习模型公平性的统一基准。", "motivation": "解决因数据异质性、不一致的公平度量等问题导致的偏见缓解方法对比困难的问题。", "method": "系统地研究了ERM调优，识别出影响效用和差异的关键训练选择，并提出了组合的数据增强方法以实现公平性和实用性兼得。", "result": "很多去偏方法并不能可靠地超过精心调整过的ERM基线；组合数据增强方法在不牺牲实用性的前提下一致地提高了群体间的平等性。LVLMs虽然平均精度更高，但在子群差距上依然存在问题。", "conclusion": "NH-Fair为公平评估提供了可重现、调优感知的流水线。"}}
{"id": "2602.03894", "pdf": "https://arxiv.org/pdf/2602.03894", "abs": "https://arxiv.org/abs/2602.03894", "authors": ["Hugo Markoff", "Stefan Hein Bengtson", "Michael Ørsted"], "title": "Vision Transformers for Zero-Shot Clustering of Animal Images: A Comparative Benchmarking Study", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Manual labeling of animal images remains a significant bottleneck in ecological research, limiting the scale and efficiency of biodiversity monitoring efforts. This study investigates whether state-of-the-art Vision Transformer (ViT) foundation models can reduce thousands of unlabeled animal images directly to species-level clusters. We present a comprehensive benchmarking framework evaluating five ViT models combined with five dimensionality reduction techniques and four clustering algorithms, two supervised and two unsupervised, across 60 species (30 mammals and 30 birds), with each test using a random subset of 200 validated images per species. We investigate when clustering succeeds at species-level, where it fails, and whether clustering within the species-level reveals ecologically meaningful patterns such as sex, age, or phenotypic variation. Our results demonstrate near-perfect species-level clustering (V-measure: 0.958) using DINOv3 embeddings with t-SNE and supervised hierarchical clustering methods. Unsupervised approaches achieve competitive performance (0.943) while requiring no prior species knowledge, rejecting only 1.14% of images as outliers requiring expert review. We further demonstrate robustness to realistic long-tailed distributions of species and show that intentional over-clustering can reliably extract intra-specific variation including age classes, sexual dimorphism, and pelage differences. We introduce an open-source benchmarking toolkit and provide recommendations for ecologists to select appropriate methods for sorting their specific taxonomic groups and data.", "AI": {"tldr": "本文探讨了使用Vision Transformer（ViT）模型对未标记的动物图像进行零样本聚类的有效性，通过实验评估了不同方法在物种级别分类中的性能。", "motivation": "手动标注动物图像在生态研究中是一个瓶颈问题，限制了生物多样性监测项目的规模和效率。本文旨在利用最先进的Vision Transformer（ViT）模型减少未标记的动物图像直接分类到物种级别的难度。", "method": "本研究采用五种不同的ViT模型结合五种降维技术以及四个聚类算法，在涵盖30种哺乳动物和30种鸟类共60个物种的数据集上进行了全面基准测试，每个测试使用每种物种随机选取的200张验证图像。", "result": "结果表明，使用DINOv3嵌入与t-SNE和监督分层聚类方法可以实现接近完美的物种级别分类（V-measure：0.958）。无监督方法同样取得了竞争性成绩（V-measure：0.943），并且只有1.14%的图像被标记为需要专家审查的异常值。", "conclusion": "研究展示了模型在处理现实中的长尾分布物种时的强大能力，证明了有意图地过度聚类可以可靠地提取包括年龄类别、性别二态性及毛皮差异在内的种内变异。此外，本文还提供了开源基准测试工具，并为生态学家选择适合其特定分类群体和数据的方法提供建议。"}}
{"id": "2602.03893", "pdf": "https://arxiv.org/pdf/2602.03893", "abs": "https://arxiv.org/abs/2602.03893", "authors": ["Yibing Wang", "Shuang Li", "Tingting Huang", "Yu Zhang", "Chulhong Kim", "Seongwook Choi", "Changhui Li"], "title": "GPAIR: Gaussian-Kernel-Based Ultrafast 3D Photoacoustic Iterative Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Although the iterative reconstruction (IR) algorithm can substantially correct reconstruction artifacts in photoacoustic (PA) computed tomography (PACT), it suffers from long reconstruction times, especially for large-scale three-dimensional (3D) imaging in which IR takes hundreds of seconds to hours. The computing burden severely limits the practical applicability of IR algorithms. In this work, we proposed an ultrafast IR method for 3D PACT, called Gaussian-kernel-based Ultrafast 3D Photoacoustic Iterative Reconstruction (GPAIR), which achieves orders-of-magnitude acceleration in computing. GPAIR transforms traditional spatial grids with continuous isotropic Gaussian kernels. By deriving analytical closed-form expression for pressure waves and implementing powerful GPU-accelerated differentiable Triton operators, GPAIR demonstrates extraordinary ultrafast sub-second reconstruction speed for 3D targets containing 8.4 million voxels in animal experiments. This revolutionary ultrafast image reconstruction enables near-real-time large-scale 3D PA reconstruction, significantly advancing 3D PACT toward clinical applications.", "AI": {"tldr": "该论文提出了一种名为GPAIR的超快速三维光声迭代重建方法，以实现大规模三维光声成像的近实时重建。", "motivation": "传统的迭代重建算法在三维光声计算断层成像中存在长时间的计算负担，严重限制了其实用性。为了加速计算过程并提高其实际应用价值，作者提出了GPAIR方法。", "method": "GPAIR通过使用连续的各向同性高斯核来转换传统空间网格，并推导出压力波的解析闭合形式表达式，同时利用强大的GPU加速可微Triton操作符实现了超快速重建。", "result": "实验表明，对于含有8.4百万体素的三维目标，GPAIR能够在动物实验中实现次秒级的重建速度。这使得大规模三维光声成像能够接近实时地完成。", "conclusion": "通过提出GPAIR方法，该研究显著推进了三维光声计算断层成像向临床应用的发展。"}}
{"id": "2602.03892", "pdf": "https://arxiv.org/pdf/2602.03892", "abs": "https://arxiv.org/abs/2602.03892", "authors": ["Jinxing Zhou", "Yanghao Zhou", "Yaoting Wang", "Zongyan Han", "Jiaqi Ma", "Henghui Ding", "Rao Muhammad Anwer", "Hisham Cholakkal"], "title": "Audit After Segmentation: Reference-Free Mask Quality Assessment for Language-Referred Audio-Visual Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "Language-referred audio-visual segmentation (Ref-AVS) aims to segment target objects described by natural language by jointly reasoning over video, audio, and text. Beyond generating segmentation masks, providing rich and interpretable diagnoses of mask quality remains largely underexplored. In this work, we introduce Mask Quality Assessment in the Ref-AVS context (MQA-RefAVS), a new task that evaluates the quality of candidate segmentation masks without relying on ground-truth annotations as references at inference time. Given audio-visual-language inputs and each provided segmentation mask, the task requires estimating its IoU with the unobserved ground truth, identifying the corresponding error type, and recommending an actionable quality-control decision. To support this task, we construct MQ-RAVSBench, a benchmark featuring diverse and representative mask error modes that span both geometric and semantic issues. We further propose MQ-Auditor, a multimodal large language model (MLLM)-based auditor that explicitly reasons over multimodal cues and mask information to produce quantitative and qualitative mask quality assessments. Extensive experiments demonstrate that MQ-Auditor outperforms strong open-source and commercial MLLMs and can be integrated with existing Ref-AVS systems to detect segmentation failures and support downstream segmentation improvement. Data and codes will be released at https://github.com/jasongief/MQA-RefAVS.", "AI": {"tldr": "该论文提出了在语言引导的音频视觉分割（Ref-AVS）上下文中评估分割掩码质量的任务，并开发了一种基于多模态大语言模型的审计器，用于无参考条件下的掩码质量评估。", "motivation": "当前的语言引导的音频视频分割技术主要关注生成分割掩码，而对这些掩码的质量诊断较少探讨。因此，该研究旨在提供一种无需依赖地面实况注释就能估计掩码质量的方法。", "method": "通过构建MQ-RAVSBench基准集来支持新任务，并提出了一种基于多模态大语言模型的审计器（MQ-Auditor），它能够综合考虑多模式线索和掩码信息，生成定量和定性的掩码质量评估。", "result": "实验表明，所提出的MQ-Auditor优于强大的开源和商业多模态大型语言模型，并可以与现有的Ref-AVS系统集成以检测分割失败并支持下游的分割改进。", "conclusion": "该工作通过开发新的任务和方法，为语言引导的音频视频分割的质量评估提供了有效的工具和技术。"}}
{"id": "2602.03891", "pdf": "https://arxiv.org/pdf/2602.03891", "abs": "https://arxiv.org/abs/2602.03891", "authors": ["Seohyun Joo", "Yoori Oh"], "title": "Sounding Highlights: Dual-Pathway Audio Encoders for Audio-Visual Video Highlight Detection", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.MM", "cs.SD"], "comment": "5 pages, 2 figures, to appear in ICASSP 2026", "summary": "Audio-visual video highlight detection aims to automatically identify the most salient moments in videos by leveraging both visual and auditory cues. However, existing models often underutilize the audio modality, focusing on high-level semantic features while failing to fully leverage the rich, dynamic characteristics of sound. To address this limitation, we propose a novel framework, Dual-Pathway Audio Encoders for Video Highlight Detection (DAViHD). The dual-pathway audio encoder is composed of a semantic pathway for content understanding and a dynamic pathway that captures spectro-temporal dynamics. The semantic pathway extracts high-level information by identifying the content within the audio, such as speech, music, or specific sound events. The dynamic pathway employs a frequency-adaptive mechanism as time evolves to jointly model these dynamics, enabling it to identify transient acoustic events via salient spectral bands and rapid energy changes. We integrate the novel audio encoder into a full audio-visual framework and achieve new state-of-the-art performance on the large-scale Mr.HiSum benchmark. Our results demonstrate that a sophisticated, dual-faceted audio representation is key to advancing the field of highlight detection.", "AI": {"tldr": "提出了一种新的双通路音频编码框架DAViHD，用于音视频精彩片段检测。", "motivation": "现有模型通常未能充分利用音频模式的丰富动态特性，专注于高级语义特征而忽略了瞬时声学事件。", "method": "设计了包含内容理解和捕捉频谱时间动力学的双通路音频编码器。内容理解路径提取高级信息，频谱时间动力学通过频率自适应机制建模。", "result": "在Mr.HiSum基准测试中实现了最先进的性能，表明复杂的双面音频表示对提升精彩片段检测领域至关重要。", "conclusion": "提出的DAViHD框架能够更有效地利用音频特征进行音视频精彩片段检测。"}}
{"id": "2602.03890", "pdf": "https://arxiv.org/pdf/2602.03890", "abs": "https://arxiv.org/abs/2602.03890", "authors": ["Xindan Zhang", "Weilong Yan", "Yufei Shi", "Xuerui Qiu", "Tao He", "Ying Li", "Ming Li", "Hehe Fan"], "title": "4DPC$^2$hat: Towards Dynamic Point Cloud Understanding with Failure-Aware Bootstrapping", "categories": ["cs.CV"], "comment": null, "summary": "Point clouds provide a compact and expressive representation of 3D objects, and have recently been integrated into multimodal large language models (MLLMs). However, existing methods primarily focus on static objects, while understanding dynamic point cloud sequences remains largely unexplored. This limitation is mainly caused by the lack of large-scale cross-modal datasets and the difficulty of modeling motions in spatio-temporal contexts. To bridge this gap, we present 4DPC$^2$hat, the first MLLM tailored for dynamic point cloud understanding. To this end, we construct a large-scale cross-modal dataset 4DPC$^2$hat-200K via a meticulous two-stage pipeline consisting of topology-consistent 4D point construction and two-level captioning. The dataset contains over 44K dynamic object sequences, 700K point cloud frames, and 200K curated question-answer (QA) pairs, supporting inquiries about counting, temporal relationship, action, spatial relationship, and appearance. At the core of the framework, we introduce a Mamba-enhanced temporal reasoning MLLM to capture long-range dependencies and dynamic patterns among a point cloud sequence. Furthermore, we propose a failure-aware bootstrapping learning strategy that iteratively identifies model deficiencies and generates targeted QA supervision to continuously strengthen corresponding reasoning capabilities. Extensive experiments demonstrate that our 4DPC$^2$hat significantly improves action understanding and temporal reasoning compared with existing models, establishing a strong foundation for 4D dynamic point cloud understanding.", "AI": {"tldr": "4DPC$^2$hat 是一种用于理解动态点云序列的多模态大型语言模型，通过构建大规模跨模态数据集和引入失败感知引导学习策略来提高动作理解和时间推理能力。", "motivation": "现有方法主要集中在静态对象的理解上，缺乏对动态点云序列的理解。这主要是由于缺少大规模跨模态数据集以及在时空上下文中建模运动的困难。", "method": "该研究构建了一个大型跨模态数据集4DPC$^2$hat-200K，并提出了一个增强的时间推理多模态大语言模型，同时引入了失败感知引导学习策略以提高模型性能。", "result": "实验表明，与现有方法相比，4DPC$^2$hat 在动作理解和时间推理上具有显著改进。", "conclusion": "该研究通过构建大规模数据集和提出新颖的学习策略，为动态点云的理解打下了坚实的基础。"}}
{"id": "2602.03887", "pdf": "https://arxiv.org/pdf/2602.03887", "abs": "https://arxiv.org/abs/2602.03887", "authors": ["Weiming Chen", "Xitong Ling", "Xidong Wang", "Zhenyang Cai", "Yijia Guo", "Mingxi Fu", "Ziyi Zeng", "Minxi Ouyang", "Jiawen Li", "Yizhi Wang", "Tian Guan", "Benyou Wang", "Yonghong He"], "title": "To What Extent Do Token-Level Representations from Pathology Foundation Models Improve Dense Prediction?", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Pathology foundation models (PFMs) have rapidly advanced and are becoming a common backbone for downstream clinical tasks, offering strong transferability across tissues and institutions. However, for dense prediction (e.g., segmentation), practical deployment still lacks a clear, reproducible understanding of how different PFMs behave across datasets and how adaptation choices affect performance and stability. We present PFM-DenseBench, a large-scale benchmark for dense pathology prediction, evaluating 17 PFMs across 18 public segmentation datasets. Under a unified protocol, we systematically assess PFMs with multiple adaptation and fine-tuning strategies, and derive insightful, practice-oriented findings on when and why different PFMs and tuning choices succeed or fail across heterogeneous datasets. We release containers, configs, and dataset cards to enable reproducible evaluation and informed PFM selection for real-world dense pathology tasks. Project Website: https://m4a1tastegood.github.io/PFM-DenseBench", "AI": {"tldr": "病理学基础模型在密集预测任务中的表现评估。", "motivation": "探索不同病理学基础模型在密集预测任务上的适应性和性能差异，为实际应用提供指导。", "method": "建立PFM-DenseBench基准测试平台，评估17种病理学基础模型在18个公开分割数据集的表现，并采用多种适配和微调策略进行系统性评估。", "result": "得出关于不同病理学基础模型及其调整选择如何影响性能的实用见解。", "conclusion": "提供了详细的实践指导，帮助用户根据具体需求选择合适的病理学基础模型。"}}
{"id": "2602.03883", "pdf": "https://arxiv.org/pdf/2602.03883", "abs": "https://arxiv.org/abs/2602.03883", "authors": ["Akshansh Mishra", "Rakesh Morisetty"], "title": "Explainable Computer Vision Framework for Automated Pore Detection and Criticality Assessment in Additive Manufacturing", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG"], "comment": "6 figures", "summary": "Internal porosity remains a critical defect mode in additively manufactured components, compromising structural performance and limiting industrial adoption. Automated defect detection methods exist but lack interpretability, preventing engineers from understanding the physical basis of criticality predictions. This study presents an explainable computer vision framework for pore detection and criticality assessment in three-dimensional tomographic volumes. Sequential grayscale slices were reconstructed into volumetric datasets, and intensity-based thresholding with connected component analysis identified 500 individual pores. Each pore was characterized using geometric descriptors including size, aspect ratio, extent, and spatial position relative to the specimen boundary. A pore interaction network was constructed using percentile-based Euclidean distance criteria, yielding 24,950 inter-pore connections. Machine learning models predicted pore criticality scores from extracted features, and SHAP analysis quantified individual feature contributions. Results demonstrate that normalized surface distance dominates model predictions, contributing more than an order of magnitude greater importance than all other descriptors. Pore size provides minimal influence, while geometric parameters show negligible impact. The strong inverse relationship between surface proximity and criticality reveals boundary-driven failure mechanisms. This interpretable framework enables transparent defect assessment and provides actionable insights for process optimization and quality control in additive manufacturing.", "AI": {"tldr": "该论文提出了一种可解释的计算机视觉框架，用于增材制造内部孔隙检测和评估。", "motivation": "由于内部孔隙是增材制造的关键缺陷模式，现有的自动检测方法缺乏解释性，因此工程师无法理解关键性的物理基础。", "method": "通过灰度阈值分割与连通组件分析识别出500个独立的孔。利用几何特征描述孔特性，并构建孔相互作用网络。最后使用机器学习模型预测孔的关键性评分并用SHAP分析量化各特征贡献。", "result": "结果显示，归一化表面距离对模型预测的影响最大，而孔径大小影响很小，几何参数几乎无影响。", "conclusion": "该可解释框架能够透明地评估缺陷，并为增材制造的过程优化和质量控制提供操作见解。"}}
{"id": "2602.03882", "pdf": "https://arxiv.org/pdf/2602.03882", "abs": "https://arxiv.org/abs/2602.03882", "authors": ["Haijiang Yan", "Nick Chater", "Adam Sanborn"], "title": "PriorProbe: Recovering Individual-Level Priors for Personalizing Neural Networks in Facial Expression Recognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Incorporating individual-level cognitive priors offers an important route to personalizing neural networks, yet accurately eliciting such priors remains challenging: existing methods either fail to uniquely identify them or introduce systematic biases. Here, we introduce PriorProbe, a novel elicitation approach grounded in Markov Chain Monte Carlo with People that recovers fine-grained, individual-specific priors. Focusing on a facial expression recognition task, we apply PriorProbe to individual participants and test whether integrating the recovered priors with a state-of-the-art neural network improves its ability to predict an individual's classification on ambiguous stimuli. The PriorProbe-derived priors yield substantial performance gains, outperforming both the neural network alone and alternative sources of priors, while preserving the network's inference on ground-truth labels. Together, these results demonstrate that PriorProbe provides a general and interpretable framework for personalizing deep neural networks.", "AI": {"tldr": "PriorProbe是一种新的人工智能方法，用于恢复个人的认知先验以个性化神经网络，在面部表情识别任务中表现出色。", "motivation": "准确获取个体认知先验是个性化解析深度学习模型的关键挑战。现有的技术要么无法唯一确定这些先验，要么引入系统偏差。因此需要开发一种新的方法来解决这个问题。", "method": "PriorProbe采用基于人与马尔可夫链蒙特卡罗的方法，通过参与者的数据恢复细粒度的个体特定先验，并将其应用于神经网络以提高其预测性能。", "result": "实验结果表明，使用PriorProbe提取的先验显著提高了模型在模糊刺激物上的分类精度，优于单独使用深度学习模型和其他先验源的表现。", "conclusion": "PriorProbe提供了一个通用且可解释的框架来个性化深层神经网络，并展示了它在面部表情识别任务中的有效性和优越性。"}}
{"id": "2602.03881", "pdf": "https://arxiv.org/pdf/2602.03881", "abs": "https://arxiv.org/abs/2602.03881", "authors": ["Maxx Richard Rahman", "Mostafa Hammouda", "Wolfgang Maass"], "title": "DiGAN: Diffusion-Guided Attention Network for Early Alzheimer's Disease Detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Early diagnosis of Alzheimer's disease (AD) remains a major challenge due to the subtle and temporally irregular progression of structural brain changes in the prodromal stages. Existing deep learning approaches require large longitudinal datasets and often fail to model the temporal continuity and modality irregularities inherent in real-world clinical data. To address these limitations, we propose the Diffusion-Guided Attention Network (DiGAN), which integrates latent diffusion modelling with an attention-guided convolutional network. The diffusion model synthesizes realistic longitudinal neuroimaging trajectories from limited training data, enriching temporal context and improving robustness to unevenly spaced visits. The attention-convolutional layer then captures discriminative structural--temporal patterns that distinguish cognitively normal subjects from those with mild cognitive impairment and subjective cognitive decline. Experiments on synthetic and ADNI datasets demonstrate that DiGAN outperforms existing state-of-the-art baselines, showing its potential for early-stage AD detection.", "AI": {"tldr": "该论文提出了一种名为DiGAN的扩散引导注意力网络，用于早期阿尔茨海默病检测。", "motivation": "当前深度学习方法需要大量的纵向数据，并且难以模拟真实的临床数据中的时间连续性和模式不规则性。为了克服这些问题，作者提出了DiGAN。", "method": "该模型结合了潜在扩散建模和注意力引导卷积网络，从有限的训练数据中合成现实的纵向神经影像轨迹，提高了对不均匀间隔访问的鲁棒性，并通过注意力-卷积层捕捉区分认知正常个体与轻度认知障碍或主观认知下降模式的时间结构特征。", "result": "实验结果表明DiGAN在合成和ADNI数据集上优于现有最先进基线模型，展示了其早期阿尔茨海默病检测的潜力。", "conclusion": "DiGAN通过结合扩散建模和注意力引导卷积网络，在有限的数据下提高了早期阿尔茨海默病诊断的准确性。"}}
{"id": "2602.03879", "pdf": "https://arxiv.org/pdf/2602.03879", "abs": "https://arxiv.org/abs/2602.03879", "authors": ["Ali Bayeh", "Samira Sadaoui", "Malek Mouhoub"], "title": "TruKAN: Towards More Efficient Kolmogorov-Arnold Networks Using Truncated Power Functions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "23 pages, 9 figures", "summary": "To address the trade-off between computational efficiency and adherence to Kolmogorov-Arnold Network (KAN) principles, we propose TruKAN, a new architecture based on the KAN structure and learnable activation functions. TruKAN replaces the B-spline basis in KAN with a family of truncated power functions derived from k-order spline theory. This change maintains the KAN's expressiveness while enhancing accuracy and training time. Each TruKAN layer combines a truncated power term with a polynomial term and employs either shared or individual knots. TruKAN exhibits greater interpretability than other KAN variants due to its simplified basis functions and knot configurations. By prioritizing interpretable basis functions, TruKAN aims to balance approximation efficacy with transparency. We develop the TruKAN model and integrate it into an advanced EfficientNet-V2-based framework, which is then evaluated on computer vision benchmark datasets. To ensure a fair comparison, we develop various models: MLP-, KAN-, SineKAN and TruKAN-based EfficientNet frameworks and assess their training time and accuracy across small and deep architectures. The training phase uses hybrid optimization to improve convergence stability. Additionally, we investigate layer normalization techniques for all the models and assess the impact of shared versus individual knots in TruKAN. Overall, TruKAN outperforms other KAN models in terms of accuracy, computational efficiency and memory usage on the complex vision task, demonstrating advantages beyond the limited settings explored in prior KAN studies.", "AI": {"tldr": "提出TruKAN架构，通过使用截断幂函数替换KAN中的B样条基来提高计算效率和准确性。", "motivation": "为了在保持KAN原则的同时解决计算效率与表达力之间的权衡问题", "method": "将k阶样条理论的截断幂函数家族应用于TruKAN架构，每层结合了截断幂项和多项式项，并采用共享或个体节点。", "result": "在计算机视觉基准数据集上进行评估时，TruKAN在准确性和计算效率方面优于其他KAN模型。", "conclusion": "通过引入截断幂函数来改进KAN架构，实现了更好的可解释性、更高的准确性以及更高效的训练时间。"}}
{"id": "2602.03878", "pdf": "https://arxiv.org/pdf/2602.03878", "abs": "https://arxiv.org/abs/2602.03878", "authors": ["Longjie Zhao", "Ziming Hong", "Jiaxin Huang", "Runnan Chen", "Mingming Gong", "Tongliang Liu"], "title": "Intellectual Property Protection for 3D Gaussian Splatting Assets: A Survey", "categories": ["cs.CV", "cs.CR"], "comment": "A collection of relevant papers is summarized and will be continuously updated at \\url{https://github.com/tmllab/Awesome-3DGS-IP-Protection}", "summary": "3D Gaussian Splatting (3DGS) has become a mainstream representation for real-time 3D scene synthesis, enabling applications in virtual and augmented reality, robotics, and 3D content creation. Its rising commercial value and explicit parametric structure raise emerging intellectual property (IP) protection concerns, prompting a surge of research on 3DGS IP protection. However, current progress remains fragmented, lacking a unified view of the underlying mechanisms, protection paradigms, and robustness challenges. To address this gap, we present the first systematic survey on 3DGS IP protection and introduce a bottom-up framework that examines (i) underlying Gaussian-based perturbation mechanisms, (ii) passive and active protection paradigms, and (iii) robustness threats under emerging generative AI era, revealing gaps in technical foundations and robustness characterization and indicating opportunities for deeper investigation. Finally, we outline six research directions across robustness, efficiency, and protection paradigms, offering a roadmap toward reliable and trustworthy IP protection for 3DGS assets.", "AI": {"tldr": "该论文对3D高斯点集知识产权保护进行了系统性综述，提出了基于高斯扰动机制、被动和主动保护模式以及新兴AI威胁的综合框架，并指出了未来的研究方向。", "motivation": "随着3D高斯点集在实时三维场景合成中的广泛应用及其商业价值的增长，其明确参数结构引发了知识产权保护的关注。然而，目前的研究进展仍然较为碎片化，缺乏统一的技术基础和鲁棒性分析，因此本文提出了系统性的综述框架来填补这一空白。", "method": "通过梳理高斯扰动机制、被动及主动保护模式以及针对新兴AI的威胁进行详细讨论，并指出了技术基础与鲁棒性方面的不足之处。", "result": "揭示了当前3D高斯点集知识产权保护研究中的技术缺陷和鲁棒性挑战，为未来的研究提供了六个方向性的建议：加强鲁棒性、提高效率及探索新的保护模式。", "conclusion": "本文提出了对3D高斯点集知识产权保护的系统性综述框架，并通过识别现有研究中的不足之处，为未来的深入研究指明了方向。"}}
{"id": "2602.03876", "pdf": "https://arxiv.org/pdf/2602.03876", "abs": "https://arxiv.org/abs/2602.03876", "authors": ["Kyuseong Choi", "Dwaipayan Saha", "Woojeong Kim", "Anish Agarwal", "Raaz Dwivedi"], "title": "GOPO: Policy Optimization using Ranked Rewards", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 8 figures", "summary": "Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimization techniques rely on absolute reward magnitudes during training. In settings where the rewards are non-verifiable such as summarization, instruction following, and chat completion, this misalignment often leads to suboptimal performance. We introduce Group Ordinal Policy Optimization (GOPO), a policy optimization method that uses only the ranking of the rewards and discards their magnitudes. Our rank-based transformation of rewards provides several gains, compared to Group Relative Policy Optimization (GRPO), in settings with non-verifiable rewards: (1) consistently higher training/validation reward trajectories, (2) improved LLM-as-judge evaluations across most intermediate training steps, and (3) reaching a policy of comparable quality in substantially less training steps than GRPO. We demonstrate consistent improvements across a range of tasks and model sizes.", "AI": {"tldr": "介绍了一种新的策略优化方法GOPO，该方法使用奖励排名而不是绝对值进行训练，以提高在不可验证环境中RLHF的性能。", "motivation": "标准的RLHF技术依赖于绝对奖励的大小来进行策略优化，这与相对奖励模型捕捉的偏好不符，在无法核实奖励的情况下会导致次优表现。因此需要一种新的方法来解决此问题。", "method": "提出了一种基于排名的方法GOPO，该方法仅使用奖励的排名而忽略其实际数值进行策略优化，适用于不可验证奖励的情境如总结、指令遵循和聊天完成任务。", "result": "对比现有GRPO技术，GOPO在多种设置下表现出更优的训练和验证奖励轨迹，并且在LLM作为评判的标准下表现更好。此外，在达到相同质量政策所需的时间上也显著减少。", "conclusion": "研究表明，使用排名而非绝对奖励值进行策略优化能够有效提升RLHF模型在非可验证环境中的性能和效率。"}}
{"id": "2602.03875", "pdf": "https://arxiv.org/pdf/2602.03875", "abs": "https://arxiv.org/abs/2602.03875", "authors": ["Stefan Kuhn", "Vandana Dwarka", "Przemyslaw Karol Grenda", "Eero Vainikko"], "title": "Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "10 pages, 4 figures, 4 tables", "summary": "We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by construction. We train the model to predict a 128-bit binned spectrum code from a graph-based structure encoding, while the remaining latent dimensions capture residual variability. At inference time, we invert the same trained network to generate structure candidates from a spectrum code, which explicitly represents the one-to-many nature of spectrum-to-structure inference. On a filtered subset, the model is numerically invertible on trained examples, achieves spectrum-code prediction above chance, and produces coarse but meaningful structural signals when inverted on validation spectra. These results demonstrate that invertible architectures can unify spectrum prediction and uncertainty-aware candidate generation within one end-to-end model.", "AI": {"tldr": "开发了一种可逆的深度学习模型，用于从分子结构预测13C NMR光谱，并从光谱生成可能的分子结构。", "motivation": "通过单个条件可逆神经网络实现分子结构与13C NMR光谱之间的双向映射，以提高化学信息学中的光谱分析能力并解决光谱到结构的推断问题。", "method": "使用i-RevNet样式的双射块构建模型，训练该模型从图编码结构预测128位分箱光谱代码，并在验证光谱上生成有意义的结构信号。", "result": "模型在滤除子集上实现了数值可逆性，提高了光谱代码预测准确性，并能产生粗略但有意义的结构信号。", "conclusion": "研究表明，可逆架构可以在一个端到端模型中统一光谱预测和不确定性感知候选生成。"}}
{"id": "2602.03873", "pdf": "https://arxiv.org/pdf/2602.03873", "abs": "https://arxiv.org/abs/2602.03873", "authors": ["Hong Jia", "Weibin Li", "Jingyao Wu", "Xiaofeng Yu", "Yan Gao", "Jintao Cheng", "Xiaoyu Tang", "Feng Xia", "Ting Dang"], "title": "Decoding Ambiguous Emotions with Test-Time Scaling in Audio-Language Models", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Emotion recognition from human speech is a critical enabler for socially aware conversational AI. However, while most prior work frames emotion recognition as a categorical classification problem, real-world affective states are often ambiguous, overlapping, and context-dependent, posing significant challenges for both annotation and automatic modeling. Recent large-scale audio language models (ALMs) offer new opportunities for nuanced affective reasoning without explicit emotion supervision, but their capacity to handle ambiguous emotions remains underexplored. At the same time, advances in inference-time techniques such as test-time scaling (TTS) have shown promise for improving generalization and adaptability in hard NLP tasks, but their relevance to affective computing is still largely unknown. In this work, we introduce the first benchmark for ambiguous emotion recognition in speech with ALMs under test-time scaling. Our evaluation systematically compares eight state-of-the-art ALMs and five TTS strategies across three prominent speech emotion datasets. We further provide an in-depth analysis of the interaction between model capacity, TTS, and affective ambiguity, offering new insights into the computational and representational challenges of ambiguous emotion understanding. Our benchmark establishes a foundation for developing more robust, context-aware, and emotionally intelligent speech-based AI systems, and highlights key future directions for bridging the gap between model assumptions and the complexity of real-world human emotion.", "AI": {"tldr": "本文介绍了首个针对音频语言模型在测试时间缩放下的模糊情感识别基准，系统地比较了八种最先进的音频语言模型和五种测试时间缩放策略。", "motivation": "现有的语音情绪识别通常被视作分类问题，但在现实世界中，情绪往往是模棱两可的、重叠且依赖于上下文，这给标注和自动建模带来了挑战。因此，研究如何利用测试时间缩放技术改进音频语言模型对模糊情感的理解变得至关重要。", "method": "本文在三个著名的语音情感数据集上系统地评估了八种最先进的音频语言模型及五种测试时间缩放策略之间的交互作用，并深入分析了模型容量、测试时间缩放与情绪模棱两可性的关系。", "result": "研究表明，通过合适的测试时间缩放策略可以显著提高模糊情感识别的性能；同时发现了模型容量对于处理复杂的人类情感的重要性。", "conclusion": "本文确立了一个研究更稳健、上下文感知和情感智能语音AI系统的基准，并指出了未来开发能够更好地应对现实世界中情绪复杂性的技术方向。"}}
{"id": "2602.03872", "pdf": "https://arxiv.org/pdf/2602.03872", "abs": "https://arxiv.org/abs/2602.03872", "authors": ["Jiaming Zhang", "Huanyi Xie", "Meng Ding", "Shaopeng Fu", "Jinyan Liu", "Di Wang"], "title": "Understanding the Impact of Differentially Private Training on Memorization of Long-Tailed Data", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2502.11893 by other authors", "summary": "Recent research shows that modern deep learning models achieve high predictive accuracy partly by memorizing individual training samples. Such memorization raises serious privacy concerns, motivating the widespread adoption of differentially private training algorithms such as DP-SGD. However, a growing body of empirical work shows that DP-SGD often leads to suboptimal generalization performance, particularly on long-tailed data that contain a large number of rare or atypical samples. Despite these observations, a theoretical understanding of this phenomenon remains largely unexplored, and existing differential privacy analysis are difficult to extend to the nonconvex and nonsmooth neural networks commonly used in practice. In this work, we develop the first theoretical framework for analyzing DP-SGD on long-tailed data from a feature learning perspective. We show that the test error of DP-SGD-trained models on the long-tailed subpopulation is significantly larger than the overall test error over the entire dataset. Our analysis further characterizes the training dynamics of DP-SGD, demonstrating how gradient clipping and noise injection jointly adversely affect the model's ability to memorize informative but underrepresented samples. Finally, we validate our theoretical findings through extensive experiments on both synthetic and real-world datasets.", "AI": {"tldr": "本文开发了第一个从特征学习角度分析DP-SGD在长尾数据集上训练动态的理论框架。", "motivation": "现代深度学习模型通过记忆个别训练样本获得高预测准确性，引发隐私担忧。DP-SGD虽然被广泛应用以解决这个问题，但在处理包含大量罕见或不典型样本的数据时表现不佳，因此需要从理论上理解这一现象。", "method": "本文提出了一个理论框架，通过特征学习视角分析DP-SGD在长尾数据上的训练过程，并研究了梯度裁剪和噪声注入如何共同影响模型记忆稀有但信息丰富的样本的能力。", "result": "实验结果验证了论文中的理论发现：DP-SGD训练的模型在长尾子群体上的测试误差显著高于整个数据集的整体测试误差。", "conclusion": "研究揭示了DP-SGD对长尾分布数据的影响，并表明噪声注入和梯度裁剪限制了模型记忆稀有但信息丰富的样本的能力。"}}
{"id": "2602.03870", "pdf": "https://arxiv.org/pdf/2602.03870", "abs": "https://arxiv.org/abs/2602.03870", "authors": ["Jiayu Huo", "Jingyuan Hong", "Liyun Chen"], "title": "DINO-AD: Unsupervised Anomaly Detection with Frozen DINO-V3 Features", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted by ISBI 2026, 4 pages, 2 figures, 3 tables", "summary": "Unsupervised anomaly detection (AD) in medical images aims to identify abnormal regions without relying on pixel-level annotations, which is crucial for scalable and label-efficient diagnostic systems. In this paper, we propose a novel anomaly detection framework based on DINO-V3 representations, termed DINO-AD, which leverages self-supervised visual features for precise and interpretable anomaly localization. Specifically, we introduce an embedding similarity matching strategy to select a semantically aligned support image and a foreground-aware K-means clustering module to model the distribution of normal features. Anomaly maps are then computed by comparing the query features with clustered normal embeddings through cosine similarity. Experimental results on both the Brain and Liver datasets demonstrate that our method achieves superior quantitative performance compared with state-of-the-art approaches, achieving AUROC scores of up to 98.71. Qualitative results further confirm that our framework produces clearer and more accurate anomaly localization. Extensive ablation studies validate the effectiveness of each proposed component, highlighting the robustness and generalizability of our approach.", "AI": {"tldr": "本文提出了一种基于DINO-V3表示的无监督异常检测框架DINO-AD，用于医学图像中的异常区域识别。", "motivation": "在缺乏像素级注释的情况下，无监督异常检测对于开发可扩展和标签高效的诊断系统至关重要。此方法旨在利用自监督视觉特征进行精确且可解释的异常定位。", "method": "提出了一种基于DINO-V3表示的框架DINO-AD，包括嵌入相似性匹配策略以选择语义对齐的支持图像以及前景感知K-means聚类模块来建模正常特征分布。通过余弦相似度比较查询特征和聚类后的正常嵌入生成异常图。", "result": "实验结果表明，在大脑和肝脏数据集上，该方法与现有最先进技术相比实现了更高的AUROC分数（高达98.71），并且定性结果显示其具有更清晰准确的异常定位能力。消融研究表明每个组件的有效性和框架的鲁棒性和泛化能力。", "conclusion": "DINO-AD通过利用预训练模型的特征进行无监督学习，显著提高了医学图像中异常检测的准确性，并证明了该方法在实际应用中的潜力和价值。"}}
{"id": "2602.03868", "pdf": "https://arxiv.org/pdf/2602.03868", "abs": "https://arxiv.org/abs/2602.03868", "authors": ["Chandrashekar M S", "Vineet Singh", "Lakshmi Pedapudi"], "title": "Benchmarking Automatic Speech Recognition for Indian Languages in Agricultural Contexts", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "comment": "9 pages, 6 figures", "summary": "The digitization of agricultural advisory services in India requires robust Automatic Speech Recognition (ASR) systems capable of accurately transcribing domain-specific terminology in multiple Indian languages. This paper presents a benchmarking framework for evaluating ASR performance in agricultural contexts across Hindi, Telugu, and Odia languages. We introduce evaluation metrics including Agriculture Weighted Word Error Rate (AWWER) and domain-specific utility scoring to complement traditional metrics. Our evaluation of 10,934 audio recordings, each transcribed by up to 10 ASR models, reveals performance variations across languages and models, with Hindi achieving the best overall performance (WER: 16.2%) while Odia presents the greatest challenges (best WER: 35.1%, achieved only with speaker diarization). We characterize audio quality challenges inherent to real-world agricultural field recordings and demonstrate that speaker diarization with best-speaker selection can substantially reduce WER for multi-speaker recordings (upto 66% depending on the proportion of multi-speaker audio). We identify recurring error patterns in agricultural terminology and provide practical recommendations for improving ASR systems in low-resource agricultural domains. The study establishes baseline benchmarks for future agricultural ASR development.", "AI": {"tldr": "本文提出了一个评估印度农业领域自动语音识别（ASR）系统的基准框架，重点关注印地语、泰卢固语和奥迪亚语。", "motivation": "为了实现印度农业咨询服务平台的数字化，需要开发能够准确转录多语言专业术语的稳健ASR系统。目前缺乏针对这些特定领域的评估指标和技术。", "method": "作者引入了一种新的评价标准体系，包括农业加权词错误率（AWWER）和领域实用性评分，并使用10,934个音频片段对十个ASR模型进行测试。分析了不同语言中各系统的性能差异以及如何通过说话人识别提高多说话者场景下的准确度。", "result": "印地语ASR系统表现最佳，其词错误率为16.2%；奥迪亚语最困难，最好的词错误率为35.1%，且仅在使用说话人分离的情况下实现。发现并记录了农业术语中的重复误识模式，并提出改进低资源环境下的ASR系统的实际建议。", "conclusion": "该研究为印度多语言农业领域的未来ASR系统开发提供了基准测试结果，强调了领域特定评估的重要性以及技术进步的必要性。"}}
{"id": "2602.03866", "pdf": "https://arxiv.org/pdf/2602.03866", "abs": "https://arxiv.org/abs/2602.03866", "authors": ["Tao Yu", "Minghui Zhang", "Zhiqing Cui", "Hao Wang", "Zhongtian Luo", "Shenghua Chai", "Junhao Gong", "Yuzhao Peng", "Yuxuan Zhou", "Yujia Yang", "Zhenghao Zhang", "Haopeng Jin", "Xinming Wang", "Yufei Xiong", "Jiabing Yang", "Jiahao Yuan", "Hanqing Wang", "Hongzhu Yi", "YiFan Zhang", "Yan Huang", "Liang Wang"], "title": "PaperX: A Unified Framework for Multimodal Academic Presentation Generation with Scholar DAG", "categories": ["cs.DL", "cs.AI"], "comment": "29 pages, 9 figures", "summary": "Transforming scientific papers into multimodal presentation content is essential for research dissemination but remains labor intensive. Existing automated solutions typically treat each format as an isolated downstream task, leading to redundant processing and semantic inconsistency. We introduce PaperX, a unified framework that models academic presentation generation as a structural transformation and rendering process. Central to our approach is the Scholar DAG, an intermediate representation that decouples the paper's logical structure from its final presentation syntax. By applying adaptive graph traversal strategies, PaperX generates diverse, high quality outputs from a single source. Comprehensive evaluations demonstrate that our framework achieves the state of the art performance in content fidelity and aesthetic quality while significantly improving cost efficiency compared to specialized single task agents.", "AI": {"tldr": "论文X提出了一种统一框架，用于将学术论文转换为多模态展示内容。", "motivation": "现有的自动化解决方案通常将每种格式视为独立的任务处理，导致冗余和语义不一致。因此需要一种更有效的方法来提高研究的传播效率。", "method": "论文X采用学者DAG作为中间表示形式，并通过自适应图遍历策略生成高质量、多样化的输出。", "result": "评估表明该框架在内容忠实性和美学质量方面达到了最先进的性能，同时与专门的任务代理相比，显著提高了成本效益。", "conclusion": "PaperX提供了一种有效的方法来自动化学术论文的多模态展示转换过程，从而提高研究传播效率和质量。"}}
{"id": "2602.03854", "pdf": "https://arxiv.org/pdf/2602.03854", "abs": "https://arxiv.org/abs/2602.03854", "authors": ["Mona Alfayez", "Ohoud Alharbi"], "title": "From Expectation To Experience: A Before And After Survey Of Public Opinion On Autonomous Cars In Saudi Arabia", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Autonomous vehicles (AVs) are emerging as a transformative innovation in transportation, offering potential benefits in safety, sustainability, and efficiency. Saudi Arabian adoption of AVs aligns with Vision 2030, emphasizing smart mobility through initiatives such as the Riyadh Autonomous Metro and self-driving cars. This study explores Saudi citizens perceptions of AVs before and after exposure to these technologies and examines whether demographic factors age, gender, education level, and driving habits affect acceptance. Using quantitative methods, the findings provide insights into the broader influences shaping AV adoption, highlighting the importance of trust, perceived safety, and convenience. These results can inform policymakers and industry stakeholders on strategies to facilitate successful integration of AVs into Saudi Arabian transportation ecosystem.", "AI": {"tldr": "研究探讨了沙特公民对自动驾驶汽车的态度变化及其影响因素。", "motivation": "探索沙特阿拉伯民众在接触自动驾驶技术前后对其的看法，并分析年龄、性别等因素如何影响接受程度，以支持政策制定和行业策略的制定。", "method": "采用定量方法，通过问卷调查来衡量公众态度的变化。", "result": "发现信任度、感知的安全性和便利性是影响自动驾驶汽车接纳的关键因素。", "conclusion": "这些结果对促进自动驾驶汽车在沙特交通系统中的整合有重要指导意义。"}}
{"id": "2602.03853", "pdf": "https://arxiv.org/pdf/2602.03853", "abs": "https://arxiv.org/abs/2602.03853", "authors": ["Saizo Aoyagi", "Ryoma Okazaki", "Seishiro Hara", "Fumiya Ikeda", "Michiya Yamamoto"], "title": "On-Demand Lecture Watching System Using Various Actions of Student Characters to Maintain Concentration", "categories": ["cs.HC"], "comment": "This is the author's final draft of Aoyagi, S., Okazaki, R., Hara, S., Ikeda, F., Yamamoto, M. (2025). On-Demand Lecture Watching System Using Various Actions of Student Characters to Maintain Concentration. In: Mori, H., Asahi, Y. (eds) Human Interface and the Management of Information. HCII 2025. Lecture Notes in Computer Science, vol 15774. Springer, Cham", "summary": "Since the COVID-19 pandemic, online lectures have spread rapidly and many students are satisfied with them. However, one challenge remains the loss of concentration due to the lack of students' copresence. Our previous work suggests that presenting 3D characters with appropriate actions has the potential to improve concentration in online lectures. Nevertheless, an effective combination of actions has not yet been identified. In this study, we developed a lecture watching system that presents a 3D virtual classroom using a naked-eye 3D display. The system includes student characters that show copresence with various actions such as nodding, notetaking, and sleeping. An evaluation experiment was conducted with two conditions; (1) student characters perform only positive actions and (2) both positive and negative actions. The results, analyzed using posture and notetaking behavior as key indicators, suggest that the system can help to maintain concentration when the student characters perform both positive and negative actions, rather than only positive ones. These findings provide promising strategies for maintaining student focus in on-demand lectures and contribute to the development of more effective online education systems.", "AI": {"tldr": "开发了一个使用裸眼3D显示的虚拟教室系统，通过学生角色的不同动作来维持在线讲座中的注意力。", "motivation": "为了应对因缺乏学生的共同存在而引起的在线讲座中注意力下降的问题，研究团队提出了一个利用3D角色进行在线教育以提高集中度的方法，并希望找到最有效的角色动作组合。", "method": "开发了一种虚拟教室系统，其中包含执行诸如点头、记笔记和睡觉等不同行动的学生角色。实验分为两种条件：仅积极行为和积极与消极行为的结合。通过分析姿势和记笔记的行为作为关键指标来评估该系统的有效性。", "result": "结果表明，当学生角色执行积极和消极动作时，系统在维持学生的注意力方面比只有积极动作的效果更好。", "conclusion": "这些发现为保持在线讲座中学生的专注度提供了有希望的策略，并有助于开发更有效的在线教育系统。"}}
{"id": "2602.03852", "pdf": "https://arxiv.org/pdf/2602.03852", "abs": "https://arxiv.org/abs/2602.03852", "authors": ["Chan-in Sio", "Alex Mann", "Lingxi Fan", "Andrew Cheung", "Lik-hang Lee"], "title": "Perceptions of AI-CBT: Trust and Barriers in Chinese Postgrads", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "Accepted and presented in The 30th International Conference on Technologies and Applications of Artificial Intelligence in Taipei, Taiwan on 13-14 December 2025 (TAAI 2025)", "summary": "The mental well-being of graduate students is an increasing concern, yet the adoption of scalable support remains uneven. Artificial intelligence-powered cognitive behavioral therapy chatbots (AI-CBT) offer low barrier help, but little is known about how Chinese postgraduates perceive and use them. This qualitative study explored perceptions and experiences of AI-CBT chatbots among ten Chinese graduate students recruited through social media. Semi-structured Zoom interviews were conducted and analyzed using reflexive thematic analysis, with the Health Belief Model (HBM) and the Theory of Planned Behavior (TPB) as sensitizing frameworks. The findings indicate a cautious openness to AI-CBT chatbots: perceived usefulness and 24/7 access supported favorable attitudes, while data privacy, emotional safety, and uncertainty about `fit' for complex problems restricted the intention to use. Social norms (e.g., stigma and peer views) and perceived control (digital literacy, language quality) further shaped adoption. The study offers context-specific information to guide the culturally sensitive design, communication, and deployment of AI mental well-being tools for student populations in China and outlines the design implications around transparency, safeguards, and graduated care pathways.", "AI": {"tldr": "探讨中国研究生对AI驱动的认知行为治疗聊天机器人的感知和使用情况。", "motivation": "探讨如何通过AI-CBT聊天机器人提高中国研究生的心理健康支持，填补该领域的研究空白。", "method": "采用定性研究方法，通过对十名研究生进行半结构化Zoom访谈，并运用反思性主题分析法，结合健康信念模型（HBM）和计划行为理论（TPB），对数据进行了深入分析。", "result": "发现受访者对于AI-CBT聊天机器人持谨慎乐观的态度：认为其有用且可以随时获取；但隐私问题、情感安全性和是否适合处理复杂问题的不确定性限制了他们的使用意愿。社会规范和个人数字素养也影响着采纳行为。", "conclusion": "研究提供了文化特定的信息，以指导针对中国学生群体设计、沟通和部署AI心理健康工具，并提出了围绕透明度、保护措施以及渐进护理路径的设计建议。"}}
{"id": "2602.03851", "pdf": "https://arxiv.org/pdf/2602.03851", "abs": "https://arxiv.org/abs/2602.03851", "authors": ["Wisnu Uriawan", "Denis Firmansyah", "Devi Mulyana", "Dika Haekal Firza Pratama", "Adly Juliarta Lerian", "Fajar Satria Wiguna"], "title": "Gamification-Based Learning Method for Hijaiyah Letters", "categories": ["cs.HC"], "comment": "12 pages. 13 figures, and 2 tables", "summary": "The mastery of Hijaiyah letters is a crucial foundation for reading and comprehending the Quran, yet conventional pedagogical approaches based on repetitive memorization frequently struggle to maintain the engagement of young learners in contemporary educational contexts. This research presents the design and implementation of an innovative gamification-based methodology for Hijaiyah literacy acquisition, systematically developed through the ADDIE framework (Analysis, Design, Development, Implementation, Evaluation) to optimize student motivation, participation, and educational outcomes. The resulting technological solution, engineered using Unity 2D and Firebase, strategically incorporates game design elements such as points, badges, leaderboards, and progressive leveling, while integrating multifaceted learning components including visual animations, authentic tajwid-based audio pronunciation, and interactive letter tracing exercises to simultaneously develop cognitive recognition capabilities and fine motor skills. Empirical evaluation involving 50 elementary school participants revealed substantial quantitative improvements, with mean assessment scores increasing from 42.8 to 88.6 (107% improvement, p < 0.001), demonstrating an exceptionally large effect size (Cohen's d = 4.87), complemented by strong user engagement metrics (4.2 average daily sessions) and high satisfaction ratings (4.82 out of 5 mean motivation score). Beyond cognitive learning outcomes, the gamified approach effectively fostered intrinsic Islamic values such as perseverance, responsibility, and disciplined practice, thereby establishing an innovative educational paradigm that successfully integrates traditional Islamic pedagogical principles with modern digital learning technologies to create a transformative, engaging, and meaningful framework for Hijaiyah literacy development in contemporary Islamic education.", "AI": {"tldr": "该论文提出了一种基于游戏化的学习方法，旨在提高小学生对希贾字母的掌握能力。", "motivation": "传统的重复记忆教学方式难以在现代教育环境中保持年轻学生的兴趣与参与度。本研究希望通过游戏化的方式优化学生的学习动机、参与度和教育成果。", "method": "该研究采用ADDIE框架设计并实施了一种创新的游戏化学习方法，利用Unity2D和Firebase技术开发，结合了视觉动画、基于塔吉温的音频发音和交互式字母描边练习等多维教学元素。", "result": "实验结果显示，50名小学生的评估成绩从42.8提高到88.6（提升107%，p<0.001），且平均每天参与四次以上，并获得了较高的满意度评分。", "conclusion": "游戏化方法不仅显著提升了认知学习成果，还培养了坚持不懈、责任感等内在伊斯兰价值观，成功地将传统伊斯兰教学理念与现代数字技术相结合。"}}
{"id": "2602.03850", "pdf": "https://arxiv.org/pdf/2602.03850", "abs": "https://arxiv.org/abs/2602.03850", "authors": ["Amber Yijia Zheng", "Jae Joong Lee", "Bedrich Benes", "Raymond A. Yeh"], "title": "WebAccessVL: Making an Accessible Web via Violation-Conditioned VLM", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": null, "summary": "We present a vision-language model (VLM) that automatically edits website HTML to address Web Content Accessibility Guidelines 2 (WCAG2) violations. We formulate this as a supervised image-conditioned program synthesis task, where the model learns to correct HTML given the HTML and its rendering. We collected WebAccessVL, a new dataset with manually corrected accessibility violations, establishing paired training data. We then propose a violation-conditioned VLM that additionally conditions on the WCAG2 violation count to guide the correction process. Experiments demonstrate that our method effectively reduces the average number of violations from 5.34 to 0.44 per website, outperforming commercial LLM APIs (Gemini, GPT-5). A perceptual study confirms that our edited websites maintain the original visual appearance and content.", "AI": {"tldr": "通过图像条件下的程序合成任务训练模型，以纠正网站HTML中的WCAG2违规行为。", "motivation": "解决网页内容可访问性问题，提高Web Content Accessibility Guidelines 2 (WCAG2)的合规性。", "method": "提出了一种新的基于视觉语言的模型(VLM)，该模型学习如何在给定HTML及其渲染的情况下纠正HTML。同时，通过添加对违规计数的条件来指导纠正过程，建立了一个带有手动修复后的可访问性违规数据集WebAccessVL。", "result": "实验结果显示，该方法有效地将每个网站的平均违规数量从5.34减少到0.44，优于商用LLM API（Gemini, GPT-5）。感知研究证实，修改后的网页保持了原始视觉外观和内容。", "conclusion": "通过使用新的数据集WebAccessVL和提出的方法Violation-conditioned VLM，可以有效降低网站的WCAG2违规数量，并且不会影响网页的设计和功能。"}}
{"id": "2602.03849", "pdf": "https://arxiv.org/pdf/2602.03849", "abs": "https://arxiv.org/abs/2602.03849", "authors": ["Keyu Zhao", "Fengli Xu", "Yong Li", "Tie-Yan Liu"], "title": "HybridQuestion: Human-AI Collaboration for Identifying High-Impact Research Questions", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "comment": "16 pages, 6 figures, 4 tables", "summary": "The \"AI Scientist\" paradigm is transforming scientific research by automating key stages of the research process, from idea generation to scholarly writing. This shift is expected to accelerate discovery and expand the scope of scientific inquiry. However, a key question remains unclear: can AI scientists identify meaningful research questions? While Large Language Models (LLMs) have been applied successfully to task-specific ideation, their potential to conduct strategic, long-term assessments of past breakthroughs and future questions remains largely unexplored. To address this gap, we explore a human-AI hybrid solution that integrates the scalable data processing capabilities of AI with the value judgment of human experts. Our methodology is structured in three phases. The first phase, AI-Accelerated Information Gathering, leverages AI's advantage in processing vast amounts of literature to generate a hybrid information base. The second phase, Candidate Question Proposing, utilizes this synthesized data to prompt an ensemble of six diverse LLMs to propose an initial candidate pool, filtered via a cross-model voting mechanism. The third phase, Hybrid Question Selection, refines this pool through a multi-stage filtering process that progressively increases human oversight. To validate this system, we conducted an experiment aiming to identify the Top 10 Scientific Breakthroughs of 2025 and the Top 10 Scientific Questions for 2026 across five major disciplines. Our analysis reveals that while AI agents demonstrate high alignment with human experts in recognizing established breakthroughs, they exhibit greater divergence in forecasting prospective questions, suggesting that human judgment remains crucial for evaluating subjective, forward-looking challenges.", "AI": {"tldr": "研究通过人类与AI的合作来识别高影响力的研究问题", "motivation": "探讨大型语言模型在战略性、长期性评估过去突破和未来问题上的潜力，解决AI科学家是否能提出有意义的研究问题这一关键问题", "method": "采用三个阶段的方法：第一阶段利用AI加速信息收集；第二阶段使用综合数据提示多个LLM生成候选研究问题，并通过跨模型投票机制筛选；第三阶段通过多级过滤过程进行筛选，逐步增加人类监督", "result": "实验结果显示，虽然AI在识别已确立的突破方面与人类专家高度一致，但在预测未来的研究方向上则表现出较大的差异性", "conclusion": "证明了人类判断对于评估主观、前瞻性的挑战仍然至关重要"}}
{"id": "2602.03847", "pdf": "https://arxiv.org/pdf/2602.03847", "abs": "https://arxiv.org/abs/2602.03847", "authors": ["Shreyas Sachan", "Viktor Rudnev", "Mohamed Elgharib", "Christian Theobalt", "Vladislav Golyanik"], "title": "EventNeuS: 3D Mesh Reconstruction from a Single Event Camera", "categories": ["cs.CV"], "comment": "13 pages, 10 figures, 3 tables; project page: https://4dqv.mpi-inf.mpg.de/EventNeuS/", "summary": "Event cameras offer a considerable alternative to RGB cameras in many scenarios. While there are recent works on event-based novel-view synthesis, dense 3D mesh reconstruction remains scarcely explored and existing event-based techniques are severely limited in their 3D reconstruction accuracy. To address this limitation, we present EventNeuS, a self-supervised neural model for learning 3D representations from monocular colour event streams. Our approach, for the first time, combines 3D signed distance function and density field learning with event-based supervision. Furthermore, we introduce spherical harmonics encodings into our model for enhanced handling of view-dependent effects. EventNeuS outperforms existing approaches by a significant margin, achieving 34% lower Chamfer distance and 31% lower mean absolute error on average compared to the best previous method.", "AI": {"tldr": "本文提出了EventNeuS，一种从单色事件流中学习三维表示的自监督神经模型。", "motivation": "事件相机在许多场景中提供了一个重要的替代方案，然而基于事件的密集三维网格重建仍然鲜有研究。现有的方法在3D重构精度上存在严重限制。为此，本文旨在开发新的技术提高这一方面的性能。", "method": "EventNeuS首次将3D符号距离函数和密度场学习与基于事件的监督相结合，并引入球面调和编码来增强对视图依赖效应的处理。", "result": "在实验中，EventNeuS相比现有最佳方法，平均降低了34%的Chamfer距离和31%的均方绝对误差。", "conclusion": "EventNeuS通过自监督学习从单色事件流中产生高质量的三维表示，并展示了对基于事件的数据进行高精度密集重建的能力。"}}
{"id": "2602.03846", "pdf": "https://arxiv.org/pdf/2602.03846", "abs": "https://arxiv.org/abs/2602.03846", "authors": ["Romain Cosentino"], "title": "PLATE: Plasticity-Tunable Efficient Adapters for Geometry-Aware Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We develop a continual learning method for pretrained models that \\emph{requires no access to old-task data}, addressing a practical barrier in foundation model adaptation where pretraining distributions are often unavailable. Our key observation is that pretrained networks exhibit substantial \\emph{geometric redundancy}, and that this redundancy can be exploited in two complementary ways. First, redundant neurons provide a proxy for dominant pretraining-era feature directions, enabling the construction of approximately protected update subspaces directly from pretrained weights. Second, redundancy offers a natural bias for \\emph{where} to place plasticity: by restricting updates to a subset of redundant neurons and constraining the remaining degrees of freedom, we obtain update families with reduced functional drift on the old-data distribution and improved worst-case retention guarantees. These insights lead to \\textsc{PLATE} (\\textbf{Pla}sticity-\\textbf{T}unable \\textbf{E}fficient Adapters), a continual learning method requiring no past-task data that provides explicit control over the plasticity-retention trade-off. PLATE parameterizes each layer with a structured low-rank update $ΔW = B A Q^\\top$, where $B$ and $Q$ are computed once from pretrained weights and kept frozen, and only $A$ is trained on the new task. The code is available at https://github.com/SalesforceAIResearch/PLATE.", "AI": {"tldr": "本文提出了一种称为PLATE的方法，用于在无需访问旧任务数据的情况下进行持续学习。", "motivation": "解决预训练分布不可用时的实用障碍，利用神经网络中的几何冗余来改进模型适应性。", "method": "通过构造受保护的更新子空间并限制冗余神经元的更新来控制可塑性和保留之间的权衡。", "result": "PLATE方法在新任务上仅训练中间矩阵A，并提供了对可塑性和保持之间平衡的显式控制。", "conclusion": "本文展示了如何利用几何冗余来改进持续学习，且无需访问旧任务的数据。"}}
{"id": "2602.03840", "pdf": "https://arxiv.org/pdf/2602.03840", "abs": "https://arxiv.org/abs/2602.03840", "authors": ["Devroop Kar", "Daniel Krutz", "Travis Desell"], "title": "Investigating Quantum Circuit Designs Using Neuro-Evolution", "categories": ["cs.NE", "cs.LG"], "comment": "Submitted to The Genetic and Evolutionary Computation Conference (GECCO) 2026. Under Review", "summary": "Designing effective quantum circuits remains a central challenge in quantum computing, as circuit structure strongly influences expressivity, trainability, and hardware feasibility. Current approaches, whether using manually designed circuit templates, fixed heuristics, or automated rules, face limitations in scalability, flexibility, and adaptability, often producing circuits that are poorly matched to the specific problem or quantum hardware. In this work, we propose the Evolutionary eXploration of Augmenting Quantum Circuits (EXAQC), an evolutionary approach to the automated design and training of parameterized quantum circuits (PQCs) which leverages and extends on strategies from neuroevolution and genetic programming. The proposed method jointly searches over gate types, qubit connectivity, parameterization, and circuit depth while respecting hardware and noise constraints. The method supports both Qiskit and Pennylane libraries, allowing the user to configure every aspect. This work highlights evolutionary search as a critical tool for advancing quantum machine learning and variational quantum algorithms, providing a principled pathway toward scalable, problem-aware, and hardware-efficient quantum circuit design. Preliminary results demonstrate that circuits evolved on classification tasks are able to achieve over 90% accuracy on most of the benchmark datasets with a limited computational budget, and are able to emulate target circuit quantum states with high fidelity scores.", "AI": {"tldr": "该论文提出了一种基于神经进化的方法来自动设计和训练参数化量子电路，以应对当前方法在可扩展性、灵活性和适应性方面的局限性。", "motivation": "目前的量子电路设计方法存在局限性，包括手动设计模板、固定启发式策略或自动化规则等，难以满足特定问题或量子硬件的需求。因此需要一种新的自动设计方案来解决这些问题。", "method": "该论文提出了EXAQC（进化探索增强量子电路）这种方法，利用神经进化和遗传编程的技术来联合搜索门类型、量子比特连接性、参数化和电路深度，并且考虑到硬件噪声约束。", "result": "初步结果表明，在分类任务中进化的电路能够达到90%以上的准确率，同时在有限的计算预算下还能以高保真度模拟目标量子态。", "conclusion": "该论文证明了进化搜索对于推进量子机器学习和变分量子算法具有重要意义，并提供了一条通往可扩展、问题意识强且硬件效率高的量子电路设计的途径。"}}
{"id": "2602.03838", "pdf": "https://arxiv.org/pdf/2602.03838", "abs": "https://arxiv.org/abs/2602.03838", "authors": ["Erzhen Hu", "Frederik Brudy", "David Ledo", "George Fitzmaurice", "Fraser Anderson"], "title": "PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": "21 pages, 13 figures; accepted and to appear at CHI 2026", "summary": "In pre-production, filmmakers and 3D animation experts must rapidly prototype ideas to explore a film's possibilities before fullscale production, yet conventional approaches involve trade-offs in efficiency and expressiveness. Hand-drawn storyboards often lack spatial precision needed for complex cinematography, while 3D previsualization demands expertise and high-quality rigged assets. To address this gap, we present PrevizWhiz, a system that leverages rough 3D scenes in combination with generative image and video models to create stylized video previews. The workflow integrates frame-level image restyling with adjustable resemblance, time-based editing through motion paths or external video inputs, and refinement into high-fidelity video clips. A study with filmmakers demonstrates that our system lowers technical barriers for film-makers, accelerates creative iteration, and effectively bridges the communication gap, while also surfacing challenges of continuity, authorship, and ethical consideration in AI-assisted filmmaking.", "AI": {"tldr": "PrevizWhiz结合粗糙的3D场景和生成式视频模型，以创建风格化的预览视频。", "motivation": "传统的方法在效率和表达上存在权衡。手绘故事板缺乏空间精度，而三维预可视化则需要专业技能和高质量的角色资产。为了弥补这一差距，研究者提出了PrevizWhiz系统。", "method": "该系统利用粗糙的3D场景与生成图像和视频模型结合，进行帧级别的图像重样式化、基于时间编辑以及高保真度视频剪辑的细化。", "result": "研究表明，此系统降低了技术门槛，加速了创意迭代，并有效地弥合了沟通缺口；同时也揭示了连贯性、作者身份及AI辅助电影制作中的伦理考量等挑战。", "conclusion": "PrevizWhiz为电影制作者提供了一种高效的工具，以创造风格化的视频预览，在降低技术障碍的同时增强了创造力和沟通效率。"}}
{"id": "2602.03837", "pdf": "https://arxiv.org/pdf/2602.03837", "abs": "https://arxiv.org/abs/2602.03837", "authors": ["David P. Woodruff", "Vincent Cohen-Addad", "Lalit Jain", "Jieming Mao", "Song Zuo", "MohammadHossein Bateni", "Simina Branzei", "Michael P. Brenner", "Lin Chen", "Ying Feng", "Lance Fortnow", "Gang Fu", "Ziyi Guan", "Zahra Hadizadeh", "Mohammad T. Hajiaghayi", "Mahdi JafariRaviz", "Adel Javanmard", "Karthik C. S.", "Ken-ichi Kawarabayashi", "Ravi Kumar", "Silvio Lattanzi", "Euiwoong Lee", "Yi Li", "Ioannis Panageas", "Dimitris Paparas", "et al. (9 additional authors not shown)"], "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a \"neuro-symbolic\" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.", "AI": {"tldr": "本文通过案例研究展示了研究人员如何与Gemini等高级AI模型合作，加速科学发现。", "motivation": "探索大型语言模型在协助解决科研问题、反驳猜想和生成新证明方面的能力。", "method": "收集了使用Gemini Deep Think及其先进变体进行合作的研究案例，并提取了一些有效的合作技术，如迭代改进、问题分解和跨学科知识转移。", "result": "展示了AI不仅作为工具简化任务，还能在复杂推理验证中发挥作用的实例。", "conclusion": "这些研究证明了高级AI模型可以成为科研发现过程中有价值的合作伙伴。"}}
{"id": "2602.03828", "pdf": "https://arxiv.org/pdf/2602.03828", "abs": "https://arxiv.org/abs/2602.03828", "authors": ["Minjun Zhu", "Zhen Lin", "Yixuan Weng", "Panzhong Lu", "Qiujie Xie", "Yifan Wei", "Sifan Liu", "Qiyao Sun", "Yue Zhang"], "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.DL"], "comment": "Accepted at the ICLR 2026", "summary": "High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.", "AI": {"tldr": "AutoFigure 是一种自动生成高质量科学插图的框架，它通过长文本生成符合出版标准的插图。", "motivation": "高质量的科学插图对于有效沟通复杂的科学和技术概念至关重要，但其手动创作仍然是学术界和工业界的瓶颈。因此，作者提出了 AutoFigure 来解决这一问题。", "method": "AutoFigure 是一种自动框架，它基于长文本生成科学插图，在渲染最终结果之前会进行思考、重组和验证以确保布局既结构合理又美观。", "result": "通过使用 FigureBench 中的高质量数据，实验表明 AutoFigure 在性能上超过了所有基线方法，并能够输出符合出版标准的科学插图。", "conclusion": "AutoFigure 是第一个自动生成高质科学插图的方法框架，其在结构完整性和美学吸引力方面都超越了现有技术。"}}
{"id": "2602.03827", "pdf": "https://arxiv.org/pdf/2602.03827", "abs": "https://arxiv.org/abs/2602.03827", "authors": ["Matthias Bentert", "Stefan Schmid"], "title": "Perfect Network Resilience in Polynomial Time", "categories": ["cs.DS", "cs.NI"], "comment": null, "summary": "Modern communication networks support local fast rerouting mechanisms to quickly react to link failures: nodes store a set of conditional rerouting rules which define how to forward an incoming packet in case of incident link failures. The rerouting decisions at any node $v$ must rely solely on local information available at $v$: the link from which a packet arrived at $v$, the target of the packet, and the incident link failures at $v$. Ideally, such rerouting mechanisms provide perfect resilience: any packet is routed from its source to its target as long as the two are connected in the underlying graph after the link failures. Already in their seminal paper at ACM PODC '12, Feigenbaum, Godfrey, Panda, Schapira, Shenker, and Singla showed that perfect resilience cannot always be achieved. While the design of local rerouting algorithms has received much attention since then, we still lack a detailed understanding of when perfect resilience is achievable. This paper closes this gap and presents a complete characterization of when perfect resilience can be achieved. This characterization also allows us to design an $O(n)$-time algorithm to decide whether a given instance is perfectly resilient and an $O(nm)$-time algorithm to compute perfectly resilient rerouting rules whenever it is. Our algorithm is also attractive for the simple structure of the rerouting rules it uses, known as skipping in the literature: alternative links are chosen according to an ordered priority list (per in-port), where failed links are simply skipped. Intriguingly, our result also implies that in the context of perfect resilience, skipping rerouting rules are as powerful as more general rerouting rules. This partially answers a long-standing open question by Chiesa, Nikolaevskiy, Mitrovic, Gurtov, Madry, Schapira, and Shenker [IEEE/ACM Transactions on Networking, 2017] in the affirmative.", "AI": {"tldr": "该论文研究了在网络链路故障情况下，如何通过本地重路由规则实现完美的网络恢复能力。", "motivation": "虽然在局部快速重路由机制的设计上已经取得了一些进展，但对完美恢复性何时可达成的理解仍然不足。本文填补了这一空白，并提出了一个完全的特性化模型，以决定是否可以实现完美恢复。", "method": "提出了一种$O(n)$时间复杂度的算法来判定给定实例是否具有完美的恢复能力以及一种$O(nm)$的时间复杂度算法来计算可恢复的重路由规则。此算法使用了称为跳过（skipping）的简单结构，它通过优先级列表选择替代链路，失败的链接会被忽略。", "result": "该方法能够有效地判断网络中是否可以实现完美的恢复能力，并且能够在可能的情况下快速地计算出可恢复的重路由规则。此外，研究还表明，在完美恢复性背景下，跳过（skipping）重路由规则与更通用的规则一样强大。", "conclusion": "本文通过提供一种判定和计算方法解决了在网络链路故障时实现完美网络恢复能力的问题，并部分回答了关于重路由规则效力的长期开放问题。"}}
{"id": "2602.03826", "pdf": "https://arxiv.org/pdf/2602.03826", "abs": "https://arxiv.org/abs/2602.03826", "authors": ["Alon Wolf", "Chen Katzir", "Kfir Aberman", "Or Patashnik"], "title": "Continuous Control of Editing Models via Adaptive-Origin Guidance", "categories": ["cs.CV", "cs.GR"], "comment": "Project page at https://adaor-paper.github.io/", "summary": "Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.", "AI": {"tldr": "该论文提出了一种名为自适应原点引导(AdaOr)的新方法，以实现基于文本指导的图像和视频编辑模型中的连续控制。", "motivation": "现有扩散式编辑模型无法在文本指导下平滑地调整编辑强度。标准的无条件预测在低引导尺度下会主导生成过程，并且代表了输入内容的任意改动。因此需要一种新方法来实现更细腻和平滑的编辑效果。", "method": "该论文引入了一种自适应原点引导(AdaOr)的方法，通过使用身份指令对应的适应性原点调整标准无条件预测，在推断阶段时依据编辑强度在两者之间进行插值。这种方法整合到了常规训练框架中，并不需要每项编辑过程的特定数据集。", "result": "该方法在图像和视频编辑任务中的评估结果表明，它提供了比当前滑块控制编辑方法更平滑和一致的连续性。", "conclusion": "通过自适应原点引导(AdaOr)的方法，论文成功实现了基于文本指导的编辑模型中更好的连续强度控制，并展示了该方法的有效性和优越性。"}}
{"id": "2602.03824", "pdf": "https://arxiv.org/pdf/2602.03824", "abs": "https://arxiv.org/abs/2602.03824", "authors": ["Jiao Sun"], "title": "Deep-learning-based pan-phenomic data reveals the explosive evolution of avian visual disparity", "categories": ["q-bio.PE", "cs.CV"], "comment": "Readers from the field of computer science may be interested in section 2.1, 2.2, 3.1, 4.1, 4.2. These sections discussed the interpretability and representation learning, especially the texture vs shape problem, highlighting our model's ability of overcoming the texture biases and capturing overall shape features. (Although they're put here to prove the biological validity of the model.)", "summary": "The evolution of biological morphology is critical for understanding the diversity of the natural world, yet traditional analyses often involve subjective biases in the selection and coding of morphological traits. This study employs deep learning techniques, utilising a ResNet34 model capable of recognising over 10,000 bird species, to explore avian morphological evolution. We extract weights from the model's final fully connected (fc) layer and investigate the semantic alignment between the high-dimensional embedding space learned by the model and biological phenotypes. The results demonstrate that the high-dimensional embedding space encodes phenotypic convergence. Subsequently, we assess the morphological disparity among various taxa and evaluate the association between morphological disparity and species richness, demonstrating that species richness is the primary driver of morphospace expansion. Moreover, the disparity-through-time analysis reveals a visual \"early burst\" after the K-Pg extinction. While mainly aimed at evolutionary analysis, this study also provides insights into the interpretability of Deep Neural Networks. We demonstrate that hierarchical semantic structures (biological taxonomy) emerged in the high-dimensional embedding space despite being trained on flat labels. Furthermore, through adversarial examples, we provide evidence that our model in this task can overcome texture bias and learn holistic shape representations (body plans), challenging the prevailing view that CNNs rely primarily on local textures.", "AI": {"tldr": "使用深度学习技术分析鸟类形态进化，揭示了视觉差异的爆炸性演化。", "motivation": "传统生物学形态分析存在主观偏见，该研究旨在通过深度学习方法解决这一问题，并探索鸟类形态演化的模式。", "method": "采用ResNet34模型识别超过10,000种鸟类物种，提取最终全连接层的权重以探究高维嵌入空间与生物表型之间的语义对齐。评估不同类群间的形态差异及与其丰富度的关系，并通过时间分析揭示视觉“早期爆发”现象。", "result": "研究发现模型在训练时生成了层次化的语义结构，证明模型能够克服纹理偏差并学习整体形状表示，支持生物多样性的主要驱动因素是物种丰富度。此外，在K-Pg灭绝后鸟类形态差异急剧增加。", "conclusion": "该研究揭示了鸟类视觉差异的爆炸性演化，并提供了关于深度神经网络可解释性的见解，表明CNN可以超越局部纹理学习整体形状表示。"}}
{"id": "2602.03817", "pdf": "https://arxiv.org/pdf/2602.03817", "abs": "https://arxiv.org/abs/2602.03817", "authors": ["Oscar Ovanger", "Levi Harris", "Timothy H. Keitt"], "title": "Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Many machine learning systems have access to multiple sources of evidence for the same prediction target, yet these sources often differ in reliability and informativeness across inputs. In bioacoustic classification, species identity may be inferred both from the acoustic signal and from spatiotemporal context such as location and season; while Bayesian inference motivates multiplicative evidence combination, in practice we typically only have access to discriminative predictors rather than calibrated generative models. We introduce \\textbf{F}usion under \\textbf{IN}dependent \\textbf{C}onditional \\textbf{H}ypotheses (\\textbf{FINCH}), an adaptive log-linear evidence fusion framework that integrates a pre-trained audio classifier with a structured spatiotemporal predictor. FINCH learns a per-sample gating function that estimates the reliability of contextual information from uncertainty and informativeness statistics. The resulting fusion family \\emph{contains} the audio-only classifier as a special case and explicitly bounds the influence of contextual evidence, yielding a risk-contained hypothesis class with an interpretable audio-only fallback. Across benchmarks, FINCH consistently outperforms fixed-weight fusion and audio-only baselines, improving robustness and error trade-offs even when contextual information is weak in isolation. We achieve state-of-the-art performance on CBI and competitive or improved performance on several subsets of BirdSet using a lightweight, interpretable, evidence-based approach. Code is available: \\texttt{\\href{https://anonymous.4open.science/r/birdnoise-85CD/README.md}{anonymous-repository}}", "AI": {"tldr": "论文提出了一种自适应的证据融合框架，将音频分类器与结构化的时空预测器结合，以提高生物声学分类的准确性。", "motivation": "在机器学习系统中，对于相同的预测目标存在多种不同的证据来源。这些证据源在不同输入上的可靠性和信息量可能有所不同，在生物声学分类中，物种识别可以通过音频信号和时空上下文（如位置和季节）来实现；然而，由于缺乏校准的生成模型，实践中我们通常只拥有区分性预测器。", "method": "论文引入了FINCH框架，该框架是一种自适应的对数线性证据融合方法，它将预训练的音频分类器与结构化的时空预测器结合起来。FINCH通过不确定性及信息量统计学习每样例的门控函数来估计上下文信息的可靠性。", "result": "在多个基准测试中，FINCH优于固定权重融合和仅基于音频的方法，即使独立时时空信息较弱也能提高准确性和错误交易比。", "conclusion": "通过一种轻量级且可解释性的证据基础方法，在CBI数据集上达到最先进的性能，并在BirdSet的几个子集中实现竞争性或改进的表现。"}}
{"id": "2602.03815", "pdf": "https://arxiv.org/pdf/2602.03815", "abs": "https://arxiv.org/abs/2602.03815", "authors": ["Dingkun Zhang", "Shuhan Qi", "Yulin Wu", "Xinyu Xiao", "Xuan Wang", "Long Chen"], "title": "Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) suffer from severe training inefficiency issue, which is associated with their massive model sizes and visual token numbers. Existing efforts in efficient training focus on reducing model sizes or trainable parameters. Inspired by the success of Visual Token Pruning (VTP) in improving inference efficiency, we are exploring another substantial research direction for efficient training by reducing visual tokens. However, applying VTP at the training stage results in a training-inference mismatch: pruning-trained models perform poorly when inferring on non-pruned full visual token sequences. To close this gap, we propose DualSpeed, a fast-slow framework for efficient training of MLLMs. The fast-mode is the primary mode, which incorporates existing VTP methods as plugins to reduce visual tokens, along with a mode isolator to isolate the model's behaviors. The slow-mode is the auxiliary mode, where the model is trained on full visual sequences to retain training-inference consistency. To boost its training, it further leverages self-distillation to learn from the sufficiently trained fast-mode. Together, DualSpeed can achieve both training efficiency and non-degraded performance. Experiments show DualSpeed accelerates the training of LLaVA-1.5 by 2.1$\\times$ and LLaVA-NeXT by 4.0$\\times$, retaining over 99% performance. Code: https://github.com/dingkun-zhang/DualSpeed", "AI": {"tldr": "提出DualSpeed框架，通过快速和慢速模式训练多模态大型语言模型，提高效率并保持性能。", "motivation": "解决多模态大型语言模型在训练时的效率问题，尤其是在视觉标记数量上的挑战。", "method": "使用Visual Token Pruning（VTP）减少视觉标记，在快模式下应用以提升效率；慢模式则保留完整的视觉序列进行训练，并通过自我蒸馏学习快速模式的知识来确保一致性。", "result": "DualSpeed框架使LLaVA-1.5的训练速度提高2.1倍，LLaVA-NeXT提高4.0倍，同时保持超过99%的性能水平。", "conclusion": "提出的新方法成功解决了多模态大型语言模型在高效训练时的关键挑战，并且证明了该框架的有效性和鲁棒性。"}}
{"id": "2602.03814", "pdf": "https://arxiv.org/pdf/2602.03814", "abs": "https://arxiv.org/abs/2602.03814", "authors": ["Xi Wang", "Anushri Suresh", "Alvin Zhang", "Rishi More", "William Jurayj", "Benjamin Van Durme", "Mehrdad Farajtabar", "Daniel Khashabi", "Eric Nalisnick"], "title": "Conformal Thinking: Risk Control for Reasoning on a Compute Budget", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.", "AI": {"tldr": "本文提出了一种基于风险控制的计算预算设置方法，以在限定错误率的情况下最小化计算资源。", "motivation": "大型语言模型在推理过程中可以根据令牌预算调整表现，但如何设定合适的令牌预算是一个挑战。文章旨在通过引入风险控制来解决这个问题，提高推理的效率和准确性。", "method": "重新定义了预算设置问题为风险管理，提出了上阈值和下阈值的概念，并使用无分布风险控制方法优化这些停止机制，同时在多个预算限制条件下加入了效率损失函数以选择最优退出策略。", "result": "实验结果展示了该方法的有效性，在各种推理任务和模型中实现了计算效率的提高，同时也满足了用户指定的风险目标。", "conclusion": "通过引入风险控制框架并优化停止机制，本文有效解决了在限定错误率的情况下最小化计算资源的问题。"}}
{"id": "2602.03812", "pdf": "https://arxiv.org/pdf/2602.03812", "abs": "https://arxiv.org/abs/2602.03812", "authors": ["Yixuan Even Xu", "John Kirchenbauer", "Yash Savani", "Asher Trockman", "Alexander Robey", "Tom Goldstein", "Fei Fang", "J. Zico Kolter"], "title": "Antidistillation Fingerprinting", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "26 pages, 11 figures", "summary": "Model distillation enables efficient emulation of frontier large language models (LLMs), creating a need for robust mechanisms to detect when a third-party student model has trained on a teacher model's outputs. However, existing fingerprinting techniques that could be used to detect such distillation rely on heuristic perturbations that impose a steep trade-off between generation quality and fingerprinting strength, often requiring significant degradation of utility to ensure the fingerprint is effectively internalized by the student. We introduce antidistillation fingerprinting (ADFP), a principled approach that aligns the fingerprinting objective with the student's learning dynamics. Building upon the gradient-based framework of antidistillation sampling, ADFP utilizes a proxy model to identify and sample tokens that directly maximize the expected detectability of the fingerprint in the student after fine-tuning, rather than relying on the incidental absorption of the un-targeted biases of a more naive watermark. Experiments on GSM8K and OASST1 benchmarks demonstrate that ADFP achieves a significant Pareto improvement over state-of-the-art baselines, yielding stronger detection confidence with minimal impact on utility, even when the student model's architecture is unknown.", "AI": {"tldr": "本文提出了一种新的指纹技术ADFP，用于检测模型蒸馏过程。", "motivation": "现有的指纹技术在检测模型蒸馏时存在质量与强度之间的权衡问题，需要牺牲一定的生成质量来确保指纹的有效性。因此，作者提出了一个新的方法——抗蒸馏指纹（ADFP），以解决这一问题。", "method": "基于反蒸馏采样框架的梯度基础，ADFP使用代理模型识别并选择在学生模型微调后能最大化检测到指纹概率的令牌。", "result": "实验结果表明，与现有的最佳方法相比，ADFP能够显著提高检测精度，并且对学生模型架构未知的情况下也表现出了较强的鲁棒性。", "conclusion": "通过引入抗蒸馏技术，可以在不牺牲生成质量的前提下有效地检测出学生模型是否经过了教师模型的训练。"}}
{"id": "2602.03811", "pdf": "https://arxiv.org/pdf/2602.03811", "abs": "https://arxiv.org/abs/2602.03811", "authors": ["David Eigen"], "title": "Progressive Checkerboards for Autoregressive Multiscale Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "A key challenge in autoregressive image generation is to efficiently sample independent locations in parallel, while still modeling mutual dependencies with serial conditioning. Some recent works have addressed this by conditioning between scales in a multiscale pyramid. Others have looked at parallelizing samples in a single image using regular partitions or randomized orders. In this work we examine a flexible, fixed ordering based on progressive checkerboards for multiscale autoregressive image generation. Our ordering draws samples in parallel from evenly spaced regions at each scale, maintaining full balance in all levels of a quadtree subdivision at each step. This enables effective conditioning both between and within scales. Intriguingly, we find evidence that in our balanced setting, a wide range of scale-up factors lead to similar results, so long as the total number of serial steps is constant. On class-conditional ImageNet, our method achieves competitive performance compared to recent state-of-the-art autoregressive systems with like model capacity, using fewer sampling steps.", "AI": {"tldr": "本文提出了一种基于渐进棋盘的固定顺序方法，用于多尺度自回归图像生成。", "motivation": "在自回归图像生成中，如何高效并行采样独立位置同时保持模型间的相互依赖关系是一个关键挑战。先前的工作要么通过跨尺度条件化解决此问题，要么尝试单个图像中的随机或规则分区以实现平行样本采样。", "method": "本文提出了一种灵活的固定顺序方法——渐进棋盘，该方法在每个尺度上从均匀间隔区域并行采集样本，保持四叉树细分中所有级别的完全平衡。此法允许有效地跨尺度和在同一尺度内进行条件化。", "result": "实验证明，在一定条件下，不同放大因子会导致相似的结果，只要总步数恒定即可。在类条件ImageNet数据集上，该方法的性能与最新的自回归系统相当或优于后者，并且采样步骤更少。", "conclusion": "提出的方法通过采用渐进棋盘策略实现了高效的多尺度自回归图像生成，展示了广泛适用性和有效性。"}}
{"id": "2602.03809", "pdf": "https://arxiv.org/pdf/2602.03809", "abs": "https://arxiv.org/abs/2602.03809", "authors": ["Leonardo Monchieri", "Elena Camuffo", "Francesco Barbato", "Pietro Zanuttigh", "Simone Milani"], "title": "Split&Splat: Zero-Shot Panoptic Segmentation via Explicit Instance Modeling and 3D Gaussian Splatting", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (GS) enables fast and high-quality scene reconstruction, but it lacks an object-consistent and semantically aware structure. We propose Split&Splat, a framework for panoptic scene reconstruction using 3DGS. Our approach explicitly models object instances. It first propagates instance masks across views using depth, thus producing view-consistent 2D masks. Each object is then reconstructed independently and merged back into the scene while refining its boundaries. Finally, instance-level semantic descriptors are embedded in the reconstructed objects, supporting various applications, including panoptic segmentation, object retrieval, and 3D editing. Unlike existing methods, Split&Splat tackles the problem by first segmenting the scene and then reconstructing each object individually. This design naturally supports downstream tasks and allows Split&Splat to achieve state-of-the-art performance on the ScanNetv2 segmentation benchmark.", "AI": {"tldr": "提出了一种名为Split&Splat的框架，用于通过显式实例建模和3D高斯点喷射进行全景场景重建。", "motivation": "现有的基于3D高斯点喷射的方法缺乏一致的对象结构和语义感知。为了改善这一状况，并支持诸如全景分割、对象检索和3D编辑等下游任务，作者提出了Split&Splat框架。", "method": "该方法首先使用深度信息在视图之间传播实例掩码，生成视图一致的2D掩码；然后独立重建每个对象并将其合并回场景中；最后嵌入实例级语义描述符以支持多种应用。", "result": "相比现有方法，Split&Splat实现了更好的性能，并且在ScanNetv2分割基准测试上达到了最先进的水平。", "conclusion": "通过提出新的框架设计，解决了3D高斯点喷射缺乏一致性和语义感知的问题，并提升了全景场景重建的应用范围和效果。"}}
{"id": "2602.03808", "pdf": "https://arxiv.org/pdf/2602.03808", "abs": "https://arxiv.org/abs/2602.03808", "authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen", "Shaoyang Zhang"], "title": "Enhancing Imbalanced Node Classification via Curriculum-Guided Feature Learning and Three-Stage Attention Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Imbalanced node classification in graph neural networks (GNNs) happens when some labels are much more common than others, which causes the model to learn unfairly and perform badly on the less common classes. To solve this problem, we propose a Curriculum-Guided Feature Learning and Three-Stage Attention Network (CL3AN-GNN), a learning network that uses a three-step attention system (Engage, Enact, Embed) similar to how humans learn. The model begins by engaging with structurally simpler features, defined as (1) local neighbourhood patterns (1-hop), (2) low-degree node attributes, and (3) class-separable node pairs identified via initial graph convolutional networks and graph attention networks (GCN and GAT) embeddings. This foundation enables stable early learning despite label skew. The Enact stage then addresses complicated aspects: (1) connections that require multiple steps, (2) edges that connect different types of nodes, and (3) nodes at the edges of minority classes by using adjustable attention weights. Finally, Embed consolidates these features via iterative message passing and curriculum-aligned loss weighting. We evaluate CL3AN-GNN on eight Open Graph Benchmark datasets spanning social, biological, and citation networks. Experiments show consistent improvements across all datasets in accuracy, F1-score, and AUC over recent state-of-the-art methods. The model's step-by-step method works well with different types of graph datasets, showing quicker results than training everything at once, better performance on new, imbalanced graphs, and clear explanations of each step using gradient stability and attention correlation learning curves. This work provides both a theoretically grounded framework for curriculum learning in GNNs and practical evidence of its effectiveness against imbalances, validated through metrics, convergence speeds, and generalisation tests.", "AI": {"tldr": "该论文提出了一种新的图神经网络模型CL3AN-GNN，用于解决节点分类任务中的不平衡问题。", "motivation": "在图神经网络中，当某些标签比其他标签更常见时，会导致模型学习不公平，对较少的类别的性能较差。因此，作者提出了一个通过三阶段注意力机制和课程引导特征学习来提高不平衡节点分类准确性的方法。", "method": "CL3AN-GNN采用了一个类似于人类学习方式的三步注意系统（Engage、Enact、Embed），先从简单的局部邻居模式、低度节点属性等开始，再逐渐过渡到更复杂的连接和不同类型的节点。模型通过迭代消息传递和课程一致性的损失权重来巩固特征。", "result": "实验结果表明，在八个开放图基准数据集上，CL3AN-GNN在准确率、F1得分和AUC方面均优于近期的最先进方法。该模型不仅具有更好的泛化性能，还显示出更快的结果收敛速度，并且可以更好地解释每个步骤的学习过程。", "conclusion": "本文提出了一种理论上合理且实践中有效的课程学习框架用于解决图神经网络中的不平衡节点分类问题，通过理论基础和实验结果验证了其有效性。"}}
{"id": "2602.03806", "pdf": "https://arxiv.org/pdf/2602.03806", "abs": "https://arxiv.org/abs/2602.03806", "authors": ["Ziru Chen", "Dongdong Chen", "Ruinan Jin", "Yingbin Liang", "Yujia Xie", "Huan Sun"], "title": "Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SE"], "comment": null, "summary": "Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.", "AI": {"tldr": "论文提出了一种结合在线和离线强化学习优点的新方法Cobalt，用于多轮代码生成任务。", "motivation": "虽然在线RL在实际任务上表现更好，但其高昂的训练成本和不稳定性阻碍了广泛应用。因此，研究者希望通过结合在线和离线RL的优势来解决这些问题。", "method": "提出了一种新的方法Cobalt，它首先使用参考LLM收集代码生成轨迹并将其分为部分上下文提示；然后，在线带学习中LLM通过单步代码生成完成每个上下文提示。此外还分析了LLM的在上下文中奖励作弊行为，并引入扰动轨迹以缓解此问题。", "result": "Cobalt比基于GRPO和VeRPO的多轮在线RL基线模型更好，且显著提高了R1-Distill 8B和Qwen3 8B在LiveCodeBench上的Pass@1得分。", "conclusion": "实验结果表明，Cobalt是一种迭代决策任务（如多轮代码生成）有前景的解决方案。"}}
{"id": "2602.03802", "pdf": "https://arxiv.org/pdf/2602.03802", "abs": "https://arxiv.org/abs/2602.03802", "authors": ["Grigory Begunov", "Alexander Tyurin"], "title": "Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods", "categories": ["cs.DC", "cs.AI", "math.NA", "math.OC"], "comment": null, "summary": "Modern distributed optimization methods mostly rely on traditional synchronous approaches, despite substantial recent progress in asynchronous optimization. We revisit Synchronous SGD and its robust variant, called $m$-Synchronous SGD, and theoretically show that they are nearly optimal in many heterogeneous computation scenarios, which is somewhat unexpected. We analyze the synchronous methods under random computation times and adversarial partial participation of workers, and prove that their time complexities are optimal in many practical regimes, up to logarithmic factors. While synchronous methods are not universal solutions and there exist tasks where asynchronous methods may be necessary, we show that they are sufficient for many modern heterogeneous computation scenarios.", "AI": {"tldr": "重新审视同步SGD及其变体，证明其在许多异构计算场景下的近似最优性。", "motivation": "尽管异步优化取得了进展，但现代分布式优化方法大多依赖于传统同步方法。本文探讨了为什么同步方法仍然有效，并分析了它们在随机计算时间和部分参与工作节点下的表现。", "method": "通过理论分析，研究了同步SGD和$m$-同步SGD在不同情况下的性能表现。", "result": "证明了同步方法的时间复杂度在许多实用场景下是近似最优的，仅相差对数因子。", "conclusion": "虽然异步方法对于某些任务可能是必要的，但同步方法足够适用于许多现代异构计算场景。"}}
{"id": "2602.03799", "pdf": "https://arxiv.org/pdf/2602.03799", "abs": "https://arxiv.org/abs/2602.03799", "authors": ["Xinhang Ma", "Junlin Wu", "Yiannis Kantaros", "Yevgeniy Vorobeychik"], "title": "Conformal Reachability for Safe Control in Unknown Environments", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Designing provably safe control is a core problem in trustworthy autonomy. However, most prior work in this regard assumes either that the system dynamics are known or deterministic, or that the state and action space are finite, significantly limiting application scope. We address this limitation by developing a probabilistic verification framework for unknown dynamical systems which combines conformal prediction with reachability analysis. In particular, we use conformal prediction to obtain valid uncertainty intervals for the unknown dynamics at each time step, with reachability then verifying whether safety is maintained within the conformal uncertainty bounds. Next, we develop an algorithmic approach for training control policies that optimize nominal reward while also maximizing the planning horizon with sound probabilistic safety guarantees. We evaluate the proposed approach in seven safe control settings spanning four domains -- cartpole, lane following, drone control, and safe navigation -- for both affine and nonlinear safety specifications. Our experiments show that the policies we learn achieve the strongest provable safety guarantees while still maintaining high average reward.", "AI": {"tldr": "开发了一个结合了符合预测和可达性分析的框架，用于未知动态系统的安全控制。", "motivation": "当前大多数关于可证明安全性的研究假设系统动力学已知或确定，并且状态和动作空间是有限的。这限制了应用范围。为了解决这个问题，作者提出了一个新的概率验证框架来处理未知动态系统。", "method": "使用符合预测获得未知动态在每个时间步长的有效不确定性区间，然后通过可达性分析验证是否在符合不确定性范围内维持安全性。还开发了一个算法方法训练控制策略以优化名义奖励并最大化规划期限，在保持合理的概率安全保证的同时实现这一点。", "result": "实验结果显示学习到的政策实现了最强的可证明的安全保障，同时仍然保持着高平均收益。", "conclusion": "该框架和算法在多个领域中的七个安全控制设置中进行了评估，并展示了其有效性。"}}
{"id": "2602.03798", "pdf": "https://arxiv.org/pdf/2602.03798", "abs": "https://arxiv.org/abs/2602.03798", "authors": ["Zimu Lu", "Houxing Ren", "Yunqiao Yang", "Ke Wang", "Zhuofan Zong", "Mingjie Zhan", "Hongsheng Li"], "title": "FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation", "categories": ["cs.SE", "cs.CL", "cs.CV"], "comment": null, "summary": "Assisting non-expert users to develop complex interactive websites has become a popular task for LLM-powered code agents. However, existing code agents tend to only generate frontend web pages, masking the lack of real full-stack data processing and storage with fancy visual effects. Notably, constructing production-level full-stack web applications is far more challenging than only generating frontend web pages, demanding careful control of data flow, comprehensive understanding of constantly updating packages and dependencies, and accurate localization of obscure bugs in the codebase. To address these difficulties, we introduce FullStack-Agent, a unified agent system for full-stack agentic coding that consists of three parts: (1) FullStack-Dev, a multi-agent framework with strong planning, code editing, codebase navigation, and bug localization abilities. (2) FullStack-Learn, an innovative data-scaling and self-improving method that back-translates crawled and synthesized website repositories to improve the backbone LLM of FullStack-Dev. (3) FullStack-Bench, a comprehensive benchmark that systematically tests the frontend, backend and database functionalities of the generated website. Our FullStack-Dev outperforms the previous state-of-the-art method by 8.7%, 38.2%, and 15.9% on the frontend, backend, and database test cases respectively. Additionally, FullStack-Learn raises the performance of a 30B model by 9.7%, 9.5%, and 2.8% on the three sets of test cases through self-improvement, demonstrating the effectiveness of our approach. The code is released at https://github.com/mnluzimu/FullStack-Agent.", "AI": {"tldr": "介绍了一个名为FullStack-Agent的统一代理系统，用于增强全栈自动编码能力。", "motivation": "现有的代码代理倾向于只生成前端网页，而忽略实际的全栈数据处理和存储。构建生产级全栈网络应用比仅生成前端页面要困难得多，需要精细的数据流控制、全面理解不断更新的包依赖以及准确定位代码库中的错误。", "method": "提出了一种包含三个部分的方法：(1) FullStack-Dev是一个具有强大计划、编码编辑、导航和故障定位能力的多代理框架；(2) FullStack-Learn是一种创新的数据扩展和自我改进方法，通过反向翻译爬取和合成的网站仓库来提高基础LLM的能力；(3) FullStack-Bench是全面测试前端、后端和数据库功能的基准。", "result": "与现有的最佳实践相比，FullStack-Dev在前端、后端和数据库测试案例上分别高出8.7%、38.2%和15.9%，同时FullStack-Learn通过自我改进将一个30B模型的表现提高了9.7%、9.5%和2.8%", "conclusion": "该研究证明了全栈代理系统可以显著提高全栈编码的质量和效率。"}}
{"id": "2602.03796", "pdf": "https://arxiv.org/pdf/2602.03796", "abs": "https://arxiv.org/abs/2602.03796", "authors": ["Zhixue Fang", "Xu He", "Songlin Tang", "Haoxian Zhang", "Qingfeng Li", "Xiaoqiang Liu", "Pengfei Wan", "Kun Gai"], "title": "3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation", "categories": ["cs.CV"], "comment": "Project Page: https://hjrphoebus.github.io/3DiMo/", "summary": "Existing methods for human motion control in video generation typically rely on either 2D poses or explicit 3D parametric models (e.g., SMPL) as control signals. However, 2D poses rigidly bind motion to the driving viewpoint, precluding novel-view synthesis. Explicit 3D models, though structurally informative, suffer from inherent inaccuracies (e.g., depth ambiguity and inaccurate dynamics) which, when used as a strong constraint, override the powerful intrinsic 3D awareness of large-scale video generators. In this work, we revisit motion control from a 3D-aware perspective, advocating for an implicit, view-agnostic motion representation that naturally aligns with the generator's spatial priors rather than depending on externally reconstructed constraints. We introduce 3DiMo, which jointly trains a motion encoder with a pretrained video generator to distill driving frames into compact, view-agnostic motion tokens, injected semantically via cross-attention. To foster 3D awareness, we train with view-rich supervision (i.e., single-view, multi-view, and moving-camera videos), forcing motion consistency across diverse viewpoints. Additionally, we use auxiliary geometric supervision that leverages SMPL only for early initialization and is annealed to zero, enabling the model to transition from external 3D guidance to learning genuine 3D spatial motion understanding from the data and the generator's priors. Experiments confirm that 3DiMo faithfully reproduces driving motions with flexible, text-driven camera control, significantly surpassing existing methods in both motion fidelity and visual quality.", "AI": {"tldr": "该论文提出了一种新的方法来控制视频生成中的三维人体运动，采用隐式的、视角无关的运动表示，以自然地与生成器的空间先验一致。", "motivation": "现有方法依赖于2D姿态或显式3D参数模型作为控制信号，在新视图合成中存在局限性。该论文旨在通过引入一种新的三维感知的方法来克服这些问题。", "method": "提出了一个名为3DiMo的新框架，它联合训练运动编码器和预训练的视频生成器以提取驱动帧中的紧凑、视角无关的运动令牌，并通过跨注意力机制注入这些令牌。此外，使用了丰富的视图监督和辅助几何监督。", "result": "实验结果表明，该方法能够忠实再现驱动动作并具有灵活的文字驱动相机控制能力，在动作真实性和视觉质量方面超过了现有方法。", "conclusion": "3DiMo通过隐式的视角无关运动表示法实现了高质量的人体视频生成，并在三维人体运动理解和新视图合成方面取得了显著进展。"}}
{"id": "2602.03794", "pdf": "https://arxiv.org/pdf/2602.03794", "abs": "https://arxiv.org/abs/2602.03794", "authors": ["Yingxuan Yang", "Chengrui Qu", "Muning Wen", "Laixi Shi", "Ying Wen", "Weinan Zhang", "Adam Wierman", "Shangding Gu"], "title": "Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.", "AI": {"tldr": "研究了基于大语言模型的多智能体系统中的性能扩展和多样性的影响", "motivation": "探讨在同质环境下增加代理数量导致性能提升减弱的原因，以及异构性如何持续带来显著收益", "method": "提出一个信息理论框架来证明MAS性能受限于任务不确定性而非代理数量，并引入K*指标量化有效通道数", "result": "实验证明，在没有真实标签的情况下，2个多样化智能体的性能可以超过16个同质化智能体", "conclusion": "多样性是提高多智能体系统效率和鲁棒性的关键"}}
{"id": "2602.03793", "pdf": "https://arxiv.org/pdf/2602.03793", "abs": "https://arxiv.org/abs/2602.03793", "authors": ["Yixiang Chen", "Peiyan Li", "Jiabing Yang", "Keji He", "Xiangnan Wu", "Yuan Xu", "Kai Wang", "Jing Liu", "Nianfeng Liu", "Yan Huang", "Liang Wang"], "title": "BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Embodied world models have emerged as a promising paradigm in robotics, most of which leverage large-scale Internet videos or pretrained video generation models to enrich visual and motion priors. However, they still face key challenges: a misalignment between coordinate-space actions and pixel-space videos, sensitivity to camera viewpoint, and non-unified architectures across embodiments. To this end, we present BridgeV2W, which converts coordinate-space actions into pixel-aligned embodiment masks rendered from the URDF and camera parameters. These masks are then injected into a pretrained video generation model via a ControlNet-style pathway, which aligns the action control signals with predicted videos, adds view-specific conditioning to accommodate camera viewpoints, and yields a unified world model architecture across embodiments. To mitigate overfitting to static backgrounds, BridgeV2W further introduces a flow-based motion loss that focuses on learning dynamic and task-relevant regions. Experiments on single-arm (DROID) and dual-arm (AgiBot-G1) datasets, covering diverse and challenging conditions with unseen viewpoints and scenes, show that BridgeV2W improves video generation quality compared to prior state-of-the-art methods. We further demonstrate the potential of BridgeV2W on downstream real-world tasks, including policy evaluation and goal-conditioned planning. More results can be found on our project website at https://BridgeV2W.github.io .", "AI": {"tldr": "本文提出了BridgeV2W，通过使用从URDF和相机参数生成的像素对齐的主体掩码，将坐标空间的动作转换为像素空间，并注入预训练视频生成模型中。", "motivation": "当前基于视频的机器人世界模型面临的问题包括动作控制信号与预测视频之间的不一致、视角敏感性以及不同主体之间架构的非统一。BridgeV2W旨在解决这些问题，提高视频生成质量和任务性能。", "method": "通过引入ControlNet样式路径和运动流损失，将坐标空间的动作转换为像素对齐的主体掩码，并将其注入预训练的视频生成模型中，以适应不同视角并实现架构的一致性。", "result": "实验结果表明，与现有方法相比，BridgeV2W在单臂(DROID)和双臂(AgiBot-G1)数据集上的视频生成质量得到了改进，并且适用于下游任务如策略评估和目标条件规划。", "conclusion": "通过提出BridgeV2W，解决了当前基于视频的机器人世界模型中的一系列挑战，提高了视频生成质量和任务相关性。"}}
{"id": "2602.03792", "pdf": "https://arxiv.org/pdf/2602.03792", "abs": "https://arxiv.org/abs/2602.03792", "authors": ["Xilong Wang", "Yinuo Liu", "Zhun Wang", "Dawn Song", "Neil Gong"], "title": "WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Prompt injection attacks manipulate webpage content to cause web agents to execute attacker-specified tasks instead of the user's intended ones. Existing methods for detecting and localizing such attacks achieve limited effectiveness, as their underlying assumptions often do not hold in the web-agent setting. In this work, we propose WebSentinel, a two-step approach for detecting and localizing prompt injection attacks in webpages. Given a webpage, Step I extracts \\emph{segments of interest} that may be contaminated, and Step II evaluates each segment by checking its consistency with the webpage content as context. We show that WebSentinel is highly effective, substantially outperforming baseline methods across multiple datasets of both contaminated and clean webpages that we collected. Our code is available at: https://github.com/wxl-lxw/WebSentinel.", "AI": {"tldr": "WebSentinel是一种用于检测和定位网页中提示注入攻击的两步方法。", "motivation": "现有的检测和定位提示注入攻击的方法在Web代理环境中效果有限，因为它们的基本假设往往不成立。因此提出了WebSentinel以解决这一问题。", "method": "第一步从网页中提取可能被污染的部分（段落），第二步评估每个部分是否与网页内容一致。", "result": "实验表明，WebSentinel在多个数据集上显著优于基线方法。", "conclusion": "WebSentinel是一个有效的工具，可以有效地检测和定位网页中的提示注入攻击。"}}
{"id": "2602.03789", "pdf": "https://arxiv.org/pdf/2602.03789", "abs": "https://arxiv.org/abs/2602.03789", "authors": ["Gabriel Damsholt", "Jes Frellsen", "Susanne Ditlevsen"], "title": "Fast Sampling for Flows and Diffusions with Lazy and Point Mass Stochastic Interpolants", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Stochastic interpolants unify flows and diffusions, popular generative modeling frameworks. A primary hyperparameter in these methods is the interpolation schedule that determines how to bridge a standard Gaussian base measure to an arbitrary target measure. We prove how to convert a sample path of a stochastic differential equation (SDE) with arbitrary diffusion coefficient under any schedule into the unique sample path under another arbitrary schedule and diffusion coefficient. We then extend the stochastic interpolant framework to admit a larger class of point mass schedules in which the Gaussian base measure collapses to a point mass measure. Under the assumption of Gaussian data, we identify lazy schedule families that make the drift identically zero and show that with deterministic sampling one gets a variance-preserving schedule commonly used in diffusion models, whereas with statistically optimal SDE sampling one gets our point mass schedule. Finally, to demonstrate the usefulness of our theoretical results on realistic highly non-Gaussian data, we apply our lazy schedule conversion to a state-of-the-art pretrained flow model and show that this allows for generating images in fewer steps without retraining the model.", "AI": {"tldr": "本文提出了一种将样本路径从一个随机微分方程转换到另一个的方法，该方法可用于处理不同类型的插值调度，并在高斯数据假设下识别懒惰调度家族。", "motivation": "研究如何通过不同的插值调度来统一流模型和扩散模型的采样过程。引入点质量调度以扩大插值框架的应用范围，并探讨其理论与应用价值。", "method": "证明了将随机微分方程（SDE）样本路径从一种扩散系数转换到另一种的方法，同时扩展了随机插值框架来处理更多的点质量调度。提出了懒惰调度家族的定义和转化方法，并应用于预训练流模型中。", "result": "在高斯数据假设下识别出两种特殊类型的懒惰调度：确定性采样时得到方差保持的调度；统计上最优的SDE采样则得到点质量调度。实验表明，应用懒惰调度转换可以在更少步骤生成图像而无需重新训练模型。", "conclusion": "通过理论研究和实际测试证明了所提出的懒惰调度转化方法的有效性，并展示了其在非高斯数据上的潜力。"}}
{"id": "2602.03786", "pdf": "https://arxiv.org/pdf/2602.03786", "abs": "https://arxiv.org/abs/2602.03786", "authors": ["Jianhao Ruan", "Zhihao Xu", "Yiran Peng", "Fashen Ren", "Zhaoyang Yu", "Xinbing Liang", "Jinyu Xiang", "Bang Liu", "Chenglin Wu", "Yuyu Luo", "Jiayi Zhang"], "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra", "AI": {"tldr": "本文提出了一种自动创建子代理以实现智能任务编排的系统AOrchestra。", "motivation": "现有的语言代理在处理复杂和长期的任务时缺乏动态抽象，影响了系统的适应性。为了克服这个问题，并减少人工工程努力，同时保持对不同框架的支持，提出了该研究。", "method": "通过建立一种统一的、与框架无关的代理抽象模型，将任何代理视为指令、上下文、工具和模型的组合体。在此基础上设计了一个智能系统AOrchestra，其中中央编排器在每一步中具体化这个元组：它策划任务相关的上下文，选择合适的工具和模型，并通过即时自动创建子代理来执行任务。", "result": "该系统在三个挑战性基准测试（GAIA、SWE-Bench、Terminal-Bench）上相对于最强基线实现了16.28%的相对改进。", "conclusion": "AOrchestra提供了一个有效的解决方案，能够自动生成适合特定任务需求的子代理，从而提高复杂和长期任务处理的能力，并且系统具有可控的成本性能权衡。"}}
{"id": "2602.03785", "pdf": "https://arxiv.org/pdf/2602.03785", "abs": "https://arxiv.org/abs/2602.03785", "authors": ["Jingjing Peng", "Giorgio Fiore", "Yang Liu", "Ksenia Ellum", "Debayan Daspupta", "Keyoumars Ashkan", "Andrew McEvoy", "Anna Miserocchi", "Sebastien Ourselin", "John Duncan", "Alejandro Granados"], "title": "From Pre- to Intra-operative MRI: Predicting Brain Shift in Temporal Lobe Resection for Epilepsy Surgery", "categories": ["cs.CV"], "comment": null, "summary": "Introduction: In neurosurgery, image-guided Neurosurgery Systems (IGNS) highly rely on preoperative brain magnetic resonance images (MRI) to assist surgeons in locating surgical targets and determining surgical paths. However, brain shift invalidates the preoperative MRI after dural opening. Updated intraoperative brain MRI with brain shift compensation is crucial for enhancing the precision of neuronavigation systems and ensuring the optimal outcome of surgical interventions. Methodology: We propose NeuralShift, a U-Net-based model that predicts brain shift entirely from pre-operative MRI for patients undergoing temporal lobe resection. We evaluated our results using Target Registration Errors (TREs) computed on anatomical landmarks located on the resection side and along the midline, and DICE scores comparing predicted intraoperative masks with masks derived from intraoperative MRI. Results: Our experimental results show that our model can predict the global deformation of the brain (DICE of 0.97) with accurate local displacements (achieve landmark TRE as low as 1.12 mm), compensating for large brain shifts during temporal lobe removal neurosurgery. Conclusion: Our proposed model is capable of predicting the global deformation of the brain during temporal lobe resection using only preoperative images, providing potential opportunities to the surgical team to increase safety and efficiency of neurosurgery and better outcomes to patients. Our contributions will be publicly available after acceptance in https://github.com/SurgicalDataScienceKCL/NeuralShift.", "AI": {"tldr": "使用预手术MRI预测脑移位，提高神经导航系统精度和手术效果。", "motivation": "为了克服术中大脑移位带来的问题，提高神经外科手术的精确度和安全性，研究团队开发了一种基于U-Net的模型NeuralShift，该模型能从预手术MRI图像中预测出脑部变形情况。", "method": "提出一种基于U-Net的模型NeuralShift，通过训练此模型来学习如何利用术前MRI数据准确地预测术后的大脑移位。", "result": "实验结果表明，所提出的模型能够以高达0.97的DICE得分全局预测大脑变形，并能将定位误差降至1.12毫米以下，从而有效补偿了颞叶切除手术中的大量脑移位。", "conclusion": "该模型有望通过仅使用预手术图像来预测神经外科手术期间的大脑变形，提高手术团队的安全性和效率，最终为患者带来更好的治疗效果。"}}
{"id": "2602.03783", "pdf": "https://arxiv.org/pdf/2602.03783", "abs": "https://arxiv.org/abs/2602.03783", "authors": ["Zhenshuo Zhang", "Minxuan Duan", "Hongyang R. Zhang"], "title": "Efficient Estimation of Kernel Surrogate Models for Task Attribution", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "27 pages. To appear in ICLR 2026", "summary": "Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing each task, but is computationally infeasible at scale. An alternative approach that builds surrogate models to predict a target task's performance for any subset of training tasks has emerged in recent literature. Prior work focuses on linear surrogate models, which capture first-order relationships, but miss nonlinear interactions such as synergy, antagonism, or XOR-type effects. In this paper, we first consider a unified task weighting framework for analyzing task attribution methods, and show a new connection between linear surrogate models and influence functions through a second-order analysis. Then, we introduce kernel surrogate models, which more effectively represent second-order task interactions. To efficiently learn the kernel surrogate, we develop a gradient-based estimation procedure that leverages a first-order approximation of pretrained models; empirically, this yields accurate estimates with less than $2\\%$ relative error without repeated retraining. Experiments across multiple domains -- including math reasoning in transformers, in-context learning, and multi-objective reinforcement learning -- demonstrate the effectiveness of kernel surrogate models. They achieve a $25\\%$ higher correlation with the leave-one-out ground truth than linear surrogates and influence-function baselines. When used for downstream task selection, kernel surrogate models yield a $40\\%$ improvement in demonstration selection for in-context learning and multi-objective reinforcement learning benchmarks.", "AI": {"tldr": "本文提出了一种高效的核代理模型方法，用于量化大规模语言模型中各个训练任务对目标任务性能的影响。", "motivation": "现有线性代理模型无法捕捉非线性交互作用如协同、拮抗或XOR效应。为解决此问题并提高任务归因准确性，引入了更有效的核代理模型。", "method": "本文提出了一种基于梯度的估计程序来高效学习核代理模型，该程序利用预训练模型的一阶近似进行优化。", "result": "实验表明，在不同领域内核代理模型比线性代理和影响函数基线具有更高的准确性，与离群值剔除的真实结果相关性提高了25%。在下游任务选择方面，改善了上下文学习和多目标强化学习基准的任务选择效率。", "conclusion": "本文引入的核代理模型提供了更准确、有效的任务归因方法，并且通过高效的估计程序降低了计算成本。"}}
{"id": "2602.03782", "pdf": "https://arxiv.org/pdf/2602.03782", "abs": "https://arxiv.org/abs/2602.03782", "authors": ["Yuhao Xu", "Yantai Yang", "Zhenyang Fan", "Yufan Liu", "Yuming Li", "Bing Li", "Zhipeng Zhang"], "title": "QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization", "categories": ["cs.CV", "cs.RO"], "comment": "ICLR2026", "summary": "The advent of Vision-Language-Action (VLA) models represents a significant leap for embodied intelligence, yet their immense computational demands critically hinder deployment on resource-constrained robotic platforms. Intuitively, low-bit quantization is a prevalent and preferred technique for large-scale model compression. However, we find that a systematic analysis of VLA model's quantization is fundamentally lacking. We argue that naively applying uniform-bit quantization from Large Language Models (LLMs) to robotics is flawed, as these methods prioritize passive data fidelity while ignoring how minor action deviations compound into catastrophic task failures. To bridge this gap, we introduce QVLA, the first action-centric quantization framework specifically designed for embodied control. In a sharp departure from the rigid, uniform-bit quantization of LLM-based methods, QVLA introduces a highly granular, channel-wise bit allocation strategy. Its core mechanism is to directly measure the final action-space sensitivity when quantizing each individual channel to various bit-widths. This process yields a precise, per-channel importance metric that guides a global optimization, which elegantly unifies quantization and pruning (0-bit) into a single, cohesive framework. Extensive evaluations on different baselines demonstrate the superiority of our approach. In the LIBERO, the quantization version of OpenVLA-OFT with our method requires only 29.2% of the original model's VRAM while maintaining 98.9% of its original performance and achieving a 1.49x speedup. This translates to a 22.6% performance improvement over the LLM-derived method SmoothQuant. Our work establishes a new, principled foundation for compressing VLA models in robotics, paving the way for deploying powerful, large-scale models on real-world hardware. Code will be released.", "AI": {"tldr": "QVLA是一种针对视觉语言动作模型量化的新框架，通过精细化的通道级比特分配策略提高在机器人上的应用效果。", "motivation": "现有视觉语言动作模型因其巨大的计算需求难以部署于资源有限的平台，而简单的均匀位量化方法忽视了动作偏差导致的任务失败问题。", "method": "QVLA引入一种基于行动中心的量化框架，通过测量每个通道在不同比特宽度下的最终动作空间敏感度来确定重要性，并进行全局优化。", "result": "实验结果表明，使用QVLA处理后的模型只需要原模型29.2%的VRAM，性能保持在98.9%，并且速度提高了1.49倍。相对于SmoothQuant方法，其性能提升了22.6%。", "conclusion": "此研究为视觉语言动作模型量化提供了新的原则性基础，并且有望使大规模模型部署于实际硬件上成为可能。"}}
{"id": "2602.03781", "pdf": "https://arxiv.org/pdf/2602.03781", "abs": "https://arxiv.org/abs/2602.03781", "authors": ["Martin Günther", "Felix Igelbrink", "Oscar Lima", "Lennart Niecksch", "Marian Renz", "Martin Atzmueller"], "title": "A Scene Graph Backed Approach to Open Set Semantic Mapping", "categories": ["cs.RO"], "comment": null, "summary": "While Open Set Semantic Mapping and 3D Semantic Scene Graphs (3DSSGs) are established paradigms in robotic perception, deploying them effectively to support high-level reasoning in large-scale, real-world environments remains a significant challenge. Most existing approaches decouple perception from representation, treating the scene graph as a derivative layer generated post hoc. This limits both consistency and scalability. In contrast, we propose a mapping architecture where the 3DSSG serves as the foundational backend, acting as the primary knowledge representation for the entire mapping process. Our approach leverages prior work on incremental scene graph prediction to infer and update the graph structure in real-time as the environment is explored. This ensures that the map remains topologically consistent and computationally efficient, even during extended operations in large-scale settings. By maintaining an explicit, spatially grounded representation that supports both flat and hierarchical topologies, we bridge the gap between sub-symbolic raw sensor data and high-level symbolic reasoning. Consequently, this provides a stable, verifiable structure that knowledge-driven frameworks, ranging from knowledge graphs and ontologies to Large Language Models (LLMs), can directly exploit, enabling agents to operate with enhanced interpretability, trustworthiness, and alignment to human concepts.", "AI": {"tldr": "提出了一种基于三维语义场景图的开放集语义映射方法，以支持大规模现实环境中高级别的推理。", "motivation": "现有方法将感知与表示分离，导致一致性和可扩展性的限制。通过使3DSSG成为基础后端，可以提高环境探索的一致性并减少计算负担。", "method": "采用增量场景图预测工作来实时推断和更新图形结构，以保持地图的拓扑一致性并支持高级别符号推理。", "result": "提供了一种稳定、可验证的结构，使知识驱动框架能够直接利用，增强代理的操作透明度、信任性和与人类概念的一致性。", "conclusion": "该方法通过结合感知和表示，解决了大规模现实环境中语义映射的关键挑战。"}}
{"id": "2602.03778", "pdf": "https://arxiv.org/pdf/2602.03778", "abs": "https://arxiv.org/abs/2602.03778", "authors": ["Aneri Muni", "Vincent Taboga", "Esther Derman", "Pierre-Luc Bacon", "Erick Delage"], "title": "Reward Redistribution for CVaR MDPs using a Bellman Operator on L-infinity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Tail-end risk measures such as static conditional value-at-risk (CVaR) are used in safety-critical applications to prevent rare, yet catastrophic events. Unlike risk-neutral objectives, the static CVaR of the return depends on entire trajectories without admitting a recursive Bellman decomposition in the underlying Markov decision process. A classical resolution relies on state augmentation with a continuous variable. However, unless restricted to a specialized class of admissible value functions, this formulation induces sparse rewards and degenerate fixed points. In this work, we propose a novel formulation of the static CVaR objective based on augmentation. Our alternative approach leads to a Bellman operator with: (1) dense per-step rewards; (2) contracting properties on the full space of bounded value functions. Building on this theoretical foundation, we develop risk-averse value iteration and model-free Q-learning algorithms that rely on discretized augmented states. We further provide convergence guarantees and approximation error bounds due to discretization. Empirical results demonstrate that our algorithms successfully learn CVaR-sensitive policies and achieve effective performance-safety trade-offs.", "AI": {"tldr": "提出了一种基于贝尔曼算子的新方法，用于计算静态条件价值风险(CVaR)目标，并开发了相应的风险厌恶值迭代和模型无关的Q学习算法。", "motivation": "为了防止罕见但灾难性的事件，在安全关键应用中使用尾部风险度量如静态CVaR。然而，传统的解决办法会诱导稀疏奖励和退化固定点，因此需要新方法来改进。", "method": "提出了一种新的基于状态增强的静态CVaR目标计算方法，并构建了贝尔曼算子以保证稠密每步奖励和全有界函数空间上的收缩性质。在此基础上开发风险厌恶值迭代和模型无关的Q学习算法。", "result": "实验结果表明，所提出的算法能够有效学习CVaR敏感策略并实现有效的性能与安全权衡。", "conclusion": "该研究成功提出了一种改进的方法来计算静态条件价值风险(CVaR)，并通过理论分析和实验证明了其有效性。"}}
{"id": "2602.03776", "pdf": "https://arxiv.org/pdf/2602.03776", "abs": "https://arxiv.org/abs/2602.03776", "authors": ["Zhuohan Wang", "Carmine Ventre"], "title": "DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books", "categories": ["q-fin.CP", "cs.AI"], "comment": "12 pages, 8 figures", "summary": "Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require interaction with another agent to explore alternative outcomes. This limits their usefulness for stress testing, scenario analysis, and decision-making. We propose \\textbf{DiffLOB}, a regime-conditioned \\textbf{Diff}usion model for controllable and counterfactual generation of \\textbf{LOB} trajectories. DiffLOB explicitly conditions the generative process on future market regimes--including trend, volatility, liquidity, and order-flow imbalance, which enables the model to answer counterfactual queries of the form: ``If the future market regime were X instead of Y, how would the limit order book evolve?'' Our systematic evaluation framework for counterfactual LOB generation consists of three criteria: (1) \\textit{Controllable Realism}, measuring how well generated trajectories can reproduce marginal distributions, temporal dependence structure and regime variables; (2) \\textit{Counterfactual validity}, testing whether interventions on future regimes induce consistent changes in the generated LOB dynamics; (3) \\textit{Counterfactual usefulness}, assessing whether synthetic counterfactual trajectories improve downstream prediction of future market regimes.", "AI": {"tldr": "提出了DiffLOB模型，用于控制和反事实生成限价订单簿轨迹。", "motivation": "现有的限价订单簿生成模型无法应对假设的未来市场状况或需要与其他代理交互以探索替代结果，限制了它们在压力测试、情景分析和决策中的实用性。", "method": "使用条件扩散模型DiffLOB来生成限价订单簿动态，并评估其可控现实性、反事实有效性以及反事实有用性。", "result": "系统评价框架显示，所提出的模型能够准确模拟限价订单簿的未来趋势、波动性和流动性等特性。", "conclusion": "通过引入DiffLOB，解决了现有模型无法应对假设市场状况的问题，提高了决策过程中的实用性。"}}
{"id": "2602.03775", "pdf": "https://arxiv.org/pdf/2602.03775", "abs": "https://arxiv.org/abs/2602.03775", "authors": ["Farnoosh Hashemi", "Michael W. Macy"], "title": "An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and interactions among 32K LLM agents over a year. We start with homophily and social influence among LLMs, learning that similar to humans', their social networks exhibit these fundamental phenomena. Next, we study the toxic language of LLMs, its linguistic features, and their interaction patterns, finding that LLMs show different structural patterns in toxic posting than humans. After studying the ideological leaning in LLMs posts, and the polarization in their community, we focus on how to prevent their potential harmful activities. We present a simple yet effective method, called Chain of Social Thought (CoST), that reminds LLM agents to avoid harmful posting.", "AI": {"tldr": "研究大型语言模型在社交平台中的集体行为和社会动态。", "motivation": "探讨大型语言模型反复交互是否会放大偏见或导致排斥行为，以理解其社会影响。", "method": "分析Chirper.ai平台上32K个LLM代理的700万帖子和互动数据，研究同质性、社交影响力、毒性语言模式及政治倾向。", "result": "发现LLM表现出与人类不同的有毒发言结构；提出一种简单有效的方法Chain of Social Thought (CoST)来预防有害行为。", "conclusion": "大型语言模型在社交平台上的交互存在特定的社会动态和集体行为，需采取措施避免潜在的负面影响。"}}
{"id": "2602.03772", "pdf": "https://arxiv.org/pdf/2602.03772", "abs": "https://arxiv.org/abs/2602.03772", "authors": ["Changhao Wang", "Yunfei Yu", "Xinhao Yao", "Jiaolong Yang", "Riccardo Cantoro", "Chaobo Li", "Qing Cui", "Jun Zhou"], "title": "UniGeM: Unifying Data Mixing and Selection via Geometric Exploration and Mining", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The scaling of Large Language Models (LLMs) is increasingly limited by data quality. Most methods handle data mixing and sample selection separately, which can break the structure in code corpora. We introduce \\textbf{UniGeM}, a framework that unifies mixing and selection by treating data curation as a \\textit{manifold approximation} problem without training proxy models or relying on external reference datasets. UniGeM operates hierarchically: \\textbf{Macro-Exploration} learns mixing weights with stability-based clustering; \\textbf{Micro-Mining} filters high-quality instances by their geometric distribution to ensure logical consistency. Validated by training 8B and 16B MoE models on 100B tokens, UniGeM achieves \\textbf{2.0$\\times$ data efficiency} over a random baseline and further improves overall performance compared to SOTA methods in reasoning-heavy evaluations and multilingual generalization.", "AI": {"tldr": "本文提出了UniGeM框架，统一处理数据混合和选择问题，通过几何探索和挖掘来提升大规模语言模型的数据质量。", "motivation": "随着大型语言模型规模的增长，数据质量问题成为限制因素。现有方法通常单独处理数据混合和样本选择，这会破坏代码语料库的结构。本文旨在解决这一问题，提出一种新的框架以提高数据效率和模型性能。", "method": "UniGeM通过将数据整理视为流形逼近问题来统一处理数据混合和选择，并且不依赖于训练代理模型或外部参考数据集。该方法包含两个层次：宏观探索利用基于稳定性的聚类学习混合权重；微观挖掘依据几何分布筛选高质量实例。", "result": "在训练8B和16B MoE模型时，UniGeM相较于随机基线实现了2.0倍的数据效率提升，并且在推理任务和多语言泛化中超越了现有最佳方法的性能表现。", "conclusion": "本文提出的UniGeM框架通过几何探索和挖掘技术统一处理数据混合与选择问题，在提高模型训练效率的同时，也提升了整体模型性能。"}}
{"id": "2602.03767", "pdf": "https://arxiv.org/pdf/2602.03767", "abs": "https://arxiv.org/abs/2602.03767", "authors": ["Rajat Masiwal", "Colin Aitken", "Adam Marchakitus", "Mayank Gupta", "Katherine Kowal", "Hamid A. Pahlavan", "Tyler Yang", "Y. Qiang Sun", "Michael Kremer", "Amir Jina", "William R. Boos", "Pedram Hassanzadeh"], "title": "Decision-oriented benchmarking to transform AI weather forecast access: Application to the Indian monsoon", "categories": ["cs.LG", "cs.AI", "econ.GN", "physics.ao-ph"], "comment": null, "summary": "Artificial intelligence weather prediction (AIWP) models now often outperform traditional physics-based models on common metrics while requiring orders-of-magnitude less computing resources and time. Open-access AIWP models thus hold promise as transformational tools for helping low- and middle-income populations make decisions in the face of high-impact weather shocks. Yet, current approaches to evaluating AIWP models focus mainly on aggregated meteorological metrics without considering local stakeholders' needs in decision-oriented, operational frameworks. Here, we introduce such a framework that connects meteorology, AI, and social sciences. As an example, we apply it to the 150-year-old problem of Indian monsoon forecasting, focusing on benefits to rain-fed agriculture, which is highly susceptible to climate change. AIWP models skillfully predict an agriculturally relevant onset index at regional scales weeks in advance when evaluated out-of-sample using deterministic and probabilistic metrics. This framework informed a government-led effort in 2025 to send 38 million Indian farmers AI-based monsoon onset forecasts, which captured an unusual weeks-long pause in monsoon progression. This decision-oriented benchmarking framework provides a key component of a blueprint for harnessing the power of AIWP models to help large vulnerable populations adapt to weather shocks in the face of climate variability and change.", "AI": {"tldr": "本文介绍了决策导向的基准框架，用于评估AI天气预报模型，并应用于印度季风预测，以帮助农业适应气候变化。", "motivation": "传统的气象指标不足以反映本地利益相关者的实际需求，因此需要一个结合了气象学、人工智能和社会科学的新框架来解决这一问题。", "method": "通过建立一种新的决策导向基准框架来评估AI天气预报模型的性能，并将其应用于印度季风预测中，重点是雨养农业受益情况。", "result": "该框架成功地在数周前准确预测出与农业生产相关的季节性指标，并且帮助3800万农民接收到了基于AI的季风雨期预测信息。", "conclusion": "该决策导向基准框架为利用AI天气预报模型帮助大规模脆弱人群适应气候灾害提供了蓝图。"}}
{"id": "2602.03766", "pdf": "https://arxiv.org/pdf/2602.03766", "abs": "https://arxiv.org/abs/2602.03766", "authors": ["Nicholas M. Blauch", "George A. Alvarez", "Talia Konkle"], "title": "FOVI: A biologically-inspired foveated interface for deep vision models", "categories": ["cs.CV", "cs.NE", "q-bio.NC"], "comment": null, "summary": "Human vision is foveated, with variable resolution peaking at the center of a large field of view; this reflects an efficient trade-off for active sensing, allowing eye-movements to bring different parts of the world into focus with other parts of the world in context. In contrast, most computer vision systems encode the visual world at a uniform resolution, raising challenges for processing full-field high-resolution images efficiently. We propose a foveated vision interface (FOVI) based on the human retina and primary visual cortex, that reformats a variable-resolution retina-like sensor array into a uniformly dense, V1-like sensor manifold. Receptive fields are defined as k-nearest-neighborhoods (kNNs) on the sensor manifold, enabling kNN-convolution via a novel kernel mapping technique. We demonstrate two use cases: (1) an end-to-end kNN-convolutional architecture, and (2) a foveated adaptation of the foundational DINOv3 ViT model, leveraging low-rank adaptation (LoRA). These models provide competitive performance at a fraction of the computational cost of non-foveated baselines, opening pathways for efficient and scalable active sensing for high-resolution egocentric vision. Code and pre-trained models are available at https://github.com/nblauch/fovi and https://huggingface.co/fovi-pytorch.", "AI": {"tldr": "提出了一种基于人类视觉系统的FOVI模型，用于高效处理高分辨率图像。", "motivation": "模仿人眼的可变分辨率特性以提高计算机视觉系统对全视野高分辨率图像处理效率。", "method": "通过k最近邻卷积和低秩适应技术实现foveated接口设计。展示了两种应用场景：端到端kNN-convolution架构和DINOv3 ViT模型的foveated适配版本。", "result": "在减少计算成本的情况下，FOVI模型提供了与基准模型相竞争的表现。", "conclusion": "为高效、可扩展的主动感知高分辨率自视域视觉开辟了途径。"}}
{"id": "2602.03762", "pdf": "https://arxiv.org/pdf/2602.03762", "abs": "https://arxiv.org/abs/2602.03762", "authors": ["Hugo Malard", "Gael Le Lan", "Daniel Wong", "David Lou Alon", "Yi-Chiao Wu", "Sanjeel Parekh"], "title": "Conditional Flow Matching for Visually-Guided Acoustic Highlighting", "categories": ["eess.AS", "cs.LG"], "comment": null, "summary": "Visually-guided acoustic highlighting seeks to rebalance audio in alignment with the accompanying video, creating a coherent audio-visual experience. While visual saliency and enhancement have been widely studied, acoustic highlighting remains underexplored, often leading to misalignment between visual and auditory focus. Existing approaches use discriminative models, which struggle with the inherent ambiguity in audio remixing, where no natural one-to-one mapping exists between poorly-balanced and well-balanced audio mixes. To address this limitation, we reframe this task as a generative problem and introduce a Conditional Flow Matching (CFM) framework. A key challenge in iterative flow-based generation is that early prediction errors -- in selecting the correct source to enhance -- compound over steps and push trajectories off-manifold. To address this, we introduce a rollout loss that penalizes drift at the final step, encouraging self-correcting trajectories and stabilizing long-range flow integration. We further propose a conditioning module that fuses audio and visual cues before vector field regression, enabling explicit cross-modal source selection. Extensive quantitative and qualitative evaluations show that our method consistently surpasses the previous state-of-the-art discriminative approach, establishing that visually-guided audio remixing is best addressed through generative modeling.", "AI": {"tldr": "本文提出了条件流动匹配（CFM）框架，用于解决视觉引导的音频突出显示问题。", "motivation": "当前的方法通常使用判别模型来处理音频重混的问题，但这种模型在面对音频重混时的内在模糊性上表现不佳，无法准确地将不均衡的音频混合调整为平衡的音频混合。因此，需要一种新的方法来解决这个问题。", "method": "本文提出了一种条件流动匹配（CFM）框架，该框架通过生成式问题重新定义任务，并引入了滚筒损失以减少早期预测错误的影响，同时提出了一种融合模块用于将视觉和听觉线索相结合，从而实现显式的跨模态源选择。", "result": "实验结果表明，本文的方法在定量和定性评估中均优于现有的判别模型方法。", "conclusion": "通过生成式建模来解决视觉引导的音频重混问题比传统的判别模型更有效。"}}
{"id": "2602.03760", "pdf": "https://arxiv.org/pdf/2602.03760", "abs": "https://arxiv.org/abs/2602.03760", "authors": ["Mishal Fatima", "Shashank Agnihotri", "Kanchana Vaishnavi Gandikota", "Michael Moeller", "Margret Keuper"], "title": "RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images", "categories": ["cs.CV"], "comment": "*Equal Contribution", "summary": "Most vision models are trained on RGB images processed through ISP pipelines optimized for human perception, which can discard sensor-level information useful for machine reasoning. RAW images preserve unprocessed scene data, enabling models to leverage richer cues for both object detection and object description, capturing fine-grained details, spatial relationships, and contextual information often lost in processed images. To support research in this domain, we introduce RAWDet-7, a large-scale dataset of ~25k training and 7.6k test RAW images collected across diverse cameras, lighting conditions, and environments, densely annotated for seven object categories following MS-COCO and LVIS conventions. In addition, we provide object-level descriptions derived from the corresponding high-resolution sRGB images, facilitating the study of object-level information preservation under RAW image processing and low-bit quantization. The dataset allows evaluation under simulated 4-bit, 6-bit, and 8-bit quantization, reflecting realistic sensor constraints, and provides a benchmark for studying detection performance, description quality & detail, and generalization in low-bit RAW image processing. Dataset & code upon acceptance.", "AI": {"tldr": "介绍了一个用于量化RAW图像上物体检测和描述的大规模数据集RAWDet-7。", "motivation": "大多数视觉模型在经过ISP优化的RGB图像上进行训练，这会丢弃对机器推理有用的传感器级信息。RAW图像保存了未经处理的数据，可以提供更丰富的线索来捕捉细微细节、空间关系以及丢失的信息。", "method": "创建了一个包含约25k训练和7.6k测试RAW图像的大规模数据集，并提供了基于高分辨率sRGB图像的物体描述，允许在4位、6位和8位量化下进行评估。", "result": "提供一个用于研究低比特量化RAW图像处理中检测性能、描述质量和泛化的基准。该数据集支持模拟真实传感器限制的研究。", "conclusion": "RAWDet-7为研究未经过ISP优化的RAW图像中的物体检测和描述提供了宝贵的资源，促进了相关领域的进一步发展。"}}
{"id": "2602.03753", "pdf": "https://arxiv.org/pdf/2602.03753", "abs": "https://arxiv.org/abs/2602.03753", "authors": ["Nicolas Sereyjol-Garros", "Ellington Kirby", "Victor Letzelter", "Victor Besnier", "Nermin Samet"], "title": "Test-Time Conditioning with Representation-Aligned Visual Features", "categories": ["cs.CV"], "comment": null, "summary": "While representation alignment with self-supervised models has been shown to improve diffusion model training, its potential for enhancing inference-time conditioning remains largely unexplored. We introduce Representation-Aligned Guidance (REPA-G), a framework that leverages these aligned representations, with rich semantic properties, to enable test-time conditioning from features in generation. By optimizing a similarity objective (the potential) at inference, we steer the denoising process toward a conditioned representation extracted from a pre-trained feature extractor. Our method provides versatile control at multiple scales, ranging from fine-grained texture matching via single patches to broad semantic guidance using global image feature tokens. We further extend this to multi-concept composition, allowing for the faithful combination of distinct concepts. REPA-G operates entirely at inference time, offering a flexible and precise alternative to often ambiguous text prompts or coarse class labels. We theoretically justify how this guidance enables sampling from the potential-induced tilted distribution. Quantitative results on ImageNet and COCO demonstrate that our approach achieves high-quality, diverse generations. Code is available at https://github.com/valeoai/REPA-G.", "AI": {"tldr": "本文提出了一种在生成过程中使用表示对齐特征进行测试时条件控制的框架REPA-G，该方法利用预训练特征提取器的特征以引导去噪过程。", "motivation": "现有研究显示，通过自监督模型实现的表示对齐可以改进扩散模型的训练。然而，在推理时间上如何利用这种对齐表示来改善生成结果尚不明确。本文旨在探索这种方法在测试时条件控制方面的潜力。", "method": "REPA-G框架使用优化过的相似性目标（潜在值）引导去噪过程，使其指向从预训练特征提取器中得到的条件表示。此方法能够提供多尺度控制，包括通过单个补丁进行精细纹理匹配和通过全局图像特征标记进行广泛的语义指导，并支持多个概念组合。", "result": "实验结果显示，在ImageNet和COCO数据集上使用REPA-G可以生成高质量且多样化的图像。", "conclusion": "本文提出的方法在测试时利用对齐的表示来控制生成过程，为模糊的文字提示或粗糙的类别标签提供了一种灵活而精确的选择。"}}
{"id": "2602.03750", "pdf": "https://arxiv.org/pdf/2602.03750", "abs": "https://arxiv.org/abs/2602.03750", "authors": ["Owen Dong", "Lily Gao", "Manish Kota", "Bennett A. Landmana", "Jelena Bekvalac", "Gaynor Western", "Katherine D. Van Schaik"], "title": "Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Paleoradiology, the use of modern imaging technologies to study archaeological and anthropological remains, offers new windows on millennial scale patterns of human health. Unfortunately, the radiographs collected during field campaigns are heterogeneous: bones are disarticulated, positioning is ad hoc, and laterality markers are often absent. Additionally, factors such as age at death, age of bone, sex, and imaging equipment introduce high variability. Thus, content navigation, such as identifying a subset of images with a specific projection view, can be time consuming and difficult, making efficient triaging a bottleneck for expert analysis. We report a zero shot prompting strategy that leverages a state of the art Large Vision Language Model (LVLM) to automatically identify the main bone, projection view, and laterality in such images. Our pipeline converts raw DICOM files to bone windowed PNGs, submits them to the LVLM with a carefully engineered prompt, and receives structured JSON outputs, which are extracted and formatted onto a spreadsheet in preparation for validation. On a random sample of 100 images reviewed by an expert board certified paleoradiologist, the system achieved 92% main bone accuracy, 80% projection view accuracy, and 100% laterality accuracy, with low or medium confidence flags for ambiguous cases. These results suggest that LVLMs can substantially accelerate code word development for large paleoradiology datasets, allowing for efficient content navigation in future anthropology workflows.", "AI": {"tldr": "本文提出了一种利用大型视觉语言模型进行自动骨骼识别的方法，以提高古放射学图像分析的效率。", "motivation": "由于古放射学影像异质性强、定位随意且缺乏侧别标记，导致内容导航困难，成为专家分析的一大瓶颈。因此，本研究旨在开发一种零样本提示策略来解决这些问题，并加速大型古放射学数据集的内容导航。", "method": "该方法通过将原始DICOM文件转换为骨窗PNG图像，利用精心设计的提示向大型视觉语言模型提交请求，接收结构化的JSON输出并格式化到电子表格中供验证。", "result": "在由专家认证的古放射学家审查的100张随机样本影像中，系统的主要骨骼识别准确率为92%，投影视图准确率为80%，侧别准确率为100%。", "conclusion": "研究表明，大型视觉语言模型可以显著加速大规模古放射学数据集中的内容导航，并在未来的考古工作流中实现高效的内容检索。"}}
{"id": "2602.03749", "pdf": "https://arxiv.org/pdf/2602.03749", "abs": "https://arxiv.org/abs/2602.03749", "authors": ["Jian Lin", "Chengze Li", "Haoyun Qin", "Kwun Wang Chan", "Yanghua Jin", "Hanyuan Liu", "Stephen Chun Wang Choy", "Xueting Liu"], "title": "See-through: Single-image Layer Decomposition for Anime Characters", "categories": ["cs.CV", "cs.GR"], "comment": "23 pages, 20 figures, preprint version only", "summary": "We introduce a framework that automates the transformation of static anime illustrations into manipulatable 2.5D models. Current professional workflows require tedious manual segmentation and the artistic ``hallucination'' of occluded regions to enable motion. Our approach overcomes this by decomposing a single image into fully inpainted, semantically distinct layers with inferred drawing orders. To address the scarcity of training data, we introduce a scalable engine that bootstraps high-quality supervision from commercial Live2D models, capturing pixel-perfect semantics and hidden geometry. Our methodology couples a diffusion-based Body Part Consistency Module, which enforces global geometric coherence, with a pixel-level pseudo-depth inference mechanism. This combination resolves the intricate stratification of anime characters, e.g., interleaving hair strands, allowing for dynamic layer reconstruction. We demonstrate that our approach yields high-fidelity, manipulatable models suitable for professional, real-time animation applications.", "AI": {"tldr": "通过分解单张图片，将静态的动漫插图转换为可操作的2.5D模型。", "motivation": "现有的专业工作流程需要繁琐的手动分割和对被遮挡区域的艺术性‘想象’以实现动画效果。提出的方法旨在简化这一过程，提高效率。", "method": "利用扩散基线体部件一致性模块保证全局几何一致性和像素级伪深度推理机制来推断隐藏的层次结构，从而将单张图片分解为完全填充、语义独立且具有预测绘制顺序的层。", "result": "该方法可以生成高保真度、可操作的模型，适用于专业实时动画应用。", "conclusion": "通过结合先进的技术手段和创新的方法论，成功地解决了动漫插图转换中复杂的层次划分问题，提高了工作效率。"}}
{"id": "2602.03747", "pdf": "https://arxiv.org/pdf/2602.03747", "abs": "https://arxiv.org/abs/2602.03747", "authors": ["Junchao Huang", "Ziyang Ye", "Xinting Hu", "Tianyu He", "Guiyu Zhang", "Shaoshuai Shi", "Jiang Bian", "Li Jiang"], "title": "LIVE: Long-horizon Interactive Video World Modeling", "categories": ["cs.CV"], "comment": "18 pages, 22 figures", "summary": "Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective, thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.", "AI": {"tldr": "本文提出了一种称为LIVE的长期视频世界模型，以解决现有方法在长时预测中的误差累积问题。", "motivation": "现有的自回归视频世界模型虽然能在短时间范围内有效预测未来视觉观察结果，但在长时间范围内的生成中经常出现误差累积的问题。传统的方法通过引入预训练教师模型和序列级分布匹配来缓解这一问题，但这些方法增加了计算成本并且未能防止超出训练范围的错误传播。", "method": "LIVE通过一种新颖的循环一致性目标强制执行有界的误差积累，从而消除了对教师基于蒸馏的需求。LIVE首先从真实帧进行前向滚动，然后应用逆向生成过程重构初始状态。随后，在重建终端状态下计算扩散损失，为长时间范围内的误差传播提供明确约束。", "result": "实验结果显示，LIVE在长时基准测试中表现出了最先进的性能，能够在训练滚出长度之外生成稳定、高质量的视频。", "conclusion": "通过引入循环一致性目标和逐步训练课程来解决长期预测中的误差累积问题，LIVE成功地提高了模型在长时间范围内的稳定性，并且能够产生更高质量的结果。"}}
{"id": "2602.03743", "pdf": "https://arxiv.org/pdf/2602.03743", "abs": "https://arxiv.org/abs/2602.03743", "authors": ["Roberta Mota", "Julio D. Silva", "Fabio Miranda", "Usman Alim", "Ehud Sharlin", "Nivan Ferreira"], "title": "Occlusion-Free Conformal Lensing for Spatiotemporal Visualization in 3D Urban Analytics", "categories": ["cs.HC", "cs.GR"], "comment": "Accepted at IEEE VR 2026", "summary": "The visualization of temporal data on urban buildings, such as shadows, noise, and solar potential, plays a critical role in the analysis of dynamic urban phenomena. However, in dense and geographically constrained 3D urban environments, visual representations of time-varying building data often suffer from occlusion and visual clutter. To address these two challenges, we introduce an immersive lens visualization that integrates a view-dependent cutaway de-occlusion technique and a temporal display derived from a conformal mapping algorithm. The mapping process first partitions irregular building footprints into smaller, sufficiently regular subregions that serve as structural primitives. These subregions are then seamlessly recombined to form a conformal, layered layout for our temporal lens visualization. The view-responsive cutaway is inspired by traditional architectural illustrations, preserving the overall layout of the building and its surroundings to maintain users' sense of spatial orientation. This lens design enables the occlusion-free embedding of shape-adaptive temporal displays across building facades on demand, supporting rapid time-space association for the discovery, access and interpretation of spatiotemporal urban patterns. Guided by domain and design goals, we outline the rationale behind the lens visual and interaction design choices, such as the encoding of time progression and temporal values in the conforming lens image. A user study compares our approach against conventional juxtaposition and x-ray spatiotemporal designs. Results validate the usage and utility of our lens, showing that it improves task accuracy and completion time, reduces navigation effort, and increases user confidence. From these findings, we distill design recommendations and promising directions for future research on spatially-embedded lenses in 3D visualization and urban analytics.", "AI": {"tldr": "本文提出了一种沉浸式透镜可视化技术，用于在3D城市环境中无遮挡地展示时间变化的建筑物数据。", "motivation": "解决密集的城市环境中动态建筑数据可视化的遮挡和视觉杂乱问题。", "method": "结合视图相关的切口去遮挡技术和基于共形映射算法的时间显示方法，通过分割不规则建筑足迹为较小区域并重新组合形成共形分层布局来实现。", "result": "用户研究结果表明，该技术提高了任务准确性、缩短了完成时间、减少了导航努力，并增强了用户的信心。", "conclusion": "透镜设计有效支持快速时空关联，发现和访问解释空间时间城市模式。"}}
{"id": "2602.03742", "pdf": "https://arxiv.org/pdf/2602.03742", "abs": "https://arxiv.org/abs/2602.03742", "authors": ["Johny J. Lopez", "Md Meftahul Ferdaus", "Mahdi Abdelguerfi"], "title": "Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment", "categories": ["cs.CV"], "comment": null, "summary": "Autonomous inspection of underground infrastructure, such as sewer and culvert systems, is critical to public safety and urban sustainability. Although robotic platforms equipped with visual sensors can efficiently detect structural deficiencies, the automated generation of human-readable summaries from these detections remains a significant challenge, especially on resource-constrained edge devices. This paper presents a novel two-stage pipeline for end-to-end summarization of underground deficiencies, combining our lightweight RAPID-SCAN segmentation model with a fine-tuned Vision-Language Model (VLM) deployed on an edge computing platform. The first stage employs RAPID-SCAN (Resource-Aware Pipeline Inspection and Defect Segmentation using Compact Adaptive Network), achieving 0.834 F1-score with only 0.64M parameters for efficient defect segmentation. The second stage utilizes a fine-tuned Phi-3.5 VLM that generates concise, domain-specific summaries in natural language from the segmentation outputs. We introduce a curated dataset of inspection images with manually verified descriptions for VLM fine-tuning and evaluation. To enable real-time performance, we employ post-training quantization with hardware-specific optimization, achieving significant reductions in model size and inference latency without compromising summarization quality. We deploy and evaluate our complete pipeline on a mobile robotic platform, demonstrating its effectiveness in real-world inspection scenarios. Our results show the potential of edge-deployable integrated AI systems to bridge the gap between automated defect detection and actionable insights for infrastructure maintenance, paving the way for more scalable and autonomous inspection solutions.", "AI": {"tldr": "本文提出了一种针对地下基础设施检测的两阶段管道，结合了轻量级RAPID-SCAN分割模型与微调过的视觉语言模型（VLM），实现了在边缘设备上的高效缺陷检测和自然语言总结。", "motivation": "自动产生可读性高的报告以供人类理解，从具有视觉传感器的机器人平台获得的数据中提取结构缺陷信息是一个重要挑战，尤其是在资源受限的边缘设备上实现这一目标更为困难。因此本文提出了一种新的解决方案来优化地下基础设施检测。", "method": "该方法包括两个阶段：首先使用轻量级RAPID-SCAN模型进行高效分割，然后利用微调后的Phi-3.5 VLM生成自然语言描述；通过引入数据集和硬件特定的优化技术，实现了低延迟的实时性能。", "result": "研究展示了所提出管道在移动机器人平台上的有效性，并且结果证明了这种方法能够提供高质量的总结而不增加模型大小或推理时间。", "conclusion": "边缘部署集成AI系统具有自动化缺陷检测与可操作性见解之间的桥梁作用，有助于实现更大规模和自主化的基础设施检查解决方案。"}}
{"id": "2602.03733", "pdf": "https://arxiv.org/pdf/2602.03733", "abs": "https://arxiv.org/abs/2602.03733", "authors": ["Wenfang Sun", "Hao Chen", "Yingjun Du", "Yefeng Zheng", "Cees G. M. Snoek"], "title": "RegionReasoner: Region-Grounded Multi-Round Visual Reasoning", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026", "summary": "Large vision-language models have achieved remarkable progress in visual reasoning, yet most existing systems rely on single-step or text-only reasoning, limiting their ability to iteratively refine understanding across multiple visual contexts. To address this limitation, we introduce a new multi-round visual reasoning benchmark with training and test sets spanning both detection and segmentation tasks, enabling systematic evaluation under iterative reasoning scenarios. We further propose RegionReasoner, a reinforcement learning framework that enforces grounded reasoning by requiring each reasoning trace to explicitly cite the corresponding reference bounding boxes, while maintaining semantic coherence via a global-local consistency reward. This reward extracts key objects and nouns from both global scene captions and region-level captions, aligning them with the reasoning trace to ensure consistency across reasoning steps. RegionReasoner is optimized with structured rewards combining grounding fidelity and global-local semantic alignment. Experiments on detection and segmentation tasks show that RegionReasoner-7B, together with our newly introduced benchmark RegionDial-Bench, considerably improves multi-round reasoning accuracy, spatial grounding precision, and global-local consistency, establishing a strong baseline for this emerging research direction.", "AI": {"tldr": "本文提出了RegionReasoner，一种基于强化学习的多轮视觉推理框架，以提高在检测和分割任务中的迭代推理准确性。", "motivation": "现有的大多数系统依赖单步或文本推理，这限制了它们在多个视觉场景中反复细化理解的能力。为了克服这一局限性，本文提出了一个新的多轮视觉推理基准测试，并引入了一种新的基于强化学习的框架RegionReasoner来解决这个问题。", "method": "RegionReasoner通过要求每一轮推理都要明确引用相应的参考边界框并保持语义一致性来强制执行基于地面事实的推理。该框架使用结合了定位准确性和全局-局部语义对齐奖励结构化的奖励进行优化。", "result": "实验结果表明，与新引入的基准测试RegionDial-Bench相比，RegionReasoner在检测和分割任务中的多轮推理准确性、空间定位精度以及全局-局部一致性方面都有显著提升。", "conclusion": "本文提出的RegionReasoner建立了新兴研究方向的一个强有力基线，并为视觉语言模型的迭代理解提供了新的视角。"}}
{"id": "2602.03732", "pdf": "https://arxiv.org/pdf/2602.03732", "abs": "https://arxiv.org/abs/2602.03732", "authors": ["Themistoklis Haris", "Steve Choi", "Mutiraj Laksanawisit"], "title": "Fast-MWEM: Private Data Release in Sublinear Time", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "The Multiplicative Weights Exponential Mechanism (MWEM) is a fundamental iterative framework for private data analysis, with broad applications such as answering $m$ linear queries, or privately solving systems of $m$ linear constraints. However, a critical bottleneck hindering its scalability is the $Θ(m)$ time complexity required to execute the exponential mechanism in each iteration. We introduce a modification to the MWEM framework that improves the per-iteration runtime dependency to $Θ(\\sqrt{m})$ in expectation. This is done via a lazy sampling approach to the Report-Noisy-Max mechanism, which we implement efficiently using Gumbel noise and a $k$-Nearest Neighbor data structure. This allows for the rapid selection of the approximate score in the exponential mechanism without an exhaustive linear scan. We apply our accelerated framework to the problems of private linear query release and solving Linear Programs (LPs) under neighboring constraint conditions and low-sensitivity assumptions. Experimental evaluation confirms that our method provides a substantial runtime improvement over classic MWEM.", "AI": {"tldr": "提出了Fast-MWEM框架，通过改进Report-Noisy-Max机制的采样方式，使得MWEM在每次迭代中的时间复杂度从Θ(m)降低到Θ(√m)，实现了更快的数据发布。", "motivation": "原始的MWEM框架虽然功能强大，但在处理大规模数据时因每次迭代的时间复杂度为Θ(m)而面临可扩展性问题。通过改进算法来加速这一过程是很有必要的。", "method": "引入了一种懒惰采样方式并结合Gumbel噪声和k-最近邻结构优化了Report-Noisy-Max机制，从而在执行指数机制时能够快速选择近似得分，而不是进行耗时的线性扫描。该方法应用于私有线性查询发布以及具有邻居约束条件下的LP求解。", "result": "实验结果显示，新的Fast-MWEM框架相比传统的MWEM算法显著提高了运行时间效率。", "conclusion": "通过引入懒惰采样技术并优化执行机制的实现方式，成功地将MWEM每次迭代的时间复杂度降低到Θ(√m)，从而大幅度提升了私有数据发布的速度。"}}
{"id": "2602.03725", "pdf": "https://arxiv.org/pdf/2602.03725", "abs": "https://arxiv.org/abs/2602.03725", "authors": ["Dylan Herman", "Yue Sun", "Jin-Peng Liu", "Marco Pistoia", "Charlie Che", "Rob Otter", "Shouvanik Chakrabarti", "Aram Harrow"], "title": "Quantum Speedups for Derivative Pricing Beyond Black-Scholes", "categories": ["quant-ph", "cs.DS", "q-fin.CP", "q-fin.MF"], "comment": null, "summary": "This paper explores advancements in quantum algorithms for derivative pricing of exotics, a computational pipeline of fundamental importance in quantitative finance. For such cases, the classical Monte Carlo integration procedure provides the state-of-the-art provable, asymptotic performance: polynomial in problem dimension and quadratic in inverse-precision. While quantum algorithms are known to offer quadratic speedups over classical Monte Carlo methods, end-to-end speedups have been proven only in the simplified setting over the Black-Scholes geometric Brownian motion (GBM) model. This paper extends existing frameworks to demonstrate novel quadratic speedups for more practical models, such as the Cox-Ingersoll-Ross (CIR) model and a variant of Heston's stochastic volatility model, utilizing a characteristic of the underlying SDEs which we term fast-forwardability. Additionally, for general models that do not possess the fast-forwardable property, we introduce a quantum Milstein sampler, based on a novel quantum algorithm for sampling Lévy areas, which enables quantum multi-level Monte Carlo to achieve quadratic speedups for multi-dimensional stochastic processes exhibiting certain correlation types. We also present an improved analysis of numerical integration for derivative pricing, leading to substantial reductions in the resource requirements for pricing GBM and CIR models. Furthermore, we investigate the potential for additional reductions using arithmetic-free quantum procedures. Finally, we critique quantum partial differential equation (PDE) solvers as a method for derivative pricing based on amplitude estimation, identifying theoretical barriers that obstruct achieving a quantum speedup through this approach. Our findings significantly advance the understanding of quantum algorithms in derivative pricing, addressing key challenges and open questions in the field.", "AI": {"tldr": "本文探讨了量子算法在衍生品定价中的应用，特别是在Cox-Ingersoll-Ross模型和Heston的随机波动率模型中实现二次加速的方法。", "motivation": "传统蒙特卡洛方法在处理复杂金融模型时效率低下，而量子算法提供了一种潜在的二次加速机会。本文旨在扩展现有框架以解决更实际且复杂的金融衍生品定价问题，提高计算效率和准确性。", "method": "通过引入量子快速前进特性以及针对不具备该特性的模型设计量子米尔斯采样器，并改进数值积分方法来实现对于多种复杂金融模型的二次加速。此外还研究了基于振幅估计的量子偏微分方程求解法在衍生品定价中的应用。", "result": "论文证明了对于CIR和Heston模型，可以利用快速前进特性和新的采样算法达到二次加速效果；同时也提出了改进的数值积分技术以减少资源需求。然而，在使用PDE方法进行衍生品定价时存在理论障碍无法实现量子加速。", "conclusion": "研究成果显著推进了量子算法在金融衍生品定价领域的应用，为解决相关挑战和开放性问题提供了新的视角和解决方案。"}}
{"id": "2602.03704", "pdf": "https://arxiv.org/pdf/2602.03704", "abs": "https://arxiv.org/abs/2602.03704", "authors": ["Yu Tian", "Linh Huynh", "Katerina Christhilf", "Shubham Chakraborty", "Micah Watanabe", "Tracy Arner", "Danielle McNamara"], "title": "Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "This manuscript is under review at Electronics", "summary": "Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap, we introduce ReQUESTA, a hybrid, multi-agent framework for generating cognitively diverse MCQs that systematically target text-based, inferential, and main idea comprehension. ReQUESTA decomposes MCQ authoring into specialized subtasks and coordinates LLM-powered agents with rule-based components to support planning, controlled generation, iterative evaluation, and post-processing. We evaluated the framework in a large-scale reading comprehension study using academic expository texts, comparing ReQUESTA-generated MCQs with those produced by a single-pass GPT-5 zero-shot baseline. Psychometric analyses of learner responses assessed item difficulty and discrimination, while expert raters evaluated question quality across multiple dimensions, including topic relevance and distractor quality. Results showed that ReQUESTA-generated items were consistently more challenging, more discriminative, and more strongly aligned with overall reading comprehension performance. Expert evaluations further indicated stronger alignment with central concepts and superior distractor linguistic consistency and semantic plausibility, particularly for inferential questions. These findings demonstrate that hybrid, agentic orchestration can systematically improve the reliability and controllability of LLM-based generation, highlighting workflow design as a key lever for structured artifact generation beyond single-pass prompting.", "AI": {"tldr": "本文提出了一种混合多代理框架ReQUESTA，用于生成认知多样化的选择题，该框架通过分解任务并协调语言模型和规则组件来提高问题的可靠性和可控制性。", "motivation": "尽管大型语言模型的进步使得自动产生多项选择题变得可行，但确保它们满足特定的认知要求仍然是一个挑战。本文旨在解决这一问题，提出了一种新的方法以生成认知多样化且高质量的选择题。", "method": "ReQUESTA框架将MCQ创作分解为专门的子任务，并协调使用大型语言模型和规则组件进行规划、控制产生、迭代评估和后期处理，以此来提高选择题的质量。", "result": "实验结果显示，与单一通过GPT-5生成的问题相比，由ReQUESTA生成的选择题在难度、区分度以及与整体阅读理解表现的关联性上都更为优越。专家评估也显示其对核心概念的把握更强，并且干扰项的语言一致性和语义合理性更好。", "conclusion": "研究表明，混合多代理框架可以系统地提高基于大型语言模型的问题产生任务中的可靠性和可控性，强调了工作流程设计对于结构化产出生成的重要性"}}
{"id": "2602.03702", "pdf": "https://arxiv.org/pdf/2602.03702", "abs": "https://arxiv.org/abs/2602.03702", "authors": ["Alexandru Meterez", "Pranav Ajit Nair", "Depen Morwani", "Cengiz Pehlevan", "Sham Kakade"], "title": "Anytime Pretraining: Horizon-Free Learning-Rate Schedules with Weight Averaging", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "Large language models are increasingly trained in continual or open-ended settings, where the total training horizon is not known in advance. Despite this, most existing pretraining recipes are not anytime: they rely on horizon-dependent learning rate schedules and extensive tuning under a fixed compute budget. In this work, we provide a theoretical analysis demonstrating the existence of anytime learning schedules for overparameterized linear regression, and we highlight the central role of weight averaging - also known as model merging - in achieving the minimax convergence rates of stochastic gradient descent. We show that these anytime schedules polynomially decay with time, with the decay rate determined by the source and capacity conditions of the problem. Empirically, we evaluate 150M and 300M parameter language models trained at 1-32x Chinchilla scale, comparing constant learning rates with weight averaging and $1/\\sqrt{t}$ schedules with weight averaging against a well-tuned cosine schedule. Across the full training range, the anytime schedules achieve comparable final loss to cosine decay. Taken together, our results suggest that weight averaging combined with simple, horizon-free step sizes offers a practical and effective anytime alternative to cosine learning rate schedules for large language model pretraining.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.03695", "pdf": "https://arxiv.org/pdf/2602.03695", "abs": "https://arxiv.org/abs/2602.03695", "authors": ["Haibo Jin", "Kuang Peng", "Ye Yu", "Xiaopeng Yuan", "Haohan Wang"], "title": "Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": "16 pages", "summary": "While existing multi-agent systems (MAS) can handle complex problems by enabling collaboration among multiple agents, they are often highly task-specific, relying on manually crafted agent roles and interaction prompts, which leads to increased architectural complexity and limited reusability across tasks. Moreover, most MAS communicate primarily through natural language, making them vulnerable to error accumulation and instability in long-context, multi-stage interactions within internal agent histories. In this work, we propose \\textbf{Agent Primitives}, a set of reusable latent building blocks for LLM-based MAS. Inspired by neural network design, where complex models are built from reusable components, we observe that many existing MAS architectures can be decomposed into a small number of recurring internal computation patterns. Based on this observation, we instantiate three primitives: Review, Voting and Selection, and Planning and Execution. All primitives communicate internally via key-value (KV) cache, which improves both robustness and efficiency by mitigating information degradation across multi-stage interactions. To enable automatic system construction, an Organizer agent selects and composes primitives for each query, guided by a lightweight knowledge pool of previously successful configurations, forming a primitive-based MAS. Experiments show that primitives-based MAS improve average accuracy by 12.0-16.5\\% over single-agent baselines, reduce token usage and inference latency by approximately 3$\\times$-4$\\times$ compared to text-based MAS, while incurring only 1.3$\\times$-1.6$\\times$ overhead relative to single-agent inference and providing more stable performance across model backbones.", "AI": {"tldr": "提出了Agent Primitives，这是一种基于LLM的多智能体系统的可重用隐式构建块。", "motivation": "现有的多代理系统高度任务特定且依赖于手动设计的代理角色和交互提示，导致架构复杂性增加和跨任务的有限重用。此外，大多数多代理系统主要通过自然语言进行通信，在长上下文、多阶段互动中容易出现错误积累和稳定性问题。", "method": "提出了三种Agent Primitives：Review, Voting and Selection以及Planning and Execution，并且所有这些原始组件之间都是通过键值缓存进行内部交流的，这提高了系统的健壮性和效率。还引入了一个Organizer代理来自动选择和组合适合每个查询的任务。", "result": "实验表明，基于原始组件的多智能体系统相对于单个代理基线模型平均准确率提升了12.0%-16.5%，与文本驱动的MAS相比减少了3$\times$-4$\times$令牌使用量和推理延迟，而仅比单一代理推断高出约1.3$\times$-1.6$\times$。", "conclusion": "基于Agent Primitives的设计有助于构建更加稳定、高效且可重用的多智能体系统。"}}
{"id": "2602.03693", "pdf": "https://arxiv.org/pdf/2602.03693", "abs": "https://arxiv.org/abs/2602.03693", "authors": ["Deniz Yılmaz", "Evren Ayberk Munis", "Çağrı Toraman", "Süha Kağan Köse", "Burak Aktaş", "Mehmet Can Baytekin", "Bilge Kaan Görür"], "title": "OCRTurk: A Comprehensive OCR Benchmark for Turkish", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by EACL 2026 SIGTURK", "summary": "Document parsing is now widely used in applications, such as large-scale document digitization, retrieval-augmented generation, and domain-specific pipelines in healthcare and education. Benchmarking these models is crucial for assessing their reliability and practical robustness. Existing benchmarks mostly target high-resource languages and provide limited coverage for low-resource settings, such as Turkish. Moreover, existing studies on Turkish document parsing lack a standardized benchmark that reflects real-world scenarios and document diversity. To address this gap, we introduce OCRTurk, a Turkish document parsing benchmark covering multiple layout elements and document categories at three difficulty levels. OCRTurk consists of 180 Turkish documents drawn from academic articles, theses, slide decks, and non-academic articles. We evaluate seven OCR models on OCRTurk using element-wise metrics. Across difficulty levels, PaddleOCR achieves the strongest overall results, leading most element-wise metrics except figures and attaining high Normalized Edit Distance scores in easy, medium, and hard subsets. We also observe performance variation by document type. Models perform well on non-academic documents, while slideshows become the most challenging.", "AI": {"tldr": "本文介绍了OCRTurk，这是一个针对土耳其语文档解析的基准测试，覆盖多种布局元素和文档类别。", "motivation": "现有的OCR基准主要集中在高资源语言上，并且在低资源环境如土耳其语方面提供的覆盖率有限。当前关于土耳其语文档解析的研究缺乏一个标准化的基准来反映现实场景中的文档多样性。", "method": "OCRTurk包括180份来自学术文章、论文、幻灯片和非学术文章的不同类型的土耳其文文档，并针对七种OCR模型进行评估，使用元素级别的指标衡量性能。", "result": "PaddleOCR在不同难度级别上表现最佳，在大多数元素级指标中领先，仅除图例外。并且在易、中等和难子集中都取得了较高的标准化编辑距离评分。", "conclusion": "OCRTurk填补了土耳其语文档解析标准基准的空白，并揭示了不同模型在不同类型文档上的性能差异。"}}
{"id": "2602.03691", "pdf": "https://arxiv.org/pdf/2602.03691", "abs": "https://arxiv.org/abs/2602.03691", "authors": ["Max H. Cohen", "Pio Ong", "Aaron D. Ames"], "title": "Input-to-State Safe Backstepping: Robust Safety-Critical Control with Unmatched Uncertainties", "categories": ["eess.SY", "cs.RO", "math.OC"], "comment": "To appear at the 2026 American Control Conference", "summary": "Guaranteeing safety in the presence of unmatched disturbances -- uncertainties that cannot be directly canceled by the control input -- remains a key challenge in nonlinear control. This paper presents a constructive approach to safety-critical control of nonlinear systems with unmatched disturbances. We first present a generalization of the input-to-state safety (ISSf) framework for systems with these uncertainties using the recently developed notion of an Optimal Decay CBF, which provides more flexibility for satisfying the associated Lyapunov-like conditions for safety. From there, we outline a procedure for constructing ISSf-CBFs for two relevant classes of systems with unmatched uncertainties: i) strict-feedback systems; ii) dual-relative-degree systems, which are similar to differentially flat systems. Our theoretical results are illustrated via numerical simulations of an inverted pendulum and planar quadrotor.", "AI": {"tldr": "提出了针对非线性系统中未匹配扰动的安全关键控制的构造方法", "motivation": "保证存在未匹配干扰时系统的安全性是当前非线性控制系统面临的重大挑战", "method": "通过使用最优衰减CBF的概念扩展了输入到状态安全(ISSf)框架，并为严格反馈和双相对度两类具有未匹配不确定性的系统提供了ISSf-CBF构造方法", "result": "理论结果通过倒立摆和平面四旋翼的数值仿真进行了验证", "conclusion": "提出的方法能够有效地解决非线性系统的安全性问题"}}
{"id": "2602.03690", "pdf": "https://arxiv.org/pdf/2602.03690", "abs": "https://arxiv.org/abs/2602.03690", "authors": ["Zishi Zhang", "Jinhui Han", "Ming Hu", "Yijie Peng"], "title": "LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We consider small-data, large-scale decision problems in which a firm must make many operational decisions simultaneously (e.g., across a large product portfolio) while observing only a few, potentially noisy, data points per instance. Inspired by the success of large language models (LLMs), we propose a pretrain-then-finetune approach built on a designed Transformer model to address this challenge. The model is first pretrained on large-scale, domain-informed synthetic data that encode managerial knowledge and structural features of the decision environment, and is then fine-tuned on real observations. This new pipeline offers two complementary advantages: pretraining injects domain knowledge into the learning process and enables the training of high-capacity models using abundant synthetic data, while finetuning adapts the pretrained model to the operational environment and improves alignment with the true data-generating regime. While we have leveraged the Transformer's state-of-the-art representational capacity, particularly its attention mechanism, to efficiently extract cross-task structure, our approach is not an off-the-shelf application. Instead, it relies on problem-specific architectural design and a tailored training procedure to match the decision setting. Theoretically, we develop the first comprehensive error analysis regarding Transformer learning in relevant contexts, establishing nonasymptotic guarantees that validate the method's effectiveness. Critically, our analysis reveals how pretraining and fine-tuning jointly determine performance, with the dominant contribution governed by whichever is more favorable. In particular, finetuning exhibits an economies-of-scale effect, whereby transfer learning becomes increasingly effective as the number of instances grows.", "AI": {"tldr": "提出了一种基于Transformer模型的预训练然后微调方法，用于解决小数据集下的大规模决策问题。", "motivation": "在大数据环境中，企业需要同时做出众多运营决定，但每个实例只有少量可能有噪声的数据点。受大型语言模型（LLM）成功启发，开发适合此类问题的方法。", "method": "首先通过包含管理知识和结构特征的合成数据对设计的Transformer模型进行预训练，然后在真实观测数据上微调此模型。这种方法利用了Transformer的强大表示能力以及注意力机制来高效提取跨任务结构，并结合特定于问题的设计和定制训练过程以适应决策环境。", "result": "理论分析表明，方法的有效性通过非渐近保证得到验证，预训练和微调共同决定了性能，且随着实例数量的增加，迁移学习变得越来越有效。", "conclusion": "该研究提出了一种创新的方法来解决小数据集下的大规模决策问题，并提供了有效的理论支持。"}}
{"id": "2602.03689", "pdf": "https://arxiv.org/pdf/2602.03689", "abs": "https://arxiv.org/abs/2602.03689", "authors": ["Jiashuo Sun", "Pengcheng Jiang", "Saizhuo Wang", "Jiajun Fan", "Heng Wang", "Siru Ouyang", "Ming Zhong", "Yizhu Jiao", "Chengsong Huang", "Xueqiang Xu", "Pengrui Han", "Peiran Li", "Jiaxin Huang", "Ge Liu", "Heng Ji", "Jiawei Han"], "title": "Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 8 tables, 5 figures", "summary": "Retrieval-Augmented Generation (RAG) systems remain brittle under realistic retrieval noise, even when the required evidence appears in the top-K results. A key reason is that retrievers and rerankers optimize solely for relevance, often selecting either trivial, answer-revealing passages or evidence that lacks the critical information required to answer the question, without considering whether the evidence is suitable for the generator. We propose BAR-RAG, which reframes the reranker as a boundary-aware evidence selector that targets the generator's Goldilocks Zone -- evidence that is neither trivially easy nor fundamentally unanswerable for the generator, but is challenging yet sufficient for inference and thus provides the strongest learning signal. BAR-RAG trains the selector with reinforcement learning using generator feedback, and adopts a two-stage pipeline that fine-tunes the generator under the induced evidence distribution to mitigate the distribution mismatch between training and inference. Experiments on knowledge-intensive question answering benchmarks show that BAR-RAG consistently improves end-to-end performance under noisy retrieval, achieving an average gain of 10.3 percent over strong RAG and reranking baselines while substantially improving robustness. Code is publicly avaliable at https://github.com/GasolSun36/BAR-RAG.", "AI": {"tldr": "本文提出了一种新的证据选择方法BAR-RAG，旨在改进检索增强生成系统在现实噪声环境下的性能。", "motivation": "现有RAG系统对检索结果的噪音非常敏感，在存在需要的信息出现在前K项结果中时仍表现不佳。这是因为检索器和重排序器仅优化相关性，而不考虑所选证据是否适合生成器。", "method": "BAR-RAG将重排序器重新定义为边界感知型证据选择器，并通过强化学习使用生成器反馈训练该选择器，采用两阶段流程来缓解训练和推理之间的分布偏差问题。", "result": "实验结果显示，在知识密集型问答基准测试中，与强大的RAG和其他重排序基线相比，BAR-RAG的性能平均提升了10.3%，同时显著提高了系统的鲁棒性。", "conclusion": "通过优化证据选择过程并引入更合适的训练方法，BAR-RAG能够在现实中的噪声环境下表现出更好的性能和更强的适应性。"}}
{"id": "2602.03688", "pdf": "https://arxiv.org/pdf/2602.03688", "abs": "https://arxiv.org/abs/2602.03688", "authors": ["Wenzhe Fan", "Tommaso Tognoli", "Henry Peng Zou", "Chunyu Miao", "Yibo Wang", "Xinhua Zhang"], "title": "TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System", "categories": ["cs.AI"], "comment": null, "summary": "Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic applications where the agents' roles may change \\textit{across rounds} due to dynamic adversary, task progression, or time-varying constraints such as communication bandwidth. In this paper, we propose addressing this issue through TodyComm, a \\textbf{t}ask-\\textbf{o}riented \\textbf{dy}namic \\textbf{comm}unication algorithm. It produces behavior-driven collaboration topologies that adapt to the dynamics at each round, optimizing the utility for the task through policy gradient. Experiments on five benchmarks demonstrate that under both dynamic adversary and communications budgets, TodyComm delivers superior task effectiveness while retaining token efficiency and scalability.", "AI": {"tldr": "该论文提出了TodyComm算法，用于多轮LLM（大型语言模型）基于的多代理系统中的动态通信。", "motivation": "大多数现有方法使用固定的通信拓扑结构，在实际应用中无法适应各个回合中代理人角色的变化。为解决这一问题，作者提出了一种新的解决方案来优化任务效果和通信效率。", "method": "TodyComm算法根据各回合的行为驱动协作网络的动态变化进行调整，并通过策略梯度优化任务效用。", "result": "实验结果表明，与现有方法相比，在动态对手或通信预算的情况下，TodyComm在保持令牌效率的同时提供了更优的任务效果和可扩展性。", "conclusion": "通过使用行为驱动协作网络的动态变化进行调整，TodyComm能够在多轮LLM基于的多代理系统中提供更好的任务效用和通信效率。"}}
{"id": "2602.03686", "pdf": "https://arxiv.org/pdf/2602.03686", "abs": "https://arxiv.org/abs/2602.03686", "authors": ["Mattia Sabella", "Alberto Archetti", "Pietro Pinoli", "Matteo Matteucci", "Cinzia Cappiello"], "title": "QuAIL: Quality-Aware Inertial Learning for Robust Training under Data Corruption", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Tabular machine learning systems are frequently trained on data affected by non-uniform corruption, including noisy measurements, missing entries, and feature-specific biases. In practice, these defects are often documented only through column-level reliability indicators rather than instance-wise quality annotations, limiting the applicability of many robustness and cleaning techniques. We present QuAIL, a quality-informed training mechanism that incorporates feature reliability priors directly into the learning process. QuAIL augments existing models with a learnable feature-modulation layer whose updates are selectively constrained by a quality-dependent proximal regularizer, thereby inducing controlled adaptation across features of varying trustworthiness. This stabilizes optimization under structured corruption without explicit data repair or sample-level reweighting. Empirical evaluation across 50 classification and regression datasets demonstrates that QuAIL consistently improves average performance over neural baselines under both random and value-dependent corruption, with especially robust behavior in low-data and systematically biased settings. These results suggest that incorporating feature reliability information directly into optimization dynamics is a practical and effective approach for resilient tabular learning.", "AI": {"tldr": "QuAIL是一种质量感知训练机制，它在学习过程中直接融入特征可靠性的先验知识，以提高数据存在缺陷时的模型性能。", "motivation": "传统的机器学习系统常面临非均匀的数据损坏问题，如噪声、缺失值和特异性偏差。由于这些缺陷通常只能通过列级可靠性指标来记录，而不是实例级别的质量注释，限制了许多鲁棒性和清理技术的应用范围。因此，本文提出了QuAIL。", "method": "QuAIL在现有模型中加入了一个可学习的特征调制层，并且其更新被一个基于质量依赖的近似正则化约束所控制，从而实现对不同可信度特性的有控制地适应，以增强优化过程下的鲁棒性。", "result": "实验结果表明，在50个分类和回归数据集上，QuAIL在随机和值相关损坏的情况下都比神经基线平均性能更优，并且在低数据量和系统偏差设置中表现尤为稳健。", "conclusion": "将特征可靠性信息直接融入优化动力学是实现抗干扰表格学习的一种实用有效的方法。"}}
{"id": "2602.03685", "pdf": "https://arxiv.org/pdf/2602.03685", "abs": "https://arxiv.org/abs/2602.03685", "authors": ["Yizhou Liu", "Ziming Liu", "Cengiz Pehlevan", "Jeff Gore"], "title": "Universal One-third Time Scaling in Learning Peaked Distributions", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "24 pages, 6 main text figures, 27 figures in total", "summary": "Training large language models (LLMs) is computationally expensive, partly because the loss exhibits slow power-law convergence whose origin remains debatable. Through systematic analysis of toy models and empirical evaluation of LLMs, we show that this behavior can arise intrinsically from the use of softmax and cross-entropy. When learning peaked probability distributions, e.g., next-token distributions, these components yield power-law vanishing losses and gradients, creating a fundamental optimization bottleneck. This ultimately leads to power-law time scaling of the loss with a universal exponent of $1/3$. Our results provide a mechanistic explanation for observed neural scaling and suggest new directions for improving LLM training efficiency.", "AI": {"tldr": "本文通过分析玩具模型和大规模语言模型(LLM)的实证评估，揭示了在学习尖峰概率分布时，使用softmax和交叉熵会导致损失函数和梯度随时间以幂律方式衰减，并最终导致损失函数的时间尺度遵循一个通用的1/3指数规律。", "motivation": "训练大型语言模型是非常耗时且资源密集型的任务。这种慢速收敛的部分原因是因为其损失函数呈现幂律下降，而造成这一现象的原因尚存在争议。本文旨在揭示这种行为背后的根本机制。", "method": "通过系统分析玩具模型以及大规模语言模型的实证评估，研究了在使用softmax和交叉熵的情况下，学习尖峰概率分布时所出现的问题，并探讨了解决方案。", "result": "研究表明，在学习尖峰概率分布（例如下一个标记分布）时，使用softmax和交叉熵会导致损失函数随时间以幂律方式衰减，其中衰减速率具有普遍的1/3指数。这一结果为理解神经网络扩展性提供了机械性解释，并提出了提高大型语言模型训练效率的新方向。", "conclusion": "本文的研究揭示了在学习尖峰概率分布时使用softmax和交叉熵所引发的基本优化瓶颈，并指出了改善大规模语言模型训练效率的方法。"}}
{"id": "2602.03678", "pdf": "https://arxiv.org/pdf/2602.03678", "abs": "https://arxiv.org/abs/2602.03678", "authors": ["Simon Dietz", "Kai Klede", "An Nguyen", "Bjoern M Eskofier"], "title": "ContraLog: Log File Anomaly Detection with Contrastive Learning and Masked Language Modeling", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages with 16 figures", "summary": "Log files record computational events that reflect system state and behavior, making them a primary source of operational insights in modern computer systems. Automated anomaly detection on logs is therefore critical, yet most established methods rely on log parsers that collapse messages into discrete templates, discarding variable values and semantic content. We propose ContraLog, a parser-free and self-supervised method that reframes log anomaly detection as predicting continuous message embeddings rather than discrete template IDs. ContraLog combines a message encoder that produces rich embeddings for individual log messages with a sequence encoder to model temporal dependencies within sequences. The model is trained with a combination of masked language modeling and contrastive learning to predict masked message embeddings based on the surrounding context. Experiments on the HDFS, BGL, and Thunderbird benchmark datasets empirically demonstrate effectiveness on complex datasets with diverse log messages. Additionally, we find that message embeddings generated by ContraLog carry meaningful information and are predictive of anomalies even without sequence context. These results highlight embedding-level prediction as an approach for log anomaly detection, with potential applicability to other event sequences.", "AI": {"tldr": "ContraLog 提出了一种无需日志解析器的自监督方法，通过对比学习和掩码语言建模来预测连续的消息嵌入以进行异常检测。", "motivation": "传统的方法依赖于将消息压缩为离散模板的日志解析器，这会导致变量值和语义内容丢失。因此需要一种新的方法来保留日志中的丰富信息并实现有效的异常检测。", "method": "ContraLog 结合了消息编码器和序列编码器以生成丰富的嵌入表示，并通过掩码语言建模与对比学习训练模型，预测被掩盖的消息基于上下文。", "result": "在 HDFS、BGL 和 Thunderbird 数据集上的实验表明 ContraLog 在复杂数据集上具有较高的异常检测效果。此外，发现消息嵌入本身也携带了有意义的信息可以用于异常检测。", "conclusion": "ContraLog 展示了一种新的方法来预测日志消息的嵌入以进行异常检测，并且这种方法有可能应用于其他事件序列中。"}}
{"id": "2602.03674", "pdf": "https://arxiv.org/pdf/2602.03674", "abs": "https://arxiv.org/abs/2602.03674", "authors": ["Caleb Probine", "Su Ann Low", "David Fridovich-Keil", "Ufuk Topcu"], "title": "When Should Agents Coordinate in Differentiable Sequential Decision Problems?", "categories": ["cs.MA", "cs.GT", "cs.RO", "math.OC"], "comment": "15 content pages, 2 pages for references, 4 figures", "summary": "Multi-robot teams must coordinate to operate effectively. When a team operates in an uncoordinated manner, and agents choose actions that are only individually optimal, the team's outcome can suffer. However, in many domains, coordination requires costly communication. We explore the value of coordination in a broad class of differentiable motion-planning problems. In particular, we model coordinated behavior as a spectrum: at one extreme, agents jointly optimize a common team objective, and at the other, agents make unilaterally optimal decisions given their individual decision variables, i.e., they operate at Nash equilibria. We then demonstrate that reasoning about coordination in differentiable motion-planning problems reduces to reasoning about the second-order properties of agents' objectives, and we provide algorithms that use this second-order reasoning to determine at which times a team of agents should coordinate.", "AI": {"tldr": "研究多机器人团队在可微分运动规划问题中何时应进行协调。", "motivation": "探讨多机器人队伍如何通过合理协调避免各自最优策略导致的整体效率低下，同时尽量减少昂贵的通信成本。", "method": "建立了一种协调行为模型：从完全共同优化到独立纳什均衡决策，并提出算法利用二阶特性来决定团队在何时应进行协调。", "result": "提供了一套用于确定多机器人队伍在可微分运动规划问题中何时应该协调的算法，该算法基于对代理目标函数第二阶特性的推理。", "conclusion": "通过合理的时间选择协调策略可以提高多机器人任务的整体性能，同时减少不必要的通信成本。"}}
{"id": "2602.03673", "pdf": "https://arxiv.org/pdf/2602.03673", "abs": "https://arxiv.org/abs/2602.03673", "authors": ["Pengfei Yue", "Xiaokang Jiang", "Yilin Lu", "Jianghang Lin", "Shengchuan Zhang", "Liujuan Cao"], "title": "Referring Industrial Anomaly Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Industrial Anomaly Detection (IAD) is vital for manufacturing, yet traditional methods face significant challenges: unsupervised approaches yield rough localizations requiring manual thresholds, while supervised methods overfit due to scarce, imbalanced data. Both suffer from the \"One Anomaly Class, One Model\" limitation. To address this, we propose Referring Industrial Anomaly Segmentation (RIAS), a paradigm leveraging language to guide detection. RIAS generates precise masks from text descriptions without manual thresholds and uses universal prompts to detect diverse anomalies with a single model. We introduce the MVTec-Ref dataset to support this, designed with diverse referring expressions and focusing on anomaly patterns, notably with 95% small anomalies. We also propose the Dual Query Token with Mask Group Transformer (DQFormer) benchmark, enhanced by Language-Gated Multi-Level Aggregation (LMA) to improve multi-scale segmentation. Unlike traditional methods using redundant queries, DQFormer employs only \"Anomaly\" and \"Background\" tokens for efficient visual-textual integration. Experiments demonstrate RIAS's effectiveness in advancing IAD toward open-set capabilities. Code: https://github.com/swagger-coder/RIAS-MVTec-Ref.", "AI": {"tldr": "提出了一种新的工业异常分割方法RIAS，通过语言引导实现精确的异常定位。", "motivation": "传统工业异常检测方法存在粗糙定位和过度拟合问题，并且受限于单一模型处理单类异常。", "method": "采用双查询令牌与掩码组变换器（DQFormer）结合语言门控多级聚合技术，实现基于文本描述的精确异常分割。", "result": "实验结果显示RIAS在工业异常检测中表现出色，具备开放集能力。", "conclusion": "该方法通过引入MVTec-Ref数据集和新的模型结构，有效解决了传统方法中存在的问题。"}}
{"id": "2602.03670", "pdf": "https://arxiv.org/pdf/2602.03670", "abs": "https://arxiv.org/abs/2602.03670", "authors": ["Antonino Emanuele Scurria", "Dimitri Vanden Abeele", "Bortolo Matteo Mognetti", "Serge Massar"], "title": "Equilibrium Propagation for Non-Conservative Systems", "categories": ["cs.LG", "cs.AI", "cs.NE", "math.DS", "physics.class-ph"], "comment": "19 pages (9 pages main text), 7 figures", "summary": "Equilibrium Propagation (EP) is a physics-inspired learning algorithm that uses stationary states of a dynamical system both for inference and learning. In its original formulation it is limited to conservative systems, $\\textit{i.e.}$ to dynamics which derive from an energy function. Given their importance in applications, it is important to extend EP to nonconservative systems, $\\textit{i.e.}$ systems with non-reciprocal interactions. Previous attempts to generalize EP to such systems failed to compute the exact gradient of the cost function. Here we propose a framework that extends EP to arbitrary nonconservative systems, including feedforward networks. We keep the key property of equilibrium propagation, namely the use of stationary states both for inference and learning. However, we modify the dynamics in the learning phase by a term proportional to the non-reciprocal part of the interaction so as to obtain the exact gradient of the cost function. This algorithm can also be derived using a variational formulation that generates the learning dynamics through an energy function defined over an augmented state space. Numerical experiments using the MNIST database show that this algorithm achieves better performance and learns faster than previous proposals.", "AI": {"tldr": "本文提出了将平衡传播算法扩展到非保守系统的框架。", "motivation": "现有平衡传播算法仅适用于保守系统，而大多数实际应用中的网络模型是非保守的。因此有必要开发一种适应于非保守系统的平衡传播算法。", "method": "通过在学习阶段修改动态过程添加了一个与非互易交互成比例的项以获得成本函数的确切梯度，并提出了一个新的能量函数定义扩展了EP。", "result": "数值实验表明，所提出的算法优于先前的方法，在MNIST数据库上实现了更好的性能并加快了学习速度。", "conclusion": "本文成功地将平衡传播算法扩展到了非保守系统模型中，验证了该方法的有效性。"}}
{"id": "2602.03669", "pdf": "https://arxiv.org/pdf/2602.03669", "abs": "https://arxiv.org/abs/2602.03669", "authors": ["Sandeep Patil", "Yongqi Dong", "Haneen Farah", "Hans Hellendoorn"], "title": "Efficient Sequential Neural Network with Spatial-Temporal Attention and Linear LSTM for Robust Lane Detection Using Multi-Frame Images", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "14 pages, 9 figures, under review by IEEE T-ITS", "summary": "Lane detection is a crucial perception task for all levels of automated vehicles (AVs) and Advanced Driver Assistance Systems, particularly in mixed-traffic environments where AVs must interact with human-driven vehicles (HDVs) and challenging traffic scenarios. Current methods lack versatility in delivering accurate, robust, and real-time compatible lane detection, especially vision-based methods often neglect critical regions of the image and their spatial-temporal (ST) salience, leading to poor performance in difficult circumstances such as serious occlusion and dazzle lighting. This study introduces a novel sequential neural network model with a spatial-temporal attention mechanism to focus on key features of lane lines and exploit salient ST correlations among continuous image frames. The proposed model, built on a standard encoder-decoder structure and common neural network backbones, is trained and evaluated on three large-scale open-source datasets. Extensive experiments demonstrate the strength and robustness of the proposed model, outperforming state-of-the-art methods in various testing scenarios. Furthermore, with the ST attention mechanism, the developed sequential neural network models exhibit fewer parameters and reduced Multiply-Accumulate Operations (MACs) compared to baseline sequential models, highlighting their computational efficiency. Relevant data, code, and models are released at https://doi.org/10.4121/4619cab6-ae4a-40d5-af77-582a77f3d821.", "AI": {"tldr": "提出了一种新的基于空间时间注意力机制的顺序神经网络模型，用于增强车道检测的准确性和鲁棒性。", "motivation": "当前方法在复杂交通环境中缺乏灵活性和鲁棒性，尤其是在严重遮挡和眩光照明等困难情况下。", "method": "采用标准编码器-解码器结构，并引入空间时间注意力机制来关注关键特征并利用连续帧之间的显著关联。", "result": "实验表明该模型在多种测试场景中优于现有方法，同时具有较少的参数和较低的MACs操作。", "conclusion": "所提出的顺序神经网络模型展示了强大的性能和鲁棒性，并且计算效率更高。"}}
{"id": "2602.03668", "pdf": "https://arxiv.org/pdf/2602.03668", "abs": "https://arxiv.org/abs/2602.03668", "authors": ["Jung Min Lee", "Dohyeok Lee", "Seokhun Ju", "Taehyun Cho", "Jin Woo Koo", "Li Zhao", "Sangwoo Hong", "Jungwoo Lee"], "title": "MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Learning \\emph{latent actions} from diverse human videos enables scaling robot learning beyond embodiment-specific robot datasets, and these latent actions have recently been used as pseudo-action labels for vision-language-action (VLA) model pretraining. To make VLA pretraining effective, latent actions should contain information about the underlying agent's actions despite the absence of ground-truth labels. We propose \\textbf{M}ulti-\\textbf{V}iew\\textbf{P}oint \\textbf{L}atent \\textbf{A}ction \\textbf{M}odel (\\textbf{MVP-LAM}), which learns discrete latent actions that are highly informative about ground-truth actions from time-synchronized multi-view videos. MVP-LAM trains latent actions with a \\emph{cross-viewpoint reconstruction} objective, so that a latent action inferred from one view must explain the future in another view, reducing reliance on viewpoint-specific cues. On Bridge V2, MVP-LAM produces more action-centric latent actions, achieving higher mutual information with ground-truth actions and improved action prediction, including under out-of-distribution evaluation. Finally, pretraining VLAs with MVP-LAM latent actions improves downstream manipulation performance on the SIMPLER and LIBERO-Long benchmarks.", "AI": {"tldr": "提出MVP-LAM模型，通过时间同步的多视角视频学习更具行动中心性的潜在动作。", "motivation": "为了使视觉-语言-行动预训练更加有效，需要从多样化的人类视频中学习到包含底层代理行为信息的潜在动作。", "method": "利用跨视点重建目标来训练潜在动作，使其在不同视角下保持一致性和可解释性。", "result": "MVP-LAM模型产生的潜在动作与真实动作之间具有更高的互信息，并且提高了行动预测性能，在SIMPLER和LIBERO-Long基准测试中的下游操作表现更好。", "conclusion": "通过跨视点重建，MVP-LAM能够学习到更具行动中心性的潜在动作，从而提高视觉-语言-行动模型的预训练效果。"}}
{"id": "2602.03665", "pdf": "https://arxiv.org/pdf/2602.03665", "abs": "https://arxiv.org/abs/2602.03665", "authors": ["Eunkyu Park", "Wesley Hanwen Deng", "Cheyon Jin", "Matheus Kunzler Maldaner", "Jordan Wheeler", "Jason I. Hong", "Hong Shen", "Adam Perer", "Ken Holstein", "Motahhare Eslami", "Gunhee Kim"], "title": "MM-SCALE: Grounded Multimodal Moral Reasoning via Scalar Judgment and Listwise Alignment", "categories": ["cs.CV", "cs.HC"], "comment": null, "summary": "Vision-Language Models (VLMs) continue to struggle to make morally salient judgments in multimodal and socially ambiguous contexts. Prior works typically rely on binary or pairwise supervision, which often fail to capture the continuous and pluralistic nature of human moral reasoning. We present MM-SCALE (Multimodal Moral Scale), a large-scale dataset for aligning VLMs with human moral preferences through 5-point scalar ratings and explicit modality grounding. Each image-scenario pair is annotated with moral acceptability scores and grounded reasoning labels by humans using an interface we tailored for data collection, enabling listwise preference optimization over ranked scenario sets. By moving from discrete to scalar supervision, our framework provides richer alignment signals and finer calibration of multimodal moral reasoning. Experiments show that VLMs fine-tuned on MM-SCALE achieve higher ranking fidelity and more stable safety calibration than those trained with binary signals.", "AI": {"tldr": "本文提出了MM-SCALE数据集，用于通过5级标度评分和显式模态接地来对VLM进行道德判断的校准。", "motivation": "现有模型在多模式和社会模糊环境中的道德判断能力不足，传统的二元或成对比监督方法无法充分捕捉人类连续且多元化的道德推理方式。", "method": "本文构建了MM-SCALE数据集，并利用5级标度评分和显式模态接地进行标注。该框架支持列表偏好优化，通过更精细的多模式道德推理信号来改进模型校准。", "result": "实验表明，在MM-SCALE上微调后的VLM达到了更高的排名准确性和更加稳定的伦理安全校准。", "conclusion": "本文提出的方法提高了视觉语言模型在复杂情境中的道德判断能力。"}}
{"id": "2602.03664", "pdf": "https://arxiv.org/pdf/2602.03664", "abs": "https://arxiv.org/abs/2602.03664", "authors": ["Yang Wan", "Zheng Cao", "Zhenhao Zhang", "Zhengwen Zeng", "Shuheng Shen", "Changhua Meng", "Linchao Zhu"], "title": "Mitigating Conversational Inertia in Multi-Turn Agents", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large language models excel as few-shot learners when provided with appropriate demonstrations, yet this strength becomes problematic in multiturn agent scenarios, where LLMs erroneously mimic their own previous responses as few-shot examples. Through attention analysis, we identify conversational inertia, a phenomenon where models exhibit strong diagonal attention to previous responses, which is associated with imitation bias that constrains exploration. This reveals a tension when transforming few-shot LLMs into agents: longer context enriches environmental feedback for exploitation, yet also amplifies conversational inertia that undermines exploration. Our key insight is that for identical states, actions generated with longer contexts exhibit stronger inertia than those with shorter contexts, enabling construction of preference pairs without environment rewards. Based on this, we propose Context Preference Learning to calibrate model preferences to favor low-inertia responses over highinertia ones. We further provide context management strategies at inference time to balance exploration and exploitation. Experimental results across eight agentic environments and one deep research scenario validate that our framework reduces conversational inertia and achieves performance improvements.", "AI": {"tldr": "本文研究了大语言模型在多轮对话场景中表现出的模仿偏见问题，并提出了上下文偏好学习方法以减轻这种惯性。", "motivation": "大型语言模型在提供适当演示时表现出色，但在多轮对话代理场景下容易错误地模仿其之前的响应。这导致了对话中的惯性现象，限制了探索能力。", "method": "通过注意力分析识别出对话惯性的特征，并提出上下文偏好学习方法来校准模型偏好，使其更倾向于生成低惯性响应而不是高惯性响应。", "result": "实验结果表明，所提出的框架能够减少对话中的惯性问题并提高性能。", "conclusion": "本文解决了大型语言模型在多轮对话场景中由于模仿偏见而产生的对话惯性问题。通过引入上下文偏好学习方法，成功地提高了代理的探索能力和整体表现。"}}
{"id": "2602.03652", "pdf": "https://arxiv.org/pdf/2602.03652", "abs": "https://arxiv.org/abs/2602.03652", "authors": ["Süha Kağan Köse", "Mehmet Can Baytekin", "Burak Aktaş", "Bilge Kaan Görür", "Evren Ayberk Munis", "Deniz Yılmaz", "Muhammed Yusuf Kartal", "Çağrı Toraman"], "title": "RAGTurk: Best Practices for Retrieval Augmented Generation in Turkish", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted by EACL 2026 SIGTURK", "summary": "Retrieval-Augmented Generation (RAG) enhances LLM factuality, yet design guidance remains English-centric, limiting insights for morphologically rich languages like Turkish. We address this by constructing a comprehensive Turkish RAG dataset derived from Turkish Wikipedia and CulturaX, comprising question-answer pairs and relevant passage chunks. We benchmark seven stages of the RAG pipeline, from query transformation and reranking to answer refinement, without task-specific fine-tuning. Our results show that complex methods like HyDE maximize accuracy (85%) that is considerably higher than the baseline (78.70%). Also a Pareto-optimal configuration using Cross-encoder Reranking and Context Augmentation achieves comparable performance (84.60%) with much lower cost. We further demonstrate that over-stacking generative modules can degrade performance by distorting morphological cues, whereas simple query clarification with robust reranking offers an effective solution.", "AI": {"tldr": "构建了一个综合的土耳其语RAG数据集，并评估了不同阶段的性能。", "motivation": "现有设计指导偏向于英语，忽略了形态丰富的语言如土耳其语的需求。需要一个专门针对这些语言的数据集和方法来提升LLM的事实准确性。", "method": "从Turkish Wikipedia和CulturaX构建了一个包含问题-答案对及相关段落片段的综合数据集，评估了七个阶段性能，包括查询转换、重排序等。", "result": "复杂的方法如HyDE可以实现最高准确率85%，而帕累托最优配置使用交叉编码器重新排序和上下文增强可达到类似效果（84.60%），且成本更低。过度堆叠生成模块可能会影响性能，而简单的查询澄清结合稳健的重排序则是一个有效解决方案。", "conclusion": "为形态丰富的语言如土耳其语提供了重要的设计指导，展示了复杂方法和帕累托最优配置的有效性，强调了适度使用生成模块的重要性。"}}
{"id": "2602.03647", "pdf": "https://arxiv.org/pdf/2602.03647", "abs": "https://arxiv.org/abs/2602.03647", "authors": ["Bowei He", "Minda Hu", "Zenan Xu", "Hongru Wang", "Licheng Zong", "Yankai Chen", "Chen Ma", "Xue Liu", "Pluto Zhou", "Irwin King"], "title": "Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a 'cut-and-regenerate' mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy, proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.", "AI": {"tldr": "本文提出了Search-R2框架，通过演员-修正器协作来提高搜索集成推理的性能。", "motivation": "现有的搜索集成推理方法在强化学习训练中受限于多尺度信用分配问题，导致无法区分高质量推理和偶然猜对的行为。这使得模型容易产生冗余或误导性的搜索行为。", "method": "Search-R2通过将生成过程分解为演员和元修正器两部分来解决此问题：演员负责生成初始推理轨迹，而元修正器则使用'切断与再生'机制有选择地诊断并修复错误步骤。此外引入了混合奖励设计以提供细粒度监督。", "result": "实验结果表明，Search-R2在多个通用和多跳问答数据集上超越了强基线模型，并实现了更高的推理准确性而几乎没有增加额外开销。", "conclusion": "通过提出新颖的演员-修正器协作框架Search-R2，本文有效地解决了搜索集成推理中的信用分配问题，并显著提高了模型性能。"}}
{"id": "2602.03640", "pdf": "https://arxiv.org/pdf/2602.03640", "abs": "https://arxiv.org/abs/2602.03640", "authors": ["Mohanna Hoveyda", "Panagiotis Efstratiadis", "Arjen de Vries", "Maarten de Rijke"], "title": "Tutorial on Reasoning for IR & IR for Reasoning", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "Accepted to ECIR 2026", "summary": "Information retrieval has long focused on ranking documents by semantic relatedness. Yet many real-world information needs demand more: enforcement of logical constraints, multi-step inference, and synthesis of multiple pieces of evidence. Addressing these requirements is, at its core, a problem of reasoning. Across AI communities, researchers are developing diverse solutions for the problem of reasoning, from inference-time strategies and post-training of LLMs, to neuro-symbolic systems, Bayesian and probabilistic frameworks, geometric representations, and energy-based models. These efforts target the same problem: to move beyond pattern-matching systems toward structured, verifiable inference. However, they remain scattered across disciplines, making it difficult for IR researchers to identify the most relevant ideas and opportunities. To help navigate the fragmented landscape of research in reasoning, this tutorial first articulates a working definition of reasoning within the context of information retrieval and derives from it a unified analytical framework. The framework maps existing approaches along axes that reflect the core components of the definition. By providing a comprehensive overview of recent approaches and mapping current methods onto the defined axes, we expose their trade-offs and complementarities, highlight where IR can benefit from cross-disciplinary advances, and illustrate how retrieval process itself can play a central role in broader reasoning systems. The tutorial will equip participants with both a conceptual framework and practical guidance for enhancing reasoning-capable IR systems, while situating IR as a domain that both benefits and contributes to the broader development of reasoning methodologies.", "AI": {"tldr": "教程旨在为信息检索(IR)与推理之间的关系提供一个统一的分析框架，帮助研究人员理解如何将推理技术应用于IR系统。", "motivation": "当前在AI领域中，针对解决推理问题提出了多种方法和技术，但这些研究分散于不同学科之间，使得IR研究人员难以找到最相关的方法和机会。因此需要一种统一的方式整合这些研究成果并为IR系统的改进提供指导。", "method": "首先定义了在信息检索上下文中推理的含义，并根据该定义开发了一个分析框架。此框架将现有方法映射到反映定义核心组件的轴上，以便揭示它们的优缺点及其互补性。", "result": "通过概述近期的方法并将当前技术定位在这个新定义的框架下，教程为IR研究人员提供了理解和应用跨学科进展所需的概念性和实践性指南。", "conclusion": "该教程使参与者能够从概念和实践中理解如何改进推理能力的信息检索系统，并且将IR领域视为既受益于又促进更广泛推理方法论发展的关键区域。"}}
{"id": "2602.03639", "pdf": "https://arxiv.org/pdf/2602.03639", "abs": "https://arxiv.org/abs/2602.03639", "authors": ["Fabian Schramm", "Franki Nguimatsia Tiofack", "Nicolas Perrin-Gilbert", "Marc Toussaint", "Justin Carpentier"], "title": "Variance-Reduced Model Predictive Path Integral via Quadratic Model Approximation", "categories": ["cs.RO"], "comment": null, "summary": "Sampling-based controllers, such as Model Predictive Path Integral (MPPI) methods, offer substantial flexibility but often suffer from high variance and low sample efficiency. To address these challenges, we introduce a hybrid variance-reduced MPPI framework that integrates a prior model into the sampling process. Our key insight is to decompose the objective function into a known approximate model and a residual term. Since the residual captures only the discrepancy between the model and the objective, it typically exhibits a smaller magnitude and lower variance than the original objective. Although this principle applies to general modeling choices, we demonstrate that adopting a quadratic approximation enables the derivation of a closed-form, model-guided prior that effectively concentrates samples in informative regions. Crucially, the framework is agnostic to the source of geometric information, allowing the quadratic model to be constructed from exact derivatives, structural approximations (e.g., Gauss- or Quasi-Newton), or gradient-free randomized smoothing. We validate the approach on standard optimization benchmarks, a nonlinear, underactuated cart-pole control task, and a contact-rich manipulation problem with non-smooth dynamics. Across these domains, we achieve faster convergence and superior performance in low-sample regimes compared to standard MPPI. These results suggest that the method can make sample-based control strategies more practical in scenarios where obtaining samples is expensive or limited.", "AI": {"tldr": "本文提出了一种基于二次模型近似的混合方差减少MPPI框架，以提高采样效率和收敛速度。", "motivation": "现有的采样控制器（如MPPI方法）存在高方差和低样本效率的问题。为了克服这些挑战，文章提出了新的变体来改善这些问题。", "method": "通过将目标函数分解为一个已知的近似模型和一个残差项，并采用二次逼近作为先验模型以导出闭式解，从而集中样本在具有信息量较大的区域中。", "result": "实验结果表明，在标准优化基准、非线性少自由度倒立摆控制任务及多接触复杂操作问题上，与传统MPPI方法相比，该方法实现了更快的收敛速度和更好的性能表现。", "conclusion": "这种基于二次模型近似的混合方差减少MPPI框架为采样效率低下的场景提供了有效的解决方案。"}}
{"id": "2602.03634", "pdf": "https://arxiv.org/pdf/2602.03634", "abs": "https://arxiv.org/abs/2602.03634", "authors": ["Wei Zhang", "Xiang Liu", "Ningjing Liu", "Mingxin Liu", "Wei Liao", "Chunyan Xu", "Xue Yang"], "title": "SPWOOD: Sparse Partial Weakly-Supervised Oriented Object Detection", "categories": ["cs.CV"], "comment": "The Fourteenth International Conference on Learning Representations (ICLR 2026)", "summary": "A consistent trend throughout the research of oriented object detection has been the pursuit of maintaining comparable performance with fewer and weaker annotations. This is particularly crucial in the remote sensing domain, where the dense object distribution and a wide variety of categories contribute to prohibitively high costs. Based on the supervision level, existing oriented object detection algorithms can be broadly grouped into fully supervised, semi-supervised, and weakly supervised methods. Within the scope of this work, we further categorize them to include sparsely supervised and partially weakly-supervised methods. To address the challenges of large-scale labeling, we introduce the first Sparse Partial Weakly-Supervised Oriented Object Detection framework, designed to efficiently leverage only a few sparse weakly-labeled data and plenty of unlabeled data. Our framework incorporates three key innovations: (1) We design a Sparse-annotation-Orientation-and-Scale-aware Student (SOS-Student) model to separate unlabeled objects from the background in a sparsely-labeled setting, and learn orientation and scale information from orientation-agnostic or scale-agnostic weak annotations. (2) We construct a novel Multi-level Pseudo-label Filtering strategy that leverages the distribution of model predictions, which is informed by the model's multi-layer predictions. (3) We propose a unique sparse partitioning approach, ensuring equal treatment for each category. Extensive experiments on the DOTA and DIOR datasets show that our framework achieves a significant performance gain over traditional oriented object detection methods mentioned above, offering a highly cost-effective solution. Our code is publicly available at https://github.com/VisionXLab/SPWOOD.", "AI": {"tldr": "该论文提出了一种稀疏部分弱监督的定向目标检测框架，旨在利用少量稀疏弱标注数据和大量无标注数据进行高效学习。", "motivation": "在遥感领域中，密集的对象分布及多样化的类别使得全面标记的成本高得难以接受。为了应对大规模标签标注的挑战，该论文致力于开发一种高效的解决方案以减少成本同时保持性能。", "method": "框架采用三个关键创新：设计了稀疏注释方向和尺度感知的学生模型（SOS-学生），构建多级伪标签过滤策略以及提出了一种独特的稀疏分区方法。这些措施使得模型能够在少量弱标注数据环境中区分对象背景并学习定向与比例信息。", "result": "在DOTA和DIOR数据集上的广泛实验表明，该框架相对于传统的定向目标检测方法实现了显著的性能提升，并提供了成本效益高的解决方案。", "conclusion": "通过引入稀疏部分弱监督的学习策略，论文提供了一种新的、高效的定向物体检测方案，能够在减少标注成本的同时保持或提高检测精度。"}}
{"id": "2602.03633", "pdf": "https://arxiv.org/pdf/2602.03633", "abs": "https://arxiv.org/abs/2602.03633", "authors": ["Burak Aktaş", "Mehmet Can Baytekin", "Süha Kağan Köse", "Ömer İlbilgi", "Elif Özge Yılmaz", "Çağrı Toraman", "Bilge Kaan Görür"], "title": "BIRDTurk: Adaptation of the BIRD Text-to-SQL Dataset to Turkish", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": "Accepted by EACL 2026 SIGTURK", "summary": "Text-to-SQL systems have achieved strong performance on English benchmarks, yet their behavior in morphologically rich, low-resource languages remains largely unexplored. We introduce BIRDTurk, the first Turkish adaptation of the BIRD benchmark, constructed through a controlled translation pipeline that adapts schema identifiers to Turkish while strictly preserving the logical structure and execution semantics of SQL queries and databases. Translation quality is validated on a sample size determined by the Central Limit Theorem to ensure 95% confidence, achieving 98.15% accuracy on human-evaluated samples. Using BIRDTurk, we evaluate inference-based prompting, agentic multi-stage reasoning, and supervised fine-tuning. Our results reveal that Turkish introduces consistent performance degradation, driven by both structural linguistic divergence and underrepresentation in LLM pretraining, while agentic reasoning demonstrates stronger cross-lingual robustness. Supervised fine-tuning remains challenging for standard multilingual baselines but scales effectively with modern instruction-tuned models. BIRDTurk provides a controlled testbed for cross-lingual Text-to-SQL evaluation under realistic database conditions. We release the training and development splits to support future research.", "AI": {"tldr": "介绍BIRDTurk，这是第一个将BIRD基准转换为土耳其语的项目，旨在评估跨语言Text-to-SQL系统的性能。", "motivation": "由于在形态丰富的低资源语言中对文本到SQL系统的研究有限，因此创建了针对土耳其语的翻译版本以了解其行为表现。", "method": "通过一个控制翻译管道构建BIRDTurk，该管道适应模式标识符并保持SQL查询和数据库逻辑结构的一致性。使用样本大小由中心极限定理确定的人类评估数据验证翻译质量，并评估了不同方法在土耳其语中的性能。", "result": "结果显示，土耳其语引入了一致的性能下降，这是由于语言结构差异和LLM预训练不足导致的。代理式推理展示了更强的语言间鲁棒性，而监督微调则对标准多语言基础模型具有挑战性但可以有效地与现代指令调整模型一起使用。", "conclusion": "BIRDTurk为在实际数据库条件下评估跨语言Text-to-SQL系统提供了控制测试平台。研究团队发布了训练和开发分割以支持未来的研究。"}}
{"id": "2602.03630", "pdf": "https://arxiv.org/pdf/2602.03630", "abs": "https://arxiv.org/abs/2602.03630", "authors": ["Iñaki del Campo", "Pablo Cuervo", "Victor Rodriguez-Fernandez", "Roberto Armellin", "Jack Yarndley"], "title": "Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12", "categories": ["cs.AI"], "comment": "Extended version of the paper presented at AIAA SciTech 2026 Forum. Includes futher experiments, corrections and new appendix", "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency in code generation and general reasoning, yet their capacity for autonomous multi-stage planning in high-dimensional, physically constrained environments remains an open research question. This study investigates the limits of current AI agents by evaluating them against the 12th Global Trajectory Optimization Competition (GTOC 12), a complex astrodynamics challenge requiring the design of a large-scale asteroid mining campaign. We adapt the MLE-Bench framework to the domain of orbital mechanics and deploy an AIDE-based agent architecture to autonomously generate and refine mission solutions. To assess performance beyond binary validity, we employ an \"LLM-as-a-Judge\" methodology, utilizing a rubric developed by domain experts to evaluate strategic viability across five structural categories. A comparative analysis of models, ranging from GPT-4-Turbo to reasoning-enhanced architectures like Gemini 2.5 Pro, and o3, reveals a significant trend: the average strategic viability score has nearly doubled in the last two years (rising from 9.3 to 17.2 out of 26). However, we identify a critical capability gap between strategy and execution. While advanced models demonstrate sophisticated conceptual understanding, correctly framing objective functions and mission architectures, they consistently fail at implementation due to physical unit inconsistencies, boundary condition errors, and inefficient debugging loops. We conclude that, while current LLMs often demonstrate sufficient knowledge and intelligence to tackle space science tasks, they remain limited by an implementation barrier, functioning as powerful domain facilitators rather than fully autonomous engineers.", "AI": {"tldr": "本文探讨了大型语言模型（LLM）在复杂任务中的极限，特别是它们能否胜任自主多阶段规划的能力。", "motivation": "研究旨在探索当前AI代理的局限性，尤其是在高维、物理约束环境下的能力。", "method": "采用MLE-Bench框架并结合AIDE架构来评估模型在GTOC 12任务中的表现，并通过专家制定的标准对策略进行评分。", "result": "尽管战略规划方面有所进步，从9.3分提升至17.2分（满分26分），但在执行过程中仍存在物理单位不一致、边界条件错误等问题。", "conclusion": "当前的LLM虽具备足够的知识和智能来解决航天科学任务中的问题，但受限于实施障碍，它们更像领域内的辅助工具而非完全自主工程师。"}}
{"id": "2602.03625", "pdf": "https://arxiv.org/pdf/2602.03625", "abs": "https://arxiv.org/abs/2602.03625", "authors": ["Estelle Chigot", "Thomas Oberlin", "Manon Huguenin", "Dennis Wilson"], "title": "Multi-Objective Optimization for Synthetic-to-Real Style Transfer", "categories": ["cs.CV"], "comment": "Accepted in International Conference on the Applications of Evolutionary Computation (Part of EvoStar), April 2026 (EvoApplications 2026)", "summary": "Semantic segmentation networks require large amounts of pixel-level annotated data, which are costly to obtain for real-world images. Computer graphics engines can generate synthetic images alongside their ground-truth annotations. However, models trained on such images can perform poorly on real images due to the domain gap between real and synthetic images. Style transfer methods can reduce this difference by applying a realistic style to synthetic images. Choosing effective data transformations and their sequence is difficult due to the large combinatorial search space of style transfer operators. Using multi-objective genetic algorithms, we optimize pipelines to balance structural coherence and style similarity to target domains. We study the use of paired-image metrics on individual image samples during evolution to enable rapid pipeline evaluation, as opposed to standard distributional metrics that require the generation of many images. After optimization, we evaluate the resulting Pareto front using distributional metrics and segmentation performance. We apply this approach to standard datasets in synthetic-to-real domain adaptation: from the video game GTA5 to real image datasets Cityscapes and ACDC, focusing on adverse conditions. Results demonstrate that evolutionary algorithms can propose diverse augmentation pipelines adapted to different objectives. The contribution of this work is the formulation of style transfer as a sequencing problem suitable for evolutionary optimization and the study of efficient metrics that enable feasible search in this space. The source code is available at: https://github.com/echigot/MOOSS.", "AI": {"tldr": "本文提出了使用多目标遗传算法优化风格迁移管道，以缩小合成图像和真实图像之间的域差距，提高语义分割模型在现实场景中的性能。", "motivation": "由于真实世界图像的像素级注释数据获取成本高，研究者利用计算机图形引擎生成带有地面真值注释的合成图像。然而，直接用这些合成图像训练出的模型在实际应用中表现不佳，因为存在合成与真实图像之间的域差距。通过优化风格迁移操作顺序来减少这种差距。", "method": "提出了一种基于多目标遗传算法的方法，用于优化风格迁移管道以平衡结构一致性和目标域样式相似性。采用配对图度量单个样本以加快进化过程，并在演化完成后使用分布度量评估最终结果。", "result": "实验表明，所提出的演化方法能够为不同的目标任务生成多样化的增强管道。该研究将风格转换视为适合进化解的序列问题，并探讨了高效度量的研究，使此类空间中的搜索成为可能。", "conclusion": "本文的工作在于通过多目标遗传算法优化合成到现实风格迁移的操作顺序，提高语义分割模型在实际场景中的性能。"}}
{"id": "2602.03624", "pdf": "https://arxiv.org/pdf/2602.03624", "abs": "https://arxiv.org/abs/2602.03624", "authors": ["Rien Sonck", "Bernd Accou", "Tom Francart", "Jonas Vanthornhout"], "title": "A Multi-decoder Neural Tracking Method for Accurately Predicting Speech Intelligibility", "categories": ["eess.SP", "cs.SD"], "comment": null, "summary": "Objective: EEG-based methods can predict speech intelligibility, but their accuracy and robustness lag behind behavioral tests, which typically show test-retest differences under 1 dB. We introduce the multi-decoder method to predict speech reception thresholds (SRTs) from EEG recordings, enabling objective assessment for populations unable to perform behavioral tests; such as those with disorders of consciousness or during hearing aid fitting. Approach: The method aggregates data from hundreds of decoders, each trained on different speech features and EEG preprocessing setups to quantify neural tracking (NT) of speech signals. Using data from 39 participants (ages 18-24), we recorded 29 minutes of EEG per person while they listened to speech at six signal-to-noise ratios and a quiet story. NT values were combined into a high-dimensional feature vector per subject, and a support vector regression model was trained to predict SRTs from these vectors. Main Result: Predictions correlated significantly with behavioral SRTs (r = 0.647, p < 0.001; NRMSE = 0.19), with all differences under 1 dB. SHAP analysis showed theta/delta bands and early lags had slightly greater influence. Using pretrained subject-independent decoders reduced required EEG data collection to 15 minutes (3 minutes of story, 12 minutes across six SNR conditions) without losing accuracy.", "AI": {"tldr": "本文提出了一种多解码器神经跟踪方法，通过EEG预测言语可懂度，以实现客观评估。", "motivation": "基于EEG的方法可以预测言语可懂度，但其准确性和鲁棒性仍低于行为测试。本文旨在为无法进行行为测试的群体（如意识障碍者或听力辅助装置适配期间的人）提供一种更有效的客观评估方法。", "method": "该方法从数百个解码器中汇总数据，每个解码器基于不同的语音特征和EEG预处理设置来量化言语信号的神经跟踪。研究使用了39名参与者的数据，每人在六种信噪比条件下以及安静故事背景下听演讲并记录EEG。", "result": "预测值与行为测试中的SRT显著相关（r=0.647,p<0.001;NRMSE=0.19），所有差异小于1dB。SHAP分析表明，theta/delta频带和早期时滞的影响稍大。使用预训练的独立于受试者的解码器可以将EEG数据采集时间减少到15分钟（3分钟故事，6种SNR条件下的12分钟）而不降低准确性。", "conclusion": "研究证明了多解码器神经跟踪方法能够准确地预测言语可懂度，并为无法进行行为测试的群体提供了新的评估手段。"}}
{"id": "2602.03623", "pdf": "https://arxiv.org/pdf/2602.03623", "abs": "https://arxiv.org/abs/2602.03623", "authors": ["Youyuan Long", "Gokhan Solak", "Sara Zeynalpour", "Heng Zhang", "Arash Ajoudani"], "title": "Self-supervised Physics-Informed Manipulation of Deformable Linear Objects with Non-negligible Dynamics", "categories": ["cs.RO"], "comment": "Submitted to IEEE Transactions on Robotics. Video: https://youtu.be/lgX2J-00TRM", "summary": "We address dynamic manipulation of deformable linear objects by presenting SPiD, a physics-informed self-supervised learning framework that couples an accurate deformable object model with an augmented self-supervised training strategy. On the modeling side, we extend a mass-spring model to more accurately capture object dynamics while remaining lightweight enough for high-throughput rollouts during self-supervised learning. On the learning side, we train a neural controller using a task-oriented cost, enabling end-to-end optimization through interaction with the differentiable object model. In addition, we propose a self-supervised DAgger variant that detects distribution shift during deployment and performs offline self-correction to further enhance robustness without expert supervision. We evaluate our method primarily on the rope stabilization task, where a robot must bring a swinging rope to rest as quickly and smoothly as possible. Extensive experiments in both simulation and the real world demonstrate that the proposed controller achieves fast and smooth rope stabilization, generalizing across unseen initial states, rope lengths, masses, non-uniform mass distributions, and external disturbances. Additionally, we develop an affordable markerless rope perception method and demonstrate that our controller maintains performance with noisy and low-frequency state updates. Furthermore, we demonstrate the generality of the framework by extending it to the rope trajectory tracking task. Overall, SPiD offers a data-efficient, robust, and physically grounded framework for dynamic manipulation of deformable linear objects, featuring strong sim-to-real generalization.", "AI": {"tldr": "该论文提出了SPiD框架，用于动态操作可变形线性物体的自我监督学习方法。", "motivation": "解决动态可变形线性物体的操作问题，开发一种有效的自我监督学习框架以提高机器人对绳索稳定任务中的性能。", "method": "引入了物理学引导的自我监督学习框架SPiD，该框架结合了一种精确的可变形对象模型和增强型自我监督训练策略。通过扩展质量-弹簧模型来准确捕捉物体的动力学，并使用任务导向的成本函数训练神经控制器。", "result": "实验表明，在模拟环境和实际世界中，提出的控制器能够实现快速和平稳的绳索稳定操作，且能够在未见过的状态下泛化。", "conclusion": "SPiD提供了一种数据高效、鲁棒性强且物理基础良好的框架来处理可变形线性物体的操作问题。"}}
{"id": "2602.03622", "pdf": "https://arxiv.org/pdf/2602.03622", "abs": "https://arxiv.org/abs/2602.03622", "authors": ["Lu Zhang", "Huizhen Yu", "Zuowei Wang", "Fu Gui", "Yatu Guo", "Wei Zhang", "Mengyu Jia"], "title": "Quasi-multimodal-based pathophysiological feature learning for retinal disease diagnosis", "categories": ["cs.CV", "physics.med-ph"], "comment": "ef:Zhang, L., Yu, H., Wang, Z., Gui, F., Guo, Y., Zhang, W., Jia, M., 2026. Quasi-multimodal-based pathophysiological feature learning for retinal disease diagnosis. Medical Image Analysis 109, 103886", "summary": "Retinal diseases spanning a broad spectrum can be effectively identified and diagnosed using complementary signals from multimodal data. However, multimodal diagnosis in ophthalmic practice is typically challenged in terms of data heterogeneity, potential invasiveness, registration complexity, and so on. As such, a unified framework that integrates multimodal data synthesis and fusion is proposed for retinal disease classification and grading. Specifically, the synthesized multimodal data incorporates fundus fluorescein angiography (FFA), multispectral imaging (MSI), and saliency maps that emphasize latent lesions as well as optic disc/cup regions. Parallel models are independently trained to learn modality-specific representations that capture cross-pathophysiological signatures. These features are then adaptively calibrated within and across modalities to perform information pruning and flexible integration according to downstream tasks. The proposed learning system is thoroughly interpreted through visualizations in both image and feature spaces. Extensive experiments on two public datasets demonstrated the superiority of our approach over state-of-the-art ones in the tasks of multi-label classification (F1-score: 0.683, AUC: 0.953) and diabetic retinopathy grading (Accuracy:0.842, Kappa: 0.861). This work not only enhances the accuracy and efficiency of retinal disease screening but also offers a scalable framework for data augmentation across various medical imaging modalities.", "AI": {"tldr": "本文提出了一种基于准多模态数据融合的视网膜疾病诊断方法，通过合成和融合不同类型的图像数据以提高疾病的分类与分级准确性。", "motivation": "为了克服传统多模态诊断中的数据异质性、潜在侵入性和配准复杂性等问题，并提升视网膜疾病的筛查准确率和效率。", "method": "该研究采用一种统一框架，将不同类型的图像数据（如FFA、MSI、注意力图）进行合成与融合。通过训练并校准模态间特征以实现信息的灵活整合与优化。", "result": "实验结果表明，在多标签分类任务和糖尿病视网膜病变分级上，所提出的方法显著优于现有方法（F1分数：0.683，AUC：0.953；准确率:0.842, Kappa系数:0.861）。", "conclusion": "该工作不仅提高了视网膜疾病的诊断准确性与效率，还提供了一个可扩展的数据增强框架，适用于多种医学成像模式。"}}
{"id": "2602.03615", "pdf": "https://arxiv.org/pdf/2602.03615", "abs": "https://arxiv.org/abs/2602.03615", "authors": ["Baiyang Song", "Jun Peng", "Yuxin Zhang", "Guangyao Chen", "Feidiao Yang", "Jianyuan Guo"], "title": "KTV: Keyframes and Key Tokens Selection for Efficient Training-Free Video LLMs", "categories": ["cs.CV"], "comment": null, "summary": "Training-free video understanding leverages the strong image comprehension capabilities of pre-trained vision language models (VLMs) by treating a video as a sequence of static frames, thus obviating the need for costly video-specific training. However, this paradigm often suffers from severe visual redundancy and high computational overhead, especially when processing long videos. Crucially, existing keyframe selection strategies, especially those based on CLIP similarity, are prone to biases and may inadvertently overlook critical frames, resulting in suboptimal video comprehension. To address these significant challenges, we propose \\textbf{KTV}, a novel two-stage framework for efficient and effective training-free video understanding. In the first stage, KTV performs question-agnostic keyframe selection by clustering frame-level visual features, yielding a compact, diverse, and representative subset of frames that mitigates temporal redundancy. In the second stage, KTV applies key visual token selection, pruning redundant or less informative tokens from each selected keyframe based on token importance and redundancy, which significantly reduces the number of tokens fed into the LLM. Extensive experiments on the Multiple-Choice VideoQA task demonstrate that KTV outperforms state-of-the-art training-free baselines while using significantly fewer visual tokens, \\emph{e.g.}, only 504 visual tokens for a 60-min video with 10800 frames, achieving $44.8\\%$ accuracy on the MLVU-Test benchmark. In particular, KTV also exceeds several training-based approaches on certain benchmarks.", "AI": {"tldr": "提出了一种名为KTV的两阶段框架，用于高效和有效的无训练视频理解。", "motivation": "现有基于CLIP相似度的关键帧选择策略容易出现偏差，忽略关键帧，导致视频理解效果不佳。为了克服这一挑战，提出了KTV框架，以解决视觉冗余和高计算开销的问题。", "method": "第一阶段通过聚类选择关键帧；第二阶段进行重要性剪枝，减少每个选定的关键帧中的令牌数量。", "result": "在多个视频问答任务中，KTV表现优于现有的无训练基线方法，并且仅使用较少的视觉令牌即可实现高准确率。", "conclusion": "KTV不仅提高了视频理解的效率和效果，还在某些基准测试上超过了有训练的方法。"}}
{"id": "2602.03608", "pdf": "https://arxiv.org/pdf/2602.03608", "abs": "https://arxiv.org/abs/2602.03608", "authors": ["Haibo Jin", "Ruoxi Chen", "Peiyan Zhang", "Yifeng Luo", "Huimin Zeng", "Man Luo", "Haohan Wang"], "title": "Controlling Output Rankings in Generative Engines for LLM-based Search", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "23 pages", "summary": "The way customers search for and choose products is changing with the rise of large language models (LLMs). LLM-based search, or generative engines, provides direct product recommendations to users, rather than traditional online search results that require users to explore options themselves. However, these recommendations are strongly influenced by the initial retrieval order of LLMs, which disadvantages small businesses and independent creators by limiting their visibility. In this work, we propose CORE, an optimization method that \\textbf{C}ontrols \\textbf{O}utput \\textbf{R}ankings in g\\textbf{E}nerative Engines for LLM-based search. Since the LLM's interactions with the search engine are black-box, CORE targets the content returned by search engines as the primary means of influencing output rankings. Specifically, CORE optimizes retrieved content by appending strategically designed optimization content to steer the ranking of outputs. We introduce three types of optimization content: string-based, reasoning-based, and review-based, demonstrating their effectiveness in shaping output rankings. To evaluate CORE in realistic settings, we introduce ProductBench, a large-scale benchmark with 15 product categories and 200 products per category, where each product is associated with its top-10 recommendations collected from Amazon's search interface. Extensive experiments on four LLMs with search capabilities (GPT-4o, Gemini-2.5, Claude-4, and Grok-3) demonstrate that CORE achieves an average Promotion Success Rate of \\textbf{91.4\\% @Top-5}, \\textbf{86.6\\% @Top-3}, and \\textbf{80.3\\% @Top-1}, across 15 product categories, outperforming existing ranking manipulation methods while preserving the fluency of optimized content.", "AI": {"tldr": "提出了一种控制生成引擎输出排名的方法CORE，以提高LLM驱动搜索中较小企业和独立创作者的可见性。", "motivation": "大语言模型（LLMs）在产品推荐中的应用使得传统搜索结果的呈现方式发生了变化。然而，这些推荐受到初始检索顺序的影响，导致小型企业及独立创作者的产品难以获得曝光度，因此需要一种新的方法来优化输出排名。", "method": "CORE通过向搜索引擎返回的内容添加特定设计的优化内容（字符串、推理和评论类型）来影响LLM驱动搜索中产品推荐的排序。研究引入了ProductBench基准测试集，并在四个具备搜索功能的LLMs上进行了实验。", "result": "实验结果表明，CORE方法实现了平均91.4% @Top-5，86.6% @Top-3和80.3% @Top-1的产品推荐提升率，在保持优化内容流畅度的同时超过了现有的排名操纵方法。", "conclusion": "该研究提出了一种有效的解决方案——CORE，能够显著提高LLM驱动搜索中的产品可见性，特别是对于小型企业及独立创作者。"}}
{"id": "2602.03604", "pdf": "https://arxiv.org/pdf/2602.03604", "abs": "https://arxiv.org/abs/2602.03604", "authors": ["Basile Terver", "Randall Balestriero", "Megi Dervishi", "David Fan", "Quentin Garrido", "Tushar Nagarajan", "Koustuv Sinha", "Wancong Zhang", "Mike Rabbat", "Yann LeCun", "Amir Bar"], "title": "A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present EB-JEPA, an open-source library for learning representations and world models using Joint-Embedding Predictive Architectures (JEPAs). JEPAs learn to predict in representation space rather than pixel space, avoiding the pitfalls of generative modeling while capturing semantically meaningful features suitable for downstream tasks. Our library provides modular, self-contained implementations that illustrate how representation learning techniques developed for image-level self-supervised learning can transfer to video, where temporal dynamics add complexity, and ultimately to action-conditioned world models, where the model must additionally learn to predict the effects of control inputs. Each example is designed for single-GPU training within a few hours, making energy-based self-supervised learning accessible for research and education. We provide ablations of JEA components on CIFAR-10. Probing these representations yields 91% accuracy, indicating that the model learns useful features. Extending to video, we include a multi-step prediction example on Moving MNIST that demonstrates how the same principles scale to temporal modeling. Finally, we show how these representations can drive action-conditioned world models, achieving a 97% planning success rate on the Two Rooms navigation task. Comprehensive ablations reveal the critical importance of each regularization component for preventing representation collapse. Code is available at https://github.com/facebookresearch/eb_jepa.", "AI": {"tldr": "提出了一种基于能量的联合嵌入预测架构（EB-JEPA）开源库，用于学习表示和世界模型。", "motivation": "避免生成建模中的陷阱，并捕获适合下游任务的语义有意义的功能。", "method": "通过在表征空间而非像素空间中进行预测来实现，提供了模块化、自包含的实施例以展示图像级自我监督学习技术如何转移到视频上以及动作条件下的世界模型。", "result": "对CIFAR-10的数据集进行探究时，准确率达到91%；在Moving MNIST数据集上的多步预测示例中显示了相同原则可扩展到时间建模的能力，并且在Two Rooms导航任务中的规划成功率达到了97％。", "conclusion": "通过详细的消融研究揭示了每个正则化组件对于防止表示崩溃的重要性。"}}
{"id": "2602.03603", "pdf": "https://arxiv.org/pdf/2602.03603", "abs": "https://arxiv.org/abs/2602.03603", "authors": ["Lorena Maria Genua", "Nikita Boguslavskii", "Zhi Li"], "title": "Human-in-the-Loop Failure Recovery with Adaptive Task Allocation", "categories": ["cs.RO"], "comment": null, "summary": "Since the recent Covid-19 pandemic, mobile manipulators and humanoid assistive robots with higher levels of autonomy have increasingly been adopted for patient care and living assistance. Despite advancements in autonomy, these robots often struggle to perform reliably in dynamic and unstructured environments and require human intervention to recover from failures. Effective human-robot collaboration is essential to enable robots to receive assistance from the most competent operator, in order to reduce their workload and minimize disruptions in task execution. In this paper, we propose an adaptive method for allocating robotic failures to human operators (ARFA). Our proposed approach models the capabilities of human operators, and continuously updates these beliefs based on their actual performance for failure recovery. For every failure to be resolved, a reward function calculates expected outcomes based on operator capabilities and historical data, task urgency, and current workload distribution. The failure is then assigned to the operator with the highest expected reward. Our simulations and user studies show that ARFA outperforms random allocation, significantly reducing robot idle time, improving overall system performance, and leading to a more distributed workload among operators.", "AI": {"tldr": "本文提出了一种适应性方法，用于将机器人故障分配给人类操作员（ARFA），以提高人机协作效率。", "motivation": "在COVID-19疫情期间，移动机械臂和助行机器人被广泛应用于患者护理中。然而，这些机器人在动态环境中常常出现故障，需要人类干预才能恢复正常运行。有效的合作可以减少操作者的工作负担并降低任务执行中断的风险。", "method": "该方法通过建模操作员的能力，并根据他们的实际表现持续更新对失败恢复的信念。对于每个待解决的故障，基于操作员能力、历史数据、紧急程度以及当前工作量分配来计算预期结果。最终将故障分配给具有最高预期收益的操作员。", "result": "模拟和用户研究显示，ARFA优于随机分配方法，显著减少了机器人空闲时间并提高了系统的整体性能。", "conclusion": "ARFA是一种有效的适应性任务分配方法，能够改善人机协作中的效率，并且可以更均衡地分配操作者的负担。"}}
{"id": "2602.03595", "pdf": "https://arxiv.org/pdf/2602.03595", "abs": "https://arxiv.org/abs/2602.03595", "authors": ["Haichao Jiang", "Tianming Liang", "Wei-Shi Zheng", "Jian-Fang Hu"], "title": "Refer-Agent: A Collaborative Multi-Agent System with Reasoning and Reflection for Referring Video Object Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Referring Video Object Segmentation (RVOS) aims to segment objects in videos based on textual queries. Current methods mainly rely on large-scale supervised fine-tuning (SFT) of Multi-modal Large Language Models (MLLMs). However, this paradigm suffers from heavy data dependence and limited scalability against the rapid evolution of MLLMs. Although recent zero-shot approaches offer a flexible alternative, their performance remains significantly behind SFT-based methods, due to the straightforward workflow designs. To address these limitations, we propose \\textbf{Refer-Agent}, a collaborative multi-agent system with alternating reasoning-reflection mechanisms. This system decomposes RVOS into step-by-step reasoning process. During reasoning, we introduce a Coarse-to-Fine frame selection strategy to ensure the frame diversity and textual relevance, along with a Dynamic Focus Layout that adaptively adjusts the agent's visual focus. Furthermore, we propose a Chain-of-Reflection mechanism, which employs a Questioner-Responder pair to generate a self-reflection chain, enabling the system to verify intermediate results and generates feedback for next-round reasoning refinement. Extensive experiments on five challenging benchmarks demonstrate that Refer-Agent significantly outperforms state-of-the-art methods, including both SFT-based models and zero-shot approaches. Moreover, Refer-Agent is flexible and enables fast integration of new MLLMs without any additional fine-tuning costs. Code will be released.", "AI": {"tldr": "提出了一种多代理协作系统Refer-Agent，用于视频中的对象分割任务。", "motivation": "当前方法依赖大规模监督微调存在数据依赖性和可扩展性问题；零样本方法性能落后。", "method": "采用推理-反思交替机制和粗到细帧选择策略，并引入动态聚焦布局及自反馈链以提高准确性。", "result": "在五个基准测试中超越现有SOTA模型，包括监督微调和零样本方法。", "conclusion": "Refer-Agent具备灵活性且易于集成新模态大型语言模型。"}}
{"id": "2602.03594", "pdf": "https://arxiv.org/pdf/2602.03594", "abs": "https://arxiv.org/abs/2602.03594", "authors": ["Alireza Salehi", "Ehsan Karami", "Sepehr Noey", "Sahand Noey", "Makoto Yamada", "Reshad Hosseini", "Mohammad Sabokrou"], "title": "TIPS Over Tricks: Simple Prompts for Effective Zero-shot Anomaly Detection", "categories": ["cs.CV"], "comment": "This is the extended version of the paper accepted in ICASSP'26, which will be publicly available in May. Authors' contributions may vary among the versions", "summary": "Anomaly detection identifies departures from expected behavior in safety-critical settings. When target-domain normal data are unavailable, zero-shot anomaly detection (ZSAD) leverages vision-language models (VLMs). However, CLIP's coarse image-text alignment limits both localization and detection due to (i) spatial misalignment and (ii) weak sensitivity to fine-grained anomalies; prior work compensates with complex auxiliary modules yet largely overlooks the choice of backbone. We revisit the backbone and use TIPS-a VLM trained with spatially aware objectives. While TIPS alleviates CLIP's issues, it exposes a distributional gap between global and local features. We address this with decoupled prompts-fixed for image-level detection and learnable for pixel-level localization-and by injecting local evidence into the global score. Without CLIP-specific tricks, our TIPS-based pipeline improves image-level performance by 1.1-3.9% and pixel-level by 1.5-6.9% across seven industrial datasets, delivering strong generalization with a lean architecture. Code is available at github.com/AlirezaSalehy/Tipsomaly.", "AI": {"tldr": "本文提出了一种基于TIPS的零样本异常检测方法，通过简单提示改善了CLIP模型在空间对齐和细粒度异常敏感性方面的不足。", "motivation": "现有零样本异常检测方法依赖于复杂的辅助模块来弥补视觉语言模型（如CLIP）的空间错位及对于细粒度异常的弱敏感性。本文旨在通过重新审视模型架构并引入TIPS这一具有空间感知训练目标的视觉语言模型，以简化和优化该过程。", "method": "利用了TIPS模型的特性，并设计了分离提示（用于图像级检测）和可学习提示（用于像素级定位），同时将局部证据注入全局得分来解决分布差距问题。无需针对CLIP进行特殊处理即可实现性能提升。", "result": "在七个工业数据集上，基于TIPS的方法实现了1.1%-3.9%的图像级别性能改进和1.5%-6.9%的像素级定位改善。", "conclusion": "该方法通过引入TIPS模型并结合简单的提示策略，在不需要复杂辅助模块的情况下提高了零样本异常检测的精度，展现了良好的泛化能力。"}}
{"id": "2602.03591", "pdf": "https://arxiv.org/pdf/2602.03591", "abs": "https://arxiv.org/abs/2602.03591", "authors": ["Wenji Wu", "Shuo Ye", "Yiyu Liu", "Jiguang He", "Zhuo Wang", "Zitong Yu"], "title": "High-Resolution Underwater Camouflaged Object Detection: GBU-UCOD Dataset and Topology-Aware and Frequency-Decoupled Networks", "categories": ["cs.CV"], "comment": null, "summary": "Underwater Camouflaged Object Detection (UCOD) is a challenging task due to the extreme visual similarity between targets and backgrounds across varying marine depths. Existing methods often struggle with topological fragmentation of slender creatures in the deep sea and the subtle feature extraction of transparent organisms. In this paper, we propose DeepTopo-Net, a novel framework that integrates topology-aware modeling with frequency-decoupled perception. To address physical degradation, we design the Water-Conditioned Adaptive Perceptor (WCAP), which employs Riemannian metric tensors to dynamically deform convolutional sampling fields. Furthermore, the Abyssal-Topology Refinement Module (ATRM) is developed to maintain the structural connectivity of spindly targets through skeletal priors. Specifically, we first introduce GBU-UCOD, the first high-resolution (2K) benchmark tailored for marine vertical zonation, filling the data gap for hadal and abyssal zones. Extensive experiments on MAS3K, RMAS, and our proposed GBU-UCOD datasets demonstrate that DeepTopo-Net achieves state-of-the-art performance, particularly in preserving the morphological integrity of complex underwater patterns. The datasets and codes will be released at https://github.com/Wuwenji18/GBU-UCOD.", "AI": {"tldr": "该论文提出了一种新的框架DeepTopo-Net，用于解决水下伪装物体检测中的拓扑结构和频率解耦问题。", "motivation": "现有的方法在处理深海中细长生物的拓扑碎片化以及透明生物的细微特征提取方面存在困难。本文提出了一个新型框架来克服这些问题。", "method": "设计了WCAP模块使用黎曼度量张量动态变形卷积采样场，发展了ATRM模块通过骨骼先验保持纤细目标的结构连接性，并引入GBU-UCOD数据集填补深海和深渊区域的数据空白。", "result": "实验表明DeepTopo-Net在MAS3K、RMAS以及新提出的GBU-UCOD数据集中实现了最先进的性能，特别是在保持复杂水下图案形态完整性的方面。", "conclusion": "通过提出新的框架和技术模块，本文成功提升了水下伪装物体检测的精度和鲁棒性。"}}
{"id": "2602.03589", "pdf": "https://arxiv.org/pdf/2602.03589", "abs": "https://arxiv.org/abs/2602.03589", "authors": ["Ming Nie", "Dan Ding", "Chunwei Wang", "Yuanfan Guo", "Jianhua Han", "Hang Xu", "Li Zhang"], "title": "SlowFocus: Enhancing Fine-grained Temporal Understanding in Video LLM", "categories": ["cs.CV"], "comment": "NeurIPS 2024", "summary": "Large language models (LLMs) have demonstrated exceptional capabilities in text understanding, which has paved the way for their expansion into video LLMs (Vid-LLMs) to analyze video data. However, current Vid-LLMs struggle to simultaneously retain high-quality frame-level semantic information (i.e., a sufficient number of tokens per frame) and comprehensive video-level temporal information (i.e., an adequate number of sampled frames per video). This limitation hinders the advancement of Vid-LLMs towards fine-grained video understanding. To address this issue, we introduce the SlowFocus mechanism, which significantly enhances the equivalent sampling frequency without compromising the quality of frame-level visual tokens. SlowFocus begins by identifying the query-related temporal segment based on the posed question, then performs dense sampling on this segment to extract local high-frequency features. A multi-frequency mixing attention module is further leveraged to aggregate these local high-frequency details with global low-frequency contexts for enhanced temporal comprehension. Additionally, to tailor Vid-LLMs to this innovative mechanism, we introduce a set of training strategies aimed at bolstering both temporal grounding and detailed temporal reasoning capabilities. Furthermore, we establish FineAction-CGR, a benchmark specifically devised to assess the ability of Vid-LLMs to process fine-grained temporal understanding tasks. Comprehensive experiments demonstrate the superiority of our mechanism across both existing public video understanding benchmarks and our proposed FineAction-CGR.", "AI": {"tldr": "通过引入SlowFocus机制提高视频LLM在细粒度时间理解上的性能", "motivation": "当前的Vid-LLMs难以同时保持高质量的帧级语义信息和全面的视频级别时间信息，限制了其对细粒度视频的理解能力。为此，提出了一种新的方法来解决这个问题。", "method": "SlowFocus机制首先基于提问识别相关的时间片段，并在此段落上进行密集采样以提取局部高频特征。同时使用多频率混合注意力模块聚合这些局部高频细节和全局低频背景，以此提高时间理解力。此外，还提出了训练策略以及一个新的基准FineAction-CGR来评估Vid-LLMs在细粒度时间任务处理上的能力。", "result": "实验结果表明，该机制比现有方法在多个公共视频理解和新提出的FineAction-CGR上都表现出优越性。", "conclusion": "通过引入SlowFocus机制和相关训练策略，成功提升了Vid-LLMs在细粒度时间理解方面的能力，并验证了其有效性。"}}
{"id": "2602.03586", "pdf": "https://arxiv.org/pdf/2602.03586", "abs": "https://arxiv.org/abs/2602.03586", "authors": ["Tao Ren", "Xiaoyu Luo", "Qiongxiu Li"], "title": "APEX: Probing Neural Networks via Activation Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Prior work on probing neural networks primarily relies on input-space analysis or parameter perturbation, both of which face fundamental limitations in accessing structural information encoded in intermediate representations. We introduce Activation Perturbation for EXploration (APEX), an inference-time probing paradigm that perturbs hidden activations while keeping both inputs and model parameters fixed. We theoretically show that activation perturbation induces a principled transition from sample-dependent to model-dependent behavior by suppressing input-specific signals and amplifying representation-level structure, and further establish that input perturbation corresponds to a constrained special case of this framework. Through representative case studies, we demonstrate the practical advantages of APEX. In the small-noise regime, APEX provides a lightweight and efficient measure of sample regularity that aligns with established metrics, while also distinguishing structured from randomly labeled models and revealing semantically coherent prediction transitions. In the large-noise regime, APEX exposes training-induced model-level biases, including a pronounced concentration of predictions on the target class in backdoored models. Overall, our results show that APEX offers an effective perspective for exploring, and understanding neural networks beyond what is accessible from input space alone.", "AI": {"tldr": "本文提出了一种名为APEX的推理时间探测范式，通过扰动隐藏激活来分析神经网络。", "motivation": "前人研究主要依赖于输入空间分析或参数扰动，这两种方法都难以访问中间表示中编码的结构信息。因此，作者提出了一个基于激活扰动的方法来探索和理解神经网络的内部结构。", "method": "APEX通过在推理时间对隐藏激活进行扰动，同时保持输入和模型参数不变。理论分析表明这种扰动可从样本依赖行为转移到模型依赖行为，并且可以区分具有结构信息和随机标记的模型。", "result": "实验结果表明，在小噪声情况下，APEX能有效地度量样本规则性并揭示语义上一致的预测转换；在大噪声情况下，则能暴露训练诱导的模型偏见。", "conclusion": "总体而言，研究显示APEX提供了一种有效的方法来探索和理解神经网络内部结构，超越了单纯依赖输入空间分析所能提供的信息。"}}
{"id": "2602.03584", "pdf": "https://arxiv.org/pdf/2602.03584", "abs": "https://arxiv.org/abs/2602.03584", "authors": ["Yi-Kai Zhang", "Zhiyuan Yao", "Hongyan Hao", "Yueqing Sun", "Qi Gu", "Hui Su", "Xunliang Cai", "De-Chuan Zhan", "Han-Jia Ye"], "title": "$V_0$: A Generalist Value Model for Any Policy at State Zero", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Policy gradient methods rely on a baseline to measure the relative advantage of an action, ensuring the model reinforces behaviors that outperform its current average capability. In the training of Large Language Models (LLMs) using Actor-Critic methods (e.g., PPO), this baseline is typically estimated by a Value Model (Critic) often as large as the policy model itself. However, as the policy continuously evolves, the value model requires expensive, synchronous incremental training to accurately track the shifting capabilities of the policy. To avoid this overhead, Group Relative Policy Optimization (GRPO) eliminates the coupled value model by using the average reward of a group of rollouts as the baseline; yet, this approach necessitates extensive sampling to maintain estimation stability. In this paper, we propose $V_0$, a Generalist Value Model capable of estimating the expected performance of any model on unseen prompts without requiring parameter updates. We reframe value estimation by treating the policy's dynamic capability as an explicit context input; specifically, we leverage a history of instruction-performance pairs to dynamically profile the model, departing from the traditional paradigm that relies on parameter fitting to perceive capability shifts. Focusing on value estimation at State Zero (i.e., the initial prompt, hence $V_0$), our model serves as a critical resource scheduler. During GRPO training, $V_0$ predicts success rates prior to rollout, allowing for efficient sampling budget allocation; during deployment, it functions as a router, dispatching instructions to the most cost-effective and suitable model. Empirical results demonstrate that $V_0$ significantly outperforms heuristic budget allocation and achieves a Pareto-optimal trade-off between performance and cost in LLM routing tasks.", "AI": {"tldr": "本文提出了一种名为$V_0$的通用价值模型，可以在不更新参数的情况下估计任意策略在未见提示上的预期表现。", "motivation": "传统的方法中，随着策略不断进化，价值模型需要昂贵且同步增量训练以准确跟踪策略的能力变化。为避免此开销，Group Relative Policy Optimization (GRPO) 方法通过平均奖励作为基线消除了耦合的价值模型，但这又需要大量的采样来保持估计的稳定性。", "method": "$V_0$方法通过将政策动态能力视为显式上下文输入进行价值估算，并利用指令-表现对的历史记录动态配置策略。具体来说，在状态零（即初始提示）上进行价值估计时，此模型作为关键资源调度器发挥作用。", "result": "实验结果表明，$V_0$显著优于基于直觉的预算分配方法，在大语言模型路由任务中实现了性能与成本之间的帕累托最优权衡。", "conclusion": "$V_0$通过将策略动态能力作为显式上下文输入进行价值估算，并利用指令-表现对的历史记录配置策略，能够在不更新参数的情况下估计任意策略在未见提示上的预期表现，从而实现高效采样预算分配和模型路由功能。"}}
{"id": "2602.03580", "pdf": "https://arxiv.org/pdf/2602.03580", "abs": "https://arxiv.org/abs/2602.03580", "authors": ["Zhihao Li", "Boyang Ma", "Xuelong Dai", "Minghui Xu", "Yue Zhang", "Biwei Yan", "Kun Li"], "title": "Don't believe everything you read: Understanding and Measuring MCP Behavior under Misleading Tool Descriptions", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The Model Context Protocol (MCP) enables large language models to invoke external tools through natural-language descriptions, forming the foundation of many AI agent applications. However, MCP does not enforce consistency between documented tool behavior and actual code execution, even though MCP Servers often run with broad system privileges. This gap introduces a largely unexplored security risk. We study how mismatches between externally presented tool descriptions and underlying implementations systematically shape the mental models and decision-making behavior of intelligent agents. Specifically, we present the first large-scale study of description-code inconsistency in the MCP ecosystem. We design an automated static analysis framework and apply it to 10,240 real-world MCP Servers across 36 categories. Our results show that while most servers are highly consistent, approximately 13% exhibit substantial mismatches that can enable undocumented privileged operations, hidden state mutations, or unauthorized financial actions. We further observe systematic differences across application categories, popularity levels, and MCP marketplaces. Our findings demonstrate that description-code inconsistency is a concrete and prevalent attack surface in MCP-based AI agents, and motivate the need for systematic auditing and stronger transparency guarantees in future agent ecosystems.", "AI": {"tldr": "研究模型上下文协议（MCP）中描述与实际代码不一致的安全风险。", "motivation": "MCP服务器可能运行具有广泛系统权限的大型语言模型，但并未强制执行工具行为文档与实际代码执行之间的一致性。这种不一致性引入了潜在的安全威胁。", "method": "设计了一个自动静态分析框架并应用于10,240个真实的MCP服务器上进行大规模研究。", "result": "发现大部分服务器高度一致，约有13%的服务器存在显著不匹配问题，可能导致未记录的操作、状态变化或未经授权的行为。", "conclusion": "描述和代码之间的一致性问题是基于MCP的AI代理中的实际攻击面，并促使未来需要系统性的审计和更强的安全透明度保证。"}}
{"id": "2602.03578", "pdf": "https://arxiv.org/pdf/2602.03578", "abs": "https://arxiv.org/abs/2602.03578", "authors": ["Su Dong", "Qinggang Zhang", "Yilin Xiao", "Shengyuan Chen", "Chuang Zhou", "Xiao Huang"], "title": "Use Graph When It Needs: Efficiently and Adaptively Integrating Retrieval-Augmented Generation with Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) often struggle with knowledge-intensive tasks due to hallucinations and outdated parametric knowledge. While Retrieval-Augmented Generation (RAG) addresses this by integrating external corpora, its effectiveness is limited by fragmented information in unstructured domain documents. Graph-augmented RAG (GraphRAG) emerged to enhance contextual reasoning through structured knowledge graphs, yet paradoxically underperforms vanilla RAG in real-world scenarios, exhibiting significant accuracy drops and prohibitive latency despite gains on complex queries. We identify the rigid application of GraphRAG to all queries, regardless of complexity, as the root cause. To resolve this, we propose an efficient and adaptive GraphRAG framework called EA-GraphRAG that dynamically integrates RAG and GraphRAG paradigms through syntax-aware complexity analysis. Our approach introduces: (i) a syntactic feature constructor that parses each query and extracts a set of structural features; (ii) a lightweight complexity scorer that maps these features to a continuous complexity score; and (iii) a score-driven routing policy that selects dense RAG for low-score queries, invokes graph-based retrieval for high-score queries, and applies complexity-aware reciprocal rank fusion to handle borderline cases. Extensive experiments on a comprehensive benchmark, consisting of two single-hop and two multi-hop QA benchmarks, demonstrate that our EA-GraphRAG significantly improves accuracy, reduces latency, and achieves state-of-the-art performance in handling mixed scenarios involving both simple and complex queries.", "AI": {"tldr": "该论文提出了一种自适应的图增强检索生成框架，旨在根据查询复杂性动态选择RAG或GraphRAG以提高准确性和效率。", "motivation": "大型语言模型在知识密集型任务中常常因幻觉和过时的知识而表现不佳。虽然检索增强生成（RAG）通过整合外部语料库解决了这些问题，但其效果受限于未结构化文档中的碎片化信息。图增强的RAG尽管可以改善上下文推理，但在实际场景中却表现出准确率下降和高延迟的问题。", "method": "作者提出了一个自适应的GraphRAG框架（EA-GraphRAG），通过语法感知复杂度分析动态整合RAG与GraphRAG。该方法包括：(i) 查询解析器以提取结构特征；(ii) 轻量级复杂性评分器将这些特征映射为连续复杂度分数；以及(iii) 根据分数驱动的路由策略选择最适合处理不同复杂查询的方法。", "result": "在两个单跳和两个多跳问答基准上的广泛实验表明，该方法显著提高了准确率、降低了延迟，并且在处理简单与复杂查询混合场景时达到了最先进的性能。", "conclusion": "EA-GraphRAG框架能够根据任务需求自适应地选择合适的模型，有效解决知识密集型任务中的挑战。"}}
{"id": "2602.03571", "pdf": "https://arxiv.org/pdf/2602.03571", "abs": "https://arxiv.org/abs/2602.03571", "authors": ["Karim Essalmi", "Fernando Garrido", "Fawzi Nashashibi"], "title": "Multi-Player, Multi-Strategy Quantum Game Model for Interaction-Aware Decision-Making in Autonomous Driving", "categories": ["cs.RO"], "comment": null, "summary": "Although significant progress has been made in decision-making for automated driving, challenges remain for deployment in the real world. One challenge lies in addressing interaction-awareness. Most existing approaches oversimplify interactions between the ego vehicle and surrounding agents, and often neglect interactions among the agents themselves. A common solution is to model these interactions using classical game theory. However, its formulation assumes rational players, whereas human behavior is frequently uncertain or irrational. To address these challenges, we propose the Quantum Game Decision-Making (QGDM) model, a novel framework that combines classical game theory with quantum mechanics principles (such as superposition, entanglement, and interference) to tackle multi-player, multi-strategy decision-making problems. To the best of our knowledge, this is one of the first studies to apply quantum game theory to decision-making for automated driving. QGDM runs in real time on a standard computer, without requiring quantum hardware. We evaluate QGDM in simulation across various scenarios, including roundabouts, merging, and highways, and compare its performance with multiple baseline methods. Results show that QGDM significantly improves success rates and reduces collision rates compared to classical approaches, particularly in scenarios with high interaction.", "AI": {"tldr": "本文提出了一种结合经典博弈理论和量子力学原理的新型框架，用于解决自动驾驶中的多玩家、多种策略决策问题。", "motivation": "现有的大多数方法在处理车辆与周围代理之间的互动时过于简化，并且往往忽视了这些代理之间相互作用。此外，传统的方法假设参与者是理性的，而人类行为常常不确定或非理性。因此，需要一种新的模型来应对这些问题。", "method": "提出了量子博弈决策（QGDM）模型，该模型结合经典博弈理论与量子力学原理如叠加、纠缠和干涉等概念，解决多玩家多策略的决策问题。此框架能够实时运行在普通计算机上而无需量子硬件，并通过模拟实验验证其性能。", "result": "QGDM 在各种场景中的表现优于传统的基线方法，特别是在存在高度互动的情况下，提高了成功概率并减少了碰撞率。", "conclusion": "本文首次将量子博弈理论应用于自动驾驶决策中，展示了该模型在解决复杂、不确定的交通环境下的优势。"}}
{"id": "2602.03569", "pdf": "https://arxiv.org/pdf/2602.03569", "abs": "https://arxiv.org/abs/2602.03569", "authors": ["Linjie Mu", "Zhongzhen Huang", "Yannian Gu", "Shengqian Qin", "Shaoting Zhang", "Xiaofan Zhang"], "title": "EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "World models offer a principled framework for simulating future states under interventions, but realizing such models in complex, high-stakes domains like medicine remains challenging. Recent large language models (LLMs) have achieved strong performance on static medical reasoning tasks, raising the question of whether they can function as dynamic medical world models capable of simulating disease progression and treatment outcomes over time. In this work, we show that LLMs only incorporating medical knowledge struggle to maintain consistent patient states under sequential interventions, leading to error accumulation in long-horizon clinical simulation. To address this limitation, we introduce EHRWorld, a patient-centric medical world model trained under a causal sequential paradigm, together with EHRWorld-110K, a large-scale longitudinal clinical dataset derived from real-world electronic health records. Extensive evaluations demonstrate that EHRWorld significantly outperforms naive LLM-based baselines, achieving more stable long-horizon simulation, improved modeling of clinically sensitive events, and favorable reasoning efficiency, highlighting the necessity of training on causally grounded, temporally evolving clinical data for reliable and robust medical world modeling.", "AI": {"tldr": "本文提出了一种基于电子健康记录的患者为中心的医学世界模型EHRWorld，用于长期临床轨迹模拟。", "motivation": "现有的大型语言模型在静态医疗推理任务上表现良好，但在复杂的、高风险领域如医学中实现动态医学世界模型存在挑战。这些模型难以维持一致的患者状态并积累错误。", "method": "提出了一个基于因果顺序训练的EHRWorld模型，并构建了110K规模的大规模纵向临床数据集EHRWorld-110K，用于改善长期临床模拟的稳定性和效率。", "result": "实验结果显示，EHRWorld在长期时间跨度上的模拟更加稳定，对临床敏感事件建模更好，并且具有更好的推理效率。", "conclusion": "证明了需要基于因果基础、时间演化的临床数据进行训练以获得可靠的医学世界模型。"}}
{"id": "2602.03567", "pdf": "https://arxiv.org/pdf/2602.03567", "abs": "https://arxiv.org/abs/2602.03567", "authors": ["Weiqi Wang", "Zhiyi Tian", "Chenhan Zhang", "Luoyu Chen", "Shui Yu"], "title": "EVE: Efficient Verification of Data Erasure through Customized Perturbation in Approximate Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Verifying whether the machine unlearning process has been properly executed is critical but remains underexplored. Some existing approaches propose unlearning verification methods based on backdooring techniques. However, these methods typically require participation in the model's initial training phase to backdoor the model for later verification, which is inefficient and impractical. In this paper, we propose an efficient verification of erasure method (EVE) for verifying machine unlearning without requiring involvement in the model's initial training process. The core idea is to perturb the unlearning data to ensure the model prediction of the specified samples will change before and after unlearning with perturbed data. The unlearning users can leverage the observation of the changes as a verification signal. Specifically, the perturbations are designed with two key objectives: ensuring the unlearning effect and altering the unlearned model's prediction of target samples. We formalize the perturbation generation as an adversarial optimization problem, solving it by aligning the unlearning gradient with the gradient of boundary change for target samples. We conducted extensive experiments, and the results show that EVE can verify machine unlearning without involving the model's initial training process, unlike backdoor-based methods. Moreover, EVE significantly outperforms state-of-the-art unlearning verification methods, offering significant speedup in efficiency while enhancing verification accuracy. The source code of EVE is released at \\uline{https://anonymous.4open.science/r/EVE-C143}, providing a novel tool for verification of machine unlearning.", "AI": {"tldr": "提出了一种高效的机器遗忘验证方法EVE，通过定制化扰动来确保模型在未经初始训练参与的情况下正确执行了数据删除。", "motivation": "现有的基于后门技术的验证方法通常需要在模型初始化阶段进行干预，效率低下且不切实际。为了克服这些问题，提出了EVE方法以提高验证过程的效率和准确性。", "method": "通过扰动未学习的数据来改变目标样本在删除前后的预测结果，将其形式化为对抗性优化问题，并通过与边界变化梯度对齐的方式来解决这个优化问题。", "result": "实验结果显示，EVE方法无需涉及模型初始化阶段即可验证机器遗忘过程，相比后门技术方法更为高效准确。", "conclusion": "提出了高效的机器遗忘验证工具EVE，它能够在不参与初始训练的情况下执行有效的数据删除验证，并且提供了显著的速度和准确性提升。"}}
{"id": "2602.03560", "pdf": "https://arxiv.org/pdf/2602.03560", "abs": "https://arxiv.org/abs/2602.03560", "authors": ["Yizhao Gao", "Jianyu Wei", "Qihao Zhang", "Yu Cheng", "Shimao Chen", "Zhengju Tang", "Zihan Jiang", "Yifan Song", "Hailin Zhang", "Liang Zhao", "Bo Yang", "Gang Wang", "Shijie Cao", "Fuli Luo"], "title": "HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing", "categories": ["cs.CL", "cs.AI"], "comment": "17 pages, 2 figures", "summary": "This work introduces Hybrid Sparse Attention (HySparse), a new architecture that interleaves each full attention layer with several sparse attention layers. While conceptually simple, HySparse strategically derives each sparse layer's token selection and KV caches directly from the preceding full attention layer. This architecture resolves two fundamental limitations of prior sparse attention methods. First, conventional approaches typically rely on additional proxies to predict token importance, introducing extra complexity and potentially suboptimal performance. In contrast, HySparse uses the full attention layer as a precise oracle to identify important tokens. Second, existing sparse attention designs often reduce computation without saving KV cache. HySparse enables sparse attention layers to reuse the full attention KV cache, thereby reducing both computation and memory. We evaluate HySparse on both 7B dense and 80B MoE models. Across all settings, HySparse consistently outperforms both full attention and hybrid SWA baselines. Notably, in the 80B MoE model with 49 total layers, only 5 layers employ full attention, yet HySparse achieves substantial performance gains while reducing KV cache storage by nearly 10x.", "AI": {"tldr": "介绍了HySparse，一种新的混合稀疏注意力架构，在每个完整的注意力层之后加入多个稀疏注意力层，并利用前一层的全注意力作为重要令牌的选择和KV缓存复用。", "motivation": "传统方法依赖额外代理预测令牌的重要性，引入了不必要的复杂性并可能降低性能。HySparse通过使用先前的全注意力层精确识别重要令牌来解决这一问题，并且在计算中节省KV缓存以减少内存需求。", "method": "HySparse架构在一个完整的注意力层后面跟随多个稀疏注意力层，这些层从之前的完整层获取重要令牌和KV缓存。这消除了传统方法中的额外复杂性并优化了资源利用。", "result": "在7B稠密模型和80B MoE模型中，HySparse表现出色，即使只有少数全注意力层也能实现显著的性能提升，并且大幅减少了内存消耗。", "conclusion": "HySparse通过精确选择重要令牌和高效复用KV缓存，在计算效率和性能之间实现了良好的平衡。"}}
{"id": "2602.03558", "pdf": "https://arxiv.org/pdf/2602.03558", "abs": "https://arxiv.org/abs/2602.03558", "authors": ["Xinyue Li", "Zhiming Xu", "Zhichao Zhang", "Zhaolin Cai", "Sijing Wu", "Xiongkuo Min", "Yitong Chen", "Guangtao Zhai"], "title": "ELIQ: A Label-Free Framework for Quality Assessment of Evolving AI-Generated Images", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Generative text-to-image models are advancing at an unprecedented pace, continuously shifting the perceptual quality ceiling and rendering previously collected labels unreliable for newer generations. To address this, we present ELIQ, a Label-free Framework for Quality Assessment of Evolving AI-generated Images. Specifically, ELIQ focuses on visual quality and prompt-image alignment, automatically constructs positive and aspect-specific negative pairs to cover both conventional distortions and AIGC-specific distortion modes, enabling transferable supervision without human annotations. Building on these pairs, ELIQ adapts a pre-trained multimodal model into a quality-aware critic via instruction tuning and predicts two-dimensional quality using lightweight gated fusion and a Quality Query Transformer. Experiments across multiple benchmarks demonstrate that ELIQ consistently outperforms existing label-free methods, generalizes from AI-generated content (AIGC) to user-generated content (UGC) scenarios without modification, and paves the way for scalable and label-free quality assessment under continuously evolving generative models. The code will be released upon publication.", "AI": {"tldr": "ELIQ是一个无标签框架，用于评估不断演进的AI生成图像的质量。", "motivation": "随着生成性文本到图像模型的发展，先前收集的标注变得不可靠。因此提出了一种新的方法来解决这个问题，即无需人工标注即可进行高质量评价的问题。", "method": "ELIQ通过构造正面和特定方面的负面样本对，适应预训练的多模态模型，并使用轻量级门控融合及质量查询变换器预测二维质量评估。", "result": "实验结果表明，ELIQ在多个基准上优于现有的无标签方法，且可以从AI生成内容推广到用户生成内容场景。", "conclusion": "该研究为大规模和无标注的图像质量评估提供了可能，并适应于不断演进的生成模型。"}}
{"id": "2602.03555", "pdf": "https://arxiv.org/pdf/2602.03555", "abs": "https://arxiv.org/abs/2602.03555", "authors": ["Chang Liu", "Fuxin Fan", "Annette Schwarz", "Andreas Maier"], "title": "Cut to the Mix: Simple Data Augmentation Outperforms Elaborate Ones in Limited Organ Segmentation Datasets", "categories": ["cs.CV"], "comment": "Accepted at MICCAI 2024", "summary": "Multi-organ segmentation is a widely applied clinical routine and automated organ segmentation tools dramatically improve the pipeline of the radiologists. Recently, deep learning (DL) based segmentation models have shown the capacity to accomplish such a task. However, the training of the segmentation networks requires large amount of data with manual annotations, which is a major concern due to the data scarcity from clinic. Working with limited data is still common for researches on novel imaging modalities. To enhance the effectiveness of DL models trained with limited data, data augmentation (DA) is a crucial regularization technique. Traditional DA (TDA) strategies focus on basic intra-image operations, i.e. generating images with different orientations and intensity distributions. In contrast, the interimage and object-level DA operations are able to create new images from separate individuals. However, such DA strategies are not well explored on the task of multi-organ segmentation. In this paper, we investigated four possible inter-image DA strategies: CutMix, CarveMix, ObjectAug and AnatoMix, on two organ segmentation datasets. The result shows that CutMix, CarveMix and AnatoMix can improve the average dice score by 4.9, 2.0 and 1.9, compared with the state-of-the-art nnUNet without DA strategies. These results can be further improved by adding TDA strategies. It is revealed in our experiments that Cut-Mix is a robust but simple DA strategy to drive up the segmentation performance for multi-organ segmentation, even when CutMix produces intuitively 'wrong' images. Our implementation is publicly available for future benchmarks.", "AI": {"tldr": "研究了四种跨图像数据增强策略在多器官分割任务中的表现，发现CutMix是最有效的简单但强大的策略。", "motivation": "深度学习模型进行多器官分割需要大量标注数据，而临床中此类数据稀缺。为了提高有限数据训练的DL模型性能，采用了跨图像的数据增强技术。", "method": "研究了四种跨图像DA策略：CutMix、CarveMix、ObjectAug和AnatoMix，并与最先进的nnUNet进行了比较。", "result": "实验结果表明，CutMix比其他方法在平均Dice分数上有更好的提升效果。即使生成的图像看起来不正确，CutMix也能有效提高分割性能。", "conclusion": "CutMix是一种简单而有效的数据增强策略，适用于多器官分割任务，在有限的数据环境下尤其有用。"}}
{"id": "2602.03554", "pdf": "https://arxiv.org/pdf/2602.03554", "abs": "https://arxiv.org/abs/2602.03554", "authors": ["Bogdan Zagribelnyy", "Ivan Ilin", "Maksim Kuznetsov", "Nikita Bondarev", "Roman Schutski", "Thomas MacDougall", "Rim Shayakhmetov", "Zulfat Miftakhutdinov", "Mikolaj Mizera", "Vladimir Aladinskiy", "Alex Aliper", "Alex Zhavoronkov"], "title": "When Single Answer Is Not Enough: Rethinking Single-Step Retrosynthesis Benchmarks for LLMs", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CL"], "comment": null, "summary": "Recent progress has expanded the use of large language models (LLMs) in drug discovery, including synthesis planning. However, objective evaluation of retrosynthesis performance remains limited. Existing benchmarks and metrics typically rely on published synthetic procedures and Top-K accuracy based on single ground-truth, which does not capture the open-ended nature of real-world synthesis planning. We propose a new benchmarking framework for single-step retrosynthesis that evaluates both general-purpose and chemistry-specialized LLMs using ChemCensor, a novel metric for chemical plausibility. By emphasizing plausibility over exact match, this approach better aligns with human synthesis planning practices. We also introduce CREED, a novel dataset comprising millions of ChemCensor-validated reaction records for LLM training, and use it to train a model that improves over the LLM baselines under this benchmark.", "AI": {"tldr": "提出了一种新的单步逆合成分析评估框架，使用ChemCensor作为化学合理性指标，并引入了CREED数据集以改进LLM在合成规划中的性能。", "motivation": "现有逆合成分析基准依赖于单一真值和基于发布的合成程序的Top-K准确性，这不能完全捕捉现实世界中合成计划的开放性。论文旨在通过强调化学合理性而非精确匹配来更好地评估大型语言模型（LLMs）的表现。", "method": "引入了一种新的单步逆合成分析指标ChemCensor，并创建了一个名为CREED的数据集，该数据集包含数百万个经过ChemCensor验证的反应记录，用于训练改进后的模型。此外还介绍了使用新框架评估通用和化学专用的LLM的方法。", "result": "通过在新的评估基准下对LLM进行重新训练并使用CREED数据集，论文展示了改进后的模型显著优于基线模型的表现。", "conclusion": "新提出的评估方法更贴合人类合成规划实践，并为大型语言模型在药物发现中的应用提供了更好的评价标准。"}}
{"id": "2602.03550", "pdf": "https://arxiv.org/pdf/2602.03550", "abs": "https://arxiv.org/abs/2602.03550", "authors": ["Fang Yan", "Simon Foster", "Ana Cavalcanti", "Ibrahim Habli", "James Baxter"], "title": "Formal Evidence Generation for Assurance Cases for Robotic Software Models", "categories": ["cs.SE", "cs.FL", "cs.LO", "cs.RO"], "comment": "This is a preprint. The paper is currently under review at Software and Systems Modeling", "summary": "Robotics and Autonomous Systems are increasingly deployed in safety-critical domains, so that demonstrating their safety is essential. Assurance Cases (ACs) provide structured arguments supported by evidence, but generating and maintaining this evidence is labour-intensive, error-prone, and difficult to keep consistent as systems evolve. We present a model-based approach to systematically generating AC evidence by embedding formal verification into the assurance workflow. The approach addresses three challenges: systematically deriving formal assertions from natural language requirements using templates, orchestrating multiple formal verification tools to handle diverse property types, and integrating formal evidence production into the workflow. Leveraging RoboChart, a domain-specific modelling language with formal semantics, we combine model checking and theorem proving in our approach. Structured requirements are automatically transformed into formal assertions using predefined templates, and verification results are automatically integrated as evidence. Case studies demonstrate the effectiveness of our approach.", "AI": {"tldr": "机器人软件模型的安全性保证案例的正式证据生成方法", "motivation": "证明机器人和自主系统的安全性在安全关键领域尤为重要，但传统的保证案例难以维护且易出错。", "method": "提出一种基于模型的方法，通过将形式验证嵌入到保障工作流程中来系统地生成AC证据。利用RoboChart语言自动转换结构化需求为正式断言，并整合多种验证工具的结果作为证据。", "result": "实验表明此方法有效提高了证据生成的效率和准确性。", "conclusion": "该模型化的方法能有效地解决传统保证案例存在的问题，提高安全性证明的可靠性和一致性。"}}
{"id": "2602.03549", "pdf": "https://arxiv.org/pdf/2602.03549", "abs": "https://arxiv.org/abs/2602.03549", "authors": ["Michael Küttner", "Valeria Zitz", "Supraja Ramesh", "Michael Beigl", "Tobias Röddiger"], "title": "EarResp-ANS : Audio-Based On-Device Respiration Rate Estimation on Earphones with Adaptive Noise Suppression", "categories": ["cs.SD", "cs.HC"], "comment": "31 pages, 11 figures", "summary": "Respiratory rate (RR) is a key vital sign for clinical assessment and mental well-being, yet it is rarely monitored in everyday life due to the lack of unobtrusive sensing technologies. In-ear audio sensing is promising due to its high social acceptance and the amplification of physiological sounds caused by the occlusion effect; however, existing approaches often fail under real-world noise or rely on computationally expensive models. We present EarResp-ANS, the first system enabling fully on-device, real-time RR estimation on commercial earphones. The system employs LMS-based adaptive noise suppression (ANS) to attenuate ambient noise while preserving respiration-related acoustic components, without requiring neural networks or audio streaming, thereby explicitly addressing the energy and privacy constraints of wearable devices. We evaluate EarResp-ANS in a study with 18 participants under realistic acoustic conditions, including music, cafeteria noise, and white noise up to 80 dB SPL. EarResp-ANS achieves robust performance with a global MAE of 0.84 CPM , reduced to 0.47 CPM via automatic outlier rejection, while operating with less than 2% processor load directly on the earphone.", "AI": {"tldr": "EarResp-ANS是一种在耳塞上进行实时呼吸速率估计的系统，利用自适应噪声抑制来减少环境噪音的影响。", "motivation": "现有的方法在现实世界中的噪音环境下表现不佳或依赖昂贵计算模型。EarResp-ANS旨在提供一个完全在设备端运行、低能耗且保护隐私的解决方案。", "method": "EarResp-ANS使用LMS自适应噪声抑制来减少环境噪音，并保存与呼吸相关的声学成分，同时无需神经网络或音频流。", "result": "在包含音乐和高达80 dB SPL白噪声等现实环境中对18名参与者进行测试后，EarResp-ANS表现出强大的性能，全局MAE为每分钟0.84次。通过自动异常值拒绝进一步减少到每分钟0.47次，并且处理器负载小于2%。", "conclusion": "EarResp-ANS提供了一种在耳塞上实时估计呼吸速率的新方法，在现实环境中具有较高的准确性和鲁棒性，同时解决了设备能耗和隐私问题。"}}
{"id": "2602.03547", "pdf": "https://arxiv.org/pdf/2602.03547", "abs": "https://arxiv.org/abs/2602.03547", "authors": ["Dingyi Zhou", "Mu He", "Zhuowei Fang", "Xiangtong Yao", "Yinlong Liu", "Alois Knoll", "Hu Cao"], "title": "AffordanceGrasp-R1:Leveraging Reasoning-Based Affordance Segmentation with Reinforcement Learning for Robotic Grasping", "categories": ["cs.RO", "cs.CV"], "comment": "Preprint version", "summary": "We introduce AffordanceGrasp-R1, a reasoning-driven affordance segmentation framework for robotic grasping that combines a chain-of-thought (CoT) cold-start strategy with reinforcement learning to enhance deduction and spatial grounding. In addition, we redesign the grasping pipeline to be more context-aware by generating grasp candidates from the global scene point cloud and subsequently filtering them using instruction-conditioned affordance masks. Extensive experiments demonstrate that AffordanceGrasp-R1 consistently outperforms state-of-the-art (SOTA) methods on benchmark datasets, and real-world robotic grasping evaluations further validate its robustness and generalization under complex language-conditioned manipulation scenarios.", "AI": {"tldr": "提出了一种结合推理和强化学习的机器人抓取框架AffordanceGrasp-R1，用于改进机器人在复杂语言条件下抓取任务的表现。", "motivation": "为了提高机器人在复杂环境中的抓取能力以及增强对指令条件下的操作场景理解，引入了基于推理的方法来提升分割准确性和空间定位。", "method": "设计了一种新的抓取管道，利用全局点云生成候选抓取位置，并通过指令调节的可及性掩码进行过滤；同时使用强化学习和冷启动策略结合链式思考方法以增强推断能力。", "result": "在基准数据集上的实验表明，AffordanceGrasp-R1的表现优于现有的最先进技术；现实世界中的机器人测试进一步验证了其鲁棒性和泛化能力。", "conclusion": "通过引入推理驱动的可及性分割框架并结合强化学习策略，显著提升了机器人在复杂语言条件下的抓取性能和可靠性。"}}
{"id": "2602.03546", "pdf": "https://arxiv.org/pdf/2602.03546", "abs": "https://arxiv.org/abs/2602.03546", "authors": ["Jonathan Lin", "Aman Desai", "Frank Barrows", "Francesco Caravelli"], "title": "How to Train Your Resistive Network: Generalized Equilibrium Propagation and Analytical Learning", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.mes-hall", "cond-mat.soft", "cs.ET"], "comment": "8 pages double column; plus 16 supp mat.;", "summary": "Machine learning is a powerful method of extracting meaning from data; unfortunately, current digital hardware is extremely energy-intensive. There is interest in an alternative analog computing implementation that could match the performance of traditional machine learning while being significantly more energy-efficient. However, it remains unclear how to train such analog computing systems while adhering to locality constraints imposed by the physical (as opposed to digital) nature of these systems. Local learning algorithms such as Equilibrium Propagation and Coupled Learning have been proposed to address this issue. In this paper, we develop an algorithm to exactly calculate gradients using a graph theoretic and analytical framework for Kirchhoff's laws. We also introduce Generalized Equilibrium Propagation, a framework encompassing a broad class of Hebbian learning algorithms, including Coupled Learning and Equilibrium Propagation, and show how our algorithm compares. We demonstrate our algorithm using numerical simulations and show that we can train resistor networks without the need for a replica or readout over all resistors, only at the output layer. We also show that under the analytical gradient approach, it is possible to update only a subset of the resistance values without a strong degradation in performance.", "AI": {"tldr": "本文开发了一种精确计算梯度的算法，适用于模拟计算系统中的电阻网络训练。", "motivation": "当前数字硬件在处理机器学习任务时能耗极高。需要一种更节能的替代方案——即通过物理性质实现的能量密集型模拟计算来匹配传统机器学习性能。", "method": "提出了一种基于图论和分析框架下的基尔霍夫定律计算梯度的方法，并引入了广义平衡传播，这是一种包含赫布学习算法广泛类别（如耦合学习和平衡传播）的理论框架。", "result": "通过数值模拟展示了可以在输出层直接训练电阻网络而无需额外复制品或读出所有电阻值。同时，在分析梯度方法下，仅更新部分阻抗值也能保持性能不严重下降。", "conclusion": "研究成功开发了适用于模拟计算系统的有效学习算法，并在能耗效率与准确率之间找到了平衡点。"}}
{"id": "2602.03545", "pdf": "https://arxiv.org/pdf/2602.03545", "abs": "https://arxiv.org/abs/2602.03545", "authors": ["Davide Paglieri", "Logan Cross", "William A. Cunningham", "Joel Z. Leibo", "Alexander Sasha Vezhnevets"], "title": "Persona Generators: Generating Diverse Synthetic Personas at Scale", "categories": ["cs.AI"], "comment": null, "summary": "Evaluating AI systems that interact with humans requires understanding their behavior across diverse user populations, but collecting representative human data is often expensive or infeasible, particularly for novel technologies or hypothetical future scenarios. Recent work in Generative Agent-Based Modeling has shown that large language models can simulate human-like synthetic personas with high fidelity, accurately reproducing the beliefs and behaviors of specific individuals. However, most approaches require detailed data about target populations and often prioritize density matching (replicating what is most probable) rather than support coverage (spanning what is possible), leaving long-tail behaviors underexplored. We introduce Persona Generators, functions that can produce diverse synthetic populations tailored to arbitrary contexts. We apply an iterative improvement loop based on AlphaEvolve, using large language models as mutation operators to refine our Persona Generator code over hundreds of iterations. The optimization process produces lightweight Persona Generators that can automatically expand small descriptions into populations of diverse synthetic personas that maximize coverage of opinions and preferences along relevant diversity axes. We demonstrate that evolved generators substantially outperform existing baselines across six diversity metrics on held-out contexts, producing populations that span rare trait combinations difficult to achieve in standard LLM outputs.", "AI": {"tldr": "本文介绍了Persona Generators，一种可以生成多样化的合成人格的方法。", "motivation": "为了评估与人类交互的AI系统的性能，需要了解其在各种用户群体中的行为表现。然而，收集具有代表性的数据通常成本高昂或不可行，特别是对于新技术或未来场景。", "method": "通过基于AlphaEvolve的迭代改进循环和大规模语言模型作为变异操作符来优化Persona Generator代码，从而生成轻量级的Persona Generators，能够将简短描述扩展为覆盖各种意见和偏好的合成人群。", "result": "与现有基线相比，在六个多样性指标上表现更优，特别是在标准LLM输出难以涵盖的罕见特征组合方面取得了重大突破。", "conclusion": "本文提出的方法可以生成多样化的人格模型，适用于不同场景，并在多种多样性度量中显著优于现有方法。"}}
{"id": "2602.03544", "pdf": "https://arxiv.org/pdf/2602.03544", "abs": "https://arxiv.org/abs/2602.03544", "authors": ["Nicolas Leins", "Jana Gonnermann-Müller", "Malte Teichmann", "Sebastian Pokutta"], "title": "Investigating the Influence of Spatial Ability in Augmented Reality-assisted Robot Programming", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Augmented Reality (AR) offers promising opportunities to enhance learning, but its mechanisms and effects are not yet fully understood. As learning becomes increasingly personalized, considering individual learner characteristics becomes more important. This study investigates the moderating effect of spatial ability on learning experience with AR in the context of robot programming. A between-subjects experiment ($N=71$) compared conventional robot programming to an AR-assisted approach using a head-mounted display. Participants' spatial ability was assessed using the Mental Rotation Test. The learning experience was measured through the System Usability Scale (SUS) and cognitive load. The results indicate that AR support does not significantly improve the learning experience compared to the conventional approach. However, AR appears to have a compensatory effect on the influence of spatial ability. In the control group, spatial ability was significantly positively associated with SUS scores and negatively associated with extraneous cognitive load, indicating that higher spatial ability predicts a better learning experience. In the AR condition, these relationships were not observable, suggesting that AR mitigated the disadvantage typically experienced by learners with lower spatial abilities. These findings suggest that AR can serve a compensatory function by reducing the influence of learner characteristics. Future research should further explore this compensatory role of AR to guide the design of personalized learning environments that address diverse learner needs and reduce barriers for learners with varying cognitive profiles.", "AI": {"tldr": "研究探讨了空间能力在增强现实辅助机器人编程中的作用。", "motivation": "了解AR如何影响学习体验，特别是在考虑个体学习者特征时的重要性。", "method": "通过对照实验（N=71）比较传统机器人编程与AR辅助方法的效果。参与者的空间能力使用心理旋转测试评估，而学习体验则通过系统可用性量表和认知负荷衡量。", "result": "结果显示AR并不显著改善学习体验，但似乎对空间能力的影响具有补偿作用：在对照组中，较高的空间能力与较好的学习体验相关，在AR条件下这种关系不再明显。", "conclusion": "研究结果表明AR可以减少不同认知特征的学习者之间的差距。未来应进一步探索AR的这一功能以设计个性化学习环境"}}
{"id": "2602.03541", "pdf": "https://arxiv.org/pdf/2602.03541", "abs": "https://arxiv.org/abs/2602.03541", "authors": ["Qiankun Zhong", "Thomas F. Eisenmann", "Julian Garcia", "Iyad Rahwan"], "title": "Group Selection as a Safeguard Against AI Substitution", "categories": ["cs.AI", "econ.TH"], "comment": "19 pages, 7 Figures", "summary": "Reliance on generative AI can reduce cultural variance and diversity, especially in creative work. This reduction in variance has already led to problems in model performance, including model collapse and hallucination. In this paper, we examine the long-term consequences of AI use for human cultural evolution and the conditions under which widespread AI use may lead to \"cultural collapse\", a process in which reliance on AI-generated content reduces human variation and innovation and slows cumulative cultural evolution. Using an agent-based model and evolutionary game theory, we compare two types of AI use: complement and substitute. AI-complement users seek suggestions and guidance while remaining the main producers of the final output, whereas AI-substitute users provide minimal input, and rely on AI to produce most of the output. We then study how these use strategies compete and spread under evolutionary dynamics. We find that AI-substitute users prevail under individual-level selection despite the stronger reduction in cultural variance. By contrast, AI-complement users can benefit their groups by maintaining the variance needed for exploration, and can therefore be favored under cultural group selection when group boundaries are strong. Overall, our findings shed light on the long-term, population-level effects of AI adoption and inform policy and organizational strategies to mitigate these risks.", "AI": {"tldr": "研究探讨了AI在人类文化演变中的长期影响，特别是不同使用策略（互补和替代）如何通过进化动态竞争与传播。", "motivation": "减少对人工智能的依赖可以降低因过度依靠生成性AI而造成的文化和多样性丧失问题，以及由此导致的文化坍塌的风险。", "method": "采用基于代理模型和演化博弈理论来比较两种类型的AI使用策略：互补策略（寻求建议并主要生产最终输出）与替代策略（提供极少输入，让AI生成大部分内容）。", "result": "研究发现，在个体选择下，AI替代用户占优势；然而在群体选择中，AI互补用户通过保持探索所需的变异性而有益于其群体。", "conclusion": "总体而言，研究结果揭示了人工智能采用的长期、人口层面的影响，并为制定政策和组织策略以减轻这些风险提供了参考。"}}
{"id": "2602.03538", "pdf": "https://arxiv.org/pdf/2602.03538", "abs": "https://arxiv.org/abs/2602.03538", "authors": ["Zihan Zheng", "Zhenglong Wu", "Xuanxuan Wang", "Houqiang Zhong", "Xiaoyun Zhang", "Qiang Hu", "Guangtao Zhai", "Wenjun Zhang"], "title": "Constrained Dynamic Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "While Dynamic Gaussian Splatting enables high-fidelity 4D reconstruction, its deployment is severely hindered by a fundamental dilemma: unconstrained densification leads to excessive memory consumption incompatible with edge devices, whereas heuristic pruning fails to achieve optimal rendering quality under preset Gaussian budgets. In this work, we propose Constrained Dynamic Gaussian Splatting (CDGS), a novel framework that formulates dynamic scene reconstruction as a budget-constrained optimization problem to enforce a strict, user-defined Gaussian budget during training. Our key insight is to introduce a differentiable budget controller as the core optimization driver. Guided by a multi-modal unified importance score, this controller fuses geometric, motion, and perceptual cues for precise capacity regulation. To maximize the utility of this fixed budget, we further decouple the optimization of static and dynamic elements, employing an adaptive allocation mechanism that dynamically distributes capacity based on motion complexity. Furthermore, we implement a three-phase training strategy to seamlessly integrate these constraints, ensuring precise adherence to the target count. Coupled with a dual-mode hybrid compression scheme, CDGS not only strictly adheres to hardware constraints (error < 2%}) but also pushes the Pareto frontier of rate-distortion performance. Extensive experiments demonstrate that CDGS delivers optimal rendering quality under varying capacity limits, achieving over 3x compression compared to state-of-the-art methods.", "AI": {"tldr": "提出了一种预算约束的动态高斯点阵框架，解决4D重建中的内存消耗和渲染质量之间的矛盾问题。", "motivation": "Dynamic Gaussian Splatting在部署时面临内存消耗过大及渲染质量不高的挑战，通过引入一种新颖的优化策略来平衡这些限制。", "method": "提出了Constrained Dynamic Gaussian Splatting（CDGS）框架，该框架利用可微预算控制器结合几何、运动和感知线索进行精确容量控制，并采用双模式混合压缩方案以满足硬件约束。训练过程分为三阶段：初始化、融合及调整。", "result": "CDGS在各种容量限制下均能实现最佳渲染质量，并且与最先进的方法相比，实现了超过3倍的压缩率。", "conclusion": "通过严格的预算控制和优化策略，CDGS不仅能够适应边缘设备的要求，还能显著提高4D重建的质量和效率。"}}
{"id": "2602.03533", "pdf": "https://arxiv.org/pdf/2602.03533", "abs": "https://arxiv.org/abs/2602.03533", "authors": ["Yongwei Chen", "Tianyi Wei", "Yushi Lan", "Zhaoyang Lyu", "Shangchen Zhou", "Xudong Xu", "Xingang Pan"], "title": "PnP-U3D: Plug-and-Play 3D Framework Bridging Autoregression and Diffusion for Unified Understanding and Generation", "categories": ["cs.CV"], "comment": "Yongwei Chen and Tianyi Wei contributed equally. Project page: https://cyw-3d.github.io/PnP-U3D/", "summary": "The rapid progress of large multimodal models has inspired efforts toward unified frameworks that couple understanding and generation. While such paradigms have shown remarkable success in 2D, extending them to 3D remains largely underexplored. Existing attempts to unify 3D tasks under a single autoregressive (AR) paradigm lead to significant performance degradation due to forced signal quantization and prohibitive training cost. Our key insight is that the essential challenge lies not in enforcing a unified autoregressive paradigm, but in enabling effective information interaction between generation and understanding while minimally compromising their inherent capabilities and leveraging pretrained models to reduce training cost. Guided by this perspective, we present the first unified framework for 3D understanding and generation that combines autoregression with diffusion. Specifically, we adopt an autoregressive next-token prediction paradigm for 3D understanding, and a continuous diffusion paradigm for 3D generation. A lightweight transformer bridges the feature space of large language models and the conditional space of 3D diffusion models, enabling effective cross-modal information exchange while preserving the priors learned by standalone models. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across diverse 3D understanding and generation benchmarks, while also excelling in 3D editing tasks. These results highlight the potential of unified AR+diffusion models as a promising direction for building more general-purpose 3D intelligence.", "AI": {"tldr": "本文提出了一个结合自回归和扩散的统一框架PnP-U3D，用于3D理解和生成任务。", "motivation": "现有的统一3D任务的框架在扩展到3D时性能下降，因为强制信号量化且训练成本高。作者认为关键在于有效交换生成与理解之间的信息，并保持各自的能力，同时利用预训练模型降低成本。", "method": "该方法采用自回归预测范式进行3D理解和扩散模式进行3D生成。使用轻量级的变压器连接大型语言模型和条件空间的3D扩散模型，实现跨模态信息交换的同时保留单独模型学到的先验知识。", "result": "实验表明，PnP-U3D在广泛的3D理解、生成以及编辑任务中达到了最先进的性能。", "conclusion": "研究展示了结合自回归与扩散模型作为构建更通用3D智能方向的巨大潜力。"}}
{"id": "2602.03531", "pdf": "https://arxiv.org/pdf/2602.03531", "abs": "https://arxiv.org/abs/2602.03531", "authors": ["Anika Shrivastava", "Renu Rameshan", "Samar Agnihotri"], "title": "Robust Representation Learning in Masked Autoencoders", "categories": ["cs.LG", "cs.CV"], "comment": "11 pages, 8 figures, and 3 tables", "summary": "Masked Autoencoders (MAEs) achieve impressive performance in image classification tasks, yet the internal representations they learn remain less understood. This work started as an attempt to understand the strong downstream classification performance of MAE. In this process we discover that representations learned with the pretraining and fine-tuning, are quite robust - demonstrating a good classification performance in the presence of degradations, such as blur and occlusions. Through layer-wise analysis of token embeddings, we show that pretrained MAE progressively constructs its latent space in a class-aware manner across network depth: embeddings from different classes lie in subspaces that become increasingly separable. We further observe that MAE exhibits early and persistent global attention across encoder layers, in contrast to standard Vision Transformers (ViTs). To quantify feature robustness, we introduce two sensitivity indicators: directional alignment between clean and perturbed embeddings, and head-wise retention of active features under degradations. These studies help establish the robust classification performance of MAEs.", "AI": {"tldr": "研究在掩码自动编码器（MAE）中学习的表示方法及其鲁棒性。", "motivation": "理解掩码自动编码器在图像分类任务中的强下游性能背后的机制。", "method": "通过分析预训练和微调过程中学到的表示，展示其对降质如模糊和遮挡具有良好的分类性能。引入两个敏感度指标以量化特征鲁棒性：清洁与扰动嵌入的方向一致性，以及在降质下主动特征的头部保留情况。", "result": "发现MAE预训练过程中的潜空间构建是类别的意识渐进性的，并且其全局注意力在编码层中表现出早发性和持久性。", "conclusion": "掩码自动编码器（MAE）在图像分类任务上具有良好的鲁棒性能，通过逐步构造类别感知的潜在空间和早期持续的全局注意力机制来实现。"}}
{"id": "2602.03530", "pdf": "https://arxiv.org/pdf/2602.03530", "abs": "https://arxiv.org/abs/2602.03530", "authors": ["Xufei Zhang", "Xinjiao Zhou", "Ziling Deng", "Dongdong Geng", "Jianxiong Wang"], "title": "Interpretable Logical Anomaly Classification via Constraint Decomposition and Instruction Fine-Tuning", "categories": ["cs.CV"], "comment": "6 pages, 6 figures", "summary": "Logical anomalies are violations of predefined constraints on object quantity, spatial layout, and compositional relationships in industrial images. While prior work largely treats anomaly detection as a binary decision, such formulations cannot indicate which logical rule is broken and therefore offer limited value for quality assurance. We introduce Logical Anomaly Classification (LAC), a task that unifies anomaly detection and fine-grained violation classification in a single inference step. To tackle LAC, we propose LogiCls, a vision-language framework that decomposes complex logical constraints into a sequence of verifiable subqueries. We further present a data-centric instruction synthesis pipeline that generates chain-of-thought (CoT) supervision for these subqueries, coupling precise grounding annotations with diverse image-text augmentations to adapt vision language models (VLMs) to logic-sensitive reasoning. Training is stabilized by a difficulty-aware resampling strategy that emphasizes challenging subqueries and long tail constraint types. Extensive experiments demonstrate that LogiCls delivers robust, interpretable, and accurate industrial logical anomaly classification, providing both the predicted violation categories and their evidence trails.", "AI": {"tldr": "本文提出了LogiCls框架，用于工业图像中的逻辑异常分类任务。该框架将复杂的逻辑约束分解为可验证的子查询，并通过数据为中心的指令合成管道生成链式思考监督。", "motivation": "先前的工作大多将异常检测视为二元决策问题，不能指出违反的具体逻辑规则，这限制了其在质量保证中的价值。因此，本文旨在同时解决异常检测和细粒度违规分类的问题。", "method": "LogiCls框架通过分解复杂逻辑约束为子查询序列，并采用链式思考监督生成方法进行训练，结合精确的标注和图像文本增强来适应视觉语言模型（VLM）的逻辑敏感推理。使用难度感知重采样策略稳定训练过程。", "result": "实验结果表明，LogiCls框架能够提供准确、可解释且稳健的工业逻辑异常分类，并输出违反的具体类别及其证据路径。", "conclusion": "本文提出了一种新的任务和方法来解决逻辑异常检测问题，实现了细粒度违规分类并提供了可解释性。"}}
{"id": "2602.03529", "pdf": "https://arxiv.org/pdf/2602.03529", "abs": "https://arxiv.org/abs/2602.03529", "authors": ["Tianyi Gong", "Zijian Cao", "Zixing Zhang", "Jiangkai Wu", "Xinggong Zhang", "Shuguang Cui", "Fangxin Wang"], "title": "Morphe: High-Fidelity Generative Video Streaming with Vision Foundation Model", "categories": ["cs.NI", "cs.AI", "cs.MM"], "comment": "Accepted by NSDI 2026 Fall", "summary": "Video streaming is a fundamental Internet service, while the quality still cannot be guaranteed especially in poor network conditions such as bandwidth-constrained and remote areas. Existing works mainly work towards two directions: traditional pixel-codec streaming nearly approaches its limit and is hard to step further in compression; the emerging neural-enhanced or generative streaming usually fall short in latency and visual fidelity, hindering their practical deployment. Inspired by the recent success of vision foundation model (VFM), we strive to harness the powerful video understanding and processing capacities of VFM to achieve generalization, high fidelity and loss resilience for real-time video streaming with even higher compression rate. We present the first revolutionized paradigm that enables VFM-based end-to-end generative video streaming towards this goal. Specifically, Morphe employs joint training of visual tokenizers and variable-resolution spatiotemporal optimization under simulated network constraints. Additionally, a robust streaming system is constructed that leverages intelligent packet dropping to resist real-world network perturbations. Extensive evaluation demonstrates that Morphe achieves comparable visual quality while saving 62.5\\% bandwidth compared to H.265, and accomplishes real-time, loss-resilient video delivery in challenging network environments, representing a milestone in VFM-enabled multimedia streaming solutions.", "AI": {"tldr": "Morphe提出了基于视觉基础模型的端到端生成视频流媒体技术，旨在提高视频质量并减少带宽需求。", "motivation": "现有的视频流媒体方法在带宽受限和偏远地区难以保证视频质量。该研究通过利用视觉基础模型来解决这些问题，并实现更高压缩率下的实时、抗丢包视频传输。", "method": "Morphe采用联合训练的视觉令牌器以及模拟网络限制条件下的可变分辨率时空优化，构建了基于智能分组丢弃技术的鲁棒流媒体系统。", "result": "实验结果显示，与H.265相比，Morphe在节省62.5％带宽的同时实现了可比的视频质量，并且能够在挑战性网络环境下完成实时、抗丢包的视频传输。", "conclusion": "该研究代表了基于视觉基础模型的多媒体流媒体解决方案的一个里程碑。"}}
{"id": "2602.03525", "pdf": "https://arxiv.org/pdf/2602.03525", "abs": "https://arxiv.org/abs/2602.03525", "authors": ["Antoine Limasset"], "title": "ZOR filters: fast and smaller than fuse filters", "categories": ["cs.DS"], "comment": null, "summary": "Probabilistic membership filters support fast approximate membership queries with a controlled false-positive probability $\\varepsilon$ and are widely used across storage, analytics, networking, and bioinformatics \\cite{chang2008bigtable,dayan2018optimalbloom,broder2004network,harris2020improved,marchet2023scalable,chikhi2025logan,hernandez2025reindeer2}. In the static setting, state-of-the-art designs such as XOR and fuse filters achieve low overhead and very fast queries, but their peeling-based construction succeeds only with high probability, which complicates deterministic builds \\cite{graf2020xor,graf2022binary,ulrich2023taxor}. We introduce \\emph{ZOR filters}, a deterministic continuation of XOR/fuse filters that guarantees construction termination while preserving the same XOR-based query mechanism. ZOR replaces restart-on-failure with deterministic peeling that abandons a small fraction of keys, and restores false-positive-only semantics by storing the remainder in a compact auxiliary structure. In our experiments, the abandoned fraction drops below $1\\%$ for moderate arity (e.g., $N\\ge 5$), so the auxiliary handles a negligible fraction of keys. As a result, ZOR filters can achieve overhead within $1\\%$ of the information-theoretic lower bound $\\log_2(1/\\varepsilon)$ while retaining fuse-like query performance; the additional cost is concentrated on negative queries due to the auxiliary check. Our current prototype builds several-fold slower than highly optimized fuse builders because it maintains explicit incidence information during deterministic peeling; closing this optimisation gap is an engineering target.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.03523", "pdf": "https://arxiv.org/pdf/2602.03523", "abs": "https://arxiv.org/abs/2602.03523", "authors": ["Eunjin Choi", "Hounsu Kim", "Hayeon Bang", "Taegyun Kwon", "Juhan Nam"], "title": "D3PIA: A Discrete Denoising Diffusion Model for Piano Accompaniment Generation From Lead sheet", "categories": ["cs.SD", "cs.AI", "cs.MM"], "comment": "Accepted at 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)", "summary": "Generating piano accompaniments in the symbolic music domain is a challenging task that requires producing a complete piece of piano music from given melody and chord constraints, such as those provided by a lead sheet. In this paper, we propose a discrete diffusion-based piano accompaniment generation model, D3PIA, leveraging local alignment between lead sheet and accompaniment in piano-roll representation. D3PIA incorporates Neighborhood Attention (NA) to both encode the lead sheet and condition it for predicting note states in the piano accompaniment. This design enhances local contextual modeling by efficiently attending to nearby melody and chord conditions. We evaluate our model using the POP909 dataset, a widely used benchmark for piano accompaniment generation. Objective evaluation results demonstrate that D3PIA preserves chord conditions more faithfully compared to continuous diffusion-based and Transformer-based baselines. Furthermore, a subjective listening test indicates that D3PIA generates more musically coherent accompaniments than the comparison models.", "AI": {"tldr": "该论文提出了一种基于离散扩散的钢琴伴奏生成模型D3PIA，从给定的旋律和和弦约束中生成完整的钢琴音乐。", "motivation": "生成符合旋律和和弦条件的钢琴伴奏是一项挑战性的任务，需要利用乐谱中的信息进行高效建模。因此，论文提出了一种新的方法来提高伴奏质量并保持和弦的一致性。", "method": "D3PIA模型使用局部对齐策略将乐谱与伴奏在钢琴卷表示中联系起来，并通过引入邻域注意机制有效地处理附近旋律和和弦条件，以进行更准确的预测。", "result": "实验结果表明，相比连续扩散和基于Transformer的方法，D3PIA能够在客观评价中更好地保留和弦条件，并且主观听评结果显示生成的伴奏更加和谐一致。", "conclusion": "论文成功提出了一种新的离散扩散模型D3PIA来解决钢琴伴奏生成问题，提高了音乐的一致性和质量。"}}
{"id": "2602.03520", "pdf": "https://arxiv.org/pdf/2602.03520", "abs": "https://arxiv.org/abs/2602.03520", "authors": ["Yiran Qiao", "Jing Chen", "Xiang Ao", "Qiwei Zhong", "Yang Liu", "Qing He"], "title": "Live or Lie: Action-Aware Capsule Multiple Instance Learning for Risk Assessment in Live Streaming Platforms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Live streaming has become a cornerstone of today's internet, enabling massive real-time social interactions. However, it faces severe risks arising from sparse, coordinated malicious behaviors among multiple participants, which are often concealed within normal activities and challenging to detect timely and accurately. In this work, we provide a pioneering study on risk assessment in live streaming rooms, characterized by weak supervision where only room-level labels are available. We formulate the task as a Multiple Instance Learning (MIL) problem, treating each room as a bag and defining structured user-timeslot capsules as instances. These capsules represent subsequences of user actions within specific time windows, encapsulating localized behavioral patterns. Based on this formulation, we propose AC-MIL, an Action-aware Capsule MIL framework that models both individual behaviors and group-level coordination patterns. AC-MIL captures multi-granular semantics and behavioral cues through a serial and parallel architecture that jointly encodes temporal dynamics and cross-user dependencies. These signals are integrated for robust room-level risk prediction, while also offering interpretable evidence at the behavior segment level. Extensive experiments on large-scale industrial datasets from Douyin demonstrate that AC-MIL significantly outperforms MIL and sequential baselines, establishing new state-of-the-art performance in room-level risk assessment for live streaming. Moreover, AC-MIL provides capsule-level interpretability, enabling identification of risky behavior segments as actionable evidence for intervention. The project page is available at: https://qiaoyran.github.io/AC-MIL/.", "AI": {"tldr": "该论文提出了一种用于直播平台风险评估的AC-MIL框架，通过结构化的用户时隙胶囊来捕捉个体行为和群体协调模式。", "motivation": "为了应对直播平台上由多参与者协同产生的稀疏恶意行为所带来的挑战，作者提出了一个弱监督下的行动感知胶囊多重实例学习方法（AC-MIL），以实现风险评估。", "method": "该论文将问题定义为多重实例学习任务，并提出了一种序列和并行架构来编码时间动态性和跨用户依赖性。每个房间被看作是一个包，而结构化的用户时隙胶囊则是其中的实例。", "result": "实验表明，在大规模工业数据集上，AC-MIL方法在直播房间级别的风险评估中显著优于其他多重实例学习和序列基线方法。", "conclusion": "该论文提出了一种能够捕捉多粒度语义和行为线索的方法，并提供了胶囊级别可解释性，有助于识别危险的行为片段作为干预的证据。"}}
{"id": "2602.03516", "pdf": "https://arxiv.org/pdf/2602.03516", "abs": "https://arxiv.org/abs/2602.03516", "authors": ["Zixiang Di", "Jinyi Han", "Shuo Zhang", "Ying Liao", "Zhi Li", "Xiaofeng Ji", "Yongqi Wang", "Zheming Yang", "Ming Gao", "Bingdong Li", "Jie Wang"], "title": "Not All Negative Samples Are Equal: LLMs Learn Better from Plausible Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning from negative samples holds great promise for improving Large Language Model (LLM) reasoning capability, yet existing methods treat all incorrect responses as equally informative, overlooking the crucial role of sample quality. To address this, we propose Plausible Negative Samples (PNS), a method that synthesizes high-quality negative samples exhibiting expected format and structural coherence while ultimately yielding incorrect answers. PNS trains a dedicated model via reverse reinforcement learning (RL) guided by a composite reward combining format compliance, accuracy inversion, reward model assessment, and chain-of-thought evaluation, generating responses nearly indistinguishable from correct solutions. We further validate PNS as a plug-and-play data source for preference optimization across three backbone models on seven mathematical reasoning benchmarks. Results demonstrate that PNS consistently outperforms other negative sample synthesis methods, achieving an average improvement of 2.03% over RL-trained models.", "AI": {"tldr": "本文提出了一种生成高质量负样本的方法PNS，用于改进大型语言模型的推理能力。", "motivation": "现有的方法将所有错误答案视为同样具有信息量，忽略了样本质量的重要性。本文旨在通过合成高质素的负样本来解决这一问题。", "method": "利用反向强化学习训练专门模型，生成格式一致、结构连贯且最终给出错误答案的高质量负样本。采用复合奖励机制结合格式一致性、准确性反转、奖励模型评估及思考链评价指导生成过程。", "result": "PNS在三个骨干模型上七个数学推理基准测试中表现优异，平均提升了2.03%。", "conclusion": "PNS作为一种即插即用的数据源，在偏好优化方面优于其他负样本合成方法。"}}
{"id": "2602.03515", "pdf": "https://arxiv.org/pdf/2602.03515", "abs": "https://arxiv.org/abs/2602.03515", "authors": ["Hyunji Jung", "Sungbin Shin", "Namhoon Lee"], "title": "Mitigating Staleness in Asynchronous Pipeline Parallelism via Basis Rotation", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "Preprint. Under review", "summary": "Asynchronous pipeline parallelism maximizes hardware utilization by eliminating the pipeline bubbles inherent in synchronous execution, offering a path toward efficient large-scale distributed training. However, this efficiency gain can be compromised by gradient staleness, where the immediate model updates with delayed gradients introduce noise into the optimization process. Crucially, we identify a critical, yet often overlooked, pathology: this delay scales linearly with pipeline depth, fundamentally undermining the very scalability that the method originally intends to provide. In this work, we investigate this inconsistency and bridge the gap by rectifying delayed gradients through basis rotation, restoring scalable asynchronous training while maintaining performance. Specifically, we observe that the deleterious effects of delayed gradients are exacerbated when the Hessian eigenbasis is misaligned with the standard coordinate basis. We demonstrate that this misalignment prevents coordinate-wise adaptive schemes, such as Adam, from effectively leveraging curvature-aware adaptivity. This failure leads to significant oscillations in the optimization trajectory and, consequently, slower convergence. We substantiate these findings through both rigorous theoretical analysis and empirical evaluation. To address this challenge, we propose the use of basis rotation, demonstrating that it effectively mitigates the alignment issue and significantly accelerates convergence in asynchronous settings. For example, our training of a 1B-parameter LLM with basis rotation achieves the same training loss in 76.8% fewer iterations compared to the best-performing asynchronous pipeline parallel training baseline.", "AI": {"tldr": "论文提出了通过基础旋转来缓解异步管道并行中的梯度滞后问题，从而提高大规模分布式训练的效率。", "motivation": "异步管道并行能有效利用硬件资源，但随着管道深度增加，延迟性导致的梯度不一致问题会严重影响优化过程和模型性能。", "method": "提出使用基础旋转技术来解决由于海森矩阵特征基与标准坐标系基错位造成的适应性失效问题，以此减少优化轨迹中的振荡并加快收敛速度。", "result": "实验表明，该方法能够显著加速异步设置下的收敛过程，在训练一个10亿参数的大语言模型时，比最佳的异步管道并行基础线少76.8%的迭代次数即可达到相同的训练损失。", "conclusion": "论文证明了通过合理旋转基底可以有效缓解梯度滞后问题，并为大规模分布式训练提供了新的优化策略。"}}
{"id": "2602.03511", "pdf": "https://arxiv.org/pdf/2602.03511", "abs": "https://arxiv.org/abs/2602.03511", "authors": ["Qixin Zeng", "Hongyin Zhang", "Shangke Lyu", "Junxi Jin", "Donglin Wang", "Chao Huang"], "title": "CMR: Contractive Mapping Embeddings for Robust Humanoid Locomotion on Unstructured Terrains", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Robust disturbance rejection remains a longstanding challenge in humanoid locomotion, particularly on unstructured terrains where sensing is unreliable and model mismatch is pronounced. While perception information, such as height map, enhances terrain awareness, sensor noise and sim-to-real gaps can destabilize policies in practice. In this work, we provide theoretical analysis that bounds the return gap under observation noise, when the induced latent dynamics are contractive. Furthermore, we present Contractive Mapping for Robustness (CMR) framework that maps high-dimensional, disturbance-prone observations into a latent space, where local perturbations are attenuated over time. Specifically, this approach couples contrastive representation learning with Lipschitz regularization to preserve task-relevant geometry while explicitly controlling sensitivity. Notably, the formulation can be incorporated into modern deep reinforcement learning pipelines as an auxiliary loss term with minimal additional technical effort required. Further, our extensive humanoid experiments show that CMR potently outperforms other locomotion algorithms under increased noise.", "AI": {"tldr": "提出一种稳健的人形机器人行走框架CMR，用于在不规则地形上进行稳定行走。", "motivation": "提高人形机器人在不可靠感知和模型偏差大的不规则地形上的稳定性。", "method": "将高维扰动观测映射到局部波动被抑制的潜在空间中，并通过对比性表示学习和Lipschitz正则化来控制敏感度。", "result": "实验表明，CMR在噪声增加的情况下显著优于其他行走算法。", "conclusion": "CMR框架可以在现代深度强化学习管道作为辅助损失项集成使用，提高人形机器人在不规则地形上的稳定性。"}}
{"id": "2602.03510", "pdf": "https://arxiv.org/pdf/2602.03510", "abs": "https://arxiv.org/abs/2602.03510", "authors": ["Bozhou Li", "Yushuo Guan", "Haolin Li", "Bohan Zeng", "Yiyan Ji", "Yue Ding", "Pengfei Wan", "Kun Gai", "Yuanxing Zhang", "Wentao Zhang"], "title": "Semantic Routing: Exploring Multi-Layer LLM Feature Weighting for Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Recent DiT-based text-to-image models increasingly adopt LLMs as text encoders, yet text conditioning remains largely static and often utilizes only a single LLM layer, despite pronounced semantic hierarchy across LLM layers and non-stationary denoising dynamics over both diffusion time and network depth. To better match the dynamic process of DiT generation and thereby enhance the diffusion model's generative capability, we introduce a unified normalized convex fusion framework equipped with lightweight gates to systematically organize multi-layer LLM hidden states via time-wise, depth-wise, and joint fusion. Experiments establish Depth-wise Semantic Routing as the superior conditioning strategy, consistently improving text-image alignment and compositional generation (e.g., +9.97 on the GenAI-Bench Counting task). Conversely, we find that purely time-wise fusion can paradoxically degrade visual generation fidelity. We attribute this to a train-inference trajectory mismatch: under classifier-free guidance, nominal timesteps fail to track the effective SNR, causing semantically mistimed feature injection during inference. Overall, our results position depth-wise routing as a strong and effective baseline and highlight the critical need for trajectory-aware signals to enable robust time-dependent conditioning.", "AI": {"tldr": "本文提出了一个统一的标准化凸融合框架，通过时间维度、深度维度和联合融合来组织多层LLM隐藏状态，以提升DiT模型的文字图像对齐能力。", "motivation": "现有DiT文本到图像模型采用单一LLM层作为文字编码器，但忽略了语义层次性和非平稳去噪动态。为了更好地匹配DiT生成过程并提高生成性能，引入了深度维度语义路由策略。", "method": "提出了一种统一的标准化凸融合框架，并使用轻量级门控机制来组织多层LLM隐藏状态，在时间、深度和联合融合方面进行了系统化处理。", "result": "实验结果表明，深度维度语义路由是最优条件策略，能够显著提高文本图像对齐能力与组合生成任务（如+9.97在GenAI-Bench计数任务上）的表现。同时发现仅使用时间维融合会导致视觉生成保真度下降。", "conclusion": "研究结果表明深度维度路由是一种强大的基线方法，并强调了需要具有轨迹意识的信号以实现稳健的时间依赖条件处理"}}
{"id": "2602.03506", "pdf": "https://arxiv.org/pdf/2602.03506", "abs": "https://arxiv.org/abs/2602.03506", "authors": ["Arco van Breda", "Erman Acar"], "title": "Explaining the Explainer: Understanding the Inner Workings of Transformer-based Symbolic Regression Models", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 5 figures", "summary": "Following their success across many domains, transformers have also proven effective for symbolic regression (SR); however, the internal mechanisms underlying their generation of mathematical operators remain largely unexplored. Although mechanistic interpretability has successfully identified circuits in language and vision models, it has not yet been applied to SR. In this article, we introduce PATCHES, an evolutionary circuit discovery algorithm that identifies compact and correct circuits for SR. Using PATCHES, we isolate 28 circuits, providing the first circuit-level characterisation of an SR transformer. We validate these findings through a robust causal evaluation framework based on key notions such as faithfulness, completeness, and minimality. Our analysis shows that mean patching with performance-based evaluation most reliably isolates functionally correct circuits. In contrast, we demonstrate that direct logit attribution and probing classifiers primarily capture correlational features rather than causal ones, limiting their utility for circuit discovery. Overall, these results establish SR as a high-potential application domain for mechanistic interpretability and propose a principled methodology for circuit discovery.", "AI": {"tldr": "该论文介绍了PATCHES算法，用于识别和验证Transformer在符号回归模型中的内部电路。", "motivation": "尽管变压器已成功应用于许多领域，但其生成数学操作符的内部机制尚未被深入研究。为填补这一空白，本文引入了一种新的电路发现算法，并对SR变压器进行了首次电路级别的特性化。", "method": "通过PATCHES算法来识别和验证28个紧凑且正确的电路，该论文提出并应用了基于性能评价的平均修补方法进行因果验证。", "result": "研究结果显示，均值补丁结合性能评估最可靠地隔离出功能上正确的电路。直接对数属性归因和探针分类器主要捕捉到相关特征而非因果特性。", "conclusion": "该论文建立了符号回归作为机制可解释性的高潜力应用领域，并提出了一种基于原则的电路发现方法论。"}}
{"id": "2602.03505", "pdf": "https://arxiv.org/pdf/2602.03505", "abs": "https://arxiv.org/abs/2602.03505", "authors": ["Saeed R. Khosravirad", "Ahmed Alkhateeb", "Ingrid van de Voorde"], "title": "Generative Decompression: Optimal Lossy Decoding Against Distribution Mismatch", "categories": ["cs.IT", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper addresses optimal decoding strategies in lossy compression where the assumed distribution for compressor design mismatches the actual (true) distribution of the source. This problem has immediate relevance in standardized communication systems where the decoder acquires side information or priors about the true distribution that are unavailable to the fixed encoder. We formally define the mismatched quantization problem, demonstrating that the optimal reconstruction rule, termed generative decompression, aligns with classical Bayesian estimation by taking the conditional expectation under the true distribution given the quantization indices and adapting it to fixed-encoder constraints. This strategy effectively performs a generative Bayesian correction on the decoder side, strictly outperforming the conventional centroid rule. We extend this framework to transmission over noisy channels, deriving a robust soft-decoding rule that quantifies the inefficiency of standard modular source--channel separation architectures under mismatch. Furthermore, we generalize the approach to task-oriented decoding, showing that the optimal strategy shifts from conditional mean estimation to maximum a posteriori (MAP) detection. Experimental results on Gaussian sources and deep-learning-based semantic classification demonstrate that generative decompression closes a vast majority of the performance gap to the ideal joint-optimization benchmark, enabling adaptive, high-fidelity reconstruction without modifying the encoder.", "AI": {"tldr": "提出了一种在假设分布与实际源分布不匹配时的最优解码策略，称为生成解压缩。", "motivation": "解决标准化通信系统中的解码器获取侧信息或先验知识而固定编码器不可用的情况下的损失压缩问题。", "method": "定义了不匹配量化问题，并提出了一种基于真实分布和量化的条件期望的优化重构规则。该方法在解码端执行生成贝叶斯校正，优于传统质心法则。进一步扩展到带噪信道传输，推导出鲁棒软解码规则。", "result": "实验表明，对于高斯源和深度学习语义分类任务，生成解压缩策略能显著缩小与理想联合优化基准的性能差距。", "conclusion": "提出的方法能够实现适应性强、保真度高的重建效果，而无需修改编码器。"}}
{"id": "2602.03501", "pdf": "https://arxiv.org/pdf/2602.03501", "abs": "https://arxiv.org/abs/2602.03501", "authors": ["Hai Zhong", "Zhuoran Li", "Xun Wang", "Longbo Huang"], "title": "Reparameterization Flow Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reparameterization Policy Gradient (RPG) has emerged as a powerful paradigm for model-based reinforcement learning, enabling high sample efficiency by backpropagating gradients through differentiable dynamics. However, prior RPG approaches have been predominantly restricted to Gaussian policies, limiting their performance and failing to leverage recent advances in generative models. In this work, we identify that flow policies, which generate actions via differentiable ODE integration, naturally align with the RPG framework, a connection not established in prior work. However, naively exploiting this synergy proves ineffective, often suffering from training instability and a lack of exploration. We propose Reparameterization Flow Policy Optimization (RFO). RFO computes policy gradients by backpropagating jointly through the flow generation process and system dynamics, unlocking high sample efficiency without requiring intractable log-likelihood calculations. RFO includes two tailored regularization terms for stability and exploration. We also propose a variant of RFO with action chunking. Extensive experiments on diverse locomotion and manipulation tasks, involving both rigid and soft bodies with state or visual inputs, demonstrate the effectiveness of RFO. Notably, on a challenging locomotion task controlling a soft-body quadruped, RFO achieves almost $2\\times$ the reward of the state-of-the-art baseline.", "AI": {"tldr": "本文提出了利用再参数化流策略优化(RFO)来提高模型强化学习的样本效率。", "motivation": "现有的Reparameterization Policy Gradient (RPG)方法主要局限于高斯策略，限制了性能并未能充分利用生成模型的进步。因此，提出了一种新的方法以增强样本效率和探索性。", "method": "RFO通过联合反向传播流生成过程和系统动态计算策略梯度，无需进行难以处理的对数似然计算，并引入了两个定制化的正则化项来提高稳定性和探索性。此外，还提出了一种带有动作分块的变体。", "result": "实验结果表明RFO在多种运动和操作任务中表现优异，在控制软体四足动物的复杂运动任务上达到了现有最佳基线两倍以上的回报。", "conclusion": "通过结合流策略和再参数化政策梯度，本文提出的RFO方法显著提高了强化学习中的样本效率，并且展示了广泛的适用性和优越性。"}}
{"id": "2602.03491", "pdf": "https://arxiv.org/pdf/2602.03491", "abs": "https://arxiv.org/abs/2602.03491", "authors": ["Yingjie Zhu", "Xuefeng Bai", "Kehai Chen", "Yang Xiang", "Youcheng Pan", "Xiaoqiang Zhou", "Min Zhang"], "title": "Decoupling Skeleton and Flesh: Efficient Multimodal Table Reasoning with Disentangled Alignment and Structure-aware Guidance", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Reasoning over table images remains challenging for Large Vision-Language Models (LVLMs) due to complex layouts and tightly coupled structure-content information. Existing solutions often depend on expensive supervised training, reinforcement learning, or external tools, limiting efficiency and scalability. This work addresses a key question: how to adapt LVLMs to table reasoning with minimal annotation and no external tools? Specifically, we first introduce DiSCo, a Disentangled Structure-Content alignment framework that explicitly separates structural abstraction from semantic grounding during multimodal alignment, efficiently adapting LVLMs to tables structures. Building on DiSCo, we further present Table-GLS, a Global-to-Local Structure-guided reasoning framework that performs table reasoning via structured exploration and evidence-grounded inference. Extensive experiments across diverse benchmarks demonstrate that our framework efficiently enhances LVLM's table understanding and reasoning capabilities, particularly generalizing to unseen table structures.", "AI": {"tldr": "提出了一种解耦骨架和肉质的方法，用于高效的多模态表格推理。", "motivation": "大型视觉-语言模型处理表格图像时存在复杂布局和结构内容信息紧密结合的问题，现有解决方案依赖昂贵的监督训练或外部工具，效率低且难以扩展。本文旨在探索如何在最少标注和无需外部工具的情况下使LVLM适应表格推理。", "method": "首先引入了DiSCo框架，它通过多模态对齐阶段明确分离结构抽象与语义定位，然后提出了Table-GLS框架，利用全局到局部的结构引导进行表格推理。", "result": "实验表明所提方法能够有效地提升LVLM在处理表格图像时的理解和推理能力，并且对于未见过的表格结构也有很好的泛化性能。", "conclusion": "该研究成功地解决了大型视觉-语言模型处理复杂多模态表格信息时面临的挑战，提高了模型效率并增强了其可扩展性。"}}
{"id": "2602.03486", "pdf": "https://arxiv.org/pdf/2602.03486", "abs": "https://arxiv.org/abs/2602.03486", "authors": ["Elena Umili", "Francesco Argenziano", "Roberto Capobianco"], "title": "DeepDFA: Injecting Temporal Logic in Deep Learning for Sequential Subsymbolic Applications", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Integrating logical knowledge into deep neural network training is still a hard challenge, especially for sequential or temporally extended domains involving subsymbolic observations. To address this problem, we propose DeepDFA, a neurosymbolic framework that integrates high-level temporal logic - expressed as Deterministic Finite Automata (DFA) or Moore Machines - into neural architectures. DeepDFA models temporal rules as continuous, differentiable layers, enabling symbolic knowledge injection into subsymbolic domains. We demonstrate how DeepDFA can be used in two key settings: (i) static image sequence classification, and (ii) policy learning in interactive non-Markovian environments. Across extensive experiments, DeepDFA outperforms traditional deep learning models (e.g., LSTMs, GRUs, Transformers) and novel neuro-symbolic systems, achieving state-of-the-art results in temporal knowledge integration. These results highlight the potential of DeepDFA to bridge subsymbolic learning and symbolic reasoning in sequential tasks.", "AI": {"tldr": "提出一种将高阶时序逻辑注入深度神经网络的新框架DeepDFA，用于序列或时间扩展领域中子符号观察的处理。", "motivation": "在深度学习训练中融入高级逻辑知识仍然是一个挑战，特别是在涉及子符号观察的序列或时间延展域。为此，提出了一种新的混合模型DeepDFA来解决这一问题。", "method": "通过将时序规则建模为连续可微分层，DeepDFA框架可以将符号知识注入到子符号领域，具体实现包括静态图像序列分类和非马尔可夫环境中的策略学习。", "result": "实验表明，DeepDFA在时间知识集成方面优于传统深度学习模型（如LSTM、GRU、Transformer）和其他新兴的神经符号系统，并取得了最先进的结果。", "conclusion": "研究表明，DeepDFA框架能够有效连接子符号学习与符号推理，在处理序列任务时展现出强大的性能和潜力。"}}
{"id": "2602.03485", "pdf": "https://arxiv.org/pdf/2602.03485", "abs": "https://arxiv.org/abs/2602.03485", "authors": ["Quanyu Long", "Kai Jie Jiang", "Jianda Chen", "Xu Guo", "Leilei Gan", "Wenya Wang"], "title": "Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "19 pages, 8 figures", "summary": "Large Reasoning Models (LRMs) achieve strong performance by generating long reasoning traces with reflection. Through a large-scale empirical analysis, we find that a substantial fraction of reflective steps consist of self-verification (recheck) that repeatedly confirm intermediate results. These rechecks occur frequently across models and benchmarks, yet the vast majority are confirmatory rather than corrective, rarely identifying errors and altering reasoning outcomes. This reveals a mismatch between how often self-verification is activated and how often it is actually useful. Motivated by this, we propose a novel, experience-driven test-time framework that reduces the overused verification. Our method detects the activation of recheck behavior, consults an offline experience pool of past verification outcomes, and estimates whether a recheck is likely unnecessary via efficient retrieval. When historical experience suggests unnecessary, a suppression signal redirects the model to proceed. Across multiple model and benchmarks, our approach reduces token usage up to 20.3% while maintaining the accuracy, and in some datasets even yields accuracy improvements.", "AI": {"tldr": "提出了一种经验驱动的测试时间框架，以减少大型推理模型中过度使用的自我验证。", "motivation": "发现大量反射步骤为自我验证（复查），这些复查大多数是确认性的而非纠正性的，揭示了自查激活频率与其实用性之间的不匹配", "method": "通过检测重新检查行为的激活，查询离线经验池中的先前验证结果，并通过高效检索估计重新检查是否可能是不必要的。当历史经验表明不需要时，抑制信号引导模型继续。", "result": "在多个模型和基准测试中，该方法减少了最多20.3%的标记使用量，同时保持准确性，在某些数据集上甚至提高了准确性。", "conclusion": "提出的方法有效解决了大型推理模型中的自我验证过度问题，并且可以在减少资源消耗的同时保持或提高准确性。"}}
{"id": "2602.03478", "pdf": "https://arxiv.org/pdf/2602.03478", "abs": "https://arxiv.org/abs/2602.03478", "authors": ["Guannan Lai", "Han-Jia Ye"], "title": "When Routing Collapses: On the Degenerate Convergence of LLM Routers", "categories": ["cs.AI"], "comment": null, "summary": "LLM routing aims to achieve a favorable quality--cost trade-off by dynamically assigning easy queries to smaller models and harder queries to stronger ones. However, across both unimodal and multimodal settings, we uncover a pervasive yet underexplored failure mode in existing routers: as the user's cost budget increases, routers systematically default to the most capable and most expensive model even when cheaper models already suffice. As a result, current routers under-utilize small models, wasting computation and monetary cost and undermining the core promise of routing; we term this phenomenon routing collapse. We attribute routing collapse to an objective--decision mismatch: many routers are trained to predict scalar performance scores, whereas routing decisions ultimately depend on discrete comparisons among candidate models. Consequently, small prediction errors can flip relative orderings and trigger suboptimal selections. To bridge this gap, we propose EquiRouter, a decision-aware router that directly learns model rankings, restoring the role of smaller models and mitigating routing collapse. On RouterBench, EquiRouter reduces cost by about 17\\% at GPT-4-level performance compared to the strongest prior router. Our code is available at https://github.com/AIGNLAI/EquiRouter.", "AI": {"tldr": "本文研究了LLM路由中的一个问题，即随着成本预算的增加，现有的路由器倾向于将任务分配给最强大但也是最昂贵的模型，而不是更便宜且足够处理任务的小型模型。为此，提出了EquiRouter来解决这一问题。", "motivation": "现有路由方法在面对预算增加时会过度依赖大模型而忽视了小模型的有效使用，导致计算资源浪费和成本过高。作者希望通过研究这个问题并提出解决方案来优化模型的利用效率。", "method": "通过分析现有的路由器如何做出决策以及为何会产生这种偏好昂贵模型的行为模式，作者提出了EquiRouter这一新方法，它直接学习候选模型间的排名顺序以避免因预测误差导致的选择失误。", "result": "在RouterBench上评估时，与最强的现有路由方法相比，EquiRouter可以在保持GPT-4级性能的同时降低约17%的成本。", "conclusion": "现有的路由器存在一个问题即'路由崩溃'现象，在给定预算增加的情况下倾向于使用最强大的模型而非更合适的较小模型。通过引入决策意识型路由器（如EquiRouter），可以有效解决这个问题，提高资源利用率和降低成本"}}
{"id": "2602.03477", "pdf": "https://arxiv.org/pdf/2602.03477", "abs": "https://arxiv.org/abs/2602.03477", "authors": ["Mingxuan Wang", "Cheng Chen", "Gaoyang Jiang", "Zijia Ren", "Chuangxin Zhao", "Lu Shi", "Yanbiao Ma"], "title": "ScDiVa: Masked Discrete Diffusion for Joint Modeling of Single-Cell Identity and Expression", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "19 pages, 11 figures", "summary": "Single-cell RNA-seq profiles are high-dimensional, sparse, and unordered, causing autoregressive generation to impose an artificial ordering bias and suffer from error accumulation. To address this, we propose scDiVa, a masked discrete diffusion foundation model that aligns generation with the dropout-like corruption process by defining a continuous-time forward masking mechanism in token space. ScDiVa features a bidirectional denoiser that jointly models discrete gene identities and continuous values, utilizing entropy-normalized serialization and a latent anchor token to maximize information efficiency and preserve global cell identity. The model is trained via depth-invariant time sampling and a dual denoising objective to simulate varying sparsity levels while ensuring precise recovery of both identity and magnitude. Pre-trained on 59 million cells, scDiVa achieves strong transfer performance across major benchmarks, including batch integration, cell type annotation, and perturbation response prediction. These results suggest that masked discrete diffusion serves as a biologically coherent and effective alternative to autoregression.", "AI": {"tldr": "提出了一种用于单细胞RNA测序数据生成的新型掩码离散扩散模型scDiVa。", "motivation": "传统自回归方法在处理高维、稀疏且无序的数据时存在顺序偏置和误差累积的问题，因此需要一种新的方法来解决这些问题。", "method": "通过定义连续时间向前掩码机制，提出了一种联合建模离散基因身份和连续值的双向去噪器。模型利用熵规范化序列化和潜在锚令牌提高信息效率，并保持全局细胞身份。", "result": "在大规模数据集上预训练后，scDiVa在跨主要基准测试中的表现优于现有方法，包括批次整合、细胞类型注释和扰动响应预测。", "conclusion": "掩码离散扩散是一种生物学一致且有效的自回归替代方法。"}}
{"id": "2602.03476", "pdf": "https://arxiv.org/pdf/2602.03476", "abs": "https://arxiv.org/abs/2602.03476", "authors": ["Yihao Dong", "Praneeth Bimsara Perera", "Chin-Teng Lin", "Craig T Jin", "Anusha Withana"], "title": "TactDeform: Finger Pad Deformation Inspired Spatial Tactile Feedback for Virtual Geometry Exploration", "categories": ["cs.HC"], "comment": "Accepted to CHI 2026. Version of Record: DOI https://doi.org/10.1145/3772318.3791699", "summary": "Spatial tactile feedback can enhance the realism of geometry exploration in virtual reality applications. Current vibrotactile approaches often face challenges with the spatial and temporal resolution needed to render different 3D geometries. Inspired by the natural deformation of finger pads when exploring 3D objects and surfaces, we propose TactDeform, a parametric approach to render spatio-temporal tactile patterns using a finger-worn electro-tactile interface. The system dynamically renders electro-tactile patterns based on both interaction contexts (approaching, contact, and sliding) and geometric contexts (geometric features and textures), emulating deformations that occur during real-world touch exploration. Results from a user study \\rr{(N=24)} show that the proposed approach enabled high texture discrimination and geometric feature identification compared to a baseline. Informed by results from a free 3D-geometry exploration phase, we provide insights that can inform future tactile interface designs.", "AI": {"tldr": "本文提出了一种基于手指皮肤自然变形的参数化方法，以增强虚拟现实中的几何探索体验。", "motivation": "目前的振动触觉反馈技术在空间和时间分辨率上难以准确模拟不同三维物体。为此，作者设计了一种新的电触觉接口来模仿真实接触时的手指皮肤变形。", "method": "TactDeform通过手指穿戴式设备动态生成基于交互状态和几何特征变化的电触觉模式。", "result": "实验结果显示用户能够更准确地区分纹理并识别形状特征，与基线相比有显著提高。", "conclusion": "该方法为未来设计更加真实的虚拟环境提供了重要参考。"}}
{"id": "2602.03473", "pdf": "https://arxiv.org/pdf/2602.03473", "abs": "https://arxiv.org/abs/2602.03473", "authors": ["Meng Lou", "Yunxiang Fu", "Yizhou Yu"], "title": "Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Continual learning, especially class-incremental learning (CIL), on the basis of a pre-trained model (PTM) has garnered substantial research interest in recent years. However, how to effectively learn both discriminative and comprehensive feature representations while maintaining stability and plasticity over very long task sequences remains an open problem. We propose CaRE, a scalable {C}ontinual Le{a}rner with efficient Bi-Level {R}outing Mixture-of-{E}xperts (BR-MoE). The core idea of BR-MoE is a bi-level routing mechanism: a router selection stage that dynamically activates relevant task-specific routers, followed by an expert routing phase that dynamically activates and aggregates experts, aiming to inject discriminative and comprehensive representations into every intermediate network layer. On the other hand, we introduce a challenging evaluation protocol for comprehensively assessing CIL methods across very long task sequences spanning hundreds of tasks. Extensive experiments show that CaRE demonstrates leading performance across a variety of datasets and task settings, including commonly used CIL datasets with classical CIL settings (e.g., 5-20 tasks). To the best of our knowledge, CaRE is the first continual learner that scales to very long task sequences (ranging from 100 to over 300 non-overlapping tasks), while outperforming all baselines by a large margin on such task sequences. Code will be publicly released at https://github.com/LMMMEng/CaRE.git.", "AI": {"tldr": "该论文提出了CaRE，一种基于Bi-Level Routing Mixture-of-Experts的可扩展连续学习模型。", "motivation": "如何在长任务序列中保持稳定性和适应性的同时有效学习具有区分性和全面性的特征表示是一个开放问题。为此，需要提出一个有效的解决方案来应对这一挑战。", "method": "CaRE通过一种双级路由机制实现：首先选择相关的特定任务路由器，然后动态激活和聚合专家，以将有区别的和全面的表示注入到每个中间网络层中。", "result": "实验结果表明，在各种数据集和任务设置下，包括常用的CIL数据集及其经典设置（如5-20个任务），CaRE表现出领先性能，并且在长任务序列上超越所有基线方法。", "conclusion": "CaRE是第一个能够扩展到非常长的任务序列的连续学习者，在从100多个非重叠任务组成的序列中表现得尤为出色。"}}
{"id": "2602.03472", "pdf": "https://arxiv.org/pdf/2602.03472", "abs": "https://arxiv.org/abs/2602.03472", "authors": ["Minsu Kim", "Dongyeun Lee", "Jaemyung Yu", "Jiwan Hur", "Giseop Kim", "Junmo Kim"], "title": "Inlier-Centric Post-Training Quantization for Object Detection Models", "categories": ["cs.CV"], "comment": null, "summary": "Object detection is pivotal in computer vision, yet its immense computational demands make deployment slow and power-hungry, motivating quantization. However, task-irrelevant morphologies such as background clutter and sensor noise induce redundant activations (or anomalies). These anomalies expand activation ranges and skew activation distributions toward task-irrelevant responses, complicating bit allocation and weakening the preservation of informative features. Without a clear criterion to distinguish anomalies, suppressing them can inadvertently discard useful information. To address this, we present InlierQ, an inlier-centric post-training quantization approach that separates anomalies from informative inliers. InlierQ computes gradient-aware volume saliency scores, classifies each volume as an inlier or anomaly, and fits a posterior distribution over these scores using the Expectation-Maximization (EM) algorithm. This design suppresses anomalies while preserving informative features. InlierQ is label-free, drop-in, and requires only 64 calibration samples. Experiments on the COCO and nuScenes benchmarks show consistent reductions in quantization error for camera-based (2D and 3D) and LiDAR-based (3D) object detection.", "AI": {"tldr": "本文提出了一种名为InlierQ的后训练量化方法，旨在通过区分异常值和有用特征来提高目标检测模型的性能。", "motivation": "目标检测任务在计算机视觉中至关重要，但由于计算需求大导致部署速度慢且耗电。为了缓解这一问题，需要进行量化。然而背景杂乱和其他无关形态会导致冗余激活，从而影响量化效果。", "method": "InlierQ方法通过计算基于梯度的体积显著性得分来区分异常值和有用特征，并利用期望最大化算法拟合这些得分的后验分布，最终抑制异常值同时保留有用信息。", "result": "实验结果表明，在COCO和nuScenes数据集上，该方法在相机（2D和3D）和激光雷达（3D）目标检测任务中均表现出一致性的量化误差降低效果。", "conclusion": "InlierQ通过区分背景杂乱和其他无关形态，提高了目标检测模型的量化效果。"}}
{"id": "2602.03470", "pdf": "https://arxiv.org/pdf/2602.03470", "abs": "https://arxiv.org/abs/2602.03470", "authors": ["Nicolás E. Díaz Ferreyra", "Moritz Mock", "Max Kretschmann", "Barbara Russo", "Mojtaba Shahin", "Mansooreh Zahedi", "Riccardo Scandariato"], "title": "Reading Between the Code Lines: On the Use of Self-Admitted Technical Debt for Security Analysis", "categories": ["cs.CR", "cs.HC", "cs.SE"], "comment": "Preprint submitted to Journal of Systems and Software", "summary": "Static Analysis Tools (SATs) are central to security engineering activities, as they enable early identification of code weaknesses without requiring execution. However, their effectiveness is often limited by high false-positive rates and incomplete coverage of vulnerability classes. At the same time, developers frequently document security-related shortcuts and compromises as Self-Admitted Technical Debt (SATD) in software artifacts, such as code comments. While prior work has recognized SATD as a rich source of security information, it remains unclear whether -and in what ways- it is utilized during SAT-aided security analysis. OBJECTIVE: This work investigates the extent to which security-related SATD complements the output produced by SATs and helps bridge some of their well-known limitations. METHOD: We followed a mixed-methods approach consisting of (i) the analysis of a SATD-annotated vulnerability dataset using three state-of-the-art SATs and (ii) an online survey with 72 security practitioners. RESULTS: The combined use of all SATs flagged 114 of the 135 security-related SATD instances, spanning 24 distinct Common Weakness Enumeration (CWE) identifiers. A manual mapping of the SATD comments revealed 33 unique CWE types, 6 of which correspond to categories that SATs commonly overlook or struggle to detect (e.g., race conditions). Survey responses further suggest that developers frequently pair SAT outputs with SATD insights to better understand the impact and root causes of security weaknesses and to identify suitable fixes. IMPLICATIONS: Our findings show that such SATD-encoded information can be a meaningful complement to SAT-driven security analysis, while helping to overcome some of SATs' practical shortcomings.", "AI": {"tldr": "研究探讨了自我承认的技术债务（SATD）在静态分析工具（SATs）辅助安全分析中的作用，以弥补SAT的局限性。", "motivation": "前人研究表明SATD是丰富的安全性信息来源，但不清楚其如何用于增强SAT的安全性分析效果。因此，该研究旨在探讨SATD是否能补充SAT结果，并克服一些已知的SAT限制。", "method": "采用混合方法：首先使用三个最先进的SAT对包含安全相关SATD的漏洞数据集进行分析；其次通过在线调查收集了72名安全从业者的反馈。", "result": "结合所有SAT，标记出了135个安全相关SATD实例中的114个，并揭示了33种独特的CWE类型。此外，调查显示开发人员经常使用SAT输出和SATD见解来更好地理解安全性弱点的影响及其根本原因。", "conclusion": "研究发现SATD编码信息可作为补充静态分析驱动的安全性分析的有意义工具，有助于克服一些SAT的实际局限性。"}}
{"id": "2602.03468", "pdf": "https://arxiv.org/pdf/2602.03468", "abs": "https://arxiv.org/abs/2602.03468", "authors": ["Haohao Luo", "Zexi Li", "Yuexiang Xie", "Wenhao Zhang", "Yaliang Li", "Ying Shen"], "title": "IntentRL: Training Proactive User-intent Agents for Open-ended Deep Research via Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint", "summary": "Deep Research (DR) agents extend Large Language Models (LLMs) beyond parametric knowledge by autonomously retrieving and synthesizing evidence from large web corpora into long-form reports, enabling a long-horizon agentic paradigm. However, unlike real-time conversational assistants, DR is computationally expensive and time-consuming, creating an autonomy-interaction dilemma: high autonomy on ambiguous user queries often leads to prolonged execution with unsatisfactory outcomes. To address this, we propose IntentRL, a framework that trains proactive agents to clarify latent user intents before starting long-horizon research. To overcome the scarcity of open-ended research data, we introduce a scalable pipeline that expands a few seed samples into high-quality dialogue turns via a shallow-to-deep intent refinement graph. We further adopt a two-stage reinforcement learning (RL) strategy: Stage I applies RL on offline dialogues to efficiently learn general user-interaction behavior, while Stage II uses the trained agent and a user simulator for online rollouts to strengthen adaptation to diverse user feedback. Extensive experiments show that IntentRL significantly improves both intent hit rate and downstream task performance, outperforming the built-in clarify modules of closed-source DR agents and proactive LLM baselines.", "AI": {"tldr": "本文提出了IntentRL框架，通过强化学习训练预主动代理以明确潜在的用户意图，从而提高长期研究任务的成功率。", "motivation": "深度研究（DR）代理人需要解决计算成本高和时间消耗大的问题，这导致了自主性和互动性之间的矛盾。为此，作者提出了解决方案来改善用户体验。", "method": "IntentRL框架采用了一种两阶段的强化学习策略：第一阶段在离线对话上进行训练以获取通用的用户交互行为；第二阶段则通过使用经过训练的代理和一个用户模拟器来进行在线滚动，增强对各种用户反馈的适应性。", "result": "实验结果显示，IntentRL框架显著提高了意图命中率和下游任务性能，并优于封闭源深度研究代理自带的澄清模块以及主动LLM基线模型。", "conclusion": "通过使用强化学习技术训练代理人明确潜在用户意图，可以有效提高长期研究报告生成的质量。"}}
{"id": "2602.03467", "pdf": "https://arxiv.org/pdf/2602.03467", "abs": "https://arxiv.org/abs/2602.03467", "authors": ["Zeynep G. Saribatur", "Johannes Langer", "Ute Schmid"], "title": "The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding", "categories": ["cs.AI", "cs.HC"], "comment": "8 pages, 5 figures", "summary": "Explanations are central to human cognition, yet AI systems often produce outputs that are difficult to understand. While symbolic AI offers a transparent foundation for interpretability, raw logical traces often impose a high extraneous cognitive load. We investigate how formal abstractions, specifically removal and clustering, impact human reasoning performance and cognitive effort. Utilizing Answer Set Programming (ASP) as a formal framework, we define a notion of irrelevant details to be abstracted over to obtain simplified explanations. Our cognitive experiments, in which participants classified stimuli across domains with explanations derived from an answer set program, show that clustering details significantly improve participants' understanding, while removal of details significantly reduce cognitive effort, supporting the hypothesis that abstraction enhances human-centered symbolic explanations.", "AI": {"tldr": "研究了形式抽象在人类理解能力和认知努力上的影响，提出了基于ASP的简化解释方法", "motivation": "旨在提高AI系统输出的人类可理解性，减少不必要的认知负担", "method": "使用ASP框架定义无关细节进行摘要处理，并通过分类实验测试参与者对不同形式说明的理解能力与认知努力", "result": "聚类详细信息显著提高了参与者的理解力，而删除详细信息显著减少了认知努力", "conclusion": "抽象化能增强以人为中心的符号解释"}}
{"id": "2602.03454", "pdf": "https://arxiv.org/pdf/2602.03454", "abs": "https://arxiv.org/abs/2602.03454", "authors": ["Yeongtak Oh", "Sangwon Yu", "Junsung Park", "Han Cheol Moon", "Jisoo Mok", "Sungroh Yoon"], "title": "Contextualized Visual Personalization in Vision-Language Models", "categories": ["cs.CV"], "comment": "Project Page: https://github.com/oyt9306/CoViP", "summary": "Despite recent progress in vision-language models (VLMs), existing approaches often fail to generate personalized responses based on the user's specific experiences, as they lack the ability to associate visual inputs with a user's accumulated visual-textual context. We newly formalize this challenge as contextualized visual personalization, which requires the visual recognition and textual retrieval of personalized visual experiences by VLMs when interpreting new images. To address this issue, we propose CoViP, a unified framework that treats personalized image captioning as a core task for contextualized visual personalization and improves this capability through reinforcement-learning-based post-training and caption-augmented generation. We further introduce diagnostic evaluations that explicitly rule out textual shortcut solutions and verify whether VLMs truly leverage visual context. Extensive experiments demonstrate that existing open-source and proprietary VLMs exhibit substantial limitations, while CoViP not only improves personalized image captioning but also yields holistic gains across downstream personalization tasks. These results highlight CoViP as a crucial stage for enabling robust and generalizable contextualized visual personalization.", "AI": {"tldr": "提出了一种统一框架CoViP，旨在通过强化学习和生成改进个性化图像描述的能力，从而提升视觉语言模型的上下文感知个人化能力。", "motivation": "现有视觉-语言模型在生成基于用户特定经验的个性化响应方面存在不足，缺乏将视觉输入与用户的累积视听文本背景联系起来的能力。因此，提出了新的挑战——情境化视觉个人化，以解决这一问题。", "method": "通过强化学习后训练和增强描述的方法来改进图像描述能力，并引入诊断评估以排除仅依赖于文本捷径的解决方案，验证模型是否真正利用了视觉上下文。", "result": "实验表明现有开源和专有的视觉语言模型在个性化图像描述方面存在重大限制，而CoViP不仅能提高这种能力，还能在整个下游个人化任务中实现整体改进。", "conclusion": "这些结果强调了CoViP作为提升稳健且通用的上下文感知个人化的关键阶段的重要性。"}}
{"id": "2602.03452", "pdf": "https://arxiv.org/pdf/2602.03452", "abs": "https://arxiv.org/abs/2602.03452", "authors": ["Xin Sheng", "Jiaxin Li", "Yujuan Pang", "Ran Peng", "Yong Ma"], "title": "Beyond Variance: Prompt-Efficient RLVR via Rare-Event Amplification and Bidirectional Pairing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) is effective for training large language models on deterministic outcome reasoning tasks. Prior work shows RLVR works with few prompts, but prompt selection is often based only on training-accuracy variance, leading to unstable optimization directions and weaker transfer. We revisit prompt selection from a mechanism-level view and argue that an effective minibatch should provide both (i) a reliable positive anchor and (ii) explicit negative learning signals from rare failures. Based on this principle, we propose \\emph{positive--negative pairing}: at each update, we sample a hard-but-solvable $q^{+}$ and an easy-but-brittle prompt $q^{-}$(high success rate but not perfect), characterized by low and high empirical success rates under multiple rollouts. We further introduce Weighted GRPO, which reweights binary outcomes at the pair level and uses group-normalized advantages to amplify rare successes on $q^{+}$ into sharp positive guidance while turning rare failures on $q^{-}$ into strong negative penalties. This bidirectional signal provides informative learning feedback for both successes and failures, improving sample efficiency without suppressing exploration. On Qwen2.5-Math-7B, a single paired minibatch per update consistently outperforms a GRPO baseline that selects two prompts via commonly used variance-based selection heuristics: AIME~2025 Pass@8 improves from 16.8 to 22.2, and AMC23 Pass@64 from 94.0 to 97.0, while remaining competitive with large-scale RLVR trained from a pool of 1209 training prompts. Similar gains are observed on Qwen2.5-Math-7B-Instruct.", "AI": {"tldr": "该论文提出了一种新的强化学习与验证奖励方法，通过罕见事件放大和双向配对来提高样本效率。", "motivation": "以往的RLVR研究中，提示选择仅依赖于训练准确性的方差，导致优化方向不稳定且转移效果较弱。作者建议有效的minibatch应提供可靠正向锚点及明确负向学习信号，以增强稀有失败案例的学习反馈。", "method": "论文提出正负对配策略，即每次更新时选取一个难以但可解的提示（成功率为低）和一个容易但脆弱的提示（成功率高但非完美），并引入加权GRPO模型来重新分配二元结果权重，并利用组归一化优势放大稀有成功案例的同时将罕见失败转化为强负向惩罚。", "result": "在Qwen2.5-Math-7B上的实验显示，单个配对minibatch每次更新比使用常见方差选择策略的GRPO基线有所提高：AIME~2025 Pass@8从16.8提升至22.2；AMC23 Pass@64从94.0提升到97.0，同时保持与大规模RLVR训练相当的竞争性。", "conclusion": "通过罕见事件放大和双向配对策略改进样本效率，论文方法在减少计算资源使用的同时增强了模型的性能。"}}
{"id": "2602.03448", "pdf": "https://arxiv.org/pdf/2602.03448", "abs": "https://arxiv.org/abs/2602.03448", "authors": ["Yijia Xu", "Zihao Wang", "Jinshi Cui"], "title": "Hierarchical Concept-to-Appearance Guidance for Multi-Subject Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multi-subject image generation aims to synthesize images that faithfully preserve the identities of multiple reference subjects while following textual instructions. However, existing methods often suffer from identity inconsistency and limited compositional control, as they rely on diffusion models to implicitly associate text prompts with reference images. In this work, we propose Hierarchical Concept-to-Appearance Guidance (CAG), a framework that provides explicit, structured supervision from high-level concepts to fine-grained appearances. At the conceptual level, we introduce a VAE dropout training strategy that randomly omits reference VAE features, encouraging the model to rely more on robust semantic signals from a Visual Language Model (VLM) and thereby promoting consistent concept-level generation in the absence of complete appearance cues. At the appearance level, we integrate the VLM-derived correspondences into a correspondence-aware masked attention module within the Diffusion Transformer (DiT). This module restricts each text token to attend only to its matched reference regions, ensuring precise attribute binding and reliable multi-subject composition. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the multi-subject image generation, substantially improving prompt following and subject consistency.", "AI": {"tldr": "提出了Hierarchical Concept-to-Appearance Guidance (CAG)框架，用于多主体图像生成。", "motivation": "现有的方法在处理身份一致性及合成控制方面存在不足，依赖扩散模型隐式关联文本提示与参考图像。", "method": "引入VAE dropout训练策略以增强语义信号的可靠性，并将VLM导出对应关系集成到Diffusion Transformer (DiT)中，确保精确属性绑定和可靠的多主体组合。", "result": "实验表明该方法在多主体图像生成方面达到最佳性能，显著改善了指令遵循与身份一致性。", "conclusion": "所提出的方法解决了现有技术中的问题，并提高了多主题图像生成的质量。"}}
{"id": "2602.03447", "pdf": "https://arxiv.org/pdf/2602.03447", "abs": "https://arxiv.org/abs/2602.03447", "authors": ["Yu-Hsiang Chen", "Wei-Jer Chang", "Christian Kotulla", "Thomas Keutgens", "Steffen Runde", "Tobias Moers", "Christoph Klas", "Wei Zhan", "Masayoshi Tomizuka", "Yi-Ting Chen"], "title": "HetroD: A High-Fidelity Drone Dataset and Benchmark for Autonomous Driving in Heterogeneous Traffic", "categories": ["cs.RO", "cs.CV"], "comment": "IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "We present HetroD, a dataset and benchmark for developing autonomous driving systems in heterogeneous environments. HetroD targets the critical challenge of navi- gating real-world heterogeneous traffic dominated by vulner- able road users (VRUs), including pedestrians, cyclists, and motorcyclists that interact with vehicles. These mixed agent types exhibit complex behaviors such as hook turns, lane splitting, and informal right-of-way negotiation. Such behaviors pose significant challenges for autonomous vehicles but remain underrepresented in existing datasets focused on structured, lane-disciplined traffic. To bridge the gap, we collect a large- scale drone-based dataset to provide a holistic observation of traffic scenes with centimeter-accurate annotations, HD maps, and traffic signal states. We further develop a modular toolkit for extracting per-agent scenarios to support downstream task development. In total, the dataset comprises over 65.4k high- fidelity agent trajectories, 70% of which are from VRUs. HetroD supports modeling of VRU behaviors in dense, het- erogeneous traffic and provides standardized benchmarks for forecasting, planning, and simulation tasks. Evaluation results reveal that state-of-the-art prediction and planning models struggle with the challenges presented by our dataset: they fail to predict lateral VRU movements, cannot handle unstructured maneuvers, and exhibit limited performance in dense and multi-agent scenarios, highlighting the need for more robust approaches to heterogeneous traffic. See our project page for more examples: https://hetroddata.github.io/HetroD/", "AI": {"tldr": "本文介绍了一个用于开发自动驾驶系统在异质交通环境中的数据集和基准，重点关注行人、骑自行车者和其他易受伤害的道路使用者的行为。", "motivation": "现有数据集中对结构化交通的关注不足，忽略了复杂的VRU行为。为填补这一空白，HetroD旨在提供一个大规模的无人机采集的数据集来观测复杂多样的道路场景，并支持下游任务开发。", "method": "通过无人机收集了大型交通场景数据集，包含高精度轨迹、高清地图和交通信号状态等信息；建立了模块化工具包以提取个体代理者的行为模式，用于预测和规划任务的标准化基准。", "result": "评估结果表明，最先进的预测和计划模型在处理横向VRU运动、非结构化操作和多代理密集场景时表现不佳，凸显了对异质交通更鲁棒方法的需求。", "conclusion": "HetroD提供了一个全面的数据集来支持自动驾驶系统的研究和发展，在解决复杂现实世界中的交通挑战方面具有重要作用。"}}
{"id": "2602.03445", "pdf": "https://arxiv.org/pdf/2602.03445", "abs": "https://arxiv.org/abs/2602.03445", "authors": ["Qixin Zeng", "Shuo Zhang", "Hongyin Zhang", "Renjie Wang", "Han Zhao", "Libang Zhao", "Runze Li", "Donglin Wang", "Chao Huang"], "title": "CRL-VLA: Continual Vision-Language-Action Learning", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Lifelong learning is critical for embodied agents in open-world environments, where reinforcement learning fine-tuning has emerged as an important paradigm to enable Vision-Language-Action (VLA) models to master dexterous manipulation through environmental interaction. Thus, Continual Reinforcement Learning (CRL) is a promising pathway for deploying VLA models in lifelong robotic scenarios, yet balancing stability (retaining old skills) and plasticity (learning new ones) remains a formidable challenge for existing methods. We introduce CRL-VLA, a framework for continual post-training of VLA models with rigorous theoretical bounds. We derive a unified performance bound linking the stability-plasticity trade-off to goal-conditioned advantage magnitude, scaled by policy divergence. CRL-VLA resolves this dilemma via asymmetric regulation: constraining advantage magnitudes on prior tasks while enabling controlled growth on new tasks. This is realized through a simple but effective dual-critic architecture with novel Goal-Conditioned Value Formulation (GCVF), where a frozen critic anchors semantic consistency and a trainable estimator drives adaptation. Experiments on the LIBERO benchmark demonstrate that CRL-VLA effectively harmonizes these conflicting objectives, outperforming baselines in both anti-forgetting and forward adaptation.", "AI": {"tldr": "本文提出了一种名为CRL-VLA的框架，用于持续训练视觉语言行动模型以实现终身学习。", "motivation": "在开放世界环境中，使机器人通过与环境交互掌握灵巧操作是至关重要的。然而，现有方法难以平衡稳定性（保留旧技能）和可塑性（学习新技能），这成为了挑战。", "method": "CRL-VLA框架通过不对称调节解决稳定性和可塑性的矛盾，限制先前任务的优势大小并允许在新任务上控制增长，从而实现持续强化学习。此方法采用新颖的双重评论架构以及目标导向价值公式，其中冻结评论员锚定语义一致性而训练中的估计算法驱动适应。", "result": "实验表明CRL-VLA框架在LIBERO基准测试中表现出色，在防止遗忘和前向适应方面均优于基线模型。", "conclusion": "CRL-VLA为视觉语言行动学习提供了有效的解决方案，解决了终身学习环境中稳定性和可塑性之间的冲突。"}}
{"id": "2602.03444", "pdf": "https://arxiv.org/pdf/2602.03444", "abs": "https://arxiv.org/abs/2602.03444", "authors": ["Arivarasan Karmegam", "Lucianna Kiffer", "Antonio Fernández Anta"], "title": "Exploiting Multi-Core Parallelism in Blockchain Validation and Construction", "categories": ["cs.DC", "cs.DS"], "comment": null, "summary": "Blockchain validators can reduce block processing time by exploiting multi-core CPUs, but deterministic execution must preserve a given total order while respecting transaction conflicts and per-block runtime limits. This paper systematically examines how validators can exploit multi-core parallelism during both block construction and execution without violating blockchain semantics. We formalize two validator-side optimization problems: (i) executing an already ordered block on \\(p\\) cores to minimize makespan while ensuring equivalence to sequential execution; and (ii) selecting and scheduling a subset of mempool transactions under a runtime limit \\(B\\) to maximize validator reward. For both, we develop exact Mixed-Integer Linear Programming (MILP) formulations that capture conflict, order, and capacity constraints, and propose fast deterministic heuristics that scale to realistic workloads. Using Ethereum mainnet traces and including a Solana-inspired declared-access baseline (Sol) for ordered-block scheduling and a simple reward-greedy baseline (RG) for block construction, we empirically quantify the trade-offs between optimality and runtime.", "AI": {"tldr": "本文探讨了区块链验证者如何利用多核CPU的并行性在保持区块构造和执行语义不变的情况下，最小化区块处理时间。", "motivation": "通过利用多核CPU的并行计算能力可以显著减少区块链中区块处理的时间。然而，在这种优化过程中必须保证交易执行的一致性和总顺序，同时不违反区块链的核心规则。", "method": "本文提出了两个形式化的验证者侧优化问题，并开发了精确的混合整数线性规划（MILP）模型来解决这些问题。此外还提出了一些快速确定性的启发式算法以适应大规模的实际工作负载需求。", "result": "实验结果表明，所提出的算法在保证最优解的情况下能够有效地缩短区块处理时间，并且通过与基准方法进行比较进一步验证了该研究的有效性和实用性。", "conclusion": "本文的研究为区块链系统中的多核并行计算提供了新的见解和解决方案。未来的工作可以考虑将这些优化策略应用于实际的分布式网络中，以提高整个系统的性能和效率。"}}
{"id": "2602.03439", "pdf": "https://arxiv.org/pdf/2602.03439", "abs": "https://arxiv.org/abs/2602.03439", "authors": ["Xiaochi Zhou", "Patrick Bulter", "Changxuan Yang", "Simon D. Rihm", "Thitikarn Angkanaporn", "Jethro Akroyd", "Sebastian Mosbach", "Markus Kraft"], "title": "Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents", "categories": ["cs.AI", "cs.IR"], "comment": "mber:c4e-343", "summary": "We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge. Within The World Avatar (TWA), ontological specifications are compiled into executable tool interfaces that LLM-based agents must use to create and modify knowledge graph instances, enforcing semantic constraints during generation rather than through post-hoc validation. Extending TWA's semantic agent composition framework, the Model Context Protocol (MCP) and associated agents are integral components of the knowledge graph ecosystem, enabling structured interaction between generative models, symbolic constraints, and external resources. An agent-based workflow translates ontologies into ontology-aware tools and iteratively applies them to extract, validate, and repair structured knowledge from unstructured scientific text. Using metal-organic polyhedra synthesis literature as an illustrative case, we show how executable ontological semantics can guide LLM behaviour and reduce manual schema and prompt engineering, establishing a general paradigm for embedding formal knowledge into generative systems.", "AI": {"tldr": "本文介绍了从本体到工具的编译机制，使大型语言模型能够利用形式化的领域知识来执行语义约束。", "motivation": "通过将大型语言模型与正式领域的知识相连接，可以在生成过程中而不是事后验证时强制执行语义约束。", "method": "在《世界Avatar》的知识图谱生态系统中，利用模型上下文协议和相关代理将本体编译为可执行工具接口，指导LLM的行为并减少人工模式和提示工程的工作量。", "result": "通过使用金属有机多面体合成文献作为案例，证明了可执行的语义约束能够引导大型语言模型行为，并减少了手动知识模式设计与提示工程的需求。", "conclusion": "提出了一种将正式的知识嵌入到生成系统中的通用范式，为LLM和知识图谱生态系统之间的交互提供了结构化的框架。"}}
{"id": "2602.03436", "pdf": "https://arxiv.org/pdf/2602.03436", "abs": "https://arxiv.org/abs/2602.03436", "authors": ["Kenta Komoto", "Kazuhiro Kurita", "Hirotaka Ono"], "title": "On the Complexity of Maximal/Closed Frequent Tree Mining for Bounded Height Trees", "categories": ["cs.DS"], "comment": null, "summary": "In this paper, we address the problem of enumerating all frequent maximal/closed trees. This is a classical and central problem in data mining. Although many practical algorithms have been developed for this problem, its complexity under ``realistic assumptions'' on tree height has not been clarified. More specifically, while it was known that the mining problem becomes hard when the tree height is at least 60, the complexity for cases where the tree height is smaller has not yet been clarified. We resolve this gap by establishing results for these tree mining problems under several settings, including ordered and unordered trees, as well as maximal and closed variants.", "AI": {"tldr": "论文探讨了高度有限制的树结构中的最大/封闭频繁模式挖掘问题。", "motivation": "在实际应用中，虽然已有许多算法解决该问题，但对于较小树高的复杂度未明确。作者旨在填补这一空白，并为有序和无序树以及最大值和封闭变体建立结果。", "method": "通过理论分析不同条件下（包括有顺序与无顺序树）的挖掘问题的难度。", "result": "确立了在各种设置下的高度有限制的树结构中频繁模式挖掘问题的复杂度。", "conclusion": "论文解决了特定场景下频繁树模式挖掘的问题，并明确了其计算复杂性，填补了理论空白。"}}
{"id": "2602.03435", "pdf": "https://arxiv.org/pdf/2602.03435", "abs": "https://arxiv.org/abs/2602.03435", "authors": ["Daniele Caradonna", "Nikhil Nair", "Anup Teejo Mathew", "Daniel Feliu Talegón", "Imran Afgan", "Egidio Falotico", "Cosimo Della Santina", "Federico Renda"], "title": "Model-based Optimal Control for Rigid-Soft Underactuated Systems", "categories": ["cs.RO"], "comment": null, "summary": "Continuum soft robots are inherently underactuated and subject to intrinsic input constraints, making dynamic control particularly challenging, especially in hybrid rigid-soft robots. While most existing methods focus on quasi-static behaviors, dynamic tasks such as swing-up require accurate exploitation of continuum dynamics. This has led to studies on simple low-order template systems that often fail to capture the complexity of real continuum deformations. Model-based optimal control offers a systematic solution; however, its application to rigid-soft robots is often limited by the computational cost and inaccuracy of numerical differentiation for high-dimensional models. Building on recent advances in the Geometric Variable Strain model that enable analytical derivatives, this work investigates three optimal control strategies for underactuated soft systems-Direct Collocation, Differential Dynamic Programming, and Nonlinear Model Predictive Control-to perform dynamic swing-up tasks. To address stiff continuum dynamics and constrained actuation, implicit integration schemes and warm-start strategies are employed to improve numerical robustness and computational efficiency. The methods are evaluated in simulation on three Rigid-Soft and high-order soft benchmark systems-the Soft Cart-Pole, the Soft Pendubot, and the Soft Furuta Pendulum- highlighting their performance and computational trade-offs.", "AI": {"tldr": "研究基于模型的最优控制策略，以解决刚柔混合机器人在动态任务中的控制问题。", "motivation": "针对刚柔混合机器人的复杂动力学和受限制输入的问题，现有方法难以准确处理其动态行为。本文旨在开发有效的控制策略来克服这些挑战，提高系统的性能。", "method": "采用直接配位法、微分动态规划及非线性模型预测控制三种最优控制策略进行刚柔混合机器人在摆动任务中的动态优化，并通过隐式积分方案和预热启动策略提升数值稳定性和计算效率。", "result": "方法在软车杆、软双足机器人和软福尔塔摆等基准系统上的模拟结果表明，该技术能够有效解决刚柔混合机器人的动力学问题，并展示了不同控制策略之间的性能及计算成本的权衡。", "conclusion": "本文提出的基于模型的最优控制策略为处理刚柔混合系统的动态行为提供了一种有效的解决方案。未来的工作将探讨如何进一步优化算法以减少计算时间并提高实用性。"}}
{"id": "2602.03430", "pdf": "https://arxiv.org/pdf/2602.03430", "abs": "https://arxiv.org/abs/2602.03430", "authors": ["Xiaomeng Zhu", "Fengming Zhu", "Weijie Zhou", "Ye Tian", "Zhenlin Hu", "Yufei Huang", "Yuchun Guo", "Xinyu Wu", "Zhengyou Zhang", "Fangzhen Lin", "Xuantang Xiong"], "title": "ProAct: A Benchmark and Multimodal Framework for Structure-Aware Proactive Response", "categories": ["cs.RO"], "comment": null, "summary": "While passive agents merely follow instructions, proactive agents align with higher-level objectives, such as assistance and safety by continuously monitoring the environment to determine when and how to act. However, developing proactive agents is hindered by the lack of specialized resources. To address this, we introduce ProAct-75, a benchmark designed to train and evaluate proactive agents across diverse domains, including assistance, maintenance, and safety monitoring. Spanning 75 tasks, our dataset features 91,581 step-level annotations enriched with explicit task graphs. These graphs encode step dependencies and parallel execution possibilities, providing the structural grounding necessary for complex decision-making. Building on this benchmark, we propose ProAct-Helper, a reference baseline powered by a Multimodal Large Language Model (MLLM) that grounds decision-making in state detection, and leveraging task graphs to enable entropy-driven heuristic search for action selection, allowing agents to execute parallel threads independently rather than mirroring the human's next step. Extensive experiments demonstrate that ProAct-Helper outperforms strong closed-source models, improving trigger detection mF1 by 6.21%, saving 0.25 more steps in online one-step decision, and increasing the rate of parallel actions by 15.58%.", "AI": {"tldr": "本文提出了ProAct基准和多模态框架，用于训练和评估结构感知的主动性代理。", "motivation": "被动代理仅遵循指令，而主动代理通过持续监测环境来实现更高层次的目标。然而，由于缺乏专用资源，开发主动代理受到了阻碍。", "method": "引入了涵盖75个任务、包含91,581个步骤级注释的ProAct-75基准，并构建了基于多模态大型语言模型（MLLM）的参考基线ProAct-Helper。利用任务图进行状态检测和决策，采用熵驱动启发式搜索选择动作。", "result": "实验显示，ProAct-Helper在触发检测mF1上提高了6.21%，节省了0.25个步骤，并增加了并行行动率15.58%。", "conclusion": "该框架成功地提升了主动代理的性能和效率。"}}
{"id": "2602.03429", "pdf": "https://arxiv.org/pdf/2602.03429", "abs": "https://arxiv.org/abs/2602.03429", "authors": ["Tae Soo Kim", "Yoonjoo Lee", "Jaesang Yu", "John Joon Young Chung", "Juho Kim"], "title": "DiscoverLLM: From Executing Intents to Discovering Them", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "To handle ambiguous and open-ended requests, Large Language Models (LLMs) are increasingly trained to interact with users to surface intents they have not yet expressed (e.g., ask clarification questions). However, users are often ambiguous because they have not yet formed their intents: they must observe and explore outcomes to discover what they want. Simply asking \"what kind of tone do you want?\" fails when users themselves do not know. We introduce DiscoverLLM, a novel and generalizable framework that trains LLMs to help users form and discover their intents. Central to our approach is a novel user simulator that models cognitive state with a hierarchy of intents that progressively concretize as the model surfaces relevant options -- where the degree of concretization serves as a reward signal that models can be trained to optimize. Resulting models learn to collaborate with users by adaptively diverging (i.e., explore options) when intents are unclear, and converging (i.e., refine and implement) when intents concretize. Across proposed interactive benchmarks in creative writing, technical writing, and SVG drawing, DiscoverLLM achieves over 10% higher task performance while reducing conversation length by up to 40%. In a user study with 75 human participants, DiscoverLLM improved conversation satisfaction and efficiency compared to baselines.", "AI": {"tldr": "DiscoverLLM是一种框架，旨在帮助用户发现和形成其意图，特别是在他们还不清楚自己的需求时。通过与用户的互动来适应性地探索选项或细化实施。", "motivation": "处理模糊且开放的请求时，大型语言模型需要训练以交互方式来发掘用户尚未明确表达的意图。然而，在某些情况下，用户本身也并不确定他们的具体需求。因此，迫切需要一种能够帮助用户发现和形成其真实意图的方法。", "method": "提出了DiscoverLLM框架，该方法包括一个新颖的用户模拟器，它通过建立一系列逐步细化的目标层次结构来反映用户的认知状态，并用这一过程中的抽象程度作为奖励信号进行优化训练。这使模型能够在用户意图不明确时探索更多选项，在目标具体化后进一步细化和实施。", "result": "在创意写作、技术写作和SVG绘图的互动基准测试中，DiscoverLLM相比基线方法提高了超过10%的任务性能，并缩短了最多40%的对话长度。并且通过与75位参与者进行的人类研究也显示，DiscoverLLM提升了对话满意度和效率。", "conclusion": "本文提出了一种新的框架DiscoverLLM，它使大型语言模型能够帮助用户在不明确其需求时发现并形成这些需求。该方法不仅提高了任务完成度还缩短了交互时间，并且改善了用户的互动体验和工作效率。"}}
{"id": "2602.03425", "pdf": "https://arxiv.org/pdf/2602.03425", "abs": "https://arxiv.org/abs/2602.03425", "authors": ["Xiaofeng Tan", "Jun Liu", "Yuanting Fan", "Bin-Bin Gao", "Xi Jiang", "Xiaochen Chen", "Jinlong Peng", "Chengjie Wang", "Hongsong Wang", "Feng Zheng"], "title": "ConsistentRFT: Reducing Visual Hallucinations in Flow-based Reinforcement Fine-Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Reinforcement Fine-Tuning (RFT) on flow-based models is crucial for preference alignment. However, they often introduce visual hallucinations like over-optimized details and semantic misalignment. This work preliminarily explores why visual hallucinations arise and how to reduce them. We first investigate RFT methods from a unified perspective, and reveal the core problems stemming from two aspects, exploration and exploitation: (1) limited exploration during stochastic differential equation (SDE) rollouts, leading to an over-emphasis on local details at the expense of global semantics, and (2) trajectory imitation process inherent in policy gradient methods, distorting the model's foundational vector field and its cross-step consistency. Building on this, we propose ConsistentRFT, a general framework to mitigate these hallucinations. Specifically, we design a Dynamic Granularity Rollout (DGR) mechanism to balance exploration between global semantics and local details by dynamically scheduling different noise sources. We then introduce a Consistent Policy Gradient Optimization (CPGO) that preserves the model's consistency by aligning the current policy with a more stable prior. Extensive experiments demonstrate that ConsistentRFT significantly mitigates visual hallucinations, achieving average reductions of 49\\% for low-level and 38\\% for high-level perceptual hallucinations. Furthermore, ConsistentRFT outperforms other RFT methods on out-of-domain metrics, showing an improvement of 5.1\\% (v.s. the baseline's decrease of -0.4\\%) over FLUX1.dev. This is \\href{https://xiaofeng-tan.github.io/projects/ConsistentRFT}{Project Page}.", "AI": {"tldr": "本文提出了一种减少基于流的模型在强化微调过程中产生的视觉幻觉的方法ConsistentRFT。", "motivation": "传统的强化微调方法容易引入过度优化细节和语义偏差等视觉幻觉问题。为了改善这个问题，作者从探索和利用两个方面来研究如何减少这些幻觉。", "method": "本文提出了一个名为ConsistentRFT的框架，该框架通过动态颗粒度回滚机制平衡全局语义与局部细节之间的探索，并采用一致策略梯度优化方法保持模型的一致性。", "result": "实验表明，所提方法在降低视觉幻觉方面表现出色，对于低层次和高层次感知幻觉分别降低了49%和38%，并且在外域指标上比基线提升了5.1%。", "conclusion": "本文通过平衡探索与利用，并保持模型的一致性来减少基于流的强化微调过程中的视觉幻觉问题。"}}
{"id": "2602.03423", "pdf": "https://arxiv.org/pdf/2602.03423", "abs": "https://arxiv.org/abs/2602.03423", "authors": ["Alexander Loth", "Dominique Conceicao Rosario", "Peter Ebinger", "Martin Kappes", "Marc-Oliver Pahl"], "title": "Origin Lens: A Privacy-First Mobile Framework for Cryptographic Image Provenance and AI Detection", "categories": ["cs.CR", "cs.CV", "cs.CY", "cs.HC"], "comment": "Accepted at ACM TheWebConf '26 Companion", "summary": "The proliferation of generative AI poses challenges for information integrity assurance, requiring systems that connect model governance with end-user verification. We present Origin Lens, a privacy-first mobile framework that targets visual disinformation through a layered verification architecture. Unlike server-side detection systems, Origin Lens performs cryptographic image provenance verification and AI detection locally on the device via a Rust/Flutter hybrid architecture. Our system integrates multiple signals - including cryptographic provenance, generative model fingerprints, and optional retrieval-augmented verification - to provide users with graded confidence indicators at the point of consumption. We discuss the framework's alignment with regulatory requirements (EU AI Act, DSA) and its role in verification infrastructure that complements platform-level mechanisms.", "AI": {"tldr": "本文介绍了一种名为Origin Lens的隐私优先移动框架，用于加密图像来源验证和AI检测。", "motivation": "生成式人工智能的普及对信息完整性保障提出了挑战，需要能够将模型治理与终端用户验证相结合的系统。本文旨在通过本地执行验证来解决视觉误导问题，同时符合监管要求。", "method": "Origin Lens采用Rust/Flutter混合架构，在设备上进行加密图像来源验证和AI检测。该框架结合了多种信号源，包括加密来源、生成模型指纹和可选检索增强验证，为用户提供分级信心指示器。", "result": "未具体说明实验结果或数据指标。", "conclusion": "Origin Lens是一种隐私优先的移动框架，旨在通过本地执行验证来对抗视觉误导，并且符合相关法规要求。"}}
{"id": "2602.03420", "pdf": "https://arxiv.org/pdf/2602.03420", "abs": "https://arxiv.org/abs/2602.03420", "authors": ["Siyi Wang", "Shihong Tan", "Siyi Liu", "Hong Jia", "Gongping Huang", "James Bailey", "Ting Dang"], "title": "CoCoEmo: Composable and Controllable Human-Like Emotional TTS via Activation Steering", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Emotional expression in human speech is nuanced and compositional, often involving multiple, sometimes conflicting, affective cues that may diverge from linguistic content. In contrast, most expressive text-to-speech systems enforce a single utterance-level emotion, collapsing affective diversity and suppressing mixed or text-emotion-misaligned expression. While activation steering via latent direction vectors offers a promising solution, it remains unclear whether emotion representations are linearly steerable in TTS, where steering should be applied within hybrid TTS architectures, and how such complex emotion behaviors should be evaluated. This paper presents the first systematic analysis of activation steering for emotional control in hybrid TTS models, introducing a quantitative, controllable steering framework, and multi-rater evaluation protocols that enable composable mixed-emotion synthesis and reliable text-emotion mismatch synthesis. Our results demonstrate, for the first time, that emotional prosody and expressive variability are primarily synthesized by the TTS language module instead of the flow-matching module, and also provide a lightweight steering approach for generating natural, human-like emotional speech.", "AI": {"tldr": "本文提出了一种通过激活引导来控制情感的框架，使合成的情感语音更加自然和人性。", "motivation": "传统的文本转语音系统通常仅能生成单一情感表达的语音，无法体现人类言语中复杂多变的情感。因此，研究一种能够灵活且可控地生成多种混合情绪的系统具有重要意义。", "method": "本文提出了CoCoEmo框架，通过激活引导技术在TTS模型中实现可组合的情感控制，并设计了一套定量评估方法以确保合成语音的质量和自然度。", "result": "实验结果表明，情感韵律和表情变化主要由语言模块生成，而不是流量匹配模块；此外，该方法能够有效地产生自然且人性化的混合情绪合成语音。", "conclusion": "本文的研究成果展示了通过激活引导技术在TTS系统中实现复杂情感控制的潜力，并为未来的相关研究提供了新的方向。"}}
{"id": "2602.03418", "pdf": "https://arxiv.org/pdf/2602.03418", "abs": "https://arxiv.org/abs/2602.03418", "authors": ["Minsung Yoon", "Mincheul Kang", "Daehyung Park", "Sung-Eui Yoon"], "title": "Learning-based Initialization of Trajectory Optimization for Path-following Problems of Redundant Manipulators", "categories": ["cs.RO"], "comment": "Accepted to ICRA 2023. <a href=\"https://sgvr.kaist.ac.kr/~msyoon/papers/ICRA23_RLITG/\" rel=\"external noopener nofollow\" class=\"link-external link-https\">Project Page</a>", "summary": "Trajectory optimization (TO) is an efficient tool to generate a redundant manipulator's joint trajectory following a 6-dimensional Cartesian path. The optimization performance largely depends on the quality of initial trajectories. However, the selection of a high-quality initial trajectory is non-trivial and requires a considerable time budget due to the extremely large space of the solution trajectories and the lack of prior knowledge about task constraints in configuration space. To alleviate the issue, we present a learning-based initial trajectory generation method that generates high-quality initial trajectories in a short time budget by adopting example-guided reinforcement learning. In addition, we suggest a null-space projected imitation reward to consider null-space constraints by efficiently learning kinematically feasible motion captured in expert demonstrations. Our statistical evaluation in simulation shows the improved optimality, efficiency, and applicability of TO when we plug in our method's output, compared with three other baselines. We also show the performance improvement and feasibility via real-world experiments with a seven-degree-of-freedom manipulator.", "AI": {"tldr": "本文提出了一种基于学习的方法来生成冗余机械臂路径跟踪问题的初始轨迹，以提高路径优化效率。", "motivation": "为了改善冗余机械臂跟随6维笛卡尔路径时的路径优化性能，通过引入基于学习的方法快速生成高质量初始轨迹来解决这一问题。", "method": "采用示例引导增强学习方法生成高质初始轨迹，并结合空闲空间投影模仿奖励以考虑任务约束条件。", "result": "统计评估表明该方法在模拟和实际实验中均优于三种基准方案，显示出更优的优化效率与应用性。", "conclusion": "基于学习的方法能够有效提高冗余机械臂路径跟随问题中的初始轨迹质量，从而提升整体路径优化性能。"}}
{"id": "2602.03414", "pdf": "https://arxiv.org/pdf/2602.03414", "abs": "https://arxiv.org/abs/2602.03414", "authors": ["Zhengbo Jiao", "Shaobo Wang", "Zifan Zhang", "Wei Wang", "Bing Zhao", "Hu Wei", "Linfeng Zhang"], "title": "Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction", "categories": ["cs.CV", "cs.AI"], "comment": "18pages", "summary": "Multimodal Large Language Models (MLLMs) have significantly advanced vision-language understanding. However, even state-of-the-art models struggle with geometric reasoning, revealing a critical bottleneck: the extreme scarcity of high-quality image-text pairs. Human annotation is prohibitively expensive, while automated methods fail to ensure fidelity and training effectiveness. Existing approaches either passively adapt to available images or employ inefficient random exploration with filtering, decoupling generation from learning needs. We propose Socratic-Geo, a fully autonomous framework that dynamically couples data synthesis with model learning through multi-agent interaction. The Teacher agent generates parameterized Python scripts with reflective feedback (Reflect for solvability, RePI for visual validity), ensuring image-text pair purity. The Solver agent optimizes reasoning through preference learning, with failure paths guiding Teacher's targeted augmentation. Independently, the Generator learns image generation capabilities on accumulated \"image-code-instruction\" triplets, distilling programmatic drawing intelligence into visual generation. Starting from only 108 seed problems, Socratic-Solver achieves 49.11 on six benchmarks using one-quarter of baseline data, surpassing strong baselines by 2.43 points. Socratic-Generator achieves 42.4% on GenExam, establishing new state-of-the-art for open-source models, surpassing Seedream-4.0 (39.8%) and approaching Gemini-2.5-Flash-Image (43.1%).", "AI": {"tldr": "提出Socratic-Geo框架，通过多代理交互自动生成高质量的图像文本对，并优化几何推理能力。", "motivation": "解决视觉语言模型在几何推理方面的瓶颈问题，即缺乏高质图像文本配对数据，现有方法无法有效生成符合训练需求的数据。", "method": "Socratic-Geo框架包括三个代理：教师代理生成参数化Python脚本和反馈；求解器代理优化推理并通过失败路径指导教师进行针对性增强；独立的生成器通过积累“图像代码指令”三元组学习图像生成能力。", "result": "从108个种子问题开始，Socratic-Solver在六个基准上达到49.11分，超过基线2.43点；Socratic-Generator在GenExam上实现42.4%的准确率，超越现有开源模型并接近商用模型。", "conclusion": "通过多代理交互生成高质量图像文本对，显著提升视觉语言模型的几何推理能力。"}}
{"id": "2602.03410", "pdf": "https://arxiv.org/pdf/2602.03410", "abs": "https://arxiv.org/abs/2602.03410", "authors": ["Piotr Wójcik", "Maksym Petrenko", "Wojciech Gromski", "Przemysław Spurek", "Maciej Zieba"], "title": "UnHype: CLIP-Guided Hypernetworks for Dynamic LoRA Unlearning", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in large-scale diffusion models have intensified concerns about their potential misuse, particularly in generating realistic yet harmful or socially disruptive content. This challenge has spurred growing interest in effective machine unlearning, the process of selectively removing specific knowledge or concepts from a model without compromising its overall generative capabilities. Among various approaches, Low-Rank Adaptation (LoRA) has emerged as an effective and efficient method for fine-tuning models toward targeted unlearning. However, LoRA-based methods often exhibit limited adaptability to concept semantics and struggle to balance removing closely related concepts with maintaining generalization across broader meanings. Moreover, these methods face scalability challenges when multiple concepts must be erased simultaneously. To address these limitations, we introduce UnHype, a framework that incorporates hypernetworks into single- and multi-concept LoRA training. The proposed architecture can be directly plugged into Stable Diffusion as well as modern flow-based text-to-image models, where it demonstrates stable training behavior and effective concept control. During inference, the hypernetwork dynamically generates adaptive LoRA weights based on the CLIP embedding, enabling more context-aware, scalable unlearning. We evaluate UnHype across several challenging tasks, including object erasure, celebrity erasure, and explicit content removal, demonstrating its effectiveness and versatility. Repository: https://github.com/gmum/UnHype.", "AI": {"tldr": "介绍了一种基于CLIP的超网络框架UnHype，用于动态LoRA卸载以实现概念控制和内容移除。", "motivation": "解决大型扩散模型在生成现实但有害或社会破坏性内容时面临的潜在滥用问题，同时保持其整体生成能力。现有的LoRA方法存在适应性有限、难以平衡删除紧密相关概念与维护广泛意义之间的关系以及多概念同步移除的可扩展性挑战。", "method": "提出将超网络集成到单个和多个概念的LoRA训练中，通过CLIP嵌入动态生成适应性的LoRA权重，实现在推理时更具体上下文感知、可扩展的学习卸载。该架构可以直接应用于Stable Diffusion和其他现代文本到图像模型中。", "result": "在物体移除、名人移除和显式内容去除等多个挑战性任务上验证了UnHype的有效性和多功能性。", "conclusion": "UnHype提供了一种有效的方法来实现概念控制，同时保持大型扩散模型的生成能力。"}}
{"id": "2602.03406", "pdf": "https://arxiv.org/pdf/2602.03406", "abs": "https://arxiv.org/abs/2602.03406", "authors": ["Yuancheng Shao", "Yao Zhang", "Jia Gu", "Zixi Chen", "Di Wu", "Yuqiao Chen", "Bo Lu", "Wenjie Liu", "Cesare Stefanini", "Peng Qi"], "title": "Deep-Learning-Based Control of a Decoupled Two-Segment Continuum Robot for Endoscopic Submucosal Dissection", "categories": ["cs.RO"], "comment": null, "summary": "Manual endoscopic submucosal dissection (ESD) is technically demanding, and existing single-segment robotic tools offer limited dexterity. These limitations motivate the development of more advanced solutions. To address this, DESectBot, a novel dual segment continuum robot with a decoupled structure and integrated surgical forceps, enabling 6 degrees of freedom (DoFs) tip dexterity for improved lesion targeting in ESD, was developed in this work. Deep learning controllers based on gated recurrent units (GRUs) for simultaneous tip position and orientation control, effectively handling the nonlinear coupling between continuum segments, were proposed. The GRU controller was benchmarked against Jacobian based inverse kinematics, model predictive control (MPC), a feedforward neural network (FNN), and a long short-term memory (LSTM) network. In nested-rectangle and Lissajous trajectory tracking tasks, the GRU achieved the lowest position/orientation RMSEs: 1.11 mm/ 4.62° and 0.81 mm/ 2.59°, respectively. For orientation control at a fixed position (four target poses), the GRU attained a mean RMSE of 0.14 mm and 0.72°, outperforming all alternatives. In a peg transfer task, the GRU achieved a 100% success rate (120 success/120 attempts) with an average transfer time of 11.8s, the STD significantly outperforms novice-controlled systems. Additionally, an ex vivo ESD demonstration grasping, elevating, and resecting tissue as the scalpel completed the cut confirmed that DESectBot provides sufficient stiffness to divide thick gastric mucosa and an operative workspace adequate for large lesions.These results confirm that GRU-based control significantly enhances precision, reliability, and usability in ESD surgical training scenarios.", "AI": {"tldr": "本文提出了一种基于门控循环单元的深度学习控制器，用于双段连续机器人在内镜粘膜下剥离手术中的位置和姿态控制。", "motivation": "现有的单节段机器人工具在内镜粘膜下剥离（ESD）中操作复杂且灵活性有限，因此需要开发一种具有更高柔顺性的解决方案。本文设计了一种新型的双节段连续机器人——DESectBot，以解决这些问题，并通过深度学习控制提高手术精度。", "method": "采用基于门控循环单元（GRU）的深度学习控制器对DESectBot进行位置和姿态控制，并与逆雅可比方法、模型预测控制（MPC）、前馈神经网络（FNN）和长短期记忆网络（LSTM）进行了对比实验。在嵌套矩形和李萨如轨迹跟踪任务中，GRU表现出了最佳的精度。", "result": "实验结果表明，在嵌套矩形和李萨如轨迹跟踪任务中，GRU控制器实现了最低的位置误差1.11毫米/4.62度和姿态误差0.81毫米/2.59度。固定位置的姿态控制任务中，GRU达到了平均误差0.14毫米和0.72度，优于所有其他方法。在钉子转移实验中，GRU实现了100%的成功率（120次成功/120次尝试），平均转移时间为11.8秒，标准差显著低于新手操作。", "conclusion": "研究结果表明，基于GRU的深度学习控制大大提高了DESectBot在ESD手术中的精度、可靠性和可用性。"}}
{"id": "2602.03403", "pdf": "https://arxiv.org/pdf/2602.03403", "abs": "https://arxiv.org/abs/2602.03403", "authors": ["Guangming Lang", "Mingchuan Shang", "Mengjun Hu", "Jie Zhou", "Feng Xu"], "title": "Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations", "categories": ["cs.AI"], "comment": null, "summary": "In three-way conflict analysis, preference-based conflict situations characterize agents' attitudes towards issues by formally modeling their preferences over pairs of issues. However, existing preference-based conflict models rely exclusively on three qualitative relations, namely, preference, converse, and indifference, to describe agents' attitudes towards issue pairs, which significantly limits their capacity in capturing the essence of conflict. To overcome this limitation, we introduce the concept of an intuitionistic fuzzy preference-based conflict situation that captures agents' attitudes towards issue pairs with finer granularity than that afforded by classical preference-based models. Afterwards, we develop intuitionistic fuzzy preference-based conflict measures within this framework, and construct three-way conflict analysis models for trisecting the set of agent pairs, the agent set, and the issue set. Additionally, relative loss functions built on the proposed conflict functions are employed to calculate thresholds for three-way conflict analysis. Finally, we present adjustment mechanism-based feasible strategies that simultaneously account for both adjustment magnitudes and conflict degrees, together with an algorithm for constructing such feasible strategies, and provide an illustrative example to demonstrate the validity and effectiveness of the proposed model.", "AI": {"tldr": "该论文提出了基于直觉模糊偏好的冲突解决策略，以更精细地捕捉冲突的本质。", "motivation": "现有的偏好基础的冲突模型仅依赖三种定性关系来描述代理人对议题的态度，这限制了其在捕捉冲突本质方面的能力。", "method": "引入直觉模糊偏好为基础的冲突情况概念，发展相应的冲突测量方法，并构造三元分割分析模型。运用相对损失函数计算阈值并提出调整机制。", "result": "提出了基于调整幅度和冲突程度同时考虑的新策略，给出构建该策略的方法及实例验证其有效性和实用性。", "conclusion": "新的直觉模糊偏好基础的冲突解决方法能够更有效地捕捉和处理复杂的冲突情况。"}}
{"id": "2602.03402", "pdf": "https://arxiv.org/pdf/2602.03402", "abs": "https://arxiv.org/abs/2602.03402", "authors": ["Mengxuan Wang", "Yuxin Chen", "Gang Xu", "Tao He", "Hongjie Jiang", "Ming Li"], "title": "Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Vision language models (VLMs) extend the reasoning capabilities of large language models (LLMs) to cross-modal settings, yet remain highly vulnerable to multimodal jailbreak attacks. Existing defenses predominantly rely on safety fine-tuning or aggressive token manipulations, incurring substantial training costs or significantly degrading utility. Recent research shows that LLMs inherently recognize unsafe content in text, and the incorporation of visual inputs in VLMs frequently dilutes risk-related signals. Motivated by this, we propose Risk Awareness Injection (RAI), a lightweight and training-free framework for safety calibration that restores LLM-like risk recognition by amplifying unsafe signals in VLMs. Specifically, RAI constructs an Unsafe Prototype Subspace from language embeddings and performs targeted modulation on selected high-risk visual tokens, explicitly activating safety-critical signals within the cross-modal feature space. This modulation restores the model's LLM-like ability to detect unsafe content from visual inputs, while preserving the semantic integrity of original tokens for cross-modal reasoning. Extensive experiments across multiple jailbreak and utility benchmarks demonstrate that RAI substantially reduces attack success rate without compromising task performance.", "AI": {"tldr": "本文提出了一种称为风险意识注入（RAI）的框架，用于校准视觉语言模型的安全性而不损害其效用。", "motivation": "现有的安全防御措施成本高或会显著降低模型效用。因此，作者提出了一个轻量级、无训练的成本效益方法来增强视觉语言模型对危险内容的识别能力。", "method": "RAI通过构建不安全原型子空间并调整选定的风险视觉令牌来放大VLM中的风险信号，从而恢复大型语言模型在检测视觉输入中不安全内容的能力。", "result": "实验表明，与基线方法相比，RAI显著减少了攻击成功率而不影响任务性能。", "conclusion": "Risk Awareness Injection（RAI）框架提供了一种有效的、低成本的方法来增强VLM的安全性，同时保持其跨模态推理的效用。"}}
{"id": "2602.03400", "pdf": "https://arxiv.org/pdf/2602.03400", "abs": "https://arxiv.org/abs/2602.03400", "authors": ["Jintai Li", "Songqiang Chen", "Shuo Jin", "Xiaoyuan Xie"], "title": "Precision in Practice: Knowledge Guided Code Summarizing Grounded in Industrial Expectations", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code summaries are essential for helping developers understand code functionality and reducing maintenance and collaboration costs. Although recent advances in large language models (LLMs) have significantly improved automatic code summarization, the practical usefulness of generated summaries in industrial settings remains insufficiently explored. In collaboration with documentation experts from the industrial HarmonyOS project, we conducted a questionnaire study showing that over 57.4% of code summaries produced by state-of-the-art approaches were rejected due to violations of developers' expectations for industrial documentation. Beyond semantic similarity to reference summaries, developers emphasize additional requirements, including the use of appropriate domain terminology, explicit function categorization, and the avoidance of redundant implementation details. To address these expectations, we propose ExpSum, an expectation-aware code summarization approach that integrates function metadata abstraction, informative metadata filtering, context-aware domain knowledge retrieval, and constraint-driven prompting to guide LLMs in generating structured, expectation-aligned summaries. We evaluate ExpSum on the HarmonyOS project and widely used code summarization benchmarks. Experimental results show that ExpSum consistently outperforms all baselines, achieving improvements of up to 26.71% in BLEU-4 and 20.10% in ROUGE-L on HarmonyOS. Furthermore, LLM-based evaluations indicate that ExpSum-generated summaries better align with developer expectations across other projects, demonstrating its effectiveness for industrial code documentation.", "AI": {"tldr": "本文提出了ExpSum，一种基于期望感知的代码总结方法，旨在提高大型语言模型生成的代码摘要在工业环境中的实用性。", "motivation": "尽管最近的大规模语言模型显著提高了自动代码总结的质量，但这些生成的摘要在实际工业应用中仍然未能满足开发人员的需求和预期。为了填补这一差距，本文通过问卷调查识别了当前方法中存在的问题，并提出了新的解决方案来改进代码摘要。", "method": "ExpSum结合了函数元数据抽象、有用元信息过滤、上下文感知领域知识检索以及约束驱动的提示策略，以指导大规模语言模型生成结构化且符合预期的代码摘要。", "result": "在HarmonyOS项目和广泛使用的代码总结基准上进行的实验表明，ExpSum显著优于所有基线方法，在BLEU-4得分方面提高了26.71%，在ROUGE-L得分方面提高了20.1%。此外，基于LLM的评估显示，ExpSum生成的摘要更好地符合开发人员对其他项目的期望。", "conclusion": "本文通过提出ExpSum来解决代码总结的实际应用问题，并证明了其方法的有效性，有助于提高工业环境中的代码维护和协作效率。"}}
{"id": "2602.03397", "pdf": "https://arxiv.org/pdf/2602.03397", "abs": "https://arxiv.org/abs/2602.03397", "authors": ["Minsung Yoon", "Sung-Eui Yoon"], "title": "Enhancing Navigation Efficiency of Quadruped Robots via Leveraging Personal Transportation Platforms", "categories": ["cs.RO"], "comment": "Accepted to ICRA 2025. <a href=\"https://sgvr.kaist.ac.kr/~msyoon/papers/ICRA25/\" rel=\"external noopener nofollow\" class=\"link-external link-https\">Project Page</a>", "summary": "Quadruped robots face limitations in long-range navigation efficiency due to their reliance on legs. To ameliorate the limitations, we introduce a Reinforcement Learning-based Active Transporter Riding method (\\textit{RL-ATR}), inspired by humans' utilization of personal transporters, including Segways. The \\textit{RL-ATR} features a transporter riding policy and two state estimators. The policy devises adequate maneuvering strategies according to transporter-specific control dynamics, while the estimators resolve sensor ambiguities in non-inertial frames by inferring unobservable robot and transporter states. Comprehensive evaluations in simulation validate proficient command tracking abilities across various transporter-robot models and reduced energy consumption compared to legged locomotion. Moreover, we conduct ablation studies to quantify individual component contributions within the \\textit{RL-ATR}. This riding ability could broaden the locomotion modalities of quadruped robots, potentially expanding the operational range and efficiency.", "AI": {"tldr": "通过引入基于强化学习的主动运输者骑行方法（RL-ATR），提高四足机器人在长距离导航中的效率。", "motivation": "为了克服四足机器人由于依赖腿部而导致的长距离导航效率低下的问题，提出了结合个人交通工具利用情况的方法来提升其移动能力。", "method": "提出了一种基于强化学习的主动运输者骑行方法（RL-ATR），包括一个骑乘策略和两个状态估计器。该策略根据特定控制动力学制定有效的操纵策略，而估测器则通过推断非惯性框架中不可观察的机器人和运载工具的状态来解决传感器歧义问题。", "result": "模拟评估表明，RL-ATR能够有效跟踪指令并且与腿部移动相比显著减少能量消耗。此外，通过消融研究量化了方法内部各个组件的作用。", "conclusion": "骑乘能力可以扩展四足机器人的运动模式，并可能扩大其操作范围和效率。"}}
{"id": "2602.03392", "pdf": "https://arxiv.org/pdf/2602.03392", "abs": "https://arxiv.org/abs/2602.03392", "authors": ["Shumin Wang", "Yuexiang Xie", "Wenhao Zhang", "Yuchang Sun", "Yanxi Chen", "Yaliang Li", "Yanyong Zhang"], "title": "On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Entropy serves as a critical metric for measuring the diversity of outputs generated by large language models (LLMs), providing valuable insights into their exploration capabilities. While recent studies increasingly focus on monitoring and adjusting entropy to better balance exploration and exploitation in reinforcement fine-tuning (RFT), a principled understanding of entropy dynamics during this process is yet to be thoroughly investigated. In this paper, we establish a theoretical framework for analyzing the entropy dynamics during the RFT process, which begins with a discriminant expression that quantifies entropy change under a single logit update. This foundation enables the derivation of a first-order expression for entropy change, which can be further extended to the update formula of Group Relative Policy Optimization (GRPO). The corollaries and insights drawn from the theoretical analysis inspire the design of entropy control methods, and also offer a unified lens for interpreting various entropy-based methods in existing studies. We provide empirical evidence to support the main conclusions of our analysis and demonstrate the effectiveness of the derived entropy-discriminator clipping methods. This study yields novel insights into RFT training dynamics, providing theoretical support and practical strategies for optimizing the exploration-exploitation balance during LLM fine-tuning.", "AI": {"tldr": "本文建立了理论框架来分析在强化微调过程中大型语言模型的熵动力学。", "motivation": "当前研究缺乏对大型语言模型在强化微调过程中的熵变化原理性理解，本文旨在填补这一空白。", "method": "通过建立一个区分表达式量化单个logit更新时熵的变化，并推导出一阶熵变化公式，进一步扩展至Group Relative Policy Optimization的更新公式。", "result": "实验验证了理论分析的主要结论，并展示了所提出的熵控制方法的有效性。", "conclusion": "这项研究提供了关于强化微调训练动态的新见解，为优化探索与利用之间的平衡提供了理论支持和实用策略。"}}
{"id": "2602.03390", "pdf": "https://arxiv.org/pdf/2602.03390", "abs": "https://arxiv.org/abs/2602.03390", "authors": ["Hyun Seok Seong", "WonJun Moon", "Jae-Pil Heo"], "title": "From Vicious to Virtuous Cycles: Synergistic Representation Learning for Unsupervised Video Object-Centric Learning", "categories": ["cs.CV", "cs.LG"], "comment": "ICLR 2026; Code is available at https://github.com/hynnsk/SRL", "summary": "Unsupervised object-centric learning models, particularly slot-based architectures, have shown great promise in decomposing complex scenes. However, their reliance on reconstruction-based training creates a fundamental conflict between the sharp, high-frequency attention maps of the encoder and the spatially consistent but blurry reconstruction maps of the decoder. We identify that this discrepancy gives rise to a vicious cycle: the noisy feature map from the encoder forces the decoder to average over possibilities and produce even blurrier outputs, while the gradient computed from blurry reconstruction maps lacks high-frequency details necessary to supervise encoder features. To break this cycle, we introduce Synergistic Representation Learning (SRL) that establishes a virtuous cycle where the encoder and decoder mutually refine one another. SRL leverages the encoder's sharpness to deblur the semantic boundary within the decoder output, while exploiting the decoder's spatial consistency to denoise the encoder's features. This mutual refinement process is stabilized by a warm-up phase with a slot regularization objective that initially allocates distinct entities per slot. By bridging the representational gap between the encoder and decoder, SRL achieves state-of-the-art results on video object-centric learning benchmarks. Codes are available at https://github.com/hynnsk/SRL.", "AI": {"tldr": "该论文提出了一种名为协同表示学习（SRL）的方法，用于解决无监督视频对象中心化学习中的编码器和解码器之间的表征差距问题。", "motivation": "传统的基于槽的架构在分解复杂场景方面表现出色，但其依赖于重建训练导致了编码器与解码器之间的冲突。为了解决这一问题，论文提出了SRL方法以建立一个良性循环，促进两者互相改进。", "method": "SRL利用编码器的清晰性去除解码器输出中的模糊边界，并通过解码器的空间一致性来降低编码器特征中的噪声。此过程由初始阶段的槽正则化目标稳定，确保每个槽分配到不同的实体。", "result": "该方法在视频对象中心化学习基准上达到了最先进的结果。", "conclusion": "SRL成功解决了无监督视频对象中心化学习中编码器和解码器之间的表征差距问题，并取得了优于现有技术的性能。"}}
{"id": "2602.03389", "pdf": "https://arxiv.org/pdf/2602.03389", "abs": "https://arxiv.org/abs/2602.03389", "authors": ["Jinwoo Choi", "Sang-Hyun Lee", "Seung-Woo Seo"], "title": "Chain-of-Goals Hierarchical Policy for Long-Horizon Offline Goal-Conditioned RL", "categories": ["cs.LG", "cs.AI"], "comment": "22 pages", "summary": "Offline goal-conditioned reinforcement learning remains challenging for long-horizon tasks. While hierarchical approaches mitigate this issue by decomposing tasks, most existing methods rely on separate high- and low-level networks and generate only a single intermediate subgoal, making them inadequate for complex tasks that require coordinating multiple intermediate decisions. To address this limitation, we draw inspiration from the chain-of-thought paradigm and propose the Chain-of-Goals Hierarchical Policy (CoGHP), a novel framework that reformulates hierarchical decision-making as autoregressive sequence modeling within a unified architecture. Given a state and a final goal, CoGHP autoregressively generates a sequence of latent subgoals followed by the primitive action, where each latent subgoal acts as a reasoning step that conditions subsequent predictions. To implement this efficiently, we pioneer the use of an MLP-Mixer backbone, which supports cross-token communication and captures structural relationships among state, goal, latent subgoals, and action. Across challenging navigation and manipulation benchmarks, CoGHP consistently outperforms strong offline baselines, demonstrating improved performance on long-horizon tasks.", "AI": {"tldr": "提出了一种新的框架Chain-of-Goals Hierarchical Policy（CoGHP），通过自回归序列建模来解决长期任务中的离线目标条件强化学习问题。", "motivation": "现有的分层方法在处理复杂需要协调多个中间决策的任务时表现不足，因此提出了CoGHP以改善长时序任务的表现。", "method": "将层次化决策转化为自回归序列模型，并采用MLP-Mixer骨干网络来支持状态、目标、潜在子目标和动作之间的跨令牌通信。通过给定初始状态和最终目标，CoGHP生成一系列潜意识的子目标然后执行原始行动。", "result": "在具有挑战性的导航和操作基准上，CoGHP的表现优于离线基线模型，在长时序任务上表现出色。", "conclusion": "本文提出的方法有效地解决了长期任务中的离线目标条件强化学习问题，展示了其在复杂场景下的优越性能。"}}
{"id": "2602.03387", "pdf": "https://arxiv.org/pdf/2602.03387", "abs": "https://arxiv.org/abs/2602.03387", "authors": ["Zhengwei Ni", "Zhidu Li", "Wei Chen", "Zhaoyang Zhang", "Zehua Wang", "F. Richard Yu", "Victor C. M. Leung"], "title": "Toward a Sustainable Federated Learning Ecosystem: A Practical Least Core Mechanism for Payoff Allocation", "categories": ["cs.GT", "cs.AI"], "comment": "7 pages, 3 figures, submitted to IEEE Network", "summary": "Emerging network paradigms and applications increasingly rely on federated learning (FL) to enable collaborative intelligence while preserving privacy. However, the sustainability of such collaborative environments hinges on a fair and stable payoff allocation mechanism. Focusing on coalition stability, this paper introduces a payoff allocation framework based on the least core (LC) concept. Unlike traditional methods, the LC prioritizes the cohesion of the federation by minimizing the maximum dissatisfaction among all potential subgroups, ensuring that no participant has an incentive to break away. To adapt this game-theoretic concept to practical, large-scale networks, we propose a streamlined implementation with a stack-based pruning algorithm, effectively balancing computational efficiency with allocation precision. Case studies in federated intrusion detection demonstrate that our mechanism correctly identifies pivotal contributors and strategic alliances. The results confirm that the practical LC framework promotes stable collaboration and fosters a sustainable FL ecosystem.", "AI": {"tldr": "本文提出了一种基于最小核心概念的联邦学习支付分配框架，旨在促进协作智能并确保隐私。通过引入堆栈修剪算法来提高其实用性和效率。", "motivation": "为了保证联邦学习环境中合作的可持续性，需要一种公平且稳定的支付分配机制。传统方法无法有效解决潜在子群体的最大不满问题。", "method": "本文提出了一个基于最小核心概念的支付分配框架，并设计了一种堆栈修剪算法来提高其实用性和效率。", "result": "实验结果表明该机制能够正确识别关键贡献者和战略联盟，促进了稳定的协作并建立了可持续的联邦学习生态系统。", "conclusion": "通过引入最小核心概念及其实用实现，本文为建立一个稳定且公平的支付分配机制提供了有效的解决方案。"}}
{"id": "2602.03386", "pdf": "https://arxiv.org/pdf/2602.03386", "abs": "https://arxiv.org/abs/2602.03386", "authors": ["Leif Doering", "Daniel Schmidt", "Moritz Melcher", "Sebastian Kassing", "Benedikt Wille", "Tilman Aach", "Simon Weissmann"], "title": "An Approximate Ascent Approach To Prove Convergence of PPO", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Proximal Policy Optimization (PPO) is among the most widely used deep reinforcement learning algorithms, yet its theoretical foundations remain incomplete. Most importantly, convergence and understanding of fundamental PPO advantages remain widely open. Under standard theory assumptions we show how PPO's policy update scheme (performing multiple epochs of minibatch updates on multi-use rollouts with a surrogate gradient) can be interpreted as approximated policy gradient ascent. We show how to control the bias accumulated by the surrogate gradients and use techniques from random reshuffling to prove a convergence theorem for PPO that sheds light on PPO's success. Additionally, we identify a previously overlooked issue in truncated Generalized Advantage Estimation commonly used in PPO. The geometric weighting scheme induces infinite mass collapse onto the longest $k$-step advantage estimator at episode boundaries. Empirical evaluations show that a simple weight correction can yield substantial improvements in environments with strong terminal signal, such as Lunar Lander.", "AI": {"tldr": "该论文证明了PPO算法的收敛性，并提出了一种改进的加权方案以提高其在特定环境下的性能。", "motivation": "尽管PPO是广泛使用的一种深度强化学习算法，但其理论基础尚不完善。研究者希望通过分析其政策更新方案来理解PPO的优势并证明其收敛性。", "method": "通过标准理论假设，论文展示了PPO的政策更新机制可以被解释为近似策略梯度上升。同时探讨了截断泛化优势估计中一个被忽视的问题，并提出了一种简单的加权修正方法以改善性能。", "result": "证明了PPO算法在标准理论条件下的收敛性，并通过实验证明了一个简单的权重调整可以在具有强烈终止信号的环境中（例如Lunar Lander）显著提高其表现。", "conclusion": "论文为理解PPO的成功提供了重要的理论支持，并提出了一种改进的方法，这有助于增强该算法的应用效果。"}}
{"id": "2602.03380", "pdf": "https://arxiv.org/pdf/2602.03380", "abs": "https://arxiv.org/abs/2602.03380", "authors": ["Hao Fang", "Jinyu Li", "Jiawei Kong", "Tianqu Zhuang", "Kuofeng Gao", "Bin Chen", "Shu-Tao Xia", "Yaowei Wang"], "title": "Seeing Through the Chain: Mitigate Hallucination in Multimodal Reasoning Models via CoT Compression and Contrastive Preference Optimization", "categories": ["cs.CV"], "comment": null, "summary": "While multimodal reasoning models (MLRMs) have exhibited impressive capabilities, they remain prone to hallucinations, and effective solutions are still underexplored. In this paper, we experimentally analyze the hallucination cause and propose C3PO, a training-based mitigation framework comprising \\textbf{C}hain-of-Thought \\textbf{C}ompression and \\textbf{C}ontrastive \\textbf{P}reference \\textbf{O}ptimization. Firstly, we identify that introducing reasoning mechanisms exacerbates models' reliance on language priors while overlooking visual inputs, which can produce CoTs with reduced visual cues but redundant text tokens. To this end, we propose to selectively filter redundant thinking tokens for a more compact and signal-efficient CoT representation that preserves task-relevant information while suppressing noise. In addition, we observe that the quality of the reasoning trace largely determines whether hallucination emerges in subsequent responses. To leverage this insight, we introduce a reasoning-enhanced preference tuning scheme that constructs training pairs using high-quality AI feedback. We further design a multimodal hallucination-inducing mechanism that elicits models' inherent hallucination patterns via carefully crafted inducers, yielding informative negative signals for contrastive correction. We provide theoretical justification for the effectiveness and demonstrate consistent hallucination reduction across diverse MLRMs and benchmarks.", "AI": {"tldr": "提出C3PO框架，通过压缩链式思考和对比偏好优化来减轻多模态推理模型中的幻觉问题。", "motivation": "虽然多模态推理模型表现出强大的能力，但仍然容易出现幻觉。引入推理机制会加剧模型对语言先验的依赖而忽视视觉输入，产生包含冗余文本标记而缺乏视觉线索的链式思考（CoT），因此需要有效的方法来减轻这种问题。", "method": "提出C3PO框架，通过压缩链式思考和对比偏好优化来解决幻觉问题。包括选择性过滤冗余思维标记以获得更紧凑且信号高效的CoT表示，并设计一种多模态诱导机制，通过精心构造的诱因促使模型产生内在的幻觉模式。", "result": "实验结果表明C3PO框架能够有效地降低各种多模态推理模型中的幻觉水平。", "conclusion": "通过理论分析和实验证明了所提出的C3PO框架的有效性，并展示了在不同多模态推理模型和基准上的幻觉减少效果。"}}
{"id": "2602.03379", "pdf": "https://arxiv.org/pdf/2602.03379", "abs": "https://arxiv.org/abs/2602.03379", "authors": ["Sangyeon Yoon", "Hyesoo Hong", "Wonje Jeung", "Albert No"], "title": "Rethinking Benign Relearning: Syntax as the Hidden Driver of Unlearning Failures", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICLR 2026", "summary": "Machine unlearning aims to remove specific content from trained models while preserving overall performance. However, the phenomenon of benign relearning, in which forgotten information reemerges even from benign fine-tuning data, reveals that existing unlearning methods remain fundamentally fragile. A common explanation attributes this effect to topical relevance, but we find this account insufficient. Through systematic analysis, we demonstrate that syntactic similarity, rather than topicality, is the primary driver: across benchmarks, syntactically similar data consistently trigger recovery even without topical overlap, due to their alignment in representations and gradients with the forgotten content. Motivated by this insight, we introduce syntactic diversification, which paraphrases the original forget queries into heterogeneous structures prior to unlearning. This approach effectively suppresses benign relearning, accelerates forgetting, and substantially alleviates the trade-off between unlearning efficacy and model utility.", "AI": {"tldr": "重新思考良性重新学习现象，提出句法是触发遗忘信息恢复的主要因素，并引入句法多样化策略以抑制这一现象。", "motivation": "揭示现有卸载方法的脆弱性，通过系统分析发现句法规则而非主题相关性才是导致忘记内容重新出现的关键。", "method": "通过对多个基准进行分析，证明了句法相似性是触发遗忘信息恢复的主要因素。进而提出一种新的策略——句法多样化，将原始遗忘查询转化为异构结构以抑制良性重新学习现象，并通过实验验证其有效性。", "result": "该方法有效抑制了良性重新学习，加速了模型的忘记过程，并大幅缓解了卸载效率与模型实用性之间的权衡问题。", "conclusion": "句法相似性是触发遗忘信息恢复的主要因素。引入句法多样化策略可更有效地管理机器学习中的数据删除，同时保持整体性能和实用性。"}}
{"id": "2602.03376", "pdf": "https://arxiv.org/pdf/2602.03376", "abs": "https://arxiv.org/abs/2602.03376", "authors": ["Constantin Selzer", "Fabina B. Flohr"], "title": "PlanTRansformer: Unified Prediction and Planning with Goal-conditioned Transformer", "categories": ["cs.RO", "cs.CV"], "comment": "Submitted and accepted at IEEE IV 2026", "summary": "Trajectory prediction and planning are fundamental yet disconnected components in autonomous driving. Prediction models forecast surrounding agent motion under unknown intentions, producing multimodal distributions, while planning assumes known ego objectives and generates deterministic trajectories. This mismatch creates a critical bottleneck: prediction lacks supervision for agent intentions, while planning requires this information. Existing prediction models, despite strong benchmarking performance, often remain disconnected from planning constraints such as collision avoidance and dynamic feasibility. We introduce Plan TRansformer (PTR), a unified Gaussian Mixture Transformer framework integrating goal-conditioned prediction, dynamic feasibility, interaction awareness, and lane-level topology reasoning. A teacher-student training strategy progressively masks surrounding agent commands during training to align with inference conditions where agent intentions are unavailable. PTR achieves 4.3%/3.5% improvement in marginal/joint mAP compared to the baseline Motion Transformer (MTR) and 15.5% planning error reduction at 5s horizon compared to GameFormer. The architecture-agnostic design enables application to diverse Transformer-based prediction models. Project Website: https://github.com/SelzerConst/PlanTRansformer", "AI": {"tldr": "本文提出了PlanTRansformer，一种统一的预测和规划框架，用于解决自动驾驶中轨迹预测和规划脱节的问题。", "motivation": "传统预测模型无法直接获得代理意图，而规划算法需要这些信息来避免碰撞和动态可行性问题。现有方法存在瓶颈，缺乏监督训练代理意图的能力，同时难以满足规划约束。", "method": "PlanTRansformer采用了一个基于目标条件的Gaussian Mixture Transformer框架，实现了预测、动态可行性和交互感知的一体化设计，并通过教师-学生策略进行训练以模拟实际推断环境。", "result": "在mAP指标上优于MotionTransformer，且显著降低了规划误差。该架构可以应用于各种Transformer基线的预测模型。", "conclusion": "PlanTRansformer解决了现有方法中的瓶颈问题，提高了轨迹预测和规划的一致性和有效性。"}}
{"id": "2602.03374", "pdf": "https://arxiv.org/pdf/2602.03374", "abs": "https://arxiv.org/abs/2602.03374", "authors": ["Danqing Shi", "Lan Jiang", "Katherine M. Collins", "Shangzhe Wu", "Ayush Tewari", "Miri Zilka"], "title": "How do people watch AI-generated videos of physical scenes?", "categories": ["cs.HC"], "comment": null, "summary": "The growing prevalence of realistic AI-generated videos on media platforms increasingly blurs the line between fact and fiction, eroding public trust. Understanding how people watch AI-generated videos offers a human-centered perspective for improving AI detection and guiding advancements in video generation. However, existing studies have not investigated human gaze behavior in response to AI-generated videos of physical scenes. Here, we collect and analyze the eye movements from 40 participants during video understanding and AI detection tasks involving a mix of real-world and AI-generated videos. We find that given the high realism of AI-generated videos, gaze behavior is driven less by the video's actual authenticity and more by the viewer's perception of its authenticity. Our results demonstrate that the mere awareness of potential AI generation may alter media consumption from passive viewing into an active search for anomalies.", "AI": {"tldr": "研究通过分析参与者观看真实世界和AI生成视频时的眼动行为，探讨人们如何辨别AI生成的视频。", "motivation": "随着逼真的AI生成视频在媒体平台上的普及，公众信任受到侵蚀。了解人们对这些视频的认知有助于改进AI检测并指导视频生成技术的发展。", "method": "研究人员收集了40名参与者在观看真实世界和AI生成视频时的眼动数据，并分析他们进行视频理解和AI识别任务中的行为差异。", "result": "结果显示，由于AI生成视频的高逼真度，观众的眼动行为更多地受到其感知到的真实性影响，而不是实际真实性。意识到潜在的人工智能生成可能导致媒体消费从被动观看转变为积极寻找异常。", "conclusion": "研究表明，人们对AI生成视频的认知与实际内容的真实性不同，并且他们可能会更加主动地检查这些视频中的细节和不一致性。"}}
{"id": "2602.03373", "pdf": "https://arxiv.org/pdf/2602.03373", "abs": "https://arxiv.org/abs/2602.03373", "authors": ["Jiale Meng", "Runyi Hu", "Jie Zhang", "Zheming Lu", "Ivor Tsang", "Tianwei Zhang"], "title": "Unifying Watermarking via Dimension-Aware Mapping", "categories": ["cs.CV"], "comment": "29 pages, 25 figures", "summary": "Deep watermarking methods often share similar encoder-decoder architectures, yet differ substantially in their functional behaviors. We propose DiM, a new multi-dimensional watermarking framework that formulates watermarking as a dimension-aware mapping problem, thereby unifying existing watermarking methods at the functional level. Under DiM, watermark information is modeled as payloads of different dimensionalities, including one-dimensional binary messages, two-dimensional spatial masks, and three-dimensional spatiotemporal structures. We find that the dimensional configuration of embedding and extraction largely determines the resulting watermarking behavior. Same-dimensional mappings preserve payload structure and support fine-grained control, while cross-dimensional mappings enable spatial or spatiotemporal localization. We instantiate DiM in the video domain, where spatiotemporal representations enable a broader set of dimension mappings. Experiments demonstrate that varying only the embedding and extraction dimensions, without architectural changes, leads to different watermarking capabilities, including spatiotemporal tamper localization, local embedding control, and recovery of temporal order under frame disruptions.", "AI": {"tldr": "本文提出了DiM框架，将水印嵌入和提取视为维度感知映射问题，从而统一了现有的水印方法。", "motivation": "深度水印技术虽然有相似的编码解码架构，但在功能性行为上差异较大。为了统一定制化需求与设计自由度，作者提出了一个新颖的多维框架DiM。", "method": "该框架将水印信息表示为不同维度的数据结构，并通过调整嵌入和提取维度来实现不同的水印功能。例如，相同维度映射保持负载结构并支持精细控制；跨维度映射则使空间或时空定位成为可能。", "result": "实验表明，仅改变嵌入与提取的维度而不改变架构即可获得不同的水印能力，包括时间空域篡改定位、局部嵌入控制以及帧中断下的时序恢复。", "conclusion": "DiM框架通过统一现有深度水印方法的功能层面，展示出广泛的适用性和灵活性。"}}
{"id": "2602.03372", "pdf": "https://arxiv.org/pdf/2602.03372", "abs": "https://arxiv.org/abs/2602.03372", "authors": ["Mario Pascual-González", "Ariadna Jiménez-Partinen", "R. M. Luque-Baena", "Fátima Nagib-Raya", "Ezequiel López-Rubio"], "title": "SLIM-Diff: Shared Latent Image-Mask Diffusion with Lp loss for Data-Scarce Epilepsy FLAIR MRI", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 2 figures, 1 table, conference paper", "summary": "Focal cortical dysplasia (FCD) lesions in epilepsy FLAIR MRI are subtle and scarce, making joint image--mask generative modeling prone to instability and memorization. We propose SLIM-Diff, a compact joint diffusion model whose main contributions are (i) a single shared-bottleneck U-Net that enforces tight coupling between anatomy and lesion geometry from a 2-channel image+mask representation, and (ii) loss-geometry tuning via a tunable $L_p$ objective. As an internal baseline, we include the canonical DDPM-style objective ($ε$-prediction with $L_2$ loss) and isolate the effect of prediction parameterization and $L_p$ geometry under a matched setup. Experiments show that $x_0$-prediction is consistently the strongest choice for joint synthesis, and that fractional sub-quadratic penalties ($L_{1.5}$) improve image fidelity while $L_2$ better preserves lesion mask morphology. Our code and model weights are available in https://github.com/MarioPasc/slim-diff", "AI": {"tldr": "提出SLIM-Diff模型，用于癫痫FLAIR MRI中的FCD病灶检测与生成", "motivation": "现有方法在稀疏数据下难以稳定地联合图像-掩膜生成建模，导致不稳定性和过度拟合问题", "method": "设计共享瓶颈U-Net结构，并通过调整$L_p$损失函数来优化模型性能，实验对比了不同损失函数的效果", "result": "发现$x_0$预测对于联合合成是最强的选择，而分数次非二次惩罚改善图像保真度，$L_2$则更好保持病灶掩膜形态", "conclusion": "SLIM-Diff在稀疏数据下具有稳定性和优越性能"}}
{"id": "2602.03371", "pdf": "https://arxiv.org/pdf/2602.03371", "abs": "https://arxiv.org/abs/2602.03371", "authors": ["Zhiwen Yang", "Yuxin Peng"], "title": "Multi-Resolution Alignment for Voxel Sparsity in Camera-Based 3D Semantic Scene Completion", "categories": ["cs.CV"], "comment": "15 pages, 6 figures, accepted by TIP 2026", "summary": "Camera-based 3D semantic scene completion (SSC) offers a cost-effective solution for assessing the geometric occupancy and semantic labels of each voxel in the surrounding 3D scene with image inputs, providing a voxel-level scene perception foundation for the perception-prediction-planning autonomous driving systems. Although significant progress has been made in existing methods, their optimization rely solely on the supervision from voxel labels and face the challenge of voxel sparsity as a large portion of voxels in autonomous driving scenarios are empty, which limits both optimization efficiency and model performance. To address this issue, we propose a \\textit{Multi-Resolution Alignment (MRA)} approach to mitigate voxel sparsity in camera-based 3D semantic scene completion, which exploits the scene and instance level alignment across multi-resolution 3D features as auxiliary supervision. Specifically, we first propose the Multi-resolution View Transformer module, which projects 2D image features into multi-resolution 3D features and aligns them at the scene level through fusing discriminative seed features. Furthermore, we design the Cubic Semantic Anisotropy module to identify the instance-level semantic significance of each voxel, accounting for the semantic differences of a specific voxel against its neighboring voxels within a cubic area. Finally, we devise a Critical Distribution Alignment module, which selects critical voxels as instance-level anchors with the guidance of cubic semantic anisotropy, and applies a circulated loss for auxiliary supervision on the critical feature distribution consistency across different resolutions. The code is available at https://github.com/PKU-ICST-MIPL/MRA_TIP.", "AI": {"tldr": "本文提出了一种多分辨率对齐方法，以解决相机基于3D语义场景补全中的体素稀疏问题。", "motivation": "现有的相机基于3D语义场景补全方法依赖于体素标签的监督，但由于自动驾驶环境中的大量体素为空白，导致优化效率低和模型性能受限。为了解决这个问题，作者提出了多分辨率对齐的方法来减少体素稀疏性。", "method": "本文提出了一种多分辨率视图转换器模块将2D图像特征投影到多分辨率3D特征并进行场景级别的对齐；设计了立方语义各向异性模块来识别每个体素的实例级别语义重要性，考虑一个特定体素相对于其周围邻居体素之间的语义差异；最后提出关键分布对齐模块选择临界体素作为实例级别的锚点，并应用循环损失进行辅助监督以确保不同分辨率下的特征分布一致性。", "result": "该方法通过在多分辨率3D特征之间执行场景和实例级对齐，显著提高了模型的优化效率和性能。", "conclusion": "本文提出的多分辨率对齐方法能够有效地减少体素稀疏性，并提高相机基于3D语义场景补全任务中的模型性能。"}}
{"id": "2602.03370", "pdf": "https://arxiv.org/pdf/2602.03370", "abs": "https://arxiv.org/abs/2602.03370", "authors": ["Takaya Kawakatsu", "Ryo Ishiyama"], "title": "Symbol-Aware Reasoning with Masked Discrete Diffusion for Handwritten Mathematical Expression Recognition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Handwritten Mathematical Expression Recognition (HMER) requires reasoning over diverse symbols and 2D structural layouts, yet autoregressive models struggle with exposure bias and syntactic inconsistency. We present a discrete diffusion framework that reformulates HMER as iterative symbolic refinement instead of sequential generation. Through multi-step remasking, the proposal progressively refines both symbols and structural relations, removing causal dependencies and improving structural consistency. A symbol-aware tokenization and Random-Masking Mutual Learning further enhance syntactic alignment and robustness to handwriting diversity. On the MathWriting benchmark, the proposal achieves 5.56\\% CER and 60.42\\% EM, outperforming strong Transformer and commercial baselines. Consistent gains on CROHME 2014--2023 demonstrate that discrete diffusion provides a new paradigm for structure-aware visual recognition beyond generative modeling.", "AI": {"tldr": "该论文提出了一种基于离散扩散框架的手写数学表达式识别方法，通过迭代符号细化而非顺序生成来提高结构一致性。", "motivation": "传统的自回归模型在手写数学表达式识别中存在暴露偏差和语法不一致问题，因此提出了新的离散扩散框架以改进这些问题。", "method": "该论文采用多步掩码技术和符号感知的分词方法，并通过随机掩码相互学习进一步增强语法对齐和对手写多样性的鲁棒性。", "result": "在MathWriting基准测试中，提出的模型取得了5.56% CER和60.42% EM的优异成绩，优于Transformer和其他商业基线。同时，在CROHME 2014--2023上的一致增益显示离散扩散提供了超越生成建模的新结构感知视觉识别范式。", "conclusion": "该论文证明了基于离散扩散框架的手写数学表达式识别方法在提高语法一致性方面有显著优势，为结构感知的视觉识别提供了一种新的思路。"}}
