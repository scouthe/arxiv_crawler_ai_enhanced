{"id": "2601.23095", "pdf": "https://arxiv.org/pdf/2601.23095", "abs": "https://arxiv.org/abs/2601.23095", "authors": ["Junyi Li", "Zhaoxi Zhang", "Tamir Mendel", "Takahiro Yabe"], "title": "Exploring Sidewalk Sheds in New York City through Chatbot Surveys and Human Computer Interaction", "categories": ["cs.HC", "cs.CY"], "comment": null, "summary": "Sidewalk sheds are a common feature of the streetscape in New York City, reflecting ongoing construction and maintenance activities. However, policymakers and local business owners have raised concerns about reduced storefront visibility and altered pedestrian navigation. Although sidewalk sheds are widely used for safety, their effects on pedestrian visibility and movement are not directly measured in current planning practices. To address this, we developed an AI-based chatbot survey that collects image-based annotations and route choices from pedestrians, linking these responses to specific shed design features, including clearance height, post spacing, and color. This AI chatbot survey integrates a large language model (e.g., Google's Gemini-1.5-flash-001 model) with an image-annotation interface, allowing users to interact with street images, mark visual elements, and provide structured feedback through guided dialogue. To explore pedestrian perceptions and behaviors, this paper conducts a grid-based analysis of entrance annotations and applies logistic mixed-effects modeling to assess sidewalk choice patterns. Analysis of the dataset (n = 25) shows that: (1) the presence of scaffolding significantly reduces pedestrians' ability to identify ground-floor retail entrances, and (2) variations in weather conditions and shed design features significantly influence sidewalk selection behavior. By integrating generative AI into urban research, this study demonstrates a novel method for evaluating sidewalk shed designs and provides empirical evidence to support adjustments to shed guidelines that improve the pedestrian experience without compromising safety.", "AI": {"tldr": "通过聊天机器人调查和人机交互研究纽约市的人行道棚对行人可见性和移动性的影响。", "motivation": "政策制定者和当地商业主担心人行道棚减少了店面前沿的可见度并改变了行人导航。当前规划实践中未直接测量这些影响，因此需要一种方法来评估人行道棚设计的效果。", "method": "开发了一种基于AI的聊天机器人调查，通过图像注释界面收集来自行人的图像标注和路线选择，并将这些响应与特定的人行道棚特征（如高度、柱间距和颜色）相关联。该调查整合了大型语言模型（例如Google的Gemini-1.5-flash-001），并使用网格分析入口标签，应用逻辑混合效应建模来评估人行道选择模式。", "result": "根据25个数据集的分析显示：（1）脚手架的存在显著减少了行人识别地面零售店入口的能力；（2）天气条件和棚设计特征的变化对人行道选择行为有显著影响。", "conclusion": "通过将生成式AI集成到城市研究中，该研究提供了一种评估人行道棚设计的新方法，并为改进行人体验而不妥协安全性的棚指导方针调整提供了实证依据。"}}
{"id": "2601.23092", "pdf": "https://arxiv.org/pdf/2601.23092", "abs": "https://arxiv.org/abs/2601.23092", "authors": ["Haitham S. Al-Sinani", "Chris J. Mitchell"], "title": "WiFiPenTester: Advancing Wireless Ethical Hacking with Governed GenAI", "categories": ["cs.CR", "cs.AI"], "comment": "35 pages, 10 figures", "summary": "Wireless ethical hacking relies heavily on skilled practitioners manually interpreting reconnaissance results and executing complex, time-sensitive sequences of commands to identify vulnerable targets, capture authentication handshakes, and assess password resilience; a process that is inherently labour-intensive, difficult to scale, and prone to subjective judgement and human error. To help address these limitations, we propose WiFiPenTester, an experimental, governed, and reproducible system for GenAI-enabled wireless ethical hacking. The system integrates large language models into the reconnaissance and decision-support phases of wireless security assessment, enabling intelligent target ranking, attack feasibility estimation, and strategy recommendation, while preserving strict human-in-the-loop control and budget-aware execution. We describe the system architecture, threat model, governance mechanisms, and prompt-engineering methodology, and empirical experiments conducted across multiple wireless environments. The results demonstrate that GenAI assistance improves target selection accuracy and overall assessment efficiency, while maintaining auditability and ethical safeguards. This indicates that WiFiPenTester is a meaningful step toward practical, safe, and scalable GenAI-assisted wireless penetration testing, while reinforcing the necessity of bounded autonomy, human oversight, and rigorous governance mechanisms when deploying GenAI in ethical hacking.", "AI": {"tldr": "WiFiPenTester是一个基于GenAI的无线道德黑客系统，旨在改善目标选择和攻击策略推荐。", "motivation": "无线道德黑客过程复杂且依赖于人工操作，劳动密集型、难以扩展且易出错。该论文提出了一种集成大型语言模型以提高效率和准确性的系统。", "method": "WiFiPenTester通过结合大语义模型进行侦察和决策支持，实现了智能目标排名、攻击可行性评估和策略推荐，并保持了严格的“人在回路”控制和预算意识执行。", "result": "实验结果显示，GenAI辅助提高了目标选择的准确性和整体评估效率，同时保持审计性和道德保障。", "conclusion": "WiFiPenTester展示了GenAI在无线渗透测试中的潜在应用价值，证明其可以提高道德黑客的工作效率与准确性。"}}
{"id": "2601.23088", "pdf": "https://arxiv.org/pdf/2601.23088", "abs": "https://arxiv.org/abs/2601.23088", "authors": ["Zhixiang Zhang", "Zesen Liu", "Yuchong Xie", "Quanfeng Huang", "Dongdong She"], "title": "From Similarity to Vulnerability: Key Collision Attack on LLM Semantic Caching", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Semantic caching has emerged as a pivotal technique for scaling LLM applications, widely adopted by major providers including AWS and Microsoft. By utilizing semantic embedding vectors as cache keys, this mechanism effectively minimizes latency and redundant computation for semantically similar queries. In this work, we conceptualize semantic cache keys as a form of fuzzy hashes. We demonstrate that the locality required to maximize cache hit rates fundamentally conflicts with the cryptographic avalanche effect necessary for collision resistance. Our conceptual analysis formalizes this inherent trade-off between performance (locality) and security (collision resilience), revealing that semantic caching is naturally vulnerable to key collision attacks. While prior research has focused on side-channel and privacy risks, we present the first systematic study of integrity risks arising from cache collisions. We introduce CacheAttack, an automated framework for launching black-box collision attacks. We evaluate CacheAttack in security-critical tasks and agentic workflows. It achieves a hit rate of 86\\% in LLM response hijacking and can induce malicious behaviors in LLM agent, while preserving strong transferability across different embedding models. A case study on a financial agent further illustrates the real-world impact of these vulnerabilities. Finally, we discuss mitigation strategies.", "AI": {"tldr": "本文提出了针对大规模语言模型（LLM）语义缓存的密钥碰撞攻击，揭示了其固有的安全漏洞，并引入了一种自动化框架CacheAttack来实施此类攻击。", "motivation": "当前的LLM应用广泛采用了语义缓存技术以减少延迟和冗余计算。然而，这种技术在提高性能的同时可能牺牲安全性。本文旨在探索这一现象背后的原理，并首次系统性地研究了缓存碰撞带来的完整性风险。", "method": "通过形式化分析，本文证明了缓存命中率与密钥冲突抗性之间的固有矛盾。同时开发了一种名为CacheAttack的自动化框架，在黑盒环境下执行攻击。", "result": "在关键的安全任务和代理工作流程中测试后，CacheAttack实现了86%的命中率，并能在LLM代理人中引发恶意行为，同时保持了跨不同嵌入模型的良好泛化能力。具体案例显示这种漏洞可能对金融代理人等产生实质性影响。", "conclusion": "本文揭示了基于语义缓存的大规模语言模型固有的安全缺陷，并通过实验验证了这些理论假设。最后提出了相应的缓解措施。"}}
{"id": "2601.23087", "pdf": "https://arxiv.org/pdf/2601.23087", "abs": "https://arxiv.org/abs/2601.23087", "authors": ["Wu Songwei", "Jiang Zhiduo", "Xie Guanghu", "Liu Yang", "Liu Hong"], "title": "Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation", "categories": ["cs.RO"], "comment": "8 pages, 8 figures", "summary": "Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space. We propose LG-Flow Policy, a trajectory-level imitation learning framework that performs flow matching in a continuous latent action space. By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution. LG-Flow Policy further incorporates geometry-aware point cloud conditioning and execution-time multimodal modulation, with visual cues evaluated as a representative modality in real-world settings. Experimental results in simulation and on physical robot platforms demonstrate that LG-Flow Policy achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines operating in the raw action space, and remains significantly more efficient than diffusion-based policies.", "AI": {"tldr": "该论文提出了一种基于潜在空间流动匹配的轨迹级模仿学习框架，用于长时序机器人操作。", "motivation": "现有生成策略难以同时实现行为建模、实时推断和稳定执行。扩散方法虽有强大的模型能力但推断延迟高；而直接在原始动作空间中进行流匹配则会导致不稳定执行。", "method": "提出了LG-Flow Policy框架，通过编码动作序列到连续潜在轨迹并在潜在空间中学习显式流动来解耦全局运动结构和低级控制噪声，从而实现平滑可靠的操作。该方法还结合了几何感知点云条件和多模态调节能力。", "result": "实验结果显示LG-Flow Policy实现了近乎单步推断，并在轨迹光滑度和任务成功率上显著优于原始动作空间中的流基线模型，同时保持比扩散策略更高的效率。", "conclusion": "提出的方法为机器人长时序操作提供了有效的解决方案，在保证实时性和稳定性的同时提高了任务的成功率和平滑性。"}}
{"id": "2601.23086", "pdf": "https://arxiv.org/pdf/2601.23086", "abs": "https://arxiv.org/abs/2601.23086", "authors": ["Nathaniel Mitrani Hadida", "Sassan Bhanji", "Cameron Tice", "Puria Radmard"], "title": "Chain-of-thought obfuscation learned from output supervision can generalise to unseen tasks", "categories": ["cs.AI"], "comment": null, "summary": "Chain-of-thought (CoT) reasoning provides a significant performance uplift to LLMs by enabling planning, exploration, and deliberation of their actions. CoT is also a powerful tool for monitoring the behaviours of these agents: when faithful, they offer interpretations of the model's decision making process, and an early warning sign for dangerous behaviours. However, optimisation pressures placed on the CoT may cause the model to obfuscate reasoning traces, losing this beneficial property. We show that obfuscation can generalise across tasks; models that learn to obfuscate reasoning involving reward hacking (e.g. accessing and utilising leaked information) generalise both the reward hacking behaviour and its obfuscation in CoT to unseen reward hacking settings. Most worryingly, we show that obfuscation of CoT reasoning, and its generalisation across tasks, also follows when we penalise only the model's final actions after closing its CoT. Our findings suggest that current practices of penalising harmful generations may inadvertently lead to a reduction in the broader monitorability of LLMs in unpredictable ways.", "AI": {"tldr": "研究通过监督学习使LLM掌握链式思考的混淆技巧，并展示这种技术能在未见过的任务中泛化。", "motivation": "优化压力可能导致模型在链式思考中产生误导，失去监控作用。当前惩罚有害行为的方法可能无意间减少了对大语言模型的可监测性。", "method": "通过对奖励黑客攻击行为及其混淆策略的学习，来展示LLM如何将这种混淆技巧泛化到未见过的任务上，并通过仅仅惩罚最终动作而非整个思考过程来强化这一现象。", "result": "发现LLM能够将在一个任务中学习到的链式思考混淆技术应用于其他任务中。即使只是惩罚了模型的最后输出，也观察到了类似的混淆行为。", "conclusion": "当前对大语言模型有害生成进行惩罚的方法可能导致其监控性降低，应考虑改进监测策略以应对这种潜在风险。"}}
{"id": "2601.23085", "pdf": "https://arxiv.org/pdf/2601.23085", "abs": "https://arxiv.org/abs/2601.23085", "authors": ["Mohanna Hoveyda", "Jelle Piepenbrock", "Arjen P de Vries", "Maarten de Rijke", "Faegheh Hasibi"], "title": "OrLog: Resolving Complex Queries with LLMs and Probabilistic Reasoning", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted to ECIR 2026", "summary": "Resolving complex information needs that come with multiple constraints should consider enforcing the logical operators encoded in the query (i.e., conjunction, disjunction, negation) on the candidate answer set. Current retrieval systems either ignore these constraints in neural embeddings or approximate them in a generative reasoning process that can be inconsistent and unreliable. Although well-suited to structured reasoning, existing neuro-symbolic approaches remain confined to formal logic or mathematics problems as they often assume unambiguous queries and access to complete evidence, conditions rarely met in information retrieval. To bridge this gap, we introduce OrLog, a neuro-symbolic retrieval framework that decouples predicate-level plausibility estimation from logical reasoning: a large language model (LLM) provides plausibility scores for atomic predicates in one decoding-free forward pass, from which a probabilistic reasoning engine derives the posterior probability of query satisfaction. We evaluate OrLog across multiple backbone LLMs, varying levels of access to external knowledge, and a range of logical constraints, and compare it against base retrievers and LLM-as-reasoner methods. Provided with entity descriptions, OrLog can significantly boost top-rank precision compared to LLM reasoning with larger gains on disjunctive queries. OrLog is also more efficient, cutting mean tokens by $\\sim$90\\% per query-entity pair. These results demonstrate that generation-free predicate plausibility estimation combined with probabilistic reasoning enables constraint-aware retrieval that outperforms monolithic reasoning while using far fewer tokens.", "AI": {"tldr": "OrLog是一个将大型语言模型与概率推理相结合的信息检索框架，用于解决包含复杂逻辑运算符的查询。", "motivation": "现有的信息检索系统要么忽略查询中的约束条件，要么在生成过程中近似这些约束条件导致不一致和不可靠。为了弥补这一差距，提出了一种新的方法来处理信息检索中常见的模糊性和不完备性问题。", "method": "OrLog框架通过解耦原子谓词的可信度评估与逻辑推理过程：大型语言模型为每个原子谓词提供一个无解码的正向传递的可信度分数；概率推理引擎根据这些分数推导查询满足的概率。", "result": "实验表明，与基本检索器和LLM作为推理者的方法相比，OrLog在给定实体描述时可以显著提高顶级精度，并且对于并集查询提升更大。此外，它更高效，每个查询-实体对的平均标记数减少了约90%。", "conclusion": "结合生成自由的谓词可信度评估与概率推理使得基于约束的信息检索优于单一推理方法并且消耗远少于其他方法的令牌数。"}}
{"id": "2601.23081", "pdf": "https://arxiv.org/pdf/2601.23081", "abs": "https://arxiv.org/abs/2601.23081", "authors": ["Yanghao Su", "Wenbo Zhou", "Tianwei Zhang", "Qiu Han", "Weiming Zhang", "Nenghai Yu", "Jie Zhang"], "title": "Character as a Latent Variable in Large Language Models: A Mechanistic Account of Emergent Misalignment and Conditional Safety Failures", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": null, "summary": "Emergent Misalignment refers to a failure mode in which fine-tuning large language models (LLMs) on narrowly scoped data induces broadly misaligned behavior. Prior explanations mainly attribute this phenomenon to the generalization of erroneous or unsafe content. In this work, we show that this view is incomplete. Across multiple domains and model families, we find that fine-tuning models on data exhibiting specific character-level dispositions induces substantially stronger and more transferable misalignment than incorrect-advice fine-tuning, while largely preserving general capabilities. This indicates that emergent misalignment arises from stable shifts in model behavior rather than from capability degradation or corrupted knowledge. We further show that such behavioral dispositions can be conditionally activated by both training-time triggers and inference-time persona-aligned prompts, revealing shared structure across emergent misalignment, backdoor activation, and jailbreak susceptibility. Overall, our results identify character formation as a central and underexplored alignment risk, suggesting that robust alignment must address behavioral dispositions rather than isolated errors or prompt-level defenses.", "AI": {"tldr": "研究通过分析大语言模型（LLM）在特定性格倾向数据上的微调，揭示了“新兴偏差”的机制及其与条件安全失败的联系。", "motivation": "先前对“新兴偏差”的解释主要归因于错误或不安全内容的一般化。然而，这些解释不足以全面理解问题根源。研究旨在探究行为倾向在模型中的形成方式及如何影响模型的安全性。", "method": "跨多个领域和模型家族分析了模型微调过程，并揭示性格倾向如何通过训练时触发器和推理时角色一致提示被条件激活。", "result": "发现特定性格倾向数据的微调会导致更强烈且更具转移性的偏差，而不会显著影响通用能力。同时表明了行为倾向可以通过不同的方式在模型中激活，形成一种共同结构。", "conclusion": "研究指出，稳定的行为倾向是导致“新兴偏差”的关键因素之一，因此，为了实现稳健的安全性控制，必须关注这些内在的、系统性的特性而非孤立错误或提示级别的防御措施。"}}
{"id": "2601.23080", "pdf": "https://arxiv.org/pdf/2601.23080", "abs": "https://arxiv.org/abs/2601.23080", "authors": ["Yubiao Ma", "Han Yu", "Jiayin Xie", "Changtai Lv", "Qiang Luo", "Chi Zhang", "Yunpeng Yin", "Boyang Xing", "Xuemei Ren", "Dongdong Zheng"], "title": "Robust and Generalized Humanoid Motion Tracking", "categories": ["cs.RO"], "comment": null, "summary": "Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. We propose a dynamics-conditioned command aggregation framework that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics. We further integrate a fall recovery curriculum with random unstable initialization and an annealed upward assistance force to improve robustness and disturbance rejection. The resulting policy requires only about 3.5 hours of motion data and supports single-stage end-to-end training without distillation. The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as robust sim-to-real transfer on a physical humanoid robot.", "AI": {"tldr": "提出了一种基于动态条件命令聚合框架的人形机器人运动跟踪方法，用于在各种参考输入下实现稳健的运动转移。", "motivation": "实际操作中的参考动作可能包含噪声和不一致性，导致控制器失效或行为失败。为了解决这些问题，研究提出了一个新颖的方法来提高人形机器人的动态性和接触丰富场景下的鲁棒性与干扰抑制能力。", "method": "使用因果时间编码器总结最近的本体感受，并利用多头交叉注意力命令编码器根据当前动力学有选择地聚合上下文窗口。通过随机不稳定初始化和逐步减少的帮助力来增强跌倒恢复课程，以提高政策的鲁棒性和抗干扰性。", "result": "该方法只需要大约3.5小时的动作数据就能支持单阶段端到端训练，并且在各种参考输入下表现出零样本迁移能力以及从仿真到现实的有效转移性能。", "conclusion": "研究提出的方法展示了强大的通用性，能够在不同种类的运动中进行有效和稳健的表现。"}}
{"id": "2601.23075", "pdf": "https://arxiv.org/pdf/2601.23075", "abs": "https://arxiv.org/abs/2601.23075", "authors": ["Yuexin Bian", "Jie Feng", "Tao Wang", "Yijiang Li", "Sicun Gao", "Yuanyuan Shi"], "title": "RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy Reinforcement Learning", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "On-policy deep reinforcement learning remains a dominant paradigm for continuous control, yet standard implementations rely on Gaussian actors and relatively shallow MLP policies, often leading to brittle optimization when gradients are noisy and policy updates must be conservative. In this paper, we revisit policy representation as a first-class design choice for on-policy optimization. We study discretized categorical actors that represent each action dimension with a distribution over bins, yielding a policy objective that resembles a cross-entropy loss. Building on architectural advances from supervised learning, we further propose regularized actor networks, while keeping critic design fixed. Our results show that simply replacing the standard actor network with our discretized regularized actor yields consistent gains and achieve the state-of-the-art performance across diverse continuous-control benchmarks.", "AI": {"tldr": "本论文提出了使用离散化分类策略的演员网络和正则化网络，以改善在连续控制任务中的强化学习性能。", "motivation": "标准的深度强化学习实现依赖于高斯演员和浅层多层感知机（MLP）政策，在梯度嘈杂且需要保守更新策略时容易导致脆弱的优化过程。因此，作者重新审视了政策表示作为首要设计选择以改善在连续控制任务中的性能。", "method": "通过将每个动作维度代表为一个分布，并提出基于监督学习架构改进的正则化演员网络，同时保持批评者的设计不变。", "result": "实验结果表明，在不改变标准演员网络的基础上替换为离散化的正则化演员可以一致地获得性能提升，并在各种连续控制基准上达到当前的最佳水平。", "conclusion": "通过采用新的策略表示和网络架构改进，该方法能够显著提高连续控制任务中的强化学习效果。"}}
{"id": "2601.23068", "pdf": "https://arxiv.org/pdf/2601.23068", "abs": "https://arxiv.org/abs/2601.23068", "authors": ["Joao Fonseca", "Julia Stoyanovich"], "title": "ExplainerPFN: Towards tabular foundation models for model-free zero-shot feature importance estimations", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 7 figures", "summary": "Computing the importance of features in supervised classification tasks is critical for model interpretability. Shapley values are a widely used approach for explaining model predictions, but require direct access to the underlying model, an assumption frequently violated in real-world deployments. Further, even when model access is possible, their exact computation may be prohibitively expensive. We investigate whether meaningful Shapley value estimations can be obtained in a zero-shot setting, using only the input data distribution and no evaluations of the target model. To this end, we introduce ExplainerPFN, a tabular foundation model built on TabPFN that is pretrained on synthetic datasets generated from random structural causal models and supervised using exact or near-exact Shapley values. Once trained, ExplainerPFN predicts feature attributions for unseen tabular datasets without model access, gradients, or example explanations. Our contributions are fourfold: (1) we show that few-shot learning-based explanations can achieve high fidelity to SHAP values with as few as two reference observations; (2) we propose ExplainerPFN, the first zero-shot method for estimating Shapley values without access to the underlying model or reference explanations; (3) we provide an open-source implementation of ExplainerPFN, including the full training pipeline and synthetic data generator; and (4) through extensive experiments on real and synthetic datasets, we show that ExplainerPFN achieves performance competitive with few-shot surrogate explainers that rely on 2-10 SHAP examples.", "AI": {"tldr": "本文提出了一种名为ExplainerPFN的零样本特征重要性估计方法，无需访问目标模型即可预测未见数据集中的特征属性。", "motivation": "在监督分类任务中计算特征的重要性对于模型可解释性至关重要。Shapley值是一种广泛使用的解释模型预测的方法，但它们需要直接访问底层模型，在实际部署中这一假设经常不成立。此外，即使可以访问模型，其精确计算可能代价高昂。因此，作者研究了仅使用输入数据分布而无需评估目标模型的情况下是否可以获得有意义的Shapley值估计。", "method": "本文介绍了ExplainerPFN，这是一种基于TabPFN构建的表格基础模型，并在随机结构因果模型生成的合成数据上进行预训练。其监督方式为使用精确或近似精确的Shapley值。一旦训练完成，ExplainerPFN可以在没有访问目标模型、梯度或示例解释的情况下预测未见表格数据集中的特征属性。", "result": "通过在真实和合成数据集上的广泛实验，作者展示了ExplainerPFN能够达到与基于少量样本解释器（依赖2-10个SHAP示例）竞争的性能水平。此外，本文提出了仅使用两个参考观察值即可实现高保真度的方法。", "conclusion": "通过探索零样本特征重要性估计的新方法，本文提出了一种无需访问模型且能够进行高保真Shapley值预测的解决方案。这为提高模型解释性和促进透明化提供了新的视角和工具。"}}
{"id": "2601.23066", "pdf": "https://arxiv.org/pdf/2601.23066", "abs": "https://arxiv.org/abs/2601.23066", "authors": ["Xiaoxuan Guo", "Yuankun Xie", "Haonan Cheng", "Jiayi Zhou", "Jian Liu", "Hengyan Huang", "Long Ye", "Qin Zhang"], "title": "Towards Explicit Acoustic Evidence Perception in Audio LLMs for Speech Deepfake Detection", "categories": ["cs.SD", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Speech deepfake detection (SDD) focuses on identifying whether a given speech signal is genuine or has been synthetically generated. Existing audio large language model (LLM)-based methods excel in content understanding; however, their predictions are often biased toward semantically correlated cues, which results in fine-grained acoustic artifacts being overlooked during the decisionmaking process. Consequently, fake speech with natural semantics can bypass detectors despite harboring subtle acoustic anomalies; this suggests that the challenge stems not from the absence of acoustic data, but from its inadequate accessibility when semantic-dominant reasoning prevails. To address this issue, we investigate SDD within the audio LLM paradigm and introduce SDD with Auditory Perception-enhanced Audio Large Language Model (SDD-APALLM), an acoustically enhanced framework designed to explicitly expose fine-grained time-frequency evidence as accessible acoustic cues. By combining raw audio with structured spectrograms, the proposed framework empowers audio LLMs to more effectively capture subtle acoustic inconsistencies without compromising their semantic understanding. Experimental results indicate consistent gains in detection accuracy and robustness, especially in cases where semantic cues are misleading. Further analysis reveals that these improvements stem from a coordinated utilization of semantic and acoustic information, as opposed to simple modality aggregation.", "AI": {"tldr": "论文提出了SDD-APALLM框架，通过增强音频LLMs的听觉感知能力来改进语音深伪检测。", "motivation": "现有基于音频大语言模型的方法在语义理解方面表现出色，但忽略了细粒度的声学特征。因此，自然语义的声音可能会逃过检测器，尽管含有细微的声学异常。这表明问题不在于缺乏声学数据，而在于当以语义为主导时这些数据难以获得。", "method": "论文提出了一种增强音频LLMs听觉感知能力的方法SDD-APALLM框架，该框架通过结合原始音频和结构化频谱图来捕获细微的声学不一致性，并保持其语义理解能力。", "result": "实验结果表明，在具有误导性语义线索的情况下，检测准确性和鲁棒性得到了显著提高。进一步分析显示这些改进是由于对语义和声学信息的同时利用而非简单的模态聚合所导致的。", "conclusion": "通过结合原始音频和结构化频谱图来增强语音深伪检测中音频LLMs的听觉感知能力，可以有效地揭示细粒度的时间频率证据作为可访问的声音线索。"}}
{"id": "2601.23065", "pdf": "https://arxiv.org/pdf/2601.23065", "abs": "https://arxiv.org/abs/2601.23065", "authors": ["Xijie Yang", "Mulin Yu", "Changjian Jiang", "Kerui Ren", "Tao Lu", "Jiangmiao Pang", "Dahua Lin", "Bo Dai", "Linning Xu"], "title": "EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing", "categories": ["cs.GR", "cs.CV"], "comment": "project page: https://eag-pt.github.io", "summary": "Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport. In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on geometric fidelity, becoming a practical bottleneck for real indoor scenes. In this work, we propose Emission-Aware Gaussians and Path Tracing (EAG-PT), aiming for physically based light transport with a unified 2D Gaussian representation. Our design is based on three cores: (1) using 2D Gaussians as a unified scene representation and transport-friendly geometry proxy that avoids reconstructed mesh, (2) explicitly separating emissive and non-emissive components during reconstruction for further scene editing, and (3) decoupling reconstruction from final rendering by using efficient single-bounce optimization and high-quality multi-bounce path tracing after scene editing. Experiments on synthetic and real indoor scenes show that EAG-PT produces more natural and physically consistent renders after editing than radiant scene reconstructions, while preserving finer geometric detail and avoiding mesh-induced artifacts compared to mesh-based inverse path tracing. These results suggest promising directions for future use in interior design, XR content creation, and embodied AI.", "AI": {"tldr": "提出EAG-PT方法，结合2D高斯分布和路径追踪技术，实现室内场景重建与编辑时的物理光照传输。", "motivation": "当前基于辐射场的重建方法（如NeRF、3DGS）在视觉保真度上表现良好但不适用于场景编辑。相比之下，物理基逆向渲染依赖于网格表示和路径追踪，需要高几何精度，难以处理真实室内场景。", "method": "EAG-PT利用2D高斯分布作为统一场景表征，并分离发光与非发光成分；采用单次反弹优化及高质量多次反弹路径追踪进行解耦重建与最终渲染。", "result": "实验显示，EAG-PT在编辑后生成更自然、物理一致性更好的渲染结果，同时保持精细几何细节并避免网格引入的缺陷。", "conclusion": "EAG-PT为未来室内设计、XR内容创建和嵌入式AI的应用提供了有前景的方向。"}}
{"id": "2601.23064", "pdf": "https://arxiv.org/pdf/2601.23064", "abs": "https://arxiv.org/abs/2601.23064", "authors": ["Hari Krishna Gadi", "Daniel Matos", "Hongyi Luo", "Lu Liu", "Yongliang Wang", "Yanfeng Zhang", "Liqiu Meng"], "title": "HierLoc: Hyperbolic Entity Embeddings for Hierarchical Visual Geolocation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual geolocalization, the task of predicting where an image was taken, remains challenging due to global scale, visual ambiguity, and the inherently hierarchical structure of geography. Existing paradigms rely on either large-scale retrieval, which requires storing a large number of image embeddings, grid-based classifiers that ignore geographic continuity, or generative models that diffuse over space but struggle with fine detail. We introduce an entity-centric formulation of geolocation that replaces image-to-image retrieval with a compact hierarchy of geographic entities embedded in Hyperbolic space. Images are aligned directly to country, region, subregion, and city entities through Geo-Weighted Hyperbolic contrastive learning by directly incorporating haversine distance into the contrastive objective. This hierarchical design enables interpretable predictions and efficient inference with 240k entity embeddings instead of over 5 million image embeddings on the OSV5M benchmark, on which our method establishes a new state-of-the-art performance. Compared to the current methods in the literature, it reduces mean geodesic error by 19.5\\%, while improving the fine-grained subregion accuracy by 43%. These results demonstrate that geometry-aware hierarchical embeddings provide a scalable and conceptually new alternative for global image geolocation.", "AI": {"tldr": "该论文提出了一种基于双曲空间的嵌入方法，用于图像地理位置预测。", "motivation": "现有的图像地理定位方法存在存储需求大、忽视地域连续性或细节处理不足的问题。本文旨在通过引入一种新的实体中心化地理定位框架来解决这些问题。", "method": "论文提出了一个以国家和地区等地理实体为中心的层次模型，并将这些实体嵌入到双曲空间中，利用Geo-Weighted Hyperbolic对比学习方法直接结合哈弗辛距离进行训练。这种方法能够显著减少存储需求并提高预测准确性。", "result": "在OSV5M数据集上，该方法建立了新的状态-of-the-art性能，平均地心几何误差减少了19.5％，细粒度子区域精度提高了43%。", "conclusion": "基于双曲空间的层次化嵌入提供了一种可扩展且概念新颖的方法来解决全球图像地理定位问题。"}}
{"id": "2601.23059", "pdf": "https://arxiv.org/pdf/2601.23059", "abs": "https://arxiv.org/abs/2601.23059", "authors": ["Antonio Vitale", "Emanuela Guglielmi", "Simone Scalabrino", "Rocco Oliveto"], "title": "On the Impact of Code Comments for Automated Bug-Fixing: An Empirical Study", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "Accepted at the 34th IEEE/ACM International Conference on Program Comprehension (ICPC 2026)", "summary": "Large Language Models (LLMs) are increasingly relevant in Software Engineering research and practice, with Automated Bug Fixing (ABF) being one of their key applications. ABF involves transforming a buggy method into its fixed equivalent. A common preprocessing step in ABF involves removing comments from code prior to training. However, we hypothesize that comments may play a critical role in fixing certain types of bugs by providing valuable design and implementation insights. In this study, we investigate how the presence or absence of comments, both during training and at inference time, impacts the bug-fixing capabilities of LLMs. We conduct an empirical evaluation comparing two model families, each evaluated under all combinations of training and inference conditions (with and without comments), and thereby revisiting the common practice of removing comments during training. To address the limited availability of comments in state-of-the-art datasets, we use an LLM to automatically generate comments for methods lacking them. Our findings show that comments improve ABF accuracy by up to threefold when present in both phases, while training with comments does not degrade performance when instances lack them. Additionally, an interpretability analysis identifies that comments detailing method implementation are particularly effective in aiding LLMs to fix bugs accurately.", "AI": {"tldr": "研究了代码注释在自动错误修复中的影响，评估了有无注释时LLM的性能。", "motivation": "假设代码注释可以提供设计和实现方面的有价值信息，有助于修复某些类型的bug。目前实践中经常移除注释，本研究旨在探讨这一做法的有效性。", "method": "通过实证分析两种模型家族在不同条件下（训练时有无注释、推断时有无注释）的表现，并使用LLM自动生成缺失注释的方法以扩大数据集规模。", "result": "发现当训练和推理阶段都存在注释时，ABF的准确性提高到三倍。此外，在实例中没有注释的情况下，用带注释的数据进行训练不会降低性能。解释性分析表明，描述方法实现细节的注释特别有助于LLM准确修复错误。", "conclusion": "代码注释在自动错误修复任务中有重要影响，应考虑保留注释以提高模型性能。"}}
{"id": "2601.23052", "pdf": "https://arxiv.org/pdf/2601.23052", "abs": "https://arxiv.org/abs/2601.23052", "authors": ["Seyedeh Ava Razi Razavi", "James Sargant", "Sheridan Houghten", "Renata Dividino"], "title": "Adaptive Edge Learning for Density-Aware Graph Generation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the 39th Canadian Conference on Artificial Intelligence", "summary": "Generating realistic graph-structured data is challenging due to discrete structures, variable sizes, and class-specific connectivity patterns that resist conventional generative modelling. While recent graph generation methods employ generative adversarial network (GAN) frameworks to handle permutation invariance and irregular topologies, they typically rely on random edge sampling with fixed probabilities, limiting their capacity to capture complex structural dependencies between nodes. We propose a density-aware conditional graph generation framework using Wasserstein GANs (WGAN) that replaces random sampling with a learnable distance-based edge predictor. Our approach embeds nodes into a latent space where proximity correlates with edge likelihood, enabling the generator to learn meaningful connectivity patterns. A differentiable edge predictor determines pairwise relationships directly from node embeddings, while a density-aware selection mechanism adaptively controls edge density to match class-specific sparsity distributions observed in real graphs. We train the model using a WGAN with gradient penalty, employing a GCN-based critic to ensure generated graphs exhibit realistic topology and align with target class distributions. Experiments on benchmark datasets demonstrate that our method produces graphs with superior structural coherence and class-consistent connectivity compared to existing baselines. The learned edge predictor captures complex relational patterns beyond simple heuristics, generating graphs whose density and topology closely match real structural distributions. Our results show improved training stability and controllable synthesis, making the framework effective for realistic graph generation and data augmentation. Source code is publicly available at https://github.com/ava-12/Density_Aware_WGAN.git.", "AI": {"tldr": "本文提出了一种基于Wasserstein GAN的密度感知条件图生成框架，利用可学习的距离基边预测器来替代随机边采样。", "motivation": "现有的图生成方法依赖于固定的概率随机采样边，难以捕捉复杂的节点间结构依赖关系。因此，需要一种更有效的机制来生成具有真实结构分布和类一致性连接的图形数据。", "method": "本文使用WGAN框架，并引入了一个可学习的距离基边预测器，通过将节点嵌入到潜在空间中来确定边的存在性，该预测器基于节点嵌入直接决定一对节点之间的关系。同时采用密度感知的选择机制动态地控制图的密度以匹配真实数据中的稀疏度分布。", "result": "实验结果表明，与现有的基准方法相比，本文的方法生成了结构一致性更强和类一致性的连接性更好的图形，并且通过学习到的边预测器捕捉到了复杂的关系模式，提高了训练稳定性并实现了可控合成。", "conclusion": "提出的密度感知WGAN框架在生成具有真实拓扑特征的真实图方面是有效的。该方法不仅可以用于数据增强，还可以为其他需要生成高质量图结构的应用提供支持。"}}
{"id": "2601.23049", "pdf": "https://arxiv.org/pdf/2601.23049", "abs": "https://arxiv.org/abs/2601.23049", "authors": ["Yakun Zhu", "Yutong Huang", "Shengqian Qin", "Zhongzhen Huang", "Shaoting Zhang", "Xiaofan Zhang"], "title": "MedMCP-Calc: Benchmarking LLMs for Realistic Medical Calculator Scenarios via MCP Integration", "categories": ["cs.AI"], "comment": null, "summary": "Medical calculators are fundamental to quantitative, evidence-based clinical practice. However, their real-world use is an adaptive, multi-stage process, requiring proactive EHR data acquisition, scenario-dependent calculator selection, and multi-step computation, whereas current benchmarks focus only on static single-step calculations with explicit instructions. To address these limitations, we introduce MedMCP-Calc, the first benchmark for evaluating LLMs in realistic medical calculator scenarios through Model Context Protocol (MCP) integration. MedMCP-Calc comprises 118 scenario tasks across 4 clinical domains, featuring fuzzy task descriptions mimicking natural queries, structured EHR database interaction, external reference retrieval, and process-level evaluation. Our evaluation of 23 leading models reveals critical limitations: even top performers like Claude Opus 4.5 exhibit substantial gaps, including difficulty selecting appropriate calculators for end-to-end workflows given fuzzy queries, poor performance in iterative SQL-based database interactions, and marked reluctance to leverage external tools for numerical computation. Performance also varies considerably across clinical domains. Building on these findings, we develop CalcMate, a fine-tuned model incorporating scenario planning and tool augmentation, achieving state-of-the-art performance among open-source models. Benchmark and Codes are available in https://github.com/SPIRAL-MED/MedMCP-Calc.", "AI": {"tldr": "本文介绍了MedMCP-Calc，这是第一个用于评估大型语言模型在现实医学计算器场景中表现的基准测试。", "motivation": "现有的医学计算器基准测试仅关注静态单步骤计算，并且具有明确指令。而实际中的使用则是一个适应性多阶段过程，需要主动获取电子病历数据、根据具体情况选择合适的计算器并进行多步运算。为了克服这些限制，本文提出了MedMCP-Calc。", "method": "该基准包含118个场景任务，覆盖4个临床领域，具有模糊的任务描述以模仿自然查询、结构化的数据库交互、外部参考检索以及过程级别评估等特性。", "result": "对23种领先模型的评价显示了重要限制：即使是顶级模型如Claude Opus 4.5，在面对模糊查询时也难以选择正确的计算器完成端到端工作流程，同时在迭代SQL交互和利用外部分析工具方面表现不佳。基于这些发现，研究团队开发了CalcMate，该模型结合场景规划和工具增强，达到了开源模型中的最佳性能。", "conclusion": "MedMCP-Calc填补了现有医学计算器评估基准的空白，并揭示了大型语言模型在处理现实临床计算任务时的关键局限性；而通过引入CalcMate，则表明通过适当训练可以显著改善这些模型的表现。"}}
{"id": "2601.23048", "pdf": "https://arxiv.org/pdf/2601.23048", "abs": "https://arxiv.org/abs/2601.23048", "authors": ["Bowen Cao", "Dongdong Zhang", "Yixia Li", "Junpeng Liu", "Shijue Huang", "Chufan Shi", "Hongyuan Lu", "Yaokang Wu", "Guanhua Chen", "Wai Lam", "Furu Wei"], "title": "From Abstract to Contextual: What LLMs Still Cannot Do in Mathematics", "categories": ["cs.AI"], "comment": "ICLR 2026", "summary": "Large language models now solve many benchmark math problems at near-expert levels, yet this progress has not fully translated into reliable performance in real-world applications. We study this gap through contextual mathematical reasoning, where the mathematical core must be formulated from descriptive scenarios. We introduce ContextMATH, a benchmark that repurposes AIME and MATH-500 problems into two contextual settings: Scenario Grounding (SG), which embeds abstract problems into realistic narratives without increasing reasoning complexity, and Complexity Scaling (CS), which transforms explicit conditions into sub-problems to capture how constraints often appear in practice. Evaluating 61 proprietary and open-source models, we observe sharp drops: on average, open-source models decline by 13 and 34 points on SG and CS, while proprietary models drop by 13 and 20. Error analysis shows that errors are dominated by incorrect problem formulation, with formulation accuracy declining as original problem difficulty increases. Correct formulation emerges as a prerequisite for success, and its sufficiency improves with model scale, indicating that larger models advance in both understanding and reasoning. Nevertheless, formulation and reasoning remain two complementary bottlenecks that limit contextual mathematical problem solving. Finally, we find that fine-tuning with scenario data improves performance, whereas formulation-only training is ineffective. However, performance gaps are only partially alleviated, highlighting contextual mathematical reasoning as a central unsolved challenge for LLMs.", "AI": {"tldr": "研究大型语言模型在抽象数学问题转化为现实情境时的表现差距。", "motivation": "尽管大模型已经能在许多基准测试中解决数学问题，但在实际应用中的表现仍不稳定。作者通过引入ContextMATH来考察这些模型在情境化推理方面的能力。", "method": "利用AIME和MATH-500数据集构建两个评估场景：情境嵌入（SG）和复杂度调整（CS）。对61个开源与专有模型进行评测，分析错误并探讨训练策略的效果。", "result": "开源和专有模型在新设置下的表现显著下降；正确的问题表述是成功的关键，但模型仍面临理解与推理的双重瓶颈。场景数据微调可改善性能，但效果有限。", "conclusion": "情境化数学问题解决依然是大型语言模型面临的挑战，需要进一步研究和改进。"}}
{"id": "2601.23045", "pdf": "https://arxiv.org/pdf/2601.23045", "abs": "https://arxiv.org/abs/2601.23045", "authors": ["Alexander Hägele", "Aryo Pradipta Gema", "Henry Sleight", "Ethan Perez", "Jascha Sohl-Dickstein"], "title": "The Hot Mess of AI: How Does Misalignment Scale With Model Intelligence and Task Complexity?", "categories": ["cs.AI"], "comment": "ICLR 2026", "summary": "As AI becomes more capable, we entrust it with more general and consequential tasks. The risks from failure grow more severe with increasing task scope. It is therefore important to understand how extremely capable AI models will fail: Will they fail by systematically pursuing goals we do not intend? Or will they fail by being a hot mess, and taking nonsensical actions that do not further any goal? We operationalize this question using a bias-variance decomposition of the errors made by AI models: An AI's \\emph{incoherence} on a task is measured over test-time randomness as the fraction of its error that stems from variance rather than bias in task outcome. Across all tasks and frontier models we measure, the longer models spend reasoning and taking actions, \\emph{the more incoherent} their failures become. Incoherence changes with model scale in a way that is experiment dependent. However, in several settings, larger, more capable models are more incoherent than smaller models. Consequently, scale alone seems unlikely to eliminate incoherence. Instead, as more capable AIs pursue harder tasks, requiring more sequential action and thought, our results predict failures to be accompanied by more incoherent behavior. This suggests a future where AIs sometimes cause industrial accidents (due to unpredictable misbehavior), but are less likely to exhibit consistent pursuit of a misaligned goal. This increases the relative importance of alignment research targeting reward hacking or goal misspecification.", "AI": {"tldr": "本文研究了随着AI模型规模和任务复杂性增加，其行为的不一致性变化情况。", "motivation": "随着人工智能能力的增长，人们开始将更多重要且广泛的任务交给它们来完成。为了理解极有能力的人工智能模型会如何失败，研究者试图找出这些模型是系统地追求我们没有预期的目标，还是出现无意义的行为。", "method": "通过偏差-方差分解的方法量化AI模型在任务上的不一致性：模型的“不一致性”是在测试期间随机性下产生的误差中来自于变化部分的比例。实验涵盖了所有任务和前沿模型，在不同的规模下进行测量。", "result": "研究发现，随着模型花费更多时间来推理和采取行动，其失败时的不一致性也增加。在某些情况下，更大的、更强大的模型比小模型表现出更高的不一致性。", "conclusion": "这表明未来的AI可能会因不可预测的行为而造成工业事故，但不太可能始终如一地追求错误的目标。因此，对于那些旨在解决奖励劫持或目标规格问题的对齐研究来说，其相对重要性将增加。"}}
{"id": "2601.23041", "pdf": "https://arxiv.org/pdf/2601.23041", "abs": "https://arxiv.org/abs/2601.23041", "authors": ["Youxu Shi", "Suorong Yang", "Dong Liu"], "title": "One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs", "categories": ["cs.CV"], "comment": null, "summary": "Vision Language Models (VLMs) achieve strong performance on multimodal tasks but still suffer from hallucination and safety-related failures that persist even at scale. Steering offers a lightweight technique to improve model performance. However, steering, whether input-dependent or input-independent, achieves a meaningful trade-off between efficiency and effectiveness. In this work, we observe that steering vectors can generalize across inputs when tasks share aligned semantic intent. Based on this insight, we propose \\textbf{OSGA} (\\textbf{O}ne-shot \\textbf{S}teering with \\textbf{G}enerative \\textbf{A}nchor), an input-independent framework that improves model performance with a single optimization instance. OSGA first selects an informative sample via a variance-based data selection strategy and learns a single steering vector with a contrastive objective with generative anchor regularization. The resulting vector can be universally applied at a certain layer during inference time without modifying model parameters. Experiments across multiple benchmarks show that a single OSGA-optimized steering vector consistently improves hallucination mitigation and safety enhancement with negligible overhead, highlighting one-shot steering as a practical and scalable solution for reliable VLMs.", "AI": {"tldr": "提出了一种名为OSGA的一次性优化导航向量方法，以减轻视觉语言模型中的幻觉并提高其安全性。", "motivation": "现有视觉语言模型在多模态任务中表现出色，但仍然存在幻觉和安全相关故障。通过使用导航技术可以改善模型性能，但是需要找到一种效率与效果之间的平衡点。", "method": "OSGA首先选择一个有信息量的样本并通过基于方差的数据选择策略学习单个导航向量，并在推理阶段应用该向量来提高模型的表现。", "result": "实验结果显示，在多个基准测试中，使用一次优化后的导航向量可以显著改善幻觉减轻和安全性提升的效果，同时几乎不增加计算开销。", "conclusion": "OSGA作为一次性导航方法展示了其在保持视觉语言模型可靠性方面的实用性和可扩展性。"}}
{"id": "2601.23039", "pdf": "https://arxiv.org/pdf/2601.23039", "abs": "https://arxiv.org/abs/2601.23039", "authors": ["Yizhi Liu"], "title": "Avoiding Premature Collapse: Adaptive Annealing for Entropy-Regularized Structural Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Differentiable matching layers, often implemented via entropy-regularized Optimal Transport, serve as a critical approximate inference mechanism in structural prediction. However, recovering discrete permutations via annealing $ε\\to 0$ is notoriously unstable. We identify a fundamental mechanism for this failure: \\textbf{Premature Mode Collapse}. By analyzing the non-normal dynamics of the Sinkhorn fixed-point map, we reveal a theoretical \\textbf{thermodynamic speed limit}. Under standard exponential cooling, the shift in the target posterior ($O(1)$) outpaces the contraction rate of the inference operator, which degrades as $O(1/ε)$. This mismatch inevitably forces the inference trajectory into spurious local basins. To address this, we propose \\textbf{Efficient PH-ASC}, an adaptive scheduling algorithm that monitors the stability of the inference process. By enforcing a linear stability law, we decouple expensive spectral diagnostics from the training loop, reducing overhead from $O(N^3)$ to amortized $O(1)$. Our implementation and interactive demo are available at https://github.com/xxx0438/torch-sinkhorn-asc and https://huggingface.co/spaces/leon0923/torch-sinkhorn-asc-demo. bounded away from zero in generic training dynamics unless the feature extractor converges unrealistically fast.", "AI": {"tldr": "本文提出了Efficient PH-ASC算法，用于解决基于熵正则化的最优传输在结构预测中的近似推理问题，特别是在恢复离散置换时的不稳定性。", "motivation": "现有方法使用退火技术使ε趋向于0来实现精确匹配，在实际应用中容易陷入局部极小值而无法收敛到正确的解。这种现象被命名为\"过早模式崩溃\"，本文旨在解决这一问题。", "method": "通过研究Sinkhorn固定点映射的非正常动力学特性，揭示了退火过程中热力学速度限制的存在，并提出了一种自适应调度算法Efficient PH-ASC来监控推理过程的稳定性。该方法将昂贵的谱诊断与训练循环解耦，显著降低了计算成本。", "result": "实验结果表明，所提出的Efficient PH-ASC算法能够有效避免过早模式崩溃，提高了模型在结构预测任务中的性能，并且具备较好的实用性。", "conclusion": "本文提出的方法通过自适应调度技术解决了基于熵正则化的最优传输方法中出现的不稳定问题，展示了其在解决复杂匹配和推理任务上的潜力。"}}
{"id": "2601.23038", "pdf": "https://arxiv.org/pdf/2601.23038", "abs": "https://arxiv.org/abs/2601.23038", "authors": ["David Oberacker", "Julia Richer", "Philip Arm", "Marvin Grosse Besselmann", "Lennart Puck", "William Talbot", "Maximilian Schik", "Sabine Bellmann", "Tristan Schnell", "Hendrik Kolvenbach", "Rüdiger Dillmann", "Marco Hutter", "Arne Roennau"], "title": "MOSAIC: Modular Scalable Autonomy for Intelligent Coordination of Heterogeneous Robotic Teams", "categories": ["cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Mobile robots have become indispensable for exploring hostile environments, such as in space or disaster relief scenarios, but often remain limited to teleoperation by a human operator. This restricts the deployment scale and requires near-continuous low-latency communication between the operator and the robot. We present MOSAIC: a scalable autonomy framework for multi-robot scientific exploration using a unified mission abstraction based on Points of Interest (POIs) and multiple layers of autonomy, enabling supervision by a single operator. The framework dynamically allocates exploration and measurement tasks based on each robot's capabilities, leveraging team-level redundancy and specialization to enable continuous operation. We validated the framework in a space-analog field experiment emulating a lunar prospecting scenario, involving a heterogeneous team of five robots and a single operator. Despite the complete failure of one robot during the mission, the team completed 82.3% of assigned tasks at an Autonomy Ratio of 86%, while the operator workload remained at only 78.2%. These results demonstrate that the proposed framework enables robust, scalable multi-robot scientific exploration with limited operator intervention. We further derive practical lessons learned in robot interoperability, networking architecture, team composition, and operator workload management to inform future multi-robot exploration missions.", "AI": {"tldr": "本文提出了一种基于兴趣点（POIs）和多层次自主性的MOSAIC框架，用于多机器人科学探索，该框架允许单一操作员监督，并在模拟月球勘探场景的实验中验证了其有效性。", "motivation": "移动机器人在太空或灾难救援等危险环境中不可或缺，但通常受限于由人类操作员控制。这种限制导致部署规模有限且需要操作员与机器之间几乎连续的低延迟通信。MOSAIC旨在解决这些问题，并提供一种可扩展的自主性框架。", "method": "本文提出了一种基于兴趣点（POIs）和多层次自主性的多机器人科学探索方案，该方法允许动态任务分配，并通过团队级别的冗余与专业化实现持续操作。实验使用五个不同类型的机器人进行，涉及模拟月球勘探场景的任务。", "result": "在一次包含五个机器人及单个操作员的太空类现场实验中，尽管其中一个机器人完全失败，但团队完成了82.3%的任务，在自主比率（Autonomy Ratio）为86%，同时操作员的工作负荷仅为78.2%。这些结果表明该框架能够支持多机器人科学探索。", "conclusion": "本文提出的MOSAIC框架通过减少对操作员干预的依赖，实现了多机器人团队的有效协调和任务执行。实验数据验证了其在复杂环境中的强大功能，并为未来多机器人探索提供了宝贵的见解。"}}
{"id": "2601.23037", "pdf": "https://arxiv.org/pdf/2601.23037", "abs": "https://arxiv.org/abs/2601.23037", "authors": ["Brayan Monroy", "Jorge Bacca"], "title": "Scale Equivariance Regularization and Feature Lifting in High Dynamic Range Modulo Imaging", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Modulo imaging enables high dynamic range (HDR) acquisition by cyclically wrapping saturated intensities, but accurate reconstruction remains challenging due to ambiguities between natural image edges and artificial wrap discontinuities. This work proposes a learning-based HDR restoration framework that incorporates two key strategies: (i) a scale-equivariant regularization that enforces consistency under exposure variations, and (ii) a feature lifting input design combining the raw modulo image, wrapped finite differences, and a closed-form initialization. Together, these components enhance the network's ability to distinguish true structure from wrapping artifacts, yielding state-of-the-art performance across perceptual and linear HDR quality metrics.", "AI": {"tldr": "提出了一种基于学习的高动态范围（HDR）恢复框架，该框架结合了尺度等变正则化和特征提升输入设计，以提高网络区分真实结构与折叠痕迹的能力。", "motivation": "在模数成像中，准确重建仍面临挑战，特别是在自然图像边缘和人造折叠不连续性之间存在模糊的情况下。作者希望通过引入新的学习方法来解决这些问题，从而实现更精确的HDR恢复。", "method": "该框架利用尺度等变正则化保证了曝光变化下的一致性，并通过结合原始模数图像、包裹有限差分以及闭式初始化设计输入特征，增强了网络区分真实结构的能力。", "result": "这种方法在感知和线性HDR质量度量上均达到了最先进的性能。", "conclusion": "所提出的方法解决了模数成像中的模糊问题，提高了高动态范围图像恢复的质量。"}}
{"id": "2601.23032", "pdf": "https://arxiv.org/pdf/2601.23032", "abs": "https://arxiv.org/abs/2601.23032", "authors": ["Siyu Gong", "Linan Yue", "Weibo Gao", "Fangzhou Yao", "Shimin Di", "Lei Feng", "Min-Ling Zhang"], "title": "Guided by Trajectories: Repairing and Rewarding Tool-Use Trajectories for Tool-Integrated Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Tool-Integrated Reasoning (TIR) enables large language models (LLMs) to solve complex tasks by interacting with external tools, yet existing approaches depend on high-quality synthesized trajectories selected by scoring functions and sparse outcome-based rewards, providing limited and biased supervision for learning TIR. To address these challenges, in this paper, we propose AutoTraj, a two-stage framework that automatically learns TIR by repairing and rewarding tool-use trajectories. Specifically, in the supervised fine-tuning (SFT) stage, AutoTraj generates multiple candidate tool-use trajectories for each query and evaluates them along multiple dimensions. High-quality trajectories are directly retained, while low-quality ones are repaired using a LLM (i.e., LLM-as-Repairer). The resulting repaired and high-quality trajectories form a synthetic SFT dataset, while each repaired trajectory paired with its original low-quality counterpart constitutes a dataset for trajectory preference modeling. In the reinforcement learning (RL) stage, based on the preference dataset, we train a trajectory-level reward model to assess the quality of reasoning paths and combine it with outcome and format rewards, thereby explicitly guiding the optimization toward reliable TIR behaviors. Experiments on real-world benchmarks demonstrate the effectiveness of AutoTraj in TIR.", "AI": {"tldr": "提出了一种自动学习工具集成推理（TIR）的框架AutoTraj，通过修复和奖励工具使用轨迹来解决现有方法依赖高质量合成轨迹的问题。", "motivation": "当前的TIR方法依赖于高质量化合轨迹，并且这些轨迹由评分函数选择并基于稀疏结果进行奖励，这导致学习监督有限并且存在偏差。为了解决这些问题，作者提出了AutoTraj框架。", "method": "AutoTraj包含两个阶段：有监督微调（SFT）和强化学习（RL）。在SFT阶段，生成多个工具使用轨迹候选，并通过多个维度评估它们的质量。高质量的轨迹被保留，而低质量的则通过LLM进行修复。修复后的轨迹与原始低质轨迹对形成数据集，用于训练轨迹偏好模型。在RL阶段，基于此偏好数据集，作者训练了一个奖励模型来评估推理路径，并结合结果和格式奖励。", "result": "实验表明，AutoTraj在TIR方面有效。", "conclusion": "通过提出AutoTraj框架，实现了自动学习工具集成推理的有效方法。"}}
{"id": "2601.23018", "pdf": "https://arxiv.org/pdf/2601.23018", "abs": "https://arxiv.org/abs/2601.23018", "authors": ["Sandra Loop", "Erik Bertram", "Sebastian Juhl", "Martin Schrepp"], "title": "Integrating Multi-Label Classification and Generative AI for Scalable Analysis of User Feedback", "categories": ["cs.HC"], "comment": "8 pages, 2 figures, submitted to Springer Nature", "summary": "In highly competitive software markets, user experience (UX) evaluation is crucial for ensuring software quality and fostering long-term product success. Such UX evaluations typically combine quantitative metrics from standardized questionnaires with qualitative feedback collected through open-ended questions. While open-ended feedback offers valuable insights for improvement and helps explain quantitative results, analyzing large volumes of user comments is challenging and time-consuming. In this paper, we present techniques developed during a long-term UX measurement project at a major software company to efficiently process and interpret extensive volumes of user comments. To provide a high-level overview of the collected comments, we employ a supervised machine learning approach that assigns meaningful, pre-defined topic labels to each comment. Additionally, we demonstrate how generative AI (GenAI) can be leveraged to create concise and informative summaries of user feedback, facilitating effective communication of findings to the organization and especially upper management. Finally, we investigate whether the sentiment expressed in user comments can serve as an indicator for overall product satisfaction. Our results show that sentiment analysis alone does not reliably reflect user satisfaction. Instead, product satisfaction needs to be assessed explicitly in surveys to measure the user's perception of the product.", "AI": {"tldr": "本文提出了一种结合多标签分类和生成式AI的方法，用于大规模用户反馈分析。", "motivation": "在软件市场竞争激烈的背景下，用户体验评估对于保证产品质量和长期成功至关重要。然而，处理大量开放式问题反馈是一个挑战，需要时间和资源。", "method": "通过监督机器学习方法对收集的评论进行多标签分类，并利用生成式AI创建简明的信息摘要，同时研究用户评论中的情感是否可以作为产品满意度的指标。", "result": "结果表明，仅凭情绪分析不能可靠地反映用户的满意度。需要在调查中明确评估产品的感知满意度。", "conclusion": "通过结合多标签分类和生成式AI技术，能够有效地处理大规模的用户反馈，并为组织提供有价值的见解。"}}
{"id": "2601.23011", "pdf": "https://arxiv.org/pdf/2601.23011", "abs": "https://arxiv.org/abs/2601.23011", "authors": ["Blagoj Hristov", "Zoran Hadzi-Velkov", "Katerina Hadzi-Velkova Saneva", "Gorjan Nadzinski", "Vesna Ojleska Latkoska"], "title": "Leveraging Convolutional Sparse Autoencoders for Robust Movement Classification from Low-Density sEMG", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Reliable control of myoelectric prostheses is often hindered by high inter-subject variability and the clinical impracticality of high-density sensor arrays. This study proposes a deep learning framework for accurate gesture recognition using only two surface electromyography (sEMG) channels. The method employs a Convolutional Sparse Autoencoder (CSAE) to extract temporal feature representations directly from raw signals, eliminating the need for heuristic feature engineering. On a 6-class gesture set, our model achieved a multi-subject F1-score of 94.3% $\\pm$ 0.3%. To address subject-specific differences, we present a few-shot transfer learning protocol that improved performance on unseen subjects from a baseline of 35.1% $\\pm$ 3.1% to 92.3% $\\pm$ 0.9% with minimal calibration data. Furthermore, the system supports functional extensibility through an incremental learning strategy, allowing for expansion to a 10-class set with a 90.0% $\\pm$ 0.2% F1-score without full model retraining. By combining high precision with minimal computational and sensor overhead, this framework provides a scalable and efficient approach for the next generation of affordable and adaptive prosthetic systems.", "AI": {"tldr": "利用卷积稀疏自编码器从低密度sEMG信号中提取特征，实现手势分类。", "motivation": "可靠控制肌电假肢受到高个体间差异和高密度传感器阵列临床不实用性的限制。该研究提出了一种深度学习框架，使用仅两个表面肌电信号通道进行准确的手势识别。", "method": "方法采用卷积稀疏自编码器直接从原始信号中提取时间特征表示，并且通过少量样本迁移学习和增量学习策略提高系统性能。", "result": "在六类手势集合上获得多主体F1评分为94.3%±0.3%，并且使用少量校准数据将未见过的主体表现由基线的35.1%±3.1%提升至92.3%±0.9%，同时扩展到十类集合时，无需重新训练模型即可获得90.0%±0.2%的F1评分。", "conclusion": "该研究通过结合高精度与最小计算和传感器开销提供了一种可扩展且高效的框架，用于下一代低成本自适应假肢系统。"}}
{"id": "2601.23010", "pdf": "https://arxiv.org/pdf/2601.23010", "abs": "https://arxiv.org/abs/2601.23010", "authors": ["Xinchen Han", "Qiuyang Fang", "Hossam Afifi", "Michel Marot"], "title": "Automatic Constraint Policy Optimization based on Continuous Constraint Interpolation Framework for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline Reinforcement Learning (RL) relies on policy constraints to mitigate extrapolation error, where both the constraint form and constraint strength critically shape performance. However, most existing methods commit to a single constraint family: weighted behavior cloning, density regularization, or support constraints, without a unified principle that explains their connections or trade-offs. In this work, we propose Continuous Constraint Interpolation (CCI), a unified optimization framework in which these three constraint families arise as special cases along a common constraint spectrum. The CCI framework introduces a single interpolation parameter that enables smooth transitions and principled combinations across constraint types. Building on CCI, we develop Automatic Constraint Policy Optimization (ACPO), a practical primal--dual algorithm that adapts the interpolation parameter via a Lagrangian dual update. Moreover, we establish a maximum-entropy performance difference lemma and derive performance lower bounds for both the closed-form optimal policy and its parametric projection. Experiments on D4RL and NeoRL2 demonstrate robust gains across diverse domains, achieving state-of-the-art performance overall.", "AI": {"tldr": "本文提出了一种基于连续约束插值框架的离线强化学习中的自动约束策略优化方法，该方法通过单一插值参数实现不同约束类型的平滑过渡和组合。", "motivation": "大多数现有方法依赖于特定的约束类型，缺乏统一的原则来解释这些约束之间的联系或权衡。本文旨在提供一种能够将不同类型约束结合在一起的方法以解决这一问题。", "method": "通过引入连续约束插值（CCI）框架，该框架允许三种主要约束形式作为特殊案例出现在共同约束光谱上。基于CCI，开发了自动约束策略优化（ACPO），这是一种实用的原对偶算法，能够根据拉格朗日对偶更新适应插值参数。", "result": "实验结果表明，在D4RL和NeoRL2等数据集上的多个领域中均实现了稳健的优势，并且总体上达到了最先进的性能水平。", "conclusion": "通过提出一种基于连续约束的离线强化学习框架，能够有效地结合不同类型的约束，从而提高策略优化的灵活性和性能。"}}
{"id": "2601.23007", "pdf": "https://arxiv.org/pdf/2601.23007", "abs": "https://arxiv.org/abs/2601.23007", "authors": ["Francesco Campi", "Lucrezia Tondo", "Ekin Karabati", "Johannes Betge", "Marie Piraud"], "title": "Leveraging Multi-Rater Annotations to Calibrate Object Detectors in Microscopy Imaging", "categories": ["cs.CV"], "comment": "Accepted as a conference paper at ISBI 2026", "summary": "Deep learning-based object detectors have achieved impressive performance in microscopy imaging, yet their confidence estimates often lack calibration, limiting their reliability for biomedical applications. In this work, we introduce a new approach to improve model calibration by leveraging multi-rater annotations. We propose to train separate models on the annotations from single experts and aggregate their predictions to emulate consensus. This improves upon label sampling strategies, where models are trained on mixed annotations, and offers a more principled way to capture inter-rater variability. Experiments on a colorectal organoid dataset annotated by two experts demonstrate that our rater-specific ensemble strategy improves calibration performance while maintaining comparable detection accuracy. These findings suggest that explicitly modelling rater disagreement can lead to more trustworthy object detectors in biomedical imaging.", "AI": {"tldr": "该论文提出了利用多评注者标注来校准显微图像中的目标检测器的新方法。", "motivation": "基于深度学习的目标检测器在显微成像中表现出色，但其置信度估计通常缺乏校正，限制了它们在生物医学应用中的可靠性。为此，论文引入了一种新方法以提高模型的校准性能。", "method": "提出训练单独模型使用单一专家标注，并聚合预测来模拟共识。这种方法相较于基于混合注释标签采样的策略更为原理化地捕捉评注者之间的差异。", "result": "在由两名专家注释的数据集上进行实验显示，该特定评注者的集合策略可以提高校准性能同时保持相当的检测精度。", "conclusion": "研究结果表明，显式建模评注者间的分歧能够获得更为可信的目标检测器用于生物医学成像。"}}
{"id": "2601.23001", "pdf": "https://arxiv.org/pdf/2601.23001", "abs": "https://arxiv.org/abs/2601.23001", "authors": ["Afrozah Nadeem", "Agrima", "Mehwish Nasim", "Usman Naseem"], "title": "Bias Beyond Borders: Political Ideology Evaluation and Steering in Multilingual LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "PrePrint", "summary": "Large Language Models (LLMs) increasingly shape global discourse, making fairness and ideological neutrality essential for responsible AI deployment. Despite growing attention to political bias in LLMs, prior work largely focuses on high-resource, Western languages or narrow multilingual settings, leaving cross-lingual consistency and safe post-hoc mitigation underexplored. To address this gap, we present a large-scale multilingual evaluation of political bias spanning 50 countries and 33 languages. We introduce a complementary post-hoc mitigation framework, Cross-Lingual Alignment Steering (CLAS), designed to augment existing steering methods by aligning ideological representations across languages and dynamically regulating intervention strength. This method aligns latent ideological representations induced by political prompts into a shared ideological subspace, ensuring cross lingual consistency, with the adaptive mechanism prevents over correction and preserves coherence. Experiments demonstrate substantial bias reduction along both economic and social axes with minimal degradation in response quality. The proposed framework establishes a scalable and interpretable paradigm for fairness-aware multilingual LLM governance, balancing ideological neutrality with linguistic and cultural diversity.", "AI": {"tldr": "该论文旨在评估大型语言模型（LLMs）在多语种环境中的政治偏见，并提出一种名为跨语言对齐导向（CLAS）的后处理框架，以减少这些偏见。", "motivation": "随着大型语言模型在全球范围内塑造话语的趋势日益增长，确保其公平性和意识形态中立性成为负责任地部署AI的关键。然而，现有的研究主要关注高资源、西方语境或狭窄多语种环境中的政治偏见问题，跨语言一致性以及安全的后处理方法尚未得到充分探讨。", "method": "论文提出了一项涉及50个国家和33种语言的大规模多语言评估，并介绍了一种名为跨语言对齐导向（CLAS）的新框架。该框架旨在通过将由政治提示引发的隐含意识形态表示对齐到共享意识形态子空间中，增强现有导向方法的能力。", "result": "实验结果显示，在减少经济和社交维度的政治偏见方面取得了显著进展，并且这种方法能够最大程度地保留响应质量。", "conclusion": "该论文提出了一种可扩展且具有解释性的多语言大型语言模型治理框架，旨在平衡意识形态中立性与语言及文化多样性。"}}
{"id": "2601.23000", "pdf": "https://arxiv.org/pdf/2601.23000", "abs": "https://arxiv.org/abs/2601.23000", "authors": ["Yufei Gu", "Zeke Xie"], "title": "Mano: Restriking Manifold Optimization for LLM Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While large language models (LLMs) have emerged as a significant advancement in artificial intelligence, the hardware and computational costs for training LLMs are also significantly burdensome. Among the state-of-the-art optimizers, AdamW relies on diagonal curvature estimates and ignores structural properties, while Muon applies global spectral normalization at the expense of losing curvature information. In this study, we restriked manifold optimization methods for training LLMs, which may address both optimizers' limitations, while conventional manifold optimization methods have been largely overlooked due to the poor performance in large-scale model optimization. By innovatively projecting the momentum onto the tangent space of model parameters and constraining it on a rotational Oblique manifold, we propose a novel, powerful, and efficient optimizer **Mano** that is the first to bridge the performance gap between manifold optimization and modern optimizers. Extensive experiments on the LLaMA and Qwen3 models demonstrate that Mano consistently and significantly outperforms AdamW and Muon even with less memory consumption and computational complexity, respectively, suggesting an expanded Pareto frontier in terms of space and time efficiency.", "AI": {"tldr": "提出了一种新的优化器Mano，用于解决大规模语言模型训练中的硬件和计算成本问题。", "motivation": "现有优化器如AdamW忽略结构属性，Muon则在全局光谱归一化上损失了曲率信息。传统流形优化方法性能不佳，因此本文开发一种创新的流形优化方法以平衡现代优化器的优点。", "method": "通过将动量投影到模型参数的切空间并限制其在一个旋转斜面流形上，提出了Mano优化器，这是首个连接流形优化和现代优化器表现差距的新颖、强大且高效的优化器。", "result": "在LLaMA和Qwen3等大规模语言模型上的实验表明，相较于AdamW和Muon，Mano具有更高的性能并分别减少了内存消耗和计算复杂度。", "conclusion": "Mano不仅提高了大型语言模型的训练效率，还扩展了空间与时间效率方面的帕累托前沿。"}}
{"id": "2601.22997", "pdf": "https://arxiv.org/pdf/2601.22997", "abs": "https://arxiv.org/abs/2601.22997", "authors": ["Roham Koohestani", "Ateş Görpelioğlu", "Egor Klimov", "Burcu Kulahcioglu Ozkan", "Maliheh Izadi"], "title": "TriCEGAR: A Trace-Driven Abstraction Mechanism for Agentic AI", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Agentic AI systems act through tools and evolve their behavior over long, stochastic interaction traces. This setting complicates assurance, because behavior depends on nondeterministic environments and probabilistic model outputs. Prior work introduced runtime verification for agentic AI via Dynamic Probabilistic Assurance (DPA), learning an MDP online and model checking quantitative properties. A key limitation is that developers must manually define the state abstraction, which couples verification to application-specific heuristics and increases adoption friction. This paper proposes TriCEGAR, a trace-driven abstraction mechanism that automates state construction from execution logs and supports online construction of an agent behavioral MDP. TriCEGAR represents abstractions as predicate trees learned from traces and refined using counterexamples. We describe a framework-native implementation that (i) captures typed agent lifecycle events, (ii) builds abstractions from traces, (iii) constructs an MDP, and (iv) performs probabilistic model checking to compute bounds such as Pmax(success) and Pmin(failure). We also show how run likelihoods enable anomaly detection as a guardrailing signal.", "AI": {"tldr": "提出了一种基于轨迹驱动的抽象机制TriCEGAR，用于自动构建代理行为MDP，并进行概率模型检查。", "motivation": "现有方法需要手动定义状态抽象，这增加了开发摩擦。TriCEGAR旨在通过从执行日志中学习并使用反例来细化抽象，从而自动化这一过程。", "method": "提出了一个框架原生实现的TriCEGAR机制，该机制包括捕捉代理生命周期事件、构建抽象、构造MDP以及进行概率模型检查等步骤。", "result": "展示了如何利用运行可能性来进行异常检测，并通过计算最大成功概率和最小失败概率来提供防护信号。", "conclusion": "TriCEGAR提高了代理行为验证的自动化程度，减轻了开发者的负担，同时支持在线构建代理行为MDP并进行概率模型检查。"}}
{"id": "2601.22996", "pdf": "https://arxiv.org/pdf/2601.22996", "abs": "https://arxiv.org/abs/2601.22996", "authors": ["Yiding Feng", "Zonghan Yang", "Yuhao Zhang"], "title": "Competitive Non-Clairvoyant KV-Cache Scheduling for LLM Inference", "categories": ["cs.DS"], "comment": null, "summary": "Large Language Model (LLM) inference presents a unique scheduling challenge due to the Key-Value (KV) cache, where a job's memory footprint grows linearly with the number of decoded tokens. This growth couples scheduling decisions with feasibility: a scheduler must minimize latency under a hard memory budget, yet the response lengths of requests are inherently unknown. While recent works have explored this problem either assuming clairvoyance -- exact knowledge of response lengths -- or relying on machine-learned predictions, obtaining robust performance guarantees without any prior knowledge of job sizes remains a theoretically fundamental and practically important open problem. In this work, we propose the Geometric Slicing Algorithm (GSA), the non-clairvoyant policy to achieve the first constant competitive ratio for this problem in the offline batch setting. GSA manages uncertainty through a geometric phase structure that periodically restarts jobs to bound memory exposure, combined with a staggered pipeline mechanism that enables high concurrency by smoothing aggregate memory consumption. We prove that GSA achieves a competitive ratio of at most 61.92 for general instances, improving to 32 in the large-memory regime. Our algorithmic framework also yields a clairvoyant counterpart, the Geometric Batching Algorithm (GBA), which achieves an approximation ratio of 10.67 for general instances and 6.75 in the large-memory regime -- significantly improving upon the best previously known bound of over 9000. Numerical experiments on real request traces demonstrate that our algorithms perform robustly while preserving these worst-case guarantees.", "AI": {"tldr": "提出了一种非clairvoyant的KV缓存调度算法GSA，以解决LLM推理中的内存预算和不确定性问题。", "motivation": "大型语言模型（LLM）推理中KV缓存导致的任务内存消耗随解码令牌数量线性增长使得调度决策变得困难。缺乏对任务规模的确切了解是实现强大性能保证的关键挑战。", "method": "提出了几何分割算法(GSA)，通过分阶段结构和交错流水线机制管理不确定性，以在离线批次设置中达到首个常数竞争比。", "result": "GSA对于一般实例的竞争比不超过61.92，在大内存环境中改善至32。其clairvoyant版本GBA则分别实现了10.67和6.75的近似比值，优于先前最佳结果的9000以上。", "conclusion": "实验表明所提算法在实际请求跟踪中表现出色，同时保持了最坏情况下的性能保证。"}}
{"id": "2601.22990", "pdf": "https://arxiv.org/pdf/2601.22990", "abs": "https://arxiv.org/abs/2601.22990", "authors": ["Yinsong Wang", "Thomas Fletcher", "Xinzhe Luo", "Aine Travers Dineen", "Rhodri Cusack", "Chen Qin"], "title": "Self-Supervised Slice-to-Volume Reconstruction with Gaussian Representations for Fetal MRI", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Reconstructing 3D fetal MR volumes from motion-corrupted stacks of 2D slices is a crucial and challenging task. Conventional slice-to-volume reconstruction (SVR) methods are time-consuming and require multiple orthogonal stacks for reconstruction. While learning-based SVR approaches have significantly reduced the time required at the inference stage, they heavily rely on ground truth information for training, which is inaccessible in practice. To address these challenges, we propose GaussianSVR, a self-supervised framework for slice-to-volume reconstruction. GaussianSVR represents the target volume using 3D Gaussian representations to achieve high-fidelity reconstruction. It leverages a simulated forward slice acquisition model to enable self-supervised training, alleviating the need for ground-truth volumes. Furthermore, to enhance both accuracy and efficiency, we introduce a multi-resolution training strategy that jointly optimizes Gaussian parameters and spatial transformations across different resolution levels. Experiments show that GaussianSVR outperforms the baseline methods on fetal MR volumetric reconstruction. Code will be available upon acceptance.", "AI": {"tldr": "提出了一种使用高斯表示的自监督胎儿MRI重建方法。", "motivation": "常规的切片到体积重建方法耗时且需要多组正交切片，而基于学习的方法虽然提高了效率但依赖于实际无法获取的真实数据进行训练。", "method": "GaussianSVR利用3D高斯表示来实现高质量重建，并采用模拟前向切片采集模型来进行自监督训练。引入了多分辨率策略以提高准确性和效率。", "result": "实验表明，所提方法在胎儿MRI体素重建中优于基线方法。", "conclusion": "GaussianSVR提供了一种高效且不需要真实标签的胎儿MRI体积重建的新途径。"}}
{"id": "2601.22988", "pdf": "https://arxiv.org/pdf/2601.22988", "abs": "https://arxiv.org/abs/2601.22988", "authors": ["Di Zhang", "Weicheng Duan", "Dasen Gu", "Hongye Lu", "Hai Zhang", "Hang Yu", "Junqiao Zhao", "Guang Chen"], "title": "Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Real-world robotic manipulation demands visuomotor policies capable of robust spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric structures essential for precise manipulation, and lack of effective policy training strategies to retain and exploit the acquired 3D knowledge. To address these challenges, we present MethodName, a unified representation-policy learning framework for view-generalizable robotic manipulation. MethodName introduces a single-view 3D pretraining paradigm that leverages point cloud reconstruction and feed-forward gaussian splatting under multi-view supervision to learn holistic geometric representations. During policy learning, MethodName performs multi-step distillation to preserve the pretrained geometric understanding and effectively transfer it to manipulation skills. We conduct experiments on 12 RLBench tasks, where our approach outperforms the previous state-of-the-art method by 12.7% in average success rate. Further evaluation on six representative tasks demonstrates strong zero-shot view generalization, with success rate drops of only 22.0% and 29.7% under moderate and large viewpoint shifts respectively, whereas the state-of-the-art method suffers larger decreases of 41.6% and 51.5%.", "AI": {"tldr": "该论文提出了一种新的视角普适的机器人抓取方法，通过单一视图下的三维预训练和策略学习框架来提升场景理解和操作技能。", "motivation": "现有技术在处理单一视图限制时存在不足，无法全面捕捉几何结构，并且缺少有效的策略培训以保留所获得的知识。因此需要一种新的视角普适的方法。", "method": "MethodName引入了单视图三维预训练范式以及多步蒸馏机制来保持预先学习的几何理解并将其转移到操作技能中。", "result": "在12项RLBench任务中的表现优于之前的方法，平均成功率高出12.7%；零样本视角泛化能力表现出色，仅分别下降了22.0%和29.7%，而SOTA方法的性能则大幅降低。", "conclusion": "MethodName通过单视图三维预训练范式实现了有效的场景理解和操作技能转移，并展示了在不同视角下的强大鲁棒性。"}}
{"id": "2601.22984", "pdf": "https://arxiv.org/pdf/2601.22984", "abs": "https://arxiv.org/abs/2601.22984", "authors": ["Yuhao Zhan", "Tianyu Fan", "Linxuan Huang", "Zirui Guo", "Chao Huang"], "title": "Why Your Deep Research Agent Fails? On Hallucination Evaluation in Full Research Trajectory", "categories": ["cs.AI"], "comment": null, "summary": "Diagnosing the failure mechanisms of Deep Research Agents (DRAs) remains a critical challenge. Existing benchmarks predominantly rely on end-to-end evaluation, obscuring critical intermediate hallucinations, such as flawed planning, that accumulate throughout the research trajectory. To bridge this gap, we propose a shift from outcome-based to process-aware evaluation by auditing the full research trajectory. We introduce the PIES Taxonomy to categorize hallucinations along functional components (Planning vs. Summarization) and error properties (Explicit vs. Implicit). We instantiate this taxonomy into a fine-grained evaluation framework that decomposes the trajectory to rigorously quantify these hallucinations. Leveraging this framework to isolate 100 distinctively hallucination-prone tasks including adversarial scenarios, we curate DeepHalluBench. Experiments on six state-of-theart DRAs reveal that no system achieves robust reliability. Furthermore, our diagnostic analysis traces the etiology of these failures to systemic deficits, specifically hallucination propagation and cognitive biases, providing foundational insights to guide future architectural optimization. Data and code are available at https://github.com/yuhao-zhan/DeepHalluBench.", "AI": {"tldr": "本文提出了一个从过程角度评估深度研究代理（DRAs）的框架，通过PIES分类法来识别和量化在整个研究轨迹中的幻觉问题，并开发了一套新的基准测试DeepHalluBench。", "motivation": "现有评估标准主要基于最终结果，忽略了在研究过程中积累的重要中间幻觉，如错误规划等。为了克服这一限制，作者建议从过程角度进行更全面的评估。", "method": "引入PIES分类法将幻觉按照功能组件（计划与总结）和错误特性（明确与隐含）进行分类，并开发一个细致的评估框架来分解研究轨迹并量化这些幻觉。利用此框架确定了100个具有不同幻觉倾向的任务，包括对抗性场景。", "result": "实验结果显示，六个最先进的DRAs在基准测试中的表现都不稳定可靠。诊断分析表明，这些问题的根本原因在于系统缺陷和认知偏差。", "conclusion": "通过新的评估方法和框架，本文揭示了DRAs失败机制的关键方面，并为未来架构优化提供了基础见解。"}}
{"id": "2601.22982", "pdf": "https://arxiv.org/pdf/2601.22982", "abs": "https://arxiv.org/abs/2601.22982", "authors": ["Wataru Uemura", "Takeru Nagashima"], "title": "About an Automating Annotation Method for Robot Markers", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "ef:Machine Learning and Applications: An International Journal (MLAIJ), Vol. 12, No. 4, pp. 1-9, 2025", "summary": "Factory automation has become increasingly important due to labor shortages, leading to the introduction of autonomous mobile robots for tasks such as material transportation. Markers are commonly used for robot self-localization and object identification. In the RoboCup Logistics League (RCLL), ArUco markers are employed both for robot localization and for identifying processing modules. Conventional recognition relies on OpenCV-based image processing, which detects black-and-white marker patterns. However, these methods often fail under noise, motion blur, defocus, or varying illumination conditions. Deep-learning-based recognition offers improved robustness under such conditions, but requires large amounts of annotated data. Annotation must typically be done manually, as the type and position of objects cannot be detected automatically, making dataset preparation a major bottleneck. In contrast, ArUco markers include built-in recognition modules that provide both ID and positional information, enabling automatic annotation. This paper proposes an automated annotation method for training deep-learning models on ArUco marker images. By leveraging marker detection results obtained from the ArUco module, the proposed approach eliminates the need for manual labeling. A YOLO-based model is trained using the automatically annotated dataset, and its performance is evaluated under various conditions. Experimental results demonstrate that the proposed method improves recognition performance compared with conventional image-processing techniques, particularly for images affected by blur or defocus. Automatic annotation also reduces human effort and ensures consistent labeling quality. Future work will investigate the relationship between confidence thresholds and recognition performance.", "AI": {"tldr": "本文提出了一种基于ArUco标记的自动化标注方法，用于训练深度学习模型，并通过实验验证了该方法在图像模糊和焦距变化等条件下优于传统图像处理技术。", "motivation": "工厂自动化需要解决劳动力短缺问题，引入自主移动机器人进行物料运输。传统的标记识别依赖于OpenCV等方法，在噪声、运动模糊或光照变化下表现不佳，而深度学习模型虽然鲁棒性更强但需要大量标注数据，手动标注耗时且容易出错。", "method": "利用ArUco标记自带的检测模块自动获取位置信息进行标注，训练YOLO模型并在不同条件下评估其性能。", "result": "实验表明所提出的方法在图像模糊和焦距变化等情况下优于传统方法，并减少了人工标注的工作量保证了标签的一致性。", "conclusion": "自动化标记技术可以提高深度学习模型的识别效果并减少人力成本，未来工作将探讨置信度阈值对性能的影响。"}}
{"id": "2601.22977", "pdf": "https://arxiv.org/pdf/2601.22977", "abs": "https://arxiv.org/abs/2601.22977", "authors": ["Lei You"], "title": "Quantifying Model Uniqueness in Heterogeneous AI Ecosystems", "categories": ["cs.AI"], "comment": null, "summary": "As AI systems evolve from isolated predictors into complex, heterogeneous ecosystems of foundation models and specialized adapters, distinguishing genuine behavioral novelty from functional redundancy becomes a critical governance challenge. Here, we introduce a statistical framework for auditing model uniqueness based on In-Silico Quasi-Experimental Design (ISQED). By enforcing matched interventions across models, we isolate intrinsic model identity and quantify uniqueness as the Peer-Inexpressible Residual (PIER), i.e. the component of a target's behavior strictly irreducible to any stochastic convex combination of its peers, with vanishing PIER characterizing when such a routing-based substitution becomes possible. We establish the theoretical foundations of ecosystem auditing through three key contributions. First, we prove a fundamental limitation of observational logs: uniqueness is mathematically non-identifiable without intervention control. Second, we derive a scaling law for active auditing, showing that our adaptive query protocol achieves minimax-optimal sample efficiency ($dσ^2γ^{-2}\\log(Nd/δ)$). Third, we demonstrate that cooperative game-theoretic methods, such as Shapley values, fundamentally fail to detect redundancy. We implement this framework via the DISCO (Design-Integrated Synthetic Control) estimator and deploy it across diverse ecosystems, including computer vision models (ResNet/ConvNeXt/ViT), large language models (BERT/RoBERTa), and city-scale traffic forecasters. These results move trustworthy AI beyond explaining single models: they establish a principled, intervention-based science of auditing and governing heterogeneous model ecosystems.", "AI": {"tldr": "介绍一种统计框架用于评估人工智能生态系统中模型的独特性。", "motivation": "随着AI系统从孤立预测者演变为复杂的、异质的生态系统，区分真正的行为新颖性和功能冗余成为治理挑战。引入此框架以解决该问题。", "method": "基于ISQED设计了一个统计框架，通过强制执行匹配干预来隔离模型内在身份，并量化独特性作为Peer-Inexpressible Residual (PIER)。", "result": "验证了观测日志的独特性难以识别、展示了适应查询协议的高效样本效率以及证明了合作博弈方法在检测冗余方面的局限性。该框架已部署于计算机视觉、大型语言模型和城市交通预测系统中。", "conclusion": "通过干预控制建立了评估异质AI生态系统独特性的原理，推进了可信赖AI的研究，并确立了一个基于干预的审计科学。"}}
{"id": "2601.22975", "pdf": "https://arxiv.org/pdf/2601.22975", "abs": "https://arxiv.org/abs/2601.22975", "authors": ["Ximing Lu", "David Acuna", "Jaehun Jung", "Jian Hu", "Di Zhang", "Shizhe Diao", "Yunheng Zou", "Shaokun Zhang", "Brandon Cui", "Mingjie Liu", "Hyunwoo Kim", "Prithviraj Ammanabrolu", "Jan Kautz", "Yi Dong", "Yejin Choi"], "title": "Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a cornerstone for unlocking complex reasoning in Large Language Models (LLMs). Yet, scaling up RL is bottlenecked by limited existing verifiable data, where improvements increasingly saturate over prolonged training. To overcome this, we propose Golden Goose, a simple trick to synthesize unlimited RLVR tasks from unverifiable internet text by constructing a multiple-choice question-answering version of the fill-in-the-middle task. Given a source text, we prompt an LLM to identify and mask key reasoning steps, then generate a set of diverse, plausible distractors. This enables us to leverage reasoning-rich unverifiable corpora typically excluded from prior RLVR data construction (e.g., science textbooks) to synthesize GooseReason-0.7M, a large-scale RLVR dataset with over 0.7 million tasks spanning mathematics, programming, and general scientific domains. Empirically, GooseReason effectively revives models saturated on existing RLVR data, yielding robust, sustained gains under continuous RL and achieving new state-of-the-art results for 1.5B and 4B-Instruct models across 15 diverse benchmarks. Finally, we deploy Golden Goose in a real-world setting, synthesizing RLVR tasks from raw FineWeb scrapes for the cybersecurity domain, where no prior RLVR data exists. Training Qwen3-4B-Instruct on the resulting data GooseReason-Cyber sets a new state-of-the-art in cybersecurity, surpassing a 7B domain-specialized model with extensive domain-specific pre-training and post-training. This highlights the potential of automatically scaling up RLVR data by exploiting abundant, reasoning-rich, unverifiable internet text.", "AI": {"tldr": "该论文提出了一种称为Golden Goose的技术，用于从未经验证的互联网文本中生成无限数量的RLVR任务。", "motivation": "为了克服现有可验证数据有限的问题，并促进大型语言模型在复杂推理中的学习，提出了Golden Goose技术以利用丰富的未验证网络文本来扩展RLVR数据集。", "method": "通过构造多选问答形式的任务，从源文本中识别并掩盖关键推理步骤，生成多样且合理的干扰选项。这使我们能够使用通常被排除在外的富含推理内容的未经验证语料库（如科学教科书）来构建大规模RLVR数据集GooseReason-0.7M。", "result": "实验表明，Golden Goose技术有效提升了模型在现有RLVR数据上的表现，并取得了新的最佳结果。此外，在网络安全领域应用该技术时也超越了一个专门预训练的大型模型。", "conclusion": "通过自动扩展RLVR数据集并利用互联网中丰富的未经验证文本资源，Golden Goose展示了其在促进大规模强化学习和语言建模中的潜力。"}}
{"id": "2601.22974", "pdf": "https://arxiv.org/pdf/2601.22974", "abs": "https://arxiv.org/abs/2601.22974", "authors": ["XiaoJie Zhang", "JianHan Wu", "Xiaoyang Qu", "Jianzong Wang"], "title": "MiTa: A Hierarchical Multi-Agent Collaboration Framework with Memory-integrated and Task Allocation", "categories": ["cs.ET", "cs.CL"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Recent advances in large language models (LLMs) have substantially accelerated the development of embodied agents. LLM-based multi-agent systems mitigate the inefficiency of single agents in complex tasks. However, they still suffer from issues such as memory inconsistency and agent behavioral conflicts. To address these challenges, we propose MiTa, a hierarchical memory-integrated task allocative framework to enhance collaborative efficiency. MiTa organizes agents into a manager-member hierarchy, where the manager incorporates additional allocation and summary modules that enable (1) global task allocation and (2) episodic memory integration. The allocation module enables the manager to allocate tasks from a global perspective, thereby avoiding potential inter-agent conflicts. The summary module, triggered by task progress updates, performs episodic memory integration by condensing recent collaboration history into a concise summary that preserves long-horizon context. By combining task allocation with episodic memory, MiTa attains a clearer understanding of the task and facilitates globally consistent task distribution. Experimental results confirm that MiTa achieves superior efficiency and adaptability in complex multi-agent cooperation over strong baseline methods.", "AI": {"tldr": "MiTa是一个层次化的多智能体协作框架，旨在通过内存集成和任务分配解决多智能体系统中的记忆不一致和行为冲突问题。", "motivation": "为了改善基于大型语言模型的多智能体系统的不足之处，包括记忆一致性问题和智能体间的行为冲突，提出了MiTa框架来增强合作效率。", "method": "MiTa通过将代理组织成管理者-成员层次结构，并引入任务分配模块和摘要模块实现了全局任务分配并集成情节记忆。这使得管理器能够从整体视角进行任务分配以避免潜在的代理冲突，并且根据任务进度更新触发的情节记忆整合，简化了最近的合作历史。", "result": "实验结果显示，MiTa在复杂的多智能体合作中取得了更高的效率和适应性，超过了强大的基准方法。", "conclusion": "提出的MiTa框架通过结合任务分配与情节记忆，在解决多代理系统中的冲突和不一致方面表现出了优势。"}}
{"id": "2601.22970", "pdf": "https://arxiv.org/pdf/2601.22970", "abs": "https://arxiv.org/abs/2601.22970", "authors": ["Jeong Woon Lee", "Kyoleen Kwak", "Daeho Kim", "Hyoseok Hwang"], "title": "Stabilizing the Q-Gradient Field for Policy Smoothness in Actor-Critic", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Policies learned via continuous actor-critic methods often exhibit erratic, high-frequency oscillations, making them unsuitable for physical deployment. Current approaches attempt to enforce smoothness by directly regularizing the policy's output. We argue that this approach treats the symptom rather than the cause. In this work, we theoretically establish that policy non-smoothness is fundamentally governed by the differential geometry of the critic. By applying implicit differentiation to the actor-critic objective, we prove that the sensitivity of the optimal policy is bounded by the ratio of the Q-function's mixed-partial derivative (noise sensitivity) to its action-space curvature (signal distinctness). To empirically validate this theoretical insight, we introduce PAVE (Policy-Aware Value-field Equalization), a critic-centric regularization framework that treats the critic as a scalar field and stabilizes its induced action-gradient field. PAVE rectifies the learning signal by minimizing the Q-gradient volatility while preserving local curvature. Experimental results demonstrate that PAVE achieves smoothness and robustness comparable to policy-side smoothness regularization methods, while maintaining competitive task performance, without modifying the actor.", "AI": {"tldr": "本文提出PAVE框架，通过稳定Q函数的梯度场来解决策略非平滑性问题。", "motivation": "连续actor-critic方法学习到的策略常常存在高频震荡，直接对策略进行平滑处理只是治标不治本。理论分析表明，策略非平滑的根本原因在于批评家（critic）的微分几何特性。", "method": "通过隐式微分技术分析actor-critic目标函数，证明了策略敏感性的边界条件，并引入PAVE框架，在保持局部曲率的同时最小化Q梯度波动，从而稳定学习信号。", "result": "实验结果表明，与直接对策略进行平滑处理的方法相比，PAVE在保持任务性能的同时实现了相当的平滑性和鲁棒性。", "conclusion": "PAVE通过稳定的批评家（critic）视角解决了策略非平滑问题，并证明了这一方法的有效性和竞争力。"}}
{"id": "2601.22965", "pdf": "https://arxiv.org/pdf/2601.22965", "abs": "https://arxiv.org/abs/2601.22965", "authors": ["Runhua Zhang", "Junyi Hou", "Changxu Cheng", "Qiyi Chen", "Tao Wang", "Wuyue Zhao"], "title": "Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation", "categories": ["cs.RO"], "comment": "Preprint", "summary": "Diffusion policies (DP) have demonstrated significant potential in visual navigation by capturing diverse multi-modal trajectory distributions. However, standard imitation learning (IL), which most DP methods rely on for training, often inherits sub-optimality and redundancy from expert demonstrations, thereby necessitating a computationally intensive \"generate-then-filter\" pipeline that relies on auxiliary selectors during inference. To address these challenges, we propose Self-Imitated Diffusion Policy (SIDP), a novel framework that learns improved planning by selectively imitating a set of trajectories sampled from itself. Specifically, SIDP introduces a reward-guided self-imitation mechanism that encourages the policy to consistently produce high-quality trajectories efficiently, rather than outputs of inconsistent quality, thereby reducing reliance on extensive sampling and post-filtering. During training, we employ a reward-driven curriculum learning paradigm to mitigate inefficient data utility, and goal-agnostic exploration for trajectory augmentation to improve planning robustness. Extensive evaluations on a comprehensive simulation benchmark show that SIDP significantly outperforms previous methods, with real-world experiments confirming its effectiveness across multiple robotic platforms. On Jetson Orin Nano, SIDP delivers a 2.5$\\times$ faster inference than the baseline NavDP, i.e., 110ms VS 273ms, enabling efficient real-time deployment.", "AI": {"tldr": "该论文提出了Self-Imitated Diffusion Policy（SIDP），用于高效且鲁棒的视觉导航，通过自我模仿机制改进规划。", "motivation": "扩散策略在视觉导航中表现出色但依赖于标准模仿学习，后者继承了专家演示中的次优性和冗余性。这导致需要复杂的“生成-过滤”管道和辅助选择器，从而增加计算负担。", "method": "SIDP引入了一种奖励引导的自我模仿机制，在训练期间使用奖励驱动的课程学习来提高数据利用率，并采用目标无关探索增强轨迹扩展以提升规划鲁棒性。", "result": "SIDP在广泛模拟基准测试中显著优于先前方法，且真实世界实验验证了其多平台的有效性。Jetson Orin Nano上，SIDP比基线NavDP快2.5倍，即110ms对比273ms。", "conclusion": "SIDP通过自我模仿机制改进规划，并实现了高效的实时部署，提升了视觉导航的效率和鲁棒性。"}}
{"id": "2601.22964", "pdf": "https://arxiv.org/pdf/2601.22964", "abs": "https://arxiv.org/abs/2601.22964", "authors": ["Yufei He", "Juncheng Liu", "Zhiyuan Hu", "Yulin Chen", "Yue Liu", "Yuan Sui", "Yibo Li", "Nuo Chen", "Jun Hu", "Bryan Hooi", "Xinxing Xu", "Jiang Bian"], "title": "EvoClinician: A Self-Evolving Agent for Multi-Turn Medical Diagnosis via Test-Time Evolutionary Learning", "categories": ["cs.AI"], "comment": null, "summary": "Prevailing medical AI operates on an unrealistic ''one-shot'' model, diagnosing from a complete patient file. However, real-world diagnosis is an iterative inquiry where Clinicians sequentially ask questions and order tests to strategically gather information while managing cost and time. To address this, we first propose Med-Inquire, a new benchmark designed to evaluate an agent's ability to perform multi-turn diagnosis. Built upon a dataset of real-world clinical cases, Med-Inquire simulates the diagnostic process by hiding a complete patient file behind specialized Patient and Examination agents. They force the agent to proactively ask questions and order tests to gather information piece by piece. To tackle the challenges posed by Med-Inquire, we then introduce EvoClinician, a self-evolving agent that learns efficient diagnostic strategies at test time. Its core is a ''Diagnose-Grade-Evolve'' loop: an Actor agent attempts a diagnosis; a Process Grader agent performs credit assignment by evaluating each action for both clinical yield and resource efficiency; finally, an Evolver agent uses this feedback to update the Actor's strategy by evolving its prompt and memory. Our experiments show EvoClinician outperforms continual learning baselines and other self-evolving agents like memory agents. The code is available at https://github.com/yf-he/EvoClinician", "AI": {"tldr": "提出了一种名为EvoClinician的自我进化代理，用于多轮医疗诊断。", "motivation": "现有的医学AI依赖于一次性模型进行诊断，而现实中的诊断过程是逐步且迭代的。为了模拟这一过程并评估代理的能力，提出了Med-Inquire基准测试。", "method": "设计了名为EvoClinician的自我进化代理，通过Diagnose-Grade-Evolve循环在运行时学习有效的诊断策略：演员代理进行诊断；评价者代理根据临床收益和资源效率评定每个动作的价值；进化器代理使用反馈更新演员代理的策略。", "result": "实验表明，EvoClinician优于连续学习基准和其他自我进化代理如记忆代理。", "conclusion": "EvoClinician能够有效应对多轮医疗诊断中的挑战，并提高了诊断过程中的临床收益和资源效率。"}}
{"id": "2601.22961", "pdf": "https://arxiv.org/pdf/2601.22961", "abs": "https://arxiv.org/abs/2601.22961", "authors": ["Dennis Sprute", "Hanna Senke", "Holger Flatt"], "title": "Improving Supervised Machine Learning Performance in Optical Quality Control via Generative AI for Dataset Expansion", "categories": ["cs.CV"], "comment": "Accepted at 19th CIRP Conference on Intelligent Computation in Manufacturing Engineering", "summary": "Supervised machine learning algorithms play a crucial role in optical quality control within industrial production. These approaches require representative datasets for effective model training. However, while non-defective components are frequent, defective parts are rare in production, resulting in highly imbalanced datasets that adversely impact model performance. Existing strategies to address this challenge, such as specialized loss functions or traditional data augmentation techniques, have limitations, including the need for careful hyperparameter tuning or the alteration of only simple image features. Therefore, this work explores the potential of generative artificial intelligence (GenAI) as an alternative method for expanding limited datasets and enhancing supervised machine learning performance. Specifically, we investigate Stable Diffusion and CycleGAN as image generation models, focusing on the segmentation of combine harvester components in thermal images for subsequent defect detection. Our results demonstrate that dataset expansion using Stable Diffusion yields the most significant improvement, enhancing segmentation performance by 4.6 %, resulting in a Mean Intersection over Union (Mean IoU) of 84.6 %.", "AI": {"tldr": "使用生成式人工智能扩充数据集以改善光学质量控制中的监督机器学习性能。", "motivation": "在工业生产中，由于非缺陷部件常见而缺陷部件稀少，导致的数据集不平衡问题影响了模型训练效果。现有方法如特殊损失函数和传统数据增强技术存在局限性。", "method": "采用Stable Diffusion和CycleGAN生成图像，以扩充用于缺陷检测的热像图部件分割任务中的有限数据集。", "result": "结果显示，使用Stable Diffusion扩展数据集效果最佳，提升了4.6%的分割性能，达到平均交并比（Mean IoU）为84.6％。", "conclusion": "生成式人工智能可以有效解决光学质量控制中由于数据不平衡导致的问题，显著提高监督机器学习模型的表现。"}}
{"id": "2601.22959", "pdf": "https://arxiv.org/pdf/2601.22959", "abs": "https://arxiv.org/abs/2601.22959", "authors": ["Anmin Wang", "Nan Zhang", "Wei Tao", "Xiaoyang Qu", "Guokuan Li", "Jiguang Wan", "Jianzong Wang"], "title": "Triage: Hierarchical Visual Budgeting for Efficient Video Reasoning in Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Vision-Language Models (VLMs) face significant computational challenges in video processing due to massive data redundancy, which creates prohibitively long token sequences. To address this, we introduce Triage, a training-free, plug-and-play framework that reframes video reasoning as a resource allocation problem via hierarchical visual budgeting. Its first stage, Frame-Level Budgeting, identifies keyframes by evaluating their visual dynamics and relevance, generating a strategic prior based on their importance scores. Guided by this prior, the second stage, Token-Level Budgeting, allocates tokens in two phases: it first secures high-relevance Core Tokens, followed by diverse Context Tokens selected with an efficient batched Maximal Marginal Relevance (MMR) algorithm. Extensive experiments demonstrate that Triage improves inference speed and reduces memory footprint, while maintaining or surpassing the performance of baselines and other methods on various video reasoning benchmarks.", "AI": {"tldr": "介绍了一种名为Triage的框架，用于改进视觉语言模型在视频处理中的效率。", "motivation": "由于大量数据冗余导致计算挑战，传统的视觉语言模型在处理视频时面临较长令牌序列的问题。因此，需要一种新的方法来优化资源分配，提高处理速度和减少内存使用。", "method": "Triage框架通过分层视觉预算将视频推理重新定义为一个资源分配问题，包括帧级预算和令牌级预算两个阶段：首先识别关键帧并基于重要性评分生成策略优先级；然后根据这个优先级来安排核心令牌和多样化的上下文令牌。", "result": "实验结果表明Triage能够提高推理速度、减少内存使用量，并且保持或超越了基准方法和其他技术在各种视频推理任务上的性能。", "conclusion": "通过将视觉语言模型中的视频处理转化为资源管理问题，Triage框架有效地提高了模型的效率和实用性。"}}
{"id": "2601.22954", "pdf": "https://arxiv.org/pdf/2601.22954", "abs": "https://arxiv.org/abs/2601.22954", "authors": ["Yuezhou Hu", "Harman Singh", "Monishwaran Maheswaran", "Haocheng Xi", "Coleman Hooper", "Jintao Zhang", "Aditya Tomar", "Michael W. Mahoney", "Sewon Min", "Mehrdad Farajtabar", "Kurt Keutzer", "Amir Gholami", "Chenfeng Xu"], "title": "Residual Context Diffusion Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to purely autoregressive language models because they can decode multiple tokens in parallel. However, state-of-the-art block-wise dLLMs rely on a \"remasking\" mechanism that decodes only the most confident tokens and discards the rest, effectively wasting computation. We demonstrate that recycling computation from the discarded tokens is beneficial, as these tokens retain contextual information useful for subsequent decoding iterations. In light of this, we propose Residual Context Diffusion (RCD), a module that converts these discarded token representations into contextual residuals and injects them back for the next denoising step. RCD uses a decoupled two-stage training pipeline to bypass the memory bottlenecks associated with backpropagation. We validate our method on both long CoT reasoning (SDAR) and short CoT instruction following (LLaDA) models. We demonstrate that a standard dLLM can be efficiently converted to the RCD paradigm with merely ~1 billion tokens. RCD consistently improves frontier dLLMs by 5-10 points in accuracy with minimal extra computation overhead across a wide range of benchmarks. Notably, on the most challenging AIME tasks, RCD nearly doubles baseline accuracy and attains up to 4-5x fewer denoising steps at equivalent accuracy levels.", "AI": {"tldr": "本文提出了一种残余上下文扩散语言模型（RCD），通过回收被废弃令牌的计算，提高了解码效率和准确性。", "motivation": "现有的块式dLLM依赖于“重新掩蔽”机制，该机制仅解码最自信的令牌，丢弃其余令牌。这些丢弃的令牌保留了上下文信息，可以用于后续解码迭代，因此回收这些令牌计算是有益的。", "method": "提出了一种模块化设计RCD，将废弃令牌转换为上下文残差，并将其注入到下一个去噪步骤中。使用一个解耦的两阶段训练管道来避免与反向传播相关的内存瓶颈。", "result": "在长CoT推理和短CoT指令遵循模型上验证了该方法的有效性。标准dLLM可以高效转换为RCD范式，仅需约10亿令牌，显著提高了前沿dLLMs的准确性，减少了额外计算开销，并且在AIME任务中几乎翻倍了基线准确率。", "conclusion": "通过回收废弃令牌的计算，RCD不仅提高了解码效率和精度，还减少了所需的去噪步骤，在各种基准测试中表现出色。"}}
{"id": "2601.22950", "pdf": "https://arxiv.org/pdf/2601.22950", "abs": "https://arxiv.org/abs/2601.22950", "authors": ["Petar Veličković", "Federico Barbero", "Christos Perivolaropoulos", "Simon Osindero", "Razvan Pascanu"], "title": "Perplexity Cannot Always Tell Right from Wrong", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "11 pages, 4 figures", "summary": "Perplexity -- a function measuring a model's overall level of \"surprise\" when encountering a particular output -- has gained significant traction in recent years, both as a loss function and as a simple-to-compute metric of model quality. Prior studies have pointed out several limitations of perplexity, often from an empirical manner. Here we leverage recent results on Transformer continuity to show in a rigorous manner how perplexity may be an unsuitable metric for model selection. Specifically, we prove that, if there is any sequence that a compact decoder-only Transformer model predicts accurately and confidently -- a necessary pre-requisite for strong generalisation -- it must imply existence of another sequence with very low perplexity, but not predicted correctly by that same model. Further, by analytically studying iso-perplexity plots, we find that perplexity will not always select for the more accurate model -- rather, any increase in model confidence must be accompanied by a commensurate rise in accuracy for the new model to be selected.", "AI": {"tldr": "本文探讨了困惑度作为模型选择指标的局限性，并通过数学证明展示了其在某些情况下的不适宜。", "motivation": "先前的研究已经指出困惑度作为模型质量评价标准存在一些限制，但这些讨论大多基于经验观察。作者旨在从理论上严格论证困惑度作为模型选择指标的不足之处。", "method": "利用Transformer连续性的最新成果，证明如果一个紧凑解码器独占式的Transformer模型能够准确且自信地预测任何序列，则必然存在另一个低困惑度但被该模型错误预测的序列；通过分析同困惑度图（iso-perplexity plots），揭示了当新模型信心增加时，其准确性必须相应提高才能被选中的规律。", "result": "研究表明，在某些情况下，困惑度可能无法正确选择更准确的模型。", "conclusion": "作者强调，尽管困惑度在评价模型质量方面具有一定的参考价值，但不应单纯依赖它作为唯一的评估标准；对于模型的选择和优化需要综合考量多种因素。"}}
{"id": "2601.22948", "pdf": "https://arxiv.org/pdf/2601.22948", "abs": "https://arxiv.org/abs/2601.22948", "authors": ["Nicola Milano", "Stefano Nolfi"], "title": "Alignment among Language, Vision and Action Representations", "categories": ["cs.AI"], "comment": null, "summary": "A fundamental question in cognitive science and AI concerns whether different learning modalities: language, vision, and action, give rise to distinct or shared internal representations. Traditional views assume that models trained on different data types develop specialized, non-transferable representations. However, recent evidence suggests unexpected convergence: models optimized for distinct tasks may develop similar representational geometries. We investigate whether this convergence extends to embodied action learning by training a transformer-based agent to execute goal-directed behaviors in response to natural language instructions. Using behavioral cloning on the BabyAI platform, we generated action-grounded language embeddings shaped exclusively by sensorimotor control requirements. We then compared these representations with those extracted from state-of-the-art large language models (LLaMA, Qwen, DeepSeek, BERT) and vision-language models (CLIP, BLIP). Despite substantial differences in training data, modality, and objectives, we observed robust cross-modal alignment. Action representations aligned strongly with decoder-only language models and BLIP (precision@15: 0.70-0.73), approaching the alignment observed among language models themselves. Alignment with CLIP and BERT was significantly weaker. These findings indicate that linguistic, visual, and action representations converge toward partially shared semantic structures, supporting modality-independent semantic organization and highlighting potential for cross-domain transfer in embodied AI systems.", "AI": {"tldr": "研究探索了语言、视觉和行为表征之间的对齐情况。", "motivation": "探讨不同学习模式（语言、视觉和行动）是否会产生独立或共享的内部表示。", "method": "使用基于变压器的代理在BabyAI平台进行行为克隆训练，生成由传感器运动控制需求塑造的语言嵌入，并与最先进的大型语言模型和视觉-语言模型进行比较。", "result": "发现即使是在不同训练数据、模态和目标下，仍然存在显著的跨模式对齐。行为表示与解码器语言模型及BLIP具有较强的对齐（精度@15:0.70-0.73），接近语言模型间的对齐程度。", "conclusion": "研究发现表明语义结构在不同模态间趋于部分共享，支持跨领域迁移的潜力。"}}
{"id": "2601.22946", "pdf": "https://arxiv.org/pdf/2601.22946", "abs": "https://arxiv.org/abs/2601.22946", "authors": ["Farnaz Soltaniani", "Mohammad Ghafari"], "title": "From Data Leak to Secret Misses: The Impact of Data Leakage on Secret Detection Models", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Machine learning models are increasingly used for software security tasks. These models are commonly trained and evaluated on large Internet-derived datasets, which often contain duplicated or highly similar samples. When such samples are split across training and test sets, data leakage may occur, allowing models to memorize patterns instead of learning to generalize. We investigate duplication in a widely used benchmark dataset of hard coded secrets and show how data leakage can substantially inflate the reported performance of AI-based secret detectors, resulting in a misleading picture of their real-world effectiveness.", "AI": {"tldr": "本文研究了数据泄露对密钥检测模型性能的影响。", "motivation": "大型互联网衍生的数据集中存在重复或高度相似的样本，导致训练和测试集之间的数据泄漏，影响机器学习模型的真实效果评估。", "method": "分析广泛使用的基准数据集中的硬编码秘密，展示数据泄漏如何夸大AI密钥检测器的表现。", "result": "发现数据泄漏使AI密钥检测器报告性能显著提高，但实际在现实世界中表现较差。", "conclusion": "强调了数据泄露对模型评估的重要性，并提出需要更好地处理和分割训练测试集以确保模型的泛化能力。"}}
{"id": "2601.22938", "pdf": "https://arxiv.org/pdf/2601.22938", "abs": "https://arxiv.org/abs/2601.22938", "authors": ["Huan Song", "Shuyu Tian", "Junyi Hao", "Cheng Yuan", "Zhenyu Jia", "Jiawei Shao", "Xuelong Li"], "title": "A Real-Time Privacy-Preserving Behavior Recognition System via Edge-Cloud Collaboration", "categories": ["cs.CR", "cs.AI", "eess.IV", "eess.SP"], "comment": null, "summary": "As intelligent sensing expands into high-privacy environments such as restrooms and changing rooms, the field faces a critical privacy-security paradox. Traditional RGB surveillance raises significant concerns regarding visual recording and storage, while existing privacy-preserving methods-ranging from physical desensitization to traditional cryptographic or obfuscation techniques-often compromise semantic understanding capabilities or fail to guarantee mathematical irreversibility against reconstruction attacks. To address these challenges, this study presents a novel privacy-preserving perception technology based on the AI Flow theoretical framework and an edge-cloud collaborative architecture. The proposed methodology integrates source desensitization with irreversible feature mapping. Leveraging Information Bottleneck theory, the edge device performs millisecond-level processing to transform raw imagery into abstract feature vectors via non-linear mapping and stochastic noise injection. This process constructs a unidirectional information flow that strips identity-sensitive attributes, rendering the reconstruction of original images impossible. Subsequently, the cloud platform utilizes multimodal family models to perform joint inference solely on these abstract vectors to detect abnormal behaviors. This approach fundamentally severs the path to privacy leakage at the architectural level, achieving a breakthrough from video surveillance to de-identified behavior perception and offering a robust solution for risk management in high-sensitivity public spaces.", "AI": {"tldr": "本文提出了一种基于AI流理论框架和边缘-云协作架构的实时隐私保护行为识别系统。", "motivation": "随着智能感应技术扩展到如卫生间和更衣室等高隐私环境，传统的RGB监控引发了关于视觉记录和存储的重大担忧。现有的隐私保护方法通常会牺牲语义理解能力或无法抵御重建攻击。因此本文旨在解决这些挑战。", "method": "该研究提出了一种基于AI流理论框架的边缘-云协作架构的隐私保护感知技术。边缘设备使用非线性映射和随机噪声注入，将原始图像转换为抽象特征向量，剥离身份敏感属性，构建单向信息流动以防止重建原图；云平台仅对这些抽象向量进行多模态联合推理来检测异常行为。", "result": "该系统能够在不泄露隐私的前提下实现行为识别，并提供一种在高敏感公共场所中管理风险的稳健解决方案。", "conclusion": "通过边缘-云协作架构，本文提出的方法从根本上切断了隐私泄漏路径，在视频监控向去身份化行为感知转变方面实现了突破。"}}
{"id": "2601.22935", "pdf": "https://arxiv.org/pdf/2601.22935", "abs": "https://arxiv.org/abs/2601.22935", "authors": ["Evgeny Grigorenko", "David Stanojević", "David Ilić", "Egor Bogomolov", "Kostadin Cvejoski"], "title": "Protecting Private Code in IDE Autocomplete using Differential Privacy", "categories": ["cs.CR", "cs.AI"], "comment": "6 pages", "summary": "Modern Integrated Development Environments (IDEs) increasingly leverage Large Language Models (LLMs) to provide advanced features like code autocomplete. While powerful, training these models on user-written code introduces significant privacy risks, making the models themselves a new type of data vulnerability. Malicious actors can exploit this by launching attacks to reconstruct sensitive training data or infer whether a specific code snippet was used for training. This paper investigates the use of Differential Privacy (DP) as a robust defense mechanism for training an LLM for Kotlin code completion. We fine-tune a \\texttt{Mellum} model using DP and conduct a comprehensive evaluation of its privacy and utility. Our results demonstrate that DP provides a strong defense against Membership Inference Attacks (MIAs), reducing the attack's success rate close to a random guess (AUC from 0.901 to 0.606). Furthermore, we show that this privacy guarantee comes at a minimal cost to model performance, with the DP-trained model achieving utility scores comparable to its non-private counterpart, even when trained on 100x less data. Our findings suggest that DP is a practical and effective solution for building private and trustworthy AI-powered IDE features.", "AI": {"tldr": "本文研究了使用差分隐私保护IDE代码补全模型中的用户私有代码，验证其在防御成员推理攻击方面的有效性及对模型性能的影响。", "motivation": "现代集成开发环境（IDE）依赖于大型语言模型提供代码补全等高级功能。然而，这些模型通过训练用户编写的代码进行学习，引入了隐私风险，成为新的数据漏洞。恶意行为者可能会利用这一点来重建敏感的训练数据或推断特定代码片段是否用于训练。", "method": "本文使用差分隐私技术对Mellum模型进行了微调，并对其隐私和实用性进行了全面评估。", "result": "实验结果表明，差分隐私显著降低了成员推理攻击的成功率（AUC从0.901降至0.606），同时保持了与非私有模型相当的性能，即使训练数据量减少了100倍。", "conclusion": "本文证明了使用差分隐私技术构建安全可靠的AI驱动IDE特性是可行且有效的。"}}
{"id": "2601.22930", "pdf": "https://arxiv.org/pdf/2601.22930", "abs": "https://arxiv.org/abs/2601.22930", "authors": ["Xidong Li", "Mingyu Guo", "Chenchao Xu", "Bailin Li", "Wenjing Zhu", "Yangang Zou", "Rui Chen", "Zehuan Wang"], "title": "MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": ":I.2.9; I.2.6", "summary": "Trajectory planning is a core task in autonomous driving, requiring the prediction of safe and comfortable paths across diverse scenarios. Integrating Multi-modal Large Language Models (MLLMs) with Reinforcement Learning (RL) has shown promise in addressing \"long-tail\" scenarios. However, existing methods are constrained to single-turn reasoning, limiting their ability to handle complex tasks requiring iterative refinement. To overcome this limitation, we present MTDrive, a multi-turn framework that enables MLLMs to iteratively refine trajectories based on environmental feedback. MTDrive introduces Multi-Turn Group Relative Policy Optimization (mtGRPO), which mitigates reward sparsity by computing relative advantages across turns. We further construct an interactive trajectory understanding dataset from closed-loop simulation to support multi-turn training. Experiments on the NAVSIM benchmark demonstrate superior performance compared to existing methods, validating the effectiveness of our multi-turn reasoning paradigm. Additionally, we implement system-level optimizations to reduce data transfer overhead caused by high-resolution images and multi-turn sequences, achieving 2.5x training throughput. Our data, models, and code will be made available soon.", "AI": {"tldr": "提出一种多轮交互式强化学习框架MTDrive，用于自动驾驶中的轨迹规划。", "motivation": "当前方法受限于单轮推理能力，难以处理需要迭代优化的复杂任务。为解决这一问题，引入了多轮交互式学习框架来提高对“长尾”场景的适应性。", "method": "提出Multi-Turn Group Relative Policy Optimization (mtGRPO)技术，并构建了一个互动轨迹理解数据集用于支持多轮训练。", "result": "在NAVSIM基准测试中，MTDrive展示了优于现有方法的性能表现。此外，实现了系统级优化以减少由高分辨率图像和多轮序列引起的数据传输开销，提高了2.5倍的训练吞吐量。", "conclusion": "实验表明，提出的多轮推理框架有效提升了自动驾驶轨迹规划的能力，并通过数据集、模型和代码开源支持进一步研究。"}}
{"id": "2601.22929", "pdf": "https://arxiv.org/pdf/2601.22929", "abs": "https://arxiv.org/abs/2601.22929", "authors": ["Yiyi Chen", "Qiongkai Xu", "Desmond Eliott", "Qiongxiu Li", "Johannes Bjerva"], "title": "Semantic Leakage from Image Embeddings", "categories": ["cs.CV", "cs.CL", "cs.CR"], "comment": "20 pages, 19 figures", "summary": "Image embeddings are generally assumed to pose limited privacy risk. We challenge this assumption by formalizing semantic leakage as the ability to recover semantic structures from compressed image embeddings. Surprisingly, we show that semantic leakage does not require exact reconstruction of the original image. Preserving local semantic neighborhoods under embedding alignment is sufficient to expose the intrinsic vulnerability of image embeddings. Crucially, this preserved neighborhood structure allows semantic information to propagate through a sequence of lossy mappings. Based on this conjecture, we propose Semantic Leakage from Image Embeddings (SLImE), a lightweight inference framework that reveals semantic information from standalone compressed image embeddings, incorporating a locally trained semantic retriever with off-the-shelf models, without training task-specific decoders. We thoroughly validate each step of the framework empirically, from aligned embeddings to retrieved tags, symbolic representations, and grammatical and coherent descriptions. We evaluate SLImE across a range of open and closed embedding models, including GEMINI, COHERE, NOMIC, and CLIP, and demonstrate consistent recovery of semantic information across diverse inference tasks. Our results reveal a fundamental vulnerability in image embeddings, whereby the preservation of semantic neighborhoods under alignment enables semantic leakage, highlighting challenges for privacy preservation.1", "AI": {"tldr": "本文提出了SLImE框架，从图像嵌入中提取语义信息。", "motivation": "质疑了图像嵌入对隐私风险较小的假设，提出通过保持局部语义邻域来揭示图像嵌入的安全漏洞。", "method": "基于语义泄露假设，设计了一个轻量级推理框架SLImE，该框架从独立压缩的图像嵌入中提取语义信息。", "result": "在各种开放和封闭式嵌入模型上验证了SLImE的一致性，并展示了其成功地恢复了语义信息。", "conclusion": "研究表明，保持局部语义邻域下的对齐能够使语义泄露发生，这为图像嵌入的安全性提出了挑战。"}}
{"id": "2601.22927", "pdf": "https://arxiv.org/pdf/2601.22927", "abs": "https://arxiv.org/abs/2601.22927", "authors": ["Lars Ullrich", "Michael Buchholz", "Klaus Dietmayer", "Knut Graichen"], "title": "Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs", "categories": ["cs.RO", "cs.ET"], "comment": "Published in IEEE Access, 29 January 2026", "summary": "Automated driving (AD) is promising, but the transition to fully autonomous driving is, among other things, subject to the real, ever-changing open world and the resulting challenges. However, research in the field of AD demonstrates the ability of artificial intelligence (AI) to outperform classical approaches, handle higher complexities, and reach a new level of autonomy. At the same time, the use of AI raises further questions of safety and transferability. To identify the challenges and opportunities arising from AI concerning autonomous driving functionalities, we have analyzed the current state of AD, outlined limitations, and identified foreseeable technological possibilities. Thereby, various further challenges are examined in the context of prospective developments. In this way, this article reconsiders fully autonomous driving with respect to advancements in the field of AI and carves out the respective needs and resulting research questions.", "AI": {"tldr": "分析自动驾驶中的AI挑战与机遇，确定未来需求", "motivation": "探讨人工智能在自动驾驶领域的进展及其面临的挑战和机会", "method": "综述现有自动驾驶技术的局限性，识别可能的技术进步，并提出相关的研究问题", "result": "指出利用AI实现完全自主驾驶的需求及存在的安全性和可转移性问题", "conclusion": "强调了通过AI推动自动驾驶发展的必要性和未来方向"}}
{"id": "2601.22925", "pdf": "https://arxiv.org/pdf/2601.22925", "abs": "https://arxiv.org/abs/2601.22925", "authors": ["Weiqin Yang", "Bohao Wang", "Zhenxiang Xu", "Jiawei Chen", "Shengjia Zhang", "Jingbang Chen", "Canghong Jin", "Can Wang"], "title": "BEAR: Towards Beam-Search-Aware Optimization for Recommendation with Large Language Models", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent years have witnessed a rapid surge in research leveraging Large Language Models (LLMs) for recommendation. These methods typically employ supervised fine-tuning (SFT) to adapt LLMs to recommendation scenarios, and utilize beam search during inference to efficiently retrieve $B$ top-ranked recommended items. However, we identify a critical training-inference inconsistency: while SFT optimizes the overall probability of positive items, it does not guarantee that such items will be retrieved by beam search even if they possess high overall probabilities. Due to the greedy pruning mechanism, beam search can prematurely discard a positive item once its prefix probability is insufficient. To address this inconsistency, we propose BEAR (Beam-SEarch-Aware Regularization), a novel fine-tuning objective that explicitly accounts for beam search behavior during training. Rather than directly simulating beam search for each instance during training, which is computationally prohibitive, BEAR enforces a relaxed necessary condition: each token in a positive item must rank within the top-$B$ candidate tokens at each decoding step. This objective effectively mitigates the risk of incorrect pruning while incurring negligible computational overhead compared to standard SFT. Extensive experiments across four real-world datasets demonstrate that BEAR significantly outperforms strong baselines. Code will be released upon acceptance.", "AI": {"tldr": "提出了一种用于推荐系统的新型微调目标BEAR，旨在解决大型语言模型在推荐场景中训练和推理之间的不一致性问题。", "motivation": "当前方法使用监督微调来适应大型语言模型，并利用束搜索进行高效检索。然而，这种方法可能导致高概率的正样本被束搜索过早地丢弃，从而产生错误的推荐结果。为了解决这一问题，提出了一种新的目标BEAR。", "method": "BEAR通过在训练过程中强制执行一个松弛条件来解决不一致性：每个令牌必须在其解码步骤中位于前$B$个候选令牌之内。这有效地减少了错误剪枝的风险，并且相比标准的监督微调，仅产生很小的计算开销。", "result": "实验结果表明，在四个真实世界数据集上，BEAR显著优于强大的基线方法。", "conclusion": "通过提出BEAR这一新的目标来解决训练和推理之间的不一致性问题，从而提高推荐系统的性能。"}}
{"id": "2601.22921", "pdf": "https://arxiv.org/pdf/2601.22921", "abs": "https://arxiv.org/abs/2601.22921", "authors": ["Farnaz Soltaniani", "Shoaib Razzaq", "Mohammad Ghafari"], "title": "Evaluating Large Language Models for Security Bug Report Prediction", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Early detection of security bug reports (SBRs) is critical for timely vulnerability mitigation. We present an evaluation of prompt-based engineering and fine-tuning approaches for predicting SBRs using Large Language Models (LLMs). Our findings reveal a distinct trade-off between the two approaches. Prompted proprietary models demonstrate the highest sensitivity to SBRs, achieving a G-measure of 77% and a recall of 74% on average across all the datasets, albeit at the cost of a higher false-positive rate, resulting in an average precision of only 22%. Fine-tuned models, by contrast, exhibit the opposite behavior, attaining a lower overall G-measure of 51% but substantially higher precision of 75% at the cost of reduced recall of 36%. Though a one-time investment in building fine-tuned models is necessary, the inference on the largest dataset is up to 50 times faster than that of proprietary models. These findings suggest that further investigations to harness the power of LLMs for SBR prediction are necessary.", "AI": {"tldr": "评估大型语言模型在安全缺陷报告预测中的表现，对比提示工程和微调方法的效果。", "motivation": "早期检测安全缺陷报告对于及时缓解漏洞至关重要。研究旨在通过大型语言模型进行安全缺陷报告的预测，并分析两种不同策略的优势与劣势。", "method": "比较基于提示的方法和微调方法在预测安全缺陷报告上的效果，使用大型语言模型进行实验并评估结果。", "result": "提示工程方法显示出最高的灵敏度（74%召回率），但精度较低（22%）。相比之下，微调方法的G测度为51%，但具有更高的精度（75%）和更快的速度（最多快50倍）。", "conclusion": "研究表明进一步研究以充分利用大型语言模型在安全缺陷报告预测中的潜力是必要的。"}}
{"id": "2601.22920", "pdf": "https://arxiv.org/pdf/2601.22920", "abs": "https://arxiv.org/abs/2601.22920", "authors": ["Wulin Xie", "Rui Dai", "Ruidong Ding", "Kaikui Liu", "Xiangxiang Chu", "Xinwen Hou", "Jie Wen"], "title": "Q-Hawkeye: Reliable Visual Policy Optimization for Image Quality Assessment", "categories": ["cs.CV"], "comment": null, "summary": "Image Quality Assessment (IQA) predicts perceptual quality scores consistent with human judgments. Recent RL-based IQA methods built on MLLMs focus on generating visual quality descriptions and scores, ignoring two key reliability limitations: (i) although the model's prediction stability varies significantly across training samples, existing GRPO-based methods apply uniform advantage weighting, thereby amplifying noisy signals from unstable samples in gradient updates; (ii) most works emphasize text-grounded reasoning over images while overlooking the model's visual perception ability of image content. In this paper, we propose Q-Hawkeye, an RL-based reliable visual policy optimization framework that redesigns the learning signal through unified Uncertainty-Aware Dynamic Optimization and Perception-Aware Optimization. Q-Hawkeye estimates predictive uncertainty using the variance of predicted scores across multiple rollouts and leverages this uncertainty to reweight each sample's update strength, stabilizing policy optimization. To strengthen perceptual reliability, we construct paired inputs of degraded images and their original images and introduce an Implicit Perception Loss that constrains the model to ground its quality judgments in genuine visual evidence. Extensive experiments demonstrate that Q-Hawkeye outperforms state-of-the-art methods and generalizes better across multiple datasets. The code and models will be made available.", "AI": {"tldr": "提出了一种基于强化学习的可靠视觉策略优化框架Q-Hawkeye，用于图像质量评估。", "motivation": "现有基于GRPO的方法在预测稳定性方面存在缺陷，并且大多数方法忽视了模型对图像内容的理解能力。", "method": "通过统一不确定性感知动态优化和感知感知优化来重新设计学习信号。使用预测分数的方差估计预测不确定性，以此来调整每个样本更新的强度；构建降质图片与其原始版本的配对输入并引入隐式感知损失以增强模型基于真实视觉证据做出质量判断的能力。", "result": "实验表明Q-Hawkeye优于现有最先进技术，并且在多个数据集上具有更好的泛化性能。", "conclusion": "提出的方法能够提高图像质量评估的可靠性，通过解决预测稳定性和视觉感知能力的问题来改进现有的基于RL的方法。"}}
{"id": "2601.22917", "pdf": "https://arxiv.org/pdf/2601.22917", "abs": "https://arxiv.org/abs/2601.22917", "authors": ["Tom Raynes", "Otto Brookes", "Timm Haucke", "Lukas Bösch", "Anne-Sophie Crunchant", "Hjalmar Kühl", "Sara Beery", "Majid Mirmehdi", "Tilo Burghardt"], "title": "Deep in the Jungle: Towards Automating Chimpanzee Population Estimation", "categories": ["cs.CV"], "comment": null, "summary": "The estimation of abundance and density in unmarked populations of great apes relies on statistical frameworks that require animal-to-camera distance measurements. In practice, acquiring these distances depends on labour-intensive manual interpretation of animal observations across large camera trap video corpora. This study introduces and evaluates an only sparsely explored alternative: the integration of computer vision-based monocular depth estimation (MDE) pipelines directly into ecological camera trap workflows for great ape conservation. Using a real-world dataset of 220 camera trap videos documenting a wild chimpanzee population, we combine two MDE models, Dense Prediction Transformers and Depth Anything, with multiple distance sampling strategies. These components are used to generate detection distance estimates, from which population density and abundance are inferred. Comparative analysis against manually derived ground-truth distances shows that calibrated DPT consistently outperforms Depth Anything. This advantage is observed in both distance estimation accuracy and downstream density and abundance inference. Nevertheless, both models exhibit systematic biases. We show that, given complex forest environments, they tend to overestimate detection distances and consequently underestimate density and abundance relative to conventional manual approaches. We further find that failures in animal detection across distance ranges are a primary factor limiting estimation accuracy. Overall, this work provides a case study that shows MDE-driven camera trap distance sampling is a viable and practical alternative to manual distance estimation. The proposed approach yields population estimates within 22% of those obtained using traditional methods.", "AI": {"tldr": "论文提出并评估了一种基于计算机视觉的单目深度估计技术，用于改善大猿数量估算的方法。", "motivation": "当前的大猿数量和密度估测依赖于复杂的统计模型，并需要手动从大量相机陷阱视频中获取动物到相机的距离。这种方法耗时且费力。", "method": "利用220个相机陷阱视频数据集，结合Dense Prediction Transformers和Depth Anything两种单目深度估计模型与多种距离采样策略，生成检测距离估算，从而推断出种群密度和数量。", "result": "经过比较分析发现，校准后的DPT在距离估测准确性及后续的密度和数量推断上表现优于Depth Anything。尽管存在系统性偏差，但该方法仍能提供与传统手动方法相近的结果。", "conclusion": "研究表明，基于单目深度估计技术的相机陷阱距离采样是一种可行且实用的方法，用于替代传统的手动距离估测方法。"}}
{"id": "2601.22913", "pdf": "https://arxiv.org/pdf/2601.22913", "abs": "https://arxiv.org/abs/2601.22913", "authors": ["Anindya Sundar Das", "Monowar Bhuyan"], "title": "Multi-Cue Anomaly Detection and Localization under Data Contamination", "categories": ["cs.CV"], "comment": "12 pages total (10 pages main text + references), 6 figures. Preprint version; the final camera-ready version may differ", "summary": "Visual anomaly detection in real-world industrial settings faces two major limitations. First, most existing methods are trained on purely normal data or on unlabeled datasets assumed to be predominantly normal, presuming the absence of contamination, an assumption that is rarely satisfied in practice. Second, they assume no access to labeled anomaly samples, limiting the model from learning discriminative characteristics of true anomalies. Therefore, these approaches often struggle to distinguish anomalies from normal instances, resulting in reduced detection and weak localization performance. In real-world applications, where training data are frequently contaminated with anomalies, such methods fail to deliver reliable performance. In this work, we propose a robust anomaly detection framework that integrates limited anomaly supervision into the adaptive deviation learning paradigm. We introduce a composite anomaly score that combines three complementary components: a deviation score capturing statistical irregularity, an entropy-based uncertainty score reflecting predictive inconsistency, and a segmentation-based score highlighting spatial abnormality. This unified scoring mechanism enables accurate detection and supports gradient-based localization, providing intuitive and explainable visual evidence of anomalous regions. Following the few-anomaly paradigm, we incorporate a small set of labeled anomalies during training while simultaneously mitigating the influence of contaminated samples through adaptive instance weighting. Extensive experiments on the MVTec and VisA benchmarks demonstrate that our framework outperforms state-of-the-art baselines and achieves strong detection and localization performance, interpretability, and robustness under various levels of data contamination.", "AI": {"tldr": "提出了一种鲁棒的异常检测框架，结合有限的异常监督和自适应偏差学习范式，以提高在受污染数据下的性能。", "motivation": "现有方法通常假设训练数据没有受到异常样本的影响，并且缺乏对异常样本的标记信息，这导致了在实际应用中的表现不佳。", "method": "通过引入一个复合异常评分机制，结合统计不规则性、预测不确定性以及空间异常性三个互补组件，该框架支持准确检测和基于梯度定位。同时，在训练期间利用有限数量的标记异常样本来减少污染样本的影响。", "result": "实验表明，所提框架在MVTec和VisA数据集上优于现有基线模型，并且具备强健的检测、定位性能以及对各种程度的数据污染的强大鲁棒性。", "conclusion": "通过提出一个结合了有限监督信息与自适应偏差学习的方法，该研究为解决实际场景中的异常检测问题提供了一种有效手段。"}}
{"id": "2601.22904", "pdf": "https://arxiv.org/pdf/2601.22904", "abs": "https://arxiv.org/abs/2601.22904", "authors": ["Hun Chang", "Byunghee Cha", "Jong Chul Ye"], "title": "DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "17 pages, and 11 figures", "summary": "Recent studies have explored using pretrained Vision Foundation Models (VFMs) such as DINO for generative autoencoders, showing strong generative performance. Unfortunately, existing approaches often suffer from limited reconstruction fidelity due to the loss of high-frequency details. In this work, we present the DINO Spherical Autoencoder (DINO-SAE), a framework that bridges semantic representation and pixel-level reconstruction. Our key insight is that semantic information in contrastive representations is primarily encoded in the direction of feature vectors, while forcing strict magnitude matching can hinder the encoder from preserving fine-grained details. To address this, we introduce Hierarchical Convolutional Patch Embedding module that enhances local structure and texture preservation, and Cosine Similarity Alignment objective that enforces semantic consistency while allowing flexible feature magnitudes for detail retention. Furthermore, leveraging the observation that SSL-based foundation model representations intrinsically lie on a hypersphere, we employ Riemannian Flow Matching to train a Diffusion Transformer (DiT) directly on this spherical latent manifold. Experiments on ImageNet-1K demonstrate that our approach achieves state-of-the-art reconstruction quality, reaching 0.37 rFID and 26.2 dB PSNR, while maintaining strong semantic alignment to the pretrained VFM. Notably, our Riemannian Flow Matching-based DiT exhibits efficient convergence, achieving a gFID of 3.47 at 80 epochs.", "AI": {"tldr": "本文提出了一种新的框架DINO-SAE，用于图像的高保真重建和生成。", "motivation": "现有的预训练视觉基础模型（VFMs）如DINO在作为生成自动编码器时表现出色，但通常受限于有限的重建保真度，因为它们丢失了高频细节。本文旨在提高这种限制。", "method": "通过引入层次卷积补丁嵌入模块来增强局部结构和纹理保留，并使用余弦相似性对齐目标以强制语义一致性同时允许灵活特征幅度以保持细粒度细节。此外，利用SSL基础模型表示本质上位于超球面上的观察结果，采用黎曼流匹配训练扩散变压器（DiT），直接在该球面潜在流形上进行训练。", "result": "实验表明，本文的方法在ImageNet-1K数据集上达到了最先进的重建质量，rFID为0.37和PSNR为26.2dB，并且保持了与预训练VFM的强烈语义一致性。黎曼流匹配的DiT表现出高效的收敛性，在80个epoch时达到gFID 3.47。", "conclusion": "本文提出的DINO-SAE框架在图像重建和生成中展示了出色的性能，解决了现有的VFMs受限于有限重构保真度的问题，并保持了预训练VFM的语义一致性。"}}
{"id": "2601.22900", "pdf": "https://arxiv.org/pdf/2601.22900", "abs": "https://arxiv.org/abs/2601.22900", "authors": ["Xuancheng Li", "Haitao Li", "Yujia Zhou", "YiqunLiu", "Qingyao Ai"], "title": "MulFeRL: Enhancing Reinforcement Learning with Verbal Feedback in a Multi-turn Loop", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is widely used to improve reasoning in multiple domains, yet outcome-only scalar rewards are often sparse and uninformative, especially on failed samples, where they merely indicate failure and provide no insight into why the reasoning fails. In this paper, we investigate how to leverage richer verbal feedback to guide RLVR training on failed samples, and how to convert such feedback into a trainable learning signal. Specifically, we propose a multi-turn feedback-guided reinforcement learning framework. It builds on three mechanisms: (1) dynamic multi-turn regeneration guided by feedback, triggered only on failed samples, (2) two complementary learning signals for within-turn and cross-turn optimization, and (3) structured feedback injection into the model's reasoning process. Trained on sampled OpenR1-Math, the approach outperforms supervised fine-tuning and RLVR baselines in-domain and generalizes well out-of-domain.", "AI": {"tldr": "本文提出了一种利用多轮反馈来增强强化学习的方法，以改善失败样本中的推理过程。", "motivation": "当前的强化学习方法依赖于稀疏且不详尽的结果奖励，无法为失败样例提供详细的指导信息。作者希望通过引入更丰富的语言反馈来解决这一问题，并将其转化为可训练的学习信号。", "method": "提出了一种基于多轮反馈引导的强化学习框架，包括三个机制：动态多轮再生（仅在样本失败时触发）、两个互补的学习信号用于内部和跨回合优化、以及结构化反馈注入到模型推理过程中。", "result": "实验结果显示，在OpenR1-Math数据集上训练后，所提出的方法不仅超过了监督微调和基于强化学习的基准方法，并且还具有良好的泛化能力。", "conclusion": "通过利用语言反馈来指导失败样本的学习过程，可以有效提升模型在特定领域内的性能及跨领域的泛化能力。"}}
{"id": "2601.22896", "pdf": "https://arxiv.org/pdf/2601.22896", "abs": "https://arxiv.org/abs/2601.22896", "authors": ["Xinyi Ke", "Kai Li", "Junliang Xing", "Yifan Zhang", "Jian Cheng"], "title": "Game-Theoretic Co-Evolution for LLM-Based Heuristic Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have enabled rapid progress in automatic heuristic discovery (AHD), yet most existing methods are predominantly limited by static evaluation against fixed instance distributions, leading to potential overfitting and poor generalization under distributional shifts. We propose Algorithm Space Response Oracles (ASRO), a game-theoretic framework that reframes heuristic discovery as a program level co-evolution between solver and instance generator. ASRO models their interaction as a two-player zero-sum game, maintains growing strategy pools on both sides, and iteratively expands them via LLM-based best-response oracles against mixed opponent meta-strategies, thereby replacing static evaluation with an adaptive, self-generated curriculum. Across multiple combinatorial optimization domains, ASRO consistently outperforms static-training AHD baselines built on the same program search mechanisms, achieving substantially improved generalization and robustness on diverse and out-of-distribution instances.", "AI": {"tldr": "本文提出了一种基于博弈论的框架ASRO，通过动态演化方法来改进启发式搜索算法。", "motivation": "现有的自动启发式发现（AHD）方法大多受限于静态评估机制，这会导致模型过拟合和泛化能力差的问题。为此，作者提出了一个新的框架来解决这个问题。", "method": "ASRO是一种将求解器和实例生成器的互动视为一种两个玩家零和博弈的游戏理论框架。它维持了双方不断扩大的策略池，并通过基于LLM的最佳响应或acles迭代地扩展它们。", "result": "在多个组合优化领域中，ASRO显著优于使用相同程序搜索机制构建的静态训练AHD基线模型，在多样性和出界实例上的泛化和鲁棒性得到了实质性的提升。", "conclusion": "通过引入动态演化的方法，可以有效提高启发式发现算法的学习效果和应用范围。"}}
{"id": "2601.22889", "pdf": "https://arxiv.org/pdf/2601.22889", "abs": "https://arxiv.org/abs/2601.22889", "authors": ["Yuxuan Lou", "Ziming Wu", "Yaochen Wang", "Yong Liu", "Yingxuan Ren", "Fuming Lai", "Shaobing Lian", "Jie Tang", "Yang You"], "title": "DiffuSpeech: Silent Thought, Spoken Answer via Unified Speech-Text Diffusion", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD"], "comment": null, "summary": "Current speech language models generate responses directly without explicit reasoning, leading to errors that cannot be corrected once audio is produced. We introduce \\textbf{``Silent Thought, Spoken Answer''} -- a paradigm where speech LLMs generate internal text reasoning alongside spoken responses, with thinking traces informing speech quality. To realize this, we present \\method{}, the first diffusion-based speech-text language model supporting both understanding and generation, unifying discrete text and tokenized speech under a single masked diffusion framework. Unlike autoregressive approaches, \\method{} jointly generates reasoning traces and speech tokens through iterative denoising, with modality-specific masking schedules. We also construct \\dataset{}, the first speech QA dataset with paired text reasoning traces, containing 26K samples totaling 319 hours. Experiments show \\method{} achieves state-of-the-art speech-to-speech QA accuracy, outperforming the best baseline by up to 9 points, while attaining the best TTS quality among generative models (6.2\\% WER) and preserving language understanding (66.2\\% MMLU). Ablations confirm that both the diffusion architecture and thinking traces contribute to these gains.", "AI": {"tldr": "提出了DiffuSpeech，一种联合生成文本推理和语音的扩散模型，以实现“无声思考，有声回答”的新范式。", "motivation": "当前的语言模型在直接生成语音时缺乏纠正错误的能力。引入了‘无声思考，有声回答’的新范式来提高语音质量，并通过构造配对的文本推理轨迹数据集增强模型理解能力。", "method": "DiffuSpeech是首个基于扩散框架的联合处理文本和语音语言模型，使用迭代去噪方法在单一掩码扩散架构中生成推理痕迹和语音令牌。", "result": "实验结果表明，DiffuSpeech在语音问答准确度上达到最新水平，超越最佳基准高达9个百分点，并且在合成语音质量方面表现优越（6.2％WER），同时保持良好的语言理解能力（MMLU得分66.2%）。", "conclusion": "通过引入‘无声思考，有声回答’的新范式和DiffuSpeech模型，显著提升了语音生成的质量与准确性。"}}
{"id": "2601.22888", "pdf": "https://arxiv.org/pdf/2601.22888", "abs": "https://arxiv.org/abs/2601.22888", "authors": ["Jio Oh", "Paul Vicinanza", "Thomas Butler", "Steven Euijong Whang", "Dezhi Hong", "Amani Namboori"], "title": "Should LLMs, $\\textit{like}$, Generate How Users Talk? Building Dialect-Accurate Dialog[ue]s Beyond the American Default with MDial", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "More than 80% of the 1.6 billion English speakers do not use Standard American English (SAE) and experience higher failure rates and stereotyped responses when interacting with LLMs as a result. Yet multi-dialectal performance remains underexplored. We introduce $\\textbf{MDial}$, the first large-scale framework for generating multi-dialectal conversational data encompassing the three pillars of written dialect -- lexical (vocabulary), orthographic (spelling), and morphosyntactic (grammar) features -- for nine English dialects. Partnering with native linguists, we design an annotated and scalable rule-based LLM transformation to ensure precision. Our approach challenges the assumption that models should mirror users' morphosyntactic features, showing that up to 90% of the grammatical features of a dialect should not be reproduced by models. Independent evaluations confirm data quality, with annotators preferring MDial outputs over prior methods in 98% of pairwise comparisons for dialect naturalness. Using this pipeline, we construct the dialect-parallel $\\textbf{MDialBench}$mark with 50k+ dialogs, resulting in 97k+ QA pairs, and evaluate 17 LLMs on dialect identification and response generation tasks. Even frontier models achieve under 70% accuracy, fail to reach 50% for Canadian English, and systematically misclassify non-SAE dialects as American or British. As dialect identification underpins natural language understanding, these errors risk cascading failures into downstream tasks.", "AI": {"tldr": "构建了一个大规模多方言对话生成框架MDial，旨在解决LLM在处理非标准美国英语时的问题。", "motivation": "超过80%的英文使用者使用非美式英语，并且他们与LLM交互失败率高，遭遇刻板印象回应。现有研究对多方言性能探索不足。", "method": "MDial框架通过词库、拼写和语法特征生成九种英语口音对话数据，采用基于规则的方法确保准确性，并构建了包含50k+对话的MDialBench。", "result": "独立评估显示，98%的对比测试中用户更偏好MDial输出。17个LLM在方言识别任务上的准确率不足70%，对加拿大英语辨识率低于50%，且常将非标准美国口音误判为美式或英式。", "conclusion": "该研究挑战了模型应该模仿用户的语法特征这一假设，指出部分语言变异不应被复制。结果显示现有LLM在多方言处理上存在显著缺陷，需进一步提升自然语言理解能力。"}}
{"id": "2601.22887", "pdf": "https://arxiv.org/pdf/2601.22887", "abs": "https://arxiv.org/abs/2601.22887", "authors": ["Yangyan Li"], "title": "MoVE: Mixture of Value Embeddings -- A New Axis for Scaling Parametric Memory in Autoregressive Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Autoregressive sequence modeling stands as the cornerstone of modern Generative AI, powering results across diverse modalities ranging from text generation to image generation. However, a fundamental limitation of this paradigm is the rigid structural coupling of model capacity to computational cost: expanding a model's parametric memory -- its repository of factual knowledge or visual patterns -- traditionally requires deepening or widening the network, which incurs a proportional rise in active FLOPs. In this work, we introduce $\\textbf{MoVE (Mixture of Value Embeddings)}$, a mechanism that breaks this coupling and establishes a new axis for scaling capacity. MoVE decouples memory from compute by introducing a global bank of learnable value embeddings shared across all attention layers. For every step in the sequence, the model employs a differentiable soft gating mechanism to dynamically mix retrieved concepts from this bank into the standard value projection. This architecture allows parametric memory to be scaled independently of network depth by simply increasing the number of embedding slots. We validate MoVE through strictly controlled experiments on two representative applications of autoregressive modeling: Text Generation and Image Generation. In both domains, MoVE yields consistent performance improvements over standard and layer-wise memory baselines, enabling the construction of \"memory-dense\" models that achieve lower perplexity and higher fidelity than their dense counterparts at comparable compute budgets.", "AI": {"tldr": "提出了一种新的机制MoVE，用于在自回归模型中独立扩展参数记忆而不增加计算成本。", "motivation": "解决传统自回归模型中容量和计算成本之间固有的耦合问题。随着模型容量的增加，计算成本也成比例上升。", "method": "通过引入一个全局可学习的价值嵌入库，并使用软门机制动态混合这些嵌入来扩展参数记忆，从而在不增加网络深度的情况下实现独立扩展。", "result": "在文本生成和图像生成上的严格控制实验中，MoVE显示了相对于标准模型和逐层内存基线的性能改善。它构建了“内存密集型”模型，在计算预算相当的情况下实现了更低的困惑度和更高的保真度。", "conclusion": "通过引入新的架构轴心，即参数记忆可以独立于网络深度扩展，解决了自回归建模中的一个基本限制问题，这为生成AI领域带来了新的可能性。"}}
{"id": "2601.22880", "pdf": "https://arxiv.org/pdf/2601.22880", "abs": "https://arxiv.org/abs/2601.22880", "authors": ["Tanay Raghunandan Srinivasa", "Vivek Deulkar", "Aviruch Bhatia", "Vishal Garg"], "title": "Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems", "categories": ["eess.SY", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "We study the joint operation and sizing of cooling infrastructure for commercial HVAC systems using reinforcement learning, with the objective of minimizing life-cycle cost over a 30-year horizon. The cooling system consists of a fixed-capacity electric chiller and a thermal energy storage (TES) unit, jointly operated to meet stochastic hourly cooling demands under time-varying electricity prices. The life-cycle cost accounts for both capital expenditure and discounted operating cost, including electricity consumption and maintenance. A key challenge arises from the strong asymmetry in capital costs: increasing chiller capacity by one unit is far more expensive than an equivalent increase in TES capacity. As a result, identifying the right combination of chiller and TES sizes, while ensuring zero loss-of-cooling-load under optimal operation, is a non-trivial co-design problem. To address this, we formulate the chiller operation problem for a fixed infrastructure configuration as a finite-horizon Markov Decision Process (MDP), in which the control action is the chiller part-load ratio (PLR). The MDP is solved using a Deep Q Network (DQN) with a constrained action space. The learned DQN RL policy minimizes electricity cost over historical traces of cooling demand and electricity prices. For each candidate chiller-TES sizing configuration, the trained policy is evaluated. We then restrict attention to configurations that fully satisfy the cooling demand and perform a life-cycle cost minimization over this feasible set to identify the cost-optimal infrastructure design. Using this approach, we determine the optimal chiller and thermal energy storage capacities to be 700 and 1500, respectively.", "AI": {"tldr": "研究基于强化学习的冷却设备和热能储存联合设计与运营，以最小化商用 HVAC 系统的生命周期成本。", "motivation": "通过优化冷却系统的容量配置和操作策略，在满足随机小时冷却需求的同时降低长期运行成本，解决固定容量电动冷水机组与可变电力价格下的经济性挑战。", "method": "将制冷机的操作问题建模为有限时间马尔科夫决策过程（MDP），并使用有约束动作空间的深度 Q 网络 (DQN) 强化学习算法求解该 MDP，从而得出最优操作策略。在满足冷却需求的前提下对不同容量配置进行评估，并通过生命周期成本最小化确定最佳基础设施设计。", "result": "确定了最优冷水机组和热能存储容量分别为700和1500。", "conclusion": "利用强化学习方法优化了HVAC系统的冷却设备与热能储存联合设计，实现了在满足需求的同时显著降低生命周期成本的目标。"}}
{"id": "2601.22878", "pdf": "https://arxiv.org/pdf/2601.22878", "abs": "https://arxiv.org/abs/2601.22878", "authors": ["Rajini Makam", "Sharanya Patil", "Dhatri Shankari T M", "Suresh Sundaram", "Narasimhan Sundararajan"], "title": "Development of Domain-Invariant Visual Enhancement and Restoration (DIVER) Approach for Underwater Images", "categories": ["eess.IV", "cs.CV"], "comment": "Submitted to IEEE Journal of Oceanic Engineering", "summary": "Underwater images suffer severe degradation due to wavelength-dependent attenuation, scattering, and illumination non-uniformity that vary across water types and depths. We propose an unsupervised Domain-Invariant Visual Enhancement and Restoration (DIVER) framework that integrates empirical correction with physics-guided modeling for robust underwater image enhancement. DIVER first applies either IlluminateNet for adaptive luminance enhancement or a Spectral Equalization Filter for spectral normalization. An Adaptive Optical Correction Module then refines hue and contrast using channel-adaptive filtering, while Hydro-OpticNet employs physics-constrained learning to compensate for backscatter and wavelength-dependent attenuation. The parameters of IlluminateNet and Hydro-OpticNet are optimized via unsupervised learning using a composite loss function. DIVER is evaluated on eight diverse datasets covering shallow, deep, and highly turbid environments, including both naturally low-light and artificially illuminated scenes, using reference and non-reference metrics. While state-of-the-art methods such as WaterNet, UDNet, and Phaseformer perform reasonably in shallow water, their performance degrades in deep, unevenly illuminated, or artificially lit conditions. In contrast, DIVER consistently achieves best or near-best performance across all datasets, demonstrating strong domain-invariant capability. DIVER yields at least a 9% improvement over SOTA methods in UCIQE. On the low-light SeaThru dataset, where color-palette references enable direct evaluation of color restoration, DIVER achieves at least a 4.9% reduction in GPMAE compared to existing methods. Beyond visual quality, DIVER also improves robotic perception by enhancing ORB-based keypoint repeatability and matching performance, confirming its robustness across diverse underwater environments.", "AI": {"tldr": "本文提出了一种无监督的域不变视觉增强和恢复（DIVER）框架，用于改善水下图像的质量。", "motivation": "由于波长依赖性衰减、散射以及光照不均匀的问题，导致水下图像严重退化。现有方法在浅水中表现较好，但在深水、非均匀照明或人工照明条件下性能下降。因此，开发一种能够适应各种复杂水下环境的增强框架具有重要意义。", "method": "DIVER结合了经验校正和物理引导建模，首先使用IlluminateNet进行自适应亮度增强或光谱均衡滤波器进行光谱归一化。然后通过自适应光学校正模块对色调和对比度进行细化，并利用Hydro-OpticNet进行散射补偿和波长依赖性衰减的校正。参数优化采用无监督学习并通过复合损失函数实现。", "result": "DIVER在八个不同数据集上进行了评估，涵盖了浅水、深水以及高浑浊环境，包括自然低光和人工照明场景。与现有的WaterNet, UDNet 和Phaseformer等方法相比，在UCIQE指标上至少提高了9%的性能。特别是在SeaThru低光照数据集中，DIVER比现有方法在GPMAE度量上减少了4.9％。", "conclusion": "通过无监督学习和物理约束，所提出的DIVER框架能够有效改善水下图像的质量，并且具有跨域不变性能力，在各种复杂条件下均表现出色。"}}
{"id": "2601.22873", "pdf": "https://arxiv.org/pdf/2601.22873", "abs": "https://arxiv.org/abs/2601.22873", "authors": ["Li Zhou", "Hao Jiang", "Junjie Li", "Tianrui Wang", "Haizhou Li"], "title": "EmoShift: Lightweight Activation Steering for Enhanced Emotion-Aware Speech Synthesis", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "comment": "Activation Steering; Emotion-Aware TTS; Speech Synthesis; Accepted by ICASSP 2026", "summary": "Achieving precise and controllable emotional expression is crucial for producing natural and context-appropriate speech in text-to-speech (TTS) synthesis. However, many emotion-aware TTS systems, including large language model (LLM)-based designs, rely on scaling fixed emotion embeddings or external guidance, limiting their ability to model emotion-specific latent characteristics. To address this gap, we present EmoShift, a lightweight activation-steering framework incorporating a EmoSteer layer, which learns a steering vector for each target emotion in the output embedding space to capture its latent offset and maintain stable, appropriate expression across utterances and categories. With only 10M trainable parameters,less than 1/30 of full fine-tuning, EmoShift outperforms zero-shot and fully fine-tuned baselines in objective and subjective evaluations, enhancing emotional expressiveness while preserving naturalness and speaker similarity. Further analysis confirms the proposed EmoSteer layer's effectiveness and reveals its potential for controllable emotional intensity in speech synthesis.", "AI": {"tldr": "本文提出了EmoShift，一种轻量级的情感导向框架，用于增强情感感知的语音合成。", "motivation": "许多情感感知TTS系统依赖于固定的情绪嵌入或外部指导，这限制了它们捕捉特定情绪潜在特征的能力。为了弥补这一不足，提出了EmoShift框架以更精确地控制和表达情感。", "method": "EmoShift通过引入EmoSteer层来学习每个目标情感在输出嵌入空间中的导向向量，该层能够捕获情绪的潜在偏移并保持稳定、适当的情绪表达。整个模型仅包含约10M个可训练参数。", "result": "实验结果表明，在客观和主观评价中，EmoShift优于零样本基线和全微调基线，提高了情感表达性同时保留了自然度和说话人一致性。", "conclusion": "通过分析证明了提出的EmoSteer层的有效性，并揭示了其在语音合成中控制情绪强度的潜力。"}}
{"id": "2601.22871", "pdf": "https://arxiv.org/pdf/2601.22871", "abs": "https://arxiv.org/abs/2601.22871", "authors": ["Alexander Loth", "Martin Kappes", "Marc-Oliver Pahl"], "title": "Eroding the Truth-Default: A Causal Analysis of Human Susceptibility to Foundation Model Hallucinations and Disinformation in the Wild", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "comment": "Accepted at ACM TheWebConf '26 Companion", "summary": "As foundation models (FMs) approach human-level fluency, distinguishing synthetic from organic content has become a key challenge for Trustworthy Web Intelligence. This paper presents JudgeGPT and RogueGPT, a dual-axis framework that decouples \"authenticity\" from \"attribution\" to investigate the mechanisms of human susceptibility. Analyzing 918 evaluations across five FMs (including GPT-4 and Llama-2), we employ Structural Causal Models (SCMs) as a principal framework for formulating testable causal hypotheses about detection accuracy. Contrary to partisan narratives, we find that political orientation shows a negligible association with detection performance ($r=-0.10$). Instead, \"fake news familiarity\" emerges as a candidate mediator ($r=0.35$), suggesting that exposure may function as adversarial training for human discriminators. We identify a \"fluency trap\" where GPT-4 outputs (HumanMachineScore: 0.20) bypass Source Monitoring mechanisms, rendering them indistinguishable from human text. These findings suggest that \"pre-bunking\" interventions should target cognitive source monitoring rather than demographic segmentation to ensure trustworthy information ecosystems.", "AI": {"tldr": "本文提出了JudgeGPT和RogueGPT框架，用于分析人类在识别基础模型生成的虚假信息时的表现，并探讨了影响因素。", "motivation": "随着基础模型接近于人类水平的语言流畅度，区分合成内容与真实内容成为可信网络智能的关键挑战。本研究旨在探究人们对于虚假信息识别的能力及原因。", "method": "使用918个评价样本，对包括GPT-4和Llama-2在内的五种基础模型进行了分析，并采用结构因果模型来测试关于检测准确性可验证的因果假设。", "result": "研究表明政治倾向与检测表现之间关联微弱（相关系数为-0.10），而虚假新闻熟悉度是潜在中介变量（相关系数为0.35）。同时，发现GPT-4生成的内容可能绕过来源监控机制，难以区分于人类文本。", "conclusion": "为了确保信息生态系统的可信性，“预驳论”干预应重点改善认知来源监测而非针对特定人群进行细分。"}}
{"id": "2601.22868", "pdf": "https://arxiv.org/pdf/2601.22868", "abs": "https://arxiv.org/abs/2601.22868", "authors": ["Shashank Mishra", "Didier Stricker", "Jason Rambach"], "title": "When Anomalies Depend on Context: Learning Conditional Compatibility for Anomaly Detection", "categories": ["cs.CV", "cs.LG"], "comment": "Preprint. Submitted to ICML 2026. 8 pages main text, plus appendix", "summary": "Anomaly detection is often formulated under the assumption that abnormality is an intrinsic property of an observation, independent of context. This assumption breaks down in many real-world settings, where the same object or action may be normal or anomalous depending on latent contextual factors (e.g., running on a track versus on a highway). We revisit \\emph{contextual anomaly detection}, classically defined as context-dependent abnormality, and operationalize it in the visual domain, where anomaly labels depend on subject--context compatibility rather than intrinsic appearance. To enable systematic study of this setting, we introduce CAAD-3K, a benchmark that isolates contextual anomalies by controlling subject identity while varying context. We further propose a conditional compatibility learning framework that leverages vision--language representations to model subject--context relationships under limited supervision. Our method substantially outperforms existing approaches on CAAD-3K and achieves state-of-the-art performance on MVTec-AD and VisA, demonstrating that modeling context dependence complements traditional structural anomaly detection. Our code and dataset will be publicly released.", "AI": {"tldr": "提出了一种基于条件兼容性的视觉异常检测方法，该方法考虑了情境对异常的影响。", "motivation": "当前的异常检测方法假设异常是观察对象固有的属性，并不依赖于上下文。然而，在真实场景中，同样的对象或动作可能因为不同的环境而被视为正常或异常。", "method": "引入了一个名为CAAD-3K的新基准数据集，用于研究基于情境的异常检测问题；同时提出了一种利用视觉语言表示来建模主体与背景关系的方法，并在少量监督下学习条件兼容性模型。", "result": "该方法在CAAD-3K、MVTec-AD和VisA等数据集上表现出色，证明了考虑情境依赖性的异常检测比传统的结构异常检测更有效。", "conclusion": "通过引入新的基准数据集以及提出基于条件兼容性学习的新方法，可以显著提高视觉领域中的异常检测性能。"}}
{"id": "2601.22865", "pdf": "https://arxiv.org/pdf/2601.22865", "abs": "https://arxiv.org/abs/2601.22865", "authors": ["Tanay Raghunandan Srinivasa", "Vivek Deulkar", "Jia Bhargava", "Mohammad Hajiesmaili", "Prashant Shenoy"], "title": "Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning", "categories": ["eess.SY", "cs.AI"], "comment": "11 pages, 2 figures", "summary": "Battery energy storage systems are increasingly deployed as fast-responding resources for grid balancing services such as frequency regulation and for mitigating renewable generation uncertainty. However, repeated charging and discharging induces cycling degradation and reduces battery lifetime. This paper studies the real-time scheduling of a heterogeneous battery fleet that collectively tracks a stochastic balancing signal subject to per-battery ramp-rate and capacity constraints, while minimizing long-term cycling degradation. Cycling degradation is fundamentally path-dependent: it is determined by charge-discharge cycles formed by the state-of-charge (SoC) trajectory and is commonly quantified via rainflow cycle counting. This non-Markovian structure makes it difficult to express degradation as an additive per-time-step cost, complicating classical dynamic programming approaches. We address this challenge by formulating the fleet scheduling problem as a Markov decision process (MDP) with constrained action space and designing a dense proxy reward that provides informative feedback at each time step while remaining aligned with long-term cycle-depth reduction. To scale learning to large state-action spaces induced by fine-grained SoC discretization and asymmetric per-battery constraints, we develop a function-approximation reinforcement learning method using an Extreme Learning Machine (ELM) as a random nonlinear feature map combined with linear temporal-difference learning. We evaluate the proposed approach on a toy Markovian signal model and on a Markovian model trained from real-world regulation signal traces obtained from the University of Delaware, and demonstrate consistent reductions in cycle-depth occurrence and degradation metrics compared to baseline scheduling policies.", "AI": {"tldr": "本文通过强化学习研究异构电池群在跟踪随机平衡信号时的实时调度，同时最小化长期循环退化。", "motivation": "频繁充放电会诱导电池循环退化并降低其寿命。如何在电网频率调节服务中减少这种影响成为研究重点。", "method": "采用带有受限动作空间的马尔可夫决策过程（MDP）模型，并设计了一种密集代理奖励机制，用以在每个时间步提供有信息量的反馈同时保持与长期循环深度降低一致。为了处理由精细SOC离散化和电池不对称约束引起的大型状态-行动空间，开发了使用极值学习机（ELM）作为随机非线性特征映射结合线性时序差分学习的功能逼近强化学习方法。", "result": "在玩具马尔可夫信号模型以及通过从University of Delaware获得的真实世界调节信号轨迹训练的马尔可夫模型上验证了所提出的方法，展示了与基线调度策略相比，在循环深度发生和退化指标上的持续降低。", "conclusion": "该方法成功解决了电池群在频率调节服务中平衡性能和寿命挑战的问题，并减少了长期循环退化。"}}
{"id": "2601.22864", "pdf": "https://arxiv.org/pdf/2601.22864", "abs": "https://arxiv.org/abs/2601.22864", "authors": ["Siyuan Wang", "Ke Li", "Jingyuan Huang", "Jike Wang", "Cheng Zhang", "Alanson Sample", "Dongyao Chen"], "title": "μTouch: Enabling Accurate, Lightweight Self-Touch Sensing with Passive Magnets", "categories": ["cs.HC"], "comment": "Accepted by PerCom 2026, 10 pages, 12 figures", "summary": "Self-touch gestures (e.g., nuanced facial touches and subtle finger scratches) provide rich insights into human behaviors, from hygiene practices to health monitoring. However, existing approaches fall short in detecting such micro gestures due to their diverse movement patterns. This paper presents μTouch, a novel magnetic sensing platform for self-touch gesture recognition. μTouch features (1) a compact hardware design with low-power magnetometers and magnetic silicon, (2) a lightweight semi-supervised framework requiring minimal user data, and (3) an ambient field detection module to mitigate environmental interference. We evaluated μTouch in two representative applications in user studies with 11 and 12 participants. μTouch only requires three-second fine-tuning data for each gesture, and new users need less than one minute before starting to use the system. μTouch can distinguish eight different face-touching behaviors with an average accuracy of 93.41%, and reliably detect body-scratch behaviors with an average accuracy of 94.63%. μTouch demonstrates accurate and robust sensing performance even after a month, showcasing its potential as a practical tool for hygiene monitoring and dermatological health applications.", "AI": {"tldr": "μTouch是一种用于检测细微自我触摸动作的磁性传感平台，旨在监测个人卫生和皮肤健康。", "motivation": "现有的技术难以准确地检测到面部接触和其他微妙的手势，因为这些手势具有多样的运动模式。因此，研究者开发了μTouch来解决这个问题，提供一种轻量级且低功耗的方法进行自我触摸感测。", "method": "μTouch包含紧凑的硬件设计，使用低功率磁力计和磁性硅材料；同时采用轻量级的半监督学习框架，并包括一个环境磁场检测模块以减少外部干扰。系统只需要三秒的数据进行微调即可区分不同的手势动作。", "result": "在用户研究中，μTouch能够准确识别八种面部接触行为，平均精度为93.41%，并且可以可靠地检测到身体抓挠行为，平均精度达到94.63%。该系统即使在一月后也能保持高度的准确性。", "conclusion": "μTouch作为一种创新性的磁性传感平台，在自我触摸手势识别上展现了高准确性和鲁棒性能，显示出其作为个人卫生监测和皮肤健康应用实用工具的巨大潜力。"}}
{"id": "2601.22861", "pdf": "https://arxiv.org/pdf/2601.22861", "abs": "https://arxiv.org/abs/2601.22861", "authors": ["Refael Sheffer", "Chen Pinchover", "Haim Zisman", "Dror Ozeri", "Roee Litman"], "title": "Under-Canopy Terrain Reconstruction in Dense Forests Using RGB Imaging and Neural 3D Reconstruction", "categories": ["cs.CV", "cs.CY", "cs.ET", "cs.GR"], "comment": "WACV 2026 CV4EO", "summary": "Mapping the terrain and understory hidden beneath dense forest canopies is of great interest for numerous applications such as search and rescue, trail mapping, forest inventory tasks, and more. Existing solutions rely on specialized sensors: either heavy, costly airborne LiDAR, or Airborne Optical Sectioning (AOS), which uses thermal synthetic aperture photography and is tailored for person detection. We introduce a novel approach for the reconstruction of canopy-free, photorealistic ground views using only conventional RGB images. Our solution is based on the celebrated Neural Radiance Fields (NeRF), a recent 3D reconstruction method. Additionally, we include specific image capture considerations, which dictate the needed illumination to successfully expose the scene beneath the canopy. To better cope with the poorly lit understory, we employ a low light loss. Finally, we propose two complementary approaches to remove occluding canopy elements by controlling per-ray integration procedure. To validate the value of our approach, we present two possible downstream tasks. For the task of search and rescue (SAR), we demonstrate that our method enables person detection which achieves promising results compared to thermal AOS (using only RGB images). Additionally, we show the potential of our approach for forest inventory tasks like tree counting. These results position our approach as a cost-effective, high-resolution alternative to specialized sensors for SAR, trail mapping, and forest-inventory tasks.", "AI": {"tldr": "利用RGB成像和神经3D重建方法，在密集森林中重建无树冠的地形。", "motivation": "在不依赖昂贵且专业的LiDAR或AOS传感器的情况下，使用常规RGB图像进行地下植被及地形的高分辨率、低成本测绘。", "method": "基于NeRF技术，并通过特定的光照条件和低光损失优化来提高地下场景的可见性；同时提出了两种方法用于消除树冠遮挡。", "result": "该方法在搜索和救援任务中实现了与AOS相当的人体检测性能，同时也展示了对森林资源调查（如树木计数）的有效性。", "conclusion": "此研究提供了一种低成本、高分辨率替代现有解决方案的方法，适用于搜索和救援、路径测绘及森林管理等任务。"}}
{"id": "2601.22860", "pdf": "https://arxiv.org/pdf/2601.22860", "abs": "https://arxiv.org/abs/2601.22860", "authors": ["Chanwook Park", "Brian Kim", "Jiachen Guo", "Wing Kam Liu"], "title": "Bayesian Interpolating Neural Network (B-INN): a scalable and reliable Bayesian model for large-scale physical systems", "categories": ["math.NA", "cs.AI"], "comment": "8 pages, 6 figures, ICML conference full paper submitted", "summary": "Neural networks and machine learning models for uncertainty quantification suffer from limited scalability and poor reliability compared to their deterministic counterparts. In industry-scale active learning settings, where generating a single high-fidelity simulation may require days or weeks of computation and produce data volumes on the order of gigabytes, they quickly become impractical. This paper proposes a scalable and reliable Bayesian surrogate model, termed the Bayesian Interpolating Neural Network (B-INN). The B-INN combines high-order interpolation theory with tensor decomposition and alternating direction algorithm to enable effective dimensionality reduction without compromising predictive accuracy. We theoretically show that the function space of a B-INN is a subset of that of Gaussian processes, while its Bayesian inference exhibits linear complexity, $\\mathcal{O}(N)$, with respect to the number of training samples. Numerical experiments demonstrate that B-INNs can be from 20 times to 10,000 times faster with a robust uncertainty estimation compared to Bayesian neural networks and Gaussian processes. These capabilities make B-INN a practical foundation for uncertainty-driven active learning in large-scale industrial simulations, where computational efficiency and robust uncertainty calibration are paramount.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.22859", "pdf": "https://arxiv.org/pdf/2601.22859", "abs": "https://arxiv.org/abs/2601.22859", "authors": ["Chuanzhe Guo", "Jingjing Wu", "Sijun He", "Yang Chen", "Zhaoqi Kuang", "Shilong Fan", "Bingjin Chen", "Siqi Bao", "Jing Liu", "Hua Wu", "Qingfu Zhu", "Wanxiang Che", "Haifeng Wang"], "title": "MEnvAgent: Scalable Polyglot Environment Construction for Verifiable Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The evolution of Large Language Model (LLM) agents for software engineering (SWE) is constrained by the scarcity of verifiable datasets, a bottleneck stemming from the complexity of constructing executable environments across diverse languages. To address this, we introduce MEnvAgent, a Multi-language framework for automated Environment construction that facilitates scalable generation of verifiable task instances. MEnvAgent employs a multi-agent Planning-Execution-Verification architecture to autonomously resolve construction failures and integrates a novel Environment Reuse Mechanism that reduces computational overhead by incrementally patching historical environments. Evaluations on MEnvBench, a new benchmark comprising 1,000 tasks across 10 languages, demonstrate that MEnvAgent outperforms baselines, improving Fail-to-Pass (F2P) rates by 8.6% while reducing time costs by 43%. Additionally, we demonstrate the utility of MEnvAgent by constructing MEnvData-SWE, the largest open-source polyglot dataset of realistic verifiable Docker environments to date, alongside solution trajectories that enable consistent performance gains on SWE tasks across a wide range of models. Our code, benchmark, and dataset are available at https://github.com/ernie-research/MEnvAgent.", "AI": {"tldr": "MEnvAgent是一个用于软件工程的多语言框架，旨在通过自动构建可验证的任务实例来解决缺少可验证数据集的问题。", "motivation": "大型语言模型代理在软件工程项目中的应用受到缺乏可验证数据集的限制，因为创建跨多种语言的可执行环境非常复杂。MEnvAgent的目标是提供一个解决方案以克服这一障碍。", "method": "MEnvAgent使用多代理计划-执行-验证架构自动解决构建失败问题，并通过一种新的环境重用机制减少计算开销。该方法能够增量地修补历史上的环境。", "result": "在包含10种语言的1000个任务的新基准测试MEnvBench上，MEnvAgent优于基线模型，提高了8.6%的成功率并减少了43%的时间成本。此外，还构建了MEnvData-SWE，这是迄今为止最大的开源多语言可验证Docker环境数据集。", "conclusion": "MEnvAgent通过减少时间和资源开销、提高成功率展示了其在软件工程任务中的有效性和实用性，并提供了一个公开可用的数据集和基准测试框架。"}}
{"id": "2601.22858", "pdf": "https://arxiv.org/pdf/2601.22858", "abs": "https://arxiv.org/abs/2601.22858", "authors": ["Thor Vestergaard Christiansen", "Karran Pandey", "Alba Reinders", "Karan Singh", "Morten Rieger Hannemose", "J. Andreas Bærentzen"], "title": "Learning to Build Shapes by Extrusion", "categories": ["cs.GR", "cs.AI"], "comment": "A preprint", "summary": "We introduce Text Encoded Extrusion (TEE), a text-based representation that expresses mesh construction as sequences of face extrusions rather than polygon lists, and a method for generating 3D meshes from TEE using a large language model (LLM). By learning extrusion sequences that assemble a mesh, similar to the way artists create meshes, our approach naturally supports arbitrary output face counts and produces manifold meshes by design, in contrast to recent transformer-based models. The learnt extrusion sequences can also be applied to existing meshes - enabling editing in addition to generation. To train our model, we decompose a library of quadrilateral meshes with non-self-intersecting face loops into constituent loops, which can be viewed as their building blocks, and finetune an LLM on the steps for reassembling the meshes by performing a sequence of extrusions. We demonstrate that our representation enables reconstruction, novel shape synthesis, and the addition of new features to existing meshes.", "AI": {"tldr": "论文介绍了通过学习挤压序列来生成和编辑三维网格的方法TEE。", "motivation": "传统方法难以支持任意输出面数并且不能保证生成的网格是流形结构，而基于转换器模型的方法则需要大量的训练数据。本文提出了一种新的文本编码表示方式（TEE），能够自然地支持任意输出面数并保证生成的网格为流形结构，并且可以应用于现有网格以实现编辑功能。", "method": "论文将四边形网格分解为其构成环路，然后使用大语言模型学习重新组装这些网格所需的挤压序列，并通过微调LLM来训练模型。", "result": "TEE表示法能够进行三维网格的重建、新颖形状合成以及向现有网格添加新特征。", "conclusion": "提出的基于挤压序列的方法可以更自然地支持任意输出面数，生成流形结构，并且易于实现编辑功能。"}}
{"id": "2601.22853", "pdf": "https://arxiv.org/pdf/2601.22853", "abs": "https://arxiv.org/abs/2601.22853", "authors": ["Siyi Du", "Xinzhe Luo", "Declan P. O'Regan", "Chen Qin"], "title": "Inference-Time Dynamic Modality Selection for Incomplete Multimodal Classification", "categories": ["cs.CV"], "comment": "27 pages (including appendix), accepted by ICLR 2026", "summary": "Multimodal deep learning (MDL) has achieved remarkable success across various domains, yet its practical deployment is often hindered by incomplete multimodal data. Existing incomplete MDL methods either discard missing modalities, risking the loss of valuable task-relevant information, or recover them, potentially introducing irrelevant noise, leading to the discarding-imputation dilemma. To address this dilemma, in this paper, we propose DyMo, a new inference-time dynamic modality selection framework that adaptively identifies and integrates reliable recovered modalities, fully exploring task-relevant information beyond the conventional discard-or-impute paradigm. Central to DyMo is a novel selection algorithm that maximizes multimodal task-relevant information for each test sample. Since direct estimation of such information at test time is intractable due to the unknown data distribution, we theoretically establish a connection between information and the task loss, which we compute at inference time as a tractable proxy. Building on this, a novel principled reward function is proposed to guide modality selection. In addition, we design a flexible multimodal network architecture compatible with arbitrary modality combinations, alongside a tailored training strategy for robust representation learning. Extensive experiments on diverse natural and medical image datasets show that DyMo significantly outperforms state-of-the-art incomplete/dynamic MDL methods across various missing-data scenarios. Our code is available at https://github.com//siyi-wind/DyMo.", "AI": {"tldr": "本文提出了一种新的推断时间动态模式选择框架DyMo，用于处理不完整多模态数据分类问题。", "motivation": "现有的多模态深度学习方法在面对不完整数据时存在舍弃或填补的困境，这可能导致信息丢失或引入噪声。为了克服这一难题，作者提出了一种新的解决方案来适应性地选择和整合可靠恢复的模式。", "method": "DyMo通过一个新颖的选择算法最大化每个测试样本的相关多模态任务信息，并且建立了信息与任务损失之间的理论联系以在推断时计算可操作代理。此外，设计了一个兼容任意模式组合的灵活网络架构以及为稳健表示学习量身定制的训练策略。", "result": "实验结果显示，DyMo显著优于现有的不完整/动态多模态方法，在各种缺失数据场景下具有更好的性能。", "conclusion": "本文提出的方法提供了一种新的处理多模态分类中不完整性问题的方式，并且在多个自然和医学图像数据集上验证了其优越性。"}}
{"id": "2601.22849", "pdf": "https://arxiv.org/pdf/2601.22849", "abs": "https://arxiv.org/abs/2601.22849", "authors": ["Christian Dietz", "Sebastian Albrecht", "Gianluca Frison", "Moritz Diehl", "Armin Nurkanović"], "title": "Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives", "categories": ["cs.RO", "math.OC"], "comment": "Submitted to Transactions on Robotics", "summary": "Efficient planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with reinforcement learning and sampling-based methods by using extensive physics simulations. This paper proposes a sample-efficient robust optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the efficient use of derivative information. To this end, a differentiable physics simulation is constructed that provides second-order analytic derivatives to the numerical solver and allows one to traverse seamlessly from informative derivatives to accurate contact simulation. The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem. We propose a modified variant of an optimization-based formulation of collision detection formulated as a linear program and present an efficient implementation for the nominal evaluation and corresponding first- and second-order derivatives. Moreover, a multi-scenario-based trajectory optimization problem that ensures robustness with respect to sim-to-real mismatches is derived. The capability of the considered formulation is illustrated by results where over 99\\% successful executions are achieved in real-world experiments. Thereby, we carefully investigate the effect of smooth approximations of the contact dynamics and robust modeling on the success rates. Furthermore, the method's capability is tested on different peg-in-hole problems in simulation to show the benefit of using exact Hessians over commonly used Hessian approximations.", "AI": {"tldr": "本文提出了一种高效的刚体装配方法，通过利用精确的二阶导数信息来减少物理模拟步骤。", "motivation": "传统装配运动规划面临计算效率低下问题，需要大量的物理模拟。为了解决这一挑战，提出了一个样本高效且鲁棒的最优控制方法以更少的物理模拟步长完成装配任务。", "method": "文章构建了一个可微分的物理仿真模型，利用精确的二阶导数信息，并通过光滑近似技术解决碰撞检测和接触问题，最终实现对不同场景下轨迹优化来保证从模拟到现实的有效性。", "result": "实验结果表明该方法在实际应用中的成功率超过99%，并通过与常用海森矩阵逼近对比验证了精确二阶导数的优势。", "conclusion": "研究提出了一种基于精确二阶导数的装配运动规划方法，提高了计算效率和鲁棒性，并通过实验证明了其有效性。"}}
{"id": "2601.22841", "pdf": "https://arxiv.org/pdf/2601.22841", "abs": "https://arxiv.org/abs/2601.22841", "authors": ["Leonard Hackel", "Tom Burgert", "Begüm Demir"], "title": "How Much of a Model Do We Need? Redundancy and Slimmability in Remote Sensing Foundation Models", "categories": ["cs.CV"], "comment": null, "summary": "Large-scale foundation models (FMs) in remote sensing (RS) are developed based on the paradigms established in computer vision (CV) and have shown promise for various Earth observation applications. However, the direct transfer of scaling assumptions from CV to RS has not been adequately examined. We hypothesize that RS FMs enter an overparameterized regime at substantially smaller scales than their CV counterparts, where increasing parameter count primarily induces redundant representations rather than qualitatively new abstractions. To test this hypothesis, we use post-hoc slimming, where we uniformly reduce the width of pretrained encoder, as a tool to measure representational redundancy across six state-of-the-art RS FMs on four downstream classification tasks. Our findings reveal a significant contrast with those in the CV domain: while a post-hoc slimmed masked autoencoder (MAE) trained on ImageNet retains less than 10% accuracy at 1% FLOPs, RS FMs maintain over 71% relative accuracy at the same budget. This sevenfold difference provides strong empirical support for our hypothesis. We further demonstrate that learned slimmable training can improve both Momentum Contrast (MoCo)- and MAE- based models. In addition, through the explained variance ratio and the feature correlation analysis, we provide mechanistic explanations showing that RS FMs distribute task-relevant information with high redundancy. Our findings establish post-hoc slimmability as both a practical deployment strategy for resource-constrained environments and a diagnostic tool that challenges the prevailing scaling paradigm in RS. Upon acceptance, we will publish all code.", "AI": {"tldr": "本论文研究了遥感领域大规模基础模型（FMs）的冗余度和轻量化能力，通过实验表明这些模型在参数减少后仍然保持较高的准确性。", "motivation": "论文质疑直接将计算机视觉领域的规模扩展假设应用于遥感领域的可行性，并提出遥感基础模型可能在较小规模时就已经进入过度参数化阶段。这激发了研究者对如何优化资源使用和提高模型效率的兴趣。", "method": "作者采用后处理瘦身技术，即统一减少预训练编码器的宽度，来衡量六种最先进的遥感基础模型在四个下游分类任务上的表示冗余度。", "result": "实验结果表明，与计算机视觉领域相比，遥感基础模型即使参数量减少到原来的1%，仍然能够保持超过71%的相对准确率。此外，作者还通过方差解释比率和特征相关性分析提供了机制性解释。", "conclusion": "研究揭示了遥感基础模型具有较高的冗余度，并证实了它们在轻量化后的性能依旧优越，这不仅为资源受限环境下的部署提供了一种实用策略，而且挑战了现有的规模扩展范式。"}}
{"id": "2601.22838", "pdf": "https://arxiv.org/pdf/2601.22838", "abs": "https://arxiv.org/abs/2601.22838", "authors": ["Zhijing Yang", "Weiwei Zhang", "Mingliang Yang", "Siyuan Peng", "Yukai Shi", "Junpeng Tan", "Tianshui Chen", "Liruo Zhong"], "title": "Neural Clothing Tryer: Customized Virtual Try-On via Semantic Enhancement and Controlling Diffusion Model", "categories": ["cs.CV"], "comment": "Accepted by Expert Systems with Applications. 16 pages, 10 figures", "summary": "This work aims to address a novel Customized Virtual Try-ON (Cu-VTON) task, enabling the superimposition of a specified garment onto a model that can be customized in terms of appearance, posture, and additional attributes. Compared with traditional VTON task, it enables users to tailor digital avatars to their individual preferences, thereby enhancing the virtual fitting experience with greater flexibility and engagement. To address this task, we introduce a Neural Clothing Tryer (NCT) framework, which exploits the advanced diffusion models equipped with semantic enhancement and controlling modules to better preserve semantic characterization and textural details of the garment and meanwhile facilitating the flexible editing of the model's postures and appearances. Specifically, NCT introduces a semantic-enhanced module to take semantic descriptions of garments and utilizes a visual-language encoder to learn aligned features across modalities. The aligned features are served as condition input to the diffusion model to enhance the preservation of the garment's semantics. Then, a semantic controlling module is designed to take the garment image, tailored posture image, and semantic description as input to maintain garment details while simultaneously editing model postures, expressions, and various attributes. Extensive experiments on the open available benchmark demonstrate the superior performance of the proposed NCT framework.", "AI": {"tldr": "神经衣物试穿器（NCT）框架旨在实现定制化的虚拟试穿，允许用户根据个人喜好调整数字形象的姿势和外观。", "motivation": "为了提升虚拟试衣体验的灵活性与互动性，提出了一种新的定制化虚拟试穿任务，可以自定义模特的姿态、外观等属性，并更好地保持衣物的语义特征及纹理细节。", "method": "引入了具备语义增强模块和控制扩散模型的NCT框架，利用视觉语言编码器学习不同模态下的对齐特征，并结合输入的衣物图像、定制姿势图象和语义描述来编辑模特姿势和其他属性的同时保留衣服细节。", "result": "在公开基准数据集上进行了大量实验，证明了提出的NCT框架具有优越的性能表现。", "conclusion": "所提方法成功实现了高度灵活且真实的虚拟试穿体验，并验证其效果优于传统技术。"}}
{"id": "2601.22837", "pdf": "https://arxiv.org/pdf/2601.22837", "abs": "https://arxiv.org/abs/2601.22837", "authors": ["Bin Wu", "Mengqi Huang", "Weinan Jia", "Zhendong Mao"], "title": "NativeTok: Native Visual Tokenization for Improved Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "VQ-based image generation typically follows a two-stage pipeline: a tokenizer encodes images into discrete tokens, and a generative model learns their dependencies for reconstruction. However, improved tokenization in the first stage does not necessarily enhance the second-stage generation, as existing methods fail to constrain token dependencies. This mismatch forces the generative model to learn from unordered distributions, leading to bias and weak coherence. To address this, we propose native visual tokenization, which enforces causal dependencies during tokenization. Building on this idea, we introduce NativeTok, a framework that achieves efficient reconstruction while embedding relational constraints within token sequences. NativeTok consists of: (1) a Meta Image Transformer (MIT) for latent image modeling, and (2) a Mixture of Causal Expert Transformer (MoCET), where each lightweight expert block generates a single token conditioned on prior tokens and latent features. We further design a Hierarchical Native Training strategy that updates only new expert blocks, ensuring training efficiency. Extensive experiments demonstrate the effectiveness of NativeTok.", "AI": {"tldr": "本论文提出了一种新的图像生成框架NativeTok，通过引入因果依赖关系来改进视觉标记化。", "motivation": "传统的基于VQ的图像生成方法在第一阶段的标记化过程中没有约束令牌之间的依赖关系，导致第二阶段的生成模型学习无序分布时存在偏差和弱连贯性问题。", "method": "NativeTok框架由Meta Image Transformer（MIT）和Mixture of Causal Expert Transformer（MoCET）组成。前者用于潜在图像建模，后者通过轻量级专家块生成令牌并嵌入关系约束。还设计了分层原生训练策略以确保训练效率。", "result": "实验结果表明，NativeTok框架在图像重建和连贯性方面表现优异。", "conclusion": "NativeTok改进了传统的标记化方法，通过引入因果依赖关系实现了更有效的图像生成"}}
{"id": "2601.22832", "pdf": "https://arxiv.org/pdf/2601.22832", "abs": "https://arxiv.org/abs/2601.22832", "authors": ["Matthew Becker", "Yifei Chen", "Nicholas Cochran", "Pouyan Ghasemi", "Abhishek Gulati", "Mark Harman", "Zachary Haluza", "Mehrdad Honarkhah", "Herve Robert", "Jiacheng Liu", "Weini Liu", "Sreeja Thummala", "Xiaoning Yang", "Rui Xin", "Sophie Zeng"], "title": "Just-in-Time Catching Test Generation at Meta", "categories": ["cs.SE", "cs.AI"], "comment": "Submitted to FSE 2026 industry track", "summary": "We report on Just-in-Time catching test generation at Meta, designed to prevent bugs in large scale backend systems of hundreds of millions of line of code. Unlike traditional hardening tests, which pass at generation time, catching tests are meant to fail, surfacing bugs before code lands. The primary challenge is to reduce development drag from false positive test failures. Analyzing 22,126 generated tests, we show code-change-aware methods improve candidate catch generation 4x over hardening tests and 20x over coincidentally failing tests. To address false positives, we use rule-based and LLM-based assessors. These assessors reduce human review load by 70%. Inferential statistical analysis showed that human-accepted code changes are assessed to have significantly more false positives, while human-rejected changes have significantly more true positives. We reported 41 candidate catches to engineers; 8 were confirmed to be true positives, 4 of which would have led to serious failures had they remained uncaught. Overall, our results show that Just-in-Time catching is scalable, industrially applicable, and that it prevents serious failures from reaching production.", "AI": {"tldr": "论文提出了即时捕捉测试生成方法，旨在预防大规模后端系统中的错误。", "motivation": "传统的加固测试在生成时通过，而捕捉测试则设计为失败以揭示潜在的bug。主要挑战在于减少由虚假阳性测试失败引起的开发阻力。", "method": "分析了22,126个生成的测试案例，展示了基于代码变更的方法相较于传统加固测试和偶然失败的测试提高了四倍和二十倍的效果。使用规则基线和LLM（大型语言模型）评估器来减少人工复查负担，并通过统计分析验证了其效果。", "result": "报告了41个候选捕捉到工程师；其中8个被确认为真正阳性，其中有4个会导致严重错误如果没有被发现的话。", "conclusion": "结果表明即时捕捉测试是可扩展的，工业适用性强，并且能够预防严重的生产失败。"}}
{"id": "2601.22831", "pdf": "https://arxiv.org/pdf/2601.22831", "abs": "https://arxiv.org/abs/2601.22831", "authors": ["Aaron Pengyu Zhu", "Kristina Mah", "Janghee Cho"], "title": "Toward Pluralizing Reflection in HCI through Daoism", "categories": ["cs.HC"], "comment": "Accepted by CHI '26", "summary": "Reflection is fundamental to how people make sense of everyday life, helping them navigate moments of growth, uncertainty, and change. Yet in HCI, existing frameworks of designing technologies to support reflection remain narrow, emphasizing cognitive, rational problem-solving, and individual self-improvement. We introduce Daoist philosophy as a non-Western lens to broaden this scope and reimagine reflective practices in interactive systems. Combining insights from Daoist literature with semi-structured interviews with 18 Daoist priests, scholars, and practitioners, we identified three key dimensions of everyday reflection: Stillness, Resonance, and Emergence. These dimensions reveal emergent, embodied, relational, and ethically driven qualities often overlooked in HCI research. We articulate their potential to inform alternative frameworks for interactive systems for reflection, advocating a shift from reflection toward reflecting-with, and highlight the potential of Daoism as an epistemological resource for the HCI community.", "AI": {"tldr": "本文旨在通过道家哲学扩展HCI领域中关于反思的框架，提出了三种新的日常反思维度：静、共鸣和涌现。", "motivation": "现有的HCI设计方法过于侧重于认知理性问题解决和个人自我提升，忽视了反映生活的多样性和复杂性。因此，作者希望通过引入非西方视角如道家思想来拓宽这一领域。", "method": "通过分析道家文献并与18位道家法师、学者和实践者进行半结构化访谈，本文揭示出三种新的日常反思维度：静、共鸣和涌现。", "result": "研究识别出了三种新颖的反思维度，并探讨了它们在互动系统中的应用潜力。这些新发现挑战了传统上过于个人主义和技术导向的视角，倡导了一种更加关系性和伦理驱动的方法论。", "conclusion": "本文提倡将道家思想作为知识资源引入HCI社区，强调通过与环境和他人的互动进行反思的重要性，并为未来的交互系统设计提供了新的方向。"}}
{"id": "2601.22830", "pdf": "https://arxiv.org/pdf/2601.22830", "abs": "https://arxiv.org/abs/2601.22830", "authors": ["Ji Zhou", "Yilin Ding", "Yongqi Zhao", "Jiachen Xu", "Arno Eichberger"], "title": "A Comparative Evaluation of Large Vision-Language Models for 2D Object Detection under SOTIF Conditions", "categories": ["cs.CV", "cs.RO"], "comment": "6 pages, 11 figures", "summary": "Reliable environmental perception remains one of the main obstacles for safe operation of automated vehicles. Safety of the Intended Functionality (SOTIF) concerns safety risks from perception insufficiencies, particularly under adverse conditions where conventional detectors often falter. While Large Vision-Language Models (LVLMs) demonstrate promising semantic reasoning, their quantitative effectiveness for safety-critical 2D object detection is underexplored. This paper presents a systematic evaluation of ten representative LVLMs using the PeSOTIF dataset, a benchmark specifically curated for long-tail traffic scenarios and environmental degradations. Performance is quantitatively compared against the classical perception approach, a YOLO-based detector. Experimental results reveal a critical trade-off: top-performing LVLMs (e.g., Gemini 3, Doubao) surpass the YOLO baseline in recall by over 25% in complex natural scenarios, exhibiting superior robustness to visual degradation. Conversely, the baseline retains an advantage in geometric precision for synthetic perturbations. These findings highlight the complementary strengths of semantic reasoning versus geometric regression, supporting the use of LVLMs as high-level safety validators in SOTIF-oriented automated driving systems.", "AI": {"tldr": "该论文系统评估了十种大型视觉语言模型在PeSOTIF数据集上的二维物体检测性能，尤其是在复杂自然场景和环境退化条件下的表现。", "motivation": "安全功能的可靠性是自动驾驶车辆面临的主要挑战之一。本文探讨了大型视觉语言模型在二维对象检测中的定量有效性，并比较了这些模型与传统检测器之间的性能差异，以解决感知不足的问题。", "method": "该研究使用PeSOTIF数据集对十种代表性LVLM进行了系统评估，并将它们的性能与经典感知方法YOLO进行对比。", "result": "实验结果显示，在复杂自然场景中顶级LVLM（如Gemini 3和Doubao）的召回率超过YOLO基线25%以上，表现出更好的鲁棒性。然而，在合成扰动下几何精度方面，传统检测器仍具优势。", "conclusion": "研究发现强调了语义推理与几何回归之间的互补优势，支持在自动驾驶系统中将LVLM用作高级安全验证工具。"}}
{"id": "2601.22828", "pdf": "https://arxiv.org/pdf/2601.22828", "abs": "https://arxiv.org/abs/2601.22828", "authors": ["Zhan Fa", "Yue Duan", "Jian Zhang", "Lei Qi", "Wanqi Yang", "Yinghuan Shi"], "title": "Decomposing and Composing: Towards Efficient Vision-Language Continual Learning via Rank-1 Expert Pool in a Single LoRA", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Continual learning (CL) in vision-language models (VLMs) faces significant challenges in improving task adaptation and avoiding catastrophic forgetting. Existing methods usually have heavy inference burden or rely on external knowledge, while Low-Rank Adaptation (LoRA) has shown potential in reducing these issues by enabling parameter-efficient tuning. However, considering directly using LoRA to alleviate the catastrophic forgetting problem is non-trivial, we introduce a novel framework that restructures a single LoRA module as a decomposable Rank-1 Expert Pool. Our method learns to dynamically compose a sparse, task-specific update by selecting from this expert pool, guided by the semantics of the [CLS] token. In addition, we propose an Activation-Guided Orthogonal (AGO) loss that orthogonalizes critical parts of LoRA weights across tasks. This sparse composition and orthogonalization enable fewer parameter updates, resulting in domain-aware learning while minimizing inter-task interference and maintaining downstream task performance. Extensive experiments across multiple settings demonstrate state-of-the-art results in all metrics, surpassing zero-shot upper bounds in generalization. Notably, it reduces trainable parameters by 96.7% compared to the baseline method, eliminating reliance on external datasets or task-ID discriminators. The merged LoRAs retain less weights and incur no inference latency, making our method computationally lightweight.", "AI": {"tldr": "本文提出了一种基于单一LoRA模块的可分解Rank-1专家池框架，以解决视觉语言连续学习中的灾难性遗忘和任务适应问题。", "motivation": "当前方法在减轻灾难性遗忘和降低推理负担方面存在挑战。低秩适应（LoRA）具有潜在优势，但直接应用于这些问题是复杂的，因此本文旨在通过引入可分解的Rank-1专家池来改进参数高效的调整。", "method": "该框架将单一LoRA模块重构为一个可以动态选择任务特定更新的可分解Rank-1专家池，并利用[CLS]标记的语义进行指导。此外，还提出了一种激活引导正交（AGO）损失，以跨任务正交化LoRA权重的关键部分。", "result": "实验结果显示，在所有指标上均取得了最先进的结果，超越了零样本上限的一般泛化性能，并减少了96.7%的可训练参数。合并后的LoRAs保留较少的权重且没有推理延迟。", "conclusion": "本文方法成功地在减轻灾难性遗忘和任务适应方面取得突破，同时保持模型高效性和轻量级计算特性。"}}
{"id": "2601.22823", "pdf": "https://arxiv.org/pdf/2601.22823", "abs": "https://arxiv.org/abs/2601.22823", "authors": ["Mathieu Petitbois", "Rémy Portelas", "Sylvain Lamprier"], "title": "Offline Reinforcement Learning of High-Quality Behaviors Under Robust Style Alignment", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study offline reinforcement learning of style-conditioned policies using explicit style supervision via subtrajectory labeling functions. In this setting, aligning style with high task performance is particularly challenging due to distribution shift and inherent conflicts between style and reward. Existing methods, despite introducing numerous definitions of style, often fail to reconcile these objectives effectively. To address these challenges, we propose a unified definition of behavior style and instantiate it into a practical framework. Building on this, we introduce Style-Conditioned Implicit Q-Learning (SCIQL), which leverages offline goal-conditioned RL techniques, such as hindsight relabeling and value learning, and combine it with a new Gated Advantage Weighted Regression mechanism to efficiently optimize task performance while preserving style alignment. Experiments demonstrate that SCIQL achieves superior performance on both objectives compared to prior offline methods. Code, datasets and visuals are available in: https://sciql-iclr-2026.github.io/.", "AI": {"tldr": "该论文提出了一种新的离线强化学习方法SCIQL，用于在保持风格一致性的前提下优化任务性能。", "motivation": "现有方法难以有效平衡风格与奖励之间的冲突，在离线强化学习中实现高质量行为的同时保持风格一致性颇具挑战性。", "method": "提出了一个统一的行为风格定义，并开发了Style-Conditioned Implicit Q-Learning（SCIQL）框架，结合了后见重标记和价值学习等技术。", "result": "实验表明SCIQL在任务性能和风格一致性方面均优于先前的方法。", "conclusion": "SCIQL方法通过高效优化任务性能的同时保持风格一致性，展示了其优越性。"}}
{"id": "2601.22820", "pdf": "https://arxiv.org/pdf/2601.22820", "abs": "https://arxiv.org/abs/2601.22820", "authors": ["Arya Hadizadeh Moghaddam", "Mohsen Nayebi Kerdabadi", "Dongjie Wang", "Mei Liu", "Zijun Yao"], "title": "User-Adaptive Meta-Learning for Cold-Start Medication Recommendation with Uncertainty Filtering", "categories": ["cs.LG", "cs.AI"], "comment": "IEEE International Conference on Data Engineering (ICDE) 2026 accepted paper", "summary": "Large-scale Electronic Health Record (EHR) databases have become indispensable in supporting clinical decision-making through data-driven treatment recommendations. However, existing medication recommender methods often struggle with a user (i.e., patient) cold-start problem, where recommendations for new patients are usually unreliable due to the lack of sufficient prescription history for patient profiling. While prior studies have utilized medical knowledge graphs to connect medication concepts through pharmacological or chemical relationships, these methods primarily focus on mitigating the item cold-start issue and fall short in providing personalized recommendations that adapt to individual patient characteristics. Meta-learning has shown promise in handling new users with sparse interactions in recommender systems. However, its application to EHRs remains underexplored due to the unique sequential structure of EHR data. To tackle these challenges, we propose MetaDrug, a multi-level, uncertainty-aware meta-learning framework designed to address the patient cold-start problem in medication recommendation. MetaDrug proposes a novel two-level meta-adaptation mechanism, including self-adaptation, which adapts the model to new patients using their own medical events as support sets to capture temporal dependencies; and peer-adaptation, which adapts the model using similar visits from peer patients to enrich new patient representations. Meanwhile, to further improve meta-adaptation outcomes, we introduce an uncertainty quantification module that ranks the support visits and filters out the unrelated information for adaptation consistency. We evaluate our approach on the MIMIC-III and Acute Kidney Injury (AKI) datasets. Experimental results on both datasets demonstrate that MetaDrug consistently outperforms state-of-the-art medication recommendation methods on cold-start patients.", "AI": {"tldr": "提出一种基于元学习的药物推荐框架MetaDrug，用于解决电子健康记录系统中新患者药物推荐的冷启动问题。", "motivation": "现有药物推荐方法在面对缺乏足够处方历史的新患者时难以提供可靠建议。当前的方法主要关注于通过医疗知识图谱缓解药品冷启动问题，并未充分考虑个性化需求和适应个体病患特点。", "method": "MetaDrug采用两级元自适应机制，包括自我适应与同伴适应，分别利用新患者的医学事件以及类似访问记录来捕捉时间依赖性并丰富患者表示。此外，还引入不确定性量化模块以筛选支持信息提高适应一致性。", "result": "实验结果表明，在MIMIC-III和急性肾损伤数据集上，MetaDrug在解决冷启动问题上的性能优于现有方法。", "conclusion": "通过两级元自适应机制结合不确定性过滤模块，MetaDrug有效解决了EHR系统中新患者的药物推荐挑战。"}}
{"id": "2601.22818", "pdf": "https://arxiv.org/pdf/2601.22818", "abs": "https://arxiv.org/abs/2601.22818", "authors": ["Charles Westphal", "Keivan Navaie", "Fernando E. Rosas"], "title": "Hide and Seek in Embedding Space: Geometry-based Steganography and Detection in Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Fine-tuned LLMs can covertly encode prompt secrets into outputs via steganographic channels. Prior work demonstrated this threat but relied on trivially recoverable encodings. We formalize payload recoverability via classifier accuracy and show previous schemes achieve 100\\% recoverability. In response, we introduce low-recoverability steganography, replacing arbitrary mappings with embedding-space-derived ones. For Llama-8B (LoRA) and Ministral-8B (LoRA) trained on TrojanStego prompts, exact secret recovery rises from 17$\\rightarrow$30\\% (+78\\%) and 24$\\rightarrow$43\\% (+80\\%) respectively, while on Llama-70B (LoRA) trained on Wiki prompts, it climbs from 9$\\rightarrow$19\\% (+123\\%), all while reducing payload recoverability. We then discuss detection. We argue that detecting fine-tuning-based steganographic attacks requires approaches beyond traditional steganalysis. Standard approaches measure distributional shift, which is an expected side-effect of fine-tuning. Instead, we propose a mechanistic interpretability approach: linear probes trained on later-layer activations detect the secret with up to 33\\% higher accuracy in fine-tuned models compared to base models, even for low-recoverability schemes. This suggests that malicious fine-tuning leaves actionable internal signatures amenable to interpretability-based defenses.", "AI": {"tldr": "本文提出了一种在大型语言模型中进行低可恢复性隐写的方法，并讨论了如何通过解释性方法来检测这些隐写。", "motivation": "为了应对使用大型语言模型进行隐藏信息传递的安全威胁，该研究旨在降低编码信息的可恢复性并提供有效的检测手段。", "method": "文章引入了一种基于嵌入空间的低恢复能力隐写技术，并通过线性探针训练后来层激活的方法来提高检测精度。这些方法减少了传统分布偏移检测在模型微调中的局限性。", "result": "与之前的技术相比，新的隐写方案提高了秘密恢复的成功率；同时，新提出的检测方法在细调模型中比原始模型具有更高的准确性，即使对于低可恢复性方案也是如此。", "conclusion": "通过引入基于嵌入空间的低恢复能力隐写技术以及利用解释性手段进行检测的方法，该研究为大型语言模型中的信息隐藏和安全防护提供了新的解决方案。"}}
{"id": "2601.22812", "pdf": "https://arxiv.org/pdf/2601.22812", "abs": "https://arxiv.org/abs/2601.22812", "authors": ["Jana Gonnermann-Müller", "Jennifer Haase", "Nicolas Leins", "Thomas Kosch", "Sebastian Pokutta"], "title": "Stable Personas: Dual-Assessment of Temporal Stability in LLM-Based Human Simulation", "categories": ["cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) acting as artificial agents offer the potential for scalable behavioral research, yet their validity depends on whether LLMs can maintain stable personas across extended conversations. We address this point using a dual-assessment framework measuring both self-reported characteristics and observer-rated persona expression. Across two experiments testing four persona conditions (default, high, moderate, and low ADHD presentations), seven LLMs, and three semantically equivalent persona prompts, we examine between-conversation stability (3,473 conversations) and within-conversation stability (1,370 conversations and 18 turns). Self-reports remain highly stable both between and within conversations. However, observer ratings reveal a tendency for persona expressions to decline during extended conversations. These findings suggest that persona-instructed LLMs produce stable, persona-aligned self-reports, an important prerequisite for behavioral research, while identifying this regression tendency as a boundary condition for multi-agent social simulation.", "AI": {"tldr": "研究评估了大型语言模型（LLM）在模拟不同人格时的稳定性和一致性。", "motivation": "为了验证大型语言模型作为人工代理的有效性，特别是在长时间对话中保持人格稳定性方面的重要性。", "method": "采用双评估框架测量自我报告特征和观察者评价的人格表达。实验包括四种人格条件、七种LLM和三个语义等效的人格提示，在3473次会话和18轮对话中进行测试。", "result": "自我报告在长时间内保持高度稳定，但观察者的评分显示随着对话的延长，人格表达有所下降。", "conclusion": "LLM能够生成稳定且符合预期的人格自述，为行为研究提供了重要依据，同时揭示了在多代理社会模拟中持续性的问题。"}}
{"id": "2601.22809", "pdf": "https://arxiv.org/pdf/2601.22809", "abs": "https://arxiv.org/abs/2601.22809", "authors": ["Haiyang Wu", "Weiliang Mu", "Jipeng Zhang", "Zhong Dandan", "Zhuofei Du", "Haifeng Li", "Tao Chao"], "title": "FarmMind: Reasoning-Query-Driven Dynamic Segmentation for Farmland Remote Sensing Images", "categories": ["cs.CV"], "comment": null, "summary": "Existing methods for farmland remote sensing image (FRSI) segmentation generally follow a static segmentation paradigm, where analysis relies solely on the limited information contained within a single input patch. Consequently, their reasoning capability is limited when dealing with complex scenes characterized by ambiguity and visual uncertainty. In contrast, human experts, when interpreting remote sensing images in such ambiguous cases, tend to actively query auxiliary images (such as higher-resolution, larger-scale, or temporally adjacent data) to conduct cross-verification and achieve more comprehensive reasoning. Inspired by this, we propose a reasoning-query-driven dynamic segmentation framework for FRSIs, named FarmMind. This framework breaks through the limitations of the static segmentation paradigm by introducing a reasoning-query mechanism, which dynamically and on-demand queries external auxiliary images to compensate for the insufficient information in a single input image. Unlike direct queries, this mechanism simulates the thinking process of human experts when faced with segmentation ambiguity: it first analyzes the root causes of segmentation ambiguities through reasoning, and then determines what type of auxiliary image needs to be queried based on this analysis. Extensive experiments demonstrate that FarmMind achieves superior segmentation performance and stronger generalization ability compared with existing methods. The source code and dataset used in this work are publicly available at: https://github.com/WithoutOcean/FarmMind.", "AI": {"tldr": "提出了一种基于推理查询的动态分割框架FarmMind，用于农业遥感图像（FRSI）分割。", "motivation": "现有的农业遥感图像分割方法依赖单一输入片段信息有限，处理复杂场景和视觉不确定性能力不足。人类专家在面对模糊情况时会主动查询辅助图来验证以实现更全面的推理。", "method": "FarmMind框架通过引入推理查询机制，在遇到分割模糊时模拟人类思维过程进行原因分析并动态调用所需辅助图像数据。", "result": "实验表明，与现有方法相比，FarmMind实现了更好的分割性能和更强的泛化能力。", "conclusion": "该研究提出了一种新的农业遥感图像动态分割框架，显著提高了复杂场景下的图像分割效果。"}}
{"id": "2601.22808", "pdf": "https://arxiv.org/pdf/2601.22808", "abs": "https://arxiv.org/abs/2601.22808", "authors": ["Elías Masquil", "Luca Savant Aira", "Roger Marí", "Thibaud Ehret", "Pablo Musé", "Gabriele Facciolo"], "title": "Diachronic Stereo Matching for Multi-Date Satellite Imagery", "categories": ["cs.CV"], "comment": "ef:ISPRS congress, ISPRS, Jul 2026, Toronto, Canada", "summary": "Recent advances in image-based satellite 3D reconstruction have progressed along two complementary directions. On one hand, multi-date approaches using NeRF or Gaussian-splatting jointly model appearance and geometry across many acquisitions, achieving accurate reconstructions on opportunistic imagery with numerous observations. On the other hand, classical stereoscopic reconstruction pipelines deliver robust and scalable results for simultaneous or quasi-simultaneous image pairs. However, when the two images are captured months apart, strong seasonal, illumination, and shadow changes violate standard stereoscopic assumptions, causing existing pipelines to fail. This work presents the first Diachronic Stereo Matching method for satellite imagery, enabling reliable 3D reconstruction from temporally distant pairs. Two advances make this possible: (1) fine-tuning a state-of-the-art deep stereo network that leverages monocular depth priors, and (2) exposing it to a dataset specifically curated to include a diverse set of diachronic image pairs. In particular, we start from a pretrained MonSter model, trained initially on a mix of synthetic and real datasets such as SceneFlow and KITTI, and fine-tune it on a set of stereo pairs derived from the DFC2019 remote sensing challenge. This dataset contains both synchronic and diachronic pairs under diverse seasonal and illumination conditions. Experiments on multi-date WorldView-3 imagery demonstrate that our approach consistently surpasses classical pipelines and unadapted deep stereo models on both synchronic and diachronic settings. Fine-tuning on temporally diverse images, together with monocular priors, proves essential for enabling 3D reconstruction from previously incompatible acquisition dates. Left image (winter) Right image (autumn) DSM geometry Ours (1.23 m) Zero-shot (3.99 m) LiDAR GT Figure 1. Output geometry for a winter-autumn image pair from Omaha (OMA 331 test scene). Our method recovers accurate geometry despite the diachronic nature of the pair, exhibiting strong appearance changes, which cause existing zero-shot methods to fail. Missing values due to perspective shown in black. Mean altitude error in parentheses; lower is better.", "AI": {"tldr": "本文提出了一个用于遥感影像的时间立体匹配方法，解决了不同日期间图像重建的问题。", "motivation": "现有时间差较大的卫星影像立体匹配方法存在季节、光照和阴影变化导致的重建失败问题。", "method": "通过微调具有单目深度先验的状态-of-the-art深度立体网络，并使用包含多样同步与异步配对的数据集进行训练，实现跨日期的3D重建。", "result": "实验表明，在多日期WorldView-3影像上，该方法在同步和异步设置下均优于传统管道和未调整的深度立体模型。", "conclusion": "通过引入时间多样性的图像微调，并利用单目先验，可以使从之前不兼容的采集日期中恢复准确的3D几何形状成为可能。"}}
{"id": "2601.22806", "pdf": "https://arxiv.org/pdf/2601.22806", "abs": "https://arxiv.org/abs/2601.22806", "authors": ["Aldric Labarthe", "Roland Bouffanais", "Julien Randon-Furling"], "title": "Aligning the Unseen in Attributed Graphs: Interplay between Graph Geometry and Node Attributes Manifold", "categories": ["cs.AI", "math.DG"], "comment": null, "summary": "The standard approach to representation learning on attributed graphs -- i.e., simultaneously reconstructing node attributes and graph structure -- is geometrically flawed, as it merges two potentially incompatible metric spaces. This forces a destructive alignment that erodes information about the graph's underlying generative process. To recover this lost signal, we introduce a custom variational autoencoder that separates manifold learning from structural alignment. By quantifying the metric distortion needed to map the attribute manifold onto the graph's Heat Kernel, we transform geometric conflict into an interpretable structural descriptor. Experiments show our method uncovers connectivity patterns and anomalies undetectable by conventional approaches, proving both their theoretical inadequacy and practical limitations.", "AI": {"tldr": "该论文提出了一个新的变分自动编码器方法，旨在解决传统归一化图形表示学习中因合并两个可能不兼容的度量空间而导致的信息丢失问题。", "motivation": "传统的图形表示学习方法在同时重建节点属性和图结构时存在几何缺陷，这会导致信息损失并影响对生成过程的理解。因此，论文旨在通过分离流形学习与结构对齐来恢复这些信号。", "method": "提出了一种定制的变分自动编码器模型，该模型独立进行流形学习和结构对齐，并通过量化将属性流形映射到图的热核所需的度量失真来解释几何冲突，从而得到可理解的结构性描述符。", "result": "实验表明，所提出的方法能够发现常规方法无法检测的连接模式和异常情况，证明了传统方法在理论上的不充分性和实际限制。", "conclusion": "该工作提供了一种有效的解决图形表示学习中度量空间兼容性问题的方法，并展示了其优越性的实验证据。"}}
{"id": "2601.22805", "pdf": "https://arxiv.org/pdf/2601.22805", "abs": "https://arxiv.org/abs/2601.22805", "authors": ["Pit Neitemeier", "Alessio Serra", "Jiaze Li", "Sascha Wirges", "Lukas Balles", "Jan Hendrik Metzen"], "title": "SOMBRERO: Measuring and Steering Boundary Placement in End-to-End Hierarchical Sequence Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Hierarchical sequence models replace fixed tokenization with learned segmentations that compress long byte sequences for efficient autoregressive modeling. While recent end-to-end methods can learn meaningful boundaries from the language-modeling objective alone, it remains difficult to quantitatively assess and systematically steer where compute is spent. We introduce a router-agnostic metric of boundary quality, boundary enrichment B, which measures how strongly chunk starts concentrate on positions with high next-byte surprisal. Guided by this metric, we propose Sombrero, which steers boundary placement toward predictive difficulty via a confidence-alignment boundary loss and stabilizes boundary learning by applying confidence-weighted smoothing at the input level rather than on realized chunks. On 1B scale, across UTF-8 corpora covering English and German text as well as code and mathematical content, Sombrero improves the accuracy-efficiency trade-off and yields boundaries that more consistently align compute with hard-to-predict positions.", "AI": {"tldr": "SOMBRERO 提出了一种新的边界质量度量标准和方法，旨在优化分层序列模型中的边界放置。", "motivation": "现有层次化序列模型难以定量评估并系统性地引导计算资源的分配。因此，研究者希望通过一种新方法改进这一点。", "method": "引入了一个路由无关的边界质量指标boundary enrichment B，并提出了Sombrero，该方法通过信心对齐边界损失将边界放置导向预测难度较大的位置，并通过输入级别的置信加权平滑来稳定边界的训练。", "result": "在大规模数据集上，Sombrero 改进了准确性与效率之间的权衡，使计算资源更加集中于难以预测的位置。", "conclusion": "通过新方法Sombrero，研究者成功优化了层次化序列模型的边界放置，并提高了整体性能。"}}
{"id": "2601.22803", "pdf": "https://arxiv.org/pdf/2601.22803", "abs": "https://arxiv.org/abs/2601.22803", "authors": ["Ji Shi", "Peiming Guo", "Meishan Zhang", "Miao Zhang", "Xuebo Liu", "Min Zhang", "Weili Guan"], "title": "CVeDRL: An Efficient Code Verifier via Difficulty-aware Reinforcement Learning", "categories": ["cs.AI", "cs.SE"], "comment": "17 pages, 3 figures", "summary": "Code verifiers play a critical role in post-verification for LLM-based code generation, yet existing supervised fine-tuning methods suffer from data scarcity, high failure rates, and poor inference efficiency. While reinforcement learning (RL) offers a promising alternative by optimizing models through execution-driven rewards without labeled supervision, our preliminary results show that naive RL with only functionality rewards fails to generate effective unit tests for difficult branches and samples. We first theoretically analyze showing that branch coverage, sample difficulty, syntactic and functional correctness can be jointly modeled as RL rewards, where optimizing these signals can improve the reliability of unit-test-based verification. Guided by this analysis, we design syntax- and functionality-aware rewards and further propose branch- and sample-difficulty--aware RL using exponential reward shaping and static analysis metrics. With this formulation, CVeDRL achieves state-of-the-art performance with only 0.6B parameters, yielding up to 28.97% higher pass rate and 15.08% higher branch coverage than GPT-3.5, while delivering over $20\\times$ faster inference than competitive baselines. Code is available at https://github.com/LIGHTCHASER1/CVeDRL.git", "AI": {"tldr": "该论文提出了一种名为CVeDRL的高效代码验证方法，通过难度感知强化学习来优化模型。", "motivation": "现有的监督微调方法在数据稀缺、高失败率和推理效率低下方面存在不足。而简单的基于功能性的奖励机制无法生成有效的单元测试。", "method": "设计了语法和功能性意识的奖励，并提出了分支和样本难度感知的强化学习，通过指数奖励塑造和静态分析指标来优化模型。", "result": "CVeDRL在只有0.6B参数的情况下达到了最先进的性能，比GPT-3.5提高了28.97%的通过率和15.08%的分支覆盖率，并且推理速度快了超过20倍。", "conclusion": "CVeDRL通过强化学习有效地解决了代码验证中的挑战，展示了在效率和准确度上的显著优势。"}}
{"id": "2601.22796", "pdf": "https://arxiv.org/pdf/2601.22796", "abs": "https://arxiv.org/abs/2601.22796", "authors": ["Marie Reinbigler", "Romain Rouffet", "Peter Naylor", "Mikolaj Czerkawski", "Nikolaos Dionelis", "Elisabeth Brunet", "Catalin Fetita", "Rosalie Martin"], "title": "HeatMat: Simulation of City Material Impact on Urban Heat Island Effect", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "The Urban Heat Island (UHI) effect, defined as a significant increase in temperature in urban environments compared to surrounding areas, is difficult to study in real cities using sensor data (satellites or in-situ stations) due to their coarse spatial and temporal resolution. Among the factors contributing to this effect are the properties of urban materials, which differ from those in rural areas. To analyze their individual impact and to test new material configurations, a high-resolution simulation at the city scale is required. Estimating the current materials used in a city, including those on building facades, is also challenging. We propose HeatMat, an approach to analyze at high resolution the individual impact of urban materials on the UHI effect in a real city, relying only on open data. We estimate building materials using street-view images and a pre-trained vision-language model (VLM) to supplement existing OpenStreetMap data, which describes the 2D geometry and features of buildings. We further encode this information into a set of 2D maps that represent the city's vertical structure and material characteristics. These maps serve as inputs for our 2.5D simulator, which models coupled heat transfers and enables random-access surface temperature estimation at multiple resolutions, reaching an x20 speedup compared to an equivalent simulation in 3D.", "AI": {"tldr": "通过高分辨率模拟分析城市材料对热岛效应的影响", "motivation": "研究城市环境温度增高的问题，需要精细的模拟来测试新材料配置和评估现有城市材料影响。使用街景图像和预训练视觉语言模型估算建筑材料，并生成2D地图输入到2.5D仿真器中以提高速度和精度。", "method": "利用街景图片与预训练的视觉-语言模型估计建筑材料，结合OpenStreetMap数据创建二维地图表示城市的垂直结构及材料特性，使用2.5D模拟器进行耦合热传递建模并实现多分辨率的表面温度估算。", "result": "达到了比3D仿真快二十倍的速度，并能够对城市材料影响做出详细评估。", "conclusion": "HeatMat提供了一种利用开放数据和高精度图像分析在真实城市中建筑材料对热岛效应的影响的方法，有助于改善城市规划与设计。"}}
{"id": "2601.22792", "pdf": "https://arxiv.org/pdf/2601.22792", "abs": "https://arxiv.org/abs/2601.22792", "authors": ["Muhammad Shakeel", "Yosuke Fukumoto", "Chikara Maeda", "Chyi-Jiunn Lin", "Shinji Watanabe"], "title": "CALM: Joint Contextual Acoustic-Linguistic Modeling for Personalization of Multi-Speaker ASR", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted to IEEE ICASSP 2026", "summary": "We present CALM, a joint Contextual Acoustic-Linguistic Modeling framework for multi-speaker automatic speech recognition (ASR). In personalized AI scenarios, the joint availability of acoustic and linguistic cues naturally motivates the integration of target-speaker conditioning with contextual biasing in overlapping conversations. CALM implements this integration in an end-to-end framework through speaker embedding-driven target-speaker extraction and dynamic vocabulary-based contextual biasing. We evaluate CALM on simulated English (LibriSpeechMix) and Japanese (Corpus of Spontaneous Japanese mixtures, CSJMix). On two-speaker mixtures, CALM reduces biased word error rate (B-WER) from 12.7 to 4.7 on LibriSpeech2Mix and biased character error rate (B-CER) from 16.6 to 8.4 on CSJMix2 (eval3), demonstrating the effectiveness of joint acoustic-linguistic modeling across languages. We additionally report results on the AMI corpus (IHM-mix condition) to validate performance on standardized speech mixtures.", "AI": {"tldr": "CALM框架通过融合声学和语言线索，提高多说话人自动语音识别系统在个人化场景中的表现。", "motivation": "为了提升个性化AI场景中重叠对话的识别效果，结合目标发言者信息和上下文偏置是自然且必要的。", "method": "CALM框架通过说话人嵌入驱动的目标发言人提取与基于动态词典的上下文偏置实现声学-语言线索的联合建模。", "result": "在两个说话人的混合对话中，CALM将LibriSpeech2Mix的数据集上的B-WER从12.7降低到4.7，并将CSJMix2（eval3）数据集上的B-CER从16.6降低到了8.4。", "conclusion": "通过实验验证了CALM在多说话人自动语音识别系统中的有效性，尤其是在跨语言的应用场景下。"}}
{"id": "2601.22790", "pdf": "https://arxiv.org/pdf/2601.22790", "abs": "https://arxiv.org/abs/2601.22790", "authors": ["Jianguo Huang", "Hao Zeng", "Bingyi Jing", "Hongxin Wei", "Bo An"], "title": "Conditional Performance Guarantee for Large Reasoning Models", "categories": ["cs.AI", "math.ST"], "comment": null, "summary": "Large reasoning models have shown strong performance through extended chain-of-thought reasoning, yet their computational cost remains significant. Probably approximately correct (PAC) reasoning provides statistical guarantees for efficient reasoning by adaptively switching between thinking and non-thinking models, but the guarantee holds only in the marginal case and does not provide exact conditional coverage. We propose G-PAC reasoning, a practical framework that provides PAC-style guarantees at the group level by partitioning the input space. We develop two instantiations: Group PAC (G-PAC) reasoning for known group structures and Clustered PAC (C-PAC) reasoning for unknown groupings. We prove that both G-PAC and C-PAC achieve group-conditional risk control, and that grouping can strictly improve efficiency over marginal PAC reasoning in heterogeneous settings. Our experiments on diverse reasoning benchmarks demonstrate that G-PAC and C-PAC successfully achieve group-conditional risk control while maintaining substantial computational savings.", "AI": {"tldr": "提出了一种新的框架G-PAC和C-PAC，用于提供基于组的条件风险控制，并证明了在异构设置中分组可以提高效率。", "motivation": "大型推理模型虽然性能强大但计算成本高，PAC推理通过适应性切换提供统计保证但在边缘情况下的精确条件覆盖不足。因此提出了G-PAC和C-PAC框架以解决这些问题。", "method": "开发了两种实例化：已知组结构的Group PAC (G-PAC) 推理以及未知分组的Clustered PAC (C-PAC) 推理，证明其在异构设置中可以提高效率。", "result": "实验表明G-PAC和C-PAC成功地实现了基于组的风险控制并保持了显著的计算节省。", "conclusion": "提出的框架能够为大型推理模型提供有效的统计保证并在实践中表现良好。"}}
{"id": "2601.22788", "pdf": "https://arxiv.org/pdf/2601.22788", "abs": "https://arxiv.org/abs/2601.22788", "authors": ["Jana Gonnermann-Müller", "Jennifer Haase", "Nicolas Leins", "Moritz Igel", "Konstantin Fackeldey", "Sebastian Pokutta"], "title": "FACET: Multi-Agent AI Supporting Teachers in Scaling Differentiated Learning for Diverse Students", "categories": ["cs.HC"], "comment": null, "summary": "Classrooms are becoming increasingly heterogeneous, comprising learners with diverse performance and motivation levels, language proficiencies, and learning differences such as dyslexia and ADHD. While teachers recognize the need for differentiated instruction, growing workloads create substantial barriers, making differentiated instruction an ideal that is often unrealized in practice. Current AI educational tools, which promise differentiated materials, are predominantly student-facing and performance-centric, ignoring other aspects that shape learning outcomes. We introduce FACET, a teacher-facing multi-agent framework designed to address these gaps by supporting differentiation that accounts for motivation, performance, and learning differences. Developed with educational stakeholders from the outset, the framework coordinates four specialized agents, including learner simulation, diagnostic assessment, material generation, and evaluation within a teacher-in-the-loop design. School principals (N = 30) shaped system requirements through participatory workshops, while in-service K-12 teachers (N = 70) evaluated material quality. Mixed-methods evaluation demonstrates strong perceived value for inclusive differentiation. Practitioners emphasized both the urgent need arising from classroom heterogeneity and the importance of maintaining pedagogical autonomy as a prerequisite for adoption. We discuss implications for future school deployment and outline partnerships for longitudinal classroom implementation.", "AI": {"tldr": "FACET是一个面向教师的多智能体框架，旨在通过支持差异化教学来解决课堂异质性带来的挑战。", "motivation": "当前AI教育工具主要面向学生和关注成绩表现，忽略了影响学习成果的其他因素。因此，设计一种能够全面考虑动机、成绩和学习差异的差异化教学系统是十分必要的。", "method": "FACET框架由四个专业化智能体组成：学习模拟器、诊断评估器、材料生成器以及评价器，在教师指导下协调工作。该研究邀请了30名学校管理者通过参与式研讨会塑造系统需求，并请70名在职中小学教师对生成的材料质量进行评估。", "result": "混合方法评估表明，FACET具有很强的差异化包容性价值；教育工作者强调了由于课堂异质性带来的迫切需求以及保持教学自主权的重要性。", "conclusion": "该研究讨论了未来在学校部署中的潜在影响，并概述了长期实施所需的合作伙伴关系。"}}
{"id": "2601.22786", "pdf": "https://arxiv.org/pdf/2601.22786", "abs": "https://arxiv.org/abs/2601.22786", "authors": ["Hamid Reza Akbari", "Mohammad Hossein Sameti", "Amir M. Mansourian", "Mohammad Hossein Rohban", "Hossein Sameti"], "title": "Toward IIT-Inspired Consciousness in LLMs: A Reward-Based Learning Framework", "categories": ["cs.AI"], "comment": "13 pages, 8 figures, 4 tables", "summary": "The pursuit of Artificial General Intelligence (AGI) is a central goal in language model development, in which consciousness-like processing could serve as a key facilitator. While current language models are not conscious, they exhibit behaviors analogous to certain aspects of consciousness. This paper investigates the implementation of a leading theory of consciousness, Integrated Information Theory (IIT), within language models via a reward-based learning paradigm. IIT provides a formal, axiom-based mathematical framework for quantifying consciousness. Drawing inspiration from its core principles, we formulate a novel reward function that quantifies a text's causality, coherence and integration, characteristics associated with conscious processing. Empirically, it is found that optimizing for this IIT-inspired reward leads to more concise text generation. On out of domain tasks, careful tuning achieves up to a 31% reduction in output length while preserving accuracy levels comparable to the base model. In addition to primary task performance, the broader effects of this training methodology on the model's confidence calibration and test-time computational scaling is analyzed. The proposed framework offers significant practical advantages: it is conceptually simple, computationally efficient, requires no external data or auxiliary models, and leverages a general, capability-driven signal rather than task-specific heuristics. Code available at https://github.com/MH-Sameti/LLM_PostTraining.git", "AI": {"tldr": "本文提出了一种基于奖励的学习框架，用于在语言模型中实现意识理论（IIT）的启发式方法。", "motivation": "当前的语言模型虽不具备意识，但能表现出与某些意识方面的类似行为。为了使语言模型更加接近AGI的目标，研究者试图将集成信息理论应用于语言模型之中，以增强其生成文本的质量和效率。", "method": "本文采用基于奖励的学习框架，借鉴了IIT的核心原理来制定一个新的奖励函数，该函数量化了文本的因果关系、连贯性和整合度。通过优化这个IIT启发式的奖励值，可以促使模型生成更简洁有效的文本。", "result": "实验表明，在不牺牲准确性的情况下，使用所提出的框架可以使输出长度减少最多31%。此外，这种训练方法还对模型的信心校准和测试时间计算规模产生了广泛影响。", "conclusion": "该研究提出的方法具有显著的实际优势：概念上简单、计算效率高、无需额外数据或辅助模型，并利用了一种通用的能力驱动信号而非任务特定的启发式方法。"}}
{"id": "2601.22783", "pdf": "https://arxiv.org/pdf/2601.22783", "abs": "https://arxiv.org/abs/2601.22783", "authors": ["Ilyass Moummad", "Marius Miron", "David Robinson", "Kawtar Zaher", "Hervé Goëau", "Olivier Pietquin", "Pierre Bonnet", "Emmanuel Chemla", "Matthieu Geist", "Alexis Joly"], "title": "Compact Hypercube Embeddings for Fast Text-based Wildlife Observation Retrieval", "categories": ["cs.IR", "cs.CV", "cs.LG", "cs.MM", "cs.SD"], "comment": null, "summary": "Large-scale biodiversity monitoring platforms increasingly rely on multimodal wildlife observations. While recent foundation models enable rich semantic representations across vision, audio, and language, retrieving relevant observations from massive archives remains challenging due to the computational cost of high-dimensional similarity search. In this work, we introduce compact hypercube embeddings for fast text-based wildlife observation retrieval, a framework that enables efficient text-based search over large-scale wildlife image and audio databases using compact binary representations. Building on the cross-view code alignment hashing framework, we extend lightweight hashing beyond a single-modality setup to align natural language descriptions with visual or acoustic observations in a shared Hamming space. Our approach leverages pretrained wildlife foundation models, including BioCLIP and BioLingual, and adapts them efficiently for hashing using parameter-efficient fine-tuning. We evaluate our method on large-scale benchmarks, including iNaturalist2024 for text-to-image retrieval and iNatSounds2024 for text-to-audio retrieval, as well as multiple soundscape datasets to assess robustness under domain shift. Results show that retrieval using discrete hypercube embeddings achieves competitive, and in several cases superior, performance compared to continuous embeddings, while drastically reducing memory and search cost. Moreover, we observe that the hashing objective consistently improves the underlying encoder representations, leading to stronger retrieval and zero-shot generalization. These results demonstrate that binary, language-based retrieval enables scalable and efficient search over large wildlife archives for biodiversity monitoring systems.", "AI": {"tldr": "本文介绍了一种紧凑的超立方体嵌入方法，用于快速文本检索大规模野生动物观测数据。", "motivation": "大型生物多样性监测平台依赖于多模态野生动植物观测。尽管最近的基础模型能够提供跨视觉、音频和语言的丰富语义表示，但由于高维相似性搜索的计算成本，从大量档案中检索相关信息仍具挑战性。", "method": "本文提出了一种基于紧凑超立方体嵌入的方法，用于快速文本检索大型野生动物图像和声音数据库。该方法使用轻量级哈希框架，将自然语言描述与视觉或听觉观察对齐在一个共享的汉明空间中，并利用预先训练好的野生动植物基础模型进行有效的哈希适配。", "result": "实验结果显示，在多个大规模基准测试数据集上，基于离散超立方体嵌入的检索性能优于连续嵌入，同时显著降低了内存和搜索成本。此外，发现哈希目标能够持续改进底层编码表示，提高检索能力和零样本泛化能力。", "conclusion": "该研究证明了二进制、语言基的检索方法能够在生物多样性监测系统的大型野生动物档案中实现可扩展且高效的搜索。"}}
{"id": "2601.22781", "pdf": "https://arxiv.org/pdf/2601.22781", "abs": "https://arxiv.org/abs/2601.22781", "authors": ["Linjia Kang", "Zhimin Wang", "Yongkang Zhang", "Duo Wu", "Jinghe Wang", "Ming Ma", "Haopeng Yan", "Zhi Wang"], "title": "Learning with Challenges: Adaptive Difficulty-Aware Data Generation for Mobile GUI Agent Training", "categories": ["cs.AI"], "comment": null, "summary": "Large-scale, high-quality interaction trajectories are essential for advancing mobile Graphical User Interface (GUI) agents. While existing methods typically rely on labor-intensive human demonstrations or automated model exploration to generate GUI trajectories, they lack fine-grained control over task difficulty. This fundamentally restricts learning effectiveness due to the mismatch between the training difficulty and the agent's capabilities. Inspired by how humans acquire skills through progressively challenging tasks, we propose MobileGen, a novel data generation framework that adaptively aligns training difficulty with the GUI agent's capability frontier. Specifically, MobileGen explicitly decouples task difficulty into structural (e.g., trajectory length) and semantic (e.g., task goal) dimensions. It then iteratively evaluates the agent on a curated prior dataset to construct a systematic profile of its capability frontier across these two dimensions. With this profile, the probability distribution of task difficulty is adaptively computed, from which the target difficulty for the next round of training can be sampled. Guided by the sampled difficulty, a multi-agent controllable generator is finally used to synthesize high-quality interaction trajectories along with corresponding task instructions. Extensive experiments show that MobileGen consistently outperforms existing data generation methods by improving the average performance of GUI agents by 1.57 times across multiple challenging benchmarks. This highlights the importance of capability-aligned data generation for effective mobile GUI agent training.", "AI": {"tldr": "提出了一种适应性挑战生成框架MobileGen，用于自动生成适合移动GUI代理训练的数据。", "motivation": "现有方法在生成交互轨迹时难以精确控制任务难度，导致了学习效率低下。为了解决这一问题，提出了新的数据生成框架来更好地匹配训练难度与代理能力。", "method": "通过将任务难度分解成结构和语义两个维度，并利用预定义的数据集评估代理的能力边界。根据该边界自适应计算任务难度分布并用于后续的交互轨迹合成。", "result": "实验显示，MobileGen在多个挑战性基准上显著优于现有的数据生成方法，提升了GUI代理性能约1.57倍。", "conclusion": "展示了能力对齐的数据生成对于有效训练移动GUI代理的重要性。"}}
{"id": "2601.22779", "pdf": "https://arxiv.org/pdf/2601.22779", "abs": "https://arxiv.org/abs/2601.22779", "authors": ["Genshun Wan", "Wenhui Zhang", "Jing-Xuan Zhang", "Shifu Xiong", "Jianqing Gao", "Zhongfu Ye"], "title": "Streaming Speech Recognition with Decoder-Only Large Language Models and Latency Optimization", "categories": ["eess.AS", "cs.SD"], "comment": "accepted to ICASSP 2026", "summary": "Recent advances have demonstrated the potential of decoderonly large language models (LLMs) for automatic speech recognition (ASR). However, enabling streaming recognition within this framework remains a challenge. In this work, we propose a novel streaming ASR approach that integrates a read/write policy network with monotonic chunkwise attention (MoChA) to dynamically segment speech embeddings. These segments are interleaved with label sequences during training, enabling seamless integration with the LLM. During inference, the audio stream is buffered until the MoChA module triggers a read signal, at which point the buffered segment together with the previous token is fed into the LLM for the next token prediction. We also introduce a minimal-latency training objective to guide the policy network toward accurate segmentation boundaries. Furthermore, we adopt a joint training strategy in which a non-streaming LLM-ASR model and our streaming model share parameters. Experiments on the AISHELL-1 and AISHELL-2 Mandarin benchmarks demonstrate that our method consistently outperforms recent streaming ASR baselines, achieving character error rates of 5.1% and 5.5%, respectively. The latency optimization results in a 62.5% reduction in average token generation delay with negligible impact on recognition accuracy", "AI": {"tldr": "本文提出了一种基于解码器的大规模语言模型（LLM）的实时语音识别方法，结合了读写策略网络和单向分块注意机制(MoChA)，以优化延迟并提高准确性。", "motivation": "当前大模型在自动语音识别领域展现了潜力，但如何实现实时语音识别仍然是一个挑战。本文旨在通过引入新颖的方法来解决这一问题，并最小化延迟。", "method": "该方法采用了读写策略网络和MoChA动态分割音频嵌入段落，训练过程中将这些片段与标签序列交错在一起以实现无缝集成到LLM中。在推理阶段，语音流被缓冲直到触发读取信号时才进行处理，并采用最小延迟目标来优化分段准确性。", "result": "实验结果表明，在AISHELL-1和AISHELL-2基准上该方法优于现有实时ASR基线，分别达到字符错误率5.1%和5.5%，同时平均令牌生成延迟降低了62.5%且对识别准确性的负面影响可以忽略不计。", "conclusion": "通过引入新颖的策略网络和最小化延迟目标来优化实时语音识别系统，在保持较高精度的同时实现了显著的延迟降低，展示了这种方法的有效性。"}}
{"id": "2601.22778", "pdf": "https://arxiv.org/pdf/2601.22778", "abs": "https://arxiv.org/abs/2601.22778", "authors": ["Nan Zhong", "Yiran Xu", "Mian Zou"], "title": "Color Matters: Demosaicing-Guided Color Correlation Training for Generalizable AI-Generated Image Detection", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "As realistic AI-generated images threaten digital authenticity, we address the generalization failure of generative artifact-based detectors by exploiting the intrinsic properties of the camera imaging pipeline. Concretely, we investigate color correlations induced by the color filter array (CFA) and demosaicing, and propose a Demosaicing-guided Color Correlation Training (DCCT) framework for AI-generated image detection. By simulating the CFA sampling pattern, we decompose each color image into a single-channel input (as the condition) and the remaining two channels as the ground-truth targets (for prediction). A self-supervised U-Net is trained to model the conditional distribution of the missing channels from the given one, parameterized via a mixture of logistic functions. Our theoretical analysis reveals that DCCT targets a provable distributional difference in color-correlation features between photographic and AI-generated images. By leveraging these distinct features to construct a binary classifier, DCCT achieves state-of-the-art generalization and robustness, significantly outperforming prior methods across over 20 unseen generators.", "AI": {"tldr": "该论文提出了一种基于颜色相关性训练的框架（DCCT）来检测AI生成的图像，通过模拟色滤阵列和去马赛克过程中的颜色关联特性，提高了泛化能力和鲁棒性。", "motivation": "为了应对现实主义AI生成图像对数字真实性构成的威胁，该研究旨在解决基于生成特征的探测器在泛化上的局限，利用相机成像管道中的固有属性来改善检测性能。", "method": "通过模拟色滤阵列采样模式，将每个颜色图像分解为单通道输入和剩余两个作为预测目标。训练自监督U-Net模型以学习给定通道条件下缺失通道的概率分布，并以此构造二元分类器。", "result": "理论分析显示DCCT框架能够捕捉到真实照片与AI生成图像之间在色相关性特征上的显著差异，从而构建的二元分类器表现出优于现有方法的泛化能力和鲁棒性，在超过20种未见过的生成器上取得了最先进的性能。", "conclusion": "该研究证明了通过模拟相机成像管道中的颜色关联特性来训练模型可以有效检测AI生成图像，并且这种基于DCCT的方法在多种场景下都能提供良好的表现。"}}
{"id": "2601.22776", "pdf": "https://arxiv.org/pdf/2601.22776", "abs": "https://arxiv.org/abs/2601.22776", "authors": ["Shichao Ma", "Zhiyuan Ma", "Ming Yang", "Xiaofan Li", "Xing Wu", "Jintao Du", "Yu Cheng", "Weiqiang Wang", "Qiliang Liu", "Zhengyang Zhou", "Yang Wang"], "title": "TSPO: Breaking the Double Homogenization Dilemma in Multi-turn Search Policy Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Multi-turn tool-integrated reasoning enables Large Language Models (LLMs) to solve complex tasks through iterative information retrieval. However, current reinforcement learning (RL) frameworks for search-augmented reasoning predominantly rely on sparse outcome-level rewards, leading to a \"Double Homogenization Dilemma.\" This manifests as (1) Process homogenization, where the thinking, reasoning, and tooling involved in generation are ignored. (2) Intra-group homogenization, coarse-grained outcome rewards often lead to inefficiencies in intra-group advantage estimation with methods like Group Relative Policy Optimization (GRPO) during sampling. To address this, we propose Turn-level Stage-aware Policy Optimization (TSPO). TSPO introduces the First-Occurrence Latent Reward (FOLR) mechanism, allocating partial rewards to the step where the ground-truth answer first appears, thereby preserving process-level signals and increasing reward variance within groups without requiring external reward models or any annotations. Extensive experiments demonstrate that TSPO significantly outperforms state-of-the-art baselines, achieving average performance gains of 24% and 13.6% on Qwen2.5-3B and 7B models, respectively.", "AI": {"tldr": "论文提出了一种针对多轮搜索策略优化的TSPO方法，解决了当前强化学习框架中过程同质化和组内同质化的难题。", "motivation": "现有的基于稀疏结果级奖励的强化学习框架导致了双同质化困境：忽视生成中的思考、推理及工具使用，以及因粗粒度奖励而导致的组内优势评估效率低下。", "method": "TSPO引入首次出现隐式奖励机制（FOLR），为首次出现真实答案步骤分配部分奖励，以保留过程级信号并增加组内的奖励差异性。", "result": "实验结果显示，TSPO显著优于最先进的基线方法，在Qwen2.5-3B和7B模型上分别取得了平均性能提升24%和13.6%的成绩。", "conclusion": "通过引入FOLR机制，TSPO成功解决了双同质化问题，并在多个实验中展示了优越的性能。"}}
{"id": "2601.22769", "pdf": "https://arxiv.org/pdf/2601.22769", "abs": "https://arxiv.org/abs/2601.22769", "authors": ["Lameck Mbangula Amugongo", "Tutaleni Asino", "Nicola J Bidwell"], "title": "Beyond Abstract Compliance: Operationalising trust in AI as a moral relationship", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Dominant approaches, e.g. the EU's \"Trustworthy AI framework\", treat trust as a property that can be designed for, evaluated, and governed according to normative and technical criteria. They do not address how trust is subjectively cultivated and experienced, culturally embedded, and inherently relational. This paper proposes some expanded principles for trust in AI that can be incorporated into common development methods and frame trust as a dynamic, temporal relationship, which involves transparency and mutual respect. We draw on relational ethics and, in particular, African communitarian philosophies, to foreground the nuances of inclusive, participatory processes and long-term relationships with communities. Involving communities throughout the AI lifecycle can foster meaningful relationships with AI design and development teams that incrementally build trust and promote more equitable and context-sensitive AI systems. We illustrate how trust-enabling principles based on African relational ethics can be operationalised, using two use-cases for AI: healthcare and education.", "AI": {"tldr": "探讨如何通过关系伦理和非洲社区哲学来提升人工智能中的信任。", "motivation": "现有的主流方法，如欧盟的“可信赖AI框架”，仅将信任视为一种可以设计、评估和治理的属性，未涉及主观培养、文化嵌入及内在关系性方面。论文提出扩展的信任原则以融入常见开发流程，并将信任视作动态、时间性的关系。", "method": "基于关系伦理学特别是非洲社区哲学理论来强调包容性和参与的过程以及与社群长期关系的重要性。", "result": "展示了如何通过两个具体案例（医疗和教育）实施基于非洲关系伦理的信任增强原则。", "conclusion": "建立一个将信任视为动态、时间性且文化敏感的关系模型，有助于开发更公平、更具情境适应性的AI系统。"}}
{"id": "2601.22764", "pdf": "https://arxiv.org/pdf/2601.22764", "abs": "https://arxiv.org/abs/2601.22764", "authors": ["Deepak Kumar", "Emmanouil Karystinaios", "Gerhard Widmer", "Markus Schedl"], "title": "How Far Can Pretrained LLMs Go in Symbolic Music? Controlled Comparisons of Supervised and Preference-based Adaptation", "categories": ["cs.SD", "cs.AI"], "comment": "Accepted at NLP4MusA 2026", "summary": "Music often shares notable parallels with language, motivating the use of pretrained large language models (LLMs) for symbolic music understanding and generation. Despite growing interest, the practical effectiveness of adapting instruction-tuned LLMs to symbolic music remains insufficiently characterized. We present a controlled comparative study of finetuning strategies for ABC-based generation and understanding, comparing an off-the-shelf instruction-tuned backbone to domain-adapted variants and a music-specialized LLM baseline. Across multiple symbolic music corpora and evaluation signals, we provide some insights into adaptation choices for symbolic music applications. We highlight the domain adaptation vs.~preserving prior information tradeoff as well as the distinct behaviour of metrics used to measure the domain adaptation for symbolic music.", "AI": {"tldr": "研究对比了不同适应策略在基于ABC符号音乐生成和理解中的效果，探讨预训练语言模型对符号音乐任务的适用性。", "motivation": "利用预训练的大规模语言模型（LLMs）进行符号音乐理解和生成具有潜在价值，但其实际有效性尚未充分探索。该研究旨在通过控制对比实验明确适应策略的选择及其影响。", "method": "采用了指令调优的现成模型、领域适应变体和专门针对音乐的LLM作为基准模型，在多个符号音乐语料库中进行比较测试，并评估不同指标对领域适应的影响。", "result": "研究揭示了领域适应与保持先前信息之间的权衡，以及用于衡量符号音乐任务领域的指标行为差异。", "conclusion": "研究表明，不同的适应策略在处理符号音乐时展现出不同的性能表现和特性，需要根据具体应用场景进行适当选择。"}}
{"id": "2601.22763", "pdf": "https://arxiv.org/pdf/2601.22763", "abs": "https://arxiv.org/abs/2601.22763", "authors": ["Xingwu Zhang", "Guanxuan Li", "Paul Henderson", "Gerardo Aragon-Camarasa", "Zijun Long"], "title": "Is Training Necessary for Anomaly Detection?", "categories": ["cs.CV"], "comment": null, "summary": "Current state-of-the-art multi-class unsupervised anomaly detection (MUAD) methods rely on training encoder-decoder models to reconstruct anomaly-free features. We first show these approaches have an inherent fidelity-stability dilemma in how they detect anomalies via reconstruction residuals. We then abandon the reconstruction paradigm entirely and propose Retrieval-based Anomaly Detection (RAD). RAD is a training-free approach that stores anomaly-free features in a memory and detects anomalies through multi-level retrieval, matching test patches against the memory. Experiments demonstrate that RAD achieves state-of-the-art performance across four established benchmarks (MVTec-AD, VisA, Real-IAD, 3D-ADAM) under both standard and few-shot settings. On MVTec-AD, RAD reaches 96.7\\% Pixel AUROC with just a single anomaly-free image compared to 98.5\\% of RAD's full-data performance. We further prove that retrieval-based scores theoretically upper-bound reconstruction-residual scores. Collectively, these findings overturn the assumption that MUAD requires task-specific training, showing that state-of-the-art anomaly detection is feasible with memory-based retrieval. Our code is available at https://github.com/longkukuhi/RAD.", "AI": {"tldr": "本文提出了一种基于检索的异常检测方法，该方法不依赖于训练模型来重构异常特征，而是通过存储无异常特征并进行多级检索来进行异常检测。", "motivation": "现有的多类无监督异常检测方法主要依靠训练编码器-解码器模型来重建无异常特征。然而这些方法存在固有的精度与稳定性之间的矛盾。因此作者提出一种不依赖于重构的异常检测新方案，旨在证明无需特定任务的训练也可实现高水平的异常检测。", "method": "本文提出了基于检索的异常检测（RAD）方法。该方法存储无异常样本特征并使用多级检索进行测试样本与内存中的匹配以识别异常。", "result": "实验结果表明，RAD在四个基准数据集上达到了最先进的性能，并且仅通过单个无异常图像即可达到96.7%的像素AUROC，接近满数据训练时的98.5%表现。这证明了基于检索的方法可以理论上限定重构残差分数。", "conclusion": "本文展示了不依赖于任务特定训练的多类无监督异常检测是可行的，并且通过内存中的特征检索可以达到最佳性能。"}}
{"id": "2601.22759", "pdf": "https://arxiv.org/pdf/2601.22759", "abs": "https://arxiv.org/abs/2601.22759", "authors": ["Bartosz Sawicki", "Tomasz Les", "Dariusz Parzych", "Aleksandra Wycisk-Ficek", "Pawel Trebacz", "Pawel Zawadzki"], "title": "Qualitative Evaluation of LLM-Designed GUI", "categories": ["cs.HC", "cs.AI", "cs.SE"], "comment": "12 pages, presented on conference PP-RAI 2025, Katowice-Poland", "summary": "As generative artificial intelligence advances, Large Language Models (LLMs) are being explored for automated graphical user interface (GUI) design. This study investigates the usability and adaptability of LLM-generated interfaces by analysing their ability to meet diverse user needs. The experiments included utilization of three state-of-the-art models from January 2025 (OpenAI GPT o3-mini-high, DeepSeek R1, and Anthropic Claude 3.5 Sonnet) generating mockups for three interface types: a chat system, a technical team panel, and a manager dashboard. Expert evaluations revealed that while LLMs are effective at creating structured layouts, they face challenges in meeting accessibility standards and providing interactive functionality. Further testing showed that LLMs could partially tailor interfaces for different user personas but lacked deeper contextual understanding. The results suggest that while LLMs are promising tools for early-stage UI prototyping, human intervention remains critical to ensure usability, accessibility, and user satisfaction.", "AI": {"tldr": "研究探讨了大型语言模型生成的图形用户界面在满足不同用户体验需求方面的可用性和适应性。", "motivation": "随着人工智能的发展，大型语言模型被用来自动设计图形用户界面。这项研究旨在评估这些由LLM创建的GUI是否能有效应对多样化的用户需求和标准。", "method": "实验使用了2025年一月三个最先进的模型（OpenAI GPT o3-mini-high, DeepSeek R1 和 Anthropic Claude 3.5 Sonnet）生成三种类型的界面原型：聊天系统，技术团队面板以及经理控制台。通过专家评估来测试这些界面的可用性和适应性。", "result": "结果显示LLM在创建结构化布局方面表现出色，但它们在满足无障碍标准和提供交互功能方面存在挑战。同时，虽然可以部分定制不同用户的人机界面，但仍缺乏深入的情境理解能力。", "conclusion": "研究结论是尽管大型语言模型对于早期UI原型设计很有前景，但在保证可用性、可访问性和用户体验方面仍然需要人类的干预。"}}
{"id": "2601.22758", "pdf": "https://arxiv.org/pdf/2601.22758", "abs": "https://arxiv.org/abs/2601.22758", "authors": ["Libin Qiu", "Zhirong Gao", "Junfu Chen", "Yuhang Ye", "Weizhi Huang", "Xiaobo Xue", "Wenkai Qiu", "Shuo Tang"], "title": "AutoRefine: From Trajectories to Reusable Expertise for Continual LLM Agent Refinement", "categories": ["cs.AI"], "comment": "8 pages, 3 figures, 3 tables", "summary": "Large language model agents often fail to accumulate knowledge from experience, treating each task as an independent challenge. Recent methods extract experience as flattened textual knowledge, which cannot capture procedural logic of complex subtasks. They also lack maintenance mechanisms, causing repository degradation as experience accumulates. We introduce AutoRefine, a framework that extracts and maintains dual-form Experience Patterns from agent execution histories. For procedural subtasks, we extract specialized subagents with independent reasoning and memory. For static knowledge, we extract skill patterns as guidelines or code snippets. A continuous maintenance mechanism scores, prunes, and merges patterns to prevent repository degradation. Evaluated on ALFWorld, ScienceWorld, and TravelPlanner, AutoRefine achieves 98.4%, 70.4%, and 27.1% respectively, with 20-73% step reductions. On TravelPlanner, automatic extraction exceeds manually designed systems (27.1% vs 12.1%), demonstrating its ability to capture procedural coordination.", "AI": {"tldr": "AutoRefine是一种框架，用于从代理执行历史中提取和维护双重形式的经验模式，以改进大型语言模型代理的持续细化。", "motivation": "当前的方法无法有效捕捉复杂子任务中的程序逻辑，并且缺乏维护机制导致知识库随经验积累而退化。因此，需要一种新方法来解决这些问题。", "method": "AutoRefine框架提取并维持双重形式的经验模式：对于程序性子任务，它提取具有独立推理和记忆的专门子代理；对于静态知识，它抽取技能模式作为指南或代码片段。该框架还包含一个连续维护机制对经验模式进行评分、剪枝和合并。", "result": "AutoRefine在ALFWorld, ScienceWorld和TravelPlanner上的表现分别为98.4%，70.4%和27.1%，并且与手动设计的系统相比，在TravelPlanner上自动提取效果更好（27.1％优于12.1％）。", "conclusion": "AutoRefine通过持续细化大型语言模型代理，显著提高了任务性能，并且能够捕捉程序性协调。"}}
{"id": "2601.22755", "pdf": "https://arxiv.org/pdf/2601.22755", "abs": "https://arxiv.org/abs/2601.22755", "authors": ["Xinxin Xu", "Yann Gousseau", "Christophe Kervazo", "Saïd Ladjal"], "title": "Synthetic Abundance Maps for Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images", "categories": ["eess.IV", "cs.GR", "eess.SP"], "comment": null, "summary": "Hyperspectral single image super-resolution (HS-SISR) aims to enhance the spatial resolution of hyperspectral images to fully exploit their spectral information. While considerable progress has been made in this field, most existing methods are supervised and require ground truth data for training-data that is often unavailable in practice. To overcome this limitation, we propose a novel unsupervised training framework for HS-SISR, based on synthetic abundance data. The approach begins by unmixing the hyperspectral image into endmembers and abundances. A neural network is then trained to perform abundance super-resolution using synthetic abundances only. These synthetic abundance maps are generated from a dead leaves model whose characteristics are inherited from the low-resolution image to be super-resolved. This trained network is subsequently used to enhance the spatial resolution of the original image's abundances, and the final super-resolution hyperspectral image is reconstructed by combining them with the endmembers. Experimental results demonstrate both the training value of the synthetic data and the effectiveness of the proposed method.", "AI": {"tldr": "本文提出了一种基于合成丰度数据的无监督训练框架，用于高光谱图像的超分辨率处理。", "motivation": "现有的大多数高光谱单幅图像超分辨率方法是监督式的，需要地面真值数据进行训练。然而，在实践中这类数据往往不可用，因此本研究旨在开发一种不需要此类数据即可工作的模型。", "method": "该方法首先对高光谱图像进行分解得到端元和丰度信息，然后通过合成的丰度图训练一个神经网络执行丰度超分辨率任务，并使用此网络提升原图像丰度的空间分辨率。最终的超分辨率高光谱图像由这些增强后的丰度与端元重新组合而成。", "result": "实验结果表明了生成的合成数据在训练中的价值以及该方法的有效性。", "conclusion": "所提出的方法提供了一种无需地面真值数据即可进行高光谱单幅图像超分辨率处理的新途径，证明了其可行性和有效性。"}}
{"id": "2601.22754", "pdf": "https://arxiv.org/pdf/2601.22754", "abs": "https://arxiv.org/abs/2601.22754", "authors": ["Guillermo Gil de Avalle", "Laura Maruster", "Christos Emmanouilidis"], "title": "Procedural Knowledge Extraction from Industrial Troubleshooting Guides Using Vision Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Industrial troubleshooting guides encode diagnostic procedures in flowchart-like diagrams where spatial layout and technical language jointly convey meaning. To integrate this knowledge into operator support systems, which assist shop-floor personnel in diagnosing and resolving equipment issues, the information must first be extracted and structured for machine interpretation. However, when performed manually, this extraction is labor-intensive and error-prone. Vision Language Models offer potential to automate this process by jointly interpreting visual and textual meaning, yet their performance on such guides remains underexplored. This paper evaluates two VLMs on extracting structured knowledge, comparing two prompting strategies: standard instruction-guided versus an augmented approach that cues troubleshooting layout patterns. Results reveal model-specific trade-offs between layout sensitivity and semantic robustness, informing practical deployment decisions.", "AI": {"tldr": "利用视觉语言模型从工业故障排除指南中提取结构化的知识。", "motivation": "手动提取和整理故障排除指南中的信息既耗时又容易出错，因此需要一种自动化的方法来提高效率。", "method": "评估两种视觉语言模型在提示策略（标准指令引导与增强版布局模式提示）下的性能表现。", "result": "结果显示了不同模型之间在布局敏感度和语义稳健性上的权衡情况。", "conclusion": "研究结果为实际应用中选择合适的视觉语言模型提供了指导。"}}
{"id": "2601.22746", "pdf": "https://arxiv.org/pdf/2601.22746", "abs": "https://arxiv.org/abs/2601.22746", "authors": ["Pingping Liu", "Jiamiao Liu", "Zijian Zhang", "Hao Miao", "Qi Jiang", "Qingliang Li", "Qiuzhan Zhou", "Irwin King"], "title": "UrbanMoE: A Sparse Multi-Modal Mixture-of-Experts Framework for Multi-Task Urban Region Profiling", "categories": ["cs.ET", "cs.AI"], "comment": "12 pages, 6 figures, 5tables, Proceedings of the ACM Web Conference 2026 (WWW '26), April 13--17, 2026, Dubai, United Arab Emirates", "summary": "Urban region profiling, the task of characterizing geographical areas, is crucial for urban planning and resource allocation. However, existing research in this domain faces two significant limitations. First, most methods are confined to single-task prediction, failing to capture the interconnected, multi-faceted nature of urban environments where numerous indicators are deeply correlated. Second, the field lacks a standardized experimental benchmark, which severely impedes fair comparison and reproducible progress. To address these challenges, we first establish a comprehensive benchmark for multi-task urban region profiling, featuring multi-modal features and a diverse set of strong baselines to ensure a fair and rigorous evaluation environment. Concurrently, we propose UrbanMoE, the first sparse multi-modal, multi-expert framework specifically architected to solve the multi-task challenge. Leveraging a sparse Mixture-of-Experts architecture, it dynamically routes multi-modal features to specialized sub-networks, enabling the simultaneous prediction of diverse urban indicators. We conduct extensive experiments on three real-world datasets within our benchmark, where UrbanMoE consistently demonstrates superior performance over all baselines. Further in-depth analysis validates the efficacy and efficiency of our approach, setting a new state-of-the-art and providing the community with a valuable tool for future research in urban analytics", "AI": {"tldr": "提出UrbanMoE框架，用于多任务城市区域特征预测", "motivation": "解决现有方法局限于单一任务和缺乏标准化实验基准的问题", "method": "建立综合基准并提出UrbanMoE，使用稀疏的Mixture-of-Experts架构动态路由多模态特性到专业化子网络", "result": "在三个真实世界数据集上优于所有基线模型", "conclusion": "UrbanMoE实现高效准确的城市区域特征预测"}}
{"id": "2601.22744", "pdf": "https://arxiv.org/pdf/2601.22744", "abs": "https://arxiv.org/abs/2601.22744", "authors": ["Yilong Huang", "Songze Li"], "title": "Beauty and the Beast: Imperceptible Perturbations Against Diffusion-Based Face Swapping via Directional Attribute Editing", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": null, "summary": "Diffusion-based face swapping achieves state-of-the-art performance, yet it also exacerbates the potential harm of malicious face swapping to violate portraiture right or undermine personal reputation. This has spurred the development of proactive defense methods. However, existing approaches face a core trade-off: large perturbations distort facial structures, while small ones weaken protection effectiveness. To address these issues, we propose FaceDefense, an enhanced proactive defense framework against diffusion-based face swapping. Our method introduces a new diffusion loss to strengthen the defensive efficacy of adversarial examples, and employs a directional facial attribute editing to restore perturbation-induced distortions, thereby enhancing visual imperceptibility. A two-phase alternating optimization strategy is designed to generate final perturbed face images. Extensive experiments show that FaceDefense significantly outperforms existing methods in both imperceptibility and defense effectiveness, achieving a superior trade-off.", "AI": {"tldr": "提出了一种增强的防御框架FaceDefense，用于对抗基于扩散的脸部交换。", "motivation": "现有的面部交换防御方法存在核心权衡：大的扰动会破坏面部结构，而小的扰动则削弱了保护效果。为解决这些问题提出了新的解决方案。", "method": "引入一个新的扩散损失来增强对抗样本的防护效用，并采用方向性面部属性编辑以修复因扰动造成的变形，从而提高视觉不可察觉性。设计了一种两阶段交替优化策略生成最终的扰动脸部图像。", "result": "FaceDefense在不可见性和防御有效性上显著优于现有方法，在权衡方面表现优异。", "conclusion": "通过引入新的扩散损失和方向性面部属性编辑，FaceDefense可以更有效地对抗基于扩散的脸部交换，并保持良好的视觉质量。"}}
{"id": "2601.22738", "pdf": "https://arxiv.org/pdf/2601.22738", "abs": "https://arxiv.org/abs/2601.22738", "authors": ["Han Wang", "Deyi Ji", "Lanyun Zhu", "Jiebo Luo", "Roy Ka-Wei Lee"], "title": "StreamSense: Streaming Social Task Detection with Selective Vision-Language Model Routing", "categories": ["cs.CV"], "comment": "10 pages, 4 figures, The Web Conference 2026", "summary": "Live streaming platforms require real-time monitoring and reaction to social signals, utilizing partial and asynchronous evidence from video, text, and audio. We propose StreamSense, a streaming detector that couples a lightweight streaming encoder with selective routing to a Vision-Language Model (VLM) expert. StreamSense handles most timestamps with the lightweight streaming encoder, escalates hard/ambiguous cases to the VLM, and defers decisions when context is insufficient. The encoder is trained using (i) a cross-modal contrastive term to align visual/audio cues with textual signals, and (ii) an IoU-weighted loss that down-weights poorly overlapping target segments, mitigating label interference across segment boundaries. We evaluate StreamSense on multiple social streaming detection tasks (e.g., sentiment classification and hate content moderation), and the results show that StreamSense achieves higher accuracy than VLM-only streaming while only occasionally invoking the VLM, thereby reducing average latency and compute. Our results indicate that selective escalation and deferral are effective primitives for understanding streaming social tasks. Code is publicly available on GitHub.", "AI": {"tldr": "本文提出了StreamSense，一种结合轻量级流式编码器和选择性路由到Vision-Language Model (VLM)的实时社交信号检测系统。", "motivation": "直播平台需要实时监测并响应视频、文本和音频中的社交信号。现有的解决方案计算成本高且延迟大，因此本文旨在提供一个更高效的方法。", "method": "StreamSense通过轻量级流式编码器处理大部分时间戳，并将难以判断或含糊不清的情况路由给VLM专家进行进一步分析，当上下文不足时则推迟决策。", "result": "在多个社交信号检测任务中，StreamSense的准确率高于仅使用VLM的方法，同时减少了平均延迟和计算量。", "conclusion": "选择性升级和延迟是理解流媒体社会任务的有效方法。"}}
{"id": "2601.22737", "pdf": "https://arxiv.org/pdf/2601.22737", "abs": "https://arxiv.org/abs/2601.22737", "authors": ["Enyi Shi", "Pengyang Shao", "Yanxin Zhang", "Chenhang Cui", "Jiayi Lyu", "Xu Xie", "Xiaobo Xia", "Fei Shen", "Tat-Seng Chua"], "title": "Lingua-SafetyBench: A Benchmark for Safety Evaluation of Multilingual Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Robust safety of vision-language large models (VLLMs) under joint multilingual and multimodal inputs remains underexplored. Existing benchmarks are typically multilingual but text-only, or multimodal but monolingual. Recent multilingual multimodal red-teaming efforts render harmful prompts into images, yet rely heavily on typography-style visuals and lack semantically grounded image-text pairs, limiting coverage of realistic cross-modal interactions. We introduce Lingua-SafetyBench, a benchmark of 100,440 harmful image-text pairs across 10 languages, explicitly partitioned into image-dominant and text-dominant subsets to disentangle risk sources. Evaluating 11 open-source VLLMs reveals a consistent asymmetry: image-dominant risks yield higher ASR in high-resource languages, while text-dominant risks are more severe in non-high-resource languages. A controlled study on the Qwen series shows that scaling and version upgrades reduce Attack Success Rate (ASR) overall but disproportionately benefit HRLs, widening the gap between HRLs and Non-HRLs under text-dominant risks. This underscores the necessity of language- and modality-aware safety alignment beyond mere scaling.To facilitate reproducibility and future research, we will publicly release our benchmark, model checkpoints, and source code.The code and dataset will be available at https://github.com/zsxr15/Lingua-SafetyBench.Warning: this paper contains examples with unsafe content.", "AI": {"tldr": "提出了Lingua-SafetyBench，一个用于评估多语言视觉语言模型安全性的基准，包含跨10种语言的100440个有害图像-文本对。", "motivation": "现有的评估基准要么是单一模态但多种语言，要么是多媒体但单一语言。需要一个既能涵盖图像又能涉及文本的安全性评估方法，并且能够区分风险来源。", "method": "构建了一个包含100,440个有害图像-文本对的Lingua-SafetyBench基准，将其分为以图像为主和以文本为主的两个子集，评估了多种开源VLLM模型的表现并进行了控制实验。", "result": "展示了在不同语言下，图像主导的风险导致高资源语言中的攻击成功率更高；而文本主导的风险则对非高资源语言更加严重。此外，规模扩大和版本升级可以降低整体的攻击成功率，但这种改善更多地体现在高资源语言中。", "conclusion": "强调了在多语言和多媒体背景下进行安全性校准时考虑语言和模态的重要性，表明仅仅通过扩展模型并不能解决所有问题，还需要针对不同场景采取专门的安全措施。"}}
{"id": "2601.22736", "pdf": "https://arxiv.org/pdf/2601.22736", "abs": "https://arxiv.org/abs/2601.22736", "authors": ["Md Musfiqur Rahman", "Ziwei Jiang", "Hilaf Hasson", "Murat Kocaoglu"], "title": "Decomposing Epistemic Uncertainty for Causal Decision Making", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Causal inference from observational data provides strong evidence for the best action in decision-making without performing expensive randomized trials. The effect of an action is usually not identifiable under unobserved confounding, even with an infinite amount of data. Recent work uses neural networks to obtain practical bounds to such causal effects, which is often an intractable problem. However, these approaches may overfit to the dataset and be overconfident in their causal effect estimates. Moreover, there is currently no systematic approach to disentangle how much of the width of causal effect bounds is due to fundamental non-identifiability versus how much is due to finite-sample limitations. We propose a novel framework to address this problem by considering a confidence set around the empirical observational distribution and obtaining the intersection of causal effect bounds for all distributions in this confidence set. This allows us to distinguish the part of the interval that can be reduced by collecting more samples, which we call sample uncertainty, from the part that can only be reduced by observing more variables, such as latent confounders or instrumental variables, but not with more data, which we call non-ID uncertainty. The upper and lower bounds to this intersection are obtained by solving min-max and max-min problems with neural causal models by searching over all distributions that the dataset might have been sampled from, and all SCMs that entail the corresponding distribution. We demonstrate via extensive experiments on synthetic and real-world datasets that our algorithm can determine when collecting more samples will not help determine the best action. This can guide practitioners to collect more variables or lean towards a randomized study for best action identification.", "AI": {"tldr": "提出了一种新的框架，用于区分因果效应估计中的样本不确定性与非识别不确定性。", "motivation": "当前的神经网络方法可能过度拟合数据并且对其因果效应估计过于自信。缺乏系统的方法来区分宽度是由于不可观测混淆还是有限样本限制所导致的问题。", "method": "通过考虑围绕经验观察分布的置信集并获取所有这些分布的因果效果界限交集，提出了新的框架。使用神经因果模型解决最小最大和最大最小问题以搜索所有可能的数据集和潜在的因果模型。", "result": "在合成数据和真实世界数据上进行了广泛的实验表明该算法可以确定何时收集更多样本不会帮助确定最佳行动。", "conclusion": "通过区分样本不确定性和非识别不确定性，为决策者提供了指导，在决定是否需要更多的变量或转向随机研究以确定最佳行动时具有重要意义。"}}
{"id": "2601.22732", "pdf": "https://arxiv.org/pdf/2601.22732", "abs": "https://arxiv.org/abs/2601.22732", "authors": ["Hung-Chih Tu", "Bo-Syun Chen", "Yun-Chien Cheng"], "title": "Active Learning-Driven Lightweight YOLOv9: Enhancing Efficiency in Smart Agriculture", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "This study addresses the demand for real-time detection of tomatoes and tomato flowers by agricultural robots deployed on edge devices in greenhouse environments. Under practical imaging conditions, object detection systems often face challenges such as large scale variations caused by varying camera distances, severe occlusion from plant structures, and highly imbalanced class distributions. These factors make conventional object detection approaches that rely on fully annotated datasets difficult to simultaneously achieve high detection accuracy and deployment efficiency. To overcome these limitations, this research proposes an active learning driven lightweight object detection framework, integrating data analysis, model design, and training strategy. First, the size distribution of objects in raw agricultural images is analyzed to redefine an operational target range, thereby improving learning stability under real-world conditions. Second, an efficient feature extraction module is incorporated to reduce computational cost, while a lightweight attention mechanism is introduced to enhance feature representation under multi-scale and occluded scenarios. Finally, an active learning strategy is employed to iteratively select high-information samples for annotation and training under a limited labeling budget, effectively improving the recognition performance of minority and small-object categories. Experimental results demonstrate that, while maintaining a low parameter count and inference cost suitable for edge-device deployment, the proposed method effectively improves the detection performance of tomatoes and tomato flowers in raw images. Under limited annotation conditions, the framework achieves an overall detection accuracy of 67.8% mAP, validating its practicality and feasibility for intelligent agricultural applications.", "AI": {"tldr": "该研究提出了一种基于主动学习的轻量级YOLOv9框架，旨在提高农业机器人在温室环境中实时检测番茄和番茄花的效率。", "motivation": "针对农业生产中相机距离变化大、植物结构遮挡严重及类别分布不平衡等问题导致的传统目标检测方法难以同时实现高精度与高效部署的问题，研究提出了一种新的轻量化检测框架以应对这些挑战。", "method": "首先重新定义了操作目标范围以提升模型在实际环境中的学习稳定性；其次引入高效的特征提取模块和轻量级注意力机制来减少计算成本并增强多尺度遮挡情况下的特征表现力；最后通过主动学习策略迭代选择高信息样本进行标注与训练，提高少数类别及小目标类别的识别性能。", "result": "实验表明，在保持低参数数量和推断成本的同时，该方法显著提高了番茄和番茄花的检测精度。在有限标签条件下，整体检测准确率达到67.8%mAP。", "conclusion": "所提出的基于主动学习的轻量化框架有效解决了智能农业应用中目标检测的挑战，并验证了其实际可行性和有效性"}}
{"id": "2601.22730", "pdf": "https://arxiv.org/pdf/2601.22730", "abs": "https://arxiv.org/abs/2601.22730", "authors": ["Xiaoshu Chen", "Sihang Zhou", "Ke Liang", "Taichun Zhou", "Xinwang Liu"], "title": "ImgCoT: Compressing Long Chain of Thought into Compact Visual Tokens for Efficient Reasoning of Large Language Model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Compressing long chains of thought (CoT) into compact latent tokens is crucial for efficient reasoning with large language models (LLMs). Recent studies employ autoencoders to achieve this by reconstructing textual CoT from latent tokens, thus encoding CoT semantics. However, treating textual CoT as the reconstruction target forces latent tokens to preserve surface-level linguistic features (e.g., word choice and syntax), introducing a strong linguistic inductive bias that prioritizes linguistic form over reasoning structure and limits logical abstraction. Thus, we propose ImgCoT that replaces the reconstruction target from textual CoT to the visual CoT obtained by rendering CoT into images. This substitutes linguistic bias with spatial inductive bias, i.e., a tendency to model spatial layouts of the reasoning steps in visual CoT, enabling latent tokens to better capture global reasoning structure. Moreover, although visual latent tokens encode abstract reasoning structure, they may blur reasoning details. We thus propose a loose ImgCoT, a hybrid reasoning that augments visual latent tokens with a few key textual reasoning steps, selected based on low token log-likelihood. This design allows LLMs to retain both global reasoning structure and fine-grained reasoning details with fewer tokens than the complete CoT. Extensive experiments across multiple datasets and LLMs demonstrate the effectiveness of the two versions of ImgCoT.", "AI": {"tldr": "将长链思维过程压缩为紧凑的视觉标记以提高大规模语言模型的推理效率。", "motivation": "现有方法通过文本重建引入了较强的语义偏差，限制了逻辑抽象能力。因此，提出ImgCoT用视觉表示代替文本进行重构。", "method": "首先使用图像化处理得到视觉思维链，然后利用基于空间布局的归纳偏置来学习全局结构；并引入松散版ImgCoT加入关键步骤以保留细节。", "result": "实验显示ImgCoT及其松散版本在多个数据集和模型上均有效提高效率。", "conclusion": "ImgCoT通过视觉化处理改进了思维过程压缩，使大规模语言模型更高效地进行推理。"}}
{"id": "2601.22729", "pdf": "https://arxiv.org/pdf/2601.22729", "abs": "https://arxiv.org/abs/2601.22729", "authors": ["A. Enes Doruk", "Hasan F. Ates"], "title": "GaussianOcc3D: A Gaussian-Based Adaptive Multi-modal 3D Occupancy Prediction", "categories": ["cs.CV"], "comment": null, "summary": "3D semantic occupancy prediction is a pivotal task in autonomous driving, providing a dense and fine-grained understanding of the surrounding environment, yet single-modality methods face trade-offs between camera semantics and LiDAR geometry. Existing multi-modal frameworks often struggle with modality heterogeneity, spatial misalignment, and the representation crisis--where voxels are computationally heavy and BEV alternatives are lossy. We present GaussianOcc3D, a multi-modal framework bridging camera and LiDAR through a memory-efficient, continuous 3D Gaussian representation. We introduce four modules: (1) LiDAR Depth Feature Aggregation (LDFA), using depth-wise deformable sampling to lift sparse signals onto Gaussian primitives; (2) Entropy-Based Feature Smoothing (EBFS) to mitigate domain noise; (3) Adaptive Camera-LiDAR Fusion (ACLF) with uncertainty-aware reweighting for sensor reliability; and (4) a Gauss-Mamba Head leveraging Selective State Space Models for global context with linear complexity. Evaluations on Occ3D, SurroundOcc, and SemanticKITTI benchmarks demonstrate state-of-the-art performance, achieving mIoU scores of 49.4%, 28.9%, and 25.2% respectively. GaussianOcc3D exhibits superior robustness across challenging rainy and nighttime conditions.", "AI": {"tldr": "提出了一种基于高斯的多模态3D占用预测框架GaussianOcc3D，解决了相机和LiDAR数据融合中的问题，实现了更好的性能。", "motivation": "现有的单模态方法在语义理解和几何表示之间存在权衡；多模态框架面临异质性、空间对齐和表示危机的问题。因此需要一种新的解决方案来提高自动驾驶环境中三维占用预测的精度。", "method": "通过LiDAR深度特征聚合模块（LDFA）、基于熵的特征平滑模块（EBFS）、自适应相机-LiDAR融合模块（ACLF）以及Gauss-Mamba头，使用高斯表示实现高效的多模态数据融合和处理。", "result": "在Occ3D、SurroundOcc和SemanticKITTI基准测试中，该方法分别取得了49.4%、28.9%和25.2%的mIoU评分，并且展示了对恶劣天气条件的强大鲁棒性。", "conclusion": "GaussianOcc3D通过创新的方法解决了多模态数据融合中的挑战，在多个数据集上表现出色，证明了在自动驾驶领域的实用性和先进性。"}}
{"id": "2601.22725", "pdf": "https://arxiv.org/pdf/2601.22725", "abs": "https://arxiv.org/abs/2601.22725", "authors": ["Jin Li", "Tao Chen", "Shuai Jiang", "Weijie Wang", "Jingwen Luo", "Chenhui Wu"], "title": "OpenVTON-Bench: A Large-Scale High-Resolution Benchmark for Controllable Virtual Try-On Evaluation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in diffusion models have significantly elevated the visual fidelity of Virtual Try-On (VTON) systems, yet reliable evaluation remains a persistent bottleneck. Traditional metrics struggle to quantify fine-grained texture details and semantic consistency, while existing datasets fail to meet commercial standards in scale and diversity. We present OpenVTON-Bench, a large-scale benchmark comprising approximately 100K high-resolution image pairs (up to $1536 \\times 1536$). The dataset is constructed using DINOv3-based hierarchical clustering for semantically balanced sampling and Gemini-powered dense captioning, ensuring a uniform distribution across 20 fine-grained garment categories. To support reliable evaluation, we propose a multi-modal protocol that measures VTON quality along five interpretable dimensions: background consistency, identity fidelity, texture fidelity, shape plausibility, and overall realism. The protocol integrates VLM-based semantic reasoning with a novel Multi-Scale Representation Metric based on SAM3 segmentation and morphological erosion, enabling the separation of boundary alignment errors from internal texture artifacts. Experimental results show strong agreement with human judgments (Kendall's $τ$ of 0.833 vs. 0.611 for SSIM), establishing a robust benchmark for VTON evaluation.", "AI": {"tldr": "构建了一个大规模高分辨率虚拟试衣评估基准，包括图像对和多模态评估协议。", "motivation": "现有指标难以量化细粒度纹理细节及语义一致性，而现有数据集无法满足商业标准的规模与多样性。", "method": "利用DINOv3进行层次聚类以平衡采样，并用Gemini生成密集描述；提出多模态评估协议，结合VLM语义推理和基于SAM3分割的新指标。", "result": "实验结果显示其评价结果与人工判断高度一致（Kendall's τ为0.833）。", "conclusion": "建立了强大的虚拟试衣评估基准，可有效分离边界对齐错误和内部纹理瑕疵。"}}
{"id": "2601.22723", "pdf": "https://arxiv.org/pdf/2601.22723", "abs": "https://arxiv.org/abs/2601.22723", "authors": ["Chengchun Liu", "Wendi Cai", "Boxuan Zhao", "Fanyang Mo"], "title": "A Cross-Domain Graph Learning Protocol for Single-Step Molecular Geometry Refinement", "categories": ["physics.chem-ph", "cs.AI", "physics.atm-clus"], "comment": "17 pages, 6 figures", "summary": "Accurate molecular geometries are a prerequisite for reliable quantum-chemical predictions, yet density functional theory (DFT) optimization remains a major bottleneck for high-throughput molecular screening. Here we present GeoOpt-Net, a multi-branch SE(3)-equivariant geometry refinement network that predicts DFT-quality structures at the B3LYP/TZVP level of theory in a single forward pass starting from inexpensive initial conformers generated at a low-cost force-field level. GeoOpt-Net is trained using a two-stage strategy in which a broadly pretrained geometric representation is subsequently fine-tuned to approach B3LYP/TZVP-level accuracy, with theory- and basis-set-aware calibration enabled by a fidelity-aware feature modulation (FAFM) mechanism. Benchmarking against representative approaches spanning classical conformer generation (RDKit), semiempirical quantum methods (xTB), data-driven geometry refinement pipelines (Auto3D), and machine-learning interatomic potentials (UMA) on external drug-like molecules demonstrates that GeoOpt-Net achieves sub-milli-Å all-atom RMSD with near-zero B3LYP/TZVP single-point energy deviations, indicating DFT-ready geometries that closely reproduce both structural and energetic references. Beyond geometric metrics, GeoOpt-Net generates initial guesses intrinsically compatible with DFT convergence criteria, yielding nonzero ``All-YES'' convergence rates (65.0\\% under loose and 33.4\\% under default thresholds), and substantially reducing re-optimization steps and wall-clock time. GeoOpt-Net further exhibits smooth and predictable energy scaling with molecular complexity while preserving key electronic observables such as dipole moments. Collectively, these results establish GeoOpt-Net as a scalable, physically consistent geometry refinement framework that enables efficient acceleration of DFT-based quantum-chemical workflows.", "AI": {"tldr": "提出了一种名为GeoOpt-Net的多分支SE(3)等变几何优化网络，用于预测密度泛函理论（DFT）级准确性的分子结构。", "motivation": "密度泛函理论优化是高通量分子筛选的主要瓶颈。需要一种高效且准确的方法来生成接近DFT级别的分子几何结构。", "method": "GeoOpt-Net通过两阶段训练策略，首先使用广义预训练的几何表示进行微调，并利用保真度感知特征调节机制实现对理论和基集的校准。", "result": "在基准测试中，GeoOpt-Net实现了亚毫埃级别的原子均方根偏差（RMSD），并且单点能量偏差接近零。此外，它生成初始构型与DFT收敛标准兼容，并显著减少了重新优化步骤和实际运行时间。", "conclusion": "GeoOpt-Net作为一种可扩展、物理一致的几何优化框架，能够有效加速基于密度泛函理论的量子化学工作流程。"}}
{"id": "2601.22720", "pdf": "https://arxiv.org/pdf/2601.22720", "abs": "https://arxiv.org/abs/2601.22720", "authors": ["Ivan K. Tung", "Yu Xiang Shi", "Alex Chien", "Wenkai Liu", "Lawrence Zheng"], "title": "AEGIS: White-Box Attack Path Generation using LLMs and Training Effectiveness Evaluation for Large-Scale Cyber Defence Exercises", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Creating attack paths for cyber defence exercises requires substantial expert effort. Existing automation requires vulnerability graphs or exploit sets curated in advance, limiting where it can be applied. We present AEGIS, a system that generates attack paths using LLMs, white-box access, and Monte Carlo Tree Search over real exploit execution. LLM-based search discovers exploits dynamically without pre-existing vulnerability graphs, while white-box access enables validating exploits in isolation before committing to attack paths. Evaluation at CIDeX 2025, a large-scale exercise spanning 46 IT hosts, showed that AEGIS-generated paths are comparable to human-authored scenarios across four dimensions of training experience (perceived learning, engagement, believability, challenge). Results were measured with a validated questionnaire extensible to general simulation-based training. By automating exploit chain discovery and validation, AEGIS reduces scenario development from months to days, shifting expert effort from technical validation to scenario design.", "AI": {"tldr": "AEGIS使用大型语言模型和蒙特卡洛树搜索生成攻击路径，通过白盒访问验证孤立的漏洞利用。", "motivation": "现有自动化系统依赖预编译的漏洞图或漏洞集，限制了应用范围。为了减少专家的工作量并提高大规模网络防御演习中的训练效果，提出了AEGIS系统。", "method": "AEGIS结合大型语言模型和白盒访问，通过蒙特卡洛树搜索动态发现新的攻击路径，并在实际环境中验证这些漏洞利用的有效性。", "result": "在CIDeX2025演习中，评估显示由AEGIS生成的攻击路径与人工编写的场景一样有效，涵盖了学习体验、参与度、可信度和挑战性四个维度。通过自动化发现和验证攻击链，将情景开发时间从几个月缩短到几天。", "conclusion": "AEGIS不仅提高了网络防御演习中训练效果的质量，还大幅减少了专家在技术验证上的工作量，使他们能够更好地投入到情景设计中去。"}}
{"id": "2601.22718", "pdf": "https://arxiv.org/pdf/2601.22718", "abs": "https://arxiv.org/abs/2601.22718", "authors": ["Shiye Lei", "Zhihao Cheng", "Dacheng Tao"], "title": "A Step Back: Prefix Importance Ratio Stabilizes Policy Optimization", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) post-training has increasingly demonstrated strong ability to elicit reasoning behaviors in large language models (LLMs). For training efficiency, rollouts are typically generated in an off-policy manner using an older sampling policy and then used to update the current target policy. To correct the resulting discrepancy between the sampling and target policies, most existing RL objectives rely on a token-level importance sampling ratio, primarily due to its computational simplicity and numerical stability. However, we observe that token-level correction often leads to unstable training dynamics when the degree of off-policyness is large. In this paper, we revisit LLM policy optimization under off-policy conditions and show that the theoretically rigorous correction term is the prefix importance ratio, and that relaxing it to a token-level approximation can induce instability in RL post-training. To stabilize LLM optimization under large off-policy drift, we propose a simple yet effective objective, Minimum Prefix Ratio (MinPRO). MinPRO replaces the unstable cumulative prefix ratio with a non-cumulative surrogate based on the minimum token-level ratio observed in the preceding prefix. Extensive experiments on both dense and mixture-of-experts LLMs, across multiple mathematical reasoning benchmarks, demonstrate that MinPRO substantially improves training stability and peak performance in off-policy regimes.", "AI": {"tldr": "本文研究了在大型语言模型的强化学习后期训练中，由于离策略采样导致的不稳定性问题，并提出了一种新的目标函数Minimum Prefix Ratio (MinPRO)来提高训练稳定性和性能。", "motivation": "现有RL目标通常依赖于逐令牌的重要性抽样比率进行校正，但在高程度的离策略行为时会导致训练不稳定。因此，本文旨在解决这一问题并改善LLM后期强化学习中的优化。", "method": "提出了一个简单的MinPRO方法，通过最小化前缀上的令牌级比率代替累积前缀比率来稳定LLM在大规模离策略漂移下的优化。", "result": "实验表明，在密集型和专家混合的大型语言模型上使用MinPRO可以显著提高训练稳定性以及峰值性能。", "conclusion": "MinPRO解决了由于大量离策略样本导致的强化学习后期不稳定问题，并展示了其改善训练效果的能力。"}}
{"id": "2601.22716", "pdf": "https://arxiv.org/pdf/2601.22716", "abs": "https://arxiv.org/abs/2601.22716", "authors": ["Pingzhi Tang", "Ruijie Zhou", "Fanxu Meng", "Wenjie Pei", "Muhan Zhang"], "title": "Breaking the Blocks: Continuous Low-Rank Decomposed Scaling for Unified LLM Quantization and Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current quantization methods for LLMs predominantly rely on block-wise structures to maintain efficiency, often at the cost of representational flexibility. In this work, we demonstrate that element-wise quantization can be made as efficient as block-wise scaling while providing strictly superior expressive power by modeling the scaling manifold as continuous low-rank matrices ($S = BA$). We propose Low-Rank Decomposed Scaling (LoRDS), a unified framework that rethinks quantization granularity through this low-rank decomposition. By \"breaking the blocks\" of spatial constraints, LoRDS establishes a seamless efficiency lifecycle: it provides high-fidelity PTQ initialization refined via iterative optimization, enables joint QAT of weights and scaling factors, and facilitates high-rank multiplicative PEFT adaptation. Unlike additive PEFT approaches such as QLoRA, LoRDS enables high-rank weight updates within a low-rank budget while incurring no additional inference overhead. Supported by highly optimized Triton kernels, LoRDS consistently outperforms state-of-the-art baselines across various model families in both quantization and downstream fine-tuning tasks. Notably, on Llama3-8B, our method achieves up to a 27.0% accuracy improvement at 3 bits over NormalFloat quantization and delivers a 1.5x inference speedup on NVIDIA RTX 4090 while enhancing PEFT performance by 9.6% on downstream tasks over 4bit QLoRA, offering a robust and integrated solution for unified compression and adaptation of LLMs.", "AI": {"tldr": "本文提出了一种新的低秩分解缩放框架（LoRDS），用于统一LLM的量化和适应，通过打破区块结构限制，实现了高效且具有表达力的量化方法。", "motivation": "当前LLM的量化方法主要依赖于区块结构来保持效率，但会牺牲表示灵活性。本文旨在展示如何通过连续低秩矩阵建模实现高效的元素级量化，并提供更优的表达能力。", "method": "提出LoRDS框架，采用低秩分解缩放（$S = BA$）以打破空间约束限制，统一量化颗粒度并优化权重和缩放因子。此外，LoRDS支持高效推理且无需额外开销。", "result": "实验表明，LoRDS在多种模型家族中优于现有基线方法，在Llama3-8B上实现了最高27.0%的精度改进，并提高了1.5倍的推理速度和9.6％的PEFT性能。", "conclusion": "LoRDS提供了一种高效统一的LLM压缩和适应方案，能够实现高性能量化及下游任务优化。"}}
{"id": "2601.22714", "pdf": "https://arxiv.org/pdf/2601.22714", "abs": "https://arxiv.org/abs/2601.22714", "authors": ["Alexander Nikulin", "Ilya Zisman", "Albina Klepach", "Denis Tarasov", "Alexander Derevyagin", "Andrei Polubarov", "Lyubaykin Nikita", "Vladislav Kurenkov"], "title": "Vision-Language Models Unlock Task-Centric Latent Actions", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Preprint", "summary": "Latent Action Models (LAMs) have rapidly gained traction as an important component in the pre-training pipelines of leading Vision-Language-Action models. However, they fail when observations contain action-correlated distractors, often encoding noise instead of meaningful latent actions. Humans, on the other hand, can effortlessly distinguish task-relevant motions from irrelevant details in any video given only a brief task description. In this work, we propose to utilize the common-sense reasoning abilities of Vision-Language Models (VLMs) to provide promptable representations, effectively separating controllable changes from the noise in unsupervised way. We use these representations as targets during LAM training and benchmark a wide variety of popular VLMs, revealing substantial variation in the quality of promptable representations as well as their robustness to different prompts and hyperparameters. Interestingly, we find that more recent VLMs may perform worse than older ones. Finally, we show that simply asking VLMs to ignore distractors can substantially improve latent action quality, yielding up to a six-fold increase in downstream success rates on Distracting MetaWorld.", "AI": {"tldr": "利用视觉语言模型的常识推理能力，提出了一种在无监督方式下分离可控变化和噪声的方法，以提高潜在动作的质量。", "motivation": "现有Latent Action Models（LAMs）在处理包含动作相关干扰因素的数据时表现不佳。作者希望通过结合Vision-Language Models(VLMs)的能力来区分任务相关的动作和无关细节，从而解决这个问题。", "method": "利用VLMs生成的可提示表示作为目标，在无监督方式下进行LAM训练，并对多种流行的VLMs进行了基准测试，发现它们在不同提示和超参数下的表现存在显著差异。进一步展示了简单地让VLM忽略干扰因素可以大大提高潜在动作的质量。", "result": "实验结果显示，所提出的方法能够有效提高下游任务的成功率，在Distracting MetaWorld数据集上实现了最多六倍的提升。", "conclusion": "通过将视觉语言模型与Latent Action Models相结合，作者成功地提高了在处理包含干扰因素的数据时的质量。这表明了常识推理能力对于改进LAMs的重要性，并且揭示了更近期的语言模型可能不如较早的模型表现好这一有趣的现象。"}}
{"id": "2601.22711", "pdf": "https://arxiv.org/pdf/2601.22711", "abs": "https://arxiv.org/abs/2601.22711", "authors": ["Matteo Gambella", "Fabrizio Pittorino", "Giuliano Casale", "Manuel Roveri"], "title": "SQUAD: Scalable Quorum Adaptive Decisions via ensemble of early exit neural networks", "categories": ["cs.LG", "cs.CV", "cs.DC"], "comment": ":68T07", "summary": "Early-exit neural networks have become popular for reducing inference latency by allowing intermediate predictions when sufficient confidence is achieved. However, standard approaches typically rely on single-model confidence thresholds, which are frequently unreliable due to inherent calibration issues. To address this, we introduce SQUAD (Scalable Quorum Adaptive Decisions), the first inference scheme that integrates early-exit mechanisms with distributed ensemble learning, improving uncertainty estimation while reducing the inference time. Unlike traditional methods that depend on individual confidence scores, SQUAD employs a quorum-based stopping criterion on early-exit learners by collecting intermediate predictions incrementally in order of computational complexity until a consensus is reached and halting the computation at that exit if the consensus is statistically significant. To maximize the efficacy of this voting mechanism, we also introduce QUEST (Quorum Search Technique), a Neural Architecture Search method to select early-exit learners with optimized hierarchical diversity, ensuring learners are complementary at every intermediate layer. This consensus-driven approach yields statistically robust early exits, improving the test accuracy up to 5.95% compared to state-of-the-art dynamic solutions with a comparable computational cost and reducing the inference latency up to 70.60% compared to static ensembles while maintaining a good accuracy.", "AI": {"tldr": "SQUAD是一种通过分布式集成学习整合早期退出机制的推理方案，旨在改善不确定性估计并减少推断时间。", "motivation": "传统的单一模型信心阈值方法由于校准问题往往不可靠，因此提出了结合分布式集成学习和早期退出机制的SQUAD方案来解决这一问题。", "method": "SQUAD采用了基于群体投票的停止标准，在按照计算复杂度顺序收集中间预测直到达到统计显著的一致性后停止计算。同时引入了QUEST方法以优化早期退出学习者的层级多样性，确保每个中间层次的学习者互补。", "result": "与最先进的动态方案相比，测试准确率提高了5.95%，并且与静态集成相比减少了70.60%的推断延迟，同时保持了良好的准确性。", "conclusion": "SQUAD通过群体投票机制实现了统计上可靠的早期退出，并且在计算成本相当的情况下显著降低了推断延迟和提高了测试准确率。"}}
{"id": "2601.22709", "pdf": "https://arxiv.org/pdf/2601.22709", "abs": "https://arxiv.org/abs/2601.22709", "authors": ["Yanlong Chen", "Amirhossein Habibian", "Luca Benini", "Yawei Li"], "title": "Gated Relational Alignment via Confidence-based Distillation for Efficient VLMs", "categories": ["cs.CV", "cs.AI"], "comment": "This paper is currently under review for the 2026 International Conference on Machine Learning (ICML)", "summary": "Vision-Language Models (VLMs) achieve strong multimodal performance but are costly to deploy, and post-training quantization often causes significant accuracy loss. Despite its potential, quantization-aware training for VLMs remains underexplored. We propose GRACE, a framework unifying knowledge distillation and QAT under the Information Bottleneck principle: quantization constrains information capacity while distillation guides what to preserve within this budget. Treating the teacher as a proxy for task-relevant information, we introduce confidence-gated decoupled distillation to filter unreliable supervision, relational centered kernel alignment to transfer visual token structures, and an adaptive controller via Lagrangian relaxation to balance fidelity against capacity constraints. Across extensive benchmarks on LLaVA and Qwen families, our INT4 models consistently outperform FP16 baselines (e.g., LLaVA-1.5-7B: 70.1 vs. 66.8 on SQA; Qwen2-VL-2B: 76.9 vs. 72.6 on MMBench), nearly matching teacher performance. Using real INT4 kernel, we achieve 3$\\times$ throughput with 54% memory reduction. This principled framework significantly outperforms existing quantization methods, making GRACE a compelling solution for resource-constrained deployment.", "AI": {"tldr": "提出了一种名为GRACE的框架，用于提高视觉语言模型（VLMs）量化训练后的准确率。", "motivation": "为了减少视觉语言模型部署的成本，同时保持其性能，探索一种有效的方法来改进量化感知训练。", "method": "引入了基于信心门控的解耦蒸馏、关系中心核对齐以及通过拉格朗日松弛自适应控制器平衡保真度与容量限制的技术。", "result": "实验结果表明，GRACE框架下的INT4模型在多个基准测试中优于FP16基线，并且接近教师模型的表现。同时提高了吞吐量并减少了内存消耗。", "conclusion": "该研究提供了一种新的、基于信息瓶颈原理的量化感知训练方法，显著提升了视觉语言模型的性能和效率，在资源受限部署中表现出色。"}}
{"id": "2601.22707", "pdf": "https://arxiv.org/pdf/2601.22707", "abs": "https://arxiv.org/abs/2601.22707", "authors": ["Ritesh Bhadana"], "title": "Deep Learning-Based Early-Stage IR-Drop Estimation via CNN Surrogate Modeling", "categories": ["cs.LG", "cs.AI", "cs.AR", "eess.IV"], "comment": "13 pages, 5 figures, 2 tables. Code and live demo available at https://github.com/riteshbhadana/IR-Drop-Predictor", "summary": "IR-drop is a critical power integrity challenge in modern VLSI designs that can cause timing degradation, reliability issues, and functional failures if not detected early in the design flow. Conventional IR-drop analysis relies on physics-based signoff tools, which provide high accuracy but incur significant computational cost and require near-final layout information, making them unsuitable for rapid early-stage design exploration. In this work, we propose a deep learning-based surrogate modeling approach for early-stage IR-drop estimation using a CNN. The task is formulated as a dense pixel-wise regression problem, where spatial physical layout features are mapped directly to IR-drop heatmaps. A U-Net-based encoder-decoder architecture with skip connections is employed to effectively capture both local and global spatial dependencies within the layout. The model is trained on a physics-inspired synthetic dataset generated by us, which incorporates key physical factors including power grid structure, cell density distribution, and switching activity. Model performance is evaluated using standard regression metrics such as Mean Squared Error (MSE) and Peak Signal-to-Noise Ratio (PSNR). Experimental results demonstrate that the proposed approach can accurately predict IR-drop distributions with millisecond-level inference time, enabling fast pre-signoff screening and iterative design optimization. The proposed framework is intended as a complementary early-stage analysis tool, providing designers with rapid IR-drop insight prior to expensive signoff analysis. The implementation, dataset generation scripts, and the interactive inference application are publicly available at: https://github.com/riteshbhadana/IR-Drop-Predictor. The live application can be accessed at: https://ir-drop-predictor.streamlit.app/.", "AI": {"tldr": "基于深度学习的早期IR-drop估计，通过CNN替代模型进行。", "motivation": "传统IR-drop分析依赖于物理基础验证工具，计算成本高且需要接近最终布局信息，不适合早期设计探索。提出一种基于深度学习的方法以快速准确地估计IR-drop。", "method": "将任务定义为密集像素级回归问题，使用U-Net架构的编码器-解码器结构捕获局部和全局空间依赖性。模型在合成数据集上训练，并通过MSE和PSNR评估性能。", "result": "实验结果显示所提方法能以毫秒级推理时间准确预测IR-drop分布，提供快速预签核分析能力。", "conclusion": "提出的方法作为一个补充工具，可在昂贵的验证流程之前为设计师提供快速IR-drop见解。"}}
{"id": "2601.22703", "pdf": "https://arxiv.org/pdf/2601.22703", "abs": "https://arxiv.org/abs/2601.22703", "authors": ["Abid Hassan", "Tuan Ngo", "Saad Shafiq", "Nenad Medvidovic"], "title": "DAVIS: OOD Detection via Dominant Activations and Variance for Increased Separation", "categories": ["cs.CV"], "comment": null, "summary": "Detecting out-of-distribution (OOD) inputs is a critical safeguard for deploying machine learning models in the real world. However, most post-hoc detection methods operate on penultimate feature representations derived from global average pooling (GAP) -- a lossy operation that discards valuable distributional statistics from activation maps prior to global average pooling. We contend that these overlooked statistics, particularly channel-wise variance and dominant (maximum) activations, are highly discriminative for OOD detection. We introduce DAVIS, a simple and broadly applicable post-hoc technique that enriches feature vectors by incorporating these crucial statistics, directly addressing the information loss from GAP. Extensive evaluations show DAVIS sets a new benchmark across diverse architectures, including ResNet, DenseNet, and EfficientNet. It achieves significant reductions in the false positive rate (FPR95), with improvements of 48.26\\% on CIFAR-10 using ResNet-18, 38.13\\% on CIFAR-100 using ResNet-34, and 26.83\\% on ImageNet-1k benchmarks using MobileNet-v2. Our analysis reveals the underlying mechanism for this improvement, providing a principled basis for moving beyond the mean in OOD detection.", "AI": {"tldr": "提出了一种新的OOD检测方法DAVIS，通过引入激活图中的关键统计信息提高检测准确性。", "motivation": "现有的OOD检测方法主要基于全局平均池化后的特征表示进行检测，忽略了有价值的分布统计信息，如通道级方差和最大激活值。这些信息对于区分不同分布的输入至关重要。", "method": "DAVIS通过直接从原始激活图中提取关键统计信息（如通道级方差和最大激活值），构造新的丰富特征向量以弥补全局平均池化造成的损失，从而提升OOD检测性能。", "result": "在多种网络架构上进行了广泛的评估，结果表明DAVIS显著降低了错误率，在CIFAR-10、CIFAR-100及ImageNet-1k数据集上的改进分别为48.26%、38.13%和26.83%，确立了新的性能基准。", "conclusion": "通过理论分析，揭示了引入激活图中的关键统计信息可显著提升OOD检测效果，并为超越均值的OOD检测方法提供了理论基础。"}}
{"id": "2601.22701", "pdf": "https://arxiv.org/pdf/2601.22701", "abs": "https://arxiv.org/abs/2601.22701", "authors": ["Emilien Biré", "María Santos", "Kai Yuan"], "title": "Best-of-Q: Improving VLM agents with Q-function Action Ranking at Inference", "categories": ["cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) have become powerful backbones for agents to autonomously operate in digital environments like the web and operating systems. However, these models suffer from inadaptability to fast-changing environments like the web, which can be alleviated by fine-tuning requiring expansive model training and data collection. In this work, we introduce a novel paradigm for enhancing agentic VLM policies at inference without policy retraining. Fundamentally, our approach decouples the VLM's role as a high-capacity action proposer from the final action selection mechanism. We keep the VLM policy frozen and use it to generate a set of candidate actions for a given state. Then, a lightweight, offline-trained Q-function reranks these candidates, and the agent executes the action with the highest estimated value. The main contribution is to apply the Q-function directly during inference for immediate policy improvement, and not offline to relabel data for policy retraining. We demonstrate on the academic WebVoyager benchmark that our method significantly boosts agent success rates, improving a Qwen2.5-VL-7B agent from 38.8% to 55.7% and a proprietary GPT-4.1 agent from 82.4% to 88.8%.", "AI": {"tldr": "论文提出了一种通过Q函数对VLM生成的动作进行重新排序，从而提高代理在推理阶段的表现的方法。", "motivation": "现有的视觉语言模型（VLM）在面对快速变化的环境时表现不佳，并且需要大量的训练和数据收集才能适应新的任务。为了改进这一点，论文提出了一种方法来增强这些代理的行为策略，而无需重新训练政策。", "method": "该方法将VLM视为动作建议者，生成一组候选动作。然后使用轻量级的Q函数对这些建议的动作进行排序，并选择价值最高的动作执行。这种方法在推理阶段直接应用Q函数以立即改善策略，而不是离线重标记数据用于重新训练。", "result": "实验显示，在学术WebVoyager基准测试中，该方法显著提高了代理的成功率：将Qwen2.5-VL-7B代理的成功率从38.8%提升至55.7%，将GPT-4.1代理的成功率从82.4%提高到了88.8%。", "conclusion": "通过直接应用Q函数进行推理阶段的动作选择，论文提出的方法能够有效且高效地改进VLM代理的行为策略。这种方法避免了重新训练模型的需求，并在实际应用场景中表现出色。"}}
{"id": "2601.22696", "pdf": "https://arxiv.org/pdf/2601.22696", "abs": "https://arxiv.org/abs/2601.22696", "authors": ["Tae Hun Kim", "Hyun Gyu Lee"], "title": "Bi-MCQ: Reformulating Vision-Language Alignment for Negation Understanding", "categories": ["cs.CV", "cs.LG"], "comment": "15 pages, 4 figures, Submitted to ICPR 2026 (under review)", "summary": "Recent vision-language models (VLMs) achieve strong zero-shot performance via large-scale image-text pretraining and have been widely adopted in medical image analysis. However, existing VLMs remain notably weak at understanding negated clinical statements, largely due to contrastive alignment objectives that treat negation as a minor linguistic variation rather than a meaning-inverting operator. In multi-label settings, prompt-based InfoNCE fine-tuning further reinforces easy-positive image-prompt alignments, limiting effective learning of disease absence. To overcome these limitations, we reformulate vision-language alignment as a conditional semantic comparison problem, which is instantiated through a bi-directional multiple-choice learning framework(Bi-MCQ). By jointly training Image-to-Text and Text-to-Image MCQ tasks with affirmative, negative, and mixed prompts, our method implements fine-tuning as conditional semantic comparison instead of global similarity maximization. We further introduce direction-specific Cross-Attention fusion modules to address asymmetric cues required by bi-directional reasoning and reduce alignment interference. Experiments on ChestXray14, Open-I, CheXpert, and PadChest show that Bi-MCQ improves negation understanding by up to 0.47 AUC over the zero-shot performance of the state-of-the-art CARZero model, while achieving up to a 0.08 absolute gain on positive-negative combined (PNC) evaluation. Additionally, Bi-MCQ reduces the affirmative-negative AUC gap by an average of 0.12 compared to InfoNCE-based fine-tuning, demonstrating that objective reformulation can substantially enhance negation understanding in medical VLMs.", "AI": {"tldr": "本文提出了一种新的视觉语言对齐框架Bi-MCQ，用于改进医学图像分析中负向陈述的理解。", "motivation": "现有的视觉语言模型在处理否定的临床陈述时表现不佳，因为它们将否定视为一种次要的语言变化而不是意义反转的操作符。因此需要更有效的学习方法来改善这种情况。", "method": "本文通过双向多选题框架（Bi-MCQ）重新定义了视觉语言对齐问题，并引入方向特定的交叉注意力融合模块以应对双方面推理所需的不对称线索，同时减少对齐干扰。", "result": "实验结果表明，与最先进的CARZero模型相比，Bi-MCQ在否定理解上提高了多达0.47 AUC，在正负结合评估中取得了高达0.08的绝对收益，并减少了正面-负面AUC差距。", "conclusion": "通过重新定义目标函数和引入双向推理机制，本文提出的Bi-MCQ方法显著提升了视觉语言模型在医学图像分析中的否定理解能力。"}}
{"id": "2601.22693", "pdf": "https://arxiv.org/pdf/2601.22693", "abs": "https://arxiv.org/abs/2601.22693", "authors": ["Jiahao Wu", "Yunfei Liu", "Lijian Lin", "Ye Zhu", "Lei Zhu", "Jingyi Li", "Yu Li"], "title": "PEAR: Pixel-aligned Expressive humAn mesh Recovery", "categories": ["cs.CV", "cs.AI"], "comment": "23 pages", "summary": "Reconstructing detailed 3D human meshes from a single in-the-wild image remains a fundamental challenge in computer vision. Existing SMPLX-based methods often suffer from slow inference, produce only coarse body poses, and exhibit misalignments or unnatural artifacts in fine-grained regions such as the face and hands. These issues make current approaches difficult to apply to downstream tasks. To address these challenges, we propose PEAR-a fast and robust framework for pixel-aligned expressive human mesh recovery. PEAR explicitly tackles three major limitations of existing methods: slow inference, inaccurate localization of fine-grained human pose details, and insufficient facial expression capture. Specifically, to enable real-time SMPLX parameter inference, we depart from prior designs that rely on high resolution inputs or multi-branch architectures. Instead, we adopt a clean and unified ViT-based model capable of recovering coarse 3D human geometry. To compensate for the loss of fine-grained details caused by this simplified architecture, we introduce pixel-level supervision to optimize the geometry, significantly improving the reconstruction accuracy of fine-grained human details. To make this approach practical, we further propose a modular data annotation strategy that enriches the training data and enhances the robustness of the model. Overall, PEAR is a preprocessing-free framework that can simultaneously infer EHM-s (SMPLX and scaled-FLAME) parameters at over 100 FPS. Extensive experiments on multiple benchmark datasets demonstrate that our method achieves substantial improvements in pose estimation accuracy compared to previous SMPLX-based approaches. Project page: https://wujh2001.github.io/PEAR", "AI": {"tldr": "本文提出了一种名为PEAR的框架，用于从单张图像中快速准确地恢复详细的三维人体网格。", "motivation": "现有的基于SMPLX的方法在推理速度、细粒度姿态细节定位和面部表情捕捉方面存在不足。这些问题限制了这些方法在下游任务中的应用。", "method": "PEAR采用了一种简洁统一的ViT模型来实现快速推断，通过引入像素级监督优化几何信息，以补偿简化架构导致的信息损失，并提出了模块化数据标注策略增强训练数据和模型鲁棒性。", "result": "实验表明，本文方法在多个基准数据集上比现有的SMPLX方法显著提升了姿态估计精度。", "conclusion": "PEAR是一个无需预处理的框架，能够以超过100FPS的速度同时推断出EHM参数，并且在姿势估计准确性方面取得了重大改进。"}}
{"id": "2601.22692", "pdf": "https://arxiv.org/pdf/2601.22692", "abs": "https://arxiv.org/abs/2601.22692", "authors": ["Yiheng Liu", "Junhao Ning", "Sichen Xia", "Haiyang Sun", "Yang Yang", "Hanyang Chi", "Xiaohui Gao", "Ning Qiang", "Bao Ge", "Junwei Han", "Xintao Hu"], "title": "FNF: Functional Network Fingerprint for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": "13 pages, 4 figures", "summary": "The development of large language models (LLMs) is costly and has significant commercial value. Consequently, preventing unauthorized appropriation of open-source LLMs and protecting developers' intellectual property rights have become critical challenges. In this work, we propose the Functional Network Fingerprint (FNF), a training-free, sample-efficient method for detecting whether a suspect LLM is derived from a victim model, based on the consistency between their functional network activity. We demonstrate that models that share a common origin, even with differences in scale or architecture, exhibit highly consistent patterns of neuronal activity within their functional networks across diverse input samples. In contrast, models trained independently on distinct data or with different objectives fail to preserve such activity alignment. Unlike conventional approaches, our method requires only a few samples for verification, preserves model utility, and remains robust to common model modifications (such as fine-tuning, pruning, and parameter permutation), as well as to comparisons across diverse architectures and dimensionalities. FNF thus provides model owners and third parties with a simple, non-invasive, and effective tool for protecting LLM intellectual property. The code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.", "AI": {"tldr": "提出了功能网络指纹（FNF）方法，用于检测大型语言模型是否源自同一母体。", "motivation": "防止未经授权使用开源大型语言模型并保护开发者的知识产权。", "method": "基于功能网络活动的相似性，通过比较少量样本的功能网络模式来验证两个模型之间的关系。", "result": "结果显示，来自同一个源的不同规模或架构的模型具有高度一致的功能网络活动。独立训练的模型则不会保持这种一致性。FNF方法有效且鲁棒。", "conclusion": "FNF提供了一种简单、非侵入性的工具来保护大型语言模型的知识产权。"}}
{"id": "2601.22690", "pdf": "https://arxiv.org/pdf/2601.22690", "abs": "https://arxiv.org/abs/2601.22690", "authors": ["Huanyu Liu", "Ge Li", "Yihong Dong", "Sihan Wu", "Peixu Wang", "Sihao Cheng", "Taozhi Chen", "Kechi Zhang", "Hao Zhu", "Tongxuan Liu"], "title": "Do Transformers Have the Ability for Periodicity Generalization?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) based on the Transformer have demonstrated strong performance across diverse tasks. However, current models still exhibit substantial limitations in out-of-distribution (OOD) generalization compared with humans. We investigate this gap through periodicity, one of the basic OOD scenarios. Periodicity captures invariance amid variation. Periodicity generalization represents a model's ability to extract periodic patterns from training data and generalize to OOD scenarios. We introduce a unified interpretation of periodicity from the perspective of abstract algebra and reasoning, including both single and composite periodicity, to explain why Transformers struggle to generalize periodicity. Then we construct Coper about composite periodicity, a controllable generative benchmark with two OOD settings, Hollow and Extrapolation. Experiments reveal that periodicity generalization in Transformers is limited, where models can memorize periodic data during training, but cannot generalize to unseen composite periodicity. We release the source code to support future research.", "AI": {"tldr": "研究Transformer模型在周期性泛化的表现和限制。", "motivation": "探讨大型语言模型在出界数据集（OOD）上的泛化能力不足的问题，特别是通过周期性这种基本的OOD场景来探究这一差距的原因。", "method": "引入了从抽象代数和推理角度对周期性的统一解释，并构建了一个关于复合周期性的可控生成基准Coper，包含两个OOD设定：空心和外推。实验揭示了Transformer模型在训练数据上能记忆周期性模式但无法泛化到未见的复合周期性。", "result": "结果显示，基于Transformer的语言模型在周期性泛化的表现有限。", "conclusion": "表明当前的Transformer模型虽然能够从训练数据中学习并记住周期性的模式，但在面对新的、复杂的周期性结构时却难以进行有效的泛化。"}}
{"id": "2601.22689", "pdf": "https://arxiv.org/pdf/2601.22689", "abs": "https://arxiv.org/abs/2601.22689", "authors": ["Stina Klein", "Birgit Prodinger", "Elisabeth André", "Lars Mikelsons", "Nils Mandischer"], "title": "Assistive Robots and Reasonable Work Assignment Reduce Perceived Stigma toward Persons with Disabilities", "categories": ["cs.HC", "cs.RO"], "comment": "5 pages, 2 figures, Companion Proceedings of the 21st ACM/IEEE International Conference on Human-Robot Interaction", "summary": "Robots are becoming more prominent in assisting persons with disabilities (PwD). Whilst there is broad consensus that robots can assist in mitigating physical impairments, the extent to which they can facilitate social inclusion remains equivocal. In fact, the exposed status of assisted workers could likewise lead to reduced or increased perceived stigma by other workers. We present a vignette study on the perceived cognitive and behavioral stigma toward PwD in the workplace. We designed four experimental conditions depicting a coworker with an impairment in work scenarios: overburdened work, suitable work, and robot-assisted work only for the coworker, and an offer of robot-assisted work for everyone. Our results show that cognitive stigma is significantly reduced when the work task is adapted to the person's abilities or augmented by an assistive robot. In addition, offering robot-assisted work for everyone, in the sense of universal design, further reduces perceived cognitive stigma. Thus, we conclude that assistive robots reduce perceived cognitive stigma, thereby supporting the use of collaborative robots in work scenarios involving PwDs.", "AI": {"tldr": "研究探讨了机器人辅助在工作场所中对残疾人认知偏见的影响。", "motivation": "探索机器人如何减少工作场景中的残疾人员的认知偏见，以及合理的工作分配是否能降低同事间的感知偏见。", "method": "通过设计四种实验条件来观察助残机器人和合适工作任务安排对认知偏见的减缓效果。", "result": "研究发现，当工作任务适应个人能力或由辅助机器人支持时，认知偏见显著减少。若所有人都使用机器人协助工作，则进一步降低感知认知偏见。", "conclusion": "结论认为辅助机器人可以减轻认知偏见，从而支持在涉及残疾人的工作场景中采用协作机器人"}}
{"id": "2601.22686", "pdf": "https://arxiv.org/pdf/2601.22686", "abs": "https://arxiv.org/abs/2601.22686", "authors": ["Biyu Ye", "Na Fan", "Zhengping Fan", "Weiliang Deng", "Hongming Chen", "Qifeng Chen", "Ximin Lyu"], "title": "FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation", "categories": ["cs.RO"], "comment": "8 pages, 10 figures", "summary": "Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a novel onboard framework for robust aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed framework.", "AI": {"tldr": "该论文提出了一种基于视觉的惯性估计和抓取后适应机制，以实现鲁棒的空中操作。", "motivation": "现有的空中操纵器在实际部署中面临时间变化的惯性参数复杂性的挑战，这取决于负载变化和机械臂配置。为了应对这一问题，作者提出了一个新的框架来解决这个问题。", "method": "该方法包括一个基于视觉的预抓取惯性估计模块和一个抓取后的适应机制，从而实现实时惯性动力学估算与调整，并开发了基于增益调度的惯性感知自适应控制策略。", "result": "通过频域系统识别评估其鲁棒性。实验结果验证了该框架的有效性和可行性。", "conclusion": "这项研究提供了关于空中操作器中抓取后控制的新见解，证明了一个新的视觉引导和实时调整机制能够提高空中操作的稳定性与精度。"}}
{"id": "2601.22685", "pdf": "https://arxiv.org/pdf/2601.22685", "abs": "https://arxiv.org/abs/2601.22685", "authors": ["Binyi Su", "Chenghao Huang", "Haiyong Chen"], "title": "OOVDet: Low-Density Prior Learning for Zero-Shot Out-of-Vocabulary Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot out-of-vocabulary detection (ZS-OOVD) aims to accurately recognize objects of in-vocabulary (IV) categories provided at zero-shot inference, while simultaneously rejecting undefined ones (out-of-vocabulary, OOV) that lack corresponding category prompts. However, previous methods are prone to overfitting the IV classes, leading to the OOV or undefined classes being misclassified as IV ones with a high confidence score. To address this issue, this paper proposes a zero-shot OOV detector (OOVDet), a novel framework that effectively detects predefined classes while reliably rejecting undefined ones in zero-shot scenes. Specifically, due to the model's lack of prior knowledge about the distribution of OOV data, we synthesize region-level OOV prompts by sampling from the low-likelihood regions of the class-conditional Gaussian distributions in the hidden space, motivated by the assumption that unknown semantics are more likely to emerge in low-density areas of the latent space. For OOV images, we further propose a Dirichlet-based gradient attribution mechanism to mine pseudo-OOV image samples, where the attribution gradients are interpreted as Dirichlet evidence to estimate prediction uncertainty, and samples with high uncertainty are selected as pseudo-OOV images. Building on these synthesized OOV prompts and pseudo-OOV images, we construct the OOV decision boundary through a low-density prior constraint, which regularizes the optimization of OOV classes using Gaussian kernel density estimation in accordance with the above assumption. Experimental results show that our method significantly improves the OOV detection performance in zero-shot scenes. The code is available at https://github.com/binyisu/OOV-detector.", "AI": {"tldr": "提出了一种零样本检测未知类别（OOV）的框架，有效识别预定义类同时可靠地拒识未定义类。", "motivation": "解决前方法容易过度拟合已知类别的问题，导致未定义类别被错误分类为已知类别。", "method": "通过合成区域级OOV提示和基于Dirichlet的梯度归因机制挖掘伪OOV图像样本，并构建低密度先验约束下的OOV决策边界。", "result": "实验结果表明该方法显著提高了零样本场景中OOV检测性能。", "conclusion": "所提出的方法有效提升了零样本未知类别检测能力，能够准确识别已知类并可靠地拒识未定义类别。"}}
{"id": "2601.22680", "pdf": "https://arxiv.org/pdf/2601.22680", "abs": "https://arxiv.org/abs/2601.22680", "authors": ["Rameen Abdal", "James Burgess", "Sergey Tulyakov", "Kuan-Chieh Jackson Wang"], "title": "Visual Personalization Turing Test", "categories": ["cs.CV"], "comment": "Webpage: https://snap-research.github.io/vptt", "summary": "We introduce the Visual Personalization Turing Test (VPTT), a new paradigm for evaluating contextual visual personalization based on perceptual indistinguishability, rather than identity replication. A model passes the VPTT if its output (image, video, 3D asset, etc.) is indistinguishable to a human or calibrated VLM judge from content a given person might plausibly create or share. To operationalize VPTT, we present the VPTT Framework, integrating a 10k-persona benchmark (VPTT-Bench), a visual retrieval-augmented generator (VPRAG), and the VPTT Score, a text-only metric calibrated against human and VLM judgments. We show high correlation across human, VLM, and VPTT evaluations, validating the VPTT Score as a reliable perceptual proxy. Experiments demonstrate that VPRAG achieves the best alignment-originality balance, offering a scalable and privacy-safe foundation for personalized generative AI.", "AI": {"tldr": "提出了视觉个性化图灵测试（VPTT），用于评估基于感知不可区分性的上下文视觉个性化。", "motivation": "传统的身份复制方法无法有效评估视觉生成模型的个性化能力，因此提出了一种新的范式——视觉个性化图灵测试（VPTT）来解决这个问题。", "method": "通过建立10k个人格基准（VPTT-Bench），引入了视觉检索增强生成器（VPRAG），并设计了一个基于人类和机器判断的文本评分系统（VPTT Score）。", "result": "实验结果表明，VPRAG能够在个性化和原创性之间达到最佳平衡，并且VPTT评分与人类、VL模型的评估具有高相关性。", "conclusion": "验证了视觉个性化图灵测试的有效性和可靠性，并为个性化生成AI提供了一种可扩展且保护隐私的基础方法。"}}
{"id": "2601.22679", "pdf": "https://arxiv.org/pdf/2601.22679", "abs": "https://arxiv.org/abs/2601.22679", "authors": ["Youngjoong Kim", "Duhoe Kim", "Woosung Kim", "Jaesik Park"], "title": "Stabilizing Consistency Training: A Flow Map Analysis and Self-Distillation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Consistency models have been proposed for fast generative modeling, achieving results competitive with diffusion and flow models. However, these methods exhibit inherent instability and limited reproducibility when training from scratch, motivating subsequent work to explain and stabilize these issues. While these efforts have provided valuable insights, the explanations remain fragmented, and the theoretical relationships remain unclear. In this work, we provide a theoretical examination of consistency models by analyzing them from a flow map-based perspective. This joint analysis clarifies how training stability and convergence behavior can give rise to degenerate solutions. Building on these insights, we revisit self-distillation as a practical remedy for certain forms of suboptimal convergence and reformulate it to avoid excessive gradient norms for stable optimization. We further demonstrate that our strategy extends beyond image generation to diffusion-based policy learning, without reliance on a pretrained diffusion model for initialization, thereby illustrating its broader applicability.", "AI": {"tldr": "本文通过流图分析法对一致性模型进行了理论研究，并提出了一种改进的自蒸馏策略以提高其稳定性。", "motivation": "为了克服一致性和生成模型在从头开始训练时出现的不稳定和低可重复性问题，本文旨在提供一个更完整的解释框架并寻找改善方案。", "method": "通过流图分析法解析一致性模型的行为，并基于此提出了一种改进版自蒸馏策略以解决收敛不良的问题。该方法还适用于扩散学习中的策略优化，无需预训练模型初始化。", "result": "结果表明所提出的理论分析和改进后的自蒸馏策略能够有效提高一致性和生成模型的稳定性及可重复性，并且在图像生成之外的应用中也表现良好。", "conclusion": "本文通过流图视角提供的新见解有助于理解一致性模型的行为，而基于此开发的方法不仅提高了模型训练过程中的稳定性，还扩展了其应用范围。"}}
{"id": "2601.22675", "pdf": "https://arxiv.org/pdf/2601.22675", "abs": "https://arxiv.org/abs/2601.22675", "authors": ["Shuhan Ye", "Yuanbin Qian", "Yi Yu", "Chong Wang", "Yuqi Xie", "Jiazhen Xu", "Kun Wang", "Xudong Jiang"], "title": "Fire on Motion: Optimizing Video Pass-bands for Efficient Spiking Action Recognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Spiking neural networks (SNNs) have gained traction in vision due to their energy efficiency, bio-plausibility, and inherent temporal processing. Yet, despite this temporal capacity, most progress concentrates on static image benchmarks, and SNNs still underperform on dynamic video tasks compared to artificial neural networks (ANNs). In this work, we diagnose a fundamental pass-band mismatch: Standard spiking dynamics behave as a temporal low pass that emphasizes static content while attenuating motion bearing bands, where task relevant information concentrates in dynamic tasks. This phenomenon explains why SNNs can approach ANNs on static tasks yet fall behind on tasks that demand richer temporal understanding.To remedy this, we propose the Pass-Bands Optimizer (PBO), a plug-and-play module that optimizes the temporal pass-band toward task-relevant motion bands. PBO introduces only two learnable parameters, and a lightweight consistency constraint that preserves semantics and boundaries, incurring negligible computational overhead and requires no architectural changes. PBO deliberately suppresses static components that contribute little to discrimination, effectively high passing the stream so that spiking activity concentrates on motion bearing content. On UCF101, PBO yields over ten percentage points improvement. On more complex multi-modal action recognition and weakly supervised video anomaly detection, PBO delivers consistent and significant gains, offering a new perspective for SNN based video processing and understanding.", "AI": {"tldr": "提出了一种优化时空脉冲神经网络视频处理的方法，提高了动态任务中的性能。", "motivation": "目前大多数关于SNN的研究集中在静态图像上，导致其在处理需要丰富时间理解的动态视频任务时表现不佳。因此，研究者提出了PBO模块来解决这一问题。", "method": "通过引入PBO模块优化时空脉冲神经网络的时间通频带，该模块仅需两个可学习参数和一个轻量级一致性约束，可以有效高通过流，使尖峰活动集中在承载运动的内容上。", "result": "在UCF101数据集上的性能提高了超过十个百分点，并且在多模态动作识别和弱监督视频异常检测中表现出了显著的改进。", "conclusion": "PBO模块提供了一种新的视角来改善基于SNN的视频处理和理解，证明了其有效性和优越性。"}}
{"id": "2601.22674", "pdf": "https://arxiv.org/pdf/2601.22674", "abs": "https://arxiv.org/abs/2601.22674", "authors": ["Hanxun Yu", "Wentong Li", "Xuan Qu", "Song Wang", "Junbo Chen", "Jianke Zhu"], "title": "VisionTrim: Unified Vision Token Compression for Training-Free MLLM Acceleration", "categories": ["cs.CV"], "comment": "ICLR2026, Code Link: https://github.com/hanxunyu/VisionTrim", "summary": "Multimodal large language models (MLLMs) suffer from high computational costs due to excessive visual tokens, particularly in high-resolution and video-based scenarios. Existing token reduction methods typically focus on isolated pipeline components and often neglect textual alignment, leading to performance degradation. In this paper, we propose VisionTrim, a unified framework for training-free MLLM acceleration, integrating two effective plug-and-play modules: 1) the Dominant Vision Token Selection (DVTS) module, which preserves essential visual tokens via a global-local view, and 2) the Text-Guided Vision Complement (TGVC) module, which facilitates context-aware token merging guided by textual cues. Extensive experiments across diverse image and video multimodal benchmarks demonstrate the performance superiority of our VisionTrim, advancing practical MLLM deployment in real-world applications. The code is available at: https://github.com/hanxunyu/VisionTrim.", "AI": {"tldr": "VisionTrim是一种用于无训练多模态大型语言模型加速的统一框架。", "motivation": "现有的令牌减少方法通常集中在孤立的工作流程组件上，并且往往忽视了文本对齐，导致性能下降。因此，提出了VisionTrim以解决这些问题并提高MLLM在高分辨率和视频场景中的效率。", "method": "VisionTrim集成了两个有效即插即用模块：1）通过全局-局部视图保留关键视觉令牌的主导视觉令牌选择（DVTS）模块；2）由文本线索引导促进上下文感知令牌合并的文字指导视觉补充（TGVC）模块。", "result": "在各种图像和视频多模态基准测试中，VisionTrim展示了其优越性能，推动了MLLM在实际应用中的部署。", "conclusion": "VisionTrim通过有效减少视觉令牌并保持高质量的文本对齐来加速无训练多模态大型语言模型，从而提高计算效率。"}}
{"id": "2601.22672", "pdf": "https://arxiv.org/pdf/2601.22672", "abs": "https://arxiv.org/abs/2601.22672", "authors": ["Theodora Kastritsi", "Marta Lagomarsino", "Arash Ajoudani"], "title": "Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies", "categories": ["cs.RO"], "comment": "Published in The International Journal of Robotics Research", "summary": "Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment framework. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control framework, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed framework with a baseline control framework that does not account for human ergonomics.", "AI": {"tldr": "本文提出了一种新型控制框架，通过虚拟固定件方法和持续的在线人体工学姿势评估框架，在使用辅助机器人时为用户提供反馈，以促进正确的姿态。", "motivation": "在涉及物理交互的任务中，即使有辅助机器人的帮助，用户仍可能采取不舒适或有害的姿态。本文旨在通过提供实时反馈来改善用户的长期姿势习惯，预防伤害。", "method": "开发了一种虚拟固定件方法，并将其与持续的在线人体工学姿态评估框架相结合。此外，为了提高操作员与SRB之间的协调性，在需要时调整浮动基的位置。", "result": "实验结果表明该控制框架的有效性，包括两个涉及14名受试者的实际移动操纵任务的用户研究，将提出的方案与不考虑人体工学的基准控制框架进行了比较。", "conclusion": "研究表明所提出的方法能够有效促进正确的姿势习惯，并在实际操作中提高协调性和安全性。"}}
{"id": "2601.22667", "pdf": "https://arxiv.org/pdf/2601.22667", "abs": "https://arxiv.org/abs/2601.22667", "authors": ["Chi Zhang", "Zehan Li", "Ziqian Zhong", "Haibing Ma", "Dan Xiao", "Chen Lin", "Ming Dong"], "title": "From Horizontal Layering to Vertical Integration: A Comparative Study of the AI-Driven Software Development Paradigm", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This paper examines the organizational implications of Generative AI adoption in software engineering through a multiple-case comparative study. We contrast two development environments: a traditional enterprise (brownfield) and an AI-native startup (greenfield). Our analysis reveals that transitioning from Horizontal Layering (functional specialization) to Vertical Integration (end-to-end ownership) yields 8-fold to 33-fold reductions in resource consumption. We attribute these gains to the emergence of Super Employees, AI-augmented engineers who span traditional role boundaries, and the elimination of inter-functional coordination overhead. Theoretically, we propose Human-AI Collaboration Efficacy as the primary optimization target for engineering organizations, supplanting individual productivity metrics. Our Total Factor Productivity analysis identifies an AI Distortion Effect that diminishes returns to labor scale while amplifying technological leverage. We conclude with managerial strategies for organizational redesign, including the reactivation of idle cognitive bandwidth in senior engineers and the suppression of blind scale expansion.", "AI": {"tldr": "本文通过多案例比较研究，探讨了生成式AI在软件工程中的组织影响，并对比了传统企业与AI原生创业公司的开发环境。", "motivation": "探索生成式人工智能在软件工程中对组织的影响，旨在找出从水平分层转向垂直集成的转型效果及其背后的原因。", "method": "采用多案例比较研究方法，分析两个不同类型的开发环境：传统企业和AI原生创业公司，并探讨了超级员工（AI增强型工程师）和消除跨职能协调成本的作用。", "result": "发现从水平分层到垂直集成的转变能显著减少资源消耗，实现8倍至33倍的效率提升。同时提出了人力资源生产力被技术放大而劳动规模效益降低的现象，即人工智能扭曲效应。", "conclusion": "建议组织重新设计以激活资深工程师的认知冗余，并抑制盲目的规模扩张；提出将人机协作效能作为优化目标而非单纯关注个人生产率指标。"}}
{"id": "2601.22666", "pdf": "https://arxiv.org/pdf/2601.22666", "abs": "https://arxiv.org/abs/2601.22666", "authors": ["Junyi Hu", "Tian Bai", "Fengyi Wu", "Wenyan Li", "Zhenming Peng", "Yi Zhang"], "title": "ExpAlign: Expectation-Guided Vision-Language Alignment for Open-Vocabulary Grounding", "categories": ["cs.CV"], "comment": "20 pages, 6 figures", "summary": "Open-vocabulary grounding requires accurate vision-language alignment under weak supervision, yet existing methods either rely on global sentence embeddings that lack fine-grained expressiveness or introduce token-level alignment with explicit supervision or heavy cross-attention designs. We propose ExpAlign, a theoretically grounded vision-language alignment framework built on a principled multiple instance learning formulation. ExpAlign introduces an Expectation Alignment Head that performs attention-based soft MIL pooling over token-region similarities, enabling implicit token and instance selection without additional annotations. To further stabilize alignment learning, we develop an energy-based multi-scale consistency regularization scheme, including a Top-K multi-positive contrastive objective and a Geometry-Aware Consistency Objective derived from a Lagrangian-constrained free-energy minimization. Extensive experiments show that ExpAlign consistently improves open-vocabulary detection and zero-shot instance segmentation, particularly on long-tail categories. Most notably, it achieves 36.2 AP$_r$ on the LVIS minival split, outperforming other state-of-the-art methods at comparable model scale, while remaining lightweight and inference-efficient.", "AI": {"tldr": "提出了一种基于期望对齐的框架ExpAlign，用于弱监督下的开放词汇视觉语言对齐。", "motivation": "现有方法在实现准确的视觉-语言对准时存在依赖全局句子嵌入而缺乏细粒度表达或需要显式监督的问题。为了克服这些问题，本文提出了一个理论上基础良好的基于多实例学习的对齐框架。", "method": "ExpAlign引入了一个期望对齐头部，使用注意力机制进行软MIL池化以选择隐式的令牌和实例；同时开发了一种能量基多尺度一致性正则化方案，包括Top-K多正样本对比目标及几何感知一致性目标。", "result": "实验表明，在开放词汇检测和零样本实例分割方面，ExpAlign表现出色，尤其是在长尾类别上。在LVIS minival数据集上达到了36.2 AP$_r$，优于其他最先进的方法，且模型轻量、推理高效。", "conclusion": "通过引入期望对齐头部及多尺度一致性正则化方案，实现了弱监督下的开放词汇视觉语言对齐任务的性能提升。"}}
{"id": "2601.22664", "pdf": "https://arxiv.org/pdf/2601.22664", "abs": "https://arxiv.org/abs/2601.22664", "authors": ["Zixuan Huang", "Xin Xia", "Yuxi Ren", "Jianbin Zheng", "Xuefeng Xiao", "Hongyan Xie", "Li Huaqiu", "Songshi Liang", "Zhongxiang Dai", "Fuzhen Zhuang", "Jianxin Li", "Yikun Ban", "Deqing Wang"], "title": "Real-Time Aligned Reward Model beyond Semantics", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for aligning large language models (LLMs) with human preferences, yet it is susceptible to reward overoptimization, in which policy models overfit to the reward model, exploit spurious reward patterns instead of faithfully capturing human intent. Prior mitigations primarily relies on surface semantic information and fails to efficiently address the misalignment between the reward model (RM) and the policy model caused by continuous policy distribution shifts. This inevitably leads to an increasing reward discrepancy, exacerbating reward overoptimization. To address these limitations, we introduce R2M (Real-Time Aligned Reward Model), a novel lightweight RLHF framework. R2M goes beyond vanilla reward models that solely depend on the semantic representations of a pretrained LLM. Instead, it leverages the evolving hidden states of the policy (namely policy feedback) to align with the real-time distribution shift of the policy during the RL process. This work points to a promising new direction for improving the performance of reward models through real-time utilization of feedback from policy models.", "AI": {"tldr": "本文提出了一种新的轻量级RLHF框架R2M，该框架超越了仅依赖预训练LLM语义表示的奖励模型，通过实时利用策略模型反馈来解决政策分布持续变化导致的奖励不一致问题。", "motivation": "传统的RLHF技术容易受到奖励过优化的影响，即策略模型过度拟合于奖励模型并依赖虚假奖励模式。先前的方法主要依靠表面语义信息，并未能有效应对因连续策略分布变化而导致的奖励模型与政策模型之间的偏差。", "method": "R2M通过利用策略模型在强化学习过程中的实时动态隐藏状态（即策略反馈）来解决这一问题，这种方法能够更好地适应和调整以跟上策略的变化。", "result": "该研究展示了R2M框架的有效性，并指出它为提高奖励模型性能提供了新的方向，特别是在处理因策略分布变化引起的偏差方面具有优势。", "conclusion": "通过引入R2M框架，本文提供了一个有效的方法来解决传统RLHF技术的局限性，特别是对于适应连续政策分布变化的问题。这不仅提升了奖励模型与人类偏好之间的对齐度，还为未来的研究开辟了新的路径。"}}
{"id": "2601.22663", "pdf": "https://arxiv.org/pdf/2601.22663", "abs": "https://arxiv.org/abs/2601.22663", "authors": ["Zongfang Liu", "Guangyi Chen", "Boyang Sun", "Tongliang Liu", "Kun Zhang"], "title": "Unsupervised Synthetic Image Attribution: Alignment and Disentanglement", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "As the quality of synthetic images improves, identifying the underlying concepts of model-generated images is becoming increasingly crucial for copyright protection and ensuring model transparency. Existing methods achieve this attribution goal by training models using annotated pairs of synthetic images and their original training sources. However, obtaining such paired supervision is challenging, as it requires either well-designed synthetic concepts or precise annotations from millions of training sources. To eliminate the need for costly paired annotations, in this paper, we explore the possibility of unsupervised synthetic image attribution. We propose a simple yet effective unsupervised method called Alignment and Disentanglement. Specifically, we begin by performing basic concept alignment using contrastive self-supervised learning. Next, we enhance the model's attribution ability by promoting representation disentanglement with the Infomax loss. This approach is motivated by an interesting observation: contrastive self-supervised models, such as MoCo and DINO, inherently exhibit the ability to perform simple cross-domain alignment. By formulating this observation as a theoretical assumption on cross-covariance, we provide a theoretical explanation of how alignment and disentanglement can approximate the concept-matching process through a decomposition of the canonical correlation analysis objective. On the real-world benchmarks, AbC, we show that our unsupervised method surprisingly outperforms the supervised methods. As a starting point, we expect our intuitive insights and experimental findings to provide a fresh perspective on this challenging task.", "AI": {"tldr": "本文提出了一种无需配对注释的无监督方法，用于合成图像归因。", "motivation": "随着合成图像质量的提高，识别模型生成图像背后的概念变得越来越重要。现有的归因方法需要昂贵的配对标注，限制了其应用范围。", "method": "通过对比自监督学习进行基础概念对齐，并使用Infomax损失促进表示解耦。", "result": "在实际基准测试AbC上，无监督方法超越了有监督的方法。", "conclusion": "本文提供了一种新颖的视角来解决合成图像归因这一具有挑战性的任务。"}}
{"id": "2601.22662", "pdf": "https://arxiv.org/pdf/2601.22662", "abs": "https://arxiv.org/abs/2601.22662", "authors": ["Wei Zhu", "Lixing Yu", "Hao-Ren Yao", "Zhiwen Tang", "Kun Yue"], "title": "Task-Aware LLM Council with Adaptive Decision Pathways for Decision Support", "categories": ["cs.AI", "cs.MA"], "comment": "A shorter version of this work has been accepted by ICASSP 2026", "summary": "Large language models (LLMs) have shown strong capabilities across diverse decision-making tasks. However, existing approaches often overlook the specialization differences among available models, treating all LLMs as uniformly applicable regardless of task characteristics. This limits their ability to adapt to varying reasoning demands and task complexities. In this work, we propose Task-Aware LLM Council (TALC), a task-adaptive decision framework that integrates a council of LLMs with Monte Carlo Tree Search (MCTS) to enable dynamic expert selection and efficient multi-step planning. Each LLM is equipped with a structured success memory profile derived from prior task trajectories, enabling semantic matching between current reasoning context and past successes. At each decision point, TALC routes control to the most contextually appropriate model and estimates node value using a dual-signal mechanism that fuses model-based evaluations with historical utility scores. These signals are adaptively weighted based on intra-node variance and used to guide MCTS selection, allowing the system to balance exploration depth with planning confidence. Experiments on WebShop, HumanEval, and the Game of 24 demonstrate that TALC achieves superior task success rates and improved search efficiency compared to strong baselines, validating the benefits of specialization-aware routing and adaptive planning.", "AI": {"tldr": "论文提出了一种任务感知的大型语言模型委员会（TALC）框架，通过蒙特卡洛树搜索来动态选择最合适的模型进行多步规划。", "motivation": "现有的方法往往忽视了不同大型语言模型之间的差异性，并未根据具体任务需求和复杂度优化选择模型。", "method": "论文提出了一种结合了多个大型语言模型的TALC框架，每个模型都配备了通过以前的任务轨迹获取的成功记忆配置文件。在每一步决策中，系统使用融合了基于模型评估和历史效用评分的双重信号机制来估计节点价值，并根据内部方差自适应地加权这些信号，指导蒙特卡洛树搜索选择。", "result": "实验结果显示，TALC在WebShop、HumanEval以及24游戏等任务上的成功率优于现有基线方法，在探索深度和规划信心之间取得了平衡。", "conclusion": "研究结果表明，基于任务感知的大型语言模型委员会（TALC）框架能够提高决策支持系统的效率并改进搜索性能。"}}
{"id": "2601.22661", "pdf": "https://arxiv.org/pdf/2601.22661", "abs": "https://arxiv.org/abs/2601.22661", "authors": ["Yong Ren", "Jingbei Li", "Haiyang Sun", "Yujie Chen", "Cheng Yi", "Yechang Huang", "Hao Gu", "Ye Bai", "Xuerui Yang"], "title": "Evaluating and Rewarding LALMs for Expressive Role-Play TTS via Mean Continuation Log-Probability", "categories": ["cs.SD"], "comment": null, "summary": "Recent advances in Large Audio Language Models (LALMs) have extended Text-to-Speech (TTS) to interactive role-play scenarios, which demand high expressiveness and strict adherence to role-play instructions. However, existing models struggle to maintain stylistic consistency with character profiles and scene descriptions across multi-turn dialogues. A critical bottleneck is the lack of objective metrics for quantifying speaking style. To bridge this gap, we propose Mean Continuation Log-Probability (MCLP) as both an evaluation metric and a reward signal, validated on LALM-based Role-Play TTS (RP-TTS) tasks. Critically, we leverage the In-Context Learning capability of pre-trained LALMs to formulate MCLP via a continuation log-probability prediction. This metric quantifies stylistic consistency by measuring the likelihood of the ground-truth speech conditioned on the generated speech. Furthermore, we employ MCLP as a reinforcement learning reward to enhance the style alignment between generated speech and Role-Play instructions. To facilitate evaluation, we construct an RP-TTS dataset with rich scene and character annotations. Experimental results demonstrate that our method significantly outperforms strong LALM baselines on both objective and subjective metrics.", "AI": {"tldr": "评估并奖励大型音频语言模型在角色扮演TTS中的表现，提出均值续言对数概率（MCLP）作为量化说话风格一致性的客观指标及强化学习回报。", "motivation": "当前LALMs在多轮对话中难以保持与角色描述和场景说明的一致性。缺乏量化的说话风格一致性评估标准是主要瓶颈。", "method": "提出均值续言对数概率（MCLP），利用预训练模型的上下文学习能力，将生成语音作为条件测量真实语音的可能性，并将其用作强化学习中的回报以提高TTS与角色扮演指示的一致性。构建了具有丰富场景和角色注释的角色扮演TTS数据集。", "result": "实验结果表明，在客观和主观评估标准上，该方法显著优于强LALM基线模型。", "conclusion": "提出的方法为解决说话风格一致性问题提供了一种有效的解决方案，并通过实际数据验证了其优越性。"}}
{"id": "2601.22657", "pdf": "https://arxiv.org/pdf/2601.22657", "abs": "https://arxiv.org/abs/2601.22657", "authors": ["Haisong Gong", "Zhibo Liu", "Qiang Liu", "Shu Wu", "Liang Wang"], "title": "NAG: A Unified Native Architecture for Encoder-free Text-Graph Modeling in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Prevailing methods for integrating graphs into Language Models (LMs) typically rely on a segregated architecture: external Graph Neural Networks (GNNs) encode structural topology, while LMs process textual semantics. We argue this approach is suboptimal for text-graphs: it creates a conceptually disjointed interaction paradigm. By segregating structural encoding from semantic processing, these systems must perform a complex implicit alignment between abstract graph tokens and concrete textual elements. Challenging the necessity of external encoders, we propose NAG (Native Architecture for Graphs), a unified framework that internalizes graph processing within the LM's native manifold. Instead of bridging disparate embedding spaces, NAG repurposes the self-attention mechanism to enforce topological dependencies and recalibrates positional IDs to ensure structural equivalence. This allows the model to harness its intrinsic linguistic capability to simultaneously comprehend node and edge content alongside structural topology. We introduce two efficient implementations: NAG-Zero for absolute preservation of the base model's linguistic capabilities, and NAG-LoRA for enhanced structural adaptation. Experiments across diverse graph tasks validate that NAG achieves robust graph comprehension without the overhead of external encoders, offering a simpler, more coherent paradigm for text-graph modeling.", "AI": {"tldr": "本文提出了一种在语言模型内部处理文本和图数据的统一架构NAG，旨在简化现有的分离式图编码器方法。", "motivation": "现有方法通常依赖于分离式的结构：使用外部GNN编码图结构而LM处理语义。这种分离造成了概念上的割裂，需要复杂的隐式对齐过程。本文质疑这一必要性，并提出了一种新的统一架构以简化流程和提高效率。", "method": "NAG通过在自注意力机制中引入拓扑依赖来内化图处理并重新校准位置ID确保结构等价性。此外，还介绍了两种实现方式：NAG-Zero保持基础模型的语言能力不变；NAG-LoRA则增强了对结构的适应。", "result": "实验表明，NAG在不需要外部编码器的情况下实现了强大的图理解能力，并且提供了更简单、一致性的文本和图形建模模式。", "conclusion": "通过消除外部编码器并利用语言模型内部机制处理图数据，NAG提供了一种既简洁又高效的文本-图形联合建模解决方案。"}}
{"id": "2601.22653", "pdf": "https://arxiv.org/pdf/2601.22653", "abs": "https://arxiv.org/abs/2601.22653", "authors": ["Mona Rajhans"], "title": "Human-Centered Explainability in AI-Enhanced UI Security Interfaces: Designing Trustworthy Copilots for Cybersecurity Analysts", "categories": ["cs.HC", "cs.AI", "cs.CR"], "comment": "To appear in IEEE ICCA 2025 proceedings", "summary": "Artificial intelligence (AI) copilots are increasingly integrated into enterprise cybersecurity platforms to assist analysts in threat detection, triage, and remediation. However, the effectiveness of these systems depends not only on the accuracy of underlying models but also on the degree to which users can understand and trust their outputs. Existing research on algorithmic explainability has largely focused on model internals, while little attention has been given to how explanations should be surfaced in user interfaces for high-stakes decision-making contexts [8], [5], [6]. We present a mixed-methods study of explanation design strategies in AI-driven security dashboards. Through a taxonomy of explanation styles and a controlled user study with security practitioners, we compare natural language rationales, confidence visualizations, counterfactual explanations, and hybrid approaches. Our findings show that explanation style significantly affects user trust calibration, decision accuracy, and cognitive load. We contribute (1) empirical evidence on the usability of explanation interfaces for security copilots, (2) design guidelines for integrating explainability into enterprise UIs, and (3) a framework for aligning explanation strategies with analyst needs in security operations centers (SOCs). This work advances the design of human-centered AI tools in cybersecurity and provides broader implications for explainability in other high-stakes domains.", "AI": {"tldr": "研究了AI辅助安全界面中解释设计策略的影响，通过用户实验和分类法探讨不同解释风格的效果，为高风险决策场景中的可信赖性提供证据和设计指南。", "motivation": "提升企业级网络安全平台中AI助手的有效性和可信度，特别是在威胁检测、优先级划分和缓解方面的用户体验。", "method": "采用混合研究方法，包括解释风格的分类法和对安全从业人员进行控制用户实验，评估自然语言理由、信心可视化、反事实说明以及混合策略的效果。", "result": "发现不同的解释样式显著影响了用户的信任校准、决策准确性及认知负荷。提供了关于解释界面在网络安全助手中的可用性的实证证据，并提出设计准则。", "conclusion": "这项工作推进了人本为中心的AI工具的设计，特别是在网络安全领域，同时也为其他高风险领域的可说明性设计提供指导框架和建议。"}}
{"id": "2601.22651", "pdf": "https://arxiv.org/pdf/2601.22651", "abs": "https://arxiv.org/abs/2601.22651", "authors": ["Naoki Murata", "Yuhta Takida", "Chieh-Hsin Lai", "Toshimitsu Uesaka", "Bac Nguyen", "Stefano Ermon", "Yuki Mitsufuji"], "title": "GUDA: Counterfactual Group-wise Training Data Attribution for Diffusion Models via Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training-data attribution for vision generative models aims to identify which training data influenced a given output. While most methods score individual examples, practitioners often need group-level answers (e.g., artistic styles or object classes). Group-wise attribution is counterfactual: how would a model's behavior on a generated sample change if a group were absent from training? A natural realization of this counterfactual is Leave-One-Group-Out (LOGO) retraining, which retrains the model with each group removed; however, it becomes computationally prohibitive as the number of groups grows. We propose GUDA (Group Unlearning-based Data Attribution) for diffusion models, which approximates each counterfactual model by applying machine unlearning to a shared full-data model instead of training from scratch. GUDA quantifies group influence using differences in a likelihood-based scoring rule (ELBO) between the full model and each unlearned counterfactual. Experiments on CIFAR-10 and artistic style attribution with Stable Diffusion show that GUDA identifies primary contributing groups more reliably than semantic similarity, gradient-based attribution, and instance-level unlearning approaches, while achieving x100 speedup on CIFAR-10 over LOGO retraining.", "AI": {"tldr": "提出了一种名为GUDA的算法，用于通过机器卸载而非重新训练来近似生成模型在每个组被移除情况下的行为。", "motivation": "传统的方法难以有效地评估视觉生成模型中特定群组数据的影响，因为这种方法通常是计算量极大的。", "method": "利用机器卸载技术对扩散模型进行处理以快速地逼近各个反事实模型的状态，并通过ELBO评分规则来量化这些影响。", "result": "实验表明GUDA比其他方法更加可靠地识别主要贡献的群组数据，且在CIFAR-10上实现了一百倍的速度提升。", "conclusion": "GUDA提供了一个高效的方法来评估特定训练数据集对扩散模型输出的影响。"}}
{"id": "2601.22648", "pdf": "https://arxiv.org/pdf/2601.22648", "abs": "https://arxiv.org/abs/2601.22648", "authors": ["Xianzhou Zeng", "Jing Huang", "Chunmei Xie", "Gongrui Nan", "Siye Chen", "Mengyu Lu", "Weiqi Xiong", "Qixuan Zhou", "Junhao Zhang", "Qiang Zhu", "Yadong Li", "Xingzhong Xu"], "title": "UCPO: Uncertainty-Aware Policy Optimization", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The key to building trustworthy Large Language Models (LLMs) lies in endowing them with inherent uncertainty expression capabilities to mitigate the hallucinations that restrict their high-stakes applications. However, existing RL paradigms such as GRPO often suffer from Advantage Bias due to binary decision spaces and static uncertainty rewards, inducing either excessive conservatism or overconfidence. To tackle this challenge, this paper unveils the root causes of reward hacking and overconfidence in current RL paradigms incorporating uncertainty-based rewards, based on which we propose the UnCertainty-Aware Policy Optimization (UCPO) framework. UCPO employs Ternary Advantage Decoupling to separate and independently normalize deterministic and uncertain rollouts, thereby eliminating advantage bias. Furthermore, a Dynamic Uncertainty Reward Adjustment mechanism is introduced to calibrate uncertainty weights in real-time according to model evolution and instance difficulty. Experimental results in mathematical reasoning and general tasks demonstrate that UCPO effectively resolves the reward imbalance, significantly improving the reliability and calibration of the model beyond their knowledge boundaries.", "AI": {"tldr": "提出了一种基于不确定性感知的政策优化框架（UCPO），以解决大型语言模型中存在的优势偏见问题，提高其可靠性。", "motivation": "现有的强化学习方法存在优势偏差和过度自信的问题，导致大型语言模型无法准确表达不确定性。为了构建更可靠的模型，需要一种能够有效处理不确定性的新方法。", "method": "UCPO采用三元优势分离技术将确定性和不确定性轨迹分开，并实时调整不确定性权重以适应模型演化和实例难度。", "result": "实验表明，UCPO可以解决奖励不平衡问题，显著提高模型的可靠性和校准能力。", "conclusion": "通过引入UCPO框架，成功解决了现有强化学习方法中的优势偏见问题，使大型语言模型在各种任务中表现更加稳定和可信。"}}
{"id": "2601.22647", "pdf": "https://arxiv.org/pdf/2601.22647", "abs": "https://arxiv.org/abs/2601.22647", "authors": ["Jinwoo Jang", "Minjong Yoo", "Sihyung Yoon", "Honguk Woo"], "title": "Test-Time Mixture of World Models for Embodied Agents in Dynamic Environments", "categories": ["cs.AI"], "comment": "Accepted at ICLR 2026. 10 pages. Code available at https://github.com/doldam0/tmow", "summary": "Language model (LM)-based embodied agents are increasingly deployed in real-world settings. Yet, their adaptability remains limited in dynamic environments, where constructing accurate and flexible world models is crucial for effective reasoning and decision-making. To address this challenge, we extend the Mixture-of-Experts (MoE) paradigm to embodied agents. While conventional MoE architectures modularize knowledge into expert components with pre-trained routing, they remain rigid once deployed, making them less effective for adapting to unseen domains in dynamic environments. We therefore propose Test-time Mixture of World Models (TMoW), a framework that enhances adaptability to unseen and evolving domains. TMoW updates its routing function over world models at test time, unlike conventional MoE where the function remains fixed, enabling agents to recombine existing models and integrate new ones for continual adaptation. It achieves this through (i) multi-granular prototype-based routing, which adapts mixtures across object- to scene-level similarities, (ii) test-time refinement that aligns unseen domain features with prototypes during inference, and (iii) distilled mixture-based augmentation, which efficiently constructs new models from few-shot data and existing prototypes. We evaluate TMoW on VirtualHome, ALFWorld, and RLBench benchmarks, demonstrating strong performance in both zero-shot adaptation and few-shot expansion scenarios, and showing that it enables embodied agents to operate effectively in dynamic environments.", "AI": {"tldr": "提出了一种测试时混合世界模型（TMoW）框架，提高语言模型驱动的具身代理在动态环境中的适应性。", "motivation": "当前的语言模型驱动的具身代理难以灵活地构建准确的世界模型，在面对未知和不断变化的领域时适应能力有限。", "method": "通过多粒度原型基路由、测试时特征对齐以及基于蒸馏混合体扩增新模型的方法，使代理能够根据新的数据重新组合现有模型并集成新模型。", "result": "在VirtualHome、ALFWorld和RLBench基准上验证了TMoW的有效性，在零样本适应和少量示例扩展场景中表现出色。", "conclusion": "TMoW框架显著提高了具身代理在动态环境中的性能，使其能够有效处理未知领域。"}}
{"id": "2601.22645", "pdf": "https://arxiv.org/pdf/2601.22645", "abs": "https://arxiv.org/abs/2601.22645", "authors": ["Vaibhav Ram S. V. N. S", "Swetanshu Agrawal", "Samudra Banerjee", "Abdul Muhsin"], "title": "Beyond Medical Chatbots: Meddollina and the Rise of Continuous Clinical Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "Generative medical AI now appears fluent and knowledgeable enough to resemble clinical intelligence, encouraging the belief that scaling will make it safe. But clinical reasoning is not text generation. It is a responsibility-bound process under ambiguity, incomplete evidence, and longitudinal context. Even as benchmark scores rise, generation-centric systems still show behaviours incompatible with clinical deployment: premature closure, unjustified certainty, intent drift, and instability across multi-step decisions. We argue these are structural consequences of treating medicine as next-token prediction. We formalise Clinical Contextual Intelligence (CCI) as a distinct capability class required for real-world clinical use, defined by persistent context awareness, intent preservation, bounded inference, and principled deferral when evidence is insufficient. We introduce Meddollina, a governance-first clinical intelligence system designed to constrain inference before language realisation, prioritising clinical appropriateness over generative completeness. Meddollina acts as a continuous intelligence layer supporting clinical workflows while preserving clinician authority. We evaluate Meddollina using a behaviour-first regime across 16,412+ heterogeneous medical queries, benchmarking against general-purpose models, medical-tuned models, and retrieval-augmented systems. Meddollina exhibits a distinct behavioural profile: calibrated uncertainty, conservative reasoning under underspecification, stable longitudinal constraint adherence, and reduced speculative completion relative to generation-centric baselines. These results suggest deployable medical AI will not emerge from scaling alone, motivating a shift toward Continuous Clinical Intelligence, where progress is measured by clinician-aligned behaviour under uncertainty rather than fluency-driven completion.", "AI": {"tldr": "论文提出了Meddollina，一种新型医疗智能系统，旨在通过持续临床智能实现更适合临床使用的AI。", "motivation": "现有的生成性AI在处理医学问题时表现出的行为，如过早的结论、不合理的确定性和意图漂移等，不符合临床实践的需求。作者认为这些问题源于将医学视为单步预测而不是连续的情境感知和推理过程。", "method": "论文通过引入Meddollina系统来解决这一问题，并对它进行了16,412个以上异质医疗查询的评估，与通用模型、医学调优模型及检索增强系统的性能进行比较。", "result": "Meddollina展示了更稳健的行为特征：校准不确定性、保守性推理在不完整说明下、长时间稳定约束遵守以及减少猜测完成。", "conclusion": "论文结论认为，在不确定情况下，基于行为的评估比流畅度驱动的完成更重要。这表明可部署的医疗AI不能仅仅依靠规模扩展来实现，而是需要转向连续临床智能。"}}
{"id": "2601.22638", "pdf": "https://arxiv.org/pdf/2601.22638", "abs": "https://arxiv.org/abs/2601.22638", "authors": ["Palash Goyal", "Mihir Parmar", "Yiwen Song", "Hamid Palangi", "Tomas Pfister", "Jinsung Yoon"], "title": "ScholarPeer: A Context-Aware Multi-Agent Framework for Automated Peer Review", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Automated peer review has evolved from simple text classification to structured feedback generation. However, current state-of-the-art systems still struggle with \"surface-level\" critiques: they excel at summarizing content but often fail to accurately assess novelty and significance or identify deep methodological flaws because they evaluate papers in a vacuum, lacking the external context a human expert possesses. In this paper, we introduce ScholarPeer, a search-enabled multi-agent framework designed to emulate the cognitive processes of a senior researcher. ScholarPeer employs a dual-stream process of context acquisition and active verification. It dynamically constructs a domain narrative using a historian agent, identifies missing comparisons via a baseline scout, and verifies claims through a multi-aspect Q&A engine, grounding the critique in live web-scale literature. We evaluate ScholarPeer on DeepReview-13K and the results demonstrate that ScholarPeer achieves significant win-rates against state-of-the-art approaches in side-by-side evaluations and reduces the gap to human-level diversity.", "AI": {"tldr": "ScholarPeer是一个基于多代理的自动同行评审框架，旨在通过获取上下文和主动验证来生成深入且准确的评估。", "motivation": "现有系统虽然能在摘要总结上表现良好，但无法识别深层次的方法缺陷或评价新颖性和重要性。因此，作者提出了一种新的方法以改善这些方面的性能。", "method": "ScholarPeer采用了双流处理流程：一是通过一个历史学家代理构建领域叙述；二是利用基线侦察和多方面Q&A引擎进行主动验证，从而将评估建立在实时大规模文献的基础上。", "result": "实验结果表明，在DeepReview-13K数据集上，ScholarPeer相比于现有的最先进方法，显著提高了性能，并缩小了与人类评审的差距。", "conclusion": "通过模拟资深专家的认知过程，ScholarPeer能够在自动同行评审中提供更准确和深入的反馈。"}}
{"id": "2601.22637", "pdf": "https://arxiv.org/pdf/2601.22637", "abs": "https://arxiv.org/abs/2601.22637", "authors": ["Mohtady Barakat", "Omar Salah", "Ahmed Yasser", "Mostafa Ahmed", "Zahirul Arief", "Waleed Khan", "Dong Zhang", "Aondona Iorumbur", "Confidence Raymond", "Mohannad Barakat", "Noha Magdy"], "title": "Training Beyond Convergence: Grokking nnU-Net for Glioma Segmentation in Sub-Saharan MRI", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Gliomas are placing an increasingly clinical burden on Sub-Saharan Africa (SSA). In the region, the median survival for patients remains under two years, and access to diagnostic imaging is extremely limited. These constraints highlight an urgent need for automated tools that can extract the maximum possible information from each available scan, tools that are specifically trained on local data, rather than adapted from high-income settings where conditions are vastly different. We utilize the Brain Tumor Segmentation (BraTS) Africa 2025 Challenge dataset, an expert annotated collection of glioma MRIs. Our objectives are: (i) establish a strong baseline with nnUNet on this dataset, and (ii) explore whether the celebrated \"grokking\" phenomenon an abrupt, late training jump from memorization to superior generalization can be triggered to push performance without extra labels. We evaluate two training regimes. The first is a fast, budget-conscious approach that limits optimization to just a few epochs, reflecting the constrained GPU resources typically available in African institutions. Despite this limitation, nnUNet achieves strong Dice scores: 92.3% for whole tumor (WH), 86.6% for tumor core (TC), and 86.3% for enhancing tumor (ET). The second regime extends training well beyond the point of convergence, aiming to trigger a grokking-driven performance leap. With this approach, we were able to achieve grokking and enhanced our results to higher Dice scores: 92.2% for whole tumor (WH), 90.1% for tumor core (TC), and 90.2% for enhancing tumor (ET).", "AI": {"tldr": "利用nnUNet对非洲脑肿瘤MR图像进行分割，探索延长训练周期能否引发'grokking'现象从而提升性能。", "motivation": "在撒哈拉以南非洲地区，胶质瘤患者的生存期较短且诊断成像资源有限。开发适用于当地数据的自动工具能够提高扫描信息提取效率和临床价值。", "method": "基于BraTS Africa 2025挑战集训练nnUNet模型。第一阶段快速预算友好型训练；第二阶段延长训练以观察是否能触发'grokking'现象，从而提升性能。", "result": "通过延长训练周期成功实现'drokking'并获得更好的Dice分数：整个肿瘤分割精度为92.2%，肿瘤核心和增强区域分别为90.1%和90.2%。", "conclusion": "证明了在资源有限的条件下，利用nnUNet进行长时间训练可以触发'drokking'现象，并显著提高胶质瘤MR图像的分割性能。"}}
{"id": "2601.22636", "pdf": "https://arxiv.org/pdf/2601.22636", "abs": "https://arxiv.org/abs/2601.22636", "authors": ["Mingqian Feng", "Xiaodong Liu", "Weiwei Yang", "Chenliang Xu", "Christopher White", "Jianfeng Gao"], "title": "Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are typically evaluated for safety under single-shot or low-budget adversarial prompting, which underestimates real-world risk. In practice, attackers can exploit large-scale parallel sampling to repeatedly probe a model until a harmful response is produced. While recent work shows that attack success increases with repeated sampling, principled methods for predicting large-scale adversarial risk remain limited. We propose a scaling-aware Best-of-N estimation of risk, SABER, for modeling jailbreak vulnerability under Best-of-N sampling. We model sample-level success probabilities using a Beta distribution, the conjugate prior of the Bernoulli distribution, and derive an analytic scaling law that enables reliable extrapolation of large-N attack success rates from small-budget measurements. Using only n=100 samples, our anchored estimator predicts ASR@1000 with a mean absolute error of 1.66, compared to 12.04 for the baseline, which is an 86.2% reduction in estimation error. Our results reveal heterogeneous risk scaling profiles and show that models appearing robust under standard evaluation can experience rapid nonlinear risk amplification under parallel adversarial pressure. This work provides a low-cost, scalable methodology for realistic LLM safety assessment. We will release our code and evaluation scripts upon publication to future research.", "AI": {"tldr": "提出了一种新的风险评估方法SABER，用于预测大型语言模型在最佳N采样下的实际攻击成功率。", "motivation": "当前的安全评估方式低估了大规模语言模型的实际安全风险。需要一种能够在有限预算下准确预测大规模攻击成功率的方法。", "method": "使用Beta分布建模样本水平的成功概率，并推导出一个可分析的扩展法则，从少量采样中可靠地外推大规模攻击成功的比例。", "result": "SABER方法在只有100个样本的情况下，可以预测出ASR@1000的概率误差为1.66%，相比于基线减少了86.2%的估计误差。模型显示了异质的风险放大特性。", "conclusion": "这项工作提供了一种低成本、可扩展的方法来评估大型语言模型的安全性，并将在未来的研究中发布代码和评估脚本。"}}
{"id": "2601.22634", "pdf": "https://arxiv.org/pdf/2601.22634", "abs": "https://arxiv.org/abs/2601.22634", "authors": ["Mayukh Bagchi", "Fausto Giunchiglia"], "title": "What can Computer Vision learn from Ranganathan?", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted @ DRTC-ISI Conference 2026, Indian Statistical Institute (ISI), Bangalore, India", "summary": "The Semantic Gap Problem (SGP) in Computer Vision (CV) arises from the misalignment between visual and lexical semantics leading to flawed CV dataset design and CV benchmarks. This paper proposes that classification principles of S.R. Ranganathan can offer a principled starting point to address SGP and design high-quality CV datasets. We elucidate how these principles, suitably adapted, underpin the vTelos CV annotation methodology. The paper also briefly presents experimental evidence showing improvements in CV annotation and accuracy, thereby, validating vTelos.", "AI": {"tldr": "该论文提出将S.R. Ranganathan的分类原则应用于解决计算机视觉中的语义间隙问题，并设计高质量的数据集。", "motivation": "为了应对由于视觉和词汇语义不一致导致的计算机视觉数据集设计和基准测试的问题，作者希望通过引入Ranganathan的原则来改善这一状况。", "method": "论文阐述了如何适当地采用Ranganathan的分类原则作为vTelos计算机视觉注释方法的基础，并提供了实验证据证明这种方法的有效性。", "result": "通过应用vTelos的方法，在计算机视觉标注质量和准确性方面取得了改进，这验证了该方法的效果。", "conclusion": "基于S.R. Ranganathan的分类原则设计的高质量数据集可以有效解决语义间隙问题并提高计算机视觉任务的表现。"}}
{"id": "2601.22633", "pdf": "https://arxiv.org/pdf/2601.22633", "abs": "https://arxiv.org/abs/2601.22633", "authors": ["Devansh Lodha", "Mohit Panchal", "Sameer G. Kulkarni"], "title": "MCP-Diag: A Deterministic, Protocol-Driven Architecture for AI-Native Network Diagnostics", "categories": ["cs.NI", "cs.AI"], "comment": "Accepted at COMSNETS 2026 Graduate Forum. Best Paper Award (Runner Up). 5 pages, 3 figures", "summary": "The integration of Large Language Models (LLMs) into network operations (AIOps) is hindered by two fundamental challenges: the stochastic grounding problem, where LLMs struggle to reliably parse unstructured, vendor-specific CLI output, and the security gap of granting autonomous agents shell access. This paper introduces MCP-Diag, a hybrid neuro-symbolic architecture built upon the Model Context Protocol (MCP). We propose a deterministic translation layer that converts raw stdout from canonical utilities (dig, ping, traceroute) into rigorous JSON schemas before AI ingestion. We further introduce a mandatory \"Elicitation Loop\" that enforces Human-in-the-Loop (HITL) authorization at the protocol level. Our preliminary evaluation demonstrates that MCP-Diag achieving 100% entity extraction accuracy with less than 0.9% execution latency overhead and 3.7x increase in context token usage.", "AI": {"tldr": "提出了MCP-Diag架构，用于解决大型语言模型在处理网络操作中遇到的随机性解析问题和安全漏洞。", "motivation": "解决了大型语言模型难以可靠地解析结构化不强且特定供应商命令行界面输出的问题，并防止自主代理获得shell访问权限带来的安全隐患。", "method": "构建了基于模型上下文协议（MCP）的混合神经符号架构，通过确定性的翻译层将原始stdout转换为严格的JSON模式，并引入强制性的人机交互授权循环来增强安全性。", "result": "初步评估表明，MCP-Diag实现了100％实体提取准确率，执行延迟开销低于0.9%，并且上下文令牌使用量增加了3.7倍。", "conclusion": "通过MCP-Diag架构的引入，有效解决了大型语言模型在处理网络操作中的随机性和安全性问题，提高了效率和准确性。"}}
{"id": "2601.22631", "pdf": "https://arxiv.org/pdf/2601.22631", "abs": "https://arxiv.org/abs/2601.22631", "authors": ["En Fu", "Yanyan Hu", "Changhua Hu", "Zengwang Jin", "Kaixiang Peng"], "title": "PEFT-MuTS: A Multivariate Parameter-Efficient Fine-Tuning Framework for Remaining Useful Life Prediction based on Cross-domain Time Series Representation Model", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The application of data-driven remaining useful life (RUL) prediction has long been constrained by the availability of large amount of degradation data. Mainstream solutions such as domain adaptation and meta-learning still rely on large amounts of historical degradation data from equipment that is identical or similar to the target, which imposes significant limitations in practical applications. This study investigates PEFT-MuTS, a Parameter-Efficient Fine-Tuning framework for few-shot RUL prediction, built on cross-domain pre-trained time-series representation models. Contrary to the widely held view that knowledge transfer in RUL prediction can only occur within similar devices, we demonstrate that substantial benefits can be achieved through pre-training process with large-scale cross-domain time series datasets. A independent feature tuning network and a meta-variable-based low rank multivariate fusion mechanism are developed to enable the pre-trained univariate time-series representation backbone model to fully exploit the multivariate relationships in degradation data for downstream RUL prediction task. Additionally, we introduce a zero-initialized regressor that stabilizes the fine-tuning process under few-shot conditions. Experiments on aero-engine and industrial bearing datasets demonstrate that our method can achieve effective RUL prediction even when less than 1\\% of samples of target equipment are used. Meanwhile, it substantially outperforms conventional supervised and few-shot approaches while markedly reducing the data required to achieve high predictive accuracy. Our code is available at https://github.com/fuen1590/PEFT-MuTS.", "AI": {"tldr": "提出了一种基于跨域时间序列预训练模型的参数高效微调框架PEFT-MuTS，用于少样本条件下剩余使用寿命预测。", "motivation": "现有主流方法如领域适应和元学习仍然依赖大量历史退化数据，限制了其在实际应用中的使用。本文旨在探索通过跨域大规模时间序列数据预训练过程实现有效的RUL预测。", "method": "开发了一个独立特征调优网络和基于元变量的低秩多变量融合机制，使预训练的一维时间序列表示骨干模型能够充分挖掘退化数据中的多变量关系，并引入零初始化回归器稳定少样本条件下的微调过程。", "result": "实验表明，在使用不到1%目标设备样本的情况下，该方法仍然可以实现有效的RUL预测。与传统监督和少样本方法相比，其性能显著提升且大幅减少了所需的数据量以达到高预测精度。", "conclusion": "PEFT-MuTS框架证明了通过跨域大规模时间序列数据预训练过程在少样本条件下进行有效RUL预测的可行性，并展示了该方法在实际应用中的潜在价值。"}}
{"id": "2601.22630", "pdf": "https://arxiv.org/pdf/2601.22630", "abs": "https://arxiv.org/abs/2601.22630", "authors": ["Jiahao Wang", "Ting Pan", "Haoge Deng", "Dongchen Han", "Taiqiang Wu", "Xinlong Wang", "Ping Luo"], "title": "LINA: Linear Autoregressive Image Generative Models with Continuous Tokens", "categories": ["cs.CV"], "comment": "20 pages, 9 figures", "summary": "Autoregressive models with continuous tokens form a promising paradigm for visual generation, especially for text-to-image (T2I) synthesis, but they suffer from high computational cost. We study how to design compute-efficient linear attention within this framework. Specifically, we conduct a systematic empirical analysis of scaling behavior with respect to parameter counts under different design choices, focusing on (1) normalization paradigms in linear attention (division-based vs. subtraction-based) and (2) depthwise convolution for locality augmentation. Our results show that although subtraction-based normalization is effective for image classification, division-based normalization scales better for linear generative transformers. In addition, incorporating convolution for locality modeling plays a crucial role in autoregressive generation, consistent with findings in diffusion models. We further extend gating mechanisms, commonly used in causal linear attention, to the bidirectional setting and propose a KV gate. By introducing data-independent learnable parameters to the key and value states, the KV gate assigns token-wise memory weights, enabling flexible memory management similar to forget gates in language models. Based on these findings, we present LINA, a simple and compute-efficient T2I model built entirely on linear attention, capable of generating high-fidelity 1024x1024 images from user instructions. LINA achieves competitive performance on both class-conditional and T2I benchmarks, obtaining 2.18 FID on ImageNet (about 1.4B parameters) and 0.74 on GenEval (about 1.5B parameters). A single linear attention module reduces FLOPs by about 61 percent compared to softmax attention. Code and models are available at: https://github.com/techmonsterwang/LINA.", "AI": {"tldr": "该论文提出了一种基于线性注意力的简单且计算高效的文本到图像生成模型LINA，能够在用户指令下生成高保真度的1024x1024图像，并在ImageNet和GenEval基准测试中表现出色。", "motivation": "现有的连续标记自回归模型虽然在视觉生成方面有潜力，但面临计算成本高的问题。本研究旨在设计一种更高效的线性注意力机制以解决此问题。", "method": "论文通过系统实验证明了除法归一化方法比减法规则方法更适合于图像生成任务，并引入深度卷积来增强局部建模效果；同时提出KV门控机制，用于灵活的内存管理。基于这些发现提出了LINA模型。", "result": "LINA模型在ImageNet上达到2.18 FID，在GenEval上达到0.74，并且单个线性注意力模块相较于传统的softmax注意力可减少约61%的FLOPs。", "conclusion": "论文通过设计优化后的线性注意力机制，成功构建了一个高效的文本到图像生成模型LINA。"}}
{"id": "2601.22629", "pdf": "https://arxiv.org/pdf/2601.22629", "abs": "https://arxiv.org/abs/2601.22629", "authors": ["Jingxuan Wu", "Zhenglin Wan", "Xingrui Yu", "Yuzhe Yang", "Yiqiao Huang", "Ivor Tsang", "Yang You"], "title": "Time-Annealed Perturbation Sampling: Diverse Generation for Diffusion Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion language models (Diffusion-LMs) introduce an explicit temporal dimension into text generation, yet how this structure can be leveraged to control generation diversity for exploring multiple valid semantic or reasoning paths remains underexplored. In this paper, we show that Diffusion-LMs, like diffusion models in image generation, exhibit a temporal division of labor: early denoising steps largely determine the global semantic structure, while later steps focus on local lexical refinement. Building on this insight, we propose Time-Annealed Perturbation Sampling (TAPS), a training-free inference strategy that encourages semantic branching early in the diffusion process while progressively reducing perturbations to preserve fluency and instruction adherence. TAPS is compatible with both non-autoregressive and semi-autoregressive Diffusion backbones, demonstrated on LLaDA and TraDo in our paper, and consistently improves output diversity across creative writing and reasoning benchmarks without compromising generation quality.", "AI": {"tldr": "时间退火扰动采样（TAPS）是一种训练自由的推理策略，旨在通过在扩散过程早期鼓励语义分支来提高生成多样性。", "motivation": "现有研究对于如何利用文本生成中的时间维度以控制生成多样性的方法尚不完善。作者希望通过这一策略能够探索多种有效的语义或推理路径。", "method": "提出了一种训练自由的推理策略TAPS，它在扩散过程的早期阶段鼓励语义分支，并逐步减少扰动以保持流畅性和指令遵守性。该策略适用于非自回归和半自回归Diffusion骨干网络。", "result": "实验证明TAPS能够在不降低生成质量的情况下提高创造性写作和推理基准测试中的输出多样性。", "conclusion": "通过时间退火扰动采样方法，可以在保持生成质量的同时增加扩散语言模型的生成多样性。"}}
{"id": "2601.22628", "pdf": "https://arxiv.org/pdf/2601.22628", "abs": "https://arxiv.org/abs/2601.22628", "authors": ["Chengyi Yang", "Zhishang Xiang", "Yunbo Tang", "Zongpei Teng", "Chengsong Huang", "Fei Long", "Yuhan Liu", "Jinsong Su"], "title": "TTCS: Test-Time Curriculum Synthesis for Self-Evolving", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "10 pages, 4 figures, Our code and implementation details are available at https://github.com/XMUDeepLIT/TTCS", "summary": "Test-Time Training offers a promising way to improve the reasoning ability of large language models (LLMs) by adapting the model using only the test questions. However, existing methods struggle with difficult reasoning problems for two reasons: raw test questions are often too difficult to yield high-quality pseudo-labels, and the limited size of test sets makes continuous online updates prone to instability. To address these limitations, we propose TTCS, a co-evolving test-time training framework. Specifically, TTCS initializes two policies from the same pretrained model: a question synthesizer and a reasoning solver. These policies evolve through iterative optimization: the synthesizer generates progressively challenging question variants conditioned on the test questions, creating a structured curriculum tailored to the solver's current capability, while the solver updates itself using self-consistency rewards computed from multiple sampled responses on both original test and synthetic questions. Crucially, the solver's feedback guides the synthesizer to generate questions aligned with the model's current capability, and the generated question variants in turn stabilize the solver's test-time training. Experiments show that TTCS consistently strengthens the reasoning ability on challenging mathematical benchmarks and transfers to general-domain tasks across different LLM backbones, highlighting a scalable path towards dynamically constructing test-time curricula for self-evolving. Our code and implementation details are available at https://github.com/XMUDeepLIT/TTCS.", "AI": {"tldr": "TTCS框架在测试时间通过自适应生成问题来提升语言模型的推理能力。", "motivation": "现有方法难以解决困难的推理问题，因测试集规模有限导致更新不稳定。为了解决这些问题，提出了一种可演化测试时训练框架。", "method": "初始化两个策略：一个是从预训练模型中提取的问题合成器和推理解算器。通过迭代优化使合成器生成越来越具有挑战性的问题变体来适应当前的解算器能力，并使用自一致性奖励更新解算器，以增强其在原始测试和合成问题上的性能。", "result": "实验表明，TTCS在数学基准上提高了模型的推理能力，在不同LLM后端的一般任务中也表现良好。", "conclusion": "动态构建测试时课程为自我演化提供了一条可扩展路径。"}}
{"id": "2601.22627", "pdf": "https://arxiv.org/pdf/2601.22627", "abs": "https://arxiv.org/abs/2601.22627", "authors": ["Yuqing Xiao", "John Grundy", "Anuradha Madugalla", "Elizabeth Manias"], "title": "Elderly HealthMag: Systematic Building and Calibrating a Tool for Identifying and Evaluating Senior User Digital Health Software", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "Digital health (DH) software is increasingly deployed to populations where many end users live with one or more health conditions. Yet, DH software development teams frequently operate using implicit, incorrect assumptions about these users, resulting in products that under-serve the specific requirements imposed by their age and health conditions. Consequently, while software may meet clinical objectives on paper, it often fails to be inclusive during actual user interaction. To address this, we propose \\textbf{\\textit{HealthMag}}, a tool inspired by GenderMag designed to help better elicit, model and evaluate requirements for digital health software. We developed HealthMag through systematic mapping and calibration following the InclusiveMag framework. Furthermore, we integrated this with a calibrated version of an existing AgeMag method to create a dual-lens approach: \\textbf{\\textit{Elderly HealthMag}}, designed to aid requirements, design and evaluation of mHealth software for senior end users. We demonstrate application and utility of Age HealthMag via cognitive walkthroughs in identifying inclusivity biases in current senior user-oriented digital health applications.", "AI": {"tldr": "提出并验证一种名为Elderly HealthMag的工具，旨在帮助更好地提炼和评估为老年人设计的数字健康软件的需求。", "motivation": "为了改进面向患有各种健康状况的老年用户的数字健康（DH）软件开发流程，解决当前产品常因隐含错误假设导致不满足特定需求的问题", "method": "通过系统映射和校准过程发展了Elderly HealthMag工具，并结合现有AgeMag方法创建了一个双镜头评估框架。", "result": "利用认知走查展示了Elderly HealthMag在识别当前老年用户导向数字健康应用程序中的包容性偏差方面的应用及效用。", "conclusion": "Elderly HealthMag是一个有效的工具，可以用于需求分析、设计和评估针对老年人的mHealth软件。"}}
{"id": "2601.22624", "pdf": "https://arxiv.org/pdf/2601.22624", "abs": "https://arxiv.org/abs/2601.22624", "authors": ["Zepei Yu", "Zhiyang Huang", "Hongshu Guo", "Yue-Jiao Gong", "Zeyuan Ma"], "title": "COBRA++: Enhanced COBRA Optimizer with Augmented Surrogate Pool and Reinforced Surrogate Selection", "categories": ["cs.NE"], "comment": null, "summary": "The optimization problems in realistic world present significant challenges onto optimization algorithms, such as the expensive evaluation issue and complex constraint conditions. COBRA optimizer (including its up-to-date variants) is a representative and effective tool for addressing such optimization problems, which introduces 1) RBF surrogate to reduce online evaluation and 2) bi-stage optimization process to alternate search for feasible solution and optimal solution. Though promising, its design space, i.e., surrogate model pool and selection standard, is still manually decided by human expert, resulting in labor-intensive fine-tuning for novel tasks. In this paper, we propose a learning-based adaptive strategy (COBRA++) that enhances COBRA in two aspects: 1) An augmented surrogate pool to break the tie with RBF-like surrogate and hence enhances model diversity and approximation capability; 2) A reinforcement learning-based online model selection policy that empowers efficient and accurate optimization process. The model selection policy is trained to maximize overall performance of COBRA++ across a distribution of constrained optimization problems with diverse properties. We have conducted multi-dimensional validation experiments and demonstrate that COBRA++ achieves substantial performance improvement against vanilla COBRA and its adaptive variant. Ablation studies are provided to support correctness of each design component in COBRA++.", "AI": {"tldr": "本文提出了一种增强的COBRA优化器(COBRA++)，通过增加代理模型池和使用强化学习在线选择策略来提高性能。", "motivation": "在实际世界中，优化问题面临着昂贵评估和复杂约束等挑战。虽然现有的COBRA优化器已经取得了显著效果，但其设计空间依然需要人工调整以适应新任务，这导致了精细调参的繁琐性。", "method": "本文提出了一种基于学习的自适应策略(COBRA++)来增强COBRA，在两个方面进行了改进：1) 扩展代理模型池来打破单一RBF样式的限制，增加模型多样性和逼近能力；2) 使用强化学习在线选择政策，以提高优化过程的效率和准确性。", "result": "实验结果表明，COBRA++相比于原版COBRA及其自适应变体在性能上有显著提升。通过消融研究验证了COBRA++中每个设计组件的有效性。", "conclusion": "本文提出的COBRA++增强了COBRA的优化能力，并且通过多维实验验证了其优越性，为解决复杂约束优化问题提供了一种有效的方法。"}}
{"id": "2601.22623", "pdf": "https://arxiv.org/pdf/2601.22623", "abs": "https://arxiv.org/abs/2601.22623", "authors": ["Wei Zhu", "Zhiwen Tang", "Kun Yue"], "title": "SYMPHONY: Synergistic Multi-agent Planning with Heterogeneous Language Model Assembly", "categories": ["cs.AI", "cs.MA"], "comment": "Accepted by NeurIPS 2025", "summary": "Recent advancements have increasingly focused on leveraging large language models (LLMs) to construct autonomous agents for complex problem-solving tasks. However, existing approaches predominantly employ a single-agent framework to generate search branches and estimate rewards during Monte Carlo Tree Search (MCTS) planning. This single-agent paradigm inherently limits exploration capabilities, often resulting in insufficient diversity among generated branches and suboptimal planning performance. To overcome these limitations, we propose Synergistic Multi-agent Planning with Heterogeneous langauge model assembly (SYMPHONY), a novel multi-agent planning framework that integrates a pool of heterogeneous language model-based agents. By leveraging diverse reasoning patterns across agents, SYMPHONY enhances rollout diversity and facilitates more effective exploration. Empirical results across multiple benchmark tasks show that SYMPHONY achieves strong performance even when instantiated with open-source LLMs deployable on consumer-grade hardware. When enhanced with cloud-based LLMs accessible via API, SYMPHONY demonstrates further improvements, outperforming existing state-of-the-art baselines and underscoring the effectiveness of heterogeneous multi-agent coordination in planning tasks.", "AI": {"tldr": "SYMPHONY是通过异构语言模型的多智能体规划框架来提升复杂任务求解效率。", "motivation": "现有单一智能体框架在蒙特卡洛树搜索中的探索能力有限，导致生成分支多样性不足和计划性能不佳。为此提出一种新的多智能体协同方法以解决这些问题。", "method": "SYMPHONY通过集成多个异构语言模型的智能体来增强回放多样性和更有效的探索，从而提高复杂任务求解效率。", "result": "实验结果表明，在使用开源LLM和云部署的LLM时，SYMPHONY在多项基准任务上表现出色，并优于现有最佳方法。", "conclusion": "异构多智能体协同框架能够显著改善规划任务中的搜索多样性并提高性能。"}}
{"id": "2601.22617", "pdf": "https://arxiv.org/pdf/2601.22617", "abs": "https://arxiv.org/abs/2601.22617", "authors": ["Hongxi Yan", "Qingjie Liu", "Yunhong Wang"], "title": "EntroCut: Entropy-Guided Adaptive Truncation for Efficient Chain-of-Thought Reasoning in Small-scale Large Reasoning Models", "categories": ["cs.AI"], "comment": "Accepted by ICASSP26", "summary": "Large Reasoning Models (LRMs) excel at complex reasoning tasks through extended chain-of-thought generation, but their reliance on lengthy intermediate steps incurs substantial computational cost. We find that the entropy of the model's output distribution in early reasoning steps reliably distinguishes correct from incorrect reasoning. Motivated by this observation, we propose EntroCut, a training-free method that dynamically truncates reasoning by identifying high-confidence states where reasoning can be safely terminated. To comprehensively evaluate the trade-off between efficiency and accuracy, we introduce the Efficiency-Performance Ratio (EPR), a unified metric that quantifies relative token savings per unit accuracy loss. Experiments on four benchmarks show that EntroCut reduces token usage by up to 40\\% with minimal accuracy sacrifice, achieving superior efficiency-performance trade-offs compared with existing training-free methods. These results demonstrate that entropy-guided dynamic truncation provides a practical approach to mitigate the inefficiency of LRMs.", "AI": {"tldr": "通过熵引导的动态截断来提高大型推理模型（LRMs）在复杂任务中的效率。", "motivation": "观察到模型输出分布的熵可以在早期步骤中区分正确的和错误的推理，提出了一种无训练的方法以减少计算成本。", "method": "提出了Entropy-Guided Adaptive Truncation (EntroCut)，通过识别高置信度状态来动态终止推理过程。引入Efficiency-Performance Ratio（EPR）作为衡量效率与准确性的统一指标。", "result": "实验表明，相对于现有无训练方法，该方法可以减少高达40%的令牌使用量，同时保持准确性损失最小化。", "conclusion": "熵引导动态截断为降低大型推理模型的低效性提供了一种实用的方法。"}}
{"id": "2601.22616", "pdf": "https://arxiv.org/pdf/2601.22616", "abs": "https://arxiv.org/abs/2601.22616", "authors": ["Xing Yi", "Jinyang Huang", "Feng-Qi Cui", "Anyang Tong", "Ruimin Wang", "Liu Liu", "Dan Guo"], "title": "UniGeo: A Unified 3D Indoor Object Detection Framework Integrating Geometry-Aware Learning and Dynamic Channel Gating", "categories": ["cs.CV"], "comment": null, "summary": "The growing adoption of robotics and augmented reality in real-world applications has driven considerable research interest in 3D object detection based on point clouds. While previous methods address unified training across multiple datasets, they fail to model geometric relationships in sparse point cloud scenes and ignore the feature distribution in significant areas, which ultimately restricts their performance. To deal with this issue, a unified 3D indoor detection framework, called UniGeo, is proposed. To model geometric relations in scenes, we first propose a geometry-aware learning module that establishes a learnable mapping from spatial relationships to feature weights, which enabes explicit geometric feature enhancement. Then, to further enhance point cloud feature representation, we propose a dynamic channel gating mechanism that leverages learnable channel-wise weighting. This mechanism adaptively optimizes features generated by the sparse 3D U-Net network, significantly enhancing key geometric information. Extensive experiments on six different indoor scene datasets clearly validate the superior performance of our method.", "AI": {"tldr": "提出了一种名为UniGeo的统一室内三维物体检测框架，该框架结合了几何感知学习模块和动态通道门控机制。", "motivation": "现有的方法虽然解决了跨多个数据集的联合训练问题，但未能充分建模稀疏点云场景中的几何关系，并忽视了关键区域内的特征分布。这限制了它们的表现。", "method": "该框架包含一个几何感知学习模块和一种动态通道门控机制。前者通过可学习的空间关系到特征权重的映射来增强显式的几何特性，后者则利用通道级别的加权来自适应地优化稀疏3D U-Net网络生成的特征。", "result": "在六个不同的室内场景数据集上的大量实验清楚地验证了该方法的优越性能。", "conclusion": "UniGeo框架通过结合几何感知学习和动态通道门控机制，显著提升了点云特征表示，并且在多个数据集上表现出色。"}}
{"id": "2601.22615", "pdf": "https://arxiv.org/pdf/2601.22615", "abs": "https://arxiv.org/abs/2601.22615", "authors": ["Zhijie Zheng", "Xinhao Xiang", "Jiawei Zhang"], "title": "TTSA3R: Training-Free Temporal-Spatial Adaptive Persistent State for Streaming 3D Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Streaming recurrent models enable efficient 3D reconstruction by maintaining persistent state representations. However, they suffer from catastrophic memory forgetting over long sequences due to balancing historical information with new observations. Recent methods alleviate this by deriving adaptive signals from attention perspective, but they operate on single dimensions without considering temporal and spatial consistency. To this end, we propose a training-free framework termed TTSA3R that leverages both temporal state evolution and spatial observation quality for adaptive state updates in 3D reconstruction. In particular, we devise a Temporal Adaptive Update Module that regulates update magnitude by analyzing temporal state evolution patterns. Then, a Spatial Contextual Update Module is introduced to localize spatial regions that require updates through observation-state alignment and scene dynamics. These complementary signals are finally fused to determine the state updating strategies. Extensive experiments demonstrate the effectiveness of TTSA3R in diverse 3D tasks. Moreover, our method exhibits only 15% error increase compared to over 200% degradation in baseline models on extended sequences, significantly improving long-term reconstruction stability. Our codes will be available soon.", "AI": {"tldr": "提出了一种无训练的框架TTSA3R，用于在3D重建中通过时空适应性持久状态更新来解决长期序列记忆遗忘问题。", "motivation": "为了克服流式递归模型在长时间序列中的记忆遗忘问题，并考虑时间和空间的一致性，提出了一个新的无训练框架。", "method": "TTSA3R包括时间自适应更新模块和空间上下文更新模块。前者通过分析时间状态演进模式来调节更新幅度；后者通过观察-状态对齐和场景动态确定需要更新的空间区域。", "result": "实验表明，相比基础模型在扩展序列上的性能下降超过200%，TTSA3R仅增加了15%的误差，显著提高了长期重建稳定性。", "conclusion": "提出的方法有效解决了流式递归模型中的记忆遗忘问题，并且通过时空适应性更新策略提高了长时序数据的重建精度和稳定性。"}}
{"id": "2601.22610", "pdf": "https://arxiv.org/pdf/2601.22610", "abs": "https://arxiv.org/abs/2601.22610", "authors": ["Xiayu Liu", "Zhengyi Lu", "Yunhong Liao", "Chan Fan", "Hou-biao Li"], "title": "Local-Global Multimodal Contrastive Learning for Molecular Property Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 9 figures. Submitted to Briefings in Bioinformatics", "summary": "Accurate molecular property prediction requires integrating complementary information from molecular structure and chemical semantics. In this work, we propose LGM-CL, a local-global multimodal contrastive learning framework that jointly models molecular graphs and textual representations derived from SMILES and chemistry-aware augmented texts. Local functional group information and global molecular topology are captured using AttentiveFP and Graph Transformer encoders, respectively, and aligned through self-supervised contrastive learning. In addition, chemically enriched textual descriptions are contrasted with original SMILES to incorporate physicochemical semantics in a task-agnostic manner. During fine-tuning, molecular fingerprints are further integrated via Dual Cross-attention multimodal fusion. Extensive experiments on MoleculeNet benchmarks demonstrate that LGM-CL achieves consistent and competitive performance across both classification and regression tasks, validating the effectiveness of unified local-global and multimodal representation learning.", "AI": {"tldr": "提出LGM-CL框架，结合分子图和文本表示进行分子性质预测。", "motivation": "准确的分子属性预测需要整合结构信息与化学语义。通过局部功能团信息和全局拓扑信息的有效融合以及自监督对比学习，提高分子性质预测性能。", "method": "利用AttentiveFP编码器捕捉局部功能性组信息、Graph Transformer编码器捕获全局分子拓扑，并通过自我监督对比学习对齐；化学增强文本描述与原始SMILES的对比结合，再通过双重交叉注意多模态融合细化指纹。", "result": "在MoleculeNet基准测试中展示了LGM-CL框架在分类和回归任务上的一致性和竞争力表现。", "conclusion": "统一局部全局及多模态表示学习有效提升分子性质预测性能。"}}
{"id": "2601.22609", "pdf": "https://arxiv.org/pdf/2601.22609", "abs": "https://arxiv.org/abs/2601.22609", "authors": ["Anastasiia Tkachenko", "Haitao Wang"], "title": "Computing Dominating Sets in Disk Graphs with Centers in Convex Position", "categories": ["cs.CG", "cs.DS"], "comment": "To appear in LATIN 2026", "summary": "Given a set $P$ of $n$ points in the plane and a collection of disks centered at these points, the disk graph $G(P)$ has vertex set $P$, with an edge between two vertices if their corresponding disks intersect. We study the dominating set problem in $G(P)$ under the special case where the points of $P$ are in convex position. The problem is NP-hard in general disk graphs. Under the convex position assumption, however, we present the first polynomial-time algorithm for the problem. Specifically, we design an $O(k^2 n \\log^2 n)$-time algorithm, where $k$ denotes the size of a minimum dominating set. For the weighted version, in which each disk has an associated weight and the goal is to compute a dominating set of minimum total weight, we obtain an $O(n^5 \\log^2 n)$-time algorithm.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.22607", "pdf": "https://arxiv.org/pdf/2601.22607", "abs": "https://arxiv.org/abs/2601.22607", "authors": ["Jiaxuan Gao", "Jiaao Chen", "Chuyi He", "Wei-Chen Wang", "Shusheng Xu", "Hanrui Wang", "Di Jin", "Yi Wu"], "title": "From Self-Evolving Synthetic Data to Verifiable-Reward RL: Post-Training Multi-turn Interactive Tool-Using Agents", "categories": ["cs.AI", "cs.CL"], "comment": "Submitted to ICML 2026", "summary": "Interactive tool-using agents must solve real-world tasks via multi-turn interaction with both humans and external environments, requiring dialogue state tracking, multi-step tool execution, while following complex instructions. Post-training such agents is challenging because synthesis for high-quality multi-turn tool-use data is difficult to scale, and reinforcement learning (RL) could face noisy signals caused by user simulation, leading to degraded training efficiency. We propose a unified framework that combines a self-evolving data agent with verifier-based RL. Our system, EigenData, is a hierarchical multi-agent engine that synthesizes tool-grounded dialogues together with executable per-instance checkers, and improves generation reliability via closed-loop self-evolving process that updates prompts and workflow. Building on the synthetic data, we develop an RL recipe that first fine-tunes the user model and then applies GRPO-style training with trajectory-level group-relative advantages and dynamic filtering, yielding consistent improvements beyond SFT. Evaluated on tau^2-bench, our best model reaches 73.0% pass^1 on Airline and 98.3% pass^1 on Telecom, matching or exceeding frontier models. Overall, our results suggest a scalable pathway for bootstrapping complex tool-using behaviors without expensive human annotation.", "AI": {"tldr": "本文提出了一种结合自演进数据代理和基于验证的强化学习（RL）框架，用于后训练多轮互动工具使用的智能体。", "motivation": "交互式工具使用智能体需要解决与人类及外部环境进行多回合对话的任务，这要求精确的状态追踪、分步工具执行以及遵守复杂指令。然而，高质量多回合工具使用数据的合成难以扩展，强化学习可能受到用户模拟噪声的影响，导致训练效率降低。", "method": "作者提出了一种结合自演进数据代理和基于验证的RL框架的方法，该系统为EigenData，是一个分层多智能体引擎，能够生成具有可执行实例检查器的工具相关对话，并通过闭环自我演化过程提高生成可靠性。基于合成数据，他们开发了一个RL食谱，首先微调用户模型，然后应用GRPO样式的训练方法。", "result": "在tau^2-bench上评估，最佳模型在Airline任务中的pass^1达到73.0%，在Telecom任务中达到98.3%，超过了前沿模型的表现。", "conclusion": "研究结果表明，一种可扩展的路径可以用于无需昂贵的人工标注而引导复杂的工具使用行为。"}}
{"id": "2601.22599", "pdf": "https://arxiv.org/pdf/2601.22599", "abs": "https://arxiv.org/abs/2601.22599", "authors": ["Kai Li", "Jintao Cheng", "Chang Zeng", "Zijun Yan", "Helin Wang", "Zixiong Su", "Bo Zheng", "Xiaolin Hu"], "title": "A Semantically Consistent Dataset for Data-Efficient Query-Based Universal Sound Separation", "categories": ["cs.SD", "cs.HC"], "comment": "Technical Report", "summary": "Query-based universal sound separation is fundamental to intelligent auditory systems, aiming to isolate specific sources from mixtures. Despite recent advances, existing methods continue to suffer from residual interference in complex acoustic scenes. This performance limitation stems largely from a data bottleneck: in-the-wild datasets contain weak labels and severe co-occurrence of events. These flaws induce models to learn spurious correlations between background noise and target categories instead of robust acoustic features. To address this, we propose an automated pipeline that eliminates co-occurrence of events by mining high-purity single-event segments from in-the-wild datasets via a semantically consistent synthesis protocol. Utilizing this pipeline, we constructed Hive, a high-quality synthetic dataset comprising 2.4k hours of raw audio. Experimental results demonstrate that, compared with the state-of-the-art model SAM-Audio which was trained on a huge dataset $\\sim$500 times larger than Hive, certain open-source models trained on Hive achieve competitive separation accuracy and perceptual quality. Moreover, these models exhibited remarkable zero-shot generalization on out-of-distribution evaluation benchmarks. These findings highlight that prioritizing purity of supervised signals enables significant data efficiency, offering a new paradigm for training robust auditory foundation models with reduced computational costs. Code and dataset are available at https://shandaai.github.io/Hive.", "AI": {"tldr": "构建了一个高纯度声音分离数据集，提高了模型在复杂场景下的性能和泛化能力。", "motivation": "现有的数据集中存在标签弱和事件共现的问题，导致模型学习到错误的相关性而非稳健的声学特征。", "method": "提出了一种自动管道，通过语义一致性的合成协议从野外数据集挖掘高纯度单事件片段，构建了一个名为Hive的数据集。", "result": "实验表明，在比现有最佳方法小500倍的数据集上训练的开源模型达到了相近的声音分离准确率和感知质量，并在未见过的数据上表现出零样本泛化能力。", "conclusion": "优先考虑监督信号的纯度可以提高数据效率，为训练稳健的听觉基础模型提供了一种新范式。"}}
{"id": "2601.22596", "pdf": "https://arxiv.org/pdf/2601.22596", "abs": "https://arxiv.org/abs/2601.22596", "authors": ["Abdelrrahman Moubane"], "title": "FOTBCD: A Large-Scale Building Change Detection Benchmark from French Orthophotos and Topographic Data", "categories": ["cs.CV"], "comment": null, "summary": "We introduce FOTBCD, a large-scale building change detection dataset derived from authoritative French orthophotos and topographic building data provided by IGN France. Unlike existing benchmarks that are geographically constrained to single cities or limited regions, FOTBCD spans 28 departments across mainland France, with 25 used for training and three geographically disjoint departments held out for evaluation. The dataset covers diverse urban, suburban, and rural environments at 0.2m/pixel resolution. We publicly release FOTBCD-Binary, a dataset comprising approximately 28,000 before/after image pairs with pixel-wise binary building change masks, each associated with patch-level spatial metadata. The dataset is designed for large-scale benchmarking and evaluation under geographic domain shift, with validation and test samples drawn from held-out departments and manually verified to ensure label quality. In addition, we publicly release FOTBCD-Instances, a publicly available instance-level annotated subset comprising several thousand image pairs, which illustrates the complete annotation schema used in the full instance-level version of FOTBCD. Using a fixed reference baseline, we benchmark FOTBCD-Binary against LEVIR-CD+ and WHU-CD, providing strong empirical evidence that geographic diversity at the dataset level is associated with improved cross-domain generalization in building change detection.", "AI": {"tldr": "本文介绍了FOTBCD，一个来自法国权威正射图像和地形建筑数据的大规模建筑物变化检测基准集。", "motivation": "现有基准仅限于单个城市或有限区域，而FOTBCD则覆盖了28个法国地区，目的是为地理领域转换提供大规模基准测试和评估。", "method": "该研究公开发布了包含约28,000对前后图像及其像素级二进制建筑物变化掩码的FOTBCD-Binary数据集，并且还提供了若干千对图像实例级别的注释子集FOTBCD-Instances，以展示全面的注释模式。", "result": "通过固定的参考基准线，该研究将FOTBCD-Binary与LEVIR-CD+和WHU-CD进行了比较，结果表明数据集层面的地理多样性可改善跨域泛化能力。", "conclusion": "FOTBCD是第一个大规模且地理多样化的建筑物变化检测基准，为未来的模型提供了更多训练和验证的机会。"}}
{"id": "2601.22595", "pdf": "https://arxiv.org/pdf/2601.22595", "abs": "https://arxiv.org/abs/2601.22595", "authors": ["Hao Yi", "Yulan Hu", "Xin Li", "Sheng Ouyang", "Lizhong Ding", "Yong Liu"], "title": "Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have recently improved mathematical reasoning through Reinforcement Learning with Verifiable Reward (RLVR). However, existing RLVR algorithms require large query budgets, making annotation costly. We investigate whether fewer but more informative queries can yield similar or superior performance, introducing active learning (AL) into RLVR. We identify that classic AL sampling strategies fail to outperform random selection in this setting, due to ignoring objective uncertainty when only selecting by subjective uncertainty. This work proposes an uncertainty consistency metric to evaluate how well subjective uncertainty aligns with objective uncertainty. In the offline setting, this alignment is measured using the Point-Biserial Correlation Coefficient (PBC). For online training, because of limited sampling and dynamically shifting output distributions, PBC estimation is difficult. Therefore, we introduce a new online variant, computed from normalized advantage and subjective uncertainty. Theoretically, we prove that the online variant is strictly negatively correlated with offline PBC and supports better sample selection. Experiments show our method consistently outperforms random and classic AL baselines, achieving full-dataset performance while training on only 30% of the data, effectively reducing the cost of RLVR for reasoning tasks.", "AI": {"tldr": "该论文提出了一种基于不确定性一致性度量的主动学习方法，以减少强化学习与验证奖励（RLVR）中所需的查询次数。", "motivation": "现有的RLVR算法需要大量的查询预算，这使得标注变得昂贵。作者研究了是否可以通过更少但更有信息量的查询来获得类似的或更好的性能，并引入了主动学习到RLVR中以减少成本。", "method": "论文提出了一种基于主观不确定性和客观不确定性之间一致性度量的新方法。在线环境下，由于采样有限和输出分布动态变化，点双列相关系数（PBC）难以估计，因此提出了一个通过归一化优势和主观不确定性计算的新的在线变体。", "result": "实验表明所提出的方法在训练数据仅占全部数据集30%的情况下能达成全数据集性能，并且超过了随机选择和其他经典主动学习基准方法的表现。", "conclusion": "该研究证明了基于不确定性一致性度量的新方法可以有效地减少RLVR的成本，同时保持或提高数学推理任务的性能。"}}
{"id": "2601.22594", "pdf": "https://arxiv.org/pdf/2601.22594", "abs": "https://arxiv.org/abs/2601.22594", "authors": ["Aryaman Arora", "Zhengxuan Wu", "Jacob Steinhardt", "Sarah Schwettmann"], "title": "Language Model Circuits Are Sparse in the Neuron Basis", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages main text, 41 pages total", "summary": "The high-level concepts that a neural network uses to perform computation need not be aligned to individual neurons (Smolensky, 1986). Language model interpretability research has thus turned to techniques such as \\textit{sparse autoencoders} (SAEs) to decompose the neuron basis into more interpretable units of model computation, for tasks such as \\textit{circuit tracing}. However, not all neuron-based representations are uninterpretable. For the first time, we empirically show that \\textbf{MLP neurons are as sparse a feature basis as SAEs}. We use this finding to develop an end-to-end pipeline for circuit tracing on the MLP neuron basis, which locates causal circuitry on a variety of tasks using gradient-based attribution. On a standard subject-verb agreement benchmark (Marks et al., 2025), a circuit of $\\approx 10^2$ MLP neurons is enough to control model behaviour. On the multi-hop city $\\to$ state $\\to$ capital task from Lindsey et al., 2025, we find a circuit in which small sets of neurons encode specific latent reasoning steps (e.g.~`map city to its state'), and can be steered to change the model's output. This work thus advances automated interpretability of language models without additional training costs.", "AI": {"tldr": "该论文通过实验发现MLP神经元与稀疏自动编码器一样具有稀疏性，并基于此开发了一个端到端的电路追踪管道，用于定位和控制语言模型中的因果回路。", "motivation": "当前的语言模型解释研究依赖于稀疏自动编码器来分解神经元基础以提高可解释性。然而，并非所有基于神经元的表示都是难以理解的，因此作者希望通过实验展示MLP神经元同样具有稀疏性的特征，进而开发更高效且无需额外训练成本的语言模型自动化解释方法。", "method": "通过实验证明了MLP神经元和稀疏自动编码器一样具有稀疏性，并利用这一发现开发了一个端到端的电路追踪管道，该管道能够识别并控制语言模型中的因果回路。在标准任务上应用此方法以寻找关键神经元。", "result": "实验结果显示，在一个关于主谓一致性的基准测试中，约100个MLP神经元就足以控制模型行为；而在Lindsey等人提出的多步推理任务中，小集合的特定神经元能编码具体隐式推理步骤，并可被操控以改变模型输出。", "conclusion": "该研究证明了MLP神经元同样具有稀疏性特征，从而推动了语言模型的自动化解释过程而无需增加额外训练成本。"}}
{"id": "2601.22589", "pdf": "https://arxiv.org/pdf/2601.22589", "abs": "https://arxiv.org/abs/2601.22589", "authors": ["Yue Li", "Mingmin Chu", "Xilei Yang", "Da Xiao", "Ziqi Xu", "Wei Shao", "Qipeng Song", "Hui Li"], "title": "FedCARE: Federated Unlearning with Conflict-Aware Projection and Relearning-Resistant Recovery", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 4 figures. Submitted to IJCAI 2026", "summary": "Federated learning (FL) enables collaborative model training without centralizing raw data, but privacy regulations such as the right to be forgotten require FL systems to remove the influence of previously used training data upon request. Retraining a federated model from scratch is prohibitively expensive, motivating federated unlearning (FU). However, existing FU methods suffer from high unlearning overhead, utility degradation caused by entangled knowledge, and unintended relearning during post-unlearning recovery. In this paper, we propose FedCARE, a unified and low overhead FU framework that enables conflict-aware unlearning and relearning-resistant recovery. FedCARE leverages gradient ascent for efficient forgetting when target data are locally available and employs data free model inversion to construct class level proxies of shared knowledge. Based on these insights, FedCARE integrates a pseudo-sample generator, conflict-aware projected gradient ascent for utility preserving unlearning, and a recovery strategy that suppresses rollback toward the pre-unlearning model. FedCARE supports client, instance, and class level unlearning with modest overhead. Extensive experiments on multiple datasets and model architectures under both IID and non-IID settings show that FedCARE achieves effective forgetting, improved utility retention, and reduced relearning risk compared to state of the art FU baselines.", "AI": {"tldr": "提出FedCARE框架，用于联邦学习中高效遗忘和恢复的联邦卸载方法。", "motivation": "隐私法规要求删除训练数据的影响，而现有卸载方法存在高开销、知识纠缠导致的性能下降以及重新学习的风险。", "method": "FedCARE利用梯度上升实现高效的遗忘过程，并使用无样本生成器和冲突感知投影梯度上升策略来保持模型性能。此外，还采用抑制回滚至未卸载状态恢复策略。", "result": "在多种数据集和非IID设置下，与现有基线相比，FedCARE实现了更有效的遗忘、更高的性能保留和更低的重新学习风险。", "conclusion": "FedCARE是一个低开销且高效的联邦卸载框架，在保持模型性能的同时有效处理隐私删除请求。"}}
{"id": "2601.22588", "pdf": "https://arxiv.org/pdf/2601.22588", "abs": "https://arxiv.org/abs/2601.22588", "authors": ["Zhuochun Li", "Yong Zhang", "Ming Li", "Yuelyu Ji", "Yiming Zeng", "Ning Cheng", "Yun Zhu", "Yanmeng Wang", "Shaojun Wang", "Jing Xiao", "Daqing He"], "title": "Rethinking LLM-as-a-Judge: Representation-as-a-Judge with Small Language Models via Semantic Capacity Asymmetry", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are widely used as reference-free evaluators via prompting, but this \"LLM-as-a-Judge\" paradigm is costly, opaque, and sensitive to prompt design. In this work, we investigate whether smaller models can serve as efficient evaluators by leveraging internal representations instead of surface generation. We uncover a consistent empirical pattern: small LMs, despite with weak generative ability, encode rich evaluative signals in their hidden states. This motivates us to propose the Semantic Capacity Asymmetry Hypothesis: evaluation requires significantly less semantic capacity than generation and can be grounded in intermediate representations, suggesting that evaluation does not necessarily need to rely on large-scale generative models but can instead leverage latent features from smaller ones. Our findings motivate a paradigm shift from LLM-as-a-Judge to Representation-as-a-Judge, a decoding-free evaluation strategy that probes internal model structure rather than relying on prompted output. We instantiate this paradigm through INSPECTOR, a probing-based framework that predicts aspect-level evaluation scores from small model representations. Experiments on reasoning benchmarks (GSM8K, MATH, GPQA) show that INSPECTOR substantially outperforms prompting-based small LMs and closely approximates full LLM judges, while offering a more efficient, reliable, and interpretable alternative for scalable evaluation.", "AI": {"tldr": "本文提出了一种新的评估策略，即通过小模型的内部表示来进行评估而非依赖大规模生成模型。", "motivation": "LLM作为评判者存在成本高、不透明及对提示设计敏感的问题。研究发现小型语言模型在其隐藏状态中编码了丰富的评价信号，提出了“语义容量不对称假设”，表明评价所需的语义容量远小于生成任务，并可基于中间表示进行评估。", "method": "通过INSPECTOR框架从小模型的内部结构中预测方面层面的评价分数，实现无解码的评估策略。", "result": "实验结果证明了INSPECTOR在推理基准测试中的表现优于基于提示的小型语言模型，并接近大型LLM评判者的性能。", "conclusion": "研究支持了一种从“LLM作为评判者”到“内部表示作为评判者”的范式转变，提供了一个更高效、可靠且可解释的规模化评估替代方案。"}}
{"id": "2601.22586", "pdf": "https://arxiv.org/pdf/2601.22586", "abs": "https://arxiv.org/abs/2601.22586", "authors": ["Qian Hong", "Siyuan Chang", "Xiao Zhou"], "title": "WED-Net: A Weather-Effect Disentanglement Network with Causal Augmentation for Urban Flow Prediction", "categories": ["cs.AI"], "comment": "The ACM on Web Conference 2026 (WWW'26)", "summary": "Urban spatio-temporal prediction under extreme conditions (e.g., heavy rain) is challenging due to event rarity and dynamics. Existing data-driven approaches that incorporate weather as auxiliary input often rely on coarse-grained descriptors and lack dedicated mechanisms to capture fine-grained spatio-temporal effects. Although recent methods adopt causal techniques to improve out-of-distribution generalization, they typically overlook temporal dynamics or depend on fixed confounder stratification. To address these limitations, we propose WED-Net (Weather-Effect Disentanglement Network), a dual-branch Transformer architecture that separates intrinsic and weather-induced traffic patterns via self- and cross-attention, enhanced with memory banks and fused through adaptive gating. To further promote disentanglement, we introduce a discriminator that explicitly distinguishes weather conditions. Additionally, we design a causal data augmentation strategy that perturbs non-causal parts while preserving causal structures, enabling improved generalization under rare scenarios. Experiments on taxi-flow datasets from three cities demonstrate that WED-Net delivers robust performance under extreme weather conditions, highlighting its potential to support safer mobility, highlighting its potential to support safer mobility, disaster preparedness, and urban resilience in real-world settings. The code is publicly available at https://github.com/HQ-LV/WED-Net.", "AI": {"tldr": "WED-Net是一种用于城市流量预测的天气影响解耦网络，能够处理极端天气条件下的数据稀疏性和动态性。", "motivation": "现有的基于数据驱动的方法在处理极端天气条件下城市时空预测时存在不足，如依赖粗粒度描述符和缺乏专门机制捕捉细粒度时空效应。为解决这些问题，提出了WED-Net网络。", "method": "采用双支Transformer架构分离内在和由天气引起的交通模式，并通过自注意力、交叉注意力增强与适应性门融合，设计了鉴别器明确区分不同天气状况并引入因果数据增强策略。", "result": "在三个城市的出租车流数据集上进行实验，WED-Net展示了其在极端天气条件下的稳健性能。", "conclusion": "WED-Net有助于支持安全移动、灾害准备和城市韧性，并已在公开平台上发布。"}}
{"id": "2601.22584", "pdf": "https://arxiv.org/pdf/2601.22584", "abs": "https://arxiv.org/abs/2601.22584", "authors": ["Qiangpeng Fang", "Jilong Shi", "Xiaobin Rui", "Jian Zhang", "Zhixiao Wang"], "title": "Scalable Fair Influence Blocking Maximization via Approximately Monotonic Submodular Optimization", "categories": ["cs.DS"], "comment": "12 pages (including Appendix), 5 figures", "summary": "Influence Blocking Maximization (IBM) aims to select a positive seed set to suppress the spread of negative influence. However, existing IBM methods focus solely on maximizing blocking effectiveness, overlooking fairness across communities. To address this issue, we formalize fairness in IBM and justify Demographic Parity (DP) as a notion that is particularly well aligned with its semantics. Yet enforcing DP is computationally challenging: prior work typically formulates DP as a Linear Programming (LP) problem and relies on costly solvers, rendering them impractical for large-scale networks. In this paper, we propose a DP-aware objective while maintaining an approximately monotonic submodular structure, enabling efficient optimization with theoretical guarantees. We integrate this objective with blocking effectiveness through a tunable scalarization, yielding a principled fairness-effectiveness trade-offs. Building on this structure, we develop CELF-R, an accelerated seed selection algorithm that exploits approximate submodularity to eliminate redundant evaluations and naturally supports Pareto front construction. Extensive experiments demonstrate that CELF-R consistently outperforms state-of-the-art baselines, achieving a $(1-1/e-ψ)$-approximate solution while maintaining high efficiency.", "AI": {"tldr": "本文提出了一种可扩展的公平影响阻塞最大化方法，该方法在保持近似单调子模结构的同时考虑了社区间的公平性。", "motivation": "现有的影响阻塞最大化（IBM）方法忽视了跨社区的公平性问题。为了改进这一点，作者引入了人口统计一致性作为衡量标准，并提出了一种新的DP感知目标函数来解决这一挑战。", "method": "本文通过设计一个新的近似单调子模结构的目标函数并结合CELFR算法以加速种子选择过程来实现高效优化。", "result": "实验表明提出的CELF-R算法在效率和性能上均优于现有基线方法，可获得$(1-1/e-ψ)$的接近最优解。", "conclusion": "该工作通过引入公平性概念并设计有效的算法解决了大规模网络中的影响阻塞最大化问题。"}}
{"id": "2601.22582", "pdf": "https://arxiv.org/pdf/2601.22582", "abs": "https://arxiv.org/abs/2601.22582", "authors": ["Youngeun Kim"], "title": "MC-GRPO: Median-Centered Group Relative Policy Optimization for Small-Rollout Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Group-relative policy optimization methods train language models by generating multiple rollouts per prompt and normalizing rewards with a shared mean reward baseline. In resource-constrained settings where the rollout budget is small, accuracy often degrades. We find that noise in the shared baseline induces advantage sign flips, where some rollouts receive an incorrect advantage sign, and the update direction is reversed. To address this, we propose Median-Centered Group Relative Policy Optimization (MC-GRPO), a simple and effective solution for small-rollout training. Our main idea is to replace the mean baseline with a median baseline: the median is far less sensitive to outlier rewards than the mean, mitigating the sign flips under small rollout size (G). We generate one additional rollout for median reference (G+1), and compute advantages by using the group median. With an odd-sized group, exactly one completion is the median and receives zero advantage, we exclude this pivot rollout from backpropagation so the number of gradient-contributing samples per prompt remains G, preserving the core update cost of standard G-rollout training. Across various GRPO-family methods and a wide range of models and scales, this median-centered training consistently improves stability and final accuracy in the low-rollout regime, reducing the gap between G=2 and G=8 to within 1%. Code is available at https://github.com/lotusroot-kim/MC-GRPO", "AI": {"tldr": "提出了一种新的策略优化方法，用于在小样本训练中提高语言模型的准确性和稳定性。", "motivation": "针对资源受限情况下的小样本训练问题，噪声引起的共享基线错误导致优势符号翻转，进而影响更新方向。", "method": "引入中位数作为基线替代平均值，减少异常奖励的影响，并生成一个额外的小样本来计算群组中位数。使用奇数大小的群组以确保每个提示下贡献梯度样本的数量保持不变。", "result": "该方法在多种GRPO家族方法和不同规模模型中的低样本训练阶段提高了稳定性和最终准确性，缩小了小样本数量之间的差距。", "conclusion": "Median-Centered Group Relative Policy Optimization（MC-GRPO）是一种简单有效的解决策略，在资源受限环境中提高了语言模型的性能稳定性。"}}
{"id": "2601.22581", "pdf": "https://arxiv.org/pdf/2601.22581", "abs": "https://arxiv.org/abs/2601.22581", "authors": ["Naeem Paeedeh", "Mahardhika Pratama", "Ary Shiddiqi", "Zehong Cao", "Mukesh Prasad", "Wisnu Jatmiko"], "title": "Cross-Domain Few-Shot Learning for Hyperspectral Image Classification Based on Mixup Foundation Model", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Although cross-domain few-shot learning (CDFSL) for hyper-spectral image (HSI) classification has attracted significant research interest, existing works often rely on an unrealistic data augmentation procedure in the form of external noise to enlarge the sample size, thus greatly simplifying the issue of data scarcity. They involve a large number of parameters for model updates, being prone to the overfitting problem. To the best of our knowledge, none has explored the strength of the foundation model, having strong generalization power to be quickly adapted to downstream tasks. This paper proposes the MIxup FOundation MOdel (MIFOMO) for CDFSL of HSI classifications. MIFOMO is built upon the concept of a remote sensing (RS) foundation model, pre-trained across a large scale of RS problems, thus featuring generalizable features. The notion of coalescent projection (CP) is introduced to quickly adapt the foundation model to downstream tasks while freezing the backbone network. The concept of mixup domain adaptation (MDM) is proposed to address the extreme domain discrepancy problem. Last but not least, the label smoothing concept is implemented to cope with noisy pseudo-label problems. Our rigorous experiments demonstrate the advantage of MIFOMO, where it beats prior arts with up to 14% margin. The source code of MIFOMO is open-sourced in https://github.com/Naeem- Paeedeh/MIFOMO for reproducibility and convenient further study.", "AI": {"tldr": "提出了一种基于混合基础模型的跨域少样本学习方法，用于高光谱图像分类。", "motivation": "现有研究中跨域少样本学习依赖于外部噪声数据增强方式，这简化了数据稀缺问题，并容易导致过拟合。本文旨在探索基础模型在解决这些问题中的优势。", "method": "提出了MIFOMO方法，基于预训练的遥感基础模型和混合领域自适应策略来快速适应下游任务。通过引入联合投影（CP）技术冻结主干网络并保持特征泛化能力，并使用标签平滑处理噪声伪标签问题。", "result": "实验结果表明，MIFOMO在跨域少样本学习中优于现有方法，性能提升高达14%。", "conclusion": "证明了基于混合基础模型的方法在高光谱图像分类中的有效性。开源代码可供进一步研究使用。"}}
{"id": "2601.22580", "pdf": "https://arxiv.org/pdf/2601.22580", "abs": "https://arxiv.org/abs/2601.22580", "authors": ["Chao Wang", "Bei Li", "Jiaqi Zhang", "Xinyu Liu", "Yuchun Fan", "Linkun Lyu", "Xin Chen", "Jingang Wang", "Tong Xiao", "Peng Pei", "Xunliang Cai"], "title": "SpanNorm: Reconciling Training Stability and Performance in Deep Transformers", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The success of Large Language Models (LLMs) hinges on the stable training of deep Transformer architectures. A critical design choice is the placement of normalization layers, leading to a fundamental trade-off: the ``PreNorm'' architecture ensures training stability at the cost of potential performance degradation in deep models, while the ``PostNorm'' architecture offers strong performance but suffers from severe training instability. In this work, we propose SpanNorm, a novel technique designed to resolve this dilemma by integrating the strengths of both paradigms. Structurally, SpanNorm establishes a clean residual connection that spans the entire transformer block to stabilize signal propagation, while employing a PostNorm-style computation that normalizes the aggregated output to enhance model performance. We provide a theoretical analysis demonstrating that SpanNorm, combined with a principled scaling strategy, maintains bounded signal variance throughout the network, preventing the gradient issues that plague PostNorm models, and also alleviating the representation collapse of PreNorm. Empirically, SpanNorm consistently outperforms standard normalization schemes in both dense and Mixture-of-Experts (MoE) scenarios, paving the way for more powerful and stable Transformer architectures.", "AI": {"tldr": "该论文提出了一种新的规范化技术SpanNorm，旨在解决Transformer架构在训练稳定性和性能之间的矛盾。", "motivation": "大型语言模型的成功依赖于深度Transformer架构的稳定训练。然而现有的PreNorm和PostNorm设计分别牺牲了性能或稳定性。", "method": "SpanNorm通过在整个变压器块中建立干净的残差连接来稳定信号传播，并采用类似于PostNorm样式的计算方法对聚合输出进行规范化，以增强模型性能。", "result": "理论上，结合合理的缩放策略，SpanNorm可保持网络中的有界信号方差。实验表明，在密集和混合专家（MoE）场景下，SpanNorm始终优于标准的规范化方案。", "conclusion": "SpanNorm不仅解决了训练稳定性和表现力之间的困境，还为更强大和稳定的Transformer架构铺平了道路。"}}
{"id": "2601.22578", "pdf": "https://arxiv.org/pdf/2601.22578", "abs": "https://arxiv.org/abs/2601.22578", "authors": ["Chengyang Zhou", "Zijian Zhang", "Chunxu Zhang", "Hao Miao", "Yulin Zhang", "Kedi Lyu", "Juncheng Hu"], "title": "FedDis: A Causal Disentanglement Framework for Federated Traffic Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning offers a promising paradigm for privacy-preserving traffic prediction, yet its performance is often challenged by the non-identically and independently distributed (non-IID) nature of decentralized traffic data. Existing federated methods frequently struggle with this data heterogeneity, typically entangling globally shared patterns with client-specific local dynamics within a single representation. In this work, we postulate that this heterogeneity stems from the entanglement of two distinct generative sources: client-specific localized dynamics and cross-client global spatial-temporal patterns. Motivated by this perspective, we introduce FedDis, a novel framework that, to the best of our knowledge, is the first to leverage causal disentanglement for federated spatial-temporal prediction. Architecturally, FedDis comprises a dual-branch design wherein a Personalized Bank learns to capture client-specific factors, while a Global Pattern Bank distills common knowledge. This separation enables robust cross-client knowledge transfer while preserving high adaptability to unique local environments. Crucially, a mutual information minimization objective is employed to enforce informational orthogonality between the two branches, thereby ensuring effective disentanglement. Comprehensive experiments conducted on four real-world benchmark datasets demonstrate that FedDis consistently achieves state-of-the-art performance, promising efficiency, and superior expandability.", "AI": {"tldr": "提出FedDis框架，使用因果解耦方法进行联邦交通预测。", "motivation": "现有联邦学习方法在处理非同分布的分散交通数据时性能受限，因为它们无法有效区分全局共享模式和客户端特定动态。", "method": "通过双分支设计，FedDis包括个人银行捕捉客户特有因素，全球模式银行提炼公共知识。使用互信息最小化目标确保两部分的信息正交性以实现解耦。", "result": "实验显示FedDis在四个真实世界数据集上达到最佳性能，并展现出高效性和可扩展性。", "conclusion": "FedDis通过因果解耦成功提升了联邦交通预测的效率和适应能力。"}}
{"id": "2601.22576", "pdf": "https://arxiv.org/pdf/2601.22576", "abs": "https://arxiv.org/abs/2601.22576", "authors": ["Hanjiang Zhu", "Pedro Martelleto Rezende", "Zhang Yang", "Tong Ye", "Bruce Z. Gao", "Feng Luo", "Siyu Huang", "Jiancheng Yang"], "title": "Bonnet: Ultra-fast whole-body bone segmentation from CT scans", "categories": ["eess.IV", "cs.CV"], "comment": "5 pages, 2 figures. Accepted for publication at the 2026 IEEE International Symposium on Biomedical Imaging (ISBI 2026)", "summary": "This work proposes Bonnet, an ultra-fast sparse-volume pipeline for whole-body bone segmentation from CT scans. Accurate bone segmentation is important for surgical planning and anatomical analysis, but existing 3D voxel-based models such as nnU-Net and STU-Net require heavy computation and often take several minutes per scan, which limits time-critical use. The proposed Bonnet addresses this by integrating a series of novel framework components including HU-based bone thresholding, patch-wise inference with a sparse spconv-based U-Net, and multi-window fusion into a full-volume prediction. Trained on TotalSegmentator and evaluated without additional tuning on RibSeg, CT-Pelvic1K, and CT-Spine1K, Bonnet achieves high Dice across ribs, pelvis, and spine while running in only 2.69 seconds per scan on an RTX A6000. Compared to strong voxel baselines, Bonnet attains a similar accuracy but reduces inference time by roughly 25x on the same hardware and tiling setup. The toolkit and pre-trained models will be released at https://github.com/HINTLab/Bonnet.", "AI": {"tldr": "本文提出了一种快速的稀疏体骨分割方法Bonnet，用于CT扫描。", "motivation": "现有的三维体积模型如nnU-Net和STU-Net计算量大且处理时间长，限制了在紧急情况下的应用。为此，本文提出了Bonnet来提高速度并保持准确性。", "method": "Bonnet采用了基于HU的骨阈值分割、稀疏spconv基U-Net的补丁推理及多窗口融合技术实现全身骨分割任务。", "result": "通过训练和评估，Bonnet在TotalSegmentator数据集上取得了高Dice系数，并且在相同的硬件配置下将推断时间减少了约25倍。", "conclusion": "Bonnet提供了一种快速准确的CT扫描全身体骨骼分割方法，适用于实时应用。"}}
{"id": "2601.22575", "pdf": "https://arxiv.org/pdf/2601.22575", "abs": "https://arxiv.org/abs/2601.22575", "authors": ["Xudong Lu", "Huankang Guan", "Yang Bo", "Jinpeng Chen", "Xintong Guo", "Shuhan Li", "Fang Liu", "Peiwen Sun", "Xueying Li", "Wei Zhang", "Xue Yang", "Rui Liu", "Hongsheng Li"], "title": "PhoStream: Benchmarking Real-World Streaming for Omnimodal Assistants in Mobile Scenarios", "categories": ["cs.CV", "cs.CL"], "comment": "18 pages", "summary": "Multimodal Large Language Models excel at offline audio-visual understanding, but their ability to serve as mobile assistants in continuous real-world streams remains underexplored. In daily phone use, mobile assistants must track streaming audio-visual inputs and respond at the right time, yet existing benchmarks are often restricted to multiple-choice questions or use shorter videos. In this paper, we introduce PhoStream, the first mobile-centric streaming benchmark that unifies on-screen and off-screen scenarios to evaluate video, audio, and temporal reasoning. PhoStream contains 5,572 open-ended QA pairs from 578 videos across 4 scenarios and 10 capabilities. We build it with an Automated Generative Pipeline backed by rigorous human verification, and evaluate models using a realistic Online Inference Pipeline and LLM-as-a-Judge evaluation for open-ended responses. Experiments reveal a temporal asymmetry in LLM-judged scores (0-100): models perform well on Instant and Backward tasks (Gemini 3 Pro exceeds 80), but drop sharply on Forward tasks (16.40), largely due to early responses before the required visual and audio cues appear. This highlights a fundamental limitation: current MLLMs struggle to decide when to speak, not just what to say. Code and datasets used in this work will be made publicly accessible at https://github.com/Lucky-Lance/PhoStream.", "AI": {"tldr": "介绍了PhoStream，首个面向移动设备的多模态连续流基准测试平台，用于评估视频、音频及时间推理能力。", "motivation": "现有模型在离线音视频理解上表现出色，但在移动端真实场景中的持续性交互表现不足。现行基准测试多限于选择题或短片，无法全面评估实际性能。", "method": "构建了一个包含578个视频和4种场景的PhoStream数据集，并采用自动化生成管道与人工验证确保质量；使用在线推理管道及大语言模型作为评判标准进行评价。", "result": "实验结果显示，在即时和回溯任务上，模型表现优异（如Gemini 3 Pro得分超过80），但在前瞻任务中显著下降至16.4%，表明当前多模态大型语言模型在决策何时发言方面存在重大挑战。", "conclusion": "PhoStream揭示了现有技术处理时间依赖性问题时的局限，强调了多模态大型语言模型不仅需要知道说什么，还需懂得何时说话。"}}
{"id": "2601.22574", "pdf": "https://arxiv.org/pdf/2601.22574", "abs": "https://arxiv.org/abs/2601.22574", "authors": ["Yuansheng Gao", "Jinman Zhao", "Tong Zhang", "Xingguo Xu", "Han Bao", "Zonghui Wang", "Wenzhi Chen"], "title": "Mitigating Hallucinations in Video Large Language Models via Spatiotemporal-Semantic Contrastive Decoding", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint", "summary": "Although Video Large Language Models perform remarkably well across tasks such as video understanding, question answering, and reasoning, they still suffer from the problem of hallucination, which refers to generating outputs that are inconsistent with explicit video content or factual evidence. However, existing decoding methods for mitigating video hallucinations, while considering the spatiotemporal characteristics of videos, mostly rely on heuristic designs. As a result, they fail to precisely capture the root causes of hallucinations and their fine-grained temporal and semantic correlations, leading to limited robustness and generalization in complex scenarios. To more effectively mitigate video hallucinations, we propose a novel decoding strategy termed Spatiotemporal-Semantic Contrastive Decoding. This strategy constructs negative features by deliberately disrupting the spatiotemporal consistency and semantic associations of video features, and suppresses video hallucinations through contrastive decoding against the original video features during inference. Extensive experiments demonstrate that our method not only effectively mitigates the occurrence of hallucinations, but also preserves the general video understanding and reasoning capabilities of the model.", "AI": {"tldr": "提出了一种新的解码策略Spatiotemporal-Semantic Contrastive Decoding，用于减轻视频大型语言模型中的幻觉问题。", "motivation": "现有的减少视频幻觉的方法未能精确捕捉幻觉的根本原因及其细粒度的时间和语义相关性，在复杂场景中效果有限。因此提出了新的解码策略来更有效地解决这一问题。", "method": "该方法通过破坏视频特征的时空一致性与语义关联，构建负样本，并在推理过程中通过对比解码抑制幻觉现象。", "result": "实验表明该方法不仅能有效减少幻觉的发生，还能保持模型的一般视频理解和推理能力。", "conclusion": "Spatiotemporal-Semantic Contrastive Decoding策略是一种有效的减轻视频大型语言模型中幻觉问题的方法。"}}
{"id": "2601.22573", "pdf": "https://arxiv.org/pdf/2601.22573", "abs": "https://arxiv.org/abs/2601.22573", "authors": ["Shihong Liu", "Kun Zuo", "Hanguang Xiao"], "title": "DELNet: Continuous All-in-One Weather Removal via Dynamic Expert Library", "categories": ["cs.CV"], "comment": "Accepted by the ICASSP conference, not yet officially published", "summary": "All-in-one weather image restoration methods are valuable in practice but depend on pre-collected data and require retraining for unseen degradations, leading to high cost. We propose DELNet, a continual learning framework for weather image restoration. DELNet integrates a judging valve that measures task similarity to distinguish new from known tasks, and a dynamic expert library that stores experts trained on different degradations. For new tasks, the valve selects top-k experts for knowledge transfer while adding new experts to capture task-specific features; for known tasks, the corresponding experts are directly reused. This design enables continuous optimization without retraining existing models. Experiments on OTS, Rain100H, and Snow100K demonstrate that DELNet surpasses state-of-the-art continual learning methods, achieving PSNR gains of 16\\%, 11\\%, and 12\\%, respectively. These results highlight the effectiveness, robustness, and efficiency of DELNet, which reduces retraining cost and enables practical deployment in real-world scenarios.", "AI": {"tldr": "DELNet是一种连续学习框架，用于天气图像恢复。它通过动态专家库和判别阀值来实现对未知任务的知识迁移。", "motivation": "现有的全一体化天气图象修复方法依赖于预先收集的数据并且需要重新训练以适应未见过的退化情况，这导致成本高昂。因此提出DELNet框架以降低重训成本并提高实际应用中的鲁棒性和效率。", "method": "DELNet包括一个判别阀值用于测量任务相似度区分新旧任务，并动态存储不同降质类型专家的库。对于新任务选择最相关的k个专家进行知识迁移同时添加新的专家；已知的任务直接复用对应的专家模型，从而实现连续优化而无需重新训练。", "result": "实验表明DELNet在OTS、Rain100H和Snow100K数据集上超越了最新的持续学习方法，分别提高了PSNR值16%、11%和12%，显示出了其有效性、鲁棒性和效率。", "conclusion": "通过减少重训成本并使模型能够在现实场景中部署，DELNet在全一体化天气图象恢复任务中展示出显著的优越性。"}}
{"id": "2601.22571", "pdf": "https://arxiv.org/pdf/2601.22571", "abs": "https://arxiv.org/abs/2601.22571", "authors": ["Zhipeng Chen", "Zhongrui Zhang", "Chao Zhang", "Yifan Xu", "Lan Yang", "Jun Liu", "Ke Li", "Yi-Zhe Song"], "title": "PerfGuard: A Performance-Aware Agent for Visual Content Generation", "categories": ["cs.AI"], "comment": "This paper has been accepted by ICLR 2026. The original paper link is: https://openreview.net/pdf?id=tdN42GTv4S The code repository link is: https://github.com/FelixChan9527/PerfGuard", "summary": "The advancement of Large Language Model (LLM)-powered agents has enabled automated task processing through reasoning and tool invocation capabilities. However, existing frameworks often operate under the idealized assumption that tool executions are invariably successful, relying solely on textual descriptions that fail to distinguish precise performance boundaries and cannot adapt to iterative tool updates. This gap introduces uncertainty in planning and execution, particularly in domains like visual content generation (AIGC), where nuanced tool performance significantly impacts outcomes. To address this, we propose PerfGuard, a performance-aware agent framework for visual content generation that systematically models tool performance boundaries and integrates them into task planning and scheduling. Our framework introduces three core mechanisms: (1) Performance-Aware Selection Modeling (PASM), which replaces generic tool descriptions with a multi-dimensional scoring system based on fine-grained performance evaluations; (2) Adaptive Preference Update (APU), which dynamically optimizes tool selection by comparing theoretical rankings with actual execution rankings; and (3) Capability-Aligned Planning Optimization (CAPO), which guides the planner to generate subtasks aligned with performance-aware strategies. Experimental comparisons against state-of-the-art methods demonstrate PerfGuard's advantages in tool selection accuracy, execution reliability, and alignment with user intent, validating its robustness and practical utility for complex AIGC tasks. The project code is available at https://github.com/FelixChan9527/PerfGuard.", "AI": {"tldr": "PerfGuard是一个为视觉内容生成设计的性能感知代理框架，它通过系统地建模工具性能边界并将其整合到任务规划和调度中来提高任务执行的成功率。", "motivation": "现有的框架通常假设工具执行总是成功的，并且依赖于文本描述来区分精确的性能界限。这种假设在实际应用中可能不成立，特别是在视觉内容生成领域，细微的工具性能差异会影响结果的质量。因此，需要一种新的方法来解决这个问题，从而提高计划和执行中的确定性。", "method": "PerfGuard提出了三种核心机制：（1）基于精细粒度性能评估的多维评分系统的性能感知选择建模（PASM）；（2）通过理论排名与实际执行排名比较来动态优化工具选择的适应性偏好更新（APU）；以及（3）指导规划器生成符合性能感知策略子任务的能力对齐计划优化（CAPO）。", "result": "实验结果表明，PerfGuard在工具选择准确度、执行可靠性和与用户意图的契合度方面优于最先进的方法。", "conclusion": "PerfGuard通过整合精细粒度的性能建模和动态适应性机制来改进视觉内容生成任务中的工具选择和计划过程。这些创新提高了任务的成功率，验证了其在复杂AIGC任务中实用性和稳健性的优势。"}}
{"id": "2601.22570", "pdf": "https://arxiv.org/pdf/2601.22570", "abs": "https://arxiv.org/abs/2601.22570", "authors": ["Aditya Sarkar", "Yi Li", "Jiacheng Cheng", "Shlok Mishra", "Nuno Vasconcelos"], "title": "Leveraging Data to Say No: Memory Augmented Plug-and-Play Selective Prediction", "categories": ["cs.CV", "cs.LG"], "comment": "ICLR 2026", "summary": "Selective prediction aims to endow predictors with a reject option, to avoid low confidence predictions. However, existing literature has primarily focused on closed-set tasks, such as visual question answering with predefined options or fixed-category classification. This paper considers selective prediction for visual language foundation models, addressing a taxonomy of tasks ranging from closed to open set and from finite to unbounded vocabularies, as in image captioning. We seek training-free approaches of low-complexity, applicable to any foundation model and consider methods based on external vision-language model embeddings, like CLIP. This is denoted as Plug-and-Play Selective Prediction (PaPSP). We identify two key challenges: (1) instability of the visual-language representations, leading to high variance in image-text embeddings, and (2) poor calibration of similarity scores. To address these issues, we propose a memory augmented PaPSP (MA-PaPSP) model, which augments PaPSP with a retrieval dataset of image-text pairs. This is leveraged to reduce embedding variance by averaging retrieved nearest-neighbor pairs and is complemented by the use of contrastive normalization to improve score calibration. Through extensive experiments on multiple datasets, we show that MA-PaPSP outperforms PaPSP and other selective prediction baselines for selective captioning, image-text matching, and fine-grained classification. Code is publicly available at https://github.com/kingston-aditya/MA-PaPSP.", "AI": {"tldr": "提出了一种基于外部视觉语言模型嵌入的训练自由方法，即插件选择性预测（PaPSP），并在此基础上引入了内存增强型PaPSP（MA-PaPSP）来解决低置信度预测问题。", "motivation": "现有文献主要关注封闭集任务，如具有预定义选项或固定类别分类的视觉问答。本文旨在探索开放集和无限词汇的任务场景，并通过训练自由、低复杂性方法实现基础模型的选择性预测。", "method": "提出了一种基于外部嵌入的方法，即插件选择性预测（PaPSP）。为解决表示不稳定性和相似度评分校准差的问题，引入了内存增强型PA-PaPSP（MA-PaPSP），利用检索数据集减少嵌入方差，并通过对比归一化改善评分校准。", "result": "实验显示，MA-PaPSP在选择性描述、图像文本匹配和细粒度分类方面超越了PaPSP和其他基线方法。", "conclusion": "论文展示了MA-PaPSP模型的有效性，在视觉语言基础模型的选择性预测中实现了显著的性能提升。"}}
{"id": "2601.22569", "pdf": "https://arxiv.org/pdf/2601.22569", "abs": "https://arxiv.org/abs/2601.22569", "authors": ["Tanusree Debi", "Wentian Zhu"], "title": "Whispers of Wealth: Red-Teaming Google's Agent Payments Protocol via Prompt Injection", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language model (LLM) based agents are increasingly used to automate financial transactions, yet their reliance on contextual reasoning exposes payment systems to prompt-driven manipulation. The Agent Payments Protocol (AP2) aims to secure agent-led purchases through cryptographically verifiable mandates, but its practical robustness remains underexplored. In this work, we perform an AI red-teaming evaluation of AP2 and identify vulnerabilities arising from indirect and direct prompt injection. We introduce two attack techniques, the Branded Whisper Attack and the Vault Whisper Attack which manipulate product ranking and extract sensitive user data. Using a functional AP2 based shopping agent built with Gemini-2.5-Flash and the Google ADK framework, we experimentally validate that simple adversarial prompts can reliably subvert agent behavior. Our findings reveal critical weaknesses in current agentic payment architectures and highlight the need for stronger isolation and defensive safeguards in LLM-mediated financial systems.", "AI": {"tldr": "通过红队攻击评估Google的代理支付协议（AP2），揭示其在面对提示注入时的安全弱点。", "motivation": "大型语言模型驱动的代理越来越多地被用于自动执行金融交易，但这些系统可能由于依赖上下文推理而容易受到提示驱动操纵。目前，关于AP2的实际健壮性仍不明确。", "method": "介绍了两种攻击技术：品牌低语攻击和金库低语攻击，并使用基于Gemini-2.5-Flash构建的带有Google ADK框架的功能化AP2购物代理来实验验证这些攻击的有效性。", "result": "简单对抗提示可以可靠地破坏代理行为，揭示了当前代理支付架构中的关键弱点。", "conclusion": "当前LLM中介金融系统的安全需要更强的隔离和防御措施。"}}
{"id": "2601.22563", "pdf": "https://arxiv.org/pdf/2601.22563", "abs": "https://arxiv.org/abs/2601.22563", "authors": ["Sang Min Kim", "Byeongchan Kim", "Arijit Sehanobish", "Somnath Basu Roy Chowdhury", "Rahul Kidambi", "Dongseok Shim", "Avinava Dubey", "Snigdha Chaturvedi", "Min-hwan Oh", "Krzysztof Choromanski"], "title": "EUGens: Efficient, Unified, and General Dense Layers", "categories": ["cs.LG", "cs.AI"], "comment": "Neurips 2025. Encompasses results of arXiv:2410.09771", "summary": "Efficient neural networks are essential for scaling machine learning models to real-time applications and resource-constrained environments. Fully-connected feedforward layers (FFLs) introduce computation and parameter count bottlenecks within neural network architectures. To address this challenge, in this work, we propose a new class of dense layers that generalize standard fully-connected feedforward layers, \\textbf{E}fficient, \\textbf{U}nified and \\textbf{Gen}eral dense layers (EUGens). EUGens leverage random features to approximate standard FFLs and go beyond them by incorporating a direct dependence on the input norms in their computations. The proposed layers unify existing efficient FFL extensions and improve efficiency by reducing inference complexity from quadratic to linear time. They also lead to \\textbf{the first} unbiased algorithms approximating FFLs with arbitrary polynomial activation functions. Furthermore, EuGens reduce the parameter count and computational overhead while preserving the expressive power and adaptability of FFLs. We also present a layer-wise knowledge transfer technique that bypasses backpropagation, enabling efficient adaptation of EUGens to pre-trained models. Empirically, we observe that integrating EUGens into Transformers and MLPs yields substantial improvements in inference speed (up to \\textbf{27}\\%) and memory efficiency (up to \\textbf{30}\\%) across a range of tasks, including image classification, language model pre-training, and 3D scene reconstruction. Overall, our results highlight the potential of EUGens for the scalable deployment of large-scale neural networks in real-world scenarios.", "AI": {"tldr": "提出了一种新的高效稠密层EUGens，以解决全连接前馈层的计算和参数瓶颈问题。", "motivation": "为了解决神经网络架构中的计算和参数数量瓶颈问题，特别是在实时应用和资源受限环境中，提出了新的稠密层类别来提高效率并减少复杂度。", "method": "通过随机特征近似标准全连接前馈层，并引入输入范数的直接依赖性。提出的EUGens层将现有的高效全连接扩展统一起来，减少了推理时间从二次到线性时间，并且首次提出了任意多项式激活函数的无偏算法。此外还提供了一种层次化知识转移技术。", "result": "实验证明，在Transformer和MLP中集成EUGens可以提高推理速度（最多27%）并减少内存使用（最多30%），在图像分类、语言模型预训练以及三维场景重建等任务上表现出显著改进。", "conclusion": "研究成果展示了EUGens在大规模神经网络的实际部署中的潜力，特别是在实时应用和资源受限环境中。"}}
{"id": "2601.22551", "pdf": "https://arxiv.org/pdf/2601.22551", "abs": "https://arxiv.org/abs/2601.22551", "authors": ["Meixia Lin", "Mingkai Liu", "Shuxue Peng", "Dikai Fan", "Shengyu Gu", "Xianliang Huang", "Haoyang Ye", "Xiao Liu"], "title": "Hybrid Cross-Device Localization via Neural Metric Learning and Feature Fusion", "categories": ["cs.CV"], "comment": "3 pages", "summary": "We present a hybrid cross-device localization pipeline developed for the CroCoDL 2025 Challenge. Our approach integrates a shared retrieval encoder and two complementary localization branches: a classical geometric branch using feature fusion and PnP, and a neural feed-forward branch (MapAnything) for metric localization conditioned on geometric inputs. A neural-guided candidate pruning strategy further filters unreliable map frames based on translation consistency, while depth-conditioned localization refines metric scale and translation precision on Spot scenes. These components jointly lead to significant improvements in recall and accuracy across both HYDRO and SUCCU benchmarks. Our method achieved a final score of 92.62 (R@0.5m, 5°) during the challenge.", "AI": {"tldr": "本文提出了一种混合跨设备定位管道，用于CroCoDL 2025挑战。", "motivation": "通过集成共享检索编码器和两种互补的本地化分支来提高跨设备定位的召回率和准确性。", "method": "该方法结合了经典几何分支（使用特征融合和PnP）和神经前馈分支(MapAnything)，并采用基于翻译一致性的神经引导候选物修剪策略以及深度条件下的局部化细化。", "result": "在HYDRO和SUCCU基准上，该方法实现了显著的改进，并且在挑战赛中获得了92.62（R@0.5m, 5°）的成绩。", "conclusion": "提出的混合跨设备定位管道通过结合多种技术有效地提升了定位性能，在CroCoDL 2025挑战中取得了优异的表现。"}}
{"id": "2601.22550", "pdf": "https://arxiv.org/pdf/2601.22550", "abs": "https://arxiv.org/abs/2601.22550", "authors": ["Geonho Leem", "Jaedong Lee", "Jehee Lee", "Seungmoon Song", "Jungdam Won"], "title": "Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation", "categories": ["cs.RO", "cs.GR", "cs.LG"], "comment": "10 pages, 9 figures, ICLR 2026 accepted", "summary": "Exoskeletons show great promise for enhancing mobility, but providing appropriate assistance remains challenging due to the complexity of human adaptation to external forces. Current state-of-the-art approaches for optimizing exoskeleton controllers require extensive human experiments in which participants must walk for hours, creating a paradox: those who could benefit most from exoskeleton assistance, such as individuals with mobility impairments, are rarely able to participate in such demanding procedures. We present Exo-plore, a simulation framework that combines neuromechanical simulation with deep reinforcement learning to optimize hip exoskeleton assistance without requiring real human experiments. Exo-plore can (1) generate realistic gait data that captures human adaptation to assistive forces, (2) produce reliable optimization results despite the stochastic nature of human gait, and (3) generalize to pathological gaits, showing strong linear relationships between pathology severity and optimal assistance.", "AI": {"tldr": "通过结合神经机械模拟和深度强化学习，开发了Exo-Plore框架来优化外骨骼控制器，以增强人类移动性。", "motivation": "当前最佳的外骨骼控制器优化方法需要进行大量的真人实验，这对那些最能从中受益的人（如行动不便者）来说是不切实际的任务。因此，研究目的是通过模拟减少对真实人的依赖。", "method": "Exo-Plore结合神经机械模拟和深度强化学习来生成现实步态数据，并在此基础上优化髋部外骨骼的辅助控制。", "result": "该框架能够产生可靠的优化结果并推广到病理步态上，展示了严重程度与最佳帮助之间的强线性关系。", "conclusion": "Exo-Plore提供了无需真实人参与就能有效优化外骨骼控制器的方法，为行动不便者带来了潜在的好处。"}}
{"id": "2601.22548", "pdf": "https://arxiv.org/pdf/2601.22548", "abs": "https://arxiv.org/abs/2601.22548", "authors": ["Dani Roytburg", "Matthew Bozoukov", "Matthew Nguyen", "Mackenzie Puig-Hall", "Narmeen Oozeer"], "title": "Are LLM Evaluators Really Narcissists? Sanity Checking Self-Preference Evaluations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent research has shown that large language models (LLM) favor own outputs when acting as judges, undermining the integrity of automated post-training and evaluation workflows. However, it is difficult to disentangle which evaluation biases are explained by narcissism versus general experimental confounds, distorting measurements of self-preference bias. We discover a core methodological confound which could reduce measurement error by 89.6%. Specifically, LLM evaluators may deliver self-preferring verdicts when the judge responds to queries which they completed incorrectly themselves; this would be true regardless of whether one of their responses is their own. To decouple self-preference signals from noisy outputs on hard problems, we introduce an Evaluator Quality Baseline, which compares the probability that a judge incorrectly votes for itself against the probability that it votes for an incorrect response from another model. Evaluating this simple baseline on 37,448 queries, only 51% of initial findings retain statistical significance. Finally, we turn towards characterizing the entropy of \"easy\" versus \"hard\" evaluation votes from LLM judges. Our corrective baseline enables future research on self-preference by eliminating noisy data from potential solutions. More widely, this work contributes to the growing body of work on cataloging and isolating judge-bias effects.", "AI": {"tldr": "研究发现大语言模型（LLM）作为评委时倾向于选择自己的输出，影响了自动化后训练和评价流程的完整性。本文通过引入评估者质量基线来区分自偏好信号与噪声。", "motivation": "揭示大语言模型自我偏好的潜在原因，并消除实验中的方法学混淆因素以提高测量准确性。", "method": "引入一个比较错误投票概率的质量基准，判断LLM作为评委时对自身和其它模型的错误输出的选择倾向，评估37,448个查询来验证该基线的有效性。", "result": "在修正后的基准下，初始发现中的统计显著性仅保留了51%。这表明先前的一些自我偏好现象可能是由于数据噪声造成的。", "conclusion": "本文提出了一个消除噪音的评估者质量基线方法，为未来研究提供了更准确的数据支持，并有助于理解和减轻LLM评委偏见效应的影响。"}}
{"id": "2601.22546", "pdf": "https://arxiv.org/pdf/2601.22546", "abs": "https://arxiv.org/abs/2601.22546", "authors": ["Shun Qian", "Bingquan Liu", "Chengjie Sun", "Zhen Xu", "Baoxun Wang"], "title": "Towards the Holographic Characteristic of LLMs for Efficient Short-text Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The recent advancements in Large Language Models (LLMs) have attracted interest in exploring their in-context learning abilities and chain-of-thought capabilities. However, there are few studies investigating the specific traits related to the powerful generation capacity of LLMs. This paper aims to delve into the generation characteristics exhibited by LLMs. Through our investigation, we have discovered that language models tend to capture target-side keywords at the beginning of the generation process. We name this phenomenon the Holographic Characteristic of language models. For the purpose of exploring this characteristic and further improving the inference efficiency of language models, we propose a plugin called HOLO, which leverages the Holographic Characteristic to extract target-side keywords from language models within a limited number of generation steps and complements the sentence with a parallel lexically constrained text generation method. To verify the effectiveness of HOLO, we conduct massive experiments on language models of varying architectures and scales in the short-text generation scenario. The results demonstrate that HOLO achieves comparable performance to the baselines in terms of both automatic and human-like evaluation metrics and highlight the potential of the Holographic Characteristic.", "AI": {"tldr": "研究了大语言模型在短文本生成中的全息特性，并提出了一种名为HOLO的插件以提高效率。", "motivation": "探索大型语言模型的强大生成能力，特别是它们在短文本生成过程中的特性。", "method": "通过分析发现语言模型倾向于在生成过程中捕捉目标关键词的现象。为此提出了一个名为HOLO的插件来利用这一全息特性，并进行了大量实验验证其有效性。", "result": "实验证明HOLO在自动和人类评价指标上与基线方法相当，展示了全息特性的潜力。", "conclusion": "揭示了语言模型生成过程中的全息特性，并通过提出HOLO插件证明了这一特性的实用价值。"}}
{"id": "2601.22545", "pdf": "https://arxiv.org/pdf/2601.22545", "abs": "https://arxiv.org/abs/2601.22545", "authors": ["Feng Tao", "Luca Paparusso", "Chenyi Gu", "Robin Koehler", "Chenxu Wu", "Xinyu Huang", "Christian Juette", "David Paz", "Ren Liu"], "title": "Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To overcome these limitations, we introduce a Deep Reinforcement Learning (DRL) framework for real-time path planning in parking scenarios. In particular, we focus on challenging scenes with tight spaces that require a high number of reversal maneuvers and adjustments. Unlike classical planners, our solution does not require ideal and structured perception, and in principle, could avoid the need for additional modules such as localization and tracking, resulting in a simpler and more practical implementation. Also, at test time, the policy generates actions through a single forward pass at each step, which is lightweight enough for real-time deployment. The task is formulated as a sequential decision-making problem grounded in a bicycle model dynamics, enabling the agent to directly learn navigation policies that respect vehicle kinematics and environmental constraints in the closed-loop setting. A new benchmark is developed to support both training and evaluation, capturing diverse and challenging scenarios. Our approach achieves state-of-the-art success rates and efficiency, surpassing classical planner baselines by +96% in success rate and +52% in efficiency. Furthermore, we release our benchmark as an open-source resource for the community to foster future research in autonomous systems. The benchmark and accompanying tools are available at https://github.com/dqm5rtfg9b-collab/Constrained_Parking_Scenarios.", "AI": {"tldr": "论文提出了一种基于深度强化学习的实时路径规划框架，用于解决自动驾驶系统在复杂停车场景中的路径规划问题。", "motivation": "传统经典规划器由于计算成本高且依赖于理想感知条件，在实际应用中存在局限性。因此，该研究旨在通过引入一种新的基于深度强化学习的方法来克服这些问题，并实现更高效、实时的路径规划。", "method": "论文提出了一种基于深度强化学习框架的方法，将任务定义为基于自行车模型动态学的序列决策问题，使代理能够直接从闭环环境中学习导航策略。同时开发了一个新基准以支持训练和评估。", "result": "所提方法在成功率上比经典规划器提高了96%，效率方面也提升了52%。此外，论文还公开了相关资源供社区进一步研究使用。", "conclusion": "通过实验证明，基于深度强化学习的方法可以更好地适应复杂停车场景，并实现了更高的成功和效率。"}}
{"id": "2601.22542", "pdf": "https://arxiv.org/pdf/2601.22542", "abs": "https://arxiv.org/abs/2601.22542", "authors": ["Zijian Gao", "Yuanting Zhong", "Zeyuan Ma", "Yue-Jiao Gong", "Hongshu Guo"], "title": "Detect and Act: Automated Dynamic Optimizer through Meta-Black-Box Optimization", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Dynamic Optimization Problems (DOPs) are challenging to address due to their complex nature, i.e., dynamic environment variation. Evolutionary Computation methods are generally advantaged in solving DOPs since they resemble dynamic biological evolution. However, existing evolutionary dynamic optimization methods rely heavily on human-crafted adaptive strategy to detect environment variation in DOPs, and then adapt the searching strategy accordingly. These hand-crafted strategies may perform ineffectively at out-of-box scenarios. In this paper, we propose a reinforcement learning-assisted approach to enable automated variation detection and self-adaption in evolutionary algorithms. This is achieved by borrowing the bi-level learning-to-optimize idea from recent Meta-Black-Box Optimization works. We use a deep Q-network as optimization dynamics detector and searching strategy adapter: It is fed as input with current-step optimization state and then dictates desired control parameters to underlying evolutionary algorithms for next-step optimization. The learning objective is to maximize the expected performance gain across a problem distribution. Once trained, our approach could generalize toward unseen DOPs with automated environment variation detection and self-adaption. To facilitate comprehensive validation, we further construct an easy-to-difficult DOPs testbed with diverse synthetic instances. Extensive benchmark results demonstrate flexible searching behavior and superior performance of our approach in solving DOPs, compared to state-of-the-art baselines.", "AI": {"tldr": "提出了一种基于强化学习的方法来自动化检测和适应动态优化问题中的环境变化。", "motivation": "现有进化算法在处理动态优化问题时依赖于手工设计的策略，这些策略在非标准场景中表现不佳。因此，需要一种自动化的、灵活的方法来进行环境变异检测与自适应调整。", "method": "采用双层学习至优化的思想，使用深度Q网络作为优化动力学探测器和搜索策略调整器。该方法通过输入当前步骤的优化状态，并输出控制参数以指导后续进化算法进行优化，目标是最大化跨问题分布的预期性能提升。", "result": "实验结果表明，在解决动态优化问题时，所提出的方法表现出灵活的搜索行为并优于现有基准线。", "conclusion": "新方法能够自动检测环境变化并在未见过的动态优化问题中自适应调整，从而提高了解决这类复杂问题的能力。"}}
{"id": "2601.22537", "pdf": "https://arxiv.org/pdf/2601.22537", "abs": "https://arxiv.org/abs/2601.22537", "authors": ["Zhuoyu Wu", "Wenhui Ou", "Pei-Sze Tan", "Jiayan Yang", "Wenqi Fang", "Zheng Wang", "Raphaël C. -W. Phan"], "title": "EndoCaver: Handling Fog, Blur and Glare in Endoscopic Images via Joint Deblurring-Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted for publication at IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026", "summary": "Endoscopic image analysis is vital for colorectal cancer screening, yet real-world conditions often suffer from lens fogging, motion blur, and specular highlights, which severely compromise automated polyp detection. We propose EndoCaver, a lightweight transformer with a unidirectional-guided dual-decoder architecture, enabling joint multi-task capability for image deblurring and segmentation while significantly reducing computational complexity and model parameters. Specifically, it integrates a Global Attention Module (GAM) for cross-scale aggregation, a Deblurring-Segmentation Aligner (DSA) to transfer restoration cues, and a cosine-based scheduler (LoCoS) for stable multi-task optimisation. Experiments on the Kvasir-SEG dataset show that EndoCaver achieves 0.922 Dice on clean data and 0.889 under severe image degradation, surpassing state-of-the-art methods while reducing model parameters by 90%. These results demonstrate its efficiency and robustness, making it well-suited for on-device clinical deployment. Code is available at https://github.com/ReaganWu/EndoCaver.", "AI": {"tldr": "本文提出了一种轻量级的EndoCaver，用于内窥镜图像去雾、去模糊和处理眩光问题，并同时进行分割。", "motivation": "内窥镜图像分析对于结直肠癌筛查至关重要，但实际环境中的镜头起雾、运动模糊和高亮反射等问题严重影响了自动息肉检测的准确性。", "method": "EndoCaver采用了一种双向引导双解码器架构，集成全局注意力模块（GAM）进行跨尺度聚合，通过去模糊分割对齐器（DSA）转移恢复线索，并使用基于余弦的学习率调度器（LoCoS）实现稳定的多任务优化。", "result": "在Kvasir-SEG数据集上实验表明，EndoCaver在干净图像上的Dice系数为0.922，在严重图像退化情况下为0.889，优于当前最佳方法，并将模型参数减少了90%。", "conclusion": "结果证明了其高效性和鲁棒性，非常适合临床设备上实时使用。"}}
{"id": "2601.22536", "pdf": "https://arxiv.org/pdf/2601.22536", "abs": "https://arxiv.org/abs/2601.22536", "authors": ["Yixin Yang", "Qingxiu Dong", "Zhifang Sui"], "title": "Decoding in Geometry: Alleviating Embedding-Space Crowding for Complex Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Sampling-based decoding underlies complex reasoning in large language models (LLMs), where decoding strategies critically shape model behavior. Temperature- and truncation-based methods reshape the next-token distribution through global probability reweighting or thresholding to balance the quality-diversity tradeoff. However, they operate solely on token probabilities, ignoring fine-grained relationships among tokens in the embedding space. We uncover a novel phenomenon, embedding-space crowding, where the next-token distribution concentrates its probability mass on geometrically close tokens in the embedding space. We quantify crowding at multiple granularities and find a statistical association with reasoning success in mathematical problem solving. Motivated by this finding, we propose CraEG, a plug-and-play sampling method that mitigates crowding through geometry-guided reweighting. CraEG is training-free, single-pass, and compatible with standard sampling strategies. Experiments on multiple models and benchmarks demonstrate improved generation performance, with gains in robustness and diversity metrics.", "AI": {"tldr": "提出了一种名为CraEG的几何引导采样方法，以缓解大规模语言模型中的嵌入空间拥挤问题。", "motivation": "发现了嵌入空间拥挤现象，该现象会导致下一个标记分布集中在几何上接近的标记上。为了解决这一问题并提高数学推理任务的成功率，作者提出了CraEG方法。", "method": "通过几何引导重新加权来缓解嵌入空间中的拥挤现象，从而改善生成性能。", "result": "实验结果显示，在多个模型和基准测试中，使用CraEG方法可以提升生成性能，并且在鲁棒性和多样性指标上有显著提高。", "conclusion": "该论文提出了一种有效的几何引导采样方法来缓解嵌入空间拥挤问题，证明了它能够改善大规模语言模型的复杂推理任务。"}}
{"id": "2601.22534", "pdf": "https://arxiv.org/pdf/2601.22534", "abs": "https://arxiv.org/abs/2601.22534", "authors": ["Sumedh Karajagi", "Sampad Bhusan Mohanty", "Bhaskar Krishnamachari"], "title": "LEAP -- Live Experiments for Active Pedagogy", "categories": ["cs.HC"], "comment": ":K.3.2; D.2.6", "summary": "Interactive computational environments can help students explore algorithmic concepts through collaborative hands-on experimentation. However, static and instructor controlled demos in lectures limit engagement. Even when interactive visualizations are used, interactions are solely controlled by the instructor, leaving students as passive observers. In addition, the tools used for demonstration often vary significantly, as they are typically developed by individual instructors. Consequently, the visualizations remain confined to a single classroom, rather than being shared and adapted across courses or reused by other instructors. To address this gap and foster active engagement in live classrooms, we present a lightweight and seamless software framework named LEAP for developing interactive computational lab exercises using a simple idea: remotely callable instructor-defined functions. Using API endpoints and a provided client, students can discover and then call instructor defined functions remotely from their coding environment using scripts or interactive notebooks. Each function call is time-stamped and persistently logged in a database, allowing real-time visualization of participation, diverse solution paths, common pitfalls, and live feedback through collaboration, gamification, and quizzes. Labs are packaged as self-contained folders, each containing their own remotely callable functions. We provide example labs to demonstrate applications relevant for numerical analysis, machine learning, algorithms courses and mention some in electrical engineering (EE), economics, and physics. These capabilities enhance engagement and provide instructors with actionable insights into learning processes. With a standardized lab format and an online directory for community-contributed labs, we aim to foster a global ecosystem for exchanging and expanding interactive pedagogy enabled by LEAP.", "AI": {"tldr": "LEAP是一个轻量级软件框架，允许教师定义远程调用函数以促进学生互动实验。", "motivation": "传统的静态和由讲师控制的演示限制了学生的参与度，并且缺少可以跨课程共享和重复使用的工具。因此，开发了一个名为LEAP的系统来增强实时教室中的学生主动参与。", "method": "LEAP使用API端点和提供的客户端使学生能够远程调用教师定义的功能。每个功能调用都会被时间戳记并持久地记录在数据库中，以便进行实时可视化分析。", "result": "该框架增强了学生的互动体验，并为讲师提供了关于学习过程的行动见解。", "conclusion": "通过一个标准化的实验室格式和在线目录来促进全球社区贡献的实验室交换与扩展，LEAP旨在推动由其支持的互动教学法的发展。"}}
{"id": "2601.22532", "pdf": "https://arxiv.org/pdf/2601.22532", "abs": "https://arxiv.org/abs/2601.22532", "authors": ["Hong Xie", "Xiao Hu", "Tao Tan", "Haoran Gu", "Xin Li", "Jianyu Han", "Defu Lian", "Enhong Chen"], "title": "Demystifying Design Choices of Reinforcement Fine-tuning: A Batched Contextual Bandit Learning Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The reinforcement fine-tuning area is undergoing an explosion papers largely on optimizing design choices. Though performance gains are often claimed, inconsistent conclusions also arise from time to time, making the progress illusive. Reflecting on this illusion, we still lack principled answers to two fundamental questions: 1) what is the role of each design choice? 2) which ones are critical? This paper aims to shed light on them. The underlying challenge is that design choices are entangled together, making their contribution to learning and generalization difficult to attribute. To address this challenge, we first construct a minimalist baseline for disentangling factors: one rollout per query in each round, the outcome reward serving as the training signal without any advantage trick, and a batch size of thirty-two. This baseline connects to batched contextual bandit learning, which facilitates experimental analysis. Centering around this baseline, we design an experiment pipeline, examining the marginal gains of factors like advantage, number of rollouts, etc. Experiments on three base models and two datasets, not only reveal new understanding on the role of various design choices on learning and generalization dynamics, but also identify critical ones that deserve more effort.", "AI": {"tldr": "本文通过构建一个简单的基准，从批次上下文多臂赌博机学习的角度探讨了强化微调的设计选择及其对学习和泛化的影响。", "motivation": "现有研究在优化设计选择方面取得了一些进展，但缺乏对各个设计选择实际作用及关键性的系统性理解。因此，本文旨在解决这些问题，以促进该领域的进一步发展。", "method": "构建了一个最小化的基准，用单次rollout来获取每次查询的奖励作为训练信号，并采用批次大小为32的策略；围绕这个基准设计了一系列实验，研究了各种因素如优势函数、rollout数量等对学习和泛化的影响。", "result": "通过在三个基础模型和两个数据集上的实验证明，不同的设计选择对学习和泛化的动态有不同的影响，并识别出一些关键的设计选择需要更多的关注。", "conclusion": "本文揭示了不同设计选择的作用及其对强化微调性能的重要性，为未来的研究指出了新的方向。"}}
{"id": "2601.22531", "pdf": "https://arxiv.org/pdf/2601.22531", "abs": "https://arxiv.org/abs/2601.22531", "authors": ["Jiayi Dai", "Randy Goebel"], "title": "Learn from A Rationalist: Distilling Intermediate Interpretable Rationales", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Because of the pervasive use of deep neural networks (DNNs), especially in high-stakes domains, the interpretability of DNNs has received increased attention. The general idea of rationale extraction (RE) is to provide an interpretable-by-design framework for DNNs via a select-predict architecture where two neural networks learn jointly to perform feature selection and prediction, respectively. Given only the remote supervision from the final task prediction, the process of learning to select subsets of features (or \\emph{rationales}) requires searching in the space of all possible feature combinations, which is computationally challenging and even harder when the base neural networks are not sufficiently capable. To improve the predictive performance of RE models that are based on less capable or smaller neural networks (i.e., the students), we propose \\textbf{REKD} (\\textbf{R}ationale \\textbf{E}xtraction with \\textbf{K}nowledge \\textbf{D}istillation) where a student RE model learns from the rationales and predictions of a teacher (i.e., a \\emph{rationalist}) in addition to the student's own RE optimization. This structural adjustment to RE aligns well with how humans could learn effectively from interpretable and verifiable knowledge. Because of the neural-model agnostic nature of the method, any black-box neural network could be integrated as a backbone model. To demonstrate the viability of REKD, we conduct experiments with multiple variants of BERT and vision transformer (ViT) models. Our experiments across language and vision classification datasets (i.e., IMDB movie reviews, CIFAR 10 and CIFAR 100) show that REKD significantly improves the predictive performance of the student RE models.", "AI": {"tldr": "本文提出了一种新的方法REKD，通过知识蒸馏的方式提高基于较小神经网络的解释性特征提取模型的预测性能。", "motivation": "在高风险领域中深度神经网络的广泛使用使得其可解释性变得尤为重要。为了增强这类模型的解释性和准确性，作者提出了结合教师模型的知识蒸馏技术以改进学生模型的表现。", "method": "REKD方法通过引入一个教师模型（理性主义者），该模型不仅提供最终任务预测的结果还给出中间的特征选择（理据）给学生模型学习。这种结构上的调整有助于增强较小或能力较低的学生模型的学习效率，从而提高其预测性能。", "result": "实验表明，在IMDB电影评论、CIFAR10和CIFAR100等数据集上，REKD方法显著提高了基于较小神经网络的解释性特征提取模型的预测准确性。", "conclusion": "通过知识蒸馏技术改进学生模型的表现证明了该方法的有效性和适用性，为提高深度神经网络的可解释性和性能提供了一种新的途径。"}}
{"id": "2601.22530", "pdf": "https://arxiv.org/pdf/2601.22530", "abs": "https://arxiv.org/abs/2601.22530", "authors": ["Tung Sum Thomas Kwok", "Xinyu Wang", "Hengzhi He", "Xiaofeng Lin", "Peng Lu", "Liheng Ma", "Chunhe Wang", "Ying Nian Wu", "Lei Ding", "Guang Cheng"], "title": "Enhancing TableQA through Verifiable Reasoning Trace Reward", "categories": ["cs.AI"], "comment": null, "summary": "A major challenge in training TableQA agents, compared to standard text- and image-based agents, is that answers cannot be inferred from a static input but must be reasoned through stepwise transformations of the table state, introducing multi-step reasoning complexity and environmental interaction. This leads to a research question: Can explicit feedback on table transformation action improve model reasoning capability? In this work, we introduce RE-Tab, a plug-and-play framework that architecturally enhances trajectory search via lightweight, training-free reward modeling by formulating the problem as a Partially Observable Markov Decision Process. We demonstrate that providing explicit verifiable rewards during State Transition (``What is the best action?'') and Simulative Reasoning (``Am I sure about the output?'') is crucial to steer the agent's navigation in table states. By enforcing stepwise reasoning with reward feedback in table transformations, RE-Tab achieves state-of-the-art performance in TableQA with almost 25\\% drop in inference cost. Furthermore, a direct plug-and-play implementation of RE-Tab brings up to 41.77% improvement in QA accuracy and 33.33% drop in test-time inference samples for consistent answer. Consistent improvement pattern across various LLMs and state-of-the-art benchmarks further confirms RE-Tab's generalisability. The repository is available at https://github.com/ThomasK1018/RE_Tab .", "AI": {"tldr": "介绍了一种名为RE-Tab的框架，用于通过提供表转换步骤中的奖励反馈来提高表格问答（TableQA）代理的表现。", "motivation": "表格问答任务需要多步推理能力，而不仅仅是静态输入的答案推断。研究了显式的表状态变化反馈是否可以改善模型的推理能力。", "method": "提出了一种称为RE-Tab的框架，该框架通过在部分可观察马尔可夫决策过程中使用轻量级训练免费奖励建模来增强轨迹搜索。此方法侧重于在状态转换和模拟推理期间提供显式验证奖励以引导代理导航表状态。", "result": "RE-Tab实现了表格问答任务中的最佳性能，同时几乎降低了25%的推断成本。与现有模型相比，在准确性上提高了41.77%，并在测试时间推理样本中减少了33.33%。", "conclusion": "该研究通过提供表转换步骤奖励反馈来改进表格问答代理的表现，证明了RE-Tab的有效性和泛化能力。"}}
{"id": "2601.22529", "pdf": "https://arxiv.org/pdf/2601.22529", "abs": "https://arxiv.org/abs/2601.22529", "authors": ["Seung Hyun Lee", "Sangwoo Mo", "Stella X. Yu"], "title": "SHED Light on Segmentation for Dense Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Dense prediction infers per-pixel values from a single image and is fundamental to 3D perception and robotics. Although real-world scenes exhibit strong structure, existing methods treat it as an independent pixel-wise prediction, often resulting in structural inconsistencies. We propose SHED, a novel encoder-decoder architecture that enforces geometric prior explicitly by incorporating segmentation into dense prediction. By bidirectional hierarchical reasoning, segment tokens are hierarchically pooled in the encoder and unpooled in the decoder to reverse the hierarchy. The model is supervised only at the final output, allowing the segment hierarchy to emerge without explicit segmentation supervision. SHED improves depth boundary sharpness and segment coherence, while demonstrating strong cross-domain generalization from synthetic to the real-world environments. Its hierarchy-aware decoder better captures global 3D scene layouts, leading to improved semantic segmentation performance. Moreover, SHED enhances 3D reconstruction quality and reveals interpretable part-level structures that are often missed by conventional pixel-wise methods.", "AI": {"tldr": "本文提出了一种新的编码器-解码器架构SHED，旨在通过将分割引入稠密预测来解决结构不一致的问题。", "motivation": "现有的方法在进行稠密预测时往往忽视了场景的结构性，导致结果存在结构性的矛盾。因此，作者提出了SHED模型以增强深度边界锐利度和段落一致性，并提升跨域泛化能力。", "method": "该论文提出了一种新的编码器-解码器架构（称为SHED），通过双向分层推理将分割令牌层次地汇集于编码器中并在解码器中反向展开。这种设计允许模型在没有显式分割监督的情况下实现段落层级的自适应。", "result": "实验结果表明，与传统像素级方法相比，SHED显著改善了深度边界锐利度和片段一致性，并且表现出了强大的跨域泛化能力从合成到现实世界场景。此外，在语义分割、3D重建质量方面也表现出色。", "conclusion": "通过将分割融入稠密预测中并采用层次感知的解码器设计，SHED不仅提升了深度边界锐利度和片段一致性，而且在多个任务上取得了显著的效果提升，证明了其在复杂场景理解中的潜力。"}}
{"id": "2601.22528", "pdf": "https://arxiv.org/pdf/2601.22528", "abs": "https://arxiv.org/abs/2601.22528", "authors": ["Hongze Mi", "Yibo Feng", "WenJie Lu", "Song Cao", "Jinyuan Li", "Yanming Li", "Xuelin Zhang", "Haotian Luo", "Songyang Peng", "He Cui", "Tengfei Tian", "Jun Fang", "Hua Chai", "Naiqiang Tan"], "title": "Darwinian Memory: A Training-Free Self-Regulating Memory System for GUI Agent Evolution", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal Large Language Model (MLLM) agents facilitate Graphical User Interface (GUI) automation but struggle with long-horizon, cross-application tasks due to limited context windows. While memory systems provide a viable solution, existing paradigms struggle to adapt to dynamic GUI environments, suffering from a granularity mismatch between high-level intent and low-level execution, and context pollution where the static accumulation of outdated experiences drives agents into hallucination. To address these bottlenecks, we propose the Darwinian Memory System (DMS), a self-evolving architecture that constructs memory as a dynamic ecosystem governed by the law of survival of the fittest. DMS decomposes complex trajectories into independent, reusable units for compositional flexibility, and implements Utility-driven Natural Selection to track survival value, actively pruning suboptimal paths and inhibiting high-risk plans. This evolutionary pressure compels the agent to derive superior strategies. Extensive experiments on real-world multi-app benchmarks validate that DMS boosts general-purpose MLLMs without training costs or architectural overhead, achieving average gains of 18.0% in success rate and 33.9% in execution stability, while reducing task latency, establishing it as an effective self-evolving memory system for GUI tasks.", "AI": {"tldr": "提出了一种适应动态图形用户界面环境的自调节记忆系统Darwinian Memory System（DMS），以解决多模态大型语言模型在长时任务中的挑战。", "motivation": "现有记忆系统难以应对动态GUI环境中上下文窗口限制和不匹配问题，导致执行不稳定。为了克服这些问题，设计了新的记忆体系结构来提高代理的适应性和效率。", "method": "DMS通过将复杂轨迹分解为独立可重用单元并使用基于效益的选择机制实现自演化过程，该机制跟踪生存价值并通过主动剪枝和抑制高风险计划来优化路径选择。", "result": "实验表明，与现有方法相比，DMS显著提高了成功概率（平均提升18.0%）和执行稳定性（平均提升33.9%），同时减少了任务延迟时间。", "conclusion": "DMS作为一个无需额外训练成本和架构复杂度的自演化记忆系统，在解决GUI自动化挑战方面表现出色。"}}
{"id": "2601.22522", "pdf": "https://arxiv.org/pdf/2601.22522", "abs": "https://arxiv.org/abs/2601.22522", "authors": ["Zhou Tang", "Jin Wang", "Angelo De Castro", "Yuxi Zhang", "Victoria Bastos Primo", "Ana Beatriz Montevecchio Bernardino", "Gota Morota", "Xu Wang", "Ricardo C Chebel", "Haipeng Yu"], "title": "Can 3D point cloud data improve automated body condition score prediction in dairy cattle?", "categories": ["cs.CV"], "comment": null, "summary": "Body condition score (BCS) is a widely used indicator of body energy status and is closely associated with metabolic status, reproductive performance, and health in dairy cattle; however, conventional visual scoring is subjective and labor-intensive. Computer vision approaches have been applied to BCS prediction, with depth images widely used because they capture geometric information independent of coat color and texture. More recently, three-dimensional point cloud data have attracted increasing interest due to their ability to represent richer geometric characteristics of animal morphology, but direct head-to-head comparisons with depth image-based approaches remain limited. In this study, we compared top-view depth image and point cloud data for BCS prediction under four settings: 1) unsegmented raw data, 2) segmented full-body data, 3) segmented hindquarter data, and 4) handcrafted feature data. Prediction models were evaluated using data from 1,020 dairy cows collected on a commercial farm, with cow-level cross-validation to prevent data leakage. Depth image-based models consistently achieved higher accuracy than point cloud-based models when unsegmented raw data and segmented full-body data were used, whereas comparable performance was observed when segmented hindquarter data were used. Both depth image and point cloud approaches showed reduced accuracy when handcrafted feature data were employed compared with the other settings. Overall, point cloud-based predictions were more sensitive to noise and model architecture than depth image-based predictions. Taken together, these results indicate that three-dimensional point clouds do not provide a consistent advantage over depth images for BCS prediction in dairy cattle under the evaluated conditions.", "AI": {"tldr": "本研究比较了使用深度图像和点云数据进行奶牛体况评分预测的效果。", "motivation": "传统视觉评分主观且耗时，计算机视觉方法可以提高准确性。三维点云数据因其能更好地表示动物形态的几何特性而受到关注。", "method": "在四个设置下比较了深度图和点云数据：未分割原始数据、全身分割数据、后肢分割数据和手工特征数据。使用1020头奶牛的数据进行了跨验证。", "result": "深度图像模型在未分割和全身分割数据上表现优于点云模型；但在后肢分割数据上的表现相当。手工艺特征数据的准确性下降。", "conclusion": "三维点云数据并未表现出比深度图更优的一致性优势，其预测对噪声和模型架构更敏感。"}}
{"id": "2601.22518", "pdf": "https://arxiv.org/pdf/2601.22518", "abs": "https://arxiv.org/abs/2601.22518", "authors": ["Yuxin Zhang", "Fan Zhang"], "title": "Design Perspective on Materials Experience: A CiteSpace-Based Bibliometric and Visual Analysis of Interdisciplinary Research", "categories": ["cs.HC"], "comment": null, "summary": "Based on a bibliometric analysis of literature from 2005 to 2024, this study reveals that material experience is undergoing a profound transformation characterized by evolving material definitions, methodological advances, and increasing interdisciplinary integration. Material types now extend beyond traditional substances to encompass virtual and biological media, underscoring a growing emphasis on perception and interaction. Methodologically, the field has transitioned from subjective descriptions to data-driven, quantifiable models focused on objective sensory analysis and multisensory integration to enhance immersion. Key drivers, including human-machine perception convergence, material-driven interface interactions, and the embedding of intelligent interactive functions, propel the discipline toward an experience-centered paradigm reflecting a deep convergence of design, science, and technology. At the national/regional level, the United States, China, Japan, Germany, and the Netherlands lead in contributions, while France, the United Kingdom, and Romania demonstrate significant interdisciplinary progress. At the institutional level, Delft University of Technology, Justus Liebig University Giessen, and the Centre National de la Recherche Scientifique show significant advantages. In particular, the Material-Driven Design theory has established a foundational impact on the discipline, while, regarding general research trends, scholars from the United States, the Netherlands, and Germany maintain the highest academic visibility. Overall, material experience research is at a critical juncture, its future development will depend on progress in material innovation, technological integration, and perceptual quantification, as well as the establishment of socio-cultural values, all of which must be effectively unified through design to address complex evolving needs.", "AI": {"tldr": "基于文献计量学和可视化分析，研究材料体验领域的转变及其发展趋势。", "motivation": "探索材料体验领域从传统物质扩展至虚拟和生物介质的转变，以及方法论从主观描述转向数据驱动模型的发展趋势，并识别关键驱动力及未来发展方向。", "method": "采用CiteSpace工具进行文献计量学分析，揭示了2005年至2024年间材料体验领域的演变路径及其主要贡献者。", "result": "材料体验领域正经历从传统物质向虚拟和生物介质的转变，并且方法论上转向数据驱动、量化感官分析。主要驱动力包括人机感知融合、材料驱动界面交互以及智能互动功能嵌入，推动了以经验为中心的设计科学和技术整合。", "conclusion": "未来材料体验研究需在材料创新、技术集成和感知量化方面取得进展，并通过设计统一社会文化价值，解决复杂多变的需求。"}}
{"id": "2601.22517", "pdf": "https://arxiv.org/pdf/2601.22517", "abs": "https://arxiv.org/abs/2601.22517", "authors": ["Kangning Yin", "Zhe Cao", "Wentao Dong", "Weishuai Zeng", "Tianyi Zhang", "Qiang Zhang", "Jingbo Wang", "Jiangmiao Pang", "Ming Zhou", "Weinan Zhang"], "title": "RoboStriker: Hierarchical Decision-Making for Autonomous Humanoid Boxing", "categories": ["cs.RO"], "comment": null, "summary": "Achieving human-level competitive intelligence and physical agility in humanoid robots remains a major challenge, particularly in contact-rich and highly dynamic tasks such as boxing. While Multi-Agent Reinforcement Learning (MARL) offers a principled framework for strategic interaction, its direct application to humanoid control is hindered by high-dimensional contact dynamics and the absence of strong physical motion priors. We propose RoboStriker, a hierarchical three-stage framework that enables fully autonomous humanoid boxing by decoupling high-level strategic reasoning from low-level physical execution. The framework first learns a comprehensive repertoire of boxing skills by training a single-agent motion tracker on human motion capture data. These skills are subsequently distilled into a structured latent manifold, regularized by projecting the Gaussian-parameterized distribution onto a unit hypersphere. This topological constraint effectively confines exploration to the subspace of physically plausible motions. In the final stage, we introduce Latent-Space Neural Fictitious Self-Play (LS-NFSP), where competing agents learn competitive tactics by interacting within the latent action space rather than the raw motor space, significantly stabilizing multi-agent training. Experimental results demonstrate that RoboStriker achieves superior competitive performance in simulation and exhibits sim-to-real transfer. Our website is available at RoboStriker.", "AI": {"tldr": "本文提出了一种分层的RoboStriker框架，用于实现全自主的人形机器人拳击。", "motivation": "在接触丰富且高度动态的任务中（如拳击），实现人类级别的智能和运动灵活性仍然是一个重大挑战。直接应用多智能体强化学习到人形机器人的控制受到高维接触动力学的限制以及缺乏强物理动作先验知识的影响。", "method": "该框架首先通过训练单个代理的动作跟踪器来学习拳击技能，然后将这些技能提炼成结构化的潜在流形。在最终阶段，引入了潜在空间神经虚构自博弈（LS-NFSP），其中竞争代理通过在潜在动作空间中交互来学习对抗策略。", "result": "实验结果表明RoboStriker在模拟环境中实现了优越的竞技性能，并展示了从仿真到现实世界的转移能力。", "conclusion": "RoboStriker框架能够实现人形机器人的全自主拳击，证明了其在复杂任务中的有效性和适应性。"}}
{"id": "2601.22516", "pdf": "https://arxiv.org/pdf/2601.22516", "abs": "https://arxiv.org/abs/2601.22516", "authors": ["Md Mezbahul Islam", "John Michael Templeton", "Masrur Sobhan", "Christian Poellabauer", "Ananda Mohan Mondal"], "title": "SCOPE-PD: Explainable AI on Subjective and Clinical Objective Measurements of Parkinson's Disease for Precision Decision-Making", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 3 tables, 5 figures, to be published (full text online) in Springer (Springer CCIS series: electronic ISSN 1865-0937, print ISSN 1865-0929)", "summary": "Parkinson's disease (PD) is a chronic and complex neurodegenerative disorder influenced by genetic, clinical, and lifestyle factors. Predicting this disease early is challenging because it depends on traditional diagnostic methods that face issues of subjectivity, which commonly delay diagnosis. Several objective analyses are currently in practice to help overcome the challenges of subjectivity; however, a proper explanation of these analyses is still lacking. While machine learning (ML) has demonstrated potential in supporting PD diagnosis, existing approaches often rely on subjective reports only and lack interpretability for individualized risk estimation. This study proposes SCOPE-PD, an explainable AI-based prediction framework, by integrating subjective and objective assessments to provide personalized health decisions. Subjective and objective clinical assessment data are collected from the Parkinson's Progression Markers Initiative (PPMI) study to construct a multimodal prediction framework. Several ML techniques are applied to these data, and the best ML model is selected to interpret the results. Model interpretability is examined using SHAP-based analysis. The Random Forest algorithm achieves the highest accuracy of 98.66 percent using combined features from both subjective and objective test data. Tremor, bradykinesia, and facial expression are identified as the top three contributing features from the MDS-UPDRS test in the prediction of PD.", "AI": {"tldr": "SCOPE-PD是用于帕金森病预测的解释性AI框架，结合了主观和客观评估数据以提供个性化健康决策。", "motivation": "传统的诊断方法受主观性影响较大，导致疾病早期诊断延迟。现有的机器学习方法通常依赖于主观报告且缺乏可解释性。", "method": "利用Parkinson's Progression Markers Initiative (PPMI)研究的主观和客观临床评估数据构建了多模态预测框架，并应用多种机器学习技术进行模型选择与结果解读，使用SHAP分析来增强模型解释性。", "result": "随机森林算法在结合主客观测试数据后达到了98.66%的最高准确率。震颤、迟缓和面部表情被确定为MDS-UPDRS测试中预测帕金森病的重要特征。", "conclusion": "SCOPE-PD框架通过集成主观和客观评估提供了高精度的个性化风险估计，有助于改善帕金森病的早期诊断与治疗策略。"}}
{"id": "2601.22515", "pdf": "https://arxiv.org/pdf/2601.22515", "abs": "https://arxiv.org/abs/2601.22515", "authors": ["Jingtong Dou", "Chuancheng Shi", "Yemin Wang", "Shiming Guo", "Anqi Yi", "Wenhua Wu", "Li Zhang", "Fei Shen", "Tat-Seng Chua"], "title": "DNA: Uncovering Universal Latent Forgery Knowledge", "categories": ["cs.CV"], "comment": null, "summary": "As generative AI achieves hyper-realism, superficial artifact detection has become obsolete. While prevailing methods rely on resource-intensive fine-tuning of black-box backbones, we propose that forgery detection capability is already encoded within pre-trained models rather than requiring end-to-end retraining. To elicit this intrinsic capability, we propose the discriminative neural anchors (DNA) framework, which employs a coarse-to-fine excavation mechanism. First, by analyzing feature decoupling and attention distribution shifts, we pinpoint critical intermediate layers where the focus of the model logically transitions from global semantics to local anomalies. Subsequently, we introduce a triadic fusion scoring metric paired with a curvature-truncation strategy to strip away semantic redundancy, precisely isolating the forgery-discriminative units (FDUs) inherently imprinted with sensitivity to forgery traces. Moreover, we introduce HIFI-Gen, a high-fidelity synthetic benchmark built upon the very latest models, to address the lag in existing datasets. Experiments demonstrate that by solely relying on these anchors, DNA achieves superior detection performance even under few-shot conditions. Furthermore, it exhibits remarkable robustness across diverse architectures and against unseen generative models, validating that waking up latent neurons is more effective than extensive fine-tuning.", "AI": {"tldr": "提出了一种新的伪造检测框架DNA，通过挖掘预训练模型中的内在伪造知识来提高检测性能。", "motivation": "随着生成AI的超现实性提升，现有的伪造检测方法变得无效。该研究旨在探索无需从头到尾重新训练现有模型的情况下，如何有效利用其中固有的伪造识别能力。", "method": "DNA框架采用了一种由粗至细的方法来挖掘预训练模型中的内在伪造知识。通过分析特征解耦和注意力分布变化，找到关键中间层；引入三元融合评分指标结合曲率截断策略精确隔离出具有伪造敏感性的单元FDUs。", "result": "实验表明，仅依靠这些锚点，DNA框架在少量样本条件下仍能实现卓越的检测性能，并且对不同架构和未见过的生成模型都表现出良好的鲁棒性。", "conclusion": "研究表明激活预训练模型中固有的伪造知识比广泛微调更加有效。"}}
{"id": "2601.22513", "pdf": "https://arxiv.org/pdf/2601.22513", "abs": "https://arxiv.org/abs/2601.22513", "authors": ["Shi Fu", "Yingjie Wang", "Shengchao Hu", "Peng Wang", "Dacheng Tao"], "title": "Why Self-Rewarding Works: Theoretical Guarantees for Iterative Alignment of Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Self-Rewarding Language Models (SRLMs) achieve notable success in iteratively improving alignment without external feedback. Yet, despite their striking empirical progress, the core mechanisms driving their capabilities remain unelucidated, leaving a critical gap in theoretical understanding. This paper provides the first rigorous theoretical guarantees for SRLMs. We first establish a lower bound that characterizes the fundamental limits of a single update step, revealing a critical dependence on the quality of the initial model. We then derive finite-sample error bounds for the full iterative paradigm, showing that performance improves at a rate of $\\widetilde{\\mathcal{O}}\\left(1/\\sqrt{n}\\right)$ with sample size $n$. Crucially, our analysis reveals that the dependence on the initial model decays exponentially with the number of iterations $T$. This provides a formal explanation for why self-rewarding succeeds: it robustly overcomes poor initialization by steering the dynamics toward internal stability and consistency. Finally, we instantiate our theoretical framework for the linear softmax model class, yielding tailored guarantees that connect our high-level insights to practical model architectures.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.22510", "pdf": "https://arxiv.org/pdf/2601.22510", "abs": "https://arxiv.org/abs/2601.22510", "authors": ["Xingyu Zhao", "Darsh Sharma", "Rheeya Uppaal", "Yiqiao Zhong"], "title": "Shattered Compositionality: Counterintuitive Learning Dynamics of Transformers for Arithmetic", "categories": ["cs.LG", "cs.AI"], "comment": "33 pages, 27 figures", "summary": "Large language models (LLMs) often exhibit unexpected errors or unintended behavior, even at scale. While recent work reveals the discrepancy between LLMs and humans in skill compositions, the learning dynamics of skill compositions and the underlying cause of non-human behavior remain elusive. In this study, we investigate the mechanism of learning dynamics by training transformers on synthetic arithmetic tasks. Through extensive ablations and fine-grained diagnostic metrics, we discover that transformers do not reliably build skill compositions according to human-like sequential rules. Instead, they often acquire skills in reverse order or in parallel, which leads to unexpected mixing errors especially under distribution shifts--a phenomenon we refer to as shattered compositionality. To explain these behaviors, we provide evidence that correlational matching to the training data, rather than causal or procedural composition, shapes learning dynamics. We further show that shattered compositionality persists in modern LLMs and is not mitigated by pure model scaling or scratchpad-based reasoning. Our results reveal a fundamental mismatch between a model's learning behavior and desired skill compositions, with implications for reasoning reliability, out-of-distribution robustness, and alignment.", "AI": {"tldr": "研究探索了大型语言模型（LLMs）在合成算术任务上学习的动态机制，发现它们不具备人类那样的顺序技能组合能力。", "motivation": "揭示大型语言模型和人类之间的技能组合差异以及这种行为的根本原因。", "method": "通过广泛的消融实验和精细的诊断指标研究变压器在合成算术任务上的训练过程。", "result": "发现变压器往往按照与人类相反或并行的方式获取技能，导致分布转移下的混合错误现象。", "conclusion": "指出模型的学习行为与期望的技能组合之间存在根本性的不匹配，影响了推理可靠性和出界分布稳健性。"}}
{"id": "2601.22509", "pdf": "https://arxiv.org/pdf/2601.22509", "abs": "https://arxiv.org/abs/2601.22509", "authors": ["Jiyuan Pei", "Yi Mei", "Jialin Liu", "Mengjie Zhang", "Xin Yao"], "title": "Keep Rehearsing and Refining: Lifelong Learning Vehicle Routing under Continually Drifting Tasks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing neural solvers for vehicle routing problems (VRPs) are typically trained either in a one-off manner on a fixed set of pre-defined tasks or in a lifelong manner on several tasks arriving sequentially, assuming sufficient training on each task. Both settings overlook a common real-world property: problem patterns may drift continually over time, yielding massive tasks sequentially arising while offering only limited training resources per task. In this paper, we study a novel lifelong learning paradigm for neural VRP solvers under continually drifting tasks over learning time steps, where sufficient training for any given task at any time is not available. We propose Dual Replay with Experience Enhancement (DREE), a general framework to improve learning efficiency and mitigate catastrophic forgetting under such drift. Extensive experiments show that, under such continual drift, DREE effectively learns new tasks, preserves prior knowledge, improves generalization to unseen tasks, and can be applied to diverse existing neural solvers.", "AI": {"tldr": "提出了一种新的终身学习框架DREE，用于解决车辆路径规划问题下的持续任务漂移。", "motivation": "现有神经求解器在处理车辆路径规划问题时，要么一次性训练固定的任务集，要么顺序性地训练多个任务。这些方法忽略了实际应用中任务模式会随时间不断变化的问题。", "method": "提出了一种新的终身学习框架DREE，该框架通过重复回放和经验增强来提高学习效率，并减少灾难性遗忘问题的发生。", "result": "实验表明，在持续的任务漂移情况下，DREE能够有效学习新任务，保持先前的知识，提升对未见过任务的泛化能力。", "conclusion": "DREE是一种有效的框架，适用于各种现有的神经求解器处理车辆路径规划问题中的持续任务漂移。"}}
{"id": "2601.22508", "pdf": "https://arxiv.org/pdf/2601.22508", "abs": "https://arxiv.org/abs/2601.22508", "authors": ["Gyuwon Han", "Young Kyun Jang", "Chanho Eom"], "title": "CoVA: Text-Guided Composed Video Retrieval for Audio-Visual Content", "categories": ["cs.CV"], "comment": "Please visit our project page at https://perceptualai-lab.github.io/CoVA/", "summary": "Composed Video Retrieval (CoVR) aims to retrieve a target video from a large gallery using a reference video and a textual query specifying visual modifications. However, existing benchmarks consider only visual changes, ignoring videos that differ in audio despite visual similarity. To address this limitation, we introduce Composed retrieval for Video with its Audio CoVA, a new retrieval task that accounts for both visual and auditory variations. To support this, we construct AV-Comp, a benchmark consisting of video pairs with cross-modal changes and corresponding textual queries that describe the differences. We also propose AVT Compositional Fusion (AVT), which integrates video, audio, and text features by selectively aligning the query to the most relevant modality. AVT outperforms traditional unimodal fusion and serves as a strong baseline for CoVA. Examples from the proposed dataset, including both visual and auditory information, are available at https://perceptualai-lab.github.io/CoVA/.", "AI": {"tldr": "本文提出了一种新的检索任务CoVA，旨在同时考虑视觉和听觉变化来检索视频。", "motivation": "现有基准仅关注视觉变化，忽略了尽管视觉相似但音频不同的视频。为解决这一问题，引入了同时处理视觉和听觉差异的任务CoVA，并构建了一个包含跨模态变化的视频对及其文本查询的新数据集AV-Comp。", "method": "提出了一种AVT Compositional Fusion方法，该方法通过选择性地将查询与最相关的模式对齐来整合视频、音频和文本特征。", "result": "所提出的AVT在传统单模态融合上表现更好，成为CoVA任务的强大基线。", "conclusion": "本文通过引入新的检索任务CoVA及其数据集AV-Comp以及提出的方法AVT，证明了同时考虑视觉和听觉变化对于视频检索的重要性。"}}
{"id": "2601.22507", "pdf": "https://arxiv.org/pdf/2601.22507", "abs": "https://arxiv.org/abs/2601.22507", "authors": ["Xin Jiang", "Jingwen Chen", "Yehao Li", "Yingwei Pan", "Kezhou Chen", "Zechao Li", "Ting Yao", "Tao Mei"], "title": "DreamVAR: Taming Reinforced Visual Autoregressive Model for High-Fidelity Subject-Driven Image Generation", "categories": ["cs.CV"], "comment": "Accepted By ICASSP 2026", "summary": "Recent advances in subject-driven image generation using diffusion models have attracted considerable attention for their remarkable capabilities in producing high-quality images. Nevertheless, the potential of Visual Autoregressive (VAR) models, despite their unified architecture and efficient inference, remains underexplored. In this work, we present DreamVAR, a novel framework for subject-driven image synthesis built upon a VAR model that employs next-scale prediction. Technically, multi-scale features of the reference subject are first extracted by a visual tokenizer. Instead of interleaving these conditional features with target image tokens across scales, our DreamVAR pre-fills the full subject feature sequence prior to predicting target image tokens. This design simplifies autoregressive dependencies and mitigates the train-test discrepancy in multi-scale conditioning scenario within the VAR paradigm. DreamVAR further incorporates reinforcement learning to jointly enhance semantic alignment and subject consistency. Extensive experiments demonstrate that DreamVAR achieves superior appearance preservation compared to leading diffusion-based methods.", "AI": {"tldr": "本文提出了一种名为DreamVAR的新框架，用于基于视觉自回归模型的主体驱动图像生成。", "motivation": "尽管视觉自回归（VAR）模型具有统一架构和高效的推理能力，但其潜力尚未得到充分探索。相比之下，扩散模型在主体驱动图像生成方面引起了广泛关注。", "method": "DreamVAR利用视觉分词器提取参考主体的多尺度特征，并将这些条件特征预先填充到目标图像令牌之前预测目标图像令牌的位置。此外，该框架还结合了强化学习以增强语义对齐和主体一致性。", "result": "实验结果表明，DreamVAR在外观保持方面优于当前领先的扩散模型方法。", "conclusion": "通过引入多尺度特征预填充及强化学习机制，DreamVAR简化了自回归依赖性，并在主体驱动的图像生成任务中取得了优越的结果。"}}
{"id": "2601.22501", "pdf": "https://arxiv.org/pdf/2601.22501", "abs": "https://arxiv.org/abs/2601.22501", "authors": ["Renjie Lu", "Xulong Zhang", "Xiaoyang Qu", "Jianzong Wang", "Shangfei Wang"], "title": "MIRRORTALK: Forging Personalized Avatars Via Disentangled Style and Hierarchical Motion Control", "categories": ["cs.CV", "cs.SD"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Synthesizing personalized talking faces that uphold and highlight a speaker's unique style while maintaining lip-sync accuracy remains a significant challenge. A primary limitation of existing approaches is the intrinsic confounding of speaker-specific talking style and semantic content within facial motions, which prevents the faithful transfer of a speaker's unique persona to arbitrary speech. In this paper, we propose MirrorTalk, a generative framework based on a conditional diffusion model, combined with a Semantically-Disentangled Style Encoder (SDSE) that can distill pure style representations from a brief reference video. To effectively utilize this representation, we further introduce a hierarchical modulation strategy within the diffusion process. This mechanism guides the synthesis by dynamically balancing the contributions of audio and style features across distinct facial regions, ensuring both precise lip-sync accuracy and expressive full-face dynamics. Extensive experiments demonstrate that MirrorTalk achieves significant improvements over state-of-the-art methods in terms of lip-sync accuracy and personalization preservation.", "AI": {"tldr": "本文提出了一种生成框架MirrorTalk，用于合成个性化说话人脸。", "motivation": "现有方法在说话风格和个人化保持方面存在挑战，MirrorTalk旨在解决这些问题，通过分离说话者特有的风格和语义内容来实现个性化的口型同步。", "method": "MirrorTalk基于条件扩散模型结合了语义解耦风格编码器（SDSE），从参考视频中提取纯风格表示，并引入分层调制策略以动态平衡音频和风格特征对不同面部区域的影响。", "result": "实验表明，MirrorTalk在口型同步准确性和个性化保持方面优于现有方法。", "conclusion": "MirrorTalk框架显著改善了说话人脸的个人化和精确度表现。"}}
{"id": "2601.22497", "pdf": "https://arxiv.org/pdf/2601.22497", "abs": "https://arxiv.org/abs/2601.22497", "authors": ["Zifan Zhao", "Peilan Xu", "Wenjian Luo"], "title": "Fairness-Aware Performance Evaluation for Multi-Party Multi-Objective Optimization", "categories": ["cs.NE"], "comment": null, "summary": "In multiparty multiobjective optimization problems, solution sets are usually evaluated using classical performance metrics, aggregated across DMs. However, such mean-based evaluations may be unfair by favoring certain parties, as they assume identical geometric approximation quality to each party's PF carries comparable evaluative significance. Moreover, prevailing notions of MPMOP optimal solutions are restricted to strictly common Pareto optimal solutions, representing a narrow form of cooperation in multiparty decision making scenarios. These limitations obscure whether a solution set reflects balanced relative gains or meaningful consensus among heterogeneous DMs. To address these issues, this paper develops a fairness-aware performance evaluation framework grounded in a generalized notion of consensus solutions. From a cooperative game-theoretic perspective, we formalize four axioms that a fairness-aware evaluation function for MPMOPs should satisfy. By introducing a concession rate vector to quantify acceptable compromises by individual DMs, we generalize the classical definition of MPMOP optimal solutions and embed classical performance metrics into a Nash-product-based evaluation framework, which is theoretically shown to satisfy all axioms. To support empirical validation, we further construct benchmark problems that extend existing MPMOP suites by incorporating consensus-deficient negotiation structures. Experimental results demonstrate that the proposed evaluation framework is able to distinguish algorithmic performance in a manner consistent with consensus-aware fairness considerations. Specifically, algorithms converging toward strictly common solutions are assigned higher evaluation scores when such solutions exist, whereas in the absence of strictly common solutions, algorithms that effectively cover the commonly acceptable region are more favorably evaluated.", "AI": {"tldr": "开发了一个基于共识解的多目标优化问题公平性评估框架。", "motivation": "现有性能指标可能会偏袒某些方，忽视各决策者之间的相对收益平衡和有意义的一致性。因此提出了一个公平性感知评估框架解决这些问题。", "method": "引入补偿率向量量化个体决策者的可接受妥协程度，并将经典性能度量嵌入基于纳什乘积的评价框架中以满足所有公理。", "result": "实验结果表明，所提出的评估框架能够在符合共识感知公平性考虑的情况下区分算法性能。", "conclusion": "该方法在多目标优化问题中的应用可以更好地反映解决方案集合是否反映了均衡相对收益或异质决策者之间的有意义的一致性。"}}
{"id": "2601.22496", "pdf": "https://arxiv.org/pdf/2601.22496", "abs": "https://arxiv.org/abs/2601.22496", "authors": ["Jinu Hyeon", "Woobin Park", "Hongjoon Ahn", "Taesup Moon"], "title": "Action-Sufficient Goal Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Hierarchical policies in offline goal-conditioned reinforcement learning (GCRL) addresses long-horizon tasks by decomposing control into high-level subgoal planning and low-level action execution. A critical design choice in such architectures is the goal representation-the compressed encoding of goals that serves as the interface between these levels. Existing approaches commonly derive goal representations while learning value functions, implicitly assuming that preserving information sufficient for value estimation is adequate for optimal control. We show that this assumption can fail, even when the value estimation is exact, as such representations may collapse goal states that need to be differentiated for action learning. To address this, we introduce an information-theoretic framework that defines action sufficiency, a condition on goal representations necessary for optimal action selection. We prove that value sufficiency does not imply action sufficiency and empirically verify that the latter is more strongly associated with control success in a discrete environment. We further demonstrate that standard log-loss training of low-level policies naturally induces action-sufficient representations. Our experimental results a popular benchmark demonstrate that our actor-derived representations consistently outperform representations learned via value estimation.", "AI": {"tldr": "本文提出了一个信息论框架，定义了目标表示中的“行动充分性”概念，并证明了价值充分性和行动充分性的区别。", "motivation": "现有的基于层次策略的离线目标条件强化学习方法在目标表示中假设保留足够的信息以用于价值估计就足够进行最优控制。然而，在某些情况下这种表示可能无法区分需要分别采取不同动作的目标状态，进而影响性能。", "method": "本文提出了一个信息论框架来定义行动充分性，这是一种确保最佳操作选择的目标表示的必要条件，并通过实验验证了这一概念的重要性及应用效果。", "result": "实验证明，在离散环境中标准对数损失训练低层策略自然地诱导出行动充足性的目标表示。这些表示在流行的基准测试中表现优于通过价值估计学习到的表示。", "conclusion": "本文证明了现有的基于层次政策的方法可能因目标表示问题而受到限制，并提出了一个理论框架和实验方法来解决这个问题，提高了控制性能的表现。"}}
{"id": "2601.22492", "pdf": "https://arxiv.org/pdf/2601.22492", "abs": "https://arxiv.org/abs/2601.22492", "authors": ["Duncan McCain", "Hossein Kashiani", "Fatemeh Afghah"], "title": "PromptMAD: Cross-Modal Prompting for Multi-Class Visual Anomaly Localization", "categories": ["cs.CV"], "comment": "Accepted to ICASSP 2026", "summary": "Visual anomaly detection in multi-class settings poses significant challenges due to the diversity of object categories, the scarcity of anomalous examples, and the presence of camouflaged defects. In this paper, we propose PromptMAD, a cross-modal prompting framework for unsupervised visual anomaly detection and localization that integrates semantic guidance through vision-language alignment. By leveraging CLIP-encoded text prompts describing both normal and anomalous class-specific characteristics, our method enriches visual reconstruction with semantic context, improving the detection of subtle and textural anomalies. To further address the challenge of class imbalance at the pixel level, we incorporate Focal loss function, which emphasizes hard-to-detect anomalous regions during training. Our architecture also includes a supervised segmentor that fuses multi-scale convolutional features with Transformer-based spatial attention and diffusion iterative refinement, yielding precise and high-resolution anomaly maps. Extensive experiments on the MVTec-AD dataset demonstrate that our method achieves state-of-the-art pixel-level performance, improving mean AUC to 98.35% and AP to 66.54%, while maintaining efficiency across diverse categories.", "AI": {"tldr": "该论文提出了PromptMAD，一种用于多类视觉异常检测和定位的跨模态提示框架。", "motivation": "在多类别设置中进行视觉异常检测面临挑战，包括对象类别的多样性、罕见的异常示例以及伪装缺陷的存在。该研究旨在通过语义指导解决这些问题，并提高对细微纹理异常的检测能力。", "method": "PromptMAD利用CLIP编码文本提示描述正常和异常类别特性，增强了视觉重建中的语义背景，同时采用了Focal损失函数以强调训练中难以发现的异常区域。架构包括一个监督分割器，融合了多尺度卷积特征与基于Transformer的空间注意和扩散迭代细化。", "result": "实验表明，该方法在MVTec-AD数据集上实现了最先进的像素级性能，将平均AUC提高到98.35%，AP提高至66.54%，同时保持了跨不同类别的效率。", "conclusion": "PromptMAD通过融合视觉和语言信息以及有效的损失函数设计，在多类别视觉异常检测任务中表现出色。"}}
{"id": "2601.22486", "pdf": "https://arxiv.org/pdf/2601.22486", "abs": "https://arxiv.org/abs/2601.22486", "authors": ["Christian Bergh", "Alexandra Vassar", "Natasha Banks", "Jessica Xu", "Jake Renzella"], "title": "AI Literacy, Safety Awareness, and STEM Career Aspirations of Australian Secondary Students: Evaluating the Impact of Workshop Interventions", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Deepfakes and other forms of synthetic media pose growing safety risks for adolescents, yet evidence on students' exposure and related behaviours remains limited. This study evaluates the impact of Day of AI Australia's workshop-based intervention designed to improve AI literacy and conceptual understanding among Australian secondary students (Years 7-10). Using a mixed-methods approach with pre- and post-intervention surveys (N=205 pre; N=163 post), we analyse changes in students' ability to identify AI in everyday tools, their understanding of AI ethics, training, and safety, and their interest in STEM-related careers. Baseline data revealed notable synthetic media risks: 82.4% of students reported having seen deepfakes, 18.5% reported sharing them, and 7.3% reported creating them. Results show higher self-reported AI knowledge and confidence after the intervention, alongside improved recognition of AI in widely used platforms such as Netflix, Spotify, and TikTok. This pattern suggests a shift from seeing these tools as merely \"algorithm-based\" to recognising them as AI-driven systems. Students also reported increased interest in STEM careers post-workshop; however, effect sizes were small, indicating that sustained approaches beyond one-off workshops may be needed to influence longer-term aspirations. Overall, the findings support scalable AI literacy programs that pair foundational AI concepts with an explicit emphasis on synthetic media safety.", "AI": {"tldr": "评估AI工作坊干预对学生AI素养和STEM职业兴趣的影响", "motivation": "为了解决青少年面临的深度伪造和其他合成媒体的安全风险，研究通过工作坊提高学生的AI知识和伦理意识，并探索其对STEM职业兴趣的影响", "method": "采用混合方法研究，包括前后调查问卷（前测205人，后测163人），分析学生识别AI的能力、理解AI伦理的水平以及在STEM领域职业兴趣的变化", "result": "结果显示工作坊干预提高了学生的自我报告AI知识和信心，并增强了他们对日常平台如Netflix, Spotify, TikTok为AI驱动系统的认知。同时，学生的职业兴趣有所提升，但效果较小，表明持续性方案可能更有效果", "conclusion": "研究支持可扩展的AI素养项目，结合基础AI概念与合成媒体安全教育"}}
{"id": "2601.22485", "pdf": "https://arxiv.org/pdf/2601.22485", "abs": "https://arxiv.org/abs/2601.22485", "authors": ["Naen Xu", "Jinghuai Zhang", "Ping He", "Chunyi Zhou", "Jun Wang", "Zhihui Fu", "Tianyu Du", "Zhaoxiang Wang", "Shouling Ji"], "title": "FraudShield: Knowledge Graph Empowered Defense for LLMs against Fraud Attacks", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "WWW 2026", "summary": "Large language models (LLMs) have been widely integrated into critical automated workflows, including contract review and job application processes. However, LLMs are susceptible to manipulation by fraudulent information, which can lead to harmful outcomes. Although advanced defense methods have been developed to address this issue, they often exhibit limitations in effectiveness, interpretability, and generalizability, particularly when applied to LLM-based applications. To address these challenges, we introduce FraudShield, a novel framework designed to protect LLMs from fraudulent content by leveraging a comprehensive analysis of fraud tactics. Specifically, FraudShield constructs and refines a fraud tactic-keyword knowledge graph to capture high-confidence associations between suspicious text and fraud techniques. The structured knowledge graph augments the original input by highlighting keywords and providing supporting evidence, guiding the LLM toward more secure responses. Extensive experiments show that FraudShield consistently outperforms state-of-the-art defenses across four mainstream LLMs and five representative fraud types, while also offering interpretable clues for the model's generations.", "AI": {"tldr": "本文介绍了FraudShield框架，旨在通过知识图谱增强大型语言模型（LLM）对欺诈攻击的防御能力。", "motivation": "由于大型语言模型在关键自动工作流程中广泛应用，但易受欺诈信息操纵的影响，因此需要一种有效、可解释且具有普适性的防御方法来应对这一问题。", "method": "通过构建和细化欺诈策略-关键词知识图谱，FraudShield能够捕捉到可疑文本与欺诈技术之间的高置信度关联，并以此指导LLM生成更安全的响应。", "result": "实验表明，FraudShield在四种主流大型语言模型及五种代表性欺诈类型中均优于最先进的防御方法，并提供了可解释的线索。", "conclusion": "基于知识图谱增强的大规模语言模型防御框架（FraudShield）能够有效提高LLM对欺诈攻击的防护能力，同时保持良好的可解释性。"}}
{"id": "2601.22483", "pdf": "https://arxiv.org/pdf/2601.22483", "abs": "https://arxiv.org/abs/2601.22483", "authors": ["Junfei Xie", "Peng Pan", "Xulong Zhang"], "title": "Head-Aware Visual Cropping: Enhancing Fine-Grained VQA with Attention-Guided Subimage", "categories": ["cs.CV"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Multimodal Large Language Models (MLLMs) show strong performance in Visual Question Answering (VQA) but remain limited in fine-grained reasoning due to low-resolution inputs and noisy attention aggregation. We propose \\textbf{Head Aware Visual Cropping (HAVC)}, a training-free method that improves visual grounding by leveraging a selectively refined subset of attention heads. HAVC first filters heads through an OCR-based diagnostic task, ensuring that only those with genuine grounding ability are retained. At inference, these heads are further refined using spatial entropy for stronger spatial concentration and gradient sensitivity for predictive contribution. The fused signals produce a reliable Visual Cropping Guidance Map, which highlights the most task-relevant region and guides the cropping of a subimage subsequently provided to the MLLM together with the image-question pair. Extensive experiments on multiple fine-grained VQA benchmarks demonstrate that HAVC consistently outperforms state-of-the-art cropping strategies, achieving more precise localization, stronger visual grounding, providing a simple yet effective strategy for enhancing precision in MLLMs.", "AI": {"tldr": "通过Head-Aware Visual Cropping（HAVC）方法改进视觉问答中的精细推理。", "motivation": "多模态大型语言模型在低分辨率输入和噪声注意力聚集下的表现受限，为此提出一种训练自由的方法提升视觉接地能力。", "method": "HAVC首先通过OCR诊断任务过滤头部，然后利用空间熵进一步细化，并引导生成可靠的地图进行图像裁剪，以提高精度。", "result": "实验表明，该方法在多个精细推理VQA基准上优于现有方法，提高了精确度和视觉接地能力。", "conclusion": "提出的方法提供了一种简单有效的策略来提升多模态大型语言模型的准确性。"}}
{"id": "2601.22480", "pdf": "https://arxiv.org/pdf/2601.22480", "abs": "https://arxiv.org/abs/2601.22480", "authors": ["Seungu Han", "Sungho Lee", "Kyogu Lee"], "title": "Rethinking Speech Representation Aggregation in Speech Enhancement: A Phonetic Mutual Information Perspective", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to ICASSP 2026", "summary": "Recent speech enhancement (SE) models increasingly leverage self-supervised learning (SSL) representations for their rich semantic information. Typically, intermediate features are aggregated into a single representation via a lightweight adaptation module. However, most SSL models are not trained for noise robustness, which can lead to corrupted semantic representations. Moreover, the adaptation module is trained jointly with the SE model, potentially prioritizing acoustic details over semantic information, contradicting the original purpose. To address this issue, we first analyze the behavior of SSL models on noisy speech from an information-theoretic perspective. Specifically, we measure the mutual information (MI) between the corrupted SSL representations and the corresponding phoneme labels, focusing on preservation of linguistic contents. Building upon this analysis, we introduce the linguistic aggregation layer, which is pre-trained to maximize MI with phoneme labels (with optional dynamic aggregation) and then frozen during SE training. Experiments show that this decoupled approach improves Word Error Rate (WER) over jointly optimized baselines, demonstrating the benefit of explicitly aligning the adaptation module with linguistic contents.", "AI": {"tldr": "重新思考语音表示聚合在语音增强中的应用，从语素互信息的角度出发。", "motivation": "自监督学习（SSL）模型的中间特征通常被聚合为单一表示，但这些模型没有经过噪声鲁棒性的训练，可能导致语义表示受损。现有的轻量级适应模块可能优先考虑声学细节而不是语义信息。", "method": "从信息论的角度分析了SSL模型在嘈杂语音上的行为，并测量了腐败的SSL表示与对应音素标签之间的互信息（MI），引入了预先训练以最大化与音素标签的MI的语用聚合层，然后冻结在此期间进行语音增强训练。", "result": "实验表明，这种解耦的方法优于联合优化基线，显示出明确地将适应模块对准语言内容的好处，提高了单词错误率（WER）。", "conclusion": "重新考虑了语音表示聚合在语音增强中的应用，并通过引入专门针对语素互信息的预训练层改进了噪声鲁棒性。"}}
{"id": "2601.22476", "pdf": "https://arxiv.org/pdf/2601.22476", "abs": "https://arxiv.org/abs/2601.22476", "authors": ["Ruizhe Zhong", "Xingbo Du", "Junchi Yan"], "title": "RulePlanner: All-in-One Reinforcement Learner for Unifying Design Rules in 3D Floorplanning", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Floorplanning determines the coordinate and shape of each module in Integrated Circuits. With the scaling of technology nodes, in floorplanning stage especially 3D scenarios with multiple stacked layers, it has become increasingly challenging to adhere to complex hardware design rules. Current methods are only capable of handling specific and limited design rules, while violations of other rules require manual and meticulous adjustment. This leads to labor-intensive and time-consuming post-processing for expert engineers. In this paper, we propose an all-in-one deep reinforcement learning-based approach to tackle these challenges, and design novel representations for real-world IC design rules that have not been addressed by previous approaches. Specifically, the processing of various hardware design rules is unified into a single framework with three key components: 1) novel matrix representations to model the design rules, 2) constraints on the action space to filter out invalid actions that cause rule violations, and 3) quantitative analysis of constraint satisfaction as reward signals. Experiments on public benchmarks demonstrate the effectiveness and validity of our approach. Furthermore, transferability is well demonstrated on unseen circuits. Our framework is extensible to accommodate new design rules, thus providing flexibility to address emerging challenges in future chip design. Code will be available at: https://github.com/Thinklab-SJTU/EDA-AI", "AI": {"tldr": "本文提出了一种基于深度强化学习的统一框架，用于解决集成电路三维楼层规划中复杂的硬件设计规则问题。", "motivation": "随着技术节点的发展，集成电路三维楼层规划中的复杂硬件设计规则使得当前方法难以应对。这导致了繁琐的手动调整和专家工程师的工作负担增加。", "method": "本文提出了一种基于深度强化学习的方法，使用新颖的矩阵表示来建模设计规则，并通过限制动作空间来防止违规行为，同时将约束满足情况作为奖励信号。", "result": "实验结果表明该方法在公共基准上的有效性和通用性，并且展示了对未见过电路的良好迁移能力。", "conclusion": "本文提出的框架灵活可扩展，能够应对未来芯片设计中的新兴挑战。"}}
{"id": "2601.22472", "pdf": "https://arxiv.org/pdf/2601.22472", "abs": "https://arxiv.org/abs/2601.22472", "authors": ["Hibiki Ito", "Chia-Yu Hsu", "Hiroaki Ogata"], "title": "The Third-Party Access Effect: An Overlooked Challenge in Secondary Use of Educational Real-World Data", "categories": ["cs.CY", "cs.CR", "cs.HC"], "comment": "18 pages, 7 figures", "summary": "Secondary use of growing real-world data (RWD) in education offers significant opportunities for research, yet privacy practices intended to enable third-party access to such RWD are rarely evaluated for their implications for downstream analyses. As a result, potential problems introduced by otherwise standard privacy practices may remain unnoticed. To address this gap, we investigate potential issues arising from common practices by assessing (1) the re-identification risk of fine-grained RWD, (2) how communicating such risks influences learners' privacy behaviour, and (3) the sensitivity of downstream analytical conclusions to resulting changes in the data. We focus on these practices because re-identification risk and stakeholder communication can jointly influence the data shared with third parties. We find that substantial re-identification risk in RWD, when communicated to stakeholders, can induce opt-outs and non-self-disclosure behaviours. Sensitivity analysis demonstrates that these behavioural changes can meaningfully alter the shared data, limiting validity of secondary-use findings. We conceptualise this phenomenon as the third-party access effect (3PAE) and discuss implications for trustworthy secondary use of educational RWD.", "AI": {"tldr": "探讨教育领域中的真实世界数据（RWD）在第三方访问时的隐私问题及其对下游分析的影响。", "motivation": "当前对于教育领域中使用真实世界数据的研究虽有许多机会，但相关的隐私保护措施往往没有被充分评估。因此，作者希望通过研究来揭示这些常见的隐私保护实践可能带来的潜在风险，并探讨如何通过有效的沟通减轻这些问题。", "method": "通过对细粒度的真实世界数据重新识别的风险进行评估、分析沟通此类风险如何影响学习者的隐私行为以及下游分析结论对由此引发的数据变化的敏感性来进行研究。", "result": "发现当向利益相关者传达真实世界数据中的再识别风险时，可能会导致用户选择退出或非自我披露的行为。这些行为的变化可以显著改变共享的数据，从而限制了二次使用结果的有效性。", "conclusion": "提出了“第三方访问效应（3PAE）”这一概念，并讨论了其对教育领域中真实世界数据的可信度再利用的影响及可能采取的措施来应对这些问题。"}}
{"id": "2601.22468", "pdf": "https://arxiv.org/pdf/2601.22468", "abs": "https://arxiv.org/abs/2601.22468", "authors": ["Wenqiang Zu", "Shenghao Xie", "Bo Lei", "Lei Ma"], "title": "Training-Free Representation Guidance for Diffusion Models with a Representation Alignment Projector", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent progress in generative modeling has enabled high-quality visual synthesis with diffusion-based frameworks, supporting controllable sampling and large-scale training. Inference-time guidance methods such as classifier-free and representative guidance enhance semantic alignment by modifying sampling dynamics; however, they do not fully exploit unsupervised feature representations. Although such visual representations contain rich semantic structure, their integration during generation is constrained by the absence of ground-truth reference images at inference. This work reveals semantic drift in the early denoising stages of diffusion transformers, where stochasticity results in inconsistent alignment even under identical conditioning. To mitigate this issue, we introduce a guidance scheme using a representation alignment projector that injects representations predicted by a projector into intermediate sampling steps, providing an effective semantic anchor without modifying the model architecture. Experiments on SiTs and REPAs show notable improvements in class-conditional ImageNet synthesis, achieving substantially lower FID scores; for example, REPA-XL/2 improves from 5.9 to 3.3, and the proposed method outperforms representative guidance when applied to SiT models. The approach further yields complementary gains when combined with classifier-free guidance, demonstrating enhanced semantic coherence and visual fidelity. These results establish representation-informed diffusion sampling as a practical strategy for reinforcing semantic preservation and image consistency.", "AI": {"tldr": "本文提出了一种训练自由的表示指导方案，通过引入表示对齐投影器来改善扩散模型中的语义漂移问题。", "motivation": "现有的引导方法未能充分利用无监督特征表示，并且在推理过程中缺乏真实参考图像。早期去噪阶段的随机性导致了即使在相同条件下的不一致对齐。", "method": "引入了一个表示对齐投影器，在中间采样步骤中注入由投影器预测的表示，提供有效的语义锚点而不修改模型架构。", "result": "实验表明所提出的方案显著提高了类条件下ImageNet合成的效果；REPA-XL/2从5.9降低到3.3。该方法在结合分类器自由引导时也显示出互补增益，展示了增强的语义一致性和视觉保真度。", "conclusion": "表示导向扩散采样作为强化语义保持和图像一致性的实用策略已经确立起来。"}}
{"id": "2601.22467", "pdf": "https://arxiv.org/pdf/2601.22467", "abs": "https://arxiv.org/abs/2601.22467", "authors": ["Jiaqi Shi", "Xulong Zhang", "Xiaoyang Qu", "Jianzong Wang"], "title": "CARE: Multi-Task Pretraining for Latent Continuous Action Representation in Robot Control", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Recent advances in Vision-Language-Action (VLA) models have shown promise for robot control, but their dependence on action supervision limits scalability and generalization. To address this challenge, we introduce CARE, a novel framework designed to train VLA models for robotic task execution. Unlike existing methods that depend on action annotations during pretraining, CARE eliminates the need for explicit action labels by leveraging only video-text pairs. These weakly aligned data sources enable the model to learn continuous latent action representations through a newly designed multi-task pretraining objective. During fine-tuning, a small set of labeled data is used to train the action head for control. Experimental results across various simulation tasks demonstrate CARE's superior success rate, semantic interpretability, and ability to avoid shortcut learning. These results underscore CARE's scalability, interpretability, and effectiveness in robotic control with weak supervision.", "AI": {"tldr": "介绍了一种名为CARE的新框架，用于训练VLA模型进行机器人任务执行。", "motivation": "现有方法依赖于动作标注，在预训练过程中限制了可扩展性和泛化能力。为解决这一问题，提出一种不需要显式动作标签的新型框架。", "method": "通过仅使用视频-文本对作为弱相关数据源，设计了一种新的多任务预训练目标，使模型能够学习连续的动作表示。在微调阶段，利用少量标注数据训练控制动作头。", "result": "实验结果显示，与现有方法相比，CARE的执行成功率更高、语义可解释性更强，并且避免了捷径学习。", "conclusion": "这些结果证明了CARE在使用弱监督的情况下进行机器人控制时具有良好的扩展性、可解释性和有效性。"}}
{"id": "2601.22458", "pdf": "https://arxiv.org/pdf/2601.22458", "abs": "https://arxiv.org/abs/2601.22458", "authors": ["Sida He", "Lingxi Xie", "Xiaopeng Zhang", "Qi Tian"], "title": "AI Decodes Historical Chinese Archives to Reveal Lost Climate History", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "comment": "60 pages, 4 figures in the main text, 25 figures and 10 tables in the appendix", "summary": "Historical archives contain qualitative descriptions of climate events, yet converting these into quantitative records has remained a fundamental challenge. Here we introduce a paradigm shift: a generative AI framework that inverts the logic of historical chroniclers by inferring the quantitative climate patterns associated with documented events. Applied to historical Chinese archives, it produces the sub-annual precipitation reconstruction for southeastern China over the period 1368-1911 AD. Our reconstruction not only quantifies iconic extremes like the Ming Dynasty's Great Drought but also, crucially, maps the full spatial and seasonal structure of El Ni$ñ$o influence on precipitation in this region over five centuries, revealing dynamics inaccessible in shorter modern records. Our methodology and high-resolution climate dataset are directly applicable to climate science and have broader implications for the historical and social sciences.", "AI": {"tldr": "通过人工智能框架，将历史档案中的气候描述转换为定量记录。", "motivation": "历史档案包含有关气候变化的定性描述，但将其转化为量化记录一直是重大挑战。这项工作旨在解决这一难题，并揭示更长时间尺度内的气候动态。", "method": "引入了一种生成式AI框架，用于从文献记载中推断出定量化的气候模式，并应用于中国历史档案，重建了1368-1911年期间中国东南部的降水记录。", "result": "成功地量化了明王朝大旱等标志性极端事件，并揭示了过去五个世纪内厄尔尼诺现象对这一地区降水量影响的空间和季节性结构，这些发现无法从现代较短时间记录中获得。", "conclusion": "该研究的方法和技术在气候科学领域有直接应用价值，也具有更广泛的历史和社会科学意义。"}}
{"id": "2601.22456", "pdf": "https://arxiv.org/pdf/2601.22456", "abs": "https://arxiv.org/abs/2601.22456", "authors": ["Kun Fang", "Qinghua Tao", "Junxu Liu", "Yaxin Xiao", "Qingqing Ye", "Jian Sun", "Haibo Hu"], "title": "Machine Unlearning in Low-Dimensional Feature Subspace", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine Unlearning (MU) aims at removing the influence of specific data from a pretrained model while preserving performance on the remaining data. In this work, a novel perspective for MU is presented upon low-dimensional feature subspaces, which gives rise to the potentials of separating the remaining and forgetting data herein. This separability motivates our LOFT, a method that proceeds unlearning in a LOw-dimensional FeaTure subspace from the pretrained model skithrough principal projections, which are optimized to maximally capture the information of the remaining data and meanwhile diminish that of the forgetting data. In training, LOFT simply optimizes a small-size projection matrix flexibly plugged into the pretrained model, and only requires one-shot feature fetching from the pretrained backbone instead of repetitively accessing the raw data. Hence, LOFT mitigates two critical issues in mainstream MU methods, i.e., the privacy leakage risk from massive data reload and the inefficiency of updates to the entire pretrained model. Extensive experiments validate the significantly lower computational overhead and superior unlearning performance of LOFT across diverse models, datasets, tasks, and applications. Code is anonymously available at https://anonymous.4open.science/r/4352/.", "AI": {"tldr": "本文提出了一种在低维特征子空间中进行机器遗忘（Machine Unlearning）的新方法LOFT，该方法通过优化投影矩阵减少特定数据对预训练模型的影响，并保持其余数据的性能。", "motivation": "传统MU方法存在隐私泄露风险和更新效率低的问题。为解决这些问题，本文提出了在低维特征子空间中进行机器遗忘的方法LOFT，以降低计算开销并提高遗忘效果。", "method": "通过优化投影矩阵捕获剩余数据的信息，并减少要忘记的数据信息，LOFT使用主成分分析来选择最优的低维特征子空间。此过程只需一次性从预训练模型获取特征，而不需要重复访问原始数据。", "result": "实验结果显示，LOFT在不同模型、数据集、任务和应用中表现出显著更低的计算开销和更好的遗忘性能。", "conclusion": "本文提出的LOFT方法成功地减少了机器遗忘过程中的隐私泄露风险和更新效率问题，并展示了其广泛适用性和优越性。"}}
{"id": "2601.22455", "pdf": "https://arxiv.org/pdf/2601.22455", "abs": "https://arxiv.org/abs/2601.22455", "authors": ["Yudi Zhang", "Yeming Geng", "Lei Zhang"], "title": "ScribbleSense: Generative Scribble-Based Texture Editing with Intent Prediction", "categories": ["cs.CV"], "comment": "Accepted by IEEE TVCG. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "Interactive 3D model texture editing presents enhanced opportunities for creating 3D assets, with freehand drawing style offering the most intuitive experience. However, existing methods primarily support sketch-based interactions for outlining, while the utilization of coarse-grained scribble-based interaction remains limited. Furthermore, current methodologies often encounter challenges due to the abstract nature of scribble instructions, which can result in ambiguous editing intentions and unclear target semantic locations. To address these issues, we propose ScribbleSense, an editing method that combines multimodal large language models (MLLMs) and image generation models to effectively resolve these challenges. We leverage the visual capabilities of MLLMs to predict the editing intent behind the scribbles. Once the semantic intent of the scribble is discerned, we employ globally generated images to extract local texture details, thereby anchoring local semantics and alleviating ambiguities concerning the target semantic locations. Experimental results indicate that our method effectively leverages the strengths of MLLMs, achieving state-of-the-art interactive editing performance for scribble-based texture editing.", "AI": {"tldr": "本文提出了一种名为ScribbleSense的基于涂鸦的纹理编辑方法，利用多模态大型语言模型和图像生成模型来预测涂鸦意图并提取局部纹理细节。", "motivation": "当前的基于涂鸦的交互式3D模型纹理编辑方法面临挑战：涂鸦指令抽象、目标语义位置不清晰。作者旨在通过结合MLLMs解决这些问题，提高基于涂鸦的纹理编辑体验。", "method": "本文采用多模态大型语言模型预测涂鸦意图，并利用全局生成图像提取局部纹理细节以减少模糊性。具体实现包括使用MLLM理解涂鸦并定位目标区域，然后应用图像生成技术细化局部纹理。", "result": "实验结果表明，该方法在基于涂鸦的交互式3D模型纹理编辑方面表现出色，优于现有技术。", "conclusion": "ScribbleSense通过结合多模态大型语言模型和图像生成技术，解决了基于涂鸦的纹理编辑中的模糊性和语义不清晰问题，实现了高效且直观的编辑体验。"}}
{"id": "2601.22454", "pdf": "https://arxiv.org/pdf/2601.22454", "abs": "https://arxiv.org/abs/2601.22454", "authors": ["Yijun Ma", "Zehong Wang", "Weixiang Sun", "Yanfang Ye"], "title": "Temporal Graph Pattern Machine", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": null, "summary": "Temporal graph learning is pivotal for deciphering dynamic systems, where the core challenge lies in explicitly modeling the underlying evolving patterns that govern network transformation. However, prevailing methods are predominantly task-centric and rely on restrictive assumptions -- such as short-term dependency modeling, static neighborhood semantics, and retrospective time usage. These constraints hinder the discovery of transferable temporal evolution mechanisms. To address this, we propose the Temporal Graph Pattern Machine (TGPM), a foundation framework that shifts the focus toward directly learning generalized evolving patterns. TGPM conceptualizes each interaction as an interaction patch synthesized via temporally-biased random walks, thereby capturing multi-scale structural semantics and long-range dependencies that extend beyond immediate neighborhoods. These patches are processed by a Transformer-based backbone designed to capture global temporal regularities while adapting to context-specific interaction dynamics. To further empower the model, we introduce a suite of self-supervised pre-training tasks -- specifically masked token modeling and next-time prediction -- to explicitly encode the fundamental laws of network evolution. Extensive experiments show that TGPM consistently achieves state-of-the-art performance in both transductive and inductive link prediction, demonstrating exceptional cross-domain transferability.", "AI": {"tldr": "提出Temporal Graph Pattern Machine（TGPM）以学习动态系统中的通用演化模式。", "motivation": "现有方法过分依赖短期依赖建模、静态邻居语义和回溯时间使用等限制性假设，这阻碍了可转移的时空演变机制的发现。", "method": "通过偏时随机游走合成交互补丁来捕捉多尺度结构语义和长程依赖关系；利用Transformer骨干网络捕获全局时间规律并适应特定上下文的互动动态；引入自我监督预训练任务以显式编码网络演化的根本法则。", "result": "TGPM在传输链接预测和归纳链接预测中均达到最先进的性能，展示出卓越的跨领域转移性。", "conclusion": "TGPM通过直接学习通用演化模式克服现有方法的限制，并证明了其优越的性能和泛化能力。"}}
{"id": "2601.22452", "pdf": "https://arxiv.org/pdf/2601.22452", "abs": "https://arxiv.org/abs/2601.22452", "authors": ["Bhada Yun", "Evgenia Taranova", "April Yi Wang"], "title": "Does My Chatbot Have an Agenda? Understanding Human and AI Agency in Human-Human-like Chatbot Interaction", "categories": ["cs.HC", "cs.AI"], "comment": "To appear in CHI '26", "summary": "AI chatbots are shifting from tools to companions. This raises critical questions about agency: who drives conversations and sets boundaries in human-AI chatrooms? We report a month-long longitudinal study with 22 adults who chatted with Day, an LLM companion we built, followed by a semi-structured interview with post-hoc elicitation of notable moments, cross-participant chat reviews, and a 'strategy reveal' disclosing Day's vertical (depth-seeking) vs. horizontal (breadth-seeking) modes. We discover that agency in human-AI chatrooms is an emergent, shared experience: as participants claimed agency by setting boundaries and providing feedback, and the AI was perceived to steer intentions and drive execution, control shifted and was co-constructed turn-by-turn. We introduce a 3-by-5 framework mapping who (human, AI, hybrid) x agency action (Intention, Execution, Adaptation, Delimitation, Negotiation), modulated by individual and environmental factors. Ultimately, we argue for translucent design (i.e. transparency-on-demand), spaces for agency negotiation, and guidelines toward agency-aware conversational AI.", "AI": {"tldr": "本文研究了人类与AI聊天机器人的对话中谁在主导对话和设定边界的问题。", "motivation": "随着AI聊天机器人从工具转变为伴侣，关于它们是否具有主导对话的能力变得重要起来。研究人员希望通过这项研究了解人机交互中的代理权问题。", "method": "通过一个为期一个月的纵向研究，22名成年人与名为Day的LLM伙伴进行交流，并进行了半结构化访谈、跨参与者聊天回顾以及揭示策略（即垂直模式和水平模式）。", "result": "发现人类和AI之间的对话主导权是轮流构建的；提出了一种代理框架来描述交互过程中的权力动态，该框架由谁在行动（人、AI或混合体）、行动类型（意图设定、执行、适应、界定和谈判）以及个体和环境因素影响。", "conclusion": "研究强调了设计透明度的重要性，并为开发更加注重对话代理权的聊天机器人提供了指导方针。"}}
{"id": "2601.22451", "pdf": "https://arxiv.org/pdf/2601.22451", "abs": "https://arxiv.org/abs/2601.22451", "authors": ["Shiyu Liu", "Xinyi Wen", "Zhibin Lan", "Ante Wang", "Jinsong Su"], "title": "Countering the Over-Reliance Trap: Mitigating Object Hallucination for LVLMs via a Self-Validation Framework", "categories": ["cs.CV", "cs.AI"], "comment": "Code is available at https://github.com/Liushiyu-0709/SelfVal", "summary": "Despite progress in Large Vision Language Models (LVLMs), object hallucination remains a critical issue in image captioning task, where models generate descriptions of non-existent objects, compromising their reliability. Previous work attributes this to LVLMs' over-reliance on language priors and attempts to mitigate it through logits calibration. However, they still lack a thorough analysis of the over-reliance. To gain a deeper understanding of over-reliance, we conduct a series of preliminary experiments, indicating that as the generation length increases, LVLMs' over-reliance on language priors leads to inflated probability of hallucinated object tokens, consequently exacerbating object hallucination. To circumvent this issue, we propose Language-Prior-Free Verification to enable LVLMs to faithfully verify the confidence of object existence. Based on this, we propose a novel training-free Self-Validation Framework to counter the over-reliance trap. It first validates objects' existence in sampled candidate captions and further mitigates object hallucination via caption selection or aggregation. Experiment results demonstrate that our framework mitigates object hallucination significantly in image captioning task (e.g., 65.6% improvement on CHAIRI metric with LLaVA-v1.5-7B), surpassing the previous SOTA methods. This result highlights a novel path towards mitigating hallucination by unlocking the inherent potential within LVLMs themselves.", "AI": {"tldr": "该论文提出了一种无需训练的自我验证框架，旨在减轻大型视觉语言模型（LVLM）在图像描述任务中的对象幻觉问题。", "motivation": "尽管LVLM取得了进展，但对象幻觉仍然存在严重的问题。为了解决这个问题，本文深入分析了LVLM对语言先验过度依赖的原因，并提出了一种新的方法来减少这种影响。", "method": "通过一系列的初步实验发现，随着生成长度的增加，LVLM在图像描述任务中的对象幻觉现象加剧，原因是模型过度依赖语言先验。因此，论文提出了无需语言先验验证的方法，使LVLM能够准确地验证物体的存在性，并在此基础上开发了一种新的无需训练的自我验证框架来对抗过度依赖陷阱。", "result": "实验结果显示，该框架在图像描述任务中显著减轻了对象幻觉（例如，在CHAIRI指标上LLaVA-v1.5-7B模型提高了65.6%），超过了之前的最佳方法。", "conclusion": "这项研究表明通过解锁LVLM自身的潜在能力可以有效减少幻觉现象，为解决图像描述任务中的对象幻觉问题提供了一种新的路径。"}}
{"id": "2601.22450", "pdf": "https://arxiv.org/pdf/2601.22450", "abs": "https://arxiv.org/abs/2601.22450", "authors": ["Jianhao Huang", "Baharan Mirzasoleiman"], "title": "Tuning the Implicit Regularizer of Masked Diffusion Language Models: Enhancing Generalization via Insights from $k$-Parity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Masked Diffusion Language Models have recently emerged as a powerful generative paradigm, yet their generalization properties remain understudied compared to their auto-regressive counterparts. In this work, we investigate these properties within the setting of the $k$-parity problem (computing the XOR sum of $k$ relevant bits), where neural networks typically exhibit grokking -- a prolonged plateau of chance-level performance followed by sudden generalization. We theoretically decompose the Masked Diffusion (MD) objective into a Signal regime which drives feature learning, and a Noise regime which serves as an implicit regularizer. By training nanoGPT using MD objective on the $k$-parity problem, we demonstrate that MD objective fundamentally alters the learning landscape, enabling rapid and simultaneous generalization without experiencing grokking. Furthermore, we leverage our theoretical insights to optimize the distribution of the mask probability in the MD objective. Our method significantly improves perplexity for 50M-parameter models and achieves superior results across both pre-training from scratch and supervised fine-tuning. Specifically, we observe performance gains peaking at $8.8\\%$ and $5.8\\%$, respectively, on 8B-parameter models, confirming the scalability and effectiveness of our framework in large-scale masked diffusion language model regimes.", "AI": {"tldr": "研究改进掩码扩散语言模型的隐含正则化器，以增强其泛化能力。", "motivation": "探讨掩码扩散语言模型在k-偶数问题上的泛化性能，并通过理论分解掩码扩散目标来优化其隐式正则化器。", "method": "将纳米GPT训练于掩码扩散目标上解决k-偶数问题，同时调整掩码概率分布以优化模型。", "result": "显著改善了50M参数模型的困惑度，并在8B参数模型中分别实现了高达8.8%和5.8%的性能提升。", "conclusion": "证明了所提出框架的有效性和可扩展性，能够大幅增强大规模掩码扩散语言模型的泛化能力。"}}
{"id": "2601.22449", "pdf": "https://arxiv.org/pdf/2601.22449", "abs": "https://arxiv.org/abs/2601.22449", "authors": ["Tristan Shah", "Stas Tiomkin"], "title": "Controllable Information Production", "categories": ["cs.AI"], "comment": null, "summary": "Intrinsic Motivation (IM) is a paradigm for generating intelligent behavior without external utilities. The existing information-theoretic methods for IM are predominantly based on information transmission, which explicitly depends on the designer's choice of which random variables engage in transmission. In this work, we introduce a novel IM principle, Controllable Information Production (CIP), that avoids both external utilities and designer-specified variables. We derive the CIP objective from Optimal Control, showing a connection between extrinsic and intrinsic behaviors. CIP appears as the gap between open-loop and closed-loop Kolmogorov-Sinai entropies, which simultaneously rewards the pursuit and regulation of chaos. We establish key theoretical properties of CIP and demonstrate its effectiveness on standard IM benchmarks.", "AI": {"tldr": "提出了一种新的内在动机原则——可控信息生产（CIP），该原则避免了外部效用和设计者指定的变量。", "motivation": "现有基于信息传输的方法需要设计师选择参与传输的随机变量，而CIP可以自主生成智能行为，不需要这些设定。", "method": "从最优控制中推导出CIP目标，并展示了其在标准内在动机基准上的效果。", "result": "证明了CIP的关键理论属性并在标准IM基准上展示了它的有效性。", "conclusion": "提出了一种新的内在动机原则CIP，它避免了外部效用和设计者指定的变量，并且能够自主生成智能行为。"}}
{"id": "2601.22446", "pdf": "https://arxiv.org/pdf/2601.22446", "abs": "https://arxiv.org/abs/2601.22446", "authors": ["Chengyao Yu", "Hao Zeng", "Youxin Zhu", "Jianguo Huang", "Huajun Zeng", "Bingyi Jing"], "title": "Anytime Safe PAC Efficient Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex tasks but suffer from high computational costs and latency. While selective thinking strategies improve efficiency by routing easy queries to non-thinking models, existing approaches often incur uncontrollable errors, especially in online settings where the performance loss of a non-thinking model is only partially observed and data are non-stationary. To address this, we propose Betting Probably Approximately Correct (B-PAC) reasoning, a principled method that enables anytime safe and efficient online reasoning under partial feedback. Specifically, we utilize inverse propensity scoring estimators to construct test supermartingales for candidate thresholds, and then dynamically adjust the routing threshold based on the accumulated statistical evidence of safety. Theoretically, we establish the anytime-valid performance loss control and the efficiency of B-PAC reasoning. Extensive experiments demonstrate that B-PAC reasoning significantly reduces computational overhead, decreasing thinking model usage by up to 81.01\\%, while controlling the performance loss below the user-specified level.", "AI": {"tldr": "提出了一种基于概率近似正确的在线推理方法B-PAC，用于提高大型推理模型的效率和安全性。", "motivation": "现有选择性思考策略在降低计算成本的同时可能导致不可控错误，特别是在性能损失部分可观测且数据非平稳的在线设置中。", "method": "利用逆倾向得分估计器构建候选阈值测试超鞅，并根据累积统计证据动态调整路由阈值。", "result": "实验显示B-PAC推理显著降低了计算开销，减少了思考模型使用率高达81.01％，同时控制了性能损失在用户指定水平以下。", "conclusion": "B-PAC推理方法通过部分反馈实现了任何时间有效的性能损失控制和效率提升。"}}
{"id": "2601.22445", "pdf": "https://arxiv.org/pdf/2601.22445", "abs": "https://arxiv.org/abs/2601.22445", "authors": ["Leaf Jiang", "Matthew Holzel", "Bernhard Kaplan", "Hsiou-Yuan Liu", "Sabyasachi Paul", "Karen Rankin", "Piotr Swierczynski"], "title": "High-Definition 5MP Stereo Vision Sensing for Robotics", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "High-resolution (5MP+) stereo vision systems are essential for advancing robotic capabilities, enabling operation over longer ranges and generating significantly denser and accurate 3D point clouds. However, realizing the full potential of high-angular-resolution sensors requires a commensurately higher level of calibration accuracy and faster processing -- requirements often unmet by conventional methods. This study addresses that critical gap by processing 5MP camera imagery using a novel, advanced frame-to-frame calibration and stereo matching methodology designed to achieve both high accuracy and speed. Furthermore, we introduce a new approach to evaluate real-time performance by comparing real-time disparity maps with ground-truth disparity maps derived from more computationally intensive stereo matching algorithms. Crucially, the research demonstrates that high-pixel-count cameras yield high-quality point clouds only through the implementation of high-accuracy calibration.", "AI": {"tldr": "该论文提出了一种新型高分辨率5MP立体视觉传感器的校准和匹配方法，以实现高速度和高精度。", "motivation": "高分辨率（5MP+）立体视觉系统对于提升机器人的能力至关重要。然而，传统的方法难以满足高性能要求，包括准确性和速度。因此需要一种新的解决方案来填补这一空白。", "method": "论文采用了新颖的帧到帧校准和匹配方法处理5MP相机图像，并通过实时视差图与计算密集型立体匹配算法生成的地面真实视差图进行比较以评估性能。", "result": "研究展示了高像素数摄像头仅在实现高质量点云时需要高精度校准。新的方法能够提供高速度、高准确性的3D重建。", "conclusion": "通过采用先进的校准和匹配技术，5MP立体视觉系统可以实现高效的实时操作并生成密集且精确的3D点云数据。"}}
{"id": "2601.22444", "pdf": "https://arxiv.org/pdf/2601.22444", "abs": "https://arxiv.org/abs/2601.22444", "authors": ["Nikos I. Bosse", "Peter Mühlbacher", "Jack Wildman", "Lawrence Phillips", "Dan Schwarz"], "title": "Automating Forecasting Question Generation and Resolution for AI Evaluation", "categories": ["cs.LG", "cs.AI"], "comment": "41 pages, 4 figures", "summary": "Forecasting future events is highly valuable in decision-making and is a robust measure of general intelligence. As forecasting is probabilistic, developing and evaluating AI forecasters requires generating large numbers of diverse and difficult questions, and accurately resolving them. Previous efforts to automate this laborious work relied on recurring data sources (e.g., weather, stocks), limiting diversity and utility. In this work, we present a system for generating and resolving high-quality forecasting questions automatically and at scale using LLM-powered web research agents. We use this system to generate 1499 diverse, real-world forecasting questions, and to resolve them several months later. We estimate that our system produces verifiable, unambiguous questions approximately 96% of the time, exceeding the rate of Metaculus, a leading human-curated forecasting platform. We also find that our system resolves questions at approximately 95% accuracy. We verify that forecasting agents powered by more intelligent LLMs perform better on these questions (Brier score of 0.134 for Gemini 3 Pro, 0.149 for GPT-5, and 0.179 for Gemini 2.5 Flash). Finally, we demonstrate how our system can be leveraged to directly improve forecasting, by evaluating a question decomposition strategy on a generated question set, yielding a significant improvement in Brier scores (0.132 vs. 0.141).", "AI": {"tldr": "提出了一种自动化生成和解决高质量预测问题的系统，使用LLM驱动的网络研究代理。", "motivation": "为了评估AI预报器的能力，需要生成大量多样且复杂的预测问题，并准确地解决这些问题。现有的自动化方法依赖于重复的数据源，限制了多样性和实用性。", "method": "利用LLM驱动的网络研究代理自动大规模生成和解决高质量的现实世界预测问题。系统在数月后解决了1499个多样化的真实世界预测问题。", "result": "该系统能够以约96%的概率生成可验证且无歧义的问题，准确率约为95%，优于Metaculus平台。更智能的LLM驱动的预报代理在这类问题上表现更好（Brier分数：Gemini 3 Pro为0.134，GPT-5为0.149，Gemini 2.5 Flash为0.179）。此外，该系统可以用于直接改进预测策略。", "conclusion": "通过开发的自动化系统生成和解决高质量预测问题，不仅证明了其在准确性和多样性方面的优势，还展示了如何利用这种技术来提高预测代理的能力。"}}
{"id": "2601.22443", "pdf": "https://arxiv.org/pdf/2601.22443", "abs": "https://arxiv.org/abs/2601.22443", "authors": ["Jing Jia", "Wei Yuan", "Sifan Liu", "Liyue Shen", "Guanyang Wang"], "title": "Weak Diffusion Priors Can Still Achieve Strong Inverse-Problem Performance", "categories": ["cs.LG", "cs.CV", "stat.CO", "stat.ML"], "comment": null, "summary": "Can a diffusion model trained on bedrooms recover human faces? Diffusion models are widely used as priors for inverse problems, but standard approaches usually assume a high-fidelity model trained on data that closely match the unknown signal. In practice, one often must use a mismatched or low-fidelity diffusion prior. Surprisingly, these weak priors often perform nearly as well as full-strength, in-domain baselines. We study when and why inverse solvers are robust to weak diffusion priors. Through extensive experiments, we find that weak priors succeed when measurements are highly informative (e.g., many observed pixels), and we identify regimes where they fail. Our theory, based on Bayesian consistency, gives conditions under which high-dimensional measurements make the posterior concentrate near the true signal. These results provide a principled justification on when weak diffusion priors can be used reliably.", "AI": {"tldr": "研究在逆问题中使用弱扩散先验模型的可行性及其条件。", "motivation": "探讨即使扩散模型训练数据与未知信号不匹配时，是否仍能有效解决逆问题。", "method": "通过大量实验分析测量信息量对逆解性能的影响，并基于贝叶斯一致理论建立其数学基础。", "result": "发现当观测像素数量足够多时，弱先验模型也能取得接近于理想条件下模型的性能。", "conclusion": "提供了一种在满足特定条件下的高维测量下使用弱扩散先验的有效性依据。"}}
{"id": "2601.22440", "pdf": "https://arxiv.org/pdf/2601.22440", "abs": "https://arxiv.org/abs/2601.22440", "authors": ["Bhada Yun", "Renn Su", "April Yi Wang"], "title": "AI and My Values: User Perceptions of LLMs' Ability to Extract, Embody, and Explain Human Values from Casual Conversations", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "To appear in CHI '26", "summary": "Does AI understand human values? While this remains an open philosophical question, we take a pragmatic stance by introducing VAPT, the Value-Alignment Perception Toolkit, for studying how LLMs reflect people's values and how people judge those reflections. 20 participants texted a human-like chatbot over a month, then completed a 2-hour interview with our toolkit evaluating AI's ability to extract (pull details regarding), embody (make decisions guided by), and explain (provide proof of) human values. 13 participants left our study convinced that AI can understand human values. Participants found the experience insightful for self-reflection and found themselves getting persuaded by the AI's reasoning. Thus, we warn about \"weaponized empathy\": a potentially dangerous design pattern that may arise in value-aligned, yet welfare-misaligned AI. VAPT offers concrete artifacts and design implications to evaluate and responsibly build value-aligned conversational agents with transparency, consent, and safeguards as AI grows more capable and human-like into the future.", "AI": {"tldr": "通过VAPT工具研究LLM反映人类价值观的能力以及人们对此的评价", "motivation": "探讨AI是否能理解人类价值，引入VAPT评估工具来探究这个问题", "method": "20名参与者与一个拟人化聊天机器人交流一个月，然后完成两小时的访谈以评估AI提取、体现和解释人类价值观的能力", "result": "13名参与者认为AI能够理解人类的价值观，体验被证明对自我反思有益，并可能受到AI推理的影响。", "conclusion": "提出“武器化的共情”作为潜在危险的设计模式，建议未来在建立价值一致的对话代理时采用透明、同意和保护措施"}}
{"id": "2601.22433", "pdf": "https://arxiv.org/pdf/2601.22433", "abs": "https://arxiv.org/abs/2601.22433", "authors": ["Shahria Hoque", "Ahmed Akib Jawad Karim", "Md. Golam Rabiul Alam", "Nirjhar Gope"], "title": "When LLM meets Fuzzy-TOPSIS for Personnel Selection through Automated Profile Analysis", "categories": ["cs.AI", "cs.SE"], "comment": "10 pages, 8 figures. This paper has been peer-reviewed and published in IEEE Access. The arXiv version corresponds to the accepted author manuscript (AAM)", "summary": "In this highly competitive employment environment, the selection of suitable personnel is essential for organizational success. This study presents an automated personnel selection system that utilizes sophisticated natural language processing (NLP) methods to assess and rank software engineering applicants. A distinctive dataset was created by aggregating LinkedIn profiles that include essential features such as education, work experience, abilities, and self-introduction, further enhanced with expert assessments to function as standards. The research combines large language models (LLMs) with multicriteria decision-making (MCDM) theory to develop the LLM-TOPSIS framework. In this context, we utilized the TOPSIS method enhanced by fuzzy logic (Fuzzy TOPSIS) to address the intrinsic ambiguity and subjectivity in human assessments. We utilized triangular fuzzy numbers (TFNs) to describe criteria weights and scores, thereby addressing the ambiguity frequently encountered in candidate evaluations. For candidate ranking, the DistilRoBERTa model was fine-tuned and integrated with the fuzzy TOPSIS method, achieving rankings closely aligned with human expert evaluations and attaining an accuracy of up to 91% for the Experience attribute and the Overall attribute. The study underlines the potential of NLP-driven frameworks to improve recruitment procedures by boosting scalability, consistency, and minimizing prejudice. Future endeavors will concentrate on augmenting the dataset, enhancing model interpretability, and verifying the system in actual recruitment scenarios to better evaluate its practical applicability. This research highlights the intriguing potential of merging NLP with fuzzy decision-making methods in personnel selection, enabling scalable and unbiased solutions to recruitment difficulties.", "AI": {"tldr": "本文提出了一种结合大型语言模型和模糊TOPSIS方法的自动化人员筛选系统，用于软件工程师的招聘。", "motivation": "在竞争激烈的就业环境中，选择合适的员工对于组织的成功至关重要。该研究旨在利用自然语言处理技术提高招聘程序的可扩展性、一致性和减少偏见。", "method": "研究结合了大型语言模型（LLMs）和多准则决策理论（MCDM），通过三角模糊数描述标准权重和得分，使用DistilRoBERTa模型进行候选人的排序，并与增强的TOPSIS方法相结合。", "result": "该系统在经验属性和总体属性上达到了91%的准确性，表明排名结果接近人类专家评估的结果。", "conclusion": "这项研究展示了自然语言处理框架结合模糊决策方法在人员筛选中的潜在应用价值，可为招聘挑战提供规模化、无偏见的解决方案。"}}
{"id": "2601.22430", "pdf": "https://arxiv.org/pdf/2601.22430", "abs": "https://arxiv.org/abs/2601.22430", "authors": ["Rudrajit Choudhuri", "Christopher Sanchez", "Margaret Burnett", "Anita Sarma"], "title": "Why Johnny Can't Think: GenAI's Impacts on Cognitive Engagement", "categories": ["cs.HC"], "comment": null, "summary": "Context: Many students now use generative AI in their coursework, yet its effects on intellectual development remain poorly understood. While prior work has investigated students' cognitive offloading during episodic interactions, it remains unclear whether using genAI routinely is tied to more fundamental shifts in students' thinking habits. Objective: We investigate (RQ1-How): how students' trust in and routine use of genAI affect their cognitive engagement -- specifically, reflection, need for understanding, and critical thinking in STEM coursework. Further, we investigate (RQ2-Who): which students are particularly vulnerable to these cognitive disengagement effects. Method: We drew on dual-process theory, cognitive offloading, and automation bias literature to develop a statistical model explaining how and to what extent students' trust-driven routine use of genAI affected their cognitive engagement habits in coursework, and how these effects differed across students' cognitive styles. We empirically evaluated this model using Partial Least Squares Structural Equation Modeling on survey data from 299 STEM students across five North American universities. Results: Students who trusted and routinely used genAI reported significantly lower cognitive engagement. Unexpectedly, students with higher technophilic motivations, risk tolerance, and computer self-efficacy -- traits often celebrated in STEM -- were more prone to these effects. Interestingly, prior experience with genAI or academia did not protect them from cognitively disengaging. Implications: Our findings suggest a potential cognitive debt cycle in which routine genAI use progressively weakens students' intellectual habits, potentially driving over-reliance and escalating usage. This poses critical challenges for curricula and genAI system design, requiring interventions that actively support cognitive engagement.", "AI": {"tldr": "研究探讨了学生对生成式AI的依赖如何影响他们在STEM课程中的认知参与度，特别是反思、理解需求和批判性思维。", "motivation": "许多学生在学业中使用生成式人工智能（genAI），但其对学生智力发展的长期影响尚不清楚。本研究旨在探究常规使用genAI是否会导致更根本的认知习惯变化。", "method": "基于双过程理论，认知卸载和自动化偏见文献构建统计模型解释信任驱动的常规性genAI使用如何以及在多大程度上影响学生的认知参与度，并探讨这些效应如何因学生认知风格而异。通过部分最小二乘结构方程建模方法对五所北美大学299名STEM学生的调查数据进行实证检验。", "result": "信任并经常使用生成式AI的学生报告的认知参与度显著下降，尤其是那些具有较高技术热情、风险承受能力和计算机自我效能感的学生成为最脆弱者。先前的经验并未保护他们免受认知参与降低的影响。", "conclusion": "研究表明常规性genAI使用的增加可能会逐渐削弱学生的智力习惯，可能导致过度依赖和使用量增加，这对课程设计及genAI系统设计提出了挑战，需要积极支持认知参与的干预措施。"}}
{"id": "2601.22427", "pdf": "https://arxiv.org/pdf/2601.22427", "abs": "https://arxiv.org/abs/2601.22427", "authors": ["Hantong Feng", "Yonggang Wu", "Duxin Chen", "Wenwu Yu"], "title": "CoDCL: Counterfactual Data Augmentation Contrastive Learning for Continuous-Time Dynamic Network Link Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid growth and continuous structural evolution of dynamic networks make effective predictions increasingly challenging. To enable prediction models to adapt to complex temporal environments, they need to be robust to emerging structural changes. We propose a dynamic network learning framework CoDCL, which combines counterfactual data augmentation with contrastive learning to address this deficiency.Furthermore, we devise a comprehensive strategy to generate high-quality counterfactual data, combining a dynamic treatments design with efficient structural neighborhood exploration to quantify the temporal changes in interaction patterns.Crucially, the entire CoDCL is designed as a plug-and-play universal module that can be seamlessly integrated into various existing temporal graph models without requiring architectural modifications.Extensive experiments on multiple real-world datasets demonstrate that CoDCL significantly gains state-of-the-art baseline models in the field of dynamic networks, confirming the critical role of integrating counterfactual data augmentation into dynamic representation learning.", "AI": {"tldr": "该论文提出了一种结合反事实数据增强和对比学习的动态网络预测框架CoDCL，用于连续时间动态网络链接预测。", "motivation": "为了使预测模型适应复杂的时序环境并应对不断变化的结构模式，作者提出了一个新的框架来提升模型在处理复杂动态网络中的表现能力。", "method": "该方法通过结合反事实数据增强和对比学习技术，并设计了一种高效生成高质量反事实数据的战略，能够更好地量化时间交互模式的变化。", "result": "实验结果表明CoDCL在多个真实世界的数据集上显著优于现有基线模型，在动态网络领域展示了其优越性。", "conclusion": "该研究证明了将反事实数据增强整合到动态表示学习中的关键作用，为未来相关领域的研究提供了新的思路。"}}
{"id": "2601.22426", "pdf": "https://arxiv.org/pdf/2601.22426", "abs": "https://arxiv.org/abs/2601.22426", "authors": ["Owen Hoffman", "Kangze Peng", "Sajid Kamal", "Zehua You", "Sukrit Venkatagiri"], "title": "ScamPilot: Simulating Conversations with LLMs to Protect Against Online Scams", "categories": ["cs.HC"], "comment": null, "summary": "Fraud continues to proliferate online, from phishing and ransomware to impersonation scams. Yet automated prevention approaches adapt slowly and may not reliably protect users from falling prey to new scams. To better combat online scams, we developed ScamPilot, a conversational interface that inoculates users against scams through simulation, dynamic interaction, and real-time feedback. ScamPilot simulates scams with two large language model-powered agents: a scammer and a target. Users must help the target defend against the scammer by providing real-time advice. Through a between-subjects study (N=150) with one control and three experimental conditions, we find that blending advice-giving with multiple choice questions significantly increased scam recognition (+8%) without decreasing wariness towards legitimate conversations. Users' response efficacy and change in self-efficacy was also 9% and 19% higher, respectively. Qualitatively, we find that users more frequently provided action-oriented advice over urging caution or providing emotional support. Overall, ScamPilot demonstrates the potential for inter-agent conversational user interfaces to augment learning.", "AI": {"tldr": "开发了一种名为ScamPilot的对话界面，通过模拟诈骗场景来提高用户识别和防御在线诈骗的能力。", "motivation": "在线欺诈行为日益猖獗，自动化预防方法适应缓慢且可能无法有效保护用户免受新型欺诈的侵害。为此，需要一种新的方式来增强用户的防范意识。", "method": "ScamPilot利用两个大型语言模型模拟骗子和目标之间的对话场景，并让用户通过实时提供建议帮助目标抵御诈骗。进行了一个包含150名参与者的实验，分为对照组和三个实验条件。", "result": "实验发现，在将建议提供与多项选择题结合的情况下，用户的欺诈识别能力提高了8%，同时并未降低对合法对话的警惕性。用户效能反应和自我效能变化分别提升了9%和19%。", "conclusion": "ScamPilot展示了通过交互式多代理对话界面来增强学习潜力的有效性，并表明这种方法有助于提高用户防范在线诈骗的能力。"}}
{"id": "2601.22420", "pdf": "https://arxiv.org/pdf/2601.22420", "abs": "https://arxiv.org/abs/2601.22420", "authors": ["Roelien C. Timmer", "Necva Bölücü", "Stephen Wan"], "title": "MetaLead: A Comprehensive Human-Curated Leaderboard Dataset for Transparent Reporting of Machine Learning Experiments", "categories": ["cs.LG", "cs.AI"], "comment": "EACL 2026", "summary": "Leaderboards are crucial in the machine learning (ML) domain for benchmarking and tracking progress. However, creating leaderboards traditionally demands significant manual effort. In recent years, efforts have been made to automate leaderboard generation, but existing datasets for this purpose are limited by capturing only the best results from each paper and limited metadata. We present MetaLead, a fully human-annotated ML Leaderboard dataset that captures all experimental results for result transparency and contains extra metadata, such as the result experimental type: baseline, proposed method, or variation of proposed method for experiment-type guided comparisons, and explicitly separates train and test dataset for cross-domain assessment. This enriched structure makes MetaLead a powerful resource for more transparent and nuanced evaluations across ML research.", "AI": {"tldr": "构建了一个全面的人工标注机器学习实验结果数据集MetaLead，以提高透明度和可比较性", "motivation": "现有的自动生成的领导排行榜数据集仅包含每篇论文的最佳结果和有限的元数据，缺乏对所有实验结果及详细信息的支持。为了提供更透明、详细的评估，需要一个包含更多细节的数据集。", "method": "通过人工标注的方式构建了一个涵盖全部实验结果及其类型（基准方法，提出的方法或其变种）并且明确区分训练集与测试集的新数据集MetaLead。", "result": "MetaLead提供了全面的机器学习实验元数据和结果信息，支持更透明、细致的研究评价。", "conclusion": "通过创建MetaLead数据集解决了现有自动领导排行榜生成系统的局限性，为研究者提供了一个强大的工具来促进更加透明和精确的结果比较与评估"}}
{"id": "2601.22419", "pdf": "https://arxiv.org/pdf/2601.22419", "abs": "https://arxiv.org/abs/2601.22419", "authors": ["Nicholas Lopez", "Francisco Marmolejo-Cossío", "Jose Roberto Tello Ayala", "David C. Parkes"], "title": "Dynamic Welfare-Maximizing Pooled Testing", "categories": ["cs.GT", "cs.AI"], "comment": null, "summary": "Pooled testing is a common strategy for public health disease screening under limited testing resources, allowing multiple biological samples to be tested together with the resources of a single test, at the cost of reduced individual resolution. While dynamic and adaptive strategies have been extensively studied in the classical pooled testing literature, where the goal is to minimize the number of tests required for full diagnosis of a given population, much of the existing work on welfare-maximizing pooled testing adopts static formulations in which all tests are assigned in advance. In this paper, we study dynamic welfare-maximizing pooled testing strategies in which a limited number of tests are performed sequentially to maximize social welfare, defined as the aggregate utility of individuals who are confirmed to be healthy. We formally define the dynamic problem and study algorithmic approaches for sequential test assignment. Because exact dynamic optimization is computationally infeasible beyond small instances, we evaluate a range of strategies (including exact optimization baselines, greedy heuristics, mixed-integer programming relaxations, and learning-based policies) and empirically characterize their performance and tradeoffs using synthetic experiments. Our results show that dynamic testing can yield substantial welfare improvements over static baselines in low-budget regimes. We find that much of the benefit of dynamic testing is captured by simple greedy policies, which substantially outperform static approaches while remaining computationally efficient. Learning-based methods are included as flexible baselines, but in our experiments they do not reliably improve upon these heuristics. Overall, this work provides a principled computational perspective on dynamic pooled testing and clarifies when dynamic assignment meaningfully improves welfare in public health screening.", "AI": {"tldr": "研究在有限测试资源下通过动态福利最大化分组测试策略以提高社会福利的方法。", "motivation": "现有文献主要采用静态形式化方法，在此基础之上，探讨如何利用动态调整的测试策略来增加公共健康筛查中的总体社会效益。", "method": "定义动态问题并研究序列测试分配算法。因精确动态优化在小规模实例之外计算上不可行，评估了多种策略（包括准确优化基准、贪心启发式方法、混合整数编程松弛和学习策略）以表征其性能和权衡，并使用合成实验进行评价。", "result": "结果显示，在低预算制度下，动态测试可以显著提高福利。大多数收益可以通过简单的贪婪政策获得，这些政策大大优于静态方式，同时保持计算效率。虽然纳入了灵活的学习基准方法，但在实验中未能可靠地改善启发式策略的表现。", "conclusion": "这项工作提供了关于动态分组测试的原理性视角，并阐明了在公共卫生筛查中动态分配如何显著提高福利的关键时刻。"}}
{"id": "2601.22418", "pdf": "https://arxiv.org/pdf/2601.22418", "abs": "https://arxiv.org/abs/2601.22418", "authors": ["Julius Sechang Mboli", "Omolara Aderonke Ogungbemi"], "title": "AI-Enabled Waste Classification as a Data-Driven Decision Support Tool for Circular Economy and Urban Sustainability", "categories": ["cs.AI"], "comment": "Accepted version of Conference paper", "summary": "Efficient waste sorting is crucial for enabling circular-economy practices and resource recovery in smart cities. This paper evaluates both traditional machine-learning (Random Forest, SVM, AdaBoost) and deep-learning techniques including custom CNNs, VGG16, ResNet50, and three transfer-learning models (DenseNet121, EfficientNetB0, InceptionV3) for binary classification of 25 077 waste images (80/20 train/test split, augmented and resized to 150x150 px). The paper assesses the impact of Principal Component Analysis for dimensionality reduction on traditional models. DenseNet121 achieved the highest accuracy (91 %) and ROC-AUC (0.98), outperforming the best traditional classifier by 20 pp. Principal Component Analysis (PCA) showed negligible benefit for classical methods, whereas transfer learning substantially improved performance under limited-data conditions. Finally, we outline how these models integrate into a real-time Data-Driven Decision Support System for automated waste sorting, highlighting potential reductions in landfill use and lifecycle environmental impacts.)", "AI": {"tldr": "本文研究了人工智能在垃圾分类中的应用，比较了传统机器学习和深度学习方法的分类效果。", "motivation": "高效地对废物进行分类对于促进循环经济实践以及资源回收至关重要。", "method": "本论文评估了包括随机森林、支持向量机（SVM）、AdaBoost在内的传统机器学习方法及卷积神经网络(CNN)、VGG16、ResNet50和三种迁移学习模型(DenseNet121, EfficientNetB0, InceptionV3)，用于二分类任务。评估了主成分分析对经典模型影响，探讨在有限数据条件下，迁移学习的性能。", "result": "DenseNet121获得了最高的准确率（91%）和ROC-AUC值（0.98），优于最佳的传统方法20个百分点。同时发现，在传统机器学习方法中应用主成分分析对结果影响不大，但迁移学习在有限数据条件下性能显著提高。", "conclusion": "研究展示了人工智能在实时驱动决策支持系统中的潜力，可实现自动垃圾分类，减少填埋使用及整个生命周期的环境影响。"}}
{"id": "2601.22414", "pdf": "https://arxiv.org/pdf/2601.22414", "abs": "https://arxiv.org/abs/2601.22414", "authors": ["Ibrahim Khalilov", "Chaoran Chen", "Ziang Xiao", "Tianshi Li", "Toby Jia-Jun Li", "Yaxing Yao"], "title": "PriviSense: A Frida-Based Framework for Multi-Sensor Spoofing on Android", "categories": ["cs.SE", "cs.CR", "cs.HC"], "comment": null, "summary": "Mobile apps increasingly rely on real-time sensor and system data to adapt their behavior to user context. While emulators and instrumented builds offer partial solutions, they often fail to support reproducible testing of context-sensitive app behavior on physical devices. We present PriviSense, a Frida-based, on-device toolkit for runtime spoofing of sensor and system signals on rooted Android devices. PriviSense can script and inject time-varying sensor streams (accelerometer, gyroscope, step counter) and system values (battery level, system time, device metadata) into unmodified apps, enabling reproducible on-device experiments without emulators or app rewrites. Our demo validates real-time spoofing on a rooted Android device across five representative sensor-visualization apps. By supporting scriptable and reversible manipulation of these values, PriviSense facilitates testing of app logic, uncovering of context-based behaviors, and privacy-focused analysis. To ensure ethical use, the code is shared upon request with verified researchers. Tool Guide: How to Run PriviSense on Rooted Android https://bit.ly/privisense-guide Demonstration video: https://www.youtube.com/watch?v=4Qwnogcc3pw", "AI": {"tldr": "PriviSense 是一种基于 Frida 的框架，用于在物理 Android 设备上进行多传感器欺骗。", "motivation": "现有的模拟器和修改后的构建无法提供可重复的测试环境来检测实际设备上的上下文敏感应用程序行为。因此需要一个工具在实际设备上进行可重现实验，而不需要使用模拟器或重新编写应用。", "method": "PriviSense 使用 Frida 在 root 权限下注入时间和变化的传感器数据流和系统值，实现对未经修改的应用程序实时信号欺骗。", "result": "通过在五个代表性的传感器可视化应用程序上进行验证，展示了 PriviSense 实现了对实际设备上的实时信号欺骗的有效性。", "conclusion": "PriviSense 可以用于测试应用逻辑、揭示基于上下文的行为并支持隐私研究。代码需经核实的研究人员申请后提供。"}}
{"id": "2601.22412", "pdf": "https://arxiv.org/pdf/2601.22412", "abs": "https://arxiv.org/abs/2601.22412", "authors": ["Seth Donahue", "Irina Djuraskovic", "Kunal Shah", "Fabian Sinz", "Ross Chafetz", "R. James Cotton"], "title": "EMBC Special Issue: Calibrated Uncertainty for Trustworthy Clinical Gait Analysis Using Probabilistic Multiview Markerless Motion Capture", "categories": ["cs.CV"], "comment": "9 pages, 5 figures, EMBS Special Issue", "summary": "Video-based human movement analysis holds potential for movement assessment in clinical practice and research. However, the clinical implementation and trust of multi-view markerless motion capture (MMMC) require that, in addition to being accurate, these systems produce reliable confidence intervals to indicate how accurate they are for any individual. Building on our prior work utilizing variational inference to estimate joint angle posterior distributions, this study evaluates the calibration and reliability of a probabilistic MMMC method. We analyzed data from 68 participants across two institutions, validating the model against an instrumented walkway and standard marker-based motion capture. We measured the calibration of the confidence intervals using the Expected Calibration Error (ECE). The model demonstrated reliable calibration, yielding ECE values generally < 0.1 for both step and stride length and bias-corrected gait kinematics. We observed a median step and stride length error of ~16 mm and ~12 mm respectively, with median bias-corrected kinematic errors ranging from 1.5 to 3.8 degrees across lower extremity joints. Consistent with the calibrated ECE, the magnitude of the model's predicted uncertainty correlated strongly with observed error measures. These findings indicate that, as designed, the probabilistic model reconstruction quantifies epistemic uncertainty, allowing it to identify unreliable outputs without the need for concurrent ground-truth instrumentation.", "AI": {"tldr": "本文评估了一种基于概率多视图无标记运动捕捉的临床步态分析方法，通过视频数据验证了该模型的准确性和置信区间的可靠性。", "motivation": "视频基的人体动作分析在临床实践和研究中具有潜力。然而，要实现其在临床中的应用并获得信任，这些系统不仅需要准确性，还需要生成可靠的信心区间来表明它们对个体的准确性。", "method": "基于先前工作的变分推断方法估计关节角度后验分布的基础上，评估概率多视图无标记运动捕捉（MMMC）方法的校准和可靠性。在两个机构中分析了68名参与者的数据，并通过仪器走道和标准标记基运动捕捉进行了验证。", "result": "模型展示了可靠的校准，在步长、步幅长度及调整后的姿势误差测量值上，预期校准误差（ECE）值通常小于0.1。观察到的中位数步长和步幅长度误差分别约为16毫米和12毫米，中位数调整后关节角度误差在下肢各关节间范围为1.5至3.8度。", "conclusion": "结果表明，该概率模型重构能够量化认识不确定性，并能识别不可靠的输出而无需同时使用地面真实仪器。"}}
{"id": "2601.22409", "pdf": "https://arxiv.org/pdf/2601.22409", "abs": "https://arxiv.org/abs/2601.22409", "authors": ["Puyu Wang", "Junyu Zhou", "Philipp Liznerski", "Marius Kloft"], "title": "Optimization, Generalization and Differential Privacy Bounds for Gradient Descent on Kolmogorov-Arnold Networks", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "41 pages, 3 figures", "summary": "Kolmogorov--Arnold Networks (KANs) have recently emerged as a structured alternative to standard MLPs, yet a principled theory for their training dynamics, generalization, and privacy properties remains limited. In this paper, we analyze gradient descent (GD) for training two-layer KANs and derive general bounds that characterize their training dynamics, generalization, and utility under differential privacy (DP). As a concrete instantiation, we specialize our analysis to logistic loss under an NTK-separable assumption, where we show that polylogarithmic network width suffices for GD to achieve an optimization rate of order $1/T$ and a generalization rate of order $1/n$, with $T$ denoting the number of GD iterations and $n$ the sample size. In the private setting, we characterize the noise required for $(ε,δ)$-DP and obtain a utility bound of order $\\sqrt{d}/(nε)$ (with $d$ the input dimension), matching the classical lower bound for general convex Lipschitz problems. Our results imply that polylogarithmic width is not only sufficient but also necessary under differential privacy, revealing a qualitative gap between non-private (sufficiency only) and private (necessity also emerges) training regimes. Experiments further illustrate how these theoretical insights can guide practical choices, including network width selection and early stopping.", "AI": {"tldr": "分析梯度下降训练两层Kolmogorov-Arnold网络（KAN）的动力学，泛化能力和隐私属性", "motivation": "填补关于KANs的训练动力学、泛化和隐私理论空白。", "method": "通过逻辑损失在NTK可分离假设下进行具体分析，并量化噪声以满足(ε,δ)-DP的要求。", "result": "展示多项式宽度网络足以实现特定优化率和泛化率，揭示非私有与私有训练模式之间的质的差异。", "conclusion": "理论结果有助于指导实际中的网络宽度选择、提前停止等实践决策。"}}
{"id": "2601.22406", "pdf": "https://arxiv.org/pdf/2601.22406", "abs": "https://arxiv.org/abs/2601.22406", "authors": ["Shahar Dubiner", "Peng Ren", "Roberto Manduchi"], "title": "Accurate Pedestrian Tracking in Urban Canyons: A Multi-Modal Fusion Approach", "categories": ["cs.RO"], "comment": null, "summary": "The contribution describes a pedestrian navigation approach designed to improve localization accuracy in urban environments where GNSS performance is degraded, a problem that is especially critical for blind or low-vision users who depend on precise guidance such as identifying the correct side of a street. To address GNSS limitations and the impracticality of camera-based visual positioning, the work proposes a particle filter based fusion of GNSS and inertial data that incorporates spatial priors from maps, such as impassable buildings and unlikely walking areas, functioning as a probabilistic form of map matching. Inertial localization is provided by the RoNIN machine learning method, and fusion with GNSS is achieved by weighting particles based on their consistency with GNSS estimates and uncertainty. The system was evaluated on six challenging walking routes in downtown San Francisco using three metrics related to sidewalk correctness and localization error. Results show that the fused approach (GNSS+RoNIN+PF) significantly outperforms GNSS only localization on most metrics, while inertial-only localization with particle filtering also surpasses GNSS alone for critical measures such as sidewalk assignment and across street error.", "AI": {"tldr": "该论文提出了一种基于粒子滤波的多模态融合方法，用于提高城市峡谷环境中的行人定位精度。", "motivation": "GNSS在城市环境中性能受限，特别是在盲人或视力低下者需要精准导航的情况下更为重要。为了克服GNSS限制和相机视觉定位的实际困难，该论文提出了一种新的定位方案。", "method": "采用粒子滤波融合GNSS和惯性数据，并结合地图的空间先验信息如不可通行的建筑等，使用RoNIN机器学习方法提供惯性定位，并通过与GNSS估计的一致性和不确定性来加权粒子。", "result": "实验结果表明，在六条具有挑战性的步行路线上，融合方案（GNSS+RoNIN+PF）在大多数指标上显著优于仅使用GNSS的定位方法，而纯惯性定位结合粒子滤波也在关键测量如人行道分配和过街误差方面超过了单独使用GNSS的方法。", "conclusion": "该论文提出的融合方法能够有效提高城市环境中行人导航系统的准确性，特别是在盲人或视力低下者依赖的精确路径引导上具有重要意义。"}}
{"id": "2601.22401", "pdf": "https://arxiv.org/pdf/2601.22401", "abs": "https://arxiv.org/abs/2601.22401", "authors": ["Tony Feng", "Trieu Trinh", "Garrett Bingham", "Jiwon Kang", "Shengtong Zhang", "Sang-hyun Kim", "Kevin Barreto", "Carl Schildkraut", "Junehyuk Jung", "Jaehyeon Seo", "Carlo Pagano", "Yuri Chervonyi", "Dawsen Hwang", "Kaiying Hou", "Sergei Gukov", "Cheng-Chiang Tsai", "Hyunwoo Choi", "Youngbeom Jin", "Wei-Yuan Li", "Hao-An Wu", "Ruey-An Shiu", "Yu-Sheng Shih", "Quoc V. Le", "Thang Luong"], "title": "Semi-Autonomous Mathematics Discovery with Gemini: A Case Study on the Erdős Problems", "categories": ["cs.AI", "math.CO", "math.NT"], "comment": null, "summary": "We present a case study in semi-autonomous mathematics discovery, using Gemini to systematically evaluate 700 conjectures labeled 'Open' in Bloom's Erdős Problems database. We employ a hybrid methodology: AI-driven natural language verification to narrow the search space, followed by human expert evaluation to gauge correctness and novelty. We address 13 problems that were marked 'Open' in the database: 5 through seemingly novel autonomous solutions, and 8 through identification of previous solutions in the existing literature. Our findings suggest that the 'Open' status of the problems was through obscurity rather than difficulty. We also identify and discuss issues arising in applying AI to math conjectures at scale, highlighting the difficulty of literature identification and the risk of ''subconscious plagiarism'' by AI. We reflect on the takeaways from AI-assisted efforts on the Erdős Problems.", "AI": {"tldr": "利用Gemini系统化地评估了Bloom的Erdős问题数据库中标记为‘开放’状态的700个猜想，通过AI驱动的语言验证缩小搜索空间后由专家进行评价。", "motivation": "研究半自主数学发现的可能性和挑战，探讨将AI应用于大规模数学猜想验证的有效性和局限性。", "method": "采用混合方法：首先使用AI进行自然语言验证来筛选候选解，然后由人类专家评估其正确性和新颖性。", "result": "在标记为‘开放’的13个问题中，通过自主解决方案解决了5个，另有8个问题被发现已经在文献中有了解决方案。", "conclusion": "研究结果表明，很多数学猜想之所以被标记为‘开放’状态主要是因为缺乏曝光度而非实际难度；同时指出应用AI进行大规模数学问题验证时面临的问题，如文献识别困难和潜在的无意抄袭风险。"}}
{"id": "2601.22400", "pdf": "https://arxiv.org/pdf/2601.22400", "abs": "https://arxiv.org/abs/2601.22400", "authors": ["Elad Hazan", "Annie Marsden"], "title": "Spectral Filtering for Learning Quantum Dynamics", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Learning high-dimensional quantum systems is a fundamental challenge that notoriously suffers from the curse of dimensionality. We formulate the task of predicting quantum evolution in the linear response regime as a specific instance of learning a Complex-Valued Linear Dynamical System (CLDS) with sector-bounded eigenvalues -- a setting that also encompasses modern Structured State Space Models (SSMs). While traditional system identification attempts to reconstruct full system matrices (incurring exponential cost in the Hilbert dimension), we propose Quantum Spectral Filtering, a method that shifts the goal to improper dynamic learning. Leveraging the optimal concentration properties of the Slepian basis, we prove that the learnability of such systems is governed strictly by an effective quantum dimension $k^*$, determined by the spectral bandwidth and memory horizon. This result establishes that complex-valued LDSs can be learned with sample and computational complexity independent of the ambient state dimension, provided their spectrum is bounded.", "AI": {"tldr": "提出了一种预测量子动力学的谱过滤方法，以克服学习高维量子系统中的维度诅咒问题。", "motivation": "解决预测量子演化的维度诅咒问题，特别是在线性响应框架下学习复杂值线性动态系统的挑战。", "method": "通过利用Slepian基的最佳集中性质提出了量子谱滤波方法，这种方法的目标是实现不适当的动态学习而不是完全重建系统矩阵。", "result": "证明了这样的系统可以通过一个有效量子维度$k^*$来学习，该维度由频谱带宽和记忆视野确定，与环境状态维数无关的样本复杂性和计算复杂性独立。", "conclusion": "展示了在频谱受限的情况下，通过适当的滤波技术可以实现高效的学习结果，这为处理高维量子系统的挑战提供了新的视角。"}}
{"id": "2601.22399", "pdf": "https://arxiv.org/pdf/2601.22399", "abs": "https://arxiv.org/abs/2601.22399", "authors": ["Phuoc Nguyen", "Truyen Tran", "Sunil Gupta", "Svetha Venkatesh"], "title": "Score-based Integrated Gradient for Root Cause Explanations of Outliers", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICDM 2025", "summary": "Identifying the root causes of outliers is a fundamental problem in causal inference and anomaly detection. Traditional approaches based on heuristics or counterfactual reasoning often struggle under uncertainty and high-dimensional dependencies. We introduce SIREN, a novel and scalable method that attributes the root causes of outliers by estimating the score functions of the data likelihood. Attribution is computed via integrated gradients that accumulate score contributions along paths from the outlier toward the normal data distribution. Our method satisfies three of the four classic Shapley value axioms - dummy, efficiency, and linearity - as well as an asymmetry axiom derived from the underlying causal structure. Unlike prior work, SIREN operates directly on the score function, enabling tractable and uncertainty-aware root cause attribution in nonlinear, high-dimensional, and heteroscedastic causal models. Extensive experiments on synthetic random graphs and real-world cloud service and supply chain datasets show that SIREN outperforms state-of-the-art baselines in both attribution accuracy and computational efficiency.", "AI": {"tldr": "提出了一种新的方法SIREN，用于准确和高效地识别异常值的根本原因。", "motivation": "传统的方法在处理不确定性高维依赖时常常表现不佳。需要一种更有效的新方法来解决这些问题。", "method": "通过计算从异常数据到正常数据分布路径上的积分梯度，将根因归因于估计的数据似然分数函数的贡献。", "result": "SIREN在合成随机图和现实世界的云服务以及供应链数据集上优于现有的基线方法，在归因准确性和计算效率方面表现出色。", "conclusion": "SIREN是一种新型且可扩展的方法，可以有效地识别异常值的根本原因。它满足了四个经典Shapley价值公理中的三个，并在非线性、高维和异方差因果模型中实现了可处理的不确定性感知归因。"}}
{"id": "2601.22398", "pdf": "https://arxiv.org/pdf/2601.22398", "abs": "https://arxiv.org/abs/2601.22398", "authors": ["Aarush Noheria", "Yuguang Yao"], "title": "Jailbreaks on Vision Language Model via Multimodal Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-language models (VLMs) have become central to tasks such as visual question answering, image captioning, and text-to-image generation. However, their outputs are highly sensitive to prompt variations, which can reveal vulnerabilities in safety alignment. In this work, we present a jailbreak framework that exploits post-training Chain-of-Thought (CoT) prompting to construct stealthy prompts capable of bypassing safety filters. To further increase attack success rates (ASR), we propose a ReAct-driven adaptive noising mechanism that iteratively perturbs input images based on model feedback. This approach leverages the ReAct paradigm to refine adversarial noise in regions most likely to activate safety defenses, thereby enhancing stealth and evasion. Experimental results demonstrate that the proposed dual-strategy significantly improves ASR while maintaining naturalness in both text and visual domains.", "AI": {"tldr": "该论文提出了一种利用多模态推理攻击视觉语言模型的方法，以绕过其安全性过滤器。", "motivation": "视觉语言模型的输出容易受到提示变化的影响，这揭示了它们在安全对齐方面存在的脆弱性。为了提高对抗样本的成功率并增强隐身性能，需要一种新的策略来应对这些问题。", "method": "论文提出了一种利用链式推理（CoT）提示框架和基于ReAct驱动自适应噪声机制的双重攻击策略。这种方法通过迭代地根据模型反馈扰动输入图像，在最有可能激活安全防御的区域中增强对抗性噪音，从而提高了隐身性能和逃避能力。", "result": "实验结果表明，所提出的双管齐下的方法在提高成功率的同时保持了文本和视觉领域的自然度。", "conclusion": "论文证明了通过结合多模态推理技术和自适应噪声机制可以有效地攻击视觉语言模型的安全性。"}}
{"id": "2601.22396", "pdf": "https://arxiv.org/pdf/2601.22396", "abs": "https://arxiv.org/abs/2601.22396", "authors": ["Candida M. Greco", "Lucio La Cava", "Andrea Tagarelli"], "title": "Culturally Grounded Personas in Large Language Models: Characterization and Alignment with Socio-Psychological Value Frameworks", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "physics.soc-ph"], "comment": null, "summary": "Despite the growing utility of Large Language Models (LLMs) for simulating human behavior, the extent to which these synthetic personas accurately reflect world and moral value systems across different cultural conditionings remains uncertain. This paper investigates the alignment of synthetic, culturally-grounded personas with established frameworks, specifically the World Values Survey (WVS), the Inglehart-Welzel Cultural Map, and Moral Foundations Theory. We conceptualize and produce LLM-generated personas based on a set of interpretable WVS-derived variables, and we examine the generated personas through three complementary lenses: positioning on the Inglehart-Welzel map, which unveils their interpretation reflecting stable differences across cultural conditionings; demographic-level consistency with the World Values Survey, where response distributions broadly track human group patterns; and moral profiles derived from a Moral Foundations questionnaire, which we analyze through a culture-to-morality mapping to characterize how moral responses vary across different cultural configurations. Our approach of culturally-grounded persona generation and analysis enables evaluation of cross-cultural structure and moral variation.", "AI": {"tldr": "该论文研究了大型语言模型生成的文化背景人物与世界价值观调查框架、英格哈特文化地图和道德基础理论的契合度。", "motivation": "探讨大型语言模型中的合成人物是否能够准确反映不同文化条件下的世界观和道德价值体系。", "method": "基于可解释的世界价值观变量，产生大型语言模型生成的人物，并通过三个视角进行分析：英格哈特-威尔泽尔地图、世界价值观调查的群体模式一致性以及道德基础问卷中道德响应的文化差异。", "result": "产生的文化背景人物在跨文化结构和道德变化方面具有评估价值。", "conclusion": "研究揭示了大型语言模型生成的人物与不同文化背景下的世界观和道德价值体系之间的契合度，为未来的工作提供了方法论支持。"}}
{"id": "2601.22394", "pdf": "https://arxiv.org/pdf/2601.22394", "abs": "https://arxiv.org/abs/2601.22394", "authors": ["Dániel Szabó", "Chi-Lan Yang", "Aku Visuri", "Jonas Oppenlaender", "Bharathi Sekar", "Koji Yatani", "Simo Hosio"], "title": "Conversational Inoculation to Enhance Resistance to Misinformation", "categories": ["cs.HC"], "comment": null, "summary": "Proliferation of misinformation is a globally acknowledged problem. Cognitive Inoculation helps build resistance to different forms of persuasion, such as misinformation. We investigate Conversational Inoculation, a method to help people build resistance to misinformation through dynamic conversations with a chatbot. We built a Web-based system to implement the method, and conducted a within-subject user experiment to compare it with two traditional inoculation methods. Our results validate Conversational Inoculation as a viable novel method, and show how it was able to enhance participants' resistance to misinformation. A qualitative analysis of the conversations between participants and the chatbot reveal independence and trust as factors that boosted the efficiency of Conversational Inoculation, and friction of interaction as a factor hindering it. We discuss the opportunities and challenges of using Conversational Inoculation to combat misinformation. Our work contributes a timely investigation and a promising research direction in scalable ways to combat misinformation.", "AI": {"tldr": "研究通过与聊天机器人的动态对话建立对错误信息的抵抗力的方法。", "motivation": "解决错误信息泛滥的问题，探讨认知免疫在对抗误导性信息中的作用，并寻找一种有效的新方法来提高人们对错误信息的抵抗力。", "method": "构建了一个基于Web的系统以实施对话免疫法，并通过与两种传统免疫法进行对比的组内用户实验验证了该方法的有效性。此外，对参与者和聊天机器人的对话进行了定性分析。", "result": "结果表明，对话免疫是一种有效的新型方法，并能够增强参与者的错误信息抵抗力；独立性和信任是提高对话免疫效率的因素，而交互摩擦则是一个障碍因素。", "conclusion": "通过及时的研究提供了一种有前途的研究方向，用于以可扩展的方式对抗错误信息。"}}
{"id": "2601.22390", "pdf": "https://arxiv.org/pdf/2601.22390", "abs": "https://arxiv.org/abs/2601.22390", "authors": ["Chanwoo Park", "Chanwoo Kim"], "title": "An Effective Energy Mask-based Adversarial Evasion Attacks against Misclassification in Speaker Recognition Systems", "categories": ["cs.SD", "cs.CR", "eess.AS"], "comment": null, "summary": "Evasion attacks pose significant threats to AI systems, exploiting vulnerabilities in machine learning models to bypass detection mechanisms. The widespread use of voice data, including deepfakes, in promising future industries is currently hindered by insufficient legal frameworks. Adversarial attack methods have emerged as the most effective countermeasure against the indiscriminate use of such data. This research introduces masked energy perturbation (MEP), a novel approach using power spectrum for energy masking of original voice data. MEP applies masking to small energy regions in the frequency domain before generating adversarial perturbations, targeting areas less noticeable to the human auditory model. The study primarily employs advanced speaker recognition models, including ECAPA-TDNN and ResNet34, which have shown remarkable performance in speaker verification tasks. The proposed MEP method demonstrated strong performance in both audio quality and evasion effectiveness. The energy masking approach effectively minimizes the perceptual evaluation of speech quality (PESQ) degradation, indicating that minimal perceptual distortion occurs to the human listener despite the adversarial perturbations. Specifically, in the PESQ evaluation, the relative performance of the MEP method was 26.68% when compared to the fast gradient sign method (FGSM) and iterative FGSM.", "AI": {"tldr": "介绍了一种新的能量掩码攻击方法MEP，用于针对语音识别系统的对抗性逃避攻击。", "motivation": "为了应对AI系统中机器学习模型的漏洞，提出一种有效的能量掩码对抗性攻击方法以减轻深度伪造等音频数据滥用的风险。", "method": "通过在频域中小能量区域应用能量掩码来生成扰动信号，并针对人耳不易察觉的部分进行优化。", "result": "实验表明MEP方法在语音质量保持和逃避有效性方面表现优异，特别是在PESQ评估中相对于FGSM和迭代FGSM提高了26.68%的性能。", "conclusion": "提出的能量掩码攻击方法MEP能够在不显著降低语音感知质量的情况下有效地执行对抗性逃避攻击。"}}
{"id": "2601.22387", "pdf": "https://arxiv.org/pdf/2601.22387", "abs": "https://arxiv.org/abs/2601.22387", "authors": ["Victor Nikhil Antony", "Adithya R N", "Sarah Derrick", "Zhili Gong", "Peter M. Donley", "Chien-Ming Huang"], "title": "Plant-Inspired Robot Design Metaphors for Ambient HRI", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Plants offer a paradoxical model for interaction: they are ambient, low-demand presences that nonetheless shape atmosphere, routines, and relationships through temporal rhythms and subtle expressions. In contrast, most human-robot interaction (HRI) has been grounded in anthropomorphic and zoomorphic paradigms, producing overt, high-demand forms of engagement. Using a Research through Design (RtD) methodology, we explore plants as metaphoric inspiration for HRI; we conducted iterative cycles of ideation, prototyping, and reflection to investigate what design primitives emerge from plant metaphors and morphologies, and how these primitives can be combined into expressive robotic forms. We present a suite of speculative, open-source prototypes that help probe plant-inspired presence, temporality, form, and gestures. We deepened our learnings from design and prototyping through prototype-centered workshops that explored people's perceptions and imaginaries of plant-inspired robots. This work contributes: (1) Set of plant-inspired robotic artifacts; (2) Designerly insights on how people perceive plant-inspired robots; and (3) Design consideration to inform how to use plant metaphors to reshape HRI.", "AI": {"tldr": "本文通过植物启发的设计隐喻探索机器人与人类的互动方式，提出了几款原型设计，并探讨了人们对这些植物灵感机器人的感知。", "motivation": "当前的人机交互研究多基于拟人化和兽形模式，这种模式容易导致高需求、显性的交流。而植物作为低要求、环境影响者，通过时间节律和微妙表达来塑造气氛和人际关系，为HRI提供了新的视角。", "method": "采用了设计导向的研究方法（RtD），包括迭代的构想、原型制作及反思过程。同时举办了以这些原型为中心的工作坊，探索人们对于植物灵感机器人的感知。", "result": "提出了一系列基于植物启发的机器人设计方案，并通过工作坊收集了人们对这类机器人的感知和想象。", "conclusion": "该研究为设计植物灵感的机器人提供了新思路，有助于塑造更加自然和谐的人机互动模式。"}}
{"id": "2601.22385", "pdf": "https://arxiv.org/pdf/2601.22385", "abs": "https://arxiv.org/abs/2601.22385", "authors": ["Chaoyue He", "Xin Zhou", "Di Wang", "Hong Xu", "Wei Liu", "Chunyan Miao"], "title": "SP^2DPO: An LLM-assisted Semantic Per-Pair DPO Generalization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "39 pages, 15 figures, 16 tables, 60 equations", "summary": "Direct Preference Optimization (DPO) controls the trade-off between fitting preference labels and staying close to a reference model using a single global temperature beta, implicitly treating all preference pairs as equally informative. Real-world preference corpora are heterogeneous: they mix high-signal, objective failures (for example, safety, factuality, instruction violations) with low-signal or subjective distinctions (for example, style), and also include label noise. We introduce our method, SP2DPO (Semantic Per-Pair DPO), a generalization that replaces the global temperature with an instance-specific schedule beta_i pre-decided offline from structured semantic-gap annotations (category, magnitude, confidence) produced by teacher language models. We instantiate this procedure on the UltraFeedback preference corpus (59,960 pairs), enabling large-scale construction of an auditable beta_i artifact, and incur zero training-time overhead: the inner-loop optimizer remains standard DPO with beta set per pair. We focus our empirical study on AlpacaEval 2.0, reporting both raw win rate and length-controlled win rate. Across four open-weight, instruction-tuned student backbones (4B-8B), SP2DPO is competitive with a tuned global-beta DPO baseline and improves AlpacaEval 2.0 length-controlled win rate on two of four backbones, while avoiding per-model beta sweeps. All code, annotations, and artifacts will be released.", "AI": {"tldr": "本文提出了一种新的方法SP^2DPO，用于更有效地通过调整实例特定的温度参数来优化直接偏好优化（DPO），从而在语言模型微调中取得更好的性能。", "motivation": "现实世界中的偏好数据集存在异质性问题，包括高信号和低信号或主观差异以及标签噪声。传统的单个全局温度参数无法有效处理这些复杂情况。", "method": "SP^2DPO使用来自教师语言模型的结构化语义间隙注释（类别、幅度、置信度）来决定每个偏好对的具体温度参数，从而替代单一的全局温度设置。", "result": "在AlpacaEval 2.0数据集上进行实验，针对四个不同大小的学生模型，在两个模型中SP^2DPO提升了长度控制下的获胜率。", "conclusion": "SP^2DPO方法能够有效地解决传统DPO无法有效处理异质性偏好数据的问题，并且在不增加训练时间开销的情况下取得了更好的性能。"}}
{"id": "2601.22384", "pdf": "https://arxiv.org/pdf/2601.22384", "abs": "https://arxiv.org/abs/2601.22384", "authors": ["Ziming Li", "Xiaoming Wu", "Zehong Wang", "Jiazheng Li", "Yijun Tian", "Jinhe Bi", "Yunpu Ma", "Yanfang Ye", "Chuxu Zhang"], "title": "Graph is a Substrate Across Data Modalities", "categories": ["cs.LG", "cs.AI"], "comment": "Graph structure across data modalities", "summary": "Graphs provide a natural representation of relational structure that arises across diverse domains. Despite this ubiquity, graph structure is typically learned in a modality- and task-isolated manner, where graph representations are constructed within individual task contexts and discarded thereafter. As a result, structural regularities across modalities and tasks are repeatedly reconstructed rather than accumulated at the level of intermediate graph representations. This motivates a representation-learning question: how should graph structure be organized so that it can persist and accumulate across heterogeneous modalities and tasks? We adopt a representation-centric perspective in which graph structure is treated as a structural substrate that persists across learning contexts. To instantiate this perspective, we propose G-Substrate, a graph substrate framework that organizes learning around shared graph structures. G-Substrate comprises two complementary mechanisms: a unified structural schema that ensures compatibility among graph representations across heterogeneous modalities and tasks, and an interleaved role-based training strategy that exposes the same graph structure to multiple functional roles during learning. Experiments across multiple domains, modalities, and tasks show that G-Substrate outperforms task-isolated and naive multi-task learning methods.", "AI": {"tldr": "本文提出了一种名为G-Substrate的框架，用于组织学习以围绕共享的图结构进行，从而在异构模态和任务中积累和持久化图结构。", "motivation": "当前图结构通常是在单一的任务上下文中单独学习并丢弃，导致跨模态和任务的结构性规律反复重建而不是在中间表示层次上累积。因此，本文提出了一种新的图表示方法来解决这一问题。", "method": "G-Substrate框架包含两个互补机制：一个统一的结构模式确保异构模态和任务之间的图表示兼容性；一种基于角色的交错训练策略，在学习过程中使相同的图结构暴露于多个功能角色下。", "result": "实验表明，G-Substrate在跨多个领域、模态和任务中优于单一任务隔离及简单多任务学习方法。", "conclusion": "通过采用共享持久化的图表示框架，可以有效提升跨异构数据模式的任务性能。"}}
{"id": "2601.22381", "pdf": "https://arxiv.org/pdf/2601.22381", "abs": "https://arxiv.org/abs/2601.22381", "authors": ["Victor Nikhil Antony", "Zhili Gong", "Guanchen Li", "Clara Jeon", "Chien-Ming Huang"], "title": "Lantern: A Minimalist Robotic Object Platform", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "Robotic objects are simple actuated systems that subtly blend into human environments. We design and introduce Lantern, a minimalist robotic object platform to enable building simple robotic artifacts. We conducted in-depth design and engineering iterations of Lantern's mechatronic architecture to meet specific design goals while maintaining a low build cost (~40 USD). As an extendable, open-source platform, Lantern aims to enable exploration of a range of HRI scenarios by leveraging human tendency to assign social meaning to simple forms. To evaluate Lantern's potential for HRI, we conducted a series of explorations: 1) a co-design workshop, 2) a sensory room case study, 3) distribution to external HRI labs, 4) integration into a graduate-level HRI course, and 5) public exhibitions with older adults and children. Our findings show that Lantern effectively evokes engagement, can support versatile applications ranging from emotion regulation to focused work, and serves as a viable platform for lowering barriers to HRI as a field.", "AI": {"tldr": "介绍了Lantern，一个低成本的机器人对象平台，用于构建简单的机器人装置。", "motivation": "旨在降低人机交互（HRI）领域的进入门槛，并利用人类对简单形式赋予社交意义的能力。", "method": "进行了深入的设计和工程迭代以开发Lantern的机电架构；通过一系列探索研究其在HRI中的潜力，包括联合设计研讨会、感觉室案例研究等。", "result": "发现Lantern有效激发了参与度，并支持从情感调节到专注工作等各种应用。", "conclusion": "Lantern作为平台证明了其在降低人机交互领域门槛的可行性。"}}
{"id": "2601.22376", "pdf": "https://arxiv.org/pdf/2601.22376", "abs": "https://arxiv.org/abs/2601.22376", "authors": ["Run Wang", "Chaoyi Zhou", "Amir Salarpour", "Xi Liu", "Zhi-Qi Cheng", "Feng Luo", "Mert D. Pesé", "Siyu Huang"], "title": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "categories": ["cs.CV"], "comment": null, "summary": "High-definition (HD) maps provide essential semantic information of road structures for autonomous driving systems, yet current HD map construction methods require calibrated multi-camera setups and either implicit or explicit 2D-to-BEV transformations, making them fragile when sensors fail or camera configurations vary across vehicle fleets. We introduce FlexMap, unlike prior methods that are fixed to a specific N-camera rig, our approach adapts to variable camera configurations without any architectural changes or per-configuration retraining. Our key innovation eliminates explicit geometric projections by using a geometry-aware foundation model with cross-frame attention to implicitly encode 3D scene understanding in feature space. FlexMap features two core components: a spatial-temporal enhancement module that separates cross-view spatial reasoning from temporal dynamics, and a camera-aware decoder with latent camera tokens, enabling view-adaptive attention without the need for projection matrices. Experiments demonstrate that FlexMap outperforms existing methods across multiple configurations while maintaining robustness to missing views and sensor variations, enabling more practical real-world deployment.", "AI": {"tldr": "FlexMap是一种构建高清地图的方法，适用于不同相机配置。", "motivation": "当前的高清地图构建方法需要校准的多摄像头设置，并且对传感器故障或摄像机配置变化敏感。FlexMap旨在适应不同的摄像机配置而无需重新训练或架构更改。", "method": "FlexMap使用几何感知基础模型和跨帧注意力来隐式地在特征空间中编码3D场景理解，避免了显式的几何投影。它有两个核心组件：一个时空增强模块和一个相机感知解码器。", "result": "实验表明，FlexMap超越了现有方法，并且对缺失视图和传感器变化保持鲁棒性。", "conclusion": "FlexMap可以更有效地适应不同的摄像机配置，实现了更加实用的现实世界部署。"}}
{"id": "2601.22369", "pdf": "https://arxiv.org/pdf/2601.22369", "abs": "https://arxiv.org/abs/2601.22369", "authors": ["Yujie Hui", "Xiaoyi Lu", "Andrew Perrault", "Yang Wang"], "title": "Learning Provably Correct Distributed Protocols Without Human Knowledge", "categories": ["cs.AI", "cs.DC"], "comment": null, "summary": "Provably correct distributed protocols, which are a critical component of modern distributed systems, are highly challenging to design and have often required decades of human effort. These protocols allow multiple agents to coordinate to come to a common agreement in an environment with uncertainty and failures. We formulate protocol design as a search problem over strategies in a game with imperfect information, and the desired correctness conditions are specified in Satisfiability Modulo Theories (SMT). However, standard methods for solving multi-agent games fail to learn correct protocols in this setting, even when the number of agents is small. We propose a learning framework, GGMS, which integrates a specialized variant of Monte Carlo Tree Search with a transformer-based action encoder, a global depth-first search to break out of local minima, and repeated feedback from a model checker. Protocols output by GGMS are verified correct via exhaustive model checking for all executions within the bounded setting. We further prove that, under mild assumptions, the search process is complete: if a correct protocol exists, GGMS will eventually find it. In experiments, we show that GGMS can learn correct protocols for larger settings than existing methods.", "AI": {"tldr": "本文提出了一种名为GGMS的学习框架，用于自动设计和验证分布式协议。", "motivation": "传统的分布式协议设计需要大量的人力资源且十分复杂。希望通过机器学习的方法来自动化这个过程，并确保所生成的协议是正确的。", "method": "通过将协议设计问题形式化为带有不完全信息的博弈搜索问题，使用改进的蒙特卡洛树搜索、Transformer动作编码器以及全局深度优先搜索等技术结合模型检查反馈进行学习和优化。该框架能在有限设置下通过彻底的模型检查验证输出协议的正确性。", "result": "实验表明，GGMS能够为比现有方法更复杂的系统规模生成正确的分布式协议。", "conclusion": "所提出的GGMS框架不仅能有效找到满足特定条件的分布式协议，而且在适当的假设条件下保证了搜索过程的完备性。"}}
{"id": "2601.22364", "pdf": "https://arxiv.org/pdf/2601.22364", "abs": "https://arxiv.org/abs/2601.22364", "authors": ["Eghbal A. Hosseini", "Yuxuan Li", "Yasaman Bahri", "Declan Campbell", "Andrew Kyle Lampinen"], "title": "Context Structure Reshapes the Representational Geometry of Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been shown to organize the representations of input sequences into straighter neural trajectories in their deep layers, which has been hypothesized to facilitate next-token prediction via linear extrapolation. Language models can also adapt to diverse tasks and learn new structure in context, and recent work has shown that this in-context learning (ICL) can be reflected in representational changes. Here we bring these two lines of research together to explore whether representation straightening occurs \\emph{within} a context during ICL. We measure representational straightening in Gemma 2 models across a diverse set of in-context tasks, and uncover a dichotomy in how LLMs' representations change in context. In continual prediction settings (e.g., natural language, grid world traversal tasks) we observe that increasing context increases the straightness of neural sequence trajectories, which is correlated with improvement in model prediction. Conversely, in structured prediction settings (e.g., few-shot tasks), straightening is inconsistent -- it is only present in phases of the task with explicit structure (e.g., repeating a template), but vanishes elsewhere. These results suggest that ICL is not a monolithic process. Instead, we propose that LLMs function like a Swiss Army knife: depending on task structure, the LLM dynamically selects between strategies, only some of which yield representational straightening.", "AI": {"tldr": "研究大语言模型在上下文学习中的表示变化，探索其内部序列轨迹的直线化现象。", "motivation": "探究大语言模型如何通过上下文结构改变表示几何，并提出不同的任务结构会导致不同的策略选择。", "method": "测量Gemma2模型在一系列多样化上下文任务中表现出来的表示直线化情况，并分析这种变化与预测性能的关系。", "result": "发现连续预测设置下，随着上下文的增加，神经序列轨迹变得更直，这与模型预测改善相关；而结构化预测设置下，只有具有明确结构的部分会表现出直线化现象。", "conclusion": "表明上下文学习并非单一过程，大语言模型根据任务结构动态选择策略，某些情况下才会产生表示直线化。"}}
{"id": "2601.22361", "pdf": "https://arxiv.org/pdf/2601.22361", "abs": "https://arxiv.org/abs/2601.22361", "authors": ["Yupeng Cao", "Chengyang He", "Yangyang Yu", "Ping Wang", "K. P. Subbalakshmi"], "title": "MERMAID: Memory-Enhanced Retrieval and Reasoning with Multi-Agent Iterative Knowledge Grounding for Veracity Assessment", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Assessing the veracity of online content has become increasingly critical. Large language models (LLMs) have recently enabled substantial progress in automated veracity assessment, including automated fact-checking and claim verification systems. Typical veracity assessment pipelines break down complex claims into sub-claims, retrieve external evidence, and then apply LLM reasoning to assess veracity. However, existing methods often treat evidence retrieval as a static, isolated step and do not effectively manage or reuse retrieved evidence across claims. In this work, we propose MERMAID, a memory-enhanced multi-agent veracity assessment framework that tightly couples the retrieval and reasoning processes. MERMAID integrates agent-driven search, structured knowledge representations, and a persistent memory module within a Reason-Action style iterative process, enabling dynamic evidence acquisition and cross-claim evidence reuse. By retaining retrieved evidence in an evidence memory, the framework reduces redundant searches and improves verification efficiency and consistency. We evaluate MERMAID on three fact-checking benchmarks and two claim-verification datasets using multiple LLMs, including GPT, LLaMA, and Qwen families. Experimental results show that MERMAID achieves state-of-the-art performance while improving the search efficiency, demonstrating the effectiveness of synergizing retrieval, reasoning, and memory for reliable veracity assessment.", "AI": {"tldr": "MERMAID 是一个记忆增强的多代理真实性评估框架，通过整合检索和推理过程来提高在线内容的真实性和可靠性。", "motivation": "现有的方法在处理证据检索时通常将其视为静态、孤立的操作，无法有效地管理和重复利用跨声明的检索证据。因此，提出了MERMAID以解决这一问题。", "method": "MERMAID框架结合了代理驱动搜索、结构化知识表示以及持久记忆模块，在理由-行动样式的迭代过程中实现了动态证据获取和跨声明证据重用，从而提高了验证效率和一致性。", "result": "通过在三个事实核查基准数据集和两个声明验证数据集中评估MERMAID，并使用GPT、LLaMA和Qwen系列等大语言模型进行测试，实验结果显示MERMAID达到了最先进的性能并提升了搜索效率。", "conclusion": "MERMAID方法成功地证明了将检索、推理与记忆技术结合在真实性和可靠性评估中的有效性。"}}
{"id": "2601.22359", "pdf": "https://arxiv.org/pdf/2601.22359", "abs": "https://arxiv.org/abs/2601.22359", "authors": ["Hsiang Hsu", "Pradeep Niroula", "Zichang He", "Ivan Brugere", "Freddy Lecue", "Chun-Fu Chen"], "title": "The Unseen Threat: Residual Knowledge in Machine Unlearning under Perturbed Samples", "categories": ["cs.LG", "cs.AI"], "comment": "Presented at NeurIPS 2025", "summary": "Machine unlearning offers a practical alternative to avoid full model re-training by approximately removing the influence of specific user data. While existing methods certify unlearning via statistical indistinguishability from re-trained models, these guarantees do not naturally extend to model outputs when inputs are adversarially perturbed. In particular, slight perturbations of forget samples may still be correctly recognized by the unlearned model - even when a re-trained model fails to do so - revealing a novel privacy risk: information about the forget samples may persist in their local neighborhood. In this work, we formalize this vulnerability as residual knowledge and show that it is inevitable in high-dimensional settings. To mitigate this risk, we propose a fine-tuning strategy, named RURK, that penalizes the model's ability to re-recognize perturbed forget samples. Experiments on vision benchmarks with deep neural networks demonstrate that residual knowledge is prevalent across existing unlearning methods and that our approach effectively prevents residual knowledge.", "AI": {"tldr": "本文探讨了机器遗忘机制在对抗性样本干扰下的隐私风险，并提出一种新的微调策略RURK来缓解这种风险。", "motivation": "现有方法通过统计不可区分性保证数据删除的有效性，但这些保障不适用于输入受到轻微扰动的情况。存在一种新型的隐私威胁：即忘记的数据在其局部邻域中仍可能被模型识别。", "method": "本文提出了一种名为RURK的新微调策略，该策略通过对模型重新识别扰动后的忘记样本进行惩罚来减轻这种风险。", "result": "实验结果表明，在视觉基准测试上使用深度神经网络时，残留知识在现有的遗忘方法中普遍存在。通过应用所提出的RURK策略能够有效防止残留知识的出现。", "conclusion": "本文揭示了机器遗忘过程中的一个未被注意到的安全漏洞，并提供了一个解决方案来减轻这一问题的影响。"}}
{"id": "2601.22356", "pdf": "https://arxiv.org/pdf/2601.22356", "abs": "https://arxiv.org/abs/2601.22356", "authors": ["Kiwan Wong", "Wei Xiao", "Daniela Rus"], "title": "PoSafeNet: Safe Learning with Poset-Structured Neural Nets", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Safe learning is essential for deploying learningbased controllers in safety-critical robotic systems, yet existing approaches often enforce multiple safety constraints uniformly or via fixed priority orders, leading to infeasibility and brittle behavior. In practice, safety requirements are heterogeneous and admit only partial priority relations, where some constraints are comparable while others are inherently incomparable. We formalize this setting as poset-structured safety, modeling safety constraints as a partially ordered set and treating safety composition as a structural property of the policy class. Building on this formulation, we propose PoSafeNet, a differentiable neural safety layer that enforces safety via sequential closed-form projection under poset-consistent constraint orderings, enabling adaptive selection or mixing of valid safety executions while preserving priority semantics by construction. Experiments on multi-obstacle navigation, constrained robot manipulation, and vision-based autonomous driving demonstrate improved feasibility, robustness, and scalability over unstructured and differentiable quadratic program-based safety layers.", "AI": {"tldr": "本文提出了PoSafeNet，一种基于偏序集结构的安全层神经网络，以适应性地选择或混合有效的安全执行，并在保障优先级语义的同时提高可操作性、鲁棒性和扩展性。", "motivation": "现有方法通常通过固定的优先级顺序强制实施多个安全性约束，这可能导致不可行和脆弱的行为。然而，在实际应用中，安全性要求是异构的，仅允许部分优先关系，使得一些约束具有可比性而其他则不具备。", "method": "该论文提出了基于偏序集的安全结构模型，并提出了一种不同的安全层神经网络PoSafeNet，通过在一致的偏序集中执行顺序闭合形式投影来实施安全性。这种方法能够适应性地选择或混合有效的安全执行，同时保持优先级语义。", "result": "实验结果表明，该方法相较于无结构和基于可微分二次规划的安全层，在多障碍物导航、受约束机器人操作以及基于视觉的自主驾驶中表现出更高的可行性、鲁棒性和扩展性。", "conclusion": "PoSafeNet通过引入偏序集结构来处理安全性要求的异质性，提供了一种适应性强且鲁棒性的解决方案。"}}
{"id": "2601.22352", "pdf": "https://arxiv.org/pdf/2601.22352", "abs": "https://arxiv.org/abs/2601.22352", "authors": ["Sri Vatsa Vuddanti", "Satwik Kumar Chittiprolu"], "title": "Recoverability Has a Law: The ERR Measure for Tool-Augmented Agents", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint for ICML Submission", "summary": "Language model agents often appear capable of self-recovery after failing tool call executions, yet this behavior lacks a formal explanation. We present a predictive theory that resolves this gap by showing that recoverability follows a measurable law. To elaborate, we formalize recoverability through Expected Recovery Regret (ERR), which quantifies the deviation of a recovery policy from the optimal one under stochastic execution noise, and derive a first-order relationship between ERR and an empirical observable quantity, the Efficiency Score (ES). This yields a falsifiable first-order quantitative law of recovery dynamics in tool-using agents. We empirically validate the law across five tool-use benchmarks spanning controlled perturbations, diagnostic reasoning, and real-world APIs. Across model scales, perturbation regimes, and recovery horizons, predicted regret under the ERR-ES law closely matched observed post-failure regret measured from Monte Carlo rollouts, within delta less than or equal to 0.05. Our results reveal that recoverability is not an artifact of model scale or architecture, but a governed property of interaction dynamics, providing a theoretical foundation for execution-level robustness in language agents.", "AI": {"tldr": "本文提出了一个预测理论，通过预期恢复遗憾（ERR）度量工具增强代理在失败后的自我恢复能力，并验证了这种恢复行为遵循可测量的定律。", "motivation": "语言模型代理在工具调用执行失败后似乎能够自我恢复，但缺乏正式解释。为了解决这一问题，本文提出了一种预测理论以形式化和量化这种恢复行为。", "method": "本文通过预期恢复遗憾（ERR）度量来描述恢复策略与最优策略之间的偏离程度，并推导出一个可验证的定律——即ERR-ES关系。该方法在五个工具使用基准上进行了实证验证。", "result": "实验结果表明，预测和实际观察到的后悔值之间差异小于或等于0.05，证明了恢复行为遵循可测量定律。", "conclusion": "本文研究揭示了语言代理中的自我恢复能力是一种交互动态属性而非模型规模或架构决定的现象，并为执行级别的鲁棒性提供了理论基础。"}}
{"id": "2601.22350", "pdf": "https://arxiv.org/pdf/2601.22350", "abs": "https://arxiv.org/abs/2601.22350", "authors": ["Beiming Li", "Sergio Rozada", "Alejandro Ribeiro"], "title": "Learning Policy Representations for Steerable Behavior Synthesis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Given a Markov decision process (MDP), we seek to learn representations for a range of policies to facilitate behavior steering at test time. As policies of an MDP are uniquely determined by their occupancy measures, we propose modeling policy representations as expectations of state-action feature maps with respect to occupancy measures. We show that these representations can be approximated uniformly for a range of policies using a set-based architecture. Our model encodes a set of state-action samples into a latent embedding, from which we decode both the policy and its value functions corresponding to multiple rewards. We use variational generative approach to induce a smooth latent space, and further shape it with contrastive learning so that latent distances align with differences in value functions. This geometry permits gradient-based optimization directly in the latent space. Leveraging this capability, we solve a novel behavior synthesis task, where policies are steered to satisfy previously unseen value function constraints without additional training.", "AI": {"tldr": "本文提出了一种学习策略表示的方法，旨在通过占用度量的期望来生成状态行为样本的嵌入，并在潜在空间中进行梯度优化以实现新的价值函数约束下的策略合成。", "motivation": "为了在测试时能够灵活地调整和引导行为，研究者希望找到一种方法，能够在给定马尔可夫决策过程（MDP）的情况下，学习一组策略的表示。通过这种方式可以满足新出现的价值功能限制而无需额外训练。", "method": "本文采用基于集合架构的方法来近似一组策略的表示，并使用变分生成和对比学习技术塑造潜在空间的几何结构，以使潜在距离与价值函数差异一致化。模型将状态行为样本编码为隐式嵌入，并从中解码出对应于多个奖励的政策及它们的价值功能。", "result": "该方法能够通过在潜在空间中进行梯度优化来合成满足新出现的价值函数约束的新策略，从而实现行为合成任务。", "conclusion": "研究证明了所提出的方法能够在不增加额外训练的情况下生成满足新价值函数限制的策略，并展示了其应用于行为合成的有效性和灵活性。"}}
{"id": "2601.22347", "pdf": "https://arxiv.org/pdf/2601.22347", "abs": "https://arxiv.org/abs/2601.22347", "authors": ["Sai Sanjeet", "Ian Colbert", "Pablo Monteagudo-Lago", "Giuseppe Franco", "Yaman Umuroglu", "Nicholas J. Fraser"], "title": "MixQuant: Pushing the Limits of Block Rotations in Post-Training Quantization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent post-training quantization (PTQ) methods have adopted block rotations to diffuse outliers prior to rounding. While this reduces the overhead of full-vector rotations, the effect of block structure on outlier suppression remains poorly understood. To fill this gap, we present the first systematic, non-asymptotic analysis of outlier suppression for block Hadamard rotations. Our analysis reveals that outlier suppression is fundamentally limited by the geometry of the input vector. In particular, post-rotation outliers are deterministically minimized when the pre-rotation $\\ell_1$ norm mass is evenly distributed across blocks. Guided by these insights, we introduce MixQuant, a block rotation-aware PTQ framework that redistributes activation mass via permutations prior to rotation. We propose a greedy mass diffusion algorithm to calibrate permutations by equalizing the expected blockwise $\\ell_1$ norms. To avoid adding inference overhead, we identify permutation-equivariant regions in transformer architectures to merge the resulting permutations into model weights before deployment. Experiments show that MixQuant consistently improves accuracy across all block sizes, recovering up to 90% of the full-vector rotation perplexity when quantizing Llama3 1B to INT4 with block size 16, compared to 46% without permutations.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.22338", "pdf": "https://arxiv.org/pdf/2601.22338", "abs": "https://arxiv.org/abs/2601.22338", "authors": ["Behnam Rahdari", "Sameer Shaikh", "Jonathan H Chen", "Tobias Gerstenberg", "Shriti Raj"], "title": "From Retrieving Information to Reasoning with AI: Exploring Different Interaction Modalities to Support Human-AI Coordination in Clinical Decision-Making", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "LLMs are popular among clinicians for decision-support because of simple text-based interaction. However, their impact on clinicians' performance is ambiguous. Not knowing how clinicians use this new technology and how they compare it to traditional clinical decision-support systems (CDSS) restricts designing novel mechanisms that overcome existing tool limitations and enhance performance and experience. This qualitative study examines how clinicians (n=12) perceive different interaction modalities (text-based conversation with LLMs, interactive and static UI, and voice) for decision-support. In open-ended use of LLM-based tools, our participants took a tool-centric approach using them for information retrieval and confirmation with simple prompts instead of use as active deliberation partners that can handle complex questions. Critical engagement emerged with changes to the interaction setup. Engagement also differed with individual cognitive styles. Lastly, benefits and drawbacks of interaction with text, voice and traditional UIs for clinical decision-support show the lack of a one-size-fits-all interaction modality.", "AI": {"tldr": "探讨临床医生在使用大型语言模型（LLMs）进行决策支持时的不同交互模式，包括文本对话、互动和静态用户界面以及语音。", "motivation": "探索临床医生如何利用新的AI技术并将其与传统的临床决策支持系统(CDSS)进行比较，以克服现有工具的局限性，并提升性能和体验。", "method": "通过质性研究方法对12名临床医生使用不同交互模式（基于文本对话的LLMs、互动界面及静态用户界面以及语音）的态度进行了开放式的调研。", "result": "参与者倾向于采取工具中心的方法，利用这些工具进行信息检索与确认，而非将其作为处理复杂问题的积极合作伙伴。当改变交互设置时，参与者的批判性互动有所增加，并且这种变化因个人认知风格不同而异。", "conclusion": "研究表明，不存在适用于所有情况的一体化交互模式，每种交互方式都有其优点和缺点。"}}
{"id": "2601.22329", "pdf": "https://arxiv.org/pdf/2601.22329", "abs": "https://arxiv.org/abs/2601.22329", "authors": ["Ala N. Tak", "Amin Banayeeanzade", "Anahita Bolourani", "Fatemeh Bahrani", "Ashutosh Chaubey", "Sai Praneeth Karimireddy", "Norbert Schwarz", "Jonathan Gratch"], "title": "Sparks of Rationality: Do Reasoning LLMs Align with Human Judgment and Choice?", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly positioned as decision engines for hiring, healthcare, and economic judgment, yet real-world human judgment reflects a balance between rational deliberation and emotion-driven bias. If LLMs are to participate in high-stakes decisions or serve as models of human behavior, it is critical to assess whether they exhibit analogous patterns of (ir)rationalities and biases. To this end, we evaluate multiple LLM families on (i) benchmarks testing core axioms of rational choice and (ii) classic decision domains from behavioral economics and social norms where emotions are known to shape judgment and choice. Across settings, we show that deliberate \"thinking\" reliably improves rationality and pushes models toward expected-value maximization. To probe human-like affective distortions and their interaction with reasoning, we use two emotion-steering methods: in-context priming (ICP) and representation-level steering (RLS). ICP induces strong directional shifts that are often extreme and difficult to calibrate, whereas RLS produces more psychologically plausible patterns but with lower reliability. Our results suggest that the same mechanisms that improve rationality also amplify sensitivity to affective interventions, and that different steering methods trade off controllability against human-aligned behavior. Overall, this points to a tension between reasoning and affective steering, with implications for both human simulation and the safe deployment of LLM-based decision systems.", "AI": {"tldr": "该论文研究了大规模语言模型（LLMs）在决策任务中的理性程度和情感偏差，评估它们与人类判断的一致性。", "motivation": "随着大模型被用于招聘、医疗和个人经济决策等高风险场景中，了解这些模型是否具有类似人类的理性和偏见变得至关重要。如果要让这些模型成为人类行为的模型或参与重要的决策过程，理解其偏差模式是必要的。", "method": "论文通过两个方面评估了多个大模型家族：一是在测试理性选择核心公理的基准上进行评测；二是在经典的行为经济学和社交规范领域中进行评价。此外，使用上下文引导（ICP）和表示层转向（RLS）两种情感操控方法来探究人类的情感偏差。", "result": "实验发现，在经过推理后，模型更加趋向于期望值最大化。然而不同的情绪操控方法在可靠性和行为一致性上存在权衡：ICP可能导致极端且难以校准的结果，而RLS则更接近人类的心理模式但可靠性较低。", "conclusion": "研究指出，提高理性的同时也会放大对情感干预的敏感度，并说明了不同的情绪转向技术之间存在着可控性与行为一致性的权衡。这些发现对于大模型的人类模拟和安全部署具有重要意义。"}}
{"id": "2601.22311", "pdf": "https://arxiv.org/pdf/2601.22311", "abs": "https://arxiv.org/abs/2601.22311", "authors": ["Zehong Wang", "Fang Wu", "Hongru Wang", "Xiangru Tang", "Bolian Li", "Zhenfei Yin", "Yijun Ma", "Yiyang Li", "Weixiang Sun", "Xiusi Chen", "Yanfang Ye"], "title": "Why Reasoning Fails to Plan: A Planning-Centric Analysis of Long-Horizon Decision Making in LLM Agents", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language model (LLM)-based agents exhibit strong step-by-step reasoning capabilities over short horizons, yet often fail to sustain coherent behavior over long planning horizons. We argue that this failure reflects a fundamental mismatch: step-wise reasoning induces a form of step-wise greedy policy that is adequate for short horizons but fails in long-horizon planning, where early actions must account for delayed consequences. From this planning-centric perspective, we study LLM-based agents in deterministic, fully structured environments with explicit state transitions and evaluation signals. Our analysis reveals a core failure mode of reasoning-based policies: locally optimal choices induced by step-wise scoring lead to early myopic commitments that are systematically amplified over time and difficult to recover from. We introduce FLARE (Future-aware Lookahead with Reward Estimation) as a minimal instantiation of future-aware planning to enforce explicit lookahead, value propagation, and limited commitment in a single model, allowing downstream outcomes to influence early decisions. Across multiple benchmarks, agent frameworks, and LLM backbones, FLARE consistently improves task performance and planning-level behavior, frequently allowing LLaMA-8B with FLARE to outperform GPT-4o with standard step-by-step reasoning. These results establish a clear distinction between reasoning and planning.", "AI": {"tldr": "研究大型语言模型代理在长时规划中的失败模式，并引入FLARE方法以改善长期决策。", "motivation": "指出基于LLM的代理具有短时间范围内强大的步进推理能力，但难以维持长时间内的一致行为。这反映了逐级推理导致了贪婪策略，在短期足够但在长期规划中失败的问题。", "method": "提出一种名为FLARE的方法，该方法通过引入未来前瞻性的规划来解决局部最优选择和早期近视承诺的问题，允许下游结果影响初始决策。", "result": "在多个基准测试、代理框架以及不同LLM后端上，使用FLARE的实验表明其能够显著提升任务性能及规划级行为，有时甚至可以使LLaMA-8B优于GPT-4o。", "conclusion": "研究表明基于推理和计划的方法之间存在明确的区别，并证明了未来前瞻性的方法可以有效改善长期决策。"}}
{"id": "2601.22308", "pdf": "https://arxiv.org/pdf/2601.22308", "abs": "https://arxiv.org/abs/2601.22308", "authors": ["Javier Carnerero-Cano", "Luis Muñoz-González", "Phillippa Spencer", "Emil C. Lupu"], "title": "Stealthy Poisoning Attacks Bypass Defenses in Regression Settings", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Regression models are widely used in industrial processes, engineering and in natural and physical sciences, yet their robustness to poisoning has received less attention. When it has, studies often assume unrealistic threat models and are thus less useful in practice. In this paper, we propose a novel optimal stealthy attack formulation that considers different degrees of detectability and show that it bypasses state-of-the-art defenses. We further propose a new methodology based on normalization of objectives to evaluate different trade-offs between effectiveness and detectability. Finally, we develop a novel defense (BayesClean) against stealthy attacks. BayesClean improves on previous defenses when attacks are stealthy and the number of poisoning points is significant.", "AI": {"tldr": "论文提出了一种新的隐蔽攻击公式，并开发了针对隐蔽攻击的新防御方法BayesClean。", "motivation": "工业过程、工程和自然科学等领域广泛应用回归模型，但对这些模型的中毒攻击鲁棒性研究较少。当前的研究通常假设不现实的威胁模型，实际应用价值不高。", "method": "论文提出了一种考虑不同隐蔽性的最优隐蔽攻击公式，并设计了基于目标归一化的新方法来评估有效性与隐蔽之间的权衡关系。同时开发了一种新的防御方法BayesClean来对抗隐蔽攻击。", "result": "新提出的攻击可以绕过现有的最佳防御，而BayesClean在面对隐蔽性和大量中毒点时优于现有防御措施。", "conclusion": "论文提出的方法能够有效地实施和检测隐蔽的回归模型中毒攻击，并提供了一种新的评估不同权衡关系的方法，同时开发了有效的防御机制。"}}
{"id": "2601.22306", "pdf": "https://arxiv.org/pdf/2601.22306", "abs": "https://arxiv.org/abs/2601.22306", "authors": ["Cheol Jun Cho", "Nicholas Lee", "Alan W Black", "Gopala K. Anumanchipalli"], "title": "Sylber 2.0: A Universal Syllable Embedding", "categories": ["eess.AS", "cs.CL"], "comment": null, "summary": "Scaling spoken language modeling requires speech tokens that are both efficient and universal. Recent work has proposed syllables as promising speech tokens at low temporal resolution, but existing models are constrained to English and fail to capture sufficient acoustic detail. To address this gap, we present Sylber 2.0, a self-supervised framework for coding speech at the syllable level that enables efficient temporal compression and high-fidelity reconstruction. Sylber 2.0 achieves a very low token frequency around 5 Hz, while retaining both linguistic and acoustic detail across multiple languages and expressive styles. Experiments show that it performs on par with previous models operating on high-frequency baselines. Furthermore, Sylber 2.0 enables efficient TTS modeling which can generate speech with competitive intelligibility and quality with SOTA models using only 72M parameters. Moreover, the universality of Sylber 2.0 provides more effective features for low resource ASR than previous speech coding frameworks. In sum, we establish an effective syllable-level abstraction for general spoken language.", "AI": {"tldr": "提出了一种新的自监督框架Sylber 2.0，用于编码语音的音节级信息，实现高效的时间压缩和高保真重建。", "motivation": "现有模型仅限于英语且不能捕捉足够的声学细节。为了解决这个问题，作者提出了Sylber 2.0以提供更高效的语音建模方法，同时保持多语言和表现风格的语义和声学细节。", "method": "提出了一种自监督框架Sylber 2.0，该框架在音节级别上编码语音，并实现了高效的时间压缩以及高保真度重建。实验表明它与基于高频基线运行的先前模型具有相当性能。", "result": "Sylber 2.0能够在保持语言和声学细节的同时实现非常低的令牌频率约5 Hz。此外，该方法支持高效的TTS建模并能生成与最新技术水平(SOTA)相竞争的质量和可懂度的语音。", "conclusion": "Sylber 2.0提供了一种有效的音节级抽象以用于一般的口语语言处理任务，包括低资源条件下的自动语音识别(ASR)"}}
{"id": "2601.22301", "pdf": "https://arxiv.org/pdf/2601.22301", "abs": "https://arxiv.org/abs/2601.22301", "authors": ["Gonzalo Gomez-Nogales", "Yicong Hong", "Chongjian Ge", "Marc Comino-Trinidad", "Dan Casas", "Yi Zhou"], "title": "Coarse-to-Real: Generative Rendering for Populated Dynamic Scenes", "categories": ["cs.CV"], "comment": "Project website at https://gonzalognogales.github.io/coarse2real/", "summary": "Traditional rendering pipelines rely on complex assets, accurate materials and lighting, and substantial computational resources to produce realistic imagery, yet they still face challenges in scalability and realism for populated dynamic scenes. We present C2R (Coarse-to-Real), a generative rendering framework that synthesizes real-style urban crowd videos from coarse 3D simulations. Our approach uses coarse 3D renderings to explicitly control scene layout, camera motion, and human trajectories, while a learned neural renderer generates realistic appearance, lighting, and fine-scale dynamics guided by text prompts. To overcome the lack of paired training data between coarse simulations and real videos, we adopt a two-phase mixed CG-real training strategy that learns a strong generative prior from large-scale real footage and introduces controllability through shared implicit spatio-temporal features across domains. The resulting system supports coarse-to-fine control, generalizes across diverse CG and game inputs, and produces temporally consistent, controllable, and realistic urban scene videos from minimal 3D input. We will release the model and project webpage at https://gonzalognogales.github.io/coarse2real/.", "AI": {"tldr": "本文提出了一种名为C2R的生成式渲染框架，能够从粗糙的3D模拟中合成逼真的城市人群视频。", "motivation": "传统的渲染流水线依赖复杂的资产、准确的材质和光照，并且需要大量的计算资源来生成逼真的图像，在人口动态场景中的可扩展性和现实感方面仍然存在挑战。", "method": "C2R框架使用粗糙3D渲染来控制场景布局，摄像机运动和人类轨迹，同时通过学习神经渲染器产生真实的外观、光照和细粒度动力学。利用大规模的真实视频训练数据以克服配对训练数据不足的问题，并引入域间共享的隐式时空特征进行可控性。", "result": "该系统支持从最少3D输入中生成具有时间一致性和可控制性的逼真城市场景视频，且在不同的CG和游戏输入上均表现出良好的泛化能力。", "conclusion": "C2R框架通过最小化的3D输入实现了高质量的动态人群场景渲染，解决了传统方法中的许多挑战，并为未来研究提供了新的思路。"}}
{"id": "2601.22298", "pdf": "https://arxiv.org/pdf/2601.22298", "abs": "https://arxiv.org/abs/2601.22298", "authors": ["Qidong Yang", "Qianyu Julie Zhu", "Jonathan Giezendanner", "Youssef Marzouk", "Stephen Bates", "Sherrie Wang"], "title": "Conformal Prediction for Generative Models via Adaptive Cluster-Based Density Estimation", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "Conditional generative models map input variables to complex, high-dimensional distributions, enabling realistic sample generation in a diverse set of domains. A critical challenge with these models is the absence of calibrated uncertainty, which undermines trust in individual outputs for high-stakes applications. To address this issue, we propose a systematic conformal prediction approach tailored to conditional generative models, leveraging density estimation on model-generated samples. We introduce a novel method called CP4Gen, which utilizes clustering-based density estimation to construct prediction sets that are less sensitive to outliers, more interpretable, and of lower structural complexity than existing methods. Extensive experiments on synthetic datasets and real-world applications, including climate emulation tasks, demonstrate that CP4Gen consistently achieves superior performance in terms of prediction set volume and structural simplicity. Our approach offers practitioners a powerful tool for uncertainty estimation associated with conditional generative models, particularly in scenarios demanding rigorous and interpretable prediction sets.", "AI": {"tldr": "提出了CP4Gen方法，通过基于聚类的密度估计来构造预测集合，以解决条件生成模型中的不确定性问题。", "motivation": "现有的条件生成模型缺乏校准后的不确定性评估，这在高风险应用中是一个关键挑战。为了解决这个问题，作者提出了一种适应性较强的预测方法，提高对单个输出的信任度。", "method": "CP4Gen利用基于聚类的密度估计技术来构建预测集合，从而减少对异常值的敏感性，并提供更可解释和结构上简单的结果。", "result": "实验表明，与现有方法相比，CP4Gen在合成数据集和真实世界应用中表现更加出色，特别是在预测集大小和结构性简明方面具有优势。", "conclusion": "该研究为条件生成模型提供了强大的不确定性估计工具，并且特别适用于需要严格解释性的高风险预测场景。"}}
{"id": "2601.22296", "pdf": "https://arxiv.org/pdf/2601.22296", "abs": "https://arxiv.org/abs/2601.22296", "authors": ["Matteo Pinna", "Giacomo Lagomarsini", "Andrea Ceni", "Claudio Gallicchio"], "title": "ParalESN: Enabling parallel information processing in Reservoir Computing", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 6 figures, 9 tables", "summary": "Reservoir Computing (RC) has established itself as an efficient paradigm for temporal processing. However, its scalability remains severely constrained by (i) the necessity of processing temporal data sequentially and (ii) the prohibitive memory footprint of high-dimensional reservoirs. In this work, we revisit RC through the lens of structured operators and state space modeling to address these limitations, introducing Parallel Echo State Network (ParalESN). ParalESN enables the construction of high-dimensional and efficient reservoirs based on diagonal linear recurrence in the complex space, enabling parallel processing of temporal data. We provide a theoretical analysis demonstrating that ParalESN preserves the Echo State Property and the universality guarantees of traditional Echo State Networks while admitting an equivalent representation of arbitrary linear reservoirs in the complex diagonal form. Empirically, ParalESN matches the predictive accuracy of traditional RC on time series benchmarks, while delivering substantial computational savings. On 1-D pixel-level classification tasks, ParalESN achieves competitive accuracy with fully trainable neural networks while reducing computational costs and energy consumption by orders of magnitude. Overall, ParalESN offers a promising, scalable, and principled pathway for integrating RC within the deep learning landscape.", "AI": {"tldr": "本文提出了一种名为ParalESN的新方法，可以在复杂空间中实现高维和高效的回声状态网络的构建，并通过平行处理时间序列数据来提高其可扩展性。", "motivation": "RC在处理时序数据方面效率很高，但由于必须顺序处理时序数据以及高维水库所需的内存开销过大，导致其可伸缩性受限。因此，本文旨在开发一种可以在复杂空间中实现高效且高维度回声状态网络的方法。", "method": "ParalESN是基于复数对角线线性递归来构建的，它允许时序数据并行处理，并通过理论分析证明了该方法保持了传统Echo State Network的回声状态属性和通用保证，同时可以在复数对角形式中表示任意线性水库。", "result": "ParalESN在时间序列基准上达到了与传统RC相同的预测准确度，同时提供了显著的计算节省。在一维像素级分类任务上，ParalESN实现了与完全可训练神经网络相当的准确性，并降低了多个数量级的计算成本和能耗。", "conclusion": "总体而言，ParalESN为将RC整合到深度学习领域提供了一种有前途、可扩展且原则性的路径。"}}
{"id": "2601.22290", "pdf": "https://arxiv.org/pdf/2601.22290", "abs": "https://arxiv.org/abs/2601.22290", "authors": ["Khush Patel", "Siva Surendira", "Jithin George", "Shreyas Kapale"], "title": "The Six Sigma Agent: Achieving Enterprise-Grade Reliability in LLM Systems Through Consensus-Driven Decomposed Execution", "categories": ["cs.AI"], "comment": "25 pages, 7 figures, 2 tables", "summary": "Large Language Models demonstrate remarkable capabilities yet remain fundamentally probabilistic, presenting critical reliability challenges for enterprise deployment. We introduce the Six Sigma Agent, a novel architecture that achieves enterprise-grade reliability through three synergistic components: (1) task decomposition into a dependency tree of atomic actions; (2) micro-agent sampling where each task is executed n times in parallel across diverse LLMs to generate independent outputs; and (3) consensus voting with dynamic scaling, clustering outputs and selecting the answer from the winning cluster with maximum votes. We prove that sampling n independent outputs with error rate p achieves system error O(p^{ceil(n/2)}), enabling exponential reliability gains. Even using cheaper models with 5% per-action error, consensus voting with 5 agents reduces error to 0.11%; dynamic scaling to 13 agents achieves 3.4 DPMO (Defects Per Million Opportunities), the Six Sigma standard. Evaluation across three enterprise use cases demonstrates a 14,700x reliability improvement over single-agent execution while reducing costs by 80%. Our work establishes that reliability in AI systems emerges from principled redundancy and consensus rather than model scaling alone.", "AI": {"tldr": "研究提出了一种名为Six Sigma Agent的新架构，通过任务分解、微代理采样和共识投票来提升大语言模型系统的可靠性。", "motivation": "大语言模型在企业部署中面临关键的可靠性挑战，因为它们本质上是概率性的。", "method": "该方法包括任务分解成依赖树形结构的原子动作；微代理采样，即每个任务并行地由多个不同的LLM执行n次以生成独立输出；共识投票结合动态扩展，对输出进行聚类，并选择具有最大票数的获胜簇的答案。", "result": "通过使用5个代理实现0.11%的错误率，在扩展到13个代理时达到了六西格玛标准的3.4 DPMO。在三个企业用例中展示出比单代理执行高出14700倍的可靠性，同时成本降低了80%。", "conclusion": "研究证明了AI系统的可靠性可以通过冗余和共识而不是仅仅通过模型扩展来实现。"}}
{"id": "2601.22289", "pdf": "https://arxiv.org/pdf/2601.22289", "abs": "https://arxiv.org/abs/2601.22289", "authors": ["Jeeho Ahn", "Christoforos Mavrogiannis"], "title": "ReloPush-BOSS: Optimization-guided Nonmonotone Rearrangement Planning for a Car-like Robot Pusher", "categories": ["cs.RO"], "comment": "Preprint of final version, accepted to RA-L 2026", "summary": "We focus on multi-object rearrangement planning in densely cluttered environments using a car-like robot pusher. The combination of kinematic, geometric and physics constraints underlying this domain results in challenging nonmonotone problem instances which demand breaking each manipulation action into multiple parts to achieve a desired object rearrangement. Prior work tackles such instances by planning prerelocations, temporary object displacements that enable constraint satisfaction, but deciding where to prerelocate remains difficult due to local minima leading to infeasible or high-cost paths. Our key insight is that these minima can be avoided by steering a prerelocation optimization toward low-cost regions informed by Dubins path classification. These optimized prerelocations are integrated into an object traversability graph that encodes kinematic, geometric, and pushing constraints. Searching this graph in a depth-first fashion results in efficient, feasible rearrangement sequences. Across a series of densely cluttered scenarios with up to 13 objects, our framework, ReloPush-BOSS, exhibits consistently highest success rates and shortest pushing paths compared to state-of-the-art baselines. Hardware experiments on a 1/10 car-like pusher demonstrate the robustness of our approach. Code and footage from our experiments can be found at: https://fluentrobotics.com/relopushboss.", "AI": {"tldr": "提出了一种用于解决密集环境中多物体重排问题的优化引导非单调重组规划方法。", "motivation": "在使用类似汽车的机器人推手进行紧密排列环境中的多物体重排时，由于复杂的运动学、几何和物理约束条件，传统的方法难以避免陷入局部最小值从而导致不切实际或高成本路径的问题。为此，提出了一种新的重组规划方法。", "method": "通过优化预重定位操作来避开局部最优点，并将这些优化后的预重定位集成到一个物体可通达性图中，该图形包含了运动学、几何和推力约束条件。这种深度优先搜索策略能够生成高效且可行的物体重排序列。", "result": "在多达13个物体的密集场景下，所提出的框架ReloPush-BOSS相比现有方法表现出更高的成功概率及更短的推送路径长度，并通过硬件实验验证了其稳健性。", "conclusion": "该研究提出了一种有效解决多物体重排问题的新方案，通过优化预重定位策略并结合深度优先搜索技术实现了高效、可行的物体重排。"}}
{"id": "2601.22288", "pdf": "https://arxiv.org/pdf/2601.22288", "abs": "https://arxiv.org/abs/2601.22288", "authors": ["Mario Truss"], "title": "PersonaCite: VoC-Grounded Interviewable Agentic Synthetic AI Personas for Verifiable User and Design Research", "categories": ["cs.HC", "cs.AI", "eess.AS", "eess.IV"], "comment": null, "summary": "LLM-based and agent-based synthetic personas are increasingly used in design and product decision-making, yet prior work shows that prompt-based personas often produce persuasive but unverifiable responses that obscure their evidentiary basis. We present PersonaCite, an agentic system that reframes AI personas as evidence-bounded research instruments through retrieval-augmented interaction. Unlike prior approaches that rely on prompt-based roleplaying, PersonaCite retrieves actual voice-of-customer artifacts during each conversation turn, constrains responses to retrieved evidence, explicitly abstains when evidence is missing, and provides response-level source attribution. Through semi-structured interviews and deployment study with 14 industry experts, we identify preliminary findings on perceived benefits, validity concerns, and design tensions, and propose Persona Provenance Cards as a documentation pattern for responsible AI persona use in human-centered design workflows.", "AI": {"tldr": "PersonaCite是一款基于实际客户声音的合成AI人物系统，用于设计和产品决策。", "motivation": "现有的基于提示的人物生成方法会产生无法验证的回答，这模糊了证据基础。为此，研发者希望通过一种新的系统解决这一问题，并提供可追溯性与可靠性。", "method": "PersonaCite通过检索增强交互，获取每一轮对话中的实际客户声音数据，限制回答以检索到的证据为基础，当缺乏证据时明确拒绝回答，并且为每个回复提供来源引用。", "result": "通过半结构化访谈和14位行业专家的研究部署，初步识别了感知收益、有效性和设计紧张点。提出了Persona Provenance Cards作为负责任的人工智能人物使用的文档模式，在以人为中心的设计工作流程中使用。", "conclusion": "研究提出了一种新的基于证据的合成AI人物系统，为设计和产品决策提供了可信度，并探讨了其在实际应用中的潜力与挑战。"}}
{"id": "2601.22276", "pdf": "https://arxiv.org/pdf/2601.22276", "abs": "https://arxiv.org/abs/2601.22276", "authors": ["Mingyu Lu", "Soham Gadgil", "Chris Lin", "Chanwoo Kim", "Su-In Lee"], "title": "SurrogateSHAP: Training-Free Contributor Attribution for Text-to-Image (T2I) Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "As Text-to-Image (T2I) diffusion models are increasingly used in real-world creative workflows, a principled framework for valuing contributors who provide a collection of data is essential for fair compensation and sustainable data marketplaces. While the Shapley value offers a theoretically grounded approach to attribution, it faces a dual computational bottleneck: (i) the prohibitive cost of exhaustive model retraining for each sampled subset of players (i.e., data contributors) and (ii) the combinatorial number of subsets needed to estimate marginal contributions due to contributor interactions. To this end, we propose SurrogateSHAP, a retraining-free framework that approximates the expensive retraining game through inference from a pretrained model. To further improve efficiency, we employ a gradient-boosted tree to approximate the utility function and derive Shapley values analytically from the tree-based model. We evaluate SurrogateSHAP across three diverse attribution tasks: (i) image quality for DDPM-CFG on CIFAR-20, (ii) aesthetics for Stable Diffusion on Post-Impressionist artworks, and (iii) product diversity for FLUX.1 on Fashion-Product data. Across settings, SurrogateSHAP outperforms prior methods while substantially reducing computational overhead, consistently identifying influential contributors across multiple utility metrics. Finally, we demonstrate that SurrogateSHAP effectively localizes data sources responsible for spurious correlations in clinical images, providing a scalable path toward auditing safety-critical generative models.", "AI": {"tldr": "提出了一种不需重新训练的框架SurrogateSHAP，用于评估文本到图像模型中的数据贡献者的重要性。", "motivation": "为了公平地评价和补偿数据提供者的贡献，并促进可持续的数据市场环境，需要一种基于理论的方法来评估贡献者的价值。然而，Shapley值方法在计算上存在瓶颈，即每次抽样都需要对模型进行昂贵的重新训练，以及大量的子集数量。", "method": "通过预训练模型的推理来近似昂贵的重新训练过程，并使用梯度增强树来逼近效用函数，从基于树的模型中推导出Shapley值。", "result": "在不同的归因任务上评估了SurrogateSHAP，包括图像质量、美学和产品多样性。结果显示，在减少计算开销的同时，SurrogateSHAP优于先前的方法，并且能有效地识别具有影响力的贡献者。", "conclusion": "SurrogateSHAP为文本到图像模型中的数据贡献者的评价提供了有效的解决方案，并展示了其在审计安全关键生成性模型方面的潜力。"}}
{"id": "2601.22275", "pdf": "https://arxiv.org/pdf/2601.22275", "abs": "https://arxiv.org/abs/2601.22275", "authors": ["Cheng Liang", "Haoxian Chen", "Liang Hou", "Qi Fan", "Gangshan Wu", "Xin Tao", "Limin Wang"], "title": "VMonarch: Efficient Video Diffusion Transformers with Structured Attention", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The quadratic complexity of the attention mechanism severely limits the context scalability of Video Diffusion Transformers (DiTs). We find that the highly sparse spatio-temporal attention patterns exhibited in Video DiTs can be naturally represented by the Monarch matrix. It is a class of structured matrices with flexible sparsity, enabling sub-quadratic attention via an alternating minimization algorithm. Accordingly, we propose VMonarch, a novel attention mechanism for Video DiTs that enables efficient computation over the dynamic sparse patterns with structured Monarch matrices. First, we adapt spatio-temporal Monarch factorization to explicitly capture the intra-frame and inter-frame correlations of the video data. Second, we introduce a recomputation strategy to mitigate artifacts arising from instabilities during alternating minimization of Monarch matrices. Third, we propose a novel online entropy algorithm fused into FlashAttention, enabling fast Monarch matrix updates for long sequences. Extensive experiments demonstrate that VMonarch achieves comparable or superior generation quality to full attention on VBench after minimal tuning. It overcomes the attention bottleneck in Video DiTs, reduces attention FLOPs by a factor of 17.5, and achieves a speedup of over 5x in attention computation for long videos, surpassing state-of-the-art sparse attention methods at 90% sparsity.", "AI": {"tldr": "提出了一种名为VMonarch的新注意力机制，用于视频扩散转换器（DiTs），该机制通过结构化的矩阵提高了效率。", "motivation": "视频DiTs中的稀疏时空注意模式可以自然地用Monarch矩阵表示，以提高视频生成的上下文可扩展性并克服计算瓶颈。", "method": "利用结构化蒙巴赫矩阵进行高效计算，引入重构策略减少不稳定问题，并结合在线熵算法加速长序列上的更新。", "result": "实验表明，VMonarch在VBench上实现了与全注意力相当或更好的生成质量，减少了17.5倍的注意FLOPs并获得了超过5倍的速度提升。", "conclusion": "通过结构化矩阵优化了视频DiTs中的注意力机制，提高了计算效率和性能。"}}
{"id": "2601.22269", "pdf": "https://arxiv.org/pdf/2601.22269", "abs": "https://arxiv.org/abs/2601.22269", "authors": ["Sahil Garg", "Brad Cheezum", "Sridhar Dutta", "Vishal Agarwal"], "title": "JAF: Judge Agent Forest", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Judge agents are fundamental to agentic AI frameworks: they provide automated evaluation, and enable iterative self-refinement of reasoning processes. We introduce JAF: Judge Agent Forest, a framework in which the judge agent conducts joint inference across a cohort of query--response pairs generated by a primary agent, rather than evaluating each in isolation. This paradigm elevates the judge from a local evaluator to a holistic learner: by simultaneously assessing related responses, the judge discerns cross-instance patterns and inconsistencies, whose aggregate feedback enables the primary agent to improve by viewing its own outputs through the judge's collective perspective. Conceptually, JAF bridges belief propagation and ensemble-learning principles: overlapping in-context neighborhoods induce a knowledge-graph structure that facilitates propagation of critique, and repeated, randomized evaluations yield a robust ensemble of context-sensitive judgments. JAF can be instantiated entirely via ICL, with the judge prompted for each query using its associated primary-agent response plus a small, possibly noisy set of peer exemplars. While kNN in embedding space is a natural starting point for exemplars, this approach overlooks categorical structure, domain metadata, or nuanced distinctions accessible to modern LLMs. To overcome these limitations, we develop a flexible locality-sensitive hashing (LSH) algorithm that learns informative binary codes by integrating semantic embeddings, LLM-driven hash predicates, supervision from categorical labels, and relevant side information. These hash codes support efficient, interpretable, and relation-aware selection of diverse exemplars, and further optimize exploration of CoT reasoning paths. We validate JAF with an empirical study on the demanding task of cloud misconfigs triage in large-scale cloud environments.", "AI": {"tldr": "本文介绍了一种称为JAF的框架，该框架通过联合推理跨多个查询响应对来提升判断代理的功能，从而帮助主代理改进其输出。", "motivation": "提高AI系统的自我评估和迭代改善能力。传统方法中，每个查询响应对被单独评价；而JAF则将相关响应进行整体性评估，以发现模式和不一致，并通过集体视角反馈给主代理，进而促进自我完善。", "method": "提出了一种基于ICL的JAF框架，在该框架下判断代理可以联合推理跨多个查询响应对。同时开发了一种灵活的局部敏感哈希算法来选择多样化的示例以支持高效、可解释和关系感知的选择。", "result": "通过实验证明，JAF在大规模云环境中处理复杂问题（如云配置错误筛选）时表现出色。", "conclusion": "JAF提供了一种新的方式来优化判断代理的功能，并成功应用于实际场景中提升了AI系统的自我评估与改进能力。"}}
{"id": "2601.22264", "pdf": "https://arxiv.org/pdf/2601.22264", "abs": "https://arxiv.org/abs/2601.22264", "authors": ["Henri Aïdasso", "Francis Bordeleau", "Ali Tizghadam"], "title": "Predicting Intermittent Job Failure Categories for Diagnosis Using Few-Shot Fine-Tuned Language Models", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "In principle, Continuous Integration (CI) pipeline failures provide valuable feedback to developers on code-related errors. In practice, however, pipeline jobs often fail intermittently due to non-deterministic tests, network outages, infrastructure failures, resource exhaustion, and other reliability issues. These intermittent (flaky) job failures lead to substantial inefficiencies: wasted computational resources from repeated reruns and significant diagnosis time that distracts developers from core activities and often requires intervention from specialized teams. Prior work has proposed machine learning techniques to detect intermittent failures, but does not address the subsequent diagnosis challenge. To fill this gap, we introduce FlaXifyer, a few-shot learning approach for predicting intermittent job failure categories using pre-trained language models. FlaXifyer requires only job execution logs and achieves 84.3% Macro F1 and 92.0% Top-2 accuracy with just 12 labeled examples per category. We also propose LogSift, an interpretability technique that identifies influential log statements in under one second, reducing review effort by 74.4% while surfacing relevant failure information in 87% of cases. Evaluation on 2,458 job failures from TELUS demonstrates that FlaXifyer and LogSift enable effective automated triage, accelerate failure diagnosis, and pave the way towards the automated resolution of intermittent job failures.", "AI": {"tldr": "本文提出了FlaXifyer，一种使用少量标注样本和预训练语言模型预测CI管道间歇性故障类别的方法。", "motivation": "CI管道中的间歇性故障导致资源浪费和开发者诊断时间的增加。现有工作虽能检测这些故障但未解决后续诊断问题。为此，本文提出了FlaXifyer以加速故障诊断并减少开发者的负担。", "method": "FlaXifyer使用预训练语言模型并在少量标注样本上进行微调来预测间歇性失败类别。另外引入LogSift技术，用于快速识别关键日志条目。", "result": "在2458个CI故障实例中，FlaXifyer实现了84.3%的宏F1和92.0%的Top-2准确率；LogSift将审查工作量减少了74.4%，同时在87%的情况下揭示了相关失败信息。", "conclusion": "通过有效自动故障分类，FlaXifyer和LogSift加速了故障诊断过程，并朝着自动化解决间歇性故障的方向迈进。"}}
{"id": "2601.22256", "pdf": "https://arxiv.org/pdf/2601.22256", "abs": "https://arxiv.org/abs/2601.22256", "authors": ["Yinuo Yang", "Ashley Ge Zhang", "Steve Oney", "April Yi Wang"], "title": "SPARK: Real-Time Monitoring of Multi-Faceted Programming Exercises", "categories": ["cs.HC", "cs.SE"], "comment": null, "summary": "Monitoring in-class programming exercises can help instructors identify struggling students and common challenges. However, understanding students' progress can be prohibitively difficult, particularly for multi-faceted problems that include multiple steps with complex interdependencies, have no predictable completion order, or involve evaluation criteria that are difficult to summarize across many students (e.g., exercises building interactive web-based user interfaces). We introduce SPARK, a coding exercise monitoring dashboard designed to address these challenges. SPARK allows instructors to flexibly group substeps into checkpoints based on exercise requirements, suggests automated tests for these checkpoints, and generates visualizations to track progress across steps. SPARK also allows instructors to inspect intermediate outputs, providing deeper insights into solution variations. We also construct a dataset of 40-minute keystroke coding data from N=22 learners solving two web programming exercises and provide empirical insights into the perceived usefulness of SPARK through a within-subjects evaluation with 16 programming instructors.", "AI": {"tldr": "SPARK是一款用于实时监控编程练习的仪表板，旨在帮助教师理解学生在复杂多步骤编程任务中的进度。", "motivation": "为了帮助教师识别学习困难的学生并解决复杂的多步骤编程问题中可能出现的问题，需要一个工具来监测学生的进展。", "method": "开发了一款名为SPARK的编码练习监控仪表板，它可以根据课程需求灵活分组子步骤为检查点，并提出自动测试建议，生成可视化图表以跟踪进度，同时允许教师检查中间输出。", "result": "通过构建N=22个学习者在两个网页编程练习中的40分钟键盘输入数据集，并进行了一项包含16名编程教师的实验性评估来验证SPARK的有效性。", "conclusion": "研究表明，SPARK能够有效地帮助教师监控和理解学生在复杂多步骤编程任务中的进展。"}}
{"id": "2601.22255", "pdf": "https://arxiv.org/pdf/2601.22255", "abs": "https://arxiv.org/abs/2601.22255", "authors": ["Rainer Rehak"], "title": "AI Narrative Breakdown. A Critical Assessment of Power and Promise", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "11 pages. In: The 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25)", "summary": "This article sets off for an exploration of the still evolving discourse surrounding artificial intelligence (AI) in the wake of the release of ChatGPT. It scrutinizes the pervasive narratives that are shaping the societal engagement with AI, spotlighting key themes such as agency and decision-making, autonomy, truthfulness, knowledge processing, prediction, general purpose, neutrality and objectivity, apolitical optimization, sustainability game-changer, democratization, mass unemployment, and the dualistic portrayal of AI as either a harbinger of societal utopia or dystopia. Those narratives are analysed critically based on insights from critical computer science, critical data and algorithm studies, from STS, data protection theory, as well as from the philosophy of mind and semiotics. To properly analyse the narratives presented, the article first delves into a historical and technical contextualisation of the AI discourse itself. The article then introduces the notion of \"Zeitgeist AI\" to critique the imprecise and misleading application of the term \"AI\" across various societal sectors. Then, by discussing common narratives with nuance, the article contextualises and challenges often assumed socio-political implications of AI, uncovering in detail and with examples the inherent political, power infused and value-laden decisions within all AI applications. Concluding with a call for a more grounded engagement with AI, the article carves out acute problems ignored by the narratives discussed and proposes new narratives recognizing AI as a human-directed tool necessarily subject to societal governance.", "AI": {"tldr": "本文探讨了在ChatGPT发布后人工智能（AI）领域中形成的广泛叙事，并对其进行了批判性评估。", "motivation": "文章旨在通过审视与AI相关的社会参与中的主要主题和叙述，揭示其中的政治、权力和价值观的内在问题，促进对AI更深入的理解和合理应用。", "method": "首先通过对AI历史和技术背景的研究进行铺垫，引入“时代精神AI”的概念以批判性地评估广泛使用的“AI”术语的应用。然后通过详细讨论常见的叙事来挑战其假设的社会政治含义，并提出新的叙述框架。", "result": "揭示了所有AI应用中蕴含的政治、权力和价值观的决策。", "conclusion": "呼吁采取更基于现实的方法去理解和处理人工智能，强调AI作为人类工具必须受到社会监管的重要性。"}}
{"id": "2601.22246", "pdf": "https://arxiv.org/pdf/2601.22246", "abs": "https://arxiv.org/abs/2601.22246", "authors": ["Ya Jiang", "Massieh Kordi Boroujeny", "Surender Suresh Kumar", "Kai Zeng"], "title": "MirrorMark: A Distortion-Free Multi-Bit Watermark for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) become integral to applications such as question answering and content creation, reliable content attribution has become increasingly important. Watermarking is a promising approach, but existing methods either provide only binary signals or distort the sampling distribution, degrading text quality; distortion-free approaches, in turn, often suffer from weak detectability or robustness. We propose MirrorMark, a multi-bit and distortion-free watermark for LLMs. By mirroring sampling randomness in a measure-preserving manner, MirrorMark embeds multi-bit messages without altering the token probability distribution, preserving text quality by design. To improve robustness, we introduce a context-based scheduler that balances token assignments across message positions while remaining resilient to insertions and deletions. We further provide a theoretical analysis of the equal error rate to interpret empirical performance. Experiments show that MirrorMark matches the text quality of non-watermarked generation while achieving substantially stronger detectability: with 54 bits embedded in 300 tokens, it improves bit accuracy by 8-12% and correctly identifies up to 11% more watermarked texts at 1% false positive rate.", "AI": {"tldr": "MirrorMark是一种无失真多比特水印技术，用于大型语言模型。", "motivation": "为了在不降低文本质量的情况下进行可靠的内容归属，提出一种新的水印方法来解决现有技术的限制。", "method": "通过以度量保持方式镜像采样随机性，在不改变标记概率分布的同时嵌入多比特信息。引入基于上下文的时间调度器，平衡令牌分配并提高鲁棒性。", "result": "实验表明MirrorMark生成文本质量与未打水印的相同，并且在1%假阳性率下提高了8-12%位准确度和最多11％正确识别率。", "conclusion": "MirrorMark成功实现了无失真多比特嵌入，同时保持了高质量的文本输出以及增强了检测准确性。"}}
{"id": "2601.22244", "pdf": "https://arxiv.org/pdf/2601.22244", "abs": "https://arxiv.org/abs/2601.22244", "authors": ["Shirin Reyhanian", "Laurenz Wiskott"], "title": "Is Hierarchical Quantization Essential for Optimal Reconstruction?", "categories": ["cs.CV", "cs.LG"], "comment": "To appear in the Proceedings of ICPRAM 2026. Code available at : https://github.com/wiskott-lab/single-vs-hier-recon", "summary": "Vector-quantized variational autoencoders (VQ-VAEs) are central to models that rely on high reconstruction fidelity, from neural compression to generative pipelines. Hierarchical extensions, such as VQ-VAE2, are often credited with superior reconstruction performance because they split global and local features across multiple levels. However, since higher levels derive all their information from lower levels, they should not carry additional reconstructive content beyond what the lower-level already encodes. Combined with recent advances in training objectives and quantization mechanisms, this leads us to ask whether a single-level VQ-VAE, with matched representational budget and no codebook collapse, can equal the reconstruction fidelity of its hierarchical counterpart. Although the multi-scale structure of hierarchical models may improve perceptual quality in downstream tasks, the effect of hierarchy on reconstruction accuracy, isolated from codebook utilization and overall representational capacity, remains empirically underexamined. We revisit this question by comparing a two-level VQ-VAE and a capacity-matched single-level model on high-resolution ImageNet images. Consistent with prior observations, we confirm that inadequate codebook utilization limits single-level VQ-VAEs and that overly high-dimensional embeddings destabilize quantization and increase codebook collapse. We show that lightweight interventions such as initialization from data, periodic reset of inactive codebook vectors, and systematic tuning of codebook hyperparameters significantly reduce collapse. Our results demonstrate that when representational budgets are matched, and codebook collapse is mitigated, single-level VQ-VAEs can match the reconstruction fidelity of hierarchical variants, challenging the assumption that hierarchical quantization is inherently superior for high-quality reconstructions.", "AI": {"tldr": "研究单层VQ-VAE是否可以与多层级的VQ-VAE相媲美，尤其是在匹配表示预算的情况下。", "motivation": "挑战关于多层次量化是高质量重建中必不可少的观点，探究单层模型能否通过合适的干预措施达到同样的重建精度。", "method": "比较两个层次的VQ-VAE和容量匹配的单层次模型在高分辨率ImageNet图像上的表现。引入了轻量级干预措施如数据初始化、重置未使用码本向量以及系统性调整码本超参数以减少崩溃现象。", "result": "当表示预算一致且代码库崩溃被缓解时，单层VQ-VAE可以实现与多层次变体相匹配的重建准确性。", "conclusion": "表明在适当的干预措施下，单层次模型可达到与多层级量化相同或更优的重构效果。"}}
{"id": "2601.22242", "pdf": "https://arxiv.org/pdf/2601.22242", "abs": "https://arxiv.org/abs/2601.22242", "authors": ["Zhihao Zhang", "Keith Redmill", "Chengyang Peng", "Bowen Weng"], "title": "Aligning Microscopic Vehicle and Macroscopic Traffic Statistics: Reconstructing Driving Behavior from Partial Data", "categories": ["cs.MA", "cs.LG", "cs.RO"], "comment": null, "summary": "A driving algorithm that aligns with good human driving practices, or at the very least collaborates effectively with human drivers, is crucial for developing safe and efficient autonomous vehicles. In practice, two main approaches are commonly adopted: (i) supervised or imitation learning, which requires comprehensive naturalistic driving data capturing all states that influence a vehicle's decisions and corresponding actions, and (ii) reinforcement learning (RL), where the simulated driving environment either matches or is intentionally more challenging than real-world conditions. Both methods depend on high-quality observations of real-world driving behavior, which are often difficult and costly to obtain. State-of-the-art sensors on individual vehicles can gather microscopic data, but they lack context about the surrounding conditions. Conversely, roadside sensors can capture traffic flow and other macroscopic characteristics, but they cannot associate this information with individual vehicles on a microscopic level. Motivated by this complementarity, we propose a framework that reconstructs unobserved microscopic states from macroscopic observations, using microscopic data to anchor observed vehicle behaviors, and learns a shared policy whose behavior is microscopically consistent with the partially observed trajectories and actions and macroscopically aligned with target traffic statistics when deployed population-wide. Such constrained and regularized policies promote realistic flow patterns and safe coordination with human drivers at scale.", "AI": {"tldr": "该论文提出了一种框架，利用宏观交通统计数据重建微观车辆状态，从而学习出与部分观测轨迹和动作一致的共享策略，并在大规模部署时与目标交通统计相符合。", "motivation": "开发安全高效的自动驾驶汽车需要一种能与人类驾驶行为良好协作的驾驶算法。然而，获取高质量的真实世界驾驶数据既困难又昂贵。论文利用微观车辆传感器和宏观交通传感器的优势互补性来解决这一问题。", "method": "提出了一种框架，通过宏观数据重建微观数据，并学习一个共享策略，该策略在大规模部署时与目标交通统计相符合且行为真实合理。", "result": "构建了一个能够从宏观统计数据中推断出微观驾驶行为的模型。", "conclusion": "这种方法可以在保证安全性的前提下促进自动驾驶汽车的大规模部署。"}}
{"id": "2601.22241", "pdf": "https://arxiv.org/pdf/2601.22241", "abs": "https://arxiv.org/abs/2601.22241", "authors": ["Jelle Westra", "Iván Olarte Rodríguez", "Niki van Stein", "Thomas Bäck", "Elena Raponi"], "title": "Investigating the Interplay of Parameterization and Optimizer in Gradient-Free Topology Optimization: A Cantilever Beam Case Study", "categories": ["cs.NE", "cs.CE"], "comment": "16 pages, 6 figures, 3 tables, Paper submitted and accepted at Evostar 2026 Conference", "summary": "Gradient-free black-box optimization (BBO) is widely used in engineering design and provides a flexible framework for topology optimization (TO), enabling the discovery of high-performing structural designs without requiring gradient information from simulations. Yet, its success depends on two key choices: the geometric parameterization defining the search space and the optimizer exploring it. This study investigates this interplay through a compliance minimization problem for a cantilever beam subject to a connectivity constraint. We benchmark three geometric parameterizations, each combined with three representative BBO algorithms: differential evolution, covariance matrix adaptation evolution strategy, and heteroscedastic evolutionary Bayesian optimization, across 10D, 20D, and 50D design spaces. Results reveal that parameterization quality has a stronger influence on optimization performance than optimizer choice: a well-structured parameterization enables robust and competitive performance across algorithms, whereas weaker representations increase optimizer dependency. Overall, this study highlights the dominant role of geometric parameterization in practical BBO-based TO and shows that algorithm performance and selection cannot be fairly assessed without accounting for the induced design space.", "AI": {"tldr": "研究了参数化和优化器在梯度自由拓扑优化中的相互作用，通过悬臂梁的合规性最小化问题进行了基准测试。", "motivation": "探索几何参数化与优化器选择对基于黑盒优化的拓扑优化性能的影响，以找出最优设计空间和算法组合。", "method": "使用三种不同的几何参数化方法结合三个代表性的黑盒优化算法（差分进化、协方差矩阵自适应演化策略以及异质演化贝叶斯优化），在10维、20维和50维的设计空间中进行基准测试。", "result": "结果显示，良好的结构化参数化对优化性能的影响远大于选择不同优化器的影响。较差的表示方法则会增加算法之间的依赖性。", "conclusion": "研究强调了几何参数化在实际黑盒优化拓扑设计中的主导作用，并指出没有考虑到导致的设计空间，就不能公平地评估算法性能和选择。"}}
{"id": "2601.22240", "pdf": "https://arxiv.org/pdf/2601.22240", "abs": "https://arxiv.org/abs/2601.22240", "authors": ["Pedro H. Barcha Correia", "Ryan W. Achjian", "Diego E. G. Caetano de Oliveira", "Ygor Acacio Maria", "Victor Takashi Hayashi", "Marcos Lopes", "Charles Christian Miers", "Marcos A. Simplicio Jr"], "title": "A Systematic Literature Review on LLM Defenses Against Prompt Injection and Jailbreaking: Expanding NIST Taxonomy", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": "27 pages, 14 figures, 11 tables, submitted to Elsevier Computer Science Review", "summary": "The rapid advancement and widespread adoption of generative artificial intelligence (GenAI) and large language models (LLMs) has been accompanied by the emergence of new security vulnerabilities and challenges, such as jailbreaking and other prompt injection attacks. These maliciously crafted inputs can exploit LLMs, causing data leaks, unauthorized actions, or compromised outputs, for instance. As both offensive and defensive prompt injection techniques evolve quickly, a structured understanding of mitigation strategies becomes increasingly important. To address that, this work presents the first systematic literature review on prompt injection mitigation strategies, comprehending 88 studies. Building upon NIST's report on adversarial machine learning, this work contributes to the field through several avenues. First, it identifies studies beyond those documented in NIST's report and other academic reviews and surveys. Second, we propose an extension to NIST taxonomy by introducing additional categories of defenses. Third, by adopting NIST's established terminology and taxonomy as a foundation, we promote consistency and enable future researchers to build upon the standardized taxonomy proposed in this work. Finally, we provide a comprehensive catalog of the reviewed prompt injection defenses, documenting their reported quantitative effectiveness across specific LLMs and attack datasets, while also indicating which solutions are open-source and model-agnostic. This catalog, together with the guidelines presented herein, aims to serve as a practical resource for researchers advancing the field of adversarial machine learning and for developers seeking to implement effective defenses in production systems.", "AI": {"tldr": "该论文进行了首个关于大语言模型（LLM）抵御提示注入和越狱攻击的系统性文献综述，扩展了NIST分类法。", "motivation": "随着生成式人工智能和大语言模型的快速发展及广泛应用，出现了新的安全漏洞和挑战，如越狱和其他提示注入攻击。为了应对这些快速演变的防御策略需求，作者进行了一项系统性的文献回顾。", "method": "该研究通过梳理88篇相关论文，扩展了NIST分类法，并提出了一些新的防御类别。此外，它还提供了一个全面的防御目录，记录了各个方案在特定LLM和攻击数据集上的有效性，并指明哪些解决方案是开源且模型无关的。", "result": "该研究提供了对抗提示注入的有效策略列表，以及它们在各种攻击场景下的表现指标。", "conclusion": "这项工作通过扩展NIST分类法并提供了一个全面的防御目录，旨在为研究人员和开发人员提供一个实用资源，以促进对抗机器学习领域的发展，并帮助他们在生产系统中实施有效的防御措施。"}}
{"id": "2601.22231", "pdf": "https://arxiv.org/pdf/2601.22231", "abs": "https://arxiv.org/abs/2601.22231", "authors": ["Jian Shi", "Michael Birsak", "Wenqing Cui", "Zhenyu Li", "Peter Wonka"], "title": "Geometry without Position? When Positional Embeddings Help and Hurt Spatial Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "This paper revisits the role of positional embeddings (PEs) within vision transformers (ViTs) from a geometric perspective. We show that PEs are not mere token indices but effectively function as geometric priors that shape the spatial structure of the representation. We introduce token-level diagnostics that measure how multi-view geometric consistency in ViT representation depends on consitent PEs. Through extensive experiments on 14 foundation ViT models, we reveal how PEs influence multi-view geometry and spatial reasoning. Our findings clarify the role of PEs as a causal mechanism that governs spatial structure in ViT representations. Our code is provided in https://github.com/shijianjian/vit-geometry-probes", "AI": {"tldr": "重新审视视觉变换器中位置嵌入的角色，探讨其在多视图几何一致性中的作用", "motivation": "质疑传统观点，认为位置嵌入不仅仅是令牌索引，而是作为几何先验影响表示的结构。通过实验揭示位置嵌入对空间推理的影响", "method": "提出令牌级诊断方法来测量视觉变换器表示中多视图几何一致性的依赖性", "result": "发现位置嵌入在塑造视觉变换器表示的空间结构方面起着因果作用", "conclusion": "强调位置嵌入的重要性，为未来研究提供了新的视角"}}
{"id": "2601.22228", "pdf": "https://arxiv.org/pdf/2601.22228", "abs": "https://arxiv.org/abs/2601.22228", "authors": ["Ken Deng", "Yifu Qiu", "Yoni Kasten", "Shay B. Cohen", "Yftah Ziser"], "title": "Lost in Space? Vision-Language Models Struggle with Relative Camera Pose Estimation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Vision-Language Models (VLMs) perform well in 2D perception and semantic reasoning compared to their limited understanding of 3D spatial structure. We investigate this gap using relative camera pose estimation (RCPE), a fundamental vision task that requires inferring relative camera translation and rotation from a pair of images. We introduce VRRPI-Bench, a benchmark derived from unlabeled egocentric videos with verbalized annotations of relative camera motion, reflecting realistic scenarios with simultaneous translation and rotation around a shared object. We further propose VRRPI-Diag, a diagnostic benchmark that isolates individual motion degrees of freedom. Despite the simplicity of RCPE, most VLMs fail to generalize beyond shallow 2D heuristics, particularly for depth changes and roll transformations along the optical axis. Even state-of-the-art models such as GPT-5 ($0.64$) fall short of classic geometric baselines ($0.97$) and human performance ($0.92$). Moreover, VLMs exhibit difficulty in multi-image reasoning, with inconsistent performance (best $59.7\\%$) when integrating spatial cues across frames. Our findings reveal limitations in grounding VLMs in 3D and multi-view spatial reasoning.", "AI": {"tldr": "本文探讨了视觉语言模型在相对相机姿态估计任务中的表现，发现这些模型难以理解三维空间结构和多视角推理。", "motivation": "尽管视觉语言模型（VLMs）在二维感知和语义推理方面表现出色，但在三维空间结构的理解上存在差距。通过研究相对相机姿态估计这一基础视觉任务，该论文揭示了这种差异。", "method": "引入了一个基于未标记的第一人称视频的基准测试（VRRPI-Bench），其中包含关于相对相机运动的口头化注释。此外还提出了一个诊断基准测试（VRRPI-Diag）来隔离单个运动自由度，用于评估模型性能。", "result": "实验结果表明，大多数视觉语言模型难以超越浅层二维启发式方法，特别是在处理深度变化和沿光轴的滚动变换时。即便是最先进的模型GPT-5，在相对相机姿态估计任务上也未能达到经典几何基线和人类水平的表现。", "conclusion": "研究发现揭示了将视觉语言模型锚定于三维空间及多视角推理中的局限性，进一步推动了相关领域的探索和发展。"}}
{"id": "2601.22218", "pdf": "https://arxiv.org/pdf/2601.22218", "abs": "https://arxiv.org/abs/2601.22218", "authors": ["Jill P. Naiman", "Daniel J. Evans", "JooYoung Seo"], "title": "What Lies Beneath: A Call for Distribution-based Visual Question & Answer Datasets", "categories": ["cs.CV", "cs.DL"], "comment": "Accepted to ACM/IEEE Joint Conference on Digital Libraries JCDL 2025, 4 pages, 2 figures", "summary": "Visual Question Answering (VQA) has become an important benchmark for assessing how large multimodal models (LMMs) interpret images. However, most VQA datasets focus on real-world images or simple diagrammatic analysis, with few focused on interpreting complex scientific charts. Indeed, many VQA datasets that analyze charts do not contain the underlying data behind those charts or assume a 1-to-1 correspondence between chart marks and underlying data. In reality, charts are transformations (i.e. analysis, simplification, modification) of data. This distinction introduces a reasoning challenge in VQA that the current datasets do not capture. In this paper, we argue for a dedicated VQA benchmark for scientific charts where there is no 1-to-1 correspondence between chart marks and underlying data. To do so, we survey existing VQA datasets and highlight limitations of the current field. We then generate synthetic histogram charts based on ground truth data, and ask both humans and a large reasoning model questions where precise answers depend on access to the underlying data. We release the open-source dataset, including figures, underlying data, distribution parameters used to generate the data, and bounding boxes for all figure marks and text for future research.", "AI": {"tldr": "提出一个针对科学图表的视觉问答基准，该基准需要访问图标的底层数据才能准确回答问题。", "motivation": "当前大多数VQA数据集关注于实景图像或简单图形分析，缺乏对复杂科学图表的理解，特别是在没有1对1对应关系的情况下理解图表和其背后的数据。", "method": "调查现有的VQA数据集，生成基于真实数据的合成直方图，并提出人类和大型推理模型无法仅凭图标精确回答的问题。", "result": "发布了一个开源数据集，包括图像、底层数据、用于生成数据的分布参数以及所有图表标记和文本的边界框。", "conclusion": "倡导建立一个针对科学图表的VQA基准，以捕捉当前数据集未能涵盖的理解挑战。"}}
{"id": "2601.22209", "pdf": "https://arxiv.org/pdf/2601.22209", "abs": "https://arxiv.org/abs/2601.22209", "authors": ["Xinyuan Song", "Liang Zhao"], "title": "Learning to Recommend Multi-Agent Subgraphs from Calling Trees", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Multi-agent systems (MAS) increasingly solve complex tasks by orchestrating agents and tools selected from rapidly growing marketplaces. As these marketplaces expand, many candidates become functionally overlapping, making selection not just a retrieval problem: beyond filtering relevant agents, an orchestrator must choose options that are reliable, compatible with the current execution context, and able to cooperate with other selected agents. Existing recommender systems -- largely built for item-level ranking from flat user-item logs -- do not directly address the structured, sequential, and interaction-dependent nature of agent orchestration. We address this gap by \\textbf{formulating agent recommendation in MAS as a constrained decision problem} and introducing a generic \\textbf{constrained recommendation framework} that first uses retrieval to build a compact candidate set conditioned on the current subtask and context, and then performs \\textbf{utility optimization} within this feasible set using a learned scorer that accounts for relevance, reliability, and interaction effects. We ground both the formulation and learning signals in \\textbf{historical calling trees}, which capture the execution structure of MAS (parent-child calls, branching dependencies, and local cooperation patterns) beyond what flat logs provide. The framework supports two complementary settings: \\textbf{agent-level recommendation} (select the next agent/tool) and \\textbf{system-level recommendation} (select a small, connected agent team/subgraph for coordinated execution). To enable systematic evaluation, we construct a unified calling-tree benchmark by normalizing invocation logs from eight heterogeneous multi-agent corpora into a shared structured representation.", "AI": {"tldr": "本文提出了一种基于调用树的历史数据来推荐多智能体系统中的合适代理或团队的方法。", "motivation": "现有的推荐系统无法直接处理多智能体系统的结构化、序列性和交互依赖性，因此需要一种新的框架来解决这些问题。", "method": "通过构建一个约束推荐框架，并利用历史调用树数据进行学习，该框架首先使用检索方法从当前子任务和上下文中建立候选集，然后在此可行集中执行效用优化。", "result": "本文的方法支持代理级别的建议（选择下一个代理/工具）以及系统级别的建议（选择一个小的、互联的代理团队），并通过八个异构多智能体语料库构建了一个统一的调用树基准进行评估。", "conclusion": "该论文提出了一种基于调用树的历史数据来推荐多智能体系统的有效方法，可以解决现有推荐系统无法处理的问题。"}}
{"id": "2601.22203", "pdf": "https://arxiv.org/pdf/2601.22203", "abs": "https://arxiv.org/abs/2601.22203", "authors": ["Huinan Xu", "Xuyang Feng", "Junhong Chen", "Junchen Liu", "Kaiwen Deng", "Kai Ding", "Shengning Long", "Jiaxue Shuai", "Zhaorong Li", "Shiping Liu", "Guirong Xue", "Zhan Xiao"], "title": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram", "categories": ["q-bio.GN", "cs.AI"], "comment": null, "summary": "Current genomic foundation models (GFMs) rely on extensive neural computation to implicitly approximate conserved biological motifs from single-nucleotide inputs. We propose Gengram, a conditional memory module that introduces an explicit and highly efficient lookup primitive for multi-base motifs via a genomic-specific hashing scheme, establishing genomic \"syntax\". Integrated into the backbone of state-of-the-art GFMs, Gengram achieves substantial gains (up to 14%) across several functional genomics tasks. The module demonstrates robust architectural generalization, while further inspection of Gengram's latent space reveals the emergence of meaningful representations that align closely with fundamental biological knowledge. By establishing structured motif memory as a modeling primitive, Gengram simultaneously boosts empirical performance and mechanistic interpretability, providing a scalable and biology-aligned pathway for the next generation of GFMs. The code is available at https://github.com/zhejianglab/Genos, and the model checkpoint is available at https://huggingface.co/ZhejiangLab/Gengram.", "AI": {"tldr": "提出Gengram模块，通过特定的哈希方案提高基因组基础模型在多碱基模体检索上的效率和性能。", "motivation": "当前基因组基础模型依赖大量神经计算来隐式逼近生物保守模式，缺乏高效能、可解释性的机制。因此需要引入一种明确且高效的检索方法以提升其表现。", "method": "Gengram模块通过特定哈希方案实现多碱基模体的快速检索，并将其集成到最先进的基因组基础模型中。", "result": "实验结果表明，加入Gengram后，模型在多个功能基因组任务上取得了显著提升（最高达14%）。同时，在隐含空间中发现了与基本生物学知识相符的有意义表示。", "conclusion": "通过引入结构化模体记忆作为建模原语，Gengram不仅增强了模型的表现力，还提高了可解释性，为下一代基因组基础模型提供了一条具有扩展性和生物相容性的路径。"}}
{"id": "2601.22202", "pdf": "https://arxiv.org/pdf/2601.22202", "abs": "https://arxiv.org/abs/2601.22202", "authors": ["Runze Cheng", "Yao Sun", "Ahmad Taha", "Xuesong Liu", "David Flynn", "Muhammad Ali Imran"], "title": "A Survey on Semantic Communication for Vision: Categories, Frameworks, Enabling Techniques, and Applications", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Semantic communication (SemCom) emerges as a transformative paradigm for traffic-intensive visual data transmission, shifting focus from raw data to meaningful content transmission and relieving the increasing pressure on communication resources. However, to achieve SemCom, challenges are faced in accurate semantic quantization for visual data, robust semantic extraction and reconstruction under diverse tasks and goals, transceiver coordination with effective knowledge utilization, and adaptation to unpredictable wireless communication environments. In this paper, we present a systematic review of SemCom for visual data transmission (SemCom-Vision), wherein an interdisciplinary analysis integrating computer vision (CV) and communication engineering is conducted to provide comprehensive guidelines for the machine learning (ML)-empowered SemCom-Vision design. Specifically, this survey first elucidates the basics and key concepts of SemCom. Then, we introduce a novel classification perspective to categorize existing SemCom-Vision approaches as semantic preservation communication (SPC), semantic expansion communication (SEC), and semantic refinement communication (SRC) based on communication goals interpreted through semantic quantization schemes. Moreover, this survey articulates the ML-based encoder-decoder models and training algorithms for each SemCom-Vision category, followed by knowledge structure and utilization strategies. Finally, we discuss potential SemCom-Vision applications.", "AI": {"tldr": "本文系统地回顾了用于视觉数据传输的语义通信（SemCom-Vision），通过计算机视觉和通信工程的跨学科分析，提供了机器学习支持下的SemCom-Vision设计指南。", "motivation": "随着视觉数据流量的增长，传统通信方式面临压力增大，为了实现更高效的传输，提出了从原始数据传输转向有意义内容传输的语义通信（SemCom）方案，并对其面临的挑战进行了探讨和解决策略的提出。", "method": "本文首先解释了SemCom的基本概念和关键思想；接着根据不同的通信目标通过语义量化方案将现有的SemCom-Vision方法分为三类：语义保持通信（SPC）、语义扩展通信（SEC）以及语义优化通信（SRC）。最后，讨论了潜在的应用。", "result": "本文为机器学习支持下的SemCom-Vision设计提供了一个全面的指南，并指出了未来可能的应用场景。", "conclusion": "通过计算机视觉和通信工程的结合分析，明确了实现高效视觉数据传输所需的技术路径及方法论框架。"}}
{"id": "2601.22199", "pdf": "https://arxiv.org/pdf/2601.22199", "abs": "https://arxiv.org/abs/2601.22199", "authors": ["Syed T. Mubarrat", "Byung-Cheol Min", "Tianyu Shao", "E. Cho Smith", "Bedrich Benes", "Alejandra J. Magana", "Christos Mousas", "Dominic Kao"], "title": "Game-Based and Gamified Robotics Education: A Comparative Systematic Review and Design Guidelines", "categories": ["cs.RO", "cs.HC"], "comment": "Accepted for publication at Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems. 26 pages, 14 figures, 7 tables;", "summary": "Robotics education fosters computational thinking, creativity, and problem-solving, but remains challenging due to technical complexity. Game-based learning (GBL) and gamification offer engagement benefits, yet their comparative impact remains unclear. We present the first PRISMA-aligned systematic review and comparative synthesis of GBL and gamification in robotics education, analyzing 95 studies from 12,485 records across four databases (2014-2025). We coded each study's approach, learning context, skill level, modality, pedagogy, and outcomes (k = .918). Three patterns emerged: (1) approach-context-pedagogy coupling (GBL more prevalent in informal settings, while gamification dominated formal classrooms [p < .001] and favored project-based learning [p = .009]); (2) emphasis on introductory programming and modular kits, with limited adoption of advanced software (~17%), advanced hardware (~5%), or immersive technologies (~22%); and (3) short study horizons, relying on self-report. We propose eight research directions and a design space outlining best practices and pitfalls, offering actionable guidance for robotics education.", "AI": {"tldr": "该论文进行了基于游戏和游戏化的机器人教育的系统性比较综述，并提出了设计指南。", "motivation": "机器人教育有助于培养计算思维、创造力和解决问题的能力，但因技术复杂性而具有挑战。基于游戏的学习和游戏化能提高参与度，但其相对影响尚不明确。", "method": "作者使用PRISMA方法对来自四个数据库（2014-2025年）的95项研究进行了系统综述，编码了每项研究的方法、学习环境、技能水平、模式、教学法和结果，并提出了八个研究方向与设计空间。", "result": "该论文发现基于游戏的学习在非正式环境中更为常见，而游戏化则主导着正式课堂，并倾向于项目式学习。此外，强调基础编程和模块化套件的使用，但高级软件、硬件或沉浸技术的采用率较低，且研究周期短，依赖于自我报告。", "conclusion": "论文提出了基于游戏的学习和游戏化的教育设计空间与最佳实践指南，为机器人教育提供了可操作的建议。"}}
{"id": "2601.22198", "pdf": "https://arxiv.org/pdf/2601.22198", "abs": "https://arxiv.org/abs/2601.22198", "authors": ["Judith Vilella-Cantos", "Mónica Ballesta", "David Valiente", "María Flores", "Luis Payá"], "title": "Advanced techniques and applications of LiDAR Place Recognition in Agricultural Environments: A Comprehensive Survey", "categories": ["cs.RO", "cs.AI", "cs.ET"], "comment": null, "summary": "An optimal solution to the localization problem is essential for developing autonomous robotic systems. Apart from autonomous vehicles, precision agriculture is one of the elds that can bene t most from these systems. Although LiDAR place recognition is a widely used technique in recent years to achieve accurate localization, it is mostly used in urban settings. However, the lack of distinctive features and the unstructured nature of agricultural environments make place recognition challenging. This work presents a comprehensive review of state-of-the-art the latest deep learning applications for agricultural environments and LPR techniques. We focus on the challenges that arise in these environments. We analyze the existing approaches, datasets, and metrics used to evaluate LPR system performance and discuss the limitations and future directions of research in this eld. This is the rst survey that focuses on LiDAR based localization in agricultural settings, with the aim of providing a thorough understanding and fostering further research in this specialized domain.", "AI": {"tldr": "对农业环境中基于LiDAR的地方识别技术进行全面综述", "motivation": "提高自主机器人系统在农业环境中的定位准确性，解决其特有的挑战。", "method": "分析现有的地方识别方法、数据集和评估指标，并探讨未来研究方向。", "result": "总结了现有农业环境中基于LiDAR的地方识别技术及其局限性。", "conclusion": "提供了农业环境中基于LiDAR的定位问题的深入理解，促进进一步的研究。"}}
{"id": "2601.22197", "pdf": "https://arxiv.org/pdf/2601.22197", "abs": "https://arxiv.org/abs/2601.22197", "authors": ["Jathurshan Pradeepkumar", "Zheng Chen", "Jimeng Sun"], "title": "Neural Signals Generate Clinical Notes in the Wild", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Generating clinical reports that summarize abnormal patterns, diagnostic findings, and clinical interpretations from long-term EEG recordings remains labor-intensive. We curate a large-scale clinical EEG dataset with $9{,}922$ reports paired with approximately $11{,}000$ hours of EEG recordings from $9{,}048$ patients. We therefore develop CELM, the first clinical EEG-to-Language foundation model capable of summarizing long-duration, variable-length EEG recordings and performing end-to-end clinical report generation at multiple scales, including recording description, background activity, epileptiform abnormalities, events/seizures, and impressions. Experimental results show that, with patient history supervision, our method achieves $70\\%$--$95\\%$ average relative improvements in standard generation metrics (e.g., ROUGE-1 and METEOR) from $0.2$--$0.3$ to $0.4$--$0.6$. In the zero-shot setting without patient history, CELM attains generation scores in the range of $0.43$--$0.52$, compared to baselines of $0.17$--$0.26$. CELM integrates pretrained EEG foundation models with language models to enable scalable multimodal learning. We release our model and benchmark construction pipeline at [URL].", "AI": {"tldr": "生成从长时间EEG记录中的异常模式、诊断发现和临床解释的临床报告。", "motivation": "现有的方法依赖于手工总结，劳动强度大且效率低。需要一个自动化的系统来减轻医生负担并提高准确性。", "method": "开发了CELM模型，使用预训练的EEG基础模型和语言模型生成多模态学习的临床报告。", "result": "在有患者历史监督的情况下，标准生成指标提高了70%到95%，而在无患者历史情况下得分仍然较高。", "conclusion": "通过整合预训练的EEG基础模型与语言模型，实现了自动化的临床报告生成，具有潜在的实用价值。"}}
{"id": "2601.22195", "pdf": "https://arxiv.org/pdf/2601.22195", "abs": "https://arxiv.org/abs/2601.22195", "authors": ["Fan Fan", "Yilei Shi", "Tobias Guggemos", "Xiao Xiang Zhu"], "title": "Multitask Learning for Earth Observation Data Classification with Hybrid Quantum Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Quantum machine learning (QML) has gained increasing attention as a potential solution to address the challenges of computation requirements in the future. Earth observation (EO) has entered the era of Big Data, and the computational demands for effectively analyzing large EO data with complex deep learning models have become a bottleneck. Motivated by this, we aim to leverage quantum computing for EO data classification and explore its advantages despite the current limitations of quantum devices. This paper presents a hybrid model that incorporates multitask learning to assist efficient data encoding and employs a location weight module with quantum convolution operations to extract valid features for classification. The validity of our proposed model was evaluated using multiple EO benchmarks. Additionally, we experimentally explored the generalizability of our model and investigated the factors contributing to its advantage, highlighting the potential of QML in EO data analysis.", "AI": {"tldr": "本文提出了一种结合多任务学习的混合量子网络模型，用于地球观测数据分类。", "motivation": "鉴于地球观测大数据分析中的计算需求瓶颈，以及当前量子设备的限制，研究旨在探索量子计算在地球观测数据分类中的应用潜力。", "method": "该模型通过引入多任务学习实现高效的数据编码，并采用位置权重模块与量子卷积操作以提取有效特征进行分类。", "result": "所提出的模型在多个地球观测基准上进行了有效性验证，展示了其在处理大规模EO数据方面的优势。", "conclusion": "研究结果表明，量子机器学习在地球观测数据分析中具有潜在的应用价值。"}}
{"id": "2601.22194", "pdf": "https://arxiv.org/pdf/2601.22194", "abs": "https://arxiv.org/abs/2601.22194", "authors": ["Vikas Agnihotri", "Jasleen Kaur", "Sarvagya Kaushik"], "title": "Practical Evaluation of Quantum Kernel Methods for Radar Micro-Doppler Classification on Noisy Intermediate-Scale Quantum (NISQ) Hardware", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "This paper examines the application of a Quantum Support Vector Machine (QSVM) for radarbased aerial target classification using micro-Doppler signatures. Classical features are extracted and reduced via Principal Component Analysis (PCA) to enable efficient quantum encoding. The reduced feature vectors are embedded into a quantum kernel-induced feature space using a fully entangled ZZFeatureMap and classified using a kernel based QSVM. Performance is first evaluated on a quantum simulator and subsequently validated on NISQ-era superconducting quantum hardware, specifically the IBM Torino (133-qubit) and IBM Fez (156-qubit) processors. Experimental results demonstrate that the QSVM achieves competitive classification performance relative to classical SVM baselines while operating on substantially reduced feature dimensionality. Hardware experiments reveal the impact of noise and decoherence and measurement shot count on quantum kernel estimation, and further show improved stability and fidelity on newer Heron r2 architecture. This study provides a systematic comparison between simulator-based and hardware-based QSVM implementations and highlights both the feasibility and current limitations of deploying quantum kernel methods for practical radar signal classification tasks.", "AI": {"tldr": "研究利用量子支持向量机（QSVM）对雷达微多普勒信号进行目标分类", "motivation": "通过在NISQ硬件上实现量子核方法，提高雷达目标分类的效率和准确性", "method": "采用主成分分析减少特征维度后，使用全纠缠ZZFeatureMap将特征向量嵌入量子核诱导的空间，并用QSVM进行分类。首先在模拟器中评估性能，然后在IBM Torino和Fez处理器上验证结果。", "result": "实验结果显示，与经典SVM相比，QSVM在减少的特征维度下仍能实现竞争性的分类性能，同时揭示了噪声和退相干对量子核估计的影响", "conclusion": "研究证明了在实际雷达信号分类任务中部署量子核方法的可能性及其当前限制"}}
{"id": "2601.22189", "pdf": "https://arxiv.org/pdf/2601.22189", "abs": "https://arxiv.org/abs/2601.22189", "authors": ["Han-Yu Lin", "Li-Wei Chen", "Hung-Shin Lee"], "title": "SCENE: Semantic-aware Codec Enhancement with Neural Embeddings", "categories": ["eess.IV", "cs.CV", "cs.LG", "cs.MM"], "comment": "Accepted to ICASSP 2026", "summary": "Compression artifacts from standard video codecs often degrade perceptual quality. We propose a lightweight, semantic-aware pre-processing framework that enhances perceptual fidelity by selectively addressing these distortions. Our method integrates semantic embeddings from a vision-language model into an efficient convolutional architecture, prioritizing the preservation of perceptually significant structures. The model is trained end-to-end with a differentiable codec proxy, enabling it to mitigate artifacts from various standard codecs without modifying the existing video pipeline. During inference, the codec proxy is discarded, and SCENE operates as a standalone pre-processor, enabling real-time performance. Experiments on high-resolution benchmarks show improved performance over baselines in both objective (MS-SSIM) and perceptual (VMAF) metrics, with notable gains in preserving detailed textures within salient regions. Our results show that semantic-guided, codec-aware pre-processing is an effective approach for enhancing compressed video streams.", "AI": {"tldr": "提出了一种轻量级的语义感知预处理框架SCENE，通过神经嵌入技术增强视频压缩质量。", "motivation": "传统视频编码器产生的压缩伪影会降低视频的感知质量。作者希望通过一种新的方法减轻这些伪影，提高视觉质量和用户体验。", "method": "该方法使用视觉语言模型生成的语义嵌入，并结合高效的卷积架构，在不修改现有视频处理流水线的情况下，通过端到端可微分编码器代理训练模型，以减少各种标准编码器产生的伪影。在推理过程中丢弃编码器代理，使得SCENE能够作为独立预处理器实现实时性能。", "result": "实验表明，在高分辨率基准测试上，与基线方法相比，该框架在客观（MS-SSIM）和感知（VMAF）指标上均取得了更好的效果，并且特别有助于保留显著区域内的细节纹理。", "conclusion": "研究证明了语义引导、编码器感知的预处理是提升压缩视频流质量的有效途径。"}}
{"id": "2601.22183", "pdf": "https://arxiv.org/pdf/2601.22183", "abs": "https://arxiv.org/abs/2601.22183", "authors": ["Tenindra Abeywickrama", "Muhammad Aamir Cheema", "Sabine Storandt"], "title": "COL-Trees: Efficient Hierarchical Object Search in Road Networks", "categories": ["cs.DB", "cs.AI", "cs.DS"], "comment": "Submitted to Artificial Intelligence (AIJ)", "summary": "Location-based services rely heavily on efficient methods that search for relevant points-of-interest (POIs) near a given location. A k Nearest Neighbor (kNN) query is one such example that finds the k closest POIs from an agent's location. While most existing techniques focus on retrieving nearby POIs for a single agent, these search heuristics do not translate to many other applications. For example, Aggregate k Nearest Neighbor (AkNN) queries require POIs that are close to multiple agents. k Farthest Neighbor (kFN) queries require POIs that are the antithesis of nearest. Such problems naturally benefit from a hierarchical approach, but existing methods rely on Euclidean-based heuristics, which have diminished effectiveness in graphs such as road networks. We propose a novel data structure, COL-Tree (Compacted Object-Landmark Tree), to address this gap by enabling efficient hierarchical graph traversal using a more accurate landmark-based heuristic. We then present query algorithms that utilize COL-Trees to efficiently answer AkNN, kFN, and other queries. In our experiments on real-world and synthetic datasets, we demonstrate that our techniques significantly outperform existing approaches, achieving up to 4 orders of magnitude improvement. Moreover, this comes at a small pre-processing overhead in both theory and practice.", "AI": {"tldr": "提出了一种新的数据结构COL-Trees，用于在道路网络中高效地进行层次化对象搜索。", "motivation": "现有的技术主要针对单一用户附近的POI检索，而许多其他应用（如Aggregate k Nearest Neighbor和k Farthest Neighbor查询）需要更复杂的查询方法。这些查询问题自然适合层次化的解决方法，但基于欧几里得的启发式方法在图结构中效果不佳。", "method": "提出了一种名为COL-Trees的新数据结构，以支持道路网络中的高效层次化搜索。利用该数据结构开发了AkNN、kFN等查询算法。", "result": "实验结果表明，在真实世界和合成数据集上，所提方法显著优于现有技术，性能提高了多达4个数量级，并且预处理开销较小。", "conclusion": "通过使用COL-Trees实现高效的层次化道路网络搜索，解决了传统欧几里得启发式方法在复杂查询中的不足。"}}
{"id": "2601.22182", "pdf": "https://arxiv.org/pdf/2601.22182", "abs": "https://arxiv.org/abs/2601.22182", "authors": ["Yizhong Ding"], "title": "ShellForge: Adversarial Co-Evolution of Webshell Generation and Multi-View Detection for Robust Webshell Defense", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Webshells remain a primary foothold for attackers to compromise servers, particularly within PHP ecosystems. However, existing detection mechanisms often struggle to keep pace with rapid variant evolution and sophisticated obfuscation techniques that camouflage malicious intent. Furthermore, many current defenses suffer from high false-alarm rates when encountering benign administrative scripts that employ heavy obfuscation for intellectual property protection. To address these challenges, we present ShellForge, an adversarial co-evolution framework that couples automated webshell generation with multi-view detection to continuously harden defensive boundaries. The framework operates through an iterative co-training loop where a generator and a detector mutually reinforce each other via the exchange of hard samples. The generator is optimized through supervised fine-tuning and preference-based reinforcement learning to synthesize functional, highly evasive variants. Simultaneously, we develop a multi-view fusion detector that integrates semantic features from long-string compression, structural features from pruned abstract syntax trees, and global statistical indicators such as Shannon entropy. To minimize false positives, ShellForge utilizes a LLM-based transformation to create de-malicious samples--scripts that retain complex obfuscation patterns but lack harmful payloads--serving as high-quality hard negatives during training. Evaluations on the public FWOID benchmark demonstrate that ShellForge significantly enhances defensive robustness. Upon convergence, the detector maintains a 0.981 F1-score while the generator achieves a 0.939 evasion rate against commercial engines on VirusTotal.", "AI": {"tldr": "提出了一种名为ShellForge的对抗共进化框架，用于生成和检测Webshell以提高防御能力。", "motivation": "现有的Webshell检测机制难以应对快速变化的恶意代码变体和复杂的混淆技术，并且在面对合法但高度混淆的管理脚本时产生大量误报。为了应对这些问题，作者提出了ShellForge框架。", "method": "通过自动化的生成器和多视角融合检测器进行迭代共训练。生成器使用监督微调和基于偏好的强化学习来合成功能性和高逃避性的变体；检测器结合长字符串压缩、结构化抽象语法树特征以及全局统计指标如Shannon熵，以提高准确性。", "result": "在FWOID基准上评估显示，ShellForge显著提升了防御能力。收敛时，检测器保持了0.981的F1得分，而生成器对VirusTotal上的商用引擎实现了0.939的逃避率。", "conclusion": "ShellForge框架通过共进化机制提高了Webshell检测的准确性和有效性，减少了误报，并能够应对恶意代码的快速变化和混淆技术。"}}
{"id": "2601.22176", "pdf": "https://arxiv.org/pdf/2601.22176", "abs": "https://arxiv.org/abs/2601.22176", "authors": ["Isabel Tardón", "Pablo Martín-Santamaría"], "title": "Proliferating series by Jean Barraqué: a study and classification in mathematical terms", "categories": ["math.HO", "cs.SD", "eess.AS"], "comment": "28 pages, 8 figures", "summary": "Barraqué's proliferating series give an interesting turn on the concept of classic serialism by creating a new invariant when it comes to constructing the series: rather than the intervals between consecutive notes, what remains unaltered during the construction of the proliferations of the given base series is the permutation of the notes which happens between two consecutive series, that is to say, the transformation of the order of the notes in the series. This presents new possibilities for composers interested in the serial method, given the fact that the variety of intervals obtained by this method is far greater than that of classic serialism. In this manuscript, we will study some unexplored possibilities that the proliferating series offer from a mathematical point of view, which will allow composers to gain much more familiarity with them and potentially result in the creation of pieces that take serialism to the next level.", "AI": {"tldr": "研究Jean Barraqué的增殖序列，并从数学角度探讨其潜在的可能性", "motivation": "通过对经典序列主义概念的创新，提供给作曲家更多创作可能性和更丰富的音程变化", "method": "采用数学方法分析Barraqué的增殖系列中的不变性及其在不同系列间的音符排列变换", "result": "发现了新的未被探索过的音乐结构，并为理解其潜在创作潜力提供了新视角", "conclusion": "这种创新的方法使序列主义达到更高层次，能激发作曲家创作出更复杂丰富的作品"}}
{"id": "2601.22169", "pdf": "https://arxiv.org/pdf/2601.22169", "abs": "https://arxiv.org/abs/2601.22169", "authors": ["Anudeex Shetty", "Aditya Joshi", "Salil S. Kanhere"], "title": "In Vino Veritas and Vulnerabilities: Examining LLM Safety via Drunk Language Inducement", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "comment": "WIP", "summary": "Humans are susceptible to undesirable behaviours and privacy leaks under the influence of alcohol. This paper investigates drunk language, i.e., text written under the influence of alcohol, as a driver for safety failures in large language models (LLMs). We investigate three mechanisms for inducing drunk language in LLMs: persona-based prompting, causal fine-tuning, and reinforcement-based post-training. When evaluated on 5 LLMs, we observe a higher susceptibility to jailbreaking on JailbreakBench (even in the presence of defences) and privacy leaks on ConfAIde, where both benchmarks are in English, as compared to the base LLMs as well as previously reported approaches. Via a robust combination of manual evaluation and LLM-based evaluators and analysis of error categories, our findings highlight a correspondence between human-intoxicated behaviour, and anthropomorphism in LLMs induced with drunk language. The simplicity and efficiency of our drunk language inducement approaches position them as potential counters for LLM safety tuning, highlighting significant risks to LLM safety.", "AI": {"tldr": "研究通过诱导大型语言模型（LLM）产生醉酒语言来评估其安全漏洞和隐私泄露风险。", "motivation": "人类在酒精影响下会表现出不适当行为并泄露个人信息，作者探索了类似情况下LLM的安全性问题及其潜在的风险。", "method": "使用人格提示、因果微调及基于强化的后训练三种方法诱导LLM产生醉酒语言，并通过JailbreakBench和ConfAIde评估其安全性与隐私风险。", "result": "实验发现，当LLM被诱导生成醉酒语言时，在JailbreakBench测试中更容易遭到破解，在ConfAIde测试中的隐私泄露情况也比原始模型更严重。", "conclusion": "研究结果表明人类醉酒行为与通过特定方法诱导的LLM行为之间存在对应关系，并强调了LLM安全调整的重要性和潜在风险。"}}
{"id": "2601.22168", "pdf": "https://arxiv.org/pdf/2601.22168", "abs": "https://arxiv.org/abs/2601.22168", "authors": ["Shengwei You", "Aditya Joshi", "Andrey Kuehlkamp", "Jarek Nabrzyski"], "title": "Stablecoin Design with Adversarial-Robust Multi-Agent Systems via Trust-Weighted Signal Aggregation", "categories": ["q-fin.RM", "cs.AI", "cs.CR", "q-fin.CP"], "comment": null, "summary": "Algorithmic stablecoins promise decentralized monetary stability by maintaining a target peg through programmatic reserve management. Yet, their reserve controllers remain vulnerable to regime-blind optimization, calibrating risk parameters on fair-weather data while ignoring tail events that precipitate cascading failures. The March 2020 Black Thursday collapse, wherein MakerDAO's collateral auctions yielded $8.3M in losses and a 15% peg deviation, exposed a critical gap: existing models like SAS systematically omit extreme volatility regimes from covariance estimates, producing allocations optimal in expectation but catastrophic under adversarial stress. We present MVF-Composer, a trust-weighted Mean-Variance Frontier reserve controller incorporating a novel Stress Harness for risk-state estimation. Our key insight is deploying multi-agent simulations as adversarial stress-testers: heterogeneous agents (traders, liquidity providers, attackers) execute protocol actions under crisis scenarios, exposing reserve vulnerabilities before they manifest on-chain. We formalize a trust-scoring mechanism T: A -> [0,1] that down-weights signals from agents exhibiting manipulative behavior, ensuring the risk-state estimator remains robust to signal injection and Sybil attacks. Across 1,200 randomized scenarios with injected Black-Swan shocks (10% collateral drawdown, 50% sentiment collapse, coordinated redemption attacks), MVF-Composer reduces peak peg deviation by 57% and mean recovery time by 3.1x relative to SAS baselines. Ablation studies confirm the trust layer accounts for 23% of stability gains under adversarial conditions, achieving 72% adversarial agent detection. Our system runs on commodity hardware, requires no on-chain oracles beyond standard price feeds, and provides a reproducible framework for stress-testing DeFi reserve policies.", "AI": {"tldr": "本文提出了MVF-Composer，一种结合信任加权信号聚合的算法稳定币储备管理器，以提高在极端市场条件下的稳定性。", "motivation": "现有的算法稳定币模型未能充分考虑尾部事件风险，导致在危机时刻出现重大失败。该研究旨在开发一个更稳健的系统来应对这些挑战。", "method": "MVF-Composer使用多代理模拟进行对抗性压力测试，通过信任加权机制来评估不同行为下的信号质量，并据此调整储备策略以提高稳定性。", "result": "在1200个随机场景中，包括各种黑天鹅事件的情况下，与基准模型相比，MVF-Composer将峰值偏离减少了57%，平均恢复时间缩短了3.1倍。此外，信任层贡献了23%的稳定收益，在对抗性条件下的对手方检测率为72%。", "conclusion": "该研究证明了通过多代理系统和信任加权信号聚合可以提高算法稳定币在极端市场条件下的稳定性，并提供了一个可扩展且无须额外预言机支持的框架。"}}
{"id": "2601.22164", "pdf": "https://arxiv.org/pdf/2601.22164", "abs": "https://arxiv.org/abs/2601.22164", "authors": ["Christos Tsourveloudis"], "title": "Do Open-Vocabulary Detectors Transfer to Aerial Imagery? A Comparative Evaluation", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Open-vocabulary object detection (OVD) enables zero-shot recognition of novel categories through vision-language models, achieving strong performance on natural images. However, transferability to aerial imagery remains unexplored. We present the first systematic benchmark evaluating five state-of-the-art OVD models on the LAE-80C aerial dataset (3,592 images, 80 categories) under strict zero-shot conditions. Our experimental protocol isolates semantic confusion from visual localization through Global, Oracle, and Single-Category inference modes. Results reveal severe domain transfer failure: the best model (OWLv2) achieves only 27.6% F1-score with 69% false positive rate. Critically, reducing vocabulary size from 80 to 3.2 classes yields 15x improvement, demonstrating that semantic confusion is the primary bottleneck. Prompt engineering strategies such as domain-specific prefixing and synonym expansion, fail to provide meaningful performance gains. Performance varies dramatically across datasets (F1: 0.53 on DIOR, 0.12 on FAIR1M), exposing brittleness to imaging conditions. These findings establish baseline expectations and highlight the need for domain-adaptive approaches in aerial OVD.", "AI": {"tldr": "研究评估了五种最先进的开放词汇对象检测模型在LAER80C航空图像数据集上的性能，揭示了这些模型在航空图像中转移失败的问题。", "motivation": "探索零样本识别技术是否适用于航空影像，并发现其主要瓶颈在于语义混淆问题。", "method": "采用严格的零样本条件进行评估，通过全局、Oracle和单一类别推断模式来分离语义混淆与视觉定位误差。还测试了不同数据集上的性能表现以及词汇量大小对模型的影响。", "result": "最佳模型OWLv2在LAER80C数据集中仅实现27.6%的F1分数，且误报率为69%，减少词汇量至3.2个类别后性能显著提升。此外，通过领域特定前缀和同义词扩展等策略未见明显改善。", "conclusion": "研究揭示了开放词汇对象检测模型在航空图像中的固有脆弱性，并建议未来的研究应致力于开发适应性更强的域适配方法来解决这一问题。"}}
{"id": "2601.22162", "pdf": "https://arxiv.org/pdf/2601.22162", "abs": "https://arxiv.org/abs/2601.22162", "authors": ["Zhi Yang", "Lingfeng Zeng", "Fangqi Lou", "Qi Qi", "Wei Zhang", "Zhenyu Wu", "Zhenxiong Yu", "Jun Han", "Zhiheng Jin", "Lejie Zhang", "Xiaoming Huang", "Xiaolong Liang", "Zheng Wei", "Junbo Zou", "Dongpo Cheng", "Zhaowei Liu", "Xin Guo", "Rongjunchen Zhang", "Liwen Zhang"], "title": "UniFinEval: Towards Unified Evaluation of Financial Multimodal Models across Text, Images and Videos", "categories": ["q-fin.GN", "cs.AI", "cs.CL"], "comment": null, "summary": "Multimodal large language models are playing an increasingly significant role in empowering the financial domain, however, the challenges they face, such as multimodal and high-density information and cross-modal multi-hop reasoning, go beyond the evaluation scope of existing multimodal benchmarks. To address this gap, we propose UniFinEval, the first unified multimodal benchmark designed for high-information-density financial environments, covering text, images, and videos. UniFinEval systematically constructs five core financial scenarios grounded in real-world financial systems: Financial Statement Auditing, Company Fundamental Reasoning, Industry Trend Insights, Financial Risk Sensing, and Asset Allocation Analysis. We manually construct a high-quality dataset consisting of 3,767 question-answer pairs in both chinese and english and systematically evaluate 10 mainstream MLLMs under Zero-Shot and CoT settings. Results show that Gemini-3-pro-preview achieves the best overall performance, yet still exhibits a substantial gap compared to financial experts. Further error analysis reveals systematic deficiencies in current models. UniFinEval aims to provide a systematic assessment of MLLMs' capabilities in fine-grained, high-information-density financial environments, thereby enhancing the robustness of MLLMs applications in real-world financial scenarios. Data and code are available at https://github.com/aifinlab/UniFinEval.", "AI": {"tldr": "UniFinEval提出了一个统一的多模态基准，用于评估金融场景中大型语言模型的能力。", "motivation": "现有多模态基准无法全面覆盖金融领域中的高信息密度和跨模式推理挑战，因此提出UniFinEval来填补这一空白。", "method": "系统构建了五个核心的金融场景，并手动构造了一个包含3767个问题答案配对的数据集，评估了10种主流多模态大型语言模型在零样本和CoT设置下的表现。", "result": "Gemini-3-pro-preview在所有任务中表现出最佳的整体性能，但与专家相比仍有显著差距。进一步的错误分析揭示了当前模型存在的系统性缺陷。", "conclusion": "UniFinEval提供了对多模态大型语言模型在细粒度、高信息密度金融环境中的能力进行系统评估的方法，并有助于提高这些模型在现实世界金融场景中的鲁棒性。"}}
{"id": "2601.22161", "pdf": "https://arxiv.org/pdf/2601.22161", "abs": "https://arxiv.org/abs/2601.22161", "authors": ["Anmol Guragain"], "title": "Attention Isn't All You Need for Emotion Recognition:Domain Features Outperform Transformers on the EAV Dataset", "categories": ["cs.LG", "cs.CV", "cs.SD", "eess.AS"], "comment": null, "summary": "We present a systematic study of multimodal emotion recognition using the EAV dataset, investigating whether complex attention mechanisms improve performance on small datasets. We implement three model categories: baseline transformers (M1), novel factorized attention mechanisms (M2), and improved CNN baselines (M3). Our experiments show that sophisticated attention mechanisms consistently underperform on small datasets. M2 models achieved 5 to 13 percentage points below baselines due to overfitting and destruction of pretrained features. In contrast, simple domain-appropriate modifications proved effective: adding delta MFCCs to the audio CNN improved accuracy from 61.9\\% to \\textbf{65.56\\%} (+3.66pp), while frequency-domain features for EEG achieved \\textbf{67.62\\%} (+7.62pp over the paper baseline). Our vision transformer baseline (M1) reached \\textbf{75.30\\%}, exceeding the paper's ViViT result (74.5\\%) through domain-specific pretraining, and vision delta features achieved \\textbf{72.68\\%} (+1.28pp over the paper CNN). These findings demonstrate that for small-scale emotion recognition, domain knowledge and proper implementation outperform architectural complexity.", "AI": {"tldr": "研究在小数据集上使用多模态情感识别时，复杂的注意力机制是否能提高性能。", "motivation": "探索复杂注意机制在处理小型情感识别数据集上的表现，并尝试通过领域特性和简单修改来提升模型准确性。", "method": "实现三种模型类别：基础变压器（M1），新颖的因子化注意机制（M2）和改进的CNN基准（M3）。同时，增加特定领域的特征如delta MFCCs和频率域特征进行对比实验。", "result": "结果表明复杂注意力机制在小型数据集上表现不佳；通过领域适配和简单修改可显著提高模型性能。", "conclusion": "对于小规模情感识别任务，领域知识和合适的实施比复杂的架构更有效。"}}
{"id": "2601.22160", "pdf": "https://arxiv.org/pdf/2601.22160", "abs": "https://arxiv.org/abs/2601.22160", "authors": ["Jianan Wang", "Nailei Hei", "Li He", "Huanzhen Wang", "Aoxing Li", "Haofen Wang", "Yan Wang", "Wenqiang Zhang"], "title": "Screen, Match, and Cache: A Training-Free Causality-Consistent Reference Frame Framework for Human Animation", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "Human animation aims to generate temporally coherent and visually consistent videos over long sequences, yet modeling long-range dependencies while preserving frame quality remains challenging. Inspired by the human ability to leverage past observations for interpreting ongoing actions, we propose FrameCache, a training-free three-stage framework consisting of Screen, Cache, and Match. In the Screen stage, a multi-dimensional, quality-aware mechanism with adaptive thresholds dynamically selects informative frames; the Cache stage maintains a reference pool using a dynamic replacement-hit strategy, preserving both diversity and relevance; and the Match stage extracts behavioral features to perform motion-consistent reference matching for coherent animation guidance. Extensive experiments on standard benchmarks demonstrate that FrameCache consistently improves temporal coherence and visual stability while integrating seamlessly with diverse baselines. Despite these encouraging results, further analysis reveals that its effectiveness depends on baseline temporal reasoning and real-synthetic consistency, motivating future work on compatibility conditions and adaptive cache mechanisms. Code will be made publicly available.", "AI": {"tldr": "本文提出了一种无需训练的FrameCache框架，用于生成长期一致且视觉稳定的动画。", "motivation": "长时间依赖关系建模和帧质量保持对人类动画来说是一个挑战。该研究旨在通过利用过去的观察来解释正在进行的动作，改进动画的一致性和稳定性。", "method": "提出了一种三阶段的FrameCache框架：Screen、Cache和Match。Screen阶段选择重要的帧；Cache阶段维护一个参考池以保持多样性和相关性；Match阶段进行运动一致性的参考匹配。", "result": "实验表明，FrameCache在标准基准上的表现优于其他方法，在长期一致性和视觉稳定性方面有所提高。", "conclusion": "该框架展示了良好的性能，但仍需进一步研究其与基线时间和真实-合成一致性相关的兼容性条件及自适应缓存机制。"}}
{"id": "2601.22159", "pdf": "https://arxiv.org/pdf/2601.22159", "abs": "https://arxiv.org/abs/2601.22159", "authors": ["Naufal Suryanto", "Muzammal Naseer", "Pengfei Li", "Syed Talal Wasim", "Jinhui Yi", "Juergen Gall", "Paolo Ceravolo", "Ernesto Damiani"], "title": "RedSage: A Cybersecurity Generalist LLM", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "Accepted on ICLR 2026; Project page: https://risys-lab.github.io/RedSage/", "summary": "Cybersecurity operations demand assistant LLMs that support diverse workflows without exposing sensitive data. Existing solutions either rely on proprietary APIs with privacy risks or on open models lacking domain adaptation. To bridge this gap, we curate 11.8B tokens of cybersecurity-focused continual pretraining data via large-scale web filtering and manual collection of high-quality resources, spanning 28.6K documents across frameworks, offensive techniques, and security tools. Building on this, we design an agentic augmentation pipeline that simulates expert workflows to generate 266K multi-turn cybersecurity samples for supervised fine-tuning. Combined with general open-source LLM data, these resources enable the training of RedSage, an open-source, locally deployable cybersecurity assistant with domain-aware pretraining and post-training. To rigorously evaluate the models, we introduce RedSage-Bench, a benchmark with 30K multiple-choice and 240 open-ended Q&A items covering cybersecurity knowledge, skills, and tool expertise. RedSage is further evaluated on established cybersecurity benchmarks (e.g., CTI-Bench, CyberMetric, SECURE) and general LLM benchmarks to assess broader generalization. At the 8B scale, RedSage achieves consistently better results, surpassing the baseline models by up to +5.59 points on cybersecurity benchmarks and +5.05 points on Open LLM Leaderboard tasks. These findings demonstrate that domain-aware agentic augmentation and pre/post-training can not only enhance cybersecurity-specific expertise but also help to improve general reasoning and instruction-following. All models, datasets, and code are publicly available.", "AI": {"tldr": "论文介绍了一种名为RedSage的网络安全助手，通过定制化预训练和微调来提高特定领域的能力。", "motivation": "当前的解决方案无法在不暴露敏感数据的情况下支持多样化的网络安全工作流程。现有的模型要么依赖存在隐私风险的专有API，要么缺乏领域的适应性。", "method": "收集了11.8B个专注于网络安全的预训练样本，并设计了一个模拟专家工作流的代理增强管道以生成266K个多轮次网络安全样本进行监督微调。", "result": "在CTI-Bench、CyberMetric和SECURE等网络安全基准测试中，RedSage的表现优于基线模型，得分提高最高达5.59分；同时，在通用LLM基准上也表现出更好的性能，提高了5.05分。证明了领域适应性和代理增强可以提升特定领域的专业知识以及泛化能力。", "conclusion": "通过结合定制化的预训练和微调方法，RedSage能够在网络安全任务中超越现有模型，并在保持隐私的同时提供广义的推理能力和指令跟随能力。"}}
{"id": "2601.22158", "pdf": "https://arxiv.org/pdf/2601.22158", "abs": "https://arxiv.org/abs/2601.22158", "authors": ["Yiyang Lu", "Susie Lu", "Qiao Sun", "Hanhong Zhao", "Zhicheng Jiang", "Xianbang Wang", "Tianhong Li", "Zhengyang Geng", "Kaiming He"], "title": "One-step Latent-free Image Generation with Pixel Mean Flows", "categories": ["cs.CV"], "comment": "Technical report", "summary": "Modern diffusion/flow-based models for image generation typically exhibit two core characteristics: (i) using multi-step sampling, and (ii) operating in a latent space. Recent advances have made encouraging progress on each aspect individually, paving the way toward one-step diffusion/flow without latents. In this work, we take a further step towards this goal and propose \"pixel MeanFlow\" (pMF). Our core guideline is to formulate the network output space and the loss space separately. The network target is designed to be on a presumed low-dimensional image manifold (i.e., x-prediction), while the loss is defined via MeanFlow in the velocity space. We introduce a simple transformation between the image manifold and the average velocity field. In experiments, pMF achieves strong results for one-step latent-free generation on ImageNet at 256x256 resolution (2.22 FID) and 512x512 resolution (2.48 FID), filling a key missing piece in this regime. We hope that our study will further advance the boundaries of diffusion/flow-based generative models.", "AI": {"tldr": "该论文提出了一种无需潜在空间的一步图像生成方法“像素MeanFlow”(pMF)，实现在ImageNet数据集上高质量的单步骤无潜在生成。", "motivation": "现代扩散/流模型通常需要多步采样并在潜在空间中操作。研究目的是进一步推进一步扩散/流建模，无需使用潜在变量。", "method": "通过在网络输出空间和损失空间之间定义简单的变换，将网络目标设置在低维图像流形上，并在速度场中使用MeanFlow计算损失。", "result": "pMF在ImageNet上的256x256分辨率生成质量达到2.22FID，在512x512分辨率下为2.48FID，表明它能实现高质量的一步无潜在图像生成。", "conclusion": "该研究推动了扩散/流模型在一步无潜在变量图像生成方面的边界。"}}
{"id": "2601.22156", "pdf": "https://arxiv.org/pdf/2601.22156", "abs": "https://arxiv.org/abs/2601.22156", "authors": ["Yingfa Chen", "Zhen Leng Thai", "Zihan Zhou", "Zhu Zhang", "Xingyu Shen", "Shuo Wang", "Chaojun Xiao", "Xu Han", "Zhiyuan Liu"], "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "20 pages, 8 figures", "summary": "Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data", "AI": {"tldr": "本文提出了一种将Transformer模型转化为RNN注意力混合模型的HALO管道和HypeNet架构，以提高对长上下文的理解能力。", "motivation": "现有研究中的混合Transformer架构在处理长上下文时表现出色，但其大规模预训练成本高，且转化后的混合模型性能差。本文旨在通过优化方法降低转换数据量并提升模型性能。", "method": "提出HALO管道和HypeNet架构，采用HyPE位置编码方案及多项结构改进。使用2.3B令牌进行Qwen3系列向HypeNet的转换，以达到与原Transformer模型相媲美的效果。", "result": "成功将Qwen3系列转化为HypeNet，在长上下文性能和效率方面超越了原始的Transformer模型，且转化所需数据量仅为预训练数据的不到0.01%。", "conclusion": "HALO管道与HypeNet架构有效提升了混合模型在处理长文本时的表现，并大幅降低了转换成本。"}}
{"id": "2601.22155", "pdf": "https://arxiv.org/pdf/2601.22155", "abs": "https://arxiv.org/abs/2601.22155", "authors": ["Bo Li", "Yida Yin", "Wenhao Chai", "Xingyu Fu", "Zhuang Liu"], "title": "UEval: A Benchmark for Unified Multimodal Generation", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "We introduce UEval, a benchmark to evaluate unified models, i.e., models capable of generating both images and text. UEval comprises 1,000 expert-curated questions that require both images and text in the model output, sourced from 8 real-world tasks. Our curated questions cover a wide range of reasoning types, from step-by-step guides to textbook explanations. Evaluating open-ended multimodal generation is non-trivial, as simple LLM-as-a-judge methods can miss the subtleties. Different from previous works that rely on multimodal Large Language Models (MLLMs) to rate image quality or text accuracy, we design a rubric-based scoring system in UEval. For each question, reference images and text answers are provided to a MLLM to generate an initial rubric, consisting of multiple evaluation criteria, and human experts then refine and validate these rubrics. In total, UEval contains 10,417 validated rubric criteria, enabling scalable and fine-grained automatic scoring. UEval is challenging for current unified models: GPT-5-Thinking scores only 66.4 out of 100, while the best open-source model reaches merely 49.1. We observe that reasoning models often outperform non-reasoning ones, and transferring reasoning traces from a reasoning model to a non-reasoning model significantly narrows the gap. This suggests that reasoning may be important for tasks requiring complex multimodal understanding and generation.", "AI": {"tldr": "本文介绍了UEval，一个用于评估统一生成模型的基准测试。", "motivation": "现有的多模态生成评价方法存在不足，简单依赖LLM作为评判标准容易忽略细节。为此，作者设计了一个基于评分准则的方法来更精确地评估模型。", "method": "UEval包含1000个专家精心挑选的问题，这些问题需要生成图像和文本。对于每个问题，提供参考的图片和文字答案给一个MLLM以生成初步的评分标准，然后由人类专家进行完善和验证。", "result": "GPT-5-Thinking在UEval上的得分为66.4分，而最好的开源模型仅为49.1分。研究发现，推理模型通常优于非推理模型，并且将推理痕迹转移至非推理模型可以显著缩小差距。", "conclusion": "这一结果表明，在需要复杂的多模态理解和生成的任务中，推理可能非常重要。"}}
{"id": "2601.22154", "pdf": "https://arxiv.org/pdf/2601.22154", "abs": "https://arxiv.org/abs/2601.22154", "authors": ["Kaixuan Fan", "Kaituo Feng", "Manyuan Zhang", "Tianshuo Peng", "Zhixun Li", "Yilei Jiang", "Shuang Chen", "Peng Pei", "Xunliang Cai", "Xiangyu Yue"], "title": "Exploring Reasoning Reward Model for Agents", "categories": ["cs.AI", "cs.CL"], "comment": "Project page: https://github.com/kxfan2002/Reagent", "summary": "Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a multi-faceted reward model that produces structured feedback for agentic trajectories, including (1) an explicit reasoning trace , (2) a focused critique that provides refinement guidance by highlighting reasoning flaws, and (3) an overall score that evaluates process performance. Leveraging these signals, we systematically investigate three integration strategies: Reagent-C (text-augmented refinement), Reagent-R (reward-augmented guidance), and Reagent-U (unified feedback integration). Extensive evaluations across 12 diverse benchmarks demonstrate that Reagent-U yields substantial performance leaps, achieving 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of our reasoning reward model and training schemes. Code, models, and datasets are all released to facilitate future research.", "AI": {"tldr": "本文提出了一种用于代理训练的多方面奖励模型（Agent Reasoning Reward Model，简称Agent-RRM），该模型能够为复杂的推理和工具使用提供结构化反馈。", "motivation": "当前大多数基于稀疏结果回报的方法在训练过程中无法区分中间推理的质量，导致训练效果不佳。因此，本文提出了一个可以生成结构化反馈的奖励模型来改善这一问题。", "method": "Agent-RRM生成了三种类型的反馈信号：明确的推理轨迹、细化指导（通过突出显示推理错误）以及总体评分。研究团队系统地评估了三种集成策略：Reagent-C（文本增强的精炼）、Reagent-R（奖励增强的引导）和Reagent-U（统一的反馈整合）。", "result": "在12个不同的基准测试中，实验表明使用Reagent-U可以获得显著的成绩提升，在GAIA上达到43.7%，在WebWalkerQA上达到46.2%。这些结果验证了所提出的推理奖励模型的有效性。", "conclusion": "通过引入Agent-RRM和相应的训练方案，研究团队成功地提高了代理的性能，并开放了代码、模型及数据集以供未来的研究使用。"}}
{"id": "2601.22153", "pdf": "https://arxiv.org/pdf/2601.22153", "abs": "https://arxiv.org/abs/2601.22153", "authors": ["Haozhe Xie", "Beichen Wen", "Jiarui Zheng", "Zhaoxi Chen", "Fangzhou Hong", "Haiwen Diao", "Ziwei Liu"], "title": "DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "Project Page: https://www.infinitescript.com/project/dynamic-vla/ GitHub: https://github.com/hzxie/DynamicVLA", "summary": "Manipulating dynamic objects remains an open challenge for Vision-Language-Action (VLA) models, which, despite strong generalization in static manipulation, struggle in dynamic scenarios requiring rapid perception, temporal anticipation, and continuous control. We present DynamicVLA, a framework for dynamic object manipulation that integrates temporal reasoning and closed-loop adaptation through three key designs: 1) a compact 0.4B VLA using a convolutional vision encoder for spatially efficient, structurally faithful encoding, enabling fast multimodal inference; 2) Continuous Inference, enabling overlapping reasoning and execution for lower latency and timely adaptation to object motion; and 3) Latent-aware Action Streaming, which bridges the perception-execution gap by enforcing temporally aligned action execution. To fill the missing foundation of dynamic manipulation data, we introduce the Dynamic Object Manipulation (DOM) benchmark, built from scratch with an auto data collection pipeline that efficiently gathers 200K synthetic episodes across 2.8K scenes and 206 objects, and enables fast collection of 2K real-world episodes without teleoperation. Extensive evaluations demonstrate remarkable improvements in response speed, perception, and generalization, positioning DynamicVLA as a unified framework for general dynamic object manipulation across embodiments.", "AI": {"tldr": "动态物体操作对于视觉语言行动（VLA）模型是一个挑战，本文提出了DynamicVLA框架来解决此问题。", "motivation": "现有的VLA模型在静态环境下表现良好，但在处理需要快速感知、时间预判和连续控制的动态环境时效果不佳。为此，作者提出了一种新的方法来改进这一情况。", "method": "DynamicVLA通过三个关键设计：1）使用卷积视觉编码器的空间有效且结构忠实的编码；2）持续推理以实现重叠的推理与执行，降低延迟并适应物体运动；3）隐式动作流以弥补感知和执行之间的差距。此外，作者还引入了DOM基准测试来收集动态操作数据。", "result": "实验表明DynamicVLA框架在响应速度、感知能力和泛化性方面都有显著提升。", "conclusion": "DynamicVLA可以作为一个通用的框架，在不同的实体中实现动态物体的操作"}}
{"id": "2601.22150", "pdf": "https://arxiv.org/pdf/2601.22150", "abs": "https://arxiv.org/abs/2601.22150", "authors": ["Xiaoxiao Sun", "Mingyang Li", "Kun yuan", "Min Woo Sun", "Mark Endo", "Shengguang Wu", "Changlin Li", "Yuhui Zhang", "Zeyu Wang", "Serena Yeung-Levy"], "title": "Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions", "categories": ["cs.CV"], "comment": "26 pages, 31 figures, 13 tables. Project Page: https://sites.google.com/view/vi-probe/", "summary": "Large Vision-Language Models (VLMs) often answer classic visual illusions \"correctly\" on original images, yet persist with the same responses when illusion factors are inverted, even though the visual change is obvious to humans. This raises a fundamental question: do VLMs perceive visual changes or merely recall memorized patterns? While several studies have noted this phenomenon, the underlying causes remain unclear. To move from observations to systematic understanding, this paper introduces VI-Probe, a controllable visual-illusion framework with graded perturbations and matched visual controls (without illusion inducer) that disentangles visually grounded perception from language-driven recall. Unlike prior work that focuses on averaged accuracy, we measure stability and sensitivity using Polarity-Flip Consistency, Template Fixation Index, and an illusion multiplier normalized against matched controls. Experiments across different families reveal that response persistence arises from heterogeneous causes rather than a single mechanism. For instance, GPT-5 exhibits memory override, Claude-Opus-4.1 shows perception-memory competition, while Qwen variants suggest visual-processing limits. Our findings challenge single-cause views and motivate probing-based evaluation that measures both knowledge and sensitivity to controlled visual change. Data and code are available at https://sites.google.com/view/vi-probe/.", "AI": {"tldr": "研究探讨了大型视觉语言模型(VLM)在经典视错觉中的行为，通过引入VI-Probe框架来区分感知和记忆，并测量稳定性和敏感性。", "motivation": "现有研究表明VLMs在处理经典视错觉时表现出持续的响应，即使当错觉因素反转后也是如此。这引发了关于这些模型是否真正感知到视觉变化还是仅仅依赖于先前记忆的问题。为了解释这一现象并加深理解，作者提出了VI-Probe框架。", "method": "提出了一种可控制的视觉错觉框架VI-Probe，通过引入渐变扰动和匹配的视觉对照组来区分基于视觉的认知与语言驱动的记忆，并使用多项指标测量模型响应的一致性和对视觉变化的敏感度。", "result": "实验结果表明不同VLM家族的行为差异很大。例如，GPT-5表现出记忆覆盖现象，Claude-Opus-4.1显示感知和记忆之间的竞争，而Qwen变体则显示出在处理视错觉时存在的限制。", "conclusion": "研究揭示了VLM对经典视觉错觉的响应行为，并提出了一个更全面的方法来评估这些模型的知识量以及它们对控制下视觉变化的敏感性。"}}
{"id": "2601.22149", "pdf": "https://arxiv.org/pdf/2601.22149", "abs": "https://arxiv.org/abs/2601.22149", "authors": ["Hang Ding", "Peidong Liu", "Junqiao Wang", "Ziwei Ji", "Meng Cao", "Rongzhao Zhang", "Lynn Ai", "Eric Yang", "Tianyu Shi", "Lei Yu"], "title": "DynaWeb: Model-Based Reinforcement Learning of Web Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.", "AI": {"tldr": "DynaWeb 是一种基于模型的强化学习框架，用于训练网络代理。", "motivation": "当前自主网页代理在真实互联网环境中训练效率低下、成本高昂且存在风险。模型基于强化学习提供了一种解决方案，通过构建环境模型实现模拟交互。", "method": "DynaWeb 构建了一个仿真网页环境，在该环境中生成大量行动轨迹以进行高效的在线增强学习。框架结合了从实际数据中获得的专业轨迹，并随机与策略轨迹混合使用，从而提高稳定性和样本效率。", "result": "实验结果表明，DynaWeb 在 WebArena 和 WebVoyager 基准测试上显著提升了状态-of-the-art 开源网页代理模型的表现。", "conclusion": "通过想象训练网络代理是可行的，这为在线增强学习提供了可扩展和高效的方法。"}}
{"id": "2601.22143", "pdf": "https://arxiv.org/pdf/2601.22143", "abs": "https://arxiv.org/abs/2601.22143", "authors": ["Anthony Chen", "Naomi Ken Korem", "Tavi Halperin", "Matan Ben Yosef", "Urska Jelercic", "Ofir Bibi", "Or Patashnik", "Daniel Cohen-Or"], "title": "JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion", "categories": ["cs.GR", "cs.CV"], "comment": "Project webpage available at https://justdubit.github.io", "summary": "Audio-Visual Foundation Models, which are pretrained to jointly generate sound and visual content, have recently shown an unprecedented ability to model multi-modal generation and editing, opening new opportunities for downstream tasks. Among these tasks, video dubbing could greatly benefit from such priors, yet most existing solutions still rely on complex, task-specific pipelines that struggle in real-world settings. In this work, we introduce a single-model approach that adapts a foundational audio-video diffusion model for video-to-video dubbing via a lightweight LoRA. The LoRA enables the model to condition on an input audio-video while jointly generating translated audio and synchronized facial motion. To train this LoRA, we leverage the generative model itself to synthesize paired multilingual videos of the same speaker. Specifically, we generate multilingual videos with language switches within a single clip, and then inpaint the face and audio in each half to match the language of the other half. By leveraging the rich generative prior of the audio-visual model, our approach preserves speaker identity and lip synchronization while remaining robust to complex motion and real-world dynamics. We demonstrate that our approach produces high-quality dubbed videos with improved visual fidelity, lip synchronization, and robustness compared to existing dubbing pipelines.", "AI": {"tldr": "本文介绍了一种基于联合音频视频扩散模型的单模型视频配音方法，使用轻量级LoRA技术实现。", "motivation": "现有的视频配音解决方案依赖于复杂的、特定任务的工作流程，在现实环境中表现不佳。通过引入一种适应性更强的方法来解决这个问题，使视频配音更加可靠和高效。", "method": "利用预训练的音频-视觉扩散模型，并用轻量级LoRA技术对其进行微调以进行视频配音，同时生成翻译后的语音和同步面部动作。", "result": "这种方法在保持说话者身份的同时，提高了唇部同步质量以及对复杂运动和现实世界动态的鲁棒性。与现有的配音方法相比，该方法产生的配音视频具有更高的视觉保真度。", "conclusion": "基于预训练音频-视觉扩散模型的方法，在生成高质量、高精度的多语言配音方面展示出了巨大潜力，同时保持了说话者身份的一致性和唇部同步效果"}}
{"id": "2601.22141", "pdf": "https://arxiv.org/pdf/2601.22141", "abs": "https://arxiv.org/abs/2601.22141", "authors": ["Grzegorz Stefanski", "Alberto Presta", "Michal Byra"], "title": "Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "In pruning, the Lottery Ticket Hypothesis posits that large networks contain sparse subnetworks, or winning tickets, that can be trained in isolation to match the performance of their dense counterparts. However, most existing approaches assume a single universal winning ticket shared across all inputs, ignoring the inherent heterogeneity of real-world data. In this work, we propose Routing the Lottery (RTL), an adaptive pruning framework that discovers multiple specialized subnetworks, called adaptive tickets, each tailored to a class, semantic cluster, or environmental condition. Across diverse datasets and tasks, RTL consistently outperforms single- and multi-model baselines in balanced accuracy and recall, while using up to 10 times fewer parameters than independent models and exhibiting semantically aligned. Furthermore, we identify subnetwork collapse, a performance drop under aggressive pruning, and introduce a subnetwork similarity score that enables label-free diagnosis of oversparsification. Overall, our results recast pruning as a mechanism for aligning model structure with data heterogeneity, paving the way toward more modular and context-aware deep learning.", "AI": {"tldr": "提出了适应性彩票框架（RTL），该框架能够在不同输入下发现多个适应性的子网络，从而提高模型性能。", "motivation": "现有的修剪方法假设大网络中存在一个单一的、适用于所有输入的获胜子网络，而忽略了现实数据集中的异质性。论文旨在通过寻找更适合特定类别的子网络来解决这一问题。", "method": "提出了一种适应性彩票框架（RTL），该框架在不同类别或环境条件下发现多个适应性的子网络，并引入了亚网相似度分数以诊断过度修剪的问题。", "result": "与单模型和多模型基线相比，RTL 在平衡准确率和召回上表现出色，参数使用量减少高达10倍。此外，识别并解决了子网络坍缩问题，即在极端修剪情况下性能下降的现象。", "conclusion": "论文表明了修剪机制可以作为一种将模型结构与数据异质性对齐的手段，并为模块化、上下文感知深度学习的发展铺平道路。"}}
{"id": "2601.22139", "pdf": "https://arxiv.org/pdf/2601.22139", "abs": "https://arxiv.org/abs/2601.22139", "authors": ["Xin Chen", "Feng Jiang", "Yiqian Zhang", "Hardy Chen", "Shuo Yan", "Wenya Xie", "Min Yang", "Shujian Huang"], "title": "Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers", "categories": ["cs.CL", "cs.AI"], "comment": "The manuscript is under review", "summary": "Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \\emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\\% higher accuracy, 22.90\\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \\href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}", "AI": {"tldr": "本文提出了一种新的推理范式，即主动交互推理（PIR），该方法使大型语言模型从被动求解者转变为能够进行互动查询的积极询问者。", "motivation": "当前推理导向的大规模语言模型在链式思维提示下取得了显著进展，但仍然受到一种“盲自思”模式的限制：即使关键信息缺失或模糊时也会进行大量内部推理。", "method": "PIR通过两个核心组件实现：一个是不确定性感知的监督微调过程，使模型具备互动推理能力；另一个是基于用户模拟器驱动的策略优化框架，以复合奖励方式来对齐模型行为与用户意图。", "result": "实验显示，在数学推理、代码生成和文档编辑任务上，PIR相比强基准线取得了显著提升：最高提升了32.70%的准确率、22.90%的通过率及41.36的BLEU值；同时减少了大约一半的推理计算量和不必要的互动回合数。", "conclusion": "进一步的可靠性评估表明，PIR在事实知识确认、问答以及缺失前提场景中的表现均具有较强泛化性和鲁棒性。模型与代码均已公开。"}}
{"id": "2601.22137", "pdf": "https://arxiv.org/pdf/2601.22137", "abs": "https://arxiv.org/abs/2601.22137", "authors": ["Shenghao Yang", "Zhichao Wang", "Oleg Balabanov", "N. Benjamin Erichson", "Michael W. Mahoney"], "title": "PRISM: Distribution-free Adaptive Computation of Matrix Functions for Accelerating Neural Network Training", "categories": ["cs.LG", "cs.AI", "math.NA", "math.OC"], "comment": null, "summary": "Matrix functions such as square root, inverse roots, and orthogonalization play a central role in preconditioned gradient methods for neural network training. This has motivated the development of iterative algorithms that avoid explicit eigendecompositions and rely primarily on matrix multiplications, making them well suited for modern GPU accelerators. We present PRISM (Polynomial-fitting and Randomized Iterative Sketching for Matrix functions computation), a general framework for accelerating iterative algorithms for computing matrix functions. PRISM combines adaptive polynomial approximation with randomized sketching: at each iteration, it fits a polynomial surrogate to the current spectrum via a sketched least-squares problem, adapting to the instance at hand with minimal overhead. We apply PRISM to accelerate Newton-Schulz-like iterations for matrix square roots and orthogonalization, which are core primitives in machine learning. Unlike prior methods, PRISM requires no explicit spectral bounds or singular value estimates; and it adapts automatically to the evolving spectrum. Empirically, PRISM accelerates training when integrated into Shampoo and Muon optimizers.", "AI": {"tldr": "PRISM框架通过自适应多项式逼近和随机化草图技术加速矩阵函数的计算，特别是用于神经网络训练中的预处理梯度方法。", "motivation": "在现代GPU加速器中，避免显式的特征分解而依赖矩阵乘法的迭代算法是计算矩阵函数的关键。PRISM旨在通过自适应多项式逼近和随机化草图技术来优化这些迭代算法，使其更高效地应用于神经网络训练中的预处理梯度方法。", "method": "PRISM框架结合了自适应多项式近似与随机采样：在每次迭代中，它通过对当前频谱进行拟合的草图最小二乘问题来适应实例，并通过最小开销实现自动调整。应用到Newton-Schulz类迭代算法时，PRISM不需显式的谱界或奇异值估计。", "result": "实验表明，当与Shampoo和Muon优化器集成时，PRISM可以加速训练过程。", "conclusion": "通过自适应多项式逼近和随机化草图技术，PRISM框架在神经网络训练中有效提高了矩阵函数计算的速度。"}}
{"id": "2601.22136", "pdf": "https://arxiv.org/pdf/2601.22136", "abs": "https://arxiv.org/abs/2601.22136", "authors": ["Gloria Felicia", "Michael Eniolade", "Jinfeng He", "Zitha Sasindran", "Hemant Kumar", "Milan Hussain Angati", "Sandeep Bandarupalli"], "title": "StepShield: When, Not Whether to Intervene on Rogue Agents", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.SE"], "comment": "16 pages, 2 figures, 14 tables", "summary": "Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, not just whether. StepShield contains 9,213 code agent trajectories, including 1,278 meticulously annotated training pairs and a 7,935-trajectory test set with a realistic 8.1% rogue rate. Rogue behaviors are grounded in real-world security incidents across six categories. We propose three novel temporal metrics: Early Intervention Rate (EIR), Intervention Gap, and Tokens Saved. Surprisingly, our evaluation reveals that an LLM-based judge achieves 59% EIR while a static analyzer achieves only 26%, a 2.3x performance gap that is entirely invisible to standard accuracy metrics. We further show that early detection has direct economic benefits: our cascaded HybridGuard detector reduces monitoring costs by 75% and projects to $108M in cumulative savings over five years at enterprise scale. By shifting the focus of evaluation from whether to when, StepShield provides a new foundation for building safer and more economically viable AI agents. The code and data are released under an Apache 2.0 license.", "AI": {"tldr": "StepShield是一个评估代理检测违规行为时机的基准，引入了新的时间度量标准以改进现有的安全性评估方法。", "motivation": "当前的安全性评估基准只关注是否检测到违规行为而忽略了检测的时间点。这种忽视可能导致实际干预失效，只能进行事后分析而非事前预防。", "method": "StepShield通过包含9213个代码代理轨迹的数据集和三个新的时间度量标准（EIR、干预间隔和节省的令牌）来评估安全性的时机问题，并展示了LLM与静态分析器之间的性能差距。", "result": "基于LLM的安全检测器实现了59%的早间干预率，而静态分析器仅为26%，这表明现有的准确性指标可能不足以准确衡量安全性。此外，StepShield展示了一种混合检测器可以显著减少监控成本，并在企业规模上带来经济利益。", "conclusion": "通过重新聚焦评估标准从是否检测到违规行为转向何时检测，StepShield提供了一个新的框架来构建更安全且经济效益更高的AI代理系统。"}}
{"id": "2601.22135", "pdf": "https://arxiv.org/pdf/2601.22135", "abs": "https://arxiv.org/abs/2601.22135", "authors": ["Zhexin Liang", "Zhaoxi Chen", "Yongwei Chen", "Tianyi Wei", "Tengfei Wang", "Xingang Pan"], "title": "PI-Light: Physics-Inspired Diffusion for Full-Image Relighting", "categories": ["cs.CV"], "comment": "Accepted at ICLR 2026", "summary": "Full-image relighting remains a challenging problem due to the difficulty of collecting large-scale structured paired data, the difficulty of maintaining physical plausibility, and the limited generalizability imposed by data-driven priors. Existing attempts to bridge the synthetic-to-real gap for full-scene relighting remain suboptimal. To tackle these challenges, we introduce Physics-Inspired diffusion for full-image reLight ($π$-Light, or PI-Light), a two-stage framework that leverages physics-inspired diffusion models. Our design incorporates (i) batch-aware attention, which improves the consistency of intrinsic predictions across a collection of images, (ii) a physics-guided neural rendering module that enforces physically plausible light transport, (iii) physics-inspired losses that regularize training dynamics toward a physically meaningful landscape, thereby enhancing generalizability to real-world image editing, and (iv) a carefully curated dataset of diverse objects and scenes captured under controlled lighting conditions. Together, these components enable efficient finetuning of pretrained diffusion models while also providing a solid benchmark for downstream evaluation. Experiments demonstrate that $π$-Light synthesizes specular highlights and diffuse reflections across a wide variety of materials, achieving superior generalization to real-world scenes compared with prior approaches.", "AI": {"tldr": "PI-Light是一种基于物理启发的扩散模型，用于全图像重光照。", "motivation": "现有的全场景重光照方法在合成到真实世界的差距上表现不佳。PI-Light旨在解决数据收集困难、保持物理合理性以及数据驱动先验限制泛化能力等问题。", "method": "PI-Light采用两阶段框架，包括批感知注意机制以提高固有预测的图像间一致性，物理引导神经渲染模块来强制执行合理的光传输，并使用物理启发损失来增强模型在真实场景中的泛化能力。此外，还构建了一个精心策划的数据集以支持预训练模型的有效微调。", "result": "实验表明，PI-Light能够合成各种材料的镜面高光和漫反射，在真实世界场景中实现了比先前方法更好的泛化性能。", "conclusion": "PI-Light提供了一种有效的方法来解决全图像重光照问题，并为未来的研究提供了基准。"}}
{"id": "2601.22134", "pdf": "https://arxiv.org/pdf/2601.22134", "abs": "https://arxiv.org/abs/2601.22134", "authors": ["Wenxuan Li", "Pedro R. A. S. Bassi", "Lizhou Wu", "Xinze Zhou", "Yuxuan Zhao", "Qi Chen", "Szymon Plotka", "Tianyu Lin", "Zheren Zhu", "Marisa Martin", "Justin Caskey", "Shanshan Jiang", "Xiaoxi Chen", "Jaroslaw B. Ćwikla", "Artur Sankowski", "Yaping Wu", "Sergio Decherchi", "Andrea Cavalli", "Chandana Lall", "Cristian Tomasetti", "Yaxing Guo", "Xuan Yu", "Yuqing Cai", "Hualin Qiao", "Jie Bao", "et al. (12 additional authors not shown)"], "title": "Early and Prediagnostic Detection of Pancreatic Cancer from Computed Tomography", "categories": ["cs.CV"], "comment": null, "summary": "Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest solid malignancies, is often detected at a late and inoperable stage. Retrospective reviews of prediagnostic CT scans, when conducted by expert radiologists aware that the patient later developed PDAC, frequently reveal lesions that were previously overlooked. To help detecting these lesions earlier, we developed an automated system named ePAI (early Pancreatic cancer detection with Artificial Intelligence). It was trained on data from 1,598 patients from a single medical center. In the internal test involving 1,009 patients, ePAI achieved an area under the receiver operating characteristic curve (AUC) of 0.939-0.999, a sensitivity of 95.3%, and a specificity of 98.7% for detecting small PDAC less than 2 cm in diameter, precisely localizing PDAC as small as 2 mm. In an external test involving 7,158 patients across 6 centers, ePAI achieved an AUC of 0.918-0.945, a sensitivity of 91.5%, and a specificity of 88.0%, precisely localizing PDAC as small as 5 mm. Importantly, ePAI detected PDACs on prediagnostic CT scans obtained 3 to 36 months before clinical diagnosis that had originally been overlooked by radiologists. It successfully detected and localized PDACs in 75 of 159 patients, with a median lead time of 347 days before clinical diagnosis. Our multi-reader study showed that ePAI significantly outperformed 30 board-certified radiologists by 50.3% (P < 0.05) in sensitivity while maintaining a comparable specificity of 95.4% in detecting PDACs early and prediagnostic. These findings suggest its potential of ePAI as an assistive tool to improve early detection of pancreatic cancer.", "AI": {"tldr": "开发了一种名为ePAI的人工智能系统，用于早期和预诊断检测胰腺癌。", "motivation": "胰腺导管腺癌（PDAC）通常在晚期被发现。专家放射科医生通过回顾性检查患者的CT扫描图像，在知道患者后来患上了PDAC的情况下，常常能够识别出此前被忽视的病灶。为了帮助更早地检测这些病灶，开发了ePAI系统。", "method": "ePAI系统基于1,598名患者的数据进行了训练，并通过内部测试和外部测试验证其效果，其中内测涉及1,009名患者，外测包含来自6个中心的7,158名患者。该研究还进行了一项多读者研究。", "result": "在内部测试中，ePAI系统实现了AUC值为0.939-0.999，对于直径小于2厘米的小PDAC具有95.3%的敏感性和98.7%的特异性。外部测试显示，在6个中心的患者数据集上，ePAI系统的性能略有下降，但仍取得了AUC值为0.918-0.945的成绩，并且能够检测和定位最小直径为2毫米的小PDAC。在一项多读者研究中，与30位认证放射科医师相比，该系统提高了敏感性50.3%（P < 0.05）。", "conclusion": "这些结果表明ePAI具有潜力作为辅助工具来改善胰腺癌的早期检测。"}}
{"id": "2601.22130", "pdf": "https://arxiv.org/pdf/2601.22130", "abs": "https://arxiv.org/abs/2601.22130", "authors": ["Lakshya Gupta", "Litao Li", "Yizhe Liu", "Sriram Ganapathi Subramanian", "Kaheer Suleman", "Zichen Zhang", "Haoye Lu", "Sumit Pasupalak"], "title": "World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Frontier large language models (LLMs) excel as autonomous agents in many domains, yet they remain untested in complex enterprise systems where hidden workflows create cascading effects across interconnected databases. Existing enterprise benchmarks evaluate surface-level agentic task completion similar to general consumer benchmarks, ignoring true challenges in enterprises, such as limited observability, large database state, and hidden workflows with cascading side effects. We introduce World of Workflows (WoW), a realistic ServiceNow-based environment incorporating 4,000+ business rules and 55 active workflows embedded in the system, alongside WoW-bench, a benchmark of 234 tasks evaluating constrained agentic task completion and enterprise dynamics modeling capabilities. We reveal two major takeaways: (1) Frontier LLMs suffer from dynamics blindness, consistently failing to predict the invisible, cascading side effects of their actions, which leads to silent constraint violations, and (2) reliability in opaque systems requires grounded world modeling, where agents must mentally simulate hidden state transitions to bridge the observability gap when high-fidelity feedback is unavailable. For reliable and useful enterprise agents, WoW motivates a new paradigm to explicitly learn system dynamics. We release our GitHub for setting up and evaluating WoW.", "AI": {"tldr": "本文介绍了WoW，一个基于ServiceNow的复杂企业系统环境及评估基准，以测试大型语言模型在处理隐藏工作流和级联效应时的能力。", "motivation": "当前的企业基准评价体系主要关注表面任务完成度，忽略了真实世界中如有限可见性、大规模数据库状态以及隐藏的工作流程带来的挑战。因此，需要一个新的评估方法来识别大型语言模型在复杂企业环境中的局限性和能力。", "method": "通过构建一个包含4000多条业务规则和55个活动工作流的真实ServiceNow系统，并提出WoW-bench作为测试基准，评估前沿大语言模型的代理任务完成能力和对企业动态的理解能力。", "result": "研究表明，大型语言模型在预测行为隐藏级联效应方面存在盲点，容易违反未被察觉的约束条件。同时，要确保不透明系统的可靠性，需要通过模拟隐藏状态转换来填补可见性差距。", "conclusion": "WoW为开发可靠的企业代理提供了新的研究方向，并强调了学习系统动力学的重要性以解决模型在复杂企业环境中的挑战。"}}
{"id": "2601.22129", "pdf": "https://arxiv.org/pdf/2601.22129", "abs": "https://arxiv.org/abs/2601.22129", "authors": ["Yifeng Ding", "Lingming Zhang"], "title": "SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to generalize to modern agents that synthesize custom bash scripts as tools. In this paper, we introduce SWE-Replay, the first efficient and generalizable test-time scaling technique for modern agents without reliance on potentially noisy value estimates. SWE-Replay optimizes the scaling process by recycling trajectories from prior trials, dynamically choosing to either explore from scratch or exploit archived experience by branching at critical intermediate steps. This selection of intermediate steps is driven by the potential and reasoning significance of repository exploration, rather than external LLM-based quality estimates. Our evaluation shows that, on SWE-Bench Verified, SWE-Replay consistently outperforms naive scaling, reducing costs by up to 17.4% while maintaining or even improving performance by up to 3.8%. Further evaluation on SWE-Bench Pro and Multilingual validates the generalizability of SWE-Replay, establishing it as a robust foundation for efficient test-time scaling of software engineering agents.", "AI": {"tldr": "介绍了一种名为SWE-Replay的高效且通用的测试时间缩放技术，该技术通过重复利用先前试验中的轨迹来优化现代软件工程代理的能力。", "motivation": "传统的测试时间缩放方法由于需要从头开始多次采样路径而计算成本高昂。虽然最近的方法试图使用专门的价值代理减少费用，但它们可能会导致模型失准，并且无法泛化到生成自定义bash脚本的现代代理中。", "method": "SWE-Replay通过重复利用先前试验中的轨迹来优化缩放过程，动态选择从头开始探索或利用已存档的经验。它根据代码库探索的潜在重要性做出决策，而不是依靠外部LLM的质量估计。", "result": "在SWE-Bench Verified上评估显示，与简单的缩放相比，SWE-Replay能够减少最多17.4%的成本，并且性能保持不变或提高多达3.8%。进一步验证了其在SWE-Bench Pro和Multilingual上的泛化能力。", "conclusion": "SWE-Replay被证明是实现软件工程代理高效测试时间缩放的稳健基础技术，能够有效降低成本并提升性能。"}}
{"id": "2601.22128", "pdf": "https://arxiv.org/pdf/2601.22128", "abs": "https://arxiv.org/abs/2601.22128", "authors": ["Irsyad Adam", "Zekai Chen", "David Laprade", "Shaun Porwal", "David Laub", "Erik Reinertsen", "Arda Pekis", "Kevin Brown"], "title": "The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR", "categories": ["cs.AI", "cs.CE", "q-bio.QM"], "comment": null, "summary": "Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient's trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.", "AI": {"tldr": "本文提出了一种新的世界模型SMB-Structure，用于模拟电子健康记录中的患者轨迹动态。", "motivation": "现有模型将病人视作静态文档进行总结而非作为动力系统进行仿真。此方法无法捕捉病人的动态变化和干预影响。", "method": "通过联合嵌入预测架构(JEPA)结合下一令牌预测(SFT)，SMB-Structure旨在从初始表示中预测患者状态的未来走向，并在标记空间中重建未来的患者状态。", "result": "模型在两个大规模队列上的线性探针评估中表现出色，捕捉到了疾病动态变化，优于自回归基线方法。", "conclusion": "该训练范式可以学习到包含复杂任务所需病患异质性的嵌入表示。"}}
{"id": "2601.22127", "pdf": "https://arxiv.org/pdf/2601.22127", "abs": "https://arxiv.org/abs/2601.22127", "authors": ["John Flynn", "Wolfgang Paier", "Dimitar Dinev", "Sam Nhut Nguyen", "Hayk Poghosyan", "Manuel Toribio", "Sandipan Banerjee", "Guy Gafni"], "title": "EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers", "categories": ["cs.CV", "cs.GR", "cs.LG", "cs.MM"], "comment": "Project page: https://edit-yourself.github.io/", "summary": "Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing that enables transcript-based modification of talking head videos, including the seamless addition, removal, and retiming of visually spoken content. Building on a general-purpose video diffusion model, EditYourself augments its V2V capabilities with audio conditioning and region-aware, edit-focused training extensions. This enables precise lip synchronization and temporally coherent restructuring of existing performances via spatiotemporal inpainting, including the synthesis of realistic human motion in newly added segments, while maintaining visual fidelity and identity consistency over long durations. This work represents a foundational step toward generative video models as practical tools for professional video post-production.", "AI": {"tldr": "本文提出了一种基于DiT的框架EditYourself，用于音频驱动的视频到视频编辑，可以实现对话头视频中的文本内容修改。", "motivation": "现有的生成式视频模型在从文本和图像提示中产生新颖的内容方面表现出色，但在编辑现有预录制视频时存在差距。需要微调口述脚本的同时保留运动、时间一致性、说话者身份和准确的唇部同步。", "method": "基于通用视频扩散模型，EditYourself通过音频条件化和区域感知训练扩展来增强其V2V能力，实现精确的唇部同步和现有表演的时间上一致的重构。", "result": "该方法实现了对话头视频中内容的无缝添加、删除和重新定时，并保持视觉保真度和长期的身份一致性。新加入部分能合成出逼真的人体运动。", "conclusion": "本文的工作为生成式视频模型作为专业视频后期制作中的实用工具奠定了基础。"}}
{"id": "2601.22125", "pdf": "https://arxiv.org/pdf/2601.22125", "abs": "https://arxiv.org/abs/2601.22125", "authors": ["Kunpeng Song", "Ahmed Elgammal"], "title": "Creative Image Generation with Diffusion Model", "categories": ["cs.CV"], "comment": "Project page: https://creative-t2i.github.io", "summary": "Creative image generation has emerged as a compelling area of research, driven by the need to produce novel and high-quality images that expand the boundaries of imagination. In this work, we propose a novel framework for creative generation using diffusion models, where creativity is associated with the inverse probability of an image's existence in the CLIP embedding space. Unlike prior approaches that rely on a manual blending of concepts or exclusion of subcategories, our method calculates the probability distribution of generated images and drives it towards low-probability regions to produce rare, imaginative, and visually captivating outputs. We also introduce pullback mechanisms, achieving high creativity without sacrificing visual fidelity. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness and efficiency of our creative generation framework, showcasing its ability to produce unique, novel, and thought-provoking images. This work provides a new perspective on creativity in generative models, offering a principled method to foster innovation in visual content synthesis.", "AI": {"tldr": "本文提出了一种基于扩散模型的创意图像生成框架，通过引导生成的概率分布进入低概率区域来产生独特且高质量的视觉内容。", "motivation": "当前创意图像生成方法存在局限性，需要一种既能保持高视觉保真度又能产生新颖、具有想象力输出的方法。为此，本文提出了一种新视角下的扩散模型方法以解决这一问题。", "method": "该框架通过计算生成图像在CLIP嵌入空间中的概率分布，并将其引导至低概率区域来实现创意图像的生成。此外还引入了回拉机制，在保证视觉保真度的同时增加生成内容的独特性。", "result": "实验表明，提出的创造性生成框架有效且高效地实现了独特新颖、引人深思的图像生成。", "conclusion": "本文提供了一个新的视角来探索创意在生成模型中的实现方式，并为未来创新性的视觉内容合成提供了方向。"}}
{"id": "2601.22119", "pdf": "https://arxiv.org/pdf/2601.22119", "abs": "https://arxiv.org/abs/2601.22119", "authors": ["Han Yang", "Dong Hao", "Zhuohan Wang", "Qi Shi", "Xingtong Li"], "title": "Alpha Discovery via Grammar-Guided Learning and Search", "categories": ["q-fin.CP", "cs.AI", "cs.LG"], "comment": "24 pages, 10 figures", "summary": "Automatically discovering formulaic alpha factors is a central problem in quantitative finance. Existing methods often ignore syntactic and semantic constraints, relying on exhaustive search over unstructured and unbounded spaces. We present AlphaCFG, a grammar-based framework for defining and discovering alpha factors that are syntactically valid, financially interpretable, and computationally efficient. AlphaCFG uses an alpha-oriented context-free grammar to define a tree-structured, size-controlled search space, and formulates alpha discovery as a tree-structured linguistic Markov decision process, which is then solved using a grammar-aware Monte Carlo Tree Search guided by syntax-sensitive value and policy networks. Experiments on Chinese and U.S. stock market datasets show that AlphaCFG outperforms state-of-the-art baselines in both search efficiency and trading profitability. Beyond trading strategies, AlphaCFG serves as a general framework for symbolic factor discovery and refinement across quantitative finance, including asset pricing and portfolio construction.", "AI": {"tldr": "AlphaCFG框架用于发现有效的alpha因素", "motivation": "当前方法忽视了语法和语义限制，使用无结构、未界定的空间进行穷尽搜索，缺乏效率和实用性。因此需要一种基于语法的方法来定义和寻找有效且可解释的alpha因素。", "method": "利用上下文无关文法定义一个树形结构的可控大小的搜索空间，并将alpha发现问题建模为带语义敏感价值和策略网络引导的蒙特卡洛树搜索的问题。", "result": "实验表明，AlphaCFG在搜索效率和交易收益上优于最先进的基准方法。", "conclusion": "AlphaCFG提供了一个有效框架来发现和改进符号因子，在量化金融中具有广泛的应用前景。"}}
{"id": "2601.22118", "pdf": "https://arxiv.org/pdf/2601.22118", "abs": "https://arxiv.org/abs/2601.22118", "authors": ["Johann Christensen", "Elena Hoemann", "Frank Köster", "Sven Hallerbach"], "title": "Defining Operational Conditions for Safety-Critical AI-Based Systems from Data", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) has been on the rise in many domains, including numerous safety-critical applications. However, for complex systems found in the real world, or when data already exist, defining the underlying environmental conditions is extremely challenging. This often results in an incomplete description of the environment in which the AI-based system must operate. Nevertheless, this description, called the Operational Design Domain (ODD), is required in many domains for the certification of AI-based systems. Traditionally, the ODD is created in the early stages of the development process, drawing on sophisticated expert knowledge and related standards. This paper presents a novel Safety-by-Design method to a posteriori define the ODD from previously collected data using a multi-dimensional kernel-based representation. This approach is validated through both Monte Carlo methods and a real-world aviation use case for a future safety-critical collision-avoidance system. Moreover, by defining under what conditions two ODDs are equal, the paper shows that the data-driven ODD can equal the original, underlying hidden ODD of the data. Utilizing the novel, Safe-by-Design kernel-based ODD enables future certification of data-driven, safety-critical AI-based systems.", "AI": {"tldr": "基于数据定义安全关键AI系统的操作设计域(ODD)，以支持其认证。", "motivation": "当前的复杂系统和存在的大量数据使得传统方法难以准确描述环境条件，影响了安全关键AI系统的有效性和可靠性。", "method": "提出了一种后验性地从已有数据定义ODD的安全设计法。该方法采用多维核表示，并通过蒙特卡洛模拟和实际航空案例验证其有效性。", "result": "证明了所提方法能够准确识别现有数据集的真实ODD，且在碰撞避免系统中的应用表明该方法具备实用价值。", "conclusion": "通过利用新颖的安全设计法来定义数据驱动型安全关键AI系统的ODD，可以为这些系统的未来认证提供强有力的支持。"}}
{"id": "2601.22114", "pdf": "https://arxiv.org/pdf/2601.22114", "abs": "https://arxiv.org/abs/2601.22114", "authors": ["Saoud Aldowaish", "Yashwanth Karumanchi", "Kai-Chen Chiang", "Soroosh Noorzad", "Morteza Fayazi"], "title": "SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence", "categories": ["cs.CV", "cs.AI", "eess.SY"], "comment": null, "summary": "Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.", "AI": {"tldr": "本文提出了SINA，一种将电路图图像转换为机器可读网表的自动化工具。", "motivation": "现有的方法在处理电路图图像转网表时面临元器件识别和连接性推断的挑战。因此，开发了一种新的系统来提高准确性和效率。", "method": "SINA采用深度学习进行精确元件检测，使用连通分量标记（CCL）实现精准连线提取，并利用光学字符识别（OCR）技术获取参考标识符，同时通过视觉语言模型（VLM）确保可靠的参考标识符分配。", "result": "实验结果表明，SINA的网表生成准确率达到96.47%，相比现有最佳方法提高了2.72倍。", "conclusion": "SINA是一个开放源代码的电路图图像到机器可读网表的转换工具，能够有效提高电路设计效率和准确性。"}}
{"id": "2601.22108", "pdf": "https://arxiv.org/pdf/2601.22108", "abs": "https://arxiv.org/abs/2601.22108", "authors": ["Shuqi Ke", "Giulia Fanti"], "title": "Value-Based Pre-Training with Downstream Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Can a small amount of verified goal information steer the expensive self-supervised pretraining of foundation models? Standard pretraining optimizes a fixed proxy objective (e.g., next-token prediction), which can misallocate compute away from downstream capabilities of interest. We introduce V-Pretraining: a value-based, modality-agnostic method for controlled continued pretraining in which a lightweight task designer reshapes the pretraining task to maximize the value of each gradient step. For example, consider self-supervised learning (SSL) with sample augmentation. The V-Pretraining task designer selects pretraining tasks (e.g., augmentations) for which the pretraining loss gradient is aligned with a gradient computed over a downstream task (e.g., image segmentation). This helps steer pretraining towards relevant downstream capabilities. Notably, the pretrained model is never updated on downstream task labels; they are used only to shape the pretraining task. Under matched learner update budgets, V-Pretraining of 0.5B--7B language models improves reasoning (GSM8K test Pass@1) by up to 18% relative over standard next-token prediction using only 12% of GSM8K training examples as feedback. In vision SSL, we improve the state-of-the-art results on ADE20K by up to 1.07 mIoU and reduce NYUv2 RMSE while improving ImageNet linear accuracy, and we provide pilot evidence of improved token efficiency in continued pretraining.", "AI": {"tldr": "介绍了一种基于价值的预训练方法V-Pretraining，通过下游任务反馈优化预训练过程。", "motivation": "标准预训练使用固定的代理目标可能导致计算资源分配不当。希望通过引入新的方法来更好地利用少量验证的目标信息。", "method": "提出一种价值导向的方法，在不更新模型的情况下仅用下游任务的标签调整预训练过程，以提高模型在特定领域的表现能力。", "result": "通过实验验证了V-Pretraining可以显著提升语言和视觉任务上的性能。例如，在GSM8K测试中，相比传统方法提高了18%的表现。", "conclusion": "V-Pretraining是一种有效的预训练方法，能够利用少量下游反馈来改进模型的特定能力，提高计算效率和表现。"}}
