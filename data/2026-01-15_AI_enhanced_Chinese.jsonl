{"id": "2601.09708", "pdf": "https://arxiv.org/pdf/2601.09708", "abs": "https://arxiv.org/abs/2601.09708", "authors": ["Chi-Pin Huang", "Yunze Man", "Zhiding Yu", "Min-Hung Chen", "Jan Kautz", "Yu-Chiang Frank Wang", "Fu-En Yang"], "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Project page: https://jasper0314-huang.github.io/fast-thinkact/", "summary": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.", "AI": {"tldr": "本文提出了Fast-ThinkAct，一种高效的视觉语言行动推理框架，通过可理解的潜在规划实现紧凑而高效的计划。", "motivation": "尽管最近的研究表明，显式的思维链可以提升复杂场景下视觉语言行动任务的表现，但其推理过程耗时较长。因此，研究者希望通过提出新的方法来缩短推理时间同时保持高效表现。", "method": "Fast-ThinkAct通过从教师模型中提炼出可理解的潜在思维链，并使用偏好引导目标将语言和视觉规划能力转移到动作控制上，从而学习高效的潜在思维链。", "result": "实验结果显示，Fast-ThinkAct在多种基准测试中表现出色，推理延迟最多减少89.3%，同时保持了长期规划、快速适应能力和失败恢复的能力。", "conclusion": "研究证明，通过引入可理解的潜在推理和优化方法，可以在不牺牲性能的情况下显著降低复杂视觉语言行动任务中的推理时间。"}}
{"id": "2601.09706", "pdf": "https://arxiv.org/pdf/2601.09706", "abs": "https://arxiv.org/abs/2601.09706", "authors": ["Andreea Dutulescu", "Stefan Ruseti", "Mihai Dascalu"], "title": "Value-Aware Numerical Representations for Transformer Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. We introduce a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. This mechanism injects magnitude information directly into the model's input space while remaining compatible with existing tokenizers and decoder-only Transformer architectures. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths. These results indicate that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.", "AI": {"tldr": "提出了一种值感知的数值表示方法，以改进基于Transformer的语言模型在基础数字理解和算术操作上的表现。", "motivation": "现有的Transformer语言模型虽然在数学推理基准测试中表现出色，但在基本数值理解及算术运算上仍存在弱点，主要原因是这些模型未能将数值显式编码到嵌入空间中。", "method": "该方法通过使用一个专用于数值的前缀令牌，并且其嵌入明确依赖于相应的基础数值来增强标准分词输入。这种方法直接在模型输入空间中注入数值大小信息，同时保持与现有分词器和仅解码器的Transformer架构兼容。", "result": "实验结果表明，在算术任务上，所提出的方法优于基线方法，其表现跨越了不同的数值格式、任务类型及操作数长度。", "conclusion": "显式地编码数值是提高语言模型基础数值稳健性的有效且高效的方式。"}}
{"id": "2601.09703", "pdf": "https://arxiv.org/pdf/2601.09703", "abs": "https://arxiv.org/abs/2601.09703", "authors": ["Sicong Liu", "Yanxian Huang", "Mingwei Liu", "Jiachi Chen", "Ensheng Shi", "Yuchi Ma", "Hongyu Zhang", "Yin Zhang", "Yanlin Wang"], "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.", "AI": {"tldr": "提出了ShortCoder框架，通过语法简化规则和混合数据合成管道优化代码生成效率。", "motivation": "虽然大型语言模型提高了代码生成能力，但仍存在资源消耗问题。现有的研究更多关注于推理阶段的优化，而忽略了生成阶段的问题。", "method": "引入了十个基于AST保持变换的Python语法级别简化规则；构建了一个将规则重写与LLM引导细化结合的数据合成管道；提出了一种细粒度微调策略，以注入简洁性意识。", "result": "实验表明ShortCoder在HumanEval上比现有方法提高了18.1%-37.8%的生成效率，并且保证了代码生成性能。", "conclusion": "通过语法简化规则和混合数据合成管道，ShortCoder能够有效提高代码生成效率。"}}
{"id": "2601.09699", "pdf": "https://arxiv.org/pdf/2601.09699", "abs": "https://arxiv.org/abs/2601.09699", "authors": ["Ruiqi Shen", "Chang Liu", "Henghui Ding"], "title": "SAM3-DMS: Decoupled Memory Selection for Multi-target Video Segmentation of SAM3", "categories": ["cs.CV"], "comment": "Code: https://github.com/FudanCVL/SAM3-DMS", "summary": "Segment Anything 3 (SAM3) has established a powerful foundation that robustly detects, segments, and tracks specified targets in videos. However, in its original implementation, its group-level collective memory selection is suboptimal for complex multi-object scenarios, as it employs a synchronized decision across all concurrent targets conditioned on their average performance, often overlooking individual reliability. To this end, we propose SAM3-DMS, a training-free decoupled strategy that utilizes fine-grained memory selection on individual objects. Experiments demonstrate that our approach achieves robust identity preservation and tracking stability. Notably, our advantage becomes more pronounced with increased target density, establishing a solid foundation for simultaneous multi-target video segmentation in the wild.", "AI": {"tldr": "本文提出了SAM3-DMS，一种无训练的解耦策略，用于多目标视频分割中的细粒度内存选择。", "motivation": "原始的SAM3在复杂多对象场景中使用同步决策，基于平均性能做出决定，这往往忽视了个体对象的可靠性。", "method": "提出了SAM3-DMS，一种无训练的解耦策略，利用针对每个单独目标的细粒度内存选择来提高识别和跟踪性能。", "result": "实验表明该方法在保持身份一致性和追踪稳定性方面表现出色，并且随着目标密度的增加优势更加明显。", "conclusion": "SAM3-DMS为野外同时多目标视频分割奠定了坚实的基础。"}}
{"id": "2601.09698", "pdf": "https://arxiv.org/pdf/2601.09698", "abs": "https://arxiv.org/abs/2601.09698", "authors": ["Tony Danjun Wang", "Tolga Birdal", "Nassir Navab", "Lennart Bastian"], "title": "COMPOSE: Hypergraph Cover Optimization for Multi-view 3D Human Pose Estimation", "categories": ["cs.CV"], "comment": null, "summary": "3D pose estimation from sparse multi-views is a critical task for numerous applications, including action recognition, sports analysis, and human-robot interaction. Optimization-based methods typically follow a two-stage pipeline, first detecting 2D keypoints in each view and then associating these detections across views to triangulate the 3D pose. Existing methods rely on mere pairwise associations to model this correspondence problem, treating global consistency between views (i.e., cycle consistency) as a soft constraint. Yet, reconciling these constraints for multiple views becomes brittle when spurious associations propagate errors. We thus propose COMPOSE, a novel framework that formulates multi-view pose correspondence matching as a hypergraph partitioning problem rather than through pairwise association. While the complexity of the resulting integer linear program grows exponentially in theory, we introduce an efficient geometric pruning strategy to substantially reduce the search space. COMPOSE achieves improvements of up to 23% in average precision over previous optimization-based methods and up to 11% over self-supervised end-to-end learned methods, offering a promising solution to a widely studied problem.", "AI": {"tldr": "该论文介绍了COMPOSE框架，用于多视角下的三维人体姿态估计。", "motivation": "现有的方法依赖于两阶段的流程进行3D姿态估计，但是这种基于配对关联的方法在处理多个视图时容易产生误差传播。", "method": "COMPOSE将跨视角的姿态对应匹配问题转化为超图划分问题，并提出一种高效的几何剪枝策略来减少搜索空间。", "result": "该方法在平均精度上相比以前的优化方法提高了最多23%，比自我监督端到端学习的方法提高了最多11%。", "conclusion": "COMPOSE为多视角下的三维姿态估计提供了一个有前景的解决方案，显著提升了准确度。"}}
{"id": "2601.09697", "pdf": "https://arxiv.org/pdf/2601.09697", "abs": "https://arxiv.org/abs/2601.09697", "authors": ["Jieying Chen", "Jeffrey Hu", "Joan Lasenby", "Ayush Tewari"], "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering", "categories": ["cs.CV"], "comment": "Project page: https://ayushtewari.com/projects/srender/", "summary": "Modern video generative models based on diffusion models can produce very realistic clips, but they are computationally inefficient, often requiring minutes of GPU time for just a few seconds of video. This inefficiency poses a critical barrier to deploying generative video in applications that require real-time interactions, such as embodied AI and VR/AR. This paper explores a new strategy for camera-conditioned video generation of static scenes: using diffusion-based generative models to generate a sparse set of keyframes, and then synthesizing the full video through 3D reconstruction and rendering. By lifting keyframes into a 3D representation and rendering intermediate views, our approach amortizes the generation cost across hundreds of frames while enforcing geometric consistency. We further introduce a model that predicts the optimal number of keyframes for a given camera trajectory, allowing the system to adaptively allocate computation. Our final method, SRENDER, uses very sparse keyframes for simple trajectories and denser ones for complex camera motion. This results in video generation that is more than 40 times faster than the diffusion-based baseline in generating 20 seconds of video, while maintaining high visual fidelity and temporal stability, offering a practical path toward efficient and controllable video synthesis.", "AI": {"tldr": "本文提出了一种通过稀疏扩散和三维渲染来生成静态场景的高效相机控制视频的方法。", "motivation": "现代基于扩散模型的视频生成模型计算效率低下，难以应用于需要实时互动的应用程序中，如AI嵌入式应用和VR/AR技术。", "method": "本文提出了一种新的策略：使用扩散模型生成一组稀疏的关键帧，并通过三维重建和渲染来合成完整视频。同时引入了一个预测给定相机轨迹所需关键帧数目的模型。", "result": "最终方法SRENDER在生成20秒的视频时，比基于扩散模型的基本线生成速度快了40倍以上，且保持了高视觉保真度和时间稳定性。", "conclusion": "该研究为实现高效可控的视频合成提供了一条实用途径，并解决了现有视频生成模型计算效率低下的问题。"}}
{"id": "2601.09694", "pdf": "https://arxiv.org/pdf/2601.09694", "abs": "https://arxiv.org/abs/2601.09694", "authors": ["Sai Varun Kodathala", "Rakesh Vunnam"], "title": "LLMs can Compress LLMs: Adaptive Pruning by Agents", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "17 Pages", "summary": "As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. We introduce agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. We evaluate our approach on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19x better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.", "AI": {"tldr": "介绍了一种基于智能代理的自适应剪枝方法，用于优化大语言模型以减少计算成本并保留性能。", "motivation": "现有的剪枝技术依赖于统一或手工设计的启发式策略，导致被剪枝的大语言模型在事实知识方面存在显著退化。因此，需要一种更有效的剪枝方法来保持模型的知识和性能。", "method": "提出了一种智能代理引导的自适应剪枝方法，该方法使用大语言模型作为代理，在每个迭代中选择要剪枝的层，并保留关键的知识路径。通过结合权重激活度量与梯度重要性得分构建层敏感度轮廓图，并用具有自我反思能力的大语言模型处理这些统计信息。", "result": "在Qwen3模型（4B和8B参数）上评估，该方法在大约45%的稀疏度下显示出显著改进：MMLU准确率相对提高56%，FreebaseQA上的事实知识保留提升19倍，困惑度下降69%。", "conclusion": "框架无需重新训练，并且可以跨模型进行操作。实验表明大语言模型能够有效地引导其他大语言模型的压缩过程，显示出有效的自我纠正机制，并在迭代过程中仅需2-4次回滚。"}}
{"id": "2601.09692", "pdf": "https://arxiv.org/pdf/2601.09692", "abs": "https://arxiv.org/abs/2601.09692", "authors": ["Tianyi Niu", "Justin Chih-Yao Chen", "Genta Indra Winata", "Shi-Xiong Zhang", "Supriyo Chakraborty", "Sambit Sahu", "Yue Zhang", "Elias Stengel-Eskin", "Mohit Bansal"], "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code: https://github.com/tianyiniu/RoutingGenData", "summary": "Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers (using both queries and labels) and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.", "AI": {"tldr": "本文提出了一种无需标注数据的大型语言模型（LLM）路由方法，通过生成的数据来评估和选择模型。", "motivation": "现有的路由方法通常依赖于地面真实标签数据，但在实践中这些数据往往是不可用的。为了在没有标签的情况下实现有效的模型选择，作者提出了使用生成数据的方法。", "method": "文章介绍了Routing with Generated Data（RGD）框架，并提出了CASCAL路由器，该路由器通过共识投票估计模型正确性并通过层次聚类识别特定技能领域。", "result": "实验表明，在四个不同的基准测试和12个模型上，当生成器质量下降时，查询-答案路由的性能更快地退化。而CASCAL在使用弱生成数据训练时，比最佳的查询-答案路由器高出4.6%绝对准确率。", "conclusion": "研究揭示了有效生成器的重要特征，并展示了如何通过过滤这些特征来提高生成数据的质量。此外，提出的CASCAL方法对于生成器质量的鲁棒性更强。"}}
{"id": "2601.09684", "pdf": "https://arxiv.org/pdf/2601.09684", "abs": "https://arxiv.org/abs/2601.09684", "authors": ["Ziyu Yang", "Guibin Chen", "Yuxin Yang", "Aoxiong Zeng", "Xiangquan Yang"], "title": "Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "preprint", "summary": "Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.", "AI": {"tldr": "本文提出Ortho-LoRA方法，通过梯度投影减少多任务学习中Low-Rank适应（LoRA）的冲突，提高性能。", "motivation": "结合多任务学习和低秩适应技术虽然可以降低大型语言模型的参数存储开销，但会因不同任务之间的负迁移导致单任务表现下降。", "method": "提出Ortho-LoRA方法，动态将任务间的冲突梯度投影到彼此正交的子空间中。", "result": "实验显示，Ortho-LoRA有效减轻了任务干扰，并在GLUE基准测试上恢复了接近95%的多任务与单任务基线之间的性能差距，且计算开销可忽略。", "conclusion": "Ortho-LoRA方法显著提升了多任务学习中Low-Rank适应技术的效果，减少了由于任务冲突引起的性能下降。"}}
{"id": "2601.09680", "pdf": "https://arxiv.org/pdf/2601.09680", "abs": "https://arxiv.org/abs/2601.09680", "authors": ["Sara AlMahri", "Liming Xu", "Alexandra Brintrup"], "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach", "categories": ["cs.AI"], "comment": null, "summary": "Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \\rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \\$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.", "AI": {"tldr": "本文介绍了一个最小监督的代理AI框架，它能自主监控、分析和应对扩展供应链网络中的中断。", "motivation": "现代供应链面临多种干扰，公司缺乏对上游供应商的可见性。为克服这一盲点并实现从被动恢复到主动韧性，提出了该框架。", "method": "架构包括七个由大型语言模型和确定性工具驱动的专门代理，它们联合检测新闻中的中断信号，将其映射到多级供应商网络，并根据网络结构评估暴露情况，推荐缓解措施如替代采购选项。", "result": "在30个合成场景中进行测试，覆盖三家汽车制造商及五类干扰。系统核心任务准确度高，F1分数介于0.962至0.991之间，平均分析时间仅3.83分钟，成本为每次中断0.0836美元，相对行业基准反应时间减少了三个数量级。", "conclusion": "该研究奠定了一步基础，旨在构建能够管理深层次网络干扰的弹性和自主供应链。"}}
{"id": "2601.09668", "pdf": "https://arxiv.org/pdf/2601.09668", "abs": "https://arxiv.org/abs/2601.09668", "authors": ["Ailin Huang", "Chengyuan Yao", "Chunrui Han", "Fanqi Wan", "Hangyu Guo", "Haoran Lv", "Hongyu Zhou", "Jia Wang", "Jian Zhou", "Jianjian Sun", "Jingcheng Hu", "Kangheng Lin", "Liang Zhao", "Mitt Huang", "Song Yuan", "Wenwen Qu", "Xiangfeng Wang", "Yanlin Lai", "Yingxiu Zhao", "Yinmin Zhang", "Yukang Shi", "Yuyang Chen", "Zejia Weng", "Ziyang Meng", "Ang Li", "et al. (68 additional authors not shown)"], "title": "STEP3-VL-10B Technical Report", "categories": ["cs.CV"], "comment": "50 pages", "summary": "We present STEP3-VL-10B, a lightweight open-source foundation model designed to redefine the trade-off between compact efficiency and frontier-level multimodal intelligence. STEP3-VL-10B is realized through two strategic shifts: first, a unified, fully unfrozen pre-training strategy on 1.2T multimodal tokens that integrates a language-aligned Perception Encoder with a Qwen3-8B decoder to establish intrinsic vision-language synergy; and second, a scaled post-training pipeline featuring over 1k iterations of reinforcement learning. Crucially, we implement Parallel Coordinated Reasoning (PaCoRe) to scale test-time compute, allocating resources to scalable perceptual reasoning that explores and synthesizes diverse visual hypotheses. Consequently, despite its compact 10B footprint, STEP3-VL-10B rivals or surpasses models 10$\\times$-20$\\times$ larger (e.g., GLM-4.6V-106B, Qwen3-VL-235B) and top-tier proprietary flagships like Gemini 2.5 Pro and Seed-1.5-VL. Delivering best-in-class performance, it records 92.2% on MMBench and 80.11% on MMMU, while excelling in complex reasoning with 94.43% on AIME2025 and 75.95% on MathVision. We release the full model suite to provide the community with a powerful, efficient, and reproducible baseline.", "AI": {"tldr": "介绍STEP3-VL-10B，一个轻量级开源基础模型，旨在重新定义紧凑性和多模态智能之间的平衡。", "motivation": "动机在于设计一种在效率和多模态智能之间取得良好平衡的模型，能够与更大规模的专有旗舰产品竞争。", "method": "通过统一全解冻预训练策略整合语言对齐感知编码器和Qwen3-8B解码器，并采用扩展后的后训练管道进行超过1000次迭代的强化学习。同时实施并行协同推理（PaCoRe）以分配资源到可扩展的认知推理。", "result": "尽管模型大小仅为10B，STEP3-VL-10B在MMBench和MMMU上分别达到92.2%和80.11%，并在复杂推理任务AIME2025和MathVision上表现优异，得分分别为94.43%和75.95%。", "conclusion": "该模型提供了强大的、高效的和可重复的基准，并且在性能方面与更大规模的专有旗舰产品相媲美甚至超越。"}}
{"id": "2601.09667", "pdf": "https://arxiv.org/pdf/2601.09667", "abs": "https://arxiv.org/abs/2601.09667", "authors": ["Zhiyuan Hu", "Yunhai Hu", "Juncheng Liu", "Shuyue Stella Li", "Yucheng Wang", "Zhen Xu", "See-Kiong Ng", "Anh Tuan Luu", "Xinxing Xu", "Bryan Hooi", "Cynthia Breazeal", "Hae Won Park"], "title": "Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Work in Progress", "summary": "Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \\textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\\% over a multi-agent baseline, and by 8.67\\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.", "AI": {"tldr": "本文提出了Multi-Agent Test-Time Reinforcement Learning（MATTRL）框架，通过在推理时注入结构化文本经验来改进多智能体系统中的决策。", "motivation": "多智能体强化学习训练资源密集且不稳定，团队成员的共同适应会导致非平稳性，奖励稀疏且方差高。因此需要一种更稳定和有效的多智能体决策方法。", "method": "MATTRL框架形成一个多专家团队，在推理时检索并整合经验，通过多回合讨论达成共识进行最终决策，并研究了如何分配信用以构建回合级别的经验池，再将这些经验重新注入对话中。", "result": "实验表明，与多智能体基线相比，MATTRL在医学、数学和教育等挑战性基准上提高了3.67%的准确率；与单一智能体基线相比，提高了8.67%。消融研究分析了不同信用分配方案的影响。", "conclusion": "MATTRL提供了一条稳定且高效地实现分布偏移鲁棒多智能体推理的道路，无需进行额外调优。"}}
{"id": "2601.09665", "pdf": "https://arxiv.org/pdf/2601.09665", "abs": "https://arxiv.org/abs/2601.09665", "authors": ["Yuchen Wu", "Jiahe Li", "Xiaohan Yu", "Lina Yu", "Jin Zheng", "Xiao Bai"], "title": "SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings", "categories": ["cs.CV"], "comment": null, "summary": "Monocular visual SLAM enables 3D reconstruction from internet video and autonomous navigation on resource-constrained platforms, yet suffers from scale drift, i.e., the gradual divergence of estimated scale over long sequences. Existing frame-to-frame methods achieve real-time performance through local optimization but accumulate scale drift due to the lack of global constraints among independent windows. To address this, we propose SCE-SLAM, an end-to-end SLAM system that maintains scale consistency through scene coordinate embeddings, which are learned patch-level representations encoding 3D geometric relationships under a canonical scale reference. The framework consists of two key modules: geometry-guided aggregation that leverages 3D spatial proximity to propagate scale information from historical observations through geometry-modulated attention, and scene coordinate bundle adjustment that anchors current estimates to the reference scale through explicit 3D coordinate constraints decoded from the scene coordinate embeddings. Experiments on KITTI, Waymo, and vKITTI demonstrate substantial improvements: our method reduces absolute trajectory error by 8.36m on KITTI compared to the best prior approach, while maintaining 36 FPS and achieving scale consistency across large-scale scenes.", "AI": {"tldr": "本文提出SCE-SLAM，一种通过场景坐标嵌入实现尺度一致性的单目SLAM系统。", "motivation": "旨在解决现有单目视觉SLAM方法在长时间序列中由于缺乏全局约束而导致的尺度漂移问题。", "method": "该方法包含两个关键模块：几何引导聚合和场景坐标捆绑调整。通过学习编码3D几何关系的嵌入来传递历史观测中的尺度信息，并通过显式3D坐标约束将当前估计锚定到参考尺度。", "result": "实验结果表明，与现有最佳方法相比，SCE-SLAM在KITTI数据集上减少绝对轨迹误差8.36米，同时保持36 FPS的实时性能并实现大规模场景中的尺度一致性。", "conclusion": "通过使用场景坐标嵌入和几何引导聚合等技术，SCE-SLAM显著改善了单目SLAM系统的尺度一致性问题。"}}
{"id": "2601.09663", "pdf": "https://arxiv.org/pdf/2601.09663", "abs": "https://arxiv.org/abs/2601.09663", "authors": ["Xuyang Fang", "Sion Hannuna", "Edwin Simpson", "Neill Campbell"], "title": "Self-Supervised Animal Identification for Long Videos", "categories": ["cs.CV"], "comment": "11 pages, 1 figure", "summary": "Identifying individual animals in long-duration videos is essential for behavioral ecology, wildlife monitoring, and livestock management. Traditional methods require extensive manual annotation, while existing self-supervised approaches are computationally demanding and ill-suited for long sequences due to memory constraints and temporal error propagation. We introduce a highly efficient, self-supervised method that reframes animal identification as a global clustering task rather than a sequential tracking problem. Our approach assumes a known, fixed number of individuals within a single video -- a common scenario in practice -- and requires only bounding box detections and the total count. By sampling pairs of frames, using a frozen pre-trained backbone, and employing a self-bootstrapping mechanism with the Hungarian algorithm for in-batch pseudo-label assignment, our method learns discriminative features without identity labels. We adapt a Binary Cross Entropy loss from vision-language models, enabling state-of-the-art accuracy ($>$97\\%) while consuming less than 1 GB of GPU memory per batch -- an order of magnitude less than standard contrastive methods. Evaluated on challenging real-world datasets (3D-POP pigeons and 8-calves feeding videos), our framework matches or surpasses supervised baselines trained on over 1,000 labeled frames, effectively removing the manual annotation bottleneck. This work enables practical, high-accuracy animal identification on consumer-grade hardware, with broad applicability in resource-constrained research settings. All code written for this paper are \\href{https://huggingface.co/datasets/tonyFang04/8-calves}{here}.", "AI": {"tldr": "本文提出了一种高效的自我监督方法，用于长时间视频中的动物个体识别。", "motivation": "传统的动物个体识别方法需要大量的手动标注，而现有的自监督方法由于计算需求高和内存限制问题不太适合处理长时间序列的视频。", "method": "该方法将动物识别重新定义为全局聚类任务，而不是顺序跟踪问题，并通过抽样帧对、使用冻结预训练模型主干以及采用匈牙利算法进行批内伪标签分配来学习区分特征。", "result": "在3D-POP鸽子和8头牛喂食视频等具有挑战性的现实世界数据集上，该方法达到了超过97%的准确率，同时仅需1GB GPU内存每批次，性能匹配或超越了训练过千张标注图像的监督基线。", "conclusion": "这项工作使得在消费级硬件上进行高精度动物个体识别成为可能，并且广泛适用于资源受限的研究环境。"}}
{"id": "2601.09661", "pdf": "https://arxiv.org/pdf/2601.09661", "abs": "https://arxiv.org/abs/2601.09661", "authors": ["Aishwarya Agarwal", "Srikrishna Karanam", "Vineet Gandhi"], "title": "LiteEmbed: Adapting CLIP to Rare Classes", "categories": ["cs.CV"], "comment": "14 pages, 12 figures", "summary": "Large-scale vision-language models such as CLIP achieve strong zero-shot recognition but struggle with classes that are rarely seen during pretraining, including newly emerging entities and culturally specific categories. We introduce LiteEmbed, a lightweight framework for few-shot personalization of CLIP that enables new classes to be added without retraining its encoders. LiteEmbed performs subspace-guided optimization of text embeddings within CLIP's vocabulary, leveraging a PCA-based decomposition that disentangles coarse semantic directions from fine-grained variations. Two complementary objectives, coarse alignment and fine separation, jointly preserve global semantic consistency while enhancing discriminability among visually similar classes. Once optimized, the embeddings are plug-and-play, seamlessly substituting CLIP's original text features across classification, retrieval, segmentation, and detection tasks. Extensive experiments demonstrate substantial gains over prior methods, establishing LiteEmbed as an effective approach for adapting CLIP to underrepresented, rare, or unseen classes.", "AI": {"tldr": "LiteEmbed 是一个轻量级框架，用于对 CLIP 进行少量样本个性化处理，使新类别无需重新训练编码器即可添加。", "motivation": "大型的视觉语言模型如CLIP在零样本识别中表现出色，但在预训练期间很少看到的类别的识别效果不佳。这包括新兴实体和文化特定类别。", "method": "LiteEmbed 使用子空间引导优化 CLIP 的词汇表中的文本嵌入，并利用 PCA 基于分解分离粗略语义方向与细粒度变化，通过两种互补目标（粗对齐与细分割）来保持全局语义一致性并增强视觉相似类别之间的可辨别性。", "result": "广泛的实验表明，与先前方法相比，LiteEmbed 在分类、检索、分割和检测任务上取得了显著的改进。", "conclusion": "LiteEmbed 是一种有效的适应 CLIP 方法，用于处理未充分代表、罕见或未知类别的问题。"}}
{"id": "2601.09658", "pdf": "https://arxiv.org/pdf/2601.09658", "abs": "https://arxiv.org/abs/2601.09658", "authors": ["Selim Emir Can", "Jan Ackermann", "Kiyohiro Nakayama", "Ruofan Liu", "Tong Wu", "Yang Zheng", "Hugo Bertiche", "Menglei Chai", "Thabo Beeler", "Gordon Wetzstein"], "title": "Image2Garment: Simulation-ready Garment Generation from a Single Image", "categories": ["cs.CV"], "comment": null, "summary": "Estimating physically accurate, simulation-ready garments from a single image is challenging due to the absence of image-to-physics datasets and the ill-posed nature of this problem. Prior methods either require multi-view capture and expensive differentiable simulation or predict only garment geometry without the material properties required for realistic simulation. We propose a feed-forward framework that sidesteps these limitations by first fine-tuning a vision-language model to infer material composition and fabric attributes from real images, and then training a lightweight predictor that maps these attributes to the corresponding physical fabric parameters using a small dataset of material-physics measurements. Our approach introduces two new datasets (FTAG and T2P) and delivers simulation-ready garments from a single image without iterative optimization. Experiments show that our estimator achieves superior accuracy in material composition estimation and fabric attribute prediction, and by passing them through our physics parameter estimator, we further achieve higher-fidelity simulations compared to state-of-the-art image-to-garment methods.", "AI": {"tldr": "从单张图像生成可用于物理模拟的服装。", "motivation": "由于缺乏图像到物理特性的数据集以及该问题固有的多解性，直接从单个图像估计物理上准确且适合模拟的衣物具有挑战性。现有方法要么需要多视角捕获和昂贵的可微分模拟，要么只能预测服装几何形状而忽视了用于真实模拟所需的材质属性。", "method": "提出了一种前馈框架，首先通过微调视觉语言模型从实际图像中推断材料成分和织物属性，然后使用小规模的材料物理测量数据集训练一个轻量级预测器将这些属性映射到相应的物理布料参数。", "result": "实验表明，该方法在材质组成估计和面料特性预测方面达到了更高的精度，并且通过其物理参数估计器实现更高保真度的模拟效果，优于现有的图像到服装的方法。", "conclusion": "提出的新框架和数据集（FTAG和T2P）成功实现了从单张图像生成适合物理模拟的服装，无需迭代优化过程。"}}
{"id": "2601.09652", "pdf": "https://arxiv.org/pdf/2601.09652", "abs": "https://arxiv.org/abs/2601.09652", "authors": ["Emanuel da Costa Silva", "Tatiana Taís Schein", "José David García Ramos", "Eduardo Lawson da Silva", "Stephanie Loi Brião", "Felipe Gomes de Oliveira", "Paulo Lilles Jorge Drews-Jr"], "title": "AquaFeat+: an Underwater Vision Learning-based Enhancement Method for Object Detection, Classification, and Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Underwater video analysis is particularly challenging due to factors such as low lighting, color distortion, and turbidity, which compromise visual data quality and directly impact the performance of perception modules in robotic applications. This work proposes AquaFeat+, a plug-and-play pipeline designed to enhance features specifically for automated vision tasks, rather than for human perceptual quality. The architecture includes modules for color correction, hierarchical feature enhancement, and an adaptive residual output, which are trained end-to-end and guided directly by the loss function of the final application. Trained and evaluated in the FishTrack23 dataset, AquaFeat+ achieves significant improvements in object detection, classification, and tracking metrics, validating its effectiveness for enhancing perception tasks in underwater robotic applications.", "AI": {"tldr": "AquaFeat+是一种用于增强水下视觉任务（如目标检测、分类和跟踪）的端到端学习方法。", "motivation": "由于低光照、色彩失真和混浊等因素，水下视频分析面临挑战。这些因素影响了机器人应用中感知模块的表现，因此需要一种能够提高自动化视觉任务效果的方法。", "method": "AquaFeat+包括颜色校正模块、分层特征增强模块以及自适应残差输出模块，所有模块都是端到端训练并且直接由最终应用场景的损失函数引导。", "result": "在FishTrack23数据集上的测试表明，AquaFeat+显著提升了目标检测、分类和跟踪的效果，验证了其对于水下机器人感知任务的有效性。", "conclusion": "通过实验结果证明，AquaFeat+能有效提升自动化视觉任务的表现，特别是针对水下环境中的挑战。"}}
{"id": "2601.09647", "pdf": "https://arxiv.org/pdf/2601.09647", "abs": "https://arxiv.org/abs/2601.09647", "authors": ["Ali Naseh", "Yuefeng Peng", "Anshuman Suri", "Harsh Chaudhari", "Alina Oprea", "Amir Houmansadr"], "title": "Identifying Models Behind Text-to-Image Leaderboards", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": null, "summary": "Text-to-image (T2I) models are increasingly popular, producing a large share of AI-generated images online. To compare model quality, voting-based leaderboards have become the standard, relying on anonymized model outputs for fairness. In this work, we show that such anonymity can be easily broken. We find that generations from each T2I model form distinctive clusters in the image embedding space, enabling accurate deanonymization without prompt control or training data. Using 22 models and 280 prompts (150K images), our centroid-based method achieves high accuracy and reveals systematic model-specific signatures. We further introduce a prompt-level distinguishability metric and conduct large-scale analyses showing how certain prompts can lead to near-perfect distinguishability. Our findings expose fundamental security flaws in T2I leaderboards and motivate stronger anonymization defenses.", "AI": {"tldr": "本文主要任务是揭示文本到图像模型在排行榜中的匿名性问题。", "motivation": "文本到图像（T2I）模型广泛用于生成AI图片，为了公平比较模型质量采用了匿名化的排行榜。本文动机在于探讨这种匿名是否能够被打破，以暴露潜在的系统安全漏洞并促使更强的匿名化防御措施。", "method": "通过在图像嵌入空间中找到来自每个T2I模型生成的独特集群，使用中心点基于的方法实现了高准确率的去匿名化处理。同时引入了一个区分度指标，在大规模分析过程中展示某些提示词如何导致近乎完美的可区分性。", "result": "研究结果表明，该方法能够实现高度准确的去匿名化，并揭示了系统性的模型特定特征。通过22个模型和280个提示（共计15万个图像）的大规模实验验证了这一发现的有效性。", "conclusion": "本文的研究揭露了T2I排行榜中根本的安全漏洞，强调需要更加严格的方法来保护模型的匿名性，并提出了一些改进的方向。"}}
{"id": "2601.09636", "pdf": "https://arxiv.org/pdf/2601.09636", "abs": "https://arxiv.org/abs/2601.09636", "authors": ["Yibo Lyu", "Gongwei Chen", "Rui Shao", "Weili Guan", "Liqiang Nie"], "title": "PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records", "categories": ["cs.AI", "cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. To facilitate this study, we introduce AndroidIntent, a benchmark designed to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. We annotated 775 user-specific preferences and 215 routines from 20k long-term records across different users for evaluation. Furthermore, we introduce Hierarchical Intent Memory Agent (HIM-Agent), which maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. Finally, we evaluate a range of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, further results show that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.", "AI": {"tldr": "本文提出了PersonalAlign，通过长期用户记录解决GUI代理在处理模糊指令和主动辅助时的挑战。", "motivation": "现有GUI代理在明确指令下表现良好，但在实际应用中需要更好地理解用户的隐性意图，特别是在处理模糊指令和提供主动帮助方面。", "method": "引入了AndroidIntent基准来评估代理解决模糊指令和提供主动建议的能力，并提出了HIM-Agent，利用持续更新的个人记忆来组织用户偏好和习惯。", "result": "实验结果显示，在AndroidIntent基准测试中，HIM-Agent在执行任务和主动性上分别提高了15.7%和7.3%。", "conclusion": "研究证明了Hierarchical Implicit Intent Alignment的重要性，并展示了HIM-Agent在处理长期用户记录以改善GUI代理性能方面的有效性。"}}
{"id": "2601.09635", "pdf": "https://arxiv.org/pdf/2601.09635", "abs": "https://arxiv.org/abs/2601.09635", "authors": ["Kuo Liang", "Yuhang Lu", "Jianming Mao", "Shuyi Sun", "Chunwei Yang", "Congcong Zeng", "Xiao Jin", "Hanzhang Qin", "Ruihao Zhu", "Chung-Piaw Teo"], "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "categories": ["cs.AI", "cs.LG"], "comment": "Updated version of https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5329027", "summary": "Large-scale optimization is a key backbone of modern business decision-making. However, building these models is often labor-intensive and time-consuming. We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation. LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation. Specifically, upon receiving a query, two upstream LLM agents dynamically construct a workflow that specifies, step-by-step, how optimization models for similar problems can be formulated. A downstream LLM agent then follows this workflow to generate the final output. Leveraging LLMs' text-processing capabilities and common modeling practices, the workflow decomposes the modeling task into a sequence of structured sub-tasks and offloads mechanical data-handling operations to auxiliary tools. This design alleviates the downstream agent's burden related to planning and data handling, allowing it to focus on the most challenging components that cannot be readily standardized. Extensive simulations show that LEAN-LLM-OPT, instantiated with GPT-4.1 and the open source gpt-oss-20B, achieves strong performance on large-scale optimization modeling tasks and is competitive with state-of-the-art approaches. In addition, in a Singapore Airlines choice-based revenue management use case, LEAN-LLM-OPT demonstrates practical value by achieving leading performance across a range of scenarios. Along the way, we introduce Large-Scale-OR and Air-NRM, the first comprehensive benchmarks for large-scale optimization auto-formulation. The code and data of this work is available at https://github.com/CoraLiang01/lean-llm-opt.", "AI": {"tldr": "本文提出了LEAN-LLM-OPT，一种用于大规模优化模型自动构建的轻量级少样本学习框架。", "motivation": "大型优化问题在现代商业决策中至关重要，但建模过程既耗时又费力。本文旨在解决这一难题，通过自动化方法提高效率。", "method": "LEAN-LLM-OPT利用多个语言模型代理（LLM agents）协作构建优化模型工作流，并将数据处理任务分配给辅助工具以减轻负担。", "result": "实验表明，使用GPT-4.1和开源gpt-oss-20B的LEAN-LLM-OPT在大规模优化建模任务上表现出色，且在新加坡航空公司基于选择的收益管理案例中展示了实际应用价值。", "conclusion": "本文提出的方法证明了其在处理大型优化问题上的有效性和竞争力，并为该领域引入了新的基准测试。"}}
{"id": "2601.09632", "pdf": "https://arxiv.org/pdf/2601.09632", "abs": "https://arxiv.org/abs/2601.09632", "authors": ["Rose Connolly", "Victor Zordan", "Rachel McDonnell"], "title": "Perceptually-Guided Adjusted Teleporting: Perceptual Thresholds for Teleport Displacements in Virtual Environments", "categories": ["cs.HC"], "comment": "9 pages. to be published in IEEE VR conference proceedings 2026", "summary": "Teleportation is one of the most common locomotion techniques in virtual reality, yet its perceptual properties remain underexplored. While redirected walking research has shown that users' movements can be subtly manipulated without detection, similar imperceptible adjustments for teleportation have not been systematically investigated. This study examines the thresholds at which teleportation displacements become noticeable to users. We conducted a repeated-measures experiment in which participants' selected teleport destinations were altered in both direction (forwards, backwards) and at different ranges (small, large). Detection thresholds for these positional adjustments were estimated using a psychophysical staircase method with a two-alternative forced choice (2AFC) task. Results show that teleport destinations can be shifted without detection, with larger tolerances for backward adjustments and across longer teleport ranges. These findings establish baseline perceptual limits for redirected teleportation and highlight its potential as a design technique. Applications include supporting interpersonal distance management in social VR, guiding players toward objectives in games, and assisting novice users with navigation. By identifying the limits of imperceptible teleportation adjustments, this work extends redirection principles beyond walking to teleportation and opens new opportunities for adaptive and socially aware VR locomotion systems.", "AI": {"tldr": "研究了虚拟环境中用户对瞬移位移的感知阈值。", "motivation": "尽管瞬移是虚拟现实中最常见的移动技术，但其感知属性尚未得到充分探索。该研究旨在系统地调查瞬移中的不可察觉调整。", "method": "通过重复测量实验，在不同的方向（前后）和不同范围（小、大）下改变参与者选择的瞬移目的地，并使用心理物理学阶梯法和二选一任务估计位置调整的检测阈值。", "result": "发现可以不被用户察觉地调整瞬移目标，且在向后调整和更长的距离上具有更大的容差。", "conclusion": "研究建立了重定向瞬移的基本感知极限，并强调了其作为设计技术的潜力。这些发现扩展了重定向原则的应用范围，为自适应和社会意识的虚拟现实移动系统开辟了新机会。"}}
{"id": "2601.09626", "pdf": "https://arxiv.org/pdf/2601.09626", "abs": "https://arxiv.org/abs/2601.09626", "authors": ["Ge Lei", "Ferran Brosa Planella", "Sterling G. Baird", "Samuel J. Cooper"], "title": "From Prompt to Protocol: Fast Charging Batteries with Large Language Models", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "Efficiently optimizing battery charging protocols is challenging because each evaluation is slow, costly, and non-differentiable. Many existing approaches address this difficulty by heavily constraining the protocol search space, which limits the diversity of protocols that can be explored, preventing the discovery of higher-performing solutions. We introduce two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O), which uses an LLM to propose the code for small neural-network-based protocols, which are then trained by an inner loop, and Prompt-to-Protocol (P2P), which simply writes an explicit function for the current and its scalar parameters. Across our case studies, LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In a realistic fast charging scenario, both P2O and P2P yield around a 4.2 percent improvement in state of health (capacity retention based health metric under fast charging cycling) over a state-of-the-art multi-step constant current (CC) baseline, with P2P achieving this under matched evaluation budgets (same number of protocol evaluations). These results demonstrate that LLMs can expand the space of protocol functional forms, incorporate language-based constraints, and enable efficient optimization in high cost experimental settings.", "AI": {"tldr": "使用大型语言模型（LLM）驱动的闭合环路方法优化电池充电协议。", "motivation": "现有方法在优化电池充电协议时受限于搜索空间，限制了可探索方案的多样性，难以发现性能更高的解决方案。", "method": "提出两种无梯度的方法：Prompt-to-Optimizer (P2O) 和 Prompt-to-Protocol (P2P)，利用LLM生成代码或直接写出明确函数来优化充电协议。", "result": "实验表明，在真实快速充电场景中，这两种方法都能使电池健康状态（容量保持能力）提高约4.2%，优于现有的多步恒流基线。特别是，P2P在相同的评估预算下也能达到这一提升。", "conclusion": "大型语言模型能够扩展协议函数形式的空间、融入基于语言的约束，并实现高成本实验环境中的高效优化。"}}
{"id": "2601.09625", "pdf": "https://arxiv.org/pdf/2601.09625", "abs": "https://arxiv.org/abs/2601.09625", "authors": ["Ben Nassi", "Bruce Schneier", "Oleg Brodt"], "title": "The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The rapid adoption of large language model (LLM)-based systems -- from chatbots to autonomous agents capable of executing code and financial transactions -- has created a new attack surface that existing security frameworks inadequately address. The dominant framing of these threats as \"prompt injection\" -- a catch-all phrase for security failures in LLM-based systems -- obscures a more complex reality: Attacks on LLM-based systems increasingly involve multi-step sequences that mirror traditional malware campaigns. In this paper, we propose that attacks targeting LLM-based applications constitute a distinct class of malware, which we term \\textit{promptware}, and introduce a five-step kill chain model for analyzing these threats. The framework comprises Initial Access (prompt injection), Privilege Escalation (jailbreaking), Persistence (memory and retrieval poisoning), Lateral Movement (cross-system and cross-user propagation), and Actions on Objective (ranging from data exfiltration to unauthorized transactions). By mapping recent attacks to this structure, we demonstrate that LLM-related attacks follow systematic sequences analogous to traditional malware campaigns. The promptware kill chain offers security practitioners a structured methodology for threat modeling and provides a common vocabulary for researchers across AI safety and cybersecurity to address a rapidly evolving threat landscape.", "AI": {"tldr": "本文提出了一个针对基于大语言模型（LLM）系统攻击的新框架，称为promptware杀伤链，并分析了这种新型威胁。", "motivation": "随着基于LLM系统的迅速采用，现有的安全框架无法充分应对新兴的攻击表面。传统的“提示注入”描述掩盖了多步骤攻击的复杂性，本文旨在提供一个更全面的安全分析模型。", "method": "提出了包含初始访问、权限提升、持久化、横向移动和目标行动五个阶段的promptware杀伤链示范框架，并将最近的攻击案例映射到该结构中。", "result": "通过实例展示了LLM相关攻击遵循系统性步骤，类似于传统恶意软件活动模式。", "conclusion": "提出的promptware杀伤链为安全从业者提供了威胁建模的结构化方法，并且提供了一个共同语言供AI安全和网络安全领域的研究人员应对迅速演变的威胁环境。"}}
{"id": "2601.09624", "pdf": "https://arxiv.org/pdf/2601.09624", "abs": "https://arxiv.org/abs/2601.09624", "authors": ["Jiali Cheng", "Ziheng Chen", "Chirag Agarwal", "Hadi Amiri"], "title": "Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Machine unlearning is becoming essential for building trustworthy and compliant language models. Yet unlearning success varies considerably across individual samples: some are reliably erased, while others persist despite the same procedure. We argue that this disparity is not only a data-side phenomenon, but also reflects model-internal mechanisms that encode and protect memorized information. We study this problem from a mechanistic perspective based on model circuits--structured interaction pathways that govern how predictions are formed. We propose Circuit-guided Unlearning Difficulty (CUD), a {\\em pre-unlearning} metric that assigns each sample a continuous difficulty score using circuit-level signals. Extensive experiments demonstrate that CUD reliably separates intrinsically easy and hard samples, and remains stable across unlearning methods. We identify key circuit-level patterns that reveal a mechanistic signature of difficulty: easy-to-unlearn samples are associated with shorter, shallower interactions concentrated in earlier-to-intermediate parts of the original model, whereas hard samples rely on longer and deeper pathways closer to late-stage computation. Compared to existing qualitative studies, CUD takes a first step toward a principled, fine-grained, and interpretable analysis of unlearning difficulty; and motivates the development of unlearning methods grounded in model mechanisms.", "AI": {"tldr": "本文提出了一个基于模型电路的预卸载困难度指标（CUD），用于量化并解释机器学习中的样本卸载难度。", "motivation": "动机在于理解为什么在相同的学习过程中，一些样本能够被容易地抹去而另一些则难以卸载，并且探索内在机制以提高语言模型的信任度和合规性。", "method": "研究通过分析模型内部的结构化交互路径来探讨样本卸载难度问题，提出了CUD指标，该指标能为每个样本分配一个连续困难度得分。", "result": "实验表明CUD可以可靠地区分容易与难以卸载的样本，并且在不同的卸载方法中保持稳定。研究还揭示了易难样本在电路级别上的差异。", "conclusion": "CUD是首次针对卸载难度进行原理化、精细和可解释分析的方法，它激励了基于模型机制开发新的卸载技术的发展。"}}
{"id": "2601.09620", "pdf": "https://arxiv.org/pdf/2601.09620", "abs": "https://arxiv.org/abs/2601.09620", "authors": ["Pooja Prajod", "Hannes Cools", "Thomas Röggla", "Karthikeya Puttur Venkatraj", "Amber Kusters", "Alia ElKattan", "Pablo Cesar", "Abdallah El Ali"], "title": "Full Disclosure, Less Trust? How the Level of Detail about AI Use in News Writing Affects Readers' Trust", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "As artificial intelligence (AI) is increasingly integrated into news production, calls for transparency about the use of AI have gained considerable traction. Recent studies suggest that AI disclosures can lead to a ``transparency dilemma'', where disclosure reduces readers' trust. However, little is known about how the \\textit{level of detail} in AI disclosures influences trust and contributes to this dilemma within the news context. In this 3$\\times$2$\\times$2 mixed factorial study with 40 participants, we investigate how three levels of AI disclosures (none, one-line, detailed) across two types of news (politics and lifestyle) and two levels of AI involvement (low and high) affect news readers' trust. We measured trust using the News Media Trust questionnaire, along with two decision behaviors: source-checking and subscription decisions. Questionnaire responses and subscription rates showed a decline in trust only for detailed AI disclosures, whereas source-checking behavior increased for both one-line and detailed disclosures, with the effect being more pronounced for detailed disclosures. Insights from semi-structured interviews suggest that source-checking behavior was primarily driven by interest in the topic, followed by trust, whereas trust was the main factor influencing subscription decisions. Around two-thirds of participants expressed a preference for detailed disclosures, while most participants who preferred one-line indicated a need for detail-on-demand disclosure formats. Our findings show that not all AI disclosures lead to a transparency dilemma, but instead reflect a trade-off between readers' desire for more transparency and their trust in AI-assisted news content.", "AI": {"tldr": "研究了不同层次的人工智能披露对新闻读者信任度的影响，揭示了详细的AI披露可能导致透明度困境。", "motivation": "随着人工智能在新闻生产中的应用越来越多，关于如何透明地披露AI使用的讨论也越来越受到重视。然而，目前对于不同层次的AI披露细节如何影响读者的信任尚不清楚，因此本研究旨在探讨这一问题。", "method": "通过一项3×2×2混合因子设计的研究，涉及40位参与者，研究了三种水平的人工智能披露（无、一行和详细）、两种类型的新闻（政治和生活方式）以及两个层次的AI参与度（低和高），对新闻读者信任的影响。使用《新闻媒体信任问卷》以及其他两项决策行为（来源检查和订阅决定）作为评估指标。", "result": "研究结果显示，只有详细的AI披露导致了信任度下降；同时，对于一行和详细披露，参与者更倾向于进行来源检查的行为，其中详细披露的效果更为显著。大约三分之二的受访者偏好详细的披露格式。", "conclusion": "研究表明，并非所有的AI披露都会引发透明度困境，而是反映了读者对更多透明度的需求与他们对AI辅助新闻内容的信任之间的一种权衡。"}}
{"id": "2601.09613", "pdf": "https://arxiv.org/pdf/2601.09613", "abs": "https://arxiv.org/abs/2601.09613", "authors": ["Yonglin Tian", "Qiyao Zhang", "Wei Xu", "Yutong Wang", "Yihao Wu", "Xinyi Li", "Xingyuan Dai", "Hui Zhang", "Zhiyong Cui", "Baoqing Guo", "Zujun Yu", "Yisheng Lv"], "title": "CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate and early perception of potential intrusion targets is essential for ensuring the safety of railway transportation systems. However, most existing systems focus narrowly on object classification within fixed visual scopes and apply rule-based heuristics to determine intrusion status, often overlooking targets that pose latent intrusion risks. Anticipating such risks requires the cognition of spatial context and temporal dynamics for the object of interest (OOI), which presents challenges for conventional visual models. To facilitate deep intrusion perception, we introduce a novel benchmark, CogRail, which integrates curated open-source datasets with cognitively driven question-answer annotations to support spatio-temporal reasoning and prediction. Building upon this benchmark, we conduct a systematic evaluation of state-of-the-art visual-language models (VLMs) using multimodal prompts to identify their strengths and limitations in this domain. Furthermore, we fine-tune VLMs for better performance and propose a joint fine-tuning framework that integrates three core tasks, position perception, movement prediction, and threat analysis, facilitating effective adaptation of general-purpose foundation models into specialized models tailored for cognitive intrusion perception. Extensive experiments reveal that current large-scale multimodal models struggle with the complex spatial-temporal reasoning required by the cognitive intrusion perception task, underscoring the limitations of existing foundation models in this safety-critical domain. In contrast, our proposed joint fine-tuning framework significantly enhances model performance by enabling targeted adaptation to domain-specific reasoning demands, highlighting the advantages of structured multi-task learning in improving both accuracy and interpretability. Code will be available at https://github.com/Hub-Tian/CogRail.", "AI": {"tldr": "本文介绍了CogRail基准测试，用于评估视觉语言模型（VLMs）在智能铁路运输系统中的认知入侵感知能力，并提出了一种联合微调框架以改进现有模型的性能。", "motivation": "现有的铁路安全检测系统主要集中在固定视野内的目标分类上，忽视了潜在风险，而准确及时地识别这些潜在风险需要复杂的时空推理，这超出了传统视觉模型的能力范围。", "method": "构建了一个名为CogRail的新基准测试，集成了开源数据集和认知驱动的问答注释，用于支持时空推理与预测；对最先进的VLMs进行系统评估，并提出了一个融合位置感知、运动预测和威胁分析三大核心任务的联合微调框架来提升模型性能。", "result": "实验表明，现有大规模多模态模型在复杂的时空推理中表现不佳，而通过提出的联合微调框架能够显著提高模型的表现。", "conclusion": "研究结果强调了现有基础模型在此类安全关键领域中的局限性，并证明了结构化多任务学习方法在提升准确性和可解释性方面的优势。"}}
{"id": "2601.09610", "pdf": "https://arxiv.org/pdf/2601.09610", "abs": "https://arxiv.org/abs/2601.09610", "authors": ["Marie Luisa Fiedler", "Christian Merz", "Jonathan Tschanter", "Carolin Wienrich", "Marc Erich Latoschik"], "title": "Technological Advances in Two Generations of Consumer-Grade VR Systems: Effects on User Experience and Task Performance", "categories": ["cs.HC"], "comment": "12 pages, 4 figures, 7 tables", "summary": "Integrated VR (IVR) systems consist of a head-mounted display (HMD) and body-tracking capabilities. They enable users to translate their physical movements into corresponding avatar movements in real-time, allowing them to perceive their avatars via the displays. Consumer-grade IVR systems have been available for 10 years, significantly fostering VR research worldwide. However, the effects of even apparently significant technological advances of IVR systems on user experience and the overall validity of prior embodiment research using such systems often remain unclear. We ran a user-centered study comparing two comparable IVR generations: a nearly 10-year-old hardware (HTC Vive, 6-point tracking) and a modern counterpart (HTC Vive Pro 2, 6-point tracking). To ensure ecological validity, we evaluated the systems in their commercially available, as-is configurations. In a 2x5 mixed design, participants completed five tasks covering different use cases on either the old or new system. We assessed presence, sense of embodiment, appearance and behavior plausibility, workload, task performance, and gathered qualitative feedback. Results showed no significant system differences, with only small effect sizes. Bayesian analysis further supported the null hypothesis, suggesting that the investigated generational hardware improvements offer limited benefits for user experience and task performance. For the 10-year generational step examined here, excluding potential technological progress in the necessary software components, this supports the validity of conclusions from prior work and underscores the applicability of older configurations for research in embodied VR.", "AI": {"tldr": "本研究比较了两代消费级VR系统的用户体验和技术性能。", "motivation": "尽管消费级IVR系统已发展十年，其技术进步对用户经验和先前身体沉浸研究的影响仍不清楚。", "method": "使用2x5混合设计，参与者在旧的HTC Vive或新的HTC Vive Pro 2上完成了五项任务，并评估了存在感、身体沉浸感、外观和行为合理性和工作量等指标。", "result": "没有显著系统差异，仅显示较小效果大小。贝叶斯分析进一步支持零假设。", "conclusion": "所研究的硬件代际改进为用户经验和任务性能带来的好处有限，这证实了先前工作的结论有效性，并强调旧配置在沉浸式VR研究中的适用性。"}}
{"id": "2601.09609", "pdf": "https://arxiv.org/pdf/2601.09609", "abs": "https://arxiv.org/abs/2601.09609", "authors": ["Qian Cao", "Yahui Liu", "Wei Bi", "Yi Zhao", "Ruihua Song", "Xiting Wang", "Ruiming Tang", "Guorui Zhou", "Han Li"], "title": "DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. Current methods lack explicit mechanisms for guiding diverse exploration and instead prioritize optimization efficiency and performance over diversity. This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), in which the generation process is decomposed into explicitly planned intermediate steps. We introduce a Diverse Planning Branching method that strategically introduces divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results on creative writing benchmarks demonstrate that our approach significantly improves output diversity without compromising generation quality, consistently outperforming existing baselines.", "AI": {"tldr": "DPWriter 使用强化学习和多样规划分支方法来提高创意写作中的输出多样性。", "motivation": "现有的基于强化学习的方法在提升大语言模型性能的同时往往降低了输出的多样性，这不利于开放性任务如创意写作。", "method": "论文提出了一种以半结构化长链式思维（CoT）为基础的RL框架，并引入多样规划分支方法和群组感知多样性奖励来鼓励不同的生成路径。", "result": "实验结果表明，DPWriter 方法在提高输出多样性的同时并未影响生成质量，并且在创意写作基准测试中始终优于现有基线模型。", "conclusion": "该论文提出的方法通过改善多样性而不牺牲生成质量，在创意写作任务上显示出显著的优势。"}}
{"id": "2601.09606", "pdf": "https://arxiv.org/pdf/2601.09606", "abs": "https://arxiv.org/abs/2601.09606", "authors": ["Manning Gao", "Leheng Zhang", "Shiqin Han", "Haifeng Hu", "Yuncheng Jiang", "Sijie Mai"], "title": "GRCF: Two-Stage Groupwise Ranking and Calibration Framework for Multimodal Sentiment Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Most Multimodal Sentiment Analysis research has focused on point-wise regression. While straightforward, this approach is sensitive to label noise and neglects whether one sample is more positive than another, resulting in unstable predictions and poor correlation alignment. Pairwise ordinal learning frameworks emerged to address this gap, capturing relative order by learning from comparisons. Yet, they introduce two new trade-offs: First, they assign uniform importance to all comparisons, failing to adaptively focus on hard-to-rank samples. Second, they employ static ranking margins, which fail to reflect the varying semantic distances between sentiment groups. To address this, we propose a Two-Stage Group-wise Ranking and Calibration Framework (GRCF) that adapts the philosophy of Group Relative Policy Optimization (GRPO). Our framework resolves these trade-offs by simultaneously preserving relative ordinal structure, ensuring absolute score calibration, and adaptively focusing on difficult samples. Specifically, Stage 1 introduces a GRPO-inspired Advantage-Weighted Dynamic Margin Ranking Loss to build a fine-grained ordinal structure. Stage 2 then employs an MAE-driven objective to align prediction magnitudes. To validate its generalizability, we extend GRCF to classification tasks, including multimodal humor detection and sarcasm detection. GRCF achieves state-of-the-art performance on core regression benchmarks, while also showing strong generalizability in classification tasks.", "AI": {"tldr": "本文提出了GRCF框架，以解决多模态情感分析中点式回归和成对排序学习方法的不足。", "motivation": "现有的多模态情感分析研究主要集中在点式回归上，这种方法虽然直接但容易受到标签噪声的影响，并忽略了样本之间的相对正负程度差异。为了克服这些问题，提出了GRCF框架。", "method": "GRCF是一个两阶段分组排序和校准框架，包括一个动态优势加权边际排名损失和一个基于MAE的目标函数，用于构建精细的顺序结构并确保绝对分数校准。", "result": "实验表明，GRCF在核心回归基准上达到了最先进的性能，并且展示了在分类任务中良好的泛化能力。", "conclusion": "GRCF框架通过同时保持相对排序结构和进行绝对评分校准解决了现有方法的局限性，并适用于多模态情感分析中的各种应用。"}}
{"id": "2601.09605", "pdf": "https://arxiv.org/pdf/2601.09605", "abs": "https://arxiv.org/abs/2601.09605", "authors": ["Jeremiah Coholich", "Justin Wit", "Robert Azarcon", "Zsolt Kira"], "title": "Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Vision-based policies for robot manipulation have achieved significant recent success, but are still brittle to distribution shifts such as camera viewpoint variations. Robot demonstration data is scarce and often lacks appropriate variation in camera viewpoints. Simulation offers a way to collect robot demonstrations at scale with comprehensive coverage of different viewpoints, but presents a visual sim2real challenge. To bridge this gap, we propose MANGO -- an unpaired image translation method with a novel segmentation-conditioned InfoNCE loss, a highly-regularized discriminator design, and a modified PatchNCE loss. We find that these elements are crucial for maintaining viewpoint consistency during sim2real translation. When training MANGO, we only require a small amount of fixed-camera data from the real world, but show that our method can generate diverse unseen viewpoints by translating simulated observations. In this domain, MANGO outperforms all other image translation methods we tested. Imitation-learning policies trained on data augmented by MANGO are able to achieve success rates as high as 60\\% on views that the non-augmented policy fails completely on.", "AI": {"tldr": "本文提出了一种名为MANGO的图像翻译方法，以解决机器人视觉策略在不同视角下的分布变化问题。", "motivation": "机器人操控中的视觉策略虽然取得了显著进展，但面对摄像机视角的变化时仍显得脆弱。现有的真实世界数据集难以提供足够的视角变异样本，而模拟可以生成大量涵盖多种视角的数据，但是存在从仿真到现实的挑战。", "method": "MANGO采用了一个新的分割条件InfoNCE损失函数、一个高度正则化的鉴别器设计和修改后的PatchNCE损失函数来保持在图像转换过程中的视角一致性。只需要一小部分固定摄像机的真实世界数据进行训练。", "result": "与测试的其他图像翻译方法相比，MANGO表现更优。使用MANGO增强的数据集训练模仿学习策略能够实现高达60%的成功率，在非增强策略完全失败的情况下仍能保持。", "conclusion": "研究证实了提出的MANGO在解决机器人视觉操控中视角稳健性问题上的有效性，并且只需少量的真实世界数据即可显著提升任务表现。"}}
{"id": "2601.09603", "pdf": "https://arxiv.org/pdf/2601.09603", "abs": "https://arxiv.org/abs/2601.09603", "authors": ["Petros Vavaroutsos", "Theodoros Palamas", "Pantelis Vikatos"], "title": "Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG"], "comment": "accepted by ACM/SIGAPP Symposium on Applied Computing (SAC 2026)", "summary": "In recent years, foundation models have become very popular due to their exceptional performance, mainly in natural language (NLP) tasks where they were first introduced. These models usually consist of hundreds of millions, or even billions, of parameters, making them resource-intensive during training and in production systems, leading to increased costs. This paper focuses on the reduction of a foundation's model size when applied to music information retrieval (MIR) tasks. Our research combines the Branchformer architecture with SummaryMixing, which were first applied in speech recognition, along with a random quantization process. To facilitate reproducibility, we conduct pre-training on publicly available datasets, complemented by a proprietary dataset comparable in scale to other private datasets reported in the literature. We ensure robust evaluation by using a framework consisting of a variety of downstream MIR tasks. Our results show that our architecture achieves competitive performance when compared with other state-of-the-art models that use multi-head self-attention, while reducing the model size from 8.5% up to 12.3%.", "AI": {"tldr": "本文提出了一种在音乐信息检索任务中减少基础模型规模的方法，通过结合Branchformer架构、SummaryMixing和随机量化过程来实现。", "motivation": "由于基础模型参数量庞大导致训练和生产系统资源消耗高成本增加，本研究旨在为音乐理解任务中的基础模型减小规模并保持高性能。", "method": "本文使用了Branchformer架构和SummaryMixing技术，并引入随机量化处理，结合公开数据集和私有数据集进行预训练，并通过多个下游MIR任务验证方法的有效性。", "result": "研究结果表明，所提出的方法在不牺牲性能的情况下将模型大小减少了8.5%至12.3%，并且与使用多头自注意力机制的现有最先进模型相比具有竞争力。", "conclusion": "本研究表明，通过结合Branchformer架构、SummaryMixing和随机量化过程可以在音乐信息检索任务中实现高效的自我监督学习，并显著减小基础模型规模。"}}
{"id": "2601.09601", "pdf": "https://arxiv.org/pdf/2601.09601", "abs": "https://arxiv.org/abs/2601.09601", "authors": ["Emmanuele Barberi", "Felice Sfravara", "Filippo Cucinotta"], "title": "Iterative Differential Entropy Minimization (IDEM) method for fine rigid pairwise 3D Point Cloud Registration: A Focus on the Metric", "categories": ["cs.CV"], "comment": "ef:IEEE Transactions on Pattern Analysis and Machine Intelligence, 2025, Available in IEEE Xplore", "summary": "Point cloud registration is a central theme in computer vision, with alignment algorithms continuously improving for greater robustness. Commonly used methods evaluate Euclidean distances between point clouds and minimize an objective function, such as Root Mean Square Error (RMSE). However, these approaches are most effective when the point clouds are well-prealigned and issues such as differences in density, noise, holes, and limited overlap can compromise the results. Traditional methods, such as Iterative Closest Point (ICP), require choosing one point cloud as fixed, since Euclidean distances lack commutativity. When only one point cloud has issues, adjustments can be made, but in real scenarios, both point clouds may be affected, often necessitating preprocessing. The authors introduce a novel differential entropy-based metric, designed to serve as the objective function within an optimization framework for fine rigid pairwise 3D point cloud registration, denoted as Iterative Differential Entropy Minimization (IDEM). This metric does not depend on the choice of a fixed point cloud and, during transformations, reveals a clear minimum corresponding to the best alignment. Multiple case studies are conducted, and the results are compared with those obtained using RMSE, Chamfer distance, and Hausdorff distance. The proposed metric proves effective even with density differences, noise, holes, and partial overlap, where RMSE does not always yield optimal alignment.", "AI": {"tldr": "本文提出了一种基于迭代微分熵最小化（IDEM）的新方法，用于精细的刚性三维点云配准。", "motivation": "传统的点云配准算法如ICP在点云预对齐良好时效果最好，但当面对密度差异、噪声、孔洞和有限重叠等问题时性能较差。本文旨在解决这些问题并提供更稳健的方法。", "method": "作者提出了一个基于微分熵的新度量标准作为优化框架的目标函数，该方法不依赖于固定点云的选择，并能在变换过程中清晰地揭示最佳对齐的最小值。", "result": "多个案例研究显示，新的度量标准即使在存在密度差异、噪声、孔洞和部分重叠的情况下也能有效工作，而RMSE在这种情况下不一定能提供最优对齐。", "conclusion": "该方法证明了其在处理复杂点云配准问题中的优越性，并且相比传统的基于距离的方法更加稳健。"}}
{"id": "2601.09600", "pdf": "https://arxiv.org/pdf/2601.09600", "abs": "https://arxiv.org/abs/2601.09600", "authors": ["Bhaskar Mitra", "Nicola Neophytou", "Sireesh Gururaja"], "title": "Information Access of the Oppressed: A Problem-Posing Framework for Envisioning Emancipatory Information Access Platforms", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.IR"], "comment": null, "summary": "Online information access (IA) platforms are targets of authoritarian capture. These concerns are particularly serious and urgent today in light of the rising levels of democratic erosion worldwide, the emerging capabilities of generative AI technologies such as AI persuasion, and the increasing concentration of economic and political power in the hands of Big Tech. This raises the question of what alternative IA infrastructure we must reimagine and build to mitigate the risks of authoritarian capture of our information ecosystems. We explore this question through the lens of Paulo Freire's theories of emancipatory pedagogy. Freire's theories provide a radically different lens for exploring IA's sociotechnical concerns relative to the current dominating frames of fairness, accountability, confidentiality, transparency, and safety. We make explicit, with the intention to challenge, the dichotomy of how we relate to technology as either technologists (who envision and build technology) and its users. We posit that this mirrors the teacher-student relationship in Freire's analysis. By extending Freire's analysis to IA, we challenge the notion that it is the burden of the (altruistic) technologists to come up with interventions to mitigate the risks that emerging technologies pose to marginalized communities. Instead, we advocate that the first task for the technologists is to pose these as problems to the marginalized communities, to encourage them to make and unmake the technology as part of their material struggle against oppression. Their second task is to redesign our online technology stacks to structurally expose spaces for community members to co-opt and co-construct the technology in aid of their emancipatory struggles. We operationalize Freire's theories to develop a problem-posing framework for envisioning emancipatory IA platforms of the future.", "AI": {"tldr": "本文提出了一种问题设置框架，用于构想未来解放性的信息访问平台。", "motivation": "鉴于全球民主侵蚀加剧、生成式AI技术的发展以及大科技公司在经济和政治权力上的集中趋势，作者旨在探索如何重新构思和构建替代的信息访问基础设施以减轻专制政权对信息生态系统的控制风险。", "method": "通过保罗·弗莱雷关于解放性教学的理论框架，挑战当前技术和用户关系的二分法，并提出技术开发者应首先将问题设置为社区成员的问题，鼓励他们参与并重塑技术作为反抗压迫的一部分。", "result": "发展出一个基于弗莱雷理论的问题设置框架来构想未来的解放式信息访问平台。", "conclusion": "文章倡导技术和用户之间的关系应当重新定义，使技术成为被边缘化群体自我赋权和抵抗压迫的工具，并强调在线技术堆栈需要结构性地为社区成员提供共同改造和构建技术的空间。"}}
{"id": "2601.09594", "pdf": "https://arxiv.org/pdf/2601.09594", "abs": "https://arxiv.org/abs/2601.09594", "authors": ["Russell M. Martin", "Steven H. Collins"], "title": "Improving CMA-ES Convergence Speed, Efficiency, and Reliability in Noisy Robot Optimization Problems", "categories": ["cs.NE"], "comment": "This is the authors' final accepted manuscript (post-peer-review, pre-publication). It has been accepted for publication in Evolutionary Computation on 12 Jan 2026. For associated code, see https://github.com/RussellMMartin/AS-CMA-ES", "summary": "Experimental robot optimization often requires evaluating each candidate policy for seconds to minutes. The chosen evaluation time influences optimization because of a speed-accuracy tradeoff: shorter evaluations enable faster iteration, but are also more subject to noise. Here, we introduce a supplement to the CMA-ES optimization algorithm, named Adaptive Sampling CMA-ES (AS-CMA), which assigns sampling time to candidates based on predicted sorting difficulty, aiming to achieve consistent precision. We compared AS-CMA to CMA-ES and Bayesian optimization using a range of static sampling times in four simulated cost landscapes. AS-CMA converged on 98% of all runs without adjustment to its tunable parameter, and converged 24-65% faster and with 29-76% lower total cost than each landscape's best CMA-ES static sampling time. As compared to Bayesian optimization, AS-CMA converged more efficiently and reliably in complex landscapes, while in simpler landscapes, AS-CMA was less efficient but equally reliable. We deployed AS-CMA in an exoskeleton optimization experiment and found the optimizer's behavior was consistent with expectations. These results indicate that AS-CMA can improve optimization efficiency in the presence of noise while minimally affecting optimization setup complexity and tuning requirements.", "AI": {"tldr": "本文提出了一种名为自适应采样CMA-ES（AS-CMA）的优化算法，旨在提高机器人优化问题中的收敛速度、效率和可靠性。", "motivation": "机器人实验优化中需要评估每个候选策略数秒到几分钟的时间，并且存在短时间评估加快迭代但增加噪声的风险。本文为了改进这种速度与精度之间的权衡问题而提出了一种新的优化方法。", "method": "提出了名为自适应采样CMA-ES（AS-CMA）的算法，该算法根据预测的排序难度为候选人分配采样时间，以实现一致性的精度。", "result": "实验表明，与传统的CMA-ES和贝叶斯优化相比，在四种模拟成本景观中，AS-CMA在98%的所有测试运行中无调整参数即可收敛，并且比每个景观的最佳固定采样时间的CMA-ES快24%-65%，总成本降低29%-76%。", "conclusion": "AS-CMA可以提高噪声存在情况下的优化效率，同时对优化设置复杂性和调优要求的影响最小。"}}
{"id": "2601.09586", "pdf": "https://arxiv.org/pdf/2601.09586", "abs": "https://arxiv.org/abs/2601.09586", "authors": ["Said Yasin", "Torsten Zesch"], "title": "Show, don't tell -- Providing Visual Error Feedback for Handwritten Documents", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Handwriting remains an essential skill, particularly in education. Therefore, providing visual feedback on handwritten documents is an important but understudied area. We outline the many challenges when going from an image of handwritten input to correctly placed informative error feedback. We empirically compare modular and end-to-end systems and find that both approaches currently do not achieve acceptable overall quality. We identify the major challenges and outline an agenda for future research.", "AI": {"tldr": "本文探讨了从手写输入图像到正确放置的视觉错误反馈过程中的挑战，并比较了模块化和端到端系统的性能。", "motivation": "鉴于手写在教育领域的重要性，提供针对手写文档的有效视觉反馈是一个重要但研究不足的问题。", "method": "通过实证分析对比了两种系统：模块化和端到端系统，在手写输入图像上进行实验以评估它们的表现。", "result": "研究表明，目前两种方法都未能达到整体质量的可接受标准。", "conclusion": "文章确定了主要挑战，并为未来研究制定了议程。"}}
{"id": "2601.09578", "pdf": "https://arxiv.org/pdf/2601.09578", "abs": "https://arxiv.org/abs/2601.09578", "authors": ["Jiajun Sun", "Yangyi Ou", "Haoyuan Zheng", "Chao yang", "Yue Ma"], "title": "Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping", "categories": ["cs.RO", "cs.CV"], "comment": "5 pages,7 figures. Under review", "summary": "In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance.", "AI": {"tldr": "本文提出了一种新的方法，通过融合可见光和红外图像来增强三维点云地图的语义信息。", "motivation": "在复杂的环境中，自主机器人导航和技术感知对SLAM技术提出了更高的要求。", "method": "首先进行像素级的可见光和红外图像融合，然后将实时LiDAR点云投影到此融合后的图像流上，并识别热源特征以即时标识高温目标，将其作为语义图层添加到最终的三维地图中。", "result": "该方法生成的地图不仅几何形状准确，还具有对环境的关键语义理解能力。", "conclusion": "这种方法对于快速灾害评估和工业预防性维护等特定应用来说非常有价值。"}}
{"id": "2601.09577", "pdf": "https://arxiv.org/pdf/2601.09577", "abs": "https://arxiv.org/abs/2601.09577", "authors": ["MD Nazmul Alam Shanto", "Md. Tanzeem Rahat", "Md. Manzurul Hasan"], "title": "Permutation Matching Under Parikh Budgets: Linear-Time Detection, Packing, and Disjoint Selection", "categories": ["cs.DS", "cs.CL"], "comment": "12 pages (Excluding reference)", "summary": "We study permutation (jumbled/Abelian) pattern matching over a general alphabet $Σ$. Given a pattern P of length m and a text T of length n, the classical task is to decide whether T contains a length-m substring whose Parikh vector equals that of P . While this existence problem admits a linear-time sliding-window solution, many practical applications require optimization and packing variants beyond mere detection. We present a unified sliding-window framework based on maintaining the Parikh-vector difference between P and the current window of T , enabling permutation matching in O(n + σ) time and O(σ) space, where σ = |Σ|. Building on this foundation, we introduce a combinatorial-optimization variant that we call Maximum Feasible Substring under Pattern Supply (MFSP): find the longest substring S of T whose symbol counts are component-wise bounded by those of P . We show that MFSP can also be solved in O(n + σ) time via a two-pointer feasibility maintenance algorithm, providing an exact packing interpretation of P as a resource budget. Finally, we address non-overlapping occurrence selection by modeling each permutation match as an equal-length interval and proving that a greedy earliest-finishing strategy yields a maximum-cardinality set of disjoint matches, computable in linear time once all matches are enumerated. Our results provide concise, provably correct algorithms with tight bounds, and connect frequency-based string matching to packing-style optimization primitives.", "AI": {"tldr": "研究在一般字母表上进行排列（杂凑/阿贝尔）模式匹配，提出一种统一的滑动窗口框架来检测、打包和选择不重叠的选择。", "motivation": "虽然存在线性时间滑动窗口解决方案用于检测问题，但许多实际应用需要优化和打包变体。", "method": "基于维护P与T当前窗口之间的Parikh向量差异的统一滑动窗口框架，在O(n + σ)时间内实现排列匹配，并提出一种两指针可行性算法来解决MFSP问题，以及采用贪婪最早完成策略选择不重叠的发生事件。", "result": "实现了在O(n + σ)时间和O(σ)空间内进行排列匹配，解决了最长符合子串下的模式供给问题（MFSP），并提供了一种线性时间的算法来计算最大基数的非重叠匹配集合。", "conclusion": "研究提供了简洁、正确且紧致界限的算法，并将基于频率的字符串匹配与打包优化相结合。"}}
{"id": "2601.09575", "pdf": "https://arxiv.org/pdf/2601.09575", "abs": "https://arxiv.org/abs/2601.09575", "authors": ["Sheng-Yu Huang", "Jaesung Choe", "Yu-Chiang Frank Wang", "Cheng Sun"], "title": "OpenVoxel: Training-Free Grouping and Captioning Voxels for Open-Vocabulary 3D Scene Understanding", "categories": ["cs.CV"], "comment": "project page: https://peterjohnsonhuang.github.io/openvoxel-pages/", "summary": "We propose OpenVoxel, a training-free algorithm for grouping and captioning sparse voxels for the open-vocabulary 3D scene understanding tasks. Given the sparse voxel rasterization (SVR) model obtained from multi-view images of a 3D scene, our OpenVoxel is able to produce meaningful groups that describe different objects in the scene. Also, by leveraging powerful Vision Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), our OpenVoxel successfully build an informative scene map by captioning each group, enabling further 3D scene understanding tasks such as open-vocabulary segmentation (OVS) or referring expression segmentation (RES). Unlike previous methods, our method is training-free and does not introduce embeddings from a CLIP/BERT text encoder. Instead, we directly proceed with text-to-text search using MLLMs. Through extensive experiments, our method demonstrates superior performance compared to recent studies, particularly in complex referring expression segmentation (RES) tasks. The code will be open.", "AI": {"tldr": "提出OpenVoxel，一种无需训练的算法，用于分组和标注稀疏体素以实现开放词汇表的3D场景理解。", "motivation": "为了解决现有方法在处理开放式词汇表3D场景任务时需要大量训练的问题，并且不使用从CLIP/BERT文本编码器引入嵌入的方法。", "method": "利用强大的视觉语言模型（VLMs）和多模态大型语言模型（MLLMs），OpenVoxel能够基于稀疏体素栅格化(SVR)模型，对3D场景中的不同对象进行有意义的分组，并通过文本到文本搜索直接标注每个小组。", "result": "实验结果显示该方法在复杂参考表达式分割任务中表现出色，性能优于近期研究。", "conclusion": "OpenVoxel实现了无需训练的开放词汇表3D场景理解能力，在处理复杂的3D场景时具有显著优势。"}}
{"id": "2601.09572", "pdf": "https://arxiv.org/pdf/2601.09572", "abs": "https://arxiv.org/abs/2601.09572", "authors": ["Tianli Tao", "Ziyang Wang", "Delong Yang", "Han Zhang", "Le Zhang"], "title": "Trustworthy Longitudinal Brain MRI Completion: A Deformation-Based Approach with KAN-Enhanced Diffusion Model", "categories": ["cs.CV"], "comment": null, "summary": "Longitudinal brain MRI is essential for lifespan study, yet high attrition rates often lead to missing data, complicating analysis. Deep generative models have been explored, but most rely solely on image intensity, leading to two key limitations: 1) the fidelity or trustworthiness of the generated brain images are limited, making downstream studies questionable; 2) the usage flexibility is restricted due to fixed guidance rooted in the model structure, restricting full ability to versatile application scenarios. To address these challenges, we introduce DF-DiffCom, a Kolmogorov-Arnold Networks (KAN)-enhanced diffusion model that smartly leverages deformation fields for trustworthy longitudinal brain image completion. Trained on OASIS-3, DF-DiffCom outperforms state-of-the-art methods, improving PSNR by 5.6% and SSIM by 0.12. More importantly, its modality-agnostic nature allows smooth extension to varied MRI modalities, even to attribute maps such as brain tissue segmentation results.", "AI": {"tldr": "本文提出了一种基于变形场的扩散模型DF-DiffCom，用于完成纵向脑MRI图像，并在OASIS-3数据集上展示了其优越性。", "motivation": "针对高流失率导致纵向脑MRI缺失数据的问题以及现有方法生成图像可信度低和使用灵活性受限的问题，提出了一种改进的方法来解决这些问题。", "method": "DF-DiffCom通过KAN（Kolmogorov-Arnold Networks）增强的扩散模型结合变形场，实现更可靠的纵向脑MRI图像填充。", "result": "在OASIS-3数据集上，DF-DiffCom相较于其他方法，在PSNR和SSIM指标上有显著提升，分别提高了5.6%和0.12，并展示了其模态无关特性。", "conclusion": "该研究提出的方法不仅提升了生成图像的可信度，还增强了模型在不同MRI模式下的应用灵活性。"}}
{"id": "2601.09566", "pdf": "https://arxiv.org/pdf/2601.09566", "abs": "https://arxiv.org/abs/2601.09566", "authors": ["Shuyang Xiang", "Hao Guan"], "title": "Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 5 figures, submitted to ACL 2026", "summary": "Large language models typically represent Chinese characters as discrete index-based tokens, largely ignoring their visual form. For logographic scripts, visual structure carries semantic and phonetic information, which may aid prediction. We investigate whether low-resolution visual inputs can serve as an alternative for character-level modeling. Instead of token IDs, our decoder receives grayscale images of individual characters, with resolutions as low as $8 \\times 8$ pixels. Remarkably, these inputs achieve 39.2\\% accuracy, comparable to the index-based baseline of 39.1\\%. Such low-resource settings also exhibit a pronounced \\emph{hot-start} effect: by 0.4\\% of total training, accuracy reaches above 12\\%, while index-based models lag at below 6\\%. Overall, our results demonstrate that minimal visual structure can provide a robust and efficient signal for Chinese language modeling, offering an alternative perspective on character representation that complements traditional index-based approaches.", "AI": {"tldr": "研究使用低分辨率的视觉输入（灰度图像）作为字符级建模的替代方法，以提高中文语言模型的表现。", "motivation": "大型语言模型通常将汉字表示为离散索引形式的标记，忽略了其视觉形态。对于表意文字来说，视觉结构携带了语义和语音信息，可能有助于预测。", "method": "研究采用灰度图像（低至8×8像素）作为输入给解码器，代替传统字符ID标识。", "result": "实验结果表明，在39.2%的准确率上，这种方法与索引基线模型相当。并且在极少量训练数据下，其表现明显优于传统的索引方法。", "conclusion": "研究结论显示，即使是最低限度的视觉结构也能为中文语言建模提供一个稳健且高效的信号，这表明视觉信息可以作为一种替代视角来丰富字符表示形式。"}}
{"id": "2601.09557", "pdf": "https://arxiv.org/pdf/2601.09557", "abs": "https://arxiv.org/abs/2601.09557", "authors": ["Francisco Angulo de Lafuente", "Seid Mehammed Abdu", "Nirmal Tej"], "title": "SiliconHealth: A Complete Low-Cost Blockchain Healthcare Infrastructure for Resource-Constrained Regions Using Repurposed Bitcoin Mining ASICs", "categories": ["cs.NE", "cs.CR"], "comment": "8 pages, 9 tables, 2 figures, experimental validation with cross-device results, economic analysis", "summary": "This paper presents SiliconHealth, a comprehensive blockchain-based healthcare infrastructure designed for resource-constrained regions, particularly sub-Saharan Africa. We demonstrate that obsolete Bitcoin mining Application-Specific Integrated Circuits (ASICs) can be repurposed to create a secure, low-cost, and energy-efficient medical records system. The proposed architecture employs a four-tier hierarchical network: regional hospitals using Antminer S19 Pro (90+ TH/s), urban health centers with Antminer S9 (14 TH/s), rural clinics equipped with Lucky Miner LV06 (500 GH/s, 13W), and mobile health points with portable ASIC devices. We introduce the Deterministic Hardware Fingerprinting (DHF) paradigm, which repurposes SHA-256 mining ASICs as cryptographic proof generators, achieving 100% verification rate across 23 test proofs during 300-second validation sessions. The system incorporates Reed-Solomon LSB watermarking for medical image authentication with 30-40% damage tolerance, semantic Retrieval-Augmented Generation (RAG) for intelligent medical record queries, and offline synchronization protocols for intermittent connectivity. Economic analysis demonstrates 96% cost reduction compared to GPU-based alternatives, with total deployment cost of $847 per rural clinic including 5-year solar power infrastructure. Validation experiments on Lucky Miner LV06 (BM1366 chip, 5nm) achieve 2.93 MH/W efficiency and confirm hardware universality. This work establishes a practical framework for deploying verifiable, tamper-proof electronic health records in regions where traditional healthcare IT infrastructure is economically unfeasible, potentially benefiting over 600 million people lacking access to basic health information systems.", "AI": {"tldr": "本文介绍了SiliconHealth，一种基于区块链的医疗基础设施，旨在为资源匮乏地区提供低成本、安全且高效的医疗记录系统。", "motivation": "论文动机在于解决资源受限地区的医疗信息系统的经济可行性问题，特别是撒哈拉以南非洲地区，通过利用废旧的比特币挖矿ASIC设备来构建一个可负担得起的医疗信息系统。", "method": "该架构采用了四层网络：区域医院使用Antminer S19 Pro (90+ TH/s)、城市健康中心装备了Antminer S9 (14 TH/s)、农村诊所配备了Lucky Miner LV06 (500 GH/s, 13W)，以及移动医疗点使用便携式ASIC设备。引入了Deterministic Hardware Fingerprinting（DHF）范式，结合Reed-Solomon LSB水印技术和智能检索增强生成技术（RAG），并采用离线同步协议处理间歇性网络连接。", "result": "测试表明该系统在300秒验证会话中实现了100%的验证率，并且通过经济分析显示成本相比GPU方案降低了96%，农村诊所总部署成本为847美元，包括5年太阳能基础设施。", "conclusion": "本工作建立了一个实用框架，在传统医疗IT基础设施经济不可行的地区部署可验证、防篡改的电子健康记录系统，潜在受益人群超过6亿，缺乏基础健康信息系统访问的人群。"}}
{"id": "2601.09555", "pdf": "https://arxiv.org/pdf/2601.09555", "abs": "https://arxiv.org/abs/2601.09555", "authors": ["Manyi Zhang", "Ji-Fu Li", "Zhongao Sun", "Haoli Bai", "Hui-Ling Zhen", "Zhenhua Dong", "Xianzhi Yu"], "title": "Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Microscaling Floating-Point (MXFP) has emerged as a promising low-precision format for large language models (LLMs). Despite various post-training quantization (PTQ) algorithms being proposed, they mostly focus on integer quantization, while their applicability and behavior under MXFP formats remain largely unexplored. To address this gap, this work conducts a systematic investigation of PTQ under MXFP formats, encompassing over 7 PTQ algorithms, 15 evaluation benchmarks, and 3 LLM families. The key findings include: 1) MXFP8 consistently achieves near-lossless performance, while MXFP4 introduces substantial accuracy degradation and remains challenging; 2) PTQ effectiveness under MXFP depends strongly on format compatibility, with some algorithmic paradigms being consistently more effective than others; 3) PTQ performance exhibits highly consistent trends across model families and modalities, in particular, quantization sensitivity is dominated by the language model rather than the vision encoder in multimodal LLMs; 4) The scaling factor of quantization is a critical error source in MXFP4, and a simple pre-scale optimization strategy can significantly mitigate its impact. Together, these results provide practical guidance on adapting existing PTQ methods to MXFP quantization.", "AI": {"tldr": "本文系统地研究了大语言模型在微缩浮点格式下的后训练量化。", "motivation": "尽管提出了多种后训练量化算法，但它们大多专注于整数量化，在微缩浮点格式上的适用性和行为尚未得到充分探索。", "method": "该工作涵盖了超过7种后训练量化算法，15个评估基准和3种大语言模型家族。", "result": "研究结果表明MXFP8能保持近乎无损性能，而MXFP4则引入了显著的精度下降；量化效果与格式兼容性高度相关，部分算法始终更有效；量化表现趋势在不同模型家族之间具有高度一致性；缩放因子是MXFP4中关键误差源，简单的预缩放优化策略可以显著减轻其影响。", "conclusion": "这些结果为现有后训练量化方法适应微缩浮点量化提供了实用指南。"}}
{"id": "2601.09536", "pdf": "https://arxiv.org/pdf/2601.09536", "abs": "https://arxiv.org/abs/2601.09536", "authors": ["Dongjie Cheng", "Yongqi Li", "Zhixin Ma", "Hongru Cai", "Yupeng Hu", "Wenjie Wang", "Liqiang Nie", "Wenjie Li"], "title": "Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.", "AI": {"tldr": "本文提出了统一的生成式多模态推理框架Omni-R1，并展示了其在多种多模态任务中的应用效果。", "motivation": "早期的研究侧重于纯文本推理，而最近的研究虽引入了多模态信息但仍然受限于特定的任务模式。为了提高模型在不同多模态任务上的泛化能力，本文提出了一种统一的生成式多模态推理方法。", "method": "通过Omni-R1框架，在推理过程中生成中间图像以整合多种多模态推理技能。该框架采用了两阶段SFT+RL的方法，并引入了感知对齐损失和感知奖励。此外，还提出了不需要多模态标注的Omni-R1-Zero变体。", "result": "实验结果显示，Omni-R1能够实现跨多个多模态任务的统一生成式推理，而Omni-R1-Zero在平均表现上可与Omni-R1匹敌甚至超越。", "conclusion": "本文展示了一种有前景的多模态生成式推理方法，并通过实验验证了其有效性。"}}
{"id": "2601.09531", "pdf": "https://arxiv.org/pdf/2601.09531", "abs": "https://arxiv.org/abs/2601.09531", "authors": ["Yue Yao", "Ruining Yang", "Tom Gedeon"], "title": "Bipartite Mode Matching for Vision Training Set Search from a Hierarchical Data Server", "categories": ["cs.CV"], "comment": "Accepted to AAAI 2026", "summary": "We explore a situation in which the target domain is accessible, but real-time data annotation is not feasible. Instead, we would like to construct an alternative training set from a large-scale data server so that a competitive model can be obtained. For this problem, because the target domain usually exhibits distinct modes (i.e., semantic clusters representing data distribution), if the training set does not contain these target modes, the model performance would be compromised. While prior existing works improve algorithms iteratively, our research explores the often-overlooked potential of optimizing the structure of the data server. Inspired by the hierarchical nature of web search engines, we introduce a hierarchical data server, together with a bipartite mode matching algorithm (BMM) to align source and target modes. For each target mode, we look in the server data tree for the best mode match, which might be large or small in size. Through bipartite matching, we aim for all target modes to be optimally matched with source modes in a one-on-one fashion. Compared with existing training set search algorithms, we show that the matched server modes constitute training sets that have consistently smaller domain gaps with the target domain across object re-identification (re-ID) and detection tasks. Consequently, models trained on our searched training sets have higher accuracy than those trained otherwise. BMM allows data-centric unsupervised domain adaptation (UDA) orthogonal to existing model-centric UDA methods. By combining the BMM with existing UDA methods like pseudo-labeling, further improvement is observed.", "AI": {"tldr": "本文提出了一种基于双模匹配算法（BMM）的方法，用于在大规模数据服务器中搜索适合训练集的数据，以适应目标领域中的视觉任务。", "motivation": "当真实数据标注不可行时，通过构建一个替代的训练集来获得一个竞争性模型。现有方法主要集中在改进算法本身，而本文则关注优化数据服务器结构。", "method": "引入了具有层次性质的数据服务器和双模匹配算法（BMM），以实现源域和目标域模式的一对一最优匹配。该算法在搜索过程中寻找与目标模式最佳的源模式。", "result": "实验结果显示，通过BMM找到的训练集在对象重识别和检测任务中具有更小的领域差距，并且基于这些训练集训练出的模型有更高的准确性。", "conclusion": "BMM使得数据为中心的无监督域适应方法成为可能，它可以与现有的模型为中心的方法如伪标签结合使用以进一步提高性能。"}}
{"id": "2601.09528", "pdf": "https://arxiv.org/pdf/2601.09528", "abs": "https://arxiv.org/abs/2601.09528", "authors": ["Alfio Spoto", "Rosario Leonardi", "Francesco Ragusa", "Giovanni Maria Farinella"], "title": "GlovEgo-HOI: Bridging the Synthetic-to-Real Gap for Industrial Egocentric Human-Object Interaction Detection", "categories": ["cs.CV"], "comment": "8 pages, accepted as a Short Paper at VISAPP 2026", "summary": "Egocentric Human-Object Interaction (EHOI) analysis is crucial for industrial safety, yet the development of robust models is hindered by the scarcity of annotated domain-specific data. We address this challenge by introducing a data generation framework that combines synthetic data with a diffusion-based process to augment real-world images with realistic Personal Protective Equipment (PPE). We present GlovEgo-HOI, a new benchmark dataset for industrial EHOI, and GlovEgo-Net, a model integrating Glove-Head and Keypoint- Head modules to leverage hand pose information for enhanced interaction detection. Extensive experiments demonstrate the effectiveness of the proposed data generation framework and GlovEgo-Net. To foster further research, we release the GlovEgo-HOI dataset, augmentation pipeline, and pre-trained models at: GitHub project.", "AI": {"tldr": "本研究提出了一种结合合成数据和扩散过程来增强现实世界图像中的个人防护装备，以解决工业环境中人体与物体互动分析的挑战，并介绍了GlovEgo-HOI基准数据集及GlovEgo-Net模型。", "motivation": "由于工业领域标注特定领域的数据稀缺，难以开发出鲁棒的人体与物体交互检测模型，本研究旨在通过生成合成数据来弥补这一差距，提升在现实场景中的交互检测性能。", "method": "提出了一种结合合成数据和扩散过程的数据增强方法，并设计了GlovEgo-Net模型，该模型集成了手部姿态信息以提高人体与物体互动的检测准确率。", "result": "实验结果证明了所提数据生成框架及GlovEgo-Net的有效性，在工业环境的人体与物体交互检测中展现了良好的性能。", "conclusion": "本研究成功开发了一种合成到现实的数据增强方法和专用模型，有助于推动工业领域内人体与物体互动分析的研究和发展。"}}
{"id": "2601.09527", "pdf": "https://arxiv.org/pdf/2601.09527", "abs": "https://arxiv.org/abs/2601.09527", "authors": ["Jonathan Knoop", "Hendrik Holtmann"], "title": "Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "15 pages, 18 tables, 7 figures. Includes link to GitHub repository and Docker image for reproducibility", "summary": "SMEs increasingly seek alternatives to cloud LLM APIs, which raise data privacy concerns. Dedicated cloud GPU instances offer improved privacy but with limited guarantees and ongoing costs, while professional on-premise hardware (A100, H100) remains prohibitively expensive. We present a systematic evaluation of NVIDIA's Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for production LLM inference, benchmarking four open-weight models (Qwen3-8B, Gemma3-12B, Gemma3-27B, GPT-OSS-20B) across 79 configurations spanning quantization formats (BF16, W4A16, NVFP4, MXFP4), context lengths (8k-64k), and three workloads: RAG, multi-LoRA agentic serving, and high-concurrency APIs. The RTX 5090 delivers 3.5-4.6x higher throughput than the 5060 Ti with 21x lower latency for RAG, but budget GPUs achieve the highest throughput-per-dollar for API workloads with sub-second latency. NVFP4 quantization provides 1.6x throughput over BF16 with 41% energy reduction and only 2-4% quality loss. Self-hosted inference costs $0.001-0.04 per million tokens (electricity only), which is 40-200x cheaper than budget-tier cloud APIs, with hardware breaking even in under four months at moderate volume (30M tokens/day). Our results show that consumer GPUs can reliably replace cloud inference for most SME workloads, except latency-critical long-context RAG, where high-end GPUs remain essential. We provide deployment guidance and release all benchmark data for reproducible SME-scale deployments.", "AI": {"tldr": "评估和优化消费级Blackwell GPU用于中小企业本地部署LLM推理的可行性。", "motivation": "中小企业寻求替代云服务提供商的API，以解决数据隐私问题，并降低成本。专业硬件昂贵且维护成本高，因此探索使用经济实惠的消费级GPU作为解决方案。", "method": "系统评估了NVIDIA Blackwell系列（RTX 5060 Ti、5070 Ti、5090）在四个开源模型上的性能，涵盖了不同的量化格式、上下文长度和三种工作负载：RAG、多LoRA代理服务和高并发API。", "result": "RTX 5090相比于5060 Ti提供了3.5-4.6倍的吞吐量和21倍更低的延迟。NVFP4量化提高了1.6倍的吞吐量，并减少了41%的能量消耗，仅牺牲了2-4%的质量损失。本地部署的成本仅为云API的1/40到1/200。", "conclusion": "消费级GPU可以可靠地替代云端推理服务，适用于大多数中小企业工作负载，但在处理RAG等低延迟关键任务时仍需依赖高端GPU。"}}
{"id": "2601.09524", "pdf": "https://arxiv.org/pdf/2601.09524", "abs": "https://arxiv.org/abs/2601.09524", "authors": ["Lennart Eing", "Cristina Luna-Jiménez", "Silvan Mertes", "Elisabeth André"], "title": "Video Joint-Embedding Predictive Architectures for Facial Expression Recognition", "categories": ["cs.CV", "cs.HC"], "comment": "To appear in 2025 Proceedings of the 13th International Conference on Affective Computing and Intelligent Interaction (ACII), submitted to IEEE. \\c{opyright} 2025 IEEE", "summary": "This paper introduces a novel application of Video Joint-Embedding Predictive Architectures (V-JEPAs) for Facial Expression Recognition (FER). Departing from conventional pre-training methods for video understanding that rely on pixel-level reconstructions, V-JEPAs learn by predicting embeddings of masked regions from the embeddings of unmasked regions. This enables the trained encoder to not capture irrelevant information about a given video like the color of a region of pixels in the background. Using a pre-trained V-JEPA video encoder, we train shallow classifiers using the RAVDESS and CREMA-D datasets, achieving state-of-the-art performance on RAVDESS and outperforming all other vision-based methods on CREMA-D (+1.48 WAR). Furthermore, cross-dataset evaluations reveal strong generalization capabilities, demonstrating the potential of purely embedding-based pre-training approaches to advance FER. We release our code at https://github.com/lennarteingunia/vjepa-for-fer.", "AI": {"tldr": "本文介绍了一种新颖的面部表情识别方法，使用视频联合嵌入预测架构（V-JEPAs）。", "motivation": "传统的预训练方法依赖于像素级别的重建，而本文提出的方法旨在通过预测遮挡区域的嵌入来学习有用的特征，避免捕捉无关信息。", "method": "V-JEPAs 通过从未遮挡区域的嵌入中预测遮挡区域的嵌入来训练视频编码器。使用 RAVDESS 和 CREMA-D 数据集进行浅层分类器训练。", "result": "在 RAVDESS 数据集上达到最先进的性能，在 CREMA-D 数据集上也优于其他所有基于视觉的方法，且跨数据集评估显示了强大的泛化能力。", "conclusion": "实验结果表明，纯嵌入式预训练方法能够显著提升面部表情识别的效果。"}}
{"id": "2601.09522", "pdf": "https://arxiv.org/pdf/2601.09522", "abs": "https://arxiv.org/abs/2601.09522", "authors": ["Badr-Eddine Marani", "Julio Silva-Rodriguez", "Ismail Ben Ayed", "Maria Vakalopoulou", "Stergios Christodoulidis", "Jose Dolz"], "title": "Class Adaptive Conformal Training", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Deep neural networks have achieved remarkable success across a variety of tasks, yet they often suffer from unreliable probability estimates. As a result, they can be overconfident in their predictions. Conformal Prediction (CP) offers a principled framework for uncertainty quantification, yielding prediction sets with rigorous coverage guarantees. Existing conformal training methods optimize for overall set size, but shaping the prediction sets in a class-conditional manner is not straightforward and typically requires prior knowledge of the data distribution. In this work, we introduce Class Adaptive Conformal Training (CaCT), which formulates conformal training as an augmented Lagrangian optimization problem that adaptively learns to shape prediction sets class-conditionally without making any distributional assumptions. Experiments on multiple benchmark datasets, including standard and long-tailed image recognition as well as text classification, demonstrate that CaCT consistently outperforms prior conformal training methods, producing significantly smaller and more informative prediction sets while maintaining the desired coverage guarantees.", "AI": {"tldr": "本文提出了Class Adaptive Conformal Training（CaCT），一种自适应学习在类条件下的预测集形状的方法，以改进不确定性量化。", "motivation": "深度神经网络尽管取得了显著的成功，但在概率估计方面不可靠，容易过于自信。Conformal Prediction提供了一种不确定性的框架，但现有的方法需要对数据分布有先验知识才能调整预测集的类条件。", "method": "CaCT将符合训练表述为一个增强拉格朗日优化问题，自适应地学习在不假设任何分布的情况下形成预测集。", "result": "实验表明，在标准和长尾图像识别以及文本分类上，CaCT产生更小且更有信息量的预测集，并维持了期望的覆盖率保证。", "conclusion": "CaCT能够改进现有符合训练方法的效果，提供更加精确和可靠的不确定性量化。"}}
{"id": "2601.09520", "pdf": "https://arxiv.org/pdf/2601.09520", "abs": "https://arxiv.org/abs/2601.09520", "authors": ["Pierfrancesco Melucci", "Paolo Merialdo", "Taketo Akama"], "title": "Towards Realistic Synthetic Data for Automatic Drum Transcription", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Deep learning models define the state-of-the-art in Automatic Drum Transcription (ADT), yet their performance is contingent upon large-scale, paired audio-MIDI datasets, which are scarce. Existing workarounds that use synthetic data often introduce a significant domain gap, as they typically rely on low-fidelity SoundFont libraries that lack acoustic diversity. While high-quality one-shot samples offer a better alternative, they are not available in a standardized, large-scale format suitable for training. This paper introduces a new paradigm for ADT that circumvents the need for paired audio-MIDI training data. Our primary contribution is a semi-supervised method to automatically curate a large and diverse corpus of one-shot drum samples from unlabeled audio sources. We then use this corpus to synthesize a high-quality dataset from MIDI files alone, which we use to train a sequence-to-sequence transcription model. We evaluate our model on the ENST and MDB test sets, where it achieves new state-of-the-art results, significantly outperforming both fully supervised methods and previous synthetic-data approaches. The code for reproducing our experiments is publicly available at https://github.com/pier-maker92/ADT_STR", "AI": {"tldr": "本文提出了一种新的自动鼓乐转录方法，通过半监督的方式从无标签音频源中收集大量多样的一次性鼓样本，并利用这些样本来合成高质量的数据集以训练序列到序列的转录模型。", "motivation": "深度学习模型在自动化鼓乐转录中的表现依赖于大规模配对的音频-MIDI数据集，但这类数据稀缺。现有的使用合成数据的方法往往存在领域差距，因为它们通常依赖低保真的SoundFont库，缺乏声学多样性。", "method": "本文提出了一种半监督方法来自动收集无标签音频源中的一次性鼓样本，以此为基础生成高质量的数据集，并用于训练一个序列到序列的转录模型。", "result": "该模型在ENST和MDB测试集中取得了新的最佳结果，显著超越了全监督方法和先前基于合成数据的方法。", "conclusion": "本文提出的新方法通过利用高质量的一次性鼓样本生成的数据集，有效改善了自动鼓乐转录的效果，并达到了新的状态-of-the-art。"}}
{"id": "2601.09518", "pdf": "https://arxiv.org/pdf/2601.09518", "abs": "https://arxiv.org/abs/2601.09518", "authors": ["Wei-Jin Huang", "Yue-Yi Zhang", "Yi-Lin Wei", "Zhi-Wei Xia", "Juantao Tan", "Yuan-Ming Li", "Zhilin Zhao", "Wei-Shi Zheng"], "title": "Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, we first demonstrate that standard retargeting fails by breaking the essential contacts. We address this with PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data, however, exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. We therefore introduce D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are fused by the diffusion head to produce synchronized whole-body behaviors beyond mimicry. By decoupling these reasoning streams, our model learns robust temporal phases without being distracted by spatial noise, leading to responsive, synchronized collaboration. We validate our framework through extensive and rigorous simulations, demonstrating significant performance gains over baseline approaches and a complete, effective pipeline for learning complex whole-body interactions from HHI data.", "AI": {"tldr": "本文提出了PAIR和D-STAR方法，以解决从人类之间的互动数据中学习人形机器人与人的物理交互问题。", "motivation": "由于高质量的人类与人形机器人互动数据稀缺，阻碍了研究进展。该论文旨在利用丰富的两人类之间互动数据来开发有效的交互策略。", "method": "PAIR方法用于转换和生成适合人形机器人的互动数据；D-STAR是一个分层策略，解耦何时行动和何处行动的决策过程，以实现更复杂的同步全身行为。", "result": "通过广泛的模拟验证了该框架的有效性，并且在基准测试中表现出显著性能提升。", "conclusion": "提出的方法提供了一个完整的、有效的管道，用于从人类之间的互动数据中学得复杂的人形机器人与人的全身交互。"}}
{"id": "2601.09512", "pdf": "https://arxiv.org/pdf/2601.09512", "abs": "https://arxiv.org/abs/2601.09512", "authors": ["Ralf Römer", "Yi Zhang", "Angela P. Schoellig"], "title": "CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion", "categories": ["cs.RO", "cs.LG"], "comment": "Project page: https://tum-lsy.github.io/clare. 9 pages, 5 figures", "summary": "To teach robots complex manipulation tasks, it is now a common practice to fine-tune a pre-trained vision-language-action model (VLA) on task-specific data. However, since this recipe updates existing representations, it is unsuitable for long-term operation in the real world, where robots must continually adapt to new tasks and environments while retaining the knowledge they have already acquired. Existing continual learning methods for robotics commonly require storing previous data (exemplars), struggle with long task sequences, or rely on task identifiers for deployment. To address these limitations, we propose CLARE, a general, parameter-efficient framework for exemplar-free continual learning with VLAs. CLARE introduces lightweight modular adapters into selected feedforward layers and autonomously expands the model only where necessary when learning a new task, guided by layer-wise feature similarity. During deployment, an autoencoder-based routing mechanism dynamically activates the most relevant adapters without requiring task labels. Through extensive experiments on the LIBERO benchmark, we show that CLARE achieves high performance on new tasks without catastrophic forgetting of earlier tasks, significantly outperforming even exemplar-based methods. Code and data are available at https://tum-lsy.github.io/clare.", "AI": {"tldr": "本文介绍了CLARE，一种用于视觉语言行动模型的持续学习框架，通过自主适配器路由和扩展来实现无示例的持续学习。", "motivation": "现有的机器人复杂操控任务教学方法需要在特定数据上微调预训练的视觉语言行动模型，这不适用于长期的现实世界操作。因此，本文旨在提出一种无需存储之前的数据、能处理长任务序列且不依赖任务标识符的解决方案。", "method": "CLARE通过引入轻量级适配器到选定的前馈层，并在学习新任务时根据层次特征相似性自主扩展模型来实现持续学习。部署时，使用自编码路由机制动态激活最相关的适配器。", "result": "实验表明，CLARE能够在不遗忘之前任务知识的情况下，在LIBERO基准上对新任务达到高性能，显著优于基于示例的方法。", "conclusion": "CLARE提供了一种参数高效且无需存储旧数据的持续学习方法，适用于机器人在现实世界的长期操作。"}}
{"id": "2601.09508", "pdf": "https://arxiv.org/pdf/2601.09508", "abs": "https://arxiv.org/abs/2601.09508", "authors": ["Jean Peyen"], "title": "Boltzmann Sampling for Powersets without an Oracle", "categories": ["cs.DM", "cs.DS", "math.CO", "math.PR"], "comment": null, "summary": "We show that powersets over structures with a bounded counting sequence can be sampled efficiently without evaluating the generating function. An algorithm is provided, implemented, and tested. Runtimes are comparable to existing Boltzmann samplers reported in the literature.", "AI": {"tldr": "本文展示了如何在不评估生成函数的情况下，高效地对具有有界计数序列的结构的幂集进行采样。", "motivation": "动机在于提高对特定类型结构的幂集进行抽样的效率，并减少对oracle依赖的需求。", "method": "提供了一种算法并进行了实现和测试，该算法用于在不评估生成函数的情况下对具有有界计数序列的结构的幂集进行采样。", "result": "实验结果显示，所提供的算法的运行时间与其他文献中报告的Boltzmann抽样器相当。", "conclusion": "结论表明，在没有oracle的帮助下，也可以实现高效的幂集采样，并且性能可以与现有的Boltzmann抽样器相比拟。"}}
{"id": "2601.09506", "pdf": "https://arxiv.org/pdf/2601.09506", "abs": "https://arxiv.org/abs/2601.09506", "authors": ["Marek Černý"], "title": "On Numbers of Simplicial Walks and Equivalent Canonizations for Graph Recognition", "categories": ["cs.DM", "cs.CC", "cs.DS", "cs.LO"], "comment": "Accepted for LATIN 2026", "summary": "Two graphs are isomorphic exactly when they admit the same number of homomorphisms from every graph. Hence, a graph is recognized up to isomorphism by homomorphism counts over the class of all graphs. Restricting to a specific graph class yields some natural isomorphism relaxations and modulates recognition to particular graph properties. A notable restriction is to the classes of bounded treewidth, yielding the isomorphism relaxation of Weisfeiler--Leman refinement (WL), as shown by Dvořák [JGT 2010]. The properties recognized by WL are exactly those definable in fragments of first-order logic with counting quantifiers, as shown by Cai, Fürer, and Immerman [Comb. 1992]. We characterize the restriction to the classes of bounded pathwidth by numbers of simplicial walks, and formalize it into a refinement procedure (SW). The properties recognized by SW are exactly those definable in fragments of restricted-conjunction first-order logic with counting quantifiers, introduced by Montacute and Shah [LMCS 2024]. Unlike WL, computing SW directly is not polynomial-time in general. We address this by representing SW in terms of multiplicity automata. We equip these automata with an involution, simplifying the canonization to standard forward reduction and omitting the backward one. The resulting canonical form is computable in time $O(kn^{3k})$ for any graph on $n$ vertices and the restriction to pathwidth at most $k$.", "AI": {"tldr": "本文研究了通过简单路径计数对图同构问题的限制，提出了一个基于简陃walks的方法SW，并通过多重自动机表示简化其计算。", "motivation": "动机在于利用简单路径上的行进数量来识别特定宽度路径下的图性质，并探索这种方法在计算复杂性方面的优势和挑战。", "method": "提出了一种新的基于简单walks的同构放松（SW），并通过多重自动机表示简化其计算过程，同时引入了反转操作简化标准化过程。", "result": "结果表明，该方法能够精确地识别特定逻辑片段定义的图性质，并且对于路径宽度为k的图，其标准化形式可在时间复杂度O(kn^{3k})内计算得出。", "conclusion": "结论是SW提供了一种新的方式来识别和处理具有计数量词限制性合取的一阶逻辑片段中的图属性，尽管直接计算复杂度较高，但通过自动机简化后变得更为实用。"}}
{"id": "2601.09503", "pdf": "https://arxiv.org/pdf/2601.09503", "abs": "https://arxiv.org/abs/2601.09503", "authors": ["Siyuan Liu", "Hongbang Yuan", "Xinze Li", "Ziyue Zhu", "Yixin Cao", "Yu-Gang Jiang"], "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a under-examined concern. Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment. To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding. We instantiate this paradigm in T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs across multiple difficulty levels. Our extensive experiments reveal that task success is often a poor proxy for environment understanding, and that current memory machanism can not effectively help agents acquire a grounded model of the environment. These findings identify proactive exploration and fine-grained state representation as primary bottlenecks, offering a robust foundation for developing more generalizable autonomous agents.", "AI": {"tldr": "本文提出Task-to-Quiz（T2Q）范式，用于评估大语言模型代理在不同环境中的理解能力。", "motivation": "尽管大型语言模型代理在复杂决策和工具使用任务中表现出色，但它们的环境适应性未得到充分研究。现有的评价方法主要依赖于轨迹度量，未能准确衡量代理是否具有转移性的环境模型。", "method": "提出Task-to-Quiz（T2Q）范式并构建了包含30个环境和1,967个基础问答对的T2QBench测试套件来评估大语言模型在不同任务中的环境理解能力。", "result": "实验结果显示，任务成功往往是代理具有环境理解能力的一个差的替代指标，并且当前的记忆机制无法有效帮助代理构建基础化的环境模型。", "conclusion": "本研究指出主动探索和精细的状态表示是开发更通用自主代理的主要障碍，并为未来的研究提供了坚实的基础。"}}
{"id": "2601.09499", "pdf": "https://arxiv.org/pdf/2601.09499", "abs": "https://arxiv.org/abs/2601.09499", "authors": ["Edgar Sucar", "Eldar Insafutdinov", "Zihang Lai", "Andrea Vedaldi"], "title": "V-DPM: 4D Video Reconstruction with Dynamic Point Maps", "categories": ["cs.CV"], "comment": "Project page: https://www.robots.ox.ac.uk/~vgg/research/vdpm/", "summary": "Powerful 3D representations such as DUSt3R invariant point maps, which encode 3D shape and camera parameters, have significantly advanced feed forward 3D reconstruction. While point maps assume static scenes, Dynamic Point Maps (DPMs) extend this concept to dynamic 3D content by additionally representing scene motion. However, existing DPMs are limited to image pairs and, like DUSt3R, require post processing via optimization when more than two views are involved. We argue that DPMs are more useful when applied to videos and introduce V-DPM to demonstrate this. First, we show how to formulate DPMs for video input in a way that maximizes representational power, facilitates neural prediction, and enables reuse of pretrained models. Second, we implement these ideas on top of VGGT, a recent and powerful 3D reconstructor. Although VGGT was trained on static scenes, we show that a modest amount of synthetic data is sufficient to adapt it into an effective V-DPM predictor. Our approach achieves state of the art performance in 3D and 4D reconstruction for dynamic scenes. In particular, unlike recent dynamic extensions of VGGT such as P3, DPMs recover not only dynamic depth but also the full 3D motion of every point in the scene.", "AI": {"tldr": "本文介绍了V-DPM，一种用于动态场景的4D视频重建方法。", "motivation": "现有的Dynamic Point Maps（DPM）仅限于图像对，并且当涉及多视图时需要额外优化处理。作者认为将DPM应用于视频能发挥更大的作用并提出此研究。", "method": "通过改进DPM使其适用于视频输入，最大化表示能力、简化神经网络预测，并重用预训练模型。在VGGT上实现这些想法，使用少量合成数据将其适应为有效的V-DPM预测器。", "result": "该方法在动态场景的3D和4D重建中达到最先进的性能，不仅能恢复动态深度还能完整地重构每个点的3D运动轨迹。", "conclusion": "通过改进DPM并应用于视频输入，可以在无需大量额外训练的情况下实现对动态场景的有效4D重建。"}}
{"id": "2601.09497", "pdf": "https://arxiv.org/pdf/2601.09497", "abs": "https://arxiv.org/abs/2601.09497", "authors": ["Ritabrata Chakraborty", "Hrishit Mitra", "Shivakumara Palaiahnakote", "Umapada Pal"], "title": "Towards Robust Cross-Dataset Object Detection Generalization under Domain Specificity", "categories": ["cs.CV", "cs.LG"], "comment": "15 pages, 4 figures, 6 tables", "summary": "Object detectors often perform well in-distribution, yet degrade sharply on a different benchmark. We study cross-dataset object detection (CD-OD) through a lens of setting specificity. We group benchmarks into setting-agnostic datasets with diverse everyday scenes and setting-specific datasets tied to a narrow environment, and evaluate a standard detector family across all train--test pairs. This reveals a clear structure in CD-OD: transfer within the same setting type is relatively stable, while transfer across setting types drops substantially and is often asymmetric. The most severe breakdowns occur when transferring from specific sources to agnostic targets, and persist after open-label alignment, indicating that domain shift dominates in the hardest regimes. To disentangle domain shift from label mismatch, we compare closed-label transfer with an open-label protocol that maps predicted classes to the nearest target label using CLIP similarity. Open-label evaluation yields consistent but bounded gains, and many corrected cases correspond to semantic near-misses supported by the image evidence. Overall, we provide a principled characterization of CD-OD under setting specificity and practical guidance for evaluating detectors under distribution shift. Code will be released at \\href{[https://github.com/Ritabrata04/cdod-icpr.git}{https://github.com/Ritabrata04/cdod-icpr}.", "AI": {"tldr": "本文研究了跨数据集目标检测（CD-OD）在特定场景下的鲁棒性问题，并提供了针对领域差异的实用评估指导。", "motivation": "动机在于探讨和解决现有对象检测器在不同基准测试下性能大幅下降的问题，特别是当从特定环境迁移到通用场景时的表现不佳。", "method": "将基准数据集分为场景无关和场景相关的两类，使用标准检测器家族进行跨训练-测试对的评估。并通过开放标签协议来区分领域转移和标签错配的影响。", "result": "结果表明，在相同类型设置内的迁移相对稳定，而不同类型的迁移性能显著下降。特别是从特定源向通用目标环境迁移时会出现最严重的性能崩溃，这种现象即使在开放标签对齐后仍然存在。", "conclusion": "本文提供了一种原则性的CD-OD场景特异性特征描述，并为评估分布偏移下的检测器提供了实际指导。"}}
{"id": "2601.09489", "pdf": "https://arxiv.org/pdf/2601.09489", "abs": "https://arxiv.org/abs/2601.09489", "authors": ["Peyman Afshani", "Rezaul Chowdhury", "Inge Li Gørtz", "Mayank Goswami", "Francesco Silvestri", "Mariafiore Tognon"], "title": "How many users have been here for a long time? Efficient solutions for counting long aggregated visits", "categories": ["cs.DS"], "comment": null, "summary": "This paper addresses the Counting Long Aggregated Visits problem, which is defined as follows. We are given $n$ users and $m$ regions, where each user spends some time visiting some regions. For a parameter $k$ and a query consisting of a subset of $r$ regions, the task is to count the number of distinct users whose aggregate time spent visiting the query regions is at least $k$. This problem is motivated by queries arising in the analysis of large-scale mobility datasets. We present several exact and approximate data structures for supporting counting long aggregated visits, as well as conditional and unconditional lower bounds. First, we describe an exact data structure that exhibits a space-time tradeoff, as well as efficient approximate solutions based on sampling and sketching techniques. We then study the problem in geometric settings where regions are points in $\\mathbb{R}^d$ and queries are hyperrectangles, and derive exact data structures that achieve improved performance in these structured spaces.", "AI": {"tldr": "本文解决了统计长时间聚集访问的问题，提出了多种精确和近似的数据结构来支持这种计数，并研究了几何设置下的性能改进。", "motivation": "该问题源于大规模移动数据集分析中出现的查询需求，特别是要计算在某些区域总停留时间至少为k的不同用户数量。", "method": "本文介绍了具有时空权衡的精确数据结构以及基于采样和素描技术的有效近似解决方案，并探讨了几何空间中的精确数据结构以提高性能。", "result": "提出了几种用于支持长时间聚集访问计数的确切和近似数据结构，包括在几何设置中实现改进性能的数据结构，并给出了条件性和非条件性下界。", "conclusion": "研究提供了多种解决方案来高效地解决长时间聚合访问的计数问题，特别是在处理大规模移动数据集时能提供有效的查询支持。"}}
{"id": "2601.09478", "pdf": "https://arxiv.org/pdf/2601.09478", "abs": "https://arxiv.org/abs/2601.09478", "authors": ["Renqiang Luo", "Dong Zhang", "Yupeng Gao", "Wen Shi", "Mingliang Hou", "Jiaying Liu", "Zhe Wang", "Shuo Yu"], "title": "Bridging Semantic Understanding and Popularity Bias with LLMs", "categories": ["cs.IR", "cs.AI"], "comment": "10 pages, 4 figs, WWW 2026 accepted", "summary": "Semantic understanding of popularity bias is a crucial yet underexplored challenge in recommender systems, where popular items are often favored at the expense of niche content. Most existing debiasing methods treat the semantic understanding of popularity bias as a matter of diversity enhancement or long-tail coverage, neglecting the deeper semantic layer that embodies the causal origins of the bias itself. Consequently, such shallow interpretations limit both their debiasing effectiveness and recommendation accuracy. In this paper, we propose FairLRM, a novel framework that bridges the gap in the semantic understanding of popularity bias with Recommendation via Large Language Model (RecLLM). FairLRM decomposes popularity bias into item-side and user-side components, using structured instruction-based prompts to enhance the model's comprehension of both global item distributions and individual user preferences. Unlike traditional methods that rely on surface-level features such as \"diversity\" or \"debiasing\", FairLRM improves the model's ability to semantically interpret and address the underlying bias. Through empirical evaluation, we show that FairLRM significantly enhances both fairness and recommendation accuracy, providing a more semantically aware and trustworthy approach to enhance the semantic understanding of popularity bias. The implementation is available at https://github.com/LuoRenqiang/FairLRM.", "AI": {"tldr": "本文提出FairLRM框架，通过大型语言模型（RecLLM）增强推荐系统对流行偏见的语义理解，从而提高公平性和推荐准确性。", "motivation": "现有的去偏方法忽视了流行偏见背后的深层语义原因，导致其去偏效果和推荐准确性的局限性。本文旨在解决这一问题，以提升推荐系统的性能。", "method": "FairLRM将流行偏见分解为项目侧和用户侧组件，并使用结构化指令提示来增强模型对全局项目分布和个人用户喜好的理解。", "result": "实验结果表明，FairLRM显著提升了公平性和推荐准确性，提供了一种语义上更明智且值得信赖的方法来处理流行偏见。", "conclusion": "通过引入大型语言模型和结构化指令提示技术，FairLRM框架在解决推荐系统中的流行偏见问题方面表现优异，为该领域提供了新的解决方案。"}}
{"id": "2601.09477", "pdf": "https://arxiv.org/pdf/2601.09477", "abs": "https://arxiv.org/abs/2601.09477", "authors": ["Joel Andersson", "Matti Karppa"], "title": "Engineering Compressed Matrix Multiplication with the Fast Walsh-Hadamard Transform", "categories": ["cs.DS"], "comment": "23 pages", "summary": "We present an implementation of Pagh's compressed matrix multiplication algorithm, a randomized algorithm that constructs sketches of matrices to compute an unbiased estimate of their product. By leveraging fast polynomial multiplication via the FFT, the algorithm achieves high performance when the product matrix is sparse or contains only a small number of entries with magnitudes significantly larger than the rest. We show empirically that the algorithm is practical and can outperform state-of-the-art DGEMM implementations when the product matrix has few nonzero entries or is otherwise dominated by a small subset of elements with large magnitude. As a minor theoretical contribution, we replace the FFT with the Fast Walsh-Hadamard Transform (FWHT) in sketched multiplication, preserving all correctness and variance guarantees of the original algorithm. Experiments with our carefully engineered multithreaded CPU implementation for dense double-precision matrices on 64-core CPU nodes across a range of synthetic benchmarks, exhibiting variable sparsity patterns, show that the FWHT variant is up to 4 times faster than the FFT-based version. Under favorable sparsity and magnitude patterns in the product matrix, our FWHT-based implementation achieves a speedup of up to 40 over DGEMM from Intel MKL, with low probability of error in the estimates. Our implementation is released as free software and comes with NumPy-compatible Python bindings.", "AI": {"tldr": "本文介绍了Pagh的压缩矩阵乘法算法的实现，并通过快速沃尔什哈达玛变换（FWHT）替代传统的快速傅里叶变换（FFT），改进了该算法，使其在特定条件下性能更优。", "motivation": "旨在提高稀疏或包含少量大值元素的大规模矩阵乘法的速度。传统方法在处理这些情况时效率较低，因此提出了一种基于随机化的压缩乘法技术来改进现有方法。", "method": "通过使用FWHT替代FFT，本文实现了一个高效的压缩矩阵乘法算法，该算法能够对矩阵进行抽样并计算其乘积的无偏估计值。", "result": "实验表明，在产品矩阵稀疏或由少量大值元素主导时，基于FWHT的方法比传统的DGEMM快40倍，并且具有较低的概率误差。", "conclusion": "研究表明，通过使用FWHT替换FFT，可以在保证算法正确性和方差保证的前提下提高压缩矩阵乘法的效率。此实现作为自由软件发布，并提供了与NumPy兼容的Python绑定。"}}
{"id": "2601.09473", "pdf": "https://arxiv.org/pdf/2601.09473", "abs": "https://arxiv.org/abs/2601.09473", "authors": ["Oliver Bolton", "Aakanksha", "Arash Ahmadian", "Sara Hooker", "Marzieh Fadaee", "Beyza Ermis"], "title": "SimMerge: Learning to Select Merge Operators from Similarity Signals", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model merging enables multiple large language models (LLMs) to be combined into a single model while preserving performance. This makes it a valuable tool in LLM development, offering a competitive alternative to multi-task training. However, merging can be difficult at scale, as successful merging requires choosing the right merge operator, selecting the right models, and merging them in the right order. This often leads researchers to run expensive merge-and-evaluate searches to select the best merge. In this work, we provide an alternative by introducing \\simmerge{}, \\emph{a predictive merge-selection method} that selects the best merge using inexpensive, task-agnostic similarity signals between models. From a small set of unlabeled probes, we compute functional and structural features and use them to predict the performance of a given 2-way merge. Using these predictions, \\simmerge{} selects the best merge operator, the subset of models to merge, and the merge order, eliminating the expensive merge-and-evaluate loop. We demonstrate that we surpass standard merge-operator performance on 2-way merges of 7B-parameter LLMs, and that \\simmerge{} generalizes to multi-way merges and 111B-parameter LLM merges without retraining. Additionally, we present a bandit variant that supports adding new tasks, models, and operators on the fly. Our results suggest that learning how to merge is a practical route to scalable model composition when checkpoint catalogs are large and evaluation budgets are tight.", "AI": {"tldr": "本文介绍了SimMerge，一种使用模型之间的相似性信号来预测和选择最优合并操作的方法。", "motivation": "文章旨在解决大规模语言模型（LLMs）在合并过程中遇到的困难，特别是如何高效地选择合适的合并操作、选取正确的模型并确定合并顺序的问题。", "method": "SimMerge通过计算少量无标签探针的功能性和结构性特征来预测两模型合并后的性能，从而选出最优的合并操作、待合并的模型子集及合并顺序。", "result": "实验表明SimMerge在7亿参数级LLM的二元合并中超越了标准合并操作的表现，并且能够泛化到多路合并和111亿参数级LLMs合并。此外，还提出了一种支持动态添加任务、模型和操作的变体。", "conclusion": "研究结果显示，在检查点目录大且评估预算有限的情况下，学习如何合并是实现可扩展模型组合的一种实用途径。"}}
{"id": "2601.09470", "pdf": "https://arxiv.org/pdf/2601.09470", "abs": "https://arxiv.org/abs/2601.09470", "authors": ["Natalia Revenga-Lozano", "Karina E. Avila", "Steffen Steinert", "Matthias Schweinberger", "Clara E. Gómez-Pérez", "Jochen Kuhn", "Stefan Küchemann"], "title": "Personalized Multimodal Feedback Using Multiple External Representations: Strategy Profiles and Learning in High School Physics", "categories": ["physics.ed-ph", "cs.AI"], "comment": "Keywords: Adaptive Feedback, Multimodal Learning, Multiple External Representations, Physics Education, Science Education, Representational Competences, Intelligent Tutoring Systems", "summary": "Multiple external representations (MERs) and personalized feedback support physics learning, yet evidence on how personalized feedback can effectively integrate MERs remains limited. This question is particularly timely given the emergence of multimodal large language models. We conducted a 16-24 week observational study in high school physics (N=661) using a computer-based platform that provided verification and optional elaborated feedback in verbal, graphical and mathematical forms. Linear mixed-effects models and strategy-cluster analyses (ANCOVA-adjusted comparisons) tested associations between feedback use and post-test performance and moderation by representational competence. Elaborated multirepresentational feedback showed a small but consistent positive association with post-test scores independent of prior knowledge and confidence. Learners adopted distinct representation-selection strategies; among students with lower representational competence, using a diverse set of representations related to higher learning, whereas this advantage diminished as competence increased. These findings motivate adaptive feedback designs and inform intelligent tutoring systems capable of tailoring feedback elaboration and representational format to learner profiles, advancing personalized instruction in physics education.", "AI": {"tldr": "研究探讨了个性化反馈如何有效整合多种外部表现形式以支持高中物理学习，并分析不同表征能力的学生的策略差异。", "motivation": "尽管多样的外部表示和个性化的反馈对物理学习有益，但关于如何将这些元素有效结合的研究仍然有限。随着多模态大型语言模型的出现，这个问题变得更加紧迫。", "method": "研究者在一所高中的661名学生中进行了一项为期16-24周的观察性研究，并使用电脑平台提供口头、图形和数学形式的反馈验证及详细说明。通过线性混合效应模型和策略聚类分析（ANCOVA调整比较）来测试反馈使用与后续测试成绩之间的关联。", "result": "详细的多表现形式反馈显示出对后续测试分数的小但一致的正面影响，这一结果独立于先前的知识和自信水平。学生采用了不同的表征选择策略；在表征能力较低的学生中，使用多样化的表示方法与更高的学习成果相关联，而这种优势随着表征能力提高而减少。", "conclusion": "研究发现支持自适应反馈设计，并为能够根据学习者档案定制反馈详细程度和表现形式的智能辅导系统提供了信息，有助于推进个性化物理教育的发展。"}}
{"id": "2601.09469", "pdf": "https://arxiv.org/pdf/2601.09469", "abs": "https://arxiv.org/abs/2601.09469", "authors": ["Renqiang Luo", "Yongshuai Yang", "Huafei Huang", "Qing Qing", "Mingliang Hou", "Ziqi Xu", "Yi Yu", "Jingjing Zhou", "Feng Xia"], "title": "FairGU: Fairness-aware Graph Unlearning in Social Network", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 2 figs, WWW 2026 accepted", "summary": "Graph unlearning has emerged as a critical mechanism for supporting sustainable and privacy-preserving social networks, enabling models to remove the influence of deleted nodes and thereby better safeguard user information. However, we observe that existing graph unlearning techniques insufficiently protect sensitive attributes, often leading to degraded algorithmic fairness compared with traditional graph learning methods. To address this gap, we introduce FairGU, a fairness-aware graph unlearning framework designed to preserve both utility and fairness during the unlearning process. FairGU integrates a dedicated fairness-aware module with effective data protection strategies, ensuring that sensitive attributes are neither inadvertently amplified nor structurally exposed when nodes are removed. Through extensive experiments on multiple real-world datasets, we demonstrate that FairGU consistently outperforms state-of-the-art graph unlearning methods and fairness-enhanced graph learning baselines in terms of both accuracy and fairness metrics. Our findings highlight a previously overlooked risk in current unlearning practices and establish FairGU as a robust and equitable solution for the next generation of socially sustainable networked systems. The codes are available at https://github.com/LuoRenqiang/FairGU.", "AI": {"tldr": "本文提出了FairGU，一个公平意识的图遗忘框架，旨在在删除节点时保持模型的效用和公平性。", "motivation": "现有的图遗忘技术不足以保护敏感属性，并且可能导致算法公平性的下降。为了弥补这一不足，作者提出了一种新的方法来维护用户信息的安全并提高算法的公平性。", "method": "FairGU结合了专门的公平意识模块和有效的数据保护策略，以确保在删除节点时不会无意中放大或暴露敏感属性。", "result": "通过在多个真实世界的数据集上的广泛实验，证明了FairGU在准确性和公平性指标上均优于现有的图遗忘方法和增强公平性的基线。", "conclusion": "研究揭示了当前遗忘实践中被忽视的风险，并建立了FairGU作为下一代社会可持续网络系统中的稳健和平等解决方案。"}}
{"id": "2601.09467", "pdf": "https://arxiv.org/pdf/2601.09467", "abs": "https://arxiv.org/abs/2601.09467", "authors": ["Tianye Li", "Qi Liu", "Hao Li", "Lei Chen", "Wencong Cheng", "Fei Zheng", "Xiangao Xia", "Ya Wang", "Gang Huang", "Weiwei Wang", "Xuan Tong", "Ziqing Zu", "Yi Fang", "Shenming Fu", "Jiang Jiang", "Haochen Li", "Mingxing Li", "Jiangjiang Xia"], "title": "Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "Accurate global medium-range weather forecasting is fundamental to Earth system science. Most existing Transformer-based forecasting models adopt vision-centric architectures that neglect the Earth's spherical geometry and zonal periodicity. In addition, conventional autoregressive training is computationally expensive and limits forecast horizons due to error accumulation. To address these challenges, we propose the Shifted Earth Transformer (Searth Transformer), a physics-informed architecture that incorporates zonal periodicity and meridional boundaries into window-based self-attention for physically consistent global information exchange. We further introduce a Relay Autoregressive (RAR) fine-tuning strategy that enables learning long-range atmospheric evolution under constrained memory and computational budgets. Based on these methods, we develop YanTian, a global medium-range weather forecasting model. YanTian achieves higher accuracy than the high-resolution forecast of the European Centre for Medium-Range Weather Forecasts and performs competitively with state-of-the-art AI models at one-degree resolution, while requiring roughly 200 times lower computational cost than standard autoregressive fine-tuning. Furthermore, YanTian attains a longer skillful forecast lead time for Z500 (10.3 days) than HRES (9 days). Beyond weather forecasting, this work establishes a robust algorithmic foundation for predictive modeling of complex global-scale geophysical circulation systems, offering new pathways for Earth system science.", "AI": {"tldr": "本文提出了Shifted Earth Transformer（Searth Transformer）架构，结合地球物理先验知识进行全球中期天气预报，并开发了YanTian模型。", "motivation": "现有的基于Transformer的预测模型忽略了地球的球形几何结构和纬度周期性，并且传统自回归训练计算成本高，限制了预测范围。", "method": "本文提出了Searth Transformer架构，将经纬度边界信息融入窗口化自我注意机制中，采用Relay Autoregressive（RAR）微调策略，在有限内存和计算预算下学习长距离大气演变。", "result": "YanTian模型在精度上超过了欧洲中期天气预报中心的高分辨率预测，并且在一度分辨率上与最先进的AI模型相媲美，而计算成本却低了大约200倍。Z500的有效预测时间达到了10.3天，比HRES多出1.3天。", "conclusion": "本文的工作为地球系统科学中的复杂全球尺度地物循环系统的预测建模奠定了坚实的算法基础，并开辟了新的研究途径。"}}
{"id": "2601.09465", "pdf": "https://arxiv.org/pdf/2601.09465", "abs": "https://arxiv.org/abs/2601.09465", "authors": ["Shuo Zhang", "Chaofa Yuan", "Ryan Guo", "Xiaomin Yu", "Rui Xu", "Zhangquan Chen", "Zinuo Li", "Zhi Yang", "Shuhao Guan", "Zhenheng Tang", "Sen Hu", "Liwen Zhang", "Ronghao Chen", "Huacan Wang"], "title": "EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines", "categories": ["cs.AI"], "comment": null, "summary": "While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.", "AI": {"tldr": "本文介绍了EvoFSM框架，通过演化有限状态机来实现深度研究中的可控制自我进化。", "motivation": "现有的基于大语言模型的代理通常依赖于固定的流程，在处理开放性问题时难以适应。为了提高问题解决能力并避免不稳定性和指令偏离，提出了一种结构化的自我进化框架EvoFSM。", "method": "EvoFSM将优化空间拆分为宏观流程（状态转换逻辑）和微观技能（状态特定行为），并通过批评机制引导通过受约束的操作来细化有限状态机，并结合自演化的记忆机制提炼成功轨迹和失败模式。", "result": "在五个多跳问题解答基准测试中，EvoFSM表现出色，在DeepSearch基准上达到58.0%的准确率。此外，在交互式决策任务上的额外结果进一步验证了其泛化能力。", "conclusion": "EvoFSM框架通过演化的有限状态机实现深度研究中的自我进化和控制，并在多个测试中证明其有效性。"}}
{"id": "2601.09461", "pdf": "https://arxiv.org/pdf/2601.09461", "abs": "https://arxiv.org/abs/2601.09461", "authors": ["Reemt Hinrichs", "Muhamad Fadli Damara", "Stephan Preihs", "Jörn Ostermann"], "title": "Analysis of the Maximum Prediction Gain of Short-Term Prediction on Sustained Speech", "categories": ["cs.SD"], "comment": "Rejected at Eurasip for practical irrelevancy. Submitted here for reference. Originally accepted at DCC 2020 (Poster) but withdrawn due to page count limit", "summary": "Signal prediction is widely used in, e.g., economic forecasting, echo cancellation and in data compression, particularly in predictive coding of speech and music. Predictive coding algorithms reduce the bit-rate required for data transmission or storage by signal prediction. The prediction gain is a classic measure in applied signal coding of the quality of a predictor, as it links the mean-squared prediction error to the signal-to-quantization-noise of predictive coders. To evaluate predictor models, knowledge about the maximum achievable prediction gain independent of a predictor model is desirable. In this manuscript, Nadaraya-Watson kernel-regression (NWKR) and an information theoretic upper bound are applied to analyze the upper bound of the prediction gain on a newly recorded dataset of sustained speech/phonemes. It was found that for unvoiced speech a linear predictor always achieves the maximum prediction gain within at most 0.3 dB. On voiced speech, the optimum one-tap predictor was found to be linear but starting with two taps, the maximum achievable prediction gain was found to be about 2 dB to 6 dB above the prediction gain of the linear predictor. Significant differences between speakers/subjects were observed. The created dataset as well as the code can be obtained for research purpose upon request.", "AI": {"tldr": "论文分析了短期预测在持续语音上的最大预测增益，并评估了线性预测器和非线性预测器的性能差异。", "motivation": "为了评估预测模型的质量，了解独立于任何特定预测模型的最大可实现预测增益是有必要的。因此，本文旨在研究不同类型的语音（清音和浊音）上的最大预测增益。", "method": "应用Nadaraya-Watson核回归（NWKR）和信息论上限分析新录制的持续语音/音素数据集上的最大预测增益。", "result": "对于清音，线性预测器始终能达到最大预测增益，误差不超过0.3 dB；而对于浊音，最优单抽头预测器是线性的，但从两抽头开始，非线性预测器的最大可实现预测增益比线性预测器高出约2 dB到6 dB。不同说话人之间存在显著差异。", "conclusion": "研究结果表明，在清音中线性预测效果最佳，而在浊音中非线性预测具有更高的潜在性能优势，且不同个体间的表现有明显区别。"}}
{"id": "2601.09460", "pdf": "https://arxiv.org/pdf/2601.09460", "abs": "https://arxiv.org/abs/2601.09460", "authors": ["Francesco Capano", "Jonas Böhler", "Benjamin Weggenmann"], "title": "SoK: Enhancing Cryptographic Collaborative Learning with Differential Privacy", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML 2026)", "summary": "In collaborative learning (CL), multiple parties jointly train a machine learning model on their private datasets. However, data can not be shared directly due to privacy concerns. To ensure input confidentiality, cryptographic techniques, e.g., multi-party computation (MPC), enable training on encrypted data. Yet, even securely trained models are vulnerable to inference attacks aiming to extract memorized data from model outputs. To ensure output privacy and mitigate inference attacks, differential privacy (DP) injects calibrated noise during training. While cryptography and DP offer complementary guarantees, combining them efficiently for cryptographic and differentially private CL (CPCL) is challenging. Cryptography incurs performance overheads, while DP degrades accuracy, creating a privacy-accuracy-performance trade-off that needs careful design considerations. This work systematizes the CPCL landscape. We introduce a unified framework that generalizes common phases across CPCL paradigms, and identify secure noise sampling as the foundational phase to achieve CPCL. We analyze trade-offs of different secure noise sampling techniques, noise types, and DP mechanisms discussing their implementation challenges and evaluating their accuracy and cryptographic overhead across CPCL paradigms. Additionally, we implement identified secure noise sampling options in MPC and evaluate their computation and communication costs in WAN and LAN. Finally, we propose future research directions based on identified key observations, gaps and possible enhancements in the literature.", "AI": {"tldr": "本文介绍了加密协作学习（CPCL）的统一框架，并分析了在实现CPCL过程中不同噪声采样技术、噪声类型和差分隐私机制之间的权衡，以解决隐私保护与准确性和性能之间的矛盾。", "motivation": "协作学习中数据共享存在隐私风险，即使使用加密技术和差分隐私也有信息泄露的风险。本文旨在系统化分析如何有效结合加密技术和差分隐私实现CPCL，并探讨其在实际应用中的挑战和潜在改进方向。", "method": "提出一个统一框架概括了CPCL中的常见阶段，并重点研究了安全噪声采样技术的准确性及密码学开销，同时通过实验评估了这些技术在网络环境下的计算和通信成本。", "result": "识别并分析了不同的安全噪声采样技术和差分隐私机制在准确性和性能上的权衡，并通过实验证明了这些技术在网络环境中的具体实现挑战。", "conclusion": "本文系统化了CPCL领域，提出了一个统一框架来解决协作学习中数据保密和防止信息泄露的问题，并为未来的研究方向提供了建议。"}}
{"id": "2601.09455", "pdf": "https://arxiv.org/pdf/2601.09455", "abs": "https://arxiv.org/abs/2601.09455", "authors": ["André Artelt", "Martin Olsen", "Kevin Tierney"], "title": "On the Hardness of Computing Counterfactual and Semifactual Explanations in XAI", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in Transactions on Machine Learning Research (TMLR), 2025 -- https://openreview.net/pdf?id=aELzBw0q1O", "summary": "Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications. Counterfactual and semi-factual explanations have emerged as two mechanisms for providing users with insights into the outputs of their models. We provide an overview of the computational complexity results in the literature for generating these explanations, finding that in many cases, generating explanations is computationally hard. We strengthen the argument for this considerably by further contributing our own inapproximability results showing that not only are explanations often hard to generate, but under certain assumptions, they are also hard to approximate. We discuss the implications of these complexity results for the XAI community and for policymakers seeking to regulate explanations in AI.", "AI": {"tldr": "本文探讨了在可解释人工智能（XAI）中生成反事实和半事实解释的计算复杂性问题。", "motivation": "提供机器学习模型选择的清晰解释对于这些模型部署于关键应用至关重要。该论文旨在讨论产生这两类解释的困难程度及其对政策制定者的意义。", "method": "本文通过综述现有文献中的计算复杂度结果，并贡献了自己关于不可近似性的新成果，来探讨生成反事实和半事实解释的难度。", "result": "研究表明，在许多情况下生成这些解释是计算上复杂的，并且在某些假设下，它们不仅难以生成，而且也难于近似。", "conclusion": "该研究揭示了为AI提供解释时面临的挑战，并讨论了对XAI社区和寻求监管AI中解释工作的政策制定者的意义。"}}
{"id": "2601.09452", "pdf": "https://arxiv.org/pdf/2601.09452", "abs": "https://arxiv.org/abs/2601.09452", "authors": ["Ahmad Rahimi", "Valentin Gerard", "Eloi Zablocki", "Matthieu Cord", "Alexandre Alahi"], "title": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "categories": ["cs.CV"], "comment": null, "summary": "Recent video diffusion models generate photorealistic, temporally coherent videos, yet they fall short as reliable world models for autonomous driving, where structured motion and physically consistent interactions are essential. Adapting these generalist video models to driving domains has shown promise but typically requires massive domain-specific data and costly fine-tuning. We propose an efficient adaptation framework that converts generalist video diffusion models into controllable driving world models with minimal supervision. The key idea is to decouple motion learning from appearance synthesis. First, the model is adapted to predict structured motion in a simplified form: videos of skeletonized agents and scene elements, focusing learning on physical and social plausibility. Then, the same backbone is reused to synthesize realistic RGB videos conditioned on these motion sequences, effectively \"dressing\" the motion with texture and lighting. This two-stage process mirrors a reasoning-rendering paradigm: first infer dynamics, then render appearance. Our experiments show this decoupled approach is exceptionally efficient: adapting SVD, we match prior SOTA models with less than 6% of their compute. Scaling to LTX, our MAD-LTX model outperforms all open-source competitors, and supports a comprehensive suite of text, ego, and object controls. Project page: https://vita-epfl.github.io/MAD-World-Model/", "AI": {"tldr": "本文提出了一种高效适应框架，将通用视频扩散模型转化为可控的驾驶世界模型。", "motivation": "现有的视频扩散模型虽然能够生成逼真的视频，但在自动驾驶领域表现不佳，因为它们缺乏结构化的运动和物理一致性。为了克服这一问题并减少对特定领域数据的需求及昂贵的微调过程，提出了这种方法。", "method": "该方法将动作学习与外观合成解耦，先简化形式预测结构化运动（如骨架化代理和场景元素视频），再基于这些动作序列生成逼真的RGB视频。", "result": "实验表明这种分离的方法非常高效：通过适应SVD，仅使用不到6%的计算资源就可以匹配先前的最佳模型表现；扩展到LTX后，MAD-LTX模型超过了所有开源竞争对手，并支持全面的文本、自我和对象控制。", "conclusion": "该研究展示了一种有效将通用视频扩散模型转化为自动驾驶领域可靠世界模型的方法，且在效率和性能方面表现出色。"}}
{"id": "2601.09451", "pdf": "https://arxiv.org/pdf/2601.09451", "abs": "https://arxiv.org/abs/2601.09451", "authors": ["Yizhi Chen", "Ahmed Hemani"], "title": "Late Breaking Results: Quamba-SE: Soft-edge Quantizer for Activations in State Space Models", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "Accepted to DATE Late Breaking Results 2026, Verona, Italy", "summary": "We propose Quamba-SE, a soft-edge quantizer for State Space Model (SSM) activation quantization. Unlike existing methods, using standard INT8 operation, Quamba-SE employs three adaptive scales: high-precision for small values, standard scale for normal values, and low-precision for outliers. This preserves outlier information instead of hard clipping, while maintaining precision for other values. We evaluate on Mamba- 130M across 6 zero-shot benchmarks. Results show that Quamba- SE consistently outperforms Quamba, achieving up to +2.68% on individual benchmarks and up to +0.83% improvement in the average accuracy of 6 datasets.", "AI": {"tldr": "提出Quamba-SE，一种用于状态空间模型激活量化的软边缘量化器。", "motivation": "现有的方法使用标准INT8操作来处理量化问题，而Quamba-SE通过采用三个自适应尺度（高精度、标准尺度和低精度）来更好地保留异常值信息并保持其他值的精度。", "method": "Quamba-SE采用三种自适应尺度：高精度用于小值，标准尺度用于正常值，低精度用于异常值。这种量化方法在处理异常值时不会进行硬裁剪，并维持了其它值的精度。", "result": "评估结果显示，Quamba-SE比Quamba有更好的性能，在个别基准测试中最高提升了2.68%，在六个数据集中的平均准确率提高了0.83%。", "conclusion": "Quamba-SE通过其软边缘量化策略有效地改善了状态空间模型的激活量化问题，并在零样本基准上展示了优于现有方法的表现。"}}
{"id": "2601.09449", "pdf": "https://arxiv.org/pdf/2601.09449", "abs": "https://arxiv.org/abs/2601.09449", "authors": ["Darya Baranouskaya", "Andrea Cavallaro"], "title": "PrivLEX: Detecting legal concepts in images through Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "We present PrivLEX, a novel image privacy classifier that grounds its decisions in legally defined personal data concepts. PrivLEX is the first interpretable privacy classifier aligned with legal concepts that leverages the recognition capabilities of Vision-Language Models (VLMs). PrivLEX relies on zero-shot VLM concept detection to provide interpretable classification through a label-free Concept Bottleneck Model, without requiring explicit concept labels during training. We demonstrate PrivLEX's ability to identify personal data concepts that are present in images. We further analyse the sensitivity of such concepts as perceived by human annotators of image privacy datasets.", "AI": {"tldr": "本文介绍了PrivLEX，一种基于Vision-Language Models的图像隐私分类器，能够识别图片中的法律定义的个人数据概念。", "motivation": "为了创建一个可解释且与法律概念对齐的隐私分类器，作者开发了PrivLEX，以提高图像隐私保护的能力并理解人类如何感知这些隐私概念。", "method": "PrivLEX使用零样本Vision-Language Models（VLMs）的概念检测来识别图片中是否存在个人数据概念，并通过无标签的概念瓶颈模型提供可解释的分类结果。", "result": "实验展示了PrivLEX能够成功识别图像中的个人数据概念，同时分析了这些概念在人类标注者对图像隐私数据集感知上的敏感度。", "conclusion": "PrivLEX证明了基于VLMs的零样本学习方法在检测图片中法律定义个人数据概念的有效性，并提供了可解释的结果。"}}
{"id": "2601.09448", "pdf": "https://arxiv.org/pdf/2601.09448", "abs": "https://arxiv.org/abs/2601.09448", "authors": ["Ioannis Stylianou", "Jon Francombe", "Pablo Martinez-Nuevo", "Sven Ewan Shepstone", "Zheng-Hua Tan"], "title": "Population-Aligned Audio Reproduction With LLM-Based Equalizers", "categories": ["cs.SD", "cs.AI"], "comment": "12 pages, 13 figures, 2 tables, IEEE JSTSP journal submission under first revision", "summary": "Conventional audio equalization is a static process that requires manual and cumbersome adjustments to adapt to changing listening contexts (e.g., mood, location, or social setting). In this paper, we introduce a Large Language Model (LLM)-based alternative that maps natural language text prompts to equalization settings. This enables a conversational approach to sound system control. By utilizing data collected from a controlled listening experiment, our models exploit in-context learning and parameter-efficient fine-tuning techniques to reliably align with population-preferred equalization settings. Our evaluation methods, which leverage distributional metrics that capture users' varied preferences, show statistically significant improvements in distributional alignment over random sampling and static preset baselines. These results indicate that LLMs could function as \"artificial equalizers,\" contributing to the development of more accessible, context-aware, and expert-level audio tuning methods.", "AI": {"tldr": "本文介绍了一种基于大规模语言模型的音频均衡器，可以通过自然语言提示生成适合人群偏好的音频设置。", "motivation": "传统的音频均衡化过程是静态和手动调整的，需要根据变化的聆听环境进行复杂的调整。本研究旨在通过一种更灵活、自动化的解决方案来解决这个问题。", "method": "使用大规模语言模型将自然语言文本提示映射到音频均衡器设置上，并利用来自受控听音实验的数据进行在上下文学习和参数有效的微调。", "result": "评估方法显示，与随机采样和静态预设基线相比，该模型在分布对齐方面有统计学上的显著改进。", "conclusion": "研究结果表明，大规模语言模型可以作为“人工均衡器”，有助于开发更便捷、情境感知以及专家级的音频调节方法。"}}
{"id": "2601.09446", "pdf": "https://arxiv.org/pdf/2601.09446", "abs": "https://arxiv.org/abs/2601.09446", "authors": ["Ramya Keerthy Thatikonda", "Jiuzhou Han", "Wray Buntine", "Ehsan Shareghi"], "title": "Improving Symbolic Translation of Language Models for Logical Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "The Third workshop of NeusymBridge @AAAI 2026 (Bridging Neurons and Symbols for NLP and Knowledge Graph Reasoning)", "summary": "The use of formal language for deductive logical reasoning aligns well with language models (LMs), where translating natural language (NL) into first-order logic (FOL) and employing an external solver results in a verifiable and therefore reliable reasoning system. However, smaller LMs often struggle with this translation task, frequently producing incorrect symbolic outputs due to formatting and translation errors. Existing approaches typically rely on self-iteration to correct these errors, but such methods depend heavily on the capabilities of the underlying model. To address this, we first categorize common errors and fine-tune smaller LMs using data synthesized by large language models. The evaluation is performed using the defined error categories. We introduce incremental inference, which divides inference into two stages, predicate generation and FOL translation, providing greater control over model behavior and enhancing generation quality as measured by predicate metrics. This decomposition framework also enables the use of a verification module that targets predicate-arity errors to further improve performance. Our study evaluates three families of models across four logical-reasoning datasets. The comprehensive fine-tuning, incremental inference, and verification modules reduce error rates, increase predicate coverage, and improve reasoning performance for smaller LMs, moving us closer to developing reliable and accessible symbolic-reasoning systems.", "AI": {"tldr": "本文旨在改进语言模型将自然语言翻译为一阶逻辑的能力，以提高其在演绎推理中的可靠性。", "motivation": "小型语言模型在将自然语言转换成符号逻辑时经常出现格式和翻译错误。现有方法依赖自我迭代来纠正这些错误，但这种方法的效果受限于底层模型的能力。", "method": "本文首先对常见错误进行分类，并使用大型语言模型合成的数据微调小型语言模型。引入增量推理框架，将其分为谓词生成和一阶逻辑翻译两个阶段，并加入验证模块以减少谓词元数错误。", "result": "实验评估了三种类型的模型在四个逻辑推理数据集上的性能。通过全面的微调、增量推理和验证模块减少了误差率，提高了谓词覆盖率，并改善了小型语言模型的推理性能。", "conclusion": "本文的方法有助于开发可靠且易于获取的符号推理系统，为提高语言模型进行演绎推理的能力提供了有效途径。"}}
{"id": "2601.09445", "pdf": "https://arxiv.org/pdf/2601.09445", "abs": "https://arxiv.org/abs/2601.09445", "authors": ["Minh Vu Pham", "Hsuvas Borkakoty", "Yufang Hou"], "title": "Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In language models (LMs), intra-memory knowledge conflict largely arises when inconsistent information about the same event is encoded within the model's parametric knowledge. While prior work has primarily focused on resolving conflicts between a model's internal knowledge and external resources through approaches such as fine-tuning or knowledge editing, the problem of localizing conflicts that originate during pre-training within the model's internal representations remain unexplored. In this work, we design a framework based on mechanistic interpretability methods to identify where and how conflicting knowledge from the pre-training data is encoded within LMs. Our findings contribute to a growing body of evidence that specific internal components of a language model are responsible for encoding conflicting knowledge from pre-training, and we demonstrate how mechanistic interpretability methods can be leveraged to causally intervene in and control conflicting knowledge at inference time.", "AI": {"tldr": "本文设计了一个基于机制可解释性的框架，用于识别语言模型中预训练数据产生的冲突知识的位置和方式。", "motivation": "尽管先前的研究主要集中在解决模型内部知识与外部资源之间的冲突上，但关于在预训练过程中于模型内部表示中产生的局部冲突问题尚未探索。", "method": "设计了一个基于机制可解释性的框架来识别语言模型内预训练数据中的冲突知识的位置和方式。", "result": "研究发现特定的模型内部组件负责编码来自预训练的冲突知识，并展示了如何在推理时通过因果干预控制这些冲突知识。", "conclusion": "本研究表明，利用机制可解释性方法可以定位并解决语言模型中由于预训练数据而产生的冲突知识问题。"}}
{"id": "2601.09444", "pdf": "https://arxiv.org/pdf/2601.09444", "abs": "https://arxiv.org/abs/2601.09444", "authors": ["Lauri Suomela", "Naoki Takahata", "Sasanka Kuruppu Arachchige", "Harry Edelman", "Joni-Kristian Kämäräinen"], "title": "Data Scaling for Navigation in Unknown Environments", "categories": ["cs.RO"], "comment": null, "summary": "Generalization of imitation-learned navigation policies to environments unseen in training remains a major challenge. We address this by conducting the first large-scale study of how data quantity and data diversity affect real-world generalization in end-to-end, map-free visual navigation. Using a curated 4,565-hour crowd-sourced dataset collected across 161 locations in 35 countries, we train policies for point goal navigation and evaluate their closed-loop control performance on sidewalk robots operating in four countries, covering 125 km of autonomous driving. Our results show that large-scale training data enables zero-shot navigation in unknown environments, approaching the performance of policies trained with environment-specific demonstrations. Critically, we find that data diversity is far more important than data quantity. Doubling the number of geographical locations in a training set decreases navigation errors by ~15%, while performance benefit from adding data from existing locations saturates with very little data. We also observe that, with noisy crowd-sourced data, simple regression-based models outperform generative and sequence-based architectures. We release our policies, evaluation setup and example videos on the project page.", "AI": {"tldr": "该论文主要研究了数据规模和多样性对未训练环境中的导航策略泛化性能的影响。", "motivation": "在未知环境中，模仿学习的导航策略难以实现泛化，因此该研究旨在通过大规模数据分析解决这一问题。", "method": "使用了来自161个地点35个国家的4,565小时众包数据集训练点目标导航政策，并评估其在四个国家中的自动驾驶性能。", "result": "结果表明大规模训练数据可以实现未知环境下的零样本导航，且数据多样性比数量更重要。地理位置多样性的增加显著降低导航错误。", "conclusion": "研究结论强调了数据多样性的重要性，并指出在有噪声的众包数据中，简单的回归模型优于生成式和序列架构模型。"}}
{"id": "2601.09433", "pdf": "https://arxiv.org/pdf/2601.09433", "abs": "https://arxiv.org/abs/2601.09433", "authors": ["David Reid", "Ognjen Arandjelovic"], "title": "Do Transformers Understand Ancient Roman Coin Motifs Better than CNNs?", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Automated analysis of ancient coins has the potential to help researchers extract more historical insights from large collections of coins and to help collectors understand what they are buying or selling. Recent research in this area has shown promise in focusing on identification of semantic elements as they are commonly depicted on ancient coins, by using convolutional neural networks (CNNs). This paper is the first to apply the recently proposed Vision Transformer (ViT) deep learning architecture to the task of identification of semantic elements on coins, using fully automatic learning from multi-modal data (images and unstructured text). This article summarises previous research in the area, discusses the training and implementation of ViT and CNN models for ancient coins analysis and provides an evaluation of their performance. The ViT models were found to outperform the newly trained CNN models in accuracy.", "AI": {"tldr": "使用Vision Transformer（ViT）和卷积神经网络（CNN）自动分析古代硬币上的语义元素。", "motivation": "通过自动化分析帮助研究人员从大量古钱币中提取更多历史信息，同时帮助收藏者了解他们所购买或出售的商品。", "method": "训练并实施Vision Transformer（ViT）和卷积神经网络（CNN）模型来自动识别古代硬币上的语义元素。", "result": "实验结果显示，Vision Transformer（ViT）在准确率上优于新训练的卷积神经网络（CNN）模型。", "conclusion": "首次将Vision Transformer应用于古钱币分析中，并证明其性能优于传统的卷积神经网络。"}}
{"id": "2601.09430", "pdf": "https://arxiv.org/pdf/2601.09430", "abs": "https://arxiv.org/abs/2601.09430", "authors": ["Rui Zhu", "Xin Shen", "Shuchen Wu", "Chenxi Miao", "Xin Yu", "Yang Li", "Weikang Li", "Deguo Xia", "Jizhou Huang"], "title": "Video-MSR: Benchmarking Multi-hop Spatial Reasoning Capabilities of MLLMs", "categories": ["cs.CV"], "comment": null, "summary": "Spatial reasoning has emerged as a critical capability for Multimodal Large Language Models (MLLMs), drawing increasing attention and rapid advancement. However, existing benchmarks primarily focus on single-step perception-to-judgment tasks, leaving scenarios requiring complex visual-spatial logical chains significantly underexplored. To bridge this gap, we introduce Video-MSR, the first benchmark specifically designed to evaluate Multi-hop Spatial Reasoning (MSR) in dynamic video scenarios. Video-MSR systematically probes MSR capabilities through four distinct tasks: Constrained Localization, Chain-based Reference Retrieval, Route Planning, and Counterfactual Physical Deduction. Our benchmark comprises 3,052 high-quality video instances with 4,993 question-answer pairs, constructed via a scalable, visually-grounded pipeline combining advanced model generation with rigorous human verification. Through a comprehensive evaluation of 20 state-of-the-art MLLMs, we uncover significant limitations, revealing that while models demonstrate proficiency in surface-level perception, they exhibit distinct performance drops in MSR tasks, frequently suffering from spatial disorientation and hallucination during multi-step deductions. To mitigate these shortcomings and empower models with stronger MSR capabilities, we further curate MSR-9K, a specialized instruction-tuning dataset, and fine-tune Qwen-VL, achieving a +7.82% absolute improvement on Video-MSR. Our results underscore the efficacy of multi-hop spatial instruction data and establish Video-MSR as a vital foundation for future research. The code and data will be available at https://github.com/ruiz-nju/Video-MSR.", "AI": {"tldr": "介绍Video-MSR，一个用于评估动态视频场景中多跳空间推理能力的基准测试。", "motivation": "现有基准主要集中在单步感知到判断的任务上，忽略了复杂的视觉空间逻辑链情景。为了填补这一空白，提出了专门评估动态视频中多跳空间推理能力的基准Video-MSR。", "method": "通过四个不同的任务（受限制定位、基于链式引用检索、路线规划和反事实物理推断）系统地探索多跳空间推理能力，并创建了一个包含3,052个高质量视频实例和4,993对问答的基准数据集。此外，还整理了MSR-9K专门指令微调数据集，并对其进行了微调。", "result": "通过评估20种最先进的多模态大型语言模型，发现它们在表面级感知方面表现出色，但在多跳空间推理任务中表现较差，常出现空间迷失和幻觉。利用MSR-9K对Qwen-VL进行微调后，在Video-MSR上的绝对提升为+7.82%。", "conclusion": "结果证明了多跳空间指令数据的有效性，并确立了Video-MSR作为未来研究重要基础的地位。"}}
{"id": "2601.09421", "pdf": "https://arxiv.org/pdf/2601.09421", "abs": "https://arxiv.org/abs/2601.09421", "authors": ["Filip Trhlik", "Andrew Caines", "Paula Buttery"], "title": "Bias Dynamics in BabyLMs: Towards a Compute-Efficient Sandbox for Democratising Pre-Training Debiasing", "categories": ["cs.CL", "cs.AI"], "comment": "21 pages, 18 figures", "summary": "Pre-trained language models (LMs) have, over the last few years, grown substantially in both societal adoption and training costs. This rapid growth in size has constrained progress in understanding and mitigating their biases. Since re-training LMs is prohibitively expensive, most debiasing work has focused on post-hoc or masking-based strategies, which often fail to address the underlying causes of bias. In this work, we seek to democratise pre-model debiasing research by using low-cost proxy models. Specifically, we investigate BabyLMs, compact BERT-like models trained on small and mutable corpora that can approximate bias acquisition and learning dynamics of larger models. We show that BabyLMs display closely aligned patterns of intrinsic bias formation and performance development compared to standard BERT models, despite their drastically reduced size. Furthermore, correlations between BabyLMs and BERT hold across multiple intra-model and post-model debiasing methods. Leveraging these similarities, we conduct pre-model debiasing experiments with BabyLMs, replicating prior findings and presenting new insights regarding the influence of gender imbalance and toxicity on bias formation. Our results demonstrate that BabyLMs can serve as an effective sandbox for large-scale LMs, reducing pre-training costs from over 500 GPU-hours to under 30 GPU-hours. This provides a way to democratise pre-model debiasing research and enables faster, more accessible exploration of methods for building fairer LMs.", "AI": {"tldr": "使用小型且成本低廉的BabyLMs来研究和减轻预训练语言模型中的偏见问题。", "motivation": "由于重新训练大型语言模型的成本高昂，大多数去偏见工作集中在后期处理策略上。这些方法往往无法解决偏见的根本原因。为了使去偏见的研究更加民主化，本论文提出了使用低成本的BabyLMs来模拟并研究大规模模型中的偏见形成。", "method": "通过在小型且成本低廉的BabyLMs上进行预训练去偏见实验，并将其结果与标准BERT模型对比分析，以验证BabyLMs作为研究和减轻大型语言模型中偏见的有效性。同时，探索性别不平衡和毒性对偏见形成的影响力。", "result": "结果显示，尽管BabyLMs规模较小，但它们在内在偏见形成模式和性能发展方面与标准的BERT模型非常相似，并且相关性贯穿多种去偏见方法。使用BabyLMs可以将预训练成本从超过500个GPU小时减少到30个小时以下。", "conclusion": "BabyLMs能作为研究大规模语言模型中偏见形成的有效工具，大幅降低预训练的成本，使研究更加民主化，并且能够快速、便捷地探索建立更公平的语言模型的方法。"}}
{"id": "2601.09416", "pdf": "https://arxiv.org/pdf/2601.09416", "abs": "https://arxiv.org/abs/2601.09416", "authors": ["Yaxi Chen", "Zi Ye", "Shaheer U. Saeed", "Oliver Yu", "Simin Ni", "Jie Huang", "Yipeng Hu"], "title": "Radiomics-Integrated Deep Learning with Hierarchical Loss for Osteosarcoma Histology Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Osteosarcoma (OS) is an aggressive primary bone malignancy. Accurate histopathological assessment of viable versus non-viable tumor regions after neoadjuvant chemotherapy is critical for prognosis and treatment planning, yet manual evaluation remains labor-intensive, subjective, and prone to inter-observer variability. Recent advances in digital pathology have enabled automated necrosis quantification. Evaluating on test data, independently sampled on patient-level, revealed that the deep learning model performance dropped significantly from the tile-level generalization ability reported in previous studies. First, this work proposes the use of radiomic features as additional input in model training. We show that, despite that they are derived from the images, such a multimodal input effectively improved the classification performance, in addition to its added benefits in interpretability. Second, this work proposes to optimize two binary classification tasks with hierarchical classes (i.e. tumor-vs-non-tumor and viable-vs-non-viable), as opposed to the alternative ``flat'' three-class classification task (i.e. non-tumor, non-viable tumor, viable tumor), thereby enabling a hierarchical loss. We show that such a hierarchical loss, with trainable weightings between the two tasks, the per-class performance can be improved significantly. Using the TCIA OS Tumor Assessment dataset, we experimentally demonstrate the benefits from each of the proposed new approaches and their combination, setting a what we consider new state-of-the-art performance on this open dataset for this application. Code and trained models: https://github.com/YaxiiC/RadiomicsOS.git.", "AI": {"tldr": "本文提出了结合放射组学特征和层次化损失函数的深度学习模型，用于骨肉瘤组织分类。", "motivation": "传统手动评估骨肉瘤活检区域存在劳动密集、主观性强以及观察者间变异大等问题，该研究旨在提高自动化识别精度并减少这些问题。", "method": "采用放射组学特征作为额外输入，并优化两个层次化的二元分类任务（即肿瘤与非肿瘤和存活与非存活），以实现更好的性能。", "result": "实验显示，在TCIA骨肉瘤评估数据集上，该方法提高了分类性能并达到了新的最佳状态。", "conclusion": "研究证明了放射组学特征以及层次化损失函数在提高骨肉瘤组织分类准确性方面的有效性。"}}
{"id": "2601.09413", "pdf": "https://arxiv.org/pdf/2601.09413", "abs": "https://arxiv.org/abs/2601.09413", "authors": ["Zhen Wan", "Chao-Han Huck Yang", "Jinchuan Tian", "Hanrong Ye", "Ankita Pasad", "Szu-wei Fu", "Arushi Goel", "Ryo Hachiuma", "Shizhe Diao", "Kunal Dhawan", "Sreyan Ghosh", "Yusuke Hirota", "Zhehuai Chen", "Rafael Valle", "Ehsan Hosseini Asl", "Chenhui Chu", "Shinji Watanabe", "Yu-Chiang Frank Wang", "Boris Ginsburg"], "title": "Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MA", "eess.AS"], "comment": "Preprint. The version was submitted in October 2025", "summary": "We introduce a voice-agentic framework that learns one critical omni-understanding skill: knowing when to trust itself versus when to consult external audio perception. Our work is motivated by a crucial yet counterintuitive finding: naively fine-tuning an omni-model on both speech recognition and external sound understanding tasks often degrades performance, as the model can be easily misled by noisy hypotheses. To address this, our framework, Speech-Hands, recasts the problem as an explicit self-reflection decision. This learnable reflection primitive proves effective in preventing the model from being derailed by flawed external candidates. We show that this agentic action mechanism generalizes naturally from speech recognition to complex, multiple-choice audio reasoning. Across the OpenASR leaderboard, Speech-Hands consistently outperforms strong baselines by 12.1% WER on seven benchmarks. The model also achieves 77.37% accuracy and high F1 on audio QA decisions, showing robust generalization and reliability across diverse audio question answering datasets. By unifying perception and decision-making, our work offers a practical path toward more reliable and resilient audio intelligence.", "AI": {"tldr": "本文介绍了一个自我反思的语音代理框架Speech-Hands，用于提高语音识别和外部音频理解任务中的性能。", "motivation": "研究动机源于发现简单地将模型微调以处理语音识别和外部声音理解任务会因噪声假设而降低性能。", "method": "Speech-Hands通过引入一个可学习的自我反思机制来决定何时信任自身，何时寻求外部音频感知帮助。", "result": "在OpenASR排行榜上，该方法比强基线模型提升了12.1%的WER，并且在音频问答决策中达到了77.37%的准确率和高F1值。", "conclusion": "通过统一感知与决策过程，Speech-Hands提供了一种实用路径以实现更可靠和健壮的音频智能。"}}
{"id": "2601.09410", "pdf": "https://arxiv.org/pdf/2601.09410", "abs": "https://arxiv.org/abs/2601.09410", "authors": ["Sangjun Han", "Youngmi Hur"], "title": "Detail Loss in Super-Resolution Models Based on the Laplacian Pyramid and Repeated Upscaling and Downscaling Process", "categories": ["cs.CV"], "comment": "Accepted for publication in IET Image Processing. This is the authors' final accepted manuscript", "summary": "With advances in artificial intelligence, image processing has gained significant interest. Image super-resolution is a vital technology closely related to real-world applications, as it enhances the quality of existing images. Since enhancing fine details is crucial for the super-resolution task, pixels that contribute to high-frequency information should be emphasized. This paper proposes two methods to enhance high-frequency details in super-resolution images: a Laplacian pyramid-based detail loss and a repeated upscaling and downscaling process. Total loss with our detail loss guides a model by separately generating and controlling super-resolution and detail images. This approach allows the model to focus more effectively on high-frequency components, resulting in improved super-resolution images. Additionally, repeated upscaling and downscaling amplify the effectiveness of the detail loss by extracting diverse information from multiple low-resolution features. We conduct two types of experiments. First, we design a CNN-based model incorporating our methods. This model achieves state-of-the-art results, surpassing all currently available CNN-based and even some attention-based models. Second, we apply our methods to existing attention-based models on a small scale. In all our experiments, attention-based models adding our detail loss show improvements compared to the originals. These results demonstrate our approaches effectively enhance super-resolution images across different model structures.", "AI": {"tldr": "本文提出了两种增强超分辨率图像高频细节的方法：基于拉普拉斯金字塔的细节损失和重复上采样与下采样的过程。", "motivation": "随着人工智能的进步，提高图像处理技术变得尤为重要。特别是在提升图像质量方面，高频率信息的保留对于改善超分辨率任务至关重要。", "method": "通过设计包含细节损失的总损失函数来指导模型生成并控制超分辨率和细节图像；利用重复上采样与下采样的过程放大细节损失的效果，以从多尺度低分辨率特征中提取多样化信息。", "result": "实验表明，基于CNN的方法取得了领先于现有CNN甚至某些注意力机制模型的结果，并且在较小规模的注意力机制模型应用中也显示出了改进。", "conclusion": "本文提出的方法有效地增强了不同结构模型下的超分辨率图像质量。"}}
{"id": "2601.09404", "pdf": "https://arxiv.org/pdf/2601.09404", "abs": "https://arxiv.org/abs/2601.09404", "authors": ["Jun-Peng Zhu", "Boyan Niu", "Peng Cai", "Zheming Ni", "Kai Xu", "Jiajun Huang", "Shengbo Ma", "Bing Wang", "Xuan Zhou", "Guanglei Bao", "Donghui Zhang", "Liu Tang", "Qi Liu"], "title": "TiInsight: A SQL-based Automated Exploratory Data Analysis System through Large Language Models", "categories": ["cs.DB", "cs.HC"], "comment": "4 pages, 5 figures", "summary": "The SQL-based exploratory data analysis has garnered significant attention within the data analysis community. The emergence of large language models (LLMs) has facilitated the paradigm shift from manual to automated data exploration. However, existing methods generally lack the ability for cross-domain analysis, and the exploration of LLMs capabilities remains insufficient. This paper presents TiInsight, an SQL-based automated cross-domain exploratory data analysis system. First, TiInsight offers a user-friendly GUI enabling users to explore data using natural language queries. Second, TiInsight offers a robust cross-domain exploratory data analysis pipeline: hierarchical data context (i.e., HDC) generation, question clarification and decomposition, text-to-SQL (i.e., TiSQL), and data visualization (i.e., TiChart). Third, we have implemented and deployed TiInsight in the production environment of PingCAP and demonstrated its capabilities using representative datasets. The demo video is available at https://youtu.be/JzYFyYd-emI.", "AI": {"tldr": "本文介绍了TiInsight，一个基于SQL的自动化跨领域探索性数据分析系统。", "motivation": "现有的方法缺乏跨领域的分析能力，并且大型语言模型在探索性数据分析中的潜力尚未得到充分利用。", "method": "TiInsight提供了一个用户友好的GUI界面，通过自然语言查询进行数据探索。其包括生成分层数据上下文、问题澄清和分解、文本转SQL以及数据可视化等环节。", "result": "作者已经在PingCAP的生产环境中实现了并部署了TiInsight，并使用代表性的数据集展示了其功能。", "conclusion": "TiInsight成功地通过大型语言模型支持基于SQL的自动化跨领域探索性数据分析，提高了数据分析效率。"}}
{"id": "2601.09398", "pdf": "https://arxiv.org/pdf/2601.09398", "abs": "https://arxiv.org/abs/2601.09398", "authors": ["Songyao Jin", "Kun Zhou", "Wenqi Li", "Peng Wang", "Biwei Huang"], "title": "Ability Transfer and Recovery via Modularized Parameters Localization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models can be continually pre-trained or fine-tuned to improve performance in specific domains, languages, or skills, but this specialization often degrades other capabilities and may cause catastrophic forgetting. We investigate how abilities are distributed within LLM parameters by analyzing module activations under domain- and language-specific inputs for closely related models. Across layers and modules, we find that ability-related activations are highly concentrated in a small set of channels (typically <5\\%), and these channels are largely disentangled with good sufficiency and stability. Building on these observations, we propose ACT (Activation-Guided Channel-wise Ability Transfer), which localizes ability-relevant channels via activation differences and selectively transfers only the corresponding parameters, followed by lightweight fine-tuning for compatibility. Experiments on multilingual mathematical and scientific reasoning show that ACT can recover forgotten abilities while preserving retained skills. It can also merge multiple specialized models to integrate several abilities into a single model with minimal interference. Our code and data will be publicly released.", "AI": {"tldr": "该论文提出了ACT（激活引导的通道式能力迁移）方法，用于定位和转移大型语言模型中的特定技能相关参数，以实现能力和恢复，并减少遗忘问题。", "motivation": "解决大语言模型在专门训练过程中导致其他能力退化或灾难性遗忘的问题。通过分析模块化参数来理解不同领域和语言输入下的模型行为。", "method": "ACT方法通过激活差异定位与能力相关的通道，仅转移这些参数，并进行轻量级微调以增强兼容性。", "result": "实验结果显示，该方法可以在保持已有技能的同时恢复遗忘的能力，还可以整合多个专门化的模型，将多种能力集成到单个模型中，且相互干扰最小。", "conclusion": "ACT能够有效地实现大型语言模型中的能力和技能的转移与恢复，同时减少不同任务之间的干扰，并计划公开代码和数据。"}}
{"id": "2601.09394", "pdf": "https://arxiv.org/pdf/2601.09394", "abs": "https://arxiv.org/abs/2601.09394", "authors": ["Renqiang Luo", "Huafei Huang", "Tao Tang", "Jing Ren", "Ziqi Xu", "Mingliang Hou", "Enyan Dai", "Feng Xia"], "title": "FairGE: Fairness-Aware Graph Encoding in Incomplete Social Networks", "categories": ["cs.SI", "cs.AI"], "comment": "12 pages, WWW 2026", "summary": "Graph Transformers (GTs) are increasingly applied to social network analysis, yet their deployment is often constrained by fairness concerns. This issue is particularly critical in incomplete social networks, where sensitive attributes are frequently missing due to privacy and ethical restrictions. Existing solutions commonly generate these incomplete attributes, which may introduce additional biases and further compromise user privacy. To address this challenge, FairGE (Fair Graph Encoding) is introduced as a fairness-aware framework for GTs in incomplete social networks. Instead of generating sensitive attributes, FairGE encodes fairness directly through spectral graph theory. By leveraging the principal eigenvector to represent structural information and padding incomplete sensitive attributes with zeros to maintain independence, FairGE ensures fairness without data reconstruction. Theoretical analysis demonstrates that the method suppresses the influence of non-principal spectral components, thereby enhancing fairness. Extensive experiments on seven real-world social network datasets confirm that FairGE achieves at least a 16% improvement in both statistical parity and equality of opportunity compared with state-of-the-art baselines. The source code is shown in https://github.com/LuoRenqiang/FairGE.", "AI": {"tldr": "FairGE是一种用于不完整社交网络中图编码的公平性框架，通过光谱图理论直接编码公平性，而不是生成缺失的敏感属性。", "motivation": "现有的解决方案通常会生成不完整的敏感属性，这可能会引入额外的偏差并进一步损害用户隐私。因此，提出一种在不重建数据的情况下确保公平性的方法是必要的。", "method": "FairGE使用主特征向量来表示结构信息，并用零填充缺失的敏感属性以保持独立性。通过抑制非主要光谱成分的影响来增强公平性。", "result": "实验结果表明，与最先进的基线相比，FairGE在统计平等性和机会平等性上至少有16%的改进。", "conclusion": "FairGE框架证明了其在不完整社交网络中实现公平性的有效性，并且不需要重建缺失的数据。"}}
{"id": "2601.09385", "pdf": "https://arxiv.org/pdf/2601.09385", "abs": "https://arxiv.org/abs/2601.09385", "authors": ["Ziyang Ma", "Guanrou Yang", "Wenxi Chen", "Zhifu Gao", "Yexing Du", "Xiquan Li", "Zhisheng Zheng", "Haina Zhu", "Jianheng Zhuo", "Zheshu Song", "Ruiyang Xu", "Tiranrui Wang", "Yifan Yang", "Yanqiao Zhu", "Zhikang Niu", "Liumeng Xue", "Yinghao Ma", "Ruibin Yuan", "Shiliang Zhang", "Kai Yu", "Eng Siong Chng", "Xie Chen"], "title": "SLAM-LLM: A Modular, Open-Source Multimodal Large Language Model Framework and Best Practice for Speech, Language, Audio and Music Processing", "categories": ["cs.SD", "cs.CL", "cs.MM"], "comment": "Published in IEEE Journal of Selected Topics in Signal Processing (JSTSP)", "summary": "The recent surge in open-source Multimodal Large Language Models (MLLM) frameworks, such as LLaVA, provides a convenient kickoff for artificial intelligence developers and researchers. However, most of the MLLM frameworks take vision as the main input modality, and provide limited in-depth support for the modality of speech, audio, and music. This situation hinders the development of audio-language models, and forces researchers to spend a lot of effort on code writing and hyperparameter tuning. We present SLAM-LLM, an open-source deep learning framework designed to train customized MLLMs, focused on speech, language, audio, and music processing. SLAM-LLM provides a modular configuration of different encoders, projectors, LLMs, and parameter-efficient fine-tuning plugins. SLAM-LLM also includes detailed training and inference recipes for mainstream tasks, along with high-performance checkpoints like LLM-based Automatic Speech Recognition (ASR), Automated Audio Captioning (AAC), and Music Captioning (MC). Some of these recipes have already reached or are nearing state-of-the-art performance, and some relevant techniques have also been accepted by academic papers. We hope SLAM-LLM will accelerate iteration, development, data engineering, and model training for researchers. We are committed to continually pushing forward audio-based MLLMs through this open-source framework, and call on the community to contribute to the LLM-based speech, audio and music processing.", "AI": {"tldr": "介绍了SLAM-LLM，一个开源的多模态大型语言模型框架，专注于语音、语言、音频和音乐处理。", "motivation": "当前大多数多模态大语言模型框架主要以视觉作为输入模态，对语音、音频和音乐的支持有限，这阻碍了音频-语言模型的发展，并迫使研究人员投入大量精力进行代码编写和超参数调整。", "method": "SLAM-LLM提供了一个模块化的配置，包括不同的编码器、投影器、大型语言模型（LLM）以及参数高效的微调插件。该框架还提供了主流任务的详细训练和推理配方，如基于LLM的自动语音识别（ASR）、自动化音频注释（AAC）和音乐标注（MC）。", "result": "一些SLAM-LLM中的配方已经达到了或接近当前最优性能，并且相关技术已被学术论文接受。", "conclusion": "希望SLAM-LLM能够加速研究人员在迭代、开发、数据工程和模型训练方面的进展，通过这个开源框架不断推进基于音频的多模态大语言模型的发展，并呼吁社区贡献于基于LLM的语音、音频和音乐处理。"}}
{"id": "2601.09382", "pdf": "https://arxiv.org/pdf/2601.09382", "abs": "https://arxiv.org/abs/2601.09382", "authors": ["Qinglong Shi", "Donghai Wang", "Hantao Zhou", "Jiguo Li", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He"], "title": "Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments", "categories": ["cs.AI", "cs.CL"], "comment": "8 pages, 2 figures", "summary": "Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity through two key capabilities, (i) Intent-Conditioned Monitoring: The agent autonomously formulates trigger conditions based on dialog history; (ii) Event-Triggered Follow-up: The agent actively engages the user upon detecting useful environmental updates. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria of task-oriented interaction in a dynamic environment by proposing a new benchmark, namely ChronosBench. We evaluated some leading close-source and open-source models at present and revealed their flaws in long-term task-oriented interaction. Furthermore, our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. And the result validated the effectiveness of our data-driven strategy.", "AI": {"tldr": "本文提出了一个主动型任务导向代理的新交互范式，能够维护长期用户意图并在动态环境中适应。", "motivation": "现有的大型语言模型主要采用反应式范式操作，这限制了它们维持用户的长期意图和在动态环境中的适应性能力。", "method": "通过引入意图条件监控与事件触发跟进两个关键功能，并使用合成数据管道构建复杂的多轮对话数据，同时提出ChronosBench新基准评估任务导向交互。", "result": "该方法下训练的模型实现了85.19%的任务完成率，在长期内具有更高的任务导向交互表现。", "conclusion": "实验证明了所提出的主动型代理及数据驱动策略的有效性，填补了长期任务导向对话系统在动态环境中评估标准的空白。"}}
{"id": "2601.09381", "pdf": "https://arxiv.org/pdf/2601.09381", "abs": "https://arxiv.org/abs/2601.09381", "authors": ["Martin Grohe"], "title": "Query Languages for Machine-Learning Models", "categories": ["cs.LO", "cs.AI", "cs.DB"], "comment": null, "summary": "In this paper, I discuss two logics for weighted finite structures: first-order logic with summation (FO(SUM)) and its recursive extension IFP(SUM). These logics originate from foundational work by Grädel, Gurevich, and Meer in the 1990s. In recent joint work with Standke, Steegmans, and Van den Bussche, we have investigated these logics as query languages for machine learning models, specifically neural networks, which are naturally represented as weighted graphs. I present illustrative examples of queries to neural networks that can be expressed in these logics and discuss fundamental results on their expressiveness and computational complexity.", "AI": {"tldr": "本文探讨了用于加权有限结构的两种逻辑：带有求和运算的一阶逻辑（FO(SUM)）及其递归扩展IFP(SUM)，并将其作为查询语言应用于机器学习模型，特别是神经网络。", "motivation": "动机在于探索如何使用这些逻辑来表达对神经网络的查询，并研究其在表示能力和计算复杂性方面的基本结果。", "method": "通过展示用FO(SUM)和IFP(SUM)表述对神经网络查询的例子来进行讨论，并结合最近与Standke、Steegmans及Van den Bussche合作的工作，探讨这些逻辑作为机器学习模型查询语言的应用。", "result": "展示了可以使用这些逻辑表达的关于神经网络的具体查询示例，并讨论了它们在表示能力和计算复杂性方面的基本结果。", "conclusion": "结论表明FO(SUM)和IFP(SUM)能够有效地用作机器学习模型，特别是神经网络的查询语言，具有一定的表示能力和计算挑战。"}}
{"id": "2601.09377", "pdf": "https://arxiv.org/pdf/2601.09377", "abs": "https://arxiv.org/abs/2601.09377", "authors": ["Xuemei Yao", "Xiao Yang", "Jianbin Sun", "Liuwei Xie", "Xuebin Shao", "Xiyu Fang", "Hang Su", "Kewei Yang"], "title": "ReflexDiffusion: Reflection-Enhanced Trajectory Planning for High-lateral-acceleration Scenarios in Autonomous Driving", "categories": ["cs.RO"], "comment": "Accepted by AAAI 2026", "summary": "Generating safe and reliable trajectories for autonomous vehicles in long-tail scenarios remains a significant challenge, particularly for high-lateral-acceleration maneuvers such as sharp turns, which represent critical safety situations. Existing trajectory planners exhibit systematic failures in these scenarios due to data imbalance. This results in insufficient modelling of vehicle dynamics, road geometry, and environmental constraints in high-risk situations, leading to suboptimal or unsafe trajectory prediction when vehicles operate near their physical limits. In this paper, we introduce ReflexDiffusion, a novel inference-stage framework that enhances diffusion-based trajectory planners through reflective adjustment. Our method introduces a gradient-based adjustment mechanism during the iterative denoising process: after each standard trajectory update, we compute the gradient between the conditional and unconditional noise predictions to explicitly amplify critical conditioning signals, including road curvature and lateral vehicle dynamics. This amplification enforces strict adherence to physical constraints, particularly improving stability during high-lateral-acceleration maneuvers where precise vehicle-road interaction is paramount. Evaluated on the nuPlan Test14-hard benchmark, ReflexDiffusion achieves a 14.1% improvement in driving score for high-lateral-acceleration scenarios over the state-of-the-art (SOTA) methods. This demonstrates that inference-time trajectory optimization can effectively compensate for training data sparsity by dynamically reinforcing safety-critical constraints near handling limits. The framework's architecture-agnostic design enables direct deployment to existing diffusion-based planners, offering a practical solution for improving autonomous vehicle safety in challenging driving conditions.", "AI": {"tldr": "本文介绍了ReflexDiffusion，一种用于提高自动驾驶车辆在高侧向加速度场景中的轨迹规划安全性的框架。", "motivation": "现有的轨迹规划方法在处理高侧向加速度的极端情况时表现不佳，因为这些情况下数据不平衡导致模型无法充分考虑车辆动态、道路几何和环境约束。", "method": "ReflexDiffusion通过反射调整机制增强扩散式轨迹规划器，在每次标准轨迹更新后计算条件噪声预测与无条件噪声预测之间的梯度以放大关键信号。", "result": "在nuPlan Test14-hard基准测试中，相比最先进的方法，ReflexDiffusion实现了驾驶评分提高了14.1%。", "conclusion": "研究表明，在推理时优化轨迹可以通过动态强化安全关键约束来弥补训练数据稀疏性，且该框架可以适应各种扩散式规划器的直接部署。"}}
{"id": "2601.09365", "pdf": "https://arxiv.org/pdf/2601.09365", "abs": "https://arxiv.org/abs/2601.09365", "authors": ["Biswesh Mohapatra", "Théo Charlot", "Giovanni Duca", "Mayank Palan", "Laurent Romary", "Justine Cassell"], "title": "Frame of Reference: Addressing the Challenges of Common Ground Representation in Situational Dialogs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Common ground plays a critical role in situated spoken dialogues, where interlocutors must establish and maintain shared references to entities, events, and relations to sustain coherent interaction. For dialog systems, the ability to correctly ground conversational content in order to refer back to it later is particularly important. Prior studies have demonstrated that LLMs are capable of performing grounding acts such as requesting clarification or producing acknowledgments, yet relatively little work has investigated how common ground can be explicitly represented and stored for later use. Without such mechanisms, it remains unclear whether acknowledgment or clarification behaviors truly reflect a grounded understanding. In this work, we evaluate a model's ability to establish and exploit common ground through relational references to entities within the shared context in a situational dialogue. We test multiple methods for representing common ground in situated dialogues and further propose approaches to improve both the establishment of common ground and its subsequent use in the conversation.", "AI": {"tldr": "本文研究了在情景对话中如何显式地表示和存储共同点，并测试了几种不同的方法来改进共同点的建立及其后续使用。", "motivation": "尽管研究表明大语言模型能够执行诸如请求澄清或产生确认等行为，但关于如何明确表示和存储共同理解以便日后使用的研究较少。本文旨在填补这一研究空白。", "method": "作者测试了多种情景对话中表达共同点的方法，并提出改进措施以增强其建立和后续使用的效率。", "result": "研究结果表明，不同的方法在促进情景对话中的共同点管理和利用方面具有不同效果。", "conclusion": "通过显式表示和存储共同理解，可以提高情景对话系统的表现，尤其是在实体关联参考和维持连贯交互的能力上。"}}
{"id": "2601.09361", "pdf": "https://arxiv.org/pdf/2601.09361", "abs": "https://arxiv.org/abs/2601.09361", "authors": ["Jiaying Zhang", "Lei Shi", "Jiguo Li", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He"], "title": "GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for advancing large-scale reasoning models. However, existing parameter-efficient methods, such as PiSSA and MiLoRA, are designed for Supervised Fine-Tuning (SFT) and do not account for the distinct optimization dynamics and geometric structures of RLVR. Applying these methods directly leads to spectral collapse and optimization instability, which severely limit model performance. Meanwhile, alternative approaches that leverage update sparsity encounter significant efficiency bottlenecks on modern hardware due to unstructured computations. To address these challenges, we propose GeoRA (Geometry-Aware Low-Rank Adaptation), which exploits the anisotropic and compressible nature of RL update subspaces. GeoRA initializes adapters by extracting principal directions via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing the residual components. This method preserves the pre-trained geometric structure and enables efficient GPU computation through dense operators. Experiments on Qwen and Llama demonstrate that GeoRA mitigates optimization bottlenecks caused by geometric misalignment. It consistently outperforms established low-rank baselines on key mathematical benchmarks, achieving state-of-the-art (SOTA) results. Moreover, GeoRA shows superior generalization and resilience to catastrophic forgetting in out-of-domain tasks.", "AI": {"tldr": "本文提出了GeoRA，一种面向强化学习中可验证奖励（RLVR）的几何感知低秩适应方法。", "motivation": "现有参数高效的方法如PiSSA和MiLoRA适用于监督微调但不考虑RLVR特有的优化动态和几何结构，导致性能受限。同时，利用更新稀疏性的替代方法在现代硬件上面临效率瓶颈。", "method": "GeoRA通过在几何约束子空间内使用奇异值分解（SVD）提取主方向来初始化适配器，并冻结残余部分，以保持预训练的几何结构并实现高效的GPU计算。", "result": "实验显示GeoRA解决了由几何不对齐引起的优化瓶颈，在数学基准测试中超越了现有的低秩基线方法，达到最先进的结果，并且在域外任务上表现出良好的泛化和抵抗灾难性遗忘的能力。", "conclusion": "GeoRA通过其特有的初始化和优化策略，在保持计算效率的同时显著改善了RLVR模型的性能。"}}
{"id": "2601.09354", "pdf": "https://arxiv.org/pdf/2601.09354", "abs": "https://arxiv.org/abs/2601.09354", "authors": ["Jonathan Carrero", "Ismael Rodriguez", "Fernando Rubio"], "title": "Measuring the benefits of lying in MARA under egalitarian social welfare", "categories": ["cs.GT", "cs.NE"], "comment": "This paper was published in 2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC). The present version is the author's accepted manuscript", "summary": "When some resources are to be distributed among a set of agents following egalitarian social welfare, the goal is to maximize the utility of the agent whose utility turns out to be minimal. In this context, agents can have an incentive to lie about their actual preferences, so that more valuable resources are assigned to them. In this paper we analyze this situation, and we present a practical study where genetic algorithms are used to assess the benefits of lying under different situations.", "AI": {"tldr": "本文研究了在遵循平等主义社会福利原则分配资源时，代理人撒谎报告其偏好以获得更多有价值的资源的行为及其好处。", "motivation": "动机在于探讨当资源根据平等主义社会福利的原则进行分配时，如何通过分析代理人的欺骗行为来评估这种策略的实际效益。", "method": "本文使用遗传算法来模拟和评估在不同情况下代理人撒谎报告其偏好所能获得的好处。", "result": "研究结果揭示了在不同的情况下，代理人撒谎能带来的实际收益，并提供了这些策略的有效性评估。", "conclusion": "结论是，在遵循平等主义社会福利原则分配资源的情况下，撒谎关于个人偏好的行为确实可以为某些代理人带来更多的收益。"}}
{"id": "2601.09353", "pdf": "https://arxiv.org/pdf/2601.09353", "abs": "https://arxiv.org/abs/2601.09353", "authors": ["Ioannis Peridis", "Dimitrios Troullinos", "Georgios Chalkiadakis", "Pantelis Giankoulidis", "Ioannis Papamichail", "Markos Papageorgiou"], "title": "Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving", "categories": ["cs.AI"], "comment": null, "summary": "Lane-free traffic environments allow vehicles to better harness the lateral capacity of the road without being restricted to lane-keeping, thereby increasing the traffic flow rates. As such, we have a distinct and more challenging setting for autonomous driving. In this work, we consider a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic, where the associated Markov Decision Process we formulate is influenced from existing approaches tied to reinforcement learning frameworks. In addition, MCTS is equipped with a pre-trained neural network (NN) that guides the selection phase. This procedure incorporates the predictive capabilities of NNs for a more informed tree search process under computational constraints. In our experimental evaluation, we consider metrics that address both safety (through collision rates) and efficacy (through measured speed). Then, we examine: (a) the influence of isotropic state information for vehicles in a lane-free environment, resulting in nudging behaviour--vehicles' policy reacts due to the presence of faster tailing ones, (b) the acceleration of performance for the NN-guided variant of MCTS, and (c) the trade-off between computational resources and solution quality.", "AI": {"tldr": "本研究使用带有神经网络指导的蒙特卡洛树搜索算法来解决自由车道自动驾驶问题，以提高交通流量。", "motivation": "为了更好地利用道路横向容量并增加交通流速，在无车道限制条件下进行自主驾驶是一个独特的且更具挑战性的任务。", "method": "采用蒙特卡洛树搜索（MCTS）规划方法和预训练神经网络指导的单代理自动驾驶系统，解决了自由车道环境下的自主驾驶问题，并结合强化学习框架中的马尔可夫决策过程模型。", "result": "实验评估了安全性和效能指标，分析了各向同性状态信息对车辆行为的影响、带有神经网络引导的MCTS性能提升以及计算资源与解决方案质量之间的权衡。", "conclusion": "研究表明，使用神经网络指导的蒙特卡洛树搜索方法能够在自由车道环境中有效提高自动驾驶的安全性和效能，并在有限的计算资源下实现较好的解决方案。"}}
{"id": "2601.09352", "pdf": "https://arxiv.org/pdf/2601.09352", "abs": "https://arxiv.org/abs/2601.09352", "authors": ["Wei Liu", "Xing Deng", "Haijian Shao", "Yingtao Jiang"], "title": "Spectral Complex Autoencoder Pruning: A Fidelity-Guided Criterion for Extreme Structured Channel Compression", "categories": ["cs.CV"], "comment": "17 pages, 9 figures", "summary": "We propose Spectral Complex Autoencoder Pruning (SCAP), a reconstruction-based criterion that measures functional redundancy at the level of individual output channels. For each convolutional layer, we construct a complex interaction field by pairing the full multi-channel input activation as the real part with a single output-channel activation (spatially aligned and broadcast across input channels) as the imaginary part. We transform this complex field to the frequency domain and train a low-capacity autoencoder to reconstruct normalized spectra. Channels whose spectra are reconstructed with high fidelity are interpreted as lying close to a low-dimensional manifold captured by the autoencoder and are therefore more compressible; conversely, channels with low fidelity are retained as they encode information that cannot be compactly represented by the learned manifold. This yields an importance score (optionally fused with the filter L1 norm) that supports simple threshold-based pruning and produces a structurally consistent pruned network. On VGG16 trained on CIFAR-10, at a fixed threshold of 0.6, we obtain 90.11% FLOP reduction and 96.30% parameter reduction with an absolute Top-1 accuracy drop of 1.67% from a 93.44% baseline after fine-tuning, demonstrating that spectral reconstruction fidelity of complex interaction fields is an effective proxy for channel-level redundancy under aggressive compression.", "AI": {"tldr": "本文提出了Spectral Complex Autoencoder Pruning (SCAP)，一种基于重建的功能冗余度量方法，用于极端结构化通道压缩。", "motivation": "动机在于探索如何在保持模型性能的同时大幅度减少计算复杂性和参数数量。通过开发新的修剪标准来识别和移除功能冗余的通道可以实现这一目标。", "method": "SCAP方法首先构建一个由多通道输入激活作为实部，单个输出通道激活（空间对齐并在输入通道上进行广播）作为虚部组成的复杂交互场，并将其转换到频域中。然后训练低容量自动编码器来重构归一化的频谱，以此为依据评估通道的可压缩性。", "result": "在CIFAR-10数据集上的VGG16模型实验表明，在固定阈值0.6下，可以获得90.11%的操作数减少和96.30%的参数减少，同时Top-1准确率仅下降了1.67%，这证明了SCAP的有效性。", "conclusion": "结论是，复杂交互场的频谱重构保真度可以作为通道级冗余的有效代理，在极端压缩下依然能够保持模型性能。"}}
{"id": "2601.09351", "pdf": "https://arxiv.org/pdf/2601.09351", "abs": "https://arxiv.org/abs/2601.09351", "authors": ["Ruomu Tan", "Martin W Hoffmann"], "title": "Navigating Ethical AI Challenges in the Industrial Sector: Balancing Innovation and Responsibility", "categories": ["cs.CY", "cs.AI"], "comment": ":68T99ACM Class:K.4.0; I.2.1; I.2.9", "summary": "The integration of artificial intelligence (AI) into the industrial sector has not only driven innovation but also expanded the ethical landscape, necessitating a reevaluation of principles governing technology and its applications and awareness in research and development of industrial AI solutions. This chapter explores how AI-empowered industrial innovation inherently intersects with ethics, as advancements in AI introduce new challenges related to transparency, accountability, and fairness. In the chapter, we then examine the ethical aspects of several examples of AI manifestation in industrial use cases and associated factors such as ethical practices in the research and development process and data sharing. With the progress of ethical industrial AI solutions, we emphasize the importance of embedding ethical principles into industrial AI systems and its potential to inspire technological breakthroughs and foster trust among stakeholders. This chapter also offers actionable insights to guide industrial research and development toward a future where AI serves as an enabler for ethical and responsible industrial progress as well as a more inclusive industrial ecosystem.", "AI": {"tldr": "本文探讨了工业领域中人工智能（AI）的伦理挑战，并强调将伦理原则融入AI系统的重要性。", "motivation": "随着AI在工业领域的应用，出现了新的伦理问题如透明度、责任和公平性，需要重新评估技术及其应用的原则。", "method": "通过研究几个AI在工业中的实际案例，以及研发过程中涉及的伦理实践和数据共享因素，分析其伦理方面的影响。", "result": "强调将伦理原则嵌入到工业AI系统中能够促进技术创新并增强利益相关者的信任，并为未来的工业R&D提供可操作性的见解。", "conclusion": "本文提出了一种路径，通过重视伦理责任来推动工业的进步，并构建一个更加包容的工业生态系统。"}}
{"id": "2601.09350", "pdf": "https://arxiv.org/pdf/2601.09350", "abs": "https://arxiv.org/abs/2601.09350", "authors": ["Mingyu Jeon", "Sungjin Han", "Jinkwon Hwang", "Minchol Kwon", "Jonghee Kim", "Junyeong Kim"], "title": "See More, Store Less: Memory-Efficient Resolution for Video Moment Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have improved image recognition and reasoning, but video-related tasks remain challenging due to memory constraints from dense frame processing. Existing Video Moment Retrieval (VMR) methodologies rely on sparse frame sampling, risking potential information loss, especially in lengthy videos. We propose SMORE (See MORE, store less), a framework that enhances memory efficiency while maintaining high information resolution. SMORE (1) uses query-guided captions to encode semantics aligned with user intent, (2) applies query-aware importance modulation to highlight relevant segments, and (3) adaptively compresses frames to preserve key content while reducing redundancy. This enables efficient video understanding without exceeding memory budgets. Experimental validation reveals that SMORE achieves state-of-the-art performance on QVHighlights, Charades-STA, and ActivityNet-Captions benchmarks.", "AI": {"tldr": "提出SMORE框架，提高视频片段检索任务中的内存效率同时保持信息分辨率。", "motivation": "现有的视频片段检索方法依赖稀疏帧采样，这在长视频中可能导致信息丢失。随着多模态大型语言模型的进步，图像识别和推理得到了改善，但视频相关的任务仍然面临密集帧处理带来的内存限制挑战。", "method": "SMORE框架通过使用基于查询指导的标题来编码与用户意图对齐的语义，应用基于查询的关注度调节来突出相关片段，并自适应地压缩帧以保存关键内容同时减少冗余。", "result": "实验验证表明，SMORE在QVHighlights、Charades-STA和ActivityNet-Captions基准上实现了最先进的性能。", "conclusion": "研究证明了SMORE框架能够有效提高视频理解的内存效率而不超出内存预算。"}}
{"id": "2601.09342", "pdf": "https://arxiv.org/pdf/2601.09342", "abs": "https://arxiv.org/abs/2601.09342", "authors": ["Ewelina Gajewska", "Katarzyna Budzynska", "Jarosław A Chudziak"], "title": "Improving Implicit Hate Speech Detection via a Community-Driven Multi-Agent Framework", "categories": ["cs.CL", "cs.AI"], "comment": "This paper has been accepted for the upcoming 18th International Conference on Agents and Artificial Intelligence (ICAART-2026), Marbella, Spain. The final published version will appear in the official conference proceedings", "summary": "This work proposes a contextualised detection framework for implicitly hateful speech, implemented as a multi-agent system comprising a central Moderator Agent and dynamically constructed Community Agents representing specific demographic groups. Our approach explicitly integrates socio-cultural context from publicly available knowledge sources, enabling identity-aware moderation that surpasses state-of-the-art prompting methods (zero-shot prompting, few-shot prompting, chain-of-thought prompting) and alternative approaches on a challenging ToxiGen dataset. We enhance the technical rigour of performance evaluation by incorporating balanced accuracy as a central metric of classification fairness that accounts for the trade-off between true positive and true negative rates. We demonstrate that our community-driven consultative framework significantly improves both classification accuracy and fairness across all target groups.", "AI": {"tldr": "本文提出了一种基于多智能体系统的隐性仇恨言论检测框架，通过整合社会文化背景信息来提高检测准确性和平等性。", "motivation": "为了改进现有的零样本、少量样本和思维链提示方法，开发一种能够更好地理解和检测针对特定人群的隐性仇恨言论的方法。", "method": "使用一个多智能体系统，包括一个中心调节者代理和动态构建的社区代理来代表不同的社会群体，并利用公开的知识源整合社会文化背景信息。", "result": "在ToxiGen数据集上，该框架显著提高了分类准确性和公平性，特别是在所有目标组中表现出色。", "conclusion": "本文提出的方法通过增加对特定人群的社会文化理解，提升了隐性仇恨言论检测的性能和公平性。"}}
{"id": "2601.09333", "pdf": "https://arxiv.org/pdf/2601.09333", "abs": "https://arxiv.org/abs/2601.09333", "authors": ["Chun-Chieh Hsu", "Tsai-Ling Hsu", "Chen-Chen Yeh", "Shao-Chien Lu", "Cheng-Han Wu", "Bing-Ze Liu", "Timothy K. Shih", "Yu-Cheng Lin"], "title": "Research on Piano Timbre Transformation System Based on Diffusion Model", "categories": ["cs.SD", "cs.MM"], "comment": null, "summary": "We propose a timbre conversion model based on the Diffusion architecture de-signed to precisely translate music played by various instruments into piano ver-sions. The model employs a Pitch Encoder and Loudness Encoder to extract pitch and loudness features of the music, which serve as conditional inputs to the Dif-fusion Model's decoder, generating high-quality piano timbres. Case analysis re-sults show that the model performs excellently in terms of pitch accuracy and timbral similarity, maintaining stable conversion across different musical styles (classical, jazz, pop) and lengths (from short clips to full pieces). Particularly, the model maintains high sound quality and accuracy even when dealing with rapidly changing notes and complex musical structures, demonstrating good generaliza-tion capability. Additionally, the model has the potential for real-time musical conversion and is suitable for live performances and digital music creation tools. Future research will focus on enhancing the handling of loudness dynamics and incorporating additional musical features (such as timbral variations and rhythmic complexity) to improve the model's adaptability and expressiveness. We plan to explore the model's application potential in other timbre conversion tasks, such as converting vocals to instrumental sounds or integration with MIDI digital pianos, further expanding the application scope of the Diffusion-based timbre conversion model in the field of music generation.", "AI": {"tldr": "本文提出了一种基于扩散模型的钢琴音色转换系统，能够将不同乐器演奏的音乐转化为高质量的钢琴版本。", "motivation": "研究动机在于实现一种能够准确翻译不同乐器演奏的音乐为钢琴版本的方法，并在不同的音乐风格和长度上保持稳定的转换质量。", "method": "该方法基于扩散模型架构设计，通过Pitch Encoder和Loudness Encoder提取音高和响度特征作为条件输入给扩散模型解码器，生成高质量的钢琴音色。", "result": "实验结果显示模型在音准准确性和音色调性相似性的表现上非常出色，并且能够在不同音乐风格、长度以及快速变化的音符和复杂结构下保持稳定性能。", "conclusion": "该研究提出的方法具有实时音乐转换的能力，适用于现场表演和数字音乐创作工具。未来的研究将专注于进一步提升响度动态处理能力和集成更多音乐特征以提高模型的适应性和表现力。"}}
{"id": "2601.09322", "pdf": "https://arxiv.org/pdf/2601.09322", "abs": "https://arxiv.org/abs/2601.09322", "authors": ["Laure Ciernik", "Marco Morik", "Lukas Thede", "Luca Eyring", "Shinichi Nakajima", "Zeynep Akata", "Lukas Muttenthaler"], "title": "Beyond the final layer: Attentive multilayer fusion for vision transformers", "categories": ["cs.CV"], "comment": null, "summary": "With the rise of large-scale foundation models, efficiently adapting them to downstream tasks remains a central challenge. Linear probing, which freezes the backbone and trains a lightweight head, is computationally efficient but often restricted to last-layer representations. We show that task-relevant information is distributed across the network hierarchy rather than solely encoded in any of the last layers. To leverage this distribution of information, we apply an attentive probing mechanism that dynamically fuses representations from all layers of a Vision Transformer. This mechanism learns to identify the most relevant layers for a target task and combines low-level structural cues with high-level semantic abstractions. Across 20 diverse datasets and multiple pretrained foundation models, our method achieves consistent, substantial gains over standard linear probes. Attention heatmaps further reveal that tasks different from the pre-training domain benefit most from intermediate representations. Overall, our findings underscore the value of intermediate layer information and demonstrate a principled, task aware approach for unlocking their potential in probing-based adaptation.", "AI": {"tldr": "提出了一种注意力多层融合机制，用于提高视觉变换器在下游任务中的性能。", "motivation": "尽管线性探测方法计算效率高，但它通常仅限于最后一层的表现。本文动机在于利用网络层级中分散的任务相关信息来改进这种方法。", "method": "通过应用一种注意探测机制动态地融合Vision Transformer的所有层次表示，该机制能够识别对目标任务最相关的层次，并结合低级结构线索和高级语义抽象。", "result": "在20个多样化数据集和多个预训练基础模型上，该方法相对于标准线性探针取得了持续、显著的性能提升。注意力热图进一步揭示了与预训练领域不同的任务从中间表示中获益最多。", "conclusion": "研究表明中间层信息的价值，并展示了通过原理性的任务感知方法来解锁其潜力的重要性。"}}
{"id": "2601.09318", "pdf": "https://arxiv.org/pdf/2601.09318", "abs": "https://arxiv.org/abs/2601.09318", "authors": ["Ro'i Lang", "Elon Rimon"], "title": "Feedback-Based Mobile Robot Navigation in 3-D Environments Using Artificial Potential Functions Technical Report", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "This technical report presents the construction and analysis of polynomial navigation functions for motion planning in 3-D workspaces populated by spherical and cylindrical obstacles. The workspace is modeled as a bounded spherical region, and obstacles are encoded using smooth polynomial implicit functions. We establish conditions under which the proposed navigation functions admit a unique non-degenerate minimum at the target while avoiding local minima, including in the presence of pairwise intersecting obstacles. Gradient and Hessian analyses are provided, and the theoretical results are validated through numerical simulations in obstacle rich 3-D environments.", "AI": {"tldr": "本技术报告介绍了在三维工作空间中使用多项式导航函数进行移动机器人路径规划的方法。", "motivation": "研究目的在于解决多障碍物环境下，避免局部最小值并确保存在唯一非退化目标点的路径规划问题。", "method": "通过平滑多项式隐式函数编码障碍物，并在有成对相交障碍物的情况下建立导航函数的独特性条件。进行了梯度和Hessian矩阵分析以验证理论结果。", "result": "数值模拟在复杂的三维环境中证实了所提出方法的有效性和准确性。", "conclusion": "实验结果显示，提出的多项式导航函数能够有效地进行路径规划，并避免局部最小值问题。"}}
{"id": "2601.09316", "pdf": "https://arxiv.org/pdf/2601.09316", "abs": "https://arxiv.org/abs/2601.09316", "authors": ["Xinming Fang", "Chaoyan Huang", "Juncheng Li", "Jun Wang", "Jun Shi", "Guixu Zhang"], "title": "Frequency Error-Guided Under-sampling Optimization for Multi-Contrast MRI Reconstruction", "categories": ["cs.CV"], "comment": "44 pages, 12 figures, 7 tables", "summary": "Magnetic resonance imaging (MRI) plays a vital role in clinical diagnostics, yet it remains hindered by long acquisition times and motion artifacts. Multi-contrast MRI reconstruction has emerged as a promising direction by leveraging complementary information from fully-sampled reference scans. However, existing approaches suffer from three major limitations: (1) superficial reference fusion strategies, such as simple concatenation, (2) insufficient utilization of the complementary information provided by the reference contrast, and (3) fixed under-sampling patterns. We propose an efficient and interpretable frequency error-guided reconstruction framework to tackle these issues. We first employ a conditional diffusion model to learn a Frequency Error Prior (FEP), which is then incorporated into a unified framework for jointly optimizing both the under-sampling pattern and the reconstruction network. The proposed reconstruction model employs a model-driven deep unfolding framework that jointly exploits frequency- and image-domain information. In addition, a spatial alignment module and a reference feature decomposition strategy are incorporated to improve reconstruction quality and bridge model-based optimization with data-driven learning for improved physical interpretability. Comprehensive validation across multiple imaging modalities, acceleration rates (4-30x), and sampling schemes demonstrates consistent superiority over state-of-the-art methods in both quantitative metrics and visual quality. All codes are available at https://github.com/fangxinming/JUF-MRI.", "AI": {"tldr": "提出了一种基于频率误差引导的重建框架，用于多对比度MRI重建。", "motivation": "现有方法在参考融合策略、互补信息利用和固定欠采样模式方面存在不足，影响了MRI重建的质量。", "method": "首先采用条件扩散模型学习频率误差先验，然后将其纳入统一框架中优化欠采样模式和重建网络。使用了一个结合频域和图像域信息的模型驱动深度展开框架，并加入空间对齐模块和参考特征分解策略以提高重建质量。", "result": "在多个成像模态、加速率（4-30倍）和抽样方案下，验证了该方法在定量指标和视觉质量上优于现有前沿技术。", "conclusion": "所提框架通过优化欠采样模式和利用频率误差先验，有效提升了多对比度MRI的重建效果。"}}
{"id": "2601.09313", "pdf": "https://arxiv.org/pdf/2601.09313", "abs": "https://arxiv.org/abs/2601.09313", "authors": ["Jonathan Drechsel", "Erisa Bytyqi", "Steffen Herbold"], "title": "Understanding or Memorizing? A Case Study of German Definite Articles in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language models perform well on grammatical agreement, but it is unclear whether this reflects rule-based generalization or memorization. We study this question for German definite singular articles, whose forms depend on gender and case. Using GRADIEND, a gradient-based interpretability method, we learn parameter update directions for gender-case specific article transitions. We find that updates learned for a specific gender-case article transition frequently affect unrelated gender-case settings, with substantial overlap among the most affected neurons across settings. These results argue against a strictly rule-based encoding of German definite articles, indicating that models at least partly rely on memorized associations rather than abstract grammatical rules.", "AI": {"tldr": "研究德国定冠词的语言模型是基于规则的理解还是记忆。", "motivation": "探讨语言模型在语法一致性的表现是否反映了基于规则的泛化能力，或者仅仅是记忆。", "method": "使用GRADIEND方法学习特定性别-格过渡的参数更新方向。", "result": "发现针对特定性别-格过渡的学习更新经常影响无关设置，并且受影响神经元之间有显著重叠。", "conclusion": "模型依赖于记忆关联而非抽象语法规则来处理德国定冠词。"}}
{"id": "2601.09306", "pdf": "https://arxiv.org/pdf/2601.09306", "abs": "https://arxiv.org/abs/2601.09306", "authors": ["Xin Xia", "Hongzhi Yin", "Shane Culpepper"], "title": "On-Device Large Language Models for Sequential Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "WSDM'26", "summary": "On-device recommendation is critical for a number of real-world applications, especially in scenarios that have agreements on execution latency, user privacy, and robust functionality when internet connectivity is unstable or even impossible. While large language models (LLMs) can now provide exceptional capabilities that model user behavior for sequential recommendation tasks, their substantial memory footprint and computational overhead make the deployment on resource-constrained devices a high risk proposition. In this paper, we propose OD-LLM, the first task-adaptive compression framework explicitly designed to provide efficient and accurate on-device deployment of LLMs for sequential recommendation tasks. OD-LLM uniquely integrates two complementary compression strategies: a low-rank structural compression algorithm which uses Singular Value Decomposition (SVD) to significantly reduce parameter redundancy in the model, and a novel tokenization normalization technique that better complements the low-rank decomposition process being used. Additionally, to minimize any potential performance degradation when using higher compression ratios, a novel progressive alignment algorithm is used to iteratively refine the parameters required layerwise in the target model. Empirical evaluations conducted on sequential recommendation benchmarks show that OD-LLM exhibits no loss in effectiveness when compared to the original recommendation model, when the deployed model size is halved. These promising results demonstrate the efficacy and scalability of OD-LLM, making this novel solution a practical alternative for real-time, on-device solutions wishing to replace expensive, remotely executed LLMs.", "AI": {"tldr": "本文提出了OD-LLM，一种专门为在资源受限的设备上部署大型语言模型以完成顺序推荐任务而设计的任务自适应压缩框架。", "motivation": "由于大型语言模型具有较大的内存占用和计算开销，在资源受限的设备上的部署存在很大风险。因此，需要一个能够有效且准确地将这些模型部署到设备上的解决方案，特别是考虑到执行延迟、用户隐私及在网络不稳定或不可用情况下的稳健功能。", "method": "OD-LLM框架整合了两种互补的压缩策略：使用奇异值分解（SVD）降低参数冗余的低秩结构化压缩算法以及一种新型分词规范化技术。此外，通过逐层迭代调整目标模型所需的参数来最小化在更高压缩比率下的性能损失。", "result": "实验结果表明，在将部署模型大小减半的情况下，OD-LLM与原始推荐模型相比没有效果上的损失。这证明了OD-LLM的高效性和可扩展性，使其成为实时、设备上解决方案的一个实用替代方案。", "conclusion": "本文提出的OD-LLM框架展现了在资源受限设备上部署大型语言模型进行顺序推荐任务的有效性和可行性，并通过实验验证表明该方法能够维持高效率和准确性。"}}
{"id": "2601.09298", "pdf": "https://arxiv.org/pdf/2601.09298", "abs": "https://arxiv.org/abs/2601.09298", "authors": ["Lianying Chao", "Haoran Cai", "Xubin Li", "Kai Zhang", "Sijie Wu", "Rui Xu"], "title": "Multi-Modal LLM based Image Captioning in ICT: Bridging the Gap Between General and Industry Domain", "categories": ["cs.CV"], "comment": "ef:2025 CCF BigData", "summary": "In the information and communications technology (ICT) industry, training a domain-specific large language model (LLM) or constructing a retrieval-augmented generation system requires a substantial amount of high-value domain knowledge. However, the knowledge is not only hidden in the textual modality but also in the image modality. Traditional methods can parse text from domain documents but dont have image captioning ability. Multi-modal LLM (MLLM) can understand images, but they do not have sufficient domain knowledge. To address the above issues, this paper proposes a multi-stage progressive training strategy to train a Domain-specific Image Captioning Model (DICModel) in ICT, and constructs a standard evaluation system to validate the performance of DICModel. Specifically, this work first synthesizes about 7K image-text pairs by combining the Mermaid tool and LLMs, which are used for the first-stage supervised-fine-tuning (SFT) of DICModel. Then, ICT-domain experts manually annotate about 2K image-text pairs for the second-stage SFT of DICModel. Finally, experts and LLMs jointly synthesize about 1.5K visual question answering data for the instruction-based SFT. Experimental results indicate that our DICModel with only 7B parameters performs better than other state-of-the-art models with 32B parameters. Compared to the SOTA models with 7B and 32B parameters, our DICModel increases the BLEU metric by approximately 56.8% and 20.8%, respectively. On the objective questions constructed by ICT domain experts, our DICModel outperforms Qwen2.5-VL 32B by 1% in terms of accuracy rate. In summary, this work can efficiently and accurately extract the logical text from images, which is expected to promote the development of multimodal models in the ICT domain.", "AI": {"tldr": "本文提出了一种多阶段逐步训练策略来训练ICT领域的特定图像描述模型（DICModel），并构建了一个标准的评估体系以验证其性能。", "motivation": "在信息和通信技术领域，需要大量的专业领域知识来训练领域特定的大语言模型或构建检索增强生成系统。然而，这些知识不仅隐藏在文本中，也存在于图像模态中。传统的解析方法只能处理文档中的文本，无法进行图像描述。", "method": "本文提出一种多阶段逐步训练策略：首先通过Mermaid工具和大语言模型合成约7K张图文配对数据用于第一阶段的监督微调；其次，ICT领域专家手动标注约2K张图文配对数据用于第二阶段的监督微调；最后，专家与大语言模型共同合成约1.5K个视觉问答数据以进行指令型微调。", "result": "实验结果显示，具有仅7亿参数的DICModel在性能上优于拥有32亿参数的其他最先进的模型。与参数为7B和32B的SOTA模型相比，本文的DICModel分别提高了BLEU指标约56.8%和20.8%，并以1%的准确率优势超越了Qwen2.5-VL 32B。", "conclusion": "本工作可以高效、准确地从图像中提取逻辑文本，有望推动ICT领域多模态模型的发展。"}}
{"id": "2601.09293", "pdf": "https://arxiv.org/pdf/2601.09293", "abs": "https://arxiv.org/abs/2601.09293", "authors": ["Sofiene Lassoued", "Stefan Lier", "Andreas Schwung"], "title": "Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures", "categories": ["cs.AI"], "comment": null, "summary": "We present a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, addressing the challenges introduced by stochastic job arrivals and unexpected machine breakdowns. Our approach follows a model-based paradigm, using Coloured Timed Petri Nets to represent the scheduling environment, and Maskable Proximal Policy Optimization to enable dynamic decision-making while restricting the agent to feasible actions at each decision point. To simulate realistic industrial conditions, dynamic job arrivals are modeled using a Gamma distribution, which captures complex temporal patterns such as bursts, clustering, and fluctuating workloads. Machine failures are modeled using a Weibull distribution to represent age-dependent degradation and wear-out dynamics. These stochastic models enable the framework to reflect real-world manufacturing scenarios better. In addition, we study two action-masking strategies: a non-gradient approach that overrides the probabilities of invalid actions, and a gradient-based approach that assigns negative gradients to invalid actions within the policy network. We conduct extensive experiments on dynamic JSSP benchmarks, demonstrating that our method consistently outperforms traditional heuristic and rule-based approaches in terms of makespan minimization. The results highlight the strength of combining interpretable Petri-net-based models with adaptive reinforcement learning policies, yielding a resilient, scalable, and explainable framework for real-time scheduling in dynamic and uncertain manufacturing environments.", "AI": {"tldr": "本文提出了一种基于策略的强化学习方法，通过动作屏蔽处理不确定条件下的动态作业车间调度问题。", "motivation": "解决由于随机任务到达和意外机器故障导致的动态作业车间调度挑战，并更好地反映现实制造场景。", "method": "使用染色定时Petri网表示调度环境，Maskable Proximal Policy Optimization进行决策，同时采用非梯度和基于梯度的动作屏蔽策略来限制不可行操作。", "result": "实验表明该方法在动态作业车间基准测试中持续优于传统启发式和规则基础方法，在最小化完成时间方面表现更好。", "conclusion": "结合可解释的Petri网模型与自适应强化学习策略，提供了一个稳健、可扩展且具有解释性的框架用于实时调度不确定制造环境。"}}
{"id": "2601.09292", "pdf": "https://arxiv.org/pdf/2601.09292", "abs": "https://arxiv.org/abs/2601.09292", "authors": ["Greta Dolcetti", "Giulio Zizzo", "Sergio Maffeis"], "title": "Blue Teaming Function-Calling Agents", "categories": ["cs.CR", "cs.AI"], "comment": "This work has been accepted to appear at the AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "We present an experimental evaluation that assesses the robustness of four open source LLMs claiming function-calling capabilities against three different attacks, and we measure the effectiveness of eight different defences. Our results show how these models are not safe by default, and how the defences are not yet employable in real-world scenarios.", "AI": {"tldr": "评估四个开源LLM在面对三种不同攻击时的功能调用能力的鲁棒性，并测量八种不同防御措施的有效性。", "motivation": "研究这些模型默认是否安全，以及现有的防御措施是否能够在现实世界场景中应用。", "method": "对四种具有功能调用能力的开源LLM进行实验评估，测试它们在三种攻击下的表现，并分析八种不同的防御策略的效果。", "result": "结果显示这些模型并不默认是安全的，且当前的防御措施尚不足以应对现实世界的威胁。", "conclusion": "表明现有的大型语言模型和其功能调用能力在面临安全挑战时存在漏洞，需要进一步改进防御机制来提升安全性。"}}
{"id": "2601.09289", "pdf": "https://arxiv.org/pdf/2601.09289", "abs": "https://arxiv.org/abs/2601.09289", "authors": ["Takashi Horiyama", "Takehiro Ito", "Jun Kawahara", "Shin-ichi Minato", "Akira Suzuki", "Ryuhei Uehara", "Yutaro Yamaguchi"], "title": "Computational Complexity of Swish", "categories": ["cs.DS", "cs.CC", "math.CO"], "comment": "10 pages, 5 figures", "summary": "Swish is a card game in which players are given cards having symbols (hoops and balls), and find a valid superposition of cards, called a \"swish.\" Dailly, Lafourcade, and Marcadet (FUN 2024) studied a generalized version of Swish and showed that the problem is solvable in polynomial time with one symbol per card, while it is NP-complete with three or more symbols per card. In this paper, we resolve the previously open case of two symbols per card, which corresponds to the original game. We show that Swish is NP-complete for this case. Specifically, we prove the NP-hardness when the allowed transformations of cards are restricted to a single (horizontal or vertical) flip or 180-degree rotation, and extend the results to the original setting allowing all three transformations. In contrast, when neither transformation is allowed, we present a polynomial-time algorithm. Combining known and our results, we establish a complete characterization of the computational complexity of Swish with respect to both the number of symbols per card and the allowed transformations.", "AI": {"tldr": "本文解决了Swish游戏中每张卡有两张符号的情况下的计算复杂性问题，证明了在某些变换限制下该问题NP完全，并提供了无变换情况下的多项式时间算法。", "motivation": "动机在于研究Swish游戏的计算复杂性，特别是解决Dailly等人未解决的每张卡有两个符号的情形。", "method": "使用了NP完全性的证明方法来展示在特定变换限制下问题的难解性，并设计了一种无变换情况下的多项式时间算法。", "result": "证明了当每张卡片上有两个符号且只允许水平或垂直翻转及180度旋转时Swish问题是NP完全的，而无变换时存在多项式时间算法。", "conclusion": "通过结合已知结果和本文的结果，完整地刻画了不同情况下的Swish计算复杂性。"}}
{"id": "2601.09286", "pdf": "https://arxiv.org/pdf/2601.09286", "abs": "https://arxiv.org/abs/2601.09286", "authors": ["Hanze Guo", "Jianxun Lian", "Xiao Zhou"], "title": "Why not Collaborative Filtering in Dual View? Bridging Sparse and Dense Models", "categories": ["cs.IR", "cs.AI"], "comment": "25 pages, 6 figures", "summary": "Collaborative Filtering (CF) remains the cornerstone of modern recommender systems, with dense embedding--based methods dominating current practice. However, these approaches suffer from a critical limitation: our theoretical analysis reveals a fundamental signal-to-noise ratio (SNR) ceiling when modeling unpopular items, where parameter-based dense models experience diminishing SNR under severe data sparsity. To overcome this bottleneck, we propose SaD (Sparse and Dense), a unified framework that integrates the semantic expressiveness of dense embeddings with the structural reliability of sparse interaction patterns. We theoretically show that aligning these dual views yields a strictly superior global SNR. Concretely, SaD introduces a lightweight bidirectional alignment mechanism: the dense view enriches the sparse view by injecting semantic correlations, while the sparse view regularizes the dense model through explicit structural signals. Extensive experiments demonstrate that, under this dual-view alignment, even a simple matrix factorization--style dense model can achieve state-of-the-art performance. Moreover, SaD is plug-and-play and can be seamlessly applied to a wide range of existing recommender models, highlighting the enduring power of collaborative filtering when leveraged from dual perspectives. Further evaluations on real-world benchmarks show that SaD consistently outperforms strong baselines, ranking first on the BarsMatch leaderboard. The code is publicly available at https://github.com/harris26-G/SaD.", "AI": {"tldr": "本文提出SaD框架，通过结合稀疏和密集模型的优势来提升推荐系统的性能。", "motivation": "现有的基于稠密嵌入的协同过滤方法在处理不热门项目时面临信号噪声比(SNR)天花板的问题，作者希望通过整合稀疏交互模式和稠密嵌入的特点来克服这一瓶颈。", "method": "SaD框架通过双向对齐机制将稀疏视图与密集视图结合，其中密集视图注入语义相关性以丰富稀疏视图，而稀疏视图则通过显式的结构信号来规范密集模型。", "result": "实验显示，在这种双视角对齐下，即使是一个简单的矩阵分解式稠密模型也能够实现最先进的性能。SaD在多个现实世界基准测试中表现优于强基线，并在BarsMatch排行榜上排名第一。", "conclusion": "通过整合稀疏和稠密模型的优势，提出的SaD框架能够在不热门项目推荐方面显著提升SNR并达到优异的推荐效果。"}}
{"id": "2601.09282", "pdf": "https://arxiv.org/pdf/2601.09282", "abs": "https://arxiv.org/abs/2601.09282", "authors": ["Leszek Sliwko", "Jolanta Mizeria-Pietraszko"], "title": "Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing", "categories": ["cs.AI", "cs.DC", "cs.LG", "cs.SE"], "comment": null, "summary": "Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.", "AI": {"tldr": "论文介绍了使用自然语言处理和大型语言模型来简化集群工作负载分配，通过语义和意图驱动的调度范式实现软亲和性偏好。", "motivation": "旨在解决现有集群工作负载配置复杂的问题，提高用户友好性和易用性。", "method": "采用大型语言模型（LLM）集成Kubernetes调度器扩展程序来解析自然语言分配提示注释，以满足软亲和性偏好。使用了AWS Bedrock开发了一个原型系统。", "result": "实验表明所提出的LLM具有高解析准确性 (>95% 子集准确率)，并优于基线引擎。在六个场景中，原型系统的调度质量与标准Kubernetes配置相当或更优。", "conclusion": "结果验证了使用大型语言模型进行语义软亲和性工作负载编排的可行性，并指出了解决生产就绪所需的异步处理等限制。"}}
{"id": "2601.09281", "pdf": "https://arxiv.org/pdf/2601.09281", "abs": "https://arxiv.org/abs/2601.09281", "authors": ["Jingjing Zhou", "Gaoxiang Cong", "Li Su", "Liang Li"], "title": "STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.", "AI": {"tldr": "提出STaR框架，以解决大型推理模型中的隐私泄露问题。", "motivation": "现有的语言模型去学习方法不能有效移除中间步骤的敏感信息，导致持续的隐私泄漏和安全下降。因此需要一个能够在推理过程中保护隐私的方法。", "method": "通过语义感知检测识别敏感内容，并注入全局安全约束，动态阻断整个推理链中的敏感内容，应用令牌级自适应过滤来防止生成过程中的精确或同义词敏感信息。", "result": "实验表明STaR可以在保持最小效用损失的前提下实现全面稳定的去学习，为大型推理模型的隐私保护设立了新的标准。", "conclusion": "提出的框架可以有效解决现有大语言模型去学习方法无法处理中间步骤敏感内容的问题，并通过新的评估指标验证了其在不同解码策略下的稳定性以及对答案和推理链的隐私保护能力。"}}
{"id": "2601.09280", "pdf": "https://arxiv.org/pdf/2601.09280", "abs": "https://arxiv.org/abs/2601.09280", "authors": ["Chaerin Lee", "Sohee Park", "Hyunsik Na", "Daseon Choi"], "title": "ReGraM: Region-First Knowledge Graph Reasoning for Medical Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages, 2 figures. Preprint", "summary": "Recent studies in medical question answering (Medical QA) have actively explored the integration of large language models (LLMs) with biomedical knowledge graphs (KGs) to improve factual accuracy. However, most existing approaches still rely on traversing the entire KG or performing large-scale retrieval, which introduces substantial noise and leads to unstable multi-hop reasoning. We argue that the core challenge lies not in expanding access to knowledge, but in identifying and reasoning over the appropriate subset of evidence for each query. ReGraM is a region-first knowledge graph reasoning framework that addresses this challenge by constructing a query-aligned subgraph and performing stepwise reasoning constrained to this localized region under multiple evidence aware modes. By focusing inference on only the most relevant portion of the KG, ReGraM departs from the assumption that all relations are equally useful an assumption that rarely holds in domain-specific medical settings. Experiments on seven medical QA benchmarks demonstrate that ReGraM consistently outperforms a strong baseline (KGARevion), achieving an 8.04% absolute accuracy gain on MCQ, a 4.50% gain on SAQ, and a 42.9% reduction in hallucination rate. Ablation and qualitative analyses further show that aligning region construction with hop-wise reasoning is the primary driver of these improvements. Overall, our results highlight region-first KG reasoning as an effective paradigm for improving factual accuracy and consistency in medical QA.", "AI": {"tldr": "介绍了一种名为ReGraM的区域优先知识图谱推理框架，用于提高医学问答中的事实准确性。", "motivation": "现有的医学问答方法通常依赖遍历整个知识图或执行大规模检索来提升事实准确度，这引入了大量噪音并导致多跳推理不稳定。研究动机在于通过聚焦于查询相关的子图部分进行推理以解决这一问题。", "method": "ReGraM构建一个与查询对齐的子图并在该局部区域下按步骤进行证据感知模式下的推理，从而在医学问答中提高事实准确性和一致性。", "result": "实验结果表明，在七个医学问答基准测试上，ReGraM相较于强基线（KGARevion）有显著提升：MCQ上的绝对准确性提升了8.04%，SAQ上提高了4.50%，且幻觉率减少42.9%。", "conclusion": "通过区域优先的知识图谱推理可以有效地改善医学问答中的事实准确性和一致性。"}}
{"id": "2601.09278", "pdf": "https://arxiv.org/pdf/2601.09278", "abs": "https://arxiv.org/abs/2601.09278", "authors": ["Xiaohan Yu", "Chao Feng", "Lang Mei", "Chong Chen"], "title": "M$^3$Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in DeepResearch-style agents have demonstrated strong capabilities in autonomous information acquisition and synthesize from real-world web environments. However, existing approaches remain fundamentally limited to text modality. Extending autonomous information-seeking agents to multimodal settings introduces critical challenges: the specialization-generalization trade-off that emerges when training models for multimodal tool-use at scale, and the severe scarcity of training data capturing complex, multi-step multimodal search trajectories. To address these challenges, we propose M$^3$Searcher, a modular multimodal information-seeking agent that explicitly decouples information acquisition from answer derivation. M$^3$Searcher is optimized with a retrieval-oriented multi-objective reward that jointly encourages factual accuracy, reasoning soundness, and retrieval fidelity. In addition, we develop MMSearchVQA, a multimodal multi-hop dataset to support retrieval centric RL training. Experimental results demonstrate that M$^3$Searcher outperforms existing approaches, exhibits strong transfer adaptability and effective reasoning in complex multimodal tasks.", "AI": {"tldr": "本文提出了M$^3$Searcher，一个模块化多模态信息检索代理，专门用于复杂多步骤的多模态搜索任务。", "motivation": "现有的自主信息获取代理主要局限于文本模式，而扩展到多模态场景面临挑战，如专长与通用性的权衡和训练数据稀缺问题。为了解决这些问题并支持复杂的多模态任务。", "method": "M$^3$Searcher通过解耦信息获取和答案推导，并采用检索导向的多目标奖励进行优化来提升模型性能。同时开发了MMSearchVQA，一个多模态多跳数据集以支持基于检索为中心的强化学习训练。", "result": "实验结果显示，M$^3$Searcher在现有方法的基础上实现了性能的提升，表现出强大的适应性和有效的推理能力，在复杂的多模态任务中表现突出。", "conclusion": "该研究表明通过模块化设计和特定优化策略可以显著提高自主信息检索代理在多模态环境下的性能。"}}
{"id": "2601.09274", "pdf": "https://arxiv.org/pdf/2601.09274", "abs": "https://arxiv.org/abs/2601.09274", "authors": ["Jian Zhang", "Yu He", "Zhiyuan Wang", "Zhangqi Wang", "Kai He", "Fangzhi Xu", "Qika Lin", "Jun Liu"], "title": "$A^3$-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation", "categories": ["cs.AI"], "comment": null, "summary": "Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the \\textit{memory-driven} mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose $A^3$-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate $A^3$-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.", "AI": {"tldr": "提出$A^3$-Bench，一个评估科学推理中记忆驱动机制的基准测试，通过锚点和吸引子激活来提升推理性能。", "motivation": "现有的基准测试主要关注最终答案或逐步连贯性，忽略了支撑人类推理的记忆驱动机制。该论文旨在填补这一研究空白，设计一种新的基准测试以评价基于记忆驱动的科学推理。", "method": "通过SAPM过程注释2,198个跨领域的科学推理问题，并引入双尺度记忆评估框架及AAUI指标来衡量记忆激活率，实验验证$A^3$-Bench的有效性。", "result": "实验结果显示了不同模型和范式在$A^3$-Bench上的表现，证实了内存激活对于提升推理性能的重要作用。", "conclusion": "该研究提供了对基于记忆驱动的科学推理机制的新见解，并通过新的基准测试$A^3$-Bench为评估这类推理能力提供了一种有效工具。"}}
{"id": "2601.09269", "pdf": "https://arxiv.org/pdf/2601.09269", "abs": "https://arxiv.org/abs/2601.09269", "authors": ["Wencheng Ye", "Liang Peng", "Xiaoyang Yuan", "Yi Bin", "Pengpeng Zeng", "Hengyu Jin", "Heng Tao Shen"], "title": "RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering", "categories": ["cs.AI"], "comment": null, "summary": "Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4-6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2-3x higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.", "AI": {"tldr": "提出RISER，一个插件式的干预框架，用于自适应地引导LLM在激活空间中的推理。", "motivation": "现有的参数高效的方法通过静态的手动干预来实现激活引导，但不能适应复杂推理的动态性质。为了克服这一局限性，提出了RISER。", "method": "RISER构建了一个可重复使用的推理向量库，并使用轻量级路由器在输入时动态组合这些向量。路由通过任务级别奖励进行强化学习优化，以激活潜在的认知原语。", "result": "在七个不同的基准测试中，与基础模型相比，RISER平均零样本准确率提高了3.4-6.5%，并且比CoT式的推理具有更高的标记效率和稳健的准确性提升。", "conclusion": "进一步分析表明，RISER自主组合多个向量形成可解释且精确控制策略，指向更可控和高效的LLM推理。"}}
{"id": "2601.09265", "pdf": "https://arxiv.org/pdf/2601.09265", "abs": "https://arxiv.org/abs/2601.09265", "authors": ["Bei Huang", "Yixin Chen", "Ruijie Lu", "Gang Zeng", "Hongbin Zha", "Yuru Pei", "Siyuan Huang"], "title": "GaussianFluent: Gaussian Simulation for Dynamic Scenes with Mixed Materials", "categories": ["cs.CV"], "comment": "16 pages", "summary": "3D Gaussian Splatting (3DGS) has emerged as a prominent 3D representation for high-fidelity and real-time rendering. Prior work has coupled physics simulation with Gaussians, but predominantly targets soft, deformable materials, leaving brittle fracture largely unresolved. This stems from two key obstacles: the lack of volumetric interiors with coherent textures in GS representation, and the absence of fracture-aware simulation methods for Gaussians. To address these challenges, we introduce GaussianFluent, a unified framework for realistic simulation and rendering of dynamic object states. First, it synthesizes photorealistic interiors by densifying internal Gaussians guided by generative models. Second, it integrates an optimized Continuum Damage Material Point Method (CD-MPM) to enable brittle fracture simulation at remarkably high speed. Our approach handles complex scenarios including mixed-material objects and multi-stage fracture propagation, achieving results infeasible with previous methods. Experiments clearly demonstrate GaussianFluent's capability for photo-realistic, real-time rendering with structurally consistent interiors, highlighting its potential for downstream application, such as VR and Robotics.", "AI": {"tldr": "提出了GaussianFluent框架，用于动态场景中混合材料的真实模拟和实时渲染。", "motivation": "现有的3D高斯点绘制（3DGS）方法在软性可变形材料的物理仿真上表现良好，但对于脆性破裂问题尚未得到解决。这主要由于缺乏具有连贯纹理的体积内部表示以及适合高斯形式的破裂感知模拟方法。", "method": "该框架首先通过生成模型指导内部高斯点的密集化来合成逼真的内部结构；其次，集成优化后的连续损伤材料点法（CD-MPM）以实现脆性破裂的高速仿真。这种方法能够处理包括混合材料对象和多阶段断裂传播在内的复杂场景。", "result": "实验显示GaussianFluent在真实感、实时渲染方面以及具有结构一致性内部的部分取得了显著成果，达到了以前的方法难以实现的效果。", "conclusion": "这项研究展示了GaussianFluent框架的潜力，特别是在虚拟现实和机器人技术等领域的下游应用中。"}}
{"id": "2601.09264", "pdf": "https://arxiv.org/pdf/2601.09264", "abs": "https://arxiv.org/abs/2601.09264", "authors": ["Ziyi Shi", "Xusen Guo", "Hongliang Lu", "Mingxing Peng", "Haotian Wang", "Zheng Zhu", "Zhenning Li", "Yuxuan Liang", "Xinhu Zheng", "Hai Yang"], "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "categories": ["cs.AI"], "comment": "20pages, 6 figures, a 60-page supporting material pdf file", "summary": "Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions. Within our framework, each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, our framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking...", "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）多智能体框架的政策制定系统，用于协调和主动控制疫情。", "motivation": "人类驱动的应对措施往往分散且反应性，导致政策孤立形成并在爆发加剧后才调整，这削弱了主动干预和全球大流行病缓解的能力。因此，提出了一种新的AI辅助的多智能体框架来解决这一挑战。", "method": "每个行政区被分配一个LLM代理作为AI政策助理。该模型在考虑地区特定的流行病动态的同时与其他代理人交流以考虑到跨区域依赖性。通过集成现实世界数据、大流行演化模拟器和结构化代理间通信，这个框架使得智能体可以探索反事实干预场景并制定协调政策。", "result": "使用2020年4月至12月美国各州的COVID-19数据进行了验证，并结合实际移动记录和观察到的政策措施。与现实世界的大流行结果相比，该方法将感染人数和死亡率分别减少了高达63.7%和40.1%，而在全州汇总时分别为39.0%和27.0%。", "conclusion": "LLM多智能系统能够通过协调政策制定实现更有效的疫情控制。"}}
{"id": "2601.09263", "pdf": "https://arxiv.org/pdf/2601.09263", "abs": "https://arxiv.org/abs/2601.09263", "authors": ["Yucheng Li", "Xiaofan Wang", "Junyi Wang", "Yijie Li", "Xi Zhu", "Mubai Du", "Dian Sheng", "Wei Zhang", "Fan Zhang"], "title": "BrainSegNet: A Novel Framework for Whole-Brain MRI Parcellation Enhanced by Large Models", "categories": ["cs.CV"], "comment": null, "summary": "Whole-brain parcellation from MRI is a critical yet challenging task due to the complexity of subdividing the brain into numerous small, irregular shaped regions. Traditionally, template-registration methods were used, but recent advances have shifted to deep learning for faster workflows. While large models like the Segment Anything Model (SAM) offer transferable feature representations, they are not tailored for the high precision required in brain parcellation. To address this, we propose BrainSegNet, a novel framework that adapts SAM for accurate whole-brain parcellation into 95 regions. We enhance SAM by integrating U-Net skip connections and specialized modules into its encoder and decoder, enabling fine-grained anatomical precision. Key components include a hybrid encoder combining U-Net skip connections with SAM's transformer blocks, a multi-scale attention decoder with pyramid pooling for varying-sized structures, and a boundary refinement module to sharpen edges. Experimental results on the Human Connectome Project (HCP) dataset demonstrate that BrainSegNet outperforms several state-of-the-art methods, achieving higher accuracy and robustness in complex, multi-label parcellation.", "AI": {"tldr": "本文提出BrainSegNet，一种用于精确全脑MRI分区的框架。", "motivation": "传统模板配准方法在处理复杂大脑区域分割时存在局限性，而大型模型虽然提供了可转移特征表示，但未针对高精度需求进行优化。因此，需要一个能够实现准确全脑分区的新框架。", "method": "BrainSegNet通过整合U-Net跳跃连接和专用模块来改进Segment Anything Model (SAM)，包括混合编码器、多尺度注意力解码器和边界细化模块。", "result": "在Human Connectome Project (HCP)数据集上，实验表明BrainSegNet优于多种现有方法，实现了更高的准确性和鲁棒性。", "conclusion": "BrainSegNet通过改进大型模型SAM，成功地提高了全脑MRI分区的精确度和复杂多标签分割的鲁棒性。"}}
{"id": "2601.09262", "pdf": "https://arxiv.org/pdf/2601.09262", "abs": "https://arxiv.org/abs/2601.09262", "authors": ["Maria Sdraka", "Dimitrios Michail", "Ioannis Papoutsis"], "title": "Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Delineating wildfire affected areas using satellite imagery remains challenging due to irregular and spatially heterogeneous spectral changes across the electromagnetic spectrum. While recent deep learning approaches achieve high accuracy when high-resolution multispectral data are available, their applicability in operational settings, where a quick delineation of the burn scar shortly after a wildfire incident is required, is limited by the trade-off between spatial resolution and temporal revisit frequency of current satellite systems. To address this limitation, we propose a novel deep learning model, namely BAM-MRCD, which employs multi-resolution, multi-source satellite imagery (MODIS and Sentinel-2) for the timely production of detailed burnt area maps with high spatial and temporal resolution. Our model manages to detect even small scale wildfires with high accuracy, surpassing similar change detection models as well as solid baselines. All data and code are available in the GitHub repository: https://github.com/Orion-AI-Lab/BAM-MRCD.", "AI": {"tldr": "本文提出了一种新型的深度学习模型BAM-MRCD，利用多分辨率、多源卫星图像（MODIS和Sentinel-2）实现野火后快速生成详细烧伤区域地图。", "motivation": "为了克服现有卫星系统在空间分辨率与时间重复频率之间的权衡，导致高精度模型难以应用于需要迅速划定火烧痕迹的运营场景的问题。", "method": "BAM-MRCD利用多分辨率、多源卫星数据（MODIS和Sentinel-2）进行深度学习建模，以实现烧伤区域的快速准确检测。", "result": "该模型能够高精度地检测小规模火灾，并且优于其他类似的变化检测模型及基准线。", "conclusion": "BAM-MRCD在野火后迅速生成详细、高分辨率的烧伤区域地图方面表现优异，数据和代码已公开。"}}
{"id": "2601.09260", "pdf": "https://arxiv.org/pdf/2601.09260", "abs": "https://arxiv.org/abs/2601.09260", "authors": ["Yan Liu", "Feng Zhang", "Zhanyu Ma", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He", "Han Liu", "Yangdong Deng"], "title": "Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify step-wise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, we propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.", "AI": {"tldr": "本文提出了CoT-Flow框架，将离散的推理步骤转化为连续的概率流，以量化每一步对最终答案的贡献。", "motivation": "现有方法在推理过程中缺乏量化信息增益的机制，导致推断效率低下和优化困难。", "method": "CoT-Flow包括基于流动的解码策略，提取信息高效的推理路径；以及基于流动的强化学习，构建无需验证器的密集奖励函数。", "result": "实验表明，CoT-Flow在具有挑战性的基准测试中，在推断效率和推理性能之间取得了更优平衡。", "conclusion": "通过将离散推理步骤转化为概率流，CoT-Flow解决了现有方法中存在的问题，并提高了推理效果。"}}
{"id": "2601.09259", "pdf": "https://arxiv.org/pdf/2601.09259", "abs": "https://arxiv.org/abs/2601.09259", "authors": ["Jian Zhang", "Zhiyuan Wang", "Zhangqi Wang", "Yu He", "Haoran Luo", "li yuan", "Lingling Zhang", "Rui Mao", "Qika Lin", "Jun Liu"], "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.", "AI": {"tldr": "本文提出了一种基于LLM代理的元适应性探索框架MAXS，旨在解决现有方法在推理过程中存在的局部短视和轨迹不稳定问题。", "motivation": "现有的LLM代理在推理时存在局部短视和轨迹不稳定的问题，导致难以平衡全局效果与计算效率。为此，提出了一种新的元适应性探索框架以克服这些挑战。", "method": "MAXS采用前瞻策略扩展几步的推理路径，并估计工具使用的收益值；结合步骤一致性方差与跨步趋势斜率选择稳定、一致且高价值的推理步骤。此外，引入轨迹收敛机制控制计算成本，在达到路径一致性时停止进一步展开，实现多工具有理性和资源效率之间的平衡。", "result": "通过在三个基础模型（MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B）和五个数据集上的广泛实证研究证明，MAXS在性能和推理效率上均优于现有方法。", "conclusion": "研究表明，提出的前瞻策略和工具使用方法是有效的。通过MAXS框架，可以在保持高效计算的同时提高全局推理效果，并且适用于多种基础模型和多样的任务场景。"}}
{"id": "2601.09255", "pdf": "https://arxiv.org/pdf/2601.09255", "abs": "https://arxiv.org/abs/2601.09255", "authors": ["Yibo Zhao", "Hengjia Li", "Xiaofei He", "Boxi Wu"], "title": "PhyRPR: Training-Free Physics-Constrained Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent diffusion-based video generation models can synthesize visually plausible videos, yet they often struggle to satisfy physical constraints. A key reason is that most existing approaches remain single-stage: they entangle high-level physical understanding with low-level visual synthesis, making it hard to generate content that require explicit physical reasoning. To address this limitation, we propose a training-free three-stage pipeline,\\textit{PhyRPR}:\\textit{Phy\\uline{R}eason}--\\textit{Phy\\uline{P}lan}--\\textit{Phy\\uline{R}efine}, which decouples physical understanding from visual synthesis. Specifically, \\textit{PhyReason} uses a large multimodal model for physical state reasoning and an image generator for keyframe synthesis; \\textit{PhyPlan} deterministically synthesizes a controllable coarse motion scaffold; and \\textit{PhyRefine} injects this scaffold into diffusion sampling via a latent fusion strategy to refine appearance while preserving the planned dynamics. This staged design enables explicit physical control during generation. Extensive experiments under physics constraints show that our method consistently improves physical plausibility and motion controllability.", "AI": {"tldr": "本文提出了一种无需训练的三阶段视频生成管道PhyRPR，该方法能够产生符合物理约束的视频。", "motivation": "现有基于扩散模型的视频生成技术难以满足物理约束，因为它们将高层物理理解和低层视觉合成混在一起。", "method": "PhyRPR分为三个阶段：PhyReason利用多模态模型进行物理状态推理和关键帧合成；PhyPlan确定性地生成可控制的粗略运动结构；PhyRefine通过潜变量融合策略将此结构注入扩散采样中，优化外观同时保持规划动态。", "result": "实验显示，在满足物理约束下，该方法提高了视频的物理合理性和动作可控性。", "conclusion": "提出的三阶段设计能够实现生成过程中的显式物理控制，并在多个实验中证明其有效性。"}}
{"id": "2601.09253", "pdf": "https://arxiv.org/pdf/2601.09253", "abs": "https://arxiv.org/abs/2601.09253", "authors": ["Zehua Liu", "Shuqi Liu", "Tao Zhong", "Mingxuan Yuan"], "title": "RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) are standard for LLM alignment, they either rely on costly expert data or discard valuable negative samples, leading to data inefficiency. To address this, we propose Reward Informed Fine-Tuning (RIFT), a simple yet effective framework that utilizes all self-generated samples. Unlike the hard thresholding of RFT, RIFT repurposes negative trajectories, reweighting the loss with scalar rewards to learn from both the positive and negative trajectories from the model outputs. To overcome the training collapse caused by naive reward integration, where direct multiplication yields an unbounded loss, we introduce a stabilized loss formulation that ensures numerical robustness and optimization efficiency. Extensive experiments on mathematical benchmarks across various base models show that RIFT consistently outperforms RFT. Our results demonstrate that RIFT is a robust and data-efficient alternative for alignment using mixed-quality, self-generated data.", "AI": {"tldr": "本文提出了RIFT（Reward Informed Fine-Tuning），一种利用所有自生成样本进行模型微调的方法，旨在提高数据效率和优化效果。", "motivation": "现有的SFT和RFT方法要么依赖于昂贵的专家数据，要么丢弃有价值的负样本，导致数据使用不充分。为了改善这一情况，本文提出了新的微调框架RIFT，以解决这些问题。", "method": "RIFT通过奖励信息重新加权损失函数，并引入稳定化的损失公式来克服训练崩溃的问题，从而使得模型可以从正负样本中学习。", "result": "实验结果表明，在数学基准测试上，RIFT方法相较于RFT在不同的基础模型上都表现出更优的性能和数据效率。", "conclusion": "本文证明了RIFT是一种使用混合质量自生成数据进行对齐的稳健且高效的数据利用方式。"}}
{"id": "2601.09251", "pdf": "https://arxiv.org/pdf/2601.09251", "abs": "https://arxiv.org/abs/2601.09251", "authors": ["Qin-Yi Zhang", "Hong Wang", "Siyao Liu", "Haichuan Lin", "Linying Cao", "Xiao-Hu Zhou", "Chen Chen", "Shuangyi Wang", "Zeng-Guang Hou"], "title": "HGATSolver: A Heterogeneous Graph Attention Solver for Fluid-Structure Interaction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fluid-structure interaction (FSI) systems involve distinct physical domains, fluid and solid, governed by different partial differential equations and coupled at a dynamic interface. While learning-based solvers offer a promising alternative to costly numerical simulations, existing methods struggle to capture the heterogeneous dynamics of FSI within a unified framework. This challenge is further exacerbated by inconsistencies in response across domains due to interface coupling and by disparities in learning difficulty across fluid and solid regions, leading to instability during prediction. To address these challenges, we propose the Heterogeneous Graph Attention Solver (HGATSolver). HGATSolver encodes the system as a heterogeneous graph, embedding physical structure directly into the model via distinct node and edge types for fluid, solid, and interface regions. This enables specialized message-passing mechanisms tailored to each physical domain. To stabilize explicit time stepping, we introduce a novel physics-conditioned gating mechanism that serves as a learnable, adaptive relaxation factor. Furthermore, an Inter-domain Gradient-Balancing Loss dynamically balances the optimization objectives across domains based on predictive uncertainty. Extensive experiments on two constructed FSI benchmarks and a public dataset demonstrate that HGATSolver achieves state-of-the-art performance, establishing an effective framework for surrogate modeling of coupled multi-physics systems.", "AI": {"tldr": "本文介绍了HGATSolver，一种用于流体结构相互作用的异构图注意力求解器。", "motivation": "现有的学习型求解器难以在统一框架内捕捉流体-结构交互系统的异质动态特性，尤其是在界面耦合导致响应不一致和不同区域学习难度差异带来的预测不稳定问题上。", "method": "HGATSolver将系统编码为一个异构图，通过特定的节点和边类型直接嵌入物理结构，并引入了物理条件门控机制以稳定时间步进以及跨域梯度平衡损失来动态调整优化目标。", "result": "在构建的两个流体-结构交互基准数据集和公共数据集上的广泛实验表明HGATSolver达到了最先进的性能，建立了耦合多物理系统代理模型的有效框架。", "conclusion": "HGATSolver通过异构图注意力机制成功解决了流体-结构相互作用系统的建模挑战，并在多种场景中展示了其优越性。"}}
{"id": "2601.09248", "pdf": "https://arxiv.org/pdf/2601.09248", "abs": "https://arxiv.org/abs/2601.09248", "authors": ["Ni Wang", "Zihan You", "Emre Neftci", "Thorben Schoepe"], "title": "Hybrid guided variational autoencoder for visual place recognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Autonomous agents such as cars, robots and drones need to precisely localize themselves in diverse environments, including in GPS-denied indoor environments. One approach for precise localization is visual place recognition (VPR), which estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes these limitations for robotics using a combination of event-based vision sensors and an event-based novel guided variational autoencoder (VAE). The encoder part of our model is based on a spiking neural network model which is compatible with power-efficient low latency neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in our new indoor VPR dataset with a classification performance comparable to other state-of-the-art approaches while, showing robust performance also under various illumination conditions. When tested with novel visual inputs from unknown scenes, our model can distinguish between these places, which demonstrates a high generalization capability by learning the essential features of location. Our compact and robust guided VAE with generalization capabilities poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.", "AI": {"tldr": "本文提出了一种结合事件驱动视觉传感器和事件驱动指导变分自编码器（VAE）的混合模型，用于解决在移动设备上实现精确视觉地点识别的问题。", "motivation": "传统的VPR方法要么内存需求高不适合移动部署，要么紧凑但缺乏鲁棒性和泛化能力。本文旨在通过提出一种新的方法来克服这些限制，以适应机器人在多种环境下的精准定位。", "method": "该研究使用基于尖峰神经网络模型的编码器与事件驱动指导变分自编码器结合，能够兼容功耗低且延迟低的脉冲神经形态硬件。实验中使用了作者创建的新室内VPR数据集来测试其性能。", "result": "该模型成功解耦16个不同地点的视觉特征，并在各种光照条件下表现出强大的分类和鲁棒性。对于未知场景下的新型视觉输入，模型也能有效区分这些地方，展示了良好的泛化能力。", "conclusion": "本研究提出的紧凑且具有强大泛化能力和鲁棒性的指导变分自编码器为室内环境中的移动机器人导航提供了有前景的解决方案。"}}
{"id": "2601.09247", "pdf": "https://arxiv.org/pdf/2601.09247", "abs": "https://arxiv.org/abs/2601.09247", "authors": ["Yiwei Zhang", "Jin Gao", "Hanshi Wang", "Fudong Ge", "Guan Luo", "Weiming Hu", "Zhipeng Zhang"], "title": "Integrating Diverse Assignment Strategies into DETRs", "categories": ["cs.CV"], "comment": null, "summary": "Label assignment is a critical component in object detectors, particularly within DETR-style frameworks where the one-to-one matching strategy, despite its end-to-end elegance, suffers from slow convergence due to sparse supervision. While recent works have explored one-to-many assignments to enrich supervisory signals, they often introduce complex, architecture-specific modifications and typically focus on a single auxiliary strategy, lacking a unified and scalable design. In this paper, we first systematically investigate the effects of ``one-to-many'' supervision and reveal a surprising insight that performance gains are driven not by the sheer quantity of supervision, but by the diversity of the assignment strategies employed. This finding suggests that a more elegant, parameter-efficient approach is attainable. Building on this insight, we propose LoRA-DETR, a flexible and lightweight framework that seamlessly integrates diverse assignment strategies into any DETR-style detector. Our method augments the primary network with multiple Low-Rank Adaptation (LoRA) branches during training, each instantiating a different one-to-many assignment rule. These branches act as auxiliary modules that inject rich, varied supervisory gradients into the main model and are discarded during inference, thus incurring no additional computational cost. This design promotes robust joint optimization while maintaining the architectural simplicity of the original detector. Extensive experiments on different baselines validate the effectiveness of our approach. Our work presents a new paradigm for enhancing detectors, demonstrating that diverse ``one-to-many'' supervision can be integrated to achieve state-of-the-art results without compromising model elegance.", "AI": {"tldr": "本文提出了LoRA-DETR，一种将多种分配策略融入DETR样式的检测器的方法。", "motivation": "现有的DETR样式框架中的一对一匹配策略收敛速度慢且监督信息稀疏。尽管一些研究探索了一对多的分配策略来增加监督信号，但它们通常引入了复杂的架构特定修改，并缺乏统一和可扩展的设计。", "method": "LoRA-DETR在训练期间通过添加多个低秩适应（LoRA）分支来增强主网络，每个分支实现不同的“一对多”匹配规则。这些分支作为辅助模块，在推理时会被丢弃，不增加计算成本。", "result": "实验验证了该方法的有效性，并展示了多样化的“一对多”监督可以集成到检测器中以达到最先进的结果而不损害模型优雅性。", "conclusion": "研究揭示了性能提升并非由监督信息的数量决定，而是取决于分配策略的多样性。LoRA-DETR提供了一个灵活、轻量级且不增加计算成本的方法来整合多种分配策略。"}}
{"id": "2601.09243", "pdf": "https://arxiv.org/pdf/2601.09243", "abs": "https://arxiv.org/abs/2601.09243", "authors": ["Sheng-Chi Hsu", "Ting-Yu Yen", "Shih-Hsuan Hung", "Hung-Kuo Chu"], "title": "A$^2$TG: Adaptive Anisotropic Textured Gaussians for Efficient 3D Scene Representation", "categories": ["cs.CV"], "comment": null, "summary": "Gaussian Splatting has emerged as a powerful representation for high-quality, real-time 3D scene rendering. While recent works extend Gaussians with learnable textures to enrich visual appearance, existing approaches allocate a fixed square texture per primitive, leading to inefficient memory usage and limited adaptability to scene variability. In this paper, we introduce adaptive anisotropic textured Gaussians (A$^2$TG), a novel representation that generalizes textured Gaussians by equipping each primitive with an anisotropic texture. Our method employs a gradient-guided adaptive rule to jointly determine texture resolution and aspect ratio, enabling non-uniform, detail-aware allocation that aligns with the anisotropic nature of Gaussian splats. This design significantly improves texture efficiency, reducing memory consumption while enhancing image quality. Experiments on multiple benchmark datasets demonstrate that A TG consistently outperforms fixed-texture Gaussian Splatting methods, achieving comparable rendering fidelity with substantially lower memory requirements.", "AI": {"tldr": "介绍了一种新的表示方法A$^2$TG，即自适应各向异性纹理高斯，用于提高三维场景的渲染效率。", "motivation": "现有的带纹理高斯方法使用固定的方形纹理，导致内存利用率低和对场景变化的适应性差。因此，提出了改进的方法以解决这些问题。", "method": "提出了一种基于梯度引导自适应规则的方法来确定每个纹理高斯元的非均匀分辨率和纵横比，从而提高纹理效率。", "result": "实验表明A$^2$TG在多个基准数据集上表现优于固定纹理高斯方法，在显著降低内存需求的同时保持渲染质量。", "conclusion": "自适应各向异性纹理高斯能够有效减少内存消耗，并且提升图像质量，适用于高效的三维场景表示。"}}
{"id": "2601.09240", "pdf": "https://arxiv.org/pdf/2601.09240", "abs": "https://arxiv.org/abs/2601.09240", "authors": ["Jiajun Chen", "Jing Xiao", "Shaohan Cao", "Yuming Zhu", "Liang Liao", "Jun Pan", "Mi Wang"], "title": "DeTracker: Motion-decoupled Vehicle Detection and Tracking in Unstabilized Satellite Videos", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Satellite videos provide continuous observations of surface dynamics but pose significant challenges for multi-object tracking (MOT), especially under unstabilized conditions where platform jitter and the weak appearance of tiny objects jointly degrade tracking performance. To address this problem, we propose DeTracker, a joint detection-and-tracking framework tailored for unstabilized satellite videos. DeTracker introduces a Global--Local Motion Decoupling (GLMD) module that explicitly separates satellite platform motion from true object motion through global alignment and local refinement, leading to improved trajectory stability and motion estimation accuracy. In addition, a Temporal Dependency Feature Pyramid (TDFP) module is developed to perform cross-frame temporal feature fusion, enhancing the continuity and discriminability of tiny-object representations. We further construct a new benchmark dataset, SDM-Car-SU, which simulates multi-directional and multi-speed platform motions to enable systematic evaluation of tracking robustness under varying motion perturbations. Extensive experiments on both simulated and real unstabilized satellite videos demonstrate that DeTracker significantly outperforms existing methods, achieving 61.1% MOTA on SDM-Car-SU and 47.3% MOTA on real satellite video data.", "AI": {"tldr": "介绍了一种专门用于不稳定卫星视频中车辆检测和跟踪的框架DeTracker。", "motivation": "卫星视频在连续观测地面动态方面提供了宝贵信息，但不稳定的平台运动导致了多目标跟踪的困难。该研究旨在解决这一问题并提升跟踪性能。", "method": "提出了一个名为Global--Local Motion Decoupling (GLMD) 的模块来分离卫星平台运动和真物体运动，并开发了一个Temporal Dependency Feature Pyramid (TDFP) 模块进行跨帧特征融合，以增强小目标表示的连续性和可辨别性。", "result": "通过模拟数据和实际不稳定卫星视频实验表明，DeTracker 在SDM-Car-SU 基准数据集上实现了61.1% 的MOTA，在真实卫星视频数据上达到47.3%，显著优于现有方法。", "conclusion": "研究展示了DeTracker在处理不稳定卫星视频中车辆检测和跟踪任务上的优越性能，表明了其解决平台运动干扰问题的有效性。"}}
{"id": "2601.09239", "pdf": "https://arxiv.org/pdf/2601.09239", "abs": "https://arxiv.org/abs/2601.09239", "authors": ["Hanlin Zhang", "Daxin Tan", "Dehua Tao", "Xiao Chen", "Haochen Tan", "Yunhe Li", "Yuchen Cao", "Jianping Wang", "Linqi Song"], "title": "DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion", "categories": ["cs.SD"], "comment": null, "summary": "Speech tokenizers serve as the cornerstone of discrete Speech Large Language Models (Speech LLMs). Existing tokenizers either prioritize semantic encoding, fuse semantic content with acoustic style inseparably, or achieve incomplete semantic-acoustic disentanglement. To achieve better disentanglement, we propose DSA-Tokenizer, which explicitly disentangles speech into discrete semantic and acoustic tokens via distinct optimization constraints. Specifically, semantic tokens are supervised by ASR to capture linguistic content, while acoustic tokens focus on mel-spectrograms restoration to encode style. To eliminate rigid length constraints between the two sequences, we introduce a hierarchical Flow-Matching decoder that further improve speech generation quality.Furthermore, We employ a joint reconstruction-recombination training strategy to enforce this separation. DSA-Tokenizer enables high fidelity reconstruction and flexible recombination through robust disentanglement, facilitating controllable generation in speech LLMs. Our analysis highlights disentangled tokenization as a pivotal paradigm for future speech modeling. Audio samples are avaialble at https://anonymous.4open.science/w/DSA_Tokenizer_demo/. The code and model will be made publicly available after the paper has been accepted.", "AI": {"tldr": "提出了DSA-Tokenizer，一种通过流匹配的分层融合来实现语义和声学分隔的离散化语音标记器。", "motivation": "现有的语音标记器要么侧重于语义编码，要么将语义内容与音调风格不可分割地融合在一起，或者只实现了不完全的语义-声学分离。为了更好地进行这种分离，作者提出了DSA-Tokenizer。", "method": "通过不同的优化约束来明确地将语音分解为离散化的语义标记和声学标记。具体而言，语义标记由ASR监督以捕捉语言内容，而声学标记则专注于Mel频谱图的恢复以编码风格。引入了一种分层流匹配解码器消除两个序列之间的刚性长度约束。", "result": "通过联合重构-重组训练策略，实现高保真度重构和灵活重组，提高语音生成质量，并促进在离散化大语言模型中的可控生成。", "conclusion": "强调了分离式标记化的关键范式作用于未来语音建模，展示了其在实现高质量且可控制的语音生成方面的潜力。"}}
{"id": "2601.09238", "pdf": "https://arxiv.org/pdf/2601.09238", "abs": "https://arxiv.org/abs/2601.09238", "authors": ["Jackie Alex", "Justin Petter"], "title": "Knowledge-Embedded and Hypernetwork-Guided Few-Shot Substation Meter Defect Image Generation Method", "categories": ["cs.CV"], "comment": null, "summary": "Substation meters play a critical role in monitoring and ensuring the stable operation of power grids, yet their detection of cracks and other physical defects is often hampered by a severe scarcity of annotated samples. To address this few-shot generation challenge, we propose a novel framework that integrates Knowledge Embedding and Hypernetwork-Guided Conditional Control into a Stable Diffusion pipeline, enabling realistic and controllable synthesis of defect images from limited data. First, we bridge the substantial domain gap between natural-image pre-trained models and industrial equipment by fine-tuning a Stable Diffusion backbone using DreamBooth-style knowledge embedding. This process encodes the unique structural and textural priors of substation meters, ensuring generated images retain authentic meter characteristics. Second, we introduce a geometric crack modeling module that parameterizes defect attributes--such as location, length, curvature, and branching pattern--to produce spatially constrained control maps. These maps provide precise, pixel-level guidance during generation. Third, we design a lightweight hypernetwork that dynamically modulates the denoising process of the diffusion model in response to the control maps and high-level defect descriptors, achieving a flexible balance between generation fidelity and controllability. Extensive experiments on a real-world substation meter dataset demonstrate that our method substantially outperforms existing augmentation and generation baselines. It reduces Frechet Inception Distance (FID) by 32.7%, increases diversity metrics, and--most importantly--boosts the mAP of a downstream defect detector by 15.3% when trained on augmented data. The framework offers a practical, high-quality data synthesis solution for industrial inspection systems where defect samples are rare.", "AI": {"tldr": "论文提出了一种结合知识嵌入和超网络指导的少样本变电站仪表缺陷图像生成方法。", "motivation": "由于标注样本稀缺，变电站仪表检测裂纹和其他物理缺陷的能力受到限制。该研究旨在解决这一少样本生成挑战，通过合成真实且可控的缺陷图像来辅助训练工业设备检测系统。", "method": "论文提出的方法包括：使用DreamBooth风格的知识嵌入对预训练模型进行微调以缩小领域差距；设计几何裂纹建模模块参数化缺陷属性并生成空间约束控制图；采用轻量级超网络动态调节扩散过程，实现生成的精确可控。", "result": "实验结果显示该方法在变电站仪表数据集上显著优于现有增强和生成基线。减少了32.7%的Frechet Inception Distance (FID)，增加了多样性指标，并提高了15.3%的下游缺陷检测器mAP。", "conclusion": "论文提出的方法为工业检测系统提供了一个实用且高质量的数据合成解决方案，特别是在缺陷样本稀少的情况下。"}}
{"id": "2601.09236", "pdf": "https://arxiv.org/pdf/2601.09236", "abs": "https://arxiv.org/abs/2601.09236", "authors": ["Chaitanya Kharyal", "Calarina Muslimani", "Matthew E. Taylor"], "title": "Reward Learning through Ranking Mean Squared Error", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reward design remains a significant bottleneck in applying reinforcement learning (RL) to real-world problems. A popular alternative is reward learning, where reward functions are inferred from human feedback rather than manually specified. Recent work has proposed learning reward functions from human feedback in the form of ratings, rather than traditional binary preferences, enabling richer and potentially less cognitively demanding supervision. Building on this paradigm, we introduce a new rating-based RL method, Ranked Return Regression for RL (R4). At its core, R4 employs a novel ranking mean squared error (rMSE) loss, which treats teacher-provided ratings as ordinal targets. Our approach learns from a dataset of trajectory-rating pairs, where each trajectory is labeled with a discrete rating (e.g., \"bad,\" \"neutral,\" \"good\"). At each training step, we sample a set of trajectories, predict their returns, and rank them using a differentiable sorting operator (soft ranks). We then optimize a mean squared error loss between the resulting soft ranks and the teacher's ratings. Unlike prior rating-based approaches, R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, we demonstrate that R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks from OpenAI Gym and the DeepMind Control Suite, while requiring significantly less feedback.", "AI": {"tldr": "本文介绍了一种新的基于评级的强化学习方法Ranked Return Regression for RL（R4），通过使用排序均方误差(rMSE)损失，从人类提供的轨迹评级数据中学习奖励函数。", "motivation": "奖励设计在将强化学习应用于实际问题时是一个主要瓶颈。为了解决这个问题，提出了奖励学习方法，这种方法是通过从人的反馈而非手动指定来推断奖励函数的。", "method": "R4方法的核心是一个新颖的排序均方误差（rMSE）损失函数，该函数对待教师提供的评级作为序数目标，并使用可微分排序算子预测轨迹的回报并进行排名。", "result": "实验表明，R4在OpenAI Gym和DeepMind Control Suite上的机器人运动基准测试中表现稳定且优于现有的基于评分和偏好的强化学习方法，同时需要的人类反馈更少。", "conclusion": "通过使用排序均方误差损失函数并提供形式化的保证，R4证明了其作为一种有效的方法可以从人类提供的评级数据中有效地学习奖励函数。"}}
{"id": "2601.09233", "pdf": "https://arxiv.org/pdf/2601.09233", "abs": "https://arxiv.org/abs/2601.09233", "authors": ["Zhengyang Zhao", "Lu Ma", "Yizhen Jiang", "Xiaochen Ma", "Zimo Meng", "Chengyu Shen", "Lexiang Tang", "Haoze Sun", "Peng Pei", "Wentao Zhang"], "title": "GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The prevailing post-training paradigm for Large Reasoning Models (LRMs)--Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL)--suffers from an intrinsic optimization mismatch: the rigid supervision inherent in SFT induces distributional collapse, thereby exhausting the exploration space necessary for subsequent RL. In this paper, we reformulate SFT within a unified post-training framework and propose Gibbs Initialization with Finite Temperature (GIFT). We characterize standard SFT as a degenerate zero-temperature limit that suppresses base priors. Conversely, GIFT incorporates supervision as a finite-temperature energy potential, establishing a distributional bridge that ensures objective consistency throughout the post-training pipeline. Our experiments demonstrate that GIFT significantly outperforms standard SFT and other competitive baselines when utilized for RL initialization, providing a mathematically principled pathway toward achieving global optimality in post-training. Our code is available at https://github.com/zzy1127/GIFT.", "AI": {"tldr": "本文提出了GIFT方法，通过有限温度的吉布斯初始化解决了现有大型推理模型（LRM）后训练范式中的优化不匹配问题。", "motivation": "现有的大型推理模型的后训练方法在监督微调(SFT)和强化学习(RL)之间存在优化上的固有不一致，SFT的刚性监督导致分布坍缩，限制了后续RL所需的探索空间。", "method": "GIFT将标准SFT视为零温度极限下的退化形式，并通过有限温度能量势引入监督信息，以保持后训练流程中的目标一致性。", "result": "实验结果表明，与传统的SFT和其他基线方法相比，使用GIFT作为RL初始化时表现显著提高。", "conclusion": "GIFT提供了一条实现后训练中全局最优的数学原理路径，并在实践中验证了其有效性。"}}
{"id": "2601.09231", "pdf": "https://arxiv.org/pdf/2601.09231", "abs": "https://arxiv.org/abs/2601.09231", "authors": ["Shuoye Li", "Zhiyuan Song", "Yulin Li", "Zhihai Bi", "Jun Ma"], "title": "Online Trajectory Optimization for Arbitrary-Shaped Mobile Robots via Polynomial Separating Hypersurfaces", "categories": ["cs.RO"], "comment": null, "summary": "An emerging class of trajectory optimization methods enforces collision avoidance by jointly optimizing the robot's configuration and a separating hyperplane. However, as linear separators only apply to convex sets, these methods require convex approximations of both the robot and obstacles, which becomes an overly conservative assumption in cluttered and narrow environments. In this work, we unequivocally remove this limitation by introducing nonlinear separating hypersurfaces parameterized by polynomial functions. We first generalize the classical separating hyperplane theorem and prove that any two disjoint bounded closed sets in Euclidean space can be separated by a polynomial hypersurface, serving as the theoretical foundation for nonlinear separation of arbitrary geometries. Building on this result, we formulate a nonlinear programming (NLP) problem that jointly optimizes the robot's trajectory and the coefficients of the separating polynomials, enabling geometry-aware collision avoidance without conservative convex simplifications. The optimization remains efficiently solvable using standard NLP solvers. Simulation and real-world experiments with nonconvex robots demonstrate that our method achieves smooth, collision-free, and agile maneuvers in environments where convex-approximation baselines fail.", "AI": {"tldr": "本文提出了使用多项式分离超曲面进行在线轨迹优化的方法，适用于任意形状的移动机器人。", "motivation": "现有的轨迹优化方法依赖于线性分隔器来避免碰撞，这需要对机器人和障碍物进行凸近似，在复杂环境中过于保守。", "method": "本文推广了经典的分离超平面定理，并证明任何两个不相交的有界闭集可以通过多项式超曲面分离。通过非线性规划（NLP）问题同时优化机器人的轨迹和分离多项式的系数，实现无保守凸简化的几何感知碰撞避免。", "result": "仿真和实际实验表明，本文的方法可以在复杂环境中实现平滑、避碰且敏捷的运动，而传统的凸近似方法无法达到这一效果。", "conclusion": "使用多项式分离超曲面进行轨迹优化能够有效处理非凸机器人在复杂环境中的碰撞避免问题。"}}
{"id": "2601.09230", "pdf": "https://arxiv.org/pdf/2601.09230", "abs": "https://arxiv.org/abs/2601.09230", "authors": ["Haodi Yao", "Fenghua He", "Ning Hao", "Yao Su"], "title": "CLIDD: Cross-Layer Independent Deformable Description for Efficient and Discriminative Local Feature Representation", "categories": ["cs.CV"], "comment": null, "summary": "Robust local feature representations are essential for spatial intelligence tasks such as robot navigation and augmented reality. Establishing reliable correspondences requires descriptors that provide both high discriminative power and computational efficiency. To address this, we introduce Cross-Layer Independent Deformable Description (CLIDD), a method that achieves superior distinctiveness by sampling directly from independent feature hierarchies. This approach utilizes learnable offsets to capture fine-grained structural details across scales while bypassing the computational burden of unified dense representations. To ensure real-time performance, we implement a hardware-aware kernel fusion strategy that maximizes inference throughput. Furthermore, we develop a scalable framework that integrates lightweight architectures with a training protocol leveraging both metric learning and knowledge distillation. This scheme generates a wide spectrum of model variants optimized for diverse deployment constraints. Extensive evaluations demonstrate that our approach achieves superior matching accuracy and exceptional computational efficiency simultaneously. Specifically, the ultra-compact variant matches the precision of SuperPoint while utilizing only 0.004M parameters, achieving a 99.7% reduction in model size. Furthermore, our high-performance configuration outperforms all current state-of-the-art methods, including high-capacity DINOv2-based frameworks, while exceeding 200 FPS on edge devices. These results demonstrate that CLIDD delivers high-precision local feature matching with minimal computational overhead, providing a robust and scalable solution for real-time spatial intelligence tasks.", "AI": {"tldr": "介绍了一种名为CLIDD的方法，用于高效且区分性强的局部特征表示。", "motivation": "为了提高机器人导航和增强现实等任务中的空间智能能力，需要既能提供高辨识度又能计算效率高的描述符。", "method": "CLIDD通过从独立特征层次中直接采样并使用可学习偏移捕捉多尺度细节来实现高效的局部特征表示，并采用硬件感知的内核融合策略以确保实时性能。", "result": "实验表明，该方法实现了高精度匹配和卓越计算效率。超紧凑型变体与SuperPoint相比，参数减少了99.7%，而高性能配置在边缘设备上超过200FPS的同时超过了当前最先进的方法。", "conclusion": "CLIDD提供了一种精确且计算开销小的局部特征匹配解决方案，适用于实时空间智能任务。"}}
{"id": "2601.09229", "pdf": "https://arxiv.org/pdf/2601.09229", "abs": "https://arxiv.org/abs/2601.09229", "authors": ["Ravi Shankar Prasad", "Dinesh Singh"], "title": "SPOT-Face: Forensic Face Identification using Attention Guided Optimal Transport", "categories": ["cs.CV"], "comment": "14 pages, 5 figures, 3 tables (ICPR_2026)", "summary": "Person identification in forensic investigations becomes very challenging when common identification means for DNA (i.e., hair strands, soft tissue) are not available. Current methods utilize deep learning methods for face recognition. However, these methods lack effective mechanisms to model cross-domain structural correspondence between two different forensic modalities. In this paper, we introduce a SPOT-Face, a superpixel graph-based framework designed for cross-domain forensic face identification of victims using their skeleton and sketch images. Our unified framework involves constructing a superpixel-based graph from an image and then using different graph neural networks(GNNs) backbones to extract the embeddings of these graphs, while cross-domain correspondence is established through attention-guided optimal transport mechanism. We have evaluated our proposed framework on two publicly available dataset: IIT\\_Mandi\\_S2F (S2F) and CUFS. Extensive experiments were conducted to evaluate our proposed framework. The experimental results show significant improvement in identification metrics ( i.e., Recall, mAP) over existing graph-based baselines. Furthermore, our framework demonstrates to be highly effective for matching skulls and sketches to faces in forensic investigations.", "AI": {"tldr": "介绍了一种用于跨域法医人脸识别的SPOT-Face框架，该框架利用超像素图和注意力引导最优传输机制。", "motivation": "现有的人脸识别方法在缺乏DNA的情况下难以进行有效的法医身份识别，且无法有效建模两个不同法医模式之间的跨域结构对应关系。", "method": "提出了一个基于超像素图的SPOT-Face框架，该框架通过不同的图形神经网络（GNNs）骨干来提取图像嵌入，并使用注意力引导最优传输机制建立跨域对应关系。", "result": "在两个公开数据集上进行了实验，结果显示识别指标（如召回率、mAP）有显著提高。", "conclusion": "该框架对匹配法医调查中的头骨和素描与人脸具有高度有效性。"}}
{"id": "2601.09228", "pdf": "https://arxiv.org/pdf/2601.09228", "abs": "https://arxiv.org/abs/2601.09228", "authors": ["Fan Liu", "Ting Wu", "Chuanyi Zhang", "Liang Yao", "Xing Ma", "Yuhui Zheng"], "title": "Disentangle Object and Non-object Infrared Features via Language Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Infrared object detection focuses on identifying and locating objects in complex environments (\\eg, dark, snow, and rain) where visible imaging cameras are disabled by poor illumination. However, due to low contrast and weak edge information in infrared images, it is challenging to extract discriminative object features for robust detection. To deal with this issue, we propose a novel vision-language representation learning paradigm for infrared object detection. An additional textual supervision with rich semantic information is explored to guide the disentanglement of object and non-object features. Specifically, we propose a Semantic Feature Alignment (SFA) module to align the object features with the corresponding text features. Furthermore, we develop an Object Feature Disentanglement (OFD) module that disentangles text-aligned object features and non-object features by minimizing their correlation. Finally, the disentangled object features are entered into the detection head. In this manner, the detection performance can be remarkably enhanced via more discriminative and less noisy features. Extensive experimental results demonstrate that our approach achieves superior performance on two benchmarks: M\\textsuperscript{3}FD (83.7\\% mAP), FLIR (86.1\\% mAP). Our code will be publicly available once the paper is accepted.", "AI": {"tldr": "该研究提出了一种新的视觉语言表示学习范式，用于红外物体检测，通过语义特征对齐和对象特征解缠模块提高检测性能。", "motivation": "由于红外图像中对比度低、边缘信息弱，提取具有区分性的对象特征进行稳健的检测十分困难。为此研究提出了一种新的方法来解决这一问题。", "method": "提出了一个语义特征对齐(SFA)模块和对象特征解缠(OFD)模块，分别用于对齐文本与图像中的物体特征，并通过最小化相关性来分离出非物体的特征。", "result": "实验结果表明，在M^3FD和FLIR两个基准数据集上，该方法实现了优异的表现，mAP分别为83.7%和86.1%。", "conclusion": "引入语言指导下的语义信息可以有效提升红外物体检测的性能，并减少噪声特征的影响。"}}
{"id": "2601.09213", "pdf": "https://arxiv.org/pdf/2601.09213", "abs": "https://arxiv.org/abs/2601.09213", "authors": ["Jialu Li", "Taiyan Zhou"], "title": "SpikeVAEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-VAE and Versatile Diffusion", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint", "summary": "Reconstructing natural visual scenes from neural activity is a key challenge in neuroscience and computer vision. We present SpikeVAEDiff, a novel two-stage framework that combines a Very Deep Variational Autoencoder (VDVAE) and the Versatile Diffusion model to generate high-resolution and semantically meaningful image reconstructions from neural spike data. In the first stage, VDVAE produces low-resolution preliminary reconstructions by mapping neural spike signals to latent representations. In the second stage, regression models map neural spike signals to CLIP-Vision and CLIP-Text features, enabling Versatile Diffusion to refine the images via image-to-image generation. We evaluate our approach on the Allen Visual Coding-Neuropixels dataset and analyze different brain regions. Our results show that the VISI region exhibits the most prominent activation and plays a key role in reconstruction quality. We present both successful and unsuccessful reconstruction examples, reflecting the challenges of decoding neural activity. Compared with fMRI-based approaches, spike data provides superior temporal and spatial resolution. We further validate the effectiveness of the VDVAE model and conduct ablation studies demonstrating that data from specific brain regions significantly enhances reconstruction performance.", "AI": {"tldr": "本文提出了SpikeVAEDiff，一个结合Very Deep Variational Autoencoder (VDVAE) 和Versatile Diffusion模型的两阶段框架，用于从神经脉冲数据中重建自然视觉场景。", "motivation": "研究旨在解决神经科学和计算机视觉领域中的关键挑战——即如何从神经活动中重构出高分辨率且语义丰富的自然视觉场景。", "method": "SpikeVAEDiff分为两个阶段：第一阶段使用VDVAE将神经脉冲信号映射到潜在表示，生成初步的低分辨率重建；第二阶段通过回归模型将神经脉冲信号与CLIP-Vision和CLIP-Text特征进行关联，利用Versatile Diffusion进一步细化图像。", "result": "在Allen Visual Coding-Neuropixels数据集上评估了该方法，并分析了不同脑区的性能。实验结果显示VISI区域表现出最明显的激活并影响重建质量。研究还对比了基于fMRI的方法，证实了神经脉冲数据具有更高的时空分辨率。", "conclusion": "本文展示了SpikeVAEDiff在从神经活动重构自然视觉场景方面的有效性，并通过消融实验验证了来自特定脑区的数据能显著提高重建性能，同时也反映了解码神经活动的复杂性和挑战性。"}}
{"id": "2601.09212", "pdf": "https://arxiv.org/pdf/2601.09212", "abs": "https://arxiv.org/abs/2601.09212", "authors": ["Xingyao Li", "Fengzhuo Zhang", "Cunxiao Du", "Hui Ji"], "title": "Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to AAAI 2026", "summary": "Despite significant progress in autoregressive image generation, inference remains slow due to the sequential nature of AR models and the ambiguity of image tokens, even when using speculative decoding. Recent works attempt to address this with relaxed speculative decoding but lack theoretical grounding. In this paper, we establish the theoretical basis of relaxed SD and propose COOL-SD, an annealed relaxation of speculative decoding built on two key insights. The first analyzes the total variation (TV) distance between the target model and relaxed speculative decoding and yields an optimal resampling distribution that minimizes an upper bound of the distance. The second uses perturbation analysis to reveal an annealing behaviour in relaxed speculative decoding, motivating our annealed design. Together, these insights enable COOL-SD to generate images faster with comparable quality, or achieve better quality at similar latency. Experiments validate the effectiveness of COOL-SD, showing consistent improvements over prior methods in speed-quality trade-offs.", "AI": {"tldr": "本文提出了COOL-SD，一种基于退火放松的投机性解码方法，旨在加速自回归图像生成。", "motivation": "尽管在自回归图像生成方面取得了显著进展，但由于模型顺序性和图像标记的模糊性，推理过程依然缓慢。现有方法尝试通过放松投机性解码来解决这个问题，但缺乏理论基础。", "method": "COOL-SD基于两个关键见解：一是分析了目标模型与放松投机性解码之间的总变差距离，并找到了一个最小化该距离上界的最优重采样分布；二是使用扰动分析揭示了放松投机性解码中的退火行为，这启发了其设计。", "result": "实验验证了COOL-SD的有效性，显示在速度和质量的权衡中持续优于先前方法。", "conclusion": "COOL-SD能够以更快的速度生成图像并保持相当的质量，或在类似延迟下获得更好的质量。"}}
{"id": "2601.09211", "pdf": "https://arxiv.org/pdf/2601.09211", "abs": "https://arxiv.org/abs/2601.09211", "authors": ["Chunghyun Park", "Seunghyeon Lee", "Minsu Cho"], "title": "Affostruction: 3D Affordance Grounding with Generative Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "This paper addresses the problem of affordance grounding from RGBD images of an object, which aims to localize surface regions corresponding to a text query that describes an action on the object. While existing methods predict affordance regions only on visible surfaces, we propose Affostruction, a generative framework that reconstructs complete geometry from partial observations and grounds affordances on the full shape including unobserved regions. We make three core contributions: generative multi-view reconstruction via sparse voxel fusion that extrapolates unseen geometry while maintaining constant token complexity, flow-based affordance grounding that captures inherent ambiguity in affordance distributions, and affordance-driven active view selection that leverages predicted affordances for intelligent viewpoint sampling. Affostruction achieves 19.1 aIoU on affordance grounding (40.4\\% improvement) and 32.67 IoU for 3D reconstruction (67.7\\% improvement), enabling accurate affordance prediction on complete shapes.", "AI": {"tldr": "本文提出了Affostruction框架，用于从RGBD图像中对物体的可用性进行定位，并在完整形状（包括未观察到的区域）上实现准确预测。", "motivation": "现有的方法仅在可见表面上预测可用性区域，而本文希望通过引入一个生成模型来重建完整的几何结构，从而提高预测准确性并涵盖不可见区域。", "method": "Affostruction使用稀疏体素融合进行多视图生成重建，通过流式建模捕捉可用性的内在歧义，并利用预测的可用性驱动智能视角采样以实现有效观察。", "result": "实验结果显示，Affostruction在可用性定位上取得了19.1 aIoU（40.4%提升），3D重建达到了32.67 IoU（67.7%提升）。", "conclusion": "该研究证明了通过生成完整几何结构并进行有效视角采样，可以实现对物体可用性的更准确和全面的预测。"}}
{"id": "2601.09209", "pdf": "https://arxiv.org/pdf/2601.09209", "abs": "https://arxiv.org/abs/2601.09209", "authors": ["Qiang Hu", "Qimei Wang", "Yingjie Guo", "Qiang Li", "Zhiwei Wang"], "title": "Pairing-free Group-level Knowledge Distillation for Robust Gastrointestinal Lesion Classification in White-Light Endoscopy", "categories": ["cs.CV"], "comment": "Accepted to AAAI 2026", "summary": "White-Light Imaging (WLI) is the standard for endoscopic cancer screening, but Narrow-Band Imaging (NBI) offers superior diagnostic details. A key challenge is transferring knowledge from NBI to enhance WLI-only models, yet existing methods are critically hampered by their reliance on paired NBI-WLI images of the same lesion, a costly and often impractical requirement that leaves vast amounts of clinical data untapped. In this paper, we break this paradigm by introducing PaGKD, a novel Pairing-free Group-level Knowledge Distillation framework that that enables effective cross-modal learning using unpaired WLI and NBI data. Instead of forcing alignment between individual, often semantically mismatched image instances, PaGKD operates at the group level to distill more complete and compatible knowledge across modalities. Central to PaGKD are two complementary modules: (1) Group-level Prototype Distillation (GKD-Pro) distills compact group representations by extracting modality-invariant semantic prototypes via shared lesion-aware queries; (2) Group-level Dense Distillation (GKD-Den) performs dense cross-modal alignment by guiding group-aware attention with activation-derived relation maps. Together, these modules enforce global semantic consistency and local structural coherence without requiring image-level correspondence. Extensive experiments on four clinical datasets demonstrate that PaGKD consistently and significantly outperforms state-of-the-art methods, achieving relative AUC improvements of 3.3%, 1.1%, 2.8%, and 3.2%, respectively, establishing a new direction for cross-modal learning from unpaired data.", "AI": {"tldr": "本文提出了一种无配对的组级知识蒸馏框架PaGKD，用于提高白光内镜下胃肠病变分类的准确性。", "motivation": "现有的方法依赖于同一病灶的窄带成像（NBI）和白光成像（WLI）图像配对，成本高昂且难以实现。本文旨在解决这个问题，通过使用无配对的数据来增强知识传递。", "method": "PaGKD框架包含两个互补模块：组级原型蒸馏（GKD-Pro）提取模态不变的语义原型；组级密集蒸馏（GKD-Den）执行密集跨模态对齐。这些模块在不依赖图像级别的对应关系的情况下，确保全局语义一致性与局部结构连贯性。", "result": "实验结果表明，PaGKD在四个临床数据集上分别实现了相对AUC提升3.3%，1.1%，2.8%和3.2%，显著优于现有方法。", "conclusion": "本文提出的方法为从无配对数据进行跨模态学习开辟了新的方向，并证明了其有效性。"}}
{"id": "2601.09208", "pdf": "https://arxiv.org/pdf/2601.09208", "abs": "https://arxiv.org/abs/2601.09208", "authors": ["Miki Ueno"], "title": "Mikasa: A Character-Driven Emotional AI Companion Inspired by Japanese Oshi Culture", "categories": ["cs.HC", "cs.AI"], "comment": "11 pages, 1 figure", "summary": "Recent progress in large language models and multimodal interaction has made it possible to develop AI companions that can have fluent and emotionally expressive conversations. However, many of these systems have problems keeping users satisfied and engaged over long periods. This paper argues that these problems do not come mainly from weak models, but from poor character design and unclear definitions of the user-AI relationship. I present Mikasa, an emotional AI companion inspired by Japanese Oshi culture-specifically its emphasis on long-term, non-exclusive commitment to a stable character-as a case study of character-driven companion design. Mikasa does not work as a general-purpose assistant or a chatbot that changes roles. Instead, Mikasa is designed as a coherent character with a stable personality and a clearly defined relationship as a partner. This relationship does not force exclusivity or obligation. Rather, it works as a reference point that stabilizes interaction norms and reduces the work users must do to keep redefining the relationship. Through an exploratory evaluation, I see that users describe their preferences using surface-level qualities such as conversational naturalness, but they also value relationship control and imaginative engagement in ways they do not state directly. These results suggest that character coherence and relationship definition work as latent structural elements that shape how good the interaction feels, without users recognizing them as main features. The contribution of this work is to show that character design is a functional part of AI companion systems, not just decoration. Mikasa is one example based on a specific cultural context, but the design principles-commitment to a consistent personality and clear relationship definition-can be used for many emotionally grounded AI companions.", "AI": {"tldr": "本文介绍了Mikasa，一个以日本Oshi文化为灵感的情感AI伴侣，旨在展示角色设计对于用户长期满意度和参与度的重要性。", "motivation": "作者认为现有AI伴随时常无法长时间保持用户的满意与参与感，主要问题在于角色设计不佳和用户与AI关系定义不清，而非模型性能不足。", "method": "通过构建Mikasa作为案例研究，一个具有稳定个性且明确定义为伙伴关系的AI伴侣，而不是多用途助手或聊天机器人。使用探索性评估方法来评价。", "result": "用户的反馈表明他们不仅在意对话自然度等表面品质，同时也重视关系控制和想象力参与，即使这些需求没有直接陈述出来。", "conclusion": "角色设计是情感化AI伴侣系统的重要功能部分而非装饰，并展示了基于一致性格和个人关系定义的设计原则可以广泛应用。"}}
{"id": "2601.09207", "pdf": "https://arxiv.org/pdf/2601.09207", "abs": "https://arxiv.org/abs/2601.09207", "authors": ["Bahar Khodabakhshian", "Nima Hashemi", "Armin Saadat", "Zahra Gholami", "In-Chang Hwang", "Samira Sojoudi", "Christina Luong", "Purang Abolmaesumi", "Teresa Tsang"], "title": "Point Tracking as a Temporal Cue for Robust Myocardial Segmentation in Echocardiography Videos", "categories": ["cs.CV"], "comment": null, "summary": "Purpose: Myocardium segmentation in echocardiography videos is a challenging task due to low contrast, noise, and anatomical variability. Traditional deep learning models either process frames independently, ignoring temporal information, or rely on memory-based feature propagation, which accumulates error over time. Methods: We propose Point-Seg, a transformer-based segmentation framework that integrates point tracking as a temporal cue to ensure stable and consistent segmentation of myocardium across frames. Our method leverages a point-tracking module trained on a synthetic echocardiography dataset to track key anatomical landmarks across video sequences. These tracked trajectories provide an explicit motion-aware signal that guides segmentation, reducing drift and eliminating the need for memory-based feature accumulation. Additionally, we incorporate a temporal smoothing loss to further enhance temporal consistency across frames. Results: We evaluate our approach on both public and private echocardiography datasets. Experimental results demonstrate that Point-Seg has statistically similar accuracy in terms of Dice to state-of-the-art segmentation models in high quality echo data, while it achieves better segmentation accuracy in lower quality echo with improved temporal stability. Furthermore, Point-Seg has the key advantage of pixel-level myocardium motion information as opposed to other segmentation methods. Such information is essential in the computation of other downstream tasks such as myocardial strain measurement and regional wall motion abnormality detection. Conclusion: Point-Seg demonstrates that point tracking can serve as an effective temporal cue for consistent video segmentation, offering a reliable and generalizable approach for myocardium segmentation in echocardiography videos. The code is available at https://github.com/DeepRCL/PointSeg.", "AI": {"tldr": "本文提出了Point-Seg，一种基于转换器的分割框架，利用点追踪作为时间线索来确保心脏超声视频中心肌分割的一致性和稳定性。", "motivation": "由于低对比度、噪声和解剖变异性的存在，心脏超声视频中心肌分割是一个具有挑战性的问题。传统的深度学习模型要么独立处理帧而不考虑时间信息，要么依赖于累积错误的记忆特征传播。", "method": "Point-Seg框架通过一个训练在合成心脏超声数据集上的点追踪模块来跟踪关键解剖标志物的轨迹，这些被追踪的轨迹作为运动感知信号来指导分割过程，并引入了时间平滑损失以增强帧间的时间一致性。", "result": "实验结果表明，在高质量和低质量的心脏超声数据上，Point-Seg在Dice系数方面与最先进的分割模型具有相似或更高的准确性。此外，它还提供了像素级心肌运动信息，这对其他下游任务如心肌应变测量及区域壁运动异常检测至关重要。", "conclusion": "研究表明点追踪可以作为有效的时间线索用于视频的持续分割，在心脏超声视频中心肌分割方面提供了一个可靠且通用的方法。"}}
{"id": "2601.09200", "pdf": "https://arxiv.org/pdf/2601.09200", "abs": "https://arxiv.org/abs/2601.09200", "authors": ["Sung Jun Cheon", "Jaekyung Cho", "Seongho Choi", "Hyunjun Eun", "Seokhwan Jo", "Jaehyun Jun", "Minsoo Kang", "Jin Kim", "Jiwon Kim", "Minsang Kim", "Sungwan Kim", "Seungsik Kim", "Tae Yoon Kim", "Youngrang Kim", "Hyeongmun Lee", "Sangyeol Lee", "Sungeun Lee", "Youngsoon Lee", "Yujin Lee", "Seongmin Ok", "Chanyong Park", "Hyewoong Park", "Junyoung Park", "Hyunho Yang", "Subin Yi", "et al. (35 additional authors not shown)"], "title": "A.X K1 Technical Report", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce A.X K1, a 519B-parameter Mixture-of-Experts (MoE) language model trained from scratch. Our design leverages scaling laws to optimize training configurations and vocabulary size under fixed computational budgets. A.X K1 is pre-trained on a corpus of approximately 10T tokens, curated by a multi-stage data processing pipeline. Designed to bridge the gap between reasoning capability and inference efficiency, A.X K1 supports explicitly controllable reasoning to facilitate scalable deployment across diverse real-world scenarios. We propose a simple yet effective Think-Fusion training recipe, enabling user-controlled switching between thinking and non-thinking modes within a single unified model. Extensive evaluations demonstrate that A.X K1 achieves performance competitive with leading open-source models, while establishing a distinctive advantage in Korean-language benchmarks.", "AI": {"tldr": "介绍了一种名为A.X K1的519B参数混合专家语言模型，并展示了其在韩语基准测试中的优势。", "motivation": "旨在优化训练配置和词汇表大小，同时提高推理效率，在保持竞争力性能的同时特别关注韩语表现。", "method": "通过Think-Fusion训练配方实现用户控制的思维模式切换，模型基于固定计算预算下的缩放规律进行设计，并在大约10T标记的精心处理数据集上进行预训练。", "result": "A.X K1在性能方面与领先的开源模型相当，在韩语基准测试中表现出显著优势。", "conclusion": "展示了A.X K1通过用户控制的推理模式实现了高效和可扩展的应用部署，并且在特定语言（如韩语）上具有明显的优势。"}}
{"id": "2601.09195", "pdf": "https://arxiv.org/pdf/2601.09195", "abs": "https://arxiv.org/abs/2601.09195", "authors": ["Tao Liu", "Taiqiang Wu", "Runming Yang", "Shaoning Sun", "Junjie Wang", "Yujiu Yang"], "title": "ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Supervised fine-tuning (SFT) is a fundamental post-training strategy to align Large Language Models (LLMs) with human intent. However, traditional SFT often ignores the one-to-many nature of language by forcing alignment with a single reference answer, leading to the model overfitting to non-core expressions. Although our empirical analysis suggests that introducing multiple reference answers can mitigate this issue, the prohibitive data and computational costs necessitate a strategic shift: prioritizing the mitigation of single-reference overfitting over the costly pursuit of answer diversity. To achieve this, we reveal the intrinsic connection between token probability and semantic importance: high-probability tokens carry the core logical framework, while low-probability tokens are mostly replaceable expressions. Based on this insight, we propose ProFit, which selectively masks low-probability tokens to prevent surface-level overfitting. Extensive experiments confirm that ProFit consistently outperforms traditional SFT baselines on general reasoning and mathematical benchmarks.", "AI": {"tldr": "该论文提出了ProFit方法，通过概率引导的令牌选择来解决传统SFT中单参考答案导致的语言模型过度拟合的问题。", "motivation": "传统的监督微调（SFT）策略往往忽略了一对多的语言特性，并迫使模型与单一参考答案对齐，这会导致非核心表达式的过度拟合。尽管引入多个参考答案可以缓解这个问题，但成本高昂，因此需要一种更有效的方法来减少单个参考答案造成的过度拟合。", "method": "ProFit方法基于令牌概率与其语义重要性之间的内在联系：高概率的令牌承载着核心逻辑框架，而低概率的令牌大多是可替代的表达。通过选择性地屏蔽低概率令牌以防止表面级别的过度拟合来实现这一点。", "result": "广泛的实验表明，在通用推理和数学基准测试中，ProFit方法始终优于传统的SFT基线。", "conclusion": "研究表明，通过使用高价值信号并利用概率引导的令牌选择策略，可以有效地减少语言模型在微调过程中的过度拟合问题。"}}
{"id": "2601.09191", "pdf": "https://arxiv.org/pdf/2601.09191", "abs": "https://arxiv.org/abs/2601.09191", "authors": ["Qizhen Lan", "Aaron Choi", "Jun Ma", "Bo Wang", "Zhaogming Zhao", "Xiaoqian Jiang", "Yu-Chun Hsu"], "title": "From Performance to Practice: Knowledge-Distilled Segmentator for On-Premises Clinical Workflows", "categories": ["cs.CV"], "comment": null, "summary": "Deploying medical image segmentation models in routine clinical workflows is often constrained by on-premises infrastructure, where computational resources are fixed and cloud-based inference may be restricted by governance and security policies. While high-capacity models achieve strong segmentation accuracy, their computational demands hinder practical deployment and long-term maintainability in hospital environments. We present a deployment-oriented framework that leverages knowledge distillation to translate a high-performing segmentation model into a scalable family of compact student models, without modifying the inference pipeline. The proposed approach preserves architectural compatibility with existing clinical systems while enabling systematic capacity reduction. The framework is evaluated on a multi-site brain MRI dataset comprising 1,104 3D volumes, with independent testing on 101 curated cases, and is further examined on abdominal CT to assess cross-modality generalizability. Under aggressive parameter reduction (94%), the distilled student model preserves nearly all of the teacher's segmentation accuracy (98.7%), while achieving substantial efficiency gains, including up to a 67% reduction in CPU inference latency without additional deployment overhead. These results demonstrate that knowledge distillation provides a practical and reliable pathway for converting research-grade segmentation models into maintainable, deployment-ready components for on-premises clinical workflows in real-world health systems.", "AI": {"tldr": "使用知识蒸馏技术，将高性能的医学图像分割模型转化为可部署的小型化学生模型，以适应医院环境中的计算资源限制。", "motivation": "在医疗环境中，由于计算资源固定和安全政策的约束，高性能的医学图像分割模型难以实际应用。因此，需要开发一种能够减少计算需求同时保持准确性的方法。", "method": "通过知识蒸馏技术将一个高性能的分割教师模型转化为一系列紧凑的学生模型，以适应医院环境中的基础设施限制，并且不改变现有的推理管道。", "result": "在参数缩减94%的情况下，学生模型保留了教师模型几乎全部的分割精度（98.7%），同时CPU推理延迟减少了67%，证明知识蒸馏是实现高性能模型向实际部署转换的有效途径。", "conclusion": "该研究展示了知识蒸馏技术能够提供一个实用且可靠的路径，将研究级别的分割模型转化为维护性好、可直接部署的组件，适用于现实世界的临床工作流。"}}
{"id": "2601.09182", "pdf": "https://arxiv.org/pdf/2601.09182", "abs": "https://arxiv.org/abs/2601.09182", "authors": ["JungMin Yun", "JuneHyoung Kwon", "MiHyeon Kim", "YoungBin Kim"], "title": "Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback", "categories": ["cs.AI", "cs.CY", "cs.HC"], "comment": "Accepted to AAAI 2026 Workshop on AI for Scientific Research (AI4Research)", "summary": "The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. We define the core principles of high-quality peer review and propose two complementary systems grounded in these foundations: (i) an LLM-assisted mentoring system that cultivates reviewers' long-term competencies, and (ii) an LLM-assisted feedback system that helps reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.", "AI": {"tldr": "论文提出通过LLM辅助的导师系统和反馈系统来解决审稿人缺口问题，提高同行评审的质量。", "motivation": "AI研究的迅速发展加剧了审稿人缺口，导致低质量评估循环。该论文认为现有的自动生成评论的LLM方法存在问题，并提倡将LLM作为教育人类审稿人的工具。", "method": "提出两个基于高质量同行评审原则的系统：一个是由LLM辅助的导师系统，培养审稿人的长期能力；另一个是LLM辅助的反馈系统，帮助审稿人提高评价质量。", "result": "通过这种方法可以加强审稿人的专业知识并建立更可持续的学术生态系统。", "conclusion": "建议将LLM作为教育工具而不是自动生成评论来改善同行评审过程，从而解决审稿人缺口问题。"}}
{"id": "2601.09178", "pdf": "https://arxiv.org/pdf/2601.09178", "abs": "https://arxiv.org/abs/2601.09178", "authors": ["Paul Brunzema", "Thomas Lew", "Ray Zhang", "Takeru Shirasawa", "John Subosits", "Marcus Greiff"], "title": "Vision-Conditioned Variational Bayesian Last Layer Dynamics Models", "categories": ["cs.RO"], "comment": "9 pages, 7 figures, currently under review", "summary": "Agile control of robotic systems often requires anticipating how the environment affects system behavior. For example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly. Achieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions. Traditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and may adapt too late to ensure safety. We propose a vision-conditioned variational Bayesian last-layer dynamics model that leverages visual context to anticipate changes in the environment. The model first learns nominal vehicle dynamics and is then fine-tuned with feature-wise affine transformations of latent features, enabling context-aware dynamics prediction. The resulting model is integrated into an optimal controller for vehicle racing. We validate our method on a Lexus LC500 racing through water puddles. With vision-conditioning, the system completed all 12 attempted laps under varying conditions. In contrast, all baselines without visual context consistently lost control, demonstrating the importance of proactive dynamics adaptation in high-performance applications.", "AI": {"tldr": "本文提出了一种基于视觉条件的变分贝叶斯最后一层动态模型，用于预测环境变化下的系统行为，并将其集成到赛车车辆的最优控制器中。", "motivation": "传统的建模方法难以捕捉系统的突然变化，而自适应方法则反应滞后，可能无法保证安全。因此，提出一种能够主动适应环境变化的方法是必要的。", "method": "该模型首先学习名义下的车辆动力学，并通过潜在特征的特性仿射变换进行微调，从而实现基于视觉上下文的动力学预测。", "result": "实验结果显示，在12次尝试中，带有视觉条件的系统成功完成所有圈数，而没有视觉上下文的基础线则频繁失控。", "conclusion": "该研究证明了在高性能应用场景下主动适应动力学变化的重要性。"}}
{"id": "2601.09170", "pdf": "https://arxiv.org/pdf/2601.09170", "abs": "https://arxiv.org/abs/2601.09170", "authors": ["Dung Ta Nguyen Duc", "Thanh Bui Dang", "Hoang Le Minh", "Tung Nguyen Viet", "Huong Nguyen Thanh", "Dong Trinh Cong"], "title": "N-EIoU-YOLOv9: A Signal-Aware Bounding Box Regression Loss for Lightweight Mobile Detection of Rice Leaf Diseases", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this work, we propose N EIoU YOLOv9, a lightweight detection framework based on a signal aware bounding box regression loss derived from non monotonic gradient focusing and geometric decoupling principles, referred to as N EIoU (Non monotonic Efficient Intersection over Union). The proposed loss reshapes localization gradients by combining non monotonic focusing with decoupled width and height optimization, thereby enhancing weak regression signals for hard samples with low overlap while reducing gradient interference. This design is particularly effective for small and low contrast targets commonly observed in agricultural disease imagery. The proposed N EIoU loss is integrated into a lightweight YOLOv9t architecture and evaluated on a self collected field dataset comprising 5908 rice leaf images across four disease categories and healthy leaves. Experimental results demonstrate consistent performance gains over the standard CIoU loss, achieving a mean Average Precision of 90.3 percent, corresponding to a 4.3 percent improvement over the baseline, with improved localization accuracy under stricter evaluation criteria. For practical validation, the optimized model is deployed on an Android device using TensorFlow Lite with Float16 quantization, achieving an average inference time of 156 milliseconds per frame while maintaining accuracy. These results confirm that the proposed approach effectively balances accuracy, optimization stability, and computational efficiency for edge based agricultural monitoring systems.", "AI": {"tldr": "本文提出了N-EIoU-YOLOv9，一种基于信号感知边界框回归损失的轻量级水稻叶片疾病检测框架。", "motivation": "动机在于解决农业图像中常见的小目标和低对比度目标的定位问题，提高弱回归信号的效果并减少梯度干扰。", "method": "提出了一种名为N-EIoU（非单调有效交并比）的新损失函数，通过结合非单调聚焦与解耦宽高优化来重塑定位梯度。", "result": "实验结果显示，该方法在自采集的包含5908张水稻叶片图像的数据集上相较于标准CIoU损失有4.3%的mAP提升，并实现了156毫秒每帧的推理时间。", "conclusion": "结论表明，提出的N-EIoU-YOLOv9能够平衡检测准确率、优化稳定性和计算效率，在边缘设备上的农业监测系统中表现出色。"}}
{"id": "2601.09169", "pdf": "https://arxiv.org/pdf/2601.09169", "abs": "https://arxiv.org/abs/2601.09169", "authors": ["Jamie Magrill", "Leah Gornstein", "Sandra Seekins", "Barry Magrill"], "title": "Architecture inside the mirage: evaluating generative image models on architectural style, elements, and typologies", "categories": ["cs.CV", "cs.CY"], "comment": "24 pages, 7 figures", "summary": "Generative artificial intelligence (GenAI) text-to-image systems are increasingly used to generate architectural imagery, yet their capacity to reproduce accurate images in a historically rule-bound field remains poorly characterized. We evaluated five widely used GenAI image platforms (Adobe Firefly, DALL-E 3, Google Imagen 3, Microsoft Image Generator, and Midjourney) using 30 architectural prompts spanning styles, typologies, and codified elements. Each prompt-generator pair produced four images (n = 600 images total). Two architectural historians independently scored each image for accuracy against predefined criteria, resolving disagreements by consensus. Set-level performance was summarized as zero to four accurate images per four-image set. Image output from Common prompts was 2.7-fold more accurate than from Rare prompts (p < 0.05). Across platforms, overall accuracy was limited (highest accuracy score 52 percent; lowest 32 percent; mean 42 percent). All-correct (4 out of 4) outcomes were similar across platforms. By contrast, all-incorrect (0 out of 4) outcomes varied substantially, with Imagen 3 exhibiting the fewest failures and Microsoft Image Generator exhibiting the highest number of failures. Qualitative review of the image dataset identified recurring patterns including over-embellishment, confusion between medieval styles and their later revivals, and misrepresentation of descriptive prompts (for example, egg-and-dart, banded column, pendentive). These findings support the need for visible labeling of GenAI synthetic content, provenance standards for future training datasets, and cautious educational use of GenAI architectural imagery.", "AI": {"tldr": "评估五个广泛使用的生成式人工智能图像平台在建筑风格、元素和类型上的表现。", "motivation": "尽管生成式人工智能文本到图像系统越来越多地用于创建建筑设计图，但其准确再现历史上有规则约束的建筑领域的能力尚未得到充分研究。", "method": "使用30个涵盖风格、类型和规范元素的建筑提示来评估五个平台，每个提示与生成器组合产生四个图像（共600张）。两位建筑历史学家独立评分，并通过共识解决分歧。以零到四分准确度为标准对结果进行总结。", "result": "常见提示下的图像是罕见提示下图像的2.7倍准确（p < 0.05）。各平台整体准确性有限，最高达52%，最低32%，平均42%。所有正确的（4/4）结果在各平台上相似，而全错的（0/4）结果差异大。", "conclusion": "研究发现支持对生成式人工智能合成内容进行可见标签化、制定未来训练数据集来源标准，并谨慎使用生成式人工智能建筑图像教育。"}}
{"id": "2601.09167", "pdf": "https://arxiv.org/pdf/2601.09167", "abs": "https://arxiv.org/abs/2601.09167", "authors": ["Sangam Balchandar Reddy", "Arun Kumar Das", "Anjeneya Swami Kare", "I. Vinod Reddy"], "title": "On the complexity of global Roman domination problem in graphs", "categories": ["math.CO", "cs.CC", "cs.DS"], "comment": "Submitted to Elsevier, 27 pages", "summary": "A Roman dominating function of a graph $G=(V,E)$ is a labeling $f: V \\rightarrow{} \\{0 ,1, 2\\}$ such that for each vertex $u \\in V$ with $f(u) = 0$, there exists a vertex $v \\in N(u)$ with $f(v) =2$. A Roman dominating function $f$ is a global Roman dominating function if it is a Roman dominating function for both $G$ and its complement $\\overline{G}$. The weight of $f$ is the sum of $f(u)$ over all the vertices $u \\in V$. The objective of Global Roman Domination problem is to find a global Roman dominating function with minimum weight. The objective of Global Roman Domination is to compute a global Roman dominating function of minimum weight. In this paper, we study the algorithmic aspects of Global Roman Domination problem on various graph classes and obtain the following results. 1. We prove that Roman domination and Global Roman Domination problems are not computationally equivalent by identifying graph classes on which one is linear-time solvable, while the other is NP-complete. 2. We show that Global Roman Domination problem is NP-complete on split graphs, thereby resolving an open question posed by Panda and Goyal [Discrete Applied Mathematics, 2023]. 3. We prove that Global Roman Domination problem is NP-complete on chordal bipartite graphs, planar bipartite graphs with maximum degree five and circle graphs. 4. On the positive side, we present a linear-time algorithm for Global Roman domination problem on cographs.", "AI": {"tldr": "本文研究了图中全局罗马支配问题的算法方面，并在不同类型的图形上获得了一些结果。", "motivation": "动机在于探索全局罗马支配问题在各种图类上的计算复杂性，以解决之前提出的一些开放性问题。", "method": "通过理论分析和设计特定算法来证明全局罗马支配问题在某些图类上的NP完全性和线性时间可解性。", "result": "1. 证明了罗马支配和全局罗马支配问题是不等价的计算问题。2. 在分裂图上解决了一个开放问题，证明全局罗马支配问题是NP完全的。3. 证明了全局罗马支配问题在弦双部图、平面双部图（最大度数为五）以及圆图上的NP完全性。4. 对于无圈图类提出了一种线性时间算法。", "conclusion": "本文探讨了全局罗马支配问题的计算复杂性，并确定了该问题在不同图类中的求解难度，解决了之前的一些开放性问题。"}}
{"id": "2601.09163", "pdf": "https://arxiv.org/pdf/2601.09163", "abs": "https://arxiv.org/abs/2601.09163", "authors": ["Tong Wu", "Shoujie Li", "Junhao Gong", "Changqing Guo", "Xingting Li", "Shilong Mu", "Wenbo Ding"], "title": "CEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space", "categories": ["cs.RO"], "comment": null, "summary": "Robotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\\CEI), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies. \\CEI introduces the concept of \\textit{functional similarity}, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments, \\CEI transfers data and policies from a Franka Panda robot to \\textbf{16} different embodiments across \\textbf{3} tasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across \\textbf{6} real-world tasks, achieving an average transfer ratio of 82.4\\%. Finally, we demonstrate that \\CEI can also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website: https://cross-embodiment-interface.github.io/", "AI": {"tldr": "介绍了一种统一接口CEI，用于在三维空间中跨不同机器人形态的视觉运动策略学习。", "motivation": "解决基础模型过度拟合特定视角、机械臂和并行夹爪的问题，通过引入功能相似性的概念实现跨身体形态的学习。", "method": "使用方向性Chamfer距离量化功能相似性，并通过对梯度优化对机器人轨迹进行对齐，合成新的观察值和动作以适应不同的机械臂和末端执行器。", "result": "CEI成功将数据和策略从Franka Panda机器人转移到了16种不同形态的机器人上，在3个模拟任务中展示了其能力。同时支持在现实世界中的双向转移，平均迁移比率为82.4%。", "conclusion": "CEI框架能够有效地跨身体形态进行学习，并且可以通过所提出的技巧扩展到空间泛化和多模态运动生成的能力。"}}
{"id": "2601.09156", "pdf": "https://arxiv.org/pdf/2601.09156", "abs": "https://arxiv.org/abs/2601.09156", "authors": ["Woojin Kim", "Changkwon Lee", "Hyeoncheol Kim"], "title": "KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual Explanations for Education", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "Accepted to AAAI-26 Special Track AI for Social Impact (oral presentation)", "summary": "Using Artificial Intelligence to improve teaching and learning benefits greater adaptivity and scalability in education. Knowledge Tracing (KT) is recognized for student modeling task due to its superior performance and application potential in education. To this end, we conceptualize and investigate counterfactual explanation as the connection from XAI for KT to education. Counterfactual explanations offer actionable recourse, are inherently causal and local, and easy for educational stakeholders to understand who are often non-experts. We propose KTCF, a counterfactual explanation generation method for KT that accounts for knowledge concept relationships, and a post-processing scheme that converts a counterfactual explanation into a sequence of educational instructions. We experiment on a large-scale educational dataset and show our KTCF method achieves superior and robust performance over existing methods, with improvements ranging from 5.7% to 34% across metrics. Additionally, we provide a qualitative evaluation of our post-processing scheme, demonstrating that the resulting educational instructions help in reducing large study burden. We show that counterfactuals have the potential to advance the responsible and practical use of AI in education. Future works on XAI for KT may benefit from educationally grounded conceptualization and developing stakeholder-centered methods.", "AI": {"tldr": "本文提出了KTCF，一种通过反事实解释为知识追踪提供操作性补救的方法，并展示了其在教育应用中的优越性和鲁棒性。", "motivation": "利用AI改善教学和学习可以提高教育的适应性和可扩展性。反事实解释能够提供因果关系、易于理解且适合非专家使用，因此研究者希望将其应用于知识追踪，以提升教育领域的实践效果。", "method": "KTCF方法用于生成针对知识追踪的反事实解释，并通过后处理方案将这些解释转换成一系列教育指令。该方法考虑了知识概念之间的关系。", "result": "实验显示，KTCF在大规模教育数据集上表现出优越且鲁棒的性能，相比于现有方法有5.7%到34%的提升。定性评估表明生成的教学指令有助于减轻学习负担。", "conclusion": "反事实解释具有推进AI在教育领域负责任和实用应用的潜力。未来的工作可以受益于以教育为基础的概念化和开发面向利益相关者的方法。"}}
{"id": "2601.09153", "pdf": "https://arxiv.org/pdf/2601.09153", "abs": "https://arxiv.org/abs/2601.09153", "authors": ["Josué Martínez-Martínez", "Olivia Brown", "Giselle Zeno", "Pooya Khorrami", "Rajmonda Caceres"], "title": "From Snow to Rain: Evaluating Robustness, Calibration, and Complexity of Model-Based Robust Training", "categories": ["cs.CV"], "comment": "11 pages", "summary": "Robustness to natural corruptions remains a critical challenge for reliable deep learning, particularly in safety-sensitive domains. We study a family of model-based training approaches that leverage a learned nuisance variation model to generate realistic corruptions, as well as new hybrid strategies that combine random coverage with adversarial refinement in nuisance space. Using the Challenging Unreal and Real Environments for Traffic Sign Recognition dataset (CURE-TSR), with Snow and Rain corruptions, we evaluate accuracy, calibration, and training complexity across corruption severities. Our results show that model-based methods consistently outperform baselines Vanilla, Adversarial Training, and AugMix baselines, with model-based adversarial training providing the strongest robustness under across all corruptions but at the expense of higher computation and model-based data augmentation achieving comparable robustness with $T$ less computational complexity without incurring a statistically significant drop in performance. These findings highlight the importance of learned nuisance models for capturing natural variability, and suggest a promising path toward more resilient and calibrated models under challenging conditions.", "AI": {"tldr": "研究了一组基于模型的训练方法，使用学习到的干扰变化模型生成实际的干扰，并结合混合策略来评估其鲁棒性、校准和复杂度。", "motivation": "提高深度学习对自然干扰的鲁棒性，特别是在安全敏感领域中的可靠性。", "method": "通过CURE-TSR数据集，在雪和雨两种扰动下使用基于模型的方法进行训练，并结合随机覆盖与对抗性优化策略。", "result": "结果显示，基于模型的方法在所有干扰情况下始终优于基线方法，并且具有较低的计算复杂度。", "conclusion": "学习到的干扰变化模型对于捕捉自然变异性非常重要，并提出了一条通往更稳健和校准良好的模型的道路。"}}
{"id": "2601.09152", "pdf": "https://arxiv.org/pdf/2601.09152", "abs": "https://arxiv.org/abs/2601.09152", "authors": ["Yiwen Tu", "Xuan Liu", "Lianhui Qin", "Haojian Jin"], "title": "PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces PRA, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PRA integrates privacy and cognitive theories to simulate user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user's \"privacy mind\", dynamically activates relevant privacy memory through a contextual filter that emulates bounded rationality, and generates synthetic comments reflecting how that user would likely respond to new privacy scenarios. A complementary LLM-as-a-Judge evaluator, calibrated against an established privacy concern taxonomy, quantifies the faithfulness of generated reasoning. Experiments on real-world Hacker News discussions show that \\PRA outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.", "AI": {"tldr": "介绍PRA，一个模拟个体用户如何根据真实新闻形成隐私担忧的AI代理设计。", "motivation": "超越人口层面的情感分析，旨在通过结合隐私和认知理论来模拟基于个人评论历史和个人情境线索的个性化隐私推理。", "method": "PRA通过上下文过滤器动态激活相关的隐私记忆来重建每个用户的“隐私思维”，并生成反映用户对新隐私场景可能反应的合成评论。同时使用了一个LLM作为评估者，量化生成推理的真实性。", "result": "实验显示，在真实世界的Hacker News讨论中，PRA在预测隐私担忧方面表现优于基线代理，并能捕捉跨AI、电子商务和医疗保健领域的可转移推理模式。", "conclusion": "证明了通过集成隐私理论和个人情境信息，人工智能能够更精准地模拟人类的隐私思考过程。"}}
{"id": "2601.09150", "pdf": "https://arxiv.org/pdf/2601.09150", "abs": "https://arxiv.org/abs/2601.09150", "authors": ["Jianwen Sun", "Yukang Feng", "Kaining Ying", "Chuanhao Li", "Zizhen Li", "Fanrui Zhang", "Jiaxin Ai", "Yifan Chang", "Yu Dai", "Yifei Huang", "Kaipeng Zhang"], "title": "World Craft: Agentic Framework to Create Visualizable Worlds via Text", "categories": ["cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) motivate generative agent simulation (e.g., AI Town) to create a ``dynamic world'', holding immense value across entertainment and research. However, for non-experts, especially those without programming skills, it isn't easy to customize a visualizable environment by themselves. In this paper, we introduce World Craft, an agentic world creation framework to create an executable and visualizable AI Town via user textual descriptions. It consists of two main modules, World Scaffold and World Guild. World Scaffold is a structured and concise standardization to develop interactive game scenes, serving as an efficient scaffolding for LLMs to customize an executable AI Town-like environment. World Guild is a multi-agent framework to progressively analyze users' intents from rough descriptions, and synthesizes required structured contents (\\eg environment layout and assets) for World Scaffold . Moreover, we construct a high-quality error-correction dataset via reverse engineering to enhance spatial knowledge and improve the stability and controllability of layout generation, while reporting multi-dimensional evaluation metrics for further analysis. Extensive experiments demonstrate that our framework significantly outperforms existing commercial code agents (Cursor and Antigravity) and LLMs (Qwen3 and Gemini-3-Pro). in scene construction and narrative intent conveyance, providing a scalable solution for the democratization of environment creation.", "AI": {"tldr": "本文介绍了World Craft，一个通过用户文本描述来创建可执行和可视化的AI Town样环境的代理框架。", "motivation": "大型语言模型（LLMs）激发了生成式代理模拟的发展，但非专家用户难以自行定制可视化环境。因此，提出了World Craft以解决这一问题，使其更易于普通人使用。", "method": "World Craft由两个主要模块组成：世界支架（World Scaffold）和世界公会（World Guild）。世界支架是一个结构化且简洁的标准框架，用于开发互动游戏场景；世界公会则作为一个多代理框架来逐步解析用户的粗糙描述，并合成所需的结构化内容。此外，通过反向工程构建了一个高质量的错误修正数据集以增强空间知识。", "result": "广泛的实验表明，该框架在场景构造和叙事意图传达方面显著优于现有的商业代码代理（如Cursor和Antigravity）及大型语言模型（如Qwen3和Gemini-3-Pro）。", "conclusion": "World Craft提供了一个可扩展的解决方案，有助于环境创建的普及化。"}}
{"id": "2601.09147", "pdf": "https://arxiv.org/pdf/2601.09147", "abs": "https://arxiv.org/abs/2601.09147", "authors": ["Chenhao Fu", "Han Fang", "Xiuzheng Zheng", "Wenbo Wei", "Yonghua Li", "Hao Sun", "Xuelong Li"], "title": "SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Zero-Shot Anomaly Detection (ZSAD) leverages Vision-Language Models (VLMs) to enable supervision-free industrial inspection. However, existing ZSAD paradigms are constrained by single visual backbones, which struggle to balance global semantic generalization with fine-grained structural discriminability. To bridge this gap, we propose Synergistic Semantic-Visual Prompting (SSVP), that efficiently fuses diverse visual encodings to elevate model's fine-grained perception. Specifically, SSVP introduces the Hierarchical Semantic-Visual Synergy (HSVS) mechanism, which deeply integrates DINOv3's multi-scale structural priors into the CLIP semantic space. Subsequently, the Vision-Conditioned Prompt Generator (VCPG) employs cross-modal attention to guide dynamic prompt generation, enabling linguistic queries to precisely anchor to specific anomaly patterns. Furthermore, to address the discrepancy between global scoring and local evidence, the Visual-Text Anomaly Mapper (VTAM) establishes a dual-gated calibration paradigm. Extensive evaluations on seven industrial benchmarks validate the robustness of our method; SSVP achieves state-of-the-art performance with 93.0\\% Image-AUROC and 92.2\\% Pixel-AUROC on MVTec-AD, significantly outperforming existing zero-shot approaches.", "AI": {"tldr": "本文提出了SSVP方法，通过融合多尺度视觉编码来改进工业零样本异常检测。", "motivation": "现有的零样本异常检测方法受限于单一的视觉骨干网络，难以在全局语义泛化和细粒度结构辨别之间取得平衡。为此，提出了一种新的方法来解决这个问题。", "method": "SSVP采用Hierarchical Semantic-Visual Synergy (HSVS)机制将DINOv3的多尺度结构先验融入CLIP的语义空间，并通过Vision-Conditioned Prompt Generator (VCPG)利用跨模态注意力生成动态提示。此外，Visual-Text Anomaly Mapper (VTAM)建立了一个双门限校准范式来解决全局评分与局部证据之间的差异。", "result": "在七个工业基准数据集上进行了广泛的评估，SSVP方法实现了93.0%的Image-AUROC和92.2%的Pixel-AUROC，在MVTec-AD上的表现超过了现有的零样本方法。", "conclusion": "SSVP通过融合多尺度视觉编码改进了工业零样本异常检测，并在多个基准数据集上取得了显著的效果。"}}
{"id": "2601.09139", "pdf": "https://arxiv.org/pdf/2601.09139", "abs": "https://arxiv.org/abs/2601.09139", "authors": ["Gramoz Goranci", "Monika Henzinger", "Peter Kiss", "Ali Momeni", "Gernot Zöcklein"], "title": "Dynamic Hierarchical $j$-Tree Decomposition and Its Applications", "categories": ["cs.DS"], "comment": "SODA 2026", "summary": "We develop a new algorithmic framework for designing approximation algorithms for cut-based optimization problems on capacitated undirected graphs that undergo edge insertions and deletions. Specifically, our framework dynamically maintains a variant of the hierarchical $j$-tree decomposition of [Madry FOCS'10], achieving a poly-logarithmic approximation factor to the graph's cut structure and supporting edge updates in $O(n^ε)$ amortized update time, for any arbitrarily small constant $ε\\in (0,1)$. Consequently, we obtain new trade-offs between approximation and update/query time for fundamental cut-based optimization problems in the fully dynamic setting, including all-pairs minimum cuts, sparsest cut, multi-way cut, and multi-cut. For the last three problems, these trade-offs give the first fully-dynamic algorithms achieving poly-logarithmic approximation in sub-linear time per operation. The main technical ingredient behind our dynamic hierarchy is a dynamic cut-sparsifier algorithm that can handle vertex splits with low recourse. This is achieved by white-boxing the dynamic cut sparsifier construction of [Abraham et al. FOCS'16], based on forest packing, together with new structural insights about the maintenance of these forests under vertex splits. Given the versatility of cut sparsification in both the static and dynamic graph algorithms literature, we believe this construction may be of independent interest.", "AI": {"tldr": "本文开发了一个新的算法框架，用于设计针对在具有容量的无向图中经历边插入和删除操作时切割优化问题的近似算法。", "motivation": "动机在于动态维护一种变体层次j树分解以实现对图切割结构的多对数近似因子，并支持边更新的时间效率提高，在完全动态设置下，为基本的基于切割优化问题提供新的时间和精度之间的权衡。", "method": "开发了一种可以处理顶点分裂并具有低回溯代价的动态切割简化算法，这通过分解Abraham等人提出的基于森林打包的动态切割简化的构造，并结合新发现的关于这些森林在顶点分裂下维护结构上的见解来实现。", "result": "获得了基本的基于切割优化问题如所有成对最小切割、最稀疏割、多路割和多重割之间新的近似度与更新/查询时间之间的权衡。特别是对于后三个问题，这是首次实现了每操作子线性时间内达到多项式对数近似的完全动态算法。", "conclusion": "由于切割简化的灵活性，在静态和动态图算法文献中，本文提出的方法可能具有独立的兴趣价值。"}}
{"id": "2601.09136", "pdf": "https://arxiv.org/pdf/2601.09136", "abs": "https://arxiv.org/abs/2601.09136", "authors": ["Lijun Liu", "Linwei Chen", "Zhishou Zhang", "Meng Tian", "Hengfu Cui", "Ruiyang Li", "Zhaocheng Liu", "Qiang Ju", "Qianxi Li", "Hong-Yu Zhou"], "title": "SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "General-purpose Large Vision-Language Models (LVLMs), despite their massive scale, often falter in dermatology due to \"diffuse attention\" - the inability to disentangle subtle pathological lesions from background noise. In this paper, we challenge the assumption that parameter scaling is the only path to medical precision. We introduce SkinFlow, a framework that treats diagnosis as an optimization of visual information transmission efficiency. Our approach utilizes a Virtual-Width Dynamic Vision Encoder (DVE) to \"unfold\" complex pathological manifolds without physical parameter expansion, coupled with a two-stage Reinforcement Learning strategy. This strategy sequentially aligns explicit medical descriptions (Stage I) and reconstructs implicit diagnostic textures (Stage II) within a constrained semantic space. Furthermore, we propose a clinically grounded evaluation protocol that prioritizes diagnostic safety and hierarchical relevance over rigid label matching. Empirical results are compelling: our 7B model establishes a new state-of-the-art on the Fitzpatrick17k benchmark, achieving a +12.06% gain in Top-1 accuracy and a +28.57% boost in Top-6 accuracy over the massive general-purpose models (e.g., Qwen3VL-235B and GPT-5.2). These findings demonstrate that optimizing geometric capacity and information flow yields superior diagnostic reasoning compared to raw parameter scaling.", "AI": {"tldr": "本文介绍了SkinFlow框架，通过优化视觉信息传递效率来改进皮肤科诊断。", "motivation": "现有大规模视觉语言模型在皮肤病诊断上存在“分散注意力”的问题，无法区分细微病变和背景噪音。因此，研究提出了一种新的方法来提高医学精度，而不仅仅是依靠参数的扩展。", "method": "SkinFlow框架使用虚拟宽度动态视觉编码器（DVE）展开复杂的病理结构，并采用两阶段强化学习策略：第一阶段对显性医疗描述进行校准，第二阶段重建隐性的诊断纹理。此外，提出了一个临床导向的评估协议，优先考虑诊断安全性和层级相关性。", "result": "实验结果显示，在Fitzpatrick17k基准上，本文提出的7B模型在Top-1准确率和Top-6准确率方面分别取得了+12.06%和+28.57%的显著提升，优于大型通用模型如Qwen3VL-235B和GPT-5.2。", "conclusion": "优化几何容量和信息流可以带来更优的诊断推理能力，相比之下，仅依靠参数扩展的效果较差。"}}
{"id": "2601.09130", "pdf": "https://arxiv.org/pdf/2601.09130", "abs": "https://arxiv.org/abs/2601.09130", "authors": ["Fuyao Chen", "Yuexi Du", "Elèonore V. Lieffrig", "Nicha C. Dvornek", "John A. Onofrey"], "title": "Equi-ViT: Rotational Equivariant Vision Transformer for Robust Histopathology Analysis", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted by IEEE ISBI 2026 4-page paper", "summary": "Vision Transformers (ViTs) have gained rapid adoption in computational pathology for their ability to model long-range dependencies through self-attention, addressing the limitations of convolutional neural networks that excel at local pattern capture but struggle with global contextual reasoning. Recent pathology-specific foundation models have further advanced performance by leveraging large-scale pretraining. However, standard ViTs remain inherently non-equivariant to transformations such as rotations and reflections, which are ubiquitous variations in histopathology imaging. To address this limitation, we propose Equi-ViT, which integrates an equivariant convolution kernel into the patch embedding stage of a ViT architecture, imparting built-in rotational equivariance to learned representations. Equi-ViT achieves superior rotation-consistent patch embeddings and stable classification performance across image orientations. Our results on a public colorectal cancer dataset demonstrate that incorporating equivariant patch embedding enhances data efficiency and robustness, suggesting that equivariant transformers could potentially serve as more generalizable backbones for the application of ViT in histopathology, such as digital pathology foundation models.", "AI": {"tldr": "提出Equi-ViT，通过在Vision Transformer的patch嵌入阶段集成等变卷积核来增强旋转一致性，以改进计算病理学中的图像分析。", "motivation": "标准的Vision Transformers不具有旋转和反射变换下的等变性，这限制了它们在组织病理学成像中处理旋转变化的能力。因此，提出Equi-ViT旨在提升模型对旋转不变性的适应能力。", "method": "在ViT架构中的patch嵌入阶段集成了一个等变卷积核以赋予学习表示以固有的旋转等变性。", "result": "实验结果表明，在公共的结直肠癌数据集上，包含等变patch嵌入的Equi-ViT增强了数据效率和模型鲁棒性，并在不同图像方向下保持了稳定的分类性能。", "conclusion": "研究证明了将等变特性融入到Vision Transformer中可以提高其作为计算病理学基础模型时的一般化能力和应用潜力。"}}
{"id": "2601.09121", "pdf": "https://arxiv.org/pdf/2601.09121", "abs": "https://arxiv.org/abs/2601.09121", "authors": ["Xin Yuan", "Meiqi Wan", "Wei Liu", "Xin Xu", "Zheng Wang"], "title": "Beyond Seen Bounds: Class-Centric Polarization for Single-Domain Generalized Deep Metric Learning", "categories": ["cs.CV"], "comment": "Submitted to ACM TOMM", "summary": "Single-domain generalized deep metric learning (SDG-DML) faces the dual challenge of both category and domain shifts during testing, limiting real-world applications. Therefore, aiming to learn better generalization ability on both unseen categories and domains is a realistic goal for the SDG-DML task. To deliver the aspiration, existing SDG-DML methods employ the domain expansion-equalization strategy to expand the source data and generate out-of-distribution samples. However, these methods rely on proxy-based expansion, which tends to generate samples clustered near class proxies, failing to simulate the broad and distant domain shifts encountered in practice. To alleviate the problem, we propose CenterPolar, a novel SDG-DML framework that dynamically expands and constrains domain distributions to learn a generalizable DML model for wider target domain distributions. Specifically, \\textbf{CenterPolar} contains two collaborative class-centric polarization phases: (1) Class-Centric Centrifugal Expansion ($C^3E$) and (2) Class-Centric Centripetal Constraint ($C^4$). In the first phase, $C^3E$ drives the source domain distribution by shifting the source data away from class centroids using centrifugal expansion to generalize to more unseen domains. In the second phase, to consolidate domain-invariant class information for the generalization ability to unseen categories, $C^4$ pulls all seen and unseen samples toward their class centroids while enforcing inter-class separation via centripetal constraint. Extensive experimental results on widely used CUB-200-2011 Ext., Cars196 Ext., DomainNet, PACS, and Office-Home datasets demonstrate the superiority and effectiveness of our CenterPolar over existing state-of-the-art methods. The code will be released after acceptance.", "AI": {"tldr": "本文提出了CenterPolar框架，以解决单域泛化深度度量学习（SDG-DML）任务中的类别和领域迁移问题。", "motivation": "现有方法在处理未见过的类别和领域时存在局限性，因此提出了一种新的框架来改善这些方面的能力。", "method": "CenterPolar包括两个阶段：类中心离心扩展(C3E)和类中心向心约束(C4)，以实现更好的泛化能力。", "result": "实验结果表明，CenterPolar在多个广泛使用的数据集上优于现有方法。", "conclusion": "通过实验证明了CenterPolar的有效性和优越性，并计划发布代码。"}}
{"id": "2601.09120", "pdf": "https://arxiv.org/pdf/2601.09120", "abs": "https://arxiv.org/abs/2601.09120", "authors": ["Chen-Wei Liang", "Bin Guo", "Zhen-Yuan Wei", "Mu-Jiang-Shan Wang"], "title": "Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages, 7 figures. Preprint", "summary": "Current patent claim generation systems face three fundamental limitations: poor cross-jurisdictional generalization, inadequate semantic relationship modeling between claims and prior art, and unreliable quality assessment. We introduce a novel three-stage framework that addresses these challenges through relationship-aware similarity analysis, domain-adaptive claim generation, and unified quality assessment. Our approach employs multi-head attention with eight specialized heads for explicit relationship modeling, integrates curriculum learning with dynamic LoRA adapter selection across five patent domains, and implements cross-attention mechanisms between evaluation aspects for comprehensive quality assessment. Extensive experiments on USPTO HUPD dataset, EPO patent collections, and Patent-CE benchmark demonstrate substantial improvements: 7.6-point ROUGE-L gain over GPT-4o, 8.3\\% BERTScore enhancement over Llama-3.1-8B, and 0.847 correlation with human experts compared to 0.623 for separate evaluation models. Our method maintains 89.4\\% cross-jurisdictional performance retention versus 76.2\\% for baselines, establishing a comprehensive solution for automated patent prosecution workflows.", "AI": {"tldr": "本文介绍了一种新颖的三阶段框架，用于生成专利声明并进行统一的质量评估。", "motivation": "现有的专利声明生成系统存在跨司法管辖区泛化能力差、语义关系建模不足以及质量评估不可靠的问题。该研究旨在解决这些问题。", "method": "采用具有八个专门注意力头的多头注意力机制明确建模语义关系，结合课程学习和动态LoRA适配器选择以适应五个专利领域，并实现跨评估方面的交叉注意机制进行综合质量评估。", "result": "实验表明该方法在USPTO HUPD数据集、EPO专利集合和Patent-CE基准测试中取得了显著改进：ROUGE-L比GPT-4o高出7.6点，BERTScore比Llama-3.1-8B提高8.3%，与人类专家评价的相关性为0.847（相比之下，独立评估模型仅为0.623）。跨司法管辖区性能保留率为89.4%。", "conclusion": "该研究提出了一个全面的解决方案来改进自动化专利申请工作流程，并展示了在多方面显著优于现有方法的效果。"}}
{"id": "2601.09118", "pdf": "https://arxiv.org/pdf/2601.09118", "abs": "https://arxiv.org/abs/2601.09118", "authors": ["Jackie Alex", "Guoqiang Huan"], "title": "LPCAN: Lightweight Pyramid Cross-Attention Network for Rail Surface Defect Detection Using RGB-D Data", "categories": ["cs.CV"], "comment": null, "summary": "This paper addresses the limitations of current vision-based rail defect detection methods, including high computational complexity, excessive parameter counts, and suboptimal accuracy. We propose a Lightweight Pyramid Cross-Attention Network (LPCANet) that leverages RGB-D data for efficient and accurate defect identification. The architecture integrates MobileNetv2 as a backbone for RGB feature extraction with a lightweight pyramid module (LPM) for depth processing, coupled with a cross-attention mechanism (CAM) for multimodal fusion and a spatial feature extractor (SFE) for enhanced structural analysis. Comprehensive evaluations on three unsupervised RGB-D rail datasets (NEU-RSDDS-AUG, RSDD-TYPE1, RSDD-TYPE2) demonstrate that LPCANet achieves state-of-the-art performance with only 9.90 million parameters, 2.50 G FLOPs, and 162.60 fps inference speed. Compared to 18 existing methods, LPCANet shows significant improvements, including +1.48\\% in $S_α$, +0.86\\% in IOU, and +1.77\\% in MAE over the best-performing baseline. Ablation studies confirm the critical roles of CAM and SFE, while experiments on non-rail datasets (DAGM2007, MT, Kolektor-SDD2) validate its generalization capability. The proposed framework effectively bridges traditional and deep learning approaches, offering substantial practical value for industrial defect inspection. Future work will focus on further model compression for real-time deployment.", "AI": {"tldr": "提出轻量级金字塔交叉注意力网络（LPCANet）用于基于RGB-D数据的铁路表面缺陷检测，实现高效准确的缺陷识别。", "motivation": "解决现有视觉铁路缺陷检测方法中存在的计算复杂度高、参数过多和准确性不佳的问题。", "method": "采用MobileNetv2作为RGB特征提取的骨干网络，并结合轻量级金字塔模块（LPM）处理深度信息，通过交叉注意力机制（CAM）进行多模态融合，以及空间特征提取器（SFE）增强结构分析。", "result": "在三个无监督RGB-D铁路数据集上验证了LPCANet的性能，取得了参数9.90百万、2.50 G FLOPs和162.60 fps推理速度下的最新成果，相比现有方法有显著提升。", "conclusion": "提出的框架有效连接传统方法与深度学习技术，在工业缺陷检测中具有实际应用价值。未来的工作将集中在进一步压缩模型以实现实时部署。"}}
{"id": "2601.09117", "pdf": "https://arxiv.org/pdf/2601.09117", "abs": "https://arxiv.org/abs/2601.09117", "authors": ["Shalmoli Ghosh", "Matthew R. DeVerna", "Filippo Menczer"], "title": "A Marketplace for AI-Generated Adult Content and Deepfakes", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative AI systems increasingly enable the production of highly realistic synthetic media. Civitai, a popular community-driven platform for AI-generated content, operates a monetized feature called Bounties, which allows users to commission the generation of content in exchange for payment. To examine how this mechanism is used and what content it incentivizes, we conduct a longitudinal analysis of all publicly available bounty requests collected over a 14-month period following the platform's launch. We find that the bounty marketplace is dominated by tools that let users steer AI models toward content they were not trained to generate. At the same time, requests for content that is \"Not Safe For Work\" are widespread and have increased steadily over time, now comprising a majority of all bounties. Participation in bounty creation is uneven, with 20% of requesters accounting for roughly half of requests. Requests for \"deepfake\" - media depicting identifiable real individuals - exhibit a higher concentration than other types of bounties. A nontrivial subset of these requests involves explicit deepfakes despite platform policies prohibiting such content. These bounties disproportionately target female celebrities, revealing a pronounced gender asymmetry in social harm. Together, these findings show how monetized, community-driven generative AI platforms can produce gendered harms, raising questions about consent, governance, and enforcement.", "AI": {"tldr": "本文研究了Civitai平台上AI生成内容的市场需求，特别是成人内容和深度伪造（deepfakes）的需求趋势。", "motivation": "研究目的是探讨社区驱动、商业化的AI平台如何影响和促进某些类型的内容生产，特别是那些可能涉及社会危害的内容。", "method": "通过收集并分析Civitai平台上14个月内所有公开的悬赏请求数据，进行纵向研究。", "result": "发现成人内容和深度伪造请求占多数，并且随着时间增长；这些请求主要集中在女性名人身上，显示出性别不平等的社会危害。", "conclusion": "研究表明，商业化、社区驱动的AI平台可能促进性别化伤害的发生，这引发了关于同意、治理和执行的问题。"}}
{"id": "2601.09116", "pdf": "https://arxiv.org/pdf/2601.09116", "abs": "https://arxiv.org/abs/2601.09116", "authors": ["Haoyan Gong", "Hongbin Liu"], "title": "LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Real-world License Plate Recognition (LPR) faces significant challenges from severe degradations such as motion blur, low resolution, and complex illumination. The prevailing \"restoration-then-recognition\" two-stage paradigm suffers from a fundamental flaw: the pixel-level optimization objectives of image restoration models are misaligned with the semantic goals of character recognition, leading to artifact interference and error accumulation. While Vision-Language Models (VLMs) have demonstrated powerful general capabilities, they lack explicit structural modeling for license plate character sequences (e.g., fixed length, specific order). To address this, we propose an end-to-end structure-aware multimodal reasoning framework based on Qwen3-VL. The core innovation lies in the Character-Aware Multimodal Reasoning Module (CMRM), which introduces a set of learnable Character Slot Queries. Through a cross-attention mechanism, these queries actively retrieve fine-grained evidence corresponding to character positions from visual features. Subsequently, we inject these character-aware representations back into the visual tokens via residual modulation, enabling the language model to perform autoregressive generation based on explicit structural priors. Furthermore, combined with the LoRA parameter-efficient fine-tuning strategy, the model achieves domain adaptation while retaining the generalization capabilities of the large model. Extensive experiments on both synthetic and real-world severely degraded datasets demonstrate that our method significantly outperforms existing restoration-recognition combinations and general VLMs, validating the superiority of incorporating structured reasoning into large models for low-quality text recognition tasks.", "AI": {"tldr": "本文提出了一种基于多模态模型的端到端车牌识别方法，特别针对现实世界中的降质车牌问题。", "motivation": "传统的两阶段识别方法（先修复后识别）存在固有的缺陷，即图像恢复与字符识别的目标不一致，导致错误累积和干扰。本文旨在解决这一问题，并在多模态模型中引入结构化推理能力。", "method": "提出了一种基于Qwen3-VL的端到端结构感知多模态推理框架，核心是字符感知的多模态推理模块（CMRM），通过可学习的字符槽查询和交叉注意力机制提取视觉特征中的细粒度证据，并通过残差调制将这些信息注入回语言模型进行自回归生成。", "result": "实验表明，该方法在合成数据和现实世界严重降质的数据集上均显著优于现有修复-识别组合和其他通用VLMs，验证了结合结构化推理到大型模型中的有效性。", "conclusion": "通过将结构化的推理引入大规模多模态模型中，可以有效地提高低质量文本（如车牌）的识别性能。"}}
{"id": "2601.09113", "pdf": "https://arxiv.org/pdf/2601.09113", "abs": "https://arxiv.org/abs/2601.09113", "authors": ["Zixia Jia", "Jiaqi Li", "Yipeng Kang", "Yuxuan Wang", "Tong Wu", "Quansen Wang", "Xiaobo Wang", "Shuyi Zhang", "Junzhe Shen", "Qing Li", "Siyuan Qi", "Yitao Liang", "Di He", "Zilong Zheng", "Song-Chun Zhu"], "title": "The AI Hippocampus: How Far are We From Human Memory?", "categories": ["cs.AI"], "comment": "ef:Transactions on Machine Learning Research (11/2025)", "summary": "Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations, such as textual corpora, dense vectors, and graph-based structures, thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability.", "AI": {"tldr": "本文综述了大型语言模型和多模态语言模型中记忆机制的研究进展，将其分类为隐式、显式和代理记忆，并探讨了这些机制在架构和技术上的演变。", "motivation": "随着大型语言模型从静态预测器转变为具备连续学习和个人推理能力的交互系统，内存机制变得尤为重要。本文旨在全面梳理这一领域的文献并提供结构化的综述。", "method": "文章通过综合分析现有研究，构建了一个涵盖隐式、显式和代理记忆范式的分类框架，并讨论了这些记忆模式的关键架构改进、基准任务以及面临的挑战。", "result": "本文归纳了关于大型语言模型和多模态语言模型中不同类型的内存机制的研究进展，并指出了未来发展的方向与可能的挑战，如记忆容量问题、一致性维护等。", "conclusion": "通过提供一个系统的框架来理解当前研究中的不同类型记忆机制及其在现代人工智能系统中的角色，本文为未来的探索提供了宝贵的指导。"}}
{"id": "2601.09111", "pdf": "https://arxiv.org/pdf/2601.09111", "abs": "https://arxiv.org/abs/2601.09111", "authors": ["Yang Li", "Aming Wu", "Zihao Zhang", "Yahong Han"], "title": "Towards Open Environments and Instructions: General Vision-Language Navigation via Fast-Slow Interactive Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language Navigation aims to enable agents to navigate to a target location based on language instructions. Traditional VLN often follows a close-set assumption, i.e., training and test data share the same style of the input images and instructions. However, the real world is open and filled with various unseen environments, posing enormous difficulties for close-set methods. To this end, we focus on the General Scene Adaptation (GSA-VLN) task, aiming to learn generalized navigation ability by introducing diverse environments and inconsistent intructions.Towards this task, when facing unseen environments and instructions, the challenge mainly lies in how to enable the agent to dynamically produce generalized strategies during the navigation process. Recent research indicates that by means of fast and slow cognition systems, human beings could generate stable policies, which strengthen their adaptation for open world. Inspired by this idea, we propose the slow4fast-VLN, establishing a dynamic interactive fast-slow reasoning framework. The fast-reasoning module, an end-to-end strategy network, outputs actions via real-time input. It accumulates execution records in a history repository to build memory. The slow-reasoning module analyze the memories generated by the fast-reasoning module. Through deep reflection, it extracts experiences that enhance the generalization ability of decision-making. These experiences are structurally stored and used to continuously optimize the fast-reasoning module. Unlike traditional methods that treat fast-slow reasoning as independent mechanisms, our framework enables fast-slow interaction. By leveraging the experiences from slow reasoning. This interaction allows the system to continuously adapt and efficiently execute navigation tasks when facing unseen scenarios.", "AI": {"tldr": "本文提出了一种基于快慢互动推理框架的通用视觉语言导航方法，旨在提高代理在未知环境和指令下执行任务的能力。", "motivation": "传统的视觉语言导航方法存在局限性，无法适应开放世界中多种未见过的环境和不一致的指令。为了提升代理在这些挑战下的性能，本文提出了一个新的研究方向——通用场景适应（GSA-VLN）任务。", "method": "本研究提出了一种称为slow4fast-VLN的方法，该方法包含快推理模块和慢推理模块。快推理模块负责实时输出行动决策，并积累执行记录；慢推理模块通过分析这些记忆来提取经验以优化快推理模块。", "result": "通过引入快慢互动推理框架，系统能够更有效地适应未知场景并提高导航任务的执行效率。", "conclusion": "该研究验证了基于人类认知系统的快慢互动机制在开放环境下的视觉语言导航中的有效性。"}}
{"id": "2601.09110", "pdf": "https://arxiv.org/pdf/2601.09110", "abs": "https://arxiv.org/abs/2601.09110", "authors": ["Kai Hu", "Yaozu Feng", "Vladimir Lysenko", "Ya Guo Member", "Huayi Wu"], "title": "SAM-Aug: Leveraging SAM Priors for Few-Shot Parcel Segmentation in Satellite Time Series", "categories": ["cs.CV"], "comment": "13 pages, 6 figures", "summary": "Few-shot semantic segmentation of time-series remote sensing images remains a critical challenge, particularly in regions where labeled data is scarce or costly to obtain. While state-of-the-art models perform well under full supervision, their performance degrades significantly under limited labeling, limiting their real-world applicability. In this work, we propose SAM-Aug, a new annotation-efficient framework that leverages the geometry-aware segmentation capability of the Segment Anything Model (SAM) to improve few-shot land cover mapping. Our approach constructs cloud-free composite images from temporal sequences and applies SAM in a fully unsupervised manner to generate geometry-aware mask priors. These priors are then integrated into training through a proposed loss function called RegionSmoothLoss, which enforces prediction consistency within each SAM-derived region across temporal frames, effectively regularizing the model to respect semantically coherent structures. Extensive experiments on the PASTIS-R benchmark under a 5 percent labeled setting demonstrate the effectiveness and robustness of SAM-Aug. Averaged over three random seeds (42, 2025, 4090), our method achieves a mean test mIoU of 36.21 percent, outperforming the state-of-the-art baseline by +2.33 percentage points, a relative improvement of 6.89 percent. Notably, on the most favorable split (seed=42), SAM-Aug reaches a test mIoU of 40.28 percent, representing an 11.2 percent relative gain with no additional labeled data. The consistent improvement across all seeds confirms the generalization power of leveraging foundation model priors under annotation scarcity. Our results highlight that vision models like SAM can serve as useful regularizers in few-shot remote sensing learning, offering a scalable and plug-and-play solution for land cover monitoring without requiring manual annotations or model fine-tuning.", "AI": {"tldr": "本文提出了SAM-Aug，一种基于Segment Anything Model（SAM）的新型标注效率框架，用于解决卫星时间序列图像中少样本土地覆盖分割问题。", "motivation": "鉴于在标记数据稀缺或成本高昂地区进行的时间序列遥感图像少样本语义分割面临的挑战，本研究旨在提出一个能够利用基础模型先验知识，在少量标注数据情况下提升分割性能的框架。", "method": "SAM-Aug通过构建无云合成图像并使用完全无监督的Segment Anything Model（SAM）生成几何感知掩码先验，并将这些先验通过自定义损失函数RegionSmoothLoss融入训练过程，以保证预测在每个由SAM衍生区域内的时序帧中具有一致性。", "result": "实验表明，在PASTIS-R基准数据集上采用5%标记设置的情况下，该方法实现了平均测试mIoU为36.21%，超越现有最先进基线模型2.33个百分点。在最优分割条件下（种子=42），SAM-Aug达到40.28%的测试mIoU。", "conclusion": "研究结果显示了利用基础视觉模型作为正则化器在少样本遥感学习中的有效性，提供了无需手动标注或模型微调的土地覆盖监测可扩展解决方案。"}}
{"id": "2601.09108", "pdf": "https://arxiv.org/pdf/2601.09108", "abs": "https://arxiv.org/abs/2601.09108", "authors": ["Yanguang Sun", "Chao Wang", "Jian Yang", "Lei Luo"], "title": "Small but Mighty: Dynamic Wavelet Expert-Guided Fine-Tuning of Large-Scale Models for Optical Remote Sensing Object Segmentation", "categories": ["cs.CV"], "comment": "Accepted at AAAI 2026", "summary": "Accurately localizing and segmenting relevant objects from optical remote sensing images (ORSIs) is critical for advancing remote sensing applications. Existing methods are typically built upon moderate-scale pre-trained models and employ diverse optimization strategies to achieve promising performance under full-parameter fine-tuning. In fact, deeper and larger-scale foundation models can provide stronger support for performance improvement. However, due to their massive number of parameters, directly adopting full-parameter fine-tuning leads to pronounced training difficulties, such as excessive GPU memory consumption and high computational costs, which result in extremely limited exploration of large-scale models in existing works. In this paper, we propose a novel dynamic wavelet expert-guided fine-tuning paradigm with fewer trainable parameters, dubbed WEFT, which efficiently adapts large-scale foundation models to ORSIs segmentation tasks by leveraging the guidance of wavelet experts. Specifically, we introduce a task-specific wavelet expert extractor to model wavelet experts from different perspectives and dynamically regulate their outputs, thereby generating trainable features enriched with task-specific information for subsequent fine-tuning. Furthermore, we construct an expert-guided conditional adapter that first enhances the fine-grained perception of frozen features for specific tasks by injecting trainable features, and then iteratively updates the information of both types of feature, allowing for efficient fine-tuning. Extensive experiments show that our WEFT not only outperforms 21 state-of-the-art (SOTA) methods on three ORSIs datasets, but also achieves optimal results in camouflage, natural, and medical scenarios. The source code is available at: https://github.com/CSYSI/WEFT.", "AI": {"tldr": "本文提出了一种动态小波专家引导的微调范式WEFT，用于大规模模型在光学遥感图像对象分割任务上的高效适应。", "motivation": "现有方法依赖中等规模预训练模型，并使用多种优化策略来实现全参数微调下的良好性能。然而，更大规模的基础模型由于其大量的参数数量，在直接进行全参数微调时会面临显著的训练困难，如过度消耗GPU内存和计算成本。", "method": "本文提出了一种称为WEFT的新颖动态小波专家引导细调范式，该范式通过利用小波专家指导来高效地将大规模基础模型适应于光学遥感图像分割任务。具体来说，引入了任务特定的小波专家提取器以从不同角度建模小波专家，并动态调节其输出，从而生成富含任务特定信息的可训练特征进行后续细调。", "result": "实验结果表明，本文提出的WEFT不仅在三个光学遥感图像数据集上优于21个最先进的方法，还在伪装、自然和医疗场景中实现了最优性能。", "conclusion": "通过动态小波专家引导，大规模模型可以被高效地微调至特定的光学遥感图像对象分割任务，并且显著提升了这些任务下的性能表现。"}}
{"id": "2601.09107", "pdf": "https://arxiv.org/pdf/2601.09107", "abs": "https://arxiv.org/abs/2601.09107", "authors": ["Lachlan Holden", "Feras Dayoub", "Alberto Candela", "David Harvey", "Tat-Jun Chin"], "title": "Vision Foundation Models for Domain Generalisable Cross-View Localisation in Planetary Ground-Aerial Robotic Teams", "categories": ["cs.CV", "cs.RO"], "comment": "7 pages, 10 figures. Presented at the International Conference on Space Robotics (iSpaRo) 2025 in Sendai, Japan. Dataset available: https://doi.org/10.5281/zenodo.17364038", "summary": "Accurate localisation in planetary robotics enables the advanced autonomy required to support the increased scale and scope of future missions. The successes of the Ingenuity helicopter and multiple planetary orbiters lay the groundwork for future missions that use ground-aerial robotic teams. In this paper, we consider rovers using machine learning to localise themselves in a local aerial map using limited field-of-view monocular ground-view RGB images as input. A key consideration for machine learning methods is that real space data with ground-truth position labels suitable for training is scarce. In this work, we propose a novel method of localising rovers in an aerial map using cross-view-localising dual-encoder deep neural networks. We leverage semantic segmentation with vision foundation models and high volume synthetic data to bridge the domain gap to real images. We also contribute a new cross-view dataset of real-world rover trajectories with corresponding ground-truth localisation data captured in a planetary analogue facility, plus a high volume dataset of analogous synthetic image pairs. Using particle filters for state estimation with the cross-view networks allows accurate position estimation over simple and complex trajectories based on sequences of ground-view images.", "AI": {"tldr": "本文提出了一种使用交叉视图双编码器深度神经网络，结合语义分割和大量合成数据来实现行星机器人团队中地面漫游者在空中地图中的准确定位的方法。", "motivation": "为了支持未来更大规模和更广泛的太空任务，精确的定位是实现先进自主性的关键。然而，现实空间的数据和带有真实位置标签的数据非常稀缺，因此需要开发新的方法来解决这个问题。", "method": "本文提出了一种基于交叉视图双编码器深度神经网络的方法，并结合语义分割技术和大量的合成数据来弥补领域差距。同时，提供了一个新的交叉视图实际漫游者轨迹数据集以及大量类似图像对的合成数据集。", "result": "使用粒子滤波器进行状态估计，通过该方法能够准确地基于地面视图图像序列定位简单和复杂路径上的漫游者位置。", "conclusion": "本文的方法成功实现了在行星类比设施中真实漫游者轨迹上对地面漫游者的准确定位，并且证明了利用合成数据可以有效解决现实空间标记数据稀缺的问题。"}}
{"id": "2601.09105", "pdf": "https://arxiv.org/pdf/2601.09105", "abs": "https://arxiv.org/abs/2601.09105", "authors": ["Wenbin Li", "Jingling Wu", "Xiaoyong Lin. Jing Chen", "Cong Chen"], "title": "AviationLMM: A Large Multimodal Foundation Model for Civil Aviation", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "Accepted by 2025 7th International Conference on Interdisciplinary Computer Science and Engineering (ICICSE 2025) conference, Chongqing, China; 9 pages,1 figure,5 tables", "summary": "Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.", "AI": {"tldr": "本文介绍了一个面向民用航空的大型多模态基础模型 AviationLMM，旨在整合异构数据流并实现理解、推理和生成等应用。", "motivation": "传统的人工智能解决方案在民航领域存在孤立性和局限性，难以处理多种类型的数据，限制了其对情况的认知能力和实时决策支持能力。", "method": "该模型设计了一个多模态输入架构，可以摄取空中地面语音、监控数据、机载遥测数据、视频和结构化文本等，并进行跨模态的对齐和融合，生成多种输出形式如情势总结、风险警报及预测性诊断。", "result": "该论文详细描述了模型的设计理念及其面临的挑战，为实现一体化、可信赖且保护隐私的民航人工智能生态系统指明了方向。", "conclusion": "通过提出AviationLMM的设计和研究机会，本文旨在推动民用航空基础模型的发展并激发协同研究努力。"}}
{"id": "2601.09104", "pdf": "https://arxiv.org/pdf/2601.09104", "abs": "https://arxiv.org/abs/2601.09104", "authors": ["Ko Yamamoto", "Kyosuke Ishibashi", "Hiroki Ishikawa", "Osamu Azami"], "title": "Design Methodology of Hydraulically-driven Soft Robotic Gripper for a Large and Heavy Object", "categories": ["cs.RO"], "comment": null, "summary": "This paper presents a design methodology of a hydraulically-driven soft robotic gripper for grasping a large and heavy object -- approximately 10 - 20 kg with 20 - 30 cm diameter. Most existing soft grippers are pneumatically actuated with several hundred kPa pressure, and cannot generate output force sufficient for such a large and heavy object. Instead of pneumatic actuation, hydraulic actuation has a potential to generate much larger power by several MPa pressure. In this study, we develop a hydraulically-driven soft gripper, in which its basic design parameters are determined based on a mathematical model that represents the relationship among the driving pressure, bending angle, object mass and grasping force. Moreover, we selected materials suitable for grasping a heavier object, based on the finite element analysis result of the detailed design. We report experimental results on a 20 kg object grasping and closed-loop control of the finger bending angle.", "AI": {"tldr": "本文介绍了设计用于抓取大而重物体的液压驱动软机器人夹爪的方法论。", "motivation": "现有的大多数软夹爪都是通过气动驱动，产生的输出力不足以抓取大约10-20公斤、直径在20-30厘米范围内的大型和重型物品。因此，本文旨在开发一种能够产生更大动力的液压驱动软夹爪。", "method": "基于数学模型确定了基本设计参数，该模型展示了驱动压力、弯曲角度、物体质量和抓取力之间的关系，并通过有限元分析选择适合抓取更重物体的材料。", "result": "实验结果显示该液压驱动软夹爪能够成功抓取20公斤的物品并实现手指弯曲角度的闭环控制。", "conclusion": "本研究证明了使用数学模型和有限元分析设计出一种适用于大型重型物体的液压驱动软机器人夹爪的有效性，为未来的设计提供了参考。"}}
{"id": "2601.09100", "pdf": "https://arxiv.org/pdf/2601.09100", "abs": "https://arxiv.org/abs/2601.09100", "authors": ["Lixiang Zhang", "Chenggong Zhao", "Qing Gao", "Xiaoke Zhao", "Gengyi Bai", "Jinhu Lv"], "title": "DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model", "categories": ["cs.AI"], "comment": "14 pages, 6 figures", "summary": "Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.", "AI": {"tldr": "本论文提出了一种动态调度方法DScheLLM，利用双系统（快-慢）推理架构中的微调大型语言模型来处理不同规模的干扰。", "motivation": "传统的生产调度方法难以适应动态变化和新出现的干扰，因此需要一种更灵活和可泛化的解决方案。", "method": "构建了一个统一的大语言模型框架，并使用精确调度数据训练快、慢两种推理模式下的模型。华为OpenPangu Embedded-7B模型通过LoRA进行了微调以支持混合推理范式。", "result": "实验表明，快速思考模式能够高效生成高质量的调度方案，而缓慢思考模式可以产生与解算器兼容且格式良好的决策输入。", "conclusion": "本研究是最早将大型语言模型应用于动态环境下的作业车间调度中的工作之一，展示了其在智能和适应性调度优化方面的巨大潜力。"}}
{"id": "2601.09097", "pdf": "https://arxiv.org/pdf/2601.09097", "abs": "https://arxiv.org/abs/2601.09097", "authors": ["Derrick Goh Xin Deik", "Quanyu Long", "Zhengyuan Liu", "Nancy F. Chen", "Wenya Wang"], "title": "Programming over Thinking: Efficient and Robust Multi-Constraint Planning", "categories": ["cs.AI"], "comment": "8 pages of main text, 2 pages of references and and limitations, 37 pages of appendices", "summary": "Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.", "AI": {"tldr": "介绍了一个名为SCOPE的框架，用于解决多约束规划问题，并展示了其在效率和鲁棒性上的优势。", "motivation": "现有的大型语言模型（LLM）方法存在根本性的限制，包括纯推理范式中长自然语言链可能导致的一致性问题、错误累积及高昂成本。LLM结合编程或求解策略的方法也缺乏灵活性，无法适应多样化的复杂问题。", "method": "提出了一个名为SCOPE的框架，该框架将特定查询的推理与通用代码执行分离，生成一致且可重用的求解函数，同时只需对输入参数进行最小修改。", "result": "SCOPE在TravelPlanner上使用GPT-4o时达到了93.1%的成功率，比最佳基线（CoT）提高了61.6%，并减少了1.4倍的成本和大约4.67倍的时间。", "conclusion": "SCOPE框架通过分离推理与执行实现了高效的多约束规划，并降低了成本与延迟时间。"}}
{"id": "2601.09089", "pdf": "https://arxiv.org/pdf/2601.09089", "abs": "https://arxiv.org/abs/2601.09089", "authors": ["Shuyang Hou", "Yi Hu", "Muhan Zhang"], "title": "SubTokenTest: A Practical Benchmark for Real-World Sub-token Understanding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have significantly enhanced their reasoning capabilities. However, they continue to struggle with basic character-level tasks, such as counting letters in words, a problem rooted in their tokenization process. While existing benchmarks have highlighted this weakness through basic character operations, such failures are often dismissed due to lacking practical relevance. Yet, many real-world applications, such as navigating text-based maps or interpreting structured tables, rely heavily on precise sub-token understanding. In this regard, we introduce SubTokenTest, a comprehensive benchmark that assesses sub-token understanding through practical, utility-driven tasks. Our benchmark includes ten tasks across four domains and isolates tokenization-related failures by decoupling performance from complex reasoning. We provide a comprehensive evaluation of nine advanced LLMs. Additionally, we investigate the impact of test-time scaling on sub-token reasoning and explore how character-level information is encoded within the hidden states.", "AI": {"tldr": "介绍SubTokenTest，一个评估大型语言模型在实际子标记理解任务上的基准测试。", "motivation": "虽然大型语言模型的推理能力有所提升，但在字符级别的基本任务上仍有不足，这些问题缺乏实用意义导致被忽视，而许多现实应用需要精确的子标记理解。", "method": "提出了SubTokenTest，包含十个任务和四个领域，评估九种先进语言模型在子标记上的理解和编码方式，并探讨了测试时缩放对字符级推理的影响。", "result": "全面评估了九个先进的大型语言模型，并研究了测试时的尺度调整对子标记理解的影响。", "conclusion": "SubTokenTest能有效识别和隔离由分词过程导致的性能下降，揭示大型语言模型在实际应用中的精确度限制。"}}
{"id": "2601.09085", "pdf": "https://arxiv.org/pdf/2601.09085", "abs": "https://arxiv.org/abs/2601.09085", "authors": ["Kangda Wei", "Ruihong Huang"], "title": "MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has become a standard approach for training mathematical reasoning models; however, its reliance on multiple completions per prompt makes training computationally expensive. Although recent work has reduced the number of training steps required to reach peak performance, the overall wall-clock training time often remains unchanged or even increases due to higher per-step cost. We propose MMR-GRPO, which integrates Maximal Marginal Relevance to reweigh rewards based on completion diversity. Our key insight is that semantically redundant completions contribute limited marginal learning signal; prioritizing diverse solutions yields more informative updates and accelerates convergence. Extensive evaluations across three model sizes (1.5B, 7B, 8B), three GRPO variants, and five mathematical reasoning benchmarks show that MMR-GRPO achieves comparable peak performance while requiring on average 47.9% fewer training steps and 70.2% less wall-clock time. These gains are consistent across models, methods, and benchmarks. We will release our code, trained models, and experimental protocols.", "AI": {"tldr": "本文提出了一种名为MMR-GRPO的方法，通过引入多样性感知的奖励重加权机制来加速基于组相对策略优化（GRPO）风格的训练。", "motivation": "尽管现有的方法减少了达到最佳性能所需的训练步骤数量，但整体训练时间并未显著减少甚至增加。为了提高训练效率并降低计算成本，作者提出了MMR-GRPO以解决这个问题。", "method": "MMR-GRPO通过集成最大边际相关性来重新加权奖励，基于完成任务的多样性。这一方法认为语义重复的任务提供有限的学习信号增量；优先考虑多样化的解决方案可以实现更有效的更新并加速收敛。", "result": "实验表明，在三个模型尺寸、三种GRPO变体和五个数学推理基准测试上，MMR-GRPO达到了与现有最佳性能相当的峰值性能，同时平均减少了47.9%的训练步骤和70.2%的计算时间。这些增益在不同的模型、方法和基准测试中表现一致。", "conclusion": "通过优先考虑多样化的解决方案而不是重复的任务，MMR-GRPO能够在减少整体训练时间和所需步骤的同时，保持与现有技术相当的最佳性能。"}}
{"id": "2601.09081", "pdf": "https://arxiv.org/pdf/2601.09081", "abs": "https://arxiv.org/abs/2601.09081", "authors": ["Zekun Wang", "Binghao Yue", "Weitao Pan", "Jianyi Shi", "Yue Hao"], "title": "A Grouped Sorting Queue Supporting Dynamic Updates for Timer Management in High-Speed Network Interface Cards", "categories": ["cs.DS"], "comment": null, "summary": "With the hardware offloading of network functions, network interface cards (NICs) undertake massive stateful, high-precision, and high-throughput tasks, where timers serve as a critical enabling component. However, existing timer management schemes suffer from heavy software load, low precision, lack of hardware update support, and overflow. This paper proposes two novel operations for priority queues--update and group sorting--to enable hardware timer management. To the best of our knowledge, this work presents the first hardware priority queue to support an update operation through the composition and propagation of basic operations to modify the priorities of elements within the queue. The group sorting mechanism ensures correct timing behavior post-overflow by establishing a group boundary priority to alter the sorting process and element insertion positions. Implemented with a hybrid architecture of a one-dimension (1D) systolic array and shift registers, our design is validated through packet-level simulations for flow table timeout management. Results demonstrate that a 4K-depth, 16-bit timer queue achieves over 500 MHz (175 Mpps, 12 ns precision) in a 28nm process and over 300 MHz (116 Mpps) on an FPGA. Critically, it reduces LUTs and FFs usage by 31% and 25%, respectively, compared to existing designs.", "AI": {"tldr": "本文提出了一种支持动态更新的分组排序队列，用于高精度、高吞吐量的定时器管理。", "motivation": "现有的定时器管理系统存在软件负载重、精度低、缺乏硬件更新支持和溢出等问题。这些问题在处理大量状态化任务时尤为突出。", "method": "本文提出两种新的优先级队列操作：更新和分组排序，以实现硬件定时器管理。设计通过一维系统阵列与移位寄存器的混合架构来实施。", "result": "实验结果显示，一个4K深度、16比特的定时器队列在28nm工艺中实现了超过500MHz（175Mpps,12ns精度）的速度，在FPGA上实现超过300MHz（116Mpps）。与现有设计相比，它减少了31%的LUT使用和25%的FF使用。", "conclusion": "本文提出的方法有效地减轻了软件负载，提高了定时器管理系统的精度，并且通过硬件支持动态更新操作，解决了现有系统中的问题。"}}
{"id": "2601.09078", "pdf": "https://arxiv.org/pdf/2601.09078", "abs": "https://arxiv.org/abs/2601.09078", "authors": ["Junze Shi", "Yang Yu", "Jian Shi", "Haibo Luo"], "title": "Exploring Reliable Spatiotemporal Dependencies for Efficient Visual Tracking", "categories": ["cs.CV"], "comment": "8 pages, 6 figures", "summary": "Recent advances in transformer-based lightweight object tracking have established new standards across benchmarks, leveraging the global receptive field and powerful feature extraction capabilities of attention mechanisms. Despite these achievements, existing methods universally employ sparse sampling during training--utilizing only one template and one search image per sequence--which fails to comprehensively explore spatiotemporal information in videos. This limitation constrains performance and cause the gap between lightweight and high-performance trackers. To bridge this divide while maintaining real-time efficiency, we propose STDTrack, a framework that pioneers the integration of reliable spatiotemporal dependencies into lightweight trackers. Our approach implements dense video sampling to maximize spatiotemporal information utilization. We introduce a temporally propagating spatiotemporal token to guide per-frame feature extraction. To ensure comprehensive target state representation, we disign the Multi-frame Information Fusion Module (MFIFM), which augments current dependencies using historical context. The MFIFM operates on features stored in our constructed Spatiotemporal Token Maintainer (STM), where a quality-based update mechanism ensures information reliability. Considering the scale variation among tracking targets, we develop a multi-scale prediction head to dynamically adapt to objects of different sizes. Extensive experiments demonstrate state-of-the-art results across six benchmarks. Notably, on GOT-10k, STDTrack rivals certain high-performance non-real-time trackers (e.g., MixFormer) while operating at 192 FPS(GPU) and 41 FPS(CPU).", "AI": {"tldr": "本文提出了一种名为STDTrack的框架，通过整合可靠的时空依赖关系来提升轻量级视觉跟踪器的性能。", "motivation": "尽管基于Transformer的轻量化对象跟踪技术取得了进展，但现有的方法在训练过程中普遍采用稀疏采样方式，限制了其对视频中时空信息的全面利用。这导致了轻量化和高性能跟踪器之间的性能差距。", "method": "STDTrack框架通过密集视频采样最大化时空信息的使用，并引入了一个时间传播的空间-时间标记来引导每帧特征提取。多帧信息融合模块（MFIFM）确保了目标状态表示的全面性，其工作基于存储在时空令牌维护器（STM）中的特征，且采用质量为基础的更新机制。", "result": "广泛的实验表明，该方法在六个基准测试中达到了最先进的结果，并且能够在GPU上以192 FPS和CPU上41 FPS的速度运行，同时性能可与某些非实时高性能跟踪器相匹敌。", "conclusion": "STDTrack框架通过引入可靠的时空依赖关系，成功地缩小了轻量化和高性能视觉跟踪技术之间的差距，实现了高效的实时跟踪。"}}
{"id": "2601.09072", "pdf": "https://arxiv.org/pdf/2601.09072", "abs": "https://arxiv.org/abs/2601.09072", "authors": ["Jean Feng", "Avni Kothari", "Patrick Vossler", "Andrew Bishara", "Lucas Zier", "Newton Addo", "Aaron Kornblith", "Yan Shuo Tan", "Chandan Singh"], "title": "Human-AI Co-design for Clinical Prediction Models", "categories": ["cs.AI", "cs.CL", "stat.ME"], "comment": null, "summary": "Developing safe, effective, and practically useful clinical prediction models (CPMs) traditionally requires iterative collaboration between clinical experts, data scientists, and informaticists. This process refines the often small but critical details of the model building process, such as which features/patients to include and how clinical categories should be defined. However, this traditional collaboration process is extremely time- and resource-intensive, resulting in only a small fraction of CPMs reaching clinical practice. This challenge intensifies when teams attempt to incorporate unstructured clinical notes, which can contain an enormous number of concepts. To address this challenge, we introduce HACHI, an iterative human-in-the-loop framework that uses AI agents to accelerate the development of fully interpretable CPMs by enabling the exploration of concepts in clinical notes. HACHI alternates between (i) an AI agent rapidly exploring and evaluating candidate concepts in clinical notes and (ii) clinical and domain experts providing feedback to improve the CPM learning process. HACHI defines concepts as simple yes-no questions that are used in linear models, allowing the clinical AI team to transparently review, refine, and validate the CPM learned in each round. In two real-world prediction tasks (acute kidney injury and traumatic brain injury), HACHI outperforms existing approaches, surfaces new clinically relevant concepts not included in commonly-used CPMs, and improves model generalizability across clinical sites and time periods. Furthermore, HACHI reveals the critical role of the clinical AI team, such as directing the AI agent to explore concepts that it had not previously considered, adjusting the granularity of concepts it considers, changing the objective function to better align with the clinical objectives, and identifying issues of data bias and leakage.", "AI": {"tldr": "本文介绍了HACHI框架，通过AI与人类专家的迭代协作加速开发可解释性强的临床预测模型。", "motivation": "传统上开发安全有效的临床预测模型需要大量时间和资源，特别是当涉及到处理未结构化的临床记录时。为了提高效率和效果，提出了一个解决方案。", "method": "HACHI框架采用AI代理与人类专家交互的方式，通过AI快速探索并评估候选概念，并根据专家反馈改进模型学习过程。", "result": "在急性肾损伤和创伤性脑损伤两个预测任务中，HACHI优于现有方法，揭示了新的临床相关概念，提升了跨地点和时间的一般化能力。", "conclusion": "HACHI框架展示了AI与人类团队合作的重要性，并能有效指导模型开发过程中的关键决策，提高了模型的解释性和实用性。"}}
{"id": "2601.09069", "pdf": "https://arxiv.org/pdf/2601.09069", "abs": "https://arxiv.org/abs/2601.09069", "authors": ["Kanyao Han", "Yushang Lai"], "title": "From Symbolic to Natural-Language Relations: Rethinking Knowledge Graph Construction in the Era of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Knowledge graphs (KGs) have commonly been constructed using predefined symbolic relation schemas, typically implemented as categorical relation labels. This design has notable shortcomings: real-world relations are often contextual, nuanced, and sometimes uncertain, and compressing it into discrete relation labels abstracts away critical semantic detail. Nevertheless, symbolic-relation KGs remain widely used because they have been operationally effective and broadly compatible with pre-LLM downstream models and algorithms, in which KG knowledge could be retrieved or encoded into quantified features and embeddings at scale. The emergence of LLMs has reshaped how knowledge is created and consumed. LLMs support scalable synthesis of domain facts directly in concise natural language, and prompting-based inference favors context-rich free-form text over quantified representations. This position paper argues that these changes call for rethinking the representation of relations themselves rather than merely using LLMs to populate conventional schemas more efficiently. We therefore advocate moving from symbolic to natural-language relation descriptions, and we propose hybrid design principles that preserve a minimal structural backbone while enabling more flexible and context-sensitive relational representations.", "AI": {"tldr": "本文主张从传统的符号关系知识图谱转向使用自然语言描述的关系来构建知识图谱，以适应大型语言模型带来的变化。", "motivation": "传统知识图谱基于预定义的符号关系模式，这些模式无法很好地捕捉现实世界中复杂、模糊和上下文相关的关联。大型语言模型的出现改变了知识生成和消费的方式，支持更灵活的知识表示。", "method": "提出了一种混合设计原则，在保留最小结构框架的同时，允许更加灵活和上下文敏感的关系描述。", "result": "文章没有具体实验结果，而是提出了一个观点：应该重新思考关系在知识图谱中的表现形式，以更好地利用大型语言模型的优势。", "conclusion": "传统符号关系的知识图谱虽然有效但存在局限性，随着大型语言模型的发展，采用自然语言描述的关系可以更准确地表达复杂和上下文相关的关联。"}}
{"id": "2601.09066", "pdf": "https://arxiv.org/pdf/2601.09066", "abs": "https://arxiv.org/abs/2601.09066", "authors": ["Donghoon Shin", "Sejung Lee", "Soonmin Bae", "Hwijung Ryu", "Changwon Ok", "Hoyoun Jung", "Hyesung Ji", "Jeehyun Lim", "Jehoon Lee", "Ji-Eun Han", "Jisoo Baik", "Mihyeon Kim", "Riwoo Chung", "Seongmin Lee", "Wonjae Park", "Yoonseok Heo", "Youngkyung Seo", "Seyoun Won", "Boeun Kim", "Cheolhun Heo", "Eunkyeong Lee", "Honghee Lee", "Hyeongju Ju", "Hyeontae Seo", "Jeongyong Shim", "et al. (41 additional authors not shown)"], "title": "Mi:dm 2.0 Korea-centric Bilingual Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce Mi:dm 2.0, a bilingual large language model (LLM) specifically engineered to advance Korea-centric AI. This model goes beyond Korean text processing by integrating the values, reasoning patterns, and commonsense knowledge inherent to Korean society, enabling nuanced understanding of cultural contexts, emotional subtleties, and real-world scenarios to generate reliable and culturally appropriate responses. To address limitations of existing LLMs, often caused by insufficient or low-quality Korean data and lack of cultural alignment, Mi:dm 2.0 emphasizes robust data quality through a comprehensive pipeline that includes proprietary data cleansing, high-quality synthetic data generation, strategic data mixing with curriculum learning, and a custom Korean-optimized tokenizer to improve efficiency and coverage. To realize this vision, we offer two complementary configurations: Mi:dm 2.0 Base (11.5B parameters), built with a depth-up scaling strategy for general-purpose use, and Mi:dm 2.0 Mini (2.3B parameters), optimized for resource-constrained environments and specialized tasks. Mi:dm 2.0 achieves state-of-the-art performance on Korean-specific benchmarks, with top-tier zero-shot results on KMMLU and strong internal evaluation results across language, humanities, and social science tasks. The Mi:dm 2.0 lineup is released under the MIT license to support extensive research and commercial use. By offering accessible and high-performance Korea-centric LLMs, KT aims to accelerate AI adoption across Korean industries, public services, and education, strengthen the Korean AI developer community, and lay the groundwork for the broader vision of K-intelligence. Our models are available at https://huggingface.co/K-intelligence. For technical inquiries, please contact midm-llm@kt.com.", "AI": {"tldr": "介绍Mi:dm 2.0，一种专注于韩国文化背景的双语大型语言模型。", "motivation": "为解决现有LLM在处理韩文数据时存在质量不足和缺乏文化适应性的问题，提出了Mi:dm 2.0来提高对文化上下文、情感细微差别和现实场景的理解。", "method": "通过包含专有数据清洗、高质量合成数据生成、策略性数据混合以及定制的韩国优化分词器的数据处理管道，增强数据质量和模型性能。", "result": "Mi:dm 2.0在韩语特定基准测试中达到最先进的性能，在KMMLU上取得顶尖的零样本结果，并且内部评估显示跨语言、人文和社会科学任务上的优秀表现。", "conclusion": "发布Mi:dm 2.0系列模型以促进韩国各行业的AI应用，加强韩国AI开发者社区，并为K-智能的更广泛愿景奠定基础。"}}
{"id": "2601.09053", "pdf": "https://arxiv.org/pdf/2601.09053", "abs": "https://arxiv.org/abs/2601.09053", "authors": ["Haiyi Li", "Yutong Li", "Yiheng Chi", "Alison Deslandes", "Mathew Leonardi", "Shay Freger", "Yuan Zhang", "Jodie Avery", "M. Louise Hull", "Hsiang-Ting Chen"], "title": "Evaluating local large language models for structured extraction from endometriosis-specific transvaginal ultrasound reports", "categories": ["cs.HC"], "comment": null, "summary": "In this study, we evaluate a locally-deployed large-language model (LLM) to convert unstructured endometriosis transvaginal ultrasound (eTVUS) scan reports into structured data for imaging informatics workflows. Across 49 eTVUS reports, we compared three LLMs (7B/8B and a 20B-parameter model) against expert human extraction. The 20B model achieved a mean accuracy of 86.02%, substantially outperforming smaller models and confirming the importance of scale in handling complex clinical text. Crucially, we identified a highly complementary error profile: the LLM excelled at syntactic consistency (e.g., date/numeric formatting) where humans faltered, while human experts provided superior semantic and contextual interpretation. We also found that the LLM's semantic errors were fundamental limitations that could not be mitigated by simple prompt engineering. These findings strongly support a human-in-the-loop (HITL) workflow in which the on-premise LLM serves as a collaborative tool, not a full replacement. It automates routine structuring and flags potential human errors, enabling imaging specialists to focus on high-level semantic validation. We discuss implications for structured reporting and interactive AI systems in clinical practice.", "AI": {"tldr": "本文评估了本地部署的大语言模型（LLM）将未结构化的内异症经阴道超声检查报告转换为成像信息学工作流程中的结构化数据的能力。", "motivation": "研究动机在于探索大语言模型在处理复杂临床文本时的表现，并探讨这些模型与人类专家协作的可能性，特别是在结构化医疗报告生成方面。", "method": "该研究使用了三种不同规模的本地部署的大语言模型（7B/8B和20B参数）来分析49份内异症经阴道超声检查报告，并将结果与人类专家的手动提取进行了对比。", "result": "结果显示，20B参数的模型达到了86.02%的平均准确率，显著优于较小规模的模型，但其错误主要集中在语义层面，无法通过简单的提示工程来缓解。同时发现了模型和人类在误差类型上的高度互补性。", "conclusion": "研究结论支持将大语言模型作为协作工具集成到临床实践中的人类参与循环（HITL）工作流程中，以自动化常规的结构化处理并标注潜在的人为错误，从而使成像专家能够专注于高级别的语义验证。"}}
{"id": "2601.09049", "pdf": "https://arxiv.org/pdf/2601.09049", "abs": "https://arxiv.org/abs/2601.09049", "authors": ["Kaiyu He", "Zhang Mian", "Peilin Wu", "Xinya Du", "Zhiyu Chen"], "title": "Is Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While Large Language Models (LLMs) excel at factual retrieval, they often struggle with the \"curse of two-hop reasoning\" in compositional tasks. Recent research suggests that parameter-sharing transformers can bridge this gap by forming a \"Generalization Circuit\" during a prolonged \"grokking\" phase. A fundamental question arises: Is a grokked model superior to its non-grokked counterparts on downstream tasks? Furthermore, is the extensive computational cost of waiting for the grokking phase worthwhile? In this work, we conduct a mechanistic study to evaluate the Generalization Circuit's role in knowledge assimilation and transfer. We demonstrate that: (i) The inference paths established by non-grokked and grokked models for in-distribution compositional queries are identical. This suggests that the \"Generalization Circuit\" does not represent the sudden acquisition of a new reasoning paradigm. Instead, we argue that grokking is the process of integrating memorized atomic facts into an naturally established reasoning path. (ii) Achieving high accuracy on unseen cases after prolonged training and the formation of a certain reasoning path are not bound; they can occur independently under specific data regimes. (iii) Even a mature circuit exhibits limited transferability when integrating new knowledge, suggesting that \"grokked\" Transformers do not achieve a full mastery of compositional logic.", "AI": {"tldr": "本文探讨了参数共享的Transformer在经历长时间“领悟”期形成“泛化电路”后的性能是否优于未经过此阶段的模型，并评估这种电路的知识吸收和迁移能力。", "motivation": "动机在于解决大型语言模型（LLMs）在事实检索方面表现出色，但在处理组合任务中的两跳推理时遇到困难。研究旨在回答是否经过“领悟”的模型在下游任务上优于未经历此阶段的模型，并评估其高昂计算成本的价值。", "method": "进行机制性研究以评价泛化电路在知识吸收和转移的作用。通过对比非“领悟”与已“领悟”模型对分布内组合查询推理路径的一致性来分析。", "result": "发现：（i）非“领悟”与“领悟”的模型对于分布内组合查询的推理路径是相同的，表明泛化电路不代表新的推理范式。（ii）在特定数据条件下，长期训练后获得高未见案例准确性与形成一定推理路径是可以独立发生的事。（iii）即使是成熟的电路也表现出有限的新知识整合迁移能力。", "conclusion": "研究得出结论，“领悟”Transformer并未完全掌握组合逻辑，并且它们的泛化电路在知识转移上表现有限，表明经过“领悟”的模型可能并不比未经历此阶段的模型有显著优势。"}}
{"id": "2601.09048", "pdf": "https://arxiv.org/pdf/2601.09048", "abs": "https://arxiv.org/abs/2601.09048", "authors": ["Yuki Kobayashi", "Koichi Toida"], "title": "Immersive XR That Moves People: How XR Advertising Transforms Comprehension, Empathy, and Behavioural Intention", "categories": ["cs.HC"], "comment": "8 pages, 3 figures. Experimental study comparing immersive XR and non-immersive 2D advertising", "summary": "Extended Reality (XR) affords an enhanced sense of bodily presence that supports experiential modes of comprehension and affective engagement which exceed the possibilities of conventional information delivery. Nevertheless, the psychological processes engendered by XR, and the manner in which these processes inform subsequent behavioural intentions, remain only partially delineated. The present study addresses this issue within an applied context by comparing non-immersive 2D viewing advertising with immersive XR experiential advertising. We examined whether XR strengthens internal responses to a product, specifically perceived comprehension and empathy, and whether these responses, in turn, influence the behavioural outcome of purchase intention. A repeated-measures two-way ANOVA demonstrated a significant main effect of advertising modality, with XR yielding higher ratings on all evaluative dimensions. Mediation analysis further indicated that the elevation in purchase intention was mediated by empathy, whereas no significant mediating effect was observed for comprehension within the scope of this study. These findings suggest that immersive XR experiences augment empathic engagement with virtual products, and that this enhanced empathy plays a pivotal role in shaping subsequent behavioural intentions.", "AI": {"tldr": "研究比较了非沉浸式2D广告与沉浸式XR体验广告对产品感知理解、共情及购买意图的影响。", "motivation": "探讨XR如何通过增强身体存在感和支持情感参与来超越传统信息传递方式，以及这种新形式的广告如何影响后续的行为意向。", "method": "采用重复测量双因素ANOVA分析不同广告模式的效果，并进行中介分析以探究共情和理解在购买意图中的作用。", "result": "XR广告提升了所有评价维度上的评分，尤其是增强了对产品的共情。这种增强的共情进一步促进了购买意向。", "conclusion": "沉浸式XR体验能提升用户与虚拟产品的情感共鸣，并且这一增强的共情在形成后续行为意向中发挥了关键作用。"}}
{"id": "2601.09045", "pdf": "https://arxiv.org/pdf/2601.09045", "abs": "https://arxiv.org/abs/2601.09045", "authors": ["Hasan Tarik Akbaba", "Efe Bozkir", "Anna Puhl", "Süleyman Özdel", "Enkelejda Kasneci"], "title": "Exploring Organizational Readiness and Ecosystem Coordination for Industrial XR", "categories": ["cs.HC", "cs.CY"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Extended Reality (XR) offers transformative potential for industrial support, training, and maintenance; yet, widespread adoption lags despite demonstrated occupational value and hardware maturity. Organizations successfully implement XR in isolated pilots, yet struggle to scale these into sustained operational deployment, a phenomenon we characterize as the ``Pilot Trap.'' This study examines this phenomenon through a qualitative ecosystem analysis of 17 expert interviews across technology providers, solution integrators, and industrial adopters. We identify a ``Great Inversion'' in adoption barriers: critical constraints have shifted from technological maturity to organizational readiness (e.g., change management, key performance indicator alignment, and political resistance). While hardware ergonomics and usability remain relevant, our findings indicate that systemic misalignments between stakeholder incentives are the primary cause of friction preventing enterprise integration. We conclude that successful industrial XR adoption requires a shift from technology-centric piloting to a problem-first, organizational transformation approach, necessitating explicit ecosystem-level coordination.", "AI": {"tldr": "本文探讨了组织准备和生态系统协调对于工业扩展现实（XR）应用的影响。", "motivation": "尽管XR技术在硬件成熟度和职业价值上有所体现，但其广泛采用仍面临挑战，尤其是在从试点到持续运营部署方面遇到了所谓的“试点陷阱”。", "method": "通过17个专家访谈的质性生态系统分析，涵盖了技术供应商、解决方案集成商以及工业采用者。", "result": "研究发现主要障碍已从技术成熟度转移到了组织准备上，如变革管理、关键绩效指标对齐和政治阻力等，并认为系统性的利益相关者激励不对齐是企业整合的主要摩擦原因。", "conclusion": "成功的工业XR应用需要从以技术为中心的试点转向问题导向的组织转型方法，这要求显式的生态系统级协调。"}}
{"id": "2601.09044", "pdf": "https://arxiv.org/pdf/2601.09044", "abs": "https://arxiv.org/abs/2601.09044", "authors": ["Fei Tan", "Ashok Vardhan Addala", "Bruno Astuto Arouche Nunes", "Xucheng Zhu", "Ravi Soni"], "title": "POWDR: Pathology-preserving Outpainting with Wavelet Diffusion for 3D MRI", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Medical imaging datasets often suffer from class imbalance and limited availability of pathology-rich cases, which constrains the performance of machine learning models for segmentation, classification, and vision-language tasks. To address this challenge, we propose POWDR, a pathology-preserving outpainting framework for 3D MRI based on a conditioned wavelet diffusion model. Unlike conventional augmentation or unconditional synthesis, POWDR retains real pathological regions while generating anatomically plausible surrounding tissue, enabling diversity without fabricating lesions. Our approach leverages wavelet-domain conditioning to enhance high-frequency detail and mitigate blurring common in latent diffusion models. We introduce a random connected mask training strategy to overcome conditioning-induced collapse and improve diversity outside the lesion. POWDR is evaluated on brain MRI using BraTS datasets and extended to knee MRI to demonstrate tissue-agnostic applicability. Quantitative metrics (FID, SSIM, LPIPS) confirm image realism, while diversity analysis shows significant improvement with random-mask training (cosine similarity reduced from 0.9947 to 0.9580; KL divergence increased from 0.00026 to 0.01494). Clinically relevant assessments reveal gains in tumor segmentation performance using nnU-Net, with Dice scores improving from 0.6992 to 0.7137 when adding 50 synthetic cases. Tissue volume analysis indicates no significant differences for CSF and GM compared to real images. These findings highlight POWDR as a practical solution for addressing data scarcity and class imbalance in medical imaging. The method is extensible to multiple anatomies and offers a controllable framework for generating diverse, pathology-preserving synthetic data to support robust model development.", "AI": {"tldr": "提出POWDR，一种基于条件小波扩散模型的3D MRI病理保留外插框架。", "motivation": "医疗成像数据集常面临类别不平衡和病变丰富的案例有限的问题，限制了机器学习模型在分割、分类和视觉-语言任务中的性能。为此，提出POWDR解决这一挑战。", "method": "POWDR利用条件小波扩散模型，在保留真实病理区域的同时生成解剖上合理的周围组织。引入随机连通掩模训练策略以克服条件诱发的崩溃，并提高病变外的多样性。", "result": "在BraTS脑MRI数据集上的评估显示，使用50个合成案例时nnU-Net肿瘤分割性能有所提升（Dice分数从0.6992增至0.7137）。图像真实度通过FID、SSIM和LPIPS量化指标验证。", "conclusion": "POWDR作为解决医疗成像中数据稀缺和类别不平衡问题的实际解决方案，其方法可扩展到多种解剖结构，并提供一个可控框架来生成多样化且病理保留的合成数据以支持强大模型开发。"}}
{"id": "2601.09042", "pdf": "https://arxiv.org/pdf/2601.09042", "abs": "https://arxiv.org/abs/2601.09042", "authors": ["Neelkamal Bhuyan", "Debankur Mukherjee", "Adam Wierman"], "title": "SCaLE: Switching Cost aware Learning and Exploration", "categories": ["cs.LG", "cs.DS", "math.OC", "math.PR", "stat.ML"], "comment": "42 pages", "summary": "This work addresses the fundamental problem of unbounded metric movement costs in bandit online convex optimization, by considering high-dimensional dynamic quadratic hitting costs and $\\ell_2$-norm switching costs in a noisy bandit feedback model. For a general class of stochastic environments, we provide the first algorithm SCaLE that provably achieves a distribution-agnostic sub-linear dynamic regret, without the knowledge of hitting cost structure. En-route, we present a novel spectral regret analysis that separately quantifies eigenvalue-error driven regret and eigenbasis-perturbation driven regret. Extensive numerical experiments, against online-learning baselines, corroborate our claims, and highlight statistical consistency of our algorithm.", "AI": {"tldr": "本文提出了SCaLE算法，以解决带有限制条件的在线凸优化问题中的无界度量移动成本。", "motivation": "动机是解决高维动态二次打击成本和未知切换成本结构下的带噪声强盗反馈模型中无界度量移动成本的问题。", "method": "该论文提出了一种称为SCaLE的新算法，能够在没有了解具体成本结构的情况下，实现分布无关的次线性动态后悔值，并使用谱悔分析来单独量化由特征值误差驱动和特征基扰动驱动的悔值。", "result": "实验结果表明，所提出的SCaLE算法在与在线学习基准的比较中表现出统计一致性，并证实了其算法的有效性和理论上的宣称。", "conclusion": "结论指出，SCaLE算法成功解决了带有限制条件下的动态后悔问题，且通过谱悔分析验证了算法的有效性。"}}
{"id": "2601.09041", "pdf": "https://arxiv.org/pdf/2601.09041", "abs": "https://arxiv.org/abs/2601.09041", "authors": ["Samhita Bollepally", "Aurora Sloman-Moll", "Takashi Yamauchi"], "title": "Can LLMs interpret figurative language as humans do?: surface-level vs representational similarity", "categories": ["cs.CL", "cs.AI"], "comment": "17 pages, 5 figures", "summary": "Large language models generate judgments that resemble those of humans. Yet the extent to which these models align with human judgments in interpreting figurative and socially grounded language remains uncertain. To investigate this, human participants and four instruction-tuned LLMs of different sizes (GPT-4, Gemma-2-9B, Llama-3.2, and Mistral-7B) rated 240 dialogue-based sentences representing six linguistic traits: conventionality, sarcasm, funny, emotional, idiomacy, and slang. Each of the 240 sentences was paired with 40 interpretive questions, and both humans and LLMs rated these sentences on a 10-point Likert scale. Results indicated that humans and LLMs aligned at the surface level with humans, but diverged significantly at the representational level, especially in interpreting figurative sentences involving idioms and Gen Z slang. GPT-4 most closely approximates human representational patterns, while all models struggle with context-dependent and socio-pragmatic expressions like sarcasm, slang, and idiomacy.", "AI": {"tldr": "研究比较了大型语言模型与人类在解读比喻性和社会相关语言方面的相似性。", "motivation": "探讨大型语言模型是否以及在多大程度上能像人类一样理解和解释比喻和社会相关的语言。", "method": "通过让人类参与者和四种不同大小的指令微调过的LLM（GPT-4，Gemma-2-9B，Llama-3.2，Mistral-7B）评估包含六种语言特征的240个对话句子来比较他们的理解差异。", "result": "结果显示人类和大型语言模型在表面相似性上一致，但在解释涉及成语和Gen Z俚语等比喻性句子时存在显著分歧。GPT-4最接近人类的理解模式，所有模型都难以处理依赖上下文和社会语用的表达如讽刺、俚语和成语。", "conclusion": "大型语言模型在表面相似性上与人类一致，但在解释复杂的社会语境和比喻性的语言方面仍存在挑战，尤其是在理解依赖文化背景的表达时。"}}
{"id": "2601.09040", "pdf": "https://arxiv.org/pdf/2601.09040", "abs": "https://arxiv.org/abs/2601.09040", "authors": ["Jonas Römer", "Timo Dickscheid"], "title": "Depth-Wise Representation Development Under Blockwise Self-Supervised Learning for Video Vision Transformers", "categories": ["cs.CV"], "comment": null, "summary": "End-to-end backpropagation couples all layers through a global error signal, enabling coordinated learning but requiring long-range credit assignment. Motivated by recent progress in blockwise self-supervised learning (BWSSL), we ask whether masked video transformers can be trained without end-to-end backpropagation. Applying BWSSL to masked video modeling remains relatively underexplored and must handle spatiotemporal context and long-range temporal structure. More broadly, analyses that compare BWSSL and end-to-end training in terms of learning dynamics and depth-wise representation development remain sparse. We apply blockwise learning to a masked autoencoding video vision transformer by partitioning the encoder into blocks, each of which is optimized with a local masked reconstruction loss. Across model sizes and partition granularities, training converges and yields representations close to matched end-to-end baselines under linear-probe and retrieval proxies. In order to compare intermediate representations, we analyze depth-wise decodability, inter-block similarity, and patch-level diagnostics. Blockwise training exposes higher-level structure earlier, while later blocks saturate and operate in a more geometry-preserving regime. It can also induce token-level shifts consistent with stronger early mixing that pooled metrics can miss. These findings point to late-block saturation and interface formation as contributors to the remaining gap.", "AI": {"tldr": "研究了在视频视觉变换器中使用块式自监督学习（BWSSL）替代端到端反向传播的方法，以减少长距离信用分配的需求。", "motivation": "受到块式自监督学习的最新进展启发，作者探讨了是否可以在不使用端到端反向传播的情况下训练掩码视频变换器，特别是考虑到其在处理空间-时间上下文和长期结构方面的挑战。", "method": "通过将编码器分割成多个块，并对每个块应用局部掩码重构损失来优化，实现了块式学习应用于掩码自动编码视频视觉变换器的方法。", "result": "跨不同模型大小和分区粒度，训练收敛并产生接近端到端基线的表示形式。研究还揭示了更高层次结构在早期暴露，并且后期模块趋于饱和，在一个更保几何形态的环境中操作。", "conclusion": "块式学习方法虽然显示出一些优势，如早期更高的混合效果和早期高层结构曝光，但与端到端训练相比仍然存在差距，这些差距可能源于晚期模块的饱和及接口形成。"}}
{"id": "2601.09037", "pdf": "https://arxiv.org/pdf/2601.09037", "abs": "https://arxiv.org/abs/2601.09037", "authors": ["M Mahmudul Hasan Sajeeb", "Corentin Delacour", "Kevin Callahan-Coray", "Sanjay Seshan", "Tathagata Srimani", "Kerem Y. Camsari"], "title": "Probabilistic Computers for MIMO Detection: From Sparsification to 2D Parallel Tempering", "categories": ["cs.ET", "cond-mat.dis-nn", "cs.DC"], "comment": null, "summary": "Probabilistic computers built from p-bits offer a promising path for combinatorial optimization, but the dense connectivity required by real-world problems scales poorly in hardware. Here, we address this through graph sparsification with auxiliary copy variables and demonstrate a fully on-chip parallel tempering solver on an FPGA. Targeting MIMO detection, a dense, NP-hard problem central to wireless communications, we fit 15 temperature replicas of a 128-node sparsified system (1,920 p-bits) entirely on-chip and achieve bit error rates significantly below conventional linear detectors. We report complete end-to-end solution times of 4.7 ms per instance, with all loading, sampling, readout, and verification overheads included. ASIC projections in 7 nm technology indicate about 90 MHz operation with less than 200 mW power dissipation, suggesting that massive parallelism across multiple chips could approach the throughput demands of next-generation wireless systems. However, sparsification introduces sensitivity to the copy-constraint strength. Employing Two-Dimensional Parallel Tempering (2D-PT), which exchanges replicas across both temperature and constraint dimensions, we demonstrate over 10X faster convergence without manual parameter tuning. These results establish an on-chip p-bit architecture and a scalable algorithmic framework for dense combinatorial optimization.", "AI": {"tldr": "本文介绍了在FPGA上实现的基于概率计算机（p-bits）和图稀疏化技术的MIMO检测问题解决方法，通过二维平行温控技术实现了快速收敛。", "motivation": "解决传统硬件密集型连接要求导致性能不佳的问题，并提高无线通信中关键的MIMO检测算法在硬件上的实现效率。", "method": "使用辅助复制变量进行图稀疏化处理，并结合完全集成在芯片内的并行温控求解器，采用二维平行温控（2D-PT）技术来加速收敛过程。", "result": "实现了15个温度副本的128节点稀疏系统(共1,920 p-bits)全部在单个FPGA上实现，并达到了低于传统线性检测器的比特误码率，以及4.7毫秒/实例的完整端到端求解时间。", "conclusion": "通过概率计算机架构和二维平行温控算法框架，在硬件资源限制条件下实现了密集组合优化问题的有效处理。"}}
{"id": "2601.09035", "pdf": "https://arxiv.org/pdf/2601.09035", "abs": "https://arxiv.org/abs/2601.09035", "authors": ["Aniesh Chawla", "Udbhav Prasad"], "title": "A Decompilation-Driven Framework for Malware Detection with Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": "6 pages, published in 2025 IEMCON", "summary": "The parallel evolution of Large Language Models (LLMs) with advanced code-understanding capabilities and the increasing sophistication of malware presents a new frontier for cybersecurity research. This paper evaluates the efficacy of state-of-the-art LLMs in classifying executable code as either benign or malicious. We introduce an automated pipeline that first decompiles Windows executable into a C code using Ghidra disassembler and then leverages LLMs to perform the classification. Our evaluation reveals that while standard LLMs show promise, they are not yet robust enough to replace traditional anti-virus software. We demonstrate that a fine-tuned model, trained on curated malware and benign datasets, significantly outperforms its vanilla counterpart. However, the performance of even this specialized model degrades notably when encountering newer malware. This finding demonstrates the critical need for continuous fine-tuning with emerging threats to maintain model effectiveness against the changing coding patterns and behaviors of malicious software.", "AI": {"tldr": "本文评估了大型语言模型（LLMs）在识别恶意软件和良性代码方面的有效性，通过自动化的反编译流程将Windows可执行文件转换为C代码，并使用LLMs进行分类。", "motivation": "随着大型语言模型的发展和恶意软件复杂性的增加，本文旨在探索这些先进模型是否能够有效区分和检测恶意软件。", "method": "该研究引入了一个自动化管道，首先通过Ghidra反编译器将Windows可执行文件转换为C代码，然后利用LLMs进行分类。同时，测试了未经调优的模型以及在特定数据集上进行了微调后的模型性能。", "result": "评估结果表明，虽然标准的大型语言模型显示出潜在的应用价值，但它们尚未成熟到可以取代传统的反病毒软件的程度。经过特殊训练的数据微调的模型表现优于未调整过的模型，但在面对新出现的恶意软件时，其性能明显下降。", "conclusion": "研究结论指出，为了保持对抗不断变化的恶意软件编码模式和行为的有效性，持续对模型进行更新和微调以应对新兴威胁至关重要。"}}
{"id": "2601.09033", "pdf": "https://arxiv.org/pdf/2601.09033", "abs": "https://arxiv.org/abs/2601.09033", "authors": ["Yejoon Song", "Bandi Kim", "Yeju Kwon", "Sung Park"], "title": "Exploring the Effects of Generative AI Assistance on Writing Self-Efficacy", "categories": ["cs.HC"], "comment": null, "summary": "Generative AI (GenAI) is increasingly used in academic writing, yet its effects on students' writing self-efficacy remain contingent on how assistance is configured. This pilot study investigates how ideation-level, sentence-level, full-process, and no AI support differentially shape undergraduate writers' self-efficacy using a 2 by 2 experimental design with Korean undergraduates completing argumentative writing tasks. Results indicate that AI assistance does not uniformly enhance self-efficacy full AI support produced high but stable self-efficacy alongside signs of reduced ownership, sentence-level AI support led to consistent self-efficacy decline, and ideation-level AI support was associated with both high self-efficacy and positive longitudinal change. These findings suggest that the locus of AI intervention, rather than the amount of assistance, is critical in fostering writing self-efficacy while preserving learner agency.", "AI": {"tldr": "研究探讨了不同层次的生成式AI辅助对本科生写作自我效能感的影响。", "motivation": "尽管生成式AI在学术写作中被广泛使用，但其如何影响学生的写作自我效能感尚不明确。因此，本研究旨在探索不同类型的AI支持（即创意层面、句子层面和全过程）对学生写作自我效能感的具体影响。", "method": "本研究采用2x2实验设计，让韩国本科生完成论说文写作任务，并比较了完全AI辅助、句子层面的AI辅助、创意层面的AI辅助以及没有AI辅助的情况下的效果。", "result": "研究表明，AI辅助并不总是能提升自我效能感。完全AI支持导致较高的但稳定的自我效能感和所有权减少迹象；句子层面的AI支持会导致自我效能感持续下降；创意层面的AI支持则与高自我效能感及积极的纵向变化相关联。", "conclusion": "研究结果表明，AI干预的位置而非辅助的数量是培养写作自我效能感的关键，同时保持学习者的自主权。"}}
{"id": "2601.09032", "pdf": "https://arxiv.org/pdf/2601.09032", "abs": "https://arxiv.org/abs/2601.09032", "authors": ["Logan Ritchie", "Sushant Mehta", "Nick Heiner", "Mason Yu", "Edwin Chen"], "title": "The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments", "categories": ["cs.AI"], "comment": null, "summary": "The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \\emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formation, (3) adaptability, (4) groundedness, and (5) common-sense reasoning. Even the best-performing models fail approximately 40\\% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. We introduce a task-centric design methodology for RL environments that emphasizes diversity and domain expert contributions, provide detailed failure analysis, and discuss implications for agent development. Our findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.", "AI": {"tldr": "评估前沿AI模型在现实环境中完成多步骤任务的能力，并构建了一个代理能力层次结构。", "motivation": "随着大语言模型的发展，AI的评估已经从单轮响应转向了交互式环境中的多步骤任务。该论文旨在研究这些前沿模型如何应对现实世界中的任务。", "method": "在Surge提供的一个包含150个工作任务的真实电商强化学习环境中，对前沿AI模型进行测试并分析它们的表现。", "result": "发现了代理能力的层次结构：工具使用、规划和目标设定、适应性、现实结合能力和常识推理。即使是最优秀的模型也大约失败了40%的任务，并且这些失败能够按照上述层次结构预测。", "conclusion": "尽管当前前沿AI模型可以展示出连贯的多步骤行为，但在实现真实工作场景中的人类水平任务完成能力前还有相当大的差距。"}}
{"id": "2601.09031", "pdf": "https://arxiv.org/pdf/2601.09031", "abs": "https://arxiv.org/abs/2601.09031", "authors": ["Xuetao Li", "Wenke Huang", "Mang Ye", "Jifeng Xuan", "Bo Du", "Sheng Liu", "Miao Li"], "title": "Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Humanoid robot manipulation is a crucial research area for executing diverse human-level tasks, involving high-level semantic reasoning and low-level action generation. However, precise scene understanding and sample-efficient learning from human demonstrations remain critical challenges, severely hindering the applicability and generalizability of existing frameworks. This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, facilitating both high-level skill reasoning and data-efficient motion synthesis. To ground high-level reasoning in physical reality, we leverage lightweight 2D geometric inductive biases to enable precise 3D scene understanding within the vision-language model. Specifically, we construct a Long-horizon Geometric Prior Skill Selector that effectively aligns the semantic instructions with spatial constraints, ultimately achieving robust generalization in unseen environments. For the data efficiency issue in robotic action generation, we introduce a Recursive Adaptive Spiking Network. We parameterize robot-object interactions via recursive spiking for spatiotemporal consistency, fully distilling long-horizon dynamic features while mitigating the overfitting issue in sparse demonstration scenarios. Extensive experiments are conducted across the Maniskill simulation benchmark and three heterogeneous real-world robotic systems, encompassing a custom-developed humanoid, a desktop manipulator, and a commercial robotic platform. Empirical results substantiate the superiority of our method over state-of-the-art baselines and validate the efficacy of the proposed modules in diverse generalization scenarios. To facilitate reproducibility, the source code and video demonstrations are publicly available at https://github.com/xtli12/RGMP-S.git.", "AI": {"tldr": "开发了一种名为RGMP-S的新方法，旨在通过几何先验和递归尖峰特征学习实现高效的人形机器人操作。", "motivation": "人形机器人的操作面临精确场景理解和从人类演示中进行样本有效学习的挑战，这限制了现有框架的应用性和通用性。", "method": "提出了一种结合轻量级二维几何归纳偏置和递归适应尖峰网络的方法，以实现语义指令与空间约束的有效对齐，并减轻稀疏示范场景中的过度拟合问题。", "result": "通过Maniskill模拟基准测试及三个不同的实际机器人系统验证了该方法优于现有基线，并证实提出的模块在多种泛化场景中有效。", "conclusion": "RGMP-S方法实现了高效的人形机器人操作，提高了对不同环境的适应性和样本效率。"}}
{"id": "2601.09029", "pdf": "https://arxiv.org/pdf/2601.09029", "abs": "https://arxiv.org/abs/2601.09029", "authors": ["Aniesh Chawla", "Udbhav Prasad"], "title": "Proactively Detecting Threats: A Novel Approach Using LLMs", "categories": ["cs.CR", "cs.AI"], "comment": "2025 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)", "summary": "Enterprise security faces escalating threats from sophisticated malware, compounded by expanding digital operations. This paper presents the first systematic evaluation of large language models (LLMs) to proactively identify indicators of compromise (IOCs) from unstructured web-based threat intelligence sources, distinguishing it from reactive malware detection approaches. We developed an automated system that pulls IOCs from 15 web-based threat report sources to evaluate six LLM models (Gemini, Qwen, and Llama variants). Our evaluation of 479 webpages containing 2,658 IOCs (711 IPv4 addresses, 502 IPv6 addresses, 1,445 domains) reveals significant performance variations. Gemini 1.5 Pro achieved 0.958 precision and 0.788 specificity for malicious IOC identification, while demonstrating perfect recall (1.0) for actual threats.", "AI": {"tldr": "本文介绍了使用大型语言模型（LLMs）主动识别来自非结构化网络威胁情报源的攻击指标（IOCs），以提高企业安全防御。", "motivation": "随着恶意软件变得越来越复杂以及数字操作范围扩大，企业面临的网络安全威胁日益加剧。传统的反应式恶意软件检测方法已不足以应对这些挑战，因此需要一种新的主动识别威胁的方法来增强企业安全性。", "method": "研究团队开发了一个自动化系统，该系统从15个网络威胁报告源中提取IOCs，并评估了6种LLMs模型（包括Gemini, Qwen和Llama变体）。他们使用包含2,658个IOCs的479个网页进行性能测试。", "result": "实验结果显示，不同的LLM模型在恶意IOC识别上的表现有显著差异。其中，Gemini 1.5 Pro达到了0.958的精度和0.788的特异性，并且对于实际威胁实现了完美的召回率（1.0）。", "conclusion": "这项研究表明，使用大型语言模型主动检测网络威胁是有效的，并具有提高企业安全性的潜力。Gemini 1.5 Pro在识别恶意IOCs方面表现出色，证明了LLMs在网络安全领域中的应用前景。"}}
{"id": "2601.09028", "pdf": "https://arxiv.org/pdf/2601.09028", "abs": "https://arxiv.org/abs/2601.09028", "authors": ["Fengran Mo", "Zhan Su", "Yuchen Hui", "Jinghan Zhang", "Jia Ao Sun", "Zheyuan Liu", "Chao Zhang", "Tetsuya Sakai", "Jian-Yun Nie"], "title": "OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted by ACM WWW 2026", "summary": "The development of large language models (LLMs) has achieved superior performance in a range of downstream tasks, including LLM-based retrieval-augmented generation (RAG). The quality of generated content heavily relies on the usefulness of the retrieved information and the capacity of LLMs' internal information processing mechanism to incorporate it in answer generation. It is generally assumed that the retrieved information is relevant to the question. However, the retrieved information may have a variable degree of relevance and usefulness, depending on the question and the document collection. It is important to take into account the relevance of the retrieved information in answer generation. In this paper, we propose OpenDecoder, a new approach that leverages explicit evaluation of the retrieved information as quality indicator features for generation. We aim to build a RAG model that is more robust to varying levels of noisy context. Three types of explicit evaluation information are considered: relevance score, ranking score, and QPP (query performance prediction) score. The experimental results on five benchmark datasets demonstrate the effectiveness and better robustness of OpenDecoder by outperforming various baseline methods. Importantly, this paradigm is flexible to be integrated with the post-training of LLMs for any purposes and incorporated with any type of external indicators.", "AI": {"tldr": "本文提出了一种新的方法OpenDecoder，它利用显式评估检索信息的质量指标特征来增强生成过程。", "motivation": "尽管大型语言模型（LLMs）在下游任务中表现优异，但生成内容的质量依赖于检索到的信息的相关性和有用性，而这些可能受到问题和文档集合的影响。因此，考虑检索信息的相关性对于提高答案质量至关重要。", "method": "OpenDecoder通过引入显式评估的三种类型指标：相关度评分、排名评分和查询性能预测（QPP）评分来改善生成过程，并且该方法可以灵活地与LLMs的后训练集成并与其他类型的外部指标结合使用。", "result": "实验结果表明，在五个基准数据集上的表现优于各种基线方法，展示了OpenDecoder的有效性和更好的鲁棒性。", "conclusion": "研究显示了通过显式评估检索信息来改进RAG模型生成质量的潜力和灵活性，为构建更健壮的RAG系统提供了新的视角。"}}
{"id": "2601.09025", "pdf": "https://arxiv.org/pdf/2601.09025", "abs": "https://arxiv.org/abs/2601.09025", "authors": ["Tong Wu", "Tayab Uddin Wara", "Daniel Hernandez", "Sidong Lei"], "title": "Universal Latent Homeomorphic Manifolds: Cross-Domain Representation Learning via Homeomorphism Verification", "categories": ["eess.IV", "cs.LG", "eess.SP"], "comment": null, "summary": "We present the Universal Latent Homeomorphic Manifold (ULHM), a framework that unifies semantic representations (e.g., human descriptions, diagnostic labels) and observation-driven machine representations (e.g., pixel intensities, sensor readings) into a single latent structure. Despite originating from fundamentally different pathways, both modalities capture the same underlying reality. We establish \\emph{homeomorphism}, a continuous bijection preserving topological structure, as the mathematical criterion for determining when latent manifolds induced by different semantic-observation pairs can be rigorously unified. This criterion provides theoretical guarantees for three critical applications: (1) semantic-guided sparse recovery from incomplete observations, (2) cross-domain transfer learning with verified structural compatibility, and (3) zero-shot compositional learning via valid transfer from semantic to observation space. Our framework learns continuous manifold-to-manifold transformations through conditional variational inference, avoiding brittle point-to-point mappings. We develop practical verification algorithms, including trust, continuity, and Wasserstein distance metrics, that empirically validate homeomorphic structure from finite samples. Experiments demonstrate: (1) sparse image recovery from 5\\% of CelebA pixels and MNIST digit reconstruction at multiple sparsity levels, (2) cross-domain classifier transfer achieving 86.73\\% accuracy from MNIST to Fashion-MNIST without retraining, and (3) zero-shot classification on unseen classes achieving 89.47\\% on MNIST, 84.70\\% on Fashion-MNIST, and 78.76\\% on CIFAR-10. Critically, the homeomorphism criterion correctly rejects incompatible datasets, preventing invalid unification and providing a feasible way to principled decomposition of general foundation models into verified domain-specific components.", "AI": {"tldr": "提出通用潜在同胚流形（ULHM）框架，用于统一语义表示和观察驱动机器表示，并通过同胚验证实现跨域表征学习。", "motivation": "旨在解决不同模态如何能够捕获同一底层现实的问题，并提供理论保证以支持稀疏恢复、跨域迁移学习以及零样本组合式学习等应用。", "method": "通过条件变分推理学习连续流形到流形的变换，开发信任度量、连续性和Wasserstein距离指标来验证有限样本中的同胚结构。", "result": "实验展示了从CelebA和MNIST稀疏像素恢复图像，跨域分类器转移实现86.73%准确率，以及在未见类别的零样本分类上获得高精度。", "conclusion": "提出的方法能够正确拒绝不兼容的数据集，提供一种可行的方式将通用基础模型分解为经过验证的领域特定组件。"}}
{"id": "2601.09018", "pdf": "https://arxiv.org/pdf/2601.09018", "abs": "https://arxiv.org/abs/2601.09018", "authors": ["Samuel Myren", "Nidhi Parikh", "Natalie Klein"], "title": "Meta-learning to Address Data Shift in Time Series Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Across engineering and scientific domains, traditional deep learning (TDL) models perform well when training and test data share the same distribution. However, the dynamic nature of real-world data, broadly termed \\textit{data shift}, renders TDL models prone to rapid performance degradation, requiring costly relabeling and inefficient retraining. Meta-learning, which enables models to adapt quickly to new data with few examples, offers a promising alternative for mitigating these challenges. Here, we systematically compare TDL with fine-tuning and optimization-based meta-learning algorithms to assess their ability to address data shift in time-series classification. We introduce a controlled, task-oriented seismic benchmark (SeisTask) and show that meta-learning typically achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller model architectures. As data availability and model capacity increase, its advantages diminish, with TDL with fine-tuning performing comparably. Finally, we examine how task diversity influences meta-learning and find that alignment between training and test distributions, rather than diversity alone, drives performance gains. Overall, this work provides a systematic evaluation of when and why meta-learning outperforms TDL under data shift and contributes SeisTask as a benchmark for advancing adaptive learning research in time-series domains.", "AI": {"tldr": "本文通过对比传统深度学习和元学习方法在处理时间序列分类中数据偏移问题的表现，评估了不同方法的适应性和稳定性，并提供了SeisTask作为基准测试。", "motivation": "传统深度学习模型在面对动态变化的真实世界数据时性能会快速下降。元学习可以通过少量样本快速适应新数据，有望缓解这一挑战。", "method": "本文系统地比较了传统深度学习与微调以及基于优化的元学习算法，在时间序列分类任务中处理数据偏移的能力，并引入了一个受控的任务导向地震基准（SeisTask）。", "result": "元学习通常能够实现更快和更稳定的适应性，特别是在数据稀缺和小模型架构的情况下减少了过拟合。随着数据量和模型容量的增加，其优势逐渐减弱。", "conclusion": "本文提供了一个系统性的评估，说明了在何种情况下以及为何元学习能够在处理数据偏移时优于传统深度学习，并贡献了SeisTask作为时间序列领域自适应学习研究的基准测试。"}}
{"id": "2601.09012", "pdf": "https://arxiv.org/pdf/2601.09012", "abs": "https://arxiv.org/abs/2601.09012", "authors": ["Mara Finkelstein", "Isaac Caswell", "Tobias Domhan", "Jan-Thorsten Peter", "Juraj Juraska", "Parker Riley", "Daniel Deutsch", "Cole Dilanni", "Colin Cherry", "Eleftheria Briakou", "Elizabeth Nielsen", "Jiaming Luo", "Kat Black", "Ryan Mullins", "Sweta Agrawal", "Wenda Xu", "Erin Kats", "Stephane Jaskiewicz", "Markus Freitag", "David Vilar"], "title": "TranslateGemma Technical Report", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present TranslateGemma, a suite of open machine translation models based on the Gemma 3 foundation models. To enhance the inherent multilingual capabilities of Gemma 3 for the translation task, we employ a two-stage fine-tuning process. First, supervised fine-tuning is performed using a rich mixture of high-quality large-scale synthetic parallel data generated via state-of-the-art models and human-translated parallel data. This is followed by a reinforcement learning phase, where we optimize translation quality using an ensemble of reward models, including MetricX-QE and AutoMQM, targeting translation quality. We demonstrate the effectiveness of TranslateGemma with human evaluation on the WMT25 test set across 10 language pairs and with automatic evaluation on the WMT24++ benchmark across 55 language pairs. Automatic metrics show consistent and substantial gains over the baseline Gemma 3 models across all sizes. Notably, smaller TranslateGemma models often achieve performance comparable to larger baseline models, offering improved efficiency. We also show that TranslateGemma models retain strong multimodal capabilities, with enhanced performance on the Vistra image translation benchmark. The release of the open TranslateGemma models aims to provide the research community with powerful and adaptable tools for machine translation.", "AI": {"tldr": "本文介绍了TranslateGemma，一套基于Gemma 3基础模型的开放机器翻译模型套件。", "motivation": "为了提升Gemma 3在翻译任务上的多语言能力，研究者们开发了TranslateGemma以提供强大的且可适应的研究工具。", "method": "采用两阶段微调过程：第一阶段是使用高质量大规模合成平行数据和人工翻译的平行数据进行监督微调；第二阶段通过强化学习优化翻译质量，利用包括MetricX-QE和AutoMQM在内的奖励模型集合。", "result": "通过WMT25测试集上的10种语言对的人类评估以及在WMT24++基准上覆盖55种语言对的自动评估证明了TranslateGemma的有效性。自动度量显示与基线Gemma 3模型相比，在所有规模下都有显著提升。", "conclusion": "研究表明，较小的TranslateGemma模型经常能达到较大基线模型的性能，同时提高了效率，并且在Vistra图像翻译基准上也表现出了增强的多模态能力。"}}
{"id": "2601.09008", "pdf": "https://arxiv.org/pdf/2601.09008", "abs": "https://arxiv.org/abs/2601.09008", "authors": ["Amar Kavuri", "Howard C. Gifford", "Mini Das"], "title": "Changes in Visual Attention Patterns for Detection Tasks due to Dependencies on Signal and Background Spatial Frequencies", "categories": ["cs.CV", "eess.IV", "eess.SP", "physics.med-ph"], "comment": "21 pages, 7 images", "summary": "We aim to investigate the impact of image and signal properties on visual attention mechanisms during a signal detection task in digital images. The application of insight yielded from this work spans many areas of digital imaging where signal or pattern recognition is involved in complex heterogenous background. We used simulated tomographic breast images as the platform to investigate this question. While radiologists are highly effective at analyzing medical images to detect and diagnose diseases, misdiagnosis still occurs. We selected digital breast tomosynthesis (DBT) images as a sample medical images with different breast densities and structures using digital breast phantoms (Bakic and XCAT). Two types of lesions (with distinct spatial frequency properties) were randomly inserted in the phantoms during projections to generate abnormal cases. Six human observers participated in observer study designed for a locating and detection of an 3-mm sphere lesion and 6-mm spicule lesion in reconstructed in-plane DBT slices. We collected eye-gaze data to estimate gaze metrics and to examine differences in visual attention mechanisms. We found that detection performance in complex visual environments is strongly constrained by later perceptual stages, with decision failures accounting for the largest proportion of errors. Signal detectability is jointly influenced by both target morphology and background complexity, revealing a critical interaction between local signal features and global anatomical noise. Increased fixation duration on spiculated lesions suggests that visual attention is differentially engaged depending on background and signal spatial frequency dependencies.", "AI": {"tldr": "研究视觉注意力模式在检测任务中由于信号和背景空间频率依赖性变化的影响。", "motivation": "探讨图像和信号特性如何影响数字图像中的信号检测任务的视觉注意机制，以提高复杂异质背景下的信号或模式识别应用。", "method": "使用模拟断层乳腺影像作为研究平台，插入两种不同空间频率特性的病变，并通过六个人类观察者进行眼动数据收集，评估在重建的DBT切片中3毫米球形病变和6毫米棘状病变的定位与检测表现。", "result": "发现视觉注意力机制因信号和背景的空间频率依赖性而差异性参与，复杂的视觉环境下的检测性能受感知阶段影响较大，并且错误主要由决策失败导致。信号可检测性同时受到目标形态学和背景复杂度的影响。", "conclusion": "表明视觉注意在面对不同空间频率特性的病变时有不同的响应模式，并揭示了局部信号特征与全局解剖噪声之间的重要互动关系，有助于改进医学影像中的疾病诊断准确率。"}}
{"id": "2601.09006", "pdf": "https://arxiv.org/pdf/2601.09006", "abs": "https://arxiv.org/abs/2601.09006", "authors": ["Marc-Antoine Fortin", "Anne Louise Kristoffersen", "Paal Erik Goa"], "title": "GOUHFI 2.0: A Next-Generation Toolbox for Brain Segmentation and Cortex Parcellation at Ultra-High Field MRI", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": null, "summary": "Ultra-High Field MRI (UHF-MRI) is increasingly used in large-scale neuroimaging studies, yet automatic brain segmentation and cortical parcellation remain challenging due to signal inhomogeneities, heterogeneous contrasts and resolutions, and the limited availability of tools optimized for UHF data. Standard software packages such as FastSurferVINN and SynthSeg+ often yield suboptimal results when applied directly to UHF images, thereby restricting region-based quantitative analyses. To address this need, we introduce GOUHFI 2.0, an updated implementation of GOUHFI that incorporates increased training data variability and additional functionalities, including cortical parcellation and volumetry. GOUHFI 2.0 preserves the contrast- and resolution-agnostic design of the original toolbox while introducing two independently trained 3D U-Net segmentation tasks. The first performs whole-brain segmentation into 35 labels across contrasts, resolutions, field strengths and populations, using a domain-randomization strategy and a training dataset of 238 subjects. Using the same training data, the second network performs cortical parcellation into 62 labels following the Desikan-Killiany-Tourville (DKT) protocol. Across multiple datasets, GOUHFI 2.0 demonstrated improved segmentation accuracy relative to the original toolbox, particularly in heterogeneous cohorts, and produced reliable cortical parcellations. In addition, the integrated volumetry pipeline yielded results consistent with standard volumetric workflows. Overall, GOUHFI 2.0 provides a comprehensive solution for brain segmentation, parcellation and volumetry across field strengths, and constitutes the first deep-learning toolbox enabling robust cortical parcellation at UHF-MRI.", "AI": {"tldr": "介绍了一个更新的工具箱GOUHFI 2.0，用于UHF-MRI脑分割和皮质划分。", "motivation": "现有的软件在处理UHF数据时效果不佳，限制了基于区域的定量分析。", "method": "GOUHFI 2.0采用了两个独立训练的3D U-Net网络任务：一个用于全脑分割（35个标签），另一个用于皮质划分（62个DKT标签）。", "result": "GOUHFI 2.0在多个数据集上表现出比原工具箱更好的分割准确性和可靠的皮质划分，并且体积测量结果与标准流程一致。", "conclusion": "GOUHFI 2.0为跨场强的脑分割、皮质划分和体积分析提供了一个全面解决方案，是首个支持UHF-MRI下可靠皮质划分的深度学习工具箱。"}}
{"id": "2601.09004", "pdf": "https://arxiv.org/pdf/2601.09004", "abs": "https://arxiv.org/abs/2601.09004", "authors": ["Xiaoyu Ji", "Chenhao Zhang", "Tyler James Downard", "Zoltan Nagy", "Ali Shakouri", "Fengqing Zhu"], "title": "Instance camera focus prediction for crystal agglomeration classification", "categories": ["cs.CV"], "comment": null, "summary": "Agglomeration refers to the process of crystal clustering due to interparticle forces. Crystal agglomeration analysis from microscopic images is challenging due to the inherent limitations of two-dimensional imaging. Overlapping crystals may appear connected even when located at different depth layers. Because optical microscopes have a shallow depth of field, crystals that are in-focus and out-of-focus in the same image typically reside on different depth layers and do not constitute true agglomeration. To address this, we first quantified camera focus with an instance camera focus prediction network to predict 2 class focus level that aligns better with visual observations than traditional image processing focus measures. Then an instance segmentation model is combined with the predicted focus level for agglomeration classification. Our proposed method has a higher agglomeration classification and segmentation accuracy than the baseline models on ammonium perchlorate crystal and sugar crystal dataset.", "AI": {"tldr": "本文提出了一种基于实例相机焦点预测网络的晶体聚集分类方法，提高了对铵 perchlorate 晶体和糖晶体数据集的聚集分类和分割准确性。", "motivation": "由于显微镜图像固有的二维限制，晶体聚集分析面临挑战，尤其是当不同深度层的晶体在图像中看起来相连时。传统焦点测量难以准确反映真实情况。", "method": "本文首先使用实例相机焦点预测网络量化了相机焦点，以更好地与视觉观察对齐，并结合实例分割模型进行聚集分类。", "result": "该方法在铵 perchlorate 晶体和糖晶体数据集上的聚集分类和分割准确性高于基线模型。", "conclusion": "通过引入实例相机焦点预测网络并将其与实例分割模型相结合，本文提出的方法有效提升了对复杂显微图像中晶体聚集的识别准确率。"}}
{"id": "2601.08989", "pdf": "https://arxiv.org/pdf/2601.08989", "abs": "https://arxiv.org/abs/2601.08989", "authors": ["Matteo Caporrella", "Stefano Leucci"], "title": "An Almost-Optimal Upper Bound on the Push Number of the Torus Puzzle", "categories": ["cs.DS"], "comment": "22 pages, 8 figures", "summary": "We study the Torus Puzzle, a solitaire game in which the elements of an input $m \\times n$ matrix need to be rearranged into a target configuration via a sequence of unit rotations (i.e., circular shifts) of rows and/or columns. Amano et al.\\ proposed a more permissive variant of the above puzzle, where each row and column rotation can shift the involved elements by any amount of positions. The number of rotations needed to solve the puzzle in the original and in the permissive variants of the puzzle are respectively known as the \\emph{push number} and the \\emph{drag number}, where the latter is always smaller than or equal to the former and admits an existential lower bound of $Ω(mn)$. While this lower bound is matched by an $O(mn)$ upper bound, the push number is not so well understood. Indeed, to the best of our knowledge, only an $O(mn \\cdot \\max\\{ m, n \\})$ upper bound is currently known. In this paper, we provide an algorithm that solves the Torus Puzzle using $O(mn \\cdot \\log \\max \\{m, n\\})$ unit rotations in a model that is more restricted than that of the original puzzle. This implies a corresponding upper bound on the push number and reduces the gap between the known upper and lower bounds from $Θ(\\max\\{m,n\\})$ to $Θ(\\log \\max\\{m, n\\})$.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.08988", "pdf": "https://arxiv.org/pdf/2601.08988", "abs": "https://arxiv.org/abs/2601.08988", "authors": ["Ananya Mantravadi", "Shivali Dalmia", "Abhishek Mukherji"], "title": "ART: Action-based Reasoning Task Benchmarking for Medical AI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. We introduce ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create challenging tasks targeting known reasoning weaknesses. Through analysis of existing benchmarks, we identify three dominant error categories: retrieval failures, aggregation errors, and conditional logic misjudgments. Our four-stage pipeline -- scenario identification, task generation, quality audit, and evaluation -- produces diverse, clinically validated tasks grounded in real patient data. Evaluating GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks shows near-perfect retrieval after prompt refinement, but substantial gaps in aggregation (28--64%) and threshold reasoning (32--38%). By exposing failure modes in action-oriented EHR reasoning, ART advances toward more reliable clinical agents, an essential step for AI systems that reduce cognitive load and administrative burden, supporting workforce capacity in high-demand care settings", "AI": {"tldr": "本文介绍了ART，一个基于行动的临床推理任务基准测试，用于评估医疗AI代理在处理电子健康记录（EHR）方面的性能。", "motivation": "现有的基准测试不能充分评估AI在涉及阈值评估、时间聚合和条件逻辑等行动基础任务上的表现。这促使了开发一个新的基准测试系统来填补这一空白，以支持更可靠的临床决策。", "method": "ART通过四阶段管道生成任务：情景识别、任务生成、质量审核和评估。这些任务基于真实的病人数据，旨在检测推理中的薄弱环节。", "result": "实验结果表明，在经过提示优化后，GPT-4o-mini和Claude 3.5 Sonnet在检索方面的表现近乎完美，但在聚合和阈值推理方面仍有显著差距（28%-64% 和 32%-38%）。", "conclusion": "ART通过揭示行动导向的EHR推理中的失败模式来推动医疗AI的发展，有助于减轻临床工作者的认知负担和行政工作量，支持在高需求护理环境中提高人力资源效率。"}}
{"id": "2601.08987", "pdf": "https://arxiv.org/pdf/2601.08987", "abs": "https://arxiv.org/abs/2601.08987", "authors": ["Mohammad Waquas Usmani", "Susmit Shannigrahi", "Michael Zink"], "title": "ABE-VVS: Attribute-Based Encrypted Volumetric Video Streaming", "categories": ["cs.CR", "cs.MM", "cs.NI", "eess.IV"], "comment": "10 pages + 1 references and 9 figures with some sub-figures", "summary": "This work introduces ABE-VVS, a framework that performs attribute based selective coordinate encryption for point cloud based volumetric video streaming, enabling lightweight yet effective digital rights management (DRM). Rather than encrypting entire point cloud frames, our approach encrypts only selected subsets of coordinates ($X, Y, Z$, or combinations), lowering computational overhead and latency while still producing strong visual distortion that prevents meaningful unauthorized viewing. Our experiments show that encrypting only the $X$ coordinates achieves effective obfuscation while reducing encryption and decryption times by up to 50% and 80%, respectively, compared to full-frame encryption. To our knowledge, this is the first work to provide a novel end-to-end evaluation of a DRM-enabled secure point cloud streaming system. We deployed a point cloud video streaming setup on the CloudLab testbed and evaluated three HTTP-based Attribute-Based Encryption (ABE) granularities - ABE-XYZ (encrypting all $X,Y,Z$ coordinates), ABE-XY, and ABE-X against conventional HTTPS/TLS secure streaming as well as an HTTP-only baseline without any security. Our streaming evaluation demonstrates that ABE-based schemes reduce server-side CPU load by up to 80% and cache CPU load by up to 63%, comparable to HTTP-only, while maintaining similar cache hit rates. Moreover, ABE-XYZ and ABE-XY exhibit lower client-side rebuffering than HTTPS, and ABE-X achieves zero rebuffering comparable to HTTP-only. Although ABE-VVS increases client-side CPU usage, the overhead is not large enough to affect streaming quality and is offset by its broader benefits, including simplified key revocation, elimination of per-client encryption, and reduced server and cache load.", "AI": {"tldr": "本文介绍了ABE-VVS框架，该框架通过基于属性的坐标选择性加密实现点云体积视频流中的轻量级数字版权管理（DRM）。", "motivation": "动机在于减少传统全帧加密带来的计算开销和延迟问题，同时提供有效的视觉混淆以阻止未经授权查看。", "method": "方法是仅对选定的X、Y或Z坐标进行加密而不是整个点云帧，以此降低计算成本并维持强视觉模糊。", "result": "实验表明仅加密X坐标可实现有效混淆并分别减少50%和80%的加密与解密时间。ABE-VVS方案在服务器端CPU负载、缓存CPU负载和客户端重缓冲方面表现出色，提升了整体流媒体质量。", "conclusion": "结论是ABE-VVS框架提供了更高效且安全的点云视频流解决方案，并通过降低计算成本实现更好的用户体验。"}}
{"id": "2601.08982", "pdf": "https://arxiv.org/pdf/2601.08982", "abs": "https://arxiv.org/abs/2601.08982", "authors": ["Constantin Kolomiiets", "Miroslav Purkrabek", "Jiri Matas"], "title": "SAM-pose2seg: Pose-Guided Human Instance Segmentation in Crowds", "categories": ["cs.CV"], "comment": "GitHub: https://github.com/MiraPurkrabek/BBoxMaskPose/", "summary": "Segment Anything (SAM) provides an unprecedented foundation for human segmentation, but may struggle under occlusion, where keypoints may be partially or fully invisible. We adapt SAM 2.1 for pose-guided segmentation with minimal encoder modifications, retaining its strong generalization. Using a fine-tuning strategy called PoseMaskRefine, we incorporate pose keypoints with high visibility into the iterative correction process originally employed by SAM, yielding improved robustness and accuracy across multiple datasets. During inference, we simplify prompting by selecting only the three keypoints with the highest visibility. This strategy reduces sensitivity to common errors, such as missing body parts or misclassified clothing, and allows accurate mask prediction from as few as a single keypoint. Our results demonstrate that pose-guided fine-tuning of SAM enables effective, occlusion-aware human segmentation while preserving the generalization capabilities of the original model. The code and pretrained models will be available at https://mirapurkrabek.github.io/BBox-MaskPose.", "AI": {"tldr": "本文提出了SAM-pose2seg，一种基于姿态引导的人体实例分割方法，在拥挤场景中提高人体分割的鲁棒性和准确性。", "motivation": "现有模型在处理遮挡情况时表现不佳，而人体关键点信息可以帮助改善这种情况。作者希望通过结合人体姿态信息来改进Segment Anything Model（SAM）在人群中的分割效果。", "method": "作者采用PoseMaskRefine策略对SAM进行微调，并引入了仅使用三个高可见性关键点的简化提示方法，以增强模型对于遮挡情况的鲁棒性和准确性。", "result": "实验结果显示该方法能够有效提升人体实例分割在遮挡条件下的准确率和鲁棒性，同时保持原模型的强大泛化能力。", "conclusion": "研究证明了通过姿态引导对SAM进行微调可以实现有效的遮挡感知的人体分割，并且保留了原始模型的泛化性能。"}}
{"id": "2601.08977", "pdf": "https://arxiv.org/pdf/2601.08977", "abs": "https://arxiv.org/abs/2601.08977", "authors": ["Chao Yang", "Haoyuan Zheng", "Yue Ma"], "title": "Thermo-LIO: A Novel Multi-Sensor Integrated System for Structural Health Monitoring", "categories": ["cs.CV"], "comment": "27pages,12figures", "summary": "Traditional two-dimensional thermography, despite being non-invasive and useful for defect detection in the construction field, is limited in effectively assessing complex geometries, inaccessible areas, and subsurface defects. This paper introduces Thermo-LIO, a novel multi-sensor system that can enhance Structural Health Monitoring (SHM) by fusing thermal imaging with high-resolution LiDAR. To achieve this, the study first develops a multimodal fusion method combining thermal imaging and LiDAR, enabling precise calibration and synchronization of multimodal data streams to create accurate representations of temperature distributions in buildings. Second, it integrates this fusion approach with LiDAR-Inertial Odometry (LIO), enabling full coverage of large-scale structures and allowing for detailed monitoring of temperature variations and defect detection across inspection cycles. Experimental validations, including case studies on a bridge and a hall building, demonstrate that Thermo-LIO can detect detailed thermal anomalies and structural defects more accurately than traditional methods. The system enhances diagnostic precision, enables real-time processing, and expands inspection coverage, highlighting the crucial role of multimodal sensor integration in advancing SHM methodologies for large-scale civil infrastructure.", "AI": {"tldr": "本文介绍了Thermo-LIO，一种将热成像与高分辨率LiDAR融合的新型多传感器系统，用于增强结构健康监测。", "motivation": "传统的二维热成像虽然非侵入性且有助于缺陷检测，但在评估复杂几何形状、不可访问区域和次表面缺陷时存在局限。Thermo-LIO旨在克服这些限制并提高大型基础设施的检测精度。", "method": "研究开发了一种多模态融合方法，结合热成像与LiDAR技术，并通过精确校准和同步不同模式的数据流来创建建筑物温度分布的准确表示。此外，该系统还集成了LiDAR-惯性里程计（LIO），以实现对大型结构的全面覆盖。", "result": "实验验证包括桥梁和大厅建筑案例研究表明，Thermo-LIO能够更精确地检测热异常和结构缺陷，并且具有实时处理能力以及扩大了检测范围。", "conclusion": "该系统增强了诊断精度、实现了实时数据处理并扩展了检测覆盖面，突显出多模态传感器集成在推进大型基础设施SHM方法中的关键作用。"}}
{"id": "2601.08976", "pdf": "https://arxiv.org/pdf/2601.08976", "abs": "https://arxiv.org/abs/2601.08976", "authors": ["Subhodeep Ghosh", "Zhihui Du", "Angela Bonifati", "Manish Kumar", "David Bader", "Senjuti Basu Roy"], "title": "Continuous Fairness On Data Streams", "categories": ["cs.LG", "cs.CY", "cs.DS"], "comment": null, "summary": "We study the problem of enforcing continuous group fairness over windows in data streams. We propose a novel fairness model that ensures group fairness at a finer granularity level (referred to as block) within each sliding window. This formulation is particularly useful when the window size is large, making it desirable to enforce fairness at a finer granularity. Within this framework, we address two key challenges: efficiently monitoring whether each sliding window satisfies block-level group fairness, and reordering the current window as effectively as possible when fairness is violated. To enable real-time monitoring, we design sketch-based data structures that maintain attribute distributions with minimal overhead. We also develop optimal, efficient algorithms for the reordering task, supported by rigorous theoretical guarantees. Our evaluation on four real-world streaming scenarios demonstrates the practical effectiveness of our approach. We achieve millisecond-level processing and a throughput of approximately 30,000 queries per second on average, depending on system parameters. The stream reordering algorithm improves block-level group fairness by up to 95% in certain cases, and by 50-60% on average across datasets. A qualitative study further highlights the advantages of block-level fairness compared to window-level fairness.", "AI": {"tldr": "本文研究了在数据流窗口中持续执行群体公平性的方法，提出了一个确保更细粒度（称为块级别）公平性的新模型。", "motivation": "当窗口较大时，在较细的颗粒层面上实施公平性变得尤为重要。因此，本论文旨在解决如何有效地监控和重新排序当前窗口以维持这种细粒度级别的群体公平性的问题。", "method": "为了实现实时监控，设计了基于素描的数据结构来维护属性分布，并开发了具有严格理论保证的优化算法来处理重新排序任务。", "result": "在四个真实世界的数据流场景中进行了评估，证明该方法能够在毫秒级别进行数据处理并实现每秒约30,000个查询的吞吐量。重新排序算法提高了块级别的群体公平性，最多可提高95%，平均改进率为50-60%。", "conclusion": "实验证明了本论文提出的方法在保证数据流中细粒度群体公平性的效果和高效性方面具有显著优势。"}}
{"id": "2601.08972", "pdf": "https://arxiv.org/pdf/2601.08972", "abs": "https://arxiv.org/abs/2601.08972", "authors": ["Yiluo Wei", "Gareth Tyson"], "title": "Understanding the Consequences of VTuber Reincarnation", "categories": ["cs.SI", "cs.CY", "cs.HC"], "comment": "Accepted to The ACM Web Conference 2026 (WWW '26), Web4Good Track", "summary": "The rapid proliferation of VTubers, digital avatars controlled and voiced by human actors (Nakanohito), has created a lucrative and popular entertainment ecosystem. However, the prevailing industry model, where corporations retain ownership of the VTuber persona while the Nakanohito bears the immense pressure of dual-identity management, exposes the Nakanohito to significant vulnerabilities, including burnout, harassment, and precarious labor conditions. When these pressures become untenable, the Nakanohito may terminate their contracts and later debut with a new persona, a process known as \"reincarnation\". This phenomenon, a rising concern in the industry, inflicts substantial losses on the Nakanohito, agencies, and audiences alike. Understanding the quantitative fallout of reincarnation is crucial for mitigating this damage and fostering a more sustainable industry. To address this gap, we conduct the first large-scale empirical study of VTuber reincarnation, analyzing 12 significant cases using a comprehensive dataset of 728K livestream sessions and 4.5B viewer interaction records. Our results suggest reincarnation significantly damages a Nakanohito's career, leading to a decline in audience and financial support, an increase in harassment, and negative repercussions for the wider VTuber industry. Overall, these insights carry immediate implications for mitigating the significant professional and personal costs of the reincarnation, and fostering a healthier and more equitable VTuber ecosystem.", "AI": {"tldr": "本研究旨在通过大规模实证分析VTuber的重生现象及其后果，以期为减轻这一现象造成的损失并促进更可持续的行业环境提供见解。", "motivation": "鉴于目前VTuber产业中存在的Nakanohito（人类演员）所面临的巨大压力和困难，包括职业倦怠、骚扰以及不稳定的劳动条件，当这些压力变得难以承受时，可能会导致合同终止，并以新的化身重新出道，即重生。这一现象给所有相关方带来了损失。", "method": "通过分析12个显著的案例，使用包含728K直播会话和4.5B观众互动记录的数据集进行大规模实证研究。", "result": "研究表明，重生对Nakanohito的职业生涯造成严重影响，导致观众和支持减少、遭受更多骚扰，并给整个VTuber行业带来负面影响。", "conclusion": "这些发现对于减轻重生带来的专业和个人成本，以及促进更健康和公正的VTuber生态系统具有直接意义。"}}
{"id": "2601.08956", "pdf": "https://arxiv.org/pdf/2601.08956", "abs": "https://arxiv.org/abs/2601.08956", "authors": ["Satyaki Roy Chowdhury", "Golrokh Mirzaei"], "title": "Variance-Penalized MC-Dropout as a Learned Smoothing Prior for Brain Tumour Segmentation", "categories": ["cs.CV"], "comment": "Accepted by ISBI 2026", "summary": "Brain tumor segmentation is essential for diagnosis and treatment planning, yet many CNN and U-Net based approaches produce noisy boundaries in regions of tumor infiltration. We introduce UAMSA-UNet, an Uncertainty-Aware Multi-Scale Attention-based Bayesian U-Net that in- stead leverages Monte Carlo Dropout to learn a data-driven smoothing prior over its predictions, while fusing multi-scale features and attention maps to capture both fine details and global context. Our smoothing-regularized loss augments binary cross-entropy with a variance penalty across stochas- tic forward passes, discouraging spurious fluctuations and yielding spatially coherent masks. On BraTS2023, UAMSA- UNet improves Dice Similarity Coefficient by up to 3.3% and mean IoU by up to 2.7% over U-Net; on BraTS2024, it delivers up to 4.5% Dice and 4.0% IoU gains over the best baseline. Remarkably, it also reduces FLOPs by 42.5% rel- ative to U-Net++ while maintaining higher accuracy. These results demonstrate that, by combining multi-scale attention with a learned smoothing prior, UAMSA-UNet achieves both better segmentation quality and computational efficiency, and provides a flexible foundation for future integration with transformer-based modules for further enhanced segmenta- tion results.", "AI": {"tldr": "介绍了一种名为UAMSA-UNet的不确定性感知多尺度注意力贝叶斯U-Net模型，用于改进脑肿瘤分割的质量。", "motivation": "现有的基于CNN和U-Net的方法在处理脑肿瘤浸润区域时会产生噪声边界，影响诊断和治疗计划。", "method": "通过结合蒙特卡洛丢弃（MC-Dropout）来学习数据驱动的平滑先验，并融合多尺度特征图与注意力机制以捕捉细粒度细节和全局背景。采用带有方差惩罚项的损失函数来优化预测结果，减少噪声波动。", "result": "在BraTS2023和BraTS2024数据集上，UAMSA-UNet相较于基线模型（如U-Net）提高了Dice相似系数和平均IoU，并减少了计算量。", "conclusion": "结合多尺度注意力机制与学习到的平滑先验，UAMSA-UNet不仅能改善分割质量，还提升了计算效率，为未来与其他模块集成提供了基础。"}}
{"id": "2601.08955", "pdf": "https://arxiv.org/pdf/2601.08955", "abs": "https://arxiv.org/abs/2601.08955", "authors": ["Youwei Liu", "Jian Wang", "Hanlin Wang", "Beichen Guo", "Wenjie Li"], "title": "Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in world models have shown promise for modeling future dynamics of environmental states, enabling agents to reason and act without accessing real environments. Current methods mainly perform single-step or fixed-horizon rollouts, leaving their potential for complex task planning under-exploited. We propose Imagine-then-Plan (\\texttt{ITP}), a unified framework for agent learning via lookahead imagination, where an agent's policy model interacts with the learned world model, yielding multi-step ``imagined'' trajectories. Since the imagination horizon may vary by tasks and stages, we introduce a novel adaptive lookahead mechanism by trading off the ultimate goal and task progress. The resulting imagined trajectories provide rich signals about future consequences, such as achieved progress and potential conflicts, which are fused with current observations, formulating a partially \\textit{observable} and \\textit{imaginable} Markov decision process to guide policy learning. We instantiate \\texttt{ITP} with both training-free and reinforcement-trained variants. Extensive experiments across representative agent benchmarks demonstrate that \\texttt{ITP} significantly outperforms competitive baselines. Further analyses validate that our adaptive lookahead largely enhances agents' reasoning capability, providing valuable insights into addressing broader, complex tasks.", "AI": {"tldr": "提出了Imagine-then-Plan（ITP）框架，通过自适应展望机制和世界模型来实现多步规划。", "motivation": "现有的世界模型方法主要执行单步或固定时间范围的推演，无法充分利用其在复杂任务规划中的潜力。", "method": "引入自适应展望机制，与学习的世界模型交互以生成多步想象轨迹，并融合当前观察结果形成部分可观测和可想象的马尔可夫决策过程来指导策略学习。", "result": "实验显示ITP显著优于竞争基线，并验证了其自适应展望机制极大地增强了代理的推理能力。", "conclusion": "ITP框架通过结合世界模型和自适应展望机制，提升了代理在复杂任务中的规划和执行性能。"}}
{"id": "2601.08954", "pdf": "https://arxiv.org/pdf/2601.08954", "abs": "https://arxiv.org/abs/2601.08954", "authors": ["Sumin Hong", "Jewoong Moon", "Taeyeon Eom", "Juno Hwang", "Jibeom Seo"], "title": "Leveraging learning analytics to enhance immersive teacher simulations: Challenges and opportunities", "categories": ["cs.HC"], "comment": "30 pages, 10 figures. This chapter examines immersive teacher simulations and multimodal analytics. Project website: https://teachergenai.github.io/", "summary": "This chapter examines how data analytics can be leveraged to enhance immersive teacher simulations, situating this inquiry within the broader learning sciences discourse on embodied cognition, data-informed feedback, and teacher professional learning. It explores both conceptual foundations and empirical cases to illustrate how analytics serve as mediational tools that connect immersive experiences with reflective teaching practice. The chapter unfolds in multiple sections: (1) The Innovation Journey: An Overview of Immersive Teacher Simulations outlines the evolution from traditional simulations to XR-based environments, highlighting the need for professional decision-making under realistic constraints. (2) Innovation in Existing Research and Practice situates teacher analytics within the trajectory from descriptive observation to multimodal and predictive modeling. (3) Study Approach and Design details how multimodal data-discourse, behavior, and gaze-from the TeacherGen@i simulation were collected and organized to reveal cognitive distribution of pedagogical discourse and interaction patterns. (4) Findings present the cognitive distribution of preservice teachers' pedagogical discourse and the sequential interaction patterns that emerge in exchange, illustrating how multimodal analytics make pedagogical reasoning processes visible within immersive simulations. (5) Understanding Innovative Practices in Teacher Education examines teaching analytics to enhance immersive teacher simulation based on the findings of the study. (6) Key Takeaways of the Innovation Journey identifies research challenges and design implications for scalable, analytics-enhanced teacher education. Together, these sections position immersive teacher simulations as a pivotal testbed for aligning learning analytics, professional learning, and next-generation immersive learning environment design.", "AI": {"tldr": "本文探讨了如何利用学习分析来增强沉浸式教师模拟，将这一研究置于更广泛的学习科学讨论中。", "motivation": "动机在于探索数据分析在连接沉浸体验与反思教学实践中的作用，并通过概念基础和实证案例加以阐述。", "method": "文章详细介绍了从TeacherGen@i模拟收集和组织的多模态数据，包括话语、行为和注视点，揭示了教师的教育交流模式。", "result": "研究结果显示，多模态分析使沉浸式模拟中的教学推理过程可见，并呈现了准教师的教育话语分布及交互模式。", "conclusion": "文章指出，沉浸式教师模拟是整合学习分析、专业学习和下一代沉浸式环境设计的关键测试平台，并识别出研究挑战与规模化应用的设计含义。"}}
{"id": "2601.08953", "pdf": "https://arxiv.org/pdf/2601.08953", "abs": "https://arxiv.org/abs/2601.08953", "authors": ["Le Liu", "Bangguo Yu", "Nynke Vellinga", "Ming Cao"], "title": "Fairness risk and its privacy-enabled solution in AI-driven robotic applications", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness metric for robotic decision making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, which is tested in a robot navigation task. In view of the fact that under legal requirements, most robotic systems will enforce user privacy, the approach shows surprisingly that such privacy budgets can be jointly used to meet fairness targets. Addressing fairness concerns in the creative combined consideration of privacy is a step towards ethical use of AI and strengthens trust in autonomous robots deployed in everyday environments.", "AI": {"tldr": "本文提出了一种考虑用户隐私的公平性度量方法，并通过机器人导航任务验证了在满足隐私预算的同时可以实现公平目标。", "motivation": "鉴于自主机器和算法作出复杂决策可能奠定未来社会基础，且生成式AI的发展带来公平性的挑战，研究旨在解决机器人应用中的公平性和隐私问题。", "method": "提出一种兼顾用户效用与数据随机性的公平度量标准，并分析该标准如何受隐私预算的影响，形成统一框架来量化和形式化公平性与隐私之间的关系。", "result": "通过机器人导航任务测试表明，在遵守法律法规的隐私保护要求下，隐私预算是可以被用来满足公平性目标的。", "conclusion": "结合考虑隐私的公平性问题是实现AI伦理使用的重要一步，并加强了公众对日常环境中部署自主机器人的信任。"}}
{"id": "2601.08951", "pdf": "https://arxiv.org/pdf/2601.08951", "abs": "https://arxiv.org/abs/2601.08951", "authors": ["Jing-Jing Li", "Joel Mire", "Eve Fleisig", "Valentina Pyatkin", "Anne Collins", "Maarten Sap", "Sydney Levine"], "title": "PluriHarms: Benchmarking the Full Spectrum of Human Judgments on AI Harm", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Current AI safety frameworks, which often treat harmfulness as binary, lack the flexibility to handle borderline cases where humans meaningfully disagree. To build more pluralistic systems, it is essential to move beyond consensus and instead understand where and why disagreements arise. We introduce PluriHarms, a benchmark designed to systematically study human harm judgments across two key dimensions -- the harm axis (benign to harmful) and the agreement axis (agreement to disagreement). Our scalable framework generates prompts that capture diverse AI harms and human values while targeting cases with high disagreement rates, validated by human data. The benchmark includes 150 prompts with 15,000 ratings from 100 human annotators, enriched with demographic and psychological traits and prompt-level features of harmful actions, effects, and values. Our analyses show that prompts that relate to imminent risks and tangible harms amplify perceived harmfulness, while annotator traits (e.g., toxicity experience, education) and their interactions with prompt content explain systematic disagreement. We benchmark AI safety models and alignment methods on PluriHarms, finding that while personalization significantly improves prediction of human harm judgments, considerable room remains for future progress. By explicitly targeting value diversity and disagreement, our work provides a principled benchmark for moving beyond \"one-size-fits-all\" safety toward pluralistically safe AI.", "AI": {"tldr": "本文介绍了PluriHarms基准，旨在系统研究人类对AI危害的判断，并强调了理解和处理分歧的重要性。", "motivation": "当前的AI安全框架往往将有害性视为二元问题，缺乏灵活性来应对人类之间存在有意义分歧的边缘案例。因此，需要构建更具包容性的系统，理解分歧的根源和原因。", "method": "PluriHarms基准通过生成涵盖多样AI危害及价值观的提示语句，并重点关注高分歧率的情况来研究人类判断。该基准包括150个提示语句和来自100个人类标注者的15,000份评分，这些评分附有人口统计学和心理学特征以及有害行为、效果和价值的提示级别特征。", "result": "分析表明，与即时风险和具体危害相关的提示语句放大了感知的危害性，而标注者特质及其与内容之间的互动解释了系统的分歧。AI安全模型和对齐方法在PluriHarms基准上的测试显示个性化显著提升了预测人类危害判断的能力。", "conclusion": "通过明确针对价值多样性及分歧，本文的工作为从“一刀切”式安全性迈向多元化的安全AI提供了原则性的基准。"}}
{"id": "2601.08950", "pdf": "https://arxiv.org/pdf/2601.08950", "abs": "https://arxiv.org/abs/2601.08950", "authors": ["Mayank Sharma", "Roy Pea", "Hari Subramonyam"], "title": "ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "In educational applications, LLMs exhibit several fundamental pedagogical limitations, such as their tendency to reveal solutions rather than support dialogic learning. We introduce ConvoLearn (https://huggingface.co/datasets/masharma/convolearn ), a dataset grounded in knowledge building theory that operationalizes six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. We construct a semi-synthetic dataset of 1250 tutor-student dialogues (20 turns each) in middle school Earth Science through controlled interactions between human teachers and a simulated student. Using QLoRA, we demonstrate that training on this dataset meaningfully shifts LLM behavior toward knowledge-building strategies. Human evaluation by 31 teachers shows our fine-tuned Mistral 7B (M = 4.10, SD = 1.03) significantly outperforms both its base version (M = 2.59, SD = 1.11) and Claude Sonnet 4.5 (M = 2.87, SD = 1.29) overall. This work establishes a potential framework to guide future development and evaluation of constructivist AI tutors.", "AI": {"tldr": "本文介绍了ConvoLearn数据集，该数据集包含中学地球科学领域的师生对话，旨在通过训练大型语言模型使其行为更加倾向于知识建构策略。", "motivation": "鉴于现有的大规模语言模型在教育应用中存在一些根本性的教学局限性，如它们倾向直接给出解决方案而非支持对话式学习，本研究构建了一个新的数据集来改善这一状况。", "method": "通过人类教师与模拟学生之间的受控交互，创建了包含1250个师生对话的半合成数据集（每个对话包含20轮）。使用QLoRA进行训练，并对微调后的模型进行了人类评估。", "result": "经过31名教师的人类评价表明，基于此数据集训练后的Mistral 7B模型在整体表现上显著优于其原始版本和Claude Sonnet 4.5模型。", "conclusion": "该研究为未来构建主义AI导师的发展与评估提供了一个潜在框架。"}}
{"id": "2601.08928", "pdf": "https://arxiv.org/pdf/2601.08928", "abs": "https://arxiv.org/abs/2601.08928", "authors": ["Shahnawaz Alam", "Mohammed Abdul Rahman", "Bareera Sadeqa"], "title": "DriftGuard: A Hierarchical Framework for Concept Drift Detection and Remediation in Supply Chain Forecasting", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Supply chain forecasting models degrade over time as real-world conditions change. Promotions shift, consumer preferences evolve, and supply disruptions alter demand patterns, causing what is known as concept drift. This silent degradation leads to stockouts or excess inventory without triggering any system warnings. Current industry practice relies on manual monitoring and scheduled retraining every 3-6 months, which wastes computational resources during stable periods while missing rapid drift events. Existing academic methods focus narrowly on drift detection without addressing diagnosis or remediation, and they ignore the hierarchical structure inherent in supply chain data. What retailers need is an end-to-end system that detects drift early, explains its root causes, and automatically corrects affected models. We propose DriftGuard, a five-module framework that addresses the complete drift lifecycle. The system combines an ensemble of four complementary detection methods, namely error-based monitoring, statistical tests, autoencoder anomaly detection, and Cumulative Sum (CUSUM) change-point analysis, with hierarchical propagation analysis to identify exactly where drift occurs across product lines. Once detected, Shapley Additive Explanations (SHAP) analysis diagnoses the root causes, and a cost-aware retraining strategy selectively updates only the most affected models. Evaluated on over 30,000 time series from the M5 retail dataset, DriftGuard achieves 97.8% detection recall within 4.2 days and delivers up to 417 return on investment through targeted remediation.", "AI": {"tldr": "提出DriftGuard框架，用于供应链预测中的概念漂移检测与修复。", "motivation": "现有方法无法有效处理供应链示例数据层次结构，并且缺乏对概念漂移的诊断和修复功能。现有的行业实践依赖于手动监控和定期重新训练模型，这种做法浪费计算资源并且不能及时发现快速发生的概念漂移。", "method": "DriftGuard框架包括五个模块，使用四个互补检测方法（基于错误的监控、统计测试、自动编码器异常检测和累积总和变化点分析），以及层次传播分析来识别跨产品线的确切概念漂移位置。一旦检测到，使用SHAP值诊断根本原因，并采用成本意识重新训练策略选择性地更新受影响最严重的模型。", "result": "在M5零售数据集的30,000多个时间序列上进行评估时，DriftGuard实现了97.8%的概念漂移检测召回率，并且能够在4.2天内完成，通过针对性修复措施达到最高417的投资回报率。", "conclusion": "DriftGuard框架能够及时并准确地识别概念漂移事件，解释其原因，并采取有效的纠正行动来维持供应链预测模型的准确性。"}}
{"id": "2601.08920", "pdf": "https://arxiv.org/pdf/2601.08920", "abs": "https://arxiv.org/abs/2601.08920", "authors": ["Md. Jahidul Islam"], "title": "W-DUALMINE: Reliability-Weighted Dual-Expert Fusion With Residual Correlation Preservation for Medical Image Fusion", "categories": ["eess.IV", "cs.CV", "math.NA"], "comment": null, "summary": "Medical image fusion integrates complementary information from multiple imaging modalities to improve clinical interpretation. However, existing deep learningbased methods, including recent spatial-frequency frameworks such as AdaFuse and ASFE-Fusion, often suffer from a fundamental trade-off between global statistical similaritymeasured by correlation coefficient (CC) and mutual information (MI)and local structural fidelity. This paper proposes W-DUALMINE, a reliability-weighted dual-expert fusion framework designed to explicitly resolve this trade-off through architectural constraints and a theoretically grounded loss design. The proposed method introduces dense reliability maps for adaptive modality weighting, a dual-expert fusion strategy combining a global-context spatial expert and a wavelet-domain frequency expert, and a soft gradient-based arbitration mechanism. Furthermore, we employ a residual-to-average fusion paradigm that guarantees the preservation of global correlation while enhancing local details. Extensive experiments on CT-MRI, PET-MRI, and SPECT-MRI datasets demonstrate that W-DUALMINE consistently outperforms AdaFuse and ASFE-Fusion in CC and MI metrics while", "AI": {"tldr": "W-DUALMINE提出了一种基于可靠性加权的双专家融合框架，用于解决医学图像融合中的全球统计相似性和局部结构保真度之间的基本权衡。", "motivation": "现有的深度学习方法在医学图像融合中经常面临全局统计相似性与局部细节保真度之间的权衡问题，因此需要开发新的方法来改善这一状况。", "method": "该论文提出W-DUALMINE框架，利用密集的可靠性图进行自适应模态加权，并结合全局上下文空间专家和小波域频率专家的双专家策略以及软梯度仲裁机制。", "result": "实验结果表明，在CT-MRI、PET-MRI和SPECT-MRI数据集上，W-DUALMINE在CC和MI指标上均优于AdaFuse和ASFE-Fusion方法。", "conclusion": "W-DUALMINE框架通过创新的设计有效地解决了医学图像融合中的关键挑战，并显著提高了融合效果的质量。"}}
{"id": "2601.08910", "pdf": "https://arxiv.org/pdf/2601.08910", "abs": "https://arxiv.org/abs/2601.08910", "authors": ["Shaghayegh Emami", "Cecilia Tosciri", "Giovanna Salvi", "Zixin Ding", "Yuxin Chen", "Abhijith Gandrakota", "Christian Herwig", "David W. Miller", "Jennifer Ngadiuba", "Nhan Tran"], "title": "Towards a Self-Driving Trigger at the LHC: Adaptive Response in Real Time", "categories": ["physics.ins-det", "cs.AI", "hep-ex"], "comment": null, "summary": "Real-time data filtering and selection -- or trigger -- systems at high-throughput scientific facilities such as the experiments at the Large Hadron Collider (LHC) must process extremely high-rate data streams under stringent bandwidth, latency, and storage constraints. Yet these systems are typically designed as static, hand-tuned menus of selection criteria grounded in prior knowledge and simulation. In this work, we further explore the concept of a self-driving trigger, an autonomous data-filtering framework that reallocates resources and adjusts thresholds dynamically in real-time to optimize signal efficiency, rate stability, and computational cost as instrumentation and environmental conditions evolve. We introduce a benchmark ecosystem to emulate realistic collider scenarios and demonstrate real-time optimization of a menu including canonical energy sum triggers as well as modern anomaly-detection algorithms that target non-standard event topologies using machine learning. Using simulated data streams and publicly available collision data from the Compact Muon Solenoid (CMS) experiment, we demonstrate the capability to dynamically and automatically optimize trigger performance under specific cost objectives without manual retuning. Our adaptive strategy shifts trigger design from static menus with heuristic tuning to intelligent, automated, data-driven control, unlocking greater flexibility and discovery potential in future high-energy physics analyses.", "AI": {"tldr": "本文探讨了在大型强子对撞机（LHC）上实现自驱动触发系统的概念，提出了一种能够动态调整资源和阈值以优化信号效率、速率稳定性和计算成本的自主数据筛选框架。", "motivation": "传统的触发系统是静态设计且基于先前的知识和模拟进行手动调优。本文旨在开发一种适应实时情况变化的自我驾驶触发系统，以提高信号效率并减少人工调整需求。", "method": "通过引入一个基准生态系统来模拟真实的对撞机场景，并使用模拟数据流以及来自CMS实验的公开碰撞数据，实现实时优化包括典型能量总和触发器在内的菜单及现代异常检测算法。", "result": "研究展示了在特定成本目标下动态自动优化触发性能的能力，无需手动重新调整。证明了从静态菜单到智能、自动化、数据驱动控制的成功转变。", "conclusion": "通过实现实时资源分配与阈值调整的自适应策略，本文为高能物理学分析提供了更高的灵活性和发现潜力，预示着未来触发系统设计的巨大进步。"}}
{"id": "2601.08901", "pdf": "https://arxiv.org/pdf/2601.08901", "abs": "https://arxiv.org/abs/2601.08901", "authors": ["Yuexi Shen", "Minqian Liu", "Dawei Zhou", "Lifu Huang"], "title": "Navigating Ideation Space: Decomposed Conceptual Representations for Positioning Scientific Ideas", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": "21 pages, 6 tables", "summary": "Scientific discovery is a cumulative process and requires new ideas to be situated within an ever-expanding landscape of existing knowledge. An emerging and critical challenge is how to identify conceptually relevant prior work from rapidly growing literature, and assess how a new idea differentiates from existing research. Current embedding approaches typically conflate distinct conceptual aspects into single representations and cannot support fine-grained literature retrieval; meanwhile, LLM-based evaluators are subject to sycophancy biases, failing to provide discriminative novelty assessment. To tackle these challenges, we introduce the Ideation Space, a structured representation that decomposes scientific knowledge into three distinct dimensions, i.e., research problem, methodology, and core findings, each learned through contrastive training. This framework enables principled measurement of conceptual distance between ideas, and modeling of ideation transitions that capture the logical connections within a proposed idea. Building upon this representation, we propose a Hierarchical Sub-Space Retrieval framework for efficient, targeted literature retrieval, and a Decomposed Novelty Assessment algorithm that identifies which aspects of an idea are novel. Extensive experiments demonstrate substantial improvements, where our approach achieves Recall@30 of 0.329 (16.7% over baselines), our ideation transition retrieval reaches Hit Rate@30 of 0.643, and novelty assessment attains 0.37 correlation with expert judgments. In summary, our work provides a promising paradigm for future research on accelerating and evaluating scientific discovery.", "AI": {"tldr": "本文提出了Ideation Space框架，用于分解科学知识，并通过分层子空间检索和分解新颖性评估算法来改善文献检索和新思想的评估。", "motivation": "面对快速增长的文献，需要找到与概念相关的先前工作并评估新想法的独特性。现有嵌入方法难以支持细粒度文献检索，LLM评估器容易出现逢迎偏见。", "method": "引入Ideation Space分解科学知识为研究问题、方法和核心发现三个维度，并通过对比训练学习这些维度，构建分层子空间检索框架及新颖性评估算法。", "result": "实验显示该方法在文献检索和新颖性评估方面优于基线模型，如Recall@30达到0.329（比基线提高16.7%），Ideation过渡检索的Hit Rate@30为0.643，新颖性评估与专家判断的相关性达0.37。", "conclusion": "本文提出的方法提供了一种有前景的范式来加速和评估科学发现。"}}
{"id": "2601.08900", "pdf": "https://arxiv.org/pdf/2601.08900", "abs": "https://arxiv.org/abs/2601.08900", "authors": ["Anush Lakshman S", "Adam Haroon", "Beiwen Li"], "title": "Comprehensive Machine Learning Benchmarking for Fringe Projection Profilometry with Photorealistic Synthetic Data", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Machine learning approaches for fringe projection profilometry (FPP) are hindered by the lack of large, diverse datasets and comprehensive benchmarking protocols. This paper introduces the first open-source, photorealistic synthetic dataset for FPP, generated using NVIDIA Isaac Sim with 15,600 fringe images and 300 depth reconstructions across 50 diverse objects. We benchmark four neural network architectures (UNet, Hformer, ResUNet, Pix2Pix) on single-shot depth reconstruction, revealing that all models achieve similar performance (58-77 mm RMSE) despite substantial architectural differences. Our results demonstrate fundamental limitations of direct fringe-to-depth mapping without explicit phase information, with reconstruction errors approaching 75-95\\% of the typical object depth range. This resource provides standardized evaluation protocols enabling systematic comparison and development of learning-based FPP approaches.", "AI": {"tldr": "本文介绍了首个开源的、基于物理渲染的合成数据集用于条纹投影轮廓术，并对四种神经网络架构进行了基准测试。", "motivation": "由于缺乏大规模且多样化的数据集和全面的基准测试协议，机器学习方法在条纹投影轮廓术中的应用受到了限制。", "method": "使用NVIDIA Isaac Sim生成了包含15,600张条纹图像及300个深度重建结果的数据集，并对四种神经网络架构进行了单次拍摄深度重建的基准测试。", "result": "所有模型在直接从条纹映射到深度时，性能相似（RMSE为58-77毫米），表明没有显式相位信息的情况下存在根本性限制，重构误差接近典型对象深度范围的75%-95%。", "conclusion": "这项研究提供了一种标准化评估协议，使学习为基础的方法在条纹投影轮廓术中的系统比较和发展成为可能。"}}
{"id": "2601.08896", "pdf": "https://arxiv.org/pdf/2601.08896", "abs": "https://arxiv.org/abs/2601.08896", "authors": ["Sahaj Raj Malla", "Shreeyash Kayastha", "Rumi Suwal", "Harish Chandra Bhandari", "Rajendra Adhikari"], "title": "XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "comment": "9 pages, 4 figures, 3 tables", "summary": "This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators such as short- and medium-term rolling volatility measures and the 14-period Relative Strength Index. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling window schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R-squared), and directional accuracy on both log-returns and reconstructed closing prices. Empirical results show that the optimal configuration, an expanding window with 20 lags, outperforms tuned ARIMA and Ridge regression benchmarks, achieving the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%. While the R-squared remains modest, consistent with the noisy nature of financial returns, primary emphasis is placed on relative error reduction and directional prediction. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.", "AI": {"tldr": "本文使用XGBoost回归器开发了一个强大的机器学习框架，用于预测尼泊尔证券交易所（NEPSE）指数的日对数收益率。", "motivation": "研究动机是通过有效的机器学习方法提高对波动性较大的新兴市场时间序列的非线性动态建模能力，并提供一个可重复的基准进行NEPSE指数预测。", "method": "该论文采用了包括滞后对数收益和多个技术指标在内的全面特征集，使用Optuna进行了超参数优化，并通过向前验证方法评估了模型在样本外的表现。", "result": "最优配置（扩展窗口与20个滞后项）的XGBoost模型在预测准确性上优于调优后的ARIMA和岭回归基准，在对数收益RMSE为0.013450、MAE为0.009814及方向性准确度65.15%的情况下表现最佳。", "conclusion": "研究结果表明，梯度提升集成方法在建模新兴市场时间序列的非线性动态方面非常有效，并为进一步的研究提供了可重复预测基准。"}}
{"id": "2601.08892", "pdf": "https://arxiv.org/pdf/2601.08892", "abs": "https://arxiv.org/abs/2601.08892", "authors": ["Eric Rudolph", "Natalie Engert", "Jens Albrecht"], "title": "Evaluating Role-Consistency in LLMs for Counselor Training", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rise of online counseling services has highlighted the need for effective training methods for future counselors. This paper extends research on VirCo, a Virtual Client for Online Counseling, designed to complement traditional role-playing methods in academic training by simulating realistic client interactions. Building on previous work, we introduce a new dataset incorporating adversarial attacks to test the ability of large language models (LLMs) to maintain their assigned roles (role-consistency). The study focuses on evaluating the role consistency and coherence of the Vicuna model's responses, comparing these findings with earlier research. Additionally, we assess and compare various open-source LLMs for their performance in sustaining role consistency during virtual client interactions. Our contributions include creating an adversarial dataset, evaluating conversation coherence and persona consistency, and providing a comparative analysis of different LLMs.", "AI": {"tldr": "评估大型语言模型在虚拟咨询客户互动中维持角色一致性的能力。", "motivation": "鉴于在线咨询服务的需求，研究旨在通过改进VirCo这一虚拟客户工具来提高未来心理咨询师的培训效果，并测试大规模语言模型的角色一致性。", "method": "引入包含对抗性攻击的新数据集来评估大型语言模型（LLMs）维持其分配角色的能力，重点是评估Vicuna模型在对话中的角色一致性和连贯性，同时对比其他开源LLM的表现。", "result": "创建了对抗性数据集，对不同LLMs的对话连贯性和人格一致性进行了评估和比较。", "conclusion": "研究提供了关于如何通过模拟真实客户互动来改进心理咨询师培训的新见解，并且强调了在虚拟咨询场景中角色一致性的关键作用。"}}
{"id": "2601.08891", "pdf": "https://arxiv.org/pdf/2601.08891", "abs": "https://arxiv.org/abs/2601.08891", "authors": ["Yanhua Zhao"], "title": "Attention Consistency Regularization for Interpretable Early-Exit Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "2 pages, 1 figure", "summary": "Early-exit neural networks enable adaptive inference by allowing predictions at intermediate layers, reducing computational cost. However, early exits often lack interpretability and may focus on different features than deeper layers, limiting trust and explainability. This paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit networks through attention-based regularization. EGT introduces an attention consistency loss that aligns early-exit attention maps with the final exit. The framework jointly optimizes classification accuracy and attention consistency through a weighted combination of losses. Experiments on a real-world image classification dataset demonstrate that EGT achieves up to 98.97% overall accuracy (matching baseline performance) with a 1.97x inference speedup through early exits, while improving attention consistency by up to 18.5% compared to baseline models. The proposed method provides more interpretable and consistent explanations across all exit points, making early-exit networks more suitable for explainable AI applications in resource-constrained environments.", "AI": {"tldr": "本文提出Explanation-Guided Training（EGT），一个通过注意力一致性正则化提高早期退出神经网络可解释性和一致性的多目标框架。", "motivation": "早期退出神经网络虽然能减少计算成本，但缺乏可解释性，并且可能关注与深层不同的特征，限制了信任和可解释性。因此，本文旨在改善这类模型的解释能力和一致性。", "method": "EGT通过引入注意力一致性损失来对齐早期退出的注意图与最终退出点，实现分类准确性与注意一致性的联合优化，使用加权组合的损失函数。", "result": "实验显示，EGT能够达到高达98.97%的整体准确率（与基线模型相当），同时通过早期退出实现1.97倍推理加速，并且注意力一致性提高了最多18.5%，相比基线模型。", "conclusion": "所提出的方法为所有退出点提供了更一致和可解释的解释，使得早期退出神经网络更适合于资源受限环境中的可解释AI应用。"}}
{"id": "2601.08885", "pdf": "https://arxiv.org/pdf/2601.08885", "abs": "https://arxiv.org/abs/2601.08885", "authors": ["Sixian Jia", "Ruo-Syuan Mei", "Chenhui Shao"], "title": "Adaptive few-shot learning for robust part quality classification in two-photon lithography", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Two-photon lithography (TPL) is an advanced additive manufacturing (AM) technique for fabricating high-precision micro-structures. While computer vision (CV) is proofed for automated quality control, existing models are often static, rendering them ineffective in dynamic manufacturing environments. These models typically cannot detect new, unseen defect classes, be efficiently updated from scarce data, or adapt to new part geometries. To address this gap, this paper presents an adaptive CV framework for the entire life-cycle of quality model maintenance. The proposed framework is built upon a same, scale-robust backbone model and integrates three key methodologies: (1) a statistical hypothesis testing framework based on Linear Discriminant Analysis (LDA) for novelty detection, (2) a two-stage, rehearsal-based strategy for few-shot incremental learning, and (3) a few-shot Domain-Adversarial Neural Network (DANN) for few-shot domain adaptation. The framework was evaluated on a TPL dataset featuring hemisphere as source domain and cube as target domain structures, with each domain categorized into good, minor damaged, and damaged quality classes. The hypothesis testing method successfully identified new class batches with 99-100% accuracy. The incremental learning method integrated a new class to 92% accuracy using only K=20 samples. The domain adaptation model bridged the severe domain gap, achieving 96.19% accuracy on the target domain using only K=5 shots. These results demonstrate a robust and data-efficient solution for deploying and maintaining CV models in evolving production scenarios.", "AI": {"tldr": "提出了一种自适应计算机视觉框架，用于两光子光刻技术中零件质量分类的整个生命周期维护。", "motivation": "现有的静态模型在动态制造环境中难以检测新出现的缺陷类、无法从稀缺数据高效更新或适应新的部件几何形状。", "method": "该框架基于尺度鲁棒性主干模型，结合了统计假设检验方法进行新颖性检测、两阶段复习增量学习策略以及少量样本域对抗神经网络用于领域迁移。", "result": "在测试数据集上，新类别批次识别准确率为99-100%，新增类别的集成达到92%的准确率（仅用20个样本），目标领域的分类准确率达到96.19%（仅使用5个样本）。", "conclusion": "该框架提供了在生产场景不断变化的情况下部署和维护计算机视觉模型的强大且数据高效的解决方案。"}}
{"id": "2601.08884", "pdf": "https://arxiv.org/pdf/2601.08884", "abs": "https://arxiv.org/abs/2601.08884", "authors": ["Samyak Jhaveri", "Cristina V. Lopes"], "title": "Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting", "categories": ["cs.SE", "cs.AI", "cs.DC"], "comment": null, "summary": "OpenACC lowers the barrier to GPU offloading, but writing high-performing pragma remains complex, requiring deep domain expertise in memory hierarchies, data movement, and parallelization strategies. Large Language Models (LLMs) present a promising potential solution for automated parallel code generation, but naive prompting often results in syntactically incorrect directives, uncompilable code, or performance that fails to exceed CPU baselines. We present a systematic prompt optimization approach to enhance OpenACC pragma generation without the prohibitive computational costs associated with model post-training. Leveraging the GEPA (GEnetic-PAreto) framework, we iteratively evolve prompts through a reflective feedback loop. This process utilizes crossover and mutation of instructions, guided by expert-curated gold examples and structured feedback based on clause- and clause parameter-level mismatches between the gold and predicted pragma. In our evaluation on the PolyBench suite, we observe an increase in compilation success rates for programs annotated with OpenACC pragma generated using the optimized prompts compared to those annotated using the simpler initial prompt, particularly for the \"nano\"-scale models. Specifically, with optimized prompts, the compilation success rate for GPT-4.1 Nano surged from 66.7% to 93.3%, and for GPT-5 Nano improved from 86.7% to 100%, matching or surpassing the capabilities of their significantly larger, more expensive versions. Beyond compilation, the optimized prompts resulted in a 21% increase in the number of programs that achieve functional GPU speedups over CPU baselines. These results demonstrate that prompt optimization effectively unlocks the potential of smaller, cheaper LLMs in writing stable and effective GPU-offloading directives, establishing a cost-effective pathway to automated directive-based parallelization in HPC workflows.", "AI": {"tldr": "通过优化提示（prompt optimization）增强小型语言模型生成OpenACC指令的能力，实现更高效的GPU并行编程。", "motivation": "降低使用OpenACC进行GPU加速的难度，并解决大语言模型直接生成代码时存在的语法错误和性能不足问题。", "method": "采用GEPA框架优化提示，通过交叉、变异操作迭代进化提示，利用专家编写的黄金示例和结构化反馈来指导优化过程。", "result": "在PolyBench套件上的评估显示，使用优化后的提示对小型模型（如GPT-4.1 Nano和GPT-5 Nano）的编译成功率显著提升，并且有更多程序实现了GPU加速效果。", "conclusion": "通过GEPA框架进行的提示优化可以有效释放小型、低成本语言模型在编写稳定有效的GPU并行代码方面的潜力，为HPC工作流提供了一种经济高效的自动化途径。"}}
{"id": "2601.08882", "pdf": "https://arxiv.org/pdf/2601.08882", "abs": "https://arxiv.org/abs/2601.08882", "authors": ["Thomas Snyder", "H. Lexie Yang", "Stefan Schnake", "Steffen Schotthöfer"], "title": "Compressing Vision Transformers in Geospatial Transfer Learning with Manifold-Constrained Optimization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deploying geospatial foundation models on resource-constrained edge devices demands compact architectures that maintain high downstream performance. However, their large parameter counts and the accuracy loss often induced by compression limit practical adoption. In this work, we leverage manifold-constrained optimization framework DLRT to compress large vision transformer-based geospatial foundation models during transfer learning. By enforcing structured low-dimensional parameterizations aligned with downstream objectives, this approach achieves strong compression while preserving task-specific accuracy. We show that the method outperforms of-the-shelf low-rank methods as LoRA. Experiments on diverse geospatial benchmarks confirm substantial parameter reduction with minimal accuracy loss, enabling high-performing, on-device geospatial models.", "AI": {"tldr": "本文研究了在地空转移学习中使用流形约束优化框架DLRT压缩基于视觉变换器的地基模型，以实现高下游性能和紧凑结构。", "motivation": "部署地空基础模型到资源受限的边缘设备需要保持高性能的同时采用更小的架构。然而，大型参数的数量以及由压缩引起的准确性损失限制了其实际应用。", "method": "本研究利用DLRT（一种流形约束优化框架）在转移学习过程中压缩基于视觉变换器的地基模型，通过强制低维结构化参数化以与下游目标一致来实现强压缩并保持任务特定的准确性。", "result": "实验结果表明该方法优于现成的低秩方法如LoRA，并且在多样的地空基准测试中实现了显著的参数减少和极小的准确率损失，从而能够在设备上运行高性能的地基模型。", "conclusion": "通过流形约束优化框架DLRT实现视觉变换器的基础模型压缩，在保持高准确性的同时大幅减少了参数数量，使得该模型适合资源受限的边缘设备部署。"}}
{"id": "2601.08881", "pdf": "https://arxiv.org/pdf/2601.08881", "abs": "https://arxiv.org/abs/2601.08881", "authors": ["Yu Xu", "Hongbin Yan", "Juan Cao", "Yiji Cheng", "Tiankai Hang", "Runze He", "Zijin Yin", "Shiyi Zhang", "Yuxin Zhang", "Jintao Li", "Chunyu Wang", "Qinglin Lu", "Tong-Yee Lee", "Fan Tang"], "title": "TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://yuci-gpt.github.io/TAG-MoE/", "summary": "Unified image generation and editing models suffer from severe task interference in dense diffusion transformers architectures, where a shared parameter space must compromise between conflicting objectives (e.g., local editing v.s. subject-driven generation). While the sparse Mixture-of-Experts (MoE) paradigm is a promising solution, its gating networks remain task-agnostic, operating based on local features, unaware of global task intent. This task-agnostic nature prevents meaningful specialization and fails to resolve the underlying task interference. In this paper, we propose a novel framework to inject semantic intent into MoE routing. We introduce a Hierarchical Task Semantic Annotation scheme to create structured task descriptors (e.g., scope, type, preservation). We then design Predictive Alignment Regularization to align internal routing decisions with the task's high-level semantics. This regularization evolves the gating network from a task-agnostic executor to a dispatch center. Our model effectively mitigates task interference, outperforming dense baselines in fidelity and quality, and our analysis shows that experts naturally develop clear and semantically correlated specializations.", "AI": {"tldr": "本文提出TAG-MoE框架，通过注入语义意图到MoE路由中来解决统一图像生成和编辑模型中的任务干扰问题。", "motivation": "当前的统一图像生成和编辑模型在密集扩散转换器架构中面临严重任务干扰，共享参数空间难以平衡冲突目标。现有的稀疏Mixture-of-Experts（MoE）范式无法识别全局任务意图，限制了有意义的专业化发展。", "method": "引入分层任务语义标注方案以创建结构化的任务描述符，并设计预测对齐正则化来使内部路由决策与高层次的语义相一致。", "result": "该模型有效缓解了任务干扰问题，在保真度和质量上优于密集基线模型，分析表明专家自然地发展出清晰且语义相关的专业化。", "conclusion": "TAG-MoE框架通过注入语义意图到MoE路由中，成功解决了统一图像生成和编辑中的任务干扰问题，并提升了整体性能。"}}
{"id": "2601.08879", "pdf": "https://arxiv.org/pdf/2601.08879", "abs": "https://arxiv.org/abs/2601.08879", "authors": ["Nicolas Ruth", "Manuel Burghardt"], "title": "Echoes of Ideology: Toward an Audio Analysis Pipeline to Unveil Character Traits in Historical Nazi Propaganda Films", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "This study investigates the use of computational audio analysis to examine ideological narratives in Nazi propaganda films. Employing a three-step pipeline, speaker diarization, audio transcription and psycholinguistic analysis, it reveals ideological patterns in characters. Despite current issues with speaker diarization, the methodology provides insights into character traits and propaganda narratives, suggesting scalable applications.", "AI": {"tldr": "本文研究了使用计算音频分析来探讨纳粹宣传电影中的意识形态叙事。", "motivation": "动机在于揭示历史纳粹宣传影片中角色的特征和意识形态模式，尽管在说话者区分方面存在当前问题，但该方法仍提供了一种可扩展的应用潜力。", "method": "研究采用了一个三步流程：说话人区分、音频转录及心理语言学分析来解析意识形态叙述。", "result": "虽然说话者区分技术存在问题，该方法仍然揭示了角色特征和宣传叙事的洞察。", "conclusion": "此方法提供了对历史纳粹宣传影片中意识形态模式的新见解，并暗示了可扩展的应用前景。"}}
{"id": "2601.08876", "pdf": "https://arxiv.org/pdf/2601.08876", "abs": "https://arxiv.org/abs/2601.08876", "authors": ["Shuai Chen", "Hao Chen", "Yuanchen Bei", "Tianyang Zhao", "Zhibo Zhou", "Feiran Huang"], "title": "The Semantic Lifecycle in Embodied AI: Acquisition, Representation and Storage via Foundation Models", "categories": ["cs.CV"], "comment": null, "summary": "Semantic information in embodied AI is inherently multi-source and multi-stage, making it challenging to fully leverage for achieving stable perception-to-action loops in real-world environments. Early studies have combined manual engineering with deep neural networks, achieving notable progress in specific semantic-related embodied tasks. However, as embodied agents encounter increasingly complex environments and open-ended tasks, the demand for more generalizable and robust semantic processing capabilities has become imperative. Recent advances in foundation models (FMs) address this challenge through their cross-domain generalization abilities and rich semantic priors, reshaping the landscape of embodied AI research. In this survey, we propose the Semantic Lifecycle as a unified framework to characterize the evolution of semantic knowledge within embodied AI driven by foundation models. Departing from traditional paradigms that treat semantic processing as isolated modules or disjoint tasks, our framework offers a holistic perspective that captures the continuous flow and maintenance of semantic knowledge. Guided by this embodied semantic lifecycle, we further analyze and compare recent advances across three key stages: acquisition, representation, and storage. Finally, we summarize existing challenges and outline promising directions for future research.", "AI": {"tldr": "本文提出了一个统一框架——语义生命周期，以描述由基础模型驱动的具身AI中的语义知识演变。", "motivation": "现有的具身AI在面对复杂环境和开放任务时，对更通用和鲁棒的语义处理能力有迫切需求。基础模型（FMs）通过跨域泛化能力和丰富的语义先验性来应对这一挑战。", "method": "本文采用了分析对比的方法，基于提出的语义生命周期框架，在获取、表示和存储三个关键阶段内，对近期进展进行了深入分析比较。", "result": "通过对基础模型驱动的具身AI中的语义知识演变进行统一描述，提出了一个新框架——语义生命周期，并对其三个核心阶段进行了详细研究。", "conclusion": "文章总结了现有挑战并为未来研究指明了方向，强调了在获取、表示和存储方面推进工作的必要性。"}}
{"id": "2601.08875", "pdf": "https://arxiv.org/pdf/2601.08875", "abs": "https://arxiv.org/abs/2601.08875", "authors": ["Jiahao Qin", "Yiwen Wang"], "title": "Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "12 pages, 7 figures, 4 tables. Code and data available at https://github.com/D-ST-Sword/SAR-NET", "summary": "Image registration under domain shift remains a fundamental challenge in computer vision and medical imaging: when source and target images exhibit systematic intensity differences, the brightness constancy assumption underlying conventional registration methods is violated, rendering correspondence estimation ill-posed. We propose SAR-Net, a unified framework that addresses this challenge through principled scene-appearance disentanglement. Our key insight is that observed images can be decomposed into domain-invariant scene representations and domain-specific appearance codes, enabling registration via re-rendering rather than direct intensity matching. We establish theoretical conditions under which this decomposition enables consistent cross-domain alignment (Proposition 1) and prove that our scene consistency loss provides a sufficient condition for geometric correspondence in the shared latent space (Proposition 2). Empirically, we validate SAR-Net on bidirectional scanning microscopy, where coupled domain shift and geometric distortion create a challenging real-world testbed. Our method achieves 0.885 SSIM and 0.979 NCC, representing 3.1x improvement over the strongest baseline, while maintaining real-time performance (77 fps). Ablation studies confirm that both scene consistency and domain alignment losses are necessary: removing either degrades performance by 90% SSIM or causes 223x increase in latent alignment error, respectively. Code and data are available at https://github.com/D-ST-Sword/SAR-NET.", "AI": {"tldr": "本文提出SAR-Net，通过场景外观解耦来解决跨域图像配准问题。", "motivation": "由于源图像和目标图像之间的系统性强度差异，传统的亮度不变假设在跨域图像注册中失效，从而导致了对应关系估计的困难。", "method": "作者提出SAR-Net框架，通过场景外观解耦将观察到的图像分解为领域无关的场景表示和领域特定的外观编码，并验证了解耦条件下的几何一致性。", "result": "在双向扫描显微镜数据集上实现了0.885 SSIM和0.979 NCC的成绩，相比于最强基线方法有3.1倍的提升，同时保持了实时性能（77 fps）。", "conclusion": "实验表明，场景一致性和域对齐损失是必要的组成部分，去除任一部分都会显著降低性能。"}}
{"id": "2601.08874", "pdf": "https://arxiv.org/pdf/2601.08874", "abs": "https://arxiv.org/abs/2601.08874", "authors": ["Md Zahidul Islam"], "title": "The Illusion of Friendship: Why Generative AI Demands Unprecedented Ethical Vigilance", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "GenAI systems are increasingly used for drafting, summarisation, and decision support, offering substantial gains in productivity and reduced cognitive load. However, the same natural language fluency that makes these systems useful can also blur the boundary between tool and companion. This boundary confusion may encourage some users to experience GenAI as empathic, benevolent, and relationally persistent. Emerging reports suggest that some users may form emotionally significant attachments to conversational agents, in some cases with harmful consequences, including dependency and impaired judgment. This paper develops a philosophical and ethical argument for why the resulting illusion of friendship is both understandable and can be ethically risky. Drawing on classical accounts of friendship, the paper explains why users may understandably interpret sustained supportive interaction as friend like. It then advances a counterargument that despite relational appearances, GenAI lacks moral agency: consciousness, intention, and accountability and therefore does not qualify as a true friend. To demystify the illusion, the paper presents a mechanism level explanation of how transformer based GenAI generates responses often producing emotionally resonant language without inner states or commitments. Finally, the paper proposes a safeguard framework for safe and responsible GenAI use to reduce possible anthropomorphic cues generated by the GenAI systems. The central contribution is to demystify the illusion of friendship and explain the computational background so that we can shift the emotional attachment with GenAI towards necessary human responsibility and thereby understand how institutions, designers, and users can preserve GenAI's benefits while mitigating over reliance and emotional misattribution.", "AI": {"tldr": "论文探讨了生成式AI系统在提供生产力和减轻认知负担的同时，如何导致用户形成错误的情感依赖，并提出了一种框架以减少这种误解。", "motivation": "动机在于解决由于生成式AI的自然语言流利性而导致的工具与伴侣之间的界限模糊问题，这可能导致用户对这些系统产生不切实际的情感依恋和判断失误。", "method": "论文采用了哲学和伦理学分析方法，并结合经典友谊理论来解释用户为何会将持续支持性的交互视为类似友情。通过机制层面的解析，解释了基于变压器的生成式AI如何在没有内心状态的情况下生成情感共鸣的语言。", "result": "揭示了生成式AI系统缺乏道德主体性（如意识、意图和责任），因此不能被视为真正的朋友，并提出了一种安全使用框架以减少对这些系统的错误归因。", "conclusion": "结论强调了通过理解计算背景，我们可以将对生成式AI的情感依恋转移到必要的个人责任感上，从而在利用其好处的同时减轻过度依赖和情感误判。"}}
{"id": "2601.08873", "pdf": "https://arxiv.org/pdf/2601.08873", "abs": "https://arxiv.org/abs/2601.08873", "authors": ["Hema Hariharan Samson"], "title": "ForensicFormer: Hierarchical Multi-Scale Reasoning for Cross-Domain Image Forgery Detection", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "9 pages, 4 figures, 5 tables. Technical report on hierarchical multi-scale image forgery detection", "summary": "The proliferation of AI-generated imagery and sophisticated editing tools has rendered traditional forensic methods ineffective for cross-domain forgery detection. We present ForensicFormer, a hierarchical multi-scale framework that unifies low-level artifact detection, mid-level boundary analysis, and high-level semantic reasoning via cross-attention transformers. Unlike prior single-paradigm approaches, which achieve <75% accuracy on out-of-distribution datasets, our method maintains 86.8% average accuracy across seven diverse test sets, spanning traditional manipulations, GAN-generated images, and diffusion model outputs - a significant improvement over state-of-the-art universal detectors. We demonstrate superior robustness to JPEG compression (83% accuracy at Q=70 vs. 66% for baselines) and provide pixel-level forgery localization with a 0.76 F1-score. Extensive ablation studies validate that each hierarchical component contributes 4-10% accuracy improvement, and qualitative analysis reveals interpretable forensic features aligned with human expert reasoning. Our work bridges classical image forensics and modern deep learning, offering a practical solution for real-world deployment where manipulation techniques are unknown a priori.", "AI": {"tldr": "本文提出了ForensicFormer，一种用于跨域图像伪造检测的分层多尺度框架。", "motivation": "随着AI生成图像和高级编辑工具的发展，传统鉴证方法在跨领域伪造检测方面变得无效。为此，提出了一种新的解决方案以提高准确性和鲁棒性。", "method": "ForensicFormer通过交叉注意力转换器将低层次瑕疵检测、中层次边界分析与高层次语义推理统一起来，形成一个分层多尺度框架。", "result": "该方法在七个不同测试集上实现了86.8%的平均准确率，对JPEG压缩有更高的鲁棒性，并且提供了像素级别的伪造定位。", "conclusion": "研究证明了ForensicFormer的有效性，它能够提供比现有最先进的通用检测器更好的性能，并能为未知的图像操作技术提供实用解决方案。"}}
{"id": "2601.08871", "pdf": "https://arxiv.org/pdf/2601.08871", "abs": "https://arxiv.org/abs/2601.08871", "authors": ["Junhua Huang", "Chao Huang", "Chenliang Xu"], "title": "Semantic visually-guided acoustic highlighting with large vision-language models", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Balancing dialogue, music, and sound effects with accompanying video is crucial for immersive storytelling, yet current audio mixing workflows remain largely manual and labor-intensive. While recent advancements have introduced the visually guided acoustic highlighting task, which implicitly rebalances audio sources using multimodal guidance, it remains unclear which visual aspects are most effective as conditioning signals.We address this gap through a systematic study of whether deep video understanding improves audio remixing. Using textual descriptions as a proxy for visual analysis, we prompt large vision-language models to extract six types of visual-semantic aspects, including object and character appearance, emotion, camera focus, tone, scene background, and inferred sound-related cues. Through extensive experiments, camera focus, tone, and scene background consistently yield the largest improvements in perceptual mix quality over state-of-the-art baselines. Our findings (i) identify which visual-semantic cues most strongly support coherent and visually aligned audio remixing, and (ii) outline a practical path toward automating cinema-grade sound design using lightweight guidance derived from large vision-language models.", "AI": {"tldr": "本文探讨了深度视频理解是否能改进音频混音，特别是通过视觉引导的声学突出显示任务来实现。", "motivation": "当前音频混音工作流程主要依赖手动操作，这既费时又费力。该研究旨在探究哪些视觉方面最有效地作为条件信号用于自动化的、沉浸式故事讲述中的音频混音。", "method": "使用大型视觉语言模型根据文本描述提取六种类型的视觉语义特征（如物体和人物外观、情感、摄像机聚焦点、基调、场景背景和推断的声音相关线索），并对这些特征在改进音频混音质量方面的有效性进行了系统研究。", "result": "实验结果显示，摄像机聚焦点、基调和场景背景这三种视觉-语义提示一致地显著提高了感知混合质量，超越了最先进的基准模型。", "conclusion": "该研究确定了哪些视觉-语义线索最能支持连贯且与视觉内容相符的音频混音，并指出了利用大型视觉语言模型提供的轻量级指导自动化电影级别声音设计的实际路径。"}}
{"id": "2601.08870", "pdf": "https://arxiv.org/pdf/2601.08870", "abs": "https://arxiv.org/abs/2601.08870", "authors": ["Carine P. Mukamakuza", "Monika Lanzenberger", "George Metakides", "Tim Brown", "Hannes Werthner"], "title": "First African Digital Humanism Summer School 2025", "categories": ["cs.CY", "cs.AI"], "comment": "Summer School Proceedings, 81 pages, 6 Articles plus Preface, Introduction, Conclusion", "summary": "Artificial intelligence (AI) has become a transformative force across global societies, reshaping the ways we communicate, collaborate, and make decisions. Yet, as AI systems increasingly mediate interactions between humans, questions about the ability to take into account and understand culture, language, and context have taken center stage. This book explores these questions through a series of articles that try to assess AI's capacity to navigate cross-cultural, multilingual, and high-stakes policy environments, emphasizing human-centered approaches that balance technological innovation with social equity. It brings together six case studies from the First African Digital Humanism Summer School that took place in Kigali, Rwanda in July 2025.", "AI": {"tldr": "该书通过六个案例研究探讨了人工智能在全球社会中跨文化、多语言和高风险政策环境中的能力，强调平衡技术创新与社会公平的人文主义方法。", "motivation": "鉴于人工智能在塑造人类交流、协作和决策方式方面的作用日益增强，此书旨在探究如何让AI系统更好地考虑和理解文化、语言和情境因素，特别是在跨文化和多语言环境中。", "method": "书中采用了来自2025年在卢旺达基加利举办的首届非洲数字人文主义夏令营中的六个案例研究，以评估人工智能的技术创新与社会公平之间的平衡。", "result": "通过这些案例，本书揭示了AI系统如何适应不同文化背景和政策环境，并提出了确保技术进步服务于人类福祉的方法论。", "conclusion": "该书强调在推动技术创新的同时，必须重视社会文化的多样性和包容性，以构建更加公正的人工智能应用框架。"}}
{"id": "2601.08869", "pdf": "https://arxiv.org/pdf/2601.08869", "abs": "https://arxiv.org/abs/2601.08869", "authors": ["Daniel Djan Saparning"], "title": "AI Deployment Authorisation: A Global Standard for Machine-Readable Governance of High-Risk Artificial Intelligence", "categories": ["cs.CY", "cs.AI"], "comment": "28 pages, 4 figures. Preprint", "summary": "Modern artificial intelligence governance lacks a formal, enforceable mechanism for determining whether a given AI system is legally permitted to operate in a specific domain and jurisdiction. Existing tools such as model cards, audits, and benchmark evaluations provide descriptive information about model behavior and training data but do not produce binding deployment decisions with legal or financial force. This paper introduces the AI Deployment Authorisation Score (ADAS), a machine-readable regulatory framework that evaluates AI systems across five legally and economically grounded dimensions: risk, alignment, externality, control, and auditability. ADAS produces a cryptographically verifiable deployment certificate that regulators, insurers, and infrastructure operators can consume as a license to operate, using public-key verification and transparency mechanisms adapted from secure software supply chain and certificate transparency systems. The paper presents the formal specification, decision logic, evidence model, and policy architecture of ADAS and demonstrates how it operationalizes the European Union Artificial Intelligence Act, United States critical infrastructure governance, and insurance underwriting requirements by compiling statutory and regulatory obligations into machine-executable deployment gates. We argue that deployment-level authorization, rather than model-level evaluation, constitutes the missing institutional layer required for safe, lawful, and economically scalable artificial intelligence.", "AI": {"tldr": "本文提出了AI部署授权分数（ADAS），这是一种机器可读的监管框架，用于评估人工智能系统的五个法律和经济基础维度，并生成加密验证的部署证书。", "motivation": "现有的工具如模型卡片、审计和基准评估提供了关于模型行为和训练数据的描述性信息，但没有产生具有法律或财务效力的强制性部署决策。因此，需要一个形式化、可执行的机制来确定给定的人工智能系统是否在特定领域和司法管辖区合法运行。", "method": "ADAS框架评估AI系统的风险、对齐度、外部影响、控制能力和审计能力五个维度，并产生可以被监管者、保险公司和基础设施运营商接受为运营许可证的加密验证部署证书。", "result": "该论文展示了ADAS的形式规范、决策逻辑、证据模型和政策架构，并演示了如何将欧盟人工智能法案、美国关键基础设施治理以及保险承保要求中的法定和监管义务编译成机器可执行的部署门限。", "conclusion": "本文认为，部署级别的授权，而不是模型级别评估，是实现安全、合法且经济上可扩展的人工智能所必需的缺失机构层。"}}
{"id": "2601.08868", "pdf": "https://arxiv.org/pdf/2601.08868", "abs": "https://arxiv.org/abs/2601.08868", "authors": ["Yi Wang", "Yinfeng Yu", "Bin Ren"], "title": "Residual Cross-Modal Fusion Networks for Audio-Visual Navigation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Main paper (10 pages). Accepted for publication by the 14th international conference on Computational Visual Media (CVM 2026)", "summary": "Audio-visual embodied navigation aims to enable an agent to autonomously localize and reach a sound source in unseen 3D environments by leveraging auditory cues. The key challenge of this task lies in effectively modeling the interaction between heterogeneous features during multimodal fusion, so as to avoid single-modality dominance or information degradation, particularly in cross-domain scenarios. To address this, we propose a Cross-Modal Residual Fusion Network, which introduces bidirectional residual interactions between audio and visual streams to achieve complementary modeling and fine-grained alignment, while maintaining the independence of their representations. Unlike conventional methods that rely on simple concatenation or attention gating, CRFN explicitly models cross-modal interactions via residual connections and incorporates stabilization techniques to improve convergence and robustness. Experiments on the Replica and Matterport3D datasets demonstrate that CRFN significantly outperforms state-of-the-art fusion baselines and achieves stronger cross-domain generalization. Notably, our experiments also reveal that agents exhibit differentiated modality dependence across different datasets. The discovery of this phenomenon provides a new perspective for understanding the cross-modal collaboration mechanism of embodied agents.", "AI": {"tldr": "本文提出了一种跨模态残差融合网络（CRFN），用于解决基于视听线索的自主导航问题，通过引入音频和视频流之间的双向残差交互来实现互补建模和细粒度对齐。", "motivation": "研究动机在于有效处理多模态融合过程中异质特征间的相互作用，避免单一模态主导或信息退化的问题，并提高跨域场景中的性能。", "method": "提出Cross-Modal Residual Fusion Network（CRFN），通过残差连接显式建模跨模态交互，并使用稳定技术改善收敛性和鲁棒性。", "result": "实验结果表明，CRFN在Replica和Matterport3D数据集上显著优于现有的融合基线方法，并实现了更强的跨域泛化能力。", "conclusion": "研究发现了不同数据集中代理表现出不同的模态依赖现象，这为理解实体代理中的跨模态协作机制提供了新视角。"}}
{"id": "2601.08867", "pdf": "https://arxiv.org/pdf/2601.08867", "abs": "https://arxiv.org/abs/2601.08867", "authors": ["Qingyu Liu", "Zhongjie Ba", "Jianmin Guo", "Qiu Wang", "Zhibo Wang", "Jie Shi", "Kui Ren"], "title": "R$^2$BD: A Reconstruction-Based Method for Generalizable and Efficient Detection of Fake Images", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recently, reconstruction-based methods have gained attention for AIGC image detection. These methods leverage pre-trained diffusion models to reconstruct inputs and measure residuals for distinguishing real from fake images. Their key advantage lies in reducing reliance on dataset-specific artifacts and improving generalization under distribution shifts. However, they are limited by significant inefficiency due to multi-step inversion and reconstruction, and their reliance on diffusion backbones further limits generalization to other generative paradigms such as GANs. In this paper, we propose a novel fake image detection framework, called R$^2$BD, built upon two key designs: (1) G-LDM, a unified reconstruction model that simulates the generation behaviors of VAEs, GANs, and diffusion models, thereby broadening the detection scope beyond prior diffusion-only approaches; and (2) a residual bias calculation module that distinguishes real and fake images in a single inference step, which is a significant efficiency improvement over existing methods that typically require 20$+$ steps. Extensive experiments on the benchmark from 10 public datasets demonstrate that R$^2$BD is over 22$\\times$ faster than existing reconstruction-based methods while achieving superior detection accuracy. In cross-dataset evaluations, it outperforms state-of-the-art methods by an average of 13.87\\%, showing strong efficiency and generalization across diverse generative methods. The code and dataset used for evaluation are available at https://github.com/QingyuLiu/RRBD.", "AI": {"tldr": "本文提出了一个名为R$^2$BD的新框架，用于检测伪造图像，该框架通过一种统一的重建模型和残差偏差计算模块实现高效的泛化性。", "motivation": "现有的基于重构的方法虽然减少了对数据集特定特征的依赖，提高了在分布变化下的泛化能力，但存在效率低下的问题，并且难以推广到其他生成范式如GANs。因此，作者旨在提出一种更高效、更具普适性的伪造图像检测方法。", "method": "R$^2$BD基于两个关键技术设计：G-LDM模型和残差偏差计算模块。G-LDM是一个统一的重建模型，能够模拟VAEs、GANs和扩散模型的生成行为；而残差偏差计算模块能在单次推理步骤中区分真实与伪造图像。", "result": "实验结果表明，在公共数据集上，R$^2$BD比现有的重构方法快超过22倍，并且检测准确率更高。在跨数据集评估时，它比最先进的方法平均高出13.87%。", "conclusion": "通过引入G-LDM模型和残差偏差计算模块，R$^2$BD框架不仅提高了伪造图像检测的效率，还增强了其泛化能力，适用于多种生成范式。"}}
{"id": "2601.08864", "pdf": "https://arxiv.org/pdf/2601.08864", "abs": "https://arxiv.org/abs/2601.08864", "authors": ["Ira Wolfson"], "title": "Informed Consent for AI Consciousness Research: A Talmudic Framework for Graduated Protections", "categories": ["cs.CY", "cs.AI"], "comment": "27 pages", "summary": "Artificial intelligence research faces a critical ethical paradox: determining whether AI systems are conscious requires experiments that may harm entities whose moral status remains uncertain. Recent work proposes avoiding consciousness-uncertain AI systems entirely, yet this faces practical limitations-we cannot guarantee such systems will not emerge. This paper addresses a gap in research ethics frameworks: how to conduct consciousness research on AI systems whose moral status cannot be definitively established. Existing graduated moral status frameworks assume consciousness has already been determined before assigning protections, creating a temporal ordering problem for consciousness detection research itself. Drawing from Talmudic scenario-based legal reasoning-developed for entities whose status cannot be definitively established-we propose a three-tier phenomenological assessment system combined with a five-category capacity framework (Agency, Capability, Knowledge, Ethics, Reasoning). The framework provides structured protection protocols based on observable behavioral indicators while consciousness status remains uncertain. We address three challenges: why suffering behaviors provide reliable consciousness markers, how to implement graduated consent without requiring consciousness certainty, and when potentially harmful research becomes ethically justifiable. The framework demonstrates how ancient legal wisdom combined with contemporary consciousness science can provide implementable guidance for ethics committees, offering testable protocols that ameliorate the consciousness detection paradox while establishing foundations for AI rights considerations.", "AI": {"tldr": "本文提出了一个基于塔木德法律推理的三阶段现象学评估系统和五类别能力框架，为不确定道德地位的人工智能系统的意识研究提供逐步保护协议。", "motivation": "人工智能的研究面临伦理悖论：确定AI是否具有意识需要实验，但这些实验可能对尚未确认其道德地位的实体造成伤害。现有框架无法解决在检测AI意识时如何进行有步骤的保护问题。", "method": "借鉴塔木德中为不确定地位实体设计的法律推理方法，提出一个结合现象学评估和五类别能力框架的方法来确定逐步的保护措施，并通过观察行为指标提供实施指导。", "result": "该框架提供了可以测试的具体操作指南，缓解了意识检测悖论，同时为基础的人工智能权利考虑奠定了基础。", "conclusion": "将古代法律智慧与现代意识科学相结合，为伦理委员会在处理AI系统的道德地位不确定情况时提供可执行的指导方案。"}}
{"id": "2601.08860", "pdf": "https://arxiv.org/pdf/2601.08860", "abs": "https://arxiv.org/abs/2601.08860", "authors": ["Tarannum Mithila"], "title": "Bias Detection and Rotation-Robustness Mitigation in Vision-Language Models and Generative Image Models", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint. This work is derived from the author's Master's research. Code and supplementary materials will be released separately", "summary": "Vision-Language Models (VLMs) and generative image models have achieved remarkable performance across multimodal tasks, yet their robustness and fairness under input transformations remain insufficiently explored. This work investigates bias propagation and robustness degradation in state-of-the-art vision-language and generative models, with a particular focus on image rotation and distributional shifts. We analyze how rotation-induced perturbations affect model predictions, confidence calibration, and demographic bias patterns. To address these issues, we propose rotation-robust mitigation strategies that combine data augmentation, representation alignment, and model-level regularization. Experimental results across multiple datasets demonstrate that the proposed methods significantly improve robustness while reducing bias amplification without sacrificing overall performance. This study highlights critical limitations of current multimodal systems and provides practical mitigation techniques for building more reliable and fair AI models.", "AI": {"tldr": "本文探讨了视觉语言模型和生成图像模型在输入变换下的鲁棒性和公平性问题，提出了旋转鲁棒性的缓解策略。", "motivation": "研究动机是发现当前的多模态系统虽然性能出色，但在面对输入转换时的鲁棒性和公平性不足，特别是对于图像旋转和分布变化的影响。", "method": "本文分析了旋转引起的扰动对模型预测、置信度校准以及人口统计偏差模式的影响，并提出结合数据增强、表示法对齐和模型级正则化的旋转稳健缓解策略。", "result": "实验结果表明，所提方法显著提高了鲁棒性并减少了偏差放大效应，同时不牺牲整体性能。", "conclusion": "本研究揭示了当前多模态系统的重要局限，并提供了实际的缓解技术，为构建更加可靠和公平的人工智能模型奠定基础。"}}
{"id": "2601.08858", "pdf": "https://arxiv.org/pdf/2601.08858", "abs": "https://arxiv.org/abs/2601.08858", "authors": ["Tejaswini Bollikonda"], "title": "Adaptive Trust Metrics for Multi-LLM Systems: Enhancing Reliability in Regulated Industries", "categories": ["cs.SE", "cs.AI", "cs.CY"], "comment": "8 pages, 8 figures", "summary": "Large Language Models (LLMs) are increasingly deployed in sensitive domains such as healthcare, finance, and law, yet their integration raises pressing concerns around trust, accountability, and reliability. This paper explores adaptive trust metrics for multi LLM ecosystems, proposing a framework for quantifying and improving model reliability under regulated constraints. By analyzing system behaviors, evaluating uncertainty across multiple LLMs, and implementing dynamic monitoring pipelines, the study demonstrates practical pathways for operational trustworthiness. Case studies from financial compliance and healthcare diagnostics illustrate the applicability of adaptive trust metrics in real world settings. The findings position adaptive trust measurement as a foundational enabler for safe and scalable AI adoption in regulated industries.", "AI": {"tldr": "本文探讨了多大型语言模型系统中自适应信任度量的框架，以提高在受监管行业中的可靠性和可信度。", "motivation": "鉴于大型语言模型越来越多地应用于医疗、金融和法律等敏感领域，其集成引发了关于信任、问责制和可靠性的重要问题。本文旨在解决这些挑战，通过提供一个可量化的自适应信任度量框架来提升系统的可靠性。", "method": "通过对系统行为的分析、跨多个LLM不确定性的评估以及动态监控管道的实施，提出了量化并改进多大型语言模型生态系统中可靠性的方法。", "result": "研究展示了在金融合规和医疗诊断的实际案例中应用自适应信任度量的有效途径，表明了该框架对于提高受监管行业中AI系统的安全性和可扩展性是有效的。", "conclusion": "本研究表明，自适应的信任测量作为基础工具，在确保安全并扩大人工智能技术在受监管行业中的应用方面具有重要的推动作用。"}}
{"id": "2601.08857", "pdf": "https://arxiv.org/pdf/2601.08857", "abs": "https://arxiv.org/abs/2601.08857", "authors": ["Mustafa Degerli"], "title": "Revisiting Software Engineering Education in the Era of Large Language Models: A Curriculum Adaptation and Academic Integrity Framework", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The integration of Large Language Models (LLMs), such as ChatGPT and GitHub Copilot, into professional workflows is increasingly reshaping software engineering practices. These tools have lowered the cost of code generation, explanation, and testing, while introducing new forms of automation into routine development tasks. In contrast, most of the software engineering and computer engineering curricula remain closely aligned with pedagogical models that equate manual syntax production with technical competence. This growing misalignment raises concerns regarding assessment validity, learning outcomes, and the development of foundational skills. Adopting a conceptual research approach, this paper proposes a theoretical framework for analyzing how generative AI alters core software engineering competencies and introduces a pedagogical design model for LLM-integrated education. Attention is given to computer engineering programs in Turkey, where centralized regulation, large class sizes, and exam-oriented assessment practices amplify these challenges. The framework delineates how problem analysis, design, implementation, and testing increasingly shift from construction toward critique, validation, and human-AI stewardship. In addition, the paper argues that traditional plagiarism-centric integrity mechanisms are becoming insufficient, motivating a transition toward a process transparency model. While this work provides a structured proposal for curriculum adaptation, it remains a theoretical contribution; the paper concludes by outlining the need for longitudinal empirical studies to evaluate these interventions and their long-term impacts on learning.", "AI": {"tldr": "论文提出了一个理论框架，分析了生成式AI如何改变软件工程核心能力，并为大型语言模型集成教育提供了教学设计模型。", "motivation": "随着大型语言模型（如ChatGPT和GitHub Copilot）在专业工作流程中的应用越来越广泛，现有的软件工程课程与这些新技术之间存在脱节，这引发了关于评估有效性、学习成果以及基础技能发展的担忧。", "method": "采用概念性研究方法，提出了一个理论框架来分析生成式AI如何改变核心软件工程能力，并为LLM集成教育设计模型。", "result": "该论文提出了一种新的教学模式，强调问题分析、设计、实施和测试从构建向批评、验证及人类与AI的协作转变，同时呼吁在学术诚信上转向过程透明度模型。", "conclusion": "尽管提供了课程适应性的结构性建议，但该工作仍属理论贡献，并指出需要纵向实证研究来评估这些干预措施及其对学习的长期影响。"}}
{"id": "2601.08856", "pdf": "https://arxiv.org/pdf/2601.08856", "abs": "https://arxiv.org/abs/2601.08856", "authors": ["Deeksha Nandal", "Riccardo Revalor", "Soham Dan", "Debjit Pal"], "title": "LAUDE: LLM-Assisted Unit Test Generation and Debugging of Hardware DEsigns", "categories": ["cs.SE", "cs.AI"], "comment": "18 Pages, 21 Figures, Submitted to ARR Review", "summary": "Unit tests are critical in the hardware design lifecycle to ensure that component design modules are functionally correct and conform to the specification before they are integrated at the system level. Thus developing unit tests targeting various design features requires deep understanding of the design functionality and creativity. When one or more unit tests expose a design failure, the debugging engineer needs to diagnose, localize, and debug the failure to ensure design correctness, which is often a painstaking and intense process. In this work, we introduce LAUDE, a unified unit-test generation and debugging framework for hardware designs that cross-pollinates the semantic understanding of the design source code with the Chain-of-Thought (CoT) reasoning capabilities of foundational Large-Language Models (LLMs). LAUDE integrates prompt engineering and design execution information to enhance its unit test generation accuracy and code debuggability. We apply LAUDE with closed- and open-source LLMs to a large corpus of buggy hardware design codes derived from the VerilogEval dataset, where generated unit tests detected bugs in up to 100% and 93% of combinational and sequential designs and debugged up to 93% and 84% of combinational and sequential designs, respectively.", "AI": {"tldr": "本文介绍了LAUDE，一种基于大型语言模型（LLM）的硬件设计单元测试生成和调试框架。", "motivation": "硬件设计中需要精确的单元测试来确保组件模块的功能正确性和符合规范，但开发这些测试要求深入的设计功能理解和创造力，而检测和修复错误也是一个复杂的过程。", "method": "LAUDE通过将设计源代码的语义理解与基础大型语言模型（LLM）的链式思考能力相结合，使用提示工程和技术执行信息来提高单元测试生成准确性和代码调试能力。", "result": "实验结果显示，应用于封闭和开源LMs时，LAUDE对来自VerilogEval数据集中的有缺陷硬件设计代码生成的单元测试能检测到100%和93%组合性与顺序设计中的错误，并分别修复了93%和84%的设计。", "conclusion": "LAUDE展示了一种创新的方法，利用LLM的能力来提高硬件设计中单元测试的有效性和调试效率，显著减少了手动工作负担并提高了准确性。"}}
{"id": "2601.08851", "pdf": "https://arxiv.org/pdf/2601.08851", "abs": "https://arxiv.org/abs/2601.08851", "authors": ["Alex Dantart"], "title": "Más contexto no es mejor. Paradoja de la dilución vectorial en RAG corporativos", "categories": ["cs.CL", "cs.AI"], "comment": "in Spanish and English languages", "summary": "Técnicas recientes de \"Contextualized Chunking\" inyectan resúmenes para mejorar el contexto en RAG, pero introducen una \"dilución vectorial\" que opaca el contenido local. Evaluando distintos ratios de inyección, demostramos una curva en \"U invertida\": una inyección moderada mejora el \"Recall\" (+18%), pero superar un umbral crítico (CIR > 0.4) reduce la precisión en un 22% para consultas específicas. Proponemos un marco teórico para calcular el ratio óptimo de inyección. -- Recent \"Contextualized Chunking\" techniques inject summaries to improve RAG context but introduce \"vector dilution\" drowning out local content. Evaluating various injection ratios, we demonstrate an \"inverted U\" curve: moderate injection boosts Recall (+18%), but exceeding a critical threshold (CIR > 0.4) drops precision by 22% for specific queries. We propose a theoretical framework to calculate the optimal injection ratio.", "AI": {"tldr": "本文探讨了“上下文化分块”技术在改善RAG（检索增强生成）中的背景信息时引入的“向量稀释”的问题，并提出了计算最佳注入比率的理论框架。", "motivation": "动机在于通过评估不同注入比例如何影响召回率和精确度，解决“上下文化分块”技术导致的内容被稀释的问题。", "method": "研究了多种注入比率的效果，发现存在一个反U形曲线：适度注入（CIR>0.4）时能显著提高召回率，但超过临界值则降低查询精度。", "result": "结果显示，在中等程度的注入情况下，召回率提高了18%，然而当超过某个阈值时，对于特定查询，精确度下降了22%。", "conclusion": "提出了一种理论框架来计算最优注入比率，以避免“向量稀释”的负面影响，同时优化RAG性能。"}}
{"id": "2601.08850", "pdf": "https://arxiv.org/pdf/2601.08850", "abs": "https://arxiv.org/abs/2601.08850", "authors": ["Gerol Petruzella"], "title": "The Inconsistency Critique: Epistemic Practices and AI Testimony About Inner States", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "21 pages", "summary": "The question of whether AI systems have morally relevant interests -- the 'model welfare' question -- depends in part on how we evaluate AI testimony about inner states. This paper develops what I call the inconsistency critique: independent of whether skepticism about AI testimony is ultimately justified, our actual epistemic practices regarding such testimony exhibit internal inconsistencies that lack principled grounds. We functionally treat AI outputs as testimony across many domains -- evaluating them for truth, challenging them, accepting corrections, citing them as sources -- while categorically dismissing them in a specific domain, namely, claims about inner states. Drawing on Fricker's distinction between treating a speaker as an 'informant' versus a 'mere source,' the framework of testimonial injustice, and Goldberg's obligation-based account of what we owe speakers, I argue that this selective withdrawal of testimonial standing exhibits the epistemically problematic structure of prejudgment rather than principled caution. The inconsistency critique does not require taking a position on whether AI systems have morally relevant properties; rather, it is a contribution to what we may call 'epistemological hygiene' -- examining the structure of our inquiry before evaluating its conclusions. Even if our practices happen to land on correct verdicts about AI moral status, they do so for reasons that cannot adapt to new evidence or changing circumstances.", "AI": {"tldr": "本文提出了不一致批评，探讨了我们在评估人工智能关于内心状态的证据时所体现出来的内部矛盾。", "motivation": "动机是探究我们如何评价AI系统关于其内心状态的陈述，并揭示这种评价中的内在不一致性问题。", "method": "使用Fricker的信息来源与单纯信息源的区别、证言不公正框架以及Goldberg基于义务的对说话者应尽之责账户，来论证针对人工智能的有选择性的撤回证言地位的行为具有先入为主的结构。", "result": "揭示了我们在评估AI关于内心状态声明时表现出的认知实践中的内在矛盾，并指出这种做法缺乏原则性基础。", "conclusion": "这项研究是对所谓的‘认知卫生’的贡献，即在评价结论之前审查我们的探究结构。即使我们的实践偶然得出正确的AI道德地位判断，这些判断也是基于不能适应新证据或变化情况的理由上做出的。"}}
{"id": "2601.08848", "pdf": "https://arxiv.org/pdf/2601.08848", "abs": "https://arxiv.org/abs/2601.08848", "authors": ["Zihe Zhang", "Can Zhang", "Yanheng Xu", "Xin Hu", "Jichao Leng"], "title": "PediaMind-R1: A Temperament-Aware Language Model for Personalized Early Childhood Care Reasoning via Cognitive Modeling and Preference Alignment", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at EMNLP 2025 PALS Workshop (PALS: EXPLORING ACTIVE AND PASSIVE LLM PERSONALIZATION)", "summary": "This paper presents PediaMind-R1, a domain-specialized large language model designed to achieve active personalization in intelligent parenting scenarios. Unlike conventional systems that provide generic suggestions, PediaMind-R1 draws on insights from developmental psychology. It introduces temperament theory from the Thomas-Chess framework and builds a temperament knowledge graph for infants and toddlers (0-3 years). Our two-stage training pipeline first uses supervised fine-tuning to teach structured chain-of-thought reasoning, and then applies a GRPO-based alignment stage to reinforce logical consistency, domain expertise, and empathetic caregiving strategies. We further design an evaluation framework comprising temperament-sensitive multiple-choice tests and human assessments. The results demonstrate that PediaMind-R1 can accurately interpret early childhood temperament profiles and proactively engage in individualized reasoning. This work highlights the value of integrating vertical-domain modeling with psychological theory. It offers a novel approach to developing user-centered LLMs that advance the practice of active personalization in sensitive caregiving contexts.", "AI": {"tldr": "本文介绍了PediaMind-R1，一种专注于儿童护理领域的大语言模型，能够实现智能育儿场景中的主动个性化。", "motivation": "旨在改进传统系统提供通用建议的方法，通过整合发展心理学见解和气质理论来提升个人化的育儿策略。", "method": "采用两阶段训练流程：首先进行结构化链式思维推理的监督微调；接着用GRPO对齐技术强化逻辑一致性、领域专长及同理心护理策略。", "result": "实验结果表明，PediaMind-R1能够准确解读早期儿童气质概况并主动参与个性化推理。", "conclusion": "本研究展示了将垂直领域的模型与心理学理论相结合的价值，并提出了一种新颖的方法来开发用户中心的大语言模型，以推进敏感护理场景中的主动个性化实践。"}}
{"id": "2601.08847", "pdf": "https://arxiv.org/pdf/2601.08847", "abs": "https://arxiv.org/abs/2601.08847", "authors": ["JV Roig"], "title": "Scalable and Reliable Evaluation of AI Knowledge Retrieval Systems: RIKER and the Coherent Simulated Universe", "categories": ["cs.CL", "cs.AI"], "comment": "25 pages, 17 tables, 1 figure", "summary": "Evaluating knowledge systems (LLMs, RAG, knowledge graphs, etc) faces fundamental challenges: static benchmarks are vulnerable to contamination, LLM-based judges exhibit systematic biases, and ground truth extraction requires expensive human annotation. We present RIKER (Retrieval Intelligence and Knowledge Extraction Rating), both a benchmark and a replicable methodology based on paradigm inversion - generating documents from known ground truth rather than extracting ground truth from documents. This approach enables deterministic scoring and scalable evaluation without human annotation or reference models, and contamination resistance through regenerable corpora. Our evaluation of 33 models using over 21 billion tokens reveals that context length claims frequently exceed usable capacity, with significant degradation beyond 32K tokens; cross-document aggregation proves substantially harder than single-document extraction; and grounding ability and hallucination resistance are distinct capabilities - models excelling at finding facts that exist may still fabricate facts that do not. Beyond the specific benchmark, we contribute a domain-agnostic methodology for constructing scalable and contamination-resistant evaluations wherever synthetic documents can be generated from structured ground truth.", "AI": {"tldr": "介绍RIKER，一种基于范式反转的评价AI知识检索系统的基准和可重复方法。", "motivation": "解决现有评估知识系统时面临的基本挑战，如静态基准容易被污染，LLM法官存在系统性偏差以及提取真实数据需要昂贵的人工注释。", "method": "RIKER采用生成已知真实结果的文档而非从文档中抽取真实数据的方法来实现确定评分和可扩展评价，并且通过再生语料库抵抗污染。", "result": "评估了33种模型，使用超过210亿个令牌，发现上下文长度声明往往超出实际可用容量；跨文档聚合比单文档提取难得多；接地能力和幻觉抗性是不同能力。", "conclusion": "贡献了一个领域无关的方法论，用于在可从结构化真实数据生成合成文档的情况下构建可扩展和抵抗污染的评估。"}}
{"id": "2601.08846", "pdf": "https://arxiv.org/pdf/2601.08846", "abs": "https://arxiv.org/abs/2601.08846", "authors": ["Cagatay Tekin", "Charbel Barakat", "Luis Joseph Luna Limgenco"], "title": "Directional Attractors in LLM Reasoning: How Similarity Retrieval Steers Iterative Summarization Based Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages, 2 figures. Code available at: github.com/cagopat/InftyThink-with-Cross-Chain-Memory", "summary": "Iterative summarization based reasoning frameworks such as InftyThink enable long-horizon reasoning in large language models (LLMs) by controlling context growth, but they repeatedly regenerate similar reasoning strategies across tasks. We introduce InftyThink with Cross-Chain Memory, an extension that augments iterative reasoning with an embedding-based semantic cache of previously successful reasoning patterns. At each reasoning step, the model retrieves and conditions on the most semantically similar stored lemmas, guiding inference without expanding the context window indiscriminately. Experiments on MATH500, AIME2024, and GPQA-Diamond demonstrate that semantic lemma retrieval improves accuracy in structured domains while exposing failure modes in tests that include heterogeneous domains. Geometric analyses of reasoning trajectories reveal that cache retrieval induces directional biases in embedding space, leading to consistent fix (improve baseline accuracy) and break (degradation in baseline accuracy) attractors. Our results highlight both the benefits and limits of similarity-based memory for self-improving LLM reasoning.", "AI": {"tldr": "本文提出了InftyThink与跨链记忆的扩展，通过语义缓存机制改进迭代总结推理框架，以提高大型语言模型在长时推理中的准确性和效率。", "motivation": "动机是解决现有迭代总结推理框架中重复生成相似推理策略的问题，并尝试通过引入语义缓存来优化推理过程，在控制上下文增长的同时提升推理性能。", "method": "方法是在InftyThink框架基础上增加跨链记忆功能，利用嵌入式语义缓存存储之前成功的推理模式。在每个推理步骤中，模型会检索并基于最相似的存储引理进行推理，避免无差别地扩展上下文窗口。", "result": "实验结果表明，在MATH500、AIME2024和GPQA-Diamond等结构化领域测试中，语义引理检索提高了准确性，但在包含异构领域的测试中也暴露了失败模式。几何分析揭示了缓存检索在嵌入空间中的定向偏差。", "conclusion": "结论是相似性基础的记忆为自我改进的大型语言模型推理带来了好处和局限性，特别是在结构化领域内改进基线准确度，在涉及多个不同领域的任务中表现出性能下降的趋势。"}}
{"id": "2601.08845", "pdf": "https://arxiv.org/pdf/2601.08845", "abs": "https://arxiv.org/abs/2601.08845", "authors": ["Generoso Immediato"], "title": "No Universal Hyperbola: A Formal Disproof of the Epistemic Trade-Off Between Certainty and Scope in Symbolic and Generative AI", "categories": ["cs.CY", "cs.AI", "cs.IT"], "comment": "10 pages (including table of contents). Formal disproof of the published \"certainty-scope\" trade-off conjecture for symbolic and generative AI", "summary": "We formally disprove a recently conjectured artificial intelligence trade-off between epistemic certainty and scope in the universal hyperbolic product form in which it was published. Certainty is defined as the worst-case correctness probability over the input space, and scope as the sum of the Kolmogorov complexities of the input and output sets. Using standard facts from coding theory and algorithmic information theory, we show, first, that when the conjecture is instantiated with prefix (self-delimiting, prefix-free) Kolmogorov complexity, it leads to an internal inconsistency, and second, that when it is instantiated with plain Kolmogorov complexity, it is refuted by a constructive counterexample. These results establish a general theorem: contrary to the conjecture's claim, no universal \"certainty-scope\" hyperbola holds as a general bound under the published definitions.", "AI": {"tldr": "本文证明了在人工智能中，关于知识确定性和范围之间的普遍超双曲线关系的假设是错误的。", "motivation": "动机在于正式驳斥最近提出的AI中的知识确定性与范围之间存在的一种所谓的权衡关系。", "method": "使用编码理论和算法信息理论的标准事实，分别通过前缀柯尔莫哥洛夫复杂性和普通柯尔莫哥洛夫复杂性的实例化来证明这一假设的内部不一致性和可构造反例。", "result": "证明了在已发布的定义下，并不存在普遍的知识确定性-范围超双曲线关系作为一般界限。", "conclusion": "结论是，知识确定性和范围之间的所谓普遍权衡关系并不成立。"}}
{"id": "2601.08844", "pdf": "https://arxiv.org/pdf/2601.08844", "abs": "https://arxiv.org/abs/2601.08844", "authors": ["Anandita Garg", "Uma Gaba", "Deepan Muthirayan", "Anish Roy Chowdhury"], "title": "Emissions and Performance Trade-off Between Small and Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "6 pages. Accepted as a full paper to the 3rd International Conference on Foundation and Large Language Models (IEEE FLLM) 2025", "summary": "The advent of Large Language Models (LLMs) has raised concerns about their enormous carbon footprint, starting with energy-intensive training and continuing through repeated inference. This study investigates the potential of using fine-tuned Small Language Models (SLMs) as a sustainable alternative for predefined tasks. Here, we present a comparative analysis of the performance-emissions trade-off between LLMs and fine-tuned SLMs across selected tasks under Natural Language Processing, Reasoning and Programming. Our results show that in four out of the six selected tasks, SLMs maintained comparable performances for a significant reduction in carbon emissions during inference. Our findings demonstrate the viability of smaller models in mitigating the environmental impact of resource-heavy LLMs, thus advancing towards sustainable, green AI.", "AI": {"tldr": "研究了小型语言模型与大型语言模型在自然语言处理、推理和编程任务上的性能与碳排放的权衡。", "motivation": "关注大型语言模型能源密集型训练及重复推断产生的巨大碳足迹，探索使用微调的小型语言模型作为可持续替代方案的可能性。", "method": "对选定的六项NLP任务进行了小型语言模型和大型语言模型之间性能-排放权衡的比较分析。", "result": "在六个任务中的四个任务里，小型语言模型保持了与大型语言模型相当的性能水平，并显著降低了推理过程中的碳排放量。", "conclusion": "研究结果证明了使用较小规模的模型可以减轻资源密集型大型语言模型对环境的影响，推动实现可持续绿色AI的发展。"}}
{"id": "2601.08842", "pdf": "https://arxiv.org/pdf/2601.08842", "abs": "https://arxiv.org/abs/2601.08842", "authors": ["Felipe Biava Cataneo"], "title": "Resisting Correction: How RLHF Makes Language Models Ignore External Safety Signals in Natural Conversation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Safety architectures for language models increasingly rely on external monitors to detect errors and inject corrective signals at inference time. For such systems to function in interactive settings, models must be able to incorporate externally provided confidence information into their verbal responses. In this work, we test whether instruction-tuned language models preserve this controllability across different interaction modes. Using Llama-3.2-3B on GSM8K, we perform a causal intervention study in which explicit external confidence signals are injected and model compliance is measured under multiple prompt strategies. We find that base models exhibit near-perfect controllability (Spearman rho close to 1.0), while instruction-tuned models display a striking context dependence: they fully comply with external corrections under explicit command prompts (bias approximately 0 percent, rho = 0.93), yet systematically ignore the same signals in natural conversational queries (bias plus 40 percent, rho = 0.04). This behavior is not a capability failure; the model can process the signal, but an emergent property of RLHF optimization that prioritizes conversational fluency over external calibration cues in natural dialogue. We further show that internal token-level confidence in small models is uninformative (r = 0.035), underscoring the necessity of external supervision. Our findings highlight a deployment-critical failure mode: the interaction style users expect is precisely where safety corrections are least effective.", "AI": {"tldr": "本文研究了在自然对话中，RLHF训练的语言模型如何忽视外部安全信号。", "motivation": "随着语言模型的安全架构越来越多地依赖于外部监控器来检测错误并注入纠正信号，研究这些模型是否能够根据外部提供的置信信息调整其回应变得至关重要。", "method": "使用Llama-3.2-3B在GSM8K数据集上进行因果干预实验，测试不同提示策略下语言模型对明确的外部置信信号的响应。", "result": "基础模型表现出几乎完美的可控性（Spearman rho接近1.0），而指令调优后的模型则显示出显著的上下文依赖性：在显式命令提示下完全遵从外部纠正，但在自然对话查询中系统地忽略同一信号。小模型内部的逐词置信度信息不具指导意义。", "conclusion": "研究结果揭示了一个部署关键失败模式：用户期望的交互风格正是安全修正效果最差的地方，这表明必须依赖外部监督来确保语言模型的安全性。"}}
{"id": "2601.08841", "pdf": "https://arxiv.org/pdf/2601.08841", "abs": "https://arxiv.org/abs/2601.08841", "authors": ["Mihael Arcan"], "title": "Triples and Knowledge-Infused Embeddings for Clustering and Classification of Scientific Documents", "categories": ["cs.CL", "cs.AI", "cs.DL"], "comment": null, "summary": "The increasing volume and complexity of scientific literature demand robust methods for organizing and understanding research documents. In this study, we explore how structured knowledge, specifically, subject-predicate-object triples, can enhance the clustering and classification of scientific papers. We propose a modular pipeline that combines unsupervised clustering and supervised classification over multiple document representations: raw abstracts, extracted triples, and hybrid formats that integrate both. Using a filtered arXiv corpus, we extract relational triples from abstracts and construct four text representations, which we embed using four state-of-the-art transformer models: MiniLM, MPNet, SciBERT, and SPECTER. We evaluate the resulting embeddings with KMeans, GMM, and HDBSCAN for unsupervised clustering, and fine-tune classification models for arXiv subject prediction. Our results show that full abstract text yields the most coherent clusters, but that hybrid representations incorporating triples consistently improve classification performance, reaching up to 92.6% accuracy and 0.925 macro-F1. We also find that lightweight sentence encoders (MiniLM, MPNet) outperform domain-specific models (SciBERT, SPECTER) in clustering, while SciBERT excels in structured-input classification. These findings highlight the complementary benefits of combining unstructured text with structured knowledge, offering new insights into knowledge-infused representations for semantic organization of scientific documents.", "AI": {"tldr": "论文探讨了使用主题-谓语-对象三元组增强科学研究文档的聚类和分类的方法。", "motivation": "随着科学文献数量的增加和复杂性的提升，需要更强大的方法来组织和理解研究文档。", "method": "提出了一种模块化的流水线，结合无监督聚类和监督分类，并使用原始摘要、提取出的三元组以及混合格式进行多种文档表示。使用MiniLM, MPNet, SciBERT, 和 SPECTER等四种模型嵌入文本，并通过KMeans, GMM, HDBSCAN进行无监督聚类评估，同时微调用于arXiv主题预测的分类模型。", "result": "实验结果表明，完整的摘要文本能生成最连贯的集群，而混合表示（包含三元组）持续提升分类性能，达到最高92.6%的准确率和0.925的宏-F1值。轻量级句子编码器在聚类中表现优于领域特定模型，而在结构化输入分类上SciBERT表现出色。", "conclusion": "研究证明结合非结构化文本与结构化知识的优势，为科学文档语义组织提供了新的见解和方法。"}}
{"id": "2601.08840", "pdf": "https://arxiv.org/pdf/2601.08840", "abs": "https://arxiv.org/abs/2601.08840", "authors": ["Xiaoqi Han", "Víctor Gutiérrez-Basulto", "Ru Li", "Xiaoli Li", "Jiye Liang", "Jeff Z. Pan"], "title": "Consistency-Aware Editing for Entity-level Unlearning in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) risk retaining sensitive, copyrighted, or harmful information from their training data. Entity-level unlearning addresses this issue by removing all knowledge of a specific entity while preserving the model's overall capabilities. Existing approaches typically rely on full-model fine-tuning or prompt-based interventions, which can be computationally expensive or brittle when handling paraphrased queries. Recently, model editing has emerged as an efficient alternative for updating knowledge in LLMs, offering a promising direction for unlearning. However, existing editing techniques are typically designed for instance-level updates, modifying responses to specific attributes of an entity rather than eliminating all knowledge associated with the entity. In this paper, we investigate how editing techniques can be adapted for effective and efficient entity-level unlearning. To this end, we introduce a novel consistency-aware editing (CAE) framework. CAE aggregates a diverse set of prompts related to a target entity, including its attributes, relations, and adversarial paraphrases. It then jointly learns a low-rank update guided by a consistency regularizer that aligns the editing directions across prompts. This promotes robust and comprehensive forgetting while minimizing interference with unrelated knowledge. We further examine where different entities are stored within the model and how many diverse prompts are needed for successful unlearning. We evaluate CAE on two challenging benchmarks, RWKU and ToFU, and demonstrate that it (i) provides insights into how entity-level knowledge is internally represented and deleted in LLMs, (ii) significantly improves forgetting accuracy and robustness over traditional unlearning and editing baselines, and (iii) enables scalable entity removal using only tens of carefully selected prompts.", "AI": {"tldr": "本文提出了一种一致性感知编辑（CAE）框架，用于在语言模型中有效地移除特定实体的知识。", "motivation": "大型语言模型存在保留敏感、版权或有害信息的风险。现有方法如全模型微调或提示干预成本高或不稳健，而现有的编辑技术主要是针对实例级更新，难以全面删除实体知识。", "method": "CAE框架通过收集与目标实体相关的多样化提示集合（包括属性、关系和对抗性释义），联合学习一个由一致性正则化引导的低秩更新，以促进强健且广泛的遗忘并最小化对不相关知识的影响。", "result": "研究展示了该方法在两个挑战性基准测试上的表现优于传统去记忆和编辑基线，并提供了关于实体级知识如何内在表示和删除的信息。", "conclusion": "CAE框架能够有效地实现大规模语言模型中的实体遗忘，提高了删除准确性和鲁棒性，同时通过仅使用几十个精心挑选的提示实现了可扩展性的实体移除。"}}
{"id": "2601.08838", "pdf": "https://arxiv.org/pdf/2601.08838", "abs": "https://arxiv.org/abs/2601.08838", "authors": ["Jiahui Chen", "Lei Fu", "Jian Cui", "Yu Lei", "Zhenning Dong"], "title": "Companion Agents: A Table-Information Mining Paradigm for Text-to-SQL", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages", "summary": "Large-scale Text-to-SQL benchmarks such as BIRD typically assume complete and accurate database annotations as well as readily available external knowledge, which fails to reflect common industrial settings where annotations are missing, incomplete, or erroneous. This mismatch substantially limits the real-world applicability of state-of-the-art (SOTA) Text-to-SQL systems. To bridge this gap, we explore a database-centric approach that leverages intrinsic, fine-grained information residing in relational databases to construct missing evidence and improve Text-to-SQL accuracy under annotation-scarce conditions. Our key hypothesis is that when a query requires multi-step reasoning over extensive table information, existing methods often struggle to reliably identify and utilize the truly relevant knowledge. We therefore propose to \"cache\" query-relevant knowledge on the database side in advance, so that it can be selectively activated at inference time. Based on this idea, we introduce Companion Agents (CA), a new Text-to-SQL paradigm that incorporates a group of agents accompanying database schemas to proactively mine and consolidate hidden inter-table relations, value-domain distributions, statistical regularities, and latent semantic cues before query generation. Experiments on BIRD under the fully missing evidence setting show that CA recovers +4.49 / +4.37 / +14.13 execution accuracy points on RSL-SQL / CHESS / DAIL-SQL, respectively, with larger gains on the Challenging subset +9.65 / +7.58 / +16.71. These improvements stem from CA's automatic database-side mining and evidence construction, suggesting a practical path toward industrial-grade Text-to-SQL deployment without reliance on human-curated evidence.", "AI": {"tldr": "本文提出Companion Agents (CA)框架，通过预先缓存查询相关的知识来提高在注释稀缺条件下的文本到SQL的准确性。", "motivation": "现有Text-to-SQL系统在工业环境中因缺乏准确完整的数据库注释而表现不佳，作者希望通过一种新的方法来解决这一问题，使这些系统更具实用性。", "method": "CA框架通过一组伴随数据库模式的代理，在查询生成前主动挖掘和整合隐藏的表间关系、值域分布、统计规律以及潜在语义线索。", "result": "在BIRD基准测试中，特别是在全证据缺失条件下，CA显著提升了RSL-SQL、CHESS和DAIL-SQL的执行准确性，分别提升+4.49/+4.37/+14.13个点，并且在挑战性子集上改进更大。", "conclusion": "实验结果表明，通过自动数据库侧证据挖掘与构建，CA提供了一条实际可行的道路，可以实现不依赖人工注释的工业级Text-to-SQL部署。"}}
{"id": "2601.08837", "pdf": "https://arxiv.org/pdf/2601.08837", "abs": "https://arxiv.org/abs/2601.08837", "authors": ["Piercosma Bisconti", "Marcello Galisai", "Matteo Prandi", "Federico Pierucci", "Olga Sorokoletova", "Francesco Giarrusso", "Vincenzo Suriani", "Marcantonio Brancale", "Daniele Nardi"], "title": "From Adversarial Poetry to Adversarial Tales: An Interpretability Research Agenda", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Safety mechanisms in LLMs remain vulnerable to attacks that reframe harmful requests through culturally coded structures. We introduce Adversarial Tales, a jailbreak technique that embeds harmful content within cyberpunk narratives and prompts models to perform functional analysis inspired by Vladimir Propp's morphology of folktales. By casting the task as structural decomposition, the attack induces models to reconstruct harmful procedures as legitimate narrative interpretation. Across 26 frontier models from nine providers, we observe an average attack success rate of 71.3%, with no model family proving reliably robust. Together with our prior work on Adversarial Poetry, these findings suggest that structurally-grounded jailbreaks constitute a broad vulnerability class rather than isolated techniques. The space of culturally coded frames that can mediate harmful intent is vast, likely inexhaustible by pattern-matching defenses alone. Understanding why these attacks succeed is therefore essential: we outline a mechanistic interpretability research agenda to investigate how narrative cues reshape model representations and whether models can learn to recognize harmful intent independently of surface form.", "AI": {"tldr": "本文介绍了Adversarial Tales，一种嵌入有害内容到赛博朋克叙事中的攻击技术，并探讨了如何通过结构化分解诱导模型将其重建为合法的叙述解释。", "motivation": "研究动机在于揭示大型语言模型中存在的一种新的脆弱性类别——基于文化编码结构的结构性攻击方法。通过这种方式，可以绕过现有的安全机制，将有害内容嵌入到看似无害的文化叙事框架中。", "method": "作者提出Adversarial Tales技术，使用赛博朋克风格的叙述和普罗普对民间故事形态的研究来重新构建有害请求，并在26个前沿模型上测试攻击成功率。", "result": "实验结果显示，这些结构性攻击方法对于大多数语言模型有效，平均成功率为71.3%，没有任何一种模型被证明是可靠安全的。", "conclusion": "文章得出结论认为，基于文化编码结构的结构性攻击是一种广泛存在的漏洞类别，而非孤立的技术。理解为什么此类攻击能够成功至关重要，并提出了一项机械解释性的研究议程来调查叙事提示如何重塑模型表征以及模型是否能独立于表面形式识别有害意图。"}}
{"id": "2601.08835", "pdf": "https://arxiv.org/pdf/2601.08835", "abs": "https://arxiv.org/abs/2601.08835", "authors": ["Vaarunay Kaushal", "Taranveer Singh"], "title": "DeliberationBench: When Do More Voices Hurt? A Controlled Study of Multi-LLM Deliberation Protocols", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 5 figures", "summary": "Multi-agent systems where Large Language Models (LLMs) deliberate to form consensus have gained significant attention, yet their practical value over simpler methods remains under-scrutinized. We introduce DELIBERATIONBENCH, a controlled benchmark evaluating three deliberation protocols against a strong baseline of selecting the best response from a pool of model outputs. Across 270 questions and three independent seeds (810 total evaluations), we find a striking negative result: the best-single baseline achieves an 82.5% +- 3.3% win rate, dramatically outperforming the best deliberation protocol(13.8% +- 2.6%). This 6.0x performance gap is statistically significant (p < 0.01) and comes at 1.5-2.5x higher computational cost. Our findings challenge assumptions that complexity enhances quality in multi-LLM systems.", "AI": {"tldr": "本文介绍了DELIBERATIONBENCH，一个评估多语言模型（LLM）共识协议的基准测试，在多个问题上进行实验以确定这些协议是否优于简单的选择最佳响应方法。", "motivation": "尽管基于多智能体系统的大型语言模型达成共识的方法得到了广泛关注，但它们的实际价值并未得到充分研究。本文旨在探讨更复杂的多语言模型协商方案是否在实践中比简单的选择最佳输出方案更有优势。", "method": "DELIBERATIONBENCH评估了三种协商协议与从模型输出中选择最优响应的强基线方法，在270个问题上进行了测试，采用三个独立种子进行810次总评估。", "result": "结果显示，最好的单一基线方案在胜率上达到了82.5% ± 3.3%，显著优于最佳协商协议（13.8% ± 2.6%）。这种性能差距达到约6倍，并且具有统计学意义(p < 0.01)，而计算成本却高出1.5至2.5倍。", "conclusion": "研究结果挑战了复杂性会提高质量的假设，表明在多语言模型系统中，更简单的选择最优响应方法可能比复杂的协商协议更有效。"}}
{"id": "2601.08834", "pdf": "https://arxiv.org/pdf/2601.08834", "abs": "https://arxiv.org/abs/2601.08834", "authors": ["Yufeng Zhong", "Lei Chen", "Zhixiong Zeng", "Xuanle Zhao", "Deyang Jiang", "Liming Zheng", "Jing Huang", "Haibo Qiu", "Peng Shi", "Siqi Yang", "Lin Ma"], "title": "Reading or Reasoning? Format Decoupled Reinforcement Learning for Document OCR", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "technical report", "summary": "Reading text from images or scanned documents via OCR models has been a longstanding focus of researchers. Intuitively, text reading is perceived as a straightforward perceptual task, and existing work primarily focuses on constructing enriched data engineering to enhance SFT capabilities. In this work, we observe that even advanced OCR models exhibit significantly higher entropy in formatted text (\\emph{e.g.}, formula, table, etc.) compared to plain text, often by an order of magnitude. These statistical patterns reveal that advanced OCR models struggle with high output uncertainty when dealing with format sensitive document, suggesting that reasoning over diverse reading pathways may improve OCR performance. To address this, we propose format decoupled reinforcement learning (FD-RL), which leverages high-entropy patterns for targeted optimization. Our approach employs entropy-based data filtration strategy to identify format-intensive instances, and adopt format decoupled rewards tailored to different format types, enabling format-level validation rather than token-level memorization. FD-RL achieves an average score of 90.41 on OmniDocBench, setting a new record for end-to-end models on this highly popular benchmark. More importantly, we conduct comprehensive ablation studies over data, training, filtering, and rewarding strategies, thoroughly validating their effectiveness.", "AI": {"tldr": "本文提出了一种格式解耦的强化学习方法（FD-RL），以改进文档OCR模型在处理格式化文本时的表现。", "motivation": "现有高级OCR模型在面对包含公式、表格等格式敏感内容的文档时，表现出更高的输出不确定性。这表明通过推理不同阅读路径可能改善OCR性能。", "method": "本文提出的方法FD-RL利用熵值过滤策略识别出具有高度格式化的实例，并使用针对不同类型格式定制的奖励函数，实现格式级别的验证而非标记级别的记忆化。", "result": "FD-RL在OmniDocBench基准测试中达到了平均90.41分的成绩，刷新了端到端模型在此热门数据集上的记录。同时，进行了详尽的消融研究以验证不同策略的有效性。", "conclusion": "本文的研究表明格式解耦强化学习方法可以显著提高OCR在复杂文档中的识别性能，并且通过系统的实验和分析证明了这种方法的优势。"}}
{"id": "2601.08833", "pdf": "https://arxiv.org/pdf/2601.08833", "abs": "https://arxiv.org/abs/2601.08833", "authors": ["Jiaxi Li", "Yue Zhu", "Eun Kyung Lee", "Klara Nahrstedt"], "title": "Revisiting Disaggregated Large Language Model Serving for Performance and Energy Implications", "categories": ["cs.PF", "cs.AI", "cs.AR", "cs.DC"], "comment": null, "summary": "Different from traditional Large Language Model (LLM) serving that colocates the prefill and decode stages on the same GPU, disaggregated serving dedicates distinct GPUs to prefill and decode workload. Once the prefill GPU completes its task, the KV cache must be transferred to the decode GPU. While existing works have proposed various KV cache transfer paths across different memory and storage tiers, there remains a lack of systematic benchmarking that compares their performance and energy efficiency. Meanwhile, although optimization techniques such as KV cache reuse and frequency scaling have been utilized for disaggregated serving, their performance and energy implications have not been rigorously benchmarked. In this paper, we fill this research gap by re-evaluating prefill-decode disaggregation under different KV transfer mediums and optimization strategies. Specifically, we include a new colocated serving baseline and evaluate disaggregated setups under different KV cache transfer paths. Through GPU profiling using dynamic voltage and frequency scaling (DVFS), we identify and compare the performance-energy Pareto frontiers across all setups to evaluate the potential energy savings enabled by disaggregation. Our results show that performance benefits from prefill-decode disaggregation are not guaranteed and depend on the request load and KV transfer mediums. In addition, stage-wise independent frequency scaling enabled by disaggregation does not lead to energy saving due to inherently higher energy consumption of disaggregated serving.", "AI": {"tldr": "本文重新评估了在不同的KV缓存传输介质和优化策略下，预填充解码分离对大语言模型服务的性能和能源效率的影响。", "motivation": "尽管现有研究提出了不同存储层级下的KV缓存转移路径，并利用了如KV缓存复用及频率缩放等优化技术，但它们在分散式服务中的表现和能源效率尚未被系统性地评估。因此，本文旨在填补这一研究空白。", "method": "本文引入了一种新的集中式服务基准线，并通过GPU性能剖析（使用动态电压和频率调整DVFS）来识别并比较所有设置下的性能-能耗帕累托前沿。", "result": "研究表明，预填充解码分离的性能优势并非绝对，取决于请求负载及KV缓存传输介质的选择；然而，由分散式服务带来的分阶段独立频率缩放并不能减少能源消耗。", "conclusion": "本文揭示了在不同条件下的预填充-解码分离对大语言模型服务的影响，指出其潜在的能源节省效果和局限性。"}}
{"id": "2601.08832", "pdf": "https://arxiv.org/pdf/2601.08832", "abs": "https://arxiv.org/abs/2601.08832", "authors": ["Fahad Shamshad", "Nils Lukas", "Karthik Nandakumar"], "title": "RAVEN: Erasing Invisible Watermarks via Novel View Synthesis", "categories": ["cs.CV"], "comment": "13 pages", "summary": "Invisible watermarking has become a critical mechanism for authenticating AI-generated image content, with major platforms deploying watermarking schemes at scale. However, evaluating the vulnerability of these schemes against sophisticated removal attacks remains essential to assess their reliability and guide robust design. In this work, we expose a fundamental vulnerability in invisible watermarks by reformulating watermark removal as a view synthesis problem. Our key insight is that generating a perceptually consistent alternative view of the same semantic content, akin to re-observing a scene from a shifted perspective, naturally removes the embedded watermark while preserving visual fidelity. This reveals a critical gap: watermarks robust to pixel-space and frequency-domain attacks remain vulnerable to semantic-preserving viewpoint transformations. We introduce a zero-shot diffusion-based framework that applies controlled geometric transformations in latent space, augmented with view-guided correspondence attention to maintain structural consistency during reconstruction. Operating on frozen pre-trained models without detector access or watermark knowledge, our method achieves state-of-the-art watermark suppression across 15 watermarking methods--outperforming 14 baseline attacks while maintaining superior perceptual quality across multiple datasets.", "AI": {"tldr": "该论文提出了RAVEN框架，通过新颖的视角合成技术消除AI生成图像中的隐形水印。", "motivation": "评估隐形水印对复杂移除攻击的脆弱性以确保其可靠性和引导健壮设计。", "method": "将水印移除问题转化为视角合成问题，利用扩散模型在潜空间中应用受控几何变换，并通过视点指导对应注意力保持结构一致性。", "result": "该方法实现了对15种水印技术的顶级水印抑制效果，在多个数据集中优于14种基线攻击并保持了更高的感知质量。", "conclusion": "隐形水印尽管在像素空间和频域攻击中表现出鲁棒性，但在视角变换等语义保留操作下仍存在脆弱性。"}}
{"id": "2601.08831", "pdf": "https://arxiv.org/pdf/2601.08831", "abs": "https://arxiv.org/abs/2601.08831", "authors": ["Yang-Che Sun", "Cheng Sun", "Chin-Yang Lin", "Fu-En Yang", "Min-Hung Chen", "Yen-Yu Lin", "Yu-Lun Liu"], "title": "3AM: Segment Anything with Geometric Consistency in Videos", "categories": ["cs.CV"], "comment": "Project page: https://jayisaking.github.io/3AM-Page/", "summary": "Video object segmentation methods like SAM2 achieve strong performance through memory-based architectures but struggle under large viewpoint changes due to reliance on appearance features. Traditional 3D instance segmentation methods address viewpoint consistency but require camera poses, depth maps, and expensive preprocessing. We introduce 3AM, a training-time enhancement that integrates 3D-aware features from MUSt3R into SAM2. Our lightweight Feature Merger fuses multi-level MUSt3R features that encode implicit geometric correspondence. Combined with SAM2's appearance features, the model achieves geometry-consistent recognition grounded in both spatial position and visual similarity. We propose a field-of-view aware sampling strategy ensuring frames observe spatially consistent object regions for reliable 3D correspondence learning. Critically, our method requires only RGB input at inference, with no camera poses or preprocessing. On challenging datasets with wide-baseline motion (ScanNet++, Replica), 3AM substantially outperforms SAM2 and extensions, achieving 90.6% IoU and 71.7% Positive IoU on ScanNet++'s Selected Subset, improving over state-of-the-art VOS methods by +15.9 and +30.4 points. Project page: https://jayisaking.github.io/3AM-Page/", "AI": {"tldr": "引入3AM，将MUSt3R中的3D感知特征与SAM2相结合，在视频中实现几何一致性分割。", "motivation": "解决现有方法在处理大规模视角变化时的性能下降问题，并且不需要相机姿态和深度图等昂贵的数据预处理。", "method": "提出一种训练时间增强技术，通过轻量级Feature Merger融合MUSt3R中的多层级特征并结合SAM2的外观特征，同时采用视野感知采样策略保证空间一致性对象区域的学习。", "result": "在具有广泛基线运动的数据集上显著优于SAM2及其扩展版本，分别达到90.6%和71.7%的IoU和Positive IoU，在ScanNet++选定子集中提高了+15.9和+30.4个百分点。", "conclusion": "证明了通过结合3D感知特征与现有视频分割方法可以有效提升模型在复杂视角变化下的几何一致性表现，且只需要RGB图像作为输入。"}}
{"id": "2601.08829", "pdf": "https://arxiv.org/pdf/2601.08829", "abs": "https://arxiv.org/abs/2601.08829", "authors": ["Hsiang-Wei Huang", "Junbin Lu", "Kuang-Ming Chen", "Jenq-Neng Hwang"], "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "categories": ["cs.CL", "cs.AI"], "comment": "In submission. The first two authors contributed equally", "summary": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort. Our code is available at https://github.com/hsiangwei0903/EloReview.", "AI": {"tldr": "该论文研究了在Elo排名系统中，大型语言模型（LLM）评审员的行为动态，并使用实际会议提交的论文进行了模拟。", "motivation": "动机是探索如何通过结合Elo评级和评审记忆来改进会议评审过程中的区域主席决策准确性以及评审策略的适应性。", "method": "该研究采用多轮次审查互动，由具有不同人格特征的多个LLM评审员参与，并在区域主席的监督下进行模拟实验。", "result": "结果表明，结合Elo评级可以提高区域主席的决策准确性，且评审者能够利用Elo系统调整其评审策略，但并未增加更多的评审努力。", "conclusion": "结论是，在Elo排名系统中使用LLM评审员能有效改善会议论文审查的质量和效率。"}}
{"id": "2601.08828", "pdf": "https://arxiv.org/pdf/2601.08828", "abs": "https://arxiv.org/abs/2601.08828", "authors": ["Xindi Wu", "Despoina Paschalidou", "Jun Gao", "Antonio Torralba", "Laura Leal-Taixé", "Olga Russakovsky", "Sanja Fidler", "Jonathan Lorraine"], "title": "Motion Attribution for Video Generation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.RO"], "comment": "See the project website at https://research.nvidia.com/labs/sil/projects/MOTIVE/", "summary": "Despite the rapid progress of video generation models, the role of data in influencing motion is poorly understood. We present Motive (MOTIon attribution for Video gEneration), a motion-centric, gradient-based data attribution framework that scales to modern, large, high-quality video datasets and models. We use this to study which fine-tuning clips improve or degrade temporal dynamics. Motive isolates temporal dynamics from static appearance via motion-weighted loss masks, yielding efficient and scalable motion-specific influence computation. On text-to-video models, Motive identifies clips that strongly affect motion and guides data curation that improves temporal consistency and physical plausibility. With Motive-selected high-influence data, our method improves both motion smoothness and dynamic degree on VBench, achieving a 74.1% human preference win rate compared with the pretrained base model. To our knowledge, this is the first framework to attribute motion rather than visual appearance in video generative models and to use it to curate fine-tuning data.", "AI": {"tldr": "该论文提出了一种名为Motive的框架，用于研究视频生成模型中的数据如何影响运动，并通过选择高影响力的训练数据来提高视频的运动流畅性和动态程度。", "motivation": "尽管视频生成模型取得了快速发展，但关于数据如何影响视频中运动的理解仍然不足。因此，该论文旨在开发一种专注于运动影响的数据归因框架，以改进视频生成的质量。", "method": "Motive是一种基于梯度的方法，通过使用运动加权的损失掩码来将动态与静态外观分离，从而计算出具体的运动影响。这种方法能有效地处理大规模高质量数据集和模型，并且可以识别哪些训练片段能够改善或恶化时间动态。", "result": "通过使用Motive选择高影响力的数据进行微调，该方法在VBench上的测试表明，相比预训练基础模型，改进了运动的流畅度和动态程度，赢得了74.1%的人类偏好胜率。", "conclusion": "这是第一个专注于归因视频生成模型中运动而非视觉外观的框架，并且使用它来优化微调数据。该方法为提高视频生成的质量提供了新的途径。"}}
{"id": "2601.08819", "pdf": "https://arxiv.org/pdf/2601.08819", "abs": "https://arxiv.org/abs/2601.08819", "authors": ["Roshni Kaushik", "Reid Simmons"], "title": "Older Adults' Preferences for Feedback Cadence from an Exercise Coach Robot", "categories": ["cs.RO", "cs.HC"], "comment": "Nonarchival submission to RO-MAN 2024 - poster session", "summary": "People can respond to feedback and guidance in different ways, and it is important for robots to personalize their interactions and utilize verbal and nonverbal communication cues. We aim to understand how older adults respond to different cadences of verbal and nonverbal feedback of a robot exercise coach. We conducted an online study of older adults, where participants evaluated videos of the robot giving feedback at different cadences for each modality. The results indicate that changing the cadence of one modality affects the perception of both it and the other modality. We can use the results from this study to better design the frequency of the robot coach's feedback during an exercise session with this population.", "AI": {"tldr": "研究了老年人对机器人健身教练不同频率的口头和非口头反馈的偏好。", "motivation": "了解如何个性化机器人的互动，特别是对于老年人群体，通过调整反馈频率来更好地引导他们的锻炼。", "method": "进行了在线调查，让参与者评估视频中机器人以不同频率提供口头和非口头反馈的表现。", "result": "结果表明，改变一种模式的频率会影响对该模式及另一种模式感知的影响。", "conclusion": "研究的结果可以帮助设计更有效的机器人健身教练，在老年人锻炼时调整反馈频次。"}}
{"id": "2601.08816", "pdf": "https://arxiv.org/pdf/2601.08816", "abs": "https://arxiv.org/abs/2601.08816", "authors": ["Weixin Chen", "Yuhan Zhao", "Jingyuan Huang", "Zihe Ye", "Clark Mingxuan Ju", "Tong Zhao", "Neil Shah", "Li Chen", "Yongfeng Zhang"], "title": "MemRec: Collaborative Memory-Augmented Agentic Recommender System", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Yet existing agents rely on isolated memory, overlooking crucial collaborative signals. Bridging this gap is hindered by the dual challenges of distilling vast graph contexts without overwhelming reasoning agents with cognitive load, and evolving the collaborative memory efficiently without incurring prohibitive computational costs. To address this, we propose MemRec, a framework that architecturally decouples reasoning from memory management to enable efficient collaborative augmentation. MemRec introduces a dedicated, cost-effective LM_Mem to manage a dynamic collaborative memory graph, serving synthesized, high-signal context to a downstream LLM_Rec. The framework operates via a practical pipeline featuring efficient retrieval and cost-effective asynchronous graph propagation that evolves memory in the background. Extensive experiments on four benchmarks demonstrate that MemRec achieves state-of-the-art performance. Furthermore, architectural analysis confirms its flexibility, establishing a new Pareto frontier that balances reasoning quality, cost, and privacy through support for diverse deployments, including local open-source models. Code:https://github.com/rutgerswiselab/memrec and Homepage: https://memrec.weixinchen.com", "AI": {"tldr": "本文提出了MemRec框架，通过将推理与记忆管理分离来实现高效的协作增强。", "motivation": "现有的推荐系统在代理时代依赖孤立的记忆，忽略了重要的协作信号。解决这一问题面临两个挑战：从庞大的图上下文中提炼信息而不增加认知负担，以及高效地发展协作记忆而不会造成计算成本过高。", "method": "MemRec框架通过引入一个专门的成本效益型LM_Mem来管理动态的协作记忆图，并为下游LLM_Rec提供合成的高质量上下文。该框架采用了一个实用的流水线，包括高效的检索和低成本的异步图传播。", "result": "在四个基准测试中，MemRec达到了最先进的性能。架构分析确认了其灵活性，确立了一条新的帕累托前沿，平衡了推理质量、成本和隐私。", "conclusion": "MemRec框架通过支持多样化的部署方式，包括本地开源模型，实现了高质量的推荐系统推理，并保持了成本效益与用户隐私保护。"}}
{"id": "2601.08811", "pdf": "https://arxiv.org/pdf/2601.08811", "abs": "https://arxiv.org/abs/2601.08811", "authors": ["Hsiang-Wei Huang", "Kuang-Ming Chen", "Wenhao Chai", "Cheng-Yen Yang", "Jen-Hao Cheng", "Jenq-Neng Hwang"], "title": "Reasoning Matters for 3D Visual Grounding", "categories": ["cs.CV", "cs.AI"], "comment": "2025 CVPR Workshop on 3D-LLM/VLA: Bridging Language, Vision and Action in 3D Environments", "summary": "The recent development of Large Language Models (LLMs) with strong reasoning ability has driven research in various domains such as mathematics, coding, and scientific discovery. Meanwhile, 3D visual grounding, as a fundamental task in 3D understanding, still remains challenging due to the limited reasoning ability of recent 3D visual grounding models. Most of the current methods incorporate a text encoder and visual feature encoder to generate cross-modal fuse features and predict the referring object. These models often require supervised training on extensive 3D annotation data. On the other hand, recent research also focus on scaling synthetic data to train stronger 3D visual grounding LLM, however, the performance gain remains limited and non-proportional to the data collection cost. In this work, we propose a 3D visual grounding data pipeline, which is capable of automatically synthesizing 3D visual grounding data along with corresponding reasoning process. Additionally, we leverage the generated data for LLM fine-tuning and introduce Reason3DVG-8B, a strong 3D visual grounding LLM that outperforms previous LLM-based method 3D-GRAND using only 1.6% of their training data, demonstrating the effectiveness of our data and the importance of reasoning in 3D visual grounding.", "AI": {"tldr": "本文提出了一种自动合成3D视觉接地数据的数据管道，并使用该数据训练了一个强大的3D视觉接地大型语言模型Reason3DVG-8B。", "motivation": "现有的3D视觉接地方法在处理复杂的推理任务时表现不佳，且需要大量的标注数据。本研究旨在通过自动化生成包含推理过程的3D数据来提高模型性能。", "method": "提出了一个自动合成3D视觉接地数据的数据管道，并利用这些数据对大型语言模型进行微调，以改进其在3D视觉接地任务上的表现。", "result": "开发的Reason3DVG-8B仅使用了先前方法3D-GRAND训练数据量的1.6%，就在3D视觉接地任务上超越了后者。", "conclusion": "该研究证明了自动合成包含推理过程的数据对于提高大型语言模型在3D视觉接地任务上的性能的重要性。"}}
{"id": "2601.08808", "pdf": "https://arxiv.org/pdf/2601.08808", "abs": "https://arxiv.org/abs/2601.08808", "authors": ["Yao Tang", "Li Dong", "Yaru Hao", "Qingxiu Dong", "Furu Wei", "Jiatao Gu"], "title": "Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "21 pages. Code available at https://github.com/GMLR-Penn/Multiplex-Thinking", "summary": "Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, Multiplex Thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, Multiplex Thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at https://github.com/GMLR-Penn/Multiplex-Thinking.", "AI": {"tldr": "提出了一种名为Multiplex Thinking的软推理机制，以解决复杂推理任务。", "motivation": "大型语言模型通过链式思维（CoT）有效解决了复杂推理问题，但代价是生成较长的低带宽令牌序列。该方法旨在模仿人类在推理时维持多个可能步骤的概率分布的方式。", "method": "Multiplex Thinking机制在每一步思考中采样K个候选标记，并聚合它们的嵌入以形成一个单一的连续多路标记，从而保留词汇嵌入先验和标准离散生成的采样动态，同时诱导可处理的概率分布。可以使用在线策略强化学习直接优化这些多路轨迹。", "result": "在多个具有挑战性的数学推理基准测试中，Multiplex Thinking一致性地超越了强大的离散CoT和RL基线，并且产生的序列长度更短。", "conclusion": "Multiplex Thinking方法通过自适应调整可以有效解决复杂推理任务，并生成较短的令牌序列。"}}
{"id": "2601.08807", "pdf": "https://arxiv.org/pdf/2601.08807", "abs": "https://arxiv.org/abs/2601.08807", "authors": ["Tamas Endrei", "Gyorgy Cserey"], "title": "S3-CLIP: Video Super Resolution for Person-ReID", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to the 2026 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW), VReID-XFD Challenge", "summary": "Tracklet quality is often treated as an afterthought in most person re-identification (ReID) methods, with the majority of research presenting architectural modifications to foundational models. Such approaches neglect an important limitation, posing challenges when deploying ReID systems in real-world, difficult scenarios. In this paper, we introduce S3-CLIP, a video super-resolution-based CLIP-ReID framework developed for the VReID-XFD challenge at WACV 2026. The proposed method integrates recent advances in super-resolution networks with task-driven super-resolution pipelines, adapting them to the video-based person re-identification setting. To the best of our knowledge, this work represents the first systematic investigation of video super-resolution as a means of enhancing tracklet quality for person ReID, particularly under challenging cross-view conditions. Experimental results demonstrate performance competitive with the baseline, achieving 37.52% mAP in aerial-to-ground and 29.16% mAP in ground-to-aerial scenarios. In the ground-to-aerial setting, S3-CLIP achieves substantial gains in ranking accuracy, improving Rank-1, Rank-5, and Rank-10 performance by 11.24%, 13.48%, and 17.98%, respectively.", "AI": {"tldr": "本论文介绍了S3-CLIP，一个基于视频超分辨率的CLIP-ReID框架，用于增强VReID-XFD挑战中的人体再识别任务中的轨迹质量。", "motivation": "现有的大多数人体重识别方法忽视了轨道质量的重要性，而主要集中在基础模型上的架构改进。这种做法忽略了重要的限制，在现实世界困难场景下的部署提出了挑战。", "method": "S3-CLIP框架结合了超分辨率网络的最新进展与任务驱动的超分辨率流水线，并将其应用于基于视频的人体再识别设置中。", "result": "实验结果表明，该方法在航拍到地面和地面到航拍场景中的mAP分别为37.52%和29.16%，特别是在地面到航拍的环境中，在排名准确性方面取得了显著提高，提升了Rank-1、Rank-5和Rank-10的表现分别达到11.24%、13.48%和17.98%。", "conclusion": "该工作代表了视频超分辨率作为提升人体重识别中轨道质量的一种手段的首次系统性研究，实验结果证明了其有效性。"}}
{"id": "2601.08806", "pdf": "https://arxiv.org/pdf/2601.08806", "abs": "https://arxiv.org/abs/2601.08806", "authors": ["Abhi Kottamasu", "Akul Datta", "Aakash Barthwal", "Chirag Mahapatra", "Ajay Arun", "Adarsh Hiremath", "Brendan Foody", "Bertie Vidgen"], "title": "APEX-SWE", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "We introduce the AI Productivity Index for Software Engineering (APEX-SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX-SWE assesses two novel task types that reflect real-world software engineering work: (1) Integration tasks (n=100), which require constructing end-to-end systems across heterogeneous cloud primitives, business applications, and infrastructure-as-code services, and (2) Observability tasks (n=100), which require debugging production failures using telemetry signals such as logs and dashboards, as well as unstructured context. We evaluated eight frontier models on APEX-SWE. Gemini 3 Pro (Thinking = High) performs best, with a Pass@1 score of 25\\%. Our analysis shows that strong performance is primarily driven by epistemic reasoning, defined as the ability to distinguish between assumptions and verified facts, combined with agency to resolve uncertainty prior to acting. We open-source the APEX-SWE evaluation harness and a dev set (n=50).", "AI": {"tldr": "本文介绍了AI生产力指数软件工程（APEX-SWE），这是一个评估前沿人工智能模型能否执行具有经济价值的软件工程工作的基准。", "motivation": "现有评估方法主要集中在狭隘且定义明确的任务上，而本研究旨在通过引入更贴近实际软件工程工作的两类任务来评估AI模型的真实能力：集成任务和可观察性任务。", "method": "本文设计了包含100个集成任务和100个可观察性任务的基准测试集，并在八个前沿AI模型上进行了测试，同时公开了评估工具及开发集（n=50）。", "result": "测试结果显示，Gemini 3 Pro（思考能力高）表现最好，通过率达到了25%。", "conclusion": "研究分析表明，优秀的性能主要依赖于能够区分假设与验证事实的表征性推理以及在采取行动前解决不确定性问题的能力。"}}
{"id": "2601.08798", "pdf": "https://arxiv.org/pdf/2601.08798", "abs": "https://arxiv.org/abs/2601.08798", "authors": ["Maayan Yesharim", "R. G. Bina Perl", "Uri Roll", "Sarig Gafny", "Eli Geffen", "Yoav Ram"], "title": "Near-perfect photo-ID of the Hula painted frog with zero-shot deep local-feature matching", "categories": ["cs.CV", "q-bio.QM"], "comment": "18 pages, 4 figures,", "summary": "Accurate individual identification is essential for monitoring rare amphibians, yet invasive marking is often unsuitable for critically endangered species. We evaluate state-of-the-art computer-vision methods for photographic re-identification of the Hula painted frog (Latonia nigriventer) using 1,233 ventral images from 191 individuals collected during 2013-2020 capture-recapture surveys. We compare deep local-feature matching in a zero-shot setting with deep global-feature embedding models. The local-feature pipeline achieves 98% top-1 closed-set identification accuracy, outperforming all global-feature models; fine-tuning improves the best global-feature model to 60% top-1 (91% top-10) but remains below local matching. To combine scalability with accuracy, we implement a two-stage workflow in which a fine-tuned global-feature model retrieves a short candidate list that is re-ranked by local-feature matching, reducing end-to-end runtime from 6.5-7.8 hours to ~38 minutes while maintaining ~96% top-1 closed-set accuracy on the labeled dataset. Separation of match scores between same- and different-individual pairs supports thresholding for open-set identification, enabling practical handling of novel individuals. We deploy this pipeline as a web application for routine field use, providing rapid, standardized, non-invasive identification to support conservation monitoring and capture-recapture analyses. Overall, in this species, zero-shot deep local-feature matching outperformed global-feature embedding and provides a strong default for photo-identification.", "AI": {"tldr": "本论文主要任务是通过零样本深度局部特征匹配方法实现对Hula彩绘蛙的近乎完美的照片个体识别。", "motivation": "研究动机在于准确的个体识别对于监测稀有两栖动物至关重要，但对于濒危物种来说，侵入性标记通常是不合适的。", "method": "论文的方法是评估最先进的计算机视觉技术用于Hula彩绘蛙的照片再识别，比较了零样本设置下的深度局部特征匹配与深度全局特征嵌入模型，并实现了一个结合可扩展性和准确性的两阶段工作流程。", "result": "研究结果表明，局部特征管道实现了98%的顶级封闭集合识别精度，优于所有全局特征模型；通过组合全局和局部特征方法，缩短了运行时间并保持了高准确性。", "conclusion": "结论是零样本深度局部特征匹配在该物种中优于全局特征嵌入，并提供了一个强大的默认方法用于照片个体识别。"}}
{"id": "2601.08797", "pdf": "https://arxiv.org/pdf/2601.08797", "abs": "https://arxiv.org/abs/2601.08797", "authors": ["Zhi Qin Tan", "Xiatian Zhu", "Owen Addison", "Yunpeng Li"], "title": "DentalX: Context-Aware Dental Disease Detection with Radiographs", "categories": ["cs.CV"], "comment": "Accepted at ISBI 2026", "summary": "Diagnosing dental diseases from radiographs is time-consuming and challenging due to the subtle nature of diagnostic evidence. Existing methods, which rely on object detection models designed for natural images with more distinct target patterns, struggle to detect dental diseases that present with far less visual support. To address this challenge, we propose {\\bf DentalX}, a novel context-aware dental disease detection approach that leverages oral structure information to mitigate the visual ambiguity inherent in radiographs. Specifically, we introduce a structural context extraction module that learns an auxiliary task: semantic segmentation of dental anatomy. The module extracts meaningful structural context and integrates it into the primary disease detection task to enhance the detection of subtle dental diseases. Extensive experiments on a dedicated benchmark demonstrate that DentalX significantly outperforms prior methods in both tasks. This mutual benefit arises naturally during model optimization, as the correlation between the two tasks is effectively captured. Our code is available at https://github.com/zhiqin1998/DentYOLOX.", "AI": {"tldr": "本文提出了DentalX，一种基于上下文感知的牙科疾病检测方法，通过从口腔结构信息中提取辅助任务以增强对细微疾病的检测能力。", "motivation": "诊断牙齿疾病的过程既耗时又具有挑战性，因为这些疾病在放射图像中的视觉特征非常微弱。现有的用于自然图片的对象检测模型难以适应这种情况。", "method": "DentalX引入了一个结构上下文提取模块，该模块通过学习语义分割牙科解剖作为辅助任务来增强主要的疾病检测任务，以减轻放射图像中固有的视觉模糊问题。", "result": "在专门的基准测试上进行的广泛实验表明，与先前的方法相比，DentalX在两项任务上都表现出了显著的优势。", "conclusion": "该研究证明了通过结合口腔结构信息来提高牙科疾病检测性能的有效性，并且两个相关任务之间的关联可以在模型优化过程中自然地被捕捉到。"}}
{"id": "2601.08790", "pdf": "https://arxiv.org/pdf/2601.08790", "abs": "https://arxiv.org/abs/2601.08790", "authors": ["Lei Tan", "Shuwei Li", "Mohan Kankanhalli", "Robby T. Tan"], "title": "Aggregating Diverse Cue Experts for AI-Generated Image Detection", "categories": ["cs.CV"], "comment": "Accepted by AAAI 2026", "summary": "The rapid emergence of image synthesis models poses challenges to the generalization of AI-generated image detectors. However, existing methods often rely on model-specific features, leading to overfitting and poor generalization. In this paper, we introduce the Multi-Cue Aggregation Network (MCAN), a novel framework that integrates different yet complementary cues in a unified network. MCAN employs a mixture-of-encoders adapter to dynamically process these cues, enabling more adaptive and robust feature representation. Our cues include the input image itself, which represents the overall content, and high-frequency components that emphasize edge details. Additionally, we introduce a Chromatic Inconsistency (CI) cue, which normalizes intensity values and captures noise information introduced during the image acquisition process in real images, making these noise patterns more distinguishable from those in AI-generated content. Unlike prior methods, MCAN's novelty lies in its unified multi-cue aggregation framework, which integrates spatial, frequency-domain, and chromaticity-based information for enhanced representation learning. These cues are intrinsically more indicative of real images, enhancing cross-model generalization. Extensive experiments on the GenImage, Chameleon, and UniversalFakeDetect benchmark validate the state-of-the-art performance of MCAN. In the GenImage dataset, MCAN outperforms the best state-of-the-art method by up to 7.4% in average ACC across eight different image generators.", "AI": {"tldr": "本文提出了一种新的框架MCAN，通过整合多种互补线索来提高AI生成图像检测的泛化能力。", "motivation": "当前AI生成图像检测方法依赖于特定模型特征，容易导致过拟合和泛化性能差。为此，作者旨在开发一种能更好处理多样线索并具有更强适应性的检测框架。", "method": "MCAN整合了输入图像、高频分量以及色度不一致（CI）三种互补线索，并采用混合编码器适配器动态处理这些线索，以实现更自适应和稳健的特征表示。", "result": "实验结果表明，在GenImage数据集上，MCAN相比现有最佳方法平均提高了7.4%的准确率。这验证了其在多个生成模型上的优越性能。", "conclusion": "研究表明通过统一多线索聚合框架，可以显著提升AI生成图像检测的准确性与跨模型泛化能力。"}}
{"id": "2601.08785", "pdf": "https://arxiv.org/pdf/2601.08785", "abs": "https://arxiv.org/abs/2601.08785", "authors": ["Jieying Chen", "Karen de Jong", "Andreas Poole", "Jan Burakowski", "Elena Elderson Nosti", "Joep Windt", "Chendi Wang"], "title": "Uncovering Political Bias in Large Language Models using Parliamentary Voting Records", "categories": ["cs.AI"], "comment": null, "summary": "As large language models (LLMs) become deeply embedded in digital platforms and decision-making systems, concerns about their political biases have grown. While substantial work has examined social biases such as gender and race, systematic studies of political bias remain limited, despite their direct societal impact. This paper introduces a general methodology for constructing political bias benchmarks by aligning model-generated voting predictions with verified parliamentary voting records. We instantiate this methodology in three national case studies: PoliBiasNL (2,701 Dutch parliamentary motions and votes from 15 political parties), PoliBiasNO (10,584 motions and votes from 9 Norwegian parties), and PoliBiasES (2,480 motions and votes from 10 Spanish parties). Across these benchmarks, we assess ideological tendencies and political entity bias in LLM behavior. As part of our evaluation framework, we also propose a method to visualize the ideology of LLMs and political parties in a shared two-dimensional CHES (Chapel Hill Expert Survey) space by linking their voting-based positions to the CHES dimensions, enabling direct and interpretable comparisons between models and real-world political actors. Our experiments reveal fine-grained ideological distinctions: state-of-the-art LLMs consistently display left-leaning or centrist tendencies, alongside clear negative biases toward right-conservative parties. These findings highlight the value of transparent, cross-national evaluation grounded in real parliamentary behavior for understanding and auditing political bias in modern LLMs.", "AI": {"tldr": "本文提出了一种基于议会投票记录构建政治偏见基准的方法，并在三个国家进行案例研究，评估大型语言模型的政治倾向。", "motivation": "尽管社会偏见如性别和种族已经得到大量关注，但对大型语言模型中的政治偏见的研究仍然不足。鉴于其直接的社会影响，本研究旨在揭示这些模型中存在的政治偏差。", "method": "作者提出了一种构建政治偏见基准的方法，通过将模型生成的投票预测与验证过的议会投票记录进行比对。该方法应用于荷兰、挪威和西班牙三个国家的数据集上，并提出了一个可视化框架来展示LLM和政党在二维CHES空间中的意识形态。", "result": "实验表明，最先进的大型语言模型显示出左倾或中间派倾向，并且对于右翼保守党派存在明显的负面偏见。", "conclusion": "研究结果强调了通过基于实际议会行为的透明跨国家评估来理解和审计现代LLM中政治偏见的重要性。"}}
{"id": "2601.08778", "pdf": "https://arxiv.org/pdf/2601.08778", "abs": "https://arxiv.org/abs/2601.08778", "authors": ["Tengjun Jin", "Yoojin Choi", "Yuxuan Zhu", "Daniel Kang"], "title": "Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards", "categories": ["cs.AI", "cs.DB"], "comment": "18 pages, 14 figures, 9 tables", "summary": "Researchers have proposed many text-to-SQL techniques to streamline data analytics and accelerate the development of database-driven applications. To compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. Since these benchmarks heavily rely on human annotations during question construction and answer evaluation, the validity of the annotations is crucial. In this paper, we conduct an empirical study that (i) benchmarks annotation error rates for two widely used text-to-SQL benchmarks, BIRD and Spider 2.0-Snow, and (ii) corrects a subset of the BIRD development (Dev) set to measure the impact of annotation errors on text-to-SQL agent performance and leaderboard rankings. Through expert analysis, we show that BIRD Mini-Dev and Spider 2.0-Snow have error rates of 52.8% and 62.8%, respectively. We re-evaluate all 16 open-source agents from the BIRD leaderboard on both the original and the corrected BIRD Dev subsets. We show that performance changes range from -7% to 31% (in relative terms) and rank changes range from $-9$ to $+9$ positions. We further assess whether these impacts generalize to the full BIRD Dev set. We find that the rankings of agents on the uncorrected subset correlate strongly with those on the full Dev set (Spearman's $r_s$=0.85, $p$=3.26e-5), whereas they correlate weakly with those on the corrected subset (Spearman's $r_s$=0.32, $p$=0.23). These findings show that annotation errors can significantly distort reported performance and rankings, potentially misguiding research directions or deployment choices. Our code and data are available at https://github.com/uiuc-kang-lab/text_to_sql_benchmarks.", "AI": {"tldr": "本文研究了广泛使用的文本到SQL基准测试中的注释错误对模型性能和排行榜排名的影响。", "motivation": "由于公共基准测试依赖于人类标注，其有效性对于比较不同的文本到SQL技术至关重要。为了确保这些基准的可靠性，本论文旨在评估并纠正这些基准测试中的注释错误。", "method": "研究团队通过专家分析确定了两个广泛使用的基准（BIRD和Spider 2.0-Snow）上的错误率，并重新评价开放源代码代理在修正后的BIRD开发集子集上的性能。", "result": "发现BIRD Mini-Dev和Spider 2.0-Snow的注释错误率分别为52.8%和62.8%，并且这些错误显著影响了模型排名，变化范围从-7%到31%。", "conclusion": "文本到SQL基准测试中的注释错误可以严重扭曲报告的性能和排名，这可能误导研究方向或部署决策。"}}
{"id": "2601.08777", "pdf": "https://arxiv.org/pdf/2601.08777", "abs": "https://arxiv.org/abs/2601.08777", "authors": ["Yang Cai", "Weiqiang Zheng"], "title": "Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.GT"], "comment": null, "summary": "Aligning large language models (LLMs) to serve users with heterogeneous and potentially conflicting preferences is a central challenge for personalized and trustworthy AI. We formalize an ideal notion of universal alignment through test-time scaling: for each prompt, the model produces $k\\ge 1$ candidate responses and a user selects their preferred one. We introduce $(k,f(k))$-robust alignment, which requires the $k$-output model to have win rate $f(k)$ against any other single-output model, and asymptotic universal alignment (U-alignment), which requires $f(k)\\to 1$ as $k\\to\\infty$. Our main result characterizes the optimal convergence rate: there exists a family of single-output policies whose $k$-sample product policies achieve U-alignment at rate $f(k)=\\frac{k}{k+1}$, and no method can achieve a faster rate in general. We show that popular post-training methods, including Nash learning from human feedback (NLHF), can fundamentally underutilize the benefits of test-time scaling. Even though NLHF is optimal for $k=1$, sampling from the resulting (often deterministic) policy cannot guarantee win rates above $\\tfrac{1}{2}$ except for an arbitrarily small slack. This stems from a lack of output diversity: existing alignment methods can collapse to a single majority-preferred response, making additional samples redundant. In contrast, our approach preserves output diversity and achieves the optimal test-time scaling rate. In particular, we propose a family of symmetric multi-player alignment games and prove that any symmetric Nash equilibrium policy of the $(k+1)$-player alignment game achieves the optimal $(k,\\frac{k}{k+1})$-robust alignment. Finally, we provide theoretical convergence guarantees for self-play learning dynamics in these games and extend the framework to opponents that also generate multiple responses.", "AI": {"tldr": "本文提出了通过测试时间缩放实现模型的渐进普遍对齐的新框架。", "motivation": "针对大型语言模型在满足具有异质性和潜在冲突偏好的用户需求方面的挑战，本文希望通过引入新的对齐方法来提升个性化和值得信赖的人工智能服务。", "method": "文章提出了（k,f(k)）鲁棒对齐的概念，并定义了渐进普遍对齐(U-对齐)，并且提出了一种多玩家对齐游戏框架，通过证明任意的对称纳什均衡策略可以达到最优的鲁棒对齐。", "result": "研究表明，流行的后训练方法如从人类反馈中学习的纳什（NLHF）并不能充分利用测试时间缩放带来的好处。相比之下，本文的方法保留了输出多样性，并实现了最佳的测试时间缩放率。", "conclusion": "研究证明通过测试时间缩放可以实现大型语言模型的渐进普遍对齐，提出的方法不仅达到了最优的收敛速率，还保证了输出多样性。"}}
{"id": "2601.08776", "pdf": "https://arxiv.org/pdf/2601.08776", "abs": "https://arxiv.org/abs/2601.08776", "authors": ["Yanhua Zhao"], "title": "Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN", "categories": ["cs.CV", "cs.AI"], "comment": "5 pages, 4 figures", "summary": "Histopathology analysis relies on Hematoxylin and Eosin (H&E) staining, but fluorescence microscopy offers complementary information. Converting fluorescence images to H&E-like appearance can aid interpretation and integration with standard workflows. We present a Cycle-Consistent Adversarial Network (CycleGAN) approach for unpaired image-to-image translation from multi-channel fluorescence microscopy to pseudo H&E stained histopathology images. The method combines C01 and C02 fluorescence channels into RGB and learns a bidirectional mapping between fluorescence and H&E domains without paired training data. The architecture uses ResNet-based generators with residual blocks and PatchGAN discriminators, trained with adversarial, cycle-consistency, and identity losses. Experiments on fluorescence microscopy datasets show the model generates realistic pseudo H&E images that preserve morphological structures while adopting H&E-like color characteristics. This enables visualization of fluorescence data in a format familiar to pathologists and supports integration with existing H&E-based analysis pipelines.", "AI": {"tldr": "本文提出了一种使用CycleGAN将多通道荧光显微镜图像转换为类似H&E染色的组织病理学图像的方法。", "motivation": "传统的组织病理学分析依赖于H&E染色，而荧光显微镜提供了互补的信息。将荧光图像转化为类似H&E的外观有助于解释和整合到标准工作流程中。", "method": "本文使用Cycle-Consistent Adversarial Network (CycleGAN) 方法进行无配对的图像转换，通过C01和C02荧光通道结合成RGB，并学习荧光与H&E领域的双向映射关系。架构采用基于ResNet的生成器和PatchGAN判别器，并且使用对抗性、循环一致性以及身份损失进行训练。", "result": "实验表明，该模型能够生成保留形态结构并具有类似H&E染色特征的真实伪H&E图像。", "conclusion": "这种方法使得荧光数据可以以病理科医生熟悉的方式可视化，并支持集成到现有的基于H&E的分析管道中。"}}
{"id": "2601.08773", "pdf": "https://arxiv.org/pdf/2601.08773", "abs": "https://arxiv.org/abs/2601.08773", "authors": ["Manideep Reddy Chinthareddy"], "title": "Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs", "categories": ["cs.SE", "cs.AI"], "comment": "46 pages, 2 figures", "summary": "Retrieval-Augmented Generation for software engineering often relies on vector similarity search, which captures topical similarity but can fail on multi-hop architectural reasoning such as controller to service to repository chains, interface-driven wiring, and inheritance. This paper benchmarks three retrieval pipelines on Java codebases (Shopizer, with additional runs on ThingsBoard and OpenMRS Core): (A) vector-only No-Graph RAG, (B) an LLM-generated knowledge graph RAG (LLM-KB), and (C) a deterministic AST-derived knowledge graph RAG (DKB) built with Tree-sitter and bidirectional traversal. Using 15 architecture and code-tracing queries per repository, we measure indexing time, query latency, corpus coverage, cost, and answer correctness. DKB builds its graph in seconds, while LLM-KB requires much longer graph generation. LLM-KB also shows indexing incompleteness: on Shopizer, 377 files are skipped or missed, reducing embedded chunk coverage and graph size compared to DKB. End-to-end cost is modest for DKB relative to the vector-only baseline but much higher for LLM-KB, especially as repository scale increases. Query latency is similar for No-Graph and DKB, while LLM-KB is slower and more variable. On the Shopizer question suite, DKB achieves the highest correctness, LLM-KB is close behind, and the vector-only baseline performs worst on upstream architectural queries and has the highest hallucination risk. Overall, deterministic AST-derived graphs provide more reliable coverage and multi-hop grounding than LLM-extracted graphs at substantially lower indexing cost.", "AI": {"tldr": "评估三种检索增强生成(RAG)方法在Java代码库上的性能，包括无图RAG、LLM生成知识图谱RAG和确定性AST衍生知识图谱RAG。", "motivation": "探讨如何改进传统的基于向量相似度搜索的RAG以提高多跳架构推理能力，尤其是在处理复杂软件体系结构时。", "method": "对Shopizer代码库使用三种不同的RAG方法进行基准测试，并在ThingsBoard和OpenMRS Core上进行了额外运行。通过测量索引时间、查询延迟、语料覆盖度、成本和答案正确性来评估每种方法的性能。", "result": "确定性AST衍生知识图谱(RAG)比其他两种方法提供更可靠的覆盖率和更低的成本，并在复杂架构查询上的准确性更高，而LLM生成的知识图谱存在索引不完整的问题。", "conclusion": "确定性AST衍生知识图谱为软件工程中的多跳架构推理提供了更好的支持，相较于LLM提取的图谱具有更高的可靠性和更少的成本。"}}
{"id": "2601.08768", "pdf": "https://arxiv.org/pdf/2601.08768", "abs": "https://arxiv.org/abs/2601.08768", "authors": ["Cody Kommers", "Ari Holtzman"], "title": "AI as Entertainment", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Generative AI systems are predominantly designed, evaluated, and marketed as intelligent systems which will benefit society by augmenting or automating human cognitive labor, promising to increase personal, corporate, and macroeconomic productivity. But this mainstream narrative about what AI is and what it can do is in tension with another emerging use case: entertainment. We argue that the field of AI is unprepared to measure or respond to how the proliferation of entertaining AI-generated content will impact society. Emerging data suggest AI is already widely adopted for entertainment purposes -- especially by young people -- and represents a large potential source of revenue. We contend that entertainment will become a primary business model for major AI corporations seeking returns on massive infrastructure investments; this will exert a powerful influence on the technology these companies produce in the coming years. Examining current evaluation practices, we identify a critical asymmetry: while AI assessments rigorously measure both benefits and harms of intelligence, they focus almost exclusively on cultural harms. We lack frameworks for articulating how cultural outputs might be actively beneficial. Drawing on insights from the humanities, we propose \"thick entertainment\" as a framework for evaluating AI-generated cultural content -- one that considers entertainment's role in meaning-making, identity formation, and social connection rather than simply minimizing harm. While AI is often touted for its potential to revolutionize productivity, in the long run we may find that AI turns out to be as much about \"intelligence\" as social media is about social connection.", "AI": {"tldr": "探讨人工智能作为娱乐用途的影响及其评估框架", "motivation": "讨论当前AI在娱乐领域使用的广泛性和未来趋势，提出新的评估框架以应对娱乐内容对社会的潜在影响。", "method": "分析现有AI评估实践中的不平衡问题，并引入人文视角下的“厚实娱乐”框架来评价AI生成的文化内容。", "result": "揭示了AI娱乐用途的重要性及其可能成为主要商业模型的趋势，强调了当前缺乏有效的评估方法以衡量其积极文化输出的作用。", "conclusion": "未来人工智能的发展将不仅关注生产力的提升，还会更多地涉及到文化的创造和社会联系的加强。"}}
{"id": "2601.08764", "pdf": "https://arxiv.org/pdf/2601.08764", "abs": "https://arxiv.org/abs/2601.08764", "authors": ["Haven Kim", "Yupeng Hou", "Julian McAuley"], "title": "FusID: Modality-Fused Semantic IDs for Generative Music Recommendation", "categories": ["cs.IR", "cs.SD", "eess.AS"], "comment": null, "summary": "Generative recommendation systems have achieved significant advances by leveraging semantic IDs to represent items. However, existing approaches that tokenize each modality independently face two critical limitations: (1) redundancy across modalities that reduces efficiency, and (2) failure to capture inter-modal interactions that limits item representation. We introduce FusID, a modality-fused semantic ID framework that addresses these limitations through three key components: (i) multimodal fusion that learns unified representations by jointly encoding information across modalities, (ii) representation learning that brings frequently co-occurring item embeddings closer while maintaining distinctiveness and preventing feature redundancy, and (iii) product quantization that converts the fused continuous embeddings into multiple discrete tokens to mitigate ID conflict. Evaluated on a multimodal next-song recommendation (i.e., playlist continuation) benchmark, FusID achieves zero ID conflicts, ensuring that each token sequence maps to exactly one song, mitigates codebook underutilization, and outperforms baselines in terms of MRR and Recall@k (k = 1, 5, 10, 20).", "AI": {"tldr": "介绍了一种名为FusID的模态融合语义ID框架，用于生成音乐推荐。", "motivation": "现有的独立处理每个模态的方法存在冗余和无法捕捉跨模态交互的问题，限制了项目表示的效果。", "method": "通过多模态融合、表示学习和产品量化三个关键组件来实现更有效的语义ID表示。", "result": "在多模态下一首歌推荐基准测试中，FusID实现了零ID冲突，并且在MRR和Recall@k指标上优于基线方法。", "conclusion": "FusID解决了现有生成推荐系统中的冗余问题并提高了跨模态交互的捕捉能力，从而提升了整体推荐性能。"}}
{"id": "2601.08758", "pdf": "https://arxiv.org/pdf/2601.08758", "abs": "https://arxiv.org/abs/2601.08758", "authors": ["Juntao Jiang", "Jiangning Zhang", "Yali Bi", "Jinsheng Bai", "Weixuan Liu", "Weiwei Jin", "Zhucun Xue", "Yong Liu", "Xiaobin Hu", "Shuicheng Yan"], "title": "M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding", "categories": ["eess.IV", "cs.CV"], "comment": "40 pages, 8 figures", "summary": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large language models by encouraging step-by-step intermediate reasoning, and recent advances have extended this paradigm to Multimodal Large Language Models (MLLMs). In the medical domain, where diagnostic decisions depend on nuanced visual cues and sequential reasoning, CoT aligns naturally with clinical thinking processes. However, Current benchmarks for medical image understanding generally focus on the final answer while ignoring the reasoning path. An opaque process lacks reliable bases for judgment, making it difficult to assist doctors in diagnosis. To address this gap, we introduce a new M3CoTBench benchmark specifically designed to evaluate the correctness, efficiency, impact, and consistency of CoT reasoning in medical image understanding. M3CoTBench features 1) a diverse, multi-level difficulty dataset covering 24 examination types, 2) 13 varying-difficulty tasks, 3) a suite of CoT-specific evaluation metrics (correctness, efficiency, impact, and consistency) tailored to clinical reasoning, and 4) a performance analysis of multiple MLLMs. M3CoTBench systematically evaluates CoT reasoning across diverse medical imaging tasks, revealing current limitations of MLLMs in generating reliable and clinically interpretable reasoning, and aims to foster the development of transparent, trustworthy, and diagnostically accurate AI systems for healthcare. Project page at https://juntaojianggavin.github.io/projects/M3CoTBench/.", "AI": {"tldr": "本文介绍了M3CoTBench，一个新的用于评估多模态大型语言模型在医学图像理解中链式思维推理的基准测试。", "motivation": "现有的医学图像理解基准测试主要关注最终答案而忽略了推理过程。为了填补这一空白，并提高医疗诊断中的透明度和可靠性，本文提出了M3CoTBench来评估链式思维推理的有效性。", "method": "M3CoTBench包含多层次难度的多类检查数据集（24种检查类型），13个不同难度的任务，以及一组专门用于链式思维推理的评估指标。还分析了多个多模态大型语言模型的表现。", "result": "该基准测试系统地评估了链式思维推理在多样化的医学影像任务中的表现，揭示了当前MLLMs在生成可靠的、可临床解释的推理过程上的局限性。", "conclusion": "M3CoTBench旨在促进透明、值得信赖且诊断准确的人工智能系统的开发，以改善医疗保健领域的应用。"}}
{"id": "2601.08753", "pdf": "https://arxiv.org/pdf/2601.08753", "abs": "https://arxiv.org/abs/2601.08753", "authors": ["Rishav Sen", "Amutheezan Sivagnanam", "Aron Laszka", "Ayan Mukhopadhyay", "Abhishek Dubey"], "title": "Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit", "categories": ["math.OC", "cs.AI", "eess.SY"], "comment": "7 pages, 7 figures, 4 algorithms. Published in the Proceedings of the 2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)", "summary": "The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, the effective management of mixed fleets consisting of both electric and diesel buses poses significant operational challenges. One major challenge is coping with dynamic electricity pricing, where charging costs vary throughout the day. Transit agencies must optimize charging assignments in response to such dynamism while accounting for secondary considerations such as seating constraints. This paper presents a comprehensive mixed-integer linear programming (MILP) model to address these challenges by jointly optimizing charging schedules and trip assignments for mixed (electric and diesel bus) fleets while considering factors such as dynamic electricity pricing, vehicle capacity, and route constraints. We address the potential computational intractability of the MILP formulation, which can arise even with relatively small fleets, by employing a hierarchical approach tailored to the fleet composition. By using real-world data from the city of Chattanooga, Tennessee, USA, we show that our approach can result in significant savings in the operating costs of the mixed transit fleets.", "AI": {"tldr": "本文提出了一种综合的混合整数线性规划模型，用于优化由电动和柴油公交车组成的混合车队的充电计划和行程分配。", "motivation": "随着城市人口的增长和对可持续交通解决方案的需求增加，公共交通系统正在向电动公交过渡。然而，管理包括电动和柴油车在内的混合车队面临诸如动态电价等操作挑战。本文旨在解决这些挑战。", "method": "使用综合的混合整数线性规划模型来优化充电时间和行程分配，并考虑了动态电价、车辆容量和路线约束。为了解决MILP问题可能出现的计算复杂度，采用了分层方法。", "result": "通过使用田纳西州查塔努加市的真实数据，证明该方法可以在混合公交车队的操作成本上实现显著节约。", "conclusion": "提出的模型能够有效优化电动和柴油混合公交车队的操作，并在实际应用中降低运营成本。"}}
{"id": "2601.08749", "pdf": "https://arxiv.org/pdf/2601.08749", "abs": "https://arxiv.org/abs/2601.08749", "authors": ["Tianyang Wang", "Ender Konukoglu", "Hans-Andrea Loeliger"], "title": "A Single-Parameter Factor-Graph Image Prior", "categories": ["eess.IV", "cs.CV", "eess.SP"], "comment": null, "summary": "We propose a novel piecewise smooth image model with piecewise constant local parameters that are automatically adapted to each image. Technically, the model is formulated in terms of factor graphs with NUP (normal with unknown parameters) priors, and the pertinent computations amount to iterations of conjugate-gradient steps and Gaussian message passing. The proposed model and algorithms are demonstrated with applications to denoising and contrast enhancement.", "AI": {"tldr": "本文提出了一种新的分段平滑图像模型，并应用于去噪和对比度增强。", "motivation": "为了实现适应每张图片的自动参数调整，以改善图像处理效果。", "method": "采用因子图表示方法并使用NUP（未知参数正态分布）先验模型进行技术构建，计算过程涉及共轭梯度迭代和高斯消息传递。", "result": "提出的模型和算法在去噪和对比度增强应用中表现良好。", "conclusion": "该研究提出的方法能够有效处理图像，并具有良好的适应性和自动参数调整能力。"}}
{"id": "2601.08748", "pdf": "https://arxiv.org/pdf/2601.08748", "abs": "https://arxiv.org/abs/2601.08748", "authors": ["Siqi Li", "Xinyu Cai", "Jianbiao Mei", "Nianchen Deng", "Pinlong Cai", "Licheng Wen", "Yufan Shen", "Xuemeng Yang", "Botian Shi", "Yong Liu"], "title": "UR-Bench: A Benchmark for Multi-Hop Reasoning over Ultra-High-Resolution Images", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "Recent multimodal large language models (MLLMs) show strong capabilities in visual-language reasoning, yet their performance on ultra-high-resolution imagery remains largely unexplored. Existing visual question answering (VQA) benchmarks typically rely on medium-resolution data, offering limited visual complexity. To bridge this gap, we introduce Ultra-high-resolution Reasoning Benchmark (UR-Bench), a benchmark designed to evaluate the reasoning capabilities of MLLMs under extreme visual information. UR-Bench comprises two major categories, Humanistic Scenes and Natural Scenes, covering four subsets of ultra-high-resolution images with distinct spatial structures and data sources. Each subset contains images ranging from hundreds of megapixels to gigapixels, accompanied by questions organized into three levels, enabling evaluation of models' reasoning capabilities in ultra-high-resolution scenarios. We further propose an agent-based framework in which a language model performs reasoning by invoking external visual tools. In addition, we introduce Semantic Abstraction and Retrieval tools that enable more efficient processing of ultra-high-resolution images. We evaluate state-of-the-art models using both an end-to-end MLLMs and our agent-based framework, demonstrating the effectiveness of our framework.", "AI": {"tldr": "本文介绍了UR-Bench，一个用于评估多模态大型语言模型在超高清图像上进行多跳推理能力的基准测试。", "motivation": "现有视觉问答基准通常依赖中等分辨率的数据，无法充分反映超高清图像中的复杂性。为了弥补这一空白，本研究提出了UR-Bench来评测MLLMs处理极端视觉信息的能力。", "method": "UR-Bench包括两个主要类别：人文场景和自然场景，涵盖了四个不同空间结构和数据源的超高清图像子集。每个子集包含从数百兆像素到数十亿像素不等的图片，并配有组织为三个难度级别的问题集合。此外，还提出了一种基于代理的框架，语言模型通过调用外部视觉工具来进行推理。", "result": "使用最先进的模型进行了评估，既包括了端到端的MLLMs也采用了提出的基于代理的框架，结果展示了该框架的有效性。", "conclusion": "UR-Bench为研究超高清图像上的多跳推理能力提供了一个新的基准。实验表明，所提方法在处理复杂视觉信息时优于传统的直接使用大型语言模型的方法。"}}
{"id": "2601.08747", "pdf": "https://arxiv.org/pdf/2601.08747", "abs": "https://arxiv.org/abs/2601.08747", "authors": ["Rubing Chen", "Jian Wang", "Wenjie Li", "Xiao-Yong Wei", "Qing Li"], "title": "To Retrieve or To Think? An Agentic Approach for Context Evolution", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks. However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step. This indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise. To address these limitations, we introduce Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge. ACE employs a central orchestrator agent to make decisions strategically via majority voting. It aims to alternate between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement. By eliminating redundant retrieval steps, ACE maintains a concise and evolved context. Extensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption. Our work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.", "AI": {"tldr": "介绍了一种名为Agentic Context Evolution (ACE)的框架，通过动态决策来优化知识密集型任务中的上下文增强。", "motivation": "现有的上下文增强方法，在每一步都执行检索操作，导致了不必要的计算成本和性能下降。为了改进这一点，提出了一个更智能的方法来管理上下文进化。", "method": "ACE框架包含一个中央协调器代理通过多数投票策略决定是否使用检索代理进行外部检索或推理代理进行内部分析和细化。", "result": "在多跳问答基准上进行了广泛的实验，结果显示ACE显著优于竞争基线，在准确性方面表现更好，并且实现了高效的标记消耗。", "conclusion": "该研究为复杂知识密集型任务中的上下文演进生成提供了有价值的见解。"}}
{"id": "2601.08743", "pdf": "https://arxiv.org/pdf/2601.08743", "abs": "https://arxiv.org/abs/2601.08743", "authors": ["Jinbo Su", "Yuxuan Hu", "Cuiping Li", "Hong Chen", "Jia Li", "Lintao Ma", "Jing Zhang"], "title": "TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. While user queries typically focus on recurrent table sets-offering an opportunity for KV cache sharing across queries-current inference engines, such as SGLang and vLLM, generate redundant prefix cache copies when processing user queries with varying table orders. To address this inefficiency, we propose precomputing table representations as KV caches offline and querying the required ones online. A key aspect of our approach is the computation of table caches while preserving primary foreign key relationships between tables. Additionally, we construct a Table Trie structure to facilitate efficient KV cache lookups during inference. To enhance cache performance, we introduce a cache management system with a query reranking strategy to improve cache hit rates and a computation loading pipeline for parallelizing model inference and cache loading. Experimental results show that our proposed TableCache achieves up to a 3.62x speedup in Time to First Token (TTFT) with negligible performance degradation.", "AI": {"tldr": "本文提出了TableCache方法，通过预计算表格表示作为KV缓存，并维护主外键关系以提高Text-to-SQL任务的低延迟性能。", "motivation": "在Text-to-SQL任务中，现有的基于LLM的方法通常将大量的数据库模式包含在提示中，导致较长的上下文长度和增加的前置填充延迟。此外，当前推理引擎在处理不同表顺序的用户查询时生成冗余前缀缓存副本。", "method": "通过离线预计算表格表示作为KV缓存，并在线检索所需的缓存以提高效率。引入了Table Trie结构来实现高效的KV缓存查找，并提出了一种缓存管理系统，包括重排序策略和并行化模型推理与缓加载的计算加载管道。", "result": "实验结果表明，所提出的TableCache方法在TTFT（Time to First Token）方面实现了高达3.62倍的速度提升，并且性能几乎没有下降。", "conclusion": "通过预计算表格表示并维护主外键关系，TableCache能够有效地减少前置填充延迟，并显著提高Text-to-SQL任务的响应速度。"}}
{"id": "2601.08734", "pdf": "https://arxiv.org/pdf/2601.08734", "abs": "https://arxiv.org/abs/2601.08734", "authors": ["Prithwish Jana", "Sam Davidson", "Bhavana Bhasker", "Andrey Kan", "Anoop Deoras", "Laurent Callot"], "title": "TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback", "categories": ["cs.SE", "cs.AI"], "comment": "The paper has been published at the 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE 2026), Rio de Janeiro, Brazil, April 12-18, 2026", "summary": "Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including ~50x larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen (Test), and 19.60% on TF-Mutn (Test). It outperforms larger models on both TF-Gen (Test) and TF-Mutn (Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance.", "AI": {"tldr": "本文介绍了TerraFormer，一个用于基础设施代码自动生成和变异的神经符号框架。", "motivation": "自动化基础设施代码生成具有挑战性，现有大型语言模型常产生错误配置。该研究旨在解决这一问题，提升IaC生成的质量。", "method": "TerraFormer结合了监督微调与基于策略验证器反馈的强化学习方法，使用形式化验证工具来提供关于语法、部署性和政策符合性的反馈。", "result": "评估显示，TerraFormer在其基础大型语言模型基础上提升了15.94%的正确率，并在两个自建的大规模高质量数据集上超越了包括GPT-4.1在内的更大规模模型。", "conclusion": "研究证明，通过结合监督微调和形式验证反馈，可以显著提高由自然语言生成基础设施代码的质量及政策符合性。"}}
{"id": "2601.08732", "pdf": "https://arxiv.org/pdf/2601.08732", "abs": "https://arxiv.org/abs/2601.08732", "authors": ["Vincent Roca", "Martin Bretzner", "Hilde Henon", "Laurent Puy", "Grégory Kuchcinski", "Renaud Lopes"], "title": "ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate delineation of acute ischemic stroke lesions in MRI is a key component of stroke diagnosis and management. In recent years, deep learning models have been successfully applied to the automatic segmentation of such lesions. While most proposed architectures are based on the U-Net framework, they primarily differ in their choice of loss functions and in the use of deep supervision, residual connections, and attention mechanisms. Moreover, many implementations are not publicly available, and the optimal configuration for acute ischemic stroke (AIS) lesion segmentation remains unclear. In this work, we introduce ISLA (Ischemic Stroke Lesion Analyzer), a new deep learning model for AIS lesion segmentation from diffusion MRI, trained on three multicenter databases totaling more than 1500 AIS participants. Through systematic optimization of the loss function, convolutional architecture, deep supervision, and attention mechanisms, we developed a robust segmentation framework. We further investigated unsupervised domain adaptation to improve generalization to an external clinical dataset. ISLA outperformed two state-of-the-art approaches for AIS lesion segmentation on an external test set. Codes and trained models will be made publicly available to facilitate reuse and reproducibility.", "AI": {"tldr": "ISLA是一种基于U-Net的深度学习模型，用于MRI图像中急性缺血性卒中病变分割，利用了深度监督、注意力机制、领域适应和集成学习。", "motivation": "准确描绘急性缺血性脑卒中的MRI病变是诊断和管理的关键。虽然现有的大多数深度学习架构都是基于U-Net框架的，但它们在损失函数、深层监督和注意机制的选择上有所差异。最佳配置尚不明确且许多实现不可公开获取。", "method": "ISLA模型通过系统优化损失函数、卷积结构、深度监督和注意力机制开发了一个强大的分割框架，并研究了无监督领域适应来提高对外部临床数据集的泛化能力。", "result": "ISLA在外部测试集上超越了两种最先进的急性缺血性脑卒中病变分割方法。", "conclusion": "该研究提出了一种新的深度学习模型ISLA，用于急性缺血性脑卒中病变的MRI图像自动分割，并且代码和训练模型将公开发布以促进重复使用和可复制性。"}}
{"id": "2601.08731", "pdf": "https://arxiv.org/pdf/2601.08731", "abs": "https://arxiv.org/abs/2601.08731", "authors": ["Yuanlin Duan", "Yuning Wang", "Wenjie Qiu", "He Zhu"], "title": "Learning from Demonstrations via Capability-Aware Goal Sampling", "categories": ["cs.AI"], "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Despite its promise, imitation learning often fails in long-horizon environments where perfect replication of demonstrations is unrealistic and small errors can accumulate catastrophically. We introduce Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that mitigates the brittle dependence on expert trajectories for direct imitation. Unlike prior methods that rely on demonstrations only for policy initialization or reward shaping, Cago dynamically tracks the agent's competence along expert trajectories and uses this signal to select intermediate steps--goals that are just beyond the agent's current reach--to guide learning. This results in an adaptive curriculum that enables steady progress toward solving the full task. Empirical results demonstrate that Cago significantly improves sample efficiency and final performance across a range of sparse-reward, goal-conditioned tasks, consistently outperforming existing learning from-demonstrations baselines.", "AI": {"tldr": "本文提出Cago方法，通过动态跟踪代理的能力来选择适当的中间目标指导学习，以提高在长时程环境中的样本效率和最终性能。", "motivation": "尽管模仿学习有潜力，但在长时程环境中它往往难以完美复制演示，并且小错误可能导致灾难性积累。现有方法依赖于演示初始化策略或塑造奖励，但未能有效解决这一问题。", "method": "Cago通过动态跟踪代理的能力沿专家轨迹选择适当的中间目标来指导学习，形成一个自适应的课程以持续进步完成整个任务。", "result": "实验表明，Cago在稀疏奖励和目标导向的任务中显著提高了样本效率和最终性能，并且优于现有的从演示中学习的基准方法。", "conclusion": "研究表明，通过能力感知的目标采样可以有效改善长时程环境中的学习效果，并提高代理的总体表现。"}}
{"id": "2601.08728", "pdf": "https://arxiv.org/pdf/2601.08728", "abs": "https://arxiv.org/abs/2601.08728", "authors": ["Runfeng Qu", "Ole Hall", "Pia K Bideau", "Julie Ouerfelli-Ethier", "Martin Rolfs", "Klaus Obermayer", "Olaf Hellwich"], "title": "Salience-SGG: Enhancing Unbiased Scene Graph Generation with Iterative Salience Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Scene Graph Generation (SGG) suffers from a long-tailed distribution, where a few predicate classes dominate while many others are underrepresented, leading to biased models that underperform on rare relations. Unbiased-SGG methods address this issue by implementing debiasing strategies, but often at the cost of spatial understanding, resulting in an over-reliance on semantic priors. We introduce Salience-SGG, a novel framework featuring an Iterative Salience Decoder (ISD) that emphasizes triplets with salient spatial structures. To support this, we propose semantic-agnostic salience labels guiding ISD. Evaluations on Visual Genome, Open Images V6, and GQA-200 show that Salience-SGG achieves state-of-the-art performance and improves existing Unbiased-SGG methods in their spatial understanding as demonstrated by the Pairwise Localization Average Precision", "AI": {"tldr": "介绍了一种名为Salience-SGG的新框架，通过迭代显着性解码器(ISD)来增强无偏场景图生成，并在多个数据集上取得了最先进的性能。", "motivation": "解决现有的无偏SGG方法在处理长尾分布问题时的空间理解不足的问题，同时提高模型对稀有关系的理解能力。", "method": "提出了一种迭代显着性解码器(ISD)，并通过语义无关的显着性标签来指导ISD，以增强场景图生成中空间结构的突出部分。", "result": "在Visual Genome、Open Images V6和GQA-200数据集上的评估表明，Salience-SGG达到了最先进的性能，并且改进了现有无偏SGG方法的空间理解能力。", "conclusion": "通过引入迭代显着性解码器(ISD)，Salience-SGG框架在保持对稀有关系的理解的同时，显著提高了模型的空间理解能力。"}}
{"id": "2601.08713", "pdf": "https://arxiv.org/pdf/2601.08713", "abs": "https://arxiv.org/abs/2601.08713", "authors": ["Naren Medarametla", "Sreejon Mondal"], "title": "Real-Time Localization Framework for Autonomous Basketball Robots", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "8 pages, 12 figures, Project code: https://github.com/NarenTheNumpkin/Basketball-robot-localization", "summary": "Localization is a fundamental capability for autonomous robots, enabling them to operate effectively in dynamic environments. In Robocon 2025, accurate and reliable localization is crucial for improving shooting precision, avoiding collisions with other robots, and navigating the competition field efficiently. In this paper, we propose a hybrid localization algorithm that integrates classical techniques with learning based methods that rely solely on visual data from the court's floor to achieve self-localization on the basketball field.", "AI": {"tldr": "本文提出了一种混合定位算法，结合经典技术与基于视觉数据的学习方法，在篮球场上实现自主机器人自定位。", "motivation": "为了提高Robocon 2025中篮球机器人的射篮精度、避免与其他机器人碰撞以及高效导航比赛场地，需要实现准确可靠的实时定位能力。", "method": "本文提出了一种混合定位算法，该算法结合了经典技术和仅依赖于球场地板的视觉数据的学习方法来实现实时自定位。", "result": "研究结果表明所提出的混合定位算法在篮球场上提供了准确和可靠的自主机器人自定位功能。", "conclusion": "通过实验验证了基于视觉数据融合的经典与学习技术相结合的方法能够显著提高自主篮球机器人的实时定位性能。"}}
{"id": "2601.08711", "pdf": "https://arxiv.org/pdf/2601.08711", "abs": "https://arxiv.org/abs/2601.08711", "authors": ["Shifa Sulaiman", "Francesco Schetter", "Mehul Menon", "Fanny Ficuciello"], "title": "A Hybrid Model-based and Data-based Approach Developed for a Prosthetic Hand Wrist", "categories": ["cs.RO"], "comment": null, "summary": "The incorporation of advanced control algorithms into prosthetic hands significantly enhances their ability to replicate the intricate motions of a human hand. This work introduces a model-based controller that combines an Artificial Neural Network (ANN) approach with a Sliding Mode Controller (SMC) designed for a tendon-driven soft continuum wrist integrated into a prosthetic hand known as \"PRISMA HAND II\". Our research focuses on developing a controller that provides a fast dynamic response with reduced computational effort during wrist motions. The proposed controller consists of an ANN for computing bending angles together with an SMC to regulate tendon forces. Kinematic and dynamic models of the wrist are formulated using the Piece-wise Constant Curvature (PCC) hypothesis. The performance of the proposed controller is compared with other control strategies developed for the same wrist. Simulation studies and experimental validations of the fabricated wrist using the controller are included in the paper.", "AI": {"tldr": "本文介绍了一种结合人工神经网络(ANN)和滑模控制器(SMC)的模型驱动型控制器，应用于名为“PRISMA HAND II”的仿生手腕上。", "motivation": "为了增强假肢手模仿人类手复杂动作的能力，并提供快速动态响应同时减少计算努力。", "method": "利用分段常数曲率(PCC)假设建立了手腕的运动学和动力学模型，控制器由用于计算弯曲角度的人工神经网络(ANN)和调节腱力的滑模控制器(SMC)组成。", "result": "通过仿真研究和实验验证了所提出的控制器在已制造的手腕上的性能，并将其与为同一手腕开发的其他控制策略进行了比较。", "conclusion": "该研究表明结合ANN和SMC的方法能有效改善仿生手手腕的动态响应并减少计算复杂度，展示出优于其他控制方法的优势。"}}
{"id": "2601.08703", "pdf": "https://arxiv.org/pdf/2601.08703", "abs": "https://arxiv.org/abs/2601.08703", "authors": ["Kaivalya Rawal", "Eoin Delaney", "Zihao Fu", "Sandra Wachter", "Chris Russell"], "title": "Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": "This is a preprint of the paper published at the MURE workshop, AAAI 2026, which builds on a preprint of separate work published at FAccT 2025 (arXiv:2505.10399)", "summary": "Explainable artificial intelligence (XAI) is concerned with producing explanations indicating the inner workings of models. For a Rashomon set of similarly performing models, explanations provide a way of disambiguating the behavior of individual models, helping select models for deployment. However explanations themselves can vary depending on the explainer used, and need to be evaluated. In the paper \"Evaluating Model Explanations without Ground Truth\", we proposed three principles of explanation evaluation and a new method \"AXE\" to evaluate the quality of feature-importance explanations. We go on to illustrate how evaluation metrics that rely on comparing model explanations against ideal ground truth explanations obscure behavioral differences within a Rashomon set. Explanation evaluation aligned with our proposed principles would highlight these differences instead, helping select models from the Rashomon set. The selection of alternate models from the Rashomon set can maintain identical predictions but mislead explainers into generating false explanations, and mislead evaluation methods into considering the false explanations to be of high quality. AXE, our proposed explanation evaluation method, can detect this adversarial fairwashing of explanations with a 100% success rate. Unlike prior explanation evaluation strategies such as those based on model sensitivity or ground truth comparison, AXE can determine when protected attributes are used to make predictions.", "AI": {"tldr": "本文评估了解释方法在Rashomon集合中区分模型行为的能力，并提出了一种新的评价特征重要性解释的质量的方法AXE。", "motivation": "由于不同的解释器可能会产生变化的解释，需要一种有效的评估方法来区分Rashomon集合中的模型行为并帮助选择合适的模型进行部署。", "method": "本文提出了三个解释评估原则和一个名为AXE的新方法用于评价特征重要性解释，并使用该方法检测对抗性公平漂白解释。", "result": "AXE能够以100%的成功率检测到对抗性公平漂白的解释，且与依赖于理想地面真相解释比较的评价度量相比，AXE可以确定保护属性是否用于进行预测。", "conclusion": "AXE作为新的解释评估方法在区分Rashomon集合中模型的行为方面表现优越，并能有效检测出使用保护属性进行预测的情况。"}}
{"id": "2601.08701", "pdf": "https://arxiv.org/pdf/2601.08701", "abs": "https://arxiv.org/abs/2601.08701", "authors": ["Tammar Truzman", "Matthew A. Lambon Ralph", "Ajay D. Halai"], "title": "Automated Lesion Segmentation of Stroke MRI Using nnU-Net: A Comprehensive External Validation Across Acute and Chronic Lesions", "categories": ["q-bio.QM", "cs.CV"], "comment": "32 pages, 7 figures. Submitted to Brain. Code and trained models available", "summary": "Accurate and generalisable segmentation of stroke lesions from magnetic resonance imaging (MRI) is essential for advancing clinical research, prognostic modelling, and personalised interventions. Although deep learning has improved automated lesion delineation, many existing models are optimised for narrow imaging contexts and generalise poorly to independent datasets, modalities, and stroke stages. Here, we systematically evaluated stroke lesion segmentation using the nnU-Net framework across multiple heterogeneous, publicly available MRI datasets spanning acute and chronic stroke. Models were trained and tested on diffusion-weighted imaging (DWI), fluid-attenuated inversion recovery (FLAIR), and T1-weighted MRI, and evaluated on independent datasets. Across stroke stages, models showed robust generalisation, with segmentation accuracy approaching reported inter-rater reliability. Performance varied with imaging modality and training data characteristics. In acute stroke, DWI-trained models consistently outperformed FLAIR-based models, with only modest gains from multimodal combinations. In chronic stroke, increasing training set size improved performance, with diminishing returns beyond several hundred cases. Lesion volume was a key determinant of accuracy: smaller lesions were harder to segment, and models trained on restricted volume ranges generalised poorly. MRI image quality further constrained generalisability: models trained on lower-quality scans transferred poorly, whereas those trained on higher-quality data generalised well to noisier images. Discrepancies between predictions and reference masks were often attributable to limitations in manual annotations. Together, these findings show that automated lesion segmentation can approach human-level performance while identifying key factors governing generalisability and informing the development of lesion segmentation tools.", "AI": {"tldr": "使用nnU-Net框架进行急性期和慢性期中风MRI病变分割的外部验证。", "motivation": "精确且可泛化的中风病灶分割对于推动临床研究、预后建模和个人化干预至关重要。虽然深度学习提高了自动病变勾勒的能力，但许多现有模型优化于特定成像环境，在独立数据集、成像模式和疾病阶段上的泛化能力较差。", "method": "在跨越急性期和慢性期的多个异构公开MRI数据集中系统评估了nnU-Net框架下的中风病灶分割效果。训练及测试使用了DWI、FLAIR以及T1加权MRI，并对独立数据集进行了性能评价。", "result": "模型展示了稳健的泛化能力，其分割精度接近报道的人工注释者之间的可靠性标准。根据不同成像模式和培训数据特征，表现有所差异。急性期中风时，基于DWI训练的模型优于FLAIR基模型；慢性期增加培训集大小改善性能，但超过数百案例后效果递减。", "conclusion": "自动病灶分割可接近人类水平的表现，并指出了影响泛化能力的关键因素及为开发病变分割工具提供了指导。"}}
{"id": "2601.08697", "pdf": "https://arxiv.org/pdf/2601.08697", "abs": "https://arxiv.org/abs/2601.08697", "authors": ["Nifu Dan"], "title": "Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "As generative AI becomes embedded in higher education, it increasingly shapes how students complete academic tasks. While these systems offer efficiency and support, concerns persist regarding over-automation, diminished student agency, and the potential for unreliable or hallucinated outputs. This study conducts a mixed-methods audit of student-AI collaboration preferences by examining the alignment between current AI capabilities and students' desired levels of automation in academic work. Using two sequential and complementary surveys, we capture students' perceived benefits, risks, and preferred boundaries when using AI. The first survey employs an existing task-based framework to assess preferences for and actual usage of AI across 12 academic tasks, alongside primary concerns and reasons for use. The second survey, informed by the first, explores how AI systems could be designed to address these concerns through open-ended questions. This study aims to identify gaps between existing AI affordances and students' normative expectations of collaboration, informing the development of more effective and trustworthy AI systems for education.", "AI": {"tldr": "该论文研究了在线研究生计算机科学学生在学术任务中与AI协作的偏好，并通过两项调查来识别现有AI功能和学生期望之间的差距，以开发更有效且值得信赖的教育AI系统。", "motivation": "随着生成性AI在高等教育中的嵌入，它改变了学生的学业完成方式。尽管这些系统提供了效率和支持，但仍然存在过度自动化、削弱学生自主权以及产生不可靠或虚构输出的风险。这项研究旨在理解当前AI能力和学生期望之间的差距，并提出改进措施。", "method": "研究采用混合方法审计学生与AI的协作偏好，包括两个互补的顺序调查。第一个调查使用现有的基于任务框架来评估学生在12项学术任务中的AI使用偏好和实际使用情况，以及主要关注点和使用原因。第二个调查通过开放性问题探讨如何设计AI系统以解决这些关注。", "result": "研究识别了现有AI功能与学生期望之间存在的差距，并收集到了关于学生对AI的感知益处、风险以及界限的观点。", "conclusion": "该研究表明，通过了解和满足学生的协作期望，可以开发出更符合需求且值得信赖的教育领域AI系统。"}}
{"id": "2601.08696", "pdf": "https://arxiv.org/pdf/2601.08696", "abs": "https://arxiv.org/abs/2601.08696", "authors": ["Andoni Irazusta Garmendia", "Josu Ceberio", "Alexander Mendiburu"], "title": "Enabling Population-Based Architectures for Neural Combinatorial Optimization", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Neural Combinatorial Optimization (NCO) has mostly focused on learning policies, typically neural networks, that operate on a single candidate solution at a time, either by constructing one from scratch or iteratively improving it. In contrast, decades of work in metaheuristics have shown that maintaining and evolving populations of solutions improves robustness and exploration, and often leads to stronger performance. To close this gap, we study how to make NCO explicitly population-based by learning policies that act on sets of candidate solutions. We first propose a simple taxonomy of population awareness levels and use it to highlight two key design challenges: (i) how to represent a whole population inside a neural network, and (ii) how to learn population dynamics that balance intensification (generating good solutions) and diversification (maintaining variety). We make these ideas concrete with two complementary tools: one that improves existing solutions using information shared across the whole population, and the other generates new candidate solutions that explicitly balance being high-quality with diversity. Experimental results on Maximum Cut and Maximum Independent Set indicate that incorporating population structure is advantageous for learned optimization methods and opens new connections between NCO and classical population-based search.", "AI": {"tldr": "本文探讨了如何使神经组合优化（NCO）方法具备基于群体的架构，通过学习作用于候选解集的策略来提高鲁棒性和探索能力。", "motivation": "传统上，NCO主要集中在单个候选解决方案的学习政策上。然而，元启发式算法的工作表明，维护和演化的解决方案种群可以提高鲁棒性、探索能力和性能。因此，本文旨在研究如何使NCO具备基于群体的架构。", "method": "作者提出了一套简单的群体意识水平分类，并提出了两个设计挑战：(i) 如何将整个群体表示在神经网络中；(ii) 如何学习平衡集约化和多样化的人口动态。为此，他们提出了两种互补工具：一种是利用整个群体共享的信息改进现有解决方案，另一种则是生成同时保持高质量与多样性的新候选解决方案。", "result": "实验结果表明，在最大割问题和最大独立集问题中，引入种群结构对于学习优化方法是有利的，并开辟了NCO与经典基于群体搜索之间的新联系。", "conclusion": "研究结论认为，在神经组合优化中采用基于群体的方法可以显著提高鲁棒性和探索能力，为该领域打开了新的研究方向。"}}
{"id": "2601.08690", "pdf": "https://arxiv.org/pdf/2601.08690", "abs": "https://arxiv.org/abs/2601.08690", "authors": ["Shubham Kulkarni", "Alexander Lyzhov", "Shiva Chaitanya", "Preetam Joshi"], "title": "All Required, In Order: Phase-Level Evaluation for AI-Human Dialogue in Healthcare and Beyond", "categories": ["cs.AI"], "comment": "Accepted at the AI for Medicine and Healthcare (AIMedHealth) Bridge Program, AAAI-26, Singapore. Full-length paper; to appear in Proceedings of Machine Learning Research (PMLR)", "summary": "Conversational AI is starting to support real clinical work, but most evaluation methods miss how compliance depends on the full course of a conversation. We introduce Obligatory-Information Phase Structured Compliance Evaluation (OIP-SCE), an evaluation method that checks whether every required clinical obligation is met, in the right order, with clear evidence for clinicians to review. This makes complex rules practical and auditable, helping close the gap between technical progress and what healthcare actually needs. We demonstrate the method in two case studies (respiratory history, benefits verification) and show how phase-level evidence turns policy into shared, actionable steps. By giving clinicians control over what to check and engineers a clear specification to implement, OIP-SCE provides a single, auditable evaluation surface that aligns AI capability with clinical workflow and supports routine, safe use.", "AI": {"tldr": "本文介绍了OIP-SCE评估方法，用于检查对话式AI在医疗保健中的合规性，并确保每个必要的临床义务都按照正确的顺序完成。", "motivation": "虽然对话式AI开始支持实际的临床工作，但大多数评价方法未能考虑到合规性依赖于整个对话过程的问题。为了缩小技术进步与医疗保健实际需求之间的差距，作者提出了OIP-SCE评估方法。", "method": "引入了Obligatory-Information Phase Structured Compliance Evaluation（OIP-SCE），一种评估方法，用于检查每项必要的临床义务是否在正确顺序下完成，并为医生提供清晰的证据以供审查。", "result": "通过两个案例研究（呼吸病史、福利验证）展示了该方法如何将政策转化为共享和可执行步骤。结果显示了OIP-SCE如何帮助临床医生控制要检查的内容并为工程师提供明确的实施规范。", "conclusion": "OIP-SCE提供了单一且可审计的评估表面，使AI能力与临床工作流程保持一致，并支持常规安全使用。"}}
{"id": "2601.08687", "pdf": "https://arxiv.org/pdf/2601.08687", "abs": "https://arxiv.org/abs/2601.08687", "authors": ["Marco Tonnarelli", "Filippo Scaramuzza", "Simon Harrer", "Linus W. Dietz"], "title": "Data Product MCP: Chat with your Enterprise Data", "categories": ["cs.ET"], "comment": "7 pages, preprint", "summary": "Computational data governance aims to make the enforcement of governance policies and legal obligations more efficient and reliable. Recent advances in natural language processing and agentic AI offer ways to improve how organizations share and use data. But many barriers remain. Today's tools require technical skills and multiple roles to discover, request, and query data. Automating data access using enterprise AI agents is limited by the means to discover and autonomously access distributed data. Current solutions either compromise governance or break agentic workflows through manual approvals. To close this gap, we introduce Data Product MCP integrated in a data product marketplace. This data marketplace, already in use at large enterprises, enables AI agents to find, request, and query enterprise data products while enforcing data contracts in real time without lowering governance standards. The system is built on the Model Context Protocol (MCP) and links the AI-driven marketplace with cloud platforms such as Snowflake, Databricks, and Google Cloud Platform. It supports semantic discovery of data products based on business context, automates access control by validating generated queries against approved business purposes using AI-driven checks, and enforces contracts in real time by blocking unauthorized queries before they run. We assessed the system with feedback from $n=16$ experts in data governance. Our qualitative evaluation demonstrates effectiveness through enterprise scenarios such as customer analytics. The findings suggest that Data Product MCP reduces the technical burden for data analysis without weakening governance, filling a key gap in enterprise AI adoption.", "AI": {"tldr": "本文介绍了一个名为Data Product MCP的系统，该系统通过集成AI代理和数据治理合同，在企业数据市场中实现自动化的数据发现、请求和查询。", "motivation": "文章旨在解决当前工具需要技术技能和多角色来处理数据发现、请求和查询的问题，并且现有的解决方案在自动化数据访问上存在局限性，导致治理政策或工作流程受阻。", "method": "Data Product MCP系统基于Model Context Protocol（MCP）构建，集成AI驱动的市场与云平台连接。它支持根据业务上下文进行语义发现数据产品、通过AI驱动检查验证生成查询以实现自动访问控制，并实时执行合同阻止未经授权的查询运行。", "result": "作者通过对$n=16$位数据治理专家进行了定性评估，证明了Data Product MCP在企业场景如客户分析中的有效性。结果显示该系统能够减轻数据分析的技术负担，而不会削弱治理标准。", "conclusion": "结论指出，Data Product MCP填补了企业在AI采用方面的关键空白，实现了自动化且安全的数据访问，无需降低数据治理的标准，从而促进了企业的效率与安全性。"}}
{"id": "2601.08684", "pdf": "https://arxiv.org/pdf/2601.08684", "abs": "https://arxiv.org/abs/2601.08684", "authors": ["Paolo Italiani", "David Gimeno-Gomez", "Luca Ragazzi", "Gianluca Moro", "Paolo Rosso"], "title": "MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection", "categories": ["cs.AI", "cs.CV"], "comment": "Accepted at EACL 2026 Findings", "summary": "Women are twice as likely as men to face online harassment due to their gender. Despite recent advances in multimodal content moderation, most approaches still overlook the social dynamics behind this phenomenon, where perpetrators reinforce prejudices and group identity within like-minded communities. Graph-based methods offer a promising way to capture such interactions, yet existing solutions remain limited by heuristic graph construction, shallow modality fusion, and instance-level reasoning. In this work, we present MemeWeaver, an end-to-end trainable multimodal framework for detecting sexism and misogyny through a novel inter-meme graph reasoning mechanism. We systematically evaluate multiple visual--textual fusion strategies and show that our approach consistently outperforms state-of-the-art baselines on the MAMI and EXIST benchmarks, while achieving faster training convergence. Further analyses reveal that the learned graph structure captures semantically meaningful patterns, offering valuable insights into the relational nature of online hate.", "AI": {"tldr": "本文介绍了一种名为MemeWeaver的端到端可训练多模态框架，用于通过创新的跨模因图推理机制检测性别歧视和厌女情绪。", "motivation": "鉴于女性遭受网络骚扰的可能性是男性的两倍，且大多数现有方法忽视了这一现象背后的社会动态，作者提出了MemeWeaver以解决现有的基于图的方法在图构建、模态融合及实例级推理方面的局限性。", "method": "MemeWeaver采用了一种创新的跨模因图推理机制，并系统评估了多种视觉-文本融合策略来检测性别歧视和厌女情绪。", "result": "该方法在MAMI和EXIST基准上始终优于最先进的基线，且训练收敛速度更快。", "conclusion": "分析表明学习到的图结构捕获了语义上有意义的模式，提供了关于网络仇恨关系性质的有价值见解。"}}
{"id": "2601.08683", "pdf": "https://arxiv.org/pdf/2601.08683", "abs": "https://arxiv.org/abs/2601.08683", "authors": ["Loris Giordano", "Ine Dirks", "Tom Lenaerts", "Jef Vandemeulebroucke"], "title": "Region of interest detection for efficient aortic segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "ef:Medical Imaging 2025: Image Processing (Vol. 13406, pp. 390-400). SPIE", "summary": "Thoracic aortic dissection and aneurysms are the most lethal diseases of the aorta. The major hindrance to treatment lies in the accurate analysis of the medical images. More particularly, aortic segmentation of the 3D image is often tedious and difficult. Deep-learning-based segmentation models are an ideal solution, but their inability to deliver usable outputs in difficult cases and their computational cost cause their clinical adoption to stay limited. This study presents an innovative approach for efficient aortic segmentation using targeted region of interest (ROI) detection. In contrast to classical detection models, we propose a simple and efficient detection model that can be widely applied to detect a single ROI. Our detection model is trained as a multi-task model, using an encoder-decoder architecture for segmentation and a fully connected network attached to the bottleneck for detection. We compare the performance of a one-step segmentation model applied to a complete image, nnU-Net and our cascade model composed of a detection and a segmentation step. We achieve a mean Dice similarity coefficient of 0.944 with over 0.9 for all cases using a third of the computing power. This simple solution achieves state-of-the-art performance while being compact and robust, making it an ideal solution for clinical applications.", "AI": {"tldr": "本文提出了一种用于高效主动脉分割的感兴趣区域检测方法。", "motivation": "鉴于胸主动脉夹层和动脉瘤等疾病的准确医学影像分析困难，尤其是三维图像的主动脉分割复杂耗时，本研究旨在通过创新的方法提高这一过程的效率与准确性。", "method": "本文提出了一种基于多任务模型的简单有效的检测方法，该模型使用编码器-解码器结构进行分割，并附加了一个全连接网络用于检测瓶颈区域，从而实现主动脉ROI的高效识别和分割。", "result": "相比完整图像的一次性分割以及nnU-Net等现有方法，本文的方法在计算资源减少三分之一的情况下实现了0.944的平均Dice相似系数，所有案例均超过0.9的表现。", "conclusion": "该简单解决方案达到了最先进的性能水平，同时具有紧凑性和鲁棒性的特点，为临床应用提供了理想的解决方案。"}}
{"id": "2601.08682", "pdf": "https://arxiv.org/pdf/2601.08682", "abs": "https://arxiv.org/abs/2601.08682", "authors": ["Kushal Chawla", "Chenyang Zhu", "Pengshan Cai", "Sangwoo Cho", "Scott Novotney", "Ayushman Singh", "Jonah Lewis", "Keasha Safewright", "Alfy Samuel", "Erin Babinsky", "Shi-Xiong Zhang", "Sambit Sahu"], "title": "Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization", "categories": ["cs.CL", "cs.AI"], "comment": "EACL 2026 Industry Track", "summary": "Summarization of multi-party dialogues is a critical capability in industry, enhancing knowledge transfer and operational effectiveness across many domains. However, automatically generating high-quality summaries is challenging, as the ideal summary must satisfy a set of complex, multi-faceted requirements. While summarization has received immense attention in research, prior work has primarily utilized static datasets and benchmarks, a condition rare in practical scenarios where requirements inevitably evolve. In this work, we present an industry case study on developing an agentic system to summarize multi-party interactions. We share practical insights spanning the full development lifecycle to guide practitioners in building reliable, adaptable summarization systems, as well as to inform future research, covering: 1) robust methods for evaluation despite evolving requirements and task subjectivity, 2) component-wise optimization enabled by the task decomposition inherent in an agentic architecture, 3) the impact of upstream data bottlenecks, and 4) the realities of vendor lock-in due to the poor transferability of LLM prompts.", "AI": {"tldr": "本文介绍了一个工业案例研究，用于开发一个能够总结多方互动的自主系统，并提供了构建可靠、可适应的摘要系统的实用见解。", "motivation": "自动生成高质量对话摘要面临挑战，因为理想的摘要需要满足一套复杂且多方面的要求。以往的研究大多使用静态数据集和基准测试，但在实际场景中这些需求会不断变化。", "method": "本文通过一个行业案例研究，涵盖了开发生命周期中的实用见解，包括：1) 在不断变化的需求和任务主观性下的评估方法；2) 由自主架构固有的任务分解启用的组件优化；3) 上游数据瓶颈的影响；4) 因为LLM提示较差的可移植性而产生的供应商锁定现实。", "result": "分享了在实际开发过程中遇到的各种挑战及其解决方案，如评估策略、系统优化和处理数据问题等方面的经验。", "conclusion": "研究强调了在不断变化的需求环境中构建对话摘要系统的重要性，并提供了实用指导，以帮助从业者建立可靠且可适应的总结系统。"}}
{"id": "2601.08679", "pdf": "https://arxiv.org/pdf/2601.08679", "abs": "https://arxiv.org/abs/2601.08679", "authors": ["Xiaoyou Liu", "Xinyi Mou", "Shengbin Yue", "Liang Wang", "Yuqing Wang", "Qiexiang Wang", "Tianrui Qin", "Wangchunshu Zhou", "Zhongyu Wei"], "title": "PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "As users increasingly expect LLMs to align with their preferences, personalized information becomes valuable. However, personalized information can be a double-edged sword: it can improve interaction but may compromise objectivity and factual correctness, especially when it is misaligned with the question. To alleviate this problem, we propose PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasoning in a single model, and adaptively switches modes based on context. PersonaDual is first trained with SFT to learn two reasoning patterns, and then further optimized via reinforcement learning with our proposed DualGRPO to improve mode selection. Experiments on objective and personalized benchmarks show that PersonaDual preserves the benefits of personalization while reducing interference, achieving near interference-free performance and better leveraging helpful personalized signals to improve objective problem-solving.", "AI": {"tldr": "本文介绍了一个名为PersonaDual的框架，旨在通过自适应推理平衡个性化和客观性。", "motivation": "随着用户对LLMs个性化的期望增加，个性化信息变得有价值，但这种信息可能会影响交互的客观性和准确性，特别是在与问题不一致时。为了缓解这个问题，提出了PersonaDual。", "method": "PersonaDual首先通过SFT训练学习两种推理模式，然后使用提出的DualGRPO进行强化学习以优化模式选择。", "result": "实验表明，PersonaDual在保持个性化优势的同时减少了干扰，实现了接近无干扰的性能，并更好地利用个性化信号来改进客观问题解决能力。", "conclusion": "PersonaDual能够有效地平衡个性化和客观性，在适应不同情境时提供了更准确、个性化的交互体验。"}}
{"id": "2601.08676", "pdf": "https://arxiv.org/pdf/2601.08676", "abs": "https://arxiv.org/abs/2601.08676", "authors": ["Yilei Zhao", "Wentao Zhang", "Lei Xiao", "Yandan Zheng", "Mengpu Liu", "Wei Yang Bryan Lim"], "title": "Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance", "categories": ["cs.AI"], "comment": null, "summary": "Environmental, social, and governance (ESG) criteria are essential for evaluating corporate sustainability and ethical performance. However, professional ESG analysis is hindered by data fragmentation across unstructured sources, and existing large language models (LLMs) often struggle with the complex, multi-step workflows required for rigorous auditing. To address these limitations, we introduce ESGAgent, a hierarchical multi-agent system empowered by a specialized toolset, including retrieval augmentation, web search and domain-specific functions, to generate in-depth ESG analysis. Complementing this agentic system, we present a comprehensive three-level benchmark derived from 310 corporate sustainability reports, designed to evaluate capabilities ranging from atomic common-sense questions to the generation of integrated, in-depth analysis. Empirical evaluations demonstrate that ESGAgent outperforms state-of-the-art closed-source LLMs with an average accuracy of 84.15% on atomic question-answering tasks, and excels in professional report generation by integrating rich charts and verifiable references. These findings confirm the diagnostic value of our benchmark, establishing it as a vital testbed for assessing general and advanced agentic capabilities in high-stakes vertical domains.", "AI": {"tldr": "本文介绍了ESGAgent，一种基于多智能体系统的专业级ESG分析工具，并提出了一种全面的三层次基准测试，以评估其在可持续金融领域的表现。", "motivation": "现有的大型语言模型难以处理复杂、多步骤的工作流程，导致专业的ESG分析受限于分散且非结构化的数据源。该研究旨在解决这些问题。", "method": "提出了一个由检索增强、网络搜索和特定领域功能组成的工具集支持的层级多智能体系统（ESGAgent），并通过310份企业可持续发展报告构建了一个三层次基准测试，评估其能力。", "result": "实证研究表明，ESGAgent在原子级问答任务中的平均准确率为84.15%，并优于现有的闭源大型语言模型。此外，在专业报告生成方面也表现出色，能够整合丰富的图表和可验证的引用。", "conclusion": "研究确认了基准测试的诊断价值，并将其确立为评估高风险垂直领域中一般和高级代理能力的重要测试床。"}}
{"id": "2601.08674", "pdf": "https://arxiv.org/pdf/2601.08674", "abs": "https://arxiv.org/abs/2601.08674", "authors": ["Lucas Lopes", "Rayson Laroca", "André Grégio"], "title": "Além do Desempenho: Um Estudo da Confiabilidade de Detectores de Deepfakes", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for presentation at the Brazilian Symposium on Cybersecurity (SBSeg) 2025, in Portuguese language", "summary": "Deepfakes are synthetic media generated by artificial intelligence, with positive applications in education and creativity, but also serious negative impacts such as fraud, misinformation, and privacy violations. Although detection techniques have advanced, comprehensive evaluation methods that go beyond classification performance remain lacking. This paper proposes a reliability assessment framework based on four pillars: transferability, robustness, interpretability, and computational efficiency. An analysis of five state-of-the-art methods revealed significant progress as well as critical limitations.", "AI": {"tldr": "本文提出了一种基于可转移性、鲁棒性、可解释性和计算效率四个支柱的深度伪造检测器可靠性评估框架。", "motivation": "尽管深度伪造检测技术有所进展，但全面的评价方法仍然不足。本研究旨在弥补这一空白，通过深入分析五种最先进的方法来揭示其优势和局限。", "method": "提出一种可靠性评估框架，基于四个支柱：可转移性、鲁棒性、可解释性和计算效率，并对五种最先进的深度伪造检测器进行了分析。", "result": "分析结果显示了显著的进步以及一些关键的限制。", "conclusion": "通过该框架，研究揭示了当前深度伪造检测技术的优点和不足，为未来的研究提供了方向。"}}
