{"id": "2602.19319", "pdf": "https://arxiv.org/pdf/2602.19319", "abs": "https://arxiv.org/abs/2602.19319", "authors": ["Sujaya Maiyya", "Shantanu Sharma", "Avinash Kumar"], "title": "Health+: Empowering Individuals via Unifying Health Data", "categories": ["cs.MM", "cs.AI", "cs.CR", "cs.DB", "cs.DC"], "comment": "This paper has been accepted in ACM Multimedia 2025", "summary": "Managing personal health data is a challenge in today's fragmented and institution-centric healthcare ecosystem. Individuals often lack meaningful control over their medical records, which are scattered across incompatible systems and formats. This vision paper presents Health+, a user-centric, multimodal health data management system that empowers individuals (including those with limited technical expertise) to upload, query, and share their data across modalities (e.g., text, images, reports). Rather than aiming for institutional overhaul, Health+ emphasizes individual agency by providing intuitive interfaces and intelligent recommendations for data access and sharing. At the system level, it tackles the complexity of storing, integrating, and securing heterogeneous health records, ensuring both efficiency and privacy. By unifying multimodal data and prioritizing patients, Health+ lays the foundation for a more connected, interpretable, and user-controlled health information ecosystem.", "AI": {"tldr": "Health+是一款个人健康数据管理系统，旨在通过统一多模态健康记录来增强个体的控制和管理能力。", "motivation": "当前医疗系统的碎片化和个人对医疗记录缺乏有效控制促使了开发一个用户友好的系统的需求，以便更好地管理和分享个人健康数据。", "method": "Health+设计了一个直观的操作界面，并提供了智能推荐机制以支持数据访问与共享；同时处理存储、整合及保护异构健康记录的问题，保证高效性及隐私安全。", "result": "通过统一多模态健康信息和优先考虑患者需求，Health+建立了更加互联、可解读且用户可控的健康信息系统基础。", "conclusion": "该系统为未来医疗领域的个人健康管理提供了一个新视角，强调了个体在数据管理中的关键作用。"}}
{"id": "2602.19317", "pdf": "https://arxiv.org/pdf/2602.19317", "abs": "https://arxiv.org/abs/2602.19317", "authors": ["Maryam Amirizaniani", "Alireza Salemi", "Hamed Zamani"], "title": "Learning to Reason for Multi-Step Retrieval of Personal Context in Personalized Question Answering", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Personalization in Question Answering (QA) requires answers that are both accurate and aligned with users' background, preferences, and historical context. Existing state-of-the-art methods primarily rely on retrieval-augmented generation (RAG) solutions that construct personal context by retrieving relevant items from the user's profile. Existing methods use the user's query directly to retrieve personal documents, and such strategies often lead to surface-level personalization. We propose PR2 (Personalized Retrieval-Augmented Reasoning), a reinforcement learning framework that integrates reasoning and retrieval from personal context for personalization. PR2 learns adaptive retrieval-reasoning policies, determining when to retrieve, what evidence to retrieve from user profiles, and how to incorporate it into intermediate reasoning steps. By optimizing multi-turn reasoning trajectories under a personalized reward function, the framework reinforces reasoning paths that better align with user-specific preferences and contextual signals reflected by the reward model. Extensive experiments on the LaMP-QA benchmark using three LLMs show that PR2 consistently outperforms strong baselines, achieving an average relative improvement of 8.8%-12% in personalized QA.", "AI": {"tldr": "论文提出了一种用于个性化问答的强化学习框架PR2，该框架结合了推理和从个人背景中检索证据的能力。", "motivation": "现有的个性化问题回答方法主要依赖于从用户资料中直接检索相关文档进行表面化个性化处理。因此，需要一种能够深入理解用户背景并生成与之高度相关的答案的方法。", "method": "PR2框架利用强化学习来优化多步推理路径，并通过奖励模型实现个性化反馈机制，该模型决定何时检索、检索什么证据以及如何将其融入到中间的推理步骤中。", "result": "在LaMP-QA基准测试上使用三种大型语言模型进行实验表明，PR2框架相比现有基线方法在个性化问答方面实现了8.8%-12%的相对性能提升。", "conclusion": "通过优化多步推理路径和奖励机制，PR2能够更好地生成与用户背景相关的答案，并提高个性化问题回答的质量。"}}
{"id": "2602.19316", "pdf": "https://arxiv.org/pdf/2602.19316", "abs": "https://arxiv.org/abs/2602.19316", "authors": ["Alexandros Haliassos", "Rodrigo Mira", "Stavros Petridis"], "title": "Pay Attention to CTC: Fast and Robust Pseudo-Labelling for Unified Speech Recognition", "categories": ["cs.CV", "cs.SD"], "comment": "ICLR 2026. Code: https://github.com/ahaliassos/usr2", "summary": "Unified Speech Recognition (USR) has emerged as a semi-supervised framework for training a single model for audio, visual, and audiovisual speech recognition, achieving state-of-the-art results on in-distribution benchmarks. However, its reliance on autoregressive pseudo-labelling makes training expensive, while its decoupled supervision of CTC and attention branches increases susceptibility to self-reinforcing errors, particularly under distribution shifts involving longer sequences, noise, or unseen domains. We propose CTC-driven teacher forcing, where greedily decoded CTC pseudo-labels are fed into the decoder to generate attention targets in a single forward pass. Although these can be globally incoherent, in the pseudo-labelling setting they enable efficient and effective knowledge transfer. Because CTC and CTC-driven attention pseudo-labels have the same length, the decoder can predict both simultaneously, benefiting from the robustness of CTC and the expressiveness of attention without costly beam search. We further propose mixed sampling to mitigate the exposure bias of the decoder relying solely on CTC inputs. The resulting method, USR 2.0, halves training time, improves robustness to out-of-distribution inputs, and achieves state-of-the-art results on LRS3, LRS2, and WildVSR, surpassing USR and modality-specific self-supervised baselines.", "AI": {"tldr": "提出了一种基于CTC驱动的教师强制学习方法，用于统一语音识别中的伪标签生成，提高了模型训练效率和鲁棒性。", "motivation": "现有统一语音识别框架依赖于自回归伪标签导致训练成本高，并且CTC与注意力分支的解耦监督增加了错误积累的风险，特别是在长序列、噪声或未见领域的情况下。", "method": "引入了基于贪婪解码CTC伪标签进行教师强制学习的方法，在一次前向传播中生成注意力目标，同时使用混合采样减轻解码器仅依赖CTC输入导致的暴露偏差问题。", "result": "该方法将训练时间减半，增强了模型对分布外输入的鲁棒性，并在LRS3、LRS2和WildVSR等数据集上取得了最先进的性能。", "conclusion": "所提出的方法USR 2.0提升了统一语音识别系统的效率与表现力，在多个基准测试中超越了现有方法和其他模态特定的自监督基线。"}}
{"id": "2602.19315", "pdf": "https://arxiv.org/pdf/2602.19315", "abs": "https://arxiv.org/abs/2602.19315", "authors": ["Victor-Alexandru Darvariu", "Charlotte Z. Reed", "Jan Stratmann", "Bruno Lacerda", "Benjamin Allsup", "Stephen Woodward", "Elizabeth Siddle", "Trishna Saeharaseelan", "Owain Jones", "Dan Jones", "Tobias Ferreira", "Chloe Baker", "Kevin Chaplin", "James Kirk", "Ashley Morris", "Ryan Patmore", "Jeff Polton", "Charlotte Williams", "Alexandra Kokkinaki", "Alvaro Lorenzo Lopez", "Justin J. H. Buck", "Nick Hawes"], "title": "Online Navigation Planning for Long-term Autonomous Operation of Underwater Gliders", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Underwater glider robots have become an indispensable tool for ocean sampling. Although stakeholders are calling for tools to manage increasingly large fleets of gliders, successful autonomous long-term deployments have thus far been scarce, which hints at a lack of suitable methodologies and systems. In this work, we formulate glider navigation planning as a stochastic shortest-path Markov Decision Process and propose a sample-based online planner based on Monte Carlo Tree Search. Samples are generated by a physics-informed simulator that captures uncertain execution of controls and ocean current forecasts while remaining computationally tractable. The simulator parameters are fitted using historical glider data. We integrate these methods into an autonomous command-and-control system for Slocum gliders that enables closed-loop replanning at each surfacing. The resulting system was validated in two field deployments in the North Sea totalling approximately 3 months and 1000 km of autonomous operation. Results demonstrate improved efficiency compared to straight-to-goal navigation and show the practicality of sample-based planning for long-term marine autonomy.", "AI": {"tldr": "论文提出了基于蒙特卡洛树搜索的样本生成在线规划方法，用于优化水下滑翔机的自主航行。", "motivation": "目前水下滑翔机的大规模舰队管理缺乏有效的技术和系统支持，该研究旨在通过开发新的导航规划算法提高其自主长期操作效率。", "method": "论文采用基于马尔可夫决策过程的随机最短路径问题模型，并利用物理信息生成样本的方法结合蒙特卡洛树搜索进行在线规划。此方法被集成到一个闭环重新规划系统中，该系统在每次浮出水面时自动调整航行计划。", "result": "实验结果显示，与直接目标导航相比，新提出的规划策略提高了滑翔机的航行效率，并验证了样本生成规划方法在长期海上自主操作中的实用性。", "conclusion": "论文展示了基于蒙特卡洛树搜索的在线规划算法能够有效提升水下滑翔机自主长时间运行的表现。"}}
{"id": "2602.19314", "pdf": "https://arxiv.org/pdf/2602.19314", "abs": "https://arxiv.org/abs/2602.19314", "authors": ["Guoliang Gong", "Man Yu"], "title": "IPv2: An Improved Image Purification Strategy for Real-World Ultra-Low-Dose Lung CT Denoising", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The image purification strategy constructs an intermediate distribution with aligned anatomical structures, which effectively corrects the spatial misalignment between real-world ultra-low-dose CT and normal-dose CT images and significantly enhances the structural preservation ability of denoising models. However, this strategy exhibits two inherent limitations. First, it suppresses noise only in the chest wall and bone regions while leaving the image background untreated. Second, it lacks a dedicated mechanism for denoising the lung parenchyma. To address these issues, we systematically redesign the original image purification strategy and propose an improved version termed IPv2. The proposed strategy introduces three core modules, namely Remove Background, Add noise, and Remove noise. These modules endow the model with denoising capability in both background and lung tissue regions during training data construction and provide a more reasonable evaluation protocol through refined label construction at the testing stage. Extensive experiments on our previously established real-world patient lung CT dataset acquired at 2% radiation dose demonstrate that IPv2 consistently improves background suppression and lung parenchyma restoration across multiple mainstream denoising models. The code is publicly available at https://github.com/MonkeyDadLufy/Image-Purification-Strategy-v2.", "AI": {"tldr": "改进了一种用于超低剂量肺CT图像去噪的图像净化策略，引入了背景去除、加噪声和去噪声三个核心模块。", "motivation": "原有的图像净化策略在处理胸部壁骨区域时有效但忽略了背景，并且缺乏对肺实质的去噪机制。为了解决这些问题，提出了改进版IPv2。", "method": "提出了一种新的去噪策略IPv2，包括去除背景、加噪声和去噪声三个模块，通过训练数据构建提升模型在背景和肺组织区域的去噪能力，并通过精细化标签构造提高测试阶段评估的合理性。", "result": "实验证明，在2%辐射剂量的真实患者肺CT图像上，IPv2能够显著改进背景抑制和肺实质恢复效果。", "conclusion": "新的净化策略IPv2能够在超低剂量CT图像去噪中提供更好的性能，尤其是在提升背景噪声处理能力和改善肺实质质量方面。"}}
{"id": "2602.19313", "pdf": "https://arxiv.org/pdf/2602.19313", "abs": "https://arxiv.org/abs/2602.19313", "authors": ["Shirui Chen", "Cole Harrison", "Ying-Chun Lee", "Angela Jin Yang", "Zhongzheng Ren", "Lillian J. Ratliff", "Jiafei Duan", "Dieter Fox", "Ranjay Krishna"], "title": "TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "While Vision-Language-Action (VLA) models have seen rapid progress in pretraining, their advancement in Reinforcement Learning (RL) remains hampered by low sample efficiency and sparse rewards in real-world settings. Developing generalizable process reward models is essential for providing the fine-grained feedback necessary to bridge this gap, yet existing temporal value functions often fail to generalize beyond their training domains. We introduce TOPReward, a novel, probabilistically grounded temporal value function that leverages the latent world knowledge of pretrained video Vision-Language Models (VLMs) to estimate robotic task progress. Unlike prior methods that prompt VLMs to directly output progress values, which are prone to numerical misrepresentation, TOPReward extracts task progress directly from the VLM's internal token logits. In zero-shot evaluations across 130+ distinct real-world tasks and multiple robot platforms (e.g., Franka, YAM, SO-100/101), TOPReward achieves 0.947 mean Value-Order Correlation (VOC) on Qwen3-VL, dramatically outperforming the state-of-the-art GVL baseline which achieves near-zero correlation on the same open-source model. We further demonstrate that TOPReward serves as a versatile tool for downstream applications, including success detection and reward-aligned behavior cloning.", "AI": {"tldr": "TOPReward利用预训练视频Vision-Language模型的内部令牌概率，估计机器人任务进度，以提高零样本环境中的强化学习效率。", "motivation": "当前VLA模型在预训练上取得了快速进展，但在真实场景下的强化学习中仍然面临低样本效率和稀疏奖励的问题。因此，需要一种能够提供细粒度反馈的通用过程奖励模型来解决这一问题。", "method": "TOPReward通过从预训练视频Vision-Language模型的内部令牌概率中直接提取任务进度信息，而不是让模型直接输出数值表示的任务进度值，从而避免了数值表示的误差。这种方法在130多个不同的真实世界任务和多种机器人平台上进行了零样本评估，并展示了其优越性。", "result": "TOPReward在Qwen3-VL模型上达到了0.947的平均价值顺序相关性，在同一开放源码模型上，超过了基线GVL的表现，后者仅达到近零的相关性。此外，该方法还被证明适用于下游应用，如成功率检测和奖励对齐的行为克隆。", "conclusion": "TOPReward提供了一种创新的方法来估计机器人任务进度，通过利用预训练视频Vision-Language模型的内部令牌概率，在零样本环境中大幅提高了强化学习的表现，并展示了在多种下游任务中的广泛应用潜力。"}}
{"id": "2602.19312", "pdf": "https://arxiv.org/pdf/2602.19312", "abs": "https://arxiv.org/abs/2602.19312", "authors": ["Kyriakos Stylianopoulos", "Mario Edoardo Pandolfo", "Paolo Di Lorenzo", "George C. Alexandropoulos"], "title": "Metasurfaces-Integrated Wireless Neural Networks for Lightweight Over-The-Air Edge Inference", "categories": ["cs.ET", "cs.LG", "eess.SP"], "comment": "9 pages, 6 figures, submitted for magazine publication", "summary": "The upcoming sixth Generation (6G) of wireless networks envisions ultra-low latency and energy efficient Edge Inference (EI) for diverse Internet of Things (IoT) applications. However, traditional digital hardware for machine learning is power intensive, motivating the need for alternative computation paradigms. Over-The-Air (OTA) computation is regarded as an emerging transformative approach assigning the wireless channel to actively perform computational tasks. This article introduces the concept of Metasurfaces-Integrated Neural Networks (MINNs), a physical-layer-enabled deep learning framework that leverages programmable multi-layer metasurface structures and Multiple-Input Multiple-Output (MIMO) channels to realize computational layers in the wave propagation domain. The MINN system is conceptualized as three modules: Encoder, Channel (uncontrollable propagation features and metasurfaces), and Decoder. The first and last modules, realized respectively at the multi-antenna transmitter and receiver, consist of conventional digital or purposely designed analog Deep Neural Network (DNN) layers, and the metasurfaces responses of the Channel module are optimized alongside all modules as trainable weights. This architecture enables computation offloading into the end-to-end physical layer, flexibly among its constituent modules, achieving performance comparable to fully digital DNNs while significantly reducing power consumption. The training of the MINN framework, two representative variations, and performance results for indicative applications are presented, highlighting the potential of MINNs as a lightweight and sustainable solution for future EI-enabled wireless systems. The article is concluded with a list of open challenges and promising research directions.", "AI": {"tldr": "介绍了一种基于可编程多层超表面和MIMO信道的物理层深度学习框架，用于实现无线边缘推理。", "motivation": "传统的数字硬件对于机器学习来说能耗高，因此需要替代计算范式。引入了物理层驱动的深度学习框架，以减少功耗并提高边缘推断效率。", "method": "提出了一种基于超表面集成神经网络（MINN）的概念，包括编码器、信道模块和解码器三部分，并通过优化各个模块实现计算任务。", "result": "展示了所提架构的训练过程以及两种代表性变体的表现结果，证明了其在性能上与全数字深度神经网络相当的同时显著减少了功耗。", "conclusion": "介绍了MINN作为轻量级和可持续解决方案在未来边缘推理支持无线系统中的潜力，并提出了一些开放性挑战及研究方向。"}}
{"id": "2602.19308", "pdf": "https://arxiv.org/pdf/2602.19308", "abs": "https://arxiv.org/abs/2602.19308", "authors": ["Hardik Shah", "Erica Tevere", "Deegan Atha", "Marcel Kaufmann", "Shehryar Khattak", "Manthan Patel", "Marco Hutter", "Jonas Frey", "Patrick Spieler"], "title": "WildOS: Open-Vocabulary Object Search in the Wild", "categories": ["cs.RO", "cs.CV"], "comment": "28 pages, 16 figures, 2 tables", "summary": "Autonomous navigation in complex, unstructured outdoor environments requires robots to operate over long ranges without prior maps and limited depth sensing. In such settings, relying solely on geometric frontiers for exploration is often insufficient. In such settings, the ability to reason semantically about where to go and what is safe to traverse is crucial for robust, efficient exploration. This work presents WildOS, a unified system for long-range, open-vocabulary object search that combines safe geometric exploration with semantic visual reasoning. WildOS builds a sparse navigation graph to maintain spatial memory, while utilizing a foundation-model-based vision module, ExploRFM, to score frontier nodes of the graph. ExploRFM simultaneously predicts traversability, visual frontiers, and object similarity in image space, enabling real-time, onboard semantic navigation tasks. The resulting vision-scored graph enables the robot to explore semantically meaningful directions while ensuring geometric safety. Furthermore, we introduce a particle-filter-based method for coarse localization of the open-vocabulary target query, that estimates candidate goal positions beyond the robot's immediate depth horizon, enabling effective planning toward distant goals. Extensive closed-loop field experiments across diverse off-road and urban terrains demonstrate that WildOS enables robust navigation, significantly outperforming purely geometric and purely vision-based baselines in both efficiency and autonomy. Our results highlight the potential of vision foundation models to drive open-world robotic behaviors that are both semantically informed and geometrically grounded. Project Page: https://leggedrobotics.github.io/wildos/", "AI": {"tldr": "WildOS是一种结合了几何安全探索和语义视觉推理的长期范围开放词汇物体搜索系统。", "motivation": "在复杂未结构化的户外环境中，仅依赖几何前沿进行探索是不够的。需要一个能够对去哪里以及什么是可以安全穿越的地方进行语义理解的系统来实现稳健高效的探索。", "method": "WildOS利用稀疏导航图维护空间记忆，并使用基于基础模型的视觉模块ExploRFM为图中的各个节点打分，同时预测可通行性、视觉前沿和图像空间中物体相似度。此外还引入了一种粒子滤波方法进行粗略定位。", "result": "野外实验表明WildOS在效率和自主性方面均显著优于纯几何或纯视觉基线系统。", "conclusion": "研究表明，基于视觉基础模型的方法能够驱动既具有语义信息又具备几何基础的开放世界机器人行为。"}}
{"id": "2602.19304", "pdf": "https://arxiv.org/pdf/2602.19304", "abs": "https://arxiv.org/abs/2602.19304", "authors": ["Haojun Shi", "Suyu Ye", "Katherine M. Guerrerio", "Jianzhi Shen", "Yifan Yin", "Daniel Khashabi", "Chien-Ming Huang", "Tianmin Shu"], "title": "Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.MA"], "comment": null, "summary": "Successful cooperation among decentralized agents requires each agent to quickly adapt its plan to the behavior of other agents. In scenarios where agents cannot confidently predict one another's intentions and plans, language communication can be crucial for ensuring safety. In this work, we focus on path-level cooperation in which agents must adapt their paths to one another in order to avoid collisions or perform physical collaboration such as joint carrying. In particular, we propose a safe and interpretable multimodal path planning method, CaPE (Code as Path Editor), which generates and updates path plans for an agent based on the environment and language communication from other agents. CaPE leverages a vision-language model (VLM) to synthesize a path editing program verified by a model-based planner, grounding communication to path plan updates in a safe and interpretable way. We evaluate our approach in diverse simulated and real-world scenarios, including multi-robot and human-robot cooperation in autonomous driving, household, and joint carrying tasks. Experimental results demonstrate that CaPE can be integrated into different robotic systems as a plug-and-play module, greatly enhancing a robot's ability to align its plan to language communication from other robots or humans. We also show that the combination of the VLM-based path editing program synthesis and model-based planning safety enables robots to achieve open-ended cooperation while maintaining safety and interpretability.", "AI": {"tldr": "提出了一种安全且可解释的多模态路径规划方法CaPE，以促进代理之间的路径级合作。", "motivation": "在不确定其他代理意图和计划的情况下，语言通信对于确保安全性至关重要。通过这种方式增强机器人与机器人或人类之间的协作能力。", "method": "利用视觉-语言模型（VLM）合成经过基于模型的规划器验证的路径编辑程序，从而实现安全且可解释的合作。", "result": "实验结果表明，在不同的模拟和真实场景中，CaPE能显著提升机器人的合作能力和安全性。", "conclusion": "展示了如何将VLM与模型规划结合，以使机器人在保持安全性和可解释性的同时实现开放式的多代理协作。"}}
{"id": "2602.19303", "pdf": "https://arxiv.org/pdf/2602.19303", "abs": "https://arxiv.org/abs/2602.19303", "authors": ["Kirk Vanacore", "Ryan S. Baker", "Avery H. Closser", "Jeremy Roschelle"], "title": "The Path to Conversational AI Tutors: Integrating Tutoring Best Practices and Targeted Technologies to Produce Scalable AI Agents", "categories": ["cs.HC"], "comment": null, "summary": "The emergence of generative AI has accelerated the development of conversational tutoring systems that interact with students through natural language dialogue. Unlike prior intelligent tutoring systems (ITS), which largely function as adaptive and interactive problem sets with feedback and hints, conversational tutors hold the potential to simulate high-quality human tutoring by engaging with students' thoughts, questions, and misconceptions in real time. While some previous ITS, such as AutoTutor, could respond conversationally, they were expensive to author and lacked a full range of conversational ability. Generative AI has changed the capacity of ITS to engage conversationally. However, realizing the full potential of conversational tutors requires careful consideration of what research on human tutoring and ITS has already established, while also unpacking what new research will be needed. This paper synthesizes tenets of successful human tutoring, lessons learned from legacy ITS, and emerging work on conversational AI tutors. We use a keep, change, center, study framework for guiding the design of conversational tutoring. We argue that systems should keep proven methods from prior ITS, such as knowledge tracing and affect detection; change how tutoring is delivered by leveraging generative AI for dynamic content generation and dialogic scaffolding; and center opportunities for meaning-making, student agency, and granular diagnosis of reasoning. Finally, we identify areas requiring further study, including efficacy testing, student experience, and integration with human instruction. By synthesizing insights from human tutoring, legacy ITS, and emerging generative AI technologies, this paper outlines a research agenda for developing conversational tutors that are scalable, pedagogically effective, and responsive to the social and motivational dimensions of learning.", "AI": {"tldr": "这篇论文探讨了如何利用生成式AI技术与既有人工智能辅导系统（ITS）的最佳实践相结合，开发出能够大规模使用的对话型人工智能导师。", "motivation": "由于生成式AI的出现，对话性教学系统的发展得以加速。这些系统可以模拟高质量的人类教学，并通过自然语言交流实时理解学生的思想、问题和误解。", "method": "作者提出了一个框架来指导对话辅导系统的开发，该框架包括保留现有ITS中的有效方法（如知识追踪和情感检测）、利用生成式AI进行动态内容生成和对话性支架以及关注意义构建机会、学生自主权和推理诊断。", "result": "论文概述了一个研究议程，旨在通过合成人类教学实践、既有智能辅导系统经验及新兴的生成式AI技术的优势来开发具有可扩展性且有效果的教学助手。", "conclusion": "文章强调了在对话型人工智能导师开发中需要进一步探索的领域包括效果测试、学生体验以及与人工指导的集成。"}}
{"id": "2602.19298", "pdf": "https://arxiv.org/pdf/2602.19298", "abs": "https://arxiv.org/abs/2602.19298", "authors": ["Nolan Brady", "Tom Yeh"], "title": "ALPACA: A Reinforcement Learning Environment for Medication Repurposing and Treatment Optimization in Alzheimer's Disease", "categories": ["cs.AI"], "comment": null, "summary": "Evaluating personalized, sequential treatment strategies for Alzheimer's disease (AD) using clinical trials is often impractical due to long disease horizons and substantial inter-patient heterogeneity. To address these constraints, we present the Alzheimer's Learning Platform for Adaptive Care Agents (ALPACA), an open-source, Gym-compatible reinforcement learning (RL) environment for systematically exploring personalized treatment strategies using existing therapies. ALPACA is powered by the Continuous Action-conditioned State Transitions (CAST) model trained on longitudinal trajectories from the Alzheimer's Disease Neuroimaging Initiative (ADNI), enabling medication-conditioned simulation of disease progression under alternative treatment decisions. We show that CAST autoregressively generates realistic medication-conditioned trajectories and that RL policies trained in ALPACA outperform no-treatment and behavior-cloned clinician baselines on memory-related outcomes. Interpretability analyses further indicated that the learned policies relied on clinically meaningful patient features when selecting actions. Overall, ALPACA provides a reusable in silico testbed for studying individualized sequential treatment decision-making for AD.", "AI": {"tldr": "本论文提出了一种用于阿兹海默病个性化治疗策略研究的增强学习环境ALPACA。", "motivation": "为了克服临床试验中评估个性化、序贯治疗方法在阿兹海默病中的挑战，如疾病时间长和患者间异质性大等问题，需要一种可重复使用的虚拟实验平台来研究个体化治疗决策。", "method": "使用Continuous Action-conditioned State Transitions (CAST)模型训练，并基于纵向轨迹数据构建了Gym兼容的增强学习环境ALPACA。该模型能根据药物条件模拟疾病进程，并利用此环境探索个性化治疗方法的效果。", "result": "结果表明，CAST可以生成现实主义的治疗路径；在ALPACA环境中训练出的策略比没有治疗或模仿医生操作的基准方法更优，在记忆相关指标上表现更好；同时解释性分析显示学习到的策略依赖于临床意义重大的患者特征来选择行动。", "conclusion": "总体而言，ALPACA提供了一个可重复使用的虚拟实验平台，用于研究阿兹海默病个体化治疗决策。"}}
{"id": "2602.19297", "pdf": "https://arxiv.org/pdf/2602.19297", "abs": "https://arxiv.org/abs/2602.19297", "authors": ["Jasper Davidson", "Skylar Stockham", "Allen Boston", "Ashton Snelgrove. Valerio Tenace", "Pierre-Emmanuel Gaillardon"], "title": "Automated Generation of Microfluidic Netlists using Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Microfluidic devices have emerged as powerful tools in various laboratory applications, but the complexity of their design limits accessibility for many practitioners. While progress has been made in microfluidic design automation (MFDA), a practical and intuitive solution is still needed to connect microfluidic practitioners with MFDA techniques. This work introduces the first practical application of large language models (LLMs) in this context, providing a preliminary demonstration. Building on prior research in hardware description language (HDL) code generation with LLMs, we propose an initial methodology to convert natural language microfluidic device specifications into system-level structural Verilog netlists. We demonstrate the feasibility of our approach by generating structural netlists for practical benchmarks representative of typical microfluidic designs with correct functional flow and an average syntactical accuracy of 88%.", "AI": {"tldr": "利用大型语言模型将自然语言的微流控设备规格转换为系统级结构Verilog网表。", "motivation": "为了提高微流控设计的可访问性，提出了一种实用的方法来连接微流控从业者与设计自动化技术。", "method": "基于硬件描述语言代码生成的研究，在此基础上提出了一个初步方法论，将自然语言描述转化为系统级别的Verilog网表。", "result": "展示了一个可行性验证示例，成功地为实际基准中的典型微流控设计生成了结构化网表，具有正确的功能流程和88%的平均语法准确性。", "conclusion": "证明了大型语言模型在微流控设计自动化领域的应用潜力。"}}
{"id": "2602.19296", "pdf": "https://arxiv.org/pdf/2602.19296", "abs": "https://arxiv.org/abs/2602.19296", "authors": ["Kirk Vanacore", "Danielle R Thomas", "Digory Smith", "Bibi Groot", "Justin Reich", "Rene Kizilcec"], "title": "A Causal Framework for Estimating Heterogeneous Effects of On-Demand Tutoring", "categories": ["cs.HC", "stat.AP"], "comment": null, "summary": "This paper introduces a scalable causal inference framework for estimating the immediate, session-level effects of on-demand human tutoring embedded within adaptive learning systems. Because students seek assistance at moments of difficulty, conventional evaluation is confounded by self-selection and time-varying knowledge states. We address these challenges by integrating principled analytic sample construction with Deep Knowledge Tracing (DKT) to estimate latent mastery, followed by doubly robust estimation using Causal Forests. Applying this framework to over 5,000 middle-school mathematics tutoring sessions, we find that requesting human tutoring increases next-problem correctness by approximately 4 percentage points and accuracy on the subsequent skill encountered by approximately 3 percentage points, suggesting that the effects of tutoring have proximal transfer across knowledge components. This effect is robust to various forms of model specification and potential unmeasured confounders. Notably, these effects exhibit significant heterogeneity across sessions and students, with session-level effect estimates ranging from $-20.25pp$ to $+19.91pp$. Our follow-up analyses suggest that typical behavioral indicators, such as student talk time, do not consistently correlate with high-impact sessions. Furthermore, treatment effects are larger for students with lower prior mastery and slightly smaller for low-SES students. This framework offers a rigorous, practical template for the evaluation and continuous improvement of on-demand human tutoring, with direct applications for emerging AI tutoring systems.", "AI": {"tldr": "介绍了一种用于评估按需辅导即时效果的因果推理框架", "motivation": "解决了学生在困难时刻寻求帮助导致的传统评估方法受到自我选择和时间变化知识状态影响的问题", "method": "通过结合原则性样本构造与深度知识追踪（DKT）来估计潜在掌握情况，然后使用双重稳健估计法中的因果森林进行分析", "result": "发现请求按需辅导可以提高下一题正确率约4个百分点，并且对随后技能的准确度也有类似提升。效果在会话间和学生间存在显著差异", "conclusion": "提出的方法为按需辅导评估和持续改进提供了严谨实用的模板，具有直接应用于新兴AI辅导系统的意义"}}
{"id": "2602.19285", "pdf": "https://arxiv.org/pdf/2602.19285", "abs": "https://arxiv.org/abs/2602.19285", "authors": ["Jindi Kong", "Yuting He", "Cong Xia", "Rongjun Ge", "Shuo Li"], "title": "MRI Contrast Enhancement Kinetics World Model", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2026", "summary": "Clinical MRI contrast acquisition suffers from inefficient information yield, which presents as a mismatch between the risky and costly acquisition protocol and the fixed and sparse acquisition sequence. Applying world models to simulate the contrast enhancement kinetics in the human body enables continuous contrast-free dynamics. However, the low temporal resolution in MRI acquisition restricts the training of world models, leading to a sparsely sampled dataset. Directly training a generative model to capture the kinetics leads to two limitations: (a) Due to the absence of data on missing time, the model tends to overfit to irrelevant features, leading to content distortion. (b) Due to the lack of continuous temporal supervision, the model fails to learn the continuous kinetics law over time, causing temporal discontinuities. For the first time, we propose MRI Contrast Enhancement Kinetics World model (MRI CEKWorld) with SpatioTemporal Consistency Learning (STCL). For (a), guided by the spatial law that patient-level structures remain consistent during enhancement, we propose Latent Alignment Learning (LAL) that constructs a patient-specific template to constrain contents to align with this template. For (b), guided by the temporal law that the kinetics follow a consistent smooth trend, we propose Latent Difference Learning (LDL) which extends the unobserved intervals by interpolation and constrains smooth variations in the latent space among interpolated sequences. Extensive experiments on two datasets show our MRI CEKWorld achieves better realistic contents and kinetics. Codes will be available at https://github.com/DD0922/MRI-Contrast-Enhancement-Kinetics-World-Model.", "AI": {"tldr": "提出了一种MRI对比增强动力学世界模型（MRI CEKWorld）及其时空一致性学习方法，以解决传统MRI采集过程中信息提取效率低的问题。", "motivation": "传统的MRI采集在时间和空间上存在不足，导致训练生成模型时数据稀疏，影响了模型的学习效果和连续性。为了提高对比增强动力学的模拟准确性，需要引入新的策略来克服这些问题。", "method": "通过构造患者特定的模板并利用隐式对齐学习（LAL）使内容与该模板对齐以减少过拟合；同时利用隐式差分学习（LDL）在潜在空间中约束插值序列间的平滑变化，从而解决连续动力学问题。", "result": "实验表明MRI CEKWorld模型可以生成更具真实感的内容并更好地模拟对比增强动力学。", "conclusion": "通过提出MRI CEKWorld及其时空一致性学习方法解决了传统MRI采集过程中存在的数据稀疏和过拟合问题，提高了对比增强动力学的模拟准确性。"}}
{"id": "2602.19281", "pdf": "https://arxiv.org/pdf/2602.19281", "abs": "https://arxiv.org/abs/2602.19281", "authors": ["Zhenyu Li", "Guanlin Wu", "Cheems Wang", "Yongqiang Zhao"], "title": "Limited Reasoning Space: The cage of long-horizon reasoning in LLMs", "categories": ["cs.AI"], "comment": null, "summary": "The test-time compute strategy, such as Chain-of-Thought (CoT), has significantly enhanced the ability of large language models to solve complex tasks like logical reasoning. However, empirical studies indicate that simply increasing the compute budget can sometimes lead to a collapse in test-time performance when employing typical task decomposition strategies such as CoT. This work hypothesizes that reasoning failures with larger compute budgets stem from static planning methods, which hardly perceive the intrinsic boundaries of LLM reasoning. We term it as the Limited Reasoning Space hypothesis and perform theoretical analysis through the lens of a non-autonomous stochastic dynamical system. This insight suggests that there is an optimal range for compute budgets; over-planning can lead to redundant feedback and may even impair reasoning capabilities. To exploit the compute-scaling benefits and suppress over-planning, this work proposes Halo, a model predictive control framework for LLM planning. Halo is designed for long-horizon tasks with reason-based planning and crafts an entropy-driven dual controller, which adopts a Measure-then-Plan strategy to achieve controllable reasoning. Experimental results demonstrate that Halo outperforms static baselines on complex long-horizon tasks by dynamically regulating planning at the reasoning boundary.", "AI": {"tldr": "该论文探讨了大型语言模型在长期推理任务中遇到的计算策略问题，并提出了一种新的框架Halo来优化这种推理。", "motivation": "通过实验观察到，增加计算预算并不总是能提高基于链式思考（CoT）等典型任务分解方法的性能。这表明静态规划方法未能识别出大型语言模型推理的实际边界。", "method": "提出了一个名为Halo的模型预测控制框架来优化LLM中的长期计划，并设计了一个采用测然后计划策略的熵驱动双控制器，以实现可调性推理。", "result": "实验结果显示，在复杂和长期的任务上，动态调节计划可以在推理边界处优于静态基线方法。", "conclusion": "该论文揭示了大型语言模型在长期任务中的计算预算优化问题，并提出了一种有效的方法来解决这个问题。"}}
{"id": "2602.19278", "pdf": "https://arxiv.org/pdf/2602.19278", "abs": "https://arxiv.org/abs/2602.19278", "authors": ["Keonvin Park", "Aditya Pal", "Jin Hong Mok"], "title": "A Two-Stage Detection-Tracking Framework for Stable Apple Quality Inspection in Dense Conveyor-Belt Environments", "categories": ["cs.CV"], "comment": null, "summary": "Industrial fruit inspection systems must operate reliably under dense multi-object interactions and continuous motion, yet most existing works evaluate detection or classification at the image level without ensuring temporal stability in video streams. We present a two-stage detection-tracking framework for stable multi-apple quality inspection in conveyor-belt environments. An orchard-trained YOLOv8 model performs apple localization, followed by ByteTrack multi-object tracking to maintain persistent identities. A ResNet18 defect classifier, fine-tuned on a healthy-defective fruit dataset, is applied to cropped apple regions. Track-level aggregation is introduced to enforce temporal consistency and reduce prediction oscillation across frames. We define video-level industrial metrics such as track-level defect ratio and temporal consistency to evaluate system robustness under realistic processing conditions. Results demonstrate improved stability compared to frame-wise inference, suggesting that integrating tracking is essential for practical automated fruit grading systems.", "AI": {"tldr": "本文提出了一种两阶段检测跟踪框架，用于密集传送带环境中稳定苹果质量检查。", "motivation": "现有的工业水果检查系统在处理视频流中的时间稳定性方面表现不佳。大多数工作仅评估图像级别的检测或分类，未确保视频流的时间一致性。", "method": "首先使用YOLOv8模型进行苹果定位，然后通过ByteTrack多目标跟踪保持持久身份，最后利用ResNet18缺陷分类器对剪裁的苹果区域进行分类，并引入轨迹级聚合以增强时间一致性并减少帧间预测波动。定义了视频级别的工业指标来评估系统在实际处理条件下的鲁棒性。", "result": "实验结果表明，在密集传送带环境中，两阶段检测跟踪框架相比于单帧推理提高了系统的稳定性。", "conclusion": "将跟踪集成到自动化水果分级系统中对于提高其实用性和准确性是至关重要的。"}}
{"id": "2602.19274", "pdf": "https://arxiv.org/pdf/2602.19274", "abs": "https://arxiv.org/abs/2602.19274", "authors": ["Krishna Khadka", "Yu Lei", "Raghu N. Kacker", "D. Richard Kuhn"], "title": "DD-CAM: Minimal Sufficient Explanations for Vision Models Using Delta Debugging", "categories": ["cs.CV", "cs.SE"], "comment": null, "summary": "We introduce a gradient-free framework for identifying minimal, sufficient, and decision-preserving explanations in vision models by isolating the smallest subset of representational units whose joint activation preserves predictions. Unlike existing approaches that aggregate all units, often leading to cluttered saliency maps, our approach, DD-CAM, identifies a 1-minimal subset whose joint activation suffices to preserve the prediction (i.e., removing any unit from the subset alters the prediction). To efficiently isolate minimal sufficient subsets, we adapt delta debugging, a systematic reduction strategy from software debugging, and configure its search strategy based on unit interactions in the classifier head: testing individual units for models with non-interacting units and testing unit combinations for models in which unit interactions exist. We then generate minimal, prediction-preserving saliency maps that highlight only the most essential features. Our experimental evaluation demonstrates that our approach can produce more faithful explanations and achieve higher localization accuracy than the state-of-the-art CAM-based approaches.", "AI": {"tldr": "提出了一种使用delta调试来识别视觉模型中最小、足够的决策保持解释的框架DD-CAM。", "motivation": "现有的方法通常通过聚合所有表示单元生成解释，导致混乱的热图。为了减少这些冗余并准确地找到预测的关键要素，本文提出了一个基于delta调试的方法来找出最简化的必要解释。", "method": "利用delta调试这一从软件调试中借来的系统化缩减策略来有效地识别最小、足够的子集，并生成仅突出显示最关键特征的局部热图。", "result": "实验结果显示所提出方法能够产生更忠实的解释，同时在定位准确度上超过现有的CAM基线方法。", "conclusion": "DD-CAM通过运用delta调试实现了视觉模型中预测关键要素的有效识别，并提供了更清晰、更有意义的解释。"}}
{"id": "2602.19273", "pdf": "https://arxiv.org/pdf/2602.19273", "abs": "https://arxiv.org/abs/2602.19273", "authors": ["Abhinav Gandhi", "Shou-Shan Chiang", "Cagdas D. Onal", "Berk Calli"], "title": "3D Shape Control of Extensible Multi-Section Soft Continuum Robots via Visual Servoing", "categories": ["cs.RO"], "comment": null, "summary": "In this paper, we propose a novel vision-based control algorithm for regulating the whole body shape of extensible multisection soft continuum manipulators. Contrary to existing vision-based control algorithms in the literature that regulate the robot's end effector pose, our proposed control algorithm regulates the robot's whole body configuration, enabling us to leverage its kinematic redundancy. Additionally, our model-based 2.5D shape visual servoing provides globally stable asymptotic convergence in the robot's 3D workspace compared to the closest works in the literature that report local minima. Unlike existing visual servoing algorithms in the literature, our approach does not require information from proprioceptive sensors, making it suitable for continuum manipulators without such capabilities. Instead, robot state is estimated from images acquired by an external camera that observes the robot's whole body shape and is also utilized to close the shape control loop. Traditionally, visual servoing schemes require an image of the robot at its reference pose to generate the reference features. In this work, we utilize an inverse kinematics solver to generate reference features for the desired robot configuration and do not require images of the robot at the reference. Experiments are performed on a multisection continuum manipulator demonstrating the controller's capability to regulate the robot's whole body shape while precisely positioning the robot's end effector. Results validate our controller's ability to regulate the shape of continuum robots while demonstrating a smooth transient response and a steady-state error within 1 mm. Proof-of-concept object manipulation experiments including stacking, pouring, and pulling tasks are performed to demonstrate our controller's applicability.", "AI": {"tldr": "提出了一种基于视觉的控制算法，用于调节可伸缩多节软连续机器人的整体形状。", "motivation": "现有文献中的视觉伺服算法主要调控机器人末端执行器的姿态而非其整体结构。本研究旨在通过利用该机器人的运动冗余性来解决这一问题，并实现全局稳定的渐近收敛。", "method": "采用2.5D模型基于视觉的形体伺服控制，从外部摄像机获取的信息中估计机器人的状态并关闭形状控制环路。无需参考姿态图像即可生成目标特征。", "result": "实验表明控制器能够精确调节机器人整体形状的同时使末端执行器准确定位，并展示平滑瞬态响应和稳态误差在1毫米以内。", "conclusion": "通过视觉伺服控制算法，成功地展示了对于可伸缩多节软连续机器人的形体调控能力。"}}
{"id": "2602.19271", "pdf": "https://arxiv.org/pdf/2602.19271", "abs": "https://arxiv.org/abs/2602.19271", "authors": ["Junkang Liu", "Fanhua Shang", "Hongying Liu", "Jin Liu", "Weixin An", "Yuanyuan Liu"], "title": "Taming Preconditioner Drift: Unlocking the Potential of Second-Order Optimizers for Federated Learning on Non-IID Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Second-order optimizers can significantly accelerate large-scale training, yet their naive federated variants are often unstable or even diverge on non-IID data. We show that a key culprit is \\emph{preconditioner drift}: client-side second-order training induces heterogeneous \\emph{curvature-defined geometries} (i.e., preconditioner coordinate systems), and server-side model averaging updates computed under incompatible metrics, corrupting the global descent direction. To address this geometric mismatch, we propose \\texttt{FedPAC}, a \\emph{preconditioner alignment and correction} framework for reliable federated second-order optimization. \\texttt{FedPAC} explicitly decouples parameter aggregation from geometry synchronization by: (i) \\textbf{Alignment} (i.e.,aggregating local preconditioners into a global reference and warm-starting clients via global preconditioner); and (ii) \\textbf{Correction} (i.e., steering local preconditioned updates using a global preconditioned direction to suppress long-term drift). We provide drift-coupled non-convex convergence guarantees with linear speedup under partial participation. Empirically, \\texttt{FedPAC} consistently improves stability and accuracy across vision and language tasks, achieving up to $5.8\\%$ absolute accuracy gain on CIFAR-100 with ViTs. Code is available at https://anonymous.4open.science/r/FedPAC-8B24.", "AI": {"tldr": "提出了一种新的框架FedPAC，用于解决联邦学习中非独立同分布数据上的预处理漂移问题，从而实现更稳定和准确的训练。", "motivation": "在非独立同分布的数据上进行联邦学习时，传统的二阶优化器常常不稳定甚至发散。这是由于客户端的二阶训练会导致不同尺度的曲率定义几何体，而服务器端模型平均更新则破坏了全局下降方向。", "method": "FedPAC通过分离参数聚合与几何同步来解决预处理漂移问题。具体而言，包括两个步骤：（i）对齐，即通过全球预处理器来收集本地预处理器并启动客户端；（ii）校正，即利用一个全局预处理器方向引导局部预处理器更新以抑制长期漂移。", "result": "在视觉和语言任务上，FedPAC显著提高了稳定性和准确性，在CIFAR-100与ViTs的测试中获得了高达5.8%的绝对精度提升。", "conclusion": "该研究通过解决联邦学习中的预处理漂移问题，展示了FedPAC框架的有效性，并提供了线性加速和部分参与下的非凸收敛保证。"}}
{"id": "2602.19268", "pdf": "https://arxiv.org/pdf/2602.19268", "abs": "https://arxiv.org/abs/2602.19268", "authors": ["Sonu Kumar", "Mohd Faisal Khan", "Mukul Lokhande", "Santosh Kumar Vishvakarma"], "title": "CORVET: A CORDIC-Powered, Resource-Frugal Mixed-Precision Vector Processing Engine for High-Throughput AIoT applications", "categories": ["cs.AR", "cs.AI", "cs.CV", "cs.NE", "eess.IV"], "comment": null, "summary": "This brief presents a runtime-adaptive, performance-enhanced vector engine featuring a low-resource, iterative CORDIC-based MAC unit for edge AI acceleration. The proposed design enables dynamic reconfiguration between approximate and accurate modes, exploiting the latency-accuracy trade-off for a wide range of workloads. Its resource-efficient approach further enables up to 4x throughput improvement within the same hardware resources by leveraging vectorised, time-multiplexed execution and flexible precision scaling. With a time-multiplexed multi-AF block and a lightweight pooling and normalisation unit, the proposed vector engine supports flexible precision (4/8/16-bit) and high MAC density. The ASIC implementation results show that each MAC stage can save up to 33% of time and 21% of power, with a 256-PE configuration that achieves higher compute density (4.83 TOPS/mm2 ) and energy efficiency (11.67 TOPS/W) than previous state-of-the-art work. A detailed hardware-software co-design methodology for object detection and classification tasks on Pynq-Z2 is discussed to assess the proposed architecture, demonstrating a scalable, energy-efficient solution for edge AI applications.", "AI": {"tldr": "本文提出了一种基于CORDIC的低资源、迭代型MAC单元，用于边缘AI加速的动态可重构矢量引擎。", "motivation": "动机在于开发一种能够根据时延和精度进行权衡以适应各种工作负载，并在相同硬件资源下通过向量化时间复用执行和灵活精度缩放实现高达4倍吞吐量提升的高效计算架构。", "method": "提出了一种采用CORDIC算法的低资源MAC单元，支持动态重新配置到近似或准确模式。该设计还利用了时间多路复用的多个AF块以及轻量级池化和归一化单元，以实现灵活精度(4/8/16位)及高MAC密度。", "result": "ASIC实验证明每个MAC阶段可节省多达33%的时间和21%的能量。在256-PE配置下,计算密度高达4.83 TOPS/mm²，能效为11.67 TOPS/W，比现有最佳技术高出许多。", "conclusion": "该论文展示了CORVET架构的详细硬件软件协同设计方法，并通过Pynq-Z2平台上的对象检测和分类任务评估了其性能，证明了它是一种可扩展、节能的边缘AI解决方案。"}}
{"id": "2602.19261", "pdf": "https://arxiv.org/pdf/2602.19261", "abs": "https://arxiv.org/abs/2602.19261", "authors": ["Aleksei Liuliakov", "Luca Hermes", "Barbara Hammer"], "title": "DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "Submitted to IJCNN 2026 (IEEE WCCI). 6 pages, 4 figures", "summary": "Reinforcement learning fine-tuning has proven effective for steering generative diffusion models toward desired properties in image and molecular domains. Graph diffusion models have similarly been applied to combinatorial structure generation, including neural architecture search (NAS). However, neural architectures are directed acyclic graphs (DAGs) where edge direction encodes functional semantics such as data flow-information that existing graph diffusion methods, designed for undirected structures, discard. We propose Directed Graph Policy Optimization (DGPO), which extends reinforcement learning fine-tuning of discrete graph diffusion models to DAGs via topological node ordering and positional encoding. Validated on NAS-Bench-101 and NAS-Bench-201, DGPO matches the benchmark optimum on all three NAS-Bench-201 tasks (91.61%, 73.49%, 46.77%). The central finding is that the model learns transferable structural priors: pretrained on only 7% of the search space, it generates near-oracle architectures after fine-tuning, within 0.32 percentage points of the full-data model and extrapolating 7.3 percentage points beyond its training ceiling. Bidirectional control experiments confirm genuine reward-driven steering, with inverse optimization reaching near random-chance accuracy (9.5%). These results demonstrate that reinforcement learning-steered discrete diffusion, once extended to handle directionality, provides a controllable generative framework for directed combinatorial structures.", "AI": {"tldr": "提出了用于神经架构搜索的定向图策略优化（DGPO）方法，通过强化学习引导离散图扩散模型处理有向无环图。", "motivation": "现有的图形扩散方法在处理包含数据流功能语义信息的有向无环图时存在缺陷。因此需要一种新的方法来保留这种方向性信息并提高搜索效率和准确性。", "method": "提出了DGPO，通过拓扑节点排序和位置编码将强化学习微调应用于离散图扩散模型以处理DAG结构，并验证了该方法在NAS-Bench-101和NAS-Bench-201上的性能。", "result": "DGPO在所有三个NAS-Bench-201任务中达到了91.61％，73.49％和46.77％的准确性。此外，在仅使用搜索空间7%的数据进行预训练后，通过微调可以生成接近最优结构。", "conclusion": "研究表明，将强化学习引导离散扩散扩展至处理方向性信息，为有向组合结构提供了一个可控的生成框架，并且显示出在神经架构搜索中的优越性能。"}}
{"id": "2602.19260", "pdf": "https://arxiv.org/pdf/2602.19260", "abs": "https://arxiv.org/abs/2602.19260", "authors": ["Timothy Duggan", "Pierrick Lorang", "Hong Lu", "Matthias Scheutz"], "title": "The Price Is Not Right: Neuro-Symbolic Methods Outperform VLAs on Structured Long-Horizon Manipulation Tasks with Significantly Lower Energy Consumption", "categories": ["cs.RO"], "comment": "Accepted at the 2026 IEEE International Conference on Robotics & Automation (ICRA 2026)", "summary": "Vision-Language-Action (VLA) models have recently been proposed as a pathway toward generalist robotic policies capable of interpreting natural language and visual inputs to generate manipulation actions. However, their effectiveness and efficiency on structured, long-horizon manipulation tasks remain unclear. In this work, we present a head-to-head empirical comparison between a fine-tuned open-weight VLA model π0 and a neuro-symbolic architecture that combines PDDL-based symbolic planning with learned low-level control. We evaluate both approaches on structured variants of the Towers of Hanoi manipulation task in simulation while measuring both task performance and energy consumption during training and execution. On the 3-block task, the neuro-symbolic model achieves 95% success compared to 34% for the best-performing VLA. The neuro-symbolic model also generalizes to an unseen 4-block variant (78% success), whereas both VLAs fail to complete the task. During training, VLA fine-tuning consumes nearly two orders of magnitude more energy than the neuro-symbolic approach. These results highlight important trade-offs between end-to-end foundation-model approaches and structured reasoning architectures for long-horizon robotic manipulation, emphasizing the role of explicit symbolic structure in improving reliability, data efficiency, and energy efficiency. Code and models are available at https://price-is-not-right.github.io", "AI": {"tldr": "本文对比了VLA模型和神经符号架构在长周期操控任务中的表现，发现神经符号方法在成功率、泛化能力和能源消耗上均优于VLA。", "motivation": "目前对于视觉语言动作（VLA）模型在结构化的长周期操作任务上的有效性和效率还不明确。本文旨在探究这两种方法在这类任务上的优劣，并强调显式符号结构的重要性。", "method": "研究将经过微调的开放权重VLA模型与结合PDDL符号规划和学习低级控制的神经符号架构进行了对比实验，评估了它们在模拟环境中塔状汉诺塔（Towers of Hanoi）任务上的表现和能耗情况。", "result": "在三个盘子的任务中，神经符号模型的成功率为95%，而VLA模型只有34%。当面对未见过的四个盘子变体时，神经符号模型保持了78%的成功率，但VLA模型则完全失败。此外，在训练期间，VLA微调消耗的能量比神经符号方法高出近两个数量级。", "conclusion": "实验结果表明，对于长周期机器人操作任务而言，端到端基础模型和结构化推理架构之间存在重要的权衡，显式符号结构能够提升可靠性、数据效率及能源效率。"}}
{"id": "2602.19259", "pdf": "https://arxiv.org/pdf/2602.19259", "abs": "https://arxiv.org/abs/2602.19259", "authors": ["Sajjad Hashemian"], "title": "Quantum Sketches, Hashing, and Approximate Nearest Neighbors", "categories": ["quant-ph", "cs.DS"], "comment": "8 pages, 1 figure, submitted to journal of Information and Computation", "summary": "Motivated by Johnson--Lindenstrauss dimension reduction, amplitude encoding, and the view of measurements as hash-like primitives, one might hope to compress an $n$-point approximate nearest neighbor (ANN) data structure into $O(\\log n)$ qubits. We rule out this possibility in a broad quantum sketch model, the dataset $P$ is encoded as an $m$-qubit state $ρ_P$, and each query is answered by an arbitrary query-dependent measurement on a fresh copy of $ρ_P$. For every approximation factor $c\\ge 1$ and constant success probability $p>1/2$, we exhibit $n$-point instances in Hamming space $\\{0,1\\}^d$ with $d=Θ(\\log n)$ for which any such sketch requires $m=Ω(n)$ qubits, via a reduction to quantum random access codes and Nayak's lower bound. These memory lower bounds coexist with potential quantum query-time gains and in candidate-scanning abstractions of hashing-based ANN, amplitude amplification yields a quadratic reduction in candidate checks, which is essentially optimal by Grover/BBBV-type bounds.", "AI": {"tldr": "论文探讨了量子压缩近似最近邻（ANN）数据结构的可能性，提出了一个量子草图模型，并证明在哈密顿空间中需要Ω(n)个量子比特。", "motivation": "受到Johnson-Lindenstrauss降维、振幅编码和测量作为散列原始技术的启发，希望将n点近似最近邻（ANN）数据结构压缩至O(log n)量子比特。然而，这种可能性被在广泛量子草图模型中的研究排除。", "method": "通过将数据集P编码为m个量子比特状态ρ_P，并且每个查询由对新鲜副本的任意查询依赖测量来回答。利用量子随机访问码和Nayak下界，展示了对于每一个近似因子c≥1和大于1/2的成功概率p，在哈密顿空间{0,1}^d中存在n点实例需要m=Ω(n)个量子比特。", "result": "在候选扫描抽象的散列基础上ANN，振幅放大实现了候选检查次数上的二次减少。这是Grover/BBBV类型下界的本质最优解。", "conclusion": "论文揭示了压缩近似最近邻数据结构到O(log n)量子比特的局限性，在哈密顿空间中需要Ω(n)个量子比特；同时在查询时间上存在潜在的优势，振幅放大可以实现候选检查上的二次减少。"}}
{"id": "2602.19254", "pdf": "https://arxiv.org/pdf/2602.19254", "abs": "https://arxiv.org/abs/2602.19254", "authors": ["Bowen Chen", "Jake Zuena", "Alan C. Bovik", "Divya Kothandaraman"], "title": "RegionRoute: Regional Style Transfer with Diffusion Model", "categories": ["cs.CV"], "comment": null, "summary": "Precise spatial control in diffusion-based style transfer remains challenging. This challenge arises because diffusion models treat style as a global feature and lack explicit spatial grounding of style representations, making it difficult to restrict style application to specific objects or regions. To our knowledge, existing diffusion models are unable to perform true localized style transfer, typically relying on handcrafted masks or multi-stage post-processing that introduce boundary artifacts and limit generalization. To address this, we propose an attention-supervised diffusion framework that explicitly teaches the model where to apply a given style by aligning the attention scores of style tokens with object masks during training. Two complementary objectives, a Focus loss based on KL divergence and a Cover loss using binary cross-entropy, jointly encourage accurate localization and dense coverage. A modular LoRA-MoE design further enables efficient and scalable multi-style adaptation. To evaluate localized stylization, we introduce the Regional Style Editing Score, which measures Regional Style Matching through CLIP-based similarity within the target region and Identity Preservation via masked LPIPS and pixel-level consistency on unedited areas. Experiments show that our method achieves mask-free, single-object style transfer at inference, producing regionally accurate and visually coherent results that outperform existing diffusion-based editing approaches.", "AI": {"tldr": "提出了RegionRoute框架，通过注意力监督的扩散模型实现精确的空间控制风格迁移。", "motivation": "现有的扩散模型无法进行真正的局部风格转移，通常依赖手工制作的掩码或多阶段后处理，这会引入边界伪影并限制泛化能力。", "method": "提出了一种基于注意力监督的扩散框架，在训练过程中通过将风格令牌的关注度与对象掩码对齐来明确教学模型应用给定样式的位置。使用两种互补的目标函数：Focus损失（KL散度）和Cover损失（二元交叉熵），以促进准确的定位和密集覆盖。", "result": "实验表明，该方法能够在推理时实现无掩码、单对象风格迁移，并产生区域精确且视觉一致的结果，优于现有的基于扩散模型的编辑方法。", "conclusion": "RegionRoute框架能够有效地解决局部风格转移中的挑战，通过引入注意力监督和多目标学习策略来提高风格迁移的质量。"}}
{"id": "2602.19253", "pdf": "https://arxiv.org/pdf/2602.19253", "abs": "https://arxiv.org/abs/2602.19253", "authors": ["Qusai Khaled", "Uzay Kaymak", "Laura Genga"], "title": "Alternating Bi-Objective Optimization for Explainable Neuro-Fuzzy Systems", "categories": ["cs.LG", "cs.NE"], "comment": "Accepted at IEEE Conference on Artificial Intelligence 2026 (IEEE CAI 2026)", "summary": "Fuzzy systems show strong potential in explainable AI due to their rule-based architecture and linguistic variables. Existing approaches navigate the accuracy-explainability trade-off either through evolutionary multi-objective optimization (MOO), which is computationally expensive, or gradient-based scalarization, which cannot recover non-convex Pareto regions. We propose X-ANFIS, an alternating bi-objective gradient-based optimization scheme for explainable adaptive neuro-fuzzy inference systems. Cauchy membership functions are used for stable training under semantically controlled initializations, and a differentiable explainability objective is introduced and decoupled from the performance objective through alternating gradient passes. Validated in approximately 5,000 experiments on nine UCI regression datasets, X-ANFIS consistently achieves target distinguishability while maintaining competitive predictive accuracy, recovering solutions beyond the convex hull of the MOO Pareto front.", "AI": {"tldr": "提出了一种交替双目标梯度优化方案X-ANFIS，用于可解释性自适应神经模糊推理系统。", "motivation": "现有方法在精度和可解释性的权衡上存在问题，进化多目标优化计算昂贵且难以恢复非凸帕累托区域，而基于梯度的方法无法处理这种情况。提出了一种新方案以解决这些问题。", "method": "使用柯西隶属函数进行稳定训练，在语义控制初始化下引入并解耦可解释性目标通过交替梯度传递实现。", "result": "在九个UCI回归数据集上进行了大约5000次实验，X-ANFIS能够保持预测准确性同时达到目标区分性，并恢复了多目标优化帕累托前沿外部的解决方案。", "conclusion": "所提出的交替双目标梯度方案能够在可解释性和精度之间找到更好的平衡点，为解决模糊系统中的权衡问题提供了新的方向。"}}
{"id": "2602.19248", "pdf": "https://arxiv.org/pdf/2602.19248", "abs": "https://arxiv.org/abs/2602.19248", "authors": ["Zunkai Dai", "Ke Li", "Jiajia Liu", "Jie Yang", "Yuanyuan Qiao"], "title": "No Need For Real Anomaly: MLLM Empowered Zero-Shot Video Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR 2026", "summary": "The collection and detection of video anomaly data has long been a challenging problem due to its rare occurrence and spatio-temporal scarcity. Existing video anomaly detection (VAD) methods under perform in open-world scenarios. Key contributing factors include limited dataset diversity, and inadequate understanding of context-dependent anomalous semantics. To address these issues, i) we propose LAVIDA, an end-to-end zero-shot video anomaly detection framework. ii) LAVIDA employs an Anomaly Exposure Sampler that transforms segmented objects into pseudo-anomalies to enhance model adaptability to unseen anomaly categories. It further integrates a Multimodal Large Language Model (MLLM) to bolster semantic comprehension capabilities. Additionally, iii) we design a token compression approach based on reverse attention to handle the spatio-temporal scarcity of anomalous patterns and decrease computational cost. The training process is conducted solely on pseudo anomalies without any VAD data. Evaluations across four benchmark VAD datasets demonstrate that LAVIDA achieves SOTA performance in both frame-level and pixel-level anomaly detection under the zero-shot setting. Our code is available in https://github.com/VitaminCreed/LAVIDA.", "AI": {"tldr": "本文提出了一种零样本视频异常检测框架LAVIDA，通过生成伪异常数据和多模态大型语言模型提升模型对未知异常类别的适应性。", "motivation": "现有的视频异常检测方法在开放世界场景中表现不佳，主要原因包括数据集多样性不足以及缺乏上下文依赖的异常语义理解能力。为此，本文旨在提出一种能有效应对这些挑战的方法。", "method": "LAVIDA框架采用了一个伪异常生成器将分割的对象转换为伪异常来增强模型适应未知类别异常的能力，并结合多模态大型语言模型以提升语义理解能力；同时设计了基于逆向注意力的token压缩方法处理时空稀缺性问题并降低计算成本。", "result": "在四个基准数据集上的评估显示，LAVIDA框架在零样本设置下的帧级和像素级异常检测中达到了最新水平。", "conclusion": "本文提出的LAVIDA框架通过生成伪异常及多模态大型语言模型的应用，在零样本视频异常检测任务上取得了显著的性能提升。"}}
{"id": "2602.19244", "pdf": "https://arxiv.org/pdf/2602.19244", "abs": "https://arxiv.org/abs/2602.19244", "authors": ["Toshihide Ubukata", "Zhiyao Wang", "Enhong Mu", "Jialong Li", "Kenji Tei"], "title": "Robust Exploration in Directed Controller Synthesis via Reinforcement Learning with Soft Mixture-of-Experts", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "On-the-fly Directed Controller Synthesis (OTF-DCS) mitigates state-space explosion by incrementally exploring the system and relies critically on an exploration policy to guide search efficiently. Recent reinforcement learning (RL) approaches learn such policies and achieve promising zero-shot generalization from small training instances to larger unseen ones. However, a fundamental limitation is anisotropic generalization, where an RL policy exhibits strong performance only in a specific region of the domain-parameter space while remaining fragile elsewhere due to training stochasticity and trajectory-dependent bias. To address this, we propose a Soft Mixture-of-Experts framework that combines multiple RL experts via a prior-confidence gating mechanism and treats these anisotropic behaviors as complementary specializations. The evaluation on the Air Traffic benchmark shows that Soft-MoE substantially expands the solvable parameter space and improves robustness compared to any single expert.", "AI": {"tldr": "提出了一种Soft Mixture-of-Experts框架，以增强基于强化学习的在线控制合成器探索策略的鲁棒性和泛化能力。", "motivation": "解决现有RL方法在特定参数空间外性能不稳定的问题，提升控制器合成任务中的探索效率和稳健性。", "method": "通过一个带有先验置信度门控机制的混合专家框架组合多个RL模型来实现更加全面的行为覆盖和策略优化。", "result": "实验表明该方法显著扩大了可解参数空间，并提升了鲁棒性能优于单一专家的表现。", "conclusion": "所提出的Soft Mixture-of-Experts方法成功地提高了控制合成任务中探索策略的有效性和稳健性，为解决复杂系统的高效搜索提供了新的思路。"}}
{"id": "2602.19243", "pdf": "https://arxiv.org/pdf/2602.19243", "abs": "https://arxiv.org/abs/2602.19243", "authors": ["Jiasheng Li", "Zining Zhang", "Zeyu Yan", "Matthew Wong", "Arnav Mittal", "Ge Gao", "Huaishu Peng"], "title": "As Content and Layout Co-Evolve: TangibleSite for Scaffolding Blind People's Webpage Design through Multimodal Interaction", "categories": ["cs.HC"], "comment": null, "summary": "Creating webpages requires generating content and arranging layout while iteratively refining both to achieve a coherent design, a process that can be challenging for blind individuals. To understand how blind designers navigate this process, we conducted two rounds of co-design sessions with blind participants, using design probes to elicit their strategies and support needs. Our findings reveal a preference for content and layout to co-evolve, but this process requires external support through cues that situate local elements within the broader page structure as well as multimodal interactions. Building on these insights, we developed TangibleSite, an accessible web design tool that provides real-time multimodal feedback through tangible, auditory, and speech-based interactions. TangibleSite enables blind individuals to create, edit, and reposition webpage elements while integrating content and layout decisions. A formative evaluation with six blind participants demonstrated that TangibleSite enabled independent webpage creation, supported refinement across content and layout, and reduced barriers to achieving visually consistent designs.", "AI": {"tldr": "该论文开发了一种名为TangibleSite的可访问网页设计工具，旨在通过多模式互动支持盲人设计者独立创建和编辑网页。", "motivation": "创造网页需要生成内容并调整布局，在此过程中盲人设计师面临挑战。研究团队通过多次共设计会话发现，盲人设计师偏好于内容和布局的同时演化，并且这种过程需要外部支持。", "method": "研究人员进行了两轮的共设计会议，利用设计探针来激发盲人的策略和支持需求。基于这些洞察力开发了TangibleSite工具，该工具提供实时多模式反馈，包括触觉、声音及语音互动。", "result": "一个初步评估显示，TangibleSite使盲人能够独立创建网页并支持内容和布局的优化，并减少了达成视觉一致设计的障碍。", "conclusion": "此研究展示了如何通过开发辅助工具帮助盲人设计师克服挑战，实现独立的网页设计能力。"}}
{"id": "2602.19241", "pdf": "https://arxiv.org/pdf/2602.19241", "abs": "https://arxiv.org/abs/2602.19241", "authors": ["Dechen Zhang", "Xuan Tang", "Yingyu Liang", "Difan Zou"], "title": "Scaling Laws for Precision in High-Dimensional Linear Regression", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Low-precision training is critical for optimizing the trade-off between model quality and training costs, necessitating the joint allocation of model size, dataset size, and numerical precision. While empirical scaling laws suggest that quantization impacts effective model and data capacities or acts as an additive error, the theoretical mechanisms governing these effects remain largely unexplored. In this work, we initiate a theoretical study of scaling laws for low-precision training within a high-dimensional sketched linear regression framework. By analyzing multiplicative (signal-dependent) and additive (signal-independent) quantization, we identify a critical dichotomy in their scaling behaviors. Our analysis reveals that while both schemes introduce an additive error and degrade the effective data size, they exhibit distinct effects on effective model size: multiplicative quantization maintains the full-precision model size, whereas additive quantization reduces the effective model size. Numerical experiments validate our theoretical findings. By rigorously characterizing the complex interplay among model scale, dataset size, and quantization error, our work provides a principled theoretical basis for optimizing training protocols under practical hardware constraints.", "AI": {"tldr": "论文探讨了低精度训练中量化对高维线性回归模型规模和数据集大小的影响，提出了两种量化的理论分析方法。", "motivation": "在优化模型质量和训练成本的权衡时，需要联合分配模型规模、数据集规模和数值精度。虽然经验性的扩展规律表明量化影响有效模型和数据容量或作为附加误差存在，但这些效应背后的理论机制尚未充分研究。", "method": "通过分析乘法（信号依赖）和加法（信号独立）量化，在高维线性回归框架下进行理论探讨，发现这两种方案虽然引入了附加误差并降低了有效数据规模，但在模型规模上的表现不同。", "result": "理论研究表明，乘法量化保留了全精度的模型大小，而加法量化减少了有效模型大小。数值实验验证了这些理论结果。", "conclusion": "通过详细研究在实际硬件约束下的训练协议优化中模型规模、数据集大小和量化误差之间的复杂相互作用，论文提供了基于原理性的理论基础。"}}
{"id": "2602.19240", "pdf": "https://arxiv.org/pdf/2602.19240", "abs": "https://arxiv.org/abs/2602.19240", "authors": ["Sen Zhao", "Lincheng Zhou", "Yue Chen", "Ding Zou"], "title": "Topology of Reasoning: Retrieved Cell Complex-Augmented Generation for Textual Graph Question Answering", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances the reasoning ability of Large Language Models (LLMs) by dynamically integrating external knowledge, thereby mitigating hallucinations and strengthening contextual grounding for structured data such as graphs. Nevertheless, most existing RAG variants for textual graphs concentrate on low-dimensional structures -- treating nodes as entities (0-dimensional) and edges or paths as pairwise or sequential relations (1-dimensional), but overlook cycles, which are crucial for reasoning over relational loops. Such cycles often arise in questions requiring closed-loop inference about similar objects or relative positions. This limitation often results in incomplete contextual grounding and restricted reasoning capability. In this work, we propose Topology-enhanced Retrieval-Augmented Generation (TopoRAG), a novel framework for textual graph question answering that effectively captures higher-dimensional topological and relational dependencies. Specifically, TopoRAG first lifts textual graphs into cellular complexes to model multi-dimensional topological structures. Leveraging these lifted representations, a topology-aware subcomplex retrieval mechanism is proposed to extract cellular complexes relevant to the input query, providing compact and informative topological context. Finally, a multi-dimensional topological reasoning mechanism operates over these complexes to propagate relational information and guide LLMs in performing structured, logic-aware inference. Empirical evaluations demonstrate that our method consistently surpasses existing baselines across diverse textual graph tasks.", "AI": {"tldr": "提出了一种新的框架TopoRAG，用于增强大型语言模型在文本图问答中的推理能力。", "motivation": "现有Retrieval-Augmented Generation (RAG) 方法主要关注低维结构（节点和边），忽略了循环等高维度的拓扑依赖关系，导致上下文理解不充分和推理能力受限。", "method": "通过将文本图提升为细胞复形来捕捉多维拓扑结构，并提出了一种基于拓扑的认知子复形检索机制及一个多维拓扑推理机制，以增强大型语言模型的逻辑推理能力。", "result": "实验结果表明该方法在各种文本图任务中优于现有基线。", "conclusion": "TopoRAG框架能够有效捕捉高维度的拓扑和关系依赖性，增强了大型语言模型在文本图问答中的推理能力。"}}
{"id": "2602.19237", "pdf": "https://arxiv.org/pdf/2602.19237", "abs": "https://arxiv.org/abs/2602.19237", "authors": ["Amit Lal"], "title": "Evaluating SAP RPT-1 for Enterprise Business Process Prediction: In-Context Learning vs. Traditional Machine Learning on Structured SAP Data", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 5 figures, 32 references. Reproducible experiments available at Hugging Face Spaces", "summary": "Tabular foundation models aim to make machine learning accessible for enterprise data without task-specific training. This paper presents the first independent evaluation of SAP's Retrieval Pretrained Transformer (RPT-1) from a practitioner perspective. RPT-1 is a compact 64.6 MB model pretrained on 1.34 TB of structured data across 3.1 million tables. We benchmark it against tuned gradient-boosted decision trees (XGBoost, LightGBM, CatBoost) on three SAP business scenarios: demand forecasting across SD/MM/PP modules, predictive data integrity in BC/MM/QM, and financial risk classification in FI/CO/AR. Across five-fold cross-validation on datasets ranging from 2,500 to 3,200 rows, RPT-1 reaches 91-96% of tuned GBDT accuracy without any training examples. The classification gap is modest at 3.6-4.1 percentage points on AUC-ROC, though regression tasks show wider gaps of 8.9-11.1 percentage points on R-squared. An interesting finding is a crossover at roughly 75-100 context rows where RPT-1 actually outperforms XGBoost under limited data. Based on these results, we propose a practical hybrid workflow: use RPT-1 for rapid screening, then train GBDT selectively where prediction accuracy justifies the effort. All experiments are reproducible through publicly available Hugging Face Spaces.", "AI": {"tldr": "评估SAP RPT-1在企业业务流程预测中的性能，对比传统机器学习方法。", "motivation": "通过独立评估SAP的Retrieval Pretrained Transformer (RPT-1)模型，研究其在处理结构化企业数据时的效果与效率。", "method": "将SAP RPT-1与调优后的梯度提升决策树（XGBoost、LightGBM和CatBoost）进行对比测试，在需求预测、预测性数据完整性和财务风险分类三个场景下评估模型表现，采用五折交叉验证方法。", "result": "在不同任务中，RPT-1达到了91%至96%的调优GBDT准确率；在小样本情况下（大约75-100行内容），RPT-1甚至超过了XGBoost的表现。", "conclusion": "建议使用RPT-1进行快速筛选，在准确性需要更高时再选择性训练GBDT。所有实验可在Hugging Face Spaces中重现。"}}
{"id": "2602.19232", "pdf": "https://arxiv.org/pdf/2602.19232", "abs": "https://arxiv.org/abs/2602.19232", "authors": ["Han Li"], "title": "A Comparative Analysis of Peer Support in Forum-based and Chat-based Mental Health Communities: Technical-Structural-Functional Model of Social Support", "categories": ["cs.HC", "cs.CY"], "comment": "15 pages, 5 figures", "summary": "Online support communities have become vital spaces offering varied forms of support to individuals facing mental health challenges. Despite the proliferation of platforms with distinct technical structures, little is known about how these features shape support dynamics and the socio-technical mechanisms at play. This study introduces a technical-structural-functional model of social support and systematically compares communication network structures and support types in 20 forum-based and 20 chat-based mental health communities. Using supervised machine learning and social network analysis, we find that forum-based communities foster more informational and emotional support, whereas chat-based communities promote greater companionship. These patterns were partially explained by network structure: higher in-degree centralization in forums accounted for the prevalence of informational support, while decentralized reply patterns in chat groups accounted for more companionship. These findings extend the structural-functional model of support to online contexts and provide actionable guidance for designing support communities that align technical structures with users' support needs.", "AI": {"tldr": "研究通过比较论坛和聊天形式的心理健康社区中的支持动态，引入并验证了一个技术结构功能模型。", "motivation": "探讨不同技术支持结构如何影响心理健康社区内的社会支持模式及其机制。", "method": "使用监督机器学习和社会网络分析方法，对比20个论坛和20个聊天形式的社区，分析其通讯网络结构和支持类型。", "result": "发现论坛型社区提供更多信息性和情感性支持；聊天型社区促进更多陪伴。这些结果部分由网络结构解释：高入度中心化与信息支持相关联，在分散回复模式下产生更多的同伴互动。", "conclusion": "研究扩展了社会支持的结构功能模型到在线环境中，为设计符合用户需求的支持社区提供指导建议。"}}
{"id": "2602.19225", "pdf": "https://arxiv.org/pdf/2602.19225", "abs": "https://arxiv.org/abs/2602.19225", "authors": ["Yangyi Fang", "Jiaye Lin", "Xiaoliang Fu", "Cong Qin", "Haolin Shi", "Chang Liu", "Peilin Zhao"], "title": "Proximity-Based Multi-Turn Optimization: Practical Credit Assignment for LLM Agent Training", "categories": ["cs.AI"], "comment": null, "summary": "Multi-turn LLM agents are becoming pivotal to production systems, spanning customer service automation, e-commerce assistance, and interactive task management, where accurately distinguishing high-value informative signals from stochastic noise is critical for sample-efficient training. In real-world scenarios, a failure in a trivial task may reflect random instability, whereas success in a high-difficulty task signifies a genuine capability breakthrough. Yet, existing group-based policy optimization methods rigidly rely on statistical deviation within discrete batches, frequently misallocating credit when task difficulty fluctuates. To address this issue, we propose Proximity-based Multi-turn Optimization (ProxMO), a practical and robust framework engineered specifically for the constraints of real-world deployment. ProxMO integrates global context via two lightweight mechanisms: success-rate-aware modulation dynamically adapts gradient intensity based on episode-level difficulty, while proximity-based soft aggregation derives baselines through continuous semantic weighting at the step level. Extensive evaluations on ALFWorld and WebShop benchmarks demonstrate that ProxMO yields substantial performance gains over existing baselines with negligible computational cost. Ablation studies further validate the independent and synergistic efficacy of both mechanisms. Crucially, ProxMO offers plug-and-play compatibility with standard GRPO frameworks, facilitating immediate, low-friction adoption in existing industrial training pipelines. Our implementation is available at: \\href{https://anonymous.4open.science/r/proxmo-B7E7/README.md}{https://anonymous.4open.science/r/proxmo}.", "AI": {"tldr": "提出了一种基于接近度的多轮优化（ProxMO）框架，以解决LLM代理在实际部署中样本高效训练的问题。", "motivation": "现有政策优化方法难以准确分配信用，特别是在任务难度波动的情况下。为了解决这一问题并实现更有效的多轮代理培训，作者提出了基于接近度的多轮优化（ProxMO）框架。", "method": "ProxMO通过两个轻量级机制集成全局上下文：成功比率感知调节根据每个回合的难易程度动态适应梯度强度；而接近度基线软聚合则在步骤级别上使用持续语义加权来派生基准。", "result": "实验结果表明，与现有基准相比，ProxMO在ALFWorld和WebShop等基准测试中表现出显著性能提升，并且几乎无额外计算成本。消融研究进一步验证了这两种机制的独立有效性和协同作用。", "conclusion": "ProxMO提供了一种实用、强大的方法来优化多轮LLM代理训练，具备与标准GRPO框架即插即用兼容性，能够轻易融入现有的工业级培训管道中，并已公开代码供参考。"}}
{"id": "2602.19224", "pdf": "https://arxiv.org/pdf/2602.19224", "abs": "https://arxiv.org/abs/2602.19224", "authors": ["Siran Li", "Li Mi", "Javiera Castillo-Navarro", "Devis Tuia"], "title": "Knowledge-aware Visual Question Generation for Remote Sensing Images", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid development of remote sensing image archives, asking questions about images has become an effective way of gathering specific information or performing image retrieval. However, automatically generated image-based questions tend to be simplistic and template-based, which hinders the real deployment of question answering or visual dialogue systems. To enrich and diversify the questions, we propose a knowledge-aware remote sensing visual question generation model, KRSVQG, that incorporates external knowledge related to the image content to improve the quality and contextual understanding of the generated questions. The model takes an image and a related knowledge triplet from external knowledge sources as inputs and leverages image captioning as an intermediary representation to enhance the image grounding of the generated questions. To assess the performance of KRSVQG, we utilized two datasets that we manually annotated: NWPU-300 and TextRS-300. Results on these two datasets demonstrate that KRSVQG outperforms existing methods and leads to knowledge-enriched questions, grounded in both image and domain knowledge.", "AI": {"tldr": "本文提出了一种知识感知的遥感图像问题生成模型KRSVQG，该模型通过将外部知识与图像内容相结合，提高了问题的质量和语境理解。", "motivation": "自动化的基于图像的问题生成方法往往过于简单且模板化，这限制了问答或视觉对话系统在实际应用中的部署。为了丰富这些问题的多样性并提高其质量，作者提出了KRSVQG模型。", "method": "该模型结合图像和外部知识来源的相关三元组作为输入，并通过使用图像描述作为中介表示来增强生成问题与图像之间的关联性。", "result": "实验结果表明，KRSVQG在两个手动标注的数据集（NWPU-300和TextRS-300）上的表现优于现有方法，能够产生更丰富、更具上下文相关性的知识强化问题。", "conclusion": "本文通过引入外部知识源来提高视觉问答系统的性能，并成功验证了其模型KRSVQG的有效性和优越性。"}}
{"id": "2602.19223", "pdf": "https://arxiv.org/pdf/2602.19223", "abs": "https://arxiv.org/abs/2602.19223", "authors": ["Aymen Khouja", "Imen Jendoubi", "Oumayma Mahjoub", "Oussama Mahfoudhi", "Claude Formanek", "Siddarth Singh", "Ruan De Kock"], "title": "Characterizing MARL for Energy Control: A Multi-KPI Benchmark on the CityLearn Environment", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": ":I.2.6; I.2.11; G.3", "summary": "The optimization of urban energy systems is crucial for the advancement of sustainable and resilient smart cities, which are becoming increasingly complex with multiple decision-making units. To address scalability and coordination concerns, Multi-Agent Reinforcement Learning (MARL) is a promising solution. This paper addresses the imperative need for comprehensive and reliable benchmarking of MARL algorithms on energy management tasks. CityLearn is used as a case study environment because it realistically simulates urban energy systems, incorporates multiple storage systems, and utilizes renewable energy sources. By doing so, our work sets a new standard for evaluation, conducting a comparative study across multiple key performance indicators (KPIs). This approach illuminates the key strengths and weaknesses of various algorithms, moving beyond traditional KPI averaging which often masks critical insights. Our experiments utilize widely accepted baselines such as Proximal Policy Optimization (PPO) and Soft Actor Critic (SAC), and encompass diverse training schemes including Decentralized Training with Decentralized Execution (DTDE) and Centralized Training with Decentralized Execution (CTDE) approaches and different neural network architectures. Our work also proposes novel KPIs that tackle real world implementation challenges such as individual building contribution and battery storage lifetime. Our findings show that DTDE consistently outperforms CTDE in both average and worst-case performance. Additionally, temporal dependency learning improved control on memory dependent KPIs such as ramping and battery usage, contributing to more sustainable battery operation. Results also reveal robustness to agent or resource removal, highlighting both the resilience and decentralizability of the learned policies.", "AI": {"tldr": "研究利用多智能体强化学习优化城市能源系统，通过CityLearn环境进行基准测试。", "motivation": "解决城市能源管理系统中的可扩展性和协调性问题，提供一个可靠的基准测试方法。", "method": "使用多种关键绩效指标（KPI）比较不同MARL算法的表现，并采用Proximal Policy Optimization和Soft Actor Critic等广泛接受的基线进行实验。", "result": "发现分散式训练与执行优于集中式训练与执行，时间依赖学习提高了对记忆相关KPI的控制效果，表明所学策略既灵活又具有抗干扰性。", "conclusion": "研究提出了新的评估基准和关键绩效指标，展示了MARL在城市能源管理中的潜力。"}}
{"id": "2602.19219", "pdf": "https://arxiv.org/pdf/2602.19219", "abs": "https://arxiv.org/abs/2602.19219", "authors": ["Joris Kirchner", "Amogh Gudi", "Marian Bittner", "Chirag Raman"], "title": "Controlled Face Manipulation and Synthesis for Data Augmentation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning vision models excel with abundant supervision, but many applications face label scarcity and class imbalance. Controllable image editing can augment scarce labeled data, yet edits often introduce artifacts and entangle non-target attributes. We study this in facial expression analysis, targeting Action Unit (AU) manipulation where annotation is costly and AU co-activation drives entanglement. We present a facial manipulation method that operates in the semantic latent space of a pre-trained face generator (Diffusion Autoencoder). Using lightweight linear models, we reduce entanglement of semantic features via (i) dependency-aware conditioning that accounts for AU co-activation, and (ii) orthogonal projection that removes nuisance attribute directions (e.g., glasses), together with an expression neutralization step to enable absolute AU edit. We use these edits to balance AU occurrence by editing labeled faces and to diversify identities/demographics via controlled synthesis. Augmenting AU detector training with the generated data improves accuracy and yields more disentangled predictions with fewer co-activation shortcuts, outperforming alternative data-efficient training strategies and suggesting improvements similar to what would require substantially more labeled data in our learning-curve analysis. Compared to prior methods, our edits are stronger, produce fewer artifacts, and preserve identity better.", "AI": {"tldr": "研究一种面部编辑方法，以解决面部表情分析中的标签稀缺和类不平衡问题。", "motivation": "在深度学习视觉模型中，为了克服标记数据不足及类别失衡的问题，需要通过可控图像编辑来扩充稀有标注数据。这种方法可以改善面部动作单位（AU）操作的难题，并减少非目标属性的纠缠。", "method": "提出一种基于预训练面部生成器的语义潜在空间的操作方法。利用轻量级线性模型降低语义特征中的纠缠，通过依赖感知条件处理AU协同激活和正交投影去除噪音属性方向（例如眼镜），并添加表情中立化步骤实现绝对AU编辑。", "result": "使用生成数据增强AU检测器的训练不仅提高了精度，还减少了共激活捷径。相比先前的方法，这种方法产生的编辑更强、更少产生伪影，并更好地保留身份特征。", "conclusion": "该方法改进了面部表情分析中的标签稀缺和类不平衡问题，通过控制合成增强数据的有效性，同时减少非目标属性的纠缠。"}}
{"id": "2602.19217", "pdf": "https://arxiv.org/pdf/2602.19217", "abs": "https://arxiv.org/abs/2602.19217", "authors": ["Siran Li", "Li Mi", "Javiera Castillo-Navarro", "Devis Tuia"], "title": "Questions beyond Pixels: Integrating Commonsense Knowledge in Visual Question Generation for Remote Sensing", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid development of remote sensing image archives, asking questions about images has become an effective way of gathering specific information or performing semantic image retrieval. However, current automatically generated questions tend to be simplistic and template-based, which hinders the deployment of question answering or visual dialogue systems for real-world applications. To enrich and diversify the questions with both image content and commonsense knowledge, we propose a Knowledge-aware Remote Sensing Visual Question Generation model (KRSVQG). The proposed model incorporates related knowledge triplets from external knowledge sources to broaden the question content, while employing image captioning as an intermediary representation to ground questions to the corresponding images. Moreover, KRSVQG utilizes a vision-language pre-training and fine-tuning strategy, enabling the model's adaptation to low data regimes. To evaluate the proposed KRSVQG model, we construct two knowledge-aware remote sensing visual question generation datasets: the NWPU-300 dataset and the TextRS-300 dataset. Evaluations, including metrics and human assessment, demonstrate that KRSVQG outperforms existing methods and leads to rich questions, grounded in both image and domain knowledge. As a key practice in vision-language research, knowledge-aware visual question generation advances the understanding of image content beyond pixels, facilitating the development of knowledge-enriched vision-language systems with vision-grounded human commonsense.", "AI": {"tldr": "提出了一种结合常识知识的遥感图像问答生成模型KRSVQG，以丰富和多样化问题内容。", "motivation": "当前自动产生的问题是模板化的，并且缺乏深度，这阻碍了视觉对话系统的实际应用。通过引入常识知识来增强和扩大问题内容的多样性和复杂性。", "method": "KRSVQG模型利用外部的知识三元组来扩展问题的内容，并使用图像描述作为中间表示将问题与对应图片关联起来；采用了视觉语言预训练和微调策略，以适应低数据环境。", "result": "实验结果表明，所提出的KRSVQG模型优于现有方法，能够生成丰富且基于图象及领域知识的问题。", "conclusion": "该研究推动了对图像内容的理解超越像素，并促进了视觉语言系统的发展。"}}
{"id": "2602.19213", "pdf": "https://arxiv.org/pdf/2602.19213", "abs": "https://arxiv.org/abs/2602.19213", "authors": ["Yujie Lu", "Jingwen Li", "Sibo Ju", "Yanzhou Su", "he yao", "Yisong Liu", "Min Zhu", "Junlong Cheng"], "title": "SegMoTE: Token-Level Mixture of Experts for Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Medical image segmentation is vital for clinical diagnosis and quantitative analysis, yet remains challenging due to the heterogeneity of imaging modalities and the high cost of pixel-level annotations. Although general interactive segmentation models like SAM have achieved remarkable progress, their transfer to medical imaging still faces two key bottlenecks: (i) the lack of adaptive mechanisms for modality- and anatomy-specific tasks, which limits generalization in out-of-distribution medical scenarios; and (ii) current medical adaptation methods fine-tune on large, heterogeneous datasets without selection, leading to noisy supervision, higher cost, and negative transfer. To address these issues, we propose SegMoTE, an efficient and adaptive framework for medical image segmentation. SegMoTE preserves SAM's original prompt interface, efficient inference, and zero-shot generalization while introducing only a small number of learnable parameters to dynamically adapt across modalities and tasks. In addition, we design a progressive prompt tokenization mechanism that enables fully automatic segmentation, significantly reducing annotation dependence. Trained on MedSeg-HQ, a curated dataset less than 1% of existing large-scale datasets, SegMoTE achieves SOTA performance across diverse imaging modalities and anatomical tasks. It represents the first efficient, robust, and scalable adaptation of general segmentation models to the medical domain under extremely low annotation cost, advancing the practical deployment of foundation vision models in clinical applications.", "AI": {"tldr": "本文提出了SegMoTE，一种用于医学图像分割的高效且适应性强的框架。", "motivation": "现有的通用交互式分割模型在医学影像应用中存在两个瓶颈：缺乏适应特定模态和解剖结构任务机制、当前的方法会因数据异质性导致训练成本高和负迁移。", "method": "SegMoTE保持了SAM原有的提示界面、高效推断和零样本泛化能力，引入少量可学习参数实现跨模态和任务的动态适应。设计了一种逐步提示标记机制来支持全自动分割，显著降低标注依赖。", "result": "在MedSeg-HQ数据集上训练后，SegMoTE实现了多样医学成像模式及解剖任务中的SOTA性能。", "conclusion": "SegMoTE为通用分割模型向医疗领域的高效、稳健和大规模适应提供了可能，推进了基础视觉模型在临床应用的实际部署。"}}
{"id": "2602.19208", "pdf": "https://arxiv.org/pdf/2602.19208", "abs": "https://arxiv.org/abs/2602.19208", "authors": ["Yangyi Fang", "Jiaye Lin", "Xiaoliang Fu", "Cong Qin", "Haolin Shi", "Chaowen Hu", "Lu Pan", "Ke Zeng", "Xunliang Cai"], "title": "How to Allocate, How to Learn? Dynamic Rollout Allocation and Advantage Modulation for Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for Large Language Model (LLM) reasoning, yet current methods face key challenges in resource allocation and policy optimization dynamics: (i) uniform rollout allocation ignores gradient variance heterogeneity across problems, and (ii) the softmax policy structure causes gradient attenuation for high-confidence correct actions, while excessive gradient updates may destabilize training. Therefore, we propose DynaMO, a theoretically-grounded dual-pronged optimization framework. At the sequence level, we prove that uniform allocation is suboptimal and derive variance-minimizing allocation from the first principle, establishing Bernoulli variance as a computable proxy for gradient informativeness. At the token level, we develop gradient-aware advantage modulation grounded in theoretical analysis of gradient magnitude bounds. Our framework compensates for gradient attenuation of high-confidence correct actions while utilizing entropy changes as computable indicators to stabilize excessive update magnitudes. Extensive experiments conducted on a diverse range of mathematical reasoning benchmarks demonstrate consistent improvements over strong RLVR baselines. Our implementation is available at: \\href{https://anonymous.4open.science/r/dynamo-680E/README.md}{https://anonymous.4open.science/r/dynamo}.", "AI": {"tldr": "本文提出了一种理论基础的双管齐下优化框架DynaMO，旨在解决强化学习中资源分配和策略优化的问题。", "motivation": "现有的方法在资源分配和政策优化动态方面面临挑战：均匀rollout分配忽略了问题间梯度方差的异质性，softmax策略结构导致了高置信度正确行为的梯度衰减，并可能使训练变得不稳定。", "method": "DynaMO框架分为序列级和标记级。在序列级别上，证明了统一分配是次优的并从基本原则派生出方差最小化的分配方式；在标记级别上，提出了基于理论分析的梯度幅度限制的优势调节。", "result": "在广泛的数学推理基准测试中进行了大量实验，并显示出明显优于强大的RLVR基线。", "conclusion": "DynaMO框架能够补偿高置信度正确行为的梯度衰减并利用熵变化作为可计算指标来稳定过度更新幅度，从而提高了政策优化效率。"}}
{"id": "2602.19207", "pdf": "https://arxiv.org/pdf/2602.19207", "abs": "https://arxiv.org/abs/2602.19207", "authors": ["Afsana Khan", "Marijn ten Thij", "Guangzhi Tang", "Anna Wilbik"], "title": "HybridFL: A Federated Learning Approach for Financial Crime Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) is a privacy-preserving machine learning paradigm that enables multiple parties to collaboratively train models on privately owned data without sharing raw information. While standard FL typically addresses either horizontal or vertical data partitions, many real-world scenarios exhibit a complex hybrid distribution. This paper proposes Hybrid Federated Learning (HybridFL) to address data split both horizontally across disjoint users and vertically across complementary feature sets. We evaluate HybridFL in a financial crime detection context, where a transaction party holds transaction-level attributes and multiple banks maintain private account-level features. By integrating horizontal aggregation and vertical feature fusion, the proposed architecture enables joint learning while strictly preserving data locality. Experiments on AMLSim and SWIFT datasets demonstrate that HybridFL significantly outperforms the transaction-only local model and achieves performance comparable to a centralized benchmark.", "AI": {"tldr": "提出了混合联邦学习(HybridFL)方法，用于金融犯罪检测中的数据联合训练。", "motivation": "标准的联邦学习仅适用于横向或纵向的数据分割，在实际应用中需要解决复杂的数据分布问题。因此，本文提出HybridFL来应对既横向又纵向的数据分割。", "method": "通过集成水平聚合和垂直特征融合的方式，实现了在不共享原始数据的前提下进行联合训练，并在金融犯罪检测场景下进行了实验验证。", "result": "与仅基于交易的本地模型相比，HybridFL性能显著提升；其效果接近于中心化基准测试。", "conclusion": "HybridFL能够在保护隐私的同时实现高效的数据联合学习，在金融犯罪检测中展现出良好的应用前景。"}}
{"id": "2602.19206", "pdf": "https://arxiv.org/pdf/2602.19206", "abs": "https://arxiv.org/abs/2602.19206", "authors": ["Zehao Deng", "An Liu", "Yan Wang"], "title": "GS-CLIP: Zero-shot 3D Anomaly Detection by Geometry-Aware Prompt and Synergistic View Representation Learning", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot 3D Anomaly Detection is an emerging task that aims to detect anomalies in a target dataset without any target training data, which is particularly important in scenarios constrained by sample scarcity and data privacy concerns. While current methods adapt CLIP by projecting 3D point clouds into 2D representations, they face challenges. The projection inherently loses some geometric details, and the reliance on a single 2D modality provides an incomplete visual understanding, limiting their ability to detect diverse anomaly types. To address these limitations, we propose the Geometry-Aware Prompt and Synergistic View Representation Learning (GS-CLIP) framework, which enables the model to identify geometric anomalies through a two-stage learning process. In stage 1, we dynamically generate text prompts embedded with 3D geometric priors. These prompts contain global shape context and local defect information distilled by our Geometric Defect Distillation Module (GDDM). In stage 2, we introduce Synergistic View Representation Learning architecture that processes rendered and depth images in parallel. A Synergistic Refinement Module (SRM) subsequently fuses the features of both streams, capitalizing on their complementary strengths. Comprehensive experimental results on four large-scale public datasets show that GS-CLIP achieves superior performance in detection. Code can be available at https://github.com/zhushengxinyue/GS-CLIP.", "AI": {"tldr": "提出了一种零样本三维异常检测框架GS-CLIP，通过几何感知提示和协同视图表示学习来改进现有的基于CLIP的方法。", "motivation": "现有方法在将3D点云投影到2D时会丢失几何细节，并且依赖单一的2D模态限制了多样性的异常类型识别。为此提出GS-CLIP解决这些问题。", "method": "采用两阶段学习过程，第一阶段生成嵌入有三维几何先验信息的文字提示；第二阶段通过协同视图表示学习架构处理渲染和深度图像，并利用融合模块结合两种特征的优势。", "result": "实验结果表明，GS-CLIP在四个大规模公共数据集上的检测性能优于现有方法。", "conclusion": "所提出的GS-CLIP框架能够有效提高零样本三维异常检测的准确性和鲁棒性。"}}
{"id": "2602.19202", "pdf": "https://arxiv.org/pdf/2602.19202", "abs": "https://arxiv.org/abs/2602.19202", "authors": ["Gang Xu", "Zhiyu Zhu", "Junhui Hou"], "title": "UniE2F: A Unified Diffusion Framework for Event-to-Frame Reconstruction with Video Foundation Models", "categories": ["cs.CV"], "comment": null, "summary": "Event cameras excel at high-speed, low-power, and high-dynamic-range scene perception. However, as they fundamentally record only relative intensity changes rather than absolute intensity, the resulting data streams suffer from a significant loss of spatial information and static texture details. In this paper, we address this limitation by leveraging the generative prior of a pre-trained video diffusion model to reconstruct high-fidelity video frames from sparse event data. Specifically, we first establish a baseline model by directly applying event data as a condition to synthesize videos. Then, based on the physical correlation between the event stream and video frames, we further introduce the event-based inter-frame residual guidance to enhance the accuracy of video frame reconstruction. Furthermore, we extend our method to video frame interpolation and prediction in a zero-shot manner by modulating the reverse diffusion sampling process, thereby creating a unified event-to-frame reconstruction framework. Experimental results on real-world and synthetic datasets demonstrate that our method significantly outperforms previous approaches both quantitatively and qualitatively. We also refer the reviewers to the video demo contained in the supplementary material for video results. The code will be publicly available at https://github.com/CS-GangXu/UniE2F.", "AI": {"tldr": "该论文提出了一个统一的扩散框架UniE2F，用于从稀疏事件数据重建高质量视频帧。", "motivation": "事件相机记录的是相对强度变化而不是绝对强度，因此导致空间信息和静态纹理细节损失。为了弥补这一限制，研究者利用预训练的视频扩散模型生成先验来提高视频帧的重建准确性。", "method": "首先建立了用事件数据直接条件化合成视频的基线模型；接着通过引入基于事件之间的物理相关性残差指导来改进视频帧重建精度；最后扩展该方法以实现零样本方式下的视频帧插值和预测，形成一个统一的事件到帧重建框架。", "result": "实验证明，与先前的方法相比，本文提出的方法在真实数据集和合成数据集上都显示出显著更好的性能指标。", "conclusion": "通过使用预训练的扩散模型，该方法能够从稀疏的事件流中恢复高质量的视频帧，并且可以用于零样本方式下的视频插值和预测。"}}
{"id": "2602.19198", "pdf": "https://arxiv.org/pdf/2602.19198", "abs": "https://arxiv.org/abs/2602.19198", "authors": ["Xi Yang", "Yuanrong Xu", "Weigang Zhang", "Guangming Lu", "David Zhang", "Jie Wen"], "title": "Prompt Tuning for CLIP on the Pretrained Manifold", "categories": ["cs.CV"], "comment": null, "summary": "Prompt tuning introduces learnable prompt vectors that adapt pretrained vision-language models to downstream tasks in a parameter-efficient manner. However, under limited supervision, prompt tuning alters pretrained representations and drives downstream features away from the pretrained manifold toward directions that are unfavorable for transfer. This drift degrades generalization. To address this limitation, we propose ManiPT, a framework that performs prompt tuning on the pretrained manifold. ManiPT introduces cosine consistency constraints in both the text and image modalities to confine the learned representations within the pretrained geometric neighborhood. Furthermore, we introduce a structural bias that enforces incremental corrections, guiding the adaptation along transferable directions to mitigate reliance on shortcut learning. From a theoretical perspective, ManiPT alleviates overfitting tendencies under limited data. Our experiments cover four downstream settings: unseen-class generalization, few-shot classification, cross-dataset transfer, and domain generalization. Across these settings, ManiPT achieves higher average performance than baseline methods. Notably, ManiPT provides an explicit perspective on how prompt tuning overfits under limited supervision.", "AI": {"tldr": "提出了一种名为ManiPT的框架，用于在预训练流形上进行提示微调，以改善下游任务中的泛化性能。", "motivation": "为了减少有限监督下的过拟合倾向并提高泛化能力，在提示调整时引入了余弦一致性约束和渐进式修正偏置。", "method": "ManiPT通过在文本和图像模态中添加余弦一致性的约束条件，并采用递增的校正偏差，将学习到的表示限制在预训练的几何邻域内。", "result": "实验结果显示，在未见类泛化、小样本分类、跨数据集迁移和领域泛化等四个下游任务设置下，ManiPT平均性能优于基线方法。", "conclusion": "该论文提出了一种新的框架，可以有效地限制提示微调过程中表示的变化，并提高模型在有限监督条件下的泛化能力。"}}
{"id": "2602.19193", "pdf": "https://arxiv.org/pdf/2602.19193", "abs": "https://arxiv.org/abs/2602.19193", "authors": ["Hieu Bui", "Ziyan Gao", "Yuya Hosoda", "Joo-Ho Lee"], "title": "Visual Prompt Guided Unified Pushing Policy", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "As one of the simplest non-prehensile manipulation skills, pushing has been widely studied as an effective means to rearrange objects. Existing approaches, however, typically rely on multi-step push plans composed of pre-defined pushing primitives with limited application scopes, which restrict their efficiency and versatility across different scenarios. In this work, we propose a unified pushing policy that incorporates a lightweight prompting mechanism into a flow matching policy to guide the generation of reactive, multimodal pushing actions. The visual prompt can be specified by a high-level planner, enabling the reuse of the pushing policy across a wide range of planning problems. Experimental results demonstrate that the proposed unified pushing policy not only outperforms existing baselines but also effectively serves as a low-level primitive within a VLM-guided planning framework to solve table-cleaning tasks efficiently.", "AI": {"tldr": "提出了一种统一的推动策略，通过视觉提示引导生成反应式多模态推动动作。", "motivation": "现有方法依赖于预定义的推送原语，限制了其在不同场景下的效率和灵活性。为了提高推送操作的通用性和高效性。", "method": "将轻量级提示机制融入流匹配政策中，利用高阶计划器指定视觉提示以指导生成多模态推动动作。", "result": "实验结果表明，该统一推动策略不仅优于现有基准，还能够作为低阶原语在VLM引导的规划框架内高效解决桌面上清理任务。", "conclusion": "所提出的模型提升了非抓取式操作的能力和效率。"}}
{"id": "2602.19190", "pdf": "https://arxiv.org/pdf/2602.19190", "abs": "https://arxiv.org/abs/2602.19190", "authors": ["Xiaokun Zhang", "Yi Yang", "Ziqi Ye", "Baiyun", "Xiaorong Guo", "Qingchen Fang", "Ruyi Zhang", "Xinpeng Zhou", "Haipeng Wang"], "title": "FUSAR-GPT : A Spatiotemporal Feature-Embedded and Two-Stage Decoupled Visual Language Model for SAR Imagery", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Research on the intelligent interpretation of all-weather, all-time Synthetic Aperture Radar (SAR) is crucial for advancing remote sensing applications. In recent years, although Visual Language Models (VLMs) have demonstrated strong open-world understanding capabilities on RGB images, their performance is severely limited when directly applied to the SAR field due to the complexity of the imaging mechanism, sensitivity to scattering features, and the scarcity of high-quality text corpora. To systematically address this issue, we constructed the inaugural SAR Image-Text-AlphaEarth feature triplet dataset and developed FUSAR-GPT, a VLM specifically for SAR. FUSAR-GPT innovatively introduces a geospatial baseline model as a 'world knowledge' prior and embeds multi-source remote-sensing temporal features into the model's visual backbone via 'spatiotemporal anchors', enabling dynamic compensation for the sparse representation of targets in SAR images. Furthermore, we designed a two-stage SFT strategy to decouple the knowledge injection and task execution of large models. The spatiotemporal feature embedding and the two-stage decoupling paradigm enable FUSAR-GPT to achieve state-of-the-art performance across several typical remote sensing visual-language benchmark tests, significantly outperforming mainstream baseline models by over 12%.", "AI": {"tldr": "构建了一个用于SAR图像的视觉语言模型FUSAR-GPT，该模型通过引入时空特征和两阶段解耦策略来提高性能。", "motivation": "解决现有VLM在直接应用于SAR领域的局限性问题，包括成像机制复杂、对散射特性敏感以及高质量文本语料缺乏等问题。", "method": "构建了首个SAR图像-文本-AlphaEarth特征三元组数据集，并开发了FUSAR-GPT模型。该模型引入地理基线模型作为“世界知识”先验，通过时空锚点将多源遥感时间特征嵌入到视觉骨干网络中，并设计了两阶段解耦策略。", "result": "在几个典型的遥感视觉-语言基准测试中，FUSAR-GPT取得了最先进的性能，比主流基线模型高出12%以上。", "conclusion": "提出的FUSAR-GPT模型通过时空特征嵌入和两阶段解耦范式，在SAR图像理解方面表现出了优越的性能。"}}
