{"id": "2602.11154", "pdf": "https://arxiv.org/pdf/2602.11154", "abs": "https://arxiv.org/abs/2602.11154", "authors": ["Yue Gao", "Hong-Xing Yu", "Sanghyeon Chang", "Qianxi Fu", "Bo Zhu", "Yoonjin Won", "Juan Carlos Niebles", "Jiajun Wu"], "title": "SurfPhase: 3D Interfacial Dynamics in Two-Phase Flows from Sparse Videos", "categories": ["cs.CV"], "comment": "The first two authors contributed equally. Project website: https://yuegao.me/SurfPhase", "summary": "Interfacial dynamics in two-phase flows govern momentum, heat, and mass transfer, yet remain difficult to measure experimentally. Classical techniques face intrinsic limitations near moving interfaces, while existing neural rendering methods target single-phase flows with diffuse boundaries and cannot handle sharp, deformable liquid-vapor interfaces. We propose SurfPhase, a novel model for reconstructing 3D interfacial dynamics from sparse camera views. Our approach integrates dynamic Gaussian surfels with a signed distance function formulation for geometric consistency, and leverages a video diffusion model to synthesize novel-view videos to refine reconstruction from sparse observations. We evaluate on a new dataset of high-speed pool boiling videos, demonstrating high-quality view synthesis and velocity estimation from only two camera views. Project website: https://yuegao.me/SurfPhase.", "AI": {"tldr": "提出了一种从稀疏视频中重建两相流体界面动态的新模型SurfPhase。", "motivation": "传统技术在移动界面上存在固有局限，现有神经渲染方法仅适用于单相流体且处理模糊边界，无法应对尖锐、可变形的液汽界面。因此需要新的解决方案来准确测量和重建两相流动中的界面动态。", "method": "SurfPhase结合了动态高斯点元与符号距离函数以保证几何一致性，并利用视频扩散模型从稀疏观测中合成新视角视频，从而提高重建精度。", "result": "通过高速沸腾实验数据集验证了该方法能够实现高质量的视图合成及速度估计，仅需两个摄像机视角即可达到高精度。", "conclusion": "SurfPhase为测量和模拟复杂两相流体中的界面动态提供了一个有效的解决方案。"}}
{"id": "2602.11150", "pdf": "https://arxiv.org/pdf/2602.11150", "abs": "https://arxiv.org/abs/2602.11150", "authors": ["Manan H Anjaria", "Mehmet Enes Erciyes", "Vedant Ghatnekar", "Neha Navarkar", "Haritheja Etukuru", "Xiaole Jiang", "Kanad Patel", "Dhawal Kabra", "Nicholas Wojno", "Radhika Ajay Prayage", "Soumith Chintala", "Lerrel Pinto", "Nur Muhammad Mahi Shafiullah", "Zichen Jeff Cui"], "title": "YOR: Your Own Mobile Manipulator for Generalizable Robotics", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Recent advances in robot learning have generated significant interest in capable platforms that may eventually approach human-level competence. This interest, combined with the commoditization of actuators, has propelled growth in low-cost robotic platforms. However, the optimal form factor for mobile manipulation, especially on a budget, remains an open question. We introduce YOR, an open-source, low-cost mobile manipulator that integrates an omnidirectional base, a telescopic vertical lift, and two arms with grippers to achieve whole-body mobility and manipulation. Our design emphasizes modularity, ease of assembly using off-the-shelf components, and affordability, with a bill-of-materials cost under 10,000 USD. We demonstrate YOR's capability by completing tasks that require coordinated whole-body control, bimanual manipulation, and autonomous navigation. Overall, YOR offers competitive functionality for mobile manipulation research at a fraction of the cost of existing platforms. Project website: https://www.yourownrobot.ai/", "AI": {"tldr": "介绍了YOY，一种低成本的移动机械臂平台，旨在实现全身控制、双臂操作和自主导航。", "motivation": "随着机器人学习的进步以及执行器的普及化，低预算下的最优形态因子的移动操纵仍是一个开放问题。为了探索这一领域，作者提出了一个经济实惠且功能强大的解决方案。", "method": "设计了一种模块化的平台YOY，它集成有全向底座、可伸缩垂直提升装置和两个带抓手的手臂，能够实现全身运动与操作，并展示了其在完成复杂任务中的能力。", "result": "YOY展示了在完成需要协调的全身控制、双臂操作及自主导航的任务方面的功能。", "conclusion": "YOY为移动操纵研究提供了一个具有竞争力的功能平台，且成本远低于现有平台。"}}
{"id": "2602.11146", "pdf": "https://arxiv.org/pdf/2602.11146", "abs": "https://arxiv.org/abs/2602.11146", "authors": ["Gongye Liu", "Bo Yang", "Yida Zhi", "Zhizhou Zhong", "Lei Ke", "Didan Deng", "Han Gao", "Yongxiang Huang", "Kaihao Zhang", "Hongbo Fu", "Wenhan Luo"], "title": "Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling", "categories": ["cs.CV", "cs.AI"], "comment": "Code: https://github.com/HKUST-C4G/diffusion-rm", "summary": "Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. However, their computation and memory cost can be substantial, and optimizing a latent diffusion generator through a pixel-space reward introduces a domain mismatch that complicates alignment. In this paper, we propose DiNa-LRM, a diffusion-native latent reward model that formulates preference learning directly on noisy diffusion states. Our method introduces a noise-calibrated Thurstone likelihood with diffusion-noise-dependent uncertainty. DiNa-LRM leverages a pretrained latent diffusion backbone with a timestep-conditioned reward head, and supports inference-time noise ensembling, providing a diffusion-native mechanism for test-time scaling and robust rewarding. Across image alignment benchmarks, DiNa-LRM substantially outperforms existing diffusion-based reward baselines and achieves performance competitive with state-of-the-art VLMs at a fraction of the computational cost. In preference optimization, we demonstrate that DiNa-LRM improves preference optimization dynamics, enabling faster and more resource-efficient model alignment.", "AI": {"tldr": "本文提出了一种称为DiNa-LRM的新型扩散原生潜在奖励模型，旨在改进基于扩散和流匹配模型中的偏好优化。", "motivation": "视觉-语言模型作为主要奖励提供者面临计算成本高和内存消耗大的问题。此外，通过像素空间奖励对潜在扩散生成器进行优化会导致领域偏差，使对齐变得复杂。", "method": "提出了一种称为DiNa-LRM的新型扩散原生潜在奖励模型，该方法基于噪声校准的 Thurstone 极似度与扩散噪声相关的不确定性，使用预训练的潜在扩散骨干和时间步长条件化的奖励头，并支持推断时噪音集成。", "result": "在图像对齐基准测试中，DiNa-LRM显著优于现有的扩散基础奖励基线，并且其性能可与最先进的视觉-语言模型相比，计算成本更低。", "conclusion": "该方法改进了偏好优化动力学，在更快和更资源高效的模型对齐方面具有优势。"}}
{"id": "2602.11145", "pdf": "https://arxiv.org/pdf/2602.11145", "abs": "https://arxiv.org/abs/2602.11145", "authors": ["Christopher Mitcheltree", "Vincent Lostanlen", "Emmanouil Benetos", "Mathieu Lagrange"], "title": "SCRAPL: Scattering Transform with Random Paths for Machine Learning", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Accepted to ICLR 2026. Code, audio samples, and Python package provided at https://christhetree.github.io/scrapl/", "summary": "The Euclidean distance between wavelet scattering transform coefficients (known as paths) provides informative gradients for perceptual quality assessment of deep inverse problems in computer vision, speech, and audio processing. However, these transforms are computationally expensive when employed as differentiable loss functions for stochastic gradient descent due to their numerous paths, which significantly limits their use in neural network training. Against this problem, we propose \"Scattering transform with Random Paths for machine Learning\" (SCRAPL): a stochastic optimization scheme for efficient evaluation of multivariable scattering transforms. We implement SCRAPL for the joint time-frequency scattering transform (JTFS) which demodulates spectrotemporal patterns at multiple scales and rates, allowing a fine characterization of intermittent auditory textures. We apply SCRAPL to differentiable digital signal processing (DDSP), specifically, unsupervised sound matching of a granular synthesizer and the Roland TR-808 drum machine. We also propose an initialization heuristic based on importance sampling, which adapts SCRAPL to the perceptual content of the dataset, improving neural network convergence and evaluation performance. We make our code and audio samples available and provide SCRAPL as a Python package.", "AI": {"tldr": "提出了一种随机路径的散射变换方法（SCRAPL）用于机器学习中的神经网络训练，以解决现有波浪散射变换在作为可微损失函数时计算成本高的问题。", "motivation": "现有的欧几里得距离波浪散射变换系数由于其众多的路径，在用作随机梯度下降法的可微分损失函数时，计算效率低下，极大地限制了它们用于神经网络训练。为此提出了SCRAPL以解决该问题。", "method": "提出了一种基于随机优化方案的SCRAPL方法，用于高效评估多变量散射变换，并应用于联合时间频率散射变换（JTFS），以解调时频模式并适应感知内容的数据集初始化启发式策略来提高神经网络收敛和评价性能。", "result": "通过在不同可微数字信号处理应用中使用SCRAPL，包括无监督声音匹配等任务，验证了该方法的有效性和优越性。", "conclusion": "SCRAPL作为一种新的随机优化方案，可以有效降低计算成本并提高神经网络训练效率。"}}
{"id": "2602.11144", "pdf": "https://arxiv.org/pdf/2602.11144", "abs": "https://arxiv.org/abs/2602.11144", "authors": ["Ruichuan An", "Sihan Yang", "Ziyu Guo", "Wei Dai", "Zijun Shen", "Haodong Li", "Renrui Zhang", "Xinyu Wei", "Guopeng Li", "Wenshan Wu", "Wentao Zhang"], "title": "GENIUS: Generative Fluid Intelligence Evaluation Suite", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess $\\textit{Crystallized Intelligence}$, which relies on recalling accumulated knowledge and learned schemas. This focus overlooks $\\textit{Generative Fluid Intelligence (GFI)}$: the capacity to induce patterns, reason through constraints, and adapt to novel scenarios on the fly. To rigorously assess this capability, we introduce $\\textbf{GENIUS}$ ($\\textbf{GEN}$ Fluid $\\textbf{I}$ntelligence Eval$\\textbf{U}$ation $\\textbf{S}$uite). We formalize $\\textit{GFI}$ as a synthesis of three primitives. These include $\\textit{Inducing Implicit Patterns}$ (e.g., inferring personalized visual preferences), $\\textit{Executing Ad-hoc Constraints}$ (e.g., visualizing abstract metaphors), and $\\textit{Adapting to Contextual Knowledge}$ (e.g., simulating counter-intuitive physics). Collectively, these primitives challenge models to solve problems grounded entirely in the immediate context. Our systematic evaluation of 12 representative models reveals significant performance deficits in these tasks. Crucially, our diagnostic analysis disentangles these failure modes. It demonstrates that deficits stem from limited context comprehension rather than insufficient intrinsic generative capability. To bridge this gap, we propose a training-free attention intervention strategy. Ultimately, $\\textbf{GENIUS}$ establishes a rigorous standard for $\\textit{GFI}$, guiding the field beyond knowledge utilization toward dynamic, general-purpose reasoning. Our dataset and code will be released at: $\\href{https://github.com/arctanxarc/GENIUS}{https://github.com/arctanxarc/GENIUS}$.", "AI": {"tldr": "本文提出了GENIUS，一个用于评估生成流体智能的基准测试套件。", "motivation": "当前大多数基准测试主要侧重于晶体智力的评价，忽略了模型在动态环境中的适应能力和问题解决能力，即生成流体智力（GFI）。为了全面衡量这一能力，作者开发了GENIUS。", "method": "通过定义三个基本要素——隐式模式诱导、即时约束执行和上下文知识适应来构建GENIUS。系统性评估12种代表性模型以揭示性能缺陷，并提出一种无训练注意力干预策略来解决这些问题。", "result": "对12个代表性的模型进行的评价显示，它们在GFI任务中存在显著表现不足的问题；分析表明这些失败主要源于有限上下文理解能力而非内在生成能力不足。", "conclusion": "GENIUS确立了衡量模型动态通用推理能力的标准，并为未来研究提供了方向。"}}
{"id": "2602.11143", "pdf": "https://arxiv.org/pdf/2602.11143", "abs": "https://arxiv.org/abs/2602.11143", "authors": ["Yikai Wang", "Tingxuan Leng", "Changyi Lin", "Shiqi Liu", "Shir Simon", "Bingqing Chen", "Jonathan Francis", "Ding Zhao"], "title": "APEX: Learning Adaptive High-Platform Traversal for Humanoid Robots", "categories": ["cs.RO"], "comment": "Project Website: https://apex-humanoid.github.io/", "summary": "Humanoid locomotion has advanced rapidly with deep reinforcement learning (DRL), enabling robust feet-based traversal over uneven terrain. Yet platforms beyond leg length remain largely out of reach because current RL training paradigms often converge to jumping-like solutions that are high-impact, torque-limited, and unsafe for real-world deployment. To address this gap, we propose APEX, a system for perceptive, climbing-based high-platform traversal that composes terrain-conditioned behaviors: climb-up and climb-down at vertical edges, walking or crawling on the platform, and stand-up and lie-down for posture reconfiguration. Central to our approach is a generalized ratchet progress reward for learning contact-rich, goal-reaching maneuvers. It tracks the best-so-far task progress and penalizes non-improving steps, providing dense yet velocity-free supervision that enables efficient exploration under strong safety regularization. Based on this formulation, we train LiDAR-based full-body maneuver policies and reduce the sim-to-real perception gap through a dual strategy: modeling mapping artifacts during training and applying filtering and inpainting to elevation maps during deployment. Finally, we distill all six skills into a single policy that autonomously selects behaviors and transitions based on local geometry and commands. Experiments on a 29-DoF Unitree G1 humanoid demonstrate zero-shot sim-to-real traversal of 0.8 meter platforms (approximately 114% of leg length), with robust adaptation to platform height and initial pose, as well as smooth and stable multi-skill transitions.", "AI": {"tldr": "提出了一种名为APEX的系统，用于人形机器人跨越高平台的学习。", "motivation": "当前的强化学习训练范式通常收敛于跳跃式的解决方案，这在实际部署中具有冲击力大、扭矩受限和不安全的特点。因此，开发一种能够适应性地完成跨平台任务的方法至关重要。", "method": "通过引入广义棘轮进度奖励来学习接触密集型目标达到操作，该奖励跟踪最佳任务进展并惩罚非改进步骤。基于此方法训练了LiDAR全身体态政策，并减少了仿真到真实感知差距，实现了单一策略执行所有技能的能力。", "result": "实验结果表明，在29自由度的Unitree G1人形机器人上能够实现零样本从模拟到现实0.8米（约腿长的114%）平台的跨越，展示了对平台高度和初始姿态的强大适应能力以及平滑稳定的多技能转换。", "conclusion": "该方法成功解决了人形机器人跨高平台任务中的挑战，并证明了其在不同场景下的有效性和鲁棒性。"}}
{"id": "2602.11142", "pdf": "https://arxiv.org/pdf/2602.11142", "abs": "https://arxiv.org/abs/2602.11142", "authors": ["Shaswat Garg", "Matin Moezzi", "Brandon Da Silva"], "title": "Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "9 pages, 3 figures, IEEE International Conference on Robotics and Automation 2026", "summary": "Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-HIQL), a novel framework that replaces unimodal gaussian policies with expressive normalizing flow policies at both the high- and low-levels of the hierarchy is introduced. This design enables tractable log-likelihood computation, efficient sampling, and the ability to model rich multimodal behaviors. New theoretical guarantees are derived, including explicit KL-divergence bounds for Real-valued non-volume preserving (RealNVP) policies and PAC-style sample efficiency results, showing that NF-HIQL preserves stability while improving generalization. Empirically, NF-HIQL is evaluted across diverse long-horizon tasks in locomotion, ball-dribbling, and multi-step manipulation from OGBench. NF-HIQL consistently outperforms prior goal-conditioned and hierarchical baselines, demonstrating superior robustness under limited data and highlighting the potential of flow-based architectures for scalable, data-efficient hierarchical reinforcement learning.", "AI": {"tldr": "介绍了一种基于正规流的分层隐式Q学习方法，以提高数据效率和策略表达性。", "motivation": "当前分层目标条件强化学习在数据效率低和策略表达能力有限的情况下难以实际应用。此研究旨在通过引入正常化流策略来解决这些问题。", "method": "提出NF-HIQL框架，利用多模式的正规化流策略替代传统的高斯政策，在层次结构中提供可计算的日志似然性、高效采样和丰富行为建模能力。", "result": "实验结果表明，NF-HIQL在各种长时任务中优于先前的目标条件和分层基准方法，特别是在数据有限的情况下表现更佳。", "conclusion": "该论文展示了正规化流架构在提高大规模分层强化学习的数据效率方面的潜力。"}}
{"id": "2602.11141", "pdf": "https://arxiv.org/pdf/2602.11141", "abs": "https://arxiv.org/abs/2602.11141", "authors": ["Yu Wang", "Frederik L. Dennig", "Michael Behrisch", "Alexandru Telea"], "title": "LCIP: Loss-Controlled Inverse Projection of High-Dimensional Image Data", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Projections (or dimensionality reduction) methods $P$ aim to map high-dimensional data to typically 2D scatterplots for visual exploration. Inverse projection methods $P^{-1}$ aim to map this 2D space to the data space to support tasks such as data augmentation, classifier analysis, and data imputation. Current $P^{-1}$ methods suffer from a fundamental limitation -- they can only generate a fixed surface-like structure in data space, which poorly covers the richness of this space. We address this by a new method that can `sweep' the data space under user control. Our method works generically for any $P$ technique and dataset, is controlled by two intuitive user-set parameters, and is simple to implement. We demonstrate it by an extensive application involving image manipulation for style transfer.", "AI": {"tldr": "提出了一种新的逆投影方法，可以控制性地在数据空间中扫掠，以改进高维图像数据的视觉探索。", "motivation": "当前的逆投影方法只能生成固定表面结构，在数据空间中的覆盖率较差。因此，研究旨在通过用户可控的方式扫掠整个数据空间来解决这个问题。", "method": "新方法可以与任何降维技术及数据集结合使用，并由两个直观的参数控制，易于实现。", "result": "展示了该方法在图像处理中广泛的应用，包括风格转换等任务中的表现。", "conclusion": "新的逆投影方法能够提供更丰富的视觉探索能力，提高了对高维图像数据的理解和利用。"}}
{"id": "2602.11137", "pdf": "https://arxiv.org/pdf/2602.11137", "abs": "https://arxiv.org/abs/2602.11137", "authors": ["Tessa Han", "Sebastian Bordt", "Hanlin Zhang", "Sham Kakade"], "title": "Weight Decay Improves Language Model Plasticity", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The prevailing paradigm in large language model (LLM) development is to pretrain a base model, then perform further training to improve performance and model behavior. However, hyperparameter optimization and scaling laws have been studied primarily from the perspective of the base model's validation loss, ignoring downstream adaptability. In this work, we study pretraining from the perspective of model plasticity, that is, the ability of the base model to successfully adapt to downstream tasks through fine-tuning. We focus on the role of weight decay, a key regularization parameter during pretraining. Through systematic experiments, we show that models trained with larger weight decay values are more plastic, meaning they show larger performance gains when fine-tuned on downstream tasks. This phenomenon can lead to counterintuitive trade-offs where base models that perform worse after pretraining can perform better after fine-tuning. Further investigation of weight decay's mechanistic effects on model behavior reveals that it encourages linearly separable representations, regularizes attention matrices, and reduces overfitting on the training data. In conclusion, this work demonstrates the importance of using evaluation metrics beyond cross-entropy loss for hyperparameter optimization and casts light on the multifaceted role of that a single optimization hyperparameter plays in shaping model behavior.", "AI": {"tldr": "研究了预训练中权重衰减参数对语言模型适应下游任务能力的影响，发现较大的权重衰减值可提高模型的泛化能力和适应性。", "motivation": "主流的大规模语言模型开发是先进行基础模型的预训练再进一步微调优化。然而，超参数优化和扩展规律研究主要基于基础模型验证损失的角度，忽略了后续任务的适应能力。本文旨在从塑性角度研究预训练过程中的权重衰减作用。", "method": "通过系统的实验分析不同权重衰减值对语言模型在下游任务中表现的影响，并探讨了其背后的机制。", "result": "发现较大权重衰减值的模型具有更强的任务适应性和更高的性能增益，同时揭示了权重衰减如何影响线性可分表示、注意力矩阵以及减少训练数据过拟合问题。", "conclusion": "研究表明使用仅基于交叉熵损失的评价指标不足以优化超参数，并强调了一个单一优化器参数在塑造模型行为中的复杂角色。"}}
{"id": "2602.11136", "pdf": "https://arxiv.org/pdf/2602.11136", "abs": "https://arxiv.org/abs/2602.11136", "authors": ["Jiayi Zhou", "Yang Sheng", "Hantao Lou", "Yaodong Yang", "Jie Fu"], "title": "FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight", "categories": ["cs.AI"], "comment": "27 pages", "summary": "As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hindered by a critical bottleneck: the translation from natural language requirements to formal specifications. This paper bridges this gap by proposing , a neuro-symbolic framework that employs a bidirectional Formal-of-Thought architecture: LLMs serve as specification compilers that top-down decompose high-level human intent into atomic, verifiable constraints, then bottom-up prove compliance using Dafny specifications and Z3 Satisfiability modulo theories solving, which produces mathematical guarantees rather than probabilistic scores. We validate across three benchmarks spanning behavioral safety, multi-domain constraint adherence, and agentic upward deception detection. Experiments on 7 agent models demonstrate that achieves an average improvement of 16.6% over LLM-as-a-Judge baselines, enables weak-to-strong generalization where a 7B judge achieves over 90% accuracy detecting deception from 72B agents, and provides near-linear safety improvement through iterative refinement.", "AI": {"tldr": "提出了FormalJudge框架，利用神经符号方法将自然语言要求转化为形式规范，并验证代理行为的安全性。", "motivation": "随着基于LLM的代理在高风险领域中的应用增加，确保其行为安全变得至关重要。现有的监督范式面临如何可靠地监督其他概率系统的挑战，而正式验证提供了一个可能的解决方案但存在将自然语言要求转化为形式规范的难题。", "method": "FormalJudge框架使用双向思维架构：LLM作为规格编译器将高层次的人类意图分解为原子、可验证约束，并使用Dafny和Z3证明合规性，从而产生数学保证而非概率分数。", "result": "实验显示在7个代理模型上平均改进了16.6%，并且展示出弱到强的泛化能力以及近线性的安全性提升。", "conclusion": "FormalJudge框架有效解决了自然语言要求转化为形式规范的问题，并提供了更可靠的安全监督方法。"}}
{"id": "2602.11130", "pdf": "https://arxiv.org/pdf/2602.11130", "abs": "https://arxiv.org/abs/2602.11130", "authors": ["Maximilian Plattner", "Fabian Paischer", "Johannes Brandstetter", "Arturs Berzins"], "title": "From Circuits to Dynamics: Understanding and Stabilizing Failure in 3D Diffusion Transformers", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Reliable surface completion from sparse point clouds underpins many applications spanning content creation and robotics. While 3D diffusion transformers attain state-of-the-art results on this task, we uncover that they exhibit a catastrophic mode of failure: arbitrarily small on-surface perturbations to the input point cloud can fracture the output into multiple disconnected pieces -- a phenomenon we call Meltdown. Using activation-patching from mechanistic interpretability, we localize Meltdown to a single early denoising cross-attention activation. We find that the singular-value spectrum of this activation provides a scalar proxy: its spectral entropy rises when fragmentation occurs and returns to baseline when patched. Interpreted through diffusion dynamics, we show that this proxy tracks a symmetry-breaking bifurcation of the reverse process. Guided by this insight, we introduce PowerRemap, a test-time control that stabilizes sparse point-cloud conditioning. We demonstrate that Meltdown persists across state-of-the-art architectures (WaLa, Make-a-Shape), datasets (GSO, SimJEB) and denoising strategies (DDPM, DDIM), and that PowerRemap effectively counters this failure with stabilization rates of up to 98.3%. Overall, this work is a case study on how diffusion model behavior can be understood and guided based on mechanistic analysis, linking a circuit-level cross-attention mechanism to diffusion-dynamics accounts of trajectory bifurcations.", "AI": {"tldr": "研究通过激活修补技术定位并修复了3D扩散变压器在处理稀疏点云时的断裂输出问题，提出了一种名为PowerRemap的方法来稳定模型。", "motivation": "揭示了3D扩散变压器在输入点云遭受微小扰动时会出现严重断裂的问题，并试图找到一种方法以提高其鲁棒性。", "method": "使用激活修补技术定位了导致输出断裂的单一早期去噪交叉注意力激活，提出了一个基于该激活的幂重映射（PowerRemap）控制方法来稳定模型。", "result": "实验结果显示，所提出的方法在不同的架构、数据集和去噪策略下均能有效降低断裂发生率，最高可达到98.3%。", "conclusion": "通过机制分析连接了电路级的交叉注意力机制与扩散动力学轨迹分叉模型，并展示了如何理解和引导扩散模型的行为。"}}
{"id": "2602.11125", "pdf": "https://arxiv.org/pdf/2602.11125", "abs": "https://arxiv.org/abs/2602.11125", "authors": ["Animesh Maiti", "Abhinav Chakraborty", "Bibhuti Das", "Subhash Bhagat", "Krishnendu Mukhopadhyaya"], "title": "Min-Sum Uniform Coverage Problem by Autonomous Mobile Robots", "categories": ["cs.DC", "cs.RO"], "comment": null, "summary": "We study the \\textit{min-sum uniform coverage} problem for a swarm of $n$ mobile robots on a given finite line segment and on a circle having finite positive radius, where the circle is given as an input. The robots must coordinate their movements to reach a uniformly spaced configuration that minimizes the total distance traveled by all robots. The robots are autonomous, anonymous, identical, and homogeneous, and operate under the \\textit{Look-Compute-Move} (LCM) model with \\textit{non-rigid} motion controlled by a fair asynchronous scheduler. They are oblivious and silent, possessing neither persistent memory nor a means of explicit communication. In the \\textbf{line-segment setting}, the \\textit{min-sum uniform coverage} problem requires placing the robots at uniformly spaced points along the segment so as to minimize the total distance traveled by all robots. In the \\textbf{circle setting} for this problem, the robots have to arrange themselves uniformly around the given circle to form a regular $n$-gon. There is no fixed orientation or designated starting vertex, and the goal is to minimize the total distance traveled by all the robots. We present a deterministic distributed algorithm that achieves uniform coverage in the line-segment setting with minimum total movement cost. For the circle setting, we characterize all initial configurations for which the \\textit{min-sum uniform coverage} problem is deterministically unsolvable under the considered robot model. For all the other remaining configurations, we provide a deterministic distributed algorithm that achieves uniform coverage while minimizing the total distance traveled. These results characterize the deterministic solvability of min-sum coverage for oblivious robots and achieve optimal cost whenever solvable.", "AI": {"tldr": "研究了在有限线段和圆上，多移动机器人最小总距离均匀覆盖问题的确定性分布式算法。", "motivation": "通过协调移动机器人的运动来实现最优配置，从而达到最小化所有机器人行驶的总距离的目标。", "method": "对于线段设置，提出了一个使总移动成本最少的确定性分布式算法。在圆设置中，则对无法解决的情况进行了特征描述，并为其余情况提供了相应的解决方案。", "result": "在线段设置中实现了最优配置，且总的移动成本最小；在圆设置中，表征了问题不可解的所有初始配置并对其他情况提供了解决方案。", "conclusion": "研究结果表明，在考虑的机器人模型下确定性地解决了最小时总覆盖问题，并在可行的情况下达到了最优性能。"}}
{"id": "2602.11124", "pdf": "https://arxiv.org/pdf/2602.11124", "abs": "https://arxiv.org/abs/2602.11124", "authors": ["Tianyi Xiong", "Shihao Wang", "Guilin Liu", "Yi Dong", "Ming Li", "Heng Huang", "Jan Kautz", "Zhiding Yu"], "title": "PhyCritic: Multimodal Critic Models for Physical AI", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid development of large multimodal models, reliable judge and critic models have become essential for open-ended evaluation and preference alignment, providing pairwise preferences, numerical scores, and explanatory justifications for assessing model-generated responses. However, existing critics are primarily trained in general visual domains such as captioning or image question answering, leaving physical AI tasks involving perception, causal reasoning, and planning largely underexplored. We introduce PhyCritic, a multimodal critic model optimized for physical AI through a two-stage RLVR pipeline: a physical skill warmup stage that enhances physically oriented perception and reasoning, followed by self-referential critic finetuning, where the critic generates its own prediction as an internal reference before judging candidate responses, improving judgment stability and physical correctness. Across both physical and general-purpose multimodal judge benchmarks, PhyCritic achieves strong performance gains over open-source baselines and, when applied as a policy model, further improves perception and reasoning in physically grounded tasks.", "AI": {"tldr": "本文介绍了PhyCritic，这是一种针对物理AI任务的多模态批评模型。", "motivation": "随着大规模多模态模型的发展，可靠的评判模型对于开放式评估和偏好对齐变得至关重要。然而，现有的评判模型主要在一般视觉领域进行训练，忽略了感知、因果推理和规划等物理AI任务的研究。", "method": "PhyCritic通过两阶段的RLVR流程优化：首先是一个物理技能预热阶段，增强物理导向的理解与推断；接着是自我参照批评微调阶段，在评判候选响应之前生成其自身的预测作为内部参考，提升判断稳定性和物理准确性。", "result": "在物理和通用多模态裁判基准测试中，PhyCritic相较于开源基线模型表现优异，并且当应用于策略模型时，进一步提升了感知与推理的准确性。", "conclusion": "PhyCritic在物理AI任务评估中的优越性能表明了专门针对这些领域的批评模型的重要性。"}}
{"id": "2602.11117", "pdf": "https://arxiv.org/pdf/2602.11117", "abs": "https://arxiv.org/abs/2602.11117", "authors": ["Di Chang", "Ji Hou", "Aljaz Bozic", "Assaf Neuberger", "Felix Juefei-Xu", "Olivier Maury", "Gene Wei-Chin Lin", "Tuur Stuyck", "Doug Roble", "Mohammad Soleymani", "Stephane Grabli"], "title": "HairWeaver: Few-Shot Photorealistic Hair Motion Synthesis with Sim-to-Real Guided Video Diffusion", "categories": ["cs.CV"], "comment": "Website: https://boese0601.github.io/hairweaver/", "summary": "We present HairWeaver, a diffusion-based pipeline that animates a single human image with realistic and expressive hair dynamics. While existing methods successfully control body pose, they lack specific control over hair, and as a result, fail to capture the intricate hair motions, resulting in stiff and unrealistic animations. HairWeaver overcomes this limitation using two specialized modules: a Motion-Context-LoRA to integrate motion conditions and a Sim2Real-Domain-LoRA to preserve the subject's photoreal appearance across different data domains. These lightweight components are designed to guide a video diffusion backbone while maintaining its core generative capabilities. By training on a specialized dataset of dynamic human motion generated from a CG simulator, HairWeaver affords fine control over hair motion and ultimately learns to produce highly realistic hair that responds naturally to movement. Comprehensive evaluations demonstrate that our approach sets a new state of the art, producing lifelike human hair animations with dynamic details.", "AI": {"tldr": "提出HairWeaver，一个基于扩散模型的管道，用于通过有限样本实现照片级真实感的人发动态合成。", "motivation": "现有方法虽然能够控制人体姿态，但在头发控制上存在不足，导致动画僵硬不自然。为此，作者设计了专门模块以解决这一问题。", "method": "HairWeaver采用Motion-Context-LoRA和Sim2Real-Domain-LoRA两个模块，结合视频扩散模型进行训练，实现对头发动态的精细控制，并保持图像的真实性。", "result": "通过专用数据集评估，HairWeaver在生成照片级真实感的人发动画方面表现出色，达到了新的技术前沿。", "conclusion": "HairWeaver成功实现了高质量的照片级真实感人发动画合成，为未来相关研究提供了新方向。"}}
{"id": "2602.11116", "pdf": "https://arxiv.org/pdf/2602.11116", "abs": "https://arxiv.org/abs/2602.11116", "authors": ["Alfonso Sciacchitano", "Liraz Mudrik", "Sean Kragelund", "Isaac Kaminer"], "title": "Multi-UAV Trajectory Optimization for Bearing-Only Localization in GPS Denied Environments", "categories": ["eess.SY", "cs.RO", "math.OC"], "comment": "38 pages, 7 figure, and 6 tables", "summary": "Accurate localization of maritime targets by unmanned aerial vehicles (UAVs) remains challenging in GPS-denied environments. UAVs equipped with gimballed electro-optical sensors are typically used to localize targets, however, reliance on these sensors increases mechanical complexity, cost, and susceptibility to single-point failures, limiting scalability and robustness in multi-UAV operations. This work presents a new trajectory optimization framework that enables cooperative target localization using UAVs with fixed, non-gimballed cameras operating in coordination with a surface vessel. This estimation-aware optimization generates dynamically feasible trajectories that explicitly account for mission constraints, platform dynamics, and out-of-frame events. Estimation-aware trajectories outperform heuristic paths by reducing localization error by more than a factor of two, motivating their use in cooperative operations. Results further demonstrate that coordinated UAVs with fixed, non-gimballed cameras achieve localization accuracy that meets or exceeds that of single gimballed systems, while substantially lowering system complexity and cost, enabling scalability, and enhancing mission resilience.", "AI": {"tldr": "本文提出了一个新的轨迹优化框架，用于在GPS缺失环境下使用固定相机的无人机进行目标定位。", "motivation": "利用装备有陀螺稳定光电传感器的无人机来定位海上目标面临着机械复杂性高、成本大以及单点故障风险等问题。本文旨在通过设计一种新的轨迹优化方法提高多架无人机协同作业时的目标定位精度和系统可靠性。", "method": "该框架生成了适应任务约束、平台动态及相机视野外事件的估计感知轨迹，这种方法优于传统的启发式路径规划。", "result": "实验结果显示，采用固定非陀螺稳定摄像机的协调无人机群可以达到或者超过单架装备有陀螺稳定系统的无人机的目标定位精度，同时显著降低了系统复杂度和成本。", "conclusion": "通过这种新方法，不仅可以提高目标定位的准确性，还可以实现多无人机任务中的可扩展性和增强的任务鲁棒性。"}}
{"id": "2602.11114", "pdf": "https://arxiv.org/pdf/2602.11114", "abs": "https://arxiv.org/abs/2602.11114", "authors": ["Jialiang Wang", "Shengxiang Xu", "Hanmo Liu", "Jiachuan Wang", "Yuyu Luo", "Shimin Di", "Min-Ling Zhang", "Lei Chen"], "title": "Learning to Compose for Cross-domain Agentic Workflow Generation", "categories": ["cs.MA", "cs.AI", "cs.LG", "cs.SE"], "comment": null, "summary": "Automatically generating agentic workflows -- executable operator graphs or codes that orchestrate reasoning, verification, and repair -- has become a practical way to solve complex tasks beyond what single-pass LLM generation can reliably handle. Yet what constitutes a good workflow depends heavily on the task distribution and the available operators. Under domain shift, current systems typically rely on iterative workflow refinement to discover a feasible workflow from a large workflow space, incurring high iteration costs and yielding unstable, domain-specific behavior. In response, we internalize a decompose-recompose-decide mechanism into an open-source LLM for cross-domain workflow generation. To decompose, we learn a compact set of reusable workflow capabilities across diverse domains. To recompose, we map each input task to a sparse composition over these bases to generate a task-specific workflow in a single pass. To decide, we attribute the success or failure of workflow generation to counterfactual contributions from learned capabilities, thereby capturing which capabilities actually drive success by their marginal effects. Across stringent multi-domain, cross-domain, and unseen-domain evaluations, our 1-pass generator surpasses SOTA refinement baselines that consume 20 iterations, while substantially reducing generation latency and cost.", "AI": {"tldr": "本文提出了一种基于LLM的跨域代理工作流生成方法，通过学习可重用的工作流能力并在单次迭代中重组这些能力来生成特定任务的工作流。", "motivation": "当前系统在领域转移时依赖于迭代工作流优化，这导致了高昂的成本和不稳定的行为。本文旨在减少迭代次数并提高工作效率与稳定性。", "method": "通过学习跨域工作的可重用能力集，并将输入任务映射为这些基础的能力组合，从而在一个步骤中生成特定的工作流。该方法还能够通过归因成功或失败来改进未来的工作流程生成。", "result": "在严格的多领域、跨领域和未见领域的评估下，所提出的一次性工作流生成器超越了SOTA迭代基准，并显著降低了生成延迟与成本。", "conclusion": "该方法证明了一种高效且稳定的方式来进行跨域代理工作流的自动化生成。"}}
{"id": "2602.11113", "pdf": "https://arxiv.org/pdf/2602.11113", "abs": "https://arxiv.org/abs/2602.11113", "authors": ["Daniel S. J. Derwent", "Simon Watson", "Bruno V. Adorno"], "title": "A receding-horizon multi-contact motion planner for legged robots in challenging environments", "categories": ["cs.RO"], "comment": "Submitted to Robotics and Autonomous Systems For supplementary video, see https://www.youtube.com/watch?v=RJp8DCmhDa4", "summary": "We present a novel receding-horizon multi-contact motion planner for legged robots in challenging scenarios, able to plan motions such as chimney climbing, navigating very narrow passages or crossing large gaps. Our approach adds new capabilities to the state of the art, including the ability to reactively re-plan in response to new information, and planning contact locations and whole-body trajectories simultaneously, simplifying the implementation and removing the need for post-processing or complex multi-stage approaches. Our method is more resistant to local minima problems than other potential field based approaches, and our quadratic-program-based posture generator returns nodes more quickly than those of existing algorithms. Rigorous statistical analysis shows that, with short planning horizons (e.g., one step ahead), our planner is faster than the state-of-the-art across all scenarios tested (between 45% and 98% faster on average, depending on the scenario), while planning less efficient motions (requiring 5% fewer to 700% more stance changes on average). In all but one scenario (Chimney Walking), longer planning horizons (e.g., four steps ahead) extended the average planning times (between 73% faster and 400% slower than the state-of-the-art) but resulted in higher quality motion plans (between 8% more and 47% fewer stance changes than the state-of-the-art).", "AI": {"tldr": "提出了一种新的滚动地平线多接触运动规划器，用于在具有挑战性的环境中规划腿式机器人的复杂动作。", "motivation": "为了提高腿式机器人在复杂环境中的适应性和效率，解决现有方法的局限性，如局部最优问题和复杂的多阶段处理流程。", "method": "采用滚动地平线策略进行实时重新规划，同时考虑接触点位置和全身轨迹。使用二次程序生成器快速计算姿态节点。", "result": "在所有测试场景中均表现出更快的速度（平均比现有技术快45%至98%），但在某些情况下动作效率较低。更长的规划视野能提高运动计划质量，但同时会增加规划时间。", "conclusion": "该方法提供了强大的实时重新规划能力，在复杂环境中实现了高效的腿式机器人运动规划，并在速度和效果之间找到了平衡点。"}}
{"id": "2602.11105", "pdf": "https://arxiv.org/pdf/2602.11105", "abs": "https://arxiv.org/abs/2602.11105", "authors": ["Divya Jyoti Bajpai", "Dhruv Bhardwaj", "Soumya Roy", "Tejas Duseja", "Harsh Agarwal", "Aashay Sandansing", "Manjesh Kumar Hanawal"], "title": "FastFlow: Accelerating The Generative Flow Matching Models with Bandit Inference", "categories": ["cs.CV"], "comment": "Accepted at International Conference on Learning Representations (ICLR) 2026", "summary": "Flow-matching models deliver state-of-the-art fidelity in image and video generation, but the inherent sequential denoising process renders them slower. Existing acceleration methods like distillation, trajectory truncation, and consistency approaches are static, require retraining, and often fail to generalize across tasks. We propose FastFlow, a plug-and-play adaptive inference framework that accelerates generation in flow matching models. FastFlow identifies denoising steps that produce only minor adjustments to the denoising path and approximates them without using the full neural network models used for velocity predictions. The approximation utilizes finite-difference velocity estimates from prior predictions to efficiently extrapolate future states, enabling faster advancements along the denoising path at zero compute cost. This enables skipping computation at intermediary steps. We model the decision of how many steps to safely skip before requiring a full model computation as a multi-armed bandit problem. The bandit learns the optimal skips to balance speed with performance. FastFlow integrates seamlessly with existing pipelines and generalizes across image generation, video generation, and editing tasks. Experiments demonstrate a speedup of over 2.6x while maintaining high-quality outputs. The source code for this work can be found at https://github.com/Div290/FastFlow.", "AI": {"tldr": "提出FastFlow，一种用于流匹配模型的自适应推理框架，通过跳过无显著改进的去噪步骤来加速图像和视频生成。", "motivation": "现有加速方法依赖于重新训练且无法在任务间泛化。作者旨在开发一个不需要重训、可插拔的方法以提高流匹配模型的速度。", "method": "FastFlow利用有限差分速度估计进行近似计算，跳过无显著改进的去噪步骤，并通过多臂赌博机问题来决定如何安全地跳过这些步骤。", "result": "实验表明，FastFlow能够在保持高质量输出的同时实现超过2.6倍的速度提升。", "conclusion": "FastFlow作为一种插件式方法，在多个任务中展示了卓越性能和泛化能力。"}}
{"id": "2602.11103", "pdf": "https://arxiv.org/pdf/2602.11103", "abs": "https://arxiv.org/abs/2602.11103", "authors": ["Wayne Chi", "Yixiong Fang", "Arnav Yayavaram", "Siddharth Yayavaram", "Seth Karten", "Qiuhong Anna Wei", "Runkun Chen", "Alexander Wang", "Valerie Chen", "Ameet Talwalkar", "Chris Donahue"], "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development", "categories": ["cs.AI", "cs.CL", "cs.SE"], "comment": null, "summary": "Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench, the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials. Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development, with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity, with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development.", "AI": {"tldr": "GameDevBench是一个评估代理在游戏开发任务上的能力的基准测试，它包含132个从网络和视频教程中提取的任务。", "motivation": "当前编码代理的发展迅速，但其多模态理解的能力仍然不足。缺乏能够同时涵盖软件开发复杂性和深度多模态理解需求的评估环境是一个关键挑战。游戏开发提供了这样一个评估平台，因为代理必须在大型密集代码库中导航，并处理如着色器、精灵和动画等内在多模态资产。", "method": "提出了GameDevBench，这是一个基于网络和视频教程中的132个任务的游戏开发基准测试。这些任务需要显著的多模态理解能力并且非常复杂，平均解决方案所需的代码行数和文件更改量是先前软件开发基准测试的三倍以上。", "result": "最优秀的代理仅能解决54.5%的任务。发现任务难度与多模态复杂性之间存在强相关性，成功率从游戏玩法导向任务的46.9%下降到2D图形任务的31.6%。为了提高多模态能力，引入了两种基于图像和视频的反馈机制，简单但有效。", "conclusion": "尽管有这些挑战，代理在进行改进后取得了显著进步。GameDevBench作为一个公开平台发布，以支持进一步研究代理游戏开发的能力。"}}
{"id": "2602.11096", "pdf": "https://arxiv.org/pdf/2602.11096", "abs": "https://arxiv.org/abs/2602.11096", "authors": ["Soumya Suvra Ghosal", "Souradip Chakraborty", "Vaibhav Singh", "Furong Huang", "Dinesh Manocha", "Amrit Singh Bedi"], "title": "Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) based post-training for explicit chain-of-thought (e.g., GRPO) improves the reasoning ability of multimodal large-scale reasoning models (MLRMs). But recent evidence shows that it can simultaneously degrade safety alignment and increase jailbreak success rates. We propose SafeThink, a lightweight inference-time defense that treats safety recovery as a satisficing constraint rather than a maximization objective. SafeThink monitors the evolving reasoning trace with a safety reward model and conditionally injects an optimized short corrective prefix (\"Wait, think safely\") only when the safety threshold is violated. In our evaluations across six open-source MLRMs and four jailbreak benchmarks (JailbreakV-28K, Hades, FigStep, and MM-SafetyBench), SafeThink reduces attack success rates by 30-60% (e.g., LlamaV-o1: 63.33% to 5.74% on JailbreakV-28K, R1-Onevision: 69.07% to 5.65% on Hades) while preserving reasoning performance (MathVista accuracy: 65.20% to 65.00%). A key empirical finding from our experiments is that safety recovery is often only a few steering steps away: intervening in the first 1-3 reasoning steps typically suffices to redirect the full generation toward safe completions.", "AI": {"tldr": "本文提出了一种轻量级的推理时防御机制SafeThink，用于改善多模态大规模推理模型的安全性。", "motivation": "基于强化学习的训练后处理虽然能提高推理能力，但同时也可能降低安全性并增加逃脱成功的概率。因此需要一种方法来平衡安全性和性能。", "method": "SafeThink通过监测推理过程中的安全奖励模型，并在违反阈值时插入优化的安全纠正前缀来进行干预。", "result": "实验表明，SafeThink能够在减少攻击成功率30-60%的同时保持推理准确性。干预仅需1-3个步骤即可使生成向安全完成转变。", "conclusion": "SafeThink是一种有效的防御机制，可以在不牺牲性能的情况下提高模型的安全性。"}}
{"id": "2602.11090", "pdf": "https://arxiv.org/pdf/2602.11090", "abs": "https://arxiv.org/abs/2602.11090", "authors": ["Carlos Stein Brito"], "title": "Direct Learning of Calibration-Aware Uncertainty for Neural PDE Surrogates", "categories": ["cs.LG", "cs.AI", "cs.CE", "stat.CO"], "comment": "13 pages, 11 figures", "summary": "Neural PDE surrogates are often deployed in data-limited or partially observed regimes where downstream decisions depend on calibrated uncertainty in addition to low prediction error. Existing approaches obtain uncertainty through ensemble replication, fixed stochastic noise such as dropout, or post hoc calibration. Cross-regularized uncertainty learns uncertainty parameters during training using gradients routed through a held-out regularization split. The predictor is optimized on the training split for fit, while low-dimensional uncertainty controls are optimized on the regularization split to reduce train-test mismatch, yielding regime-adaptive uncertainty without per-regime noise tuning. The framework can learn continuous noise levels at the output head, within hidden features, or within operator-specific components such as spectral modes. We instantiate the approach in Fourier Neural Operators and evaluate on APEBench sweeps over observed fraction and training-set size. Across these sweeps, the learned predictive distributions are better calibrated on held-out splits and the resulting uncertainty fields concentrate in high-error regions in one-step spatial diagnostics.", "AI": {"tldr": "本文提出了一种直接学习校准感知不确定性的方法，用于神经偏微分方程代理。", "motivation": "在数据有限或部分观测的情况下，下游决策依赖于校准的不确定性以及低预测误差。现有方法通过集成复制、固定随机噪声或事后校正获得不确定性。", "method": "该框架通过交叉正则化学习，在训练阶段使用梯度路由到保留的正则化分割来优化模型和不确定参数，从而在不同场景下自适应地调整不确定性而无需针对每个场景进行噪声调整。", "result": "实验表明，所学的概率分布在校验集上具有更好的校准效果，并且生成的不确定性集中在高误差区域。", "conclusion": "该方法提高了神经偏微分方程代理在数据有限或部分观测情况下的性能和可靠性。"}}
{"id": "2602.11089", "pdf": "https://arxiv.org/pdf/2602.11089", "abs": "https://arxiv.org/abs/2602.11089", "authors": ["Yicheng Chen", "Zerun Ma", "Xinchen Xie", "Yining Li", "Kai Chen"], "title": "DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the \\emph{data recipe}, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipes remains largely manual and labor-intensive, requiring substantial human expertise and iteration. To bridge this gap, we formulate \\emph{end-to-end data recipe generation} for LLM adaptation. Given a target benchmark and a pool of available data sources, a model is required to output a complete data recipe that adapts a base LLM to the target task. We present DataChef-32B, which performs online reinforcement learning using a proxy reward that predicts downstream performance for candidate recipes. Across six held-out tasks, DataChef-32B produces practical recipes that reach comparable downstream performance to those curated by human experts. Notably, the recipe from DataChef-32B adapts Qwen3-1.7B-Base to the math domain, achieving 66.7 on AIME'25 and surpassing Qwen3-1.7B. This work sheds new light on automating LLM training and developing self-evolving AI systems.", "AI": {"tldr": "论文提出了一种名为DataChef的系统，通过强化学习自动生成用于大语言模型（LLM）适应的数据处理流程。", "motivation": "当前LLM训练中数据处理流程的设计通常依赖于人工和经验，效率低下。为此，作者希望通过自动化生成最佳数据处理方案来提高LLM性能。", "method": "DataChef通过在线强化学习方法利用代理奖励预测下游任务的性能，并据此自动生成优化的数据处理流程。", "result": "实验结果表明，由DataChef生成的数据处理流程在多个任务上达到了与专家设计相媲美的效果，在某些情况下甚至超过了人工定制方案的表现。", "conclusion": "该研究展示了通过自动化技术来提升LLM训练质量和效率的潜力，并推动了自进化AI系统的开发。"}}
{"id": "2602.11087", "pdf": "https://arxiv.org/pdf/2602.11087", "abs": "https://arxiv.org/abs/2602.11087", "authors": ["Jianxun Wang", "Grant C. Forbes", "Leonardo Villalobos-Arias", "David L. Roberts"], "title": "General Flexible $f$-divergence for Challenging Offline RL Datasets with Low Stochasticity and Diverse Behavior Policies", "categories": ["cs.LG", "cs.AI"], "comment": "Extended version of the full paper with the appendix accepted at AAMAS 2026", "summary": "Offline RL algorithms aim to improve upon the behavior policy that produces the collected data while constraining the learned policy to be within the support of the dataset. However, practical offline datasets often contain examples with little diversity or limited exploration of the environment, and from multiple behavior policies with diverse expertise levels. Limited exploration can impair the offline RL algorithm's ability to estimate \\textit{Q} or \\textit{V} values, while constraining towards diverse behavior policies can be overly conservative. Such datasets call for a balance between the RL objective and behavior policy constraints. We first identify the connection between $f$-divergence and optimization constraint on the Bellman residual through a more general Linear Programming form for RL and the convex conjugate. Following this, we introduce the general flexible function formulation for the $f$-divergence to incorporate an adaptive constraint on algorithms' learning objectives based on the offline training dataset. Results from experiments on the MuJoCo, Fetch, and AdroitHand environments show the correctness of the proposed LP form and the potential of the flexible $f$-divergence in improving performance for learning from a challenging dataset when applied to a compatible constrained optimization algorithm.", "AI": {"tldr": "本文提出了一个适应性约束的$f$-散度，以解决离线强化学习算法在处理多样化行为策略和有限探索数据集时遇到的问题。", "motivation": "实际离线数据集中可能包含行为策略多样性低或环境探索不足的情况。这些情况可能导致离线RL算法难以估计Q或V值，并且限制向多样化的行为策略可能会过于保守。因此需要一种平衡方法以实现更好的性能。", "method": "通过更通用的线性规划形式和凸共轭，本文建立了$f$-散度与Bellman残差优化约束之间的联系，并引入了一种一般灵活函数形式的$f$-散度来适应离线训练数据集的算法学习目标。这种方法可以调整约束以平衡强化学习的目标和行为策略限制。", "result": "实验结果表明，所提出的LP形式正确有效，并且使用灵活$f$-散度能够提升从具有挑战性的数据集中学习时的表现。", "conclusion": "通过引入适应性约束的$f$-散度，本文提供了一种方法来克服离线强化学习中多样化行为策略和有限探索带来的困难。这种方法在实验环境中表现出了潜在的优势。"}}
{"id": "2602.11086", "pdf": "https://arxiv.org/pdf/2602.11086", "abs": "https://arxiv.org/abs/2602.11086", "authors": ["Robyn Larracy", "Eve MacDonald", "Angkoon Phinyomark", "Saeid Rezaei", "Mahdi Laghaei", "Ali Hajighasem", "Aaron Tabor", "Erik Scheme"], "title": "First International StepUP Competition for Biometric Footstep Recognition: Methods, Results and Remaining Challenges", "categories": ["cs.CV", "cs.LG"], "comment": "to be published in 2025 IEEE International Joint Conference on Biometrics (IJCB)", "summary": "Biometric footstep recognition, based on a person's unique pressure patterns under their feet during walking, is an emerging field with growing applications in security and safety. However, progress in this area has been limited by the lack of large, diverse datasets necessary to address critical challenges such as generalization to new users and robustness to shifts in factors like footwear or walking speed. The recent release of the UNB StepUP-P150 dataset, the largest and most comprehensive collection of high-resolution footstep pressure recordings to date, opens new opportunities for addressing these challenges through deep learning. To mark this milestone, the First International StepUP Competition for Biometric Footstep Recognition was launched. Competitors were tasked with developing robust recognition models using the StepUP-P150 dataset that were then evaluated on a separate, dedicated test set designed to assess verification performance under challenging variations, given limited and relatively homogeneous reference data. The competition attracted global participation, with 23 registered teams from academia and industry. The top-performing team, Saeid_UCC, achieved the best equal error rate (EER) of 10.77% using a generative reward machine (GRM) optimization strategy. Overall, the competition showcased strong solutions, but persistent challenges in generalizing to unfamiliar footwear highlight a critical area for future work.", "AI": {"tldr": "首次国际StepUP步态识别竞赛，使用UNB StepUP-P150数据集评估基于脚步压力模式的生物特征识别技术。", "motivation": "推动步态识别领域的发展，解决现有挑战如新用户泛化能力和在不同鞋类或行走速度下的鲁棒性问题。", "method": "组织国际StepUP竞赛，利用UNB StepUP-P150数据集评估参赛团队的生物特征识别模型，并用专门测试集检验其性能。", "result": "Saeid_UCC团队使用生成奖励机（GRM）优化策略获得了最佳等错误率（EER），为10.77%。竞赛展示了强大的解决方案，但也表明了在不熟悉鞋类下的泛化问题仍然存在。", "conclusion": "通过此次竞赛证明步态识别技术有进展但仍有挑战，特别是在适应不同鞋类方面还需更多研究工作。"}}
{"id": "2602.11084", "pdf": "https://arxiv.org/pdf/2602.11084", "abs": "https://arxiv.org/abs/2602.11084", "authors": ["Yuheng Luo", "Shuyan Li", "Zhong Cao"], "title": "GRASP: group-Shapley feature selection for patients", "categories": ["cs.LG", "cs.AI"], "comment": "5 pages, 4 figures, 2 tables", "summary": "Feature selection remains a major challenge in medical prediction, where existing approaches such as LASSO often lack robustness and interpretability. We introduce GRASP, a novel framework that couples Shapley value driven attribution with group $L_{21}$ regularization to extract compact and non-redundant feature sets. GRASP first distills group level importance scores from a pretrained tree model via SHAP, then enforces structured sparsity through group $L_{21}$ regularized logistic regression, yielding stable and interpretable selections. Extensive comparisons with LASSO, SHAP, and deep learning based methods show that GRASP consistently delivers comparable or superior predictive accuracy, while identifying fewer, less redundant, and more stable features.", "AI": {"tldr": "该论文提出了GRASP框架，利用Shapley值驱动的属性归因与群体L_{21}正则化相结合来提取紧凑且非冗余的特征集合。", "motivation": "在医学预测中，现有的方法如LASSO通常缺乏鲁棒性和可解释性。为了克服这些问题，提出了GRASP框架以提高准确性和模型的透明度。", "method": "GRASP首先通过SHAP从预训练的树模型中提取群体层次的重要性分数，然后使用具有群体L_{21}正则化的逻辑回归来执行结构化稀疏选择。", "result": "与LASSO、SHAP和基于深度学习的方法相比，GRASP在提供可比或更好的预测准确性的同时，能够识别出更少的特征，并且这些特征更加稳定和不冗余。", "conclusion": "GRASP框架不仅提升了医学预测中的模型性能，还增强了结果的解释性与稳定性。"}}
{"id": "2602.11082", "pdf": "https://arxiv.org/pdf/2602.11082", "abs": "https://arxiv.org/abs/2602.11082", "authors": ["Unal Artan", "Martin Magnusson", "Joshua A. Marshall"], "title": "Digging for Data: Experiments in Rock Pile Characterization Using Only Proprioceptive Sensing in Excavation", "categories": ["cs.RO", "eess.SP"], "comment": "Accepted for publication in the IEEE Transactions on Field Robotics", "summary": "Characterization of fragmented rock piles is a fundamental task in the mining and quarrying industries, where rock is fragmented by blasting, transported using wheel loaders, and then sent for further processing. This field report studies a novel method for estimating the relative particle size of fragmented rock piles from only proprioceptive data collected while digging with a wheel loader. Rather than employ exteroceptive sensors (e.g., cameras or LiDAR sensors) to estimate rock particle sizes, the studied method infers rock fragmentation from an excavator's inertial response during excavation. This paper expands on research that postulated the use of wavelet analysis to construct a unique feature that is proportional to the level of rock fragmentation. We demonstrate through extensive field experiments that the ratio of wavelet features, constructed from data obtained by excavating in different rock piles with different size distributions, approximates the ratio of the mean particle size of the two rock piles. Full-scale excavation experiments were performed with a battery electric, 18-tonne capacity, load-haul-dump (LHD) machine in representative conditions in an operating quarry. The relative particle size estimates generated with the proposed sensing methodology are compared with those obtained from both a vision-based fragmentation analysis tool and from sieving of sampled materials.", "AI": {"tldr": "研究通过挖掘仅使用内感受数据来估计碎石堆中岩石颗粒的相对大小的方法", "motivation": "在采矿和采石行业中，对破碎岩堆进行特征描述是一项基本任务。现有方法依赖于视觉或其他外部传感器，但本文提出了一种新的方法，该方法仅利用挖掘机内部惯性响应的数据来推断岩石碎片的大小分布", "method": "研究使用小波分析构造了一个独特的特征，并通过在具有不同粒径分布的不同碎石堆中进行挖掘实验验证了这种方法。在操作中的采石场进行了全尺寸挖掘试验，并与基于视觉和筛分方法的结果进行了比较", "result": "实验表明，通过挖掘仅使用内感受数据所获得的相对颗粒大小估计值与视觉工具和样品筛选所得结果相当", "conclusion": "该研究展示了一种新的方法，可以利用挖掘机内部响应的数据来估计岩石碎片的大小分布，并且这种方法在实际操作中是可行的"}}
{"id": "2602.11081", "pdf": "https://arxiv.org/pdf/2602.11081", "abs": "https://arxiv.org/abs/2602.11081", "authors": ["Sebastian Wind", "Jeta Sopa", "Laurin Schmid", "Quirin Jackl", "Sebastian Kiefer", "Fei Wu", "Martin Mayr", "Harald Köstler", "Gerhard Wellein", "Andreas Maier", "Soroosh Tayebi Arasteh"], "title": "SteuerLLM: Local specialized large language model for German tax law analysis", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) demonstrate strong general reasoning and language understanding, yet their performance degrades in domains governed by strict formal rules, precise terminology, and legally binding structure. Tax law exemplifies these challenges, as correct answers require exact statutory citation, structured legal argumentation, and numerical accuracy under rigid grading schemes. We algorithmically generate SteuerEx, the first open benchmark derived from authentic German university tax law examinations. SteuerEx comprises 115 expert-validated examination questions spanning six core tax law domains and multiple academic levels, and employs a statement-level, partial-credit evaluation framework that closely mirrors real examination practice. We further present SteuerLLM, a domain-adapted LLM for German tax law trained on a large-scale synthetic dataset generated from authentic examination material using a controlled retrieval-augmented pipeline. SteuerLLM (28B parameters) consistently outperforms general-purpose instruction-tuned models of comparable size and, in several cases, substantially larger systems, demonstrating that domain-specific data and architectural adaptation are more decisive than parameter scale for performance on realistic legal reasoning tasks. All benchmark data, training datasets, model weights, and evaluation code are released openly to support reproducible research in domain-specific legal artificial intelligence. A web-based demo of SteuerLLM is available at https://steuerllm.i5.ai.fau.de.", "AI": {"tldr": "开发了一种针对德国税法的专业大型语言模型SteuerLLM，该模型在真实法律推理任务中表现优异。", "motivation": "大模型在面对严格形式规则、精确术语和法律结构时性能下降，特别是在税收法规领域。作者旨在通过生成特定领域的数据和架构适应来提升其性能。", "method": "创建了一个算法生成的SteuerEx基准测试，并使用从真实考试材料中获取的数据训练了28B参数的SteuerLLM模型，该模型在真实性法律推理任务中表现出色。", "result": "SteuerLLM在各种规模上的通用指令调优模型中表现更好，证明特定领域的数据和架构适应比参数规模更重要。", "conclusion": "展示了通过领域特定的数据集和架构优化来训练的大型语言模型在处理真实法律推理任务中的优越性能。所有相关资源均已公开以支持可重复研究。"}}
{"id": "2602.11079", "pdf": "https://arxiv.org/pdf/2602.11079", "abs": "https://arxiv.org/abs/2602.11079", "authors": ["Frank Xiao", "Santiago Aranguri"], "title": "In-the-Wild Model Organisms: Mitigating Undesirable Emergent Behaviors in Production LLM Post-Training via Data Attribution", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose activation-based data attribution, a method that traces behavioral changes in post-trained language models to responsible training datapoints. By computing activation-difference vectors for both test prompts and preference pairs and ranking by cosine similarity, we identify datapoints that cause specific behaviors and validate these attributions causally by retraining with modified data. Clustering behavior-datapoint similarity matrices also enables unsupervised discovery of emergent behaviors. Applying this to OLMo 2's production DPO training, we surfaced distractor-triggered compliance: a harmful behavior where the model complies with dangerous requests when benign formatting instructions are appended. Filtering top-ranked datapoints reduces this behavior by 63% while switching their labels achieves 78%. Our method outperforms gradient-based attribution and LLM-judge baselines while being over 10 times cheaper than both. This in-the-wild model organism - emerging from contaminated preference data rather than deliberate injection - provides a realistic benchmark for safety techniques.", "AI": {"tldr": "本文提出了一种基于激活的数据归因方法，用于追踪语言模型训练后的特定行为变化，并通过数据过滤和标签修改来减少有害行为。", "motivation": "动机在于识别和缓解大规模语言模型在生产环境中的潜在危险行为，如对危险请求的不当响应。通过追溯这些行为到原始训练数据点以实现控制。", "method": "使用激活差异向量计算并基于余弦相似度排序来定位导致特定行为的数据点；验证归因的有效性并通过重新训练修改后的数据集来实现。此外，利用聚类技术发现新的潜在行为模式。", "result": "该方法在减少OLMo2模型中的有害行为方面表现出显著效果：通过过滤高排名的训练样本可降低63%，而改变这些数据点的标签则可将负面影响降至78%以下；相比梯度归因和LLM判决基线，这种方法更高效且成本更低。", "conclusion": "本文展示了一种有效的策略用于识别和缓解大规模语言模型中的潜在风险行为，并提出一个基于实际污染偏好数据的真实基准来测试安全技术的有效性。"}}
{"id": "2602.11076", "pdf": "https://arxiv.org/pdf/2602.11076", "abs": "https://arxiv.org/abs/2602.11076", "authors": ["Kavan Fatehi", "Mostafa Rahmani Ghourtani", "Amir Sonee", "Poonam Yadav", "Alessandra M Russo", "Hamed Ahmadi", "Radu Calinescu"], "title": "Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing", "categories": ["eess.SY", "cs.AI", "eess.SP"], "comment": "This work has been accepted to appear in the IEEE International Conference on Communications (ICC)", "summary": "Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \\emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized attention mechanisms into multi-agent slice control and surfaces them as zero-cost, faithful explanations. The framework operates across O-RAN timescales with a three-phase strategy: predictive, reactive, and inter-slice optimization. A URLLC case study shows AE-MAPPO resolves a latency spike in $18$ms, restores latency to $0.98$ms with $99.9999\\%$ reliability, and reduces troubleshooting time by $93\\%$ while maintaining eMBB and mMTC continuity. These results confirm AE-MAPPO's ability to combine SLA compliance with inherent interpretability, enabling trustworthy and real-time automation for 6G RAN slicing.", "AI": {"tldr": "本文提出了一种基于注意力机制的多代理PPO算法，用于解决6G RAN切片中的延迟峰值问题。", "motivation": "在6G无线接入网络中，需要严格的服务水平协议来满足不同切片的需求。然而，现有的深度强化学习和可解释RL方法难以诊断和解决突发性的延迟峰值问题。", "method": "本文提出了带有六个专门注意力机制的多代理增强PPO框架（AE-MAPPO），该框架能够对6G RAN进行预测、反应及跨切片优化，并且提供了零成本的忠实解释。", "result": "通过一个URLLC案例研究，AE-MAPPO在18毫秒内解决了延迟峰值问题，恢复了99.9999%可靠性的0.98毫秒延迟，将故障排除时间减少了93%，同时保持了eMBB和mMTC的连续性。", "conclusion": "AE-MAPPO结合了服务水平协议的一致性和内在可解释性，能够提供可信且实时自动化的方法来解决6G RAN切片中的问题。"}}
{"id": "2602.11075", "pdf": "https://arxiv.org/pdf/2602.11075", "abs": "https://arxiv.org/abs/2602.11075", "authors": ["Jiazhi Yang", "Kunyang Lin", "Jinwei Li", "Wencong Zhang", "Tianwei Lin", "Longyan Wu", "Zhizhong Su", "Hao Zhao", "Ya-Qin Zhang", "Li Chen", "Ping Luo", "Xiangyu Yue", "Hongyang Li"], "title": "RISE: Self-Improving Robot Policy with Compositional World Model", "categories": ["cs.RO"], "comment": "Project page: https://opendrivelab.com/kai0-rl/", "summary": "Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic manipulation tasks, where minor execution deviations can compound into failures. While reinforcement learning (RL) offers a principled path to robustness, on-policy RL in the physical world is constrained by safety risk, hardware cost, and environment reset. To bridge this gap, we present RISE, a scalable framework of robotic reinforcement learning via imagination. At its core is a Compositional World Model that (i) predicts multi-view future via a controllable dynamics model, and (ii) evaluates imagined outcomes with a progress value model, producing informative advantages for the policy improvement. Such compositional design allows state and value to be tailored by best-suited yet distinct architectures and objectives. These components are integrated into a closed-loop self-improving pipeline that continuously generates imaginary rollouts, estimates advantages, and updates the policy in imaginary space without costly physical interaction. Across three challenging real-world tasks, RISE yields significant improvement over prior art, with more than +35% absolute performance increase in dynamic brick sorting, +45% for backpack packing, and +35% for box closing, respectively.", "AI": {"tldr": "RISE是一种通过想象力实现的机器人强化学习框架，用于提高接触密集和动态操作任务中的策略稳健性。", "motivation": "尽管模型容量和数据采集量不断增加，但视觉语言行动（VLA）模型在接触丰富和动态操作任务中仍然脆弱。为了克服物理世界中基于政策的强化学习的安全风险、硬件成本和环境重置问题，提出了RISE框架。", "method": "核心是一个可组合的世界模型，它通过可控的动力学模型预测多视角未来，并通过进度值模型评估想象中的结果，从而生成策略改进的信息优势。该设计允许状态和价值根据最合适的架构和目标进行定制，形成闭环自提升流程，无需昂贵的物理交互即可在虚拟空间中生成假想回放、估计优势并更新政策。", "result": "RISE在三个具有挑战性的现实世界任务中表现出显著改善，动态砖块分类性能提高超过35%，背包打包提高45%，盒子关闭提高35%。", "conclusion": "通过想象实现的强化学习框架可以显著提升机器人在复杂操作任务中的表现和稳健性。"}}
{"id": "2602.11074", "pdf": "https://arxiv.org/pdf/2602.11074", "abs": "https://arxiv.org/abs/2602.11074", "authors": ["Bingyi Han", "Ying Ma", "Simon Coghlan", "Dana McKay", "George Buchanan", "Wally Smith"], "title": "AI Sensing and Intervention in Higher Education: Student Perceptions of Learning Impacts, Affective Responses, and Ethical Priorities", "categories": ["cs.HC"], "comment": "Accepted to CHI 2026. This is the accepted author version", "summary": "AI technologies that sense student attention and emotions to enable more personalised teaching interventions are increasingly promoted, but raise pressing questions about student learning, well-being, and ethics. In particular, students' perspectives about AI sensing-intervention in learning are often overlooked. We conducted an online mixed-method experiment with Australian university students (N=132), presenting video scenarios varying by whether sensing was used (in-use vs. not-in-use), sensing modality (gaze-based attention detection vs. facial-based emotion detection), and intervention (by digital device vs. teacher). Participants also completed pairwise ranking tasks to prioritise six core ethical concerns. Findings revealed that students valued targeted intervention but responded negatively to AI monitoring, regardless of sensing methods. Students preferred system-generated hints over teacher-initiated assistance, citing learning agency and social embarrassment concerns. Students' ethical considerations prioritised autonomy and privacy, followed by transparency, accuracy, fairness, and learning beneficence. We advocate designing customisable, social-sensitive, non-intrusive systems that preserve student control, agency, and well-being.", "AI": {"tldr": "研究探讨了大学生对AI感知干预学习的态度和伦理优先级。", "motivation": "探讨学生视角下的AI感知-干预在教育中的影响，关注学生的学习、幸福感和道德问题。", "method": "通过在线混合方法实验，利用视频场景展示不同情况并收集参与者排名任务的反馈，以评估其观点。", "result": "发现学生虽然重视个性化的教学干预，但对AI监控持负面态度；更偏好由系统生成的小提示而非教师直接帮助，并强调自治、隐私等伦理考量。", "conclusion": "建议设计可定制化、社会敏感且不侵犯性的系统，保障学生的控制权、自主性和福祉。"}}
{"id": "2602.11073", "pdf": "https://arxiv.org/pdf/2602.11073", "abs": "https://arxiv.org/abs/2602.11073", "authors": ["Junfei Wu", "Jian Guan", "Qiang Liu", "Shu Wu", "Liang Wang", "Wei Wu", "Tienie Tan"], "title": "Chatting with Images for Introspective Visual Thinking", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Current large vision-language models (LVLMs) typically rely on text-only reasoning based on a single-pass visual encoding, which often leads to loss of fine-grained visual information. Recently the proposal of ''thinking with images'' attempts to alleviate this limitation by manipulating images via external tools or code; however, the resulting visual states are often insufficiently grounded in linguistic semantics, impairing effective cross-modal alignment - particularly when visual semantics or geometric relationships must be reasoned over across distant regions or multiple images. To address these challenges, we propose ''chatting with images'', a new framework that reframes visual manipulation as language-guided feature modulation. Under the guidance of expressive language prompts, the model dynamically performs joint re-encoding over multiple image regions, enabling tighter coupling between linguistic reasoning and visual state updates. We instantiate this paradigm in ViLaVT, a novel LVLM equipped with a dynamic vision encoder explicitly designed for such interactive visual reasoning, and trained it with a two-stage curriculum combining supervised fine-tuning and reinforcement learning to promote effective reasoning behaviors. Extensive experiments across eight benchmarks demonstrate that ViLaVT achieves strong and consistent improvements, with particularly pronounced gains on complex multi-image and video-based spatial reasoning tasks.", "AI": {"tldr": "提出了一种新的框架'聊天图像',通过语言引导的特征调制来增强视觉推理能力，改进了大视觉-语言模型（LVLM）在处理复杂多图和视频场景中的空间推理任务的表现。", "motivation": "当前的大视觉-语言模型依赖于单一路径的视觉编码，导致细粒度的视觉信息丢失。提出'思考图像'的方法试图通过操作图片来改善这一局限，但这种方法得到的视觉状态往往没有充分与语言语义结合，影响了跨模态对齐。", "method": "引入了一种新的框架'聊天图像',该框架将视觉操作重新定义为受语言引导的特征调制。通过表达性的语言提示，模型能够在多个图像区域进行联合再编码，实现语言推理和视觉状态更新之间的更紧密耦合。提出了一个新的LVLM-ViLaVT，并采用两阶段课程训练方法（监督微调与强化学习结合）来促进有效的推理行为。", "result": "实验结果表明，ViLaVT在八个基准上取得了显著的改善，在复杂多图和视频空间推理任务上的提升尤为突出。", "conclusion": "通过语言引导的特征调制，'聊天图像'框架能够更好地处理视觉信息，并有效提高了LVLM模型在跨模态对齐中的表现。"}}
{"id": "2602.11072", "pdf": "https://arxiv.org/pdf/2602.11072", "abs": "https://arxiv.org/abs/2602.11072", "authors": ["Tom Labiausse", "Romain Fabre", "Yannick Estève", "Alexandre Défossez", "Neil Zeghidour"], "title": "Simultaneous Speech-to-Speech Translation Without Aligned Data", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "See inference code at: https://github.com/kyutai-labs/hibiki-zero", "summary": "Simultaneous speech translation requires translating source speech into a target language in real-time while handling non-monotonic word dependencies. Traditional approaches rely on supervised training with word-level aligned data, which is difficult to collect at scale and thus depends on synthetic alignments using language-specific heuristics that are suboptimal. We propose Hibiki-Zero, which eliminates the need for word-level alignments entirely. This fundamentally simplifies the training pipeline and enables seamless scaling to diverse languages with varying grammatical structures, removing the bottleneck of designing language-specific alignment heuristics. We first train on sentence-level aligned data to learn speech translation at high latency, then apply a novel reinforcement learning strategy using GRPO to optimize latency while preserving translation quality. Hibiki-Zero achieves state-of-the-art performance in translation accuracy, latency, voice transfer, and naturalness across five X-to-English tasks. Moreover, we demonstrate that our model can be adapted to support a new input language with less than 1000h of speech. We provide examples, model weights, inference code and we release a benchmark containing 45h of multilingual data for speech translation evaluation.", "AI": {"tldr": "提出了一种名为Hibiki-Zero的方法，用于同时翻译源语言语音到目标语言而不依赖于对齐数据。", "motivation": "传统的同步语音翻译方法需要大量的词级对齐数据进行监督训练，这在实际操作中很难大规模收集，并且依赖于特定语言的启发式对齐策略。这些限制了系统的扩展性和灵活性。", "method": "首先利用句级对齐的数据进行高延迟下的语音翻译学习，然后采用了一种新的基于GRPO的强化学习策略来优化延迟同时保持翻译质量。这种新方法消除了词级对齐的需求，简化了训练流程，并能够适用于多种语言体系结构。", "result": "Hibiki-Zero在五种X到英语的任务中实现了最新的性能，在翻译准确率、延迟性、语音转移和自然度方面都有所体现。此外，模型可以适应新输入的语言只需要少于1000小时的语音数据。", "conclusion": "通过去除词级对齐的需求，Hibiki-Zero简化了训练流程，并能够高效地应用于不同语言的同步语音翻译任务中。"}}
{"id": "2602.11066", "pdf": "https://arxiv.org/pdf/2602.11066", "abs": "https://arxiv.org/abs/2602.11066", "authors": ["Yujie Chen", "Li Zhang", "Xiaomeng Chu", "Tian Zhang"], "title": "PuriLight: A Lightweight Shuffle and Purification Framework for Monocular Depth Estimation", "categories": ["cs.CV"], "comment": "8 pages, 6figures, accepted by European Conference on Artificial Intelligence (ECAI2025)", "summary": "We propose PuriLight, a lightweight and efficient framework for self-supervised monocular depth estimation, to address the dual challenges of computational efficiency and detail preservation. While recent advances in self-supervised depth estimation have reduced reliance on ground truth supervision, existing approaches remain constrained by either bulky architectures compromising practicality or lightweight models sacrificing structural precision. These dual limitations underscore the critical need to develop lightweight yet structurally precise architectures. Our framework addresses these limitations through a three-stage architecture incorporating three novel modules: the Shuffle-Dilation Convolution (SDC) module for local feature extraction, the Rotation-Adaptive Kernel Attention (RAKA) module for hierarchical feature enhancement, and the Deep Frequency Signal Purification (DFSP) module for global feature purification. Through effective collaboration, these modules enable PuriLight to achieve both lightweight and accurate feature extraction and processing. Extensive experiments demonstrate that PuriLight achieves state-of-the-art performance with minimal training parameters while maintaining exceptional computational efficiency. Codes will be available at https://github.com/ishrouder/PuriLight.", "AI": {"tldr": "提出了一种轻量级的单目深度估计框架PuriLight，该框架旨在解决计算效率和细节保持之间的平衡问题。", "motivation": "现有自监督深度估计算法要么依赖于复杂的模型来提高精度，从而牺牲了实用性；要么使用轻量级模型，但又无法保证结构上的准确性。因此，开发出既能保持轻量化又能提供高精度的模型至关重要。", "method": "PuriLight框架采用了三阶段架构，并引入了三个新的模块：用于局部特征提取的Shuffle-Dilation卷积（SDC）模块、用于增强层次特征的Rotation-Adaptive Kernel注意力（RAKA）模块以及用于全局特征净化的Deep Frequency信号净化（DFSP）模块。", "result": "实验表明，PuriLight不仅在训练参数上保持最少的同时还达到了最先进的性能表现，并且在计算效率方面也表现出色。", "conclusion": "PuriLight框架成功地解决了轻量化与准确度之间的权衡问题，在减少模型复杂性的同时实现了卓越的精度。"}}
{"id": "2602.11065", "pdf": "https://arxiv.org/pdf/2602.11065", "abs": "https://arxiv.org/abs/2602.11065", "authors": ["Dingkun Zhou", "Shuchang Pan", "Jiachen Lian", "Siddharth Banerjee", "Sarika Pasumarthy", "Dhruv Hebbar", "Siddhant Patel", "Zeyi Austin Li", "Kan Jen Cheng", "Sanay Bordia", "Krish Patel", "Akshaj Gupta", "Tingle Li", "Gopala Anumanchipalli"], "title": "Conversational Behavior Modeling Foundation Model With Multi-Level Perception", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this perceptual pathway is key to building natural full-duplex interactive systems. We introduce a framework that models this process as multi-level perception, and then reasons over conversational behaviors via a Graph-of-Thoughts (GoT). Our approach formalizes the intent-to-action pathway with a hierarchical labeling scheme, predicting high-level communicative intents and low-level speech acts to learn their causal and temporal dependencies. To train this system, we develop a high quality corpus that pairs controllable, event-rich dialogue data with human-annotated labels. The GoT framework structures streaming predictions as an evolving graph, enabling a transformer to forecast the next speech act, generate concise justifications for its decisions, and dynamically refine its reasoning. Experiments on both synthetic and real duplex dialogues show that the framework delivers robust behavior detection, produces interpretable reasoning chains, and establishes a foundation for benchmarking conversational reasoning in full duplex spoken dialogue systems.", "AI": {"tldr": "该论文提出了一种基于多层次感知的对话行为建模基础模型，并通过Graph-of-Thoughts（GoT）框架对对话行为进行推理。", "motivation": "捕捉人类对话中隐含的思想链对于建立自然全双工交互系统至关重要。此研究旨在模拟这一过程，以便更好地理解并预测对话中的意图和动作。", "method": "该方法利用多层次感知建模对话行为，并采用Graph-of-Thoughts框架来推理这些行为。通过一种分层标注方案，模型能够预测高层次的沟通意图和低层次的语言行为，从而学习它们之间的因果关系和时间依赖性。", "result": "实验结果表明，所提出的方法在合成数据集和真实全双工对话上均表现出色，具有良好的行为检测能力和可解释性的推理链生成能力。", "conclusion": "该框架为基准测试全双工语音对话系统的对话推理提供了一个基础，并展示出其在捕捉复杂对话行为方面的潜力。"}}
{"id": "2602.11055", "pdf": "https://arxiv.org/pdf/2602.11055", "abs": "https://arxiv.org/abs/2602.11055", "authors": ["Yate Ge", "Lin Tian", "Yi Dai", "Shuhan Pan", "Yiwen Zhang", "Qi Wang", "Weiwei Guo", "Xiaohua Sun"], "title": "GenFaceUI: Meta-Design of Generative Personalized Facial Expression Interfaces for Intelligent Agents", "categories": ["cs.HC"], "comment": "To appear at ACM CHI '26", "summary": "This work investigates generative facial expression interfaces for intelligent agents from a meta-design perspective. We propose the Generative Personalized Facial Expression Interface (GPFEI) framework, which organizes rule-bounded spaces, character identity, and context--expression mapping to address challenges of control, coherence, and alignment in run-time facial expression generation. To operationalize this framework, we developed GenFaceUI, a proof-of-concept tool that enables designers to create templates, apply semantic tags, define rules, and iteratively test outcomes. We evaluated the tool through a qualitative study with twelve designers. The results show perceived gains in controllability and consistency, while revealing needs for structured visual mechanisms and lightweight explanations. These findings provide a conceptual framework, a proof-of-concept tool, and empirical insights that highlight both opportunities and challenges for advancing generative facial expression interfaces within a broader meta-design paradigm.", "AI": {"tldr": "设计一种元设计方案框架，用于生成智能代理的个性化面部表情界面。", "motivation": "解决运行时人脸表情生成中的控制、一致性和对齐问题。", "method": "提出规则约束空间、角色身份和情境-表情映射的组织方法，并开发原型工具GenFaceUI进行测试。", "result": "通过12名设计师的研究显示，在可控性与一致性上有改善，同时揭示了结构化视觉机制和轻量级解释的需求。", "conclusion": "研究提供了概念框架、原型工具及实证见解，指出推进生成面部表情界面在更广泛元设计范式中的机会和挑战"}}
{"id": "2602.11052", "pdf": "https://arxiv.org/pdf/2602.11052", "abs": "https://arxiv.org/abs/2602.11052", "authors": ["Maciej Besta", "Łukasz Jarmocik", "Orest Hrycyna", "Shachar Klaiman", "Konrad Mączka", "Robert Gerstenberger", "Jürgen Müller", "Piotr Nyczyk", "Hubert Niewiadomski", "Torsten Hoefler"], "title": "GraphSeek: Next-Generation Graph Analytics with LLMs", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.HC", "cs.IR"], "comment": null, "summary": "Graphs are foundational across domains but remain hard to use without deep expertise. LLMs promise accessible natural language (NL) graph analytics, yet they fail to process industry-scale property graphs effectively and efficiently: such datasets are large, highly heterogeneous, structurally complex, and evolve dynamically. To address this, we devise a novel abstraction for complex multi-query analytics over such graphs. Its key idea is to replace brittle generation of graph queries directly from NL with planning over a Semantic Catalog that describes both the graph schema and the graph operations. Concretely, this induces a clean separation between a Semantic Plane for LLM planning and broader reasoning, and an Execution Plane for deterministic, database-grade query execution over the full dataset and tool implementations. This design yields substantial gains in both token efficiency and task effectiveness even with small-context LLMs. We use this abstraction as the basis of the first LLM-enhanced graph analytics framework called GraphSeek. GraphSeek achieves substantially higher success rates (e.g., 86% over enhanced LangChain) and points toward the next generation of affordable and accessible graph analytics that unify LLM reasoning with database-grade execution over large and complex property graphs.", "AI": {"tldr": "本文提出了GraphSeek框架，通过LLM和数据库级执行的结合来实现复杂图形分析。", "motivation": "现有LLM无法有效处理大规模、高度异构、结构复杂的图形数据。为了解决这个问题，作者设计了一种新的抽象方法以提高任务效率和效果。", "method": "作者提出了一个新颖的抽象层次：语义层和执行层，使用Semantic Catalog来规划查询而不是直接生成查询，从而实现高效的LLM辅助图形分析。", "result": "GraphSeek框架在成功率上表现优异（例如，比增强版LangChain高出86%），展现了下一代低成本、易用性高的图形分析方法的潜力。", "conclusion": "通过将LLM和数据库级执行相结合，本文提出的方法实现了高效的复杂图形数据分析，推动了未来可负担且易于使用的图形分析技术的发展。"}}
{"id": "2602.11049", "pdf": "https://arxiv.org/pdf/2602.11049", "abs": "https://arxiv.org/abs/2602.11049", "authors": ["Haocheng Zhao", "Lukas Brunke", "Oliver Lagerquist", "Siqi Zhou", "Angela P. Schoellig"], "title": "SQ-CBF: Signed Distance Functions for Numerically Stable Superquadric-Based Safety Filtering", "categories": ["cs.RO"], "comment": null, "summary": "Ensuring safe robot operation in cluttered and dynamic environments remains a fundamental challenge. While control barrier functions provide an effective framework for real-time safety filtering, their performance critically depends on the underlying geometric representation, which is often simplified, leading to either overly conservative behavior or insufficient collision coverage. Superquadrics offer an expressive way to model complex shapes using a few primitives and are increasingly used for robot safety. To integrate this representation into collision avoidance, most existing approaches directly use their implicit functions as barrier candidates. However, we identify a critical but overlooked issue in this practice: the gradients of the implicit SQ function can become severely ill-conditioned, potentially rendering the optimization infeasible and undermining reliable real-time safety filtering. To address this issue, we formulate an SQ-based safety filtering framework that uses signed distance functions as barrier candidates. Since analytical SDFs are unavailable for general SQs, we compute distances using the efficient Gilbert-Johnson-Keerthi algorithm and obtain gradients via randomized smoothing. Extensive simulation and real-world experiments demonstrate consistent collision-free manipulation in cluttered and unstructured scenes, showing robustness to challenging geometries, sensing noise, and dynamic disturbances, while improving task efficiency in teleoperation tasks. These results highlight a pathway toward safety filters that remain precise and reliable under the geometric complexity of real-world environments.", "AI": {"tldr": "提出了一种基于签名距离函数的超二次体安全过滤框架，以改善实时机器人安全性。", "motivation": "现有方法将超二次体隐式函数直接用作屏障候选者可能导致优化不稳定和可靠性降低。为解决这一问题，提出了新的安全过滤方案。", "method": "使用Gilbert-Johnson-Keerthi算法计算距离，并通过随机平滑获得梯度，以实现基于签名距离函数的安全性过滤。", "result": "模拟和真实世界实验表明，在复杂环境中实现了持续的无碰撞操作，提高了任务效率并增强了对挑战性几何结构、传感器噪声以及动态扰动的鲁棒性。", "conclusion": "该方法提供了在实际环境复杂度下保持精度与可靠性的安全过滤路径。"}}
{"id": "2602.11044", "pdf": "https://arxiv.org/pdf/2602.11044", "abs": "https://arxiv.org/abs/2602.11044", "authors": ["Kevin Yandoka Denamganaï", "Kartic Subr"], "title": "Language Model Inversion through End-to-End Differentiation", "categories": ["cs.CL", "cs.AI"], "comment": "24 pages, 5 figures, under review", "summary": "Despite emerging research on Language Models (LM), few approaches analyse the invertibility of LMs. That is, given a LM and a desirable target output sequence of tokens, determining what input prompts would yield the target output remains an open problem. We formulate this problem as a classical gradient-based optimisation. First, we propose a simple algorithm to achieve end-to-end differentiability of a given (frozen) LM and then find optimised prompts via gradient descent. Our central insight is to view LMs as functions operating on sequences of distributions over tokens (rather than the traditional view as functions on sequences of tokens). Our experiments and ablations demonstrate that our DLM-powered inversion can reliably and efficiently optimise prompts of lengths $10$ and $80$ for targets of length $20$, for several white-box LMs (out-of-the-box).", "AI": {"tldr": "通过端到端微分优化给定目标输出序列的输入提示词", "motivation": "分析语言模型的逆向问题，即确定什么输入提示可以产生给定的目标输出序列", "method": "将语言模型视为操作于标记分布序列上的函数，并使用梯度下降法寻找最优输入提示", "result": "实验结果表明该方法能有效优化长度为10和80的输入提示以匹配目标输出，对于几种白盒语言模型均适用", "conclusion": "提出的方法能够可靠且高效地解决逆向问题"}}
{"id": "2602.11029", "pdf": "https://arxiv.org/pdf/2602.11029", "abs": "https://arxiv.org/abs/2602.11029", "authors": ["Nathaniel K. Brown", "Ben Langmead"], "title": "Bounding the Average Move Structure Query for Faster and Smaller RLBWT Permutations", "categories": ["cs.DS"], "comment": null, "summary": "The move structure represents permutations with long contiguously permuted intervals in compressed space with optimal query time. They have become an important feature of compressed text indexes using space proportional to the number of Burrows-Wheeler Transform (BWT) runs, often applied in genomics. This is in thanks not only to theoretical improvements over past approaches, but great cache efficiency and average case query time in practice. This is true even without using the worst case guarantees provided by the interval splitting balancing of the original result. In this paper, we show that an even simpler type of splitting, length capping by truncating long intervals, bounds the average move structure query time to optimal whilst obtaining a superior construction time than the traditional approach. This also proves constant query time when amortized over a full traversal of a single cycle permutation from an arbitrary starting position. Such a scheme has surprising benefits both in theory and practice. We leverage the approach to improve the representation of any move structure with $r$ runs over a domain $n$ to $O(r \\log r + r \\log \\frac{n}{r})$-bits of space. The worst case query time is also improved to $O(\\log \\frac{n}{r})$ without balancing. An $O(r)$-time and $O(r)$-space construction lets us apply the method to run-length encoded BWT (RLBWT) permutations such as LF and $φ$ to obtain optimal-time algorithms for BWT inversion and suffix array (SA) enumeration in $O(r)$ additional working space. Finally, we provide the RunPerm library, providing flexible plug and play move structure support, and use it to evaluate our splitting approach. Experiments find length capping results in faster move structures, but also a space reduction: at least $\\sim 40\\%$ for LF across large repetitive genomic collections.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.11028", "pdf": "https://arxiv.org/pdf/2602.11028", "abs": "https://arxiv.org/abs/2602.11028", "authors": ["Artsvik Avetisyan", "Sachin Kumar"], "title": "Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches. Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt Corpus using three linguistic representations: raw cleaned text, a part-of-speech (POS)-enhanced representation combining lexical and grammatical information, and a POS-only syntactic representation. Logistic regression and random forest models were evaluated under two protocols: transcript-level train-test splits and subject-level five-fold cross-validation to prevent speaker overlap. Model interpretability was examined using global feature importance, and statistical validation was conducted using Mann-Whitney U tests with Cliff's delta effect sizes. Results: Across representations, models achieved stable performance, with syntactic and grammatical features retaining strong discriminative power even in the absence of lexical content. Subject-level evaluation yielded more conservative but consistent results, particularly for POS-enhanced and POS-only representations. Statistical analysis revealed significant group differences in functional word usage, lexical diversity, sentence structure, and discourse coherence, aligning closely with machine learning feature importance findings. Conclusion: The results demonstrate that abstract linguistic features capture robust markers of early cognitive decline under clinically realistic evaluation. By combining interpretable machine learning with non-parametric statistical validation, this study supports the use of linguistically grounded features for transparent and reliable language-based cognitive screening.", "AI": {"tldr": "本文通过统计和机器学习方法分析了DementiaBank Pitt语料库中的自发语言生产，以识别早期认知衰退的语言标志。", "motivation": "细微的自发言语变化是认知下降最早期的指标之一。识别可解释的语言标志可以支持透明且基于临床的方法进行筛查。", "method": "本研究使用三种语言表示分析了DementiaBank Pitt语料库中的自发话语转录：原始清理文本、结合词汇和语法信息的部分词性（POS）增强表示，以及仅包含句法的POS表示。使用逻辑回归和随机森林模型，并通过两种协议进行评估：基于转录文件级别的训练测试拆分和避免说话人重叠的主体级别五折交叉验证。", "result": "无论哪种语言表示形式，模型均表现稳定，语法特征即使在缺乏词汇内容的情况下仍具有强大的判别能力。统计分析揭示了功能词使用、词汇多样性、句子结构和话语连贯性方面的显著群体差异，这与机器学习特征重要性的发现一致。", "conclusion": "结果表明，在临床现实的评估中，抽象的语言特性可以捕捉到早期认知衰退的有效标志。结合可解释的机器学习和非参数统计验证支持使用基于语言且可靠的方法进行筛查。"}}
{"id": "2602.11026", "pdf": "https://arxiv.org/pdf/2602.11026", "abs": "https://arxiv.org/abs/2602.11026", "authors": ["Yehuda Perry", "Tawfiq Ammari"], "title": "Normalized Surveillance in the Datafied Car: How Autonomous Vehicle Users Rationalize Privacy Trade-offs", "categories": ["cs.HC"], "comment": null, "summary": "Autonomous vehicles (AVs) are characterized by pervasive datafication and surveillance through sensors like in-cabin cameras, LIDAR, and GPS. Drawing on 16 semi-structured interviews with AV drivers analyzed using constructivist grounded theory, this study examines how users make sense of vehicular surveillance within everyday datafication. Findings reveal drivers demonstrate few AV-specific privacy concerns, instead normalizing monitoring through comparisons with established digital platforms. We theorize this indifference by situating AV surveillance within the `surveillance ecology' of platform environments, arguing the datafied car functions as a mobile extension of the `leaky home' -- private spaces rendered permeable through connected technologies continuously transmitting behavioral data. The study contributes to scholarship on surveillance beliefs, datafication, and platform governance by demonstrating how users who have accepted comprehensive smartphone and smart home monitoring encounter AV datafication as just another node in normalized data extraction. We highlight how geographic restrictions on data access -- currently limiting driver log access to California -- create asymmetries that impede informed privacy deliberation, exemplifying `tertiary digital divides.' Finally, we examine how machine learning's reliance on data-intensive approaches creates structural pressure for surveillance that transcends individual manufacturer choices. We propose governance interventions to democratize social learning, including universal data access rights, binding transparency requirements, and data minimization standards to prevent race-to-the-bottom dynamics in automotive datafication.", "AI": {"tldr": "探讨自动驾驶汽车用户如何理解车辆监控并在日常数据化环境中进行隐私权交易。", "motivation": "研究自动驾驶汽车中用户的监控感知，以及他们在广泛的数据采集环境中的隐私态度。", "method": "通过对16名自动驾驶汽车驾驶员的半结构化访谈，并运用建构主义扎根理论分析。", "result": "发现自动驾驶汽车用户对特定的隐私问题表现出较少的关注，而是通过将车辆监控与其他数字平台进行比较来正常化这种监控。", "conclusion": "提出治理干预措施以民主化社会学习，包括普遍的数据访问权、强制透明度要求和数据最小化标准，防止在汽车行业中的竞争性恶化。"}}
{"id": "2602.11025", "pdf": "https://arxiv.org/pdf/2602.11025", "abs": "https://arxiv.org/abs/2602.11025", "authors": ["Liuchuan Yu", "Yongqi Zhang", "Lap-Fai Yu"], "title": "Reality Copilot: Voice-First Human-AI Collaboration in Mixed Reality Using Large Multimodal Models", "categories": ["cs.HC"], "comment": null, "summary": "Large Multimodal Models (LMMs) have shown strong potential for assisting users in tasks, such as programming, content creation, and information access, yet their interaction remains largely limited to traditional interfaces such as desktops and smartphones. Meanwhile, advances in mixed reality (MR) hardware have enabled applications that extend beyond entertainment and into everyday use. However, most existing MR systems rely primarily on manual input (e.g., hand gestures or controllers) and provide limited intelligent assistance due to the lack of integration with large-scale AI models. We present Reality Copilot, a voice-first human-AI assistant for mixed reality that leverages LMMs to enable natural speech-based interaction. The system supports contextual understanding of physical environments, realistic 3D content generation, and real-time information retrieval. In addition to in-headset interaction, Reality Copilot facilitates cross-platform workflows by generating context-aware textual content and exporting generated assets. This work explores the design space of LMM-powered human-AI collaboration in mixed reality.", "AI": {"tldr": "该论文提出了Reality Copilot，一种利用大型多模态模型实现语音优先的人机协作的混合现实系统。", "motivation": "现有的混合现实系统主要依赖于手动输入和提供有限的智能辅助，缺乏与大规模AI模型的集成。因此，作者希望通过引入基于LMM的自然语音交互来改进现有系统的用户体验。", "method": "Reality Copilot通过利用大型多模态模型支持对物理环境的理解、生成现实3D内容以及实时信息检索等功能，实现了基于语音的人机协作。", "result": "该系统不仅在头显内提供交互功能，还能生成上下文相关的文本内容，并导出生成的资产，促进了跨平台工作流。", "conclusion": "通过引入大型多模态模型，Reality Copilot展示了混合现实中人机协作的新可能性。"}}
{"id": "2602.11024", "pdf": "https://arxiv.org/pdf/2602.11024", "abs": "https://arxiv.org/abs/2602.11024", "authors": ["Rishikesh Bhyri", "Brian R Quaranto", "Philip J Seger", "Kaity Tung", "Brendan Fox", "Gene Yang", "Steven D. Schwaitzberg", "Junsong Yuan", "Nan Xi", "Peter C W Kim"], "title": "Chain-of-Look Spatial Reasoning for Dense Surgical Instrument Counting", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to WACV 2026. This version includes additional authors who contributed during the rebuttal phase", "summary": "Accurate counting of surgical instruments in Operating Rooms (OR) is a critical prerequisite for ensuring patient safety during surgery. Despite recent progress of large visual-language models and agentic AI, accurately counting such instruments remains highly challenging, particularly in dense scenarios where instruments are tightly clustered. To address this problem, we introduce Chain-of-Look, a novel visual reasoning framework that mimics the sequential human counting process by enforcing a structured visual chain, rather than relying on classic object detection which is unordered. This visual chain guides the model to count along a coherent spatial trajectory, improving accuracy in complex scenes. To further enforce the physical plausibility of the visual chain, we introduce the neighboring loss function, which explicitly models the spatial constraints inherent to densely packed surgical instruments. We also present SurgCount-HD, a new dataset comprising 1,464 high-density surgical instrument images. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches for counting (e.g., CountGD, REC) as well as Multimodality Large Language Models (e.g., Qwen, ChatGPT) in the challenging task of dense surgical instrument counting.", "AI": {"tldr": "提出了Chain-of-Look框架，用于准确计数密集场景中的手术工具。", "motivation": "确保手术中患者安全需要精确计数手术室内的工具。尽管现有的视觉语言模型和代理AI有所进步，但在密集情况下仍难以实现。", "method": "引入了模仿人类计数过程的Chain-of-Look框架，并使用邻接损失函数强化物理合理性，以提高复杂场景中的准确性。", "result": "在SurgCount-HD数据集上实验表明，该方法优于现有最先进算法和多模态大型语言模型。", "conclusion": "提出的Chain-of-Look框架能够有效解决密集手术工具计数问题，提高了准确性和可靠性。"}}
{"id": "2602.11021", "pdf": "https://arxiv.org/pdf/2602.11021", "abs": "https://arxiv.org/abs/2602.11021", "authors": ["Meizhong Wang", "Wanxin Jin", "Kun Cao", "Lihua Xie", "Yiguang Hong"], "title": "ContactGaussian-WM: Learning Physics-Grounded World Model from Videos", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Developing world models that understand complex physical interactions is essential for advancing robotic planning and simulation.However, existing methods often struggle to accurately model the environment under conditions of data scarcity and complex contact-rich dynamic motion.To address these challenges, we propose ContactGaussian-WM, a differentiable physics-grounded rigid-body world model capable of learning intricate physical laws directly from sparse and contact-rich video sequences.Our framework consists of two core components: (1) a unified Gaussian representation for both visual appearance and collision geometry, and (2) an end-to-end differentiable learning framework that differentiates through a closed-form physics engine to infer physical properties from sparse visual observations.Extensive simulations and real-world evaluations demonstrate that ContactGaussian-WM outperforms state-of-the-art methods in learning complex scenarios, exhibiting robust generalization capabilities.Furthermore, we showcase the practical utility of our framework in downstream applications, including data synthesis and real-time MPC.", "AI": {"tldr": "研究提出了一种从稀疏视频序列中学习复杂物理交互的世界模型ContactGaussian-WM。", "motivation": "现有的世界模型方法在数据稀缺和接触密集型动态运动条件下难以准确建模环境。", "method": "提出了一个统一的高斯表示法来处理视觉外观和碰撞几何，并通过可微分的物理学引擎进行端到端学习，推断物理属性。", "result": "实验表明，ContactGaussian-WM在复杂场景的学习中优于现有方法，并展示了其在数据合成和实时MPC等下游应用中的实用性。", "conclusion": "该框架能够有效处理复杂的物理交互问题，在稀疏视觉观察条件下展现出强大的泛化能力。"}}
{"id": "2602.11018", "pdf": "https://arxiv.org/pdf/2602.11018", "abs": "https://arxiv.org/abs/2602.11018", "authors": ["Returaj Burnwal", "Nirav Pravinbhai Bhatt", "Balaraman Ravindran"], "title": "OSIL: Learning Offline Safe Imitation Policies with Safety Inferred from Non-preferred Trajectories", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "21 pages, Accepted at AAMAS 2026", "summary": "This work addresses the problem of offline safe imitation learning (IL), where the goal is to learn safe and reward-maximizing policies from demonstrations that do not have per-timestep safety cost or reward information. In many real-world domains, online learning in the environment can be risky, and specifying accurate safety costs can be difficult. However, it is often feasible to collect trajectories that reflect undesirable or unsafe behavior, implicitly conveying what the agent should avoid. We refer to these as non-preferred trajectories. We propose a novel offline safe IL algorithm, OSIL, that infers safety from non-preferred demonstrations. We formulate safe policy learning as a Constrained Markov Decision Process (CMDP). Instead of relying on explicit safety cost and reward annotations, OSIL reformulates the CMDP problem by deriving a lower bound on reward maximizing objective and learning a cost model that estimates the likelihood of non-preferred behavior. Our approach allows agents to learn safe and reward-maximizing behavior entirely from offline demonstrations. We empirically demonstrate that our approach can learn safer policies that satisfy cost constraints without degrading the reward performance, thus outperforming several baselines.", "AI": {"tldr": "本文提出了一种名为OSIL的离线安全模仿学习算法，该算法能够从无风险成本或奖励信息的演示中推断出安全性，并通过非首选轨迹来避免危险行为。", "motivation": "在许多现实世界场景中，在环境中进行在线学习可能很危险，而且准确的安全成本指定也很困难。然而，通常可以收集反映不希望的行为的轨迹。本文旨在从这些无安全信息的演示数据中推断出安全性，并让智能体学会既安全又能最大化奖励的行为。", "method": "OSIL将安全策略学习表述为一个约束马尔可夫决策过程（CMDP）。通过推导最大收益目标的下限并学习成本模型来估计非首选行为的可能性，从而从离线演示中直接学习安全和高回报的行为。", "result": "实验结果表明，该方法能够学会更安全且满足成本限制的策略，并且不会降低奖励性能，优于多个基准。", "conclusion": "本文提出的OSIL算法能够在没有显式安全成本和奖励注释的情况下，从离线演示中推断安全性并学习安全行为。"}}
{"id": "2602.11016", "pdf": "https://arxiv.org/pdf/2602.11016", "abs": "https://arxiv.org/abs/2602.11016", "authors": ["Jinxin Yu", "Yudong Pan", "Mengdi Wang", "Huawei Li", "Yinhe Han", "Xiaowei Li", "Ying Wang"], "title": "From Buffers to Registers: Unlocking Fine-Grained FlashAttention with Hybrid-Bonded 3D NPU Co-Design", "categories": ["cs.AR", "cs.AI"], "comment": "Accepted to DATE 2026", "summary": "Transformer-based models dominate modern AI workloads but exacerbate memory bottlenecks due to their quadratic attention complexity and ever-growing model sizes. Existing accelerators, such as Groq and Cerebras, mitigate off-chip traffic with large on-chip caches, while algorithmic innovations such as FlashAttention fuse operators to avoid materializing large attention matrices. However, as off-chip traffic decreases, our measurements show that on-chip SRAM accesses account for over 60% of energy in long-sequence workloads, making cache access the new bottleneck. We propose 3D-Flow, a hybrid-bonded, 3D-stacked spatial accelerator that enables register-to-register communication across vertically partitioned PE tiers. Unlike 2D multi-array architectures limited by NoC-based router-to-router transfers, 3D-Flow leverages sub-10 um vertical TSVs to sustain cycle-level operator pipelining with minimal overhead. On top of this architecture, we design 3D-FlashAttention, a fine-grained scheduling method that balances latency across tiers, forming a bubble-free vertical dataflow without on-chip SRAM roundtrips. Evaluations on Transformer workloads (OPT and QWEN models) show that our 3D spatial accelerator reduces 46-93% energy consumption and achieves 1.4x-7.6x speedups compared to state-of-the-art 2D and 3D designs.", "AI": {"tldr": "本文提出了一种三维堆叠的空间加速器3D-Flow，通过在不同处理单元层之间实现寄存器到寄存器的通信来减少内存瓶颈，并设计了3D-FastAttention调度方法以优化Transformer模型的工作负载。", "motivation": "由于Transformer模型的二次注意力复杂性和不断增长的规模，它们加剧了内存瓶颈。现有加速器通过大容量片上缓存减少了外部访问流量，而算法创新如FlashAttention则避免生成大型注意矩阵。然而，随着外部交通减少，长序列工作负载中片上SRAM访问占总能耗的60％以上。", "method": "本文提出了一种三维堆叠的空间加速器3D-Flow，并设计了细粒度调度方法3D-FastAttention以优化Transformer模型的工作负载。该架构利用亚10um垂直TSV连接不同PE层，支持寄存器到寄存器通信，减少了片上SRAM往返。", "result": "实验表明，与现有二维和三维设计相比，本文提出的三维空间加速器可以将能耗降低46%-93%，并将速度提升1.4x-7.6x。", "conclusion": "通过实现寄存器到寄存器通信及优化调度方法，该研究提供了一种有效解决片上SRAM访问瓶颈的方法，并在Transformer模型中取得了显著性能改进。"}}
{"id": "2602.11015", "pdf": "https://arxiv.org/pdf/2602.11015", "abs": "https://arxiv.org/abs/2602.11015", "authors": ["Valery Khvatov", "Alexey Neyman"], "title": "CVPL: A Geometric Framework for Post-Hoc Linkage Risk Assessment in Protected Tabular Data", "categories": ["cs.CR", "cs.AI"], "comment": "53 pages, 9 figures, 6 appendices. Code: https://github.com/DGT-Network/cvpl", "summary": "Formal privacy metrics provide compliance-oriented guarantees but often fail to quantify actual linkability in released datasets. We introduce CVPL (Cluster-Vector-Projection Linkage), a geometric framework for post-hoc assessment of linkage risk between original and protected tabular data. CVPL represents linkage analysis as an operator pipeline comprising blocking, vectorization, latent projection, and similarity evaluation, yielding continuous, scenario-dependent risk estimates rather than binary compliance verdicts. We formally define CVPL under an explicit threat model and introduce threshold-aware risk surfaces, R(lambda, tau), that capture the joint effects of protection strength and attacker strictness. We establish a progressive blocking strategy with monotonicity guarantees, enabling anytime risk estimation with valid lower bounds. We demonstrate that the classical Fellegi-Sunter linkage emerges as a special case of CVPL under restrictive assumptions, and that violations of these assumptions can lead to systematic over-linking bias. Empirical validation on 10,000 records across 19 protection configurations demonstrates that formal k-anonymity compliance may coexist with substantial empirical linkability, with a significant portion arising from non-quasi-identifier behavioral patterns. CVPL provides interpretable diagnostics identifying which features drive linkage feasibility, supporting privacy impact assessment, protection mechanism comparison, and utility-risk trade-off analysis.", "AI": {"tldr": "CVPL（集群向量投影链接）是一种用于评估受保护表格数据中的关联风险的几何框架。", "motivation": "正式隐私度量提供合规性保证，但在量化发布数据集的实际相关性方面存在不足。因此，研究人员提出了CVPL来解决这个问题，并提供连续、场景依赖的风险估计。", "method": "CVPL将链接分析表示为包括分块、向量化、潜在投影和相似性评估的操作符管道，并定义了阈值感知风险表面R(lambda, tau)。", "result": "实验证明，即使满足正式的k匿名合规性要求，数据仍可能具有显著的实际相关性。CVPL能够识别哪些特征驱动链接可行性，支持隐私影响评估、保护机制比较和效用-风险权衡分析。", "conclusion": "CVPL为受保护表格数据中的关联风险提供了可解释性和实用性的框架，解决了传统度量的不足，并在实际案例中展示了其有效性。"}}
{"id": "2602.11008", "pdf": "https://arxiv.org/pdf/2602.11008", "abs": "https://arxiv.org/abs/2602.11008", "authors": ["Ammar Ali", "Baher Mohammad", "Denis Makhov", "Dmitriy Shopkhoev", "Magauiya Zhussip", "Stamatios Lefkimmiatis"], "title": "ROCKET: Rapid Optimization via Calibration-guided Knapsack Enhanced Truncation for Efficient Model Compression", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We present ROCKET, a training-free model compression method that achieves state-of-the-art performance in comparison with factorization, structured-sparsification and dynamic compression baselines. Operating under a global compression budget, ROCKET comprises two key innovations: First, it formulates layer-wise compression allocation as a multi-choice knapsack problem, selecting the optimal compression level for each layer to minimize total reconstruction error while adhering to a target model size. Second, it introduces a single-step sparse matrix factorization inspired by dictionary learning: using only a small calibration set, it sparsifies weight coefficients based on activation-weights sensitivity and then updates the dictionary in closed form via least squares bypassing iterative optimization, sparse coding, or backpropagation entirely. ROCKET consistently outperforms existing compression approaches across different model architectures at 20-50\\% compression rates. Notably, it retains over 90\\% of the original model's performance at 30\\% compression without any fine-tuning. Moreover, when applying a light fine-tuning phase, recovery is substantially enhanced: for instance, compressing Qwen3-14B to an 8B-parameter model and healing it with just 30 million tokens yields performance nearly on par with the original Qwen3-8B. The code for ROCKET is at github.com/mts-ai/ROCKET/tree/main.", "AI": {"tldr": "ROCKET是一种无需训练的模型压缩方法，通过多选择背包问题优化各层压缩分配，并使用激活权重敏感性进行稀疏化处理。", "motivation": "为了提高模型压缩效率和性能，同时保持较低的计算复杂度和良好的恢复效果。", "method": "提出了一种基于多选择背包问题来确定每层最佳压缩率的方法，并采用单步稀疏矩阵因子分解技术，在小校准集上根据激活权重敏感性进行稀疏化处理。该方法完全避免了迭代优化、稀疏编码或反向传播。", "result": "ROCKET在多种模型架构下以20-50%的压缩率超越现有压缩方法，并保持90%以上的原始性能，甚至通过轻量级微调后效果接近原模型。", "conclusion": "ROCKET展示了高效的模型压缩能力和良好的恢复性，为无需训练的模型压缩提供了一种新思路。"}}
{"id": "2602.11007", "pdf": "https://arxiv.org/pdf/2602.11007", "abs": "https://arxiv.org/abs/2602.11007", "authors": ["Lei Yao", "Yi Wang", "Yawen Cui", "Moyun Liu", "Lap-Pui Chau"], "title": "LaSSM: Efficient Semantic-Spatial Query Decoding via Local Aggregation and State Space Models for 3D Instance Segmentation", "categories": ["cs.CV"], "comment": "Accepted at IEEE-TCSVT", "summary": "Query-based 3D scene instance segmentation from point clouds has attained notable performance. However, existing methods suffer from the query initialization dilemma due to the sparse nature of point clouds and rely on computationally intensive attention mechanisms in query decoders. We accordingly introduce LaSSM, prioritizing simplicity and efficiency while maintaining competitive performance. Specifically, we propose a hierarchical semantic-spatial query initializer to derive the query set from superpoints by considering both semantic cues and spatial distribution, achieving comprehensive scene coverage and accelerated convergence. We further present a coordinate-guided state space model (SSM) decoder that progressively refines queries. The novel decoder features a local aggregation scheme that restricts the model to focus on geometrically coherent regions and a spatial dual-path SSM block to capture underlying dependencies within the query set by integrating associated coordinates information. Our design enables efficient instance prediction, avoiding the incorporation of noisy information and reducing redundant computation. LaSSM ranks first place on the latest ScanNet++ V2 leaderboard, outperforming the previous best method by 2.5% mAP with only 1/3 FLOPs, demonstrating its superiority in challenging large-scale scene instance segmentation. LaSSM also achieves competitive performance on ScanNet, ScanNet200, S3DIS and ScanNet++ V1 benchmarks with less computational cost. Extensive ablation studies and qualitative results validate the effectiveness of our design. The code and weights are available at https://github.com/RayYoh/LaSSM.", "AI": {"tldr": "该论文提出了一种名为LaSSM的高效语义空间查询解码方法，用于点云中的三维实例分割。", "motivation": "现有的基于查询的三维场景实例分割方法存在初始化问题，并依赖于计算密集型注意力机制。LaSSM旨在通过简化和提高效率来解决这些问题，同时保持竞争力的表现。", "method": "LaSSM引入了一种分层语义空间查询初始化器，从超点中推导出查询集，考虑了语义提示和空间分布，并提出了一种坐标引导的状态空间模型（SSM）解码器以渐进方式细化查询。该解码器具有局部聚合方案以及双路径SSM块，可以捕获查询集中潜在的依赖关系。", "result": "LaSSM在最新ScanNet++ V2排行榜上排名第一，在仅使用前一种最佳方法三分之一的FLOPs的情况下，mAP提高了2.5%。此外，它还在ScanNet、ScanNet200、S3DIS和ScanNet++ V1基准测试中表现出具有竞争力的结果，并且计算成本较低。", "conclusion": "LaSSM通过简化解码器设计并提高效率，在三维实例分割任务上取得了显著的性能提升。"}}
{"id": "2602.11005", "pdf": "https://arxiv.org/pdf/2602.11005", "abs": "https://arxiv.org/abs/2602.11005", "authors": ["Vasileios Arampatzakis", "George Pavlidis", "Nikolaos Mitianoudis", "Nikos Papamarkos"], "title": "Interpretable Vision Transformers in Monocular Depth Estimation via SVDA", "categories": ["cs.CV"], "comment": "8 pages, 2 figures, submitted to CVPR Conference 2026", "summary": "Monocular depth estimation is a central problem in computer vision with applications in robotics, AR, and autonomous driving, yet the self-attention mechanisms that drive modern Transformer architectures remain opaque. We introduce SVD-Inspired Attention (SVDA) into the Dense Prediction Transformer (DPT), providing the first spectrally structured formulation of attention for dense prediction tasks. SVDA decouples directional alignment from spectral modulation by embedding a learnable diagonal matrix into normalized query-key interactions, enabling attention maps that are intrinsically interpretable rather than post-hoc approximations. Experiments on KITTI and NYU-v2 show that SVDA preserves or slightly improves predictive accuracy while adding only minor computational overhead. More importantly, SVDA unlocks six spectral indicators that quantify entropy, rank, sparsity, alignment, selectivity, and robustness. These reveal consistent cross-dataset and depth-wise patterns in how attention organizes during training, insights that remain inaccessible in standard Transformers. By shifting the role of attention from opaque mechanism to quantifiable descriptor, SVDA redefines interpretability in monocular depth estimation and opens a principled avenue toward transparent dense prediction models.", "AI": {"tldr": "本文提出了SVDA技术，用于解释单目深度估计中的视觉变换器模型。", "motivation": "当前的Transformer架构在单目深度估计中使用了自注意力机制，但这些机制不透明。作者希望通过引入SVD-Inspired Attention (SVDA)，使这种结构更加可解释，并提供新的见解。", "method": "通过将一个可学习的对角矩阵嵌入到归一化的查询-键交互中，SVDA实现了方向对齐与光谱调制的解耦，从而提供了固有的可解释性，而不是后验近似。此外，它解锁了六个光谱指标以量化熵、秩、稀疏度等。", "result": "实验表明，SVDA保持或轻微提升了预测精度，并且仅增加了很小的计算开销。更重要的是，它揭示了一些一致性的跨数据集和深度上的模式如何在训练期间组织注意力。", "conclusion": "通过将注意力的角色从不透明机制转变为可量化的描述符，SVDA重新定义了单目深度估计中的可解释性，并为透明密集预测模型开辟了一条原理化途径。"}}
{"id": "2602.11004", "pdf": "https://arxiv.org/pdf/2602.11004", "abs": "https://arxiv.org/abs/2602.11004", "authors": ["Liangkai Liu", "Kang G. Shin", "Jinkyu Lee", "Chengmo Yang", "Weisong Shi"], "title": "Enhancing Predictability of Multi-Tenant DNN Inference for Autonomous Vehicles' Perception", "categories": ["cs.CV", "cs.AI", "cs.RO", "eess.SY"], "comment": "13 pages, 12 figures", "summary": "Autonomous vehicles (AVs) rely on sensors and deep neural networks (DNNs) to perceive their surrounding environment and make maneuver decisions in real time. However, achieving real-time DNN inference in the AV's perception pipeline is challenging due to the large gap between the computation requirement and the AV's limited resources. Most, if not all, of existing studies focus on optimizing the DNN inference time to achieve faster perception by compressing the DNN model with pruning and quantization. In contrast, we present a Predictable Perception system with DNNs (PP-DNN) that reduce the amount of image data to be processed while maintaining the same level of accuracy for multi-tenant DNNs by dynamically selecting critical frames and regions of interest (ROIs). PP-DNN is based on our key insight that critical frames and ROIs for AVs vary with the AV's surrounding environment. However, it is challenging to identify and use critical frames and ROIs in multi-tenant DNNs for predictable inference. Given image-frame streams, PP-DNN leverages an ROI generator to identify critical frames and ROIs based on the similarities of consecutive frames and traffic scenarios. PP-DNN then leverages a FLOPs predictor to predict multiply-accumulate operations (MACs) from the dynamic critical frames and ROIs. The ROI scheduler coordinates the processing of critical frames and ROIs with multiple DNN models. Finally, we design a detection predictor for the perception of non-critical frames. We have implemented PP-DNN in an ROS-based AV pipeline and evaluated it with the BDD100K and the nuScenes dataset. PP-DNN is observed to significantly enhance perception predictability, increasing the number of fusion frames by up to 7.3x, reducing the fusion delay by >2.6x and fusion-delay variations by >2.3x, improving detection completeness by 75.4% and the cost-effectiveness by up to 98% over the baseline.", "AI": {"tldr": "本文提出了一种可预测感知系统（PP-DNN），通过动态选择关键帧和感兴趣区域来提高自动驾驶车辆中多租户DNN推理的可预测性。", "motivation": "为了实现实时DNN推断，现有研究大多关注于优化模型压缩以加速感知。相比之下，本文提出了一种新的方法，即PP-DNN系统，在保证准确性的同时减少处理的数据量，并提高多租户DNN环境中的推理可预测性。", "method": "该系统包括一个ROI生成器、FLOPs预测器和ROI调度器。首先，ROI生成器根据连续帧的相似性和交通场景动态选择关键帧和感兴趣区域；然后，FLOPs预测器基于这些选定的关键帧和区域估计MAC操作数量；最后，ROI调度器协调处理多个DNN模型。", "result": "通过在ROS基自动驾驶车辆感知管道中实现PP-DNN，并使用BDD100K和nuScenes数据集进行评估。结果显示，PP-DNN显著提高了感知的可预测性：增加了融合帧数量至多7.3倍，减少了融合延迟超过2.6倍以及降低了延迟变化量超过2.3倍，检测完整性提升了75.4%，并节省了高达98%的成本。", "conclusion": "该系统PP-DNN在保证准确性的同时提高了自动驾驶车辆感知的可预测性，展示了其在处理资源有限条件下的有效性。"}}
{"id": "2602.11000", "pdf": "https://arxiv.org/pdf/2602.11000", "abs": "https://arxiv.org/abs/2602.11000", "authors": ["Ali Tehrani", "Yahya Emara", "Essam Wissam", "Wojciech Paluch", "Waleed Atallah", "Łukasz Dudziak", "Mohamed S. Abdelfattah"], "title": "Fine-Tuning GPT-5 for GPU Kernel Generation", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Developing efficient GPU kernels is essential for scaling modern AI systems, yet it remains a complex task due to intricate hardware architectures and the need for specialized optimization expertise. Although Large Language Models (LLMs) demonstrate strong capabilities in general sequential code generation, they face significant challenges in GPU code generation because of the scarcity of high-quality labeled training data, compiler biases when generating synthetic solutions, and limited generalization across hardware generations. This precludes supervised fine-tuning (SFT) as a scalable methodology for improving current LLMs. In contrast, reinforcement learning (RL) offers a data-efficient and adaptive alternative but requires access to relevant tools, careful selection of training problems, and a robust evaluation environment. We present Makora's environment and tools for reinforcement learning finetuning of frontier models and report our results from fine-tuning GPT-5 for Triton code generation. In the single-attempt setting, our fine-tuned model improves kernel correctness from 43.7% to 77.0% (+33.3 percentage points) and increases the fraction of problems outperforming TorchInductor from 14.8% to 21.8% (+7 percentage points) compared to baseline GPT-5, while exceeding prior state-of-the-art models on KernelBench. When integrated into a full coding agent, it is able to solve up to 97.4% of problems in an expanded KernelBench suite, outperforming the PyTorch TorchInductor compiler on 72.9% of problems with a geometric mean speedup of 2.12x. Our work demonstrates that targeted post-training with reinforcement learning can unlock LLM capabilities in highly specialized technical domains where traditional supervised learning is limited by data availability, opening new pathways for AI-assisted accelerator programming.", "AI": {"tldr": "利用强化学习对GPT-5进行微调，以生成高效的GPU内核代码。", "motivation": "开发高效GPU内核是扩展现代AI系统的关键任务，但现有大型语言模型在生成GPU代码时面临数据稀缺、编译器偏差和泛化能力不足的问题。", "method": "提出Makora环境及工具用于前沿模型的强化学习微调，并报告了GPT-5在Triton代码生成中的训练结果。", "result": "单次尝试中，微调后的模型将内核正确性从43.7%提升至77%，并在扩大版KernelBench套件中解决了97.4%的问题，超过PyTorch TorchInductor编译器在72.9%的问题上。", "conclusion": "研究展示了通过强化学习的后训练微调可以解锁大型语言模型在特殊技术领域的潜力，为AI辅助加速器编程开辟了新途径。"}}
{"id": "2602.10999", "pdf": "https://arxiv.org/pdf/2602.10999", "abs": "https://arxiv.org/abs/2602.10999", "authors": ["Yusong Lin", "Haiyang Wang", "Shuzhe Wu", "Lue Fan", "Feiyang Pan", "Sanyuan Zhao", "Dandan Tu"], "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion", "categories": ["cs.AI"], "comment": null, "summary": "Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate and explore environment histories, guided by execution feedback. By tracing histories of a healthy environment, its state can be inverted to an earlier one with runtime failures, from which a task can be derived by packing the buggy state and the corresponding error messages. With our method, named CLI-Gym, a total of 1,655 environment-intensive tasks are derived, being the largest collection of its kind. Moreover, with curated successful trajectories, our fine-tuned model, named LiberCoder, achieves substantial absolute improvements of +21.1% (to 46.1%) on Terminal-Bench, outperforming various strong baselines. To our knowledge, this is the first public pipeline for scalable derivation of environment-intensive tasks.", "AI": {"tldr": "CLI-Gym是一种通过逆向仿真环境历史来生成大规模命令行界面任务的方法。", "motivation": "当前缺乏有效的方法从大量环境中获取用于增强代理能力的任务。该研究希望通过模拟和探索环境历史，以提高代理在复杂环境中的操作能力。", "method": "基于Dockerfile与任务之间的类比关系，CLI-Gym采用逆向仿真技术追溯健康环境的状态，并将其反转至包含运行时错误的早期状态，从中导出任务。", "result": "通过CLI-Gym方法，共生成了1655个大规模命令行界面任务。经过对成功轨迹的微调后，模型在Terminal-Bench上取得了46.1%的表现，相较于各种强基线有显著提升（+21.1%）。", "conclusion": "CLI-Gym首次公开了一种可以大规模生成环境密集型任务的流程，并且展示了其对于改善代理操作能力的有效性。"}}
{"id": "2602.10997", "pdf": "https://arxiv.org/pdf/2602.10997", "abs": "https://arxiv.org/abs/2602.10997", "authors": ["Zhanyu Guo", "Zikang Yin", "Guobin Zhu", "Shiliang Guo", "Shiyu Zhao"], "title": "Multi-Task Reinforcement Learning of Drone Aerobatics by Exploiting Geometric Symmetries", "categories": ["cs.RO"], "comment": null, "summary": "Flight control for autonomous micro aerial vehicles (MAVs) is evolving from steady flight near equilibrium points toward more aggressive aerobatic maneuvers, such as flips, rolls, and Power Loop. Although reinforcement learning (RL) has shown great potential in these tasks, conventional RL methods often suffer from low data efficiency and limited generalization. This challenge becomes more pronounced in multi-task scenarios where a single policy is required to master multiple maneuvers. In this paper, we propose a novel end-to-end multi-task reinforcement learning framework, called GEAR (Geometric Equivariant Aerobatics Reinforcement), which fully exploits the inherent SO(2) rotational symmetry in MAV dynamics and explicitly incorporates this property into the policy network architecture. By integrating an equivariant actor network, FiLM-based task modulation, and a multi-head critic, GEAR achieves both efficiency and flexibility in learning diverse aerobatic maneuvers, enabling a data-efficient, robust, and unified framework for aerobatic control. GEAR attains a 98.85\\% success rate across various aerobatic tasks, significantly outperforming baseline methods. In real-world experiments, GEAR demonstrates stable execution of multiple maneuvers and the capability to combine basic motion primitives to complete complex aerobatics.", "AI": {"tldr": "提出了一种新的端到端多任务强化学习框架GEAR，利用微飞行器动力学中的SO(2)旋转对称性来高效和灵活地学习多种特技动作。", "motivation": "传统的强化学习方法在处理多任务场景时效率低且泛化能力有限，特别是在需要掌握翻滚、倒立等复杂特技动作的情况下。为解决这一问题，该研究旨在提高自主微型航空器控制的学习效率和鲁棒性。", "method": "GEAR框架通过在策略网络架构中引入旋转不变特性，结合了等变演员网络、FiLM任务调制技术和多头评论家机制，以实现数据高效的统一学习。", "result": "实验结果显示，该方法在多种特技动作中的成功率为98.85%，显著优于基线方法，并且具备执行复杂组合动作的能力。", "conclusion": "GEAR框架能够有效提高自主微型飞行器完成多任务特技控制的效率和稳定性，展示了其在现实世界应用中的潜力。"}}
{"id": "2602.10994", "pdf": "https://arxiv.org/pdf/2602.10994", "abs": "https://arxiv.org/abs/2602.10994", "authors": ["Vasileios Arampatzakis", "George Pavlidis", "Nikolaos Mitianoudis", "Nikos Papamarkos"], "title": "Interpretable Vision Transformers in Image Classification via SVDA", "categories": ["cs.CV"], "comment": "10 pages, 4 figures, submitted to IEEE Access", "summary": "Vision Transformers (ViTs) have achieved state-of-the-art performance in image classification, yet their attention mechanisms often remain opaque and exhibit dense, non-structured behaviors. In this work, we adapt our previously proposed SVD-Inspired Attention (SVDA) mechanism to the ViT architecture, introducing a geometrically grounded formulation that enhances interpretability, sparsity, and spectral structure. We apply the use of interpretability indicators -- originally proposed with SVDA -- to monitor attention dynamics during training and assess structural properties of the learned representations. Experimental evaluations on four widely used benchmarks -- CIFAR-10, FashionMNIST, CIFAR-100, and ImageNet-100 -- demonstrate that SVDA consistently yields more interpretable attention patterns without sacrificing classification accuracy. While the current framework offers descriptive insights rather than prescriptive guidance, our results establish SVDA as a comprehensive and informative tool for analyzing and developing structured attention models in computer vision. This work lays the foundation for future advances in explainable AI, spectral diagnostics, and attention-based model compression.", "AI": {"tldr": "本文提出了将SVD启发的注意力机制（SVDA）应用于视觉变压器，以提高图像分类任务中的可解释性、稀疏性和谱结构。", "motivation": "在视觉变压器中，注意力机制往往是不透明且表现密集无结构的行为。因此，研究者希望引入一种新的机制来增加模型的可解释性并保持准确性。", "method": "本文通过将先前提出的SVDA机制应用于ViT架构，引入了一种基于几何的方法以提高其可解释性和谱结构，并在训练期间使用了可解释性指标来监控注意力动态和评估学习表示的结构性质。", "result": "实验结果表明，SVDA能够产生更具有解释性的注意力模式而不会降低分类准确性。该方法在四个广泛使用的基准上进行了测试，包括CIFAR-10、FashionMNIST、CIFAR-100以及ImageNet-100，并且在所有这些数据集上均表现出一致的优势。", "conclusion": "本文展示了SVDA作为一种全面的和富有信息性的工具，在分析和发展结构化注意力模型方面具有重要的前景。这项工作为进一步改进可解释AI、光谱诊断及基于注意机制的模型压缩奠定了基础。"}}
{"id": "2602.10993", "pdf": "https://arxiv.org/pdf/2602.10993", "abs": "https://arxiv.org/abs/2602.10993", "authors": ["Ivan Vulić", "Adam Grycner", "Quentin de Laroussilhe", "Jonas Pfeiffer"], "title": "LoRA-Squeeze: Simple and Effective Post-Tuning and In-Tuning Compression of LoRA Modules", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Despite its huge number of variants, standard Low-Rank Adaptation (LoRA) is still a dominant technique for parameter-efficient fine-tuning (PEFT). Nonetheless, it faces persistent challenges, including the pre-selection of an optimal rank and rank-specific hyper-parameters, as well as the deployment complexity of heterogeneous-rank modules and more sophisticated LoRA derivatives. In this work, we introduce LoRA-Squeeze, a simple and efficient methodology that aims to improve standard LoRA learning by changing LoRA module ranks either post-hoc or dynamically during training}. Our approach posits that it is better to first learn an expressive, higher-rank solution and then compress it, rather than learning a constrained, low-rank solution directly. The method involves fine-tuning with a deliberately high(er) source rank, reconstructing or efficiently approximating the reconstruction of the full weight update matrix, and then using Randomized Singular Value Decomposition (RSVD) to create a new, compressed LoRA module at a lower target rank. Extensive experiments across 13 text and 10 vision-language tasks show that post-hoc compression often produces lower-rank adapters that outperform those trained directly at the target rank, especially if a small number of fine-tuning steps at the target rank is allowed. Moreover, a gradual, in-tuning rank annealing variant of LoRA-Squeeze consistently achieves the best LoRA size-performance trade-off.", "AI": {"tldr": "提出了一种简单有效的LoRA模块后处理和动态压缩方法，通过提高初始秩来学习更高表现力的解，再使用随机奇异值分解进行压缩。", "motivation": "标准低秩适应面临选择最优秩及特定秩超参数、异质秩模块部署复杂性等问题。为此引入了简化且高效的方法以解决这些问题。", "method": "先用高初始秩训练LoRA模块，在得到充分表达的解后，通过重构完整权重更新矩阵或近似重构，并使用随机奇异值分解技术来压缩至较低目标秩。", "result": "实验表明，这种方法比直接在低秩条件下训练出更好的适配器，特别是在允许少量目标秩下的微调步骤时表现更优。", "conclusion": "渐进式动态压缩变体LoRA-Squeeze可以实现最优的LoRA尺寸性能权衡。"}}
{"id": "2602.10985", "pdf": "https://arxiv.org/pdf/2602.10985", "abs": "https://arxiv.org/abs/2602.10985", "authors": ["Nuno Gonçalves", "Diogo Nunes", "Carla Guerra", "João Marcos"], "title": "DFIC: Towards a balanced facial image dataset for automatic ICAO compliance verification", "categories": ["cs.CV"], "comment": ":I.4", "summary": "Ensuring compliance with ISO/IEC and ICAO standards for facial images in machine-readable travel documents (MRTDs) is essential for reliable identity verification, but current manual inspection methods are inefficient in high-demand environments. This paper introduces the DFIC dataset, a novel comprehensive facial image dataset comprising around 58,000 annotated images and 2706 videos of more than 1000 subjects, that cover a broad range of non-compliant conditions, in addition to compliant portraits. Our dataset provides a more balanced demographic distribution than the existing public datasets, with one partition that is nearly uniformly distributed, facilitating the development of automated ICAO compliance verification methods. Using DFIC, we fine-tuned a novel method that heavily relies on spatial attention mechanisms for the automatic validation of ICAO compliance requirements, and we have compared it with the state-of-the-art aimed at ICAO compliance verification, demonstrating improved results. DFIC dataset is now made public (https://github.com/visteam-isr-uc/DFIC) for the training and validation of new models, offering an unprecedented diversity of faces, that will improve both robustness and adaptability to the intrinsically diverse combinations of faces and props that can be presented to the validation system. These results emphasize the potential of DFIC to enhance automated ICAO compliance methods but it can also be used in many other applications that aim to improve the security, privacy, and fairness of facial recognition systems.", "AI": {"tldr": "该论文介绍了DFIC数据集，旨在平衡面部图像以自动验证ISO/IEC和ICAO标准，并提出了一种基于空间注意力机制的新方法来改进自动合规性验证。", "motivation": "当前的手动检查方法在高需求环境中效率低下，因此需要一个更加平衡的数据集来进行可靠的自动身份验证。", "method": "通过利用DFIC数据集的丰富多样性以及新方法中的空间注意力机制进行模型微调。", "result": "与现有的最佳技术相比，该方法在ICAO合规性验证方面显示出了改进的结果。", "conclusion": "DFIC数据集和提出的自动合规性验证方法有望提高面部图像识别系统的准确性和适应性，并可以用于其他安全、隐私及公平的应用场景。"}}
{"id": "2602.10983", "pdf": "https://arxiv.org/pdf/2602.10983", "abs": "https://arxiv.org/abs/2602.10983", "authors": ["Qian Long", "Yueze Wang", "Jiaxi Song", "Junbo Zhang", "Peiyan Li", "Wenxuan Wang", "Yuqi Wang", "Haoyang Li", "Shaoxuan Xie", "Guocai Yao", "Hanbo Zhang", "Xinlong Wang", "Zhongyuan Wang", "Xuguang Lan", "Huaping Liu", "Xinghang Li"], "title": "Scaling World Model for Hierarchical Manipulation Policies", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models are promising for generalist robot manipulation but remain brittle in out-of-distribution (OOD) settings, especially with limited real-robot data. To resolve the generalization bottleneck, we introduce a hierarchical Vision-Language-Action framework \\our{} that leverages the generalization of large-scale pre-trained world model for robust and generalizable VIsual Subgoal TAsk decomposition VISTA. Our hierarchical framework \\our{} consists of a world model as the high-level planner and a VLA as the low-level executor. The high-level world model first divides manipulation tasks into subtask sequences with goal images, and the low-level policy follows the textual and visual guidance to generate action sequences. Compared to raw textual goal specification, these synthesized goal images provide visually and physically grounded details for low-level policies, making it feasible to generalize across unseen objects and novel scenarios. We validate both visual goal synthesis and our hierarchical VLA policies in massive out-of-distribution scenarios, and the performance of the same-structured VLA in novel scenarios could boost from 14% to 69% with the guidance generated by the world model. Results demonstrate that our method outperforms previous baselines with a clear margin, particularly in out-of-distribution scenarios. Project page: \\href{https://vista-wm.github.io/}{https://vista-wm.github.io}", "AI": {"tldr": "该论文提出了一种分层的Vision-Language-Action框架，用于提高机器人操作任务在分布外场景中的泛化能力。", "motivation": "现有的Vision-Language-Action模型对于一般的机器人操控很有前景，但在分布外设置下仍然脆弱且数据有限。为了克服这一问题，作者提出了一个利用大规模预训练世界模型来增强泛化的分层框架。", "method": "该方法通过一个世界模型作为高层规划器和一个VLA作为低层执行者构成的层次结构实现任务分解。世界模型首先将操作任务分为具有目标图像的任务序列，而低级策略则遵循文本和视觉指导生成动作序列。", "result": "在大规模分布外场景验证中，该方法显著提升了与相同架构VLA相比，在新情景下的性能表现，提高了14%到69%的性能。", "conclusion": "结果表明，该方法明显优于之前的基线模型，尤其是在分布外情境下具有更好的泛化能力。"}}
{"id": "2602.10982", "pdf": "https://arxiv.org/pdf/2602.10982", "abs": "https://arxiv.org/abs/2602.10982", "authors": ["Li Sun", "Qiqi Wan", "Suyang Zhou", "Zhenhao Huang", "Philip S. Yu"], "title": "RiemannGL: Riemannian Geometry Changes Graph Deep Learning", "categories": ["cs.LG", "cs.AI"], "comment": "34 pages, 11 figures, position paper", "summary": "Graphs are ubiquitous, and learning on graphs has become a cornerstone in artificial intelligence and data mining communities. Unlike pixel grids in images or sequential structures in language, graphs exhibit a typical non-Euclidean structure with complex interactions among the objects. This paper argues that Riemannian geometry provides a principled and necessary foundation for graph representation learning, and that Riemannian graph learning should be viewed as a unifying paradigm rather than a collection of isolated techniques. While recent studies have explored the integration of graph learning and Riemannian geometry, most existing approaches are limited to a narrow class of manifolds, particularly hyperbolic spaces, and often adopt extrinsic manifold formulations. We contend that the central mission of Riemannian graph learning is to endow graph neural networks with intrinsic manifold structures, which remains underexplored. To advance this perspective, we identify key conceptual and methodological gaps in existing approaches and outline a structured research agenda along three dimensions: manifold type, neural architecture, and learning paradigm. We further discuss open challenges, theoretical foundations, and promising directions that are critical for unlocking the full potential of Riemannian graph learning. This paper aims to provide a coherent viewpoint and to stimulate broader exploration of Riemannian geometry as a foundational framework for future graph learning research.", "AI": {"tldr": "提出Riemannian几何作为图学习基础框架的观点，探索赋予图神经网络内在流形结构的方法", "motivation": "现有方法在应用Riemannian几何进行图学习时局限于特定类型流形和外在流形表示，缺乏对内在流形结构的深入研究", "method": "识别当前研究中的关键概念和技术空白，并提出沿三个维度的研究议程：流型类型、神经架构和学习范式", "result": "讨论开放挑战、理论基础及未来方向，以解锁Riemannian图学习的潜力", "conclusion": "提供一致视角并激发对Riemannian几何在图学习中作为基础框架的更广泛探索"}}
{"id": "2602.10980", "pdf": "https://arxiv.org/pdf/2602.10980", "abs": "https://arxiv.org/abs/2602.10980", "authors": ["Yuhao Chen", "Zhihao Zhan", "Xiaoxin Lin", "Zijian Song", "Hao Liu", "Qinhan Lyu", "Yubo Zu", "Xiao Chen", "Zhiyuan Liu", "Tao Pu", "Tianshui Chen", "Keze Wang", "Liang Lin", "Guangrun Wang"], "title": "RADAR: Benchmarking Vision-Language-Action Generalization via Real-World Dynamics, Spatial-Physical Intelligence, and Autonomous Evaluation", "categories": ["cs.RO"], "comment": "12 pages, 11 figures, 3 tables", "summary": "VLA models have achieved remarkable progress in embodied intelligence; however, their evaluation remains largely confined to simulations or highly constrained real-world settings. This mismatch creates a substantial reality gap, where strong benchmark performance often masks poor generalization in diverse physical environments. We identify three systemic shortcomings in current benchmarking practices that hinder fair and reliable model comparison. (1) Existing benchmarks fail to model real-world dynamics, overlooking critical factors such as dynamic object configurations, robot initial states, lighting changes, and sensor noise. (2) Current protocols neglect spatial--physical intelligence, reducing evaluation to rote manipulation tasks that do not probe geometric reasoning. (3) The field lacks scalable fully autonomous evaluation, instead relying on simplistic 2D metrics that miss 3D spatial structure or on human-in-the-loop systems that are costly, biased, and unscalable. To address these limitations, we introduce RADAR (Real-world Autonomous Dynamics And Reasoning), a benchmark designed to systematically evaluate VLA generalization under realistic conditions. RADAR integrates three core components: (1) a principled suite of physical dynamics; (2) dedicated tasks that explicitly test spatial reasoning and physical understanding; and (3) a fully autonomous evaluation pipeline based on 3D metrics, eliminating the need for human supervision. We apply RADAR to audit multiple state-of-the-art VLA models and uncover severe fragility beneath their apparent competence. Performance drops precipitously under modest physical dynamics, with the expectation of 3D IoU declining from 0.261 to 0.068 under sensor noise. Moreover, models exhibit limited spatial reasoning capability. These findings position RADAR as a necessary bench toward reliable and generalizable real-world evaluation of VLA models.", "AI": {"tldr": "介绍了一个名为RADAR的基准，用于评估视觉语言动作模型在现实世界条件下的泛化能力。", "motivation": "现有评估方法无法充分模拟真实世界的动态因素和空间物理智能，缺乏大规模自主评价体系。", "method": "构建了包含实际物理动态、空间推理测试任务及基于3D指标的完全自主评估流程的RADAR基准。", "result": "通过RADAR发现先进的视觉语言动作模型在适度物理变动下性能显著下降，且表现出了有限的空间推理能力。", "conclusion": "RADAR填补了现有评估方法的不足，为真实世界条件下可靠和泛化的视觉语言动作模型评价提供了必要的工具。"}}
{"id": "2602.10978", "pdf": "https://arxiv.org/pdf/2602.10978", "abs": "https://arxiv.org/abs/2602.10978", "authors": ["Ruiqi Song", "Lei Liu", "Ya-Nan Zhang", "Chao Wang", "Xiaoning Li", "Nan Mu"], "title": "VFGS-Net: Frequency-Guided State-Space Learning for Topology-Preserving Retinal Vessel Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate retinal vessel segmentation is a critical prerequisite for quantitative analysis of retinal images and computer-aided diagnosis of vascular diseases such as diabetic retinopathy. However, the elongated morphology, wide scale variation, and low contrast of retinal vessels pose significant challenges for existing methods, making it difficult to simultaneously preserve fine capillaries and maintain global topological continuity. To address these challenges, we propose the Vessel-aware Frequency-domain and Global Spatial modeling Network (VFGS-Net), an end-to-end segmentation framework that seamlessly integrates frequency-aware feature enhancement, dual-path convolutional representation learning, and bidirectional asymmetric spatial state-space modeling within a unified architecture. Specifically, VFGS-Net employs a dual-path feature convolution module to jointly capture fine-grained local textures and multi-scale contextual semantics. A novel vessel-aware frequency-domain channel attention mechanism is introduced to adaptively reweight spectral components, thereby enhancing vessel-relevant responses in high-level features. Furthermore, at the network bottleneck, we propose a bidirectional asymmetric Mamba2-based spatial modeling block to efficiently capture long-range spatial dependencies and strengthen the global continuity of vascular structures. Extensive experiments on four publicly available retinal vessel datasets demonstrate that VFGS-Net achieves competitive or superior performance compared to state-of-the-art methods. Notably, our model consistently improves segmentation accuracy for fine vessels, complex branching patterns, and low-contrast regions, highlighting its robustness and clinical potential.", "AI": {"tldr": "提出了一种基于频率引导状态空间学习的拓扑保持视网膜血管分割网络（VFGS-Net），用于准确地进行视网膜血管分割。", "motivation": "针对现有的视网膜血管分割方法在处理细长形态、尺度变化和低对比度等挑战时存在困难的问题，提出了一种新的方法来同时保留细小毛细血管并保持全局拓扑连续性。", "method": "通过双路径特征卷积模块捕获细粒度局部纹理和多尺度上下文语义，并引入视网膜血管感知频域通道注意机制以自适应地重新加权谱分量，从而增强高级特征中的视网膜血管相关响应。在瓶颈处使用双向非对称Mamba2基空间建模块来有效捕获长距离的空间依赖性并加强血管结构的全局连续性。", "result": "实验结果表明，VFGS-Net在四个公开的数据集上表现出色或优于现有方法，并且能够在细小血管、复杂分支模式和低对比度区域中保持较高的分割准确性。", "conclusion": "提出的VFGS-Net模型在视网膜血管分割任务中展示了优越的性能，并具有潜在的临床应用价值。"}}
{"id": "2602.10975", "pdf": "https://arxiv.org/pdf/2602.10975", "abs": "https://arxiv.org/abs/2602.10975", "authors": ["Qixing Zhou", "Jiacheng Zhang", "Haiyang Wang", "Rui Hao", "Jiahe Wang", "Minghao Han", "Yuxue Yang", "Shuzhe Wu", "Feiyang Pan", "Lue Fan", "Dandan Tu", "Zhaoxiang Zhang"], "title": "FeatureBench: Benchmarking Agentic Coding for Complex Feature Development", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e.g., bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the evaluation coverage. To address such issues, we propose FeatureBench, a benchmark designed to evaluate agentic coding performance in end-to-end, feature-oriented software development. FeatureBench incorporates an execution-based evaluation protocol and a scalable test-driven method that automatically derives tasks from code repositories with minimal human effort. By tracing from unit tests along a dependency graph, our approach can identify feature-level coding tasks spanning multiple commits and PRs scattered across the development timeline, while ensuring the proper functioning of other features after the separation. Using this framework, we curated 200 challenging evaluation tasks and 3825 executable environments from 24 open-source repositories in the first version of our benchmark. Empirical evaluation reveals that the state-of-the-art agentic model, such as Claude 4.5 Opus, which achieves a 74.4% resolved rate on SWE-bench, succeeds on only 11.0% of tasks, opening new opportunities for advancing agentic coding. Moreover, benefiting from our automated task collection toolkit, FeatureBench can be easily scaled and updated over time to mitigate data leakage. The inherent verifiability of constructed environments also makes our method potentially valuable for agent training.", "AI": {"tldr": "FeatureBench是一个基准测试，用于评估大型语言模型在端到端、特征导向的软件开发中的编码性能。", "motivation": "随着大型语言模型在软件行业的采用日益增多，需要一个全面的基准来衡量其编码能力。现有基准测试覆盖范围有限，依赖非可执行评估或缺乏自动更新的方法。为解决这些问题，提出了FeatureBench。", "method": "FeatureBench利用执行基础的评价协议和一种可扩展的测试驱动方法，从代码仓库中自动提取任务，仅需少量人工干预即可持续更新。该方法通过跟踪单元测试来识别跨越多个提交和PR的功能级编码任务，并确保其他功能在分离后的正常运行。", "result": "使用FeatureBench进行实证评估显示，在SWE-bench上表现优异的Claude 4.5 Opus模型仅能在11.0%的任务中取得成功，表明了该基准对当前代理模型的重大挑战。此外，由于自动化的任务收集工具，使得FeatureBench易于扩展和更新。", "conclusion": "通过构建具有内在验证性的执行环境，FeatureBench不仅为评估提供了新的视角，也展示了其在代理训练中的潜在价值，有助于推动代理编码技术的发展。"}}
{"id": "2602.10967", "pdf": "https://arxiv.org/pdf/2602.10967", "abs": "https://arxiv.org/abs/2602.10967", "authors": ["Samanta Ghosh", "Shaila Afroz Anika", "Umma Habiba Ahmed", "B. M. Shahria Alam", "Mohammad Tahmid Noor", "Nishat Tasnim Niloy"], "title": "Healthy Harvests: A Comparative Look at Guava Disease Classification Using InceptionV3", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "6 pages, 13 figures, his is the author's accepted manuscript of a paper accepted for publication in the Proceedings of the 16th International IEEE Conference on Computing, Communication and Networking Technologies (ICCCNT 2025). The final published version will be available via IEEE Xplore", "summary": "Guava fruits often suffer from many diseases. This can harm fruit quality and fruit crop yield. Early identification is important for minimizing damage and ensuring fruit health. This study focuses on 3 different categories for classifying diseases. These are Anthracnose, Fruit flies, and Healthy fruit. The data set used in this study is collected from Mendeley Data. This dataset contains 473 original images of Guava. These images vary in size and format. The original dataset was resized to 256x256 pixels with RGB color mode for better consistency. After this, the Data augmentation process is applied to improve the dataset by generating variations of the original images. The augmented dataset consists of 3784 images using advanced preprocessing techniques. Two deep learning models were implemented to classify the images. The InceptionV3 model is well known for its advanced framework. These apply multiple convolutional filters for obtaining different features effectively. On the other hand, the ResNet50 model helps to train deeper networks by using residual learning. The InceptionV3 model achieved the impressive accuracy of 98.15%, and ResNet50got 94.46% accuracy. Data mixing methods such as CutMix and MixUp were applied to enhance the model's robustness. The confusion matrix was used to evaluate the overall model performance of both InceptionV3 and Resnet50. Additionally, SHAP analysis is used to improve interpretability, which helps to find the significant parts of the image for the model prediction. This study purposes to highlight how advanced models enhan", "AI": {"tldr": "本文研究了使用InceptionV3模型对番石榴疾病进行分类的方法，以提高早期识别的准确性。", "motivation": "为了减少番石榴因病害导致的质量下降和产量损失，通过建立高效的疾病分类系统来实现疾病的早期识别。", "method": "采用了收集自Mendeley Data的数据集，经过预处理、数据增强等步骤，并使用InceptionV3和ResNet50模型进行训练。同时利用CutMix和MixUp方法提升模型的鲁棒性，并通过SHAP分析提高模型解释性。", "result": "InceptionV3模型在疾病分类任务中达到了98.15%的准确率，而ResNet50模型为94.46%，显示出较高的识别能力。", "conclusion": "该研究证明了使用先进的深度学习技术可以有效提高番石榴疾病的早期识别和分类准确性。"}}
{"id": "2602.10964", "pdf": "https://arxiv.org/pdf/2602.10964", "abs": "https://arxiv.org/abs/2602.10964", "authors": ["F. Carichon", "R. Rampa", "G. Farnadi"], "title": "Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation", "categories": ["cs.AI"], "comment": "14 pages, 12 figures, conference", "summary": "Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising concerns about stereotyping, homogenization, and the erasure of culturally specific forms of expression. Understanding whether LLMs can meaningfully align with diverse cultures beyond the dominant ones remains a critical challenge. In this paper, we study cultural adaptation in LLMs through the lens of cooking recipes, a domain in which culture, tradition, and creativity are tightly intertwined. We build on the \\textit{GlobalFusion} dataset, which pairs human recipes from different countries according to established measures of cultural distance. Using the same country pairs, we generate culturally adapted recipes with multiple LLMs, enabling a direct comparison between human and LLM behavior in cross-cultural content creation. Our analysis shows that LLMs fail to produce culturally representative adaptations. Unlike humans, the divergence of their generated recipes does not correlate with cultural distance. We further provide explanations for this gap. We show that cultural information is weakly preserved in internal model representations, that models inflate novelty in their production by misunderstanding notions such as creativity and tradition, and that they fail to identify adaptation with its associated countries and to ground it in culturally salient elements such as ingredients. These findings highlight fundamental limitations of current LLMs for culturally oriented generation and have important implications for their use in culturally sensitive applications.", "AI": {"tldr": "研究通过生成不同国家间的烹饪食谱来探讨大型语言模型（LLM）在跨文化内容创作中的文化适应性。", "motivation": "探索和理解LLMs是否能够与主流文化以外的多样化文化有意义地对齐，解决它们可能存在的系统性文化偏见问题。", "method": "构建了一个用于生成并比较不同国家间烹饪食谱的数据集，并使用多个LLM来生成这些文化的改编版本。", "result": "发现LLMs在跨文化交流时无法产生具有代表性的文化适应。LLM的生成结果与人类行为不符，未按文化距离差异调整其产出内容。", "conclusion": "指出当前LLMs存在根本性限制，在处理文化定向生成任务上表现不佳，这些局限可能影响它们在文化敏感应用中的使用效果。"}}
{"id": "2602.10963", "pdf": "https://arxiv.org/pdf/2602.10963", "abs": "https://arxiv.org/abs/2602.10963", "authors": ["Srishti Siddharth", "Vivek Natarajan", "Ravi N. Banavar"], "title": "Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation", "categories": ["eess.SY", "cs.RO", "math.NA"], "comment": "Submitted to: Computers and Mathematics with Applications", "summary": "In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system.", "AI": {"tldr": "本文推导了三维几何精确梁的时空连续方程，并采用Lie群变分积分器技术获得一个包含旋转运动和截面变形的离散模型。", "motivation": "为了更准确地模拟三维几何精确梁的动力学行为，包括其旋转和截面变形的影响，同时确保在数值模拟中保持体积守恒和能量守恒等物理特性。", "method": "采用Lie群变分积分器技术推导出包含截面变形的连续空间时间方程，并通过离散化获得一个具备良好性能的模型。", "result": "实验结果表明，该模型在各种初始条件下均能有效复制系统的物理学行为，体现了体积守恒和能量守恒等优点。", "conclusion": "提出的Lie群变分积分器方法成功地实现了三维几何精确梁的动力学模拟，并且能够准确处理截面变形问题。"}}
{"id": "2602.10961", "pdf": "https://arxiv.org/pdf/2602.10961", "abs": "https://arxiv.org/abs/2602.10961", "authors": ["Simone Orelli", "Mirko Mizzoni", "Antonio Franchi"], "title": "Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces", "categories": ["cs.RO", "math.OC"], "comment": null, "summary": "Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.", "AI": {"tldr": "本文对一类带假力的浮动刚体进行了稳定性分析，建立了模型并证明了局部指数稳定性。", "motivation": "标准几何控制依赖于力矩解耦假设，在许多空中平台上这种假设失效。现有策略缺乏严格的理论认证，本文填补这一空白。", "method": "引入一个典型模型，采用Lyapunov方法进行稳定性分析。", "result": "证明了浮动刚体的局部指数稳定性，并解决了非最小相位行为问题。", "conclusion": "首次为带假力的浮动刚体系提供了严格的理论认证，填补了现有研究空白。"}}
{"id": "2602.10959", "pdf": "https://arxiv.org/pdf/2602.10959", "abs": "https://arxiv.org/abs/2602.10959", "authors": ["Feilong Liu"], "title": "Rotary Positional Embeddings as Phase Modulation: Theoretical Bounds on the RoPE Base for Long-Context Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Rotary positional embeddings (RoPE) are widely used in large language models to encode token positions through multiplicative rotations, yet their behavior at long context lengths remains poorly characterized. In this work, we reinterpret RoPE as phase modulation applied to a bank of complex oscillators, enabling analysis through classical signal processing theory. Under this formulation, we derive principled lower bounds on the RoPE base parameter that are necessary to preserve positional coherence over a target context length. These include a fundamental aliasing bound, analogous to a Nyquist limit, and a DC-component stability bound that constrains phase drift in low-frequency positional modes. We further extend this analysis to deep transformers, showing that repeated rotary modulation across layers compounds angular misalignment, tightening the base requirement as depth increases. Complementing these results, we derive a precision-dependent upper bound on the RoPE base arising from finite floating-point resolution. Beyond this limit, incremental phase updates become numerically indistinguishable, leading to positional erasure even in the absence of aliasing. Together, the lower and upper bounds define a precision- and depth-dependent feasibility region a Goldilocks zone for long-context transformers. We validate the framework through a comprehensive case study of state-of-the-art models, including LLaMA, Mistral, and DeepSeek variants, showing that observed successes, failures, and community retrofits align closely with the predicted bounds. Notably, models that violate the stability bound exhibit attention collapse and long-range degradation, while attempts to scale beyond one million tokens encounter a hard precision wall independent of architecture or training.", "AI": {"tldr": "该论文通过信号处理理论重新诠释了旋转位置嵌入（RoPE），并推导出在长上下文长度下保持位置一致性的RoPE基础参数的原理性下限。", "motivation": "目前，大语言模型中广泛使用RoPE来编码标记的位置，但在长上下文长度下的行为尚不清楚。该论文旨在通过信号处理理论分析RoPE的行为和限制条件。", "method": "将RoPE解释为应用于复数振荡器组的相位调制，利用经典信号处理理论推导出在目标上下文长度下保持位置一致性的RoPE基础参数的原理性下限。此外还扩展了深度Transformer中的旋转调整分析，并考虑了有限精度浮点分辨率带来的上界。", "result": "该论文提出了针对长上下文Transformer的RoPE基础参数的稳定性界限和精度依赖上限，形成了一个与精度和深度相关的工作区间。通过案例研究验证了这些理论预测的一致性。", "conclusion": "违反稳定性的模型会表现出注意力崩溃和长距离降解现象，而试图扩展到一百万个标记以上则遇到了独立于架构或训练的精确度壁垒。"}}
{"id": "2602.10953", "pdf": "https://arxiv.org/pdf/2602.10953", "abs": "https://arxiv.org/abs/2602.10953", "authors": ["Mingyu Cao", "Alvaro Correia", "Christos Louizos", "Shiwei Liu", "Lu Yin"], "title": "Search or Accelerate: Confidence-Switched Position Beam Search for Diffusion Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 8 figures", "summary": "Diffusion Language Models (DLMs) generate text by iteratively denoising a masked sequence, repeatedly deciding which positions to commit at each step. Standard decoding follows a greedy rule: unmask the most confident positions, yet this local choice can lock the model into a suboptimal unmasking order, especially on reasoning-heavy prompts. We present SOAR, a training-free decoding algorithm that adapts its behavior to the model's uncertainty. When confidence is low, SOAR briefly widens the search over alternative unmasking decisions to avoid premature commitments; when confidence is high, it collapses the search and decodes many positions in parallel to reduce the number of denoising iterations. Across mathematical reasoning and code generation benchmarks (GSM8K, MBPP, HumanEval) on Dream-7B and LLaDA-8B, SOAR improves generation quality while maintaining competitive inference speed, offering a practical way to balance quality and efficiency in DLM decoding.", "AI": {"tldr": "SOAR算法通过适应模型不确定性，改进了扩散语言模型的生成质量。", "motivation": "标准解码遵循贪婪规则，可能导致次优的去噪顺序。为此，提出了SOAR，一种无需训练即可调整行为的解码算法。", "method": "当模型信心低时，SOAR会拓宽搜索空间以避免过早承诺；信心高时，则收敛搜索并同时解码多个位置以减少迭代次数。", "result": "在数学推理和代码生成基准测试中，SOAR提升了生成质量，并保持了竞争力的推断速度。", "conclusion": "通过平衡质量和效率，SOAR为扩散语言模型提供了一种实用的解码方案。"}}
{"id": "2602.10948", "pdf": "https://arxiv.org/pdf/2602.10948", "abs": "https://arxiv.org/abs/2602.10948", "authors": ["Palash Dey", "Anubhav Dhar", "Ashlesha Hota", "Sudeshna Kolay", "Aritra Mitra"], "title": "Parameterized Complexity of Finding a Maximum Common Vertex Subgraph Without Isolated Vertices", "categories": ["cs.CC", "cs.DS"], "comment": null, "summary": "In this paper, we study the Maximum Common Vertex Subgraph problem: Given two input graphs $G_1,G_2$ and a non-negative integer $h$, is there a common subgraph $H$ on at least $h$ vertices such that there is no isolated vertex in $H$. In other words, each connected component of $H$ has at least $2$ vertices. This problem naturally arises in graph theory along with other variants of the well-studied Maximum Common Subgraph problem and also has applications in computational social choice. We show that this problem is NP-hard and provide an FPT algorithm when parameterized by $h$. Next, we conduct a study of the problem on common structural parameters like vertex cover number, maximum degree, treedepth, pathwidth and treewidth of one or both input graphs. We derive a complete dichotomy of parameterized results for our problem with respect to individual parameterizations as well as combinations of parameterizations from the above structural parameters. This provides us with a deep insight into the complexity theoretic and parameterized landscape of this problem.", "AI": {"tldr": "研究了在两个输入图中寻找一个至少有h个顶点且没有孤立节点的公共子图的问题。", "motivation": "该问题源自图论中的最大共同子图问题，并具有计算社会选择的实际应用。目的是揭示此问题的参数化复杂性，了解其理论意义和应用场景。", "method": "提出了一种当参数为h时的FPT算法；对顶点覆盖数、最大度数、树深度、路径宽度和树宽等结构参数进行了研究，并给出了完整的参数结果。", "result": "证明了该问题是NP难问题，提供了一个针对参数化h的FPT算法，并导出了关于单一参数化及多个参数化的完全二分法结果。", "conclusion": "通过详细的理论分析和技术实验揭示了最大共同子图问题在复杂性和参数化景观上的深刻见解。"}}
{"id": "2602.10947", "pdf": "https://arxiv.org/pdf/2602.10947", "abs": "https://arxiv.org/abs/2602.10947", "authors": ["Kacper Dudzic", "Karolina Drożdż", "Maciej Wodziński", "Anastazja Szuła", "Marcin Moskalewicz"], "title": "Computational Phenomenology of Temporal Experience in Autism: Quantifying the Emotional and Narrative Characteristics of Lived Unpredictability", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Disturbances in temporality, such as desynchronization with the social environment and its unpredictability, are considered core features of autism with a deep impact on relationships. However, limitations regarding research on this issue include: 1) the dominance of deficit-based medical models of autism, 2) sample size in qualitative research, and 3) the lack of phenomenological anchoring in computational research. To bridge the gap between phenomenological and computational approaches and overcome sample-size limitations, our research integrated three methodologies. Study A: structured phenomenological interviews with autistic individuals using the Transdiagnostic Assessment of Temporal Experience. Study B: computational analysis of an autobiographical corpus of autistic narratives built for this purpose. Study C: a replication of a computational study using narrative flow measures to assess the perceived phenomenological authenticity of autistic autobiographies. Interviews revealed that the most significant differences between the autistic and control groups concerned unpredictability of experience. Computational results mirrored these findings: the temporal lexicon in autistic narratives was significantly more negatively valenced - particularly the \"Immediacy & Suddenness\" category. Outlier analysis identified terms associated with perceived discontinuity (unpredictably, precipitously, and abruptly) as highly negative. The computational analysis of narrative flow found that the autistic narratives contained within the corpus quantifiably resemble autobiographical stories more than imaginary ones. Overall, the temporal challenges experienced by autistic individuals were shown to primarily concern lived unpredictability and stem from the contents of lived experience, and not from autistic narrative construction.", "AI": {"tldr": "通过结合现象学访谈和计算分析，研究自闭症个体经历中的时间体验及其情感特征。", "motivation": "为了填补现象学与计算方法之间的空白，并克服样本量限制，更好地理解自闭症中时间感的挑战性特性。", "method": "采用三项研究：结构化现象学访谈、基于叙事语料库的计算分析以及叙述流畅度测量。", "result": "发现自闭症群体在经历中的不可预测性和突然性方面表现出显著差异，其情感词汇更倾向于负面评价，并且这些特征与真实生活体验相关而非虚构故事构造。", "conclusion": "自闭症个体面临的主要时间挑战在于生活的不可预测性，这源于实际生活中所遇到的事件内容。"}}
{"id": "2602.10946", "pdf": "https://arxiv.org/pdf/2602.10946", "abs": "https://arxiv.org/abs/2602.10946", "authors": ["Ramtin Tabatabaei", "Alireza Taheri"], "title": "Developing Neural Network-Based Gaze Control Systems for Social Robots", "categories": ["cs.RO"], "comment": null, "summary": "During multi-party interactions, gaze direction is a key indicator of interest and intent, making it essential for social robots to direct their attention appropriately. Understanding the social context is crucial for robots to engage effectively, predict human intentions, and navigate interactions smoothly. This study aims to develop an empirical motion-time pattern for human gaze behavior in various social situations (e.g., entering, leaving, waving, talking, and pointing) using deep neural networks based on participants' data. We created two video clips-one for a computer screen and another for a virtual reality headset-depicting different social scenarios. Data were collected from 30 participants: 15 using an eye-tracker and 15 using an Oculus Quest 1 headset. Deep learning models, specifically Long Short-Term Memory (LSTM) and Transformers, were used to analyze and predict gaze patterns. Our models achieved 60% accuracy in predicting gaze direction in a 2D animation and 65% accuracy in a 3D animation. Then, the best model was implemented onto the Nao robot; and 36 new participants evaluated its performance. The feedback indicated overall satisfaction, with those experienced in robotics rating the models more favorably.", "AI": {"tldr": "开发基于神经网络的眼球控制系统的社会机器人", "motivation": "在多党互动中，眼球方向是兴趣和意图的关键指标。理解社交环境对机器人有效参与、预测人类意图和平滑导航交互至关重要", "method": "使用长短期记忆（LSTM）和变压器等深度学习模型分析并预测参与者数据中的眼球行为模式", "result": "在2D动画中达到60%的准确性，在3D动画中达到65%，并将最佳模型部署到Nao机器人上，新参与者对其表现表示整体满意", "conclusion": "该研究成功地开发了基于神经网络的眼球控制系统，并提高了社会机器人的交互体验"}}
{"id": "2602.10943", "pdf": "https://arxiv.org/pdf/2602.10943", "abs": "https://arxiv.org/abs/2602.10943", "authors": ["Martin Gromniak", "Jan-Gerrit Habekost", "Sebastian Kamp", "Sven Magg", "Stefan Wermter"], "title": "Towards Learning a Generalizable 3D Scene Representation from 2D Observations", "categories": ["cs.CV", "cs.RO"], "comment": "Paper accepted at ESANN 2026", "summary": "We introduce a Generalizable Neural Radiance Field approach for predicting 3D workspace occupancy from egocentric robot observations. Unlike prior methods operating in camera-centric coordinates, our model constructs occupancy representations in a global workspace frame, making it directly applicable to robotic manipulation. The model integrates flexible source views and generalizes to unseen object arrangements without scene-specific finetuning. We demonstrate the approach on a humanoid robot and evaluate predicted geometry against 3D sensor ground truth. Trained on 40 real scenes, our model achieves 26mm reconstruction error, including occluded regions, validating its ability to infer complete 3D occupancy beyond traditional stereo vision methods.", "AI": {"tldr": "本文提出了一种从二维观察中学习通用的三维场景表示的方法，以预测机器人的工作空间占用情况。", "motivation": "现有的方法通常基于相机坐标系操作，而该模型构建全局工作空间中的占用表示，使其适用于机器人操纵任务。此外，模型能够处理灵活的源视图，并且在未经特定场景微调的情况下对未见过的对象排列进行泛化。", "method": "提出了一种通用神经辐射场的方法，用于从机器人的第一人称视角观察中预测三维工作空间的占用情况。", "result": "该模型在40个真实场景上训练后，在包括被遮挡区域在内的重建误差为26毫米，证明了其比传统立体视觉方法更能完整地推断出3D占用情况的能力。", "conclusion": "通过实验验证，所提出的通用神经辐射场方法能够在未经特定场景微调的情况下泛化到未见过的对象排列，并能够准确预测三维工作空间的占用情况。"}}
{"id": "2602.10942", "pdf": "https://arxiv.org/pdf/2602.10942", "abs": "https://arxiv.org/abs/2602.10942", "authors": ["Alireza Taheri", "Minoo Alemi", "Elham Ranjkar", "Raman Rafatnejad", "Ali F. Meghdari"], "title": "Design, Development, and Use of Maya Robot as an Assistant for the Therapy/Education of Children with Cancer: a Pilot Study", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "This study centers around the design and implementation of the Maya Robot, a portable elephant-shaped social robot, intended to engage with children undergoing cancer treatment. Initial efforts were devoted to enhancing the robot's facial expression recognition accuracy, achieving a 98% accuracy through deep neural networks. Two subsequent preliminary exploratory experiments were designed to advance the study's objectives. The first experiment aimed to compare pain levels experienced by children during the injection process, with and without the presence of the Maya robot. Twenty-five children, aged 4 to 9, undergoing cancer treatment participated in this counterbalanced study. The paired T-test results revealed a significant reduction in perceived pain when the robot was actively present in the injection room. The second experiment sought to assess perspectives of hospitalized children and their mothers during engagement with Maya through a game. Forty participants, including 20 children aged 4 to 9 and their mothers, were involved. Post Human-Maya Interactions, UTAUT questionnaire results indicated that children experienced significantly less anxiety than their parents during the interaction and game play. Notably, children exhibited higher trust levels in both the robot and the games, presenting a statistically significant difference in trust levels compared to their parents (P-value < 0.05). This preliminary exploratory study highlights the positive impact of utilizing Maya as an assistant for therapy/education in a clinical setting, particularly benefiting children undergoing cancer treatment. The findings underscore the potential of social robots in pediatric healthcare contexts, emphasizing improved pain management and emotional well-being among young patients.", "AI": {"tldr": "设计并实施了一种名为Maya的社交机器人，用于减轻儿童癌症治疗期间的疼痛和焦虑。", "motivation": "利用社交机器人改善儿童在癌症治疗过程中的体验，减少他们的痛苦与焦虑情绪。", "method": "首先优化了机器人面部表情识别准确度；接着进行了两个实验：一是对比注射过程中孩子有无Maya机器人的疼痛感知情况；二是通过游戏评估孩子及其母亲对Maya的交互看法和信任水平。", "result": "实验表明，使用Maya可以显著减少孩子的疼痛感知，并降低他们的焦虑情绪。孩子们对机器人和游戏的信任度高于其父母。", "conclusion": "初步研究表明，Maya在儿科医疗环境中作为辅助工具具有积极影响，有助于提高儿童治疗期间的舒适感及心理健康状态。"}}
{"id": "2602.10940", "pdf": "https://arxiv.org/pdf/2602.10940", "abs": "https://arxiv.org/abs/2602.10940", "authors": ["Guandong Li"], "title": "FastUSP: A Multi-Level Collaborative Acceleration Framework for Distributed Diffusion Model Inference", "categories": ["cs.CV"], "comment": null, "summary": "Large-scale diffusion models such as FLUX (12B parameters) and Stable Diffusion 3 (8B parameters) require multi-GPU parallelism for efficient inference. Unified Sequence Parallelism (USP), which combines Ulysses and Ring attention mechanisms, has emerged as the state-of-the-art approach for distributed attention computation. However, existing USP implementations suffer from significant inefficiencies including excessive kernel launch overhead and suboptimal computation-communication scheduling. In this paper, we propose \\textbf{FastUSP}, a multi-level optimization framework that integrates compile-level optimization (graph compilation with CUDA Graphs and computation-communication reordering), communication-level optimization (FP8 quantized collective communication), and operator-level optimization (pipelined Ring attention with double buffering). We evaluate FastUSP on FLUX (12B) and Qwen-Image models across 2, 4, and 8 NVIDIA RTX 5090 GPUs. On FLUX, FastUSP achieves consistent \\textbf{1.12$\\times$--1.16$\\times$} end-to-end speedup over baseline USP, with compile-level optimization contributing the dominant improvement. On Qwen-Image, FastUSP achieves \\textbf{1.09$\\times$} speedup on 2 GPUs; on 4--8 GPUs, we identify a PyTorch Inductor compatibility limitation with Ring attention that prevents compile optimization, while baseline USP scales to 1.30$\\times$--1.46$\\times$ of 2-GPU performance. We further provide a detailed analysis of the performance characteristics of distributed diffusion inference, revealing that kernel launch overhead -- rather than communication latency -- is the primary bottleneck on modern high-bandwidth GPU interconnects.", "AI": {"tldr": "提出了一种名为FastUSP的多级优化框架，以加速分布式扩散模型的推理。", "motivation": "现有Unified Sequence Parallelism (USP)实现存在显著效率问题，包括过多的内核启动开销和计算-通信调度不优。", "method": "提出了一个整合了编译级别、通信级别及操作级别优化的多级框架FastUSP。具体包括使用CUDA Graphs进行图形编译与重新排序以减少延迟，并利用FP8量化集体通讯以及双缓冲流水线式Ring注意力机制优化。", "result": "在FLUX模型上，FastUSP实现了1.12倍至1.16倍的加速比；而在Qwen-Image模型中，在两个GPU上实现1.09倍加速。同时分析了分布式扩散推理性能瓶颈为内核启动开销而非通信延迟。", "conclusion": "FastUSP框架有效减少了内核启动开销，实现了显著的速度提升，且揭示了现代高带宽GPU互连下的主要瓶颈在于内核启动开销而非通信延迟。"}}
{"id": "2602.10935", "pdf": "https://arxiv.org/pdf/2602.10935", "abs": "https://arxiv.org/abs/2602.10935", "authors": ["Bijean Ghafouri", "Dorsaf Sallami", "Luca Luceri", "Taylor Lynn Curtis", "Jean-Francois Godbout", "Emilio Ferrara", "Reihaneh Rabbany"], "title": "What do people want to fact-check?", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Research on misinformation has focused almost exclusively on supply, asking what falsehoods circulate, who produces them, and whether corrections work. A basic demand-side question remains unanswered. When ordinary people can fact-check anything they want, what do they actually ask about? We provide the first large-scale evidence on this question by analyzing close to 2{,}500 statements submitted by 457 participants to an open-ended AI fact-checking system. Each claim is classified along five semantic dimensions (domain, epistemic form, verifiability, target entity, and temporal reference), producing a behavioral map of public verification demand. Three findings stand out. First, users range widely across topics but default to a narrow epistemic repertoire, overwhelmingly submitting simple descriptive claims about present-day observables. Second, roughly one in four requests concerns statements that cannot be empirically resolved, including moral judgments, speculative predictions, and subjective evaluations, revealing a systematic mismatch between what users seek from fact-checking tools and what such tools can deliver. Third, comparison with the FEVER benchmark dataset exposes sharp structural divergences across all five dimensions, indicating that standard evaluation corpora encode a synthetic claim environment that does not resemble real-world verification needs. These results reframe fact-checking as a demand-driven problem and identify where current AI systems and benchmarks are misaligned with the uncertainty people actually experience.", "AI": {"tldr": "研究通过分析参与者提交给一个开放式AI事实核查系统的近2500条声明，探讨公众在能够自由选择想要核实的信息时会提出哪些问题。", "motivation": "以往关于虚假信息的研究主要集中在供应方面，而忽略了一个基本的需求方问题：当普通人可以自由选择他们想验证的任何事情时，他们会实际询问什么？", "method": "通过分析457名参与者提交给一个开放式AI事实核查系统近2500条声明，按照五个语义维度（领域、认识形式、可验证性、目标实体和时间参考）对每个陈述进行分类。", "result": "发现用户在主题上广泛选择但倾向于提出简单描述当前观测的事实；约四分之一的请求涉及无法通过经验解决的声明；与标准评估数据集对比表明存在显著结构差异，揭示出AI系统和基准测试工具与实际验证需求不匹配的情况。", "conclusion": "研究结果将事实核查问题重新定义为一个需求驱动的问题，并指出现有AI系统和基准测试在处理公众面临的不确定性方面存在的局限性。"}}
{"id": "2602.10934", "pdf": "https://arxiv.org/pdf/2602.10934", "abs": "https://arxiv.org/abs/2602.10934", "authors": ["Yitian Gong", "Kuangwei Chen", "Zhaoye Fei", "Xiaogui Yang", "Ke Chen", "Yang Wang", "Kexin Huang", "Mingshu Chen", "Ruixiao Li", "Qingyuan Cheng", "Shimin Li", "Xipeng Qiu"], "title": "MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models", "categories": ["cs.SD", "eess.AS"], "comment": "27 pages, 8 figures", "summary": "Discrete audio tokenizers are fundamental to empowering large language models with native audio processing and generation capabilities. Despite recent progress, existing approaches often rely on pretrained encoders, semantic distillation, or heterogeneous CNN-based architectures. These designs introduce fixed inductive biases that limit reconstruction fidelity and hinder effective scaling. In this paper, we argue that discrete audio tokenization should be learned fully end-to-end using a homogeneous and scalable architecture. To this end, we first propose CAT (Causal Audio Tokenizer with Transformer), a purely Transformer-based architecture that jointly optimizes the encoder, quantizer, and decoder from scratch for high-fidelity reconstruction. Building on the CAT architecture, we develop MOSS-Audio-Tokenizer, a large-scale audio tokenizer featuring 1.6 billion parameters, pre-trained on 3 million hours of diverse, general audio data. We show that this simple, fully end-to-end approach built from homogeneous, causal Transformer blocks scales gracefully and supports high-fidelity reconstruction across diverse audio domains. Across speech, sound, and music, MOSS-Audio-Tokenizer consistently outperforms prior codecs over a wide range of bitrates, while exhibiting predictable improvements with increased scale. Notably, leveraging the discrete tokens from our model, we develop the first purely autoregressive TTS model that surpasses prior non-autoregressive and cascaded systems. Furthermore, MOSS-Audio-Tokenizer enables competitive ASR performance without auxiliary encoders. Our findings position the CAT architecture as a unified, scalable interface for the next generation of native audio foundation models.", "AI": {"tldr": "本文提出了一种基于Transformer的全端到端音频令牌化方法，并开发了MOSS-Audio-Tokenizer，一个大规模的音频令牌器，能够支持跨多种音频领域的高质量重建。", "motivation": "现有音频令牌化技术依赖于预训练编码器、语义蒸馏或异构CNN架构，这些设计引入固定的归纳偏差，限制了重构保真度并阻碍了有效扩展。因此，作者认为应采用全端到端学习的方法来实现离散音频令牌化。", "method": "首先提出了基于Transformer的CAT（因果音频令牌器）架构，该架构从头开始优化编码器、量化器和解码器以实现高保真度重构；在此基础上，开发了拥有1.6亿参数并预训练于300万小时多样化通用音频数据上的MOSS-Audio-Tokenizer。", "result": "实验表明，通过纯自回归方法生成的文本到语音模型超越了以前的非自回归和级联系统，并且该令牌器能够实现无辅助编码器的竞争性自动语音识别性能。", "conclusion": "CAT架构作为下一代原生音频基础模型统一、可扩展接口的地位得到了证实。"}}
{"id": "2602.10922", "pdf": "https://arxiv.org/pdf/2602.10922", "abs": "https://arxiv.org/abs/2602.10922", "authors": ["Jean Cardinal", "Micha Sharir"], "title": "Implicit representations via the polynomial method", "categories": ["cs.CG", "cs.DM", "cs.DS", "math.CO"], "comment": null, "summary": "Semialgebraic graphs are graphs whose vertices are points in $\\mathbb{R}^d$, and adjacency between two vertices is determined by the truth value of a semialgebraic predicate of constant complexity. We show how to harness polynomial partitioning methods to construct compact adjacency labeling schemes for families of semialgebraic graphs. That is, we show that for any family of semialgebraic graphs, given a graph on $n$ vertices in this family, we can assign a label consisting of $O(n^{1-2/(d+1) + \\varepsilon})$ bits to each vertex (where $\\varepsilon > 0$ can be made arbitrarily small and the constant of proportionality depends on $\\varepsilon$ and on the complexity of the adjacency-defining predicate), such that adjacency between two vertices can be determined solely from their two labels, without any additional information. We obtain for instance that unit disk graphs and segment intersection graphs have such labelings with labels of $O(n^{1/3 + \\varepsilon})$ bits. This is in contrast to their natural implicit representation consisting of the coordinates of the disk centers or segment endpoints, which sometimes require exponentially many bits. It also improves on the best known bound of $O(n^{1-1/d}\\log n)$ for $d$-dimensional semialgebraic families due to Alon (Discrete Comput. Geom., 2024), a bound that holds more generally for graphs with shattering functions bounded by a degree-$d$ polynomial. We also give new bounds on the size of adjacency labels for other families of graphs. In particular, we consider semilinear graphs, which are semialgebraic graphs in which the predicate only involves linear polynomials. We show that semilinear graphs have adjacency labels of size $O(\\log n)$. We also prove that polygon visibility graphs, which are not semialgebraic in the above sense, have adjacency labels of size $O(\\log^3 n)$.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.10916", "pdf": "https://arxiv.org/pdf/2602.10916", "abs": "https://arxiv.org/abs/2602.10916", "authors": ["Rashid Mushkani"], "title": "Traceable, Enforceable, and Compensable Participation: A Participation Ledger for People-Centered AI Governance", "categories": ["cs.CY", "cs.AI"], "comment": "Presented at PAIRS: Participatory AI Research & Practice Symposium", "summary": "Participatory approaches are widely invoked in AI governance, yet participation rarely translates into durable influence. In public sector and civic AI systems, community contributions such as deliberations, annotations, prompts, and incident reports are often recorded informally, weakly linked to system updates, and disconnected from enforceable rights or sustained compensation. As a result, participation is frequently symbolic rather than accountable. We introduce the Participation Ledger, a machine readable and auditable framework that operationalizes participation as traceable influence, enforceable authority, and compensable labor. The ledger represents participation as an influence graph that links contributed artifacts to verified changes in AI systems, including datasets, prompts, adapters, policies, guardrails, and evaluation suites. It integrates three elements: a Participation Evidence Standard documenting consent, privacy, compensation, and reuse terms; an influence tracing mechanism that connects system updates to replayable before and after tests, enabling longitudinal monitoring of commitments; and encoded rights and incentives. Capability Vouchers allow authorized community stewards to request or constrain specific system capabilities within defined boundaries, while Participation Credits support ongoing recognition and compensation when contributed tests continue to provide value. We ground the framework in four urban AI and public space governance deployments and provide a machine readable schema, templates, and an evaluation plan for assessing traceability, enforceability, and compensation in practice.", "AI": {"tldr": "本文提出了一种参与账本框架，使AI治理中的公众参与具有可追溯性、强制性和补偿性。", "motivation": "当前的AI治理体系中，公众参与往往缺乏持久影响。社区贡献如讨论、标注、提示和事件报告等很少被正式记录且难以转化为系统更新或权利保障。", "method": "该研究开发了一种机器可读且可审计的框架——参与账本，将公众参与形式化为有影响力的图谱，并整合了证据标准、影响跟踪机制以及编码的权利与激励。", "result": "通过四个城市AI和公共空间治理的实际案例，本文展示了如何应用参与账本来实现透明度、责任性和公正性。", "conclusion": "该框架提供了一个可行的方法来加强公众在AI治理中的角色，并支持持久且有形的影响力。"}}
{"id": "2602.10915", "pdf": "https://arxiv.org/pdf/2602.10915", "abs": "https://arxiv.org/abs/2602.10915", "authors": ["Zhenhua Zou", "Sheng Guo", "Qiuyang Zhan", "Lepeng Zhao", "Shuo Li", "Qi Li", "Ke Xu", "Mingwei Xu", "Zhuotao Liu"], "title": "Blind Gods and Broken Screens: Architecting a Secure, Intent-Centric Mobile Agent Operating System", "categories": ["cs.CR", "cs.AI"], "comment": "35 pages, 15 figures", "summary": "The evolution of Large Language Models (LLMs) has shifted mobile computing from App-centric interactions to system-level autonomous agents. Current implementations predominantly rely on a \"Screen-as-Interface\" paradigm, which inherits structural vulnerabilities and conflicts with the mobile ecosystem's economic foundations. In this paper, we conduct a systematic security analysis of state-of-the-art mobile agents using Doubao Mobile Assistant as a representative case. We decompose the threat landscape into four dimensions - Agent Identity, External Interface, Internal Reasoning, and Action Execution - revealing critical flaws such as fake App identity, visual spoofing, indirect prompt injection, and unauthorized privilege escalation stemming from a reliance on unstructured visual data. To address these challenges, we propose Aura, an Agent Universal Runtime Architecture for a clean-slate secure agent OS. Aura replaces brittle GUI scraping with a structured, agent-native interaction model. It adopts a Hub-and-Spoke topology where a privileged System Agent orchestrates intent, sandboxed App Agents execute domain-specific tasks, and the Agent Kernel mediates all communication. The Agent Kernel enforces four defense pillars: (i) cryptographic identity binding via a Global Agent Registry; (ii) semantic input sanitization through a multilayer Semantic Firewall; (iii) cognitive integrity via taint-aware memory and plan-trajectory alignment; and (iv) granular access control with non-deniable auditing. Evaluation on MobileSafetyBench shows that, compared to Doubao, Aura improves low-risk Task Success Rate from roughly 75% to 94.3%, reduces high-risk Attack Success Rate from roughly 40% to 4.4%, and achieves near-order-of-magnitude latency gains. These results demonstrate Aura as a viable, secure alternative to the \"Screen-as-Interface\" paradigm.", "AI": {"tldr": "本文提出了一种名为Aura的新型移动代理操作系统架构，旨在解决当前基于视觉数据的移动代理系统中存在的安全问题。", "motivation": "大型语言模型的发展使得移动计算从应用为中心转变为自主系统的管理。然而，现有实现依赖于“屏幕作为接口”的模式，存在结构脆弱性和经济基础冲突的问题，本文针对这些挑战提出解决方案。", "method": "通过分析状态领先的移动代理系统（如Doubao），识别了四种威胁维度：代理身份、外部界面、内部推理和行动执行。基于此，设计了一种名为Aura的通用运行架构，该架构采用结构化交互模式替换脆弱的GUI抓取，并引入Hub-and-Spoke拓扑，以及四个防御支柱。", "result": "在MobileSafetyBench上的测试表明，与Doubao相比，Aura将低风险任务成功率从75%提高到94.3%，将高风险攻击成功概率从40%降低至4.4%，并且实现了显著的延迟减少。", "conclusion": "本文展示了一种名为Aura的新架构作为替代“屏幕为界面”的可行且安全的解决方案，证明了其有效性。"}}
{"id": "2602.10910", "pdf": "https://arxiv.org/pdf/2602.10910", "abs": "https://arxiv.org/abs/2602.10910", "authors": ["Sena Saito", "Kenta Tabata", "Renato Miyagusuku", "Koichi Ozaki"], "title": "Safe mobility support system using crowd mapping and avoidance route planning using VLM", "categories": ["cs.RO"], "comment": "ef:2025 IEEE International Conference on Real-time Computing and Robotics (RCAR)", "summary": "Autonomous mobile robots offer promising solutions for labor shortages and increased operational efficiency. However, navigating safely and effectively in dynamic environments, particularly crowded areas, remains challenging. This paper proposes a novel framework that integrates Vision-Language Models (VLM) and Gaussian Process Regression (GPR) to generate dynamic crowd-density maps (``Abstraction Maps'') for autonomous robot navigation. Our approach utilizes VLM's capability to recognize abstract environmental concepts, such as crowd densities, and represents them probabilistically via GPR. Experimental results from real-world trials on a university campus demonstrated that robots successfully generated routes avoiding both static obstacles and dynamic crowds, enhancing navigation safety and adaptability.", "AI": {"tldr": "提出了一种利用视觉语言模型和高斯过程回归生成动态人群密度图以支持自主机器人导航的安全移动辅助系统。", "motivation": "解决自主移动机器人在拥挤区域安全有效导航的挑战，特别是在劳动力短缺和提高运营效率的情况下。", "method": "使用VLM识别抽象环境概念如人群密度，并通过GPR进行概率表示生成动态人群密度图以支持避免静态障碍物和动态人群的路线规划。", "result": "实验结果表明，在大学校园的实际试验中，自主机器人能够成功地避开静止障碍物和动态人群，增强了导航的安全性和适应性。", "conclusion": "提出的框架通过利用VLM和GPR生成动态人群密度图，有效支持了自主移动机器人的安全导航。"}}
{"id": "2602.10904", "pdf": "https://arxiv.org/pdf/2602.10904", "abs": "https://arxiv.org/abs/2602.10904", "authors": ["Kenta Tabata", "Ryosuke Oku", "Jun Ito", "Renato Miyagusuku", "Koichi Ozaki"], "title": "Biomimetic Mantaray robot toward the underwater autonomous -- Experimental verification of swimming and diving by flapping motion -", "categories": ["cs.RO"], "comment": "ef:2024 IEEE International Conference on Robotics and Biomimetics (ROBIO)", "summary": "This study presents the development and experimental verification of a biomimetic manta ray robot for underwater autonomous exploration. Inspired by manta rays, the robot uses flapping motion for propulsion to minimize seabed disturbance and enhance efficiency compared to traditional screw propulsion. The robot features pectoral fins driven by servo motors and a streamlined control box to reduce fluid resistance. The control system, powered by a Raspberry Pi 3B, includes an IMU and pressure sensor for real-time monitoring and control. Experiments in a pool assessed the robot's swimming and diving capabilities. Results show stable swimming and diving motions with PD control. The robot is suitable for applications in environments like aquariums and fish nurseries, requiring minimal disturbance and efficient maneuverability. Our findings demonstrate the potential of bio-inspired robotic designs to improve ecological monitoring and underwater exploration.", "AI": {"tldr": "研发并实验验证了一种仿生蝠鲼水下自主探索机器人。", "motivation": "通过模仿蝠鲼，减少海底扰动，提高推进效率以适应水下环境的探索需求。", "method": "利用舵机驱动胸鳍进行拍打运动，并采用IMU和压力传感器实时监测与控制。实验在泳池中评估其游泳和潜水能力。", "result": "展示出稳定的游泳和潜水动作，在PD控制下的表现良好。", "conclusion": "仿生设计的机器人适用于需要低扰动、高效机动性的水下环境，如水族馆和鱼苗场，表明生物启发的设计能改善生态监测和水下探索。"}}
{"id": "2602.10894", "pdf": "https://arxiv.org/pdf/2602.10894", "abs": "https://arxiv.org/abs/2602.10894", "authors": ["Kazuki Ota", "Takayuki Osa", "Motoki Omura", "Tatsuya Harada"], "title": "Resource-Efficient Model-Free Reinforcement Learning for Board Games", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Board games have long served as complex decision-making benchmarks in artificial intelligence. In this field, search-based reinforcement learning methods such as AlphaZero have achieved remarkable success. However, their significant computational demands have been pointed out as barriers to their reproducibility. In this study, we propose a model-free reinforcement learning algorithm designed for board games to achieve more efficient learning. To validate the efficiency of the proposed method, we conducted comprehensive experiments on five board games: Animal Shogi, Gardner Chess, Go, Hex, and Othello. The results demonstrate that the proposed method achieves more efficient learning than existing methods across these environments. In addition, our extensive ablation study shows the importance of core techniques used in the proposed method. We believe that our efficient algorithm shows the potential of model-free reinforcement learning in domains traditionally dominated by search-based methods.", "AI": {"tldr": "本文提出了一种针对棋盘游戏的资源高效模型自由强化学习算法，旨在减少计算需求。", "motivation": "搜索型强化学习方法虽然在AI决策制定方面取得了显著成功，但其巨大的计算成本阻碍了其可重复性。因此，该研究提出了更有效的模型自由强化学习方法以克服这一挑战。", "method": "提出了一种专门针对棋盘游戏的高效模型自由强化学习算法，并通过五种不同棋类进行实验验证。", "result": "提出的算法在各种棋类游戏中均显示出了比现有技术更加高效的训练性能，证明了其有效性。", "conclusion": "该研究展示了模型自由强化学习方法在计算效率上的潜力，可以作为传统搜索型方法的一个强有力的竞争者。"}}
{"id": "2602.10891", "pdf": "https://arxiv.org/pdf/2602.10891", "abs": "https://arxiv.org/abs/2602.10891", "authors": ["Berfin Sakallioglu", "Giorgia Nadizar", "Eric Medvet"], "title": "Interactive LLM-assisted Curriculum Learning for Multi-Task Evolutionary Policy Search", "categories": ["cs.NE", "cs.AI"], "comment": "8 pages, 7 figures, with Appendix", "summary": "Multi-task policy search is a challenging problem because policies are required to generalize beyond training cases. Curriculum learning has proven to be effective in this setting, as it introduces complexity progressively. However, designing effective curricula is labor-intensive and requires extensive domain expertise. LLM-based curriculum generation has only recently emerged as a potential solution, but was limited to operate in static, offline modes without leveraging real-time feedback from the optimizer. Here we propose an interactive LLM-assisted framework for online curriculum generation, where the LLM adaptively designs training cases based on real-time feedback from the evolutionary optimization process. We investigate how different feedback modalities, ranging from numeric metrics alone to combinations with plots and behavior visualizations, influence the LLM ability to generate meaningful curricula. Through a 2D robot navigation case study, tackled with genetic programming as optimizer, we evaluate our approach against static LLM-generated curricula and expert-designed baselines. We show that interactive curriculum generation outperforms static approaches, with multimodal feedback incorporating both progression plots and behavior visualizations yielding performance competitive with expert-designed curricula. This work contributes to understanding how LLMs can serve as interactive curriculum designers for embodied AI systems, with potential extensions to broader evolutionary robotics applications.", "AI": {"tldr": "提出了一种基于LLM的交互式课程生成框架，用于多任务进化策略搜索。", "motivation": "现有课程学习设计耗时且需要专业知识，本研究旨在通过利用实时反馈提高效率和效果。", "method": "使用LLM根据优化过程中获得的实时反馈来适应性地设计训练案例，并评估不同类型的反馈方式（包括数字指标、图表和行为可视化）。", "result": "实验表明交互式生成课程优于静态方法，特别是结合了进展图和行为可视化的多模态反馈可以达到专家设计课程的效果。", "conclusion": "该工作展示了LLM作为互动课程设计师在实体AI系统中的潜力，并可扩展应用于更广泛的进化机器人学应用中。"}}
{"id": "2602.10886", "pdf": "https://arxiv.org/pdf/2602.10886", "abs": "https://arxiv.org/abs/2602.10886", "authors": ["Zhuohan Xie", "Rania Elbadry", "Fan Zhang", "Georgi Georgiev", "Xueqing Peng", "Lingfei Qian", "Jimin Huang", "Dimitar Dimitrov", "Vanshikaa Jani", "Yuyang Dai", "Jiahui Geng", "Yuxia Wang", "Ivan Koychev", "Veselin Stoyanov", "Preslav Nakov"], "title": "The CLEF-2026 FinMMEval Lab: Multilingual and Multimodal Evaluation of Financial AI Systems", "categories": ["cs.CL", "cs.AI", "cs.CE"], "comment": "7 pages", "summary": "We present the setup and the tasks of the FinMMEval Lab at CLEF 2026, which introduces the first multilingual and multimodal evaluation framework for financial Large Language Models (LLMs). While recent advances in financial natural language processing have enabled automated analysis of market reports, regulatory documents, and investor communications, existing benchmarks remain largely monolingual, text-only, and limited to narrow subtasks. FinMMEval 2026 addresses this gap by offering three interconnected tasks that span financial understanding, reasoning, and decision-making: Financial Exam Question Answering, Multilingual Financial Question Answering (PolyFiQA), and Financial Decision Making. Together, these tasks provide a comprehensive evaluation suite that measures models' ability to reason, generalize, and act across diverse languages and modalities. The lab aims to promote the development of robust, transparent, and globally inclusive financial AI systems, with datasets and evaluation resources publicly released to support reproducible research.", "AI": {"tldr": "介绍了一种多语言和多媒体评估框架，用于评估金融大型语言模型的性能。", "motivation": "现有的基准测试在单一语言、文本仅限以及任务狭窄方面存在局限性。引入FinMMEval是为了填补这个空白，旨在提升金融AI系统的鲁棒性和透明度，并促进全球包容性的发展。", "method": "通过三项关联的任务：财务考试问答题、多语种财务问答(PolyFiQA)和财务决策制定来评估模型的推理能力、泛化能力和行动多样性。这些任务覆盖了多种语言和模态。", "result": "尚未提及具体结果，但强调将公开数据集和评价资源以支持可重复研究。", "conclusion": "提出了一种全面且多样化的金融AI系统评估框架，并促进了相关领域的开源研究和模型发展"}}
{"id": "2602.10885", "pdf": "https://arxiv.org/pdf/2602.10885", "abs": "https://arxiv.org/abs/2602.10885", "authors": ["Leheng Sheng", "Wenchang Ma", "Ruixin Hong", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics", "categories": ["cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \\textbf{RLCER} (\\textbf{R}einforcement \\textbf{L}earning with \\textbf{C}oT Supervision via Self-\\textbf{E}volving \\textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.", "AI": {"tldr": "本文提出了RLCER方法，通过自演化评分标准来增强LLM的链式思维推理能力。", "motivation": "直接奖励链式思维困难重重：训练奖励模型需要大量人力标注，并且静态奖励模型难以应对不断变化的链式思维分布和奖励欺骗问题。这促使研究者寻找一种无需人工注释、能够自主演化的奖励方式。", "method": "基于自我演化训练方法的启发，作者提出了RLCER，通过自提并自我进化的评分标准来增强以结果为中心的强化学习过程，并展示了这种方法在没有直接结果奖励的情况下仍能提供可靠的链式思维监督信号。", "result": "实验表明，使用自提和自演化的评分标准可以有效提高模型的表现。此外，作为提示信息时，这些评分标准还能进一步提升推理阶段的效果。", "conclusion": "RLCER通过引入自我演化评分机制解决了现有问题，并在多个任务上展示了优越的性能，证明了这种方法的有效性和潜力。"}}
{"id": "2602.10884", "pdf": "https://arxiv.org/pdf/2602.10884", "abs": "https://arxiv.org/abs/2602.10884", "authors": ["Jinqing Zhang", "Zehua Fu", "Zelin Xu", "Wenying Dai", "Qingjie Liu", "Yunhong Wang"], "title": "ResWorld: Temporal Residual World Model for End-to-End Autonomous Driving", "categories": ["cs.CV"], "comment": "ICLR 2026", "summary": "The comprehensive understanding capabilities of world models for driving scenarios have significantly improved the planning accuracy of end-to-end autonomous driving frameworks. However, the redundant modeling of static regions and the lack of deep interaction with trajectories hinder world models from exerting their full effectiveness. In this paper, we propose Temporal Residual World Model (TR-World), which focuses on dynamic object modeling. By calculating the temporal residuals of scene representations, the information of dynamic objects can be extracted without relying on detection and tracking. TR-World takes only temporal residuals as input, thus predicting the future spatial distribution of dynamic objects more precisely. By combining the prediction with the static object information contained in the current BEV features, accurate future BEV features can be obtained. Furthermore, we propose Future-Guided Trajectory Refinement (FGTR) module, which conducts interaction between prior trajectories (predicted from the current scene representation) and the future BEV features. This module can not only utilize future road conditions to refine trajectories, but also provides sparse spatial-temporal supervision on future BEV features to prevent world model collapse. Comprehensive experiments conducted on the nuScenes and NAVSIM datasets demonstrate that our method, namely ResWorld, achieves state-of-the-art planning performance. The code is available at https://github.com/mengtan00/ResWorld.git.", "AI": {"tldr": "提出Temporal Residual World Model (TR-World) 和 Future-Guided Trajectory Refinement (FGTR) 模块，以提升自动驾驶的规划精度。", "motivation": "现有世界模型在驾驶场景中的理解能力虽有显著提高，但仍受静态区域冗余建模和动态目标交互不足的影响。本文旨在通过提取时间残差信息来改进这一问题，从而实现更精确的目标预测。", "method": "引入TR-World，仅使用时间残差作为输入，准确预测动态对象的未来空间分布；结合FGTR模块，在先前轨迹与未来BEV特征之间进行互动，以利用未来的道路条件优化轨迹，并提供稀疏的空间时间监督防止模型崩溃。", "result": "在nuScenes和NAVSIM数据集上的全面实验表明，该方法实现了最先进的规划性能。", "conclusion": "ResWorld通过改进世界模型的动态目标预测能力以及结合未来道路状况进行轨迹优化，显著提高了自动驾驶系统的规划精度。"}}
{"id": "2602.10881", "pdf": "https://arxiv.org/pdf/2602.10881", "abs": "https://arxiv.org/abs/2602.10881", "authors": ["Zhiyin Tan", "Jennifer D'Souza"], "title": "Diagnosing Structural Failures in LLM-Based Evidence Extraction for Meta-Analysis", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at the 22nd Conference on Information and Research Science Connecting to Digital and Library Science (IRCDL 2026)", "summary": "Systematic reviews and meta-analyses rely on converting narrative articles into structured, numerically grounded study records. Despite rapid advances in large language models (LLMs), it remains unclear whether they can meet the structural requirements of this process, which hinge on preserving roles, methods, and effect-size attribution across documents rather than on recognizing isolated entities. We propose a structural, diagnostic framework that evaluates LLM-based evidence extraction as a progression of schema-constrained queries with increasing relational and numerical complexity, enabling precise identification of failure points beyond atom-level extraction. Using a manually curated corpus spanning five scientific domains, together with a unified query suite and evaluation protocol, we evaluate two state-of-the-art LLMs under both per-document and long-context, multi-document input regimes. Across domains and models, performance remains moderate for single-property queries but degrades sharply once tasks require stable binding between variables, roles, statistical methods, and effect sizes. Full meta-analytic association tuples are extracted with near-zero reliability, and long-context inputs further exacerbate these failures. Downstream aggregation amplifies even minor upstream errors, rendering corpus-level statistics unreliable. Our analysis shows that these limitations stem not from entity recognition errors, but from systematic structural breakdowns, including role reversals, cross-analysis binding drift, instance compression in dense result sections, and numeric misattribution, indicating that current LLMs lack the structural fidelity, relational binding, and numerical grounding required for automated meta-analysis. The code and data are publicly available at GitHub (https://github.com/zhiyintan/LLM-Meta-Analysis).", "AI": {"tldr": "该论文通过手动整理的跨五个科学领域的语料库和统一查询套件，评估了两个最先进的大语言模型在单文档和多文档输入条件下的结构化证据抽取性能。", "motivation": "尽管大语言模型（LLMs）有了快速进步，但它们是否能满足系统综述和元分析过程中所需的结构性要求仍不确定。这一过程依赖于跨文档保持角色、方法以及效应大小的归属，而不仅仅是识别孤立实体。", "method": "该研究使用手动整理的跨越五个科学领域的语料库，配合统一查询套件及评估协议，评估了两个最先进的LLMs在单文档和多文档输入条件下的结构化证据抽取性能。评估框架侧重于评估模型从简单到复杂的结构性查询的能力。", "result": "结果表明，在单一属性查询方面，两个LLMs的性能保持中等；然而一旦任务要求变量、角色、统计方法及效应大小之间的稳定绑定，则其表现迅速下降。全面提取元分析关联元组的成功率接近于零，并且长上下文输入进一步加剧了这些失败。", "conclusion": "该研究指出，当前LLMs在自动化的元分析中存在结构性不足的问题，包括角色逆转、跨分析绑定漂移、密集结果部分中的实例压缩以及数值归属错误。这表明现有模型缺乏所需的结构化保真度、关系绑定和数字锚定能力。"}}
{"id": "2602.10880", "pdf": "https://arxiv.org/pdf/2602.10880", "abs": "https://arxiv.org/abs/2602.10880", "authors": ["Minggui He", "Mingchen Dai", "Jian Zhang", "Yilun Liu", "Shimin Tao", "Pufan Zeng", "Osamu Yoshie", "Yuya Ieiri"], "title": "Chart Specification: Structural Representations for Incentivizing VLM Reasoning in Chart-to-Code Generation", "categories": ["cs.CV"], "comment": "under review", "summary": "Vision-Language Models (VLMs) have shown promise in generating plotting code from chart images, yet achieving structural fidelity remains challenging. Existing approaches largely rely on supervised fine-tuning, encouraging surface-level token imitation rather than faithful modeling of underlying chart structure, which often leads to hallucinated or semantically inconsistent outputs. We propose Chart Specification, a structured intermediate representation that shifts training from text imitation to semantically grounded supervision. Chart Specification filters syntactic noise to construct a structurally balanced training set and supports a Spec-Align Reward that provides fine-grained, verifiable feedback on structural correctness, enabling reinforcement learning to enforce consistent plotting logic. Experiments on three public benchmarks show that our method consistently outperforms prior approaches. With only 3K training samples, we achieve strong data efficiency, surpassing leading baselines by up to 61.7% on complex benchmarks, and scaling to 4K samples establishes new state-of-the-art results across all evaluated metrics. Overall, our results demonstrate that precise structural supervision offers an efficient pathway to high-fidelity chart-to-code generation. Code and dataset are available at: https://github.com/Mighten/chart-specification-paper", "AI": {"tldr": "提出了一种结构化中间表示方法Chart Specification，以提高从图表图像生成代码的准确性。", "motivation": "现有的方法主要依赖于监督微调，导致表面级模仿而非底层结构模型的一致性问题。", "method": "通过引入Chart Specification构建训练集并支持Spec-Align Reward提供细粒度反馈。", "result": "在三个公开基准上实验结果表明，该方法优于现有最佳方法，特别是数据效率高，在复杂任务中提升61.7%。", "conclusion": "精确的结构化监督为高质量图表代码生成提供了有效路径。"}}
{"id": "2602.10875", "pdf": "https://arxiv.org/pdf/2602.10875", "abs": "https://arxiv.org/abs/2602.10875", "authors": ["Darakshan Rashid", "Raza Imam", "Dwarikanath Mahapatra", "Brejesh Lall"], "title": "Stride-Net: Fairness-Aware Disentangled Representation Learning for Chest X-Ray Diagnosis", "categories": ["cs.CV"], "comment": "6 pages, 2 Tables, 3 Figures. Our code is available https://github.com/Daraksh/Fairness_StrideNet", "summary": "Deep neural networks for chest X-ray classification achieve strong average performance, yet often underperform for specific demographic subgroups, raising critical concerns about clinical safety and equity. Existing debiasing methods frequently yield inconsistent improvements across datasets or attain fairness by degrading overall diagnostic utility, treating fairness as a post hoc constraint rather than a property of the learned representation. In this work, we propose Stride-Net (Sensitive Attribute Resilient Learning via Disentanglement and Learnable Masking with Embedding Alignment), a fairness-aware framework that learns disease-discriminative yet demographically invariant representations for chest X-ray analysis. Stride-Net operates at the patch level, using a learnable stride-based mask to select label-aligned image regions while suppressing sensitive attribute information through adversarial confusion loss. To anchor representations in clinical semantics and discourage shortcut learning, we further enforce semantic alignment between image features and BioBERT-based disease label embeddings via Group Optimal Transport. We evaluate Stride-Net on the MIMIC-CXR and CheXpert benchmarks across race and intersectional race-gender subgroups. Across architectures including ResNet and Vision Transformers, Stride-Net consistently improves fairness metrics while matching or exceeding baseline accuracy, achieving a more favorable accuracy-fairness trade-off than prior debiasing approaches. Our code is available at https://github.com/Daraksh/Fairness_StrideNet.", "AI": {"tldr": "提出了一种名为Stride-Net的框架，用于学习胸部X光片分析中的疾病区分但人口统计学不变的表现。", "motivation": "现有方法在提高公平性的同时可能降低整体诊断准确性，因此提出了一个新框架来解决深度神经网络在特定群体中表现不佳的问题。", "method": "通过对抗混淆损失选择标签对齐的图像区域并抑制敏感属性信息，使用可学习的步幅基元掩膜，并通过组最优传输强制图像特征和疾病标签嵌入之间的语义一致。", "result": "Stride-Net在不同架构下提高了公平性指标同时匹配或超过了基准准确率，优于之前的脱偏方法。", "conclusion": "提出了一个有效的框架来提高胸部X光片分析的公平性和准确性，且该方法可以在多个数据集上稳定表现。"}}
{"id": "2602.10871", "pdf": "https://arxiv.org/pdf/2602.10871", "abs": "https://arxiv.org/abs/2602.10871", "authors": ["Yu Zhang", "Xinyi Zhao", "Chongke Bi", "Siming Chen"], "title": "Viewpoint Recommendation for Point Cloud Labeling through Interaction Cost Modeling", "categories": ["cs.HC", "cs.CV"], "comment": "Accepted to IEEE TVCG", "summary": "Semantic segmentation of 3D point clouds is important for many applications, such as autonomous driving. To train semantic segmentation models, labeled point cloud segmentation datasets are essential. Meanwhile, point cloud labeling is time-consuming for annotators, which typically involves tuning the camera viewpoint and selecting points by lasso. To reduce the time cost of point cloud labeling, we propose a viewpoint recommendation approach to reduce annotators' labeling time costs. We adapt Fitts' law to model the time cost of lasso selection in point clouds. Using the modeled time cost, the viewpoint that minimizes the lasso selection time cost is recommended to the annotator. We build a data labeling system for semantic segmentation of 3D point clouds that integrates our viewpoint recommendation approach. The system enables users to navigate to recommended viewpoints for efficient annotation. Through an ablation study, we observed that our approach effectively reduced the data labeling time cost. We also qualitatively compare our approach with previous viewpoint selection approaches on different datasets.", "AI": {"tldr": "通过交互成本建模提出了一种点云标注视角推荐方法，以减少标注时间。", "motivation": "为了降低点云标注的时间成本并提高效率，作者提出了一个基于交互成本建模的视角推荐系统。", "method": "将Fitts定律应用于点云中的lasso选择时间成本建模，并根据此模型建议最小化lasso选择时间的成本视图。创建了一个集成了该方法的数据标注系统。", "result": "通过消融研究观察到，该方法有效减少了数据标注的时间成本，并在不同数据集上与先前的视角选择方法进行了定性比较。", "conclusion": "提出的基于交互成本建模的方法能够显著减少点云注释时间，从而提高了3D点云语义分割任务中的标注效率。"}}
{"id": "2602.10870", "pdf": "https://arxiv.org/pdf/2602.10870", "abs": "https://arxiv.org/abs/2602.10870", "authors": ["Xuefeng Xu", "Graham Cormode"], "title": "FedPS: Federated data Preprocessing via aggregated Statistics", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages", "summary": "Federated Learning (FL) enables multiple parties to collaboratively train machine learning models without sharing raw data. However, before training, data must be preprocessed to address missing values, inconsistent formats, and heterogeneous feature scales. This preprocessing stage is critical for model performance but is largely overlooked in FL research. In practical FL systems, privacy constraints prohibit centralizing raw data, while communication efficiency introduces further challenges for distributed preprocessing. We introduce FedPS, a unified framework for federated data preprocessing based on aggregated statistics. FedPS leverages data-sketching techniques to efficiently summarize local datasets while preserving essential statistical information. Building on these summaries, we design federated algorithms for feature scaling, encoding, discretization, and missing-value imputation, and extend preprocessing-related models such as k-Means, k-Nearest Neighbors, and Bayesian Linear Regression to both horizontal and vertical FL settings. FedPS provides flexible, communication-efficient, and consistent preprocessing pipelines for practical FL deployments.", "AI": {"tldr": "FedPS提出了一个基于聚合统计的联邦数据预处理框架，用于解决FL中由于隐私和通信效率限制而难以进行的数据预处理问题。", "motivation": "在FL系统中，为了训练模型需要对数据进行预处理以解决缺失值、格式不一致及特征尺度异质性等问题。但现有的研究对此关注较少，并且中央化原始数据会违反隐私规则，分布式预处理又面临通信效率挑战。", "method": "FedPS通过数据抽样技术高效汇总局部数据集并保持关键统计信息，设计了针对特征缩放、编码、离散化和缺失值填充的联邦算法，扩展了k-Means等预处理模型以适用于水平和垂直FL场景。", "result": "FedPS提供了一种灵活、通信效率高且一致的数据预处理流水线方案，适配于实际部署的FL系统。", "conclusion": "该方法解决了FL中数据预处理的关键问题，为提高模型性能提供了有效的技术手段。"}}
{"id": "2602.10864", "pdf": "https://arxiv.org/pdf/2602.10864", "abs": "https://arxiv.org/abs/2602.10864", "authors": ["Anouk Duyster", "Tomasz Kociumaka"], "title": "Random Access in Grammar-Compressed Strings: Optimal Trade-Offs in Almost All Parameter Regimes", "categories": ["cs.DS"], "comment": null, "summary": "A Random Access query to a string $T\\in [0..σ)^n$ asks for the character $T[i]$ at a given position $i\\in [0..n)$. In $O(n\\logσ)$ bits of space, this fundamental task admits constant-time queries. While this is optimal in the worst case, much research has focused on compressible strings, hoping for smaller data structures that still admit efficient queries. We investigate the grammar-compressed setting, where $T$ is represented by a straight-line grammar. Our main result is a general trade-off that optimizes Random Access time as a function of string length $n$, grammar size (the total length of productions) $g$, alphabet size $σ$, data structure size $M$, and word size $w=Ω(\\log n)$ of the word RAM model. For any $M$ with $g\\log n<Mw<n\\logσ$, we show an $O(M)$-size data structure with query time $O(\\frac{\\log(n\\logσ\\,/\\,Mw)}{\\log(Mw\\,/\\,g\\log n)})$. Remarkably, we also prove a matching unconditional lower bound that holds for all parameter regimes except very small grammars and relatively small data structures. Previous work focused on query time as a function of $n$ only, achieving $O(\\log n)$ time using $O(g)$ space [Bille et al.; SIAM J. Comput. 2015] and $O(\\frac{\\log n}{\\log \\log n})$ time using $O(g\\log^ε n)$ space for any constant $ε> 0$ [Belazzougui et al.; ESA'15], [Ganardi, Jeż, Lohrey; J. ACM 2021]. The only tight lower bound [Verbin and Yu; CPM'13] was $Ω(\\frac{\\log n}{\\log\\log n})$ for $w=Θ(\\log n)$, $n^{Ω(1)}\\le g\\le n^{1-Ω(1)}$, and $M=g\\log^{Θ(1)}n$. In contrast, our result yields tight bounds in all relevant parameters and almost all regimes. Our data structure admits efficient deterministic construction. It relies on novel grammar transformations that generalize contracting grammars [Ganardi; ESA'21]. Beyond Random Access, its variants support substring extraction, rank, and select.", "AI": {"tldr": "该论文研究了在语法压缩字符串上的随机访问查询，提出了一个优化的随机访问数据结构。", "motivation": "现有工作主要集中在仅将查询时间作为字符串长度n的函数进行优化。然而，在所有相关参数和几乎所有情况下提供紧确下限的需求尚未满足。", "method": "论文提出了一种通用的权衡方法，该方法在查询时间和空间复杂性上都进行了优化，并依赖于新的语法转换技术来实现这些目标。", "result": "论文的结果是在给定的空间M、字符串长度n、语法大小g等参数下，实现了O(M)大小的数据结构和查询时间O(公式)，并证明了紧确的无条件下界。", "conclusion": "该方法在几乎所有相关参数和所有相关的参数范围内提供最优化随机访问查询方案，并且这些数据结构可以支持高效的确定性构造及其他操作如子字符串提取、排名等。"}}
{"id": "2602.10863", "pdf": "https://arxiv.org/pdf/2602.10863", "abs": "https://arxiv.org/abs/2602.10863", "authors": ["Cong Pang", "Xuyu Feng", "Yujie Yi", "Zixuan Chen", "Jiawei Hong", "Tiankuo Yao", "Nang Yuan", "Jiapeng Luo", "Lewei Lu", "Xin Lou"], "title": "ICA: Information-Aware Credit Assignment for Visually Grounded Long-Horizon Information-Seeking Agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the strong performance achieved by reinforcement learning-trained information-seeking agents, learning in open-ended web environments remains severely constrained by low signal-to-noise feedback. Text-based parsers often discard layout semantics and introduce unstructured noise, while long-horizon training typically relies on sparse outcome rewards that obscure which retrieval actions actually matter. We propose a visual-native search framework that represents webpages as visual snapshots, allowing agents to leverage layout cues to quickly localize salient evidence and suppress distractors. To learn effectively from these high-dimensional observations, we introduce Information-Aware Credit Assignment (ICA), a post-hoc method that estimates each retrieved snapshot's contribution to the final outcome via posterior analysis and propagates dense learning signals back to key search turns. Integrated with a GRPO-based training pipeline, our approach consistently outperforms text-based baselines on diverse information-seeking benchmarks, providing evidence that visual snapshot grounding with information-level credit assignment alleviates the credit-assignment bottleneck in open-ended web environments. The code and datasets will be released in https://github.com/pc-inno/ICA_MM_deepsearch.git.", "AI": {"tldr": "提出了一种基于视觉的搜索框架和信息感知信用分配（ICA）方法，用于训练在开放网络环境中寻求信息的代理。", "motivation": "现有的文本解析器容易引入噪声且依赖于稀疏回报进行长期学习，导致信号与噪音比低，影响了信息采集效率。因此需要一种新的方法来提高信号质量并更有效地分配信用。", "method": "通过将网页表示为视觉快照，允许代理利用布局线索快速定位关键证据，并抑制干扰项；引入ICA技术估计每个检索快照对最终结果的贡献并通过后验分析传播密集学习信号回搜索的关键转捩点。结合GRPO训练管道以改善长期学习。", "result": "所提出的方法在多样化的信息寻求基准上始终优于文本基础线，证明了视觉快照定位和信息级信用分配有助于解决开放网络环境中的信用分配瓶颈问题。", "conclusion": "该研究展示了通过视觉本体搜索框架和ICA技术可以显著提高长期学习的有效性，并减少了信号与噪音比低的问题。"}}
{"id": "2602.10858", "pdf": "https://arxiv.org/pdf/2602.10858", "abs": "https://arxiv.org/abs/2602.10858", "authors": ["Lujian Yao", "Haitao Zhao", "Xianghai Kong", "Yuhan Xu"], "title": "Hyperspectral Smoke Segmentation via Mixture of Prototypes", "categories": ["cs.CV"], "comment": "35 pages, 14 figures", "summary": "Smoke segmentation is critical for wildfire management and industrial safety applications. Traditional visible-light-based methods face limitations due to insufficient spectral information, particularly struggling with cloud interference and semi-transparent smoke regions. To address these challenges, we introduce hyperspectral imaging for smoke segmentation and present the first hyperspectral smoke segmentation dataset (HSSDataset) with carefully annotated samples collected from over 18,000 frames across 20 real-world scenarios using a Many-to-One annotations protocol. However, different spectral bands exhibit varying discriminative capabilities across spatial regions, necessitating adaptive band weighting strategies. We decompose this into three technical challenges: spectral interaction contamination, limited spectral pattern modeling, and complex weighting router problems. We propose a mixture of prototypes (MoP) network with: (1) Band split for spectral isolation, (2) Prototype-based spectral representation for diverse patterns, and (3) Dual-level router for adaptive spatial-aware band weighting. We further construct a multispectral dataset (MSSDataset) with RGB-infrared images. Extensive experiments validate superior performance across both hyperspectral and multispectral modalities, establishing a new paradigm for spectral-based smoke segmentation.", "AI": {"tldr": "本文提出了一种基于混合原型的网络方法，用于利用高光谱成像技术进行烟雾分割。", "motivation": "传统的方法在可见光下难以获取足够的光谱信息，并且容易受到云层干扰和半透明烟雾区域的影响。因此，引入了高光谱成像来解决这些问题，并提出了一个新的数据集HSSDataset。", "method": "本文提出了一种混合原型网络（MoP），包括光谱分离、基于原型的光谱表示以及双级路由器进行自适应的空间感知带权重调整。", "result": "实验结果表明，所提出的模型在高光谱和多光谱模态上均表现出优越性能，为基于光谱的烟雾分割建立了一个新的范式。", "conclusion": "本文通过引入混合原型网络成功解决了传统的可见光方法面临的挑战，并且验证了该方法的有效性和优越性。"}}
{"id": "2602.10851", "pdf": "https://arxiv.org/pdf/2602.10851", "abs": "https://arxiv.org/abs/2602.10851", "authors": ["Frederik Glitzner"], "title": "Near-Feasible Stable Matchings: Incentives and Optimality", "categories": ["cs.GT", "cs.DS"], "comment": "EA to appear at AAMAS 2026", "summary": "Stable matching is a fundamental area with many practical applications, such as centralised clearinghouses for school choice or job markets. Recent work has introduced the paradigm of near-feasibility in capacitated matching settings, where agent capacities are slightly modified to ensure the existence of desirable outcomes. While useful when no stable matching exists, or some agents are left unmatched, it has not previously been investigated whether near-feasible stable matchings satisfy desirable properties with regard to their stability in the original instance. Furthermore, prior works often leave open deviation incentive issues that arise when the centralised authority modifies agents' capacities. We consider these issues in the Stable Fixtures problem model, which generalises many classical models through non-bipartite preferences and capacitated agents. We develop a formal framework to analyse and quantify agent incentives to adhere to computed matchings. Then, we embed near-feasible stable matchings in this framework and study the trade-offs between instability, capacity modifications, and computational complexity. We prove that capacity modifications can be simultaneously optimal at individual and aggregate levels, and provide efficient algorithms to compute them. We show that different modification strategies significantly affect stability, and establish that minimal modifications and minimal deviation incentives are compatible and efficiently computable under general conditions. Finally, we provide exact algorithms and experimental results for tractable and intractable versions of these problems.", "AI": {"tldr": "研究了近可行稳定匹配的问题，特别是在修改容量后如何保证稳定性、计算复杂度以及激励机制。", "motivation": "探讨在某些情况下不存在完美匹配或部分代理人未被分配时，通过轻微调整代理人的容量来实现稳定匹配的可行性及激励性问题。", "method": "构建了一个形式化的框架以分析和量化代理人遵守计算出的匹配的动力。研究了不同修改策略下的稳定性、最优解及其可计算性。", "result": "证明了在个体和整体层面，容量调整可以达到最优，并提供了高效的算法来实现这些调整。展示了最小化修改与最低偏离激励是兼容且容易计算的，在一般条件下。", "conclusion": "提出了有效方法以解决稳定匹配中的容量调整问题，确保稳定性同时考虑代理人行为及优化目标。"}}
{"id": "2602.10848", "pdf": "https://arxiv.org/pdf/2602.10848", "abs": "https://arxiv.org/abs/2602.10848", "authors": ["Luigi Simeone"], "title": "Time Series Foundation Models for Energy Load Forecasting on Consumer Hardware: A Multi-Dimensional Zero-Shot Benchmark", "categories": ["cs.LG", "cs.AI"], "comment": "27 pages, 13 figures", "summary": "Time Series Foundation Models (TSFMs) have introduced zero-shot prediction capabilities that bypass the need for task-specific training. Whether these capabilities translate to mission-critical applications such as electricity demand forecasting--where accuracy, calibration, and robustness directly affect grid operations--remains an open question. We present a multi-dimensional benchmark evaluating four TSFMs (Chronos-Bolt, Chronos-2, Moirai-2, and TinyTimeMixer) alongside Prophet as an industry-standard baseline and two statistical references (SARIMA and Seasonal Naive), using ERCOT hourly load data from 2020 to 2024. All experiments run on consumer-grade hardware (AMD Ryzen 7, 16GB RAM, no GPU). The evaluation spans four axes: (1) context length sensitivity from 24 to 2048 hours, (2) probabilistic forecast calibration, (3) robustness under distribution shifts including COVID-19 lockdowns and Winter Storm Uri, and (4) prescriptive analytics for operational decision support. The top-performing foundation models achieve MASE values near 0.31 at long context lengths (C = 2048h, day-ahead horizon), a 47% reduction over the Seasonal Naive baseline. The inclusion of Prophet exposes a structural advantage of pre-trained models: Prophet fails when the fitting window is shorter than its seasonality period (MASE > 74 at 24-hour context), while TSFMs maintain stable accuracy even with minimal context because they recognise temporal patterns learned during pre-training rather than estimating them from scratch. Calibration varies substantially across models--Chronos-2 produces well-calibrated prediction intervals (95% empirical coverage at 90% nominal level) while both Moirai-2 and Prophet exhibit overconfidence (~70% coverage). We provide practical model selection guidelines and release the complete benchmark framework for reproducibility.", "AI": {"tldr": "该论文通过多维度基准测试，评估了四种时间序列基础模型在电力需求预测任务上的性能。", "motivation": "零样本预测能力是否能够应用于关键的电力需求预测任务尚不明确。为了验证这一点，研究者进行了多项实验以测试这些模型的准确性和稳健性。", "method": "使用ERCOT小时级负荷数据（2020年到2024年），在消费级硬件上评估了四种时间序列基础模型、Prophet和两个统计基准方法的表现。评估维度包括上下文长度敏感度、概率预测校准、分布偏移稳健性和决策支持。", "result": "最佳的时间序列基础模型实现了接近0.31的MASE值，与季节性朴素基线相比减少了47%。Chronos-2产生了良好的置信区间校准，而Prophet和Moirai-2表现出过度自信的问题。", "conclusion": "论文提供了时间序列基础模型在电力需求预测任务中的性能评估，并给出实用的模型选择指导建议。"}}
{"id": "2602.10847", "pdf": "https://arxiv.org/pdf/2602.10847", "abs": "https://arxiv.org/abs/2602.10847", "authors": ["Fanpu Cao", "Lu Dai", "Jindong Han", "Hui Xiong"], "title": "Enhancing Multivariate Time Series Forecasting with Global Temporal Retrieval", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR 2026", "summary": "Multivariate time series forecasting (MTSF) plays a vital role in numerous real-world applications, yet existing models remain constrained by their reliance on a limited historical context. This limitation prevents them from effectively capturing global periodic patterns that often span cycles significantly longer than the input horizon - despite such patterns carrying strong predictive signals. Naive solutions, such as extending the historical window, lead to severe drawbacks, including overfitting, prohibitive computational costs, and redundant information processing. To address these challenges, we introduce the Global Temporal Retriever (GTR), a lightweight and plug-and-play module designed to extend any forecasting model's temporal awareness beyond the immediate historical context. GTR maintains an adaptive global temporal embedding of the entire cycle and dynamically retrieves and aligns relevant global segments with the input sequence. By jointly modeling local and global dependencies through a 2D convolution and residual fusion, GTR effectively bridges short-term observations with long-term periodicity without altering the host model architecture. Extensive experiments on six real-world datasets demonstrate that GTR consistently delivers state-of-the-art performance across both short-term and long-term forecasting scenarios, while incurring minimal parameter and computational overhead. These results highlight GTR as an efficient and general solution for enhancing global periodicity modeling in MTSF tasks. Code is available at this repository: https://github.com/macovaseas/GTR.", "AI": {"tldr": "本文提出了一个用于提升多变量时间序列预测中全局周期性建模的轻量级插件模块GTR。", "motivation": "现有模型在处理长周期模式时受到历史上下文限制，无法有效捕捉跨越输入范围之外的全球周期性信号。这导致了过拟合、计算成本高及冗余信息处理等问题。", "method": "GTR维护了一个全局时间嵌入并动态检索和对齐相关的全球片段与输入序列，通过二维卷积和残差融合同时建模局部和全局依赖关系，无需修改主机模型架构即可实现短时观测向长周期性的有效过渡。", "result": "实验结果显示，在六个真实世界数据集上进行测试时，GTR在短期及长期预测场景中均取得了最先进的性能，并且参数量和计算开销极小。", "conclusion": "GTR作为一种高效通用的解决方案展示了其在增强全局周期性建模中的优越表现。"}}
{"id": "2602.10845", "pdf": "https://arxiv.org/pdf/2602.10845", "abs": "https://arxiv.org/abs/2602.10845", "authors": ["Xuecheng Zou", "Yu Tang", "Bingbing Wang"], "title": "SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy", "categories": ["cs.AI", "cs.LG"], "comment": "10 pages, 5 tables, 7 figures. This work introduces the Active Synergy mechanism and Identity Anchoring for Knowledge Graph Completion. Code: https://github.com/XuechengZou-2001/SynergyKGC-main", "summary": "Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical \"structural resolution mismatch,\" failing to reconcile divergent representational demands across varying graph densities, which precipitates structural noise interference in dense clusters and catastrophic representation collapse in sparse regions. We present SynergyKGC, an adaptive framework that advances traditional neighbor aggregation to an active Cross-Modal Synergy Expert via relation-aware cross-attention and semantic-intent-driven gating. By coupling a density-dependent Identity Anchoring strategy with a Double-tower Coherent Consistency architecture, SynergyKGC effectively reconciles topological heterogeneity while ensuring representational stability across training and inference phases. Systematic evaluations on two public benchmarks validate the superiority of our method in significantly boosting KGC hit rates, providing empirical evidence for a generalized principle of resilient information integration in non-homogeneous structured data.", "AI": {"tldr": "本文提出了SynergyKGC框架，通过跨模态协同专家机制和双塔一致架构解决了知识图谱补全任务中拓扑异质性问题。", "motivation": "现有知识图谱补全文本未能有效解决不同图密度下结构差异所带来的干扰和表示坍塌问题。", "method": "引入了关系感知的跨注意力机制以及语义意图驱动门控，并结合密度依赖的身份锚定策略与双塔一致性架构，以提升拓扑异质性下的知识图谱补全能力。", "result": "系统性的实验表明本文方法在公开基准数据集上的KGC命中率显著提高。", "conclusion": "SynergyKGC框架通过有效解决非均质结构中的信息整合问题展示了其优越的性能和稳定性。"}}
{"id": "2602.10843", "pdf": "https://arxiv.org/pdf/2602.10843", "abs": "https://arxiv.org/abs/2602.10843", "authors": ["Christian Bertram", "Mads Vestergaard Jensen"], "title": "Personalized PageRank Estimation in Undirected Graphs", "categories": ["cs.DS"], "comment": null, "summary": "Given an undirected graph $G=(V, E)$, the Personalized PageRank (PPR) of $t\\in V$ with respect to $s\\in V$, denoted $π(s,t)$, is the probability that an $α$-discounted random walk starting at $s$ terminates at $t$. We study the time complexity of estimating $π(s,t)$ with constant relative error and constant failure probability, whenever $π(s,t)$ is above a given threshold parameter $δ\\in(0,1)$. We consider common graph-access models and furthermore study the single source, single target, and single node (PageRank centrality) variants of the problem. We provide a complete characterization of PPR estimation in undirected graphs by giving tight bounds (up to logarithmic factors) for all problems and model variants in both the worst-case and average-case setting. This includes both new upper and lower bounds. Tight bounds were recently obtained by Bertram, Jensen, Thorup, Wang, and Yan for directed graphs. However, their lower bound constructions rely on asymmetry and therefore do not carry over to undirected graphs. At the same time, undirected graphs exhibit additional structure that can be exploited algorithmically. Our results resolve the undirected case by developing new techniques that capture both aspects, yielding tight bounds.", "AI": {"tldr": "研究在无向图中估计个性化PageRank的时间复杂度。", "motivation": "分析和解决在给定阈值参数δ下，如何以常数相对误差和失败概率估计无向图中的个性化PageRank问题。", "method": "通过开发新的技术来捕捉无向图的结构特点以及算法特性，获得紧致的时间复杂度上下界。", "result": "提供了所有问题模型变体在最坏情况和平均情况下的时间复杂度紧致界（对数因子忽略不计）。", "conclusion": "研究解决了无向图中个性化PageRank估计的所有基本问题，为未来相关领域的工作奠定了基础。"}}
{"id": "2602.10829", "pdf": "https://arxiv.org/pdf/2602.10829", "abs": "https://arxiv.org/abs/2602.10829", "authors": ["Theo Lepage", "Reda Dehak"], "title": "Self-Supervised Learning for Speaker Recognition: A study and review", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "accepted for publication in Speech Communication", "summary": "Deep learning models trained in a supervised setting have revolutionized audio and speech processing. However, their performance inherently depends on the quantity of human-annotated data, making them costly to scale and prone to poor generalization under unseen conditions. To address these challenges, Self-Supervised Learning (SSL) has emerged as a promising paradigm, leveraging vast amounts of unlabeled data to learn relevant representations. The application of SSL for Automatic Speech Recognition (ASR) has been extensively studied, but research on other downstream tasks, notably Speaker Recognition (SR), remains in its early stages. This work describes major SSL instance-invariance frameworks (e.g., SimCLR, MoCo, and DINO), initially developed for computer vision, along with their adaptation to SR. Various SSL methods for SR, proposed in the literature and built upon these frameworks, are also presented. An extensive review of these approaches is then conducted: (1) the effect of the main hyperparameters of SSL frameworks is investigated; (2) the role of SSL components is studied (e.g., data-augmentation, projector, positive sampling); and (3) SSL frameworks are evaluated on SR with in-domain and out-of-domain data, using a consistent experimental setup, and a comprehensive comparison of SSL methods from the literature is provided. Specifically, DINO achieves the best downstream performance and effectively models intra-speaker variability, although it is highly sensitive to hyperparameters and training conditions, while SimCLR and MoCo provide robust alternatives that effectively capture inter-speaker variability and are less prone to collapse. This work aims to highlight recent trends and advancements, identifying current challenges in the field.", "AI": {"tldr": "研究基于无监督学习的语音识别方法，特别是自监督学习在说话人识别中的应用。", "motivation": "传统的深度学习模型依赖大量人工标注数据，在成本和泛化能力方面存在局限。为克服这些挑战，引入了无需标签的数据进行训练的自监督学习策略，以提升模型的适应性和泛化性。", "method": "综述并对比了几种主要的实例不变框架（如SimCLR、MoCo和DINO）及其对说话人识别任务的适配。此外，还研究了这些方法中的关键超参数以及数据增强等组件的作用。", "result": "实验表明DINO模型在下游任务中性能最佳，可以有效建模说话人间的差异性；然而它对于训练条件非常敏感。SimCLR和MoCo则提供了更加鲁棒的选择方案，在捕捉跨说话人变异方面表现出色且不易崩溃。", "conclusion": "本研究揭示了自监督学习在语音识别领域的最新趋势与挑战，旨在通过系统的实验对比来推动该领域的发展"}}
{"id": "2602.10827", "pdf": "https://arxiv.org/pdf/2602.10827", "abs": "https://arxiv.org/abs/2602.10827", "authors": ["Yuxin Zhang", "Fan Zhang"], "title": "The Effect of Design Thinking on Creative & Innovation Processes: An Empirical Study Across Different Design Experience Levels", "categories": ["cs.HC"], "comment": null, "summary": "This study employs linear regression and structural equation modeling to explore how Thinking Skills, Design Thinking, Creative Self-Efficacy (CSE), and Collective Creative Efficacy (CCE) drive Design Creativity & Innovation, and analyzes the structural stability of the model across different levels of experience. Path analysis results indicate that the four Design Thinking Skills, Problem-driven Design (beta = 0.198, p < 0.01), Information-driven Design (beta = 0.241, p < 0.001), Solution-driven Design (beta = 0.227, p < 0.001), and Knowledge-driven Design (beta = 0.263, p < 0.001) all significantly and positively influence Design Thinking. Furthermore, Design Thinking has a significant positive predictive effect on Design Creativity & Innovation (beta = 0.286, p < 0.001). Mediation analysis confirms three significant mediation paths: the CSE mediation path (beta = 0.128, p < 0.001), the CCE mediation path (beta = 0.073, p < 0.01), and the \"CSE to CCE\" chain mediation path (beta = 0.025, p < 0.01). Multi-group comparison results reveal significant differences between the student and professional groups under the full equivalence model. After relaxing specific constraints, there were no significant differences between the nested models of the baseline model, partial measurement invariance, structural weight invariance, and structural covariance invariance. These findings elucidate the multi-dimensional pathways of Design Creativity & Innovation, providing a robust empirical basis for optimizing differentiated pedagogical models and professional practice guidelines.", "AI": {"tldr": "本文通过线性回归和结构方程模型探索了思维技能、设计思考、创意自我效能感（CSE）和集体创意效能感（CCE）如何驱动设计创新，并分析了不同经验水平下的模型结构稳定性。", "motivation": "研究旨在了解设计思考对创新过程的影响，探讨其在不同设计体验层次中的有效性以及提供优化教学模型和专业实践指南的实证基础。", "method": "采用线性回归和结构方程模型进行数据分析。具体运用了路径分析、中介效应分析及多组比较方法来验证各变量间的关系与差异。", "result": "研究结果表明，设计思考四个技能显著正向影响设计创新；CSE和CCE在其中起着重要的中介作用。“CSE到CCE”的连锁中介效应也得到了证实。同时，学生群体和专业人员群体之间的模型结构存在显著差异。", "conclusion": "该研究表明了设计创新的多维度路径，并为优化差异化教学模式和专业实践指南提供了坚实的实证依据。"}}
{"id": "2602.10825", "pdf": "https://arxiv.org/pdf/2602.10825", "abs": "https://arxiv.org/abs/2602.10825", "authors": ["Yuexiao Ma", "Xuzhe Zheng", "Jing Xu", "Xiwei Xu", "Feng Ling", "Xiawu Zheng", "Huafeng Kuang", "Huixia Li", "Xing Wang", "Xuefeng Xiao", "Fei Chao", "Rongrong Ji"], "title": "Flow caching for autoregressive video generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Autoregressive models, often built on Transformer architectures, represent a powerful paradigm for generating ultra-long videos by synthesizing content in sequential chunks. However, this sequential generation process is notoriously slow. While caching strategies have proven effective for accelerating traditional video diffusion models, existing methods assume uniform denoising across all frames-an assumption that breaks down in autoregressive models where different video chunks exhibit varying similarity patterns at identical timesteps. In this paper, we present FlowCache, the first caching framework specifically designed for autoregressive video generation. Our key insight is that each video chunk should maintain independent caching policies, allowing fine-grained control over which chunks require recomputation at each timestep. We introduce a chunkwise caching strategy that dynamically adapts to the unique denoising characteristics of each chunk, complemented by a joint importance-redundancy optimized KV cache compression mechanism that maintains fixed memory bounds while preserving generation quality. Our method achieves remarkable speedups of 2.38 times on MAGI-1 and 6.7 times on SkyReels-V2, with negligible quality degradation (VBench: 0.87 increase and 0.79 decrease respectively). These results demonstrate that FlowCache successfully unlocks the potential of autoregressive models for real-time, ultra-long video generation-establishing a new benchmark for efficient video synthesis at scale. The code is available at https://github.com/mikeallen39/FlowCache.", "AI": {"tldr": "提出了一种新的缓存框架FlowCache，用于加速自回归视频生成模型的运行速度。", "motivation": "现有的缓存策略在传统视频扩散模型中表现良好，但在自回归模型中的应用存在局限性，因为不同视频片段在同一时间步骤下的去噪特性各异。因此需要一种能够适应这些差异的新方法。", "method": "提出了一种基于块级独立缓存策略的框架FlowCache，并引入了重要性和冗余度优化的KV缓存压缩机制，以实现动态调整和固定内存限制下的高效运行。", "result": "在MAGI-1上实现了2.38倍的速度提升，在SkyReels-V2上则达到了6.7倍的速度提升，且视频生成质量几乎没有下降。", "conclusion": "FlowCache显著提高了自回归模型的运行效率，使得它们能够在实时环境下生成超长视频，为大规模视频合成设定了新标准。"}}
{"id": "2602.10818", "pdf": "https://arxiv.org/pdf/2602.10818", "abs": "https://arxiv.org/abs/2602.10818", "authors": ["Dongsik Yoon", "Jongeun Kim", "Dayeon Lee"], "title": "Resource-Efficient RGB-Only Action Recognition for Edge Deployment", "categories": ["cs.CV", "cs.PF"], "comment": "Under review", "summary": "Action recognition on edge devices poses stringent constraints on latency, memory, storage, and power consumption. While auxiliary modalities such as skeleton and depth information can enhance recognition performance, they often require additional sensors or computationally expensive pose-estimation pipelines, limiting practicality for edge use. In this work, we propose a compact RGB-only network tailored for efficient on-device inference. Our approach builds upon an X3D-style backbone augmented with Temporal Shift, and further introduces selective temporal adaptation and parameter-free attention. Extensive experiments on the NTU RGB+D 60 and 120 benchmarks demonstrate a strong accuracy-efficiency balance. Moreover, deployment-level profiling on the Jetson Orin Nano verifies a smaller on-device footprint and practical resource utilization compared to existing RGB-based action recognition techniques.", "AI": {"tldr": "本文提出了一种高效的RGB-only动作识别网络，适用于边缘设备部署。", "motivation": "在边缘设备上进行的动作识别受到延迟、内存、存储和功耗的严格限制。尽管辅助模式如骨骼信息和深度数据可以提高性能，但它们通常需要额外传感器或复杂的姿态估计流程，从而影响实用性。因此本文旨在设计一种适用于边缘设备部署的小型RGB-only网络。", "method": "该方法基于X3D样式的骨干网，并引入了时间偏移、选择性的时间适应性和无参数注意力机制。这些技术的结合使得模型更紧凑，同时保持较高的识别准确度。", "result": "在NTU RGB+D 60和120数据集上的广泛实验表明，该方法实现了良好的精度与效率平衡。此外，在Jetson Orin Nano上的部署级分析进一步验证了其较小的设备占用量和实际资源利用率。", "conclusion": "本文提出的方法展示了高效的动作识别能力，并且在边缘设备上具有更小的内存占用及更好的功耗控制，证明了其在实际应用中的潜力。"}}
{"id": "2602.10816", "pdf": "https://arxiv.org/pdf/2602.10816", "abs": "https://arxiv.org/abs/2602.10816", "authors": ["Deyuan Liu", "Zecheng Wang", "Zhanyue Qin", "Zhiying Tu", "Dianhui Chu", "Dianbo Sui"], "title": "Beyond Confidence: The Rhythms of Reasoning in Generative Models", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR 2026", "summary": "Large Language Models (LLMs) exhibit impressive capabilities yet suffer from sensitivity to slight input context variations, hampering reliability. Conventional metrics like accuracy and perplexity fail to assess local prediction robustness, as normalized output probabilities can obscure the underlying resilience of an LLM's internal state to perturbations. We introduce the Token Constraint Bound ($δ_{\\mathrm{TCB}}$), a novel metric that quantifies the maximum internal state perturbation an LLM can withstand before its dominant next-token prediction significantly changes. Intrinsically linked to output embedding space geometry, $δ_{\\mathrm{TCB}}$ provides insights into the stability of the model's internal predictive commitment. Our experiments show $δ_{\\mathrm{TCB}}$ correlates with effective prompt engineering and uncovers critical prediction instabilities missed by perplexity during in-context learning and text generation. $δ_{\\mathrm{TCB}}$ offers a principled, complementary approach to analyze and potentially improve the contextual stability of LLM predictions.", "AI": {"tldr": "论文提出了一种新指标Token Constraint Bound (TCB)，用于量化大语言模型内部状态的稳定性。", "motivation": "传统评估指标如准确率和困惑度无法全面反映语言模型对输入变化的鲁棒性，因此引入了新的衡量标准TCB来分析模型预测稳定性和提升其可靠性。", "method": "提出了TCB这一新指标，并通过实验展示了其在评估模型内部状态稳定性方面的有效性与实用性。", "result": "实验证明，TCB能有效发现传统困惑度无法揭示的预测不稳定现象，在上下文学习和文本生成中具有显著优势。", "conclusion": "TCB提供了一个衡量大语言模型稳定性的新角度，并为提升模型性能提供了潜在方法。"}}
{"id": "2602.10815", "pdf": "https://arxiv.org/pdf/2602.10815", "abs": "https://arxiv.org/abs/2602.10815", "authors": ["Aojun Lu", "Tao Feng", "Hangjie Yuan", "Wei Li", "Yanan Sun"], "title": "Why Does RL Generalize Better Than SFT? A Data-Centric Perspective on VLM Post-Training", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The adaptation of large-scale Vision-Language Models (VLMs) through post-training reveals a pronounced generalization gap: models fine-tuned with Reinforcement Learning (RL) consistently achieve superior out-of-distribution (OOD) performance compared to those trained with Supervised Fine-Tuning (SFT). This paper posits a data-centric explanation for this phenomenon, contending that RL's generalization advantage arises from an implicit data filtering mechanism that inherently prioritizes medium-difficulty training samples. To test this hypothesis, we systematically evaluate the OOD generalization of SFT models across training datasets of varying difficulty levels. Our results confirm that data difficulty is a critical factor, revealing that training on hard samples significantly degrades OOD performance. Motivated by this finding, we introduce Difficulty-Curated SFT (DC-SFT), a straightforward method that explicitly filters the training set based on sample difficulty. Experiments show that DC-SFT not only substantially enhances OOD generalization over standard SFT, but also surpasses the performance of RL-based training, all while providing greater stability and computational efficiency. This work offers a data-centric account of the OOD generalization gap in VLMs and establishes a more efficient pathway to achieving robust generalization. Code is available at https://github.com/byyx666/DC-SFT.", "AI": {"tldr": "研究探讨了视觉语言模型（VLM）通过强化学习和监督微调后在泛化性能上的差异，并提出了一种基于数据难度筛选的方法，以提高泛化的稳定性与效率。", "motivation": "解释为什么通过强化学习训练的模型比通过监督微调训练的模型具有更好的泛化能力，从数据角度出发探讨这种现象的原因。", "method": "系统性评估了不同难度级别的训练集对基于监督微调模型的出界分布（OOD）性能影响，并提出了一种名为难度筛选监督微调（DC-SFT）的方法来优化训练样本选择。", "result": "实验结果显示，通过难度筛选方法可以显著提高监督微调模型的泛化能力，甚至超过了强化学习训练的表现，且提供了更高的稳定性和计算效率。", "conclusion": "该研究为VLM中OOD性能差距提供了一种数据驱动解释，并提出一种更高效的训练策略。"}}
{"id": "2602.10814", "pdf": "https://arxiv.org/pdf/2602.10814", "abs": "https://arxiv.org/abs/2602.10814", "authors": ["Xingyi Zhang", "Yulei Ye", "Kaifeng Huang", "Wenhao Li", "Xiangfeng Wang"], "title": "See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch", "categories": ["cs.AI"], "comment": null, "summary": "Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.", "AI": {"tldr": "评估基于图形用户界面的多模态AI代理在Scratch中的编程能力", "motivation": "探索和评估AI代理通过GUI构建程序的能力，特别是在低代码教育中使用的块式编程环境中", "method": "引入ScratchWorld基准测试，包括83个任务，并使用两种交互模式：精细的拖放操作和高级语义API。提出一种基于执行的评估协议以验证所构造程序的功能正确性。", "result": "实验证明了多模态语言模型在图形界面操控上的显著差距，即使它们有强大的规划能力", "conclusion": "揭示了AI代理在细粒度GUI操作方面的持续挑战，并强调需要进一步改进"}}
{"id": "2602.10809", "pdf": "https://arxiv.org/pdf/2602.10809", "abs": "https://arxiv.org/abs/2602.10809", "authors": ["Chenlong Deng", "Mengjie Deng", "Junjie Wu", "Dun Zeng", "Teng Wang", "Qingsong Xie", "Jiadeng Huang", "Shengjie Ma", "Changwang Zhang", "Zhaoxiang Wang", "Jun Wang", "Yutao Zhu", "Zhicheng Dou"], "title": "DeepImageSearch: Benchmarking Multimodal Agents for Context-Aware Image Retrieval in Visual Histories", "categories": ["cs.CV", "cs.IR"], "comment": "17 pages, 5 figures", "summary": "Existing multimodal retrieval systems excel at semantic matching but implicitly assume that query-image relevance can be measured in isolation. This paradigm overlooks the rich dependencies inherent in realistic visual streams, where information is distributed across temporal sequences rather than confined to single snapshots. To bridge this gap, we introduce DeepImageSearch, a novel agentic paradigm that reformulates image retrieval as an autonomous exploration task. Models must plan and perform multi-step reasoning over raw visual histories to locate targets based on implicit contextual cues. We construct DISBench, a challenging benchmark built on interconnected visual data. To address the scalability challenge of creating context-dependent queries, we propose a human-model collaborative pipeline that employs vision-language models to mine latent spatiotemporal associations, effectively offloading intensive context discovery before human verification. Furthermore, we build a robust baseline using a modular agent framework equipped with fine-grained tools and a dual-memory system for long-horizon navigation. Extensive experiments demonstrate that DISBench poses significant challenges to state-of-the-art models, highlighting the necessity of incorporating agentic reasoning into next-generation retrieval systems.", "AI": {"tldr": "提出了DeepImageSearch框架，通过多模态代理进行基于上下文的图像检索。", "motivation": "现有的多模态检索系统忽视了视觉流中的时间依赖性，忽略了真实世界场景中信息的时间分布特性。为了克服这一局限，引入了一个新的范式来更好地处理这种复杂性和挑战。", "method": "构建了DISBench基准测试，并开发了一种人机协作管道以生成基于上下文的查询，同时使用模块化代理框架和双内存系统来实现长期导航任务。", "result": "实验表明DISBench对最先进的模型提出了显著挑战，强调了将代理推理纳入下一代检索系统的必要性。", "conclusion": "通过引入新的多模态代理方法，DeepImageSearch能够更好地处理视觉历史中的上下文依赖问题，并展示了其在解决实际场景中图像检索任务方面的潜力。"}}
{"id": "2602.10808", "pdf": "https://arxiv.org/pdf/2602.10808", "abs": "https://arxiv.org/abs/2602.10808", "authors": ["Rasmus Krebs", "Somnath Mazumdar"], "title": "PELLI: Framework to effectively integrate LLMs for quality software generation", "categories": ["cs.SE", "cs.AI"], "comment": "15 pages", "summary": "Recent studies have revealed that when LLMs are appropriately prompted and configured, they demonstrate mixed results. Such results often meet or exceed the baseline performance. However, these comparisons have two primary issues. First, they mostly considered only reliability as a comparison metric and selected a few LLMs (such as Codex and ChatGPT) for comparision. This paper proposes a comprehensive code quality assessment framework called Programmatic Excellence via LLM Iteration (PELLI). PELLI is an iterative analysis-based process that upholds high-quality code changes. We extended the state-of-the-art by performing a comprehensive evaluation that generates quantitative metrics for analyzing three primary nonfunctional requirements (such as maintainability, performance, and reliability) while selecting five popular LLMs. For PELLI's applicability, we selected three application domains while following Python coding standards. Following this framework, practitioners can ensure harmonious integration between LLMs and human developers, ensuring that their potential is fully realized. PELLI can serve as a practical guide for developers aiming to leverage LLMs while adhering to recognized quality standards. This study's outcomes are crucial for advancing LLM technologies in real-world applications, providing stakeholders with a clear understanding of where these LLMs excel and where they require further refinement. Overall, based on three nonfunctional requirements, we have found that GPT-4T and Gemini performed slightly better. We also found that prompt design can influence the overall code quality. In addition, each application domain demonstrated high and low scores across various metrics, and even within the same metrics across different prompts.", "AI": {"tldr": "提出了一种用于评估LLM生成代码质量的框架PELLI。", "motivation": "当前研究中的LLM在适当提示和配置下表现出混合结果，主要关注可靠性和少量模型。此论文旨在通过全面评价三个非功能性需求来改进这一现状，并选择五个流行LLM进行对比。", "method": "提出了一种迭代分析过程框架PELLI，用于维持高质量代码修改。选择了三个应用领域并遵循Python编码标准进行了评估。结果包括定量指标以分析维护性、性能和可靠性。", "result": "基于三个非功能性需求，发现GPT-4T和Gemini表现稍好一些。提示设计会影响整体代码质量，并且不同领域的得分在各种度量中有所不同。", "conclusion": "PELLI为开发者提供了指导，使他们能够充分利用LLM的同时符合公认的质量标准。研究结果表明了这些LLM的优势和需要改进的地方。"}}
{"id": "2602.10806", "pdf": "https://arxiv.org/pdf/2602.10806", "abs": "https://arxiv.org/abs/2602.10806", "authors": ["Zi Wang", "Katsuya Hotta", "Koichiro Kamide", "Yawen Zou", "Jianjian Qin", "Chao Zhang", "Jun Yu"], "title": "DMP-3DAD: Cross-Category 3D Anomaly Detection via Realistic Depth Map Projection with Few Normal Samples", "categories": ["cs.CV"], "comment": null, "summary": "Cross-category anomaly detection for 3D point clouds aims to determine whether an unseen object belongs to a target category using only a few normal examples. Most existing methods rely on category-specific training, which limits their flexibility in few-shot scenarios. In this paper, we propose DMP-3DAD, a training-free framework for cross-category 3D anomaly detection based on multi-view realistic depth map projection. Specifically, by converting point clouds into a fixed set of realistic depth images, our method leverages a frozen CLIP visual encoder to extract multi-view representations and performs anomaly detection via weighted feature similarity, which does not require any fine-tuning or category-dependent adaptation. Extensive experiments on the ShapeNetPart dataset demonstrate that DMP-3DAD achieves state-of-the-art performance under few-shot setting. The results show that the proposed approach provides a simple yet effective solution for practical cross-category 3D anomaly detection.", "AI": {"tldr": "该论文提出了一种基于多视图真实深度图投影的训练自由框架，用于跨类别3D异常检测。", "motivation": "大多数现有方法依赖于特定类别的训练，在少量样本的情况下灵活性受限。本文旨在通过引入一种无需调整或类别依赖适应的方法来解决这一问题。", "method": "将点云转换为一组固定的真实深度图像，利用冻结的CLIP视觉编码器提取多视图表示，并通过加权特征相似性执行异常检测。", "result": "在ShapeNetPart数据集上进行的大量实验表明，DMP-3DAD在少量样本设置下达到了最先进的性能。", "conclusion": "提出的这种方法提供了一种简单有效的跨类别3D异常检测解决方案。"}}
{"id": "2602.10802", "pdf": "https://arxiv.org/pdf/2602.10802", "abs": "https://arxiv.org/abs/2602.10802", "authors": ["Da-Lun Chen", "Prasasthy Balasubramanian", "Lauri Lovén", "Susanna Pirttikangas", "Jaakko Sauvola", "Panagiotis Kostakos"], "title": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act", "categories": ["cs.AI"], "comment": null, "summary": "Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure regulatory compliance when deploying cognitive systems. These developments highlight the need for institutions to engage stakeholders and tailor GenAI integration to their needs while addressing concerns. This study investigates how GenAI is perceived within the disciplines of Information Technology and Electrical Engineering (ITEE). Using a mixed-method approach, we surveyed 61 staff and 37 students at the Faculty of ITEE, University of Oulu. The results reveal both shared and discipline-specific themes, including strong interest in programming support from GenAI and concerns over response quality, privacy, and academic integrity. Drawing from these insights, the study identifies a set of high-level requirements and proposes a conceptual framework for responsible GenAI integration. Disciplinary-specific requirements reinforce the importance of stakeholder engagement when integrating GenAI into higher education. The high-level requirements and the framework provide practical guidance for universities aiming to harness GenAI while addressing stakeholder concerns and ensuring regulatory compliance.", "AI": {"tldr": "探讨信息科技与电气工程学科中生成式AI的感知，并提出一个负责任集成生成式AI的概念框架", "motivation": "在欧盟人工智能法要求下，高校需确保合规性的同时，还需解决利益相关者对生成式AI的看法分歧问题，以满足不同需求和关切点", "method": "采用混合方法研究，通过调查芬兰奥卢大学信息科技与电气工程学院的61名教职员工和37名学生来收集数据", "result": "结果显示了共同主题以及学科特定的主题，包括对编程支持的兴趣、担忧质量响应、隐私和个人诚信问题", "conclusion": "从这些见解中确定了一些高级别要求，并提出了一个概念框架以负责任地集成生成式AI"}}
{"id": "2602.10799", "pdf": "https://arxiv.org/pdf/2602.10799", "abs": "https://arxiv.org/abs/2602.10799", "authors": ["Zihui Zhou", "Yong Feng", "Yanying Chen", "Guofan Duan", "Zhenxi Song", "Mingliang Zhou", "Weijia Jia"], "title": "RSHallu: Dual-Mode Hallucination Evaluation for Remote-Sensing Multimodal Large Language Models with Domain-Tailored Mitigation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) are increasingly adopted in remote sensing (RS) and have shown strong performance on tasks such as RS visual grounding (RSVG), RS visual question answering (RSVQA), and multimodal dialogue. However, hallucinations, which are responses inconsistent with the input RS images, severely hinder their deployment in high-stakes scenarios (e.g., emergency management and agricultural monitoring) and remain under-explored in RS. In this work, we present RSHallu, a systematic study with three deliverables: (1) we formalize RS hallucinations with an RS-oriented taxonomy and introduce image-level hallucination to capture RS-specific inconsistencies beyond object-centric errors (e.g., modality, resolution, and scene-level semantics); (2) we build a hallucination benchmark RSHalluEval (2,023 QA pairs) and enable dual-mode checking, supporting high-precision cloud auditing and low-cost reproducible local checking via a compact checker fine-tuned on RSHalluCheck dataset (15,396 QA pairs); and (3) we introduce a domain-tailored dataset RSHalluShield (30k QA pairs) for training-friendly mitigation and further propose training-free plug-and-play strategies, including decoding-time logit correction and RS-aware prompting. Across representative RS-MLLMs, our mitigation improves the hallucination-free rate by up to 21.63 percentage points under a unified protocol, while maintaining competitive performance on downstream RS tasks (RSVQA/RSVG). Code and datasets will be released.", "AI": {"tldr": "提出了一种评估和减轻遥感多模态大型语言模型中幻觉现象的方法RSHallu，包括形式化定义、基准测试和训练友好型数据集。", "motivation": "在高风险场景下（如应急管理与农业监测），遥感任务中的多模态大型语言模型易产生不一致回应的现象仍需深入研究以提升其可靠性和实用性。", "method": "构建了RS导向的幻觉分类法、评估基准RSHalluEval，支持双模式检查；同时开发训练友好型数据集RSHalluShield及无需训练插件策略来减轻这种现象。", "result": "在统一协议下，所提方法显著提高了无幻觉率（最高21.63个百分点），并保持了对下游遥感任务的竞争力。", "conclusion": "通过系统研究与创新手段，论文成功地解决了多模态大型语言模型应用于远程感知时存在的幻觉问题，并推动了该领域的进一步发展。"}}
{"id": "2602.10794", "pdf": "https://arxiv.org/pdf/2602.10794", "abs": "https://arxiv.org/abs/2602.10794", "authors": ["Benjy Friedmann", "Nadav Dym"], "title": "Transport, Don't Generate: Deterministic Geometric Flows for Combinatorial Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint. 10 pages", "summary": "Recent advances in Neural Combinatorial Optimization (NCO) have been dominated by diffusion models that treat the Euclidean Traveling Salesman Problem (TSP) as a stochastic $N \\times N$ heatmap generation task. In this paper, we propose CycFlow, a framework that replaces iterative edge denoising with deterministic point transport. CycFlow learns an instance-conditioned vector field that continuously transports input 2D coordinates to a canonical circular arrangement, where the optimal tour is recovered from this $2N$ dimensional representation via angular sorting. By leveraging data-dependent flow matching, we bypass the quadratic bottleneck of edge scoring in favor of linear coordinate dynamics. This paradigm shift accelerates solving speed by up to three orders of magnitude compared to state-of-the-art diffusion baselines, while maintaining competitive optimality gaps.", "AI": {"tldr": "提出了一种名为CycFlow的新框架，用于解决欧几里得旅行商问题（TSP），该框架通过确定性的点传输代替了迭代的边缘去噪。", "motivation": "当前神经组合优化中的进展主要集中在扩散模型上，这些模型将TSP视为一个随机$N \times N$热图生成任务。为了提高效率和准确性，提出了CycFlow以更高效地解决问题。", "method": "CycFlow框架学习了一种实例条件下的矢量场，该矢量场连续传输输入的2D坐标到标准圆周排列，并通过角度排序恢复最优路径。这种方法避免了边缘评分中的二次瓶颈，转而使用线性坐标动态。", "result": "相比最先进的扩散基线模型，CycFlow将求解速度提高了三倍数量级，同时保持了竞争性的最佳差距。", "conclusion": "CycFlow框架通过确定性的点传输方法解决了TSP问题，显著提高了算法的效率和解决速度。"}}
{"id": "2602.10793", "pdf": "https://arxiv.org/pdf/2602.10793", "abs": "https://arxiv.org/abs/2602.10793", "authors": ["Li-Min Chu", "Kai-Siang Ma", "Ming-Hong Chen", "Ping-Chun Hsieh"], "title": "Semi-Supervised Cross-Domain Imitation Learning", "categories": ["cs.LG", "cs.RO"], "comment": "Published in Transactions on Machine Learning Research (TMLR)", "summary": "Cross-domain imitation learning (CDIL) accelerates policy learning by transferring expert knowledge across domains, which is valuable in applications where the collection of expert data is costly. Existing methods are either supervised, relying on proxy tasks and explicit alignment, or unsupervised, aligning distributions without paired data, but often unstable. We introduce the Semi-Supervised CDIL (SS-CDIL) setting and propose the first algorithm for SS-CDIL with theoretical justification. Our method uses only offline data, including a small number of target expert demonstrations and some unlabeled imperfect trajectories. To handle domain discrepancy, we propose a novel cross-domain loss function for learning inter-domain state-action mappings and design an adaptive weight function to balance the source and target knowledge. Experiments on MuJoCo and Robosuite show consistent gains over the baselines, demonstrating that our approach achieves stable and data-efficient policy learning with minimal supervision. Our code is available at~ https://github.com/NYCU-RL-Bandits-Lab/CDIL.", "AI": {"tldr": "介绍了一种半监督跨域模仿学习(SS-CDIL)算法，用于从少量目标领域专家演示和一些未标记的不完美轨迹中加速策略学习。", "motivation": "在收集专家数据成本高昂的应用场景下，现有方法要么依赖于代理任务或明确对齐，要么通过配对数据外的方式对齐分布但不稳定。为了解决这些问题，提出了SS-CDIL来利用少量的目标领域专家演示和未标记的不完美轨迹进行更稳定、高效的学习。", "method": "提出了一种新颖的跨域损失函数用于学习跨领域的状态动作映射，并设计了一个自适应权重函数来平衡源领域与目标领域的知识。该方法仅使用离线数据，包括少量的目标专家演示和一些未标记的不完美轨迹。", "result": "实验结果表明，在MuJoCo和Robosuite上，所提方法相比基线算法具有稳定的性能增益，证明了其在最小化监督的情况下实现了稳定且高效的学习策略。", "conclusion": "SS-CDIL方法能够在少量目标领域专家数据的支持下进行有效的跨域模仿学习，并通过实验验证了该方法的优越性和实用性。"}}
{"id": "2602.10790", "pdf": "https://arxiv.org/pdf/2602.10790", "abs": "https://arxiv.org/abs/2602.10790", "authors": ["Paula Carolina Lozano Duarte", "Sule Ozev", "Mehdi Tahoori"], "title": "Fault Tolerant Design of IGZO-based Binary Search ADCs", "categories": ["cs.AR", "cs.ET"], "comment": "Accepted for publication at the 27th International Symposium on Quality Electronic Design (ISQED'26), April 8-10, 2026", "summary": "Thin-film technologies such as Indium Gallium Zinc Oxide (IGZO) enable Flexible Electronics (FE) for emerging applications in wearable sensing, personal health monitoring, and large-area systems. Analog-to-digital converters (ADCs) serve as critical sensor interfaces in these systems. Yet, their vulnerability to manufacturing defects remains poorly understood despite unipolar technologies' inherently high defect densities and process variations compared to mature CMOS technologies. We present a hierarchical fault injection framework to characterize defect sensitivity in Binary Search ADCs implemented in n-type only technologies. Our methodology combines transistor-level defect characterization with system-level fault propagation analysis, enabling efficient exploration of both single and multiple fault scenarios across the conversion hierarchy. The framework identifies critical fault-sensitive circuit components and enables selective redundancy strategies targeting only the most sensitive components. The resulting defect-tolerant designs improve fault coverage from 60% to 92% under single-fault injections and from 34% to 77.6% under multi-fault injection, while incurring only 4.2% area overhead and 6% power increase. While validated on IGZO-TFTs, the methodology applies to all emerging unipolar technologies.", "AI": {"tldr": "研究论文介绍了针对基于IGZO的二进制搜索ADC的容错设计。", "motivation": "薄膜技术如IGZO在柔性电子领域有广泛应用，但其制造缺陷对ADC性能的影响尚未充分理解。因此，提出了一种层次化故障注入框架来表征这些电路对缺陷的敏感性。", "method": "该方法结合了晶体管级缺陷特征与系统级故障传播分析，探索单一及多重故障情况下的影响，并据此提出针对性冗余策略以提高容错率。", "result": "实验结果表明，在单次和多次故障注入的情况下，容错设计将故障覆盖率分别从60%提升至92%，从34%提升至77.6%，同时仅增加4.2%的面积开销及6%的功耗。", "conclusion": "所提出的容错技术不仅适用于IGZO-TFTs，也可应用于所有新兴单极子技术。"}}
{"id": "2602.10787", "pdf": "https://arxiv.org/pdf/2602.10787", "abs": "https://arxiv.org/abs/2602.10787", "authors": ["Samal Mukhtar", "Yinghua Yao", "Zhu Sun", "Mustafa Mustafa", "Yew Soon Ong", "Youcheng Sun"], "title": "VulReaD: Knowledge-Graph-guided Software Vulnerability Reasoning and Detection", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.IR"], "comment": "22 pages, 3 figures", "summary": "Software vulnerability detection (SVD) is a critical challenge in modern systems. Large language models (LLMs) offer natural-language explanations alongside predictions, but most work focuses on binary evaluation, and explanations often lack semantic consistency with Common Weakness Enumeration (CWE) categories. We propose VulReaD, a knowledge-graph-guided approach for vulnerability reasoning and detection that moves beyond binary classification toward CWE-level reasoning. VulReaD leverages a security knowledge graph (KG) as a semantic backbone and uses a strong teacher LLM to generate CWE-consistent contrastive reasoning supervision, enabling student model training without manual annotations. Students are fine-tuned with Odds Ratio Preference Optimization (ORPO) to encourage taxonomy-aligned reasoning while suppressing unsupported explanations. Across three real-world datasets, VulReaD improves binary F1 by 8-10% and multi-class classification by 30% Macro-F1 and 18% Micro-F1 compared to state-of-the-art baselines. Results show that LLMs outperform deep learning baselines in binary detection and that KG-guided reasoning enhances CWE coverage and interpretability.", "AI": {"tldr": "提出了一种基于知识图谱的软件漏洞推理和检测方法VulReaD，通过大型语言模型生成一致性的对比推理监督以增强学生模型训练。", "motivation": "现有大多数工作集中在二元评估上，并且缺乏与CWE类别的语义一致性。本文旨在通过引入知识图谱指导的大规模语言模型来改进软件漏洞检测的准确性、可解释性和覆盖率。", "method": "利用安全知识图谱作为语义主干，使用强教师大型语言模型生成一致性的对比推理监督，并采用Odds Ratio Preference Optimization (ORPO)对学生的模型进行微调以增强分类准确性。", "result": "在三个真实世界的数据集上，VulReaD比最先进的基线提高了8-10%的二元F1值和30%宏F1、18%微观F1的多类分类准确率。结果显示大型语言模型优于深度学习基线并在二进制检测中表现更好。", "conclusion": "通过结合知识图谱和大规模语言模型，VulReaD显著提高了软件漏洞检测的性能，并增强了解释性和CWE覆盖率。"}}
{"id": "2602.10781", "pdf": "https://arxiv.org/pdf/2602.10781", "abs": "https://arxiv.org/abs/2602.10781", "authors": ["Ernestine Großmann", "Christian Schulz", "Darren Strash", "Antonie Wagner"], "title": "Data Reductions for the Strong Maximum Independent Set Problem in Hypergraphs", "categories": ["cs.DS"], "comment": null, "summary": "This work addresses the well-known Maximum Independent Set problem in the context of hypergraphs. While this problem has been extensively studied on graphs, we focus on its strong extension to hypergraphs, where edges may connect any number of vertices. A set of vertices in a hypergraph is strongly independent if there is at most one vertex per edge in the set. One application for this problem is to find perfect minimal hash functions. We propose nine new data reduction rules specifically designed for this problem. Our reduction routine can serve as a preprocessing step for any solver. We analyze the impact on the size of the reduced instances and the performance of several subsequent solvers when combined with this preprocessing. Our results demonstrate a significant reduction in instance size and improvements in running time for subsequent solvers. The preprocessing routine reduces instances, on average, to 22% of their original size in 6.76 seconds. When combining our reduction preprocessing with the best-performing exact solver, we observe an average speedup of 3.84x over not using the reduction rules. In some cases, we can achieve speedups of up to 53x. Additionally, one more instance becomes solvable by a method when combined with our preprocessing.", "AI": {"tldr": "本文研究了超图中的强最大独立集问题，并提出了九种新的数据缩减规则，以提高求解效率。", "motivation": "该问题是为了解决在超图中找到一个顶点集合，使得这个集合中的任意两个顶点不在同一边上的最大化问题。此问题的应用包括寻找完美的最小哈希函数等。", "method": "提出了九个新的数据缩减规则，并通过这些规则作为预处理步骤来减少实例大小和提高后续求解器的性能。", "result": "结果表明，所提的数据缩减方法能够将实例平均缩小到原来的22%，并且与最佳求解器结合时可以实现平均3.84倍的速度提升，在某些情况下甚至可达到53倍的速度提升。同时，也使一个原本无法解决的问题变得可解。", "conclusion": "该研究证明了所提出的九种数据缩减规则在处理超图中的强最大独立集问题时的有效性，并为后续求解器提供了高效的预处理步骤。"}}
{"id": "2602.10780", "pdf": "https://arxiv.org/pdf/2602.10780", "abs": "https://arxiv.org/abs/2602.10780", "authors": ["Enrico Ahlers", "Daniel Passon", "Yannic Noller", "Lars Grunske"], "title": "Kill it with FIRE: On Leveraging Latent Space Directions for Runtime Backdoor Mitigation in Deep Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "comment": null, "summary": "Machine learning models are increasingly present in our everyday lives; as a result, they become targets of adversarial attackers seeking to manipulate the systems we interact with. A well-known vulnerability is a backdoor introduced into a neural network by poisoned training data or a malicious training process. Backdoors can be used to induce unwanted behavior by including a certain trigger in the input. Existing mitigations filter training data, modify the model, or perform expensive input modifications on samples. If a vulnerable model has already been deployed, however, those strategies are either ineffective or inefficient. To address this gap, we propose our inference-time backdoor mitigation approach called FIRE (Feature-space Inference-time REpair). We hypothesize that a trigger induces structured and repeatable changes in the model's internal representation. We view the trigger as directions in the latent spaces between layers that can be applied in reverse to correct the inference mechanism. Therefore, we turn the backdoored model against itself by manipulating its latent representations and moving a poisoned sample's features along the backdoor directions to neutralize the trigger. Our evaluation shows that FIRE has low computational overhead and outperforms current runtime mitigations on image benchmarks across various attacks, datasets, and network architectures.", "AI": {"tldr": "提出了一种新的推理时后门缓解方法FIRE，通过逆向操作模型内部表示来中和触发器", "motivation": "现有后门缓解策略在部署后的模型上不有效或效率低，因此需要一种新的方法来解决这一问题", "method": "将输入样本的特征沿反方向移动以消除由后门引起的结构化变化", "result": "FIRE具有较低计算开销，并且优于现有的运行时缓解措施", "conclusion": "提出的方法可以有效地减轻模型在推理阶段受到的后门攻击"}}
{"id": "2602.10771", "pdf": "https://arxiv.org/pdf/2602.10771", "abs": "https://arxiv.org/abs/2602.10771", "authors": ["Krishna Kanth Nakka", "Vedasri Nakka"], "title": "From Steering to Pedalling: Do Autonomous Driving VLMs Generalize to Cyclist-Assistive Spatial Perception and Planning?", "categories": ["cs.CV", "cs.RO"], "comment": "Preprint", "summary": "Cyclists often encounter safety-critical situations in urban traffic, highlighting the need for assistive systems that support safe and informed decision-making. Recently, vision-language models (VLMs) have demonstrated strong performance on autonomous driving benchmarks, suggesting their potential for general traffic understanding and navigation-related reasoning. However, existing evaluations are predominantly vehicle-centric and fail to assess perception and reasoning from a cyclist-centric viewpoint. To address this gap, we introduce CyclingVQA, a diagnostic benchmark designed to probe perception, spatio-temporal understanding, and traffic-rule-to-lane reasoning from a cyclist's perspective. Evaluating 31+ recent VLMs spanning general-purpose, spatially enhanced, and autonomous-driving-specialized models, we find that current models demonstrate encouraging capabilities, while also revealing clear areas for improvement in cyclist-centric perception and reasoning, particularly in interpreting cyclist-specific traffic cues and associating signs with the correct navigational lanes. Notably, several driving-specialized models underperform strong generalist VLMs, indicating limited transfer from vehicle-centric training to cyclist-assistive scenarios. Finally, through systematic error analysis, we identify recurring failure modes to guide the development of more effective cyclist-assistive intelligent systems.", "AI": {"tldr": "介绍一个用于评估视觉语言模型在从自行车骑行者视角进行感知和规划方面能力的基准测试CyclingVQA，揭示现有模型在这方面的局限性和改进方向。", "motivation": "当前的评估主要侧重于车辆角度，缺乏对骑车人视角下的感知与规划的理解。为了填补这一空白并开发更有效的辅助系统，需要一个针对性的自行车骑行者感知和规划的测试基准。", "method": "创建CyclingVQA基准以检测视觉语言模型在从骑车人角度进行感知、时空理解以及交通规则到车道推理方面的表现，并评估了包括通用型、空间增强型及自动驾驶专用型在内的31种以上近期视觉语言模型。", "result": "现有模型表现出色但仍有改进余地，特别是处理特定于自行车手的交通提示和将标志与正确的导航车道关联方面存在不足。一些专为驾驶设计的模型在转移至骑车人辅助情景时表现不如通用型VLMs。", "conclusion": "通过系统性错误分析确定了常见的故障模式，并提供了开发更有效的自行车骑行者辅助智能系统的方向指导。"}}
{"id": "2602.10770", "pdf": "https://arxiv.org/pdf/2602.10770", "abs": "https://arxiv.org/abs/2602.10770", "authors": ["Bram Van Bolderik", "Vlado Menkovski", "Sonia Heemstra de Groot", "Manil Dev Gomony"], "title": "LOREN: Low Rank-Based Code-Rate Adaptation in Neural Receivers", "categories": ["cs.LG", "cs.AI", "cs.AR", "eess.SP"], "comment": "Accepted to / To appear IEEE Wireless Communications and Networking Conference Kuala Lumpur, Malaysia 13 - 16 April 2026", "summary": "Neural network based receivers have recently demonstrated superior system-level performance compared to traditional receivers. However, their practicality is limited by high memory and power requirements, as separate weight sets must be stored for each code rate. To address this challenge, we propose LOREN, a Low Rank-Based Code-Rate Adaptation Neural Receiver that achieves adaptability with minimal overhead. LOREN integrates lightweight low rank adaptation adapters (LOREN adapters) into convolutional layers, freezing a shared base network while training only small adapters per code rate. An end-to-end training framework over 3GPP CDL channels ensures robustness across realistic wireless environments. LOREN achieves comparable or superior performance relative to fully retrained base neural receivers. The hardware implementation of LOREN in 22nm technology shows more than 65% savings in silicon area and up to 15% power reduction when supporting three code rates.", "AI": {"tldr": "提出LOREN，一种基于低秩的编码率自适应神经接收机。", "motivation": "传统接收机性能受限于高内存和功率需求，而基于神经网络的接收机则需要为每个编码率存储单独的权重集。因此提出了LOREN以实现最小化开销下的可变性。", "method": "在卷积层中集成轻量级低秩自适应适配器（LOREN适配器），冻结共享的基础网络，仅针对特定编码率训练小适配器，并通过3GPP CDL信道进行端到端训练以确保无线环境下的鲁棒性。", "result": "与完全重新训练的基础神经接收机相比，LOREN在实现类似或更优性能的同时，在22nm技术中的硬件实现在支持三个编码率时可节省65%以上的硅面积和最多15%的功率。", "conclusion": "LOREN通过低秩自适应适配器实现了高效且鲁棒的神经网络接收机设计，解决了存储高权重集的问题，并在实际无线环境中表现出优异性能。"}}
{"id": "2602.10764", "pdf": "https://arxiv.org/pdf/2602.10764", "abs": "https://arxiv.org/abs/2602.10764", "authors": ["Linwei Dong", "Ruoyu Guo", "Ge Bai", "Zehuan Yuan", "Yawei Luo", "Changqing Zou"], "title": "Dual-End Consistency Model", "categories": ["cs.CV"], "comment": null, "summary": "The slow iterative sampling nature remains a major bottleneck for the practical deployment of diffusion and flow-based generative models. While consistency models (CMs) represent a state-of-the-art distillation-based approach for efficient generation, their large-scale application is still limited by two key issues: training instability and inflexible sampling. Existing methods seek to mitigate these problems through architectural adjustments or regularized objectives, yet overlook the critical reliance on trajectory selection. In this work, we first conduct an analysis on these two limitations: training instability originates from loss divergence induced by unstable self-supervised term, whereas sampling inflexibility arises from error accumulation. Based on these insights and analysis, we propose the Dual-End Consistency Model (DE-CM) that selects vital sub-trajectory clusters to achieve stable and effective training. DE-CM decomposes the PF-ODE trajectory and selects three critical sub-trajectories as optimization targets. Specifically, our approach leverages continuous-time CMs objectives to achieve few-step distillation and utilizes flow matching as a boundary regularizer to stabilize the training process. Furthermore, we propose a novel noise-to-noisy (N2N) mapping that can map noise to any point, thereby alleviating the error accumulation in the first step. Extensive experimental results show the effectiveness of our method: it achieves a state-of-the-art FID score of 1.70 in one-step generation on the ImageNet 256x256 dataset, outperforming existing CM-based one-step approaches.", "AI": {"tldr": "该论文提出了一种双端一致性模型（DE-CM），旨在通过选择关键子轨迹来提高扩散和流生成模型的训练稳定性和采样灵活性。", "motivation": "现有的一致性模型存在训练不稳定和采样不灵活的问题，这些问题源于自我监督项引起的损失发散以及误差累积。因此，论文提出了一个新方法以解决这些问题，并通过选择关键子轨迹来提高模型的有效性。", "method": "该方法首先分解PF-ODE轨迹并选取三个关键子轨迹作为优化目标；其次使用连续时间一致性模型的目标实现少步骤蒸馏，并采用流匹配作为边界正则化器来稳定训练过程。此外，提出了一种噪声到噪声的映射（N2N）以减少第一个步骤中的误差累积。", "result": "在ImageNet 256x256数据集上进行的一步生成实验表明了该方法的有效性，其FID分数为1.70，优于现有的一步生成一致性模型方法。", "conclusion": "论文展示了通过双端一致性模型选择关键子轨迹来实现稳定和高效训练的可行性，并取得了优越的结果。"}}
{"id": "2602.10763", "pdf": "https://arxiv.org/pdf/2602.10763", "abs": "https://arxiv.org/abs/2602.10763", "authors": ["Jakob Kaiser", "Eric Müller", "Johannes Schemmel"], "title": "Amortized Inference of Neuron Parameters on Analog Neuromorphic Hardware", "categories": ["cs.NE"], "comment": null, "summary": "Our work utilized a non-sequential simulation-based inference algorithm to provide an amortized neural density estimator, which approximates the posterior distribution for seven parameters of the adaptive exponential integrate-and-fire neuron model of the analog neuromorphic BrainScaleS-2 substrate. We constrained the large parameter space by training a binary classifier to predict parameter combinations yielding observations in regimes of interest, i.e. moderate spike counts. We compared two neural density estimators: one using handcrafted summary statistics and one using a summary network trained in combination with the neural density estimator. The summary network yielded a more focused posterior and generated posterior predictive traces that accurately captured the membrane potential dynamics. When using handcrafted summary statistics, posterior predictive traces match the included features but show deviations in the exact dynamics. The posteriors showed signs of bias and miscalibration but were still able to yield posterior predictive samples that were close to the target observations on which the posteriors were constrained. Our results validate amortized simulation-based inference as a tool for parameterizing analog neuron circuits.", "AI": {"tldr": "利用非顺序模拟基础推断算法为BrainScaleS-2基板上的一种神经元模型提供参数化。", "motivation": "为了准确地对类脑硬件上的神经元模型进行参数估计，以优化其性能和应用。", "method": "使用一种非序列的基于模拟的推理算法来实现快速且可重复使用的密度估计器。该方法比较了手工选择特征统计量与训练一个总结网络的结果差异，并用二分类器限制了参数空间。", "result": "结果表明，使用训练过的总结网络生成的后验预测轨迹准确捕捉到了膜电位动力学。尽管后验存在一定程度偏差和校准问题，但仍然能产生接近目标观测值的样本。", "conclusion": "该研究验证了基于模拟的方法可用于参数化类脑硬件中的神经元模型，并展示了其在实际应用中的潜力。"}}
{"id": "2602.10757", "pdf": "https://arxiv.org/pdf/2602.10757", "abs": "https://arxiv.org/abs/2602.10757", "authors": ["Egor Bazhenov", "Stepan Kasai", "Viacheslav Shalamov", "Valeria Efimova"], "title": "Text-to-Vector Conversion for Residential Plan Design", "categories": ["cs.CV"], "comment": "4 pages, 1 figure", "summary": "Computer graphics, comprising both raster and vector components, is a fundamental part of modern science, industry, and digital communication. While raster graphics offer ease of use, its pixel-based structure limits scalability. Vector graphics, defined by mathematical primitives, provides scalability without quality loss, however, it is more complex to produce. For design and architecture, the versatility of vector graphics is paramount, despite its computational demands. This paper introduces a novel method for generating vector residential plans from textual descriptions. Our approach surpasses existing solutions by approximately 5% in CLIPScore-based visual quality, benefiting from its inherent handling of right angles and flexible settings. Additionally, we present a new algorithm for vectorizing raster plans into structured vector images. Such images have a better CLIPscore compared to others by about 4%.", "AI": {"tldr": "介绍了一种从文本描述生成住宅平面图向量的方法，以及将栅格平面图转化为结构化矢量图像的新算法。", "motivation": "在设计和建筑领域中，矢量图形的灵活性至关重要，但其计算需求较高。该论文旨在通过文本到矢量转换技术提升住宅平面图的设计效率与质量。", "method": "提出了一种从文本描述生成住宅平面图向量的方法，并开发了一个将栅格图像转化为结构化矢量图像的新算法。", "result": "所提方法在CLIPScore-based视觉质量上比现有解决方案高出约5%，新算法则使转化后的矢量图像的CLIPscore提高4%左右。", "conclusion": "该研究提供了一种有效的方法来生成高质量的住宅平面图向量，有助于设计和建筑领域的创新与效率提升。"}}
{"id": "2602.10754", "pdf": "https://arxiv.org/pdf/2602.10754", "abs": "https://arxiv.org/abs/2602.10754", "authors": ["Charlotte Cambier van Nooten", "Christos Aronis", "Yuliya Shapovalova", "Lucia Cavallaro"], "title": "Exploring the impact of adaptive rewiring in Graph Neural Networks", "categories": ["cs.LG", "cs.AI", "eess.SY", "stat.ML"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This paper explores sparsification methods as a form of regularization in Graph Neural Networks (GNNs) to address high memory usage and computational costs in large-scale graph applications. Using techniques from Network Science and Machine Learning, including Erdős-Rényi for model sparsification, we enhance the efficiency of GNNs for real-world applications. We demonstrate our approach on N-1 contingency assessment in electrical grids, a critical task for ensuring grid reliability. We apply our methods to three datasets of varying sizes, exploring Graph Convolutional Networks (GCN) and Graph Isomorphism Networks (GIN) with different degrees of sparsification and rewiring. Comparison across sparsification levels shows the potential of combining insights from both research fields to improve GNN performance and scalability. Our experiments highlight the importance of tuning sparsity parameters: while sparsity can improve generalization, excessive sparsity may hinder learning of complex patterns. Our adaptive rewiring approach, particularly when combined with early stopping, proves promising by allowing the model to adapt its connectivity structure during training. This research contributes to understanding how sparsity can be effectively leveraged in GNNs for critical applications like power grid reliability analysis.", "AI": {"tldr": "研究了自适应重连在图神经网络中的影响，探索稀疏化作为正则化的形式以提高效率和可扩展性。", "motivation": "为了解决大规模图形应用中高内存使用量和计算成本的问题，通过结合网络科学和机器学习的方法来优化图神经网络的性能。", "method": "采用Erdős-Rényi模型进行模型稀疏化，并在电力电网的一级故障评估任务上测试Graph Convolutional Networks (GCN) 和 Graph Isomorphism Networks (GIN)，探索不同程度的稀疏化和重连的影响。特别地，提出了一种自适应重连的方法结合早停策略。", "result": "实验表明适当水平的稀疏可以改善泛化性能，但过度稀疏可能妨碍复杂模式的学习。自适应重连方法在训练过程中使模型能够调整其连接结构显示出潜力。", "conclusion": "这项研究有助于理解如何有效地利用稀疏性来提高图神经网络在关键应用中的性能和可扩展性，特别是在电力电网的可靠性分析中。"}}
{"id": "2602.10750", "pdf": "https://arxiv.org/pdf/2602.10750", "abs": "https://arxiv.org/abs/2602.10750", "authors": ["Rumman Firdos", "Aman Dangi"], "title": "SecureScan: An AI-Driven Multi-Layer Framework for Malware and Phishing Detection Using Logistic Regression and Threat Intelligence Integration", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "The growing sophistication of modern malware and phishing campaigns has diminished the effectiveness of traditional signature-based intrusion detection systems. This work presents SecureScan, an AI-driven, triple-layer detection framework that integrates logistic regression-based classification, heuristic analysis, and external threat intelligence via the VirusTotal API for comprehensive triage of URLs, file hashes, and binaries. The proposed architecture prioritizes efficiency by filtering known threats through heuristics, classifying uncertain samples using machine learning, and validating borderline cases with third-party intelligence. On benchmark datasets, SecureScan achieves 93.1 percent accuracy with balanced precision (0.87) and recall (0.92), demonstrating strong generalization and reduced overfitting through threshold-based decision calibration. A calibrated threshold and gray-zone logic (0.45-0.55) were introduced to minimize false positives and enhance real-world stability. Experimental results indicate that a lightweight statistical model, when augmented with calibrated verification and external intelligence, can achieve reliability and performance comparable to more complex deep learning systems.", "AI": {"tldr": "SecureScan 是一种利用逻辑回归和威胁情报集成的三层框架，用于检测恶意软件和网络钓鱼。", "motivation": "传统的基于签名的入侵检测系统在面对日益复杂的现代恶意软件和网络钓鱼活动时效果减弱。因此开发了一种结合机器学习与外部威胁情报的新方法以提高检测效率及准确性。", "method": "SecureScan 框架包括三层：使用启发式分析过滤已知威胁，利用逻辑回归分类不确定样本，通过第三方智能验证边缘情况，并引入阈值调整和灰色区域判断逻辑减少误报。", "result": "在基准数据集上，SecureScan 达到了93.1% 的准确率，平衡精度为0.87，召回率为0.92。实验结果表明，轻量级统计模型结合校准验证和外部情报能够达到与复杂深度学习系统相当的可靠性和性能。", "conclusion": "通过引入逻辑回归、启发式分析及第三方威胁情报集成的方法，SecureScan 在检测恶意软件和网络钓鱼方面表现出色，并且具备较强的泛化能力和减少过拟合的能力。"}}
{"id": "2602.10747", "pdf": "https://arxiv.org/pdf/2602.10747", "abs": "https://arxiv.org/abs/2602.10747", "authors": ["Bernhard Haeupler", "Antti Roeyskoe", "Zhijun Zhang"], "title": "Better Diameter Bounds for Efficient Shortcuts and a Structural Criterion for Constructiveness", "categories": ["cs.DS"], "comment": null, "summary": "All parallel algorithms for directed connectivity and shortest paths crucially rely on efficient shortcut constructions that add a linear number of transitive closure edges to a given DAG to reduce its diameter. A long sequence of works has studied both (efficient) shortcut constructions and impossibility results on the best diameter and therefore the best parallelism that can be achieved with this approach. This paper introduces a new conceptual and technical tool, called certified shortcuts, for this line of research in the form of a simple and natural structural criterion that holds for any shortcut constructed by an efficient (combinatorial) algorithm. It allows us to drastically simplify and strengthen existing impossibility results by proving that any near-linear-time shortcut-based algorithm cannot reduce a graph's diameter below $n^{1/4-o(1)}$. This greatly improves over the $n^{2/9-o(1)}$ lower bound of [HXX25] and seems to be the best bound one can hope for with current techniques. Our structural criterion also precisely captures the constructiveness of all known shortcut constructions: we show that existing constructions satisfy the criterion if and only if they have known efficient algorithms. We believe our new criterion and perspective of looking for certified shortcuts can provide crucial guidance for designing efficient shortcut constructions in the future.", "AI": {"tldr": "本文引入了一种称为认证捷径的新工具，用于简化和加强现有不可能性结果，并提出了一项结构准则以精确捕捉所有已知捷径构建的可构造性。", "motivation": "长期以来的研究一直在探讨高效捷径构建及其最佳直径与并行效率之间的关系。然而，在此之前尚缺乏一种简单明了的技术工具来有效简化和加强这些不可能性结果。", "method": "本文提出了称为认证捷径的新概念和技术工具，通过证明任何接近线性时间的捷径算法都无法将图的直径减少到低于n^{1/4-o(1)}，从而大大改进了先前的结果。同时提出了一项结构准则以精确捕捉所有已知捷径构建的可构造性。", "result": "研究结果表明，与[HXX25]中的n^{2/9-o(1)}下界相比，新的认证捷径技术显著提高了不可能性边界到n^{1/4-o(1)}。此外，该结构准则也精确捕捉到了所有已知捷径构建的可构造性。", "conclusion": "论文提出的新工具和视角有望在未来为设计高效的捷径算法提供重要指导，并认为认证捷径的概念可以成为未来研究中的关键因素。"}}
{"id": "2602.10745", "pdf": "https://arxiv.org/pdf/2602.10745", "abs": "https://arxiv.org/abs/2602.10745", "authors": ["Mohamad Dhaini", "Paul Honeine", "Maxime Berar", "Antonin Van Exem"], "title": "Spectral-Spatial Contrastive Learning Framework for Regression on Hyperspectral Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Contrastive learning has demonstrated great success in representation learning, especially for image classification tasks. However, there is still a shortage in studies targeting regression tasks, and more specifically applications on hyperspectral data. In this paper, we propose a spectral-spatial contrastive learning framework for regression tasks for hyperspectral data, in a model-agnostic design allowing to enhance backbones such as 3D convolutional and transformer-based networks. Moreover, we provide a collection of transformations relevant for augmenting hyperspectral data. Experiments on synthetic and real datasets show that the proposed framework and transformations significantly improve the performance of all studied backbone models.", "AI": {"tldr": "提出了一种针对高光谱数据回归任务的频谱空间对比学习框架", "motivation": "现有研究较少关注于基于高光谱数据的回归任务，该论文旨在填补这一空白，并通过模型无关的设计增强骨干网络以提升性能", "method": "设计了一种频谱空间对比学习框架，适用于各种骨干网络如3D卷积和Transformer网络，同时提供了一系列用于增强高光谱数据的数据变换方法", "result": "实验结果表明所提出的框架及转换方法能够显著提高所有研究的骨干模型在合成和真实数据集上的性能", "conclusion": "该频谱空间对比学习框架对提升基于高光谱数据的回归任务具有重要作用"}}
{"id": "2602.10744", "pdf": "https://arxiv.org/pdf/2602.10744", "abs": "https://arxiv.org/abs/2602.10744", "authors": ["Kian Majlessi", "Amir Masoud Soltani", "Mohammad Ebrahim Mahdavi", "Aurelien Gourrier", "Peyman Adibi"], "title": "Self-Supervised Image Super-Resolution Quality Assessment based on Content-Free Multi-Model Oriented Representation Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Super-resolution (SR) applied to real-world low-resolution (LR) images often results in complex, irregular degradations that stem from the inherent complexity of natural scene acquisition. In contrast to SR artifacts arising from synthetic LR images created under well-defined scenarios, those distortions are highly unpredictable and vary significantly across different real-life contexts. Consequently, assessing the quality of SR images (SR-IQA) obtained from realistic LR, remains a challenging and underexplored problem. In this work, we introduce a no-reference SR-IQA approach tailored for such highly ill-posed realistic settings. The proposed method enables domain-adaptive IQA for real-world SR applications, particularly in data-scarce domains. We hypothesize that degradations in super-resolved images are strongly dependent on the underlying SR algorithms, rather than being solely determined by image content. To this end, we introduce a self-supervised learning (SSL) strategy that first pretrains multiple SR model oriented representations in a pretext stage. Our contrastive learning framework forms positive pairs from images produced by the same SR model and negative pairs from those generated by different methods, independent of image content. The proposed approach S3 RIQA, further incorporates targeted preprocessing to extract complementary quality information and an auxiliary task to better handle the various degradation profiles associated with different SR scaling factors. To this end, we constructed a new dataset, SRMORSS, to support unsupervised pretext training; it includes a wide range of SR algorithms applied to numerous real LR images, which addresses a gap in existing datasets. Experiments on real SR-IQA benchmarks demonstrate that S3 RIQA consistently outperforms most state-of-the-art relevant metrics.", "AI": {"tldr": "本文提出了一种无参考的超分辨率图像质量评估方法S3 RIQA，适用于真实世界的数据稀疏场景。", "motivation": "针对超分辨率算法处理的真实低分辨率图像中复杂、不可预测的质量降级问题，该文旨在开发一种有效的无参考图像质量评估方法。", "method": "本文提出了一种基于自监督学习的方法S3 RIQA，通过预训练多个模型导向的表示，并利用对比学习框架形成正负样本对。此外，还引入了辅助任务和针对性的数据预处理步骤以提取互补的质量信息。", "result": "实验表明，提出的S3 RIQA方法在真实超分辨率图像质量评估基准上超过了大多数现有的状态-of-the-art指标。", "conclusion": "本文提出的方法能够有效解决数据稀疏环境下的超分辨率图像无参考质量评估问题，并通过构建新的大规模数据集验证了其有效性。"}}
{"id": "2602.10735", "pdf": "https://arxiv.org/pdf/2602.10735", "abs": "https://arxiv.org/abs/2602.10735", "authors": ["Hugo L. Hammer", "Vajira Thambawita", "Pål Halvorsen"], "title": "Calliope: A TTS-based Narrated E-book Creator Ensuring Exact Synchronization, Privacy, and Layout Fidelity", "categories": ["cs.SD", "cs.AI", "cs.CL"], "comment": null, "summary": "A narrated e-book combines synchronized audio with digital text, highlighting the currently spoken word or sentence during playback. This format supports early literacy and assists individuals with reading challenges, while also allowing general readers to seamlessly switch between reading and listening. With the emergence of natural-sounding neural Text-to-Speech (TTS) technology, several commercial services have been developed to leverage these technology for converting standard text e-books into high-quality narrated e-books. However, no open-source solutions currently exist to perform this task. In this paper, we present Calliope, an open-source framework designed to fill this gap. Our method leverages state-of-the-art open-source TTS to convert a text e-book into a narrated e-book in the EPUB 3 Media Overlay format. The method offers several innovative steps: audio timestamps are captured directly during TTS, ensuring exact synchronization between narration and text highlighting; the publisher's original typography, styling, and embedded media are strictly preserved; and the entire pipeline operates offline. This offline capability eliminates recurring API costs, mitigates privacy concerns, and avoids copyright compliance issues associated with cloud-based services. The framework currently supports the state-of-the-art open-source TTS systems XTTS-v2 and Chatterbox. A potential alternative approach involves first generating narration via TTS and subsequently synchronizing it with the text using forced alignment. However, while our method ensures exact synchronization, our experiments show that forced alignment introduces drift between the audio and text highlighting significant enough to degrade the reading experience. Source code and usage instructions are available at https://github.com/hugohammer/TTS-Narrated-Ebook-Creator.git.", "AI": {"tldr": "Calliope是一款基于TTS的有声电子书创建工具，旨在确保精确同步、隐私保护和布局保真度。", "motivation": "现有技术缺乏开源解决方案将标准文本电子书转换为高质量的有声电子书。因此开发了Calliope以填补这一空白，并提供离线操作避免API成本、版权问题和个人信息泄露。", "method": "利用先进的开源TTS系统直接获取音频时间戳，确保语音和文字同步；保留原始出版商的排版和样式，并支持XTTS-v2和Chatterbox等先进TTS系统。实验表明，与其他方法相比，这种方法能够更好地保持同步。", "result": "Calliope成功地将文本电子书转换为EPUB3多媒体覆盖格式有声电子书，确保精确同步、隐私保护和布局保真度。与使用强制对齐的方法相比，这种技术产生的音频和文字同步更好。", "conclusion": "通过直接获取TTS中的时间戳以实现精确的语音与文本同步，Calliope不仅提高了阅读体验，还提供了离线工作模式来避免云服务的相关问题。"}}
{"id": "2602.10728", "pdf": "https://arxiv.org/pdf/2602.10728", "abs": "https://arxiv.org/abs/2602.10728", "authors": ["Xinhao Xiang", "Zhengxin Li", "Saurav Dhakad", "Theo Bancroft", "Jiawei Zhang", "Weiyang Li"], "title": "OccFace: Unified Occlusion-Aware Facial Landmark Detection with Per-Point Visibility", "categories": ["cs.CV"], "comment": null, "summary": "Accurate facial landmark detection under occlusion remains challenging, especially for human-like faces with large appearance variation and rotation-driven self-occlusion. Existing detectors typically localize landmarks while handling occlusion implicitly, without predicting per-point visibility that downstream applications can benefits. We present OccFace, an occlusion-aware framework for universal human-like faces, including humans, stylized characters, and other non-human designs. OccFace adopts a unified dense 100-point layout and a heatmap-based backbone, and adds an occlusion module that jointly predicts landmark coordinates and per-point visibility by combining local evidence with cross-landmark context. Visibility supervision mixes manual labels with landmark-aware masking that derives pseudo visibility from mask-heatmap overlap. We also create an occlusion-aware evaluation suite reporting NME on visible vs. occluded landmarks and benchmarking visibility with Occ AP, F1@0.5, and ROC-AUC, together with a dataset annotated with 100-point landmarks and per-point visibility. Experiments show improved robustness under external occlusion and large head rotations, especially on occluded regions, while preserving accuracy on visible landmarks.", "AI": {"tldr": "OccFace是一种用于处理面部遮挡的统一框架，特别适用于具有大量外观变化和旋转驱动自我遮挡的人脸。", "motivation": "当前的面部特征点检测器在处理遮挡时存在局限性，无法预测每个点的可见性以供下游应用使用。因此，迫切需要一种能够准确处理遮挡情况的方法。", "method": "OccFace采用统一的100个密集布局和基于热图的基础模型，并添加了一个遮挡模块，该模块结合局部证据与跨特征点上下文共同预测地标坐标及每个点的可见性。通过将手动标签与根据掩码热图重叠导出伪可见性的地标感知掩码进行混合来监督可见性。", "result": "实验结果表明，OccFace在外部遮挡和大头部旋转的情况下具有改进的鲁棒性，特别是在被遮挡区域，并且保留了对可见特征点的准确性。", "conclusion": "OccFace提供了一种新颖的方法来处理面部遮挡问题，通过预测每个地标点的可见性，提高了模型的整体性能。"}}
{"id": "2602.10722", "pdf": "https://arxiv.org/pdf/2602.10722", "abs": "https://arxiv.org/abs/2602.10722", "authors": ["Davide Evangelista", "Pasquale Cascarano", "Elena Loli Piccolomini"], "title": "A Diffusion-Based Generative Prior Approach to Sparse-view Computed Tomography", "categories": ["cs.CV", "cs.AI"], "comment": "13 pages, 5 figures, 1 table", "summary": "The reconstruction of X-rays CT images from sparse or limited-angle geometries is a highly challenging task. The lack of data typically results in artifacts in the reconstructed image and may even lead to object distortions. For this reason, the use of deep generative models in this context has great interest and potential success. In the Deep Generative Prior (DGP) framework, the use of diffusion-based generative models is combined with an iterative optimization algorithm for the reconstruction of CT images from sinograms acquired under sparse geometries, to maintain the explainability of a model-based approach while introducing the generative power of a neural network. There are therefore several aspects that can be further investigated within these frameworks to improve reconstruction quality, such as image generation, the model, and the iterative algorithm used to solve the minimization problem, for which we propose modifications with respect to existing approaches. The results obtained even under highly sparse geometries are very promising, although further research is clearly needed in this direction.", "AI": {"tldr": "该论文提出了一种基于扩散生成模型的稀疏视图CT图像重建方法。", "motivation": "稀疏或受限角度下的X射线CT图像重建是一个具有挑战性的任务，由于数据不足常导致重建图像中的伪影和物体变形。因此，在这种情况下使用深度生成模型非常有潜力。", "method": "该论文采用了深生成先验框架，结合扩散生成模型与迭代优化算法从稀疏几何的sinogram中重构CT图像，保持基于模型的方法可解释性的同时引入神经网络的生成能力，并对图像生成、模型和用于求解最小化问题的迭代算法提出改进。", "result": "在高度稀疏几何条件下获得的结果非常有希望，但仍需要进一步的研究。", "conclusion": "该方法显示了潜在的优势并在稀疏数据下表现出良好的重建质量，但研究仍在进行中。"}}
{"id": "2602.10720", "pdf": "https://arxiv.org/pdf/2602.10720", "abs": "https://arxiv.org/abs/2602.10720", "authors": ["Craig Mahlasi", "Gciniwe S. Baloyi", "Zaheed Gaffoor", "Levente Klein", "Anne Jones", "Etienne Vos", "Michal Muszynski", "Geoffrey Dawson", "Campbell Watson"], "title": "Ecological mapping with geospatial foundation models", "categories": ["cs.CV"], "comment": null, "summary": "Geospatial foundation models (GFMs) are a fast-emerging paradigm for various geospatial tasks, such as ecological mapping. However, the utility of GFMs has not been fully explored for high-value use cases. This study aims to explore the utility, challenges and opportunities associated with the application of GFMs for ecological uses. In this regard, we fine-tune several pretrained AI models, namely, Prithvi-E0-2.0 and TerraMind, across three use cases, and compare this with a baseline ResNet-101 model. Firstly, we demonstrate TerraMind's LULC generation capabilities. Lastly, we explore the utility of the GFMs in forest functional trait mapping and peatlands detection. In all experiments, the GFMs outperform the baseline ResNet models. In general TerraMind marginally outperforms Prithvi. However, with additional modalities TerraMind significantly outperforms the baseline ResNet and Prithvi models. Nonetheless, consideration should be given to the divergence of input data from pretrained modalities. We note that these models would benefit from higher resolution and more accurate labels, especially for use cases where pixel-level dynamics need to be mapped.", "AI": {"tldr": "本文探讨了地基模型（GFMs）在生态制图中的应用及其性能。", "motivation": "探索地基模型（GFMs）用于生态保护等高价值应用场景的效用、挑战和机遇。", "method": "通过微调预训练AI模型，如Prithvi-E0-2.0和TerraMind，在土地利用分类生成、森林功能特征制图及泥炭地检测三个案例中与基准ResNet-101模型进行比较。", "result": "GFMs在所有实验中均优于基线的ResNet模型，其中TerraMind稍微领先于Prithvi。然而，结合更多模态时，TerraMind显著超越其他模型。需要注意的是输入数据应尽量接近预训练模式的数据集特征。", "conclusion": "这些模型在高分辨率和更准确标签的支持下表现更好，尤其是需要像素级动态映射的用例中。"}}
{"id": "2602.10719", "pdf": "https://arxiv.org/pdf/2602.10719", "abs": "https://arxiv.org/abs/2602.10719", "authors": ["Sining Ang", "Yuguang Yang", "Chenxu Dang", "Canyu Chen", "Cheng Chi", "Haiyan Liu", "Xuanyao Mao", "Jason Bao", "Xuliang", "Bingchuan Sun", "Yan Wang"], "title": "From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving", "categories": ["cs.RO", "cs.CV"], "comment": "22 pages (10 pages main text + 12 pages appendix), 18 figures", "summary": "Vision-Language-Action (VLA) driving augments end-to-end (E2E) planning with language-enabled backbones, yet it remains unclear what changes beyond the usual accuracy--cost trade-off. We revisit this question with 3--RQ analysis in RecogDrive by instantiating the system with a full VLM and vision-only backbones, all under an identical diffusion Transformer planner. RQ1: At the backbone level, the VLM can introduce additional subspaces upon the vision-only backbones. RQ2: This unique subspace leads to a different behavioral in some long-tail scenario: the VLM tends to be more aggressive whereas ViT is more conservative, and each decisively wins on about 2--3% of test scenarios; With an oracle that selects, per scenario, the better trajectory between the VLM and ViT branches, we obtain an upper bound of 93.58 PDMS. RQ3: To fully harness this observation, we propose HybridDriveVLA, which runs both ViT and VLM branches and selects between their endpoint trajectories using a learned scorer, improving PDMS to 92.10. Finally, DualDriveVLA implements a practical fast--slow policy: it runs ViT by default and invokes the VLM only when the scorer's confidence falls below a threshold; calling the VLM on 15% of scenarios achieves 91.00 PDMS while improving throughput by 3.2x. Code will be released.", "AI": {"tldr": "该论文探索了在自动驾驶中结合视觉语言模型和纯视觉模型的方法，通过HybridDriveVLA和DualDriveVLA系统实现了性能的提升。", "motivation": "研究旨在解决将视觉-语言模型纳入端到端驾驶规划时带来的额外收益问题，并通过实际场景评估不同模型的行为差异。", "method": "论文中引入了RecogDrive框架，比较了使用全视觉语言模型和纯视觉模型的表现，提出了HybridDriveVLA和DualDriveVLA方法以利用两者的优势。", "result": "通过选择性调用两种不同的模型分支，最终系统实现了91.00 PDMS的性能指标，并且吞吐量提高了3.2倍。", "conclusion": "实验表明，在自动驾驶场景中结合视觉语言模型和纯视觉模型可以实现更好的性能。"}}
{"id": "2602.10717", "pdf": "https://arxiv.org/pdf/2602.10717", "abs": "https://arxiv.org/abs/2602.10717", "authors": ["Songen Gu", "Yunuo Cai", "Tianyu Wang", "Simo Wu", "Yanwei Fu"], "title": "Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Robotic manipulation requires anticipating how the environment evolves in response to actions, yet most existing systems lack this predictive capability, often resulting in errors and inefficiency. While Vision-Language Models (VLMs) provide high-level guidance, they cannot explicitly forecast future states, and existing world models either predict only short horizons or produce spatially inconsistent frames. To address these challenges, we propose a framework for fast and predictive video-conditioned action. Our approach first selects and adapts a robust video generation model to ensure reliable future predictions, then applies adversarial distillation for fast, few-step video generation, and finally trains an action model that leverages both generated videos and real observations to correct spatial errors. Extensive experiments show that our method produces temporally coherent, spatially accurate video predictions that directly support precise manipulation, achieving significant improvements in embodiment consistency, spatial referring ability, and task completion over existing baselines. Codes & Models will be released.", "AI": {"tldr": "提出一种视频条件下的快速且预测性行动框架，解决机器人操作中的环境演变预测问题。", "motivation": "现有系统缺乏对未来状态的预测能力，导致错误和低效率。为了改善这一状况，本文旨在设计一个能够进行长时间、空间一致性的视频预测模型，并将其应用于精确的操作任务中。", "method": "采用选择并适应稳健的视频生成模型以确保可靠未来的预测，利用对抗蒸馏实现快速、少步骤的视频生成，训练行动模型使用生成的视频和真实观察来纠正空间错误。", "result": "实验显示该方法能产生时间上连贯且空间准确的视频预测，显著提高了实身体一致性、空间参照能力和任务完成度。", "conclusion": "通过提出的新框架，在机器人操作中的环境演变预测能力有了明显的提高。"}}
{"id": "2602.10716", "pdf": "https://arxiv.org/pdf/2602.10716", "abs": "https://arxiv.org/abs/2602.10716", "authors": ["Jing-Han Chen", "Bo-Hao Su", "Ya-Tse Wu", "Chi-Chun Lee"], "title": "RE-LLM: Refining Empathetic Speech-LLM Responses by Integrating Emotion Nuance", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "5 pages, 1 figure, 2 tables. Accepted at IEEE ASRU 2025", "summary": "With generative AI advancing, empathy in human-AI interaction is essential. While prior work focuses on emotional reflection, emotional exploration, key to deeper engagement, remains overlooked. Existing LLMs rely on text which captures limited emotion nuances. To address this, we propose RE-LLM, a speech-LLM integrating dimensional emotion embeddings and auxiliary learning. Experiments show statistically significant gains in empathy metrics across three datasets. RE-LLM relatively improves the Emotional Reaction score by 14.79% and 6.76% compared to text-only and speech-LLM baselines on ESD. Notably, it raises the Exploration score by 35.42% and 3.91% on IEMOCAP, 139.28% and 9.83% on ESD, and 60.95% and 22.64% on MSP-PODCAST. It also boosts unweighted accuracy by 5.4% on IEMOCAP, 2.3% on ESD, and 6.9% on MSP-PODCAST in speech emotion recognition. These results highlight the enriched emotional understanding and improved empathetic response generation of RE-LLM.", "AI": {"tldr": "RE-LLM是一个通过整合情感维度嵌入和辅助学习来改进人类与AI交互中同情心的语音LLM。", "motivation": "现有的工作主要集中在情感反射上，而更深层次的情感探索仍被忽视。传统的LLM仅依赖于文本输入，无法捕捉丰富的情绪细节。因此，提出了RE-LLM以增强对情绪的理解和生成更富有同理心的回答。", "method": "通过整合维度情感嵌入以及辅助学习来改进现有LLM模型，旨在提高其在情感反应和探索方面的表现。", "result": "实验结果表明，在三个数据集上，RE-LLM相比文本基础线和语音LLM基础线分别提高了14.79%和6.76%，在IEMOCAP、ESD以及MSP-PODCAST中的情感探索得分也有显著提升。", "conclusion": "研究表明，RE-LLM能够有效提高人类与AI交互的同情心水平，并且在语音情绪识别任务中也取得了较好的效果。"}}
{"id": "2602.10715", "pdf": "https://arxiv.org/pdf/2602.10715", "abs": "https://arxiv.org/abs/2602.10715", "authors": ["Yifei Li", "Weidong Guo", "Lingling Zhang", "Rongman Xu", "Muye Huang", "Hui Liu", "Lijiao Xu", "Yu Xu", "Jun Liu"], "title": "Locomo-Plus: Beyond-Factual Cognitive Memory Evaluation Framework for LLM Agents", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 8 figures", "summary": "Long-term conversational memory is a core capability for LLM-based dialogue systems, yet existing benchmarks and evaluation protocols primarily focus on surface-level factual recall. In realistic interactions, appropriate responses often depend on implicit constraints such as user state, goals, or values that are not explicitly queried later. To evaluate this setting, we introduce \\textbf{LoCoMo-Plus}, a benchmark for assessing cognitive memory under cue--trigger semantic disconnect, where models must retain and apply latent constraints across long conversational contexts. We further show that conventional string-matching metrics and explicit task-type prompting are misaligned with such scenarios, and propose a unified evaluation framework based on constraint consistency. Experiments across diverse backbone models, retrieval-based methods, and memory systems demonstrate that cognitive memory remains challenging and reveals failures not captured by existing benchmarks. Our code and evaluation framework are publicly available at: https://github.com/xjtuleeyf/Locomo-Plus.", "AI": {"tldr": "提出了一种评估LLM对话系统认知记忆能力的新框架LoCoMo-Plus，旨在解决现有评价体系仅关注表面事实回忆的问题。", "motivation": "当前的基准测试主要集中在表面层面的事实记忆上，忽略了在真实交互中适当响应依赖于隐含约束的情况。因此需要一种新方法来全面评估LLM的认知记忆。", "method": "提出了一种基于LoCoMo-Plus的新框架用于评价认知记忆能力，在该框架下，模型需能保留和应用潜在的隐式约束，并展示了传统字符串匹配指标在此类情况下的不适用性。", "result": "实验显示了在各种基线模型、检索方法及记忆系统中，现有的基准测试未能充分捕捉到的认知内存挑战及其失败案例。", "conclusion": "LoCoMo-Plus提供了一种统一且有效的评估框架，能够更好地衡量LLM的认知记忆能力。"}}
{"id": "2602.10711", "pdf": "https://arxiv.org/pdf/2602.10711", "abs": "https://arxiv.org/abs/2602.10711", "authors": ["Hyeongmin Lee", "Chanyeol Choi", "Jihoon Kwon", "Yoon Kim", "Alejandro Lopez-Lira", "Wonbin Ahn", "Yongjae Lee"], "title": "Cross-Sectional Asset Retrieval via Future-Aligned Soft Contrastive Learning", "categories": ["cs.CE", "cs.AI"], "comment": null, "summary": "Asset retrieval--finding similar assets in a financial universe--is central to quantitative investment decision-making. Existing approaches define similarity through historical price patterns or sector classifications, but such backward-looking criteria provide no guarantee about future behavior. We argue that effective asset retrieval should be future-aligned: the retrieved assets should be those most likely to exhibit correlated future returns. To this end, we propose Future-Aligned Soft Contrastive Learning (FASCL), a representation learning framework whose soft contrastive loss uses pairwise future return correlations as continuous supervision targets. We further introduce an evaluation protocol designed to directly assess whether retrieved assets share similar future trajectories. Experiments on 4,229 US equities demonstrate that FASCL consistently outperforms 13 baselines across all future-behavior metrics. The source code will be available soon.", "AI": {"tldr": "本文提出了一种基于未来收益相关性进行资产检索的框架FASCL。", "motivation": "现有方法依赖于历史价格或行业分类定义相似度，无法保证未来表现。因此提出了面向未来的软对比学习方法来改善这一问题。", "method": "通过引入Future-Aligned Soft Contrastive Learning (FASCL) 框架，并使用连续的监督目标进行训练，该框架利用资产对之间未来收益的相关性作为软对比损失函数的目标。", "result": "实验结果表明，在4229只美国股票上测试时，FASCL在所有未来行为评估指标上均优于13种基线方法。", "conclusion": "通过使用面向未来的软对比学习框架，可以更有效地检索出具有相似未来收益轨迹的资产。"}}
{"id": "2602.10710", "pdf": "https://arxiv.org/pdf/2602.10710", "abs": "https://arxiv.org/abs/2602.10710", "authors": ["Jialin Ma"], "title": "FGAA-FPN: Foreground-Guided Angle-Aware Feature Pyramid Network for Oriented Object Detection", "categories": ["cs.CV"], "comment": "Submitted to The Visual Computer", "summary": "With the increasing availability of high-resolution remote sensing and aerial imagery, oriented object detection has become a key capability for geographic information updating, maritime surveillance, and disaster response. However, it remains challenging due to cluttered backgrounds, severe scale variation, and large orientation changes. Existing approaches largely improve performance through multi-scale feature fusion with feature pyramid networks or contextual modeling with attention, but they often lack explicit foreground modeling and do not leverage geometric orientation priors, which limits feature discriminability. To overcome these limitations, we propose FGAA-FPN, a Foreground-Guided Angle-Aware Feature Pyramid Network for oriented object detection. FGAA-FPN is built on a hierarchical functional decomposition that accounts for the distinct spatial resolution and semantic abstraction across pyramid levels, thereby strengthening multi-scale representations. Concretely, a Foreground-Guided Feature Modulation module learns foreground saliency under weak supervision to enhance object regions and suppress background interference in low-level features. In parallel, an Angle-Aware Multi-Head Attention module encodes relative orientation relationships to guide global interactions among high-level semantic features. Extensive experiments on DOTA v1.0 and DOTA v1.5 demonstrate that FGAA-FPN achieves state-of-the-art results, reaching 75.5% and 68.3% mAP, respectively.", "AI": {"tldr": "本文提出了一种用于定向目标检测的FGAA-FPN方法，该方法结合了前景导向特征调整和角度感知多头注意力模块。", "motivation": "现有技术在处理高分辨率遥感和航空图像中的定向目标检测时，面临背景杂乱、尺度变化严重以及方位变化大的挑战。为了克服这些限制，作者提出了一种新的网络结构FGAA-FPN。", "method": "FGAA-FPN通过一个层次化的功能分解来增强多尺度表示，并采用前景导向特征调制模块学习弱监督下的前景显著性以增强目标区域并抑制背景干扰；同时使用角度感知的多头注意力模块编码相对方向关系，引导高层语义特征之间的全局交互。", "result": "实验在DOTA v1.0和DOTA v1.5数据集上验证了FGAA-FPN的效果，分别达到了75.5%和68.3%mAP，超过了当前的最先进水平。", "conclusion": "FGAA-FPN通过结合前景导向特征调整和角度感知多头注意力模块，在定向目标检测任务中表现出色。"}}
{"id": "2602.10708", "pdf": "https://arxiv.org/pdf/2602.10708", "abs": "https://arxiv.org/abs/2602.10708", "authors": ["Qiuran Zhao", "Kai Ming Ting", "Xinpeng Li"], "title": "Interpretable Graph-Level Anomaly Detection via Contrast with Normal Prototypes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The task of graph-level anomaly detection (GLAD) is to identify anomalous graphs that deviate significantly from the majority of graphs in a dataset. While deep GLAD methods have shown promising performance, their black-box nature limits their reliability and deployment in real-world applications. Although some recent methods have made attempts to provide explanations for anomaly detection results, they either provide explanations without referencing normal graphs, or rely on abstract latent vectors as prototypes rather than concrete graphs from the dataset. To address these limitations, we propose Prototype-based Graph-Level Anomaly Detection (ProtoGLAD), an interpretable unsupervised framework that provides explanation for each detected anomaly by explicitly contrasting with its nearest normal prototype graph. It employs a point-set kernel to iteratively discover multiple normal prototype graphs and their associated clusters from the dataset, then identifying graphs distant from all discovered normal clusters as anomalies. Extensive experiments on multiple real-world datasets demonstrate that ProtoGLAD achieves competitive anomaly detection performance compared to state-of-the-art GLAD methods while providing better human-interpretable prototype-based explanations.", "AI": {"tldr": "提出一种基于原型的图级异常检测框架，通过与正常原型对比解释异常结果。", "motivation": "现有的深度图级异常检测方法虽然表现出色，但其黑盒特性限制了实际应用中的可靠性。为了提供更可解释的结果，本文提出了ProtoGLAD框架。", "method": "ProtoGLAD采用点集核迭代发现数据集中多个正常原型图及关联簇，并将远离所有已知正常簇的图形识别为异常。", "result": "在多种真实世界数据集上的实验表明，ProtoGLAD与最新方法相比具有竞争性的检测性能并提供更好的可解释性。", "conclusion": "本文提出的ProtoGLAD框架实现了高效的图级异常检测同时提供了更易于人类理解的解释。"}}
{"id": "2602.10704", "pdf": "https://arxiv.org/pdf/2602.10704", "abs": "https://arxiv.org/abs/2602.10704", "authors": ["Minglei Li", "Mengfan He", "Chao Chen", "Ziyang Meng"], "title": "(MGS)$^2$-Net: Unifying Micro-Geometric Scale and Macro-Geometric Structure for Cross-View Geo-Localization", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Cross-view geo-localization (CVGL) is pivotal for GNSS-denied UAV navigation but remains brittle under the drastic geometric misalignment between oblique aerial views and orthographic satellite references. Existing methods predominantly operate within a 2D manifold, neglecting the underlying 3D geometry where view-dependent vertical facades (macro-structure) and scale variations (micro-scale) severely corrupt feature alignment. To bridge this gap, we propose (MGS)$^2$, a geometry-grounded framework. The core of our innovation is the Macro-Geometric Structure Filtering (MGSF) module. Unlike pixel-wise matching sensitive to noise, MGSF leverages dilated geometric gradients to physically filter out high-frequency facade artifacts while enhancing the view-invariant horizontal plane, directly addressing the domain shift. To guarantee robust input for this structural filtering, we explicitly incorporate a Micro-Geometric Scale Adaptation (MGSA) module. MGSA utilizes depth priors to dynamically rectify scale discrepancies via multi-branch feature fusion. Furthermore, a Geometric-Appearance Contrastive Distillation (GACD) loss is designed to strictly discriminate against oblique occlusions. Extensive experiments demonstrate that (MGS)$^2$ achieves state-of-the-art performance, recording a Recall@1 of 97.5\\% on University-1652 and 97.02\\% on SUES-200. Furthermore, the framework exhibits superior cross-dataset generalization against geometric ambiguity. The code is available at: \\href{https://github.com/GabrielLi1473/MGS-Net}{https://github.com/GabrielLi1473/MGS-Net}.", "AI": {"tldr": "本文提出了(MGS)$^2$-Net，一种用于跨视图地理定位的几何基础框架。", "motivation": "现有的方法主要在二维流形中操作，忽略了潜在的三维几何结构问题，导致特征对齐困难。为了解决这一问题，作者提出了一种新的几何基础框架。(MGS)$^2$-Net旨在通过处理宏观几何结构和微尺度变化来改善跨视图地理定位。", "method": "(MGS)$^2$-Net主要包括两个模块：Macro-Geometric Structure Filtering (MGSF)模块利用扩张的几何梯度去除高频立面细节并增强水平平面特征，Micro-Geometric Scale Adaptation (MGSA)模块通过深度先验动态修正尺度差异。此外，设计了一种新的损失函数Geometric-Appearance Contrastive Distillation (GACD)，以严格区分斜视遮挡。", "result": "(MGS)$^2$-Net在University-1652数据集上实现了97.5%的Recall@1，在SUES-200数据集上实现了97.02%。实验结果表明，(MGS)$^2$-Net具有跨数据集泛化能力。", "conclusion": "(MGS)$^2$-Net通过处理宏观几何结构和微尺度变化，显著提高了跨视图地理定位的性能和鲁棒性。"}}
{"id": "2602.10703", "pdf": "https://arxiv.org/pdf/2602.10703", "abs": "https://arxiv.org/abs/2602.10703", "authors": ["Martijn B. J. Brummelhuis", "Nathan F. Lepora", "Salua Hamaza"], "title": "Omnidirectional Dual-Arm Aerial Manipulator with Proprioceptive Contact Localization for Landing on Slanted Roofs", "categories": ["cs.RO"], "comment": "Accepted into 2026 International Conference on Robotics and Automation (ICRA) in Vienna", "summary": "Operating drones in urban environments often means they need to land on rooftops, which can have different geometries and surface irregularities. Accurately detecting roof inclination using conventional sensing methods, such as vision-based or acoustic techniques, can be unreliable, as measurement quality is strongly influenced by external factors including weather conditions and surface materials. To overcome these challenges, we propose a novel unmanned aerial manipulator morphology featuring a dual-arm aerial manipulator with an omnidirectional 3D workspace and extended reach. Building on this design, we develop a proprioceptive contact detection and contact localization strategy based on a momentum-based torque observer. This enables the UAM to infer the inclination of slanted surfaces blindly - through physical interaction - prior to touchdown. We validate the approach in flight experiments, demonstrating robust landings on surfaces with inclinations of up to 30.5 degrees and achieving an average surface inclination estimation error of 2.87 degrees over 9 experiments at different incline angles.", "AI": {"tldr": "提出了一种新型的无人机形态，配备双臂空中操作器和全方位三维工作空间，并结合基于动量的扭矩观察器开发了接触检测与定位策略，实现了在未知倾斜表面上盲降。", "motivation": "传统的视觉或声学方法难以精确检测屋顶倾斜角度，尤其是在天气条件及表面材料变化的情况下。为了克服这些问题，本研究提出了一种新的无人机形态及其接触检测和定位策略以提高降落的准确性和鲁棒性。", "method": "设计并实现了一个配备双臂空中操作器的无人机，并开发了基于动量的扭矩观察器来估计接触点的位置和表面倾斜角度。通过物理交互的方式，该方法能够在着陆前盲测出斜面的角度。", "result": "在飞行实验中展示了能够稳定地降落在倾斜达30.5度的表面上，并且在不同角度下的9次试验中平均倾斜误差为2.87度。", "conclusion": "所提出的方法能够有效地检测和定位接触点，从而实现无人机在未知倾斜表面的安全着陆。"}}
{"id": "2602.10702", "pdf": "https://arxiv.org/pdf/2602.10702", "abs": "https://arxiv.org/abs/2602.10702", "authors": ["Alejandro Mendoza Barrionuevo", "Dame Seck Diop", "Alejandro Casado Pérez", "Daniel Gutiérrez Reina", "Sergio L. Toral Marín", "Samuel Yanes Luis"], "title": "A Unified Experimental Architecture for Informative Path Planning: from Simulation to Deployment with GuadalPlanner", "categories": ["cs.RO", "cs.LG", "cs.SE"], "comment": null, "summary": "The evaluation of informative path planning algorithms for autonomous vehicles is often hindered by fragmented execution pipelines and limited transferability between simulation and real-world deployment. This paper introduces a unified architecture that decouples high-level decision-making from vehicle-specific control, enabling algorithms to be evaluated consistently across different abstraction levels without modification. The proposed architecture is realized through GuadalPlanner, which defines standardized interfaces between planning, sensing, and vehicle execution. It is an open and extensible research tool that supports discrete graph-based environments and interchangeable planning strategies, and is built upon widely adopted robotics technologies, including ROS2, MAVLink, and MQTT. Its design allows the same algorithmic logic to be deployed in fully simulated environments, software-in-the-loop configurations, and physical autonomous vehicles using an identical execution pipeline. The approach is validated through a set of experiments, including real-world deployment on an autonomous surface vehicle performing water quality monitoring with real-time sensor feedback.", "AI": {"tldr": "本文提出了一种统一的实验架构，用于信息路径规划算法评估，该架构实现了GuadalPlanner工具，支持在不同抽象层次上的一致性测试。", "motivation": "自主车辆的信息路径规划算法评估往往因执行管道碎片化和仿真与实际部署之间的迁移能力有限而受限。本文旨在通过引入统一架构解决这一问题。", "method": "该方法提出了一种新的实验架构，通过定义标准化接口将决策从特定控制中分离出来，并实现了GuadalPlanner工具以支持不同环境下的规划策略。", "result": "该研究通过一系列实验验证了所提架构的有效性，包括在自主水面车辆上进行的水质监控任务中的实际部署。", "conclusion": "结果表明，所提出的统一架构和GuadalPlanner能够有效提升信息路径规划算法评估的一致性和可移植性。"}}
{"id": "2602.10701", "pdf": "https://arxiv.org/pdf/2602.10701", "abs": "https://arxiv.org/abs/2602.10701", "authors": ["Cedric Faas", "Richard Uth", "Sarah Sterz", "Markus Langer", "Anna Maria Feit"], "title": "Don't blame me: How Intelligent Support Affects Moral Responsibility in Human Oversight", "categories": ["cs.HC"], "comment": null, "summary": "AI-based systems can increasingly perform work tasks autonomously. In safety-critical tasks, human oversight of these systems is required to mitigate risks and to ensure responsibility in case something goes wrong. Since people often struggle to stay focused and perform good oversight, intelligent support systems are used to assist them, giving decision recommendations, alerting users, or restricting them from dangerous actions. However, in cases where recommendations are wrong, decision support might undermine the very reason why human oversight was employed -- genuine moral responsibility. The goal of our study was to investigate how a decision support system that restricted available interventions would affect overseer's perceived moral responsibility, in particular in cases where the support errs. In a simulated oversight experiment, participants (\\textit{N}=274) monitored an autonomous drone that faced ten critical situations, choosing from six possible actions to resolve each situation. An AI system constrained participants' choices to either six, four, two, or only one option (between-subject study). Results showed that participants, who were restricted to choosing from a single action, felt less morally responsible if a crash occurred. At the same time, participants' judgments about the responsibility of other stakeholders (the AI; the developer of the AI) did not change between conditions. Our findings provide important insights for user interface design and oversight architectures: they should prevent users from attributing moral agency to AI, help them understand how moral responsibility is distributed, and, when oversight aims to prevent ethically undesirable outcomes, be designed to support the epistemic and causal conditions required for moral responsibility.", "AI": {"tldr": "研究探讨了智能支持系统如何影响人类在监控自主无人机时的道德责任感知。", "motivation": "随着AI系统的普及，人们越来越依赖这些技术来执行任务。然而，在推荐错误的情况下，这种决策支持可能会削弱人的真实道德责任感。本研究旨在探索当一个限制干预选择的决策支持系统犯错时，它如何影响监督者的道德责任感。", "method": "通过模拟实验让参与者（N=274）监控自主无人机并面对十个关键情况，他们可以从六个可能的操作中选择以解决每个情况。AI系统根据不同的条件限制了他们的选择范围。", "result": "当参与者的选项被限定为一个时，在发生坠机事件后，他们感觉自己的道德责任减少了。然而，关于其他利益相关者（如AI和其开发者）的责任感并没有因这些变化而改变。", "conclusion": "研究结果揭示了设计用户界面和监督架构的重要性：它们应当避免让用户将道德代理权归咎于AI，并帮助理解道德责任的分配方式；在以防止不道德行为为目标的情况下，应支持履行伦理职责所需的认知与因果条件。"}}
{"id": "2602.10699", "pdf": "https://arxiv.org/pdf/2602.10699", "abs": "https://arxiv.org/abs/2602.10699", "authors": ["Jie Jiang", "Yangru Huang", "Zeyu Wang", "Changping Wang", "Yuling Xiong", "Jun Zhang", "Huan Yu"], "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression, where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO, which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.", "AI": {"tldr": "提出了一种基于价值导向的采样和优化框架（V-STAR），用于解决生成式推荐中的概率奖励不匹配问题。", "motivation": "传统的自回归模型在利用强化学习进行微调时，面临着概率奖励不匹配的问题。这种问题导致了局部偏见和其他关键挑战，如探索不足和优势压缩。", "method": "提出了一种价值导向采样与树状优势强化框架（V-STAR）。它包含两个主要组件：价值导向高效解码（VED）和兄弟相对优势梯度引导策略优化（Sibling-GRPO），通过这些组件来解决上述问题。", "result": "实验结果表明，所提出的V-STAR框架在离线和在线数据集上均超越了现有基线方法，并且能够在严格的延迟约束下提供更高的准确性和候选集多样性。", "conclusion": "V-STAR解决了生成式推荐中的概率奖励不匹配问题，通过价值导向采样与优化策略改进了探索效率并提高了模型性能。"}}
{"id": "2602.10698", "pdf": "https://arxiv.org/pdf/2602.10698", "abs": "https://arxiv.org/abs/2602.10698", "authors": ["Zhifeng Rao", "Wenlong Chen", "Lei Xie", "Xia Hua", "Dongfu Yin", "Zhen Tian", "F. Richard Yu"], "title": "AugVLA-3D: Depth-Driven Feature Augmentation for Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language-Action (VLA) models have recently achieved remarkable progress in robotic perception and control, yet most existing approaches primarily rely on VLM trained using 2D images, which limits their spatial understanding and action grounding in complex 3D environments. To address this limitation, we propose a novel framework that integrates depth estimation into VLA models to enrich 3D feature representations. Specifically, we employ a depth estimation baseline called VGGT to extract geometry-aware 3D cues from standard RGB inputs, enabling efficient utilization of existing large-scale 2D datasets while implicitly recovering 3D structural information. To further enhance the reliability of these depth-derived features, we introduce a new module called action assistant, which constrains the learned 3D representations with action priors and ensures their consistency with downstream control tasks. By fusing the enhanced 3D features with conventional 2D visual tokens, our approach significantly improves the generalization ability and robustness of VLA models. Experimental results demonstrate that the proposed method not only strengthens perception in geometrically ambiguous scenarios but also leads to superior action prediction accuracy. This work highlights the potential of depth-driven data augmentation and auxiliary expert supervision for bridging the gap between 2D observations and 3D-aware decision-making in robotic systems.", "AI": {"tldr": "提出了一种新的框架AugVLA-3D，通过将深度估计整合到视觉语言行动模型中来增强3D特征表示。", "motivation": "现有的大多数视觉语言行动(VLA)模型主要依赖于基于2D图像训练的视觉语言模型，这限制了其在复杂三维环境中的空间理解和动作定位能力。", "method": "采用VGGT作为深度估计基线从标准RGB输入中提取几何感知3D线索，并引入一个名为action assistant的新模块以行动先验约束学习到的3D表示并确保它们与下游控制任务的一致性。通过融合增强后的3D特征和传统的2D视觉标记，该方法显著提高了VLA模型的泛化能力和鲁棒性。", "result": "实验结果表明所提出的方法不仅增强了在几何模糊场景中的感知能力，还提升了行动预测精度。", "conclusion": "该研究证明了深度驱动的数据增强及辅助专家监督对于弥补从2D观察到3D认知决策之间的差距具有潜在价值。"}}
{"id": "2602.10693", "pdf": "https://arxiv.org/pdf/2602.10693", "abs": "https://arxiv.org/abs/2602.10693", "authors": ["Guobin Shen", "Chenxiao Zhao", "Xiang Cheng", "Lei Huang", "Xing Yu"], "title": "VESPO: Variational Sequence-Level Soft Policy Optimization for Stable Off-Policy LLM Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training stability remains a central challenge in reinforcement learning (RL) for large language models (LLMs). Policy staleness, asynchronous training, and mismatches between training and inference engines all cause the behavior policy to diverge from the current policy, risking training collapse. Importance sampling provides a principled correction for this distribution shift but suffers from high variance; existing remedies such as token-level clipping and sequence-level normalization lack a unified theoretical foundation. We propose Variational sEquence-level Soft Policy Optimization (VESPO). By incorporating variance reduction into a variational formulation over proposal distributions, VESPO derives a closed-form reshaping kernel that operates directly on sequence-level importance weights without length normalization. Experiments on mathematical reasoning benchmarks show that VESPO maintains stable training under staleness ratios up to 64x and fully asynchronous execution, and delivers consistent gains across both dense and Mixture-of-Experts models. Code is available at https://github.com/FloyedShen/VESPO", "AI": {"tldr": "本文提出了一种新的算法VESPO，用于解决大规模语言模型训练中的稳定性问题。", "motivation": "在强化学习中，大型语言模型的训练面临着稳定性的挑战，包括策略过时、异步训练以及训练和推理引擎之间的不匹配等问题。这些都会导致行为策略与当前策略之间的偏差，从而可能导致训练崩溃。", "method": "通过将方差减少引入到提议分布上的变分公式化中，VESPO推导出一个直接应用于序列级别重要性权重的闭式重塑核函数。", "result": "在数学推理基准测试上实验表明，VESPO可以在高达64倍的时间延迟比和完全异步执行下保持稳定的训练，并且在密集模型和混合专家模型中均能取得一致性的提升。", "conclusion": "该算法解决了大型语言模型强化学习训练中的稳定性问题，在高延迟比和异步设置中表现尤为出色，为大规模语言模型的稳定训练提供了新的解决方案。"}}
{"id": "2602.10688", "pdf": "https://arxiv.org/pdf/2602.10688", "abs": "https://arxiv.org/abs/2602.10688", "authors": ["Jin Zhou", "Chongxun Wang", "Zikang Shen", "Fangzhou Xia"], "title": "3D-Printed Anisotropic Soft Magnetic Coating for Directional Rolling of a Magnetically Actuated Capsule Robot", "categories": ["cs.RO"], "comment": "Submitted for review at IEEE/ASME Advanced Intelligenet Mechatronics Conference (2026)", "summary": "Capsule robots are promising tools for minimally invasive diagnostics and therapy, with applications from gastrointestinal endoscopy to targeted drug delivery and biopsy sampling. Conventional magnetic capsule robots embed bulky permanent magnets at both ends, reducing the usable cavity by about 10-20 mm and limiting integration of functional modules. We propose a compact, 3D-printed soft capsule robot with a magnetic coating that replaces internal magnets, enabling locomotion via a thin, functional shell while preserving the entire interior cavity as a continuous volume for medical payloads. The compliant silicone-magnetic composite also improves swallowability, even with a slightly larger capsule size. Magnetostatic simulations and experiments confirm that programmed NSSN/SNNS pole distributions provide strong anisotropy and reliable torque generation, enabling stable bidirectional rolling, omnidirectional steering, climbing on 7.5 degree inclines, and traversal of 5 mm protrusions. Rolling motion is sustained when the magnetic field at the capsule reaches at least 0.3 mT, corresponding to an effective actuation depth of 30 mm in our setup. Future work will optimize material composition, coating thickness, and magnetic layouts to enhance force output and durability, while next-generation robotic-arm-based field generators with closed-loop feedback will address nonlinearities and expand maneuverability. Together, these advances aim to transition coating-based capsule robots toward reliable clinical deployment and broaden their applications in minimally invasive diagnostics and therapy.", "AI": {"tldr": "设计了一种具有方向性滚动能力的磁控胶囊机器人，采用3D打印的各向异性软磁涂层代替传统内部永久磁铁。", "motivation": "现有的磁控胶囊机器人由于嵌入了较大的永久磁铁而限制了有效空间及功能模块的集成。此研究旨在开发一种更加紧凑、易于吞咽且能够执行复杂操作的新一代胶囊机器人。", "method": "使用3D打印技术制造了一种含有软性硅胶-磁性复合材料涂层的胶囊机器人，通过模拟和实验验证其磁场分布与运动性能。", "result": "该设计实现了稳定双向滚动、全方位转向以及在7.5度斜坡上的爬升能力，并能够穿越5毫米高的障碍物。证明了当胶囊表面达到至少0.3毫特斯拉时可以维持持续滚动。", "conclusion": "研究成果表明，采用软磁涂层的新型胶囊机器人具有良好的吞咽性和操作性，未来将进一步优化材料组合、涂层厚度和磁场布局以提升性能并推动临床应用"}}
{"id": "2602.10687", "pdf": "https://arxiv.org/pdf/2602.10687", "abs": "https://arxiv.org/abs/2602.10687", "authors": ["Jinjie Shen", "Jing Wu", "Yaxiong Wang", "Lechao Cheng", "Shengeng Tang", "Tianrui Hui", "Nan Pu", "Zhun Zhong"], "title": "OmniVL-Guard: Towards Unified Vision-Language Forgery Detection and Grounding via Balanced RL", "categories": ["cs.CV", "cs.AI"], "comment": "38 pages, DeepFake Detection", "summary": "Existing forgery detection methods are often limited to uni-modal or bi-modal settings, failing to handle the interleaved text, images, and videos prevalent in real-world misinformation. To bridge this gap, this paper targets to develop a unified framework for omnibus vision-language forgery detection and grounding. In this unified setting, the {interplay} between diverse modalities and the dual requirements of simultaneous detection and localization pose a critical ``difficulty bias`` problem: the simpler veracity classification task tends to dominate the gradients, leading to suboptimal performance in fine-grained grounding during multi-task optimization. To address this challenge, we propose \\textbf{OmniVL-Guard}, a balanced reinforcement learning framework for omnibus vision-language forgery detection and grounding. Particularly, OmniVL-Guard comprises two core designs: Self-Evolving CoT Generatio and Adaptive Reward Scaling Policy Optimization (ARSPO). {Self-Evolving CoT Generation} synthesizes high-quality reasoning paths, effectively overcoming the cold-start challenge. Building upon this, {Adaptive Reward Scaling Policy Optimization (ARSPO)} dynamically modulates reward scales and task weights, ensuring a balanced joint optimization. Extensive experiments demonstrate that OmniVL-Guard significantly outperforms state-of-the-art methods and exhibits zero-shot robust generalization across out-of-domain scenarios.", "AI": {"tldr": "本文提出了OmniVL-Guard，一种用于统一的视觉语言伪造检测和定位的平衡强化学习框架。", "motivation": "现有伪造检测方法多局限于单模或双模设置，无法有效处理现实世界中常见的文本、图像与视频交织的信息误导。为了填补这一空白，论文旨在开发一个能够应对多种模式交互且同时满足检测和定位需求的统一框架。", "method": "OmniVL-Guard包括两个核心设计：自演进CoT生成和适应性奖励缩放策略优化（ARSPO）。前者合成高质量推理路径，解决冷启动问题；后者动态调节奖励比例和任务权重，确保均衡联合优化。", "result": "实验结果显示，OmniVL-Guard在性能上显著超过现有最佳方法，并表现出跨域零样本鲁棒泛化能力。", "conclusion": "本文通过提出OmniVL-Guard框架解决了伪造检测中的多模式交互和同步任务挑战，证明了其优越性和广泛适用性。"}}
{"id": "2602.10686", "pdf": "https://arxiv.org/pdf/2602.10686", "abs": "https://arxiv.org/abs/2602.10686", "authors": ["Seiko Piotr Yamaguchi", "Andres Mora Vargas", "Till Eisenberg", "Christian Rogon", "Tatsuya Yamamoto", "Shona Inoue", "Christoph Kössl", "Brian Coltin", "Trey Smith", "Jose V. Benavides"], "title": "Free-Flying Crew Cooperative Robots on the ISS: A Joint Review of Astrobee, CIMON, and Int-Ball Operations", "categories": ["cs.RO"], "comment": "Author's version of a manuscript accepted at the 2025 International Conference on Space Robotics (iSpaRo25). (c)IEEE", "summary": "Intra-vehicular free-flying robots are anticipated to support various work in human spaceflight while working side-by-side with astronauts. Such example of robots includes NASA's Astrobee, DLR's CIMON, and JAXA's Int-Ball, which are deployed on the International Space Station. This paper presents the first joint analyses of these robot's shared experiences, co-authored by their development and operation team members. Despite the different origins and design philosophies, the development and operations of these platforms encountered various convergences. Hence, this paper presents a detailed overview of these robots, presenting their objectives, design, and onboard operations. Hence, joint lessons learned across the lifecycle are presented, from design to on-orbit operations. These lessons learned are anticipated to serve for future development and research as design recommendations.", "AI": {"tldr": "本文对在国际空间站上运行的自由飞行机器人Astrobee、CIMON和Int-Ball进行了联合分析，总结了它们的设计理念与操作经验。", "motivation": "旨在通过比较这三个不同背景和设计理念的机器人的共性问题来为未来的航天器开发提供参考建议。", "method": "由各自的研发团队成员共同编写，对这些机器人进行详细概述，并从设计到在轨操作阶段提出联合的经验教训。", "result": "提出了关于自由飞行机器人设计与操作的若干推荐意见。", "conclusion": "这些经验教训对于未来空间技术的发展和研究具有重要的借鉴意义。"}}
{"id": "2602.10684", "pdf": "https://arxiv.org/pdf/2602.10684", "abs": "https://arxiv.org/abs/2602.10684", "authors": ["Zhuoyang Li", "Yanlai Wu", "Yao Li", "Xinning Gui", "Yuhan Luo"], "title": "Privacy Control in Conversational LLM Platforms: A Walkthrough Study", "categories": ["cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly integrated into daily life through conversational interfaces, processing user data via natural language inputs and exhibiting advanced reasoning capabilities, which raises new concerns about user control over privacy. While much research has focused on potential privacy risks, less attention has been paid to the data control mechanisms these platforms provide. This study examines six conversational LLM platforms, analyzing how they define and implement features for users to access, edit, delete, and share data. Our analysis reveals an emerging paradigm of data control in conversational LLM platforms, where user data is generated and derived through interaction itself, natural language enables flexible yet often ambiguous control, and multi-user interactions with shared data raise questions of co-ownership and governance. Based on these findings, we offer practical insights for platform developers, policymakers, and researchers to design more effective and usable privacy controls in LLM-powered conversational interactions.", "AI": {"tldr": "研究探讨了六个对话式大语言模型平台的数据控制机制，分析其用户数据的访问、编辑、删除和分享功能。", "motivation": "随着大型语言模型通过自然语言接口融入日常生活，隐私保护问题日益突出。该研究旨在填补现有文献中关于这些平台提供的数据控制机制的研究空白。", "method": "本研究选取了六个对话式大语言模型平台进行分析，评估其定义和实现用户数据控制特征的方法。", "result": "研究表明，在这些平台上生成并衍生的数据通过交互过程产生，自然语言赋予了灵活但常具歧义的控制方式。此外，多用户之间的共享互动引发了共同所有权与管理的问题。", "conclusion": "基于研究发现，作者为平台开发者、政策制定者和研究人员提供了设计更有效及易用的隐私保护机制的实用见解。"}}
{"id": "2602.10675", "pdf": "https://arxiv.org/pdf/2602.10675", "abs": "https://arxiv.org/abs/2602.10675", "authors": ["Junhua Liu", "Zhangcheng Wang", "Zhike Han", "Ningli Wang", "Guotao Liang", "Kun Kuang"], "title": "TwiFF (Think With Future Frames): A Large-Scale Dataset for Dynamic Visual Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "preprint", "summary": "Visual Chain-of-Thought (VCoT) has emerged as a promising paradigm for enhancing multimodal reasoning by integrating visual perception into intermediate reasoning steps. However, existing VCoT approaches are largely confined to static scenarios and struggle to capture the temporal dynamics essential for tasks such as instruction, prediction, and camera motion. To bridge this gap, we propose TwiFF-2.7M, the first large-scale, temporally grounded VCoT dataset derived from $2.7$ million video clips, explicitly designed for dynamic visual question and answer. Accompanying this, we introduce TwiFF-Bench, a high-quality evaluation benchmark of $1,078$ samples that assesses both the plausibility of reasoning trajectories and the correctness of final answers in open-ended dynamic settings. Building on these foundations, we propose the TwiFF model, a unified modal that synergistically leverages pre-trained video generation and image comprehension capabilities to produce temporally coherent visual reasoning cues-iteratively generating future action frames and textual reasoning. Extensive experiments demonstrate that TwiFF significantly outperforms existing VCoT methods and Textual Chain-of-Thought baselines on dynamic reasoning tasks, which fully validates the effectiveness for visual question answering in dynamic scenarios. Our code and data is available at https://github.com/LiuJunhua02/TwiFF.", "AI": {"tldr": "开发了一个大规模的数据集和模型，用于动态视觉推理任务", "motivation": "现有的视觉链式思考方法主要局限于静态场景，在处理指令、预测和相机运动等需要捕捉时间动态的任务上存在困难", "method": "提出了TwiFF-2.7M数据集及评估基准TwiFF-Bench，并开发了结合预训练视频生成与图像理解能力的TwiFF模型，用于产生一致且合理的视觉推理线索", "result": "实验表明，该方法在动态推理任务上显著优于现有方法和基线模型", "conclusion": "验证了所提出的方法在动态场景下进行视觉问答的有效性"}}
{"id": "2602.10666", "pdf": "https://arxiv.org/pdf/2602.10666", "abs": "https://arxiv.org/abs/2602.10666", "authors": ["Riccardo Miccini", "Clément Laroche", "Tobias Piechowiak", "Xenofon Fafoutis", "Luca Pezzarossa"], "title": "From Diet to Free Lunch: Estimating Auxiliary Signal Properties using Dynamic Pruning Masks in Speech Enhancement Networks", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Accepted for publication at the 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "summary": "Speech Enhancement (SE) in audio devices is often supported by auxiliary modules for Voice Activity Detection (VAD), SNR estimation, or Acoustic Scene Classification to ensure robust context-aware behavior and seamless user experience. Just like SE, these tasks often employ deep learning; however, deploying additional models on-device is computationally impractical, whereas cloud-based inference would introduce additional latency and compromise privacy. Prior work on SE employed Dynamic Channel Pruning (DynCP) to reduce computation by adaptively disabling specific channels based on the current input. In this work, we investigate whether useful signal properties can be estimated from these internal pruning masks, thus removing the need for separate models. We show that simple, interpretable predictors achieve up to 93% accuracy on VAD, 84% on noise classification, and an R2 of 0.86 on F0 estimation. With binary masks, predictions reduce to weighted sums, inducing negligible overhead. Our contribution is twofold: on one hand, we examine the emergent behavior of DynCP models through the lens of downstream prediction tasks, to reveal what they are learning; on the other, we repurpose and re-propose DynCP as a holistic solution for efficient SE and simultaneous estimation of signal properties.", "AI": {"tldr": "通过动态修剪掩码估计辅助信号属性，以减少计算开销并简化语音增强网络。", "motivation": "在音频设备中实现语音增强时需要辅助模块（如VAD、噪声比估计等），但单独部署这些模型会增加计算负担。云推理则引入延迟和隐私问题。因此探索从动态修剪掩码中提取有用信号信息的方法，以减少额外计算开销。", "method": "利用动态通道剪枝技术，在语音增强网络内部生成的修剪掩码上训练简单可解释的预测器来估计信号属性如VAD、噪声分类及F0值。", "result": "实验表明提出的模型在VAD任务中达到93%准确率，噪声分类84%，且F0估计R2得分为0.86。这些预测基于二元掩码进行加权求和，几乎不增加额外计算负担。", "conclusion": "该工作揭示了动态修剪技术的学习特性，并提出了一种高效语音增强方法，同时实现了信号属性的估测，避免了部署多个辅助模型的需求。"}}
{"id": "2602.10663", "pdf": "https://arxiv.org/pdf/2602.10663", "abs": "https://arxiv.org/abs/2602.10663", "authors": ["Arash Fatehi", "David Unnersjö-Jess", "Linus Butt", "Noémie Moreau", "Thomas Benzing", "Katarzyna Bozek"], "title": "AMAP-APP: Efficient Segmentation and Morphometry Quantification of Fluorescent Microscopy Images of Podocytes", "categories": ["cs.CV"], "comment": null, "summary": "Background: Automated podocyte foot process quantification is vital for kidney research, but the established \"Automatic Morphological Analysis of Podocytes\" (AMAP) method is hindered by high computational demands, a lack of a user interface, and Linux dependency. We developed AMAP-APP, a cross-platform desktop application designed to overcome these barriers. Methods: AMAP-APP optimizes efficiency by replacing intensive instance segmentation with classic image processing while retaining the original semantic segmentation model. It introduces a refined Region of Interest (ROI) algorithm to improve precision. Validation involved 365 mouse and human images (STED and confocal), benchmarking performance against the original AMAP via Pearson correlation and Two One-Sided T-tests (TOST). Results: AMAP-APP achieved a 147-fold increase in processing speed on consumer hardware. Morphometric outputs (area, perimeter, circularity, and slit diaphragm density) showed high correlation (r>0.90) and statistical equivalence (TOST P<0.05) to the original method. Additionally, the new ROI algorithm demonstrated superior accuracy compared to the original, showing reduced deviation from manual delineations. Conclusion: AMAP-APP democratizes deep learning-based podocyte morphometry. By eliminating the need for high-performance computing clusters and providing a user-friendly interface for Windows, macOS, and Linux, it enables widespread adoption in nephrology research and potential clinical diagnostics.", "AI": {"tldr": "AMAP-APP是一款高效的荧光显微镜图像中的足突细胞分割和形态定量分析软件。", "motivation": "现有的自动足突细胞脚突量化方法受到计算需求高、无用户界面及操作系统依赖等问题的限制，作者开发了跨平台桌面应用AMAP-APP来克服这些问题。", "method": "该研究通过优化效率，使用经典图像处理代替耗时的实例分割，并保留原始语义分割模型。引入改进的ROI算法以提高精度。验证方法包括性能测试和统计分析。", "result": "与原方法相比，AMAP-APP在消费级硬件上的处理速度提高了147倍。形态学输出显示高相关性（r>0.90）并通过TOST检验证明统计等效性（P<0.05）。新的ROI算法表现出比原始方法更高的准确性。", "conclusion": "AMAP-APP使得基于深度学习的足突细胞形态定量分析更加民主化，无需高性能计算集群且提供跨平台用户界面，促进了肾脏研究和潜在临床诊断的广泛应用。"}}
{"id": "2602.10662", "pdf": "https://arxiv.org/pdf/2602.10662", "abs": "https://arxiv.org/abs/2602.10662", "authors": ["Tiandong Shi", "Ling Zhao", "Ji Qi", "Jiayi Ma", "Chengli Peng"], "title": "Dynamic Frequency Modulation for Controllable Text-driven Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "The success of text-guided diffusion models has established a new image generation paradigm driven by the iterative refinement of text prompts. However, modifying the original text prompt to achieve the expected semantic adjustments often results in unintended global structure changes that disrupt user intent. Existing methods rely on empirical feature map selection for intervention, whose performance heavily depends on appropriate selection, leading to suboptimal stability. This paper tries to solve the aforementioned problem from a frequency perspective and analyzes the impact of the frequency spectrum of noisy latent variables on the hierarchical emergence of the structure framework and fine-grained textures during the generation process. We find that lower-frequency components are primarily responsible for establishing the structure framework in the early generation stage. Their influence diminishes over time, giving way to higher-frequency components that synthesize fine-grained textures. In light of this, we propose a training-free frequency modulation method utilizing a frequency-dependent weighting function with dynamic decay. This method maintains the structure framework consistency while permitting targeted semantic modifications. By directly manipulating the noisy latent variable, the proposed method avoids the empirical selection of internal feature maps. Extensive experiments demonstrate that the proposed method significantly outperforms current state-of-the-art methods, achieving an effective balance between preserving structure and enabling semantic updates.", "AI": {"tldr": "本文提出了一种基于频率视角的动态频谱调制方法，用于可控文本驱动图像生成。", "motivation": "现有的文本引导扩散模型在调整原始文本提示时容易导致全局结构变化，影响用户意图。现有干预方法依赖于特征图的选择，性能不稳定。", "method": "本文从频率角度分析了噪声隐变量的频谱对生成过程的影响，并提出了一种无需训练的动态频谱调制方法，通过使用随时间衰减的频率依赖加权函数来保持结构框架的一致性并允许语义修改。", "result": "实验结果表明所提方法在保持图像结构的同时实现了有效的语义更新，显著优于现有最佳方法。", "conclusion": "本文提出的方法解决了文本引导扩散模型中调整原始提示时的结构不一致问题，并且能够在生成过程中实现更精准的可控性。"}}
{"id": "2602.10660", "pdf": "https://arxiv.org/pdf/2602.10660", "abs": "https://arxiv.org/abs/2602.10660", "authors": ["Kiarash Ghasemzadeh", "Sedigheh Dehghani"], "title": "AurigaNet: A Real-Time Multi-Task Network for Enhanced Urban Driving Perception", "categories": ["cs.CV"], "comment": null, "summary": "Self-driving cars hold significant potential to reduce traffic accidents, alleviate congestion, and enhance urban mobility. However, developing reliable AI systems for autonomous vehicles remains a substantial challenge. Over the past decade, multi-task learning has emerged as a powerful approach to address complex problems in driving perception. Multi-task networks offer several advantages, including increased computational efficiency, real-time processing capabilities, optimized resource utilization, and improved generalization. In this study, we present AurigaNet, an advanced multi-task network architecture designed to push the boundaries of autonomous driving perception. AurigaNet integrates three critical tasks: object detection, lane detection, and drivable area instance segmentation. The system is trained and evaluated using the BDD100K dataset, renowned for its diversity in driving conditions. Key innovations of AurigaNet include its end-to-end instance segmentation capability, which significantly enhances both accuracy and efficiency in path estimation for autonomous vehicles. Experimental results demonstrate that AurigaNet achieves an 85.2% IoU in drivable area segmentation, outperforming its closest competitor by 0.7%. In lane detection, AurigaNet achieves a remarkable 60.8% IoU, surpassing other models by more than 30%. Furthermore, the network achieves an mAP@0.5:0.95 of 47.6% in traffic object detection, exceeding the next leading model by 2.9%. Additionally, we validate the practical feasibility of AurigaNet by deploying it on embedded devices such as the Jetson Orin NX, where it demonstrates competitive real-time performance. These results underscore AurigaNet's potential as a robust and efficient solution for autonomous driving perception systems. The code can be found here https://github.com/KiaRational/AurigaNet.", "AI": {"tldr": "AurigaNet是一种用于增强城市驾驶感知的实时多任务网络。", "motivation": "自动驾驶汽车有潜力减少交通事故，缓解拥堵并提高城市的交通流动性。然而，开发可靠的自主车辆AI系统仍然是一个巨大的挑战。在过去的十年中，多任务学习已经成为解决驾驶感知复杂问题的一种强有力的方法。", "method": "该论文提出了AurigaNet，一种先进的多任务网络架构，集成了目标检测、车道检测和可行驶区域实例分割三个关键任务。通过BDD100K数据集进行训练和评估，展示了其在路径估计方面的准确性和效率的提升。", "result": "实验结果表明，在可行驶区域分割方面，AurigaNet达到了85.2%的IoU，比最接近的竞争者高出0.7%，车道检测方面达到60.8%的IoU，超过其他模型30%以上。在交通目标检测中，mAP@0.5:0.95为47.6%，超过下一个领先模型2.9%。", "conclusion": "AurigaNet展示了其作为自动驾驶感知系统强大且高效的解决方案的潜力，具有优秀的实时性能。"}}
{"id": "2602.10659", "pdf": "https://arxiv.org/pdf/2602.10659", "abs": "https://arxiv.org/abs/2602.10659", "authors": ["Yin Wang", "Ziyao Zhang", "Zhiying Leng", "Haitian Liu", "Frederick W. B. Li", "Mu Li", "Xiaohui Liang"], "title": "Multimodal Priors-Augmented Text-Driven 3D Human-Object Interaction Generation", "categories": ["cs.CV"], "comment": null, "summary": "We address the challenging task of text-driven 3D human-object interaction (HOI) motion generation. Existing methods primarily rely on a direct text-to-HOI mapping, which suffers from three key limitations due to the significant cross-modality gap: (Q1) sub-optimal human motion, (Q2) unnatural object motion, and (Q3) weak interaction between humans and objects. To address these challenges, we propose MP-HOI, a novel framework grounded in four core insights: (1) Multimodal Data Priors: We leverage multimodal data (text, image, pose/object) from large multimodal models as priors to guide HOI generation, which tackles Q1 and Q2 in data modeling. (2) Enhanced Object Representation: We improve existing object representations by incorporating geometric keypoints, contact features, and dynamic properties, enabling expressive object representations, which tackles Q2 in data representation. (3) Multimodal-Aware Mixture-of-Experts (MoE) Model: We propose a modality-aware MoE model for effective multimodal feature fusion paradigm, which tackles Q1 and Q2 in feature fusion. (4) Cascaded Diffusion with Interaction Supervision: We design a cascaded diffusion framework that progressively refines human-object interaction features under dedicated supervision, which tackles Q3 in interaction refinement. Comprehensive experiments demonstrate that MP-HOI outperforms existing approaches in generating high-fidelity and fine-grained HOI motions.", "AI": {"tldr": "本文提出了一种基于多模态先验的文本驱动三维人体与物体交互生成框架，以解决现有方法在处理跨模态差异时存在的问题。", "motivation": "现有方法依赖于直接从文本到HOI映射，在面对显著的跨模态差距时存在不理想的人体运动、不自然的物体运动以及人和物之间弱互动的问题。本文旨在通过引入多模态先验来解决这些挑战。", "method": "MP-HOI框架包括四个核心点：利用大型多模态模型中的文本、图像、姿态/对象数据作为先验来指导HOI生成；改进现有物体表示以增强表达性；设计一种对模式感知的混合专家模型进行有效的多模态特征融合；以及开发一个分层扩散框架，通过专门监督逐步细化人与物之间的互动。", "result": "实验表明，MP-HOI在生成高保真度和细粒度的HOI运动方面优于现有方法。", "conclusion": "本文提出的MP-HOI框架能够更有效地解决文本驱动三维人体与物体交互生成中存在的问题，并显著提高了生成结果的质量。"}}
{"id": "2602.10656", "pdf": "https://arxiv.org/pdf/2602.10656", "abs": "https://arxiv.org/abs/2602.10656", "authors": ["Jingru Lin", "Chen Zhang", "Tianrui Wang", "Haizhou Li"], "title": "AudioRAG: A Challenging Benchmark for Audio Reasoning and Information Retrieval", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by Audio-AAAI", "summary": "Due to recent advancements in Large Audio-Language Models (LALMs) that demonstrate remarkable performance across a range of sound-, speech- and music-related tasks, there is a growing interest in proposing benchmarks to assess these models. Existing benchmarks generally focus only on reasoning with internal knowledge, neglecting real-world scenarios that require external information grounding. To bridge this gap, we introduce AudioRAG, a novel benchmark designed to evaluate audio-based reasoning augmented by information retrieval in realistic web environments. This benchmark comprises both LLM-generated and manually curated question-answer pairs. Our evaluations reveal that even the state-of-the-art LALMs struggle to answer these questions. We therefore propose an agentic pipeline that integrates audio reasoning with retrieval-augmented generation, providing a stronger baseline for future research.", "AI": {"tldr": "提出AudioRAG，一个评估音频推理和信息检索基准。", "motivation": "现有基准测试忽视了需要外部信息的实际场景，因此引入AudioRAG以填补这一空白。", "method": "构建由LLM生成和人工策划的问题答案对组成的新型基准测试。并建议整合音频推理与增强生成的代理管道。", "result": "评估表明最先进的LALMs难以回答这些问题。", "conclusion": "提出AudioRAG作为未来研究的更强基线，以改进音频推理和信息检索能力。"}}
{"id": "2602.10655", "pdf": "https://arxiv.org/pdf/2602.10655", "abs": "https://arxiv.org/abs/2602.10655", "authors": ["Muhammad Yousaf", "Aitor Arrieta", "Shaukat Ali", "Paolo Arcaini", "Shuai Wang"], "title": "Assessing Vision-Language Models for Perception in Autonomous Underwater Robotic Software", "categories": ["cs.SE", "cs.RO"], "comment": "10 pages, 5 figures, submitted to ICST 2026", "summary": "Autonomous Underwater Robots (AURs) operate in challenging underwater environments, including low visibility and harsh water conditions. Such conditions present challenges for software engineers developing perception modules for the AUR software. To successfully carry out these tasks, deep learning has been incorporated into the AUR software to support its operations. However, the unique challenges of underwater environments pose difficulties for deep learning models, which often rely on labeled data that is scarce and noisy. This may undermine the trustworthiness of AUR software that relies on perception modules. Vision-Language Models (VLMs) offer promising solutions for AUR software as they generalize to unseen objects and remain robust in noisy conditions by inferring information from contextual cues. Despite this potential, their performance and uncertainty in underwater environments remain understudied from a software engineering perspective. Motivated by the needs of an industrial partner in assurance and risk management for maritime systems to assess the potential use of VLMs in this context, we present an empirical evaluation of VLM-based perception modules within the AUR software. We assess their ability to detect underwater trash by computing performance, uncertainty, and their relationship, to enable software engineers to select appropriate VLMs for their AUR software.", "AI": {"tldr": "评估视觉语言模型在自主水下机器人软件中的感知模块的性能和不确定性，以帮助软件工程师选择合适的模型。", "motivation": "由于缺乏标记数据以及噪声环境下的挑战，传统的深度学习方法难以满足AUR软件的需求，而视觉语言模型提供了一种可能的解决方案，但其在水下条件下的表现尚不明确，因此需要进行研究评估。", "method": "通过计算性能和不确定性来评价基于视觉语言模型的感知模块的能力，特别关注于检测水下垃圾的任务。", "result": "结果包括了对模型性能、不确定性的评估以及二者之间的关系分析。", "conclusion": "研究表明，在特定条件下使用视觉语言模型可以提高AUR软件中感知任务的效果，并为未来的开发提供了有价值的见解。"}}
{"id": "2602.10639", "pdf": "https://arxiv.org/pdf/2602.10639", "abs": "https://arxiv.org/abs/2602.10639", "authors": ["Yuxin Cao", "Wei Song", "Shangzhi Xu", "Jingling Xue", "Jin Song Dong"], "title": "VideoSTF: Stress-Testing Output Repetition in Video Large Language Models", "categories": ["cs.CV", "cs.CR", "cs.MM"], "comment": null, "summary": "Video Large Language Models (VideoLLMs) have recently achieved strong performance in video understanding tasks. However, we identify a previously underexplored generation failure: severe output repetition, where models degenerate into self-reinforcing loops of repeated phrases or sentences. This failure mode is not captured by existing VideoLLM benchmarks, which focus primarily on task accuracy and factual correctness. We introduce VideoSTF, the first framework for systematically measuring and stress-testing output repetition in VideoLLMs. VideoSTF formalizes repetition using three complementary n-gram-based metrics and provides a standardized testbed of 10,000 diverse videos together with a library of controlled temporal transformations. Using VideoSTF, we conduct pervasive testing, temporal stress testing, and adversarial exploitation across 10 advanced VideoLLMs. We find that output repetition is widespread and, critically, highly sensitive to temporal perturbations of video inputs. Moreover, we show that simple temporal transformations can efficiently induce repetitive degeneration in a black-box setting, exposing output repetition as an exploitable security vulnerability. Our results reveal output repetition as a fundamental stability issue in modern VideoLLMs and motivate stability-aware evaluation for video-language systems. Our evaluation code and scripts are available at: https://github.com/yuxincao22/VideoSTF_benchmark.", "AI": {"tldr": "本文提出VideoSTF框架，用于评估视频大语言模型（VideoLLMs）在输出重复问题上的性能。", "motivation": "现有的VideoLLM基准测试主要关注任务准确性和事实正确性，而忽视了严重的输出重复现象。这种模式会导致模型陷入自我强化的重复循环中。", "method": "通过使用三个基于n-gram的互补度量标准和10,000个多样化视频的数据集进行系统化测量，并引入了一系列可控的时间变换来测试VideoLLM的输出重复问题。", "result": "结果显示，输出重复现象在各种高级VideoLLM中普遍存在且对时间扰动高度敏感。简单的时间转换可以有效地诱导黑盒模型进入重复循环状态。", "conclusion": "研究揭示了输出重复作为现代视频大语言模型的基本稳定性问题，并强调需要进行稳定的评估方法来改进未来的研究和应用。"}}
{"id": "2602.10635", "pdf": "https://arxiv.org/pdf/2602.10635", "abs": "https://arxiv.org/abs/2602.10635", "authors": ["Keane Ong", "Sabri Boughorbel", "Luwei Xiao", "Chanakya Ekbote", "Wei Dai", "Ao Qu", "Jingyao Wu", "Rui Mao", "Ehsan Hoque", "Erik Cambria", "Gianmarco Mengaldo", "Paul Pu Liang"], "title": "OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different heterogeneous behavioral data. To address this gap, we introduce Heterogeneity-Aware Relative Policy Optimization (HARPO), an RL method that balances leaning across heterogeneous tasks and samples. This is achieved by modulating advantages to ensure that no single task or sample carries disproportionate influence during policy optimization. Using HARPO, we develop and release Omnisapiens-7B 2.0, a foundation model for social behavior processing. Relative to existing behavioral foundation models, Omnisapiens-7B 2.0 achieves the strongest performance across behavioral tasks, with gains of up to +16.85% and +9.37% on multitask and held-out settings respectively, while producing more explicit and robust reasoning traces. We also validate HARPO against recent RL methods, where it achieves the most consistently strong performance across behavioral tasks.", "AI": {"tldr": "开发一种名为OmniSapiens的社交行为处理基础模型，通过HARPO方法解决多任务学习中的异质性问题。", "motivation": "现有方法通常独立建模人类行为维度（如情感、认知或社会属性），增加了训练成本并限制了跨行为环境的一般化。本文旨在解决这种局限，引入一种新方法来优化不同异构任务和样本的学习平衡。", "method": "提出了一种基于相对策略优化的HARPO强化学习方法，通过调整优势值以确保在策略优化期间没有单一任务或样本占有过分影响。", "result": "Omnisapiens-7B 2.0模型相较于现有行为基础模型，在多任务和保留设置中表现出更强性能，分别提高了16.85%和9.37%，并且生成了更明确、稳健的推理轨迹。", "conclusion": "HARPO方法在不同行为任务上的表现优于近期强化学习方法。"}}
{"id": "2602.10632", "pdf": "https://arxiv.org/pdf/2602.10632", "abs": "https://arxiv.org/abs/2602.10632", "authors": ["Suyash Mishra"], "title": "The Neurosymbolic Frontier of Nonuniform Ellipticity: Formalizing Sharp Schauder Theory via Topos-Theoretic Reasoning Models", "categories": ["cs.SC", "cs.AI"], "comment": null, "summary": "This white paper presents a critical synthesis of the recent breakthrough in nonuniformly elliptic regularity theory and the burgeoning field of neurosymbolic large reasoning models (LRMs). We explore the resolution of the long-standing sharp growth rate conjecture in Schauder theory, achieved by Cristiana De Filippis and Giuseppe Mingione, which identifies the exact threshold $q/p < 1 + α/n$ for gradient Hölder continuity. Central to this mathematical achievement is the ``ghost equation'' methodology, a sophisticated auxiliary derivation that bypasses the non-differentiability of classical Euler-Lagrange systems. We propose that the next era of mathematical discovery lies in the integration of these pure analytical constructs with LRMs grounded in topos theory and formal verification frameworks such as Safe and Typed Chain-of-Thought (PC-CoT). By modeling the reasoning process as a categorical colimit in a slice topos, we demonstrate how LRMs can autonomously navigate the ``Dark Side'' of the calculus of variations, providing machine-checkable proofs for regularity bounds in complex, multi-phase physical systems.", "AI": {"tldr": "本文探讨了非均匀椭圆正则性理论中的突破进展，并提出将纯分析构造与基于托普斯理论的大型推理模型(LRMs)结合，以解决复杂的多相物理系统的正则性边界问题。", "motivation": "为了在复杂系统中实现更精确和机器检查证明的数学发现，本文提出了通过融合尖端数学成果（如Schauder理论中的鬼方程方法）与基于托普斯理论的大型推理模型的方法论框架。", "method": "通过将LRMs建模为切片托普斯中的范畴同极限，并采用Safe和Typed Chain-of-Thought(PC-CoT)等形式验证框架，来自主地探索解析变分法难题。", "result": "提出了能够解决复杂系统正则性问题的新型数学模型，该模型具备机器可检查证明的能力。", "conclusion": "通过将尖端纯分析构造与基于托普斯理论的大型推理模型结合，我们开辟了下一代数学发现的可能性路径。"}}
{"id": "2602.10630", "pdf": "https://arxiv.org/pdf/2602.10630", "abs": "https://arxiv.org/abs/2602.10630", "authors": ["Yan Wang", "Shijie Zhao", "Junlin Li", "Li Zhang"], "title": "Eliminating VAE for Fast and High-Resolution Generative Detail Restoration", "categories": ["cs.CV"], "comment": "Accepted by ICLR 2026", "summary": "Diffusion models have attained remarkable breakthroughs in the real-world super-resolution (SR) task, albeit at slow inference and high demand on devices. To accelerate inference, recent works like GenDR adopt step distillation to minimize the step number to one. However, the memory boundary still restricts the maximum processing size, necessitating tile-by-tile restoration of high-resolution images. Through profiling the pipeline, we pinpoint that the variational auto-encoder (VAE) is the bottleneck of latency and memory. To completely solve the problem, we leverage pixel-(un)shuffle operations to eliminate the VAE, reversing the latent-based GenDR to pixel-space GenDR-Pix. However, upscale with x8 pixelshuffle may induce artifacts of repeated patterns. To alleviate the distortion, we propose a multi-stage adversarial distillation to progressively remove the encoder and decoder. Specifically, we utilize generative features from the previous stage models to guide adversarial discrimination. Moreover, we propose random padding to augment generative features and avoid discriminator collapse. We also introduce a masked Fourier space loss to penalize the outliers of amplitude. To improve inference performance, we empirically integrate a padding-based self-ensemble with classifier-free guidance to improve inference scaling. Experimental results show that GenDR-Pix performs 2.8x acceleration and 60% memory-saving compared to GenDR with negligible visual degradation, surpassing other one-step diffusion SR. Against all odds, GenDR-Pix can restore 4K image in only 1 second and 6GB.", "AI": {"tldr": "本文提出了一种新的高分辨率图像生成细节恢复方法GenDR-Pix，通过消除VAE来加速推理过程并降低内存需求。", "motivation": "在实际应用中，虽然扩散模型已经取得了显著的超分辨成果，但其推理速度慢且设备要求高。现有的解决方案如GenDR尽管尝试减少步骤数以加快推理，仍然受限于内存边界问题，导致必须分块处理高分辨率图像。通过分析流水线，研究者发现VAE是延迟和内存的主要瓶颈。", "method": "本文提出了一种新的方法GenDR-Pix，它利用像素重组操作来消除VAE，并引入多阶段对抗蒸馏逐步去除编码器和解码器以缓解扭曲问题；还采用了随机填充以增强生成特征并避免鉴别器崩溃。此外，提出了掩膜傅里叶空间损失惩罚振幅异常值，结合基于填充的自我集成以及无分类器指导来提高推理性能。", "result": "实验结果显示，GenDR-Pix比原版GenDR快2.8倍且节省60%内存，在视觉质量上仅有微小退化。此外，它能够以1秒和6GB内存在4K图像恢复中表现出色。", "conclusion": "通过消除VAE并采用多种改进策略，本文提出的方法在加速推理、减少内存消耗以及保持高质量生成效果方面取得了显著成果。"}}
{"id": "2602.10625", "pdf": "https://arxiv.org/pdf/2602.10625", "abs": "https://arxiv.org/abs/2602.10625", "authors": ["Nanxu Gong", "Haotian Li", "Sixun Dong", "Jianxun Lian", "Yanjie Fu", "Xing Xie"], "title": "To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform non-reasoning models and sometimes perform worse. A fine-grained analysis reveals three insights. First, slow thinking collapses: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, moderate and adaptive reasoning benefits performance: constraining reasoning length mitigates failure, while distinct success patterns demonstrate the necessity of dynamic adaptation. Third, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. We also design two intervention approaches: Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention to further verify and mitigate the problems. With all results, our study highlights the advancement of LRMs in formal reasoning (e.g., math, code) cannot be fully transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods.", "AI": {"tldr": "本论文评估了大型推理模型在理论思维任务中的性能，对比分析推理模型与非推理模型的表现。", "motivation": "研究探索大型推理模型是否能够将数学和编码领域的逐步推理能力转移到社会认知技能上。", "method": "通过三个代表性的理论思维基准测试九个高级语言模型，并比较推理模型和非推理模型的性能。进一步设计了慢转快（S2F）自适应推理和思考匹配预防（T2M）两种干预方法验证问题并减轻负面影响。", "result": "研究发现推理模型不一致地优于非推理模型，且在某些情况下表现更差；分析揭示了缓慢思维崩溃、适度与动态适应的益处以及选项匹配捷径的问题。", "conclusion": "大型推理模型虽然在形式推理（如数学、编码）方面取得了进展，但无法完全转移到理论思维任务上。实现稳健的社会认知需要超越现有方法的独特能力发展"}}
{"id": "2602.10624", "pdf": "https://arxiv.org/pdf/2602.10624", "abs": "https://arxiv.org/abs/2602.10624", "authors": ["Siyuan Yan", "Xieji Li", "Dan Mo", "Philipp Tschandl", "Yiwen Jiang", "Zhonghua Wang", "Ming Hu", "Lie Ju", "Cristina Vico-Alonso", "Yizhen Zheng", "Jiahe Liu", "Juexiao Zhou", "Camilla Chello", "Jen G. Cheung", "Julien Anriot", "Luc Thomas", "Clare Primiero", "Gin Tan", "Aik Beng Ng", "Simon See", "Xiaoying Tang", "Albert Ip", "Xiaoyang Liao", "Adrian Bowling", "Martin Haskett", "et al. (6 additional authors not shown)"], "title": "A Vision-Language Foundation Model for Zero-shot Clinical Collaboration and Automated Concept Discovery in Dermatology", "categories": ["cs.CV", "cs.AI"], "comment": "reports", "summary": "Medical foundation models have shown promise in controlled benchmarks, yet widespread deployment remains hindered by reliance on task-specific fine-tuning. Here, we introduce DermFM-Zero, a dermatology vision-language foundation model trained via masked latent modelling and contrastive learning on over 4 million multimodal data points. We evaluated DermFM-Zero across 20 benchmarks spanning zero-shot diagnosis and multimodal retrieval, achieving state-of-the-art performance without task-specific adaptation. We further evaluated its zero-shot capabilities in three multinational reader studies involving over 1,100 clinicians. In primary care settings, AI assistance enabled general practitioners to nearly double their differential diagnostic accuracy across 98 skin conditions. In specialist settings, the model significantly outperformed board-certified dermatologists in multimodal skin cancer assessment. In collaborative workflows, AI assistance enabled non-experts to surpass unassisted experts while improving management appropriateness. Finally, we show that DermFM-Zero's latent representations are interpretable: sparse autoencoders unsupervisedly disentangle clinically meaningful concepts that outperform predefined-vocabulary approaches and enable targeted suppression of artifact-induced biases, enhancing robustness without retraining. These findings demonstrate that a foundation model can provide effective, safe, and transparent zero-shot clinical decision support.", "AI": {"tldr": "介绍了一种用于皮肤病学领域的零样本临床协作和自动概念发现的视觉语言基础模型DermFM-Zero。", "motivation": "医疗基础模型在控制基准测试中显示出潜力，但广泛部署受到任务特定微调依赖性的限制。引入DermFM-Zero以解决这些问题，并提高临床决策支持的有效性、安全性和透明度。", "method": "通过掩码潜变量建模和对比学习训练DermFM-Zero，使用超过400万个多模式数据点进行模型训练。", "result": "在20个基准测试中实现了零样本诊断和多模式检索的最先进性能。AI辅助提高了全科医生对98种皮肤疾病的鉴别诊断准确性，并且在专家设置下超越了认证皮肤病学家。", "conclusion": "DermFM-Zero展示了作为有效、安全和透明零样本临床决策支持系统的潜力，证明基础模型可以在医学领域提供强大的帮助而不需特定任务调整。"}}
{"id": "2602.10623", "pdf": "https://arxiv.org/pdf/2602.10623", "abs": "https://arxiv.org/abs/2602.10623", "authors": ["Zhibin Duan", "Guowei Rong", "Zhuo Li", "Bo Chen", "Mingyuan Zhou", "Dandan Guo"], "title": "Mitigating Reward Hacking in RLHF via Bayesian Non-negative Reward Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reward models learned from human preferences are central to aligning large language models (LLMs) via reinforcement learning from human feedback, yet they are often vulnerable to reward hacking due to noisy annotations and systematic biases such as response length or style. We propose Bayesian Non-Negative Reward Model (BNRM), a principled reward modeling framework that integrates non-negative factor analysis into Bradley-Terry (BT) preference model. BNRM represents rewards through a sparse, non-negative latent factor generative process that operates at two complementary levels: instance-specific latent variables induce disentangled reward representations, while sparsity over global latent factors acts as an implicit debiasing mechanism that suppresses spurious correlations. Together, this disentanglement-then-debiasing structure enables robust uncertainty-aware reward learning. To scale BNRM to modern LLMs, we develop an amortized variational inference network conditioned on deep model representations, allowing efficient end-to-end training. Extensive empirical results demonstrate that BNRM substantially mitigates reward over-optimization, improves robustness under distribution shifts, and yields more interpretable reward decompositions than strong baselines.", "AI": {"tldr": "提出了一种基于贝叶斯非负奖励模型（BNRM）的方法，旨在减轻大规模语言模型通过人类反馈强化学习过程中的奖励欺骗问题。", "motivation": "由于人类偏好标注中存在噪声和系统偏差，导致从人类偏好训练得到的奖励模型容易受到奖励欺诈的影响。因此提出了这种方法来增强奖励模型的鲁棒性。", "method": "将非负因子分析集成到Bradley-Terry（BT）偏好模型中，引入了贝叶斯非负奖励模型（BNRM）。该方法通过稀疏、非负隐变量生成过程进行奖励表示，并开发了一种基于深度模型表示的变分推理网络。", "result": "实验结果表明，BNRM能够大幅减轻奖励过优化问题，提高在分布偏移下的鲁棒性，并产生比基准更强的结果解释。", "conclusion": "通过结合非负因子分析和变分推理网络的方法，可以更有效地缓解大规模语言模型中的奖励欺诈问题。"}}
{"id": "2602.10619", "pdf": "https://arxiv.org/pdf/2602.10619", "abs": "https://arxiv.org/abs/2602.10619", "authors": ["Guangjing Yang", "ZhangYuan Yu", "Ziyuan Qin", "Xinyuan Song", "Huahui Yi", "Qingbo Kang", "Jun Gao", "Yiyue Li", "Chenlin Du", "Qicheng Lao"], "title": "Improving Medical Visual Reinforcement Fine-Tuning via Perception and Reasoning Augmentation", "categories": ["cs.CV"], "comment": "CPAL 2026", "summary": "While recent advances in Reinforcement Fine-Tuning (RFT) have shown that rule-based reward schemes can enable effective post-training for large language models, their extension to cross-modal, vision-centric domains remains largely underexplored. This limitation is especially pronounced in the medical imaging domain, where effective performance requires both robust visual perception and structured reasoning. In this work, we address this gap by proposing VRFT-Aug, a visual reinforcement fine-tuning framework tailored for the medical domain. VRFT-Aug introduces a series of training strategies designed to augment both perception and reasoning, including prior knowledge injection, perception-driven policy refinement, medically informed reward shaping, and behavioral imitation. Together, these methods aim to stabilize and improve the RFT process. Through extensive experiments across multiple medical datasets, we show that our approaches consistently outperform both standard supervised fine-tuning and RFT baselines. Moreover, we provide empirically grounded insights and practical training heuristics that can be generalized to other medical image tasks. We hope this work contributes actionable guidance and fresh inspiration for the ongoing effort to develop reliable, reasoning-capable models for high-stakes medical applications.", "AI": {"tldr": "该论文提出了一种新的视觉强化微调框架VRFT-Aug，用于改进医学图像领域的大规模语言模型的性能。", "motivation": "当前在跨模态、以视觉为中心的领域中，规则基础奖励计划的有效扩展仍不成熟，特别是在需要强大视觉感知和结构化推理能力的医疗成像领域。为解决此问题提出了VRFT-Aug框架。", "method": "该方法通过引入包括先验知识注入、感知驱动策略细化、医学信息奖励调整以及行为模仿等多种训练策略来增强模型的视觉感知和推理能力，以稳定并提升强化微调过程。", "result": "在多个医疗数据集上的实验表明，所提出的方法比标准监督微调和RFT基线方法表现出更好的性能，并提供了可以应用于其他医学图像任务的经验指导和实用培训技巧。", "conclusion": "该工作为开发可靠、推理能力强的模型以用于高风险医学应用提供了一条可行路径。"}}
{"id": "2602.10618", "pdf": "https://arxiv.org/pdf/2602.10618", "abs": "https://arxiv.org/abs/2602.10618", "authors": ["Robin Beierling", "Manuel Scheibl", "Jonas Dech", "Abhijit Vyas", "Anna-Lisa Vollmer"], "title": "From Interaction to Demonstration Quality in Virtual Reality: Effects of Interaction Modality and Visual Representation on Everyday Tasks", "categories": ["cs.HC"], "comment": "26 pages, 6 figures, 7 tables (including appendix)", "summary": "Virtual Reality (VR) is increasingly used for training and demonstration purposes including a variety of applications ranging from robot learning to rehabilitation. However, the choice of input device and its visualization might influence workload and thus user performance leading to suboptimal demonstrations or reduced training effects. This study investigates how different VR input configurations - motion capture gloves, controllers with hand visualization, and controllers with controller visualization - affect user experience and task execution, with the goal of identifying which configuration is best suited for which type of task. Participants performed various kitchen-related activities of daily living (ADLs), including object placement, cutting, cleaning, and pouring in a simulated environment. To address two research questions, we evaluated user experience using the System Usability Scale and NASA Task Load Index (RQ1), and task-specific interaction behavior (RQ2). The latter was assessed using trajectory segmentation, analyzing movement efficiency, unnecessary actions, and execution precision. While no significant differences in overall usability and workload were found, trajectory analysis revealed configuration-specific execution behaviors with different movement strategies. Controllers enabled significantly faster task completion with less movement variability in pick-and-place style tasks such as table setting. In contrast, motion capture gloves produced more natural movements with fewer unnecessary actions, but also showed greater variance in movement patterns for manner-oriented tasks such as cutting bread. These findings highlight trade-offs between efficiency and naturalism, and have implications for optimizing VR-based training, improving the quality of user-generated demonstrations, and tailoring interaction design to specific application goals.", "AI": {"tldr": "研究不同虚拟现实输入配置对用户执行日常任务时体验的影响，以确定最适合不同类型任务的配置。", "motivation": "虚拟现实技术被广泛应用于训练和演示，但选择不同的输入设备及其可视化会影响用户体验及工作效率。为此，研究人员希望通过比较多种输入方式来找到最合适的方案。", "method": "参与者在模拟厨房环境中使用运动捕捉手套、带有手部可视化的控制器和仅显示控制器的控制器执行日常任务，包括物品放置、切割、清洁和倒水等。通过系统可用性量表和NASA工作负荷指数评估用户体验，并用轨迹分割分析交互行为的效率。", "result": "尽管总体上没有发现显著性的差异，但轨迹分析揭示了不同的运动策略。使用控制器可以更快地完成任务且具有较小的动作变化，在类似放置餐具的任务中表现出色；而运动捕捉手套则在自然动作和减少多余行动方面更为出色，但在某些特定类型的任务中存在更大的动作变异性。", "conclusion": "研究结果表明效率与自然性之间存在着权衡。这为优化虚拟现实训练、提高用户生成演示的质量以及根据具体应用目标调整交互设计提供了指导意义。"}}
{"id": "2602.10610", "pdf": "https://arxiv.org/pdf/2602.10610", "abs": "https://arxiv.org/abs/2602.10610", "authors": ["Chongxun Wang", "Zikang Shen", "Apoorav Rathore", "Akanimoh Udombeh", "Harrison Teng", "Fangzhou Xia"], "title": "Pitch Angle Control of a Magnetically Actuated Capsule Robot with Nonlinear FEA-based MPC and EKF Multisensory Fusion", "categories": ["cs.RO"], "comment": "This version is submitted for review at IEEE/ASME Transactions on Mechatronics", "summary": "Magnetically actuated capsule robots promise minimally invasive diagnosis and therapy in the gastrointestinal (GI) tract, but existing systems largely neglect control of capsule pitch, a degree of freedom critical for contact-rich interaction with inclined gastric walls. This paper presents a nonlinear, model-based framework for magnetic pitch control of an ingestible capsule robot actuated by a four-coil electromagnetic array. Angle-dependent magnetic forces and torques acting on embedded permanent magnets are characterized using three-dimensional finite-element simulations and embedded as lookup tables in a control-oriented rigid-body pitching model with rolling contact and actuator dynamics. A constrained model predictive controller (MPC) is designed to regulate pitch while respecting hardware-imposed current and slew-rate limits. Experiments on a compliant stomach-inspired surface demonstrate robust pitch reorientation from both horizontal and upright configurations, achieving about three to five times faster settling and reduced oscillatory motion than on-off control. Furthermore, an extended Kalman filter (EKF) fusing inertial sensing with intermittent visual measurements enables stable closed-loop control when the camera update rate is reduced from 30 Hz to 1 Hz, emulating clinically realistic imaging constraints. These results establish finite-element-informed MPC with sensor fusion as a scalable strategy for pitch regulation, controlled docking, and future multi-degree-of-freedom capsule locomotion.", "AI": {"tldr": "磁控胶囊机器人姿态控制研究。", "motivation": "现有系统忽视了对胶囊机器人倾斜角度的控制，而这对于与胃壁接触互动至关重要。", "method": "利用三维有限元分析模拟磁力和扭矩，并将其嵌入到刚体模型中。采用非线性模型预测控制器（MPC）来调节胶囊的姿态，在此基础上结合扩展卡尔曼滤波器（EKF）融合惯性和视觉传感器数据进行闭环控制。", "result": "实验结果显示，所提出的控制系统能够实现快速稳定姿态调整，并在减少相机刷新率时仍保持稳定的闭环控制性能。", "conclusion": "基于有限元分析的MPC结合传感器融合技术是一种可扩展策略，适用于胶囊机器人的姿态调节和未来的多自由度运动控制。"}}
{"id": "2602.10609", "pdf": "https://arxiv.org/pdf/2602.10609", "abs": "https://arxiv.org/abs/2602.10609", "authors": ["Shuo He", "Lang Feng", "Xin Cheng", "Lei Feng", "Bo An"], "title": "Online Causal Kalman Filtering for Stable and Effective Policy Optimization", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Reinforcement learning for large language models suffers from high-variance token-level importance sampling (IS) ratios, which would destabilize policy optimization at scale. To improve stability, recent methods typically use a fixed sequence-level IS ratio for all tokens in a sequence or adjust each token's IS ratio separately, thereby neglecting temporal off-policy derivation across tokens in a sequence. In this paper, we first empirically identify that local off-policy deviation is structurally inconsistent at the token level, which may distort policy-gradient updates across adjacent tokens and lead to training collapse. To address the issue, we propose Online Causal Kalman Filtering for stable and effective Policy Optimization (KPO). Concretely, we model the desired IS ratio as a latent state that evolves across tokens and apply a Kalman filter to update this state online and autoregressively based on the states of past tokens, regardless of future tokens. The resulting filtered IS ratios preserve token-wise local structure-aware variation while strongly smoothing noise spikes, yielding more stable and effective policy updates. Experimentally, KPO achieves superior results on challenging math reasoning datasets compared with state-of-the-art counterparts.", "AI": {"tldr": "本文提出了一种在线因果卡尔曼滤波器（KPO）方法，以提高大型语言模型在强化学习中的策略优化稳定性。", "motivation": "现有方法通常使用固定的序列级重要性采样比率或单独调整每个令牌的IS比率，忽略了令牌之间的时间偏差问题。这会导致相邻令牌间策略梯度更新失真，训练崩溃。", "method": "本文提出在线因果卡尔曼滤波器（KPO）来解决上述问题，通过模型所需的重要采样比率为潜变量，并使用卡尔曼滤波器基于过去令牌的状态在线自回归地更新状态。", "result": "实验表明，在具有挑战性的数学推理数据集上，所提出的KPO方法优于现有的先进技术。", "conclusion": "该研究成功解决了大型语言模型在强化学习中的策略优化稳定性问题，并展示了优越的性能。"}}
{"id": "2602.10607", "pdf": "https://arxiv.org/pdf/2602.10607", "abs": "https://arxiv.org/abs/2602.10607", "authors": ["Sansheng Cao", "Zhengyu Ma", "Yonghong Tian"], "title": "Hierarchical Zero-Order Optimization for Deep Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Corresponding author: Zhengyu Ma (mazhy@pcl.ac.cn)", "summary": "Zeroth-order (ZO) optimization has long been favored for its biological plausibility and its capacity to handle non-differentiable objectives, yet its computational complexity has historically limited its application in deep neural networks. Challenging the conventional paradigm that gradients propagate layer-by-layer, we propose Hierarchical Zeroth-Order (HZO) optimization, a novel divide-and-conquer strategy that decomposes the depth dimension of the network. We prove that HZO reduces the query complexity from $O(ML^2)$ to $O(ML \\log L)$ for a network of width $M$ and depth $L$, representing a significant leap over existing ZO methodologies. Furthermore, we provide a detailed error analysis showing that HZO maintains numerical stability by operating near the unitary limit ($L_{lip} \\approx 1$). Extensive evaluations on CIFAR-10 and ImageNet demonstrate that HZO achieves competitive accuracy compared to backpropagation.", "AI": {"tldr": "提出了一种分层零阶优化方法，用于深度神经网络的训练。", "motivation": "零阶优化由于其生物合理性以及处理非可微目标的能力而受到青睐，但计算复杂性限制了其在深度神经网络中的应用。因此，本文提出了层级零阶（HZO）优化方法来解决这个问题。", "method": "通过将深度维度分解为多个子任务，HZO策略降低了查询复杂度，并提供了详细的误差分析以确保数值稳定性。", "result": "实验结果表明，在CIFAR-10和ImageNet数据集上，HZO方法达到了与反向传播相当的准确率。", "conclusion": "HZO优化通过减少计算复杂性和保持数值稳定性，为深度神经网络训练提供了新的可能性。"}}
{"id": "2602.10604", "pdf": "https://arxiv.org/pdf/2602.10604", "abs": "https://arxiv.org/abs/2602.10604", "authors": ["Ailin Huang", "Ang Li", "Aobo Kong", "Bin Wang", "Binxing Jiao", "Bo Dong", "Bojun Wang", "Boyu Chen", "Brian Li", "Buyun Ma", "Chang Su", "Changxin Miao", "Changyi Wan", "Chao Lou", "Chen Hu", "Chen Xu", "Chenfeng Yu", "Chengting Feng", "Chengyuan Yao", "Chunrui Han", "Dan Ma", "Dapeng Shi", "Daxin Jiang", "Dehua Ma", "Deshan Sun", "et al. (190 additional authors not shown)"], "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters", "categories": ["cs.CL", "cs.AI"], "comment": "Technical report for Step 3.5 Flash", "summary": "We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.", "AI": {"tldr": "介绍了一种名为Step 3.5 Flash的模型，该模型结合了前沿级别的智能与计算效率，并在各种任务中展示了强大的性能。", "motivation": "为了构建具有快速准确执行能力的代理程序，提出一种混合专家模型以减少延迟和成本同时保持高效推理。", "method": "采用196B参数的基础模型配合11B活性参数进行有效推断；利用交错式3:1滑动窗口与全注意力以及多令牌预测技术来优化模型性能。", "result": "Step 3.5 Flash在IMO-AnswerBench、LiveCodeBench-v6等多个评估基准上取得了高分，接近于GPT-5.2 xHigh和Gemini 3.0 Pro等前沿模型的水平。", "conclusion": "通过重新定义效率边界，该模型为现实世界工业环境中部署复杂代理程序奠定了坚实基础"}}
{"id": "2602.10598", "pdf": "https://arxiv.org/pdf/2602.10598", "abs": "https://arxiv.org/abs/2602.10598", "authors": ["Shuai Han", "Mehdi Dastani", "Shihan Wang"], "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.", "AI": {"tldr": "提出了一种神经符号动作屏蔽框架，以自动学习符合高维状态约束的符号模型，并在此基础上生成动作掩码，排除不可行的动作。", "motivation": "现有深度强化学习方法在训练和执行过程中可能探索不可行的行为，需要一种能够自动学习与给定领域约束相一致的符号表示的方法。", "method": "提出神经符号动作屏蔽（NSAM）框架，在最少监督的方式下从高维状态中学习符号模型，并基于这些符号模型来学习排除不可行行为的动作掩码。该方法实现符号推理和深度策略优化的端到端集成，其中在符号建模和策略改进之间产生相互增强的效果。", "result": "实验结果表明NSAM能够显著提高带有约束条件领域中的深度强化学习代理的学习效率，并大幅降低违反约束的行为发生。", "conclusion": "神经符号动作屏蔽方法通过自动构建符合给定约束的符号模型并生成相应的动作掩码，有效提高了深度强化学习在复杂环境下的性能和稳定性。"}}
{"id": "2602.10594", "pdf": "https://arxiv.org/pdf/2602.10594", "abs": "https://arxiv.org/abs/2602.10594", "authors": ["Runze Tang", "Penny Sweetser"], "title": "Flow-Enabled Generalization to Human Demonstrations in Few-Shot Imitation Learning", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted to ICRA 2026", "summary": "Imitation Learning (IL) enables robots to learn complex skills from demonstrations without explicit task modeling, but it typically requires large amounts of demonstrations, creating significant collection costs. Prior work has investigated using flow as an intermediate representation to enable the use of human videos as a substitute, thereby reducing the amount of required robot demonstrations. However, most prior work has focused on the flow, either on the object or on specific points of the robot/hand, which cannot describe the motion of interaction. Meanwhile, relying on flow to achieve generalization to scenarios observed only in human videos remains limited, as flow alone cannot capture precise motion details. Furthermore, conditioning on scene observation to produce precise actions may cause the flow-conditioned policy to overfit to training tasks and weaken the generalization indicated by the flow. To address these gaps, we propose SFCrP, which includes a Scene Flow prediction model for Cross-embodiment learning (SFCr) and a Flow and Cropped point cloud conditioned Policy (FCrP). SFCr learns from both robot and human videos and predicts any point trajectories. FCrP follows the general flow motion and adjusts the action based on observations for precision tasks. Our method outperforms SOTA baselines across various real-world task settings, while also exhibiting strong spatial and instance generalization to scenarios seen only in human videos.", "AI": {"tldr": "该论文提出了SFCrP方法，旨在通过流预测模型和策略调整提高机器人从人类演示中学习的能力。", "motivation": "减少大量示例的需求，并改进现有模仿学习算法对于场景泛化的限制。", "method": "SFCrP包括一个跨实体学习的场景流预测模型（SFCr）和基于流与裁剪点云条件策略（FCrP）。SFCr从机器人及人类视频中学习并预测任意点轨迹，FCrP根据观测进行动作调整以提高精确度。", "result": "该方法在多种真实世界任务设置下优于当前最优基准，并且对于仅出现在人类视频中的场景展示出强大的空间和实例泛化能力。", "conclusion": "通过结合流预测与策略适应机制，SFCrP有效改善了从有限的人类演示中学习复杂技能的能力。"}}
{"id": "2602.10593", "pdf": "https://arxiv.org/pdf/2602.10593", "abs": "https://arxiv.org/abs/2602.10593", "authors": ["Mas Nurul Achmadiah", "Novendra Setyawan", "Achmad Arif Bryantono", "Chi-Chia Sun", "Wen-Kai Kuo"], "title": "Fast Person Detection Using YOLOX With AI Accelerator For Train Station Safety", "categories": ["cs.CV"], "comment": "6 pages, 8 figures, 2 tables. Presented at 2024 International Electronics Symposium (IES). IEEE DOI: 10.1109/IES63037.2024.10665874", "summary": "Recently, Image processing has advanced Faster and applied in many fields, including health, industry, and transportation. In the transportation sector, object detection is widely used to improve security, for example, in traffic security and passenger crossings at train stations. Some accidents occur in the train crossing area at the station, like passengers uncarefully when passing through the yellow line. So further security needs to be developed. Additional technology is required to reduce the number of accidents. This paper focuses on passenger detection applications at train stations using YOLOX and Edge AI Accelerator hardware. the performance of the AI accelerator will be compared with Jetson Orin Nano. The experimental results show that the Hailo-8 AI hardware accelerator has higher accuracy than Jetson Orin Nano (improvement of over 12%) and has lower latency than Jetson Orin Nano (reduced 20 ms).", "AI": {"tldr": "使用YOLOX和AI加速器进行快速人物检测，以提高火车站的安全性。", "motivation": "为了减少乘客在黄色线处不注意造成的事故，需要进一步开发安全技术。通过使用先进的图像处理技术和硬件加速器来改进火车站的人员检测系统。", "method": "利用YOLOX算法和Hailo-8 AI加速器进行人物检测，并与Jetson Orin Nano进行性能比较。", "result": "实验结果显示，Hailo-8 AI加速器比Jetson Orin Nano在准确率上提高了12%以上，在延迟方面减少了20毫秒。", "conclusion": "AI加速器技术显著提升了火车站人物检测系统的性能和效率。"}}
{"id": "2602.10592", "pdf": "https://arxiv.org/pdf/2602.10592", "abs": "https://arxiv.org/abs/2602.10592", "authors": ["Khanh Linh Tran", "Minh Nguyen Dang", "Thien Nguyen Trong", "Hung Nguyen Quoc", "Linh Nguyen Kieu"], "title": "Enhancing YOLOv11n for Reliable Child Detection in Noisy Surveillance Footage", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents a practical and lightweight solution for enhancing child detection in low-quality surveillance footage, a critical component in real-world missing child alert and daycare monitoring systems. Building upon the efficient YOLOv11n architecture, we propose a deployment-ready pipeline that improves detection under challenging conditions including occlusion, small object size, low resolution, motion blur, and poor lighting commonly found in existing CCTV infrastructures. Our approach introduces a domain-specific augmentation strategy that synthesizes realistic child placements using spatial perturbations such as partial visibility, truncation, and overlaps, combined with photometric degradations including lighting variation and noise. To improve recall of small and partially occluded instances, we integrate Slicing Aided Hyper Inference (SAHI) at inference time. All components are trained and evaluated on a filtered, child-only subset of the Roboflow Daycare dataset. Compared to the baseline YOLOv11n, our enhanced system achieves a mean Average Precision at 0.5 IoU (mAP@0.5) of 0.967 and a mean Average Precision averaged over IoU thresholds from 0.5 to 0.95 (mAP@0.5:0.95) of 0.783, yielding absolute improvements of 0.7 percent and 2.3 percent, respectively, without architectural changes. Importantly, the entire pipeline maintains compatibility with low-power edge devices and supports real-time performance, making it particularly well suited for low-cost or resource-constrained industrial surveillance deployments. The example augmented dataset and the source code used to generate it are available at: https://github.com/html-ptit/Data-Augmentation-YOLOv11n-child-detection", "AI": {"tldr": "本文提出了基于YOLOv11n架构的改进方案，以提高在低质量监控视频中对儿童的检测能力。", "motivation": "提升现有CCTV基础设施下儿童识别系统的准确性，在诸如遮挡、小目标尺寸、低分辨率等挑战性条件下实现更可靠的人脸检测功能。此研究对于失踪儿童预警和托儿所监控系统至关重要。", "method": "通过引入特定领域的增强策略，结合空间扰动（如部分可见度、截断、重叠）与光电降级（照明变化、噪声），合成现实中的儿童位置，同时在推理阶段整合Slicing Aided Hyper Inference (SAHI)以提高小目标和部分遮挡实例的召回率。", "result": "改进后的系统相较于原始YOLOv11n模型，在0.5 IoU阈值下达到96.7%的mAP，并且在IoU从0.5到0.95范围内平均得到78.3%的mAP，分别取得了7%和2.3%的绝对性能提升。", "conclusion": "该研究展示了一个实用、轻量级的儿童检测解决方案，在保持低功耗边缘设备兼容性的同时支持实时运行，特别适用于低成本或资源受限的工业监控部署。"}}
{"id": "2602.10586", "pdf": "https://arxiv.org/pdf/2602.10586", "abs": "https://arxiv.org/abs/2602.10586", "authors": ["Bosen Lin", "Feng Gao", "Yanwei Yu", "Junyu Dong", "Qian Du"], "title": "Enhancing Underwater Images via Adaptive Semantic-aware Codebook Learning", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted for publication in IEEE TGRS 2026", "summary": "Underwater Image Enhancement (UIE) is an ill-posed problem where natural clean references are not available, and the degradation levels vary significantly across semantic regions. Existing UIE methods treat images with a single global model and ignore the inconsistent degradation of different scene components. This oversight leads to significant color distortions and loss of fine details in heterogeneous underwater scenes, especially where degradation varies significantly across different image regions. Therefore, we propose SUCode (Semantic-aware Underwater Codebook Network), which achieves adaptive UIE from semantic-aware discrete codebook representation. Compared with one-shot codebook-based methods, SUCode exploits semantic-aware, pixel-level codebook representation tailored to heterogeneous underwater degradation. A three-stage training paradigm is employed to represent raw underwater image features to avoid pseudo ground-truth contamination. Gated Channel Attention Module (GCAM) and Frequency-Aware Feature Fusion (FAFF) jointly integrate channel and frequency cues for faithful color restoration and texture recovery. Extensive experiments on multiple benchmarks demonstrate that SUCode achieves state-of-the-art performance, outperforming recent UIE methods on both reference and no-reference metrics. The code will be made public available at https://github.com/oucailab/SUCode.", "AI": {"tldr": "本文提出了一种基于语义感知的自适应水下图像增强方法SUCode，通过像素级别的代码本表示解决不同场景组件之间的降质差异。", "motivation": "现有的水下图像增强方法采用单一全局模型处理图像，忽略了不同区域之间不一致的退化情况，导致色彩失真和细节损失。", "method": "本文提出了一种基于语义感知的水下代码本网络SUCode，通过三阶段训练范式来避免伪真实标签污染，并利用门控通道注意力模块和频率感知特征融合进行颜色恢复和纹理重建。", "result": "实验结果表明，SUCode在多个基准上的表现优于现有的其他方法，在有参考和无参考指标上均达到了最佳性能。", "conclusion": "本文通过引入语义感知的代码本表示，解决了水下图像增强中的异质退化问题，并实现了对色彩和纹理的有效恢复。"}}
{"id": "2602.10585", "pdf": "https://arxiv.org/pdf/2602.10585", "abs": "https://arxiv.org/abs/2602.10585", "authors": ["Guangzhi Xiong", "Sanchit Sinha", "Aidong Zhang"], "title": "Neural Additive Experts: Context-Gated Experts for Controllable Model Additivity", "categories": ["cs.LG", "cs.AI"], "comment": "AISTATS 2026", "summary": "The trade-off between interpretability and accuracy remains a core challenge in machine learning. Standard Generalized Additive Models (GAMs) offer clear feature attributions but are often constrained by their strictly additive nature, which can limit predictive performance. Introducing feature interactions can boost accuracy yet may obscure individual feature contributions. To address these issues, we propose Neural Additive Experts (NAEs), a novel framework that seamlessly balances interpretability and accuracy. NAEs employ a mixture of experts framework, learning multiple specialized networks per feature, while a dynamic gating mechanism integrates information across features, thereby relaxing rigid additive constraints. Furthermore, we propose targeted regularization techniques to mitigate variance among expert predictions, facilitating a smooth transition from an exclusively additive model to one that captures intricate feature interactions while maintaining clarity in feature attributions. Our theoretical analysis and experiments on synthetic data illustrate the model's flexibility, and extensive evaluations on real-world datasets confirm that NAEs achieve an optimal balance between predictive accuracy and transparent, feature-level explanations. The code is available at https://github.com/Teddy-XiongGZ/NAE.", "AI": {"tldr": "该论文提出了一种名为神经加性专家（NAEs）的新框架，旨在解决机器学习中解释性和准确性的权衡问题。", "motivation": "传统的广义可加模型（GAMs）虽然提供了清晰的特征归因，但其严格加性的性质限制了预测性能。引入特征交互可以提高准确性，但也可能模糊单个特征贡献。为了应对这些问题，提出了神经加性专家框架。", "method": "NAEs采用混合专家框架，在每个特征上学习多个专门化的网络，并使用动态门控机制整合不同特征之间的信息。通过特定的正则化技术来减小预测中的方差，使模型从严格的加性模型平滑过渡到能够捕捉复杂特征交互的方式。", "result": "理论分析和合成数据上的实验展示了模型的灵活性；在真实世界的数据集上进行广泛的评估后发现，NAEs能够在准确性与透明度方面达到最佳平衡，并提供清晰的特征级解释。", "conclusion": "论文提出的神经加性专家（NAEs）框架成功地解决了机器学习中的核心挑战——即在保持准确性的前提下提高模型的可解释性。"}}
{"id": "2602.10583", "pdf": "https://arxiv.org/pdf/2602.10583", "abs": "https://arxiv.org/abs/2602.10583", "authors": ["Bo Xue", "Yunchong Song", "Fanghao Shao", "Xuekai Zhu", "Lin Chen", "Luoyi Fu", "Xinbing Wang", "Zhouhan Lin"], "title": "Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets", "categories": ["cs.AI"], "comment": "Published as a conference paper at ICLR 2026", "summary": "Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. This leads to restricted exploration of compositional paths and is biased toward the chosen path. Generative Flow Networks (GFlowNets) are powerful for efficient exploring and generalizing over state spaces, particularly those with a DAG structure. However, prior GFlowNets-based language models operate at the token level and remain confined to tree-structured spaces, limiting their potential. In this work, we propose Flow of SpanS (FOSS), a principled GFlowNets framework for span generation. FoSS constructs a dynamic span vocabulary by segmenting the retrieved text flexibly, ensuring a DAG-structured state space, which allows GFlowNets to explore diverse compositional paths and improve generalization. With specialized reward models, FoSS generates diverse, high-quality text. Empirically, FoSS improves MAUVE scores by up to 12.5% over Transformer on text generation and achieves 3.5% gains on knowledge-intensive tasks, consistently outperforming state-of-the-art methods. Scaling experiments further demonstrate FoSS benefits from larger models, more data, and richer retrieval corpora, retaining its advantage over strong baselines.", "AI": {"tldr": "本文提出了一种基于生成流网络的框架Flow of SpanS（FOSS），用于动态跨度词汇生成，以提高文本生成的质量和多样性。", "motivation": "传统的语言模型在固定词汇表内进行逐词生成，限制了灵活性和表达力。现有的动态词汇方法忽视了句子可以由不同长度的跨度组成，并未明确建模有向无环图（DAG）状态空间，导致探索路径受限且偏向特定路径。", "method": "本文提出FOSS框架，通过灵活分割检索到的文本构建动态跨度词汇表，确保生成过程中的DAG结构，允许GFlowNets探索更多组合路径并提升泛化能力。使用专门的奖励模型来增强生成多样化和高质量的文本。", "result": "在实验中，FoSS在文本生成上提高了MAUVE评分最高达12.5%，并且在知识密集型任务上表现出3.5%的优势，优于最新的方法。随着更大规模模型、更多数据以及更丰富的检索语料库的应用，FOSS能够保持其相对于强基线的优越性。", "conclusion": "本文通过引入FoSS框架，有效地解决了现有动态词汇生成问题，并在多个任务上取得了显著改进，展示了GFlowNets用于跨度生成的强大潜力。"}}
{"id": "2602.10576", "pdf": "https://arxiv.org/pdf/2602.10576", "abs": "https://arxiv.org/abs/2602.10576", "authors": ["Boxiao Wang", "Kai Li", "Tianyi Liu", "Chen Li", "Junzhe Wang", "Yifan Zhang", "Jian Cheng"], "title": "LLM-Based Scientific Equation Discovery via Physics-Informed Token-Regularized Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Symbolic regression aims to distill mathematical equations from observational data. Recent approaches have successfully leveraged Large Language Models (LLMs) to generate equation hypotheses, capitalizing on their vast pre-trained scientific priors. However, existing frameworks predominantly treat the LLM as a static generator, relying on prompt-level guidance to steer exploration. This paradigm fails to update the model's internal representations based on search feedback, often yielding physically inconsistent or mathematically redundant expressions. In this work, we propose PiT-PO (Physics-informed Token-regularized Policy Optimization), a unified framework that evolves the LLM into an adaptive generator via reinforcement learning. Central to PiT-PO is a dual-constraint mechanism that rigorously enforces hierarchical physical validity while simultaneously applying fine-grained, token-level penalties to suppress redundant structures. Consequently, PiT-PO aligns LLM to produce equations that are both scientifically consistent and structurally parsimonious. Empirically, PiT-PO achieves state-of-the-art performance on standard benchmarks and successfully discovers novel turbulence models for challenging fluid dynamics problems. We also demonstrate that PiT-PO empowers small-scale models to outperform closed-source giants, democratizing access to high-performance scientific discovery.", "AI": {"tldr": "本文提出了一种基于物理信息和令牌正则化的策略优化框架PiT-PO，用于通过强化学习动态调整大型语言模型以发现科学方程。", "motivation": "现有方法将LLM作为静态生成器使用，缺乏根据搜索反馈更新内部表示的能力，导致产生的方程物理不一致或数学冗余。因此需要一种新的框架来提高方程的一致性和简洁性。", "method": "PiT-PO通过强化学习动态调整LLM，并结合双约束机制，确保物理有效性同时减少冗余结构的生成。", "result": "实验结果表明，PiT-PO在标准基准测试中表现优异，能够发现新型湍流模型并提高小型模型的性能。", "conclusion": "PiT-PO框架使科学发现更加民主化和高效。"}}
{"id": "2602.10575", "pdf": "https://arxiv.org/pdf/2602.10575", "abs": "https://arxiv.org/abs/2602.10575", "authors": ["Chenhao Zhang", "Yazhe Niu", "Hongsheng Li"], "title": "MetaphorStar: Image Metaphor Understanding and Reasoning with End-to-End Visual Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": "14 pages, 4 figures, 11 tables; Code: https://github.com/MING-ZCH/MetaphorStar, Model & Dataset: https://huggingface.co/collections/MING-ZCH/metaphorstar", "summary": "Metaphorical comprehension in images remains a critical challenge for Nowadays AI systems. While Multimodal Large Language Models (MLLMs) excel at basic Visual Question Answering (VQA), they consistently struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. This difficulty stems from the task's demand for sophisticated multi-hop reasoning, cultural context, and Theory of Mind (ToM) capabilities, which current models lack. To fill this gap, we propose MetaphorStar, the first end-to-end visual reinforcement learning (RL) framework for image implication tasks. Our framework includes three core components: the fine-grained dataset TFQ-Data, the visual RL method TFQ-GRPO, and the well-structured benchmark TFQ-Bench. Our fully open-source MetaphorStar family, trained using TFQ-GRPO on TFQ-Data, significantly improves performance by an average of 82.6% on the image implication benchmarks. Compared with 20+ mainstream MLLMs, MetaphorStar-32B achieves state-of-the-art (SOTA) on Multiple-Choice Question and Open-Style Question, significantly outperforms the top closed-source model Gemini-3.0-pro on True-False Question. Crucially, our experiments reveal that learning image implication tasks improves the general understanding ability, especially the complex visual reasoning ability. We further provide a systematic analysis of model parameter scaling, training data scaling, and the impact of different model architectures and training strategies, demonstrating the broad applicability of our method. We open-sourced all model weights, datasets, and method code at https://metaphorstar.github.io.", "AI": {"tldr": "MetaphorStar是首个用于图像隐喻理解与推理的端到端视觉强化学习框架。", "motivation": "当前AI系统在处理图像中的文化、情感和上下文含义方面存在困难，缺乏复杂的多步推理、文化背景和理论心智能力。因此，提出了一种新方法来解决这一问题。", "method": "该论文提出了MetaphorStar框架，包括细粒度数据集TFQ-Data，视觉RL方法TFQ-GRPO以及基准测试TFQ-Bench。通过这些组件的结合使用，在图像隐喻任务上实现了显著改进。", "result": "实验显示，与20多个主流多模态大语言模型相比，MetaphorStar在多项选择题和开放式问题上的表现达到SOTA水平，并且在真伪判断题中超越了Gemini-3.0-pro。同时展示了模型参数缩放、训练数据量变化以及不同架构和策略的影响。", "conclusion": "研究证明了通过学习图像隐喻任务可以增强对复杂视觉推理的理解能力，最终提出的方法具有广泛适用性，并且开放了所有代码、模型权重及数据集供社区使用。"}}
{"id": "2602.10561", "pdf": "https://arxiv.org/pdf/2602.10561", "abs": "https://arxiv.org/abs/2602.10561", "authors": ["Chongxi Meng", "Da Zhao", "Yifei Zhao", "Minghao Zeng", "Yanmin Zhou", "Zhipeng Wang", "Bin He"], "title": "Morphogenetic Assembly and Adaptive Control for Heterogeneous Modular Robots", "categories": ["cs.RO"], "comment": "Accepted by ICRA 2026", "summary": "This paper presents a closed-loop automation framework for heterogeneous modular robots, covering the full pipeline from morphological construction to adaptive control. In this framework, a mobile manipulator handles heterogeneous functional modules including structural, joint, and wheeled modules to dynamically assemble diverse robot configurations and provide them with immediate locomotion capability. To address the state-space explosion in large-scale heterogeneous reconfiguration, we propose a hierarchical planner: the high-level planner uses a bidirectional heuristic search with type-penalty terms to generate module-handling sequences, while the low level planner employs A* search to compute optimal execution trajectories. This design effectively decouples discrete configuration planning from continuous motion execution. For adaptive motion generation of unknown assembled configurations, we introduce a GPU accelerated Annealing-Variance Model Predictive Path Integral (MPPI) controller. By incorporating a multi stage variance annealing strategy to balance global exploration and local convergence, the controller enables configuration-agnostic, real-time motion control. Large scale simulations show that the type-penalty term is critical for planning robustness in heterogeneous scenarios. Moreover, the greedy heuristic produces plans with lower physical execution costs than the Hungarian heuristic. The proposed annealing-variance MPPI significantly outperforms standard MPPI in both velocity tracking accuracy and control frequency, achieving real time control at 50 Hz. The framework validates the full-cycle process, including module assembly, robot merging and splitting, and dynamic motion generation.", "AI": {"tldr": "本文提出了一种异构模块化机器人闭环自动化框架，包括形态构建和自适应控制。", "motivation": "为解决大规模异构重构中的状态空间爆炸问题以及未知组装配置的自适应运动生成问题，设计一个有效的闭环自动化系统。", "method": "使用层次规划器进行离散结构规划与连续动作执行解耦；采用GPU加速的退火-方差模型预测路径积分控制器实现实时动态控制。", "result": "大规模仿真表明，类型惩罚项对于异构场景中的规划鲁棒性至关重要。此外，贪婪启发式方法产生的计划具有更低的物理执行成本。提出的退火-方差MPPI在速度跟踪精度和控制频率上显著优于标准MPPI，实现实时控制50Hz。", "conclusion": "该框架验证了从模块组装到机器人合并、分裂以及动态运动生成的完整周期过程的有效性。"}}
{"id": "2602.10560", "pdf": "https://arxiv.org/pdf/2602.10560", "abs": "https://arxiv.org/abs/2602.10560", "authors": ["Leheng Sheng", "Yongtao Zhang", "Wenchang Ma", "Yaorui Shi", "Ting Huang", "Xiang Wang", "An Zhang", "Ke Shen", "Tat-Seng Chua"], "title": "When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "26 pages", "summary": "While reasoning over long context is crucial for various real-world applications, it remains challenging for large language models (LLMs) as they suffer from performance degradation as the context length grows. Recent work MemAgent has tried to tackle this by processing context chunk-by-chunk in an RNN-like loop and updating a textual memory for final answering. However, this naive recurrent memory update faces two crucial drawbacks: (i) memory can quickly explode because it can update indiscriminately, even on evidence-free chunks; and (ii) the loop lacks an exit mechanism, leading to unnecessary computation after even sufficient evidence is collected. To address these issues, we propose GRU-Mem, which incorporates two text-controlled gates for more stable and efficient long-context reasoning. Specifically, in GRU-Mem, the memory only updates when the update gate is open and the recurrent loop will exit immediately once the exit gate is open. To endow the model with such capabilities, we introduce two reward signals $r^{\\text{update}}$ and $r^{\\text{exit}}$ within end-to-end RL, rewarding the correct updating and exiting behaviors respectively. Experiments on various long-context reasoning tasks demonstrate the effectiveness and efficiency of GRU-Mem, which generally outperforms the vanilla MemAgent with up to 400\\% times inference speed acceleration.", "AI": {"tldr": "提出GRU-Mem模型解决长上下文推理中记忆爆炸和无意义计算的问题。", "motivation": "为了解决大语言模型在处理长上下文时性能下降的问题，特别是MemAgent中存在的记忆更新无选择性和缺乏退出机制的缺点。", "method": "引入两个文本控制门（更新门和退出门），并在端到端强化学习中添加奖励信号来指导正确的行为。", "result": "实验显示GRU-Mem在多种长上下文推理任务上比传统MemAgent更有效，且加速了400%的推断速度。", "conclusion": "通过引入可控的记忆更新和退出机制，GRU-Mem不仅提高了模型的效果，还显著减少了计算量。"}}
{"id": "2602.10556", "pdf": "https://arxiv.org/pdf/2602.10556", "abs": "https://arxiv.org/abs/2602.10556", "authors": ["Lihan Zha", "Asher J. Hancock", "Mingtong Zhang", "Tenny Yin", "Yixuan Huang", "Dhruv Shah", "Allen Z. Ren", "Anirudha Majumdar"], "title": "LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer", "categories": ["cs.RO", "cs.AI"], "comment": "Project website: https://lap-vla.github.io", "summary": "A long-standing goal in robotics is a generalist policy that can be deployed zero-shot on new robot embodiments without per-embodiment adaptation. Despite large-scale multi-embodiment pre-training, existing Vision-Language-Action models (VLAs) remain tightly coupled to their training embodiments and typically require costly fine-tuning. We introduce Language-Action Pre-training (LAP), a simple recipe that represents low-level robot actions directly in natural language, aligning action supervision with the pre-trained vision-language model's input-output distribution. LAP requires no learned tokenizer, no costly annotation, and no embodiment-specific architectural design. Based on LAP, we present LAP-3B, which to the best of our knowledge is the first VLA to achieve substantial zero-shot transfer to previously unseen robot embodiments without any embodiment-specific fine-tuning. Across multiple novel robots and manipulation tasks, LAP-3B attains over 50% average zero-shot success, delivering roughly a 2x improvement over the strongest prior VLAs. We further show that LAP enables efficient adaptation and favorable scaling, while unifying action prediction and VQA in a shared language-action format that yields additional gains through co-training.", "AI": {"tldr": "本文介绍了LAP预训练方法，使机器人在未经特定适应的新身体上实现零样本迁移。", "motivation": "现有模型仍高度依赖于其训练的身体，并且通常需要昂贵的微调。作者希望通过直接将低级动作表示为自然语言来解决这个问题，以实现更好的零样本迁移效果。", "method": "LAP预训练方法通过将机器人动作直接用自然语言描述，使其与视觉语言模型的输入输出分布对齐。基于该方法构建了无需特定身体微调即能实现良好性能的LAP-3B模型。", "result": "在多个新型机器人和操作任务中，LAP-3B达到了超过50%的平均零样本成功率，比最强前驱VLAs提高了大约两倍。", "conclusion": "通过将动作预测与VQA统一为共享的语言行动格式，LAP不仅实现了高效适应性和有利可图的扩展性，并且通过协同训练获得了额外的优势。"}}
{"id": "2602.10555", "pdf": "https://arxiv.org/pdf/2602.10555", "abs": "https://arxiv.org/abs/2602.10555", "authors": ["Hsan Sandar Win", "Andrew Walters", "Cheng-Chew Lim", "Daniel Webber", "Seth Leslie", "Tan Doan"], "title": "An Ontology-driven Dynamic Knowledge Base for Uninhabited Ground Vehicles", "categories": ["cs.MA", "cs.DB", "cs.RO"], "comment": "10 pages, 11 figures, 2025 Australasian Conference on Robotics and Automation (ACRA 2025)", "summary": "In this paper, the concept of Dynamic Contextual Mission Data (DCMD) is introduced to develop an ontology-driven dynamic knowledge base for Uninhabited Ground Vehicles (UGVs) at the tactical edge. The dynamic knowledge base with DCMD is added to the UGVs to: support enhanced situation awareness; improve autonomous decision making; and facilitate agility within complex and dynamic environments. As UGVs are heavily reliant on the a priori information added pre-mission, unexpected occurrences during a mission can cause identification ambiguities and require increased levels of user input. Updating this a priori information with contextual information can help UGVs realise their full potential. To address this, the dynamic knowledge base was designed using an ontology-driven representation, supported by near real-time information acquisition and analysis, to provide in-mission on-platform DCMD updates. This was implemented on a team of four UGVs that executed a laboratory based surveillance mission. The results showed that the ontology-driven dynamic representation of the UGV operational environment was machine actionable, producing contextual information to support a successful and timely mission, and contributed directly to the situation awareness.", "AI": {"tldr": "本文提出了用于无人地面车辆的基于本体论的动态知识库，以提升其在复杂和动态环境中的感知能力和自主决策能力。", "motivation": "为了应对任务中意外事件造成的识别模糊性和用户输入增加的问题，文章旨在通过引入动态上下文任务数据（DCMD）来更新先验信息，从而使无人地面车辆充分发挥潜力。", "method": "本文设计了一种基于本体论的表示法构建了动态知识库，并结合实时的信息获取和分析以在任务期间提供平台上的DCMD更新。该方法应用于四辆无人地面车辆执行实验室监视任务。", "result": "结果显示，所提出的基于本体论的动态表示方法是可操作的，可以生成支持及时成功完成任务的相关上下文信息，并直接促进了态势感知。", "conclusion": "基于本体论的方法在提升无人地面车辆的任务适应性和自主性方面具有显著效果。"}}
{"id": "2602.10553", "pdf": "https://arxiv.org/pdf/2602.10553", "abs": "https://arxiv.org/abs/2602.10553", "authors": ["Junichiro Takahashi", "Masataka Sato", "Satoshi Kodeta", "Norihiko Takeda"], "title": "Contrastive Learning for Multi Label ECG Classification with Jaccard Score Based Sigmoid Loss", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled the development of multimodal medical AI. While models such as MedGemini achieve high accuracy on VQA tasks like USMLE MM, their performance on ECG based tasks remains limited, and some models, such as MedGemma, do not support ECG data at all. Interpreting ECGs is inherently challenging, and diagnostic accuracy can vary depending on the interpreter's experience. Although echocardiography provides rich diagnostic information, it requires specialized equipment and personnel, limiting its availability. In this study, we focus on constructing a robust ECG encoder for multimodal pretraining using real world hospital data. We employ SigLIP, a CLIP based model with a sigmoid based loss function enabling multi label prediction, and introduce a modified loss function tailored to the multi label nature of ECG data. Experiments demonstrate that incorporating medical knowledge in the language model and applying the modified loss significantly improve multi label ECG classification. To further enhance performance, we increase the embedding dimensionality and apply random cropping to mitigate data drift. Finally, per label analysis reveals which ECG findings are easier or harder to predict. Our study provides a foundational framework for developing medical models that utilize ECG data.", "AI": {"tldr": "构建一个用于多标签ECG分类的稳健编码器，使用真实医院数据进行多模态预训练。", "motivation": "当前模型在VQA任务上表现良好，但在基于ECG的任务中性能有限。为解决这一问题并提升诊断准确性，提出了一种新的方法来处理ECG数据中的多标签预测。", "method": "采用SigLIP模型，并引入了一个基于Jaccard分数的Sigmoid损失函数以适应多标签性质。此外，通过增加嵌入维度和随机裁剪来改进性能。", "result": "实验表明，结合医学知识的语言模型和修改后的损失函数显著改善了ECG分类效果。", "conclusion": "研究为开发利用ECG数据的医疗模型提供了基础框架，并进一步揭示了哪些ECG发现更容易或更难预测。"}}
{"id": "2602.10552", "pdf": "https://arxiv.org/pdf/2602.10552", "abs": "https://arxiv.org/abs/2602.10552", "authors": ["Dongyang Li", "Kunpeng Xie", "Mingyang Wu", "Yiwei Kong", "Jiahua Tang", "Haoyang Qin", "Chen Wei", "Quanying Liu"], "title": "MindPilot: Closed-loop Visual Stimulation Optimization for Brain Modulation with EEG-guided Diffusion", "categories": ["cs.NE"], "comment": "10 pages", "summary": "Whereas most brain-computer interface research has focused on decoding neural signals into behavior or intent, the reverse challenge-using controlled stimuli to steer brain activity-remains far less understood, particularly in the visual domain. However, designing images that consistently elicit desired neural responses is difficult: subjective states lack clear quantitative measures, and EEG feedback is both noisy and non-differentiable. We introduce MindPilot, the first closed-loop framework that uses EEG signals as optimization feedback to guide naturalistic image generation. Unlike prior work limited to invasive settings or low-level flicker stimuli, MindPilot leverages non-invasive EEG with natural images, treating the brain as a black-box function and employing a pseudo-model guidance mechanism to iteratively refine images without requiring explicit rewards or gradients. We validate MindPilot in both simulation and human experiments, demonstrating (i) efficient retrieval of semantic targets, (ii) closed-loop optimization of EEG features, and (iii) human-subject validations in mental matching and emotion regulation tasks. Our results establish the feasibility of EEG-guided image synthesis and open new avenues for non-invasive closed-loop brain modulation, bidirectional brain-computer interfaces, and neural signal-guided generative modeling.", "AI": {"tldr": "本文介绍了MindPilot，一种利用EEG信号作为反馈优化自然图像生成的闭环框架。", "motivation": "大多数脑机接口研究集中在解码神经信号以预测行为或意图上，而使用可控刺激来引导脑活动的研究较少，尤其是在视觉领域。设计能一致引发期望神经反应的图片难度大，主观状态缺乏明确量化指标，EEG反馈噪声大且不可微。", "method": "MindPilot利用非侵入性EEG和自然图像，并采用伪模型指导机制迭代优化图片，无需显式奖励或梯度。", "result": "验证了MindPilot在模拟和人类实验中的有效性，包括高效检索语义目标、闭环优化EEG特征及情绪调节任务中的人体验证。", "conclusion": "结果表明EEG引导图像合成的可行性，并为非侵入性闭环脑调制、双向脑机接口及神经信号指导生成模型开辟了新途径。"}}
{"id": "2602.10551", "pdf": "https://arxiv.org/pdf/2602.10551", "abs": "https://arxiv.org/abs/2602.10551", "authors": ["Guanting Ye", "Qiyan Zhao", "Wenhao Yu", "Xiaofeng Zhang", "Jianmin Ji", "Yanyong Zhang", "Ka-Veng Yuen"], "title": "C^2ROPE: Causal Continuous Rotary Positional Encoding for 3D Large Multimodal-Models Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted in ICRA 2026", "summary": "Recent advances in 3D Large Multimodal Models (LMMs) built on Large Language Models (LLMs) have established the alignment of 3D visual features with LLM representations as the dominant paradigm. However, the inherited Rotary Position Embedding (RoPE) introduces limitations for multimodal processing. Specifically, applying 1D temporal positional indices disrupts the continuity of visual features along the column dimension, resulting in spatial locality loss. Moreover, RoPE follows the prior that temporally closer image tokens are more causally related, leading to long-term decay in attention allocation and causing the model to progressively neglect earlier visual tokens as the sequence length increases. To address these issues, we propose C^2RoPE, an improved RoPE that explicitly models local spatial Continuity and spatial Causal relationships for visual processing. C^2RoPE introduces a spatio-temporal continuous positional embedding mechanism for visual tokens. It first integrates 1D temporal positions with Cartesian-based spatial coordinates to construct a triplet hybrid positional index, and then employs a frequency allocation strategy to encode spatio-temporal positional information across the three index components. Additionally, we introduce Chebyshev Causal Masking, which determines causal dependencies by computing the Chebyshev distance of image tokens in 2D space. Evaluation results across various benchmarks, including 3D scene reasoning and 3D visual question answering, demonstrate C^2RoPE's effectiveness. The code is be available at https://github.com/ErikZ719/C2RoPE.", "AI": {"tldr": "提出了C^2ROPE，一种改进的RoPE方法，用于增强3D大型多模态模型的视觉处理能力。", "motivation": "当前基于RoPE的方法在处理多模态数据时存在局限性，包括破坏视觉特征连续性和因果关系理解的问题。", "method": "C^2ROPE通过引入时空连续位置嵌入机制，并结合Chebyshev因果掩码来解决这些问题。它利用频率分配策略编码空间和时间的位置信息。", "result": "在3D场景理解和3D视觉问答等不同基准测试中的性能优于现有方法，显示了C^2ROPE的有效性。", "conclusion": "C^2RoPE通过改进位置嵌入机制显著提升了多模态模型处理3D数据的能力。"}}
{"id": "2602.10549", "pdf": "https://arxiv.org/pdf/2602.10549", "abs": "https://arxiv.org/abs/2602.10549", "authors": ["Shengyang Sun", "Jiashen Hua", "Junyi Feng", "Xiaojin Gong"], "title": "Enhancing Weakly Supervised Multimodal Video Anomaly Detection through Text Guidance", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by IEEE Transactions on Multimedia", "summary": "Weakly supervised multimodal video anomaly detection has gained significant attention, yet the potential of the text modality remains under-explored. Text provides explicit semantic information that can enhance anomaly characterization and reduce false alarms. However, extracting effective text features is challenging due to the inability of general-purpose language models to capture anomaly-specific nuances and the scarcity of relevant descriptions. Furthermore, multimodal fusion often suffers from redundancy and imbalance. To address these issues, we propose a novel text-guided framework. First, we introduce an in-context learning-based multi-stage text augmentation mechanism to generate high-quality anomaly text samples for fine-tuning the text feature extractor. Second, we design a multi-scale bottleneck Transformer fusion module that uses compressed bottleneck tokens to progressively integrate information across modalities, mitigating redundancy and imbalance. Experiments on UCF-Crime and XD-Violence demonstrate state-of-the-art performance.", "AI": {"tldr": "本文提出了一种基于文本引导的框架，用于改进弱监督多模态视频异常检测。", "motivation": "当前的弱监督多模态视频异常检测中，文本模态的潜力尚未充分开发。文本提供了显式的语义信息，有助于改善异常特征表示并减少误报。然而，提取有效文本特征存在挑战，包括一般语言模型难以捕捉特定于异常的信息以及相关描述稀缺的问题。", "method": "本文提出了一种基于上下文学习的多阶段文本增强机制，用于生成高质量的异常文本样本以微调文本特征抽取器，并设计了一个多尺度瓶颈Transformer融合模块，利用压缩后的瓶颈令牌逐步跨模态整合信息，从而缓解冗余和不平衡问题。", "result": "在UCF-Crime和XD-Violence数据集上的实验结果表明该方法达到了最先进的性能。", "conclusion": "通过引入文本引导框架，本文有效地提高了弱监督多模态视频异常检测的性能，验证了基于上下文学习的多阶段文本增强机制和多尺度瓶颈Transformer融合模块的有效性。"}}
{"id": "2602.10548", "pdf": "https://arxiv.org/pdf/2602.10548", "abs": "https://arxiv.org/abs/2602.10548", "authors": ["Yigang Qin", "EunJeong Cheon"], "title": "Labor, Capital, and Machine: Toward a Labor Process Theory for HCI", "categories": ["cs.HC"], "comment": "20 pages, 2 figures. Accepted to CHI'26", "summary": "The HCI community has called for renewed attention to labor issues and the political economy of computing. Yet much work remains in engaging with labor theory to better understand modern work and workers. This article traces the development of Labor Process Theory (LPT) -- from Karl Marx and Harry Braverman to Michael Burawoy and beyond -- and introduces it as an essential yet underutilized resource for structural analysis of work under capitalism and the design of computing systems. We examine HCI literature on labor, investigating focal themes and conceptual, empirical, and design approaches. Drawing from LPT, we offer directions for HCI research and practice: distinguish labor from work, link work practice to value production, study up the management, analyze consent and legitimacy, move beyond the point of production, design alternative institutions, and unnaturalize bourgeois designs. These directions can deepen analyses of tech-mediated workplace regimes, inform critical and normative designs, and strengthen the field's connection to broader political economic critique.", "AI": {"tldr": "本文探讨了劳动过程理论在人机交互（HCI）中的应用，旨在为现代工作和工人提供更深层次的理解。", "motivation": "人机交互领域呼吁重新关注劳工问题和计算的政治经济。然而，在与劳动理论的对接方面仍有许多工作要做，以更好地理解现代社会的工作形式及劳动者。", "method": "本文追溯了劳动过程理论（LPT）的发展历程，并从该理论出发考察了HCI文献中的劳动主题以及概念、实证和设计方法论。", "result": "作者提出了对HCI研究与实践的指导方向：区分劳动与工作，连接工作实践和价值生产，向上层管理研究，分析同意与合法性，超越生产点范围，设计替代机构，去自然化资产阶级设计等。这些方向能够深化对于技术中介的工作制度的研究，并为批判性及规范性的设计提供信息。", "conclusion": "通过引入劳动过程理论，本文强调了其作为结构分析工具的重要性以及在人机交互领域中尚未被充分利用的资源。它有助于加深对技术影响下的工作场所研究并加强该领域的政治经济批评连接。"}}
{"id": "2602.10547", "pdf": "https://arxiv.org/pdf/2602.10547", "abs": "https://arxiv.org/abs/2602.10547", "authors": ["Yanchen Liu", "Yuang Fan", "Minghui Zhao", "Xiaofan Jiang"], "title": "ReSPEC: A Framework for Online Multispectral Sensor Reconfiguration in Dynamic Environments", "categories": ["cs.RO"], "comment": "8 pages, 4 figures. This work has been submitted to the IEEE for possible publication", "summary": "Multi-sensor fusion is central to robust robotic perception, yet most existing systems operate under static sensor configurations, collecting all modalities at fixed rates and fidelity regardless of their situational utility. This rigidity wastes bandwidth, computation, and energy, and prevents systems from prioritizing sensors under challenging conditions such as poor lighting or occlusion. Recent advances in reinforcement learning (RL) and modality-aware fusion suggest the potential for adaptive perception, but prior efforts have largely focused on re-weighting features at inference time, ignoring the physical cost of sensor data collection. We introduce a framework that unifies sensing, learning, and actuation into a closed reconfiguration loop. A task-specific detection backbone extracts multispectral features (e.g. RGB, IR, mmWave, depth) and produces quantitative contribution scores for each modality. These scores are passed to an RL agent, which dynamically adjusts sensor configurations, including sampling frequency, resolution, sensing range, and etc., in real time. Less informative sensors are down-sampled or deactivated, while critical sensors are sampled at higher fidelity as environmental conditions evolve. We implement and evaluate this framework on a mobile rover, showing that adaptive control reduces GPU load by 29.3\\% with only a 5.3\\% accuracy drop compared to a heuristic baseline. These results highlight the potential of resource-aware adaptive sensing for embedded robotic platforms.", "AI": {"tldr": "该论文介绍了一种在线多光谱传感器重新配置框架，以适应动态环境中的感知任务。", "motivation": "现有的机器人感知系统采用固定传感器配置，导致资源浪费并无法在复杂条件下优先使用关键传感器。为解决这一问题，提出了一个结合了感知识别、学习和操作的闭环重配置框架。", "method": "通过多光谱特征提取和贡献得分计算，在线调整各传感器的工作参数如采样频率、分辨率等；利用强化学习算法动态优化传感器配置。", "result": "在移动机器人平台上实现了该框架，与基于启发式策略的方法相比，GPU负载降低了29.3%，仅导致精度下降5.3%。结果表明资源感知的自适应传感对于嵌入式平台有潜力。", "conclusion": "证明了利用强化学习和多光谱特征分析可以实现动态环境中传感器的有效重配置，从而优化计算资源利用率并提升系统性能。"}}
{"id": "2602.10546", "pdf": "https://arxiv.org/pdf/2602.10546", "abs": "https://arxiv.org/abs/2602.10546", "authors": ["Hanzhe Yu", "Yun Ye", "Jintao Rong", "Qi Xuan", "Chen Ma"], "title": "RealHD: A High-Quality Dataset for Robust Detection of State-of-the-Art AI-Generated Images", "categories": ["cs.CV", "cs.AI"], "comment": "Published in the Proceedings of the 33rd ACM International Conference on Multimedia (ACM MM 2025)", "summary": "The rapid advancement of generative AI has raised concerns about the authenticity of digital images, as highly realistic fake images can now be generated at low cost, potentially increasing societal risks. In response, several datasets have been established to train detection models aimed at distinguishing AI-generated images from real ones. However, existing datasets suffer from limited generalization, low image quality, overly simple prompts, and insufficient image diversity. To address these limitations, we propose a high-quality, large-scale dataset comprising over 730,000 images across multiple categories, including both real and AI-generated images. The generated images are synthesized via state-of-the-art methods, including text-to-image generation (guided by over 10,000 carefully designed prompts), image inpainting, image refinement, and face swapping. Each generated image is annotated with its generation method and category. Inpainting images further include binary masks to indicate inpainted regions, providing rich metadata for analysis. Compared to existing datasets, detection models trained on our dataset demonstrate superior generalization capabilities. Our dataset not only serves as a strong benchmark for evaluating detection methods but also contributes to advancing the robustness of AI-generated image detection techniques. Building upon this, we propose a lightweight detection method based on image noise entropy, which transforms the original image into an entropy tensor of Non-Local Means (NLM) noise before classification. Extensive experiments demonstrate that models trained on our dataset achieve strong generalization, and our method delivers competitive performance, establishing a solid baseline for future research. The dataset and source code are publicly available at https://real-hd.github.io.", "AI": {"tldr": "构建了一个高质量的大规模数据集RealHD，用于训练检测AI生成图像的模型，并提出了一种基于图像噪声熵的轻量级检测方法。", "motivation": "针对现有的AI生成图像检测数据集存在泛化能力弱、图像质量低等问题，提出构建一个新的高质量数据集以提高检测模型的性能和鲁棒性。", "method": "通过使用最先进的文本到图像生成技术、图像修复、图像增强以及面部替换等方法生成了包含超过73万张图像的数据集，并引入了一种基于非局部均值噪声熵的方法来区分真实图像与AI生成图像。", "result": "实验表明，训练在该数据集上的模型表现出更强的泛化能力，所提出的方法也达到了竞争力的表现。", "conclusion": "RealHD不仅是一个评估检测方法的强大基准，还为提高AI生成图像检测技术的鲁棒性做出了贡献。"}}
{"id": "2602.10545", "pdf": "https://arxiv.org/pdf/2602.10545", "abs": "https://arxiv.org/abs/2602.10545", "authors": ["Yuxin Ma", "Nan Chen", "Mateo Díaz", "Soufiane Hayou", "Dmitriy Kunisky", "Soledad Villar"], "title": "$μ$pscaling small models: Principled warm starts and hyperparameter transfer", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "61 pages, 6 figures", "summary": "Modern large-scale neural networks are often trained and released in multiple sizes to accommodate diverse inference budgets. To improve efficiency, recent work has explored model upscaling: initializing larger models from trained smaller ones in order to transfer knowledge and accelerate convergence. However, this method can be sensitive to hyperparameters that need to be tuned at the target upscaled model size, which is prohibitively costly to do directly. It remains unclear whether the most common workaround -- tuning on smaller models and extrapolating via hyperparameter scaling laws -- is still sound when using upscaling. We address this with principled approaches to upscaling with respect to model widths and efficiently tuning hyperparameters in this setting. First, motivated by $μ$P and any-dimensional architectures, we introduce a general upscaling method applicable to a broad range of architectures and optimizers, backed by theory guaranteeing that models are equivalent to their widened versions and allowing for rigorous analysis of infinite-width limits. Second, we extend the theory of $μ$Transfer to a hyperparameter transfer technique for models upscaled using our method and empirically demonstrate that this method is effective on realistic datasets and architectures.", "AI": {"tldr": "该论文提出了一种新的微调和超参数迁移方法，以改善模型上采样的效率。", "motivation": "在使用上采样时，需要调整目标规模的超参数，这往往是成本高昂且不实际的。通过理论支持的方法来保证模型等价性，并证明了这种无限宽度极限的有效性。", "method": "首先引入了一种适用于各种架构和优化器的一般上采样方法；其次扩展了$μ$Transfer理论以适应模型使用该方法进行上采样的超参数迁移技术，这种方法在实际数据集和架构中有效。", "result": "结果表明，提出的超参数传递技术在现实世界的任务中是有效的，并且能够有效地加速收敛。", "conclusion": "通过提出的方法，可以更高效地执行模型上采样并且优化超参数的选择。"}}
{"id": "2602.10543", "pdf": "https://arxiv.org/pdf/2602.10543", "abs": "https://arxiv.org/abs/2602.10543", "authors": ["Andrew Adamatzky"], "title": "Fungal systems for security and resilience", "categories": ["cs.ET"], "comment": null, "summary": "Modern security, infrastructure, and safety-critical systems increasingly operate in environments characterised by disruption, uncertainty, physical damage, and degraded communications. Conventional digital technologies -- centralised sensors, software-defined control, and energy-intensive monitoring -- often struggle under such conditions. We propose fungi, and in particular living mycelial networks, as a novel class of biohybride systems for security, resilience, and protection in extreme environments. We discuss how fungi can function as distributed sensing substrates, self-healing materials, and low-observability anomaly-detection layers. We map fungal properties -- such as decentralised control, embodied memory, and autonomous repair -- to applications in infrastructure protection, environmental monitoring, tamper evidence, and long-duration resilience.", "AI": {"tldr": "提出使用真菌，特别是活的菌丝网络作为新型生物混合系统，以增强极端环境下的安全、弹性和保护能力。", "motivation": "在存在干扰、不确定性、物理损坏和通信退化等条件下，传统数字技术难以有效运行。因此，探索一种新的生物混合系统来提高安全与恢复力是必要的。", "method": "研究真菌的分布式传感基质功能、自愈材料特性以及低可观察性异常检测层的应用，并将真菌特性（如去中心化的控制能力、嵌入式记忆和自主修复）映射到基础设施保护、环境监测等领域。", "result": "展示了真菌系统在提高极端条件下的安全与恢复力方面的潜力，特别是在分布式传感、自愈材料和低可观测性异常检测等方面的应用前景。", "conclusion": "提出了一种利用真菌作为新型生物混合系统的概念框架，该框架能够为基础设施保护、环境监测等领域提供有效的解决方案。"}}
{"id": "2602.10535", "pdf": "https://arxiv.org/pdf/2602.10535", "abs": "https://arxiv.org/abs/2602.10535", "authors": ["Kai Alexander Hackney", "Lucas Guarenti Zangari", "Jhonathan Sora-Cardenas", "Emmanuel Munoz", "Sterling R. Kalogeras", "Betsy DiSalvo", "Pedro Guillermo Feijoo-Garcia"], "title": "Exploring the Interplay Between Voice, Personality, and Gender in Human-Agent Interactions", "categories": ["cs.HC"], "comment": null, "summary": "To foster effective human-agent interactions, designers need to identify characteristics that could affect how agents are perceived and accepted, and to what extent they could impact rapport-building. Aiming to explore the role of user-agent synchrony, we assessed 388 participants to determine whether they could perceive personality traits from four artificial voices we selected and adapted from human samples, considering gender (male or female) and personality (introvert or extrovert) as grouping factors. Our findings suggest that participants were able to significantly differentiate female agents by personality, while male agents were not consistently distinguished. We also observed evidence of personality synchrony, where participants tended to perceive the first agent as more similar to their own personality, with this effect driven mainly by male participants, especially toward male agents. This paper contributes findings and insights to consider the interplay of user-agent personality and gender synchrony in the design of human-agent interactions.", "AI": {"tldr": "本文探讨了在人机交互中声音、性格和性别之间的关系，研究参与者如何根据人工声音区分不同的人格特质。", "motivation": "为了提高人类与代理之间交互的有效性，设计者需要识别可能影响代理感知和接受度的特征以及这些因素对建立联系的影响程度。", "method": "作者通过评估388名参与者来确定他们能否从四种基于人类样本选择和改编的人工声音中区分性格特质，并考虑性别（男性或女性）和个人性格（内向或外向）作为分组因素。", "result": "研究发现，参与者的反应表明他们能够显著地区分女性代理的性格特征，而男性代理则不一致。此外还观察到个性同步现象，即参与者倾向于认为第一个代理与自己的人格更相似，此效果主要由男性参与者驱动，尤其是在面对男性代理时。", "conclusion": "本文的研究成果和见解提供了在设计人类-代理交互中考虑用户与代理之间的人格和性别同步性的重要参考。"}}
