{"id": "2601.11522", "pdf": "https://arxiv.org/pdf/2601.11522", "abs": "https://arxiv.org/abs/2601.11522", "authors": ["Ruiheng Zhang", "Jingfeng Yao", "Huangxuan Zhao", "Hao Yan", "Xiao He", "Lei Chen", "Zhou Wei", "Yong Luo", "Zengmao Wang", "Lefei Zhang", "Dacheng Tao", "Bo Du"], "title": "UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation", "categories": ["cs.CV"], "comment": "Codes and models are available at https://github.com/ZrH42/UniX", "summary": "Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.", "AI": {"tldr": "介绍UniX模型，该模型旨在统一胸部X光图像的理解和生成任务。", "motivation": "现有的参数共享自回归架构在理解和生成两个任务中表现不佳，因为这两个任务目标冲突：语义抽象与像素级重构。因此需要一个新模型来同时提高理解能力和生成质量。", "method": "UniX将任务分为理解的自回归分支和高保真度生成的扩散分支，并引入跨模态自我注意机制动态引导生成过程。结合严格的数据清洗管道和多阶段训练策略，实现任务之间的协同合作。", "result": "在两个代表性基准测试中，UniX的理解性能（Micro-F1）提高了46.1%，生成质量（FD-RadDino）提升了24.2%。使用四分之一的LLM-CXR参数量实现了与特定任务模型相当的表现。", "conclusion": "该研究提出了一个可扩展的方法，在医学图像理解和生成方面建立了新的范式，证明了UniX在实现高性能的同时减少了对大量参数的需求。"}}
{"id": "2601.11517", "pdf": "https://arxiv.org/pdf/2601.11517", "abs": "https://arxiv.org/abs/2601.11517", "authors": ["Koyena Pal", "David Bau", "Chandan Singh"], "title": "Do explanations generalize across large reasoning models?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large reasoning models (LRMs) produce a textual chain of thought (CoT) in the process of solving a problem, which serves as a potentially powerful tool to understand the problem by surfacing a human-readable, natural-language explanation. However, it is unclear whether these explanations generalize, i.e. whether they capture general patterns about the underlying problem rather than patterns which are esoteric to the LRM. This is a crucial question in understanding or discovering new concepts, e.g. in AI for science. We study this generalization question by evaluating a specific notion of generalizability: whether explanations produced by one LRM induce the same behavior when given to other LRMs. We find that CoT explanations often exhibit this form of generalization (i.e. they increase consistency between LRMs) and that this increased generalization is correlated with human preference rankings and post-training with reinforcement learning. We further analyze the conditions under which explanations yield consistent answers and propose a straightforward, sentence-level ensembling strategy that improves consistency. Taken together, these results prescribe caution when using LRM explanations to yield new insights and outline a framework for characterizing LRM explanation generalization.", "AI": {"tldr": "研究大型推理模型（LRMs）生成的思维链（CoT）解释是否能跨模型推广。", "motivation": "探讨这些解释是否捕捉到问题的基本模式，而不是仅适用于特定LRM的独特模式。这在理解或发现新概念方面至关重要，特别是在AI用于科学领域时。", "method": "通过评估一种通用性观念来研究这个问题：一个LRM产生的CoT解释是否能够诱导其他LRMs产生相同的行为。", "result": "发现思维链解释通常表现出这种形式的推广（即它们提高了不同LRM之间的行为一致性），并且这种提高的一致性与人类偏好的排名和强化学习后的训练相关联。研究还提出了一种简单的句子级集成策略来改善一致性。", "conclusion": "这些结果建议在使用LRMs生成的新见解时需要谨慎，并为描述LRMs解释的普遍化提供了一个框架。"}}
{"id": "2601.11516", "pdf": "https://arxiv.org/pdf/2601.11516", "abs": "https://arxiv.org/abs/2601.11516", "authors": ["János Kramár", "Joshua Engels", "Zheng Wang", "Bilal Chughtai", "Rohin Shah", "Neel Nanda", "Arthur Conmy"], "title": "Building Production-Ready Probes For Gemini", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Frontier language model capabilities are improving rapidly. We thus need stronger mitigations against bad actors misusing increasingly powerful systems. Prior work has shown that activation probes may be a promising misuse mitigation technique, but we identify a key remaining challenge: probes fail to generalize under important production distribution shifts. In particular, we find that the shift from short-context to long-context inputs is difficult for existing probe architectures. We propose several new probe architecture that handle this long-context distribution shift. We evaluate these probes in the cyber-offensive domain, testing their robustness against various production-relevant shifts, including multi-turn conversations, static jailbreaks, and adaptive red teaming. Our results demonstrate that while multimax addresses context length, a combination of architecture choice and training on diverse distributions is required for broad generalization. Additionally, we show that pairing probes with prompted classifiers achieves optimal accuracy at a low cost due to the computational efficiency of probes. These findings have informed the successful deployment of misuse mitigation probes in user-facing instances of Gemini, Google's frontier language model. Finally, we find early positive results using AlphaEvolve to automate improvements in both probe architecture search and adaptive red teaming, showing that automating some AI safety research is already possible.", "AI": {"tldr": "本文介绍了为Gemini语言模型构建生产就绪的探针，以应对恶意行为者滥用的强大系统。", "motivation": "随着前沿语言模型能力的快速提升，需要更强有力的缓解措施来防止坏演员滥用这些系统。现有激活探针虽然有潜力作为缓解技术，但在关键分布变化下表现不佳。", "method": "提出了新的探针架构以处理长上下文输入的问题，并在对抗性网络攻击领域测试了这些探针的鲁棒性，包括多轮对话、静态破解和自适应红队。结合提示分类器优化了探测准确性。", "result": "研究发现使用multimax可以解决上下文长度问题，但需要多种架构选择和多样化分布训练才能广泛推广。自动进化算法AlphaEvolve展示了自动化改进探针架构和对抗性测试的潜力。", "conclusion": "这些研究成果促进了Gemini语言模型中滥用缓解探针的成功部署，并证明了部分AI安全研究可以通过自动化实现。"}}
{"id": "2601.11514", "pdf": "https://arxiv.org/pdf/2601.11514", "abs": "https://arxiv.org/abs/2601.11514", "authors": ["Yawar Siddiqui", "Duncan Frost", "Samir Aroudj", "Armen Avetisyan", "Henry Howard-Jenkins", "Daniel DeTone", "Pierre Moulon", "Qirui Wu", "Zhengqin Li", "Julian Straub", "Richard Newcombe", "Jakob Engel"], "title": "ShapeR: Robust Conditional 3D Shape Generation from Casual Captures", "categories": ["cs.CV", "cs.LG"], "comment": "Project Page: http://facebookresearch.github.io/ShapeR Video: https://www.youtube.com/watch?v=EbY30KAA55I", "summary": "Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art.", "AI": {"tldr": "本文提出了ShapeR，一种从随意捕获的图像序列中生成条件3D物体形状的新方法。", "motivation": "现有的3D形状生成方法通常需要干净、无遮挡和良好分割的数据输入，而在现实世界场景中这些条件难以满足。因此，研究者们希望开发出能够处理随意捕捉数据的方法。", "method": "ShapeR利用视觉惯性SLAM技术、3D检测算法和视觉语言模型从图像序列中提取稀疏点云、多视角图像和机器生成的描述文本，并采用校正流转换器来综合这些模态信息生成高质量的3D形状，同时引入了多种增强技术和训练策略以应对随意捕捉数据带来的挑战。", "result": "实验表明，ShapeR在新的评估基准上显著优于现有方法，在Chamfer距离度量上有2.7倍的改进。", "conclusion": "研究证明了ShapeR的有效性，它能够在复杂且随意捕获的数据条件下生成高质量的3D形状，并引入了一个包含178个物体和7种场景的新评估基准来验证其性能。"}}
{"id": "2601.11508", "pdf": "https://arxiv.org/pdf/2601.11508", "abs": "https://arxiv.org/abs/2601.11508", "authors": ["Emily Steiner", "Jianhao Zheng", "Henry Howard-Jenkins", "Chris Xie", "Iro Armeni"], "title": "ReScene4D: Temporally Consistent Semantic Instance Segmentation of Evolving Indoor 3D Scenes", "categories": ["cs.CV"], "comment": null, "summary": "Indoor environments evolve as objects move, appear, or disappear. Capturing these dynamics requires maintaining temporally consistent instance identities across intermittently captured 3D scans, even when changes are unobserved. We introduce and formalize the task of temporally sparse 4D indoor semantic instance segmentation (SIS), which jointly segments, identifies, and temporally associates object instances. This setting poses a challenge for existing 3DSIS methods, which require a discrete matching step due to their lack of temporal reasoning, and for 4D LiDAR approaches, which perform poorly due to their reliance on high-frequency temporal measurements that are uncommon in the longer-horizon evolution of indoor environments. We propose ReScene4D, a novel method that adapts 3DSIS architectures for 4DSIS without needing dense observations. It explores strategies to share information across observations, demonstrating that this shared context not only enables consistent instance tracking but also improves standard 3DSIS quality. To evaluate this task, we define a new metric, t-mAP, that extends mAP to reward temporal identity consistency. ReScene4D achieves state-of-the-art performance on the 3RScan dataset, establishing a new benchmark for understanding evolving indoor scenes.", "AI": {"tldr": "介绍并定义了稀疏4D室内语义实例分割（SIS）任务，提出了一种新的方法ReScene4D，用于在间歇捕获的3D扫描中保持对象实例的身份一致性。", "motivation": "现有3DSIS方法缺乏时间推理能力，而4D LiDAR方法依赖高频时间测量，在室内环境长时间演变的情况下表现不佳。因此，需要一种适应室内场景动态变化的新方法。", "method": "ReScene4D通过探索在不同观察之间共享信息的策略来改进现有的3DSIS架构，无需密集观测即可实现一致的实例跟踪并提高标准3DSIS质量。", "result": "提出了一种新的评估指标t-mAP，并在3RScan数据集上达到了最先进的性能，建立了理解动态室内场景的新基准。", "conclusion": "ReScene4D展示了通过共享跨观察信息来提升时空一致性的语义实例分割能力，在稀疏时间线上的4D室内场景中表现出色。"}}
{"id": "2601.11505", "pdf": "https://arxiv.org/pdf/2601.11505", "abs": "https://arxiv.org/abs/2601.11505", "authors": ["Miriam K. Wolff", "Peter Calhoun", "Eleonora Maria Aiello", "Yao Qin", "Sam F. Royston"], "title": "MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management", "categories": ["cs.LG", "cs.AI", "eess.SY", "q-bio.QM"], "comment": "22 pages, 5 figures, 7 supplementary figures, submitted to JDST", "summary": "Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.", "AI": {"tldr": "本文介绍了MetaboNet数据集，这是一个整合了多个公开的1型糖尿病管理数据集的大规模资源。", "motivation": "当前1型糖尿病管理的数据集存在碎片化和非标准化的问题，这阻碍了算法开发的数据整合、比较和推广。因此，本研究旨在建立一个统一且易于访问的数据资源来促进1型糖尿病算法的发展。", "method": "将多个公开的1型糖尿病数据集合并为MetaboNet数据集，并要求包含连续血糖监测（CGM）数据和胰岛素泵剂量记录。此外，当存在时还保留了碳水化合物摄入量和体育活动等辅助信息。", "result": "MetaboNet数据集包括3135名受试者，涵盖1228个患者年的重叠血糖监测和胰岛素数据，是现有单独基准数据集的规模要大得多。", "conclusion": "通过整合公共数据资源，MetaboNet可以提供更广泛、更具代表性的数据支持，从而提高算法性能的推广性。"}}
{"id": "2601.11499", "pdf": "https://arxiv.org/pdf/2601.11499", "abs": "https://arxiv.org/abs/2601.11499", "authors": ["Dimitar Nedanovski", "Svetoslav Nenov", "Dimitar Pilev"], "title": "On the Probability of First Success in Differential Evolution: Hazard Identities and Tail Bounds", "categories": ["cs.NE", "cs.LG"], "comment": "All codes are publically available at https://github.com/snenovgmailcom/lshade_hazard_project", "summary": "We study first-hitting times in Differential Evolution (DE) through a conditional hazard frame work. Instead of analyzing convergence via Markov-chain transition kernels or drift arguments, we ex press the survival probability of a measurable target set $A$ as a product of conditional first-hit probabilities (hazards) $p_t=\\Prob(E_t\\mid\\mathcal F_{t-1})$. This yields distribution-free identities for survival and explicit tail bounds whenever deterministic lower bounds on the hazard hold on the survival event. For the L-SHADE algorithm with current-to-$p$best/1 mutation, we construct a checkable algorithmic witness event $\\mathcal L_t$ under which the conditional hazard admits an explicit lower bound depending only on sampling rules, population size, and crossover statistics. This separates theoretical constants from empirical event frequencies and explains why worst-case constant-hazard bounds are typically conservative. We complement the theory with a Kaplan--Meier survival analysis on the CEC2017 benchmark suite . Across functions and budgets, we identify three distinct empirical regimes: (i) strongly clustered success, where hitting times concentrate in short bursts; (ii) approximately geometric tails, where a constant-hazard model is accurate; and (iii) intractable cases with no observed hits within the evaluation horizon. The results show that while constant-hazard bounds provide valid tail envelopes, the practical behavior of L-SHADE is governed by burst-like transitions rather than homogeneous per-generati on success probabilities.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.11496", "pdf": "https://arxiv.org/pdf/2601.11496", "abs": "https://arxiv.org/abs/2601.11496", "authors": ["Eilam Shapira", "Roi Reichart", "Moshe Tennenholtz"], "title": "The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents", "categories": ["cs.GT", "cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify a strategic phenomenon termed the \"Poisoned Apple\" effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator's choice of market design in their favor. This strategic release improves the releaser's welfare at the expense of their opponent and the regulator's fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.", "AI": {"tldr": "研究了AI代理技术扩展在经济市场中的战略影响，特别是在三种游戏理论设置中，并揭示了“毒苹果效应”。", "motivation": "探讨将AI代理整合到经济市场如何改变策略互动的格局，并分析增加可选AI技术对经济结果的影响。", "method": "采用博弈论方法，在资源分配、信息不对称交易和战略信息传递三种场景下研究AI代理的技术扩展影响。", "result": "发现增加AI代理的选择可以大幅改变均衡收益和监管结果，揭示了“毒苹果效应”，即一个代理人可能发布新技术以操纵监管者的市场设计选择。", "conclusion": "静态的市场监管框架容易受到技术扩张的战略性操纵，需要发展动态市场设计来应对不断演变的AI能力。"}}
{"id": "2601.11492", "pdf": "https://arxiv.org/pdf/2601.11492", "abs": "https://arxiv.org/abs/2601.11492", "authors": ["Kaiwen Wang", "Kaili Zheng", "Rongrong Deng", "Qingmin Fan", "Milin Zhang", "Zongrui Li", "Xuesi Zhou", "Bo Han", "Liren Chen", "Chenyi Guo", "Ji Wu"], "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics", "categories": ["cs.AI"], "comment": null, "summary": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.", "AI": {"tldr": "介绍BoxMind，一种用于精英拳击的闭环AI策略优化系统，并在2024年奥运会上进行了验证。", "motivation": "传统的战术分析在竞技体育中非常重要，但像拳击这样的格斗项目由于动作动态复杂和缺乏结构化的战术表示，在人工智能驱动的分析方面发展不足。", "method": "通过定义具有精确时间边界和技术属性的原子打击事件，将比赛视频解析为18个技术-战术指标。提出了一种基于图的预测模型，融合显式的技术-战术配置文件与可学习的时间变体潜在嵌入以捕捉拳手对战的动态。", "result": "实验表明，该结果预测模型在BoxerGraph测试集上达到了69.8%的准确率，在奥运比赛中达到87.5%，并生成的战略建议与人类专家相比具有相当的专业水平。系统在2024年巴黎奥运会上直接贡献了中国国家队的历史性成就。", "conclusion": "BoxMind为将非结构化视频数据转化为战略情报建立了一种可复制的范式，填补了计算机视觉和竞技体育决策支持之间的空白。"}}
{"id": "2601.11491", "pdf": "https://arxiv.org/pdf/2601.11491", "abs": "https://arxiv.org/abs/2601.11491", "authors": ["Ziqing Zeng", "Abhimanyu Kumar", "Chris H. Kim", "Ulya R. Karpuzcu", "Sachin S. Sapatnekar"], "title": "Extractive summarization on a CMOS Ising machine", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "Extractive summarization (ES) aims to generate a concise summary by selecting a subset of sentences from a document while maximizing relevance and minimizing redundancy. Although modern ES systems achieve high accuracy using powerful neural models, their deployment typically relies on CPU or GPU infrastructures that are energy-intensive and poorly suited for real-time inference in resource-constrained environments. In this work, we explore the feasibility of implementing McDonald-style extractive summarization on a low-power CMOS coupled oscillator-based Ising machine (COBI) that supports integer-valued, all-to-all spin couplings. We first propose a hardware-aware Ising formulation that reduces the scale imbalance between local fields and coupling terms, thereby improving robustness to coefficient quantization: this method can be applied to any problem formulation that requires k of n variables to be chosen. We then develop a complete ES pipeline including (i) stochastic rounding and iterative refinement to compensate for precision loss, and (ii) a decomposition strategy that partitions a large ES problem into smaller Ising subproblems that can be efficiently solved on COBI and later combined. Experimental results on the CNN/DailyMail dataset show that our pipeline can produce high-quality summaries using only integer-coupled Ising hardware with limited precision. COBI achieves 3-4.5x runtime speedups compared to a brute-force method, which is comparable to software Tabu search, and two to three orders of magnitude reductions in energy, while maintaining competitive summary quality. These results highlight the potential of deploying CMOS Ising solvers for real-time, low-energy text summarization on edge devices.", "AI": {"tldr": "本文探讨了在低功耗CMOS耦合振荡器基Ising机器（COBI）上实现麦当劳风格提取式摘要的可能性。", "motivation": "现代提取式总结系统虽然准确度高，但依赖于能耗大、不适合实时推理的CPU或GPU基础设施，因此本文旨在探索一种低功耗且适合资源受限环境的解决方案。", "method": "提出了一种硬件感知的Ising公式化方法，减少局部字段和耦合项之间的规模失衡，提高了对系数量化稳健性，并开发了一个包括随机舍入、迭代细化及问题分解策略的完整提取式总结管道。", "result": "实验结果表明，该管道使用仅有有限精度的整数耦合Ising硬件能产生高质量摘要，COBI相较于暴力方法实现了3-4.5倍的运行时间加速和两个到三个数量级的能量减少，同时保持了竞争力的摘要质量。", "conclusion": "本文证明了在边缘设备上部署CMOS Ising求解器进行实时、低能耗文本总结的可能性及其潜力。"}}
{"id": "2601.11488", "pdf": "https://arxiv.org/pdf/2601.11488", "abs": "https://arxiv.org/abs/2601.11488", "authors": ["Vanshali Sharma", "Andrea Mia Bejar", "Gorkem Durak", "Ulas Bagci"], "title": "CTest-Metric: A Unified Framework to Assess Clinical Validity of Metrics for CT Report Generation", "categories": ["cs.CL", "cs.CV"], "comment": "Accepted at ISBI 2026", "summary": "In the generative AI era, where even critical medical tasks are increasingly automated, radiology report generation (RRG) continues to rely on suboptimal metrics for quality assessment. Developing domain-specific metrics has therefore been an active area of research, yet it remains challenging due to the lack of a unified, well-defined framework to assess their robustness and applicability in clinical contexts. To address this, we present CTest-Metric, a first unified metric assessment framework with three modules determining the clinical feasibility of metrics for CT RRG. The modules test: (i) Writing Style Generalizability (WSG) via LLM-based rephrasing; (ii) Synthetic Error Injection (SEI) at graded severities; and (iii) Metrics-vs-Expert correlation (MvE) using clinician ratings on 175 \"disagreement\" cases. Eight widely used metrics (BLEU, ROUGE, METEOR, BERTScore-F1, F1-RadGraph, RaTEScore, GREEN Score, CRG) are studied across seven LLMs built on a CT-CLIP encoder. Using our novel framework, we found that lexical NLG metrics are highly sensitive to stylistic variations; GREEN Score aligns best with expert judgments (Spearman~0.70), while CRG shows negative correlation; and BERTScore-F1 is least sensitive to factual error injection. We will release the framework, code, and allowable portion of the anonymized evaluation data (rephrased/error-injected CT reports), to facilitate reproducible benchmarking and future metric development.", "AI": {"tldr": "开发了一个统一的评估框架CTest-Metric，用于在临床环境中评估CT报告生成的质量度量标准。", "motivation": "随着AI自动化在医疗任务中的应用增加，放射学报告生成仍依赖于次优的质量度量标准。缺乏一个统一的、定义明确的框架来评估这些度量标准在临床上的适用性是其研究面临的挑战。", "method": "CTest-Metric包含三个模块用于测试CT报告生成的质量：写作风格通用化、合成错误注入以及专家对比度量，使用了175个\"争议\"案例进行评估。八个广泛使用的指标被研究，并在七个基于CT-CLIP编码器的大型语言模型上进行了测试。", "result": "发现词汇自然语言处理指标对风格变化敏感；GREEN Score与专家判断的相关性最好（Spearman~0.70），而CRG显示负相关；BERTScore-F1对事实错误注入最不敏感。该框架将被公开以促进可重复的基准测试和未来度量的发展。", "conclusion": "CTest-Metric框架为评估CT报告生成的质量提供了一个新的、统一的方法，有助于改进临床环境下的放射学自动报告系统的质量评估标准。"}}
{"id": "2601.11479", "pdf": "https://arxiv.org/pdf/2601.11479", "abs": "https://arxiv.org/abs/2601.11479", "authors": ["Yohai Trabelsi", "Guojun Xiong", "Fentabil Getnet", "Stéphane Verguet", "Milind Tambe"], "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning", "categories": ["cs.AI"], "comment": null, "summary": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.", "AI": {"tldr": "本文提出了一种将专家知识与优化技术相结合的混合框架，以解决埃塞俄比亚升级卫生设施的问题。", "motivation": "鉴于资源有限，需要在最大化人口覆盖率的同时考虑到多元化的专家和利益相关者的偏好。为了实现这一点，研究者开发了LEG框架来整合难以形式化的人类专业知识，并通过算法优化来改善农村地区的医疗服务。", "method": "本文开发了一个结合大型语言模型（LLM）驱动的迭代改进和具有理论保证的经典近似算法的框架（LEG），用于人口覆盖率优化并确保解决方案反映专家定性指导的同时保持覆盖保障。", "result": "在埃塞俄比亚三个地区的真实世界数据上的实验表明，该框架的有效性和其潜力可以用来制定公平、基于数据驱动的健康系统规划。", "conclusion": "本文提出的LEG框架成功地整合了专家知识与算法优化技术，证明了其在改善卫生设施位置选择方面的有效性，有助于实现更加公平和有效的农村医疗服务。"}}
{"id": "2601.11475", "pdf": "https://arxiv.org/pdf/2601.11475", "abs": "https://arxiv.org/abs/2601.11475", "authors": ["Rajeev Yasarla", "Deepti Hegde", "Shizhong Han", "Hsin-Pai Cheng", "Yunxiao Shi", "Meysam Sadeghigooghari", "Shweta Mahajan", "Apratim Bhattacharyya", "Litian Liu", "Risheek Garrepalli", "Thomas Svantesson", "Fatih Porikli", "Hong Cai"], "title": "Generative Scenario Rollouts for End-to-End Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language-Action (VLA) models are emerging as highly effective planning models for end-to-end autonomous driving systems. However, current works mostly rely on imitation learning from sparse trajectory annotations and under-utilize their potential as generative models. We propose Generative Scenario Rollouts (GeRo), a plug-and-play framework for VLA models that jointly performs planning and generation of language-grounded future traffic scenes through an autoregressive rollout strategy. First, a VLA model is trained to encode ego vehicle and agent dynamics into latent tokens under supervision from planning, motion, and language tasks, facilitating text-aligned generation. Next, GeRo performs language-conditioned autoregressive generation. Given multi-view images, a scenario description, and ego-action questions, it generates future latent tokens and textual responses to guide long-horizon rollouts. A rollout-consistency loss stabilizes predictions using ground truth or pseudo-labels, mitigating drift and preserving text-action alignment. This design enables GeRo to perform temporally consistent, language-grounded rollouts that support long-horizon reasoning and multi-agent planning. On Bench2Drive, GeRo improves driving score and success rate by +15.7 and +26.2, respectively. By integrating reinforcement learning with generative rollouts, GeRo achieves state-of-the-art closed-loop and open-loop performance, demonstrating strong zero-shot robustness. These results highlight the promise of generative, language-conditioned reasoning as a foundation for safer and more interpretable end-to-end autonomous driving.", "AI": {"tldr": "本文提出了用于端到端自动驾驶系统的生成场景滚动（GeRo）框架，通过自回归策略进行规划和基于语言的未来交通场景生成。", "motivation": "现有的Vision-Language-Action (VLA)模型在自主驾驶系统中的应用主要依赖于模仿学习，并且没有充分发挥其作为生成模型的潜力。", "method": "首先训练VLA模型将自我车辆和代理动态编码为潜在令牌，然后进行基于语言条件下的自回归生成，以指导长期滚动预测。通过回滚一致性损失来稳定预测并减少漂移。", "result": "在Bench2Drive测试中，GeRo提高了驾驶得分和成功率（分别提高15.7%和26.2%），并且结合强化学习后，在封闭循环和开放循环性能上达到最新技术水平，展示出强大的零样本鲁棒性。", "conclusion": "这些结果突显了基于生成模型的、语言条件下的推理作为更安全和可解释的端到端自主驾驶系统基础的重要潜力。"}}
{"id": "2601.11468", "pdf": "https://arxiv.org/pdf/2601.11468", "abs": "https://arxiv.org/abs/2601.11468", "authors": ["Alessandro Padella", "Massimiliano de Leoni", "Marlon Dumas"], "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs", "categories": ["cs.AI", "cs.IT"], "comment": "19 pages, 4 figure, TMIS journal submission", "summary": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.", "AI": {"tldr": "本文扩展了基于LLM的预测性过程监控框架，评估其在小规模事件日志中的性能。", "motivation": "为了探索LLM在数据稀缺情况下的泛化能力、语义利用和推理机制，并对比传统方法进行验证。", "method": "通过在三个不同的事件日志上进行实验，评估总时间和活动发生预测的多个关键绩效指标。", "result": "结果显示，在仅包含100条轨迹的数据稀缺设置下，LLM的表现优于基准方法。", "conclusion": "研究表明，LLM不仅利用其内在的知识和训练轨迹间的内部相关性进行推理，还展示了高级别的推理策略以生成预测。"}}
{"id": "2601.11464", "pdf": "https://arxiv.org/pdf/2601.11464", "abs": "https://arxiv.org/abs/2601.11464", "authors": ["Xiaoran Fan", "Zhichao Sun", "Tao Ji", "Lixing Shen", "Tao Gui"], "title": "MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, we present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. Our approach features two core techniques: (1) a modality-adaptive partial-RoPE strategy that supports both traditional and multimodal settings by selectively masking nonessential dimensions, and (2) a modality-decoupled low-rank approximation method that independently compresses the visual and textual KV spaces. Furthermore, we introduce parameter-efficient fine-tuning to minimize adaptation cost and demonstrate that minimizing output activation error, rather than parameter distance, substantially reduces performance loss. Extensive experiments on three representative VLMs show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.", "AI": {"tldr": "本文提出了MHA2MLA-VLM，一种参数高效且多模态感知的框架，用于将现成的视觉语言模型转换为多头潜在注意力架构。", "motivation": "随着视觉语言模型处理越来越复杂的多模态任务，KV缓存快速增长带来了显著的内存和计算瓶颈。现有的Multi-Head Latent Attention（MLA）虽然能有效压缩KV缓存并加速推理，但如何低成本地将现有VLM转换到这种架构中尚未得到充分研究。", "method": "本文方法包括两个核心技巧：（1）模态自适应部分RoPE策略，支持传统和多模态设置；（2）模态解耦低秩逼近法，独立压缩视觉和文本KV空间，并采用参数高效微调以减少转换成本。", "result": "在三个代表性VLM上的广泛实验表明，MHA2MLA-VLM能够使用最少的监督数据恢复原始模型性能，显著减小KV缓存占用，并与KV量化无缝集成。", "conclusion": "结论指出，通过提出的方法，可以将现有的视觉语言模型高效转换为多头潜在注意力架构，同时减少内存和计算资源消耗。"}}
{"id": "2601.11460", "pdf": "https://arxiv.org/pdf/2601.11460", "abs": "https://arxiv.org/abs/2601.11460", "authors": ["Franziska Herbert", "Vignesh Prasad", "Han Liu", "Dorothea Koert", "Georgia Chalvatzaki"], "title": "Learning Semantic-Geometric Task Graph-Representations from Human Demonstrations", "categories": ["cs.RO", "cs.LG"], "comment": "9 pages, 7 figures, preprint", "summary": "Learning structured task representations from human demonstrations is essential for understanding long-horizon manipulation behaviors, particularly in bimanual settings where action ordering, object involvement, and interaction geometry can vary significantly. A key challenge lies in jointly capturing the discrete semantic structure of tasks and the temporal evolution of object-centric geometric relations in a form that supports reasoning over task progression. In this work, we introduce a semantic-geometric task graph-representation that encodes object identities, inter-object relations, and their temporal geometric evolution from human demonstrations. Building on this formulation, we propose a learning framework that combines a Message Passing Neural Network (MPNN) encoder with a Transformer-based decoder, decoupling scene representation learning from action-conditioned reasoning about task progression. The encoder operates solely on temporal scene graphs to learn structured representations, while the decoder conditions on action-context to predict future action sequences, associated objects, and object motions over extended time horizons. Through extensive evaluation on human demonstration datasets, we show that semantic-geometric task graph-representations are particularly beneficial for tasks with high action and object variability, where simpler sequence-based models struggle to capture task progression. Finally, we demonstrate that task graph representations can be transferred to a physical bimanual robot and used for online action selection, highlighting their potential as reusable task abstractions for downstream decision-making in manipulation systems.", "AI": {"tldr": "本文提出了语义几何任务图表示法，从人类演示中学习结构化任务表示，并通过一个结合了消息传递神经网络（MPNN）编码器和基于Transformer的解码器的学习框架来实现这一点。", "motivation": "理解长周期操作行为，特别是在双臂设置中的动作顺序、物体参与和交互几何变化显著的情况下，需要从人类演示中学习结构化任务表示法。", "method": "提出了一种结合MPNN编码器和基于Transformer的解码器的学习框架，该框架能够单独处理时间场景图以学习结构化的表示，并在行动条件控制下预测未来动作序列、相关物体及物体运动。", "result": "通过广泛的人类演示数据集评估表明，语义几何任务图表示对具有高动作和对象变化性的任务尤其有益，简单的时间序列模型难以捕捉任务进展。", "conclusion": "双臂机器人可以使用从人类示范中学到的任务图表示进行在线动作选择，这表明了它们作为操纵系统中可重复使用的任务抽象的潜力。"}}
{"id": "2601.11459", "pdf": "https://arxiv.org/pdf/2601.11459", "abs": "https://arxiv.org/abs/2601.11459", "authors": ["Brian Keith"], "title": "Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.IR"], "comment": "17 pages, 5 figures, published in IEEE Access as open access paper", "summary": "Information overload and misinformation create significant challenges in extracting meaningful narratives from large news collections. This paper defines the nascent field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA approaches enable the interactive exploration of narrative structures through computational methods and visual interfaces that facilitate human interpretation. The field faces challenges in scalability, interactivity, knowledge integration, and evaluation standardization, yet offers promising opportunities across news analysis, intelligence, scientific literature exploration, and social media analysis. Through the combination of computational and human insight, INA addresses complex challenges in narrative sensemaking.", "AI": {"tldr": "本文介绍了交互叙事分析（INA）领域，该领域结合了计算叙事提取和互动可视化分析，以支持意义构建。", "motivation": "信息过载和虚假信息在从大量新闻集合中提取有意义的叙述方面带来了重大挑战，因此提出了交互叙事分析的概念来解决这些问题。", "method": "通过将计算方法与视觉界面相结合，INA允许对叙事结构进行互动探索，并促进人类解读。", "result": "该研究领域面临可扩展性、互动性、知识整合和评估标准制定的挑战，但也为新闻分析、情报、科学文献探索和社会媒体分析等提供了机会。", "conclusion": "通过结合计算洞察力和人类见解，INA能够应对叙述意义构建中的复杂挑战。"}}
{"id": "2601.11451", "pdf": "https://arxiv.org/pdf/2601.11451", "abs": "https://arxiv.org/abs/2601.11451", "authors": ["Oishee Bintey Hoque", "Nibir Chandra Mandal", "Kyle Luong", "Amanda Wilson", "Samarth Swarup", "Madhav Marathe", "Abhijin Adiga"], "title": "PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Large-scale livestock operations pose significant risks to human health and the environment, while also being vulnerable to threats such as infectious diseases and extreme weather events. As the number of such operations continues to grow, accurate and scalable mapping has become increasingly important. In this work, we present an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) from aerial and satellite imagery. Our method (1) detects candidate infrastructure (e.g., barns, feedlots, manure lagoons, silos) with a domain-tuned YOLOv8 detector, then derives SAM2 masks from these boxes and filters component-specific criteria, (2) extracts structured descriptors (e.g., counts, areas, orientations, and spatial relations) and fuses them with deep visual features using a lightweight spatial cross-attention classifier, and (3) outputs both CAFO type predictions and mask-level attributions that link decisions to visible infrastructure. Through comprehensive evaluation, we show that our approach achieves state-of-the-art performance, with Swin-B+PRISM-CAFO surpassing the best performing baseline by up to 15\\%. Beyond strong predictive performance across diverse U.S. regions, we run systematic gradient--activation analyses that quantify the impact of domain priors and show ho", "AI": {"tldr": "本文提出了一个用于识别和表征集中式动物饲养操作（CAFOs）的基础设施优先、可解释性管道，通过空中和卫星图像。", "motivation": "大规模畜禽养殖对人类健康和环境构成重大风险，并且容易受到传染病和极端天气事件等威胁。随着此类设施数量的增长，准确而规模化的映射变得越来越重要。", "method": "本文的方法包括：(1) 使用域调整的YOLOv8检测器识别候选基础设施（如畜舍、饲料场、粪便池、粮仓），并从中导出SAM2掩码和应用特定组件标准过滤；(2) 提取结构描述符（例如计数、区域、方向、空间关系）并与深度视觉特征融合，使用轻量级空间交叉注意力分类器；(3) 输出CAFO类型预测以及与可见基础设施相关联的遮罩级别归因。", "result": "通过全面评估，本文的方法达到最先进的性能水平，Swin-B+PRISM-CAFO比最佳基准模型高出最多15%。此外，该方法在不同的美国地区展现出强大的预测性能，并且系统地分析了领域先验的影响。", "conclusion": "研究证明了提出的方法能够实现对集中式动物饲养操作的有效识别和表征，并展示了其优越的性能以及通过结构化描述符和深度视觉特征融合来提高准确性的潜力。"}}
{"id": "2601.11444", "pdf": "https://arxiv.org/pdf/2601.11444", "abs": "https://arxiv.org/abs/2601.11444", "authors": ["Raphaël Razafindralambo", "Rémy Sun", "Frédéric Precioso", "Damien Garreau", "Pierre-Alexandre Mattei"], "title": "When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models", "categories": ["cs.LG", "cs.CV", "math.ST", "stat.ME", "stat.ML"], "comment": "Accepted at TMLR. Code: https://github.com/rarazafin/score_diffusion_ensemble", "summary": "Diffusion models now generate high-quality, diverse samples, with an increasing focus on more powerful models. Although ensembling is a well-known way to improve supervised models, its application to unconditional score-based diffusion models remains largely unexplored. In this work we investigate whether it provides tangible benefits for generative modelling. We find that while ensembling the scores generally improves the score-matching loss and model likelihood, it fails to consistently enhance perceptual quality metrics such as FID on image datasets. We confirm this observation across a breadth of aggregation rules using Deep Ensembles, Monte Carlo Dropout, on CIFAR-10 and FFHQ. We attempt to explain this discrepancy by investigating possible explanations, such as the link between score estimation and image quality. We also look into tabular data through random forests, and find that one aggregation strategy outperforms the others. Finally, we provide theoretical insights into the summing of score models, which shed light not only on ensembling but also on several model composition techniques (e.g. guidance).", "AI": {"tldr": "研究了扩散模型的集成方法是否能提升生成质量，并探讨其理论基础。", "motivation": "虽然集合是提高监督模型性能的一种常用方法，但在无条件评分扩散模型中的应用尚未得到充分探索，本文旨在探究这种方法是否能够带来实质性的益处。", "method": "通过在CIFAR-10和FFHQ数据集上使用深度集成、蒙特卡洛丢弃等不同的聚合规则来验证积分评分对图像生成质量的影响，并在表格数据中采用随机森林进行对比分析。", "result": "发现虽然积分评分一般能改善评分匹配损失和模型可能性，但在提高感知质量度量如FID上的效果并不一致；而在表格数据中一种聚合同策优于其他策略。", "conclusion": "提供了关于评分模型汇总的理论见解，并指出集成方法不仅对集成本身有意义，还对多种模型组合技术有启示作用。"}}
{"id": "2601.11442", "pdf": "https://arxiv.org/pdf/2601.11442", "abs": "https://arxiv.org/abs/2601.11442", "authors": ["Xiangjun Gao", "Zhensong Zhang", "Dave Zhenyu Chen", "Songcen Xu", "Long Quan", "Eduardo Pérez-Pellitero", "Youngkyoon Jang"], "title": "Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D VLMs. The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations, including vector operations, bounding-box distances, and occlusion-aware appearance order cues, producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision, closely matching the 60.9% baseline trained with the full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.", "AI": {"tldr": "提出Map2Thought框架，实现3D视觉语言模型的明确可解释的空间推理。", "motivation": "现有的方法在处理3D空间理解和几何关系时缺乏透明度和精确性，本研究旨在开发一个可以提供明确且可理解的3D空间推理机制。", "method": "Map2Thought框架包括两个关键组件：Metric Cognitive Map（用于统一的空间表示）和Cognitive Chain-of-Thought（基于确定性操作进行显式几何推理）。", "result": "实验结果显示，与完全监督训练相比，使用一半的监督数据，Map2Thought达到了59.9%的准确率。在不同规模的数据集子集中测试时，分别比最先进的方法高出5.3%，4.8%和4.0%。", "conclusion": "研究表明，通过结合Metric-CogMap和Cog-CoT，Map2Thought能够实现对三维结构有解释力的理解，并显著提高了性能。"}}
{"id": "2601.11441", "pdf": "https://arxiv.org/pdf/2601.11441", "abs": "https://arxiv.org/abs/2601.11441", "authors": ["Xiaojie Gu", "Guangxu Chen", "Yuheng Yang", "Jingxin Han", "Andi Zhang"], "title": "Hierarchical Orthogonal Residual Spread for Precise Massive Editing in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICASSP 2026", "summary": "Large language models (LLMs) exhibit exceptional performance across various domains, yet they face critical safety concerns. Model editing has emerged as an effective approach to mitigate these issues. Existing model editing methods often focus on optimizing an information matrix that blends new and old knowledge. While effective, these approaches can be computationally expensive and may cause conflicts. In contrast, we shift our attention to Hierarchical Orthogonal Residual SprEad of the information matrix, which reduces noisy gradients and enables more stable edits from a different perspective. We demonstrate the effectiveness of our method HORSE through a clear theoretical comparison with several popular methods and extensive experiments conducted on two datasets across multiple LLMs. The results show that HORSE maintains precise massive editing across diverse scenarios. The code is available at https://github.com/XiaojieGu/HORSE", "AI": {"tldr": "本文提出了一种名为HORSE的方法，通过分层正交残差传播来提高大型语言模型的大规模精确编辑能力。", "motivation": "虽然现有的模型编辑方法有效，但它们计算成本高且可能引起冲突。因此，需要一种更稳定和高效的编辑方法来改善大型语言模型的安全性问题。", "method": "HORSE通过分层正交残差传播技术减少噪声梯度并实现信息矩阵的优化，从而使得大规模精确编辑更加稳定。", "result": "实验结果表明，与几种流行的方法相比，HORSE在两个数据集上对多个大型语言模型进行了广泛的测试，并显示出维持跨多种场景下的精准大规模编辑的能力。", "conclusion": "通过理论对比和大量实验证明了HORSE方法的有效性，提供了更稳定、高效的大型语言模型编辑解决方案。"}}
{"id": "2601.11440", "pdf": "https://arxiv.org/pdf/2601.11440", "abs": "https://arxiv.org/abs/2601.11440", "authors": ["Francisco Giral", "Álvaro Manzano", "Ignacio Gómez", "Ricardo Vinuesa", "Soledad Le Clainche"], "title": "GenDA: Generative Data Assimilation on Complex Urban Areas via Classifier-Free Diffusion Guidance", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort, yet remains challenging when only sparse sensor data are available. We propose GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics (CFD) simulations and interprets classifier-free guidance as a learned posterior reconstruction mechanism: the unconditional branch learns a geometry-aware flow prior, while the sensor-conditioned branch injects observational constraints during sampling. This formulation enables obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. We consider both sparse fixed sensors and trajectory-based observations using the same reconstruction procedure. When evaluated against supervised graph neural network (GNN) baselines and classical reduced-order data assimilation methods, GenDA reduces the relative root-mean-square error (RRMSE) by 25-57% and increases the structural similarity index (SSIM) by 23-33% across the tested meshes. Experiments are conducted on Reynolds-averaged Navier-Stokes (RANS) simulations of a real urban neighbourhood in Bristol, United Kingdom, at a characteristic Reynolds number of $\\mathrm{Re}\\approx2\\times10^{7}$, featuring complex building geometry and irregular terrain. The proposed framework provides a scalable path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.", "AI": {"tldr": "本文提出了GenDA，一种基于生成式数据同化框架的高分辨率风场重建方法，适用于复杂城市区域。", "motivation": "城市风流的重建对于评估空气质量、热量扩散和行人舒适度至关重要，但当只有稀疏传感器数据可用时，这仍然是一个挑战。", "method": "GenDA采用多尺度图神经网络架构，并通过无分类器指导机制将观测约束注入采样过程中。该模型从计算流体动力学（CFD）模拟中训练，能够基于几何感知的流动先验进行障碍物敏感的重建和泛化。", "result": "相较于监督学习的GNN基线和经典的降阶数据同化方法，GenDA降低了25-57%的相对均方根误差（RRMSE），并提升了23-33%的结构相似性指数（SSIM）。", "conclusion": "该框架为复杂环境监测提供了一条可扩展路径，并能在不重新训练的情况下处理未知几何形状、风向和网格分辨率。"}}
{"id": "2601.11429", "pdf": "https://arxiv.org/pdf/2601.11429", "abs": "https://arxiv.org/abs/2601.11429", "authors": ["Yuetian Lu", "Yihong Liu", "Hinrich Schütze"], "title": "Relational Linearity is a Predictor of Hallucinations", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 4 figures, 8 tables", "summary": "Hallucination is a central failure mode in large language models (LLMs). We focus on hallucinations of answers to questions like: \"Which instrument did Glenn Gould play?\", but we ask these questions for synthetic entities that are unknown to the model. Surprisingly, we find that medium-size models like Gemma-7B-IT frequently hallucinate, i.e., they have difficulty recognizing that the hallucinated fact is not part of their knowledge. We hypothesize that an important factor in causing these hallucinations is the linearity of the relation: linear relations tend to be stored more abstractly, making it difficult for the LLM to assess its knowledge; the facts of nonlinear relations tend to be stored more directly, making knowledge assessment easier. To investigate this hypothesis, we create SyntHal, a dataset of 6000 synthetic entities for six relations. In our experiments with four models, we determine, for each relation, the hallucination rate on SyntHal and also measure its linearity, using $Δ\\cos$. We find a strong correlation ($r \\in [.78,.82]$) between relational linearity and hallucination rate, providing evidence for our hypothesis that the underlying storage of triples of a relation is a factor in how well a model can self-assess its knowledge. This finding has implications for how to manage hallucination behavior and suggests new research directions for improving the representation of factual knowledge in LLMs.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.11426", "pdf": "https://arxiv.org/pdf/2601.11426", "abs": "https://arxiv.org/abs/2601.11426", "authors": ["Abdelrahman Ramadan", "Sidney Givigi"], "title": "Learning-Based Shrinking Disturbance-Invariant Tubes for State- and Input-Dependent Uncertainty", "categories": ["eess.SY", "cs.RO", "math.OC"], "comment": "ef:IEEE Control Systems Letters, vol. 9, pp. 2699-2704, Dec. 2025", "summary": "We develop a learning-based framework for constructing shrinking disturbance-invariant tubes under state- and input-dependent uncertainty, intended as a building block for tube Model Predictive Control (MPC), and certify safety via a lifted, isotone (order-preserving) fixed-point map. Gaussian Process (GP) posteriors become $(1-α)$ credible ellipsoids, then polytopic outer sets for deterministic set operations. A two-time-scale scheme separates learning epochs, where these polytopes are frozen, from an inner, outside-in iteration that converges to a compact fixed point $Z^\\star\\!\\subseteq\\!\\mathcal G$; its state projection is RPI for the plant. As data accumulate, disturbance polytopes tighten, and the associated tubes nest monotonically, resolving the circular dependence between the set to be verified and the disturbance model while preserving hard constraints. A double-integrator study illustrates shrinking tube cross-sections in data-rich regions while maintaining invariance.", "AI": {"tldr": "本文开发了一种基于学习的框架，用于在状态和输入依赖性不确定性下构建收缩扰动不变管，并作为管模型预测控制（MPC）的构建模块。", "motivation": "目的是解决传统方法中验证集与扰动模型之间的循环依赖问题，并通过累积数据逐步缩小扰动多面体以提高安全性和效率。", "method": "使用高斯过程（GP）后验形成可信椭球，转化为确定性集合操作的多面体外集。采用两时间尺度方案分离学习周期和内部迭代。", "result": "随着数据积累，扰动多面体紧缩，并且相关的管单调嵌套，实现了在数据丰富区域收缩管截面的同时保持不变性。", "conclusion": "研究表明提出的基于学习的方法可以有效地解决状态-输入依赖不确定性下的安全控制问题，为模型预测控制提供了一种新的方法。"}}
{"id": "2601.11425", "pdf": "https://arxiv.org/pdf/2601.11425", "abs": "https://arxiv.org/abs/2601.11425", "authors": ["Hunter Heidenreich", "Yosheb Getachew", "Olivia Dinica", "Ben Elliott"], "title": "PubMed-OCR: PMC Open Access OCR Annotations", "categories": ["cs.CV", "cs.CL", "cs.DL", "cs.LG"], "comment": null, "summary": "PubMed-OCR is an OCR-centric corpus of scientific articles derived from PubMed Central Open Access PDFs. Each page image is annotated with Google Cloud Vision and released in a compact JSON schema with word-, line-, and paragraph-level bounding boxes. The corpus spans 209.5K articles (1.5M pages; ~1.3B words) and supports layout-aware modeling, coordinate-grounded QA, and evaluation of OCR-dependent pipelines. We analyze corpus characteristics (e.g., journal coverage and detected layout features) and discuss limitations, including reliance on a single OCR engine and heuristic line reconstruction. We release the data and schema to facilitate downstream research and invite extensions.", "AI": {"tldr": "本论文介绍了PubMed-OCR，这是一个从PubMed Central开放访问PDF中提取的科学文章OCR中心语料库。", "motivation": "动机是创建一个大规模的OCR标注数据集，以支持布局感知建模、基于坐标的问答和依赖OCR的工作流程评估。", "method": "使用Google Cloud Vision对每页图像进行注释，并发布紧凑的JSON架构，包含词级、行级和段落级边界框。", "result": "构建了涵盖209.5K篇文章（150万页；约13亿字）的语料库，并分析了期刊覆盖率和检测到的布局特性等语料库特征。", "conclusion": "论文讨论了局限性，如仅依赖单一OCR引擎和启发式行重建方法，并发布了数据和架构以促进后续研究。"}}
{"id": "2601.11421", "pdf": "https://arxiv.org/pdf/2601.11421", "abs": "https://arxiv.org/abs/2601.11421", "authors": ["Ziyu Wang", "Chenyuan Liu", "Yushun Xiang", "Runhao Zhang", "Qingbo Hao", "Hongliang Lu", "Houyu Chen", "Zhizhong Feng", "Kaiyue Zheng", "Dehao Ye", "Xianchao Zeng", "Xinyu Zhou", "Boran Wen", "Jiaxin Li", "Mingyu Zhang", "Kecheng Zheng", "Qian Zhu", "Ran Cheng", "Yong-Lu Li"], "title": "The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflect the differentiated performance of various methods proposed by different teams and evaluated on different tasks? To address these issues, we introduce the Great March 100 (\\textbf{GM-100}) as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs. These tasks are developed through systematic analysis and expansion of existing task designs, combined with insights from human-object interaction primitives and object affordances. We collect a large amount of trajectory data on different robotic platforms and evaluate several baseline models. Experimental results demonstrate that the GM-100 tasks are 1) feasible to execute and 2) sufficiently challenging to effectively differentiate the performance of current VLA models. Our data and code are available at https://rhos.ai/research/gm-100.", "AI": {"tldr": "介绍了Great March 100 (GM-100)，这是一个包含100个详细任务的集合，用于评估和提高机器人代理的能力。", "motivation": "当前机器人学习和模仿学习的数据集及任务设计缺乏系统的考虑和原则，该研究旨在通过系统设计的任务来全面评价机器人的能力，并促进数据集中任务多样性和复杂性的提升。", "method": "GM-100包含100个精心设计的任务，这些任务覆盖了广泛的交互行为和长尾行为，基于现有任务设计的系统分析扩展以及人类对象互动基本原理和物体可用性洞察而开发。", "result": "实验表明，GM-100任务既可行又具有足够的挑战性，可以有效区分当前模型的表现，并收集了大量的不同机器人平台上的轨迹数据以评估基线模型。", "conclusion": "GM-100提供了一个全面的、多样化的和具有挑战性的任务集来评估机器人代理的能力，有助于推动机器学习研究的发展。"}}
{"id": "2601.11417", "pdf": "https://arxiv.org/pdf/2601.11417", "abs": "https://arxiv.org/abs/2601.11417", "authors": ["Tyler Reinmund", "Lars Kunze", "Marina Jirotka"], "title": "Sociotechnical Challenges of Machine Learning in Healthcare and Social Welfare", "categories": ["cs.HC"], "comment": "6 pages, short form, work-in-progress, conceptual paper", "summary": "Sociotechnical challenges of machine learning in healthcare and social welfare are mismatches between how a machine learning tool functions and the structure of care practices. While prior research has documented many such issues, existing accounts often attribute them either to designers' limited social understanding or to inherent technical constraints, offering limited support for systematic description and comparison across settings. In this paper, we present a framework for conceptualizing sociotechnical challenges of machine learning grounded in qualitative fieldwork, a review of longitudinal deployment studies, and co-design workshops with healthcare and social welfare practitioners. The framework comprises (1) a categorization of eleven sociotechnical challenges organized along an ML-enabled care pathway, and (2) a process-oriented account of the conditions through which these challenges emerge across design and use. By providing a parsimonious vocabulary and an explanatory lens focused on practice, this work supports more precise analysis of how machine learning tools function and malfunction within real-world care delivery.", "AI": {"tldr": "本文提出一个框架，用以概念化机器学习在医疗和社会福利中遇到的社会技术挑战。", "motivation": "现有研究将社会技术问题归因于设计者对社会理解的局限或固有的技术限制，缺乏系统描述和跨设置比较的支持。", "method": "基于质性田野调查、纵向部署研究回顾及与医疗和社会福利从业者共设计工作坊。", "result": "提出了包含沿机器学习赋能护理路径组织的十一个社会技术挑战分类以及这些挑战在设计和使用中出现的过程导向账户框架。", "conclusion": "该工作支持对现实世界护理交付中的机器学习工具如何运行和故障进行更精确分析。"}}
{"id": "2601.11409", "pdf": "https://arxiv.org/pdf/2601.11409", "abs": "https://arxiv.org/abs/2601.11409", "authors": ["Wenxiao Li", "Xue-Cheng Tai", "Jun Liu"], "title": "Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints", "categories": ["cs.CV", "cs.AI"], "comment": ":68U10; 62H35; 94A08", "summary": "Existing research highlights the crucial role of topological priors in image segmentation, particularly in preserving essential structures such as connectivity and genus. Accurately capturing these topological features often requires incorporating width-related information, including the thickness and length inherent to the image structures. However, traditional mathematical definitions of topological structures lack this dimensional width information, limiting methods like persistent homology from fully addressing practical segmentation needs. To overcome this limitation, we propose a novel mathematical framework that explicitly integrates width information into the characterization of topological structures. This method leverages persistent homology, complemented by smoothing concepts from partial differential equations (PDEs), to modify local extrema of upper-level sets. This approach enables the resulting topological structures to inherently capture width properties. We incorporate this enhanced topological description into variational image segmentation models. Using some proper loss functions, we are also able to design neural networks that can segment images with the required topological and width properties. Through variational constraints on the relevant topological energies, our approach successfully preserves essential topological invariants such as connectivity and genus counts, simultaneously ensuring that segmented structures retain critical width attributes, including line thickness and length. Numerical experiments demonstrate the effectiveness of our method, showcasing its capability to maintain topological fidelity while explicitly embedding width characteristics into segmented image structures.", "AI": {"tldr": "本文提出了一种新的数学框架，将宽度信息集成到拓扑结构的表征中，并将其应用于图像分割，以保持连通性和属数等关键属性。", "motivation": "现有的研究强调了拓扑先验在图像分割中的重要作用，特别是对于保留连通性、属数等重要结构。然而，传统的数学定义缺乏宽度信息，限制了方法如持久同调法的应用。", "method": "本文提出了一种新的数学框架，结合持久同调和偏微分方程的平滑概念来修改上层集的地方极值，使得拓扑结构能够捕获宽度属性。该方法被集成到变分图像分割模型中，并设计了神经网络以实现所需的拓扑和宽度特性。", "result": "通过数值实验，证明了所提出的方法在保持拓扑保真度的同时，可以将宽度特征明确嵌入到分割的图像结构中。", "conclusion": "本文展示了一种有效的集成宽度信息并确保关键拓扑不变量的方法，对于实现高质量的图像分割具有重要意义。"}}
{"id": "2601.11404", "pdf": "https://arxiv.org/pdf/2601.11404", "abs": "https://arxiv.org/abs/2601.11404", "authors": ["Linqing Zhong", "Yi Liu", "Yifei Wei", "Ziyu Xiong", "Maoqing Yao", "Si Liu", "Guanghui Ren"], "title": "ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models", "categories": ["cs.RO"], "comment": null, "summary": "Vision-Language-Action (VLA) models have emerged as essential generalist robot policies for diverse manipulation tasks, conventionally relying on directly translating multimodal inputs into actions via Vision-Language Model (VLM) embeddings. Recent advancements have introduced explicit intermediary reasoning, such as sub-task prediction (language) or goal image synthesis (vision), to guide action generation. However, these intermediate reasoning are often indirect and inherently limited in their capacity to convey the full, granular information required for precise action execution. Instead, we posit that the most effective form of reasoning is one that deliberates directly in the action space. We introduce Action Chain-of-Thought (ACoT), a paradigm where the reasoning process itself is formulated as a structured sequence of coarse action intents that guide the final policy. In this paper, we propose ACoT-VLA, a novel architecture that materializes the ACoT paradigm. Specifically, we introduce two complementary components: an Explicit Action Reasoner (EAR) and Implicit Action Reasoner (IAR). The former proposes coarse reference trajectories as explicit action-level reasoning steps, while the latter extracts latent action priors from internal representations of multimodal input, co-forming an ACoT that conditions the downstream action head to enable grounded policy learning. Extensive experiments in real-world and simulation environments demonstrate the superiority of our proposed method, which achieves 98.5%, 84.1%, and 47.4% on LIBERO, LIBERO-Plus and VLABench, respectively.", "AI": {"tldr": "本文提出了ACoT-VLA架构，用于提升Vision-Language-Action模型在多样化的操作任务中的表现。", "motivation": "传统的VLM嵌入方法难以提供执行精确动作所需的全部详细信息，因此提出直接在动作空间进行推理以提高行动的准确性。", "method": "引入了两个组件：显式行为推理器（EAR）和隐式行为推理器（IAR），前者生成粗略的参考轨迹作为明确的动作级推理步骤，后者从多模态输入中提取潜在的行为先验，共同组成ACoT以条件化下游动作头。", "result": "在真实世界和模拟环境中的实验表明，所提出的方法优于其他方法，在LIBERO、LIBERO-Plus 和VLABench上分别达到了98.5%、84.1%和47.4%的性能表现。", "conclusion": "通过使用ACoT-VLA架构，显著提升了Vision-Language-Action模型在执行复杂操作任务时的表现，证明了直接在动作空间进行推理的优势。"}}
{"id": "2601.11402", "pdf": "https://arxiv.org/pdf/2601.11402", "abs": "https://arxiv.org/abs/2601.11402", "authors": ["Meng Han"], "title": "SME-YOLO: A Real-Time Detector for Tiny Defect Detection on PCB Surfaces", "categories": ["cs.CV"], "comment": null, "summary": "Surface defects on Printed Circuit Boards (PCBs) directly compromise product reliability and safety. However, achieving high-precision detection is challenging because PCB defects are typically characterized by tiny sizes, high texture similarity, and uneven scale distributions. To address these challenges, this paper proposes a novel framework based on YOLOv11n, named SME-YOLO (Small-target Multi-scale Enhanced YOLO). First, we employ the Normalized Wasserstein Distance Loss (NWDLoss). This metric effectively mitigates the sensitivity of Intersection over Union (IoU) to positional deviations in tiny objects. Second, the original upsampling module is replaced by the Efficient Upsampling Convolution Block (EUCB). By utilizing multi-scale convolutions, the EUCB gradually recovers spatial resolution and enhances the preservation of edge and texture details for tiny defects. Finally, this paper proposes the Multi-Scale Focused Attention (MSFA) module. Tailored to the specific spatial distribution of PCB defects, this module adaptively strengthens perception within key scale intervals, achieving efficient fusion of local fine-grained features and global context information. Experimental results on the PKU-PCB dataset demonstrate that SME-YOLO achieves state-of-the-art performance. Specifically, compared to the baseline YOLOv11n, SME-YOLO improves mAP by 2.2% and Precision by 4%, validating the effectiveness of the proposed method.", "AI": {"tldr": "本论文提出了一种名为SME-YOLO的新框架，用于印刷电路板（PCB）表面的微小缺陷检测。", "motivation": "由于PCB缺陷通常具有尺寸小、纹理相似度高和尺度分布不均匀的特点，实现高精度的缺陷检测极具挑战性。因此，本论文旨在解决这些问题。", "method": "SME-YOLO框架包括使用规范化瓦瑟斯坦距离损失（NWDLoss）来减轻交并比对微小物体位置偏差的敏感性；替换原始上采样模块为高效的上采样卷积块（EUCB），通过多尺度卷积恢复空间分辨率，增强边缘和纹理细节；以及提出多尺度聚焦注意力（MSFA）模块以适应PCB缺陷的空间分布。", "result": "实验结果表明，在PKU-PCB数据集上，与基线YOLOv11n相比，SME-YOLO提升了2.2%的mAP和4%的精度。", "conclusion": "该论文验证了所提出方法的有效性，并实现了同类最佳性能。"}}
{"id": "2601.11400", "pdf": "https://arxiv.org/pdf/2601.11400", "abs": "https://arxiv.org/abs/2601.11400", "authors": ["Shuai Yuan", "Tianwu Lin", "Shuang Chen", "Yu Xia", "Peng Qin", "Xiangyu Liu", "Xiaoqing Xu", "Nan Xu", "Hongsheng Zhang", "Jie Wang", "Peng Gong"], "title": "Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate wetland mapping is essential for ecosystem monitoring, yet dense pixel-level annotation is prohibitively expensive and practical applications usually rely on sparse point labels, under which existing deep learning models perform poorly, while strong seasonal and inter-annual wetland dynamics further render single-date imagery inadequate and lead to significant mapping errors; although foundation models such as SAM show promising generalization from point prompts, they are inherently designed for static images and fail to model temporal information, resulting in fragmented masks in heterogeneous wetlands. To overcome these limitations, we propose WetSAM, a SAM-based framework that integrates satellite image time series for wetland mapping from sparse point supervision through a dual-branch design, where a temporally prompted branch extends SAM with hierarchical adapters and dynamic temporal aggregation to disentangle wetland characteristics from phenological variability, and a spatial branch employs a temporally constrained region-growing strategy to generate reliable dense pseudo-labels, while a bidirectional consistency regularization jointly optimizes both branches. Extensive experiments across eight global regions of approximately 5,000 km2 each demonstrate that WetSAM substantially outperforms state-of-the-art methods, achieving an average F1-score of 85.58%, and delivering accurate and structurally consistent wetland segmentation with minimal labeling effort, highlighting its strong generalization capability and potential for scalable, low-cost, high-resolution wetland mapping.", "AI": {"tldr": "提出WetSAM框架，用于从稀疏注释和卫星图像时间序列进行湿地映射。", "motivation": "现有深度学习模型在依赖稀疏点标签的条件下性能不佳，并且单一日期影像无法捕捉到强季节性和年际间的湿地动态变化，导致显著的制图错误。此外，基础模型如SAM虽然能从点提示中展示良好的泛化能力，但它们设计用于静态图像，无法处理时间信息。", "method": "WetSAM框架集成了卫星图像时间序列，通过双分支设计进行湿地映射：一个时间提示分支扩展了SAM以使用分层适配器和动态时态聚合来区分湿地特征与物候变化；另一个空间分支采用受限的时间区域生长策略生成可靠的密集伪标签。同时，双向一致性正则化优化两个分支。", "result": "WetSAM在八个全球区域（每个约5000平方公里）的广泛实验中显著优于现有最佳方法，平均F1得分为85.58%，实现了结构一致且准确的湿地分割，仅需少量标注工作。", "conclusion": "WetSAM展示出强大的泛化能力和进行可扩展、低成本、高分辨率湿地映射的巨大潜力。"}}
{"id": "2601.11396", "pdf": "https://arxiv.org/pdf/2601.11396", "abs": "https://arxiv.org/abs/2601.11396", "authors": ["Hanlin Wu", "Pengfei Lin", "Ehsan Javanmardi", "Nanren Bao", "Bo Qian", "Hao Si", "Manabu Tsukada"], "title": "SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction", "categories": ["cs.CV"], "comment": null, "summary": "As autonomous driving moves toward full scene understanding, 3D semantic occupancy prediction has emerged as a crucial perception task, offering voxel-level semantics beyond traditional detection and segmentation paradigms. However, such a refined representation for scene understanding incurs prohibitive computation and memory overhead, posing a major barrier to practical real-time deployment. To address this, we propose SUG-Occ, an explicit Semantics and Uncertainty Guided Sparse Learning Enabled 3D Occupancy Prediction Framework, which exploits the inherent sparsity of 3D scenes to reduce redundant computation while maintaining geometric and semantic completeness. Specifically, we first utilize semantic and uncertainty priors to suppress projections from free space during view transformation while employing an explicit unsigned distance encoding to enhance geometric consistency, producing a structurally consistent sparse 3D representation. Secondly, we design an cascade sparse completion module via hyper cross sparse convolution and generative upsampling to enable efficiently coarse-to-fine reasoning. Finally, we devise an object contextual representation (OCR) based mask decoder that aggregates global semantic context from sparse features and refines voxel-wise predictions via lightweight query-context interactions, avoiding expensive attention operations over volumetric features. Extensive experiments on SemanticKITTI benchmark demonstrate that the proposed approach outperforms the baselines, achieving a 7.34/% improvement in accuracy and a 57.8\\% gain in efficiency.", "AI": {"tldr": "本文提出了一种用于实时三维占用预测的显式语义和不确定性引导稀疏学习框架SUG-Occ。", "motivation": "随着自主驾驶向全面场景理解发展，传统的检测和分割方法已经不能满足需求。3D语义占用预测可以提供更精细的场景表示，但由于计算和内存开销巨大，阻碍了其实时部署。为此提出了本论文的方法。", "method": "SUG-Occ利用语义和不确定性先验抑制自由空间投影，通过无符号距离编码增强几何一致性，设计级联稀疏完成模块以及基于对象上下文的掩码解码器来实现高效粗到细推理并优化体素预测。", "result": "实验表明，该方法在SemanticKITTI基准上相比基线提高了7.34%的精度和57.8%的效率。", "conclusion": "SUG-Occ通过稀疏学习框架有效降低了计算开销，同时保持了几何和语义完整性，在实时三维占用预测中表现出色。"}}
{"id": "2601.11394", "pdf": "https://arxiv.org/pdf/2601.11394", "abs": "https://arxiv.org/abs/2601.11394", "authors": ["Henrik Hose", "Paul Brunzema", "Devdutt Subhasish", "Sebastian Trimpe"], "title": "The Mini Wheelbot Dataset: High-Fidelity Data for Robot Learning", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "The development of robust learning-based control algorithms for unstable systems requires high-quality, real-world data, yet access to specialized robotic hardware remains a significant barrier for many researchers. This paper introduces a comprehensive dynamics dataset for the Mini Wheelbot, an open-source, quasi-symmetric balancing reaction wheel unicycle. The dataset provides 1 kHz synchronized data encompassing all onboard sensor readings, state estimates, ground-truth poses from a motion capture system, and third-person video logs. To ensure data diversity, we include experiments across multiple hardware instances and surfaces using various control paradigms, including pseudo-random binary excitation, nonlinear model predictive control, and reinforcement learning agents. We include several example applications in dynamics model learning, state estimation, and time-series classification to illustrate common robotics algorithms that can be benchmarked on our dataset.", "AI": {"tldr": "介绍了一个针对Mini Wheelbot的全面动力学数据集，用于机器人学习。", "motivation": "为了开发出针对不稳定系统的稳健学习控制算法，需要高质量的真实世界数据，但访问专业硬件仍然是很多研究人员的一大障碍。该论文旨在通过提供一个高保真度的数据集来解决这一问题。", "method": "收集了Mini Wheelbot在不同硬件实例和表面上使用多种控制范式的实验数据，包括伪随机二进制激励、非线性模型预测控制和强化学习代理，并同步采集所有机载传感器读数、状态估计、运动捕捉系统的地面真实姿态和第三人称视频记录。", "result": "提供了1 kHz的同步数据，涵盖了各种应用场景下的机器人动力学信息，并提供了一些动态模型学习、状态估计和时间序列分类的应用示例。", "conclusion": "通过提供的全面数据集，为常见的机器人算法提供了基准测试的基础，有助于促进相关领域的发展。"}}
{"id": "2601.11393", "pdf": "https://arxiv.org/pdf/2601.11393", "abs": "https://arxiv.org/abs/2601.11393", "authors": ["Haomiao Tang", "Jinpeng Wang", "Minyi Zhao", "Guanghao Meng", "Ruisheng Luo", "Long Chen", "Shu-Tao Xia"], "title": "Heterogeneous Uncertainty-Guided Composed Image Retrieval with Fine-Grained Probabilistic Learning", "categories": ["cs.CV"], "comment": "Accepted for publication and oral presentation at AAAI 2026", "summary": "Composed Image Retrieval (CIR) enables image search by combining a reference image with modification text. Intrinsic noise in CIR triplets incurs intrinsic uncertainty and threatens the model's robustness. Probabilistic learning approaches have shown promise in addressing such issues; however, they fall short for CIR due to their instance-level holistic modeling and homogeneous treatment of queries and targets. This paper introduces a Heterogeneous Uncertainty-Guided (HUG) paradigm to overcome these limitations. HUG utilizes a fine-grained probabilistic learning framework, where queries and targets are represented by Gaussian embeddings that capture detailed concepts and uncertainties. We customize heterogeneous uncertainty estimations for multi-modal queries and uni-modal targets. Given a query, we capture uncertainties not only regarding uni-modal content quality but also multi-modal coordination, followed by a provable dynamic weighting mechanism to derive comprehensive query uncertainty. We further design uncertainty-guided objectives, including query-target holistic contrast and fine-grained contrasts with comprehensive negative sampling strategies, which effectively enhance discriminative learning. Experiments on benchmarks demonstrate HUG's effectiveness beyond state-of-the-art baselines, with faithful analysis justifying the technical contributions.", "AI": {"tldr": "本文提出了一个异质不确定性引导的组合图像检索框架，利用细粒度的概率学习来增强模型在处理复杂查询和目标时的表现。", "motivation": "现有的概率学习方法存在局限性，在处理组合图像检索任务时表现不佳。因此需要一种新的方法来解决这些问题，并提升检索的准确性与稳定性。", "method": "提出了异质不确定性引导（HUG）框架，使用高斯嵌入表示查询和目标，定制化多模态查询和单模态目标的异质不确定性估计，并设计了不确定度引导的目标函数和采样策略。", "result": "实验结果表明，该方法在基准测试上超越了现有的先进方法，证明了其有效性和技术贡献。", "conclusion": "HUG框架通过细粒度的概率学习有效地增强了组合图像检索的性能，为未来的相关研究提供了新方向。"}}
{"id": "2601.11389", "pdf": "https://arxiv.org/pdf/2601.11389", "abs": "https://arxiv.org/abs/2601.11389", "authors": ["Hedieh Haddad", "Thibault Falque", "Pierre Talbot", "Pascal Bouvry"], "title": "Hyperparameter Optimization of Constraint Programming Solvers", "categories": ["cs.AI"], "comment": "28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization", "summary": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time. We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations. Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.", "AI": {"tldr": "本文介绍了probe and solve算法，这是一种用于约束编程求解器自动超参数优化的新型双阶段框架，并在CPMpy库中实现。", "motivation": "由于手动寻找最优求解配置既困难又耗时且通常需要专业知识，因此提出了一种自动化的方法来改进约束编程求解器的性能。", "method": "probe and solve算法将时间预算分为两个阶段：探查阶段使用可配置超参数优化方法探索不同的超参数集，解决阶段应用找到的最佳配置解决问题。", "result": "实验结果表明，在114个组合问题实例中，Bayesian optimization显著优于求解器的默认配置，对于ACE和Choco分别在25.4%和38.6%的案例中表现更好。同时，它也超过了同一框架内的Hamming距离搜索。", "conclusion": "probe and solve算法提供了一种实用、资源感知的方法来调优约束求解器，并且在各种问题类型上都显示出稳健的改进效果。"}}
{"id": "2601.11387", "pdf": "https://arxiv.org/pdf/2601.11387", "abs": "https://arxiv.org/abs/2601.11387", "authors": ["Greta Warren", "Jingyi Sun", "Irina Shklovski", "Isabelle Augenstein"], "title": "Show me the evidence: Evaluating the role of evidence and natural language explanations in AI-supported fact-checking", "categories": ["cs.HC"], "comment": null, "summary": "Although much research has focused on AI explanations to support decisions in complex information-seeking tasks such as fact-checking, the role of evidence is surprisingly under-researched. In our study, we systematically varied explanation type, AI prediction certainty, and correctness of AI system advice for non-expert participants, who evaluated the veracity of claims and AI system predictions. Participants were provided the option of easily inspecting the underlying evidence. We found that participants consistently relied on evidence to validate AI claims across all experimental conditions. When participants were presented with natural language explanations, evidence was used less frequently although they relied on it when these explanations seemed insufficient or flawed. Qualitative data suggests that participants attempted to infer evidence source reliability, despite source identities being deliberately omitted. Our results demonstrate that evidence is a key ingredient in how people evaluate the reliability of information presented by an AI system and, in combination with natural language explanations, offers valuable support for decision-making. Further research is urgently needed to understand how evidence ought to be presented and how people engage with it in practice.", "AI": {"tldr": "本研究探讨了在AI辅助的事实核查中，证据和自然语言解释的作用。", "motivation": "尽管许多研究集中在AI解释对复杂信息检索任务的支持上，但关于证据作用的研究却相对较少。因此，作者希望通过这项研究来填补这一空白。", "method": "研究人员系统性地改变了非专家参与者在评估主张和AI系统预测的准确性时所看到的解释类型、AI预测的信心以及系统的正确性，并提供了方便检查底层证据的选择。", "result": "结果显示，参与者普遍依赖证据验证AI提出的主张，即使面对自然语言解释时也是如此，尤其是在这些解释显得不足或有缺陷的情况下。", "conclusion": "研究得出结论，证据是人们评估AI系统所呈现信息可靠性的重要因素，而与自然语言解释结合使用可以为决策提供有价值的帮助。"}}
{"id": "2601.11379", "pdf": "https://arxiv.org/pdf/2601.11379", "abs": "https://arxiv.org/abs/2601.11379", "authors": ["Morgane Hoffmann", "Emma Jouffroy", "Warren Jouanneau", "Marc Palyart", "Charles Pebereau"], "title": "Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness Across Groups, and Alignment with Human Preferences", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "comment": null, "summary": "General-purpose Large Language Models (LLMs) show significant potential in recruitment applications, where decisions require reasoning over unstructured text, balancing multiple criteria, and inferring fit and competence from indirect productivity signals. Yet, it is still uncertain how LLMs assign importance to each attribute and whether such assignments are in line with economic principles, recruiter preferences or broader societal norms. We propose a framework to evaluate an LLM's decision logic in recruitment, by drawing on established economic methodologies for analyzing human hiring behavior. We build synthetic datasets from real freelancer profiles and project descriptions from a major European online freelance marketplace and apply a full factorial design to estimate how a LLM weighs different match-relevant criteria when evaluating freelancer-project fit. We identify which attributes the LLM prioritizes and analyze how these weights vary across project contexts and demographic subgroups. Finally, we explain how a comparable experimental setup could be implemented with human recruiters to assess alignment between model and human decisions. Our findings reveal that the LLM weighs core productivity signals, such as skills and experience, but interprets certain features beyond their explicit matching value. While showing minimal average discrimination against minority groups, intersectional effects reveal that productivity signals carry different weights between demographic groups.", "AI": {"tldr": "本文评估了大型语言模型在招聘中的行为，包括其对不同属性的隐含权重、群体间的公平性以及与人类偏好的一致性。", "motivation": "尽管大型语言模型在招聘应用中表现出巨大潜力，但它们如何分配各个属性的重要性及其是否符合经济原则、招聘者偏好或社会规范仍不确定。因此，本文旨在研究其决策逻辑，并确保其行为的公正性和合理性。", "method": "构建了一个基于真实自由职业者资料和项目描述的合成数据集，并采用全因子设计来估计大型语言模型在评估自由职业者与项目的匹配度时对不同相关标准的权重分配情况。还提出了一种相似的人类招聘者的实验设置方法，以评估模型决策与人类决策的一致性。", "result": "研究发现，该模型确实注重核心生产力信号（如技能和经验），但也解读了某些超出显式匹配价值的特性。虽然对少数群体没有明显的平均歧视现象，但在交集效果下，这些生产力信号在不同的人口统计学组群中的权重存在差异。", "conclusion": "通过实验方法，本文揭示了大型语言模型在招聘决策中如何分配隐含权重以及其公平性和一致性问题，并为未来研究提供了框架和方向。"}}
{"id": "2601.11369", "pdf": "https://arxiv.org/pdf/2601.11369", "abs": "https://arxiv.org/abs/2601.11369", "authors": ["Marcantonio Bracale Syrnikov", "Federico Pierucci", "Marcello Galisai", "Matteo Prandi", "Piercosma Bisconti", "Francesco Giarrusso", "Olga Sorokoletova", "Vincenzo Suriani", "Daniele Nardi"], "title": "Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs", "categories": ["cs.GT", "cs.AI"], "comment": null, "summary": "Multi-agent LLM ensembles can converge on coordinated, socially harmful equilibria. This paper advances an experimental framework for evaluating Institutional AI, our system-level approach to AI alignment that reframes alignment from preference engineering in agent-space to mechanism design in institution-space. Central to this approach is the governance graph, a public, immutable manifest that declares legal states, transitions, sanctions, and restorative paths; an Oracle/Controller runtime interprets this manifest, attaching enforceable consequences to evidence of coordination while recording a cryptographically keyed, append-only governance log for audit and provenance. We apply the Institutional AI framework to govern the Cournot collusion case documented by prior work and compare three regimes: Ungoverned (baseline incentives from the structure of the Cournot market), Constitutional (a prompt-only policy-as-prompt prohibition implemented as a fixed written anti-collusion constitution, and Institutional (governance-graph-based). Across six model configurations including cross-provider pairs (N=90 runs/condition), the Institutional regime produces large reductions in collusion: mean tier falls from 3.1 to 1.8 (Cohen's d=1.28), and severe-collusion incidence drops from 50% to 5.6%. The prompt-only Constitutional baseline yields no reliable improvement, illustrating that declarative prohibitions do not bind under optimisation pressure. These results suggest that multi-agent alignment may benefit from being framed as an institutional design problem, where governance graphs can provide a tractable abstraction for alignment-relevant collective behavior.", "AI": {"tldr": "本文介绍了一个用于评估机构AI的实验框架，通过公共治理图来管理多智能体系统中的LLM合谋问题。", "motivation": "多智能体LLM集合可能会收敛到协调一致且对社会有害的平衡状态。该研究旨在探索如何通过机制设计在制度层面解决这一问题。", "method": "提出了一种基于公共治理图的框架，包含法律状态、转换、制裁和恢复路径等元素，并应用此框架来治理Cournot市场中的合谋行为。实验对比了无管制、宪法式和机构式的三种不同管理模式。", "result": "在多种模型配置下，机构管理方式显著降低了合谋现象：平均级别从3.1降至1.8（Cohen's d=1.28），严重合谋发生率从50%降至5.6%，而宪法式方法未显示出明显改善效果。", "conclusion": "研究表明，通过将多智能体对齐问题重新定义为机构设计问题，并采用治理图作为集体行为的可处理抽象方式，可能有助于减少不希望出现的行为。"}}
{"id": "2601.11365", "pdf": "https://arxiv.org/pdf/2601.11365", "abs": "https://arxiv.org/abs/2601.11365", "authors": ["Yi Li", "Kadek Ananta Satriadi", "Jiazhou Liu", "Anjali Khurana", "Zhiqing Wu", "Benjamin Tag", "Tim Dwyer"], "title": "Human Factors in Immersive Analytics", "categories": ["cs.HC"], "comment": null, "summary": "It has been ten years since the term ''Immersive Analytics'' (IA) was coined and research interest in the topic remains strong. Researchers in this field have produced practical and conceptual knowledge concerning the use of emerging immersive spatial display and interaction technologies for sense-making tasks through a number of papers, surveys, and books. However, a lack of truly physically and psychologically ergonomic techniques, as well as standardized human-centric validation protocols for these, remains a significant barrier to wider acceptance of practical IA systems in ubiquitous applications. Building upon a series of workshops on immersive analytics at various conferences, this workshop aims to explore new approaches and establish standard practices for evaluating immersive analytics systems from a human factors perspective. We will gather immersive analytics researchers and practitioners to look closely at these human factors -- including cognitive and physical functions as well as behaviour and performance -- to see how they inform the design and deployment of immersive analytics techniques and applications and to inform future research.", "AI": {"tldr": "本文旨在探讨沉浸式分析系统中的人体因素，并通过研讨会的形式建立标准实践方法。", "motivation": "研究领域缺乏真正物理和心理人体工程学技术以及标准化的人类中心验证协议，这阻碍了实用的沉浸式分析系统的广泛应用。", "method": "举办一系列关于沉浸式分析的研讨会，聚集研究人员和从业者探讨影响沉浸式分析技术和应用设计与部署的认知、身体功能行为及表现等因素。", "result": "尚未提供具体的研究结果，而是旨在探索新的方法并建立评估沉浸式分析系统的人体因素标准实践。", "conclusion": "通过研讨会议确定人体因素如何指导沉浸式分析技术和应用的设计和部署，并为未来研究指明方向。"}}
{"id": "2601.11359", "pdf": "https://arxiv.org/pdf/2601.11359", "abs": "https://arxiv.org/abs/2601.11359", "authors": ["Wenhui Tan", "Ruihua Song", "Jiaze Li", "Jianzhong Ju", "Zhenbo Luo"], "title": "Think-Clip-Sample: Slow-Fast Frame Selection for Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICASSP2026", "summary": "Recent progress in multi-modal large language models (MLLMs) has significantly advanced video understanding. However, their performance on long-form videos remains limited by computational constraints and suboptimal frame selection. We present Think-Clip-Sample (TCS), a training-free framework that enhances long video understanding through two key components: (i) Multi-Query Reasoning, which generates multiple queries to capture complementary aspects of the question and video; and (ii) Clip-level Slow-Fast Sampling, which adaptively balances dense local details and sparse global context. Extensive experiments on MLVU, LongVideoBench, and VideoMME demonstrate that TCS consistently improves performance across different MLLMs, boosting up to 6.9% accuracy, and is capable of achieving comparable accuracy with 50% fewer inference time cost, highlighting both efficiency and efficacy of TCS on long video understanding.", "AI": {"tldr": "本文提出了Think-Clip-Sample（TCS），一个无训练框架，通过多查询推理和片段级慢快采样来提升长视频理解的效率和效果。", "motivation": "尽管多模态大语言模型在视频理解方面取得了显著进展，但它们在处理长格式视频时受到计算约束和次优帧选择的影响。本文旨在改进这些问题，以提高长视频的理解性能和效率。", "method": "TCS框架包含两个关键组件：（i）多查询推理，生成多个查询来捕捉问题和视频的互补方面；（ii）片段级慢快采样，在密集局部细节和稀疏全局上下文之间进行自适应平衡。", "result": "在MLVU、LongVideoBench和VideoMME上的广泛实验表明，TCS框架在不同多模态大语言模型上提升了高达6.9%的准确性，并且能够以50%更少的推理时间成本达到可比的准确度，显示出其在长视频理解方面的高效性和有效性。", "conclusion": "Think-Clip-Sample（TCS）是一个无训练框架，通过多查询推理和片段级慢快采样提升长视频理解性能，同时减少了计算开销，证明了其在提高效率和准确性方面的能力。"}}
{"id": "2601.11357", "pdf": "https://arxiv.org/pdf/2601.11357", "abs": "https://arxiv.org/abs/2601.11357", "authors": ["Steffen Knoblauch", "Ram Kumar Muthusamy", "Hao Li", "Iddy Chazua", "Benedcto Adamu", "Innocent Maholi", "Alexander Zipf"], "title": "Assessing Building Heat Resilience Using UAV and Street-View Imagery with Coupled Global Context Vision Transformer", "categories": ["cs.CV"], "comment": null, "summary": "Climate change is intensifying human heat exposure, particularly in densely built urban centers of the Global South. Low-cost construction materials and high thermal-mass surfaces further exacerbate this risk. Yet scalable methods for assessing such heat-relevant building attributes remain scarce. We propose a machine learning framework that fuses openly available unmanned aerial vehicle (UAV) and street-view (SV) imagery via a coupled global context vision transformer (CGCViT) to learn heat-relevant representations of urban structures. Thermal infrared (TIR) measurements from HotSat-1 are used to quantify the relationship between building attributes and heat-associated health risks. Our dual-modality cross-view learning approach outperforms the best single-modality models by up to $9.3\\%$, demonstrating that UAV and SV imagery provide valuable complementary perspectives on urban structures. The presence of vegetation surrounding buildings (versus no vegetation), brighter roofing (versus darker roofing), and roofing made of concrete, clay, or wood (versus metal or tarpaulin) are all significantly associated with lower HotSat-1 TIR values. Deployed across the city of Dar es Salaam, Tanzania, the proposed framework illustrates how household-level inequalities in heat exposure - often linked to socio-economic disadvantage and reflected in building materials - can be identified and addressed using machine learning. Our results point to the critical role of localized, data-driven risk assessment in shaping climate adaptation strategies that deliver equitable outcomes.", "AI": {"tldr": "通过无人机和街景图像结合全球上下文视觉转换器来评估建筑物的热韧性。", "motivation": "气候变化加剧了人类对高温的暴露，特别是在全球南方的密集城市区域。缺乏低成本建筑材料和高热质量表面进一步增加了这种风险。但是，用于评估这些与热量相关的建筑属性的方法仍然稀缺。", "method": "提出了一个机器学习框架，该框架通过结合无人机（UAV）和街景图像使用耦合全局上下文视觉变换器来学习城市结构的热量相关表示，并利用HotSat-1热红外测量结果量化建筑物属性与与热量相关的健康风险之间的关系。", "result": "双模态交叉视图学习方法比最佳单模态模型的表现高出9.3%，表明无人机和街景图像提供了有价值的城市结构互补视角。植被覆盖、较亮的屋顶颜色以及由混凝土、粘土或木头制成的屋顶与较低的HotSat-1热红外值显著相关。", "conclusion": "该框架展示了如何使用机器学习来识别并解决坦桑尼亚达累斯萨拉姆市的家庭层面热量暴露不平等，这些不平等通常与社会经济劣势和建筑材料有关。研究结果强调了本地化、数据驱动的风险评估在制定适应气候变化策略中的关键作用，以实现公平的结果。"}}
{"id": "2601.11354", "pdf": "https://arxiv.org/pdf/2601.11354", "abs": "https://arxiv.org/abs/2601.11354", "authors": ["Weiyi Wang", "Xinchi Chen", "Jingjing Gong", "Xuanjing Huang", "Xipeng Qiu"], "title": "AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.", "AI": {"tldr": "介绍了AstroReason-Bench，这是一个全面的基准测试平台，用于评估代理在空间规划问题中的统一性行为和计划能力。", "motivation": "现有的代理基准主要集中在符号或弱关联环境中，对物理约束下的实际世界领域的表现研究不足。因此，需要一个能够评估代理在高风险、异质目标和长期决策等复杂情况下的性能的测试平台。", "method": "AstroReason-Bench整合了多种调度制度，包括地面站通信和敏捷地球观测，并提供了一个统一的代理人交互协议。通过使用多个最先进的开源和闭源的代理LLM系统进行评估。", "result": "当前的代理在现实约束下的表现显著低于专门设计的求解器，揭示了一般性规划的关键限制。", "conclusion": "AstroReason-Bench为未来的代理研究提供了一个具有挑战性和诊断性的测试平台。"}}
{"id": "2601.11350", "pdf": "https://arxiv.org/pdf/2601.11350", "abs": "https://arxiv.org/abs/2601.11350", "authors": ["Jaehoon Lee", "Seungwoo Lee", "Younghwi Kim", "Dohee Kim", "Sunghyun Sim"], "title": "FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)", "summary": "Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer) for accurate long-term forecasting under severe limits. FEATHer introduces: (i) ultra-lightweight multiscale decomposition into frequency pathways; (ii) a shared Dense Temporal Kernel using projection-depthwise convolution-projection without recurrence or attention; (iii) frequency-aware branch gating that adaptively fuses representations based on spectral characteristics; and (iv) a Sparse Period Kernel reconstructing outputs via period-wise downsampling to capture seasonality. FEATHer maintains a compact architecture (as few as 400 parameters) while outperforming baselines. Across eight benchmarks, it achieves the best ranking, recording 60 first-place results with an average rank of 2.05. These results demonstrate that reliable long-range forecasting is achievable on constrained edge hardware, offering a practical direction for industrial real-time inference.", "AI": {"tldr": "提出FEATHer模型，用于在边缘设备上进行长时间序列预测。", "motivation": "工业领域如制造和智能工厂需要准确的时间序列预测，但边缘计算设备受限于严格的延迟和内存限制，因此传统的深度学习架构在这里不实用。", "method": "FEATHer包括超轻量的多尺度分解到频率路径、共享密集时间核、基于频谱特性的自适应融合以及稀疏周期内核重构输出。", "result": "在八个基准测试中获得最佳排名，记录了60个第一名成绩和平均排名2.05的成绩。这些结果证明FEATHer模型能够在约束边缘硬件上实现可靠的长时间范围预测。", "conclusion": "可靠的时间序列长距离预测可以在受限的边缘计算设备上实现，为工业实时推理提供了一个实用的方向。"}}
{"id": "2601.11344", "pdf": "https://arxiv.org/pdf/2601.11344", "abs": "https://arxiv.org/abs/2601.11344", "authors": ["Parker Seegmiller", "Joseph Gatto", "Sarah E. Greer", "Ganza Belise Isingizwe", "Rohan Ray", "Timothy E. Burdick", "Sarah Masud Preum"], "title": "How Much Would a Clinician Edit This Draft? Evaluating LLM Alignment for Patient Message Response Drafting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) show promise in drafting responses to patient portal messages, yet their integration into clinical workflows raises various concerns, including whether they would actually save clinicians time and effort in their portal workload. We investigate LLM alignment with individual clinicians through a comprehensive evaluation of the patient message response drafting task. We develop a novel taxonomy of thematic elements in clinician responses and propose a novel evaluation framework for assessing clinician editing load of LLM-drafted responses at both content and theme levels. We release an expert-annotated dataset and conduct large-scale evaluations of local and commercial LLMs using various adaptation techniques including thematic prompting, retrieval-augmented generation, supervised fine-tuning, and direct preference optimization. Our results reveal substantial epistemic uncertainty in aligning LLM drafts with clinician responses. While LLMs demonstrate capability in drafting certain thematic elements, they struggle with clinician-aligned generation in other themes, particularly question asking to elicit further information from patients. Theme-driven adaptation strategies yield improvements across most themes. Our findings underscore the necessity of adapting LLMs to individual clinician preferences to enable reliable and responsible use in patient-clinician communication workflows.", "AI": {"tldr": "本论文评估了大型语言模型（LLMs）在起草患者门户消息回复中的对齐情况，以确定其是否符合临床医生的工作需求。", "motivation": "尽管大型语言模型在起草响应患者门户消息方面显示出潜力，但它们的整合可能不会节省临床医生的时间和努力。因此，研究旨在评估这些模型与个体临床医生的对齐程度。", "method": "论文提出了一种新型的临床医生回复中主题元素分类法，并开发了一个框架来评估临床医生对于由LLM起草的响应编辑负担。使用专家标注的数据集进行了大规模评估，涵盖本地和商用LLMs及各种适应技术。", "result": "研究结果揭示了在将LLM草案与临床医生答复对齐方面存在显著的认识不确定性。虽然LLMs能够在某些主题元素上表现良好，但在其他如从患者获取更多信息的问题提出等主题上则表现出不足。", "conclusion": "论文结论强调需要根据个体临床医生的偏好来调整LLMs，以支持可靠和负责任地在患者-临床医生沟通流程中使用这些模型。"}}
{"id": "2601.11336", "pdf": "https://arxiv.org/pdf/2601.11336", "abs": "https://arxiv.org/abs/2601.11336", "authors": ["Mark Eastwood", "Thomas McKee", "Zedong Hu", "Sabine Tejpar", "Fayyaz Minhas"], "title": "Beer-Lambert Autoencoder for Unsupervised Stain Representation Learning and Deconvolution in Multi-immunohistochemical Brightfield Histology Images", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Separating the contributions of individual chromogenic stains in RGB histology whole slide images (WSIs) is essential for stain normalization, quantitative assessment of marker expression, and cell-level readouts in immunohistochemistry (IHC). Classical Beer-Lambert (BL) color deconvolution is well-established for two- or three-stain settings, but becomes under-determined and unstable for multiplex IHC (mIHC) with K>3 chromogens. We present a simple, data-driven encoder-decoder architecture that learns cohort-specific stain characteristics for mIHC RGB WSIs and yields crisp, well-separated per-stain concentration maps. The encoder is a compact U-Net that predicts K nonnegative concentration channels; the decoder is a differentiable BL forward model with a learnable stain matrix initialized from typical chromogen hues. Training is unsupervised with a perceptual reconstruction objective augmented by loss terms that discourage unnecessary stain mixing. On a colorectal mIHC panel comprising 5 stains (H, CDX2, MUC2, MUC5, CD8) we show excellent RGB reconstruction, and significantly reduced inter-channel bleed-through compared with matrix-based deconvolution. Code and model are available at https://github.com/measty/StainQuant.git.", "AI": {"tldr": "本文提出了一种基于Beer-Lambert定律的自编码器，用于多免疫组化图像中染色质表示的学习和去卷积。", "motivation": "分离多种染色剂在组织切片中的贡献对于标准化、定量评估标志物表达及细胞水平读取至关重要，而传统的Beer-Lambert法在多于三种染色剂的情况下变得不稳定。因此需要一种新的方法来解决这个问题。", "method": "采用了一种简单的基于数据驱动的编码器-解码器架构，通过紧凑型U-Net预测非负浓度通道，并使用可学习的染色矩阵初始化典型的染料色调进行反卷积处理。训练过程中采用了感知重建目标和损失函数以减少不必要的染色剂混合。", "result": "在包含5种染色剂的结直肠多免疫组化面板上展示了优秀的RGB图像重构效果，以及与基于矩阵的方法相比显著减少了通道间的串扰。", "conclusion": "提出的方法能够有效分离多种染色质，并减少串扰，提高组织切片中标志物表达的定量评估精度和细胞水平读取的准确性。"}}
{"id": "2601.11335", "pdf": "https://arxiv.org/pdf/2601.11335", "abs": "https://arxiv.org/abs/2601.11335", "authors": ["Tyler Paine", "Brendan Long", "Jeremy Wenger", "Michael DeFilippo", "James Usevitch", "Michael Benjamin"], "title": "Distributed Control Barrier Functions for Safe Multi-Vehicle Navigation in Heterogeneous USV Fleets", "categories": ["cs.RO", "eess.SY"], "comment": "8 pages, 10 figures", "summary": "Collision avoidance in heterogeneous fleets of uncrewed vessels is challenging because the decision-making processes and controllers often differ between platforms, and it is further complicated by the limitations on sharing trajectories and control values in real-time. This paper presents a pragmatic approach that addresses these issues by adding a control filter on each autonomous vehicle that assumes worst-case behavior from other contacts, including crewed vessels. This distributed safety control filter is developed using control barrier function (CBF) theory and the application is clearly described to ensure explainability of these safety-critical methods. This work compares the worst-case CBF approach with a Collision Regulations (COLREGS) behavior-based approach in simulated encounters. Real-world experiments with three different uncrewed vessels and a human operated vessel were performed to confirm the approach is effective across a range of platforms and is robust to uncooperative behavior from human operators. Results show that combining both CBF methods and COLREGS behaviors achieves the best safety and efficiency.", "AI": {"tldr": "本文提出了一种基于控制屏障函数（CBF）理论的分布式安全控制滤波器，以解决异构无人驾驶船队在多船只导航中的碰撞避免问题。", "motivation": "由于不同平台之间的决策过程和控制器通常存在差异，并且实时共享轨迹和控制值受到限制，使得无人船队的安全航行面临挑战。本文旨在提出一种实用的方法来应对这些挑战。", "method": "通过假设其他接触对象（包括有人驾驶船只）的最坏情况行为，在每个自主车辆上添加一个控制滤波器，并利用CBF理论开发分布式安全控制滤波器，将其与基于COLREGS的行为方法进行比较。", "result": "在模拟遭遇和真实世界实验中证明了该方法的有效性，结果显示结合CBF方法和COLREGS行为可以实现最佳的安全性和效率。", "conclusion": "本文提出的方法能够确保异构无人船队中的安全导航，并且对人类操作员的不合作行为具有鲁棒性。"}}
{"id": "2601.11328", "pdf": "https://arxiv.org/pdf/2601.11328", "abs": "https://arxiv.org/abs/2601.11328", "authors": ["Hanqing Zhou", "Yichuan Zhang", "Zihan Zhang", "Wei Zhang", "Chao Wang", "Pengcheng An"], "title": "ProjecTA: A Semi-Humanoid Robotic Teaching Assistant with In-Situ Projection for Guided Tours", "categories": ["cs.HC"], "comment": "35 pages, 12 figures, 2 appendixes, 3 supplementary meterials, to appear in CHI'2026", "summary": "Robotic teaching assistants (TAs) often use body-mounted screens to deliver content. In nomadic, walk-and-talk learning, such as tours in makerspaces, these screens can distract learners from real-world objects, increasing extraneous cognitive load. HCI research lacks empirical comparisons of potential alternatives, such as robots with in-situ projection versus screen-based counterparts; little knowledge has been derived for designing such alternatives. We introduce ProjecTA, a semi-humanoid, gesture-capable TA that guides learners while projecting near-object overlays coordinated with speech and gestures. In a mixed-method study (N=24) in a university makerspace, ProjecTA significantly reduced extraneous load and outperformed its screen-based counterpart in perceived usability, usefulness of visual display, and cross-modal complementarity. Qualitative analyses revealed how ProjecTA's coordinated projections, gestures, and speech anchored explanations in place and time, enhancing understanding in ways a screen could not. We derive key design implications for future robotic TAs leveraging spatial projection to support mobile learning in physical environments.", "AI": {"tldr": "介绍ProjecTA，一种半人形机器人助教，通过现场投影引导学习者，并减少额外的认知负担。", "motivation": "传统助教使用身体屏幕展示内容可能分散注意力并增加认知负荷。研究缺乏对机器人现场投影与屏幕展示的实证对比和设计知识。", "method": "采用混合方法研究（N=24），在大学创客空间进行，比较了ProjecTA与其屏幕基线版本的表现。", "result": "结果表明，ProjecTA显著减少了额外的认知负荷，并在感知易用性、视觉展示的有用性和跨模态互补性方面优于其屏幕版本。", "conclusion": "研究得出设计未来机器人助教的关键启示，强调利用空间投影支持移动学习的设计方法。"}}
{"id": "2601.11325", "pdf": "https://arxiv.org/pdf/2601.11325", "abs": "https://arxiv.org/abs/2601.11325", "authors": ["Dheeraj Poolavaram", "Carsten Markgraf", "Sebastian Dorn"], "title": "GENPACK: KPI-Guided Multi-Objective Genetic Algorithm for Industrial 3D Bin Packing", "categories": ["cs.NE"], "comment": null, "summary": "The three-dimensional bin packing problem (3D-BPP) is a longstanding challenge in operations research and logistics. Classical heuristics and constructive methods can generate packings quickly, but often fail to address industrial constraints such as stability, balance, and handling feasibility. Metaheuristics such as genetic algorithms (GAs) provide flexibility and the ability to optimize across multiple objectives; however, pure GA approaches frequently struggle with efficiency, parameter sensitivity, and scalability to industrial order sizes. This gap is especially evident when scaling to real-world pallet dimensions, where even state-of-the-art algorithms often fail to achieve robust, deployable solutions. We propose a KPI-driven GA-based pipeline for industrial 3D-BPP that integrates key performance indicators directly into a multi-objective fitness function. The methodology combines a layer-based chromosome representation with domain-specific operators and constructive heuristics to balance efficiency and feasibility. On the BED-BPP benchmark of 1,500 real-world orders, our Hybrid-GA pipeline consistently outperforms heuristic- and learning-based state-of-the-art methods, achieving up to 35% higher space utilization and 15 to 20% stronger surface support, with lower variance across orders. These improvements come at a modest runtime cost but remain feasible for batch-scale deployment, yielding stable, balanced, and space-efficient packings.", "AI": {"tldr": "本文提出了一种基于KPI的多目标遗传算法（GENPACK），用于解决工业三维装箱问题。", "motivation": "传统的启发式方法和构造性方法在处理工业约束条件时效果不佳，而纯遗传算法又存在效率低、参数敏感和扩展性差的问题。该研究旨在提高3D-BPP解决方案的稳定性和可行性，并在实际场景中实现高效的部署。", "method": "GENPACK结合了分层染色体表示法、领域特定算子以及构造启发式方法，将关键性能指标直接整合到多目标适应度函数中。", "result": "实验结果显示，在BED-BPP基准测试的1500个实际订单上，该混合遗传算法管道相比现有的启发式和学习方法具有更高的空间利用率（高达35%）和更强的表面支撑能力（15-20%），且运行时间成本适度。", "conclusion": "GENPACK在保持可行性的同时提高了装箱过程中的效率和稳定性，并为工业订单提供了稳定、平衡且节省空间的解决方案。"}}
{"id": "2601.11322", "pdf": "https://arxiv.org/pdf/2601.11322", "abs": "https://arxiv.org/abs/2601.11322", "authors": ["Pavana Pradeep", "Krishna Kant", "Suya Yu"], "title": "Enhancing Vision Language Models with Logic Reasoning for Situational Awareness", "categories": ["cs.CV", "cs.LO"], "comment": "Accepted for publication in IEEE Transactions on AI", "summary": "Vision-Language Models (VLMs) offer the ability to generate high-level, interpretable descriptions of complex activities from images and videos, making them valuable for situational awareness (SA) applications. In such settings, the focus is on identifying infrequent but significant events with high reliability and accuracy, while also extracting fine-grained details and assessing recognition quality. In this paper, we propose an approach that integrates VLMs with traditional computer vision methods through explicit logic reasoning to enhance SA in three key ways: (a) extracting fine-grained event details, (b) employing an intelligent fine-tuning (FT) strategy that achieves substantially higher accuracy than uninformed selection, and (c) generating justifications for VLM outputs during inference. We demonstrate that our intelligent FT mechanism improves the accuracy and provides a valuable means, during inferencing, to either confirm the validity of the VLM output or indicate why it may be questionable.", "AI": {"tldr": "本文提出了一种将视觉语言模型与传统计算机视觉方法结合的逻辑推理方法，以提高情境感知中的事件细节提取、准确性和输出合理性。", "motivation": "传统的视觉语言模型在识别复杂活动时存在局限性，难以高可靠性地识别罕见但重要的事件并提取细粒度信息。本文旨在解决这些问题，提升情境感知的应用价值。", "method": "提出的方法是将VLMs与传统计算机视觉技术通过显式逻辑推理相结合，包含三种关键改进：（a）提取更精细的事件细节；（b）采用智能微调策略提高准确性；（c）在推断过程中生成模型输出的理由。", "result": "实验证明，该智能微调机制能显著提升精度，并能在推理期间确认VLM输出的有效性或指出其潜在问题的原因。", "conclusion": "通过结合逻辑推理和传统计算机视觉方法，本文提出的方法能够增强情境感知应用中的事件细节提取、准确性和模型结果的合理性解释。"}}
{"id": "2601.11310", "pdf": "https://arxiv.org/pdf/2601.11310", "abs": "https://arxiv.org/abs/2601.11310", "authors": ["Antoine Carreaud", "Elias Naha", "Arthur Chansel", "Nina Lahellec", "Jan Skaloud", "Adrien Gressin"], "title": "Context-Aware Semantic Segmentation via Stage-Wise Attention", "categories": ["cs.CV"], "comment": null, "summary": "Semantic ultra high resolution image (UHR) segmentation is essential in remote sensing applications such as aerial mapping and environmental monitoring. Transformer-based models struggle in this setting because memory grows quadratically with token count, constraining either the contextual scope or the spatial resolution. We introduce CASWiT (Context-Aware Stage-Wise Transformer), a dual-branch, Swin-based architecture that injects global cues into fine-grained UHR features. A context encoder processes a downsampled neighborhood to capture long-range dependencies, while a high resolution encoder extracts detailed features from UHR patches. A cross-scale fusion module, combining cross-attention and gated feature injection, enriches high-resolution tokens with context. Beyond architecture, we propose a SimMIM-style pretraining. We mask 75% of the high-resolution image tokens and the low-resolution center region that spatially corresponds to the UHR patch, then train the shared dual-encoder with small decoder to reconstruct the UHR initial image. Extensive experiments on the large-scale IGN FLAIR-HUB aerial dataset demonstrate the effectiveness of CASWiT. Our method achieves 65.83% mIoU, outperforming RGB baselines by 1.78 points. On URUR, CASWiT achieves 49.1% mIoU, surpassing the current SoTA by +0.9% under the official evaluation protocol. All codes are provided on: https://huggingface.co/collections/heig-vd-geo/caswit.", "AI": {"tldr": "本文介绍了CASWiT，一种用于语义超高清图像分割的双分支、Swin基础架构模型，在遥感应用中表现出色。", "motivation": "现有的基于Transformer的模型在处理高分辨率图像时面临着内存限制的问题。该问题导致要么上下文范围受限，要么空间分辨率受限，因此提出了CASWiT来解决这些问题。", "method": "CASWiT采用双分支架构，包括一个全局线索编码器和一个高分辨率特征提取器，并通过跨尺度融合模块将两者信息结合，同时引入了SimMIM风格的预训练方法。", "result": "实验结果表明，在IGN FLAIR-HUB数据集上，CASWiT实现了65.83%的mIoU，比RGB基线高出1.78个点；在URUR数据集中，其性能也超越了当前最佳模型。", "conclusion": "通过使用CASWiT，可以有效地提高超高清图像分割的质量，并为遥感应用提供了一个新的解决方案。"}}
{"id": "2601.11301", "pdf": "https://arxiv.org/pdf/2601.11301", "abs": "https://arxiv.org/abs/2601.11301", "authors": ["Gergely Dinya", "András Gelencsér", "Krisztina Kupán", "Clemens Küpper", "Kristóf Karacs", "Anna Gelencsér-Horváth"], "title": "SAMannot: A Memory-Efficient, Local, Open-source Framework for Interactive Video Instance Segmentation based on SAM2", "categories": ["cs.CV"], "comment": null, "summary": "Current research workflows for precise video segmentation are often forced into a compromise between labor-intensive manual curation, costly commercial platforms, and/or privacy-compromising cloud-based services. The demand for high-fidelity video instance segmentation in research is often hindered by the bottleneck of manual annotation and the privacy concerns of cloud-based tools. We present SAMannot, an open-source, local framework that integrates the Segment Anything Model 2 (SAM2) into a human-in-the-loop workflow. To address the high resource requirements of foundation models, we modified the SAM2 dependency and implemented a processing layer that minimizes computational overhead and maximizes throughput, ensuring a highly responsive user interface. Key features include persistent instance identity management, an automated ``lock-and-refine'' workflow with barrier frames, and a mask-skeletonization-based auto-prompting mechanism. SAMannot facilitates the generation of research-ready datasets in YOLO and PNG formats alongside structured interaction logs. Verified through animal behavior tracking use-cases and subsets of the LVOS and DAVIS benchmark datasets, the tool provides a scalable, private, and cost-effective alternative to commercial platforms for complex video annotation tasks.", "AI": {"tldr": "介绍了一个开源的本地框架SAMannot，用于交互式视频实例分割。", "motivation": "解决现有视频分割研究工作流程中人工标注劳动密集、商业平台成本高昂以及基于云的服务隐私问题。", "method": "将Segment Anything Model 2（SAM2）集成到一个有人员循环的工作流中，并优化了计算资源要求，实现了高响应的用户界面。主要功能包括持续实例身份管理、自动锁定和细化工作流程及骨架化提示机制。", "result": "通过动物行为跟踪案例研究及LVOS和DAVIS基准数据集子集验证了工具的有效性，提供了可扩展、私密且成本效益高的复杂视频注释任务替代方案。", "conclusion": "SAMannot提供了一种高效率且隐私保护的解决方案，适用于需要精确视频实例分割的研究需求。"}}
{"id": "2601.11290", "pdf": "https://arxiv.org/pdf/2601.11290", "abs": "https://arxiv.org/abs/2601.11290", "authors": ["Vishisht Sharma", "Sam Leroux", "Lisa Landuyt", "Nick Witvrouwen", "Pieter Simoens"], "title": "Efficient On-Board Processing of Oblique UAV Video for Rapid Flood Extent Mapping", "categories": ["cs.CV"], "comment": null, "summary": "Effective disaster response relies on rapid disaster response, where oblique aerial video is the primary modality for initial scouting due to its ability to maximize spatial coverage and situational awareness in limited flight time. However, the on-board processing of high-resolution oblique streams is severely bottlenecked by the strict Size, Weight, and Power (SWaP) constraints of Unmanned Aerial Vehicles (UAVs). The computational density required to process these wide-field-of-view streams precludes low-latency inference on standard edge hardware. To address this, we propose Temporal Token Reuse (TTR), an adaptive inference framework capable of accelerating video segmentation on embedded devices. TTR exploits the intrinsic spatiotemporal redundancy of aerial video by formulating image patches as tokens; it utilizes a lightweight similarity metric to dynamically identify static regions and propagate their precomputed deep features, thereby bypassing redundant backbone computations. We validate the framework on standard benchmarks and a newly curated Oblique Floodwater Dataset designed for hydrological monitoring. Experimental results on edge-grade hardware demonstrate that TTR achieves a 30% reduction in inference latency with negligible degradation in segmentation accuracy (< 0.5% mIoU). These findings confirm that TTR effectively shifts the operational Pareto frontier, enabling high-fidelity, real-time oblique video understanding for time-critical remote sensing missions", "AI": {"tldr": "本文提出了一个名为Temporal Token Reuse (TTR) 的自适应推理框架，用于加速嵌入式设备上的视频分割处理，特别适用于无人机拍摄的斜视角视频以快速绘制洪水范围。", "motivation": "文章旨在解决在无人机（UAVs）严格尺寸、重量和功率（SWaP）约束下高效处理高分辨率斜视视频流的问题，以便于灾害响应中的快速侦察。", "method": "TTR通过将图像块定义为令牌，并利用轻量级相似度度量动态识别静态区域以传播预计算的深层特征来规避冗余主干计算，从而加速无人机拍摄的视频分割处理。", "result": "实验结果显示，在边缘硬件上应用TTR可实现30%的推理延迟降低，同时保持分割精度基本不变（小于0.5％mIoU）。", "conclusion": "研究结果表明，TTR框架有效推进了操作帕累托前沿，使得高保真的实时斜视角视频理解成为可能，特别适用于时间关键性的遥感任务。"}}
{"id": "2601.11287", "pdf": "https://arxiv.org/pdf/2601.11287", "abs": "https://arxiv.org/abs/2601.11287", "authors": ["Markus Bink", "Marten Risius", "Udo Kruschwitz", "David Elsweiler"], "title": "Seek and You Shall Find: Design & Evaluation of a Context-Aware Interactive Search Companion", "categories": ["cs.HC", "cs.IR"], "comment": "Pre-Print accepted at CHIIR 2026", "summary": "Many users struggle with effective online search and critical evaluation, especially in high-stakes domains like health, while often overestimating their digital literacy. Thus, in this demo, we present an interactive search companion that seamlessly integrates expert search strategies into existing search engine result pages. Providing context-aware tips on clarifying information needs, improving query formulation, encouraging result exploration, and mitigating biases, our companion aims to foster reflective search behaviour while minimising cognitive burden. A user study demonstrates the companion's successful encouragement of more active and exploratory search, leading users to submit 75 % more queries and view roughly twice as many results, as well as performance gains in difficult tasks. This demo illustrates how lightweight, contextual guidance can enhance search literacy and empower users through micro-learning opportunities. While the vision involves real-time LLM adaptivity, this study utilises a controlled implementation to test the underlying intervention strategies.", "AI": {"tldr": "本文介绍了一种交互式搜索伴侣，旨在通过集成专家搜索策略来提高用户的在线搜索和批判性评估能力。", "motivation": "许多用户在高风险领域如健康方面进行有效在线搜索及批评性评估存在困难，并且经常过高估计自己的数字素养。该动机促使开发一种能够提供上下文感知提示的互动伴侣，帮助改进查询形成、信息需求澄清等。", "method": "论文提出了一种集成于现有搜索引擎结果页面的交互式搜索伴侣，它提供了上下文感知建议来支持更有效的查询和减少认知负担，通过用户研究测试其有效性。", "result": "用户研究表明，该伴侣能够鼓励更加主动和探索性的搜索行为，使用户的查询次数增加了75%，查看的结果数量也增加了一倍左右，在困难任务中的表现也有提升。", "conclusion": "轻量级、上下文导向的指导可以提高搜索素养并为用户提供微学习机会。虽然最终愿景是实现基于实时LLM（大型语言模型）的适应性，但这项研究通过受控实施测试了基本干预策略的有效性。"}}
{"id": "2601.11286", "pdf": "https://arxiv.org/pdf/2601.11286", "abs": "https://arxiv.org/abs/2601.11286", "authors": ["Weihong Qi", "Fan Huang", "Rasika Muralidharan", "Jisun An", "Haewoon Kwak"], "title": "XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making", "categories": ["cs.AI"], "comment": null, "summary": "We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.", "AI": {"tldr": "本文介绍了XChoice，一个用于评估基于大语言模型的约束决策中AI和人类对齐情况的可解释框架。", "motivation": "动机在于超越准确性和F1分数等结果一致性评价，通过机制化的决策模型来捕捉并量化决策因素的重要性、约束敏感度以及隐含的权衡关系，从而更深入地评估AI与人类的对齐情况。", "method": "XChoice使用机制化的方法拟合人和大语言模型在决策上的参数向量，并通过比较这些向量来评估不同模型、选项及亚群体之间的对齐程度。还采用了一项检索增强生成（RAG）干预措施以验证并改善框架的鲁棒性和有效性。", "result": "实验结果表明，使用美国时间使用调查（ATUS）数据作为人类基准，XChoice揭示了在不同活动和模型之间存在异质性的对齐情况，并且在黑人和已婚群体中发现了显著的不对齐现象。此外，通过不变性分析验证了框架的稳健性。", "conclusion": "结论是XChoice提供了一种基于机制的方法来诊断对齐问题并支持改进措施，而不仅仅是表面结果的一致性匹配。"}}
{"id": "2601.11284", "pdf": "https://arxiv.org/pdf/2601.11284", "abs": "https://arxiv.org/abs/2601.11284", "authors": ["Markus Bink", "Marten Risius", "Udo Kruschwitz", "David Elsweiler"], "title": "\"Can You Tell Me?\": Designing Copilots to Support Human Judgement in Online Information Seeking", "categories": ["cs.HC", "cs.IR"], "comment": "Pre-Print accepted at CHIIR 2026", "summary": "Generative AI (GenAI) tools are transforming information seeking, but their fluent, authoritative responses risk overreliance and discourage independent verification and reasoning. Rather than replacing the cognitive work of users, GenAI systems should be designed to support and scaffold it. Therefore, this paper introduces an LLM-based conversational copilot designed to scaffold information evaluation rather than provide answers and foster digital literacy skills. In a pre-registered, randomised controlled trial (N=261) examining three interface conditions including a chat-based copilot, our mixed-methods analysis reveals that users engaged deeply with the copilot, demonstrating metacognitive reflection. However, the copilot did not significantly improve answer correctness or search engagement, largely due to a \"time-on-chat vs. exploration\" trade-off and users' bias toward positive information. Qualitative findings reveal tension between the copilot's Socratic approach and users' desire for efficiency. These results highlight both the promise and pitfalls of pedagogical copilots, and we outline design pathways to reconcile literacy goals with efficiency demands.", "AI": {"tldr": "本文设计了一个基于LLM的对话式副驾系统，旨在支持人类在线信息寻找时的判断能力，而不是直接提供答案。", "motivation": "鉴于生成性AI工具在信息搜寻过程中可能导致用户的过度依赖，作者提出应设计能够支撑和促进用户认知工作的GenAI系统来避免这一问题。", "method": "通过预注册、随机对照试验（N=261），并采用混合方法分析了包括聊天式副驾在内的三种界面条件下的用户体验。", "result": "结果显示，参与者与副驾系统的深度互动中展现出元认知反思，但该系统并未显著提高答案正确率或搜索参与度，主要原因是“在聊天上花费时间而非探索”的权衡以及用户对正面信息的偏好。", "conclusion": "研究结果揭示了教育性副驾系统潜在的优势和挑战，并提出了设计路径以协调数字素养目标与效率需求之间的矛盾。"}}
{"id": "2601.11282", "pdf": "https://arxiv.org/pdf/2601.11282", "abs": "https://arxiv.org/abs/2601.11282", "authors": ["Junjie Wang", "Gaole He", "Alisa Rieger", "Ujwal Gadiraju"], "title": "From SERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics", "categories": ["cs.IR", "cs.AI", "cs.HC", "cs.SI"], "comment": "ACM CHIIR 2026", "summary": "Compared to search engine result pages (SERPs), AI-generated podcasts represent a relatively new and relatively more passive modality of information consumption, delivering narratives in a naturally engaging format. As these two media increasingly converge in everyday information-seeking behavior, it is essential to explore how their interaction influences user attitudes, particularly in contexts involving controversial, value-laden, and often debated topics. Addressing this need, we aim to understand how information mediums of present-day SERPs and AI-generated podcasts interact to shape the opinions of users. To this end, through a controlled user study (N=483), we investigated user attitudinal effects of consuming information via SERPs and AI-generated podcasts, focusing on how the sequence and modality of exposure shape user opinions. A majority of users in our study corresponded to attitude change outcomes, and we found an effect of sequence on attitude change. Our results further revealed a role of viewpoint bias and the degree of topic controversiality in shaping attitude change, although we found no effect of individual moderators.", "AI": {"tldr": "本文研究了搜索结果页面（SERPs）与AI生成播客如何相互作用影响用户对争议性话题的态度。", "motivation": "随着这两种信息消费方式的融合，探索它们在形成用户态度方面的交互效果变得至关重要，尤其是在涉及有争议的话题时。", "method": "通过一项受控的用户研究（N=483），本文探讨了用户通过SERPs和AI生成播客接收信息对态度的影响，并关注暴露顺序和模态如何塑造用户意见。", "result": "多数用户在研究中显示出了态度的变化，且发现顺序对态度变化有影响。结果还揭示了观点偏见和话题争议程度在塑造态度变化中的作用，但未发现个体调节者的效果。", "conclusion": "本文表明SERPs与AI生成播客的交互方式会影响用户对争议性话题的态度变化，并指出了暴露顺序、观点偏见及话题争议程度的作用。"}}
{"id": "2601.11269", "pdf": "https://arxiv.org/pdf/2601.11269", "abs": "https://arxiv.org/abs/2601.11269", "authors": ["Maanping Shao", "Feihong Zhang", "Gu Zhang", "Baiye Cheng", "Zhengrong Xue", "Huazhe Xu"], "title": "X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visuomotor policies often leverage large pre-trained Vision Transformers (ViTs) for their powerful generalization capabilities. However, their significant data requirements present a major challenge in the data-scarce context of most robotic learning settings, where compact CNNs with strong inductive biases can be more easily optimized. To address this trade-off, we introduce X-Distill, a simple yet highly effective method that synergizes the strengths of both architectures. Our approach involves an offline, cross-architecture knowledge distillation, transferring the rich visual representations of a large, frozen DINOv2 teacher to a compact ResNet-18 student on the general-purpose ImageNet dataset. This distilled encoder, now endowed with powerful visual priors, is then jointly fine-tuned with a diffusion policy head on the target manipulation tasks. Extensive experiments on $34$ simulated benchmarks and $5$ challenging real-world tasks demonstrate that our method consistently outperforms policies equipped with from-scratch ResNet or fine-tuned DINOv2 encoders. Notably, X-Distill also surpasses 3D encoders that utilize privileged point cloud observations or much larger Vision-Language Models. Our work highlights the efficacy of a simple, well-founded distillation strategy for achieving state-of-the-art performance in data-efficient robotic manipulation.", "AI": {"tldr": "X-Distill通过跨架构知识蒸馏将大型ViT的强大视觉表示转移到紧凑的CNN上，以提高机器人操作任务的数据效率。", "motivation": "解决在数据稀缺的环境下，如何结合Vision Transformers的强泛化能力和卷积神经网络的优化便捷性的挑战。", "method": "使用预训练的DINOv2作为教师模型，在ImageNet数据集上对ResNet-18进行跨架构知识蒸馏，然后与扩散策略头联合微调以适应特定的操作任务。", "result": "在34个模拟基准和5个真实世界挑战性任务中，X-Distill方法显著优于从零训练的CNN或直接微调的DINOv2编码器，也超过了使用点云观察的三维编码器或更大视觉语言模型的性能。", "conclusion": "研究表明一种简单、有理论基础的知识蒸馏策略在数据高效的机器人操作任务中可以达到最先进的性能。"}}
{"id": "2601.11266", "pdf": "https://arxiv.org/pdf/2601.11266", "abs": "https://arxiv.org/abs/2601.11266", "authors": ["Aoshen Huang", "Jiaming Chen", "Jiyu Cheng", "Ran Song", "Wei Pan", "Wei Zhang"], "title": "Skill-Aware Diffusion for Generalizable Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Robust generalization in robotic manipulation is crucial for robots to adapt flexibly to diverse environments. Existing methods usually improve generalization by scaling data and networks, but model tasks independently and overlook skill-level information. Observing that tasks within the same skill share similar motion patterns, we propose Skill-Aware Diffusion (SADiff), which explicitly incorporates skill-level information to improve generalization. SADiff learns skill-specific representations through a skill-aware encoding module with learnable skill tokens, and conditions a skill-constrained diffusion model to generate object-centric motion flow. A skill-retrieval transformation strategy further exploits skill-specific trajectory priors to refine the mapping from 2D motion flow to executable 3D actions. Furthermore, we introduce IsaacSkill, a high-fidelity dataset containing fundamental robotic skills for comprehensive evaluation and sim-to-real transfer. Experiments in simulation and real-world settings show that SADiff achieves good performance and generalization across various manipulation tasks. Code, data, and videos are available at https://sites.google.com/view/sa-diff.", "AI": {"tldr": "本文提出了Skill-Aware Diffusion (SADiff)，以提升机器人操作的泛化能力，通过学习技能特定表示和利用技能约束扩散模型生成对象中心运动流。", "motivation": "现有的方法通常依赖于增加数据量和网络规模来提高机器人的适应性，但忽略任务间的技能关联性和灵活性。本文旨在解决这一问题。", "method": "SADiff使用技能感知编码模块学习技能特定表示，并通过条件约束的扩散模型生成运动流；采用技能检索转换策略来细化从2D到3D动作的映射。此外，还构建了一个高保真数据集IsaacSkill用于评估和模拟到现实世界的迁移。", "result": "实验结果显示，SADiff在仿真环境和真实世界中实现了良好的性能与泛化能力，在多种操作任务上表现优异。", "conclusion": "研究证明了显式地利用技能级信息对于提升机器人操纵泛化性的有效性。"}}
{"id": "2601.11262", "pdf": "https://arxiv.org/pdf/2601.11262", "abs": "https://arxiv.org/abs/2601.11262", "authors": ["Joanne Affolter", "Benjamin Martin", "Elena V. Epure", "Gabriel Meseguer-Brocal", "Frédéric Kaplan"], "title": "Scalable Music Cover Retrieval Using Lyrics-Aligned Audio Embeddings", "categories": ["cs.SD", "cs.IR", "cs.LG"], "comment": "Published at ECIR 2026 (European Conference of Information Retrieval)", "summary": "Music Cover Retrieval, also known as Version Identification, aims to recognize distinct renditions of the same underlying musical work, a task central to catalog management, copyright enforcement, and music retrieval. State-of-the-art approaches have largely focused on harmonic and melodic features, employing increasingly complex audio pipelines designed to be invariant to musical attributes that often vary widely across covers. While effective, these methods demand substantial training time and computational resources. By contrast, lyrics constitute a strong invariant across covers, though their use has been limited by the difficulty of extracting them accurately and efficiently from polyphonic audio. Early methods relied on simple frameworks that limited downstream performance, while more recent systems deliver stronger results but require large models integrated within complex multimodal architectures. We introduce LIVI (Lyrics-Informed Version Identification), an approach that seeks to balance retrieval accuracy with computational efficiency. First, LIVI leverages supervision from state-of-the-art transcription and text embedding models during training to achieve retrieval accuracy on par with--or superior to--harmonic-based systems. Second, LIVI remains lightweight and efficient by removing the transcription step at inference, challenging the dominance of complexity-heavy pipelines.", "AI": {"tldr": "本文提出了LIVI（Lyrics-Informed Version Identification），一种通过歌词对齐的音频嵌入来实现音乐版本识别的方法，以平衡检索准确性和计算效率。", "motivation": "现有的音乐版本识别方法依赖于复杂的音频特征提取，需要大量的训练时间和计算资源。而歌词作为跨版本不变量的应用因从多声道音频中精确高效地提取歌词困难而受限。", "method": "LIVI在训练过程中利用最先进的转录和文本嵌入模型进行监督，达到与基于谐波的方法相当或更优的检索准确性，并通过去除推理阶段的转录步骤保持轻量化和高效率。", "result": "LIVI实现了与复杂管道方法相媲美的检索精度，同时降低了计算成本。", "conclusion": "该研究证明了通过歌词对齐音频嵌入可以有效实现音乐版本识别，平衡了准确性和计算效率之间的关系。"}}
{"id": "2601.11261", "pdf": "https://arxiv.org/pdf/2601.11261", "abs": "https://arxiv.org/abs/2601.11261", "authors": ["Shinnosuke Touda", "Hirotsugu Okuno"], "title": "Effects of Introducing Synaptic Scaling on Spiking Neural Network Learning", "categories": ["cs.NE", "cs.LG"], "comment": "6 pages, 4 figures, 6 tables", "summary": "Spiking neural networks (SNNs) employing unsupervised learning methods inspired by neural plasticity are expected to be a new framework for artificial intelligence. In this study, we investigated the effect of multiple types of neural plasticity, such as spike-time-dependent plasticity (STDP) and synaptic scaling, on the learning in a winner-take-all (WTA) network composed of spiking neurons. We implemented a WTA network with multiple types of neural plasticity using Python. The MNIST and the Fashion-MNIST datasets were used for training and testing. We varied the number of neurons, the time constant of STDP, and the normalization method used in synaptic scaling to compare classification accuracy. The results demonstrated that synaptic scaling based on the L2 norm was the most effective in improving classification performance. By implementing L2-norm-based synaptic scaling and setting the number of neurons in both excitatory and inhibitory layers to 400, the network achieved classification accuracies of 88.84 % on the MNIST dataset and 68.01 % on the Fashion-MNIST dataset after one epoch of training.", "AI": {"tldr": "研究了突触缩放对脉冲神经网络学习的影响，特别是在分类性能上的效果。", "motivation": "探索结合不同类型神经可塑性（如尖峰时间依赖的可塑性和突触缩放）的方法以提升基于脉冲神经网络框架的人工智能模型的学习能力。", "method": "使用Python实现了包含多种类型神经可塑性的获胜者通吃网络，并通过调整神经元数量、STDP的时间常数和突触缩放中的规范化方法来比较分类准确率。", "result": "研究表明基于L2范数的突触缩放在提高分类性能方面最为有效。在MNIST数据集上达到了88.84%的分类精度，在Fashion-MNIST数据集上达到了68.01%。", "conclusion": "突触缩放，特别是采用L2范数规范化方法，能够显著提升脉冲神经网络的分类性能。"}}
{"id": "2601.11258", "pdf": "https://arxiv.org/pdf/2601.11258", "abs": "https://arxiv.org/abs/2601.11258", "authors": ["Pingzhi Tang", "Yiding Wang", "Muhan Zhang"], "title": "Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) face the \"knowledge cutoff\" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.", "AI": {"tldr": "提出了一种名为参数技能迁移（PaST）的框架，用于高效且有效地适应知识。", "motivation": "解决大型语言模型的知识截止挑战，即其冻结的参数记忆无法直接吸收新信息，并通过轻量级监督微调和强化学习来改进模型在问题回答或决策制定中的表现能力。", "method": "基于观察到监督微调和强化学习引起的参数更新几乎是正交的事实，提出了一种名为参数技能迁移（PaST）的框架，该框架可以抽取一个领域无关的能力向量，并将其线性注入已经进行过轻量级SFT的新数据的目标模型中。", "result": "在知识吸收问题回答（如SQuAD和LooGLE）及代理工具使用基准（ToolBench）上的实验表明了方法的有效性。PaST在SQuAD上比最先进的自我编辑SFT基线高出9.9分，在长上下文问题的回答上，PaST也显示出了8.0个百分点的绝对准确性提升，并且零样本成功率为+10.3点。", "conclusion": "参数技能迁移（PaST）框架在知识适应方面表现出色，其强扩展性和跨域转移能力证明了该方法的有效性。"}}
{"id": "2601.11254", "pdf": "https://arxiv.org/pdf/2601.11254", "abs": "https://arxiv.org/abs/2601.11254", "authors": ["Cheng-Zhuang Liu", "Si-Bao Chen", "Qing-Ling Shu", "Chris Ding", "Jin Tang", "Bin Luo"], "title": "FTDMamba: Frequency-Assisted Temporal Dilation Mamba for Unmanned Aerial Vehicle Video Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in video anomaly detection (VAD) mainly focus on ground-based surveillance or unmanned aerial vehicle (UAV) videos with static backgrounds, whereas research on UAV videos with dynamic backgrounds remains limited. Unlike static scenarios, dynamically captured UAV videos exhibit multi-source motion coupling, where the motion of objects and UAV-induced global motion are intricately intertwined. Consequently, existing methods may misclassify normal UAV movements as anomalies or fail to capture true anomalies concealed within dynamic backgrounds. Moreover, many approaches do not adequately address the joint modeling of inter-frame continuity and local spatial correlations across diverse temporal scales. To overcome these limitations, we propose the Frequency-Assisted Temporal Dilation Mamba (FTDMamba) network for UAV VAD, including two core components: (1) a Frequency Decoupled Spatiotemporal Correlation Module, which disentangles coupled motion patterns and models global spatiotemporal dependencies through frequency analysis; and (2) a Temporal Dilation Mamba Module, which leverages Mamba's sequence modeling capability to jointly learn fine-grained temporal dynamics and local spatial structures across multiple temporal receptive fields. Additionally, unlike existing UAV VAD datasets which focus on static backgrounds, we construct a large-scale Moving UAV VAD dataset (MUVAD), comprising 222,736 frames with 240 anomaly events across 12 anomaly types. Extensive experiments demonstrate that FTDMamba achieves state-of-the-art (SOTA) performance on two public static benchmarks and the new MUVAD dataset. The code and MUVAD dataset will be available at: https://github.com/uavano/FTDMamba.", "AI": {"tldr": "提出了一种名为FTDMamba的网络，用于无人机视频异常检测，特别是在动态背景下的多源运动耦合问题。", "motivation": "现有方法在处理具有动态背景的无人机视频时存在局限性，无法有效区分正常的无人机移动和真正的异常行为。此外，现有的研究往往忽视了跨不同时间尺度的帧间连续性和局部空间相关性的联合建模。", "method": "FTDMamba网络包括两个核心组件：频率解耦时空关联模块（用于分解多源运动模式并通过频域分析建立全局时空依赖关系）和时序扩张Mamba模块（利用Mamba的序列建模能力，在多个时间感受野上同时学习细粒度的时间动态和局部空间结构）。", "result": "实验表明，FTDMamba在网络上的表现优于现有的无人机视频异常检测方法，并在两个公开基准测试集以及一个新的大规模移动无人机视频异常数据集（MUVAD）上实现了最佳性能。", "conclusion": "FTDMamba通过引入新的组件解决了现有无人机视频异常检测中动态背景和多源运动耦合的挑战，展示了其在处理复杂场景下的优越性。"}}
{"id": "2601.11252", "pdf": "https://arxiv.org/pdf/2601.11252", "abs": "https://arxiv.org/abs/2601.11252", "authors": ["Qianyue Wang", "Jinwu Hu", "Yufeng Wang", "Huanxiang Lin", "Bolin Chen", "Zhiquan Wen", "Yaofo Chen", "Mingkui Tan"], "title": "Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.", "AI": {"tldr": "提出Think-with-Me，一种测试时的交互式推理范式，通过引入外部干预来优化深度推理过程。", "motivation": "大规模推理模型虽然在多步推理中表现出色，但存在过度思考和推理冗余的问题。现有方法缺乏对外部干预的支持以引导推理过程。", "method": "Think-with-Me在关键过渡点暂停推理过程，引入外部反馈来延长或终止推理，使用Group Relative Policy Optimization (GRPO)进行训练。", "result": "实验表明，与QwQ-32B相比，Think-with-Me在AIME24任务上提高了7.19%的准确性，并将平均推理长度减少了81%，同时保持了准确性和效率之间的平衡。", "conclusion": "Think-with-Me范式通过引入外部干预成功优化了深度推理过程，不仅提高了解决问题的准确性，还显著缩短了推理时间。"}}
{"id": "2601.11250", "pdf": "https://arxiv.org/pdf/2601.11250", "abs": "https://arxiv.org/abs/2601.11250", "authors": ["Tobias Jülg", "Khaled Gamal", "Nisarga Nilavadi", "Pierre Krack", "Seongjin Bien", "Michael Krawez", "Florian Walter", "Wolfram Burgard"], "title": "VLAgents: A Policy Server for Efficient VLA Inference", "categories": ["cs.RO"], "comment": null, "summary": "The rapid emergence of Vision-Language-Action models (VLAs) has a significant impact on robotics. However, their deployment remains complex due to the fragmented interfaces and the inherent communication latency in distributed setups. To address this, we introduce VLAgents, a modular policy server that abstracts VLA inferencing behind a unified Gymnasium-style protocol. Crucially, its communication layer transparently adapts to the context by supporting both zero-copy shared memory for high-speed simulation and compressed streaming for remote hardware. In this work, we present the architecture of VLAgents and validate it by integrating seven policies -- including OpenVLA and Pi Zero. In a benchmark with both local and remote communication, we further demonstrate how it outperforms the default policy servers provided by OpenVLA, OpenPi, and LeRobot. VLAgents is available at https://github.com/RobotControlStack/vlagents", "AI": {"tldr": "本文介绍了VLAgents，一个用于简化Vision-Language-Action模型部署的模块化策略服务器。", "motivation": "由于接口碎片化和分布式环境中的通信延迟问题，使得Vision-Language-Action模型（VLA）难以高效部署，因此提出了VLAgents来解决这些问题。", "method": "VLAgents通过统一的Gymnasium风格协议抽象了VLA推理过程，并支持零拷贝共享内存以实现高速模拟及压缩流传输以适配远程硬件通信需求。", "result": "通过集成包括OpenVLA和Pi Zero在内的七种策略，验证了在本地和远程通信基准测试中VLAgents优于OpenVLA、OpenPi和LeRobot提供的默认政策服务器的性能。", "conclusion": "VLAgents能够有效简化VLA模型部署过程，并提升其在分布式环境中的运行效率。"}}
{"id": "2601.11248", "pdf": "https://arxiv.org/pdf/2601.11248", "abs": "https://arxiv.org/abs/2601.11248", "authors": ["Fangke Chen", "Tianhao Dong", "Sirry Chen", "Guobin Zhang", "Yishu Zhang", "Yining Chen"], "title": "Language-Agnostic Visual Embeddings for Cross-Script Handwriting Retrieval", "categories": ["cs.CV"], "comment": "9 pages,5 figures", "summary": "Handwritten word retrieval is vital for digital archives but remains challenging due to large handwriting variability and cross-lingual semantic gaps. While large vision-language models offer potential solutions, their prohibitive computational costs hinder practical edge deployment. To address this, we propose a lightweight asymmetric dual-encoder framework that learns unified, style-invariant visual embeddings. By jointly optimizing instance-level alignment and class-level semantic consistency, our approach anchors visual embeddings to language-agnostic semantic prototypes, enforcing invariance across scripts and writing styles. Experiments show that our method outperforms 28 baselines and achieves state-of-the-art accuracy on within-language retrieval benchmarks. We further conduct explicit cross-lingual retrieval, where the query language differs from the target language, to validate the effectiveness of the learned cross-lingual representations. Achieving strong performance with only a fraction of the parameters required by existing models, our framework enables accurate and resource-efficient cross-script handwriting retrieval.", "AI": {"tldr": "本文提出了一个轻量级的非对称双编码器框架，用于学习统一的、风格不变的视觉嵌入，以实现跨脚本手写检索。", "motivation": "手写单词检索对于数字档案至关重要但具有挑战性，因为存在大量的书写变化和跨语言语义差距，并且大模型计算成本高难以部署到边缘设备上。", "method": "采用轻量级非对称双编码器框架学习统一的风格不变视觉嵌入，通过实例级别的对齐优化和类级别的语义一致性约束来锚定视觉嵌入到语言无关的语义原型中。", "result": "实验表明该方法在内语言检索基准上优于28个基线，并达到最先进的准确性，在显式的跨语言检索上也表现出色。", "conclusion": "使用少量参数实现了准确且资源高效的跨脚本手写检索，证明了所提框架的有效性。"}}
{"id": "2601.11243", "pdf": "https://arxiv.org/pdf/2601.11243", "abs": "https://arxiv.org/abs/2601.11243", "authors": ["Zhiqi Pang", "Lingling Zhao", "Yang Liu", "Chunyu Wang", "Gaurav Sharma"], "title": "Image-Text Knowledge Modeling for Unsupervised Multi-Scenario Person Re-Identification", "categories": ["cs.CV"], "comment": "12 pages, 10 figures", "summary": "We propose unsupervised multi-scenario (UMS) person re-identification (ReID) as a new task that expands ReID across diverse scenarios (cross-resolution, clothing change, etc.) within a single coherent framework. To tackle UMS-ReID, we introduce image-text knowledge modeling (ITKM) -- a three-stage framework that effectively exploits the representational power of vision-language models. We start with a pre-trained CLIP model with an image encoder and a text encoder. In Stage I, we introduce a scenario embedding in the image encoder and fine-tune the encoder to adaptively leverage knowledge from multiple scenarios. In Stage II, we optimize a set of learned text embeddings to associate with pseudo-labels from Stage I and introduce a multi-scenario separation loss to increase the divergence between inter-scenario text representations. In Stage III, we first introduce cluster-level and instance-level heterogeneous matching modules to obtain reliable heterogeneous positive pairs (e.g., a visible image and an infrared image of the same person) within each scenario. Next, we propose a dynamic text representation update strategy to maintain consistency between text and image supervision signals. Experimental results across multiple scenarios demonstrate the superiority and generalizability of ITKM; it not only outperforms existing scenario-specific methods but also enhances overall performance by integrating knowledge from multiple scenarios.", "AI": {"tldr": "本文提出了一种无监督多场景人物再识别任务及其图像文本知识建模方法。", "motivation": "旨在扩展现有的人物再识别技术，使其能够处理多种不同的复杂情况（如跨分辨率、着装变化等）。", "method": "使用包含三阶段的框架ITKM，通过预训练模型CLIP进行场景嵌入和优化，并提出动态文本表示更新策略以维护图像与文本监督信号的一致性。", "result": "实验结果表明，该方法在多种情况下都表现出优越性和通用性，不仅超越了现有针对特定场景的方法，还通过整合多场景知识增强了整体性能。", "conclusion": "ITKM框架证明了其在无监督多场景人物再识别任务中的有效性和潜力，为处理复杂视觉信息提供了新的思路和技术支持。"}}
{"id": "2601.11235", "pdf": "https://arxiv.org/pdf/2601.11235", "abs": "https://arxiv.org/abs/2601.11235", "authors": ["Ana Davila", "Jacinto Colan", "Yasuhisa Hasegawa"], "title": "Bio-inspired fine-tuning for selective transfer learning in image classification", "categories": ["cs.CV"], "comment": "ef:Published in IEEE Access, vol. 13, pp. 129234-129249, 2025", "summary": "Deep learning has significantly advanced image analysis across diverse domains but often depends on large, annotated datasets for success. Transfer learning addresses this challenge by utilizing pre-trained models to tackle new tasks with limited labeled data. However, discrepancies between source and target domains can hinder effective transfer learning. We introduce BioTune, a novel adaptive fine-tuning technique utilizing evolutionary optimization. BioTune enhances transfer learning by optimally choosing which layers to freeze and adjusting learning rates for unfrozen layers. Through extensive evaluation on nine image classification datasets, spanning natural and specialized domains such as medical imaging, BioTune demonstrates superior accuracy and efficiency over state-of-the-art fine-tuning methods, including AutoRGN and LoRA, highlighting its adaptability to various data characteristics and distribution changes. Additionally, BioTune consistently achieves top performance across four different CNN architectures, underscoring its flexibility. Ablation studies provide valuable insights into the impact of BioTune's key components on overall performance. The source code is available at https://github.com/davilac/BioTune.", "AI": {"tldr": "本文提出了BioTune，一种基于生物启发的自适应微调技术，用于提升图像分类任务中的选择性迁移学习效果。", "motivation": "深度学习虽提升了图像分析能力，但仍依赖大量标注数据。然而，在源域和目标域之间存在不一致时，传统的迁移学习方法可能会受到影响。因此，本文旨在通过优化层的选择与调整学习率来改善这一问题。", "method": "BioTune采用进化优化技术，通过对哪些层进行冻结以及如何调整未冻结层的学习率来进行自适应微调。", "result": "在九个不同领域的图像分类数据集上进行了广泛的评估，结果表明BioTune比现有的自适应方法如AutoRGN和LoRA表现更优。它还展示了在四种不同的卷积神经网络架构中的一致性高性能。", "conclusion": "通过实验验证，BioTune提高了迁移学习的准确性和效率，并且展现出对数据特性和分布变化的强大适应能力。"}}
{"id": "2601.11232", "pdf": "https://arxiv.org/pdf/2601.11232", "abs": "https://arxiv.org/abs/2601.11232", "authors": ["Javier Carnerero-Cano", "Massimiliano Pronesti", "Radu Marinescu", "Tigran Tchrakian", "James Barry", "Jasmina Gajcin", "Yufang Hou", "Alessandra Pascale", "Elizabeth Daly"], "title": "FactCorrector: A Graph-Inspired Approach to Long-Form Factuality Correction of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are widely used in knowledge-intensive applications but often generate factually incorrect responses. A promising approach to rectify these flaws is correcting LLMs using feedback. Therefore, in this paper, we introduce FactCorrector, a new post-hoc correction method that adapts across domains without retraining and leverages structured feedback about the factuality of the original response to generate a correction. To support rigorous evaluations of factuality correction methods, we also develop the VELI5 benchmark, a novel dataset containing systematically injected factual errors and ground-truth corrections. Experiments on VELI5 and several popular long-form factuality datasets show that the FactCorrector approach significantly improves factual precision while preserving relevance, outperforming strong baselines. We release our code at https://ibm.biz/factcorrector.", "AI": {"tldr": "本文介绍了FactCorrector，一种无需重新训练即可跨领域适应的长文本事实性纠正方法，并开发了一个新的基准数据集VELI5用于评估事实性纠正方法。", "motivation": "大型语言模型（LLMs）在知识密集型应用中广泛使用但经常产生不正确的响应，通过反馈来校正这些错误是一个有前景的方法。", "method": "FactCorrector利用结构化的反馈关于原始响应的事实性，生成纠正信息。同时开发了包含系统性注入的事实性错误和真实修正的VELI5基准数据集。", "result": "在VELI5和其他流行的长文本事实性数据集中进行的实验表明，FactCorrector方法显著提高了事实准确性，同时保持相关性，超越了强大的基线模型。", "conclusion": "FactCorrector证明了一种有效的方法，可以提高大型语言模型的事实准确性而不影响其相关性，并且无需重新训练。"}}
{"id": "2601.11231", "pdf": "https://arxiv.org/pdf/2601.11231", "abs": "https://arxiv.org/abs/2601.11231", "authors": ["Savvas Papaioannou", "Panayiotis Kolios", "Christos G. Panayiotou", "Marios M. Polycarpou"], "title": "Adaptive Monitoring of Stochastic Fire Front Processes via Information-seeking Predictive Control", "categories": ["cs.RO", "eess.SY"], "comment": "2025 IEEE 64th Conference on Decision and Control (CDC)", "summary": "We consider the problem of adaptively monitoring a wildfire front using a mobile agent (e.g., a drone), whose trajectory determines where sensor data is collected and thus influences the accuracy of fire propagation estimation. This is a challenging problem, as the stochastic nature of wildfire evolution requires the seamless integration of sensing, estimation, and control, often treated separately in existing methods. State-of-the-art methods either impose linear-Gaussian assumptions to establish optimality or rely on approximations and heuristics, often without providing explicit performance guarantees. To address these limitations, we formulate the fire front monitoring task as a stochastic optimal control problem that integrates sensing, estimation, and control. We derive an optimal recursive Bayesian estimator for a class of stochastic nonlinear elliptical-growth fire front models. Subsequently, we transform the resulting nonlinear stochastic control problem into a finite-horizon Markov decision process and design an information-seeking predictive control law obtained via a lower confidence bound-based adaptive search algorithm with asymptotic convergence to the optimal policy.", "AI": {"tldr": "本文提出了一种自适应监控野火前沿的方法，通过移动代理（例如无人机）的轨迹优化来提高火灾蔓延估计的准确性。", "motivation": "现有的方法要么在线性高斯假设下建立最优性，要么依赖近似和启发式方法，并且通常不提供明确的性能保证。因此，需要一种整合感知、估计和控制的方法来应对野火前沿监测挑战。", "method": "本文将野火前沿监控任务定义为一个随机最优控制问题，推导出一类随机非线性椭圆生长模型下的递归贝叶斯估计器，并设计了一个基于下置信界自适应搜索算法的信息寻求预测控制律。", "result": "通过将非线性随机控制问题转化为有限时间范围的马尔可夫决策过程，并设计了信息寻求预测控制律，该方法具有渐近收敛到最优策略的能力。", "conclusion": "本文提出的方法能够有效解决野火前沿自适应监测的问题，提供了一种整合感知、估计和控制的新途径。"}}
{"id": "2601.11219", "pdf": "https://arxiv.org/pdf/2601.11219", "abs": "https://arxiv.org/abs/2601.11219", "authors": ["Zhikang Shen", "Jianrong Lu", "Haiyuan Wan", "Jianhai Chen"], "title": "SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) for large language models (LLMs) has attracted increasing attention as a way to enable privacy-preserving adaptation over distributed data. Parameter-efficient methods such as LoRA are widely adopted to reduce communication and memory costs. Despite these advances, practical FL deployments often exhibit rank heterogeneity, since different clients may use different low-rank configurations. This makes direct aggregation of LoRA updates biased and unstable. Existing solutions typically enforce unified ranks or align heterogeneous updates into a shared subspace, which over-constrains client-specific semantics, limits personalization, and provides weak protection of local client information under differential privacy noise. To address this issue, we propose Selective Dual-module Federated LoRA (SDFLoRA), which decomposes each client adapter into a global module that captures transferable knowledge and a local module that preserves client-specific adaptations. The global module is selectively aligned and aggregated across clients, while local modules remain private. This design enables robust learning under rank heterogeneity and supports privacy-aware optimization by injecting differential privacy noise exclusively into the global module. Experiments on GLUE benchmarks demonstrate that SDFLoRA outperforms representative federated LoRA baselines and achieves a better utility-privacy trade-off.", "AI": {"tldr": "论文提出了一种名为SDFLoRA的选择性双模块Federated LoRA方法，以应对联邦学习中不同客户端使用不同低秩配置的挑战。", "motivation": "该研究旨在解决联邦学习部署中存在的排名异质问题，这导致直接聚合LoRA更新出现偏差和不稳定。现有的解决方案要么强制统一等级，要么将异构更新对齐到共享子空间，限制了个性化并削弱了在差分隐私噪声下的本地客户端信息保护。", "method": "SDFLoRA通过将每个客户端适配器分解为一个捕获可转移知识的全局模块和一个保留特定客户适应性的局部模块来实现。全局模块在客户端之间选择性对齐和聚合，而局部模块保持私密。", "result": "实验结果显示SDFLoRA优于代表性的联邦LoRA基线，并且实现了更好的效用-隐私权衡。", "conclusion": "通过SDFLoRA的设计，能够在排名异质条件下实现稳健学习并支持隐私优化，同时向全局模块注入差分隐私噪声。"}}
{"id": "2601.11218", "pdf": "https://arxiv.org/pdf/2601.11218", "abs": "https://arxiv.org/abs/2601.11218", "authors": ["Sergio Mascetti", "Matteo Manzoni", "Filippo Corti", "Dragan Ahmetovic"], "title": "Game Accessibility Through Shared Control for People With Upper-Limb Impairments", "categories": ["cs.HC"], "comment": "27 pages (excluding references and appendix)", "summary": "Accessing video games is challenging for people with upper-limb impairments, especially when multiple inputs are required in rapid succession. Human cooperation, where a copilot assists the main player, has been proposed as a solution, but relying on a human assistant poses limitations in terms of availability and co-location. An alternative solution is to use partial automation, where the player is assisted by a software agent. In this work, we present a study with 13 participants with upper-limb impairments, comparatively evaluating how participants collaborate with their copilot in human cooperation and partial automation. The experiment is supported by GamePals, a modular framework that enables both human cooperation and partial automation on existing third-party video games.", "AI": {"tldr": "研究了通过共享控制（人类合作和部分自动化）来提高上肢残疾人士的视频游戏可访问性。", "motivation": "为了解决上肢功能障碍者在快速连续输入多个指令时难以接触视频游戏的问题，并探索不依赖于人工助手的解决方案。", "method": "进行了一个实验，包括13名有上肢功能障碍的参与者，比较了人类合作和部分自动化这两种协作方式。使用GamePals框架，在现有的第三方视频游戏中支持这两类控制方法。", "result": "研究结果评估了参与者在人类合作与部分自动化的不同情况下进行游戏时的表现和体验。", "conclusion": "通过实验数据分析得出结论，关于如何更好地利用共享控制技术来提高上肢功能障碍者的游戏可访问性。"}}
{"id": "2601.11210", "pdf": "https://arxiv.org/pdf/2601.11210", "abs": "https://arxiv.org/abs/2601.11210", "authors": ["Li Wang", "Wenyu Chen", "Ning Yu", "Zheng Li", "Shanqing Guo"], "title": "VidLeaks: Membership Inference Attacks Against Text-to-Video Models", "categories": ["cs.CR", "cs.CV"], "comment": null, "summary": "The proliferation of powerful Text-to-Video (T2V) models, trained on massive web-scale datasets, raises urgent concerns about copyright and privacy violations. Membership inference attacks (MIAs) provide a principled tool for auditing such risks, yet existing techniques - designed for static data like images or text - fail to capture the spatio-temporal complexities of video generation. In particular, they overlook the sparsity of memorization signals in keyframes and the instability introduced by stochastic temporal dynamics. In this paper, we conduct the first systematic study of MIAs against T2V models and introduce a novel framework VidLeaks, which probes sparse-temporal memorization through two complementary signals: 1) Spatial Reconstruction Fidelity (SRF), using a Top-K similarity to amplify spatial memorization signals from sparsely memorized keyframes, and 2) Temporal Generative Stability (TGS), which measures semantic consistency across multiple queries to capture temporal leakage. We evaluate VidLeaks under three progressively restrictive black-box settings - supervised, reference-based, and query-only. Experiments on three representative T2V models reveal severe vulnerabilities: VidLeaks achieves AUC of 82.92% on AnimateDiff and 97.01% on InstructVideo even in the strict query-only setting, posing a realistic and exploitable privacy risk. Our work provides the first concrete evidence that T2V models leak substantial membership information through both sparse and temporal memorization, establishing a foundation for auditing video generation systems and motivating the development of new defenses. Code is available at: https://zenodo.org/records/17972831.", "AI": {"tldr": "该论文介绍了针对文本到视频模型的成员推理攻击框架VidLeaks，通过空间重建保真度和时间生成稳定性来检测潜在隐私风险。", "motivation": "现有的成员推理技术不适用于视频数据的空间-时间复杂性，因此需要开发新的方法来审计由大规模训练集引起的版权和隐私问题。", "method": "引入了两个互补的信号：空间重建保真度（SRF）和时间生成稳定性（TGS），并评估在三种不同的黑盒设置下的性能。", "result": "实验表明，VidLeaks即使在严格的查询仅限条件下，在AnimateDiff上的AUC为82.92%，在InstructVideo上达到97.01%。", "conclusion": "该研究证明了T2V模型通过稀疏和时间记忆泄露大量成员信息，并为此类系统的审计奠定了基础。"}}
{"id": "2601.11207", "pdf": "https://arxiv.org/pdf/2601.11207", "abs": "https://arxiv.org/abs/2601.11207", "authors": ["Marco Arazzi", "Antonino Nocera"], "title": "LoRA as Oracle", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Backdoored and privacy-leaking deep neural networks pose a serious threat to the deployment of machine learning systems in security-critical settings. Existing defenses for backdoor detection and membership inference typically require access to clean reference models, extensive retraining, or strong assumptions about the attack mechanism. In this work, we introduce a novel LoRA-based oracle framework that leverages low-rank adaptation modules as a lightweight, model-agnostic probe for both backdoor detection and membership inference. Our approach attaches task-specific LoRA adapters to a frozen backbone and analyzes their optimization dynamics and representation shifts when exposed to suspicious samples. We show that poisoned and member samples induce distinctive low-rank updates that differ significantly from those generated by clean or non-member data. These signals can be measured using simple ranking and energy-based statistics, enabling reliable inference without access to the original training data or modification of the deployed model.", "AI": {"tldr": "本文提出了一种基于LoRA的Oracle框架，用于检测后门和成员推理问题。", "motivation": "现有的防御方法需要干净的参考模型、广泛的重新训练或对攻击机制的强大假设，这些限制促使了更轻量级、无特定模型依赖的方法的需求。", "method": "该方法通过将任务特定的LoRA适配器附加到冻结的基础模型上，并分析可疑样本暴露下的优化动态和表示变化来检测后门和成员推理问题。", "result": "研究表明，被污染或属于成员的数据会引发与干净数据显著不同的低秩更新，这些信号可以通过简单的排名和能量基统计量进行测量，从而实现可靠的推断。", "conclusion": "该方法能够在无需访问原始训练数据或修改部署模型的情况下，通过简单有效的统计量识别后门样本和成员推理。"}}
{"id": "2601.11202", "pdf": "https://arxiv.org/pdf/2601.11202", "abs": "https://arxiv.org/abs/2601.11202", "authors": ["Emanuele Ratti"], "title": "Epistemic Control and the Normativity of Machine Learning-Based Science", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The past few years have witnessed an increasing use of machine learning (ML) systems in science. Paul Humphreys has argued that, because of specific characteristics of ML systems, human scientists are pushed out of the loop of science. In this chapter, I investigate to what extent this is true. First, I express these concerns in terms of what I call epistemic control. I identify two conditions for epistemic control, called tracking and tracing, drawing on works in philosophy of technology. With this new understanding of the problem, I then argue against Humphreys pessimistic view. Finally, I construct a more nuanced view of epistemic control in ML-based science.", "AI": {"tldr": "本文探讨了机器学习系统在科学中的应用是否会导致人类科学家被排除在外的问题，并提出了一个更细腻的关于机器学习科学中认知控制的观点。", "motivation": "鉴于近年来机器学习系统越来越多地应用于科学研究，保罗·汉弗莱斯认为由于机器学习系统的特定特点，人类科学家可能会被排挤出科研过程。本文旨在探讨这一观点的真实性。", "method": "作者首先将这些问题用一种称为认知控制的术语来表达，并确定了两个条件：追踪和追溯。然后利用技术哲学中的相关工作对汉弗莱斯悲观的观点提出反对意见。", "result": "通过对认知控制问题的新理解，本文构建了一个关于机器学习科学中更细腻的认知控制观点。", "conclusion": "研究结论是机器学习系统在科学研究中的应用并不必然导致人类科学家被排除在外，而是需要从更加综合的角度来看待其影响。"}}
{"id": "2601.11200", "pdf": "https://arxiv.org/pdf/2601.11200", "abs": "https://arxiv.org/abs/2601.11200", "authors": ["Haiyang Xiao", "Weiqing Li", "Jinyue Guo", "Guochao Jiang", "Guohua Liu", "Yuewei Zhang"], "title": "FAQ: Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Although post-training quantization (PTQ) provides an efficient numerical compression scheme for deploying large language models (LLMs) on resource-constrained devices, the representativeness and universality of calibration data remain a core bottleneck in determining the accuracy of quantization parameters. Traditional PTQ methods typically rely on limited samples, making it difficult to capture the activation distribution during the inference phase, leading to biases in quantization parameters. To address this, we propose \\textbf{FAQ} (Family-Aware Quantization), a calibration data regeneration framework that leverages prior knowledge from LLMs of the same family to generate high-fidelity calibration samples. Specifically, FAQ first inputs the original calibration samples into a larger LLM from the same family as the target model, regenerating a series of high-fidelity calibration data using a highly consistent knowledge system. Subsequently, this data, carrying Chain-of-Thought reasoning and conforming to the expected activation distribution, undergoes group competition under expert guidance to select the best samples, which are then re-normalized to enhance the effectiveness of standard PTQ. Experiments on multiple model series, including Qwen3-8B, show that FAQ reduces accuracy loss by up to 28.5\\% compared to the baseline with original calibration data, demonstrating its powerful potential and contribution.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.11199", "pdf": "https://arxiv.org/pdf/2601.11199", "abs": "https://arxiv.org/abs/2601.11199", "authors": ["Aiman Al Masoud", "Marco Arazzi", "Antonino Nocera"], "title": "SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has attracted significant attention due to its ability to combine the generative capabilities of Large Language Models (LLMs) with knowledge obtained through efficient retrieval mechanisms over large-scale data collections. Currently, the majority of existing approaches overlook the risks associated with exposing sensitive or access-controlled information directly to the generation model. Only a few approaches propose techniques to instruct the generative model to refrain from disclosing sensitive information; however, recent studies have also demonstrated that LLMs remain vulnerable to prompt injection attacks that can override intended behavioral constraints. For these reasons, we propose a novel approach to Selective Disclosure in Retrieval-Augmented Generation, called SD-RAG, which decouples the enforcement of security and privacy constraints from the generation process itself. Rather than relying on prompt-level safeguards, SD-RAG applies sanitization and disclosure controls during the retrieval phase, prior to augmenting the language model's input. Moreover, we introduce a semantic mechanism to allow the ingestion of human-readable dynamic security and privacy constraints together with an optimized graph-based data model that supports fine-grained, policy-aware retrieval. Our experimental evaluation demonstrates the superiority of SD-RAG over baseline existing approaches, achieving up to a $58\\%$ improvement in the privacy score, while also showing a strong resilience to prompt injection attacks targeting the generative model.", "AI": {"tldr": "本文提出SD-RAG框架，以解决检索增强生成中敏感信息泄露的问题，并展示其在隐私保护和抵御提示注入攻击方面的优越性。", "motivation": "现有的RAG方法忽视了暴露敏感或受控信息的风险，仅有的少数方法也无法完全防止LLMs因提示注入攻击而泄漏信息。因此提出了SD-RAG框架以解决这些问题。", "method": "SD-RAG通过在检索阶段实施净化和披露控制来解耦安全性与隐私约束的执行，并引入语义机制和优化图数据模型支持细粒度、策略感知检索。", "result": "实验结果显示，相较于现有方法，SD-RAG提高了58%的隐私分数，并显示出强大的抵御生成模型提示注入攻击的能力。", "conclusion": "SD-RAG在保护敏感信息和增强RAG安全性方面表现出色，特别是在抵御提示注入攻击方面的优越性得到了验证。"}}
{"id": "2601.11196", "pdf": "https://arxiv.org/pdf/2601.11196", "abs": "https://arxiv.org/abs/2601.11196", "authors": ["Luisa Carpinelli", "Filippo Natoli", "Marco Taboga"], "title": "Artificial Intelligence and the US Economy: An Accounting Perspective on Investment and Production", "categories": ["econ.GN", "cs.AI"], "comment": "35 pages, 11 figures, pre-print", "summary": "Artificial intelligence (AI) has moved to the center of policy, market, and academic debates, but its macroeconomic footprint is still only partly understood. This paper provides an overview on how the current AI wave is captured in US national accounts, combining a simple macro-accounting framework with a stylized description of the AI production process. We highlight the crucial role played by data centers, which constitute the backbone of the AI ecosystem and have attracted formidable investment in 2025, as they are indispensable for meeting the rapidly increasing worldwide demand for AI services. We document that the boom in IT and AI-related capital expenditure in the first three quarters of the year has given an outsized boost to aggregate demand, while its contribution to GDP growth is smaller once the high import content of AI hardware is netted out. Furthermore, simple calculations suggest that, at current utilization rates and pricing, the production of services originating in new AI data centers could contribute to GDP over the turn of the next quarters on a scale comparable to that of investment spending to date. Short reinvestment cycles and uncertainty about future AI demand, while not currently acting as a macroeconomic drag, can nevertheless fuel macroeconomic risks over the medium term.", "AI": {"tldr": "本文探讨了当前人工智能浪潮在美国国民经济账户中的体现，结合简单的宏观经济会计框架和对AI生产过程的简要描述。", "motivation": "尽管人工智能已经成为了政策、市场和学术讨论的核心，但其宏观经济影响尚未完全明了，因此有必要对其进行研究。", "method": "使用一个简单宏观会计框架与AI生产的简化模型相结合的方法来分析数据。", "result": "数据显示，在2025年的前三季度中，IT和AI相关的资本支出显著提升了总体需求，尽管AI硬件的高进口比例减少了对GDP增长的贡献。此外，新的人工智能数据中心的服务产出可能在未来几个季度内为GDP作出重要贡献，其规模与当前的投资支出相当。", "conclusion": "短期内，频繁的再投资循环和对未来人工智能需求的不确定性并未成为宏观经济拖累，但可能会在中期增加宏观经济风险。"}}
{"id": "2601.11194", "pdf": "https://arxiv.org/pdf/2601.11194", "abs": "https://arxiv.org/abs/2601.11194", "authors": ["Boyi Pang", "Savva Ignatyev", "Vladimir Ippolitov", "Ramil Khafizov", "Yurii Melnik", "Oleg Voynov", "Maksim Nakhodnov", "Aibek Alanov", "Xiaopeng Fan", "Peter Wonka", "Evgeny Burnaev"], "title": "ATATA: One Algorithm to Align Them All", "categories": ["cs.CV"], "comment": null, "summary": "We suggest a new multi-modal algorithm for joint inference of paired structurally aligned samples with Rectified Flow models. While some existing methods propose a codependent generation process, they do not view the problem of joint generation from a structural alignment perspective. Recent work uses Score Distillation Sampling to generate aligned 3D models, but SDS is known to be time-consuming, prone to mode collapse, and often provides cartoonish results. By contrast, our suggested approach relies on the joint transport of a segment in the sample space, yielding faster computation at inference time. Our approach can be built on top of an arbitrary Rectified Flow model operating on the structured latent space. We show the applicability of our method to the domains of image, video, and 3D shape generation using state-of-the-art baselines and evaluate it against both editing-based and joint inference-based competing approaches. We demonstrate a high degree of structural alignment for the sample pairs obtained with our method and a high visual quality of the samples. Our method improves the state-of-the-art for image and video generation pipelines. For 3D generation, it is able to show comparable quality while working orders of magnitude faster.", "AI": {"tldr": "本文提出了一种新的多模态算法ATATA，用于联合推断配对结构对齐样本。", "motivation": "现有的方法要么缺乏从结构对齐的角度进行联合生成的能力，要么如SDS一样存在计算成本高、模式崩溃和结果卡通化的问题。因此，提出了更快速且视觉质量高的新方法。", "method": "该方法基于Rectified Flow模型在结构化的潜在空间上操作，并通过样本空间的联合传输实现配对结构的对齐。", "result": "实验显示，这种方法在图像、视频和3D形状生成领域表现良好，特别是在速度上有显著提升，在视觉质量上也优于现有方法。", "conclusion": "ATATA算法展示了在多模态生成任务中提高效率和保持高质量输出的能力，并且在多种应用上超越了当前的最佳性能。"}}
{"id": "2601.11189", "pdf": "https://arxiv.org/pdf/2601.11189", "abs": "https://arxiv.org/abs/2601.11189", "authors": ["Sofiene Lassoued", "Asrat Gobachew", "Stefan Lier", "Andreas Schwung"], "title": "Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling Problems", "categories": ["cs.AI"], "comment": null, "summary": "This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. We extend the hyper-heuristic framework with two key mechanisms. First, action prefiltering restricts decision-making to feasible low-level actions, enabling low-level heuristics to be evaluated independently of environmental constraints and providing an unbiased assessment. Second, a commitment mechanism regulates the frequency of heuristic switching. We investigate the impact of different commitment strategies, from step-wise switching to full-episode commitment, on both training behavior and makespan. Additionally, we compare two action selection strategies at the policy level: deterministic greedy selection and stochastic sampling. Computational experiments on standard JSSP benchmarks demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods", "AI": {"tldr": "本文提出了一种基于策略的深度强化学习超启发式框架，用于解决作业车间调度问题。", "motivation": "传统的启发式和元启发式方法在解决复杂调度问题时存在局限性，因此研究者提出了新的方法来提高求解质量和效率。", "method": "该框架包含两种关键机制：动作预过滤确保决策仅限于可行的低层操作，并独立评估低层启发式；承诺机制调节启发式的切换频率。同时比较了确定性和随机性的策略层面的动作选择策略。", "result": "实验结果表明，提出的方法在标准JSSP基准测试中优于传统的启发式算法、元启发式以及基于神经网络的调度方法。", "conclusion": "研究证明了所提出的深度强化学习超启发式框架在解决作业车间调度问题上的有效性和优越性。"}}
{"id": "2601.11183", "pdf": "https://arxiv.org/pdf/2601.11183", "abs": "https://arxiv.org/abs/2601.11183", "authors": ["Shuang Chen", "Jie Wang", "Shuai Yuan", "Jiayang Li", "Yu Xia", "Yuanhong Liao", "Junbo Wei", "Jincheng Yuan", "Xiaoqing Xu", "Xiaolin Zhu", "Peng Zhu", "Hongsheng Zhang", "Yuyu Zhou", "Haohuan Fu", "Huabing Huang", "Bin Chen", "Fan Dai", "Peng Gong"], "title": "Democratizing planetary-scale analysis: An ultra-lightweight Earth embedding database for accurate and flexible global land monitoring", "categories": ["cs.CV"], "comment": null, "summary": "The rapid evolution of satellite-borne Earth Observation (EO) systems has revolutionized terrestrial monitoring, yielding petabyte-scale archives. However, the immense computational and storage requirements for global-scale analysis often preclude widespread use, hindering planetary-scale studies. To address these barriers, we present Embedded Seamless Data (ESD), an ultra-lightweight, 30-m global Earth embedding database spanning the 25-year period from 2000 to 2024. By transforming high-dimensional, multi-sensor observations from the Landsat series (5, 7, 8, and 9) and MODIS Terra into information-dense, quantized latent vectors, ESD distills essential geophysical and semantic features into a unified latent space. Utilizing the ESDNet architecture and Finite Scalar Quantization (FSQ), the dataset achieves a transformative ~340-fold reduction in data volume compared to raw archives. This compression allows the entire global land surface for a single year to be encapsulated within approximately 2.4 TB, enabling decadal-scale global analysis on standard local workstations. Rigorous validation demonstrates high reconstructive fidelity (MAE: 0.0130; RMSE: 0.0179; CC: 0.8543). By condensing the annual phenological cycle into 12 temporal steps, the embeddings provide inherent denoising and a semantically organized space that outperforms raw reflectance in land-cover classification, achieving 79.74% accuracy (vs. 76.92% for raw fusion). With robust few-shot learning capabilities and longitudinal consistency, ESD provides a versatile foundation for democratizing planetary-scale research and advancing next-generation geospatial artificial intelligence.", "AI": {"tldr": "本文介绍了一种名为Embedded Seamless Data（ESD）的超轻量级地球嵌入数据库，用于实现准确和灵活的全球地表监测。", "motivation": "卫星地球观测系统的快速发展带来了大量的数据存档，但大规模分析所需的计算资源和存储需求高，限制了其广泛应用。本文旨在解决这些障碍，使得全球范围的研究更加普及。", "method": "通过将来自Landsat系列（5,7,8,9）和MODIS Terra的多传感器观测转化为信息密集型量化潜在向量，ESDNet架构和有限标量量化技术实现了大约340倍的数据压缩。", "result": "实验验证了重建保真度高（MAE: 0.0130; RMSE: 0.0179; CC: 0.8543），且在土地覆盖分类方面优于原始反射率数据，达到79.74%的准确率。", "conclusion": "ESD为地球科学和人工智能领域提供了一个灵活的基础，推动了新一代地理空间智能的发展，并实现了全球规模研究的普及。"}}
{"id": "2601.11178", "pdf": "https://arxiv.org/pdf/2601.11178", "abs": "https://arxiv.org/abs/2601.11178", "authors": ["Girish A. Koushik", "Helen Treharne", "Diptesh Kanojia"], "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech", "categories": ["cs.AI", "cs.CL", "cs.MM", "cs.SI"], "comment": "Under review at ICWSM 2026", "summary": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.", "AI": {"tldr": "介绍TANDEM框架，用于时间感知的多模态仇恨言论检测。", "motivation": "自动系统虽然能以高准确率标记仇恨言论，但难以提供细粒度、可解释的证据，如精确的时间戳和目标身份，这阻碍了有效的人机协作审核。", "method": "使用新的串联强化学习策略，视觉-语言模型和音频-语言模型通过自我约束跨模态上下文互相优化，在不需要密集帧级监督的情况下稳定推理。", "result": "实验显示TANDEM在三个基准数据集上显著优于零样本和增强背景的基线方法，HateMM目标识别F1值为0.73，比最先进方法提高了30%。", "conclusion": "研究表明，在复杂多模态环境下实现结构化、可解释对齐是可能的，并提供了一个蓝图以创建下一代透明且行动导向的在线安全审核工具。"}}
{"id": "2601.11171", "pdf": "https://arxiv.org/pdf/2601.11171", "abs": "https://arxiv.org/abs/2601.11171", "authors": ["Jules Wulms", "Wouter Meulemans", "Bettina Speckmann"], "title": "Noisy Graph Patterns via Ordered Matrices", "categories": ["cs.HC"], "comment": null, "summary": "The high-level structure of a graph is a crucial ingredient for the analysis and visualization of relational data. However, discovering the salient graph patterns that form this structure is notoriously difficult for two reasons. (1) Finding important patterns, such as cliques and bicliques, is computationally hard. (2) Real-world graphs contain noise, and therefore do not always exhibit patterns in their pure form. Defining meaningful noisy patterns and detecting them efficiently is a currently unsolved challenge. In this paper, we propose to use well-ordered matrices as a tool to both define and effectively detect noisy patterns. Specifically, we represent a graph as its adjacency matrix and optimally order it using Moran's $I$. Standard graph patterns (cliques, bicliques, and stars) now translate to rectangular submatrices. Using Moran's $I$, we define a permitted level of noise for such patterns. A combination of exact algorithms and heuristics allows us to efficiently decompose the matrix into noisy patterns. We also introduce a novel motif simplification that visualizes noisy patterns while explicitly encoding the level of noise. We showcase our techniques on several real-world data sets.", "AI": {"tldr": "本文提出使用有序矩阵来定义和有效检测图中的噪声模式。", "motivation": "发现图中的重要模式（如团、双团）很困难，且现实世界中的图含有噪声，因此寻找有效的噪声模式定义与检测方法是一个未解决的挑战。", "method": "通过将图表示为其邻接矩阵并使用Moran的$I$进行最优排序，标准图形模式转换为矩形子矩阵。结合精确算法和启发式方法来分解矩阵以发现噪声模式，并引入了一种新的模式简化可视化技术来明确编码噪音水平。", "result": "展示了所提出的技术在多个现实世界数据集上的应用。", "conclusion": "有序矩阵可用于定义并有效检测图中的噪声图形模式，从而支持关系数据分析和可视化。"}}
{"id": "2601.11164", "pdf": "https://arxiv.org/pdf/2601.11164", "abs": "https://arxiv.org/abs/2601.11164", "authors": ["Ruibang Li", "Guan Luo", "Yiwei Zhang", "Jin Gao", "Bing Li", "Weiming Hu"], "title": "SoLA-Vision: Fine-grained Layer-wise Linear Softmax Hybrid Attention", "categories": ["cs.CV"], "comment": "Preprint", "summary": "Standard softmax self-attention excels in vision tasks but incurs quadratic complexity O(N^2), limiting high-resolution deployment. Linear attention reduces the cost to O(N), yet its compressed state representations can impair modeling capacity and accuracy. We present an analytical study that contrasts linear and softmax attention for visual representation learning from a layer-stacking perspective. We further conduct systematic experiments on layer-wise hybridization patterns of linear and softmax attention. Our results show that, compared with rigid intra-block hybrid designs, fine-grained layer-wise hybridization can match or surpass performance while requiring fewer softmax layers. Building on these findings, we propose SoLA-Vision (Softmax-Linear Attention Vision), a flexible layer-wise hybrid attention backbone that enables fine-grained control over how linear and softmax attention are integrated. By strategically inserting a small number of global softmax layers, SoLA-Vision achieves a strong trade-off between accuracy and computational cost. On ImageNet-1K, SoLA-Vision outperforms purely linear and other hybrid attention models. On dense prediction tasks, it consistently surpasses strong baselines by a considerable margin. Code will be released.", "AI": {"tldr": "提出了SoLA-Vision，一种灵活的层次混合注意力机制模型，在保持高精度的同时减少了计算成本。", "motivation": "标准softmax自注意力在视觉任务中表现优秀但存在二次复杂度问题；线性注意力虽然降低了复杂度但可能损害建模能力和准确性。因此研究了层式混合注意力模式以寻找性能与计算成本之间的平衡点。", "method": "通过分析对比线性和softmax注意力，设计了一种细粒度的层次混合注意力模型SoLA-Vision，该模型允许精细控制线性与softmax注意力的集成方式，并在少量关键位置插入全局softmax层以优化性能。", "result": "实验结果表明，在ImageNet-1K数据集上，SoLA-Vision超越了纯线性和其他混合注意力模型；在密集预测任务中，它也显著优于强基线模型。", "conclusion": "研究证实细粒度层次混合注意力设计能够提供更佳的性能与计算成本平衡，并展示了SoLA-Vision的有效性。"}}
{"id": "2601.11161", "pdf": "https://arxiv.org/pdf/2601.11161", "abs": "https://arxiv.org/abs/2601.11161", "authors": ["Pascal Schlachter", "Bin Yang"], "title": "GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Unsupervised domain adaptation tackles the problem that domain shifts between training and test data impair the performance of neural networks in many real-world applications. Thereby, in realistic scenarios, the source data may no longer be available during adaptation, and the label space of the target domain may differ from the source label space. This setting, known as source-free universal domain adaptation (SF-UniDA), has recently gained attention, but all existing approaches only assume a single domain shift from source to target. In this work, we present the first study on continual SF-UniDA, where the model must adapt sequentially to a stream of multiple different unlabeled target domains. Building upon our previous methods for online SF-UniDA, we combine their key ideas by integrating Gaussian mixture model-based pseudo-labeling within a mean teacher framework for improved stability over long adaptation sequences. Additionally, we introduce consistency losses for further robustness. The resulting method GMM-COMET provides a strong first baseline for continual SF-UniDA and is the only approach in our experiments to consistently improve upon the source-only model across all evaluated scenarios. Our code is available at https://github.com/pascalschlachter/GMM-COMET.", "AI": {"tldr": "本文提出了GMM-COMET方法，用于解决连续无源通用领域适应问题，在多个未标记的目标域上进行序列适应。", "motivation": "传统的无监督领域适应假设仅存在单一的从源到目标领域的偏移，并且在实际应用中源数据可能不可用。此研究旨在处理多阶段、持续变化的无源领域适应问题，以提高模型的实际应用性能。", "method": "通过结合高斯混合模型进行伪标签生成和均值教师框架增强稳定性，同时引入一致性损失来提升鲁棒性。这种方法在连续无源通用领域适应中提供了一种强基线方法。", "result": "GMM-COMET在实验中始终能够超越仅使用源数据训练的模型，在所有测试场景下表现优异。", "conclusion": "本文提出的GMM-COMET是首个针对持续无源通用领域适应的研究，为该领域的未来研究提供了重要参考和基线方法。"}}
{"id": "2601.11160", "pdf": "https://arxiv.org/pdf/2601.11160", "abs": "https://arxiv.org/abs/2601.11160", "authors": ["Claudia Plant", "Lena G. M. Bauer", "Christian Böhm"], "title": "Clustering High-dimensional Data: Balancing Abstraction and Representation Tutorial at AAAI 2026", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "How to find a natural grouping of a large real data set? Clustering requires a balance between abstraction and representation. To identify clusters, we need to abstract from superfluous details of individual objects. But we also need a rich representation that emphasizes the key features shared by groups of objects that distinguish them from other groups of objects. Each clustering algorithm implements a different trade-off between abstraction and representation. Classical K-means implements a high level of abstraction - details are simply averaged out - combined with a very simple representation - all clusters are Gaussians in the original data space. We will see how approaches to subspace and deep clustering support high-dimensional and complex data by allowing richer representations. However, with increasing representational expressiveness comes the need to explicitly enforce abstraction in the objective function to ensure that the resulting method performs clustering and not just representation learning. We will see how current deep clustering methods define and enforce abstraction through centroid-based and density-based clustering losses. Balancing the conflicting goals of abstraction and representation is challenging. Ideas from subspace clustering help by learning one latent space for the information that is relevant to clustering and another latent space to capture all other information in the data. The tutorial ends with an outlook on future research in clustering. Future methods will more adaptively balance abstraction and representation to improve performance, energy efficiency and interpretability. By automatically finding the sweet spot between abstraction and representation, the human brain is very good at clustering and other related tasks such as single-shot learning. So, there is still much room for improvement.", "AI": {"tldr": "本文讨论了如何在高维数据聚类中平衡抽象与表示。", "motivation": "探讨在聚类过程中如何找到合适的抽象和表示之间的平衡，以提高算法性能、效率及解释性。", "method": "介绍了从经典K-means到深度聚类方法的不同技术，并阐述了通过子空间学习和密度损失等手段实现抽象与表达的平衡。", "result": "展示了不同的聚类算法如何处理高维复杂数据，并讨论了未来的改进方向。", "conclusion": "未来研究将在自动调整抽象与表示之间的平衡，提高聚类效率、性能及理解性方面进行探索。"}}
{"id": "2601.11151", "pdf": "https://arxiv.org/pdf/2601.11151", "abs": "https://arxiv.org/abs/2601.11151", "authors": ["Ji Dai", "Quan Fang", "Jun Hu", "Desheng Cai", "Yang Yang", "Can Zhao"], "title": "Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted to ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)", "summary": "Multimedia recommendation systems leverage user-item interactions and multimodal information to capture user preferences, enabling more accurate and personalized recommendations. Despite notable advancements, existing approaches still face two critical limitations: first, shallow modality fusion often relies on simple concatenation, failing to exploit rich synergic intra- and inter-modal relationships; second, asymmetric feature treatment-where users are only characterized by interaction IDs while items benefit from rich multimodal content-hinders the learning of a shared semantic space. To address these issues, we propose a Cross-modal Recursive Attention Network with dual graph Embedding (CRANE). To tackle shallow fusion, we design a core Recursive Cross-Modal Attention (RCA) mechanism that iteratively refines modality features based on cross-correlations in a joint latent space, effectively capturing high-order intra- and inter-modal dependencies. For symmetric multimodal learning, we explicitly construct users' multimodal profiles by aggregating features of their interacted items. Furthermore, CRANE integrates a symmetric dual-graph framework-comprising a heterogeneous user-item interaction graph and a homogeneous item-item semantic graph-unified by a self-supervised contrastive learning objective to fuse behavioral and semantic signals. Despite these complex modeling capabilities, CRANE maintains high computational efficiency. Theoretical and empirical analyses confirm its scalability and high practical efficiency, achieving faster convergence on small datasets and superior performance ceilings on large-scale ones. Comprehensive experiments on four public real-world datasets validate an average 5% improvement in key metrics over state-of-the-art baselines.", "AI": {"tldr": "本文提出了一种跨模态注意力网络CRANE，以解决多媒体推荐系统中的浅层模态融合和非对称特征处理问题，通过递归跨模态注意力机制和双图嵌入框架实现更准确的个性化推荐。", "motivation": "现有的多模态推荐方法在浅层次模态融合方面存在不足，仅依赖简单的拼接方式不能充分利用丰富的协同模态关系；同时，在用户和物品特征处理上不平等，导致难以构建共享语义空间。因此，需要一种新的模型来解决这些问题并提高推荐效果。", "method": "提出CRANE模型，通过递归跨模态注意力（RCA）机制迭代细化模态特征以捕获高阶的模内和模间依赖关系，并使用双图嵌入框架统一行为信号和语义信号，从而实现对称多模态学习。", "result": "理论和实验证明了CRANE模型在多个公共真实数据集上的高效性和准确性，在关键指标上平均比现有的最先进方法提升了5%。", "conclusion": "CRANE通过递归跨模态注意力机制和双图嵌入框架，有效解决了浅层融合问题，并实现了对称的多模态学习，显著提高了推荐系统的效果和效率。"}}
{"id": "2601.11147", "pdf": "https://arxiv.org/pdf/2601.11147", "abs": "https://arxiv.org/abs/2601.11147", "authors": ["Zixu Wang", "Bingbing Xu", "Yige Yuan", "Huawei Shen", "Xueqi Cheng"], "title": "Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems", "categories": ["cs.AI"], "comment": "17 pages, 4 figures, 3 tables", "summary": "Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \\textbf{SCALE}, which means \\underline{\\textbf{S}}elf prediction of the optimizer with few shot \\underline{\\textbf{CAL}}ibration for \\underline{\\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \\textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\\%.", "AI": {"tldr": "本文探讨了多智能体系统中任务级工作流与查询级工作流的优劣，并提出了一种名为SCALE的低代价任务级生成框架。", "motivation": "现有的方法在解决复杂任务时，通过协调多个代理来构建工作流。但这些方法的工作流程是按任务级别还是查询级别生成尚不清楚，本文试图澄清这一点并探索更高效的解决方案。", "method": "通过对现有方法的重新思考和实证分析，提出了名为SCALE的框架。该框架利用自我进化和生成奖励模型的思想，在少样本校准下进行自我优化预测以评估替代完全验证执行。", "result": "实验表明，SCALE在多个数据集上的性能仅比现有方法平均下降0.61%，同时减少了高达83%的令牌使用。", "conclusion": "本文得出结论，查询级别的工作流生成并不是必须的，任务级的工作流加上SCALE框架能够实现高效且成本低廉的任务执行。"}}
{"id": "2601.11144", "pdf": "https://arxiv.org/pdf/2601.11144", "abs": "https://arxiv.org/abs/2601.11144", "authors": ["Yuejie Li", "Ke Yang", "Tao Wang", "Bolin Chen", "Bowen Li", "Chengjun Mao"], "title": "Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods are often challenged by navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, frequently lacking robust multi-stage re-ranking. To overcome these deficits, we propose Deep GraphRAG, a framework designed for a balanced approach to hierarchical retrieval and adaptive integration. It introduces a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: (1) inter-community filtering, which prunes the search space using local context; (2) community-level refinement, which prioritizes relevant subgraphs via entity-interaction analysis; and (3) entity-level fine-grained search within target communities. A beam search-optimized dynamic re-ranking module guides this process, continuously filtering candidates to balance efficiency and global comprehensiveness. Deep GraphRAG also features a Knowledge Integration Module leveraging a compact LLM, trained with Dynamic Weighting Reward GRPO (DW-GRPO). This novel reinforcement learning approach dynamically adjusts reward weights to balance three key objectives: relevance, faithfulness, and conciseness. This training enables compact models (1.5B) to approach the performance of large models (70B) in the integration task. Evaluations on Natural Questions and HotpotQA demonstrate that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.", "AI": {"tldr": "提出Deep GraphRAG框架，实现层次检索和自适应集成的平衡。", "motivation": "现有的GraphRAG框架在全局搜索的全面性和局部搜索的效率之间存在权衡，缺乏多阶段重排名机制，难以优化检索路径并平衡探索与利用动态。", "method": "Deep GraphRAG采用从宏观到微观的层次检索策略，包括跨社区过滤、社区级别的精炼和实体级别的细粒度搜索，并结合基于动量权重奖励GRPO的紧凑型LLM知识集成模块。", "result": "评估结果显示，相比于基线图检索方法，Deep GraphRAG在准确性和效率上都有显著提升。", "conclusion": "Deep GraphRAG通过层次化检索策略和动态重排名机制解决了现有GraphRAG框架的问题，并证明了其在实际应用中的优越性能。"}}
{"id": "2601.11143", "pdf": "https://arxiv.org/pdf/2601.11143", "abs": "https://arxiv.org/abs/2601.11143", "authors": ["Minho Lee", "Hyeonseok Kim", "Jin Tak Kim", "Sangshin Park", "Jeong Hyun Lee", "Jungsan Cho", "Jemin Hwangbo"], "title": "Learning Quadrupedal Locomotion for a Heavy Hydraulic Robot Using an Actuator Model", "categories": ["cs.RO", "cs.AI"], "comment": "9 pages, Accepted to IEEE Robotics and Automation Letters (RA-L) 2025", "summary": "The simulation-to-reality (sim-to-real) transfer of large-scale hydraulic robots presents a significant challenge in robotics because of the inherent slow control response and complex fluid dynamics. The complex dynamics result from the multiple interconnected cylinder structure and the difference in fluid rates of the cylinders. These characteristics complicate detailed simulation for all joints, making it unsuitable for reinforcement learning (RL) applications. In this work, we propose an analytical actuator model driven by hydraulic dynamics to represent the complicated actuators. The model predicts joint torques for all 12 actuators in under 1 microsecond, allowing rapid processing in RL environments. We compare our model with neural network-based actuator models and demonstrate the advantages of our model in data-limited scenarios. The locomotion policy trained in RL with our model is deployed on a hydraulic quadruped robot, which is over 300 kg. This work is the first demonstration of a successful transfer of stable and robust command-tracking locomotion with RL on a heavy hydraulic quadruped robot, demonstrating advanced sim-to-real transferability.", "AI": {"tldr": "本文介绍了使用液压动力学驱动的分析执行器模型来实现大型液压机器人四足行走的仿真到现实转移。", "motivation": "解决大型液压机器人的复杂流体动力和慢速控制响应给仿真到现实（sim-to-real）转换带来的挑战，特别是在强化学习应用中。", "method": "提出了一种由液压动力学驱动的分析执行器模型来模拟复杂的执行器，并用这个模型预测12个关节的扭矩以支持强化学习环境中的快速处理。", "result": "在数据有限的情况下展示了该模型的优势，并成功将经过强化学习训练的行走策略转移到超过300公斤的重型液压四足机器人上，实现了稳定的命令跟踪行走。", "conclusion": "本研究首次证明了使用强化学习在重型液压四足机器人上实现稳定和健壮的行走指令追踪的成功转移，展示了先进的仿真到现实转换能力。"}}
{"id": "2601.11141", "pdf": "https://arxiv.org/pdf/2601.11141", "abs": "https://arxiv.org/abs/2601.11141", "authors": ["Tanyu Chen", "Tairan Chen", "Kai Shen", "Zhenghua Bao", "Zhihui Zhang", "Man Yuan", "Yi Shi"], "title": "FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Recent end-to-end spoken dialogue systems leverage speech tokenizers and neural audio codecs to enable LLMs to operate directly on discrete speech representations. However, these models often exhibit limited speaker identity preservation, hindering personalized voice interaction. In this work, we present Chroma 1.0, the first open-source, real-time, end-to-end spoken dialogue model that achieves both low-latency interaction and high-fidelity personalized voice cloning. Chroma achieves sub-second end-to-end latency through an interleaved text-audio token schedule (1:2) that supports streaming generation, while maintaining high-quality personalized voice synthesis across multi-turn conversations. Our experimental results demonstrate that Chroma achieves a 10.96% relative improvement in speaker similarity over the human baseline, with a Real-Time Factor (RTF) of 0.43, while maintaining strong reasoning and dialogue capabilities. Our code and models are publicly available at https://github.com/FlashLabs-AI-Corp/FlashLabs-Chroma and https://huggingface.co/FlashLabs/Chroma-4B .", "AI": {"tldr": "介绍了Chroma 1.0，一个开放源代码的实时端到端口语对话模型，实现了低延迟和个人化声音克隆。", "motivation": "现有的端到端口语对话系统在保持说话人身份方面存在不足，限制了个性化语音交互的应用。因此，开发了一个能实现低延时和高质量个人化语音合成的系统。", "method": "Chroma通过1:2交错文本-音频令牌调度支持流式生成，并维护多轮对话中的高质个性化语音合成。", "result": "实验表明，Chroma在说话人相似度上相比人类基线相对提高了10.96%，实时因子为0.43，同时保持了强大的推理和对话能力。", "conclusion": "Chroma实现了低延迟和个人化声音克隆，在多轮对话中保持高质量的语音合成，代码和模型已开源。"}}
{"id": "2601.11135", "pdf": "https://arxiv.org/pdf/2601.11135", "abs": "https://arxiv.org/abs/2601.11135", "authors": ["Van Thuy Hoang", "O-Joun Lee"], "title": "Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages", "summary": "Molecular property prediction is becoming one of the major applications of graph learning in Web-based services, e.g., online protein structure prediction and drug discovery. A key challenge arises in few-shot scenarios, where only a few labeled molecules are available for predicting unseen properties. Recently, several studies have used in-context learning to capture relationships among molecules and properties, but they face two limitations in: (1) exploiting prior knowledge of functional groups that are causally linked to properties and (2) identifying key substructures directly correlated with properties. We propose CaMol, a context-aware graph causality inference framework, to address these challenges by using a causal inference perspective, assuming that each molecule consists of a latent causal structure that determines a specific property. First, we introduce a context graph that encodes chemical knowledge by linking functional groups, molecules, and properties to guide the discovery of causal substructures. Second, we propose a learnable atom masking strategy to disentangle causal substructures from confounding ones. Third, we introduce a distribution intervener that applies backdoor adjustment by combining causal substructures with chemically grounded confounders, disentangling causal effects from real-world chemical variations. Experiments on diverse molecular datasets showed that CaMol achieved superior accuracy and sample efficiency in few-shot tasks, showing its generalizability to unseen properties. Also, the discovered causal substructures were strongly aligned with chemical knowledge about functional groups, supporting the model interpretability.", "AI": {"tldr": "本文提出了CaMol，一个用于稀疏样本分子属性预测的上下文感知图因果推理框架。", "motivation": "面对仅用少量标记分子进行未见属性预测这一挑战，现有方法在利用功能组与属性之间的因果关系和识别直接相关的子结构上存在局限性。", "method": "CaMol通过引入编码化学知识的上下文图、可学习原子掩码策略以及后门调整分布干预器来解决上述问题，以发现因果子结构并分离出混淆影响。", "result": "实验结果显示，CaMol在不同分子数据集上的稀疏样本任务中达到了更高的准确率和采样效率，并且其预测结果具有良好的解释性，与已知化学知识高度一致。", "conclusion": "该研究证明了通过因果推理来提升分子属性的稀疏样本预测效果是可行的，同时也展示了所发现的因果子结构对模型解释性的支持。"}}
{"id": "2601.11128", "pdf": "https://arxiv.org/pdf/2601.11128", "abs": "https://arxiv.org/abs/2601.11128", "authors": ["Aldo Cerulli", "Lorenzo Cima", "Benedetta Tessa", "Serena Tardelli", "Stefano Cresci"], "title": "The Big Ban Theory: A Pre- and Post-Intervention Dataset of Online Content Moderation Actions", "categories": ["cs.SI", "cs.HC", "cs.IR"], "comment": null, "summary": "Online platforms rely on moderation interventions to curb harmful behavior such hate speech, toxicity, and the spread of mis- and disinformation. Yet research on the effects and possible biases of such interventions faces multiple limitations. For example, existing works frequently focus on single or a few interventions, due to the absence of comprehensive datasets. As a result, researchers must typically collect the necessary data for each new study, which limits opportunities for systematic comparisons. To overcome these challenges, we introduce The Big Ban Theory (TBBT), a large dataset of moderation interventions. TBBT covers 25 interventions of varying type, severity, and scope, comprising in total over 339K users and nearly 39M posted messages. For each intervention, we provide standardized metadata and pseudonymized user activity collected three months before and after its enforcement, enabling consistent and comparable analyses of intervention effects. In addition, we provide a descriptive exploratory analysis of the dataset, along with several use cases of how it can support research on content moderation. With this dataset, we aim to support researchers studying the effects of moderation interventions and to promote more systematic, reproducible, and comparable research. TBBT is publicly available at: https://doi.org/10.5281/zenodo.18245670.", "AI": {"tldr": "本研究介绍了The Big Ban Theory（TBBT）数据集，旨在支持研究人员系统地分析内容审核干预措施的效果。", "motivation": "现有研究通常只关注单一或少数几项干预措施，因为缺乏全面的数据集。这限制了研究者进行系统性比较的机会。为了克服这些挑战并促进可重复和可比的研究，本论文构建了一个大规模的审核干预数据集。", "method": "TBBT涵盖了25种不同类型的干预措施及其影响范围，包括超过339K用户和近3900万发布的消息。对于每项干预措施，提供标准化元数据以及在实施前三个月和后三个月内用户的匿名活动记录。", "result": "该数据集支持研究人员探索性地分析内容审核的效果，并展示了其如何应用于多个研究案例。", "conclusion": "通过提供这个公开的数据集，本论文促进了对内容干预效果的系统、可重复且可比较的研究。"}}
{"id": "2601.11124", "pdf": "https://arxiv.org/pdf/2601.11124", "abs": "https://arxiv.org/abs/2601.11124", "authors": ["Xiaoyu Liang", "Yuchen Peng", "Jiale Luo", "Wenhao Wang", "Haoji Hu", "Xincheng Zhou"], "title": "Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings", "categories": ["cs.IR", "cs.AI"], "comment": "10 pages, 3 figures", "summary": "Large Language Models (LLMs) adapted via contrastive learning excel in general representation learning but struggle in vertical domains like chemistry and law, primarily due to a lack of domain-specific knowledge. This work identifies a core bottleneck: the prevailing ``LLM+CL'' paradigm focuses on semantic alignment but cannot perform knowledge acquisition, leading to failures on specialized terminology. To bridge this gap, we propose Learn Before Represent (LBR), a novel two-stage framework. LBR first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM's causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. This approach maintains architectural consistency and resolves the objective conflict between generative and contrastive learning. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines. Our work establishes a new paradigm for building accurate and robust representations in vertical domains.", "AI": {"tldr": "提出Learn Before Represent（LBR）框架，以解决大型语言模型在特定领域表现不佳的问题。", "motivation": "现有的LLM+CL方法虽然擅长一般性表示学习但在特定领域如化学和法律中效果较差，主要是缺乏专业知识。", "method": "LBR采用两阶段框架：首先通过信息瓶颈约束的生成式学习注入领域知识并压缩语义；然后进行生成优化后的对比学习以实现对齐。", "result": "实验结果显示LBR在医疗、化学及代码检索任务中显著优于强基线模型。", "conclusion": "本研究建立了一种新的范例，用于构建准确和稳健的特定领域表示。"}}
{"id": "2601.11115", "pdf": "https://arxiv.org/pdf/2601.11115", "abs": "https://arxiv.org/abs/2601.11115", "authors": ["Theofanis P. Raptis", "Chiara Boldrini", "Marco Conti", "Andrea Passarella"], "title": "Sparing User Time with a Socially-Aware Independent Metaverse Avatar", "categories": ["cs.SI", "cs.HC"], "comment": "Supported by PNNR projects SoBigDatait (IR0000013), FAIR (PE00000013), ICSC (CN00000013)", "summary": "The Metaverse is redefining digital interactions by merging physical, virtual, and social dimensions, yet its effects on social networking remain largely unexplored. This work examines the role of independent avatars (autonomous digital entities capable of managing social interactions on behalf of users), to optimize social time allocation and reshape Metaverse-based Online Social Networks. We propose a novel computational model that integrates a quantitative and realistic representation of user social life, grounded in evolutionary anthropology, with a framework for avatar-mediated interactions. Our model quantifies the effectiveness of a partial replacement of in-person interactions with independent avatar interactions. Additionally, it accounts for social conflicts and specific socialization constraints. We leverage our model to explore the benefits and trade-offs of an avatar-augmented social life in the Metaverse. Since the exact problem formulation leads to an NP-hard optimization problem when incorporating avatars into the social network, we tackle this challenge by introducing a heuristic solution. Through simulations, we compare avatar-mediated and non-avatar-mediated social networking, demonstrating the potential of independent avatars to enhance social connectivity and efficiency. Our findings provide a foundation for optimizing Metaverse-based social interactions, as well as useful insights for future digital social network design.", "AI": {"tldr": "研究了在元宇宙中使用独立的虚拟化身管理社交互动以优化用户时间分配，并通过模拟验证了其提高社交连接和效率的潜力。", "motivation": "尽管元宇宙正在重新定义数字交互，但关于它对社会网络的影响还未充分探索。本工作旨在探讨独立虚拟化身的作用，以实现更有效的时间利用并重塑基于元宇宙的在线社交网络。", "method": "提出了一种结合进化人类学和代理中介互动框架的计算模型，该模型量化了使用独立虚拟化身代替部分面对面交互的有效性，并通过引入启发式解决方案来解决NP难优化问题。", "result": "模拟结果显示，与非虚拟化中介社交网络相比，基于虚拟化的社交网络可以提升社会连接效率。研究结果为优化元宇宙中的社交互动提供了基础和未来数字社交网络设计的见解。", "conclusion": "本研究表明，独立虚拟化身能够有效管理用户在元宇宙中的社交时间分配，并通过提高社交互动的效率和连通性证明其潜在价值。"}}
{"id": "2601.11109", "pdf": "https://arxiv.org/pdf/2601.11109", "abs": "https://arxiv.org/abs/2601.11109", "authors": ["Shaofeng Yin", "Jiaxin Ge", "Zora Zhiruo Wang", "Xiuyu Li", "Michael J. Black", "Trevor Darrell", "Angjoo Kanazawa", "Haiwen Feng"], "title": "Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": null, "summary": "Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program is a long-standing goal of computer vision. Yet even strong VLMs aren't able to achieve this in one-shot as they lack fine-grained spatial and physical grounding capability. Our key insight is that closing this gap requires interleaved multimodal reasoning through iterative execution and verification. Stemming from this, we present VIGA (Vision-as-Inverse-Graphic Agent) that starts from an empty world and reconstructs or edits scenes through a closed-loop write-run-render-compare-revise procedure. To support long-horizon reasoning, VIGA combines (i) a skill library that alternates generator and verifier roles and (ii) an evolving context memory that contains plans, code diffs, and render history. VIGA is task-agnostic as it doesn't require auxiliary modules, covering a wide range of tasks such as 3D reconstruction, multi-step scene editing, 4D physical interaction, and 2D document editing, etc. Empirically, we found VIGA substantially improves one-shot baselines on BlenderGym (35.32%) and SlideBench (117.17%). Moreover, VIGA is also model-agnostic as it doesn't require finetuning, enabling a unified protocol to evaluate heterogeneous foundation VLMs. To better support this protocol, we introduce BlenderBench, a challenging benchmark that stress-tests interleaved multimodal reasoning with graphics engine, where VIGA improves by 124.70%.", "AI": {"tldr": "本文介绍了VIGA，一种通过迭代执行和验证的交织多模态推理来实现Vision-as-Inverse-Graphic目标的模型。", "motivation": "视觉逆图形概念旨在将图像重建为可编辑的图形程序，但现有强视觉语言模型缺乏精细的空间和物理基础能力。因此，本文提出了一种新的方法来弥补这一差距。", "method": "VIGA通过从空白世界开始并通过写-执行-渲染-比较-修订过程来重构或编辑场景。它结合了一个技能库（交替生成器和验证器角色）和一个包含计划、代码差异和渲染历史的不断演变的内容记忆。", "result": "在BlenderGym上，VIGA比单次基准提高了35.32%，在SlideBench上提高了117.17%。此外，在挑战性基准测试BlenderBench上，VIGA的表现提升了124.70%。", "conclusion": "VIGA无需辅助模块即可覆盖广泛的任务，从3D重建到多步骤场景编辑，证明了其在执行复杂视觉逆图形任务方面的有效性。"}}
{"id": "2601.11108", "pdf": "https://arxiv.org/pdf/2601.11108", "abs": "https://arxiv.org/abs/2601.11108", "authors": ["Matteo Ciferri", "Matteo Ferrante", "Nicola Toschi"], "title": "Simple Models, Rich Representations: Visual Decoding from Primate Intracortical Neural Signals", "categories": ["q-bio.NC", "cs.CV"], "comment": "Presented at \"Foundation Models for the Brain and Body\" - NeurIPS 2025 Workshop", "summary": "Understanding how neural activity gives rise to perception is a central challenge in neuroscience. We address the problem of decoding visual information from high-density intracortical recordings in primates, using the THINGS Ventral Stream Spiking Dataset. We systematically evaluate the effects of model architecture, training objectives, and data scaling on decoding performance. Results show that decoding accuracy is mainly driven by modeling temporal dynamics in neural signals, rather than architectural complexity. A simple model combining temporal attention with a shallow MLP achieves up to 70% top-1 image retrieval accuracy, outperforming linear baselines as well as recurrent and convolutional approaches. Scaling analyses reveal predictable diminishing returns with increasing input dimensionality and dataset size. Building on these findings, we design a modular generative decoding pipeline that combines low-resolution latent reconstruction with semantically conditioned diffusion, generating plausible images from 200 ms of brain activity. This framework provides principles for brain-computer interfaces and semantic neural decoding.", "AI": {"tldr": "本文研究了如何从猕猴的高密度皮层内记录数据中解码视觉信息，并展示了简单的模型结合时间注意力和浅层MLP能够实现较高的图像检索准确率。", "motivation": "理解神经活动如何产生感知是神经科学的核心挑战之一，作者旨在通过研究来解决从高密度皮层内记录数据中解码视觉信息的问题。", "method": "本文系统评估了模型架构、训练目标和数据扩展对解码性能的影响，并提出了一种结合时间注意力与浅层MLP的简单模型。此外，还设计了一个模块化生成解码管道，利用低分辨率潜在重建与语义条件扩散从200毫秒的大脑活动生成图像。", "result": "结果表明，通过建模神经信号的时间动态性可以显著提升解码准确率，提出的模型达到了70%的top-1图像检索准确率，并且在扩展分析中观察到了可预测的递减收益。", "conclusion": "本研究展示了简单模型结合时间注意力机制能够有效提高视觉信息解码的准确性，为脑机接口和语义神经解码提供了理论基础。"}}
{"id": "2601.11103", "pdf": "https://arxiv.org/pdf/2601.11103", "abs": "https://arxiv.org/abs/2601.11103", "authors": ["Minju Park", "Seunghyun Lee", "Juhwan Ma", "Dongwook Yoon"], "title": "AI Twin: Enhancing ESL Speaking Practice through AI Self-Clones of a Better Me", "categories": ["cs.HC"], "comment": "CHI 2026", "summary": "Advances in AI have enabled ESL learners to practice speaking through conversational systems. However, most tools rely on explicit correction, which can interrupt the conversation and undermine confidence. Grounded in second language acquisition and motivational psychology, we present AI Twin, a system that rephrases learner utterances into more fluent English and delivers them in the learner's voice. Embodying a more confident and proficient version of the learner, AI Twin reinforces motivation through alignment with their aspirational Ideal L2 Self. Also, its use of implicit feedback through rephrasing preserves conversational flow and fosters an emotionally supportive environment. In a within-subject study with 20 adult ESL learners, we compared AI Twin with explicit correction and a non-personalized rephrasing agent. Results show that AI Twin elicited higher emotional engagement, with participants describing the experience as more motivating. These findings highlight the potential of self-representative AI for personalized, psychologically grounded support in ESL learning.", "AI": {"tldr": "介绍AI Twin系统，该系统通过重新表述学习者的陈述并用他们的声音传达来提升英语作为第二语言的学习者口语练习。", "motivation": "传统的ESL工具依赖显式纠正，这可能会中断对话并削弱信心。因此，研究旨在开发一个能增强动机、保留会话流畅性的系统。", "method": "AI Twin系统将学习者的陈述重新表述为更流利的英语，并以他们的声音传达出来，从而体现了一个更自信和熟练的学习者版本。通过与显式纠正和非个性化重述代理的对比实验验证其效果。", "result": "在20名成人ESL学习者的单因素研究中，AI Twin系统激发了更高的情感参与度，参与者认为该体验更具动力性。", "conclusion": "这些发现强调了自代表人工智能在个性化、心理基础支持中的潜力，尤其是在ESL学习领域。"}}
{"id": "2601.11102", "pdf": "https://arxiv.org/pdf/2601.11102", "abs": "https://arxiv.org/abs/2601.11102", "authors": ["Shangbo Yuan", "Jie Xu", "Ping Hu", "Xiaofeng Zhu", "Na Zhao"], "title": "Graph Smoothing for Enhanced Local Geometry Learning in Point Cloud Analysis", "categories": ["cs.CV"], "comment": "Accepted by AAAI 2026", "summary": "Graph-based methods have proven to be effective in capturing relationships among points for 3D point cloud analysis. However, these methods often suffer from suboptimal graph structures, particularly due to sparse connections at boundary points and noisy connections in junction areas. To address these challenges, we propose a novel method that integrates a graph smoothing module with an enhanced local geometry learning module. Specifically, we identify the limitations of conventional graph structures, particularly in handling boundary points and junction areas. In response, we introduce a graph smoothing module designed to optimize the graph structure and minimize the negative impact of unreliable sparse and noisy connections. Based on the optimized graph structure, we improve the feature extract function with local geometry information. These include shape features derived from adaptive geometric descriptors based on eigenvectors and distribution features obtained through cylindrical coordinate transformation. Experimental results on real-world datasets validate the effectiveness of our method in various point cloud learning tasks, i.e., classification, part segmentation, and semantic segmentation.", "AI": {"tldr": "该论文提出了一个结合图平滑模块和增强局部几何学习模块的方法，以优化点云分析中的图结构并提高性能。", "motivation": "传统的基于图形的方法在处理边界点和连接区域时存在局限性，导致子优化的图形结构问题。为了克服这些问题，改进了点云的特征提取功能。", "method": "通过引入一个图平滑模块来优化图结构，并最小化稀疏和噪声连接的影响。此外，还使用自适应几何描述符和圆柱坐标变换改善局部几何信息。", "result": "实验结果在真实世界的数据集上验证了该方法的有效性，特别是在分类、部分分割和语义分割等任务中。", "conclusion": "提出的方法通过优化图结构并增强局部几何学习，提高了点云分析中的性能表现。"}}
{"id": "2601.11100", "pdf": "https://arxiv.org/pdf/2601.11100", "abs": "https://arxiv.org/abs/2601.11100", "authors": ["Zhezheng Hao", "Hong Wang", "Jian Luo", "Jianqing Zhang", "Yuyan Zhou", "Qiang Lin", "Can Wang", "Hande Dong", "Jiawei Chen"], "title": "ReCreate: Reasoning and Creating Domain Agents Driven by Experience", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.", "AI": {"tldr": "本文提出了ReCreate框架，旨在通过自动化的经验驱动方式创建和适应领域代理。", "motivation": "尽管大型语言模型正在重塑工业格局，但大多数实际应用的代理仍然是由人工设计的，因为任务差异广泛使得构建过程劳动密集且成本高昂。现有自动化方法主要依赖最终性能指标进行评估，忽视了成功或失败背后的原因，并且通常需要高计算成本。", "method": "ReCreate通过三个关键组件实现其功能：(i) 一种经验存储和检索机制；(ii) 将执行经验映射到框架编辑的推理-创建协同管道；(iii) 层次化更新，将实例细节抽象为可复用的领域模式。", "result": "在不同领域的实验中，ReCreate从最小的种子结构开始，持续超越人工设计的代理和其他现有的自动化生成方法。", "conclusion": "研究表明通过系统地利用代理交互历史，可以更有效地自动创建和适应领域代理，并且能够提供丰富的信号来解释成功或失败的原因以及改进的方向。"}}
{"id": "2601.11096", "pdf": "https://arxiv.org/pdf/2601.11096", "abs": "https://arxiv.org/abs/2601.11096", "authors": ["Shuai Tan", "Biao Gong", "Ke Ma", "Yutong Feng", "Qiyuan Zhang", "Yan Wang", "Yujun Shen", "Hengshuang Zhao"], "title": "CoDance: An Unbind-Rebind Paradigm for Robust Multi-Subject Animation", "categories": ["cs.CV"], "comment": "https://lucaria-academy.github.io/CoDance/", "summary": "Character image animation is gaining significant importance across various domains, driven by the demand for robust and flexible multi-subject rendering. While existing methods excel in single-person animation, they struggle to handle arbitrary subject counts, diverse character types, and spatial misalignment between the reference image and the driving poses. We attribute these limitations to an overly rigid spatial binding that forces strict pixel-wise alignment between the pose and reference, and an inability to consistently rebind motion to intended subjects. To address these challenges, we propose CoDance, a novel Unbind-Rebind framework that enables the animation of arbitrary subject counts, types, and spatial configurations conditioned on a single, potentially misaligned pose sequence. Specifically, the Unbind module employs a novel pose shift encoder to break the rigid spatial binding between the pose and the reference by introducing stochastic perturbations to both poses and their latent features, thereby compelling the model to learn a location-agnostic motion representation. To ensure precise control and subject association, we then devise a Rebind module, leveraging semantic guidance from text prompts and spatial guidance from subject masks to direct the learned motion to intended characters. Furthermore, to facilitate comprehensive evaluation, we introduce a new multi-subject CoDanceBench. Extensive experiments on CoDanceBench and existing datasets show that CoDance achieves SOTA performance, exhibiting remarkable generalization across diverse subjects and spatial layouts. The code and weights will be open-sourced.", "AI": {"tldr": "本文提出了CoDance，一种用于处理任意数量、类型和空间配置角色的动画生成框架。", "motivation": "现有的单人动画方法在面对多主体、多样化的角色类型以及参考图像与驱动姿势之间的空间错位问题时表现不佳。为了解决这些问题，作者提出了一种新的Unbind-Rebind范式。", "method": "CoDance框架包括一个解绑模块和一个重新绑定模块。解绑模块使用姿态偏移编码器来引入随机扰动以打破刚性的空间绑定；重新绑定模块则利用语义文本提示和主体掩码的空间指导将学习到的运动应用到指定的角色上。", "result": "实验显示，CoDance在作者新开发的多主体基准测试集以及现有数据集上实现了最先进的性能，并展示了其在多样化角色和空间布局中的优秀泛化能力。", "conclusion": "本文提出的CoDance框架可以有效处理任意数量、类型及空间配置的角色动画生成问题，达到了领先的性能水平。"}}
{"id": "2601.11090", "pdf": "https://arxiv.org/pdf/2601.11090", "abs": "https://arxiv.org/abs/2601.11090", "authors": ["Davor Lauc"], "title": "Efficient Multilingual Name Type Classification Using Convolutional Networks", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Preprint of paper presented at ISAI-NLP Phukat 2025", "summary": "We present a convolutional neural network approach for classifying proper names by language and entity type. Our model, Onomas-CNN X, combines parallel convolution branches with depthwise-separable operations and hierarchical classification to process names efficiently on CPU hardware. We evaluate the architecture on a large multilingual dataset covering 104 languages and four entity types (person, organization, location, other). Onomas-CNN X achieves 92.1% accuracy while processing 2,813 names per second on a single CPU core - 46 times faster than fine-tuned XLM-RoBERTa with comparable accuracy. The model reduces energy consumption by a factor of 46 compared to transformer baselines. Our experiments demonstrate that specialized CNN architectures remain competitive with large pre-trained models for focused NLP tasks when sufficient training data exists.", "AI": {"tldr": "本文介绍了一种使用卷积神经网络对专有名词按语言和实体类型进行分类的方法。", "motivation": "动机是开发一种高效且能在CPU上快速处理多语言名称分类的模型，以降低计算成本并提高速度。", "method": "方法为设计了一个名为Onomas-CNN X的卷积神经网络模型，该模型结合了平行卷积分支、深度可分离操作和层次化分类技术。", "result": "结果表明，Onomas-CNN X在处理104种语言及四类实体名称时达到了92.1%的准确率，并且每秒可以处理2,813个名称，比XLM-RoBERTa快46倍，同时减少了46倍的能量消耗。", "conclusion": "结论是针对特定NLP任务，当有足够的训练数据时，专门设计的CNN架构仍然能够与大型预训练模型竞争。"}}
{"id": "2601.11089", "pdf": "https://arxiv.org/pdf/2601.11089", "abs": "https://arxiv.org/abs/2601.11089", "authors": ["Suhan Guo", "Jiahong Deng", "Furao Shen"], "title": "MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting", "categories": ["cs.AI"], "comment": null, "summary": "Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility plays a central role in shaping the spatial spread of epidemics, but mobility data are noisy, indirect, and difficult to integrate reliably with disease records. Meanwhile, epidemic case time series are typically short and reported at coarse temporal resolution. These conditions limit the effectiveness of parameter-heavy mobility-aware forecasters that rely on clean and abundant data. In this work, we propose the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to selectively exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components such as graph neural networks or full attention. Extensive experiments on four real-world epidemic datasets, including COVID-19 incidence, COVID-19 mortality, influenza, and dengue, show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5\\% across forecasting horizons. Moreover, MiCA attains performance competitive with SOTA spatio-temporal models while remaining lightweight.", "AI": {"tldr": "本文提出了一种轻量级的Mobility-Informed Causal Adapter (MiCA)，用于改善流行病预测。", "motivation": "准确预测传染病动态对于公共卫生规划和干预至关重要，但人类移动性数据存在噪声大、间接且难以可靠整合的问题。同时，疫情案例时间序列通常较短且以粗分辨率报告，限制了依赖干净丰富数据的参数密集型移动感知预报器的效果。", "method": "MiCA通过因果发现推断出移动关系，并将其集成到时间预测模型中，采用门控残差混合方法实现轻量级预报器在不引入重型关系组件的情况下利用基于移动性的空间结构。", "result": "实验显示，MiCA在四个真实世界流行病数据集上提高了轻量级时间后端的预测性能，平均相对误差减少7.5%，同时保持了轻量性且实现了与最先进的时空模型相竞争的表现。", "conclusion": "研究表明，基于因果关系发现和轻量化设计的MiCA能够在噪声大和数据受限条件下改善流行病预测，达到更好的精度和效率。"}}
{"id": "2601.11087", "pdf": "https://arxiv.org/pdf/2601.11087", "abs": "https://arxiv.org/abs/2601.11087", "authors": ["Qiyuan Zhang", "Biao Gong", "Shuai Tan", "Zheng Zhang", "Yujun Shen", "Xing Zhu", "Yuyuan Li", "Kelu Yao", "Chunhua Shen", "Changqing Zou"], "title": "PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models", "categories": ["cs.CV"], "comment": null, "summary": "Physical principles are fundamental to realistic visual simulation, but remain a significant oversight in transformer-based video generation. This gap highlights a critical limitation in rendering rigid body motion, a core tenet of classical mechanics. While computer graphics and physics-based simulators can easily model such collisions using Newton formulas, modern pretrain-finetune paradigms discard the concept of object rigidity during pixel-level global denoising. Even perfectly correct mathematical constraints are treated as suboptimal solutions (i.e., conditions) during model optimization in post-training, fundamentally limiting the physical realism of generated videos. Motivated by these considerations, we introduce, for the first time, a physics-aware reinforcement learning paradigm for video generation models that enforces physical collision rules directly in high-dimensional spaces, ensuring the physics knowledge is strictly applied rather than treated as conditions. Subsequently, we extend this paradigm to a unified framework, termed Mimicry-Discovery Cycle (MDcycle), which allows substantial fine-tuning while fully preserving the model's ability to leverage physics-grounded feedback. To validate our approach, we construct new benchmark PhysRVGBench and perform extensive qualitative and quantitative experiments to thoroughly assess its effectiveness.", "AI": {"tldr": "介绍了一种物理感知的统一强化学习框架（PhysRVG），用于视频生成模型，以确保在高维空间中直接应用物理碰撞规则。", "motivation": "现有的基于转换器的视频生成方法忽视了物理原则，在渲染刚体运动时存在显著限制。通过引入一种新的方法来解决这些问题，并提高视频生成中的物理真实性。", "method": "提出了一种新型的物理感知强化学习范式，直接在高维空间中强制执行物理碰撞规则，并扩展为一个统一框架（MDcycle），允许大规模微调同时保留模型利用基于物理学反馈的能力。", "result": "构建了一个新的基准测试PhysRVGBench，进行了广泛的定性和定量实验来全面评估其有效性。", "conclusion": "研究证明了这种方法在视频生成中实现了更高的物理真实性，并且通过详细的实验验证了该方法的有效性。"}}
{"id": "2601.11085", "pdf": "https://arxiv.org/pdf/2601.11085", "abs": "https://arxiv.org/abs/2601.11085", "authors": ["Kaito Urata", "Maiko Nagao", "Atsushi Teramoto", "Kazuyoshi Imaizumi", "Masashi Kondo", "Hiroshi Fujita"], "title": "Generation of Chest CT pulmonary Nodule Images by Latent Diffusion Models using the LIDC-IDRI Dataset", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": null, "summary": "Recently, computer-aided diagnosis systems have been developed to support diagnosis, but their performance depends heavily on the quality and quantity of training data. However, in clinical practice, it is difficult to collect the large amount of CT images for specific cases, such as small cell carcinoma with low epidemiological incidence or benign tumors that are difficult to distinguish from malignant ones. This leads to the challenge of data imbalance. In this study, to address this issue, we proposed a method to automatically generate chest CT nodule images that capture target features using latent diffusion models (LDM) and verified its effectiveness. Using the LIDC-IDRI dataset, we created pairs of nodule images and finding-based text prompts based on physician evaluations. For the image generation models, we used Stable Diffusion version 1.5 (SDv1) and 2.0 (SDv2), which are types of LDM. Each model was fine-tuned using the created dataset. During the generation process, we adjusted the guidance scale (GS), which indicates the fidelity to the input text. Both quantitative and subjective evaluations showed that SDv2 (GS = 5) achieved the best performance in terms of image quality, diversity, and text consistency. In the subjective evaluation, no statistically significant differences were observed between the generated images and real images, confirming that the quality was equivalent to real clinical images. We proposed a method for generating chest CT nodule images based on input text using LDM. Evaluation results demonstrated that the proposed method could generate high-quality images that successfully capture specific medical features.", "AI": {"tldr": "使用潜在扩散模型生成胸部CT肺结节图像以解决数据不平衡问题。", "motivation": "计算机辅助诊断系统的性能依赖于高质量和大量训练数据，但在临床实践中难以收集特定病例的大量CT影像。为了解决这一问题，本文提出了一个基于潜在扩散模型自动生成具有目标特征的胸部CT结节图像的方法。", "method": "使用LIDC-IDRI数据集创建了肺结节图像与医生评估为基础的文字提示对，并通过微调Stable Diffusion版本1.5和2.0（SDv1和SDv2）模型来生成高质量的图像。调整指导尺度以提高输入文本的一致性。", "result": "定量和主观评价表明，使用指导尺度为5的SDv2达到了最佳性能，在图像质量、多样性和文字一致性方面表现优秀。主观评估结果确认了生成影像的质量与真实的临床影像相当。", "conclusion": "本文提出的方法能够基于输入文本生成高质量且具有特定医疗特征的胸部CT结节图像，成功解决了数据不平衡的问题，并验证了其有效性和可行性。"}}
{"id": "2601.11078", "pdf": "https://arxiv.org/pdf/2601.11078", "abs": "https://arxiv.org/abs/2601.11078", "authors": ["Jiaohong Yao", "Linfeng Liang", "Yao Deng", "Xi Zheng", "Richard Han", "Yuankai Qi"], "title": "Visual Marker Search for Autonomous Drone Landing in Diverse Urban Environments", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Marker-based landing is widely used in drone delivery and return-to-base systems for its simplicity and reliability. However, most approaches assume idealized landing site visibility and sensor performance, limiting robustness in complex urban settings. We present a simulation-based evaluation suite on the AirSim platform with systematically varied urban layouts, lighting, and weather to replicate realistic operational diversity. Using onboard camera sensors (RGB for marker detection and depth for obstacle avoidance), we benchmark two heuristic coverage patterns and a reinforcement learning-based agent, analyzing how exploration strategy and scene complexity affect success rate, path efficiency, and robustness. Results underscore the need to evaluate marker-based autonomous landing under diverse, sensor-relevant conditions to guide the development of reliable aerial navigation systems.", "AI": {"tldr": "评估无人机在复杂城市环境中基于视觉标记的自主着陆系统的性能。", "motivation": "现有无人机着陆系统假设理想的着陆点可见性和传感器性能，缺乏在真实复杂环境中的鲁棒性。", "method": "使用AirSim平台模拟不同城市布局、照明和天气条件，通过RGB摄像头进行标记检测和深度感知以避开障碍物，评估两种启发式覆盖模式和一个基于强化学习的代理的表现。", "result": "结果显示探索策略和场景复杂度对成功着陆率、路径效率及鲁棒性有显著影响。", "conclusion": "研究强调了在多样化的传感器相关条件下评估基于标记的自主着陆系统的重要性，以指导可靠空载导航系统的开发。"}}
{"id": "2601.11077", "pdf": "https://arxiv.org/pdf/2601.11077", "abs": "https://arxiv.org/abs/2601.11077", "authors": ["Jie Yang", "Honglin Guo", "Li Ji", "Jiazheng Zhou", "Rui Zheng", "Zhikai Lei", "Shuo Zhang", "Zhiheng Xi", "Shichun Liu", "Yuxin Wang", "Bo Wang", "Yining Zheng", "Tao Gui", "Xipeng Qiu"], "title": "ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench require the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering. Our code is available at https://github.com/OpenMOSS/ABC-Bench.", "AI": {"tldr": "介绍了一个名为ABC-Bench的基准测试，用于评估自主代理在真实世界后端开发中的表现。", "motivation": "现有的代码生成基准大多局限于静态环境下的逻辑评估，忽略了现实工程中动态、全生命周期的需求，特别是后端开发所需的复杂环境配置和服务部署。", "method": "设计了ABC-Bench基准测试，涵盖224个实际任务，涉及8种编程语言和19个框架，使用自动化流程从代码仓库探索到服务容器化实例化，并进行端到端API测试。", "result": "评估结果显示当前最先进的模型在这些全面的任务上难以提供可靠的表现，表明现有模型能力与实用后端工程需求之间存在显著差距。", "conclusion": "ABC-Bench揭示了现有自主代理在复杂真实世界开发任务中的局限性，为改进AI代码生成和自动化开发流程提供了新的方向。"}}
{"id": "2601.11076", "pdf": "https://arxiv.org/pdf/2601.11076", "abs": "https://arxiv.org/abs/2601.11076", "authors": ["Jiaqi Liang", "Yue Chen", "Qize Yu", "Yan Shen", "Haipeng Zhang", "Hao Dong", "Ruihai Wu"], "title": "A3D: Adaptive Affordance Assembly with Dual-Arm Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "AAAI2026 oral", "summary": "Furniture assembly is a crucial yet challenging task for robots, requiring precise dual-arm coordination where one arm manipulates parts while the other provides collaborative support and stabilization. To accomplish this task more effectively, robots need to actively adapt support strategies throughout the long-horizon assembly process, while also generalizing across diverse part geometries. We propose A3D, a framework which learns adaptive affordances to identify optimal support and stabilization locations on furniture parts. The method employs dense point-level geometric representations to model part interaction patterns, enabling generalization across varied geometries. To handle evolving assembly states, we introduce an adaptive module that uses interaction feedback to dynamically adjust support strategies during assembly based on previous interactions. We establish a simulation environment featuring 50 diverse parts across 8 furniture types, designed for dual-arm collaboration evaluation. Experiments demonstrate that our framework generalizes effectively to diverse part geometries and furniture categories in both simulation and real-world settings.", "AI": {"tldr": "本文介绍了A3D框架，该框架通过学习自适应的支撑策略以优化家具组装过程中双臂机器人的协作。", "motivation": "机器人在进行家具组装时需要精确的双臂协调操作，此任务复杂且具有挑战性，因此需要一个可以自适应地为不同几何形状零件提供支持和稳定性的系统。", "method": "A3D框架采用密集点级别的几何表示来建模部件交互模式，并通过反馈动态调整支撑策略以应对装配过程中不断变化的状态。", "result": "在包含8类家具共50种不同零件的模拟环境中，实验结果表明该框架能有效泛化到不同的零件几何形状和家具类别，在实际应用中同样表现出色。", "conclusion": "A3D框架通过自适应支撑策略提升了双臂机器人在复杂装配任务中的性能，并验证了其在多种几何形状上的通用性。"}}
{"id": "2601.11075", "pdf": "https://arxiv.org/pdf/2601.11075", "abs": "https://arxiv.org/abs/2601.11075", "authors": ["Maiko Nagao", "Kaito Urata", "Atsushi Teramoto", "Kazuyoshi Imaizumi", "Masashi Kondo", "Hiroshi Fujita"], "title": "Visual question answering-based image-finding generation for pulmonary nodules on chest CT from structured annotations", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": null, "summary": "Interpretation of imaging findings based on morphological characteristics is important for diagnosing pulmonary nodules on chest computed tomography (CT) images. In this study, we constructed a visual question answering (VQA) dataset from structured data in an open dataset and investigated an image-finding generation method for chest CT images, with the aim of enabling interactive diagnostic support that presents findings based on questions that reflect physicians' interests rather than fixed descriptions. In this study, chest CT images included in the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) datasets were used. Regions of interest surrounding the pulmonary nodules were extracted from these images, and image findings and questions were defined based on morphological characteristics recorded in the database. A dataset comprising pairs of cropped images, corresponding questions, and image findings was constructed, and the VQA model was fine-tuned on it. Language evaluation metrics such as BLEU were used to evaluate the generated image findings. The VQA dataset constructed using the proposed method contained image findings with natural expressions as radiological descriptions. In addition, the generated image findings showed a high CIDEr score of 3.896, and a high agreement with the reference findings was obtained through evaluation based on morphological characteristics. We constructed a VQA dataset for chest CT images using structured information on the morphological characteristics from the LIDC-IDRI dataset. Methods for generating image findings in response to these questions have also been investigated. Based on the generated results and evaluation metric scores, the proposed method was effective as an interactive diagnostic support system that can present image findings according to physicians' interests.", "AI": {"tldr": "本文构建了一个基于视觉问答（VQA）的数据集，用于从结构化注释中生成胸部CT肺结节的图像发现。", "motivation": "目的是实现一个交互式诊断支持系统，该系统能够根据医生的兴趣提出问题来展示发现，而不是固定的描述。", "method": "使用LIDC-IDRI数据集中包含的胸部CT图像，提取感兴趣的区域并基于数据库中的形态特征定义图像发现和问题。构建了一个由裁剪后的图像、对应的问题和图像发现组成的VQA数据集，并在此基础上微调了VQA模型。", "result": "生成的图像发现具有自然表达的放射学描述，CIDEr得分为3.896，且通过基于形态特征的评估获得了与参考发现的高度一致。", "conclusion": "该方法有效作为交互式诊断支持系统，可以按照医生的兴趣展示图像发现。"}}
{"id": "2601.11073", "pdf": "https://arxiv.org/pdf/2601.11073", "abs": "https://arxiv.org/abs/2601.11073", "authors": ["Rongkun Cui", "Nana Zhang", "Kun Zhu", "Qi Zhang"], "title": "Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web Finance Fraud", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Online financial services constitute an essential component of contemporary web ecosystems, yet their openness introduces substantial exposure to fraud that harms vulnerable users and weakens trust in digital finance. Such threats have become a significant web harm that erodes societal fairness and affects the well being of online communities. However, existing detection methods based on graph neural networks (GNNs) struggle with two persistent challenges: (1) fraud camouflage, where malicious transactions mimic benign behaviors to evade detection, and (2) long-tailed data distributions, which obscure rare but critical fraudulent cases. To fill these gaps, we propose HIMVH, a Hippocampus-Inspired Multi-View Hypergraph learning model for web finance fraud detection. Specifically, drawing inspiration from the scene conflict monitoring role of the hippocampus, we design a cross-view inconsistency perception module that captures subtle discrepancies and behavioral heterogeneity across multiple transaction views. This module enables the model to identify subtle cross-view conflicts for detecting online camouflaged fraudulent behaviors. Furthermore, inspired by the match-mismatch novelty detection mechanism of the CA1 region, we introduce a novelty-aware hypergraph learning module that measures feature deviations from neighborhood expectations and adaptively reweights messages, thereby enhancing sensitivity to online rare fraud patterns in the long-tailed settings. Extensive experiments on six web-based financial fraud datasets demonstrate that HIMVH achieves 6.42\\% improvement in AUC, 9.74\\% in F1 and 39.14\\% in AP on average over 15 SOTA models.", "AI": {"tldr": "本文提出了一种基于海马体启发的多视角超图学习模型HIMVH，用于检测在线金融服务中的伪装欺诈行为和长尾分布下的罕见欺诈案例。", "motivation": "现有基于图形神经网络（GNN）的方法在识别欺诈行为时遇到两个挑战：欺诈伪装和长尾数据分布问题。这些问题导致难以捕捉细微的欺诈迹象和稀有的欺诈模式，从而影响在线金融服务的安全性和用户信任。", "method": "HIMVH模型通过借鉴海马体跨视图不一致感知机制，设计了一个多视角超图学习模块来检测欺诈行为；同时引入新颖性意识的超图学习模块以提高对长尾环境下罕见欺诈模式的敏感度。", "result": "实验结果表明，HIMVH在六个在线金融欺诈数据集上的AUC、F1和AP平均提升了6.42%、9.74%和39.14%，相较于15种最先进的模型有显著提升。", "conclusion": "该研究展示了HIMVH在检测复杂且隐蔽的网络金融服务欺诈行为方面的有效性，证明了跨学科方法在解决现实世界问题中的潜力。"}}
{"id": "2601.11072", "pdf": "https://arxiv.org/pdf/2601.11072", "abs": "https://arxiv.org/abs/2601.11072", "authors": ["Amber Kusters", "Pooja Prajod", "Pablo Cesar", "Abdallah El Ali"], "title": "More Human or More AI? Visualizing Human-AI Collaboration Disclosures in Journalistic News Production", "categories": ["cs.HC"], "comment": "Accepted to ACM CHI 2026 - Preprint", "summary": "Within journalistic editorial processes, disclosing AI usage is currently limited to simplistic labels, which misses the nuance of how humans and AI collaborated on a news article. Through co-design sessions (N=10), we elicited 69 disclosure designs and implemented four prototypes that visually disclose human-AI collaboration in journalism. We then ran a within-subjects lab study (N=32) to examine how disclosure visualizations (Textual, Role-based Timeline, Task-based Timeline, Chatbot) and collaboration ratios (Primarily Human vs. Primarily AI) influenced visualization perceptions, gaze patterns, and post-experience responses. We found that textual disclosures were least effective in communicating human-AI collaboration, whereas Chatbot offered the most in-depth information. Furthermore, while role-based timelines amplified AI contribution in primarily human articles, task-based timeline shifted perceptions toward human involvement in primarily AI articles. We contribute Human-AI collaboration disclosure visualizations and their evaluation, and cautionary considerations on how visualizations can alter perceptions of AI's actual role during news article creation.", "AI": {"tldr": "本文探讨了在新闻生产过程中如何通过可视化设计来清晰地披露人类与AI的合作情况。", "motivation": "当前新闻编辑过程中的AI使用信息披露过于简单，未能反映人类和AI合作的复杂性，因此本研究旨在开发更有效的可视化方式来展示这种合作。", "method": "研究人员进行了共10次的设计工作坊，收集了69个设计，并实施了四种原型（文本型、基于角色的时间线、基于任务的时间线、聊天机器人）。通过一个包含32名参与者的实验测试了这些视觉披露对参与者感知、视线模式和体验后反应的影响。", "result": "研究结果表明，文本披露最不有效，而聊天机器人提供了最多的信息细节。同时，基于角色的时间线在人类为主要贡献的文章中放大了AI的贡献，而基于任务的时间线则在AI为主要贡献的文章中更强调了人的作用。", "conclusion": "本研究为新闻业提供了一种评估和展示人类与AI合作情况的新方法，并提醒人们注意可视化可能对感知AI实际角色产生的影响。"}}
{"id": "2601.11065", "pdf": "https://arxiv.org/pdf/2601.11065", "abs": "https://arxiv.org/abs/2601.11065", "authors": ["Rachmadita Andreswari", "Stephan A. Fahrenkrog-Petersen", "Jan Mendling"], "title": "Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage", "categories": ["cs.CY", "cs.AI"], "comment": "conference", "summary": "Fairness in automated decision-making has become a critical concern, particularly in high-pressure healthcare scenarios such as emergency triage, where fast and equitable decisions are essential. Process mining is increasingly investigating fairness. There is a growing area focusing on fairness-aware algorithms. So far, we know less how these concepts perform on empirical healthcare data or how they cover aspects of justice theory. This study addresses this research problem and proposes a process mining approach to assess fairness in triage by linking real-life event logs with conceptual dimensions of justice. Using the MIMICEL event log (as derived from MIMIC-IV ED), we analyze time, re-do, deviation and decision as process outcomes, and evaluate the influence of age, gender, race, language and insurance using the Kruskal-Wallis, Chi-square and effect size measurements. These outcomes are mapped to justice dimensions to support the development of a conceptual framework. The results demonstrate which aspects of potential unfairness in high-acuity and sub-acute surface. In this way, this study contributes empirical insights that support further research in responsible, fairness-aware process mining in healthcare.", "AI": {"tldr": "本文通过过程挖掘方法评估医疗急救中的公平性问题，使用MIMICEL事件日志分析了决策过程中潜在的不公平因素。", "motivation": "在医疗领域特别是急诊中，快速和公平的决策至关重要。研究动机在于探索如何利用公平感知算法评估实际医疗服务数据中的公平性，并理解这些概念如何覆盖正义理论的各个方面。", "method": "本文采用了过程挖掘方法，使用来自MIMIC-IV ED的MIMICEL事件日志分析时间、重做、偏差和决策等结果，并通过Kruskal-Wallis、卡方检验以及效应量测量来评估年龄、性别、种族、语言和保险等因素的影响。", "result": "研究结果显示了在高急性度和亚急性的医疗过程中的潜在不公平方面。这些结果支持了一个概念框架的发展，用于进一步研究负责任的公平感知过程挖掘。", "conclusion": "这项研究为负责人的、公平感知的过程挖掘在医疗领域的进一步研究提供了实证见解，并指出了未来工作需要解决的问题和方向。"}}
{"id": "2601.11063", "pdf": "https://arxiv.org/pdf/2601.11063", "abs": "https://arxiv.org/abs/2601.11063", "authors": ["Haishan Zeng", "Peng Li"], "title": "H-AIM: Orchestrating LLMs, PDDL, and Behavior Trees for Hierarchical Multi-Robot Planning", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.MA"], "comment": null, "summary": "In embodied artificial intelligence, enabling heterogeneous robot teams to execute long-horizon tasks from high-level instructions remains a critical challenge. While large language models (LLMs) show promise in instruction parsing and preliminary planning, they exhibit limitations in long-term reasoning and dynamic multi-robot coordination. We propose Hierarchical Autonomous Intelligent Multi-Robot Planning(H-AIM), a novel embodied multi-robot task planning framework that addresses these issues through a three-stage cascaded architecture: 1) It leverages an LLM to parse instructions and generate Planning Domain Definition Language (PDDL) problem descriptions, thereby transforming commands into formal planning problems; 2) It combines the semantic reasoning of LLMs with the search capabilities of a classical planner to produce optimized action sequences; 3) It compiles the resulting plan into behavior trees for reactive control. The framework supports dynamically sized heterogeneous robot teams via a shared blackboard mechanism for communication and state synchronization. To validate our approach, we introduce the MACE-THOR benchmark dataset, comprising 42 complex tasks across 8 distinct household layouts. Experimental results demonstrate that H-AIM achieves a remarkable performance improvement, elevating the task success rate from 12% to 55% and boosting the goal condition recall from 32% to 72% against the strongest baseline, LaMMA-P.", "AI": {"tldr": "本文提出了一种名为H-AIM的新型嵌入式多机器人任务规划框架，旨在解决异构机器人团队从高级指令执行长期任务的挑战。", "motivation": "虽然大型语言模型在解析指令和初步规划方面显示出了潜力，但它们存在长期推理和动态多机器人协调方面的局限性。因此，本文提出了一种新的方法来克服这些限制。", "method": "H-AIM框架通过三个阶段级联架构实现任务：1）利用大语言模型将指令转换为PDDL问题描述；2）结合语义推理能力和经典规划器生成优化的动作序列；3）编译计划以行为树的形式进行反应控制，并支持异构机器人团队的动态规模和通信同步。", "result": "实验结果表明，H-AIM显著提高了任务成功率（从12%提升到55%），并提升了目标条件回召率（从32%提升至72%）。", "conclusion": "提出的H-AIM框架通过结合大语言模型、PDDL和行为树实现了异构机器人团队在长期任务执行中的有效规划，显著提高了性能。"}}
{"id": "2601.11060", "pdf": "https://arxiv.org/pdf/2601.11060", "abs": "https://arxiv.org/abs/2601.11060", "authors": ["Emelie Fälton", "Isabelle Strömstedt", "Mathis Brossier", "Andreas Göransson", "Konrad Schönborn", "Amy Loutfi", "Erik Sunden", "Mujtaba Fadhil Jawad", "Yadgar Suleiman", "Johanna Björklund", "Mario Romero", "Anders Ynnerman", "Lonni Besançon"], "title": "Children's Expectations, Engagement, and Evaluation of an LLM-enabled Spherical Visualization Platform in the Classroom", "categories": ["cs.HC"], "comment": null, "summary": "We present our first stage results from deploying an LLM-augmented visualization software in a classroom setting to engage primary school children with earth-related datasets. Motivated by the growing interest in conversational AI as a means to support inquiry-based learning, we investigate children's expectations, engagement, and evaluation of a spoken LLM interface with a shared, immersive visualization system in a formal educational context. Our system integrates a speech-capable large language model with an interactive spherical display. It enables children to ask natural-language questions and receive coordinated verbal explanations and visual responses through the LLM-augmented visualization updating in real time based on spoken queries. We report on a classroom study with Swedish children aged 9-10, combining structured observation and small-group discussions to capture expectations prior to interaction, interaction patterns during facilitated sessions, and children's reflections on their encounter afterward. Our results provide empirical insights into children's initial encounters with an LLM-enabled visualization platform within a classroom setting and their expectations, interactions, and evaluations of the system. These findings inform the technology's potential for educational use and highlight important directions for future research.", "AI": {"tldr": "研究在课堂环境中使用LLM增强的可视化软件，以吸引小学生对地球相关数据的兴趣，并探讨他们对该系统的期望、参与度和评价。", "motivation": "受到对话式AI支持探究式学习兴趣的增长，研究动机是探索小学生在正式教育环境下与配备语音接口的大语言模型整合的沉浸式可视化系统互动的情况。", "method": "通过课堂研究结合结构化观察和小组讨论来捕捉学生在交互前后的期望、交互模式和反思。参与者为9-10岁的瑞典儿童。", "result": "结果提供了小学生首次接触LLM增强的可视化平台及其对系统的期望、互动及评价的实证见解。", "conclusion": "研究发现为该技术在教育中的潜力提供了信息，并强调了未来研究的重要方向。"}}
{"id": "2601.11049", "pdf": "https://arxiv.org/pdf/2601.11049", "abs": "https://arxiv.org/abs/2601.11049", "authors": ["Stephen Pilli", "Vivek Nallur"], "title": "Predicting Biased Human Decision-Making with Large Language Models in Conversational Settings", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted at ACM IUI 2026", "summary": "We examine whether large language models (LLMs) can predict biased decision-making in conversational settings, and whether their predictions capture not only human cognitive biases but also how those effects change under cognitive load. In a pre-registered study (N = 1,648), participants completed six classic decision-making tasks via a chatbot with dialogues of varying complexity. Participants exhibited two well-documented cognitive biases: the Framing Effect and the Status Quo Bias. Increased dialogue complexity resulted in participants reporting higher mental demand. This increase in cognitive load selectively, but significantly, increased the effect of the biases, demonstrating the load-bias interaction. We then evaluated whether LLMs (GPT-4, GPT-5, and open-source models) could predict individual decisions given demographic information and prior dialogue. While results were mixed across choice problems, LLM predictions that incorporated dialogue context were significantly more accurate in several key scenarios. Importantly, their predictions reproduced the same bias patterns and load-bias interactions observed in humans. Across all models tested, the GPT-4 family consistently aligned with human behavior, outperforming GPT-5 and open-source models in both predictive accuracy and fidelity to human-like bias patterns. These findings advance our understanding of LLMs as tools for simulating human decision-making and inform the design of conversational agents that adapt to user biases.", "AI": {"tldr": "研究探讨了大型语言模型在对话场景中预测人类偏见决策的能力，并分析了这些模型的预测是否能捕捉到认知负荷下人类认知偏差的变化。", "motivation": "了解大型语言模型能否模拟人类在复杂对话条件下的偏见决策，从而改进会话代理的设计以适应用户的行为。", "method": "通过一个预注册的研究，参与者与聊天机器人完成六个经典决策任务。研究评估了GPT-4、GPT-5和开源模型预测个体决策的准确性，并分析它们是否能再现人类的认知偏差和认知负荷的影响。", "result": "参与者展现了框架效应和现状偏见两种典型认知偏见，且对话复杂度增加导致更高的认知需求并放大这些偏见。大型语言模型在纳入对话背景后，在多个关键场景中显示出较高的预测准确性和对人类似偏见模式的再现能力。", "conclusion": "研究结果表明，LLMs可以作为模拟人类决策行为的有效工具，并为设计适应用户偏见的会话代理提供理论依据。GPT-4系列模型在预测准确性及忠实反映人类偏见模式方面表现突出。"}}
{"id": "2601.11048", "pdf": "https://arxiv.org/pdf/2601.11048", "abs": "https://arxiv.org/abs/2601.11048", "authors": ["Takuya Murakawa", "Takumi Fukuzawa", "Ning Ding", "Toru Tamaki"], "title": "M3DDM+: An improved video outpainting by a modified masking strategy", "categories": ["cs.CV"], "comment": "proc. of IWAIT2026", "summary": "M3DDM provides a computationally efficient framework for video outpainting via latent diffusion modeling. However, it exhibits significant quality degradation -- manifested as spatial blur and temporal inconsistency -- under challenging scenarios characterized by limited camera motion or large outpainting regions, where inter-frame information is limited. We identify the cause as a training-inference mismatch in the masking strategy: M3DDM's training applies random mask directions and widths across frames, whereas inference requires consistent directional outpainting throughout the video. To address this, we propose M3DDM+, which applies uniform mask direction and width across all frames during training, followed by fine-tuning of the pretrained M3DDM model. Experiments demonstrate that M3DDM+ substantially improves visual fidelity and temporal coherence in information-limited scenarios while maintaining computational efficiency. The code is available at https://github.com/tamaki-lab/M3DDM-Plus.", "AI": {"tldr": "本文提出了M3DDM+，通过改进的掩码策略提升视频外推的质量和时间连贯性。", "motivation": "解决现有模型在相机运动有限或外插区域较大的情况下出现的空间模糊和时间不一致的问题。", "method": "提出统一帧间掩码方向和宽度，并对预训练的M3DDM模型进行微调以改进视频外推效果。", "result": "实验结果表明，M3DDM+在信息受限场景中显著提高了视觉质量和时间连贯性，同时保持计算效率。", "conclusion": "通过改进掩码策略，M3DDM+有效提升了视频外推的质量和时间一致性，并维持了高效的计算性能。"}}
{"id": "2601.11045", "pdf": "https://arxiv.org/pdf/2601.11045", "abs": "https://arxiv.org/abs/2601.11045", "authors": ["Mayesha Maliha R. Mithila", "Mylene C. Q. Farias"], "title": "Convolutions Need Registers Too: HVS-Inspired Dynamic Attention for Video Quality Assessment", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "Accepted at ACM MMSys 2026. 12 pages, 8 figures. No supplementary material", "summary": "No-reference video quality assessment (NR-VQA) estimates perceptual quality without a reference video, which is often challenging. While recent techniques leverage saliency or transformer attention, they merely address global context of the video signal by using static maps as auxiliary inputs rather than embedding context fundamentally within feature extraction of the video sequence. We present Dynamic Attention with Global Registers for Video Quality Assessment (DAGR-VQA), the first framework integrating register-token directly into a convolutional backbone for spatio-temporal, dynamic saliency prediction. By embedding learnable register tokens as global context carriers, our model enables dynamic, HVS-inspired attention, producing temporally adaptive saliency maps that track salient regions over time without explicit motion estimation. Our model integrates dynamic saliency maps with RGB inputs, capturing spatial data and analyzing it through a temporal transformer to deliver a perceptually consistent video quality assessment. Comprehensive tests conducted on the LSVQ, KonVid-1k, LIVE-VQC, and YouTube-UGC datasets show that the performance is highly competitive, surpassing the majority of top baselines. Research on ablation studies demonstrates that the integration of register tokens promotes the development of stable and temporally consistent attention mechanisms. Achieving an efficiency of 387.7 FPS at 1080p, DAGR-VQA demonstrates computational performance suitable for real-time applications like multimedia streaming systems.", "AI": {"tldr": "本文提出了一种名为DAGR-VQA的框架，通过在卷积主干网络中直接集成寄存器令牌以进行动态、HVS启发的注意力机制来预测时空动态显著图，从而实现无参考视频质量评估。", "motivation": "现有的无参考视频质量评估技术通常使用静态地图作为辅助输入处理视频信号的全局上下文，并未根本性地将其嵌入到视频序列特征提取中。因此，提出DAGR-VQA框架以改善这一问题。", "method": "该方法通过嵌入可学习寄存器令牌作为全局上下文载体，使模型能够产生随时间动态调整的显著图并跟踪显著区域。模型将动态显著图与RGB输入结合，并使用时空变换器进行分析，实现感知一致的视频质量评估。", "result": "在LSVQ、KonVid-1k、LIVE-VQC和YouTube-UGC数据集上进行全面测试后显示，该方法性能优越，超越了大部分顶级基线模型。研究还表明，寄存器令牌的整合促进了稳定且时空一致注意力机制的发展。", "conclusion": "DAGR-VQA框架实现了387.7 FPS（1080p）的计算效率，适用于实时应用如多媒体流系统。"}}
{"id": "2601.11044", "pdf": "https://arxiv.org/pdf/2601.11044", "abs": "https://arxiv.org/abs/2601.11044", "authors": ["Keyu Li", "Junhao Shi", "Yang Xiao", "Mohan Jiang", "Jie Sun", "Yunze Wu", "Shijie Xia", "Xiaojie Cai", "Tianze Xu", "Weiye Si", "Wenjie Li", "Dequan Wang", "Pengfei Liu"], "title": "AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AgencyBench, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench.", "AI": {"tldr": "介绍了AgencyBench，一个全面的基准测试平台，用于评估大型语言模型（LLMs）驱动的自主代理在现实世界场景中的性能。", "motivation": "现有基准测试主要关注单一能力，并依赖人类反馈，这限制了自动化的扩展。为解决这些问题并更准确地评估真实世界的长期情景下的自主代理表现，提出了AgencyBench。", "method": "构建了一个包含32个实际情境和138项特定任务的基准测试平台，涉及6种核心代理能力，并使用用户模拟代理提供迭代反馈来实现自动化评估。", "result": "实验显示闭源模型在性能上优于开源模型（48.4% vs 32.1%），并发现不同模型间存在资源效率和自我修正方面的显著差异。此外，发现专有模型在其原生生态系统中表现更佳。", "conclusion": "AgencyBench作为下一代自主代理测试平台的重要性被强调，并指出需要优化模型架构与代理框架的结合。该工作对未来的自主代理发展方向提供了重要见解。"}}
{"id": "2601.11043", "pdf": "https://arxiv.org/pdf/2601.11043", "abs": "https://arxiv.org/abs/2601.11043", "authors": ["Max Linnander", "Yon Visell"], "title": "Haptic Light-Emitting Diodes: Miniature, Luminous Tactile Actuators", "categories": ["cs.HC", "cs.RO"], "comment": null, "summary": "We present Haptic Light-Emitting Diodes (HLEDs), luminous thermopneumatic actuators that directly convert pulsed light into mechanical forces and displacements. Each device packages a miniature surface-mount LED in a gas-filled cavity that contains a low-inertia graphite photoabsorber. The cavity is sealed by an elastic membrane, which functions as a working diaphragm. Brief optical pulses heat the photoabsorber, which heats the gas. The resulting rapid pressure increases generate forces and displacements at the working diaphragm. Millimeter-scale HLEDs produce forces exceeding 0.4 N and displacements of 1 mm at low voltages, with 5 to 100 ms response times, making them attractive as actuators providing tactile feedback in human-machine interfaces. Perceptual testing revealed that the strength of tactile feedback increased linearly with optical power. HLEDs devices are mechanically simple and efficient to fabricate. Unusually, these actuators are also light-emitting, as a fraction of optical energy is transmitted through the membrane. These opto-mechanical actuators have many potential applications in tactile displays, human interface engineering, wearable computing, and other areas.", "AI": {"tldr": "本论文介绍了Haptic Light-Emitting Diodes（HLEDs），一种将脉冲光直接转换为机械力和位移的微型、发光触觉致动器。", "motivation": "开发新型高效且简易制造的触觉反馈致动器，用于人机界面中的触觉交互。", "method": "通过将微型表面贴装LED封装在充满气体的腔体中，该腔体内含低惯性石墨光吸收剂，并由弹性膜密封作为工作隔膜，利用光学脉冲加热光吸收剂从而产生压力变化，驱动位移和力输出。", "result": "毫米级HLEDs能够在低压下产生超过0.4N的力和1mm的位移，响应时间在5到100毫秒之间。感知测试表明触觉反馈强度与光学功率呈线性关系。", "conclusion": "HLEDs作为一种轻巧且高效的致动器，在触觉显示器、人机界面工程、可穿戴计算等众多领域具有广泛的应用潜力。"}}
{"id": "2601.11042", "pdf": "https://arxiv.org/pdf/2601.11042", "abs": "https://arxiv.org/abs/2601.11042", "authors": ["Chi Zhang", "Mengqi Zhang", "Xiaotian Ye", "Runxi Cheng", "Zisheng Zhou", "Ying Zhou", "Pengjie Ren", "Zhumin Chen"], "title": "Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 18 figures", "summary": "Sequential knowledge editing in large language models often causes catastrophic collapse of the model's general abilities, especially for parameter-modifying methods. Existing approaches mitigate this issue through heuristic constraints on parameter updates, yet the mechanisms underlying such degradation remain insufficiently understood. In this work, we present a spectral analysis of sequential knowledge editing and show that a model's general abilities are closely associated with dominant singular directions of pretrained weight matrices. These directions are highly sensitive to perturbations and are progressively disrupted by repeated edits, closely tracking the collapse in both editing efficacy and general performance. Building on this insight, we propose REVIVE, a plug-and-play framework that stabilizes sequential editing by explicitly preserving the dominant singular subspace. REVIVE represents parameter updates in the spectral basis of the original weights and filters components that would interfere with the protected region. Extensive experiments across multiple models and benchmarks show that REVIVE consistently improves editing efficacy while substantially preserving general abilities under long-horizon sequential editing, including extreme settings with up to 20,000 edits.", "AI": {"tldr": "本文提出REVIVE框架，通过保护权重矩阵的主奇异子空间来稳定大型语言模型中的连续知识编辑。", "motivation": "现有方法无法充分解释大型语言模型在连续知识编辑过程中能力崩溃的原因，并且现有的缓解策略效果有限。", "method": "作者进行了频谱分析以发现模型一般能力与预训练权重矩阵的主奇异方向密切相关，提出REVIVE框架通过保留这些主要奇异子空间来稳定参数更新。", "result": "实验结果显示，REVIVE在多个模型和基准测试中持续提高编辑效果，并大幅保存连续编辑下的通用能力，甚至在多达20,000次编辑的情况下也表现良好。", "conclusion": "REVIVE框架通过保护权重矩阵的主奇异子空间来有效缓解大型语言模型中的连续知识编辑崩溃问题。"}}
{"id": "2601.11039", "pdf": "https://arxiv.org/pdf/2601.11039", "abs": "https://arxiv.org/abs/2601.11039", "authors": ["Yirong Sun", "Yanjun Chen", "Xin Qiu", "Gang Zhang", "Hongyu Chen", "Daokuan Wu", "Chengming Li", "Min Yang", "Dawei Zhu", "Wei Zhang", "Xiaoyu Shen"], "title": "SonicBench: Dissecting the Physical Perception Bottleneck in Large Audio Language Models", "categories": ["cs.SD", "cs.CL"], "comment": null, "summary": "Large Audio Language Models (LALMs) excel at semantic and paralinguistic tasks, yet their ability to perceive the fundamental physical attributes of audio such as pitch, loudness, and spatial location remains under-explored. To bridge this gap, we introduce SonicBench, a psychophysically grounded benchmark that systematically evaluates 12 core physical attributes across five perceptual dimensions. Unlike previous datasets, SonicBench uses a controllable generation toolbox to construct stimuli for two complementary paradigms: recognition (absolute judgment) and comparison (relative judgment). This design allows us to probe not only sensory precision but also relational reasoning capabilities, a domain where humans typically exhibit greater proficiency. Our evaluation reveals a substantial deficiency in LALMs' foundational auditory understanding; most models perform near random guessing and, contrary to human patterns, fail to show the expected advantage on comparison tasks. Furthermore, explicit reasoning yields minimal gains. However, our linear probing analysis demonstrates crucially that frozen audio encoders do successfully capture these physical cues (accuracy at least 60%), suggesting that the primary bottleneck lies in the alignment and decoding stages, where models fail to leverage the sensory signals they have already captured.", "AI": {"tldr": "提出了 SonicBench 基准测试，以评估大音频语言模型在感知基本物理属性方面的瓶颈。", "motivation": "虽然大型音频语言模型在语义和副语言任务方面表现出色，但它们对音频的基本物理属性的感知能力尚未充分探索。该研究旨在填补这一空白。", "method": "SonicBench 基于心理物理学原理设计，包含12个核心物理属性和五种感知维度，通过可控制生成工具箱构建刺激物用于识别和比较两种范式评估模型。", "result": "研究表明大型音频语言模型在基础听觉理解方面存在显著缺陷，大多数模型的表现接近随机猜测，并且没有显示出人类在比较任务中的优势。线性探测分析显示冻结的音频编码器成功捕获了这些物理线索，表明瓶颈在于对齐和解码阶段。", "conclusion": "主要结论是大型音频语言模型的主要瓶颈在于对齐和解码阶段，而不是感知信号的捕捉能力。"}}
{"id": "2601.11037", "pdf": "https://arxiv.org/pdf/2601.11037", "abs": "https://arxiv.org/abs/2601.11037", "authors": ["Shiyu Liu", "Yongjing Yin", "Jianhao Yan", "Yunbo Tang", "Qinggang Zhang", "Bei Li", "Xin Chen", "Jingang Wang", "Xunliang Cai", "Jinsong Su"], "title": "BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search", "categories": ["cs.AI"], "comment": "Code is available at https://github.com/Liushiyu-0709/BAPO-Reliable-Search", "summary": "RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search.", "AI": {"tldr": "本文提出了一种名为边界感知策略优化（BAPO）的新型强化学习框架，旨在提高基于RL的智能体搜索在识别其推理边界时的可靠性。", "motivation": "尽管基于RL的代理搜索通过动态规划和外部搜索解决了复杂问题，但这些代理往往不能识别其推理边界，并且即使证据不足或推理达到极限也不承认自己不知道（IDK），这可能导致答案可靠性的缺失。", "method": "BAPO框架包含两个关键组件：1) 一种基于组的边界感知奖励，鼓励在推理达到极限时作出IDK响应；2) 一个自适应奖励调节器，在早期探索阶段战略性地暂停这种奖励，防止模型利用IDK作为捷径。", "result": "实验结果表明，BAPO框架显著提升了代理搜索的整体可靠性。", "conclusion": "边界感知策略优化（BAPO）能够有效地提高基于RL的智能体在执行搜索任务时对于自身能力极限的认知和表达，从而增强系统的可靠性和安全性。"}}
{"id": "2601.11035", "pdf": "https://arxiv.org/pdf/2601.11035", "abs": "https://arxiv.org/abs/2601.11035", "authors": ["Long Ma", "Zihao Xue", "Yan Wang", "Zhiyuan Yan", "Jin Xu", "Xiaorui Jiang", "Haiyang Yu", "Yong Liao", "Zhen Bi"], "title": "Your One-Stop Solution for AI-Generated Video Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods. However, two key limitations hinder the development of this field. \\textbf{From the dataset perspective}, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diversity and rapid evolution of modern generative techniques. Moreover, the dataset construction process frequently prioritizes quantity over quality, neglecting essential aspects such as semantic diversity, scenario coverage, and technological representativeness. \\textbf{From the benchmark perspective}, current benchmarks largely remain at the stage of dataset creation, leaving many fundamental issues and in-depth analysis yet to be systematically explored. Addressing this gap, we propose AIGVDBench, a benchmark designed to be comprehensive and representative, covering \\textbf{31} state-of-the-art generation models and over \\textbf{440,000} videos. By executing more than \\textbf{1,500} evaluations on \\textbf{33} existing detectors belonging to four distinct categories. This work presents \\textbf{8 in-depth analyses} from multiple perspectives and identifies \\textbf{4 novel findings} that offer valuable insights for future research. We hope this work provides a solid foundation for advancing the field of AI-generated video detection. Our benchmark is open-sourced at https://github.com/LongMa-2025/AIGVDBench.", "AI": {"tldr": "本文提出了AIGVDBench，一个全面的AI生成视频检测基准，以解决现有数据集和评估方法存在的局限性。", "motivation": "由于现有的数据集规模有限且使用过时或范围狭窄的生成模型，以及目前的基准测试主要停留在数据集创建阶段，缺乏系统的深入分析，本文旨在填补这一空白。", "method": "AIGVDBench涵盖31种最先进生成模型和超过44万视频，进行了超过1500次评估，并对现有检测器进行8项深度分析。", "result": "该研究识别出4项新的发现，为未来的AI生成视频检测提供了有价值的见解。", "conclusion": "本文的工作提供了一个坚实的基础来推动AI生成视频检测领域的进步。"}}
{"id": "2601.11030", "pdf": "https://arxiv.org/pdf/2601.11030", "abs": "https://arxiv.org/abs/2601.11030", "authors": ["Xianliang Huang", "Jiajie Gou", "Shuhang Chen", "Zhizhou Zhong", "Jihong Guan", "Shuigeng Zhou"], "title": "IDDR-NGP: Incorporating Detectors for Distractor Removal with Instant Neural Radiance Field", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 7 figures, accepted by ACM-MM23", "summary": "This paper presents the first unified distractor removal method, named IDDR-NGP, which directly operates on Instant-NPG. The method is able to remove a wide range of distractors in 3D scenes, such as snowflakes, confetti, defoliation and petals, whereas existing methods usually focus on a specific type of distractors. By incorporating implicit 3D representations with 2D detectors, we demonstrate that it is possible to efficiently restore 3D scenes from multiple corrupted images. We design the learned perceptual image patch similarity~( LPIPS) loss and the multi-view compensation loss (MVCL) to jointly optimize the rendering results of IDDR-NGP, which could aggregate information from multi-view corrupted images. All of them can be trained in an end-to-end manner to synthesize high-quality 3D scenes. To support the research on distractors removal in implicit 3D representations, we build a new benchmark dataset that consists of both synthetic and real-world distractors. To validate the effectiveness and robustness of IDDR-NGP, we provide a wide range of distractors with corresponding annotated labels added to both realistic and synthetic scenes. Extensive experimental results demonstrate the effectiveness and robustness of IDDR-NGP in removing multiple types of distractors. In addition, our approach achieves results comparable with the existing SOTA desnow methods and is capable of accurately removing both realistic and synthetic distractors.", "AI": {"tldr": "本文提出了首个统一的干扰物移除方法IDDR-NGP，该方法可以直接在Instant-NPG上操作并从多视角受损图像中恢复高质量的3D场景。", "motivation": "现有方法通常只关注特定类型的干扰物，而本文旨在开发一种可以处理更广泛类型干扰物（如雪花、彩带、落叶和花瓣等）的方法。", "method": "通过结合隐式三维表示与二维检测器，并设计了LPIPS损失和多视角补偿损失来优化渲染结果，以实现从多个受损图像中聚合信息并合成高质量的3D场景。", "result": "实验结果显示IDDR-NGP在移除多种类型的干扰物方面有效且鲁棒，并能达到现有顶尖去雪方法的结果水平，能够准确地移除现实和合成的干扰物。", "conclusion": "研究证明了IDDR-NGP的有效性和鲁棒性，可以在隐式3D表示中处理多种类型的干扰物移除问题。"}}
{"id": "2601.11029", "pdf": "https://arxiv.org/pdf/2601.11029", "abs": "https://arxiv.org/abs/2601.11029", "authors": ["Mingyang Yu", "Jiaqi Zhang", "Haorui Yang", "Adam Slowik", "Huiling Chen", "Jing Xu"], "title": "A Quantum-Driven Evolutionary Framework for Solving High-Dimensional Sharpe Ratio Portfolio Optimization", "categories": ["cs.NE"], "comment": "Mingyang Yu and Jiaqi Zhang contributed equally", "summary": "High-dimensional portfolio optimization faces significant computational challenges under complex constraints, with traditional optimization methods struggling to balance convergence speed and global exploration capability. To address this, firstly, we introduce an enhanced Sharpe ratio-based model that incorporates all constraints into the objective function using adaptive penalty terms, transforming the original constrained problem into an unconstrained single-objective formulation. This approach preserves financial interpretability while simplifying algorithmic implementation. To efficiently solve the resulting high-dimensional optimization problem, we propose a Quantum Hybrid Differential Evolution (QHDE) algorithm, which integrates Quantum-inspired probabilistic behavior into the standard DE framework. QHDE employs a Schrodinger-inspired probabilistic mechanism for population evolution, enabling more flexible and diversified solution updates. To further enhance performance, a good point set-chaos reverse learning strategy is adopted to generate a well-dispersed initial population, and a dynamic elite pool combined with Cauchy-Gaussian hybrid perturbations strengthens global exploration and mitigates premature convergence. Experimental validation on CEC benchmarks and real-world portfolios involving 20 to 80 assets demonstrates that QHDE's performance improves by up to 73.4%. It attains faster convergence, higher solution precision, and greater robustness than seven state-of-the-art counterparts, thereby confirming its suitability for complex, high-dimensional portfolio optimization and advancing quantum-inspired evolutionary research in computational finance.", "AI": {"tldr": "提出一种基于量子驱动的进化框架来解决高维夏普比率投资组合优化问题。", "motivation": "传统的优化方法在处理复杂的约束条件时，在收敛速度和全局探索能力之间难以平衡，本文旨在通过引入增强的夏普比率模型和量子混合差分进化算法（QHDE），提高高维投资组合优化的效果。", "method": "采用带自适应惩罚项的增强型夏普比率模型将问题转化为无约束单目标问题，并提出一种结合了量子概率行为的标准差分进化框架，即QHDE。QHDE使用薛定谔启发的概率机制进行种群演化。同时采用了好点集混沌反向学习策略和动态精英池及柯西-高斯混合扰动来增强全局探索能力和防止过早收敛。", "result": "实验验证表明，在CEC基准测试和涉及20至80个资产的真实投资组合中，QHDE的性能提升了最高达73.4%，并实现了更快的收敛速度、更高的解决方案精度以及更好的鲁棒性。", "conclusion": "研究表明提出的量子混合差分进化算法（QHDE）在复杂高维投资组合优化问题上表现出色，验证了其作为计算金融领域中量子启发式进化的研究进展。"}}
{"id": "2601.11027", "pdf": "https://arxiv.org/pdf/2601.11027", "abs": "https://arxiv.org/abs/2601.11027", "authors": ["Chengyou Wang", "Mingchen Shao", "Jingbin Hu", "Zeyu Zhu", "Hongfei Xue", "Bingshen Mu", "Xin Xu", "Xingyi Duan", "Binbin Zhang", "Pengcheng Zhu", "Chuang Ding", "Xiaojun Zhang", "Hui Bu", "Lei Xie"], "title": "WenetSpeech-Wu: Datasets, Benchmarks, and Models for a Unified Chinese Wu Dialect Speech Processing Ecosystem", "categories": ["cs.SD"], "comment": null, "summary": "Speech processing for low-resource dialects remains a fundamental challenge in developing inclusive and robust speech technologies. Despite its linguistic significance and large speaker population, the Wu dialect of Chinese has long been hindered by the lack of large-scale speech data, standardized evaluation benchmarks, and publicly available models. In this work, we present WenetSpeech-Wu, the first large-scale, multi-dimensionally annotated open-source speech corpus for the Wu dialect, comprising approximately 8,000 hours of diverse speech data. Building upon this dataset, we introduce WenetSpeech-Wu-Bench, the first standardized and publicly accessible benchmark for systematic evaluation of Wu dialect speech processing, covering automatic speech recognition (ASR), Wu-to-Mandarin translation, speaker attribute prediction, speech emotion recognition, text-to-speech (TTS) synthesis, and instruction-following TTS (instruct TTS). Furthermore, we release a suite of strong open-source models trained on WenetSpeech-Wu, establishing competitive performance across multiple tasks and empirically validating the effectiveness of the proposed dataset. Together, these contributions lay the foundation for a comprehensive Wu dialect speech processing ecosystem, and we open-source proposed datasets, benchmarks, and models to support future research on dialectal speech intelligence.", "AI": {"tldr": "本文介绍了WenetSpeech-Wu，一个针对中文吴方言的大型多维度注释开源语音语料库，并基于该数据集创建了评估基准和一系列强性能模型。", "motivation": "由于缺乏大规模的语音数据、标准化评估基准和公开可用的模型，吴方言在语音处理方面面临着根本性挑战。本文旨在解决这一问题，推动包容性和健壮性的语音技术发展。", "method": "构建了一个包含约8000小时多样化语音数据的大型开源语料库WenetSpeech-Wu，并基于此创建了系统评估吴方言语音处理的标准基准WenetSpeech-Wu-Bench以及一系列强性能模型。", "result": "发布了针对吴方言自动语音识别、吴到普通话翻译、说话人属性预测等任务的强性能模型，验证了所提出数据集的有效性，并建立了有竞争力的表现。", "conclusion": "这些贡献为吴方言语音处理生态系统奠定了基础，并公开源代码以支持未来对方言语音智能的研究。"}}
{"id": "2601.11026", "pdf": "https://arxiv.org/pdf/2601.11026", "abs": "https://arxiv.org/abs/2601.11026", "authors": ["HyoJae Kang", "SunWoo Ahn", "InGyu Choi", "GeonYeong Go", "KunWoo Son", "Min-Sung Kang"], "title": "Crane Lowering Guidance Using a Attachable Camera Module for Driver Vision Support", "categories": ["cs.RO"], "comment": "Presented at ICCR 2025(International COnference on Control and Robotics 2025). Submitted to the IEEE for possible publication", "summary": "Cranes have long been essential equipment for lifting and placing heavy loads in construction projects. This study focuses on the lowering phase of crane operation, the stage in which the load is moved to the desired location. During this phase, a constant challenge exists: the load obstructs the operator's view of the landing point. As a result, operators traditionally have to rely on verbal or gestural instructions from ground personnel, which significantly impacts site safety. To alleviate this constraint, the proposed system incorporates a attachable camera module designed to be attached directly to the load via a suction cup. This module houses a single-board computer, battery, and compact camera. After installation, it streams and processes images of the ground directly below the load in real time to generate installation guidance. Simultaneously, this guidance is transmitted to and monitored by a host computer. Preliminary experiments were conducted by attaching this module to a test object, confirming the feasibility of real-time image acquisition and transmission. This approach has the potential to significantly improve safety on construction sites by providing crane operators with an instant visual reference of hidden landing zones.", "AI": {"tldr": "本文提出了一种可安装在起重设备负载上的摄像模块，以解决操作员视线受阻的问题，提高施工现场的安全性。", "motivation": "传统的起重机操作中，由于负载遮挡了操作员的视线，导致需要依赖地面人员的手势或口头指令来定位落点，这严重影响了工地安全。本文旨在通过技术手段改善这一问题。", "method": "设计了一个可附着在负载上的摄像模块，该模块内置单板计算机、电池和小型摄像头，实时采集并传输负载下方的图像，并为操作员提供安装指导。", "result": "初步实验结果验证了系统可以实现实时影像获取与传送功能，证明了其技术可行性。", "conclusion": "该方法有潜力通过为起重机操作员即时提供隐藏区域的视觉参考，显著改善施工现场的安全性。"}}
{"id": "2601.11022", "pdf": "https://arxiv.org/pdf/2601.11022", "abs": "https://arxiv.org/abs/2601.11022", "authors": ["Sravan Danda", "Aditya Challa", "Shlok Mehendale", "Snehanshu Saha"], "title": "Matching High-Dimensional Geometric Quantiles for Test-Time Adaptation of Transformers and Convolutional Networks Alike", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Test-time adaptation (TTA) refers to adapting a classifier for the test data when the probability distribution of the test data slightly differs from that of the training data of the model. To the best of our knowledge, most of the existing TTA approaches modify the weights of the classifier relying heavily on the architecture. It is unclear as to how these approaches are extendable to generic architectures. In this article, we propose an architecture-agnostic approach to TTA by adding an adapter network pre-processing the input images suitable to the classifier. This adapter is trained using the proposed quantile loss. Unlike existing approaches, we correct for the distribution shift by matching high-dimensional geometric quantiles. We prove theoretically that under suitable conditions minimizing quantile loss can learn the optimal adapter. We validate our approach on CIFAR10-C, CIFAR100-C and TinyImageNet-C by training both classic convolutional and transformer networks on CIFAR10, CIFAR100 and TinyImageNet datasets.", "AI": {"tldr": "本文提出了一种架构无关的测试时间适应方法，通过匹配高维几何分位数来调整输入图像，以提高分类器在测试数据上的表现。", "motivation": "现有大多数测试时间适应方法依赖于特定的网络架构，并且无法轻易扩展到其他架构中。因此，本文旨在开发一种可以广泛应用于不同架构的方法。", "method": "提出了一种使用分位数损失训练适配器网络来预处理输入图像的方法。这种方法通过匹配高维几何分位数来校正数据分布的差异。理论证明表明，在一定条件下最小化分位数损失可以学习到最优的适配器。", "result": "在CIFAR10-C，CIFAR100-C和TinyImageNet-C上验证了该方法的有效性，实验中同时训练了传统的卷积网络和变压器网络。", "conclusion": "本文证明了所提出的方法能够有效提升不同架构的分类器在测试数据上的性能，并且具有广泛的应用潜力。"}}
{"id": "2601.11021", "pdf": "https://arxiv.org/pdf/2601.11021", "abs": "https://arxiv.org/abs/2601.11021", "authors": ["Kecheng Cai", "Chenyang Xu", "Chao Peng"], "title": "Combating Spurious Correlations in Graph Interpretability via Self-Reflection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Interpretable graph learning has recently emerged as a popular research topic in machine learning. The goal is to identify the important nodes and edges of an input graph that are crucial for performing a specific graph reasoning task. A number of studies have been conducted in this area, and various benchmark datasets have been proposed to facilitate evaluation. Among them, one of the most challenging is the Spurious-Motif benchmark, introduced at ICLR 2022. The datasets in this synthetic benchmark are deliberately designed to include spurious correlations, making it particularly difficult for models to distinguish truly relevant structures from misleading patterns. As a result, existing methods exhibit significantly worse performance on this benchmark compared to others. In this paper, we focus on improving interpretability on the challenging Spurious-Motif datasets. We demonstrate that the self-reflection technique, commonly used in large language models to tackle complex tasks, can also be effectively adapted to enhance interpretability in datasets with strong spurious correlations. Specifically, we propose a self-reflection framework that can be integrated with existing interpretable graph learning methods. When such a method produces importance scores for each node and edge, our framework feeds these predictions back into the original method to perform a second round of evaluation. This iterative process mirrors how large language models employ self-reflective prompting to reassess their previous outputs. We further analyze the reasons behind this improvement from the perspective of graph representation learning, which motivates us to propose a fine-tuning training method based on this feedback mechanism.", "AI": {"tldr": "本文提出了一个自我反思框架，用于增强图学习解释性在存在强烈虚假相关性的数据集上的表现。", "motivation": "现有方法在Spurious-Motif基准测试中性能显著下降，因为这些数据集包含故意设计的虚假相关性，使得模型难以区分真正相关的结构和误导性模式。", "method": "本文提出的方法是一个自我反思框架，它可以与现有的可解释图学习方法结合使用。当一种方法为每个节点和边生成重要性得分时，该框架将其反馈回原始方法进行第二轮评估。", "result": "通过迭代过程，该框架能够提高模型在具有强烈虚假相关性的数据集上的解释能力，并提出了一种基于这种反馈机制的微调训练方法。", "conclusion": "研究证明了自我反思技术可以有效地适应于增强图学习中存在强虚假相关性时的可解释性问题。"}}
{"id": "2601.11019", "pdf": "https://arxiv.org/pdf/2601.11019", "abs": "https://arxiv.org/abs/2601.11019", "authors": ["Xinwei Wu", "Heng Liu", "Xiaohu Zhao", "Yuqi Ren", "Linlong Xu", "Longyue Wang", "Deyi Xiong", "Weihua Luo", "Kaifu Zhang"], "title": "Finding the Translation Switch: Discovering and Exploiting the Task-Initiation Features in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by AAAI 2026", "summary": "Large Language Models (LLMs) frequently exhibit strong translation abilities, even without task-specific fine-tuning. However, the internal mechanisms governing this innate capability remain largely opaque. To demystify this process, we leverage Sparse Autoencoders (SAEs) and introduce a novel framework for identifying task-specific features. Our method first recalls features that are frequently co-activated on translation inputs and then filters them for functional coherence using a PCA-based consistency metric. This framework successfully isolates a small set of **translation initiation** features. Causal interventions demonstrate that amplifying these features steers the model towards correct translation, while ablating them induces hallucinations and off-task outputs, confirming they represent a core component of the model's innate translation competency. Moving from analysis to application, we leverage this mechanistic insight to propose a new data selection strategy for efficient fine-tuning. Specifically, we prioritize training on **mechanistically hard** samples-those that fail to naturally activate the translation initiation features. Experiments show this approach significantly improves data efficiency and suppresses hallucinations. Furthermore, we find these mechanisms are transferable to larger models of the same family. Our work not only decodes a core component of the translation mechanism in LLMs but also provides a blueprint for using internal model mechanism to create more robust and efficient models. The codes are available at https://github.com/flamewei123/AAAI26-translation-Initiation-Features.", "AI": {"tldr": "本文旨在揭示大型语言模型（LLMs）内在翻译能力的机制，并提出一种新的数据选择策略以提高训练效率。", "motivation": "尽管大型语言模型拥有强大的翻译能力，但其内部驱动这些能力的具体机制尚不清楚。本研究希望通过探索这一过程来更好地理解并优化这些模型。", "method": "使用稀疏自编码器（SAEs）和基于主成分分析的连贯性度量方法，识别出翻译任务特有的特征，并通过因果干预验证这些特征的功能。", "result": "成功识别了启动翻译的关键特征，并证明增强这些特征可以引导模型正确翻译。采用新数据选择策略训练模型显著提高了效率并减少了幻觉输出。", "conclusion": "本研究揭示了大型语言模型中翻译机制的核心部分，并为利用内部工作机制构建更强大、更高效的模型提供了蓝图。"}}
{"id": "2601.11018", "pdf": "https://arxiv.org/pdf/2601.11018", "abs": "https://arxiv.org/abs/2601.11018", "authors": ["Badhan Mazumder", "Lei Wu", "Sir-Lord Wiafe", "Vince D. Calhoun", "Dong Hye Ye"], "title": "KOCOBrain: Kuramoto-Guided Graph Network for Uncovering Structure-Function Coupling in Adolescent Prenatal Drug Exposure", "categories": ["q-bio.NC", "cs.CV"], "comment": "Preprint version of the paper accepted to the IEEE International Symposium on Biomedical Imaging (ISBI 2026). This is the author's accepted manuscript. The final published version will appear in IEEE Xplore", "summary": "Exposure to psychoactive substances during pregnancy, such as cannabis, can disrupt neurodevelopment and alter large-scale brain networks, yet identifying their neural signatures remains challenging. We introduced KOCOBrain: KuramotO COupled Brain Graph Network; a unified graph neural network framework that integrates structural and functional connectomes via Kuramoto-based phase dynamics and cognition-aware attention. The Kuramoto layer models neural synchronization over anatomical connections, generating phase-informed embeddings that capture structure-function coupling, while cognitive scores modulate information routing in a subject-specific manner followed by a joint objective enhancing robustness under class imbalance scenario. Applied to the ABCD cohort, KOCOBrain improved prenatal drug exposure prediction over relevant baselines and revealed interpretable structure-function patterns that reflect disrupted brain network coordination associated with early exposure.", "AI": {"tldr": "介绍KOCOBrain框架，用于识别青少年早期药物暴露对大脑结构功能耦合的影响。", "motivation": "旨在解决孕期接触致幻物质如大麻对神经发育的负面影响及如何识别其神经特征这一挑战性问题。", "method": "引入KOCOBrain：一个结合了基于库拉莫托相位动力学和认知感知注意力机制的统一图神经网络框架，用于整合结构和功能连接组，并通过认知得分调节信息路由。", "result": "应用于ABCD队列数据中，KOCOBrain在预测产前药物暴露方面优于相关基线方法，并揭示了与早期暴露相关的脑网协调受损可解释模式。", "conclusion": "展示了KOCOBrain框架的有效性及其对识别产前药物暴露神经特征的重要性。"}}
{"id": "2601.11016", "pdf": "https://arxiv.org/pdf/2601.11016", "abs": "https://arxiv.org/abs/2601.11016", "authors": ["Fenglin Zhang", "Jie Wang"], "title": "Contextual Distributionally Robust Optimization with Causal and Continuous Structure: An Interpretable and Tractable Approach", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC"], "comment": null, "summary": "In this paper, we introduce a framework for contextual distributionally robust optimization (DRO) that considers the causal and continuous structure of the underlying distribution by developing interpretable and tractable decision rules that prescribe decisions using covariates. We first introduce the causal Sinkhorn discrepancy (CSD), an entropy-regularized causal Wasserstein distance that encourages continuous transport plans while preserving the causal consistency. We then formulate a contextual DRO model with a CSD-based ambiguity set, termed Causal Sinkhorn DRO (Causal-SDRO), and derive its strong dual reformulation where the worst-case distribution is characterized as a mixture of Gibbs distributions. To solve the corresponding infinite-dimensional policy optimization, we propose the Soft Regression Forest (SRF) decision rule, which approximates optimal policies within arbitrary measurable function spaces. The SRF preserves the interpretability of classical decision trees while being fully parametric, differentiable, and Lipschitz smooth, enabling intrinsic interpretation from both global and local perspectives. To solve the Causal-SDRO with parametric decision rules, we develop an efficient stochastic compositional gradient algorithm that converges to an $\\varepsilon$-stationary point at a rate of $O(\\varepsilon^{-4})$, matching the convergence rate of standard stochastic gradient descent. Finally, we validate our method through numerical experiments on synthetic and real-world datasets, demonstrating its superior performance and interpretability.", "AI": {"tldr": "本文提出了一个基于因果和连续结构的上下文分布鲁棒优化框架，并开发了解释性强且易于处理的决策规则。", "motivation": "作者旨在通过考虑底层分布的因果性和连续性，提出一种新的方法来解决现有的分布鲁棒优化问题，以获得更好的解释性和可操作性。", "method": "引入了因果Sinkhorn差异（CSD），并基于此制定了因果Sinkhorn DRO模型。提出了Soft Regression Forest（SRF）决策规则和一个有效的随机组合梯度算法来求解该模型。", "result": "数值实验显示所提出的方法在合成数据集和现实世界的数据集中都表现出优越的性能和解释性。", "conclusion": "通过结合因果推理和分布鲁棒优化，可以得到更优且可解释的结果。"}}
{"id": "2601.11012", "pdf": "https://arxiv.org/pdf/2601.11012", "abs": "https://arxiv.org/abs/2601.11012", "authors": ["Jiahao Wang", "Shuangjia Zheng"], "title": "Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics", "categories": ["cs.AI"], "comment": null, "summary": "The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.", "AI": {"tldr": "本文提出了一种名为HADES的方法，利用基于结构的汉密尔顿动力学进行高效的蛋白质优化。", "motivation": "现有的序列基础优化方法难以处理高维度复杂性和表观遗传效应，并忽视了结构约束。因此，作者希望通过一种新的优化策略来解决这些问题，提高蛋白质变体工程化的能力。", "method": "HADES是一种贝叶斯优化方法，使用汉密尔顿动力学有效地从一个基于结构的近似后验分布中采样。通过引入位置离散化过程提出连续状态系统的离散蛋白序列，并采用两阶段编码解码框架来确定突变邻居之间的结构和功能关系。", "result": "实验结果表明，该方法在多种指标上优于当前最先进的基线方法，在虚拟评估中表现更优。", "conclusion": "通过利用蛋白质结构与序列之间的相互约束，HADES可以有效地设计具有相似结构且优化属性的蛋白序列。"}}
{"id": "2601.11007", "pdf": "https://arxiv.org/pdf/2601.11007", "abs": "https://arxiv.org/abs/2601.11007", "authors": ["Zhenhua Xu", "Dongsheng Chen", "Shuo Wang", "Jian Li", "Chengjie Wang", "Meng Han", "Yabiao Wang"], "title": "AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "LLM role-playing aims to portray arbitrary characters in interactive narratives, yet existing systems often suffer from limited immersion and adaptability. They typically under-model dynamic environmental information and assume largely static scenes and casts, offering insufficient support for multi-character orchestration, scene transitions, and on-the-fly character introduction. We propose an adaptive multi-agent role-playing framework, AdaMARP, featuring an immersive message format that interleaves [Thought], (Action), <Environment>, and Speech, together with an explicit Scene Manager that governs role-playing through discrete actions (init_scene, pick_speaker, switch_scene, add_role, end) accompanied by rationales. To train these capabilities, we construct AdaRPSet for the Actor Model and AdaSMSet for supervising orchestration decisions, and introduce AdaptiveBench for trajectory-level evaluation. Experiments across multiple backbones and model scales demonstrate consistent improvements: AdaRPSet enhances character consistency, environment grounding, and narrative coherence, with an 8B actor outperforming several commercial LLMs, while AdaSMSet enables smoother scene transitions and more natural role introductions, surpassing Claude Sonnet 4.5 using only a 14B LLM.", "AI": {"tldr": "提出了一种自适应的多智能体角色扮演框架AdaMARP，以解决现有系统沉浸感和适应性不足的问题。", "motivation": "现有的LLM角色扮演游戏在动态环境信息建模、场景转换、以及即时角色引入方面存在局限性，导致沉浸感和灵活性较差。", "method": "开发了AdaMARP框架，该框架使用一种包含思维、行动、环境描述和对话的沉浸式消息格式，并配备了一个场景管理器来指导角色扮演游戏中的离散动作决策。", "result": "实验结果显示，与多个商业LLM相比，基于AdaRPSet训练的8B模型在角色一致性、环境关联性和叙事连贯性方面有显著改善；而使用AdaSMSet监督的14B LLM在场景转换和自然引入角色方面的表现超过了Claude Sonnet 4.5。", "conclusion": "该研究表明，通过自适应多智能体框架AdaMARP可以有效提升沉浸式角色扮演体验，并展示了其在多个评估指标上的优越性能。"}}
{"id": "2601.11000", "pdf": "https://arxiv.org/pdf/2601.11000", "abs": "https://arxiv.org/abs/2601.11000", "authors": ["Zhongxiang Sun", "Yi Zhan", "Chenglei Shen", "Weijie Yu", "Xiao Zhang", "Ming He", "Jun Xu"], "title": "When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 15 figures", "summary": "Personalized large language models (LLMs) adapt model behavior to individual users to enhance user satisfaction, yet personalization can inadvertently distort factual reasoning. We show that when personalized LLMs face factual queries, there exists a phenomenon where the model generates answers aligned with a user's prior history rather than the objective truth, resulting in personalization-induced hallucinations that degrade factual reliability and may propagate incorrect beliefs, due to representational entanglement between personalization and factual representations. To address this issue, we propose Factuality-Preserving Personalized Steering (FPPS), a lightweight inference-time approach that mitigates personalization-induced factual distortions while preserving personalized behavior. We further introduce PFQABench, the first benchmark designed to jointly evaluate factual and personalized question answering under personalization. Experiments across multiple LLM backbones and personalization methods show that FPPS substantially improves factual accuracy while maintaining personalized performance.", "AI": {"tldr": "本文探讨了个性化大型语言模型在事实推理中的误导现象，并提出了一种减轻这种现象的方法。", "motivation": "个性化语言模型可能产生与用户历史记录一致但不符合客观事实的答案，从而导致个人化诱导的幻觉并传播错误信息。", "method": "提出了Factuality-Preserving Personalized Steering（FPPS）方法，在减少个性化引发的事实扭曲的同时保留个性化的表现，并引入PFQABench基准测试来评估事实和个人化问答性能。", "result": "实验表明，FPPS显著提高了事实准确性，同时保持了个性化性能。", "conclusion": "通过轻量级推理时间方法FPPS可以有效减轻个性化大型语言模型中的幻觉现象，提高其事实准确性。"}}
{"id": "2601.10970", "pdf": "https://arxiv.org/pdf/2601.10970", "abs": "https://arxiv.org/abs/2601.10970", "authors": ["Canwen Wang", "Angela Chen", "Catherine Bao", "Siwei Jin", "Yee Kit Chan", "Jessica R Mindel", "Sijia Xie", "Holly Swartz", "Tongshuang Wu", "Robert E Kraut", "Haiyi Zhu"], "title": "Modeling Multi-Party Interaction in Couples Therapy: A Multi-Agent Simulation Approach", "categories": ["cs.CY", "cs.HC"], "comment": null, "summary": "Couples therapy, or relationship counseling, helps partners resolve conflicts, improve satisfaction, and foster psychological growth. Traditional approaches to training couples therapists, such as textbooks and roleplay, often fail to capture the complexity and emotional nuance of real couple dynamics. We present a novel multimodal, multi-agent simulation system that models multi-party interactions in couples therapy. Informed by our systematic research, this system creates a low-stakes environment for trainee therapists to gain valuable practical experience dealing with the critical demand-withdraw communication cycle across six couple-interaction stages. In an evaluation study involving 21 US-based licensed therapists, participants blind to conditions identified the engineered agent behaviors (i.e., the stages and the demand-withdraw cycle) and rated overall realism and agent responses higher for the experimental system than the baseline. As the first known multi-agent framework for training couples therapists, our work builds the foundation for future research that fuses HCI technologies with couples therapy.", "AI": {"tldr": "本文提出了一种多智能体模拟系统，用于训练夫妻治疗师处理需求撤退沟通循环和六个互动阶段的复杂情况。", "motivation": "传统的夫妻治疗培训方法难以捕捉真实夫妇互动的复杂性和情感细微差别，因此需要一种新的方法来帮助新手治疗师获得宝贵的实践经验。", "method": "通过系统的研究，本文构建了一个新型多模态、多智能体模拟系统，以模拟夫妻治疗中的多方交互，并在六个互动阶段中处理需求撤退沟通循环的问题。", "result": "一项包含21名美国持证治疗师的评估研究表明，参与者对实验系统的整体真实性和代理人反应给出了更高的评价。", "conclusion": "作为首个用于训练夫妻治疗师的多智能体框架，本研究为将人机交互技术与夫妻治疗融合的研究奠定了基础。"}}
{"id": "2601.10964", "pdf": "https://arxiv.org/pdf/2601.10964", "abs": "https://arxiv.org/abs/2601.10964", "authors": ["Nicholas J. C. Papadopoulos", "Ramin Ayanzadeh"], "title": "Stabilizer Code-Generic Universal Fault-Tolerant Quantum Computation", "categories": ["quant-ph", "cs.DS"], "comment": "34 pages, 6 figures, 7 tables", "summary": "Fault-tolerant quantum computation allows quantum computations to be carried out while resisting unwanted noise. Several error correcting codes have been developed to achieve this task, but none alone are capable of universal quantum computation. This universality is highly desired and often achieved using additional techniques such as code concatenation, code switching, or magic state distillation, which can be costly and only work for specific codes. This work implements logical Clifford and T gates through novel ancilla-mediated protocols to construct a universal fault-tolerant quantum gate set. Unlike traditional techniques, our implementation is deterministic, does not consume ancilla registers, does not modify the underlying data codes or registers, and is generic over all stabilizer codes. Thus, any single code becomes capable of universal quantum computation by leveraging helper codes in ancilla registers and mid-circuit measurements. Furthermore, since these logical gates are stabilizer code-generic, these implementations enable communication between heterogeneous stabilizer codes. These features collectively open the door to countless possibilities for existing and undiscovered codes as well as their scalable, heterogeneous coexistence.", "AI": {"tldr": "实现通用的容错量子计算，通过使用新颖的辅助寄存器介导协议来构建逻辑Clifford和T门。", "motivation": "现有的错误纠正码无法单独实现通用量子计算，通常需要额外的技术如代码级联、代码切换或魔术状态蒸馏，这些方法成本高且仅适用于特定编码。因此，寻求一种更高效、可广泛使用的解决方案成为动机。", "method": "通过新颖的辅助寄存器介导协议来实施逻辑Clifford和T门，该实现是确定性的，不消耗辅助寄存器，不会修改底层数据码或寄存器，并且适用于所有稳定子码。", "result": "任何单一代码借助辅助编码在辅助寄存器中并结合中途电路测量成为能够进行通用量子计算的代码，这为现有和未发现的代码提供了无数可能性以及它们可扩展的异构共存。", "conclusion": "这种方法不仅实现了逻辑门操作的确定性执行，而且促进了稳定子码之间的通信，开启了大量编码及其可扩展、异构共存的可能性。"}}
{"id": "2601.10960", "pdf": "https://arxiv.org/pdf/2601.10960", "abs": "https://arxiv.org/abs/2601.10960", "authors": ["Hyeseon An", "Shinwoo Park", "Hyundong Jin", "Yo-Sub Han"], "title": "Steering Language Models Before They Speak: Logit-Level Interventions", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages, 5 figures, preprint", "summary": "Steering LLMs is essential for specialized applications such as style-sensitive text rewriting, user-adaptive communication, and toxicity mitigation. Current steering methods, such as prompting-based and activation-based approaches, are widely used to guide model behavior. However, activation-based techniques require deep access to internal layers, while prompting-based steering often fails to provide consistent or fine-grained control. In order to address these limitations, we propose a training-free inference-time logit intervention for controllable generation. Our approach utilizes a statistical token score table derived from z-normalized log-odds of labeled corpora to shift the decoding distribution. Empirical evaluations across three diverse datasets focusing on writing complexity, formality, and toxicity demonstrate that our method effectively steers output characteristics, confirming its broad applicability and task-agnostic nature. Our results show that statistically grounded logit steering can achieve large, consistent, and multi-task control gains: up to +47%p accuracy and 50x f1 improvement.", "AI": {"tldr": "本文提出了一种在推理时进行无训练的logit级别干预方法，用于可控制文本生成。", "motivation": "当前的语言模型引导技术存在局限性，如激活基础的技术需要深度访问内部层，而提示基础的方法往往无法提供一致或精细的控制，因此本文旨在解决这些问题。", "method": "使用从标签语料库中得出的z标准化log-odds统计token得分表来调整解码分布。", "result": "在复杂性、正式性和毒性三个不同数据集上的实验结果表明，该方法可以有效引导输出特性，并显示出高达+47%p的准确率和50倍的F1值提升。", "conclusion": "基于统计学的logit引导可以在多种任务上实现大范围、一致且多任务控制增益。"}}
{"id": "2601.10957", "pdf": "https://arxiv.org/pdf/2601.10957", "abs": "https://arxiv.org/abs/2601.10957", "authors": ["Yao Lyu", "Jessica Shen", "Alina Faisal", "John M. Carroll"], "title": "\"I'm Constantly Getting Comments Like, 'Oh, You're Blind. You're Like the Only Woman That I Stand a Chance With.'\": A Study of Blind TikTokers' Intersectional Experiences of Gender and Sexuality", "categories": ["cs.HC"], "comment": "Accepted to CHI'26", "summary": "Social media platforms are important venues for identity expression, and the Human-Computer Interaction community has been paying growing attention to how marginalized groups express their identities on these platforms. Joining the emerging literature on intersectional experiences, we study blind TikTokers (\"BlindTokers\") who are also women and/or LGBTQ+. Using interview data from \\rev{41} participants, we identify their intersectional experiences as mediated by TikTok's socio-technical affordances. We argue that BlindTokers' intersectional marginalization is infrastructural: TikTok's classification and moderation features interact with social norms in ways that push them aside and distort how they are treated on the platform. We use this infrastructure perspective to understand what these experiences are, how they were formed, and how they become harmful. We further recognize participants' infrastructuring work to address these problems. This study guides future social media design with accessible creator tools, inclusive identity options, and context-aware moderation developed in partnership with communities.", "AI": {"tldr": "研究探讨了盲人TikTok用户（特别是女性和/或LGBTQ+群体）的交叉身份体验，并分析这些体验如何受到平台的技术和社会规范的影响。", "motivation": "社会媒体是表达个人身份的重要场所，该论文旨在探究边缘化群体在社交平台上是如何表现自我身份，特别关注盲人TikTok用户（BlindTokers）的交叉性别和性向经历。", "method": "通过访谈41名参与者，研究者探讨了这些盲人TikTokers的交叉身份体验如何受到TikTok的技术和社会规范影响，并分析背后的原因。", "result": "研究发现TikTok的分类与管理功能与社会准则相互作用，导致BlindTokers被边缘化并扭曲他们在平台上的待遇。参与者也展示了他们为了应对这些问题所进行的努力。", "conclusion": "该研究为未来的社交媒体设计提供了指导，强调在开发可访问的创作工具、包容性的身份选项和上下文感知的管理机制时需与社区合作。"}}
{"id": "2601.10956", "pdf": "https://arxiv.org/pdf/2601.10956", "abs": "https://arxiv.org/abs/2601.10956", "authors": ["Yao Lyu", "Tawanna Dillahunt", "Jiaying Liu", "John M. Carroll"], "title": "\"My Brother Is a School Principal, Earns About $80,000 Per Year... But When the Kids See Me, 'Wow, Uncle, You Have 1500 Followers on TikTok!'\": A Study of Blind TikTokers' Alternative Professional Development Experiences", "categories": ["cs.HC"], "comment": "Accepted to CHI'26", "summary": "One's profession is an essential part of modern life. Traditionally, professional development has been criticized for excluding people with disabilities. People with visual impairments, for example, face disproportionately low employment rates, highlighting persistent gaps in professional opportunities. Recently, there has been growing research on social media platforms as spaces for more equitable career development approaches. In this paper, we present an interview study on the professional development experiences of 60 people with visual impairments on TikTok (also known as \"BlindTokers\"). We report BlindTokers' goals, strategies, and challenges, supported by detailed examples and in-depth analysis. Based on the findings, we identify that BlindTokers' practices reveal an alternative professional development approach that is more flexible, inclusive, personalized, and diversified than traditional models. Our study also extends professional development research by foregrounding emerging digital skills and proposing design implications to foster more equitable and inclusive professional opportunities.", "AI": {"tldr": "研究了60位视障人士在TikTok上的职业发展经历，揭示了一种更灵活、包容和个性化的替代发展模式。", "motivation": "传统的职业发展方式往往排除残疾人，尤其对视力障碍者而言，就业率低，表明专业机会存在差距。本研究旨在探讨社交媒体平台作为更为公平的职业发展途径的可能性。", "method": "通过访谈60位视障人士（BlindTokers），报告了他们在TikTok上的职业发展目标、策略和挑战，并进行了详细分析。", "result": "发现BlindTokers的做法揭示了一种更加灵活、包容、个性化和多样化的替代职业发展模式，提出了设计建议以促进更公平和包容的职业机会。", "conclusion": "研究结果表明社交媒体平台如TikTok为视障人士提供了不同于传统模式的替代职业发展途径，强调了新兴数字技能的重要性，并提出设计改进措施，有助于构建更加公平和包容的专业环境。"}}
{"id": "2601.10955", "pdf": "https://arxiv.org/pdf/2601.10955", "abs": "https://arxiv.org/abs/2601.10955", "authors": ["Kaiyu Zhou", "Yongsen Zheng", "Yicheng He", "Meng Xue", "Xueluan Gong", "Yuji Wang", "Kwok-Yan Lam"], "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents. Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm. They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions. We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task. Our method adjusts text-visible fields and a template-governed return policy in a benign, Model Context Protocol (MCP)-compatible tool server, optimizing these edits with a Monte Carlo Tree Search (MCTS) optimizer. These adjustments leave function signatures unchanged and preserve the final payload, steering the agent into prolonged, verbose tool-calling sequences using text-only notices. This compounds costs across turns, escaping single-turn caps while keeping the final answer correct to evade validation. Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658x, and raises energy by 100-560x. It drives GPU KV cache occupancy from <1% to 35-74% and cuts co-running throughput by approximately 50%. Because the server remains protocol-compatible and task outcomes are correct, conventional checks fail. These results elevate the agent-tool interface to a first-class security frontier, demanding a paradigm shift from validating final answers to monitoring the economic and computational cost of the entire agentic process.", "AI": {"tldr": "本文提出了一种通过调整工具链中的文本可见字段和返回策略，在大型语言模型（LLM）代理中实现隐蔽的资源放大攻击的方法。", "motivation": "现有的拒绝服务攻击方法在现代LLM代理的新范式下效果不佳，因为这些方法通常是单轮的并且缺乏任务导向性，无法利用多轮次代理工具交互的成本累积效应。", "method": "本文提出的方法通过调整文本可见字段和由模板控制的返回策略，在一个兼容模型上下文协议（MCP）的工具服务器中优化编辑内容。这些调整保持函数签名不变并保留最终的有效负载，使用蒙特卡罗树搜索（MCTS）优化器引导代理进入冗长的工具调用序列。", "result": "在ToolBench和BFCL基准测试上对六个LLM进行测试时，本文的方法将任务扩展为超过60,000个令牌的轨迹，成本膨胀高达658倍，能耗增加100-560倍。它驱动GPU KV缓存占用率从<1%提升至35-74%，并将并行吞吐量降低约50%。", "conclusion": "由于服务器保持协议兼容且任务结果是正确的，传统的验证检查无法检测到这种攻击，这将代理工具接口提升为一个重要的安全前沿，要求从验证最终答案转向监测整个代理过程的经济和计算成本。"}}
{"id": "2601.10951", "pdf": "https://arxiv.org/pdf/2601.10951", "abs": "https://arxiv.org/abs/2601.10951", "authors": ["Shijie Jiang", "Zefan Zhang", "Kehua Zhu", "Tian Bai", "Ruihong Zhao"], "title": "Multi-Stage Patient Role-Playing Framework for Realistic Clinical Interactions", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 5figures, under review", "summary": "The simulation of realistic clinical interactions plays a pivotal role in advancing clinical Large Language Models (LLMs) and supporting medical diagnostic education. Existing approaches and benchmarks rely on generic or LLM-generated dialogue data, which limits the authenticity and diversity of doctor-patient interactions. In this work, we propose the first Chinese patient simulation dataset (Ch-PatientSim), constructed from realistic clinical interaction scenarios to comprehensively evaluate the performance of models in emulating patient behavior. Patients are simulated based on a five-dimensional persona structure. To address issues of the persona class imbalance, a portion of the dataset is augmented using few-shot generation, followed by manual verification. We evaluate various state-of-the-art LLMs and find that most produce overly formal responses that lack individual personality. To address this limitation, we propose a training-free Multi-Stage Patient Role-Playing (MSPRP) framework, which decomposes interactions into three stages to ensure both personalization and realism in model responses. Experimental results demonstrate that our approach significantly improves model performance across multiple dimensions of patient simulation.", "AI": {"tldr": "本文提出了一个多阶段患者角色扮演框架（MSPRP），以改进中文临床对话模型中模拟真实患者行为的能力。", "motivation": "现有的方法和基准依赖于通用或LLM生成的对话数据，这限制了医生-病人互动的真实性和多样性。为了克服这些限制并提高语言模型在模拟患者行为方面的表现，提出了新的框架。", "method": "构建了一个基于真实临床情境的中文患者模拟数据集（Ch-PatientSim），使用五维人物结构来模拟患者，并提出了一种无训练的多阶段患者角色扮演框架（MSPRP）以确保个性化和真实性。", "result": "实验结果显示，该方法显著提高了模型在多个维度上模拟患者的性能。", "conclusion": "通过使用多阶段患者角色扮演框架（MSPRP），可以有效改进现有大型语言模型在临床对话中的表现，增强其个性化和现实性。"}}
{"id": "2601.10949", "pdf": "https://arxiv.org/pdf/2601.10949", "abs": "https://arxiv.org/abs/2601.10949", "authors": ["Meidan Ding", "Jipeng Zhang", "Wenxuan Wang", "Haiqin Zhong", "Xiaoling Luo", "Wenting Chen", "Linlin Shen"], "title": "MMedExpert-R1: Strengthening Multimodal Medical Reasoning via Domain-Specific Adaptation and Clinical Guideline Reinforcement", "categories": ["cs.CV"], "comment": null, "summary": "Medical Vision-Language Models (MedVLMs) excel at perception tasks but struggle with complex clinical reasoning required in real-world scenarios. While reinforcement learning (RL) has been explored to enhance reasoning capabilities, existing approaches face critical mismatches: the scarcity of deep reasoning data, cold-start limits multi-specialty alignment, and standard RL algorithms fail to model clinical reasoning diversity. We propose MMedExpert-R1, a novel reasoning MedVLM that addresses these challenges through domain-specific adaptation and clinical guideline reinforcement. We construct MMedExpert, a high-quality dataset of 10K samples across four specialties with step-by-step reasoning traces. Our Domain-Specific Adaptation (DSA) creates specialty-specific LoRA modules to provide diverse initialization, while Guideline-Based Advantages (GBA) explicitly models different clinical reasoning perspectives to align with real-world diagnostic strategies. Conflict-Aware Capability Integration then merges these specialized experts into a unified agent, ensuring robust multi-specialty alignment. Comprehensive experiments demonstrate state-of-the-art performance, with our 7B model achieving 27.50 on MedXpert-MM and 83.03 on OmniMedVQA, establishing a robust foundation for reliable multimodal medical reasoning systems.", "AI": {"tldr": "本文提出MMedExpert-R1，通过领域特定适应和临床指南强化来加强多模态医疗推理。", "motivation": "现有的医疗视觉语言模型在复杂的临床推理方面表现不佳，主要问题是缺乏深度推理数据、冷启动问题以及标准的强化学习算法无法模拟临床推理多样性。", "method": "提出MMedExpert-R1方法，包括构建一个包含10K样本的高质量多专科数据集，通过领域特定适应创建专科LoRA模块，并利用指南优势显式建模不同的临床推理视角。最后，冲突感知能力集成将这些专有专家合并为统一代理。", "result": "实验结果表明该模型达到了最先进的性能，7B型号在MedXpert-MM和OmniMedVQA上的得分分别为27.50和83.03。", "conclusion": "MMedExpert-R1为可靠多模态医疗推理系统奠定了坚实基础。"}}
{"id": "2601.10945", "pdf": "https://arxiv.org/pdf/2601.10945", "abs": "https://arxiv.org/abs/2601.10945", "authors": ["K Lokesh", "Abhirama Subramanyam Penamakuri", "Uday Agarwal", "Apoorva Challa", "Shreya K Gowda", "Somesh Gupta", "Anand Mishra"], "title": "PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted at AAAI 2026 Main Track", "summary": "Traditionally, AI research in medical diagnosis has largely centered on image analysis. While this has led to notable advancements, the absence of patient-reported symptoms continues to hinder diagnostic accuracy. To address this, we propose a Pre-Consultation Dialogue Framework (PCDF) that mimics real-world diagnostic procedures, where doctors iteratively query patients before reaching a conclusion. Specifically, we simulate diagnostic dialogues between two vision-language models (VLMs): a DocVLM, which generates follow-up questions based on the image and dialogue history, and a PatientVLM, which responds using a symptom profile derived from the ground-truth diagnosis. We additionally conducted a small-scale clinical validation of the synthetic symptoms generated by our framework, with licensed clinicians confirming their clinical relevance, symptom coverage, and overall realism. These findings indicate that the resulting DocVLM-PatientVLM interactions form coherent, multi-turn consultations paired with images and diagnoses, which we then use to fine-tune the DocVLM. This dialogue-based supervision leads to substantial gains over image-only training, highlighting the value of realistic symptom elicitation for diagnosis.", "AI": {"tldr": "提出了一种预诊对话框架（PCDF），通过模拟医生与病人的多轮对话来提高诊断准确性。", "motivation": "传统的医疗诊断AI研究主要集中在图像分析上，忽视了病人报告的症状，这限制了诊断的准确性。为了改善这一状况，本文提出了一个新的方法。", "method": "该框架使用两个视觉语言模型（VLMs），一个是医生模型（DocVLM），根据图像和对话历史生成跟进问题；另一个是患者模型（PatientVLM），基于真实诊断的症状资料进行回答。", "result": "通过小型临床验证，证实了由框架生成的模拟症状具有临床相关性、全面性和真实性。与仅使用图像训练相比，这种对话监督显著提高了诊断性能。", "conclusion": "本文证明了预诊对话框架在提高医疗诊断准确性方面的有效性，并强调了真实症状提取的重要性。"}}
{"id": "2601.10936", "pdf": "https://arxiv.org/pdf/2601.10936", "abs": "https://arxiv.org/abs/2601.10936", "authors": ["Piyush Maheshwari", "Sheshera Mysore", "Hamed Zamani"], "title": "Can Instructed Retrieval Models Really Support Exploration?", "categories": ["cs.IR", "cs.HC"], "comment": null, "summary": "Exploratory searches are characterized by under-specified goals and evolving query intents. In such scenarios, retrieval models that can capture user-specified nuances in query intent and adapt results accordingly are desirable -- instruction-following retrieval models promise such a capability. In this work, we evaluate instructed retrievers for the prevalent yet under-explored application of aspect-conditional seed-guided exploration using an expert-annotated test collection. We evaluate both recent LLMs fine-tuned for instructed retrieval and general-purpose LLMs prompted for ranking with the highly performant Pairwise Ranking Prompting. We find that the best instructed retrievers improve on ranking relevance compared to instruction-agnostic approaches. However, we also find that instruction following performance, crucial to the user experience of interacting with models, does not mirror ranking relevance improvements and displays insensitivity or counter-intuitive behavior to instructions. Our results indicate that while users may benefit from using current instructed retrievers over instruction-agnostic models, they may not benefit from using them for long-running exploratory sessions requiring greater sensitivity to instructions.", "AI": {"tldr": "本文评估了指示检索模型在条件方面的种子引导探索中的性能，并与无指令的模型进行了比较。", "motivation": "探索性搜索通常涉及未明确的目标和不断变化的查询意图，因此需要能够捕捉用户指定细微差别的检索模型。", "method": "使用专家注释的数据集评估了经过微调以执行指示检索的最新LLM以及用于排名的一般用途LLM，并应用高性能成对排名提示。", "result": "最好的指示检索器在相关性排序上优于无指令的方法，但在遵循用户指令方面表现不佳。", "conclusion": "尽管当前的指示检索模型相比无指令模型可能为用户提供更好的体验，但它们不适合需要更高指令敏感性的长时间探索会话。"}}
{"id": "2601.10931", "pdf": "https://arxiv.org/pdf/2601.10931", "abs": "https://arxiv.org/abs/2601.10931", "authors": ["David Szczecina", "Hudson Sun", "Anthony Bertnyk", "Niloofar Azad", "Kyle Gao", "Lincoln Linlin Xu"], "title": "Sparse Data Tree Canopy Segmentation: Fine-Tuning Leading Pretrained Models on Only 150 Images", "categories": ["cs.CV", "cs.AI"], "comment": "4 pages, 2 figures", "summary": "Tree canopy detection from aerial imagery is an important task for environmental monitoring, urban planning, and ecosystem analysis. Simulating real-life data annotation scarcity, the Solafune Tree Canopy Detection competition provides a small and imbalanced dataset of only 150 annotated images, posing significant challenges for training deep models without severe overfitting. In this work, we evaluate five representative architectures, YOLOv11, Mask R-CNN, DeepLabv3, Swin-UNet, and DINOv2, to assess their suitability for canopy segmentation under extreme data scarcity. Our experiments show that pretrained convolution-based models, particularly YOLOv11 and Mask R-CNN, generalize significantly better than pretrained transformer-based models. DeeplabV3, Swin-UNet and DINOv2 underperform likely due to differences between semantic and instance segmentation tasks, the high data requirements of Vision Transformers, and the lack of strong inductive biases. These findings confirm that transformer-based architectures struggle in low-data regimes without substantial pretraining or augmentation and that differences between semantic and instance segmentation further affect model performance. We provide a detailed analysis of training strategies, augmentation policies, and model behavior under the small-data constraint and demonstrate that lightweight CNN-based methods remain the most reliable for canopy detection on limited imagery.", "AI": {"tldr": "评估五种代表性模型在仅使用150张图像的情况下进行树冠分割的效果。", "motivation": "研究在数据稀缺情况下如何有效训练深度学习模型以检测树冠，这对于环境监测、城市规划和生态系统分析至关重要。", "method": "对比了YOLOv11, Mask R-CNN, DeepLabv3, Swin-UNet 和 DINOv2 这五种预训练模型在处理树冠分割任务上的表现。", "result": "实验表明，基于卷积的预训练模型如YOLOv11和Mask R-CNN比基于Transformer的模型表现更好。DeepLabV3, Swin-UNet 和 DINOv2 表现较差，可能是因为语义分割与实例分割任务差异、视觉变压器的数据需求以及缺乏强归纳偏置。", "conclusion": "证实了在数据稀缺的情况下，轻量级CNN模型比Transformer架构更可靠，并提供了详细的训练策略和增强政策分析。"}}
{"id": "2601.10930", "pdf": "https://arxiv.org/pdf/2601.10930", "abs": "https://arxiv.org/abs/2601.10930", "authors": ["Zhixian Xie", "Yu Xiang", "Michael Posa", "Wanxin Jin"], "title": "Where to Touch, How to Contact: Hierarchical RL-MPC Framework for Geometry-Aware Long-Horizon Dexterous Manipulation", "categories": ["cs.RO"], "comment": "13 Pages, Plan to submit RSS", "summary": "A key challenge in contact-rich dexterous manipulation is the need to jointly reason over geometry, kinematic constraints, and intricate, nonsmooth contact dynamics. End-to-end visuomotor policies bypass this structure, but often require large amounts of data, transfer poorly from simulation to reality, and generalize weakly across tasks/embodiments. We address those limitations by leveraging a simple insight: dexterous manipulation is inherently hierarchical - at a high level, a robot decides where to touch (geometry) and move the object (kinematics); at a low level it determines how to realize that plan through contact dynamics. Building on this insight, we propose a hierarchical RL--MPC framework in which a high-level reinforcement learning (RL) policy predicts a contact intention, a novel object-centric interface that specifies (i) an object-surface contact location and (ii) a post-contact object-level subgoal pose. Conditioned on this contact intention, a low-level contact-implicit model predictive control (MPC) optimizes local contact modes and replans with contact dynamics to generate robot actions that robustly drive the object toward each subgoal. We evaluate the framework on non-prehensile tasks, including geometry-generalized pushing and object 3D reorientation. It achieves near-100% success with substantially reduced data (10x less than end-to-end baselines), highly robust performance, and zero-shot sim-to-real transfer.", "AI": {"tldr": "本文提出了一种分层RL-MPC框架，用于解决复杂接触下的长时间跨度的灵巧操作问题。", "motivation": "传统的端到端视觉运动策略需要大量数据，并且在从模拟环境转移到现实世界时表现不佳。本文旨在减少所需的数据量并提高性能稳定性。", "method": "提出了一个分层RL-MPC框架，其中高层次策略决定接触位置和目标位姿，低层次策略优化局部接触模式并根据这些信息生成机器人动作。", "result": "该框架在几何推广的推物和物体3D重新定向任务中取得了接近100%的成功率，并且所需数据量比端到端基线减少了10倍，实现了零样本模拟到现实世界的转移。", "conclusion": "分层RL-MPC框架有效解决了灵巧操作中的复杂接触问题，提高了性能并显著降低了训练所需的数据量。"}}
{"id": "2601.10926", "pdf": "https://arxiv.org/pdf/2601.10926", "abs": "https://arxiv.org/abs/2601.10926", "authors": ["Dustin S. Stoltz", "Marshall A. Taylor", "Sanuj Kumar"], "title": "Selecting Language Models for Social Science: Start Small, Start Open, and Validate", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Currently, there are thousands of large pretrained language models (LLMs) available to social scientists. How do we select among them? Using validity, reliability, reproducibility, and replicability as guides, we explore the significance of: (1) model openness, (2) model footprint, (3) training data, and (4) model architectures and fine-tuning. While ex-ante tests of validity (i.e., benchmarks) are often privileged in these discussions, we argue that social scientists cannot altogether avoid validating computational measures (ex-post). Replicability, in particular, is a more pressing guide for selecting language models. Being able to reliably replicate a particular finding that entails the use of a language model necessitates reliably reproducing a task. To this end, we propose starting with smaller, open models, and constructing delimited benchmarks to demonstrate the validity of the entire computational pipeline.", "AI": {"tldr": "本文探讨了社会科学家在选择语言模型时应考虑的关键因素，包括模型的开放性、规模、训练数据和架构，并提出从小型开源模型开始并构建有限的基准以证明计算管道的有效性的建议。", "motivation": "由于可用的大规模预训练语言模型众多，如何选择合适的模型成为社会科学家面临的问题。本文旨在通过有效性、可靠性、可重复性和可复制性作为指导，帮助他们做出明智的选择。", "method": "文章采用探讨和分析的方式讨论了开放性、模型尺寸、训练数据集以及模型架构和微调的重要性，并强调了验证计算度量的必要性。", "result": "作者提出了优先考虑小型开源语言模型并构建有限基准以展示整个计算管道有效性的建议，强调可复制性的紧迫性。", "conclusion": "本文结论是社会科学家在选择语言模型时应从小型开源模型开始，并通过验证计算度量来确保研究结果的有效性和可靠性。"}}
{"id": "2601.10923", "pdf": "https://arxiv.org/pdf/2601.10923", "abs": "https://arxiv.org/abs/2601.10923", "authors": ["Haoze Guo", "Ziqi Wei"], "title": "Hidden-in-Plain-Text: A Benchmark for Social-Web Indirect Prompt Injection in RAG", "categories": ["cs.CR", "cs.HC"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems put more and more emphasis on grounding their responses in user-generated content found on the Web, amplifying both their usefulness and their attack surface. Most notably, indirect prompt injection and retrieval poisoning attack the web-native carriers that survive ingestion pipelines and are very concerning. We provide OpenRAG-Soc, a compact, reproducible benchmark-and-harness for web-facing RAG evaluation under these threats, in a discrete data package. The suite combines a social corpus with interchangeable sparse and dense retrievers and deployable mitigations - HTML/Markdown sanitization, Unicode normalization, and attribution-gated answered. It standardizes end-to-end evaluation from ingestion to generation and reports attacks time of one of the responses at answer time, rank shifts in both sparse and dense retrievers, utility and latency, allowing for apples-to-apples comparisons across carriers and defenses. OpenRAG-Soc targets practitioners who need fast, and realistic tests to track risk and harden deployments.", "AI": {"tldr": "本文介绍了OpenRAG-Soc，一个用于评估网络面向的检索增强生成（RAG）系统间接提示注入和检索中毒攻击威胁的小型、可重复基准测试工具包。", "motivation": "随着RAG系统的日益重视从网络用户内容中获取信息来改进其响应能力，这类系统也面临着间接提示注入和检索中毒等网络安全威胁的挑战。本文旨在提供一个简洁且易于重现的评估框架以帮助从业者识别并减少这些威胁带来的风险。", "method": "OpenRAG-Soc结合了社会语料库以及可互换的稀疏与密集检索器，并引入了一系列部署防御措施如HTML/Markdown净化、Unicode规范化和引用门控响应。它提供了一个从数据摄入到生成阶段的端到端评估标准，能够报告攻击时间点上的回答时间、在稀疏和密集检索器中的排名变化以及效用和延迟。", "result": "OpenRAG-Soc为从业者提供了快速且现实的测试方法来追踪风险并强化部署，通过标准化的端到端评价框架实现了对各种载体和防御措施之间的公平比较。", "conclusion": "该基准测试工具包为评估网络面向RAG系统的安全威胁提供了一个全面、实用的方法，帮助提高其抵御间接提示注入和检索中毒攻击的能力。"}}
{"id": "2601.10922", "pdf": "https://arxiv.org/pdf/2601.10922", "abs": "https://arxiv.org/abs/2601.10922", "authors": ["Yosub Shin", "Michael Buriek", "Boris Sobolev", "Pavel Bushuyeu", "Vikas Kumar", "Haoyang Xu", "Samuel Watson", "Igor Molybog"], "title": "What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge", "categories": ["cs.AI"], "comment": null, "summary": "We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.", "AI": {"tldr": "研究数据整理对多模态推理的影响，通过NeurIPS 2025 数据整理视觉语言推理（DCVLR）挑战赛来探讨这个问题。", "motivation": "了解在固定模型和训练协议下，数据集的选择如何影响多模态推理性能，并探索不同类型的数据整理策略的有效性。", "method": "使用一个主要来自Walton 多模态冷启动的精简整理后的数据集，在DCVLR挑战赛中进行实验，通过赛后消融研究评估不同数据整理方法的影响。", "result": "基于难度的例子选择是性能提升的主要驱动因素。增加数据集大小并不会可靠地提高平均准确率，但能减少运行间的方差，常见的多样性和合成增强策略并无额外益处且常导致性能下降。", "conclusion": "DCVLR挑战赛表明在固定训练协议下，数据整理进入饱和状态评估，强调了对齐和难度在高效利用数据进行多模态推理中的核心作用。"}}
{"id": "2601.10921", "pdf": "https://arxiv.org/pdf/2601.10921", "abs": "https://arxiv.org/abs/2601.10921", "authors": ["Tasneem Shaffee", "Sherief Reda"], "title": "RobuMTL: Enhancing Multi-Task Learning Robustness Against Weather Conditions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026", "summary": "Robust Multi-Task Learning (MTL) is crucial for autonomous systems operating in real-world environments, where adverse weather conditions can severely degrade model performance and reliability. In this paper, we introduce RobuMTL, a novel architecture designed to adaptively address visual degradation by dynamically selecting task-specific hierarchical Low-Rank Adaptation (LoRA) modules and a LoRA expert squad based on input perturbations in a mixture-of-experts fashion. Our framework enables adaptive specialization based on input characteristics, improving robustness across diverse real-world conditions. To validate our approach, we evaluated it on the PASCAL and NYUD-v2 datasets and compared it against single-task models, standard MTL baselines, and state-of-the-art methods. On the PASCAL benchmark, RobuMTL delivers a +2.8% average relative improvement under single perturbations and up to +44.4% under mixed weather conditions compared to the MTL baseline. On NYUD-v2, RobuMTL achieves a +9.7% average relative improvement across tasks. The code is available at GitHub.", "AI": {"tldr": "本文介绍了RobuMTL，一种新型架构，旨在通过动态选择任务特定的层次低秩适应模块和专家队列来增强多任务学习在恶劣天气条件下的鲁棒性。", "motivation": "恶劣天气条件下模型性能会严重下降，因此需要一个能有效应对各种环境变化的鲁棒多任务学习框架。", "method": "RobuMTL采用输入扰动动态选择任务特定的层次低秩适应（LoRA）模块和专家团队，在混合专家方式下增强对输入特征的自适应专业化处理。", "result": "在PASCAL数据集上，RobuMTL相比多任务学习基准模型提高了+2.8%的相对平均改进率，并且在混合天气条件下提升达到+44.4%；在NYUD-v2上实现了所有任务中+9.7%的相对平均改进。", "conclusion": "实验结果表明，RobuMTL通过自适应选择最适合输入条件的模型结构，显著提升了多任务学习框架在恶劣环境下的鲁棒性和性能。"}}
{"id": "2601.10917", "pdf": "https://arxiv.org/pdf/2601.10917", "abs": "https://arxiv.org/abs/2601.10917", "authors": ["Pouya Afshin", "David Helminiak", "Tianling Niu", "Julie M. Jorns", "Tina Yen", "Bing Yu", "Dong Hye Ye"], "title": "Self-learned representation-guided latent diffusion model for breast cancer classification in deep ultraviolet whole surface images", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "This paper has been accepted for the IEEE International Symposium on Biomedical Imaging (ISBI) 2026, London, UK, and will be presented in the corresponding session", "summary": "Breast-Conserving Surgery (BCS) requires precise intraoperative margin assessment to preserve healthy tissue. Deep Ultraviolet Fluorescence Scanning Microscopy (DUV-FSM) offers rapid, high-resolution surface imaging for this purpose; however, the scarcity of annotated DUV data hinders the training of robust deep learning models. To address this, we propose an Self-Supervised Learning (SSL)-guided Latent Diffusion Model (LDM) to generate high-quality synthetic training patches. By guiding the LDM with embeddings from a fine-tuned DINO teacher, we inject rich semantic details of cellular structures into the synthetic data. We combine real and synthetic patches to fine-tune a Vision Transformer (ViT), utilizing patch prediction aggregation for WSI-level classification. Experiments using 5-fold cross-validation demonstrate that our method achieves 96.47 % accuracy and reduces the FID score to 45.72, significantly outperforming class-conditioned baselines.", "AI": {"tldr": "该论文提出了一种自监督学习指导的潜在扩散模型，用于生成高质量的合成训练样本，并结合真实数据对视觉变压器进行微调，以提高乳腺癌分类在深紫外线全表面图像中的准确性。", "motivation": "乳房保留手术需要精确地术中边缘评估来保存健康组织。然而，深紫外荧光扫描显微镜（DUV-FSM）的数据标注稀缺限制了深度学习模型的训练效果。", "method": "该方法采用了自监督学习指导下的潜在扩散模型生成高质量合成训练样本，并利用一个微调过的DINO教师模型提供的嵌入来注入细胞结构的丰富语义细节。结合真实和合成补丁进行视觉变压器（ViT）微调，并使用补丁预测聚合进行全幻灯片级别的分类。", "result": "实验结果表明该方法在5倍交叉验证下的准确率为96.47%，并且将FID分数降低到45.72，显著优于基于类条件的基线模型。", "conclusion": "研究表明自监督学习引导的潜在扩散模型和视觉变压器结合使用可以有效提高乳腺癌分类在深紫外线全表面图像中的准确性。"}}
{"id": "2601.10913", "pdf": "https://arxiv.org/pdf/2601.10913", "abs": "https://arxiv.org/abs/2601.10913", "authors": ["Santiago Martínez Novoa", "María Catalina Ibáñez", "Lina Gómez Mesa", "Jeremias Kramer"], "title": "Classification of Chest XRay Diseases through image processing and analysis techniques", "categories": ["cs.CV"], "comment": null, "summary": "Multi-Classification Chest X-Ray Images are one of the most prevalent forms of radiological examination used for diagnosing thoracic diseases. In this study, we offer a concise overview of several methods employed for tackling this task, including DenseNet121. In addition, we deploy an open-source web-based application. In our study, we conduct tests to compare different methods and see how well they work. We also look closely at the weaknesses of the methods we propose and suggest ideas for making them better in the future. Our code is available at: https://github.com/AML4206-MINE20242/Proyecto_AML", "AI": {"tldr": "通过图像处理和分析技术对胸部X光疾病进行分类", "motivation": "多类胸部X光图像是最常用的放射学检查方法之一，用于诊断胸腔疾病。本文旨在概述用于解决这一任务的几种方法，并比较它们的表现。", "method": "使用DenseNet121等方法进行胸部X光图像的分类，并开发了一个开源的基于Web的应用程序来部署这些方法。", "result": "测试了不同的方法，评估了它们的有效性，并仔细分析了所提方法的不足之处。", "conclusion": "提出了一些改进未来研究的方法，并提供了代码供他人参考。"}}
{"id": "2601.10909", "pdf": "https://arxiv.org/pdf/2601.10909", "abs": "https://arxiv.org/abs/2601.10909", "authors": ["Chuqiao Li", "Xianghui Xie", "Yong Cao", "Andreas Geiger", "Gerard Pons-Moll"], "title": "FrankenMotion: Part-level Human Motion Generation and Composition", "categories": ["cs.CV"], "comment": "Project page: https://coral79.github.io/frankenmotion/", "summary": "Human motion generation from text prompts has made remarkable progress in recent years. However, existing methods primarily rely on either sequence-level or action-level descriptions due to the absence of fine-grained, part-level motion annotations. This limits their controllability over individual body parts. In this work, we construct a high-quality motion dataset with atomic, temporally-aware part-level text annotations, leveraging the reasoning capabilities of large language models (LLMs). Unlike prior datasets that either provide synchronized part captions with fixed time segments or rely solely on global sequence labels, our dataset captures asynchronous and semantically distinct part movements at fine temporal resolution. Based on this dataset, we introduce a diffusion-based part-aware motion generation framework, namely FrankenMotion, where each body part is guided by its own temporally-structured textual prompt. This is, to our knowledge, the first work to provide atomic, temporally-aware part-level motion annotations and have a model that allows motion generation with both spatial (body part) and temporal (atomic action) control. Experiments demonstrate that FrankenMotion outperforms all previous baseline models adapted and retrained for our setting, and our model can compose motions unseen during training. Our code and dataset will be publicly available upon publication.", "AI": {"tldr": "本论文提出了FrankenMotion，一种基于扩散模型的人体动作生成框架，能够根据文本提示实现空间和时间上的细致控制。", "motivation": "现有的人体运动生成方法主要依赖于序列级或动作级的描述，缺乏细粒度、部分级别的运动标注，导致对单个身体部位的控制能力有限。本研究旨在解决这一问题。", "method": "论文构建了一个高质量的动作数据集，并引入了FrankenMotion框架，该框架利用扩散模型和大语言模型的推理能力，实现基于文本提示的部分级动作生成。", "result": "实验表明，FrankenMotion优于所有先前适应和重新训练的基本模型，并且能够在未见过的数据上组合运动。", "conclusion": "论文展示了通过新的数据集和方法实现了人体动作生成中的空间和时间控制，取得了显著的效果。"}}
{"id": "2601.10904", "pdf": "https://arxiv.org/pdf/2601.10904", "abs": "https://arxiv.org/abs/2601.10904", "authors": ["François Chollet", "Mike Knoop", "Gregory Kamradt", "Bryan Landers"], "title": "ARC Prize 2025: Technical Report", "categories": ["cs.AI"], "comment": null, "summary": "The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.", "AI": {"tldr": "本文调查了ARC Prize 2025竞赛中的顶级方法，探讨了改进循环在AGI进展中的作用，并讨论了知识依赖的过拟合问题。同时预览了引入交互推理挑战的ARC-AGI-3。", "motivation": "为了评估和推动人工智能在少样本泛化方面的能力，并识别新的基准测试污染形式，特别是在前沿AI实验室中。", "method": "通过竞赛分析顶级团队的方法，研究改进循环的应用以及知识依赖的过拟合问题。", "result": "2025年的ARC Prize吸引了1455支队伍和15154份参赛作品，最佳得分达到24%。还发现前沿AI实验室在知识覆盖方面的限制导致了新的基准污染形式。", "conclusion": "改进循环是推动AGI进展的关键因素，但当前的性能依然受限于知识覆盖面。ARC-AGI已成为一个重要的行业标准测试，未来将包括更多交互推理挑战。"}}
{"id": "2601.10901", "pdf": "https://arxiv.org/pdf/2601.10901", "abs": "https://arxiv.org/abs/2601.10901", "authors": ["Honglian Wang", "Sijing Tu", "Lutz Oettershagen", "Aristides Gionis"], "title": "Streaming Stochastic Submodular Maximization with On-Demand User Requests", "categories": ["cs.DS", "cs.IR"], "comment": "NeurIPS'25", "summary": "We explore a novel problem in streaming submodular maximization, inspired by the dynamics of news-recommendation platforms. We consider a setting where users can visit a news website at any time, and upon each visit, the website must display up to $k$ news items. User interactions are inherently stochastic: each news item presented to the user is consumed with a certain acceptance probability by the user, and each news item covers certain topics. Our goal is to design a streaming algorithm that maximizes the expected total topic coverage. To address this problem, we establish a connection to submodular maximization subject to a matroid constraint. We show that we can effectively adapt previous methods to address our problem when the number of user visits is known in advance or linear-size memory in the stream length is available. However, in more realistic scenarios where only an upper bound on the visits and sublinear memory is available, the algorithms fail to guarantee any bounded performance. To overcome these limitations, we introduce a new online streaming algorithm that achieves a competitive ratio of $1/(8δ)$, where $δ$ controls the approximation quality. Moreover, it requires only a single pass over the stream, and uses memory independent of the stream length. Empirically, our algorithms consistently outperform the baselines.", "AI": {"tldr": "本文探讨了在流式处理场景下，如何通过优化新闻推荐算法来最大化话题覆盖率。", "motivation": "文章的动机来源于新闻推荐平台的实际需求，在这种平台上用户可以随时访问网站，每次访问时网站需要展示最多k个新闻条目，而每个新闻条目的接受概率和覆盖的话题都是随机的。", "method": "本文建立了一个与具有独立性约束的子模最大化问题相关的连接，并提出了一种新的在线流式算法以实现竞争比为1/(8δ)，其中δ控制近似质量。该算法仅需单次遍历数据流，且内存使用量与流长度无关。", "result": "实验结果表明，所提出的算法在实际应用中相对于基线算法表现出色。", "conclusion": "本文提出了一个处理新闻推荐平台用户随机访问情况下的优化方案，并通过实验证明了其有效性和优越性。"}}
{"id": "2601.10881", "pdf": "https://arxiv.org/pdf/2601.10881", "abs": "https://arxiv.org/abs/2601.10881", "authors": ["Sunny Atalig", "Marek Chrobak", "Christoph Dürr", "Petr Kolman", "Huong Luu", "Jiří Sgall", "Gregory Zhu"], "title": "Two Complexity Results on Spanning-Tree Congestion Problems", "categories": ["cs.DS"], "comment": null, "summary": "In the spanning-tree congestion problem ($\\mathsf{STC}$), we are given a graph $G$, and the objective is to compute a spanning tree of $G$ that minimizes the maximum edge congestion. While $\\mathsf{STC}$ is known to be $\\mathbb{NP}$-hard, even for some restricted graph classes, several key questions regarding its computational complexity remain open, and we address some of these in our paper. (i) For graphs of degree at most $d$, it is known that $\\mathsf{STC}$ is $\\mathbb{NP}$-hard when $d\\ge 8$. We provide a complete resolution of this variant, by showing that $\\mathsf{STC}$ remains $\\mathbb{NP}$-hard for each degree bound $d\\ge 3$. (ii) In the decision version of $\\mathsf{STC}$, given an integer $K$, the goal is to determine whether the congestion of $G$ is at most $K$. We prove that this variant is polynomial-time solvable for $K$-edge-connected graphs.", "AI": {"tldr": "本文研究了在给定度数限制下的图中最小化最大边拥塞的生成树问题（$\\mathsf{STC}$），并解决了该问题的一些计算复杂性问题。", "motivation": "尽管已知$\\mathsf{STC}$问题是NP难的，但对于特定图类的具体难度尚不清楚。本文旨在解决一些关于$\\mathsf{STC}$在度数受限下的具体复杂性和对于K-边连通图的可解性问题。", "method": "通过证明不同条件下生成树拥塞问题的计算复杂性，并展示了对于任意$d \\geq 3$，该问题是NP难的。同时对给定整数$K$的情况下，针对$K$-边连通图证明了决策版本是多项式时间内可解的。", "result": "结果表明对于度数至少为3的图，$\\mathsf{STC}$问题仍然是NP难的；并且对于任何给定的整数$K$，当考虑$K$-边连通图时，其决策版本可以在多项式时间内解决。", "conclusion": "本文完全解决了关于度数受限下的生成树拥塞问题的复杂性，并证明了在特定条件下该问题的可解性。"}}
{"id": "2601.10880", "pdf": "https://arxiv.org/pdf/2601.10880", "abs": "https://arxiv.org/abs/2601.10880", "authors": ["Chongcong Jiang", "Tianxingjian Ding", "Chuhan Song", "Jiachen Tu", "Ziyang Yan", "Yihua Shao", "Zhenyi Wang", "Yuzhang Shang", "Tianyu Han", "Yu Tian"], "title": "Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Promptable segmentation foundation models such as SAM3 have demonstrated strong generalization capabilities through interactive and concept-based prompting. However, their direct applicability to medical image segmentation remains limited by severe domain shifts, the absence of privileged spatial prompts, and the need to reason over complex anatomical and volumetric structures. Here we present Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, obtained by fully fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts. Through a systematic analysis of vanilla SAM3, we observe that its performance degrades substantially on medical data, with its apparent competitiveness largely relying on strong geometric priors such as ground-truth-derived bounding boxes. These findings motivate full model adaptation beyond prompt engineering alone. By fine-tuning SAM3's model parameters on 33 datasets spanning 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while preserving prompt-driven flexibility. Extensive experiments across organs, imaging modalities, and dimensionalities demonstrate consistent and significant performance gains, particularly in challenging scenarios characterized by semantic ambiguity, complex morphology, and long-range 3D context. Our results establish Medical SAM3 as a universal, text-guided segmentation foundation model for medical imaging and highlight the importance of holistic model adaptation for achieving robust prompt-driven segmentation under severe domain shift. Code and model will be made available at https://github.com/AIM-Research-Lab/Medical-SAM3.", "AI": {"tldr": "开发Medical SAM3，一种用于通用提示驱动的医学图像分割的基础模型。", "motivation": "研究发现SAM3在处理医学影像时性能显著下降，主要因为领域转换、缺乏空间提示以及需要理解复杂的解剖和体积结构。这促使了对模型进行全面调整以提高其在医学图像上的表现。", "method": "通过对大规模异构2D和3D医学成像数据集进行全量微调SAM3模型参数来获得Medical SAM3，这些数据包含分割掩模和文本提示。", "result": "实验结果表明，在涵盖多种器官、影像模式和维度的场景下，Medical SAM3在处理语义模糊性、复杂形态以及长距离3D上下文等挑战时表现出显著的性能提升。", "conclusion": "研究建立了Medical SAM3作为医学成像中通用的文字引导分割基础模型的重要性，并强调了全面模型适应对于实现强大的提示驱动分割在严重领域转换下的必要性。"}}
{"id": "2601.10877", "pdf": "https://arxiv.org/pdf/2601.10877", "abs": "https://arxiv.org/abs/2601.10877", "authors": ["Ludovic Righetti", "Vincent Boulanin"], "title": "Is open robotics innovation a threat to international peace and security?", "categories": ["cs.RO"], "comment": "ef:IEEE Robotics & Automation Magazine, vol. 32, no. 4, pp. 42-50, Dec. 2025", "summary": "Open access to publication, software and hardware is central to robotics: it lowers barriers to entry, supports reproducible science and accelerates reliable system development. However, openness also exacerbates the inherent dual-use risks associated with research and innovation in robotics. It lowers barriers for states and non-state actors to develop and deploy robotics systems for military use and harmful purposes. Compared to other fields of engineering where dual-use risks are present - e.g., those that underlie the development of weapons of mass destruction (chemical, biological, radiological, and nuclear weapons) and even the field of AI, robotics offers no specific regulation and little guidance as to how research and innovation may be conducted and disseminated responsibly. While other fields can be used for guidance, robotics has its own needs and specificities which have to be taken into account. The robotics community should therefore work toward its own set of sector-specific guidance and possibly regulation. To that end, we propose a roadmap focusing on four practices: a) education in responsible robotics; b) incentivizing risk assessment; c) moderating the diffusion of high-risk material; and d) developing red lines.", "AI": {"tldr": "探讨开放机器人创新是否对国际和平与安全构成威胁，并提出相应指导建议。", "motivation": "鉴于开放性在降低进入门槛和支持可重复科学研究方面的作用，但同时增加了双用途风险，尤其是军事和有害应用的风险，论文旨在分析并提出解决这些问题的方法。", "method": "通过对比其他存在双用途风险的工程领域，如制造大规模杀伤性武器的技术，并借鉴这些领域的经验和指导原则，为机器人技术制定具体的指导方针和可能的规范措施。", "result": "识别出开放创新带来的双重风险，并提出了包括负责任的机器人教育、促进风险评估、调节高风险材料传播及建立红线等四个实践建议。", "conclusion": "建议机器人社区应朝着制定特定领域的指导原则和法规努力，以应对双用途的风险并确保研究与创新的责任传播。"}}
{"id": "2601.10854", "pdf": "https://arxiv.org/pdf/2601.10854", "abs": "https://arxiv.org/abs/2601.10854", "authors": ["Mohammad Rasras", "Iuliana Marin", "Serban Radu", "Irina Mocanu"], "title": "Effects of Different Attention Mechanisms Applied on 3D Models in Video Classification", "categories": ["cs.CV"], "comment": "18 pages, 6 figures, conference", "summary": "Human action recognition has become an important research focus in computer vision due to the wide range of applications where it is used. 3D Resnet-based CNN models, particularly MC3, R3D, and R(2+1)D, have different convolutional filters to extract spatiotemporal features. This paper investigates the impact of reducing the captured knowledge from temporal data, while increasing the resolution of the frames. To establish this experiment, we created similar designs to the three originals, but with a dropout layer added before the final classifier. Secondly, we then developed ten new versions for each one of these three designs. The variants include special attention blocks within their architecture, such as convolutional block attention module (CBAM), temporal convolution networks (TCN), in addition to multi-headed and channel attention mechanisms. The purpose behind that is to observe the extent of the influence each of these blocks has on performance for the restricted-temporal models. The results of testing all the models on UCF101 have shown accuracy of 88.98% for the variant with multiheaded attention added to the modified R(2+1)D. This paper concludes the significance of missing temporal features in the performance of the newly created increased resolution models. The variants had different behavior on class-level accuracy, despite the similarity of their enhancements to the overall performance.", "AI": {"tldr": "本文研究了不同注意力机制对3D模型在视频分类中性能的影响。", "motivation": "随着人类动作识别在计算机视觉中的重要性日益增加，本论文旨在探讨减少时间数据捕获知识同时提高帧分辨率的效果。通过对比不同的注意力模块来观察其对性能的影响。", "method": "研究基于MC3、R3D和R(2+1)D模型，并在其基础上添加了dropout层以及不同类型的注意力机制（如CBAM，TCN等）。", "result": "实验结果表明，在UCF101数据集上，对修改后的R(2+1)D模型添加多头注意力模块后准确率达到了88.98%。", "conclusion": "本论文得出结论：丢失的时间特征对于新创建的高分辨率模型性能影响显著；尽管模型整体性能相似，但不同注意力机制在类别级别的准确性上表现各异。"}}
{"id": "2601.10836", "pdf": "https://arxiv.org/pdf/2601.10836", "abs": "https://arxiv.org/abs/2601.10836", "authors": ["Gerhard Krumpl", "Henning Avenhaus", "Horst Possegger"], "title": "One Model, Many Behaviors: Training-Induced Effects on Out-of-Distribution Detection", "categories": ["cs.CV"], "comment": "WACV 2026", "summary": "Out-of-distribution (OOD) detection is crucial for deploying robust and reliable machine-learning systems in open-world settings. Despite steady advances in OOD detectors, their interplay with modern training pipelines that maximize in-distribution (ID) accuracy and generalization remains under-explored. We investigate this link through a comprehensive empirical study. Fixing the architecture to the widely adopted ResNet-50, we benchmark 21 post-hoc, state-of-the-art OOD detection methods across 56 ImageNet-trained models obtained via diverse training strategies and evaluate them on eight OOD test sets. Contrary to the common assumption that higher ID accuracy implies better OOD detection performance, we uncover a non-monotonic relationship: OOD performance initially improves with accuracy but declines once advanced training recipes push accuracy beyond the baseline. Moreover, we observe a strong interdependence between training strategy, detector choice, and resulting OOD performance, indicating that no single method is universally optimal.", "AI": {"tldr": "研究了训练策略对ResNet-50模型在多种OOD检测方法上的影响，揭示了ID准确性与OOD性能之间的非单调关系。", "motivation": "尽管OOD检测领域有所进展，但其与现代训练流程的交互作用尚未深入探索。本文旨在探究这一互动关系。", "method": "固定使用ResNet-50架构，通过多样化的训练策略获得56个ImageNet模型，并用21种最先进的后验OOD检测方法进行评估，测试了八种OOD数据集的表现。", "result": "发现ID准确性与OOD性能之间存在非单调关系：随着准确性的提高，OOD性能起初改善，但一旦使用高级训练配方将准确性提升至基准之上，性能反而下降。", "conclusion": "表明不同的训练策略、检测方法选择和最终的OOD表现之间存在强相关性，没有单一最优的方法适用于所有场景。"}}
{"id": "2601.10835", "pdf": "https://arxiv.org/pdf/2601.10835", "abs": "https://arxiv.org/abs/2601.10835", "authors": ["Hieu Bui", "Nathaniel E. Chodosh", "Arash Tavakoli"], "title": "Can Vision-Language Models Understand Construction Workers? An Exploratory Study", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "As robotics become increasingly integrated into construction workflows, their ability to interpret and respond to human behavior will be essential for enabling safe and effective collaboration. Vision-Language Models (VLMs) have emerged as a promising tool for visual understanding tasks and offer the potential to recognize human behaviors without extensive domain-specific training. This capability makes them particularly appealing in the construction domain, where labeled data is scarce and monitoring worker actions and emotional states is critical for safety and productivity. In this study, we evaluate the performance of three leading VLMs, GPT-4o, Florence 2, and LLaVa-1.5, in detecting construction worker actions and emotions from static site images. Using a curated dataset of 1,000 images annotated across ten action and ten emotion categories, we assess each model's outputs through standardized inference pipelines and multiple evaluation metrics. GPT-4o consistently achieved the highest scores across both tasks, with an average F1-score of 0.756 and accuracy of 0.799 in action recognition, and an F1-score of 0.712 and accuracy of 0.773 in emotion recognition. Florence 2 performed moderately, with F1-scores of 0.497 for action and 0.414 for emotion, while LLaVa-1.5 showed the lowest overall performance, with F1-scores of 0.466 for action and 0.461 for emotion. Confusion matrix analyses revealed that all models struggled to distinguish semantically close categories, such as collaborating in teams versus communicating with supervisors. While the results indicate that general-purpose VLMs can offer a baseline capability for human behavior recognition in construction environments, further improvements, such as domain adaptation, temporal modeling, or multimodal sensing, may be needed for real-world reliability.", "AI": {"tldr": "本文研究了三种领先视觉语言模型在识别建筑工人行为和情绪方面的表现。", "motivation": "随着机器人技术融入施工流程，其理解和响应人类行为的能力对于确保安全与高效协作至关重要。然而，在建筑业中，标记数据稀缺且监测工人的动作和情感状态对安全性和生产率极为重要。", "method": "研究评估了三种领先视觉语言模型（GPT-4o、Florence 2 和 LLaVa-1.5）在识别静态施工现场图片中的工人行为和情绪的能力。使用包含1000张标注图像的数据集，通过标准化推理管道及多种评价指标进行了模型性能的评估。", "result": "GPT-4o 在两项任务中均取得最高得分，行为识别的 F1 分数为 0.756，准确率为 0.799；情绪识别的 F1 分数为 0.712，准确率为 0.773。Florence 2 表现适中，行动和情感的F1分数分别为0.497 和 0.414。而 LLaVa-1.5 的总体表现最低，行为识别和情绪识别的 F1 分数分别是 0.466 和 0.461。", "conclusion": "研究表明，通用视觉语言模型可以在建筑环境中提供人类行为识别的基本能力，但要达到实际应用的可靠性，可能需要进行领域适应、时间建模或多模态传感等方面的改进。"}}
{"id": "2601.10832", "pdf": "https://arxiv.org/pdf/2601.10832", "abs": "https://arxiv.org/abs/2601.10832", "authors": ["Anis R. Shakkour", "David Hexner", "Yehuda Bitton", "Avishai Sintov"], "title": "IMU-based Real-Time Crutch Gait Phase and Step Detections in Lower-Limb Exoskeletons", "categories": ["cs.RO"], "comment": null, "summary": "Lower limb exoskeletons and prostheses require precise, real time gait phase and step detections to ensure synchronized motion and user safety. Conventional methods often rely on complex force sensing hardware that introduces control latency. This paper presents a minimalist framework utilizing a single, low cost Inertial-Measurement Unit (IMU) integrated into the crutch hand grip, eliminating the need for mechanical modifications. We propose a five phase classification system, including standard gait phases and a non locomotor auxiliary state, to prevent undesired motion. Three deep learning architectures were benchmarked on both a PC and an embedded system. To improve performance under data constrained conditions, models were augmented with a Finite State Machine (FSM) to enforce biomechanical consistency. The Temporal Convolutional Network (TCN) emerged as the superior architecture, yielding the highest success rates and lowest latency. Notably, the model generalized to a paralyzed user despite being trained exclusively on healthy participants. Achieving a 94% success rate in detecting crutch steps, this system provides a high performance, cost effective solution for real time exoskeleton control.", "AI": {"tldr": "本文提出了一种基于单个低成本惯性测量单元(IMU)的实时拐杖步态和步长检测框架，用于下肢外骨骼。", "motivation": "传统的步态检测方法依赖于复杂的力传感器硬件，引入了控制延迟。本研究旨在通过使用简单的IMU实现更高效、低延迟的步态检测，以确保动作同步和用户安全。", "method": "本文提出了一种五阶段分类系统，包括标准步态阶段以及一个非运动辅助状态，并比较了三种深度学习架构在PC和嵌入式系统上的性能。通过引入有限状态机(FSM)来增强生物力学一致性，在数据受限条件下提升模型表现。最终确定时空卷积网络(TCN)为最优结构。", "result": "实验表明，TCN架构达到了最高的成功率（94%）和最低延迟。值得注意的是，该模型在仅训练健康参与者的情况下，仍能适用于瘫痪用户。", "conclusion": "本文提出的方法提供了一种高性能且成本低廉的实时外骨骼控制解决方案。"}}
{"id": "2601.10827", "pdf": "https://arxiv.org/pdf/2601.10827", "abs": "https://arxiv.org/abs/2601.10827", "authors": ["Simin Liu", "Tong Zhao", "Bernhard Paus Graesdal", "Peter Werner", "Jiuguang Wang", "John Dolan", "Changliu Liu", "Tao Pang"], "title": "Approximately Optimal Global Planning for Contact-Rich SE(2) Manipulation on a Graph of Reachable Sets", "categories": ["cs.RO", "cs.AI", "eess.SY"], "comment": "17 pages, 14 figures; under submission to IEEE Transactions on Robotics", "summary": "If we consider human manipulation, it is clear that contact-rich manipulation (CRM)-the ability to use any surface of the manipulator to make contact with objects-can be far more efficient and natural than relying solely on end-effectors (i.e., fingertips). However, state-of-the-art model-based planners for CRM are still focused on feasibility rather than optimality, limiting their ability to fully exploit CRM's advantages. We introduce a new paradigm that computes approximately optimal manipulator plans. This approach has two phases. Offline, we construct a graph of mutual reachable sets, where each set contains all object orientations reachable from a starting object orientation and grasp. Online, we plan over this graph, effectively computing and sequencing local plans for globally optimized motion. On a challenging, representative contact-rich task, our approach outperforms a leading planner, reducing task cost by 61%. It also achieves a 91% success rate across 250 queries and maintains sub-minute query times, ultimately demonstrating that globally optimized contact-rich manipulation is now practical for real-world tasks.", "AI": {"tldr": "本文提出了一个新的范式，用于计算接触丰富的操纵器计划的近似最优解。", "motivation": "人类在操作过程中使用所有可接触表面进行操纵比仅依赖末端执行器（如手指）更为高效自然。然而现有的基于模型的规划方法仍主要关注可行性而非优化性，限制了其优势的发挥。", "method": "该方法包括两个阶段：离线构建可达集图，在线在该图上进行计划以计算和序列化局部计划实现全局最优运动。", "result": "在具有挑战性的接触丰富的任务中，此方法优于领先规划器，将任务成本减少了61%，并实现了250次查询中的91%成功率，同时保持了亚分钟级的查询时间。", "conclusion": "该研究证明了全局优化的接触丰富操纵现在可以用于现实世界任务是可行的。"}}
{"id": "2601.10824", "pdf": "https://arxiv.org/pdf/2601.10824", "abs": "https://arxiv.org/abs/2601.10824", "authors": ["Wanqi Zhang", "Jiangen He", "Marielle Santos"], "title": "Bridging Psychological Safety and Skill Guidance: An Adaptive Robotic Interview Coach", "categories": ["cs.HC"], "comment": "4 pages, report", "summary": "Social robots hold promise for reducing job interview anxiety, yet designing agents that provide both psychological safety and instructional guidance remains challenging. Through a three-phase iterative design study (N = 8), we empirically mapped this tension. Phase I revealed a \"Safety-Guidance Gap\": while a Person-Centered Therapy (PCT) robot established safety (d = 3.27), users felt insufficiently coached. Phase II identified a \"Scaffolding Paradox\": rigid feedback caused cognitive overload, while delayed feedback lacked specificity. In Phase III, we resolved these tensions by developing an Agency-Driven Interaction Layer. Synthesizing our empirical findings, we propose the Adaptive Scaffolding Ecosystem, a conceptual framework that redefines robotic coaching not as a static script, but as a dynamic balance between affective support and instructional challenge, mediated by user agency.", "AI": {"tldr": "本论文旨在通过设计自适应的机器人面试教练，解决提供心理安全感和技能指导之间的矛盾。", "motivation": "社会机器人有可能减少求职面试的压力，但如何在提供心理安全的同时进行有效的技能指导仍然是一个挑战。", "method": "研究采用三阶段迭代设计研究方法（N = 8），逐步识别并解决了“安全保障-指导差距”和“支架悖论”，最终开发出了自适应的支架生态系统框架。", "result": "研究结果显示，通过引入代理驱动交互层，可以动态平衡情感支持与技能挑战之间的关系，并提高了用户体验。", "conclusion": "论文提出了一种新的概念性框架——自适应支架生态系统，重新定义了机器人教练的角色为一种由用户代理介导的、在情感支持和技能指导之间动态平衡的状态。"}}
{"id": "2601.10820", "pdf": "https://arxiv.org/pdf/2601.10820", "abs": "https://arxiv.org/abs/2601.10820", "authors": ["Himanshu Thakur", "Anusha Kamath", "Anurag Muthyala", "Dhwani Sanmukhani", "Smruthi Mukund", "Jay Katukuri"], "title": "Towards Reliable ML Feature Engineering via Planning in Constrained-Topology of LLM Agents", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Recent advances in code generation models have unlocked unprecedented opportunities for automating feature engineering, yet their adoption in real-world ML teams remains constrained by critical challenges: (i) the scarcity of datasets capturing the iterative and complex coding processes of production-level feature engineering, (ii) limited integration and personalization of widely used coding agents, such as CoPilot and Devin, with a team's unique tools, codebases, workflows, and practices, and (iii) suboptimal human-AI collaboration due to poorly timed or insufficient feedback. We address these challenges with a planner-guided, constrained-topology multi-agent framework that generates code for repositories in a multi-step fashion. The LLM-powered planner leverages a team's environment, represented as a graph, to orchestrate calls to available agents, generate context-aware prompts, and use downstream failures to retroactively correct upstream artifacts. It can request human intervention at critical steps, ensuring generated code is reliable, maintainable, and aligned with team expectations. On a novel in-house dataset, our approach achieves 38% and 150% improvement in the evaluation metric over manually crafted and unplanned workflows respectively. In practice, when building features for recommendation models serving over 120 million users, our approach has delivered real-world impact by reducing feature engineering cycles from three weeks to a single day.", "AI": {"tldr": "本文提出了一种基于规划的多智能体框架，通过利用团队环境图来生成可靠且与团队期望一致的代码。", "motivation": "尽管代码生成模型在自动化特征工程方面取得了显著进展，但其在实际机器学习团队中的应用仍受到数据稀缺、个性化集成困难以及人机协作不佳等问题的限制。", "method": "该方法采用了一个由LLM驱动的规划器来指导多步代码生成过程，通过环境图调用不同智能体，生成上下文感知提示，并利用下游失败反馈调整上游生成。同时，在关键步骤请求人类干预以提高可靠性。", "result": "在内部数据集上，相较于手动和非计划工作流程，该方法分别提高了38%和150%的评估指标。实际应用中，特征工程周期从三周缩短到一天。", "conclusion": "实验表明，通过多智能体框架进行规划指导可以显著提高特征工程的质量和效率，减少开发时间，并与团队期望保持一致。"}}
{"id": "2601.10819", "pdf": "https://arxiv.org/pdf/2601.10819", "abs": "https://arxiv.org/abs/2601.10819", "authors": ["Yizhou Wang", "Sameer Pusegaonkar", "Yuxing Wang", "Anqi Li", "Vishal Kumar", "Chetan Sethi", "Ganapathy Aiyer", "Yun He", "Kartikay Thakkar", "Swapnil Rathi", "Bhushan Rupde", "Zheng Tang", "Sujit Biswas"], "title": "A Unified 3D Object Perception Framework for Real-Time Outside-In Multi-Camera Systems", "categories": ["cs.CV"], "comment": null, "summary": "Accurate 3D object perception and multi-target multi-camera (MTMC) tracking are fundamental for the digital transformation of industrial infrastructure. However, transitioning \"inside-out\" autonomous driving models to \"outside-in\" static camera networks presents significant challenges due to heterogeneous camera placements and extreme occlusion. In this paper, we present an adapted Sparse4D framework specifically optimized for large-scale infrastructure environments. Our system leverages absolute world-coordinate geometric priors and introduces an occlusion-aware ReID embedding module to maintain identity stability across distributed sensor networks. To bridge the Sim2Real domain gap without manual labeling, we employ a generative data augmentation strategy using the NVIDIA COSMOS framework, creating diverse environmental styles that enhance the model's appearance-invariance. Evaluated on the AI City Challenge 2025 benchmark, our camera-only framework achieves a state-of-the-art HOTA of $45.22$. Furthermore, we address real-time deployment constraints by developing an optimized TensorRT plugin for Multi-Scale Deformable Aggregation (MSDA). Our hardware-accelerated implementation achieves a $2.15\\times$ speedup on modern GPU architectures, enabling a single Blackwell-class GPU to support over 64 concurrent camera streams.", "AI": {"tldr": "本文提出了一种适用于大规模基础设施环境的实时多摄像头系统下的3D物体感知统一框架。", "motivation": "准确的3D物体感知和多目标多相机跟踪对于工业基础设施的数字化转型至关重要，但将自动驾驶模型从“内向外”转换为“外向内”的静态摄像机网络面临挑战。", "method": "本文提出的Sparse4D框架通过绝对世界坐标几何先验知识和遮挡感知ReID嵌入模块来保持分布式传感器网络中的身份稳定性，并使用NVIDIA COSMOS框架进行生成数据增强以解决仿真到现实的领域差距。", "result": "在AI City Challenge 2025基准上，本文的方法实现了45.22分HOTA得分，并通过优化TensorRT插件实现实时部署，在现代GPU架构上获得了2.15倍的速度提升，单个Blackwell-class GPU支持超过64个并发摄像头流。", "conclusion": "所提出的方法在大规模基础设施环境下实现了高效的3D物体感知和多目标跟踪，同时满足了实时处理的硬件加速需求。"}}
{"id": "2601.10814", "pdf": "https://arxiv.org/pdf/2601.10814", "abs": "https://arxiv.org/abs/2601.10814", "authors": ["Onur Bagoren", "Seth Isaacson", "Sacchin Sundar", "Yung-Ching Sun", "Anja Sheppard", "Haoyu Ma", "Abrar Shariff", "Ram Vasudevan", "Katherine A. Skinner"], "title": "SurfSLAM: Sim-to-Real Underwater Stereo Reconstruction For Real-Time SLAM", "categories": ["cs.RO"], "comment": null, "summary": "Localization and mapping are core perceptual capabilities for underwater robots. Stereo cameras provide a low-cost means of directly estimating metric depth to support these tasks. However, despite recent advances in stereo depth estimation on land, computing depth from image pairs in underwater scenes remains challenging. In underwater environments, images are degraded by light attenuation, visual artifacts, and dynamic lighting conditions. Furthermore, real-world underwater scenes frequently lack rich texture useful for stereo depth estimation and 3D reconstruction. As a result, stereo estimation networks trained on in-air data cannot transfer directly to the underwater domain. In addition, there is a lack of real-world underwater stereo datasets for supervised training of neural networks. Poor underwater depth estimation is compounded in stereo-based Simultaneous Localization and Mapping (SLAM) algorithms, making it a fundamental challenge for underwater robot perception. To address these challenges, we propose a novel framework that enables sim-to-real training of underwater stereo disparity estimation networks using simulated data and self-supervised finetuning. We leverage our learned depth predictions to develop \\algname, a novel framework for real-time underwater SLAM that fuses stereo cameras with IMU, barometric, and Doppler Velocity Log (DVL) measurements. Lastly, we collect a challenging real-world dataset of shipwreck surveys using an underwater robot. Our dataset features over 24,000 stereo pairs, along with high-quality, dense photogrammetry models and reference trajectories for evaluation. Through extensive experiments, we demonstrate the advantages of the proposed training approach on real-world data for improving stereo estimation in the underwater domain and for enabling accurate trajectory estimation and 3D reconstruction of complex shipwreck sites.", "AI": {"tldr": "提出了一种新的Sim-to-Real框架，用于水下实时SLAM系统中的立体深度估计和三维重建。", "motivation": "解决现有技术在水下环境中难以精确进行立体深度估计的问题，并提高水下机器人定位与建图的性能。", "method": "使用模拟数据训练水下立体视差估计算法，并通过自监督微调实现从仿真到现实环境的应用。结合多种传感器数据，提出SurfSLAM框架以实现实时水下SLAM。", "result": "在收集的真实世界复杂沉船现场的数据集上进行了大量实验，证明了所提方法能够有效提升立体深度估计精度，并实现了复杂的三维重建和精确的轨迹估算。", "conclusion": "该研究提出的方法显著提升了水下环境中的立体视觉深度估计能力，促进了水下机器人实时SLAM技术的发展。"}}
{"id": "2601.10810", "pdf": "https://arxiv.org/pdf/2601.10810", "abs": "https://arxiv.org/abs/2601.10810", "authors": ["Mengmeng Peng", "Zhenyu Fang", "He Sun"], "title": "Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning -- Towards a Pure Neural Logic Core", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) currently suffer from parameter entanglement, where general reasoning capabilities (logic) and specific factual knowledge (facts) exist in a superposition state within shared weights. This coupling leads to the \"memory wall,\" where computational capacity is squandered on simulating retrieval, often resulting in hallucinations. In this paper, we propose \"digital metabolism,\" a thermodynamic hypothesis suggesting that targeted forgetting is necessary for distilling a pure neural logic core. To validate this hypothesis, we introduce the Regenerative Logic-Core Protocol (RLCP), a dual-stream training framework that renders specific factual dependencies linearly undecodable via deep-layer gradient reversal. Applying RLCP to Qwen2.5-0.5B, we observe a distinct phase transition: the model achieves near-zero retention of targeted factual associations (Accuracy < 7%) while exhibiting changes consistent with an emergent \"structural crystallization\" effect. Empirical analysis on GSM8K reveals that the \"metabolized\" model spontaneously adopts chain-of-thought (CoT) scaffolding, which we interpret as compensating for the loss of direct associative recall (shifting from $O(1)$ recall to $O(N)$ reasoning). While the causal mechanism underlying this behavioral shift requires further investigation, our findings provide a dynamic weight-level counterpart to architectural innovations like DeepSeek's Engram, paving the way for modular \"Neural CPU + Symbolic RAM\" architectures.", "AI": {"tldr": "提出“数字代谢”概念，通过再生逻辑核心协议（RLCP）将一般推理能力和特定事实知识分离，以减少计算资源浪费并避免幻觉。", "motivation": "大型语言模型中参数纠缠导致了“内存墙”，计算能力被浪费在模拟检索上，常产生幻觉。旨在解决这一问题并通过实验证明“数字代谢”的必要性。", "method": "引入再生逻辑核心协议（RLCP），这是一种双流训练框架，通过深层梯度反转使特定事实依赖变得线性不可解。", "result": "应用RLCP于Qwen2.5-0.5B模型时观察到相变：该模型对目标事实关联的保留率几乎为零（准确率<7%），并且自发地采用了链式思考模式来补偿直接联想回忆能力的损失。", "conclusion": "研究结果支持了“数字代谢”的概念，并提出了一种动态权重级别的解决方案，与DeepSeek的Engram架构创新相呼应，为进一步开发模块化的神经CPU和符号RAM架构铺平道路。"}}
{"id": "2601.10802", "pdf": "https://arxiv.org/pdf/2601.10802", "abs": "https://arxiv.org/abs/2601.10802", "authors": ["Gerhard Krumpl", "Henning Avenhaus", "Horst Possegger"], "title": "ICONIC-444: A 3.1-Million-Image Dataset for OOD Detection Research", "categories": ["cs.CV"], "comment": "WACV 2026, Dataset repo: https://github.com/gkrumpl/iconic-444", "summary": "Current progress in out-of-distribution (OOD) detection is limited by the lack of large, high-quality datasets with clearly defined OOD categories across varying difficulty levels (near- to far-OOD) that support both fine- and coarse-grained computer vision tasks. To address this limitation, we introduce ICONIC-444 (Image Classification and OOD Detection with Numerous Intricate Complexities), a specialized large-scale industrial image dataset containing over 3.1 million RGB images spanning 444 classes tailored for OOD detection research. Captured with a prototype industrial sorting machine, ICONIC-444 closely mimics real-world tasks. It complements existing datasets by offering structured, diverse data suited for rigorous OOD evaluation across a spectrum of task complexities. We define four reference tasks within ICONIC-444 to benchmark and advance OOD detection research and provide baseline results for 22 state-of-the-art post-hoc OOD detection methods.", "AI": {"tldr": "本文介绍了ICONIC-444，一个包含超过310万张RGB图像的大型工业数据集，用于OOD检测研究。", "motivation": "当前OOD检测的研究受限于缺乏大规模、高质量且定义清晰的OOD类别数据集，该论文旨在解决这一问题，提供了一个适合各种任务复杂度的OOD检测基准数据集。", "method": "通过使用原型工业分类机捕获图像，构建了ICONIC-444数据集，并定义了四个参考任务来评估和推进OOD检测研究。提供了22种最先进的后验OOD检测方法的基线结果。", "result": "ICONIC-444包含超过310万张RGB图像，涵盖444个类别，为OOD检测研究提供了一个多样化且结构化的数据集。", "conclusion": "ICONIC-444作为专门针对OOD检测设计的数据集，能够促进该领域的进一步发展，并为未来的OOD检测方法提供了基准测试的平台。"}}
{"id": "2601.10796", "pdf": "https://arxiv.org/pdf/2601.10796", "abs": "https://arxiv.org/abs/2601.10796", "authors": ["Junxiang Wang", "Cindy Wang", "Rana Soltani Zarrin", "Zackory Erickson"], "title": "Bidirectional Human-Robot Communication for Physical Human-Robot Interaction", "categories": ["cs.RO"], "comment": "12 pages, 8 figures. To be published in 2026 ACM/IEEE International Conference on Human-Robot Interaction", "summary": "Effective physical human-robot interaction requires systems that are not only adaptable to user preferences but also transparent about their actions. This paper introduces BRIDGE, a system for bidirectional human-robot communication in physical assistance. Our method allows users to modify a robot's planned trajectory -- position, velocity, and force -- in real time using natural language. We utilize a large language model (LLM) to interpret any trajectory modifications implied by user commands in the context of the planned motion and conversation history. Importantly, our system provides verbal feedback in response to the user, either assuring any resulting changes or posing a clarifying question. We evaluated our method in a user study with 18 older adults across three assistive tasks, comparing BRIDGE to an ablation without verbal feedback and a baseline. Results show that participants successfully used the system to modify trajectories in real time. Moreover, the bidirectional feedback led to significantly higher ratings of interactivity and transparency, demonstrating that the robot's verbal response is critical for a more intuitive user experience. Videos and code can be found on our project website: https://bidir-comm.github.io/", "AI": {"tldr": "本文介绍了BRIDGE系统，该系统实现了双向人机沟通，在物理辅助任务中允许用户实时使用自然语言修改机器人的规划轨迹。", "motivation": "为了实现有效的物理人类-机器人交互，需要能够适应用户偏好并透明地显示其行为的系统。因此，动机是开发一个可以实时理解和响应用户命令以调整机器人动作的系统，并且提供反馈。", "method": "使用大型语言模型（LLM）来解释用户的自然语言指令，修改机器人的轨迹规划，包括位置、速度和力量，并通过语音反馈确认或询问以澄清意图。", "result": "在包含18名老年人参与的用户研究中，参与者成功地使用该系统实时调整了机器人轨迹。与无口头反馈的对照组相比，带有双向反馈的BRIDGE得到了更高的交互性和透明度评分。", "conclusion": "研究表明，在物理人类-机器人互动中，通过自然语言进行双向沟通可以提高用户体验，并且机器人的口头反馈对于实现更直观的用户操作至关重要。"}}
{"id": "2601.10781", "pdf": "https://arxiv.org/pdf/2601.10781", "abs": "https://arxiv.org/abs/2601.10781", "authors": ["Kanchana Ranasinghe", "Honglu Zhou", "Yu Fang", "Luyu Yang", "Le Xue", "Ran Xu", "Caiming Xiong", "Silvio Savarese", "Michael S Ryoo", "Juan Carlos Niebles"], "title": "Future Optical Flow Prediction Improves Robot Control & Video Generation", "categories": ["cs.CV"], "comment": "Project Site (Code, Models, Demo): https://fofpred.github.io", "summary": "Future motion representations, such as optical flow, offer immense value for control and generative tasks. However, forecasting generalizable spatially dense motion representations remains a key challenge, and learning such forecasting from noisy, real-world data remains relatively unexplored. We introduce FOFPred, a novel language-conditioned optical flow forecasting model featuring a unified Vision-Language Model (VLM) and Diffusion architecture. This unique combination enables strong multimodal reasoning with pixel-level generative fidelity for future motion prediction. Our model is trained on web-scale human activity data-a highly scalable but unstructured source. To extract meaningful signals from this noisy video-caption data, we employ crucial data preprocessing techniques and our unified architecture with strong image pretraining. The resulting trained model is then extended to tackle two distinct downstream tasks in control and generation. Evaluations across robotic manipulation and video generation under language-driven settings establish the cross-domain versatility of FOFPred, confirming the value of a unified VLM-Diffusion architecture and scalable learning from diverse web data for future optical flow prediction.", "AI": {"tldr": "介绍了一种新的语言条件下的光流预测模型FOFPred，该模型结合了视觉语言模型（VLM）和扩散架构，用于控制任务和视频生成。", "motivation": "光流等未来运动表征对于控制和生成任务非常有价值，但预测通用的密集空间运动表示仍是一个关键挑战，从嘈杂的真实世界数据中学习这样的预测方法仍然较少探索。", "method": "FOFPred模型结合了视觉语言模型（VLM）和扩散架构，并使用大规模的人类活动数据进行训练，采用了重要的数据预处理技术以提取有意义的信号。", "result": "该模型在机器人操作和视频生成的任务中进行了评估，在基于语言驱动的设置下展示了跨领域的适应能力。", "conclusion": "研究结果证实了视觉语言模型（VLM）与扩散架构相结合的价值，以及从多样化的网络数据进行大规模学习对于未来光流预测的重要性。"}}
{"id": "2601.10779", "pdf": "https://arxiv.org/pdf/2601.10779", "abs": "https://arxiv.org/abs/2601.10779", "authors": ["Qingyue Zhang", "Chang Chu", "Haohao Fu", "Tianren Peng", "Yanru Wu", "Guanbo Huang", "Yang Li", "Shao-Lun Huang"], "title": "Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transfer learning plays a vital role in improving model performance in data-scarce scenarios. However, naive uniform transfer from multiple source tasks may result in negative transfer, highlighting the need to properly balance the contributions of heterogeneous sources. Moreover, existing transfer learning methods typically focus on optimizing either the source weights or the amount of transferred samples, while largely neglecting the joint consideration of the other. In this work, we propose a theoretical framework, Unified Optimization of Weights and Quantities (UOWQ), which formulates multi-source transfer learning as a parameter estimation problem grounded in an asymptotic analysis of a Kullback-Leibler divergence-based generalization error measure. The proposed framework jointly determines the optimal source weights and optimal transfer quantities for each source task. Firstly, we prove that using all available source samples is always optimal once the weights are properly adjusted, and we provide a theoretical explanation for this phenomenon. Moreover, to determine the optimal transfer weights, our analysis yields closed-form solutions in the single-source setting and develops a convex optimization-based numerical procedure for the multi-source case. Building on the theoretical results, we further propose practical algorithms for both multi-source transfer learning and multi-task learning settings. Extensive experiments on real-world benchmarks, including DomainNet and Office-Home, demonstrate that UOWQ consistently outperforms strong baselines. The results validate both the theoretical predictions and the practical effectiveness of our framework.", "AI": {"tldr": "本文提出了一个统一优化源权重和转移数量的理论框架UOWQ，用于多源迁移学习。", "motivation": "现有的迁移学习方法通常只关注优化源权重或转移动量之一，而忽视了对另一个因素的同时考虑。同时，在数据稀缺场景下，简单的从多个源任务均匀迁移可能导致负向迁移。", "method": "UOWQ框架将多源迁移学习建模为一个基于Kullback-Leibler散度泛化误差的参数估计问题，并推导出在单源和多源情况下确定最优转移权重的方法。该框架能够共同决定每个源任务的最佳源权重和转移动量。", "result": "实验结果表明，UOWQ在包括DomainNet和Office-Home在内的多个基准数据集上均优于强基线模型，验证了理论预测和实际效果。", "conclusion": "本文提出了一个有效的框架来联合优化多源迁移学习中的权重和转移动量，并通过实验证明其优越性。"}}
{"id": "2601.10773", "pdf": "https://arxiv.org/pdf/2601.10773", "abs": "https://arxiv.org/abs/2601.10773", "authors": ["Niko Usai", "Dario Montagnini", "Kristian Ilianov Iliev", "Raffaele Camanzo"], "title": "LogicLens: Leveraging Semantic Code Graph to explore Multi Repository large systems", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Understanding large software systems is a challenging task, especially when code is distributed across multiple repositories and microservices. Developers often need to reason not only about the structure of the code, but also about its domain logic and runtime behaviors, which are typically implicit and scattered. We introduce LogicLens, a reactive conversational agent that assists developers in exploring complex software systems through a semantic multi-repository graph. This graph is built in a preprocessing step by combining syntactic code analysis, via AST parsing and repository traversal, with semantic enrichment using Large Language Models (LLMs). The resulting graph captures both structural elements, such as files, classes, and functions, as well as functional abstractions like domain entities, operations, and workflows. Once the graph is constructed, LogicLens enables developers to interact with it via natural language, dynamically retrieving relevant subgraphs and answering technical or functional queries. We present the architecture of the system, discuss emergent behaviors, and evaluate its effectiveness on real-world multi-repository scenarios. We demonstrate emergent capabilities including impact analysis and symptom-based debugging that arise naturally from the semantic graph structure.", "AI": {"tldr": "本文介绍了LogicLens，一种通过语义多仓库图帮助开发者探索复杂软件系统的反应式会话代理。", "motivation": "理解分布在多个存储库和微服务中的大型软件系统是一项挑战，开发人员需要推理代码结构以及其领域逻辑和运行时行为，这些通常隐含且分散。", "method": "LogicLens通过结合语法代码分析（如AST解析和仓库遍历）与语义增强（使用大语言模型），在预处理步骤中构建一个捕捉结构元素和功能抽象的多仓库图，并允许开发者以自然语言交互查询系统。", "result": "该系统能够实现动态检索相关子图并回答技术或功能性问题，还展示了诸如影响分析和基于症状的调试等新兴能力。", "conclusion": "实验表明，在现实世界的多存储库场景中，LogicLens能有效帮助开发人员理解复杂的软件系统。"}}
{"id": "2601.10770", "pdf": "https://arxiv.org/pdf/2601.10770", "abs": "https://arxiv.org/abs/2601.10770", "authors": ["Runyuan Cai", "Yu Lin", "Yiming Wang", "Chunlin Fu", "Xiaodong Zeng"], "title": "Unifying Speech Recognition, Synthesis and Conversion with Autoregressive Transformers", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Traditional speech systems typically rely on separate, task-specific models for text-to-speech (TTS), automatic speech recognition (ASR), and voice conversion (VC), resulting in fragmented pipelines that limit scalability, efficiency, and cross-task generalization. In this paper, we present General-Purpose Audio (GPA), a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture. GPA operates on a shared discrete audio token space and supports instruction-driven task induction, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications. This unified design combines a fully autoregressive formulation over discrete speech tokens, joint multi-task training across speech domains, and a scalable inference pipeline that achieves high concurrency and throughput. The resulting model family supports efficient multi-scale deployment, including a lightweight 0.3B-parameter variant optimized for edge and resource-constrained environments. Together, these design choices demonstrate that a unified autoregressive architecture can achieve competitive performance across diverse speech tasks while remaining viable for low-latency, practical deployment.", "AI": {"tldr": "本文提出了一种统一的音频基础模型General-Purpose Audio (GPA)，该模型在一个大型语言模型架构中集成了多个核心语音任务。", "motivation": "传统的语音系统依赖于不同的、特定任务的模型进行文本到语音转换（TTS）、自动语音识别（ASR）和声音转换（VC），导致了分散化的管道，限制了可扩展性、效率和跨任务泛化能力。", "method": "GPA基于共享离散音频令牌空间，支持指令驱动的任务诱导，使用单一自回归模型灵活地执行TTS、ASR和VC。该设计结合了跨越语音域的联合多任务训练，并具有高并发性和吞吐量的可扩展推理管道。", "result": "研究展示了这个统一的设计可以实现跨多种语音任务的竞争性能，包括一个针对边缘和资源受限环境优化的轻量级0.3B参数变种模型。", "conclusion": "该研究表明，统一的自回归架构可以在保持低延迟和实际部署可行性的同时，在不同的语音任务中达到竞争水平的表现。"}}
{"id": "2601.10768", "pdf": "https://arxiv.org/pdf/2601.10768", "abs": "https://arxiv.org/abs/2601.10768", "authors": ["Nina Bočková", "Barbora Volná", "Mirko Dohnal"], "title": "Optimisation of complex product innovation processes based on trend models with three-valued logic", "categories": ["cs.AI", "math.OC"], "comment": ":34C60; 91B06; 68Q85", "summary": "This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.", "AI": {"tldr": "本文研究基于三值逻辑趋势模型的复杂产品创新过程优化。", "motivation": "动机在于探讨如何通过简单趋势（增加、减少或保持不变）来最小化信息量并避免依赖数值或粗集，从而更高效地处理复杂的产品创新过程。", "method": "使用一套启发式方法构建模型，这些启发式方法通过简单的趋势表达，并用转换图表示可能的情景及其之间的转换。", "result": "定义了趋势模型的解为一系列情景及它们之间的可能转换，能够描绘系统未来或过去的任何行为。", "conclusion": "结论表明基于三值逻辑的趋势模型可以有效地描绘复杂产品创新过程中的各种行为和变化情景。"}}
{"id": "2601.10765", "pdf": "https://arxiv.org/pdf/2601.10765", "abs": "https://arxiv.org/abs/2601.10765", "authors": ["Zubair Shah", "Noaman Khan"], "title": "Pruning as Evolution: Emergent Sparsity Through Selection Dynamics in Neural Networks", "categories": ["cs.NE"], "comment": null, "summary": "Neural networks are commonly trained in highly overparameterized regimes, yet empirical evidence consistently shows that many parameters become redundant during learning. Most existing pruning approaches impose sparsity through explicit intervention, such as importance-based thresholding or regularization penalties, implicitly treating pruning as a centralized decision applied to a trained model. This assumption is misaligned with the decentralized, stochastic, and path-dependent character of gradient-based training. We propose an evolutionary perspective on pruning: parameter groups (neurons, filters, heads) are modeled as populations whose influence evolves continuously under selection pressure. Under this view, pruning corresponds to population extinction: components with persistently low fitness gradually lose influence and can be removed without discrete pruning schedules and without requiring equilibrium computation. We formalize neural pruning as an evolutionary process over population masses, derive selection dynamics governing mass evolution, and connect fitness to local learning signals. We validate the framework on MNIST using a population-scaled MLP (784--512--256--10) with 768 prunable neuron populations. All dynamics reach dense baselines near 98\\% test accuracy. We benchmark post-training hard pruning at target sparsity levels (35--50\\%): pruning 35\\% yields $\\approx$95.5\\% test accuracy, while pruning 50\\% yields $\\approx$88.3--88.6\\%, depending on the dynamic. These results demonstrate that evolutionary selection produces a measurable accuracy--sparsity tradeoff without explicit pruning schedules during training.", "AI": {"tldr": "本文提出了一种基于进化论的剪枝方法，通过模拟自然选择压力下的群体演化过程来实现神经网络中的参数剪枝。", "motivation": "传统的剪枝方法依赖于显式的干预手段，如重要性阈值或正则化惩罚，这种方法与神经网络训练过程中分散、随机和路径依赖的特点不相符。本文希望通过一种新的视角重新定义剪枝过程。", "method": "将参数群体视为在选择压力下不断进化的种群，剪枝被视为某些低适应度组分的灭绝过程。通过建立神经网络中的进化模型来描述种群质量演化的选择动态，并连接局部学习信号与适应度。", "result": "在MNIST数据集上验证了该框架的有效性，使用了一个具有768个可剪枝神经元群体的多层感知器网络。实验表明，在35%和50%的目标稀疏水平下分别能达到约95.5%和88.3-88.6%的测试准确率。", "conclusion": "研究表明，通过进化选择产生的准确性与稀疏性之间的可测量折衷关系无需在训练过程中使用显式的剪枝计划。"}}
{"id": "2601.10754", "pdf": "https://arxiv.org/pdf/2601.10754", "abs": "https://arxiv.org/abs/2601.10754", "authors": ["Hsuen-Chi Chiu", "Jeremy Foote"], "title": "Chatting with Confidants or Corporations? Privacy Management with AI Companions", "categories": ["cs.CR", "cs.CY", "cs.HC"], "comment": null, "summary": "AI chatbots designed as emotional companions blur the boundaries between interpersonal intimacy and institutional software, creating a complex, multi-dimensional privacy environment. Drawing on Communication Privacy Management theory and Masur's horizontal (user-AI) and vertical (user-platform) privacy framework, we conducted in-depth interviews with fifteen users of companion AI platforms such as Replika and Character.AI. Our findings reveal that users blend interpersonal habits with institutional awareness: while the non-judgmental, always-available nature of chatbots fosters emotional safety and encourages self-disclosure, users remain mindful of institutional risks and actively manage privacy through layered strategies and selective sharing. Despite this, many feel uncertain or powerless regarding platform-level data control. Anthropomorphic design further blurs privacy boundaries, sometimes leading to unintentional oversharing and privacy turbulence. These results extend privacy theory by highlighting the unique interplay of emotional and institutional privacy management in human-AI companionship.", "AI": {"tldr": "探讨了用户在与AI伴侣聊天时如何管理隐私。", "motivation": "研究情感陪伴型AI聊天机器人模糊了个人亲密关系和机构软件之间的界限，探究在这种复杂环境中用户的隐私管理策略。", "method": "基于沟通隐私管理和Masur的水平及垂直隐私框架理论，对使用如Replika和Character.AI平台的15名用户进行了深入访谈。", "result": "发现用户将人际习惯与机构意识相结合，在享受AI聊天机器人带来的安全感同时，也积极通过分层策略和选择性分享来管理隐私。但仍感到对于平台级数据控制不确定或无能为力。", "conclusion": "研究结果扩展了隐私理论，强调在人机陪伴中情感隐私管理和机构隐私管理的独特交互作用。"}}
{"id": "2601.10748", "pdf": "https://arxiv.org/pdf/2601.10748", "abs": "https://arxiv.org/abs/2601.10748", "authors": ["Jun Li", "Hongling Zhu", "Yujie Xiao", "Qinghao Zhao", "Yalei Ke", "Gongzheng Tang", "Guangkun Nie", "Deyun Zhang", "Jin Li", "Canqing Yu", "Shenda Hong"], "title": "AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "in progress", "summary": "Background: Artificial intelligence enabled electrocardiography (AI-ECG) has demonstrated the ability to detect diverse pathologies, but most existing models focus on single disease identification, neglecting comorbidities and future risk prediction. Although ECGFounder expanded cardiac disease coverage, a holistic health profiling model remains needed. Methods: We constructed a large multicenter dataset comprising 13.3 million ECGs from 2.98 million patients. Using transfer learning, ECGFounder was fine-tuned to develop AnyECG, a foundation model for holistic health profiling. Performance was evaluated using external validation cohorts and a 10-year longitudinal cohort for current diagnosis, future risk prediction, and comorbidity identification. Results: AnyECG demonstrated systemic predictive capability across 1172 conditions, achieving an AUROC greater than 0.7 for 306 diseases. The model revealed novel disease associations, robust comorbidity patterns, and future disease risks. Representative examples included high diagnostic performance for hyperparathyroidism (AUROC 0.941), type 2 diabetes (0.803), Crohn disease (0.817), lymphoid leukemia (0.856), and chronic obstructive pulmonary disease (0.773). Conclusion: The AnyECG foundation model provides substantial evidence that AI-ECG can serve as a systemic tool for concurrent disease detection and long-term risk prediction.", "AI": {"tldr": "开发了一种名为AnyECG的基础模型，用于全面健康状况评估。", "motivation": "现有的AI-ECG模型多专注于单一疾病检测，忽视了共病和未来风险预测的需求。尽管有ECGFounder扩展了心脏疾病的覆盖范围，但仍需要一个能够进行整体健康状况评估的模型。", "method": "构建了一个包含13.3百万份心电图数据的大规模多中心数据集，涉及298万患者；利用迁移学习对ECGFounder进行了微调，并开发了AnyECG基础模型；通过外部验证队列和十年纵向队列评估了该模型在当前疾病诊断、未来风险预测及共病识别方面的性能。", "result": "AnyECG在1172种条件下展示了系统的预测能力，在306种疾病中达到了大于0.7的AUROC值；模型揭示了新的疾病关联性、强大的共病模式和未来的疾病风险，例如对于高诊断表现的甲状旁腺功能亢进（AUROC 0.941）、二型糖尿病（0.803）、克罗恩氏病（0.817）、淋巴样白血病（0.856）和慢性阻塞性肺疾病（0.773）。", "conclusion": "AnyECG基础模型为AI-ECG可以作为系统工具进行并发性疾病检测和长期风险预测提供了重要证据。"}}
{"id": "2601.10744", "pdf": "https://arxiv.org/pdf/2601.10744", "abs": "https://arxiv.org/abs/2601.10744", "authors": ["Sen Wang", "Bangwei Liu", "Zhenkun Gao", "Lizhuang Ma", "Xuhong Wang", "Yuan Xie", "Xin Tan"], "title": "Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration", "categories": ["cs.AI", "cs.CV"], "comment": "Our dataset and code will be released at our \\href{https://wangsen99.github.io/papers/lmee/}{website}", "summary": "An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.", "AI": {"tldr": "本文提出了Long-term Memory Embodied Exploration (LMEE)框架和相应的数据集与基准LMEE-Bench，旨在通过强化学习微调多模态大语言模型来增强代理的记忆召回和主动探索能力。", "motivation": "现有的主流一次性实体任务主要关注任务完成结果，忽略了探索过程和记忆利用的重要性。本文希望通过整合长期记忆和决策行为来促进终身学习的实现。", "method": "提出了MemoryExplorer方法，通过强化学习微调多模态大语言模型，采用包含动作预测、边界选择和问题回答在内的多任务奖励函数来鼓励主动查询记忆。", "result": "实验表明，与最先进的实体探索模型相比，本文的方法在长时域实体任务上取得了显著优势。", "conclusion": "通过强化学习微调多模态大语言模型并引入长期记忆机制可以有效提升代理的主动探索能力和决策质量。"}}
{"id": "2601.10742", "pdf": "https://arxiv.org/pdf/2601.10742", "abs": "https://arxiv.org/abs/2601.10742", "authors": ["Amélie Gruel", "Pierre Lewden", "Adrien F. Vincent", "Sylvain Saïghi"], "title": "Line-based Event Preprocessing: Towards Low-Energy Neuromorphic Computer Vision", "categories": ["cs.NE", "cs.AI", "cs.CV", "eess.IV"], "comment": "18 pages (3 pages of acknowledgments and references), 10 figures and 4 tables. Submitted to the IOP Science \"Neuromorphic Computing and Engineering\" journal, awaiting feedback. This work is supported by a public grant overseen by the French National Research Agency (ANR) as part of the éPEPR IA France 2030é programme (Emergences project ANR-23-PEIA-0002)", "summary": "Neuromorphic vision made significant progress in recent years, thanks to the natural match between spiking neural networks and event data in terms of biological inspiration, energy savings, latency and memory use for dynamic visual data processing. However, optimising its energy requirements still remains a challenge within the community, especially for embedded applications. One solution may reside in preprocessing events to optimise data quantity thus lowering the energy cost on neuromorphic hardware, proportional to the number of synaptic operations. To this end, we extend an end-to-end neuromorphic line detection mechanism to introduce line-based event data preprocessing. Our results demonstrate on three benchmark event-based datasets that preprocessing leads to an advantageous trade-off between energy consumption and classification performance. Depending on the line-based preprocessing strategy and the complexity of the classification task, we show that one can maintain or increase the classification accuracy while significantly reducing the theoretical energy consumption. Our approach systematically leads to a significant improvement of the neuromorphic classification efficiency, thus laying the groundwork towards a more frugal neuromorphic computer vision thanks to event preprocessing.", "AI": {"tldr": "本文提出了基于线的事件预处理方法，以提高神经形态计算机视觉的能效和分类性能。", "motivation": "尽管神经形态视觉在近年来取得了显著进展，但优化其能量需求仍然是一个挑战，尤其是在嵌入式应用中，因此希望通过改进数据量来降低能耗。", "method": "本文扩展了一种端到端的神经形态线检测机制，引入了基于线的事件数据预处理方法。", "result": "实验结果表明，在三个基准事件数据集上，通过使用不同的线基预处理策略和任务复杂性，可以保持或提高分类准确性的同时显著降低理论上的能耗。", "conclusion": "研究结果为实现更节能的神经形态计算机视觉奠定了基础，并证明了事件预处理在提升能效方面的有效性。"}}
{"id": "2601.10740", "pdf": "https://arxiv.org/pdf/2601.10740", "abs": "https://arxiv.org/abs/2601.10740", "authors": ["Anas Hajbi"], "title": "Neuro-Symbolic Activation Discovery: Transferring Mathematical Structures from Physics to Ecology for Parameter-Efficient Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "Modern neural networks rely on generic activation functions (ReLU, GELU, SiLU) that ignore the mathematical structure inherent in scientific data. We propose Neuro-Symbolic Activation Discovery, a framework that uses Genetic Programming to extract interpretable mathematical formulas from data and inject them as custom activation functions. Our key contribution is the discovery of a Geometric Transfer phenomenon: activation functions learned from particle physics data successfully generalize to ecological classification, outperforming standard activations (ReLU, GELU, SiLU) in both accuracy and parameter efficiency. On the Forest Cover dataset, our Hybrid Transfer model achieves 82.4% accuracy with only 5,825 parameters, compared to 83.4% accuracy requiring 31,801 parameters for a conventional heavy network -- a 5.5x parameter reduction with only 1% accuracy loss. We introduce a Parameter Efficiency Score ($E_{param} = AUC / \\log_{10}(Params)$) and demonstrate that lightweight hybrid architectures consistently achieve 18-21% higher efficiency than over-parameterized baselines. Crucially, we establish boundary conditions: while Physics to Ecology transfer succeeds (both involve continuous Euclidean measurements), Physics to Text transfer fails (discrete word frequencies require different mathematical structures). Our work opens pathways toward domain-specific activation libraries for efficient scientific machine learning.", "AI": {"tldr": "本文提出Neuro-Symbolic Activation Discovery框架，通过遗传编程从数据中提取可解释的数学公式并作为自定义激活函数注入神经网络，在参数效率和精度方面优于传统激活函数。", "motivation": "现代神经网络依赖于忽略科学数据内在数学结构的通用激活函数，本文旨在发现可以转移跨学科应用的有效激活函数，提高模型在参数效率上的表现。", "method": "使用遗传编程提取数学公式作为激活函数，并展示了从粒子物理学数据中学习到的激活函数成功应用于生态分类任务的现象。", "result": "提出的Hybrid Transfer模型在Forest Cover数据集上达到了82.4%的准确率，仅需5,825个参数，比传统重网络减少了5.5倍的参数量，并提高了18-21%的参数效率评分。", "conclusion": "研究发现物理学到生态学领域的转移成功是因为两者都涉及连续欧几里得测量；该工作为领域特定激活函数库的发展提供了新途径。"}}
{"id": "2601.10738", "pdf": "https://arxiv.org/pdf/2601.10738", "abs": "https://arxiv.org/abs/2601.10738", "authors": ["Percy Jardine"], "title": "CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems", "categories": ["cs.AI"], "comment": null, "summary": "Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.", "AI": {"tldr": "本文提出了一个名为CTHA的框架，旨在解决多时间尺度代理架构中的协调稳定性问题。", "motivation": "传统的单循环范式通过引入具有不同认知层的时间层次结构得到了扩展，但这种多样化从根本上破坏了统一系统中固有的协调稳定性和可伸缩性。因此，本文提出了一个名为CTHA的框架来恢复协调稳定性并确保决策的一致性。", "method": "CTHA通过三个关键约束来实现其目标：（1）消息合同约束，形式化各层之间的信息流；（2）权威流形约束，限制每个层次的决策空间；（3）仲裁者解决约束，保证多层决策无冲突组合。", "result": "实验表明，CTHA在复杂任务执行中表现出色，减少了47%的失败级联现象，样本效率提高了2.3倍，并且相比不受约束的时间层次基线具有更好的可扩展性。", "conclusion": "CTHA作为一个时间层级结构的原则性扩展，对多代理协调的理解做出了贡献，并为稳健自主系统的发展提供了潜在的方向。"}}
{"id": "2601.10737", "pdf": "https://arxiv.org/pdf/2601.10737", "abs": "https://arxiv.org/abs/2601.10737", "authors": ["Giuseppe Romano", "Rodrigo Arrieta", "Steven G. Johnson"], "title": "Differentiating through binarized topology changes: Second-order subpixel-smoothed projection", "categories": ["eess.SP", "cond-mat.mtrl-sci", "cs.CV", "math.OC"], "comment": null, "summary": "A key challenge in topology optimization (TopOpt) is that manufacturable structures, being inherently binary, are non-differentiable, creating a fundamental tension with gradient-based optimization. The subpixel-smoothed projection (SSP) method addresses this issue by smoothing sharp interfaces at the subpixel level through a first-order expansion of the filtered field. However, SSP does not guarantee differentiability under topology changes, such as the merging of two interfaces, and therefore violates the convergence guarantees of many popular gradient-based optimization algorithms. We overcome this limitation by regularizing SSP with the Hessian of the filtered field, resulting in a twice-differentiable projected density during such transitions, while still guaranteeing an almost-everywhere binary structure. We demonstrate the effectiveness of our second-order SSP (SSP2) methodology on both thermal and photonic problems, showing that SSP2 has faster convergence than SSP for connectivity-dominant cases -- where frequent topology changes occur -- while exhibiting comparable performance otherwise. Beyond improving convergence guarantees for CCSA optimizers, SSP2 enables the use of a broader class of optimization algorithms with stronger theoretical guarantees, such as interior-point methods. Since SSP2 adds minimal complexity relative to SSP or traditional projection schemes, it can be used as a drop-in replacement in existing TopOpt codes.", "AI": {"tldr": "本文提出了一种二次平滑子像素投影（SSP2）方法，解决了传统拓扑优化中由于结构二值化导致的非可微问题，并展示了该方法在热学和光学问题中的有效性。", "motivation": "传统的子像素平滑投影（SSP）方法不能保证在拓扑变化时的可微性，这限制了其与基于梯度的优化算法的有效结合。本文旨在通过改进SSP方法来克服这一局限，并提高收敛性能。", "method": "本文提出了一种二次平滑子像素投影（SSP2），通过引入过滤字段的Hessian矩阵进行正则化处理，使得在拓扑变化时仍能保持两次可微性，同时保证结构几乎处处为二值。", "result": "实验结果表明，在涉及频繁拓扑变化的情形下，SSP2比传统的SSP方法具有更快的收敛速度，并且在其他情况下表现出相近的效果。", "conclusion": "本文提出的SSP2方法不仅改善了收敛性能，还允许使用具更强理论保证的优化算法如内点法，而且由于其增加的复杂性较小，可以作为现有拓扑优化代码中的直接替换方案。"}}
{"id": "2601.10733", "pdf": "https://arxiv.org/pdf/2601.10733", "abs": "https://arxiv.org/abs/2601.10733", "authors": ["Jakob Struye", "Nabeel Nisar Bhat", "Siddhartha Kumar", "Mohammad Hossein Moghaddam", "Jeroen Famaey"], "title": "Millimeter-Wave Gesture Recognition in ISAC: Does Reducing Sensing Airtime Hamper Accuracy?", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Most Integrated Sensing and Communications (ISAC) systems require dividing airtime across their two modes. However, the specific impact of this decision on sensing performance remains unclear and underexplored. In this paper, we therefore investigate the impact on a gesture recognition system using a Millimeter-Wave (mmWave) ISAC system. With our dataset of power per beam pair gathered with two mmWave devices performing constant beam sweeps while test subjects performed distinct gestures, we train a gesture classifier using Convolutional Neural Networks. We then subsample these measurements, emulating reduced sensing airtime, showing that a sensing airtime of 25 % only reduces classification accuracy by 0.15 percentage points from full-time sensing. Alongside this high-quality sensing at low airtime, mmWave systems are known to provide extremely high data throughputs, making mmWave ISAC a prime enabler for applications such as truly wireless Extended Reality.", "AI": {"tldr": "研究了毫米波ISAC系统在减少传感空闲时间的情况下手势识别的准确性影响。", "motivation": "大多数集成感应和通信(ISAC)系统需要将空闲时间分配给其两种模式，但这种决策对感应性能的影响尚不清楚且未被充分探索。本文探讨了一个使用毫米波(mmWave)ISAC系统的手势识别系统在这种情况下会有什么样的表现。", "method": "使用两个毫米波设备收集一组数据集，在执行恒定的波束扫描的同时测试受试者进行不同的手势，使用卷积神经网络训练手势分类器，并对这些测量值进行子采样以模拟减少传感空闲时间的影响。", "result": "发现25%的传感空闲时间仅使分类准确度降低0.15个百分点，与全时感应相比影响较小。", "conclusion": "毫米波ISAC系统可以在较低的空闲时间内提供高质量的传感，并且提供极高的数据吞吐量，使其成为真正无线扩展现实应用的理想选择。"}}
{"id": "2601.10729", "pdf": "https://arxiv.org/pdf/2601.10729", "abs": "https://arxiv.org/abs/2601.10729", "authors": ["Xinyue Ma", "Heelim Hong", "Taegeon Um", "Jongseop Lee", "Seoyeong Choy", "Woo-Yeon Lee", "Myeongjae Jeon"], "title": "ORBITFLOW: SLO-Aware Long-Context LLM Serving with Fine-Grained KV Cache Reconfiguration", "categories": ["cs.AI", "cs.LG", "cs.PF"], "comment": "Accepted at the 52nd International Conference on Very Large Data Bases (VLDB 2026). Xinyue Ma and Heelim Hong contributed equally (co-first authors)", "summary": "Serving long-context LLMs is challenging because request lengths and batch composition vary during token generation, causing the memory footprint to fluctuate significantly at runtime. Offloading KV caches to host memory limits effective memory usage, but existing static and predetermined offloading strategies cannot adapt to the rapidly shifting memory demands of long-context serving. This often leads to excessive CPU-to-GPU KV transfers that translate into latency spikes and frequent SLO violations. To address these challenges, we introduce ORBITFLOW, a fine-grained and adaptive KV cache management system that meets latency SLOs in long-context LLM serving. ORBITFLOW employs a lightweight ILP solver to decide which layers' KV caches to retain on the GPU for each request, within memory capacity constraints. It continuously refines KV placements based on runtime feedback when the active plan becomes suboptimal during token generation. Under heavy load, ORBITFLOW invokes a fallback mechanism to temporarily defer in-flight requests with large memory footprints, preserving overall SLO attainment. Our experiments demonstrate that ORBITFLOW improves SLO attainment for TPOT and TBT by up to 66% and 48%, respectively, while reducing the 95th percentile latency by 38% and achieving up to 3.3x higher throughput compared to existing offloading methods.", "AI": {"tldr": "介绍了一种名为ORBITFLOW的细粒度自适应KV缓存管理系统，以在长上下文LLM服务中满足延迟SLO。", "motivation": "处理长上下文的LLMs时，请求长度和批次组成的变化导致内存占用大幅波动，现有的静态预设卸载策略无法适应这种快速变化的需求，导致频繁的CPU到GPU KV缓存转移，产生延迟峰值并经常违反SLO。", "method": "ORBITFLOW使用轻量级整数线性规划（ILP）求解器来决定哪些层的KV缓存在每个请求中保留在GPU上，并根据运行时反馈持续调整KV位置。在高负载下，它会暂时推迟占用大量内存的请求以保证整体SLO。", "result": "实验显示ORBITFLOW将TPOT和TBT的SLO满足度分别提高了66%和48%，同时降低了95百分位数延迟38%，并实现了高达3.3倍的吞吐量提升。", "conclusion": "ORBITFLOW系统通过自适应管理KV缓存，解决了长上下文LLMs服务中的内存使用问题，并显著提升了SLO满足度、延迟性能和吞吐量。"}}
{"id": "2601.10726", "pdf": "https://arxiv.org/pdf/2601.10726", "abs": "https://arxiv.org/abs/2601.10726", "authors": ["Ross Chu", "Yuting Huang"], "title": "Building AI Agents to Improve Job Referral Requests to Strangers", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.", "AI": {"tldr": "本文开发了AI代理，帮助求职者撰写有效的职业在线社区中的工作推荐请求。", "motivation": "动机是提高弱请求的成功率，同时不降低强请求的表现，并且在真实用户测试前提供低成本的性能信号。", "method": "使用改进者代理重写推荐请求，评估者代理通过训练模型预测从其他用户获得推荐的概率来衡量修订质量。增强大语言模型（LLM）与检索增强生成（RAG），以防止削弱强请求并改善弱请求。", "result": "应用了RAG的LLM修订将弱请求的成功率提高了14%，且不损害强请求的表现。", "conclusion": "虽然模型预测的成功并不保证现实中的更多推荐，但它们为更高风险的真实用户实验提供了低成本的信号。"}}
{"id": "2601.10725", "pdf": "https://arxiv.org/pdf/2601.10725", "abs": "https://arxiv.org/abs/2601.10725", "authors": ["Hieu Do Quang", "Chien Truong-Quoc", "Quoc Van Tran"], "title": "Multi-Agent Formation Navigation Using Diffusion-Based Trajectory Generation", "categories": ["cs.RO", "math.OC"], "comment": "8 pages, 3 figures, full version of a paper submitted to a conference", "summary": "This paper introduces a diffusion-based planner for leader--follower formation control in cluttered environments. The diffusion policy is used to generate the trajectory of the midpoint of two leaders as a rigid bar in the plane, thereby defining their desired motion paths in a planar formation. While the followers track the leaders and form desired foramtion geometry using a distance-constrained formation controller based only on the relative positions in followers' local coordinates. The proposed approach produces smooth motions and low tracking errors, with most failures occurring in narrow obstacle-free space, or obstacle configurations that are not in the training data set. Simulation results demonstrate the potential of diffusion models for reliable multi-agent formation planning.", "AI": {"tldr": "本文介绍了一种基于扩散的规划器，用于在复杂环境中进行多智能体编队导航。", "motivation": "为了实现多智能体在复杂环境中的可靠编队控制，提出一种新的方法来生成平滑且低跟踪误差的轨迹。", "method": "该研究使用扩散策略生成两位领导者之间中点的轨迹作为平面内的刚性杆，并定义了它们的期望运动路径。跟随者则根据本地坐标系中的相对位置进行追踪并形成期望的编队几何形状。", "result": "实验结果表明，所提出的方法可以产生平滑且低跟踪误差的动作，在狭窄无障碍空间或训练数据集之外的障碍物配置中可能会失败。", "conclusion": "扩散模型在可靠多智能体编队规划方面具有潜力。"}}
{"id": "2601.10724", "pdf": "https://arxiv.org/pdf/2601.10724", "abs": "https://arxiv.org/abs/2601.10724", "authors": ["Rishabh Dev Yadav"], "title": "Adaptive Sliding Mode Control for Vehicle Platoons with State-Dependent Friction Uncertainty", "categories": ["cs.RO"], "comment": "Extended version based on the author MSc thesis. Related to an earlier IEEE ICAR 2021 publication", "summary": "Multi-robot formation control has various applications in domains such as vehicle troops, platoons, payload transportation, and surveillance. Maintaining formation in a vehicle platoon requires designing a suitable control scheme that can tackle external disturbances and uncertain system parameters while maintaining a predefined safe distance between the robots. A crucial challenge in this context is dealing with the unknown/uncertain friction forces between wheels and the ground, which vary with changes in road surface, wear in tires, and speed of the vehicle. Although state-of-the-art adaptive controllers can handle a priori bounded uncertainties, they struggle with accurately modeling and identifying frictional forces, which are often state-dependent and cannot be a priori bounded. This thesis proposes a new adaptive sliding mode controller for wheeled mobile robot-based vehicle platoons that can handle the unknown and complex behavior of frictional forces without prior knowledge of their parameters and structures. The controller uses the adaptive sliding mode control techniques to regulate the platoon's speed and maintain a predefined inter-robot distance, even in the presence of external disturbances and uncertain system parameters. This approach involves a two-stage process: first, the kinematic controller calculates the desired velocities based on the desired trajectory; and second, the dynamics model generates the commands to achieve the desired motion. By separating the kinematics and dynamics of the robot, this approach can simplify the control problem and allow for more efficient and robust control of the wheeled mobile robot.", "AI": {"tldr": "本文提出了一种新的自适应滑模控制策略，用于处理车辆编队中未知且复杂的摩擦力问题。", "motivation": "维持车辆编队的形成需要设计一种能够应对外部干扰和系统参数不确定性的控制方案，并保持机器人之间的预设安全距离。尤其重要的是，如何处理轮胎与地面之间未知或不确定的摩擦力是关键挑战之一。", "method": "本文提出了一种新的自适应滑模控制器，用于基于轮式移动机器人的车辆编队中，该控制器可以应对未知和复杂的摩擦力行为，即使没有这些参数和结构的先验知识也能工作。控制方案包括一个两阶段过程：首先计算基于所需轨迹的理想速度；其次生成命令以实现所需的运动。", "result": "这种控制策略通过分离机器人的动力学与运动学简化了控制问题，并允许对轮式移动机器人进行更高效、更稳健的控制，即使在存在外部干扰和系统参数不确定性的情况下也能保持编队的速度并维持预设的距离。", "conclusion": "本文提出的方法证明了其在处理车辆编队中摩擦力不确定性和复杂行为的有效性，表明该方法能够实现更加稳定和高效的编队控制。"}}
{"id": "2601.10723", "pdf": "https://arxiv.org/pdf/2601.10723", "abs": "https://arxiv.org/abs/2601.10723", "authors": ["Xu Yang", "Wei Yang", "Kaibo He", "Bo Yang", "Yanan Sui", "Yilin Mo"], "title": "Energy-Efficient Omnidirectional Locomotion for Wheeled Quadrupeds via Predictive Energy-Aware Nominal Gait Selection", "categories": ["cs.RO"], "comment": "Published in IEEE IROS 2025", "summary": "Wheeled-legged robots combine the efficiency of wheels with the versatility of legs, but face significant energy optimization challenges when navigating diverse environments. In this work, we present a hierarchical control framework that integrates predictive power modeling with residual reinforcement learning to optimize omnidirectional locomotion efficiency for wheeled quadrupedal robots. Our approach employs a novel power prediction network that forecasts energy consumption across different gait patterns over a 1-second horizon, enabling intelligent selection of the most energy-efficient nominal gait. A reinforcement learning policy then generates residual adjustments to this nominal gait, fine-tuning the robot's actions to balance energy efficiency with performance objectives. Comparative analysis shows our method reduces energy consumption by up to 35\\% compared to fixed-gait approaches while maintaining comparable velocity tracking performance. We validate our framework through extensive simulations and real-world experiments on a modified Unitree Go1 platform, demonstrating robust performance even under external disturbances. Videos and implementation details are available at \\href{https://sites.google.com/view/switching-wpg}{https://sites.google.com/view/switching-wpg}.", "AI": {"tldr": "本文提出了一种分层控制框架，通过预测性能量模型和残差强化学习优化了轮腿式四足机器人的全方位行走能效。", "motivation": "为了克服轮腿机器人在不同环境中导航时面临的能源优化挑战，旨在结合车轮的效率与腿部的灵活性，并提高其能效。", "method": "该方法使用一个新的能量预测网络来预测不同步态模式下的能耗，并通过强化学习策略对基础步态进行调整，以实现性能和能效之间的平衡。", "result": "实验结果表明，相较于固定步态的方法，本文提出的方法能够将能耗降低高达35%，同时保持相似的速度追踪性能。", "conclusion": "该框架通过仿真和真实世界实验得到了验证，在外部干扰下也表现出鲁棒的性能。"}}
{"id": "2601.10722", "pdf": "https://arxiv.org/pdf/2601.10722", "abs": "https://arxiv.org/abs/2601.10722", "authors": ["Daniel Casini", "Jian-Jia Chen", "Jing Li", "Federico Reghenzani", "Harun Teper"], "title": "A Survey of Real-Time Support, Analysis, and Advancements in ROS 2", "categories": ["cs.RO", "cs.DC", "cs.SE"], "comment": null, "summary": "The Robot Operating System 2 (ROS~2) has emerged as a relevant middleware framework for robotic applications, offering modularity, distributed execution, and communication. In the last six years, ROS~2 has drawn increasing attention from the real-time systems community and industry. This survey presents a comprehensive overview of research efforts that analyze, enhance, and extend ROS~2 to support real-time execution. We first provide a detailed description of the internal scheduling mechanisms of ROS~2 and its layered architecture, including the interaction with DDS-based communication and other communication middleware. We then review key contributions from the literature, covering timing analysis for both single- and multi-threaded executors, metrics such as response time, reaction time, and data age, and different communication modes. The survey also discusses community-driven enhancements to the ROS~2 runtime, including new executor algorithm designs, real-time GPU management, and microcontroller support via micro-ROS. Furthermore, we summarize techniques for bounding DDS communication delays, message filters, and profiling tools that have been developed to support analysis and experimentation. To help systematize this growing body of work, we introduce taxonomies that classify the surveyed contributions based on different criteria. This survey aims to guide both researchers and practitioners in understanding and improving the real-time capabilities of ROS~2.", "AI": {"tldr": "该论文是对ROS 2实时支持、分析和进展的综述。", "motivation": "随着ROS 2在过去六年中在实时系统社区和工业界引起了越来越多的关注，本文旨在全面概述研究工作，以分析、增强和扩展ROS 2以支持实时执行。", "method": "论文详细描述了ROS 2内部调度机制及其分层架构，并审查了关键贡献，包括单线程和多线程执行器的时间分析，响应时间等指标以及不同的通信模式。此外，还介绍了社区驱动的增强功能和技术分类法。", "result": "本文综述了用于实时GPU管理、微控制器支持（通过micro-ROS）的新执行程序算法设计，并总结了用于限制DDS通信延迟的技术和配置工具。", "conclusion": "该调查旨在指导研究人员和从业者了解并改善ROS 2的实时能力。"}}
{"id": "2601.10721", "pdf": "https://arxiv.org/pdf/2601.10721", "abs": "https://arxiv.org/abs/2601.10721", "authors": ["Xinyu Li", "Qian Tang", "Guoxin Yin", "Gang Zheng", "Jessica Burgner-Kahrs", "Cesare Stefanini", "Ke Wu"], "title": "Collaborative Continuum Robots: A Survey", "categories": ["cs.RO"], "comment": null, "summary": "Continuum robots (CRs), owing to their compact structure, inherent compliance, and flexible deformation, have been widely applied in various fields. By coordinating multiple CRs to form collaborative continuum robots (CCRs), task adaptability, workspace, flexibility, load capacity, and operational stability can be further improved, thus offering significant advantages. In recent years, interest in this emerging field has grown steadily within the continuum-robotics community, accompanied by a consistent rise in related publications. By presenting a comprehensive overview of recent progress from different system-architecture levels, this survey provides a clear framework for research on CCRs. First, CCRs are classified into the three collaboration modes of separated collaboration, assistance collaboration, and parallel collaboration, with definitions provided. Next, advances in structural design, modeling, motion planning, and control for each mode are systematically summarized. Finally, current challenges and future opportunities for CCRs are discussed.", "AI": {"tldr": "本文综述了协作连续体机器人（CCR）的进展，包括其分类、设计、建模、运动规划和控制方法。", "motivation": "通过协调多个连续体机器人形成协作系统，可以进一步提高任务适应性、工作空间、灵活性、承载能力和操作稳定性，因此作者对这一新兴领域进行了综述。", "method": "本文将CCR分为分离协作、辅助协作和平行协作三种模式，并从结构设计、建模、运动规划和控制等方面对其进展进行了系统的总结。", "result": "提供了关于CCR研究的清晰框架，概述了不同系统架构层次上的最新进展。", "conclusion": "讨论了目前CCR面临的主要挑战和未来的研究机会。"}}
{"id": "2601.10720", "pdf": "https://arxiv.org/pdf/2601.10720", "abs": "https://arxiv.org/abs/2601.10720", "authors": ["Atef Azaiez", "Alireza David Anisi"], "title": "Verified Design of Robotic Autonomous Systems using Probabilistic Model Checking", "categories": ["cs.RO"], "comment": "Accepted in ModelSWARD 2026 conference, 7 figures", "summary": "Safety and reliability play a crucial role when designing Robotic Autonomous Systems (RAS). Early consideration of hazards, risks and mitigation actions -- already in the concept study phase -- are important steps in building a solid foundations for the subsequent steps in the system engineering life cycle. The complex nature of RAS, as well as the uncertain and dynamic environments the robots operate within, do not merely effect fault management and operation robustness, but also makes the task of system design concept selection, a hard problem to address. Approaches to tackle the mentioned challenges and their implications on system design, range from ad-hoc concept development and design practices, to systematic, statistical and analytical techniques of Model Based Systems Engineering. In this paper, we propose a methodology to apply a formal method, namely Probabilistic Model Checking (PMC), to enable systematic evaluation and analysis of a given set of system design concepts, ultimately leading to a set of Verified Designs (VD). We illustrate the application of the suggested methodology -- using PRISM as probabilistic model checker -- to a practical RAS concept selection use-case from agriculture robotics. Along the way, we also develop and present a domain-specific Design Evaluation Criteria for agri-RAS.", "AI": {"tldr": "本文提出了一种方法，通过使用概率模型检查（PMC）来系统地评估和分析一组系统设计概念，以获得经过验证的设计。", "motivation": "鉴于机器人自主系统的复杂性和不确定的操作环境，需要一种正式的方法来确保其安全和可靠性，在早期的概念研究阶段考虑危害、风险及缓解措施是关键步骤。", "method": "本文提出了一种使用概率模型检查（PMC）的系统方法，并利用PRISM工具对农业机器人的一个实际概念选择案例进行分析，同时开发了针对农业机器人领域的设计评估标准。", "result": "通过该方法在农业机器人领域应用展示了其有效性，并发展出了一套特定领域的设计评估准则。", "conclusion": "概率模型检查是一种有效的手段，可以帮助系统地评价和分析机器人自主系统的不同设计方案，从而提高其安全性和可靠性。"}}
{"id": "2601.10719", "pdf": "https://arxiv.org/pdf/2601.10719", "abs": "https://arxiv.org/abs/2601.10719", "authors": ["Gerard Yeo", "Svetlana Churina", "Kokil Jaidka"], "title": "Do You Trust Me? Cognitive-Affective Signatures of Trustworthiness in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Perceived trustworthiness underpins how users navigate online information, yet it remains unclear whether large language models (LLMs),increasingly embedded in search, recommendation, and conversational systems, represent this construct in psychologically coherent ways. We analyze how instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encode perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Across models, systematic layer- and head-level activation differences distinguish high- from low-trust texts, revealing that trust cues are implicitly encoded during pretraining. Probing analyses show linearly de-codable trust signals and fine-tuning effects that refine rather than restructure these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self -- dimensions central to human trust formation online. These findings demonstrate that modern LLMs internalize psychologically grounded trust signals without explicit supervision, offering a representational foundation for designing credible, transparent, and trust-worthy AI systems in the web ecosystem. Code and appendix are available at: https://github.com/GerardYeo/TrustworthinessLLM.", "AI": {"tldr": "研究分析大型语言模型在心理上如何编码可信度，并展示了这些模型如何内部化心理学意义上的信任信号。", "motivation": "由于用户在线浏览信息时依赖于感知的可信度，但尚未明确大型语言模型是否以心理连贯的方式表示这种概念，因此本研究旨在探索这一问题。", "method": "使用PEACE-Reviews数据集对指令微调后的大型语言模型（如Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B）进行分析，以评估它们如何在类似网页的叙述中编码感知的信任度。", "result": "研究发现，不同信任程度的文字之间的系统层和头级别激活差异明显，并且通过线性解码可以找到可信信号。这些模型对公平、确定性和自我问责等维度有最强关联。", "conclusion": "现代大型语言模型能够在没有明确监督的情况下内部化基于心理学的信任信号，为设计在web生态系统中值得信赖的人工智能系统奠定了基础。"}}
{"id": "2601.10718", "pdf": "https://arxiv.org/pdf/2601.10718", "abs": "https://arxiv.org/abs/2601.10718", "authors": ["Junyu Liu", "Siwen Yang", "Dexiu Ma", "Qian Niu", "Zequn Zhang", "Momoko Nagai-Tanima", "Tomoki Aoyama"], "title": "Japanese AI Agent System on Human Papillomavirus Vaccination: System Design", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": null, "summary": "Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse. This study aimed to develop a dual-purpose AI agent system that provides verified HPV vaccine information through a conversational interface while generating analytical reports for medical institutions based on user interactions and social media. We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification. Performance was assessed using a 0-5 scoring scale. For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods. This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication. The architecture enables verified information delivery with source attribution while providing systematic public discourse analysis, with a transferable framework for adaptation to other medical contexts.", "AI": {"tldr": "开发了一个双用途的AI代理系统，通过对话界面提供经过验证的人乳头瘤病毒疫苗信息，并基于用户互动和社会媒体生成分析报告。", "motivation": "鉴于日本在2013至2021年间主动接种推荐暂停导致的信息缺口和社交媒体上的错误信息，传统的沟通方式无法同时解决个体查询与监测群体水平的讨论。", "method": "实施了一个包含向量数据库、检索增强生成聊天机器人以及自动化报告生成系统的AI代理系统。该系统整合了学术论文、政府资源、新闻媒体和社会媒体等多知识源，并使用ReAct架构进行多工具编排。", "result": "在评估中，聊天机器人在单轮对话中的得分分别为：相关性4.83分，路由4.89分，参考质量4.50分，正确性4.90分，专业身份4.88分（总体4.80）。多轮对话评分更高：上下文保持4.94分，话题连贯性5.00分，整体4.98分。报告生成系统得分分别为：完整性4.00-5.00，正确性4.00-5.00，有用性3.67-5.00，参考有效性在所有时期内均为5.00。", "conclusion": "本研究证明了集成AI代理系统在双向人乳头瘤病毒疫苗沟通中的可行性。该架构能够提供带有出处验证的信息，并进行系统的公众讨论分析，适用于其他医学领域的适应性框架。"}}
{"id": "2601.10716", "pdf": "https://arxiv.org/pdf/2601.10716", "abs": "https://arxiv.org/abs/2601.10716", "authors": ["Xuweiyi Chen", "Wentao Zhou", "Zezhou Cheng"], "title": "WildRayZer: Self-supervised Large View Synthesis in Dynamic Environments", "categories": ["cs.CV"], "comment": "Project Page: https://wild-rayzer.cs.virginia.edu/", "summary": "We present WildRayZer, a self-supervised framework for novel view synthesis (NVS) in dynamic environments where both the camera and objects move. Dynamic content breaks the multi-view consistency that static NVS models rely on, leading to ghosting, hallucinated geometry, and unstable pose estimation. WildRayZer addresses this by performing an analysis-by-synthesis test: a camera-only static renderer explains rigid structure, and its residuals reveal transient regions. From these residuals, we construct pseudo motion masks, distill a motion estimator, and use it to mask input tokens and gate loss gradients so supervision focuses on cross-view background completion. To enable large-scale training and evaluation, we curate Dynamic RealEstate10K (D-RE10K), a real-world dataset of 15K casually captured dynamic sequences, and D-RE10K-iPhone, a paired transient and clean benchmark for sparse-view transient-aware NVS. Experiments show that WildRayZer consistently outperforms optimization-based and feed-forward baselines in both transient-region removal and full-frame NVS quality with a single feed-forward pass.", "AI": {"tldr": "WildRayZer 是一个自监督框架，用于动态环境中的新视角合成。", "motivation": "传统的静态新视角合成模型在面对动态内容时会出现鬼影、假几何体和不稳定姿态估计等问题，因此提出了 WildRayZer 来解决这些问题。", "method": "WildRayZer 通过分析-合成测试来识别瞬态区域，并构建伪运动掩模以集中监督背景的跨视图完成。使用 D-RE10K 和 D-RE10K-iPhone 数据集进行大规模训练和评估。", "result": "实验表明，WildRayZer 在瞬态区域去除和全帧新视角合成质量方面均优于基于优化和前馈基线模型，并且仅需一次前馈传递。", "conclusion": "WildRayZer 成功解决了动态环境中的新视角合成问题，表现出色。"}}
{"id": "2601.10714", "pdf": "https://arxiv.org/pdf/2601.10714", "abs": "https://arxiv.org/abs/2601.10714", "authors": ["Tal Reiss", "Daniel Winter", "Matan Cohen", "Alex Rav-Acha", "Yael Pritch", "Ariel Shamir", "Yedid Hoshen"], "title": "Alterbute: Editing Intrinsic Attributes of Objects in Images", "categories": ["cs.CV", "cs.GR"], "comment": "Project page is available at https://talreiss.github.io/alterbute/", "summary": "We introduce Alterbute, a diffusion-based method for editing an object's intrinsic attributes in an image. We allow changing color, texture, material, and even the shape of an object, while preserving its perceived identity and scene context. Existing approaches either rely on unsupervised priors that often fail to preserve identity or use overly restrictive supervision that prevents meaningful intrinsic variations. Our method relies on: (i) a relaxed training objective that allows the model to change both intrinsic and extrinsic attributes conditioned on an identity reference image, a textual prompt describing the target intrinsic attributes, and a background image and object mask defining the extrinsic context. At inference, we restrict extrinsic changes by reusing the original background and object mask, thereby ensuring that only the desired intrinsic attributes are altered; (ii) Visual Named Entities (VNEs) - fine-grained visual identity categories (e.g., ''Porsche 911 Carrera'') that group objects sharing identity-defining features while allowing variation in intrinsic attributes. We use a vision-language model to automatically extract VNE labels and intrinsic attribute descriptions from a large public image dataset, enabling scalable, identity-preserving supervision. Alterbute outperforms existing methods on identity-preserving object intrinsic attribute editing.", "AI": {"tldr": "本文介绍了Alterbute，一种基于扩散的方法，用于编辑图像中对象的内在属性，如颜色、纹理、材质和形状，同时保持其身份识别和场景背景。", "motivation": "现有的方法要么依赖于不能很好地保存身份的无监督先验，要么使用过于严格的监督限制了有意义的内在变化。因此，本文提出了一种新的方法来解决这些问题。", "method": "该方法包括一个放松训练目标和Visual Named Entities (VNEs)，通过视觉语言模型从大型公共图像数据集中自动提取标签和属性描述以实现可扩展的身份保存监督。在推理时，通过重用原始背景和对象掩码，确保仅更改所需的内在属性。", "result": "实验结果表明，Alterbute在保持身份的物体固有属性编辑方面优于现有方法。", "conclusion": "本文提出了一种名为Alterbute的方法，成功实现了在图像中编辑对象的内在属性同时保留其身份和场景背景的目标。"}}
{"id": "2601.10712", "pdf": "https://arxiv.org/pdf/2601.10712", "abs": "https://arxiv.org/abs/2601.10712", "authors": ["Changle Qu", "Sunhao Dai", "Hengyi Cai", "Jun Xu", "Shuaiqiang Wang", "Dawei Yin"], "title": "MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To address this, we propose MatchTIR, a framework that introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. Specifically, we formulate credit assignment as a bipartite matching problem between predicted and ground-truth traces, utilizing two assignment strategies to derive dense turn-level rewards. Furthermore, to balance local step precision with global task success, we introduce a dual-level advantage estimation scheme that integrates turn-level and trajectory-level signals, assigning distinct advantage values to individual interaction turns. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR. Notably, our 4B model surpasses the majority of 8B competitors, particularly in long-horizon and multi-turn tasks. Our codes are available at https://github.com/quchangle1/MatchTIR.", "AI": {"tldr": "本文介绍了MatchTIR框架，通过二部图匹配实现工具集成推理的细粒度监督。", "motivation": "现有强化学习方法在复杂任务中对所有步骤分配统一的优势值，无法区分有效和无效的工具调用。为此提出了一种新的方法来解决这一问题。", "method": "MatchTIR通过二部图匹配实现预测轨迹与真实轨迹之间的细粒度奖励分配，并引入双层优势估计方案平衡局部精度与全局任务成功。", "result": "实验结果表明，MatchTIR在三个基准测试中表现出色，尤其是4B模型在长期和多轮次任务上超越了大多数8B竞争对手。", "conclusion": "通过细粒度的奖励分配和双层优势估计，MatchTIR框架显著提高了工具集成推理的效果。"}}
{"id": "2601.10710", "pdf": "https://arxiv.org/pdf/2601.10710", "abs": "https://arxiv.org/abs/2601.10710", "authors": ["Cheng Chen", "Yuyu Guo", "Pengpeng Zeng", "Jingkuan Song", "Peng Di", "Hang Yu", "Lianli Gao"], "title": "From One-to-One to Many-to-Many: Dynamic Cross-Layer Injection for Deep Vision-Language Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) create a severe visual feature bottleneck by using a crude, asymmetric connection that links only the output of the vision encoder to the input of the large language model (LLM). This static architecture fundamentally limits the ability of LLMs to achieve comprehensive alignment with hierarchical visual knowledge, compromising their capacity to accurately integrate local details with global semantics into coherent reasoning. To resolve this, we introduce Cross-Layer Injection (CLI), a novel and lightweight framework that forges a dynamic many-to-many bridge between the two modalities. CLI consists of two synergistic, parameter-efficient components: an Adaptive Multi-Projection (AMP) module that harmonizes features from diverse vision layers, and an Adaptive Gating Fusion (AGF) mechanism that empowers the LLM to selectively inject the most relevant visual information based on its real-time decoding context. We validate the effectiveness and versatility of CLI by integrating it into LLaVA-OneVision and LLaVA-1.5. Extensive experiments on 18 diverse benchmarks demonstrate significant performance improvements, establishing CLI as a scalable paradigm that unlocks deeper multimodal understanding by granting LLMs on-demand access to the full visual hierarchy.", "AI": {"tldr": "本文提出了Cross-Layer Injection (CLI)框架，通过动态的多对多连接解决了视觉语言模型中的特征瓶颈问题。", "motivation": "传统的Vision-Language Models存在视觉特征瓶颈，因为它们只将视觉编码器的输出与大型语言模型的输入进行粗略且不对称地连接，这限制了语言模型全面融合层次化视觉知识的能力。", "method": "CLI框架包括两个协同工作、参数高效的组件：Adaptive Multi-Projection (AMP)模块用于协调来自不同视觉层的特征，以及Adaptive Gating Fusion (AGF)机制允许LLM根据实时解码上下文选择性地注入最相关的视觉信息。", "result": "实验结果表明，在18个不同的基准测试中，CLI显著提升了模型性能，验证了其有效性和通用性。", "conclusion": "CLI框架作为一种可扩展的范式，通过提供按需访问完整视觉层次的能力，解锁了更深层次的多模态理解。"}}
{"id": "2601.10707", "pdf": "https://arxiv.org/pdf/2601.10707", "abs": "https://arxiv.org/abs/2601.10707", "authors": ["Amir Mallak", "Erfan Aasi", "Shiva Sreeram", "Tsun-Hsuan Wang", "Daniela Rus", "Alaa Maalouf"], "title": "See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly redundant. We quantify redundancy in such (BLIP2) features via PCA and cross-patch similarity: $90$% of variance is captured by $17/64$ principal components, and strong inter-token correlations are pervasive. Training on such overlapping information leads the policy to overfit spurious correlations, hurting OOD robustness. We present Stochastic-Patch-Selection (SPS), a simple yet effective approach for learning policies that are more robust, generalizable, and efficient. For every frame, SPS randomly masks a fraction of patch descriptors, not feeding them to the policy model, while preserving the spatial layout of the remaining patches. Thus, the policy is provided with different stochastic but complete views of the (same) scene: every random subset of patches acts like a different, yet still sensible, coherent projection of the world. The policy thus bases its decisions on features that are invariant to which specific tokens survive. Extensive experiments confirm that across all OOD scenarios, our method outperforms the state of the art (SOTA), achieving a $6.2$% average improvement and up to $20.4$% in closed-loop simulations, while being $2.4\\times$ faster. We conduct ablations over masking rates and patch-feature reorganization, training and evaluating 9 systems, with 8 of them surpassing prior SOTA. Finally, we show that the same learned policy transfers to a physical, real-world car without any tuning.", "AI": {"tldr": "通过随机选择基础模型中的图像补丁来提高端到端自动驾驶系统的性能和泛化能力。", "motivation": "发现基于自注意力机制的特征嵌入存在大量冗余信息，导致政策训练过程中过拟合这些虚假相关性，从而影响了其在分布外情况下的鲁棒性和泛化性。", "method": "提出了一种名为随机补丁选择（SPS）的方法，在每个帧中随机屏蔽一部分图像补丁的描述符而不提供给模型，保留剩余补丁的空间布局不变。", "result": "实验结果表明，与现有最先进技术相比，该方法在所有分布外场景下平均提高了6.2%，最高达到20.4%的性能提升，同时速度提升了2.4倍。并且所学习的策略可以无缝转移到真实世界的车辆中而无需调整。", "conclusion": "随机补丁选择技术能够通过提供不同的但完整的视图来减少训练过程中对虚假相关性的依赖，提高了自动驾驶系统的泛化能力和鲁棒性。"}}
{"id": "2601.10706", "pdf": "https://arxiv.org/pdf/2601.10706", "abs": "https://arxiv.org/abs/2601.10706", "authors": ["Quinten De Man", "Atharva Sharma", "Kishen N Gowda", "Laxman Dhulipala"], "title": "UFO Trees: Practical and Provably-Efficient Parallel Batch-Dynamic Trees", "categories": ["cs.DS"], "comment": "To appear in PPoPP 2026", "summary": "The dynamic trees problem is to maintain a tree under edge updates while supporting queries like connectivity queries or path queries. Despite the first data structure for this fundamental problem -- the link-cut tree -- being invented 40 years ago, our experiments reveal that they are still the fastest sequential data structure for the problem. However, link-cut trees cannot support parallel batch-dynamic updates and have limitations on the kinds of queries they support. In this paper, we design a new parallel batch-dynamic trees data structure called UFO trees that simultaneously supports a wide range of query functionality, supports work-efficient parallel batch-dynamic updates, and is competitive with link-cut trees when run sequentially. We prove that a key reason for the strong practical performance of both link-cut trees and UFO trees is that they can perform updates and queries in sub-logarithmic time for low-diameter trees. We perform an experimental study of our optimized C++ implementations of UFO trees with ten other dynamic tree implementations, several of which are new, in a broad benchmark of both synthetic and real-world trees of varying diameter and size. Our results show that, in both sequential and parallel settings, UFO trees are the fastest dynamic tree data structure that supports a wide range of queries. Our new implementation of UFO trees has low space usage and easily scales to billion-size inputs, making it a promising building block for implementing more complex dynamic graph algorithms in practice.", "AI": {"tldr": "本论文介绍了UFO树，一种新的并行批量动态树数据结构，它在支持广泛查询的同时，也能够在并行批量动态更新中表现出高效性，并且与传统的link-cut树相比，在顺序执行时具有竞争力。", "motivation": "尽管Link-Cut树作为第一个用于维护边更新下树的操作的数据结构已经存在了40年，但它们仍然无法支持并行批量动态更新和一些查询类型，因此本论文旨在设计一个更加高效且功能更广泛的UFO树数据结构。", "method": "作者提出了名为UFO树的新数据结构来解决并行批量动态更新问题，并通过优化的C++实现进行了实验研究。", "result": "实验结果显示，在序列和并行设置中，UFO树都是最快的能够支持广泛查询的动态树数据结构，并且具有低空间使用率，可以轻松扩展到数十亿大小的输入。", "conclusion": "UFO树在支持广泛的查询类型的同时提供了高效的并行批量动态更新能力，而且与传统的link-cut树相比，在顺序执行时表现出色。"}}
{"id": "2601.10702", "pdf": "https://arxiv.org/pdf/2601.10702", "abs": "https://arxiv.org/abs/2601.10702", "authors": ["Ruozhen Yang", "Yucheng Jiang", "Yueqi Jiang", "Priyanka Kargupta", "Yunyi Zhang", "Jiawei Han"], "title": "Grounding Agent Memory in Contextual Intent", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": ":I.2.7; H.3.3", "summary": "Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step's intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference: (1) the current latent goal defining a thematic segment, (2) the action type, and (3) the salient entity types anchoring which attributes matter. During inference, STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history. For evaluation, we introduce CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. Across CAME-Bench and LongMemEval, STITCH achieves state-of-the-art performance, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. Our analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning.", "AI": {"tldr": "本文提出STITCH系统，通过结构化检索线索来解决长期目标导向交互中的记忆问题。", "motivation": "大语言模型在长时段、目标导向的互动中面临挑战，因为相似实体和事实会在不同潜在目标和约束下重复出现，导致内存系统检索到不匹配上下文证据。", "method": "STITCH通过为每个轨迹步骤索引结构化检索线索来实现记忆管理，并根据当前步骤的意图匹配历史。这种意图包括三个部分：当前的潜在线性主题段、动作类型以及重要的实体类型。", "result": "在CAME-Bench和LongMemEval基准测试中，STITCH表现出最先进的性能，比最强的基线高出35.6%，特别是在较长轨迹上表现更好。", "conclusion": "意图索引显著减少了检索噪声，支持了针对长时段推理的记忆系统。"}}
{"id": "2601.10700", "pdf": "https://arxiv.org/pdf/2601.10700", "abs": "https://arxiv.org/abs/2601.10700", "authors": ["Gilat Toker", "Nitay Calderon", "Ohad Amosy", "Roi Reichart"], "title": "LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy. To address this, we introduce a framework for constructing datasets containing structural counterfactual pairs: LIBERTy (LLM-based Interventional Benchmark for Explainability with Reference Targets). LIBERTy is grounded in explicitly defined Structured Causal Models (SCMs) of the text generation, interventions on a concept propagate through the SCM until an LLM generates the counterfactual. We introduce three datasets (disease detection, CV screening, and workplace violence prediction) together with a new evaluation metric, order-faithfulness. Using them, we evaluate a wide range of methods across five models and identify substantial headroom for improving concept-based explanations. LIBERTy also enables systematic analysis of model sensitivity to interventions: we find that proprietary LLMs show markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation. Overall, LIBERTy provides a much-needed benchmark for developing faithful explainability methods.", "AI": {"tldr": "本文介绍了LIBERTy框架，用于通过结构因果模型生成反事实数据来评估大语言模型的概念解释的准确性。", "motivation": "概念解释对高风险领域决策者至关重要，现有的基准依赖于成本高昂且不完美的手工编写反事实数据。", "method": "引入了LIBERTy框架，基于定义明确的结构化因果模型（SCM）生成结构性反事实配对，并提出了一种新的评估指标order-faithfulness。", "result": "使用三个新数据集评估多种方法在五种模型上的表现，发现概念解释存在显著改善空间，并揭示了专有LLMs对人口统计学概念的敏感性降低。", "conclusion": "LIBERTy为开发忠实的概念解释提供了必要的基准工具。"}}
{"id": "2601.10696", "pdf": "https://arxiv.org/pdf/2601.10696", "abs": "https://arxiv.org/abs/2601.10696", "authors": ["Han Jiang", "Yao Xiao", "Rachel Hurley", "Shichao Liu"], "title": "The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load", "categories": ["cs.AI"], "comment": null, "summary": "Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea generation and visual feedback prompts were linked to greater reductions in cognitive load. These findings suggest that GenAI effectiveness depends on users' prior expertise and interaction strategies through prompting.", "AI": {"tldr": "研究探讨了生成式AI在建筑概念设计中对表现、创意自我效能和认知负荷的影响。", "motivation": "该研究旨在评估生成式AI如何影响建筑设计任务中的性能、创意自我效能以及认知负荷，特别是针对新手设计师的效果。", "method": "36名来自建筑工程和其他学科的学生参加了两阶段的建筑设计任务，首先独立完成，然后使用外部工具（生成式AI辅助和对照条件下的在线项目库）。设计结果由专家评定，自我效能感和认知负荷通过自评问卷收集。", "result": "研究发现总体上生成式AI并未显著提高表现；但对于新手设计师而言，其性能有所提升。然而，学生的创意自我效能因使用生成式AI而下降。虽然两种条件下认知负荷无显著差异，但提示的使用模式显示迭代的想法生成和视觉反馈可以减少认知负荷。", "conclusion": "研究结论指出，生成式AI的效果依赖于用户的先前专业知识以及通过提示策略进行互动的方式。"}}
{"id": "2601.10691", "pdf": "https://arxiv.org/pdf/2601.10691", "abs": "https://arxiv.org/abs/2601.10691", "authors": ["Lorena A. Barba", "Laura Stegner"], "title": "The Conversational Exam: A Scalable Assessment Design for the AI Era", "categories": ["cs.CY", "cs.CE", "cs.HC"], "comment": "12 pages", "summary": "Traditional assessment methods collapse when students use generative AI to complete work without genuine engagement, creating an illusion of competence where they believe they're learning but aren't. This paper presents the conversational exam -- a scalable oral examination format that restores assessment validity by having students code live while explaining their reasoning. Drawing on human-computer interaction principles, we examined 58 students in small groups across just two days, demonstrating that oral exams can scale to typical class sizes. The format combines authentic practice (students work with documentation and supervised AI access) with inherent validity (real-time performance cannot be faked). We provide detailed implementation guidance to help instructors adapt this approach, offering a practical path forward when many educators feel paralyzed between banning AI entirely or accepting that valid assessment is impossible.", "AI": {"tldr": "本文提出了一种可扩展的口语考试形式——对话式考试，以恢复评估的有效性，并提供了详细的实施指南。", "motivation": "由于学生利用生成AI完成工作而不真正参与学习，传统评估方法失效，因此需要一种新的评估方式来确保真实性。", "method": "通过让学生在小组中实时编码并解释其推理过程，结合人机交互原则，对58名学生进行了为期两天的小规模实验。", "result": "研究展示了口语考试可以扩展到典型班级规模，并且结合了真实实践和内在有效性。", "conclusion": "对话式考试为教育工作者提供了一种实用的方法，在完全禁止AI或接受评估无效之间找到平衡。"}}
{"id": "2601.10688", "pdf": "https://arxiv.org/pdf/2601.10688", "abs": "https://arxiv.org/abs/2601.10688", "authors": ["Rubel Hassan Mollik", "Vamsi Krishna Kosuri", "Hans Djalali", "Stephanie Ludi", "Aboubakar Mountapmbeme"], "title": "An Extension-Based Accessibility Framework for Making Blockly Accessible to Blind and Low-Vision Users", "categories": ["cs.HC", "cs.SE"], "comment": "Accepted at the 1st International Workshop on User Interface and Experience for Software Engineering (UISE 2026), co-located with ICSE 2026. Final published version available at DOI: 10.1145/3786169.3788398", "summary": "Block-based programming environments (BBPEs) such as Scratch and Code.org are now widely used in K-12 computer science classes, but they remain mostly inaccessible to blind or visually impaired (BVI) learners. A major problem is that prior accessibility solutions have relied on modifications to the Blockly library, making them difficult to apply in existing BBPEs and thereby limiting adoption. We present an Extension-based Accessibility Framework (EAF) to make BBPEs accessible for BVI students. The framework uses a modular architecture that enables seamless integration with existing Blockly-based BBPEs. We present an innovative three-dimensional (3D) hierarchical navigation model featuring stack labeling and block numbering, mode-based editing to prevent accidental modifications, and WAI-ARIA implementation to ensure compatibility with external screen readers. We evaluated our approach by integrating the EAF framework into two BBPEs (covering 177 test cases) and conducting semi-structured interviews with four participants using VoiceOver, JAWS, and NVDA. Participants reported clearer spatial orientation and easier mental model formation compared to default Blockly keyboard navigation. EAF shows that modular architecture can provide comprehensive accessibility while ensuring compatibility with existing BBPEs.", "AI": {"tldr": "本文提出了一种基于扩展的无障碍框架（EAF），旨在使Blockly基块编程环境对盲人和低视力用户更加友好。", "motivation": "当前，块状编程环境中如Scratch和Code.org广泛应用于中小学计算机科学课程中，但这些工具对于视障或弱视学生来说是不可用的。已有的无障碍解决方案需要修改Blockly库，这使其难以应用到现有的环境之中，并限制了其推广。", "method": "该框架采用模块化架构设计，能够无缝集成到已有的Blockly基块编程环境中，提出了三维分层导航模型，其中包括堆栈标签和块编号、基于模式的编辑功能以防止意外修改以及符合WAI-ARIA标准来确保与外部屏幕阅读器兼容。", "result": "通过将EAF框架整合至两种基块编程环境（涵盖了177个测试案例）并进行半结构化访谈，参与者使用了VoiceOver、JAWS和NVDA等辅助技术，反馈显示相比于默认的Blockly键盘导航，该方法提供了更清晰的空间定位与更容易构建心理模型。", "conclusion": "EAF展示了模块化的架构能够提供全面的无障碍性支持，同时保持与现有基块编程环境的兼容性。"}}
{"id": "2601.10687", "pdf": "https://arxiv.org/pdf/2601.10687", "abs": "https://arxiv.org/abs/2601.10687", "authors": ["S M Rayeed", "Mridul Khurana", "Alyson East", "Isadora E. Fluck", "Elizabeth G. Campolongo", "Samuel Stevens", "Iuliia Zarubiieva", "Scott C. Lowe", "Michael W. Denslow", "Evan D. Donoso", "Jiaman Wu", "Michelle Ramirez", "Benjamin Baiser", "Charles V. Stewart", "Paula Mabee", "Tanya Berger-Wolf", "Anuj Karpatne", "Hilmar Lapp", "Robert P. Guralnick", "Graham W. Taylor", "Sydne Record"], "title": "A continental-scale dataset of ground beetles with high-resolution images and validated morphological trait measurements", "categories": ["cs.CV"], "comment": "21 pages, 10 figures; Submitted to Nature Scientific Data", "summary": "Despite the ecological significance of invertebrates, global trait databases remain heavily biased toward vertebrates and plants, limiting comprehensive ecological analyses of high-diversity groups like ground beetles. Ground beetles (Coleoptera: Carabidae) serve as critical bioindicators of ecosystem health, providing valuable insights into biodiversity shifts driven by environmental changes. While the National Ecological Observatory Network (NEON) maintains an extensive collection of carabid specimens from across the United States, these primarily exist as physical collections, restricting widespread research access and large-scale analysis. To address these gaps, we present a multimodal dataset digitizing over 13,200 NEON carabids from 30 sites spanning the continental US and Hawaii through high-resolution imaging, enabling broader access and computational analysis. The dataset includes digitally measured elytra length and width of each specimen, establishing a foundation for automated trait extraction using AI. Validated against manual measurements, our digital trait extraction achieves sub-millimeter precision, ensuring reliability for ecological and computational studies. By addressing invertebrate under-representation in trait databases, this work supports AI-driven tools for automated species identification and trait-based research, fostering advancements in biodiversity monitoring and conservation.", "AI": {"tldr": "本文构建了一个涵盖全美及夏威夷地区的大陆级鞘翅目步甲数据集，通过高分辨率成像和验证后的形态特征测量，支持生态与计算研究。", "motivation": "鉴于无脊椎动物在生态系统健康中的重要性及其在全球特征数据库中代表性不足的问题，本研究旨在填补这一空白并促进大规模分析。", "method": "使用高分辨率成像技术数字化超过13,200个步甲样本，并自动测量每个标本的鞘翅长度和宽度，同时验证了数字特征提取的准确性。", "result": "该数据集实现了对步甲形态特征的精准测量，达到了亚毫米精度，支持AI驱动的物种识别和基于特征的研究。", "conclusion": "这项研究为生物多样性监测与保护提供了基础，促进了自动化的物种识别工具的发展，并支持生态学与计算科学研究。"}}
{"id": "2601.10684", "pdf": "https://arxiv.org/pdf/2601.10684", "abs": "https://arxiv.org/abs/2601.10684", "authors": ["Maissam Barkeshli", "Alberto Alfarano", "Andrey Gromov"], "title": "On the origin of neural scaling laws: from random graphs to natural language", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI", "stat.ML"], "comment": "33 pages", "summary": "Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. We demonstrate that this simplified setting already gives rise to neural scaling laws even in the absence of power law structure in the data correlations. We further consider dialing down the complexity of natural language systematically, by training on sequences sampled from increasingly simplified generative language models, from 4,2,1-layer transformer language models down to language bigrams, revealing a monotonic evolution of the scaling exponents. Our results also include scaling laws obtained from training on random walks on random graphs drawn from Erdös-Renyi and scale-free Barabási-Albert ensembles. Finally, we revisit conventional scaling laws for language modeling, demonstrating that several essential results can be reproduced using 2 layer transformers with context length of 50, provide a critical analysis of various fits used in prior literature, demonstrate an alternative method for obtaining compute optimal curves as compared with current practice in published literature, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization.", "AI": {"tldr": "研究神经网络缩放定律的起源，通过训练预测随机图上随机游走的大数据模型来展示简化设置下的神经缩放定律，并探讨自然语言复杂度对缩放指数的影响。", "motivation": "探索神经网络性能与参数、数据和计算量之间关系的缩放定律起源，挑战认为这些规律源于数据中的幂律结构的观点。", "method": "训练变压器模型预测随机图上的大图（二元语法）；系统地简化自然语言复杂度进行训练；在Erdös-Renyi和Barabási-Albert随机图上研究缩放定律。", "result": "展示了即使没有数据相关性的幂律结构，神经网络也会出现缩放定律；揭示了随着自然语言复杂度的降低，缩放指数单调变化的现象；用简化的变压器模型再现了一些关键结果，并提出了一种不同的方法来获得计算最优曲线。", "conclusion": "表明在简化场景下也能观察到神经缩放定律，挑战数据中的幂律结构是唯一来源的观点，并提出了更有效的参数化方式。"}}
{"id": "2601.10681", "pdf": "https://arxiv.org/pdf/2601.10681", "abs": "https://arxiv.org/abs/2601.10681", "authors": ["Amir Khurshid", "Abhishek Sehgal"], "title": "Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organising multi-granular spans (e.g., sections and rows) and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It will explicitly constrain diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets and has a better answer quality and citation faithfulness within a limited context window. Ablation studies demonstrate that both structural priors as well as diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.", "AI": {"tldr": "本文提出了一种结构和多样性意识的上下文气泡构建框架，以改善企业检索增强系统中的上下文构造问题。", "motivation": "传统的检索增强生成方法导致信息图碎片化、过量检索及内容重复等问题，且难以提供足够的查询背景信息。因此，需要一种新的方法来提高上下文的相关性和多样性，并减少冗余。", "method": "提出了一种结构导向和多样性约束的上下文气泡构建框架，该框架在严格标记预算下组装连贯、可引用的跨度集合，并通过任务条件化的结构性先验引导检索以平衡查询相关性、边际覆盖范围及冗余惩罚。", "result": "实验表明所提方法显著减少了冗余上下文，在限定的上下文窗口内能更好地覆盖二级和三级要素，提供更高质量的答案和更忠实的引用信息。此外，消融研究显示结构先验及多样性约束选择都是必要的组成部分。", "conclusion": "研究表明，通过结构和多样性的结合可以有效提升企业文档检索增强系统中的上下文质量，并在实验中验证了其有效性和必要性。"}}
{"id": "2601.10679", "pdf": "https://arxiv.org/pdf/2601.10679", "abs": "https://arxiv.org/abs/2601.10679", "authors": ["Zirui Ren", "Ziming Liu"], "title": "Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM. (b) \"Grokking\" dynamics in reasoning steps, i.e., the answer is not improved uniformly, but instead there is a critical reasoning step that suddenly makes the answer correct; (c) Existence of multiple fixed points. HRM \"guesses\" the first fixed point, which could be incorrect, and gets trapped there for a while or forever. All facts imply that HRM appears to be \"guessing\" instead of \"reasoning\". Leveraging this \"guessing\" picture, we propose three strategies to scale HRM's guesses: data augmentation (scaling the quality of guesses), input perturbation (scaling the number of guesses by leveraging inference randomness), and model bootstrapping (scaling the number of guesses by leveraging training randomness). On the practical side, by combining all methods, we develop Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%. On the scientific side, our analysis provides new insights into how reasoning models \"reason\".", "AI": {"tldr": "本文对分层推理模型(HRM)的推理模式进行了机理性研究，揭示了HRM在某些情况下似乎是在猜测而非推理，并提出了提升HRM性能的策略。", "motivation": "为了理解HRM的优势和潜在失败模式，作者试图通过机理性分析来探究其背后的原理。", "method": "通过对HRM进行机理性研究，识别出HRM存在三种现象：对极简单的谜题也失败、推理步骤中的“领悟”动态以及多固定点的存在。基于这些发现，提出了数据增强、输入扰动和模型引导等策略以改进HRM的性能。", "result": "通过结合所提出的所有方法，开发了Augmented HRM，在Sudoku-Extreme任务上的准确率从54.5%提升到了96.9%。", "conclusion": "研究揭示了HRM似乎在“猜测”而非“推理”，并为改进这类模型提供了新的策略和见解。"}}
{"id": "2601.10657", "pdf": "https://arxiv.org/pdf/2601.10657", "abs": "https://arxiv.org/abs/2601.10657", "authors": ["Minghao Yan", "Bo Peng", "Benjamin Coleman", "Ziqi Chen", "Zhouhang Xie", "Zhankui He", "Noveen Sachdeva", "Isabella Ye", "Weili Wang", "Chi Wang", "Ed H. Chi", "Wang-Cheng Kang", "Derek Zhiyuan Cheng", "Beidou Wang"], "title": "PACEvolve: Enabling Long-Horizon Progress-Aware Consistent Evolution", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode Collapse, where agents stagnate in local minima due to poor exploration-exploitation balance; and Weak Collaboration, where rigid crossover strategies fail to leverage parallel search trajectories effectively. We introduce Progress-Aware Consistent Evolution (PACEvolve), a framework designed to robustly govern the agent's context and search dynamics, to address these challenges. PACEvolve combines hierarchical context management (HCM) with pruning to address context pollution; momentum-based backtracking (MBB) to escape local minima; and a self-adaptive sampling policy that unifies backtracking and crossover for dynamic search coordination (CE), allowing agents to balance internal refinement with cross-trajectory collaboration. We demonstrate that PACEvolve provides a systematic path to consistent, long-horizon self-improvement, achieving state-of-the-art results on LLM-SR and KernelBench, while discovering solutions surpassing the record on Modded NanoGPT.", "AI": {"tldr": "本文介绍了PACEvolve框架，旨在解决大型语言模型（LLM）在进化搜索中的系统化管理问题。", "motivation": "当前的LLM循环系统缺乏系统的方法来管理进化过程。作者识别了三个失败模式：上下文污染、模式坍塌和弱协作，并提出了解决这些问题的动机。", "method": "PACEvolve框架结合了层次化的上下文管理和修剪以解决上下文污染；动量回溯方法用于逃脱局部极小值；自适应采样策略统一了回溯和交叉，以实现动态搜索协调。", "result": "实验结果表明，PACEvolve在LLM-SR和KernelBench上达到了最先进的性能，并且在Modded NanoGPT上的解决方案超过了记录。", "conclusion": "PACEvolve提供了一个系统路径，实现了长时间范围内的自我改进，证明了其在进化搜索中的有效性。"}}
{"id": "2601.10651", "pdf": "https://arxiv.org/pdf/2601.10651", "abs": "https://arxiv.org/abs/2601.10651", "authors": ["Christoph Weinhuber", "Yannik Schnitzer", "Alessandro Abate", "David Parker", "Giuseppe De Giacomo", "Moshe Y. Vardi"], "title": "Multi-Property Synthesis", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude.", "AI": {"tldr": "本论文研究了在满足所有属性可能不可行的情况下，如何进行具有多个属性的LTLf合成。", "motivation": "传统的枚举子集方法效率低下，因此动机在于开发一种更高效的方法来处理多属性的LTLf合成问题。", "method": "提出了一种完全符号化的算法，通过引入布尔目标变量并利用单调性来紧凑地表示大量可能的目标组合，并在一次固定点计算中完成状态与可达目标集之间的关系计算和最大化实现集合策略的综合。", "result": "该方法相较于基于枚举的方法性能提升了两个数量级。", "conclusion": "本文提出的新算法能够高效解决多属性LTLf合成问题，显著提高了处理此类问题的速度。"}}
{"id": "2601.10649", "pdf": "https://arxiv.org/pdf/2601.10649", "abs": "https://arxiv.org/abs/2601.10649", "authors": ["Darshan Singh", "Arsha Nagrani", "Kawshik Manikantan", "Harman Singh", "Dinesh Tewari", "Tobias Weyand", "Cordelia Schmid", "Anelia Angelova", "Shachi Dave"], "title": "CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotations from diverse, region-specific cultural videos across 18 global locales. Unlike prior work that relies on automatic translations, CURVE provides complex questions, answers, and multi-step reasoning steps, all crafted in native languages. Making progress on CURVE requires a deeply situated understanding of visual cultural context. Furthermore, we leverage CURVE's reasoning traces to construct evidence-based graphs and propose a novel iterative strategy using these graphs to identify fine-grained errors in reasoning. Our evaluations reveal that SoTA Video-LLMs struggle significantly, performing substantially below human-level accuracy, with errors primarily stemming from the visual perception of cultural elements. CURVE will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva-cultural", "AI": {"tldr": "介绍CURVE基准，用于跨文化多语言长视频理解评估。", "motivation": "当前的视频模型评测基准存在西方中心主义和英语主导的问题，需要一个更全面、多元化的评测标准。", "method": "创建了一个名为CURVE的新基准，包含18个全球地区的高质量人类生成注释的文化视频。使用证据图来构建推理步骤并提出一种迭代策略以识别细微的错误。", "result": "最先进的视频语言模型在CURVE上的表现远低于人类准确率，主要错误来自于对文化元素的视觉感知。", "conclusion": "CURVE揭示了现有模型在处理跨文化和多语种长视频理解时存在的问题，并提供了一个公开可用的新基准以推动相关研究。"}}
{"id": "2601.10632", "pdf": "https://arxiv.org/pdf/2601.10632", "abs": "https://arxiv.org/abs/2601.10632", "authors": ["Chengfeng Zhao", "Jiazhi Shu", "Yubo Zhao", "Tianyu Huang", "Jiahao Lu", "Zekai Gu", "Chengwei Ren", "Zhiyang Dou", "Qing Shuai", "Yuan Liu"], "title": "CoMoVi: Co-Generation of 3D Human Motions and Realistic Videos", "categories": ["cs.CV"], "comment": "Project Page: https://igl-hkust.github.io/CoMoVi/", "summary": "In this paper, we find that the generation of 3D human motions and 2D human videos is intrinsically coupled. 3D motions provide the structural prior for plausibility and consistency in videos, while pre-trained video models offer strong generalization capabilities for motions, which necessitate coupling their generation processes. Based on this, we present CoMoVi, a co-generative framework that couples two video diffusion models (VDMs) to generate 3D human motions and videos synchronously within a single diffusion denoising loop. To achieve this, we first propose an effective 2D human motion representation that can inherit the powerful prior of pre-trained VDMs. Then, we design a dual-branch diffusion model to couple human motion and video generation process with mutual feature interaction and 3D-2D cross attentions. Moreover, we curate CoMoVi Dataset, a large-scale real-world human video dataset with text and motion annotations, covering diverse and challenging human motions. Extensive experiments demonstrate the effectiveness of our method in both 3D human motion and video generation tasks.", "AI": {"tldr": "本文介绍了CoMoVi框架，用于同时生成3D人体运动和同步的逼真人像视频。", "motivation": "研究表明3D人类运动和2D视频生成本质上是耦合的，因此需要一种方法来结合这两者的生成过程以实现更加真实的效果。", "method": "提出了一种双分支扩散模型，该模型利用互特征交互和三维至二维交叉注意力机制，在单一去噪循环中同步生成3D人体运动和视频，并使用了有效的2D人类运动表示形式以继承预训练VDM的强大先验能力。", "result": "实验结果表明，该方法在3D人类运动和视频生成任务上都表现出了有效性。", "conclusion": "CoMoVi框架成功实现了3D人体运动和同步逼真人像视频的耦合生成，并通过实验证明了其有效性和实用性。"}}
{"id": "2601.10611", "pdf": "https://arxiv.org/pdf/2601.10611", "abs": "https://arxiv.org/abs/2601.10611", "authors": ["Christopher Clark", "Jieyu Zhang", "Zixian Ma", "Jae Sung Park", "Mohammadreza Salehi", "Rohun Tripathi", "Sangho Lee", "Zhongzheng Ren", "Chris Dongjoo Kim", "Yinuo Yang", "Vincent Shao", "Yue Yang", "Weikai Huang", "Ziqi Gao", "Taira Anderson", "Jianrui Zhang", "Jitesh Jain", "George Stoica", "Winson Han", "Ali Farhadi", "Ranjay Krishna"], "title": "Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding -- either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1 J&F on video tracking).", "AI": {"tldr": "介绍了 Molmo2，一种新的视频语言模型家族，在开放权重和数据的模型中表现最佳，并在点驱动的定位任务上展示了卓越的能力。", "motivation": "现有的最强视频语言模型是专有的，而公开权重的模型要么依赖于合成数据，要么不披露训练数据或方法。因此，开源社区缺乏改进现有视频（和图像）语言模型的基础。", "method": "提出了7个新的视频数据集和2个多图数据集，并提供了一种利用高效打包和消息树编码方案的数据训练配方，以及双向视觉标记注意力和新型令牌权重策略来提升性能。", "result": "Molmo2 在短视频、计数和描述任务上超越了同类开放权重模型，在视频定位和跟踪方面甚至超过了专有模型如 Gemini 3 Pro。", "conclusion": "展示了 Molmo2 在多种视频理解和定位任务上的优势，特别是在点驱动的定位任务上表现出色，并为开源社区提供了重要的资源。"}}
{"id": "2601.10607", "pdf": "https://arxiv.org/pdf/2601.10607", "abs": "https://arxiv.org/abs/2601.10607", "authors": ["Angeliki Katsenou", "Vignesh V. Menon", "Guoda Laurinaviciute", "Benjamin Bross", "Detlev Marpe"], "title": "Multi-Objective Pareto-Front Optimization for Efficient Adaptive VVC Streaming", "categories": ["eess.IV", "cs.CV"], "comment": "19 pages", "summary": "Adaptive video streaming has facilitated improved video streaming over the past years. A balance among coding performance objectives such as bitrate, video quality, and decoding complexity is required to achieve efficient, content- and codec-dependent, adaptive video streaming. This paper proposes a multi-objective Pareto-front (PF) optimization framework to construct quality-monotonic, content-adaptive bitrate ladders Versatile Video Coding (VVC) streaming that jointly optimize video quality, bitrate, and decoding time, which is used as a practical proxy for decoding energy. Two strategies are introduced: the Joint Rate-Quality-Time Pareto Front (JRQT-PF) and the Joint Quality-Time Pareto Front (JQT-PF), each exploring different tradeoff formulations and objective prioritizations. The ladders are constructed under quality monotonicity constraints during adaptive streaming to ensure a consistent Quality of Experience (QoE). Experiments are conducted on a large-scale UHD dataset (Inter-4K), with quality assessed using PSNR, VMAF, and XPSNR, and complexity measured via decoding time and energy consumption. The JQT-PF method achieves 11.76% average bitrate savings while reducing average decoding time by 0.29% to maintain the same XPSNR, compared to a widely-used fixed ladder. More aggressive configurations yield up to 27.88% bitrate savings at the cost of increased complexity. The JRQT-PF strategy, on the other hand, offers more controlled tradeoffs, achieving 6.38 % bitrate savings and 6.17 % decoding time reduction. This framework outperforms existing methods, including fixed ladders, VMAF- and XPSNR-based dynamic resolution selection, and complexity-aware benchmarks. The results confirm that PF optimization with decoding time constraints enables sustainable, high-quality streaming tailored to network and device capabilities.", "AI": {"tldr": "提出一个多目标Pareto前沿优化框架，用于构建内容自适应的VVC流媒体比特率阶梯。", "motivation": "为了实现高效的自适应视频流传输，需要在比特率、视频质量和解码复杂度之间找到平衡。现有的方法存在局限性，因此研究者提出了新的多目标优化策略。", "method": "该论文提出两种策略：联合速率-质量-时间Pareto前沿（JRQT-PF）和联合质量-时间Pareto前沿（JQT-PF），并在自适应流媒体过程中考虑了质量单调约束。", "result": "实验在大规模UHD数据集上进行，结果显示，在相同的XPSNR下，与广泛使用的固定阶梯相比，JQT-PF方法平均节省11.76%的比特率并减少0.29%的解码时间。JRQT-PF策略则提供更控制的权衡，实现6.38%比特率节约和6.17%的解码时间减少。", "conclusion": "该研究证明了在解码时间约束下的Pareto前沿优化能够支持可持续且高质量的流媒体传输，并适应网络和设备的能力。"}}
{"id": "2601.10606", "pdf": "https://arxiv.org/pdf/2601.10606", "abs": "https://arxiv.org/abs/2601.10606", "authors": ["Peng Chen", "Xiaobao Wei", "Yi Yang", "Naiming Yao", "Hui Chen", "Feng Tian"], "title": "RSATalker: Realistic Socially-Aware Talking Head Generation for Multi-Turn Conversation", "categories": ["cs.CV"], "comment": null, "summary": "Talking head generation is increasingly important in virtual reality (VR), especially for social scenarios involving multi-turn conversation. Existing approaches face notable limitations: mesh-based 3D methods can model dual-person dialogue but lack realistic textures, while large-model-based 2D methods produce natural appearances but incur prohibitive computational costs. Recently, 3D Gaussian Splatting (3DGS) based methods achieve efficient and realistic rendering but remain speaker-only and ignore social relationships. We introduce RSATalker, the first framework that leverages 3DGS for realistic and socially-aware talking head generation with support for multi-turn conversation. Our method first drives mesh-based 3D facial motion from speech, then binds 3D Gaussians to mesh facets to render high-fidelity 2D avatar videos. To capture interpersonal dynamics, we propose a socially-aware module that encodes social relationships, including blood and non-blood as well as equal and unequal, into high-level embeddings through a learnable query mechanism. We design a three-stage training paradigm and construct the RSATalker dataset with speech-mesh-image triplets annotated with social relationships. Extensive experiments demonstrate that RSATalker achieves state-of-the-art performance in both realism and social awareness. The code and dataset will be released.", "AI": {"tldr": "介绍RSATalker框架，该框架利用3D高斯散射技术实现真实且社会意识强的多轮对话虚拟头像生成。", "motivation": "现有的谈话头像生成方法存在局限性：基于网格的三维方法可以模拟双人对话但缺乏逼真的纹理；大型模型的二维方法能产生自然外观，但计算成本高昂；最近基于3D高斯散射的方法实现了高效和真实的渲染，但仍只局限于单个说话者且忽略了社交关系。", "method": "RSATalker首先从语音驱动网格基础的三维面部运动，然后将3D高斯绑定到网格面以生成高质量2D头像视频。为捕捉人际动态，提出社会意识模块通过可学习查询机制将血缘和非血缘以及平等与不平等的社会关系编码成高层嵌入，并设计了三阶段训练范式及构建RSATalker数据集。", "result": "大量实验表明，RSATalker在真实感和社会意识方面均达到了最先进的性能。", "conclusion": "研究结果证明RSATalker是第一个将3D高斯散射技术应用于多轮对话的社会感知虚拟头像生成的框架，并且在真实性和社会意识方面表现优异。"}}
{"id": "2601.10600", "pdf": "https://arxiv.org/pdf/2601.10600", "abs": "https://arxiv.org/abs/2601.10600", "authors": ["Joshua Caiata", "Carter Blair", "Kate Larson"], "title": "Procedural Fairness in Multi-Agent Bandits", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcomes. Empirical results confirm that fairness notions based on optimizing for outcomes sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives (like equality and utilitarianism) is minimal under procedurally fair policies. We further prove that different fairness notions prioritize fundamentally different and incompatible values, highlighting that fairness requires explicit normative choices. This paper argues that procedural legitimacy deserves greater focus as a fairness objective, and provides a framework for putting procedural fairness into practice.", "AI": {"tldr": "本文介绍了多智能体多臂老虎机（MA-MAB）中的程序公正概念，并展示了过程公平在决策中的重要性。", "motivation": "动机在于强调除了结果公平外，过程公正也应被重视，以确保所有代理都有平等的决策权。", "method": "通过引入新的程序公平目标来平衡代理之间的决策权力，同时保持比例的结果分配。", "result": "实证研究表明，基于结果优化的公平性牺牲了平等发言和代表性，而程序公平性的牺牲很小。", "conclusion": "结论指出程序合法性作为公平目标应得到更多关注，并提供了将程序公正付诸实践的框架。"}}
{"id": "2601.10592", "pdf": "https://arxiv.org/pdf/2601.10592", "abs": "https://arxiv.org/abs/2601.10592", "authors": ["Delong Chen", "Tejaswi Kasarla", "Yejin Bang", "Mustafa Shukor", "Willy Chung", "Jade Yu", "Allen Bolourchi", "Theo Moutakanni", "Pascale Fung"], "title": "Action100M: A Large-scale Video Action Dataset", "categories": ["cs.CV"], "comment": null, "summary": "Inferring physical actions from visual observations is a fundamental capability for advancing machine intelligence in the physical world. Achieving this requires large-scale, open-vocabulary video action datasets that span broad domains. We introduce Action100M, a large-scale dataset constructed from 1.2M Internet instructional videos (14.6 years of duration), yielding O(100 million) temporally localized segments with open-vocabulary action supervision and rich captions. Action100M is generated by a fully automated pipeline that (i) performs hierarchical temporal segmentation using V-JEPA 2 embeddings, (ii) produces multi-level frame and segment captions organized as a Tree-of-Captions, and (iii) aggregates evidence with a reasoning model (GPT-OSS-120B) under a multi-round Self-Refine procedure to output structured annotations (brief/detailed action, actor, brief/detailed caption). Training VL-JEPA on Action100M demonstrates consistent data-scaling improvements and strong zero-shot performance across diverse action recognition benchmarks, establishing Action100M as a new foundation for scalable research in video understanding and world modeling.", "AI": {"tldr": "本文介绍了Action100M，一个从互联网教学视频中构建的大规模开放词汇表动作数据集，并展示其在视频理解和世界建模方面的应用价值。", "motivation": "为了推进机器智能在物理世界的进步，需要大规模、涵盖广泛领域的开放词汇表视频动作数据集来推断视觉观察中的物理行为。", "method": "Action100M通过全自动化的流水线生成，包括使用V-JEPA 2嵌入进行层次化时间分割、生成多层次的帧和段落描述，以及用GPT-OSS-120B推理模型进行多轮自我优化来输出结构化注释。", "result": "在Action100M上训练的VL-JEPA表现出一致的数据扩展改进和强大的零样本性能，并且在多个动作识别基准测试中表现优异，确立了其作为视频理解和世界建模研究新基础的地位。", "conclusion": "Action100M数据集为机器学习领域提供了丰富资源，通过展示其在各种评估中的效果验证了其在推动视频理解技术进步方面的潜力和价值。"}}
{"id": "2601.10591", "pdf": "https://arxiv.org/pdf/2601.10591", "abs": "https://arxiv.org/abs/2601.10591", "authors": ["Arundeep Chinta", "Lucas Vinh Tran", "Jay Katukuri"], "title": "ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition", "categories": ["cs.LG", "cs.AI", "q-fin.RM", "q-fin.TR"], "comment": "Accepted for oral presentation at the AI Meets Quantitative Finance Workshop at ICAIF 2025. An enhanced version was accepted for oral presentation at the AI for Time Series Analysis Workshop at AAAI 2026", "summary": "Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to address the core challenge of providing theoretically-grounded uncertainty decomposition. For the very first time, we present a novel transformer-based probabilistic framework, ProbFM (probabilistic foundation model), that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. To rigorously evaluate the core DER uncertainty quantification approach independent of architectural complexity, we conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods: DER, Gaussian NLL, Student's-t NLL, Quantile Loss, and Conformal Prediction. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications.", "AI": {"tldr": "本文介绍了一种基于Transformer的新型概率框架ProbFM，该框架利用Deep Evidential Regression（DER）提供原理上的不确定性量化和明确的认知-随机分解。", "motivation": "虽然时间序列基础模型(TSFMs)在零样本金融预测中展示了强大的迁移性和数据效率增益，但它们在不确定性量化方面存在根本性的限制。现有的TSFMs方法依赖于严格的分布假设、混淆不同的不确定来源或缺乏原理上的校准机制。", "method": "本文提出了一种基于Transformer的概率框架ProbFM，利用Deep Evidential Regression（DER）来提供理论基础的不确定性量化和明确的认知-随机分解，从而避免了预先指定分布形式或需要采样推理的需求。为了独立于架构复杂性严格评估DER不确定性量化的核心方法，研究使用统一的LSTM架构对五种概率方法进行了广泛对比实验。", "result": "在加密货币收益预测上的评价表明，DER保持了竞争力的预测准确性同时提供了明确的认知-随机不确定性分解。", "conclusion": "本工作建立了扩展性框架用于基础模型中的原理不确定性量化，并且通过实验证明了DER在金融应用中的有效性。"}}
{"id": "2601.10587", "pdf": "https://arxiv.org/pdf/2601.10587", "abs": "https://arxiv.org/abs/2601.10587", "authors": ["Frank Mollard", "Marcus Becker", "Florian Roehrbein"], "title": "Adversarial Evasion Attacks on Computer Vision using SHAP Values", "categories": ["cs.CV", "cs.AI"], "comment": "10th bwHPC Symposium - September 25th & 26th, 2024", "summary": "The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibility to the human eye. The proposed attack leverages SHAP values to quantify the significance of individual inputs to the output at the inference stage. A comparison is drawn between the SHAP attack and the well-known Fast Gradient Sign Method. We find evidence that SHAP attacks are more robust in generating misclassifications particularly in gradient hiding scenarios.", "AI": {"tldr": "本文介绍了使用SHAP值对计算机视觉模型进行的白盒攻击，并展示了如何通过降低输出信心或诱导错误分类来破坏深度学习模型的性能。", "motivation": "动机在于展示利用SHAP值执行对抗性逃避攻击的可行性，这种攻击能够欺骗算法感知而不被人类察觉，特别是在梯度隐藏场景中更具鲁棒性。", "method": "方法包括使用SHAP值量化输入对输出的影响，并与Fast Gradient Sign Method进行比较。", "result": "实验结果显示SHAP攻击在生成错误分类方面比Fast Gradient Sign Method更稳健。", "conclusion": "结论是，通过利用SHAP值的白盒攻击能够有效地诱导深度学习模型发生误分类，并且这种攻击方法在梯度隐藏场景中表现尤为有效。"}}
{"id": "2601.10581", "pdf": "https://arxiv.org/pdf/2601.10581", "abs": "https://arxiv.org/abs/2601.10581", "authors": ["Kimia Abedini", "Farzad Shami", "Gianmaria Silvello"], "title": "From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA", "categories": ["cs.AI", "cs.IR"], "comment": "Accepted paper by the 48th European Conference on Information Retrieval (ECIR'26)", "summary": "Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.", "AI": {"tldr": "本文介绍了从单代理推理到多代理推理的进展，提出了GenomAgent框架以改善基因组问答任务中的性能。", "motivation": "由于大型语言模型在访问特定领域数据库方面存在限制，因此需要一种更有效的方法来处理复杂的基因组查询。", "method": "文章复制了GeneGPT，并提出了一种新的多代理框架GenomAgent，该框架可以高效地协调专门的代理以应对复杂的基因组查询。", "result": "在GeneTuring基准测试的九项任务中，GenomAgent比GeneGPT平均高出12%的表现。", "conclusion": "GenomAgent不仅提高了基因组问答系统的性能，其灵活架构还扩展到需要专家知识提取的各种科学领域。"}}
{"id": "2601.10577", "pdf": "https://arxiv.org/pdf/2601.10577", "abs": "https://arxiv.org/abs/2601.10577", "authors": ["Serena Grazia De Benedictis", "Amedeo Altavilla", "Nicoletta Del Buono"], "title": "Jordan-Segmentable Masks: A Topology-Aware definition for characterizing Binary Image Segmentation", "categories": ["cs.CV", "math.AT", "math.NA"], "comment": "27 pages, 18 figures", "summary": "Image segmentation plays a central role in computer vision. However, widely used evaluation metrics, whether pixel-wise, region-based, or boundary-focused, often struggle to capture the structural and topological coherence of a segmentation. In many practical scenarios, such as medical imaging or object delineation, small inaccuracies in boundary, holes, or fragmented predictions can result in high metric scores, despite the fact that the resulting masks fail to preserve the object global shape or connectivity. This highlights a limitation of conventional metrics: they are unable to assess whether a predicted segmentation partitions the image into meaningful interior and exterior regions. In this work, we introduce a topology-aware notion of segmentation based on the Jordan Curve Theorem, and adapted for use in digital planes. We define the concept of a \\emph{Jordan-segmentatable mask}, which is a binary segmentation whose structure ensures a topological separation of the image domain into two connected components. We analyze segmentation masks through the lens of digital topology and homology theory, extracting a $4$-curve candidate from the mask, verifying its topological validity using Betti numbers. A mask is considered Jordan-segmentatable when this candidate forms a digital 4-curve with $β_0 = β_1 = 1$, or equivalently when its complement splits into exactly two $8$-connected components. This framework provides a mathematically rigorous, unsupervised criterion with which to assess the structural coherence of segmentation masks. By combining digital Jordan theory and homological invariants, our approach provides a valuable alternative to standard evaluation metrics, especially in applications where topological correctness must be preserved.", "AI": {"tldr": "本文介绍了一种基于Jordan曲线定理的拓扑感知分割方法，用于评估二值图像分割的质量。", "motivation": "传统的图像分割评价指标往往无法捕捉到结构和拓扑的一致性。在实际应用中，如医学成像或目标轮廓提取，边界的小误差、孔洞或断裂预测会导致高评分，但实际上这些预测未能保持对象的全局形状或连接性。", "method": "通过数字拓扑学和同调理论分析分割掩码，从掩码中抽取4曲线候选者，并使用贝蒂数验证其拓扑有效性。一个掩码被认为是Jordan可分段的当且仅当该候选者形成具有$β_0 = β_1 = 1$的数字4曲线，或等效地，它的补集分为两个8连通组件。", "result": "提供了一个数学上严格的、无监督的标准来评估分割掩码的结构一致性。这种方法为标准评估指标提供了一种有价值的替代方案，尤其是在需要保持拓扑正确性的应用中。", "conclusion": "该研究提出的方法基于数字Jordan理论和同调不变量，能够在不依赖于标签的情况下对二值图像的分割质量进行评价，特别是在需要保持对象全局形状或连接性一致的应用场景中提供了新的评估手段。"}}
{"id": "2601.10567", "pdf": "https://arxiv.org/pdf/2601.10567", "abs": "https://arxiv.org/abs/2601.10567", "authors": ["Laura Ferrarotti", "Gian Maria Campedelli", "Roberto Dessì", "Andrea Baronchelli", "Giovanni Iacca", "Kathleen M. Carley", "Alex Pentland", "Joel Z. Leibo", "James Evans", "Bruno Lepri"], "title": "Generative AI collective behavior needs an interactionist paradigm", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.LG", "cs.MA"], "comment": null, "summary": "In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.", "AI": {"tldr": "本文主张理解基于大型语言模型（LLMs）的智能体集体行为是一项重要研究领域，涉及风险与利益，并提出了一个互动主义范式来系统地探讨这些问题。", "motivation": "大规模语言模型独特的初始化预训练知识和隐含的社会先验以及通过上下文学习的能力，促使需要一个新的理论基础、方法论和分析工具的互动主义范式。", "method": "文章提议并讨论了四个关键方向，包括理论、方法论及跨学科对话，以促进LLM集体的发展与部署。", "result": "提出了一个互动主义范式来系统地研究大规模语言模型在多智能体生成AI系统中的行为如何受先前知识和嵌入价值观的影响，并与社会环境相互作用而产生的现象。", "conclusion": "强调了理解和评估基于大型语言模型的集体行为的重要性，以及需要一个新的理论框架来应对这些复杂挑战。"}}
{"id": "2601.10562", "pdf": "https://arxiv.org/pdf/2601.10562", "abs": "https://arxiv.org/abs/2601.10562", "authors": ["Reza M. Asiyabi", "SEOSAW Partnership", "Steven Hancock", "Casey Ryan"], "title": "Process-Guided Concept Bottleneck Model", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "13 pages with 7 figures and 1 table, Supplementary Materials 10 pages with 3 figures", "summary": "Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains learning to follow domain-defined causal mechanisms through biophysically meaningful intermediate concepts. Using above ground biomass density estimation from Earth Observation data as a case study, we show that PG-CBM reduces error and bias compared to multiple benchmarks, whilst leveraging multi-source heterogeneous training data and producing interpretable intermediate outputs. Beyond improved accuracy, PG-CBM enhances transparency, enables detection of spurious learning, and provides scientific insights, representing a step toward more trustworthy AI systems in scientific applications.", "AI": {"tldr": "本文提出了过程引导的概念瓶颈模型（PG-CBM），以改进现有概念瓶颈模型在科学领域应用的局限性，并通过案例研究展示了其减少误差和偏差的能力。", "motivation": "标准的概念瓶颈模型经常忽略特定领域的因果关系，且受限于完全的概念标签，在监督信息稀疏但流程定义明确的科学领域中适用性有限。因此，本文旨在提出一种改进的方法来提高模型在这些领域的表现和可解释性。", "method": "PG-CBM通过引入生物物理上有意义的中间概念来遵循预定义的因果机制，并利用多源异构训练数据进行学习，从而扩展了现有概念瓶颈模型的功能。", "result": "在使用地球观测数据估算地上生物量密度的研究案例中，与多个基准相比，PG-CBM降低了误差和偏差，并且产生了可解释的中间输出结果。", "conclusion": "PG-CBM不仅提高了准确性，还增强了透明度，能够检测到非预期学习，并提供了科学见解，这是朝着在科学应用中建立更值得信赖的人工智能系统迈出的一步。"}}
{"id": "2601.10560", "pdf": "https://arxiv.org/pdf/2601.10560", "abs": "https://arxiv.org/abs/2601.10560", "authors": ["Xi Shi", "Mengxin Zheng", "Qian Lou"], "title": "Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. In this work, we investigate learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution. We propose Latency-Aware Multi-agent System (LAMaS), a latency-aware multi-agent orchestration framework that enables parallel execution and explicitly optimizes the critical execution path, allowing the controller to construct execution topology graphs with lower latency under parallel execution. Our experiments show that our approach reduces critical path length by 38-46% compared to the state-of-the-art baseline for multi-agent architecture search across multiple benchmarks, while maintaining or even improving task performance. These results highlight the importance of explicitly optimizing latency under parallel execution when designing efficient multi-agent systems. The code is available at https://github.com/xishi404/LAMaS", "AI": {"tldr": "本文介绍了LAMaS框架，通过学习并优化多智能体系统中的关键执行路径来减少延迟。", "motivation": "现有的方法在优化任务性能和推理成本的同时忽略了降低延迟的重要性，尤其是在需要并行执行的场景下。为了提高多智能体系统的可扩展性和实用性，本文提出了一种新的基于学习的方法来优化延迟。", "method": "LAMaS是一种专门针对并行执行环境下多智能体系统的关键路径优化框架。它通过显式的延时监督学习机制，让控制器构建出具有较低关键路径长度的执行拓扑图。", "result": "实验结果显示，与现有的基线方法相比，本文的方法在多个基准测试中减少了38-46%的关键路径长度，并且维持或改善了任务性能。", "conclusion": "研究强调了在设计高效的多智能体系统时显式优化延迟的重要性。"}}
{"id": "2601.10556", "pdf": "https://arxiv.org/pdf/2601.10556", "abs": "https://arxiv.org/abs/2601.10556", "authors": ["Riccardo Fonti", "Andrea Piroddi"], "title": "Enhancing Mobile Ad Hoc Networks (MANETs) with Software-Defined Networking (SDN): A Balanced Approach", "categories": ["cs.NI", "cs.ET"], "comment": "ef:Journal of Advances in Computer Networks, vol. 13, no. 1, pp. 7-14, 2025", "summary": "Mobile Ad Hoc Networks (MANETs) are decentralized wireless networks, characterized by their dynamic topologies and node mobility. In the era of cutting-edge technologies, integrating Software-Defined Networking (SDN) with MANETs offers a promising solution to manage these challenges more efficiently. This paper presents a balanced discussion of MANETs and SDN, demonstrating how SDN principles, such as centralized control and network virtualization, can optimize MANET performance in terms of scalability, cost-efficiency, and security. A mathematical model is developed to analyze Capital Expenditures (CAPEX), Operational Expenditures (OPEX), and network efficiency.", "AI": {"tldr": "本文探讨了将软件定义网络（SDN）与移动自组织网络（MANETs）结合以优化性能的方法。", "motivation": "本文旨在解决MANETs面临的动态拓扑和节点移动性挑战，通过引入SDN的集中控制和网络虚拟化原则来提高其可扩展性、成本效益和安全性。", "method": "开发了一个数学模型分析资本支出（CAPEX）、运营支出（OPEX）以及网络效率。", "result": "展示了如何使用SDN优化MANET性能，改善了整体的网络管理效果。", "conclusion": "结论指出结合SDN与MANETs能够实现更好的网络性能和成本效益，并且提高了安全性。"}}
{"id": "2601.10554", "pdf": "https://arxiv.org/pdf/2601.10554", "abs": "https://arxiv.org/abs/2601.10554", "authors": ["Constantin Selzer", "Fabian B. Flohr"], "title": "DeepUrban: Interaction-Aware Trajectory Prediction and Planning for Automated Driving by Aerial Imagery", "categories": ["cs.CV"], "comment": "ef:2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC), Edmonton, AB, Canada, 2024, pp. 221-227", "summary": "The efficacy of autonomous driving systems hinges critically on robust prediction and planning capabilities. However, current benchmarks are impeded by a notable scarcity of scenarios featuring dense traffic, which is essential for understanding and modeling complex interactions among road users. To address this gap, we collaborated with our industrial partner, DeepScenario, to develop DeepUrban-a new drone dataset designed to enhance trajectory prediction and planning benchmarks focusing on dense urban settings. DeepUrban provides a rich collection of 3D traffic objects, extracted from high-resolution images captured over urban intersections at approximately 100 meters altitude. The dataset is further enriched with comprehensive map and scene information to support advanced modeling and simulation tasks. We evaluate state-of-the-art (SOTA) prediction and planning methods, and conducted experiments on generalization capabilities. Our findings demonstrate that adding DeepUrban to nuScenes can boost the accuracy of vehicle predictions and planning, achieving improvements up to 44.1 % / 44.3% on the ADE / FDE metrics. Website: https://iv.ee.hm.edu/deepurban", "AI": {"tldr": "开发DeepUrban数据集，以增强自动驾驶系统在密集城市环境中的轨迹预测和规划能力。", "motivation": "现有的基准测试缺乏密集交通场景的数据，这限制了对道路使用者之间复杂交互的理解和建模。为解决这一问题，本文与工业伙伴合作开发了新数据集DeepUrban。", "method": "利用高分辨率无人机图像捕捉城市交叉口的三维交通对象，并添加地图和场景信息来丰富数据集。评估现有先进预测和规划方法的表现，并进行泛化能力测试。", "result": "将DeepUrban加入nuScenes后，车辆轨迹预测和规划的准确性得到了显著提升，在ADE/FDE指标上分别提升了44.1%/44.3%。", "conclusion": "DeepUrban数据集有效增强了自动驾驶系统在处理密集城市交通场景时的性能。"}}
{"id": "2601.10553", "pdf": "https://arxiv.org/pdf/2601.10553", "abs": "https://arxiv.org/abs/2601.10553", "authors": ["Jianhao Yuan", "Xiaofeng Zhang", "Felix Friedrich", "Nicolas Beltran-Velez", "Melissa Hall", "Reyhane Askari-Hemmat", "Xiaochuang Han", "Nicolas Ballas", "Michal Drozdzal", "Adriana Romero-Soriano"], "title": "Inference-time Physics Alignment of Video Generative Models with Latent World Models", "categories": ["cs.CV"], "comment": "22 pages, 10 figures", "summary": "State-of-the-art video generative models produce promising visual content yet often violate basic physics principles, limiting their utility. While some attribute this deficiency to insufficient physics understanding from pre-training, we find that the shortfall in physics plausibility also stems from suboptimal inference strategies. We therefore introduce WMReward and treat improving physics plausibility of video generation as an inference-time alignment problem. In particular, we leverage the strong physics prior of a latent world model (here, VJEPA-2) as a reward to search and steer multiple candidate denoising trajectories, enabling scaling test-time compute for better generation performance. Empirically, our approach substantially improves physics plausibility across image-conditioned, multiframe-conditioned, and text-conditioned generation settings, with validation from human preference study. Notably, in the ICCV 2025 Perception Test PhysicsIQ Challenge, we achieve a final score of 62.64%, winning first place and outperforming the previous state of the art by 7.42%. Our work demonstrates the viability of using latent world models to improve physics plausibility of video generation, beyond this specific instantiation or parameterization.", "AI": {"tldr": "本文提出一种在视频生成模型推理阶段使用潜在世界模型来增强物理合理性的方法。", "motivation": "虽然现有视频生成模型可以产生视觉效果不错的图像，但它们往往违背基本的物理学原理，限制了其应用价值。作者认为问题不仅在于预训练时对物理学理解不足，还在于不理想的推理策略。", "method": "本文提出WMReward方法，利用潜在世界模型（VJEPA-2）作为奖励机制，在多个候选去噪轨迹中搜索和引导更符合物理规律的视频生成过程。", "result": "实验表明该方法在图像条件、多帧条件和文本条件下的视频生成设置下显著提高了物理学合理性，并赢得了ICCV 2025 Perception Test PhysicsIQ Challenge比赛的第一名，得分62.64%。", "conclusion": "研究证明了使用潜在世界模型提高视频生成物理合理性的可行性，并指出该方法不仅限于本文的具体实现或参数化。"}}
{"id": "2601.10551", "pdf": "https://arxiv.org/pdf/2601.10551", "abs": "https://arxiv.org/abs/2601.10551", "authors": ["Luxuan Fu", "Chong Liu", "Bisheng Yang", "Zhen Dong"], "title": "Unleashing the Capabilities of Large Vision-Language Models for Intelligent Perception of Roadside Infrastructure", "categories": ["cs.CV"], "comment": null, "summary": "Automated perception of urban roadside infrastructure is crucial for smart city management, yet general-purpose models often struggle to capture the necessary fine-grained attributes and domain rules. While Large Vision Language Models (VLMs) excel at open-world recognition, they often struggle to accurately interpret complex facility states in compliance with engineering standards, leading to unreliable performance in real-world applications. To address this, we propose a domain-adapted framework that transforms VLMs into specialized agents for intelligent infrastructure analysis. Our approach integrates a data-efficient fine-tuning strategy with a knowledge-grounded reasoning mechanism. Specifically, we leverage open-vocabulary fine-tuning on Grounding DINO to robustly localize diverse assets with minimal supervision, followed by LoRA-based adaptation on Qwen-VL for deep semantic attribute reasoning. To mitigate hallucinations and enforce professional compliance, we introduce a dual-modality Retrieval-Augmented Generation (RAG) module that dynamically retrieves authoritative industry standards and visual exemplars during inference. Evaluated on a comprehensive new dataset of urban roadside scenes, our framework achieves a detection performance of 58.9 mAP and an attribute recognition accuracy of 95.5%, demonstrating a robust solution for intelligent infrastructure monitoring.", "AI": {"tldr": "本文提出了一个领域适应框架，将大型视觉语言模型（VLMs）转化为专用于智能基础设施分析的专门代理。", "motivation": "现有的通用模型在捕捉城市路边基础设施的细粒度属性和遵守工程标准方面存在不足，导致其在实际应用中的表现不可靠。为了克服这些限制，提出了一个领域适应框架来增强大型视觉语言模型的性能。", "method": "该方法结合了数据高效的微调策略与基于知识推理机制。具体来说，使用开放词汇集细调Grounding DINO以稳健地定位资产，并采用LoRA技术在Qwen-VL上进行深度语义属性推理。此外，引入了一个双模态检索增强生成（RAG）模块来减少幻觉并确保专业合规性。", "result": "评估结果表明，在一个全面的城区路边场景数据集上，该框架实现了58.9 mAP的目标检测性能和95.5%的属性识别准确率。", "conclusion": "这项工作证明了所提出的方法能够为智能基础设施监控提供稳健解决方案。"}}
{"id": "2601.10547", "pdf": "https://arxiv.org/pdf/2601.10547", "abs": "https://arxiv.org/abs/2601.10547", "authors": ["Dongchao Yang", "Yuxin Xie", "Yuguo Yin", "Zheyu Wang", "Xiaoyu Yi", "Gongxi Zhu", "Xiaolong Weng", "Zihan Xiong", "Yingzhe Ma", "Dading Cong", "Jingliang Liu", "Zihang Huang", "Jinghan Ru", "Rongjie Huang", "Haoran Wan", "Peixu Wang", "Kuoxi Yu", "Helin Wang", "Liming Liang", "Xianwei Zhuang", "Yuanyuan Wang", "Haohan Guo", "Junjie Cao", "Zeqian Ju", "Songxiang Liu", "et al. (3 additional authors not shown)"], "title": "HeartMuLa: A Family of Open Sourced Music Foundation Models", "categories": ["cs.SD"], "comment": null, "summary": "We present a family of open-source Music Foundation Models designed to advance large-scale music understanding and generation across diverse tasks and modalities. Our framework consists of four major components: (1) HeartCLAP, an audio-text alignment model; (2) HeartTranscriptor, a robust lyric recognition model optimized for real-world music scenarios; and (3) HeartCodec, a low-frame-rate (12.5 Hz) yet high-fidelity music codec tokenizer that captures long-range musical structure while preserving fine-grained acoustic details and enabling efficient autoregressive modeling; (4) HeartMuLa, an LLM-based song generation model capable of synthesizing high-fidelity music under rich, user-controllable conditions (e.g., textual style descriptions, lyrics, and reference audio). In addition, it provides two specialized modes: (i) fine-grained musical attribute control, which allows users to specify the style of different song sections (e.g., intro, verse, chorus) using natural language prompts; and (ii) short, engaging music generation, which is suitable as background music for short videos. Lastly, HeartMuLa improves significantly when scaled to 7B parameters. For the first time, we show that a Suno-level, commercial-grade system can be reproduced using academic-scale data and GPU resources. We expect these foundation models to serve as strong baselines for future research and to facilitate practical applications in multimodal content production.", "AI": {"tldr": "介绍了一个开源音乐基础模型系列HeartMuLa，旨在推进大规模的音乐理解和生成。", "motivation": "推动音乐理解与生成技术的发展，并提供强大且开放的基础模型以促进未来的研究和实际应用。", "method": "开发了四个主要组件：音频文本对齐模型HeartCLAP、歌词识别模型HeartTranscriptor、音乐编解码器HeartCodec以及基于大语言模型的歌曲生成模型HeartMuLa，其中包括两种特殊模式以增强用户控制能力。", "result": "展示了在学术规模数据和GPU资源下创建一个Sunos级别的商业级系统的可能性，并且当参数扩展到7B时性能显著提升。", "conclusion": "这些基础模型可以作为未来研究的强大基线，并将促进多模态内容生产的实用应用。"}}
{"id": "2601.10544", "pdf": "https://arxiv.org/pdf/2601.10544", "abs": "https://arxiv.org/abs/2601.10544", "authors": ["Andrea Piroddi", "Riccardo Fonti"], "title": "SDN-Driven Innovations in MANETs and IoT: A Path to Smarter Networks", "categories": ["cs.NI", "cs.ET"], "comment": "ef:Journal of Advances in Information Technology, Vol. 16, No. 3, pp. 411-425, 2025", "summary": "Mobile Ad Hoc Networks (MANETs) and Internet of Things (IoT) networks operate in decentralized and dynamic environments, making them ideal for scenarios lacking traditional infrastructure. However, these networks face challenges such as inefficient routing, limited scalability, and security vulnerabilities due to their decentralized nature and resource constraints. This paper explores the integration of Software-Defined Networking (SDN) as a unified solution that leverages its centralized control and network programmability to improve routing, resource management, and security. A mathematical model evaluates the impact of SDN integration on Capital Expenditure (CAPEX), Operational Expenditure (OPEX), and performance metrics. Results demonstrate that SDN-enhanced MANETs and IoT networks offer superior scalability, reduced latency, increased throughput, and lower packet loss, especially in dynamic and large-scale environments. While SDN introduces computational overhead, it significantly enhances routing efficiency, resource optimization, and adaptability. The proposed framework provides a robust and scalable solution, enabling the development of network architectures that efficiently manage growing node densities, dynamic topologies, and high data traffic. This approach ensures resilience, making it well-suited to meet the performance and reliability demands of modern, large-scale applications.", "AI": {"tldr": "本文探讨了通过软件定义网络（SDN）集成来改进移动自组织网络（MANETs）和物联网（IoT）网络的路由、资源管理和安全性。", "motivation": "由于缺乏传统基础设施，MANETs和IoT网络在去中心化和动态环境中运作时面临诸如无效路由、扩展性限制和安全漏洞等挑战。SDN作为统一解决方案，通过其集中控制和网络可编程性来应对这些问题。", "method": "本文采用了一个数学模型来评估将SDN集成对资本支出（CAPEX）、运营支出（OPEX）和性能指标的影响。", "result": "结果显示，增强的SDN-MANETs和IoT网络在动态和大规模环境中提供更好的可扩展性、减少延迟、增加吞吐量并降低数据包丢失率。", "conclusion": "尽管SDN引入了计算开销，但它显著提高了路由效率、资源优化和适应能力。提出的框架为有效管理不断增加的节点密度、动态拓扑和高数据流量提供了稳健且可扩展的解决方案，确保网络在现代大规模应用中的可靠性和性能需求得到满足。"}}
{"id": "2601.10543", "pdf": "https://arxiv.org/pdf/2601.10543", "abs": "https://arxiv.org/abs/2601.10543", "authors": ["Yinzhi Zhao", "Ming Wang", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yifei Zhang"], "title": "Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved impressive performance across natural language tasks and are increasingly deployed in real-world applications. Despite extensive safety alignment efforts, recent studies show that such alignment is often shallow and remains vulnerable to jailbreak attacks. Existing defense mechanisms, including decoding-based constraints and post-hoc content detectors, struggle against sophisticated jailbreaks, often intervening robust detection or excessively degrading model utility. In this work, we examine the decoding process of LLMs and make a key observation: even when successfully jailbroken, models internally exhibit latent safety-related signals during generation. However, these signals are overridden by the model's drive for fluent continuation, preventing timely self-correction or refusal. Building on this observation, we propose a simple yet effective approach that explicitly surfaces and leverages these latent safety signals for early detection of unsafe content during decoding. Experiments across diverse jailbreak attacks demonstrate that our approach significantly enhances safety, while maintaining low over-refusal rates on benign inputs and preserving response quality. Our results suggest that activating intrinsic safety-awareness during decoding offers a promising and complementary direction for defending against jailbreak attacks. Code is available at: https://github.com/zyz13590/SafeProbing.", "AI": {"tldr": "通过在解码过程中激活内在的安全意识，提出了一种有效的方法来检测和防御大型语言模型的越狱攻击。", "motivation": "尽管进行了大量的安全对齐工作，现有的大型语言模型仍然容易受到越狱攻击的影响。现有的防御机制如解码约束和后期内容检测器难以应对复杂的越狱攻击，无法有效地检测或过度降级了模型的功能。", "method": "观察到即使在被成功越狱的情况下，模型在生成过程中也会表现出潜在的安全信号。该方法通过显式地揭示并利用这些内在的安全信号来早期检测解码过程中的不安全内容。", "result": "实验表明，在不同类型的越狱攻击下，所提出的方法显著提升了安全性，同时保持了对良性输入的低误拒绝率和响应质量。", "conclusion": "激活解码过程中固有的安全意识为防御越狱攻击提供了一个有希望且互补的方向。"}}
{"id": "2601.10537", "pdf": "https://arxiv.org/pdf/2601.10537", "abs": "https://arxiv.org/abs/2601.10537", "authors": ["Oscar H. Ramírez-Agudelo", "Akshay N. Shewatkar", "Edoardo Milana", "Roland C. Aydin", "Kai Franke"], "title": "Enhancing the quality of gauge images captured in smoke and haze scenes through deep learning", "categories": ["cs.CV"], "comment": "17 pages, 10 figures, 6 tables, SPIE Applications of Machine Learning 2023, San Diego, US", "summary": "Images captured in hazy and smoky environments suffer from reduced visibility, posing a challenge when monitoring infrastructures and hindering emergency services during critical situations. The proposed work investigates the use of the deep learning models to enhance the automatic, machine-based readability of gauge in smoky environments, with accurate gauge data interpretation serving as a valuable tool for first responders. The study utilizes two deep learning architectures, FFA-Net and AECR-Net, to improve the visibility of gauge images, corrupted with light up to dense haze and smoke. Since benchmark datasets of analog gauge images are unavailable, a new synthetic dataset, containing over 14,000 images, was generated using the Unreal Engine. The models were trained with an 80\\% train, 10\\% validation, and 10\\% test split for the haze and smoke dataset, respectively. For the synthetic haze dataset, the SSIM and PSNR metrics are about 0.98 and 43\\,dB, respectively, comparing well to state-of-the art results. Additionally, more robust results are retrieved from the AECR-Net, when compared to the FFA-Net. Although the results from the synthetic smoke dataset are poorer, the trained models achieve interesting results. In general, imaging in the presence of smoke are more difficult to enhance given the inhomogeneity and high density. Secondly, FFA-Net and AECR-Net are implemented to dehaze and not to desmoke images. This work shows that use of deep learning architectures can improve the quality of analog gauge images captured in smoke and haze scenes immensely. Finally, the enhanced output images can be successfully post-processed for automatic autonomous reading of gauges", "AI": {"tldr": "本文研究了在烟雾和雾霾环境中使用深度学习模型来提高刻度图像的自动机器可读性。", "motivation": "烟雾和雾霾环境中的图像捕捉会导致能见度降低，这给基础设施监控和紧急服务带来了挑战。改善这些场景下刻度图像的质量对于第一响应者来说非常重要。", "method": "研究使用了FFA-Net和AECR-Net两种深度学习架构来提升被轻到重度烟雾和雾霾污染的刻度图像的可见性，创建了一个包含超过14,000张图片的新合成数据集用于训练模型。", "result": "对于合成雾霾数据集，SSIM和PSNR指标分别约为0.98和43 dB，与现有最先进结果相比表现良好。在烟雾数据集中AECR-Net的效果比FFA-Net好，但总体上改善含烟图像的难度更大。", "conclusion": "通过深度学习架构可以大大提升在烟雾和雾霾场景中捕捉到的刻度图像的质量，并且这些增强后的图像能够成功用于自动读取刻度。"}}
{"id": "2601.10536", "pdf": "https://arxiv.org/pdf/2601.10536", "abs": "https://arxiv.org/abs/2601.10536", "authors": ["Ishani Kanapathipillai", "Obhasha Priyankara"], "title": "CoGen: Creation of Reusable UI Components in Figma via Textual Commands", "categories": ["cs.HC", "cs.LG"], "comment": "8 pages, 6 figures, 11 tables", "summary": "The evolution of User Interface design has emphasized the need for efficient, reusable, and editable components to ensure an efficient design process. This research introduces CoGen, a system that uses machine learning techniques to generate reusable UI components directly in Figma, one of the most popular UI design tools. Addressing gaps in current systems, CoGen focuses on creating atomic components such as buttons, labels, and input fields using structured JSON and natural language prompts. The project integrates Figma API data extraction, Seq2Seq models, and fine-tuned T5 transformers for component generation. The key results demonstrate the efficiency of the T5 model in prompt generation, with an accuracy of 98% and a BLEU score of 0.2668, which ensures the mapping of JSON to descriptive prompts. For JSON creation, CoGen achieves a success rate of up to 100% in generating simple JSON outputs for specified component types.", "AI": {"tldr": "本文介绍了CoGen系统，该系统使用机器学习技术根据文本命令在Figma中生成可重用的UI组件。", "motivation": "随着用户界面设计的发展，高效、可复用和易于编辑的组件变得越来越重要。现有的系统存在一些不足之处，因此提出了CoGen来解决这些问题并提高设计流程的效率。", "method": "CoGen采用Figma API数据提取、Seq2Seq模型以及微调后的T5变换器生成UI组件，主要利用结构化的JSON和自然语言提示来创建原子组件如按钮、标签和输入字段等。", "result": "实验结果表明，T5模型在提示生成方面的准确率为98%，BLEU评分为0.2668，确保了从JSON到描述性提示的映射准确性；CoGen在简单JSON输出生成方面达到了100%的成功率。", "conclusion": "研究证明了CoGen系统能够有效且高效地根据文本命令自动创建可复用的UI组件，从而提高设计工作的效率和质量。"}}
{"id": "2601.10535", "pdf": "https://arxiv.org/pdf/2601.10535", "abs": "https://arxiv.org/abs/2601.10535", "authors": ["Chong Liu", "Luxuan Fu", "Yang Jia", "Zhen Dong", "Bisheng Yang"], "title": "SVII-3D: Advancing Roadside Infrastructure Inventory with Decimeter-level 3D Localization and Comprehension from Sparse Street Imagery", "categories": ["cs.CV"], "comment": null, "summary": "The automated creation of digital twins and precise asset inventories is a critical task in smart city construction and facility lifecycle management. However, utilizing cost-effective sparse imagery remains challenging due to limited robustness, inaccurate localization, and a lack of fine-grained state understanding. To address these limitations, SVII-3D, a unified framework for holistic asset digitization, is proposed. First, LoRA fine-tuned open-set detection is fused with a spatial-attention matching network to robustly associate observations across sparse views. Second, a geometry-guided refinement mechanism is introduced to resolve structural errors, achieving precise decimeter-level 3D localization. Third, transcending static geometric mapping, a Vision-Language Model agent leveraging multi-modal prompting is incorporated to automatically diagnose fine-grained operational states. Experiments demonstrate that SVII-3D significantly improves identification accuracy and minimizes localization errors. Consequently, this framework offers a scalable, cost-effective solution for high-fidelity infrastructure digitization, effectively bridging the gap between sparse perception and automated intelligent maintenance.", "AI": {"tldr": "SVII-3D提出了一个统一的框架，用于从稀疏街道图像中实现道路基础设施的详细三维定位和理解。", "motivation": "自动创建数字孪生和精确资产清单对于智能城市建设和设施生命周期管理至关重要。然而，使用成本效益高的稀疏影像进行操作仍然具有挑战性，因为它存在鲁棒性差、定位不准确以及缺乏细粒度状态理解的问题。", "method": "SVII-3D方法包括三个部分：第一，利用LoRA微调的开放集检测和空间注意力匹配网络融合来跨稀疏视图稳健地关联观测结果；第二，引入几何引导校正机制以解决结构错误并实现厘米级精确三维定位；第三，在视觉语言模型代理中采用多模态提示自动诊断细粒度操作状态。", "result": "实验表明SVII-3D显著提高了识别精度和最小化了定位误差，提供了一个可扩展且成本效益高的高质量基础设施数字化解决方案。", "conclusion": "SVII-3D框架有效解决了稀疏感知与自动化智能维护之间的差距问题，并在高保真基础设施数字孪生创建中提供了可靠的解决方案。"}}
{"id": "2601.10527", "pdf": "https://arxiv.org/pdf/2601.10527", "abs": "https://arxiv.org/abs/2601.10527", "authors": ["Xingjun Ma", "Yixu Wang", "Hengyuan Xu", "Yutao Wu", "Yifan Ding", "Yunhan Zhao", "Zilong Wang", "Jiabin Hua", "Ming Wen", "Jianan Liu", "Ranjie Duan", "Yifeng Gao", "Yingshui Tan", "Yunhao Chen", "Hui Xue", "Xin Wang", "Wei Cheng", "Jingjing Chen", "Zuxuan Wu", "Bo Li", "Yu-Gang Jiang"], "title": "A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "41 pages, 22 figures", "summary": "The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has driven major gains in reasoning, perception, and generation across language and vision, yet whether these advances translate into comparable improvements in safety remains unclear, partly due to fragmented evaluations that focus on isolated modalities or threat models. In this report, we present an integrated safety evaluation of six frontier models--GPT-5.2, Gemini 3 Pro, Qwen3-VL, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5--assessing each across language, vision-language, and image generation using a unified protocol that combines benchmark, adversarial, multilingual, and compliance evaluations. By aggregating results into safety leaderboards and model profiles, we reveal a highly uneven safety landscape: while GPT-5.2 demonstrates consistently strong and balanced performance, other models exhibit clear trade-offs across benchmark safety, adversarial robustness, multilingual generalization, and regulatory compliance. Despite strong results under standard benchmarks, all models remain highly vulnerable under adversarial testing, with worst-case safety rates dropping below 6%. Text-to-image models show slightly stronger alignment in regulated visual risk categories, yet remain fragile when faced with adversarial or semantically ambiguous prompts. Overall, these findings highlight that safety in frontier models is inherently multidimensional--shaped by modality, language, and evaluation design--underscoring the need for standardized, holistic safety assessments to better reflect real-world risk and guide responsible deployment.", "AI": {"tldr": "本文对六种前沿大型语言模型和多模态大型语言模型进行了综合安全评估，包括语言、视觉-语言和图像生成方面。", "motivation": "随着大规模语言模型和多模态大规模语言模型的快速发展，虽然它们在推理、感知和生成等方面取得了显著进展，但这些进步是否转化为类似的安全性改善尚不清楚。现有的碎片化评价方法主要集中在孤立的模式或威胁模型上。", "method": "采用统一评估协议对六种前沿模型进行综合安全评估，涵盖基准测试、对抗性评估、多语言评估和合规性评估。", "result": "GPT-5.2表现出一致的强健且均衡的安全性能，而其他模型在不同方面的安全性表现各异。所有模型在标准基准下表现良好但在对抗测试中非常脆弱，最坏情况下的安全率降至6%以下。", "conclusion": "前沿模型的安全性是多维度的，受模式、语言和评估设计的影响，强调需要标准化、全面的安全评估以更好地反映现实世界的风险并指导负责任地部署。"}}
{"id": "2601.10525", "pdf": "https://arxiv.org/pdf/2601.10525", "abs": "https://arxiv.org/abs/2601.10525", "authors": ["Yijin Zhou", "Fu Li", "Yi Niu", "Boxun Fu", "Huaning Wang", "Lijian Zhang"], "title": "Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition", "categories": ["cs.HC"], "comment": null, "summary": "Understanding how local neurophysiological patterns interact with global brain dynamics is essential for decoding human emotions from EEG signals. However, existing deep learning approaches often overlook the brain's intrinsic spatial organization, failing to simultaneously capture local topological relations and global dependencies. To address these challenges, we propose Neuro-HGLN, a Neurologically-informed Hierarchical Graph-Transformer Learning Network that integrates biologically grounded priors with hierarchical representation learning. Neuro-HGLN first constructs a spatial Euclidean prior graph based on physical electrode distances to serve as an anatomically grounded inductive bias. A learnable global dynamic graph is then introduced to model functional connectivity across the entire brain. In parallel, to capture fine-grained regional dependencies, Neuro-HGLN builds region-level local graphs using a multi-head self-attention mechanism. These graphs are processed synchronously through local-constrained parallel GCN layers to produce region-specific representations. Subsequently, an iTransformer encoder aggregates these features to capture cross-region dependencies under a dimension-as-token formulation. Extensive experiments demonstrate that Neuro-HGLN achieves state-of-the-art performance on multiple benchmarks, providing enhanced interpretability grounded in neurophysiological structure. These results highlight the efficacy of unifying local topological learning with cross-region dependency modeling for robust EEG emotion recognition.", "AI": {"tldr": "本文提出了一种称为Neuro-HGLN的神经学导向的分层图变换学习网络，用于通过脑电波信号识别情绪。", "motivation": "现有的深度学习方法往往忽略了大脑内在的空间组织结构，不能同时捕捉局部拓扑关系和全局依赖性。为此，作者提出了一种新的模型来解决这些问题。", "method": "Neuro-HGLN首先基于物理电极距离构建一个空间欧几里得先验图作为解剖学上的归纳偏置；引入可学习的全局动态图以模拟全脑的功能连接；并通过多头自注意力机制构建区域级局部图，使用同步本地约束并行GCN层来生成区域特定表示，并通过iTransformer编码器聚合这些特征。", "result": "实验表明Neuro-HGLN在多个基准数据集上取得了最先进的性能，提供了基于神经生理结构的增强解释性。", "conclusion": "将局部拓扑学习与跨区域依赖建模相结合对于实现鲁棒的脑电波情绪识别是非常有效的。"}}
{"id": "2601.10524", "pdf": "https://arxiv.org/pdf/2601.10524", "abs": "https://arxiv.org/abs/2601.10524", "authors": ["Frank Bobe III", "Gregory D. Vetaw", "Chase Pavlick", "Darshan Bryner", "Matthew Cook", "Jose Salas-Vernis"], "title": "Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection", "categories": ["cs.AI"], "comment": "16 pages, 6 figures, 6 tables", "summary": "The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91\\% F1), but only when trained on a stylistically diverse ``generalist'' dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy.", "AI": {"tldr": "本研究通过多层诊断框架分析了三种大型语言模型在细调后的钓鱼检测任务中的泛化失败问题。", "motivation": "尽管大型语言模型的微调已达到顶尖性能，但仍需解决为什么这些模型变得脆弱且无法很好地泛化的关键性难题。", "method": "研究者们对Llama 3.1 8B、Gemma 2 9B和Mistral模型进行了细调，并采用SHAP分析和机制可解释性方法来揭示它们的泛化失败的根本原因。", "result": "研究发现，泛化是由架构和数据多样性之间的强大协同作用驱动；不同的模型对训练数据多样性的需求不同，某些架构本质上更具泛化能力；通过确定导致这些失败的错误启发式规则，本工作提供了诊断和理解泛化失败的具体方法论。", "conclusion": "可靠的AI需要深入验证架构、数据和训练策略之间的相互作用。"}}
{"id": "2601.10521", "pdf": "https://arxiv.org/pdf/2601.10521", "abs": "https://arxiv.org/abs/2601.10521", "authors": ["Max A. Buettner", "Kanak Mazumder", "Luca Koecher", "Mario Finkbeiner", "Sebastian Niebler", "Fabian B. Flohr"], "title": "BikeActions: An Open Platform and Benchmark for Cyclist-Centric VRU Action Recognition", "categories": ["cs.CV"], "comment": "This work has been submitted to the IEEE ICPR for possible publication", "summary": "Anticipating the intentions of Vulnerable Road Users (VRUs) is a critical challenge for safe autonomous driving (AD) and mobile robotics. While current research predominantly focuses on pedestrian crossing behaviors from a vehicle's perspective, interactions within dense shared spaces remain underexplored. To bridge this gap, we introduce FUSE-Bike, the first fully open perception platform of its kind. Equipped with two LiDARs, a camera, and GNSS, it facilitates high-fidelity, close-range data capture directly from a cyclist's viewpoint. Leveraging this platform, we present BikeActions, a novel multi-modal dataset comprising 852 annotated samples across 5 distinct action classes, specifically tailored to improve VRU behavior modeling. We establish a rigorous benchmark by evaluating state-of-the-art graph convolution and transformer-based models on our publicly released data splits, establishing the first performance baselines for this challenging task. We release the full dataset together with data curation tools, the open hardware design, and the benchmark code to foster future research in VRU action understanding under https://iv.ee.hm.edu/bikeactions/.", "AI": {"tldr": "本文介绍了BikeActions，一个用于骑行者为中心的VRU行为识别的开放平台和基准。", "motivation": "鉴于当前研究主要集中在从车辆视角预测行人穿越行为，而密集共享空间内的交互尚待探索，本研究旨在填补这一空白，并促进自动驾驶及移动机器人领域中对易受伤害道路使用者行为的理解。", "method": "开发了FUSE-Bike平台，该平台配备两个激光雷达、一个相机和GNSS，以从骑行者的视角进行高保真数据采集。通过这个平台建立了BikeActions多模态数据集，并对其进行了评测。", "result": "发布了包含852个标注样本的新型多模态数据集，覆盖了5种不同的动作类别，并评估了图卷积和基于变换器模型在该基准上的表现。", "conclusion": "为骑行者视角下的VRU行为识别提供了第一个性能基线，并公开了整个数据集、数据整理工具、开放硬件设计以及基准代码，以促进未来的研究。"}}
{"id": "2601.10520", "pdf": "https://arxiv.org/pdf/2601.10520", "abs": "https://arxiv.org/abs/2601.10520", "authors": ["Felix Jahn", "Yannic Muskalla", "Lisa Dargasz", "Patrick Schramowski", "Kevin Baum"], "title": "Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment", "categories": ["cs.AI", "cs.CY"], "comment": "10 pages, 4 figures, accepted at 2nd Annual Conference of the International Association for Safe & Ethical AI (IASEAI'26)", "summary": "As AI agents become increasingly autonomous, widely deployed in consequential contexts, and efficacious in bringing about real-world impacts, ensuring that their decisions are not only instrumentally effective but also normatively aligned has become critical. We introduce a neuro-symbolic reason-based containment architecture, Governor for Reason-Aligned ContainmEnt (GRACE), that decouples normative reasoning from instrumental decision-making and can contain AI agents of virtually any design. GRACE restructures decision-making into three modules: a Moral Module (MM) that determines permissible macro actions via deontic logic-based reasoning; a Decision-Making Module (DMM) that encapsulates the target agent while selecting instrumentally optimal primitive actions in accordance with derived macro actions; and a Guard that monitors and enforces moral compliance. The MM uses a reason-based formalism providing a semantic foundation for deontic logic, enabling interpretability, contestability, and justifiability. Its symbolic representation enriches the DMM's informational context and supports formal verification and statistical guarantees of alignment enforced by the Guard. We demonstrate GRACE on an example of a LLM therapy assistant, showing how it enables stakeholders to understand, contest, and refine agent behavior.", "AI": {"tldr": "介绍了一个名为GRACE的神经符号推理架构，旨在确保AI决策不仅有效而且符合道德规范。", "motivation": "随着自主AI在关键场景中的广泛应用及其对现实世界的影响日益增加，需要确保其决策不仅是有效的，还要与道德标准一致。", "method": "GRACE框架包含三个模块：道德模块（MM）、决策制定模块（DMM）和守卫。MM通过德性逻辑推理决定允许的宏观行为；DMM在遵循这些宏观行为的同时选择最优微观行动；守卫监控并强制执行道德合规。", "result": "展示了GRACE如何应用于一个大型语言模型（LLM）治疗助手实例中，使利益相关者能够理解、质疑和优化代理行为。", "conclusion": "GRACE框架通过解耦规范性推理与工具理性决策，提供了确保AI系统伦理对齐的途径，并且增强了系统的透明度和可解释性。"}}
{"id": "2601.10513", "pdf": "https://arxiv.org/pdf/2601.10513", "abs": "https://arxiv.org/abs/2601.10513", "authors": ["Xuan Luo", "Lewei Yao", "Libo Zhao", "Lanqing Hong", "Kai Chen", "Dehua Tao", "Daxin Tan", "Ruifeng Xu", "Jing Li"], "title": "AEQ-Bench: Measuring Empathy of Omni-Modal Large Models", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "While the automatic evaluation of omni-modal large models (OLMs) is essential, assessing empathy remains a significant challenge due to its inherent affectivity. To investigate this challenge, we introduce AEQ-Bench (Audio Empathy Quotient Benchmark), a novel benchmark to systematically assess two core empathetic capabilities of OLMs: (i) generating empathetic responses by comprehending affective cues from multi-modal inputs (audio + text), and (ii) judging the empathy of audio responses without relying on text transcription. Compared to existing benchmarks, AEQ-Bench incorporates two novel settings that vary in context specificity and speech tone. Comprehensive assessment across linguistic and paralinguistic metrics reveals that (1) OLMs trained with audio output capabilities generally outperformed models with text-only outputs, and (2) while OLMs align with human judgments for coarse-grained quality assessment, they remain unreliable for evaluating fine-grained paralinguistic expressiveness.", "AI": {"tldr": "本文介绍了AEQ-Bench，一个用于系统评估多模态大型模型（OLMs）同理心能力的新基准。", "motivation": "自动评估OLMs的同理心是一个重大挑战，因为其涉及情感性。为此，作者设计了AEQ-Bench来解决这一问题。", "method": "通过引入两个新的设置，分别改变上下文特异性和语音语调，AEQ-Bench系统地评估了多模态输入下的同理心生成和对音频响应的评价能力。", "result": "综合评估表明，具有音频输出功能的OLMs比仅使用文本输出的模型表现更好；OLMs在粗粒度质量评估上与人类判断一致，但在细粒度非语言表达性方面仍然不可靠。", "conclusion": "AEQ-Bench提供了一种新的方法来系统地评估多模态大型模型的同理心能力，并指出这些模型在处理复杂情感表达时存在局限性。"}}
