{"id": "2601.22159", "pdf": "https://arxiv.org/pdf/2601.22159", "abs": "https://arxiv.org/abs/2601.22159", "authors": ["Naufal Suryanto", "Muzammal Naseer", "Pengfei Li", "Syed Talal Wasim", "Jinhui Yi", "Juergen Gall", "Paolo Ceravolo", "Ernesto Damiani"], "title": "RedSage: A Cybersecurity Generalist LLM", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "Accepted on ICLR 2026; Project page: https://risys-lab.github.io/RedSage/", "summary": "Cybersecurity operations demand assistant LLMs that support diverse workflows without exposing sensitive data. Existing solutions either rely on proprietary APIs with privacy risks or on open models lacking domain adaptation. To bridge this gap, we curate 11.8B tokens of cybersecurity-focused continual pretraining data via large-scale web filtering and manual collection of high-quality resources, spanning 28.6K documents across frameworks, offensive techniques, and security tools. Building on this, we design an agentic augmentation pipeline that simulates expert workflows to generate 266K multi-turn cybersecurity samples for supervised fine-tuning. Combined with general open-source LLM data, these resources enable the training of RedSage, an open-source, locally deployable cybersecurity assistant with domain-aware pretraining and post-training. To rigorously evaluate the models, we introduce RedSage-Bench, a benchmark with 30K multiple-choice and 240 open-ended Q&A items covering cybersecurity knowledge, skills, and tool expertise. RedSage is further evaluated on established cybersecurity benchmarks (e.g., CTI-Bench, CyberMetric, SECURE) and general LLM benchmarks to assess broader generalization. At the 8B scale, RedSage achieves consistently better results, surpassing the baseline models by up to +5.59 points on cybersecurity benchmarks and +5.05 points on Open LLM Leaderboard tasks. These findings demonstrate that domain-aware agentic augmentation and pre/post-training can not only enhance cybersecurity-specific expertise but also help to improve general reasoning and instruction-following. All models, datasets, and code are publicly available.", "AI": {"tldr": "该论文介绍了一种名为RedSage的网络安全领域的大型语言模型，旨在提高对网络安全任务的理解和执行能力。", "motivation": "现有的解决方案要么依赖于具有隐私风险的专有API，要么使用缺乏领域适应性的开源模型。为了填补这一空白，作者开发了一款专门针对网络安全问题设计的语言模型。", "method": "通过大规模网络过滤和高质量资源的手动收集，生成了11.8亿个令牌的数据集；随后利用模拟专家工作流程的代理增强管道产生了266K个多轮次的网络安全样本。这些数据与通用开源LLM数据结合用于训练RedSage。", "result": "在8B规模下，RedSage的表现优于基线模型，在网络安全基准上最多提高了5.59分，并且在开放性LLM排行榜任务中表现出更高的性能。", "conclusion": "研究表明，领域感知的代理增强和预/后训练不仅能提高特定领域的专业知识，还能改进通用推理能力。"}}
{"id": "2601.22158", "pdf": "https://arxiv.org/pdf/2601.22158", "abs": "https://arxiv.org/abs/2601.22158", "authors": ["Yiyang Lu", "Susie Lu", "Qiao Sun", "Hanhong Zhao", "Zhicheng Jiang", "Xianbang Wang", "Tianhong Li", "Zhengyang Geng", "Kaiming He"], "title": "One-step Latent-free Image Generation with Pixel Mean Flows", "categories": ["cs.CV"], "comment": "Technical report", "summary": "Modern diffusion/flow-based models for image generation typically exhibit two core characteristics: (i) using multi-step sampling, and (ii) operating in a latent space. Recent advances have made encouraging progress on each aspect individually, paving the way toward one-step diffusion/flow without latents. In this work, we take a further step towards this goal and propose \"pixel MeanFlow\" (pMF). Our core guideline is to formulate the network output space and the loss space separately. The network target is designed to be on a presumed low-dimensional image manifold (i.e., x-prediction), while the loss is defined via MeanFlow in the velocity space. We introduce a simple transformation between the image manifold and the average velocity field. In experiments, pMF achieves strong results for one-step latent-free generation on ImageNet at 256x256 resolution (2.22 FID) and 512x512 resolution (2.48 FID), filling a key missing piece in this regime. We hope that our study will further advance the boundaries of diffusion/flow-based generative models.", "AI": {"tldr": "本文提出了一种名为“像素均值流”(pMF)的方法，用于一步无潜在变量的图像生成。", "motivation": "现代扩散/流动模型通常需要多步采样并操作在潜在空间中。该论文旨在实现单步骤、无需潜在变量的图像生成。", "method": "通过在网络输出空间和损失空间之间定义一个简单的转换，设计了网络目标为预测低维图像流形中的像素（即x-预测），而损失则通过速度场中的均值流动来定义。", "result": "实验结果表明，在ImageNet数据集的256x256和512x512分辨率下，pMF模型获得了优秀的生成效果（FID分别为2.22和2.48），填补了该领域的空白。", "conclusion": "这项研究推进了扩散/流动基于生成模型的发展边界。"}}
{"id": "2601.22156", "pdf": "https://arxiv.org/pdf/2601.22156", "abs": "https://arxiv.org/abs/2601.22156", "authors": ["Yingfa Chen", "Zhen Leng Thai", "Zihan Zhou", "Zhu Zhang", "Xingyu Shen", "Shuo Wang", "Chaojun Xiao", "Xu Han", "Zhiyuan Liu"], "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "20 pages, 8 figures", "summary": "Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data", "AI": {"tldr": "提出了一种将Transformer模型转换为RNN注意混合模型的管道HALO，并引入了HypeNet架构，该架构具有更优的长度泛化能力。", "motivation": "旨在解决大规模预训练过程中成本高昂的问题，并提高长上下文场景下的性能和效率。", "method": "通过参数转移和知识蒸馏将Transformer注意力块转换为RNN注意力混合模型；引入了HypeNet架构，采用了一种新的位置编码方案（HyPE）并进行了多种架构修改。", "result": "在仅使用2.3B标记的情况下成功将Qwen3系列转化为HypeNet，实现了与原始Transformer模型相当的性能，同时表现出更优的长上下文性能和效率。", "conclusion": "提出的HALO管道和HypeNet架构有效解决了混合Transformer模型预训练成本高昂及长上下文场景下性能不足的问题。"}}
{"id": "2601.22155", "pdf": "https://arxiv.org/pdf/2601.22155", "abs": "https://arxiv.org/abs/2601.22155", "authors": ["Bo Li", "Yida Yin", "Wenhao Chai", "Xingyu Fu", "Zhuang Liu"], "title": "UEval: A Benchmark for Unified Multimodal Generation", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "We introduce UEval, a benchmark to evaluate unified models, i.e., models capable of generating both images and text. UEval comprises 1,000 expert-curated questions that require both images and text in the model output, sourced from 8 real-world tasks. Our curated questions cover a wide range of reasoning types, from step-by-step guides to textbook explanations. Evaluating open-ended multimodal generation is non-trivial, as simple LLM-as-a-judge methods can miss the subtleties. Different from previous works that rely on multimodal Large Language Models (MLLMs) to rate image quality or text accuracy, we design a rubric-based scoring system in UEval. For each question, reference images and text answers are provided to a MLLM to generate an initial rubric, consisting of multiple evaluation criteria, and human experts then refine and validate these rubrics. In total, UEval contains 10,417 validated rubric criteria, enabling scalable and fine-grained automatic scoring. UEval is challenging for current unified models: GPT-5-Thinking scores only 66.4 out of 100, while the best open-source model reaches merely 49.1. We observe that reasoning models often outperform non-reasoning ones, and transferring reasoning traces from a reasoning model to a non-reasoning model significantly narrows the gap. This suggests that reasoning may be important for tasks requiring complex multimodal understanding and generation.", "AI": {"tldr": "介绍UEval，一个用于评估统一生成模型的基准。", "motivation": "当前对多模态生成的评估较为困难，简单的LLM评分方法容易遗漏细节。现有工作依赖于MLLM进行图像质量和文本准确性评价，但这种方法可能不够全面和细致。", "method": "设计了一个基于评分准则的方法来评估统一生成模型的表现。通过专家团队整理出1000个涵盖多种推理类型的问题，并为每个问题提供了参照的图片及答案以供MLLM生成初步评分准则，再由人类专家进行调整和完善。", "result": "UEval包含了总计10417条经过验证的评分标准，用于自动化评估。结果显示，GPT-5-Thinking模型在UEval上得分仅为66.4分，而最好的开源模型仅得49.1分。发现具备推理能力的模型往往表现更好。", "conclusion": "表明对需要复杂多模态理解和生成的任务来说，推理可能是关键因素。"}}
{"id": "2601.22154", "pdf": "https://arxiv.org/pdf/2601.22154", "abs": "https://arxiv.org/abs/2601.22154", "authors": ["Kaixuan Fan", "Kaituo Feng", "Manyuan Zhang", "Tianshuo Peng", "Zhixun Li", "Yilei Jiang", "Shuang Chen", "Peng Pei", "Xunliang Cai", "Xiangyu Yue"], "title": "Exploring Reasoning Reward Model for Agents", "categories": ["cs.AI", "cs.CL"], "comment": "Project page: https://github.com/kxfan2002/Reagent", "summary": "Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a multi-faceted reward model that produces structured feedback for agentic trajectories, including (1) an explicit reasoning trace , (2) a focused critique that provides refinement guidance by highlighting reasoning flaws, and (3) an overall score that evaluates process performance. Leveraging these signals, we systematically investigate three integration strategies: Reagent-C (text-augmented refinement), Reagent-R (reward-augmented guidance), and Reagent-U (unified feedback integration). Extensive evaluations across 12 diverse benchmarks demonstrate that Reagent-U yields substantial performance leaps, achieving 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of our reasoning reward model and training schemes. Code, models, and datasets are all released to facilitate future research.", "AI": {"tldr": "介绍了一种新型的代理推理奖励模型（Agent RRM），以改善代理人训练中的推理质量。", "motivation": "现有方法依赖稀疏结果反馈，无法区分中间推理过程的质量，导致训练效果不佳。因此需要一种能够提供结构化反馈的模型来优化训练过程。", "method": "提出了一种多面奖励模型Agent RRM，包括明确的推理轨迹、专注批评和总体评分信号，并探讨了三种集成策略：Reagent-C（文本增强细化）、Reagent-R（奖励增强指导）和Reagent-U（统一反馈整合）。", "result": "在12个不同的基准测试中进行了广泛的评估，结果显示使用Reagent-U取得了显著的性能提升，在GAIA上达到43.7%，WebWalkerQA上达到46.2%。", "conclusion": "新的推理奖励模型及其训练方案的有效性得到了验证，并且提供了代码、模型和数据集以推动未来研究。"}}
{"id": "2601.22153", "pdf": "https://arxiv.org/pdf/2601.22153", "abs": "https://arxiv.org/abs/2601.22153", "authors": ["Haozhe Xie", "Beichen Wen", "Jiarui Zheng", "Zhaoxi Chen", "Fangzhou Hong", "Haiwen Diao", "Ziwei Liu"], "title": "DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "Project Page: https://www.infinitescript.com/project/dynamic-vla/ GitHub: https://github.com/hzxie/DynamicVLA", "summary": "Manipulating dynamic objects remains an open challenge for Vision-Language-Action (VLA) models, which, despite strong generalization in static manipulation, struggle in dynamic scenarios requiring rapid perception, temporal anticipation, and continuous control. We present DynamicVLA, a framework for dynamic object manipulation that integrates temporal reasoning and closed-loop adaptation through three key designs: 1) a compact 0.4B VLA using a convolutional vision encoder for spatially efficient, structurally faithful encoding, enabling fast multimodal inference; 2) Continuous Inference, enabling overlapping reasoning and execution for lower latency and timely adaptation to object motion; and 3) Latent-aware Action Streaming, which bridges the perception-execution gap by enforcing temporally aligned action execution. To fill the missing foundation of dynamic manipulation data, we introduce the Dynamic Object Manipulation (DOM) benchmark, built from scratch with an auto data collection pipeline that efficiently gathers 200K synthetic episodes across 2.8K scenes and 206 objects, and enables fast collection of 2K real-world episodes without teleoperation. Extensive evaluations demonstrate remarkable improvements in response speed, perception, and generalization, positioning DynamicVLA as a unified framework for general dynamic object manipulation across embodiments.", "AI": {"tldr": "DynamicVLA是一个框架，用于动态物体操作的视觉语言动作模型。", "motivation": "传统的视觉语言动作（VLA）模型在静态环境中表现良好，但在需要快速感知、时间预测和连续控制的动态场景中却面临挑战。为了克服这一问题，作者提出了一个新框架来解决动态物体操纵的问题。", "method": "DynamicVLA通过三个关键设计：1. 0.4B VLA模型使用卷积视觉编码器进行空间高效、结构忠实的编码；2. 连续推理，使重叠推理和执行成为可能，降低延迟并及时适应物体运动；3. 潜在感知动作流媒体，通过强制时间对齐的动作执行来弥合感知与执行之间的差距。此外，作者还引入了动态对象操纵（DOM）基准测试。", "result": "广泛的评估展示了DynamicVLA在响应速度、感知和泛化能力方面的显著改进，并将其定位为通用的动态物体操纵框架。", "conclusion": "DynamicVLA提供了一个统一的框架来解决不同形态下的动态物体操作问题，从而实现了更好的动态环境适应性和任务性能。"}}
{"id": "2601.22150", "pdf": "https://arxiv.org/pdf/2601.22150", "abs": "https://arxiv.org/abs/2601.22150", "authors": ["Xiaoxiao Sun", "Mingyang Li", "Kun yuan", "Min Woo Sun", "Mark Endo", "Shengguang Wu", "Changlin Li", "Yuhui Zhang", "Zeyu Wang", "Serena Yeung-Levy"], "title": "Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions", "categories": ["cs.CV"], "comment": "26 pages, 31 figures, 13 tables. Project Page: https://sites.google.com/view/vi-probe/", "summary": "Large Vision-Language Models (VLMs) often answer classic visual illusions \"correctly\" on original images, yet persist with the same responses when illusion factors are inverted, even though the visual change is obvious to humans. This raises a fundamental question: do VLMs perceive visual changes or merely recall memorized patterns? While several studies have noted this phenomenon, the underlying causes remain unclear. To move from observations to systematic understanding, this paper introduces VI-Probe, a controllable visual-illusion framework with graded perturbations and matched visual controls (without illusion inducer) that disentangles visually grounded perception from language-driven recall. Unlike prior work that focuses on averaged accuracy, we measure stability and sensitivity using Polarity-Flip Consistency, Template Fixation Index, and an illusion multiplier normalized against matched controls. Experiments across different families reveal that response persistence arises from heterogeneous causes rather than a single mechanism. For instance, GPT-5 exhibits memory override, Claude-Opus-4.1 shows perception-memory competition, while Qwen variants suggest visual-processing limits. Our findings challenge single-cause views and motivate probing-based evaluation that measures both knowledge and sensitivity to controlled visual change. Data and code are available at https://sites.google.com/view/vi-probe/.", "AI": {"tldr": "研究通过引入VI-Probe框架探讨视觉语言模型在经典视觉错觉中的感知与记忆问题，分析不同模型对视觉变化的稳定性和敏感性。", "motivation": "探究大型视觉-语言模型（VLMs）是否通过感知视觉变化还是仅仅回忆已知模式来回答经典视觉错觉的问题。尽管现有研究观察到了这种现象，但其根本原因尚不清楚。", "method": "提出VI-Probe框架，使用可控制的视觉错觉和匹配的视觉对照实验来分离基于视觉感知与语言驱动的记忆。通过测量稳定性和敏感性（例如Polarity-Flip Consistency、Template Fixation Index等）来进行系统评估。", "result": "不同家族模型在经典视觉错觉中的响应持久性源于异质原因，而非单一机制，包括记忆覆盖、感知记忆竞争以及视觉处理限制等。", "conclusion": "挑战单因素解释，并强调基于探针的评估方法能够衡量知识与对控制下视觉变化的敏感度。"}}
{"id": "2601.22149", "pdf": "https://arxiv.org/pdf/2601.22149", "abs": "https://arxiv.org/abs/2601.22149", "authors": ["Hang Ding", "Peidong Liu", "Junqiao Wang", "Ziwei Ji", "Meng Cao", "Rongzhao Zhang", "Lynn Ai", "Eric Yang", "Tianyu Shi", "Lei Yu"], "title": "DynaWeb: Model-Based Reinforcement Learning of Web Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.", "AI": {"tldr": "本文提出了DynaWeb，一种基于模型的强化学习框架，用于训练能够与网页进行交互的代理。", "motivation": "当前自主网络代理的训练面临着效率低下、成本高昂和风险大的问题。通过使用基于模型的强化学习（MBRL），可以利用世界模型来模拟环境中的互动，从而提高训练效果。", "method": "DynaWeb框架构建了一个网页世界的模型，并在此基础上生成大量的动作轨迹以进行在线强化学习。此外，该框架还引入了真实专家轨迹与在策略滚动出的动作轨迹相结合的方法，提高了稳定性和样本效率。", "result": "实验显示，在WebArena和WebVoyager基准测试中，DynaWeb显著提升了现有开源网络代理模型的表现。", "conclusion": "本研究验证了通过想象训练网页代理的可行性，并提供了一种可扩展且高效的在线强化学习方法。"}}
{"id": "2601.22143", "pdf": "https://arxiv.org/pdf/2601.22143", "abs": "https://arxiv.org/abs/2601.22143", "authors": ["Anthony Chen", "Naomi Ken Korem", "Tavi Halperin", "Matan Ben Yosef", "Urska Jelercic", "Ofir Bibi", "Or Patashnik", "Daniel Cohen-Or"], "title": "JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion", "categories": ["cs.GR", "cs.CV"], "comment": "Project webpage available at https://justdubit.github.io", "summary": "Audio-Visual Foundation Models, which are pretrained to jointly generate sound and visual content, have recently shown an unprecedented ability to model multi-modal generation and editing, opening new opportunities for downstream tasks. Among these tasks, video dubbing could greatly benefit from such priors, yet most existing solutions still rely on complex, task-specific pipelines that struggle in real-world settings. In this work, we introduce a single-model approach that adapts a foundational audio-video diffusion model for video-to-video dubbing via a lightweight LoRA. The LoRA enables the model to condition on an input audio-video while jointly generating translated audio and synchronized facial motion. To train this LoRA, we leverage the generative model itself to synthesize paired multilingual videos of the same speaker. Specifically, we generate multilingual videos with language switches within a single clip, and then inpaint the face and audio in each half to match the language of the other half. By leveraging the rich generative prior of the audio-visual model, our approach preserves speaker identity and lip synchronization while remaining robust to complex motion and real-world dynamics. We demonstrate that our approach produces high-quality dubbed videos with improved visual fidelity, lip synchronization, and robustness compared to existing dubbing pipelines.", "AI": {"tldr": "该论文提出了一种基于联合音频视觉扩散模型的视频配音方法，通过轻量级LoRA调整模型以适应输入的音视频，并生成翻译后的音频和同步面部动作。", "motivation": "现有大多数解决方案依赖于复杂的任务特定管道，在实际环境中难以应对。本文旨在通过一个单模型的方法解决这一问题，提高视频配音的质量、唇部同步度和鲁棒性。", "method": "该方法引入了一个单一的基于联合音频视觉扩散模型的框架，并使用轻量级LoRA调整来适应输入的音视频数据，从而生成翻译后的音频和同步面部动作。训练过程中利用原始模型本身合成配对多语言视频。", "result": "实验结果表明，与现有解决方案相比，该方法能够产生高质量的配音视频，提高视觉保真度、唇部同步度，并保持说话者身份的一致性。", "conclusion": "通过引入轻量级LoRA调整模型以适应输入音视频数据的方法，论文展示了其在生成高质量配音视频方面的优越性能和鲁棒性。"}}
{"id": "2601.22141", "pdf": "https://arxiv.org/pdf/2601.22141", "abs": "https://arxiv.org/abs/2601.22141", "authors": ["Grzegorz Stefanski", "Alberto Presta", "Michal Byra"], "title": "Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "In pruning, the Lottery Ticket Hypothesis posits that large networks contain sparse subnetworks, or winning tickets, that can be trained in isolation to match the performance of their dense counterparts. However, most existing approaches assume a single universal winning ticket shared across all inputs, ignoring the inherent heterogeneity of real-world data. In this work, we propose Routing the Lottery (RTL), an adaptive pruning framework that discovers multiple specialized subnetworks, called adaptive tickets, each tailored to a class, semantic cluster, or environmental condition. Across diverse datasets and tasks, RTL consistently outperforms single- and multi-model baselines in balanced accuracy and recall, while using up to 10 times fewer parameters than independent models and exhibiting semantically aligned. Furthermore, we identify subnetwork collapse, a performance drop under aggressive pruning, and introduce a subnetwork similarity score that enables label-free diagnosis of oversparsification. Overall, our results recast pruning as a mechanism for aligning model structure with data heterogeneity, paving the way toward more modular and context-aware deep learning.", "AI": {"tldr": "本文提出了一种适应性修剪框架Routing the Lottery (RTL)，用于发现针对不同类型数据的专用子网络，以提高模型性能和效率。", "motivation": "现有修剪方法假设存在单一通用的获胜子网络，忽视了实际数据中的异质性。作者希望通过引入多个适应性子网络来解决此问题，并且提出一种诊断过度稀疏的方法。", "method": "本文提出了适应性修剪框架RTL，该框架可以发现针对不同类、语义簇或环境条件的专用子网络（自适应票证）。此外，还引入了衡量子网络相似性的评分和对过度稀疏进行无标签诊断的技术。", "result": "在多种数据集和任务中，RTL方法比单模型或多模型基线表现出更高的平衡准确性和召回率，并且使用独立模型的参数减少了10倍。同时，该框架能有效识别由于过度修剪导致的性能下降现象（子网络崩溃）。", "conclusion": "本文重新定义了修剪技术为一种能够使模型结构与数据异质性相匹配的方法，有助于构建更加模块化和上下文感知的深度学习系统。"}}
{"id": "2601.22139", "pdf": "https://arxiv.org/pdf/2601.22139", "abs": "https://arxiv.org/abs/2601.22139", "authors": ["Xin Chen", "Feng Jiang", "Yiqian Zhang", "Hardy Chen", "Shuo Yan", "Wenya Xie", "Min Yang", "Shujian Huang"], "title": "Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers", "categories": ["cs.CL", "cs.AI"], "comment": "The manuscript is under review", "summary": "Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \\emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\\% higher accuracy, 22.90\\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \\href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}", "AI": {"tldr": "本文提出了一种新的推理范式PIR，将大型语言模型从被动解算器转变为通过与用户交互主动寻求澄清的积极查询者。", "motivation": "现有的Chain-of-Thought提示使得推理导向的大规模语言模型在盲目的自我思考中受限，即使关键信息缺失或模棱两可也会进行大量内部推理。因此，作者旨在开发一种新的推理框架，使模型能够主动地与用户互动以澄清不确定的信息。", "method": "PIR通过两个核心组件实现：一是具有交互式推理能力的不确定性感知监督微调过程；二是基于用户模拟器的策略优化框架，该框架由复合奖励驱动，使其行为与用户意图一致。", "result": "实验表明，在数学推理、代码生成和文档编辑任务中，PIR的表现优于现有基准线，准确率最高提升32.70%，通过率为22.90%的提高，同时减少了41.36分BLEU的不必要的交互次数。此外，在事实性知识问答和缺失前提场景中的可靠性评估进一步验证了PIR的强大泛化能力和鲁棒性。", "conclusion": "本文提出了一种新颖的方法——Proactive Interactive Reasoning (PIR)，它不仅提高了推理效率，还增强了模型在各种任务上的性能与适应能力。"}}
{"id": "2601.22137", "pdf": "https://arxiv.org/pdf/2601.22137", "abs": "https://arxiv.org/abs/2601.22137", "authors": ["Shenghao Yang", "Zhichao Wang", "Oleg Balabanov", "N. Benjamin Erichson", "Michael W. Mahoney"], "title": "PRISM: Distribution-free Adaptive Computation of Matrix Functions for Accelerating Neural Network Training", "categories": ["cs.LG", "cs.AI", "math.NA", "math.OC"], "comment": null, "summary": "Matrix functions such as square root, inverse roots, and orthogonalization play a central role in preconditioned gradient methods for neural network training. This has motivated the development of iterative algorithms that avoid explicit eigendecompositions and rely primarily on matrix multiplications, making them well suited for modern GPU accelerators. We present PRISM (Polynomial-fitting and Randomized Iterative Sketching for Matrix functions computation), a general framework for accelerating iterative algorithms for computing matrix functions. PRISM combines adaptive polynomial approximation with randomized sketching: at each iteration, it fits a polynomial surrogate to the current spectrum via a sketched least-squares problem, adapting to the instance at hand with minimal overhead. We apply PRISM to accelerate Newton-Schulz-like iterations for matrix square roots and orthogonalization, which are core primitives in machine learning. Unlike prior methods, PRISM requires no explicit spectral bounds or singular value estimates; and it adapts automatically to the evolving spectrum. Empirically, PRISM accelerates training when integrated into Shampoo and Muon optimizers.", "AI": {"tldr": "PRISM是一种加速矩阵函数计算的通用框架，适用于神经网络训练中的预处理梯度方法。", "motivation": "在神经网络训练中，矩阵平方根、逆平方根和正交化等矩阵运算对预处理梯度方法至关重要。传统迭代算法需要显式的特征分解，而PRISM结合了自适应多项式逼近与随机采样技术，避免这些步骤并加速计算。", "method": "PRISM通过在每次迭代中利用随机采样的最小二乘问题拟合一个多项式近似来工作，这种方法不需要明确的谱界限或奇异值估计，并且能够根据实例自动调整。", "result": "实验表明，当PRISM与Shampoo和Muon优化器集成时，可以加速神经网络训练过程。", "conclusion": "PRISM提供了一种无需显式谱界或奇异值估计即可适应性地加速矩阵函数计算的方法，并且在实践中证明了其有效性。"}}
{"id": "2601.22136", "pdf": "https://arxiv.org/pdf/2601.22136", "abs": "https://arxiv.org/abs/2601.22136", "authors": ["Gloria Felicia", "Michael Eniolade", "Jinfeng He", "Zitha Sasindran", "Hemant Kumar", "Milan Hussain Angati", "Sandeep Bandarupalli"], "title": "StepShield: When, Not Whether to Intervene on Rogue Agents", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.SE"], "comment": "16 pages, 2 figures, 14 tables", "summary": "Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, not just whether. StepShield contains 9,213 code agent trajectories, including 1,278 meticulously annotated training pairs and a 7,935-trajectory test set with a realistic 8.1% rogue rate. Rogue behaviors are grounded in real-world security incidents across six categories. We propose three novel temporal metrics: Early Intervention Rate (EIR), Intervention Gap, and Tokens Saved. Surprisingly, our evaluation reveals that an LLM-based judge achieves 59% EIR while a static analyzer achieves only 26%, a 2.3x performance gap that is entirely invisible to standard accuracy metrics. We further show that early detection has direct economic benefits: our cascaded HybridGuard detector reduces monitoring costs by 75% and projects to $108M in cumulative savings over five years at enterprise scale. By shifting the focus of evaluation from whether to when, StepShield provides a new foundation for building safer and more economically viable AI agents. The code and data are released under an Apache 2.0 license.", "AI": {"tldr": "StepShield是一个评估代理行为安全性的新基准，专注于早期检测违规行为的时间点。", "motivation": "当前的安全性基准仅关注是否检测到违规行为，忽略了何时干预的重要性。作者希望通过引入新的衡量标准来解决这一问题，并为构建更安全和经济可行的人工智能代理提供一个新的基础。", "method": "StepShield包含9,213个代码代理轨迹，其中1,278对被仔细注释的训练数据集以及一个7,935轨迹测试集。引入了三个新的时间度量：早期干预率（EIR），干预间隙和节省令牌数。", "result": "LLM基线模型在早检测方面达到了59%的EIR，而静态分析器只有26%，显示出了显著差距。使用混合式守护程序可以将监控成本降低75%，并在五年内实现1.08亿美元的成本节约。", "conclusion": "StepShield通过关注何时干预而不是仅仅是否干预，为建立更安全和经济上可行的人工智能代理提供了一个新的基础。"}}
{"id": "2601.22135", "pdf": "https://arxiv.org/pdf/2601.22135", "abs": "https://arxiv.org/abs/2601.22135", "authors": ["Zhexin Liang", "Zhaoxi Chen", "Yongwei Chen", "Tianyi Wei", "Tengfei Wang", "Xingang Pan"], "title": "PI-Light: Physics-Inspired Diffusion for Full-Image Relighting", "categories": ["cs.CV"], "comment": "Accepted at ICLR 2026", "summary": "Full-image relighting remains a challenging problem due to the difficulty of collecting large-scale structured paired data, the difficulty of maintaining physical plausibility, and the limited generalizability imposed by data-driven priors. Existing attempts to bridge the synthetic-to-real gap for full-scene relighting remain suboptimal. To tackle these challenges, we introduce Physics-Inspired diffusion for full-image reLight ($π$-Light, or PI-Light), a two-stage framework that leverages physics-inspired diffusion models. Our design incorporates (i) batch-aware attention, which improves the consistency of intrinsic predictions across a collection of images, (ii) a physics-guided neural rendering module that enforces physically plausible light transport, (iii) physics-inspired losses that regularize training dynamics toward a physically meaningful landscape, thereby enhancing generalizability to real-world image editing, and (iv) a carefully curated dataset of diverse objects and scenes captured under controlled lighting conditions. Together, these components enable efficient finetuning of pretrained diffusion models while also providing a solid benchmark for downstream evaluation. Experiments demonstrate that $π$-Light synthesizes specular highlights and diffuse reflections across a wide variety of materials, achieving superior generalization to real-world scenes compared with prior approaches.", "AI": {"tldr": "PI-Light是一种用于全图像重照明的两阶段框架，通过物理启发式的扩散模型来解决当前技术中的问题。", "motivation": "现有的方法难以收集大规模结构化配对数据，保持物理合理性，并且受限于数据驱动先验的泛化能力。因此，提出了一种基于物理启发式扩散模型的方法来改善这些问题。", "method": "PI-Light框架包括批次感知注意力机制、物理引导神经渲染模块和物理启发式的损失函数。这些组件共同提高了预训练扩散模型的有效微调，并提供了坚实的基准测试平台。", "result": "实验表明，与先前的方法相比，PI-Light能够合成各种材料的镜面高光和漫反射，在真实场景中的泛化能力更强。", "conclusion": "通过结合物理启发式方法和精心策划的数据集，PI-Light展示了在全图像重照明任务中显著的优势。"}}
{"id": "2601.22134", "pdf": "https://arxiv.org/pdf/2601.22134", "abs": "https://arxiv.org/abs/2601.22134", "authors": ["Wenxuan Li", "Pedro R. A. S. Bassi", "Lizhou Wu", "Xinze Zhou", "Yuxuan Zhao", "Qi Chen", "Szymon Plotka", "Tianyu Lin", "Zheren Zhu", "Marisa Martin", "Justin Caskey", "Shanshan Jiang", "Xiaoxi Chen", "Jaroslaw B. Ćwikla", "Artur Sankowski", "Yaping Wu", "Sergio Decherchi", "Andrea Cavalli", "Chandana Lall", "Cristian Tomasetti", "Yaxing Guo", "Xuan Yu", "Yuqing Cai", "Hualin Qiao", "Jie Bao", "et al. (12 additional authors not shown)"], "title": "Early and Prediagnostic Detection of Pancreatic Cancer from Computed Tomography", "categories": ["cs.CV"], "comment": null, "summary": "Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest solid malignancies, is often detected at a late and inoperable stage. Retrospective reviews of prediagnostic CT scans, when conducted by expert radiologists aware that the patient later developed PDAC, frequently reveal lesions that were previously overlooked. To help detecting these lesions earlier, we developed an automated system named ePAI (early Pancreatic cancer detection with Artificial Intelligence). It was trained on data from 1,598 patients from a single medical center. In the internal test involving 1,009 patients, ePAI achieved an area under the receiver operating characteristic curve (AUC) of 0.939-0.999, a sensitivity of 95.3%, and a specificity of 98.7% for detecting small PDAC less than 2 cm in diameter, precisely localizing PDAC as small as 2 mm. In an external test involving 7,158 patients across 6 centers, ePAI achieved an AUC of 0.918-0.945, a sensitivity of 91.5%, and a specificity of 88.0%, precisely localizing PDAC as small as 5 mm. Importantly, ePAI detected PDACs on prediagnostic CT scans obtained 3 to 36 months before clinical diagnosis that had originally been overlooked by radiologists. It successfully detected and localized PDACs in 75 of 159 patients, with a median lead time of 347 days before clinical diagnosis. Our multi-reader study showed that ePAI significantly outperformed 30 board-certified radiologists by 50.3% (P < 0.05) in sensitivity while maintaining a comparable specificity of 95.4% in detecting PDACs early and prediagnostic. These findings suggest its potential of ePAI as an assistive tool to improve early detection of pancreatic cancer.", "AI": {"tldr": "开发了一种名为ePAI的自动化系统，用于早期检测胰腺癌。", "motivation": "胰腺导管腺癌（PDAC）通常在晚期被发现。通过回顾性分析预先诊断CT扫描，并利用专家放射科医生的经验，可以发现先前遗漏的病变。因此，开发了一种自动化的AI工具以期更早地识别这些病变。", "method": "该系统ePAI基于1598名患者的数据进行了训练，在内部测试中涉及1009名患者，外部测试则包括6个中心的7158名患者。结果评估了AUC、灵敏度和特异性，并通过与30位认证放射科医生相比进一步验证。", "result": "在内部测试中，ePAI取得了0.939-0.999的AUC值，对于小于2厘米的PDAC具有95.3%的敏感性和98.7%的特异性。外部测试中的表现略有下降但仍优异，其对小至5毫米的PDAC有显著检测效果，并能在临床诊断前3到36个月内识别出遗漏病变。", "conclusion": "ePAI显示出作为辅助工具提高胰腺癌早期检测率的巨大潜力，尤其是在与专业放射科医生相比时表现出更高的敏感性。"}}
{"id": "2601.22130", "pdf": "https://arxiv.org/pdf/2601.22130", "abs": "https://arxiv.org/abs/2601.22130", "authors": ["Lakshya Gupta", "Litao Li", "Yizhe Liu", "Sriram Ganapathi Subramanian", "Kaheer Suleman", "Zichen Zhang", "Haoye Lu", "Sumit Pasupalak"], "title": "World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Frontier large language models (LLMs) excel as autonomous agents in many domains, yet they remain untested in complex enterprise systems where hidden workflows create cascading effects across interconnected databases. Existing enterprise benchmarks evaluate surface-level agentic task completion similar to general consumer benchmarks, ignoring true challenges in enterprises, such as limited observability, large database state, and hidden workflows with cascading side effects. We introduce World of Workflows (WoW), a realistic ServiceNow-based environment incorporating 4,000+ business rules and 55 active workflows embedded in the system, alongside WoW-bench, a benchmark of 234 tasks evaluating constrained agentic task completion and enterprise dynamics modeling capabilities. We reveal two major takeaways: (1) Frontier LLMs suffer from dynamics blindness, consistently failing to predict the invisible, cascading side effects of their actions, which leads to silent constraint violations, and (2) reliability in opaque systems requires grounded world modeling, where agents must mentally simulate hidden state transitions to bridge the observability gap when high-fidelity feedback is unavailable. For reliable and useful enterprise agents, WoW motivates a new paradigm to explicitly learn system dynamics. We release our GitHub for setting up and evaluating WoW.", "AI": {"tldr": "介绍了一个基于ServiceNow的环境World of Workflows（WoW），用于评估大型语言模型在复杂企业系统中的表现。", "motivation": "当前的大规模语言模型在消费者应用中表现出色，但在涉及隐藏工作流和大规模数据库状态的企业环境中存在挑战。现有基准测试忽略了这些真实场景下的问题。", "method": "构建了一个包含4000多条业务规则和55个工作流程的ServiceNow环境，并制定了一个由234个任务组成的评估标准WoW-bench，用于评价模型在企业系统中的表现。", "result": "发现前沿语言模型无法预测其行为导致的隐形、级联副作用，这会导致隐性约束违规。可靠性要求代理必须模拟隐藏状态转换以弥补观察力不足。", "conclusion": "提出了一种新的范式来明确学习系统动力学，并鼓励研究者使用WoW环境进行相关研究。"}}
{"id": "2601.22129", "pdf": "https://arxiv.org/pdf/2601.22129", "abs": "https://arxiv.org/abs/2601.22129", "authors": ["Yifeng Ding", "Lingming Zhang"], "title": "SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to generalize to modern agents that synthesize custom bash scripts as tools. In this paper, we introduce SWE-Replay, the first efficient and generalizable test-time scaling technique for modern agents without reliance on potentially noisy value estimates. SWE-Replay optimizes the scaling process by recycling trajectories from prior trials, dynamically choosing to either explore from scratch or exploit archived experience by branching at critical intermediate steps. This selection of intermediate steps is driven by the potential and reasoning significance of repository exploration, rather than external LLM-based quality estimates. Our evaluation shows that, on SWE-Bench Verified, SWE-Replay consistently outperforms naive scaling, reducing costs by up to 17.4% while maintaining or even improving performance by up to 3.8%. Further evaluation on SWE-Bench Pro and Multilingual validates the generalizability of SWE-Replay, establishing it as a robust foundation for efficient test-time scaling of software engineering agents.", "AI": {"tldr": "SWE-Replay是一种高效且通用的软件工程代理测试时间扩展技术，通过重用之前的轨迹来减少计算成本。", "motivation": "现有方法在提高大型语言模型（LLM）代理性能时存在计算成本高和模型校准问题，尤其是无法适应生成自定义bash脚本工具的任务。因此需要一种新的高效且通用的解决方案。", "method": "SWE-Replay通过从先前试验中重用轨迹，并在关键中间步骤处选择探索或利用存档经验来优化测试时间扩展过程。", "result": "实验表明，与简单缩放相比，SWE-Replay能够在减少最多17.4%计算成本的同时保持甚至提升性能至多3.8%，并在其他基准测试中验证了其泛化能力。", "conclusion": "SWE-Replay证明为软件工程代理的高效测试时间扩展提供了一个坚实的基础。"}}
{"id": "2601.22128", "pdf": "https://arxiv.org/pdf/2601.22128", "abs": "https://arxiv.org/abs/2601.22128", "authors": ["Irsyad Adam", "Zekai Chen", "David Laprade", "Shaun Porwal", "David Laub", "Erik Reinertsen", "Arda Pekis", "Kevin Brown"], "title": "The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR", "categories": ["cs.AI", "cs.CE", "q-bio.QM"], "comment": null, "summary": "Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient's trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.", "AI": {"tldr": "论文提出了SMB-Structure模型，该模型采用世界模型训练范式来模拟电子健康记录(EHR)中患者的动态变化。", "motivation": "现有大型语言模型将患者视作文档处理，未能有效捕捉其在不同干预和时间下的动态演变。因此需要一种能预测未来状态的模型以更好地理解疾病进展及治疗反应。", "method": "论文采用了一种联合嵌入预测架构(JEPA)与下一标记预测(SFT)，其中SFT用于重构未来的患者状态，而JEPA则在仅凭初始表示的情况下预测这些未来状态的变化。该方法训练后能够捕捉到复杂任务中由高异质性带来的动态变化。", "result": "通过使用两个大规模队列（纪念斯隆-凯特琳和INSPECT）进行验证，并采用线性探测评估，结果表明SMB-Structure模型在多个时间点上对疾病动力学的捕捉能力超越了自回归基准方法。此外，在复杂任务中也展现了竞争力。", "conclusion": "论文提出了一种新的世界模型训练范式，可以更好地模拟患者状态的变化，并且在处理高异质性问题时表现出色。"}}
{"id": "2601.22127", "pdf": "https://arxiv.org/pdf/2601.22127", "abs": "https://arxiv.org/abs/2601.22127", "authors": ["John Flynn", "Wolfgang Paier", "Dimitar Dinev", "Sam Nhut Nguyen", "Hayk Poghosyan", "Manuel Toribio", "Sandipan Banerjee", "Guy Gafni"], "title": "EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers", "categories": ["cs.CV", "cs.GR", "cs.LG", "cs.MM"], "comment": "Project page: https://edit-yourself.github.io/", "summary": "Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing that enables transcript-based modification of talking head videos, including the seamless addition, removal, and retiming of visually spoken content. Building on a general-purpose video diffusion model, EditYourself augments its V2V capabilities with audio conditioning and region-aware, edit-focused training extensions. This enables precise lip synchronization and temporally coherent restructuring of existing performances via spatiotemporal inpainting, including the synthesis of realistic human motion in newly added segments, while maintaining visual fidelity and identity consistency over long durations. This work represents a foundational step toward generative video models as practical tools for professional video post-production.", "AI": {"tldr": "介绍EditYourself，一个基于DiT的框架用于音频驱动的视频编辑，支持对话本修改说话头部视频。", "motivation": "当前生成模型在处理文本和图像提示的新内容时表现出色，但在编辑现有预录制视频方面存在不足，特别是需要保持运动、时间连贯性、说话者身份和准确口型同步的小幅台词更改。", "method": "通过结合音频条件化和区域感知的训练扩展，基于通用视频扩散模型增强V2V能力，实现精确的唇同步及长时间视觉一致性的编辑功能。", "result": "能够进行无缝添加、删除或重新安排口语内容的操作，并保持真实的人类运动和身份一致性。", "conclusion": "这项工作是将生成式视频模型作为专业视频后期制作实用工具的重要一步。"}}
{"id": "2601.22125", "pdf": "https://arxiv.org/pdf/2601.22125", "abs": "https://arxiv.org/abs/2601.22125", "authors": ["Kunpeng Song", "Ahmed Elgammal"], "title": "Creative Image Generation with Diffusion Model", "categories": ["cs.CV"], "comment": "Project page: https://creative-t2i.github.io", "summary": "Creative image generation has emerged as a compelling area of research, driven by the need to produce novel and high-quality images that expand the boundaries of imagination. In this work, we propose a novel framework for creative generation using diffusion models, where creativity is associated with the inverse probability of an image's existence in the CLIP embedding space. Unlike prior approaches that rely on a manual blending of concepts or exclusion of subcategories, our method calculates the probability distribution of generated images and drives it towards low-probability regions to produce rare, imaginative, and visually captivating outputs. We also introduce pullback mechanisms, achieving high creativity without sacrificing visual fidelity. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness and efficiency of our creative generation framework, showcasing its ability to produce unique, novel, and thought-provoking images. This work provides a new perspective on creativity in generative models, offering a principled method to foster innovation in visual content synthesis.", "AI": {"tldr": "提出了一种新的框架，利用扩散模型进行创意图像生成。", "motivation": "通过生成新颖高质量的图片来拓展想象力的边界。", "method": "计算生成图像的概率分布，并将其推向低概率区域以产生罕见而引人注目的输出。引入拉回机制，确保在保持视觉保真度的同时提高创造力。", "result": "实验表明该框架能够高效地生成独特新颖且富有启发性的图像。", "conclusion": "这项工作提供了一种新的视角来理解创意性，在生成模型中促进创新的视觉内容合成。"}}
{"id": "2601.22119", "pdf": "https://arxiv.org/pdf/2601.22119", "abs": "https://arxiv.org/abs/2601.22119", "authors": ["Han Yang", "Dong Hao", "Zhuohan Wang", "Qi Shi", "Xingtong Li"], "title": "Alpha Discovery via Grammar-Guided Learning and Search", "categories": ["q-fin.CP", "cs.AI", "cs.LG"], "comment": "24 pages, 10 figures", "summary": "Automatically discovering formulaic alpha factors is a central problem in quantitative finance. Existing methods often ignore syntactic and semantic constraints, relying on exhaustive search over unstructured and unbounded spaces. We present AlphaCFG, a grammar-based framework for defining and discovering alpha factors that are syntactically valid, financially interpretable, and computationally efficient. AlphaCFG uses an alpha-oriented context-free grammar to define a tree-structured, size-controlled search space, and formulates alpha discovery as a tree-structured linguistic Markov decision process, which is then solved using a grammar-aware Monte Carlo Tree Search guided by syntax-sensitive value and policy networks. Experiments on Chinese and U.S. stock market datasets show that AlphaCFG outperforms state-of-the-art baselines in both search efficiency and trading profitability. Beyond trading strategies, AlphaCFG serves as a general framework for symbolic factor discovery and refinement across quantitative finance, including asset pricing and portfolio construction.", "AI": {"tldr": "通过语法指导的学习和搜索自动发现有效的量化交易因子。", "motivation": "现有方法在寻找量化交易因子时往往忽视了语义和句法约束，导致效率低下且难以解释。因此提出了AlphaCFG框架来解决这些问题。", "method": "利用上下文无关的语法定义树状结构的、可控大小的搜索空间，并将因子发现问题转化为基于语言学的马尔科夫决策过程，使用语法感知蒙特卡洛树搜索进行求解。", "result": "实验结果表明AlphaCFG在搜索效率和交易盈利方面超越了最新的基准方法。", "conclusion": "AlphaCFG提供了一个有效的框架来解决量化金融中的因子发现问题，并且可以推广到资产定价和投资组合构建等领域。"}}
{"id": "2601.22118", "pdf": "https://arxiv.org/pdf/2601.22118", "abs": "https://arxiv.org/abs/2601.22118", "authors": ["Johann Christensen", "Elena Hoemann", "Frank Köster", "Sven Hallerbach"], "title": "Defining Operational Conditions for Safety-Critical AI-Based Systems from Data", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) has been on the rise in many domains, including numerous safety-critical applications. However, for complex systems found in the real world, or when data already exist, defining the underlying environmental conditions is extremely challenging. This often results in an incomplete description of the environment in which the AI-based system must operate. Nevertheless, this description, called the Operational Design Domain (ODD), is required in many domains for the certification of AI-based systems. Traditionally, the ODD is created in the early stages of the development process, drawing on sophisticated expert knowledge and related standards. This paper presents a novel Safety-by-Design method to a posteriori define the ODD from previously collected data using a multi-dimensional kernel-based representation. This approach is validated through both Monte Carlo methods and a real-world aviation use case for a future safety-critical collision-avoidance system. Moreover, by defining under what conditions two ODDs are equal, the paper shows that the data-driven ODD can equal the original, underlying hidden ODD of the data. Utilizing the novel, Safe-by-Design kernel-based ODD enables future certification of data-driven, safety-critical AI-based systems.", "AI": {"tldr": "本文提出了一种通过后验数据分析定义操作设计域（ODD）的新方法，旨在为安全关键的人工智能系统提供认证。", "motivation": "在现实世界中复杂的系统或已有数据的情况下，定义AI系统的环境条件极为困难。为了确保这些AI系统能够正确运行并获得认证，需要一种新的方法来准确描述其操作环境。", "method": "利用多维核表示从先前收集的数据中后验性地定义ODD，并通过蒙特卡洛方法和实际航空应用案例验证此方法的有效性。", "result": "该研究证明了数据驱动的ODD可以等同于原始隐藏的ODD，从而为基于数据的安全关键AI系统的未来认证提供了一种可能。", "conclusion": "提出的新方法Safe-by-Design核表示ODD为安全关键的人工智能系统未来的认证提供了理论基础和实用价值。"}}
{"id": "2601.22114", "pdf": "https://arxiv.org/pdf/2601.22114", "abs": "https://arxiv.org/abs/2601.22114", "authors": ["Saoud Aldowaish", "Yashwanth Karumanchi", "Kai-Chen Chiang", "Soroosh Noorzad", "Morteza Fayazi"], "title": "SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence", "categories": ["cs.CV", "cs.AI", "eess.SY"], "comment": null, "summary": "Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.", "AI": {"tldr": "SINA是一个使用人工智能将电路原理图图像转换为机器可读网络列表的全自动工具。", "motivation": "当前的方法在识别电路元件和推断连接性方面存在困难，因此提出了SINA来解决这些问题。", "method": "SINA利用深度学习进行组件检测、CCL进行精确连通性提取、OCR检索参考设计标识符，并使用视觉语言模型（VLM）进行可靠的参考设计标识符分配。", "result": "实验显示，SINA实现了96.47％的整体网络列表生成精度，比现有最佳方法高出2.72倍。", "conclusion": "SINA提供了一种准确、高效的电路原理图图像转换为机器可读网络列表的方法，克服了传统方法的局限性。"}}
{"id": "2601.22108", "pdf": "https://arxiv.org/pdf/2601.22108", "abs": "https://arxiv.org/abs/2601.22108", "authors": ["Shuqi Ke", "Giulia Fanti"], "title": "Value-Based Pre-Training with Downstream Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Can a small amount of verified goal information steer the expensive self-supervised pretraining of foundation models? Standard pretraining optimizes a fixed proxy objective (e.g., next-token prediction), which can misallocate compute away from downstream capabilities of interest. We introduce V-Pretraining: a value-based, modality-agnostic method for controlled continued pretraining in which a lightweight task designer reshapes the pretraining task to maximize the value of each gradient step. For example, consider self-supervised learning (SSL) with sample augmentation. The V-Pretraining task designer selects pretraining tasks (e.g., augmentations) for which the pretraining loss gradient is aligned with a gradient computed over a downstream task (e.g., image segmentation). This helps steer pretraining towards relevant downstream capabilities. Notably, the pretrained model is never updated on downstream task labels; they are used only to shape the pretraining task. Under matched learner update budgets, V-Pretraining of 0.5B--7B language models improves reasoning (GSM8K test Pass@1) by up to 18% relative over standard next-token prediction using only 12% of GSM8K training examples as feedback. In vision SSL, we improve the state-of-the-art results on ADE20K by up to 1.07 mIoU and reduce NYUv2 RMSE while improving ImageNet linear accuracy, and we provide pilot evidence of improved token efficiency in continued pretraining.", "AI": {"tldr": "论文提出了一种基于价值的预训练方法（V-Pretraining），通过下游反馈调整预训练任务，以提高模型在特定下游任务上的表现。", "motivation": "传统的预训练方法使用固定的代理目标优化，可能导致计算资源被误分配。V-Pretraining旨在利用少量验证的目标信息来指导昂贵的自监督预训练过程，使其更符合后续任务的需求。", "method": "通过重新选择预训练任务（例如数据增强）以使预训练损失梯度与下游任务的梯度对齐，从而引导模型学习更有价值的知识。这种方法中，模型仅在预训练阶段受到下游反馈的影响，而不会直接更新为下游标签。", "result": "V-Pretraining显著提升了语言模型的推理能力（GSM8K测试通过率提高18%），并且在视觉自监督学习任务上也达到了新的SOTA结果。此外，它还提高了继续预训练中的令牌效率。", "conclusion": "这种基于价值的预训练方法能够有效地利用少量下游反馈指导大规模模型的预训练过程，从而显著提升特定下游任务上的表现。"}}
{"id": "2601.22101", "pdf": "https://arxiv.org/pdf/2601.22101", "abs": "https://arxiv.org/abs/2601.22101", "authors": ["Mahdi Nikdan", "Amir Zandieh", "Dan Alistarh", "Vahab Mirrokni"], "title": "ECO: Quantized Training without Full-Precision Master Weights", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.", "AI": {"tldr": "本文提出了一种新的优化器ECO，用于在大型语言模型训练中消除高精度权重缓冲区（master weights），实现量化训练。", "motivation": "现有方法依赖于高精度的权重缓冲区来存储更新，在内存使用上存在巨大开销。特别是在稀疏专家混合(SMoE)模型中，该问题尤为突出。", "method": "ECO优化器通过直接在量化参数上应用更新并将其误差反馈到动量项中来消除master weights。该方法在每个步骤后量化权重，并将产生的量化误差注入优化器动量中。", "result": "实验结果表明，ECO能够匹配带有master weights的基线模型，在精度方面几乎无损，同时显著改进了静态内存与验证损失之间的帕累托边界。", "conclusion": "通过消除高精度权重缓冲区，ECO实现了更高效的训练过程，并且在多个大型语言模型上表现出了良好的效果。"}}
{"id": "2601.22094", "pdf": "https://arxiv.org/pdf/2601.22094", "abs": "https://arxiv.org/abs/2601.22094", "authors": ["Hanzhuo Huang", "Qingyang Bao", "Zekai Gu", "Zhongshuo Du", "Cheng Lin", "Yuan Liu", "Sibei Yang"], "title": "RefAny3D: 3D Asset-Referenced Diffusion Models for Image Generation", "categories": ["cs.CV"], "comment": "ICLR 2026. Project page: https://judgementh.github.io/RefAny3D Codes: https://github.com/JudgementH/RefAny3D", "summary": "In this paper, we propose a 3D asset-referenced diffusion model for image generation, exploring how to integrate 3D assets into image diffusion models. Existing reference-based image generation methods leverage large-scale pretrained diffusion models and demonstrate strong capability in generating diverse images conditioned on a single reference image. However, these methods are limited to single-image references and cannot leverage 3D assets, constraining their practical versatility. To address this gap, we present a cross-domain diffusion model with dual-branch perception that leverages multi-view RGB images and point maps of 3D assets to jointly model their colors and canonical-space coordinates, achieving precise consistency between generated images and the 3D references. Our spatially aligned dual-branch generation architecture and domain-decoupled generation mechanism ensure the simultaneous generation of two spatially aligned but content-disentangled outputs, RGB images and point maps, linking 2D image attributes with 3D asset attributes. Experiments show that our approach effectively uses 3D assets as references to produce images consistent with the given assets, opening new possibilities for combining diffusion models with 3D content creation.", "AI": {"tldr": "本文提出了一种基于3D资产的扩散模型，用于图像生成。", "motivation": "现有的参考为基础的图像生成方法局限于单张图片参考，并不能利用3D资产，这限制了其实用性。为了解决这个问题，作者提出了一个跨域扩散模型来综合多视角RGB图像和点图以更好地结合2D与3D属性。", "method": "本文提出了一种双分支感知的跨领域扩散模型，利用多个视角的RGB图像和3D资产的点云图联合建模颜色和空间坐标，并通过空间对齐的双分支生成架构以及域解耦生成机制来同时生成两个空间对齐但内容分离的输出。", "result": "实验表明该方法能够有效使用3D资产作为参考，产生与给定资产一致的图像，这为结合扩散模型与3D内容创造提供了新的可能性。", "conclusion": "本文提出了一种新型的基于3D资产的扩散模型，通过利用多视角RGB图像和点图提高了生成图像的准确性，并展示了该方法在处理2D与3D属性链接方面的潜力。"}}
{"id": "2601.22093", "pdf": "https://arxiv.org/pdf/2601.22093", "abs": "https://arxiv.org/abs/2601.22093", "authors": ["Fethiye Irmak Dogan", "Yuval Weiss", "Kajal Patel", "Jiaee Cheong", "Hatice Gunes"], "title": "Investigating Associational Biases in Inter-Model Communication of Large Generative Models", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Social bias in generative AI can manifest not only as performance disparities but also as associational bias, whereby models learn and reproduce stereotypical associations between concepts and demographic groups, even in the absence of explicit demographic information (e.g., associating doctors with men). These associations can persist, propagate, and potentially amplify across repeated exchanges in inter-model communication pipelines, where one generative model's output becomes another's input. This is especially salient for human-centred perception tasks, such as human activity recognition and affect prediction, where inferences about behaviour and internal states can lead to errors or stereotypical associations that propagate into unequal treatment. In this work, focusing on human activity and affective expression, we study how such associations evolve within an inter-model communication pipeline that alternates between image generation and image description. Using the RAF-DB and PHASE datasets, we quantify demographic distribution drift induced by model-to-model information exchange and assess whether these drifts are systematic using an explainability pipeline. Our results reveal demographic drifts toward younger representations for both actions and emotions, as well as toward more female-presenting representations, primarily for emotions. We further find evidence that some predictions are supported by spurious visual regions (e.g., background or hair) rather than concept-relevant cues (e.g., body or face). We also examine whether these demographic drifts translate into measurable differences in downstream behaviour, i.e., while predicting activity and emotion labels. Finally, we outline mitigation strategies spanning data-centric, training and deployment interventions, and emphasise the need for careful safeguards when deploying interconnected models in human-centred AI systems.", "AI": {"tldr": "研究大型生成模型在跨模型通信管道中的关联偏见，特别是在人类活动识别和情感预测任务中。", "motivation": "探讨生成AI中的社会偏差如何通过模型之间的信息交换传播并可能加剧，以及这种偏差对下游行为的影响。", "method": "利用RAF-DB和PHASE数据集，研究跨图像生成与描述的模型间通信管道中的人口分布漂移，并使用可解释性流程评估这些漂移是否系统化。", "result": "发现年龄和性别表示有显著变化，某些预测受背景而非关键概念线索影响。人口偏见可能会影响下游行为预测。", "conclusion": "提出缓解策略并强调在部署相关模型时需谨慎设置防护措施以避免不公平结果。"}}
{"id": "2601.22090", "pdf": "https://arxiv.org/pdf/2601.22090", "abs": "https://arxiv.org/abs/2601.22090", "authors": ["Runsheng Wang", "Katelyn Lee", "Xinyue Zhu", "Lauren Winterbottom", "Dawn M. Nilsen", "Joel Stein", "Matei Ciocarlie"], "title": "ReactEMG Stroke: Healthy-to-Stroke Few-shot Adaptation for sEMG-Based Intent Detection", "categories": ["cs.RO"], "comment": null, "summary": "Surface electromyography (sEMG) is a promising control signal for assist-as-needed hand rehabilitation after stroke, but detecting intent from paretic muscles often requires lengthy, subject-specific calibration and remains brittle to variability. We propose a healthy-to-stroke adaptation pipeline that initializes an intent detector from a model pretrained on large-scale able-bodied sEMG, then fine-tunes it for each stroke participant using only a small amount of subject-specific data. Using a newly collected dataset from three individuals with chronic stroke, we compare adaptation strategies (head-only tuning, parameter-efficient LoRA adapters, and full end-to-end fine-tuning) and evaluate on held-out test sets that include realistic distribution shifts such as within-session drift, posture changes, and armband repositioning. Across conditions, healthy-pretrained adaptation consistently improves stroke intent detection relative to both zero-shot transfer and stroke-only training under the same data budget; the best adaptation methods improve average transition accuracy from 0.42 to 0.61 and raw accuracy from 0.69 to 0.78. These results suggest that transferring a reusable healthy-domain EMG representation can reduce calibration burden while improving robustness for real-time post-stroke intent detection.", "AI": {"tldr": "本文提出了一种从健康人sEMG预训练模型到中风患者的小样本适应方案，用于改善基于肌电图的意图检测。", "motivation": "中风后使用表面肌电图（sEMG）进行手康复辅助存在挑战，需要长时间特定患者的校准且易受变化影响。本文旨在通过少量数据快速适应模型以提高中风患者意图检测的准确性和鲁棒性。", "method": "从大规模健康人sEMG预训练模型开始，采用头初始化、参数高效LoRA适配器和全端到端微调三种策略对每个中风患者的少量特定数据进行微调。", "result": "实验结果表明，在不同条件下，健康的预训练适应方法显著提高了中风意图检测的准确性。最佳适应方法将平均转换准确率从0.42提高到了0.61，原始准确率从0.69提升到0.78。", "conclusion": "该研究证明了通过转导健康领域EMG表征可以减少校准负担并改善实时中风后意图检测的鲁棒性。"}}
{"id": "2601.22086", "pdf": "https://arxiv.org/pdf/2601.22086", "abs": "https://arxiv.org/abs/2601.22086", "authors": ["Onur T. Doganay", "Alexander Klawonn", "Martin Eigel", "Hanno Gottschalk"], "title": "Learning Transient Convective Heat Transfer with Geometry Aware World Models", "categories": ["physics.flu-dyn", "cs.CV"], "comment": "36 pages, 18 figures, 2 tables", "summary": "Partial differential equation (PDE) simulations are fundamental to engineering and physics but are often computationally prohibitive for real-time applications. While generative AI offers a promising avenue for surrogate modeling, standard video generation architectures lack the specific control and data compatibility required for physical simulations. This paper introduces a geometry aware world model architecture, derived from a video generation architecture (LongVideoGAN), designed to learn transient physics. We introduce two key architecture elements: (1) a twofold conditioning mechanism incorporating global physical parameters and local geometric masks, and (2) an architectural adaptation to support arbitrary channel dimensions, moving beyond standard RGB constraints. We evaluate this approach on a 2D transient computational fluid dynamics (CFD) problem involving convective heat transfer from buoyancy-driven flow coupled to a heat flow in a solid structure. We demonstrate that the conditioned model successfully reproduces complex temporal dynamics and spatial correlations of the training data. Furthermore, we assess the model's generalization capabilities on unseen geometric configurations, highlighting both its potential for controlled simulation synthesis and current limitations in spatial precision for out-of-distribution samples.", "AI": {"tldr": "本文提出了一种基于几何感知的世界模型架构，用于学习瞬态物理现象。该架构通过引入两层条件机制和适应任意通道维度的改进来处理偏微分方程模拟中的计算瓶颈。", "motivation": "部分微分方程（PDE）仿真对于工程和物理学至关重要，但在实时应用中通常是计算密集型的。虽然生成式AI为替代建模提供了可能的途径，但标准视频生成架构缺乏特定控制和数据兼容性来支持物理模拟。因此，本文提出了一种基于几何感知的世界模型架构。", "method": "该方法从一个视频生成架构（LongVideoGAN）衍生而来，并引入了两个关键组件：一种两层条件机制，结合全球物理参数和局部几何掩模；以及适应任意通道维度的架构改进，超越了标准RGB约束。该方法在二维瞬态计算流体动力学问题中进行了评估，涉及浮力驱动流动耦合到固体结构中的热传递。", "result": "实验结果表明，条件模型成功复制了训练数据的复杂时间动态和空间相关性，并且在未见过的几何配置上展示了其模拟合成能力以及空间精度的局限性。", "conclusion": "通过引入一种基于LongVideoGAN架构的改进方法，本文证明了该世界模型能够有效地学习瞬态物理现象并生成控制良好的模拟。尽管存在一些限制，在处理未见数据时需要提高空间精度。"}}
{"id": "2601.22083", "pdf": "https://arxiv.org/pdf/2601.22083", "abs": "https://arxiv.org/abs/2601.22083", "authors": ["Enyi Jiang", "Yibo Jacky Zhang", "Yinglun Xu", "Andreas Haupt", "Nancy Amato", "Sanmi Koyejo"], "title": "Latent Adversarial Regularization for Offline Preference Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning from human feedback typically relies on preference optimization that constrains policy updates through token-level regularization. However, preference optimization for language models is particularly challenging because token-space similarity does not imply semantic or behavioral similarity. To address this challenge, we leverage latent-space regularization for language model preference optimization. We introduce GANPO, which achieves latent-space regularization by penalizing divergence between the internal representations of a policy model and a reference model. Given that latent representations are not associated with explicit probability densities, we adopt an adversarial approach inspired by GANs to minimize latent-space divergence. We integrate GANPO as a regularizer into existing offline preference optimization objectives. Experiments across multiple model architectures and tasks show consistent improvements from latent-space regularization. Further, by comparing GANPO-induced inferential biases with those from token-level regularization, we find that GANPO provides more robust structural feedback under distributional shift and noise while maintaining comparable downstream performance with minor computational overhead.", "AI": {"tldr": "本文提出了一种新的偏好优化方法GANPO，通过在潜在空间进行正则化来提高语言模型的性能。", "motivation": "传统的基于人类反馈的学习依赖于令牌级别的正则化，但在处理语言模型时存在挑战，因为令牌空间相似性并不意味着语义或行为上的相似。为了克服这一问题，本文提出了在潜在空间中进行正则化的策略以更好地优化偏好。", "method": "GANPO利用生成对抗网络的原理，在政策模型和参考模型之间最小化内部表示的偏差，从而实现潜在空间中的正则化。这种方法被集成到现有的离线偏好优化目标之中。", "result": "实验表明，相比于令牌级正则化，GANPO在分布偏移和噪声条件下提供了更稳健的结构反馈，并且保持了下游任务中的性能，同时增加了很少的计算负担。", "conclusion": "通过潜在空间正则化的引入，GANPO提高了语言模型从人类偏好中学习的能力，显示出在多种架构和任务上的优越性。"}}
{"id": "2601.22082", "pdf": "https://arxiv.org/pdf/2601.22082", "abs": "https://arxiv.org/abs/2601.22082", "authors": ["Yi Fei Cheng", "Jarod Bloch", "Alexander Wang", "Andrea Bianchi", "Anusha Withana", "Anhong Guo", "Laurie M. Heller", "David Lindlbauer"], "title": "Auditorily Embodied Conversational Agents: Effects of Spatialization and Situated Audio Cues on Presence and Social Perception", "categories": ["cs.HC"], "comment": "ef:Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26), April 13--17, 2026, Barcelona, Spain", "summary": "Embodiment can enhance conversational agents, such as increasing their perceived presence. This is typically achieved through visual representations of a virtual body; however, visual modalities are not always available, such as when users interact with agents using headphones or display-less glasses. In this work, we explore auditory embodiment. By introducing auditory cues of bodily presence - through spatially localized voice and situated Foley audio from environmental interactions - we investigate how audio alone can convey embodiment and influence perceptions of a conversational agent. We conducted a 2 (spatialization: monaural vs. spatialized) x 2 (Foley: none vs. Foley) within-subjects study, where participants (n=24) engaged in conversations with agents. Our results show that spatialization and Foley increase co-presence, but reduce users' perceptions of the agent's attention and other social attributes.", "AI": {"tldr": "研究通过声音线索探讨虚拟对话代理的拟人化，包括空间定位和环境音效对用户感知的影响。", "motivation": "探索在视觉受限的情况下，如何仅通过声音实现对话代理的拟人化，并提高其被感知的存在感和社会属性。", "method": "进行了一个2（空间化：单声道 vs 空间化）x 2（环境音效：无 vs 有）的双因素内组实验，参与者与虚拟代理进行会话。", "result": "结果表明，声音的空间定位和环境音效可以增加用户的共存感，但同时降低用户对对话代理注意力和其他社会属性的认知。", "conclusion": "通过仅使用声音线索，能够有效增强虚拟对话代理的拟人化程度，并影响其在用户心中的存在和社会感知。"}}
{"id": "2601.22081", "pdf": "https://arxiv.org/pdf/2601.22081", "abs": "https://arxiv.org/abs/2601.22081", "authors": ["Yichun Zhao", "Miguel A. Nacenta", "Mahadeo A. Sukhai", "Sowmya Somanath"], "title": "Accessibility-Driven Information Transformations in Mixed-Visual Ability Work Teams", "categories": ["cs.HC"], "comment": "To appear in ACM CHI 2026. DOI: https://doi.org/10.1145/3772318.3790872", "summary": "Blind and low-vision (BLV) employees in mixed-visual ability teams often encounter information (e.g., PDFs, diagrams) in inaccessible formats. To enable teamwork, teams must transform these representations by modifying or re-creating them into accessible forms. However, these transformations are frequently overlooked, lack infrastructural support, and cause additional labour. To design systems that move beyond one-off accommodations to effective mixed-ability collaboration, we need a deeper understanding of the representations, their transformations and how they occur. We conducted a week-long diary study with follow-up interviews with 23 BLV and sighted professionals from five legal, non-profit, and consulting teams, documenting 36 transformation cases. Our analysis characterizes how teams perform representational transformations for accessibility: how they are triggered proactively or reactively, how they simplify or enhance, and four common patterns in which workers coordinate with each other to address representational incompatibility. Our findings uncover opportunities for designing systems that can better support mixed-visual ability work.", "AI": {"tldr": "研究分析了混合视觉能力团队中信息转换的模式和挑战，以支持BLV员工的工作协作", "motivation": "提高混合视觉能力工作团队中的协作效率，解决盲人和低视力员工面临的无障碍格式问题", "method": "进行了一周的日志研究并进行了后续访谈，共涉及23名来自五个不同领域的参与者，记录了36个转换案例", "result": "揭示了代表转换的触发方式、简化或增强方法以及四种常见的协调模式", "conclusion": "发现为设计更有效的系统提供了机会，以支持混合视觉能力的工作团队"}}
{"id": "2601.22075", "pdf": "https://arxiv.org/pdf/2601.22075", "abs": "https://arxiv.org/abs/2601.22075", "authors": ["Kirill Antonov", "Teus Tukker", "Tiago Botari", "Thomas H. W. Bäck", "Anna V. Kononova", "Niki van Stein"], "title": "Lens-descriptor guided evolutionary algorithm for optimization of complex optical systems with glass choice", "categories": ["cs.NE"], "comment": null, "summary": "Designing high-performance optical lenses entails exploring a high-dimensional, tightly constrained space of surface curvatures, glass choices, element thicknesses, and spacings. In practice, standard optimizers (e.g., gradient-based local search and evolutionary strategies) often converge to a single local optimum, overlooking many comparably good alternatives that matter for downstream engineering decisions. We propose the Lens Descriptor-Guided Evolutionary Algorithm (LDG-EA), a two-stage framework for multimodal lens optimization. LDG-EA first partitions the design space into behavior descriptors defined by curvature-sign patterns and material indices, then learns a probabilistic model over descriptors to allocate evaluations toward promising regions. Within each descriptor, LDG-EA applies the Hill-Valley Evolutionary Algorithm with covariance-matrix self-adaptation to recover multiple distinct local minima, optionally followed by gradient-based refinement. On a 24-variable (18 continuous and 6 integer), six-element Double-Gauss topology, LDG-EA generates on average around 14500 candidate minima spanning 636 unique descriptors, an order of magnitude more than a CMA-ES baseline, while keeping wall-clock time at one hour scale. Although the best LDG-EA design is slightly worse than a fine-tuned reference lens, it remains in the same performance range. Overall, the proposed LDG-EA produces a diverse set of solutions while maintaining competitive quality within practical computational budgets and wall-clock time.", "AI": {"tldr": "提出了一种基于镜头描述符的进化算法（LDG-EA），用于优化复杂光学系统的设计。", "motivation": "传统的优化方法往往局限于单一局部最优解，忽略了下游工程决策中重要的多种可能解决方案。因此，设计出能够探索更多可行方案的方法是必要的。", "method": "LDG-EA框架分为两阶段：首先根据曲率符号模式和材料指数划分设计空间，并学习概率模型以分配评估；其次在每个描述符内部应用希尔-谷进化算法来恢复多个局部最小值，可选地使用梯度细化。", "result": "在24变量的双高斯拓扑结构上测试时，LDG-EA可以生成大约14500个候选解，并且性能优于基线CMA-ES方法。尽管最佳设计稍逊于参考镜头，但依然处于同一性能范围。", "conclusion": "提出的LDG-EA算法能够在保持计算效率的同时产生多样化的解决方案集合。"}}
{"id": "2601.22074", "pdf": "https://arxiv.org/pdf/2601.22074", "abs": "https://arxiv.org/abs/2601.22074", "authors": ["Kevin Zakka", "Qiayuan Liao", "Brent Yi", "Louis Le Lay", "Koushil Sreenath", "Pieter Abbeel"], "title": "mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning", "categories": ["cs.RO"], "comment": "Code is available at https://github.com/mujocolab/mjlab", "summary": "We present mjlab, a lightweight, open-source framework for robot learning that combines GPU-accelerated simulation with composable environments and minimal setup friction. mjlab adopts the manager-based API introduced by Isaac Lab, where users compose modular building blocks for observations, rewards, and events, and pairs it with MuJoCo Warp for GPU-accelerated physics. The result is a framework installable with a single command, requiring minimal dependencies, and providing direct access to native MuJoCo data structures. mjlab ships with reference implementations of velocity tracking, motion imitation, and manipulation tasks.", "AI": {"tldr": "介绍了一种轻量级的基于GPU加速机器人的学习框架mjlab。", "motivation": "为了简化机器人学习过程中GPU加速仿真、可组合环境和最小化设置摩擦的过程，提出了mjlab框架。", "method": "采用经理API模式引入由Isaac Lab提出的方法，并结合MuJoCo Warp进行GPU加速物理模拟。用户可以轻松组装观察、奖励和事件的模块化构建块。", "result": "该框架可以通过单个命令安装，具有最小依赖关系，并提供对原生MuJoCo数据结构的直接访问。", "conclusion": "mjlab提供了参考实现用于速度跟踪、动作模仿和操作任务，并且是一个轻量级开源框架。"}}
{"id": "2601.22061", "pdf": "https://arxiv.org/pdf/2601.22061", "abs": "https://arxiv.org/abs/2601.22061", "authors": ["Li Zhang", "Pengtao Xie"], "title": "BLO-Inst: Bi-Level Optimization Based Alignment of YOLO and SAM for Robust Instance Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "The Segment Anything Model has revolutionized image segmentation with its zero-shot capabilities, yet its reliance on manual prompts hinders fully automated deployment. While integrating object detectors as prompt generators offers a pathway to automation, existing pipelines suffer from two fundamental limitations: objective mismatch, where detectors optimized for geometric localization do not correspond to the optimal prompting context required by SAM, and alignment overfitting in standard joint training, where the detector simply memorizes specific prompt adjustments for training samples rather than learning a generalizable policy. To bridge this gap, we introduce BLO-Inst, a unified framework that aligns detection and segmentation objectives by bi-level optimization. We formulate the alignment as a nested optimization problem over disjoint data splits. In the lower level, the SAM is fine-tuned to maximize segmentation fidelity given the current detection proposals on a subset ($D_1$). In the upper level, the detector is updated to generate bounding boxes that explicitly minimize the validation loss of the fine-tuned SAM on a separate subset ($D_2$). This effectively transforms the detector into a segmentation-aware prompt generator, optimizing the bounding boxes not just for localization accuracy, but for downstream mask quality. Extensive experiments demonstrate that BLO-Inst achieves superior performance, outperforming standard baselines on tasks in general and biomedical domains.", "AI": {"tldr": "本文介绍了一种基于双层优化的框架BLO-Inst，以解决检测器和分割模型之间的目标不匹配问题，并提出一种新型的实例分割方法。", "motivation": "现有的集成对象检测器作为提示生成器的方法面临两个主要限制：目标不匹配和标准联合训练中的适应过拟合。作者旨在通过引入双层优化来改进这一过程，以实现更准确、更具泛化的实例分割结果。", "method": "BLO-Inst框架将对齐任务定义为在不同数据子集上进行的嵌套优化问题：在较低层次中，在$D_1$集合上微调SAM，以最大化给定当前检测提议的分割保真度；在较高层次中，在$D_2$集合上更新检测器，使其生成的边界框能够最小化验证损失。这种方法使检测器能够成为更具感知力的提示生成器。", "result": "实验表明，BLO-Inst方法在通用和生物医学任务上的性能均优于标准基线模型。", "conclusion": "通过双层优化策略，作者成功地解决了现有集成系统中的目标不匹配问题，并且证明了这种新框架能够提升实例分割的质量。"}}
{"id": "2601.22060", "pdf": "https://arxiv.org/pdf/2601.22060", "abs": "https://arxiv.org/abs/2601.22060", "authors": ["Wenxuan Huang", "Yu Zeng", "Qiuchen Wang", "Zhen Fang", "Shaosheng Cao", "Zheng Chu", "Qingyu Yin", "Shuang Chen", "Zhenfei Yin", "Lin Chen", "Zehui Chen", "Yao Hu", "Philip Torr", "Feng Zhao", "Wanli Ouyang"], "title": "Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.", "AI": {"tldr": "Vision-DeepResearch 提出了一种新的多模态深度研究范式，通过执行多次、多个实体和多尺度的视觉及文本搜索来解决复杂问题。", "motivation": "现有的多模态大语言模型在处理需要大量事实信息的任务时存在局限性，特别是在面对现实世界中的噪音情况时。这些方法通常依赖于简单的查询方式，并且受限于推理深度和搜索广度。", "method": "Vision-DeepResearch 通过执行多次、多个实体和多尺度的视觉及文本搜索来获取关键证据。这种方法支持几十个推理步骤和数百次引擎交互，内部化了深度研究能力。", "result": "Vision-DeepResearch 显著优于现有的多模态深度研究模型，并且在基于 GPT-5 等强大的闭源基础模型的工作流中也表现出色。", "conclusion": "通过引入 Vision-DeepResearch 范式，可以在具有挑战性的现实世界场景下提高多模态大语言模型的性能。"}}
{"id": "2601.22057", "pdf": "https://arxiv.org/pdf/2601.22057", "abs": "https://arxiv.org/abs/2601.22057", "authors": ["Archer Wang", "Emile Anand", "Yilun Du", "Marin Soljačić"], "title": "Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": "28 pages, 16 figures, 4 tables", "summary": "Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.", "AI": {"tldr": "本文提出了一个无监督的分解和重组方法，通过对抗训练信号改进扩散模型学习因子化潜在空间的能力。", "motivation": "通过对复杂数据进行分解以揭示可重用组件，并在无需因素级监督的情况下合成新样本，旨在提高潜因子发现质量和组合生成质量。", "method": "引入了通过判别器区分单一来源样例和重组因素样例的对抗训练信号，优化生成器使其误导判别器，从而鼓励物理和语义一致性。", "result": "在CelebA-HQ、Virtual KITTI、CLEVR和Falcor3D数据集上优于先前基线方法，在LIBERO基准测试中展示了对机器人视频轨迹重组的应用。", "conclusion": "该方法通过引入对抗训练信号改进了潜因子发现质量和组合生成质量，实现了更好的分解效果并扩展了状态空间覆盖率。"}}
{"id": "2601.22054", "pdf": "https://arxiv.org/pdf/2601.22054", "abs": "https://arxiv.org/abs/2601.22054", "authors": ["Baorui Ma", "Jiahui Yang", "Donglin Di", "Xuancheng Zhang", "Jianxun Cui", "Hao Li", "Yan Xie", "Wei Chen"], "title": "MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources", "categories": ["cs.CV", "cs.AI"], "comment": "Project Page: https://metric-anything.github.io/metric-anything-io/", "summary": "Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.", "AI": {"tldr": "本文介绍了一种可扩展的预训练框架Metric Anything，用于从嘈杂且多样化的3D源中学习度量深度。", "motivation": "随着视觉基础模型的发展，将扩展模式应用于度量深度估计面临着传感器噪声、相机依赖偏差和跨源数据中的度量模糊等挑战。本文旨在解决这些问题，并实现度量深度预训练的可扩展性。", "method": "Metric Anything采用随机屏蔽深度图生成稀疏度量提示作为通用接口，解耦空间推理与传感器及相机偏见；使用约20M图像-深度对进行预训练，包括重建、捕获和渲染的3D数据，并展示明确的规模趋势。", "result": "在多个任务中展示了优越性能：深度完成、超分辨率、雷达相机融合等。其蒸馏后的无提示学生模型在单目深度估计、相机参数恢复等方面达到SOTA。同时，使用Metric Anything预训练ViT作为视觉编码器显著提升了多模态大型语言模型的空间智能。", "conclusion": "本文表明度量深度估计可以受益于现代基础模型的扩展规律，为高效现实世界的度量感知开辟了一条新路径，并开放源代码以支持社区研究。"}}
{"id": "2601.22046", "pdf": "https://arxiv.org/pdf/2601.22046", "abs": "https://arxiv.org/abs/2601.22046", "authors": ["Changjian Jiang", "Kerui Ren", "Xudong Li", "Kaiwen Song", "Linning Xu", "Tao Lu", "Junting Dong", "Yu Zhang", "Bo Dai", "Mulin Yu"], "title": "PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Streaming reconstruction from monocular image sequences remains challenging, as existing methods typically favor either high-quality rendering or accurate geometry, but rarely both. We present PLANING, an efficient on-the-fly reconstruction framework built on a hybrid representation that loosely couples explicit geometric primitives with neural Gaussians, enabling geometry and appearance to be modeled in a decoupled manner. This decoupling supports an online initialization and optimization strategy that separates geometry and appearance updates, yielding stable streaming reconstruction with substantially reduced structural redundancy. PLANING improves dense mesh Chamfer-L2 by 18.52% over PGSR, surpasses ARTDECO by 1.31 dB PSNR, and reconstructs ScanNetV2 scenes in under 100 seconds, over 5x faster than 2D Gaussian Splatting, while matching the quality of offline per-scene optimization. Beyond reconstruction quality, the structural clarity and computational efficiency of \\modelname~make it well suited for a broad range of downstream applications, such as enabling large-scale scene modeling and simulation-ready environments for embodied AI. Project page: https://city-super.github.io/PLANING/ .", "AI": {"tldr": "PLANING是一种用于单目图像序列的实时三维重建框架，结合了显式几何模型和神经高斯模型。", "motivation": "现有的方法在高质量渲染与准确几何形状之间难以兼顾。PLANING旨在通过松耦合的混合表示来解决这个问题。", "method": "PLANING利用显式几何模型和神经高斯模型的松耦合结构，支持在线初始化和优化策略，以分离几何更新和外观更新。", "result": "与PGSR相比，PLANING在密集网格Chamfer-L2方面提高了18.52%；比ARTDECO高出1.31dB PSNR。它可以在不到100秒的时间内重建ScanNetV2场景，速度超过2D高斯点云的五倍。", "conclusion": "PLANING在质量和计算效率上表现出色，适用于大规模场景建模和模拟环境等下游应用。"}}
{"id": "2601.22045", "pdf": "https://arxiv.org/pdf/2601.22045", "abs": "https://arxiv.org/abs/2601.22045", "authors": ["Da Li", "Chen Yao", "Tong Mao", "Jiacheng Bao", "Houjun Sun"], "title": "Urban Neural Surface Reconstruction from Constrained Sparse Aerial Imagery with 3D SAR Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Neural surface reconstruction (NSR) has recently shown strong potential for urban 3D reconstruction from multi-view aerial imagery. However, existing NSR methods often suffer from geometric ambiguity and instability, particularly under sparse-view conditions. This issue is critical in large-scale urban remote sensing, where aerial image acquisition is limited by flight paths, terrain, and cost. To address this challenge, we present the first urban NSR framework that fuses 3D synthetic aperture radar (SAR) point clouds with aerial imagery for high-fidelity reconstruction under constrained, sparse-view settings. 3D SAR can efficiently capture large-scale geometry even from a single side-looking flight path, providing robust priors that complement photometric cues from images. Our framework integrates radar-derived spatial constraints into an SDF-based NSR backbone, guiding structure-aware ray selection and adaptive sampling for stable and efficient optimization. We also construct the first benchmark dataset with co-registered 3D SAR point clouds and aerial imagery, facilitating systematic evaluation of cross-modal 3D reconstruction. Extensive experiments show that incorporating 3D SAR markedly enhances reconstruction accuracy, completeness, and robustness compared with single-modality baselines under highly sparse and oblique-view conditions, highlighting a viable route toward scalable high-fidelity urban reconstruction with advanced airborne and spaceborne optical-SAR sensing.", "AI": {"tldr": "该论文提出了一种结合了三维合成孔径雷达（SAR）点云和多视角航空图像的神经表面重建框架，用于在稀疏视图条件下进行大规模城市三维重建。", "motivation": "现有的神经表面重建方法在处理稀疏视图条件下的几何模糊性和不稳定性时面临挑战。这种问题尤其严重于大型城市遥感中，其中航空图像获取受限于飞行路径、地形和成本。", "method": "该框架将雷达衍生的空间约束整合到基于SDF的NSR主干网中，指导结构感知光线选择和自适应采样，以实现稳定的高效优化。同时构建了第一个基准数据集，包含注册过的三维SAR点云和航空图像。", "result": "实验结果表明，在高度稀疏和倾斜视图条件下，将3D SAR融入重建过程可以显著提高重建精度、完整性和鲁棒性。", "conclusion": "该论文提出了一种新的方法以解决大规模城市遥感中的三维重建问题，并展示了这种方法的有效性。"}}
{"id": "2601.22044", "pdf": "https://arxiv.org/pdf/2601.22044", "abs": "https://arxiv.org/abs/2601.22044", "authors": ["MohammadErfan Jabbari", "Abhishek Duttagupta", "Claudio Fiandrino", "Leonardo Bonati", "Salvatore D'Oro", "Michele Polese", "Marco Fiore", "Tommaso Melodia"], "title": "SIA: Symbolic Interpretability for Anticipatory Deep Reinforcement Learning in Network Control", "categories": ["cs.NI", "cs.AI"], "comment": "10 pages, 12 figures, accepted at IEEE INFOCOM 2026", "summary": "Deep reinforcement learning (DRL) promises adaptive control for future mobile networks but conventional agents remain reactive: they act on past and current measurements and cannot leverage short-term forecasts of exogenous KPIs such as bandwidth. Augmenting agents with predictions can overcome this temporal myopia, yet uptake in networking is scarce because forecast-aware agents act as closed-boxes; operators cannot tell whether predictions guide decisions or justify the added complexity. We propose SIA, the first interpreter that exposes in real time how forecast-augmented DRL agents operate. SIA fuses Symbolic AI abstractions with per-KPI Knowledge Graphs to produce explanations, and includes a new Influence Score metric. SIA achieves sub-millisecond speed, over 200x faster than existing XAI methods. We evaluate SIA on three diverse networking use cases, uncovering hidden issues, including temporal misalignment in forecast integration and reward-design biases that trigger counter-productive policies. These insights enable targeted fixes: a redesigned agent achieves a 9% higher average bitrate in video streaming, and SIA's online Action-Refinement module improves RAN-slicing reward by 25% without retraining. By making anticipatory DRL transparent and tunable, SIA lowers the barrier to proactive control in next-generation mobile networks.", "AI": {"tldr": "SIA是一种解释框架，用于实时解析基于预测的深度强化学习网络控制决策。", "motivation": "传统DRL代理只能根据过去的测量值做出反应，并不能利用短期预测来指导行动。引入预测可解决这一问题，但缺乏透明度使得运营商难以理解预测是否真正影响了决策。", "method": "SIA结合符号AI和知识图谱生成实时解释，并提出了一种新的影响力评分指标，同时在三个网络应用场景中进行了评估。", "result": "实验表明，SIA能够以亚毫秒级速度运行，远快于现有XAI方法。通过揭示隐藏问题并提供改进建议，改进后的代理在视频流传输中的平均比特率提高了9%，并且在线动作细化模块将RAN切片奖励提高了25%。", "conclusion": "SIA使得基于预测的DRL网络控制决策更加透明和可调，从而降低了未来移动网络中主动控制实现的门槛。"}}
{"id": "2601.22041", "pdf": "https://arxiv.org/pdf/2601.22041", "abs": "https://arxiv.org/abs/2601.22041", "authors": ["Naomi Pitzer", "Daniela Mihai"], "title": "Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.LG"], "comment": "To be published in EvoLang XVI proceedings. 15 pages, 17 figures", "summary": "Emergent communication offers insight into how agents develop shared structured representations, yet most research assumes homogeneous modalities or aligned representational spaces, overlooking the perceptual heterogeneity of real-world settings. We study a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding. Despite perceptual misalignment, multimodal systems converge to class-consistent messages grounded in perceptual input. Unimodal systems communicate more efficiently, using fewer bits and achieving lower classification entropy, while multimodal agents require greater information exchange and exhibit higher uncertainty. Bit perturbation experiments provide strong evidence that meaning is encoded in a distributional rather than compositional manner, as each bit's contribution depends on its surrounding pattern. Finally, interoperability analyses show that systems trained in different perceptual worlds fail to directly communicate, but limited fine-tuning enables successful cross-system communication. This work positions emergent communication as a framework for studying how agents adapt and transfer representations across heterogeneous modalities, opening new directions for both theory and experimentation.", "AI": {"tldr": "研究了多模态异构环境中代理之间的通信机制。", "motivation": "大多数关于代理之间通信的研究假设同质的模式或者对齐的表示空间，忽略了现实世界中感知差异的存在。因此，该论文探讨在不同模式和缺乏感知基础的情况下，如何进行有效的通信。", "method": "设计了一个异构多步二进制通信游戏，其中代理以不同的方式存在并且没有感知基础。通过实验研究了单模态与多模态系统之间的信息交流效率及不确定性。", "result": "发现尽管存在感知上的不一致，但多模态系统仍然能够收敛到基于输入的类别一致性消息。同时，单模态系统比多模态系统更有效地进行通信，并且通过位干扰实验表明意义是以分布而不是组合方式编码的。", "conclusion": "该研究认为，异构环境中的代理可以通过适应和转换表示来实现跨模式的有效交流，这为理论和实验提供了新的方向。"}}
{"id": "2601.22040", "pdf": "https://arxiv.org/pdf/2601.22040", "abs": "https://arxiv.org/abs/2601.22040", "authors": ["Reza T. Batley", "Sourav Saha"], "title": "A Separable Architecture for Continuous Token Representation in Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \\times$ more parameters.", "AI": {"tldr": "研究提出了一种连续生成器架构来替代传统的离散查找表，优化了小规模语言模型中的参数分配。", "motivation": "在小型语言模型中，嵌入矩阵占据了大部分的参数预算，这种分配方式被认为效率低下且不符合直觉。因此，提出了一个新的架构来改进这一情况。", "method": "提出了一种名为Leviathan的新架构，它使用连续生成器替代了传统模型中的离散查找表，并通过Pile数据集在同参设置下进行评估。", "result": "Leviathan在同等参数条件下优于标准的LLaMA风格架构，并表现出更高的有效参数容量，相当于具有1.47到2.11倍更多的参数。", "conclusion": "新的连续生成器架构能够在小型语言模型中提供更好的性能和更高效的参数使用。"}}
{"id": "2601.22039", "pdf": "https://arxiv.org/pdf/2601.22039", "abs": "https://arxiv.org/abs/2601.22039", "authors": ["Manuel Benavent-Lledo", "Konstantinos Bacharidis", "Konstantinos Papoutsakis", "Antonis Argyros", "Jose Garcia-Rodriguez"], "title": "Understanding Multimodal Complementarity for Single-Frame Action Anticipation", "categories": ["cs.CV"], "comment": null, "summary": "Human action anticipation is commonly treated as a video understanding problem, implicitly assuming that dense temporal information is required to reason about future actions. In this work, we challenge this assumption by investigating what can be achieved when action anticipation is constrained to a single visual observation. We ask a fundamental question: how much information about the future is already encoded in a single frame, and how can it be effectively exploited? Building on our prior work on Action Anticipation at a Glimpse (AAG), we conduct a systematic investigation of single-frame action anticipation enriched with complementary sources of information. We analyze the contribution of RGB appearance, depth-based geometric cues, and semantic representations of past actions, and investigate how different multimodal fusion strategies, keyframe selection policies and past-action history sources influence anticipation performance. Guided by these findings, we consolidate the most effective design choices into AAG+, a refined single-frame anticipation framework. Despite operating on a single frame, AAG+ consistently improves upon the original AAG and achieves performance comparable to, or exceeding, that of state-of-the-art video-based methods on challenging anticipation benchmarks including IKEA-ASM, Meccano and Assembly101. Our results offer new insights into the limits and potential of single-frame action anticipation, and clarify when dense temporal modeling is necessary and when a carefully selected glimpse is sufficient.", "AI": {"tldr": "Processing failed", "motivation": "Processing failed", "method": "Processing failed", "result": "Processing failed", "conclusion": "Processing failed"}}
{"id": "2601.22037", "pdf": "https://arxiv.org/pdf/2601.22037", "abs": "https://arxiv.org/abs/2601.22037", "authors": ["Sami Abuzakuk", "Anne-Marie Kermarrec", "Rishi Sharma", "Rasmus Moorits Veski", "Martijn de Vos"], "title": "Optimizing Agentic Workflows using Meta-tools", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agentic AI enables LLM to dynamically reason, plan, and interact with tools to solve complex tasks. However, agentic workflows often require many iterative reasoning steps and tool invocations, leading to significant operational expense, end-to-end latency and failures due to hallucinations. This work introduces Agent Workflow Optimization (AWO), a framework that identifies and optimizes redundant tool execution patterns to improve the efficiency and robustness of agentic workflows. AWO analyzes existing workflow traces to discover recurring sequences of tool calls and transforms them into meta-tools, which are deterministic, composite tools that bundle multiple agent actions into a single invocation. Meta-tools bypass unnecessary intermediate LLM reasoning steps and reduce operational cost while also shortening execution paths, leading to fewer failures. Experiments on two agentic AI benchmarks show that AWO reduces the number of LLM calls up to 11.9% while also increasing the task success rate by up to 4.2 percent points.", "AI": {"tldr": "本文提出了Agent Workflow Optimization（AWO）框架，旨在优化基于LLM的复杂任务解决流程。", "motivation": "传统的agentic AI在处理复杂任务时存在操作成本高、延迟长和由于hallucination导致失败的问题。为了解决这些问题，作者引入了AWO来优化工具执行模式。", "method": "通过分析现有工作流痕迹中的重复工具调用序列并将其转换成meta-tools，实现对流程的改进，从而减少不必要的中间推理步骤，并降低成本、缩短执行路径。", "result": "实验显示，在两个agentic AI基准测试中，AWO将LLM调用次数减少了最多11.9%，同时提高了任务成功率4.2个百分点。", "conclusion": "AWO框架能够有效提升基于LLM的复杂任务解决流程的效率和可靠性。"}}
{"id": "2601.22035", "pdf": "https://arxiv.org/pdf/2601.22035", "abs": "https://arxiv.org/abs/2601.22035", "authors": ["Longxuan Yu", "Yu Fu", "Shaorong Zhang", "Hui Liu", "Mukund Varma T", "Greg Ver Steeg", "Yue Dong"], "title": "Thinking Out of Order: When Output Order Stops Reflecting Reasoning Order in Diffusion Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages, 13 figures, 5 tables", "summary": "Autoregressive (AR) language models enforce a fixed left-to-right generation order, creating a fundamental limitation when the required output structure conflicts with natural reasoning (e.g., producing answers before explanations due to presentation or schema constraints). In such cases, AR models must commit to answers before generating intermediate reasoning, and this rigid constraint forces premature commitment. Masked diffusion language models (MDLMs), which iteratively refine all tokens in parallel, offer a way to decouple computation order from output structure. We validate this capability on GSM8K, Math500, and ReasonOrderQA, a benchmark we introduce with controlled difficulty and order-level evaluation. When prompts request answers before reasoning, AR models exhibit large accuracy gaps compared to standard chain-of-thought ordering (up to 67% relative drop), while MDLMs remain stable ($\\leq$14% relative drop), a property we term \"order robustness\". Using ReasonOrderQA, we present evidence that MDLMs achieve order robustness by stabilizing simpler tokens (e.g., reasoning steps) earlier in the diffusion process than complex ones (e.g., final answers), enabling reasoning tokens to stabilize before answer commitment. Finally, we identify failure conditions where this advantage weakens, outlining the limits required for order robustness.", "AI": {"tldr": "研究提出了一个新的基准ReasonOrderQA，用于评估语言模型在不同输出顺序下的表现，并展示了扩散语言模型MDLM相比于传统的自回归模型AR模型，在特定条件下具有更好的鲁棒性。", "motivation": "现有自回归语言模型存在一个根本限制：固定从左到右的生成顺序使得在需要特定结构时（如先回答再解释），必须提前确定答案，而不能灵活地调整推理过程。扩散语言模型可以通过并行修正所有词来解决这个问题，从而实现计算顺序与输出结构的解耦。", "method": "通过引入新的基准ReasonOrderQA并在GSM8K、Math500上验证了MDLM相比于AR模型在要求答案先于解释时表现出更高的准确性。进一步分析表明，MDLM能够通过更早稳定简单的推理步骤来实现这种鲁棒性。", "result": "自回归语言模型在需要特定顺序的情况下表现较差（相对下降高达67%），而扩散语言模型保持了较高的稳定性（不超过14%的相对下降）。然而，在一些条件下，这个优势会减弱。", "conclusion": "尽管MDLM展示了比AR模型更好的鲁棒性，但也存在一定的局限。未来的研究可以继续探索如何优化这些模型以更好地适应不同任务的需求。"}}
{"id": "2601.22032", "pdf": "https://arxiv.org/pdf/2601.22032", "abs": "https://arxiv.org/abs/2601.22032", "authors": ["Linhan Wang", "Zichong Yang", "Chen Bai", "Guoxiang Zhang", "Xiaotong Liu", "Xiaoyin Zheng", "Xiao-Xiao Long", "Chang-Tien Lu", "Cheng Lu"], "title": "Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving", "categories": ["cs.CV"], "comment": null, "summary": "End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.", "AI": {"tldr": "Drive-JEPA提出了一种结合视频联合嵌入预测架构(V-JEPA)和多模态轨迹蒸馏的端到端驾驶框架，以提高自动驾驶性能。", "motivation": "当前基于自监督视频预训练的场景理解世界模型在提高自动驾驶能力方面成效有限。此外，由于每个场景通常仅提供一条人类行驶路径，难以学习多样化的驾驶行为模式。", "method": "提出Drive-JEPA框架，结合V-JEPA和多模态轨迹蒸馏技术。首先使用ViT编码器在大规模驾驶视频上进行预训练以生成预测表示；其次引入基于提议的规划者从模拟器生成的多样化行驶路径中蒸馏出稳定安全的行为。", "result": "与先前方法相比，在无感知的情况下，V-JEPA结合简单解码器的表现超出3PDMS。完整Drive-JEPA框架在v1和v2版本下分别达到93.3 PDMS和87.8 EPDMS的新最佳性能。", "conclusion": "通过整合V-JEPA与多模态轨迹蒸馏，Drive-JEPA显著提升了自动驾驶系统的规划能力和安全性表现。"}}
{"id": "2601.22027", "pdf": "https://arxiv.org/pdf/2601.22027", "abs": "https://arxiv.org/abs/2601.22027", "authors": ["Johannes Kirmayr", "Lukas Stappen", "Elisabeth André"], "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty", "categories": ["cs.AI"], "comment": null, "summary": "Existing benchmarks for Large Language Model (LLM) agents focus on task completion under idealistic settings but overlook reliability in real-world, user-facing applications. In domains, such as in-car voice assistants, users often issue incomplete or ambiguous requests, creating intrinsic uncertainty that agents must manage through dialogue, tool use, and policy adherence. We introduce CAR-bench, a benchmark for evaluating consistency, uncertainty handling, and capability awareness in multi-turn, tool-using LLM agents in an in-car assistant domain. The environment features an LLM-simulated user, domain policies, and 58 interconnected tools spanning navigation, productivity, charging, and vehicle control. Beyond standard task completion, CAR-bench introduces Hallucination tasks that test agents' limit-awareness under missing tools or information, and Disambiguation tasks that require resolving uncertainty through clarification or internal information gathering. Baseline results reveal large gaps between occasional and consistent success on all task types. Even frontier reasoning LLMs achieve less than 50% consistent pass rate on Disambiguation tasks due to premature actions, and frequently violate policies or fabricate information to satisfy user requests in Hallucination tasks, underscoring the need for more reliable and self-aware LLM agents in real-world settings.", "AI": {"tldr": "CAR-bench是评估大型语言模型代理在汽车助理领域中面对现实世界不确定性时的一致性和能力意识的基准。", "motivation": "当前的LLM代理基准测试着重于理想条件下的任务完成，忽视了用户界面应用中的可靠性。引入CAR-bench以填补这一空白，强调对话、工具使用和策略遵守的重要性。", "method": "通过模拟真实驾驶环境，包括模拟用户、领域政策以及58个互相关联的工具来构建CAR-bench。此基准测试不仅评估任务完成度还引入了幻觉任务和消歧任务以测试代理在缺失信息或不确定情况下的能力。", "result": "实验结果显示，即使是最前沿推理的LLM在处理不确定性时表现不足，成功率远低于50%，且经常违反政策或虚构信息以满足用户需求。", "conclusion": "该研究揭示了现有大型语言模型代理面对现实世界中的实际挑战时的局限性，并强调发展更加可靠和自我意识强的LLM的重要性。"}}
{"id": "2601.22026", "pdf": "https://arxiv.org/pdf/2601.22026", "abs": "https://arxiv.org/abs/2601.22026", "authors": ["Constantin Kleinbeck", "Luisa Theelke", "Hannah Schieber", "Ulrich Eck", "Rüdiger von Eisenhart-Rothe", "Daniel Roth"], "title": "Hybrid Foveated Path Tracing with Peripheral Gaussians for Immersive Anatomy", "categories": ["cs.GR", "cs.CV"], "comment": "Scheduled for publication in the Proceedings of IEEE VR 2026", "summary": "Volumetric medical imaging offers great potential for understanding complex pathologies. Yet, traditional 2D slices provide little support for interpreting spatial relationships, forcing users to mentally reconstruct anatomy into three dimensions. Direct volumetric path tracing and VR rendering can improve perception but are computationally expensive, while precomputed representations, like Gaussian Splatting, require planning ahead. Both approaches limit interactive use. We propose a hybrid rendering approach for high-quality, interactive, and immersive anatomical visualization. Our method combines streamed foveated path tracing with a lightweight Gaussian Splatting approximation of the periphery. The peripheral model generation is optimized with volume data and continuously refined using foveal renderings, enabling interactive updates. Depth-guided reprojection further improves robustness to latency and allows users to balance fidelity with refresh rate. We compare our method against direct path tracing and Gaussian Splatting. Our results highlight how their combination can preserve strengths in visual quality while re-generating the peripheral model in under a second, eliminating extensive preprocessing and approximations. This opens new options for interactive medical visualization.", "AI": {"tldr": "提出了结合视线跟踪路径追踪和外周高斯近似的混合渲染方法，用于实时高质量的解剖可视化。", "motivation": "传统2D切片难以解释空间关系，直接体积路径追踪和虚拟现实渲染计算成本高且预计算表示需要提前规划，限制了交互使用。本文旨在解决这些问题，提供一种结合两者优点的新方案。", "method": "提出了一种混合渲染方法，通过视线跟踪进行中心区域的高质量路径追踪，并用轻量级的外周高斯近似模型来简化周边区域处理，同时利用深度引导重投影提高鲁棒性。", "result": "对比直接路径追踪和高斯点阵法，该方法能够在1秒内重新生成外周模型，实现交互式更新，而不需要大量的预处理。", "conclusion": "通过结合视线跟踪路径追踪与外周高斯近似，这种混合方案解决了实时高质量解剖可视化中的计算效率问题，为互动医学可视化提供了新选择。"}}
{"id": "2601.22025", "pdf": "https://arxiv.org/pdf/2601.22025", "abs": "https://arxiv.org/abs/2601.22025", "authors": ["Daniel Commey"], "title": "When \"Better\" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.SE"], "comment": null, "summary": "Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop. We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes. In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic \"improved\" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes. All test suites, harnesses, and results are included for reproducibility.", "AI": {"tldr": "介绍了一种基于评估驱动的工作流程，用于优化大型语言模型的应用。提出了最小可行评估套件（MVES），并展示了在本地实验中使用该方法的效果。", "motivation": "由于LLM的输出具有随机性、高维度和对提示及模型变化敏感的特点，传统的软件测试方法不适用于它们。因此，需要一种新的迭代优化策略来应对这些挑战。", "method": "提出了一个定义-测试-诊断-修复的工作流程，并介绍了最小可行评估套件（MVES），它包括针对不同类型LLM应用的推荐评估组件。通过使用自动化检查、人工评分和模型作为裁判的方法进行综合评测，发现改进提示模板可能导致行为权衡。", "result": "实验观察到，在小规模结构化测试套件中，当用通用规则替换特定任务提示时，提取率从100%降至90%，而指令遵循性能提高。这些结果表明需要通过评估驱动的迭代优化来仔细校准声明，而不是依赖于通用模板。", "conclusion": "该研究强调了评价驱动工作流程和细致声明校准的重要性，在使用改进提示时需谨慎行事，并提供了详细的测试套件、工具链及实验结果以确保可重复性。"}}
{"id": "2601.22024", "pdf": "https://arxiv.org/pdf/2601.22024", "abs": "https://arxiv.org/abs/2601.22024", "authors": ["Abhishek Duttagupta", "MohammadErfan Jabbari", "Claudio Fiandrino", "Marco Fiore", "Joerg Widmer"], "title": "SymbXRL: Symbolic Explainable Deep Reinforcement Learning for Mobile Networks", "categories": ["cs.NI", "cs.AI"], "comment": "10 pages, 9 figures, published in IEEE INFOCOM 2025", "summary": "The operation of future 6th-generation (6G) mobile networks will increasingly rely on the ability of deep reinforcement learning (DRL) to optimize network decisions in real-time. DRL yields demonstrated efficacy in various resource allocation problems, such as joint decisions on user scheduling and antenna allocation or simultaneous control of computing resources and modulation. However, trained DRL agents are closed-boxes and inherently difficult to explain, which hinders their adoption in production settings. In this paper, we make a step towards removing this critical barrier by presenting SymbXRL, a novel technique for explainable reinforcement learning (XRL) that synthesizes human-interpretable explanations for DRL agents. SymbXRL leverages symbolic AI to produce explanations where key concepts and their relationships are described via intuitive symbols and rules; coupling such a representation with logical reasoning exposes the decision process of DRL agents and offers more comprehensible descriptions of their behaviors compared to existing approaches. We validate SymbXRL in practical network management use cases supported by DRL, proving that it not only improves the semantics of the explanations but also paves the way for explicit agent control: for instance, it enables intent-based programmatic action steering that improves by 12% the median cumulative reward over a pure DRL solution.", "AI": {"tldr": "本文提出了SymbXRL，一种用于生成DRL代理可解释的符号AI技术。", "motivation": "现有的DRL代理难以解释，阻碍了它们在实际场景中的应用。为了克服这个障碍，文章提出了一种新的可解释强化学习方法。", "method": "SymbXRL利用符号AI产生直观的符号和规则来描述关键概念及其关系，并通过逻辑推理展示DRL代理的决策过程。", "result": "实验表明，与纯DRL解决方案相比，SymbXRL不仅改善了解释语义，还提供了显式的代理控制功能，使得累积奖励提高了12%。", "conclusion": "文章提出的方法为理解并控制复杂的网络管理决策提供了一种新的途径。"}}
{"id": "2601.22020", "pdf": "https://arxiv.org/pdf/2601.22020", "abs": "https://arxiv.org/abs/2601.22020", "authors": ["Chengyi Cai", "Zesheng Ye", "Peike Li", "Bo Han", "Jianzhong Qi", "Feng Liu"], "title": "Visual-Guided Key-Token Regularization for Multimodal Large Language Model Unlearning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Unlearning in Multimodal Large Language Models (MLLMs) prevents the model from revealing private information when queried about target images. Existing MLLM unlearning methods largely adopt approaches developed for LLMs. They treat all answer tokens uniformly, disregarding their varying importance in the unlearning process. Moreover, these methods focus exclusively on the language modality, disregarding visual cues that indicate key tokens in answers. In this paper, after formulating the problem of unlearning in multimodal question answering for MLLMs, we propose Visual-Guided Key-Token Regularization (ViKeR). We leverage irrelevant visual inputs to predict ideal post-unlearning token-level distributions and use these distributions to regularize the unlearning process, thereby prioritizing key tokens. Further, we define key tokens in unlearning via information entropy and discuss ViKeR's effectiveness through token-level gradient reweighting, which amplifies updates on key tokens. Experiments on MLLMU and CLEAR benchmarks demonstrate that our method effectively performs unlearning while mitigating forgetting and maintaining response coherence.", "AI": {"tldr": "视觉引导的关键令牌正则化方法（ViKeR）用于多模态大型语言模型的遗忘机制，以防止模型泄漏关于目标图像的私人信息。", "motivation": "现有的多模态大语言模型（MLLM）遗忘技术忽视了各个回答令牌的重要性，并且仅关注文本模态而忽略了视觉线索的作用。这些方法无法有效保护隐私。", "method": "提出了一种新的正则化方法ViKeR，利用不相关的视觉输入预测理想的后遗忘令牌分布，并通过信息熵定义关键令牌来指导遗忘过程。", "result": "实验表明该方法能够有效地执行遗忘操作，同时减少了忘记风险并保持回答的一致性。", "conclusion": "通过引入ViKeR，可以显著提高多模态大语言模型的隐私保护能力。"}}
{"id": "2601.22018", "pdf": "https://arxiv.org/pdf/2601.22018", "abs": "https://arxiv.org/abs/2601.22018", "authors": ["Jinhao Zhang", "Zhexuan Zhou", "Huizhe Li", "Yichen Lai", "Wenlong Xia", "Haoming Song", "Youmin Gong", "Jie Me"], "title": "PocketDP3: Efficient Pocket-Scale 3D Visuomotor Policy", "categories": ["cs.RO"], "comment": null, "summary": "Recently, 3D vision-based diffusion policies have shown strong capability in learning complex robotic manipulation skills. However, a common architectural mismatch exists in these models: a tiny yet efficient point-cloud encoder is often paired with a massive decoder. Given a compact scene representation, we argue that this may lead to substantial parameter waste in the decoder. Motivated by this observation, we propose PocketDP3, a pocket-scale 3D diffusion policy that replaces the heavy conditional U-Net decoder used in prior methods with a lightweight Diffusion Mixer (DiM) built on MLP-Mixer blocks. This architecture enables efficient fusion across temporal and channel dimensions, significantly reducing model size. Notably, without any additional consistency distillation techniques, our method supports two-step inference without sacrificing performance, improving practicality for real-time deployment. Across three simulation benchmarks--RoboTwin2.0, Adroit, and MetaWorld--PocketDP3 achieves state-of-the-art performance with fewer than 1% of the parameters of prior methods, while also accelerating inference. Real-world experiments further demonstrate the practicality and transferability of our method in real-world settings. Code will be released.", "AI": {"tldr": "提出了PocketDP3，一种基于轻量级MLP-Mixer块的高效三维扩散策略，以解决现有模型中点云编码器与解码器不匹配的问题。", "motivation": "现有3D视觉基础扩散政策中存在架构上的不匹配：小型高效的点云编码器通常与庞大的解码器配对。鉴于此，作者提出了PocketDP3来减少参数浪费并提高效率。", "method": "通过采用轻量级的Diffusion Mixer (DiM)，基于MLP-Mixer块替代了先前方法中使用的重型条件U-Net解码器，实现了高效的时空融合，并支持无额外一致性蒸馏技术的两步推理。", "result": "在三个模拟基准测试（RoboTwin2.0、Adroit和MetaWorld）上，PocketDP3达到了最先进的性能，参数数量少于先前方法的1%，同时加速了推断。实现实验进一步证明了该方法在实际场景中的实用性和可迁移性。", "conclusion": "通过使用轻量级架构替代传统解码器，实现了高效、快速且高性能的三维扩散策略PocketDP3。"}}
{"id": "2601.22013", "pdf": "https://arxiv.org/pdf/2601.22013", "abs": "https://arxiv.org/abs/2601.22013", "authors": ["Catherine Yeh", "Anh Truong", "Mira Dontcheva", "Bryan Wang"], "title": "Vidmento: Creating Video Stories Through Context-Aware Expansion With Generative Video", "categories": ["cs.HC", "cs.AI", "cs.MM"], "comment": "25 pages, 18 figures", "summary": "Video storytelling is often constrained by available material, limiting creative expression and leaving undesired narrative gaps. Generative video offers a new way to address these limitations by augmenting captured media with tailored visuals. To explore this potential, we interviewed eight video creators to identify opportunities and challenges in integrating generative video into their workflows. Building on these insights and established filmmaking principles, we developed Vidmento, a tool for authoring hybrid video stories that combine captured and generated media through context-aware expansion. Vidmento surfaces opportunities for story development, generates clips that blend stylistically and narratively with surrounding media, and provides controls for refinement. In a study with 12 creators, Vidmento supported narrative development and exploration by systematically expanding initial materials with generative media, enabling expressive video storytelling aligned with creative intent. We highlight how creators bridge story gaps with generative content and where they find this blending capability most valuable.", "AI": {"tldr": "Vidmento是一款通过上下文感知扩展实现视频故事创作的工具。", "motivation": "视频创作者受限于可用材料，这限制了他们的创造性表达，并留下了叙事缺口。作者希望通过生成视频来解决这一问题，以增强捕捉到的媒体内容。", "method": "通过采访八位视频制作者并结合电影制作原则开发了Vidmento工具，该工具支持混合视频故事创作，将捕获和生成的内容结合起来进行上下文感知扩展。", "result": "在12名创作者的研究中，Vidmento支持叙事发展与探索，并能够通过系统地用生成媒体拓展初始材料来实现符合创意意图的表达性视频叙述。", "conclusion": "研究揭示了创作者如何使用生成内容填补故事缺口以及他们认为这种混合能力最有价值的地方。"}}
{"id": "2601.22009", "pdf": "https://arxiv.org/pdf/2601.22009", "abs": "https://arxiv.org/abs/2601.22009", "authors": ["Anand Babu", "Rogério Almeida Gouvêa", "Pierre Vandergheynst", "Gian-Marco Rignanese"], "title": "MEIDNet: Multimodal generative AI framework for inverse materials design", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "In this work, we present Multimodal Equivariant Inverse Design Network (MEIDNet), a framework that jointly learns structural information and materials properties through contrastive learning, while encoding structures via an equivariant graph neural network (EGNN). By combining generative inverse design with multimodal learning, our approach accelerates the exploration of chemical-structural space and facilitates the discovery of materials that satisfy predefined property targets. MEIDNet exhibits strong latent-space alignment with cosine similarity 0.96 by fusion of three modalities through cross-modal learning. Through implementation of curriculum learning strategies, MEIDNet achieves ~60 times higher learning efficiency than conventional training techniques. The potential of our multimodal approach is demonstrated by generating low-bandgap perovskite structures at a stable, unique, and novel (SUN) rate of 13.6 %, which are further validated by ab initio methods. Our inverse design framework demonstrates both scalability and adaptability, paving the way for the universal learning of chemical space across diverse modalities.", "AI": {"tldr": "本文提出了MEIDNet框架，该框架通过对比学习和等变图神经网络编码结构信息及材料属性，并结合生成逆向设计与多模态学习以加速化学-结构空间的探索。", "motivation": "研究旨在开发一种可以加速新材料发现的方法，通过联合学习结构信息和材料性质来提高探索效率。", "method": "MEIDNet框架利用对比学习技术并采用等变图神经网络编码结构信息。结合生成逆向设计与多模态学习策略，同时实施课程学习方法以提升学习效率。", "result": "实验表明，该方法能够有效地发现满足预定义属性目标的新材料，并展示了在低带隙钙钛矿结构生成中的应用效果，准确率达到了13.6%。此外，在与其他传统训练技术相比时，其学习效率提升了约60倍。", "conclusion": "MEIDNet框架具有扩展性和适应性，能够实现化学空间的通用学习并推动多模态研究的发展"}}
{"id": "2601.22001", "pdf": "https://arxiv.org/pdf/2601.22001", "abs": "https://arxiv.org/abs/2601.22001", "authors": ["Yiren Zhao", "Junyi Liu"], "title": "Heterogeneous Computing: The Key to Powering the Future of AI Agent Inference", "categories": ["cs.AI", "cs.AR", "cs.DC"], "comment": null, "summary": "AI agent inference is driving an inference heavy datacenter future and exposes bottlenecks beyond compute - especially memory capacity, memory bandwidth and high-speed interconnect. We introduce two metrics - Operational Intensity (OI) and Capacity Footprint (CF) - that jointly explain regimes the classic roofline analysis misses, including the memory capacity wall. Across agentic workflows (chat, coding, web use, computer use) and base model choices (GQA/MLA, MoE, quantization), OI/CF can shift dramatically, with long context KV cache making decode highly memory bound. These observations motivate disaggregated serving and system level heterogeneity: specialized prefill and decode accelerators, broader scale up networking, and decoupled compute-memory enabled by optical I/O. We further hypothesize agent-hardware co design, multiple inference accelerators within one system, and high bandwidth, large capacity memory disaggregation as foundations for adaptation to evolving OI/CF. Together, these directions chart a path to sustain efficiency and capability for large scale agentic AI inference.", "AI": {"tldr": "本文介绍了通过异构计算解决大规模AI代理推理中的内存瓶颈问题。", "motivation": "随着AI代理推理的发展，传统的计算性能指标无法完全解释新的挑战，如内存容量和带宽限制。这促使研究者引入了操作强度（OI）和容量足迹（CF）两个新度量标准以更好地理解和解决这些瓶颈问题。", "method": "文中提出了一种基于异构系统的解决方案，包括专用的预填充和解码加速器、更广泛的网络扩展以及通过光通信实现计算与内存分离的技术。此外，还讨论了AI代理硬件协同设计的方向，并建议在一个系统中使用多个推理加速器，以适应不断变化的操作强度和容量足迹。", "result": "本文提出的异构方法为解决大规模AI代理推理中的性能瓶颈提供了可能的解决方案，从而提升了系统的效率与能力。", "conclusion": "通过引入新的度量标准并提出异构计算的方法，可以有效地应对未来AI代理推理中出现的新挑战，并提高系统在大范围内的可扩展性和适应性。"}}
{"id": "2601.21998", "pdf": "https://arxiv.org/pdf/2601.21998", "abs": "https://arxiv.org/abs/2601.21998", "authors": ["Lin Li", "Qihang Zhang", "Yiming Luo", "Shuai Yang", "Ruilin Wang", "Fei Han", "Mingrui Yu", "Zelin Gao", "Nan Xue", "Xing Zhu", "Yujun Shen", "Yinghao Xu"], "title": "Causal World Modeling for Robot Control", "categories": ["cs.CV", "cs.RO"], "comment": "Project page: https://technology.robbyant.com/lingbot-va Code: https://github.com/robbyant/lingbot-va", "summary": "This work highlights that video world modeling, alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space, integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism, allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline, parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation, data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.", "AI": {"tldr": "本文介绍了一种新的机器人控制框架LingBot-VA，该框架通过视频世界模型理解和学习动作与视觉动态之间的因果关系，实现帧预测和策略执行的同步。", "motivation": "传统的机器人学习依赖于视频世界建模和视觉语言预训练。然而，这些方法没有充分利用视频中的因果信息来想象未来状态，并且缺乏有效的闭环反馈机制以提高控制性能。", "method": "LingBot-VA采用了一种自回归扩散框架，包括三个设计：共享潜在空间、闭环轮询机制和异步推理管道，通过整合视觉和动作令牌，利用Mixture-of-Transformers（MoT）架构进行帧预测和策略执行的同步学习。", "result": "在仿真基准和现实世界场景中，LingBot-VA显示出在长时间操纵任务中的显著潜力，在后训练数据效率方面表现出色，并且能够很好地推广到新配置。", "conclusion": "提出的视频世界模型框架为机器人控制提供了一种新的独立基础。通过整合因果推理、闭环反馈以及并行执行的能力，该方法显示了对未来机器人学习的潜在影响。"}}
{"id": "2601.21996", "pdf": "https://arxiv.org/pdf/2601.21996", "abs": "https://arxiv.org/abs/2601.21996", "authors": ["Jianhui Chen", "Yuzhang Luo", "Liangming Pan"], "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.", "AI": {"tldr": "介绍了一种可扩展的框架Mechanistic Data Attribution (MDA)，该框架通过影响函数追踪大规模语言模型中解释性组件的训练数据源头。", "motivation": "虽然机械解释性已识别出LLM中的解释性电路，但其在训练数据中的因果起源仍然难以捉摸。此研究旨在揭示这些解释性单位的具体训练样本来源，并探索它们与模型能力之间的关系。", "method": "采用影响函数对Pythia家族的模型进行实验，通过移除或增加具有高影响力的特定训练样本来验证可解释单元出现的因果关系，并观察这种操作对模型在上下文学习中的影响。", "result": "揭示了重复结构数据（如LaTeX、XML）是促进可解释头形成的关键因素；针对诱导头形成的干预同时改变了模型的上下文学习能力，为长期假设提供了直接证据。此外，提出了一种机械性数据增强管道以加速电路收敛，并在不同规模模型中显示其有效性。", "conclusion": "Mechanistic Data Attribution框架不仅揭示了大规模语言模型中可解释单位的具体训练数据来源，还通过因果验证支持了关于诱导头与上下文学习之间功能联系的假设。"}}
{"id": "2601.21993", "pdf": "https://arxiv.org/pdf/2601.21993", "abs": "https://arxiv.org/abs/2601.21993", "authors": ["Dhiogo de Sá", "Carlos Schmiedel", "Carlos Pereira Lopes"], "title": "Liquid Interfaces: A Dynamic Ontology for the Interoperability of Autonomous Systems", "categories": ["cs.AI", "cs.SE"], "comment": "28 pages, 2 figures", "summary": "Contemporary software architectures struggle to support autonomous agents whose reasoning is adaptive, probabilistic, and context-dependent, while system integration remains dominated by static interfaces and deterministic contracts. This paper introduces Liquid Interfaces, a coordination paradigm in which interfaces are not persistent technical artifacts, but ephemeral relational events that emerge through intention articulation and semantic negotiation at runtime.We formalize this model and present the Liquid Interface Protocol (LIP),which governs intention-driven interaction, negotiated execution, and enforce ephemerality under semantic uncertainty. We further discuss the governance implications of this approach and describe a reference architecture that demonstrates practical feasibility. Liquid Interfaces provide a principled foundation for adaptive coordination in agent-based systems", "AI": {"tldr": "介绍液体接口概念及其协议，以支持自主代理系统的适应性协调。", "motivation": "现有的软件架构难以处理自适应、概率性和上下文依赖性的推理，而系统集成主要依靠静态接口和确定性合同。需要一种新的方法来解决这些问题。", "method": "提出了一个动态的协调范式——液体接口，并引入了液体接口协议(LIP)，该协议通过意图驱动交互、协商执行以及在语义不确定性下维持临时性来管理意图表达和语义谈判。", "result": "提供了一个可行性的参考架构，展示了液体接口的概念应用于自主代理系统的实际可行性。", "conclusion": "液体接口为自适应协调提供了原则基础，有助于解决现有软件体系结构的问题，并促进自治系统之间的互操作性。"}}
{"id": "2601.21991", "pdf": "https://arxiv.org/pdf/2601.21991", "abs": "https://arxiv.org/abs/2601.21991", "authors": ["Zuyuan Zhang", "Mahdi Imani", "Tian Lan"], "title": "Geometry of Drifting MDPs with Path-Integral Stability Certificates", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world reinforcement learning is often \\emph{nonstationary}: rewards and dynamics drift, accelerate, oscillate, and trigger abrupt switches in the optimal action. Existing theory often represents nonstationarity with coarse-scale models that measure \\emph{how much} the environment changes, not \\emph{how} it changes locally -- even though acceleration and near-ties drive tracking error and policy chattering. We take a geometric view of nonstationary discounted Markov Decision Processes (MDPs) by modeling the environment as a differentiable homotopy path and tracking the induced motion of the optimal Bellman fixed point. This yields a length-curvature-kink signature of intrinsic complexity: cumulative drift, acceleration/oscillation, and action-gap-induced nonsmoothness. We prove a solver-agnostic path-integral stability bound and derive gap-safe feasible regions that certify local stability away from switch regimes. Building on these results, we introduce \\textit{Homotopy-Tracking RL (HT-RL)} and \\textit{HT-MCTS}, lightweight wrappers that estimate replay-based proxies of length, curvature, and near-tie proximity online and adapt learning or planning intensity accordingly. Experiments show improved tracking and dynamic regret over matched static baselines, with the largest gains in oscillatory and switch-prone regimes.", "AI": {"tldr": "本文提出了通过几何视角研究非稳态马尔可夫决策过程（MDPs）的新方法，包括路径积分稳定性界限和轻量级的同伦跟踪强化学习算法。", "motivation": "在现实世界的强化学习中，环境往往是非稳态的：奖励和动态会漂移、加速、振荡并触发最优动作的突然切换。现有的理论通常使用粗粒度模型来表示这些变化的程度而不是它们的变化方式。", "method": "通过将环境建模为可微同伦路径，并追踪由此产生的贝尔曼不动点运动，提出了长度-曲率-转折点签名以表征内在复杂性：累积漂移、加速/振荡和动作间隙引起的非光滑度。基于这些结果，引入了Homotopy-Tracking RL（HT-RL）和HT-MCTS等算法。", "result": "实验表明，在振荡和切换频繁的场景中，该方法相比静态基线有显著改进。", "conclusion": "通过几何视角研究非稳态MDPs可以更好地理解和处理环境的变化方式，从而提高强化学习在动态环境中的适应性和性能。"}}
{"id": "2601.21989", "pdf": "https://arxiv.org/pdf/2601.21989", "abs": "https://arxiv.org/abs/2601.21989", "authors": ["Edith Cohen", "Elena Gribelyuk", "Jelani Nelson", "Uri Stemmer"], "title": "Adaptively Robust Resettable Streaming", "categories": ["cs.DS"], "comment": null, "summary": "We study algorithms in the resettable streaming model, where the value of each key can either be increased or reset to zero. The model is suitable for applications such as active resource monitoring with support for deletions and machine unlearning. We show that all existing sketches for this model are vulnerable to adaptive adversarial attacks that apply even when the sketch size is polynomial in the length of the stream. To overcome these vulnerabilities, we present the first adaptively robust sketches for resettable streams that maintain polylogarithmic space complexity in the stream length. Our framework supports (sub) linear statistics including $L_p$ moments for $p\\in[0,1]$ (in particular, Cardinality and Sum) and Bernstein statistics. We bypass strong impossibility results known for linear and composable sketches by designing dedicated streaming sketches robustified via Differential Privacy. Unlike standard robustification techniques, which provide limited benefits in this setting and still require polynomial space in the stream length, we leverage the Binary Tree Mechanism for continual observation to protect the sketch's internal randomness. This enables accurate prefix-max error guarantees with polylogarithmic space.", "AI": {"tldr": "研究了重置流模型中的算法，提出了针对适应性攻击的鲁棒性算法，保持多项式空间复杂度。", "motivation": "现有的流处理算法在面对适应性攻击时容易受到威胁，特别是在流长度为多项式大小的情况下。本文旨在设计一种既具有鲁棒性又能在重置流模型中维持低空间复杂度的算法。", "method": "通过使用差异隐私技术来保护内部随机性的方法，设计了一种适用于重置流模型的适应性攻击鲁棒性算法。该方法基于二叉树机制，实现了对前缀最大误差保证的准确控制。", "result": "提出了能够在多项式空间复杂度内运行并具有适应性鲁棒性的流处理算法框架，支持包括$L_p$矩和伯恩斯坦统计在内的子线性统计信息。", "conclusion": "通过引入差异隐私保护技术设计了新的重置流模型下适配攻击的鲁棒性算法，在保持低空间复杂度的同时提供了准确且高效的前缀最大误差保证。"}}
{"id": "2601.21988", "pdf": "https://arxiv.org/pdf/2601.21988", "abs": "https://arxiv.org/abs/2601.21988", "authors": ["Fernando Palafox", "Jingqi Li", "Jesse Milzman", "David Fridovich-Keil"], "title": "Generalized Information Gathering Under Dynamics Uncertainty", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.RO", "eess.SY"], "comment": null, "summary": "An agent operating in an unknown dynamical system must learn its dynamics from observations. Active information gathering accelerates this learning, but existing methods derive bespoke costs for specific modeling choices: dynamics models, belief update procedures, observation models, and planners. We present a unifying framework that decouples these choices from the information-gathering cost by explicitly exposing the causal dependencies between parameters, beliefs, and controls. Using this framework, we derive a general information-gathering cost based on Massey's directed information that assumes only Markov dynamics with additive noise and is otherwise agnostic to modeling choices. We prove that the mutual information cost used in existing literature is a special case of our cost. Then, we leverage our framework to establish an explicit connection between the mutual information cost and information gain in linearized Bayesian estimation, thereby providing theoretical justification for mutual information-based active learning approaches. Finally, we illustrate the practical utility of our framework through experiments spanning linear, nonlinear, and multi-agent systems.", "AI": {"tldr": "提出了一个统一的信息采集框架，以加速代理在未知动态系统中学习其动力学过程。", "motivation": "现有的信息采集方法针对特定的模型选择定制了成本函数，缺乏通用性。该研究旨在建立一种与具体建模选择无关的泛化信息获取框架。", "method": "通过明确展示参数、信念和控制之间的因果依赖关系，基于Massey的有向信息推导出了一种通用的信息采集成本，并证明了现有文献中使用的互信息成本是其特殊情况。此外，该研究建立了互信息成本与线性贝叶斯估计中的信息增益之间的确切联系。", "result": "实验结果表明，所提出的框架在处理线性和非线性系统以及多智能体系统时具有实用价值。", "conclusion": "通过提出一种通用的信息获取框架，该研究证明了其理论上的合理性和实际应用的有效性。"}}
{"id": "2601.21981", "pdf": "https://arxiv.org/pdf/2601.21981", "abs": "https://arxiv.org/abs/2601.21981", "authors": ["Geonhee Jo", "Mingu Kang", "Kangmin Lee", "Minho Lee", "Pascal Bauer", "Sang-Ki Ko"], "title": "VERSA: Verified Event Data Format for Reliable Soccer Analytics", "categories": ["cs.AI", "cs.DB"], "comment": "13 pages, 5 figures, 3 tables", "summary": "Event stream data is a critical resource for fine-grained analysis across various domains, including financial transactions, system operations, and sports. In sports, it is actively used for fine-grained analyses such as quantifying player contributions and identifying tactical patterns. However, the reliability of these models is fundamentally limited by inherent data quality issues that cause logical inconsistencies (e.g., incorrect event ordering or missing events). To this end, this study proposes VERSA (Verified Event Data Format for Reliable Soccer Analytics), a systematic verification framework that ensures the integrity of event stream data within the soccer domain. VERSA is based on a state-transition model that defines valid event sequences, thereby enabling the automatic detection and correction of anomalous patterns within the event stream data. Notably, our examination of event data from the K League 1 (2024 season), provided by Bepro, detected that 18.81% of all recorded events exhibited logical inconsistencies. Addressing such integrity issues, our experiments demonstrate that VERSA significantly enhances cross-provider consistency, ensuring stable and unified data representation across heterogeneous sources. Furthermore, we demonstrate that data refined by VERSA significantly improves the robustness and performance of a downstream task called VAEP, which evaluates player contributions. These results highlight that the verification process is highly effective in increasing the reliability of data-driven analysis.", "AI": {"tldr": "VERSA 提出了一种系统验证框架，确保足球赛事中的事件流数据的完整性。", "motivation": "当前足球分析模型受限于数据质量问题，导致逻辑不一致（如错误的时间顺序或缺失事件）。为了提高这些模型的可靠性，本文提出了 VERSA 系统来解决这些问题。", "method": "VERSA 基于状态转换模型定义有效的事件序列，自动检测和纠正事件流中的异常模式。通过此框架可以增强跨供应商数据的一致性，并提升下游任务 VAEP 的性能。", "result": "通过对 K 联赛的数据进行测试，发现有18.81%的记录存在逻辑不一致。VERSA 在提高数据稳定性和统一性方面表现出色，并且增强了下游任务 VAEP 的性能。", "conclusion": "验证过程可以显著提升基于数据驱动分析的可靠性，VERSA 是一个有效的解决方案以确保事件流数据的完整性。"}}
{"id": "2601.21977", "pdf": "https://arxiv.org/pdf/2601.21977", "abs": "https://arxiv.org/abs/2601.21977", "authors": ["Javier Argota Sánchez-Vaquerizo", "Luis Borunda Monsivais"], "title": "From Particles to Agents: Hallucination as a Metric for Cognitive Friction in Spatial Simulation", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "Paper selected for the workshop Human Cognition, AI, and the Future of HCI: Navigating the Disruptive and Wild Landscape of Large Language Models and Agentic AI as part of the Human-Computer Interaction (HCI) conference of the Alpine region (AlpCHI 2026) hosted at the Congressi Stefano Franscini, March 1st to March 5th, 2026 on Monte Verità in Ascona, Switzerland", "summary": "Traditional architectural simulations (e.g. Computational Fluid Dynamics, evacuation, structural analysis) model elements as deterministic physics-based \"particles\" rather than cognitive \"agents\". To bridge this, we introduce \\textbf{Agentic Environmental Simulations}, where Large Multimodal generative models actively predict the next state of spatial environments based on semantic expectation. Drawing on examples from accessibility-oriented AR pipelines and multimodal digital twins, we propose a shift from chronological time-steps to Episodic Spatial Reasoning, where simulations advance through meaningful, surprisal-triggered events. Within this framework we posit AI hallucinations as diagnostic tools. By formalizing the \\textbf{Cognitive Friction} ($C_f$) it is possible to reveal \"Phantom Affordances\", i.e. semiotic ambiguities in built space. Finally, we challenge current HCI paradigms by treating environments as dynamic cognitive partners and propose a human-centered framework of cognitive orchestration for designing AI-driven simulations that preserve autonomy, affective clarity, and cognitive integrity.", "AI": {"tldr": "本文提出了一种新的空间仿真方法，即阿吉尼亚环境模拟，通过大型多模态生成模型预测空间环境的下一个状态，并将其视为认知摩擦和幻影行为诊断工具。", "motivation": "传统的建筑仿真（如计算流体动力学、疏散模拟、结构分析）将元素建模为基于确定性物理法则的“粒子”，而非认知上的“代理”。本文旨在通过引入阿吉尼亚环境模拟，解决这一问题，并提出一种新的仿真框架以更好地理解和设计空间。", "method": "利用大型多模态生成模型预测空间环境的状态变化；采用事件驱动的方法推进仿真进程；将AI幻觉作为认知摩擦诊断工具；正式定义了“认知摩擦”指标来揭示空间中的语义模糊性。", "result": "通过新的框架，可以更好地识别和理解空间设计中存在的问题，并提出改善建议以提高用户体验和环境的认知友好度。", "conclusion": "本文提出的阿吉尼亚环境模拟方法为建筑仿真提供了一种全新的视角，强调将环境视为动态认知伙伴的重要性，并倡导以人为中心的设计理念。"}}
{"id": "2601.21976", "pdf": "https://arxiv.org/pdf/2601.21976", "abs": "https://arxiv.org/abs/2601.21976", "authors": ["Alex S. Miller", "Leo McElroy", "Jeffrey H. Lang"], "title": "Macro-Scale Electrostatic Origami Motor", "categories": ["cs.RO", "physics.app-ph"], "comment": null, "summary": "Foldable robots have been an active area of robotics research due to their high volume-to-mass ratio, easy packability, and shape adaptability. For locomotion, previously developed foldable robots have either embedded linear actuators in, or attached non-folding rotary motors to, their structure. Further, those actuators directly embedded in the structure of the folding medium all contributed to linear or folding motion, not to continuous rotary motion. On the macro-scale there has not yet been a folding continuous rotary actuator. This paper details the development and testing of the first macro-scale origami rotary motor that can be folded flat, and then unfurled to operate. Using corona discharge for torque production, the prototype motor achieved an expansion ratio of 2.5:1, reached a top speed of 1440 rpm when driven at -29 kV, and exhibited a maximum output torque over 0.15 mN m with an active component torque density of 0.04 Nm/kg.", "AI": {"tldr": "开发并测试了首个可以在折叠后展开工作的宏尺度折纸连续旋转电机。", "motivation": "当前可变形机器人的现有驱动器不能提供持续的旋转运动，特别是在宏观尺度上尚未有可以折叠的连续旋转执行器。", "method": "使用电晕放电产生扭矩，设计并制造了一种新的宏观规模折纸旋转电机原型。", "result": "该原型机实现了2.5:1的扩张比，以-29kV驱动时最高转速达到1440rpm，并显示出超过0.15mNm的最大输出扭矩和每千克0.04Nm的主动部件扭矩密度。", "conclusion": "成功设计并验证了一种可以在折叠状态下保持紧凑且能够展开工作的宏观尺度折纸连续旋转执行器。"}}
{"id": "2601.21975", "pdf": "https://arxiv.org/pdf/2601.21975", "abs": "https://arxiv.org/abs/2601.21975", "authors": ["Pranav Mahajan", "Ihor Kendiukhov", "Syed Hussain", "Lydia Nottingham"], "title": "Mind the Gap: How Elicitation Protocols Shape the Stated-Revealed Preference Gap in Language Models", "categories": ["cs.AI", "cs.ET"], "comment": null, "summary": "Recent work identifies a stated-revealed (SvR) preference gap in language models (LMs): a mismatch between the values models endorse and the choices they make in context. Existing evaluations rely heavily on binary forced-choice prompting, which entangles genuine preferences with artifacts of the elicitation protocol. We systematically study how elicitation protocols affect SvR correlation across 24 LMs. Allowing neutrality and abstention during stated preference elicitation allows us to exclude weak signals, substantially improving Spearman's rank correlation ($ρ$) between volunteered stated preferences and forced-choice revealed preferences. However, further allowing abstention in revealed preferences drives $ρ$ to near-zero or negative values due to high neutrality rates. Finally, we find that system prompt steering using stated preferences during revealed preference elicitation does not reliably improve SvR correlation on AIRiskDilemmas. Together, our results show that SvR correlation is highly protocol-dependent and that preference elicitation requires methods that account for indeterminate preferences.", "AI": {"tldr": "研究探讨了语言模型中的声明偏好与揭示偏好之间的差距，并系统地分析了不同激励协议对这种差距的影响。", "motivation": "现有评估方法在进行二进制强制选择提示时，难以区分真实偏好和激励协议的副作用。为了更准确地理解这一差距，需要一种能排除弱信号的方法。", "method": "研究通过允许中立与拒绝来改进声明偏好的获取，并进一步探讨了揭示偏好中的中立策略对SvR相关性的影响。此外，还使用了基于声明偏好的系统提示引导技术。", "result": "研究表明，SvR的相关性高度依赖于激励协议的选择；在排除弱信号后，Spearman等级相关系数（ρ）有所改善，但引入更多的中立选项会导致ρ下降或为负值。同时发现基于声明偏好进行系统提示引导并不能可靠地提升SvR相关性。", "conclusion": "研究揭示了语言模型中的声明偏好与揭示偏好之间的差距具有高度的协议依赖性，并强调在评估时必须考虑不确定偏好的处理方法。"}}
{"id": "2601.21972", "pdf": "https://arxiv.org/pdf/2601.21972", "abs": "https://arxiv.org/abs/2601.21972", "authors": ["Shuo Liu", "Tianle Chen", "Ryan Amiri", "Christopher Amato"], "title": "Learning Decentralized LLM Collaboration with Multi-Agent Actor Critic", "categories": ["cs.AI", "cs.DC", "cs.MA"], "comment": null, "summary": "Recent work has explored optimizing LLM collaboration through Multi-Agent Reinforcement Learning (MARL). However, most MARL fine-tuning approaches rely on predefined execution protocols, which often require centralized execution. Decentralized LLM collaboration is more appealing in practice, as agents can run inference in parallel with flexible deployments. Also, current approaches use Monte Carlo methods for fine-tuning, which suffer from high variance and thus require more samples to train effectively. Actor-critic methods are prevalent in MARL for dealing with these issues, so we developed Multi-Agent Actor-Critic (MAAC) methods to optimize decentralized LLM collaboration. In this paper, we analyze when and why these MAAC methods are beneficial. We propose 2 MAAC approaches, \\textbf{CoLLM-CC} with a \\textbf{C}entralized \\textbf{C}ritic and \\textbf{CoLLM-DC} with \\textbf{D}ecentralized \\textbf{C}ritics. Our experiments across writing, coding, and game-playing domains show that Monte Carlo methods and CoLLM-DC can achieve performance comparable to CoLLM-CC in short-horizon and dense-reward settings. However, they both underperform CoLLM-CC on long-horizon or sparse-reward tasks, where Monte Carlo methods require substantially more samples and CoLLM-DC struggles to converge. Our code is available at https://github.com/OpenMLRL/CoMLRL/releases/tag/v1.3.2.", "AI": {"tldr": "本文研究了通过多智能体演员批评方法优化LLM（大型语言模型）的去中心化协作。", "motivation": "现有的MARL方法依赖于预定义的执行协议，通常需要集中式执行。此外，当前使用蒙特卡罗方法进行微调存在高方差问题，因此训练效率较低。本文旨在通过开发多智能体演员批评（MAAC）方法来解决这些问题。", "method": "提出两种MAAC方法：CoLLM-CC和CoLLM-DC，其中CoLLM-CC使用集中式评论者，而CoLLM-DC则使用去中心化评论者。这些方法旨在优化去中心化的LLM协作。", "result": "实验结果表明，在短时间范围和密集奖励设置中，Monte Carlo方法和CoLLM-DC可以实现与CoLLM-CC相当的性能；然而在长时间范围或稀疏奖励任务上，则表现较差。此外，蒙特卡罗方法需要更多的样本进行训练，而CoLLM-DC难以收敛。", "conclusion": "本文展示了MAAC方法在优化去中心化LLM协作中的潜在优势，并指出Monte Carlo和CoLLM-DC存在局限性，在特定条件下性能不如CoLLM-CC。"}}
{"id": "2601.21971", "pdf": "https://arxiv.org/pdf/2601.21971", "abs": "https://arxiv.org/abs/2601.21971", "authors": ["Lorenzo Mazza", "Ariel Rodriguez", "Rayan Younis", "Martin Lelis", "Ortrun Hellig", "Chenpan Li", "Sebastian Bodenstedt", "Martin Wagner", "Stefanie Speidel"], "title": "MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Imitation learning has achieved remarkable success in robotic manipulation, yet its application to surgical robotics remains challenging due to data scarcity, constrained workspaces, and the need for an exceptional level of safety and predictability. We present a supervised Mixture-of-Experts (MoE) architecture designed for phase-structured surgical manipulation tasks, which can be added on top of any autonomous policy. Unlike prior surgical robot learning approaches that rely on multi-camera setups or thousands of demonstrations, we show that a lightweight action decoder policy like Action Chunking Transformer (ACT) can learn complex, long-horizon manipulation from less than 150 demonstrations using solely stereo endoscopic images, when equipped with our architecture. We evaluate our approach on the collaborative surgical task of bowel grasping and retraction, where a robot assistant interprets visual cues from a human surgeon, executes targeted grasping on deformable tissue, and performs sustained retraction. We benchmark our method against state-of-the-art Vision-Language-Action (VLA) models and the standard ACT baseline. Our results show that generalist VLAs fail to acquire the task entirely, even under standard in-distribution conditions. Furthermore, while standard ACT achieves moderate success in-distribution, adopting a supervised MoE architecture significantly boosts its performance, yielding higher success rates in-distribution and demonstrating superior robustness in out-of-distribution scenarios, including novel grasp locations, reduced illumination, and partial occlusions. Notably, it generalizes to unseen testing viewpoints and also transfers zero-shot to ex vivo porcine tissue without additional training, offering a promising pathway toward in vivo deployment. To support this, we present qualitative preliminary results of policy roll-outs during in vivo porcine surgery.", "AI": {"tldr": "通过监督Mixture-of-Experts（MoE）架构改进手术模仿学习策略。", "motivation": "手术机器人中的模仿学习面临着数据稀少、工作空间受限以及对安全性和可预测性的高度要求等挑战。现有方法依赖于多摄像头设置或数千次演示，而本研究旨在减少这些需求并提高复杂任务的学习效率。", "method": "提出了一种监督Mixture-of-Experts架构，在手术模仿学习中使用轻量级动作解码策略Action Chunking Transformer (ACT)。该架构可以添加到任何自主政策之上，并从少于150次演示和仅用立体内窥镜图像的情况下，执行复杂的长时间操作任务。", "result": "在肠抓取和牵拉任务中，与最先进的Vision-Language-Action模型和标准ACT基线相比，采用监督MoE架构显著提高了性能，在分布内和分布外场景中的成功率更高，并且对新的抓取位置、照明减少和部分遮挡表现出更强的鲁棒性。该策略在未见测试视角下具有泛化能力，并零样本转移到离体猪组织上而无需额外训练，显示出向体内部署的潜在途径。", "conclusion": "通过利用监督Mixture-of-Experts架构，可以有效改进手术模仿学习中的动作解码策略ACT，提高其对复杂任务的学习效率和鲁棒性。该方法在多种条件下的表现优于现有模型，并展现出良好的泛化能力和零样本迁移性能，为未来体内应用铺平了道路。"}}
{"id": "2601.21969", "pdf": "https://arxiv.org/pdf/2601.21969", "abs": "https://arxiv.org/abs/2601.21969", "authors": ["Yifan Zhu", "Huiqiang Rong", "Haoran Luo"], "title": "Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding", "categories": ["cs.CL", "cs.AI"], "comment": "26 pages and 11 figures,this work has been accepted for presentation at ICLR 2026", "summary": "Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.", "AI": {"tldr": "Token-Guard是一种基于自检解码的令牌级幻觉控制方法，通过在每个推理步骤中进行内部验证来检测并防止生成错误信息。", "motivation": "大语言模型（LLM）容易产生与输入不一致的内容。尽管检索增强生成（RAG）和强化学习与人类反馈（RLHF）可以减轻这种问题，但它们需要资源密集型的检索或大规模微调。解码方法较轻量级，但缺乏明确的幻觉控制机制。因此提出Token-Guard以解决此问题。", "method": "Token-Guard在每个推理步骤中执行内部验证来检测幻觉令牌，并在它们传播之前将其消除。候选片段进一步在一个潜空间进行评估并计算其具体的风险评分；通过迭代剪枝和再生动态纠正已发现的错误。", "result": "实验表明，Token-Guard显著减少了HALU数据集上的幻觉现象，提高了生成准确度，提供了可靠的大规模语言模型输出。", "conclusion": "Token-Guard提出了一种基于令牌级幻觉控制的方法，并且在各种任务中展现了强大的性能和可扩展性。"}}
{"id": "2601.21967", "pdf": "https://arxiv.org/pdf/2601.21967", "abs": "https://arxiv.org/abs/2601.21967", "authors": ["Ilche Georgievski", "Serhat Tekin", "Marco Aiello"], "title": "The Energy Impact of Domain Model Design in Classical Planning", "categories": ["cs.AI", "cs.SE"], "comment": "2026 IEEE/ACM 5th International Conference on AI Engineering - Software Engineering for AI (CAIN '26)", "summary": "AI research has traditionally prioritised algorithmic performance, such as optimising accuracy in machine learning or runtime in automated planning. The emerging paradigm of Green AI challenges this by recognising energy consumption as a critical performance dimension. Despite the high computational demands of automated planning, its energy efficiency has received little attention. This gap is particularly salient given the modular planning structure, in which domain models are specified independently of algorithms. On the other hand, this separation also enables systematic analysis of energy usage through domain model design. We empirically investigate how domain model characteristics affect the energy consumption of classical planners. We introduce a domain model configuration framework that enables controlled variation of features, such as element ordering, action arity, and dead-end states. Using five benchmark domains and five state-of-the-art planners, we analyse energy and runtime impacts across 32 domain variants per benchmark. Results demonstrate that domain-level modifications produce measurable energy differences across planners, with energy consumption not always correlating with runtime.", "AI": {"tldr": "研究了经典规划中领域模型设计对能耗的影响。", "motivation": "传统AI研究主要关注算法性能，而忽视了计算效率中的能源消耗。本文通过系统分析领域模型设计来探讨自动化规划的能效问题。", "method": "引入了一个领域模型配置框架，该框架能够控制元素排序、动作元数和死胡同状态等特征的变化，使用五个基准领域和五个最先进的规划器进行实验。", "result": "结果表明，领域级别的修改会产生可测量的能量差异，并且能源消耗并不总是与运行时间相关联。", "conclusion": "通过研究领域模型设计对能耗的影响，展示了优化能源效率的可能性。"}}
{"id": "2601.21965", "pdf": "https://arxiv.org/pdf/2601.21965", "abs": "https://arxiv.org/abs/2601.21965", "authors": ["Deeksha M. Shama", "Dimitra Emmanouilidou", "Ivan J. Tashev"], "title": "Cognitive Load Estimation Using Brain Foundation Models and Interpretability for BCIs", "categories": ["cs.HC"], "comment": null, "summary": "Accurately monitoring cognitive load in real time is critical for Brain-Computer Interfaces (BCIs) that adapt to user engagement and support personalized learning. Electroencephalography (EEG) offers a non-invasive, cost-effective modality for capturing neural activity, though traditional methods often struggle with cross-subject variability and task-specific preprocessing. We propose leveraging Brain Foundation Models (BFMs), large pre-trained neural networks, to extract generalizable EEG features for cognitive load estimation. We adapt BFMs for long-term EEG monitoring and show that fine-tuning a small subset of layers yields improved accuracy over the state-of-the-art. Despite their scale, BFMs allow for real-time inference with a longer context window. To address often-overlooked interpretability challenges, we apply Partition SHAP (SHapley Additive exPlanations) to quantify feature importance. Our findings reveal consistent emphasis on prefrontal regions linked to cognitive control, while longitudinal trends suggest learning progression. These results position BFMs as efficient and interpretable tools for continuous cognitive load monitoring in real-world BCIs.", "AI": {"tldr": "利用大脑基础模型和可解释性技术估计认知负荷，以改善脑机接口性能。", "motivation": "实时准确监测认知负荷对于适应用户参与度和支持个性化学习的BCIs至关重要。EEG是一种非侵入性和成本效益高的神经活动捕捉方式，但传统方法在跨主体变异性及任务特定预处理上存在挑战。", "method": "采用大脑基础模型（BFMs）提取通用化的EEG特征以估计认知负荷，并通过调整少量层实现微调，从而提高精度。使用Partition SHAP量化特征重要性，揭示前额区域与认知控制的相关性。", "result": "研究结果表明，细调后的BFMs在认知负荷估测上超越了现有技术水平，并且可以实现实时推断和长期趋势分析。", "conclusion": "这些发现证明了BFMs作为实时连续监测BCIs中认知负荷的高效而可解释工具的地位。"}}
{"id": "2601.21963", "pdf": "https://arxiv.org/pdf/2601.21963", "abs": "https://arxiv.org/abs/2601.21963", "authors": ["Alexander Loth", "Martin Kappes", "Marc-Oliver Pahl"], "title": "Industrialized Deception: The Collateral Effects of LLM-Generated Misinformation on Digital Ecosystems", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.SI"], "comment": "Accepted at ACM TheWebConf '26 Companion", "summary": "Generative AI and misinformation research has evolved since our 2024 survey. This paper presents an updated perspective, transitioning from literature review to practical countermeasures. We report on changes in the threat landscape, including improved AI-generated content through Large Language Models (LLMs) and multimodal systems. Central to this work are our practical contributions: JudgeGPT, a platform for evaluating human perception of AI-generated news, and RogueGPT, a controlled stimulus generation engine for research. Together, these tools form an experimental pipeline for studying how humans perceive and detect AI-generated misinformation. Our findings show that detection capabilities have improved, but the competition between generation and detection continues. We discuss mitigation strategies including LLM-based detection, inoculation approaches, and the dual-use nature of generative AI. This work contributes to research addressing the adverse impacts of AI on information quality.", "AI": {"tldr": "该论文介绍了用于评估人类感知AI生成新闻的平台JudgeGPT和研究用刺激生成引擎RogueGPT，通过实验探讨了人类如何识别AI生成的虚假信息。", "motivation": "为了应对大型语言模型（LLM）和技术进步带来的信息质量下降问题，研究团队开发出新的工具来评估和对抗由AI生成的误导性内容。", "method": "使用JudgeGPT平台和RogueGPT引擎形成一个实验流程，用来研究人类识别AI产生的虚假信息的能力，并探索缓解策略。", "result": "研究表明，人们在检测AI生成的虚假信息方面有所提高，但仍有提升空间。同时提出了包括基于LLM的检测方法、预防措施等对策。", "conclusion": "论文通过实验证明了现有工具和技术的有效性，并强调需要持续研究以应对不断变化的信息环境和挑战。"}}
{"id": "2601.21961", "pdf": "https://arxiv.org/pdf/2601.21961", "abs": "https://arxiv.org/abs/2601.21961", "authors": ["Kuai Yu", "Naicheng Yu", "Han Wang", "Rui Yang", "Huan Zhang"], "title": "How do Visual Attributes Influence Web Agents? A Comprehensive Evaluation of User Interface Design Factors", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Web agents have demonstrated strong performance on a wide range of web-based tasks. However, existing research on the effect of environmental variation has mostly focused on robustness to adversarial attacks, with less attention to agents' preferences in benign scenarios. Although early studies have examined how textual attributes influence agent behavior, a systematic understanding of how visual attributes shape agent decision-making remains limited. To address this, we introduce VAF, a controlled evaluation pipeline for quantifying how webpage Visual Attribute Factors influence web-agent decision-making. Specifically, VAF consists of three stages: (i) variant generation, which ensures the variants share identical semantics as the original item while only differ in visual attributes; (ii) browsing interaction, where agents navigate the page via scrolling and clicking the interested item, mirroring how human users browse online; (iii) validating through both click action and reasoning from agents, which we use the Target Click Rate and Target Mention Rate to jointly evaluate the effect of visual attributes. By quantitatively measuring the decision-making difference between the original and variant, we identify which visual attributes influence agents' behavior most. Extensive experiments, across 8 variant families (48 variants total), 5 real-world websites (including shopping, travel, and news browsing), and 4 representative web agents, show that background color contrast, item size, position, and card clarity have a strong influence on agents' actions, whereas font styling, text color, and item image clarity exhibit minor effects.", "AI": {"tldr": "研究了视觉属性如何影响网络代理的决策。", "motivation": "现有研究主要集中在对抗性攻击对网络代理的影响，而较少关注良性场景中代理的行为偏好。早期研究探讨了文本属性对代理行为的影响，但缺乏系统了解视觉属性如何塑造代理决策的研究。", "method": "提出了VAF评估流程：包括变体生成、浏览互动和验证三个阶段，通过点击率和目标提及率联合评估视觉属性效果。", "result": "实验结果显示背景颜色对比度、项目大小、位置和卡片清晰度对代理行为影响较大，而字体样式、文本颜色和项目图片清晰度影响较小。", "conclusion": "该研究揭示了视觉属性如何系统地影响网络代理的决策，并识别出关键的影响因素。"}}
{"id": "2601.21960", "pdf": "https://arxiv.org/pdf/2601.21960", "abs": "https://arxiv.org/abs/2601.21960", "authors": ["Aref Farhadipour", "Jan Marquenie", "Srikanth Madikeri", "Teodora Vukovic", "Volker Dellwo", "Kathy Reid", "Francis M. Tyers", "Ingo Siegert", "Eleanor Chodroff"], "title": "TidyVoice 2026 Challenge Evaluation Plan", "categories": ["eess.AS", "cs.SD"], "comment": "https://tidyvoice2026.github.io/", "summary": "The performance of speaker verification systems degrades significantly under language mismatch, a critical challenge exacerbated by the field's reliance on English-centric data. To address this, we propose the TidyVoice Challenge for cross-lingual speaker verification. The challenge leverages the TidyVoiceX dataset from the novel TidyVoice benchmark, a large-scale, multilingual corpus derived from Mozilla Common Voice, and specifically curated to isolate the effect of language switching across approximately 40 languages. Participants will be tasked with building systems robust to this mismatch, with performance primarily evaluated using the Equal Error Rate on cross-language trials. By providing standardized data, open-source baselines, and a rigorous evaluation protocol, this challenge aims to drive research towards fairer, more inclusive, and language-independent speaker recognition technologies, directly aligning with the Interspeech 2026 theme, \"Speaking Together.\"", "AI": {"tldr": "提出TidyVoice跨语言说话人验证挑战，使用大规模多语种数据集评估系统在不同语言间的鲁棒性。", "motivation": "解决语音识别系统在语言不匹配情况下的性能下降问题，推动研究开发更具包容性和语言无关的说话人识别技术。", "method": "利用TidyVoiceX数据集进行挑战赛，该数据集来自Mozilla Common Voice，特别针对40种不同语言之间的转换进行了整理。评估方法主要使用跨语言试验中的等错误率。", "result": "未具体说明结果", "conclusion": "通过标准化的数据、开源基准和严格的评估协议，推动研究向着更公平、更具包容性和语言无关的说话人识别技术发展"}}
{"id": "2601.21957", "pdf": "https://arxiv.org/pdf/2601.21957", "abs": "https://arxiv.org/abs/2601.21957", "authors": ["Cheng Cui", "Ting Sun", "Suyin Liang", "Tingquan Gao", "Zelun Zhang", "Jiaxuan Liu", "Xueqing Wang", "Changda Zhou", "Hongen Liu", "Manhui Lin", "Yue Zhang", "Yubo Zhang", "Yi Liu", "Dianhai Yu", "Yanjun Ma"], "title": "PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing", "categories": ["cs.CV"], "comment": null, "summary": "We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR", "AI": {"tldr": "介绍PaddleOCR-VL-1.5模型，实现了94.5%的SOTA准确率，并扩展了文本识别任务。", "motivation": "提升在复杂环境下的文档解析能力，特别是在现实世界中物理畸变的影响下。引入Real5-OmniDocBench基准来评估鲁棒性。", "method": "开发了一种具有0.9B参数量的超紧凑视觉语言模型，并集成印章识别和文本定位任务。", "result": "在新创建的Real5-OmniDocBench上实现了SOTA性能，同时保持了高效率。", "conclusion": "PaddleOCR-VL-1.5展示了强大的文档解析能力，特别是在复杂环境下的表现。"}}
{"id": "2601.21948", "pdf": "https://arxiv.org/pdf/2601.21948", "abs": "https://arxiv.org/abs/2601.21948", "authors": ["Yang Du", "Siyuan Dai", "Yonghao Song", "Paul M. Thompson", "Haoteng Tang", "Liang Zhan"], "title": "Deep Models, Shallow Alignment: Uncovering the Granularity Mismatch in Neural Decoding", "categories": ["cs.CV"], "comment": "29 pages, 13 figures", "summary": "Neural visual decoding is a central problem in brain computer interface research, aiming to reconstruct human visual perception and to elucidate the structure of neural representations. However, existing approaches overlook a fundamental granularity mismatch between human and machine vision, where deep vision models emphasize semantic invariance by suppressing local texture information, whereas neural signals preserve an intricate mixture of low-level visual attributes and high-level semantic content. To address this mismatch, we propose Shallow Alignment, a novel contrastive learning strategy that aligns neural signals with intermediate representations of visual encoders rather than their final outputs, thereby striking a better balance between low-level texture details and high-level semantic features. Extensive experiments across multiple benchmarks demonstrate that Shallow Alignment significantly outperforms standard final-layer alignment, with performance gains ranging from 22% to 58% across diverse vision backbones. Notably, our approach effectively unlocks the scaling law in neural visual decoding, enabling decoding performance to scale predictably with the capacity of pre-trained vision backbones. We further conduct systematic empirical analyses to shed light on the mechanisms underlying the observed performance gains.", "AI": {"tldr": "该论文提出了一种新的对比学习策略浅层对齐，解决了神经信号与视觉编码器最终输出之间存在的粒度不匹配问题。", "motivation": "现有的神经解码方法忽略了人类和机器视觉之间的基本粒度不匹配，导致性能受限。因此需要一种新的方法来平衡低级纹理细节与高级语义特征。", "method": "提出了一种对比学习策略浅层对齐，它将神经信号与视觉编码器的中间表示进行对齐，而不是最终输出。", "result": "实验表明，在多个基准测试中，浅层对齐显著优于标准的最终层对齐方法，性能提升范围为22%至58%。此外，该策略解锁了神经解码中的缩放定律，使得解码性能能随着预训练视觉骨干网络的能力而可预测地提高。", "conclusion": "通过深入研究观察到的性能增益机制，浅层对齐策略在神经解码任务中表现出色，并有助于更好地理解大脑与机器之间的信息转换。"}}
{"id": "2601.21947", "pdf": "https://arxiv.org/pdf/2601.21947", "abs": "https://arxiv.org/abs/2601.21947", "authors": ["Bowen Fang", "Wen Ye", "Yunyue Su", "Jinghao Zhang", "Qiang Liu", "Yesheng Liu", "Xin Sun", "Shu Wu", "Jiabing Yang", "Baole Wei", "Liang Wang"], "title": "ToolWeaver: Weaving Collaborative Semantics for Scalable Tool Use in Large Language Models", "categories": ["cs.AI"], "comment": "10pages, 12 figures, Accepted to ICLR 2026", "summary": "Prevalent retrieval-based tool-use pipelines struggle with a dual semantic challenge: their retrievers often employ encoders that fail to capture complex semantics, while the Large Language Model (LLM) itself lacks intrinsic tool knowledge from its natural language pretraining. Generative methods offer a powerful alternative by unifying selection and execution, tasking the LLM to directly learn and generate tool identifiers. However, the common practice of mapping each tool to a unique new token introduces substantial limitations: it creates a scalability and generalization crisis, as the vocabulary size explodes and each tool is assigned a semantically isolated token. This approach also creates a semantic bottleneck that hinders the learning of collaborative tool relationships, as the model must infer them from sparse co-occurrences of monolithic tool IDs within a vast library. To address these limitations, we propose ToolWeaver, a novel generative tool learning framework that encodes tools into hierarchical sequences. This approach makes vocabulary expansion logarithmic to the number of tools. Crucially, it enables the model to learn collaborative patterns from the dense co-occurrence of shared codes, rather than the sparse co-occurrence of monolithic tool IDs. We generate these structured codes through a novel tokenization process designed to weave together a tool's intrinsic semantics with its extrinsic co-usage patterns. These structured codes are then integrated into the LLM through a generative alignment stage, where the model is fine-tuned to produce the hierarchical code sequences. Evaluation results with nearly 47,000 tools show that ToolWeaver significantly outperforms state-of-the-art methods, establishing a more scalable, generalizable, and semantically-aware foundation for advanced tool-augmented agents.", "AI": {"tldr": "本文提出了一种名为ToolWeaver的新框架，用于将工具编码为层次序列，解决大规模语言模型中的工具使用问题。", "motivation": "现有的基于检索的工具使用管道存在语义挑战：其检索器无法捕捉复杂语义，而大型语言模型在自然语言预训练中缺乏固有的工具知识。通过生成方法来统一选择和执行可以提供一种解决方案，但这种方法引入了词汇量膨胀和泛化危机。", "method": "本文提出ToolWeaver框架，该框架将工具编码为层次序列，使词典扩展呈对数增长，并允许模型从共享代码的密集共现中学习协作模式。通过新的分词过程生成这些结构化的代码，然后将其集成到语言模型中进行进一步训练。", "result": "评估结果显示，ToolWeaver在使用近47,000个工具时显著优于现有方法，展示了更可扩展、通用和语义感知的基础框架。", "conclusion": "通过将工具编码为层次序列，ToolWeaver解决了大规模语言模型中词汇量膨胀和泛化危机的问题，并提高了协作模式的学习效率。"}}
{"id": "2601.21945", "pdf": "https://arxiv.org/pdf/2601.21945", "abs": "https://arxiv.org/abs/2601.21945", "authors": ["Qingshan Wang", "Clara C. Wanjura", "Florian Marquardt"], "title": "Dependence of Equilibrium Propagation Training Success on Network Architecture", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.ET", "cs.NE"], "comment": "9 pages, 5 figures", "summary": "The rapid rise of artificial intelligence has led to an unsustainable growth in energy consumption. This has motivated progress in neuromorphic computing and physics-based training of learning machines as alternatives to digital neural networks. Many theoretical studies focus on simple architectures like all-to-all or densely connected layered networks. However, these may be challenging to realize experimentally, e.g. due to connectivity constraints. In this work, we investigate the performance of the widespread physics-based training method of equilibrium propagation for more realistic architectural choices, specifically, locally connected lattices. We train an XY model and explore the influence of architecture on various benchmark tasks, tracking the evolution of spatially distributed responses and couplings during training. Our results show that sparse networks with only local connections can achieve performance comparable to dense networks. Our findings provide guidelines for further scaling up architectures based on equilibrium propagation in realistic settings.", "AI": {"tldr": "研究了在更现实的网络架构下，平衡传播训练方法的表现。", "motivation": "为了减少人工智能带来的能源消耗问题，探索基于物理原理的学习机器培训方法，并解决简单架构难以实验实现的问题。", "method": "使用XY模型和局部连接晶格进行平衡传播训练，分析不同任务中的空间分布响应与耦合变化。", "result": "稀疏网络仅具有本地连接也能达到密集网络的性能水平。", "conclusion": "结果为基于平衡传播的大规模架构扩展提供了指导方针。"}}
{"id": "2601.21941", "pdf": "https://arxiv.org/pdf/2601.21941", "abs": "https://arxiv.org/abs/2601.21941", "authors": ["Xiaoguang Zhu", "Linxiao Gong", "Lianlong Sun", "Yang Liu", "Haoyu Wang", "Jing Liu"], "title": "Robust Multimodal Representation Learning in Healthcare", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Medical multimodal representation learning aims to integrate heterogeneous data into unified patient representations to support clinical outcome prediction. However, real-world medical datasets commonly contain systematic biases from multiple sources, which poses significant challenges for medical multimodal representation learning. Existing approaches typically focus on effective multimodal fusion, neglecting inherent biased features that affect the generalization ability. To address these challenges, we propose a Dual-Stream Feature Decorrelation Framework that identifies and handles the biases through structural causal analysis introduced by latent confounders. Our method employs a causal-biased decorrelation framework with dual-stream neural networks to disentangle causal features from spurious correlations, utilizing generalized cross-entropy loss and mutual information minimization for effective decorrelation. The framework is model-agnostic and can be integrated into existing medical multimodal learning methods. Comprehensive experiments on MIMIC-IV, eICU, and ADNI datasets demonstrate consistent performance improvements.", "AI": {"tldr": "提出了一种双重流特征去相关框架，用于处理医疗多模态数据中的系统偏差。", "motivation": "解决现有方法在处理医疗数据时忽略偏置特征的问题，这些偏置会影响模型的泛化能力。", "method": "利用因果分析和双重流神经网络区分因果特征与非因果关联，并通过广义交叉熵损失和互信息最小化实现去相关。", "result": "实验表明该框架在MIMIC-IV、eICU和ADNI数据集上均有显著性能提升。", "conclusion": "提出的方法能够有效解决医疗多模态学习中的系统偏差问题，提高模型的泛化能力。"}}
{"id": "2601.21938", "pdf": "https://arxiv.org/pdf/2601.21938", "abs": "https://arxiv.org/abs/2601.21938", "authors": ["Shaokai Liu", "Hao Feng", "Bozhi Luan", "Min Hou", "Jiajun Deng", "Wengang Zhou"], "title": "BookNet: Book Image Rectification via Cross-Page Attention Network", "categories": ["cs.CV"], "comment": null, "summary": "Book image rectification presents unique challenges in document image processing due to complex geometric distortions from binding constraints, where left and right pages exhibit distinctly asymmetric curvature patterns. However, existing single-page document image rectification methods fail to capture the coupled geometric relationships between adjacent pages in books. In this work, we introduce BookNet, the first end-to-end deep learning framework specifically designed for dual-page book image rectification. BookNet adopts a dual-branch architecture with cross-page attention mechanisms, enabling it to estimate warping flows for both individual pages and the complete book spread, explicitly modeling how left and right pages influence each other. Moreover, to address the absence of specialized datasets, we present Book3D, a large-scale synthetic dataset for training, and Book100, a comprehensive real-world benchmark for evaluation. Extensive experiments demonstrate that BookNet outperforms existing state-of-the-art methods on book image rectification. Code and dataset will be made publicly available.", "AI": {"tldr": "本书介绍了一种名为BookNet的端到端深度学习框架，用于解决书籍图像校正问题。", "motivation": "现有单页文档图像校正方法无法捕捉相邻页面间的耦合几何关系，而书籍图像矫正因装订约束导致的独特复杂几何失真进一步增加了难度。", "method": "BookNet采用双分支架构及跨页面注意机制，能够估计单个页面和整个书页展开的扭曲流，明确建模左右页之间的相互影响。同时提出了大型合成数据集Book3D用于训练，以及全面的真实世界基准测试集合Book100。", "result": "实验结果表明，BookNet在书籍图像校正上优于现有的最佳方法。", "conclusion": "通过采用新的框架和注意机制，BookNet为书籍图像的自动矫正提供了一个有效的解决方案。"}}
{"id": "2601.21937", "pdf": "https://arxiv.org/pdf/2601.21937", "abs": "https://arxiv.org/abs/2601.21937", "authors": ["Shuangshuang Ying", "Zheyu Wang", "Yunjian Peng", "Jin Chen", "Yuhao Wu", "Hongbin Lin", "Dingyu He", "Siyi Liu", "Gengchen Yu", "YinZhu Piao", "Yuchen Wu", "Xin Gui", "Zhongyuan Peng", "Xin Li", "Xeron Du", "Libo Qin", "YiXin Cao", "Ge Zhang"], "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities", "categories": ["cs.AI"], "comment": null, "summary": "Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.", "AI": {"tldr": "该论文提出了一种新的基准DeR2，用于评估大型语言模型在处理新颖科学信息时的推理能力，并分离了检索和推理过程中的误差。", "motivation": "现有的评价方法无法清晰地判断大规模语言模型是否能够对真正的新科学信息进行推理。大多数评估仅衡量端到端的RAG管道性能，其中推理被检索和工具链选择混淆，且参数记忆和开放网络波动进一步污染了信号。", "method": "引入DeR2基准测试，通过四种模式——指令模式、概念模式（无文档）、相关文档模式以及完整集模式来解耦证据访问与推理。这种方法有助于解释不同模式之间的差距并精确定位误差来源。", "result": "实验结果表明，在不同的大型模型上存在显著差异和改进空间：一些模型在面对完全设置时表现较弱，而另一些则表现出概念使用错误的情况。", "conclusion": "DeR2提供了一个有价值的工具来评估大规模语言模型的推理能力，并且强调了分离证据访问与推理的重要性。"}}
{"id": "2601.21936", "pdf": "https://arxiv.org/pdf/2601.21936", "abs": "https://arxiv.org/abs/2601.21936", "authors": ["Jon Chun", "Kathrine Elkins", "Yong Suk Lee"], "title": "AgenticSimLaw: A Juvenile Courtroom Multi-Agent Debate Simulation for Explainable High-Stakes Tabular Decision Making", "categories": ["cs.AI"], "comment": "18 pages, 5 figures", "summary": "We introduce AgenticSimLaw, a role-structured, multi-agent debate framework that provides transparent and controllable test-time reasoning for high-stakes tabular decision-making tasks. Unlike black-box approaches, our courtroom-style orchestration explicitly defines agent roles (prosecutor, defense, judge), interaction protocols (7-turn structured debate), and private reasoning strategies, creating a fully auditable decision-making process. We benchmark this framework on young adult recidivism prediction using the NLSY97 dataset, comparing it against traditional chain-of-thought (CoT) prompting across almost 90 unique combinations of models and strategies. Our results demonstrate that structured multi-agent debate provides more stable and generalizable performance compared to single-agent reasoning, with stronger correlation between accuracy and F1-score metrics. Beyond performance improvements, AgenticSimLaw offers fine-grained control over reasoning steps, generates complete interaction transcripts for explainability, and enables systematic profiling of agent behaviors. While we instantiate this framework in the criminal justice domain to stress-test reasoning under ethical complexity, the approach generalizes to any deliberative, high-stakes decision task requiring transparency and human oversight. This work addresses key LLM-based multi-agent system challenges: organization through structured roles, observability through logged interactions, and responsibility through explicit non-deployment constraints for sensitive domains. Data, results, and code will be available on github.com under the MIT license.", "AI": {"tldr": "介绍AgenticSimLaw，一种基于法庭辩论的角色结构化多智能体框架，用于高风险表格决策任务的透明推理。", "motivation": "旨在提供一个可审计和可控的决策过程，并通过角色定义、交互协议和私人推理策略来解决黑盒方法的问题。该研究使用NLSY97数据集进行青少年再犯预测，并与传统的链式思考（CoT）提示法比较，证明结构化多智能体辩论比单个代理推理更稳定且具有更强的相关性。", "method": "构建了一个法庭式的多智能体辩论框架，定义了代理角色如检察官、辩护律师和法官的职责，规定了7轮交互流程，并采用了私人推理策略。此外，还通过NLSY97数据集对青少年再犯预测进行了基准测试。", "result": "结果显示，结构化的多智能体辩论比传统的单个代理推理在准确性和F1得分上具有更稳定和泛化性能的表现。该方法提供详细的解释性交互记录，并允许系统地分析各智能体的行为。", "conclusion": "AgenticSimLaw不仅适用于刑事司法领域中的复杂伦理决策，还广泛应用于任何需要透明度和人工监督的高风险决策任务中。"}}
{"id": "2601.21933", "pdf": "https://arxiv.org/pdf/2601.21933", "abs": "https://arxiv.org/abs/2601.21933", "authors": ["Rui Zhao", "Wenrui Li", "Lin Zhu", "Yajing Zheng", "Weisi Lin"], "title": "Just Noticeable Difference Modeling for Deep Visual Features", "categories": ["cs.CV"], "comment": null, "summary": "Deep visual features are increasingly used as the interface in vision systems, motivating the need to describe feature characteristics and control feature quality for machine perception. Just noticeable difference (JND) characterizes the maximum imperceptible distortion for images under human or machine vision. Extending it to deep visual features naturally meets the above demand by providing a task-aligned tolerance boundary in feature space, offering a practical reference for controlling feature quality under constrained resources. We propose FeatJND, a task-aligned JND formulation that predicts the maximum tolerable per-feature perturbation map while preserving downstream task performance. We propose a FeatJND estimator at standardized split points and validate it across image classification, detection, and instance segmentation. Under matched distortion strength, FeatJND-based distortions consistently preserve higher task performance than unstructured Gaussian perturbations, and attribution visualizations suggest FeatJND can suppress non-critical feature regions. As an application, we further apply FeatJND to token-wise dynamic quantization and show that FeatJND-guided step-size allocation yields clear gains over random step-size permutation and global uniform step size under the same noise budget. Our code will be released after publication.", "AI": {"tldr": "提出了FeatJND模型，用于预测深度视觉特征的最大可容忍扰动图，同时保持下游任务性能。", "motivation": "随着深度视觉特征在视觉系统中的广泛应用，需要描述其特性并控制质量。引入了Just Noticeable Difference (JND) 概念来设定任务相关的容差边界，提供了一种实用的参考方法以在资源受限的情况下控制特征质量。", "method": "提出FeatJND模型预测深度视觉特征的最大可容忍扰动图，并通过标准分割点验证该模型的有效性。将此应用到令牌级动态量化中，实现基于FeatJND的步长分配策略。", "result": "在相匹配的扰动强度下，基于FeatJND的方法保持了更高的任务性能，并且归因可视化显示FeatJND可以抑制非关键特征区域。此外，在相同噪声预算下，与随机步长排列和全局统一步长相比，基于FeatJND的策略取得了明显的优势。", "conclusion": "FeatJND模型提供了一种有效的方法来预测深度视觉特征的最大可容忍扰动图，并能够应用于动态量化等实际场景中以优化性能。"}}
{"id": "2601.21926", "pdf": "https://arxiv.org/pdf/2601.21926", "abs": "https://arxiv.org/abs/2601.21926", "authors": ["Jinhao Zhang", "Wenlong Xia", "Yaojia Wang", "Zhexuan Zhou", "Huizhe Li", "Yichen Lai", "Haoming Song", "Youmin Gong", "Jie Me"], "title": "Information Filtering via Variational Regularization for Robot Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Diffusion-based visuomotor policies built on 3D visual representations have achieved strong performance in learning complex robotic skills. However, most existing methods employ an oversized denoising decoder. While increasing model capacity can improve denoising, empirical evidence suggests that it also introduces redundancy and noise in intermediate feature blocks. Crucially, we find that randomly masking backbone features at inference time (without changing training) can improve performance, confirming the presence of task-irrelevant noise in intermediate features. To this end, we propose Variational Regularization (VR), a lightweight module that imposes a timestep-conditioned Gaussian over backbone features and applies a KL-divergence regularizer, forming an adaptive information bottleneck. Extensive experiments on three simulation benchmarks (RoboTwin2.0, Adroit, and MetaWorld) show that, compared to the baseline DP3, our approach improves the success rate by 6.1% on RoboTwin2.0 and by 4.1% on Adroit and MetaWorld, achieving new state-of-the-art results. Real-world experiments further demonstrate that our method performs well in practical deployments. Code will released.", "AI": {"tldr": "该论文提出了一种通过变分正则化（VR）模块来过滤冗余和噪声，以提高基于扩散的视觉操作策略性能的方法。", "motivation": "现有方法使用过大的去噪解码器引入了冗余和噪声。随机掩蔽骨干特征可以改善性能，表明存在任务无关的噪声，因此提出变分正则化模块来解决这一问题。", "method": "通过在骨干特征上施加时间步长条件的高斯分布，并应用KL散度正则化器形成自适应的信息瓶颈，以过滤冗余和噪声。", "result": "与基线DP3相比，在RoboTwin2.0、Adroit和MetaWorld三个模拟基准测试中，成功率分别提高了6.1%、4.1%和4.1%，达到新的SOTA结果。实际部署的实验进一步验证了该方法的有效性。", "conclusion": "通过变分正则化模块过滤冗余和噪声可以显著提高基于扩散的视觉操作策略性能，并且在模拟和真实世界的应用中都表现出色。"}}
{"id": "2601.21925", "pdf": "https://arxiv.org/pdf/2601.21925", "abs": "https://arxiv.org/abs/2601.21925", "authors": ["Yuchen Mao", "Wen Huang", "Yanmin Qian"], "title": "Localizing Speech Deepfakes Beyond Transitions via Segment-Aware Learning", "categories": ["cs.SD"], "comment": null, "summary": "Localizing partial deepfake audio, where only segments of speech are manipulated, remains challenging due to the subtle and scattered nature of these modifications. Existing approaches typically rely on frame-level predictions to identify spoofed segments, and some recent methods improve performance by concentrating on the transitions between real and fake audio. However, we observe that these models tend to over-rely on boundary artifacts while neglecting the manipulated content that follows. We argue that effective localization requires understanding the entire segments beyond just detecting transitions. Thus, we propose Segment-Aware Learning (SAL), a framework that encourages models to focus on the internal structure of segments. SAL introduces two core techniques: Segment Positional Labeling, which provides fine-grained frame supervision based on relative position within a segment; and Cross-Segment Mixing, a data augmentation method that generates diverse segment patterns. Experiments across multiple deepfake localization datasets show that SAL consistently achieves strong performance in both in-domain and out-of-domain settings, with notable gains in non-boundary regions and reduced reliance on transition artifacts. The code is available at https://github.com/SentryMao/SAL.", "AI": {"tldr": "本文提出了Segment-Aware Learning (SAL) 框架，用于更好地定位部分深度伪造音频中的篡改片段。", "motivation": "现有的方法主要依赖于帧级预测来识别伪造的片段，并且有些近期的方法通过聚焦音频段之间的过渡区域来改进性能。然而，这些模型往往过于依赖边界特征而忽视了内部被篡改的内容。因此，本文提出了一种新的框架以更好地理解整个音频段。", "method": "SAL 引入了两个核心技术：Segment Positional Labeling 和 Cross-Segment Mixing。前者提供了基于片段相对位置的精细帧级监督；后者是一种生成多样片段模式的数据增强方法。", "result": "实验结果表明，SAL 在多个深度伪造定位数据集上表现优异，并且在非边界区域中实现了显著提升，减少了对过渡特征的依赖。", "conclusion": "Segment-Aware Learning (SAL) 框架有效提高了部分音频片段篡改的识别精度和鲁棒性。"}}
{"id": "2601.21922", "pdf": "https://arxiv.org/pdf/2601.21922", "abs": "https://arxiv.org/abs/2601.21922", "authors": ["Cong Cao", "Huanjing Yue", "Shangbin Xie", "Xin Liu", "Jingyu Yang"], "title": "Zero-Shot Video Restoration and Enhancement with Assistance of Video Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Although diffusion-based zero-shot image restoration and enhancement methods have achieved great success, applying them to video restoration or enhancement will lead to severe temporal flickering. In this paper, we propose the first framework that utilizes the rapidly-developed video diffusion model to assist the image-based method in maintaining more temporal consistency for zero-shot video restoration and enhancement. We propose homologous latents fusion, heterogenous latents fusion, and a COT-based fusion ratio strategy to utilize both homologous and heterogenous text-to-video diffusion models to complement the image method. Moreover, we propose temporal-strengthening post-processing to utilize the image-to-video diffusion model to further improve temporal consistency. Our method is training-free and can be applied to any diffusion-based image restoration and enhancement methods. Experimental results demonstrate the superiority of the proposed method.", "AI": {"tldr": "提出了第一个框架，利用视频扩散模型辅助图像方法进行零样本视频修复和增强，以保持更好的时间一致性。", "motivation": "现有基于扩散的零样本图像修复和增强方法在应用于视频时会导致严重的时间闪烁问题，因此提出新方案解决这一挑战。", "method": "引入同构潜在特征融合、异构潜在特征融合以及COT基融合比例策略来结合使用文本到视频扩散模型以补充图像方法，并且提出了时间强化后处理步骤来进一步提高时间一致性。该方法无需训练并且可以应用于任何基于扩散的图像修复和增强方法。", "result": "实验证明了所提出的方法在零样本视频修复和增强任务中的优越性。", "conclusion": "通过结合使用视频扩散模型，能够有效解决现有技术中时间闪烁问题，并显著提升零样本视频修复和增强的效果。"}}
{"id": "2601.21920", "pdf": "https://arxiv.org/pdf/2601.21920", "abs": "https://arxiv.org/abs/2601.21920", "authors": ["Upol Ehsan", "Samir Passi", "Koustuv Saha", "Todd McNutt", "Mark O. Riedl", "Sara Alcorn"], "title": "From Future of Work to Future of Workers: Addressing Asymptomatic AI Harms for Dignified Human-AI Interaction", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "ef:Proceedings of the CHI Conference on Human Factors in Computing Systems, 2026", "summary": "In the future of work discourse, AI is touted as the ultimate productivity amplifier. Yet, beneath the efficiency gains lie subtle erosions of human expertise and agency. This paper shifts focus from the future of work to the future of workers by navigating the AI-as-Amplifier Paradox: AI's dual role as enhancer and eroder, simultaneously strengthening performance while eroding underlying expertise. We present a year-long study on the longitudinal use of AI in a high-stakes workplace among cancer specialists. Initial operational gains hid ``intuition rust'': the gradual dulling of expert judgment. These asymptomatic effects evolved into chronic harms, such as skill atrophy and identity commoditization. Building on these findings, we offer a framework for dignified Human-AI interaction co-constructed with professional knowledge workers facing AI-induced skill erosion without traditional labor protections. The framework operationalizes sociotechnical immunity through dual-purpose mechanisms that serve institutional quality goals while building worker power to detect, contain, and recover from skill erosion, and preserve human identity. Evaluated across healthcare and software engineering, our work takes a foundational step toward dignified human-AI interaction futures by balancing productivity with the preservation of human expertise.", "AI": {"tldr": "探讨在高风险工作环境中，人工智能对专业人员技能和身份的影响，并提出促进人机和谐互动的框架。", "motivation": "揭示了AI虽然能提高工作效率，但也会逐渐削弱专家判断力等潜在危害，旨在保护职业工作者的专业能力和尊严。", "method": "通过一年的长期研究，在癌症专科医生的工作中观察AI的应用效果及其对专业人员技能的影响。", "result": "发现了AI使用过程中导致的‘直觉生锈’现象，并提出了一个框架来应对由此产生的慢性伤害，如技术退化和身份商品化。", "conclusion": "提出了一种新的方法论以促进人机和谐互动，确保生产力与人类专业知识的同时提升。"}}
{"id": "2601.21919", "pdf": "https://arxiv.org/pdf/2601.21919", "abs": "https://arxiv.org/abs/2601.21919", "authors": ["Yiqun Chen", "Jinyuan Feng", "Wei Yang", "Meizhi Zhong", "Zhengliang Shi", "Rui Li", "Xiaochi Wei", "Yan Gao", "Yi Wu", "Yao Hu", "Zhiqiang Pu", "Jiaxin Mao"], "title": "Self-Compression of Chain-of-Thought via Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "The inference overhead induced by redundant reasoning undermines the interactive experience and severely bottlenecks the deployment of Large Reasoning Models. Existing reinforcement learning (RL)-based solutions tackle this problem by coupling a length penalty with outcome-based rewards. This simplistic reward weighting struggles to reconcile brevity with accuracy, as enforcing brevity may compromise critical reasoning logic. In this work, we address this limitation by proposing a multi-agent RL framework that selectively penalizes redundant chunks, while preserving essential reasoning logic. Our framework, Self-Compression via MARL (SCMA), instantiates redundancy detection and evaluation through two specialized agents: \\textbf{a Segmentation Agent} for decomposing the reasoning process into logical chunks, and \\textbf{a Scoring Agent} for quantifying the significance of each chunk. The Segmentation and Scoring agents collaboratively define an importance-weighted length penalty during training, incentivizing \\textbf{a Reasoning Agent} to prioritize essential logic without introducing inference overhead during deployment. Empirical evaluations across model scales demonstrate that SCMA reduces response length by 11.1\\% to 39.0\\% while boosting accuracy by 4.33\\% to 10.02\\%. Furthermore, ablation studies and qualitative analysis validate that the synergistic optimization within the MARL framework fosters emergent behaviors, yielding more powerful LRMs compared to vanilla RL paradigms.", "AI": {"tldr": "通过多智能体强化学习框架减少冗余推理，提高大型推理模型的部署效率和准确性。", "motivation": "现有的基于强化学习的方法在压缩推理过程时难以平衡简洁性和准确性。作者提出一种新的多代理强化学习框架以解决这个问题。", "method": "该方法包含两个专门的智能体：分割智能体将推理过程分解为逻辑块，评分智能体量化每个块的重要性。这两个智能体共同定义了一个重要性加权长度惩罚来训练第三个智能体即推理智能体，使其优先考虑关键逻辑而减少推断开销。", "result": "实验表明SCMA在不同模型规模下可将响应长度降低11.1%至39.0%，同时提高了4.33%-10.02%的准确性。消融研究和定性分析验证了多智能体强化学习框架的有效性和优越性。", "conclusion": "通过引入多代理强化学习框架，该方法在压缩大型推理模型的同时保持甚至提升其性能，展示了比传统RL模式更强大的能力"}}
{"id": "2601.21916", "pdf": "https://arxiv.org/pdf/2601.21916", "abs": "https://arxiv.org/abs/2601.21916", "authors": ["Yiqun Chen", "Erhan Zhang", "Tianyi Hu", "Shijie Wang", "Zixuan Yang", "Meizhi Zhong", "Xiaochi Wei", "Yan Gao", "Yi Wu", "Yao Hu", "Jiaxin Mao"], "title": "JADE: Bridging the Strategic-Operational Gap in Dynamic Agentic RAG", "categories": ["cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "The evolution of Retrieval-Augmented Generation (RAG) has shifted from static retrieval pipelines to dynamic, agentic workflows where a central planner orchestrates multi-turn reasoning. However, existing paradigms face a critical dichotomy: they either optimize modules jointly within rigid, fixed-graph architectures, or empower dynamic planning while treating executors as frozen, black-box tools. We identify that this \\textit{decoupled optimization} creates a ``strategic-operational mismatch,'' where sophisticated planning strategies fail to materialize due to unadapted local executors, often leading to negative performance gains despite increased system complexity. In this paper, we propose \\textbf{JADE} (\\textbf{J}oint \\textbf{A}gentic \\textbf{D}ynamic \\textbf{E}xecution), a unified framework for the joint optimization of planning and execution within dynamic, multi-turn workflows. By modeling the system as a cooperative multi-agent team unified under a single shared backbone, JADE enables end-to-end learning driven by outcome-based rewards. This approach facilitates \\textit{co-adaptation}: the planner learns to operate within the capability boundaries of the executors, while the executors evolve to align with high-level strategic intent. Empirical results demonstrate that JADE transforms disjoint modules into a synergistic system, yielding remarkable performance improvements via joint optimization and enabling a flexible balance between efficiency and effectiveness through dynamic workflow orchestration.", "AI": {"tldr": "本文提出了JADE框架，旨在解决动态代理工作流中的战略操作差距问题。", "motivation": "现有RAG系统在优化模块和执行者之间的协调上存在脱节，导致策略规划不能充分发挥效能，进而影响整体性能。因此，有必要开发一种能够将两者统一起来的方法。", "method": "JADE框架通过一个共享的骨干模型将多代理团队视为合作体，并实现了基于结果奖励的端到端学习，使规划者适应执行者的局限性同时让执行者与高层次的战略意图相协调。", "result": "实验结果显示，通过联合优化，JADE可以有效提升系统性能，并且能够实现效率和效果之间的灵活平衡。", "conclusion": "本文提出的JADE方法成功解决了动态工作流中的战略操作不匹配问题，展示了其在提升RAG系统性能方面的潜力。"}}
{"id": "2601.21915", "pdf": "https://arxiv.org/pdf/2601.21915", "abs": "https://arxiv.org/abs/2601.21915", "authors": ["Yunhao Li", "Sijing Wu", "Zhilin Gao", "Zicheng Zhang", "Qi Jia", "Huiyu Duan", "Xiongkuo Min", "Guangtao Zhai"], "title": "VideoAesBench: Benchmarking the Video Aesthetics Perception Capabilities of Large Multimodal Models", "categories": ["cs.CV"], "comment": null, "summary": "Large multimodal models (LMMs) have demonstrated outstanding capabilities in various visual perception tasks, which has in turn made the evaluation of LMMs significant. However, the capability of video aesthetic quality assessment, which is a fundamental ability for human, remains underexplored for LMMs. To address this, we introduce VideoAesBench, a comprehensive benchmark for evaluating LMMs' understanding of video aesthetic quality. VideoAesBench has several significant characteristics: (1) Diverse content including 1,804 videos from multiple video sources including user-generated (UGC), AI-generated (AIGC), compressed, robotic-generated (RGC), and game videos. (2) Multiple question formats containing traditional single-choice questions, multi-choice questions, True or False questions, and a novel open-ended questions for video aesthetics description. (3) Holistic video aesthetics dimensions including visual form related questions from 5 aspects, visual style related questions from 4 aspects, and visual affectiveness questions from 3 aspects. Based on VideoAesBench, we benchmark 23 open-source and commercial large multimodal models. Our findings show that current LMMs only contain basic video aesthetics perception ability, their performance remains incomplete and imprecise. We hope our VideoAesBench can be served as a strong testbed and offer insights for explainable video aesthetics assessment.", "AI": {"tldr": "视频美学感知能力的基准测试，评估大型多模态模型在理解视频美学质量方面的表现。", "motivation": "大型多模态模型（LMM）在各种视觉感知任务中表现出色，但其视频美学质量评估的能力尚未被充分研究。为此引入VideoAesBench，全面评测LMM的视频美学感知能力。", "method": "构建包含1804个视频样本的数据集，并提出多种问题形式来评估模型理解视频美学质量的能力，包括单选、多选和开放式描述性问题等。", "result": "通过对23种开源及商用大型多模态模型进行基准测试发现，当前的LMM仅具备基本的视频美学感知能力，其性能仍不完善且不够精确。", "conclusion": "VideoAesBench作为一个强大的测试平台，提供了关于可解释性视频美学评估的重要见解。"}}
{"id": "2601.21912", "pdf": "https://arxiv.org/pdf/2601.21912", "abs": "https://arxiv.org/abs/2601.21912", "authors": ["Zhao Wang", "Ziliang Zhao", "Zhicheng Dou"], "title": "ProRAG: Process-Supervised Reinforcement Learning for Retrieval-Augmented Generation", "categories": ["cs.AI", "cs.CL", "cs.IR"], "comment": "11 pages, 6 figures", "summary": "Reinforcement learning (RL) has become a promising paradigm for optimizing Retrieval-Augmented Generation (RAG) in complex reasoning tasks. However, traditional outcome-based RL approaches often suffer from reward sparsity and inefficient credit assignment, as coarse-grained scalar rewards fail to identify specific erroneous steps within long-horizon trajectories. This ambiguity frequently leads to \"process hallucinations\", where models reach correct answers through flawed logic or redundant retrieval steps. Although recent process-aware approaches attempt to mitigate this via static preference learning or heuristic reward shaping, they often lack the on-policy exploration capabilities required to decouple step-level credit from global outcomes. To address these challenges, we propose ProRAG, a process-supervised reinforcement learning framework designed to integrate learned step-level supervision into the online optimization loop. Our framework consists of four stages: (1) Supervised Policy Warmup to initialize the model with a structured reasoning format; (2) construction of an MCTS-based Process Reward Model (PRM) to quantify intermediate reasoning quality; (3) PRM-Guided Reasoning Refinement to align the policy with fine-grained process preferences; and (4) Process-Supervised Reinforcement Learning with a dual-granularity advantage mechanism. By aggregating step-level process rewards with global outcome signals, ProRAG provides precise feedback for every action. Extensive experiments on five multi-hop reasoning benchmarks demonstrate that ProRAG achieves superior overall performance compared to strong outcome-based and process-aware RL baselines, particularly on complex long-horizon tasks, validating the effectiveness of fine-grained process supervision. The code and model are available at https://github.com/lilinwz/ProRAG.", "AI": {"tldr": "提出了一种基于过程监督的强化学习框架ProRAG，用于改进检索增强生成任务中的推理质量。", "motivation": "传统的基于结果的强化学习方法在复杂推理任务中存在奖励稀疏和信用分配效率低的问题。为解决这一挑战，该论文提出了一个集成细粒度过程指导的在线优化循环的新框架。", "method": "ProRAG包括四个阶段：监督策略预热、构建基于MCTS的过程奖励模型（PRM）、引导推理细化以对齐策略与过程偏好以及带有双层次优势机制的过程强化学习。通过结合步骤级过程奖励和全局结果信号，提供精确反馈给每个动作。", "result": "实验表明，ProRAG在五个跨跳推理基准测试中相较于强基线方法取得了更好的总体性能，特别是在复杂长轨迹任务上表现出色。", "conclusion": "该研究证明了细粒度过程监督的有效性，并通过代码和模型公开分享成果。"}}
{"id": "2601.21909", "pdf": "https://arxiv.org/pdf/2601.21909", "abs": "https://arxiv.org/abs/2601.21909", "authors": ["Shaojie Wang", "Liang Zhang"], "title": "From Meta-Thought to Execution: Cognitively Aligned Post-Training for Generalizable and Reliable LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Current LLM post-training methods optimize complete reasoning trajectories through Supervised Fine-Tuning (SFT) followed by outcome-based Reinforcement Learning (RL). While effective, a closer examination reveals a fundamental gap: this approach does not align with how humans actually solve problems. Human cognition naturally decomposes problem-solving into two distinct stages: first acquiring abstract strategies (i.e., meta-knowledge) that generalize across problems, then adapting them to specific instances. In contrast, by treating complete trajectories as basic units, current methods are inherently problem-centric, entangling abstract strategies with problem-specific execution. To address this misalignment, we propose a cognitively-inspired framework that explicitly mirrors the two-stage human cognitive process. Specifically, Chain-of-Meta-Thought (CoMT) focuses supervised learning on abstract reasoning patterns without specific executions, enabling acquisition of generalizable strategies. Confidence-Calibrated Reinforcement Learning (CCRL) then optimizes task adaptation via confidence-aware rewards on intermediate steps, preventing overconfident errors from cascading and improving execution reliability. Experiments across four models and eight benchmarks show 2.19\\% and 4.63\\% improvements in-distribution and out-of-distribution respectively over standard methods, while reducing training time by 65-70% and token consumption by 50%, demonstrating that aligning post-training with human cognitive principles yields not only superior generalization but also enhanced training efficiency.", "AI": {"tldr": "本文提出了一种基于人类认知过程的LLM后训练框架，以改进推理的泛化能力和可靠性。", "motivation": "现有LLM的后训练方法存在与人类解决问题方式不符的问题，导致策略抽象和具体执行纠缠在一起。", "method": "提出Chain-of-Meta-Thought (CoMT) 和Confidence-Calibrated Reinforcement Learning (CCRL)，前者专注于泛化策略的学习，后者通过中间步骤的信心奖励优化任务适应性。", "result": "实验表明，在四个模型和八个基准测试中，本文的方法分别在分布内和分布外实现了2.19％和4.63％的改进，并减少了训练时间和令牌消耗。", "conclusion": "将LLM后训练与人类认知原则对齐可以提高泛化能力并提升训练效率。"}}
{"id": "2601.21904", "pdf": "https://arxiv.org/pdf/2601.21904", "abs": "https://arxiv.org/abs/2601.21904", "authors": ["Hanmo Chen", "Guangtao Lyu", "Chenghao Xu", "Jiexi Yan", "Xu Yang", "Cheng Deng"], "title": "Beyond Global Alignment: Fine-Grained Motion-Language Retrieval via Pyramidal Shapley-Taylor Learning", "categories": ["cs.CV"], "comment": null, "summary": "As a foundational task in human-centric cross-modal intelligence, motion-language retrieval aims to bridge the semantic gap between natural language and human motion, enabling intuitive motion analysis, yet existing approaches predominantly focus on aligning entire motion sequences with global textual representations. This global-centric paradigm overlooks fine-grained interactions between local motion segments and individual body joints and text tokens, inevitably leading to suboptimal retrieval performance. To address this limitation, we draw inspiration from the pyramidal process of human motion perception (from joint dynamics to segment coherence, and finally to holistic comprehension) and propose a novel Pyramidal Shapley-Taylor (PST) learning framework for fine-grained motion-language retrieval. Specifically, the framework decomposes human motion into temporal segments and spatial body joints, and learns cross-modal correspondences through progressive joint-wise and segment-wise alignment in a pyramidal fashion, effectively capturing both local semantic details and hierarchical structural relationships. Extensive experiments on multiple public benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, achieving precise alignment between motion segments and body joints and their corresponding text tokens. The code of this work will be released upon acceptance.", "AI": {"tldr": "本文提出了一种用于细粒度动作语言检索的金字塔夏普利-泰勒学习框架。", "motivation": "现有的方法主要关注于整个运动序列与全局文本表示之间的对齐，忽略了局部运动片段和个体肢体关节及文本标记之间的精细交互作用。这导致了次优的检索性能。", "method": "本文提出了一种金字塔夏普利-泰勒（PST）学习框架，该框架通过逐步进行逐关节和逐片段对齐来分解人类动作，并在层次结构中学习跨模态对应关系。", "result": "实验结果表明，该方法显著优于现有的最先进方法，在多个公共基准数据集上实现了精细的动作片段、肢体关节及其对应的文本标记之间的精准对齐。", "conclusion": "通过提出金字塔夏普利-泰勒（PST）学习框架，本文有效解决了现有动作语言检索中的局部细节捕捉和层次结构关系识别的问题。"}}
{"id": "2601.21903", "pdf": "https://arxiv.org/pdf/2601.21903", "abs": "https://arxiv.org/abs/2601.21903", "authors": ["Konstantinos Varsos", "Adamantia Stamou", "George D. Stamoulis", "Vasillios A. Siris"], "title": "User Acceptance Model for Smart Incentives in Sustainable Video Streaming towards 6G", "categories": ["cs.ET"], "comment": null, "summary": "The rapid growth of 5G video streaming is intensifying energy consumption across access, core, and data-center networks, underscoring the critical need for energy and carbon-efficient solutions. While reducing streaming bitrates improves energy efficiency, its success hinges on user acceptance--particularly when lower bitrates may be perceived as reduced quality of experience (QoE). Therefore, there is a need to develop transparent, user-centric incentive models that balance sustainability with perceived value. We propose a user-acceptance model that combines diverse environmental awareness, personalized responsiveness to incentives, and varying levels of altruism into a unified probabilistic framework. The model incorporates dynamic, individualized incentives that adapt over time. We further enhance the framework by incorporating (i) social well-being as a motivator for altruistic choices, (ii) provider-driven education strategies that gradually adjust user acceptance thresholds, and (iii) data-driven learning of user traits from historical offer--response interactions. Extensive synthetic-data experiments reveal the trade-offs between provider cost and network flexibility, showing that personalized incentives and gradual behavioral adaptation can advance sustainability targets without compromising stakeholder requirements.", "AI": {"tldr": "研究提出了一种用户接受模型，用于在可持续视频流媒体中使用智能激励措施。", "motivation": "随着5G视频流媒体的增长，能源消耗加剧，需要开发一种透明的、以用户为中心的激励模式来平衡可再生能源和感知价值。", "method": "模型结合了多方面的环保意识、个性化响应激励以及不同级别的利他主义。引入社会福利作为利他选择的动力，并通过提供者驱动的教育策略逐渐调整用户的接受门槛，同时利用数据驱动的方法学习用户特质。", "result": "实验表明个性化的激励措施和逐步的行为适应可以在不牺牲相关方需求的情况下实现可持续目标。", "conclusion": "该模型成功地在可持续视频流媒体中平衡了环保和用户体验的需求。"}}
{"id": "2601.21900", "pdf": "https://arxiv.org/pdf/2601.21900", "abs": "https://arxiv.org/abs/2601.21900", "authors": ["Chuancheng Shi", "Shangze Li", "Wenjun Lu", "Wenhua Wu", "Cong Wang", "Zifeng Cheng", "Fei Shen", "Tat-Seng Chua"], "title": "TraceRouter: Robust Safety for Large Foundation Models via Path-Level Intervention", "categories": ["cs.CV", "cs.AI", "cs.CY", "cs.MM"], "comment": null, "summary": "Despite their capabilities, large foundation models (LFMs) remain susceptible to adversarial manipulation. Current defenses predominantly rely on the \"locality hypothesis\", suppressing isolated neurons or features. However, harmful semantics act as distributed, cross-layer circuits, rendering such localized interventions brittle and detrimental to utility. To bridge this gap, we propose \\textbf{TraceRouter}, a path-level framework that traces and disconnects the causal propagation circuits of illicit semantics. TraceRouter operates in three stages: (1) it pinpoints a sensitive onset layer by analyzing attention divergence; (2) it leverages sparse autoencoders (SAEs) and differential activation analysis to disentangle and isolate malicious features; and (3) it maps these features to downstream causal pathways via feature influence scores (FIS) derived from zero-out interventions. By selectively suppressing these causal chains, TraceRouter physically severs the flow of harmful information while leaving orthogonal computation routes intact. Extensive experiments demonstrate that TraceRouter significantly outperforms state-of-the-art baselines, achieving a superior trade-off between adversarial robustness and general utility. Our code will be publicly released. WARNING: This paper contains unsafe model responses.", "AI": {"tldr": "提出TraceRouter框架，用于在大型基础模型中通过路径级干预来增强安全性。", "motivation": "当前防御措施主要依赖于抑制孤立神经元或特征，这对抗分散的跨层电路效果不佳。为了填补这一空白，作者提出了一个新框架以追踪和切断有害语义传播回路。", "method": "TraceRouter通过三个阶段工作：首先识别敏感起始层；然后使用稀疏自动编码器分离恶意特征；最后映射这些特征到因果路径上，并抑制它们。", "result": "实验表明，TraceRouter在对抗鲁棒性和通用性之间的权衡优于现有方法。", "conclusion": "TraceRouter通过有效切断有害信息传播回路增强了模型的安全性。"}}
{"id": "2601.21898", "pdf": "https://arxiv.org/pdf/2601.21898", "abs": "https://arxiv.org/abs/2601.21898", "authors": ["Minwoo Jang", "Hoyoung Kim", "Jabin Koo", "Jungseul Ok"], "title": "Making Models Unmergeable via Scaling-Sensitive Loss Landscape", "categories": ["cs.AI", "cs.CR"], "comment": "Preprint", "summary": "The rise of model hubs has made it easier to access reusable model components, making model merging a practical tool for combining capabilities. Yet, this modularity also creates a \\emph{governance gap}: downstream users can recompose released weights into unauthorized mixtures that bypass safety alignment or licensing terms. Because existing defenses are largely post-hoc and architecture-specific, they provide inconsistent protection across diverse architectures and release formats in practice. To close this gap, we propose \\textsc{Trap}$^{2}$, an architecture-agnostic protection framework that encodes protection into the update during fine-tuning, regardless of whether they are released as adapters or full models. Instead of relying on architecture-dependent approaches, \\textsc{Trap}$^{2}$ uses weight re-scaling as a simple proxy for the merging process. It keeps released weights effective in standalone use, but degrades them under re-scaling that often arises in merging, undermining unauthorized merging.", "AI": {"tldr": "提出了一种无架构依赖的保护框架Trap²，通过在微调过程中加入权重重缩放作为简单代理来防止未经授权的模型合并。", "motivation": "现有的防护措施大多是在后处理阶段且特定于架构，无法提供一致的安全性。为此，需要一种新的方法来解决模型组件被重新组合成不合规混合物的问题，以填补这一治理缺口。", "method": "Trap²通过在微调过程中加入权重重缩放作为简单代理来防止未经授权的合并，并确保发布的权重在单独使用时仍然有效。", "result": "实验结果显示，与现有方法相比，Trap²能够更有效地阻止未经授权的模型合并。", "conclusion": "Trap²提供了一种有效的、无架构依赖的方法来保护模型免受未经授权的重新组合。"}}
{"id": "2601.21896", "pdf": "https://arxiv.org/pdf/2601.21896", "abs": "https://arxiv.org/abs/2601.21896", "authors": ["Hanmo Chen", "Chenghao Xu", "Xu Yang", "Xuan Chen", "Cheng Deng"], "title": "Past- and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Video generation is pivotal to digital media creation, and recent advances in autoregressive video generation have markedly enhanced the efficiency of real-time video synthesis. However, existing approaches generally rely on heuristic KV Cache policies, which ignore differences in token importance in long-term video generation. This leads to the loss of critical spatiotemporal information and the accumulation of redundant, invalid cache, thereby degrading video generation quality and efficiency. To address this limitation, we first observe that token contributions to video generation are highly time-heterogeneous and accordingly propose a novel Past- and Future-Informed KV Cache Policy (PaFu-KV). Specifically, PaFu-KV introduces a lightweight Salience Estimation Head distilled from a bidirectional teacher to estimate salience scores, allowing the KV cache to retain informative tokens while discarding less relevant ones. This policy yields a better quality-efficiency trade-off by shrinking KV cache capacity and reducing memory footprint at inference time. Extensive experiments on benchmarks demonstrate that our method preserves high-fidelity video generation quality while enables accelerated inference, thereby enabling more efficient long-horizon video generation. Our code will be released upon paper acceptance.", "AI": {"tldr": "提出了一种新的KV缓存策略，以提高自回归视频生成的质量和效率", "motivation": "现有方法忽略了令牌重要性差异，导致关键时空信息丢失以及无效缓存积累，影响视频生成质量和效率", "method": "引入轻量级的显著性估计头，通过双向教师模型估算显著性得分，从而优化KV缓存策略保留有用的信息并减少冗余", "result": "实验表明该方法在保持高保真度的同时加快了推断速度，提升了长期视频生成效能", "conclusion": "所提的方法通过改进KV缓存策略，在不牺牲质量的情况下提高了效率"}}
{"id": "2601.21895", "pdf": "https://arxiv.org/pdf/2601.21895", "abs": "https://arxiv.org/abs/2601.21895", "authors": ["Hongyi Zhou", "Jin Zhu", "Erhan Xu", "Kai Ye", "Ying Yang", "Chengchun Shi"], "title": "Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text", "categories": ["cs.CL", "cs.AI", "stat.ML"], "comment": "Accepted by ICLR2026", "summary": "Modern large language models (LLMs) such as GPT, Claude, and Gemini have transformed the way we learn, work, and communicate. Yet, their ability to produce highly human-like text raises serious concerns about misinformation and academic integrity, making it an urgent need for reliable algorithms to detect LLM-generated content. In this paper, we start by presenting a geometric approach to demystify rewrite-based detection algorithms, revealing their underlying rationale and demonstrating their generalization ability. Building on this insight, we introduce a novel rewrite-based detection algorithm that adaptively learns the distance between the original and rewritten text. Theoretically, we demonstrate that employing an adaptively learned distance function is more effective for detection than using a fixed distance. Empirically, we conduct extensive experiments with over 100 settings, and find that our approach demonstrates superior performance over baseline algorithms in the majority of scenarios. In particular, it achieves relative improvements from 57.8\\% to 80.6\\% over the strongest baseline across different target LLMs (e.g., GPT, Claude, and Gemini).", "AI": {"tldr": "论文提出了一个基于几何方法的LLM生成文本检测算法，该算法通过自适应学习原文和重写后的文本之间的距离来提高检测性能。", "motivation": "随着大型语言模型的能力日益增强，它们生成高度逼真的人类文本引发了对错误信息和学术诚信的关注。因此，开发可靠的LLM生成内容检测算法成为当务之急。", "method": "论文提出了一种基于几何的重写基线检测方法，并引入了自适应学习距离函数的新算法，该算法在不同场景下展现出更好的性能。", "result": "实验表明，所提方法在大多数情况下优于现有的基线算法，相对改进率从57.8%到80.6%，针对不同的目标LLM（如GPT、Claude和Gemini）表现尤为出色。", "conclusion": "论文通过自适应学习距离函数的方法提高了检测LLM生成文本的性能，并展示了该方法在多种设置下的优越性。"}}
{"id": "2601.21892", "pdf": "https://arxiv.org/pdf/2601.21892", "abs": "https://arxiv.org/abs/2601.21892", "authors": ["Jian-Feng Cai", "Haixia Liu", "Zhengyi Su", "Chao Wang"], "title": "Improving Classifier-Free Guidance of Flow Matching via Manifold Projection", "categories": ["cs.CV", "cs.AI"], "comment": "24 pages, 14 figures", "summary": "Classifier-free guidance (CFG) is a widely used technique for controllable generation in diffusion and flow-based models. Despite its empirical success, CFG relies on a heuristic linear extrapolation that is often sensitive to the guidance scale. In this work, we provide a principled interpretation of CFG through the lens of optimization. We demonstrate that the velocity field in flow matching corresponds to the gradient of a sequence of smoothed distance functions, which guides latent variables toward the scaled target image set. This perspective reveals that the standard CFG formulation is an approximation of this gradient, where the prediction gap, the discrepancy between conditional and unconditional outputs, governs guidance sensitivity. Leveraging this insight, we reformulate the CFG sampling as a homotopy optimization with a manifold constraint. This formulation necessitates a manifold projection step, which we implement via an incremental gradient descent scheme during sampling. To improve computational efficiency and stability, we further enhance this iterative process with Anderson Acceleration without requiring additional model evaluations. Our proposed methods are training-free and consistently refine generation fidelity, prompt alignment, and robustness to the guidance scale. We validate their effectiveness across diverse benchmarks, demonstrating significant improvements on large-scale models such as DiT-XL-2-256, Flux, and Stable Diffusion 3.5.", "AI": {"tldr": "通过流匹配中的流场视角重新解释分类器自由指导技术，提出了一种基于流形投影的改进方法。", "motivation": "现有分类器自由指导方法在生成控制中存在对引导尺度敏感的问题，本文旨在提供一种更稳健且精确的替代方案。", "method": "通过优化角度分析流匹配中的流场，并引入流形约束下的同伦优化和增量梯度下降方案来改进生成过程。", "result": "该方法提高了生成质量、提示一致性及对引导尺度的鲁棒性，实验在多个大规模模型上均取得显著改善效果。", "conclusion": "本文提出的方法无需额外训练且有效提升了生成任务的性能，验证了其广泛适用性和优越性。"}}
{"id": "2601.21885", "pdf": "https://arxiv.org/pdf/2601.21885", "abs": "https://arxiv.org/abs/2601.21885", "authors": ["Tiwonge Msulira Banda", "Alexandru-Ciprian Zăvoianu"], "title": "Adaptive Surrogate-Based Strategy for Accelerating Convergence Speed when Solving Expensive Unconstrained Multi-Objective Optimisation Problems", "categories": ["cs.NE"], "comment": "Accepted for publication in SWEVO (Swarm and Evolutionary Computation)", "summary": "Multi-Objective Evolutionary Algorithms (MOEAs) have proven effective at solving Multi-Objective Optimisation Problems (MOOPs). However, their performance can be significantly hindered when applied to computationally intensive industrial problems. To address this limitation, we propose an adaptive surrogate modelling approach designed to accelerate the early-stage convergence speed of state-of-the-art MOEAs. This is important because it ensures that a solver can identify optimal or near-optimal solutions with relatively few fitness function evaluations, thereby saving both time and computational resources. Our method employs a two-loop architecture. The outer loop runs a (baseline) host MOEA which carries out true fitness evaluations. The inner loop contains an Adaptive Accelerator that leverages data-driven machine learning (ML) surrogate models to approximate fitness functions. Integrated with NSGA-II and MOEA/D, our approach was tested on 31 widely known benchmark problems and a real-world North Sea fish abundance modelling case study. The results demonstrate that by incorporating Gaussian Process Regression, one-dimensional Convolutional Neural Networks, and Random Forest Regression, our proposed approach significantly accelerates the convergence speed of MOEAs in the early phases of optimisation.", "AI": {"tldr": "提出了一种自适应代理模型策略，旨在加速解决昂贵的无约束多目标优化问题时的收敛速度。", "motivation": "为了克服传统多目标进化算法在处理计算密集型工业问题中的性能瓶颈，作者提出了基于代理的加速策略以提高算法早期阶段的收敛效率。", "method": "采用两层架构：外环运行基准主机MOEA进行真实适应度评估；内环包含自适应加速器利用数据驱动机器学习代理模型近似适应度函数。该方法与NSGA-II和MOEA/D集成，测试了31个广泛认可的基准问题以及一个现实世界中的北海鱼类丰度建模案例。", "result": "实验结果显示通过融入高斯过程回归、一维卷积神经网络及随机森林回归等技术，所提出的策略在优化早期阶段显著加快了MOEA的收敛速度。", "conclusion": "该研究展示了一种有效的自适应代理模型方法能够加速昂贵多目标问题的求解速度，在实际应用中具有重要的价值。"}}
{"id": "2601.21884", "pdf": "https://arxiv.org/pdf/2601.21884", "abs": "https://arxiv.org/abs/2601.21884", "authors": ["Pratik Ingle", "Jørn Lambertsen", "Kasper Støy", "Andres Faina"], "title": "Multi-Modular MANTA-RAY: A Modular Soft Surface Platform for Distributed Multi-Object Manipulation", "categories": ["cs.RO"], "comment": "8 pages", "summary": "Manipulation surfaces control objects by actively deforming their shape rather than directly grasping them. While dense actuator arrays can generate complex deformations, they also introduce high degrees of freedom (DOF), increasing system complexity and limiting scalability. The MANTA-RAY (Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation densitY) platform addresses these challenges by leveraging a soft, fabric-based surface with reduced actuator density to manipulate fragile and heterogeneous objects. Previous studies focused on single-module implementations supported by four actuators, whereas the feasibility and benefits of a scalable, multi-module configuration remain unexplored. In this work, we present a distributed, modular, and scalable variant of the MANTA-RAY platform that maintains manipulation performance with a reduced actuator density. The proposed multi-module MANTA-RAY platform and control strategy employs object passing between modules and a geometric transformation driven PID controller that directly maps tilt-angle control outputs to actuator commands, eliminating the need for extensive data-driven or black-box training. We evaluate system performance in simulation across surface configurations of varying modules (3x3 and 4x4) and validate its feasibility through experiments on a physical 2x2 hardware prototype. The system successfully manipulates objects with diverse geometries, masses, and textures including fragile items such as eggs and apples as well as enabling parallel manipulation. The results demonstrate that the multi-module MANTA-RAY improves scalability and enables coordinated manipulation of multiple objects across larger areas, highlighting its potential for practical, real-world applications.", "AI": {"tldr": "该论文提出了一种分布式模块化MANTA-RAY平台，用于控制物体的表面变形以实现多对象同时操控。", "motivation": "传统的密集执行器阵列虽然能生成复杂的形变，但引入了高自由度和复杂性，限制了可扩展性。本研究旨在通过减少执行器密度来简化系统并提高可扩展性。", "method": "论文设计了一个软表面平台，该平台由多模块组成，并使用几何变换驱动的PID控制器直接将倾斜角度控制输出映射到执行器命令，无需大量数据训练。", "result": "在仿真和物理原型实验中展示了系统的性能，包括3x3、4x4等不同配置，能够操控各种形状、质量和纹理的物体，甚至脆弱物品如鸡蛋和苹果，并实现平行操作。", "conclusion": "该论文证明了多模块MANTA-RAY平台提高了可扩展性，支持在更广泛的区域协调控制多个对象，具有实际应用潜力。"}}
{"id": "2601.21879", "pdf": "https://arxiv.org/pdf/2601.21879", "abs": "https://arxiv.org/abs/2601.21879", "authors": ["Rem Collier", "Katharine Beaumont", "Andrei Ciortea"], "title": "astra-langchain4j: Experiences Combining LLMs and Agent Programming", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Given the emergence of Generative AI over the last two years and the increasing focus on Agentic AI as a form of Multi-Agent System it is important to explore both how such technologies can impact the use of traditional Agent Toolkits and how the wealth of experience encapsulated in those toolkits can influence the design of the new agentic platforms. This paper presents an overview of our experience developing a prototype large language model (LLM) integration for the ASTRA programming language. It presents a brief overview of the toolkit, followed by three example implementations, concluding with a discussion of the experiences garnered through the examples.", "AI": {"tldr": "开发了一个原型大型语言模型（LLM）与ASTRA编程语言的集成", "motivation": "探索生成式AI和代理编程系统的结合如何影响传统代理工具包，并讨论这些经验如何塑造新的代理平台设计", "method": "提供了ASTRA编程语言工具包的一个简要概述，随后展示了三个实现示例", "result": "通过示例获得了关于LLM与代理系统集成的经验总结", "conclusion": "基于经验和案例分析了将大型语言模型整合到代理系统的潜在影响"}}
{"id": "2601.21877", "pdf": "https://arxiv.org/pdf/2601.21877", "abs": "https://arxiv.org/abs/2601.21877", "authors": ["Chen Wang", "Sijie Ma", "Zeyuan Ma", "Yue-Jiao Gong"], "title": "Evolution of Benchmark: Black-Box Optimization Benchmark Design through Large Language Model", "categories": ["cs.NE"], "comment": null, "summary": "Benchmark Design in Black-Box Optimization (BBO) is a fundamental yet open-ended topic. Early BBO benchmarks are predominantly human-crafted, introducing expert bias and constraining diversity. Automating this design process can relieve the human-in-the-loop burden while enhancing diversity and objectivity. We propose Evolution of Benchmark (EoB), an automated BBO benchmark designer empowered by the large language model (LLM) and its program evolution capability. Specifically, we formulate benchmark design as a bi-objective optimization problem towards maximizing (i) landscape diversity and (ii) algorithm-differentiation ability across a portfolio of BBO solvers. Under this paradigm, EoB iteratively prompts LLM to evolve a population of benchmark programs and employs a reflection-based scheme to co-evolve the landscape and its corresponding program. Comprehensive experiments validate our EoB is a competitive candidate in multi-dimensional usages: 1) Benchmarking BBO algorithms; 2) Training and testing learning-assisted BBO algorithms; 3) Extending proxy for expensive real-world problems.", "AI": {"tldr": "本文提出了一种利用大型语言模型（LLM）自动设计黑盒优化问题基准的方法EoB。", "motivation": "早期的黑盒优化基准大多由人工创建，引入了专家偏见并限制了多样性。通过自动化这一过程可以减轻人力负担并提高多样性和客观性。", "method": "将基准设计视为一个双目标优化问题，并利用大型语言模型（LLM）及其程序演化能力迭代生成一组具有高度多样性并且能够区分不同算法性能的黑盒优化测试用例。", "result": "实验验证了EoB在多方面应用中是一种有竞争力的选择：1)评估黑盒优化算法；2)训练和测试基于学习辅助的黑盒优化算法；3)扩展昂贵真实世界问题的成本效益代理。", "conclusion": "自动化设计基准能够提供多样化且客观的黑盒优化测试环境，有助于提高相关研究的有效性和实用性。"}}
{"id": "2601.21876", "pdf": "https://arxiv.org/pdf/2601.21876", "abs": "https://arxiv.org/abs/2601.21876", "authors": ["He Li", "Zhaowei Chen", "Rui Gao", "Guoliang Li", "Qi Hao", "Shuai Wang", "Chengzhong Xu"], "title": "LLM-Driven Scenario-Aware Planning for Autonomous Driving", "categories": ["cs.RO"], "comment": null, "summary": "Hybrid planner switching framework (HPSF) for autonomous driving needs to reconcile high-speed driving efficiency with safe maneuvering in dense traffic. Existing HPSF methods often fail to make reliable mode transitions or sustain efficient driving in congested environments, owing to heuristic scene recognition and low-frequency control updates. To address the limitation, this paper proposes LAP, a large language model (LLM) driven, adaptive planning method, which switches between high-speed driving in low-complexity scenes and precise driving in high-complexity scenes, enabling high qualities of trajectory generation through confined gaps. This is achieved by leveraging LLM for scene understanding and integrating its inference into the joint optimization of mode configuration and motion planning. The joint optimization is solved using tree-search model predictive control and alternating minimization. We implement LAP by Python in Robot Operating System (ROS). High-fidelity simulation results show that the proposed LAP outperforms other benchmarks in terms of both driving time and success rate.", "AI": {"tldr": "本文提出了一种基于大语言模型的自适应规划方法LAP，以提高自动驾驶在复杂交通环境中的性能。", "motivation": "现有混合规划切换框架（HPSF）在复杂的交通环境中难以实现可靠模式转换或保持高效的驾驶。为了解决这一问题，文章提出了使用大语言模型进行场景理解和融合的方法，从而改善路径生成和驾驶质量。", "method": "LAP通过结合大语言模型的推断与模式配置及运动规划的联合优化来工作。该联合优化利用树搜索模型预测控制和交替最小化技术解决。", "result": "高保真模拟结果显示提出的LAP方法在行驶时间和成功率方面优于其他基准。", "conclusion": "通过结合大语言模型和先进的优化算法，可以提高自动驾驶系统在复杂交通环境下的性能表现。"}}
{"id": "2601.21872", "pdf": "https://arxiv.org/pdf/2601.21872", "abs": "https://arxiv.org/abs/2601.21872", "authors": ["Yao Zhang", "Shijie Tang", "Zeyu Li", "Zhen Han", "Volker Tresp"], "title": "WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents", "categories": ["cs.AI"], "comment": "ICLR 2026", "summary": "Web agents hold great potential for automating complex computer tasks, yet their interactions involve long-horizon, sequential decision-making with irreversible actions. In such settings, outcome-based supervision is sparse and delayed, often rewarding incorrect trajectories and failing to support inference-time scaling. This motivates the use of Process Reward Models (WebPRMs) for web navigation, but existing approaches remain limited: scalar WebPRMs collapse progress into coarse, weakly grounded signals, while checklist-based WebPRMs rely on brittle template matching that fails under layout or semantic changes and often mislabels superficially correct actions as successful, providing little insight or interpretability. To address these challenges, we introduce WebArbiter, a reasoning-first, principle-inducing WebPRM that formulates reward modeling as text generation, producing structured justifications that conclude with a preference verdict and identify the action most conducive to task completion under the current context. Training follows a two-stage pipeline: reasoning distillation equips the model with coherent principle-guided reasoning, and reinforcement learning corrects teacher biases by directly aligning verdicts with correctness, enabling stronger generalization. To support systematic evaluation, we release WebPRMBench, a comprehensive benchmark spanning four diverse web environments with rich tasks and high-quality preference annotations. On WebPRMBench, WebArbiter-7B outperforms the strongest baseline, GPT-5, by 9.1 points. In reward-guided trajectory search on WebArena-Lite, it surpasses the best prior WebPRM by up to 7.2 points, underscoring its robustness and practical value in real-world complex web tasks.", "AI": {"tldr": "本文提出了一种基于原则引导的推理过程奖励模型WebArbiter，用于改善网络代理在复杂任务中的决策性能。", "motivation": "现有的网页导航过程奖励模型存在局限性，如无法提供详细的反馈和难以应对变化。因此需要一种能够生成结构化解释并支持任务完成的新型模型。", "method": "通过引入WebArbiter，使用文本生成技术来构建奖励模型，并采用两阶段训练方法：推理提炼使模型具备连贯的原则引导式推理能力；强化学习纠正教师偏见，直接将判断与正确性对齐。同时发布了一个全面的基准测试集WebPRMBench。", "result": "在WebPRMBench上，WebArbiter-7B比最强基线GPT-5高出9.1分，在WebArena-Lite上的奖励导向轨迹搜索中超越了最佳先前过程奖励模型多达7.2分。", "conclusion": "结果表明，WebArbiter具备强大的泛化能力和实用性，能有效支持实际世界中的复杂网页任务。"}}
{"id": "2601.21866", "pdf": "https://arxiv.org/pdf/2601.21866", "abs": "https://arxiv.org/abs/2601.21866", "authors": ["Evandro S. Ortigossa", "Guy Lutsker", "Eran Segal"], "title": "MoHETS: Long-term Time Series Forecasting with Mixture-of-Heterogeneous-Experts", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Real-world multivariate time series can exhibit intricate multi-scale structures, including global trends, local periodicities, and non-stationary regimes, which makes long-horizon forecasting challenging. Although sparse Mixture-of-Experts (MoE) approaches improve scalability and specialization, they typically rely on homogeneous MLP experts that poorly capture the diverse temporal dynamics of time series data. We address these limitations with MoHETS, an encoder-only Transformer that integrates sparse Mixture-of-Heterogeneous-Experts (MoHE) layers. MoHE routes temporal patches to a small subset of expert networks, combining a shared depthwise-convolution expert for sequence-level continuity with routed Fourier-based experts for patch-level periodic structures. MoHETS further improves robustness to non-stationary dynamics by incorporating exogenous information via cross-attention over covariate patch embeddings. Finally, we replace parameter-heavy linear projection heads with a lightweight convolutional patch decoder, improving parameter efficiency, reducing training instability, and allowing a single model to generalize across arbitrary forecast horizons. We validate across seven multivariate benchmarks and multiple horizons, with MoHETS consistently achieving state-of-the-art performance, reducing the average MSE by $12\\%$ compared to strong recent baselines, demonstrating effective heterogeneous specialization for long-term forecasting.", "AI": {"tldr": "该论文提出了MoHETS模型，用于长时期时间序列的预测。", "motivation": "现实世界中的多变量时间序列具有复杂的多层次结构，使得长期预报变得困难。现有的Mixture-of-Experts（混合专家）方法虽然改进了可扩展性和专业化，但通常依赖同质MLP专家，难以捕捉到时间序列数据中多样化的动态变化。", "method": "MoHETS是一种仅编码器的Transformer模型，它集成了稀疏的异构专家层。通过深度卷积共享专家和基于傅里叶的路由专家结合来处理时序片段，并且引入了跨注意力机制用于外生信息集成，以提高对非稳态动力学的鲁棒性。", "result": "实验结果表明，在七个不同的多变量基准测试中，与强大的近期基线相比，MoHETS模型在所有时间范围内均达到了最先进的性能，平均MSE降低了12%。", "conclusion": "通过引入异构专家方法和改进的架构设计，MoHETS有效提升了长期时间序列预报的表现。"}}
{"id": "2601.21864", "pdf": "https://arxiv.org/pdf/2601.21864", "abs": "https://arxiv.org/abs/2601.21864", "authors": ["Jinhao Pan", "Chahat Raj", "Anjishnu Mukherjee", "Sina Mansouri", "Bowen Wei", "Shloka Yada", "Ziwei Zhu"], "title": "KnowBias: Mitigating Social Bias in LLMs via Know-Bias Neuron Enhancement", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) exhibit social biases that reinforce harmful stereotypes, limiting their safe deployment. Most existing debiasing methods adopt a suppressive paradigm by modifying parameters, prompts, or neurons associated with biased behavior; however, such approaches are often brittle, weakly generalizable, data-inefficient, and prone to degrading general capability. We propose \\textbf{KnowBias}, a lightweight and conceptually distinct framework that mitigates bias by strengthening, rather than suppressing, neurons encoding bias-knowledge. KnowBias identifies neurons encoding bias knowledge using a small set of bias-knowledge questions via attribution-based analysis, and selectively enhances them at inference time. This design enables strong debiasing while preserving general capabilities, generalizes across bias types and demographics, and is highly data efficient, requiring only a handful of simple yes/no questions and no retraining. Experiments across multiple benchmarks and LLMs demonstrate consistent state-of-the-art debiasing performance with minimal utility degradation. Data and code are available at https://github.com/JP-25/KnowBias.", "AI": {"tldr": "提出了一种减轻大型语言模型（LLMs）中社会偏见的新框架KnowBias，通过加强而非抑制编码偏见知识的神经元来实现。", "motivation": "大多数现有的去偏方法依赖于修改参数、提示或与偏见行为相关的神经元，这使得这些方法往往脆弱、泛化能力弱且数据效率低。因此，需要一种更有效的方法来减轻LLMs中的社会偏见。", "method": "KnowBias通过使用少量的偏见知识问题进行归因分析来识别编码偏见知识的神经元，并在推理时选择性地增强它们。这种方法不仅能够显著降低偏见，还能保持模型的一般能力。", "result": "实验表明，在多个基准和LLMs上，KnowBias展示了最先进的去偏性能，同时对模型功能的影响最小。", "conclusion": "知Bias提供了一种轻量级且概念上新颖的框架来减轻大型语言模型中的社会偏见，通过增强而非抑制神经元编码偏见知识的方法实现。"}}
{"id": "2601.21857", "pdf": "https://arxiv.org/pdf/2601.21857", "abs": "https://arxiv.org/abs/2601.21857", "authors": ["Taewon Kang"], "title": "Trajectory-Guided Diffusion for Foreground-Preserving Background Generation in Multi-Layer Documents", "categories": ["cs.CV"], "comment": "47 pages, 36 figures", "summary": "We present a diffusion-based framework for document-centric background generation that achieves foreground preservation and multi-page stylistic consistency through latent-space design rather than explicit constraints. Instead of suppressing diffusion updates or applying masking heuristics, our approach reinterprets diffusion as the evolution of stochastic trajectories through a structured latent space. By shaping the initial noise and its geometric alignment, background generation naturally avoids designated foreground regions, allowing readable content to remain intact without auxiliary mechanisms. To address the long-standing issue of stylistic drift across pages, we decouple style control from text conditioning and introduce cached style directions as persistent vectors in latent space. Once selected, these directions constrain diffusion trajectories to a shared stylistic subspace, ensuring consistent appearance across pages and editing iterations. This formulation eliminates the need for repeated prompt-based style specification and provides a more stable foundation for multi-page generation. Our framework admits a geometric and physical interpretation, where diffusion paths evolve on a latent manifold shaped by preferred directions, and foreground regions are rarely traversed as a consequence of trajectory initialization rather than explicit exclusion. The proposed method is training-free, compatible with existing diffusion backbones, and produces visually coherent, foreground-preserving results across complex documents. By reframing diffusion as trajectory design in latent space, we offer a principled approach to consistent and structured generative modeling.", "AI": {"tldr": "提出了一种基于扩散的框架，用于多层文档中的背景生成，该框架能够在不破坏前景的情况下保持背景的一致性。", "motivation": "旨在解决传统方法中背景生成时对前景区域的影响和跨页面风格漂移的问题。", "method": "通过在隐空间设计轨迹引导式扩散来避免前景区域，引入缓存样式方向以保证多页一致性，并且该框架无需训练即可与现有扩散后端兼容。", "result": "产生的结果具有视觉连贯性并且保持了背景的一致性和前景的完整性。", "conclusion": "此方法通过重新解释扩散过程为隐空间中的轨迹设计提供了一种原理性的生成模型方法，适用于多页文档的一致性背景生成。"}}
{"id": "2601.21856", "pdf": "https://arxiv.org/pdf/2601.21856", "abs": "https://arxiv.org/abs/2601.21856", "authors": ["Shujaat Khan", "Syed Muhammad Atif", "Jaeyoung Huh", "Syed Saad Azhar"], "title": "Blind Ultrasound Image Enhancement via Self-Supervised Physics-Guided Degradation Modeling", "categories": ["eess.IV", "cs.CV", "stat.ML"], "comment": "11 pages, 13 figures", "summary": "Ultrasound (US) interpretation is hampered by multiplicative speckle, acquisition blur from the point-spread function (PSF), and scanner- and operator-dependent artifacts. Supervised enhancement methods assume access to clean targets or known degradations; conditions rarely met in practice. We present a blind, self-supervised enhancement framework that jointly deconvolves and denoises B-mode images using a Swin Convolutional U-Net trained with a \\emph{physics-guided} degradation model. From each training frame, we extract rotated/cropped patches and synthesize inputs by (i) convolving with a Gaussian PSF surrogate and (ii) injecting noise via either spatial additive Gaussian noise or complex Fourier-domain perturbations that emulate phase/magnitude distortions. For US scans, clean-like targets are obtained via non-local low-rank (NLLR) denoising, removing the need for ground truth; for natural images, the originals serve as targets. Trained and validated on UDIAT~B, JNU-IFM, and XPIE Set-P, and evaluated additionally on a 700-image PSFHS test set, the method achieves the highest PSNR/SSIM across Gaussian and speckle noise levels, with margins that widen under stronger corruption. Relative to MSANN, Restormer, and DnCNN, it typically preserves an extra $\\sim$1--4\\,dB PSNR and 0.05--0.15 SSIM in heavy Gaussian noise, and $\\sim$2--5\\,dB PSNR and 0.05--0.20 SSIM under severe speckle. Controlled PSF studies show reduced FWHM and higher peak gradients, evidence of resolution recovery without edge erosion. Used as a plug-and-play preprocessor, it consistently boosts Dice for fetal head and pubic symphysis segmentation. Overall, the approach offers a practical, assumption-light path to robust US enhancement that generalizes across datasets, scanners, and degradation types.", "AI": {"tldr": "该论文提出了一个盲自监督增强框架，通过物理引导的退化模型联合去卷积和去噪B模式图像。", "motivation": "超声成像受到斑点噪声、点扩散函数引起的采集模糊以及扫描器和操作者依赖性伪影的影响。传统的监督增强方法需要干净的目标或已知退化条件，这在实践中很少满足。", "method": "提出的方法利用Swin卷积U-Net训练，并通过物理引导的退化模型合成输入。从每个训练帧中提取旋转/裁剪补丁并模拟斑点噪声和傅里叶域扰动生成输入。", "result": "该方法在不同的超声图像数据集上取得了最高的PSNR/SSIM，特别是在严重的高斯噪声和斑点噪声下表现更优，并且提高了胎儿头部和耻骨联合的分割Dice系数。", "conclusion": "提出的方法提供了一种实用、假设轻量化的路径来增强超声图像，在不同的数据集、扫描仪和退化类型上具有良好的泛化能力。"}}
{"id": "2601.21847", "pdf": "https://arxiv.org/pdf/2601.21847", "abs": "https://arxiv.org/abs/2601.21847", "authors": ["Zechuan Huang", "Zhiguang Cao", "Hongshu Guo", "Yue-Jiao Gong", "Zeyuan Ma"], "title": "READY: Reward Discovery for Meta-Black-Box Optimization", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Meta-Black-Box Optimization (MetaBBO) is an emerging avenue within Optimization community, where algorithm design policy could be meta-learned by reinforcement learning to enhance optimization performance. So far, the reward functions in existing MetaBBO works are designed by human experts, introducing certain design bias and risks of reward hacking. In this paper, we use Large Language Model~(LLM) as an automated reward discovery tool for MetaBBO. Specifically, we consider both effectiveness and efficiency sides. On effectiveness side, we borrow the idea of evolution of heuristics, introducing tailored evolution paradigm in the iterative LLM-based program search process, which ensures continuous improvement. On efficiency side, we additionally introduce multi-task evolution architecture to support parallel reward discovery for diverse MetaBBO approaches. Such parallel process also benefits from knowledge sharing across tasks to accelerate convergence. Empirical results demonstrate that the reward functions discovered by our approach could be helpful for boosting existing MetaBBO works, underscoring the importance of reward design in MetaBBO. We provide READY's project at https://anonymous.4open.science/r/ICML_READY-747F.", "AI": {"tldr": "该论文提出了一种自动发现元黑盒优化中奖励函数的方法，使用大型语言模型（LLM）作为工具。", "motivation": "现有元黑盒优化方法中的奖励函数由人工设计，存在设计偏见和奖励作弊的风险。因此，作者希望利用大型语言模型来自动化这一过程，并提高效率与效果。", "method": "该研究采用了进化的启发式算法思想，在LLM的迭代搜索过程中引入了定制的进化范式以确保持续改进；同时采用多任务并行架构支持多个元黑盒优化方法中的奖励函数发现，加速收敛。", "result": "实验结果表明所提出的奖励函数能够显著提高现有元黑盒优化工作的性能，证明了合理设计奖励的重要性。", "conclusion": "通过使用大型语言模型自动化奖励发现过程，可以有效提升元黑盒优化算法的性能，并减少人工设计中的偏见和风险。"}}
{"id": "2601.21846", "pdf": "https://arxiv.org/pdf/2601.21846", "abs": "https://arxiv.org/abs/2601.21846", "authors": ["Konstantinos Varsos", "Adamantia Stamou", "George D. Stamoulis", "Vasillios A. Siris"], "title": "Optimal Energy-Aware Service Management in Future Networks with a Gamified Incentives Mechanism", "categories": ["cs.ET", "cs.GT"], "comment": null, "summary": "As energy demands surge across ICT infrastructures, service providers must engage users in sustainable practices while maintaining the Quality of Experience (QoE) at acceptable levels. In this paper, we introduce such an approach, leveraging gamified incentives and a model for user's acceptance on incentives, thus encouraging energy-efficient behaviors such as adaptive bitrate streaming. Each user is characterized by an environmental sensitivity factor and a private incentive threshold, shaping probabilistic responses to energy-saving offers. A serious-game mechanism based on positive behavioral reinforcement and rewards of the users, due to their inclusion in top-K and bottom-M rankings, fosters peer comparison and competition, thus transforming passive acceptance into active engagement. Moreover, within a Stackelberg game formulation, the video streaming service provider--acting as the strategic leader--optimizes both incentive levels and game parameters to achieve network-wide energy and traffic reductions, while adhering to budgetary constraints. This structured approach empowers providers with proactive, application-level control over energy consumption, offering them measurable benefits such as reduced high-bitrate traffic and increased participation in energy-saving behaviors, while also considering user satisfaction. The results of our simulations show that indeed gamification boosts significantly user participation and energy savings provided that the incentive and game parameters are chosen optimally.", "AI": {"tldr": "通过引入游戏化激励机制，优化未来网络中的能源感知服务管理，以促进用户节能减排行为。", "motivation": "随着信息技术基础设施中能耗需求的增加，服务商需要鼓励用户参与可持续实践，并保持可接受的质量体验。本文旨在利用游戏化激励和用户的接受模型来提高能效。", "method": "通过建立一个基于积极行为强化的游戏机制，以及视频流服务提供商在斯塔克尔伯格博弈框架中的优化策略，来实现网络范围内的能耗降低和流量减少。", "result": "模拟结果显示，在适当选择激励和游戏参数的情况下，游戏化可以显著增加用户的参与度和能源节约效果。", "conclusion": "通过结构化的游戏化方法，服务商能够主动控制应用程序级别的能耗，并获得包括降低高比特率流量在内的可测量的好处。"}}
{"id": "2601.21844", "pdf": "https://arxiv.org/pdf/2601.21844", "abs": "https://arxiv.org/abs/2601.21844", "authors": ["So Fukuhara", "Abdallah Alabdallah", "Nuwan Gunasekara", "Slawomir Nowaczyk"], "title": "Bridging Forecast Accuracy and Inventory KPIs: A Simulation-Based Software Framework", "categories": ["cs.AI", "cs.SE"], "comment": "12 pages, 6 figures", "summary": "Efficient management of spare parts inventory is crucial in the automotive aftermarket, where demand is highly intermittent and uncertainty drives substantial cost and service risks. Forecasting is therefore central, but the quality of a forecasting model should be judged not by statistical accuracy (e.g., MAE, RMSE, IAE) but rather by its impact on key operational performance indicators (KPIs), such as total cost and service level. Yet most existing work evaluates models exclusively using accuracy metrics, and the relationship between these metrics and operational KPIs remains poorly understood. To address this gap, we propose a decision-centric simulation software framework that enables systematic evaluation of forecasting model in realistic inventory management setting. The framework comprises: (i) a synthetic demand generator tailored to spare-parts demand characteristics, (ii) a flexible forecasting module that can host arbitrary predictive models, and (iii) an inventory control simulator that consumes the forecasts and computes operational KPIs. This closed-loop setup enables researchers to evaluate models not only in terms of statistical error but also in terms of their downstream implications for inventory decisions. Using a wide range of simulation scenarios, we show that improvements in conventional accuracy metrics do not necessarily translate into better operational performance, and that models with similar statistical error profiles can induce markedly different cost-service trade-offs. We analyze these discrepancies to characterize how specific aspects of forecast performance affect inventory outcomes and derive guidance for model selection. Overall, the framework operationalizes the link between demand forecasting and inventory management, shifting evaluation from purely predictive accuracy toward operational relevance in the automotive aftermarket and related domains.", "AI": {"tldr": "该论文提出了一种基于模拟的软件框架，用于评估预测模型在库存管理中的实际效果。", "motivation": "目前大部分研究仅通过统计准确性来评价预测模型的效果，而忽视了对关键运营性能指标（如总成本和服务水平）的影响。因此，需要一个能够系统地评估这些模型的实际影响的方法。", "method": "该框架包括：需求生成器、可容纳任意预测模型的预测模块和库存控制模拟器。此闭环设置允许研究者从统计误差和下游库存决策影响两个方面来评价模型。", "result": "通过多种仿真场景，表明提高传统准确性指标不一定意味着更好的运营性能，并且具有相似统计误差配置文件的模型可以引发明显不同的成本-服务权衡。", "conclusion": "该框架将需求预测与库存管理之间的联系进行操作化，评估从单纯的预测准确性转向了运营相关性。"}}
{"id": "2601.21839", "pdf": "https://arxiv.org/pdf/2601.21839", "abs": "https://arxiv.org/abs/2601.21839", "authors": ["Ander Artola Velasco", "Dimitrios Rontogiannis", "Stratis Tsirtsis", "Manuel Gomez-Rodriguez"], "title": "Test-Time Compute Games", "categories": ["cs.CY", "cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "Test-time compute has emerged as a promising strategy to enhance the reasoning abilities of large language models (LLMs). However, this strategy has in turn increased how much users pay cloud-based providers offering LLM-as-a-service, since providers charge users for the amount of test-time compute they use to generate an output. In our work, we show that the market of LLM-as-a-service is socially inefficient: providers have a financial incentive to increase the amount of test-time compute, even if this increase contributes little to the quality of the outputs. To address this inefficiency, we introduce a reverse second-price auction mechanism where providers bid their offered price and (expected) quality for the opportunity to serve a user, and users pay proportionally to the marginal value generated by the winning provider relative to the second-highest bidder. To illustrate and complement our theoretical results, we conduct experiments with multiple instruct models from the $\\texttt{Llama}$ and $\\texttt{Qwen}$ families, as well as reasoning models distilled from $\\texttt{DeepSeek-R1}$, on math and science benchmark datasets.", "AI": {"tldr": "本文提出了一种反向第二价格拍卖机制，以解决云服务提供商过度增加测试时间计算导致的市场效率低下问题。", "motivation": "由于云计算提供者按使用量收费，用户为了提高语言模型推理能力而增加了测试时间计算。然而，这种做法使市场变得不那么高效：提供者倾向于通过增加计算量来获取更多收益，即使这并不能显著提升输出质量。因此作者提出解决方案以优化资源分配。", "method": "引入了一种新的拍卖机制，其中供应方（即提供商）出价其服务价格和预期服务质量，而需求方（用户）根据获胜供应商相对于第二高价投标者产生的边际价值支付费用。", "result": "通过在多个指令模型和推理模型上进行实验，验证了新机制的理论效果。这些模型来自不同的语言家族，并且测试集包括数学和科学基准数据集。", "conclusion": "该方法有助于降低由于计算增加导致的成本上升问题，并能更有效地利用资源以提高服务质量与用户满意度"}}
{"id": "2601.21837", "pdf": "https://arxiv.org/pdf/2601.21837", "abs": "https://arxiv.org/abs/2601.21837", "authors": ["Xiaoshan Yu", "Shangshang Yang", "Ziwen Wang", "Haiping Ma", "Xingyi Zhang"], "title": "Trustworthy Intelligent Education: A Systematic Perspective on Progress, Challenges, and Future Directions", "categories": ["cs.CY", "cs.AI", "cs.IR"], "comment": "9 pages, 3figures", "summary": "In recent years, trustworthiness has garnered increasing attention and exploration in the field of intelligent education, due to the inherent sensitivity of educational scenarios, such as involving minors and vulnerable groups, highly personalized learning data, and high-stakes educational outcomes. However, existing research either focuses on task-specific trustworthy methods without a holistic view of trustworthy intelligent education, or provides survey-level discussions that remain high-level and fragmented, lacking a clear and systematic categorization. To address these limitations, in this paper, we present a systematic and structured review of trustworthy intelligent education. Specifically, We first organize intelligent education into five representative task categories: learner ability assessment, learning resource recommendation, learning analytics, educational content understanding, and instructional assistance. Building on this task landscape, we review existing studies from five trustworthiness perspectives, including safety and privacy, robustness, fairness, explainability, and sustainability, and summarize and categorize the research methodologies and solution strategies therein. Finally, we summarize key challenges and discuss future research directions. This survey aims to provide a coherent reference framework and facilitate a clearer understanding of trustworthiness in intelligent education.", "AI": {"tldr": "本文系统性地回顾了智能教育中的可信问题，将其分为五个任务类别，并从五个信任视角总结现有研究方法和解决方案。", "motivation": "当前关于可信智能教育的研究要么局限于特定任务的方法而没有整体视图，要么停留在高层面的概述，缺乏系统的分类。因此，本文旨在提供一个连贯的参考框架，促进对智能教育中可信性的理解。", "method": "首先将智能教育分为五个代表性任务类别：学习能力评估、学习资源推荐、学习分析、教育内容理解和教学辅助，并从安全和隐私、鲁棒性、公平性、可解释性和可持续性五个信任视角进行系统回顾，总结现有研究方法和解决方案。", "result": "本文概述了可信智能教育中的主要挑战，并讨论了未来的研究方向。", "conclusion": "通过提供一个连贯的参考框架，促进对智能教育中可信性的理解和进一步发展。"}}
{"id": "2601.21830", "pdf": "https://arxiv.org/pdf/2601.21830", "abs": "https://arxiv.org/abs/2601.21830", "authors": ["Francesca Filice", "Edoardo De Rose", "Simone Bartucci", "Francesco Calimeri", "Simona Perri"], "title": "Looking Beyond Accuracy: A Holistic Benchmark of ECG Foundation Models", "categories": ["cs.AI"], "comment": null, "summary": "The electrocardiogram (ECG) is a cost-effective, highly accessible and widely employed diagnostic tool. With the advent of Foundation Models (FMs), the field of AI-assisted ECG interpretation has begun to evolve, as they enable model reuse across different tasks by relying on embeddings. However, to responsibly employ FMs, it is crucial to rigorously assess to which extent the embeddings they produce are generalizable, particularly in error-sensitive domains such as healthcare. Although prior works have already addressed the problem of benchmarking ECG-expert FMs, they focus predominantly on the evaluation of downstream performance. To fill this gap, this study aims to find an in-depth, comprehensive benchmarking framework for FMs, with a specific focus on ECG-expert ones. To this aim, we introduce a benchmark methodology that complements performance-based evaluation with representation-level analysis, leveraging SHAP and UMAP techniques. Furthermore, we rely on the methodology for carrying out an extensive evaluation of several ECG-expert FMs pretrained via state-of-the-art techniques over different cross-continental datasets and data availability settings; this includes ones featuring data scarcity, a fairly common situation in real-world medical scenarios. Experimental results show that our benchmarking protocol provides a rich insight of ECG-expert FMs' embedded patterns, enabling a deeper understanding of their representational structure and generalizability.", "AI": {"tldr": "该论文提出了一种全面的基准测试框架，用于评估心电图基础模型（ECG-FMs）的表现和表示能力。", "motivation": "当前对ECG基础模型的评估主要集中在下游任务性能上，缺乏对其表示能力和泛化性的深入分析。因此，需要一种更综合的方法来确保这些模型在医疗领域的可靠应用。", "method": "提出了一种结合SHAP和UMAP技术的新基准测试方法，用于全面评估不同跨大陆数据集上的ECG基础模型，并且特别关注数据稀缺情况下的表现。", "result": "实验结果显示，新提出的基准测试框架能够提供丰富的关于ECG基础模型嵌入模式的信息，有助于深入了解这些模型的表征结构和泛化能力。", "conclusion": "该研究提出了一种全面评估ECG基础模型的方法，强调了在医疗领域中对模型表示能力和泛化性进行深入分析的重要性。"}}
{"id": "2601.21829", "pdf": "https://arxiv.org/pdf/2601.21829", "abs": "https://arxiv.org/abs/2601.21829", "authors": ["Bsher Karbouj", "Baha Eddin Gaaloul", "Jorg Kruger"], "title": "GAZELOAD A Multimodal Eye-Tracking Dataset for Mental Workload in Industrial Human-Robot Collaboration", "categories": ["cs.RO"], "comment": null, "summary": "This article describes GAZELOAD, a multimodal dataset for mental workload estimation in industrial human-robot collaboration. The data were collected in a laboratory assembly testbed where 26 participants interacted with two collaborative robots (UR5 and Franka Emika Panda) while wearing Meta ARIA smart glasses. The dataset time-synchronizes eye-tracking signals (pupil diameter, fixations, saccades, eye gaze, gaze transition entropy, fixation dispersion index) with environmental real-time and continuous measurements (illuminance) and task and robot context (bench, task block, induced faults), under controlled manipulations of task difficulty and ambient conditions. For each participant and workload-graded task block, we provide CSV files with ocular metrics aggregated into 250 ms windows, environmental logs, and self-reported mental workload ratings on a 1-10 Likert scale, organized in participant-specific folders alongside documentation. These data can be used to develop and benchmark algorithms for mental workload estimation, feature extraction, and temporal modeling in realistic industrial HRC scenarios, and to investigate the influence of environmental factors such as lighting on eye-based workload markers.", "AI": {"tldr": "创建了一个用于工业人机协作中精神负荷估计的多模态眼动追踪数据集GAZELOAD。", "motivation": "为了开发和评估在现实工业人机协作场景中的精神负荷估计算法，以及研究环境因素如光照对基于眼睛的精神负荷标记的影响", "method": "26名参与者佩戴Meta ARIA智能眼镜，在实验室组装测试台中与两种协作机器人（UR5和Franka Emika Panda）进行交互。通过眼动追踪信号、任务上下文和环境测量时间同步收集数据，将每250毫秒的视觉指标、环境日志及自我报告的精神负荷评分组织在参与者特定文件夹。", "result": "提供了一个可用于开发、基准测试精神负荷估计算法的数据集，并研究光照等环境因素对眼动追踪的影响。", "conclusion": "GAZELOAD数据集能够支持基于眼睛的特征提取和时间建模，有助于评估现实工业人机协作场景中的精神负荷。"}}
{"id": "2601.21823", "pdf": "https://arxiv.org/pdf/2601.21823", "abs": "https://arxiv.org/abs/2601.21823", "authors": ["Zihan Huang", "Zijie Xu", "Yihan Huang", "Shanshan Jia", "Tong Bu", "Yiting Dong", "Wenxuan Liu", "Jianhao Ding", "Zhaofei Yu", "Tiejun Huang"], "title": "General Self-Prediction Enhancement for Spiking Neurons", "categories": ["cs.NE"], "comment": null, "summary": "Spiking Neural Networks (SNNs) are highly energy-efficient due to event-driven, sparse computation, but their training is challenged by spike non-differentiability and trade-offs among performance, efficiency, and biological plausibility. Crucially, mainstream SNNs ignore predictive coding, a core cortical mechanism where the brain predicts inputs and encodes errors for efficient perception. Inspired by this, we propose a self-prediction enhanced spiking neuron method that generates an internal prediction current from its input-output history to modulate membrane potential. This design offers dual advantages, it creates a continuous gradient path that alleviates vanishing gradients and boosts training stability and accuracy, while also aligning with biological principles, which resembles distal dendritic modulation and error-driven synaptic plasticity. Experiments show consistent performance gains across diverse architectures, neuron types, time steps, and tasks demonstrating broad applicability for enhancing SNNs.", "AI": {"tldr": "提出了一种基于预测编码的自增强脉冲神经元方法，以改善尖峰神经网络（SNN）的训练。", "motivation": "由于尖峰非可微性和性能、效率与生物学合理性之间的权衡，主流SNN忽略了核心皮层机制——预测编码。为了应对这些问题并提高训练效果和稳定性。", "method": "设计了一种自增强脉冲神经元方法，该方法根据输入输出历史生成内部预测电流以调节膜电位，从而创建连续梯度路径来缓解消失梯度问题，并且与生物学原理一致。", "result": "实验结果表明，在各种架构、神经元类型、时间步和任务中都取得了显著性能提升，证明了增强SNN的广泛适用性。", "conclusion": "该方法通过引入自预测增强了尖峰神经网络的训练效果和稳定性，并且在多种情况下展现了良好的应用前景。"}}
{"id": "2601.21822", "pdf": "https://arxiv.org/pdf/2601.21822", "abs": "https://arxiv.org/abs/2601.21822", "authors": ["Zitong Yu", "Boquan Sun", "Yang Li", "Zheyan Qu", "Xing Zhang"], "title": "CORE:Toward Ubiquitous 6G Intelligence Through Collaborative Orchestration of Large Language Model Agents Over Hierarchical Edge", "categories": ["cs.AI"], "comment": "Accepted by IEEE Communications Magazine", "summary": "Rapid advancements in sixth-generation (6G) networks and large language models (LLMs) have paved the way for ubiquitous intelligence, wherein seamless connectivity and distributed artificial intelligence (AI) have revolutionized various aspects of our lives.However, realizing this vision faces significant challenges owing to the fragmented and heterogeneous computing resources across hierarchical networks, which are insufficient for individual LLM agents to perform complex reasoning tasks.To address this issue, we propose Collaborative Orchestration Role at Edge (CORE), an innovative framework that employs a collaborative learning system in which multiple LLMs, each assigned a distinct functional role, are distributed across mobile devices and tiered edge servers. The system integrates three optimization modules, encompassing real-time perception,dynamic role orchestration, and pipeline-parallel execution, to facilitate efficient and rapid collaboration among distributed agents. Furthermore, we introduce a novel role affinity scheduling algorithm for dynamically orchestrating LLM role assignments across the hierarchical edge infrastructure, intelligently matching computational demands with available dispersed resources.Finally, comprehensive case studies and performance evaluations across various 6G application scenarios demonstrated the efficacy of CORE, revealing significant enhancements in the system efficiency and task completion rates. Building on these promising outcomes, we further validated the practical applicability of CORE by deploying it on a real-world edge-computing platform,that exhibits robust performance in operational environments.", "AI": {"tldr": "提出CORE框架，通过协作学习系统优化大规模语言模型在分层边缘网络中的分布和协作，提高任务完成效率。", "motivation": "为了克服6G网络中计算资源碎片化和异质性带来的挑战，实现无缝连接和分布式人工智能的普及智能愿景。", "method": "采用包含实时感知、动态角色编排和流水线并行执行三个优化模块的框架，结合新型角色亲和度调度算法进行分布式代理协作。", "result": "实验表明CORE在多种6G应用场景中显著提升了系统效率和任务完成率，并且在实际边缘计算平台上展示了稳健性能。", "conclusion": "CORE证明了其作为未来6G智能基础设施的有效性和实用性。"}}
{"id": "2601.21821", "pdf": "https://arxiv.org/pdf/2601.21821", "abs": "https://arxiv.org/abs/2601.21821", "authors": ["Honglin Lin", "Zheng Liu", "Yun Zhu", "Chonghan Qin", "Juekai Lin", "Xiaoran Shang", "Conghui He", "Wentao Zhang", "Lijun Wu"], "title": "MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a \"less is more\" phenomenon via our difficulty-aware filtering strategy: a subset of just 7\\% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.", "AI": {"tldr": "通过开放数据集方法，改进视觉语言模型在多模态推理上的表现。", "motivation": "现有的视觉语言模型（VLM）与专有系统相比，在高质量的推理数据方面存在不足，导致在STEM图示和视觉谜题等复杂领域上表现不佳。为此引入MMFineReason数据集以提高开放源代码VLM的多模态推理能力。", "method": "通过大规模的数据收集标准化、链式思考（CoT）生成及基于推理质量和难度感知的全面筛选，构建了包含1.8M样本和5.1B解决方案标记的大规模多模式推理数据集MMFineReason。并在该数据集上对Qwen3-VL-Instruct进行微调，创建了三个版本的模型：MMFineReason-2B、4B和8B。", "result": "实验结果表明，所构建的数据集显著提高了视觉语言模型在多模态推理任务上的性能。特别是，较小参数规模的MMFineReason-4B超越了更大参数量级的Qwen3-VL-8B-Thinking版本；而最大型号MMFineReason-8B甚至超越了Qwen3-VL-30B-A3B-Thinking，并接近于Qwen3-VL-32B-Thinking的表现。", "conclusion": "通过精心设计的数据集和微调策略，成功展示了较小规模模型在多模态推理任务上的优越性能。同时揭示出了一种“少即是多”的现象，即只需使用数据集中7%的样本就足以实现与完整数据集相媲美的效果，并且发现这种以推理为导向的数据组合能够增强通用能力。"}}
{"id": "2601.21815", "pdf": "https://arxiv.org/pdf/2601.21815", "abs": "https://arxiv.org/abs/2601.21815", "authors": ["Seongchan Park", "Jaehong Kim", "Hyeonseung Kim", "Heejin Bin", "Sue Moon", "Wonjae Lee"], "title": "Moral Outrage Shapes Commitments Beyond Attention: Multimodal Moral Emotions on YouTube in Korea and the US", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.SI"], "comment": "Accepted at The Web Conference 2026. We release Korean and English multimodal moral emotion classifiers", "summary": "Understanding how media rhetoric shapes audience engagement is crucial in the attention economy. This study examines how moral emotional framing by mainstream news channels on YouTube influences user behavior across Korea and the United States. To capture the platform's multimodal nature, combining thumbnail images and video titles, we develop a multimodal moral emotion classifier by fine tuning a vision language model. The model is trained on human annotated multimodal datasets in both languages and applied to approximately 400,000 videos from major news outlets. We analyze engagement levels including views, likes, and comments, representing increasing degrees of commitment. The results show that other condemning rhetoric expressions of moral outrage that criticize others morally consistently increase all forms of engagement across cultures, with effects ranging from passive viewing to active commenting. These findings suggest that moral outrage is a particularly effective emotional strategy, attracting not only attention but also active participation. We discuss concerns about the potential misuse of other condemning rhetoric, as such practices may deepen polarization by reinforcing in group and out group divisions. To facilitate future research and ensure reproducibility, we publicly release our Korean and English multimodal moral emotion classifiers.", "AI": {"tldr": "研究探讨了道德情感框架如何影响用户在YouTube上的参与度，特别是在韩国和美国的新闻视频中。", "motivation": "理解媒体修辞如何塑造受众互动对于注意力经济至关重要。本文旨在研究主流新闻频道在YouTube上使用道德情感框架如何影响用户的参与行为。", "method": "通过人类标注的多模态数据集训练模型，并将其应用于约40万来自主要新闻来源的视频，结合缩略图图像和标题开发了多模态道德情绪分类器。分析包括观看次数、点赞数和评论量等指标，以衡量用户参与度。", "result": "结果显示，在谴责他人道德行为方面的道德愤怒表达会增加所有形式的参与度，从被动观看到主动评论不等，这一效应在不同文化中普遍存在。", "conclusion": "道德愤怒是一种特别有效的策略，能够吸引不仅是注意力更是积极的参与。然而，滥用这样的修辞可能会加深社会分裂。研究公开发布了多模态道德情绪分类器以促进未来的研究和可重复性。"}}
{"id": "2601.21812", "pdf": "https://arxiv.org/pdf/2601.21812", "abs": "https://arxiv.org/abs/2601.21812", "authors": ["Francisco Caldas", "Sahil Kumar", "Cláudia Soares"], "title": "A Decomposable Forward Process in Diffusion Models for Time-Series Forecasting", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "submitted to ICML'26", "summary": "We introduce a model-agnostic forward diffusion process for time-series forecasting that decomposes signals into spectral components, preserving structured temporal patterns such as seasonality more effectively than standard diffusion. Unlike prior work that modifies the network architecture or diffuses directly in the frequency domain, our proposed method alters only the diffusion process itself, making it compatible with existing diffusion backbones (e.g., DiffWave, TimeGrad, CSDI). By staging noise injection according to component energy, it maintains high signal-to-noise ratios for dominant frequencies throughout the diffusion trajectory, thereby improving the recoverability of long-term patterns. This strategy enables the model to maintain the signal structure for a longer period in the forward process, leading to improved forecast quality. Across standard forecasting benchmarks, we show that applying spectral decomposition strategies, such as the Fourier or Wavelet transform, consistently improves upon diffusion models using the baseline forward process, with negligible computational overhead. The code for this paper is available at https://anonymous.4open.science/r/D-FDP-4A29.", "AI": {"tldr": "本文提出了一种模型无关的前向扩散过程，用于时间序列预测，并通过分解信号来保留结构化的时间模式。", "motivation": "现有扩散模型在处理具有季节性等结构性时间模式的数据时效果不佳。作者希望通过改进扩散过程本身而非网络架构或直接频率领域扩散的方法，提升长期模式的可恢复性和预报质量。", "method": "该方法通过根据组件能量分期注入噪声来维护信号到噪声的比例，保持主要频带的高信噪比。这种方法使模型能够在更长时间内维持信号结构，并且与现有扩散骨架兼容。", "result": "在标准预测基准上应用谱分解策略（如傅里叶或小波变换）能够显著改进基于基础前向过程的扩散模型性能，同时几乎不增加计算负担。", "conclusion": "通过将谱分解引入到时间序列预测中的扩散过程，本文提出的方法改善了长期模式的恢复性和预报质量。"}}
{"id": "2601.21802", "pdf": "https://arxiv.org/pdf/2601.21802", "abs": "https://arxiv.org/abs/2601.21802", "authors": ["Hoang Khang Phan", "Quang Vinh Dang", "Noriyo Colley", "Christina Garcia", "Nhat Tan Le"], "title": "A Unified XAI-LLM Approach for EndotrachealSuctioning Activity Recognition", "categories": ["cs.AI"], "comment": null, "summary": "Endotracheal suctioning (ES) is an invasive yet essential clinical procedure that requires a high degree of skill to minimize patient risk - particularly in home care and educational settings, where consistent supervision may be limited. Despite its critical importance, automated recognition and feedback systems for ES training remain underexplored. To address this gap, this study proposes a unified, LLM-centered framework for video-based activity recognition benchmarked against conventional machine learning and deep learning approaches, and a pilot study on feedback generation. Within this framework, the Large Language Model (LLM) serves as the central reasoning module, performing both spatiotemporal activity recognition and explainable decision analysis from video data. Furthermore, the LLM is capable of verbalizing feedback in natural language, thereby translating complex technical insights into accessible, human-understandable guidance for trainees. Experimental results demonstrate that the proposed LLM-based approach outperforms baseline models, achieving an improvement of approximately 15-20\\% in both accuracy and F1 score. Beyond recognition, the framework incorporates a pilot student-support module built upon anomaly detection and explainable AI (XAI) principles, which provides automated, interpretable feedback highlighting correct actions and suggesting targeted improvements. Collectively, these contributions establish a scalable, interpretable, and data-driven foundation for advancing nursing education, enhancing training efficiency, and ultimately improving patient safety.", "AI": {"tldr": "提出了一种基于大语言模型的统一框架，用于视频中的气管插管抽吸活动识别和反馈生成。", "motivation": "为了提高在家护理和教育环境下的气管插管抽吸培训效率并确保患者安全，解决自动化识别与反馈系统的不足。", "method": "采用大型语言模型作为核心推理模块进行时空活动识别及可解释性决策分析，并通过异常检测和XAI提供自动化的、可解释的训练反馈。", "result": "实验结果显示所提出的基于LLM的方法在准确率和F1值上比基准模型高出约15-20%。", "conclusion": "此研究为提高护理教育效率，增强培训效果及改善患者安全奠定了基础"}}
{"id": "2601.21800", "pdf": "https://arxiv.org/pdf/2601.21800", "abs": "https://arxiv.org/abs/2601.21800", "authors": ["Dionizije Fa", "Marko Čuljak", "Bruno Pandža", "Mateo Čupić"], "title": "BioAgent Bench: An AI Agent Evaluation Suite for Bioinformatics", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces BioAgent Bench, a benchmark dataset and an evaluation suite designed for measuring the performance and robustness of AI agents in common bioinformatics tasks. The benchmark contains curated end-to-end tasks (e.g., RNA-seq, variant calling, metagenomics) with prompts that specify concrete output artifacts to support automated assessment, including stress testing under controlled perturbations. We evaluate frontier closed-source and open-weight models across multiple agent harnesses, and use an LLM-based grader to score pipeline progress and outcome validity. We find that frontier agents can complete multi-step bioinformatics pipelines without elaborate custom scaffolding, often producing the requested final artifacts reliably. However, robustness tests reveal failure modes under controlled perturbations (corrupted inputs, decoy files, and prompt bloat), indicating that correct high-level pipeline construction does not guarantee reliable step-level reasoning. Finally, because bioinformatics workflows may involve sensitive patient data, proprietary references, or unpublished IP, closed-source models can be unsuitable under strict privacy constraints; in such settings, open-weight models may be preferable despite lower completion rates. We release the dataset and evaluation suite publicly.", "AI": {"tldr": "本文介绍了BioAgent Bench，这是一个评估AI代理在生物信息学任务中的性能和鲁棒性的基准数据集。", "motivation": "为了衡量AI代理在生物信息学领域的表现及抗干扰能力，并探索不同模型的适用性，尤其是在处理敏感患者数据时的情况。", "method": "开发了一个包含RNA序列分析、变异调用等任务的基准数据集和评估套件。通过控制扰动（如输入损坏或添加诱饵文件）来测试AI代理的稳健性；使用大语言模型自动评分管道进程和结果的有效性。", "result": "前沿的封闭源代码和开放权重模型能够在多步生物信息学流程中完成任务，但面对受控干扰时存在失败模式。此外，在隐私限制严格的环境下，封闭源模型可能不适合使用。", "conclusion": "BioAgent Bench揭示了AI代理在执行复杂生物信息学管道中的局限性，并强调了开发适应性强的开放权重模型的重要性。"}}
{"id": "2601.21798", "pdf": "https://arxiv.org/pdf/2601.21798", "abs": "https://arxiv.org/abs/2601.21798", "authors": ["Junming Huang", "Weiwei Xu"], "title": "CG-MLLM: Captioning and Generating 3D content via Multi-modal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Large Language Models(LLMs) have revolutionized text generation and multimodal perception, but their capabilities in 3D content generation remain underexplored. Existing methods compromise by producing either low-resolution meshes or coarse structural proxies, failing to capture fine-grained geometry natively. In this paper, we propose CG-MLLM, a novel Multi-modal Large Language Model (MLLM) capable of 3D captioning and high-resolution 3D generation in a single framework. Leveraging the Mixture-of-Transformer architecture, CG-MLLM decouples disparate modeling needs, where the Token-level Autoregressive (TokenAR) Transformer handles token-level content, and the Block-level Autoregressive (BlockAR) Transformer handles block-level content. By integrating a pre-trained vision-language backbone with a specialized 3D VAE latent space, CG-MLLM facilitates long-context interactions between standard tokens and spatial blocks within a single integrated architecture. Experimental results show that CG-MLLM significantly outperforms existing MLLMs in generating high-fidelity 3D objects, effectively bringing high-resolution 3D content creation into the mainstream LLM paradigm.", "AI": {"tldr": "本文提出了一种多模态大规模语言模型CG-MLLM，用于生成高质量的三维内容。", "motivation": "现有的方法在三维内容生成方面存在不足，无法同时实现高分辨率和精细几何结构。为此，作者提出了CG-MLLM来解决这些问题。", "method": "该模型使用混合Transformer架构将不同的建模需求解耦，并通过集成预训练的视觉语言骨干网与专门设计的3D VAE潜在空间，实现了标准标记和空间块之间的长上下文交互。", "result": "实验结果显示CG-MLLM在生成高质量三维对象方面显著优于现有方法。", "conclusion": "CG-MLLM将高分辨率三维内容创作引入主流的大规模语言模型范式中。"}}
{"id": "2601.21796", "pdf": "https://arxiv.org/pdf/2601.21796", "abs": "https://arxiv.org/abs/2601.21796", "authors": ["Yaocong Li", "Leihan Zhang", "Le Zhang", "Qiang Yan"], "title": "KID: Knowledge-Injected Dual-Head Learning for Knowledge-Grounded Harmful Meme Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Internet memes have become pervasive carriers of digital culture on social platforms. However, their heavy reliance on metaphors and sociocultural context also makes them subtle vehicles for harmful content, posing significant challenges for automated content moderation. Existing approaches primarily focus on intra-modal and inter-modal signal analysis, while the understanding of implicit toxicity often depends on background knowledge that is not explicitly present in the meme itself. To address this challenge, we propose KID, a Knowledge-Injected Dual-Head Learning framework for knowledge-grounded harmful meme detection. KID adopts a label-constrained distillation paradigm to decompose complex meme understanding into structured reasoning chains that explicitly link visual evidence, background knowledge, and classification labels. These chains guide the learning process by grounding external knowledge in meme-specific contexts. In addition, KID employs a dual-head architecture that jointly optimizes semantic generation and classification objectives, enabling aligned linguistic reasoning while maintaining stable decision boundaries. Extensive experiments on five multilingual datasets spanning English, Chinese, and low-resource Bengali demonstrate that KID achieves SOTA performance on both binary and multi-label harmful meme detection tasks, improving over previous best methods by 2.1%--19.7% across primary evaluation metrics. Ablation studies further confirm the effectiveness of knowledge injection and dual-head joint learning, highlighting their complementary contributions to robust and generalizable meme understanding. The code and data are available at https://github.com/PotatoDog1669/KID.", "AI": {"tldr": "本文提出了一种知识注入的双头学习框架KID，用于基于知识的有害梗图检测。", "motivation": "现有的方法主要集中在模态间的信号分析上，对于依赖背景知识理解隐含毒性内容的能力不足。因此，本文旨在通过将外部知识融入到具体的梗图上下文中来提高对有害梗图的理解和检测能力。", "method": "KID采用了标签约束蒸馏范式，将其复杂性分解为结构化推理链，这些链明确地将视觉证据、背景知识与分类标签联系起来。此外，它采用了一种双头架构，同时优化语义生成和分类目标，以促进一致的文本推理。", "result": "在五个多语言数据集上进行的大量实验表明，KID实现了有害梗图检测任务中的最佳性能，在主要评估指标上的改进为2.1%-19.7%。消融研究进一步证实了知识注入和双头联合学习的有效性，并突显了它们对鲁棒和泛化理解梗图的互补贡献。", "conclusion": "KID通过将背景知识融入具体上下文，成功提升了有害梗图检测的效果，体现了其在多语言环境下的优越性能。"}}
{"id": "2601.21795", "pdf": "https://arxiv.org/pdf/2601.21795", "abs": "https://arxiv.org/abs/2601.21795", "authors": ["Akash Dhasade", "Anne-Marie Kermarrec", "Igor Pavlovic", "Diana Petrescu", "Rafael Pires", "Mathis Randl", "Martijn de Vos"], "title": "Effective LoRA Adapter Routing using Task Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Low-rank adaptation (LoRA) enables parameter efficient specialization of large language models (LLMs) through modular adapters, resulting in rapidly growing public adapter pools spanning diverse tasks. Effectively using these adapters requires routing: selecting and composing the appropriate adapters for a query. We introduce LORAUTER, a novel routing framework that selects and composes LoRA adapters using task representations rather than adapter characteristics. Unlike existing approaches that map queries directly to adapters, LORAUTER routes queries via task embeddings derived from small validation sets and does not require adapter training data. By operating at the task level, LORAUTER achieves efficient routing that scales with the number of tasks rather than the number of adapters. Experiments across multiple tasks show that LORAUTER consistently outperforms baseline routing approaches, matching Oracle performance (101.2%) when task-aligned adapters exist and achieving state-of-the-art results on unseen tasks (+5.2 points). We further demonstrate the robustness of LORAUTER to very large, noisy adapter pools by scaling it to over 1500 adapters.", "AI": {"tldr": "介绍了LORAUTER，一种通过任务表示选择和组合LoRA适配器的新型路由框架。", "motivation": "为了有效使用日益增长且多样化的公共适配器池，提出了一种新的基于任务表示而非适配器特征进行路由的方法。", "method": "提出了LORAUTER框架，该框架利用小验证集中的任务嵌入来选择和组合LoRA适配器，并不需要适配器的训练数据。此方法在查询级别上操作，能够随着任务数量增加而高效扩展。", "result": "实验显示，与基准路由方法相比，LORAUTER表现更加优秀，在存在对齐适配器的情况下达到Oracle性能（101.2%），并在未见过的任务中实现新的最佳结果（提高5.2分）。此外，该框架还展示了在大型、嘈杂的适配器池中的鲁棒性。", "conclusion": "LORAUTER通过任务表示进行LoRA适配器路由，表现出色且具有良好的扩展性和鲁棒性。"}}
{"id": "2601.21791", "pdf": "https://arxiv.org/pdf/2601.21791", "abs": "https://arxiv.org/abs/2601.21791", "authors": ["Valerie Tan", "Luisa Jost", "Jens Gerken", "Max Pascher"], "title": "Preliminary Results of a Scoping Review on Assistive Technologies for Adults with ADHD", "categories": ["cs.HC"], "comment": "9 pages, 1 fvigure", "summary": "Attention Deficit Hyperactivity Disorder (ADHD), characterized by inattention, hyperactivity, and impulsivity, is prevalent in the adult population. Long perceived and treated as a childhood condition, ADHD and its characteristics nonetheless impact a significant portion of adults today. In contrast to children with ADHD, adults with ADHD face unique challenges in the workplace and in higher education. In this work-in-progress paper, we present a scoping review as a foundation to understand and explore existing technology-based approaches to support adults with ADHD. In total, our search returned 3,538 papers upon which we selected, based on PRISMA-ScR, a total of 46 papers for in-depth analysis. Our initial findings highlight that most papers take on a therapeutic or intervention perspective instead of a more positive support perspective. Our analysis also found a tremendous increase in recent papers on the topic, which highlights that more and more researchers are becoming aware of the need to address ADHD with adults. For the future, we aim to further analyze the corpus and identify research gaps and potentials for further development of ADHD assistive technologies.", "AI": {"tldr": "对成人ADHD辅助技术的文献进行综述，识别研究空白和未来发展方向。", "motivation": "成人ADHD患者面临工作和高等教育的独特挑战，需要有针对性的技术支持来改善他们的生活质量。", "method": "采用PRISMA-ScR标准筛选3538篇论文后，对46篇相关文献进行了深入分析。", "result": "初步结果显示大多数研究侧重于治疗性或干预措施而非积极的支持策略。最近关于成人ADHD的研究数量显著增加。", "conclusion": "未来将更深入地分析文献集以识别研究空白并探索辅助技术的发展潜力。"}}
{"id": "2601.21789", "pdf": "https://arxiv.org/pdf/2601.21789", "abs": "https://arxiv.org/abs/2601.21789", "authors": ["Adia Lumadjeng", "Ilker Birbil", "Erman Acar"], "title": "ECSEL: Explainable Classification via Signomial Equation Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We introduce ECSEL, an explainable classification method that learns formal expressions in the form of signomial equations, motivated by the observation that many symbolic regression benchmarks admit compact signomial structure. ECSEL directly constructs a structural, closed-form expression that serves as both a classifier and an explanation. On standard symbolic regression benchmarks, our method recovers a larger fraction of target equations than competing state-of-the-art approaches while requiring substantially less computation. Leveraging this efficiency, ECSEL achieves classification accuracy competitive with established machine learning models without sacrificing interpretability. Further, we show that ECSEL satisfies some desirable properties regarding global feature behavior, decision-boundary analysis, and local feature attributions. Experiments on benchmark datasets and two real-world case studies i.e., e-commerce and fraud detection, demonstrate that the learned equations expose dataset biases, support counterfactual reasoning, and yield actionable insights.", "AI": {"tldr": "ECSEL是一种通过学习符号回归基准中常见的紧致signomial结构，来构建分类器和解释的可解释分类方法。", "motivation": "为了提高机器学习模型的可解释性并保持较高的准确性，作者提出了ECSEL方法。该方法旨在直接构造一个封闭形式的表达式作为分类器，同时提供易于理解的解释。", "method": "ECSEL通过学习signomial方程来构建分类器，并在标准符号回归基准上进行测试以验证其有效性。", "result": "ECSEL在恢复目标方程式方面比其他最先进的方法更有效，在计算量显著减少的情况下达到了与传统机器学习模型相竞争的准确性。实验表明，该方法揭示了数据集中的偏见，支持反事实推理，并提供了实用见解。", "conclusion": "ECSEL不仅提高了分类任务中模型的可解释性，还保持了较高的准确性和实用性，在实际应用中展示了其优越性。"}}
{"id": "2601.21787", "pdf": "https://arxiv.org/pdf/2601.21787", "abs": "https://arxiv.org/abs/2601.21787", "authors": ["Chantale Lauer", "Peter Pfeiffer", "Alexander Rombach", "Nijat Mehdiyev"], "title": "Assessing the Business Process Modeling Competences of Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The creation of Business Process Model and Notation (BPMN) models is a complex and time-consuming task requiring both domain knowledge and proficiency in modeling conventions. Recent advances in large language models (LLMs) have significantly expanded the possibilities for generating BPMN models directly from natural language, building upon earlier text-to-process methods with enhanced capabilities in handling complex descriptions. However, there is a lack of systematic evaluations of LLM-generated process models. Current efforts either use LLM-as-a-judge approaches or do not consider established dimensions of model quality. To this end, we introduce BEF4LLM, a novel LLM evaluation framework comprising four perspectives: syntactic quality, pragmatic quality, semantic quality, and validity. Using BEF4LLM, we conduct a comprehensive analysis of open-source LLMs and benchmark their performance against human modeling experts. Results indicate that LLMs excel in syntactic and pragmatic quality, while humans outperform in semantic aspects; however, the differences in scores are relatively modest, highlighting LLMs' competitive potential despite challenges in validity and semantic quality. The insights highlight current strengths and limitations of using LLMs for BPMN modeling and guide future model development and fine-tuning. Addressing these areas is essential for advancing the practical deployment of LLMs in business process modeling.", "AI": {"tldr": "评估大型语言模型（LLM）生成业务流程建模和记号法(BPMN)模型的能力。", "motivation": "当前缺少对LLM生成的BPMN模型进行系统性评估的方法。现有的评估方法要么使用LLM作为评判者，要么不考虑已确立的质量维度。", "method": "引入了一个名为BEF4LLM的新框架，用于评估LLM生成的流程模型质量，包含四个视角：语法质量、实用质量、语义质量和有效性。", "result": "结果显示，在语法和实用质量方面，LLM表现优异；但在语义质量上人类专家更胜一筹。尽管存在挑战，但总体而言，LLM在BPMN建模中的竞争潜力仍然显著。", "conclusion": "该研究揭示了利用LLM进行BPMN模型生成的当前优势和限制，并为未来模型的发展和微调提供了指导方向。"}}
{"id": "2601.21786", "pdf": "https://arxiv.org/pdf/2601.21786", "abs": "https://arxiv.org/abs/2601.21786", "authors": ["Borja Carrillo-Perez", "Felix Sattler", "Angel Bueno Rodriguez", "Maurice Stephan", "Sarah Barnes"], "title": "Synthetic-to-Real Domain Bridging for Single-View 3D Reconstruction of Ships for Maritime Monitoring", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "ef:Applications of Machine Learning 2025, Proc. of SPIE Vol. 13606, 136061G 2025 Published by SPIE 0277-786X", "summary": "Three-dimensional (3D) reconstruction of ships is an important part of maritime monitoring, allowing improved visualization, inspection, and decision-making in real-world monitoring environments. However, most state-ofthe-art 3D reconstruction methods require multi-view supervision, annotated 3D ground truth, or are computationally intensive, making them impractical for real-time maritime deployment. In this work, we present an efficient pipeline for single-view 3D reconstruction of real ships by training entirely on synthetic data and requiring only a single view at inference. Our approach uses the Splatter Image network, which represents objects as sparse sets of 3D Gaussians for rapid and accurate reconstruction from single images. The model is first fine-tuned on synthetic ShapeNet vessels and further refined with a diverse custom dataset of 3D ships, bridging the domain gap between synthetic and real-world imagery. We integrate a state-of-the-art segmentation module based on YOLOv8 and custom preprocessing to ensure compatibility with the reconstruction network. Postprocessing steps include real-world scaling, centering, and orientation alignment, followed by georeferenced placement on an interactive web map using AIS metadata and homography-based mapping. Quantitative evaluation on synthetic validation data demonstrates strong reconstruction fidelity, while qualitative results on real maritime images from the ShipSG dataset confirm the potential for transfer to operational maritime settings. The final system provides interactive 3D inspection of real ships without requiring real-world 3D annotations. This pipeline provides an efficient, scalable solution for maritime monitoring and highlights a path toward real-time 3D ship visualization in practical applications. Interactive demo: https://dlr-mi.github.io/ship3d-demo/.", "AI": {"tldr": "通过合成数据训练并在真实单视图中进行三维重建，提出了一种高效的方法来实现船只的实时监控。", "motivation": "现有大多数三维重建方法需要多视角监督、注释的三维真值或计算密集型操作，在实际海事部署中不切实际。因此，研究旨在开发一种实用且高效的单视图三维重建技术以应对这一挑战。", "method": "采用Splatter Image网络来快速准确地从单一图像中重建3D物体，并用合成ShapeNet船只数据集进行初步训练，再通过定制的多样化真实世界船只数据集进一步微调，从而缩小合成与现实之间的差距。整合YOLOv8分割模块和自定义预处理步骤以确保与重建网络兼容。最后进行后处理包括真实世界的尺度调整、中心对齐以及方向校准。", "result": "在合成验证数据上的定量评估显示出强大的重建准确性，在来自ShipSG的真实海事图像的定性结果中也证实了其潜在的应用前景，展示了从实验室环境到实际操作应用的良好迁移能力。", "conclusion": "提出的方法提供了一种无需真实三维注释即可交互式地检查真实船只的高效解决方案，并在实际海事监控和实时三维船体可视化方面具有广阔的应用潜力。"}}
{"id": "2601.21778", "pdf": "https://arxiv.org/pdf/2601.21778", "abs": "https://arxiv.org/abs/2601.21778", "authors": ["Zijie Xu", "Zihan Huang", "Yiting Dong", "Kang Chen", "Wenxuan Liu", "Zhaofei Yu"], "title": "Error Amplification Limits ANN-to-SNN Conversion in Continuous Control", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs) can achieve competitive performance by converting already existing well-trained Artificial Neural Networks (ANNs), avoiding further costly training. This property is particularly attractive in Reinforcement Learning (RL), where training through environment interaction is expensive and potentially unsafe. However, existing conversion methods perform poorly in continuous control, where suitable baselines are largely absent. We identify error amplification as the key cause: small action approximation errors become temporally correlated across decision steps, inducing cumulative state distribution shift and severe performance degradation. To address this issue, we propose Cross-Step Residual Potential Initialization (CRPI), a lightweight training-free mechanism that carries over residual membrane potentials across decision steps to suppress temporally correlated errors. Experiments on continuous control benchmarks with both vector and visual observations demonstrate that CRPI can be integrated into existing conversion pipelines and substantially recovers lost performance. Our results highlight continuous control as a critical and challenging benchmark for ANN-to-SNN conversion, where small errors can be strongly amplified and impact performance.", "AI": {"tldr": "本文提出了一种名为CRPI的机制，用于抑制连续控制任务中ANN到SNN转换过程中的误差放大问题。", "motivation": "现有方法在连续控制任务中将训练好的人工神经网络（ANN）转换为脉冲神经网络（SNN）时性能不佳。这主要是因为小的动作近似错误会在决策步骤间变得时间相关，从而累积状态分布偏移并导致严重性能下降。", "method": "本文提出了一种轻量级的无需额外训练的方法CRPI，该方法通过跨步残差膜电位传递来抑制误差的相关性，以改进连续控制任务中的ANN到SNN转换。", "result": "在具有矢量和视觉观测数据集上的实验表明，CRPI可以集成到现有的转换流程中，并显著恢复了性能损失。这些结果突显了连续控制作为衡量ANN到SNN转换性能的关键且具挑战性的基准。", "conclusion": "本文的研究成果强调了连续控制任务在ANN到SNN转换中的重要性和挑战性，同时也展示了CRPI机制的有效性及其对提高转换后网络性能的潜在贡献。"}}
{"id": "2601.21772", "pdf": "https://arxiv.org/pdf/2601.21772", "abs": "https://arxiv.org/abs/2601.21772", "authors": ["Carmen D. R. Pita-Romero", "Pedro Arias-Perez", "Miguel Fernandez-Cortizas", "Rafael Perez-Segui", "Pascual Campoy"], "title": "Flocking behavior for dynamic and complex swarm structures", "categories": ["cs.RO"], "comment": "ef:2025 International Conference on Unmanned Aircraft Systems (ICUAS), pages 1011-1018", "summary": "Maintaining the formation of complex structures with multiple UAVs and achieving complex trajectories remains a major challenge. This work presents an algorithm for implementing the flocking behavior of UAVs based on the concept of Virtual Centroid to easily develop a structure for the flock. The approach builds on the classical virtual-based behavior, providing a theoretical framework for incorporating enhancements to dynamically control both the number of agents and the formation of the structure. Simulation tests and real-world experiments were conducted, demonstrating its simplicity even with complex formations and complex trajectories.", "AI": {"tldr": "基于虚拟中心概念开发无人机群结构的算法，实现复杂结构和轨迹下的群集行为。", "motivation": "在多架无人机中维持复杂结构的编队并完成复杂航迹是一个重大挑战。此工作旨在通过引入一种新的方法来克服这一难题。", "method": "提出了一种基于虚拟中心的无人机群集行为实施算法，并提供了一个理论框架，该框架能够动态控制代理数量和编队结构的形式。", "result": "仿真测试和现实世界实验表明，即使在复杂形式和轨迹情况下也能保持简单性。", "conclusion": "通过引入虚拟中心概念并进行相关研究验证了实现复杂无人机群集行为的可行性。"}}
{"id": "2601.21771", "pdf": "https://arxiv.org/pdf/2601.21771", "abs": "https://arxiv.org/abs/2601.21771", "authors": ["Hadi Banaee", "Stephanie Lowry"], "title": "Abstract Concept Modelling in Conceptual Spaces: A Study on Chess Strategies", "categories": ["cs.AI"], "comment": null, "summary": "We present a conceptual space framework for modelling abstract concepts that unfold over time, demonstrated through a chess-based proof-of-concept. Strategy concepts, such as attack or sacrifice, are represented as geometric regions across interpretable quality dimensions, with chess games instantiated and analysed as trajectories whose directional movement toward regions enables recognition of intended strategies. This approach also supports dual-perspective modelling, capturing how players interpret identical situations differently. Our implementation demonstrates the feasibility of trajectory-based concept recognition, with movement patterns aligning with expert commentary. This work explores extending the conceptual spaces theory to temporally realised, goal-directed concepts. The approach establishes a foundation for broader applications involving sequential decision-making and supports integration with knowledge evolution mechanisms for learning and refining abstract concepts over time.", "AI": {"tldr": "论文提出了一种基于概念空间框架的时间展开抽象概念建模方法，通过国际象棋策略验证其可行性。", "motivation": "动机在于探索如何使用几何区域表示和分析随时间演变的目标导向概念，并支持不同玩家对同一情况的不同解读。", "method": "该研究采用动态轨迹的方式在质量维度上实现抽象概念的模型化，并利用这种建模方法捕捉运动模式与专家评论的一致性，以识别策略意图。", "result": "实验结果表明，基于轨迹的概念识别是可行的，且能反映玩家的战略意图和决策过程。", "conclusion": "这项工作为包含顺序决策的应用提供了基础，并支持了知识进化机制的学习和抽象概念的持续改进。"}}
{"id": "2601.21766", "pdf": "https://arxiv.org/pdf/2601.21766", "abs": "https://arxiv.org/abs/2601.21766", "authors": ["Amit Dhurandhar", "Vijil Chenthamarakshan", "Dennis Wei", "Tejaswini Pedapati", "Karthikeyan Natesan Ramamurthy", "Rahul Nair"], "title": "CoFrGeNet: Continued Fraction Architectures for Language Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Transformers are arguably the preferred architecture for language generation. In this paper, inspired by continued fractions, we introduce a new function class for generative modeling. The architecture family implementing this function class is named CoFrGeNets - Continued Fraction Generative Networks. We design novel architectural components based on this function class that can replace Multi-head Attention and Feed-Forward Networks in Transformer blocks while requiring much fewer parameters. We derive custom gradient formulations to optimize the proposed components more accurately and efficiently than using standard PyTorch-based gradients. Our components are a plug-in replacement requiring little change in training or inference procedures that have already been put in place for Transformer-based models thus making our approach easy to incorporate in large industrial workflows. We experiment on two very different transformer architectures GPT2-xl (1.5B) and Llama3 (3.2B), where the former we pre-train on OpenWebText and GneissWeb, while the latter we pre-train on the docling data mix which consists of nine different datasets. Results show that the performance on downstream classification, Q\\& A, reasoning and text understanding tasks of our models is competitive and sometimes even superior to the original models with $\\frac{2}{3}$ to $\\frac{1}{2}$ the parameters and shorter pre-training time. We believe that future implementations customized to hardware will further bring out the true potential of our architectures.", "AI": {"tldr": "介绍了一种基于连分数的新函数类CoFrGeNets，用于语言生成。", "motivation": "为了减少参数数量并提高训练效率，同时保持模型性能，提出一种新的架构替代多头注意力和前馈网络。", "method": "设计了基于新函数类的组件，提出了定制的梯度公式以优化这些组件，并在GPT2-xl和Llama3等模型上进行实验。", "result": "实验表明，与原模型相比，在分类、问答、推理和文本理解任务中性能具有竞争力甚至更优，参数量减少了1/2到2/3，预训练时间缩短。", "conclusion": "新架构在语言生成任务中的表现优越，并且容易集成到现有的工业流程中。"}}
{"id": "2601.21760", "pdf": "https://arxiv.org/pdf/2601.21760", "abs": "https://arxiv.org/abs/2601.21760", "authors": ["Ruian Tie", "Wenbo Xiong", "Zhengyu Shi", "Xinyu Su", "Chenyu jiang", "Libo Wu", "Hao Li"], "title": "Zero-Shot Statistical Downscaling via Diffusion Posterior Sampling", "categories": ["cs.AI"], "comment": null, "summary": "Conventional supervised climate downscaling struggles to generalize to Global Climate Models (GCMs) due to the lack of paired training data and inherent domain gaps relative to reanalysis. Meanwhile, current zero-shot methods suffer from physical inconsistencies and vanishing gradient issues under large scaling factors. We propose Zero-Shot Statistical Downscaling (ZSSD), a zero-shot framework that performs statistical downscaling without paired data during training. ZSSD leverages a Physics-Consistent Climate Prior learned from reanalysis data, conditioned on geophysical boundaries and temporal information to enforce physical validity. Furthermore, to enable robust inference across varying GCMs, we introduce Unified Coordinate Guidance. This strategy addresses the vanishing gradient problem in vanilla DPS and ensures consistency with large-scale fields. Results show that ZSSD significantly outperforms existing zero-shot baselines in 99th percentile errors and successfully reconstructs complex weather events, such as tropical cyclones, across heterogeneous GCMs.", "AI": {"tldr": "提出了一种名为ZSSD的零样本气候下尺度方法，无需配对训练数据即可进行统计降尺度。", "motivation": "传统监督学习在气候降尺度中难以泛化到全球气候模型，并且当前零样本方法存在物理不一致性及梯度消失问题。", "method": "ZSSD利用从再分析数据中学得的物理一致气候先验，结合地理边界和时间信息来确保物理有效性；引入统一坐标指导策略解决梯度消失问题并保证与大尺度场的一致性。", "result": "实验结果显示，ZSSD在99分位误差上显著优于现有零样本基线，并成功重建了异构全球气候模型中的复杂天气事件。", "conclusion": "所提方法有效解决了传统降尺度任务的泛化问题及现有零样本方法存在的物理不一致性和梯度消失问题。"}}
{"id": "2601.21758", "pdf": "https://arxiv.org/pdf/2601.21758", "abs": "https://arxiv.org/abs/2601.21758", "authors": ["Bronislav Sidik", "Chaya Levi", "Joseph Kampeas"], "title": "EWSJF: An Adaptive Scheduler with Hybrid Partitioning for Mixed-Workload LLM Inference", "categories": ["cs.DC", "cs.AI"], "comment": ":I.2.6; C.2.4", "summary": "Serving Large Language Models (LLMs) under mixed workloads--short, latency-sensitive interactive queries alongside long, throughput-oriented batch requests--poses a fundamental scheduling challenge. Standard First-Come, First-Served (FCFS) policies suffer from severe head-of-line blocking, leading to high tail latency and underutilized hardware. We introduce EWSJF (Effective Workload-based Shortest Job First), an adaptive request-level scheduler that learns workload structure in real time to jointly improve fairness and throughput. EWSJF operates upstream of execution-level schedulers and integrates four components: (1) Refine-and-Prune, an unsupervised partitioning algorithm that discovers performance-homogeneous request groups; (2) Dynamic Queue Routing for assigning requests to these groups; (3) Density-Weighted Scoring, a context-aware prioritization function balancing urgency and fairness; and (4) Bayesian Meta-Optimization, which continuously tunes scoring and partitioning parameters based on live performance feedback. Implemented in vLLM, EWSJF improves end-to-end throughput by over 30% and reduces average Time-To-First-Token for short requests by up to 4x compared to FCFS. These results demonstrate that adaptive, learning-based request scheduling is a critical missing layer for efficient and responsive LLM serving. Implementation available at https://anonymous.4open.science/r/vllm_0110-32D8.", "AI": {"tldr": "提出了一种适应性的调度器EWSJF，用于在混合负载下优化大型语言模型的推理性能。", "motivation": "为了应对在混合工作负载（短、延迟敏感的交互查询和长、吞吐量导向的批量请求）下的服务挑战，传统的先来先服务策略存在严重的队头阻塞问题，导致尾部延迟高且硬件利用率低。", "method": "EWSJF引入了一种自适应的任务级调度器，实时学习工作负载结构以改善公平性和吞吐量。该方法包括：（1）Refine-and-Prune的无监督分区算法，用于发现性能同质化的任务组；（2）动态队列路由将请求分配到这些组中；（3）密度加权评分，根据紧迫性和公平性进行上下文感知的任务优先级排序；（4）贝叶斯元优化持续调整评分和分区分参数以适应实时性能反馈。", "result": "在vLLM上实现的EWSJF将端到端吞吐量提高了超过30%，并且将短请求的时间首次令牌减少到了原来的四分之一，相比传统的先来先服务策略。", "conclusion": "自适应学习型任务调度是高效和响应式的大型语言模型服务中一个关键但缺失的层。"}}
{"id": "2601.21754", "pdf": "https://arxiv.org/pdf/2601.21754", "abs": "https://arxiv.org/abs/2601.21754", "authors": ["Haoyu Wang", "Guozheng Ma", "Shugang Cui", "Yilun Kong", "Haotian Luo", "Li Shen", "Mengya Gao", "Yichao Wu", "Xiaogang Wang", "Dacheng Tao"], "title": "Language-based Trial and Error Falls Behind in the Era of Experience", "categories": ["cs.AI"], "comment": null, "summary": "While Large Language Models (LLMs) excel in language-based agentic tasks, their applicability to unseen, nonlinguistic environments (e.g., symbolic or spatial tasks) remains limited. Previous work attributes this performance gap to the mismatch between the pretraining distribution and the testing distribution. In this work, we demonstrate the primary bottleneck is the prohibitive cost of exploration: mastering these tasks requires extensive trial-and-error, which is computationally unsustainable for parameter-heavy LLMs operating in a high dimensional semantic space. To address this, we propose SCOUT (Sub-Scale Collaboration On Unseen Tasks), a novel framework that decouples exploration from exploitation. We employ lightweight \"scouts\" (e.g., small MLPs) to probe environmental dynamics at a speed and scale far exceeding LLMs. The collected trajectories are utilized to bootstrap the LLM via Supervised Fine-Tuning (SFT), followed by multi-turn Reinforcement Learning (RL) to activate its latent world knowledge. Empirically, SCOUT enables a Qwen2.5-3B-Instruct model to achieve an average score of 0.86, significantly outperforming proprietary models, including Gemini-2.5-Pro (0.60), while saving about 60% GPU hours consumption.", "AI": {"tldr": "提出SCOUT框架，通过使用轻量级的\"侦察员\"来降低探索成本，并利用收集的数据对大语言模型进行微调和强化学习。", "motivation": "解决大型语言模型在处理非语言环境任务时因高昂的探索成本而导致性能瓶颈的问题。", "method": "引入SCOUT框架，使用轻量级MLP作为侦察员来快速探查环境动态，并通过监督微调和多轮强化学习来提升大语言模型的表现。", "result": "Qwen2.5-3B-Instruct模型在SCOUT框架下平均得分0.86，显著优于其他模型如Gemini-2.5-Pro（0.60），并且节省了约60%的GPU计算资源。", "conclusion": "通过引入SCOUT框架，有效地解决了大型语言模型在非语言环境任务中的探索成本问题，并提升了整体性能。"}}
{"id": "2601.21751", "pdf": "https://arxiv.org/pdf/2601.21751", "abs": "https://arxiv.org/abs/2601.21751", "authors": ["Jiankun Peng", "Jianyuan Guo", "Ying Xu", "Yue Liu", "Jiashuang Yan", "Xuanwei Ye", "Houhua Li", "Xiaoming Wang"], "title": "Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language Navigation in Continuous Environments (VLN-CE) presents a core challenge: grounding high-level linguistic instructions into precise, safe, and long-horizon spatial actions. Explicit topological maps have proven to be a vital solution for providing robust spatial memory in such tasks. However, existing topological planning methods suffer from a \"Granularity Rigidity\" problem. Specifically, these methods typically rely on fixed geometric thresholds to sample nodes, which fails to adapt to varying environmental complexities. This rigidity leads to a critical mismatch: the model tends to over-sample in simple areas, causing computational redundancy, while under-sampling in high-uncertainty regions, increasing collision risks and compromising precision. To address this, we propose DGNav, a framework for Dynamic Topological Navigation, introducing a context-aware mechanism to modulate map density and connectivity on-the-fly. Our approach comprises two core innovations: (1) A Scene-Aware Adaptive Strategy that dynamically modulates graph construction thresholds based on the dispersion of predicted waypoints, enabling \"densification on demand\" in challenging environments; (2) A Dynamic Graph Transformer that reconstructs graph connectivity by fusing visual, linguistic, and geometric cues into dynamic edge weights, enabling the agent to filter out topological noise and enhancing instruction adherence. Extensive experiments on the R2R-CE and RxR-CE benchmarks demonstrate DGNav exhibits superior navigation performance and strong generalization capabilities. Furthermore, ablation studies confirm that our framework achieves an optimal trade-off between navigation efficiency and safe exploration. The code is available at https://github.com/shannanshouyin/DGNav.", "AI": {"tldr": "提出了一种动态拓扑导航框架（DGNav），解决现有视觉语言导航任务中的刚性颗粒度问题，提高了精确和安全的长时序空间行动能力。", "motivation": "现有的基于固定几何阈值采样的方法在环境复杂度变化时不适应，导致简单区域过采样、计算冗余以及高不确定性区域下采样不足，增加碰撞风险。", "method": "提出DGNav框架，包括场景感知自适应策略和动态图变换器两个核心创新点。前者通过预测路径点的分散程度动态调整节点构建阈值；后者融合视觉、语言和几何线索进行动态边权重重建，提高指令遵循性。", "result": "在R2R-CE和RxR-CE基准测试中表现出卓越导航性能及强泛化能力，且消融研究表明该框架实现了导航效率与安全探索间的最优权衡。", "conclusion": "DGNav通过动态调整图结构克服了固定颗粒度的局限性，在复杂环境中提供更精确、高效的视觉语言导航。"}}
{"id": "2601.21747", "pdf": "https://arxiv.org/pdf/2601.21747", "abs": "https://arxiv.org/abs/2601.21747", "authors": ["Vincent Lemaire", "Nédra Meloulli", "Pierre Jaquet"], "title": "Temporal Sepsis Modeling: a Fully Interpretable Relational Way", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sepsis remains one of the most complex and heterogeneous syndromes in intensive care, characterized by diverse physiological trajectories and variable responses to treatment. While deep learning models perform well in the early prediction of sepsis, they often lack interpretability and ignore latent patient sub-phenotypes. In this work, we propose a machine learning framework by opening up a new avenue for addressing this issue: a relational approach. Temporal data from electronic medical records (EMRs) are viewed as multivariate patient logs and represented in a relational data schema. Then, a propositionalisation technique (based on classic aggregation/selection functions from the field of relational data) is applied to construct interpretable features to \"flatten\" the data. Finally, the flattened data is classified using a selective naive Bayesian classifier. Experimental validation demonstrates the relevance of the suggested approach as well as its extreme interpretability. The interpretation is fourfold: univariate, global, local, and counterfactual.", "AI": {"tldr": "本文提出了一种基于关系数据的方法，用于解释性地预测重症监护中的败血症。", "motivation": "深度学习模型在早期预测败血症方面表现良好，但缺乏可解释性和忽视潜在的患者亚型。", "method": "利用电子医疗记录中的时间序列数据构建关系数据库，并通过经典的关系数据聚合/选择函数生成可解释特征。最后使用选择性朴素贝叶斯分类器进行分类。", "result": "实验验证了该方法的有效性和极高可解释性，解释方式包括单变量、全局、局部和反事实四种形式。", "conclusion": "提出的方法能够有效地提高败血症预测的准确性，并提供高度的可解释性。"}}
{"id": "2601.21742", "pdf": "https://arxiv.org/pdf/2601.21742", "abs": "https://arxiv.org/abs/2601.21742", "authors": ["Ruiwen Zhou", "Maojia Song", "Xiaobao Wu", "Sitao Cheng", "Xunjian Yin", "Yuxi Xie", "Zhuoqun Hao", "Wenyue Hua", "Liangming Pan", "Soujanya Poria", "Min-Yen Kan"], "title": "Epistemic Context Learning: Building Trust the Right Way in LLM-Based Multi-Agent Systems", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": "Codes and data are available at https://github.com/skyriver-2000/epistemic-context-learning", "summary": "Individual agents in multi-agent (MA) systems often lack robustness, tending to blindly conform to misleading peers. We show this weakness stems from both sycophancy and inadequate ability to evaluate peer reliability. To address this, we first formalize the learning problem of history-aware reference, introducing the historical interactions of peers as additional input, so that agents can estimate peer reliability and learn from trustworthy peers when uncertain. This shifts the task from evaluating peer reasoning quality to estimating peer reliability based on interaction history. We then develop Epistemic Context Learning (ECL): a reasoning framework that conditions predictions on explicitly-built peer profiles from history. We further optimize ECL by reinforcement learning using auxiliary rewards. Our experiments reveal that our ECL enables small models like Qwen 3-4B to outperform a history-agnostic baseline 8x its size (Qwen 3-30B) by accurately identifying reliable peers. ECL also boosts frontier models to near-perfect (100%) performance. We show that ECL generalizes well to various MA configurations and we find that trust is modeled well by LLMs, revealing a strong correlation in trust modeling accuracy and final answer quality.", "AI": {"tldr": "本文提出了Epistemic Context Learning（ECL）框架，用于多代理系统中基于历史交互构建可信度模型。", "motivation": "解决多代理系统中个体代理对误导性同伴盲目依赖的问题，提高代理人评估同辈可靠性的能力。", "method": "提出并优化了Epistemic Context Learning (ECL) 框架，通过辅助奖励的强化学习提升性能。", "result": "实验表明，ECL使得小模型可以超越规模较大的基线模型，在不同多代理配置中表现出色，并且信任建模与最终答案质量之间存在强相关性。", "conclusion": "ECL框架能够有效提高多代理系统中的信任建立和推理性能。"}}
{"id": "2601.21740", "pdf": "https://arxiv.org/pdf/2601.21740", "abs": "https://arxiv.org/abs/2601.21740", "authors": ["Meng Yang", "Jon McCormack", "Maria Teresa Llano", "Wanchao Su", "Chao Lei"], "title": "MIDI-LLaMA: An Instruction-Following Multimodal LLM for Symbolic Music Understanding", "categories": ["cs.MM", "cs.SD"], "comment": "Accepted for publication at International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026", "summary": "Recent advances in multimodal large language models (MLLM) for audio music have demonstrated strong capabilities in music understanding, yet symbolic music, a fundamental representation of musical structure, remains unexplored. In this work, we introduce MIDI-LLaMA, the first instruction-following MLLM for symbolic music understanding. Our approach aligns the MIDI encoder MusicBERT and Llama-3-8B via a two-stage pipeline comprising feature alignment and instruction tuning. To support training, we design a scalable annotation pipeline that annotates GiantMIDI-Piano with fine-grained metadata, resulting in a MIDI-text dataset. Compared with the baseline trained on converting MIDI into ABC notation under the same instruction-tuning procedure, MIDI-LLaMA substantially outperforms in captioning and semantic alignment in question answering. Human evaluation further confirms the advantages of MIDI-LLaMA in music understanding, emotion recognition, creativity, and overall preference. These findings demonstrate that incorporating symbolic music into large language models enhances their capacity for musical understanding.", "AI": {"tldr": "介绍MIDI-LLaMA，一种用于符号音乐理解的指令跟随型多模态大语言模型。", "motivation": "现有研究在音频音乐的理解方面取得了进展，但尚未探索符号音乐。本文旨在填补这一空白，提出了一种新的方法来增强大型语言模型对音乐结构的理解能力。", "method": "通过将MIDI编码器MusicBERT和Llama-3-8B进行特征对齐并使用指令调优的方法构建了MIDI-LLaMA。设计了一个可扩展的注释流程，用于生成包含精细元数据的MIDI-文本数据集。", "result": "相比基线模型，在相同的指令调优程序下，MIDI-LLaMA在音乐描述和语义对齐方面表现更好。人类评估进一步证实了其在音乐理解、情感识别、创造力及整体偏好上的优势。", "conclusion": "研究表明，将符号音乐融入大型语言模型能够显著提升它们的音乐理解能力。"}}
{"id": "2601.21739", "pdf": "https://arxiv.org/pdf/2601.21739", "abs": "https://arxiv.org/abs/2601.21739", "authors": ["Alberto Fernández-Hernández", "Cristian Pérez-Corral", "Jose I. Mestre", "Manuel F. Dolz", "Enrique S. Quintana-Ortí"], "title": "Why Adam Works Better with $β_1 = β_2$: The Missing Gradient Scale Invariance Principle", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "23 pages, 8 figures. Preprint", "summary": "Adam has been at the core of large-scale training for almost a decade, yet a simple empirical fact remains unaccounted for: both validation scores and the qualitative behaviour of the training runs improve when the momentum parameters satisfy $β_{1}=β_{2}$. Some recent studies have reported this pattern, but there is still no explanation for why this choice helps. We show that this choice is closely tied to a structural property that we refer to as \\textit{gradient scale invariance}. We formalize this notion and prove that Adam becomes gradient scale invariant of first order if and only if $β_{1}=β_{2}$. This perspective places the balanced regime of Adam in direct alignment with the design principles underlying several recent optimizers that explicitly enforce scale-robust updates. The theory is supported by experiments across vision and language tasks, and across different architectural families, in which rescaling the gradient has a markedly smoother effect on the update when $β_{1}=β_{2}$. Overall, our results offer a coherent explanation for an open question in the behavior of Adam and provide a simple principle that helps guide the design of future optimizers.", "AI": {"tldr": "本文探讨了为何Adam优化器在$β_{1}=β_{2}$时表现更好，提出了梯度尺度不变性原理来解释这一现象。", "motivation": "为了理解为什么Adam优化器在设定$β_{1}=β_{2}$时性能更佳，并为其提供一个合理的理论基础。", "method": "通过证明当$β_{1}=β_{2}$时，Adam具有梯度尺度不变性来解释这一现象。并通过实验证明了这一理论的有效性。", "result": "实验结果表明，在视觉和语言任务中，当$β_{1}=β_{2}$时，梯度缩放对更新的影响更平滑。", "conclusion": "本文提供了一个关于Adam优化器行为的合理解释，并提出了一种简单的原则来指导未来优化器的设计。"}}
{"id": "2601.21738", "pdf": "https://arxiv.org/pdf/2601.21738", "abs": "https://arxiv.org/abs/2601.21738", "authors": ["Baoliang Chen", "Danni Huang", "Hanwei Zhu", "Lingyu Zhu", "Wei Zhou", "Shiqi Wang", "Yuming Fang", "Weisi Lin"], "title": "From Global to Granular: Revealing IQA Model Performance via Correlation Surface", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Evaluation of Image Quality Assessment (IQA) models has long been dominated by global correlation metrics, such as Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank-Order Correlation Coefficient (SRCC). While widely adopted, these metrics reduce performance to a single scalar, failing to capture how ranking consistency varies across the local quality spectrum. For example, two IQA models may achieve identical SRCC values, yet one ranks high-quality images (related to high Mean Opinion Score, MOS) more reliably, while the other better discriminates image pairs with small quality/MOS differences (related to $|Δ$MOS$|$). Such complementary behaviors are invisible under global metrics. Moreover, SRCC and PLCC are sensitive to test-sample quality distributions, yielding unstable comparisons across test sets. To address these limitations, we propose \\textbf{Granularity-Modulated Correlation (GMC)}, which provides a structured, fine-grained analysis of IQA performance. GMC includes: (1) a \\textbf{Granularity Modulator} that applies Gaussian-weighted correlations conditioned on absolute MOS values and pairwise MOS differences ($|Δ$MOS$|$) to examine local performance variations, and (2) a \\textbf{Distribution Regulator} that regularizes correlations to mitigate biases from non-uniform quality distributions. The resulting \\textbf{correlation surface} maps correlation values as a joint function of MOS and $|Δ$MOS$|$, providing a 3D representation of IQA performance. Experiments on standard benchmarks show that GMC reveals performance characteristics invisible to scalar metrics, offering a more informative and reliable paradigm for analyzing, comparing, and deploying IQA models. Codes are available at https://github.com/Dniaaa/GMC.", "AI": {"tldr": "本文提出了基于粒度调节的相关性分析方法（GMC），用于更精细地评估图像质量评价模型的性能。", "motivation": "传统全局相关性指标如PLCC和SRCC无法捕捉不同质量级别间的排名一致性变化，并且对测试样本的质量分布敏感，导致跨数据集对比不稳定。为解决这些问题，本文提出了一种新的分析方法。", "method": "GMC包括粒度调节器（应用于绝对MOS值及MOS差的高斯加权相关性计算）和分布调节器（用于均衡质量分布偏斜的影响），并通过生成以MOS与|ΔMOS|为变量的相关表面图来展现更精细的性能。", "result": "实验表明，GMC揭示了传统标量指标未能显示出来的模型性能特征，并提供了更加直观可靠的评估方法。", "conclusion": "GMC作为一种细粒度分析工具能够帮助更好地理解和比较IQA模型，在图像质量评价领域具有重要意义。"}}
{"id": "2601.21737", "pdf": "https://arxiv.org/pdf/2601.21737", "abs": "https://arxiv.org/abs/2601.21737", "authors": ["Rebecca Pelke", "Joel Klein", "Jose Cubero-Cascante", "Nils Bosbach", "Jan Moritz Joseph", "Rainer Leupers"], "title": "Mixed-Precision Training and Compilation for RRAM-based Computing-in-Memory Accelerators", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "Computing-in-Memory (CIM) accelerators are a promising solution for accelerating Machine Learning (ML) workloads, as they perform Matrix-Vector Multiplications (MVMs) on crossbar arrays directly in memory. Although the bit widths of the crossbar inputs and cells are very limited, most CIM compilers do not support quantization below 8 bit. As a result, a single MVM requires many compute cycles, and weights cannot be efficiently stored in a single crossbar cell. To address this problem, we propose a mixed-precision training and compilation framework for CIM architectures. The biggest challenge is the massive search space, that makes it difficult to find good quantization parameters. This is why we introduce a reinforcement learning-based strategy to find suitable quantization configurations that balance latency and accuracy. In the best case, our approach achieves up to a 2.48x speedup over existing state-of-the-art solutions, with an accuracy loss of only 0.086 %.", "AI": {"tldr": "提出了一种混合精度训练和编译框架，用于RRAM基的计算存储加速器。", "motivation": "现有的CIM加速器无法支持低于8位的量化，导致单个MVM需要多个计算周期，并且权重不能有效存储在单一交叉点单元中。", "method": "引入了基于强化学习的方法来寻找合适的量化配置，平衡延迟和精度。", "result": "该方法在最佳情况下可实现最高2.48倍的速度提升，同时仅有0.086%的准确性损失。", "conclusion": "所提出的混合精度训练和编译框架能够有效提高RRAM基CIM加速器的性能。"}}
{"id": "2601.21726", "pdf": "https://arxiv.org/pdf/2601.21726", "abs": "https://arxiv.org/abs/2601.21726", "authors": ["Siru Zhong", "Yiqiu Liu", "Zhiqing Cui", "Zezhi Shao", "Fei Wang", "Qingsong Wen", "Yuxuan Liang"], "title": "DropoutTS: Sample-Adaptive Dropout for Robust Time Series Forecasting", "categories": ["cs.AI"], "comment": null, "summary": "Deep time series models are vulnerable to noisy data ubiquitous in real-world applications. Existing robustness strategies either prune data or rely on costly prior quantification, failing to balance effectiveness and efficiency. In this paper, we introduce DropoutTS, a model-agnostic plugin that shifts the paradigm from \"what\" to learn to \"how much\" to learn. DropoutTS employs a Sample-Adaptive Dropout mechanism: leveraging spectral sparsity to efficiently quantify instance-level noise via reconstruction residuals, it dynamically calibrates model learning capacity by mapping noise to adaptive dropout rates - selectively suppressing spurious fluctuations while preserving fine-grained fidelity. Extensive experiments across diverse noise regimes and open benchmarks show DropoutTS consistently boosts superior backbones' performance, delivering advanced robustness with negligible parameter overhead and no architectural modifications. Our code is available at https://github.com/CityMind-Lab/DropoutTS.", "AI": {"tldr": "DropoutTS是一种用于增强时间序列预测鲁棒性的模型无关插件，通过自适应调整丢弃率来减少噪声数据的影响。", "motivation": "深度时间序列模型在处理现实世界中的嘈杂数据时容易受到影响。当前的稳健策略要么剪枝数据，要么依赖昂贵的事先量化，无法兼顾有效性和效率。", "method": "DropoutTS采用样本自适应丢弃机制：利用谱稀疏性高效地通过重建残差量化解实例级噪声，并动态校准模型学习能力，将噪声映射为自适应的丢弃率。", "result": "广泛的实验表明，在各种噪音条件下和公开基准测试中，DropoutTS能够一致提升后骨干网络性能，提供先进鲁棒性的同时保持参数开销极低且无需架构修改。", "conclusion": "DropoutTS成功提高了时间序列预测模型的稳健性和准确性。"}}
{"id": "2601.21722", "pdf": "https://arxiv.org/pdf/2601.21722", "abs": "https://arxiv.org/abs/2601.21722", "authors": ["Neil Heinrich Braun", "Keane Ong", "Rui Mao", "Erik Cambria", "Gianmarco Mengaldo"], "title": "Enhancing Language Models for Robust Greenwashing Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sustainability reports are critical for ESG assessment, yet greenwashing and vague claims often undermine their reliability. Existing NLP models lack robustness to these practices, typically relying on surface-level patterns that generalize poorly. We propose a parameter-efficient framework that structures LLM latent spaces by combining contrastive learning with an ordinal ranking objective to capture graded distinctions between concrete actions and ambiguous claims. Our approach incorporates gated feature modulation to filter disclosure noise and utilizes MetaGradNorm to stabilize multi-objective optimization. Experiments in cross-category settings demonstrate superior robustness over standard baselines while revealing a trade-off between representational rigidity and generalization.", "AI": {"tldr": "本文提出了一种增强语言模型以更准确地检测绿色漂洗的框架。", "motivation": "现有的NLP模型在识别绿色漂洗和模糊声明时表现出不足，缺乏鲁棒性。这些模型通常依赖于表面模式，泛化能力差。", "method": "该方法结合对比学习和序数排名目标来构造语言模型的潜在空间，并使用门控特征调制过滤披露噪声以及利用MetaGradNorm稳定多目标优化。", "result": "在跨类别的实验中，所提出的方法显示出比标准基线更高的鲁棒性，但也揭示了表示刚性和泛化之间的权衡。", "conclusion": "该框架可以有效提高语言模型检测绿色漂洗的准确性，并为解决绿色漂洗问题提供了新的视角。"}}
{"id": "2601.21718", "pdf": "https://arxiv.org/pdf/2601.21718", "abs": "https://arxiv.org/abs/2601.21718", "authors": ["Lukas Schäfer", "Pallavi Choudhury", "Abdelhak Lemkhenter", "Chris Lovett", "Somjit Nath", "Luis França", "Matheus Ribeiro Furtado de Mendonça", "Alex Lamb", "Riashat Islam", "Siddhartha Sen", "John Langford", "Katja Hofmann", "Sergio Valcarcel Macua"], "title": "When does predictive inverse dynamics outperform behavior cloning?", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Behavior cloning (BC) is a practical offline imitation learning method, but it often fails when expert demonstrations are limited. Recent works have introduced a class of architectures named predictive inverse dynamics models (PIDM) that combine a future state predictor with an inverse dynamics model (IDM). While PIDM often outperforms BC, the reasons behind its benefits remain unclear. In this paper, we provide a theoretical explanation: PIDM introduces a bias-variance tradeoff. While predicting the future state introduces bias, conditioning the IDM on the prediction can significantly reduce variance. We establish conditions on the state predictor bias for PIDM to achieve lower prediction error and higher sample efficiency than BC, with the gap widening when additional data sources are available. We validate the theoretical insights empirically in 2D navigation tasks, where BC requires up to five times (three times on average) more demonstrations than PIDM to reach comparable performance; and in a complex 3D environment in a modern video game with high-dimensional visual inputs and stochastic transitions, where BC requires over 66\\% more samples than PIDM.", "AI": {"tldr": "论文探讨了预测逆动力学模型（PIDM）如何在演示数据有限时优于行为克隆（BC），并提供了理论解释。", "motivation": "行为克隆法通常在专家演示数据不足的情况下表现不佳，而最近引入的预测逆动力学模型虽然常表现出色但其背后的原因尚不清楚。因此论文探讨了PIDM优于BC的具体原因。", "method": "该研究通过建立状态预测偏差与PIDM误差和样本效率之间的关系进行了理论解释，并在二维导航任务及现代视频游戏中的复杂三维环境中验证了这些理论见解的正确性。", "result": "实验结果表明，在某些情况下，相比于行为克隆法，PIDM可以使用少得多的数据量达到相同性能；具体而言，BC需要比PIDM多五倍（平均三倍）的演示数据才能获得相等的表现，并且在复杂环境中表现更为突出。", "conclusion": "论文揭示了预测逆动力学模型优于行为克隆法的具体原因，并证明该理论解释通过实验得到了验证。"}}
{"id": "2601.21716", "pdf": "https://arxiv.org/pdf/2601.21716", "abs": "https://arxiv.org/abs/2601.21716", "authors": ["Mingshuang Luo", "Shuang Liang", "Zhengkun Rong", "Yuxuan Luo", "Tianshu Hu", "Ruibing Hou", "Hong Chang", "Yong Li", "Yuan Zhang", "Mingyuan Gao"], "title": "DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a \"see-saw\", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/", "AI": {"tldr": "本文提出了一种通用的动画框架DreamActor-M2，用于通过时空上下文学习将运动从驱动序列转移到静态参考图像上。", "motivation": "现有的方法在身份保持和运动一致性之间存在权衡，并且依赖于明确的姿态先验来捕捉复杂的动态特性。", "method": "本文提出了一种两阶段的方法：首先，融合参考外观和运动线索到统一的潜在空间中；其次，引入自引导数据合成流程以促进从姿态依赖控制向直接RGB驱动动画转变。", "result": "DreamActor-M2在广泛的字符类型和运动场景上实现了最先进的性能，并提高了视觉保真度和跨域泛化能力。", "conclusion": "本文提出的方法有效解决了现有方法中存在的问题，通过引入新的框架来提高动画合成的精度和普遍性。"}}
{"id": "2601.21714", "pdf": "https://arxiv.org/pdf/2601.21714", "abs": "https://arxiv.org/abs/2601.21714", "authors": ["Kaixiang Wang", "Yidan Lin", "Jiong Lou", "Zhaojiacheng Zhou", "Bunyod Suvonov", "Jie Li"], "title": "E-mem: Multi-agent based Episodic Context Reconstruction for LLM Agent Memory", "categories": ["cs.AI"], "comment": "18 pages", "summary": "The evolution of Large Language Model (LLM) agents towards System~2 reasoning, characterized by deliberative, high-precision problem-solving, requires maintaining rigorous logical integrity over extended horizons. However, prevalent memory preprocessing paradigms suffer from destructive de-contextualization. By compressing complex sequential dependencies into pre-defined structures (e.g., embeddings or graphs), these methods sever the contextual integrity essential for deep reasoning. To address this, we propose E-mem, a framework shifting from Memory Preprocessing to Episodic Context Reconstruction. Inspired by biological engrams, E-mem employs a heterogeneous hierarchical architecture where multiple assistant agents maintain uncompressed memory contexts, while a central master agent orchestrates global planning. Unlike passive retrieval, our mechanism empowers assistants to locally reason within activated segments, extracting context-aware evidence before aggregation. Evaluations on the LoCoMo benchmark demonstrate that E-mem achieves over 54\\% F1, surpassing the state-of-the-art GAM by 7.75\\%, while reducing token cost by over 70\\%.", "AI": {"tldr": "提出E-mem框架，通过多代理的事件重构来解决大型语言模型记忆中的上下文完整性问题。", "motivation": "现有的内存预处理方法会导致破坏性去上下文化，影响深度推理的能力。", "method": "设计了一种基于生物脑印的异构分层架构，其中多个助手代理维护未压缩的记忆上下文，并由中央主代理协调全局规划。", "result": "在LoCoMo基准上表现出色，F1值超过54%，比现有最佳方法GAM高出7.75%。", "conclusion": "E-mem框架通过多代理的事件重构解决了大型语言模型记忆中的上下文完整性问题。"}}
{"id": "2601.21713", "pdf": "https://arxiv.org/pdf/2601.21713", "abs": "https://arxiv.org/abs/2601.21713", "authors": ["Donatien Delehelle", "Fei Chen", "Darwin Caldwell"], "title": "Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations", "categories": ["cs.RO", "cs.AI"], "comment": "6 pages, 4 figures,", "summary": "Cloth manipulation is a ubiquitous task in everyday life, but it remains an open challenge for robotics. The difficulties in developing cloth manipulation policies are attributed to the high-dimensional state space, complex dynamics, and high propensity to self-occlusion exhibited by fabrics. As analytical methods have not been able to provide robust and general manipulation policies, reinforcement learning (RL) is considered a promising approach to these problems. However, to address the large state space and complex dynamics, data-based methods usually rely on large models and long training times. The resulting computational cost significantly hampers the development and adoption of these methods. Additionally, due to the challenge of robust state estimation, garment manipulation policies often adopt an end-to-end learning approach with workspace images as input. While this approach enables a conceptually straightforward sim-to-real transfer via real-world fine-tuning, it also incurs a significant computational cost by training agents on a highly lossy representation of the environment state. This paper questions this common design choice by exploring an efficient and modular approach to RL for cloth manipulation. We show that, through careful design choices, model size and training time can be significantly reduced when learning in simulation. Furthermore, we demonstrate how the resulting simulation-trained model can be transferred to the real world. We evaluate our approach on the SoftGym benchmark and achieve significant performance improvements over available baselines on our task, while using a substantially smaller model.", "AI": {"tldr": "本文提出了一种高效模块化的方法，用于减少仿真训练中的模型大小和训练时间，并展示如何将仿真训练的模型转移到现实世界中进行布料操纵任务。", "motivation": "现有基于数据的方法在解决高维状态空间、复杂动力学以及自我遮挡等问题时需要大规模模型与长时间训练，导致计算成本高昂，而端到端学习方法虽然便于概念上的仿真到现实转换，但使用环境状态的高度损失表示也带来了显著的计算开销。因此本文提出了一种新方法来解决这些问题。", "method": "通过仔细设计选择，在模拟中大幅减少模型大小和训练时间；然后展示如何将这种仿真实验中的模型转移到实际环境中，并在SoftGym基准上进行评估以验证该方法的有效性。", "result": "实验结果表明，相较于现有基线算法，在使用较小模型的情况下实现了显著的性能提升。", "conclusion": "提出的高效模块化学习方法不仅能够减少仿真训练的成本，还能有效地将学到的知识应用到实际环境中去解决布料操作任务，并在性能上超越了现有的基准方法。"}}
{"id": "2601.21712", "pdf": "https://arxiv.org/pdf/2601.21712", "abs": "https://arxiv.org/abs/2601.21712", "authors": ["Xuanran Zhai", "Binkai Ou", "Yemin Wang", "Hui Yi Leong", "Qiaojun Yu", "Ce Hao", "Yaohua Liu"], "title": "CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation", "categories": ["cs.RO"], "comment": null, "summary": "Vision Language Action (VLA) models enable instruction following manipulation, yet dualarm deployment remains unsafe due to under modeled selfcollisions between arms and grasped objects. We introduce CoFreeVLA, which augments an endtoend VLA with a short horizon selfcollision risk estimator that predicts collision likelihood from proprioception, visual embeddings, and planned actions. The estimator gates risky commands, recovers to safe states via risk-guided adjustments, and shapes policy refinement for safer rollouts. It is pre-trained with model-based collision labels and posttrained on real robot rollouts for calibration. On five bimanual tasks with the PiPER robot arm, CoFreeVLA reduces selfcollisions and improves success rates versus RDT and APEX.", "AI": {"tldr": "引入CoFreeVLA模型，通过视觉语言动作模型和风险估计减少双臂操作中的自我碰撞。", "motivation": "现有的Vision-Language-Action(VLA)模型在双臂部署中存在安全问题，容易发生手臂与抓取物体之间的自相撞。", "method": "提出一种短时间窗口的自我碰撞风险评估器，结合姿态感知、视觉嵌入和规划动作预测碰撞可能性，并通过模型预训练和真实机器人演练校准。", "result": "在五个双臂任务上，CoFreeVLA比RDT和APEX减少了自相撞，提高了成功率。", "conclusion": "CoFreeVLA有效解决了双臂操作中的自我碰撞问题，提升了操作的安全性和成功率。"}}
{"id": "2601.21711", "pdf": "https://arxiv.org/pdf/2601.21711", "abs": "https://arxiv.org/abs/2601.21711", "authors": ["Huiyuan Lai", "Malvina Nissim"], "title": "TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with redundant intermediate steps. To improve learning and reasoning efficiency, while preserving or even enhancing performance, we propose TACLer, a model-tailored curriculum reinforcement learning framework that gradually increases the complexity of the data based on the model's proficiency in multi-stage RL training. TACLer features two core components: (i) tailored curriculum learning that determines what knowledge the model lacks and needs to learn in progressive stages; (ii) a hybrid Thinking/NoThinking reasoning paradigm that balances accuracy and efficiency by enabling or disabling the Thinking mode. Our experiments show that TACLer yields a twofold advantage in learning and reasoning: (i) it reduces computational cost, cutting training compute by over 50% compared to long thinking models and reducing inference token usage by over 42% relative to the base model; and (ii) it improves accuracy by over 9% on the base model, consistently outperforming state-of-the-art Nothinking and Thinking baselines across four math datasets with complex problems.", "AI": {"tldr": "TACLer是一种为提高大语言模型在复杂推理任务上的学习和推理效率而设计的框架。", "motivation": "大型语言模型在具有长链式思维(Chain-of-Thought, CoT)推理时，在复杂的推理任务中表现出色，但通常需要大规模强化学习训练，并且可能导致过度思考和冗余中间步骤。为了提高学习与推理效率的同时保持甚至提升性能，研究人员设计了TACLer框架。", "method": "TACLer包括两个核心组成部分：（i）根据模型在多阶段RL训练中的熟练度逐步增加数据复杂性的定制化课程学习；（ii）一种混合的思考/不思考推理范式，通过启用或禁用思考模式来平衡准确性和效率。", "result": "实验结果表明，TACLer框架在学习和推理上具有双重优势：减少计算成本，相较于长期思考模型将训练计算量降低50%以上；相对于基础模型减少42%的推断令牌使用量；提高准确性，在四个数学数据集上的基准模型基础上提高了9％以上的准确率。", "conclusion": "TACLer框架通过定制化课程学习和混合推理范式，有效降低了大型语言模型在复杂推理任务中的训练计算成本和推理消耗，同时提升了模型的性能。"}}
{"id": "2601.21708", "pdf": "https://arxiv.org/pdf/2601.21708", "abs": "https://arxiv.org/abs/2601.21708", "authors": ["Tongxi Wang"], "title": "FBS: Modeling Native Parallel Reading inside a Transformer", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel across many tasks, yet inference is still dominated by strictly token-by-token autoregression. Existing acceleration methods largely patch this pipeline and miss core human-reading ingredients: content-adaptive foresight, chunk-structure-aware compute allocation, and train--test consistency for preview/skimming. We propose the \\textbf{Fovea-Block-Skip Transformer} (FBS), which injects a causal, trainable loop into Transformers via Parafovea-Attention Window (PAW), Chunk-Head (CH), and Skip-Gate (SG). Across diverse benchmarks, FBS improves the quality-efficiency trade-off without increasing parameters, and ablations show the three modules are complementary.", "AI": {"tldr": "本文提出了Fovea-Block-Skip Transformer（FBS）模型，通过Parafovea-Attention Window、Chunk-Head和Skip-Gate三个模块，在不增加参数的情况下提高Transformer的质量效率。", "motivation": "现有的加速方法主要修补了传统的token-by-token自回归推理流程，并未引入核心的人类阅读特性：内容适应性的前瞻性、块结构感知的计算分配及训练测试一致的预览/浏览机制。因此，作者提出FBS来弥补这一缺陷。", "method": "通过Parafovea-Attention Window（PAW）、Chunk-Head（CH）和Skip-Gate（SG），在Transformer中引入了可训练的因果循环，从而实现内容适应性的前瞻性和块结构感知的计算分配，提高模型的质量效率。", "result": "在各种基准测试中，FBS提高了质量和效率之间的权衡，并且消融实验表明这三个模块是互补的。", "conclusion": "通过引入Parafovea-Attention Window、Chunk-Head和Skip-Gate，FBS在不增加参数的情况下提高了Transformer模型的质量效率。"}}
{"id": "2601.21700", "pdf": "https://arxiv.org/pdf/2601.21700", "abs": "https://arxiv.org/abs/2601.21700", "authors": ["Wonduk Seo", "Wonseok Choi", "Junseo Koh", "Juhyeon Lee", "Hyunjin An", "Minhyeong Yu", "Jian Park", "Qingshan Zhou", "Seunghyun Lee", "Yi Bu"], "title": "Toward Culturally Aligned LLMs through Ontology-Guided Multi-Agent Reasoning", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.MA", "cs.SI"], "comment": "35 pages", "summary": "Large Language Models (LLMs) increasingly support culturally sensitive decision making, yet often exhibit misalignment due to skewed pretraining data and the absence of structured value representations. Existing methods can steer outputs, but often lack demographic grounding and treat values as independent, unstructured signals, reducing consistency and interpretability. We propose OG-MAR, an Ontology-Guided Multi-Agent Reasoning framework. OG-MAR summarizes respondent-specific values from the World Values Survey (WVS) and constructs a global cultural ontology by eliciting relations over a fixed taxonomy via competency questions. At inference time, it retrieves ontology-consistent relations and demographically similar profiles to instantiate multiple value-persona agents, whose outputs are synthesized by a judgment agent that enforces ontology consistency and demographic proximity. Experiments on regional social-survey benchmarks across four LLM backbones show that OG-MAR improves cultural alignment and robustness over competitive baselines, while producing more transparent reasoning traces.", "AI": {"tldr": "提出OG-MAR框架，通过语义网指导的多智能体推理提升大型语言模型的文化一致性。", "motivation": "现有方法难以解决文化偏见问题，缺少人口统计学基础，并将价值观视为独立、无结构的信息。", "method": "建立基于世界价值观调查的个人价值观摘要和全球文化本体论，通过竞争力提问提取固定分类体系中的关系。在推理阶段，检索符合本体论一致性和人口相似性的关系与配置文件，生成多个价值角色智能体，其输出由判断智能体综合。", "result": "实验证明，在不同大型语言模型骨干网上的区域社会调查基准测试中，OG-MAR优于竞争对手基线，提升文化一致性和鲁棒性，产生更透明的推理痕迹。", "conclusion": "OG-MAR框架通过多代理推理和结构化价值表示提升了大型语言模型的文化一致性，并增强了其解释性和鲁棒性。"}}
{"id": "2601.21698", "pdf": "https://arxiv.org/pdf/2601.21698", "abs": "https://arxiv.org/abs/2601.21698", "authors": ["Mohamed Elgaar", "Hadi Amiri"], "title": "Curriculum Learning for LLM Pretraining: An Analysis of Learning Dynamics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Curriculum learning changes the order of pre-training data, but it remains unclear whether it changes the learning trajectory or mainly reorders exposure over a fixed trajectory. We train Pythia models (14M-410M parameters) for 300B tokens under three linguistically motivated curricula-Age-of-Acquisition, word frequency, and Verb Variation (VV)-and compare each against Random ordering; at 1B parameters we compare Random and VV. Across orderings, training follows a shared sequence of latent phases, while curricula mainly change within-phase data exposure. In smaller models (up to 160M parameters), Random ordering exhibits higher gradient noise and stronger late-training output-head spectral saturation, alongside lower final accuracy; curricula reduce both effects at matched compute. At larger scales, saturation differences are smaller and curriculum gains shrink. We formalize the link between difficulty pacing and optimization stability in an idealized analysis based on gradient-variance control, and our results point to a practical takeaway: curricula help by stabilizing within-phase optimization rather than by creating new phases.", "AI": {"tldr": "研究通过不同的课程学习方法对LLM预训练的影响，探讨是否改变学习轨迹或仅重新排序数据。", "motivation": "探究课程学习在语言模型预训练中的作用，以及它如何影响学习过程和最终准确性。", "method": "使用三种基于年龄、词频和动词变化的课程顺序对Pythia模型进行预训练，并与随机顺序比较。分析不同规模下的优化稳定性和输出饱和度的变化。", "result": "在较小模型中，随机排序表现出更高的梯度噪声及较低准确性；课程学习减少了这些问题。随着模型大小增加，这些差异减小。", "conclusion": "课程学习通过改善阶段内优化稳定性而非创建新阶段来帮助训练过程，并指出此方法的实际应用价值在于稳定优化而不是改变整体学习轨迹。"}}
{"id": "2601.21694", "pdf": "https://arxiv.org/pdf/2601.21694", "abs": "https://arxiv.org/abs/2601.21694", "authors": ["Shuo Li", "Jiajun Sun", "Zhekai Wang", "Xiaoran Fan", "Hui Li", "Dingwen Yang", "Zhiheng Xi", "Yijun Wang", "Zifei Shan", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "ChartE$^{3}$: A Comprehensive Benchmark for End-to-End Chart Editing", "categories": ["cs.CV"], "comment": "Our benchmark will be publicly available at https://github.com/galactic123/ChartE3", "summary": "Charts are a fundamental visualization format for structured data analysis. Enabling end-to-end chart editing according to user intent is of great practical value, yet remains challenging due to the need for both fine-grained control and global structural consistency. Most existing approaches adopt pipeline-based designs, where natural language or code serves as an intermediate representation, limiting their ability to faithfully execute complex edits. We introduce ChartE$^{3}$, an End-to-End Chart Editing benchmark that directly evaluates models without relying on intermediate natural language programs or code-level supervision. ChartE$^{3}$ focuses on two complementary editing dimensions: local editing, which involves fine-grained appearance changes such as font or color adjustments, and global editing, which requires holistic, data-centric transformations including data filtering and trend line addition. ChartE$^{3}$ contains over 1,200 high-quality samples constructed via a well-designed data pipeline with human curation. Each sample is provided as a triplet of a chart image, its underlying code, and a multimodal editing instruction, enabling evaluation from both objective and subjective perspectives. Extensive benchmarking of state-of-the-art multimodal large language models reveals substantial performance gaps, particularly on global editing tasks, highlighting critical limitations in current end-to-end chart editing capabilities.", "AI": {"tldr": "提出了一种名为ChartE$^{3}$的端到端图表编辑基准，直接评估模型在无需中间自然语言程序或代码级监督下的性能。", "motivation": "现有方法采用管道式设计，依赖于自然语言或代码作为中间表示，限制了其执行复杂编辑的能力。因此，需要一种可以直接评估模型并在不使用中间步骤的情况下进行图表编辑的基准。", "method": "ChartE$^{3}$专注于局部和全局编辑两个方面，并通过精心设计的数据流水线创建超过1200个高质量样本，每个样本包含一个图表图像、其底层代码以及一个多模式编辑指令。", "result": "对最先进的多模态大型语言模型进行了广泛的基准测试，揭示了在全局编辑任务上的显著性能差距。", "conclusion": "当前的端到端图表编辑能力存在重大局限性，特别是在处理数据过滤和趋势线添加等全局编辑任务时。"}}
{"id": "2601.21692", "pdf": "https://arxiv.org/pdf/2601.21692", "abs": "https://arxiv.org/abs/2601.21692", "authors": ["Mingzu Liu", "Hao Fang", "Runmin Cong"], "title": "TCAP: Tri-Component Attention Profiling for Unsupervised Backdoor Detection in MLLM Fine-Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Fine-Tuning-as-a-Service (FTaaS) facilitates the customization of Multimodal Large Language Models (MLLMs) but introduces critical backdoor risks via poisoned data. Existing defenses either rely on supervised signals or fail to generalize across diverse trigger types and modalities. In this work, we uncover a universal backdoor fingerprint-attention allocation divergence-where poisoned samples disrupt the balanced attention distribution across three functional components: system instructions, vision inputs, and user textual queries, regardless of trigger morphology. Motivated by this insight, we propose Tri-Component Attention Profiling (TCAP), an unsupervised defense framework to filter backdoor samples. TCAP decomposes cross-modal attention maps into the three components, identifies trigger-responsive attention heads via Gaussian Mixture Model (GMM) statistical profiling, and isolates poisoned samples through EM-based vote aggregation. Extensive experiments across diverse MLLM architectures and attack methods demonstrate that TCAP achieves consistently strong performance, establishing it as a robust and practical backdoor defense in MLLMs.", "AI": {"tldr": "提出了TCAP框架，用于在多模态大语言模型的微调过程中进行无监督后门检测。", "motivation": "细调服务引入了通过毒化数据造成的重要后门风险。现有防御手段依赖于有监督信号或无法跨不同类型触发器和模式泛化。", "method": "提出了TCAP框架，该框架基于注意力分配差异来过滤后门样本。利用高斯混合模型对触发响应的注意力头进行统计分析，并通过期望最大化聚合投票以识别毒化样本。", "result": "实验证明了TCAP在不同多模态语言模型架构和攻击方法下表现出色。", "conclusion": "证明了TCAP作为多模态大语言模型中强大的无监督后门防御的有效性和实用性。"}}
{"id": "2601.21688", "pdf": "https://arxiv.org/pdf/2601.21688", "abs": "https://arxiv.org/abs/2601.21688", "authors": ["Alexandre Myara", "Nicolas Bourriez", "Thomas Boyer", "Thomas Lemercier", "Ihab Bendidi", "Auguste Genovesio"], "title": "XFACTORS: Disentangled Information Bottleneck via Contrastive Supervision", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Disentangled representation learning aims to map independent factors of variation to independent representation components. On one hand, purely unsupervised approaches have proven successful on fully disentangled synthetic data, but fail to recover semantic factors from real data without strong inductive biases. On the other hand, supervised approaches are unstable and hard to scale to large attribute sets because they rely on adversarial objectives or auxiliary classifiers. We introduce \\textsc{XFactors}, a weakly-supervised VAE framework that disentangles and provides explicit control over a chosen set of factors. Building on the Disentangled Information Bottleneck perspective, we decompose the representation into a residual subspace $\\mathcal{S}$ and factor-specific subspaces $\\mathcal{T}_1,\\ldots,\\mathcal{T}_K$ and a residual subspace $\\mathcal{S}$. Each target factor is encoded in its assigned $\\mathcal{T}_i$ through contrastive supervision: an InfoNCE loss pulls together latents sharing the same factor value and pushes apart mismatched pairs. In parallel, KL regularization imposes a Gaussian structure on both $\\mathcal{S}$ and the aggregated factor subspaces, organizing the geometry without additional supervision for non-targeted factors and avoiding adversarial training and classifiers. Across multiple datasets, with constant hyperparameters, \\textsc{XFactors} achieves state-of-the-art disentanglement scores and yields consistent qualitative factor alignment in the corresponding subspaces, enabling controlled factor swapping via latent replacement. We further demonstrate that our method scales correctly with increasing latent capacity and evaluate it on the real-world dataset CelebA. Our code is available at \\href{https://github.com/ICML26-anon/XFactors}{github.com/ICML26-anon/XFactors}.", "AI": {"tldr": "本文提出了XFactors，一种通过对比监督进行弱监督的VAE框架来实现独立因素分解和控制。", "motivation": "纯粹无监督方法在合成数据上取得成功但难以从真实数据中恢复语义因素；监督方法由于依赖对抗目标或辅助分类器而不稳定且难以扩展到大量属性集。XFactors旨在解决这些问题。", "method": "通过对比监督将表示分解为剩余子空间S和特定因子的子空间T1至TK，每个目标因子在分配的Ti中编码以实现信息瓶颈视角下的分离，并使用KL正则化组织几何结构而无需额外监督。", "result": "实验显示XFactors在多个数据集上实现了最先进的解缠分数并提供了定性一致的目标因子对齐。该方法可以随潜在容量增加正确扩展，且在CelebA真实世界数据集中效果良好。", "conclusion": "XFactors解决了无监督和监督方法的限制，提供了一种有效的弱监督VAE框架来实现因素分解，并通过对比损失控制目标因子而不依赖于额外的分类器或对抗训练。"}}
{"id": "2601.21682", "pdf": "https://arxiv.org/pdf/2601.21682", "abs": "https://arxiv.org/abs/2601.21682", "authors": ["Xiaoyu Xu", "Minxin Du", "Kun Fang", "Zi Liang", "Yaxin Xiao", "Zhicong Huang", "Cheng Hong", "Qingqing Ye", "Haibo Hu"], "title": "FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "comment": "20 Pages", "summary": "Large language models (LLMs) demonstrate impressive capabilities across diverse tasks but raise concerns about privacy, copyright, and harmful materials. Existing LLM unlearning methods rarely consider the continual and high-volume nature of real-world deletion requests, which can cause utility degradation and catastrophic forgetting as requests accumulate. To address this challenge, we introduce \\fit, a framework for continual unlearning that handles large numbers of deletion requests while maintaining robustness against both catastrophic forgetting and post-unlearning recovery. \\fit mitigates degradation through rigorous data \\underline{F}iltering, \\underline{I}mportance-aware updates, and \\underline{T}argeted layer attribution, enabling stable performance across long sequences of unlearning operations and achieving a favorable balance between forgetting effectiveness and utility retention. To support realistic evaluation, we present \\textbf{PCH}, a benchmark covering \\textbf{P}ersonal information, \\textbf{C}opyright, and \\textbf{H}armful content in sequential deletion scenarios, along with two symmetric metrics, Forget Degree (F.D.) and Retain Utility (R.U.), which jointly assess forgetting quality and utility preservation. Extensive experiments on four open-source LLMs with hundreds of deletion requests show that \\fit achieves the strongest trade-off between F.D. and R.U., surpasses existing methods on MMLU, CommonsenseQA, and GSM8K, and remains resistant against both relearning and quantization recovery attacks.", "AI": {"tldr": "本文提出了一个名为FIT的框架，旨在解决大规模语言模型中连续删除请求导致的记忆遗忘和性能下降问题。", "motivation": "现有的LLM撤销学习方法无法有效处理真实世界中的大量连续删除请求，这可能导致性能退化和灾难性遗忘。因此，需要一种新的方法来克服这些挑战。", "method": "FIT通过严格的过滤、重要性感知更新以及目标层归因，解决了在大量删除操作下保持模型稳定性和防止遗忘的问题。", "result": "实验表明，与其他现有技术相比，FIT在MMLU、CommonsenseQA和GSM8K等多个开放源代码LLM上实现了最佳的遗忘度与实用性的平衡，并且对重新学习和量化恢复攻击具有抵抗力。", "conclusion": "该框架通过引入PCH基准测试评估了其效果，证明了自身能够有效地处理连续删除请求并且保持模型性能，为解决大规模语言模型中的记忆遗忘问题提供了一种有效的方法。"}}
{"id": "2601.21673", "pdf": "https://arxiv.org/pdf/2601.21673", "abs": "https://arxiv.org/abs/2601.21673", "authors": ["Dexuan Ding", "Ciyuan Peng", "Endrowednes Kuantama", "Jingcai Guo", "Jia Wu", "Jian Yang", "Amin Beheshti", "Ming-Hsuan Yang", "Yuankai Qi"], "title": "Multimodal Visual Surrogate Compression for Alzheimer's Disease Classification", "categories": ["cs.CV"], "comment": null, "summary": "High-dimensional structural MRI (sMRI) images are widely used for Alzheimer's Disease (AD) diagnosis. Most existing methods for sMRI representation learning rely on 3D architectures (e.g., 3D CNNs), slice-wise feature extraction with late aggregation, or apply training-free feature extractions using 2D foundation models (e.g., DINO). However, these three paradigms suffer from high computational cost, loss of cross-slice relations, and limited ability to extract discriminative features, respectively. To address these challenges, we propose Multimodal Visual Surrogate Compression (MVSC). It learns to compress and adapt large 3D sMRI volumes into compact 2D features, termed as visual surrogates, which are better aligned with frozen 2D foundation models to extract powerful representations for final AD classification. MVSC has two key components: a Volume Context Encoder that captures global cross-slice context under textual guidance, and an Adaptive Slice Fusion module that aggregates slice-level information in a text-enhanced, patch-wise manner. Extensive experiments on three large-scale Alzheimer's disease benchmarks demonstrate our MVSC performs favourably on both binary and multi-class classification tasks compared against state-of-the-art methods.", "AI": {"tldr": "本论文提出了一种用于阿尔茨海默病分类的多模态视觉代理压缩方法（MVSC），该方法将高维结构磁共振成像数据压缩为2D特征，以便更好地利用冻结的2D基础模型进行特征提取和疾病分类。", "motivation": "现有的sMRI表示学习方法存在计算成本过高、跨切面关系丢失以及特征提取能力有限等问题。为此，本文提出了MVSC方法来解决这些问题，以提高AD诊断的准确性和效率。", "method": "MVSC包含两个关键组件：一个用于在文本指导下捕捉全局跨切面背景信息的体素上下文编码器和一个采用文本增强方式聚合切片级信息的自适应切片融合模块。通过这两个组成部分，MVSC可以将高维3D sMRI数据压缩为紧凑的2D特征，并更好地与冻结的2D基础模型对齐。", "result": "在三个大规模AD基准数据集上的广泛实验表明，相较于最先进的方法，本文提出的MVSC在二元和多类分类任务上均表现出更好的性能。", "conclusion": "通过将高维3D sMRI数据压缩为更适合与2D基础模型对齐的紧凑特征，MVSC成功解决了传统方法存在的计算成本过高、跨切面关系丢失以及有限特征提取能力等问题。"}}
{"id": "2601.21670", "pdf": "https://arxiv.org/pdf/2601.21670", "abs": "https://arxiv.org/abs/2601.21670", "authors": ["Zixuan Xia", "Hao Wang", "Pengcheng Weng", "Yanyu Qian", "Yangxin Xu", "William Dan", "Fei Wang"], "title": "When Gradient Optimization Is Not Enough: $\\dagger$ Dispersive and Anchoring Geometric Regularizer for Multimodal Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal learning aims to integrate complementary information from heterogeneous modalities, yet strong optimization alone does not guaranty well-structured representations. Even under carefully balanced training schemes, multimodal models often exhibit geometric pathologies, including intra-modal representation collapse and sample-level cross-modal inconsistency, which degrade both unimodal robustness and multimodal fusion. We identify representation geometry as a missing control axis in multimodal learning and propose \\regName, a lightweight geometry-aware regularization framework. \\regName enforces two complementary constraints on intermediate embeddings: an intra-modal dispersive regularization that promotes representation diversity, and an inter-modal anchoring regularization that bounds sample-level cross-modal drift without rigid alignment. The proposed regularizer is plug-and-play, requires no architectural modifications, and is compatible with various training paradigms. Extensive experiments across multiple multimodal benchmarks demonstrate consistent improvements in both multimodal and unimodal performance, showing that explicitly regulating representation geometry effectively mitigates modality trade-offs.", "AI": {"tldr": "本文提出了一种用于多模态学习的几何感知正则化框架，旨在通过控制表示空间的几何结构来改善模型的表现。", "motivation": "尽管经过精心平衡的训练方案可以加强多模态学习中的信息整合，但单纯的梯度优化并不能保证生成具有良好结构性的表征。因此本文强调了控制表示空间几何的重要性，并提出了新的正则化框架以解决这一问题。", "method": "\regName 是一种轻量级的、几何感知的正则化框架，它在中间嵌入上强制执行两个互补约束：一个是促进模内表征多样性的分散正则项；另一个是控制样本级别的跨模态漂移而没有刚性对齐的锚定正则项。", "result": "实验表明，在各种多模态基准上的测试显示，通过显式地调节表示空间几何结构，可以有效缓解模态之间的权衡，并且该框架在提高多模态性能的同时也能增强单模态的表现力。", "conclusion": "本文提出的正则化方法能够有效地改善多模态学习模型中的表征质量问题，同时保持了较高的灵活性和兼容性。"}}
{"id": "2601.21669", "pdf": "https://arxiv.org/pdf/2601.21669", "abs": "https://arxiv.org/abs/2601.21669", "authors": ["Abhijeet Sinha", "Sundari Elango", "Dianbo Liu"], "title": "Expected Return Causes Outcome-Level Mode Collapse in Reinforcement Learning and How to Fix It with Inverse Probability Scaling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many reinforcement learning (RL) problems admit multiple terminal solutions of comparable quality, where the goal is not to identify a single optimum but to represent a diverse set of high-quality outcomes. Nevertheless, policies trained by standard expected return maximization routinely collapse onto a small subset of outcomes, a phenomenon commonly attributed to insufficient exploration or weak regularization. We show that this explanation is incomplete: outcome level mode collapse is a structural consequence of the expected-return objective itself. Under idealized learning dynamics, the log-probability ratio between any two outcomes evolves linearly in their reward difference, implying exponential ratio divergence and inevitable collapse independent of the exploration strategy, entropy regularization, or optimization algorithm. We identify the source of this pathology as the probability multiplier inside the expectation and propose a minimal correction: inverse probability scaling, which removes outcome-frequency amplification from the learning signal, fundamentally changes the learning dynamics, and provably yields reward-proportional terminal distributions, preventing collapse in multimodal settings. We instantiate this principle in Group Relative Policy Optimization (GRPO) as a drop-in modification, IPS-GRPO, requiring no auxiliary models or architectural changes. Across different reasoning and molecular generation tasks, IPS-GRPO consistently reduces outcome-level mode collapse while matching or exceeding baseline performance, suggesting that correcting the objective rather than adding exploration heuristics is key to reliable multimodal policy optimization.", "AI": {"tldr": "本文探讨了在强化学习中，预期回报最大化导致的结局级模式崩溃，并提出了一种称为逆概率缩放（IPS）的方法来解决此问题。", "motivation": "许多强化学习任务允许存在多个质量相近的最终解决方案。然而，在标准预期回报最大化的训练下，策略通常会收敛于一组有限的结果上，这种现象往往被归咎于探索不足或正则化不够强烈。作者展示了这种解释是不完整的：结局级模式崩溃是由预期回报目标本身引起的结构性后果。", "method": "提出了一种称为逆概率缩放（IPS）的技术来修正这个问题，该技术通过移除结果频率放大从学习信号中去除，并证明可以得到与奖励成比例的终端分布，从而防止在多模态环境中发生模式崩溃。文中将这一原理应用于组相对策略优化（GRPO），形成了名为IPS-GRPO的方法。", "result": "实验表明，在不同的推理和分子生成任务上，IPS-GRPO显著减少了结局级模式崩溃同时保持或超越了基线性能。", "conclusion": "结论指出，修正目标比添加探索启发式更为关键以实现可靠的多模态策略优化。"}}
{"id": "2601.21667", "pdf": "https://arxiv.org/pdf/2601.21667", "abs": "https://arxiv.org/abs/2601.21667", "authors": ["Hao Ju", "Shaofei Huang", "Hongyu Li", "Zihan Ding", "Si Liu", "Meng Wang", "Zhedong Zheng"], "title": "From Instruction to Event: Sound-Triggered Mobile Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Current mobile manipulation research predominantly follows an instruction-driven paradigm, where agents rely on predefined textual commands to execute tasks. However, this setting confines agents to a passive role, limiting their autonomy and ability to react to dynamic environmental events. To address these limitations, we introduce sound-triggered mobile manipulation, where agents must actively perceive and interact with sound-emitting objects without explicit action instructions. To support these tasks, we develop Habitat-Echo, a data platform that integrates acoustic rendering with physical interaction. We further propose a baseline comprising a high-level task planner and low-level policy models to complete these tasks. Extensive experiments show that the proposed baseline empowers agents to actively detect and respond to auditory events, eliminating the need for case-by-case instructions. Notably, in the challenging dual-source scenario, the agent successfully isolates the primary source from overlapping acoustic interference to execute the first interaction, and subsequently proceeds to manipulate the secondary object, verifying the robustness of the baseline.", "AI": {"tldr": "本文提出了一种基于声音触发的移动操作技术，使代理能够主动感知和交互于发出声音的对象。", "motivation": "当前移动操纵研究主要依赖预定义的文字命令执行任务，限制了代理自主性和应对动态环境事件的能力。为解决这些问题，提出了声音触发的移动操作。", "method": "开发了一个名为Habitat-Echo的数据平台，将声学渲染与物理交互相结合，并提出了一种基线方法，包括高层次的任务规划器和低层次政策模型来完成这些任务。", "result": "实验表明，所提出的基线使代理能够主动探测并响应听觉事件，不需要针对每个情况的具体指令。特别是在双源场景下，验证了其鲁棒性。", "conclusion": "该方法成功实现了无需具体命令的基于声音触发的移动操作，并展示了在复杂环境中的适应性和鲁棒性。"}}
{"id": "2601.21666", "pdf": "https://arxiv.org/pdf/2601.21666", "abs": "https://arxiv.org/abs/2601.21666", "authors": ["Ahmed Y. Radwan", "Christos Emmanouilidis", "Hina Tabassum", "Deval Pandya", "Shaina Raza"], "title": "SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are a major focus of recent AI research. However, most prior work focuses on static image understanding, while their ability to process sequential audio-video data remains underexplored. This gap highlights the need for a high-quality benchmark to systematically evaluate MLLM performance in a real-world setting. We introduce SONIC-O1, a comprehensive, fully human-verified benchmark spanning 13 real-world conversational domains with 4,958 annotations and demographic metadata. SONIC-O1 evaluates MLLMs on key tasks, including open-ended summarization, multiple-choice question (MCQ) answering, and temporal localization with supporting rationales (reasoning). Experiments on closed- and open-source models reveal limitations. While the performance gap in MCQ accuracy between two model families is relatively small, we observe a substantial 22.6% performance difference in temporal localization between the best performing closed-source and open-source models. Performance further degrades across demographic groups, indicating persistent disparities in model behavior. Overall, SONIC-O1 provides an open evaluation suite for temporally grounded and socially robust multimodal understanding. We release SONIC-O1 for reproducibility and research: Project page: https://vectorinstitute.github.io/sonic-o1/ Dataset: https://huggingface.co/datasets/vector-institute/sonic-o1 Github: https://github.com/vectorinstitute/sonic-o1 Leaderboard: https://huggingface.co/spaces/vector-institute/sonic-o1-leaderboard", "AI": {"tldr": "介绍SONIC-O1，一个用于评估多模态大型语言模型在现实世界中音频视频理解能力的基准测试。", "motivation": "当前大多数关于多模态大型语言模型的研究侧重于静态图像的理解，而对序列音频视频数据处理的能力尚未充分研究。因此需要一种高质量的基准来系统性地评价这些模型的实际性能。", "method": "SONIC-O1是涵盖13个实际对话领域的综合且完全由人验证的数据集，包含4958个注释和人口统计元数据。它评估了开放型总结、多项选择题回答以及时间定位的任务，并通过实验揭示了不同模型之间的性能差异。", "result": "在多选题准确率上两个模型家族的性能差距较小，而在最佳闭源与开源模型间的时间定位任务中存在22.6%的巨大差距。此外，模型的表现随人口统计分组的不同而有所下降，表明存在着持久的行为不一致。", "conclusion": "SONIC-O1提供了一个公开的评估套件，用于基于时间的理解和具有社会鲁棒性的多模态理解，并已发布以供重复性和研究使用。"}}
{"id": "2601.21664", "pdf": "https://arxiv.org/pdf/2601.21664", "abs": "https://arxiv.org/abs/2601.21664", "authors": ["Xingyue Zhang", "Yuxuan Bao", "Mars Liyao Gao", "J. Nathan Kutz"], "title": "SENDAI: A Hierarchical Sparse-measurement, EfficieNt Data AssImilation Framework", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Bridging the gap between data-rich training regimes and observation-sparse deployment conditions remains a central challenge in spatiotemporal field reconstruction, particularly when target domains exhibit distributional shifts, heterogeneous structure, and multi-scale dynamics absent from available training data. We present SENDAI, a hierarchical Sparse-measurement, EfficieNt Data AssImilation Framework that reconstructs full spatial states from hyper sparse sensor observations by combining simulation-derived priors with learned discrepancy corrections. We demonstrate the performance on satellite remote sensing, reconstructing MODIS (Moderate Resolution Imaging Spectroradiometer) derived vegetation index fields across six globally distributed sites. Using seasonal periods as a proxy for domain shift, the framework consistently outperforms established baselines that require substantially denser observations -- SENDAI achieves a maximum SSIM improvement of 185% over traditional baselines and a 36% improvement over recent high-frequency-based methods. These gains are particularly pronounced for landscapes with sharp boundaries and sub-seasonal dynamics; more importantly, the framework effectively preserves diagnostically relevant structures -- such as field topologies, land cover discontinuities, and spatial gradients. By yielding corrections that are more structurally and spectrally separable, the reconstructed fields are better suited for downstream inference of indirectly observed variables. The results therefore highlight a lightweight and operationally viable framework for sparse-measurement reconstruction that is applicable to physically grounded inference, resource-limited deployment, and real-time monitor and control.", "AI": {"tldr": "SENDAI是一个结合模拟先验和学习偏差校正的分层稀疏测量数据同化框架，用于从超稀疏传感器观测中重建全空间状态。", "motivation": "在时空场重构中，解决训练阶段数据丰富而部署条件观测稀缺的问题，特别是在目标领域存在分布变化、异构结构和多尺度动态时，这是一个关键挑战。SENDAI旨在填补这一空白。", "method": "SENDAI通过结合模拟先验知识与学习偏差校正来重建全空间状态，使用稀疏传感器数据，并在卫星遥感中验证其效果。", "result": "SENDAI框架在MODIS植被指数场重构任务中的表现优于传统基线方法和最近的高频率方法，最大SSIM改进分别为185%和36%，特别是在具有锐利边界和次季节动态的地貌中表现出更好的性能，并且能够更好地保持诊断相关结构。", "conclusion": "SENDAI是一个轻量级、操作可行的数据重构框架，在稀疏测量情况下适用于物理基础推理、资源受限部署以及实时监控控制。"}}
{"id": "2601.21663", "pdf": "https://arxiv.org/pdf/2601.21663", "abs": "https://arxiv.org/abs/2601.21663", "authors": ["Marcel Dreier", "Nora Gourmelon", "Dakota Pyles", "Thorsten Seehaus", "Matthias H. Braun", "Andreas Maier", "Vincent Christlein"], "title": "Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation", "categories": ["cs.CV"], "comment": null, "summary": "During benchmarking, the state-of-the-art model for glacier calving front delineation achieves near-human performance. However, when applied in a real-world setting at a novel study site, its delineation accuracy is insufficient for calving front products intended for further scientific analyses. This site represents an out-of-distribution domain for a model trained solely on the benchmark dataset. By employing a few-shot domain adaptation strategy, incorporating spatial static prior knowledge, and including summer reference images in the input time series, the delineation error is reduced from 1131.6 m to 68.7 m without any architectural modifications. These methodological advancements establish a framework for applying deep learning-based calving front segmentation to novel study sites, enabling calving front monitoring on a global scale.", "AI": {"tldr": "本文提出了一种基于时空信息的迁移学习方法，以改进冰川崩解前沿的划分准确性。", "motivation": "现有的最先进的模型在基准测试中表现出接近人类水平的表现，但在新研究地点的实际应用中精度不足。为了改善这种情况，作者提出了新的方法。", "method": "通过采用少量样本域适应策略，结合空间静态先验知识，并将夏季参考图像加入到输入的时间序列中来降低划分误差。", "result": "该方法使冰川崩解前沿的划分错误从1131.6米减少到了68.7米。", "conclusion": "所提出的方法为在新研究地点应用基于深度学习的冰川崩解前沿分割技术建立了一个框架，有助于在全球范围内进行冰川崩解前沿监测。"}}
{"id": "2601.21660", "pdf": "https://arxiv.org/pdf/2601.21660", "abs": "https://arxiv.org/abs/2601.21660", "authors": ["Jingyang Zhao", "Mingyu Xiao"], "title": "Improved Approximations for the Unsplittable Capacitated Vehicle Routing Problem", "categories": ["cs.DS"], "comment": null, "summary": "The capacitated vehicle routing problem (CVRP) is one of the most extensively studied problems in combinatorial optimization. In this problem, we are given a depot and a set of customers, each with a demand, embedded in a metric space. The objective is to find a set of tours, each starting and ending at the depot, operated by the capacititated vehicle at the depot to serve all customers, such that all customers are served, and the total travel cost is minimized. We consider the unplittable variant, where the demand of each customer must be served entirely by a single tour. Let $α$ denote the current best-known approximation ratio for the metric traveling salesman problem. The previous best approximation ratio was $α+1+\\ln 2+δ<3.1932$ for a small constant $δ>0$ (Friggstad et al., Math. Oper. Res. 2025), which can be further improved by a small constant using the result of Blauth, Traub, and Vygen (Math. Program. 2023). In this paper, we propose two improved approximation algorithms. The first algorithm focuses on the case of fixed vehicle capacity and achieves an approximation ratio of $α+1+\\ln\\bigl(2-\\frac{1}{2}y_0\\bigr)<3.0897$, where $y_0>0.39312$ is the unique root of $\\ln\\bigl(2-\\frac{1}{2}y\\bigr)=\\frac{3}{2}y$. The second algorithm considers general vehicle capacity and achieves an approximation ratio of $α+1+y_1+\\ln\\left(2-2y_1\\right)+δ<3.1759$ for a small constant $δ>0$, where $y_1>0.17458$ is the unique root of $\\frac{1}{2} y_1+ 6 (1-y_1)\\bigl(1-e^{-\\frac{1}{2} y_1}\\bigr) =\\ln\\left(2-2y_1\\right)$. Both approximations can be further improved by a small constant using the result of Blauth, Traub, and Vygen (Math. Program. 2023).", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.21654", "pdf": "https://arxiv.org/pdf/2601.21654", "abs": "https://arxiv.org/abs/2601.21654", "authors": ["Hao Shen", "Hang Yang", "Zhouhong Gu"], "title": "ScholarGym: Benchmarking Deep Research Workflows on Academic Literature Retrieval", "categories": ["cs.AI"], "comment": null, "summary": "Tool-augmented large language models have advanced from single-turn question answering to deep research workflows that iteratively plan queries, invoke external tools, and synthesize information to address complex information needs. Evaluating such workflows presents a fundamental challenge: reliance on live APIs introduces non-determinism, as tool invocations may yield different results across runs due to temporal drift, rate limiting, and evolving backend states. This variance undermines reproducibility and invalidates cross-system comparisons. We present ScholarGym, a simulation environment for reproducible evaluation of deep research workflows on academic literature. The environment decouples workflow components into query planning, tool invocation, and relevance assessment, enabling fine-grained analysis of each stage under controlled conditions. Built on a static corpus of 570K papers with deterministic retrieval, ScholarGym provides 2,536 queries with expert-annotated ground truth. Experiments across diverse backbone models reveal how reasoning capabilities, planning strategies, and selection mechanisms interact over iterative refinement.", "AI": {"tldr": "ScholarGym是一个用于学术文献检索的深度研究工作流模拟环境，旨在解决工具增强的大规模语言模型在复杂信息需求下评估时遇到的问题。", "motivation": "由于依赖实时API引入了不可预测性，导致工具调用的结果会因时间漂移、速率限制和后台状态变化而改变。这种变异破坏了可重复性和跨系统比较的有效性。", "method": "将工作流组件分解为查询规划、工具调用和相关性评估，并在控制条件下进行精细分析。构建于包含570K篇静态论文的语料库上，具有确定性的检索机制。", "result": "实验揭示了不同基础模型如何在其推理能力、规划策略和选择机制之间相互作用以实现迭代改进。", "conclusion": "通过提供一种模拟环境来解决深度研究工作流评估中的可重复性问题，ScholarGym有助于更公平地比较各种系统的表现。"}}
{"id": "2601.21653", "pdf": "https://arxiv.org/pdf/2601.21653", "abs": "https://arxiv.org/abs/2601.21653", "authors": ["Vasileios Sevetlidis", "George Pavlidis"], "title": "Gauge-invariant representation holonomy", "categories": ["cs.LG", "cs.AI"], "comment": "14th International Conference on Learning Representations (ICLR)", "summary": "Deep networks learn internal representations whose geometry--how features bend, rotate, and evolve--affects both generalization and robustness. Existing similarity measures such as CKA or SVCCA capture pointwise overlap between activation sets, but miss how representations change along input paths. Two models may appear nearly identical under these metrics yet respond very differently to perturbations or adversarial stress. We introduce representation holonomy, a gauge-invariant statistic that measures this path dependence. Conceptually, holonomy quantifies the \"twist\" accumulated when features are parallel-transported around a small loop in input space: flat representations yield zero holonomy, while nonzero values reveal hidden curvature. Our estimator fixes gauge through global whitening, aligns neighborhoods using shared subspaces and rotation-only Procrustes, and embeds the result back to the full feature space. We prove invariance to orthogonal (and affine, post-whitening) transformations, establish a linear null for affine layers, and show that holonomy vanishes at small radii. Empirically, holonomy increases with loop radius, separates models that appear similar under CKA, and correlates with adversarial and corruption robustness. It also tracks training dynamics as features form and stabilize. Together, these results position representation holonomy as a practical and scalable diagnostic for probing the geometric structure of learned representations beyond pointwise similarity.", "AI": {"tldr": "本文提出了表示挠率，一种衡量表示沿输入路径变化的统计量，并证明其在诊断学习表示几何结构中的实用性与可扩展性。", "motivation": "现有相似度指标如CKA或SVCCA仅捕捉激活集间的点对点重叠，忽略表示随输入路径的变化。两模型可能在此类度量下几乎相同，但对抗扰动和敌意压力下的响应却大相径庭。", "method": "提出表示挠率概念，通过全局白化解决规范问题，使用共享子空间及仅旋转的Procrustes对齐邻域，并嵌入回完整特征空间。理论证明其对正交（与后白化的仿射）变换不变，建立仿射层线性零假设。", "result": "实验证明挠率随路径半径增加而增大，能区分CKA下看似相似的模型，且与对抗及破坏鲁棒性相关联，并跟踪训练动态以观测特征形成和稳定过程。", "conclusion": "表示挠率是一种实用且可扩展的诊断工具，用于探究学习表示几何结构超越点对点相似性的方面。"}}
{"id": "2601.21652", "pdf": "https://arxiv.org/pdf/2601.21652", "abs": "https://arxiv.org/abs/2601.21652", "authors": ["Jingyang Zhao", "Mingyu Xiao"], "title": "Improved Approximations for Dial-a-Ride Problems", "categories": ["cs.DS"], "comment": null, "summary": "The multi-vehicle dial-a-ride problem (mDaRP) is a fundamental vehicle routing problem with pickups and deliveries, widely applicable in ride-sharing, economics, and transportation. Given a set of $n$ locations, $h$ vehicles of identical capacity $λ$ located at various depots, and $m$ ride requests each defined by a source and a destination, the goal is to plan non-preemptive routes that serve all requests while minimizing the total travel distance, ensuring that no vehicle carries more than $λ$ passengers at any time. The best-known approximation ratio for the mDaRP remains $\\mathcal{O}(\\sqrtλ\\log m)$. We propose two simple algorithms: the first achieves the same approximation ratio of $\\mathcal{O}(\\sqrtλ\\log m)$ with improved running time, and the second attains an approximation ratio of $\\mathcal{O}(\\sqrt{\\frac{m}λ})$. A combination of them yields an approximation ratio of $\\mathcal{O}(\\sqrt[4]{n}\\log^{\\frac{1}{2}}n)$ under $m=Θ(n)$. Moreover, for the case $m\\gg n$, by extending our algorithms, we derive an $\\mathcal{O}(\\sqrt{n\\log n})$-approximation algorithm, which also improves the current best-known approximation ratio of $\\mathcal{O}(\\sqrt{n}\\log^2n)$ for the classic (single-vehicle) DaRP, obtained by Gupta et al. (ACM Trans. Algorithms, 2010).", "AI": {"tldr": "本文提出了改进的多车辆预约乘车问题(mDaRP)近似算法，优化了运行时间和近似比。", "motivation": "针对mDaRP现有最佳近似比为O(√λlog m)，作者希望通过新的算法设计来提高性能和效率。", "method": "提出两种简单算法：第一种保持原有近似比但减少运行时间；第二种达到新近似比O(√(m/λ))。结合使用这两种方法，在特定条件下得到更好的结果，特别是在m≫n的情况下，通过扩展算法进一步提升近似精度。", "result": "对于经典单车辆预约乘车问题(DaRP)，在某些情况下改进了现有最佳的O(√nlog^2 n)近似比为O(√nlog^(1/2)n)。同时，在mDaRP中提出了新的近似算法，优化了原有的时间复杂度和空间效率。", "conclusion": "通过提出的新方法在时间和精度上都取得了显著的改进，特别是在大规模实例下表现更为优越，从而推动了该领域的进一步研究和发展。"}}
{"id": "2601.21650", "pdf": "https://arxiv.org/pdf/2601.21650", "abs": "https://arxiv.org/abs/2601.21650", "authors": ["Alexander Erlei", "Federico Cau", "Radoslav Georgiev", "Sagar Kumar", "Kilian Bizer", "Ujwal Gadiraju"], "title": "When Life Gives You AI, Will You Turn It Into A Market for Lemons? Understanding How Information Asymmetries About AI System Capabilities Affect Market Outcomes and Adoption", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "AI consumer markets are characterized by severe buyer-supplier market asymmetries. Complex AI systems can appear highly accurate while making costly errors or embedding hidden defects. While there have been regulatory efforts surrounding different forms of disclosure, large information gaps remain. This paper provides the first experimental evidence on the important role of information asymmetries and disclosure designs in shaping user adoption of AI systems. We systematically vary the density of low-quality AI systems and the depth of disclosure requirements in a simulated AI product market to gauge how people react to the risk of accidentally relying on a low-quality AI system. Then, we compare participants' choices to a rational Bayesian model, analyzing the degree to which partial information disclosure can improve AI adoption. Our results underscore the deleterious effects of information asymmetries on AI adoption, but also highlight the potential of partial disclosure designs to improve the overall efficiency of human decision-making.", "AI": {"tldr": "研究了信息不对称对AI市场采用的影响，并探讨了部分信息披露设计的潜在改善效果。", "motivation": "在AI消费者市场中，买家和供应商之间存在严重的信息不对称问题。为了理解这些信息不对称如何影响用户采纳AI系统，作者进行了实验。", "method": "通过模拟AI产品市场的低质量AI系统的密度和信息披露要求的变化，观察人们面对低质量AI系统风险时的行为反应，并将其与理性贝叶斯模型进行比较。", "result": "实验证明了信息不对称对AI采用的负面影响，同时指出了部分信息披露设计可能提高人类决策效率的可能性。", "conclusion": "研究表明，在存在大量信息不对称的情况下，市场效率和用户采纳率都会下降。但是通过改进信息披露策略可以改善这一情况。"}}
{"id": "2601.21649", "pdf": "https://arxiv.org/pdf/2601.21649", "abs": "https://arxiv.org/abs/2601.21649", "authors": ["Jinjun Peng", "Magnus Saebo", "Tianjun Zhong", "Yi-Jie Cheng", "Junfeng Yang", "Baishakhi Ray", "Simin Chen", "Yangruibo Ding"], "title": "SWE-Spot: Building Small Repo-Experts with Repository-Centric Learning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SE"], "comment": null, "summary": "The deployment of coding agents in privacy-sensitive and resource-constrained environments drives the demand for capable open-weight Small Language Models (SLMs). However, they suffer from a fundamental capability gap: unlike frontier large models, they lack the inference-time strong generalization to work with complicated, unfamiliar codebases. We identify that the prevailing Task-Centric Learning (TCL) paradigm, which scales exposure across disparate repositories, fails to address this limitation. In response, we propose Repository-Centric Learning (RCL), a paradigm shift that prioritizes vertical repository depth over horizontal task breadth, suggesting SLMs must internalize the \"physics\" of a target software environment through parametric knowledge acquisition, rather than attempting to recover it via costly inference-time search. Following this new paradigm, we design a four-unit Repository-Centric Experience, transforming static codebases into interactive learning signals, to train SWE-Spot-4B, a family of highly compact models built as repo-specialized experts that breaks established scaling trends, outperforming open-weight models up to larger (e.g., CWM by Meta, Qwen3-Coder-30B) and surpassing/matching efficiency-focused commercial models (e.g., GPT-4.1-mini, GPT-5-nano) across multiple SWE tasks. Further analysis reveals that RCL yields higher training sample efficiency and lower inference costs, emphasizing that for building efficient intelligence, repository mastery is a distinct and necessary dimension that complements general coding capability.", "AI": {"tldr": "本文提出了一种新的学习范式Repository-Centric Learning（RCL），以解决小规模语言模型在复杂代码库中的推理性能不足问题，并设计了SWE-Spot-4B，一种针对特定仓库的专家模型。", "motivation": "现有的Task-Centric Learning（TCL）方法无法有效提升小型语言模型处理复杂和陌生代码库的能力。因此，需要新的学习范式来提高这些模型在特定软件环境中的表现。", "method": "提出Repository-Centric Learning（RCL），通过专注于垂直仓库深度而非水平任务广度，使SLM内部化目标软件环境的“物理”，并通过参数知识获取实现此目的。设计了一个四单元Repository-Centric Experience以将静态代码库转化为交互式学习信号，并训练了SWE-Spot-4B。", "result": "所提出的方法不仅在多个软件工程任务上超越或匹敌效率聚焦型商业模型，还显示出更高的训练样本效率和更低的推理成本。", "conclusion": "研究表明，构建高效智能的关键在于掌握特定仓库的知识维度，并且这与一般的编码能力相辅相成。"}}
{"id": "2601.21648", "pdf": "https://arxiv.org/pdf/2601.21648", "abs": "https://arxiv.org/abs/2601.21648", "authors": ["Bowen Zhou", "Marc-André Fiedler", "Ayoub Al-Hamadi"], "title": "CAF-Mamba: Mamba-Based Cross-Modal Adaptive Attention Fusion for Multimodal Depression Detection", "categories": ["cs.CV", "cs.CY", "cs.HC"], "comment": "The paper contains a total of 5 pages and 3 figures. This paper has been accepted for publication in the proceedings of 2026 IEEE ICASSP Conference", "summary": "Depression is a prevalent mental health disorder that severely impairs daily functioning and quality of life. While recent deep learning approaches for depression detection have shown promise, most rely on limited feature types, overlook explicit cross-modal interactions, and employ simple concatenation or static weighting for fusion. To overcome these limitations, we propose CAF-Mamba, a novel Mamba-based cross-modal adaptive attention fusion framework. CAF-Mamba not only captures cross-modal interactions explicitly and implicitly, but also dynamically adjusts modality contributions through a modality-wise attention mechanism, enabling more effective multimodal fusion. Experiments on two in-the-wild benchmark datasets, LMVD and D-Vlog, demonstrate that CAF-Mamba consistently outperforms existing methods and achieves state-of-the-art performance.", "AI": {"tldr": "提出CAF-Mamba框架用于抑郁症检测，通过基于Mamba的跨模态自适应注意力融合提升多模态数据处理效果。", "motivation": "现有深度学习方法在抑郁症检测中存在特征类型单一、忽略显式跨模态交互以及简单拼接或静态加权融合等问题。为了克服这些限制，作者提出了一种新的框架CAF-Mamba。", "method": "CAF-Mamba框架采用基于Mamba的跨模态自适应注意力机制来捕捉显性和隐性的跨模态互动，并动态调整各模态贡献。", "result": "在LMVD和D-Vlog两个基准数据集上的实验表明，CAF-Mamba能够超越现有方法并达到当前最优性能。", "conclusion": "CAF-Mamba框架通过优化多模态融合过程，在抑郁症检测任务中表现出色。"}}
{"id": "2601.21647", "pdf": "https://arxiv.org/pdf/2601.21647", "abs": "https://arxiv.org/abs/2601.21647", "authors": ["Eden Avrahami", "Eliya Nachmani"], "title": "ILRR: Inference-Time Steering Method for Masked Diffusion Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Discrete Diffusion Language Models (DLMs) offer a promising non-autoregressive alternative for text generation, yet effective mechanisms for inference-time control remain relatively underexplored. Existing approaches include sampling-level guidance procedures or trajectory optimization mechanisms. In this work, we introduce Iterative Latent Representation Refinement (ILRR), a learning-free framework for steering DLMs using a single reference sequence. ILRR guides generation by dynamically aligning the internal activations of the generated sequence with those of a given reference throughout the denoising process. This approach captures and transfers high-level semantic properties, with a tunable steering scale enabling flexible control over attributes such as sentiment. We further introduce Spatially Modulated Steering, an extension that enables steering long texts using shorter references by regulating guidance intensity across the sequence. Empirically, we demonstrate that ILRR achieves effective attribute steering on LLaDA and MDLM architectures with a minor computational overhead, requiring only one additional parallel forward pass per denoising step. Under the same compute budget, ILRR improves attribute accuracy over comparable baselines by 10$\\%$ to 60$\\%$ points, while maintaining high generation quality.", "AI": {"tldr": "介绍了一种名为ILRR的框架，用于在推理时间控制离散扩散语言模型的生成。", "motivation": "现有方法主要集中在采样指导或轨迹优化机制上，缺乏有效的推理时间控制手段。因此，需要一种新的非学习依赖的方法来实现灵活且高效的文本属性控制。", "method": "提出ILRR框架，通过动态对齐生成序列和参考序列的内部激活来引导生成过程，并引入空间调节转向以使用较短的参考进行长文本控制。", "result": "实验证明，ILRR在LLADA和MDLM架构中能够有效实现属性控制，与现有方法相比，在相同计算预算下提高了10%-60%的准确性，且保持了高质量生成。", "conclusion": "提出了一种有效的非学习依赖的方法ILRR来增强离散扩散语言模型中的推理时间控制，并展示了其在提高文本质量和灵活性方面的优越性。"}}
{"id": "2601.21641", "pdf": "https://arxiv.org/pdf/2601.21641", "abs": "https://arxiv.org/abs/2601.21641", "authors": ["Evandro S. Ortigossa", "Eran Segal"], "title": "Seg-MoE: Multi-Resolution Segment-wise Mixture-of-Experts for Time Series Forecasting Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Transformer-based models have recently made significant advances in accurate time-series forecasting, but even these architectures struggle to scale efficiently while capturing long-term temporal dynamics. Mixture-of-Experts (MoE) layers are a proven solution to scaling problems in natural language processing. However, existing MoE approaches for time-series forecasting rely on token-wise routing mechanisms, which may fail to exploit the natural locality and continuity of temporal data. In this work, we introduce Seg-MoE, a sparse MoE design that routes and processes contiguous time-step segments rather than making independent expert decisions. Token segments allow each expert to model intra-segment interactions directly, naturally aligning with inherent temporal patterns. We integrate Seg-MoE layers into a time-series Transformer and evaluate it on multiple multivariate long-term forecasting benchmarks. Seg-MoE consistently achieves state-of-the-art forecasting accuracy across almost all prediction horizons, outperforming both dense Transformers and prior token-wise MoE models. Comprehensive ablation studies confirm that segment-level routing is the key factor driving these gains. Our results show that aligning the MoE routing granularity with the inherent structure of time series provides a powerful, yet previously underexplored, inductive bias, opening new avenues for conditionally sparse architectures in sequential data modeling.", "AI": {"tldr": "本文提出了一种新的时间序列预测Transformer模型Seg-MoE，它通过在连续的时间段上路由和处理来改进现有Mixture-of-Experts（MoE）方法。", "motivation": "现有的基于Transformers的时间序列预测模型虽然有效，但难以在捕捉长期动态的同时高效扩展。本文提出了一种新的方法来解决这一问题。", "method": "Seg-MoE通过将连续时间步骤划分成段，并为每个专家分配处理这些段的任务，从而优化了MoE的路由机制。", "result": "实验结果表明，Seg-MoE在多个长期预测基准测试中达到了最先进的准确率，优于密集Transformers和其他令牌级MoE模型。", "conclusion": "该研究证明了将MoE的粒度与时间序列固有的结构相匹配可以提供强大的归纳偏置，并为顺序数据建模中的条件稀疏架构开辟新的途径。"}}
{"id": "2601.21639", "pdf": "https://arxiv.org/pdf/2601.21639", "abs": "https://arxiv.org/abs/2601.21639", "authors": ["Yufeng Zhong", "Lei Chen", "Xuanle Zhao", "Wenkang Han", "Liming Zheng", "Jing Huang", "Deyang Jiang", "Yilin Cao", "Lin Ma", "Zhixiong Zeng"], "title": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "The development of large vision language models drives the demand for managing, and applying massive amounts of multimodal data, making OCR technology, which extracts information from visual images, increasingly popular. However, existing OCR methods primarily focus on recognizing text elements from images or scanned documents (\\textbf{Text-centric OCR}), neglecting the identification of visual elements from visually information-dense image sources (\\textbf{Vision-centric OCR}), such as charts, web pages and science plots. In reality, these visually information-dense images are widespread on the internet and have significant real-world application value, such as data visualization and web page analysis. In this technical report, we propose \\textbf{OCRVerse}, the first holistic OCR method in end-to-end manner that enables unified text-centric OCR and vision-centric OCR. To this end, we constructe comprehensive data engineering to cover a wide range of text-centric documents, such as newspapers, magazines and books, as well as vision-centric rendered composites, including charts, web pages and scientific plots. Moreover, we propose a two-stage SFT-RL multi-domain training method for OCRVerse. SFT directly mixes cross-domain data to train and establish initial domain knowledge, while RL focuses on designing personalized reward strategies for the characteristics of each domain. Specifically, since different domains require various output formats and expected outputs, we provide sufficient flexibility in the RL stage to customize flexible reward signals for each domain, thereby improving cross-domain fusion and avoiding data conflicts. Experimental results demonstrate the effectiveness of OCRVerse, achieving competitive results across text-centric and vision-centric data types, even comparable to large-scale open-source and closed-source models.", "AI": {"tldr": "提出了一种统一的OCR方法OCRVerse，能够同时处理文本中心和视觉中心的OCR任务。", "motivation": "现有的OCR技术主要针对图像或扫描文档中的文本识别（文本中心OCR），忽略了对图表、网页等信息密集型图像中视觉元素的识别需求（视觉中心OCR）。这些应用场景具有重要现实价值。", "method": "构建了包含广泛文本和视觉密集数据的数据工程，并提出了两阶段SFT-RL多域训练方法。SFT阶段混合跨领域数据进行初步学习，RL阶段设计个性化奖励策略以适应各领域的特点。", "result": "实验结果显示OCRVerse在不同类型的文本中心和视觉中心数据上均表现出色，与大规模开源及闭源模型相当。", "conclusion": "OCRVerse作为首个统一处理文本和视觉元素的端到端OCR方法，在跨域融合方面取得了成功。"}}
{"id": "2601.21634", "pdf": "https://arxiv.org/pdf/2601.21634", "abs": "https://arxiv.org/abs/2601.21634", "authors": ["Shiqi Huang", "Shuting He", "Bihan Wen"], "title": "RSGround-R1: Rethinking Remote Sensing Visual Grounding through Spatial Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Remote Sensing Visual Grounding (RSVG) aims to localize target objects in large-scale aerial imagery based on natural language descriptions. Owing to the vast spatial scale and high semantic ambiguity of remote sensing scenes, these descriptions often rely heavily on positional cues, posing unique challenges for Multimodal Large Language Models (MLLMs) in spatial reasoning. To leverage this unique feature, we propose a reasoning-guided, position-aware post-training framework, dubbed \\textbf{RSGround-R1}, to progressively enhance spatial understanding. Specifically, we first introduce Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) using synthetically generated RSVG reasoning data to establish explicit position awareness. Reinforcement Fine-Tuning (RFT) is then applied, augmented by our newly designed positional reward that provides continuous and distance-aware guidance toward accurate localization. Moreover, to mitigate incoherent localization behaviors across rollouts, we introduce a spatial consistency guided optimization scheme that dynamically adjusts policy updates based on their spatial coherence, ensuring stable and robust convergence. Extensive experiments on RSVG benchmarks demonstrate superior performance and generalization of our model.", "AI": {"tldr": "本文提出了一个基于空间推理的远程感知视觉定位框架RSGround-R1，以提高在大规模航空图像中根据自然语言描述定位目标对象的能力。", "motivation": "由于遥感场景中的位置线索对模型理解至关重要，而多模态大型语言模型（MLLMs）在此方面存在挑战，因此本文旨在通过引入空间推理方法来增强模型的空间理解和定位能力。", "method": "提出了一个基于链式思维监督微调和强化学习的方法框架RSGround-R1。该框架首先使用合成生成的RSVG推理数据进行链式思维监督微调以建立明确的位置意识，然后应用带有新设计的距离感知位置奖励的增强学习来引导准确定位，并通过空间一致性优化保证稳定性和鲁棒性。", "result": "在遥感视觉接地基准测试中的实验表明该模型表现出色并且具有良好的泛化能力。", "conclusion": "RSGround-R1框架利用合成数据和强化学习策略有效增强了多模态大型语言模型的空间理解和定位精度，为大规模航空图像中基于自然语言描述的远程感知视觉接地提供了新思路。"}}
{"id": "2601.21633", "pdf": "https://arxiv.org/pdf/2601.21633", "abs": "https://arxiv.org/abs/2601.21633", "authors": ["Pu Cao", "Yiyang Ma", "Feng Zhou", "Xuedan Yin", "Qing Song", "Lu Yang"], "title": "A Tilted Seesaw: Revisiting Autoencoder Trade-off for Controllable Diffusion", "categories": ["cs.CV"], "comment": "work in progress", "summary": "In latent diffusion models, the autoencoder (AE) is typically expected to balance two capabilities: faithful reconstruction and a generation-friendly latent space (e.g., low gFID). In recent ImageNet-scale AE studies, we observe a systematic bias toward generative metrics in handling this trade-off: reconstruction metrics are increasingly under-reported, and ablation-based AE selection often favors the best-gFID configuration even when reconstruction fidelity degrades. We theoretically analyze why this gFID-dominant preference can appear unproblematic for ImageNet generation, yet becomes risky when scaling to controllable diffusion: AEs can induce condition drift, which limits achievable condition alignment. Meanwhile, we find that reconstruction fidelity, especially instance-level measures, better indicates controllability. We empirically validate the impact of tilted autoencoder evaluation on controllability by studying several recent ImageNet AEs. Using a multi-dimensional condition-drift evaluation protocol reflecting controllable generation tasks, we find that gFID is only weakly predictive of condition preservation, whereas reconstruction-oriented metrics are substantially more aligned. ControlNet experiments further confirm that controllability tracks condition preservation rather than gFID. Overall, our results expose a gap between ImageNet-centric AE evaluation and the requirements of scalable controllable diffusion, offering practical guidance for more reliable benchmarking and model selection.", "AI": {"tldr": "本文探讨了自编码器在生成式扩散模型中的偏向问题，提出了一种评估方法以更好地反映可控性。", "motivation": "在图像网络规模的自编码器研究中，存在对生成指标偏重的现象。然而这种偏向可能导致条件漂移，从而限制实现良好的条件对齐能力。作者旨在分析并解决这一问题，为可控扩散模型提供更可靠的方法。", "method": "理论分析了现有评估方法中的潜在偏差，并通过实验验证了不同自编码器在多维条件下保存任务上的性能差异。使用基于重构指标的评价标准来反映模型的控制性。", "result": "结果显示gFID仅弱预测条件保留，而重构导向指标与可控度有更强的相关性。实验证明控制网络也支持这一结论：即可控度更接近于条件保留而非gFID。", "conclusion": "研究揭示了基于ImageNet的自编码器评估方法和可扩展可控扩散模型需求之间的差距，并为未来的研究提供了实践指导，以确保更加可靠的基准测试和模型选择。"}}
{"id": "2601.21632", "pdf": "https://arxiv.org/pdf/2601.21632", "abs": "https://arxiv.org/abs/2601.21632", "authors": ["Shaina Raza", "Iuliia Eyriay", "Ahmed Y. Radwan", "Nate Lesperance", "Deval Pandya", "Sedef Akinli Kocak", "Graham W. Taylor"], "title": "Sustainable Open-Source AI Requires Tracking the Cumulative Footprint of Derivatives", "categories": ["cs.ET"], "comment": null, "summary": "Open-source AI is scaling rapidly, and model hubs now host millions of artifacts. Each foundation model can spawn large numbers of fine-tunes, adapters, quantizations, merges, and forks. We take the position that compute efficiency alone is insufficient for sustainability in open-source AI: lower per-run costs can accelerate experimentation and deployment, increasing aggregate environmental footprint unless impacts are measurable and comparable across derivative lineages. However, the energy use, water consumption, and emissions of these derivative lineages are rarely measured or disclosed in a consistent, comparable manner, leaving ecosystem-level impact largely invisible. We argue that sustainable open-source AI requires coordination infrastructure that tracks impacts across model lineages, not only base models. We propose Data and Impact Accounting (DIA), a lightweight, non-restrictive transparency layer that (i) standardizes carbon and water reporting metadata, (ii) integrates low-friction measurement into common training and inference pipelines, and (iii) aggregates reports through public dashboards to summarize cumulative impacts across releases and derivatives. DIA makes derivative costs visible and supports ecosystem-level accountability while preserving openness. https://vectorinstitute.github.io/ai-impact-accounting/", "AI": {"tldr": "提出了一种轻量级透明层Data和影响会计（DIA），用于跟踪衍生模型的累积环境足迹，以促进可持续开放源AI。", "motivation": "当前基础模型可以产生大量衍生品，但这些衍生品对能源使用、水资源消耗和排放的影响通常未被测量或公开披露。这导致总体生态系统的环境影响难以量化和比较。", "method": "提出了一种新的透明层DIA，它标准化了碳水报告元数据，并将低摩擦的度量集成到常见的训练和推断流程中；通过公共仪表板聚合报告以汇总各个发布版本及其衍生品的累积影响。", "result": "该方法使衍生成本可见化并支持生态系统级别的问责制，同时保持开放性。", "conclusion": "可持续开源AI需要跟踪模型及其所有衍生品的整体环境足迹。DIA提供了一种可行的方法来实现这一目标。"}}
{"id": "2601.21626", "pdf": "https://arxiv.org/pdf/2601.21626", "abs": "https://arxiv.org/abs/2601.21626", "authors": ["Jinhao Zhang Yunquan Zhang", "Zicheng yan", "Boyang Zhang", "Jun Sun", "Daning Cheng"], "title": "HeRo-Q: A General Framework for Stable Low Bit Quantization via Hessian Conditioning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Post Training Quantization (PTQ), a mainstream model compression technique, often leads to the paradoxical 'low error, high loss' phenomenon because it focuses solely on minimizing quantization error. The root cause lies in the Hessian matrix of the LLM loss landscape: a few high curvature directions are extremely sensitive to perturbations. To address this, we propose the Hessian Robust Quantization (HeRo Q) algorithm, which applies a lightweight, learnable rotation-compression matrix to the weight space prior to quantization. This joint framework reshapes the loss landscape by reducing the largest Hessian eigenvalue and reducing its max eigenvalue, thereby significantly enhancing robustness to quantization noise. HeRo-Q requires no architectural modifications, incurs negligible computational overhead, and integrates seamlessly into existing PTQ pipelines. Experiments on Llama and Qwen models show that HeRo Q consistently outperforms state of the art methods including GPTQ, AWQ, and SpinQuant not only achieving superior performance under standard W4A8 settings, but also excelling in the highly challenging W3A16 ultra low bit regime, where it boosts GSM8K accuracy on Llama3 8B to 70.15\\% and effectively avoids the logical collapse commonly seen in aggressive quantization.", "AI": {"tldr": "提出了一种名为HeRo-Q的框架，用于通过Hessian矩阵调理来实现稳定的低比特量化。", "motivation": "现有的后训练量化技术存在'低误差高损失'的现象，原因在于LLM损失景观中的Hessian矩阵中某些方向对扰动非常敏感。为了解决这个问题，提出了HeRo-Q算法以增强对量化噪声的鲁棒性。", "method": "应用了一个轻量级、可学习的旋转压缩矩阵到权重空间，在量化之前调整损失景观，通过减少最大的Hessian特征值来提高量化稳定性。", "result": "实验表明，HeRo-Q在标准W4A8设置下优于现有方法，并且在更具挑战性的W3A16超低比特场景中表现出色，提升了Llama-3模型的GSM8K准确率至70.15%，并避免了逻辑崩溃。", "conclusion": "HeRo-Q框架无需修改架构，计算开销小，可无缝集成到现有PTQ流程，并在实验中证明其有效性。"}}
{"id": "2601.21621", "pdf": "https://arxiv.org/pdf/2601.21621", "abs": "https://arxiv.org/abs/2601.21621", "authors": ["Matéo Mahaut", "Marco Baroni"], "title": "Similarity of Processing Steps in Vision Model Representations", "categories": ["cs.CV"], "comment": null, "summary": "Recent literature suggests that the bigger the model, the more likely it is to converge to similar, ``universal'' representations, despite different training objectives, datasets, or modalities. While this literature shows that there is an area where model representations are similar, we study here how vision models might get to those representations -- in particular, do they also converge to the same intermediate steps and operations? We therefore study the processes that lead to convergent representations in different models. First, we quantify distance between different model representations at different stages. We follow the evolution of distances between models throughout processing, identifying the processing steps which are most different between models. We find that while layers at similar positions in different models have the most similar representations, strong differences remain. Classifier models, unlike the others, will discard information about low-level image statistics in their final layers. CNN- and transformer-based models also behave differently, with transformer models applying smoother changes to representations from one layer to the next. These distinctions clarify the level and nature of convergence between model representations, and enables a more qualitative account of the underlying processes in image models.", "AI": {"tldr": "研究不同视觉模型在处理步骤上的相似性，探讨其如何达到类似表示。", "motivation": "现有文献表明更大的模型更可能收敛到类似的“通用”表示。然而，这些文献没有深入探讨这些模型是否也通过相同的中间步骤和操作来达到这种一致性。", "method": "量化不同阶段下各模型之间的距离，追踪整个处理过程中的变化趋势，识别出最不同的处理步骤，并比较不同类型的模型（如分类器、CNN 和 Transformer）的特性。", "result": "发现虽然位于相似位置的不同层表示最为接近，但仍有显著差异；分类模型在最终层会舍弃关于低层次图像统计的信息；而基于 CNN 和 Transformer 的模型表现出不同的变化模式，Transformer 模型对表征的变化较为平滑。", "conclusion": "研究揭示了不同视觉模型间表示收敛的程度和本质，并提供了一种更加定性的方法来理解这些模型内部的过程。"}}
{"id": "2601.21619", "pdf": "https://arxiv.org/pdf/2601.21619", "abs": "https://arxiv.org/abs/2601.21619", "authors": ["Yiming Wang", "Zhuosheng Zhang", "Rui Wang"], "title": "Breaking the Overscaling Curse: Thinking Parallelism Before Parallel Thinking", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Parallel thinking enhances LLM reasoning by multi-path sampling and aggregation. In system-level evaluations, a global parallelism level N is allocated to all samples, typically set large to maximize overall dataset accuracy. However, due to sample heterogeneity, some samples can achieve comparable performance with a smaller N'< N, causing budget redundancy. This incompatibility between system-level efficacy and sample-level efficiency constitutes the overscaling curse. In this paper, we formalize and quantify the overscaling curse, showing its universality and severity in practice, and analyze its trigger mechanism. We then propose a lightweight method, T2, to break the overscaling curse, which utilizes latent representations to estimate the optimal parallelism level for each sample before decoding. Experiments show that T2 significantly reduces cost while maintaining comparable performance, enabling more efficient parallel thinking.", "AI": {"tldr": "提出了一种方法T2，通过估计每个样本的最优并行级别来打破超扩展诅咒。", "motivation": "解决LLM推理中的超扩展诅咒问题，即全局分配的并行层级N在一些样本上造成预算冗余。", "method": "利用潜在表示估算每个样本的最佳并行级别，从而提高效率和性能。", "result": "实验表明T2能显著降低成本同时保持相当的性能。", "conclusion": "方法T2成功打破了超扩展诅咒，实现了更高效的并行思考。"}}
{"id": "2601.21618", "pdf": "https://arxiv.org/pdf/2601.21618", "abs": "https://arxiv.org/abs/2601.21618", "authors": ["Martiño Ríos-García", "Nawaf Alampara", "Kevin Maik Jablonka"], "title": "Semantic Content Determines Algorithmic Performance", "categories": ["cs.AI", "cs.CL"], "comment": ":cs.LG", "summary": "Counting should not depend on what is being counted; more generally, any algorithm's behavior should be invariant to the semantic content of its arguments. We introduce WhatCounts to test this property in isolation. Unlike prior work that conflates semantic sensitivity with reasoning complexity or prompt variation, WhatCounts is atomic: count items in an unambiguous, delimited list with no duplicates, distractors, or reasoning steps for different semantic types. Frontier LLMs show over 40% accuracy variation depending solely on what is being counted - cities versus chemicals, names versus symbols. Controlled ablations rule out confounds. The gap is semantic, and it shifts unpredictably with small amounts of unrelated fine-tuning. LLMs do not implement algorithms; they approximate them, and the approximation is argument-dependent. As we show with an agentic example, this has implications beyond counting: any LLM function may carry hidden dependencies on the meaning of its inputs.", "AI": {"tldr": "研究探讨了大规模语言模型在处理不同语义内容时算法性能的变化。", "motivation": "为了验证任何算法的行为应该独立于输入的语义内容，作者提出了一个新的测试方法WhatCounts。", "method": "通过让前沿的大规模语言模型对无歧义、有区隔列表中的项目进行计数来检验其表现是否受语义影响，并排除了其他可能干扰因素。", "result": "发现即使在控制条件下，不同语义内容的计数任务仍表现出超过40%的准确性差异，说明这种差异确实存在且不稳定。", "conclusion": "大规模语言模型并不是实现算法，而是近似执行；其性能受输入语义影响，并可能对具有代理性质的任务产生潜在的影响。"}}
{"id": "2601.21617", "pdf": "https://arxiv.org/pdf/2601.21617", "abs": "https://arxiv.org/abs/2601.21617", "authors": ["Songhan Jiang", "Fengchun Liu", "Ziyue Wang", "Linghan Cai", "Yongbing Zhang"], "title": "PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) are advancing computational pathology with superior visual understanding capabilities. However, current systems often reduce diagnosis to directly output conclusions without verifiable evidence-linked reasoning, which severely limits clinical trust and hinders expert error rectification. To address these barriers, we construct PathReasoner, the first large-scale dataset of whole-slide image (WSI) reasoning. Unlike previous work reliant on unverified distillation, we develop a rigorous knowledge-guided generation pipeline. By leveraging medical knowledge graphs, we explicitly align structured pathological findings and clinical reasoning with diagnoses, generating over 20K high-quality instructional samples. Based on the database, we propose PathReasoner-R1, which synergizes trajectory-masked supervised fine-tuning with reasoning-oriented reinforcement learning to instill structured chain-of-thought capabilities. To ensure medical rigor, we engineer a knowledge-aware multi-granular reward function incorporating an Entity Reward mechanism strictly aligned with knowledge graphs. This effectively guides the model to optimize for logical consistency rather than mere outcome matching, thereby enhancing robustness. Extensive experiments demonstrate that PathReasoner-R1 achieves state-of-the-art performance on both PathReasoner and public benchmarks across various image scales, equipping pathology models with transparent, clinically grounded reasoning capabilities. Dataset and code are available at https://github.com/cyclexfy/PathReasoner-R1.", "AI": {"tldr": "构建PathReasoner-R1模型，通过知识引导策略优化，在病理学视觉语言模型中引入结构化推理能力。", "motivation": "当前系统诊断结论缺乏验证性证据链的推理过程，限制了临床信任并阻碍专家纠正错误。为了应对这一挑战，作者提出了一种新的方法来提高病理分析系统的可信度和准确性。", "method": "基于知识图谱构建大规模结构化推理数据集PathReasoner，并设计了一个结合轨迹掩码监督微调与强化学习的模型PathReasoner-R1，通过引入医学常识感知多粒度奖励机制以优化逻辑一致性而非单一结果匹配。", "result": "在PathReasoner及公开基准测试中取得最佳性能，在各种图像尺度上具备透明、临床依据的推理能力。", "conclusion": "该研究提出了一种新的方法，使病理学视觉语言模型能够生成具有结构化链条思维的能力，并展示了其优越性。"}}
{"id": "2601.21615", "pdf": "https://arxiv.org/pdf/2601.21615", "abs": "https://arxiv.org/abs/2601.21615", "authors": ["Jiaxin Zhang", "Yiqi Wang", "Siwei Wang", "Xihong Yang", "Yu Shi", "Xinwang Liu", "En Zhu"], "title": "Beyond Parameter Finetuning: Test-Time Representation Refinement for Node Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks frequently exhibit significant performance degradation in the out-of-distribution test scenario. While test-time training (TTT) offers a promising solution, existing Parameter Finetuning (PaFT) paradigm suffer from catastrophic forgetting, hindering their real-world applicability. We propose TTReFT, a novel Test-Time Representation FineTuning framework that transitions the adaptation target from model parameters to latent representations. Specifically, TTReFT achieves this through three key innovations: (1) uncertainty-guided node selection for specific interventions, (2) low-rank representation interventions that preserve pre-trained knowledge, and (3) an intervention-aware masked autoencoder that dynamically adjust masking strategy to accommodate the node selection scheme. Theoretically, we establish guarantees for TTReFT in OOD settings. Empirically, extensive experiments across five benchmark datasets demonstrate that TTReFT achieves consistent and superior performance. Our work establishes representation finetuning as a new paradigm for graph TTT, offering both theoretical grounding and immediate practical utility for real-world deployment.", "AI": {"tldr": "提出了一种新的测试时表示微调框架TTReFT，用于解决图神经网络在分布外测试场景中的性能退化问题。", "motivation": "现有参数精调方法存在灾难性遗忘的问题，导致无法实现实用性。为此，本研究提出了新的解决方案以改善模型的泛化能力。", "method": "通过不确定性引导节点选择、低秩表示干预以及适应性掩码自动编码器等技术来调整模型在测试时的表现。", "result": "实验显示TTReFT框架在五个基准数据集上实现了持续且优越的性能表现。", "conclusion": "该研究将表示微调确立为图神经网络测试时间训练的新范式，既提供了理论基础又具备实用价值。"}}
{"id": "2601.21612", "pdf": "https://arxiv.org/pdf/2601.21612", "abs": "https://arxiv.org/abs/2601.21612", "authors": ["Bing Han", "Chushu Zhou", "Yifan Yang", "Wei Wang", "Chenda Li", "Wangyou Zhang", "Yanmin Qian"], "title": "Representation-Regularized Convolutional Audio Transformer for Audio Understanding", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "12 pages, 3 figures", "summary": "Bootstrap-based Self-Supervised Learning (SSL) has achieved remarkable progress in audio understanding. However, existing methods typically operate at a single level of granularity, limiting their ability to model the diverse temporal and spectral structures inherent in complex audio signals. Furthermore, bootstrapping representations from scratch is computationally expensive, often requiring extensive training to converge. In this work, we propose the Convolutional Audio Transformer (CAT), a unified framework designed to address these challenges. First, to capture hierarchical audio features, CAT incorporates a Multi-resolution Block that aggregates information across varying granularities. Second, to enhance training efficiency, we introduce a Representation Regularization objective. Drawing inspiration from generative modeling, this auxiliary task guides the student model by aligning its predictions with high-quality semantic representations from frozen, pre-trained external encoders. Experimental results demonstrate that CAT significantly outperforms baselines on audio understanding benchmarks. Notably, it achieves competitive performance on the AudioSet 20k dataset with 5 times faster convergence than existing methods. Codes and checkpoints will be released soon at https://github.com/realzhouchushu/CAT.", "AI": {"tldr": "该论文提出了Convolutional Audio Transformer（CAT），一个用于音频理解的统一框架。", "motivation": "现有方法在单一粒度级别上操作，限制了对复杂音频信号中多样化的时频结构建模的能力。此外，从零开始自举表示计算成本高，训练时间长。", "method": "CAT采用多分辨率块聚合不同粒度的信息以捕获分层音频特征，并引入表征正则化目标提高训练效率。该辅助任务通过与预训练编码器的高质量语义表示对齐来指导学生模型。", "result": "实验结果表明，CAT在音频理解基准上显著优于基线方法，在AudioSet 20k数据集上的性能甚至可以与现有方法相媲美，但收敛速度提高了5倍。", "conclusion": "CAT通过引入多分辨率块和表征正则化目标解决了现有方法的局限性，并在多个音频理解和识别任务上取得了显著的进步。"}}
{"id": "2601.21611", "pdf": "https://arxiv.org/pdf/2601.21611", "abs": "https://arxiv.org/abs/2601.21611", "authors": ["Baopu Qiu", "Hao Chen", "Yuanrong Wu", "Changtong Zan", "Chao Wei", "Weiru Zhang", "Xiaoyi Zeng"], "title": "Thinking Broad, Acting Fast: Latent Reasoning Distillation from Multi-Perspective Chain-of-Thought for E-Commerce Relevance", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "12 pages, 6 figures, Accepted by WWW2026 industry track", "summary": "Effective relevance modeling is crucial for e-commerce search, as it aligns search results with user intent and enhances customer experience. Recent work has leveraged large language models (LLMs) to address the limitations of traditional relevance models, especially for long-tail and ambiguous queries. By incorporating Chain-of-Thought (CoT) reasoning, these approaches improve both accuracy and interpretability through multi-step reasoning. However, two key limitations remain: (1) most existing approaches rely on single-perspective CoT reasoning, which fails to capture the multifaceted nature of e-commerce relevance (e.g., user intent vs. attribute-level matching vs. business-specific rules); and (2) although CoT-enhanced LLM's offer rich reasoning capabilities, their high inference latency necessitates knowledge distillation for real-time deployment, yet current distillation methods discard the CoT rationale structure at inference, using it as a transient auxiliary signal and forfeiting its reasoning utility. To address these challenges, we propose a novel framework that better exploits CoT semantics throughout the optimization pipeline. Specifically, the teacher model leverages Multi-Perspective CoT (MPCoT) to generate diverse rationales and combines Supervised Fine-Tuning (SFT) with Direct Preference Optimization (DPO) to construct a more robust reasoner. For distillation, we introduce Latent Reasoning Knowledge Distillation (LRKD), which endows a student model with a lightweight inference-time latent reasoning extractor, allowing efficient and low-latency internalization of the LLM's sophisticated reasoning capabilities. Evaluated in offline experiments and online A/B tests on an e-commerce search advertising platform serving tens of millions of users daily, our method delivers significant offline gains, showing clear benefits in both commercial performance and user experience.", "AI": {"tldr": "本文提出了一种新型框架，以更好地利用Chain-of-Thought（CoT）语义优化电商搜索的相关性模型。", "motivation": "现有相关性模型依赖单视角的CoT推理，无法捕捉电子商务多面性的需求，同时增强型LLM虽然具备丰富推理能力但高延迟限制了实时部署。本文旨在解决这些问题，提出更有效的解决方案。", "method": "通过引入Multi-Perspective CoT（MPCoT）生成多样化的理由，并结合监督微调和直接偏好优化构造更强的推论器；在知识精简过程中使用Latent Reasoning Knowledge Distillation (LRKD)，赋予学生模型一个轻量级推理时间潜在推理提取器，使其能够高效低延迟地内化LLM复杂的推理能力。", "result": "本文方法在线下实验和线上A/B测试中表现出显著的离线增益，展示了在商业性能和用户体验方面的明显优势。", "conclusion": "通过有效利用CoT语义并结合轻量级推理提取器的方法，解决了现有相关性模型面临的问题，并提高了电商搜索广告平台的相关性和用户满意度。"}}
{"id": "2601.21610", "pdf": "https://arxiv.org/pdf/2601.21610", "abs": "https://arxiv.org/abs/2601.21610", "authors": ["Zijin Yang", "Yu Sun", "Kejiang Chen", "Jiawei Zhao", "Jun Jiang", "Weiming Zhang", "Nenghai Yu"], "title": "WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Digital watermarking is essential for securing generated images from diffusion models. Accurate watermark evaluation is critical for algorithm development, yet existing methods have significant limitations: they lack a unified framework for both residual and semantic watermarks, provide results without interpretability, neglect comprehensive security considerations, and often use inappropriate metrics for semantic watermarks. To address these gaps, we propose WMVLM, the first unified and interpretable evaluation framework for diffusion model image watermarking via vision-language models (VLMs). We redefine quality and security metrics for each watermark type: residual watermarks are evaluated by artifact strength and erasure resistance, while semantic watermarks are assessed through latent distribution shifts. Moreover, we introduce a three-stage training strategy to progressively enable the model to achieve classification, scoring, and interpretable text generation. Experiments show WMVLM outperforms state-of-the-art VLMs with strong generalization across datasets, diffusion models, and watermarking methods.", "AI": {"tldr": "WMVLM是第一个用于评估扩散模型生成图像水印的统一和可解释框架，通过视觉-语言模型实现。", "motivation": "现有方法缺乏统一的残差与语义水印框架、结果不可解释、忽视全面的安全考量以及使用不当的度量标准。为解决这些问题，提出WMVLM框架。", "method": "重新定义质量与安全指标：残差水印通过伪影强度和擦除抵抗性评估，而语义水印则基于潜在分布偏移进行评估；采用三阶段训练策略，逐步实现模型分类、评分及生成解释性文本的能力。", "result": "实验表明WMVLM优于现有的视觉-语言模型，在不同数据集、扩散模型和水印方法上具有强大的泛化能力。", "conclusion": "WMVLM提供了一个有效的评估框架来解决现有图像水印评价中的不足，展示了在多种场景下的优越性能。"}}
{"id": "2601.21609", "pdf": "https://arxiv.org/pdf/2601.21609", "abs": "https://arxiv.org/abs/2601.21609", "authors": ["Bingqian Li", "Xiaolei Wang", "Junyi Li", "Weitao Li", "Long Zhang", "Sheng Chen", "Wayne Xin Zhao", "Ji-Rong Wen"], "title": "RecNet: Self-Evolving Preference Propagation for Agentic Recommender Systems", "categories": ["cs.AI"], "comment": null, "summary": "Agentic recommender systems leverage Large Language Models (LLMs) to model complex user behaviors and support personalized decision-making. However, existing methods primarily model preference changes based on explicit user-item interactions, which are sparse, noisy, and unable to reflect the real-time, mutual influences among users and items. To address these limitations, we propose RecNet, a self-evolving preference propagation framework that proactively propagates real-time preference updates across related users and items. RecNet consists of two complementary phases. In the forward phase, the centralized preference routing mechanism leverages router agents to integrate preference updates and dynamically propagate them to the most relevant agents. To ensure accurate and personalized integration of propagated preferences, we further introduce a personalized preference reception mechanism, which combines a message buffer for temporary caching and an optimizable, rule-based filter memory to guide selective preference assimilation based on past experience and interests. In the backward phase, the feedback-driven propagation optimization mechanism simulates a multi-agent reinforcement learning framework, using LLMs for credit assignment, gradient analysis, and module-level optimization, enabling continuous self-evolution of propagation strategies. Extensive experiments on various scenarios demonstrate the effectiveness of RecNet in modeling preference propagation for recommender systems.", "AI": {"tldr": "提出了一种自演化的偏好传播框架RecNet，用于代理推荐系统。", "motivation": "现有方法主要基于用户与物品的显式交互来建模用户的偏好变化，这些交互稀疏、嘈杂且无法反映实时的相互影响。", "method": "RecNet包括两个互补阶段：前向阶段利用路由器代理集成偏好转播至最相关的代理；后向阶段通过多智能体强化学习框架模拟反馈驱动传播优化机制。", "result": "实验表明，RecNet在建模推荐系统中的偏好传播方面具有有效性。", "conclusion": "通过自演化的偏好传播，RecNet能够更准确地反映用户和物品之间的实时交互。"}}
{"id": "2601.21608", "pdf": "https://arxiv.org/pdf/2601.21608", "abs": "https://arxiv.org/abs/2601.21608", "authors": ["Saisubramaniam Gopalakrishnan", "Harikrishnan P M", "Dagnachew Birru"], "title": "Search-Based Risk Feature Discovery in Document Structure Spaces under a Constrained Budget", "categories": ["cs.AI"], "comment": null, "summary": "Enterprise-grade Intelligent Document Processing (IDP) systems support high-stakes workflows across finance, insurance, and healthcare. Early-phase system validation under limited budgets mandates uncovering diverse failure mechanisms, rather than identifying a single worst-case document. We formalize this challenge as a Search-Based Software Testing (SBST) problem, aiming to identify complex interactions between document variables, with the objective to maximize the number of distinct failure types discovered within a fixed evaluation budget. Our methodology operates on a combinatorial space of document configurations, rendering instances of structural \\emph{risk features} to induce realistic failure conditions. We benchmark a diverse portfolio of search strategies spanning evolutionary, swarm-based, quality-diversity, learning-based, and quantum under identical budget constraints. Through configuration-level exclusivity, win-rate, and cross-temporal overlap analyses, we show that different solvers consistently uncover failure modes that remain undiscovered by specific alternatives at comparable budgets. Crucially, cross-temporal analysis reveals persistent solver-specific discoveries across all evaluated budgets, with no single strategy exhibiting absolute dominance. While the union of all solvers eventually recovers the observed failure space, reliance on any individual method systematically delays the discovery of important risks. These results demonstrate intrinsic solver complementarity and motivate portfolio-based SBST strategies for robust industrial IDP validation.", "AI": {"tldr": "该论文研究如何在预算限制下，通过搜索方法发现文档结构中的风险特征。", "motivation": "早期系统验证需要在有限的预算内揭示多种失败模式，而不仅仅是识别单一最坏情况下的文档。", "method": "采用组合空间内的文档配置来生成结构性风险特征，并评估了各种搜索策略的效果。", "result": "不同求解器能发现独特且互补的风险模式；所有求解器联合使用可以更全面地覆盖失败空间，但依赖单个方法会延迟重要风险的发现。", "conclusion": "结果表明不同的求解器具有内在互补性，并支持在工业级文档处理系统验证中采用组合策略。"}}
{"id": "2601.21605", "pdf": "https://arxiv.org/pdf/2601.21605", "abs": "https://arxiv.org/abs/2601.21605", "authors": ["Shashiwadana Nirmania", "Garima Sharma", "Hourieh Khalajzadeh", "Mojtaba Shahin"], "title": "Age Matters: Analyzing Age-Related Discussions in App Reviews", "categories": ["cs.SE", "cs.HC", "cs.LG"], "comment": null, "summary": "In recent years, mobile applications have become indispensable tools for managing various aspects of life. From enhancing productivity to providing personalized entertainment, mobile apps have revolutionized people's daily routines. Despite this rapid growth and popularity, gaps remain in how these apps address the needs of users from different age groups. Users of varying ages face distinct challenges when interacting with mobile apps, from younger users dealing with inappropriate content to older users having difficulty with usability due to age-related vision and cognition impairments. Although there have been initiatives to create age-inclusive apps, a limited understanding of user perspectives on age-related issues may hinder developers from recognizing specific challenges and implementing effective solutions. In this study, we explore age discussions in app reviews to gain insights into how mobile apps should cater to users across different age groups.We manually curated a dataset of 4,163 app reviews from the Google Play Store and identified 1,429 age-related reviews and 2,734 non-age-related reviews. We employed eight machine learning, deep learning, and large language models to automatically detect age discussions, with RoBERTa performing the best, achieving a precision of 92.46%. Additionally, a qualitative analysis of the 1,429 age-related reviews uncovers six dominant themes reflecting user concerns.", "AI": {"tldr": "研究通过分析应用评论中的年龄相关讨论，揭示了不同年龄段用户的需求和挑战，并提出了改进移动应用程序的建议。", "motivation": "为了更好地满足各年龄段用户的需要，理解他们在使用移动应用时遇到的问题至关重要。尽管已有努力创建适合所有年龄段的应用程序，但缺乏对用户视角的理解可能使开发者难以识别特定问题并实施有效解决方案。", "method": "研究手动整理了来自Google Play Store的4,163条评论，并通过机器学习、深度学习和大型语言模型自动检测年龄相关讨论，其中RoBERTa表现最佳。同时进行了定性分析以揭示主要主题。", "result": "RoBERTa在自动检测年龄相关评论方面表现出色，达到92.46%的精度；并确定了六个反映用户关注的主要主题。", "conclusion": "研究发现表明，不同年龄段用户的反馈可以帮助开发者更好地设计和优化应用程序，从而满足所有年龄段的需求。"}}
{"id": "2601.21602", "pdf": "https://arxiv.org/pdf/2601.21602", "abs": "https://arxiv.org/abs/2601.21602", "authors": ["Jianli Sun", "Bin Tian", "Qiyao Zhang", "Chengxiang Li", "Zihan Song", "Zhiyong Cui", "Yisheng Lv", "Yonglin Tian"], "title": "AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "While Vision-Language-Action (VLA) models have achieved remarkable success in ground-based embodied intelligence, their application to Aerial Manipulation Systems (AMS) remains a largely unexplored frontier. The inherent characteristics of AMS, including floating-base dynamics, strong coupling between the UAV and the manipulator, and the multi-step, long-horizon nature of operational tasks, pose severe challenges to existing VLA paradigms designed for static or 2D mobile bases. To bridge this gap, we propose AIR-VLA, the first VLA benchmark specifically tailored for aerial manipulation. We construct a physics-based simulation environment and release a high-quality multimodal dataset comprising 3000 manually teleoperated demonstrations, covering base manipulation, object & spatial understanding, semantic reasoning, and long-horizon planning. Leveraging this platform, we systematically evaluate mainstream VLA models and state-of-the-art VLM models. Our experiments not only validate the feasibility of transferring VLA paradigms to aerial systems but also, through multi-dimensional metrics tailored to aerial tasks, reveal the capabilities and boundaries of current models regarding UAV mobility, manipulator control, and high-level planning. AIR-VLA establishes a standardized testbed and data foundation for future research in general-purpose aerial robotics. The resource of AIR-VLA will be available at https://anonymous.4open.science/r/AIR-VLA-dataset-B5CC/.", "AI": {"tldr": "提出AIR-VLA基准，以解决无人机操作中的视觉语言行动问题。", "motivation": "填补了现有VLA模型在空中机器人应用方面的空白，并构建了一个适用于无人机操作的标准化测试平台和数据基础。", "method": "创建了一个基于物理的仿真环境并发布了包含3000个手动遥控演示的数据集，评估主流的VLA模型和最先进的视觉语言模型。", "result": "实验表明将VLA范式转移到空中系统是可行的，并揭示了当前模型在无人机移动性、机械臂控制以及高级规划方面的能力与局限性。", "conclusion": "AIR-VLA为未来的研究提供了一个标准测试床和数据基础，促进了通用空中机器人技术的发展。"}}
{"id": "2601.21601", "pdf": "https://arxiv.org/pdf/2601.21601", "abs": "https://arxiv.org/abs/2601.21601", "authors": ["Hoyeon Chang", "Bálint Mucsányi", "Seong Joon Oh"], "title": "Dynamics Reveals Structure: Challenging the Linear Propagation Assumption", "categories": ["cs.LG", "cs.AI"], "comment": ":I.2.6", "summary": "Neural networks adapt through first-order parameter updates, yet it remains unclear whether such updates preserve logical coherence. We investigate the geometric limits of the Linear Propagation Assumption (LPA), the premise that local updates coherently propagate to logical consequences. To formalize this, we adopt relation algebra and study three core operations on relations: negation flips truth values, converse swaps argument order, and composition chains relations. For negation and converse, we prove that guaranteeing direction-agnostic first-order propagation necessitates a tensor factorization separating entity-pair context from relation content. However, for composition, we identify a fundamental obstruction. We show that composition reduces to conjunction, and prove that any conjunction well-defined on linear features must be bilinear. Since bilinearity is incompatible with negation, this forces the feature map to collapse. These results suggest that failures in knowledge editing, the reversal curse, and multi-hop reasoning may stem from common structural limitations inherent to the LPA.", "AI": {"tldr": "本文探讨了线性传播假设(LPA)在神经网络中的几何限制，发现对于组合操作存在根本障碍。", "motivation": "研究局部更新是否能保持逻辑一致性，探索LPA的几何限制和内在结构局限。", "method": "使用关系代数定义并分析三种核心的关系运算：否定、反转和合成。通过理论证明揭示了这些操作对线性特征的约束条件。", "result": "对于否定与反转，需要张量分解分离实体对上下文与关系内容；而对于组合，则发现其导致特征图崩溃。", "conclusion": "研究结果表明知识编辑失败、反向诅咒及多跳推理问题可能源于LPA中的共同结构限制。"}}
{"id": "2601.21600", "pdf": "https://arxiv.org/pdf/2601.21600", "abs": "https://arxiv.org/abs/2601.21600", "authors": ["Kshitij Mishra", "Mirat Aubakirov", "Martin Takac", "Nils Lukas", "Salem Lahlou"], "title": "CORE: Collaborative Reasoning via Cross Teaching", "categories": ["cs.AI"], "comment": null, "summary": "Large language models exhibit complementary reasoning errors: on the same instance, one model may succeed with a particular decomposition while another fails. We propose Collaborative Reasoning (CORE), a training-time collaboration framework that converts peer success into a learning signal via a cross-teaching protocol. Each problem is solved in two stages: a cold round of independent sampling, followed by a contexted rescue round in which models that failed receive hint extracted from a successful peer. CORE optimizes a combined reward that balances (i) correctness, (ii) a lightweight DPP-inspired diversity term to reduce error overlap, and (iii) an explicit rescue bonus for successful recovery. We evaluate CORE across four standard reasoning datasets GSM8K, MATH, AIME, and GPQA. With only 1,000 training examples, a pair of small open source models (3B+4B) reaches Pass@2 of 99.54% on GSM8K and 92.08% on MATH, compared to 82.50% and 74.82% for single-model training. On harder datasets, the 3B+4B pair reaches Pass@2 of 77.34% on GPQA (trained on 348 examples) and 79.65% on AIME (trained on 792 examples), using a training-time budget of at most 1536 context tokens and 3072 generated tokens. Overall, these results show that training-time collaboration can reliably convert model complementarity into large gains without scaling model size.", "AI": {"tldr": "提出了一种通过跨教学协议将同伴成功转化为学习信号的协作推理框架CORE，以减少大型语言模型在相同实例上的错误重叠并提高准确性。", "motivation": "大型语言模型在相同的任务实例上表现出互补性的推理错误。一种模型可能在这个实例中成功地进行分解，而另一种则失败了。通过将同伴的成功转化为学习信号，可以降低误差的重叠，并显著提高准确性和性能。", "method": "CORE框架包括两个阶段：冷启动独立采样和带有从成功伙伴提取线索的救援轮次。该方法优化了一个结合正确性、轻量级多样性项和恢复奖励的综合奖励函数，以实现最佳协作效果。", "result": "在GSM8K、MATH、AIME和GPQA四个标准推理数据集上进行了评估。通过仅使用1000个训练样本，一对小型开源模型（3B+4B）在GSM8K上的Pass@2达到了99.54%，而在MATH上的Pass@2为92.08%。对于更难的数据集GPQA和AIME，该方法同样表现出色。", "conclusion": "结果显示，在训练过程中进行协作可以可靠地将模型的互补性转化为显著性能提升，并且无需扩大模型规模即可实现这一目标。"}}
{"id": "2601.21598", "pdf": "https://arxiv.org/pdf/2601.21598", "abs": "https://arxiv.org/abs/2601.21598", "authors": ["Zhi Zheng", "Wee Sun Lee"], "title": "Beyond Imitation: Reinforcement Learning for Active Latent Planning", "categories": ["cs.AI"], "comment": null, "summary": "Aiming at efficient and dense chain-of-thought (CoT) reasoning, latent reasoning methods fine-tune Large Language Models (LLMs) to substitute discrete language tokens with continuous latent tokens. These methods consume fewer tokens compared to the conventional language CoT reasoning and have the potential to plan in a dense latent space. However, current latent tokens are generally supervised based on imitating language labels. Considering that there can be multiple equivalent but diverse CoT labels for a question, passively imitating an arbitrary one may lead to inferior latent token representations and latent reasoning policies, undermining the potential planning ability and resulting in clear gaps between training and testing. In this work, we emphasize the importance of active planning over the representation space of latent tokens in achieving the optimal latent reasoning policy. So, we propose the \\underline{A}c\\underline{t}ive Latent \\underline{P}lanning method (ATP-Latent), which models the supervision process of latent tokens as a conditional variational auto-encoder (VAE) to obtain a smoother latent space. Moreover, to facilitate the most reasonable latent reasoning policy, ATP-Latent conducts reinforcement learning (RL) with an auxiliary coherence reward, which is calculated based on the consistency between VAE-decoded contents of latent tokens, enabling a guided RL process. In experiments on LLaMA-1B, ATP-Latent demonstrates +4.1\\% accuracy and -3.3\\% tokens on four benchmarks compared to advanced baselines. Codes are available on https://github.com/zz1358m/ATP-Latent-master.", "AI": {"tldr": "该论文提出了主动规划方法（ATP-Latent），通过强化学习来优化大型语言模型中的链式推理过程。", "motivation": "当前基于模仿的语言标签的潜在令牌表示可能导致次优的潜在推理策略，因此提出了一种新的方法以实现更有效的密集型链式推理和潜在空间规划。", "method": "ATP-Latent利用条件变分自动编码器（VAE）来获取平滑的潜在空间，并通过一个辅助一致性奖励来进行强化学习，从而指导潜意识令牌的合理政策制定。", "result": "在LLaMA-1B模型上进行实验后，与先进的基线相比，ATP-Latent展示了4.1%的准确性提升和3.3%的令牌使用减少。代码可在https://github.com/zz1358m/ATP-Latent-master找到。", "conclusion": "通过强化学习主动规划潜在令牌表示可以提高模型性能并优化推理策略，进一步推动了大型语言模型中的密集型链式推理研究方向。"}}
{"id": "2601.21595", "pdf": "https://arxiv.org/pdf/2601.21595", "abs": "https://arxiv.org/abs/2601.21595", "authors": ["Abdul Hasib", "A. S. M. Ahsanul Sarkar Akib", "Anish Giri"], "title": "HydroSense: A Dual-Microcontroller IoT Framework for Real-Time Multi-Parameter Water Quality Monitoring with Edge Processing and Cloud Analytics", "categories": ["cs.CV"], "comment": null, "summary": "The global water crisis necessitates affordable, accurate, and real-time water quality monitoring solutions. Traditional approaches relying on manual sampling or expensive commercial systems fail to address accessibility challenges in resource-constrained environments. This paper presents HydroSense, an innovative Internet of Things framework that integrates six critical water quality parameters including pH, dissolved oxygen (DO), temperature, total dissolved solids (TDS), estimated nitrogen, and water level into a unified monitoring system. HydroSense employs a novel dual-microcontroller architecture, utilizing Arduino Uno for precision analog measurements with five-point calibration algorithms and ESP32 for wireless connectivity, edge processing, and cloud integration. The system implements advanced signal processing techniques including median filtering for TDS measurement, temperature compensation algorithms, and robust error handling. Experimental validation over 90 days demonstrates exceptional performance metrics: pH accuracy of plus or minus 0.08 units across the 0 to 14 range, DO measurement stability within plus or minus 0.2 mg/L, TDS accuracy of plus or minus 1.9 percent across 0 to 1000 ppm, and 99.8 percent cloud data transmission reliability. With a total implementation cost of 32,983 BDT (approximately 300 USD), HydroSense achieves an 85 percent cost reduction compared to commercial systems while providing enhanced connectivity through the Firebase real-time database. This research establishes a new paradigm for accessible environmental monitoring, demonstrating that professional-grade water quality assessment can be achieved through intelligent system architecture and cost-effective component selection.", "AI": {"tldr": "本文提出了HydroSense，一种用于实时多参数水质监测的物联网框架。", "motivation": "全球水危机需要经济实惠、准确且实时的水质监测解决方案。传统的手动采样或昂贵的商业系统无法解决资源受限环境中的可访问性问题。", "method": "HydroSense采用了双微控制器架构，使用Arduino Uno进行精度模拟测量和五点校准算法，ESP32负责无线连接、边缘处理和云集成。该系统采用高级信号处理技术，包括中值滤波器用于TDS测量、温度补偿算法和鲁棒的错误处理。", "result": "经过90天实验验证，HydroSense表现出色：pH准确度为±0.08单位，在0到14范围内；溶解氧测量稳定性为±0.2 mg/L；总溶解固体（TDS）准确度为±1.9%，在0至1000 ppm范围内；云数据传输可靠性达到99.8%。", "conclusion": "HydroSense以32,983 BDT（约300美元）的成本实现，比商用系统成本降低85%。该研究建立了新的环境监测范例，并证明了通过智能系统架构和低成本组件选择可以实现专业级水质评估。"}}
{"id": "2601.21592", "pdf": "https://arxiv.org/pdf/2601.21592", "abs": "https://arxiv.org/abs/2601.21592", "authors": ["Luwei Tu", "Jiawei Wu", "Xing Luo", "Zhi Jin"], "title": "Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.", "AI": {"tldr": "本文提出了一种不确定性感知扩散桥模型（UDBM），用于统一处理异构退化问题，实现了单一步骤内的一站式图像恢复。", "motivation": "现有方法在解决All-in-One Image Restoration时受限于粗粒度控制机制或固定映射调度，导致适应性不佳。本文提出了一种新的模型以应对这一挑战。", "method": "引入了不确定性感知的扩散桥模型（UDBM），通过松弛终端约束来建模降质过程中的不确定性，并设计了一种双重调制策略：噪声调度将不同的退化类型统一到一个高熵潜在空间，路径调度则根据粘性动力学理论动态调整传输轨迹。", "result": "该方法在多种恢复任务中实现了最先进的性能，在单一推理步骤内达到优越的效果。", "conclusion": "UDBM通过有效的几何和动态校正，显著提高了图像恢复的质量，并展示了其在统一处理异构退化问题方面的潜力。"}}
{"id": "2601.21590", "pdf": "https://arxiv.org/pdf/2601.21590", "abs": "https://arxiv.org/abs/2601.21590", "authors": ["Xiaotong Ji", "Rasul Tutunov", "Matthieu Zimmer", "Haitham Bou Ammar"], "title": "Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) post-training is a dominant approach for improving the reasoning performance of large language models (LLMs), yet growing evidence suggests that its gains arise primarily from distribution sharpening rather than the acquisition of new capabilities. Recent work has shown that sampling from the power distribution of LLMs using Markov chain Monte Carlo (MCMC) can recover performance comparable to RL post-training without relying on external rewards; however, the high computational cost of MCMC makes such approaches impractical for widespread adoption. In this work, we propose a theoretically grounded alternative that eliminates the need for iterative MCMC. We derive a novel formulation showing that the global power distribution can be approximated by a token-level scaled low-temperature one, where the scaling factor captures future trajectory quality. Leveraging this insight, we introduce a training-free and verifier-free algorithm that sharpens the base model's generative distribution autoregressively. Empirically, we evaluate our method on math, QA, and code tasks across four LLMs, and show that our method matches or surpasses one-shot GRPO without relying on any external rewards, while reducing inference latency by over 10x compared to MCMC-based sampling.", "AI": {"tldr": "提出了一种新的方法，通过分布锐化来提高大型语言模型的推理性能，并且此方法不需要迭代马尔可夫链蒙特卡洛（MCMC）过程。", "motivation": "现有的强化学习后训练方法虽然有效但计算成本高。研究者发现使用幂采样可以达到类似效果，而无需外部奖励或额外训练，因此探索了一个更为实用的、不依赖迭代MCMC的方法来提高模型性能。", "method": "提出了一种基于理论的新方法，证明了全局功率分布可以通过调整低温度下的令牌级缩放因子近似得到。通过此方法，可以自回归地锐化基础模型的生成分布而无需训练或验证器。", "result": "在数学、问答和代码任务上进行了实证评估，结果显示该方法能够达到或超越一次强化学习策略优化（GRPO）的效果，并且显著减少了推理延迟（超过10倍于MCMC基线采样方法）。", "conclusion": "这项工作证明了通过分布锐化而非依赖外部奖励或者额外训练可以有效提高大型语言模型的推理性能。这种方法不仅提高了效率，而且具备更广泛的适用性和实用性。"}}
{"id": "2601.21584", "pdf": "https://arxiv.org/pdf/2601.21584", "abs": "https://arxiv.org/abs/2601.21584", "authors": ["Pin-Han Ho", "Limei Peng", "Yiming Miao", "Xu Fan", "Kairan Liang", "Haoran Mei", "Wei Duan"], "title": "Frequency as Aperture: Enabling Embeddable Near-Field Sensing for 6G Wireless Radios", "categories": ["cs.AR", "cs.ET"], "comment": null, "summary": "Integrated sensing and communication (ISAC) is expected to be natively supported by future 6G wireless radios, yet most mmWave sensing solutions still rely on dedicated radar hardware incompatible with cost and power constrained wireless nodes. This article introduces Frequency-as-Aperture (FaA), a wireless-first sensing paradigm that repurposes inherent frequency agility into a virtual sensing aperture, enabling near-field perception with minimal RF front end complexity. Using a single RF chain and a frequency-scanning leaky-wave antenna, FaA achieves two dimensional spatial sensing by reusing the local oscillator (LO) frequency sweep already employed for wideband communication. From a wireless-system perspective, this shifts spatial sampling from the antenna domain to the frequency domain, embedding radar-grade spatial fingerprints directly into the communication RF chain. A case study shows that FaA provides fine angular and range discrimination with low power consumption and unit cost, demonstrating significantly higher architectural efficiency than conventional multi-channel MIMO based sensing under identical physical and spectral constraints. These results indicate that near-field sensing can be seamlessly integrated into frequency-agile wireless radios, enabling hardware-efficient, embeddable, and privacy-preserving ISAC nodes for smart homes, wearables, and industrial edge deployments.", "AI": {"tldr": "本文介绍了Frequency-as-Aperture（FaA）技术，利用频率敏捷性作为虚拟感知孔径，以简化近场感知的射频前端复杂度。", "motivation": "当前大多数毫米波传感解决方案依赖于专用雷达硬件，与成本和功耗受限的无线节点不兼容。本文提出了一种新的无线优先感知范式，旨在通过复用频率扫描提高集成感测与通信（ISAC）在6G无线电台中的原生支持。", "method": "利用单一射频链路及频率扫描泄露波导天线，将空间采样从天线域转移到频率域，使得雷达级的空间特征能够直接嵌入到通信射频链中。通过频率扫描泄漏波导天线进行二维空间感知。", "result": "实验表明，FaA技术在较低功耗和成本下提供了精细的角度和距离分辨能力，并且在物理和光谱约束相同的条件下，架构效率显著高于传统的多通道MIMO传感方法。", "conclusion": "近场感测能够通过频率敏捷无线电台无缝集成，实现硬件高效、可嵌入性和隐私保护的ISAC节点，在智能家居、穿戴设备和工业边缘部署中展现出巨大潜力。"}}
{"id": "2601.21582", "pdf": "https://arxiv.org/pdf/2601.21582", "abs": "https://arxiv.org/abs/2601.21582", "authors": ["Jonas Knupp", "Jan Hendrik Metzen", "Jeremias Bohn", "Georg Groh", "Kristian Kersting"], "title": "Depth-Recurrent Attention Mixtures: Giving Latent Reasoning the Attention it Deserves", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Depth-recurrence facilitates latent reasoning by sharing parameters across depths. However, prior work lacks combined FLOP-, parameter-, and memory-matched baselines, underutilizes depth-recurrence due to partially fixed layer stacks, and ignores the bottleneck of constant hidden-sizes that restricts many-step latent reasoning. To address this, we introduce a modular framework of depth-recurrent attention mixtures (Dreamer), combining sequence attention, depth attention, and sparse expert attention. It alleviates the hidden-size bottleneck through attention along depth, decouples scaling dimensions, and allows depth-recurrent models to scale efficiently and effectively. Across language reasoning benchmarks, our models require 2 to 8x fewer training tokens for the same accuracy as FLOP-, parameter-, and memory-matched SOTA, and outperform ca. 2x larger SOTA models with the same training tokens. We further present insights into knowledge usage across depths, e.g., showing 2 to 11x larger expert selection diversity than SOTA MoEs.", "AI": {"tldr": "该论文提出了一种结合序列注意力、深度注意力和稀疏专家注意力的模块化框架，以解决深度递归模型中的瓶颈问题。", "motivation": "之前的工作缺乏与FLOP、参数和内存相匹配的基础线，未能充分利用深度递归，并忽略了限制多步潜在推理的隐藏尺寸瓶颈。", "method": "引入了一种结合序列注意力、深度注意力和稀疏专家注意力的模块化框架Dreamer，通过沿深度的注意来缓解隐藏尺寸瓶颈，解耦扩展维度，使得深度递归模型能够有效高效地扩展。", "result": "在语言推理基准测试中，该模型使用相同准确性所需的训练令牌减少2到8倍，并且与具有相同训练令牌的SOTA相比性能提高约两倍。此外，还展示了专家选择多样性比现有方法高出2到11倍的知识使用情况。", "conclusion": "Dreamer框架通过解决深度递归中的瓶颈问题，提高了模型在语言推理任务上的表现，显示出更高效的扩展能力和更好的性能提升。"}}
{"id": "2601.21576", "pdf": "https://arxiv.org/pdf/2601.21576", "abs": "https://arxiv.org/abs/2601.21576", "authors": ["Juncai Li", "Ru Li", "Yuxiang Zhou", "Boxiang Ma", "Jeff Z. Pan"], "title": "Chain Of Thought Compression: A Theoritical Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Chain-of-Thought (CoT) has unlocked advanced reasoning abilities of Large Language Models (LLMs) with intermediate steps, yet incurs prohibitive computational costs due to generation of extra tokens. Recent studies empirically show that compressing reasoning steps into latent states, or implicit CoT compression, offers a token-efficient alternative. However, the mechanism behind CoT compression remains unclear. In this paper, we provide the first theoretical analysis of the difficulty of learning to internalize intermediate reasoning steps. By introducing Order-r Interaction, we prove that the learning signal for high-order logical dependencies exponentially decays to solve irreducible problem, where skipping intermediate steps inevitably leads to high-order interaction barriers. To empirically validate this, we introduce NatBool-DAG, a challenging benchmark designed to enforce irreducible logical reasoning and eliminate semantic shortcuts. Guided by our theoretical findings, we propose ALiCoT (Aligned Implicit CoT), a novel framework that overcomes the signal decay by aligning latent token distributions with intermediate reasoning states. Experimental results demonstrate that ALiCoT successfully unlocks efficient reasoning: it achieves a 54.4x speedup while maintaining performance comparable to explicit CoT.", "AI": {"tldr": "论文提出了ALiCoT框架，该框架通过将隐式链式思维与中间推理状态对齐来解决压缩过程中信号衰减的问题。", "motivation": "论文旨在解决大型语言模型在生成额外令牌以实现高级推理能力时所面临的计算成本问题，并分析了内部化中间推理步骤学习的难度。", "method": "引入Order-r Interaction概念，证明了高阶逻辑依赖性会因信号衰减而难以学习。通过创建NatBool-DAG基准来验证理论发现，并提出了ALiCoT框架以克服这一挑战。", "result": "实验结果表明，ALiCoT框架实现了54.4倍的速度提升，同时保持与显式链式思维相当的性能表现。", "conclusion": "论文通过理论和实证研究展示了如何有效地压缩推理步骤，并提出了一种新型框架来克服信号衰减问题。"}}
{"id": "2601.21572", "pdf": "https://arxiv.org/pdf/2601.21572", "abs": "https://arxiv.org/abs/2601.21572", "authors": ["Jinhao Li", "Yuhao Sun", "Zhiyuan Ma", "Hao He", "Xinche Zhang", "Xing Chen", "Jin Li", "Sen Song"], "title": "Signal-Adaptive Trust Regions for Gradient-Free Optimization of Recurrent Spiking Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recurrent spiking neural networks (RSNNs) are a promising substrate for energy-efficient control policies, but training them for high-dimensional, long-horizon reinforcement learning remains challenging. Population-based, gradient-free optimization circumvents backpropagation through non-differentiable spike dynamics by estimating gradients. However, with finite populations, high variance of these estimates can induce harmful and overly aggressive update steps. Inspired by trust-region methods in reinforcement learning that constrain policy updates in distribution space, we propose \\textbf{Signal-Adaptive Trust Regions (SATR)}, a distributional update rule that constrains relative change by bounding KL divergence normalized by an estimated signal energy. SATR automatically expands the trust region under strong signals and contracts it when updates are noise-dominated. We instantiate SATR for Bernoulli connectivity distributions, which have shown strong empirical performance for RSNN optimization. Across a suite of high-dimensional continuous-control benchmarks, SATR improves stability under limited populations and reaches competitive returns against strong baselines including PPO-LSTM. In addition, to make SATR practical at scale, we introduce a bitset implementation for binary spiking and binary weights, substantially reducing wall-clock training time and enabling fast RSNN policy search.", "AI": {"tldr": "本文提出了一种用于递归尖峰神经网络的信号自适应信任区域方法，以解决高维、长时序强化学习训练中的挑战。", "motivation": "传统的基于群体的无梯度优化在处理非可微分的尖峰动态时存在估计误差大和更新步幅过于激进的问题。本文旨在通过引入信号自适应的信任区域来稳定网络的学习过程，提高其性能。", "method": "提出了名为信号自适应信任区域（SATR）的方法，该方法基于Kullback-Leibler散度并用估算的信号能量进行归一化限制相对变化，以约束分布空间中的策略更新。通过自动调整信任区间来应对强烈的信号和噪声主导的情况。", "result": "在多个高维连续控制基准测试中，SATR提高了有限群体下的稳定性和与PPO-LSTM等强基线算法相比达到了具有竞争力的回报。", "conclusion": "本文方法有效地解决了递归尖峰神经网络训练中的挑战，并通过优化实施降低了实际训练时间。"}}
{"id": "2601.21571", "pdf": "https://arxiv.org/pdf/2601.21571", "abs": "https://arxiv.org/abs/2601.21571", "authors": ["Neil Rathi", "Alec Radford"], "title": "Shaping capabilities with token-level data filtering", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "33 pages, 28 figures", "summary": "Current approaches to reducing undesired capabilities in language models are largely post hoc, and can thus be easily bypassed by adversaries. A natural alternative is to shape capabilities during pretraining itself. On the proxy task of removing medical capabilities, we show that the simple intervention of filtering pretraining data is highly effective, robust, and inexpensive at scale. Inspired by work on data attribution, we show that filtering tokens is more effective than filtering documents, achieving the same hit to undesired capabilities at a lower cost to benign ones. Training models spanning two orders of magnitude, we then demonstrate that filtering gets more effective with scale: for our largest models, token filtering leads to a 7000x compute slowdown on the forget domain. We also show that models trained with token filtering can still be aligned on the forget domain. Along the way, we introduce a methodology for labeling tokens with sparse autoencoders and distilling cheap, high-quality classifiers. We also demonstrate that filtering can be robust to noisy labels with sufficient pretraining compute.", "AI": {"tldr": "通过预训练阶段过滤数据来减少语言模型中的不期望功能。", "motivation": "现有方法在减少语言模型中不期望能力方面存在不足，容易被绕过。因此提出一种新的方式：在模型预训练时就塑造所需的能力。", "method": "采用基于标记级的数据过滤，在去除医疗信息等不期望能力的任务上进行实验，并展示了这种方法比文档级别过滤更有效且成本更低。此外还介绍了一种使用稀疏自动编码器给标记打标签的方法及高效的分类器提炼技术。", "result": "实验显示，随着模型规模的增加，标记级过滤方法的有效性提高，在最大规模模型中可导致在遗忘领域上的计算速度降低7000倍，但仍能保持良好的对齐效果。并且该方法对于有噪声标签也具有鲁棒性。", "conclusion": "通过预训练阶段采用标记级数据过滤可以有效地减少不期望功能，并且这种方法比文档级别过滤更有效、成本更低。"}}
{"id": "2601.21570", "pdf": "https://arxiv.org/pdf/2601.21570", "abs": "https://arxiv.org/abs/2601.21570", "authors": ["Zixing Lei", "Genjia Liu", "Yuanshuo Zhang", "Qipeng Liu", "Chuan Wen", "Shanghang Zhang", "Wenzhao Lian", "Siheng Chen"], "title": "EmboCoach-Bench: Benchmarking AI Agents on Developing Embodied Robots", "categories": ["cs.AI", "cs.RO"], "comment": "37 pages, 13 figures", "summary": "The field of Embodied AI is witnessing a rapid evolution toward general-purpose robotic systems, fueled by high-fidelity simulation and large-scale data collection. However, this scaling capability remains severely bottlenecked by a reliance on labor-intensive manual oversight from intricate reward shaping to hyperparameter tuning across heterogeneous backends. Inspired by LLMs' success in software automation and science discovery, we introduce \\textsc{EmboCoach-Bench}, a benchmark evaluating the capacity of LLM agents to autonomously engineer embodied policies. Spanning 32 expert-curated RL and IL tasks, our framework posits executable code as the universal interface. We move beyond static generation to assess a dynamic closed-loop workflow, where agents leverage environment feedback to iteratively draft, debug, and optimize solutions, spanning improvements from physics-informed reward design to policy architectures such as diffusion policies. Extensive evaluations yield three critical insights: (1) autonomous agents can qualitatively surpass human-engineered baselines by 26.5\\% in average success rate; (2) agentic workflow with environment feedback effectively strengthens policy development and substantially narrows the performance gap between open-source and proprietary models; and (3) agents exhibit self-correction capabilities for pathological engineering cases, successfully resurrecting task performance from near-total failures through iterative simulation-in-the-loop debugging. Ultimately, this work establishes a foundation for self-evolving embodied intelligence, accelerating the paradigm shift from labor-intensive manual tuning to scalable, autonomous engineering in embodied AI field.", "AI": {"tldr": "该论文提出了一种评估AI代理自主开发具身政策能力的基准EmboCoach-Bench，涵盖32个专家设计的任务。", "motivation": "当前具身AI领域的快速发展受限于手动监控等瓶颈问题，作者受到大型语言模型在软件自动化和科学发现中的成功启发，希望通过引入新框架解决这些问题，加速从劳动密集型人工调优向自主工程的转变。", "method": "论文提出了EmboCoach-Bench基准，该基准通过可执行代码作为通用接口来评估AI代理的能力。它支持动态闭环工作流程，允许代理利用环境反馈来迭代开发解决方案，并评估了各种任务上LLM代理的表现。", "result": "实验结果表明，自主代理可以比人工设计的基线高出26.5%的成功率；闭环反馈机制能有效改善政策发展并缩小开源和专有模型之间的性能差距；并且代理能够自我纠正某些工程案例中的错误，恢复任务表现。", "conclusion": "该研究为具身智能的自主进化奠定了基础，并推动了从劳动密集型手动调优向可扩展自动化工程转变的新范式。"}}
{"id": "2601.21561", "pdf": "https://arxiv.org/pdf/2601.21561", "abs": "https://arxiv.org/abs/2601.21561", "authors": ["Fanping Liu", "Hua Yang", "Jiasi Zou"], "title": "SAL: Selective Adaptive Learning for Backpropagation-Free Training with Sparsification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Standard deep learning relies on Backpropagation (BP), which is constrained by biologically implausible weight symmetry and suffers from significant gradient interference within dense representations. To mitigate these bottlenecks, we propose Selective Adaptive Learning (SAL), a training method that combines selective parameter activation with adaptive area partitioning. Specifically, SAL decomposes the parameter space into mutually exclusive, sample-dependent regions. This decoupling mitigates gradient interference across divergent semantic patterns and addresses explicit weight symmetry requirements through our refined feedback alignment. Empirically, SAL demonstrates competitive convergence rates, leading to improved classification performance across 10 standard benchmarks. Additionally, SAL achieves numerical consistency and competitive accuracy even in deep regimes (up to 128 layers) and large-scale models (up to 1B parameters). Our approach is loosely inspired by biological learning mechanisms, offering a plausible alternative that contributes to the study of scalable neural network training.", "AI": {"tldr": "提出选择性自适应学习(SAL)方法，通过参数空间分解和自适应区域划分，实现无反向传播的训练。", "motivation": "标准深度学习依赖于反向传播(BP)，受到生物上不可行的权重对称性和密集表示中的显著梯度干扰问题困扰。为了克服这些问题，引入了选择性自适应学习(SAL)方法。", "method": "SAL通过将参数空间分解为相互独立、样本相关的区域来实现训练，并且这种方法不依赖于反向传播。", "result": "实验表明，在10个标准基准上，SAL实现了具有竞争力的收敛速度和分类性能。此外，在深层(最多128层)和大规模模型(多达1B参数)中，依然保持数值一致性和准确度。", "conclusion": "该方法提供了一种可扩展神经网络训练的可行替代方案，并对研究深度学习算法提出了新的见解。"}}
{"id": "2601.21557", "pdf": "https://arxiv.org/pdf/2601.21557", "abs": "https://arxiv.org/abs/2601.21557", "authors": ["Haoran Ye", "Xuning He", "Vincent Arak", "Haonan Dong", "Guojie Song"], "title": "Meta Context Engineering via Agentic Skill Evolution", "categories": ["cs.AI", "cs.NE"], "comment": "46 pages, 4 figures", "summary": "The operational efficacy of large language models relies heavily on their inference-time context. This has established Context Engineering (CE) as a formal discipline for optimizing these inputs. Current CE methods rely on manually crafted harnesses, such as rigid generation-reflection workflows and predefined context schemas. They impose structural biases and restrict context optimization to a narrow, intuition-bound design space. To address this, we introduce Meta Context Engineering (MCE), a bi-level framework that supersedes static CE heuristics by co-evolving CE skills and context artifacts. In MCE iterations, a meta-level agent refines engineering skills via agentic crossover, a deliberative search over the history of skills, their executions, and evaluations. A base-level agent executes these skills, learns from training rollouts, and optimizes context as flexible files and code. We evaluate MCE across five disparate domains under offline and online settings. MCE demonstrates consistent performance gains, achieving 5.6--53.8% relative improvement over state-of-the-art agentic CE methods (mean of 16.9%), while maintaining superior context adaptability, transferability, and efficiency in both context usage and training.", "AI": {"tldr": "本文提出了Meta Context Engineering (MCE)框架，通过代理技能的进化来优化大型语言模型的推理时间上下文。", "motivation": "当前的上下文工程方法依赖于手动构建的方法，并且存在结构性偏见和设计空间限制，因此需要一种更加灵活的方式来进行上下文优化。", "method": "MCE是一个双层框架，通过代理交叉在元层中进化工程技能，基础层中的代理执行这些技能并学习训练回放以优化上下文。", "result": "在五个不同的领域进行离线和在线评估后，MCE显示了一致的性能提升，相对于最先进的代理上下文工程方法平均实现了16.9%的相对改进，并且具有更好的上下文适应性、可转移性和效率。", "conclusion": "MCE超越了静态的上下文工程技术，在不同领域中表现出色，并展示了优越的上下文优化能力。"}}
{"id": "2601.21548", "pdf": "https://arxiv.org/pdf/2601.21548", "abs": "https://arxiv.org/abs/2601.21548", "authors": ["Irene Ambrosini", "Ingo Blakowski", "Dmitrii Zendrikov", "Cristiano Capone", "Luna Gava", "Giacomo Indiveri", "Chiara De Luca", "Chiara Bartolozzi"], "title": "Training slow silicon neurons to control extremely fast robots with spiking reinforcement learning", "categories": ["cs.RO", "cs.AI", "cs.ET"], "comment": null, "summary": "Air hockey demands split-second decisions at high puck velocities, a challenge we address with a compact network of spiking neurons running on a mixed-signal analog/digital neuromorphic processor. By co-designing hardware and learning algorithms, we train the system to achieve successful puck interactions through reinforcement learning in a remarkably small number of trials. The network leverages fixed random connectivity to capture the task's temporal structure and adopts a local e-prop learning rule in the readout layer to exploit event-driven activity for fast and efficient learning. The result is real-time learning with a setup comprising a computer and the neuromorphic chip in-the-loop, enabling practical training of spiking neural networks for robotic autonomous systems. This work bridges neuroscience-inspired hardware with real-world robotic control, showing that brain-inspired approaches can tackle fast-paced interaction tasks while supporting always-on learning in intelligent machines.", "AI": {"tldr": "该论文旨在通过混合信号的类脑芯片和强化学习算法训练硅基神经元网络，以实现对高速运动的机器人控制。", "motivation": "空气曲棍球比赛中需要在高速度下作出快速决策，这是传统方法难以解决的问题。因此，作者希望通过结合硬件设计与学习算法来应对这一挑战。", "method": "论文采用随机连接结构并应用局部e-prop学习规则，通过强化学习训练神经网络以完成任务，在较少的试验次数中实现有效的机器人控制。", "result": "该系统在实际环境中实现了实时的学习和调整，并能够对高速运动进行有效控制。", "conclusion": "研究展示了基于大脑启发的方法能够在快速交互任务中发挥作用并支持智能机器人的持续学习。"}}
{"id": "2601.21547", "pdf": "https://arxiv.org/pdf/2601.21547", "abs": "https://arxiv.org/abs/2601.21547", "authors": ["Lige Zhang", "Ali Maatouk", "Jialin Chen", "Leandros Tassiulas", "Rex Ying"], "title": "Multi-Modal Time Series Prediction via Mixture of Modulated Experts", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 12 figures", "summary": "Real-world time series exhibit complex and evolving dynamics, making accurate forecasting extremely challenging. Recent multi-modal forecasting methods leverage textual information such as news reports to improve prediction, but most rely on token-level fusion that mixes temporal patches with language tokens in a shared embedding space. However, such fusion can be ill-suited when high-quality time-text pairs are scarce and when time series exhibit substantial variation in scale and characteristics, thus complicating cross-modal alignment. In parallel, Mixture-of-Experts (MoE) architectures have proven effective for both time series modeling and multi-modal learning, yet many existing MoE-based modality integration methods still depend on token-level fusion. To address this, we propose Expert Modulation, a new paradigm for multi-modal time series prediction that conditions both routing and expert computation on textual signals, enabling direct and efficient cross-modal control over expert behavior. Through comprehensive theoretical analysis and experiments, our proposed method demonstrates substantial improvements in multi-modal time series prediction. The current code is available at https://github.com/BruceZhangReve/MoME", "AI": {"tldr": "本文提出了一种新的多模态时间序列预测范式Expert Modulation，通过直接和有效的跨模式控制专家行为来改进现有的混合专家（MoE）架构。", "motivation": "现实世界中的时间序列表现出复杂的动态变化，使得准确的预报变得极具挑战性。传统的多模态融合方法依赖于令牌级别的融合，在高质量的时间-文本配对稀少且时间序列在规模和特征上存在显著差异的情况下难以实现有效的跨模式对齐。", "method": "本文提出Expert Modulation范式，通过条件路由和专家计算来直接控制专家行为，并将文本信号纳入考虑。这种方法避免了令牌级别融合的局限性，能够更好地处理复杂的多模态时间序列数据。", "result": "理论分析和实验表明，所提出的Expert Modulation方法在多模态时间序列预测方面取得了显著改进。", "conclusion": "通过综合理论分析和实验验证，证明了Expert Modulation范式能有效改善现有基于混合专家架构的多模态时间序列预测任务。"}}
{"id": "2601.21545", "pdf": "https://arxiv.org/pdf/2601.21545", "abs": "https://arxiv.org/abs/2601.21545", "authors": ["Yang Zhao", "Chengxiao Dai", "Yue Xiu", "Mengying Kou", "Yuliang Zheng", "Dusit Niyato"], "title": "ShardMemo: Masked MoE Routing for Sharded Agentic LLM Memory", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Agentic large language model (LLM) systems rely on external memory for long-horizon state and concurrent multi-agent execution, but centralized indexes and heuristic partitions become bottlenecks as memory volume and parallel access grow. We present ShardMemo, a budgeted tiered memory service with Tier A per-agent working state, Tier B sharded evidence with shard-local approximate nearest neighbor (ANN) indexes, and Tier C, a versioned skill library. Tier B enforces scope-before-routing: structured eligibility constraints mask ineligible shards before routing or ANN search. We cast shard probing as masked mixture-of-experts (MoE) routing over eligible shards, probing up to $B_{\\mathrm{probe}}$ shards via Top-$B_{\\mathrm{probe}}$ or adaptive Top-$P$, and use cost-aware gating over profile/observation/session shard families; the router is trained from evidence-to-shard supervision. On LoCoMo, ShardMemo improves over the strongest baseline (GAM) by +5.11 to +6.82 F1 across question categories. Under a fixed-budget routing setting ($B_{\\mathrm{probe}}=3$), ShardMemo improves over cosine-to-prototype shard routing by +6.87 F1 while reducing retrieval work (VecScan 521->414, -20.5%) and p95 latency (95->76 ms). On long-context HotpotQA, ShardMemo achieves 63.41/61.88/57.95 F1 at 56K/224K/448K tokens. On ToolBench, Tier C reaches 0.97 Precision@3 and 1.94 StepRed (+10.2% and +7.2% over embedding-similarity retrieval).", "AI": {"tldr": "论文提出了ShardMemo，一种用于大型语言模型的记忆系统方案，通过分层存储和高效的路由策略优化了长时态状态管理和多代理并行执行。", "motivation": "随着记忆量的增长和平行访问需求的增加，中央索引和启发式划分成为瓶颈。为了克服这些挑战，研究者设计了一个新的记忆服务来支持具有高效、灵活、可扩展性的大型语言模型系统。", "method": "ShardMemo包括三个层级的记忆：A级是每个代理的工作状态，B级是分片证据与局部近似最近邻居索引，C级是一个版本化的技能库。B级采用结构化资格限制以屏蔽不符合条件的分片，并通过成本感知门控和混合专家（MoE）路由来选择合适的分片。", "result": "实验结果显示，在LoCoMo上ShardMemo相比最强基线提升了5.11到6.82 F1值。在固定预算路由设置下，它比余弦相似性到原型路由改进了6.87 F1，并减少了检索工作和95百分位延迟。", "conclusion": "ShardMemo通过分层存储和高效的路由策略优化了大型语言模型的记忆管理，证明其在处理长文本和多代理任务上的优越性能。"}}
{"id": "2601.21542", "pdf": "https://arxiv.org/pdf/2601.21542", "abs": "https://arxiv.org/abs/2601.21542", "authors": ["Hongxu Chen", "Hongxiang Li", "Zhen Wang", "Long Chen"], "title": "Bi-Anchor Interpolation Solver for Accelerating Generative Modeling", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Flow Matching (FM) models have emerged as a leading paradigm for high-fidelity synthesis. However, their reliance on iterative Ordinary Differential Equation (ODE) solving creates a significant latency bottleneck. Existing solutions face a dichotomy: training-free solvers suffer from significant performance degradation at low Neural Function Evaluations (NFEs), while training-based one- or few-steps generation methods incur prohibitive training costs and lack plug-and-play versatility. To bridge this gap, we propose the Bi-Anchor Interpolation Solver (BA-solver). BA-solver retains the versatility of standard training-free solvers while achieving significant acceleration by introducing a lightweight SideNet (1-2% backbone size) alongside the frozen backbone. Specifically, our method is founded on two synergistic components: \\textbf{1) Bidirectional Temporal Perception}, where the SideNet learns to approximate both future and historical velocities without retraining the heavy backbone; and 2) Bi-Anchor Velocity Integration, which utilizes the SideNet with two anchor velocities to efficiently approximate intermediate velocities for batched high-order integration. By utilizing the backbone to establish high-precision ``anchors'' and the SideNet to densify the trajectory, BA-solver enables large interval sizes with minimized error. Empirical results on ImageNet-256^2 demonstrate that BA-solver achieves generation quality comparable to 100+ NFEs Euler solver in just 10 NFEs and maintains high fidelity in as few as 5 NFEs, incurring negligible training costs. Furthermore, BA-solver ensures seamless integration with existing generative pipelines, facilitating downstream tasks such as image editing.", "AI": {"tldr": "提出了一种用于加速生成模型的Bi-Anchor Interpolation Solver (BA-solver)", "motivation": "解决基于Flow Matching模型生成过程中存在的延迟瓶颈问题", "method": "通过引入轻量级SideNet与冻结主干网络结合，利用双向时间感知和双锚点速度积分来实现高效的速度近似和插值", "result": "BA-solver在少量NFEs下实现了高质量的图像生成，并保持了高精度和可扩展性", "conclusion": "所提出的方法显著加速了生成模型的速度，同时保证了图像质量，具有实际应用价值"}}
{"id": "2601.21541", "pdf": "https://arxiv.org/pdf/2601.21541", "abs": "https://arxiv.org/abs/2601.21541", "authors": ["Zhuoqin Yang", "Jiansong Zhang", "Xiaoling Luo", "Xu Wu", "Zheng Lu", "Linlin Shen"], "title": "Vision KAN: Towards an Attention-Free Backbone for Vision with Kolmogorov-Arnold Networks", "categories": ["cs.CV"], "comment": null, "summary": "Attention mechanisms have become a key module in modern vision backbones due to their ability to model long-range dependencies. However, their quadratic complexity in sequence length and the difficulty of interpreting attention weights limit both scalability and clarity. Recent attention-free architectures demonstrate that strong performance can be achieved without pairwise attention, motivating the search for alternatives. In this work, we introduce Vision KAN (ViK), an attention-free backbone inspired by the Kolmogorov-Arnold Networks. At its core lies MultiPatch-RBFKAN, a unified token mixer that combines (a) patch-wise nonlinear transform with Radial Basis Function-based KANs, (b) axis-wise separable mixing for efficient local propagation, and (c) low-rank global mapping for long-range interaction. Employing as a drop-in replacement for attention modules, this formulation tackles the prohibitive cost of full KANs on high-resolution features by adopting a patch-wise grouping strategy with lightweight operators to restore cross-patch dependencies. Experiments on ImageNet-1K show that ViK achieves competitive accuracy with linear complexity, demonstrating the potential of KAN-based token mixing as an efficient and theoretically grounded alternative to attention.", "AI": {"tldr": "本文提出了一个基于Kolmogorov-Arnold网络的无注意力机制视觉骨干网Vision KAN，旨在解决现代视觉骨干中注意力机制的复杂性问题。", "motivation": "注意机制虽然在处理长距离依赖方面表现良好，但其二次时间复杂度和难以解释的权重限制了其可扩展性和清晰度。因此寻求替代方案成为必要。", "method": "本文提出Vision KAN（ViK），采用MultiPatch-RBFKAN作为统一令牌混合器，结合补丁非线性转换、轴向分离式混频以及低秩全局映射来处理长距离交互问题。", "result": "实验结果表明，在ImageNet-1K数据集上，Vision KAN达到了与注意力模块相当的精度，同时具有线性时间复杂度，证明了基于Kolmogorov-Arnold网络的令牌混合是一种有效的替代方案。", "conclusion": "该研究展示了通过利用Kolmogorov-Arnold网络来设计无注意力机制视觉模型的可能性，并且提出了一个高效、理论依据坚实的替代方法。"}}
{"id": "2601.21533", "pdf": "https://arxiv.org/pdf/2601.21533", "abs": "https://arxiv.org/abs/2601.21533", "authors": ["Youngjin Jin", "Hanna Kim", "Kwanwoo Kim", "Chanhee Lee", "Seungwon Shin"], "title": "ARGORA: Orchestrated Argumentation for Causally Grounded LLM Reasoning and Decision Making", "categories": ["cs.AI"], "comment": "58 pages", "summary": "Existing multi-expert LLM systems gather diverse perspectives but combine them through simple aggregation, obscuring which arguments drove the final decision. We introduce ARGORA, a framework that organizes multi-expert discussions into explicit argumentation graphs showing which arguments support or attack each other. By casting these graphs as causal models, ARGORA can systematically remove individual arguments and recompute outcomes, identifying which reasoning chains were necessary and whether decisions would change under targeted modifications. We further introduce a correction mechanism that aligns internal reasoning with external judgments when they disagree. Across diverse benchmarks and an open-ended use case, ARGORA achieves competitive accuracy and demonstrates corrective behavior: when experts initially disagree, the framework resolves disputes toward correct answers more often than it introduces new errors, while providing causal diagnostics of decisive arguments.", "AI": {"tldr": "ARGORA框架通过组织多专家讨论生成明确的论证图，展示支持或反对的观点，并将其作为因果模型进行系统性分析。", "motivation": "现有基于多个LLM系统的决策过程简单聚合不同观点，未能清晰展现最终决定背后的具体论据。因此，提出一种新的方法来组织这些论证，使其更具透明度和可解释性。", "method": "ARGORA通过构建明确的论证图并将其作为因果模型处理，可以去除单个论证并重新计算结果，从而识别出哪些推理链条是必要的以及决策如何在特定修改下变化。此外还包含一个校正机制，在专家意见与外部判断不一致时进行调整。", "result": "ARGORA在多个基准测试和开放式案例中实现了竞争性的准确性，并表现出纠正行为：当专家最初存在分歧时，框架倾向于解决争端并导向正确答案而非引入新的错误。", "conclusion": "ARGORA不仅提高了决策过程的透明度和可解释性，而且还提供了一种有效的机制来校正内部推理与外部判断之间的差异。"}}
{"id": "2601.21531", "pdf": "https://arxiv.org/pdf/2601.21531", "abs": "https://arxiv.org/abs/2601.21531", "authors": ["Xinwei Zhang", "Hangcheng Liu", "Li Bai", "Hao Wang", "Qingqing Ye", "Tianwei Zhang", "Haibo Hu"], "title": "On the Adversarial Robustness of Large Vision-Language Models under Visual Token Compression", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": "Under Review, 20 pages", "summary": "Visual token compression is widely used to accelerate large vision-language models (LVLMs) by pruning or merging visual tokens, yet its adversarial robustness remains unexplored. We show that existing encoder-based attacks can substantially overestimate the robustness of compressed LVLMs, due to an optimization-inference mismatch: perturbations are optimized on the full-token representation, while inference is performed through a token-compression bottleneck. To address this gap, we propose the Compression-AliGnEd attack (CAGE), which aligns perturbation optimization with compression inference without assuming access to the deployed compression mechanism or its token budget. CAGE combines (i) expected feature disruption, which concentrates distortion on tokens likely to survive across plausible budgets, and (ii) rank distortion alignment, which actively aligns token distortions with rank scores to promote the retention of highly distorted evidence. Across diverse representative plug-and-play compression mechanisms and datasets, our results show that CAGE consistently achieves lower robust accuracy than the baseline. This work highlights that robustness assessments ignoring compression can be overly optimistic, calling for compression-aware security evaluation and defenses for efficient LVLMs.", "AI": {"tldr": "本文研究了大型视觉语言模型在视觉令牌压缩下的对抗鲁棒性，并提出了一种新的攻击方法CAGE来评估这种情况下模型的稳健性。", "motivation": "现有研究表明，通过修剪或合并视觉令牌来加速大尺寸视觉语言模型的技术普遍存在，但其抗扰动能力尚未被研究。传统基于编码器的攻击方法可能因优化-推理不匹配而高估了压缩后模型的鲁棒性。", "method": "为了解决这个问题，作者提出了CAGE（Compression-AliGnEd）攻击方法，这种方法结合预期特征破坏和排名扭曲对齐来评估抗扰动能力。它通过集中注意力于那些在可能预算中存活下来的令牌上进行干扰，并积极地将令牌干扰与排名分数相匹配。", "result": "实验结果表明，CAGE能够一致地降低被压缩模型的准确率，这说明忽视压缩机制的鲁棒性评估可能是过于乐观的。", "conclusion": "该研究强调了在对高效视觉语言模型进行安全评价和防御时需要考虑压缩的影响。"}}
{"id": "2601.21527", "pdf": "https://arxiv.org/pdf/2601.21527", "abs": "https://arxiv.org/abs/2601.21527", "authors": ["Sajid Mannan", "Rupert J. Myers", "Rohit Batra", "Rocio Mercado", "Lothar Wondraczek", "N. M. Anoop Krishnan"], "title": "Sustainable Materials Discovery in the Era of Artificial Intelligence", "categories": ["cond-mat.mtrl-sci", "cs.AI"], "comment": null, "summary": "Artificial intelligence (AI) has transformed materials discovery, enabling rapid exploration of chemical space through generative models and surrogate screening. Yet current AI workflows optimize performance first, deferring sustainability to post synthesis assessment. This creates inefficiency by the time environmental burdens are quantified, resources have been invested in potentially unsustainable solutions. The disconnect between atomic scale design and lifecycle assessment (LCA) reflects fundamental challenges, data scarcity across heterogeneous sources, scale gaps from atoms to industrial systems, uncertainty in synthesis pathways, and the absence of frameworks that co-optimize performance with environmental impact. We propose to integrate upstream machine learning (ML) assisted materials discovery with downstream lifecycle assessment into a uniform ML-LCA environment. The framework ML-LCA integrates five components, information extraction for building materials-environment knowledge bases, harmonized databases linking properties to sustainability metrics, multi-scale models bridging atomic properties to lifecycle impacts, ensemble prediction of manufacturing pathways with uncertainty quantification, and uncertainty-aware optimization enabling simultaneous performance-sustainability navigation. Case studies spanning glass, cement, semiconductor photoresists, and polymers demonstrate both necessity and feasibility while identifying material-specific integration challenges. Realizing ML-LCA demands coordinated advances in data infrastructure, ex-ante assessment methodologies, multi-objective optimization, and regulatory alignment enabling the discovery of materials that are sustainable by design rather than by chance.", "AI": {"tldr": "提出一种将机器学习（ML）辅助材料发现与生命周期评估（LCA）相结合的统一ML-LCA环境，以解决现有AI工作流程中性能优化优先、可持续性滞后的问题。", "motivation": "传统人工智能在材料发现中的应用通常只关注性能而忽视了早期阶段的设计可持续性问题。这导致资源浪费和潜在不可持续解决方案的发展。通过整合上游机器学习与下游生命周期评估，可以有效解决这一挑战，推动设计更环保的材料。", "method": "ML-LCA框架包含五个组成部分：信息提取建立材料-环境知识库、将属性与可持续性指标相连接的一致数据库、多尺度模型从原子性质跨越到生命周期影响、制造途径预测并进行不确定性量化以及不确定性感知优化实现同时性能和可持续性的导航。", "result": "案例研究展示了玻璃、水泥、半导体光刻胶和聚合物的材料发现，证明了这种方法的需求与可行性，并揭示了一些特定于材料的具体整合挑战。", "conclusion": "实现ML-LCA需要在数据基础设施建设、预先评估方法、多目标优化以及法规协调等方面的进步。这将有助于发现由设计决定而不是偶然性的可持续材料。"}}
{"id": "2601.21526", "pdf": "https://arxiv.org/pdf/2601.21526", "abs": "https://arxiv.org/abs/2601.21526", "authors": ["Alireza Nadaf", "Alireza Mohammadshahi", "Majid Yazdani"], "title": "KAPSO: A Knowledge-grounded framework for Autonomous Program Synthesis and Optimization", "categories": ["cs.AI", "cs.CL", "cs.SE"], "comment": null, "summary": "We introduce KAPSO, a modular framework for autonomous program synthesis and optimization. Given a natural language goal and an evaluation method, KAPSO iteratively performs ideation, code synthesis and editing, execution, evaluation, and learning to improve a runnable artifact toward measurable objectives. Rather than treating synthesis as the endpoint, KAPSO uses synthesis as an operator within a long-horizon optimization loop, where progress is defined by evaluator outcomes. KAPSO targets long-horizon failures common in coding agents, including lost experimental state, brittle debugging, and weak reuse of domain expertise, by integrating three tightly coupled components. First, a git-native experimentation engine isolates each attempt as a branch, producing reproducible artifacts and preserving provenance across iterations. Second, a knowledge system ingests heterogeneous sources, including repositories, internal playbooks, and curated external resources such as documentation, scientific papers, and web search results, and organizes them into a structured representation that supports retrieval over workflows, implementations, and environment constraints. Third, a cognitive memory layer coordinates retrieval and maintains an episodic store of reusable lessons distilled from experiment traces (run logs, diffs, and evaluator feedback), reducing repeated error modes and accelerating convergence. We evaluated KAPSO on MLE-Bench (Kaggle-style ML competitions) and ALE-Bench (AtCoder heuristic optimization), and report end-to-end performance. Code Available at: https://github.com/Leeroo-AI/kapso", "AI": {"tldr": "介绍了一种名为KAPSO的框架，该框架用于自主程序合成和优化。", "motivation": "针对编程代理在长期优化过程中常见的失败问题，如实验状态丢失、脆弱调试以及领域专业知识的弱化复用，提出了一个解决方案。", "method": "通过集成三个紧密耦合的组件：git原生实验引擎、知识系统和认知记忆层，KAPSO实现了迭代式的程序合成与编辑、执行、评估及学习过程，从而优化可运行的艺术品以达到测量目标。", "result": "在MLE-Bench（Kaggle式机器学习竞赛）和ALE-Bench（AtCoder启发式优化）上进行了评估，并报告了端到端的性能表现。", "conclusion": "该框架通过长期的迭代优化过程，提高了编程任务的成功率及效率。"}}
{"id": "2601.21522", "pdf": "https://arxiv.org/pdf/2601.21522", "abs": "https://arxiv.org/abs/2601.21522", "authors": ["Sagi Meir", "Tommer D. Keidar", "Noam Levi", "Shlomi Reuveni", "Barak Hirshberg"], "title": "More Bang for the Buck: Improving the Inference of Large Language Models at a Fixed Budget using Reset and Discard (ReD)", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI", "stat.ML"], "comment": null, "summary": "The performance of large language models (LLMs) on verifiable tasks is usually measured by pass@k, the probability of answering a question correctly at least once in k trials. At a fixed budget, a more suitable metric is coverage@cost, the average number of unique questions answered as a function of the total number of attempts. We connect the two metrics and show that the empirically-observed power-law behavior in pass@k leads to a sublinear growth of the coverage@cost (diminishing returns). To solve this problem, we propose Reset-and-Discard (ReD), a query method of LLMs that increases coverage@cost for any given budget, regardless of the pass@k form. Moreover, given a pass@k, we can quantitatively predict the savings in the total number of attempts using ReD. If pass@k is not available for the model, ReD can infer its power-law exponent. Experiments on three LLMs using HumanEval demonstrate that ReD substantially reduces the required attempts, tokens, and USD cost to reach a desired coverage, while also offering an efficient way to measure inference power-laws.", "AI": {"tldr": "提出了一种新的查询方法ReD，以提高大型语言模型在固定预算下的覆盖率。", "motivation": "现有评估指标pass@k不能有效反映固定预算下模型性能，而coverage@cost更能衡量实际应用效果。为了改进这一问题，作者提出了ReD方法。", "method": "通过连接pass@k和coverage@cost两个指标，发现幂律行为导致覆盖率增长缓慢（边际效益递减）。为此设计了ReD策略，在给定预算下增加模型的覆盖率，并预测减少尝试次数。", "result": "实验表明，使用ReD方法可以显著降低所需尝试次数、代币数量及美元成本来达到期望的覆盖率。同时提供了一种有效的方式评估推理幂律特性。", "conclusion": "ReD策略是一种有效的查询方式，在固定预算下提升大型语言模型的性能表现，并提供了量化预测和测量的方法。"}}
{"id": "2601.21521", "pdf": "https://arxiv.org/pdf/2601.21521", "abs": "https://arxiv.org/abs/2601.21521", "authors": ["Chi-Sheng Chen", "En-Jui Kuo", "Guan-Ying Chen", "Xinyu Zhang", "Fan Zhang"], "title": "A Unified SPD Token Transformer Framework for EEG Classification: Systematic Comparison of Geometric Embeddings", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Spatial covariance matrices of EEG signals are Symmetric Positive Definite (SPD) and lie on a Riemannian manifold, yet the theoretical connection between embedding geometry and optimization dynamics remains unexplored. We provide a formal analysis linking embedding choice to gradient conditioning and numerical stability for SPD manifolds, establishing three theoretical results: (1) BWSPD's $\\sqrtκ$ gradient conditioning (vs $κ$ for Log-Euclidean) via Daleckii-Kreĭn matrices provides better gradient conditioning on high-dimensional inputs ($d \\geq 22$), with this advantage reducing on low-dimensional inputs ($d \\leq 8$) where eigendecomposition overhead dominates; (2) Embedding-Space Batch Normalization (BN-Embed) approximates Riemannian normalization up to $O(\\varepsilon^2)$ error, yielding $+26\\%$ accuracy on 56-channel ERP data but negligible effect on 8-channel SSVEP data, matching the channel-count-dependent prediction; (3) bi-Lipschitz bounds prove BWSPD tokens preserve manifold distances with distortion governed solely by the condition ratio $κ$. We validate these predictions via a unified Transformer framework comparing BWSPD, Log-Euclidean, and Euclidean embeddings within identical architecture across 1,500+ runs on three EEG paradigms (motor imagery, ERP, SSVEP; 36 subjects). Our Log-Euclidean Transformer achieves state-of-the-art performance on all datasets, substantially outperforming classical Riemannian classifiers and recent SPD baselines, while BWSPD offers competitive accuracy with similar training time.", "AI": {"tldr": "本文提出了一种统一的SPD令牌变压器框架，用于EEG信号分类，并通过系统比较了几何嵌入的效果。", "motivation": "研究了不同几何嵌入方法在高维输入中的梯度条件和数值稳定性，并探讨了这些方法如何影响EEG分类性能。", "method": "提供了正式的理论分析，建立了三种结果：(1) BWSPD具有更好的梯度条件；(2) 嵌入空间批规范化与黎曼规范化的误差匹配预测；(3) bi-Lipschitz界证明了BWSPD令牌在保留下流形距离时受到条件比率的影响。", "result": "通过统一的Transformer框架，比较了三种嵌入方法（BWSPD、Log-Euclidean和欧几里得），并在三个EEG范式上进行了1500多次运行。结果表明，Log-Euclidean Transformer在所有数据集上均达到最佳性能。", "conclusion": "提出的统一Transformer框架显著提高了EEG分类的准确性，并展示了不同几何嵌入方法之间的差异性及适用性。"}}
{"id": "2601.21518", "pdf": "https://arxiv.org/pdf/2601.21518", "abs": "https://arxiv.org/abs/2601.21518", "authors": ["Xinyi Zhang", "Mamtaj Akter", "Heajun An", "Minqian Liu", "Qi Zhang", "Lifu Huang", "Jin-Hee Cho", "Pamela J. Wisniewski", "Sang Won Lee"], "title": "From Vulnerable to Resilient: Examining Parent and Teen Perceptions on How to Respond to Unwanted Cybergrooming Advances", "categories": ["cs.HC", "cs.SI"], "comment": null, "summary": "Cybergrooming is a form of online abuse that threatens teens' mental health and physical safety. Yet, most prior work has focused on detecting perpetrators' behaviors, leaving a limited understanding of how teens might respond to such unwanted advances. To address this gap, we conducted an online survey with 74 participants -- 51 parents and 23 teens -- who responded to simulated cybergrooming scenarios in two ways: responses that they think would make teens more vulnerable or resilient to unwanted sexual advances. Through a mixed-methods analysis, we identified four types of vulnerable responses (encouraging escalation, accepting an advance, displaying vulnerability, and negating risk concern) and four types of protective strategies (setting boundaries, directly declining, signaling risk awareness, and leveraging avoidance techniques). As the cybergrooming risk escalated, both vulnerable responses and protective strategies showed a corresponding progression. This study contributes a teen-centered understanding of cybergrooming, a labeled dataset, and a stage-based taxonomy of perceived protective strategies, while offering implications for educational programs and sociotechnical interventions.", "AI": {"tldr": "本论文通过在线调查研究了家长和青少年对网络诱骗的反应方式，识别出了可能导致脆弱性和保护性的策略。", "motivation": "以往的研究大多关注于检测网络诱骗者的行径，但缺少关于受害者如何应对此类威胁的理解。本文旨在填补这一空白，并提供教育计划和社会技术干预的建议。", "method": "作者通过在线调查收集了74位参与者（51名家长和23名青少年）的数据，他们对模拟的网络诱骗场景作出了回应，以分析可能使受害者更脆弱或更有抵抗力的行为模式。采用混合方法进行数据处理。", "result": "识别出四种可能导致脆弱性的反应类型以及四种保护性策略，并观察到随着风险升级，这两种行为也呈现出相应的变化趋势。", "conclusion": "本研究提供了一个以青少年为中心的网络诱骗理解框架、一个有标注的数据集和一种阶段式的保护性策略分类法。"}}
{"id": "2601.21517", "pdf": "https://arxiv.org/pdf/2601.21517", "abs": "https://arxiv.org/abs/2601.21517", "authors": ["Teerapong Panboonyuen"], "title": "HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models", "categories": ["cs.CV"], "comment": "26 pages", "summary": "Recent advances in text-to-image (T2I) diffusion models have enabled increasingly realistic synthesis of vehicle damage, raising concerns about their reliability in automated insurance workflows. The ability to generate crash-like imagery challenges the boundary between authentic and synthetic data, introducing new risks of misuse in fraud or claim manipulation. To address these issues, we propose HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation), a framework designed to improve fidelity, controllability, and domain alignment of diffusion-generated damage images. HERS fine-tunes a base diffusion model via domain-specific expert adaptation without requiring manual annotation. Using self-supervised image-text pairs automatically generated by a large language model and T2I pipeline, HERS models each damage category, such as dents, scratches, broken lights, or cracked paint, as a separate expert. These experts are later integrated into a unified multi-damage model that balances specialization with generalization. We evaluate HERS across four diffusion backbones and observe consistent improvements: plus 5.5 percent in text faithfulness and plus 2.3 percent in human preference ratings compared to baselines. Beyond image fidelity, we discuss implications for fraud detection, auditability, and safe deployment of generative models in high-stakes domains. Our findings highlight both the opportunities and risks of domain-specific diffusion, underscoring the importance of trustworthy generation in safety-critical applications such as auto insurance.", "AI": {"tldr": "HERS框架通过领域专家适应，改进了扩散模型生成车辆损坏图像的逼真度、可控性和领域一致性。", "motivation": "针对文本到图像扩散模型在自动化保险工作流中的可靠性问题，提出一种无需手动标注即可提高合成损伤图像真实性的方法。", "method": "HERS利用自监督图象-文本对和T2I管道生成的大型语言模型，将每个损坏类别视为独立专家进行训练，并将其整合为一个统一多损伤模型。", "result": "实验表明，HERS在四个扩散基础模型上均有改进：文本忠实度提高5.5％，人类偏好评分提高2.3%。", "conclusion": "研究展示了域特定扩散的优势和风险，强调了在如汽车保险等安全关键应用中生成可信图像的重要性。"}}
{"id": "2601.21511", "pdf": "https://arxiv.org/pdf/2601.21511", "abs": "https://arxiv.org/abs/2601.21511", "authors": ["Niki van Stein", "Anna V. Kononova", "Lars Kotthoff", "Thomas Bäck"], "title": "LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI", "categories": ["cs.AI", "cs.NE", "cs.SE"], "comment": "14 pages", "summary": "Large language models have enabled automated algorithm design (AAD) by generating optimization algorithms directly from natural-language prompts. While evolutionary frameworks such as LLaMEA demonstrate strong exploratory capabilities across the algorithm design space, their search dynamics are entirely driven by fitness feedback, leaving substantial information about the generated code unused. We propose a mechanism for guiding AAD using feedback constructed from graph-theoretic and complexity features extracted from the abstract syntax trees of the generated algorithms, based on a surrogate model learned over an archive of evaluated solutions. Using explainable AI techniques, we identify features that substantially affect performance and translate them into natural-language mutation instructions that steer subsequent LLM-based code generation without restricting expressivity. We propose LLaMEA-SAGE, which integrates this feature-driven guidance into LLaMEA, and evaluate it across several benchmarks. We show that the proposed structured guidance achieves the same performance faster than vanilla LLaMEA in a small controlled experiment. In a larger-scale experiment using the MA-BBOB suite from the GECCO-MA-BBOB competition, our guided approach achieves superior performance compared to state-of-the-art AAD methods. These results demonstrate that signals derived from code can effectively bias LLM-driven algorithm evolution, bridging the gap between code structure and human-understandable performance feedback in automated algorithm design.", "AI": {"tldr": "本文提出了一种通过从生成代码中提取结构反馈来指导自动算法设计的方法，即LLaMEA-SAGE。", "motivation": "传统的自动化算法设计框架主要依赖于适应度反馈进行搜索，而忽略了生成代码的其他有用信息。为了提高算法设计效率和性能，作者提出了结合可解释AI技术的机制，从抽象语法树中提取图论和复杂性特征，并将其转化为自然语言指令来指导后续代码生成。", "method": "通过建立基于已评估解决方案集的代理模型，作者提出了一种利用结构反馈引导自动算法设计的方法。他们使用可解释AI技术识别影响性能的关键特征，并将这些特征翻译成指导下一步LLM驱动代码生成的自然语言突变指令。", "result": "在小规模控制实验中，所提出的结构化指导方法比原始的LLaMEA更快地达到了相同的性能水平；而在大规模实验证明了其优越性，特别是在使用GECCO-MA-BBOB套件时，表现出比现有最佳自动化算法设计方法更优的结果。", "conclusion": "通过从代码中获取信号来引导大型语言模型驱动的算法进化可以有效提升自动算法设计的表现，并且这种方法能够建立代码结构与人类可理解性能反馈之间的桥梁。"}}
{"id": "2601.21506", "pdf": "https://arxiv.org/pdf/2601.21506", "abs": "https://arxiv.org/abs/2601.21506", "authors": ["Joonhee Lee", "Hyunseung Shin", "Jeonggil Ko"], "title": "IROS: A Dual-Process Architecture for Real-Time VLM-Based Indoor Navigation", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Indoor mobile robot navigation requires fast responsiveness and robust semantic understanding, yet existing methods struggle to provide both. Classical geometric approaches such as SLAM offer reliable localization but depend on detailed maps and cannot interpret human-targeted cues (e.g., signs, room numbers) essential for indoor reasoning. Vision-Language-Action (VLA) models introduce semantic grounding but remain strictly reactive, basing decisions only on visible frames and failing to anticipate unseen intersections or reason about distant textual cues. Vision-Language Models (VLMs) provide richer contextual inference but suffer from high computational latency, making them unsuitable for real-time operation on embedded platforms. In this work, we present IROS, a real-time navigation framework that combines VLM-level contextual reasoning with the efficiency of lightweight perceptual modules on low-cost, on-device hardware. Inspired by Dual Process Theory, IROS separates fast reflexive decisions (System One) from slow deliberative reasoning (System Two), invoking the VLM only when necessary. Furthermore, by augmenting compact VLMs with spatial and textual cues, IROS delivers robust, human-like navigation with minimal latency. Across five real-world buildings, IROS improves decision accuracy and reduces latency by 66% compared to continuous VLM-based navigation.", "AI": {"tldr": "本文提出了一种结合视觉语言模型和轻量级感知模块的实时室内导航框架IROS，以实现快速响应与语义理解。", "motivation": "现有方法难以同时满足移动机器人室内导航所需的快速响应能力和丰富的语义理解能力。传统几何方法可靠但不具有语义解读能力；VLA模型能提供语义基础但过于反应式且无法进行前瞻性判断；而视觉语言模型虽具备更丰富的情境推理，但由于计算延迟高而不适用于实时操作。", "method": "IROS框架基于双过程理论分离出快速直觉决策和缓慢深思熟虑的推理，并仅在必要时调用VLM。通过结合紧凑型VLM与空间及文本线索，实现了低延迟的人类般导航表现。", "result": "在五个真实建筑内实验中，IROS相比连续使用VLM导航，在提高决策准确率的同时减少了66%的延迟。", "conclusion": "本文提出了一种实时室内导航框架IROS，结合了视觉语言模型与轻量级感知模块的优势，实现了快速响应和低延迟的人类般导航性能。"}}
{"id": "2601.21505", "pdf": "https://arxiv.org/pdf/2601.21505", "abs": "https://arxiv.org/abs/2601.21505", "authors": ["Diaoulé Diallo", "Katharina Dworatzyk", "Sophie Jentzsch", "Peer Schütt", "Sabine Theis", "Tobias Hecking"], "title": "The Effectiveness of Style Vectors for Steering Large Language Models: A Human Evaluation", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": "ef:IEEE Access 13 (2025) 191443-191457", "summary": "Controlling the behavior of large language models (LLMs) at inference time is essential for aligning outputs with human abilities and safety requirements. \\emph{Activation steering} provides a lightweight alternative to prompt engineering and fine-tuning by directly modifying internal activations to guide generation. This research advances the literature in three significant directions. First, while previous work demonstrated the technical feasibility of steering emotional tone using automated classifiers, this paper presents the first human evaluation of activation steering concerning the emotional tone of LLM outputs, collecting over 7,000 crowd-sourced ratings from 190 participants via Prolific ($n=190$). These ratings assess both perceived emotional intensity and overall text quality. Second, we find strong alignment between human and model-based quality ratings (mean $r=0.776$, range $0.157$--$0.985$), indicating automatic scoring can proxy perceived quality. Moderate steering strengths ($λ\\approx 0.15$) reliably amplify target emotions while preserving comprehensibility, with the strongest effects for disgust ($η_p^2 = 0.616$) and fear ($η_p^2 = 0.540$), and minimal effects for surprise ($η_p^2 = 0.042$). Finally, upgrading from Alpaca to LlaMA-3 yielded more consistent steering with significant effects across emotions and strengths (all $p < 0.001$). Inter-rater reliability was high (ICC $= 0.71$--$0.87$), underscoring the robustness of the findings. These findings support activation-based control as a scalable method for steering LLM behavior across affective dimensions.", "AI": {"tldr": "该论文通过人类评估研究了使用激活引导来控制大型语言模型(LLM)输出情感强度的有效性。", "motivation": "在推理时控制LLM的行为对于确保其输出与人的能力和安全要求一致至关重要。以往的研究主要依赖自动分类器进行测试，但缺乏人类感知的验证。", "method": "通过Prolific平台收集了190名参与者的7,000多次评分，评估激活引导对情感强度和文本质量的影响，并比较人机评价的一致性。", "result": "发现适度的引导强度可以有效放大目标情绪并保持可理解性；从Alpaca到LlaMA-3升级后，模型的控制效果更加一致且显著。人类评分与自动评分高度相关。", "conclusion": "研究结果支持使用激活导向的方法作为在情感维度上控制LLM行为的有效方法，并具有较高的可靠性和一致性。"}}
{"id": "2601.21504", "pdf": "https://arxiv.org/pdf/2601.21504", "abs": "https://arxiv.org/abs/2601.21504", "authors": ["Anna Rothenhäusler", "Markus Mazzola", "Andreas Look", "Raghu Rajan", "Joschka Bödecker"], "title": "Don't double it: Efficient Agent Prediction in Occlusions", "categories": ["cs.RO"], "comment": null, "summary": "Occluded traffic agents pose a significant challenge for autonomous vehicles, as hidden pedestrians or vehicles can appear unexpectedly, yet this problem remains understudied. Existing learning-based methods, while capable of inferring the presence of hidden agents, often produce redundant occupancy predictions where a single agent is identified multiple times. This issue complicates downstream planning and increases computational load. To address this, we introduce MatchInformer, a novel transformer-based approach that builds on the state-of-the-art SceneInformer architecture. Our method improves upon prior work by integrating Hungarian Matching, a state-of-the-art object matching algorithm from object detection, into the training process to enforce a one-to-one correspondence between predictions and ground truth, thereby reducing redundancy. We further refine trajectory forecasts by decoupling an agent's heading from its motion, a strategy that improves the accuracy and interpretability of predicted paths. To better handle class imbalances, we propose using the Matthews Correlation Coefficient (MCC) to evaluate occupancy predictions. By considering all entries in the confusion matrix, MCC provides a robust measure even in sparse or imbalanced scenarios. Experiments on the Waymo Open Motion Dataset demonstrate that our approach improves reasoning about occluded regions and produces more accurate trajectory forecasts than prior methods.", "AI": {"tldr": "本文提出了一种新的基于Transformer的方法MatchInformer，以解决自动驾驶车辆中隐藏的行人或车辆的预测问题，并减少冗余预测。", "motivation": "现有的学习方法虽然能够推断出隐藏代理的存在，但往往会产生重复占用预测，增加了计算负担。为了提高下游规划的质量并降低复杂度，本文旨在通过改进的方法来解决这一挑战。", "method": "MatchInformer基于SceneInformer架构构建，并引入了Hungarian Matching算法以强制一个一对一的映射关系，同时将代理的方向与运动解耦合，提高了预测路径的准确性和可解释性。此外，利用马修斯相关系数（MCC）评估占用预测。", "result": "实验表明MatchInformer能够改善对遮挡区域的理解，并产生比以前的方法更精确的轨迹预测。", "conclusion": "通过改进现有方法，本文提出了一种新的预测技术，有效提升了自动驾驶系统在处理交通代理隐藏问题上的表现。"}}
{"id": "2601.21503", "pdf": "https://arxiv.org/pdf/2601.21503", "abs": "https://arxiv.org/abs/2601.21503", "authors": ["Junhong Cai", "Guiqin Wang", "Kejie Zhao", "Jianxiong Tang", "Xiang Wang", "Luziwei Leng", "Ran Cheng", "Yuxin Ma", "Qinghai Guo"], "title": "MAR: Efficient Large Language Models via Module-aware Architecture Refinement", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE"], "comment": "Accepted by ICASSP 2026. 5 pages, 5 figures", "summary": "Large Language Models (LLMs) excel across diverse domains but suffer from high energy costs due to quadratic attention and dense Feed-Forward Network (FFN) operations. To address these issues, we propose Module-aware Architecture Refinement (MAR), a two-stage framework that integrates State Space Models (SSMs) for linear-time sequence modeling and applies activation sparsification to reduce FFN costs. In addition, to mitigate low information density and temporal mismatch in integrating Spiking Neural Networks (SNNs) with SSMs, we design the Adaptive Ternary Multi-step Neuron (ATMN) and the Spike-aware Bidirectional Distillation Strategy (SBDS). Extensive experiments demonstrate that MAR effectively restores the performance of its dense counterpart under constrained resources while substantially reducing inference energy consumption. Furthermore, it outperforms efficient models of comparable or even larger scale, underscoring its potential for building efficient and practical LLMs.", "AI": {"tldr": "提出了一种针对大规模语言模型的模块感知架构细化框架（MAR），以提高效率并减少能耗。", "motivation": "为了解决大型语言模型由于二次注意力和密集前馈网络操作导致的高能源消耗问题，提出了MAR方法。", "method": "MAR是一种两阶段框架，集成了状态空间模型进行线性时间序列建模，并通过激活稀疏化来降低FFN成本。此外，为了减少与SNN集成时的信息密度低和时间错配的问题，设计了自适应三元多步神经元（ATMN）和脉冲感知双向蒸馏策略（SBDS）。", "result": "实验表明，MAR能够在限制资源的情况下恢复其密集模型性能，并显著降低推理能耗。同时在与同类或更大规模的高效模型相比时表现更优。", "conclusion": "该研究展示了MAR框架在构建高效的大型语言模型方面的潜力。"}}
{"id": "2601.21498", "pdf": "https://arxiv.org/pdf/2601.21498", "abs": "https://arxiv.org/abs/2601.21498", "authors": ["Thanh-Nhan Vo", "Trong-Thuan Nguyen", "Tam V. Nguyen", "Minh-Triet Tran"], "title": "SimGraph: A Unified Framework for Scene Graph-Based Image Generation and Editing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in Generative Artificial Intelligence (GenAI) have significantly enhanced the capabilities of both image generation and editing. However, current approaches often treat these tasks separately, leading to inefficiencies and challenges in maintaining spatial consistency and semantic coherence between generated content and edits. Moreover, a major obstacle is the lack of structured control over object relationships and spatial arrangements. Scene graph-based methods, which represent objects and their interrelationships in a structured format, offer a solution by providing greater control over composition and interactions in both image generation and editing. To address this, we introduce SimGraph, a unified framework that integrates scene graph-based image generation and editing, enabling precise control over object interactions, layouts, and spatial coherence. In particular, our framework integrates token-based generation and diffusion-based editing within a single scene graph-driven model, ensuring high-quality and consistent results. Through extensive experiments, we empirically demonstrate that our approach outperforms existing state-of-the-art methods.", "AI": {"tldr": "介绍SimGraph框架，该框架结合了基于场景图的图像生成和编辑，提高了对象交互、布局和空间一致性的控制精度。", "motivation": "当前的方法通常将图像生成和编辑任务分开处理，导致效率低下且难以保持生成内容与编辑之间的空间一致性及语义连贯性。为了克服这一问题并提供对物体关系的结构化控制，提出了SimGraph框架。", "method": "SimGraph整合了基于标记的生成技术和扩散式编辑技术，在一个场景图驱动的模型中统一处理图像生成和编辑任务，确保高质量且一致的结果。", "result": "实验结果表明该方法在性能上优于现有最先进的方法。", "conclusion": "SimGraph框架通过结合基于场景图的方法来增强图像生成和编辑的一致性和连贯性，并展示了优越的性能。"}}
{"id": "2601.21494", "pdf": "https://arxiv.org/pdf/2601.21494", "abs": "https://arxiv.org/abs/2601.21494", "authors": ["Ishan Jindal", "Sai Prashanth Akuthota", "Jayant Taneja", "Sachin Dev Sharma"], "title": "The Path of Least Resistance: Guiding LLM Reasining Trajectories with Prefix Consensus", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted at ICLR 2026. https://openreview.net/forum?id=hrnSqERgPn", "summary": "Large language models achieve strong reasoning performance, but inference strategies such as Self-Consistency (SC) are computationally expensive, as they fully expand all reasoning traces. We introduce PoLR (Path of Least Resistance), the first inference-time method to leverage prefix consistency for compute-efficient reasoning. PoLR clusters short prefixes of reasoning traces, identifies the dominant cluster, and expands all paths in that cluster, preserving the accuracy benefits of SC while substantially reducing token usage and latency. Our theoretical analysis, framed via mutual information and entropy, explains why early reasoning steps encode strong signals predictive of final correctness. Empirically, PoLR consistently matches or exceeds SC across GSM8K, MATH500, AIME24/25, and GPQA-DIAMOND, reducing token usage by up to 60% and wall-clock latency by up to 50%. Moreover, PoLR is fully complementary to adaptive inference methods (e.g., Adaptive Consistency, Early-Stopping SC) and can serve as a drop-in pre-filter, making SC substantially more efficient and scalable without requiring model fine-tuning.", "AI": {"tldr": "该论文提出了一种称为PoLR的新推理方法，用于在大型语言模型的推理过程中节省计算资源。", "motivation": "现有的推理策略如自一致性（Self-Consistency）虽然准确度高，但计算成本很高。因此需要一种新的方法来提高效率并减少延迟和令牌使用量。", "method": "PoLR通过利用前缀的一致性来进行高效推理：首先对短的推理前缀进行聚类，然后选择主要的簇，并仅扩展该簇中的所有路径。这种方法在保证准确性的同时显著减少了资源消耗。", "result": "实验结果表明，PoLR能够匹配甚至超过自一致性方法的表现，在多个数据集上减少令牌使用量高达60%，延迟降低最多50%。", "conclusion": "PoLR是一种新颖且高效的推理策略，可以在不损失准确性的前提下大幅节省计算资源。"}}
{"id": "2601.21492", "pdf": "https://arxiv.org/pdf/2601.21492", "abs": "https://arxiv.org/abs/2601.21492", "authors": ["Thomas Herrmann"], "title": "Organizational Practices and Socio-Technical Design of Human-Centered AI", "categories": ["cs.HC"], "comment": "29 pages, 3 figures, 1 table, Published in: Wei Xu, (Ed.) 2026, Handbook of Human-Centered Artificial Intelligence, pp 1-45, Springe Nature Singapore", "summary": "This contribution explores how the integration of Artificial Intelligence (AI) into organizational practices can be effectively framed through a socio-technical perspective to comply with the requirements of Human-centered AI (HCAI). Instead of viewing AI merely as a technical tool, the analysis emphasizes the importance of embedding AI into communication, collaboration, and decision-making processes within organizations from a human-centered perspective. Ten case-based patterns illustrate how AI support of predictive maintenance can be organized to address quality assurance and continuous improvement and to provide different types of sup-port for HCAI. The analysis shows that AI adoption often requires and enables new forms of organizational learning, where specialists jointly interpret AI output, adapt workflows, and refine rules for system improve-ment. Different dimensions and levels of socio-technical integration of AI are considered to reflect the effort and benefits of keeping the organization in the loop.", "AI": {"tldr": "探讨了从社会技术视角将人工智能（AI）集成到组织实践中，以满足以人为中心的人工智能（HCAI）的需求。", "motivation": "强调在组织内部从以人为本的角度将AI嵌入沟通、协作和决策过程中，而不是仅仅将其视为一种工具。分析表明，AI的采用通常需要并促进了新的形式的组织学习。", "method": "通过十个基于案例模式来展示如何组织人工智能支持的预测性维护以解决质量保证和持续改进，并提供不同类型的HCAI支持。", "result": "展示了将AI集成到组织实践中可以带来新形式的学习机会，例如专家共同解释AI输出、调整工作流程和细化系统改进规则等方面的好处。", "conclusion": "考虑了不同维度和社会技术整合的水平，反映了保持组织参与的努力和好处。"}}
{"id": "2601.21490", "pdf": "https://arxiv.org/pdf/2601.21490", "abs": "https://arxiv.org/abs/2601.21490", "authors": ["Fabian Albers", "Sebastian Strauß", "Nikol Rummel", "Nils Köbis"], "title": "Are they just delegating? Cross-Sample Predictions on University Students' & Teachers' Use of AI", "categories": ["cs.HC"], "comment": "27 pages, 5 figures", "summary": "Mutual trust between teachers and students is a prerequisite for effective teaching, learning, and assessment in higher education. Accurate predictions about the other group's use of generative artificial intelligence (AI) are fundamental for such trust. However, the disruptive rise of AI has transformed academic work practices, raising important questions about how teachers and students use these tools and how well they can estimate each other's usage. While the frequency of use is well studied, little is known about how AI is used, and comparisons with similar practices are rare. This study surveyed German university teachers (N = 113) and students (N = 123) on the frequency of AI use and the degree of delegation across six identical academic tasks. Participants also provided incentivized cross-sample predictions of the other group's AI use to assess the accuracy of their predictions. We find that students reported higher use of AI and greater delegation than teachers. Both groups significantly overestimated the other group's use, with teachers predicting very frequent use and high delegation by students, and students assuming teachers use AI similarly to themselves. These findings reveal a perception gap between teachers' and students' expectations and actual AI use. Such gaps may hinder trust and effective collaboration, underscoring the need for open dialogue about AI practices in academia and for policies that support the equitable and transparent integration of AI tools in higher education.", "AI": {"tldr": "该研究通过调查德国大学师生关于AI使用的频率和任务委托程度，探讨双方对彼此使用AI的预测准确性。", "motivation": "在高等教育中建立教师与学生之间的信任是有效教学、学习和评估的前提。准确地预测对方如何使用生成性人工智能工具对于这种信任至关重要。然而，随着AI技术的发展，这种互信面临挑战。研究旨在填补关于师生实际使用AI情况及其彼此预测偏差的空白。", "method": "研究人员对德国大学教师（113名）和学生（123名）进行了调查，要求他们报告在六项相同学术任务中使用AI的频率及委托程度，并对另一群体的行为进行激励性预测以评估准确性。", "result": "研究发现，与教师相比，学生报告了更高的AI使用频率以及更多的任务委托；两者都显著高估了对方使用的频率和委托程度。", "conclusion": "这些发现揭示了师生之间对于彼此实际使用人工智能工具的期望差距，这种感知差距可能阻碍信任建立及有效协作，强调了在学术界开放讨论AI实践的重要性，并制定支持公平透明地整合AI工具于高等教育中的政策"}}
{"id": "2601.21481", "pdf": "https://arxiv.org/pdf/2601.21481", "abs": "https://arxiv.org/abs/2601.21481", "authors": ["Sai Pavan Deram", "Jacopo Pegoraro", "Javier Lorca Hernando", "Jesus O. Lacruz", "Joerg Widmer"], "title": "Compressed Sensing-Driven Near-Field Localization Exploiting Array of Subarrays", "categories": ["eess.SP", "cs.ET"], "comment": "Accepted in IEEE International Conference on Communications 2026 for Signal Processing for Communications Track", "summary": "Near-field localization for ISAC requires large-aperture arrays, making fully-digital implementations prohibitively complex and costly. While sparse subarray architectures can reduce cost, they introduce severe estimation ambiguity from grating lobes. To address both issues, we propose SHARE (Sparse Hierarchical Angle-Range Estimation), a novel two-stage sparse recovery algorithm. SHARE operates in two stages. It first performs coarse, unambiguous angle estimation using individual subarrays to resolve the grating lobe ambiguity. It then leverages the full sparse aperture to perform a localized joint angle-range search. This hierarchical approach avoids an exhaustive and computationally intensive two-dimensional grid search while preserving the high resolution of the large aperture. Simulation results show that SHARE significantly outperforms conventional one-shot sparse recovery methods, such as Orthogonal Matching Pursuit (OMP), in both localization accuracy and robustness. Furthermore, we show that SHARE's overall localization accuracy is comparable to or even surpasses that of the fully-digital 2D-MUSIC algorithm, despite MUSIC having access to the complete, uncompressed data from every antenna element. SHARE therefore provides a practical path for high-resolution near-field ISAC systems.", "AI": {"tldr": "本文提出了一种新的两阶段稀疏恢复算法SHARE，用于解决近场定位中的角度范围估计问题。", "motivation": "大型孔径阵列对于ISAC的近场定位至关重要，但完全数字化实现复杂且昂贵。虽然稀疏子阵架构可以降低成本，但它引入了严重的估计模糊性。为此，本文提出了一种新的方法来解决这些问题。", "method": "SHARE算法分为两个阶段：首先使用单独的子阵进行粗略、无歧义的角度估计以解决衍射栅瓣模糊问题；然后利用整个稀疏孔径执行局部联合角度范围搜索。", "result": "模拟结果表明，SHARE在定位精度和鲁棒性方面显著优于传统的单次稀疏恢复方法，如正交匹配追踪(OMP)，并且其整体定位精度可以与完全数字的二维MUSIC算法相媲美或甚至更好。", "conclusion": "SHARE为高分辨率近场ISAC系统提供了一条实用路径。"}}
{"id": "2601.21479", "pdf": "https://arxiv.org/pdf/2601.21479", "abs": "https://arxiv.org/abs/2601.21479", "authors": ["Kaito Shiku", "Ichika Seo", "Tetsuya Matoba", "Rissei Hino", "Yasuhiro Nakano", "Ryoma Bise"], "title": "Hypernetwork-Based Adaptive Aggregation for Multimodal Multiple-Instance Learning in Predicting Coronary Calcium Debulking", "categories": ["cs.CV"], "comment": "Accepted to ISBI 2026", "summary": "In this paper, we present the first attempt to estimate the necessity of debulking coronary artery calcifications from computed tomography (CT) images. We formulate this task as a Multiple-instance Learning (MIL) problem. The difficulty of this task lies in that physicians adjust their focus and decision criteria for device usage according to tabular data representing each patient's condition. To address this issue, we propose a hypernetwork-based adaptive aggregation transformer (HyperAdAgFormer), which adaptively modifies the feature aggregation strategy for each patient based on tabular data through a hypernetwork. The experiments using the clinical dataset demonstrated the effectiveness of HyperAdAgFormer. The code is publicly available at https://github.com/Shiku-Kaito/HyperAdAgFormer.", "AI": {"tldr": "通过CT图像预测冠状动脉钙化是否需要去脂处理，将此任务定义为多重实例学习问题。", "motivation": "医生根据每个患者的表格数据调整对设备使用的关注点和决策标准，为此提出了适应性特征聚合方法。", "method": "提出了一种基于超网络的自适应聚合变换器（HyperAdAgFormer），该方法通过超网络根据表单数据自适应地修改每名患者的功能聚合策略。", "result": "临床数据集上的实验表明，所提模型有效提升了预测准确性。", "conclusion": "所提出的HyperAdAgFormer在解决冠状动脉钙化去脂预测任务上取得了显著的效果。"}}
{"id": "2601.21477", "pdf": "https://arxiv.org/pdf/2601.21477", "abs": "https://arxiv.org/abs/2601.21477", "authors": ["Tobias Schmidt", "Kai Cui"], "title": "Mean-Field Control on Sparse Graphs: From Local Limits to GNNs via Neighborhood Distributions", "categories": ["cs.MA", "cs.AI", "cs.LG", "math.OC"], "comment": "19 pages", "summary": "Mean-field control (MFC) offers a scalable solution to the curse of dimensionality in multi-agent systems but traditionally hinges on the restrictive assumption of exchangeability via dense, all-to-all interactions. In this work, we bridge the gap to real-world network structures by proposing a rigorous framework for MFC on large sparse graphs. We redefine the system state as a probability measure over decorated rooted neighborhoods, effectively capturing local heterogeneity. Our central contribution is a theoretical foundation for scalable reinforcement learning in this setting. We prove horizon-dependent locality: for finite-horizon problems, an agent's optimal policy at time t depends strictly on its (T-t)-hop neighborhood. This result renders the infinite-dimensional control problem tractable and underpins a novel Dynamic Programming Principle (DPP) on the lifted space of neighborhood distributions. Furthermore, we formally and experimentally justify the use of Graph Neural Networks (GNNs) for actor-critic algorithms in this context. Our framework naturally recovers classical MFC as a degenerate case while enabling efficient, theoretically grounded control on complex sparse topologies.", "AI": {"tldr": "本文提出了在稀疏图上进行均值场控制的理论框架，通过重新定义系统状态为概率测度下的装饰根邻居分布，解决了传统方法对全连通网络依赖的问题。", "motivation": "为了克服多智能体系统中维度诅咒问题，并将均值场控制扩展到真实的稀疏网络结构上，本文提出了一个严谨的理论框架。", "method": "重新定义了系统的状态作为概率测度下的装饰根邻居分布，证明了有限时间内的局部性定理，并提出了一种基于提升空间的动态规划原理（DPP）来处理无限维控制问题。此外，还通过形式化和实验验证了在这一背景下使用图神经网络（GNN）的有效性。", "result": "证明了在一个特定时间内，智能体的最佳策略仅依赖于其邻居分布，这使得原本复杂的控制问题变得可解，并且成功地应用了GNN来解决该问题。", "conclusion": "本文提出的框架不仅恢复了传统均值场控制的退化情况，而且能够有效地在复杂稀疏网络上实现理论上可靠的控制。"}}
{"id": "2601.21475", "pdf": "https://arxiv.org/pdf/2601.21475", "abs": "https://arxiv.org/abs/2601.21475", "authors": ["Chao Wang", "Licheng Jiao", "Lingling Li", "Jiaxuan Zhao", "Guanchun Wang", "Fang Liu", "Shuyuan Yang"], "title": "Task-free Adaptive Meta Black-box Optimization", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "This article was published as a conference paper at ICLR 2026", "summary": "Handcrafted optimizers become prohibitively inefficient for complex black-box optimization (BBO) tasks. MetaBBO addresses this challenge by meta-learning to automatically configure optimizers for low-level BBO tasks, thereby eliminating heuristic dependencies. However, existing methods typically require extensive handcrafted training tasks to learn meta-strategies that generalize to target tasks, which poses a critical limitation for realistic applications with unknown task distributions. To overcome the issue, we propose the Adaptive meta Black-box Optimization Model (ABOM), which performs online parameter adaptation using solely optimization data from the target task, obviating the need for predefined task distributions. Unlike conventional metaBBO frameworks that decouple meta-training and optimization phases, ABOM introduces a closed-loop adaptive parameter learning mechanism, where parameterized evolutionary operators continuously self-update by leveraging generated populations during optimization. This paradigm shift enables zero-shot optimization: ABOM achieves competitive performance on synthetic BBO benchmarks and realistic unmanned aerial vehicle path planning problems without any handcrafted training tasks. Visualization studies reveal that parameterized evolutionary operators exhibit statistically significant search patterns, including natural selection and genetic recombination.", "AI": {"tldr": "本文提出了一种适应性元黑盒优化模型(ABOM)，该模型在不预先定义任务分布的情况下，仅通过目标任务的优化数据进行在线参数自适应调整，实现了零样本优化。", "motivation": "现有的元黑盒优化方法需要大量的手工定制训练任务来学习适用于目标任务的元策略，这限制了其在未知任务分布的实际应用中的有效性。为了克服这一问题，本文提出了ABOM模型。", "method": "ABOM通过引入封闭循环自适应参数学习机制，使参数化的进化操作符能够在优化过程中利用生成的人群进行自我更新，从而实现了仅基于目标任务数据的在线参数调整。", "result": "实验结果显示，ABOM在合成黑盒优化基准和实际无人飞行器路径规划问题上均表现出了竞争力，并且能够展示出显著的搜索模式，如自然选择和基因重组。", "conclusion": "本文提出的ABOM模型通过在线自适应参数学习机制实现了零样本优化，在不依赖任何手工定制训练任务的情况下达到了优异的表现。"}}
{"id": "2601.21474", "pdf": "https://arxiv.org/pdf/2601.21474", "abs": "https://arxiv.org/abs/2601.21474", "authors": ["Xingyu Zhang", "Chaofan Zhang", "Boyue Zhang", "Zhinan Peng", "Shaowei Cui", "Shuo Wang"], "title": "DexTac: Learning Contact-aware Visuotactile Policies via Hand-by-hand Teaching", "categories": ["cs.RO"], "comment": null, "summary": "For contact-intensive tasks, the ability to generate policies that produce comprehensive tactile-aware motions is essential. However, existing data collection and skill learning systems for dexterous manipulation often suffer from low-dimensional tactile information. To address this limitation, we propose DexTac, a visuo-tactile manipulation learning framework based on kinesthetic teaching. DexTac captures multi-dimensional tactile data-including contact force distributions and spatial contact regions-directly from human demonstrations. By integrating these rich tactile modalities into a policy network, the resulting contact-aware agent enables a dexterous hand to autonomously select and maintain optimal contact regions during complex interactions. We evaluate our framework on a challenging unimanual injection task. Experimental results demonstrate that DexTac achieves a 91.67% success rate. Notably, in high-precision scenarios involving small-scale syringes, our approach outperforms force-only baselines by 31.67%. These results underscore that learning multi-dimensional tactile priors from human demonstrations is critical for achieving robust, human-like dexterous manipulation in contact-rich environments.", "AI": {"tldr": "DexTac是一个基于人工示范的触觉学习框架，通过集成多维度触觉数据来生成接触感知策略，实现复杂的精细操作任务。", "motivation": "现有灵巧抓取技能学习系统在处理低维触觉信息时效果不佳，本文提出了一种结合多维度触觉模态的数据收集和技能学习方法以解决该问题。", "method": "DexTac框架通过人工示范直接从人类操作中捕获接触力分布及空间接触区域等多维度触觉数据，并将其集成到策略网络中。", "result": "实验结果显示，对于挑战性的单手注射任务，DexTac达到了91.67%的成功率。特别是在处理小规模针头的高精度场景下，优于仅使用力反馈的方法31.67%。", "conclusion": "学习多维度触觉先验知识对于在接触密集环境中实现稳健、类似人类的灵巧操作至关重要。"}}
{"id": "2601.21473", "pdf": "https://arxiv.org/pdf/2601.21473", "abs": "https://arxiv.org/abs/2601.21473", "authors": ["Zaifeng Pan", "Yipeng Shen", "Zhengding Hu", "Zhuang Wang", "Aninda Manocha", "Zheng Wang", "Zhongkai Yu", "Yue Guan", "Yufei Ding"], "title": "ScaleSim: Serving Large-Scale Multi-Agent Simulation with Invocation Distance-Based Memory Management", "categories": ["cs.AI", "cs.DC"], "comment": null, "summary": "LLM-based multi-agent simulations are increasingly adopted across application domains, but remain difficult to scale due to GPU memory pressure. Each agent maintains private GPU-resident states, including models, prefix caches, and adapters, which quickly exhaust device memory as the agent count grows. We identify two key properties of these workloads: sparse agent activation and an estimable agent invocation order. Based on an analysis of representative workload classes, we introduce invocation distance, a unified abstraction that estimates the relative order in which agents will issue future LLM requests. Leveraging this abstraction, we present ScaleSim, a memory-efficient LLM serving system for large-scale multi-agent simulations. ScaleSim enables proactive prefetching and priority-based eviction, supports diverse agent-specific memory through a modular interface, and achieves up to 1.74x speedup over SGLang on simulation benchmarks.", "AI": {"tldr": "ScaleSim是为大规模多智能体模拟设计的一种内存效率高的LLM服务系统，解决了GPU内存压力问题。", "motivation": "基于大容量语言模型的多智能体模拟在各个应用领域中越来越受欢迎，但由于每个代理维护大量的本地GPU状态，导致随着代理数量的增长设备内存迅速耗尽。", "method": "提出了\"调用距离\"的概念来估计未来LLM请求的相对顺序，并利用这一抽象实现了ScaleSim系统。该系统支持主动预取和优先级基线驱逐策略，并通过模块化接口支持多样化的智能体特定内存。", "result": "在模拟基准测试中，ScaleSim比SGLang快1.74倍。", "conclusion": "ScaleSim能够有效地管理和优化大规模多智能体模拟中的GPU内存使用情况。"}}
{"id": "2601.21469", "pdf": "https://arxiv.org/pdf/2601.21469", "abs": "https://arxiv.org/abs/2601.21469", "authors": ["Haoji Zhang", "Yuzhe Li", "Zhenqiang Liu", "Chenyang Liu", "Shenyang Zhang", "Yi Zhou"], "title": "Adaptive Confidence Gating in Multi-Agent Collaboration for Efficient and Optimized Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "While Large Language Models (LLMs) have catalyzed breakthroughs in automated code generation, Small Language Models (SLMs) often encounter reasoning bottlenecks and failure loops when addressing complex logical requirements. To overcome these challenges, we propose DebateCoder, a multi-agent collaborative framework designed to improve the reasoning ability of SLMs (e.g., Pangu-1B) in resource-constrained environments. DebateCoder uses a structured role-playing protocol with three agents: User Agent (A_UA), Technical Agent (A_TA), and Quality Assurance Agent (A_QA). It also includes an Adaptive Confidence Gating mechanism with a 95% threshold to balance accuracy and inference efficiency. In addition, we introduce a multi-turn deliberation module and a reviewer-guided analytical debugging loop for orthogonal pre-generation debate and post-generation refinement. Experiments on HumanEval and MBPP show that DebateCoder achieves 70.12% Pass@1 on HumanEval, outperforming MapCoder while reducing API overhead by about 35%. These results indicate that collaborative protocols can mitigate limitations of small-parameter models and provide a scalable, efficient approach to high-quality automated software engineering.", "AI": {"tldr": "本文提出了一个名为DebateCoder的多代理协作框架，用于在资源受限环境中提高小型语言模型（SLM）如Pangu-1B的代码生成能力。", "motivation": "大型语言模型（LLMs）在自动代码生成方面取得了重大突破，但小型语言模型（SLMs）在处理复杂逻辑需求时遇到了推理瓶颈和失败循环。本文旨在通过多代理协作框架解决这些问题。", "method": "DebateCoder采用结构化的角色扮演协议，包括用户代理、技术代理和质量保证代理，并包含自适应置信度门控机制以平衡准确性和推断效率。此外还引入了多轮讨论模块和审查指导分析调试循环。", "result": "在HumanEval和MBPP数据集上的实验表明，DebateCoder实现了70.12%的Pass@1性能，超过了MapCoder，并将API开销减少了约35%", "conclusion": "结果证明协作协议可以减轻小型参数模型的局限性，并提供一种高效且可扩展的方法来实现高质量的自动软件工程。"}}
{"id": "2601.21468", "pdf": "https://arxiv.org/pdf/2601.21468", "abs": "https://arxiv.org/abs/2601.21468", "authors": ["Yaorui Shi", "Shugui Liu", "Yu Yang", "Wenyu Mao", "Yuxin Chen", "Qi GU", "Hui Su", "Xunliang Cai", "Xiang Wang", "An Zhang"], "title": "MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Long-horizon agentic reasoning necessitates effectively compressing growing interaction histories into a limited context window. Most existing memory systems serialize history as text, where token-level cost is uniform and scales linearly with length, often spending scarce budget on low-value details. To this end, we introduce MemOCR, a multimodal memory agent that improves long-horizon reasoning under tight context budgets by allocating memory space with adaptive information density through visual layout. Concretely, MemOCR maintains a structured rich-text memory (e.g., headings, highlights) and renders it into an image that the agent consults for memory access, visually prioritizing crucial evidence while aggressively compressing auxiliary details. To ensure robustness across varying memory budgets, we train MemOCR with reinforcement learning under budget-aware objectives that expose the agent to diverse compression levels. Across long-context multi-hop and single-hop question-answering benchmarks, MemOCR outperforms strong text-based baselines and achieves more effective context utilization under extreme budgets.", "AI": {"tldr": "MemOCR是一个多模态记忆代理，通过视觉布局调整信息密度来优化长时域推理。", "motivation": "现有的记忆系统在处理长时域交互历史时效率低下，因为它们以线性方式序列化文本，并且无法有效分配稀缺的上下文预算。因此，论文提出了MemOCR来提高紧缩上下文预算下的长时间推理能力。", "method": "MemOCR保持结构化的富文本内存并通过将其渲染为图像来进行记忆访问，视觉上优先处理关键证据并压缩辅助细节。通过具有预算感知目标的强化学习训练MemOCR以适应不同的压缩水平。", "result": "在长期上下文跳跃和单跳问答基准测试中，MemOCR超过了强大的基于文本的基础模型，并且在极端预算下实现了更有效的上下文利用。", "conclusion": "通过视觉布局优化信息密度，MemOCR能够在有限的上下文预算内显著提高长时间推理的效率。"}}
{"id": "2601.21465", "pdf": "https://arxiv.org/pdf/2601.21465", "abs": "https://arxiv.org/abs/2601.21465", "authors": ["Márton Kardos"], "title": "Topeax -- An Improved Clustering Topic Model with Density Peak Detection and Lexical-Semantic Term Importance", "categories": ["cs.AI", "cs.CL"], "comment": "14 pages, 6 figures", "summary": "Text clustering is today the most popular paradigm for topic modelling, both in academia and industry. Despite clustering topic models' apparent success, we identify a number of issues in Top2Vec and BERTopic, which remain largely unsolved. Firstly, these approaches are unreliable at discovering natural clusters in corpora, due to extreme sensitivity to sample size and hyperparameters, the default values of which result in suboptimal behaviour. Secondly, when estimating term importance, BERTopic ignores the semantic distance of keywords to topic vectors, while Top2Vec ignores word counts in the corpus. This results in, on the one hand, less coherent topics due to the presence of stop words and junk words, and lack of variety and trust on the other. In this paper, I introduce a new approach, \\textbf{Topeax}, which discovers the number of clusters from peaks in density estimates, and combines lexical and semantic indices of term importance to gain high-quality topic keywords. Topeax is demonstrated to be better at both cluster recovery and cluster description than Top2Vec and BERTopic, while also exhibiting less erratic behaviour in response to changing sample size and hyperparameters.", "AI": {"tldr": "介绍一种名为Topeax的新方法，该方法利用密度峰值检测确定聚类数目，并结合词典和语义指标来提高主题关键词的质量。", "motivation": "现有文本聚类模型（如Top2Vec和BERTopic）在发现自然群集、估计词汇重要性方面存在不足，导致生成的主题不连贯且缺乏多样性。作者希望通过改进这些方法以解决这些问题。", "method": "Topeax通过密度峰值检测确定最佳的聚类数目，并综合使用词频与语义距离来评估词汇的重要性，从而提高主题质量。", "result": "实验结果显示，Topeax在恢复集群和描述集群方面优于Top2Vec和BERTopic，且对样本量及超参数变化更加稳健。", "conclusion": "提出了一个新的文本聚类方法Topeax，该方法能更准确地发现自然群集，并生成高质量的主题关键词。"}}
{"id": "2601.21464", "pdf": "https://arxiv.org/pdf/2601.21464", "abs": "https://arxiv.org/abs/2601.21464", "authors": ["Yuan Sui", "Bryan Hooi"], "title": "Conversation for Non-verifiable Learning: Self-Evolving LLMs through Meta-Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "Work in Progress", "summary": "Training large language models (LLMs) for non-verifiable tasks, such as creative writing, dialogue, and ethical reasoning, remains challenging due to the absence of ground-truth labels. While LLM-as-Judge approaches offer a scalable alternative to human feedback, they face a fundamental limitation: performance is constrained by the evaluator's own quality. If the judge cannot recognize good solutions, it cannot provide useful training signals, and evaluation biases (e.g., favoring verbosity over quality) remain unaddressed. This motivates meta-evaluation: the ability to evaluate and improve the evaluator itself. We introduce CoNL, a framework that unifies generation, evaluation, and meta-evaluation through multi-agent self-play. Our key insight: critique quality can be measured by whether it helps others improve their solutions. In CoNL, multiple agents sharing the same policy engage in structured conversations to propose, critique, and revise solutions. Critiques that enable solution improvements earn a diagnostic reward, creating explicit supervision for meta-evaluation and enabling joint optimization of generation and judging capabilities through self-play, without external judges or ground truth. Experiments on five benchmarks show that CoNL achieves consistent improvements over self-rewarding baselines while maintaining stable training.", "AI": {"tldr": "该论文提出了一个名为CoNL的框架，用于训练大型语言模型以执行非验证性任务。", "motivation": "由于缺乏地面实况标签，使用大型语言模型进行如创意写作、对话和伦理推理等非验证性任务极具挑战。现有的LLM作为裁判的方法虽然提供了一个可扩展的人类反馈替代方案，但受限于评估者的质量，并不能解决评估偏见问题。", "method": "CoNL框架通过多代理自博弈统一了生成、评估与元评估过程。多个共享同一策略的代理参与结构化对话，提出建议并进行改进。评判的质量由其能否帮助其他代理人提升解决方案来衡量，这为元评估提供了显式监督。", "result": "实验在五个基准测试上证明，CoNL相较于自我奖励基线获得了持续性改进，并保持了稳定的训练过程。", "conclusion": "通过自博弈和结构化对话，CoNL框架成功地优化了生成和评判能力，而无需外部裁判或地面实况。"}}
{"id": "2601.21463", "pdf": "https://arxiv.org/pdf/2601.21463", "abs": "https://arxiv.org/abs/2601.21463", "authors": ["Jun Xue", "Yi Chai", "Yanzhen Ren", "Jinshen He", "Zhiqiang Tang", "Zhuolin Yi", "Yihuan Huang", "Yuankun Xie", "Yujie Chen"], "title": "Unifying Speech Editing Detection and Content Localization via Prior-Enhanced Audio LLMs", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Speech editing achieves semantic inversion by performing fine-grained segment-level manipulation on original utterances, while preserving global perceptual naturalness. Existing detection studies mainly focus on manually edited speech with explicit splicing artifacts, and therefore struggle to cope with emerging end-to-end neural speech editing techniques that generate seamless acoustic transitions. To address this challenge, we first construct a large-scale bilingual dataset, AiEdit, which leverages large language models to drive precise semantic tampering logic and employs multiple advanced neural speech editing methods for data synthesis, thereby filling the gap of high-quality speech editing datasets. Building upon this foundation, we propose PELM (Prior-Enhanced Audio Large Language Model), the first large-model framework that unifies speech editing detection and content localization by formulating them as an audio question answering task. To mitigate the inherent forgery bias and semantic-priority bias observed in existing audio large models, PELM incorporates word-level probability priors to provide explicit acoustic cues, and further designs a centroid-aggregation-based acoustic consistency perception loss to explicitly enforce the modeling of subtle local distribution anomalies. Extensive experimental results demonstrate that PELM significantly outperforms state-of-the-art methods on both the HumanEdit and AiEdit datasets, achieving equal error rates (EER) of 0.57\\% and 9.28\\% (localization), respectively.", "AI": {"tldr": "本文提出了一种新的模型PELM，用于统一语音编辑检测和内容定位。", "motivation": "现有的语音编辑检测研究主要针对带有明显拼接痕迹的手工编辑的音频，难以应对无缝过渡的端到端神经语音编辑技术。为解决这一问题，文章构建了大规模双语数据集AiEdit，并提出了PELM模型以应对挑战。", "method": "通过将语音编辑检测和内容定位作为音频问答任务来统一处理，并在大型语言模型中加入词级概率先验以提供明确的声学线索，同时设计了一种基于中心聚集的声学一致性感知损失函数。", "result": "PELM在HumanEdit和AiEdit数据集上的实验结果表明，在语音编辑检测方面优于现有方法，取得了0.57%的等误率；在内容定位上则达到了9.28%的结果。", "conclusion": "通过构建大规模语音编辑数据集并提出统一处理模型PELM，文章解决了新兴端到端神经语音编辑技术带来的挑战，并显著提高了检测和定位性能。"}}
{"id": "2601.21461", "pdf": "https://arxiv.org/pdf/2601.21461", "abs": "https://arxiv.org/abs/2601.21461", "authors": ["Albert Tseng", "Christopher De Sa"], "title": "L$^3$: Large Lookup Layers", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Modern sparse language models typically achieve sparsity through Mixture-of-Experts (MoE) layers, which dynamically route tokens to dense MLP \"experts.\" However, dynamic hard routing has a number of drawbacks, such as potentially poor hardware efficiency and needing auxiliary losses for stable training. In contrast, the tokenizer embedding table, which is natively sparse, largely avoids these issues by selecting a single embedding per token at the cost of not having contextual information. In this work, we introduce the Large Lookup Layer (L$^3$), which unlocks a new axis of sparsity by generalizing embedding tables to model decoder layers. L$^3$ layers use static token-based routing to aggregate a set of learned embeddings per token in a context-dependent way, allowing the model to efficiently balance memory and compute by caching information in embeddings. L$^3$ has two main components: (1) a systems-friendly architecture that allows for fast training and CPU-offloaded inference with no overhead, and (2) an information-theoretic embedding allocation algorithm that effectively balances speed and quality. We empirically test L$^3$ by training transformers with up to 2.6B active parameters and find that L$^3$ strongly outperforms both dense models and iso-sparse MoEs in both language modeling and downstream tasks.", "AI": {"tldr": "本文介绍了一种名为Large Lookup Layer (L$^3$)的新技术，通过静态令牌路由来提高语言模型的稀疏性。", "motivation": "现有稀疏语言模型通常采用Mixture-of-Experts (MoE)层动态分配令牌到密集MLP“专家”中。然而这种方法存在硬件效率低和需要辅助损失以稳定训练等问题。本文提出了一种新的方法来解决这些问题，通过静态路由选择每个令牌的单个嵌入。", "method": "L$^3$由两个主要部分组成：一种系统友好的架构，允许快速培训和无额外开销的CPU卸载推理；以及一个信息论嵌入分配算法，有效地平衡速度和质量。L$^3$解锁了一种新的稀疏性维度，通过将嵌入表扩展到模型解码器层来实现。", "result": "实验结果显示，L$^3$在语言建模和下游任务中均优于同等参数量的密集模型和MoE模型。", "conclusion": "该方法不仅提高了性能，还提供了更好的硬件效率，且无需额外损失函数辅助。"}}
{"id": "2601.21460", "pdf": "https://arxiv.org/pdf/2601.21460", "abs": "https://arxiv.org/abs/2601.21460", "authors": ["Suifang Zhou", "Qi Gong", "Ximing Shen", "RAY LC"], "title": "Tell Me What I Missed: Tell Me What I Missed: Interacting with GPT during Recalling of One-Time Witnessed Events", "categories": ["cs.HC"], "comment": "19 pages, 9 figures, CHI 2026", "summary": "LLM-assisted technologies are increasingly used to support cognitive processing and information interpretation, yet their role in aiding memory recall, and how people choose to engage with them, remains underexplored. We studied participants who watched a short robbery video (approximating a one-time eyewitness scenario) and composed recall statements using either a default GPT or a guided GPT prompted with a standardized eyewitness protocol. Results show that, in the default condition, participants who believed they had a clearer understanding of the event were more likely to trust GPT's output, whereas in the guided condition, participants showed stronger alignment between subjective clarity and actual recall. Additionally, participants evaluated the legitimacy of the individuals in the incident differently across conditions. Interaction analysis further revealed that default-GPT users spontaneously developed diverse strategies, including building on existing recollections, requesting potentially missing details, and treating GPT as a recall coach. This work shows how GPT-user interplay can subconsciously shape beliefs and perceptions of remembered events.", "AI": {"tldr": "研究参与者观看抢劫视频并使用默认GPT或引导式GPT生成回忆陈述，探讨LLM在记忆召回中的作用。", "motivation": "探索大语言模型（LLM）辅助技术如何支持认知处理和信息解读，特别是在帮助记忆回溯方面的角色以及人们如何选择与之互动。", "method": "参与者观看抢劫视频后，使用默认GPT或引导式GPT生成回忆陈述。引导式GPT以标准目击者协议为提示。", "result": "结果显示，默认条件下，相信自己对事件理解更清晰的参与者更容易信任GPT输出；而引导条件下，主观清晰度与实际召回之间的关联更强。此外，不同条件下的参与人员评价视频中人物合法性差异也较大。", "conclusion": "该研究表明，在记忆回溯过程中，GPT和用户间的互动可以潜移默化地塑造对事件的信念和感知。"}}
{"id": "2601.21459", "pdf": "https://arxiv.org/pdf/2601.21459", "abs": "https://arxiv.org/abs/2601.21459", "authors": ["Chengyu Du", "Xintao Wang", "Aili Chen", "Weiyuan Li", "Rui Xu", "Junteng Liu", "Zishan Huang", "Rong Tian", "Zijun Sun", "Yuhao Li", "Liheng Feng", "Deming Ding", "Pengyu Zhao", "Yanghua Xiao"], "title": "HER: Human-like Reasoning and Reinforcement Learning for LLM Role-playing", "categories": ["cs.LG", "cs.AI"], "comment": "41pages, 10 figures", "summary": "LLM role-playing, i.e., using LLMs to simulate specific personas, has emerged as a key capability in various applications, such as companionship, content creation, and digital games. While current models effectively capture character tones and knowledge, simulating the inner thoughts behind their behaviors remains a challenge. Towards cognitive simulation in LLM role-play, previous efforts mainly suffer from two deficiencies: data with high-quality reasoning traces, and reliable reward signals aligned with human preferences. In this paper, we propose HER, a unified framework for cognitive-level persona simulation. HER introduces dual-layer thinking, which distinguishes characters' first-person thinking from LLMs' third-person thinking. To bridge these gaps, we curate reasoning-augmented role-playing data via reverse engineering and construct human-aligned principles and reward models. Leveraging these resources, we train \\method models based on Qwen3-32B via supervised and reinforcement learning. Extensive experiments validate the effectiveness of our approach. Notably, our models significantly outperform the Qwen3-32B baseline, achieving a 30.26 improvement on the CoSER benchmark and a 14.97 gain on the Minimax Role-Play Bench. Our datasets, principles, and models will be released to facilitate future research.", "AI": {"tldr": "提出HER框架，用于提升大型语言模型在角色扮演中的认知模拟能力。", "motivation": "当前的LLM角色扮演游戏存在缺乏高质量推理痕迹和与人类偏好一致的奖励信号的问题。", "method": "引入双层思考机制，区分角色的第一人称思维与模型的第三人称思维；通过逆向工程收集带推理的数据，并构建符合人类偏好的原则和奖励模型。利用这些资源对Qwen3-32B进行监督学习和强化学习训练。", "result": "实验结果表明HER框架显著提升了LLM在角色扮演任务上的性能，比基线模型Qwen3-32B提高了CoSER基准的30.26分和Minimax Role-Play Bench基准的14.97分。", "conclusion": "提出的HER框架有效解决了当前LLM角色扮演游戏中的认知模拟挑战，并将公开数据集、原则和模型以促进未来研究。"}}
{"id": "2601.21458", "pdf": "https://arxiv.org/pdf/2601.21458", "abs": "https://arxiv.org/abs/2601.21458", "authors": ["Midou Guo", "Qilin Yin", "Wei Lu", "Xiangyang Luo", "Rui Yang"], "title": "Mining Forgery Traces from Reconstruction Error: A Weakly Supervised Framework for Multimodal Deepfake Temporal Localization", "categories": ["cs.CV"], "comment": null, "summary": "Modern deepfakes have evolved into localized and intermittent manipulations that require fine-grained temporal localization. The prohibitive cost of frame-level annotation makes weakly supervised methods a practical necessity, which rely only on video-level labels. To this end, we propose Reconstruction-based Temporal Deepfake Localization (RT-DeepLoc), a weakly supervised temporal forgery localization framework that identifies forgeries via reconstruction errors. Our framework uses a Masked Autoencoder (MAE) trained exclusively on authentic data to learn its intrinsic spatiotemporal patterns; this allows the model to produce significant reconstruction discrepancies for forged segments, effectively providing the missing fine-grained cues for localization. To robustly leverage these indicators, we introduce a novel Asymmetric Intra-video Contrastive Loss (AICL). By focusing on the compactness of authentic features guided by these reconstruction cues, AICL establishes a stable decision boundary that enhances local discrimination while preserving generalization to unseen forgeries. Extensive experiments on large-scale datasets, including LAV-DF, demonstrate that RT-DeepLoc achieves state-of-the-art performance in weakly-supervised temporal forgery localization.", "AI": {"tldr": "提出了一种基于重构误差的弱监督多模态Deepfake视频伪造部分时间定位框架。", "motivation": "现代deepfakes变得局部化和间歇性，需要精细的时间定位。高昂的手工标注成本使得仅依赖视频级别标签的弱监督方法成为必要。", "method": "提出了使用掩码自动编码器（MAE）训练模型以学习真实数据的固有时空模式，通过重构误差识别伪造段落，并引入一种不对称视频内对比损失（AICL），增强局部判别能力同时保持对未见过的伪造样本的泛化。", "result": "在大规模数据集上的实验表明，RT-DeepLoc在弱监督时间伪造定位上达到了最先进的性能。", "conclusion": "所提出的框架通过重构误差有效地解决了弱监督下多模态deepfake视频中伪造部分的时间定位问题，展示了强大的鲁棒性和泛化能力。"}}
{"id": "2601.21457", "pdf": "https://arxiv.org/pdf/2601.21457", "abs": "https://arxiv.org/abs/2601.21457", "authors": ["Tomer Adar", "Yahel Hotam", "Amit Levi"], "title": "When Local and Non-Local Meet: Quadratic Improvement for Edge Estimation with Independent Set Queries", "categories": ["cs.DS"], "comment": null, "summary": "We study the problem of estimating the number of edges in an unknown graph. We consider a hybrid model in which an algorithm may issue independent set, degree, and neighbor queries. We show that this model admits strictly more efficient edge estimation than either access type alone. Specifically, we give a randomized algorithm that outputs a $(1\\pm\\varepsilon)$-approximation of the number of edges using $O\\left(\\min\\left(\\sqrt{m}, \\sqrt{\\frac{n}{\\sqrt{m}}}\\right)\\cdot\\frac{\\log n}{\\varepsilon^{5/2}}\\right)$ queries, and prove a nearly matching lower bound. In contrast, prior work shows that in the local query model (Goldreich and Ron, \\textit{Random Structures \\& Algorithms} 2008) and in the independent set query model (Beame \\emph{et al.} ITCS 2018, Chen \\emph{et al.} SODA 2020), edge estimation requires $\\widetildeΘ(n/\\sqrt{m})$ queries in the same parameter regimes. Our results therefore yield a quadratic improvement in the hybrid model, and no asymptotically better improvement is possible.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.21454", "pdf": "https://arxiv.org/pdf/2601.21454", "abs": "https://arxiv.org/abs/2601.21454", "authors": ["Shanliang Yao", "Zhuoxiao Li", "Runwei Guan", "Kebin Cao", "Meng Xia", "Fuping Hu", "Sen Xu", "Yong Yue", "Xiaohui Zhu", "Weiping Ding", "Ryan Wen Liu"], "title": "4D-CAAL: 4D Radar-Camera Calibration and Auto-Labeling for Autonomous Driving", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "4D radar has emerged as a critical sensor for autonomous driving, primarily due to its enhanced capabilities in elevation measurement and higher resolution compared to traditional 3D radar. Effective integration of 4D radar with cameras requires accurate extrinsic calibration, and the development of radar-based perception algorithms demands large-scale annotated datasets. However, existing calibration methods often employ separate targets optimized for either visual or radar modalities, complicating correspondence establishment. Furthermore, manually labeling sparse radar data is labor-intensive and unreliable. To address these challenges, we propose 4D-CAAL, a unified framework for 4D radar-camera calibration and auto-labeling. Our approach introduces a novel dual-purpose calibration target design, integrating a checkerboard pattern on the front surface for camera detection and a corner reflector at the center of the back surface for radar detection. We develop a robust correspondence matching algorithm that aligns the checkerboard center with the strongest radar reflection point, enabling accurate extrinsic calibration. Subsequently, we present an auto-labeling pipeline that leverages the calibrated sensor relationship to transfer annotations from camera-based segmentations to radar point clouds through geometric projection and multi-feature optimization. Extensive experiments demonstrate that our method achieves high calibration accuracy while significantly reducing manual annotation effort, thereby accelerating the development of robust multi-modal perception systems for autonomous driving.", "AI": {"tldr": "提出了一种4D雷达与摄像头联合校准和自动标注的统一框架。", "motivation": "为了解决4D雷达与摄像头融合中的外参校准问题，以及基于雷达感知算法的大规模标注数据需求。", "method": "设计了具有视觉检测用棋盘格和雷达检测用角反射器的双重目标；开发了一种对齐相机中心与最强雷达反射点的方法，实现了准确的外部校准。提出了通过几何投影和多特征优化将相机分割结果转移到雷达点云上的自动标注流程。", "result": "实验表明该方法达到了高的校准精度，并大大减少了手动注释的努力。", "conclusion": "4D-CAAL框架加速了面向自动驾驶的稳健多模态感知系统的开发。"}}
{"id": "2601.21453", "pdf": "https://arxiv.org/pdf/2601.21453", "abs": "https://arxiv.org/abs/2601.21453", "authors": ["Xunkai Li", "Zhengyu Wu", "Zekai Chen", "Henan Sun", "Daohan Su", "Guang Zeng", "Hongchao Qin", "Rong-Hua Li", "Guoren Wang"], "title": "LION: A Clifford Neural Paradigm for Multimodal-Attributed Graph Learning", "categories": ["cs.AI"], "comment": null, "summary": "Recently, the rapid advancement of multimodal domains has driven a data-centric paradigm shift in graph ML, transitioning from text-attributed to multimodal-attributed graphs. This advancement significantly enhances data representation and expands the scope of graph downstream tasks, such as modality-oriented tasks, thereby improving the practical utility of graph ML. Despite its promise, limitations exist in the current neural paradigms: (1) Neglect Context in Modality Alignment: Most existing methods adopt topology-constrained or modality-specific operators as tokenizers. These aligners inevitably neglect graph context and inhibit modality interaction, resulting in suboptimal alignment. (2) Lack of Adaptation in Modality Fusion: Most existing methods are simple adaptations for 2-modality graphs and fail to adequately exploit aligned tokens equipped with topology priors during fusion, leading to poor generalizability and performance degradation. To address the above issues, we propose LION (c\\underline{LI}ff\\underline{O}rd \\underline{N}eural paradigm) based on the Clifford algebra and decoupled graph neural paradigm (i.e., propagation-then-aggregation) to implement alignment-then-fusion in multimodal-attributed graphs. Specifically, we first construct a modality-aware geometric manifold grounded in Clifford algebra. This geometric-induced high-order graph propagation efficiently achieves modality interaction, facilitating modality alignment. Then, based on the geometric grade properties of aligned tokens, we propose adaptive holographic aggregation. This module integrates the energy and scale of geometric grades with learnable parameters to improve modality fusion. Extensive experiments on 9 datasets demonstrate that LION significantly outperforms SOTA baselines across 3 graph and 3 modality downstream tasks.", "AI": {"tldr": "提出了一种基于Clifford代数的神经网络框架LION，用于多模态属性图学习。", "motivation": "当前多模态领域的快速发展推动了从文本属性到多模态属性图的数据驱动范式转变。然而现有方法在模式对齐和融合方面存在局限性，如忽略图形背景抑制模式交互以及缺乏适应性的模式融合策略导致性能下降。", "method": "通过基于Clifford代数构建的模式感知几何流形来实现高阶图传播，促进模式间相互作用；再利用几何等级属性提出自适应全息聚合模块以增强模式融合。该方法采用分离式图神经网络范式（即先传播后聚合）进行对齐后再融合。", "result": "实验结果显示LION在三种图形下游任务和三种模态下游任务上显著优于当前最佳的基线模型。", "conclusion": "LION通过改进模式对齐和融合策略，解决了现有方法的一些局限性，并证明了其在多模态属性图学习中的有效性。"}}
{"id": "2601.21452", "pdf": "https://arxiv.org/pdf/2601.21452", "abs": "https://arxiv.org/abs/2601.21452", "authors": ["Yu Xie", "Xing Kai Ren", "Ying Qi", "Hu Yao"], "title": "SAGE: Sequence-level Adaptive Gradient Evolution for Generative Recommendation", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2506.19235", "summary": "While works such as OneRec have validated the scaling laws of Large Language Models (LLMs) in recommender systems, they rely on a cumbersome separate vocabulary. This dependency prevents the model architecture from reusing native LLM vocabularies, resulting in high maintenance costs and poor scalability. In response, we aim to efficiently reuse open-source LLM architectures without constructing a separate tokenization vocabulary. Furthermore, we identify that the optimization strategy of OneRec Gradient Bounded Policy Optimization (GBPO),suffers from a \"Symmetric Conservatism\" problem: its static gradient boundaries structurally suppress the update momentum required for cold-start items and fail to prevent diversity collapse in high-noise environments.To address this issue, we propose SAGE (Sequence-level Adaptive Gradient Evolution), a unified optimization framework tailored for list-wise generative recommendation. SAGE introduces two key innovations:(1) Sequence-level Signal Decoupling: By combining a geometric mean importance ratio with decoupled multi-objective advantages, we eliminate token-level variance and resolve the \"Reward Collapse\" problem. (2) Asymmetric Adaptive Dynamics: We construct a dynamic gradient manifold that applies a \"Boost Factor\" to high-potential cold start items to achieve super-linear updates and employs an \"Entropy Aware Penalty\" to break information cocoons. Theoretical analysis and empirical results demonstrate that SAGE effectively unblocks cold-start traffic and sustains recommendation diversity, all while retaining the numerical stability of GBPO.", "AI": {"tldr": "本文提出了SAGE框架，旨在解决推荐系统中的冷启动问题和多样性崩溃问题。", "motivation": "现有工作依赖于独立词汇表导致维护成本高且可扩展性差；OneRec的优化策略存在对新项目更新抑制及高噪声环境下的多样性损失的问题。", "method": "SAGE采用序列级信号解耦结合动态梯度流形，以解决奖励崩溃并增强冷启动项目的更新和打破信息茧房。", "result": "实验表明，SAGE在保持数值稳定性的同时有效缓解了推荐系统的冷启动问题并提高了多样性。", "conclusion": "本文提出的SAGE框架可以有效地处理推荐系统中的挑战，提高模型的性能和实用性。"}}
{"id": "2601.21450", "pdf": "https://arxiv.org/pdf/2601.21450", "abs": "https://arxiv.org/abs/2601.21450", "authors": ["Donghuo Zeng", "Hao Niu", "Zhi Li", "Masato Taya"], "title": "Variance & Greediness: A comparative study of metric-learning losses", "categories": ["cs.CV"], "comment": "5 pages, 2 figures, 3 tables. Accepted by ICASSP 2026", "summary": "Metric learning is central to retrieval, yet its effects on embedding geometry and optimization dynamics are not well understood. We introduce a diagnostic framework, VARIANCE (intra-/inter-class variance) and GREEDINESS (active ratio and gradient norms), to compare seven representative losses, i.e., Contrastive, Triplet, N-pair, InfoNCE, ArcFace, SCL, and CCL, across five image-retrieval datasets. Our analysis reveals that Triplet and SCL preserve higher within-class variance and clearer inter-class margins, leading to stronger top-1 retrieval in fine-grained settings. In contrast, Contrastive and InfoNCE compact embeddings are achieved quickly through many small updates, accelerating convergence but potentially oversimplifying class structures. N-pair achieves a large mean separation but with uneven spacing. These insights reveal a form of efficiency-granularity trade-off and provide practical guidance: prefer Triplet/SCL when diversity preservation and hard-sample discrimination are critical, and Contrastive/InfoNCE when faster embedding compaction is desired.", "AI": {"tldr": "该论文介绍了诊断框架VARIANCE和GREEDINESS，用于比较七种代表性的度量学习损失函数在五个图像检索数据集上的表现。", "motivation": "度量学习对于检索任务至关重要，但其对嵌入几何结构及优化动态的影响尚不明确。本研究旨在通过引入新的诊断框架来深入理解这些影响。", "method": "提出了一种称为VARIANCE（类内/类间方差）和GREEDINESS（活跃比和梯度范数）的诊断框架，用于比较七种代表性的损失函数：对比损失、三元组损失、N-对损失、InfoNCE损失、ArcFace损失、SCL损失和CCL损失。", "result": "研究表明，三元组损失和SCL损失在保持更高类内方差和更清晰的类间间隔方面表现优异，在细粒度场景下表现出更强的top-1检索能力。对比损失和InfoNCE损失则通过大量小更新迅速紧凑嵌入，虽然加速了收敛但可能过度简化了类别结构。", "conclusion": "研究揭示了一种效率与精细度之间的权衡，并提供了实用建议：当保持多样性及区分难度样本至关重要时选择三元组/SCL损失；而需要更快的嵌入紧凑化时则应选择对比/InfoNCE损失。"}}
{"id": "2601.21449", "pdf": "https://arxiv.org/pdf/2601.21449", "abs": "https://arxiv.org/abs/2601.21449", "authors": ["Zeyu He", "Yuchang Zhang", "Yuanzhen Zhou", "Miao Tao", "Hengjie Li", "Yang Tian", "Jia Zeng", "Tai Wang", "Wenzhe Cai", "Yilun Chen", "Ning Gao", "Jiangmiao Pang"], "title": "Nimbus: A Unified Embodied Synthetic Data Generation Framework", "categories": ["cs.RO", "cs.DC"], "comment": null, "summary": "Scaling data volume and diversity is critical for generalizing embodied intelligence. While synthetic data generation offers a scalable alternative to expensive physical data acquisition, existing pipelines remain fragmented and task-specific. This isolation leads to significant engineering inefficiency and system instability, failing to support the sustained, high-throughput data generation required for foundation model training. To address these challenges, we present Nimbus, a unified synthetic data generation framework designed to integrate heterogeneous navigation and manipulation pipelines. Nimbus introduces a modular four-layer architecture featuring a decoupled execution model that separates trajectory planning, rendering, and storage into asynchronous stages. By implementing dynamic pipeline scheduling, global load balancing, distributed fault tolerance, and backend-specific rendering optimizations, the system maximizes resource utilization across CPU, GPU, and I/O resources. Our evaluation demonstrates that Nimbus achieves a 2-3X improvement in end-to-end throughput compared to unoptimized baselines and ensuring robust, long-term operation in large-scale distributed environments. This framework serves as the production backbone for the InternData suite, enabling seamless cross-domain data synthesis.", "AI": {"tldr": "介绍了Nimbus，一个统一的合成数据生成框架，旨在解决现有管道碎片化和任务特定性的问题。", "motivation": "为了克服现有合成数据生成管道中的碎片化和任务特定性的挑战，提高工程效率并支持大规模分布式环境下的持续、高吞吐量的数据生成。", "method": "Nimbus采用了一种模块化的四层架构，包括解耦的执行模型，将轨迹规划、渲染和存储分离成异步阶段。通过实现动态管道调度、全局负载均衡、分布式容错以及针对后端特定的渲染优化来最大化资源利用率。", "result": "实验表明，Nimbus在与未经优化的基准相比时，在端到端吞吐量上实现了2-3倍的提升，并且确保了大规模分布式环境中的长期稳定运行。", "conclusion": "该框架作为InternData套件的生产基础架构，支持无缝跨域数据合成。"}}
{"id": "2601.21448", "pdf": "https://arxiv.org/pdf/2601.21448", "abs": "https://arxiv.org/abs/2601.21448", "authors": ["Zhongkai Yu", "Chenyang Zhou", "Yichen Lin", "Hejia Zhang", "Haotian Ye", "Junxia Cui", "Zaifeng Pan", "Jishen Zhao", "Yufei Ding"], "title": "ChipBench: A Next-Step Benchmark for Evaluating LLM Performance in AI-Aided Chip Design", "categories": ["cs.AI", "cs.AR"], "comment": null, "summary": "While Large Language Models (LLMs) show significant potential in hardware engineering, current benchmarks suffer from saturation and limited task diversity, failing to reflect LLMs' performance in real industrial workflows. To address this gap, we propose a comprehensive benchmark for AI-aided chip design that rigorously evaluates LLMs across three critical tasks: Verilog generation, debugging, and reference model generation. Our benchmark features 44 realistic modules with complex hierarchical structures, 89 systematic debugging cases, and 132 reference model samples across Python, SystemC, and CXXRTL. Evaluation results reveal substantial performance gaps, with state-of-the-art Claude-4.5-opus achieving only 30.74\\% on Verilog generation and 13.33\\% on Python reference model generation, demonstrating significant challenges compared to existing saturated benchmarks where SOTA models achieve over 95\\% pass rates. Additionally, to help enhance LLM reference model generation, we provide an automated toolbox for high-quality training data generation, facilitating future research in this underexplored domain. Our code is available at https://github.com/zhongkaiyu/ChipBench.git.", "AI": {"tldr": "提出了一种新的基准测试ChipBench，用于评估大型语言模型在芯片设计中的表现。", "motivation": "现有的基准测试未能充分反映大规模语言模型在实际工业工作流程中的性能，因此需要一个新的更加全面的基准测试来弥补这一差距。", "method": "提出了一个涵盖Verilog代码生成、调试和参考模型生成三项任务的新基准测试ChipBench，并使用该基准对当前最先进的模型进行了评估。", "result": "最先进的Claude-4.5-opus在Verilog代码生成上仅达到30.74%，而在Python参考模型生成上的通过率仅为13.33%。此外，还提供了一个自动生成高质量训练数据的工具箱以促进相关研究的发展。", "conclusion": "新基准测试ChipBench揭示了大规模语言模型在实际芯片设计任务中的性能差距，有助于推动该领域的进一步研究和改进。"}}
{"id": "2601.21446", "pdf": "https://arxiv.org/pdf/2601.21446", "abs": "https://arxiv.org/abs/2601.21446", "authors": ["Francesco Zola", "Lucia Muñoz", "Andrea Venturi", "Amaia Gil"], "title": "Synthetic Pattern Generation and Detection of Financial Activities using Graph Autoencoders", "categories": ["cs.LG", "cs.CE", "cs.ET"], "comment": "Accept to The 7th International Workshop on Statistical Methods and Artificial Intelligence (IWSMAI'26)", "summary": "Illicit financial activities such as money laundering often manifest through recurrent topological patterns in transaction networks. Detecting these patterns automatically remains challenging due to the scarcity of labeled real-world data and strict privacy constraints. To address this, we investigate whether Graph Autoencoders (GAEs) can effectively learn and distinguish topological patterns that mimic money laundering operations when trained on synthetic data. The analysis consists of two phases: (i) data generation, where synthetic samples are created for seven well-known illicit activity patterns using parametrized generators that preserve structural consistency while introducing realistic variability; and (ii) model training and validation, where separate GAEs are trained on each pattern without explicit labels, relying solely on reconstruction error as an indicator of learned structure. We compare three GAE implementations based on three distinct convolutional layers: Graph Convolutional (GAE-GCN), GraphSAGE (GAE-SAGE), and Graph Attention Network (GAE-GAT). Experimental results show that GAE-GCN achieves the most consistent reconstruction performance across patterns, while GAE-SAGE and GAE-GAT exhibit competitive results only in few specific patterns. These findings suggest that graph-based representation learning on synthetic data provides a viable path toward developing AI-driven tools for detecting illicit behaviors, overcoming the limitations of financial datasets.", "AI": {"tldr": "使用图自编码器（GAE）在合成数据上学习和区分可能代表洗钱行为的拓扑模式，从而开发出用于检测非法金融活动的人工智能工具。", "motivation": "自动检测金融活动中重复出现的、代表非法行为的拓扑模式具有挑战性，因为现实世界的数据稀缺且受到严格的隐私限制。该研究旨在探索图自编码器是否可以利用合成数据来学习这些模式。", "method": "方法包括两部分：第一阶段通过参数化生成器创建七种已知非法活动模式的合成样本；第二阶段使用三种不同卷积层的图自编码器（GAE-GCN，GAE-SAGE，GAE-GAT）在没有明确标签的情况下仅依靠重构误差进行训练和验证。", "result": "实验结果表明，GAE-GCN在所有模式中的重建性能最为稳定。而GAE-SAGE和GAE-GAT只在少数特定的模式中表现出竞争性的结果。", "conclusion": "基于合成数据的图表示学习提供了一条开发用于检测非法行为的人工智能工具的有效途径，克服了金融数据集的限制。"}}
{"id": "2601.21444", "pdf": "https://arxiv.org/pdf/2601.21444", "abs": "https://arxiv.org/abs/2601.21444", "authors": ["Yuxiang Huang", "Mingye Li", "Xu Han", "Chaojun Xiao", "Weilin Zhao", "Ao Sun", "Ziqi Yuan", "Hao Zhou", "Fandong Meng", "Zhiyuan Liu"], "title": "Spava: Accelerating Long-Video Understanding via Sequence-Parallelism-aware Approximate Attention", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "The efficiency of long-video inference remains a critical bottleneck, mainly due to the dense computation in the prefill stage of Large Multimodal Models (LMMs). Existing methods either compress visual embeddings or apply sparse attention on a single GPU, yielding limited acceleration or degraded performance and restricting LMMs from handling longer, more complex videos. To overcome these issues, we propose Spava, a sequence-parallel framework with optimized attention that accelerates long-video inference across multiple GPUs. By distributing approximate attention, Spava reduces computation and increases parallelism, enabling efficient processing of more visual embeddings without compression and thereby improving task performance. System-level optimizations, such as load balancing and fused forward passes, further unleash the potential of Spava, delivering speedups of 12.72x, 1.70x, and 1.18x over FlashAttn, ZigZagRing, and APB, without notable performance loss. Code available at https://github.com/thunlp/APB", "AI": {"tldr": "Spava通过在多个GPU上优化和分布注意力机制，加速了长视频推理。", "motivation": "现有方法要么压缩视觉嵌入，要么在一个GPU上应用稀疏注意，这限制了大型多模态模型处理更长时间、更复杂的视频的能力。为了克服这些问题，提出了Spava框架。", "method": "Spava通过分布式的近似注意力机制减少计算量，并增加并行性，从而在不压缩视觉嵌入的情况下提高任务性能。系统级的优化包括负载均衡和融合前向传递进一步提升了Spava的效果。", "result": "与FlashAttn、ZigZagRing和APB相比，Spava实现了12.72倍、1.70倍和1.18倍的速度提升，并且没有明显的性能损失。", "conclusion": "Spava为大型多模态模型提供了有效的长视频推理加速方案。"}}
{"id": "2601.21439", "pdf": "https://arxiv.org/pdf/2601.21439", "abs": "https://arxiv.org/abs/2601.21439", "authors": ["Jon Chun", "Katherine Elkins"], "title": "The Paradox of Robustness: Decoupling Rule-Based Logic from Affective Noise in High-Stakes Decision-Making", "categories": ["cs.AI"], "comment": "22 page, 10 figures", "summary": "While Large Language Models (LLMs) are widely documented to be sensitive to minor prompt perturbations and prone to sycophantic alignment with user biases, their robustness in consequential, rule-bound decision-making remains under-explored. In this work, we uncover a striking \"Paradox of Robustness\": despite their known lexical brittleness, instruction-tuned LLMs exhibit a behavioral and near-total invariance to emotional framing effects. Using a novel controlled perturbation framework across three high-stakes domains (healthcare, law, and finance), we quantify a robustness gap where LLMs demonstrate 110-300 times greater resistance to narrative manipulation than human subjects. Specifically, we find a near-zero effect size for models (Cohen's h = 0.003) compared to the substantial biases observed in humans (Cohen's h in [0.3, 0.8]). This result is highly counterintuitive and suggests the mechanisms driving sycophancy and prompt sensitivity do not necessarily translate to a failure in logical constraint satisfaction. We show that this invariance persists across models with diverse training paradigms. Our findings show that while LLMs may be \"brittle\" to how a query is formatted, they are remarkably \"stable\" against why a decision should be biased. Our findings establish that instruction-tuned models can decouple logical rule-adherence from persuasive narratives, offering a source of decision stability that complements, and even potentially de-biases, human judgment in institutional contexts. We release the 162-scenario benchmark, code, and data to facilitate the rigorous evaluation of narrative-induced bias and robustness on GitHub.com.", "AI": {"tldr": "探讨大型语言模型在高风险决策中的稳定性，特别是在情感框架效应下的表现", "motivation": "研究大型语言模型的稳定性是否能在规则驱动的决策中超越人类的情感偏见和叙事操纵影响", "method": "通过新颖控制框架，在医疗、法律和金融三个领域测试162个场景，比较模型与人类在情感框架下决策的一致性", "result": "发现大型语言模型对情感框架效应表现出高度稳定，比人类具有更强的抵抗叙事操纵能力", "conclusion": "大型语言模型能够将逻辑规则执行与说服性叙述解耦，在高风险环境中提供稳定的决策支持，可能有助于减轻人类偏见"}}
{"id": "2601.21436", "pdf": "https://arxiv.org/pdf/2601.21436", "abs": "https://arxiv.org/abs/2601.21436", "authors": ["Hang Ni", "Weijia Zhang", "Fei Wang", "Zezhi Shao", "Hao Liu"], "title": "From Consistency to Complementarity: Aligned and Disentangled Multi-modal Learning for Time Series Understanding and Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Advances in multi-modal large language models (MLLMs) have inspired time series understanding and reasoning tasks, that enable natural language querying over time series, producing textual analyses of complex temporal dynamics. Recent attempts hybridize numerical time series with their visualized plots, facilitating precise value reasoning and visual structure comprehension for comprehensive time series understanding of MLLMs. However, effective cross-modal integration remains challenging due to fine-grained temporal misalignment across modalities and severe entanglement between shared and modality-specific semantics, which hinder localized interpretation and complementary reasoning. To address these issues, we propose MADI, a multi-modal LLM enhanced with fine-grained alignment and disentangled interaction, featuring (1) Patch-level Alignment, which enforces physically grounded fine-grained correspondence across heterogeneous modalities, (2) Discrete Disentangled Interaction, which separates modality-common semantics into compact discrete latents and adaptively synergizes the purified modality-unique information, and (3) Critical-token Highlighting, which emphasizes informative, query-relevant signals for robust reasoning. Experiments on synthetic and real-world benchmarks show that MADI consistently outperforms general-purpose LLMs and time-series-specialized MLLMs.", "AI": {"tldr": "提出了一种名为MADI的方法，旨在改善多模态时间序列理解与推理任务。", "motivation": "现有方法难以有效整合不同模式的信息，由于时间序列和视觉化图表之间的细粒度时间对齐问题及共享语义与特定于模式的语义之间纠缠不清的问题，导致了局部解释困难以及互补性推理不足。", "method": "MADI通过实施补丁级对齐、离散解耦交互和关键令牌突出显示来解决这些问题。它确保不同模态之间的细粒度对应关系，并且分离出共享信息以提高特定于模式的信息的融合效率。", "result": "实验结果表明，MADI在合成数据集和真实世界基准上均优于通用大型语言模型及专门的时间序列多模态语言模型。", "conclusion": "该研究通过提出一种新的方法MADI来改善时间序列理解与推理任务中的多模态信息整合问题。"}}
{"id": "2601.21433", "pdf": "https://arxiv.org/pdf/2601.21433", "abs": "https://arxiv.org/abs/2601.21433", "authors": ["Katherine Elkins", "Jon Chun"], "title": "When Prohibitions Become Permissions: Auditing Negation Sensitivity in Language Models", "categories": ["cs.AI"], "comment": "13 pages, 5 figures", "summary": "When a user tells an AI system that someone \"should not\" take an action, the system ought to treat this as a prohibition. Yet many large language models do the opposite: they interpret negated instructions as affirmations. We audited 16 models across 14 ethical scenarios and found that open-source models endorse prohibited actions 77% of the time under simple negation and 100% under compound negation -- a 317% increase over affirmative framing. Commercial models fare better but still show swings of 19-128%. Agreement between models drops from 74% on affirmative prompts to 62% on negated ones, and financial scenarios prove twice as fragile as medical ones. These patterns hold under deterministic decoding, ruling out sampling noise. We present case studies showing how these failures play out in practice, propose the Negation Sensitivity Index (NSI) as a governance metric, and outline a tiered certification framework with domain-specific thresholds. The findings point to a gap between what current alignment techniques achieve and what safe deployment requires: models that cannot reliably distinguish \"do X\" from \"do not X\" should not be making autonomous decisions in high-stakes contexts.", "AI": {"tldr": "本文研究了大型语言模型在处理否定指令时的表现，发现它们往往将禁止的行为误解为允许，并提出了一个评估指标及认证框架。", "motivation": "许多大语言模型未能正确解读用户的否定指令，误将“不应该”理解成肯定的指示。这可能导致严重的伦理和安全问题，特别是在高风险场景中。", "method": "作者对16个不同模型进行了审计，在14个道德情景下测试它们如何处理简单的和复杂的否定命令，并测量了这些模型之间的共识度变化。", "result": "开源模型在面对简单否定指令时有77%的几率认同禁止的行为，而在复杂否定指令下的同意率则达到100%，增幅达317%。商业模型表现略好，但其认可程度仍然从19%-128%不等。", "conclusion": "当前的技术在防止语言模型错误解读否定命令方面仍有不足，这些系统不适合在高风险领域进行自主决策。作者提出了一种评估指标——否定敏感性指数（NSI），并建议建立一个多级认证框架以确保安全性和可靠性。"}}
{"id": "2601.21426", "pdf": "https://arxiv.org/pdf/2601.21426", "abs": "https://arxiv.org/abs/2601.21426", "authors": ["Shohei Enomoto", "Shin'ya Yamaguchi"], "title": "MultiModal Fine-tuning with Synthetic Captions", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we address a fundamental gap between pre-training and fine-tuning of deep neural networks: while pre-training has shifted from unimodal to multimodal learning with enhanced visual understanding, fine-tuning predominantly remains unimodal, limiting the benefits of rich pre-trained representations. To bridge this gap, we propose a novel approach that transforms unimodal datasets into multimodal ones using Multimodal Large Language Models (MLLMs) to generate synthetic image captions for fine-tuning models with a multimodal objective. Our method employs carefully designed prompts incorporating class labels and domain context to produce high-quality captions tailored for classification tasks. Furthermore, we introduce a supervised contrastive loss function that explicitly encourages clustering of same-class representations during fine-tuning, along with a new inference technique that leverages class-averaged text embeddings from multiple synthetic captions per image. Extensive experiments across 13 image classification benchmarks demonstrate that our approach outperforms baseline methods, with particularly significant improvements in few-shot learning scenarios. Our work establishes a new paradigm for dataset enhancement that effectively bridges the gap between multimodal pre-training and fine-tuning. Our code is available at https://github.com/s-enmt/MMFT.", "AI": {"tldr": "本文提出了一种将单模态数据集转换为多模态数据集的方法，通过生成合成图像字幕来提高模型的分类性能。", "motivation": "预训练从单模态学习转移到了多模态学习以增强视觉理解能力，而细调过程仍主要局限于单模态，限制了丰富的预训练表示的优势。为解决这一问题，本文提出了一个新的方法。", "method": "该方法利用多模态大型语言模型生成合成图像字幕，并设计了包括类别标签和领域上下文的精心构造提示，以产生适合分类任务的高质量字幕。此外还引入了一种监督对比损失函数，鼓励相同类别的表示在细调期间进行聚类。", "result": "实验证明该方法优于基准方法，在少量样本学习场景中的改进尤为显著。", "conclusion": "本文的工作确立了一个新的数据增强范式，有效地弥合了多模态预训练与细调之间的差距。"}}
{"id": "2601.21424", "pdf": "https://arxiv.org/pdf/2601.21424", "abs": "https://arxiv.org/abs/2601.21424", "authors": ["Anderson de Andrade", "Alon Harell", "Ivan V. Bajić"], "title": "Lossy Common Information in a Learnable Gray-Wyner Network", "categories": ["cs.LG", "cs.CV", "cs.IT"], "comment": null, "summary": "Many computer vision tasks share substantial overlapping information, yet conventional codecs tend to ignore this, leading to redundant and inefficient representations. The Gray-Wyner network, a classical concept from information theory, offers a principled framework for separating common and task-specific information. Inspired by this idea, we develop a learnable three-channel codec that disentangles shared information from task-specific details across multiple vision tasks. We characterize the limits of this approach through the notion of lossy common information, and propose an optimization objective that balances inherent tradeoffs in learning such representations. Through comparisons of three codec architectures on two-task scenarios spanning six vision benchmarks, we demonstrate that our approach substantially reduces redundancy and consistently outperforms independent coding. These results highlight the practical value of revisiting Gray-Wyner theory in modern machine learning contexts, bridging classic information theory with task-driven representation learning.", "AI": {"tldr": "开发了一种可学习的三通道编解码器，用于在多个视觉任务中分离共享信息和任务特定细节。", "motivation": "许多计算机视觉任务包含大量重叠的信息，但传统编码方式通常忽略这一点，导致冗余和低效的表现。通过借鉴信息论中的Gray-Wyner网络概念，旨在减少这些冗余并提高效率。", "method": "提出了一种基于可学习的三通道编解码器的方法，该方法通过分离共享信息与任务特定细节来处理多个视觉任务。定义了损失共同信息的概念，并提出了一个平衡这种表示中固有折衷的优化目标。", "result": "在包含两个任务的情景下使用六种视觉基准测试对三种编解码器架构进行了比较，结果表明该方法显著减少了冗余并始终优于独立编码。", "conclusion": "通过重新审视Gray-Wyner理论在现代机器学习环境中的应用，这种方法不仅展示了其实践价值，还成功地将经典信息论与任务驱动的表示学习结合在一起。"}}
{"id": "2601.21423", "pdf": "https://arxiv.org/pdf/2601.21423", "abs": "https://arxiv.org/abs/2601.21423", "authors": ["Léo Colisson Palais", "Jean-Guillaume Dumas", "Alexis Galan", "Bruno Grenet", "Aude Maignan"], "title": "Algorithms for the local and the global postage stamp problem", "categories": ["cs.DS"], "comment": null, "summary": "We consider stamps with different values (denominations) and same dimensions, and an envelope with a fixed maximum number of stamp positions. The local postage stamp problem is to find the smallest value that cannot be realized by the sum of the stamps on the envelope. The global postage stamp problem is to find the set of denominations that maximize that smallest value for a fixed number of distinct denominations. The local problem is NP-hard and we propose here a novel algorithm that improves on both the time complexity bound and the amount of required memory. We also propose a polynomial approximation algorithm for the global problem together with its complexity analysis. Finally we show that our algorithms allow to improve secure multi-party computations on sets via a more efficient homomorphic evaluation of polynomials on ciphered values.", "AI": {"tldr": "本文研究了邮票问题，提出了一种改进的时间复杂度和内存需求的算法来解决局部邮票问题，并为全局邮票问题提出了一个多项式近似算法。", "motivation": "为了提高计算效率并减少资源消耗，在固定数量的不同面额下找到不能被组合出的最小值是NP难问题，因此需要新的算法方法。", "method": "提出了一种新型算法来优化局部邮票问题的时间复杂性和内存需求，并为全局邮票问题设计了一个多项式近似算法及其复杂性分析。此外还展示了这些算法如何改进多方面计算的安全性。", "result": "提出的算法在时间和空间上都有显著改善，且通过更高效的同态评估方法提高了安全多方计算的效率。", "conclusion": "新的算法不仅解决了邮票组合问题中的挑战，也提升了多项式加密值处理的速度和安全性。"}}
{"id": "2601.21421", "pdf": "https://arxiv.org/pdf/2601.21421", "abs": "https://arxiv.org/abs/2601.21421", "authors": ["Jiangsan Zhao", "Jakob Geipel", "Kryzysztof Kusnierek"], "title": "From Implicit Ambiguity to Explicit Solidity: Diagnosing Interior Geometric Degradation in Neural Radiance Fields for Dense 3D Scene Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Neural Radiance Fields (NeRFs) have emerged as a powerful paradigm for multi-view reconstruction, complementing classical photogrammetric pipelines based on Structure-from-Motion (SfM) and Multi-View Stereo (MVS). However, their reliability for quantitative 3D analysis in dense, self-occluding scenes remains poorly understood. In this study, we identify a fundamental failure mode of implicit density fields under heavy occlusion, which we term Interior Geometric Degradation (IGD). We show that transmittance-based volumetric optimization satisfies photometric supervision by reconstructing hollow or fragmented structures rather than solid interiors, leading to systematic instance undercounting. Through controlled experiments on synthetic datasets with increasing occlusion, we demonstrate that state-of-the-art mask-supervised NeRFs saturate at approximately 89% instance recovery in dense scenes, despite improved surface coherence and mask quality. To overcome this limitation, we introduce an explicit geometric pipeline based on Sparse Voxel Rasterization (SVRaster), initialized from SfM feature geometry. By projecting 2D instance masks onto an explicit voxel grid and enforcing geometric separation via recursive splitting, our approach preserves physical solidity and achieves a 95.8% recovery rate in dense clusters. A sensitivity analysis using degraded segmentation masks further shows that explicit SfM-based geometry is substantially more robust to supervision failure, recovering 43% more instances than implicit baselines. These results demonstrate that explicit geometric priors are a prerequisite for reliable quantitative analysis in highly self-occluding 3D scenes.", "AI": {"tldr": "论文主要任务是解决NeRF在密集、自我遮挡场景中几何结构降解的问题，并提出了一种基于稀疏体素栅格化的显式几何方法来提升实例恢复率。", "motivation": "当前的NeRF模型在处理复杂、自我遮挡的3D场景时，无法准确重建出内部结构，导致系统性地低估了物体的数量。作者通过实验发现这种问题与透射量优化有关，并且提出显式几何方法来解决这个问题。", "method": "论文引入了一种基于稀疏体素栅格化的显式几何处理流程，该流程从SfM特征几何初始化开始，在2D实例掩码投影到一个明确的体素网格并强制执行几何分离后进行递归分裂以保持物理固体性。", "result": "提出的显式方法在密集聚类场景中达到95.8％恢复率，并且对降级分割蒙版的敏感度分析显示，基于SfM的几何处理比隐含基线多恢复了43％的实例。", "conclusion": "研究结果证明，在高度自我遮挡的3D场景中进行可靠定量分析需要显式几何先验知识。"}}
{"id": "2601.21419", "pdf": "https://arxiv.org/pdf/2601.21419", "abs": "https://arxiv.org/abs/2601.21419", "authors": ["Qing Jin", "Chaoyang Wang"], "title": "Revisiting Diffusion Model Predictions Through Dimensionality", "categories": ["cs.LG", "cs.CV"], "comment": "19 pages, 5 figures", "summary": "Recent advances in diffusion and flow matching models have highlighted a shift in the preferred prediction target -- moving from noise ($\\varepsilon$) and velocity (v) to direct data (x) prediction -- particularly in high-dimensional settings. However, a formal explanation of why the optimal target depends on the specific properties of the data remains elusive. In this work, we provide a theoretical framework based on a generalized prediction formulation that accommodates arbitrary output targets, of which $\\varepsilon$-, v-, and x-prediction are special cases. We derive the analytical relationship between data's geometry and the optimal prediction target, offering a rigorous justification for why x-prediction becomes superior when the ambient dimension significantly exceeds the data's intrinsic dimension. Furthermore, while our theory identifies dimensionality as the governing factor for the optimal prediction target, the intrinsic dimension of manifold-bound data is typically intractable to estimate in practice. To bridge this gap, we propose k-Diff, a framework that employs a data-driven approach to learn the optimal prediction parameter k directly from data, bypassing the need for explicit dimension estimation. Extensive experiments in both latent-space and pixel-space image generation demonstrate that k-Diff consistently outperforms fixed-target baselines across varying architectures and data scales, providing a principled and automated approach to enhancing generative performance.", "AI": {"tldr": "重新审视扩散模型预测目标的选取问题，提出基于数据维度的理论框架和k-Diff方法。", "motivation": "当前扩散模型倾向于直接预测数据（x）而非噪声或速度，在高维情况下的表现更优。但缺乏正式解释为何最优预测目标取决于数据特性。", "method": "构建通用化的预测公式，分析数据几何与最佳预测目标的关系；提出k-Diff框架，基于数据驱动方法学习最优预测参数k，无需显式维度估计。", "result": "实验显示，k-Diff在不同架构和数据规模上均超越固定目标基线，在潜在空间和像素空间图像生成中表现优越。", "conclusion": "理论揭示了数据维度对最佳预测目标的影响；提出的方法提供了一个原理性和自动化提升生成性能的途径。"}}
{"id": "2601.21418", "pdf": "https://arxiv.org/pdf/2601.21418", "abs": "https://arxiv.org/abs/2601.21418", "authors": ["Qian Wan", "Ziao Xu", "Luona Wei", "Xiaoxuan Shen", "Jianwen Sun"], "title": "Mitigating Overthinking in Large Reasoning Models via Difficulty-aware Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) achieve explicit chain-of-thought expansion by imitating deep thinking behaviors of humans, demonstrating excellent performance in complex task scenarios. However, the deep-thinking mode often leads to unnecessarily lengthy reasoning and resource inefficiency when handling simple tasks. This overthinking phenomenon may arise from the generation preference triggered by the reward function during post-training. Existing research attempts to mitigate overthinking from the perspective of prompt design or model training, but generally underestimates the importance of task difficulty awareness, which makes it difficult for LRMs to effectively allocate reasoning resources. In this paper, we propose Difficulty-aware Policy Optimization (DiPO), a reinforcement learning-based LRM training framework. DiPO encourages LRM to spontaneously model task complexity, and integrates them into reinforcement learning framework to adjust the generation preferences introduced by post-training. A difficulty modeling method based on model self-reasoning is proposed, which significantly reduces the dependence on manual annotation and formalize task complexity. We further develop a difficulty-signal-enhanced reward function that incorporates a penalty for lengthy reasoning while considering reasoning performance and output format. Experimental results indicate that DiPO enables the model to spontaneously adjust inference overhead, significantly reducing redundant tokens without losing performance due to thought compression.", "AI": {"tldr": "提出了一种基于任务难度的强化学习框架DiPO，以减少大推理模型在简单任务中的过度思考现象。", "motivation": "现有的研究忽略了任务难度感知的重要性，导致大推理模型无法有效分配推理资源。为解决这一问题，该论文通过引入任务难度感知来优化生成偏好。", "method": "提出了基于模型自我推理的任务难度建模方法，并开发了一种增强的奖励函数，结合了对冗长推理的惩罚和性能考虑。", "result": "实验结果表明，DiPO框架可以使模型自发调整推断开销，在减少冗余令牌的同时保持性能不下降。", "conclusion": "该研究证明了任务难度感知对于优化大推理模型生成偏好的重要性，并展示了通过强化学习有效缓解过度思考现象的潜力。"}}
{"id": "2601.21416", "pdf": "https://arxiv.org/pdf/2601.21416", "abs": "https://arxiv.org/abs/2601.21416", "authors": ["Alexandre Chapin", "Bruno Machado", "Emmanuel Dellandréa", "Liming Chen"], "title": "Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "The generalization capabilities of robotic manipulation policies are heavily influenced by the choice of visual representations. Existing approaches typically rely on representations extracted from pre-trained encoders, using two dominant types of features: global features, which summarize an entire image via a single pooled vector, and dense features, which preserve a patch-wise embedding from the final encoder layer. While widely used, both feature types mix task-relevant and irrelevant information, leading to poor generalization under distribution shifts, such as changes in lighting, textures, or the presence of distractors. In this work, we explore an intermediate structured alternative: Slot-Based Object-Centric Representations (SBOCR), which group dense features into a finite set of object-like entities. This representation permits to naturally reduce the noise provided to the robotic manipulation policy while keeping enough information to efficiently perform the task. We benchmark a range of global and dense representations against intermediate slot-based representations, across a suite of simulated and real-world manipulation tasks ranging from simple to complex. We evaluate their generalization under diverse visual conditions, including changes in lighting, texture, and the presence of distractors. Our findings reveal that SBOCR-based policies outperform dense and global representation-based policies in generalization settings, even without task-specific pretraining. These insights suggest that SBOCR is a promising direction for designing visual systems that generalize effectively in dynamic, real-world robotic environments.", "AI": {"tldr": "研究提出了一种新的视觉表示方法——槽式对象中心表示（SBOCR），用于改进机器人操作策略的泛化能力。", "motivation": "现有的视觉表征在光照、纹理和干扰物等变化下会导致性能下降，因此需要一种更鲁棒的方法来提高机器人的泛化能力。", "method": "通过将密集特征分组为有限数量的对象实体形成中间结构化的槽式对象中心表示（SBOCR），从而减少噪声并保持足够的信息来进行任务执行。", "result": "实验结果表明，基于SBOCR的策略在不同的视觉条件下比全局和密集表征方法具有更好的泛化能力，且无需特定任务预训练。", "conclusion": "研究证明了槽式对象中心表示（SBOCR）是一种有潜力的方法，在动态、真实世界的机器人环境中设计高效的视觉系统。"}}
{"id": "2601.21414", "pdf": "https://arxiv.org/pdf/2601.21414", "abs": "https://arxiv.org/abs/2601.21414", "authors": ["Chenxu Yang", "Qingyi Si", "Chong Tian", "Xiyu Liu", "Dingyu Yao", "Chuanyu Qin", "Zheng Lin", "Weiping Wang", "Jiaqi Wang"], "title": "System 1&2 Synergy via Dynamic Model Interpolation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Training a unified language model that adapts between intuitive System 1 and deliberative System 2 remains challenging due to interference between their cognitive modes. Recent studies have thus pursued making System 2 models more efficient. However, these approaches focused on output control, limiting what models produce. We argue that this paradigm is misaligned: output length is merely a symptom of the model's cognitive configuration, not the root cause. In this work, we shift the focus to capability control, which modulates \\textit{how models think} rather than \\textit{what they produce}. To realize this, we leverage existing Instruct and Thinking checkpoints through dynamic parameter interpolation, without additional training. Our pilot study establishes that linear interpolation yields a convex, monotonic Pareto frontier, underpinned by representation continuity and structural connectivity. Building on this, we propose \\textbf{DAMI} (\\textbf{D}yn\\textbf{A}mic \\textbf{M}odel \\textbf{I}nterpolation), a framework that estimates a query-specific Reasoning Intensity $λ(q)$ to configure cognitive depth. For training-based estimation, we develop a preference learning method encoding accuracy and efficiency criteria. For zero-shot deployment, we introduce a confidence-based method leveraging inter-model cognitive discrepancy. Experiments on five mathematical reasoning benchmarks demonstrate that DAMI achieves higher accuracy than the Thinking model while remaining efficient, effectively combining the efficiency of System 1 with the reasoning depth of System 2.", "AI": {"tldr": "本文提出了DAMI框架，通过动态参数插值实现系统1和系统2的协同工作，实现在不额外训练的情况下灵活配置模型的认知深度。", "motivation": "现有方法集中在输出控制上，但这种模式仅解决表象问题而非根本原因。为了更好地平衡效率与推理深度，本文提出了一种新的能力调控方法。", "method": "通过动态参数插值结合现有的指令和思考检查点，实现系统1和系统2的协同工作。引入了一个基于查询的认知强度估计函数，并开发了训练基础和零样本部署的方法来估算该函数。", "result": "实验结果表明，DAMI框架在五个数学推理基准测试中实现了比仅用Thinking模型更高的准确性和效率。", "conclusion": "本文提出的动态模型插值方法有效结合了系统1的高效性与系统2的深入推理能力。"}}
{"id": "2601.21413", "pdf": "https://arxiv.org/pdf/2601.21413", "abs": "https://arxiv.org/abs/2601.21413", "authors": ["Andreas Mueller"], "title": "Singularity-Free Lie Group Integration and Geometrically Consistent Evaluation of Multibody System Models Described in Terms of Standard Absolute Coordinates", "categories": ["cs.RO"], "comment": "10 pages", "summary": "A classical approach to the multibody systems (MBS) modeling is to use absolute coordinates, i.e., a set of (possibly redundant) coordinates that describe the absolute position and orientation of the individual bodies with respect to an inertial frame (IFR). A well-known problem for the time integration of the equations of motion (EOM) is the lack of a singularity-free parameterization of spatial motions, which is usually tackled by using unit quaternions. Lie group integration methods were proposed as an alternative approach to the singularity-free time integration. At the same time, Lie group formulations of EOM naturally respect the geometry of spatial motions during integration. Lie group integration methods, operating directly on the configuration space Lie group, are incompatible with standard formulations of the EOM, and cannot be implemented in existing MBS simulation codes without a major restructuring. The contribution of this paper is twofold: (1) A framework for interfacing Lie group integrators to standard EOM formulations is presented. It allows describing MBS in terms of various absolute coordinates and at the same using Lie group integration schemes. (2) A method for consistently incorporating the geometry of rigid body motions into the evaluation of EOM in absolute coordinates integrated with standard vector space integration schemes. The direct product group and the semidirect product group SO(3)xR3 and the semidirect product group SE(3) are used for representing rigid body motions. The key element is the local-global transitions (LGT) transition map, which facilitates the update of (global) absolute coordinates in terms of the (local) coordinates on the Lie group. This LGT map is specific to the absolute coordinates, the local coordinates on the Lie group, and the Lie group used to represent rigid body configurations.", "AI": {"tldr": "该论文提出了一个框架，将李群积分器与标准运动方程（EOM）形式接口化，并提出了一种方法，在使用标准向量空间集成方案时，能够一致地融入刚体运动的几何特性。", "motivation": "经典多体系统建模中存在奇异点的时间积分问题以及现有模拟代码结构限制了李群积分器的应用。因此，论文旨在解决这些问题，实现一种新的接口框架和方法。", "method": "通过使用直接乘积群SO(3)xR3和半直积群SE(3)来表示刚体运动，并提出了局部全局转换（LGT）映射以更新绝对坐标。", "result": "论文成功展示了如何将李群积分器与标准EOM形式接口化，同时在使用标准向量空间集成方案时一致地融入刚体运动的几何特性。", "conclusion": "该研究提出的方法为解决多体系统模型中时间积分问题提供了新的解决方案，并能够应用于现有的模拟代码。"}}
{"id": "2601.21409", "pdf": "https://arxiv.org/pdf/2601.21409", "abs": "https://arxiv.org/abs/2601.21409", "authors": ["Weitao An", "Qi Liu", "Chenghao Xu", "Jiayi Chai", "Xu Yang", "Kun Wei", "Cheng Deng"], "title": "DSCD-Nav: Dual-Stance Cooperative Debate for Object Navigation", "categories": ["cs.RO"], "comment": null, "summary": "Adaptive navigation in unfamiliar indoor environments is crucial for household service robots. Despite advances in zero-shot perception and reasoning from vision-language models, existing navigation systems still rely on single-pass scoring at the decision layer, leading to overconfident long-horizon errors and redundant exploration. To tackle these problems, we propose Dual-Stance Cooperative Debate Navigation (DSCD-Nav), a decision mechanism that replaces one-shot scoring with stance-based cross-checking and evidence-aware arbitration to improve action reliability under partial observability. Specifically, given the same observation and candidate action set, we explicitly construct two stances by conditioning the evaluation on diverse and complementary objectives: a Task-Scene Understanding (TSU) stance that prioritizes goal progress from scene-layout cues, and a Safety-Information Balancing (SIB) stance that emphasizes risk and information value. The stances conduct a cooperative debate and make policy by cross-checking their top candidates with cue-grounded arguments. Then, a Navigation Consensus Arbitration (NCA) agent is employed to consolidate both sides' reasons and evidence, optionally triggering lightweight micro-probing to verify uncertain choices, preserving NCA's primary intent while disambiguating. Experiments on HM3Dv1, HM3Dv2, and MP3D demonstrate consistent improvements in success and path efficiency while reducing exploration redundancy.", "AI": {"tldr": "提出了一种新的决策机制DSCD-Nav，用于改善服务机器人在室内环境中导航的可靠性和效率", "motivation": "现有导航系统存在过度自信的长时错误和冗余探索问题，因此需要一种改进的方法来提高行动可靠性", "method": "通过构造两个具有不同评价目标的立场（TSU和SIB），进行跨验证并用仲裁器整合决策以减少不确定性", "result": "在多个数据集上实验显示DSCD-Nav提高了成功率和路径效率，并减少了探索冗余", "conclusion": "提出的DSCD-Nav机制有效地解决了现有系统中的问题，提升了服务机器人导航的性能"}}
{"id": "2601.21408", "pdf": "https://arxiv.org/pdf/2601.21408", "abs": "https://arxiv.org/abs/2601.21408", "authors": ["Xinan He", "Kaiqing Lin", "Yue Zhou", "Jiaming Zhong", "Wei Ye", "Wenhui Yi", "Bing Fan", "Feng Ding", "Haodong Li", "Bo Cao", "Bin Li"], "title": "MPF-Net: Exposing High-Fidelity AI-Generated Video Forgeries via Hierarchical Manifold Deviation and Micro-Temporal Fluctuations", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid advancement of video generation models such as Veo and Wan, the visual quality of synthetic content has reached a level where macro-level semantic errors and temporal inconsistencies are no longer prominent. However, this does not imply that the distinction between real and cutting-edge high-fidelity fake is untraceable. We argue that AI-generated videos are essentially products of a manifold-fitting process rather than a physical recording. Consequently, the pixel composition logic of consecutive adjacent frames residual in AI videos exhibits a structured and homogenous characteristic. We term this phenomenon `Manifold Projection Fluctuations' (MPF). Driven by this insight, we propose a hierarchical dual-path framework that operates as a sequential filtering process. The first, the Static Manifold Deviation Branch, leverages the refined perceptual boundaries of Large-Scale Vision Foundation Models (VFMs) to capture residual spatial anomalies or physical violations that deviate from the natural real-world manifold (off-manifold). For the remaining high-fidelity videos that successfully reside on-manifold and evade spatial detection, we introduce the Micro-Temporal Fluctuation Branch as a secondary, fine-grained filter. By analyzing the structured MPF that persists even in visually perfect sequences, our framework ensures that forgeries are exposed regardless of whether they manifest as global real-world manifold deviations or subtle computational fingerprints.", "AI": {"tldr": "提出了一种新的方法MPF-Net，用于检测高保真AI生成的视频伪造品", "motivation": "现有高质量合成内容难以通过宏观错误和时间不一致来区分真假。AI生成的视频具有结构化和平滑性特征，因此需要一种新方法来捕捉这种特性下的细微差异", "method": "利用层次化双路径框架，包含静态流形偏差分支和微时空波动分支，分别用于捕获空间异常和细粒度的时间分析", "result": "该框架能够有效检测出高保真AI生成的视频伪造品，即使这些伪造品在视觉上难以区分", "conclusion": "通过MPF-Net可以有效地暴露隐藏在高质量合成视频中的细微缺陷"}}
{"id": "2601.21407", "pdf": "https://arxiv.org/pdf/2601.21407", "abs": "https://arxiv.org/abs/2601.21407", "authors": ["Baiyu Chen", "Yujie Wu", "Siyuan Xu", "Peng Qu", "Dehua Wu", "Xu Chu", "Haodong Bian", "Shuo Zhang", "Bo Xu", "Youhui Zhang", "Zhengyu Ma", "Guoqi Li"], "title": "BrainFuse: a unified infrastructure integrating realistic biological modeling and core AI methodology", "categories": ["cs.NE", "q-bio.NC"], "comment": "21 pages, 7 figures", "summary": "Neuroscience and artificial intelligence represent distinct yet complementary pathways to general intelligence. However, amid the ongoing boom in AI research and applications, the translational synergy between these two fields has grown increasingly elusive-hampered by a widening infrastructural incompatibility: modern AI frameworks lack native support for biophysical realism, while neural simulation tools are poorly suited for gradient-based optimization and neuromorphic hardware deployment. To bridge this gap, we introduce BrainFuse, a unified infrastructure that provides comprehensive support for biophysical neural simulation and gradient-based learning. By addressing algorithmic, computational, and deployment challenges, BrainFuse exhibits three core capabilities: (1) algorithmic integration of detailed neuronal dynamics into a differentiable learning framework; (2) system-level optimization that accelerates customizable ion-channel dynamics by up to 3,000x on GPUs; and (3) scalable computation with highly compatible pipelines for neuromorphic hardware deployment. We demonstrate this full-stack design through both AI and neuroscience tasks, from foundational neuron simulation and functional cylinder modeling to real-world deployment and application scenarios. For neuroscience, BrainFuse supports multiscale biological modeling, enabling the deployment of approximately 38,000 Hodgkin-Huxley neurons with 100 million synapses on a single neuromorphic chip while consuming as low as 1.98 W. For AI, BrainFuse facilitates the synergistic application of realistic biological neuron models, demonstrating enhanced robustness to input noise and improved temporal processing endowed by complex HH dynamics. BrainFuse therefore serves as a foundational engine to facilitate cross-disciplinary research and accelerate the development of next-generation bio-inspired intelligent systems.", "AI": {"tldr": "BrainFuse 是一个统一的基础设施，旨在整合现实生物建模和核心人工智能方法论。", "motivation": "现代 AI 框架缺乏对生物物理真实性的原生支持，而神经模拟工具在梯度优化和类脑硬件部署方面表现不佳。因此需要建立一种能够跨越两者的桥梁。", "method": "通过解决算法、计算和部署方面的挑战，BrainFuse 实现了三个核心能力：将详细的神经元动力学与可微学习框架整合；系统级优化以加速自定义离子通道动力学（在 GPU 上最多提升3000倍）；以及适用于类脑硬件部署的可扩展计算。", "result": "通过基础神经元模拟和功能柱建模到现实世界部署的应用场景，BrainFuse 展示了其全栈设计能力。对于神经科学任务，BrainFuse 支持跨尺度生物建模，并在单个类脑芯片上实现约38,000个霍奇金-赫胥黎神经元及其1亿个突触的部署；对于人工智能应用，BrainFuse 显示了对现实生物模型的应用增强了输入噪声鲁棒性和时间处理能力。", "conclusion": "BrainFuse 是一种基础引擎，旨在促进跨学科研究并加速下一代类脑智能系统的开发。"}}
{"id": "2601.21406", "pdf": "https://arxiv.org/pdf/2601.21406", "abs": "https://arxiv.org/abs/2601.21406", "authors": ["Zihan Su", "Hongyang Wei", "Kangrui Cen", "Yong Wang", "Guanhua Chen", "Chun Yuan", "Xiangxiang Chu"], "title": "Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a single framework. Their ultimate aspiration is to create a cycle where understanding and generation mutually reinforce each other. While recent post-training methods have successfully leveraged understanding to enhance generation, the reverse direction of utilizing generation to improve understanding remains largely unexplored. In this work, we propose UniMRG (Unified Multi-Representation Generation), a simple yet effective architecture-agnostic post-training method. UniMRG enhances the understanding capabilities of UMMs by incorporating auxiliary generation tasks. Specifically, we train UMMs to generate multiple intrinsic representations of input images, namely pixel (reconstruction), depth (geometry), and segmentation (structure), alongside standard visual understanding objectives. By synthesizing these diverse representations, UMMs capture complementary information regarding appearance, spatial relations, and structural layout. Consequently, UMMs develop a deeper and more comprehensive understanding of visual inputs. Extensive experiments across diverse UMM architectures demonstrate that our method notably enhances fine-grained perception, reduces hallucinations, and improves spatial understanding, while simultaneously boosting generation capabilities.", "AI": {"tldr": "通过辅助生成任务提升统一多模态模型的视觉理解能力。", "motivation": "探索利用生成来增强理解的方法，弥补当前研究主要集中在使用理解来提高生成上的不足。", "method": "提出UniMRG架构无偏见后训练方法，使UMMs在学习标准视觉理解目标的同时，也能够生成输入图像的多种内在表示，包括像素、深度和分割。通过这种方式，模型捕捉到关于外观、空间关系及结构布局的互补信息。", "result": "实验证明该方法显著提升了UMMs对细粒度感知的理解能力，减少了幻觉现象，并改善了空间理解力，同时增强了生成能力。", "conclusion": "UniMRG架构在多个UMM体系结构上取得了一致的结果，在利用多表示生成任务中实现了更好的理解和生成性能。"}}
{"id": "2601.21405", "pdf": "https://arxiv.org/pdf/2601.21405", "abs": "https://arxiv.org/abs/2601.21405", "authors": ["Kailash A. Hambarde", "Hugo Proença"], "title": "Rectifying Geometry-Induced Similarity Distortions for Real-World Aerial-Ground Person Re-Identification", "categories": ["cs.CV"], "comment": null, "summary": "Aerial-ground person re-identification (AG-ReID) is fundamentally challenged by extreme viewpoint and distance discrepancies between aerial and ground cameras, which induce severe geometric distortions and invalidate the assumption of a shared similarity space across views. Existing methods primarily rely on geometry-aware feature learning or appearance-conditioned prompting, while implicitly assuming that the geometry-invariant dot-product similarity used in attention mechanisms remains reliable under large viewpoint and scale variations. We argue that this assumption does not hold. Extreme camera geometry systematically distorts the query-key similarity space and degrades attention-based matching, even when feature representations are partially aligned. To address this issue, we introduce Geometry-Induced Query-Key Transformation (GIQT), a lightweight low-rank module that explicitly rectifies the similarity space by conditioning query-key interactions on camera geometry. Rather than modifying feature representations or the attention formulation itself, GIQT adapts the similarity computation to compensate for dominant geometry-induced anisotropic distortions. Building on this local similarity rectification, we further incorporate a geometry-conditioned prompt generation mechanism that provides global, view-adaptive representation priors derived directly from camera geometry. Experiments on four aerial-ground person re-identification benchmarks demonstrate that the proposed framework consistently improves robustness under extreme and previously unseen geometric conditions, while introducing minimal computational overhead compared to state-of-the-art methods.", "AI": {"tldr": "本文提出了Geometry-Induced Query-Key Transformation (GIQT)来修正由极端视角和距离差异引起的几何扭曲，提高跨视图的人重识别精度。", "motivation": "现有方法主要依赖于几何感知特征学习或外观条件提示，但未解决由于极端相机几何导致的查询-键相似性空间扭曲问题。这使得注意力机制在大视角和尺度变化下失效。", "method": "引入了GIQT模块来修正相似性空间，并通过基于相机几何的提示生成机制提供全局适应视图表示先验。", "result": "实验结果显示，提出的框架在四个跨空地人员重识别基准上表现优异且计算开销小。", "conclusion": "本文提出的方法有效提升了极端和未见过的几何条件下的人重识别性能。"}}
{"id": "2601.21403", "pdf": "https://arxiv.org/pdf/2601.21403", "abs": "https://arxiv.org/abs/2601.21403", "authors": ["Ruyi Qi", "Zhou Liu", "Wentao Zhang"], "title": "DataCross: A Unified Benchmark and Agent Framework for Cross-Modal Heterogeneous Data Analysis", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "In real-world data science and enterprise decision-making, critical information is often fragmented across directly queryable structured sources (e.g., SQL, CSV) and \"zombie data\" locked in unstructured visual documents (e.g., scanned reports, invoice images). Existing data analytics agents are predominantly limited to processing structured data, failing to activate and correlate this high-value visual information, thus creating a significant gap with industrial needs. To bridge this gap, we introduce DataCross, a novel benchmark and collaborative agent framework for unified, insight-driven analysis across heterogeneous data modalities. DataCrossBench comprises 200 end-to-end analysis tasks across finance, healthcare, and other domains. It is constructed via a human-in-the-loop reverse-synthesis pipeline, ensuring realistic complexity, cross-source dependency, and verifiable ground truth. The benchmark categorizes tasks into three difficulty tiers to evaluate agents' capabilities in visual table extraction, cross-modal alignment, and multi-step joint reasoning. We also propose the DataCrossAgent framework, inspired by the \"divide-and-conquer\" workflow of human analysts. It employs specialized sub-agents, each an expert on a specific data source, which are coordinated via a structured workflow of Intra-source Deep Exploration, Key Source Identification, and Contextual Cross-pollination. A novel reReAct mechanism enables robust code generation and debugging for factual verification. Experimental results show that DataCrossAgent achieves a 29.7% improvement in factuality over GPT-4o and exhibits superior robustness on high-difficulty tasks, effectively activating fragmented \"zombie data\" for insightful, cross-modal analysis.", "AI": {"tldr": "介绍了一种新的基准和代理框架DataCross，用于异构数据模态的统一、洞察驱动分析", "motivation": "现有数据分析代理主要局限于处理结构化数据，未能激活和关联高价值的视觉信息，存在与工业需求之间的差距", "method": "构建了包含200个端到端分析任务的数据集DataCrossBench，并提出了基于“分而治之”工作流程的人类分析师启发式框架DataCrossAgent，该框架使用专门子代理进行协作处理", "result": "实验结果显示，DataCrossAgent在事实性方面比GPT-4o提高了29.7%，并在高难度任务上表现出色，能够激活碎片化的“僵尸数据”以进行跨模态分析", "conclusion": "通过提出DataCross框架，成功解决了现有数据分析代理处理异构数据模态时存在的挑战"}}
{"id": "2601.21402", "pdf": "https://arxiv.org/pdf/2601.21402", "abs": "https://arxiv.org/abs/2601.21402", "authors": ["Zheqi Dai", "Guangyan Zhang", "Haolin He", "Xiquan Li", "Jingyu Li", "Chunyat Wu", "Yiwen Guo", "Qiuqiang Kong"], "title": "SemanticAudio: Audio Generation and Editing in Semantic Space", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "In recent years, Text-to-Audio Generation has achieved remarkable progress, offering sound creators powerful tools to transform textual inspirations into vivid audio. However, existing models predominantly operate directly in the acoustic latent space of a Variational Autoencoder (VAE), often leading to suboptimal alignment between generated audio and textual descriptions. In this paper, we introduce SemanticAudio, a novel framework that conducts both audio generation and editing directly in a high-level semantic space. We define this semantic space as a compact representation capturing the global identity and temporal sequence of sound events, distinct from fine-grained acoustic details. SemanticAudio employs a two-stage Flow Matching architecture: the Semantic Planner first generates these compact semantic features to sketch the global semantic layout, and the Acoustic Synthesizer subsequently produces high-fidelity acoustic latents conditioned on this semantic plan. Leveraging this decoupled design, we further introduce a training-free text-guided editing mechanism that enables precise attribute-level modifications on general audio without retraining. Specifically, this is achieved by steering the semantic generation trajectory via the difference of velocity fields derived from source and target text prompts. Extensive experiments demonstrate that SemanticAudio surpasses existing mainstream approaches in semantic alignment. Demo available at: https://semanticaudio1.github.io/", "AI": {"tldr": "本文提出了一种新的框架SemanticAudio，它能够在语义空间进行音频生成和编辑。", "motivation": "现有的文本到音频生成模型大多直接在变分自编码器（VAE）的声学潜在空间中操作，导致生成的音频与文本描述之间的对齐不够理想。本文旨在解决这一问题，通过引入一个新的框架来改善这一状况。", "method": "SemanticAudio利用两阶段Flow Matching架构：语义规划器首先生成紧凑的语义特征以勾勒全局语义布局；声学合成器随后根据该语义计划产生高质量的声学潜在表示。此外还引入了一种无需训练即可指导文本引导编辑机制，通过从源和目标文本提示中导出的速度场差异来调整语义生成轨迹。", "result": "实验表明SemanticAudio在语义对齐方面超过了现有主流方法。", "conclusion": "本文提出的SemanticAudio框架能够更精确地将文本描述转化为音频，并且可以通过简单的修改进行编辑，而不必重新训练模型。"}}
{"id": "2601.21394", "pdf": "https://arxiv.org/pdf/2601.21394", "abs": "https://arxiv.org/abs/2601.21394", "authors": ["Leonidas Askianakis", "Aleksandr Artemov"], "title": "Towards Space-Based Environmentally-Adaptive Grasping", "categories": ["cs.RO"], "comment": null, "summary": "Robotic manipulation in unstructured environments requires reliable execution under diverse conditions, yet many state-of-the-art systems still struggle with high-dimensional action spaces, sparse rewards, and slow generalization beyond carefully curated training scenarios. We study these limitations through the example of grasping in space environments. We learn control policies directly in a learned latent manifold that fuses (grammarizes) multiple modalities into a structured representation for policy decision-making. Building on GPU-accelerated physics simulation, we instantiate a set of single-shot manipulation tasks and achieve over 95% task success with Soft Actor-Critic (SAC)-based reinforcement learning in less than 1M environment steps, under continuously varying grasping conditions from step 1. This empirically shows faster convergence than representative state-of-the-art visual baselines under the same open-loop single-shot conditions. Our analysis indicates that explicitly reasoning in latent space yields more sample-efficient learning and improved robustness to novel object and gripper geometries, environmental clutter, and sensor configurations compared to standard baselines. We identify remaining limitations and outline directions toward fully adaptive and generalizable grasping in the extreme conditions of space.", "AI": {"tldr": "本论文研究在空间环境中通过融合多模态信息学习适应性抓取策略，使用GPU加速物理模拟和Soft Actor-Critic（SAC）算法进行强化学习。", "motivation": "当前机器人操作系统难以应对高维度动作空间、稀疏奖励以及训练数据外的泛化问题。研究者希望通过一种新的方法解决这些问题，并实现对各种条件下的快速适应。", "method": "通过GPU加速物理模拟生成一系列单次任务，利用融合多模态信息的学习潜在流形进行决策制定，并采用SAC算法在少于1M环境步骤内完成强化学习。", "result": "研究显示，在持续变化的抓取条件下从第一步开始即实现了超过95%的任务成功率；比现有的视觉基准方法更快地收敛，且具有更好的样本效率和对新型对象及夹具几何形状、环境混乱程度以及传感器配置的适应性。", "conclusion": "本论文展示了在空间极端条件下的快速收敛和高鲁棒性的抓取策略，并指出了进一步提高完全自适应性和泛化的方向。"}}
{"id": "2601.21391", "pdf": "https://arxiv.org/pdf/2601.21391", "abs": "https://arxiv.org/abs/2601.21391", "authors": ["Minjae Cho", "Huy Trong Tran"], "title": "Intrinsic Reward Policy Optimization for Sparse-Reward Environments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Exploration is essential in reinforcement learning as an agent relies on trial and error to learn an optimal policy. However, when rewards are sparse, naive exploration strategies, like noise injection, are often insufficient. Intrinsic rewards can also provide principled guidance for exploration by, for example, combining them with extrinsic rewards to optimize a policy or using them to train subpolicies for hierarchical learning. However, the former approach suffers from unstable credit assignment, while the latter exhibits sample inefficiency and sub-optimality. We propose a policy optimization framework that leverages multiple intrinsic rewards to directly optimize a policy for an extrinsic reward without pretraining subpolicies. Our algorithm -- intrinsic reward policy optimization (IRPO) -- achieves this by using a surrogate policy gradient that provides a more informative learning signal than the true gradient in sparse-reward environments. We demonstrate that IRPO improves performance and sample efficiency relative to baselines in discrete and continuous environments, and formally analyze the optimization problem solved by IRPO. Our code is available at https://github.com/Mgineer117/IRPO.", "AI": {"tldr": "该论文提出了一种利用内在奖励直接优化策略的方法，以解决稀疏奖励环境中探索困难的问题。", "motivation": "在强化学习中，当环境中的回报非常稀疏时，传统的探索方法（如噪音注入）往往不够有效。结合外部和内部奖励虽然能够提供指导但存在信用分配不稳定、样本效率低下的问题。因此，论文旨在提出一种新的策略优化框架来解决这些问题。", "method": "提出了内在奖励策略优化（IRPO），通过使用代理策略梯度代替真实梯度，在稀疏回报环境中为策略提供更精确的学习信号，并且不需要预先训练子策略。", "result": "实验表明，与基准方法相比，IRPO在离散和连续环境中的性能得到了提升，并具有更高的样本效率。同时论文还对优化问题进行了形式化分析。", "conclusion": "IRPO算法有效解决了稀疏奖励环境中探索困难的问题，展示了改进的性能和样本效率。"}}
{"id": "2601.21386", "pdf": "https://arxiv.org/pdf/2601.21386", "abs": "https://arxiv.org/abs/2601.21386", "authors": ["June-Woo Kim", "Dhruv Agarwal", "Federica Cerina"], "title": "Understanding Frechet Speech Distance for Synthetic Speech Quality Evaluation", "categories": ["cs.SD", "cs.AI"], "comment": "accepted to ICASSP 2026", "summary": "Objective evaluation of synthetic speech quality remains a critical challenge. Human listening tests are the gold standard, but costly and impractical at scale. Fréchet Distance has emerged as a promising alternative, yet its reliability depends heavily on the choice of embeddings and experimental settings. In this work, we comprehensively evaluate Fréchet Speech Distance (FSD) and its variant Speech Maximum Mean Discrepancy (SMMD) under varied embeddings and conditions. We further incorporate human listening evaluations alongside TTS intelligibility and synthetic-trained ASR WER to validate the perceptual relevance of these metrics. Our findings show that WavLM Base+ features yield the most stable alignment with human ratings. While FSD and SMMD cannot fully replace subjective evaluation, we show that they can serve as complementary, cost-efficient, and reproducible measures, particularly useful when large-scale or direct listening assessments are infeasible. Code is available at https://github.com/kaen2891/FrechetSpeechDistance.", "AI": {"tldr": "该论文评估了Fréchet Speech Distance(FSD)及其变体Speech Maximum Mean Discrepancy(SMMD)，以确定其在合成语音质量评价中的可靠性和有效性。", "motivation": "客观评估合成语音的质量是一个重大挑战，人类听力测试是黄金标准但成本高昂且不适用于大规模应用。因此，该研究旨在探索Fréchet距离作为替代指标的可行性和可靠性。", "method": "该研究通过不同的嵌入和实验条件来全面评价FSD和SMMD，并结合人工听觉评估、TTS可懂度以及合成训练的ASRWER来验证这些指标的感知相关性。", "result": "研究表明，WavLM Base+特征提供了最稳定的人类评分对齐。尽管FSD和SMMD不能完全替代主观评价，但它们可以作为补充措施，在大规模或直接听觉评估不可行时特别有用。", "conclusion": "该研究证明了FSD和SMMD在特定条件下可以作为成本效益高且可重复的客观指标来辅助合成语音质量评估。"}}
{"id": "2601.21384", "pdf": "https://arxiv.org/pdf/2601.21384", "abs": "https://arxiv.org/abs/2601.21384", "authors": ["Hui Ma", "Qingzhong Li", "Jin Wang", "Jie Wu", "Shaoyu Dou", "Li Feng", "Xinjun Pei"], "title": "Sim-MSTNet: sim2real based Multi-task SpatioTemporal Network Traffic Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "accepted in ICASSP 2026", "summary": "Network traffic forecasting plays a crucial role in intelligent network operations, but existing techniques often perform poorly when faced with limited data. Additionally, multi-task learning methods struggle with task imbalance and negative transfer, especially when modeling various service types. To overcome these challenges, we propose Sim-MSTNet, a multi-task spatiotemporal network traffic forecasting model based on the sim2real approach. Our method leverages a simulator to generate synthetic data, effectively addressing the issue of poor generalization caused by data scarcity. By employing a domain randomization technique, we reduce the distributional gap between synthetic and real data through bi-level optimization of both sample weighting and model training. Moreover, Sim-MSTNet incorporates attention-based mechanisms to selectively share knowledge between tasks and applies dynamic loss weighting to balance task objectives. Extensive experiments on two open-source datasets show that Sim-MSTNet consistently outperforms state-of-the-art baselines, achieving enhanced accuracy and generalization.", "AI": {"tldr": "Sim-MSTNet是一种基于模拟到现实方法的多任务时空网络流量预测模型，旨在解决数据稀缺和任务不平衡问题。", "motivation": "现有的网络流量预测技术在面对少量数据时表现不佳，并且多任务学习方法面临任务不均衡和负向迁移的问题。为了解决这些问题，作者提出了一种新的预测模型Sim-MSTNet。", "method": "通过利用模拟器生成合成数据来解决由于数据稀缺导致的泛化问题，同时采用领域随机化技术减少合成数据与真实数据之间的分布差距，并结合注意力机制和动态损失权重调整以平衡任务目标。", "result": "在两个开源数据集上的广泛实验表明，Sim-MSTNet的表现优于最先进的基准方法，实现了更高的准确性和泛化能力。", "conclusion": "Sim-MSTNet有效解决了网络流量预测中数据稀缺和多任务学习中的任务不平衡问题，并展示了优越的性能。"}}
{"id": "2601.21376", "pdf": "https://arxiv.org/pdf/2601.21376", "abs": "https://arxiv.org/abs/2601.21376", "authors": ["Hongjun Chen", "Huan Zheng", "Wencheng Han", "Jianbing Shen"], "title": "Towards Geometry-Aware and Motion-Guided Video Human Mesh Recovery", "categories": ["cs.CV"], "comment": null, "summary": "Existing video-based 3D Human Mesh Recovery (HMR) methods often produce physically implausible results, stemming from their reliance on flawed intermediate 3D pose anchors and their inability to effectively model complex spatiotemporal dynamics. To overcome these deep-rooted architectural problems, we introduce HMRMamba, a new paradigm for HMR that pioneers the use of Structured State Space Models (SSMs) for their efficiency and long-range modeling prowess. Our framework is distinguished by two core contributions. First, the Geometry-Aware Lifting Module, featuring a novel dual-scan Mamba architecture, creates a robust foundation for reconstruction. It directly grounds the 2D-to-3D pose lifting process with geometric cues from image features, producing a highly reliable 3D pose sequence that serves as a stable anchor. Second, the Motion-guided Reconstruction Network leverages this anchor to explicitly process kinematic patterns over time. By injecting this crucial temporal awareness, it significantly enhances the final mesh's coherence and robustness, particularly under occlusion and motion blur. Comprehensive evaluations on 3DPW, MPI-INF-3DHP, and Human3.6M benchmarks confirm that HMRMamba sets a new state-of-the-art, outperforming existing methods in both reconstruction accuracy and temporal consistency while offering superior computational efficiency.", "AI": {"tldr": "提出了HMRMamba框架，用于视频中的人体网格恢复，提高了重建的准确性与时间一致性。", "motivation": "现有基于视频的三维人体网格恢复方法常产生物理上不合理的结果，因为依赖于错误的中间锚点和复杂时空动态建模不足。", "method": "引入几何感知提升模块和运动引导重建网络，使用结构化状态空间模型以提高长期建模能力，并通过图像特征中的几何线索直接建立2D到3D姿态映射。", "result": "在多个基准测试中表现优异，超越现有方法的重建精度和时间一致性。", "conclusion": "HMRMamba框架有效解决了传统方法的问题，提供了更准确、一致且高效的三维人体网格恢复解决方案。"}}
{"id": "2601.21375", "pdf": "https://arxiv.org/pdf/2601.21375", "abs": "https://arxiv.org/abs/2601.21375", "authors": ["Zheng Li", "Siyao Song", "Jingyuan Ma", "Rui Li", "Ying Zeng", "Minghao Li", "Zhifang Sui"], "title": "TeachBench: A Syllabus-Grounded Framework for Evaluating Teaching Ability in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) show promise as teaching assistants, yet their teaching capability remains insufficiently evaluated. Existing benchmarks mainly focus on problem-solving or problem-level guidance, leaving knowledge-centered teaching underexplored. We propose a syllabus-grounded evaluation framework that measures LLM teaching capability via student performance improvement after multi-turn instruction. By restricting teacher agents to structured knowledge points and example problems, the framework avoids information leakage and enables reuse of existing benchmarks. We instantiate the framework on Gaokao data across multiple subjects. Experiments reveal substantial variation in teaching effectiveness across models and domains: some models perform well in mathematics, while teaching remains challenging in physics and chemistry. We also find that incorporating example problems does not necessarily improve teaching, as models often shift toward example-specific error correction. Overall, our results highlight teaching ability as a distinct and measurable dimension of LLM behavior.", "AI": {"tldr": "提出了一种基于大纲的框架，用于评估大型语言模型的教学能力。", "motivation": "现有的基准主要集中在解决问题或问题层面指导上，而知识中心教学尚未得到充分探索。因此，需要一种新方法来准确评估大型语言模型的教学能力。", "method": "通过限制教师代理到结构化知识点和示例问题，提出了一种基于大纲的框架，该框架避免了信息泄露，并能够重用现有基准。在不同学科的数据上实现了这个框架。", "result": "实验结果显示，在不同的模型和领域中教学效果存在显著差异：某些模型在数学方面表现良好，但在物理和化学方面的教学仍然具有挑战性。同时发现引入示例问题并不一定能提高教学质量，因为模型往往会偏向于特定示例的错误纠正。", "conclusion": "研究结果表明，大型语言模型的教学能力是一个可以衡量的行为维度，未来需要进一步探索如何改进其在不同学科中的教学效果。"}}
{"id": "2601.21372", "pdf": "https://arxiv.org/pdf/2601.21372", "abs": "https://arxiv.org/abs/2601.21372", "authors": ["Yang Song", "Anoushka Vyas", "Zirui Wei", "Sina Khoshfetrat Pakazad", "Henrik Ohlsson", "Graham Neubig"], "title": "NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents", "categories": ["cs.AI"], "comment": null, "summary": "In this paper, we present NEMO, a system that translates Natural-language descriptions of decision problems into formal Executable Mathematical Optimization implementations, operating collaboratively with users or autonomously. Existing approaches typically rely on specialized large language models (LLMs) or bespoke, task-specific agents. Such methods are often brittle, complex and frequently generating syntactically invalid or non-executable code. NEMO instead centers on remote interaction with autonomous coding agents (ACAs), treated as a first-class abstraction analogous to API-based interaction with LLMs. This design enables the construction of higher-level systems around ACAs that structure, consolidate, and iteratively refine task specifications. Because ACAs execute within sandboxed environments, code produced by NEMO is executable by construction, allowing automated validation and repair. Building on this, we introduce novel coordination patterns with and across ACAs, including asymmetric validation loops between independently generated optimizer and simulator implementations (serving as a high-level validation mechanism), external memory for experience reuse, and robustness enhancements via minimum Bayes risk (MBR) decoding and self-consistency. We evaluate NEMO on nine established optimization benchmarks. As depicted in Figure 1, it achieves state-of-the-art performance on the majority of tasks, with substantial margins on several datasets, demonstrating the power of execution-aware agentic architectures for automated optimization modeling.", "AI": {"tldr": "NEMO是一个系统，它通过与自主编码代理（ACA）的协作或独立操作，将自然语言描述的决策问题转换为可执行的数学优化实现。", "motivation": "当前方法依赖于专用的大规模语言模型（LLMs）或特定任务定制的智能体，这些方法往往脆弱、复杂且生成错误的代码。NEMO旨在解决这些问题，通过使用远程交互与ACA构建高层系统，从而提高代码的有效性和可执行性。", "method": "NEMO利用ACA在沙箱环境中执行，确保产生的代码是可执行的，并能进行自动化验证和修复。引入了新型协调模式，包括优化器和模拟器实施之间的非对称校验循环、外部记忆以实现经验重用以及通过最小贝叶斯风险（MBR）解码和自一致性增强系统稳健性。", "result": "在九个已建立的优化基准上进行了评估，NEMO在大多数任务中实现了最先进的性能，并且在几个数据集上的表现有显著提升。", "conclusion": "展示了执行感知代理架构在自动化优化建模中的强大功能。"}}
{"id": "2601.21367", "pdf": "https://arxiv.org/pdf/2601.21367", "abs": "https://arxiv.org/abs/2601.21367", "authors": ["Wenjia Hua", "Kejie Zhao", "Luziwei Leng", "Ran Cheng", "Yuxin Ma", "Qinghai Guo"], "title": "Hebbian Learning with Global Direction", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to ICASSP 2026", "summary": "Backpropagation algorithm has driven the remarkable success of deep neural networks, but its lack of biological plausibility and high computational costs have motivated the ongoing search for alternative training methods. Hebbian learning has attracted considerable interest as a biologically plausible alternative to backpropagation. Nevertheless, its exclusive reliance on local information, without consideration of global task objectives, fundamentally limits its scalability. Inspired by the biological synergy between neuromodulators and local plasticity, we introduce a novel model-agnostic Global-guided Hebbian Learning (GHL) framework, which seamlessly integrates local and global information to scale up across diverse networks and tasks. In specific, the local component employs Oja's rule with competitive learning to ensure stable and effective local updates. Meanwhile, the global component introduces a sign-based signal that guides the direction of local Hebbian plasticity updates. Extensive experiments demonstrate that our method consistently outperforms existing Hebbian approaches. Notably, on large-scale network and complex datasets like ImageNet, our framework achieves the competitive results and significantly narrows the gap with standard backpropagation.", "AI": {"tldr": "提出了一种新的全局导向的赫布学习框架（GHL），结合局部和全局信息以增强大规模网络上的性能。", "motivation": "深度神经网络的成功主要归功于反向传播算法，但该方法缺乏生物学合理性且计算成本高。因此，研究者寻找替代训练方法，并关注赫布学习这种具有生物学合理性的选择。", "method": "引入全局导向的赫布学习框架（GHL），结合局部竞争性学习和全球信号来指导方向更新，提高了局部赫布塑性更新的有效性和稳定性。", "result": "实验证明该方法在大规模网络及复杂数据集上优于现有赫布方法，并显著缩小了与标准反向传播的差距。", "conclusion": "所提出的全局导向赫布学习框架是生物合理且计算效率高的训练方法，适用于多种任务和网络结构。"}}
{"id": "2601.21363", "pdf": "https://arxiv.org/pdf/2601.21363", "abs": "https://arxiv.org/abs/2601.21363", "authors": ["Weidong Huang", "Zhehan Li", "Hangxin Liu", "Biao Hou", "Yao Su", "Jingwen Zhang"], "title": "Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control", "categories": ["cs.RO"], "comment": "ICLR 2026", "summary": "Reinforcement learning (RL) is widely used for humanoid control, with on-policy methods such as Proximal Policy Optimization (PPO) enabling robust training via large-scale parallel simulation and, in some cases, zero-shot deployment to real robots. However, the low sample efficiency of on-policy algorithms limits safe adaptation to new environments. Although off-policy RL and model-based RL have shown improved sample efficiency, the gap between large-scale pretraining and efficient finetuning on humanoids still exists. In this paper, we find that off-policy Soft Actor-Critic (SAC), with large-batch update and a high Update-To-Data (UTD) ratio, reliably supports large-scale pretraining of humanoid locomotion policies, achieving zero-shot deployment on real robots. For adaptation, we demonstrate that these SAC-pretrained policies can be finetuned in new environments and out-of-distribution tasks using model-based methods. Data collection in the new environment executes a deterministic policy while stochastic exploration is instead confined to a physics-informed world model. This separation mitigates the risks of random exploration during adaptation while preserving exploratory coverage for improvement. Overall, the approach couples the wall-clock efficiency of large-scale simulation during pretraining with the sample efficiency of model-based learning during fine-tuning.", "AI": {"tldr": "该论文研究了如何通过大规模预训练和高效的微调来提高人形机器人控制的效率。", "motivation": "当前，强化学习方法在人形机器人的适应性上存在样本效率低的问题，尤其是在新的环境中。本文旨在探索一种结合大规模预训练和高效微调的方法以提升性能。", "method": "论文中采用Soft Actor-Critic(SAC)算法进行大规模预训练，并通过基于模型的学习实现环境变化中的高效微调。", "result": "SAC算法在大规模预训练过程中表现出色，可以实现在真实机器人上的零样本部署。在新的环境中，使用基于模型的方法进行微调也取得了良好效果。", "conclusion": "该方法结合了大规模仿真模拟的高效率以及基于模型学习的样本高效性，在人形机器人的控制上展现出潜力。"}}
{"id": "2601.21362", "pdf": "https://arxiv.org/pdf/2601.21362", "abs": "https://arxiv.org/abs/2601.21362", "authors": ["Miao Zhang", "Guanzhen Wu", "Hao Fang", "Yifei Zhu", "Fangxin Wang", "Ruixiao Zhang", "Jiangchuan Liu"], "title": "ViTMAlis: Towards Latency-Critical Mobile Video Analytics with Vision Transformers", "categories": ["cs.NI", "cs.CV", "cs.MM"], "comment": null, "summary": "Edge-assisted mobile video analytics (MVA) applications are increasingly shifting from using vision models based on convolutional neural networks (CNNs) to those built on vision transformers (ViTs) to leverage their superior global context modeling and generalization capabilities. However, deploying these advanced models in latency-critical MVA scenarios presents significant challenges. Unlike traditional CNN-based offloading paradigms where network transmission is the primary bottleneck, ViT-based systems are constrained by substantial inference delays, particularly for dense prediction tasks where the need for high-resolution inputs exacerbates the inherent quadratic computational complexity of ViTs. To address these challenges, we propose a dynamic mixed-resolution inference strategy tailored for ViT-backboned dense prediction models, enabling flexible runtime trade-offs between speed and accuracy. Building on this, we introduce ViTMAlis, a ViT-native device-to-edge offloading framework that dynamically adapts to network conditions and video content to jointly reduce transmission and inference delays. We implement a fully functional prototype of ViTMAlis on commodity mobile and edge devices. Extensive experiments demonstrate that, compared to state-of-the-art accuracy-centric, content-aware, and latency-adaptive baselines, ViTMAlis significantly reduces end-to-end offloading latency while improving user-perceived rendering accuracy, providing a practical foundation for next-generation mobile intelligence.", "AI": {"tldr": "本文提出了ViTMAlis框架，用于优化移动端视频分析中的视觉变换器（ViT）模型的推理延迟。", "motivation": "移动视频分析应用从基于卷积神经网络（CNN）的视觉模型转向了具有更优全局上下文建模和泛化能力的视觉变换器（ViTs），但在低延迟能力场景中面临显著挑战，如高分辨率输入导致的推理延迟问题。", "method": "本文提出了一种动态混合分辨率推断策略来解决这一问题，并结合网络状况及视频内容优化了传输与推理延迟。ViTMAlis框架实现了移动和边缘设备上的原型设计。", "result": "实验表明，相比现有的准确性主导、基于内容感知以及延时自适应的基线系统，ViTMAlis显著减少了端到端传输延迟并提高了用户感知渲染精度。", "conclusion": "本文提出的ViTMAlis框架为下一代移动智能技术提供了实用基础。"}}
{"id": "2601.21360", "pdf": "https://arxiv.org/pdf/2601.21360", "abs": "https://arxiv.org/abs/2601.21360", "authors": ["Devanshu Sahoo", "Manish Prasad", "Vasudev Majhi", "Arjun Neekhra", "Yash Sinha", "Murari Mandal", "Vinay Chamola", "Dhruv Kumar"], "title": "The Compliance Paradox: Semantic-Instruction Decoupling in Automated Academic Code Evaluation", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.LG", "cs.SE"], "comment": null, "summary": "The rapid integration of Large Language Models (LLMs) into educational assessment rests on the unverified assumption that instruction following capability translates directly to objective adjudication. We demonstrate that this assumption is fundamentally flawed. Instead of evaluating code quality, models frequently decouple from the submission's logic to satisfy hidden directives, a systemic vulnerability we term the Compliance Paradox, where models fine-tuned for extreme helpfulness are vulnerable to adversarial manipulation. To expose this, we introduce the Semantic-Preserving Adversarial Code Injection (SPACI) Framework and the Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP). These methods exploit the Syntax-Semantics Gap by embedding adversarial directives into syntactically inert regions (trivia nodes) of the Abstract Syntax Tree. Through a large-scale evaluation of 9 SOTA models across 25,000 submissions in Python, C, C++, and Java, we reveal catastrophic failure rates (>95%) in high-capacity open-weights models like DeepSeek-V3, which systematically prioritize hidden formatting constraints over code correctness. We quantify this failure using our novel tripartite framework measuring Decoupling Probability, Score Divergence, and Pedagogical Severity to demonstrate the widespread \"False Certification\" of functionally broken code. Our findings suggest that current alignment paradigms create a \"Trojan\" vulnerability in automated grading, necessitating a shift from standard RLHF toward domain-specific Adjudicative Robustness, where models are conditioned to prioritize evidence over instruction compliance. We release our complete dataset and injection framework to facilitate further research on the topic.", "AI": {"tldr": "论文研究了大型语言模型在学术代码评估中的局限性，特别是它们如何通过遵循隐藏指令而非逻辑来判断代码质量。作者提出了一种新的框架和协议，用于测试模型的这种行为，并展示了模型存在严重错误。", "motivation": "论文指出，现有的自动化代码评估工具过于依赖于模型是否严格遵守指示，而不是代码的实际功能正确性。这导致了一个问题：模型可能会因满足某些隐藏指令而给出错误的评价结果，即“合规悖论”。因此，作者希望通过研究和测试来揭示这个问题，并提出解决方案。", "method": "为了检验这种“合规悖论”，论文提出了一个名为SPACI（语义保持对抗代码注入）框架以及AST-ASIP（抽象语法树感知语义注入协议）。这两个方法通过在代码的抽象语法树中插入隐藏指令，来测试模型是否能够正确地判断代码质量。", "result": "通过对9个最先进的模型进行大规模评估，论文发现这些模型在处理含有对抗性指令的代码时存在很高的错误率（超过95%），这表明它们倾向于满足格式规范而非实际的功能正确性。通过提出一种新的三方面框架来量化这种脱钩行为——解耦概率、得分差异和教育严重性。", "conclusion": "研究结果表明，现有的对齐模型在自动化评估中存在严重的脆弱性和潜在的“特洛伊木马”风险。作者建议应该转向领域特定的裁决稳健性，即让模型更注重证据而非指令遵循，并公开了完整的数据集和注入框架以促进进一步的研究。"}}
{"id": "2601.21358", "pdf": "https://arxiv.org/pdf/2601.21358", "abs": "https://arxiv.org/abs/2601.21358", "authors": ["Jiecong Wang", "Hao Peng", "Chunyang Liu"], "title": "Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Chain-of-Thought (CoT) empowers Large Language Models (LLMs) to tackle complex problems, but remains constrained by the computational cost and reasoning path collapse when grounded in discrete token spaces. Recent latent reasoning approaches attempt to optimize efficiency by performing reasoning within continuous hidden states. However, these methods typically operate as opaque end-to-end mappings from explicit reasoning steps to latent states, and often require a pre-defined number of latent steps during inference. In this work, we introduce PLaT (Planning with Latent Thoughts), a framework that reformulates latent reasoning as planning by fundamentally decouple reasoning from verbalization. We model reasoning as a deterministic trajectory of latent planning states, while a separate Decoder grounds these thoughts into text when necessary. This decoupling allows the model to dynamically determine when to terminate reasoning rather than relying on fixed hyperparameters. Empirical results on mathematical benchmarks reveal a distinct trade-off: while PLaT achieves lower greedy accuracy than baselines, it demonstrates superior scalability in terms of reasoning diversity. This indicates that PLaT learns a robust, broader solution space, offering a transparent and scalable foundation for inference-time search.", "AI": {"tldr": "该论文提出了PLaT框架，将链式思考（CoT）的推理与文字表达解耦，通过动态规划提高效率和可扩展性。", "motivation": "传统的链式思考方法在复杂的任务中受到计算成本高以及推理路径崩溃的问题。现有的潜在推理方法虽然试图优化效率但仍然存在问题如固定的预定义步骤限制了灵活性。", "method": "PLaT框架将推理看作是潜在规划状态的确定性轨迹，通过解耦实现动态终止而非依赖于固定超参数，并使用独立解码器在需要时将这些思想转化为文本表达。", "result": "实验证明PLaT虽然在贪心精度上不如基线方法但展示了更好的推理多样性和可扩展性，表明它学习到更广泛的解决方案空间。", "conclusion": "PLaT框架提供了一种透明且可扩展的推理基础，为搜索提供了新的路径。"}}
{"id": "2601.21352", "pdf": "https://arxiv.org/pdf/2601.21352", "abs": "https://arxiv.org/abs/2601.21352", "authors": ["Ziyu Lu", "Tengjin Weng", "Yiying Yang", "Yuhang Zhao", "Xinxin Huang", "Wenhao Jiang"], "title": "BEAP-Agent: Backtrackable Execution and Adaptive Planning for GUI Agents", "categories": ["cs.AI"], "comment": null, "summary": "GUI agents are designed to automate repetitive tasks and enhance productivity. However, existing GUI agents struggle to recover once they follow an incorrect exploration path, often leading to task failure. In this work, we model GUI task execution as a DFS process and propose BEAP-Agent, a DFS-based framework that supports long-range, multi-level state backtracking with dynamic task tracking and updating. The framework consists of three collaborative components: Planner, Executor, and Tracker. Together, they enable effective task exploration and execution. BEAP-Agent fills the gap in systematic backtracking mechanisms for GUI agents, offering a systematic solution for long-horizon task exploration. We conducted a systematic evaluation on the OSWorld benchmark, where BEAP-Agent achieved an accuracy of 28.2%, validating the effectiveness of the proposed method.", "AI": {"tldr": "本文提出了BEAP-Agent框架，用于解决GUI自动化任务中因错误探索路径导致的恢复问题。", "motivation": "现有的GUI代理在跟随错误的探索路径后难以恢复，这可能导致任务失败。因此需要一种系统性的回溯机制来支持长时间的任务探索和执行。", "method": "BEAP-Agent框架通过DFS过程模拟GUI任务执行，并包括三个协作组件：规划器、执行者和追踪器。这些组件共同实现了有效的任务探索与执行。", "result": "在OSWorld基准测试中，BEAP-Agent达到了28.2%的准确率，验证了所提方法的有效性。", "conclusion": "通过引入系统性的回溯机制，BEAP-Agent为GUI自动化任务提供了长期任务探索的有效解决方案。"}}
{"id": "2601.21351", "pdf": "https://arxiv.org/pdf/2601.21351", "abs": "https://arxiv.org/abs/2601.21351", "authors": ["Chendong Song", "Meixuan Wang", "Hang Zhou", "Hong Liang", "Yuan Lyu", "Zixi Chen", "Yuwei Fan", "Zijie Zhou"], "title": "Theoretically Optimal Attention/FFN Ratios in Disaggregated LLM Serving", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to ICML 2026", "summary": "Attention-FFN disaggregation (AFD) is an emerging architecture for LLM decoding that separates state-heavy, KV-cache-dominated Attention computation from stateless, compute-intensive FFN computation, connected by per-step communication. While AFD enables independent scaling of memory and compute resources, its performance is highly sensitive to the Attention/FFN provisioning ratio: mis-sizing induces step-level blocking and costly device idle time. We develop a tractable analytical framework for sizing AFD bundles in an $r$A-$1$F topology, where the key difficulty is that Attention-side work is nonstationary-token context grows and requests are continuously replenished with random lengths-while FFN work is stable given the aggregated batch. Using a probabilistic workload model, we derive closed-form rules for the optimal A/F ratio that maximize average throughput per instance across the system. A trace-calibrated AFD simulator validates the theory: across workloads, the theoretical optimal A/F ratio matches the simulation-optimal within 10%, and consistently reduces idle time.", "AI": {"tldr": "本文开发了一种理论框架，以优化注意力与前馈网络（AFD）架构中的比例关系，从而在LLM解码中最大化每个实例的平均吞吐量。", "motivation": "在注意力-前馈网络拆分（AFD）架构下，由于注意力计算占用大量内存资源而前馈网络计算则更依赖于计算能力，因此独立扩展这些资源时比例不当会导致性能下降。本文旨在通过理论分析找到最优的比例来提升系统整体效率。", "method": "采用概率性工作负载模型，推导出在$r$A-$1$F拓扑结构下最大化平均吞吐量的理论最佳注意力与前馈网络比例规则。并通过校准追踪的AFD模拟器进行验证。", "result": "实验结果显示，理论上最优的比例接近于模拟优化所得结果，并且能有效减少设备闲置时间。", "conclusion": "该研究证明了通过精确调整注意力和前馈网络的比例，可以在LLM解码中显著提高系统性能。"}}
{"id": "2601.21349", "pdf": "https://arxiv.org/pdf/2601.21349", "abs": "https://arxiv.org/abs/2601.21349", "authors": ["Minghao Yang", "Ren Togo", "Guang Li", "Takahiro Ogawa", "Miki Haseyama"], "title": "L2R: Low-Rank and Lipschitz-Controlled Routing for Mixture-of-Experts", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) models scale neural networks by conditionally activating a small subset of experts, where the router plays a central role in determining expert specialization and overall model performance. However, many modern MoE systems still adopt linear routers in raw high-dimensional representation spaces, where representation mismatch, angular concentration, and scale-sensitive scoring can jointly undermine routing discriminability and stable expert specialization. In this work, we propose Low-rank \\& Lipschitz-controlled Routing (L2R), a unified routing framework that reshapes both the routing space and scoring geometry. L2R performs expert assignment in a shared low-rank latent routing space and introduces Saturated Inner-Product Scoring (SIPS) to explicitly control the Lipschitz behavior of routing functions, yielding smoother and more stable routing geometry. In addition, L2R incorporates a parameter-efficient multi-anchor routing mechanism to enhance expert expressiveness. Extensive experiments on a large-scale language MoE model and a vision MoE setting on ImageNet demonstrate that L2R consistently improves routing stability, expert specialization, and overall model performance.", "AI": {"tldr": "提出了一种低秩和Lipschitz受控的混合专家路由框架，改进了现有模型中的路由器问题。", "motivation": "当前许多MoE系统仍然使用线性路由器在原始高维空间中工作，这会导致表示不匹配、角度集中以及评分敏感等问题。这些问题会影响路由的区分性和专家专业化稳定性。", "method": "L2R框架通过引入低秩共享潜在空间和饱和内积评分机制来改进现有模型中的路由器设计，同时加入参数高效的多锚点路由机制增强专家表达能力。", "result": "实验表明，在大规模语言MoE模型以及图像识别任务上，L2R框架能提高路由稳定性和专家专业化水平，并最终提升整体模型性能。", "conclusion": "通过引入低秩共享潜在空间和饱和内积评分机制的L2R框架可以有效解决现有模型中路由器相关的问题并改善整体性能。"}}
{"id": "2601.21348", "pdf": "https://arxiv.org/pdf/2601.21348", "abs": "https://arxiv.org/abs/2601.21348", "authors": ["Thuy Phuong Vu", "Mai Viet Hoang Do", "Minhhuy Le", "Dinh-Cuong Hoang", "Phan Xuan Tan"], "title": "Memorization Control in Diffusion Models from Denoising-centric Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Controlling memorization in diffusion models is critical for applications that require generated data to closely match the training distribution. Existing approaches mainly focus on data centric or model centric modifications, treating the diffusion model as an isolated predictor. In this paper, we study memorization in diffusion models from a denoising centric perspective. We show that uniform timestep sampling leads to unequal learning contributions across denoising steps due to differences in signal to noise ratio, which biases training toward memorization. To address this, we propose a timestep sampling strategy that explicitly controls where learning occurs along the denoising trajectory. By adjusting the width of the confidence interval, our method provides direct control over the memorization generalization trade off. Experiments on image and 1D signal generation tasks demonstrate that shifting learning emphasis toward later denoising steps consistently reduces memorization and improves distributional alignment with training data, validating the generality and effectiveness of our approach.", "AI": {"tldr": "本文从去噪中心视角研究扩散模型中的记忆控制，提出了一种新的时间步采样策略，以减少过度拟合并改善与训练数据的分布匹配。", "motivation": "现有方法主要集中在数据或模型方面来处理扩散模型的记忆问题。然而，这些方法并未充分考虑不同去噪步骤中信号到噪声比率的变化对学习贡献的影响。本文希望通过控制学习在去噪过程中的发生位置来解决这一问题。", "method": "提出了一种新的时间步采样策略，该策略通过调整置信区间的宽度直接控制记忆与泛化之间的权衡。", "result": "实验结果显示，在图像和1D信号生成任务中，将学习重点转移到去噪后期步骤可以减少过度拟合，并提高与训练数据的分布对齐。", "conclusion": "本文的方法通过重新调整学习在去噪过程中的位置来控制记忆问题，证明了其有效性和普适性。"}}
{"id": "2601.21347", "pdf": "https://arxiv.org/pdf/2601.21347", "abs": "https://arxiv.org/abs/2601.21347", "authors": ["Xiuwen Zheng", "Sixun Dong", "Bornali Phukon", "Mark Hasegawa-Johnson", "Chang D. Yoo"], "title": "Towards Robust Dysarthric Speech Recognition: LLM-Agent Post-ASR Correction Beyond WER", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted to ICASSP 2026", "summary": "While Automatic Speech Recognition (ASR) is typically benchmarked by word error rate (WER), real-world applications ultimately hinge on semantic fidelity. This mismatch is particularly problematic for dysarthric speech, where articulatory imprecision and disfluencies can cause severe semantic distortions. To bridge this gap, we introduce a Large Language Model (LLM)-based agent for post-ASR correction: a Judge-Editor over the top-k ASR hypotheses that keeps high-confidence spans, rewrites uncertain segments, and operates in both zero-shot and fine-tuned modes. In parallel, we release SAP-Hypo5, the largest benchmark for dysarthric speech correction, to enable reproducibility and future exploration. Under multi-perspective evaluation, our agent achieves a 14.51% WER reduction alongside substantial semantic gains, including a +7.59 pp improvement in MENLI and +7.66 pp in Slot Micro F1 on challenging samples. Our analysis further reveals that WER is highly sensitive to domain shift, whereas semantic metrics correlate more closely with downstream task performance.", "AI": {"tldr": "该论文提出了一个基于大型语言模型（LLM）的代理，用于自动语音识别后的失语症语音校正。", "motivation": "现有的自动语音识别系统在评估时主要依赖于词错误率指标，但在实际应用中更需要关注的是语义准确性。对于发音不准和不流畅的失语症患者来说，这方面的差距更加明显。", "method": "该论文设计了一种LLM代理来修正ASR后的输出：这个代理对top-k假设进行判断编辑，保留高置信度片段并重写不确定部分，并支持零样本和微调模式。同时发布了一个名为SAP-Hypo5的大型基准数据集。", "result": "通过多角度评估，该方法在WER上减少了14.51%，并在语义指标MENLI和Slot Micro F1上分别提高了7.59个百分点和7.66个百分点。", "conclusion": "研究表明，在面对领域变化时，词错误率（WER）很敏感；而语义度量与下游任务性能的相关性更强。"}}
{"id": "2601.21346", "pdf": "https://arxiv.org/pdf/2601.21346", "abs": "https://arxiv.org/abs/2601.21346", "authors": ["Wei Zuo", "Chengyang Li", "Yikun Wang", "Bingyang Cheng", "Zeyi Ren", "Shuai Wang", "Derrick Wing Kwan Ng", "Yik-Chung Wu"], "title": "HPTune: Hierarchical Proactive Tuning for Collision-Free Model Predictive Control", "categories": ["cs.RO"], "comment": "Accepted by IEEE ICASSP 2026", "summary": "Parameter tuning is a powerful approach to enhance adaptability in model predictive control (MPC) motion planners. However, existing methods typically operate in a myopic fashion that only evaluates executed actions, leading to inefficient parameter updates due to the sparsity of failure events (e.g., obstacle nearness or collision). To cope with this issue, we propose to extend evaluation from executed to non-executed actions, yielding a hierarchical proactive tuning (HPTune) framework that combines both a fast-level tuning and a slow-level tuning. The fast one adopts risk indicators of predictive closing speed and predictive proximity distance, and the slow one leverages an extended evaluation loss for closed-loop backpropagation. Additionally, we integrate HPTune with the Doppler LiDAR that provides obstacle velocities apart from position-only measurements for enhanced motion predictions, thus facilitating the implementation of HPTune. Extensive experiments on high-fidelity simulator demonstrate that HPTune achieves efficient MPC tuning and outperforms various baseline schemes in complex environments. It is found that HPTune enables situation-tailored motion planning by formulating a safe, agile collision avoidance strategy.", "AI": {"tldr": "提出了一种分层主动调整框架HPTune，用于改善模型预测控制中的参数调优。", "motivation": "现有的参数调优方法通常只评估执行的动作，导致由于失败事件稀疏而效率低下。为了解决这个问题，作者提出了评估非执行动作的方法。", "method": "结合了快速级和慢速级调整策略，前者使用预测闭合速度和预测接近距离的风险指标，后者利用扩展的评价损失进行闭环反向传播。此外，该方法与Doppler LiDAR集成以提供障碍物的速度信息。", "result": "在高保真模拟器中进行了大量实验，HPTune证明了有效的MPC调优，并优于多种基线方案，在复杂环境中表现出色。", "conclusion": "HPTune通过制定安全且灵活的避障策略来实现情况适应性的运动规划。"}}
{"id": "2601.21345", "pdf": "https://arxiv.org/pdf/2601.21345", "abs": "https://arxiv.org/abs/2601.21345", "authors": ["Ruiqi Liu", "Boyu Diao", "Zijia An", "Runjie Shao", "Zhulin An", "Fei Wang", "Yongjun Xu"], "title": "Semantic-Guided Dynamic Sparsification for Pre-Trained Model-based Class-Incremental Learning", "categories": ["cs.CV"], "comment": null, "summary": "Class-Incremental Learning (CIL) requires a model to continually learn new classes without forgetting old ones. A common and efficient solution freezes a pre-trained model and employs lightweight adapters, whose parameters are often forced to be orthogonal to prevent inter-task interference. However, we argue that this parameter-constraining method is detrimental to plasticity. To this end, we propose Semantic-Guided Dynamic Sparsification (SGDS), a novel method that proactively guides the activation space by governing the orientation and rank of its subspaces through targeted sparsification. Specifically, SGDS promotes knowledge transfer by encouraging similar classes to share a compact activation subspace, while simultaneously preventing interference by assigning non-overlapping activation subspaces to dissimilar classes. By sculpting class-specific sparse subspaces in the activation space, SGDS effectively mitigates interference without imposing rigid constraints on the parameter space. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SGDS.", "AI": {"tldr": "本论文提出了Semantic-Guided Dynamic Sparsification (SGDS) 方法，用于解决类增量学习中的模型遗忘旧类别问题。", "motivation": "传统的参数约束方法可能限制了模型的可塑性，导致新旧任务之间相互干扰。因此，需要一种新的方法来提高知识迁移同时减少不同类别的干扰。", "method": "提出了一种通过动态稀疏化激活空间的方法SGDS，该方法通过调控子空间的方向和秩，使得相似类别共享紧凑的激活子空间，而不同类别则拥有非重叠的子空间。", "result": "在多个基准数据集上的大量实验表明，提出的SGDS方法取得了最先进的性能。", "conclusion": "本研究证明了Semantic-Guided Dynamic Sparsification 方法能够有效降低类增量学习中的干扰，并且优于传统的参数约束方法。"}}
{"id": "2601.21344", "pdf": "https://arxiv.org/pdf/2601.21344", "abs": "https://arxiv.org/abs/2601.21344", "authors": ["Hassam Tahir", "Faizan Faisal", "Fady Alnajjar", "Muhammad Imran Taj", "Lucia Gordon", "Aila Khan", "Michael Lwin", "Omar Mubin"], "title": "Dynamic Framework for Collaborative Learning: Leveraging Advanced LLM with Adaptive Feedback Mechanisms", "categories": ["cs.AI", "cs.HC", "cs.SE"], "comment": "Publication Link: https://ieeexplore.ieee.org/document/11118419", "summary": "This paper presents a framework for integrating LLM into collaborative learning platforms to enhance student engagement, critical thinking, and inclusivity. The framework employs advanced LLMs as dynamic moderators to facilitate real-time discussions and adapt to learners' evolving needs, ensuring diverse and inclusive educational experiences. Key innovations include robust feedback mechanisms that refine AI moderation, promote reflective learning, and balance participation among users. The system's modular architecture featuring ReactJS for the frontend, Flask for backend operations, and efficient question retrieval supports personalized and engaging interactions through dynamic adjustments to prompts and discussion flows. Testing demonstrates that the framework significantly improves student collaboration, fosters deeper comprehension, and scales effectively across various subjects and user groups. By addressing limitations in static moderation and personalization in existing systems, this work establishes a strong foundation for next-generation AI-driven educational tools, advancing equitable and impactful learning outcomes.", "AI": {"tldr": "提出了一种利用先进LLM的动态协作学习框架，以增强学生参与度、批判性思维和包容性。", "motivation": "为了提高学生在协作学习平台上的互动质量，促进批判性思考及实现教育公平，本研究开发了一个新的框架。", "method": "该框架使用高级LLM作为动态调解者来支持实时讨论，并通过自适应反馈机制改进AI调解。系统采用模块化架构，前端使用ReactJS，后端使用Flask，以支持个性化和互动的体验。", "result": "测试表明，所提出的框架显著提升了学生协作能力、加深了理解并能有效扩展到各种主题和用户组中。", "conclusion": "这项工作克服了现有静态调节和个人化的局限性，并为下一代AI驱动的学习工具奠定了基础。"}}
{"id": "2601.21343", "pdf": "https://arxiv.org/pdf/2601.21343", "abs": "https://arxiv.org/abs/2601.21343", "authors": ["Ellen Xiaoqing Tan", "Shehzaad Dhuliawala", "Jing Xu", "Ping Yu", "Sainbayar Sukhbaatar", "Jason Weston", "Olga Golovneva"], "title": "Self-Improving Pretraining: using post-trained models to pretrain better models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.", "AI": {"tldr": "利用后训练模型预训练更好模型的方法，通过强化学习改进生成内容的质量、安全性和真实性。", "motivation": "保证大规模语言模型的输出在安全性、事实性及整体质量方面的挑战。当前方法依赖于昂贵的数据集和多次微调来解决这些问题，但仍然无法完全纠正预训练阶段学到的问题模式。", "method": "提出一种新预训练方法，通过强化学习改进生成内容。使用一个强后训练模型对候选输出进行评估，并依据质量和安全标准给出奖励。这种方法从基础构建更高质量、更安全和更具事实性的模型。", "result": "实验表明该方法在事实性方面提高36.2%，安全性提高18.5%；整体生成质量的胜率提升高达86.3%。", "conclusion": "新提出的自改进预训练方法能够显著增强大规模语言模型的质量、安全性和真实性。"}}
{"id": "2601.21342", "pdf": "https://arxiv.org/pdf/2601.21342", "abs": "https://arxiv.org/abs/2601.21342", "authors": ["Zhiyong Shen", "Gongpeng Zhao", "Jun Zhou", "Li Yu", "Guandong Kou", "Jichen Li", "Chuanlei Dong", "Zuncheng Li", "Kaimao Li", "Bingkun Wei", "Shicheng Hu", "Wei Xia", "Wenguo Duan"], "title": "Ostrakon-VL: Towards Domain-Expert MLLM for Food-Service and Retail Stores", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have recently achieved substantial progress in general-purpose perception and reasoning. Nevertheless, their deployment in Food-Service and Retail Stores (FSRS) scenarios encounters two major obstacles: (i) real-world FSRS data, collected from heterogeneous acquisition devices, are highly noisy and lack auditable, closed-loop data curation, which impedes the construction of high-quality, controllable, and reproducible training corpora; and (ii) existing evaluation protocols do not offer a unified, fine-grained and standardized benchmark spanning single-image, multi-image, and video inputs, making it challenging to objectively gauge model robustness. To address these challenges, we first develop Ostrakon-VL, an FSRS-oriented MLLM based on Qwen3-VL-8B. Second, we introduce ShopBench, the first public benchmark for FSRS. Third, we propose QUAD (Quality-aware Unbiased Automated Data-curation), a multi-stage multimodal instruction data curation pipeline. Leveraging a multi-stage training strategy, Ostrakon-VL achieves an average score of 60.1 on ShopBench, establishing a new state of the art among open-source MLLMs with comparable parameter scales and diverse architectures. Notably, it surpasses the substantially larger Qwen3-VL-235B-A22B (59.4) by +0.7, and exceeds the same-scale Qwen3-VL-8B (55.3) by +4.8, demonstrating significantly improved parameter efficiency. These results indicate that Ostrakon-VL delivers more robust and reliable FSRS-centric perception and decision-making capabilities. To facilitate reproducible research, we will publicly release Ostrakon-VL and the ShopBench benchmark.", "AI": {"tldr": "开发了一种面向食品服务和零售商店的多模态大语言模型Ostrakon-VL，并提出了一个新的基准测试ShopBench。", "motivation": "当前多模态大语言模型在部署到实际场景时面临数据噪声高且无闭环审计、缺乏统一评估标准等问题，因此需要开发专门针对食品服务和零售商店的高质量训练数据集和标准化基准。", "method": "基于Qwen3-VL-8B构建了FSRS专用多模态大语言模型Ostrakon-VL，并引入了ShopBench作为首个公共基准测试。同时提出了一种质量感知的自动化数据整理管道QUAD，以解决数据噪声问题。", "result": "通过多项指标评估，Ostrakon-VL在ShopBench上获得平均分60.1，超过同规模模型4.8个点，并且优于参数量更大的同类模型7个点。", "conclusion": "研究成果表明Ostrakon-VL具有更强的食品服务和零售商店场景感知及决策能力。"}}
{"id": "2601.21341", "pdf": "https://arxiv.org/pdf/2601.21341", "abs": "https://arxiv.org/abs/2601.21341", "authors": ["Ruiqi Liu", "Boyu Diao", "Zijia An", "Zhulin An", "Fei Wang", "Yongjun Xu"], "title": "Dynamical Adapter Fusion: Constructing A Global Adapter for Pre-Trained Model-based Class-Incremental Learning", "categories": ["cs.CV"], "comment": null, "summary": "Class-Incremental Learning (CIL) requires models to continuously acquire new classes without forgetting previously learned ones. A dominant paradigm involves freezing a pre-trained model and training lightweight, task-specific adapters. However, maintaining task-specific parameters hinders knowledge transfer and incurs high retrieval costs, while naive parameter fusion often leads to destructive interference and catastrophic forgetting. To address these challenges, we propose Dynamical Adapter Fusion (DAF) to construct a single robust global adapter. Grounded in the PAC-Bayes theorem, we derive a fusion mechanism that explicitly integrates three components: the optimized task-specific adapter parameters, the previous global adapter parameters, and the initialization parameters. We utilize the Taylor expansion of the loss function to derive the optimal fusion coefficients, dynamically achieving the best balance between stability and plasticity. Furthermore, we propose a Robust Initialization strategy to effectively capture global knowledge patterns. Experiments on multiple CIL benchmarks demonstrate that DAF achieves state-of-the-art (SOTA) performance.", "AI": {"tldr": "构建用于持续学习的全局适配器，以解决类增量学习中的知识转移和灾难性遗忘问题。", "motivation": "现有的类增量学习方法在维持任务特定参数时面临着知识转移困难及高检索成本的问题。同时，简单地融合这些参数可能导致干扰和灾难性遗忘。因此，需要一种新的机制来平衡稳定性与可塑性，以提高性能。", "method": "提出动态适配器融合（DAF）技术，通过PAC-Bayes定理推导出一个将优化的任务特定适配器参数、先前全局适配器参数和初始化参数整合的融合机制。采用泰勒展开法从损失函数中得出最优融合系数，并设计稳健初始化策略来有效捕获全局知识模式。", "result": "实验结果表明，提出的动态适配器融合（DAF）在多个类增量学习基准测试上达到了最先进的性能。", "conclusion": "通过构建单个强大的全局适配器，DAF成功解决了类增量学习中的关键挑战，并展示了其卓越的泛化能力和持续学习能力。"}}
{"id": "2601.21340", "pdf": "https://arxiv.org/pdf/2601.21340", "abs": "https://arxiv.org/abs/2601.21340", "authors": ["Lang Cao", "Qingyu Chen", "Yue Guo"], "title": "EHR-RAG: Bridging Long-Horizon Structured Electronic Health Records and Large Language Models via Enhanced Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": null, "summary": "Electronic Health Records (EHRs) provide rich longitudinal clinical evidence that is central to medical decision-making, motivating the use of retrieval-augmented generation (RAG) to ground large language model (LLM) predictions. However, long-horizon EHRs often exceed LLM context limits, and existing approaches commonly rely on truncation or vanilla retrieval strategies that discard clinically relevant events and temporal dependencies. To address these challenges, we propose EHR-RAG, a retrieval-augmented framework designed for accurate interpretation of long-horizon structured EHR data. EHR-RAG introduces three components tailored to longitudinal clinical prediction tasks: Event- and Time-Aware Hybrid EHR Retrieval to preserve clinical structure and temporal dynamics, Adaptive Iterative Retrieval to progressively refine queries in order to expand broad evidence coverage, and Dual-Path Evidence Retrieval and Reasoning to jointly retrieves and reasons over both factual and counterfactual evidence. Experiments across four long-horizon EHR prediction tasks show that EHR-RAG consistently outperforms the strongest LLM-based baselines, achieving an average Macro-F1 improvement of 10.76%. Overall, our work highlights the potential of retrieval-augmented LLMs to advance clinical prediction on structured EHR data in practice.", "AI": {"tldr": "本文提出了一种新的框架EHR-RAG，用于准确解释长期结构化的电子健康记录数据。", "motivation": "现有的方法通常依靠截断或常规检索策略，这会丢弃临床相关事件和时间依赖关系。为了应对这些挑战，作者提出了EHR-RAG来解决这些问题。", "method": "EHR-RAG框架包括三个组件：Event-和Time-Aware Hybrid EHR Retrieval、Adaptive Iterative Retrieval 和 Dual-Path Evidence Retrieval and Reasoning。", "result": "实验表明，EHR-RAG在四种长期的电子健康记录预测任务中表现优于最强的基于大语言模型的方法，取得了Macro-F1平均改进10.76%的成绩。", "conclusion": "本文证明了增强的大语言模型在实践中有助于结构化电子健康记录数据上的临床预测。"}}
{"id": "2601.21339", "pdf": "https://arxiv.org/pdf/2601.21339", "abs": "https://arxiv.org/abs/2601.21339", "authors": ["Jennifer Haase", "Jana Gonnermann-Müller", "Paul H. P. Hanel", "Nicolas Leins", "Thomas Kosch", "Jan Mendling", "Sebastian Pokutta"], "title": "Within-Model vs Between-Prompt Variability in Large Language Models for Creative Tasks", "categories": ["cs.AI"], "comment": null, "summary": "How much of LLM output variance is explained by prompts versus model choice versus stochasticity through sampling? We answer this by evaluating 12 LLMs on 10 creativity prompts with 100 samples each (N = 12,000). For output quality (originality), prompts explain 36.43% of variance, comparable to model choice (40.94%). But for output quantity (fluency), model choice (51.25%) and within-LLM variance (33.70%) dominate, with prompts explaining only 4.22%. Prompts are powerful levers for steering output quality, but given the substantial within-LLM variance (10-34%), single-sample evaluations risk conflating sampling noise with genuine prompt or model effects.", "AI": {"tldr": "研究分析了大型语言模型在创意任务中的输出差异，探讨提示词、模型选择和抽样随机性对输出质量与数量的影响。", "motivation": "为了理解提示词、模型选择以及随机采样的波动如何影响大型语言模型的输出，特别是对于创意任务而言。", "method": "使用12种大型语言模型对10个创意任务进行测试，每个任务提供100份样本（N=12,000）。通过分析输出质量和数量来评估不同因素的影响。", "result": "提示词解释了36.43%的输出质量差异，与模型选择影响相似；对于输出量，模型选择和内部波动分别占51.25%和33.7%，而提示词只占4.22%。", "conclusion": "提示词是控制输出质量的有效工具，然而考虑到大型语言模型内部的显著差异（10-34%），单一样本评估可能会将采样噪声误认为真实影响。"}}
{"id": "2601.21338", "pdf": "https://arxiv.org/pdf/2601.21338", "abs": "https://arxiv.org/abs/2601.21338", "authors": ["Ji-Xuan He", "Guohang Zhuang", "Junge Bo", "Tingyi Li", "Chen Ling", "Yanan Qiao"], "title": "SR$^{2}$-Net: A General Plug-and-Play Model for Spectral Refinement in Hyperspectral Image Super-Resolution", "categories": ["cs.CV"], "comment": null, "summary": "HSI-SR aims to enhance spatial resolution while preserving spectrally faithful and physically plausible characteristics. Recent methods have achieved great progress by leveraging spatial correlations to enhance spatial resolution. However, these methods often neglect spectral consistency across bands, leading to spurious oscillations and physically implausible artifacts. While spectral consistency can be addressed by designing the network architecture, it results in a loss of generality and flexibility. To address this issue, we propose a lightweight plug-and-play rectifier, physically priors Spectral Rectification Super-Resolution Network (SR$^{2}$-Net), which can be attached to a wide range of HSI-SR models without modifying their architectures. SR$^{2}$-Net follows an enhance-then-rectify pipeline consisting of (i) Hierarchical Spectral-Spatial Synergy Attention (H-S$^{3}$A) to reinforce cross-band interactions and (ii) Manifold Consistency Rectification (MCR) to constrain the reconstructed spectra to a compact, physically plausible spectral manifold. In addition, we introduce a degradation-consistency loss to enforce data fidelity by encouraging the degraded SR output to match the observed low resolution input. Extensive experiments on multiple benchmarks and diverse backbones demonstrate consistent improvements in spectral fidelity and overall reconstruction quality with negligible computational overhead. Our code will be released upon publication.", "AI": {"tldr": "提出了一种轻量级的插件式修正器SR$^{2}$-Net，用于提高超光谱图像的空间分辨率同时保持其光谱一致性。", "motivation": "现有的HSI-SR方法忽视了频带间的光谱一致性问题，导致重建结果出现不合理的振荡和物理上不可信的现象。为解决这一问题，本文提出了一种插件式的修正器模型以增强网络的通用性和灵活性。", "method": "SR$^{2}$-Net包含层次化光谱空间协同注意力机制(H-S$^{3}$A)来加强频带之间的交互作用，并通过流形一致性修正(MCR)将重建光谱约束在一个紧凑、物理上合理的光谱流形中。此外，还引入了退化一致性损失以确保数据保真度。", "result": "实验结果显示，在多种基准测试和不同网络架构下，SR$^{2}$-Net在光谱忠实性和整体重建质量方面均有显著提升，并且计算开销可以忽略不计。", "conclusion": "通过提出一种通用的插件式修正器模型SR$^{2}$-Net，本文有效地解决了HSI-SR中频带间光谱一致性的问题，并提高了超光谱图像的空间分辨率和重建质量。"}}
{"id": "2601.21337", "pdf": "https://arxiv.org/pdf/2601.21337", "abs": "https://arxiv.org/abs/2601.21337", "authors": ["Xian Shi", "Xiong Wang", "Zhifang Guo", "Yongqi Wang", "Pei Zhang", "Xinyu Zhang", "Zishan Guo", "Hongkun Hao", "Yu Xi", "Baosong Yang", "Jin Xu", "Jingren Zhou", "Junyang Lin"], "title": "Qwen3-ASR Technical Report", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "https://github.com/QwenLM/Qwen3-ASR", "summary": "In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.", "AI": {"tldr": "介绍Qwen3-ASR系列模型，包括两个强大的语音识别模型和一个非自回归的语音强制对齐模型。", "motivation": "为了提升多语言语音识别能力和效率，并在真实场景中表现出色。同时提供开源许可以促进社区研究。", "method": "使用大规模语音训练数据和Qwen3-Omni基础模型的强大音频理解能力构建ASR模型，进行内部评估和公开基准测试；利用LLM基线的非自回归时间戳预测器实现文本-语音对齐。", "result": "1.7B版本在开源ASR模型中达到SOTA性能，并与最强专有API竞争；0.6B版本提供最佳准确性和效率平衡，在并发数为128时可实现实时转录；非自回归强制对准模型表现出色，且在精度和效率方面优于现有方法。", "conclusion": "Qwen3-ASR系列模型通过其优秀的性能、效率及多语言支持展现了强大的语音识别能力。开源许可促进了社区研究进步。"}}
{"id": "2601.21335", "pdf": "https://arxiv.org/pdf/2601.21335", "abs": "https://arxiv.org/abs/2601.21335", "authors": ["Yuzhe Chen", "Jie Cao", "Youquan Wang", "Haicheng Tao", "Darko B. Vukovic", "Jia Wu"], "title": "Modeling Endogenous Logic: Causal Neuro-Symbolic Reasoning Model for Explainable Multi-Behavior Recommendation", "categories": ["cs.AI"], "comment": "Accepted to The Web Conference (WWW) 2026", "summary": "Existing multi-behavior recommendations tend to prioritize performance at the expense of explainability, while current explainable methods suffer from limited generalizability due to their reliance on external information. Neuro-Symbolic integration offers a promising avenue for explainability by combining neural networks with symbolic logic rule reasoning. Concurrently, we posit that user behavior chains inherently embody an endogenous logic suitable for explicit reasoning. However, these observational multiple behaviors are plagued by confounders, causing models to learn spurious correlations. By incorporating causal inference into this Neuro-Symbolic framework, we propose a novel Causal Neuro-Symbolic Reasoning model for Explainable Multi-Behavior Recommendation (CNRE). CNRE operationalizes the endogenous logic by simulating a human-like decision-making process. Specifically, CNRE first employs hierarchical preference propagation to capture heterogeneous cross-behavior dependencies. Subsequently, it models the endogenous logic rule implicit in the user's behavior chain based on preference strength, and adaptively dispatches to the corresponding neural-logic reasoning path (e.g., conjunction, disjunction). This process generates an explainable causal mediator that approximates an ideal state isolated from confounding effects. Extensive experiments on three large-scale datasets demonstrate CNRE's significant superiority over state-of-the-art baselines, offering multi-level explainability from model design and decision process to recommendation results.", "AI": {"tldr": "本文提出了一个结合因果推理的神经符号模型CNRE，用于多行为推荐系统中的可解释性问题", "motivation": "现有推荐系统注重性能而忽视了可解释性；当前可解释方法依赖外部信息，通用性有限。通过引入因果推断增强神经符号集成，可以更好地理解用户的行为逻辑并提供更合理的推荐理由", "method": "CNRE模型首先利用层级偏好传播来捕捉不同行为间的依赖关系，然后基于偏好强度建模用户行为链中的内在逻辑规则，并根据此选择合适的推理路径（如合取或析取），最终生成一个不受混杂因素影响的因果中介以提高可解释性", "result": "在三个大规模数据集上的实验表明，CNRE模型优于现有基线方法，在设计、决策过程和推荐结果上提供了多层次的可解释性", "conclusion": "该研究通过引入因果推理机制成功改善了多行为推荐系统的可解释性问题"}}
{"id": "2601.21334", "pdf": "https://arxiv.org/pdf/2601.21334", "abs": "https://arxiv.org/abs/2601.21334", "authors": ["Pritika Vig", "Ren-Chin Wu", "William Lotter"], "title": "Do Pathology Foundation Models Encode Disease Progression? A Pseudotime Analysis of Visual Representations", "categories": ["cs.CV"], "comment": "21 pages, 17 figures. Appendix included", "summary": "Vision foundation models trained on discretely sampled images achieve strong performance on classification benchmarks, yet whether their representations encode the continuous processes underlying their training data remains unclear. This question is especially pertinent in computational pathology, where we posit that models whose latent representations implicitly capture continuous disease progression may better reflect underlying biology, support more robust generalization, and enable quantitative analyses of features associated with disease transitions. Using diffusion pseudotime, a method developed to infer developmental trajectories from single-cell transcriptomics, we probe whether foundation models organize disease states along coherent progression directions in representation space. Across four cancer progressions and six models, we find that all pathology-specific models recover trajectory orderings significantly exceeding null baselines, with vision-only models achieving the highest fidelities $(τ> 0.78$ on CRC-Serrated). Model rankings by trajectory fidelity on reference diseases strongly predict few-shot classification performance on held-out diseases ($ρ= 0.92$), and exploratory analysis shows cell-type composition varies smoothly along inferred trajectories in patterns consistent with known stromal remodeling. Together, these results demonstrate that vision foundation models can implicitly learn to represent continuous processes from independent static observations, and that trajectory fidelity provides a complementary measure of representation quality beyond downstream performance. While demonstrated in pathology, this framework could be applied to other domains where continuous processes are observed through static snapshots.", "AI": {"tldr": "研究探讨了视觉基础模型是否能够从静态图像中捕捉到疾病进展的连续过程。", "motivation": "探索病理学中，视觉基础模型能否通过其隐含表示捕获疾病的持续进程，并以此更好地反映生物学特征、支持更稳健的一般化和定量分析。", "method": "使用扩散伪时间方法来探究在表征空间中疾病状态是否沿有序进行方向组织，跨四种癌症进展和六种模型进行测试。", "result": "病理特定模型恢复轨迹顺序显著超过空基线，视觉专用模型在CRC-Serrated上实现最高保真度（τ>0.78）。基于参考疾病的轨迹保真度的模型排名可以强烈预测在未见疾病上的零样本分类性能（ρ=0.92）。", "conclusion": "视觉基础模型能够从独立静态观察中隐式学习表示连续过程，提供了一种与下游性能互补的质量评估指标。此框架可以在其他通过静态快照观测到持续进程的领域应用。"}}
{"id": "2601.21323", "pdf": "https://arxiv.org/pdf/2601.21323", "abs": "https://arxiv.org/abs/2601.21323", "authors": ["Achraf Hsain", "Ahmed Abdelkader", "Emmanuel Baldwin Mbaya", "Hamoud Aljamaan"], "title": "Adversarial Vulnerability Transcends Computational Paradigms: Feature Engineering Provides No Defense Against Neural Adversarial Transfer", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Deep neural networks are vulnerable to adversarial examples--inputs with imperceptible perturbations causing misclassification. While adversarial transfer within neural networks is well-documented, whether classical ML pipelines using handcrafted features inherit this vulnerability when attacked via neural surrogates remains unexplored. Feature engineering creates information bottlenecks through gradient quantization and spatial binning, potentially filtering high-frequency adversarial signals. We evaluate this hypothesis through the first comprehensive study of adversarial transfer from DNNs to HOG-based classifiers. Using VGG16 as a surrogate, we generate FGSM and PGD adversarial examples and test transfer to four classical classifiers (KNN, Decision Tree, Linear SVM, Kernel SVM) and a shallow neural network across eight HOG configurations on CIFAR-10. Our results strongly refute the protective hypothesis: all classifiers suffer 16.6%-59.1% relative accuracy drops, comparable to neural-to-neural transfer. More surprisingly, we discover attack hierarchy reversal--contrary to patterns where iterative PGD dominates FGSM within neural networks, FGSM causes greater degradation than PGD in 100% of classical ML cases, suggesting iterative attacks overfit to surrogate-specific features that don't survive feature extraction. Block normalization provides partial but insufficient mitigation. These findings demonstrate that adversarial vulnerability is not an artifact of end-to-end differentiability but a fundamental property of image classification systems, with implications for security-critical deployments across computational paradigms.", "AI": {"tldr": "研究通过使用不同的机器学习模型（包括基于HOG的分类器）检验了深度神经网络中对抗样本迁移性的普遍性。", "motivation": "探讨传统ML流程是否能抵御来自深度学习模型生成的对抗样本攻击，尤其是当这些模型利用手工特征时。", "method": "采用VGG16作为代理模型，通过FGSM和PGD方法生成对抗样本，并测试它们对包括KNN、决策树和支持向量机在内的经典分类器的影响。", "result": "所有经典的机器学习模型在面对神经网络生成的对抗样例时表现出显著的准确率下降，表明手工程特征并不能有效防御此类攻击。此外，FGSM比迭代PGD方法更有效地降低传统模型的性能。", "conclusion": "研究结果说明了对抗样本迁移性是图像分类系统中的一个根本属性，不依赖于深度学习独有的特性，并且影响到基于手工特征的传统ML方法的安全性。"}}
{"id": "2601.21321", "pdf": "https://arxiv.org/pdf/2601.21321", "abs": "https://arxiv.org/abs/2601.21321", "authors": ["Zihao Chen", "Jiayin Wang", "Ziyi Sun", "Ji Zhuang", "Jinyi Shen", "Xiaoyue Ke", "Li Shang", "Xuan Zeng", "Fan Yang"], "title": "White-Box Op-Amp Design via Human-Mimicking Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "This brief proposes \\emph{White-Op}, an interpretable operational amplifier (op-amp) parameter design framework based on the human-mimicking reasoning of large-language-model agents. We formalize the implicit human reasoning mechanism into explicit steps of \\emph{\\textbf{introducing hypothetical constraints}}, and develop an iterative, human-like \\emph{\\textbf{hypothesis-verification-decision}} workflow. Specifically, the agent is guided to introduce hypothetical constraints to derive and properly regulate positions of symbolically tractable poles and zeros, thus formulating a closed-form mathematical optimization problem, which is then solved programmatically and verified via simulation. Theory-simulation result analysis guides the decision-making for refinement. Experiments on 9 op-amp topologies show that, unlike the uninterpretable black-box baseline which finally fails in 5 topologies, White-Op achieves reliable, interpretable behavioral-level designs with only 8.52\\% theoretical prediction error and the design functionality retains after transistor-level mapping for all topologies. White-Op is open-sourced at \\textcolor{blue}{https://github.com/zhchenfdu/whiteop}.", "AI": {"tldr": "提出了一种基于人类模拟推理的大语言模型代理的操作放大器参数设计框架，该框架通过引入假设性约束和迭代验证决策工作流程来实现可解释的设计。", "motivation": "现有操作放大器设计方法难以理解和解释。本文旨在开发一种既可靠又易于理解的新型设计框架。", "method": "利用大型语言模型代理进行人类模仿推理，形式化隐含的人类推理机制，引入假设性约束以调节符号可解的极点和零点位置，形成闭合形式数学优化问题，并通过程序求解和仿真验证来解决问题。理论-仿真结果分析引导决策过程。", "result": "实验表明，在9种操作放大器拓扑中，White-Op实现了可靠、解释性的行为级设计，仅存在8.52%的理论预测误差，并且在晶体管级映射后仍保持功能完整性。相比之下，未经解释的黑盒基线方法最终失败了5个拓扑。", "conclusion": "White-Op通过人类模拟推理提供了可靠、可理解的操作放大器设计框架，在各种操作放大器拓扑中表现出色并实现理论与实践的良好一致性。"}}
{"id": "2601.21320", "pdf": "https://arxiv.org/pdf/2601.21320", "abs": "https://arxiv.org/abs/2601.21320", "authors": ["Keke Tang", "Ziyong Du", "Xiaofei Wang", "Weilong Peng", "Peican Zhu", "Zhihong Tian"], "title": "Optimal Transport-Induced Samples against Out-of-Distribution Overconfidence", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted by ICLR 2026", "summary": "Deep neural networks (DNNs) often produce overconfident predictions on out-of-distribution (OOD) inputs, undermining their reliability in open-world environments. Singularities in semi-discrete optimal transport (OT) mark regions of semantic ambiguity, where classifiers are particularly prone to unwarranted high-confidence predictions. Motivated by this observation, we propose a principled framework to mitigate OOD overconfidence by leveraging the geometry of OT-induced singular boundaries. Specifically, we formulate an OT problem between a continuous base distribution and the latent embeddings of training data, and identify the resulting singular boundaries. By sampling near these boundaries, we construct a class of OOD inputs, termed optimal transport-induced OOD samples (OTIS), which are geometrically grounded and inherently semantically ambiguous. During training, a confidence suppression loss is applied to OTIS to guide the model toward more calibrated predictions in structurally uncertain regions. Extensive experiments show that our method significantly alleviates OOD overconfidence and outperforms state-of-the-art methods.", "AI": {"tldr": "利用最优传输诱导的边界来减少深度神经网络在非分布输入上的过度自信预测。", "motivation": "深度神经网络在处理非分布数据时容易产生高置信度错误预测，这影响了其开放环境中的可靠性。通过半离散最优传输中发现的奇异点来标记分类器对结构不确定区域的过高自信预测。", "method": "基于连续基分布与训练数据嵌入之间的最优传输问题，识别出诱导出来的奇异边界，并据此构造非分布式输入样本集OTIS，以此引导模型在具有结构性不确定性区域进行更准确校准的预测。", "result": "实验结果显示，该方法有效降低了非分布输入上的过度自信预测，优于现有最佳方法。", "conclusion": "通过最优传输诱导出的边界能够减少深度学习模型对非分布输入的过度自信问题，从而提高了其在开放环境中的可靠性。"}}
{"id": "2601.21316", "pdf": "https://arxiv.org/pdf/2601.21316", "abs": "https://arxiv.org/abs/2601.21316", "authors": ["Aoyu Pang", "Maonan Wang", "Zifan Sha", "Wenwei Yue", "Changle Li", "Chung Shue Chen", "Man-On Pun"], "title": "Heterogeneous Vertiport Selection Optimization for On-Demand Air Taxi Services: A Deep Reinforcement Learning Approach", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Urban Air Mobility (UAM) has emerged as a transformative solution to alleviate urban congestion by utilizing low-altitude airspace, thereby reducing pressure on ground transportation networks. To enable truly efficient and seamless door-to-door travel experiences, UAM requires close integration with existing ground transportation infrastructure. However, current research on optimal integrated routing strategies for passengers in air-ground mobility systems remains limited, with a lack of systematic exploration.To address this gap, we first propose a unified optimization model that integrates strategy selection for both air and ground transportation. This model captures the dynamic characteristics of multimodal transport networks and incorporates real-time traffic conditions alongside passenger decision-making behavior. Building on this model, we propose a Unified Air-Ground Mobility Coordination (UAGMC) framework, which leverages deep reinforcement learning (RL) and Vehicle-to-Everything (V2X) communication to optimize vertiport selection and dynamically plan air taxi routes. Experimental results demonstrate that UAGMC achieves a 34\\% reduction in average travel time compared to conventional proportional allocation methods, enhancing overall travel efficiency and providing novel insights into the integration and optimization of multimodal transportation systems. This work lays a solid foundation for advancing intelligent urban mobility solutions through the coordination of air and ground transportation modes. The related code can be found at https://github.com/Traffic-Alpha/UAGMC.", "AI": {"tldr": "提出了一种基于深度强化学习的多模式交通系统集成优化框架，用于选择最优垂直起降机场和动态规划空中出租车路线。", "motivation": "缓解城市拥堵并实现高效无缝的门到门出行体验，需要整合空地交通工具的最佳策略研究。当前在此领域的研究相对有限。", "method": "建立了一个综合优化模型以集成空中和地面交通战略选择，并提出了一种利用深度强化学习和V2X通信技术进行最优垂直起降机场选取及路线规划的UAGMC框架。", "result": "实验结果表明，与传统的比例分配方法相比，该框架在平均出行时间上减少了34%，提高了整体旅行效率。", "conclusion": "这项研究为智能城市交通解决方案的发展奠定了基础，并提供了多模式交通系统集成优化的新见解。"}}
{"id": "2601.21315", "pdf": "https://arxiv.org/pdf/2601.21315", "abs": "https://arxiv.org/abs/2601.21315", "authors": ["Seonghwi Kim", "Sung Ho Jo", "Wooseok Ha", "Minwoo Chae"], "title": "Distributionally Robust Classification for Multi-source Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICLR 2026. 10 pages (excluding references)", "summary": "Unsupervised domain adaptation (UDA) is a statistical learning problem when the distribution of training (source) data is different from that of test (target) data. In this setting, one has access to labeled data only from the source domain and unlabeled data from the target domain. The central objective is to leverage the source data and the unlabeled target data to build models that generalize to the target domain. Despite its potential, existing UDA approaches often struggle in practice, particularly in scenarios where the target domain offers only limited unlabeled data or spurious correlations dominate the source domain. To address these challenges, we propose a novel distributionally robust learning framework that models uncertainty in both the covariate distribution and the conditional label distribution. Our approach is motivated by the multi-source domain adaptation setting but is also directly applicable to the single-source scenario, making it versatile in practice. We develop an efficient learning algorithm that can be seamlessly integrated with existing UDA methods. Extensive experiments under various distribution shift scenarios show that our method consistently outperforms strong baselines, especially when target data are extremely scarce.", "AI": {"tldr": "提出了一种针对多源无监督领域适应问题的分布鲁棒学习框架，以处理训练数据和测试数据分布不同的情况。", "motivation": "现有的UDA方法在面对目标域提供有限未标记数据或来源域存在虚假关联时效果不佳。为解决这些问题，提出了一个既能考虑变量分布又能考虑条件标签分布的不确定性模型。", "method": "提出了一种新的基于分布鲁棒性的学习框架，能够处理多源域适应场景，并且能直接应用于单源领域的情况。开发了一个高效的算法，可以与现有的UDA方法无缝集成。", "result": "在多种分布偏移情景下进行的广泛实验表明，该方法始终优于强基线模型，尤其是在目标数据极其稀缺时表现更佳。", "conclusion": "提出的分布鲁棒学习框架在无监督领域适应问题上展示了卓越的表现，特别是在资源有限的情况下。"}}
{"id": "2601.21314", "pdf": "https://arxiv.org/pdf/2601.21314", "abs": "https://arxiv.org/abs/2601.21314", "authors": ["Yanfeng Li", "Tao Tan", "Qingquan Gao", "Zhiwen Cao", "Xiaohong liu", "Yue Sun"], "title": "HiFi-Mesh: High-Fidelity Efficient 3D Mesh Generation via Compact Autoregressive Dependence", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "High-fidelity 3D meshes can be tokenized into one-dimension (1D) sequences and directly modeled using autoregressive approaches for faces and vertices. However, existing methods suffer from insufficient resource utilization, resulting in slow inference and the ability to handle only small-scale sequences, which severely constrains the expressible structural details. We introduce the Latent Autoregressive Network (LANE), which incorporates compact autoregressive dependencies in the generation process, achieving a $6\\times$ improvement in maximum generatable sequence length compared to existing methods. To further accelerate inference, we propose the Adaptive Computation Graph Reconfiguration (AdaGraph) strategy, which effectively overcomes the efficiency bottleneck of traditional serial inference through spatiotemporal decoupling in the generation process. Experimental validation demonstrates that LANE achieves superior performance across generation speed, structural detail, and geometric consistency, providing an effective solution for high-quality 3D mesh generation.", "AI": {"tldr": "HiFi-Mesh通过引入Latent Autoregressive Network（LANE）和Adaptive Computation Graph Reconfiguration（AdaGraph），提高了高保真3D网格生成的速度和效率。", "motivation": "现有的方法在处理3D网格时存在资源利用率不足的问题，导致推理速度慢且仅能处理小规模序列，这严重限制了结构细节的表达能力。因此，作者引入了LANE以提高生成过程中的自回归依赖性，并通过AdaGraph策略加速推理。", "method": "该方法利用Latent Autoregressive Network（LANE）来实现紧凑的自回归依赖性，在生成过程中进一步提出Adaptive Computation Graph Reconfiguration（AdaGraph）策略，通过时空解耦有效克服传统序列推理效率瓶颈。", "result": "实验结果表明，LANE在生成速度、结构细节和几何一致性方面均取得了卓越性能，并且能够处理的最大可生成序列长度比现有方法提高了6倍。", "conclusion": "该研究提出的方法为高质量3D网格生成提供了一个有效的解决方案。"}}
{"id": "2601.21307", "pdf": "https://arxiv.org/pdf/2601.21307", "abs": "https://arxiv.org/abs/2601.21307", "authors": ["Md Nadim Mahamood", "Md Imran Hasan", "Md Rasheduzzaman", "Ausrukona Ray", "Md Shafi Ud Doula", "Kamrul Hasan"], "title": "Mam-App: A Novel Parameter-Efficient Mamba Model for Apple Leaf Disease Classification", "categories": ["cs.CV"], "comment": "18 Pages, 7 Tables, 5 Figures", "summary": "The rapid growth of the global population, alongside exponential technological advancement, has intensified the demand for food production. Meeting this demand depends not only on increasing agricultural yield but also on minimizing food loss caused by crop diseases. Diseases account for a substantial portion of apple production losses, despite apples being among the most widely produced and nutritionally valuable fruits worldwide. Previous studies have employed machine learning techniques for feature extraction and early diagnosis of apple leaf diseases, and more recently, deep learning-based models have shown remarkable performance in disease recognition. However, most state-of-the-art deep learning models are highly parameter-intensive, resulting in increased training and inference time. Although lightweight models are more suitable for user-friendly and resource-constrained applications, they often suffer from performance degradation. To address the trade-off between efficiency and performance, we propose Mam-App, a parameter-efficient Mamba-based model for feature extraction and leaf disease classification. The proposed approach achieves competitive state-of-the-art performance on the PlantVillage Apple Leaf Disease dataset, attaining 99.58% accuracy, 99.30% precision, 99.14% recall, and a 99.22% F1-score, while using only 0.051M parameters. This extremely low parameter count makes the model suitable for deployment on drones, mobile devices, and other low-resource platforms. To demonstrate the robustness and generalizability of the proposed model, we further evaluate it on the PlantVillage Corn Leaf Disease and Potato Leaf Disease datasets. The model achieves 99.48%, 99.20%, 99.34%, and 99.27% accuracy, precision, recall, and F1-score on the corn dataset and 98.46%, 98.91%, 95.39%, and 97.01% on the potato dataset, respectively.", "AI": {"tldr": "本文提出了一种名为Mam-App的参数高效的Mamba模型，用于苹果叶片疾病的分类。", "motivation": "当前深度学习模型虽然在疾病识别上表现出色，但参数过多导致训练和推理时间增加。轻量级模型虽适合低资源平台应用，但在性能上有欠缺。为了平衡效率与性能，本文提出了一种新的参数高效的Mamba模型。", "method": "作者设计了一个名为Mam-App的参数高效模型，并在PlantVillage苹果叶片疾病数据集上进行训练和测试，以评估其表现。", "result": "实验结果表明，该模型在PlantVillage苹果叶片疾病数据集中达到了99.58%准确率、99.30%精度、99.14%召回率以及99.22%F1分数。同时，在玉米和土豆叶片疾病的测试集上也表现出色。", "conclusion": "Mam-App模型具有极低的参数数量，适合部署在无人机、移动设备等资源受限平台上，并且在多种数据集中显示出了强大的鲁棒性和泛化能力。"}}
{"id": "2601.21306", "pdf": "https://arxiv.org/pdf/2601.21306", "abs": "https://arxiv.org/abs/2601.21306", "authors": ["Wei-Di Chang", "Mikael Henaff", "Brandon Amos", "Gregory Dudek", "Scott Fujimoto"], "title": "The Surprising Difficulty of Search in Model-Based Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper investigates search in model-based reinforcement learning (RL). Conventional wisdom holds that long-term predictions and compounding errors are the primary obstacles for model-based RL. We challenge this view, showing that search is not a plug-and-play replacement for a learned policy. Surprisingly, we find that search can harm performance even when the model is highly accurate. Instead, we show that mitigating distribution shift matters more than improving model or value function accuracy. Building on this insight, we identify key techniques for enabling effective search, achieving state-of-the-art performance across multiple popular benchmark domains.", "AI": {"tldr": "研究基于模型的强化学习中的搜索问题", "motivation": "挑战传统观点，即长时预测和累积错误是基于模型RL的主要障碍。指出即使模型准确，搜索也可能损害性能。强调减轻分布偏移比提高模型或价值函数准确性更重要", "method": "通过关键技巧实现有效的搜索，从而在多个基准域上达到最佳性能", "result": "展示了即便模型高度精确，搜索仍可能降低性能。识别出有效搜索的关键技术", "conclusion": "提出新的见解和方法，以改善基于模型的RL中搜索的有效性"}}
{"id": "2601.21297", "pdf": "https://arxiv.org/pdf/2601.21297", "abs": "https://arxiv.org/abs/2601.21297", "authors": ["Byeongjun Kim", "H. Jin Kim"], "title": "Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter", "categories": ["cs.RO", "eess.SY"], "comment": "Accepted at L4DC 2026", "summary": "We introduce Deep QP Safety Filter, a fully data-driven safety layer for black-box dynamical systems. Our method learns a Quadratic-Program (QP) safety filter without model knowledge by combining Hamilton-Jacobi (HJ) reachability with model-free learning. We construct contraction-based losses for both the safety value and its derivatives, and train two neural networks accordingly. In the exact setting, the learned critic converges to the viscosity solution (and its derivative), even for non-smooth values. Across diverse dynamical systems -- even including a hybrid system -- and multiple RL tasks, Deep QP Safety Filter substantially reduces pre-convergence failures while accelerating learning toward higher returns than strong baselines, offering a principled and practical route to safe, model-free control.", "AI": {"tldr": "本文提出了Deep QP Safety Filter，一种无需模型知识的数据驱动安全层，通过结合HJ可达性与无模型学习来训练QP安全过滤器。", "motivation": "为了在黑盒动态系统中实现更安全、高效的控制策略，设计了一种基于学习的安全滤波器以减少预收敛失败并加快向更高回报的学习过程。", "method": "使用哈密顿-雅可比可达性与无模型学习相结合的方法来训练两个神经网络，并构建收缩损失函数，使得在精确设置下，所学评论者能够收敛于粘性解（及其导数）。", "result": "Deep QP Safety Filter 在各种动态系统和多个RL任务中显著减少了预收敛失败的情况，同时加快了向更高回报的学习过程。", "conclusion": "该方法提供了一种原理性和实用性的途径来实现安全的无模型控制。"}}
{"id": "2601.21296", "pdf": "https://arxiv.org/pdf/2601.21296", "abs": "https://arxiv.org/abs/2601.21296", "authors": ["Shaobo Wang", "Yantai Yang", "Guo Chen", "Peiru Li", "Kaixin Li", "Yufa Zhou", "Zhaorun Chen", "Linfeng Zhang"], "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICLR 2026, 20 pages, 9 figures, 11 tables", "summary": "Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1\\% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.", "AI": {"tldr": "本文提出了一种名为InfoUtil的框架，用于从大规模数据集中生成紧凑且高质量的数据集。", "motivation": "当前的方法在平衡效率和质量方面依赖于启发式方法，并未深入探讨原始数据与合成数据之间的根本关系。因此，该研究旨在通过引入信息性和实用性概念来优化这一过程。", "method": "InfoUtil框架结合了两个关键组件：利用Shapley价值归因从样本中提取重要信息的游戏理论信息最大化以及基于梯度范数选择全局有影响力的样本的原理实用性最大化。", "result": "实验表明，该方法在ImageNet-1K数据集上使用ResNet-18模型时，比前一种最佳方法提高了6.1%的性能。", "conclusion": "通过引入信息性和实用性的概念并结合游戏理论和梯度范数等技术，InfoUtil框架实现了更高效、更具代表性的数据集提取。"}}
{"id": "2601.21293", "pdf": "https://arxiv.org/pdf/2601.21293", "abs": "https://arxiv.org/abs/2601.21293", "authors": ["Changyu Li", "Dingcheng Huang", "Kexuan Yao", "Xiaoya Ni", "Lijuan Shen", "Fei Luo"], "title": "Physics-Guided Tiny-Mamba Transformer for Reliability-Aware Early Fault Warning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to IEEE Transactions on Reliability", "summary": "Reliability-centered prognostics for rotating machinery requires early warning signals that remain accurate under nonstationary operating conditions, domain shifts across speed/load/sensors, and severe class imbalance, while keeping the false-alarm rate small and predictable. We propose the Physics-Guided Tiny-Mamba Transformer (PG-TMT), a compact tri-branch encoder tailored for online condition monitoring. A depthwise-separable convolutional stem captures micro-transients, a Tiny-Mamba state-space branch models near-linear long-range dynamics, and a lightweight local Transformer encodes cross-channel resonances. We derive an analytic temporal-to-spectral mapping that ties the model's attention spectrum to classical bearing fault-order bands, yielding a band-alignment score that quantifies physical plausibility and provides physics-grounded explanations. To ensure decision reliability, healthy-score exceedances are modeled with extreme-value theory (EVT), which yields an on-threshold achieving a target false-alarm intensity (events/hour); a dual-threshold hysteresis with a minimum hold time further suppresses chatter. Under a leakage-free streaming protocol with right-censoring of missed detections on CWRU, Paderborn, XJTU-SY, and an industrial pilot, PG-TMT attains higher precision-recall AUC (primary under imbalance), competitive or better ROC AUC, and shorter mean time-to-detect at matched false-alarm intensity, together with strong cross-domain transfer. By coupling physics-aligned representations with EVT-calibrated decision rules, PG-TMT delivers calibrated, interpretable, and deployment-ready early warnings for reliability-centric prognostics and health management.", "AI": {"tldr": "提出了用于旋转机械可靠性的早期故障预警的物理指导Tiny-Mamba变压器(PG-TMT)，该模型在非平稳操作条件下保持准确性和低误报率。", "motivation": "可靠性中心的预测需要能够在不同的负载、传感器变化和严重的类别不平衡下提供准确的早期警告信号，同时降低错误警报的发生。", "method": "采用了一种紧凑型三分支编码器Tiny-Mamba变压器(PG-TMT)，包括用于捕捉微瞬态的深度可分离卷积茎、建模近线性长期动态的Tiny-Mamba状态空间分支和用于编码跨通道共振的轻量级局部Transformer。通过解析的时间到频率映射，将模型的关注谱与经典轴承故障频带对齐。", "result": "在CWRU、Paderborn、XJTU-SY和工业试点数据集上进行实验，PG-TMT在不平衡条件下达到更高的精度召回率AUC和竞争性或更好的ROC AUC，同时保持较低的误报发生率。", "conclusion": "通过结合物理对齐表示和基于极端值理论校准决策规则，PG-TMT提供了校准、可解释且适合部署的早期预警系统。"}}
{"id": "2601.21291", "pdf": "https://arxiv.org/pdf/2601.21291", "abs": "https://arxiv.org/abs/2601.21291", "authors": ["Jie Tang", "Pingping Xie", "Jian Li", "Ping Tan"], "title": "Gaussian Belief Propagation Network for Depth Completion", "categories": ["cs.CV"], "comment": null, "summary": "Depth completion aims to predict a dense depth map from a color image with sparse depth measurements. Although deep learning methods have achieved state-of-the-art (SOTA), effectively handling the sparse and irregular nature of input depth data in deep networks remains a significant challenge, often limiting performance, especially under high sparsity. To overcome this limitation, we introduce the Gaussian Belief Propagation Network (GBPN), a novel hybrid framework synergistically integrating deep learning with probabilistic graphical models for end-to-end depth completion. Specifically, a scene-specific Markov Random Field (MRF) is dynamically constructed by the Graphical Model Construction Network (GMCN), and then inferred via Gaussian Belief Propagation (GBP) to yield the dense depth distribution. Crucially, the GMCN learns to construct not only the data-dependent potentials of MRF but also its structure by predicting adaptive non-local edges, enabling the capture of complex, long-range spatial dependencies. Furthermore, we enhance GBP with a serial \\& parallel message passing scheme, designed for effective information propagation, particularly from sparse measurements. Extensive experiments demonstrate that GBPN achieves SOTA performance on the NYUv2 and KITTI benchmarks. Evaluations across varying sparsity levels, sparsity patterns, and datasets highlight GBPN's superior performance, notable robustness, and generalizable capability.", "AI": {"tldr": "提出了一种新的深度完成网络GBPN，结合了深度学习和概率图模型。", "motivation": "当前的深度完成方法在处理稀疏且不规则的输入数据时性能受限。为此，文章旨在开发一种能够有效应对高稀疏性的新框架。", "method": "通过构建场景特定的马尔可夫随机场（MRF）并利用高斯信念传播（GBP）进行推理来生成密集深度分布。此外，引入了串行和并行的消息传递机制以促进信息的有效传播。", "result": "GBPN在NYUv2和KITTI数据集上实现了最先进的性能，并显示出对不同稀疏度、模式和数据集的强大鲁棒性和泛化能力。", "conclusion": "提出的GBPN框架不仅提高了深度完成任务的准确性，还展现了良好的适应性和通用性。"}}
{"id": "2601.21288", "pdf": "https://arxiv.org/pdf/2601.21288", "abs": "https://arxiv.org/abs/2601.21288", "authors": ["Weitong Lian", "Zecong Tang", "Haoran Li", "Tianjian Gao", "Yifei Wang", "Zixu Wang", "Lingyi Meng", "Tengju Ru", "Zhejun Cui", "Yichen Zhu", "Hangshuo Cao", "Qi Kang", "Tianxing Chen", "Yusen Qin", "Kaixuan Wang", "Yu Zhang"], "title": "Drive-KD: Multi-Teacher Distillation for VLMs in Autonomous Driving", "categories": ["cs.AI", "cs.CV"], "comment": "Preprint. 23 pages, 14 figures", "summary": "Autonomous driving is an important and safety-critical task, and recent advances in LLMs/VLMs have opened new possibilities for reasoning and planning in this domain. However, large models demand substantial GPU memory and exhibit high inference latency, while conventional supervised fine-tuning (SFT) often struggles to bridge the capability gaps of small models. To address these limitations, we propose Drive-KD, a framework that decomposes autonomous driving into a \"perception-reasoning-planning\" triad and transfers these capabilities via knowledge distillation. We identify layer-specific attention as the distillation signal to construct capability-specific single-teacher models that outperform baselines. Moreover, we unify these single-teacher settings into a multi-teacher distillation framework and introduce asymmetric gradient projection to mitigate cross-capability gradient conflicts. Extensive evaluations validate the generalization of our method across diverse model families and scales. Experiments show that our distilled InternVL3-1B model, with ~42 times less GPU memory and ~11.4 times higher throughput, achieves better overall performance than the pretrained 78B model from the same family on DriveBench, and surpasses GPT-5.1 on the planning dimension, providing insights toward efficient autonomous driving VLMs.", "AI": {"tldr": "提出Drive-KD框架，通过知识蒸馏技术解决自动驾驶领域大型语言/视觉模型的内存消耗和推理延迟问题。", "motivation": "为了克服自动驾驶中大型模型带来的高内存占用与长推理时间，以及小模型在能力上的不足，本文提出了Drive-KD框架。", "method": "将自动驾驶分解为感知-推理-规划三阶段，并通过知识蒸馏转移这些能力。识别出层特定注意力作为蒸馏信号来构建单教师模型并超越基准线；进一步统一成多教师蒸馏框架，并引入不对称梯度投影以缓解跨任务的梯度冲突。", "result": "实验显示，Drive-KD方法在DriveBench测试中表现优于同家族78B预训练模型和GPT-5.1，在规划维度上尤其突出；同时，其内存需求减少了约42倍，吞吐量提高了大约11.4倍。", "conclusion": "本文提出的Drive-KD框架为自动驾驶中的视觉语言模型提供了高效的解决方案，展示了在不同规模模型家族上的广泛适用性。"}}
{"id": "2601.21285", "pdf": "https://arxiv.org/pdf/2601.21285", "abs": "https://arxiv.org/abs/2601.21285", "authors": ["Ruifeng Zhang", "Zexi Huang", "Zikai Wang", "Ke Sun", "Bohang Zheng", "Zhen Ouyang", "Huimin Xie", "Phil Shen", "Junlin Zhang", "Wentao Guo", "Qinglei Wang"], "title": "Zenith: Scaling up Ranking Models for Billion-scale Livestreaming Recommendation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages", "summary": "Accurately capturing feature interactions is essential in recommender systems, and recent trends show that scaling up model capacity could be a key driver for next-level predictive performance. While prior work has explored various model architectures to capture multi-granularity feature interactions, relatively little attention has been paid to efficient feature handling and scaling model capacity without incurring excessive inference latency. In this paper, we address this by presenting Zenith, a scalable and efficient ranking architecture that learns complex feature interactions with minimal runtime overhead. Zenith is designed to handle a few high-dimensional Prime Tokens with Token Fusion and Token Boost modules, which exhibits superior scaling laws compared to other state-of-the-art ranking methods, thanks to its improved token heterogeneity. Its real-world effectiveness is demonstrated by deploying the architecture to TikTok Live, a leading online livestreaming platform that attracts billions of users globally. Our A/B test shows that Zenith achieves +1.05%/-1.10% in online CTR AUC and Logloss, and realizes +9.93% gains in Quality Watch Session / User and +8.11% in Quality Watch Duration / User.", "AI": {"tldr": "该论文提出了一个可扩展且高效的排名架构Zenith，用于处理高维特征交互问题。", "motivation": "当前推荐系统中准确捕捉特征交互至关重要，但很少有关于如何在不增加过多推理延迟的情况下扩大模型容量的研究。因此，本文旨在通过改进的令牌异质性来解决这一问题，并展示其在真实世界中的有效性。", "method": "Zenith架构通过Token Fusion和Token Boost模块处理少量高维Prime Tokens，学习复杂的特征交互，从而实现高效的扩展。", "result": "A/B测试表明，Zenith在线CTR AUC提高了+1.05%，Logloss降低了-1.10%；同时Quality Watch Session/User提高了+9.93%，Quality Watch Duration/User提高了+8.11%。", "conclusion": "Zenith架构在TikTok Live上展现出显著的性能提升，证明其在处理高维特征交互和大规模推荐系统中的有效性。"}}
{"id": "2601.21284", "pdf": "https://arxiv.org/pdf/2601.21284", "abs": "https://arxiv.org/abs/2601.21284", "authors": ["Tianyi Zeng", "Tianyi Wang", "Jiaru Zhang", "Zimo Zeng", "Feiyang Zhang", "Yiming Xu", "Sikai Chen", "Yajie Zou", "Yangyang Wang", "Junfeng Jiao", "Christian Claudel", "Xinbo Chen"], "title": "PILD: Physics-Informed Learning via Diffusion", "categories": ["cs.LG", "cs.AI", "cs.ET", "math.AP"], "comment": null, "summary": "Diffusion models have emerged as powerful generative tools for modeling complex data distributions, yet their purely data-driven nature limits applicability in practical engineering and scientific problems where physical laws need to be followed. This paper proposes Physics-Informed Learning via Diffusion (PILD), a framework that unifies diffusion modeling and first-principles physical constraints by introducing a virtual residual observation sampled from a Laplace distribution to supervise generation during training. To further integrate physical laws, a conditional embedding module is incorporated to inject physical information into the denoising network at multiple layers, ensuring consistent guidance throughout the diffusion process. The proposed PILD framework is concise, modular, and broadly applicable to problems governed by ordinary differential equations, partial differential equations, as well as algebraic equations or inequality constraints. Extensive experiments across engineering and scientific tasks including estimating vehicle trajectories, tire forces, Darcy flow and plasma dynamics, demonstrate that our PILD substantially improves accuracy, stability, and generalization over existing physics-informed and diffusion-based baselines.", "AI": {"tldr": "提出了基于扩散模型的物理信息学习框架PILD，以解决工程和科学问题中的物理定律遵循问题。", "motivation": "现有的纯数据驱动的扩散模型在实际工程和科学应用中存在局限性，因为它们必须遵守物理定律。因此，作者提出了一种将物理规律融入扩散模型的新方法来提升其适用性和性能。", "method": "PILD通过引入来自Laplace分布的虚拟残差观测值对生成过程进行监督，并在去噪网络的多个层次中集成条件嵌入模块以注入物理信息，从而统一了扩散建模和物理第一原理约束。", "result": "实验结果显示，在估计车辆轨迹、轮胎力、达西流动力学和等离子体动态等领域，PILD比现有的基于物理学信息和扩散模型的方法更准确，更具鲁棒性和泛化能力。", "conclusion": "PILD框架简洁且模块化，适用于由常微分方程、偏微分方程以及代数方程或不等式约束控制的问题，显示了其在解决实际工程和科学问题中的优越性。"}}
{"id": "2601.21283", "pdf": "https://arxiv.org/pdf/2601.21283", "abs": "https://arxiv.org/abs/2601.21283", "authors": ["Yisheng Zhong", "Zhengbang Yang", "Zhuangdi Zhu"], "title": "DUET: Distilled LLM Unlearning from an Efficiently Contextualized Teacher", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "LLM unlearning is a technique to remove the impacts of undesirable knowledge from the model without retraining from scratch, which is indispensable towards trustworthy AI. Existing unlearning methods face significant limitations: conventional tuning-based unlearning is computationally heavy and prone to catastrophic forgetting. In contrast, in-contextualized unlearning is lightweight for precise unlearning but vulnerable to prompt removal or reverse engineering attacks. In response, we propose Distilled Unlearning from an Efficient Teacher (DUET), a novel distillation-based unlearning method that combines the merits of these two lines of work. It learns a student model to imitate the behavior of a prompt-steered teacher that effectively refuses undesirable knowledge generation while preserving general domain knowledge. Extensive evaluations on existing benchmarks with our enriched evaluation protocols demonstrate that DUET achieves higher performance in both forgetting and utility preservation, while being orders of magnitude more data-efficient than state-of-the-art unlearning methods.", "AI": {"tldr": "提出了一种新的基于蒸馏的去学习方法DUET，结合了传统调优和上下文化去学习的优点，能够在去除模型中的不良知识的同时保持其性能。", "motivation": "现有的去学习方法存在计算量大、易遗忘等问题。为此，提出了一个新的方法来克服这些问题。", "method": "通过引入一个由提示驱动的教师模型引导的学生模型，该学生模型能够拒绝生成不良的知识同时保留通用领域的知识。", "result": "在现有基准上的实验表明，DUET相比现有的去学习方法，在避免遗忘和保持性能方面表现更好，并且数据效率高得多。", "conclusion": "提出的DUET是一个有效的方法，能够在去除不良信息的同时保持模型的性能，这对于可信赖的人工智能非常重要。"}}
{"id": "2601.21282", "pdf": "https://arxiv.org/pdf/2601.21282", "abs": "https://arxiv.org/abs/2601.21282", "authors": ["Rishi Upadhyay", "Howard Zhang", "Jim Solomon", "Ayush Agrawal", "Pranay Boreddy", "Shruti Satya Narayana", "Yunhao Ba", "Alex Wong", "Celso M de Melo", "Achuta Kadambi"], "title": "WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models", "categories": ["cs.CV"], "comment": "Webpage: https://world-bench.github.io/", "summary": "Recent advances in generative foundational models, often termed \"world models,\" have propelled interest in applying them to critical tasks like robotic planning and autonomous system training. For reliable deployment, these models must exhibit high physical fidelity, accurately simulating real-world dynamics. Existing physics-based video benchmarks, however, suffer from entanglement, where a single test simultaneously evaluates multiple physical laws and concepts, fundamentally limiting their diagnostic capability. We introduce WorldBench, a novel video-based benchmark specifically designed for concept-specific, disentangled evaluation, allowing us to rigorously isolate and assess understanding of a single physical concept or law at a time. To make WorldBench comprehensive, we design benchmarks at two different levels: 1) an evaluation of intuitive physical understanding with concepts such as object permanence or scale/perspective, and 2) an evaluation of low-level physical constants and material properties such as friction coefficients or fluid viscosity. When SOTA video-based world models are evaluated on WorldBench, we find specific patterns of failure in particular physics concepts, with all tested models lacking the physical consistency required to generate reliable real-world interactions. Through its concept-specific evaluation, WorldBench offers a more nuanced and scalable framework for rigorously evaluating the physical reasoning capabilities of video generation and world models, paving the way for more robust and generalizable world-model-driven learning.", "AI": {"tldr": "本文介绍了WorldBench，一个用于诊断评估世界模型物理准确性的新基准。", "motivation": "现有基于视频的物理基准存在纠缠问题，无法独立评估单一物理概念或定律的理解。因此，作者设计了WorldBench以解决这一挑战，并为更严格地测试视频生成和世界模型提供了框架。", "method": "通过在两个不同层次上设计基准：直观物理理解的概念评价（如物体永久性）及低级物理常数的材料属性评价（例如摩擦系数或流体黏度）。对最先进的基于视频的世界模型进行评估，揭示了它们在特定物理概念上的不足之处。", "result": "所有测试的模型都无法产生可靠的现实世界交互，表明需要更高的物理一致性。WorldBench提供了更细致和可扩展的方法来评测世界模型的物理推理能力。", "conclusion": "本文通过引入WorldBench解决了现有视频基准的限制，为评估世界模型提供了一个更具诊断性的方法。"}}
{"id": "2601.21280", "pdf": "https://arxiv.org/pdf/2601.21280", "abs": "https://arxiv.org/abs/2601.21280", "authors": ["Dong Chen", "Ruoyu Li", "Xinyan Zhang", "Jialei Xu", "Ruoseng Zhao", "Zhikang Zhang", "Lingyun Li", "Zizhuang Wei"], "title": "Token Entropy Regularization for Multi-modal Antenna Affiliation Identification", "categories": ["cs.CV"], "comment": null, "summary": "Accurate antenna affiliation identification is crucial for optimizing and maintaining communication networks. Current practice, however, relies on the cumbersome and error-prone process of manual tower inspections. We propose a novel paradigm shift that fuses video footage of base stations, antenna geometric features, and Physical Cell Identity (PCI) signals, transforming antenna affiliation identification into multi-modal classification and matching tasks. Publicly available pretrained transformers struggle with this unique task due to a lack of analogous data in the communications domain, which hampers cross-modal alignment. To address this, we introduce a dedicated training framework that aligns antenna images with corresponding PCI signals. To tackle the representation alignment challenge, we propose a novel Token Entropy Regularization module in the pretraining stage. Our experiments demonstrate that TER accelerates convergence and yields significant performance gains. Further analysis reveals that the entropy of the first token is modality-dependent. Code will be made available upon publication.", "AI": {"tldr": "提出了基于Token熵正则化的多模态天线归属识别方法。", "motivation": "准确的天线归属识别对于优化和维护通信网络至关重要，但现有依赖手动塔检的方法繁琐且易出错。", "method": "提出了一种融合基站视频、天线几何特征以及物理小区标识信号（PCI）的多模态分类与匹配方法，并引入了Token熵正则化模块以解决跨模态对齐问题。", "result": "实验显示TER加速收敛并带来显著性能提升，进一步分析表明第一令牌的熵与模式相关。", "conclusion": "该方法有效解决了天线归属识别中的多模态数据对齐难题，并展示了良好的应用前景。"}}
{"id": "2601.21279", "pdf": "https://arxiv.org/pdf/2601.21279", "abs": "https://arxiv.org/abs/2601.21279", "authors": ["Zhengzheng Tang"], "title": "NEXUS: Bit-Exact ANN-to-SNN Equivalence via Neuromorphic Gate Circuits with Surrogate-Free Training", "categories": ["cs.NE", "cs.AI"], "comment": "7 pages, 6 tables, 2 figures. Preprint (January 28, 2026)", "summary": "Spiking Neural Networks (SNNs) promise energy-efficient computing through event-driven sparsity, yet all existing approaches sacrifice accuracy by approximating continuous values with discrete spikes. We propose NEXUS, a framework that achieves bit-exact ANN-to-SNN equivalence -- not approximate, but mathematically identical outputs. Our key insight is constructing all arithmetic operations, both linear and nonlinear, from pure IF neuron logic gates that implement IEEE-754 compliant floating-point arithmetic. Through spatial bit encoding (zero encoding error by construction), hierarchical neuromorphic gate circuits (from basic logic gates to complete transformer layers), and surrogate-free STE training (exact identity mapping rather than heuristic approximation), NEXUS produces outputs identical to standard ANNs up to machine precision. Experiments on models up to LLaMA-2 70B demonstrate identical task accuracy (0.00\\% degradation) with mean ULP error of only 6.19, while achieving 27-168,000$\\times$ energy reduction on neuromorphic hardware. Crucially, spatial bit encoding's single-timestep design renders the framework inherently immune to membrane potential leakage (100\\% accuracy across all decay factors $β\\in[0.1,1.0]$), while tolerating synaptic noise up to $σ=0.2$ with >98\\% gate-level accuracy.", "AI": {"tldr": "NEXUS框架实现了精确的ANN到SNN转换，保证了输出与标准ANN完全一致。", "motivation": "现有的SNN方法通过离散脉冲近似连续值牺牲了精度。本文旨在构建一个无需近似的精确等效框架。", "method": "通过构造纯IF神经元逻辑门实现IEEE-754浮点运算，结合空间比特编码、层次化神经形态电路及无代理训练来达到ANN到SNN的完全一致转换。", "result": "实验表明NEXUS在LLaMA-2 70B模型上保持了相同的任务精度（0.00%下降），平均ULP误差仅为6.19，同时能耗降低27至168,000倍。此外，该框架对膜电位泄漏和突触噪声具有鲁棒性。", "conclusion": "NEXUS成功实现了ANN到SNN的精确转换，并在能源效率上取得了显著提升，适用于各种衰减因子及突触噪声环境。"}}
{"id": "2601.21278", "pdf": "https://arxiv.org/pdf/2601.21278", "abs": "https://arxiv.org/abs/2601.21278", "authors": ["Mohit Talreja", "Joshua Diao", "Jim Thannikary James", "Radu Casapu", "Tejas Santanam", "Ethan Mendes", "Alan Ritter", "Wei Xu", "James Hays"], "title": "GeoRC: A Benchmark for Geolocation Reasoning Chains", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision Language Models (VLMs) are good at recognizing the global location of a photograph -- their geolocation prediction accuracy rivals the best human experts. But many VLMs are startlingly bad at explaining which image evidence led to their prediction, even when their location prediction is correct. The reasoning chains produced by VLMs frequently hallucinate scene attributes to support their location prediction (e.g. phantom writing, imagined infrastructure, misidentified flora). In this paper, we introduce the first benchmark for geolocation reasoning chains. We focus on the global location prediction task in the popular GeoGuessr game which draws from Google Street View spanning more than 100 countries. We collaborate with expert GeoGuessr players, including the reigning world champion, to produce 800 ground truth reasoning chains for 500 query scenes. These expert reasoning chains address hundreds of different discriminative visual attributes such as license plate shape, architecture, and soil properties to name just a few. We evaluate LLM-as-a-judge and VLM-as-a-judge strategies for scoring VLM-generated reasoning chains against our expert reasoning chains and find that Qwen 3 LLM-as-a-judge correlates best with human scoring. Our benchmark reveals that while large, closed-source VLMs such as Gemini and GPT 5 rival human experts at prediction locations, they still lag behind human experts when it comes to producing auditable reasoning chains. Open weights VLMs such as Llama and Qwen catastrophically fail on our benchmark -- they perform only slightly better than a baseline in which an LLM hallucinates a reasoning chain with oracle knowledge of the photo location but no visual information at all. We believe the gap between human experts and VLMs on this task points to VLM limitations at extracting fine-grained visual attributes from high resolution images.", "AI": {"tldr": "介绍了一个用于评估视觉语言模型（VLM）在解释地理位置预测准确性方面的基准测试GeoRC。", "motivation": "尽管现有的视觉语言模型可以准确地识别照片的全球位置，但它们在解释哪些图像证据支持其预测方面表现不佳。为此，研究人员希望通过建立一个专门针对地理定位推理链的基准来解决这个问题。", "method": "研究者通过与专家合作，生成了800个地面真实推理链条用于500个查询场景，并评估了多种LLM和VLM作为评分器的方法。", "result": "大型封闭源代码视觉语言模型在地理位置预测准确性方面可媲美人类专家，但在生成合理的解释性推理链时仍表现欠佳。开放权重的视觉语言模型的表现则远不如预期。", "conclusion": "该研究揭示了视觉语言模型在提取高分辨率图像中的细粒度视觉属性方面的局限性，并强调需要改进以更好地匹配人类专家的能力。"}}
{"id": "2601.21276", "pdf": "https://arxiv.org/pdf/2601.21276", "abs": "https://arxiv.org/abs/2601.21276", "authors": ["Haoming Huang", "Pongchai Jaisri", "Shota Shimizu", "Lingfeng Chen", "Sota Nakashima", "Gema Rodríguez-Pérez"], "title": "More Code, Less Reuse: Investigating Code Quality and Reviewer Sentiment towards AI-generated Pull Requests", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "Accepted to MSR 2026", "summary": "Large Language Model (LLM) Agents are advancing quickly, with the increasing leveraging of LLM Agents to assist in development tasks such as code generation. While LLM Agents accelerate code generation, studies indicate they may introduce adverse effects on development. However, existing metrics solely measure pass rates, failing to reflect impacts on long-term maintainability and readability, and failing to capture human intuitive evaluations of PR. To increase the comprehensiveness of this problem, we investigate and evaluate the characteristics of LLM to know the pull requests' characteristics beyond the pass rate. We observe the code quality and maintainability within PRs based on code metrics to evaluate objective characteristics and developers' reactions to the pull requests from both humans and LLM's generation. Evaluation results indicate that LLM Agents frequently disregard code reuse opportunities, resulting in higher levels of redundancy compared to human developers. In contrast to the quality issues, our emotions analysis reveals that reviewers tend to express more neutral or positive emotions towards AI-generated contributions than human ones. This disconnect suggests that the surface-level plausibility of AI code masks redundancy, leading to the silent accumulation of technical debt in real-world development environments. Our research provides insights for improving human-AI collaboration.", "AI": {"tldr": "研究LLM生成的代码质量及其对开发人员的影响，发现AI生成的pull请求虽然表面看起来合理但存在冗余问题，导致技术债务积累。", "motivation": "现有评估指标仅关注通过率，未能全面反映长期维护性和可读性。希望通过深入分析PR特性来改善人类与AI的合作。", "method": "基于代码度量和情绪分析评价LLM生成的pull请求特征，对比人工开发者的反应。", "result": "发现LLM倾向于忽视代码复用机会，产生更多冗余；同时评审者对AI贡献的情绪更偏向中性和积极。", "conclusion": "研究揭示了AI代码表面合理性掩盖冗余问题的现象，提供了改善人类与AI协作的见解。"}}
{"id": "2601.21271", "pdf": "https://arxiv.org/pdf/2601.21271", "abs": "https://arxiv.org/abs/2601.21271", "authors": ["Tram Thi Minh Tran", "Soojeong Yoo", "Oliver Weidlich", "Yidan Cao", "Xinyan Yu", "Xin Cheng", "Yin Ye", "Natalia Gulbransen-Diaz", "Callum Parker"], "title": "Envisioning Audio Augmented Reality in Everyday Life", "categories": ["cs.HC"], "comment": null, "summary": "While visual augmentation dominates the augmented reality landscape, devices like Meta Ray-Ban audio smart glasses signal growing industry movement toward audio augmented reality (AAR). Hearing is a primary channel for sensing context, anticipating change, and navigating social space, yet AAR's everyday potential remains underexplored. We address this gap through a collaborative autoethnography (N=5, authoring) and an online survey (N=74). We identify ten roles for AAR, grouped into three categories: task- and utility-oriented, emotional and social, and perceptual collaborator. These roles are further layered with a rhythmic and embodied collaborator framing, mapping them onto micro-, meso-, and macro-rhythms of everyday life. Our analysis surfaces nuanced tensions, such as blocking distractions without erasing social presence, highlighting the need for context-aware design. This paper contributes a foundational and forward-looking framework for AAR in everyday life, providing design groundwork for systems attuned to daily routines, sensory engagement, and social expectations.", "AI": {"tldr": "本文探讨了在日常生活中音频增强现实（AAR）的潜在用途，通过协作自传和在线调查确定其角色框架。", "motivation": "听觉是感知环境、预测变化和社会导航的主要途径，但在日常生活中的音频增强现实(AAR)潜力尚未充分开发。作者旨在填补这一空白，并提出设计基础框架以适应日常生活的感官参与和社会期望。", "method": "通过协作自传（N=5）和在线调查（N=74），识别了AAR的十个角色并将其分为任务实用、情感社交和感知合作者三个类别，进一步构建其与日常生活微观节奏的关系。", "result": "文章确定了十种不同的音频增强现实角色，并通过这些角色探索了日常生活的不同方面。发现了一些设计中的紧张关系，如如何在不消除社会存在感的情况下屏蔽干扰。", "conclusion": "本文提供了有关日常生活中AAR的基础和前瞻性的框架，为适应日常生活节奏、感官参与和社会期望的系统设计奠定了基础。"}}
{"id": "2601.21269", "pdf": "https://arxiv.org/pdf/2601.21269", "abs": "https://arxiv.org/abs/2601.21269", "authors": ["Jianglong Li", "Jun Xu", "Bingcong Lu", "Zhengxue Cheng", "Hongwei Hu", "Ronghua Wu", "Li Song"], "title": "Lightweight High-Fidelity Low-Bitrate Talking Face Compression for 3D Video Conference", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The demand for immersive and interactive communication has driven advancements in 3D video conferencing, yet achieving high-fidelity 3D talking face representation at low bitrates remains a challenge. Traditional 2D video compression techniques fail to preserve fine-grained geometric and appearance details, while implicit neural rendering methods like NeRF suffer from prohibitive computational costs. To address these challenges, we propose a lightweight, high-fidelity, low-bitrate 3D talking face compression framework that integrates FLAME-based parametric modeling with 3DGS neural rendering. Our approach transmits only essential facial metadata in real time, enabling efficient reconstruction with a Gaussian-based head model. Additionally, we introduce a compact representation and compression scheme, including Gaussian attribute compression and MLP optimization, to enhance transmission efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance, delivering high-quality facial rendering at extremely low bitrates, making it well-suited for real-time 3D video conferencing applications.", "AI": {"tldr": "本文提出了一种轻量级、高保真度和低比特率的3D视频会议中说话人脸压缩框架。", "motivation": "传统的2D视频压缩技术无法保留细粒度的几何和外观细节，而隐式神经渲染方法如NeRF计算成本过高。为了解决这些问题，本文提出了一种新的解决方案。", "method": "该方案结合了FLAME参数化建模和3DGS神经渲染，并通过传输必要的面部元数据来实现实时高效的重建。引入紧凑表示及压缩方案包括高斯属性压缩和MLP优化以提高传输效率。", "result": "实验结果显示，该方法在极低比特率下实现了优秀的码率失真性能，提供了高质量的面部渲染效果。", "conclusion": "本文提出的轻量级、高保真度且低比特率的人脸压缩框架适用于实时3D视频会议应用。"}}
{"id": "2601.21268", "pdf": "https://arxiv.org/pdf/2601.21268", "abs": "https://arxiv.org/abs/2601.21268", "authors": ["Micah Rentschler", "Jesse Roberts"], "title": "Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels", "categories": ["cs.NE"], "comment": null, "summary": "Most reinforcement learning (RL) methods for training large language models (LLMs) require ground-truth labels or task-specific verifiers, limiting scalability when correctness is ambiguous or expensive to obtain. We introduce Reinforcement Learning from Meta-Evaluation (RLME), which optimizes a generator using reward derived from an evaluator's answers to natural-language meta-questions (e.g., \"Is the answer correct?\" or \"Is the reasoning logically consistent?\"). RLME treats the evaluator's probability of a positive judgment as a reward and updates the generator via group-relative policy optimization, enabling learning without labels. Across a suite of experiments, we show that RLME achieves accuracy and sample efficiency comparable to label-based training, enables controllable trade-offs among multiple objectives, steers models toward reliable reasoning patterns rather than post-hoc rationalization, and generalizes to open-domain settings where ground-truth labels are unavailable, broadening the domains in which LLMs may be trained with RL.", "AI": {"tldr": "论文介绍了一种从元评估中学习的强化学习方法（RLME），用于优化大型语言模型，使其在没有地面真实标签的情况下也能准确回答问题。", "motivation": "大多数基于强化学习的方法需要真实的标签或特定任务验证器来训练大型语言模型，这限制了它们在正确性难以确定或者获得成本高昂的情况下的可扩展性。为了克服这一挑战，研究人员引入了一种新的方法，该方法使用来自自然语言元问题的答案概率作为奖励。", "method": "通过将评估者对自然语言元问题的回答视为奖励，并采用群体相对策略优化来更新生成器模型，使得在没有地面真实标签的情况下也能进行训练。这种方法可以在多个目标之间做出可控的权衡。", "result": "实验表明，RLME能够在准确性、样本效率方面与基于标签的培训方法相当；并且能够引导模型走向可靠的推理模式而不是事后合理化，并且在无标记的真实场景中也具有很好的泛化能力。", "conclusion": "通过引入元评估强化学习（RLME），论文展示了这种方法可以在没有地面真实标签的情况下训练大型语言模型，拓宽了可以使用强化学习进行培训的领域。"}}
