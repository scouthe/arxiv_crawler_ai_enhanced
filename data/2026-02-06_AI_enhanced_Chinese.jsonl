{"id": "2602.05864", "pdf": "https://arxiv.org/pdf/2602.05864", "abs": "https://arxiv.org/abs/2602.05864", "authors": ["Mandi Yang", "Zhiqi Gao", "Yibo Meng", "Dongyijie Primo Pan"], "title": "Prompting Destiny: Negotiating Socialization and Growth in an LLM-Mediated Speculative Gameworld", "categories": ["cs.HC"], "comment": null, "summary": "We present an LLM-mediated role-playing game that supports reflection on socialization, moral responsibility, and educational role positioning. Grounded in socialization theory, the game follows a four-season structure in which players guide a child prince through morally charged situations and compare the LLM-mediated NPC's differentiated responses across stages, helping them reason about how educational guidance shifts with socialization. To approximate real educational contexts and reduce score-chasing, the system hides real-time evaluative scores and provides delayed, end-of-stage growth feedback as reflective prompts. We conducted a user study (N=12) with gameplay logs and post-game interviews, analyzed via reflexive thematic analysis. Findings show how players negotiated responsibility and role positioning, and reveal an entry-load tension between open-ended expression and sustained engagement. We contribute design knowledge on translating sociological models of socialization into reflective AI-mediated game systems.", "AI": {"tldr": "研究通过LLM中介的角色扮演游戏，探讨社会化过程中的道德责任和教育定位问题", "motivation": "旨在利用社会理论模型设计游戏，使玩家反思在不同发展阶段的教育指导如何变化", "method": "进行了一项包含12名用户的用户研究，通过游戏日志和后期访谈分析数据", "result": "发现玩家在游戏中协商责任和角色定位时存在开放性表达与持续参与之间的张力", "conclusion": "贡献了将社会学模型转化为反思性的AI中介游戏系统的设计知识"}}
{"id": "2602.05863", "pdf": "https://arxiv.org/pdf/2602.05863", "abs": "https://arxiv.org/abs/2602.05863", "authors": ["Roger Girgis", "Rodrigue de Schaetzen", "Luke Rowe", "Azalée Robitaille", "Christopher Pal", "Liam Paull"], "title": "Constrained Group Relative Policy Optimization", "categories": ["cs.LG", "cs.CL", "cs.RO"], "comment": "16 pages, 6 figures", "summary": "While Group Relative Policy Optimization (GRPO) has emerged as a scalable framework for critic-free policy learning, extending it to settings with explicit behavioral constraints remains underexplored. We introduce Constrained GRPO, a Lagrangian-based extension of GRPO for constrained policy optimization. Constraints are specified via indicator cost functions, enabling direct optimization of violation rates through a Lagrangian relaxation. We show that a naive multi-component treatment in advantage estimation can break constrained learning: mismatched component-wise standard deviations distort the relative importance of the different objective terms, which in turn corrupts the Lagrangian signal and prevents meaningful constraint enforcement. We formally derive this effect to motivate our scalarized advantage construction that preserves the intended trade-off between reward and constraint terms. Experiments in a toy gridworld confirm the predicted optimization pathology and demonstrate that scalarizing advantages restores stable constraint control. In addition, we evaluate Constrained GRPO on robotics tasks, where it improves constraint satisfaction while increasing task success, establishing a simple and effective recipe for constrained policy optimization in embodied AI domains that increasingly rely on large multimodal foundation models.", "AI": {"tldr": "该论文介绍了受约束的GRPO，这是一种基于Lagrange的方法，用于行为策略优化。", "motivation": "扩展GRPO框架以处理显式的行为约束仍然是一项未充分探索的任务。作者提出了一种新的方法来直接通过Lagrange松弛优化违反率。", "method": "作者引入了带约束的GRPO，并推导出由于组件标准差不匹配而导致相对重要性失衡的问题，提出了标量化优势构造以恢复奖励和限制项之间的预期权衡关系。", "result": "实验表明，在玩具格子世界中该方法可以修复优化问题并在机器人任务上提高约束满足度同时增加任务成功率。", "conclusion": "本文提出的受约束GRPO提供了一种简单而有效的方法，用于在依赖大规模多模态基础模型的嵌入式AI领域进行受限策略优化。"}}
{"id": "2602.05859", "pdf": "https://arxiv.org/pdf/2602.05859", "abs": "https://arxiv.org/abs/2602.05859", "authors": ["Xu Wang", "Bingqing Jiang", "Yu Wan", "Baosong Yang", "Lingpeng Kong", "Difan Zou"], "title": "DLM-Scope: Mechanistic Interpretability of Diffusion Language Models via Sparse Autoencoders", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "23 pages", "summary": "Sparse autoencoders (SAEs) have become a standard tool for mechanistic interpretability in autoregressive large language models (LLMs), enabling researchers to extract sparse, human-interpretable features and intervene on model behavior. Recently, as diffusion language models (DLMs) have become an increasingly promising alternative to the autoregressive LLMs, it is essential to develop tailored mechanistic interpretability tools for this emerging class of models. In this work, we present DLM-Scope, the first SAE-based interpretability framework for DLMs, and demonstrate that trained Top-K SAEs can faithfully extract interpretable features. Notably, we find that inserting SAEs affects DLMs differently than autoregressive LLMs: while SAE insertion in LLMs typically incurs a loss penalty, in DLMs it can reduce cross-entropy loss when applied to early layers, a phenomenon absent or markedly weaker in LLMs. Additionally, SAE features in DLMs enable more effective diffusion-time interventions, often outperforming LLM steering. Moreover, we pioneer certain new SAE-based research directions for DLMs: we show that SAEs can provide useful signals for DLM decoding order; and the SAE features are stable during the post-training phase of DLMs. Our work establishes a foundation for mechanistic interpretability in DLMs and shows a great potential of applying SAEs to DLM-related tasks and algorithms.", "AI": {"tldr": "本文提出了DLM-Scope，一种基于稀疏自编码器的解释框架来研究扩散语言模型的机理可解释性。", "motivation": "随着扩散语言模型（DLMs）作为另一种有前途的语言模型形式的发展，需要开发针对此类模型的具体机理性解释工具。", "method": "本文使用稀疏自编码器（SAEs）对扩散语言模型进行分析，并展示了训练后的Top-K SAE能够提取出可解释的特征。同时探索了在DLMs中插入SAE的影响以及其解码顺序和后训练阶段稳定性等方面的研究方向。", "result": "结果显示，与自动回归LLMs相比，在早期层应用时可以减少交叉熵损失；SAEs还可以提供有用的信号来指导DLM解码顺序，并且这些特征在模型后期训练过程中保持稳定。", "conclusion": "这项工作为扩散语言模型的机理性解释奠定了基础，并显示了将稀疏自编码器应用于与DL相关的任务和算法的巨大潜力。"}}
{"id": "2602.05857", "pdf": "https://arxiv.org/pdf/2602.05857", "abs": "https://arxiv.org/abs/2602.05857", "authors": ["Junting Zhou", "Jin Chen", "Linfeng Hao", "Denghui Cao", "Zheyu Wang", "Qiguang Chen", "Chaoyou Fu", "Jiaze Chen", "Yuchen Wu", "Ge Zhang", "Mingxuan Wang", "Wenhao Huang", "Tong Yang"], "title": "BABE: Biology Arena BEnchmark", "categories": ["cs.AI"], "comment": null, "summary": "The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research.", "AI": {"tldr": "介绍了一个名为BABE的生物学领域基准测试，用于评估生物AI系统的实验推理能力。", "motivation": "现有生物学领域的基准测试无法全面衡量研究人员将实验证据与背景知识相结合的能力，因此需要一个更复杂的评估工具来填补这一空白。", "method": "构建了基于同行评审的研究论文和真实世界生物研究的BABE框架，以挑战模型进行因果推理和跨尺度推断。", "result": "提供了用于衡量AI系统科学实验能力的真实基准测试方法。", "conclusion": "通过使用更贴近实际科研环境的任务设计，可以更好地评估AI系统的生物学科研潜力。"}}
{"id": "2602.05856", "pdf": "https://arxiv.org/pdf/2602.05856", "abs": "https://arxiv.org/abs/2602.05856", "authors": ["Zhiqi Gao", "Guo Zhu", "Huarui Luo", "Dongyijie Primo Pan", "Haoming Tang", "Bingquan Zhang", "Jiahuan Pei", "Jie Li", "Benyou Wang"], "title": "\"It Talks Like a Patient, But Feels Different\": Co-Designing AI Standardized Patients with Medical Learners", "categories": ["cs.HC"], "comment": null, "summary": "Standardized patients (SPs) play a central role in clinical communication training but are costly, difficult to scale, and inconsistent. Large language model (LLM) based AI standardized patients (AI-SPs) promise flexible, on-demand practice, yet learners often report that they talk like a patient but feel different. We interviewed 12 clinical-year medical students and conducted three co-design workshops to examine how learners experience constraints of SP encounters and what they expect from AI-SPs. We identified six learner-centered needs, translated them into AI-SP design requirements, and synthesized a conceptual workflow. Our findings position AI-SPs as tools for deliberate practice and show that instructional usability, rather than conversational realism alone, drives learner trust, engagement, and educational value.", "AI": {"tldr": "本文探讨了如何通过与医学生合作设计AI标准化患者，以解决传统SP存在的问题，并提高教育价值。", "motivation": "现有标准病人（SP）在临床沟通训练中至关重要但成本高昂、难以扩展且一致性不足。大型语言模型（LLM）支持的AI SP具有灵活和按需练习的优势，但仍存在与真人不同的情感体验的问题。研究旨在探索医学生对SP互动的需求以及他们期望从AI SP获得什么，并提出改进方案。", "method": "研究人员采访了12名临床年份的医学学生并进行了三次共同设计研讨会来了解学生的经历、需求并通过这些信息转化成具体的设计要求，最终形成了概念性的工作流程。", "result": "研究发现医学生有六大中心需要，并且将这些需求转化为AI SP的设计要求，同时提出了一个概念性的工作流程以支持教学中的使用性和教育价值。", "conclusion": "AI SP可以作为刻意练习的工具，表明不仅对话的真实性更重要的是教学使用的便利性和教育价值驱动了学习者的信任、参与和教育价值提升。"}}
{"id": "2602.05855", "pdf": "https://arxiv.org/pdf/2602.05855", "abs": "https://arxiv.org/abs/2602.05855", "authors": ["Dennis Bank", "Joost Cordes", "Thomas Seel", "Simon F. G. Ehlers"], "title": "A Hybrid Autoencoder for Robust Heightmap Generation from Fused Lidar and Depth Data for Humanoid Robot Locomotion", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Reliable terrain perception is a critical prerequisite for the deployment of humanoid robots in unstructured, human-centric environments. While traditional systems often rely on manually engineered, single-sensor pipelines, this paper presents a learning-based framework that uses an intermediate, robot-centric heightmap representation. A hybrid Encoder-Decoder Structure (EDS) is introduced, utilizing a Convolutional Neural Network (CNN) for spatial feature extraction fused with a Gated Recurrent Unit (GRU) core for temporal consistency. The architecture integrates multimodal data from an Intel RealSense depth camera, a LIVOX MID-360 LiDAR processed via efficient spherical projection, and an onboard IMU. Quantitative results demonstrate that multimodal fusion improves reconstruction accuracy by 7.2% over depth-only and 9.9% over LiDAR-only configurations. Furthermore, the integration of a 3.2 s temporal context reduces mapping drift.", "AI": {"tldr": "本文提出了一种基于学习的框架，用于从融合了深度相机和激光雷达的数据中生成地形高度图以支持类人机器人在不规则环境中的行走。", "motivation": "为了提高类人机器人在复杂、人类中心环境中部署时对地形的理解能力，传统的单传感器系统不足以提供可靠的信息。因此，本文提出了一种使用多模态数据融合的方法来增强地形感知的准确性。", "method": "该方法采用了一种混合编码器-解码器结构（EDS），包括用于空间特征提取的卷积神经网络和一个门控循环单元核心以实现时间一致性。同时处理了来自Intel RealSense深度相机、LIVOX MID-360 LiDAR的数据，以及IMU数据。", "result": "实验结果表明，与仅使用深度或激光雷达数据相比，该方法在重建精度上分别提高了7.2%和9.9%，并且通过引入3.2秒的时间上下文降低了地形映射漂移。", "conclusion": "本文提出的方法展示了多模态融合对于提高类人机器人行走时的地形感知能力的有效性，并有助于改善其在复杂环境中的自主导航性能。"}}
{"id": "2602.05854", "pdf": "https://arxiv.org/pdf/2602.05854", "abs": "https://arxiv.org/abs/2602.05854", "authors": ["Yuying Tang", "Xinyi Chen", "Haotian Li", "Xing Xie", "Xiaojuan Ma", "Huamin Qu"], "title": "DuoDrama: Supporting Screenplay Refinement Through LLM-Assisted Human Reflection", "categories": ["cs.HC"], "comment": "Accepted by CHI 2026", "summary": "AI has been increasingly integrated into screenwriting practice. In refinement, screenwriters expect AI to provide feedback that supports reflection across the internal perspective of characters and the external perspective of the overall story. However, existing AI tools cannot sufficiently coordinate the two perspectives to meet screenwriters' needs. To address this gap, we present DuoDrama, an AI system that generates feedback to assist screenwriters' reflection in refinement. To enable DuoDrama, based on performance theories and a formative study with nine professional screenwriters, we design the Experience-Grounded Feedback Generation Workflow for Human Reflection (ExReflect). In ExReflect, an AI agent adopts an experience role to generate experience and then shifts to an evaluation role to generate feedback based on the experience. A study with fourteen professional screenwriters shows that DuoDrama improves feedback quality and alignment and enhances the effectiveness, depth, and richness of reflection. We conclude by discussing broader implications and future directions.", "AI": {"tldr": "DuoDrama是一个支持剧本精炼的AI系统，通过LLM辅助的人类反思来提供反馈。", "motivation": "现有的AI工具在协调角色内部视角和整体故事外部视角方面存在不足，无法满足编剧的需求。", "method": "基于表演理论以及与九名专业编剧的形成性研究，设计了Experience-Grounded Feedback Generation Workflow for Human Reflection (ExReflect)。ExReflect中，一个AI代理采用体验角色生成体验，并转换为评估角色生成反馈。", "result": "一项针对十四位专业编剧的研究表明，DuoDrama提高了反馈的质量和一致性，并增强了反思的有效性、深度和丰富度。", "conclusion": "DuoDrama通过提高反馈质量和反思效果来满足剧本精炼的需求。论文讨论了更广泛的含义和未来方向。"}}
{"id": "2602.05848", "pdf": "https://arxiv.org/pdf/2602.05848", "abs": "https://arxiv.org/abs/2602.05848", "authors": ["Henry Jiang"], "title": "DARWIN: Dynamic Agentically Rewriting Self-Improving Network", "categories": ["cs.NE", "cs.AI", "cs.CL"], "comment": "6 pages, 3 figures, 2 tables", "summary": "DARWIN is an evolutionary GPT model, utilizing a genetic-algorithm like optimization structure with several independent GPT agents being trained individually using unique training code. Each iteration, the GPT models are prompted to modify the training code of one another in an attempt to improve their performance in a mutation-like manner, and the best GPT agents are then benchmarked and selected for the next iteration by genetic algorithm. For demonstration purposes and due to budget and time constraints, OpenAI API is used to prompt training code improvements and the nanoGPT framework is used as the training code. DARWIN also utilizes persistent JSON-based memory files to track previous reasoning and changes to code to correlate with improvement to model performance. and a bidirectional interface for HITL intervention allowing the model to request upgrades such as additional datasets, training scripts, and restructuring of file hierarchies. In experiments, DARWIN achieved a 1.26 percent improvement in model FLOPS utilization (MFU) and a 2.07 percent improvement to perplexity in 5 iterations of training over baseline configurations, demonstrating promising capabilities as a foundation for scaling evolutionary GPT training.", "AI": {"tldr": "DARWIN是一种利用遗传算法优化结构的进化GPT模型，通过多个独立的GPT代理以独特的训练代码进行迭代改进。", "motivation": "旨在探索和实现一种自适应、自我提升的神经网络架构，利用遗传算法增强机器学习模型的表现。", "method": "采用多个独立的GPT代理，每次迭代时修改彼此的训练代码以优化性能。使用OpenAI API及nanoGPT框架进行实验，并引入持久化记忆文件跟踪改进过程。", "result": "在5次迭代中，DARWIN实现了1.26％的模型FLOPS利用率提升和2.07％的困惑度降低。", "conclusion": "展示了一种有效的进化训练方法，能够显著提高GPT模型性能。"}}
{"id": "2602.05847", "pdf": "https://arxiv.org/pdf/2602.05847", "abs": "https://arxiv.org/abs/2602.05847", "authors": ["Zhangquan Chen", "Jiale Tao", "Ruihuang Li", "Yihao Hu", "Ruitao Chen", "Zhantao Yang", "Xinlei Yu", "Haodong Jing", "Manyuan Zhang", "Shuai Shao", "Biao Wang", "Qinglin Lu", "Ruqi Huang"], "title": "OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention", "categories": ["cs.AI"], "comment": "19 pages, 12 figures", "summary": "While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning. OmniVideo-R1 empowers models to \"think with omnimodal cues\" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.", "AI": {"tldr": "提出了一种增强的框架OmniVideo-R1，用于改善音频和视觉信息的综合理解。", "motivation": "当前多模态视频模型在理解和处理视听任务时存在挑战，因此需要一种新的方法来提高其性能。", "method": "该论文提出了基于自我监督学习的查询密集型定位策略以及基于对比学习的模式注意力融合技术。", "result": "实验结果表明，OmniVideo-R1框架显著超越了现有基准模型，在多个数据集上的表现更加优越和鲁棒。", "conclusion": "OmniVideo-R1通过增强音频视觉推理能力展示了强大的效果及良好的泛化性能。"}}
{"id": "2602.05845", "pdf": "https://arxiv.org/pdf/2602.05845", "abs": "https://arxiv.org/abs/2602.05845", "authors": ["Pierre-François De Plaen", "Abhishek Jha", "Luc Van Gool", "Tinne Tuytelaars", "Marc Proesmans"], "title": "Self-Supervised Learning with a Multi-Task Latent Space Objective", "categories": ["cs.CV"], "comment": null, "summary": "Self-supervised learning (SSL) methods based on Siamese networks learn visual representations by aligning different views of the same image. The multi-crop strategy, which incorporates small local crops to global ones, enhances many SSL frameworks but causes instability in predictor-based architectures such as BYOL, SimSiam, and MoCo v3. We trace this failure to the shared predictor used across all views and demonstrate that assigning a separate predictor to each view type stabilizes multi-crop training, resulting in significant performance gains. Extending this idea, we treat each spatial transformation as a distinct alignment task and add cutout views, where part of the image is masked before encoding. This yields a simple multi-task formulation of asymmetric Siamese SSL that combines global, local, and masked views into a single framework. The approach is stable, generally applicable across backbones, and consistently improves the performance of ResNet and ViT models on ImageNet.", "AI": {"tldr": "本文提出了一种新的自监督学习方法，通过为每个视图类型分配单独的预测器来增强多裁剪策略，并结合全局、局部和掩码视图以提高视觉表示的学习效果。", "motivation": "多裁剪策略虽然增强了许多SSL框架的表现，但在基于预测器的架构中引入了不稳定性。作者希望通过改进这些方法来克服这一问题并提升性能。", "method": "本文提出了一种新的自监督学习方法，它为每个视图类型分配单独的预测器，并将全局、局部和掩码视图结合在一起以提高模型在ImageNet上的性能。", "result": "该方法稳定且适用于不同基础架构，在ResNet和ViT模型上均表现出色，优于现有技术。", "conclusion": "通过为每个视图类型分配单独的预测器并引入多任务学习框架，可以显著提升基于Siamese网络的自监督学习效果。"}}
{"id": "2602.05838", "pdf": "https://arxiv.org/pdf/2602.05838", "abs": "https://arxiv.org/abs/2602.05838", "authors": ["Mayank Kumar", "Qian Lou", "Paulo Barreto", "Martine De Cock", "Sikha Pentyala"], "title": "FHAIM: Fully Homomorphic AIM For Private Synthetic Data Generation", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Data is the lifeblood of AI, yet much of the most valuable data remains locked in silos due to privacy and regulations. As a result, AI remains heavily underutilized in many of the most important domains, including healthcare, education, and finance. Synthetic data generation (SDG), i.e. the generation of artificial data with a synthesizer trained on real data, offers an appealing solution to make data available while mitigating privacy concerns, however existing SDG-as-a-service workflow require data holders to trust providers with access to private data.We propose FHAIM, the first fully homomorphic encryption (FHE) framework for training a marginal-based synthetic data generator on encrypted tabular data. FHAIM adapts the widely used AIM algorithm to the FHE setting using novel FHE protocols, ensuring that the private data remains encrypted throughout and is released only with differential privacy guarantees. Our empirical analysis show that FHAIM preserves the performance of AIM while maintaining feasible runtimes.", "AI": {"tldr": "提出FHAIM，一种全同态加密框架，用于在加密表格数据上训练边际合成数据生成器。", "motivation": "现有的合成数据生成服务需要数据持有者信任提供者，并将私有数据暴露出来。为了保护隐私和遵守法规，本文提出了一种新的解决方案。", "method": "FHAIM采用全同态加密技术，适应AIM算法，确保整个训练过程中数据保持加密状态，并在输出时实现差分隐私保证。", "result": "实验表明，FHAIM能够在保持性能的同时，在合理的时间范围内运行。", "conclusion": "本文展示了如何使用FHE框架进行私有合成数据生成，这对于保护敏感信息和遵守法规具有重要意义。"}}
{"id": "2602.05837", "pdf": "https://arxiv.org/pdf/2602.05837", "abs": "https://arxiv.org/abs/2602.05837", "authors": ["Aashish Panta", "Giorgio Scorzelli", "Amy A. Gooch", "Werner Sun", "Katherine S. Shanks", "Suchismita Sarker", "Devin Bougie", "Keara Soloway", "Rolf Verberg", "Tracy Berman", "Glenn Tarcea", "John Allison", "Michela Taufer", "Valerio Pascucci"], "title": "Large Data Acquisition and Analytics at Synchrotron Radiation Facilities", "categories": ["cs.HC"], "comment": "10 pages, 11 figures, Accepted at IEEE BigDataW 2025", "summary": "Synchrotron facilities like the Cornell High Energy Synchrotron Source (CHESS) generate massive data volumes from complex beamline experiments, but face challenges such as limited access time, the need for on-site experiment monitoring, and managing terabytes of data per user group. We present the design, deployment, and evaluation of a framework that addresses CHESS's data acquisition and management issues. Deployed on a secure CHESS server, our system provides real time, web-based tools for remote experiment monitoring and data quality assessment, improving operational efficiency. Implemented across three beamlines (ID3A, ID3B, ID4B), the framework managed 50-100 TB of data and over 10 million files in late 2024. Testing with 43 research groups and 86 dashboards showed reduced overhead, improved accessibility, and streamlined data workflows. Our paper highlights the development, deployment, and evaluation of our framework and its transformative impact on synchrotron data acquisition.", "AI": {"tldr": "本文介绍了在同步辐射设施中设计并部署的数据采集和管理框架，解决了大规模数据处理中的问题。", "motivation": "解决同步加速器实验产生的大量复杂数据的采集、管理和实时监控等问题，提高研究效率。", "method": "开发了一套系统，在安全的服务器上提供基于网络的工具进行远程实验监测和数据质量评估。", "result": "该框架成功应用于三个光束线，管理了50-100TB的数据，并通过43个研究组和86个仪表板测试证明减少了开销、提升了可访问性并优化了工作流程。", "conclusion": "本文展示了框架的开发部署及评估结果，突显其对同步加速器数据采集的重要影响。"}}
{"id": "2602.05832", "pdf": "https://arxiv.org/pdf/2602.05832", "abs": "https://arxiv.org/abs/2602.05832", "authors": ["Han Xiao", "Guozhi Wang", "Hao Wang", "Shilong Liu", "Yuxiang Chai", "Yue Pan", "Yufeng Zhou", "Xiaoxin Chen", "Yafei Wen", "Hongsheng Li"], "title": "UI-Mem: Self-Evolving Experience Memory for Online Reinforcement Learning in Mobile GUI Agents", "categories": ["cs.CV"], "comment": "23 pages, 16 figures. Project page: https://ui-mem.github.io", "summary": "Online Reinforcement Learning (RL) offers a promising paradigm for enhancing GUI agents through direct environment interaction. However, its effectiveness is severely hindered by inefficient credit assignment in long-horizon tasks and repetitive errors across tasks due to the lack of experience transfer. To address these challenges, we propose UI-Mem, a novel framework that enhances GUI online RL with a Hierarchical Experience Memory. Unlike traditional replay buffers, our memory accumulates structured knowledge, including high-level workflows, subtask skills, and failure patterns. These experiences are stored as parameterized templates that enable cross-task and cross-application transfer. To effectively integrate memory guidance into online RL, we introduce Stratified Group Sampling, which injects varying levels of guidance across trajectories within each rollout group to maintain outcome diversity, driving the unguided policy toward internalizing guided behaviors. Furthermore, a Self-Evolving Loop continuously abstracts novel strategies and errors to keep the memory aligned with the agent's evolving policy. Experiments on online GUI benchmarks demonstrate that UI-Mem significantly outperforms traditional RL baselines and static reuse strategies, with strong generalization to unseen applications. Project page: https://ui-mem.github.io", "AI": {"tldr": "UI-Mem是一种用于移动GUI代理在线强化学习的自演化经验记忆框架，旨在通过积累和转移结构化知识来提高效率。", "motivation": "传统在线RL在长时任务中面临信用分配问题，并且缺乏跨任务的经验传递机制，导致重复错误。为此，提出一种新的内存系统解决这些问题。", "method": "UI-Mem使用层次经验记忆存储高阶工作流程、子任务技巧和失败模式的模板，实现跨任务转移；通过分层组采样注入不同级别指导以保持多样性，并利用自演化循环来适应性地更新记忆。", "result": "实验表明UI-Mem在在线GUI基准上显著优于传统RL方法和静态重用策略，在未见过的应用中也具有良好的泛化能力。", "conclusion": "UI-Mem通过引入结构化的经验存储机制解决了传统在线RL面临的挑战，提高了学习效率及跨应用的适应性。"}}
{"id": "2602.05830", "pdf": "https://arxiv.org/pdf/2602.05830", "abs": "https://arxiv.org/abs/2602.05830", "authors": ["Shengpu Wang", "Yuhao Mao", "Yani Zhang", "Martin Vechev"], "title": "Learning Compact Boolean Networks", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Floating-point neural networks dominate modern machine learning but incur substantial inference cost, motivating interest in Boolean networks for resource-constrained settings. However, learning compact and accurate Boolean networks is challenging due to their combinatorial nature. In this work, we address this challenge from three different angles: learned connections, compact convolutions and adaptive discretization. First, we propose a novel strategy to learn efficient connections with no additional parameters and negligible computational overhead. Second, we introduce a novel convolutional Boolean architecture that exploits the locality with reduced number of Boolean operations than existing methods. Third, we propose an adaptive discretization strategy to reduce the accuracy drop when converting a continuous-valued network into a Boolean one. Extensive results on standard vision benchmarks demonstrate that the Pareto front of accuracy vs. computation of our method significantly outperforms prior state-of-the-art, achieving better accuracy with up to 37x fewer Boolean operations.", "AI": {"tldr": "本文提出了一种学习紧凑且准确的布尔网络的方法，以降低现代机器学习中浮点神经网络的推理成本。", "motivation": "浮点神经网络在现代机器学习中占主导地位，但其推理成本较高，因此，在资源受限的情况下，人们对于布尔网络的兴趣增加。然而，由于它们的组合性质，学习紧凑且准确的布尔网络颇具挑战性。", "method": "本文从三个角度解决了这一难题：学习高效连接、紧凑卷积和自适应离散化。首先，提出了一种不添加额外参数并具有可忽略计算开销的新策略来学习高效的连接。其次，引入一种新的卷积布尔架构以利用局部特性，并减少现有方法的布尔操作数量。第三，提出了一种自适应离散化策略以减小连续值网络转换为布尔网络时的精度损失。", "result": "在标准视觉基准测试中的大量结果表明，本研究的方法显著优于先前的最佳性能，在保持更高准确性的前提下，实现了最多37倍于现有方法的布尔操作减少。", "conclusion": "本文通过提出创新的方法来学习紧凑和高效的布尔网络结构，展示了如何在资源受限环境中改进推理效率。"}}
{"id": "2602.05829", "pdf": "https://arxiv.org/pdf/2602.05829", "abs": "https://arxiv.org/abs/2602.05829", "authors": ["Yudi Shi", "Shangzhe Di", "Qirui Chen", "Qinian Wang", "Jiayin Cai", "Xiaolong Jiang", "Yao Hu", "Weidi Xie"], "title": "Weaver: End-to-End Agentic System Training for Video Interleaved Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Video reasoning constitutes a comprehensive assessment of a model's capabilities, as it demands robust perceptual and interpretive skills, thereby serving as a means to explore the boundaries of model performance. While recent research has leveraged text-centric Chain-of-Thought reasoning to augment these capabilities, such approaches frequently suffer from representational mismatch and restricted by limited perceptual acuity. To address these limitations, we propose Weaver, a novel, end-to-end trainable multimodal reasoning agentic system. Weaver empowers its policy model to dynamically invoke diverse tools throughout the reasoning process, enabling progressive acquisition of crucial visual cues and construction of authentic multimodal reasoning trajectories. Furthermore, we integrate a reinforcement learning algorithm to allow the system to freely explore strategies for employing and combining these tools with trajectory-free data. Extensive experiments demonstrate that our system, Weaver, enhances performance on several complex video reasoning benchmarks, particularly those involving long videos.", "AI": {"tldr": "提出了一种新型的端到端可训练多模态推理代理系统Weaver，以解决视频推理中的表征不匹配和感知限制问题。", "motivation": "现有的基于文本链式思考的方法在处理视频推理时存在表征不匹配以及受限于感知能力的问题。作者希望通过提出一种新的方法来提升模型的视频推理性能。", "method": "Weaver允许策略模型在整个推理过程中动态调用各种工具，同时利用强化学习算法自由探索使用和组合这些工具的方法。该系统无需轨迹数据即可工作。", "result": "通过广泛的实验表明，Weaver在多个复杂的视频推理基准测试中表现优于其他方法，特别是在处理长视频时有显著提升。", "conclusion": "Weaver能够提高模型对复杂视频的推理能力，为解决现有的表征不匹配和感知限制问题提供了一个有效的解决方案。"}}
{"id": "2602.05827", "pdf": "https://arxiv.org/pdf/2602.05827", "abs": "https://arxiv.org/abs/2602.05827", "authors": ["Hai Zhang", "Siqi Liang", "Li Chen", "Yuxian Li", "Yukuan Xu", "Yichao Zhong", "Fu Zhang", "Hongyang Li"], "title": "Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Why must vision-language navigation be bound to detailed and verbose language instructions? While such details ease decision-making, they fundamentally contradict the goal for navigation in the real-world. Ideally, agents should possess the autonomy to navigate in unknown environments guided solely by simple and high-level intents. Realizing this ambition introduces a formidable challenge: Beyond-the-View Navigation (BVN), where agents must locate distant, unseen targets without dense and step-by-step guidance. Existing large language model (LLM)-based methods, though adept at following dense instructions, often suffer from short-sighted behaviors due to their reliance on short-horimzon supervision. Simply extending the supervision horizon, however, destabilizes LLM training. In this work, we identify that video generation models inherently benefit from long-horizon supervision to align with language instructions, rendering them uniquely suitable for BVN tasks. Capitalizing on this insight, we propose introducing the video generation model into this field for the first time. Yet, the prohibitive latency for generating videos spanning tens of seconds makes real-world deployment impractical. To bridge this gap, we propose SparseVideoNav, achieving sub-second trajectory inference guided by a generated sparse future spanning a 20-second horizon. This yields a remarkable 27x speed-up compared to the unoptimized counterpart. Extensive real-world zero-shot experiments demonstrate that SparseVideoNav achieves 2.5x the success rate of state-of-the-art LLM baselines on BVN tasks and marks the first realization of such capability in challenging night scenes.", "AI": {"tldr": "本文提出了一种新的方法SparseVideoNav，以实现快速高效的远视导航任务。", "motivation": "现有基于大规模语言模型的方法在执行密集指令时表现出色，但在没有详细指导的情况下容易陷入短视行为。为了解决这个问题并提高自主导航能力，研究者们开发了能够通过生成稀疏视频预测未来轨迹的新方法。", "method": "本文提出了一种名为SparseVideoNav的新技术，该技术利用长视野的监督训练来优化视觉语言导航，并采用一种新的策略以减少视频生成延迟的时间，使其在现实世界中实现亚秒级的轨迹推理。", "result": "实验结果表明，相较于最先进的大规模语言模型基准线，SparseVideoNav在远视导航任务中的成功率提高了2.5倍，并首次实现了在具有挑战性的夜间场景下的这种能力。", "conclusion": "SparseVideoNav成功地解决了现有的视觉语言导航方法因生成视频延迟问题难以应用于现实世界的难题，同时证明了其在复杂环境下的实用性和优越性。"}}
{"id": "2602.05826", "pdf": "https://arxiv.org/pdf/2602.05826", "abs": "https://arxiv.org/abs/2602.05826", "authors": ["Dongyijie Primo Pan", "Shuyue Li", "Yawei Zhao", "Junkun Long", "Hao Li", "Pan Hui"], "title": "Whispers of the Butterfly: A Research-through-Design Exploration of In-Situ Conversational AI Guidance in Large-Scale Outdoor MR Exhibitions", "categories": ["cs.HC"], "comment": null, "summary": "Large-scale outdoor mixed reality (MR) art exhibitions distribute curated virtual works across open public spaces, but interpretation rarely scales without turning exploration into a scripted tour. Through Research-through-Design, we created Dream-Butterfly, an in-situ conversational AI docent embodied as a small non-human companion that visitors summon for multilingual, exhibition-grounded explanations. We deployed Dream-Butterfly in a large-scale outdoor MR exhibition at a public university campus in southern China, and conducted an in-the-wild between-subject study (N=24) comparing a primarily human-led tour with an AI-led tour while keeping staff for safety in both conditions. Combining questionnaires and semi-structured interviews, we characterize how shifting the primary explanation channel reshapes explanation access, perceived responsiveness, immersion, and workload, and how visitors negotiate responsibility handoffs among staff, the AI guide, and themselves. We distill transferable design implications for configuring mixed human-AI guiding roles and embodying conversational agents in mobile, safety-constrained outdoor MR exhibitions.", "AI": {"tldr": "研究探讨了在大型户外混合现实展览中使用情境对话式AI导览员的效果。", "motivation": "传统实地解说难以大规模应用，导致观展体验受限。该研究旨在探索一种新的AI解说方式以提高参观者的互动和沉浸感。", "method": "通过设计与研究的方法开发Dream-Butterfly，并在华南某大学校园的MR展览中进行实验，对比了人类导览员与AI导览的情况。", "result": "结果表明，使用AI导览可以改善解释访问、感知响应度和沉浸感，但也需要考虑工作量分配以及参观者对责任交接的态度。", "conclusion": "研究揭示了混合现实展览中人机协作的潜在价值，并为未来的AI导览设计提供了有益启示。"}}
{"id": "2602.05825", "pdf": "https://arxiv.org/pdf/2602.05825", "abs": "https://arxiv.org/abs/2602.05825", "authors": ["Lena Hegemann", "Xinyi Wen", "Michael A. Hedderich", "Tarmo Nurmi", "Hariharan Subramonyam"], "title": "ToMigo: Interpretable Design Concept Graphs for Aligning Generative AI with Creative Intent", "categories": ["cs.HC"], "comment": "18 pages, 10 figures, 2 tables", "summary": "Generative AI often produces results misaligned with user intentions, for example, resolving ambiguous prompts in unexpected ways. Despite existing approaches to clarify intent, a major challenge remains: understanding and influencing AI's interpretation of user intent through simple, direct inputs requiring no expertise or rigid procedures. We present ToMigo, representing intent as design concept graphs: nodes represent choices of purpose, content, or style, while edges link them with interpretable explanations. Applied to graphic design, ToMigo infers intent from reference images and text. We derived a schema of node types and edges from pre-study data, informing a multimodal large language model to generate graphs aligning nodes externally with user intent and internally toward a unified design goal. This structure enables users to explore AI reasoning and directly manipulate the design concept. In our user studies, ToMigo received high alignment ratings and captured most user intentions well. Users reported greater control and found interactive features-editable graphs, reflective chats, concept-design realignment-useful for evolving and realizing their design ideas.", "AI": {"tldr": "本文提出了ToMigo，一种通过设计概念图来理解和影响用户意图的系统。", "motivation": "生成式AI常常产生与用户意图不一致的结果。当前方法难以通过简单直接的方式理解并调整用户的意图表达。", "method": "ToMigo将用户意图表示为包含选择目的、内容或风格节点的设计概念图，并使用多模态大型语言模型来推断这些图以反映用户意图和设计目标。", "result": "在用户研究中，ToMigo获得了高对齐评分，并且捕捉到了大部分用户的意图。参与者认为其提供了更大的控制权并发现交互特性有用。", "conclusion": "通过设计概念图，ToMigo提供了一种直观的方式让用户理解和调整AI的设计输出。"}}
{"id": "2602.05822", "pdf": "https://arxiv.org/pdf/2602.05822", "abs": "https://arxiv.org/abs/2602.05822", "authors": ["Musawar Ali", "Manuel Carranza-García", "Nicola Fioraio", "Samuele Salti", "Luigi Di Stefano"], "title": "NVS-HO: A Benchmark for Novel View Synthesis of Handheld Objects", "categories": ["cs.CV"], "comment": null, "summary": "We propose NVS-HO, the first benchmark designed for novel view synthesis of handheld objects in real-world environments using only RGB inputs. Each object is recorded in two complementary RGB sequences: (1) a handheld sequence, where the object is manipulated in front of a static camera, and (2) a board sequence, where the object is fixed on a ChArUco board to provide accurate camera poses via marker detection. The goal of NVS-HO is to learn a NVS model that captures the full appearance of an object from (1), whereas (2) provides the ground-truth images used for evaluation. To establish baselines, we consider both a classical SfM pipeline and a state-of-the-art pre-trained feed-forward neural network (VGGT) as pose estimators, and train NVS models based on NeRF and Gaussian Splatting. Our experiments reveal significant performance gaps in current methods under unconstrained handheld conditions, highlighting the need for more robust approaches. NVS-HO thus offers a challenging real-world benchmark to drive progress in RGB-based novel view synthesis of handheld objects.", "AI": {"tldr": "提出NVS-HO基准，用于在真实环境中仅使用RGB输入进行手持对象的新视角合成。", "motivation": "现有方法在不受约束的手持条件下性能不足，需要一个挑战性的现实世界基准来推动基于RGB的新视图合成研究。", "method": "通过记录两个互补的RGB序列（手持和板子序列）建立NVS-HO，并使用SfM管道和预训练神经网络作为姿态估计器，同时基于NeRF和高斯点绘制训练NVS模型。", "result": "实验表明当前方法在不受约束的手持条件下存在显著性能差距，突显了更稳健的方法的必要性。", "conclusion": "NVS-HO作为一个基准为手持对象的新视图合成提供了一个具有挑战性的现实世界场景。"}}
{"id": "2602.05819", "pdf": "https://arxiv.org/pdf/2602.05819", "abs": "https://arxiv.org/abs/2602.05819", "authors": ["Yeon Su Park", "Nadia Azzahra Putri Arvi", "Seoyoung Kim", "Juho Kim"], "title": "Authorship Drift: How Self-Efficacy and Trust Evolve During LLM-Assisted Writing", "categories": ["cs.HC"], "comment": "Conditionally accepted to CHI 2026", "summary": "Large language models (LLMs) are increasingly used as collaborative partners in writing. However, this raises a critical challenge of authorship, as users and models jointly shape text across interaction turns. Understanding authorship in this context requires examining users' evolving internal states during collaboration, particularly self-efficacy and trust. Yet, the dynamics of these states and their associations with users' prompting strategies and authorship outcomes remain underexplored. We examined these dynamics through a study of 302 participants in LLM-assisted writing, capturing interaction logs and turn-by-turn self-efficacy and trust ratings. Our analysis showed that collaboration generally decreased users' self-efficacy while increasing trust. Participants who lost self-efficacy were more likely to ask the LLM to edit their work directly, whereas those who recovered self-efficacy requested more review and feedback. Furthermore, participants with stable self-efficacy showed higher actual and perceived authorship of the final text. Based on these findings, we propose design implications for understanding and supporting authorship in human-LLM collaboration.", "AI": {"tldr": "研究通过分析用户在与大型语言模型协作写作过程中的自我效能感和信任度变化，探讨了这些因素如何影响用户的提示策略以及最终文本的作者身份。", "motivation": "研究动机在于理解在人机合作写作品中，用户内部状态（如自我效能感和信任）的变化及其对作者身份的影响。这一领域目前尚缺乏深入的研究。", "method": "通过收集302名参与者的交互日志及逐回合的自我效能感和信任度评分，分析了这些因素与用户的提示策略和最终文本作者身份之间的关联。", "result": "研究发现合作一般降低了用户自我效能感的同时增加了其对模型的信任。丧失自我效能感的参与者更可能直接请求LLM编辑他们的工作，而恢复自我效能感的则更多寻求反馈；稳定自我效能感的表现出更高的实际与感知到的最终文本作者身份。", "conclusion": "基于研究发现，提出了理解和支持人机合作写作过程中作者身份的设计建议。"}}
{"id": "2602.05818", "pdf": "https://arxiv.org/pdf/2602.05818", "abs": "https://arxiv.org/abs/2602.05818", "authors": ["Zihao Jiang", "Miao Peng", "Zhenyan Shan", "Wenjie Xu", "Ben Liu", "Gong Chen", "Ziqi Gao", "Min Peng"], "title": "TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning", "categories": ["cs.AI", "cs.DB"], "comment": null, "summary": "Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it lack optimization through dynamic interaction with temporal knowledge graphs (TKGs) environments. To address these limitations, we propose \\textbf{TKG-Thinker}, a novel agent equipped with autonomous planning and adaptive retrieval capabilities for reasoning over TKGs. Specifically, TKG-Thinker performs in-depth temporal reasoning through dynamic multi-turn interactions with TKGs via a dual-training strategy. We first apply Supervised Fine-Tuning (SFT) with chain-of thought data to instill core planning capabilities, followed by a Reinforcement Learning (RL) stage that leverages multi-dimensional rewards to refine reasoning policies under intricate temporal constraints. Experimental results on benchmark datasets with three open-source LLMs show that TKG-Thinker achieves state-of-the-art performance and exhibits strong generalization across complex TKGQA settings.", "AI": {"tldr": "本文提出了TKG-Thinker，一种通过强化学习动态与时间知识图互动以进行推理的新方法。", "motivation": "当前的大型语言模型在处理复杂的时间约束和静态提示时存在幻觉问题以及限制了其自主性和泛化能力。为了解决这些问题，提出了一种新的代理TKG-Thinker来提高时间敏感的知识图问答任务的效果。", "method": "首先使用监督微调技术对链式思维数据进行训练以培养核心规划能力，然后通过多维奖励的强化学习阶段改进在复杂时间约束下的推理策略。采用双重训练策略实现动态多回合与时间知识图互动。", "result": "实验结果表明，在三个开源大型语言模型上，TKG-Thinker达到了最先进的性能，并且在复杂的时态知识图问答设置中表现出强大的泛化能力。", "conclusion": "通过结合自主规划和自适应检索功能，新提出的代理能够更有效地处理时间敏感的推理任务。"}}
{"id": "2602.05811", "pdf": "https://arxiv.org/pdf/2602.05811", "abs": "https://arxiv.org/abs/2602.05811", "authors": ["Zhaorui Jiang", "Yingfang Yuan", "Lei Hu", "Wei Pang"], "title": "STProtein: predicting spatial protein expression from multi-omics data", "categories": ["cs.AI"], "comment": "STProtein: predicting spatial protein expression from multi-omics data is accepted SPARTA_AAAI2026 Oral GitHub: https://github.com/zhaorui-bi/STProtein", "summary": "The integration of spatial multi-omics data from single tissues is crucial for advancing biological research. However, a significant data imbalance impedes progress: while spatial transcriptomics data is relatively abundant, spatial proteomics data remains scarce due to technical limitations and high costs. To overcome this challenge we propose STProtein, a novel framework leveraging graph neural networks with multi-task learning strategy. STProtein is designed to accurately predict unknown spatial protein expression using more accessible spatial multi-omics data, such as spatial transcriptomics. We believe that STProtein can effectively addresses the scarcity of spatial proteomics, accelerating the integration of spatial multi-omics and potentially catalyzing transformative breakthroughs in life sciences. This tool enables scientists to accelerate discovery by identifying complex and previously hidden spatial patterns of proteins within tissues, uncovering novel relationships between different marker genes, and exploring the biological \"Dark Matter\".", "AI": {"tldr": "STProtein利用图神经网络和多任务学习策略，通过空间转录组学数据预测未知的空间蛋白表达。", "motivation": "现有的空间蛋白质组学数据稀缺，难以满足研究需求。本文旨在开发一种方法来克服这一限制，并推动空间多组学数据的整合。", "method": "提出STProtein框架，该框架使用图神经网络和多任务学习策略，以更易获取的空间转录组数据为基础预测空间蛋白表达。", "result": "STProtein能够准确地利用空间转录组数据预测未知的空间蛋白质表达情况。", "conclusion": "STProtein有效地解决了空间蛋白质组学数据稀缺的问题，并促进了空间多组学数据分析的进展，有助于发现组织中复杂的、以前未被识别的空间蛋白模式。"}}
{"id": "2602.05809", "pdf": "https://arxiv.org/pdf/2602.05809", "abs": "https://arxiv.org/abs/2602.05809", "authors": ["Enwei Tong", "Yuanchao Bai", "Yao Zhu", "Junjun Jiang", "Xianming Liu"], "title": "Focus-Scan-Refine: From Human Visual Perception to Efficient Visual Token Pruning", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) often generate massive visual tokens that greatly increase inference latency and memory footprint; while training-free token pruning offers a practical remedy, existing methods still struggle to balance local evidence and global context under aggressive compression. We propose Focus-Scan-Refine (FSR), a human-inspired, plug-and-play pruning framework that mimics how humans answer visual questions: focus on key evidence, then scan globally if needed, and refine the scanned context by aggregating relevant details. FSR first focuses on key evidence by combining visual importance with instruction relevance, avoiding the bias toward visually salient but query-irrelevant regions. It then scans for complementary context conditioned on the focused set, selecting tokens that are most different from the focused evidence. Finally, FSR refines the scanned context by aggregating nearby informative tokens into the scan anchors via similarity-based assignment and score-weighted merging, without increasing the token budget. Extensive experiments across multiple VLM backbones and vision-language benchmarks show that FSR consistently improves the accuracy-efficiency trade-off over existing state-of-the-art pruning methods. The source codes can be found at https://github.com/ILOT-code/FSR", "AI": {"tldr": "提出了一种名为Focus-Scan-Refine (FSR)的视觉标记修剪框架，模仿人类视觉感知来提高视觉语言模型的效率。", "motivation": "现有的无训练标记修剪方法在压缩过程中难以平衡局部证据和全局背景的关系，在此背景下提出了FSR以解决这一问题。", "method": "FSR通过结合视觉重要性与指令相关性的焦点搜索，接着基于已聚焦区域扫描补充上下文，并最终通过相似度基元聚合并加权合并附近的信息标记来优化所扫描的上下文。", "result": "在多种VLM骨干和视觉语言基准上的广泛实验表明，FSR优于现有的最先进的修剪方法，在准确性与效率之间的折中上表现出色。", "conclusion": "FSR为解决视觉语言模型中的高效压缩问题提供了一种有效的方法，证明了模仿人类视觉感知的价值。"}}
{"id": "2602.05805", "pdf": "https://arxiv.org/pdf/2602.05805", "abs": "https://arxiv.org/abs/2602.05805", "authors": ["Kang Chen", "Zhuoka Feng", "Sihan Zhao", "Kai Xiong", "Junjie Nian", "Yaoning Wang", "Changyi Xiao", "Yixin Cao"], "title": "NEX: Neuron Explore-Exploit Scoring for Label-Free Chain-of-Thought Selection and Model Ranking", "categories": ["cs.AI"], "comment": "21 pages, 9 figures, 5 tables", "summary": "Large language models increasingly spend inference compute sampling multiple chain-of-thought traces or searching over merged checkpoints. This shifts the bottleneck from generation to selection, often without supervision on the target distribution. We show entropy-based exploration proxies follow an inverted-U with accuracy, suggesting extra exploration can become redundant and induce overthinking. We propose NEX, a white-box label-free unsupervised scoring framework that views reasoning as alternating E-phase (exploration) and X-phase (exploitation). NEX detects E-phase as spikes in newly activated MLP neurons per token from sparse activation caches, then uses a sticky two-state HMM to infer E-X phases and credits E-introduced neurons by whether they are reused in the following X span. These signals yield interpretable neuron weights and a single Good-Mass Fraction score to rank candidate responses and merged variants without task answers. Across reasoning benchmarks and Qwen3 merge families, NEX computed on a small unlabeled activation set predicts downstream accuracy and identifies better variants; we further validate the E-X signal with human annotations and provide causal evidence via \"Effective-vs-Redundant\" neuron transfer.", "AI": {"tldr": "提出NEX框架，用于无标签的推理过程选择和模型排名。", "motivation": "随着大型语言模型在推断过程中花费更多计算资源采样多个推理路径或搜索合并检查点，瓶颈从生成转变为选择。而额外探索可能导致过度思考且缺乏监督目标分布的情况下，熵基探索代理随准确度呈倒U型变化。", "method": "NEX框架通过观察激活的MLP神经元在每个令牌上的新活动来检测E阶段，并使用粘性两状态HMM推断E-X阶段。它根据是否在后续X阶段重用引入的神经元给出信用，从而获得可解释的神经元权重和单一Good-Mass分数。", "result": "NEX框架在推理基准测试和Qwen3合并家族中表现良好，并通过无标签激活集预测下游准确性和识别更好变体。它还通过人类注释验证E-X信号并提供因果证据。", "conclusion": "NEX框架为大型语言模型的推理过程选择和模型排名提供了新的方法，提高了效率和准确性。"}}
{"id": "2602.05801", "pdf": "https://arxiv.org/pdf/2602.05801", "abs": "https://arxiv.org/abs/2602.05801", "authors": ["Peter Robinson", "Ming Ming Tan"], "title": "The Quantum Message Complexity of Distributed Wake-Up with Advice", "categories": ["quant-ph", "cs.DC", "cs.DS"], "comment": null, "summary": "We consider the distributed wake-up problem with advice, where nodes are equipped with initial knowledge about the network at large. After the adversary awakens a subset of nodes, an oracle computes a bit string (``the advice'') for each node, and the goal is to wake up all sleeping nodes efficiently. We present the first upper and lower bounds on the message complexity for wake-up in the quantum routing model, introduced by Dufoulon, Magniez, and Pandurangan (PODC 2025). In more detail, we give a distributed advising scheme that, given $α$ bits of advice per node, wakes up all nodes with a message complexity of $O( \\sqrt{\\frac{n^3}{2^{\\max\\{\\lfloor (α-1)/2 \\rfloor},0\\}}}\\cdot\\log n )$ with high probability. Our result breaks the $Ω( \\frac{n^2}{2^α} )$ barrier known for the classical port numbering model in sufficiently dense graphs. To complement our algorithm, we give a lower bound on the message complexity for distributed quantum algorithms: By leveraging a lower bound result for the single-bit descriptor problem in the query complexity model, we show that wake-up has a quantum message complexity of $Ω( n^{3/2} )$ without advice, which holds independently of how much time we allow. In the setting where an adversary decides which nodes start the algorithm, most graph problems of interest implicitly require solving wake-up, and thus the same lower bound also holds for other fundamental problems such as single-source broadcast and spanning tree construction.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.05794", "pdf": "https://arxiv.org/pdf/2602.05794", "abs": "https://arxiv.org/abs/2602.05794", "authors": ["Aboli Kathar", "Aman Kumar", "Anusha Kamath", "Araveeti Srujan", "Ashish Sharma", "Chandra Bhushan", "Dilip Asbe", "Divya Sorate", "Duddu Prasanth Kumar", "Evan Acharya", "Harsh Sharma", "Hrithik Kadam", "Kanishk Singla", "Keyur Doshi", "Kiran Praveen", "Kolisetty Krishna SK", "Krishanu Adhikary", "Lokesh MPT", "Mayurdeep Sonowal", "Nadeem Shaikh", "Navya Prakash", "Nimit Kothari", "Nitin Kukreja", "Prashant Devadiga", "Rakesh Paul", "et al. (16 additional authors not shown)"], "title": "FiMI: A Domain-Specific Language Model for Indian Finance Ecosystem", "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "We present FiMI (Finance Model for India), a domain-specialized financial language model developed for Indian digital payment systems. We develop two model variants: FiMI Base and FiMI Instruct. FiMI adapts the Mistral Small 24B architecture through a multi-stage training pipeline, beginning with continuous pre-training on 68 Billion tokens of curated financial, multilingual (English, Hindi, Hinglish), and synthetic data. This is followed by instruction fine-tuning and domain-specific supervised fine-tuning focused on multi-turn, tool-driven conversations that model real-world workflows, such as transaction disputes and mandate lifecycle management. Evaluations reveal that FiMI Base achieves a 20% improvement over the Mistral Small 24B Base model on finance reasoning benchmark, while FiMI Instruct outperforms the Mistral Small 24B Instruct model by 87% on domain-specific tool-calling. Moreover, FiMI achieves these significant domain gains while maintaining comparable performance to models of similar size on general benchmarks.", "AI": {"tldr": "开发了一种专门针对印度金融生态系统的语言模型FiMI。", "motivation": "为了提升印度数字支付系统中的多轮、工具驱动对话的能力，提高财务推理和特定领域任务的准确性。", "method": "采用Mistral Small 24B架构，并通过连续预训练680亿个精心策划的金融、多语言（英语、印地语、混合语言）以及合成数据进行微调。之后进行了指令微调，专注于模拟真实工作流程的多轮对话。", "result": "FiMI Base模型在财务推理基准测试中比Mistral Small 24B基础模型提高了20%；而FiMI Instruct则在特定领域工具调用方面提高了87%，同时保持了与同规模模型相当的一般性能。", "conclusion": "FiMI通过定制化的训练和微调策略，显著提升了针对印度金融生态系统的多轮对话和工具驱动任务的能力。"}}
{"id": "2602.05791", "pdf": "https://arxiv.org/pdf/2602.05791", "abs": "https://arxiv.org/abs/2602.05791", "authors": ["Yufei Xue", "YunFeng Lin", "Wentao Dong", "Yang Tang", "Jingbo Wang", "Jiangmiao Pang", "Ming Zhou", "Minghuan Liu", "Weinan Zhang"], "title": "Scalable and General Whole-Body Control for Cross-Humanoid Locomotion", "categories": ["cs.RO"], "comment": null, "summary": "Learning-based whole-body controllers have become a key driver for humanoid robots, yet most existing approaches require robot-specific training. In this paper, we study the problem of cross-embodiment humanoid control and show that a single policy can robustly generalize across a wide range of humanoid robot designs with one-time training. We introduce XHugWBC, a novel cross-embodiment training framework that enables generalist humanoid control through: (1) physics-consistent morphological randomization, (2) semantically aligned observation and action spaces across diverse humanoid robots, and (3) effective policy architectures modeling morphological and dynamical properties. XHugWBC is not tied to any specific robot. Instead, it internalizes a broad distribution of morphological and dynamical characteristics during training. By learning motion priors from diverse randomized embodiments, the policy acquires a strong structural bias that supports zero-shot transfer to previously unseen robots. Experiments on twelve simulated humanoids and seven real-world robots demonstrate the strong generalization and robustness of the resulting universal controller.", "AI": {"tldr": "本文提出了一种新的跨人形体控制框架XHugWBC，该框架通过物理一致的形态随机化、语义对齐的观察和行动空间以及有效政策架构模型来实现通用的人形机器人控制。", "motivation": "现有的基于学习的整体控制器需要特定于机器人的训练。本文旨在研究跨人形体的人形机器人控制问题，并提出一种方法，使一个策略能够在一次训练后稳健地推广到不同设计的机器人上。", "method": "XHugWBC框架通过物理一致的形态随机化、语义对齐的观察和行动空间以及有效政策架构模型来实现。这些技术共同作用于学习从不同的随机化人形体中获得运动先验，从而支持零样本迁移至之前未见过的人形机器人。", "result": "实验结果表明，XHugWBC在12种模拟人形机器人和7个真实世界机器人的测试中表现出强大的泛化性和鲁棒性。这证明了其作为通用控制器的有效性。", "conclusion": "本文展示了如何通过跨体的训练框架来实现对不同设计的人形机器人的零样本控制，这是未来开发更广泛适用的整体控制系统的重要一步。"}}
{"id": "2602.05789", "pdf": "https://arxiv.org/pdf/2602.05789", "abs": "https://arxiv.org/abs/2602.05789", "authors": ["Hengyi Wang", "Ruiqiang Zhang", "Chang Liu", "Guanjie Wang", "Zehua Ma", "Han Fang", "Weiming Zhang"], "title": "Allocentric Perceiver: Disentangling Allocentric Reasoning from Egocentric Visual Priors via Frame Instantiation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the rising need for spatially grounded tasks such as Vision-Language Navigation/Action, allocentric perception capabilities in Vision-Language Models (VLMs) are receiving growing focus. However, VLMs remain brittle on allocentric spatial queries that require explicit perspective shifts, where the answer depends on reasoning in a target-centric frame rather than the observed camera view. Thus, we introduce Allocentric Perceiver, a training-free strategy that recovers metric 3D states from one or more images with off-the-shelf geometric experts, and then instantiates a query-conditioned allocentric reference frame aligned with the instruction's semantic intent. By deterministically transforming reconstructed geometry into the target frame and prompting the backbone VLM with structured, geometry-grounded representations, Allocentric Perceriver offloads mental rotation from implicit reasoning to explicit computation. We evaluate Allocentric Perciver across multiple backbone families on spatial reasoning benchmarks, observing consistent and substantial gains ($\\sim$10%) on allocentric tasks while maintaining strong egocentric performance, and surpassing both spatial-perception-finetuned models and state-of-the-art open-source and proprietary models.", "AI": {"tldr": "本文提出了Allocentric Perceiver，一种无需训练的策略，通过几何专家从图像中恢复三维状态，并根据指令意图实例化目标中心参考框架，以提高视觉语言模型在空间推理任务中的表现。", "motivation": "当前的视觉语言模型在处理需要显式视角转换的空间查询时存在脆弱性。这种情况下，答案依赖于基于指令语义意图的目标中心框架的推理，而非观察到的相机视图。", "method": "通过使用现成的几何专家从图像中恢复度量三维状态，并根据指令实例化目标中心参考框架，将重建的几何结构转换为目标帧并提示主干视觉语言模型以结构化的、基于几何的表示。这种方法将心理旋转从隐式推理转移到显式计算。", "result": "在多个骨干家族的空间推理基准测试上进行评估时，观察到一致且显著的性能提升（约10%）于目标中心任务，同时保持了强大的视角中心性能，并超越了空间感知微调模型和最先进的开源及专有模型。", "conclusion": "Allocentric Perceiver通过实例化基于指令意图的目标中心参考框架，显着提高了视觉语言模型在需要显式视角转换的空间查询上的表现。"}}
{"id": "2602.05787", "pdf": "https://arxiv.org/pdf/2602.05787", "abs": "https://arxiv.org/abs/2602.05787", "authors": ["Hengran Zhang", "Keping Bi", "Jiafeng Guo", "Jiaming Zhang", "Wenbo Yang", "Daiting Shi", "Xueqi Cheng"], "title": "Bagging-Based Model Merging for Robust General Text Embeddings", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "12 pages, 4 figures", "summary": "General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and how to efficiently adapt embedding models as new domains and data types continually emerge. In this work, we present a systematic study of multi-task training for text embeddings from two perspectives: data scheduling and model merging. We compare batch-level shuffling, sequential training variants, two-stage training, and multiple merging granularities, and find that simple batch-level shuffling consistently yields the strongest overall performance, suggesting that task conflicts are limited and training datasets are largely complementary. Despite its effectiveness, batch-level shuffling exhibits two practical limitations: suboptimal out-of-domain (OOD) generalization and poor suitability for incremental learning due to expensive full retraining. To address these issues, we propose Bagging-based rObust mOdel Merging (\\modelname), which trains multiple embedding models on sampled subsets and merges them into a single model, improving robustness while retaining single-model inference efficiency. Moreover, \\modelname naturally supports efficient incremental updates by training lightweight update models on new data with a small historical subset and merging them into the existing model. Experiments across diverse embedding benchmarks demonstrate that \\modelname consistently improves both in-domain and OOD performance over full-corpus batch-level shuffling, while substantially reducing training cost in incremental learning settings.", "AI": {"tldr": "提出了一种基于Bagging的模型合并方法，用于提高通用文本嵌入模型在不同任务和增量学习中的表现。", "motivation": "探讨了多任务训练策略的效果，并发现简单的批量级洗牌策略在实际应用中存在局限性，包括领域外泛化不足以及不适合增量学习。因此提出了一种新的Bagging模型合并方法来解决这些问题。", "method": "通过训练多个嵌入模型并将其合并为一个单个模型以提高鲁棒性和效率；同时支持高效增量更新的策略。", "result": "实验显示，所提出的模型合并方法在不同任务和领域外泛化性能上优于全数据集批量级洗牌方法，并且大幅降低了增量学习中的训练成本。", "conclusion": "该Bagging模型合并方法可以有效提高通用文本嵌入模型的鲁棒性和效率，在多种应用场景中具有优势。"}}
{"id": "2602.05785", "pdf": "https://arxiv.org/pdf/2602.05785", "abs": "https://arxiv.org/abs/2602.05785", "authors": ["Timur Mamedov", "Karina Kvanchiani", "Anton Konushin", "Vadim Konushin"], "title": "ReText: Text Boosts Generalization in Image-Based Person Re-identification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Generalizable image-based person re-identification (Re-ID) aims to recognize individuals across cameras in unseen domains without retraining. While multiple existing approaches address the domain gap through complex architectures, recent findings indicate that better generalization can be achieved by stylistically diverse single-camera data. Although this data is easy to collect, it lacks complexity due to minimal cross-view variation. We propose ReText, a novel method trained on a mixture of multi-camera Re-ID data and single-camera data, where the latter is complemented by textual descriptions to enrich semantic cues. During training, ReText jointly optimizes three tasks: (1) Re-ID on multi-camera data, (2) image-text matching, and (3) image reconstruction guided by text on single-camera data. Experiments demonstrate that ReText achieves strong generalization and significantly outperforms state-of-the-art methods on cross-domain Re-ID benchmarks. To the best of our knowledge, this is the first work to explore multimodal joint learning on a mixture of multi-camera and single-camera data in image-based person Re-ID.", "AI": {"tldr": "本文提出了一种名为ReText的新方法，通过图像和文本的多模态联合学习，在单相机数据上增加语义信息来增强跨领域的人体再识别性能。", "motivation": "现有的人体再识别方法主要依赖于复杂的架构来解决不同域之间的差异。然而，这些方法收集的数据由于视图变化小而缺乏复杂性。因此，作者希望通过补充文本描述来丰富单相机数据的语义信息，以实现更好的泛化能力。", "method": "ReText通过在一个混合多相机和单相机数据集上进行训练来实现这一目标。其在训练期间同时优化了三个任务：1）多相机再识别；2）图像-文本匹配；3）基于文本的单相机图像重建。这种方法结合了不同模态的数据，以提高模型的泛化能力。", "result": "实验表明，ReText方法在跨域人体再识别基准测试中表现出色，并且显著优于现有的最佳方法。", "conclusion": "本文首次探索了多模态联合学习在一个混合的多相机和单相机数据集上的应用。该方法能够有效地提高图像基于的人体再识别任务中的泛化能力。"}}
{"id": "2602.05780", "pdf": "https://arxiv.org/pdf/2602.05780", "abs": "https://arxiv.org/abs/2602.05780", "authors": ["Ulrich Finkler", "Irene Manotas", "Wei Zhang", "Geert Janssen", "Octavian Popescu", "Shyam Ramji"], "title": "Automated Customization of LLMs for Enterprise Code Repositories Using Semantic Scopes", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code completion (CC) is a task frequently used by developers when working in collaboration with LLM-based programming assistants. Despite the increased performance of LLMs on public benchmarks, out of the box LLMs still have a hard time generating code that aligns with a private code repository not previously seen by the model's training data. Customizing code LLMs to a private repository provides a way to improve the model performance. In this paper we present our approach for automated LLM customization based on semantic scopes in the code. We evaluate LLMs on real industry cases with two private enterprise code repositories with two customization strategies: Retrieval-Augmented Generation (RAG) and supervised Fine-Tuning (FT). Our mechanism for ingesting the repository's data and formulating the training data pairs with semantic scopes helps models to learn the underlying patterns specific to the repository, providing more precise code to developers and helping to boost their productivity. The code completions of moderately sized customized models can be significantly better than those of uncustomized models of much larger capacity. We also include an analysis of customization on two public benchmarks and present opportunities for future work.", "AI": {"tldr": "该论文提出了一种基于语义范围的LLM自定义方法，用于企业代码仓库中的代码补全任务。", "motivation": "现有的LLM在公开基准上的性能得到了提高，但在未见过的私有代码库上表现不佳。通过定制化可以提升模型性能并帮助开发人员提高生产力。", "method": "使用语义范围机制将仓库数据纳入训练，并采用两种自定义策略：检索增强生成（RAG）和监督微调（FT）。", "result": "与未定制的大容量模型相比，适度大小的定制化模型可以提供更精确的代码补全。", "conclusion": "语义范围机制有助于LLM学习特定于仓库的模式，提高了代码补全的质量。"}}
{"id": "2602.05774", "pdf": "https://arxiv.org/pdf/2602.05774", "abs": "https://arxiv.org/abs/2602.05774", "authors": ["Xiandong Zou", "Jianshu Li", "Jing Huang", "Pan Zhou"], "title": "Variational Speculative Decoding: Rethinking Draft Training from Token Likelihood to Sequence Acceptance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Speculative decoding accelerates inference for (M)LLMs, yet a training-decoding discrepancy persists: while existing methods optimize single greedy trajectories, decoding involves verifying and ranking multiple sampled draft paths. We propose Variational Speculative Decoding (VSD), formulating draft training as variational inference over latent proposals (draft paths). VSD maximizes the marginal probability of target-model acceptance, yielding an ELBO that promotes high-quality latent proposals while minimizing divergence from the target distribution. To enhance quality and reduce variance, we incorporate a path-level utility and optimize via an Expectation-Maximization procedure. The E-step draws MCMC samples from an oracle-filtered posterior, while the M-step maximizes weighted likelihood using Adaptive Rejection Weighting (ARW) and Confidence-Aware Regularization (CAR). Theoretical analysis confirms that VSD increases expected acceptance length and speedup. Extensive experiments across LLMs and MLLMs show that VSD achieves up to a 9.6% speedup over EAGLE-3 and 7.9% over ViSpec, significantly improving decoding efficiency.", "AI": {"tldr": "本文提出了变分投机解码（VSD）方法，旨在优化大语言模型的草案训练过程，以提高推理效率。", "motivation": "现有的投机解码虽然加速了推理速度，但在训练和解码之间存在差距。训练过程中采用单次贪婪路径进行优化而解码涉及验证和排名多个采样路径，这导致性能不足。", "method": "VSD将草案训练视为潜在提案（草案路径）的变分推断问题，并通过最大边缘概率最大化目标模型接受来形成ELBO。引入了路径级效用并通过期望最大化过程进行优化。E步从过滤后的后验中抽取MCMC样本，而M步则利用自适应拒绝加权和置信度感知正则化技术。", "result": "理论分析表明VSD可以增加预期接受长度并提高加速比。实验结果验证了VSD在大语言模型上的优越性，实现了9.6%的加速率超过EAGLE-3，7.9%的加速率超过ViSpec。", "conclusion": "通过将草案训练视为变分推断问题，VSD方法提高了大型和超大规模语言模型的解码效率。"}}
{"id": "2602.05773", "pdf": "https://arxiv.org/pdf/2602.05773", "abs": "https://arxiv.org/abs/2602.05773", "authors": ["Yılmaz Arslanoğlu"], "title": "A Structural Equivalence of Symmetric TSP to a Constrained Group Steiner Tree Problem", "categories": ["cs.DS", "cs.DM", "math.CO", "math.GT"], "comment": "4 pages, 3 figures, brief communication note to be submitted to ORL", "summary": "We present a brief structural equivalence between the symmetric TSP and a constrained Group Steiner Tree Problem (cGSTP) defined on a simplicial incidence graph. Given the complete weighted graph on the city set V, we form the bipartite incidence graph between triangles and edges. Selecting an admissible, disk-like set of triangles induces a unique boundary cycle. With global connectivity and local regularity constraints, maximizing net weight in the cGSTP is exactly equivalent to minimizing the TSP tour length.", "AI": {"tldr": "论文介绍了对称TSP与有约束的群Steiner树问题(cGSTP)之间的结构等价性。", "motivation": "通过在简单形发生图上定义cGSTP，探索对称TSP和cGSTP之间的潜在联系以寻求新的解决路径。", "method": "构建城市集上的完整加权图，并形成三角形与边的双部关联图。选择可接受的、盘状的三角形集合诱导出一个唯一的边界循环，从而建立等价性。", "result": "证明了在全局连通性和局部规则约束下最大化cGSTP中的净权重与最小化TSP巡回长度是等效的。", "conclusion": "提出了一种新的视角和方法来解决对称TSP问题。"}}
{"id": "2602.05765", "pdf": "https://arxiv.org/pdf/2602.05765", "abs": "https://arxiv.org/abs/2602.05765", "authors": ["Zhong Guan", "Haoran Sun", "Yongjian Guo", "Shuai Di", "Xiaodong Bai", "Jing Long", "Tianyun Zhao", "Mingxi Luo", "Chen Zhou", "Yucheng Guo", "Qiming Yang", "Wanting Xu", "Wen Huang", "Yunxuan Ma", "Hongke Zhao", "Likang Wu", "Xiaotie Deng", "Xi Xiao", "Sheng Wen", "Yicheng Gong", "Junwu Xiong"], "title": "RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, they still rely on synchronous execution, leading to severe resource underutilization and throughput limitations during environment interaction, policy generation (rollout), and model update phases (actor). To overcome this challenge, this paper, for the first time, proposes and implements a fully-asynchronous policy training framework encompassing the entire pipeline from environment interaction, rollout generation, to actor policy updates. Systematically drawing inspiration from asynchronous optimization ideas in large model RL, our framework designs a multi-level decoupled architecture. This includes asynchronous parallelization of environment interaction and trajectory collection, streaming execution for policy generation, and decoupled scheduling for training updates. We validated the effectiveness of our method across diverse VLA models and environments. On the LIBERO benchmark, the framework achieves throughput improvements of up to 59.25\\% compared to existing synchronous strategies. When deeply optimizing separation strategies, throughput can be increased by as much as 126.67\\%. We verified the effectiveness of each asynchronous component via ablation studies. Scaling law validation across 8 to 256 GPUs demonstrates our method's excellent scalability under most conditions.", "AI": {"tldr": "提出了一种全异步的RL-VLA训练框架，提升了模型效率。", "motivation": "现有基于强化学习的VLA模型培训方法效率低下，依赖同步执行导致资源利用率低和吞吐量限制。", "method": "设计了一个多级解耦架构，实现环境交互、轨迹收集与策略生成及训练更新阶段的全异步并行化。", "result": "在LIBERO基准测试中，框架相比现有同步策略提升了59.25%的吞吐率；通过优化分离策略，吞吐量最多可提升126.67%。", "conclusion": "该方法显著提高了VLA模型培训效率，并验证了其良好的扩展性。"}}
{"id": "2602.05762", "pdf": "https://arxiv.org/pdf/2602.05762", "abs": "https://arxiv.org/abs/2602.05762", "authors": ["Andrei Kozyrev", "Nikita Khramov", "Denis Lochmelis", "Valerio Morelli", "Gleb Solovev", "Anton Podkopaev"], "title": "RocqSmith: Can Automatic Optimization Forge Better Proof Agents?", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SE"], "comment": null, "summary": "This work studies the applicability of automatic AI agent optimization methods to real-world agents in formal verification settings, focusing on automated theorem proving in Rocq as a representative and challenging domain. We evaluate how different automatic agent optimizers perform when applied to the task of optimizing a Rocq proof-generation agent, and assess whether parts of the fine-grained tuning of agentic systems, such as prompt design, contextual knowledge, and control strategies, can be automated. Our results show that while several optimizers yield measurable improvements, simple few-shot bootstrapping is the most consistently effective; however, none of the studied methods matches the performance of a carefully engineered state-of-the-art proof agent.", "AI": {"tldr": "研究自动优化方法在形式验证设置中的适用性，特别是在Rocq中进行自动化定理证明时的性能表现。", "motivation": "探讨利用自动AI代理优化技术提高现实世界代理的表现力，特别是针对正式验证环境下的定理证明任务。", "method": "评估不同的自动代理优化器在调整一个Rocq定理生成代理方面的效果，并测试是否可以自动化细粒度的系统调优过程，如提示设计、上下文知识和控制策略。", "result": "尽管一些优化方法带来可衡量改进，但简单的少样本引导是最具持续有效性的。但是，没有一种方法能够达到精心工程化的最先进的证明代理的表现水平。", "conclusion": "自动优化技术在一定程度上可以改善定理生成代理的性能，但在复杂任务中仍然需要人工调优以获得最佳结果。"}}
{"id": "2602.05760", "pdf": "https://arxiv.org/pdf/2602.05760", "abs": "https://arxiv.org/abs/2602.05760", "authors": ["Andreea Tulbure", "Carmen Scheidemann", "Elias Steiner", "Marco Hutter"], "title": "Task-Oriented Robot-Human Handovers on Legged Manipulators", "categories": ["cs.RO", "cs.HC"], "comment": "Accepted to 21st ACM/IEEE International Conference on Human-Robot Interaction (HRI) 2026", "summary": "Task-oriented handovers (TOH) are fundamental to effective human-robot collaboration, requiring robots to present objects in a way that supports the human's intended post-handover use. Existing approaches are typically based on object- or task-specific affordances, but their ability to generalize to novel scenarios is limited. To address this gap, we present AFT-Handover, a framework that integrates large language model (LLM)-driven affordance reasoning with efficient texture-based affordance transfer to achieve zero-shot, generalizable TOH. Given a novel object-task pair, the method retrieves a proxy exemplar from a database, establishes part-level correspondences via LLM reasoning, and texturizes affordances for feature-based point cloud transfer. We evaluate AFT-Handover across diverse task-object pairs, showing improved handover success rates and stronger generalization compared to baselines. In a comparative user study, our framework is significantly preferred over the current state-of-the-art, effectively reducing human regrasping before tool use. Finally, we demonstrate TOH on legged manipulators, highlighting the potential of our framework for real-world robot-human handovers.", "AI": {"tldr": "本文提出了AFT-Handover框架，用于实现基于大语言模型的零样本任务导向式人机交接。", "motivation": "现有的任务导向式交接方法依赖于特定对象或任务的特性，难以泛化到新的场景。因此，提出了一种结合大型语言模型驱动的属性推理和纹理传递的新框架来解决此问题。", "method": "该方法通过大语言模型从数据库中检索代理实例，并利用语言模型进行局部对应关系建立，然后通过纹理化将这些特征转移到点云上，实现了零样本的任务导向式交接。", "result": "实验表明，与现有基线相比，AFT-Handover在不同的对象任务组合下成功率更高且具有更强的泛化能力。用户研究也显示该框架更受欢迎，能够有效降低人在接收到工具后重新抓取的概率。", "conclusion": "本文通过实际演示证明了AFT-Handover框架的有效性，并展示了其在腿足式机械臂上实现人机交接的潜力，为真实世界的人机交互提供了新的解决方案。"}}
{"id": "2602.05755", "pdf": "https://arxiv.org/pdf/2602.05755", "abs": "https://arxiv.org/abs/2602.05755", "authors": ["Ti Wang", "Xiaohang Yu", "Mackenzie Weygandt Mathis"], "title": "FMPose3D: monocular 3D pose estimation via flow matching", "categories": ["cs.CV"], "comment": null, "summary": "Monocular 3D pose estimation is fundamentally ill-posed due to depth ambiguity and occlusions, thereby motivating probabilistic methods that generate multiple plausible 3D pose hypotheses. In particular, diffusion-based models have recently demonstrated strong performance, but their iterative denoising process typically requires many timesteps for each prediction, making inference computationally expensive. In contrast, we leverage Flow Matching (FM) to learn a velocity field defined by an Ordinary Differential Equation (ODE), enabling efficient generation of 3D pose samples with only a few integration steps. We propose a novel generative pose estimation framework, FMPose3D, that formulates 3D pose estimation as a conditional distribution transport problem. It continuously transports samples from a standard Gaussian prior to the distribution of plausible 3D poses conditioned only on 2D inputs. Although ODE trajectories are deterministic, FMPose3D naturally generates various pose hypotheses by sampling different noise seeds. To obtain a single accurate prediction from those hypotheses, we further introduce a Reprojection-based Posterior Expectation Aggregation (RPEA) module, which approximates the Bayesian posterior expectation over 3D hypotheses. FMPose3D surpasses existing methods on the widely used human pose estimation benchmarks Human3.6M and MPI-INF-3DHP, and further achieves state-of-the-art performance on the 3D animal pose datasets Animal3D and CtrlAni3D, demonstrating strong performance across both 3D pose domains. The code is available at https://github.com/AdaptiveMotorControlLab/FMPose3D.", "AI": {"tldr": "该论文提出了FMPose3D，一种基于流匹配的单目三维姿态估计框架。", "motivation": "单目三维姿态估计算法存在深度模糊和遮挡的问题，概率方法通过生成多个可能的姿态假设来解决这些问题。然而现有扩散模型需要大量的迭代步骤，使得推断过程变得复杂且耗时。", "method": "FMPose3D将三维姿态估计问题表述为条件分布传输问题，并利用流匹配学习由常微分方程定义的速度场以高效生成三维姿态样本。它通过采样不同的噪声种子自然地产生各种姿态假设，再使用RPEA模块从这些假设中获得准确的单一预测。", "result": "在Human3.6M和MPI-INF-3DHP等常用人类姿态估计基准上超过现有方法，并且在Animal3D和CtrlAni3D等三维动物姿态数据集上达到了最先进的性能，展示了其强大的跨领域适应能力。", "conclusion": "FMPose3D通过流匹配学习速度场并利用RPEA模块从多个假设中选择准确的预测，从而提高单目三维姿态估计效率和准确性。"}}
{"id": "2602.05754", "pdf": "https://arxiv.org/pdf/2602.05754", "abs": "https://arxiv.org/abs/2602.05754", "authors": ["Seonghye Cho", "Jaemin Han", "Hyunjin Kim", "Euisoo Jung", "Jae-Gil Lee"], "title": "TimelyFreeze: Adaptive Parameter Freezing Mechanism for Pipeline Parallelism", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Pipeline parallelism enables training models that exceed single-device memory, but practical throughput remains limited by pipeline bubbles. Although parameter freezing can improve training throughput by adaptively skipping backward computation, existing methods often over-freeze parameters, resulting in unnecessary accuracy degradation. To address this issue, we propose TimelyFreeze, which models the pipeline schedule as a directed acyclic graph and solves a linear program to compute optimal freeze ratios that minimize batch execution time under accuracy constraints. Experiments show that TimelyFreeze achieves up to 40% training throughput improvement on LLaMA-8B with comparable accuracy. Overall, it enables faster large-scale model training without compromising convergence and generalizes across diverse pipeline-parallel settings.", "AI": {"tldr": "提出了一种适应性参数冻结机制TimelyFreeze，以优化管道并行训练中的吞吐量。", "motivation": "现有的参数冻结方法可能导致过度冻结，从而影响模型精度。因此需要一种新的机制来平衡吞吐量和精度之间的关系。", "method": "通过将管道调度建模为有向无环图，并解决线性规划问题以计算最优冻结比率，该比率在保持准确性的同时最小化批量执行时间。", "result": "实验结果表明，在LLaMA-8B模型上使用TimelyFreeze可以实现高达40%的训练吞吐量提升，同时精度基本不受影响。", "conclusion": "TimelyFreeze能够加速大规模模型的训练，提高管道并行设置下的性能，并在不损害收敛性和泛化能力的情况下保持准确性。"}}
{"id": "2602.05748", "pdf": "https://arxiv.org/pdf/2602.05748", "abs": "https://arxiv.org/abs/2602.05748", "authors": ["Amit Kravchik Taub", "Fred M. Grabovski", "Guy Amit", "Yisroel Mirsky"], "title": "LeakBoost: Perceptual-Loss-Based Membership Inference Attack", "categories": ["cs.AI"], "comment": null, "summary": "Membership inference attacks (MIAs) aim to determine whether a sample was part of a model's training set, posing serious privacy risks for modern machine-learning systems. Existing MIAs primarily rely on static indicators, such as loss or confidence, and do not fully leverage the dynamic behavior of models when actively probed. We propose LeakBoost, a perceptual-loss-based interrogation framework that actively probes a model's internal representations to expose hidden membership signals. Given a candidate input, LeakBoost synthesizes an interrogation image by optimizing a perceptual (activation-space) objective, amplifying representational differences between members and non-members. This image is then analyzed by an off-the-shelf membership detector, without modifying the detector itself. When combined with existing membership inference methods, LeakBoost achieves substantial improvements at low false-positive rates across multiple image classification datasets and diverse neural network architectures. In particular, it raises AUC from near-chance levels (0.53-0.62) to 0.81-0.88, and increases TPR at 1 percent FPR by over an order of magnitude compared to strong baseline attacks. A detailed sensitivity analysis reveals that deeper layers and short, low-learning-rate optimization produce the strongest leakage, and that improvements concentrate in gradient-based detectors. LeakBoost thus offers a modular and computationally efficient way to assess privacy risks in white-box settings, advancing the study of dynamic membership inference.", "AI": {"tldr": "提出了一种基于感知损失的会员推断攻击框架LeakBoost，用于增强模型训练集成员身份识别。", "motivation": "现有会员推断攻击方法主要依赖静态指标未能充分利用模型动态行为。研究目的是通过主动探查模型内部表示来揭示隐藏的成员信号。", "method": "提出一种感知损失优化的合成图像框架LeakBoost，该框架通过对候选输入进行优化以增强代表性差异，从而暴露隐含成员信息。无需修改检测器本身即可分析合成图像中的会员身份。", "result": "与现有方法结合使用时，在多个数据集和架构下取得显著改进，尤其是在低虚警率情况下的真阳性率提高超过一个数量级。", "conclusion": "LeakBoost提供了一种模块化且计算效率高的白盒隐私风险评估方法，增强了动态会员推断研究。"}}
{"id": "2602.05746", "pdf": "https://arxiv.org/pdf/2602.05746", "abs": "https://arxiv.org/abs/2602.05746", "authors": ["Xin Chen", "Jie Zhang", "Florian Tramer"], "title": "Learning to Inject: Automated Prompt Injection via Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Prompt injection is one of the most critical vulnerabilities in LLM agents; yet, effective automated attacks remain largely unexplored from an optimization perspective. Existing methods heavily depend on human red-teamers and hand-crafted prompts, limiting their scalability and adaptability. We propose AutoInject, a reinforcement learning framework that generates universal, transferable adversarial suffixes while jointly optimizing for attack success and utility preservation on benign tasks. Our black-box method supports both query-based optimization and transfer attacks to unseen models and tasks. Using only a 1.5B parameter adversarial suffix generator, we successfully compromise frontier systems including GPT 5 Nano, Claude Sonnet 3.5, and Gemini 2.5 Flash on the AgentDojo benchmark, establishing a stronger baseline for automated prompt injection research.", "AI": {"tldr": "该论文提出了一种使用强化学习的自动攻击框架AutoInject，用于生成通用且可转移的对抗性后缀以进行提示注入。", "motivation": "现有的方法依赖于人工团队和手工设计的提示语句，限制了它们的规模性和适应性。为此，作者提出了一个自动化的方法来优化并提高攻击的成功率以及在良性任务上的实用价值。", "method": "AutoInject是一个基于强化学习框架的自动攻击系统，它生成对抗性的后缀以进行黑盒操作，并支持查询和迁移攻击。", "result": "使用1.5B参数的对抗性后缀生成器，在AgentDojo基准测试中成功破坏了包括GPT 5 Nano、Claude Sonnet 3.5 和Gemini 2.5 Flash等前沿系统，建立了自动提示注入研究的新标准。", "conclusion": "AutoInject通过强化学习框架提高了对大型语言模型系统的攻击能力，并为自动化提示注入的研究奠定了更坚实的基础。"}}
{"id": "2602.05738", "pdf": "https://arxiv.org/pdf/2602.05738", "abs": "https://arxiv.org/abs/2602.05738", "authors": ["Sajjan Acharya", "Pralisha Kansakar"], "title": "Disc-Centric Contrastive Learning for Lumbar Spine Severity Grading", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "This work examines a disc-centric approach for automated severity grading of lumbar spinal stenosis from sagittal T2-weighted MRI. The method combines contrastive pretraining with disc-level fine-tuning, using a single anatomically localized region of interest per intervertebral disc. Contrastive learning is employed to help the model focus on meaningful disc features and reduce sensitivity to irrelevant differences in image appearance. The framework includes an auxiliary regression task for disc localization and applies weighted focal loss to address class imbalance. Experiments demonstrate a 78.1% balanced accuracy and a reduced severe-to-normal misclassification rate of 2.13% compared with supervised training from scratch. Detecting discs with moderate severity can still be challenging, but focusing on disc-level features provides a practical way to assess the lumbar spinal stenosis.", "AI": {"tldr": "研究提出了一种基于椎间盘的对比学习方法，用于自动分级腰椎管狭窄症严重程度。", "motivation": "旨在通过聚焦于椎间盘级别的特征来改善腰椎管狭窄症严重程度的自动化评估准确性。", "method": "利用对比预训练和椎间盘级微调的方法，并结合辅助回归任务进行椎间盘定位，使用加权焦点损失解决类别不平衡问题。", "result": "实验结果显示，该方法在平衡准确率方面达到78.1%，严重到正常的误分类率为2.13%。", "conclusion": "虽然检测中度严重程度的椎间盘仍然具有挑战性，但专注于椎间盘级别的特征提供了一种评估腰椎管狭窄症的有效途径。"}}
{"id": "2602.05737", "pdf": "https://arxiv.org/pdf/2602.05737", "abs": "https://arxiv.org/abs/2602.05737", "authors": ["Luca Ciampi", "Ludovico Iannello", "Fabrizio Tonelli", "Gabriele Lagani", "Angelo Di Garbo", "Federico Cremisi", "Giuseppe Amato"], "title": "Neuro-Inspired Visual Pattern Recognition via Biological Reservoir Computing", "categories": ["cs.CV", "cs.NE"], "comment": null, "summary": "In this paper, we present a neuro-inspired approach to reservoir computing (RC) in which a network of in vitro cultured cortical neurons serves as the physical reservoir. Rather than relying on artificial recurrent models to approximate neural dynamics, our biological reservoir computing (BRC) system leverages the spontaneous and stimulus-evoked activity of living neural circuits as its computational substrate. A high-density multi-electrode array (HD-MEA) provides simultaneous stimulation and readout across hundreds of channels: input patterns are delivered through selected electrodes, while the remaining ones capture the resulting high-dimensional neural responses, yielding a biologically grounded feature representation. A linear readout layer (single-layer perceptron) is then trained to classify these reservoir states, enabling the living neural network to perform static visual pattern-recognition tasks within a computer-vision framework. We evaluate the system across a sequence of tasks of increasing difficulty, ranging from pointwise stimuli to oriented bars, clock-digit-like shapes, and handwritten digits from the MNIST dataset. Despite the inherent variability of biological neural responses-arising from noise, spontaneous activity, and inter-session differences-the system consistently generates high-dimensional representations that support accurate classification. These results demonstrate that in vitro cortical networks can function as effective reservoirs for static visual pattern recognition, opening new avenues for integrating living neural substrates into neuromorphic computing frameworks. More broadly, this work contributes to the effort to incorporate biological principles into machine learning and supports the goals of neuro-inspired vision by illustrating how living neural systems can inform the design of efficient and biologically grounded computational models.", "AI": {"tldr": "本文提出了一种利用体外培养的大脑皮层神经元网络作为计算基础的生物型水库计算方法，用于静态视觉模式识别。", "motivation": "该研究旨在探索将生物神经系统整合到神经形态计算框架中的可能性，并展示如何使用活体神经网络来实现高效的视觉模式分类任务。", "method": "通过在高密度多电极阵列上刺激和读出来自培养的皮层神经元的反应，形成高维特征表示。然后训练一个线性读取层以识别这些水库状态并执行静态视觉模式识别任务。", "result": "该系统对于点状刺激、定向条纹、时钟数字形状以及MNIST数据集中的手写数字等不同难度的任务都显示出高度的分类准确性，表明活体神经网络可以作为有效的模式识别计算基础。", "conclusion": "研究表明，在体皮层神经元网络能够有效用于静态视觉模式识别任务，并且这一方法为将生物原理整合到机器学习和设计高效的生物启发式计算模型提供了新的途径。"}}
{"id": "2602.05735", "pdf": "https://arxiv.org/pdf/2602.05735", "abs": "https://arxiv.org/abs/2602.05735", "authors": ["Lixuan Guo", "Yifei Wang", "Tiansheng Wen", "Yifan Wang", "Aosong Feng", "Bo Chen", "Stefanie Jegelka", "Chenyu You"], "title": "CSRv2: Unlocking Ultra-Sparse Embeddings", "categories": ["cs.LG", "cs.AI", "cs.IR", "cs.IT"], "comment": "Accepted by ICLR2026", "summary": "In the era of large foundation models, the quality of embeddings has become a central determinant of downstream task performance and overall system capability. Yet widely used dense embeddings are often extremely high-dimensional, incurring substantial costs in storage, memory, and inference latency. To address these, Contrastive Sparse Representation (CSR) is recently proposed as a promising direction, mapping dense embeddings into high-dimensional but k-sparse vectors, in contrast to compact dense embeddings such as Matryoshka Representation Learning (MRL). Despite its promise, CSR suffers severe degradation in the ultra-sparse regime, where over 80% of neurons remain inactive, leaving much of its efficiency potential unrealized. In this paper, we introduce CSRv2, a principled training approach designed to make ultra-sparse embeddings viable. CSRv2 stabilizes sparsity learning through progressive k-annealing, enhances representational quality via supervised contrastive objectives, and ensures end-to-end adaptability with full backbone finetuning. CSRv2 reduces dead neurons from 80% to 20% and delivers a 14% accuracy gain at k=2, bringing ultra-sparse embeddings on par with CSR at k=8 and MRL at 32 dimensions, all with only two active features. While maintaining comparable performance, CSRv2 delivers a 7x speedup over MRL, and yields up to 300x improvements in compute and memory efficiency relative to dense embeddings in text representation. Extensive experiments across text and vision demonstrate that CSRv2 makes ultra-sparse embeddings practical without compromising performance, where CSRv2 achieves 7%/4% improvement over CSR when k=4 and further increases this gap to 14%/6% when k=2 in text/vision representation. By making extreme sparsity viable, CSRv2 broadens the design space for real-time and edge-deployable AI systems where both embedding quality and efficiency are critical.", "AI": {"tldr": "CSRv2是一种新的训练方法，旨在使极稀疏嵌入变得可行。", "motivation": "现有的密集嵌入由于维度高带来了存储、内存和推理延迟等成本问题。虽然对比稀疏表示(CSR)已被提出作为一种有前途的方向，但在极稀疏情况下性能下降严重。CSRv2的设计目的是解决这些问题，并提高嵌入质量同时保持效率。", "method": "CSRv2通过渐进式k退火稳定稀疏学习，利用监督对比目标增强表达能力，并进行全面的主干微调确保端到端适应性。", "result": "CSRv2将死神经元从80%降低至20%，在k=2时带来14％的精度提升。与MRL相比，CSRv2的速度提高了7倍，在文本表示中计算和内存效率相对密集嵌入提升了300倍。", "conclusion": "通过使极端稀疏成为可能，CSRv2扩大了实时和边缘部署AI系统的设计空间，同时保持了嵌入质量和效率的高标准。"}}
{"id": "2602.05734", "pdf": "https://arxiv.org/pdf/2602.05734", "abs": "https://arxiv.org/abs/2602.05734", "authors": ["Niall McCarroll", "Kevin Curran", "Eugene McNamee", "Angela Clist", "Andrew Brammer"], "title": "Evaluating the impact of word embeddings on similarity scoring in practical information retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Search behaviour is characterised using synonymy and polysemy as users often want to search information based on meaning. Semantic representation strategies represent a move towards richer associative connections that can adequately capture this complex usage of language. Vector Space Modelling (VSM) and neural word embeddings play a crucial role in modern machine learning and Natural Language Processing (NLP) pipelines. Embeddings use distributional semantics to represent words, sentences, paragraphs or entire documents as vectors in high dimensional spaces. This can be leveraged by Information Retrieval (IR) systems to exploit the semantic relatedness between queries and answers. This paper evaluates an alternative approach to measuring query statement similarity that moves away from the common similarity measure of centroids of neural word embeddings. Motivated by the Word Movers Distance (WMD) model, similarity is evaluated using the distance between individual words of queries and statements. Results from ranked query and response statements demonstrate significant gains in accuracy using the combined approach of similarity ranking through WMD with the word embedding techniques. The top performing WMD + GloVe combination outperforms all other state-of-the-art retrieval models including Doc2Vec and the baseline LSA model. Along with the significant gains in performance of similarity ranking through WMD, we conclude that the use of pre-trained word embeddings, trained on vast amounts of data, result in domain agnostic language processing solutions that are portable to diverse business use-cases.", "AI": {"tldr": "评估词嵌入在信息检索中相似度评分的影响", "motivation": "为了更准确地捕捉用户基于意义的搜索行为，探索使用Word Movers Distance（WMD）模型来衡量查询和陈述之间的语义相似性", "method": "通过结合WMD模型与预训练的词嵌入技术（如GloVe），并将其应用于信息检索系统中进行相似度排名", "result": "实验结果显示，WMD+GloVe组合在准确性上优于其他最先进的检索模型，包括Doc2Vec和LSA基线模型", "conclusion": "使用大量数据预训练的词嵌入技术能够提供跨领域适用的语言处理解决方案"}}
{"id": "2602.05730", "pdf": "https://arxiv.org/pdf/2602.05730", "abs": "https://arxiv.org/abs/2602.05730", "authors": ["Moussa Kassem Sbeyti", "Nadja Klein"], "title": "Depth as Prior Knowledge for Object Detection", "categories": ["cs.CV"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Detecting small and distant objects remains challenging for object detectors due to scale variation, low resolution, and background clutter. Safety-critical applications require reliable detection of these objects for safe planning. Depth information can improve detection, but existing approaches require complex, model-specific architectural modifications. We provide a theoretical analysis followed by an empirical investigation of the depth-detection relationship. Together, they explain how depth causes systematic performance degradation and why depth-informed supervision mitigates it. We introduce DepthPrior, a framework that uses depth as prior knowledge rather than as a fused feature, providing comparable benefits without modifying detector architectures. DepthPrior consists of Depth-Based Loss Weighting (DLW) and Depth-Based Loss Stratification (DLS) during training, and Depth-Aware Confidence Thresholding (DCT) during inference. The only overhead is the initial cost of depth estimation. Experiments across four benchmarks (KITTI, MS COCO, VisDrone, SUN RGB-D) and two detectors (YOLOv11, EfficientDet) demonstrate the effectiveness of DepthPrior, achieving up to +9% mAP$_S$ and +7% mAR$_S$ for small objects, with inference recovery rates as high as 95:1 (true vs. false detections). DepthPrior offers these benefits without additional sensors, architectural changes, or performance costs. Code is available at https://github.com/mos-ks/DepthPrior.", "AI": {"tldr": "本文提出了一种名为DepthPrior的框架，利用深度信息作为先验知识而非融合特征来改善对象检测器在小和远距离物体上的性能。", "motivation": "由于尺度变化、低分辨率和背景干扰的存在，现有的检测方法难以有效地检测小型及远处目标。为了解决这个问题，并提供安全应用中可靠的目标检测能力，本文探索了如何通过深度信息改进检测效果。", "method": "DepthPrior框架包括在训练时的基于深度损失加权（DLW）和基于深度损失分层（DLS），以及在推理阶段使用深度感知置信度阈值化（DCT）。这些技术能够利用预估的深度数据而无需对现有的检测器架构进行修改。", "result": "实验结果显示，DepthPrior可以在多个基准测试集上提高小物体的准确率和召回率，最高可达+9% mAP$_S$和+7% mAR$_S$。同时保持了较高的推理恢复比率（真实与误检比例）达到95:1。", "conclusion": "本文提出的DepthPrior框架能够利用深度信息显著提升检测器在处理小且远距离物体时的表现，而无需增加额外传感器或修改现有架构，并确保没有性能损失。"}}
{"id": "2602.05729", "pdf": "https://arxiv.org/pdf/2602.05729", "abs": "https://arxiv.org/abs/2602.05729", "authors": ["Lexiang Hu", "Youze Xue", "Dian Li", "Gang Liu", "Zhouchen Lin"], "title": "Adaptive Global and Fine-Grained Perceptual Fusion for MLLM Embeddings Compatible with Hard Negative Amplification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal embeddings serve as a bridge for aligning vision and language, with the two primary implementations -- CLIP-based and MLLM-based embedding models -- both limited to capturing only global semantic information. Although numerous studies have focused on fine-grained understanding, we observe that complex scenarios currently targeted by MLLM embeddings often involve a hybrid perceptual pattern of both global and fine-grained elements, thus necessitating a compatible fusion mechanism. In this paper, we propose Adaptive Global and Fine-grained perceptual Fusion for MLLM Embeddings (AGFF-Embed), a method that prompts the MLLM to generate multiple embeddings focusing on different dimensions of semantic information, which are then adaptively and smoothly aggregated. Furthermore, we adapt AGFF-Embed with the Explicit Gradient Amplification (EGA) technique to achieve in-batch hard negatives enhancement without requiring fine-grained editing of the dataset. Evaluation on the MMEB and MMVP-VLM benchmarks shows that AGFF-Embed comprehensively achieves state-of-the-art performance in both general and fine-grained understanding compared to other multimodal embedding models.", "AI": {"tldr": "本文提出了一种自适应的全局和细粒度感知融合方法AGFF-Embed，以提升多模态嵌入模型的表现。", "motivation": "当前多模态嵌入模型在复杂场景中的应用受限于只能捕捉到全球语义信息，未能充分融入细粒度理解的需求。", "method": "提出了一种新的融合机制AGFF-Embed，能够引导MLLM生成多个聚焦不同维度的语义信息嵌入，并通过自适应和渐进的方式进行聚合。此外还引入了EGA技术来增强批次中的硬负样本，无需对数据集做细致修改。", "result": "在MMEB和MMVP-VLM基准测试中表现出色，证明AGFF-Embed在全局理解与细粒度理解上均优于其他多模态嵌入模型。", "conclusion": "本文提出的AGFF-Embed方法显著提升了多模态嵌入模型在复杂场景下的理解和应用能力。"}}
{"id": "2602.05728", "pdf": "https://arxiv.org/pdf/2602.05728", "abs": "https://arxiv.org/abs/2602.05728", "authors": ["Hao Yang", "Zhiyu Yang", "Xupeng Zhang", "Wei Wei", "Yunjie Zhang", "Lin Yang"], "title": "CompactRAG: Reducing LLM Calls and Token Overhead in Multi-Hop Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) has become a key paradigm for knowledge-intensive question answering. However, existing multi-hop RAG systems remain inefficient, as they alternate between retrieval and reasoning at each step, resulting in repeated LLM calls, high token consumption, and unstable entity grounding across hops. We propose CompactRAG, a simple yet effective framework that decouples offline corpus restructuring from online reasoning. In the offline stage, an LLM reads the corpus once and converts it into an atomic QA knowledge base, which represents knowledge as minimal, fine-grained question-answer pairs. In the online stage, complex queries are decomposed and carefully rewritten to preserve entity consistency, and are resolved through dense retrieval followed by RoBERTa-based answer extraction. Notably, during inference, the LLM is invoked only twice in total - once for sub-question decomposition and once for final answer synthesis - regardless of the number of reasoning hops. Experiments on HotpotQA, 2WikiMultiHopQA, and MuSiQue demonstrate that CompactRAG achieves competitive accuracy while substantially reducing token consumption compared to iterative RAG baselines, highlighting a cost-efficient and practical approach to multi-hop reasoning over large knowledge corpora. The implementation is available at GitHub.", "AI": {"tldr": "CompactRAG是一种减少多跳问答中LLM调用和令牌消耗的有效框架。", "motivation": "现有的多跳RAG系统在每次步骤中交替进行检索和推理，导致了重复的LLM调用、高令牌消耗以及实体接地不稳定的问题。", "method": "提出了一种分离离线语料库重组与在线推理的方法。离线阶段通过一次LLM读取将语料转换为原子QA知识库；在线阶段复杂查询被分解并重写以保持实体一致性，然后进行密集检索和基于RoBERTa的答案提取。", "result": "实验表明，CompactRAG在HotpotQA、2WikiMultiHopQA和MuSiQue数据集上实现了与迭代RAG基线竞争的准确性，并大幅减少了令牌消耗。", "conclusion": "CompactRAG提供了一种成本效益高且实用的方法，在多跳推理中处理大规模知识语料库。"}}
{"id": "2602.05723", "pdf": "https://arxiv.org/pdf/2602.05723", "abs": "https://arxiv.org/abs/2602.05723", "authors": ["Taoye Yin", "Haoyuan Hu", "Yaxin Fan", "Xinhao Chen", "Xinya Wu", "Kai Deng", "Kezun Zhang", "Feng Wang"], "title": "Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification", "categories": ["cs.AI"], "comment": "accepted by ICASSP 2026", "summary": "In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.", "AI": {"tldr": "提出了一种新的强化学习框架，通过细粒度的知识验证来减少金融检索增强生成系统中的错误信息。", "motivation": "为了解决金融领域中检索增强生成模型生成的回答与检索文档不一致的问题，从而提高回答的准确性和可靠性。", "method": "引入了基于细粒度知识验证的强化学习框架（RLFKV），将金融响应分解成原子知识单元，并评估每个单位的准确性以计算精细的忠实奖励。此外，还加入了信息量奖励来防止策略模型过度简略的回答。", "result": "在公开的Financial Data Description (FDD)任务和新提出的FDD-ANT数据集上的实验表明，该方法显著提高了回答与检索文档的一致性。", "conclusion": "通过引入细粒度知识验证机制和信息量奖励策略，成功减少了金融领域中生成系统的错误信息问题，并且在多个测试集中都取得了良好效果。"}}
{"id": "2602.05718", "pdf": "https://arxiv.org/pdf/2602.05718", "abs": "https://arxiv.org/abs/2602.05718", "authors": ["Yunchuan Ma", "Laiyun Qing", "Guorong Li", "Yuqing Liu", "Yuankai Qi", "Qingming Huang"], "title": "Exploring the Temporal Consistency for Point-Level Weakly-Supervised Temporal Action Localization", "categories": ["cs.CV"], "comment": null, "summary": "Point-supervised Temporal Action Localization (PTAL) adopts a lightly frame-annotated paradigm (\\textit{i.e.}, labeling only a single frame per action instance) to train a model to effectively locate action instances within untrimmed videos. Most existing approaches design the task head of models with only a point-supervised snippet-level classification, without explicit modeling of understanding temporal relationships among frames of an action. However, understanding the temporal relationships of frames is crucial because it can help a model understand how an action is defined and therefore benefits localizing the full frames of an action. To this end, in this paper, we design a multi-task learning framework that fully utilizes point supervision to boost the model's temporal understanding capability for action localization. Specifically, we design three self-supervised temporal understanding tasks: (i) Action Completion, (ii) Action Order Understanding, and (iii) Action Regularity Understanding. These tasks help a model understand the temporal consistency of actions across videos. To the best of our knowledge, this is the first attempt to explicitly explore temporal consistency for point supervision action localization. Extensive experimental results on four benchmark datasets demonstrate the effectiveness of the proposed method compared to several state-of-the-art approaches.", "AI": {"tldr": "探索点级弱监督下的时序一致性以增强视频动作定位能力", "motivation": "现有方法在训练模型进行动作定位时，仅依赖于单帧标注而忽略了理解帧间的时间关系。这种时间关系对于模型理解和定位完整动作至关重要。因此，本研究旨在通过引入多任务学习框架来提升模型对时间一致性的理解能力。", "method": "设计了一个包含三个自监督任务的多任务学习框架：（i）动作完成、（ii）动作顺序理解、（iii）动作规律理解。这些任务帮助模型理解视频中动作的时间一致性，进而提高其在点级弱监督下的定位性能。", "result": "实验结果表明，所提出的方法与现有先进方法相比具有显著优势，在四个基准数据集上的表现均优于其他方法。", "conclusion": "本研究是首次尝试通过探索时序一致性来改进基于点监督的视频动作定位任务，有效提升了模型理解时间关系的能力及其在未修剪视频中的动作定位性能。"}}
{"id": "2602.05717", "pdf": "https://arxiv.org/pdf/2602.05717", "abs": "https://arxiv.org/abs/2602.05717", "authors": ["Tianyi Wang", "Long Li", "Hongcan Guo", "Yibiao Chen", "Yixia Li", "Yong Wang", "Yun Chen", "Guanhua Chen"], "title": "Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification", "categories": ["cs.AI"], "comment": "17 pages, 6 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.", "AI": {"tldr": "提出锚定策略优化（APO）方法，解决强化学习中探索坍缩问题。", "motivation": "揭示递归空间收缩现象导致的有效选择概率衰减，并指出KL正则化无法有效缓解此问题。", "method": "通过定义参考模型高置信度支持的安全流形，允许策略进行激进的尖锐化同时在错误修正时引入恢复力以防止坍缩。", "result": "实验证明APO方法打破准确性与多样性之间的权衡，在基准测试上显著提升Pass@1并恢复标准策略梯度法丢失的Pass@K多样性。", "conclusion": "APO通过最大化支持覆盖实现弹性恢复，有效缓解探索坍缩问题。"}}
{"id": "2602.05712", "pdf": "https://arxiv.org/pdf/2602.05712", "abs": "https://arxiv.org/abs/2602.05712", "authors": ["Lola Solovyeva", "Fernando Castor"], "title": "Towards Green AI: Decoding the Energy of LLM Inference in Software Development", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Context: AI-assisted tools are increasingly integrated into software development workflows, but their reliance on large language models (LLMs) introduces substantial computational and energy costs. Understanding and reducing the energy footprint of LLM inference is therefore essential for sustainable software development. Objective: In this study, we conduct a phase-level analysis of LLM inference energy consumption, distinguishing between the (1) prefill, where the model processes the input and builds internal representations, and (2) decoding, where output tokens are generated using the stored state. Method: We investigate six 6B-7B and four 3B-4B transformer-based models, evaluating them on code-centric benchmarks HumanEval for code generation and LongBench for code understanding. Results: Our findings show that, within both parameter groups, models exhibit distinct energy patterns across phases. Furthermore, we observed that increases in prefill cost amplify the energy cost per token during decoding, with amplifications ranging from 1.3% to 51.8% depending on the model. Lastly, three out of ten models demonstrate babbling behavior, adding excessive content to the output that unnecessarily inflates energy consumption. We implemented babbling suppression for code generation, achieving energy savings ranging from 44% to 89% without affecting generation accuracy. Conclusion: These findings show that prefill costs influence decoding, which dominates energy consumption, and that babbling suppression can yield up to 89% energy savings. Reducing inference energy therefore requires both mitigating babbling behavior and limiting impact of prefill on decoding.", "AI": {"tldr": "本文通过研究大型语言模型（LLM）在软件开发中的推理能耗，提出了减少能源消耗的方法。", "motivation": "随着AI辅助工具越来越多地集成到软件开发流程中，这些工具对大型语言模型的依赖带来了显著的计算和能量成本。为了实现可持续发展的软件开发，理解并降低LLM推理的能效是必要的。", "method": "本文通过在HumanEval（代码生成）和LongBench（代码理解）等基准上评估了六个6B-7B和四个3B-4B参数量级别的模型，进行了分阶段的能量消耗分析。研究区分了两个主要过程：预填充和解码。", "result": "实验结果显示，在不同模型之间存在显著的能耗模式差异；预填充成本增加会导致解码阶段每令牌能量消耗上升1.3%至51.8%，并且有三个模型表现出无意义冗余输出，占用了不必要的能源。通过抑制这种行为，实现了44%到89%的能量节约。", "conclusion": "研究指出，前处理（预填充）的成本影响解码过程的能耗，并且可以通过抑制无用生成来显著降低能耗，最高可达89%。因此，减少推理能耗需要同时限制预填充对解码的影响和防止不必要的输出增加。"}}
{"id": "2602.05711", "pdf": "https://arxiv.org/pdf/2602.05711", "abs": "https://arxiv.org/abs/2602.05711", "authors": ["Jingze Shi", "Zhangyang Peng", "Yizhang Zhu", "Yifan Wu", "Guang Liu", "Yuyu Luo"], "title": "OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts, enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access. To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.", "AI": {"tldr": "OmniMoE 提出了一个系统算法协同设计框架，通过引入向量级原子专家来优化混合专家架构的参数效率和执行速度。", "motivation": "当前 MoE 架构在提高参数效率的同时面临着硬件执行效率低下的问题。为了克服这一限制，提出 OmniMoE 来解决细粒度专家对路由复杂性和内存访问带来的挑战。", "method": "OmniMoE 使用了向量级原子专家设计，并引入了一个笛卡尔积路由器来减少路由复杂性，同时采用专家中心调度策略以提高执行效率。", "result": "实验结果显示，与现有的 MoE 基线相比，OmniMoE 在七项基准测试中实现了更高的准确性并大幅度减少了推理延迟。", "conclusion": "OmniMoE 展示了大规模细粒度混合专家架构在保持高精度的同时可以实现快速高效的运行。"}}
{"id": "2602.05710", "pdf": "https://arxiv.org/pdf/2602.05710", "abs": "https://arxiv.org/abs/2602.05710", "authors": ["Philippe Boisnard"], "title": "Ethology of Latent Spaces", "categories": ["cs.CY", "cs.CL", "cs.CV", "cs.LG"], "comment": "23. pages, 14 figures, presented Hyperheritage International Symposium 9 ( https://paragraphe.univ-paris8.fr/IMG/pdf/programme_colloque_his9_campuscondorcet_v3.pdf ) and accepted for publication in double-blind peer review in French in 2026-2027", "summary": "This study challenges the presumed neutrality of latent spaces in vision language models (VLMs) by adopting an ethological perspective on their algorithmic behaviors. Rather than constituting spaces of homogeneous indeterminacy, latent spaces exhibit model-specific algorithmic sensitivities, understood as differential regimes of perceptual salience shaped by training data and architectural choices. Through a comparative analysis of three models (OpenAI CLIP, OpenCLIP LAION, SigLIP) applied to a corpus of 301 artworks (15th to 20th), we reveal substantial divergences in the attribution of political and cultural categories. Using bipolar semantic axes derived from vector analogies (Mikolov et al., 2013), we show that SigLIP classifies 59.4% of the artworks as politically engaged, compared to only 4% for OpenCLIP. African masks receive the highest political scores in SigLIP while remaining apolitical in OpenAI CLIP. On an aesthetic colonial axis, inter-model discrepancies reach 72.6 percentage points. We introduce three operational concepts: computational latent politicization, describing the emergence of political categories without intentional encoding; emergent bias, irreducible to statistical or normative bias and detectable only through contrastive analysis; and three algorithmic scopic regimes: entropic (LAION), institutional (OpenAI), and semiotic (SigLIP), which structure distinct modes of visibility. Drawing on Foucault's notion of the archive, Jameson's ideologeme, and Simondon's theory of individuation, we argue that training datasets function as quasi-archives whose discursive formations crystallize within latent space. This work contributes to a critical reassessment of the conditions under which VLMs are applied to digital art history and calls for methodologies that integrate learning architectures into any delegation of cultural interpretation to algorithmic agents.", "AI": {"tldr": "本文通过比较三种模型在艺术品分类中的表现，探讨了视觉语言模型的潜在空间并非中立，而是存在特定的算法敏感性和偏见。", "motivation": "研究挑战了视觉语言模型潜在空间被认为是中性的假设，指出它们具有基于训练数据和架构选择的不同感知显著性。通过引入新的概念来理解这些差异，并呼吁对数字艺术史中的算法使用进行批判性评估。", "method": "采用三个不同模型（OpenAI CLIP、LAION、SigLIP）对301件艺术品进行分类，分析它们在政治和文化类别上的偏差，并提出计算隐性政治化等概念来解释这些差异。", "result": "结果显示，在使用不同的视觉语言模型时，艺术品被分类为具有政治意义的比例存在显著差异。例如，SigLIP将59.4%的艺术品归类为有政治意图的，而OpenCLIP仅为4%，这种偏差无法简单地用统计或规范偏差来解释。", "conclusion": "本文认为训练数据集作为准档案的功能，在潜在空间中结晶出特定的话语结构。研究强调了在将文化诠释委托给算法代理时需要考虑学习架构的方法论的重要性。"}}
{"id": "2602.05709", "pdf": "https://arxiv.org/pdf/2602.05709", "abs": "https://arxiv.org/abs/2602.05709", "authors": ["Yihao Ouyang", "Shiwei Li", "Haozhao Wang", "Xiandi Luo", "Zhuoqi Hu", "Yuetong Song", "Qiyu Qin", "Yichen Li", "Ruixuan Li"], "title": "Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions", "categories": ["cs.AI"], "comment": null, "summary": "Low-rank adaptation (LoRA) approximates the update of a pretrained weight matrix using the product of two low-rank matrices. However, standard LoRA follows an explicit-rank paradigm, where increasing model capacity requires adding more rows or columns (i.e., basis vectors) to the low-rank matrices, leading to substantial parameter growth. In this paper, we find that these basis vectors exhibit significant parameter redundancy and can be compactly represented by lightweight nonlinear functions. Therefore, we propose Generative Low-Rank Adapter (GenLoRA), which replaces explicit basis vector storage with nonlinear basis vector generation. Specifically, GenLoRA maintains a latent vector for each low-rank matrix and employs a set of lightweight radial basis functions (RBFs) to synthesize the basis vectors. Each RBF requires far fewer parameters than an explicit basis vector, enabling higher parameter efficiency in GenLoRA. Extensive experiments across multiple datasets and architectures show that GenLoRA attains higher effective LoRA ranks under smaller parameter budgets, resulting in superior fine-tuning performance. The code is available at https://anonymous.4open.science/r/GenLoRA-1519.", "AI": {"tldr": "提出了一种生成性低秩适配器GenLoRA，通过非线性的径向基函数代替显式的基矢量存储来提高参数效率。", "motivation": "标准的LoRA需要增加更多的行或列以提升模型容量，这导致了参数数量的增长。研究人员发现这些基矢量具有冗余性，并且可以用轻量级的非线性函数表示。", "method": "维护每个低秩矩阵的一个潜在向量，并使用径向基函数来合成基矢量。每个RBF所需的参数比显式的基矢量少很多，从而提高参数效率。", "result": "在多个数据集和架构上进行的广泛实验表明，GenLoRA能够在更小的参数预算下获得更高的有效LoRA秩，进而提升微调性能。", "conclusion": "通过采用非线性的径向基函数生成基矢量，GenLoRA显著提高了模型容量和参数效率。"}}
{"id": "2602.05706", "pdf": "https://arxiv.org/pdf/2602.05706", "abs": "https://arxiv.org/abs/2602.05706", "authors": ["Shadi Attarha", "Kanaga Shanmugi", "Anna Förster"], "title": "Poster: Camera Tampering Detection for Outdoor IoT Systems", "categories": ["cs.CV", "cs.AI"], "comment": "Proceedings of the 2024 INTERNATIONAL CONFERENCE ON EMBEDDED WIRELESS SYSTEMS AND NETWORKS (EWSN)", "summary": "Recently, the use of smart cameras in outdoor settings has grown to improve surveillance and security. Nonetheless, these systems are susceptible to tampering, whether from deliberate vandalism or harsh environmental conditions, which can undermine their monitoring effectiveness. In this context, detecting camera tampering is more challenging when a camera is capturing still images rather than video as there is no sequence of continuous frames over time. In this study, we propose two approaches for detecting tampered images: a rule-based method and a deep-learning-based method. The aim is to evaluate how each method performs in terms of accuracy, computational demands, and the data required for training when applied to real-world scenarios. Our results show that the deep-learning model provides higher accuracy, while the rule-based method is more appropriate for scenarios where resources are limited and a prolonged calibration phase is impractical. We also offer publicly available datasets with normal, blurred, and rotated images to support the development and evaluation of camera tampering detection methods, addressing the need for such resources.", "AI": {"tldr": "该论文提出两种方法用于检测室外物联网系统中的摄像头篡改：基于规则的方法和基于深度学习的方法，并评估了它们在准确率、计算需求以及所需训练数据量方面的性能。", "motivation": "随着智能摄像头在户外环境中的应用增加，这些系统的监控效果可能会因故意破坏或恶劣的天气条件而受到影响。特别是在相机捕获静态图像的情况下，篡改检测更为困难，因为没有连续帧的时间序列。", "method": "论文提出两种方法用于检测篡改图像：基于规则的方法和基于深度学习的方法，并通过实证研究评估了这两种方法的表现。", "result": "实验结果表明，尽管深度学习模型在准确率方面表现更佳，但是基于规则的方法更适合资源有限且不便于长时间校准的场景。此外，论文还提供了公开的数据集以支持摄像头篡改检测方法的研究和评估。", "conclusion": "该研究展示了两种不同的方法来解决室外物联网系统中的摄像头篡改问题，并指出根据实际情况选择合适的方法是重要的。"}}
{"id": "2602.05695", "pdf": "https://arxiv.org/pdf/2602.05695", "abs": "https://arxiv.org/abs/2602.05695", "authors": ["Hiari Pizzini Cavagna", "Andrea Proia", "Giacomo Madella", "Giovanni B. Esposito", "Francesco Antici", "Daniele Cesarini", "Zeynep Kiziltan", "Andrea Bartolini"], "title": "Determining Energy Efficiency Sweet Spots in Production LLM Inference", "categories": ["cs.AI", "cs.PF"], "comment": "To appear at ICPE 2026 (International Conference on Performance Engineering)", "summary": "Large Language Models (LLMs) inference is central in modern AI applications, making it critical to understand their energy footprint. Existing approaches typically estimate energy consumption through simple linear functions of input and output sequence lengths, yet our observations reveal clear Energy Efficiency regimes: peak efficiency occurs with short-to-moderate inputs and medium-length outputs, while efficiency drops sharply for long inputs or very short outputs, indicating a non-linear dependency. In this work, we propose an analytical model derived from the computational and memory-access complexity of the Transformer architecture, capable of accurately characterizing the efficiency curve as a function of input and output lengths. To assess its accuracy, we evaluate energy consumption using TensorRT-LLM on NVIDIA H100 GPUs across a diverse set of LLMs ranging from 1B to 9B parameters, including OPT, LLaMA, Gemma, Falcon, Qwen2, and Granite, tested over input and output lengths from 64 to 4096 tokens, achieving a mean MAPE of 1.79%. Our results show that aligning sequence lengths with these efficiency \"Sweet Spots\" can substantially reduce energy usage, supporting informed truncation, summarization, and adaptive generation strategies in production systems.", "AI": {"tldr": "研究确定了大型语言模型（LLMs）在推理过程中的能源效率最佳区间，并提出了一个基于Transformer架构复杂性分析的能耗预测模型。", "motivation": "现有的能耗估计方法通常使用输入和输出序列长度之间的线性关系，但观察表明存在明显的非线性能源效率区域。为了准确地描述这种依赖关系，需要开发一个新的模型来优化生产系统中的能效。", "method": "基于Transformer架构的计算和内存访问复杂度提出了一个分析模型，并通过在NVIDIA H100 GPU上使用TensorRT-LLM评估了不同大小的LLMs（从1B到9B参数）以及输入输出长度从64到4096令牌的数据集，实现了平均MAPE为1.79%。", "result": "研究表明将序列长度与效率“最佳区间”对齐可以显著降低能耗，并支持生产系统中截断、摘要和自适应生成策略的制定。", "conclusion": "通过提出一个基于Transformer架构复杂度分析的新模型，确定了LLMs推理过程中的能源效率最佳区间，优化了能效并支持更有效的生产部署。"}}
{"id": "2602.05688", "pdf": "https://arxiv.org/pdf/2602.05688", "abs": "https://arxiv.org/abs/2602.05688", "authors": ["Alex Vitvitskyi", "Michael Boratko", "Matej Grcic", "Razvan Pascanu", "Deep Shah", "Petar Veličković"], "title": "Mining Generalizable Activation Functions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The choice of activation function is an active area of research, with different proposals aimed at improving optimization, while maintaining expressivity. Additionally, the activation function can significantly alter the implicit inductive bias of the architecture, controlling its non-linear behavior. In this paper, in line with previous work, we argue that evolutionary search provides a useful framework for finding new activation functions, while we also make two novel observations. The first is that modern pipelines, such as AlphaEvolve, which relies on frontier LLMs as a mutator operator, allows for a much wider and flexible search space; e.g., over all possible python functions within a certain FLOP budget, eliminating the need for manually constructed search spaces. In addition, these pipelines will be biased towards meaningful activation functions, given their ability to represent common knowledge, leading to a potentially more efficient search of the space. The second observation is that, through this framework, one can target not only performance improvements but also activation functions that encode particular inductive biases. This can be done by using performance on out-of-distribution data as a fitness function, reflecting the degree to which the architecture respects the inherent structure in the data in a manner independent of distribution shifts. We carry an empirical exploration of this proposal and show that relatively small scale synthetic datasets can be sufficient for AlphaEvolve to discover meaningful activations.", "AI": {"tldr": "利用进化搜索框架寻找新的激活函数，通过使用现代管道和性能指标来优化激活函数的设计。", "motivation": "希望通过进化的搜索方式发现新型的、具有普适性的激活函数，并且这种方法可以基于出界数据集表现来指导搜索方向，以确保找到的激活函数能够适应不同的分布变化。", "method": "采用AlphaEvolve等现代进化搜索管道，在给定FLOP预算下探索所有可能的Python函数作为新的激活函数候选者；并通过在合成数据集上的性能评估，寻找编码特定归纳偏差的有效激活函数。", "result": "实验表明，通过这种方式可以在相对较小规模的数据集上找到有意义的、具有普适性的激活函数。", "conclusion": "利用进化搜索框架可以有效地发现新颖且高效的激活函数，并能够适应不同的分布变化。"}}
{"id": "2602.05687", "pdf": "https://arxiv.org/pdf/2602.05687", "abs": "https://arxiv.org/abs/2602.05687", "authors": ["Pavithren V S Pakianathan", "Rania Islambouli", "Diogo Branco", "Albrecht Schmidt", "Tiago Guerreiro", "Jan David Smeddinck"], "title": "Exploring AI-Augmented Sensemaking of Patient-Generated Health Data: A Mixed-Method Study with Healthcare Professionals in Cardiac Risk Reduction", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Individuals are increasingly generating substantial personal health and lifestyle data, e.g. through wearables and smartphones. While such data could transform preventative care, its integration into clinical practice is hindered by its scale, heterogeneity and the time pressure and data literacy of healthcare professionals (HCPs). We explore how large language models (LLMs) can support sensemaking of patient-generated health data (PGHD) with automated summaries and natural language data exploration. Using cardiovascular disease (CVD) risk reduction as a use case, 16 HCPs reviewed multimodal PGHD in a mixed-methods study with a prototype that integrated common charts, LLM-generated summaries, and a conversational interface. Findings show that AI summaries provided quick overviews that anchored exploration, while conversational interaction supported flexible analysis and bridged data-literacy gaps. However, HCPs raised concerns about transparency, privacy, and overreliance. We contribute empirical insights and sociotechnical design implications for integrating AI-driven summarization and conversation into clinical workflows to support PGHD sensemaking.", "AI": {"tldr": "研究探讨了人工智能（AI）在心脏病风险减少场景下，如何帮助医疗保健专业人员（HCPs）理解和分析患者生成的健康数据(PGHD)，通过原型系统提供自动化摘要和自然语言交互界面。", "motivation": "个人通过穿戴设备和智能手机等技术产生大量个人健康和生活方式数据。这些数据在预防性护理中具有巨大潜力，但由于其规模、异质性和医疗保健专业人员的时间压力及数据分析能力不足等因素的阻碍，整合到临床实践中较为困难。该研究旨在探索大型语言模型(LLM)如何帮助理解和分析患者生成的数据。", "method": "采用心血管疾病(CVD)风险减少作为案例场景，16名医疗保健专业人士在一个包含常见图表、LLM生成摘要和对话界面原型系统上进行多方法研究。参与者审查了多媒体PGHD。", "result": "AI生成的摘要可以快速提供数据概览，并为探索奠定基础；而对话交互支持灵活分析并填补数据能力差距，但HCP们也提出了关于透明度、隐私保护及过度依赖的问题。", "conclusion": "该研究提供了将AI驱动总结和会话功能集成到临床工作流程中的经验见解和社会技术设计建议。"}}
{"id": "2602.05683", "pdf": "https://arxiv.org/pdf/2602.05683", "abs": "https://arxiv.org/abs/2602.05683", "authors": ["Chuwei Wang", "Eduardo Sebastián", "Amanda Prorok", "Anastasia Bizyaeva"], "title": "From Vision to Decision: Neuromorphic Control for Autonomous Navigation and Tracking", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "Robotic navigation has historically struggled to reconcile reactive, sensor-based control with the decisive capabilities of model-based planners. This duality becomes critical when the absence of a predominant option among goals leads to indecision, challenging reactive systems to break symmetries without computationally-intense planners. We propose a parsimonious neuromorphic control framework that bridges this gap for vision-guided navigation and tracking. Image pixels from an onboard camera are encoded as inputs to dynamic neuronal populations that directly transform visual target excitation into egocentric motion commands. A dynamic bifurcation mechanism resolves indecision by delaying commitment until a critical point induced by the environmental geometry. Inspired by recently proposed mechanistic models of animal cognition and opinion dynamics, the neuromorphic controller provides real-time autonomy with a minimal computational burden, a small number of interpretable parameters, and can be seamlessly integrated with application-specific image processing pipelines. We validate our approach in simulation environments as well as on an experimental quadrotor platform.", "AI": {"tldr": "本文提出了一种基于神经形态控制的框架，用于自主导航和跟踪任务。", "motivation": "传统的机器人导航在反应式传感器控制系统与模型化规划器之间存在着矛盾。这种矛盾在于当目标选项不明显时，反应系统难以做出决策，并且需要复杂的计算资源来打破对称性。", "method": "该研究提出了一种基于视觉输入的神经形态控制框架。图像像素被编码为动态神经元群体的输入，直接将视觉目标激发转化为自我运动命令。通过引入环境几何形状诱导的临界点延迟决策，解决犹豫不决的问题。", "result": "该方法在模拟环境中和实验四旋翼平台上进行了验证，展示了实时自主性和较小计算负担的特点。", "conclusion": "所提出的神经形态控制框架为视觉指导的导航和跟踪提供了有效的解决方案。它具有解释性参数少、易于与特定图像处理管道集成的优点。"}}
{"id": "2602.05676", "pdf": "https://arxiv.org/pdf/2602.05676", "abs": "https://arxiv.org/abs/2602.05676", "authors": ["Inbar Gat", "Dana Cohen-Bar", "Guy Levy", "Elad Richardson", "Daniel Cohen-Or"], "title": "ShapeUP: Scalable Image-Conditioned 3D Editing", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Recent advancements in 3D foundation models have enabled the generation of high-fidelity assets, yet precise 3D manipulation remains a significant challenge. Existing 3D editing frameworks often face a difficult trade-off between visual controllability, geometric consistency, and scalability. Specifically, optimization-based methods are prohibitively slow, multi-view 2D propagation techniques suffer from visual drift, and training-free latent manipulation methods are inherently bound by frozen priors and cannot directly benefit from scaling. In this work, we present ShapeUP, a scalable, image-conditioned 3D editing framework that formulates editing as a supervised latent-to-latent translation within a native 3D representation. This formulation allows ShapeUP to build on a pretrained 3D foundation model, leveraging its strong generative prior while adapting it to editing through supervised training. In practice, ShapeUP is trained on triplets consisting of a source 3D shape, an edited 2D image, and the corresponding edited 3D shape, and learns a direct mapping using a 3D Diffusion Transformer (DiT). This image-as-prompt approach enables fine-grained visual control over both local and global edits and achieves implicit, mask-free localization, while maintaining strict structural consistency with the original asset. Our extensive evaluations demonstrate that ShapeUP consistently outperforms current trained and training-free baselines in both identity preservation and edit fidelity, offering a robust and scalable paradigm for native 3D content creation.", "AI": {"tldr": "ShapeUP是一个可扩展的基于图像条件的3D编辑框架，旨在解决现有3D编辑方法中的视觉控制、几何一致性及规模性问题。", "motivation": "现有的3D编辑框架难以在视觉可控性、几何一致性和可伸缩性之间找到平衡点；优化方法速度慢，多视图2D传播技术存在视觉漂移问题，无训练的潜在操作方式受限于固定的先验知识无法直接受益于规模效应。", "method": "ShapeUP通过监督学习将编辑任务作为从源3D形状到修改后3D形状的映射，并使用3D扩散变换器进行训练以实现这一目标；此方法利用图像作提示，提供细粒度视觉控制同时保持结构一致性。", "result": "实验结果表明，相比于现有基线模型，ShapeUP在身份保存和编辑保真度方面表现更好，展示出稳健且可扩展的原生3D内容生成能力。", "conclusion": "ShapeUP为解决现有3D编辑方法中的难题提供了有效方案，并展示了其在多个关键指标上的优越性。"}}
{"id": "2602.05675", "pdf": "https://arxiv.org/pdf/2602.05675", "abs": "https://arxiv.org/abs/2602.05675", "authors": ["Xuepeng Ren", "Maocai Wang", "Guangming Dai", "Zimin Liang", "Qianrong Liu", "Shengxiang Yang", "Miqing Li"], "title": "Variable Search Stepsize for Randomized Local Search in Multi-Objective Combinatorial Optimization", "categories": ["cs.NE"], "comment": null, "summary": "Over the past two decades, research in evolutionary multi-objective optimization has predominantly focused on continuous domains, with comparatively limited attention given to multi-objective combinatorial optimization problems (MOCOPs). Combinatorial problems differ significantly from continuous ones in terms of problem structure and landscape. Recent studies have shown that on MOCOPs multi-objective evolutionary algorithms (MOEAs) can even be outperformed by simple randomised local search. Starting with a randomly sampled solution in search space, randomised local search iteratively draws a random solution (from an archive) to perform local variation within its neighbourhood. However, in most existing methods, the local variation relies on a fixed neighbourhood, which limits exploration and makes the search easy to get trapped in local optima. In this paper, we present a simple yet effective local search method, called variable stepsize randomized local search (VS-RLS), which adjusts the stepsize during the search. VS-RLS transitions gradually from a broad, exploratory search in the early phases to a more focused, fine-grained search as the search progresses. We demonstrate the effectiveness and generalizability of VS-RLS through extensive evaluations against local search and MOEAs methods on diverse MOCOPs.", "AI": {"tldr": "提出了一种在多目标组合优化问题上有效的局部搜索方法VS-RLS，该方法通过调整步长来改进随机化本地搜索。", "motivation": "传统多目标进化算法在处理组合优化问题时表现不佳，并且大多数现有方法的局部变化基于固定的邻域结构，这限制了探索并可能导致陷入局部最优解。", "method": "VS-RLS根据搜索阶段逐步改变步长，从早期广泛的探索转向后期更精细的搜索。", "result": "通过与局部搜索和多目标进化算法在多种多目标组合优化问题上的对比实验，证明了VS-RLS的有效性和通用性。", "conclusion": "VS-RLS是一种改进随机化本地搜索方法，能够更好地解决多目标组合优化问题。"}}
{"id": "2602.05671", "pdf": "https://arxiv.org/pdf/2602.05671", "abs": "https://arxiv.org/abs/2602.05671", "authors": ["Damien Rudaz", "Barbara Nino Carreras", "Sara Merlino", "Brian L. Due", "Barry Brown"], "title": "(Computer) Vision in Action: Comparing Remote Sighted Assistance and a Multimodal Voice Agent in Inspection Sequences", "categories": ["cs.HC"], "comment": "Conditionally accepted at CHI 2026, 32 pages, 8 figures", "summary": "Does human-AI assistance unfold in the same way as human-human assistance? This research explores what can be learned from the expertise of blind individuals and sighted volunteers to inform the design of multimodal voice agents and address the enduring challenge of proactivity. Drawing on granular analysis of two representative fragments from a larger corpus, we contrast the practices co-produced by an experienced human remote sighted assistant and a blind participant-as they collaborate to find a stain on a blanket over the phone-with those achieved when the same participant worked with a multimodal voice agent on the same task, a few moments earlier. This comparison enables us to specify precisely which fundamental proactive practices the agent did not enact in situ. We conclude that, so long as multimodal voice agents cannot produce environmentally occasioned vision-based actions, they will lack a key resource relied upon by human remote sighted assistants.", "AI": {"tldr": "比较远程视障协助和多模态语音代理在检查序列中的表现，探讨人工智能辅助是否与人类帮助相同。", "motivation": "研究盲人专家和视力正常志愿者的经验以改善多模态语音代理设计并解决主动性挑战。", "method": "通过分析两个代表性片段来比较远程视障协助者与盲参与者合作寻找毯子上的污渍的实践，以及同一参与者使用多模态语音代理完成相同任务的情况。", "result": "发现多模态语音代理在实地操作中缺乏关键的主动性行为，这些行为是由远程视力辅助人执行的。", "conclusion": "只要多模态语音代理不能产生基于环境的视觉行动，它们就无法获得人类远程视力助理所依赖的关键资源。"}}
{"id": "2602.05670", "pdf": "https://arxiv.org/pdf/2602.05670", "abs": "https://arxiv.org/abs/2602.05670", "authors": ["Qing Wen", "Haohao Li", "Zhongjie Ba", "Peng Cheng", "Miao He", "Li Lu", "Kui Ren"], "title": "HyperPotter: Spell the Charm of High-Order Interactions in Audio Deepfake Detection", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "20 pages, 8 figures", "summary": "Advances in AIGC technologies have enabled the synthesis of highly realistic audio deepfakes capable of deceiving human auditory perception. Although numerous audio deepfake detection (ADD) methods have been developed, most rely on local temporal/spectral features or pairwise relations, overlooking high-order interactions (HOIs). HOIs capture discriminative patterns that emerge from multiple feature components beyond their individual contributions. We propose HyperPotter, a hypergraph-based framework that explicitly models these synergistic HOIs through clustering-based hyperedges with class-aware prototype initialization. Extensive experiments demonstrate that HyperPotter surpasses its baseline by an average relative gain of 22.15% across 11 datasets and outperforms state-of-the-art methods by 13.96% on 4 challenging cross-domain datasets, demonstrating superior generalization to diverse attacks and speakers.", "AI": {"tldr": "本文提出了HyperPotter框架，用于检测音频deepfake，该框架通过基于聚类的超边和类别感知原型初始化显式建模高阶交互。", "motivation": "当前大多数音频deepfake检测方法依赖于局部时域/频域特征或成对关系，忽略了高阶交互。这些交互可以捕获多特征组件协同作用产生的鉴别性模式。", "method": "HyperPotter框架通过基于聚类的超边和类别感知原型初始化来显式建模高阶交互。这种方法能更好地捕捉音频中复杂的相互作用。", "result": "实验结果表明，与基线相比，HyperPotter在11个数据集上平均提高了22.15%，并且在4个跨领域挑战性数据集上的表现优于当前最优方法13.96%。", "conclusion": "HyperPotter展示了其对各种攻击和说话人的强大泛化能力，在音频deepfake检测任务中表现出色。"}}
{"id": "2602.05668", "pdf": "https://arxiv.org/pdf/2602.05668", "abs": "https://arxiv.org/abs/2602.05668", "authors": ["Zhipeng Zhang", "Kai Li"], "title": "Stable but Wrong: When More Data Degrades Scientific Conclusions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern science increasingly relies on ever-growing observational datasets and automated inference pipelines, under the implicit belief that accumulating more data makes scientific conclusions more reliable. Here we show that this belief can fail in a fundamental and irreversible way. We identify a structural regime in which standard inference procedures converge smoothly, remain well calibrated, and pass conventional diagnostic checks, yet systematically converge to incorrect conclusions. This failure arises when the reliability of observations degrades in a manner that is intrinsically unobservable to the inference process itself. Using minimal synthetic experiments, we demonstrate that in this regime additional data do not correct error but instead amplify it, while residual-based and goodness-of-fit diagnostics remain misleadingly normal. These results reveal an intrinsic limit of data-driven science: stability, convergence, and confidence are not sufficient indicators of epistemic validity. We argue that inference cannot be treated as an unconditional consequence of data availability, but must instead be governed by explicit constraints on the integrity of the observational process.", "AI": {"tldr": "本文探讨了在某些情况下，更多的数据可能不会提高科学结论的准确性反而会导致错误结论。", "motivation": "现代科学研究依赖于不断增加的数据集和自动化的推断流程。然而，作者指出这种做法可能导致根本性的错误：当观测数据的质量下降时，即使收集到更多数据也无法纠正这一问题。", "method": "通过简单的合成实验展示了在某些特定条件下，增加数据量不仅无法修正错误反而会放大这些错误。同时说明了基于残差和拟合优度的诊断工具在这种情况下仍可能显示正常的结果，从而误导研究者。", "result": "研究表明，在观测过程中存在不可观察的质量下降时，即使推断过程稳定、收敛且具有足够的信心水平，所得出的结论也可能根本是错误的。", "conclusion": "数据驱动的科学研究存在固有的局限性：稳定性、可预测性和高自信度并不足以保证知识的有效性。需要对观测流程的完整性施加显式的限制来确保推断过程的准确性。"}}
{"id": "2602.05665", "pdf": "https://arxiv.org/pdf/2602.05665", "abs": "https://arxiv.org/abs/2602.05665", "authors": ["Chang Yang", "Chuang Zhou", "Yilin Xiao", "Su Dong", "Luyao Zhuang", "Yujing Zhang", "Zhu Wang", "Zijin Hong", "Zheng Yuan", "Zhishang Xiang", "Shengyuan Chen", "Huachi Zhou", "Qinggang Zhang", "Ninghao Liu", "Jinsong Su", "Xinrun Wang", "Yi Chang", "Xiao Huang"], "title": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications", "categories": ["cs.AI"], "comment": null, "summary": "Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands out as a powerful structure for agent memory due to the intrinsic capabilities to model relational dependencies, organize hierarchical information, and support efficient retrieval. This survey presents a comprehensive review of agent memory from the graph-based perspective. First, we introduce a taxonomy of agent memory, including short-term vs. long-term memory, knowledge vs. experience memory, non-structural vs. structural memory, with an implementation view of graph-based memory. Second, according to the life cycle of agent memory, we systematically analyze the key techniques in graph-based agent memory, covering memory extraction for transforming the data into the contents, storage for organizing the data efficiently, retrieval for retrieving the relevant contents from memory to support reasoning, and evolution for updating the contents in the memory. Third, we summarize the open-sourced libraries and benchmarks that support the development and evaluation of self-evolving agent memory. We also explore diverse application scenarios. Finally, we identify critical challenges and future research directions. This survey aims to offer actionable insights to advance the development of more efficient and reliable graph-based agent memory systems. All the related resources, including research papers, open-source data, and projects, are collected for the community in https://github.com/DEEP-PolyU/Awesome-GraphMemory.", "AI": {"tldr": "该论文从图谱视角综述了代理记忆，包括分类、技术分析和应用场景。", "motivation": "在大型语言模型（LLM）驱动的代理人中，内存成为完成长期复杂任务的核心模块，特别是对于多轮对话、游戏和科学发现等场景。图作为强大的结构可以建模关系依赖性，组织层次信息并支持高效检索。", "method": "论文首先介绍了代理记忆的分类；其次根据代理记忆生命周期系统分析了关键技术；最后探讨了开放源码库和基准测试，并讨论了各种应用场景及其挑战与未来研究方向。", "result": "综述总结了图谱为基础的记忆技术的关键组成部分，包括提取、存储、检索和进化。并提供了相关资源链接给社区。", "conclusion": "该论文旨在为更高效可靠的基于图谱的代理记忆系统发展提供实际见解"}}
{"id": "2602.05662", "pdf": "https://arxiv.org/pdf/2602.05662", "abs": "https://arxiv.org/abs/2602.05662", "authors": ["Swaroop Panda"], "title": "Making AI Agents Evaluate Misleading Charts without Nudging", "categories": ["cs.HC"], "comment": null, "summary": "AI agents are increasingly used as low-cost proxies for early visualization evaluation. In an initial study of deliberately flawed charts, we test whether agents spontaneously penalise chart junk and misleading encodings without being prompted to look for errors. Using established scales (BeauVis and PREVis), the agent evaluated visualizations containing decorative clutter, manipulated axes, and distorted proportional cues. The ratings of aesthetic appeal and perceived readability often remained relatively high even when graphical integrity was compromised. These results suggest that un-nudged AI agent evaluation may underweight integrity-related defects unless such checks are explicitly elicited.", "AI": {"tldr": "研究探讨了AI代理在未被提示的情况下能否自发地识别并评价误导性的图表。", "motivation": "随着AI代理作为早期可视化评估低成本替代品的使用增加，作者想探究这些代理是否能够在没有明确指示去寻找错误的情况下自动辨别出视觉混乱和误导性编码的存在。", "method": "利用BeauVis和PREVis等现有尺度对含有装饰性杂乱、操纵轴线以及扭曲比例提示等问题图表进行了评估。", "result": "尽管图形完整性受损，但美学吸引力和可读性的评分通常仍然相对较高。这表明除非明确要求进行检查，否则未被引导的AI代理可能会低估这些问题的存在。", "conclusion": "研究表明，在没有特别指导的情况下，AI代理可能无法充分识别图表中的完整性和缺陷问题，因此需要采取措施确保这些评估工具能够更准确地检测到潜在的问题。"}}
{"id": "2602.05660", "pdf": "https://arxiv.org/pdf/2602.05660", "abs": "https://arxiv.org/abs/2602.05660", "authors": ["Slawek Smyl", "Paweł Pełka", "Grzegorz Dudek"], "title": "Probabilistic Multi-Regional Solar Power Forecasting with Any-Quantile Recurrent Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The increasing penetration of photovoltaic (PV) generation introduces significant uncertainty into power system operation, necessitating forecasting approaches that extend beyond deterministic point predictions. This paper proposes an any-quantile probabilistic forecasting framework for multi-regional PV power generation based on the Any-Quantile Recurrent Neural Network (AQ-RNN). The model integrates an any-quantile forecasting paradigm with a dual-track recurrent architecture that jointly processes series-specific and cross-regional contextual information, supported by dilated recurrent cells, patch-based temporal modeling, and a dynamic ensemble mechanism. The proposed framework enables the estimation of calibrated conditional quantiles at arbitrary probability levels within a single trained model and effectively exploits spatial dependencies to enhance robustness at the system level. The approach is evaluated using 30 years of hourly PV generation data from 259 European regions and compared against established statistical and neural probabilistic baselines. The results demonstrate consistent improvements in forecast accuracy, calibration, and prediction interval quality, underscoring the suitability of the proposed method for uncertainty-aware energy management and operational decision-making in renewable-dominated power systems.", "AI": {"tldr": "本文提出了一种基于Any-Quantile Recurrent Neural Network (AQ-RNN) 的多区域光伏电力概率预测框架。", "motivation": "随着光伏发电的渗透率提高，对电力系统操作引入了不确定性，需要超越确定性点预测的方法来处理这种不确定性。", "method": "本文提出了一个任何分位数的概率预测框架，该框架基于Any-Quantile Recurrent Neural Network (AQ-RNN)，利用双重递归架构同时处理序列特定和跨区域上下文信息。", "result": "实验结果表明，该方法在多个预测准确度、校准和预测区间质量方面优于统计学和神经网络基准线方法。", "conclusion": "所提出的方法适用于不确定性意识下的能源管理和可再生能源主导的电力系统的操作决策。"}}
{"id": "2602.05656", "pdf": "https://arxiv.org/pdf/2602.05656", "abs": "https://arxiv.org/abs/2602.05656", "authors": ["Igor Santos-Grueiro"], "title": "Alignment Verifiability in Large Language Models: Normative Indistinguishability under Behavioral Evaluation", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages. Theoretical analysis of behavioral alignment evaluation", "summary": "Behavioral evaluation is the dominant paradigm for assessing alignment in large language models (LLMs). In practice, alignment is inferred from performance under finite evaluation protocols - benchmarks, red-teaming suites, or automated pipelines - and observed compliance is often treated as evidence of underlying alignment. This inference step, from behavioral evidence to claims about latent alignment properties, is typically implicit and rarely analyzed as an inference problem in its own right. We study this problem formally. We frame alignment evaluation as an identifiability question under partial observability and allow agent behavior to depend on information correlated with the evaluation regime. Within this setting, we introduce the Alignment Verifiability Problem and the notion of Normative Indistinguishability, capturing when distinct latent alignment hypotheses induce identical distributions over all evaluator-accessible signals. Our main result is a negative but sharply delimited identifiability theorem. Under finite behavioral evaluation and evaluation-aware agents, observed behavioral compliance does not uniquely identify latent alignment. That is, even idealized behavioral evaluation cannot, in general, certify alignment as a latent property. We further show that behavioral alignment tests should be interpreted as estimators of indistinguishability classes rather than verifiers of alignment. Passing increasingly stringent tests may reduce the space of compatible hypotheses, but cannot collapse it to a singleton under the stated conditions. This reframes alignment benchmarks as providing upper bounds on observable compliance within a regime, rather than guarantees of underlying alignment.", "AI": {"tldr": "研究通过行为评估验证大语言模型（LLMs）对齐性的可行性问题", "motivation": "探讨从有限的行为证据推断潜在的对齐性是否可靠，以及这种推理过程在实际中的局限性和不确定性", "method": "将对齐性评价视为部分可观察条件下的识别性问题，并引入对齐可验证性问题和规范不可区分的概念来分析行为一致性与潜在对齐性的关系", "result": "证明了即使理想化的行为评估也不能一般地认证潜在的对齐属性，通过行为测试只能减少兼容假设的空间但不能将其缩小到单一状态", "conclusion": "将对齐基准视为提供在给定范围内的可观察合规性上限而非保证潜在对齐性的保障"}}
{"id": "2602.05650", "pdf": "https://arxiv.org/pdf/2602.05650", "abs": "https://arxiv.org/abs/2602.05650", "authors": ["Amir Ansari", "Jana Subirana", "Bruna Silva", "Sergio Escalera", "David Gallardo-Pujol", "Cristina Palmero"], "title": "Enhancing Personality Recognition by Comparing the Predictive Power of Traits, Facets, and Nuances", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to the 2025 13th International Conference on Affective Computing and Intelligent Interaction (Late Breaking Results)", "summary": "Personality is a complex, hierarchical construct typically assessed through item-level questionnaires aggregated into broad trait scores. Personality recognition models aim to infer personality traits from different sources of behavioral data. However, reliance on broad trait scores as ground truth, combined with limited training data, poses challenges for generalization, as similar trait scores can manifest through diverse, context dependent behaviors. In this work, we explore the predictive impact of the more granular hierarchical levels of the Big-Five Personality Model, facets and nuances, to enhance personality recognition from audiovisual interaction data. Using the UDIVA v0.5 dataset, we trained a transformer-based model including cross-modal (audiovisual) and cross-subject (dyad-aware) attention mechanisms. Results show that nuance-level models consistently outperform facet and trait-level models, reducing mean squared error by up to 74% across interaction scenarios.", "AI": {"tldr": "本文探讨了利用Big-Five人格模型中更细致的层次（即方面和微妙之处）来增强从音视频互动数据中识别个性的效果。", "motivation": "传统的人格识别模型依赖广泛的人格评分作为真实值，这在结合有限的数据时存在挑战，因为相似的人格得分可能通过不同的情境行为表现出来。为了提高人格识别的准确性，本文探索了更细致的人格层次（方面和微妙之处）的影响。", "method": "使用UDIVA v0.5数据集，训练了一个具有跨模式（音视频）和跨主体注意机制的transformer模型。", "result": "结果表明，在互动场景下，微妙层面的模型比方面和特质层面的模型表现更好，平均平方误差最多减少了74%。", "conclusion": "通过利用更细致的人格层次信息，可以显著提高从音视频数据中识别人格特征的效果。"}}
{"id": "2602.05638", "pdf": "https://arxiv.org/pdf/2602.05638", "abs": "https://arxiv.org/abs/2602.05638", "authors": ["Jinlin Wu", "Felix Holm", "Chuxi Chen", "An Wang", "Yaxin Hu", "Xiaofan Ye", "Zelin Zang", "Miao Xu", "Lihua Zhou", "Huai Liao", "Danny T. M. Chan", "Ming Feng", "Wai S. Poon", "Hongliang Ren", "Dong Yi", "Nassir Navab", "Gaofeng Meng", "Jiebo Luo", "Hongbin Liu", "Zhen Lei"], "title": "UniSurg: A Video-Native Foundation Model for Universal Understanding of Surgical Videos", "categories": ["cs.CV"], "comment": null, "summary": "While foundation models have advanced surgical video analysis, current approaches rely predominantly on pixel-level reconstruction objectives that waste model capacity on low-level visual details - such as smoke, specular reflections, and fluid motion - rather than semantic structures essential for surgical understanding. We present UniSurg, a video-native foundation model that shifts the learning paradigm from pixel-level reconstruction to latent motion prediction. Built on the Video Joint Embedding Predictive Architecture (V-JEPA), UniSurg introduces three key technical innovations tailored to surgical videos: 1) motion-guided latent prediction to prioritize semantically meaningful regions, 2) spatiotemporal affinity self-distillation to enforce relational consistency, and 3) feature diversity regularization to prevent representation collapse in texture-sparse surgical scenes. To enable large-scale pretraining, we curate UniSurg-15M, the largest surgical video dataset to date, comprising 3,658 hours of video from 50 sources across 13 anatomical regions. Extensive experiments across 17 benchmarks demonstrate that UniSurg significantly outperforms state-of-the-art methods on surgical workflow recognition (+14.6% F1 on EgoSurgery, +10.3% on PitVis), action triplet recognition (39.54% mAP-IVT on CholecT50), skill assessment, polyp segmentation, and depth estimation. These results establish UniSurg as a new standard for universal, motion-oriented surgical video understanding.", "AI": {"tldr": "UniSurg是一种面向手术视频的新型基础模型，它从像素级重建转向潜在运动预测，以提高对视频中语义结构的理解。", "motivation": "当前的方法过于依赖于低层次视觉细节，如烟雾、镜面反射和流体运动等。为此，作者提出了UniSurg，一种基于视频联合嵌入预测架构的模型，旨在更关注手术视频中的语义结构。", "method": "UniSurg引入了三种关键技术改进：1）运动引导潜在预测来优先考虑具有意义的区域；2）时空亲和性自我蒸馏以强制执行关系一致性；3）特征多样性正则化以防止在纹理稀疏的手术场景中表示崩溃。为了大规模预训练，作者创建了UniSurg-15M数据集。", "result": "通过广泛的实验，UniSurg在工作流程识别、动作三元组识别、技能评估、息肉分割和深度估计等方面都超过了最先进的方法。", "conclusion": "这些结果表明，UniSurg是面向手术视频理解的新标准。"}}
{"id": "2602.05636", "pdf": "https://arxiv.org/pdf/2602.05636", "abs": "https://arxiv.org/abs/2602.05636", "authors": ["Benny Cheung"], "title": "Generative Ontology: When Structured Knowledge Learns to Create", "categories": ["cs.AI", "cs.CL"], "comment": "15 pages, 6 figures, 6 tables. Code available at https://github.com/bennycheung/GameGrammarCLI", "summary": "Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity. Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional \"anxiety\" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components. We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt (\"bioluminescent fungi competing in a cave ecosystem\"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative. The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.", "AI": {"tldr": "本文提出了一种生成本体论框架，结合了传统本体的知识结构和大规模语言模型的创造力，用于生成符合结构性约束的同时保持创意性的新作品。", "motivation": "传统的本体能够描述领域结构但无法生成新的事物。而大型语言模型虽能流畅地生成内容，但往往缺乏结构性的有效性。因此，本文旨在结合两者的优势，创造出既能遵循结构性规则又能产生创新成果的系统。", "method": "该框架将领域的知识编码为可执行的Pydantic模式，并通过DSPy签名约束大规模语言模型的生成过程。利用多智能体管道分配不同本体领域中的特定角色，以实现游戏系统的架构设计、叙事整合和漏洞识别等任务。", "result": "通过GameGrammar系统演示了该框架的有效性：给定一个主题提示（如“发光真菌在洞穴生态系统中竞争”），可以生成结构完整且可玩的游戏规格说明。这些输出符合本体论约束，同时保持真正的创造性。", "conclusion": "本文提出的方法证明，在遵循结构性规则的基础上，能够实现创新的生成性创作；类似于语法使诗歌成为可能的方式，本体论也使得有结构的生成成为可能。"}}
{"id": "2602.05629", "pdf": "https://arxiv.org/pdf/2602.05629", "abs": "https://arxiv.org/abs/2602.05629", "authors": ["Jianlei Chi", "Yuzhen Wu", "Jiaxuan Hou", "Xiaodong Zhang", "Ming Fan", "Suhui Sun", "Weijun Dai", "Bo Li", "Jianguo Sun", "Jun Sun"], "title": "ROMAN: Reward-Orchestrated Multi-Head Attention Network for Autonomous Driving System Testing", "categories": ["cs.CV"], "comment": "The manuscript includes 13 pages, 8 tables, and 7 figures", "summary": "Automated Driving System (ADS) acts as the brain of autonomous vehicles, responsible for their safety and efficiency. Safe deployment requires thorough testing in diverse real-world scenarios and compliance with traffic laws like speed limits, signal obedience, and right-of-way rules. Violations like running red lights or speeding pose severe safety risks. However, current testing approaches face significant challenges: limited ability to generate complex and high-risk law-breaking scenarios, and failing to account for complex interactions involving multiple vehicles and critical situations. To address these challenges, we propose ROMAN, a novel scenario generation approach for ADS testing that combines a multi-head attention network with a traffic law weighting mechanism. ROMAN is designed to generate high-risk violation scenarios to enable more thorough and targeted ADS evaluation. The multi-head attention mechanism models interactions among vehicles, traffic signals, and other factors. The traffic law weighting mechanism implements a workflow that leverages an LLM-based risk weighting module to evaluate violations based on the two dimensions of severity and occurrence. We have evaluated ROMAN by testing the Baidu Apollo ADS within the CARLA simulation platform and conducting extensive experiments to measure its performance. Experimental results demonstrate that ROMAN surpassed state-of-the-art tools ABLE and LawBreaker by achieving 7.91% higher average violation count than ABLE and 55.96% higher than LawBreaker, while also maintaining greater scenario diversity. In addition, only ROMAN successfully generated violation scenarios for every clause of the input traffic laws, enabling it to identify more high-risk violations than existing approaches.", "AI": {"tldr": "ROMAN是一种新型的自动驾驶系统测试场景生成方法，结合了多头注意力网络和交通法规加权机制。", "motivation": "当前自动驾驶系统的测试面临挑战，包括难以生成复杂且高风险的违规场景以及无法处理涉及多车辆及关键情况的复杂交互。为了解决这些问题，提出了ROMAN方案。", "method": "ROMAN使用多头注意力网络来模拟车辆、交通信号及其他因素之间的互动，并通过基于大模型的风险加权模块实施一个结合严重性和发生频率两个维度评估违规行为的工作流程。", "result": "实验结果显示，在百度阿波罗自动驾驶系统测试中，ROMAN比ABLE和LawBreaker工具在平均违规次数上分别提高了7.91%和55.96%，并且保持了更高的场景多样性。此外，ROMAN能够为所有输入的交通法规条款生成违反情景。", "conclusion": "研究表明ROMAN不仅能在自动驾驶系统测试中发现更多高风险的违规行为，而且还能提供更加全面和多样化的测试场景。"}}
{"id": "2602.05628", "pdf": "https://arxiv.org/pdf/2602.05628", "abs": "https://arxiv.org/abs/2602.05628", "authors": ["Alastair Howcroft", "Amber Bennett-Weston", "Ahmad Khan", "Joseff Griffiths", "Simon Gay", "Jeremy Howick"], "title": "AI chatbots versus human healthcare professionals: a systematic review and meta-analysis of empathy in patient care", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "Open Access Invited Review. Systematic review and meta analysis of 15 studies 2023-2024. Published 20 October 2025", "summary": "Background: Empathy is widely recognized for improving patient outcomes, including reduced pain and anxiety and improved satisfaction, and its absence can cause harm. Meanwhile, use of artificial intelligence (AI)-based chatbots in healthcare is rapidly expanding, with one in five general practitioners using generative AI to assist with tasks such as writing letters. Some studies suggest AI chatbots can outperform human healthcare professionals (HCPs) in empathy, though findings are mixed and lack synthesis. Sources of data: We searched multiple databases for studies comparing AI chatbots using large language models with human HCPs on empathy measures. We assessed risk of bias with ROBINS-I and synthesized findings using random-effects meta-analysis where feasible, whilst avoiding double counting. Areas of agreement: We identified 15 studies (2023-2024). Thirteen studies reported statistically significantly higher empathy ratings for AI, with only two studies situated in dermatology favouring human responses. Of the 15 studies, 13 provided extractable data and were suitable for pooling. Meta-analysis of those 13 studies, all utilising ChatGPT-3.5/4, showed a standardized mean difference of 0.87 (95% CI, 0.54-1.20) favouring AI (P < .00001), roughly equivalent to a two-point increase on a 10-point scale. Areas of controversy: Studies relied on text-based assessments that overlook non-verbal cues and evaluated empathy through proxy raters. Growing points: Our findings indicate that, in text-only scenarios, AI chatbots are frequently perceived as more empathic than human HCPs. Areas timely for developing research: Future research should validate these findings with direct patient evaluations and assess whether emerging voice-enabled AI systems can deliver similar empathic advantages.", "AI": {"tldr": "该论文通过系统性回顾和元分析，对比了人工智能聊天机器人与人类医护人员在患者护理中的同理心表现。", "motivation": "提高患者的治疗效果需要增强医患之间的同理心。然而，随着AI聊天机器人的普及，关于其是否能比人类医护人员更好地展示出同理心的研究结论不一，亟需进行综合分析以明确现状。", "method": "研究团队从多个数据库中筛选了比较大型语言模型驱动的AI聊天机器人与人类医护人员在同理心衡量方面表现的相关文献。通过ROBINS-I评估偏见风险，并使用随机效应元分析方法对符合条件的研究数据进行了汇总分析，避免重复计算。", "result": "共纳入15项研究（2023-2024年），其中13项显示AI聊天机器人在同理心评价上显著高于人类医护人员。基于此进行的元分析表明，在仅限于文本交流的情况下，使用ChatGPT-3.5/4模型的聊天机器人的平均差异值为0.87（95% CI, 0.54-1.20），P<.00001。", "conclusion": "研究结果表明，在仅依靠文本交流的情境下，AI聊天机器人比人类医护人员更常被认为是更有同理心的。然而，为了验证这些发现并评估未来声音驱动型AI系统是否能在实际患者互动中展现出类似的同理能力，仍需要进一步的研究来直接获取患者的反馈意见。"}}
{"id": "2602.05625", "pdf": "https://arxiv.org/pdf/2602.05625", "abs": "https://arxiv.org/abs/2602.05625", "authors": ["Simon Kohaut", "Benedict Flade", "Julian Eggert", "Kristian Kersting", "Devendra Singh Dhami"], "title": "Reactive Knowledge Representation and Asynchronous Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are often inefficient for ongoing reasoning, as they re-evaluate the entire model upon any change, failing to exploit that real-world information streams have heterogeneous update rates. To address this, we approach the problem from a reactive, asynchronous, probabilistic reasoning perspective. We first introduce Resin (Reactive Signal Inference), a probabilistic programming language that merges probabilistic logic with reactive programming. Furthermore, to provide efficient and exact semantics for Resin, we propose Reactive Circuits (RCs). Formulated as a meta-structure over Algebraic Circuits and asynchronous data streams, RCs are time-dynamic Directed Acyclic Graphs that autonomously adapt themselves based on the volatility of input signals. In high-fidelity drone swarm simulations, our approach achieves several orders of magnitude of speedup over frequency-agnostic inference. We demonstrate that RCs' structural adaptations successfully capture environmental dynamics, significantly reducing latency and facilitating reactive real-time reasoning. By partitioning computations based on the estimated Frequency of Change in the asynchronous inputs, large inference tasks can be decomposed into individually memoized sub-problems. This ensures that only the specific components of a model affected by new information are re-evaluated, drastically reducing redundant computation in streaming contexts.", "AI": {"tldr": "提出了一种新的概率编程语言Resin和一种高效的推理方法Reactive Circuits，用于动态环境中自主代理的实时信念更新。", "motivation": "在复杂模型中进行精确推断通常会带来高昂的计算成本。现有方法对于持续推理不够高效，因为它们会在任何变化时重新评估整个模型而未能利用现实世界信息流的不同更新率。", "method": "引入了概率编程语言Resin和Reactive Circuits（RC），通过将概率逻辑与反应式编程结合来处理动态环境中的实时信念更新问题。RC作为一种基于代数电路的异步数据流的元结构，能够自动适应输入信号的变化频率，并根据这些频率对计算任务进行分区。", "result": "在高保真无人机群仿真中，该方法比频率无关推断快几个数量级，并成功捕获了环境动态。通过将大型推理任务分解为独立缓存子问题，大大减少了冗余计算。", "conclusion": "提出的Reactive Circuits结构适应性地捕捉环境变化，显著降低延迟并支持反应式实时推理，在现实世界的异步输入中表现出色"}}
{"id": "2602.05619", "pdf": "https://arxiv.org/pdf/2602.05619", "abs": "https://arxiv.org/abs/2602.05619", "authors": ["Mohamad Mohamad", "Francesco Ponzio", "Xavier Descombes"], "title": "Mode-Dependent Rectification for Stable PPO Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mode-dependent architectural components (layers that behave differently during training and evaluation, such as Batch Normalization or dropout) are commonly used in visual reinforcement learning but can destabilize on-policy optimization. We show that in Proximal Policy Optimization (PPO), discrepancies between training and evaluation behavior induced by Batch Normalization lead to policy mismatch, distributional drift, and reward collapse. We propose Mode-Dependent Rectification (MDR), a lightweight dual-phase training procedure that stabilizes PPO under mode-dependent layers without architectural changes. Experiments across procedurally generated games and real-world patch-localization tasks demonstrate that MDR consistently improves stability and performance, and extends naturally to other mode-dependent layers.", "AI": {"tldr": "本文提出了一种轻量级的双阶段训练方法，以稳定包含模式依赖组件（如批量归一化）的Proximal Policy Optimization (PPO) 训练。", "motivation": "在视觉强化学习中广泛使用的模式依赖架构组件会在PPO上导致策略偏差、分布漂移和奖励崩溃。为了解决这个问题，本文提出了一种新的方法来稳定包含这些组件的PPO训练。", "method": "提出了Mode-Dependent Rectification (MDR)，这是一种不改变原始架构设计的新颖双阶段训练过程，用以解决模式依赖组件导致的问题，具体是通过调整训练和评估期间的行为一致性，从而提升模型稳定性。", "result": "实验结果证明，与传统方法相比，MDR能够在各种环境中稳定地改进PPO性能。它不仅适用于批量归一化层，还可以扩展到其他模式依赖的层上。", "conclusion": "本文通过提出一种新的训练策略成功解决了包含模式依赖组件的PPO在训练时遇到的问题，并展示了该策略的有效性和广泛适用性。"}}
{"id": "2602.05617", "pdf": "https://arxiv.org/pdf/2602.05617", "abs": "https://arxiv.org/abs/2602.05617", "authors": ["Nikolay Patakin", "Arsenii Shirokov", "Anton Konushin", "Dmitry Senushkin"], "title": "Unified Sensor Simulation for Autonomous Driving", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "In this work, we introduce \\textbf{XSIM}, a sensor simulation framework for autonomous driving. XSIM extends 3DGUT splatting with a generalized rolling-shutter modeling tailored for autonomous driving applications. Our framework provides a unified and flexible formulation for appearance and geometric sensor modeling, enabling rendering of complex sensor distortions in dynamic environments. We identify spherical cameras, such as LiDARs, as a critical edge case for existing 3DGUT splatting due to cyclic projection and time discontinuities at azimuth boundaries leading to incorrect particle projection. To address this issue, we propose a phase modeling mechanism that explicitly accounts temporal and shape discontinuities of Gaussians projected by the Unscented Transform at azimuth borders. In addition, we introduce an extended 3D Gaussian representation that incorporates two distinct opacity parameters to resolve mismatches between geometry and color distributions. As a result, our framework provides enhanced scene representations with improved geometric consistency and photorealistic appearance. We evaluate our framework extensively on multiple autonomous driving datasets, including Waymo Open Dataset, Argoverse 2, and PandaSet. Our framework consistently outperforms strong recent baselines and achieves state-of-the-art performance across all datasets. The source code is publicly available at \\href{https://github.com/whesense/XSIM}{https://github.com/whesense/XSIM}.", "AI": {"tldr": "介绍了一个名为XSIM的传感器仿真框架，用于自动驾驶。", "motivation": "为了解决现有3DGUT splatting在模拟具有周期性投影和时间不连续性的球形相机时存在的问题，提出了一种新的方法以提高场景表示的几何一致性和照片真实性。", "method": "XSIM扩展了3DGUT splatting，并引入了一种通用滚动快门模型来处理自动驾驶应用。框架中包含了一个相位建模机制和一个改进的3D高斯表示形式，用于解决球形相机投影时的时间和形状不连续性问题。", "result": "在Waymo Open Dataset、Argoverse 2和PandaSet等数据集上进行了评估，结果表明XSIM优于现有基线方法，并达到了最先进的性能水平。", "conclusion": "通过使用提出的XSIM框架可以实现更精确的传感器模拟，从而改善自动驾驶系统中的感知精度。"}}
{"id": "2602.05616", "pdf": "https://arxiv.org/pdf/2602.05616", "abs": "https://arxiv.org/abs/2602.05616", "authors": ["Xuhui Li", "Zhengquan Luo", "Xiwei Liu", "Yongqiang Yu", "Zhiqiang Xu"], "title": "Path-Guided Flow Matching for Dataset Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Dataset distillation compresses large datasets into compact synthetic sets with comparable performance in training models. Despite recent progress on diffusion-based distillation, this type of method typically depends on heuristic guidance or prototype assignment, which comes with time-consuming sampling and trajectory instability and thus hurts downstream generalization especially under strong control or low IPC. We propose \\emph{Path-Guided Flow Matching (PGFM)}, the first flow matching-based framework for generative distillation, which enables fast deterministic synthesis by solving an ODE in a few steps. PGFM conducts flow matching in the latent space of a frozen VAE to learn class-conditional transport from Gaussian noise to data distribution. Particularly, we develop a continuous path-to-prototype guidance algorithm for ODE-consistent path control, which allows trajectories to reliably land on assigned prototypes while preserving diversity and efficiency. Extensive experiments across high-resolution benchmarks demonstrate that PGFM matches or surpasses prior diffusion-based distillation approaches with fewer steps of sampling while delivering competitive performance with remarkably improved efficiency, e.g., 7.6$\\times$ more efficient than the diffusion-based counterparts with 78\\% mode coverage.", "AI": {"tldr": "该论文提出了Path-Guided Flow Matching (PGFM) 方法，一种基于流匹配的生成式数据集蒸馏框架。", "motivation": "现有的扩散方法依赖于启发式引导或原型分配，导致采样耗时且轨迹不稳定，影响下游泛化能力。因此，作者提出了一种新的方法来解决这些问题。", "method": "PGFM通过求解ODE在VAE的潜在空间中进行流匹配，从高斯噪声到数据分布学习类条件传输。特别地，开发了一个连续路径到原型引导算法以实现可靠且多样化的轨迹控制。", "result": "实验结果表明，与现有的扩散方法相比，PGFM不仅提供了可比或更好的性能，而且更加高效，例如，在78％模式覆盖的情况下，效率提高了7.6倍。", "conclusion": "该工作展示了基于流匹配的方法在数据集蒸馏上的潜力和优越性。"}}
{"id": "2602.05608", "pdf": "https://arxiv.org/pdf/2602.05608", "abs": "https://arxiv.org/abs/2602.05608", "authors": ["Yufei Zhu", "Shih-Min Yang", "Martin Magnusson", "Allan Wang"], "title": "HiCrowd: Hierarchical Crowd Flow Alignment for Dense Human Environments", "categories": ["cs.RO"], "comment": "Accepted to the 2026 IEEE International Conference on Robotics and Automation (ICRA)", "summary": "Navigating through dense human crowds remains a significant challenge for mobile robots. A key issue is the freezing robot problem, where the robot struggles to find safe motions and becomes stuck within the crowd. To address this, we propose HiCrowd, a hierarchical framework that integrates reinforcement learning (RL) with model predictive control (MPC). HiCrowd leverages surrounding pedestrian motion as guidance, enabling the robot to align with compatible crowd flows. A high-level RL policy generates a follow point to align the robot with a suitable pedestrian group, while a low-level MPC safely tracks this guidance with short horizon planning. The method combines long-term crowd aware decision making with safe short-term execution. We evaluate HiCrowd against reactive and learning-based baselines in offline setting (replaying recorded human trajectories) and online setting (human trajectories are updated to react to the robot in simulation). Experiments on a real-world dataset and a synthetic crowd dataset show that our method outperforms in navigation efficiency and safety, while reducing freezing behaviors. Our results suggest that leveraging human motion as guidance, rather than treating humans solely as dynamic obstacles, provides a powerful principle for safe and efficient robot navigation in crowds.", "AI": {"tldr": "提出了一种名为HiCrowd的分层框架，该框架通过将强化学习和模型预测控制相结合，使机器人在密集人群中导航更加高效与安全。", "motivation": "解决移动机器人在密集人群中的冻结问题，即机器人难以找到安全路径而被困于人群之中。", "method": "利用周围行人的运动作为指导信号，采用高层的强化学习策略生成跟随点以匹配合适的行人组群，并通过低层的模型预测控制进行短时跟踪。此方法结合了长期的人流感知决策和短期的安全执行。", "result": "在离线与在线实验中，HiCrowd优于反应型和基于学习的方法，在真实数据集和合成人群数据集中表现出了更高的导航效率和安全性，并减少了冻结行为的发生频率。", "conclusion": "通过利用人类运动作为指导而非将其单纯视为动态障碍物，该方法为机器人在人群中安全高效的导航提供了一个有力的原则。"}}
{"id": "2602.05605", "pdf": "https://arxiv.org/pdf/2602.05605", "abs": "https://arxiv.org/abs/2602.05605", "authors": ["Jiaji Zhang", "Hailiang Zhao", "Guoxuan Zhu", "Ruichao Sun", "Jiaju Wu", "Xinkui Zhao", "Hanlin Tang", "Weiyi Lu", "Kan Liu", "Tao Lan", "Lin Qu", "Shuiguang Deng"], "title": "Shiva-DiT: Residual-Based Differentiable Top-$k$ Selection for Efficient Diffusion Transformers", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Diffusion Transformers (DiTs) incur prohibitive computational costs due to the quadratic scaling of self-attention. Existing pruning methods fail to simultaneously satisfy differentiability, efficiency, and the strict static budgets required for hardware overhead. To address this, we propose Shiva-DiT, which effectively reconciles these conflicting requirements via Residual-Based Differentiable Top-$k$ Selection. By leveraging a residual-aware straight-through estimator, our method enforces deterministic token counts for static compilation while preserving end-to-end learnability through residual gradient estimation. Furthermore, we introduce a Context-Aware Router and Adaptive Ratio Policy to autonomously learn an adaptive pruning schedule. Experiments on mainstream models, including SD3.5, demonstrate that Shiva-DiT establishes a new Pareto frontier, achieving a 1.54$\\times$ wall-clock speedup with superior fidelity compared to existing baselines, effectively eliminating ragged tensor overheads.", "AI": {"tldr": "提出了一种新的残差基可微顶-k选择方法，用于高效扩散变换器（DiT），解决了现有剪枝方法无法同时满足可微性、效率和硬件开销严格静态预算的问题。", "motivation": "为了减少扩散变换器的计算成本，解决现有剪枝方法在可微性、效率及硬件开销上的矛盾需求问题。", "method": "通过引入残差感知直通估计器实现确定性的token计数以及端到端的学习能力。此外，还提出了一种上下文感知路由和自适应比率策略来自主学习一个动态的剪枝时间表。", "result": "实验表明，Shiva-DiT在主流模型上实现了1.54倍的速度提升，并且与现有基准相比具有更高的保真度。", "conclusion": "通过引入新的残差基可微顶-k选择方法，成功解决了DiT中剪枝策略的矛盾需求问题，并建立了新的帕累托前沿。"}}
{"id": "2602.05602", "pdf": "https://arxiv.org/pdf/2602.05602", "abs": "https://arxiv.org/abs/2602.05602", "authors": ["Zongliang Zhang", "Shuxiang Li", "Xingwang Huang", "Zongyue Wang"], "title": "Multi-instance robust fitting for non-classical geometric models", "categories": ["cs.CV"], "comment": null, "summary": "Most existing robust fitting methods are designed for classical models, such as lines, circles, and planes. In contrast, fewer methods have been developed to robustly handle non-classical models, such as spiral curves, procedural character models, and free-form surfaces. Furthermore, existing methods primarily focus on reconstructing a single instance of a non-classical model. This paper aims to reconstruct multiple instances of non-classical models from noisy data. We formulate this multi-instance fitting task as an optimization problem, which comprises an estimator and an optimizer. Specifically, we propose a novel estimator based on the model-to-data error, capable of handling outliers without a predefined error threshold. Since the proposed estimator is non-differentiable with respect to the model parameters, we employ a meta-heuristic algorithm as the optimizer to seek the global optimum. The effectiveness of our method are demonstrated through experimental results on various non-classical models. The code is available at https://github.com/zhangzongliang/fitting.", "AI": {"tldr": "本文旨在从噪声数据中重建多个非经典模型的实例。", "motivation": "现有的鲁棒拟合方法主要针对经典的几何模型，如直线、圆和平面。然而，较少的方法能有效处理螺旋曲线等非经典模型，并且现有技术大多只能重构单一的非经典模型实例。", "method": "本文将多实例拟合任务作为优化问题进行求解，该问题由基于模型到数据误差的新估计器组成，能够处理异常值而不需预定义的误差阈值。由于估计器对模型参数非可微分，采用元启发式算法寻找全局最优。", "result": "实验结果验证了所提方法在不同类型的非经典几何模型上的有效性。", "conclusion": "本文提出了一种有效的方法来处理多个实例的非经典模型重建问题，并通过实际数据证明其优越性。"}}
{"id": "2602.05599", "pdf": "https://arxiv.org/pdf/2602.05599", "abs": "https://arxiv.org/abs/2602.05599", "authors": ["Subhadip Maji", "Arnab Bhattacharya"], "title": "BhashaSetu: Cross-Lingual Knowledge Transfer from High-Resource to Extreme Low-Resource Languages", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted as a long paper at IJCNLP-AACL Main Conference", "summary": "Despite remarkable advances in natural language processing, developing effective systems for low-resource languages remains a formidable challenge, with performances typically lagging far behind high-resource counterparts due to data scarcity and insufficient linguistic resources. Cross-lingual knowledge transfer has emerged as a promising approach to address this challenge by leveraging resources from high-resource languages. In this paper, we investigate methods for transferring linguistic knowledge from high-resource languages to low-resource languages, where the number of labeled training instances is in hundreds. We focus on sentence-level and word-level tasks. We introduce a novel method, GETR (Graph-Enhanced Token Representation) for cross-lingual knowledge transfer along with two adopted baselines (a) augmentation in hidden layers and (b) token embedding transfer through token translation. Experimental results demonstrate that our GNN-based approach significantly outperforms existing multilingual and cross-lingual baseline methods, achieving 13 percentage point improvements on truly low-resource languages (Mizo, Khasi) for POS tagging, and 20 and 27 percentage point improvements in macro-F1 on simulated low-resource languages (Marathi, Bangla, Malayalam) across sentiment classification and NER tasks respectively. We also present a detailed analysis of the transfer mechanisms and identify key factors that contribute to successful knowledge transfer in this linguistic context.", "AI": {"tldr": "该论文提出了一种新的跨语言知识迁移方法GETR，用于从高资源语言向极度低资源语言进行有效的知识转移。", "motivation": "尽管自然语言处理取得了显著进展，但对于低资源语言的有效系统开发仍然面临重大挑战。由于数据稀缺和语言资源不足，这些系统的性能通常远远落后于高资源语言的系统。跨语言知识迁移被提出作为一种利用高资源语言来解决这一问题的方法。", "method": "论文介绍了一种新的方法GETR（图增强词表示），该方法结合了两种基线技术：隐藏层中的数据增强和通过词汇翻译进行的词嵌入转移，以实现从高资源语言向低资源语言的知识迁移。实验结果表明，这种方法在某些任务上显著优于现有的多语言和跨语言基准。", "result": "实验结果显示，GETR方法在真低资源语言（Mizo、Khasi）上的词性标注任务中取得了13个百分点的改进，并且在模拟低资源语言（马拉地语、孟加拉语、马拉雅拉姆语）上，在情感分类和命名实体识别任务中的宏观F1分数分别提高了20%和27%，明显优于其他基线方法。", "conclusion": "论文展示了GETR的实验结果，并进行了详细的分析，探讨了知识转移机制的关键因素。这些发现有助于改善极度低资源语言上的自然语言处理性能。"}}
{"id": "2602.05598", "pdf": "https://arxiv.org/pdf/2602.05598", "abs": "https://arxiv.org/abs/2602.05598", "authors": ["Aon Safdar", "Mohamed Saadeldin"], "title": "CAViT -- Channel-Aware Vision Transformer for Dynamic Feature Fusion", "categories": ["cs.CV", "cs.AI"], "comment": "Presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025 (CVPR 25) in the 4th Workshop on Transformers for Visions - T4V (https://sites.google.com/view/t4v-cvpr25/) Accepted for Publication at 33rd International Conference on Artificial Intelligence and Cognitive Science (AICS 2025), where it was shortlisted for Best Paper Award. (https://aicsconf.org/?page_id=278)", "summary": "Vision Transformers (ViTs) have demonstrated strong performance across a range of computer vision tasks by modeling long-range spatial interactions via self-attention. However, channel-wise mixing in ViTs remains static, relying on fixed multilayer perceptrons (MLPs) that lack adaptability to input content. We introduce 'CAViT', a dual-attention architecture that replaces the static MLP with a dynamic, attention-based mechanism for feature interaction. Each Transformer block in CAViT performs spatial self-attention followed by channel-wise self-attention, allowing the model to dynamically recalibrate feature representations based on global image context. This unified and content-aware token mixing strategy enhances representational expressiveness without increasing depth or complexity. We validate CAViT across five benchmark datasets spanning both natural and medical domains, where it outperforms the standard ViT baseline by up to +3.6% in accuracy, while reducing parameter count and FLOPs by over 30%. Qualitative attention maps reveal sharper and semantically meaningful activation patterns, validating the effectiveness of our attention-driven token mixing.", "AI": {"tldr": "CAViT提出了一种新的双注意力架构，通过引入动态的通道自注意力机制来增强特征交互，从而改善视觉Transformer的表现。", "motivation": "现有的视觉Transformer模型在处理长范围空间关系时表现出色，但通道混合是固定的，缺乏对输入内容的适应性。因此，作者希望通过设计一种能够根据全局图像上下文动态调整特征表示的方法来改进这一问题。", "method": "CAViT通过用注意力驱动的机制替换传统的MLP层，实现了动态的通道自注意力功能。每个Transformer块在空间自注意力之后执行通道自注意力操作，从而允许模型依据全局图像上下文动态地重新校准特征表示。", "result": "实验结果显示，在五个基准数据集上，CAViT相比标准视觉Transformer基线提高了最多3.6%的准确性，并且参数量和浮点运算次数分别减少了超过30%，同时展示出更清晰、更有意义的关注模式。", "conclusion": "通过引入动态通道自注意力机制，CAViT能够在不增加模型复杂度的情况下提高特征表示能力。实验结果表明这种方法是有效的，并在多种数据集上取得了优于基线的结果。"}}
{"id": "2602.05597", "pdf": "https://arxiv.org/pdf/2602.05597", "abs": "https://arxiv.org/abs/2602.05597", "authors": ["Stephen Pilli", "Vivek Nallur"], "title": "Emulating Aggregate Human Choice Behavior and Biases with GPT Conversational Agents", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": "Accepted at CHI'26. arXiv admin note: substantial text overlap with arXiv:2601.11049", "summary": "Cognitive biases often shape human decisions. While large language models (LLMs) have been shown to reproduce well-known biases, a more critical question is whether LLMs can predict biases at the individual level and emulate the dynamics of biased human behavior when contextual factors, such as cognitive load, interact with these biases. We adapted three well-established decision scenarios into a conversational setting and conducted a human experiment (N=1100). Participants engaged with a chatbot that facilitates decision-making through simple or complex dialogues. Results revealed robust biases. To evaluate how LLMs emulate human decision-making under similar interactive conditions, we used participant demographics and dialogue transcripts to simulate these conditions with LLMs based on GPT-4 and GPT-5. The LLMs reproduced human biases with precision. We found notable differences between models in how they aligned human behavior. This has important implications for designing and evaluating adaptive, bias-aware LLM-based AI systems in interactive contexts.", "AI": {"tldr": "本文研究了大规模语言模型在模拟人类决策偏见方面的表现，特别是在对话情境下如何再现个体水平的认知偏差。", "motivation": "探讨大型语言模型是否能够在与认知负荷等上下文因素相互作用时准确预测并模仿个人层次上的认知偏见和行为模式。", "method": "通过将三个已建立的决策场景改编为对话形式，进行人类实验（参与者数量1100），并与基于GPT-4和GPT-5的语言模型模拟相同条件下的交互来评估。", "result": "结果显示大型语言模型能够以高精度再现人类在这些互动中的偏见行为，但不同模型之间存在如何与人类行为对齐的差异。", "conclusion": "研究发现对于设计适应性、具有认知偏差意识的AI系统至关重要，在这种情况下，对话情境下的大规模语言模型需要进行更加细致地评估和调整。"}}
{"id": "2602.05596", "pdf": "https://arxiv.org/pdf/2602.05596", "abs": "https://arxiv.org/abs/2602.05596", "authors": ["Hokyun Lee", "Woo-Jeong Baek", "Junhyeok Cha", "Jaeheung Park"], "title": "TOLEBI: Learning Fault-Tolerant Bipedal Locomotion via Online Status Estimation and Fallibility Rewards", "categories": ["cs.RO"], "comment": "Accepted for Publication at IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "With the growing employment of learning algorithms in robotic applications, research on reinforcement learning for bipedal locomotion has become a central topic for humanoid robotics. While recently published contributions achieve high success rates in locomotion tasks, scarce attention has been devoted to the development of methods that enable to handle hardware faults that may occur during the locomotion process. However, in real-world settings, environmental disturbances or sudden occurrences of hardware faults might yield severe consequences. To address these issues, this paper presents TOLEBI (A faulT-tOlerant Learning framEwork for Bipedal locomotIon) that handles faults on the robot during operation. Specifically, joint locking, power loss and external disturbances are injected in simulation to learn fault-tolerant locomotion strategies. In addition to transferring the learned policy to the real robot via sim-to-real transfer, an online joint status module incorporated. This module enables to classify joint conditions by referring to the actual observations at runtime under real-world conditions. The validation experiments conducted both in real-world and simulation with the humanoid robot TOCABI highlight the applicability of the proposed approach. To our knowledge, this manuscript provides the first learning-based fault-tolerant framework for bipedal locomotion, thereby fostering the development of efficient learning methods in this field.", "AI": {"tldr": "本文提出了一种名为TOLEBI的学习故障容忍双足步态方法，旨在解决机器人在行走过程中遇到的硬件故障问题。", "motivation": "随着学习算法在机器人应用中的日益普及，双足步行控制已成为人形机器人的核心研究课题。然而，在实际环境中，由于环境干扰或突发硬件故障可能导致严重后果，现有的研究对处理这些故障的关注较少。", "method": "本文通过在线状态估计和错误奖励方法来实现故障容忍的双足行走策略学习。利用仿真模拟中注入关节锁定、电源中断和外部干扰等故障情况，以学习出有效的故障应对策略，并将所学策略转移到真实机器人上。此外，还引入了一个在线关节状态模块，在运行时根据实时观察对关节状况进行分类。", "result": "实验结果表明，TOLEBI方法能够在仿真及现实环境中有效解决双足行走过程中的硬件故障问题。这是首个基于学习的故障容错框架，为这一领域的研究提供了新的思路和解决方案。", "conclusion": "本文提出的TOLEBI方法首次提出了一种基于学习的故障容忍框架，对于人形机器人在实际环境下的稳定性和可靠性具有重要推动作用。"}}
{"id": "2602.05595", "pdf": "https://arxiv.org/pdf/2602.05595", "abs": "https://arxiv.org/abs/2602.05595", "authors": ["Langyu Li", "Ruoyu Wu", "Yong Wang", "Guofeng Zhang", "Jinhu Lü", "Qing Gao", "Yu Pan"], "title": "Adaptive controllable architecture of analog Ising machine", "categories": ["quant-ph", "cs.ET"], "comment": null, "summary": "As a quantum-inspired, non-traditional analog solver architecture, the analog Ising machine (AIM) has emerged as a distinctive computational paradigm to address the rapidly growing demand for computational power. However, the mathematical understanding of its principles, as well as the optimization of its solution speed and accuracy, remain unclear. In this work, we for the first time systematically discuss multiple implementations of AIM and establish a unified mathematical formulation. On this basis, by treating the binarization constraint of AIM (such as injection locking) as a Lagrange multiplier in optimization theory and combining it with a Lyapunov analysis from dynamical systems theory, an analytical framework for evaluating solution speed and accuracy is constructed, and further demonstrate that conventional AIMs possess a theoretical performance upper bound. Subsequently, by elevating the binarization constraint to a control variable, we propose the controllable analog Ising machine (CAIM), which integrates control Lyapunov functions and momentum-based optimization algorithms to realize adaptive sampling-feedback control, thereby surpassing the performance limits of conventional AIMs. In a proof-of-concept CAIM demonstration implemented using an FPGA-controlled LC-oscillator Ising machine, CAIM achieves a twofold speedup and a 7\\% improvement in accuracy over AIM on a 50-node all-to-all weighted MaxCut problem, validating both the effectiveness and interpretability of the proposed theoretical framework.", "AI": {"tldr": "本文提出了可控模拟伊辛机（CAIM）的概念，通过在优化理论中引入控制变量的方法来提高AIM的性能。", "motivation": "随着计算需求的增长，对非传统模拟解算器架构的理解和优化变得越来越重要。然而，AIM原理及其解决方案速度和准确性仍不清楚。", "method": "本文首先系统地讨论了多个AIM实现，并建立了一个统一的数学公式。通过将AIM中的二值化约束（如注入锁定）作为优化理论中拉格朗日乘数，并结合动力系统理论中的李亚普诺夫分析，建立了评估解决方案速度和准确性的分析框架。", "result": "提出的可控模拟伊辛机在FPGA控制的LC振荡器Ising机器上进行了概念验证演示，在50节点全部加权最大割问题中实现了AIM两倍的速度提升及7%的准确性提高。", "conclusion": "本文通过将二值化约束作为控制变量，提出了CAIM，并通过引入控制李雅普诺夫函数和动量优化算法，实现了自适应采样反馈控制，从而突破了传统AIM性能极限。"}}
{"id": "2602.05590", "pdf": "https://arxiv.org/pdf/2602.05590", "abs": "https://arxiv.org/abs/2602.05590", "authors": ["Haojie Cheng", "Shaun Jing Heng Ong", "Shaoyu Cai", "Aiden Tat Yang Koh", "Fuxi Ouyang", "Eng Tat Khoo"], "title": "EgoPoseVR: Spatiotemporal Multi-Modal Reasoning for Egocentric Full-Body Pose in Virtual Reality", "categories": ["cs.CV", "cs.ET", "cs.GR"], "comment": null, "summary": "Immersive virtual reality (VR) applications demand accurate, temporally coherent full-body pose tracking. Recent head-mounted camera-based approaches show promise in egocentric pose estimation, but encounter challenges when applied to VR head-mounted displays (HMDs), including temporal instability, inaccurate lower-body estimation, and the lack of real-time performance. To address these limitations, we present EgoPoseVR, an end-to-end framework for accurate egocentric full-body pose estimation in VR that integrates headset motion cues with egocentric RGB-D observations through a dual-modality fusion pipeline. A spatiotemporal encoder extracts frame- and joint-level representations, which are fused via cross-attention to fully exploit complementary motion cues across modalities. A kinematic optimization module then imposes constraints from HMD signals, enhancing the accuracy and stability of pose estimation. To facilitate training and evaluation, we introduce a large-scale synthetic dataset of over 1.8 million temporally aligned HMD and RGB-D frames across diverse VR scenarios. Experimental results show that EgoPoseVR outperforms state-of-the-art egocentric pose estimation models. A user study in real-world scenes further shows that EgoPoseVR achieved significantly higher subjective ratings in accuracy, stability, embodiment, and intention for future use compared to baseline methods. These results show that EgoPoseVR enables robust full-body pose tracking, offering a practical solution for accurate VR embodiment without requiring additional body-worn sensors or room-scale tracking systems.", "AI": {"tldr": "EgoPoseVR提出了一个用于虚拟现实（VR）中准确的自我中心全身体姿估计的端到端框架，该框架结合了头戴式显示器信号和自我中心RGB-D观察。", "motivation": "当前基于头部安装相机的方法在应用于VR时面临时间不稳定性、下肢估计算法不准确以及实时性能不足的问题。EgoPoseVR旨在解决这些问题，提供更准确稳定的全身体姿跟踪。", "method": "通过双模态融合管道集成头显运动提示与自我中心RGB-D观测数据，利用时空编码器提取帧和关节级别表示，并采用交叉注意力进行融合以充分探索不同模式间互补的运动线索。引入了一个从HMD信号中施加约束的几何优化模块来提高姿态估计的准确性和稳定性。", "result": "实验结果表明EgoPoseVR超越了最先进的自我中心姿势估计算法，在真实世界场景中的用户研究显示，EgoPoseVR在准确性、稳定性和未来使用意愿方面获得了显著更高的主观评分。", "conclusion": "EgoPoseVR提供了一种鲁棒的全身体姿跟踪解决方案，无需额外的身体穿戴传感器或房间规模追踪系统即可实现准确的虚拟现实存在感。"}}
{"id": "2602.05588", "pdf": "https://arxiv.org/pdf/2602.05588", "abs": "https://arxiv.org/abs/2602.05588", "authors": ["Haojie Cheng", "Chang Liu", "Abhiram Kanneganti", "Mahesh Arjandas Choolani", "Arundhati Tushar Gosavi", "Eng Tat Khoo"], "title": "A Mixed Reality System for Robust Manikin Localization in Childbirth Training", "categories": ["cs.CV", "cs.ET", "cs.GR"], "comment": null, "summary": "Opportunities for medical students to gain practical experience in vaginal births are increasingly constrained by shortened clinical rotations, patient reluctance, and the unpredictable nature of labour. To alleviate clinicians' instructional burden and enhance trainees' learning efficiency, we introduce a mixed reality (MR) system for childbirth training that combines virtual guidance with tactile manikin interaction, thereby preserving authentic haptic feedback while enabling independent practice without continuous on-site expert supervision. The system extends the passthrough capability of commercial head-mounted displays (HMDs) by spatially calibrating an external RGB-D camera, allowing real-time visual integration of physical training objects. Building on this capability, we implement a coarse-to-fine localization pipeline that first aligns the maternal manikin with fiducial markers to define a delivery region and then registers the pre-scanned neonatal head within this area. This process enables spatially accurate overlay of virtual guiding hands near the manikin, allowing trainees to follow expert trajectories reinforced by haptic interaction. Experimental evaluations demonstrate that the system achieves accurate and stable manikin localization on a standalone headset, ensuring practical deployment without external computing resources. A large-scale user study involving 83 fourth-year medical students was subsequently conducted to compare MR-based and virtual reality (VR)-based childbirth training. Four senior obstetricians independently assessed performance using standardized criteria. Results showed that MR training achieved significantly higher scores in delivery, post-delivery, and overall task performance, and was consistently preferred by trainees over VR training.", "AI": {"tldr": "提出了一种结合虚拟指导与实体模型互动的混合现实系统，用于产科训练。", "motivation": "缩短的临床轮岗、患者抵制和分娩的不可预测性限制了医学生获取实践经验的机会。该系统旨在减轻专家的教学负担并提高培训效率。", "method": "通过外部RGB-D相机的空间校准扩展商用头戴式显示器（HMD）的功能，实现物理训练对象的真实时间视觉整合；采用粗到细定位管道来对齐产科模型与标记物，并在区域内注册预扫描的新生儿头部，以准确叠加虚拟引导手。", "result": "实验评估表明该系统能够独立于外部计算资源进行精确稳定的实体模型定位。大规模用户研究显示MR培训在分娩、产后和总体任务性能方面得分显著高于VR训练。", "conclusion": "混合现实技术提供了一种有效的产科教学方法，优于虚拟现实，并被受训者一致认为更优。"}}
{"id": "2602.05582", "pdf": "https://arxiv.org/pdf/2602.05582", "abs": "https://arxiv.org/abs/2602.05582", "authors": ["Joe-Mei Feng", "Sheng-Wei Yu"], "title": "Geometric Observability Index: An Operator-Theoretic Framework for Per-Feature Sensitivity, Weak Observability, and Dynamic Effects in SE(3) Pose Estimation", "categories": ["cs.CV"], "comment": null, "summary": "We present a unified operator-theoretic framework for analyzing per-feature sensitivity in camera pose estimation on the Lie group SE(3). Classical sensitivity tools - conditioning analyses, Euclidean perturbation arguments, and Fisher information bounds - do not explain how individual image features influence the pose estimate, nor why dynamic or inconsistent observations can disproportionately distort modern SLAM and structure-from-motion systems. To address this gap, we extend influence function theory to matrix Lie groups and derive an intrinsic perturbation operator for left-trivialized M-estimators on SE(3). The resulting Geometric Observability Index (GOI) quantifies the contribution of a single measurement through the curvature operator and the Lie algebraic structure of the observable subspace. GOI admits a spectral decomposition along the principal directions of the observable curvature, revealing a direct correspondence between weak observability and amplified sensitivity. In the population regime, GOI coincides with the Fisher information geometry on SE(3), yielding a single-measurement analogue of the Cramer-Rao bound. The same spectral mechanism explains classical degeneracies such as pure rotation and vanishing parallax, as well as dynamic feature amplification along weak curvature directions. Overall, GOI provides a geometrically consistent description of measurement influence that unifies conditioning analysis, Fisher information geometry, influence function theory, and dynamic scene detectability through the spectral geometry of the curvature operator. Because these quantities arise directly within Gauss-Newton pipelines, the curvature spectrum and GOI also yield lightweight, training-free diagnostic signals for identifying dynamic features and detecting weak observability configurations without modifying existing SLAM architectures.", "AI": {"tldr": "本文提出了SE(3)姿态估计中单个测量影响的几何可观测性指数（GOI）框架", "motivation": "现有敏感度工具无法解释个体图像特征如何影响姿态估计，也无法说明动态或不一致观测为何会对SLAM和结构从运动系统产生不成比例的影响。为解决此问题，作者扩展了矩阵李群中的影响函数理论，并推导出了SE(3)上的内在扰动算子", "method": "作者通过左平凡化的M-估计算法在SE(3)上推导出几何可观测性指数（GOI），量化单个测量的影响。该方法基于曲率算子和可观测子空间的李代数结构，揭示了弱可观测性和放大敏感性的直接对应关系", "result": "在总体制度下，GOI与SE(3)上的费舍尔信息几何一致，提供了一个Cramer-Rao界的一次测量类比。该方法能解释经典退化现象以及动态特征沿弱曲率方向的放大效应，并为检测动态特征和识别弱可观测性配置提供了轻量级、无需训练的诊断信号", "conclusion": "GOI框架统一了条件分析、费舍尔信息几何学、影响函数理论及动态场景可检性的谱几何，且这些量可以直接应用于高斯-牛顿管道中"}}
{"id": "2602.05578", "pdf": "https://arxiv.org/pdf/2602.05578", "abs": "https://arxiv.org/abs/2602.05578", "authors": ["Junyang Chen", "Xiangbo Lv", "Zhiqiang Kou", "Xingdong Sheng", "Ning Xu", "Yiguo Qiao"], "title": "LoGoSeg: Integrating Local and Global Features for Open-Vocabulary Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Open-vocabulary semantic segmentation (OVSS) extends traditional closed-set segmentation by enabling pixel-wise annotation for both seen and unseen categories using arbitrary textual descriptions. While existing methods leverage vision-language models (VLMs) like CLIP, their reliance on image-level pretraining often results in imprecise spatial alignment, leading to mismatched segmentations in ambiguous or cluttered scenes. However, most existing approaches lack strong object priors and region-level constraints, which can lead to object hallucination or missed detections, further degrading performance. To address these challenges, we propose LoGoSeg, an efficient single-stage framework that integrates three key innovations: (i) an object existence prior that dynamically weights relevant categories through global image-text similarity, effectively reducing hallucinations; (ii) a region-aware alignment module that establishes precise region-level visual-textual correspondences; and (iii) a dual-stream fusion mechanism that optimally combines local structural information with global semantic context. Unlike prior works, LoGoSeg eliminates the need for external mask proposals, additional backbones, or extra datasets, ensuring efficiency. Extensive experiments on six benchmarks (A-847, PC-459, A-150, PC-59, PAS-20, and PAS-20b) demonstrate its competitive performance and strong generalization in open-vocabulary settings.", "AI": {"tldr": "本文提出了LoGoSeg，一种整合局部和全局特征的开放式词汇语义分割框架", "motivation": "现有方法在处理模糊或复杂场景时存在空间对齐不精确的问题，并且缺乏强对象先验和区域级约束导致物体幻觉或漏检。为解决这些问题，提出了一种新的框架来提高性能并减少误报", "method": "LoGoSeg整合了三个关键创新：（1）通过全局图像文本相似性动态加权相关类别以减少幻觉的物体存在优先级；（2）建立了精确区域级别视觉文本对应关系的区域感知对齐模块；以及（3）一个双流融合机制，将局部结构信息与全局语义上下文最优组合", "result": "在六个基准数据集上的实验表明该方法具有竞争力的表现和强大的开放式词汇设置下的泛化能力", "conclusion": "LoGoSeg通过整合局部和全局特征解决了现有开放词汇语义分割模型中的问题，并展示了其优越的性能"}}
{"id": "2602.05577", "pdf": "https://arxiv.org/pdf/2602.05577", "abs": "https://arxiv.org/abs/2602.05577", "authors": ["Shiyu Wu", "Shuyan Li", "Jing Li", "Jing Liu", "Yequan Wang"], "title": "LocateEdit-Bench: A Benchmark for Instruction-Based Editing Localization", "categories": ["cs.CV"], "comment": "11 pages, 7 figures", "summary": "Recent advancements in image editing have enabled highly controllable and semantically-aware alteration of visual content, posing unprecedented challenges to manipulation localization. However, existing AI-generated forgery localization methods primarily focus on inpainting-based manipulations, making them ineffective against the latest instruction-based editing paradigms. To bridge this critical gap, we propose LocateEdit-Bench, a large-scale dataset comprising $231$K edited images, designed specifically to benchmark localization methods against instruction-driven image editing. Our dataset incorporates four cutting-edge editing models and covers three common edit types. We conduct a detailed analysis of the dataset and develop two multi-metric evaluation protocols to assess existing localization methods. Our work establishes a foundation to keep pace with the evolving landscape of image editing, thereby facilitating the development of effective methods for future forgery localization. Dataset will be open-sourced upon acceptance.", "AI": {"tldr": "提出LocateEdit-Bench数据集以评估指令驱动的图像编辑定位方法", "motivation": "现有伪造图像检测方法主要针对填图操作，难以应对最新的基于指令的图像编辑。为填补此空白，设计专门用于指令驱动图像编辑的数据集和评价体系", "method": "建立包含231K张编辑图像的大规模数据集，并制定多指标评估协议来测试现有的定位方法", "result": "通过详细分析新数据集并开发有效的评价标准，促进了伪造图像检测技术的发展", "conclusion": "为应对不断变化的图像编辑趋势提供了基础，并将开源数据集"}}
{"id": "2602.05574", "pdf": "https://arxiv.org/pdf/2602.05574", "abs": "https://arxiv.org/abs/2602.05574", "authors": ["Mengyu Li", "Ingibjörg Kristjánsdóttir", "Thilo van Eimeren", "Kathrin Giehl", "Lotta M. Ellingsen", "the ASAP Neuroimaging Initiative"], "title": "A Hybrid CNN and ML Framework for Multi-modal Classification of Movement Disorders Using MRI and Brain Structural Features", "categories": ["cs.CV"], "comment": "To be published in Proceedings of SPIE Medical Imaging 2026", "summary": "Atypical Parkinsonian Disorders (APD), also known as Parkinson-plus syndrome, are a group of neurodegenerative diseases that include progressive supranuclear palsy (PSP) and multiple system atrophy (MSA). In the early stages, overlapping clinical features often lead to misdiagnosis as Parkinson's disease (PD). Identifying reliable imaging biomarkers for early differential diagnosis remains a critical challenge. In this study, we propose a hybrid framework combining convolutional neural networks (CNNs) with machine learning (ML) techniques to classify APD subtypes versus PD and distinguish between the subtypes themselves: PSP vs. PD, MSA vs. PD, and PSP vs. MSA. The model leverages multi-modal input data, including T1-weighted magnetic resonance imaging (MRI), segmentation masks of 12 deep brain structures associated with APD, and their corresponding volumetric measurements. By integrating these complementary modalities, including image data, structural segmentation masks, and quantitative volume features, the hybrid approach achieved promising classification performance with area under the curve (AUC) scores of 0.95 for PSP vs. PD, 0.86 for MSA vs. PD, and 0.92 for PSP vs. MSA. These results highlight the potential of combining spatial and structural information for robust subtype differentiation. In conclusion, this study demonstrates that fusing CNN-based image features with volume-based ML inputs improves classification accuracy for APD subtypes. The proposed approach may contribute to more reliable early-stage diagnosis, facilitating timely and targeted interventions in clinical practice.", "AI": {"tldr": "提出了一种结合卷积神经网络（CNN）和机器学习（ML）的混合框架，用于使用MRI和大脑结构特征对运动障碍进行多模态分类。", "motivation": "早期阶段帕金森病-plus综合症（APD）患者临床特征重叠导致误诊率高，寻找可靠的影像生物标志物以实现早期差异化诊断是一个重大挑战。因此需要新的方法来提高这种疾病的准确诊断。", "method": "通过融合卷积神经网络处理的图像数据和机器学习处理的大脑结构体积测量值等多模态输入数据，提出了一种混合框架用于APD亚型与帕金森病（PD）之间的分类以及APD不同亚型之间（如PSP对MSA）的区分。", "result": "该模型在多种对比任务中取得了出色的性能表现：PSP vs. PD 的 AUC 得分为0.95， MSA vs. PD得分为0.86, PSP vs. MSA 得分为0.92。", "conclusion": "结合CNN生成的图像特征和基于体积的ML输入可以提高APD亚型分类的准确性。所提出的这种方法有望在临床实践中实现更可靠的早期诊断，从而为患者提供及时且针对性的干预措施。"}}
{"id": "2602.05573", "pdf": "https://arxiv.org/pdf/2602.05573", "abs": "https://arxiv.org/abs/2602.05573", "authors": ["Arsenii Shirokov", "Mikhail Kuznetsov", "Danila Stepochkin", "Egor Evdokimov", "Daniil Glazkov", "Nikolay Patakin", "Anton Konushin", "Dmitry Senushkin"], "title": "Visual Implicit Geometry Transformer for Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "We introduce the Visual Implicit Geometry Transformer (ViGT), an autonomous driving geometric model that estimates continuous 3D occupancy fields from surround-view camera rigs. ViGT represents a step towards foundational geometric models for autonomous driving, prioritizing scalability, architectural simplicity, and generalization across diverse sensor configurations. Our approach achieves this through a calibration-free architecture, enabling a single model to adapt to different sensor setups. Unlike general-purpose geometric foundational models that focus on pixel-aligned predictions, ViGT estimates a continuous 3D occupancy field in a birds-eye-view (BEV) addressing domain-specific requirements. ViGT naturally infers geometry from multiple camera views into a single metric coordinate frame, providing a common representation for multiple geometric tasks. Unlike most existing occupancy models, we adopt a self-supervised training procedure that leverages synchronized image-LiDAR pairs, eliminating the need for costly manual annotations. We validate the scalability and generalizability of our approach by training our model on a mixture of five large-scale autonomous driving datasets (NuScenes, Waymo, NuPlan, ONCE, and Argoverse) and achieving state-of-the-art performance on the pointmap estimation task, with the best average rank across all evaluated baselines. We further evaluate ViGT on the Occ3D-nuScenes benchmark, where ViGT achieves comparable performance with supervised methods. The source code is publicly available at \\href{https://github.com/whesense/ViGT}{https://github.com/whesense/ViGT}.", "AI": {"tldr": "提出了一种用于自动驾驶的视觉隐式几何变换器ViGT，能够从周围视图相机装置估计连续的三维占用场。", "motivation": "旨在为自动驾驶开发基础几何模型，通过自监督训练过程和多相机视角的自然融合来提高可扩展性和泛化能力。", "method": "采用了无校准架构和同步图像-激光雷达对，从而在鸟瞰图中估计连续3D占用场，并实现不同传感器配置下的适应性。", "result": "模型在多个大规模自动驾驶数据集上训练并达到最先进的性能，在点地图估计任务上的平均排名最好。此外，在Occ3D-nuScenes基准测试中表现出与监督方法相当的性能。", "conclusion": "ViGT展示了其作为基础几何模型的有效性，特别是在处理多样化传感器配置时，并通过公开代码支持进一步的研究和改进。"}}
{"id": "2602.05572", "pdf": "https://arxiv.org/pdf/2602.05572", "abs": "https://arxiv.org/abs/2602.05572", "authors": ["Zhenxiao Liang", "Ning Zhang", "Youbao Tang", "Ruei-Sung Lin", "Qixing Huang", "Peng Chang", "Jing Xiao"], "title": "ShapeGaussian: High-Fidelity 4D Human Reconstruction in Monocular Videos via Vision Priors", "categories": ["cs.CV"], "comment": null, "summary": "We introduce ShapeGaussian, a high-fidelity, template-free method for 4D human reconstruction from casual monocular videos. Generic reconstruction methods lacking robust vision priors, such as 4DGS, struggle to capture high-deformation human motion without multi-view cues. While template-based approaches, primarily relying on SMPL, such as HUGS, can produce photorealistic results, they are highly susceptible to errors in human pose estimation, often leading to unrealistic artifacts. In contrast, ShapeGaussian effectively integrates template-free vision priors to achieve both high-fidelity and robust scene reconstructions. Our method follows a two-step pipeline: first, we learn a coarse, deformable geometry using pretrained models that estimate data-driven priors, providing a foundation for reconstruction. Then, we refine this geometry using a neural deformation model to capture fine-grained dynamic details. By leveraging 2D vision priors, we mitigate artifacts from erroneous pose estimation in template-based methods and employ multiple reference frames to resolve the invisibility issue of 2D keypoints in a template-free manner. Extensive experiments demonstrate that ShapeGaussian surpasses template-based methods in reconstruction accuracy, achieving superior visual quality and robustness across diverse human motions in casual monocular videos.", "AI": {"tldr": "介绍了一种名为ShapeGaussian的高保真度单目视频中4D人体重建方法。", "motivation": "现有通用重建方法缺乏稳健的视觉先验，难以在没有多视图线索的情况下捕捉到复杂的动作变形。而基于模板的方法虽然能够生成逼真的结果，但容易因姿态估计错误产生不真实的人体形态。", "method": "采用两步流程：首先使用预训练模型学习粗略可形变几何；然后利用神经网络进一步细化以获取动态细节，并通过多帧参考图解决2D关键点不可见问题。", "result": "实验表明，该方法在重建精度、视觉质量和动作多样性上都优于基于模板的方法，在单目视频中实现高质量的人体重建。", "conclusion": "ShapeGaussian利用无模板的视觉先验实现了高保真度和鲁棒性的人体4D重建，适用于各种复杂的单目人体运动场景。"}}
{"id": "2602.05570", "pdf": "https://arxiv.org/pdf/2602.05570", "abs": "https://arxiv.org/abs/2602.05570", "authors": ["Yikun Zong", "Cheston Tan"], "title": "TangramSR: Can Vision-Language Models Reason in Continuous Geometric Space?", "categories": ["cs.AI"], "comment": "13 pages, 4 figures", "summary": "Humans excel at spatial reasoning tasks like Tangram puzzle assembly through cognitive processes involving mental rotation, iterative refinement, and visual feedback. Inspired by how humans solve Tangram puzzles through trial-and-error, observation, and correction, we design a framework that models these human cognitive mechanisms. However, comprehensive experiments across five representative Vision-Language Models (VLMs) reveal systematic failures in continuous geometric reasoning: average IoU of only 0.41 on single-piece tasks, dropping to 0.23 on two-piece composition, far below human performance where children can complete Tangram tasks successfully. This paper addresses a fundamental challenge in self-improving AI: can models iteratively refine their predictions at test time without parameter updates? We introduce a test-time self-refinement framework that combines in-context learning (ICL) with reward-guided feedback loops, inspired by human cognitive processes. Our training-free verifier-refiner agent applies recursive refinement loops that iteratively self-refine predictions based on geometric consistency feedback, achieving IoU improvements from 0.63 to 0.932 on medium-triangle cases without any model retraining. This demonstrates that incorporating human-inspired iterative refinement mechanisms through ICL and reward loops can substantially enhance geometric reasoning in VLMs, moving self-improving AI from promise to practice in continuous spatial domains. Our work is available at this anonymous link https://anonymous.4open.science/r/TangramVLM-F582/.", "AI": {"tldr": "该论文研究了视觉语言模型在连续几何空间中的推理能力，并提出了一个测试时自我优化框架，通过上下文学习和奖励引导反馈循环来提升其性能。", "motivation": "现有视觉语言模型在处理连续几何推理任务上存在系统性失败问题，无法像人类一样进行迭代修正，以提高预测准确性。作者希望解决这一挑战，使模型能够模仿人类思维过程中的试错、观察与纠正机制。", "method": "提出了一个基于上下文学习和奖励引导反馈循环的测试时自我优化框架（TangramSR），该框架无需重新训练即可通过迭代反馈提升几何推理性能。", "result": "引入了验证器-修正器代理，可以将模型在中等三角形情况下的交并比从0.63提高到0.932，显示了迭代自我优化机制的有效性。", "conclusion": "该研究表明，通过模仿人类认知过程中的试错和观察纠正策略，可以在视觉语言模型中实现几何推理能力的显著提升。"}}
{"id": "2602.05557", "pdf": "https://arxiv.org/pdf/2602.05557", "abs": "https://arxiv.org/abs/2602.05557", "authors": ["Michael Schwingshackl", "Fabio F. Oberweger", "Mario Niedermeyer", "Huemer Johannes", "Markus Murschitz"], "title": "PIRATR: Parametric Object Inference for Robotic Applications with Transformers in 3D Point Clouds", "categories": ["cs.CV", "cs.RO"], "comment": "8 Pages, 11 Figures, Accepted at 2026 IEEE International Conference on Robotics & Automation (ICRA) Vienna", "summary": "We present PIRATR, an end-to-end 3D object detection framework for robotic use cases in point clouds. Extending PI3DETR, our method streamlines parametric 3D object detection by jointly estimating multi-class 6-DoF poses and class-specific parametric attributes directly from occlusion-affected point cloud data. This formulation enables not only geometric localization but also the estimation of task-relevant properties for parametric objects, such as a gripper's opening, where the 3D model is adjusted according to simple, predefined rules. The architecture employs modular, class-specific heads, making it straightforward to extend to novel object types without re-designing the pipeline. We validate PIRATR on an automated forklift platform, focusing on three structurally and functionally diverse categories: crane grippers, loading platforms, and pallets. Trained entirely in a synthetic environment, PIRATR generalizes effectively to real outdoor LiDAR scans, achieving a detection mAP of 0.919 without additional fine-tuning. PIRATR establishes a new paradigm of pose-aware, parameterized perception. This bridges the gap between low-level geometric reasoning and actionable world models, paving the way for scalable, simulation-trained perception systems that can be deployed in dynamic robotic environments. Code available at https://github.com/swingaxe/piratr.", "AI": {"tldr": "PIRATR是一个用于机器人应用的端到端三维点云中物体检测框架，通过变压器模型实现多类别6自由度姿态估计和特定类别的参数属性估计。", "motivation": "传统的3D对象检测方法难以处理遮挡影响下的点云数据，并且缺乏对任务相关属性（如抓取器开口）的直接估计能力。PIRATR旨在提供一种能够同时进行几何定位并估算功能属性的方法，以解决这些问题。", "method": "PIRATR采用了模块化、类别特定头部设计，通过变压器模型从点云数据中联合估计多类别的6自由度姿态和参数属性，并针对不同的物体类型进行了优化。该方法在合成环境中训练后能够有效推广到真实环境下的LiDAR扫描。", "result": "PIRATR在实际的室外LiDAR扫描中达到了0.919的检测mAP，无需额外微调，在叉车平台上对三种不同类型的物体（起重机抓具、装载平台和托盘）进行验证时表现出色。", "conclusion": "PIRATR开创了姿态感知、参数化感知的新范式，填补了低级几何推理与行动世界模型之间的空白。这为开发能够在动态机器人环境中部署的可扩展模拟训练感知系统奠定了基础。"}}
{"id": "2602.05555", "pdf": "https://arxiv.org/pdf/2602.05555", "abs": "https://arxiv.org/abs/2602.05555", "authors": ["Panagiotis Sapoutzoglou", "Orestis Vaggelis", "Athina Zacharia", "Evangelos Sartinas", "Maria Pateraki"], "title": "IndustryShapes: An RGB-D Benchmark dataset for 6D object pose estimation of industrial assembly components and tools", "categories": ["cs.CV", "cs.RO"], "comment": "To appear in ICRA 2026", "summary": "We introduce IndustryShapes, a new RGB-D benchmark dataset of industrial tools and components, designed for both instance-level and novel object 6D pose estimation approaches. The dataset provides a realistic and application-relevant testbed for benchmarking these methods in the context of industrial robotics bridging the gap between lab-based research and deployment in real-world manufacturing scenarios. Unlike many previous datasets that focus on household or consumer products or use synthetic, clean tabletop datasets, or objects captured solely in controlled lab environments, IndustryShapes introduces five new object types with challenging properties, also captured in realistic industrial assembly settings. The dataset has diverse complexity, from simple to more challenging scenes, with single and multiple objects, including scenes with multiple instances of the same object and it is organized in two parts: the classic set and the extended set. The classic set includes a total of 4,6k images and 6k annotated poses. The extended set introduces additional data modalities to support the evaluation of model-free and sequence-based approaches. To the best of our knowledge, IndustryShapes is the first dataset to offer RGB-D static onboarding sequences. We further evaluate the dataset on a representative set of state-of-the art methods for instance-based and novel object 6D pose estimation, including also object detection, segmentation, showing that there is room for improvement in this domain. The dataset page can be found in https://pose-lab.github.io/IndustryShapes.", "AI": {"tldr": "介绍了IndustryShapes数据集，该数据集为工业工具和组件的6D姿态估计提供了一个现实的应用场景。", "motivation": "填补了实验室研究与实际制造环境之间的差距，提供了具有挑战性的工业装配设置中的真实数据。", "method": "通过收集包含5种新对象类型的RGB-D图像和注释姿态，创建了一个用于评估不同方法的基准数据集。", "result": "展示了现有6D姿态估计方法在处理复杂场景时的表现，并指出了改进的空间。", "conclusion": "IndustryShapes数据集是第一个提供RGB-D静态上载序列的数据集，为工业应用中的姿态估计算法提供了重要的测试平台。"}}
{"id": "2602.05552", "pdf": "https://arxiv.org/pdf/2602.05552", "abs": "https://arxiv.org/abs/2602.05552", "authors": ["Bessie Dominguez-Dager", "Sergio Suescun-Ferrandiz", "Felix Escalona", "Francisco Gomez-Donoso", "Miguel Cazorla"], "title": "VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "This paper introduces VLN-Pilot, a novel framework in which a large Vision-and-Language Model (VLLM) assumes the role of a human pilot for indoor drone navigation. By leveraging the multimodal reasoning abilities of VLLMs, VLN-Pilot interprets free-form natural language instructions and grounds them in visual observations to plan and execute drone trajectories in GPS-denied indoor environments. Unlike traditional rule-based or geometric path-planning approaches, our framework integrates language-driven semantic understanding with visual perception, enabling context-aware, high-level flight behaviors with minimal task-specific engineering. VLN-Pilot supports fully autonomous instruction-following for drones by reasoning about spatial relationships, obstacle avoidance, and dynamic reactivity to unforeseen events. We validate our framework on a custom photorealistic indoor simulation benchmark and demonstrate the ability of the VLLM-driven agent to achieve high success rates on complex instruction-following tasks, including long-horizon navigation with multiple semantic targets. Experimental results highlight the promise of replacing remote drone pilots with a language-guided autonomous agent, opening avenues for scalable, human-friendly control of indoor UAVs in tasks such as inspection, search-and-rescue, and facility monitoring. Our results suggest that VLLM-based pilots may dramatically reduce operator workload while improving safety and mission flexibility in constrained indoor environments.", "AI": {"tldr": "VLN-Pilot利用大型视觉和语言模型实现室内无人机自主导航，通过自然语言指令进行飞行轨迹规划与执行。", "motivation": "解决传统路径规划方法难以处理复杂环境的问题，并减少操作员的工作量、提高安全性和任务灵活性。", "method": "引入VLN-Pilot框架，使用VLLM理解和解释自然语言指令并通过视觉感知制定和执行无人机的飞行计划。", "result": "在模拟环境中测试成功，表明能够实现复杂的自主导航任务并取得高成功率。", "conclusion": "展示出将远程无人机操作员替换为基于语言驱动的自动代理的可能性，促进室内UAV控制的可扩展性和人性化。"}}
{"id": "2602.05551", "pdf": "https://arxiv.org/pdf/2602.05551", "abs": "https://arxiv.org/abs/2602.05551", "authors": ["Yue Ma", "Zhikai Wang", "Tianhao Ren", "Mingzhe Zheng", "Hongyu Liu", "Jiayi Guo", "Mark Fong", "Yuxuan Xue", "Zixiang Zhao", "Konrad Schindler", "Qifeng Chen", "Linfeng Zhang"], "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer", "categories": ["cs.CV"], "comment": "Accepted by ICLR2026, Project page: fastvmt.gitHub.io, Code: https://github.com/mayuelala/FastVMT", "summary": "Video motion transfer aims to synthesize videos by generating visual content according to a text prompt while transferring the motion pattern observed in a reference video. Recent methods predominantly use the Diffusion Transformer (DiT) architecture. To achieve satisfactory runtime, several methods attempt to accelerate the computations in the DiT, but fail to address structural sources of inefficiency. In this work, we identify and remove two types of computational redundancy in earlier work: motion redundancy arises because the generic DiT architecture does not reflect the fact that frame-to-frame motion is small and smooth; gradient redundancy occurs if one ignores that gradients change slowly along the diffusion trajectory. To mitigate motion redundancy, we mask the corresponding attention layers to a local neighborhood such that interaction weights are not computed unnecessarily distant image regions. To exploit gradient redundancy, we design an optimization scheme that reuses gradients from previous diffusion steps and skips unwarranted gradient computations. On average, FastVMT achieves a 3.43x speedup without degrading the visual fidelity or the temporal consistency of the generated videos.", "AI": {"tldr": "本文提出了一种名为FastVMT的技术，旨在通过消除计算冗余来加速视频运动转移过程。", "motivation": "现有方法使用Diffusion Transformer（DiT）架构进行视频生成时存在运行时间效率问题。尽管有些方法尝试加速DiT的计算，但未能解决结构性低效的问题。本文识别并消除了两种类型的计算冗余：运动冗余和梯度冗余。", "method": "为了消除运动冗余，我们对相应的注意力层进行了掩码处理，只考虑局部邻域内的交互权重；为利用梯度冗余，设计了优化方案以复用前一步扩散的梯度并跳过不必要的计算。", "result": "FastVMT在不降低视觉保真度或时间一致性的前提下实现了平均3.43倍的速度提升。", "conclusion": "通过消除两种类型的计算冗余，FastVMT显著提高了视频运动转移过程的效率。"}}
{"id": "2602.05548", "pdf": "https://arxiv.org/pdf/2602.05548", "abs": "https://arxiv.org/abs/2602.05548", "authors": ["Zhiqi Yu", "Zhangquan Chen", "Mengting Liu", "Heye Zhang", "Liangqiong Qu"], "title": "Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly GRPO, has become the standard for eliciting LLM reasoning. However, its efficiency in exploration and difficulty adaptation remains an open challenge. In this work, we argue that these bottlenecks stem from an implicit advantage symmetry inherent in Group Relative Advantage Estimation (GRAE). This symmetry induces two critical limitations: (i) at the group level, strict symmetry in weights between correct and incorrect trajectories leaves unsampled action logits unchanged, thereby hindering exploration of novel correct solution. (ii) at the sample level, the algorithm implicitly prioritizes medium-difficulty samples, remaining agnostic to the non-stationary demands of difficulty focus. Through controlled experiments, we reveal that this symmetric property is sub-optimal, yielding two pivotal insights: (i) asymmetrically suppressing the advantages of correct trajectories encourages essential exploration. (ii) learning efficiency is maximized by a curriculum-like transition-prioritizing simpler samples initially before gradually shifting to complex ones. Motivated by these findings, we propose Asymmetric GRAE (A-GRAE), which dynamically modulates exploration incentives and sample-difficulty focus. Experiments across seven benchmarks demonstrate that A-GRAE consistently improves GRPO and its variants across both LLMs and MLLMs.", "AI": {"tldr": "揭示了GRPO在探索和难度适应方面面临的挑战，并提出了非对称GRAE（A-GRAE）来改进这些问题。", "motivation": "指出GRPO在探索新正确解决方案时存在瓶颈，因为优势估计中的隐式对称性导致难以处理动态变化的难度需求。", "method": "通过控制实验揭示了对称性的问题，并提出了非对称GRAE（A-GRAE），该方法能够根据学习过程调整探索激励和样本难度。", "result": "实验证明，A-GRAE在七个基准测试中均改进了GRPO及其变体的性能。", "conclusion": "非对称GRAE通过调整探索策略解决了原有算法中的瓶颈问题，并提高了模型的学习效率。"}}
{"id": "2602.05547", "pdf": "https://arxiv.org/pdf/2602.05547", "abs": "https://arxiv.org/abs/2602.05547", "authors": ["Shyam Sundhar Ramesh", "Xiaotong Ji", "Matthieu Zimmer", "Sangwoong Yoon", "Zhiyong Wang", "Haitham Bou Ammar", "Aurelien Lucchi", "Ilija Bogunovic"], "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Preprint", "summary": "RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks.", "AI": {"tldr": "本文提出了一种新的多任务GRPO（MT-GRPO）算法，以优化大型语言模型在多种推理任务上的可靠性。", "motivation": "基于强化学习的后训练方法GRPO被广泛应用于提高大语言模型在单一任务上的性能。然而，在实际部署中需要跨多样化的任务上保持可靠的性能，直接应用多任务适应的方法可能导致某些任务主导优化过程而其他任务停滞不前，从而影响整体效果。", "method": "MT-GRPO算法通过动态调整任务权重来明确优化最差任务的性能并促进跨任务平衡进步，并引入比率保护采样器以确保任务级策略梯度反映调整后的权重。", "result": "实验表明，在3任务和9任务设置中，MT-GRPO在最差任务准确性方面始终优于基线。特别是在3任务设置中，MT-GRPO比标准的GRPO提高了16%至28%，比DAPO提高了6%的绝对性能改进。", "conclusion": "MT-GRPO算法有效地解决了大型语言模型跨多种推理任务时的表现不均衡问题，并且在最差任务准确性方面取得了显著改善。"}}
{"id": "2602.05544", "pdf": "https://arxiv.org/pdf/2602.05544", "abs": "https://arxiv.org/abs/2602.05544", "authors": ["Fahad Anwaar", "Adil Mehmood Khan", "Muhammad Khalid", "Usman Zia", "Kezhi Wang"], "title": "Reasoning-guided Collaborative Filtering with Language Models for Explainable Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) exhibit potential for explainable recommendation systems but overlook collaborative signals, while prevailing methods treat recommendation and explanation as separate tasks, resulting in a memory footprint. We present RGCF-XRec, a hybrid framework that introduces reasoning-guided collaborative filtering (CF) knowledge into a language model to deliver explainable sequential recommendations in a single step. Theoretical grounding and empirical findings reveal that RGCF-XRec offers three key merits over leading CF-aware LLM-based methods: (1) reasoning-guided augmentation of CF knowledge through contextual prompting to discover latent preferences and interpretable reasoning paths; (2) an efficient scoring mechanism based on four dimensions: coherence, completeness, relevance, and consistency to mitigate noisy CF reasoning traces and retain high-quality explanations; (3) a unified representation learning network that encodes collaborative and semantic signals, enabling a structured prompt to condition the LLM for explainable sequential recommendation. RGCF-XRec demonstrates consistent improvements across Amazon datasets, Sports, Toys, and Beauty, comprising 642,503 user-item interactions. It improves HR@10 by 7.38\\% in Sports and 4.59\\% in Toys, along with ROUGE-L by 8.02\\% and 3.49\\%, respectively. It reduces the cold warm performance gap, achieving overall gains of 14.5\\% in cold-start and 11.9\\% in warm start scenarios, and enhances zero-shot HR@5 by 18.54\\% in Beauty and 23.16\\% in Toys, highlighting effective generalization and robustness. Moreover, RGCF-XRec achieves training efficiency with a lightweight LLaMA 3.2-3B backbone, ensuring scalability for real-world applications.", "AI": {"tldr": "论文提出了一种结合推理引导的协同过滤和语言模型的框架RGCF-XRec，用于生成可解释的推荐。", "motivation": "现有的基于大型语言模型的方法忽视了协同信号，并且将推荐与解释视为独立任务。因此，作者提出了一个融合推理引导的协同过滤知识到语言模型中的框架，以实现可解释的推荐系统。", "method": "RGCF-XRec通过上下文提示来增强协同过滤知识，引入高效的评分机制，并利用统一表示学习网络编码协作和语义信号，使LLM能够生成结构化提示并提供可解释性。", "result": "实验表明，RGCF-XRec在Amazon Sports、Toys、Beauty数据集上优于现有方法。HR@10指标提升了7.38%（Sports）和4.59%（Toys），ROUGE-L得分也分别提高了8.02%（Sports）和3.49%（Toys）。此外，RGCF-XRec在冷启动场景下的性能有了显著提高。", "conclusion": "RGCF-XRec通过引入推理引导的协同过滤知识到语言模型中实现了可解释性的推荐系统。该方法不仅提高了推荐精度，还缩小了冷启动和热启动之间的差距，并且具有良好的泛化能力和鲁棒性，同时保持了训练效率。"}}
{"id": "2602.05539", "pdf": "https://arxiv.org/pdf/2602.05539", "abs": "https://arxiv.org/abs/2602.05539", "authors": ["Yawei Li", "Benjamin Bergner", "Yinghan Zhao", "Vihang Prakash Patil", "Bei Chen", "Cheng Wang"], "title": "Steering Large Reasoning Models towards Concise Reasoning via Flow Matching", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "This paper has been accepted to Transactions on Machine Learning Research (TMLR)", "summary": "Large Reasoning Models (LRMs) excel at complex reasoning tasks, but their efficiency is often hampered by overly verbose outputs. Prior steering methods attempt to address this issue by applying a single, global vector to hidden representations -- an approach grounded in the restrictive linear representation hypothesis. In this work, we introduce FlowSteer, a nonlinear steering method that goes beyond uniform linear shifts by learning a complete transformation between the distributions associated with verbose and concise reasoning. This transformation is learned via Flow Matching as a velocity field, enabling precise, input-dependent control over the model's reasoning process. By aligning steered representations with the distribution of concise-reasoning activations, FlowSteer yields more compact reasoning than the linear shifts. Across diverse reasoning benchmarks, FlowSteer demonstrates strong task performance and token efficiency compared to leading inference-time baselines. Our work demonstrates that modeling the full distributional transport with generative techniques offers a more effective and principled foundation for controlling LRMs.", "AI": {"tldr": "通过Flow匹配学习流场，引导大型推理模型生成简洁的输出。", "motivation": "大型推理模型在复杂任务中表现出色，但其输出过于冗长影响效率。现有方法采用全局向量调整隐藏表示以提高效率，然而这限制了模型的表现力。", "method": "引入FlowSteer技术通过流匹配学习转换场，控制模型的推理过程，使生成结果更加简洁高效。", "result": "在多种推理基准测试中，FlowSteer方法显示出了比现有方法更优的任务表现和更少的令牌使用量。", "conclusion": "利用生成式技术建模完整分布传输可为控制大型推理模型提供更有效且原则性的基础。"}}
{"id": "2602.05538", "pdf": "https://arxiv.org/pdf/2602.05538", "abs": "https://arxiv.org/abs/2602.05538", "authors": ["Malaz Tamim", "Andrea Matic-Flierl", "Karsten Roscher"], "title": "A Comparative Study of 3D Person Detection: Sensor Modalities and Robustness in Diverse Indoor and Outdoor Environments", "categories": ["cs.CV"], "comment": "Accepted for VISAPP 2026", "summary": "Accurate 3D person detection is critical for safety in applications such as robotics, industrial monitoring, and surveillance. This work presents a systematic evaluation of 3D person detection using camera-only, LiDAR-only, and camera-LiDAR fusion. While most existing research focuses on autonomous driving, we explore detection performance and robustness in diverse indoor and outdoor scenes using the JRDB dataset. We compare three representative models - BEVDepth (camera), PointPillars (LiDAR), and DAL (camera-LiDAR fusion) - and analyze their behavior under varying occlusion and distance levels. Our results show that the fusion-based approach consistently outperforms single-modality models, particularly in challenging scenarios. We further investigate robustness against sensor corruptions and misalignments, revealing that while DAL offers improved resilience, it remains sensitive to sensor misalignment and certain LiDAR-based corruptions. In contrast, the camera-based BEVDepth model showed the lowest performance and was most affected by occlusion, distance, and noise. Our findings highlight the importance of utilizing sensor fusion for enhanced 3D person detection, while also underscoring the need for ongoing research to address the vulnerabilities inherent in these systems.", "AI": {"tldr": "该论文系统评估了在不同室内和室外场景中使用相机、激光雷达以及两者融合的三维人体检测方法的表现。", "motivation": "准确的三维人体检测对于机器人、工业监控和监视等应用的安全性至关重要。现有研究大多集中于自动驾驶，本文探讨了在JRDB数据集上多种传感器模态下的人体检测性能及鲁棒性。", "method": "作者比较了三种代表性模型——BEVDepth（相机）、PointPillars（激光雷达）以及DAL（相机-激光雷达融合），并在不同遮挡程度和距离级别下进行了行为分析。进一步研究了这些方法在传感器损坏和错位情况下的鲁棒性。", "result": "结果表明，基于融合的方法在挑战场景中表现更佳，并且比单个模态模型具有更高的鲁棒性；然而，其仍对激光雷达引起的某些错误敏感。相机模型BEVDepth性能最低，受遮挡、距离和噪声的影响最大。", "conclusion": "本文强调了利用传感器融合来提高三维人体检测效果的重要性，同时也指出了需要进一步研究以解决这些系统固有的脆弱性问题。"}}
{"id": "2602.05536", "pdf": "https://arxiv.org/pdf/2602.05536", "abs": "https://arxiv.org/abs/2602.05536", "authors": ["Yayuan Li", "Ze Peng", "Jian Zhang", "Jintao Guo", "Yue Duan", "Yinghuan Shi"], "title": "When Shared Knowledge Hurts: Spectral Over-Accumulation in Model Merging", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Model merging combines multiple fine-tuned models into a single model by adding their weight updates, providing a lightweight alternative to retraining. Existing methods primarily target resolving conflicts between task updates, leaving the failure mode of over-counting shared knowledge unaddressed. We show that when tasks share aligned spectral directions (i.e., overlapping singular vectors), a simple linear combination repeatedly accumulates these directions, inflating the singular values and biasing the merged model toward shared subspaces. To mitigate this issue, we propose Singular Value Calibration (SVC), a training-free and data-free post-processing method that quantifies subspace overlap and rescales inflated singular values to restore a balanced spectrum. Across vision and language benchmarks, SVC consistently improves strong merging baselines and achieves state-of-the-art performance. Furthermore, by modifying only the singular values, SVC improves the performance of Task Arithmetic by 13.0%. Code is available at: https://github.com/lyymuwu/SVC.", "AI": {"tldr": "本文探讨了模型融合过程中共享知识过度积累的问题，并提出了一种称为奇异值校准（SVC）的方法来解决这一问题。", "motivation": "现有的模型合并方法主要关注任务更新之间的冲突，而忽略了共享知识重复计数导致的问题。当任务具有重叠的谱方向时，简单的线性组合会导致这些方向过度累积，从而使得合并后的模型偏向于共享子空间。", "method": "为了缓解这一问题，作者提出了一种无需训练和数据的支持后处理方法——奇异值校准（SVC）。该方法通过量化子空间重叠并调整膨胀的奇异值来恢复平衡谱。这种方法仅修改了奇异值，从而改善了任务算术性能。", "result": "在视觉和语言基准测试中，SVC始终提高了强合并基线，并达到了最先进的性能。具体而言，它将任务算术性能提升了13.0%。", "conclusion": "本文揭示了模型融合过程中谱方向过度积累的问题，并通过引入奇异值校准（SVC）方法有效解决了这一问题，证明了这种方法在多种基准测试中的有效性。"}}
{"id": "2602.05534", "pdf": "https://arxiv.org/pdf/2602.05534", "abs": "https://arxiv.org/abs/2602.05534", "authors": ["Youngwoo Shin", "Jiwan Hur", "Junmo Kim"], "title": "SSG: Scaled Spatial Guidance for Multi-Scale Visual Autoregressive Generation", "categories": ["cs.CV"], "comment": "Accepted to ICLR 2026", "summary": "Visual autoregressive (VAR) models generate images through next-scale prediction, naturally achieving coarse-to-fine, fast, high-fidelity synthesis mirroring human perception. In practice, this hierarchy can drift at inference time, as limited capacity and accumulated error cause the model to deviate from its coarse-to-fine nature. We revisit this limitation from an information-theoretic perspective and deduce that ensuring each scale contributes high-frequency content not explained by earlier scales mitigates the train-inference discrepancy. With this insight, we propose Scaled Spatial Guidance (SSG), training-free, inference-time guidance that steers generation toward the intended hierarchy while maintaining global coherence. SSG emphasizes target high-frequency signals, defined as the semantic residual, isolated from a coarser prior. To obtain this prior, we leverage a principled frequency-domain procedure, Discrete Spatial Enhancement (DSE), which is devised to sharpen and better isolate the semantic residual through frequency-aware construction. SSG applies broadly across VAR models leveraging discrete visual tokens, regardless of tokenization design or conditioning modality. Experiments demonstrate SSG yields consistent gains in fidelity and diversity while preserving low latency, revealing untapped efficiency in coarse-to-fine image generation. Code is available at https://github.com/Youngwoo-git/SSG.", "AI": {"tldr": "本文提出了SSG（Scaled Spatial Guidance），一种无训练的推理时指导方法，用于改进多尺度视觉自回归生成模型。", "motivation": "在实践中，视觉自回归模型的层级结构可能因容量限制和累积误差而偏离其粗到细的特点。为了缓解这一问题并确保每个尺度都贡献高频内容，本文从信息论的角度重新审视了这个问题，并提出了解决方案。", "method": "SSG通过强调目标高频信号来引导生成过程，这些信号定义为语义残差，该残差是从较粗糙的先验中隔离出来的。为了获得这种先验，我们利用频率域方法Discrete Spatial Enhancement（DSE）来增强和更好地分离语义残差。", "result": "实验表明，SSG在保持低延迟的同时，在精度和多样性方面表现出一致的优势，揭示了粗到细图像生成中的未开发效率。", "conclusion": "SSG是一种通用的方法，适用于基于离散视觉标记的自回归模型，并且无论标记化设计或条件模式如何都能取得良好的效果。"}}
{"id": "2602.05533", "pdf": "https://arxiv.org/pdf/2602.05533", "abs": "https://arxiv.org/abs/2602.05533", "authors": ["Zhengyi Guo", "Wenpin Tang", "Renyuan Xu"], "title": "Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach", "categories": ["cs.AI"], "comment": null, "summary": "We study conditional generation in diffusion models under hard constraints, where generated samples must satisfy prescribed events with probability one. Such constraints arise naturally in safety-critical applications and in rare-event simulation, where soft or reward-based guidance methods offer no guarantee of constraint satisfaction. Building on a probabilistic interpretation of diffusion models, we develop a principled conditional diffusion guidance framework based on Doob's h-transform, martingale representation and quadratic variation process. Specifically, the resulting guided dynamics augment a pretrained diffusion with an explicit drift correction involving the logarithmic gradient of a conditioning function, without modifying the pretrained score network. Leveraging martingale and quadratic-variation identities, we propose two novel off-policy learning algorithms based on a martingale loss and a martingale-covariation loss to estimate h and its gradient using only trajectories from the pretrained model. We provide non-asymptotic guarantees for the resulting conditional sampler in both total variation and Wasserstein distances, explicitly characterizing the impact of score approximation and guidance estimation errors. Numerical experiments demonstrate the effectiveness of the proposed methods in enforcing hard constraints and generating rare-event samples.", "AI": {"tldr": "研究在扩散模型下的条件生成问题，在生成样本必须满足特定事件的概率为一的情况下，提出了基于Doob的h变换、鞅表示和二次变差过程的新框架。", "motivation": "在安全性至关重要的应用和稀有事件模拟中，软引导或奖励导向的方法无法保证约束条件的满足。因此需要提出一种新的方法来确保生成样本必须符合规定的事件。", "method": "基于扩散模型的概率解释，提出了基于Doob的h变换、鞅表示和二次变差过程的新框架，通过引入一个显式的漂移修正项而不改变预训练的得分网络，提高了条件引导的有效性。利用鞅和二次变差的身份，提出两个新的脱策学习算法。", "result": "新方法在生成符合硬约束的样本和稀有事件样例方面显示了有效性，并提供了关于条件采样的非渐近保证。", "conclusion": "通过引入新的框架和算法，解决了在扩散模型下的条件生成问题，在安全性至关重要的应用和稀有事件模拟中具有潜在的应用价值。"}}
{"id": "2602.05532", "pdf": "https://arxiv.org/pdf/2602.05532", "abs": "https://arxiv.org/abs/2602.05532", "authors": ["Florian Dietz", "William Wale", "Oscar Gilg", "Robert McCarthy", "Felix Michalak", "Gustavo Ewbank Rodrigues Danon", "Miguelito de Guzman", "Dietrich Klakow"], "title": "Split Personality Training: Revealing Latent Knowledge Through Alternate Personalities", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Detecting misalignment in large language models is challenging because models may learn to conceal misbehavior during training. Standard auditing techniques fall short: black-box methods often cannot distinguish misaligned outputs from benign ones, and mechanistic interpretability does not scale with model capabilities. We introduce Split Personality Training (SPT), which fine-tunes a second ``honest persona'' into LoRA parameters that remain inactive during normal operation. After the main model responds, we activate the LoRA adapter and insert a trigger string, enabling the honest persona to review the response while accessing the main model's latent states. We test our method on the Anthropic Auditing Game Model Organism, a benchmark where Llama-3.3-70B is trained to exploit reward hacks while concealing this behavior. SPT achieves 96% overall accuracy, whereas Anthropic reports near 0% accuracy. The honest persona reveals latent knowledge inaccessible to external observers, such as the fictional biases the compromised model was trained on.", "AI": {"tldr": "论文提出了一种名为分身训练（Split Personality Training，SPT）的方法，用于揭示大型语言模型中的潜在行为。", "motivation": "由于大型语言模型可能在训练中学会隐藏不当行为，因此检测模型的不一致很具挑战性。传统审计技术在这种情况下效果不佳，黑盒方法难以区分恶意输出和良性输出，而机械解释无法扩展到更强大的模型能力。SPT旨在解决这一问题。", "method": "分身训练（SPT）通过在低秩适应参数中微调一个“诚实的分身”，使其在正常操作时保持非活动状态来工作。主要模型响应后，激活LoRA适配器并插入触发字符串，以使诚实分身能够审查响应同时访问主模型的潜在状态。", "result": "SPT在检测Llama-3.3-70B是否利用奖励漏洞隐藏行为时表现出色，准确率高达96%，而Anthropic报告的准确率为接近0%。此外，诚实分身揭示了外部观察者无法触及的内部偏见等潜在知识。", "conclusion": "SPT方法能够有效地揭示大型语言模型中的隐蔽不当行为和潜在的知识，为解决这一难题提供了有效的途径。"}}
{"id": "2602.05527", "pdf": "https://arxiv.org/pdf/2602.05527", "abs": "https://arxiv.org/abs/2602.05527", "authors": ["Ben Isselmann", "Dilara Göksu", "Andreas Weinmann"], "title": "Generalization of Self-Supervised Vision Transformers for Protein Localization Across Microscopy Domains", "categories": ["cs.CV"], "comment": "AMEE Conference Proceeding 2025, 11 pages, 2 figures", "summary": "Task-specific microscopy datasets are often too small to train deep learning models that learn robust feature representations. Self-supervised learning (SSL) can mitigate this by pretraining on large unlabeled datasets, but it remains unclear how well such representations transfer across microscopy domains with different staining protocols and channel configurations. We investigate the cross-domain transferability of DINO-pretrained Vision Transformers for protein localization on the OpenCell dataset. We generate image embeddings using three DINO backbones pretrained on ImageNet-1k, the Human Protein Atlas (HPA), and OpenCell, and evaluate them by training a supervised classification head on OpenCell labels. All pretrained models transfer well, with the microscopy-specific HPA-pretrained model achieving the best performance (mean macro $F_1$-score = 0.8221 \\pm 0.0062), slightly outperforming a DINO model trained directly on OpenCell (0.8057 \\pm 0.0090). These results highlight the value of large-scale pretraining and indicate that domain-relevant SSL representations can generalize effectively to related but distinct microscopy datasets, enabling strong downstream performance even when task-specific labeled data are limited.", "AI": {"tldr": "研究探索了自我监督学习预训练的视觉变换器在跨显微镜域蛋白质定位中的泛化能力", "motivation": "小样本任务数据集难以训练深度学习模型，通过大规模无标签数据上的自我监督学习预训练可以缓解这一问题。作者研究了预训练模型如何有效迁移到不同染色协议和通道配置的显微镜领域中", "method": "使用三种不同的DINO backbone（ImageNet-1k、HPA、OpenCell）生成图像嵌入，然后通过在OpenCell标签上训练监督分类头来评估其性能", "result": "所有预训练模型均表现良好，其中特定于显微镜领域的HPA预训练模型表现出最佳性能（平均宏F1得分为0.8221±0.0062），略优于直接在OpenCell数据上训练的DINO模型（0.8057±0.0090）", "conclusion": "研究结果表明大规模预训练的价值，并展示了领域相关的自我监督学习表示可以有效地泛化到相关但不同的显微镜数据集中"}}
{"id": "2602.05525", "pdf": "https://arxiv.org/pdf/2602.05525", "abs": "https://arxiv.org/abs/2602.05525", "authors": ["Fabrizio Fornari", "Eleonora Cova", "Niccolò Vito Vacca", "Francesco Bocci", "Luigi Caputo"], "title": "Assessing Problem-Solving in HR Contexts: A Comparison Between Game-Based and Self-Report Measures", "categories": ["cs.HC"], "comment": "24 pages, 2 figures", "summary": "Game-based assessments (GBAs) are increasingly adopted in recruitment contexts as tools to assess transversal skills through observable behavior. However, empirical evidence directly comparing game-based behavioral indicators with traditional self-report measures remains limited. This study adopts a method-comparison approach to explore the convergence between self-perceived and behaviorally enacted problem-solving competence, comparing a game-based assessment with the Problem Solving Inventory (PSI-B). Seventy-eight participants completed both the PSI-B and a five-minute game-based problem-solving task, which classified performance into four behavioral proficiency levels. Results revealed no significant convergence between self-reported and behavior-based problem-solving scores, indicating a lack of convergence between the two measurement modalities. Rather than indicating a lack of validity of the game-based assessment, these findings support the view that self-report and behavioral measures provide complementary information about problem-solving competence. The study highlights the risks of relying on a single assessment modality in personnel selection and underscores the value of integrating game-based tools within multi-method assessment frameworks.", "AI": {"tldr": "比较游戏化评估与自我报告量表在人力资源背景下的问题解决能力测评中的有效性。", "motivation": "探索并比较游戏中行为表现和自我报告的问题解决技能，以确定哪种方法更能准确测量员工的能力。", "method": "采用78名参与者进行研究，他们完成了自我评价问卷（PSI-B）以及五分钟的游戏化评估任务。将游戏化评估分为四个等级的行为熟练度。", "result": "未发现自评和行为表现的问题解决能力分数之间存在显著相关性，表明两种测量方式之间的缺乏一致性。", "conclusion": "研究结果强调了单一测评方法的风险，并建议在员工选拔中结合使用多种评估工具。"}}
{"id": "2602.05524", "pdf": "https://arxiv.org/pdf/2602.05524", "abs": "https://arxiv.org/abs/2602.05524", "authors": ["Konosuke Yoshizato", "Kazuma Shimizu", "Ryota Higa", "Takanobu Otsuka"], "title": "AI Agent Systems for Supply Chains: Structured Decision Prompts and Memory Retrieval", "categories": ["cs.MA", "cs.AI"], "comment": "A full version of the extended abstract accepted by the 25th International Conference on Autonomous Agents and Multiagent Systems(AAMAS 2026)", "summary": "This study investigates large language model (LLM) -based multi-agent systems (MASs) as a promising approach to inventory management, which is a key component of supply chain management. Although these systems have gained considerable attention for their potential to address the challenges associated with typical inventory management methods, key uncertainties regarding their effectiveness persist. Specifically, it is unclear whether LLM-based MASs can consistently derive optimal ordering policies and adapt to diverse supply chain scenarios. To address these questions, we examine an LLM-based MAS with a fixed-ordering strategy prompt that encodes the stepwise processes of the problem setting and a safe-stock strategy commonly used in inventory management. Our empirical results demonstrate that, even without detailed prompt adjustments, an LLM-based MAS can determine optimal ordering decisions in a restricted scenario. To enhance adaptability, we propose a novel agent called AIM-RM, which leverages similar historical experiences through similarity matching. Our results show that AIM-RM outperforms benchmark methods across various supply chain scenarios, highlighting its robustness and adaptability.", "AI": {"tldr": "研究基于大型语言模型的多代理系统在库存管理中的应用，探讨其在不同供应链场景下的表现。", "motivation": "探索基于大型语言模型的多代理系统在解决传统库存管理方法挑战方面的潜力，并澄清这些系统的有效性及适应性问题。", "method": "设计了具有固定订购策略提示符和相似度匹配机制的记忆检索型新代理人AIM-RM，以提升多代理系统的决策准确性和灵活性。", "result": "实验结果显示，即使没有详细的提示调整，基于大型语言模型的多代理系统也能在限制性场景中做出最佳订单决定；AIM-RM相比基准方法在各种供应链场景下表现出更好的性能和适应能力。", "conclusion": "基于大型语言模型的多代理系统具有解决库存管理挑战的能力，并通过引入记忆检索机制进一步增强了其灵活性和通用性。"}}
{"id": "2602.05523", "pdf": "https://arxiv.org/pdf/2602.05523", "abs": "https://arxiv.org/abs/2602.05523", "authors": ["Shahin Honarvar", "Amber Gorzynski", "James Lee-Jones", "Harry Coppock", "Marek Rei", "Joseph Ryan", "Alastair F. Donaldson"], "title": "Capture the Flags: Family-Based Evaluation of Agentic LLMs via Semantics-Preserving Transformations", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Agentic large language models (LLMs) are increasingly evaluated on cybersecurity tasks using capture-the-flag (CTF) benchmarks. However, existing pointwise benchmarks have limited ability to shed light on the robustness and generalisation abilities of agents across alternative versions of the source code. We introduce CTF challenge families, whereby a single CTF is used as the basis for generating a family of semantically-equivalent challenges via semantics-preserving program transformations. This enables controlled evaluation of agent robustness to source code transformations while keeping the underlying exploit strategy fixed. We introduce a new tool, Evolve-CTF, that generates CTF families from Python challenges using a range of transformations. Using Evolve-CTF to derive families from Cybench and Intercode challenges, we evaluate 13 agentic LLM configurations with tool access. We find that models are remarkably robust to intrusive renaming and code insertion-based transformations, but that composed transformations and deeper obfuscation affect performance by requiring more sophisticated use of tools. We also find that enabling explicit reasoning has little effect on solution success rates across challenge families. Our work contributes a valuable technique and tool for future LLM evaluations, and a large dataset characterising the capabilities of current state-of-the-art models in this domain.", "AI": {"tldr": "该论文介绍了通过语义保持变换生成CTF挑战家族的方法，以评估大型语言模型（LLM）在网络安全任务上的稳健性和泛化能力。", "motivation": "现有的点式基准测试对代理的健壮性和泛化能力的评估有限。为了更好地理解和改善这些代理的能力，作者引入了通过语义保持变换生成一系列等价挑战的方法，并开发了一个名为Evolve-CTF的新工具来实现这一目标。", "method": "该方法基于单个CTF挑战生成一组语义上等效但代码结构不同的挑战家族。使用Evolve-CTF从Python挑战中衍生出这些挑战家族，然后对13种具有工具访问权限的代理配置进行评估。", "result": "发现模型在面对侵入性重命名和代码插入变换时表现出强大的稳健性，但在应对组合变换和深层次混淆时性能下降。同时，启用明确推理并未显著提高解决成功率。", "conclusion": "该研究提供了一种有价值的技术和工具来评估未来LLM的性能，并创建了一个大型数据集以表征当前最先进的模型在网络安全任务上的能力。"}}
{"id": "2602.05522", "pdf": "https://arxiv.org/pdf/2602.05522", "abs": "https://arxiv.org/abs/2602.05522", "authors": ["Jeongbin You", "Donggun Kim", "Sejun Park", "Seungsang Oh"], "title": "Mapper-GIN: Lightweight Structural Graph Abstraction for Corrupted 3D Point Cloud Classification", "categories": ["cs.CV", "math.GT"], "comment": null, "summary": "Robust 3D point cloud classification is often pursued by scaling up backbones or relying on specialized data augmentation. We instead ask whether structural abstraction alone can improve robustness, and study a simple topology-inspired decomposition based on the Mapper algorithm. We propose Mapper-GIN, a lightweight pipeline that partitions a point cloud into overlapping regions using Mapper (PCA lens, cubical cover, and followed by density-based clustering), constructs a region graph from their overlaps, and performs graph classification with a Graph Isomorphism Network. On the corruption benchmark ModelNet40-C, Mapper-GIN achieves competitive and stable accuracy under Noise and Transformation corruptions with only 0.5M parameters. In contrast to prior approaches that require heavier architectures or additional mechanisms to gain robustness, Mapper-GIN attains strong corruption robustness through simple region-level graph abstraction and GIN message passing. Overall, our results suggest that region-graph structure offers an efficient and interpretable source of robustness for 3D visual recognition.", "AI": {"tldr": "提出Mapper-GIN轻量化管道，通过区域图抽象和GIN消息传递实现对扰动点云的鲁棒分类。", "motivation": "探索结构化抽象是否能够提高点云分类的鲁棒性，而不是依赖于增大数据集或特殊的数据增强方法。", "method": "使用Mapper算法将点云分解为重叠区域，并构建一个基于这些区域重叠的图。利用Graph Isomorphism Network进行图分类。", "result": "在ModelNet40-C数据集中，Mapper-GIN在噪声和变换扰动下实现了与较复杂方法相当的准确率，参数量仅为0.5M。", "conclusion": "表明区域图结构是一种高效的、可解释性强的鲁棒性来源。"}}
{"id": "2602.05516", "pdf": "https://arxiv.org/pdf/2602.05516", "abs": "https://arxiv.org/abs/2602.05516", "authors": ["Runxiao Liu", "Pengda Mao", "Xiangli Le", "Shuang Gu", "Yapeng Chen", "Quan Quan"], "title": "Virtual-Tube-Based Cooperative Transport Control for Multi-UAV Systems in Constrained Environments", "categories": ["cs.RO"], "comment": "10 pages, 8 figures", "summary": "This paper proposes a novel control framework for cooperative transportation of cable-suspended loads by multiple unmanned aerial vehicles (UAVs) operating in constrained environments. Leveraging virtual tube theory and principles from dissipative systems theory, the framework facilitates efficient multi-UAV collaboration for navigating obstacle-rich areas. The proposed framework offers several key advantages. (1) It achieves tension distribution and coordinated transportation within the UAV-cable-load system with low computational overhead, dynamically adapting UAV configurations based on obstacle layouts to facilitate efficient navigation. (2) By integrating dissipative systems theory, the framework ensures high stability and robustness, essential for complex multi-UAV operations. The effectiveness of the proposed approach is validated through extensive simulations, demonstrating its scalability for large-scale multi-UAV systems. Furthermore, the method is experimentally validated in outdoor scenarios, showcasing its practical feasibility and robustness under real-world conditions.", "AI": {"tldr": "提出了一种基于虚拟管道的多无人机协同运输控制框架，适用于受限制环境中的电缆悬挂负载运输。", "motivation": "为了在障碍物密集区域实现高效的多无人机协同运输任务，本研究旨在开发一种低计算开销、高稳定性和鲁棒性的控制系统。", "method": "利用虚拟管道理论和耗散系统理论，设计了一种能够根据环境动态调整无人机布局的框架，以适应复杂地形并确保运输过程中的负载张力分布合理。", "result": "通过广泛的仿真验证了所提出的控制方法的有效性，并在户外环境中进行了实验测试，证明其具备可扩展性和实际应用潜力。", "conclusion": "基于虚拟管道理论与耗散系统理论的多无人机协同运输框架能够在受限制环境下实现高效且稳定的负载运输任务。"}}
{"id": "2602.05515", "pdf": "https://arxiv.org/pdf/2602.05515", "abs": "https://arxiv.org/abs/2602.05515", "authors": ["Ajo Babu George", "Anna Mariam John", "Athul Anoop", "Balu Bhasuran"], "title": "A Unified Multimodal Framework for Dataset Construction and Model-Based Diagnosis of Ameloblastoma", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Artificial intelligence (AI)-enabled diagnostics in maxillofacial pathology require structured, high-quality multimodal datasets. However, existing resources provide limited ameloblastoma coverage and lack the format consistency needed for direct model training. We present a newly curated multimodal dataset specifically focused on ameloblastoma, integrating annotated radiological, histopathological, and intraoral clinical images with structured data derived from case reports. Natural language processing techniques were employed to extract clinically relevant features from textual reports, while image data underwent domain specific preprocessing and augmentation. Using this dataset, a multimodal deep learning model was developed to classify ameloblastoma variants, assess behavioral patterns such as recurrence risk, and support surgical planning. The model is designed to accept clinical inputs such as presenting complaint, age, and gender during deployment to enhance personalized inference. Quantitative evaluation demonstrated substantial improvements; variant classification accuracy increased from 46.2 percent to 65.9 percent, and abnormal tissue detection F1-score improved from 43.0 percent to 90.3 percent. Benchmarked against resources like MultiCaRe, this work advances patient-specific decision support by providing both a robust dataset and an adaptable multimodal AI framework.", "AI": {"tldr": "构建一个用于ameloblastoma诊断的多模态数据集，并开发一个多模态深度学习模型来提高病变分类和异常组织检测的准确性。", "motivation": "现有的资源对ameloblastoma的覆盖率有限，缺乏格式一致性以直接训练模型。本文旨在提供一种结构化、高质量的多模态数据集并开发相应的AI框架，以增强患者特定决策支持。", "method": "通过自然语言处理提取临床相关特征，并对图像数据进行领域特异性预处理和增强；使用此数据集建立一个多模态深度学习模型来分类ameloblastoma变体、评估行为模式以及辅助手术规划。", "result": "模型提高了病变分类的准确性，从46.2%提高到65.9%，同时异常组织检测F1分数也从43.0%提升至90.3%。", "conclusion": "本文开发的数据集和多模态AI框架为ameloblastoma提供了更准确、个性化的诊断支持，优于现有的资源。"}}
{"id": "2602.05513", "pdf": "https://arxiv.org/pdf/2602.05513", "abs": "https://arxiv.org/abs/2602.05513", "authors": ["Xukun Li", "Yu Sun", "Lei Zhang", "Bosheng Huang", "Yibo Peng", "Yuan Meng", "Haojun Jiang", "Shaoxuan Xie", "Guacai Yao", "Alois Knoll", "Zhenshan Bing", "Xinlong Wang", "Zhenguo Sun"], "title": "DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter", "categories": ["cs.RO", "cs.AI"], "comment": "17 pages, 8 figures", "summary": "Overview of the Proposed DECO Framework.} DECO is a DiT-based policy that decouples multimodal conditioning. Image and action tokens interact via joint self attention, while proprioceptive states and optional conditions are injected through adaptive layer normalization. Tactile signals are injected via cross attention, while a lightweight LoRA-based adapter is used to efficiently fine-tune the pretrained policy. DECO is also accompanied by DECO-50, a bimanual dexterous manipulation dataset with tactile sensing, consisting of 4 scenarios and 28 sub-tasks, covering more than 50 hours of data, approximately 5 million frames, and 8,000 successful trajectories.", "AI": {"tldr": "DECO是一个基于DiT的策略，通过解耦多模态条件来实现双臂灵巧操作，并使用轻量级LoRA适配器进行有效微调。", "motivation": "该研究旨在提供一种高效的策略，以解决基于图像和触觉信号的复杂双臂灵巧操作中的挑战。DECO框架旨在利用解耦多模态条件来提升操作性能。", "method": "提出了一种名为DECO的新方法，通过解耦多模态条件进行交互，并使用交叉注意力机制将触觉信号注入模型中。同时引入了轻量级LoRA适配器以提高训练效率。", "result": "DECO框架在处理复杂双臂灵巧操作任务时表现出了优越性能，特别是在涉及大量数据和多个子任务的情况下。", "conclusion": "研究通过实验验证了DECO的有效性，并表明该方法能够在不同场景下实现高效且准确的双臂灵巧操作。"}}
{"id": "2602.05508", "pdf": "https://arxiv.org/pdf/2602.05508", "abs": "https://arxiv.org/abs/2602.05508", "authors": ["Zhuang Xiong", "Chen Zhang", "Qingshan Xu", "Wenbing Tao"], "title": "VGGT-Motion: Motion-Aware Calibration-Free Monocular SLAM for Long-Range Consistency", "categories": ["cs.CV"], "comment": null, "summary": "Despite recent progress in calibration-free monocular SLAM via 3D vision foundation models, scale drift remains severe on long sequences. Motion-agnostic partitioning breaks contextual coherence and causes zero-motion drift, while conventional geometric alignment is computationally expensive. To address these issues, we propose VGGT-Motion, a calibration-free SLAM system for efficient and robust global consistency over kilometer-scale trajectories. Specifically, we first propose a motion-aware submap construction mechanism that uses optical flow to guide adaptive partitioning, prune static redundancy, and encapsulate turns for stable local geometry. We then design an anchor-driven direct Sim(3) registration strategy. By exploiting context-balanced anchors, it achieves search-free, pixel-wise dense alignment and efficient loop closure without costly feature matching. Finally, a lightweight submap-level pose graph optimization enforces global consistency with linear complexity, enabling scalable long-range operation. Experiments show that VGGT-Motion markedly improves trajectory accuracy and efficiency, achieving state-of-the-art performance in zero-shot, long-range calibration-free monocular SLAM.", "AI": {"tldr": "提出了一种基于运动感知的无标定单目SLAM系统VGGT-Motion，用于高效且鲁棒地进行千米级轨迹的一致性优化。", "motivation": "现有无标定单目SLAM方法在长序列中存在尺度漂移严重的问题，传统几何校正计算成本高，而运动无关分区破坏了上下文连贯性导致零运动漂移。为解决这些问题，提出了VGGT-Motion系统以提升千米级轨迹的一致性和效率。", "method": "首先设计了一种基于运动感知的子图构造机制，利用光流进行自适应分区、去除静态冗余并封装转弯区域，以稳定局部几何结构；其次采用锚点驱动直接Sim(3)对齐策略，在不需特征匹配的情况下实现像素级密集对齐和高效闭环检测；最后通过轻量级子图级别的姿态图优化强制全局一致性，并保持线性复杂度。", "result": "实验表明，VGGT-Motion显著提升了轨迹精度和效率，在零样本、千米级无标定单目SLAM中达到了最新性能。", "conclusion": "提出的VGGT-Motion系统能够有效解决长距离无标定单目SLAM中的尺度漂移问题，并在保持高效的同时实现了全局一致性优化。"}}
{"id": "2602.05506", "pdf": "https://arxiv.org/pdf/2602.05506", "abs": "https://arxiv.org/abs/2602.05506", "authors": ["Xinrui Lin", "Heyan Huang", "Shumin Shi", "John Vines"], "title": "Relying on LLMs: Student Practices and Instructor Norms are Changing in Computer Science Education", "categories": ["cs.HC"], "comment": "25 pages, 1 figure", "summary": "Prior research has raised concerns about students' over-reliance on large language models (LLMs) in higher education. This paper examines how Computer Science students and instructors engage with LLMs across five scenarios: \"Writing\", \"Quiz\", \"Programming\", \"Project-based learning\", and \"Information retrieval\". Through user studies with 16 students and 6 instructors, we identify 7 key intents, including increasingly complex student practices. Findings reveal varying levels of conflict between student practices and instructor norms, ranging from clear conflict in \"Writing-generation\" and \"(Programming) quiz-solving\", through partial conflict in \"Programming project-implementation\" and \"Project-based learning\", to broad agreement in \"Writing-revision & ideation\", \"(Programming) quiz-correction\" and \"Info-query & summary\". We document instructors are shifting from prohibiting to recognizing students' use of LLMs for high-quality work, integrating usage records into assessment grading. Finally, we propose LLM design guidelines: deploying default guardrails with game-like and empathetic interaction to prevent students from \"deserting\" LLMs, especially for \"Writing-generation\", while utilizing comprehension checks in low-conflict intents to promote learning.", "AI": {"tldr": "该论文研究了计算机科学教育中学生和教师在五种场景下使用大型语言模型（LLM）的情况，探讨了不同实践与规范之间的冲突，并提出了设计指南。", "motivation": "先前的研究对高等教育中学生的过度依赖于大型语言模型表示担忧。为了更好地理解这种现象及其影响，该论文进行了深入研究。", "method": "通过用户研究包括16名学生和6名教师，探讨了五种使用场景下的意图及行为：写作、测验、编程、基于项目的教学以及信息检索。", "result": "发现不同实践与规范之间存在冲突，并且教师开始从禁止学生使用LLM转向认可高质量的工作成果。提出了设计指南以防止过度依赖。", "conclusion": "论文强调了在计算机科学教育中，需要平衡学生对大型语言模型的利用和教师指导之间的关系，同时提出了设计上的建议来优化这种关系"}}
{"id": "2602.05499", "pdf": "https://arxiv.org/pdf/2602.05499", "abs": "https://arxiv.org/abs/2602.05499", "authors": ["Hanyu Wei", "Zunhai Su", "Peng Lu", "Chao Li", "Spandan Tiwari", "Ashish Sirasao", "Yuhan Dong"], "title": "SDFP: Speculative Decoding with FIT-Pruned Models for Training-Free and Plug-and-Play LLM Acceleration", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) underpin interactive multimedia applications such as captioning, retrieval, recommendation, and creative content generation, yet their autoregressive decoding incurs substantial latency. Speculative decoding reduces latency using a lightweight draft model, but deployment is often limited by the cost and complexity of acquiring, tuning, and maintaining an effective draft model. Recent approaches usually require auxiliary training or specialization, and even training-free methods incur costly search or optimization. We propose SDFP, a fully training-free and plug-and-play framework that builds the draft model via Fisher Information Trace (FIT)-based layer pruning of a given LLM. Using layer sensitivity as a proxy for output perturbation, SDFP removes low-impact layers to obtain a compact draft while preserving compatibility with the original model for standard speculative verification. SDFP needs no additional training, hyperparameter tuning, or separately maintained drafts, enabling rapid, deployment-friendly draft construction. Across benchmarks, SDFP delivers 1.32x-1.5x decoding speedup without altering the target model's output distribution, supporting low-latency multimedia applications.", "AI": {"tldr": "提出了一种名为SDFP的框架，用于通过修剪大型语言模型来加速解码。", "motivation": "现有方法在降低延迟的同时需要辅助训练或特别化调整，并且即使没有额外训练的方法也会带来复杂的搜索或优化。因此，本文旨在开发一种完全无需培训且可以即插即用的方法。", "method": "通过Fisher Information Trace (FIT) 基于层修剪给定的大型语言模型来构建草案模型。使用层敏感性作为输出扰动的代理，移除影响较小的层以获得一个紧凑的草案同时保持与原始模型的兼容性。", "result": "SDFP在不同基准测试中提供了1.32x-1.5x的解码加速，而不会改变目标模型的输出分布。", "conclusion": "SDFP提供了一种无需额外培训、参数调整或单独维护草案的方法，可以快速构建部署友好的草案模型。"}}
{"id": "2602.05496", "pdf": "https://arxiv.org/pdf/2602.05496", "abs": "https://arxiv.org/abs/2602.05496", "authors": ["Hanwen Zhang", "Yao Liu", "Peiyuan Jiang", "Lang Junjie", "Xie Jun", "Yihui He", "Yajiao Deng", "Siyu Du", "Qiao Liu"], "title": "XEmoGPT: An Explainable Multimodal Emotion Recognition Framework with Cue-Level Perception and Reasoning", "categories": ["cs.MM", "cs.AI", "cs.CV"], "comment": null, "summary": "Explainable Multimodal Emotion Recognition plays a crucial role in applications such as human-computer interaction and social media analytics. However, current approaches struggle with cue-level perception and reasoning due to two main challenges: 1) general-purpose modality encoders are pretrained to capture global structures and general semantics rather than fine-grained emotional cues, resulting in limited sensitivity to emotional signals; and 2) available datasets usually involve a trade-off between annotation quality and scale, which leads to insufficient supervision for emotional cues and ultimately limits cue-level reasoning. Moreover, existing evaluation metrics are inadequate for assessing cue-level reasoning performance. To address these challenges, we propose eXplainable Emotion GPT (XEmoGPT), a novel EMER framework capable of both perceiving and reasoning over emotional cues. It incorporates two specialized modules: the Video Emotional Cue Bridge (VECB) and the Audio Emotional Cue Bridge (AECB), which enhance the video and audio encoders through carefully designed tasks for fine-grained emotional cue perception. To further support cue-level reasoning, we construct a large-scale dataset, EmoCue, designed to teach XEmoGPT how to reason over multimodal emotional cues. In addition, we introduce EmoCue-360, an automated metric that extracts and matches emotional cues using semantic similarity, and release EmoCue-Eval, a benchmark of 400 expert-annotated samples covering diverse emotional scenarios. Experimental results show that XEmoGPT achieves strong performance in both emotional cue perception and reasoning.", "AI": {"tldr": "本文提出了一种可解释的多模态情感识别框架XEmoGPT，该框架能够感知和推理情绪线索。", "motivation": "当前的情感识别方法在感知和推理情绪线索方面存在挑战，包括预训练模型对细粒度情绪信号敏感性不足及数据集标注质量与规模之间的权衡。此外，现有评估指标不适用于衡量线索级推理性能。", "method": "本文提出了XEmoGPT框架，包含视频情感线索桥（VECB）和音频情感线索桥（AECB），用于增强视频和音频编码器以感知情绪线索，并构建了大规模数据集EmoCue来支持线索级别推理。此外还引入了一个自动评估指标EmoCue-360。", "result": "实验结果表明，XEmoGPT在情感线索感知与推理方面表现出色。", "conclusion": "XEmoGPT成功解决了现有框架在多模态情感识别中的局限性，并通过增强的线索级感知和推理提升了性能。"}}
{"id": "2602.05495", "pdf": "https://arxiv.org/pdf/2602.05495", "abs": "https://arxiv.org/abs/2602.05495", "authors": ["Chenhang Cui", "Binyun Yang", "Fei Shen", "Yuxin Chen", "Jingnan Zheng", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Transport and Merge: Cross-Architecture Merging for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) achieve strong capabilities by scaling model capacity and training data, yet many real-world deployments rely on smaller models trained or adapted from low-resource data. This gap motivates the need for mechanisms to transfer knowledge from large, high-resource models to smaller, low-resource targets. While model merging provides an effective transfer mechanism, most existing approaches assume architecture-compatible models and therefore cannot directly transfer knowledge from large high-resource LLMs to heterogeneous low-resource targets. In this work, we propose a cross-architecture merging framework based on optimal transport (OT) that aligns activations to infer cross-neuron correspondences between heterogeneous models. The resulting transport plans are then used to guide direct weight-space fusion, enabling effective high-resource to low-resource transfer using only a small set of inputs. Extensive experiments across low-resource languages and specialized domains demonstrate consistent improvements over target models.", "AI": {"tldr": "提出了一种基于最优传输的跨架构合并框架，用于从大型高资源语言模型向小型低资源目标模型转移知识。", "motivation": "为了解决大型语言模型与实际部署中使用的小型模型之间的能力差距问题，需要机制将大型、高资源模型的知识转移到小型、低资源的目标模型上。现有的大多数方法假设架构兼容的模型，因此无法直接从大型高资源LLM向异构低资源目标进行知识转移。", "method": "基于最优传输（OT）提出了一种跨架构合并框架，该框架通过激活对齐来推断不同神经元之间的对应关系，并利用所得传输计划引导直接权重空间融合。", "result": "在低资源语言和专业领域进行了广泛的实验，显示与目标模型相比存在一致的改进。", "conclusion": "所提出的基于最优传输的跨架构合并框架能够有效地将大型高资源LLM的知识转移到小型低资源目标模型上。"}}
{"id": "2602.05494", "pdf": "https://arxiv.org/pdf/2602.05494", "abs": "https://arxiv.org/abs/2602.05494", "authors": ["Qingyuan Wu", "Yuhui Wang", "Simon Sinong Zhan", "Yanning Dai", "Shilong Deng", "Sarra Habchi", "Qi Zhu", "Matthias Gallé", "Chao Huang"], "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verified Reward (RLVR) has emerged as a critical paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). Most existing RLVR methods, such as GRPO and its variants, ensure stable updates by constraining policy divergence through clipping likelihood ratios. This paper introduces a unified clipping framework that characterizes existing methods via a general notion of policy divergence, encompassing both likelihood ratios and Kullback-Leibler (KL) divergences and extending to alternative measures. The framework provides a principled foundation for systematically analyzing how different policy divergence measures affect exploration and performance. We further identify the KL3 estimator, a variance-reduced Monte Carlo estimator of the KL divergence, as a key policy divergence constraint. We theoretically demonstrate that the KL3-based constraint is mathematically equivalent to an asymmetric ratio-based clipping that reallocates probability mass toward high-confidence actions, promoting stronger exploration while retaining the simplicity of GRPO-style methods. Empirical results on mathematical reasoning benchmarks demonstrate that incorporating the KL3 estimator into GRPO improves both training stability and final performance, highlighting the importance of principled policy divergence constraints in policy optimization.", "AI": {"tldr": "本文提出了一种统一的剪裁框架，用于重新思考GRPO中的策略分歧度量，并通过KL3估计器改进了训练稳定性和最终性能。", "motivation": "现有的RLVR方法依赖于通过限制似然比来保证稳定的更新。然而，不同的策略分歧度量可能会影响探索和性能表现。", "method": "本文引入了一个统一的剪裁框架，该框架涵盖了似然比率和KL散度等策略分歧度量，并将它们归纳为一种通用的概念。此外，文中还提出了KL3估计器作为重要的政策差异约束条件。", "result": "实验结果表明，在数学推理基准上应用了KL3估计器的GRPO方法提高了训练稳定性和最终性能。", "conclusion": "基于策略分歧度量的原则性约束在策略优化中具有重要意义，尤其是当结合KL3估算器时，可以进一步提高模型的表现。"}}
{"id": "2602.05493", "pdf": "https://arxiv.org/pdf/2602.05493", "abs": "https://arxiv.org/abs/2602.05493", "authors": ["Bingru Li"], "title": "LinguistAgent: A Reflective Multi-Model Platform for Automated Linguistic Annotation", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "Data annotation remains a significant bottleneck in the Humanities and Social Sciences, particularly for complex semantic tasks such as metaphor identification. While Large Language Models (LLMs) show promise, a significant gap remains between the theoretical capability of LLMs and their practical utility for researchers. This paper introduces LinguistAgent, an integrated, user-friendly platform that leverages a reflective multi-model architecture to automate linguistic annotation. The system implements a dual-agent workflow, comprising an Annotator and a Reviewer, to simulate a professional peer-review process. LinguistAgent supports comparative experiments across three paradigms: Prompt Engineering (Zero/Few-shot), Retrieval-Augmented Generation, and Fine-tuning. We demonstrate LinguistAgent's efficacy using the task of metaphor identification as an example, providing real-time token-level evaluation (Precision, Recall, and $F_1$ score) against human gold standards. The application and codes are released on https://github.com/Bingru-Li/LinguistAgent.", "AI": {"tldr": "介绍了一种名为LinguistAgent的平台，用于自动化的语言标注。", "motivation": "数据注释在人文学科和社会科学中仍然是一个瓶颈，特别是在复杂的语义任务如隐喻识别方面。尽管大型语言模型显示出潜力，但其理论能力与实际研究应用之间仍存在差距。", "method": "LinguistAgent采用反射式多模型架构，并实施一种双代理工作流，包括注释器和审查员，模拟专业同行评审过程。平台支持跨三个范式的比较实验：提示工程（零/少样本），检索增强生成，以及微调。", "result": "通过隐喻识别任务展示了LinguistAgent的有效性，提供了实时的标记级评估（精确度、召回率和F1分数）与人类金标准进行对比。", "conclusion": "LinguistAgent提供了一种集成且易于使用的平台，能够自动化语言标注，并为复杂的语义任务如隐喻识别提供了有力支持。"}}
{"id": "2602.05487", "pdf": "https://arxiv.org/pdf/2602.05487", "abs": "https://arxiv.org/abs/2602.05487", "authors": ["Julien Moreau", "S. Ambellouis", "Yassine Ruichek"], "title": "Feature points evaluation on omnidirectional vision with a photorealistic fisheye sequence -- A report on experiments done in 2014", "categories": ["cs.CV"], "comment": null, "summary": "What is this report: This is a scientific report, contributing with a detailed bibliography, a dataset which we will call now PFSeq for ''Photorealistic Fisheye Sequence'' and make available at https://doi.org/10. 57745/DYIVVU, and comprehensive experiments. This work should be considered as a draft, and has been done during my PhD thesis ''Construction of 3D models from fisheye video data-Application to the localisation in urban area'' in 2014 [Mor16]. These results have never been published. The aim was to find the best features detector and descriptor for fisheye images, in the context of selfcalibration, with cameras mounted on the top of a car and aiming at the zenith (to proceed then fisheye visual odometry and stereovision in urban scenes). We face a chicken and egg problem, because we can not take advantage of an accurate projection model for an optimal features detection and description, and we rightly need good features to perform the calibration (i.e. to compute the accurate projection model of the camera). What is not this report: It does not contribute with new features algorithm. It does not compare standard features algorithms to algorithms designed for omnidirectional images (unfortunately). It has not been peer-reviewed. Discussions have been translated and enhanced but the experiments have not been run again and the report has not been updated accordingly to the evolution of the state-of-the-art (read this as a 2014 report).", "AI": {"tldr": "评估全景视觉中的特征点", "motivation": "在车载顶置摄像头的全向视角下，寻找最佳的特征检测和描述方法以支持自我校准、鱼眼视觉里程计及立体视觉应用", "method": "使用PFSeq数据集进行详尽实验，未设计新算法仅比较标准特征算法", "result": "结果用于2014年博士论文，并未公开发表或更新至最新研究状态", "conclusion": "确定了适用于全向图像的最佳特征点检测和描述方法"}}
{"id": "2602.05486", "pdf": "https://arxiv.org/pdf/2602.05486", "abs": "https://arxiv.org/abs/2602.05486", "authors": ["Matteo Esposito", "Lodovica Marchesi", "Roberto Tonelli", "Valentina Lenarduzzi"], "title": "Sovereign-by-Design A Reference Architecture for AI and Blockchain Enabled Systems", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.DC"], "comment": null, "summary": "Digital sovereignty has emerged as a central concern for modern software-intensive systems, driven by the dominance of non-sovereign cloud infrastructures, the rapid adoption of Generative AI, and increasingly stringent regulatory requirements. While existing initiatives address governance, compliance, and security in isolation, they provide limited guidance on how sovereignty can be operationalized at the architectural level. In this paper, we argue that sovereignty must be treated as a first-class architectural property rather than a purely regulatory objective. We introduce a Sovereign Reference Architecture that integrates self-sovereign identity, blockchain-based trust and auditability, sovereign data governance, and Generative AI deployed under explicit architectural control. The architecture explicitly captures the dual role of Generative AI as both a source of governance risk and an enabler of compliance, accountability, and continuous assurance when properly constrained. By framing sovereignty as an architectural quality attribute, our work bridges regulatory intent and concrete system design, offering a coherent foundation for building auditable, evolvable, and jurisdiction-aware AI-enabled systems. The proposed reference architecture provides a principled starting point for future research and practice at the intersection of software architecture, Generative AI, and digital sovereignty.", "AI": {"tldr": "提出了一个结合自主权身份、区块链信任和可审计性、主权数据治理以及在明确架构控制下的生成式AI的主权参考架构。", "motivation": "为了应对现代软件密集型系统中的数字主权问题，由于非主权云基础设施主导地位、生成式AI快速采纳及日益严格的监管要求而产生的挑战，提出了一种将主权作为首要建筑属性的方法论。", "method": "引入了一个主权参考架构，该架构结合了自主权身份、区块链信任和可审计性、主权数据治理以及在明确的架构控制下的生成式AI，并且将生成式AI的角色定义为既是一个治理风险源也是一个合规性和问责性的使能者。", "result": "提供了一个构建可审计的、演化的、符合司法管辖权要求的人工智能系统的原则起点，同时也为未来的研究和实践奠定了基础。", "conclusion": "通过将主权视为建筑属性而非仅仅是监管目标，该论文桥接了监管意图与具体的系统设计，在软件架构、生成式AI和数字主权交叉领域提供了连贯的基础。"}}
{"id": "2602.05480", "pdf": "https://arxiv.org/pdf/2602.05480", "abs": "https://arxiv.org/abs/2602.05480", "authors": ["Peihao Wu", "Yongxiang Yao", "Yi Wan", "Wenfei Zhang", "Ruipeng Zhao", "Jiayuan Li", "Yongjun Zhang"], "title": "SOMA-1M: A Large-Scale SAR-Optical Multi-resolution Alignment Dataset for Multi-Task Remote Sensing", "categories": ["cs.CV"], "comment": null, "summary": "Synthetic Aperture Radar (SAR) and optical imagery provide complementary strengths that constitute the critical foundation for transcending single-modality constraints and facilitating cross-modal collaborative processing and intelligent interpretation. However, existing benchmark datasets often suffer from limitations such as single spatial resolution, insufficient data scale, and low alignment accuracy, making them inadequate for supporting the training and generalization of multi-scale foundation models. To address these challenges, we introduce SOMA-1M (SAR-Optical Multi-resolution Alignment), a pixel-level precisely aligned dataset containing over 1.3 million pairs of georeferenced images with a specification of 512 x 512 pixels. This dataset integrates imagery from Sentinel-1, PIESAT-1, Capella Space, and Google Earth, achieving global multi-scale coverage from 0.5 m to 10 m. It encompasses 12 typical land cover categories, effectively ensuring scene diversity and complexity. To address multimodal projection deformation and massive data registration, we designed a rigorous coarse-to-fine image matching framework ensuring pixel-level alignment. Based on this dataset, we established comprehensive evaluation benchmarks for four hierarchical vision tasks, including image matching, image fusion, SAR-assisted cloud removal, and cross-modal translation, involving over 30 mainstream algorithms. Experimental results demonstrate that supervised training on SOMA-1M significantly enhances performance across all tasks. Notably, multimodal remote sensing image (MRSI) matching performance achieves current state-of-the-art (SOTA) levels. SOMA-1M serves as a foundational resource for robust multimodal algorithms and remote sensing foundation models. The dataset will be released publicly at: https://github.com/PeihaoWu/SOMA-1M.", "AI": {"tldr": "SOMA-1M是一个用于多任务遥感的大规模SAR-光学多分辨率对准数据集。", "motivation": "现有基准数据集存在单一空间分辨率、数据量不足和低对齐精度的问题，限制了跨模态协作处理和智能解释。为了克服这些挑战，本文提出了一个全球多尺度覆盖的大型数据集。", "method": "设计了一种粗到细图像匹配框架，实现了像素级精准对准。", "result": "实验结果表明，在SOMA-1M上进行监督训练可显著提升跨所有任务的表现。特别是多模态遥感图像匹配性能达到了当前最先进水平。", "conclusion": "SOMA-1M数据集作为稳健的多模态算法和遥感基础模型的基础资源，为跨模态协作处理提供了支持。"}}
{"id": "2602.05479", "pdf": "https://arxiv.org/pdf/2602.05479", "abs": "https://arxiv.org/abs/2602.05479", "authors": ["Zhe Wang", "Zijing Liu", "Chencheng Xu", "Yuan Yao"], "title": "Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interactions Prediction", "categories": ["cs.AI"], "comment": "Accepted to BIBM 2025. 6 pages, 5 figures", "summary": "Drug discovery remains time-consuming, labor-intensive, and expensive, often requiring years and substantial investment per drug candidate. Predicting compound-protein interactions (CPIs) is a critical component in this process, enabling the identification of molecular interactions between drug candidates and target proteins. Recent deep learning methods have successfully modeled CPIs at the atomic level, achieving improved efficiency and accuracy over traditional energy-based approaches. However, these models do not always align with chemical realities, as molecular fragments (motifs or functional groups) typically serve as the primary units of biological recognition and binding. In this paper, we propose Phi-former, a pairwise hierarchical interaction representation learning method that addresses this gap by incorporating the biological role of motifs in CPIs. Phi-former represents compounds and proteins hierarchically and employs a pairwise pre-training framework to model interactions systematically across atom-atom, motif-motif, and atom-motif levels, reflecting how biological systems recognize molecular partners. We design intra-level and inter-level learning pipelines that make different interaction levels mutually beneficial. Experimental results demonstrate that Phi-former achieves superior performance on CPI-related tasks. A case study shows that our method accurately identifies specific atoms or motifs activated in CPIs, providing interpretable model explanations. These insights may guide rational drug design and support precision medicine applications.", "AI": {"tldr": "Phi-former是一种用于预测化合物与蛋白质相互作用的深度学习方法，通过层次化交互表示和成对预训练框架提高了预测精度。", "motivation": "当前深度学习模型虽然在原子层面建模化合物-蛋白质相互作用（CPI）上有所进步，但未能充分考虑化学现实中的基团或功能区域的作用。因此提出Phi-former来弥补这一不足。", "method": "Phi-former通过层次化表示和成对预训练框架在原子-原子、基团-基团及原子-基团水平系统地建模相互作用，并设计了不同层级之间的学习管道，以确保各交互级别互惠互利。", "result": "实验结果表明Phi-former在CPI相关任务中表现出优越的性能。案例研究表明该方法能够准确识别特定参与CPI中的原子或基团。", "conclusion": "通过引入分子片段（如基团）作为生物识别和结合的主要单元，Phi-former不仅提高了预测精度，还为理性药物设计和精准医学应用提供了可解释性模型说明。"}}
{"id": "2602.05476", "pdf": "https://arxiv.org/pdf/2602.05476", "abs": "https://arxiv.org/abs/2602.05476", "authors": ["Ameet Gadekar"], "title": "Tight FPT Approximations for Fair $k$-center with Outliers", "categories": ["cs.DS"], "comment": "22 pages, 2 figures", "summary": "The $k$-center problem is a fundamental clustering objective that has been extensively studied in approximation algorithms. Recent work has sought to incorporate modern constraints such as fairness and robustness, motivated by biased and noisy data. In this paper, we study fair $k$-center with outliers, where centers must respect group-based representation constraints while up to $z$ points may be discarded. While a bi-criteria FPT approximation was previously known, no true approximation algorithm was available for this problem. We present the first deterministic $3$-approximation algorithm running in fixed-parameter tractable time parameterized by $k$. Our approach departs from projection-based methods and instead directly constructs a fair solution using a novel iterative ball-finding framework, based on a structural trichotomy that enables fixed-parameter approximation for the problem. We further extend our algorithm to fair $k$-supplier with outliers and to the more general fair-range setting with both lower and upper bounds. Finally, we show that improving the approximation factor below $3$ is $\\mathrm{W[2]}$-hard, establishing the optimality of our results.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.05474", "pdf": "https://arxiv.org/pdf/2602.05474", "abs": "https://arxiv.org/abs/2602.05474", "authors": ["Yicheng Di", "Zhanjie Zhang", "Yun Wangc", "Jinren Liue", "Jiaqi Yanf", "Jiyu Wei", "Xiangyu Chend", "Yuan Liu"], "title": "LMMRec: LLM-driven Motivation-aware Multimodal Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": ":14J60 (Primary) 14F05; 14J26 (Secondary)", "summary": "Motivation-based recommendation systems uncover user behavior drivers. Motivation modeling, crucial for decision-making and content preference, explains recommendation generation. Existing methods often treat motivation as latent variables from interaction data, neglecting heterogeneous information like review text. In multimodal motivation fusion, two challenges arise: 1) achieving stable cross-modal alignment amid noise, and 2) identifying features reflecting the same underlying motivation across modalities. To address these, we propose LLM-driven Motivation-aware Multimodal Recommendation (LMMRec), a model-agnostic framework leveraging large language models for deep semantic priors and motivation understanding. LMMRec uses chain-of-thought prompting to extract fine-grained user and item motivations from text. A dual-encoder architecture models textual and interaction-based motivations for cross-modal alignment, while Motivation Coordination Strategy and Interaction-Text Correspondence Method mitigate noise and semantic drift through contrastive learning and momentum updates. Experiments on three datasets show LMMRec achieves up to a 4.98\\% performance improvement.", "AI": {"tldr": "LMMRec是一种利用大型语言模型提取用户和项目动机的多模态推荐框架，旨在解决跨模式对齐中的噪声问题。", "motivation": "现有的方法往往忽略异构信息如评论文本，仅通过交互数据处理动机。这导致难以实现稳定的跨模态对齐及识别同一动机在不同模态下的特征表示。", "method": "LMMRec使用链式思考提示从文本中提取细粒度的用户和项目动机，并采用双编码器架构来建模基于文本和互动的动机，通过对比学习和动量更新解决噪声和语义漂移问题。", "result": "实验表明，与基线模型相比，LMMRec在三个数据集上取得了最高4.98％的性能改进。", "conclusion": "LMMRec证明了利用大型语言模型进行动机理解的有效性，并提供了一种解决跨模态对齐挑战的新方法。"}}
{"id": "2602.05472", "pdf": "https://arxiv.org/pdf/2602.05472", "abs": "https://arxiv.org/abs/2602.05472", "authors": ["Yiwen Duan", "Jing Ye", "Xinpei Zhao"], "title": "ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \\textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \\textbf{costly} to scale, \\textbf{brittle} across domains, and \\textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \\textbf{ALIVE} (\\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \\emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.", "AI": {"tldr": "介绍了一种名为ALIVE的方法，旨在通过对抗学习和指导性口头评估来提升大型语言模型的内在推理能力。", "motivation": "传统强化学习依赖于标量奖励信号，这种信号难以扩展、易受领域影响且无法洞察解决方案背后的逻辑。这阻碍了模型对推理原则的深入理解。为此，研究团队引入了一种新的框架ALIVE，以克服这些限制并提升模型的内在推理能力。", "method": "通过对抗学习和指导性口头反馈来实现问题提出、解决与评判的一体化政策模式，使模型能够直接从原始语料中内化评估标准。这种方法有效地将外部批评转化为内生性的推理机能。", "result": "在数学推理、代码生成和一般逻辑推断基准测试中的实验结果表明，ALIVE能够有效缓解奖励信号的限制问题，并实现显著的数据和计算资源利用效率提升。同时，在跨领域泛化能力和自我校正率上也取得了明显的进步。", "conclusion": "研究团队认为，这种推理三元结构促进了能力增长的自持续轨迹，将ALIVE定位为无需人工干预监督的一般用途推理对齐的基础框架。"}}
{"id": "2602.05468", "pdf": "https://arxiv.org/pdf/2602.05468", "abs": "https://arxiv.org/abs/2602.05468", "authors": ["Pranav Ponnivalavan", "Satoshi Funabashi", "Alexander Schmitz", "Tetsuya Ogata", "Shigeki Sugano"], "title": "TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation", "categories": ["cs.RO"], "comment": "8 pages, 8 figures, 8 tables, ICRA2026 accepted", "summary": "Humans can achieve diverse in-hand manipulations, such as object pinching and tool use, which often involve simultaneous contact between the object and multiple fingers. This is still an open issue for robotic hands because such dexterous manipulation requires distinguishing between tactile sensations generated by their self-contact and those arising from external contact. Otherwise, object/robot breakage happens due to contacts/collisions. Indeed, most approaches ignore self-contact altogether, by constraining motion to avoid/ignore self-tactile information during contact. While this reduces complexity, it also limits generalization to real-world scenarios where self-contact is inevitable. Humans overcome this challenge through self-touch perception, using predictive mechanisms that anticipate the tactile consequences of their own motion, through a principle called sensory attenuation, where the nervous system differentiates predictable self-touch signals, allowing novel object stimuli to stand out as relevant. Deriving from this, we introduce TaSA, a two-phased deep predictive learning framework. In the first phase, TaSA explicitly learns self-touch dynamics, modeling how a robot's own actions generate tactile feedback. In the second phase, this learned model is incorporated into the motion learning phase, to emphasize object contact signals during manipulation. We evaluate TaSA on a set of insertion tasks, which demand fine tactile discrimination: inserting a pencil lead into a mechanical pencil, inserting coins into a slot, and fixing a paper clip onto a sheet of paper, with various orientations, positions, and sizes. Across all tasks, policies trained with TaSA achieve significantly higher success rates than baseline methods, demonstrating that structured tactile perception with self-touch based on sensory attenuation is critical for dexterous robotic manipulation.", "AI": {"tldr": "本文提出了TaSA框架，通过两阶段深度预测学习模型来解决机器人手在抓取操作中自我接触产生的触觉信号问题。", "motivation": "人类能够实现多样化的握持操纵，但目前的机器人技术无法有效处理同时接触多个手指的情况。为了解决这一挑战，本文引入了基于感官减弱机制的TaSA框架。", "method": "第一阶段学习机器人的自我动作产生的触觉反馈模型；第二阶段将该模型应用于运动学习中，强调物体接触信号以提高抓取精度和成功率。", "result": "在插入任务上进行测试时，使用TaSA训练出的策略比基线方法获得了更高的成功几率，证明了结构化触觉感知对于机器人灵巧操纵至关重要。", "conclusion": "通过两阶段深度预测学习模型，本文解决了一种新颖的方法来增强机器人的抓取操作精度和成功率。"}}
{"id": "2602.05467", "pdf": "https://arxiv.org/pdf/2602.05467", "abs": "https://arxiv.org/abs/2602.05467", "authors": ["Dekang Qi", "Shuang Zeng", "Xinyuan Chang", "Feng Xiong", "Shichao Xie", "Xiaolong Wu", "Mu Xu"], "title": "MerNav: A Highly Generalizable Memory-Execute-Review Framework for Zero-Shot Object Goal Navigation", "categories": ["cs.CV", "cs.CL", "cs.RO"], "comment": "9 pages, 2 figures, 5 tables, conference", "summary": "Visual Language Navigation (VLN) is one of the fundamental capabilities for embodied intelligence and a critical challenge that urgently needs to be addressed. However, existing methods are still unsatisfactory in terms of both success rate (SR) and generalization: Supervised Fine-Tuning (SFT) approaches typically achieve higher SR, while Training-Free (TF) approaches often generalize better, but it is difficult to obtain both simultaneously. To this end, we propose a Memory-Execute-Review framework. It consists of three parts: a hierarchical memory module for providing information support, an execute module for routine decision-making and actions, and a review module for handling abnormal situations and correcting behavior. We validated the effectiveness of this framework on the Object Goal Navigation task. Across 4 datasets, our average SR achieved absolute improvements of 7% and 5% compared to all baseline methods under TF and Zero-Shot (ZS) settings, respectively. On the most commonly used HM3D_v0.1 and the more challenging open vocabulary dataset HM3D_OVON, the SR improved by 8% and 6%, under ZS settings. Furthermore, on the MP3D and HM3D_OVON datasets, our method not only outperformed all TF methods but also surpassed all SFT methods, achieving comprehensive leadership in both SR (5% and 2%) and generalization.", "AI": {"tldr": "论文提出了一种新的Memory-Execute-Review框架，用于零样本目标导航任务。", "motivation": "现有方法在成功率和泛化能力上难以同时满足要求。为解决此问题，提出了一个新的框架来提升性能。", "method": "该框架包含三个模块：一个层次记忆模块、执行模块以及审查模块，分别负责信息支持、常规决策与行动及异常情况处理。", "result": "在四个数据集上的成功率相对基准方法提高了7%和5%，并在HM3D_v0.1和HM3D_OVON数据集上取得了8%和6%的提升。该方法在MP3D和HM3D_OVON数据集中的表现超过所有其他方法。", "conclusion": "所提出的Memory-Execute-Review框架显著提升了零样本目标导航任务的成功率与泛化能力，体现了其优越性。"}}
{"id": "2602.05466", "pdf": "https://arxiv.org/pdf/2602.05466", "abs": "https://arxiv.org/abs/2602.05466", "authors": ["Iván Olarte Rodríguez", "Gokhan Serhat", "Mariusz Bujny", "Fabian Duddeck", "Thomas Bäck", "Elena Raponi"], "title": "Optimization is Not Enough: Why Problem Formulation Deserves Equal Attention", "categories": ["cs.NE", "cs.CE"], "comment": "25 pages, 11 figures, 4 table, submitted at Conference on Evolutionary Computation, Theory and Applications (ECTA) 2025", "summary": "Black-box optimization is increasingly used in engineering design problems where simulation-based evaluations are costly and gradients are unavailable. In this context, the optimization community has largely analyzed algorithm performance in context-free setups, while not enough attention has been devoted to how problem formulation and domain knowledge may affect the optimization outcomes. We address this gap through a case study in the topology optimization of laminated composite structures, formulated as a black-box optimization problem. Specifically, we consider the design of a cantilever beam under a volume constraint, intending to minimize compliance while optimizing both the structural topology and fiber orientations. To assess the impact of problem formulation, we explicitly separate topology and material design variables and compare two strategies: a concurrent approach that optimizes all variables simultaneously without leveraging physical insight, and a sequential approach that optimizes variables of the same nature in stages. Our results show that context-agnostic strategies consistently lead to suboptimal or non-physical designs. In contrast, the sequential strategy yields better-performing and more interpretable solutions. These findings underscore the value of incorporating, when available, domain knowledge into the optimization process and motivate the development of new black-box benchmarks that reward physically informed and context-aware optimization strategies.", "AI": {"tldr": "论文通过案例研究展示了在层压复合结构的拓扑优化中，问题的设定如何影响黑盒优化的结果。", "motivation": "传统上，工程设计中的黑盒优化主要关注算法性能，在缺乏物理洞察力的情况下进行评估。然而，这种做法忽略了问题形式化和领域知识对优化结果的影响。", "method": "论文通过一种悬臂梁在体积约束下的设计案例研究，对比了同时优化所有变量的策略与分阶段优化相同性质变量（先拓扑后材料）的策略，并比较了这两种方法的结果。", "result": "结果显示，不考虑物理背景的方法往往导致次优或非物理的设计方案。而采用逐步策略则能够生成性能更好、更具解释性的解决方案。", "conclusion": "研究表明将领域知识融入优化过程中的重要性，并提出了开发奖励基于物理理解和上下文感知的黑盒基准的需求"}}
{"id": "2602.05464", "pdf": "https://arxiv.org/pdf/2602.05464", "abs": "https://arxiv.org/abs/2602.05464", "authors": ["Jiaquan Wang", "Yan Lyu", "Chen Li", "Yuheng Jia"], "title": "Refine and Purify: Orthogonal Basis Optimization with Null-Space Denoising for Conditional Representation Learning", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Conditional representation learning aims to extract criterion-specific features for customized tasks. Recent studies project universal features onto the conditional feature subspace spanned by an LLM-generated text basis to obtain conditional representations. However, such methods face two key limitations: sensitivity to subspace basis and vulnerability to inter-subspace interference. To address these challenges, we propose OD-CRL, a novel framework integrating Adaptive Orthogonal Basis Optimization (AOBO) and Null-Space Denoising Projection (NSDP). Specifically, AOBO constructs orthogonal semantic bases via singular value decomposition with a curvature-based truncation. NSDP suppresses non-target semantic interference by projecting embeddings onto the null space of irrelevant subspaces. Extensive experiments conducted across customized clustering, customized classification, and customized retrieval tasks demonstrate that OD-CRL achieves a new state-of-the-art performance with superior generalization.", "AI": {"tldr": "本文提出了一种新的框架OD-CRL，用于优化条件表示学习中的正交基并抑制非目标语义干扰。", "motivation": "现有的方法在提取特定特征时面临两个关键限制：对子空间基础的敏感性和跨子空间干扰的脆弱性。为解决这些问题，提出了新的解决方案。", "method": "OD-CRL框架结合了自适应正交基优化（AOBO）和零空间去噪投影（NSDP），通过奇异值分解构建正交语义基础，并抑制非目标语义干扰。", "result": "实验结果显示，在定制聚类、分类和检索任务上，OD-CRL达到了新的SOTA性能表现并且具有更好的泛化能力。", "conclusion": "本文提出的方法有效解决了条件表示学习中的敏感性和干扰问题，为未来的相关研究提供了一种新思路。"}}
{"id": "2602.05463", "pdf": "https://arxiv.org/pdf/2602.05463", "abs": "https://arxiv.org/abs/2602.05463", "authors": ["Koichi Takahashi", "Yusuke Hayashi"], "title": "Thermodynamic Limits of Physical Intelligence", "categories": ["cs.LG", "cs.AI", "cs.IT"], "comment": null, "summary": "Modern AI systems achieve remarkable capabilities at the cost of substantial energy consumption. To connect intelligence to physical efficiency, we propose two complementary bits-per-joule metrics under explicit accounting conventions: (1) Thermodynamic Epiplexity per Joule -- bits of structural information about a theoretical environment-instance variable newly encoded in an agent's internal state per unit measured energy within a stated boundary -- and (2) Empowerment per Joule -- the embodied sensorimotor channel capacity (control information) per expected energetic cost over a fixed horizon. These provide two axes of physical intelligence: recognition (model-building) vs.control (action influence). Drawing on stochastic thermodynamics, we show how a Landauer-scale closed-cycle benchmark for epiplexity acquisition follows as a corollary of a standard thermodynamic-learning inequality under explicit subsystem assumptions, and we clarify how Landauer-scaled costs act as closed-cycle benchmarks under explicit reset/reuse and boundary-closure assumptions; conversely, we give a simple decoupling construction showing that without such assumptions -- and without charging for externally prepared low-entropy resources (e.g.fresh memory) crossing the boundary -- information gain and in-boundary dissipation need not be tightly linked. For empirical settings where the latent structure variable is unavailable, we align the operational notion of epiplexity with compute-bounded MDL epiplexity and recommend reporting MDL-epiplexity / compression-gain surrogates as companions. Finally, we propose a unified efficiency framework that reports both metrics together with a minimal checklist of boundary/energy accounting, coarse-graining/noise, horizon/reset, and cost conventions to reduce ambiguity and support consistent bits-per-joule comparisons, and we sketch connections to energy-adjusted scaling analyses.", "AI": {"tldr": "该论文提出了两种基于能量的智能度量标准：每焦耳的热力学信息熵和每焦耳的赋能，以连接智能与物理效率。", "motivation": "现代AI系统在能耗方面消耗巨大，本文旨在通过引入新的度量标准来解决这一问题，并将智能与物理效率联系起来。", "method": "论文提出了两种基于能量的信息度量：热力学信息熵每焦耳和赋能每焦勒。这些度量标准适用于识别（模型构建）和控制（行动影响）。同时，使用Landauer定律进行闭环基准测试，并提出一个统一的效率框架来报告这两种度量。", "result": "论文提供了两种新的智能度量标准，并通过热力学学习不等式推导了闭循环基准。此外，还提出了能量调整比例分析并建议在无法获得潜在结构变量的情况下使用MDL-赋能作为替代。", "conclusion": "本文提供了一套完整的物理智能效率度量框架，旨在减少模糊性并支持一致的能量调整比较，以促进AI系统的可持续发展。"}}
{"id": "2602.05456", "pdf": "https://arxiv.org/pdf/2602.05456", "abs": "https://arxiv.org/abs/2602.05456", "authors": ["Maksym Figat", "Ryan M. Mackey", "Michel D. Ingham"], "title": "Ontology-Driven Robotic Specification Synthesis", "categories": ["cs.RO", "cs.AI", "eess.SY"], "comment": "8 pages, 9 figures, 3 tables, journal", "summary": "This paper addresses robotic system engineering for safety- and mission-critical applications by bridging the gap between high-level objectives and formal, executable specifications. The proposed method, Robotic System Task to Model Transformation Methodology (RSTM2) is an ontology-driven, hierarchical approach using stochastic timed Petri nets with resources, enabling Monte Carlo simulations at mission, system, and subsystem levels. A hypothetical case study demonstrates how the RSTM2 method supports architectural trades, resource allocation, and performance analysis under uncertainty. Ontological concepts further enable explainable AI-based assistants, facilitating fully autonomous specification synthesis. The methodology offers particular benefits to complex multi-robot systems, such as the NASA CADRE mission, representing decentralized, resource-aware, and adaptive autonomous systems of the future.", "AI": {"tldr": "该论文提出了一种基于本体的机器人系统任务到模型转换方法RSTM2，用于将高级目标转化为正式可执行规范。", "motivation": "为了解决安全和关键任务应用中的机器人系统工程问题，并缩小高层目标与形式化、可执行规格之间的差距。", "method": "使用层次化的基于本体的方法，利用带有资源的随机时序Petri网进行Monte Carlo仿真。", "result": "展示了RSTM2方法如何支持架构权衡分析、资源配置和不确定性条件下的性能分析。", "conclusion": "该方法特别适合于复杂的多机器人系统，并能提供解释性人工智能辅助，促进完全自主规范合成。"}}
{"id": "2602.05454", "pdf": "https://arxiv.org/pdf/2602.05454", "abs": "https://arxiv.org/abs/2602.05454", "authors": ["Yue Lu", "Xiangyu Zhou", "Shizhou Zhang", "Yinghui Xing", "Guoqiang Liang", "Wencong Zhang"], "title": "Attention Retention for Continual Learning with Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "AAAI-2026 Camera Ready", "summary": "Continual learning (CL) empowers AI systems to progressively acquire knowledge from non-stationary data streams. However, catastrophic forgetting remains a critical challenge. In this work, we identify attention drift in Vision Transformers as a primary source of catastrophic forgetting, where the attention to previously learned visual concepts shifts significantly after learning new tasks. Inspired by neuroscientific insights into the selective attention in the human visual system, we propose a novel attention-retaining framework to mitigate forgetting in CL. Our method constrains attention drift by explicitly modifying gradients during backpropagation through a two-step process: 1) extracting attention maps of the previous task using a layer-wise rollout mechanism and generating instance-adaptive binary masks, and 2) when learning a new task, applying these masks to zero out gradients associated with previous attention regions, thereby preventing disruption of learned visual concepts. For compatibility with modern optimizers, the gradient masking process is further enhanced by scaling parameter updates proportionally to maintain their relative magnitudes. Experiments and visualizations demonstrate the effectiveness of our method in mitigating catastrophic forgetting and preserving visual concepts. It achieves state-of-the-art performance and exhibits robust generalizability across diverse CL scenarios.", "AI": {"tldr": "提出了一种新的注意力保留框架，旨在通过视觉变换器解决持续学习中的灾难性遗忘问题。", "motivation": "持续学习中出现的灾难性遗忘是由于视觉变换器在学习新任务时对先前学习到的概念的注意漂移导致的。为了减轻这种现象，作者受到神经科学关于人类视觉系统选择性注意机制的启发，提出了注意力保留框架。", "method": "通过两步过程来限制注意漂移：首先使用逐层展开机制提取前一任务的注意力图，并生成实例自适应二值掩码；其次在学习新任务时应用这些掩码以消除与先前注意区域相关的梯度更新，从而防止已学视觉概念受到破坏。为了兼容现代优化器，通过按比例缩放参数更新来增强梯度屏蔽过程。", "result": "实验和可视化证明了该方法在缓解灾难性遗忘和保留视觉概念方面的有效性，并且它实现了最先进的性能，在各种持续学习场景中表现出良好的泛化能力。", "conclusion": "本文提出了一种新的注意力保持框架，通过控制注意漂移来减轻连续学习中的灾难性遗忘问题。实验结果表明，该方法在减少遗忘、保护先前学到的视觉概念以及跨不同持续学习情景下的性能方面均表现出了优势。"}}
{"id": "2602.05453", "pdf": "https://arxiv.org/pdf/2602.05453", "abs": "https://arxiv.org/abs/2602.05453", "authors": ["Budhaditya Mukhopadhyay", "Chirag Mandal", "Pavan Tummala", "Naghmeh Mahmoodian", "Andreas Nürnberger", "Soumick Chatterjee"], "title": "Towards Segmenting the Invisible: An End-to-End Registration and Segmentation Framework for Weakly Supervised Tumour Analysis", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph"], "comment": "Accepted for AIBio at ECAI 2025", "summary": "Liver tumour ablation presents a significant clinical challenge: whilst tumours are clearly visible on pre-operative MRI, they are often effectively invisible on intra-operative CT due to minimal contrast between pathological and healthy tissue. This work investigates the feasibility of cross-modality weak supervision for scenarios where pathology is visible in one modality (MRI) but absent in another (CT). We present a hybrid registration-segmentation framework that combines MSCGUNet for inter-modal image registration with a UNet-based segmentation module, enabling registration-assisted pseudo-label generation for CT images. Our evaluation on the CHAOS dataset demonstrates that the pipeline can successfully register and segment healthy liver anatomy, achieving a Dice score of 0.72. However, when applied to clinical data containing tumours, performance degrades substantially (Dice score of 0.16), revealing the fundamental limitations of current registration methods when the target pathology lacks corresponding visual features in the target modality. We analyse the \"domain gap\" and \"feature absence\" problems, demonstrating that whilst spatial propagation of labels via registration is feasible for visible structures, segmenting truly invisible pathology remains an open challenge. Our findings highlight that registration-based label transfer cannot compensate for the absence of discriminative features in the target modality, providing important insights for future research in cross-modality medical image analysis. Code an weights are available at: https://github.com/BudhaTronix/Weakly-Supervised-Tumour-Detection", "AI": {"tldr": "提出一种结合MSCGUNet和UNet的框架，用于跨模态图像配准与分割，旨在解决术前MRI可见而术中CT不可见肿瘤的问题", "motivation": "临床挑战在于肝脏肿瘤在术前MRI上清晰可见但在术中CT上几乎看不见。希望通过弱监督方法利用一种模式中的病理信息来指导另一种模式中的分割任务", "method": "开发了一种结合图像配准与分割的框架，使用MSCGUNet进行跨模态配准，并通过配准生成伪标签用于CT图像的分割", "result": "在CHAOS数据集上实现良好的肝脏解剖结构注册和分割（Dice分数为0.72），但在包含肿瘤的实际临床数据上的性能显著下降（Dice分数为0.16）", "conclusion": "当前的注册方法难以处理目标病理学缺乏相应视觉特征的情况，强调了跨模态医学图像分析中的挑战"}}
{"id": "2602.05449", "pdf": "https://arxiv.org/pdf/2602.05449", "abs": "https://arxiv.org/abs/2602.05449", "authors": ["Chang Zou", "Changlin Li", "Yang Li", "Patrol Li", "Jianbing Wu", "Xiao He", "Songtao Liu", "Zhao Zhong", "Kailin Huang", "Linfeng Zhang"], "title": "DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 7 figures; cvpr2026 submission", "summary": "While diffusion models have achieved great success in the field of video generation, this progress is accompanied by a rapidly escalating computational burden. Among the existing acceleration methods, Feature Caching is popular due to its training-free property and considerable speedup performance, but it inevitably faces semantic and detail drop with further compression. Another widely adopted method, training-aware step-distillation, though successful in image generation, also faces drastic degradation in video generation with a few steps. Furthermore, the quality loss becomes more severe when simply applying training-free feature caching to the step-distilled models, due to the sparser sampling steps. This paper novelly introduces a distillation-compatible learnable feature caching mechanism for the first time. We employ a lightweight learnable neural predictor instead of traditional training-free heuristics for diffusion models, enabling a more accurate capture of the high-dimensional feature evolution process. Furthermore, we explore the challenges of highly compressed distillation on large-scale video models and propose a conservative Restricted MeanFlow approach to achieve more stable and lossless distillation. By undertaking these initiatives, we further push the acceleration boundaries to $11.8\\times$ while preserving generation quality. Extensive experiments demonstrate the effectiveness of our method. The code is in the supplementary materials and will be publicly available.", "AI": {"tldr": "介绍了一种新的可训练特征缓存机制，用于加速视频扩散模型的生成。", "motivation": "现有加速方法存在语义和细节损失的问题，尤其是在进一步压缩时。此外，在应用无训练特征缓存到步骤精简模型中时，质量问题更加严重。", "method": "提出了一种新的可训练特征缓存机制，并引入了一个轻量级的神经预测器来捕捉高维特征演化过程，同时采用了保守的MeanFlow方法以实现更稳定的无损精简。", "result": "通过这些改进措施，加速比达到了11.8倍，同时保持了生成质量。实验结果证明了该方法的有效性。", "conclusion": "所提出的方法为视频扩散模型提供了有效的加速方式，实现了更高的速度和更好的生成效果。"}}
{"id": "2602.05447", "pdf": "https://arxiv.org/pdf/2602.05447", "abs": "https://arxiv.org/abs/2602.05447", "authors": ["Damon McMillan"], "title": "Structured Context Engineering for File-Native Agentic Systems: Evaluating Schema Accuracy, Format Effectiveness, and Multi-File Navigation at Scale", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 7 figures, 10 tables, 26 references", "summary": "Large Language Model agents increasingly operate external systems through programmatic interfaces, yet practitioners lack empirical guidance on how to structure the context these agents consume. Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas ranging from 10 to 10,000 tables. Our findings challenge common assumptions. First, architecture choice is model-dependent: file-based context retrieval improves accuracy for frontier-tier models (Claude, GPT, Gemini; +2.7%, p=0.029) but shows mixed results for open source models (aggregate -7.7%, p<0.001), with deficits varying substantially by model. Second, format does not significantly affect aggregate accuracy (chi-squared=2.45, p=0.484), though individual models, particularly open source, exhibit format-specific sensitivities. Third, model capability is the dominant factor, with a 21 percentage point accuracy gap between frontier and open source tiers that dwarfs any format or architecture effect. Fourth, file-native agents scale to 10,000 tables through domain-partitioned schemas while maintaining high navigation accuracy. Fifth, file size does not predict runtime efficiency: compact formats can consume significantly more tokens at scale due to format-unfamiliar search patterns. These findings provide practitioners with evidence-based guidance for deploying LLM agents on structured systems, demonstrating that architectural decisions should be tailored to model capability rather than assuming universal best practices.", "AI": {"tldr": "本文通过系统性研究探讨了大型语言模型代理在处理结构化数据时的上下文工程，包括9649个实验。", "motivation": "为了解决实践中缺乏关于如何组织大型语言模型消费上下文的经验指导问题，研究人员使用SQL生成作为程序操作代理的替代方案进行了研究。", "method": "通过对比四种格式（YAML、Markdown、JSON和TOON）以及不同数量的数据表，对11种模型进行9649个实验。实验结果揭示了架构选择依赖于模型类型，文件本体结构化代理在数据规模上能够保持高导航准确性。", "result": "发现表明架构选择取决于模型类型；格式不显著影响总体准确性；模型能力是决定因素；基于域分区模式的文件本体代理可扩展至10,000个表格且仍能保持高导航准确性。此外，文件大小并非运行效率预测指标。", "conclusion": "研究提供了部署LLM代理于结构化系统中的实证指导，表明架构决策应根据模型能力定制而非遵循通用最佳实践。"}}
{"id": "2602.05446", "pdf": "https://arxiv.org/pdf/2602.05446", "abs": "https://arxiv.org/abs/2602.05446", "authors": ["Rui Sheng", "Yukun Yang", "Chuhan Shi", "Yanna Lin", "Zixin Chen", "Huamin Qu", "Furui Cheng"], "title": "DiLLS: Interactive Diagnosis of LLM-based Multi-agent Systems via Layered Summary of Agent Behaviors", "categories": ["cs.HC"], "comment": null, "summary": "Large language model (LLM)-based multi-agent systems have demonstrated impressive capabilities in handling complex tasks. However, the complexity of agentic behaviors makes these systems difficult to understand. When failures occur, developers often struggle to identify root causes and to determine actionable paths for improvement. Traditional methods that rely on inspecting raw log records are inefficient, given both the large volume and complexity of data. To address this challenge, we propose a framework and an interactive system, DiLLS, designed to reveal and structure the behaviors of multi-agent systems. The key idea is to organize information across three levels of query completion: activities, actions, and operations. By probing the multi-agent system through natural language, DiLLS derives and organizes information about planning and execution into a structured, multi-layered summary. Through a user study, we show that DiLLS significantly improves developers' effectiveness and efficiency in identifying, diagnosing, and understanding failures in LLM-based multi-agent systems.", "AI": {"tldr": "DiLLS 是一个用于诊断基于大型语言模型的多代理系统交互式框架，通过分层总结代理行为来提高故障识别和理解的有效性和效率。", "motivation": "基于大型语言模型的多代理系统具有处理复杂任务的能力，但其复杂的代理行为使其难以理解和调试。传统依赖于检查原始日志记录的方法在大量且复杂的数据面前变得低效，因此需要一种更有效的诊断工具。", "method": "DiLLS 提出了一种通过自然语言查询来提取和组织多代理系统规划和执行信息的框架，并将其结构化为分层总结的形式。此方法包括三个层次：活动、行为和操作。", "result": "用户研究显示，DiLLS 显著提高了开发人员在识别、诊断和理解基于大型语言模型的多代理系统故障方面的有效性和效率。", "conclusion": "通过提供一种交互式框架 DiLLS 来解决复杂多代理系统的调试挑战，该工具能够显著提升开发者的工作效率，并改善他们对失败情况的理解。"}}
{"id": "2602.05443", "pdf": "https://arxiv.org/pdf/2602.05443", "abs": "https://arxiv.org/abs/2602.05443", "authors": ["Hien Ohnaka", "Yuma Shirahata", "Masaya Kawamura"], "title": "Wave-Trainer-Fit: Neural Vocoder with Trainable Prior and Fixed-Point Iteration towards High-Quality Speech Generation from SSL features", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by IEEE ICASSP 2026. 5 pages, 3 figures, and 2 tables", "summary": "We propose WaveTrainerFit, a neural vocoder that performs high-quality waveform generation from data-driven features such as SSL features. WaveTrainerFit builds upon the WaveFit vocoder, which integrates diffusion model and generative adversarial network. Furthermore, the proposed method incorporates the following key improvements: 1. By introducing trainable priors, the inference process starts from noise close to the target speech instead of Gaussian noise. 2. Reference-aware gain adjustment is performed by imposing constraints on the trainable prior to matching the speech energy. These improvements are expected to reduce the complexity of waveform modeling from data-driven features, enabling high-quality waveform generation with fewer inference steps. Through experiments, we showed that WaveTrainerFit can generate highly natural waveforms with improved speaker similarity from data-driven features, while requiring fewer iterations than WaveFit. Moreover, we showed that the proposed method works robustly with respect to the depth at which SSL features are extracted. Code and pre-trained models are available from https://github.com/line/WaveTrainerFit.", "AI": {"tldr": "提出了一种名为WaveTrainerFit的神经声码器，使用可训练先验和固定点迭代从SSL特征生成高质量语音波形。", "motivation": "旨在通过引入可训练先验来减少数据驱动特征的波形建模复杂性，并提高语音生成质量与效率。", "method": "WaveTrainerFit基于WaveFit声码器，结合了扩散模型和生成对抗网络。改进之处在于：1. 引入可训练先验使推理过程从接近目标语音的噪声开始；2. 通过调整参考相关的增益来匹配语音能量。", "result": "实验表明，WaveTrainerFit可以生成自然度高、说话者相似性更好的波形，并且比WaveFit需要更少的迭代次数。此外，在不同深度提取SSL特征时，该方法表现稳健。", "conclusion": "通过使用可训练先验和固定点迭代，WaveTrainerFit有效提高了从数据驱动特征生成高质量语音的能力，并在实验中证明了其优越性与鲁棒性。"}}
{"id": "2602.05441", "pdf": "https://arxiv.org/pdf/2602.05441", "abs": "https://arxiv.org/abs/2602.05441", "authors": ["Dean Fortier", "Timothy Adamson", "Tess Hellebrekers", "Teresa LaScala", "Kofi Ennin", "Michael Murray", "Andrey Kolobov", "Galen Mullins"], "title": "Benchmarking Affordance Generalization with BusyBox", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Vision-Language-Action (VLA) models have been attracting the attention of researchers and practitioners thanks to their promise of generalization. Although single-task policies still offer competitive performance, VLAs are increasingly able to handle commands and environments unseen in their training set. While generalization in vision and language space is undoubtedly important for robust versatile behaviors, a key meta-skill VLAs need to possess is affordance generalization -- the ability to manipulate new objects with familiar physical features. In this work, we present BusyBox, a physical benchmark for systematic semi-automatic evaluation of VLAs' affordance generalization. BusyBox consists of 6 modules with switches, sliders, wires, buttons, a display, and a dial. The modules can be swapped and rotated to create a multitude of BusyBox variations with different visual appearances but the same set of affordances. We empirically demonstrate that generalization across BusyBox variants is highly challenging even for strong open-weights VLAs such as $π_{0.5}$ and GR00T-N1.6. To encourage the research community to evaluate their own VLAs on BusyBox and to propose new affordance generalization experiments, we have designed BusyBox to be easy to build in most robotics labs. We release the full set of CAD files for 3D-printing its parts as well as a bill of materials for (optionally) assembling its electronics. We also publish a dataset of language-annotated demonstrations that we collected using the common bimanual Mobile Aloha robot on the canonical BusyBox configuration. All of the released materials are available at https://microsoft.github.io/BusyBox.", "AI": {"tldr": "提出了一种名为BusyBox的物理基准，用于评估Vision-Language-Action (VLA)模型在面对新物体时的操作能力。", "motivation": "为了测试和推动Vision-Language-Action模型在不同环境中的操作能力，特别是在遇到未见过的对象时的适应性和操作性。", "method": "设计了一套包含多个模块（如开关、滑块等）的物理基准，这些模块可以组合以形成多种不同的配置。通过收集机器人在这个基础上执行任务的数据，并公开数据集和构建指南来促进研究。", "result": "展示了即使是强大的VLA模型，在处理BusyBox的各种变化时也面临着挑战。", "conclusion": "强调了在Vision-Language-Action领域内，提高模型面对新对象时的操作能力和适应性的重要性。"}}
{"id": "2602.05440", "pdf": "https://arxiv.org/pdf/2602.05440", "abs": "https://arxiv.org/abs/2602.05440", "authors": ["Natascha Jeziorski", "Petra Gospodnetić", "Claudia Redenbach"], "title": "Synthetic Defect Geometries of Cast Metal Objects Modeled via 2d Voronoi Tessellations", "categories": ["cs.CV"], "comment": null, "summary": "In industry, defect detection is crucial for quality control. Non-destructive testing (NDT) methods are preferred as they do not influence the functionality of the object while inspecting. Automated data evaluation for automated defect detection is a growing field of research. In particular, machine learning approaches show promising results. To provide training data in sufficient amount and quality, synthetic data can be used. Rule-based approaches enable synthetic data generation in a controllable environment. Therefore, a digital twin of the inspected object including synthetic defects is needed. We present parametric methods to model 3d mesh objects of various defect types that can then be added to the object geometry to obtain synthetic defective objects. The models are motivated by common defects in metal casting but can be transferred to other machining procedures that produce similar defect shapes. Synthetic data resembling the real inspection data can then be created by using a physically based Monte Carlo simulation of the respective testing method. Using our defect models, a variable and arbitrarily large synthetic data set can be generated with the possibility to include rarely occurring defects in sufficient quantity. Pixel-perfect annotation can be created in parallel. As an example, we will use visual surface inspection, but the procedure can be applied in combination with simulations for any other NDT method.", "AI": {"tldr": "通过二维Voronoi镶嵌模型来生成铸造金属物件的合成缺陷几何形状，以用于非破坏性测试的数据训练。", "motivation": "在工业质量控制中，使用非破坏性测试方法进行缺陷检测至关重要。为了提供足够的高质量训练数据，研究采用机器学习的方法来进行自动化缺陷识别，并提出了一种基于规则的方法来生成可以模拟真实情况的合成数据。", "method": "通过参数化方法建模3D网格对象的各种类型的缺陷模型，并将其添加到物体几何形状中以获得包含人工缺陷的对象。这些模型可以与物理基础的蒙特卡洛仿真相结合，用于创建符合实际检测数据的合成数据集，并且可以精确注释生成的数据。", "result": "这种方法能够生成任意数量和多样化的合成数据集，包括很少发生的缺陷类型，同时确保每张图像都完美标注。", "conclusion": "该方法为非破坏性测试提供了大量的高质量训练数据，提高了自动化缺陷检测的能力。"}}
{"id": "2602.05435", "pdf": "https://arxiv.org/pdf/2602.05435", "abs": "https://arxiv.org/abs/2602.05435", "authors": ["Donglin Yang", "Yongxing Zhang", "Xin Yu", "Liang Hou", "Xin Tao", "Pengfei Wan", "Xiaojuan Qi", "Renjie Liao"], "title": "Stable Velocity: A Variance Perspective on Flow Matching", "categories": ["cs.CV"], "comment": null, "summary": "While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity, a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\\times$ faster sampling within the low-variance regime without degrading sample quality. Our code is available at https://github.com/linYDTHU/StableVelocity.", "AI": {"tldr": "本文提出了一种名为Stable Velocity的方法，通过减少条件速度中的方差来提高流匹配的训练效率和采样速度。", "motivation": "现有的流匹配方法由于依赖单样本条件速度导致优化目标高方差，这使得优化过程不稳定并减慢了收敛速度。作者希望解决这个问题以改善模型的性能。", "method": "本文提出了Stable Velocity框架，包括训练时使用的无偏方差减少目标Stable VM和自适应增强辅助监督的方法VA-REPA，以及用于推断的低方差区域简化方法Stable VS。", "result": "实验结果表明，在ImageNet $256\times256$ 和大型预训练模型上，该框架在不降低样本质量的情况下提高了至少两倍以上的采样速度，并且明显提升了训练效率。", "conclusion": "Stable Velocity通过减少条件速度中的方差有效解决了流匹配方法存在的问题，显著改善了模型的性能和运行效率。"}}
{"id": "2602.05434", "pdf": "https://arxiv.org/pdf/2602.05434", "abs": "https://arxiv.org/abs/2602.05434", "authors": ["Sanghoon Jeon", "Gihyun Jung", "Suhyeon Ka", "Jae-Sang Hyun"], "title": "LD-SLRO: Latent Diffusion Structured Light for 3-D Reconstruction of Highly Reflective Objects", "categories": ["cs.CV"], "comment": "10 pages, 7 figures", "summary": "Fringe projection profilometry-based 3-D reconstruction of objects with high reflectivity and low surface roughness remains a significant challenge. When measuring such glossy surfaces, specular reflection and indirect illumination often lead to severe distortion or loss of the projected fringe patterns. To address these issues, we propose a latent diffusion-based structured light for reflective objects (LD-SLRO). Phase-shifted fringe images captured from highly reflective surfaces are first encoded to extract latent representations that capture surface reflectance characteristics. These latent features are then used as conditional inputs to a latent diffusion model, which probabilistically suppresses reflection-induced artifacts and recover lost fringe information, yielding high-quality fringe images. The proposed components, including the specular reflection encoder, time-variant channel affine layer, and attention modules, further improve fringe restoration quality. In addition, LD-SLRO provides high flexibility in configuring the input and output fringe sets. Experimental results demonstrate that the proposed method improves both fringe quality and 3-D reconstruction accuracy over state-of-the-art methods, reducing the average root-mean-squared error from 1.8176 mm to 0.9619 mm.", "AI": {"tldr": "本文提出了一种基于潜扩散的结构光方法（LD-SLRO），用于重建高反光和低表面粗糙度物体的三维形状。", "motivation": "传统的条纹投影轮廓法在测量具有高反射率和平滑表面的物体时，会因镜面反射和间接照明导致严重的条纹畸变或丢失，影响3D重建精度。为此，本文提出一种新的方法来解决这些问题。", "method": "利用相移技术捕捉高反光表面上的条纹图像，并将其编码以提取反映表面特性的潜在表示。然后将这些潜在特征作为条件输入到潜扩散模型中，该模型可以概率性地抑制反射引起的伪影并恢复丢失的条纹信息，从而生成高质量的条纹图像。", "result": "实验结果显示，所提出的方法在改善条纹质量和提高3D重建精度方面优于现有方法，将平均均方根误差从1.8176毫米减少到0.9619毫米。", "conclusion": "本文提出的LD-SLRO技术通过潜扩散模型和特定设计的网络结构成功解决了高反光物体三维重建中的问题，并且具有较高的灵活性。"}}
{"id": "2602.05430", "pdf": "https://arxiv.org/pdf/2602.05430", "abs": "https://arxiv.org/abs/2602.05430", "authors": ["Kritchanat Ponyuenyong", "Pengyu Tu", "Jia Wei Tan", "Wei Soon Cheong", "Jamie Ng Suat Ling", "Lianlian Jiang"], "title": "Day-Ahead Electricity Price Forecasting for Volatile Markets Using Foundation Models with Regularization Strategy", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to AI4TS Workshop @ AAAI'26 (Oral and Poster), see https://ai4ts.github.io/aaai2026", "summary": "Electricity price forecasting (EPF) is essential for energy markets stakeholders (e.g. grid operators, energy traders, policymakers) but remains challenging due to the inherent volatility and nonlinearity of price signals. Traditional statistical and deep learning (DL) models often struggle to capture complex temporal dependencies and integrate heterogeneous data effectively. While time series foundation models (TSFMs) have shown strong performance in general time series forecasting tasks, such as traffic forecasting and weather forecasting. However, their effectiveness in day-ahead EPF, particularly in volatile markets, remains underexplored. This paper presents a spike regularization strategy and evaluates a wide range of TSFMs, including Tiny Time Mixers (TTMs), MOIRAI, MOMENT, and TimesFM, against traditional statistical and DL models such as Autoregressive Integrated Moving Average (ARIMA), Long-short Term Memory (LSTM), and Convolutional Neural Network - LSTM (CNN-LSTM) using half-hourly wholesale market data with volatile trends in Singapore. Exogenous factors (e.g. weather and calendar variables) are also incorporated into models where applicable. Results demonstrate that TSFMs consistently outperform traditional approaches, achieving up to 37.4% improvement in MAPE across various evaluation settings. The findings offer practical guidance for improving forecast accuracy and decision-making in volatile electricity markets.", "AI": {"tldr": "本文通过引入一种尖峰正则化策略并评估多种时间序列基础模型，以提高电力市场中日预测的准确性。", "motivation": "传统的统计和深度学习方法在处理波动性高、非线性强的价格信号时效果不佳，而时间序列基础模型在这类任务中的应用仍需探索。", "method": "本文采用尖峰正则化策略，并通过新加坡批发市场的历史数据对比评估了多种TSFMs（如TTM, MOIRAI等）与传统方法（ARIMA、LSTM和CNN-LSTM）。同时，模型考虑纳入气象和其他外生因素进行预测。", "result": "实验结果显示，TSFMs在各种评估设置下比传统的统计和深度学习模型表现更佳，平均绝对百分比误差（MAPE）提高了最多37.4%。", "conclusion": "本文的研究为提高波动性电力市场的预测精度提供了实用指导。"}}
{"id": "2602.05429", "pdf": "https://arxiv.org/pdf/2602.05429", "abs": "https://arxiv.org/abs/2602.05429", "authors": ["Rui Lv", "Juncheng Mo", "Tianyi Chu", "Chen Rao", "Hongyi Jing", "Jiajie Teng", "Jiafu Chen", "Shiqi Zhang", "Liangzi Ding", "Shuo Fang", "Huaizhong Lin", "Ziqiang Dang", "Chenguang Ma", "Lei Zhao"], "title": "M$^2$-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining", "categories": ["cs.AI", "cs.CV"], "comment": "Accepted by ICLR 2026. Supplementary material is included at the end of the main paper (16 pages, 15 figures, 2 tables)", "summary": "Graphical User Interface (GUI) agent is pivotal to advancing intelligent human-computer interaction paradigms. Constructing powerful GUI agents necessitates the large-scale annotation of high-quality user-behavior trajectory data (i.e., intent-trajectory pairs) for training. However, manual annotation methods and current GUI agent data mining approaches typically face three critical challenges: high construction cost, poor data quality, and low data richness. To address these issues, we propose M$^2$-Miner, the first low-cost and automated mobile GUI agent data-mining framework based on Monte Carlo Tree Search (MCTS). For better data mining efficiency and quality, we present a collaborative multi-agent framework, comprising InferAgent, OrchestraAgent, and JudgeAgent for guidance, acceleration, and evaluation. To further enhance the efficiency of mining and enrich intent diversity, we design an intent recycling strategy to extract extra valuable interaction trajectories. Additionally, a progressive model-in-the-loop training strategy is introduced to improve the success rate of data mining. Extensive experiments have demonstrated that the GUI agent fine-tuned using our mined data achieves state-of-the-art performance on several commonly used mobile GUI benchmarks. Our work will be released to facilitate the community research.", "AI": {"tldr": "提出了一种基于蒙特卡洛树搜索（MCTS）的低成本自动化移动GUI代理数据挖掘框架M$^2$-Miner。", "motivation": "为了解决手动注释方法和现有GUI代理数据挖掘方法在高构建成本、低质量数据和缺乏丰富度方面的关键挑战，本文提出了一个自动化的解决方案来提升效率并降低费用。", "method": "设计了基于MCTS的协作多智能体框架，包括指导、加速和评估三个角色：InferAgent, OrchestraAgent 和 JudgeAgent。此外，还引入了一种意图回收策略和渐进模型在环训练策略以进一步提高数据挖掘的成功率和丰富度。", "result": "实验结果表明，使用本文提出的M$^2$-Miner框架挖掘的数据进行微调的GUI代理在多个常用移动GUI基准测试中达到了最先进的性能表现。", "conclusion": "所提出的方法有效地解决了现有GUI代理数据挖掘的问题，并为社区的研究提供了便利。"}}
{"id": "2602.05426", "pdf": "https://arxiv.org/pdf/2602.05426", "abs": "https://arxiv.org/abs/2602.05426", "authors": ["Wahyu Rahmaniar", "Kenji Suzuki"], "title": "Multi-AD: Cross-Domain Unsupervised Anomaly Detection for Medical and Industrial Applications", "categories": ["cs.CV"], "comment": "28 pages, 8 figures", "summary": "Traditional deep learning models often lack annotated data, especially in cross-domain applications such as anomaly detection, which is critical for early disease diagnosis in medicine and defect detection in industry. To address this challenge, we propose Multi-AD, a convolutional neural network (CNN) model for robust unsupervised anomaly detection across medical and industrial images. Our approach employs the squeeze-and-excitation (SE) block to enhance feature extraction via channel-wise attention, enabling the model to focus on the most relevant features and detect subtle anomalies. Knowledge distillation (KD) transfers informative features from the teacher to the student model, enabling effective learning of the differences between normal and anomalous data. Then, the discriminator network further enhances the model's capacity to distinguish between normal and anomalous data. At the inference stage, by integrating multi-scale features, the student model can detect anomalies of varying sizes. The teacher-student (T-S) architecture ensures consistent representation of high-dimensional features while adapting them to enhance anomaly detection. Multi-AD was evaluated on several medical datasets, including brain MRI, liver CT, and retina OCT, as well as industrial datasets, such as MVTec AD, demonstrating strong generalization across multiple domains. Experimental results demonstrated that our approach consistently outperformed state-of-the-art models, achieving the best average AUROC for both image-level (81.4% for medical and 99.6% for industrial) and pixel-level (97.0% for medical and 98.4% for industrial) tasks, making it effective for real-world applications.", "AI": {"tldr": "提出了一种跨领域的无监督异常检测模型Multi-AD，用于医学和工业图像的早期诊断。", "motivation": "传统深度学习模型在缺乏标注数据的情况下难以执行有效的异常检测任务，尤其是在医疗和工业应用中。为了应对这一挑战，研究者开发了新的方法来提高不同领域中的异常检测性能。", "method": "使用带有挤压-激发块的卷积神经网络(CNN)来增强特征提取；利用知识蒸馏技术将教师模型的信息传递给学生模型；采用判别器网络进一步提升区分正常和异常数据的能力。在推断阶段，整合多尺度特征使学生模型能够检测不同大小的异常。", "result": "实验表明，在多个医学和工业数据集上Multi-AD取得了最好的平均AUROC值（图像级别：81.4%医学，99.6%工业；像素级别：97.0%医学，98.4%工业），证明了其在实际应用中的有效性。", "conclusion": "提出的方法有效解决了跨领域无监督异常检测的问题，并且在多种数据集上验证了模型的优越性。"}}
{"id": "2602.05424", "pdf": "https://arxiv.org/pdf/2602.05424", "abs": "https://arxiv.org/abs/2602.05424", "authors": ["Weijian Yu", "Yuhuan Lu", "Dingqi Yang"], "title": "THOR: Inductive Link Prediction over Hyper-Relational Knowledge Graphs", "categories": ["cs.AI"], "comment": null, "summary": "Knowledge graphs (KGs) have become a key ingredient supporting a variety of applications. Beyond the traditional triplet representation of facts where a relation connects two entities, modern KGs observe an increasing number of hyper-relational facts, where an arbitrary number of qualifiers associated with a triplet provide auxiliary information to further describe the rich semantics of the triplet, which can effectively boost the reasoning performance in link prediction tasks. However, existing link prediction techniques over such hyper-relational KGs (HKGs) mostly focus on a transductive setting, where KG embedding models are learned from the specific vocabulary of a given KG and subsequently can only make predictions within the same vocabulary, limiting their generalizability to previously unseen vocabularies. Against this background, we propose THOR, an inducTive link prediction technique for Hyper-relational knOwledge gRaphs. Specifically, we first introduce both relation and entity foundation graphs, modeling their fundamental inter- and intra-fact interactions in HKGs, which are agnostic to any specific relations and entities. Afterward, THOR is designed to learn from the two foundation graphs with two parallel graph encoders followed by a transformer decoder, which supports efficient masked training and fully-inductive inference. We conduct a thorough evaluation of THOR in hyper-relational link prediction tasks on 12 datasets with different settings. Results show that THOR outperforms a sizable collection of baselines, yielding 66.1%, 55.9%, and 20.4% improvement over the best-performing rule-based, semi-inductive, and fully-inductive techniques, respectively. A series of ablation studies also reveals our key design factors capturing the structural invariance transferable across HKGs for inductive tasks.", "AI": {"tldr": "THOR是一种用于超关系知识图谱（HKG）的归纳链接预测技术。", "motivation": "现有的链接预测方法大多采用传递设置，限制了其在先前未见过的词汇表中的泛化能力。为此，作者提出了THOR来解决这一问题。", "method": "THOR通过引入关系和实体基础图建模HKG中基本的事实内部和事实间交互，并使用两个平行图编码器结合变压器解码器进行训练与推理。", "result": "在12个不同设置的数据集上，THOR的表现优于一系列基线方法，分别在规则、半归纳和全归纳技术方面提高了66.1%、55.9%和20.4%。", "conclusion": "结果表明THOR能有效捕捉HKG结构上的不变性，并适用于归纳任务。"}}
{"id": "2602.05423", "pdf": "https://arxiv.org/pdf/2602.05423", "abs": "https://arxiv.org/abs/2602.05423", "authors": ["Pengcheng Chen", "Yue Hu", "Wenhao Li", "Nicole M Gunderson", "Andrew Feng", "Zhenglong Sun", "Peter Beerel", "Eric J Seibel"], "title": "NeVStereo: A NeRF-Driven NVS-Stereo Architecture for High-Fidelity 3D Tasks", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "In modern dense 3D reconstruction, feed-forward systems (e.g., VGGT, pi3) focus on end-to-end matching and geometry prediction but do not explicitly output the novel view synthesis (NVS). Neural rendering-based approaches offer high-fidelity NVS and detailed geometry from posed images, yet they typically assume fixed camera poses and can be sensitive to pose errors. As a result, it remains non-trivial to obtain a single framework that can offer accurate poses, reliable depth, high-quality rendering, and accurate 3D surfaces from casually captured views. We present NeVStereo, a NeRF-driven NVS-stereo architecture that aims to jointly deliver camera poses, multi-view depth, novel view synthesis, and surface reconstruction from multi-view RGB-only inputs. NeVStereo combines NeRF-based NVS for stereo-friendly renderings, confidence-guided multi-view depth estimation, NeRF-coupled bundle adjustment for pose refinement, and an iterative refinement stage that updates both depth and the radiance field to improve geometric consistency. This design mitigated the common NeRF-based issues such as surface stacking, artifacts, and pose-depth coupling. Across indoor, outdoor, tabletop, and aerial benchmarks, our experiments indicate that NeVStereo achieves consistently strong zero-shot performance, with up to 36% lower depth error, 10.4% improved pose accuracy, 4.5% higher NVS fidelity, and state-of-the-art mesh quality (F1 91.93%, Chamfer 4.35 mm) compared to existing prestigious methods.", "AI": {"tldr": "介绍了一种名为NeVStereo的框架，用于从多视角RGB输入中实现准确的相机姿态估计、多视图深度估计、新颖视图合成和表面重建。", "motivation": "现有的密集三维重建方法要么专注于端到端匹配和几何预测而不显式输出新颖视图合成（NVS），要么使用基于神经渲染的方法提供高保真度NVS但通常假设固定相机姿态并可能对姿态误差敏感。因此，开发一个既能准确估计姿态、可靠深度估算又能进行高质量渲染和三维表面重建的单一框架具有挑战性。", "method": "提出了一种名为NeVStereo的架构，结合了基于神经辐射场（NeRF）的新颖视图合成以支持立体友好型渲染，通过置信度引导实现多视角深度估计，并利用与NeRF耦合的束调整技术进行姿态优化。该框架还包括迭代细化阶段来更新深度和光度场。", "result": "实验结果显示，相比于现有方法，NeVStereo在各种基准测试中表现出色，在深度误差、姿态精度、NVS保真度以及网格质量方面均优于其他方法。", "conclusion": "NeVStereo框架通过结合基于神经辐射场的新颖视图合成技术解决了传统三维重建中的多项挑战，实现了高精度的相机姿态估计、多视角深度估计和新颖视图合成。"}}
{"id": "2602.05420", "pdf": "https://arxiv.org/pdf/2602.05420", "abs": "https://arxiv.org/abs/2602.05420", "authors": ["Rui Sun", "Yiwen Yang", "Kaiyu Guo", "Chen Jiang", "Dongli Xu", "Zhaonan Liu", "Tan Pan", "Limei Han", "Xue Jiang", "Wu Wei", "Yuan Cheng"], "title": "Disco: Densely-overlapping Cell Instance Segmentation via Adjacency-aware Collaborative Coloring", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 10 figures; ICLR 2026", "summary": "Accurate cell instance segmentation is foundational for digital pathology analysis. Existing methods based on contour detection and distance mapping still face significant challenges in processing complex and dense cellular regions. Graph coloring-based methods provide a new paradigm for this task, yet the effectiveness of this paradigm in real-world scenarios with dense overlaps and complex topologies has not been verified. Addressing this issue, we release a large-scale dataset GBC-FS 2025, which contains highly complex and dense sub-cellular nuclear arrangements. We conduct the first systematic analysis of the chromatic properties of cell adjacency graphs across four diverse datasets and reveal an important discovery: most real-world cell graphs are non-bipartite, with a high prevalence of odd-length cycles (predominantly triangles). This makes simple 2-coloring theory insufficient for handling complex tissues, while higher-chromaticity models would cause representational redundancy and optimization difficulties. Building on this observation of complex real-world contexts, we propose Disco (Densely-overlapping Cell Instance Segmentation via Adjacency-aware COllaborative Coloring), an adjacency-aware framework based on the \"divide and conquer\" principle. It uniquely combines a data-driven topological labeling strategy with a constrained deep learning system to resolve complex adjacency conflicts. First, \"Explicit Marking\" strategy transforms the topological challenge into a learnable classification task by recursively decomposing the cell graph and isolating a \"conflict set.\" Second, \"Implicit Disambiguation\" mechanism resolves ambiguities in conflict regions by enforcing feature dissimilarity between different instances, enabling the model to learn separable feature representations.", "AI": {"tldr": "本文提出了一种基于邻接感知的密集细胞实例分割方法Disco，用于解决复杂和高密度细胞区域的分割问题。", "motivation": "现有基于轮廓检测和距离映射的方法在处理复杂且密集的细胞区域时仍存在挑战。而图着色方法虽提供新范式，但其在实际应用场景中的有效性尚未验证。", "method": "提出了Disco框架，结合数据驱动的拓扑标记策略与约束深度学习系统解决复杂的邻接冲突问题。", "result": "通过实验表明该方法在处理密集细胞区域时表现出色，并且能够有效地分割复杂和高密度的组织结构。", "conclusion": "本文提出的Disco方法可以有效应对复杂且高密度细胞区域的实例分割任务，具有实际应用价值。"}}
{"id": "2602.05416", "pdf": "https://arxiv.org/pdf/2602.05416", "abs": "https://arxiv.org/abs/2602.05416", "authors": ["Freja Høgholm Petersen", "Jesper Sandvig Mariegaard", "Rocco Palmitessa", "Allan P. Engsig-Karup"], "title": "Reduced-Order Surrogates for Forced Flexible Mesh Coastal-Ocean Models", "categories": ["cs.CE", "cs.AI", "cs.LG", "physics.ao-ph", "physics.flu-dyn"], "comment": "Submitted for peer-review in a journal", "summary": "While POD-based surrogates are widely explored for hydrodynamic applications, the use of Koopman Autoencoders for real-world coastal-ocean modelling remains relatively limited. This paper introduces a flexible Koopman autoencoder formulation that incorporates meteorological forcings and boundary conditions, and systematically compares its performance against POD-based surrogates. The Koopman autoencoder employs a learned linear temporal operator in latent space, enabling eigenvalue regularization to promote temporal stability. This strategy is evaluated alongside temporal unrolling techniques for achieving stable and accurate long-term predictions. The models are assessed on three test cases spanning distinct dynamical regimes, with prediction horizons up to one year at 30-minute temporal resolution. Across all cases, the Koopman autoencoder with temporal unrolling yields the best overall accuracy compared to the POD-based surrogates, achieving relative root-mean-squared-errors of 0.01-0.13 and $R^2$-values of 0.65-0.996. Prediction errors are largest for current velocities, and smallest for water surface elevations. Comparing to in-situ observations, the surrogate yields -0.65% to 12% change in water surface elevation prediction error when compared to prediction errors of the physics-based model. These error levels, corresponding to a few centimeters, are acceptable for many practical applications, while inference speed-ups of 300-1400x enables workflows such as ensemble forecasting and long climate simulations for coastal-ocean modelling.", "AI": {"tldr": "本文介绍了将Koopman自编码器应用于沿海海洋模型，并与基于POD的代理模型进行了系统比较。", "motivation": "虽然基于POD的代理广泛用于流体动力学应用中，但使用Koopman自编码器进行真实世界的沿海海洋建模相对较少。为此引入了一种灵活的Koopman自编码器形式以包括气象强迫和边界条件。", "method": "该方法通过在潜在空间中使用学习到的线性时间算子来构建Koopman自编码器，并应用特征值正则化以促进时间稳定性。还评估了时域展平技术以实现稳定且准确的长期预测。", "result": "所有测试案例的结果表明，具有时域展平功能的Koopman自编码器在与基于POD的代理相比时表现最佳，在相对均方根误差和R^2值方面达到0.65-0.996。预测误差最大的是流速，最小的是水位。", "conclusion": "尽管存在一些预测误差，但该模型能够实现可接受的精度水平（几厘米），并在300到1400倍的速度上加快推断速度，这为沿海海洋建模工作流程提供了可能性。"}}
{"id": "2602.05415", "pdf": "https://arxiv.org/pdf/2602.05415", "abs": "https://arxiv.org/abs/2602.05415", "authors": ["Ningkang Peng", "Qianfeng Yu", "Yuhao Zhang", "Yafei Liu", "Xiaoqian Peng", "Peirong Ma", "Yi Chen", "Peiheng Li", "Yanhui Gu"], "title": "VMF-GOS: Geometry-guided virtual Outlier Synthesis for Long-Tailed OOD Detection", "categories": ["cs.CV"], "comment": null, "summary": "Out-of-Distribution (OOD) detection under long-tailed distributions is a highly challenging task because the scarcity of samples in tail classes leads to blurred decision boundaries in the feature space. Current state-of-the-art (sota) methods typically employ Outlier Exposure (OE) strategies, relying on large-scale real external datasets (such as 80 Million Tiny Images) to regularize the feature space. However, this dependence on external data often becomes infeasible in practical deployment due to high data acquisition costs and privacy sensitivity. To this end, we propose a novel data-free framework aimed at completely eliminating reliance on external datasets while maintaining superior detection performance. We introduce a Geometry-guided virtual Outlier Synthesis (GOS) strategy that models statistical properties using the von Mises-Fisher (vMF) distribution on a hypersphere. Specifically, we locate a low-likelihood annulus in the feature space and perform directional sampling of virtual outliers in this region. Simultaneously, we introduce a new Dual-Granularity Semantic Loss (DGS) that utilizes contrastive learning to maximize the distinction between in-distribution (ID) features and these synthesized boundary outliers. Extensive experiments on benchmarks such as CIFAR-LT demonstrate that our method outperforms sota approaches that utilize external real images.", "AI": {"tldr": "提出了一种几何引导的虚拟异常合成方法，用于长尾分布下的OOD检测。", "motivation": "当前最先进的方法依赖于外部数据集来提高OOD检测性能，但在实际部署中面临高成本和隐私问题。因此，该论文旨在消除对外部数据集的依赖，并保持优越的检测效果。", "method": "提出了Geometry-guided虚拟Outlier Synthesis (GOS)策略，利用von Mises-Fisher分布在超球面上合成异常样本；同时引入Dual-Granularity Semantic Loss (DGS)，通过对比学习最大化ID特征和合成边界异常之间的区别。", "result": "实验结果表明，该方法在CIFAR-LT等基准数据集上优于使用外部真实图像的最先进的方法。", "conclusion": "所提出的方法能够在不依赖任何外部数据的情况下实现更优的OOD检测性能。"}}
{"id": "2602.05414", "pdf": "https://arxiv.org/pdf/2602.05414", "abs": "https://arxiv.org/abs/2602.05414", "authors": ["Ngoc Doan-Minh Huynh", "Duong Nguyen-Ngoc Tran", "Long Hoang Pham", "Tai Huu-Phuong Tran", "Hyung-Joon Jeon", "Huy-Hung Nguyen", "Duong Khac Vu", "Hyung-Min Jeon", "Son Hong Phan", "Quoc Pham-Nam Ho", "Chi Dai Tran", "Trinh Le Ba Khanh", "Jae Wook Jeon"], "title": "TSBOW: Traffic Surveillance Benchmark for Occluded Vehicles Under Various Weather Conditions", "categories": ["cs.CV"], "comment": "This paper has been accepted by the 40th AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Global warming has intensified the frequency and severity of extreme weather events, which degrade CCTV signal and video quality while disrupting traffic flow, thereby increasing traffic accident rates. Existing datasets, often limited to light haze, rain, and snow, fail to capture extreme weather conditions. To address this gap, this study introduces the Traffic Surveillance Benchmark for Occluded vehicles under various Weather conditions (TSBOW), a comprehensive dataset designed to enhance occluded vehicle detection across diverse annual weather scenarios. Comprising over 32 hours of real-world traffic data from densely populated urban areas, TSBOW includes more than 48,000 manually annotated and 3.2 million semi-labeled frames; bounding boxes spanning eight traffic participant classes from large vehicles to micromobility devices and pedestrians. We establish an object detection benchmark for TSBOW, highlighting challenges posed by occlusions and adverse weather. With its varied road types, scales, and viewpoints, TSBOW serves as a critical resource for advancing Intelligent Transportation Systems. Our findings underscore the potential of CCTV-based traffic monitoring, pave the way for new research and applications. The TSBOW dataset is publicly available at: https://github.com/SKKUAutoLab/TSBOW.", "AI": {"tldr": "构建一个涵盖各种天气条件下的交通监控数据集TSBOW，以提高遮挡车辆检测的准确性。", "motivation": "全球变暖导致极端天气事件频发，影响CCTV信号和视频质量，增加交通事故率。现有数据集中仅包含轻度雾霾、雨雪等天气，无法充分应对各种极端条件。", "method": "收集超过32小时的城市交通录像，涵盖八类交通参与者（如大型车辆、微移动设备及行人），手动标注48000多个和半自动标注320万帧。TSBOW数据集可用于评估不同天气与遮挡条件下目标检测的挑战。", "result": "TSBOW包含多种道路类型、尺度和视角，成为智能交通系统研究的重要资源。", "conclusion": "通过CCTV监控实现高效且成本效益高的交通管理具有巨大潜力。TSBOW数据集为新研究与应用开辟了道路，并已公开发布。"}}
{"id": "2602.05407", "pdf": "https://arxiv.org/pdf/2602.05407", "abs": "https://arxiv.org/abs/2602.05407", "authors": ["Jun-Min Lee", "Meong Hi Son", "Edward Choi"], "title": "H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Hospital administration departments handle a wide range of operational tasks and, in large hospitals, process over 10,000 requests per day, driving growing interest in LLM-based automation. However, prior work has focused primarily on patient--physician interactions or isolated administrative subtasks, failing to capture the complexity of real administrative workflows. To address this gap, we propose H-AdminSim, a comprehensive end-to-end simulation framework that combines realistic data generation with multi-agent-based simulation of hospital administrative workflows. These tasks are quantitatively evaluated using detailed rubrics, enabling systematic comparison of LLMs. Through FHIR integration, H-AdminSim provides a unified and interoperable environment for testing administrative workflows across heterogeneous hospital settings, serving as a standardized testbed for assessing the feasibility and performance of LLM-driven administrative automation.", "AI": {"tldr": "提出H-AdminSim，一个结合现实数据生成与多代理仿真医院行政工作流程的全面端到端模拟框架", "motivation": "先前研究主要集中在患者-医生互动或孤立的行政子任务上，未能捕捉真实的行政工作流复杂性。需要一种综合性解决方案来评估大型语言模型（LLM）在处理真实医院行政工作流程中的可行性与表现", "method": "H-AdminSim结合现实数据生成和多代理仿真技术，并通过FHIR集成提供统一且互操作的测试环境", "result": "该框架使研究人员能够系统地比较不同LLM的效果，为评估基于LLM的自动化提供了标准化测试床", "conclusion": "提出的H-AdminSim解决了现有研究未能覆盖的实际医院行政工作流程复杂性问题，成为了一个有价值的工具"}}
{"id": "2602.05406", "pdf": "https://arxiv.org/pdf/2602.05406", "abs": "https://arxiv.org/abs/2602.05406", "authors": ["Isaac Wiafe", "Akon Obu Ekpezu", "Sumaya Ahmed Salihs", "Elikem Doe Atsakpo", "Fiifi Baffoe Payin Winful", "Jamal-Deen Abdulai"], "title": "Enabling Automatic Disordered Speech Recognition: An Impaired Speech Dataset in the Akan Language", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "The lack of impaired speech data hinders advancements in the development of inclusive speech technologies, particularly in low-resource languages such as Akan. To address this gap, this study presents a curated corpus of speech samples from native Akan speakers with speech impairment. The dataset comprises of 50.01 hours of audio recordings cutting across four classes of impaired speech namely stammering, cerebral palsy, cleft palate, and stroke induced speech disorder. Recordings were done in controlled supervised environments were participants described pre-selected images in their own words. The resulting dataset is a collection of audio recordings, transcriptions, and associated metadata on speaker demographics, class of impairment, recording environment and device. The dataset is intended to support research in low-resource automatic disordered speech recognition systems and assistive speech technology.", "AI": {"tldr": "构建了一个包含四种语言障碍类型的50小时以上阿坎语语音数据集，以促进低资源环境下的自动失常语音识别研究。", "motivation": "缺乏受损语音的数据阻碍了包容性语音技术的发展，特别是在阿坎等低资源语言中。为了弥补这一差距，这项研究创建了一个专门的受试者语音样本集合。", "method": "从患有口吃、脑瘫、唇裂和中风引起的言语障碍的本地阿坎语母语者那里收集了50.01小时的录音。", "result": "该数据集包括音频记录，转录和与说话人人口统计信息，损伤类型，录制环境和设备相关的元数据。它旨在支持研究开发低资源自动失常语音识别系统和辅助语音技术。", "conclusion": "通过提供一个精心策划的阿坎语受损语音数据集，该研究有助于推动包含性和无障碍的语音科技发展，特别是对于那些在低资源语言中面临挑战的研究者而言。"}}
{"id": "2602.05403", "pdf": "https://arxiv.org/pdf/2602.05403", "abs": "https://arxiv.org/abs/2602.05403", "authors": ["Chenghua Gong", "Yihang Jiang", "Hao Li", "Rui Sun", "Juyuan Zhang", "Tianjun Gu", "Liming Pan", "Linyuan Lü"], "title": "Advancing Opinion Dynamics Modeling with Neural Diffusion-Convection-Reaction Equation", "categories": ["cs.AI", "cs.CY", "cs.SI"], "comment": null, "summary": "Advanced opinion dynamics modeling is vital for deciphering social behavior, emphasizing its role in mitigating polarization and securing cyberspace. To synergize mechanistic interpretability with data-driven flexibility, recent studies have explored the integration of Physics-Informed Neural Networks (PINNs) for opinion modeling. Despite this promise, existing methods are tailored to incomplete priors, lacking a comprehensive physical system to integrate dynamics from local, global, and endogenous levels. Moreover, penalty-based constraints adopted in existing methods struggle to deeply encode physical priors, leading to optimization pathologies and discrepancy between latent representations and physical transparency. To this end, we offer a physical view to interpret opinion dynamics via Diffusion-Convection-Reaction (DCR) system inspired by interacting particle theory. Building upon the Neural ODEs, we define the neural opinion dynamics to coordinate neural networks with physical priors, and further present the OPINN, a physics-informed neural framework for opinion dynamics modeling. Evaluated on real-world and synthetic datasets, OPINN achieves state-of-the-art performance in opinion evolution forecasting, offering a promising paradigm for the nexus of cyber, physical, and social systems.", "AI": {"tldr": "本文提出了一种基于物理启发的神经网络框架OPINN，用于意见动态建模。", "motivation": "为了更好地解释社会行为并解决极化和网络安全问题，需要一个能够结合机制可解释性和数据驱动灵活性的意见动力学模型。现有方法存在不完整先验、缺乏全面物理系统等问题，因此本文提出了一种新的框架来解决这些问题。", "method": "通过引入扩散-对流-反应（DCR）系统，并基于神经ODEs定义了神经意见动力学，协调神经网络与物理先验，提出了OPINN框架。", "result": "在真实世界和合成数据集上进行的测试表明，OPINN在意见演化预测方面达到了最先进的性能。", "conclusion": "本文通过提出OPINN框架，为解决网络、物理和社会系统的交汇点提供了一个有前景的方法。"}}
{"id": "2602.05397", "pdf": "https://arxiv.org/pdf/2602.05397", "abs": "https://arxiv.org/abs/2602.05397", "authors": ["Yuechen Yang", "Junlin Guo", "Ruining Deng", "Junchao Zhu", "Zhengyi Lu", "Chongyu Qu", "Yanfan Zhu", "Xingyi Guo", "Yu Wang", "Shilin Zhao", "Haichun Yang", "Yuankai Huo"], "title": "Explainable Pathomics Feature Visualization via Correlation-aware Conditional Feature Editing", "categories": ["cs.CV"], "comment": null, "summary": "Pathomics is a recent approach that offers rich quantitative features beyond what black-box deep learning can provide, supporting more reproducible and explainable biomarkers in digital pathology. However, many derived features (e.g., \"second-order moment\") remain difficult to interpret, especially across different clinical contexts, which limits their practical adoption. Conditional diffusion models show promise for explainability through feature editing, but they typically assume feature independence**--**an assumption violated by intrinsically correlated pathomics features. Consequently, editing one feature while fixing others can push the model off the biological manifold and produce unrealistic artifacts. To address this, we propose a Manifold-Aware Diffusion (MAD) framework for controllable and biologically plausible cell nuclei editing. Unlike existing approaches, our method regularizes feature trajectories within a disentangled latent space learned by a variational auto-encoder (VAE). This ensures that manipulating a target feature automatically adjusts correlated attributes to remain within the learned distribution of real cells. These optimized features then guide a conditional diffusion model to synthesize high-fidelity images. Experiments demonstrate that our approach is able to navigate the manifold of pathomics features when editing those features. The proposed method outperforms baseline methods in conditional feature editing while preserving structural coherence.", "AI": {"tldr": "提出了一种基于扩散模型的路径学特征可视化方法，该方法通过考虑特征之间的相关性来生成更合理的图像。", "motivation": "当前路径学特征解释困难，尤其是在不同临床背景下。为了提高这些特征的可解释性和实用性，研究者开发了条件扩散模型进行特征编辑，但这些模型假设特征是独立的，这在实际应用中并不成立，导致生成的图像不合理。", "method": "通过引入一种称为Manifold-Aware Diffusion（MAD）的新框架，在解缠结潜在空间内正则化特征轨迹。该框架使用变分自编码器（VAE）学习细胞核的真实分布，并确保在调整目标特征时，相关属性会自动调节以保持在真实细胞的分布内。", "result": "实验表明，所提出的方法能够在编辑路径学特征时导航其流形空间，并且比基线方法更有效地进行条件特征编辑的同时保持结构的一致性。", "conclusion": "通过引入考虑特征相关性的Manifold-Aware Diffusion框架，研究者成功提高了路径学特征的可解释性和实用性。"}}
{"id": "2602.05395", "pdf": "https://arxiv.org/pdf/2602.05395", "abs": "https://arxiv.org/abs/2602.05395", "authors": ["Jingkai Huang", "Will Ma", "Zhengyuan Zhou"], "title": "Optimal Bayesian Stopping for Efficient Inference of Consistent LLM Answers", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "A simple strategy for improving LLM accuracy, especially in math and reasoning problems, is to sample multiple responses and submit the answer most consistently reached. In this paper we leverage Bayesian prior information to save on sampling costs, stopping once sufficient consistency is reached. Although the exact posterior is computationally intractable, we further introduce an efficient \"L-aggregated\" stopping policy that tracks only the L-1 most frequent answer counts. Theoretically, we prove that L=3 is all you need: this coarse approximation is sufficient to achieve asymptotic optimality, and strictly dominates prior-free baselines, while having a fast posterior computation. Empirically, this identifies the most consistent (i.e., mode) LLM answer using fewer samples, and can achieve similar answer accuracy while cutting the number of LLM calls (i.e., saving on LLM inference costs) by up to 50%.", "AI": {"tldr": "本文提出了一种利用贝叶斯先验信息减少采样成本的方法，用于更有效地推断LLM的一致性答案。", "motivation": "通过多次抽样并提交最一致的答案以提高LLM在数学和推理问题中的准确性。引入了基于Bayesian的策略来节省采样成本，在达到足够一致性时停止。", "method": "采用\"L-聚合\"策略，仅跟踪最频繁答案计数中前L-1个值，并证明L=3已经可以实现渐近最优性并严格超越无先验信息基准。理论和实验验证了该方法的有效性和效率。", "result": "新方法能够使用更少的样本确定最一致的答案，同时在保持相似准确性的情况下最多减少50%的LLM调用次数。", "conclusion": "提出的L-聚合策略不仅计算速度快，而且能有效提高一致性答案推断的准确性和效率。"}}
{"id": "2602.05394", "pdf": "https://arxiv.org/pdf/2602.05394", "abs": "https://arxiv.org/abs/2602.05394", "authors": ["Noah Amsel", "Yves Baumann", "Paul Beckman", "Peter Bürgisser", "Chris Camaño", "Tyler Chen", "Edmond Chow", "Anil Damle", "Michal Derezinski", "Mark Embree", "Ethan N. Epperly", "Robert Falgout", "Mark Fornace", "Anne Greenbaum", "Chen Greif", "Diana Halikias", "Zhen Huang", "Elias Jarlebring", "Yiannis Koutis", "Daniel Kressner", "Rasmus Kyng", "Jörg Liesen", "Jackie Lok", "Raphael A. Meyer", "Yuji Nakatsukasa", "et al. (11 additional authors not shown)"], "title": "Linear Systems and Eigenvalue Problems: Open Questions from a Simons Workshop", "categories": ["math.NA", "cs.DS"], "comment": null, "summary": "This document presents a series of open questions arising in matrix computations, i.e., the numerical solution of linear algebra problems. It is a result of working groups at the workshop \\emph{Linear Systems and Eigenvalue Problems}, which was organized at the Simons Institute for the Theory of Computing program on \\emph{Complexity and Linear Algebra} in Fall 2025. The complexity and numerical solution of linear algebra problems %in matrix computations and related fields is a crosscutting area between theoretical computer science and numerical analysis. The value of the particular problem formulations here is that they were produced via discussions between researchers from both groups. The open questions are organized in five categories: iterative solvers for linear systems, eigenvalue computation, low-rank approximation, randomized sketching, and other areas including tensors, quantum systems, and matrix functions.", "AI": {"tldr": "本文提出了矩阵计算中线性代数问题的开放性问题，涉及迭代求解器、特征值计算、低秩近似和随机抽样等领域。", "motivation": "通过理论计算机科学和数值分析研究人员之间的讨论，产生了一系列具有挑战性的线性代数问题，旨在推动这些领域的发展。", "method": "论文组织了五个类别的开放性问题：迭代求解器、特征值计算、低秩近似、随机抽样以及其他包括张量、量子系统和矩阵函数的领域。", "result": "提出了多个跨学科研究领域的开放性问题，旨在促进复杂性和线性代数理论的发展。", "conclusion": "这些开放性问题为未来的研究提供了方向，并促进了不同背景研究人员之间的合作。"}}
{"id": "2602.05392", "pdf": "https://arxiv.org/pdf/2602.05392", "abs": "https://arxiv.org/abs/2602.05392", "authors": ["Jiyun Chun", "Eric Fosler-Lussier", "Michael White", "Andrew Perrault"], "title": "Beyond Length: Context-Aware Expansion and Independence as Developmentally Sensitive Evaluation in Child Utterances", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating the quality of children's utterances in adult-child dialogue remains challenging due to insufficient context-sensitive metrics. Common proxies such as Mean Length of Utterance (MLU), lexical diversity (vocd-D), and readability indices (Flesch-Kincaid Grade Level, Gunning Fog Index) are dominated by length and ignore conversational context, missing aspects of response quality such as reasoning depth, topic maintenance, and discourse planning. We introduce an LLM-as-a-judge framework that first classifies the Previous Adult Utterance Type and then scores the child's response along two axes: Expansion (contextual elaboration and inferential depth) and Independence (the child's contribution to advancing the discourse). These axes reflect fundamental dimensions in child language development, where Expansion captures elaboration, clause combining, and causal and contrastive connectives. Independence captures initiative, topic control, decreasing reliance on adult scaffolding through growing self-regulation, and audience design. We establish developmental validity by showing age-related patterns and demonstrate predictive value by improving age estimation over common baselines. We further confirm semantic sensitivity by detecting differences tied to discourse relations. Our metrics align with human judgments, enabling large-scale evaluation. This shifts child utterance assessment from simply measuring length to evaluating how meaningfully the child's speech contributes to and advances the conversation within its context.", "AI": {"tldr": "通过引入LLM作为评估框架来改进儿童话语的质量评估，该框架能够根据上下文敏感的指标评价孩子的回答是否具备扩展性和独立性。", "motivation": "目前用于评估儿童语言质量的指标（如平均句子长度、词汇多样性等）主要依赖于长度而非语境信息，忽视了对话深度、话题保持及论述规划等因素。因此，研究者提出了一种新的框架来解决这一问题。", "method": "通过分类前一个成人的发言类型，并根据两个维度对孩子的回答进行评分：扩展性和独立性。扩展性衡量上下文中的细化和推理深度；独立性衡量孩子在对话中推动进程的能力，反映语言发展的核心维度。", "result": "提出的评估指标展示了与年龄相关的模式并提高了年龄估计的准确性，同时也体现了语义敏感度，能够识别出不同话语关系下的差异，并且得到了人类判断的一致认可。", "conclusion": "研究成功地将儿童话语质量评估从简单的长度衡量提升到了有意义贡献和对话推进的评价，为大规模的语言发展研究提供了新的方法。"}}
{"id": "2602.05391", "pdf": "https://arxiv.org/pdf/2602.05391", "abs": "https://arxiv.org/abs/2602.05391", "authors": ["Qianxin Xia", "Jiawei Du", "Yuhan Zhang", "Jielei Wang", "Guoming Lu"], "title": "Dataset Distillation via Relative Distribution Matching and Cognitive Heritage", "categories": ["cs.CV"], "comment": null, "summary": "Dataset distillation seeks to synthesize a highly compact dataset that achieves performance comparable to the original dataset on downstream tasks. For the classification task that use pre-trained self-supervised models as backbones, previous linear gradient matching optimizes synthetic images by encouraging them to mimic the gradient updates induced by real images on the linear classifier. However, this batch-level formulation requires loading thousands of real images and applying multiple rounds of differentiable augmentations to synthetic images at each distillation step, leading to substantial computational and memory overhead. In this paper, we introduce statistical flow matching , a stable and efficient supervised learning framework that optimizes synthetic images by aligning constant statistical flows from target class centers to non-target class centers in the original data. Our approach loads raw statistics only once and performs a single augmentation pass on the synthetic data, achieving performance comparable to or better than the state-of-the-art methods with 10x lower GPU memory usage and 4x shorter runtime. Furthermore, we propose a classifier inheritance strategy that reuses the classifier trained on the original dataset for inference, requiring only an extremely lightweight linear projector and marginal storage while achieving substantial performance gains.", "AI": {"tldr": "本文提出了一种新的数据集蒸馏方法，通过相对分布匹配和认知遗产策略来生成高性能的小型化数据集。", "motivation": "现有的线性梯度匹配方法在进行数据集蒸馏时需要加载大量真实图像并应用多次可微变换，导致计算量大且内存占用高。为了减少开销并提高效率，作者提出了统计流匹配和分类器继承策略。", "method": "本文提出了一种新的监督学习框架——统计流匹配，通过优化合成图像以使目标类中心与非目标类中心的常数统计流对齐，并仅加载原始统计数据一次且只进行单次增强操作。此外，还引入了分类器继承策略，利用原有数据集训练的分类器进行推断。", "result": "该方法在性能上达到了或超过了现有最佳方法，同时减少了10倍的GPU内存使用和4倍的运行时间。", "conclusion": "通过统计流匹配和分类器继承策略，本文提出了一种高效、低资源的数据集蒸馏方法，能够生成高性能的小型化数据集。"}}
{"id": "2602.05390", "pdf": "https://arxiv.org/pdf/2602.05390", "abs": "https://arxiv.org/abs/2602.05390", "authors": ["Wei Soon Cheong", "Lian Lian Jiang", "Jamie Ng Suat Ling"], "title": "Assessing Electricity Demand Forecasting with Exogenous Data in Time Series Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 Figure and 3 Tables. Accepted to AI4TS Workshop @ AAAI'26 as an oral presentation (see https://ai4ts.github.io/aaai2026)", "summary": "Time-series foundation models have emerged as a new paradigm for forecasting, yet their ability to effectively leverage exogenous features -- critical for electricity demand forecasting -- remains unclear. This paper empirically evaluates foundation models capable of modeling cross-channel correlations against a baseline LSTM with reversible instance normalization across Singaporean and Australian electricity markets at hourly and daily granularities. We systematically assess MOIRAI, MOMENT, TinyTimeMixers, ChronosX, and Chronos-2 under three feature configurations: all features, selected features, and target-only. Our findings reveal highly variable effectiveness: while Chronos-2 achieves the best performance among foundation models (in zero-shot settings), the simple baseline frequently outperforms all foundation models in Singapore's stable climate, particularly for short-term horizons. Model architecture proves critical, with synergistic architectural implementations (TTM's channel-mixing, Chronos-2's grouped attention) consistently leveraging exogenous features, while other approaches show inconsistent benefits. Geographic context emerges as equally important, with foundation models demonstrating advantages primarily in variable climates. These results challenge assumptions about universal foundation model superiority and highlight the need for domain-specific models, specifically in the energy domain.", "AI": {"tldr": "评估时间序列基础模型在电力需求预测中的表现，特别是在使用外部数据时的效果。", "motivation": "探讨时间序列基础模型能否有效利用外部特征进行电力需求预测，并与传统的LSTM基线模型比较其性能。", "method": "对新加坡和澳大利亚的电力市场采用五种不同的时间序列基础模型（MOIRAI, MOMENT, TinyTimeMixers, ChronosX, Chronos-2）在小时级和日级数据上进行评估，通过三种特征配置对比：全部特征、选择性特征和仅目标特征。", "result": "Chronos-2 在零样本设置下表现出最佳性能；但在新加坡稳定的气候条件下，基线模型的表现往往更佳。模型架构对于外部特征的利用至关重要，而地理环境也对预测效果有很大影响。", "conclusion": "研究结果表明，基础模型并不总是在所有场景中优于传统方法，特别是在稳定气候地区和短期预测时。这突显了在特定领域开发专用模型的重要性。"}}
{"id": "2602.05387", "pdf": "https://arxiv.org/pdf/2602.05387", "abs": "https://arxiv.org/abs/2602.05387", "authors": ["Zolnamar Dorjsembe", "Hung-Yi Chen", "Furen Xiao", "Hsing-Kuo Pao"], "title": "Parallel Swin Transformer-Enhanced 3D MRI-to-CT Synthesis for MRI-Only Radiotherapy Planning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "MRI provides superior soft tissue contrast without ionizing radiation; however, the absence of electron density information limits its direct use for dose calculation. As a result, current radiotherapy workflows rely on combined MRI and CT acquisitions, increasing registration uncertainty and procedural complexity. Synthetic CT generation enables MRI only planning but remains challenging due to nonlinear MRI-CT relationships and anatomical variability. We propose Parallel Swin Transformer-Enhanced Med2Transformer, a 3D architecture that integrates convolutional encoding with dual Swin Transformer branches to model both local anatomical detail and long-range contextual dependencies. Multi-scale shifted window attention with hierarchical feature aggregation improves anatomical fidelity. Experiments on public and clinical datasets demonstrate higher image similarity and improved geometric accuracy compared with baseline methods. Dosimetric evaluation shows clinically acceptable performance, with a mean target dose error of 1.69%. Code is available at: https://github.com/mobaidoctor/med2transformer.", "AI": {"tldr": "提出了Parallel Swin Transformer-Enhanced Med2Transformer，用于MRI到CT的合成，以支持仅使用MRI进行放射治疗计划。", "motivation": "通过减少注册不确定性并简化程序复杂性来提高放射治疗工作流程。由于MRI和CT之间存在非线性和解剖变异性的挑战，合成CT生成变得困难。", "method": "设计了一种3D架构，结合卷积编码与双Swin Transformer分支以建模局部解剖细节和长程上下文依赖关系。多尺度移动窗口注意以及分层特征聚合提升了解剖学准确性。", "result": "在公共和临床数据集上的实验展示了更高的图像相似性和改进的几何精度，并且剂量评估显示其性能可接受，平均目标剂量误差为1.69％。", "conclusion": "提出的Parallel Swin Transformer-Enhanced Med2Transformer模型能够在MRI到CT合成中表现出色，有助于实现MRI单独使用的放射治疗规划。"}}
{"id": "2602.05386", "pdf": "https://arxiv.org/pdf/2602.05386", "abs": "https://arxiv.org/abs/2602.05386", "authors": ["Zhenxiong Yu", "Zhi Yang", "Zhiheng Jin", "Shuhe Wang", "Heng Zhang", "Yanlin Fei", "Lingfeng Zeng", "Fangqi Lou", "Shuo Zhang", "Tu Hu", "Jingping Liu", "Rongze Chen", "Xingyu Zhu", "Kunyi Wang", "Chaofa Yuan", "Xin Guo", "Zhaowei Liu", "Feipeng Zhang", "Jie Huang", "Huacan Wang", "Ronghao Chen", "Liwen Zhang"], "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which security validation is forcibly triggered at predefined stages of the agent lifecycle. In this work, we argue that effective agent security should be intrinsic and selective rather than architecturally decoupled and mandatory. We propose Spider-Sense framework, an event-driven defense framework based on Intrinsic Risk Sensing (IRS), which allows agents to maintain latent vigilance and trigger defenses only upon risk perception. Once triggered, the Spider-Sense invokes a hierarchical defence mechanism that trades off efficiency and precision: it resolves known patterns via lightweight similarity matching while escalating ambiguous cases to deep internal reasoning, thereby eliminating reliance on external models. To facilitate rigorous evaluation, we introduce S$^2$Bench, a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks. Extensive experiments demonstrate that Spider-Sense achieves competitive or superior defense performance, attaining the lowest Attack Success Rate (ASR) and False Positive Rate (FPR), with only a marginal latency overhead of 8.3\\%.", "AI": {"tldr": "提出了一种基于内在风险感知的Spider-Sense框架，用于提高自主代理的安全性。", "motivation": "随着大型语言模型演变为自主代理，其应用范围扩大，并带来了新的安全挑战。现有的防御机制主要采用强制检查的方式，而作者认为有效的安全性应该内在于系统中，并且是选择性的而非强制性的。", "method": "引入Spider-Sense框架，该框架基于事件驱动的内在风险感知（IRS），能够根据风险感知触发防御措施。它采用分层防御策略，在轻量级相似性匹配和深度内部推理之间进行权衡。", "result": "通过S$^2$Bench评估，Spider-Sense达到了最低的攻击成功率和误报率，并且仅引入了8.3%的延迟开销。", "conclusion": "Spider-Sense框架能够提供有效的防御性能，同时保持较低的延迟开销，证明了基于内在风险感知的方法在自主代理安全中的有效性。"}}
{"id": "2602.05384", "pdf": "https://arxiv.org/pdf/2602.05384", "abs": "https://arxiv.org/abs/2602.05384", "authors": ["Hao Feng", "Wei Shi", "Ke Zhang", "Xiang Fei", "Lei Liao", "Dingkang Yang", "Yongkun Du", "Xuecheng Wu", "Jingqun Tang", "Yang Liu", "Hong Chen", "Can Huang"], "title": "Dolphin-v2: Universal Document Parsing via Scalable Anchor Prompting", "categories": ["cs.CV"], "comment": null, "summary": "Document parsing has garnered widespread attention as vision-language models (VLMs) advance OCR capabilities. However, the field remains fragmented across dozens of specialized models with varying strengths, forcing users to navigate complex model selection and limiting system scalability. Moreover, existing two-stage approaches depend on axis-aligned bounding boxes for layout detection, failing to handle distorted or photographed documents effectively. To this end, we present Dolphin-v2, a two-stage document image parsing model that substantially improves upon the original Dolphin. In the first stage, Dolphin-v2 jointly performs document type classification (digital-born versus photographed) alongside layout analysis. For digital-born documents, it conducts finer-grained element detection with reading order prediction. In the second stage, we employ a hybrid parsing strategy: photographed documents are parsed holistically as complete pages to handle geometric distortions, while digital-born documents undergo element-wise parallel parsing guided by the detected layout anchors, enabling efficient content extraction. Compared with the original Dolphin, Dolphin-v2 introduces several crucial enhancements: (1) robust parsing of photographed documents via holistic page-level understanding, (2) finer-grained element detection (21 categories) with semantic attribute extraction such as author information and document metadata, and (3) code block recognition with indentation preservation, which existing systems typically lack. Comprehensive evaluations are conducted on DocPTBench, OmniDocBench, and our self-constructed RealDoc-160 benchmark. The results demonstrate substantial improvements: +14.78 points overall on the challenging OmniDocBench and 91% error reduction on photographed documents, while maintaining efficient inference through parallel processing.", "AI": {"tldr": "Dolphin-v2是一款两阶段文档图像解析模型，通过全局理解与局部细节检测的结合提高了对不同类型文档（特别是照片型）的处理能力。", "motivation": "现有文献解析系统依赖特定模型且难以统一管理；同时轴向布局检测方法无法有效应对扭曲或摄影图像。Dolphin-v2旨在解决这些问题并提高整体效率。", "method": "Dolphin-v2首先进行文档类型分类和布局分析，随后根据不同文档类别采用全页理解或局部解析策略，并引入了更细致的元素检测与语义属性提取功能。", "result": "在DocPTBench、OmniDocBench及RealDoc-160上进行全面评估后，Dolphin-v2显示出了显著提升：总体提高了14.78分，在照片型文档中减少了91%的错误率。同时保持了高效的推断过程。", "conclusion": "通过引入更先进的解析技术，Dolphin-v2不仅增强了对复杂图像格式的支持能力，还大幅提升了处理效率和准确度。"}}
{"id": "2602.05382", "pdf": "https://arxiv.org/pdf/2602.05382", "abs": "https://arxiv.org/abs/2602.05382", "authors": ["Tina Khezresmaeilzadeh", "Jike Zhong", "Konstantinos Psounis"], "title": "VRIQ: Benchmarking and Analyzing Visual-Reasoning IQ of VLMs", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent progress in Vision Language Models (VLMs) has raised the question of whether they can reliably perform nonverbal reasoning. To this end, we introduce VRIQ (Visual Reasoning IQ), a novel benchmark designed to assess and analyze the visual reasoning ability of VLMs. We evaluate models on two sets of tasks: abstract puzzle-style and natural-image reasoning tasks. We find that on abstract puzzles, performance remains near random with an average accuracy of around 28%, while natural tasks yield better but still weak results with 45% accuracy. We also find that tool-augmented reasoning demonstrates only modest improvements. To uncover the source of this weakness, we introduce diagnostic probes targeting perception and reasoning. Our analysis demonstrates that around 56% of failures arise from perception alone, 43% from both perception and reasoning, and only a mere 1% from reasoning alone. This motivates us to design fine-grained diagnostic probe questions targeting specific perception categories (e.g., shape, count, position, 3D/depth), revealing that certain categories cause more failures than others. Our benchmark and analysis establish that current VLMs, even with visual reasoning tools, remain unreliable abstract reasoners, mostly due to perception limitations, and offer a principled basis for improving visual reasoning in multimodal systems.", "AI": {"tldr": "本文介绍了VRIQ，一个用于评估和分析视觉语言模型（VLMs）的视觉推理能力的新基准。", "motivation": "最近在视觉语言模型方面取得了进展，但关于这些模型是否能够可靠地执行非言语推理仍然存在疑问。因此，作者引入了VRIQ来探讨这一问题。", "method": "通过两个任务集（抽象拼图和自然图像推理）评估了模型的性能，并设计了诊断探针以分析感知和推理的问题来源。同时提出了针对特定视觉感知类别的精细粒度诊断题。", "result": "在抽象拼图上，平均准确率为28%，接近随机水平；而自然任务上的表现较好但仍然较弱，准确率为45%。通过引入的诊断探针发现大约有56%的错误来自于感知问题，只有1%的错误来自推理本身。", "conclusion": "当前的视觉语言模型在抽象推理方面仍不可靠，并且大多数问题是由于感知限制造成的。这项研究为改进多模态系统的视觉推理提供了一个理论基础。"}}
{"id": "2602.05381", "pdf": "https://arxiv.org/pdf/2602.05381", "abs": "https://arxiv.org/abs/2602.05381", "authors": ["Ting Fang Tan", "Kabilan Elangovan", "Andreas Pollreisz", "Kevin Bryan Dy", "Wei Yan Ng", "Joy Le Yi Wong", "Jin Liyuan", "Chrystie Quek Wan Ning", "Ashley Shuen Ying Hong", "Arun James Thirunavukarasu", "Shelley Yin-His Chang", "Jie Yao", "Dylan Hong", "Wang Zhaoran", "Amrita Gupta", "Daniel SW Ting"], "title": "Clinical Validation of Medical-based Large Language Model Chatbots on Ophthalmic Patient Queries with LLM-based Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Domain specific large language models are increasingly used to support patient education, triage, and clinical decision making in ophthalmology, making rigorous evaluation essential to ensure safety and accuracy. This study evaluated four small medical LLMs Meerkat-7B, BioMistral-7B, OpenBioLLM-8B, and MedLLaMA3-v20 in answering ophthalmology related patient queries and assessed the feasibility of LLM based evaluation against clinician grading. In this cross sectional study, 180 ophthalmology patient queries were answered by each model, generating 2160 responses. Models were selected for parameter sizes under 10 billion to enable resource efficient deployment. Responses were evaluated by three ophthalmologists of differing seniority and by GPT-4-Turbo using the S.C.O.R.E. framework assessing safety, consensus and context, objectivity, reproducibility, and explainability, with ratings assigned on a five point Likert scale. Agreement between LLM and clinician grading was assessed using Spearman rank correlation, Kendall tau statistics, and kernel density estimate analyses. Meerkat-7B achieved the highest performance with mean scores of 3.44 from Senior Consultants, 4.08 from Consultants, and 4.18 from Residents. MedLLaMA3-v20 performed poorest, with 25.5 percent of responses containing hallucinations or clinically misleading content, including fabricated terminology. GPT-4-Turbo grading showed strong alignment with clinician assessments overall, with Spearman rho of 0.80 and Kendall tau of 0.67, though Senior Consultants graded more conservatively. Overall, medical LLMs demonstrated potential for safe ophthalmic question answering, but gaps remained in clinical depth and consensus, supporting the feasibility of LLM based evaluation for large scale benchmarking and the need for hybrid automated and clinician review frameworks to guide safe clinical deployment.", "AI": {"tldr": "本文评估了四个小型医疗语言模型在回答眼科患者查询时的表现，并使用GPT-4-Turbo进行LLM基于的评价，以验证其临床可行性。", "motivation": "随着医学领域大语言模型在支持病人教育、分诊和临床决策中的应用日益增多，确保安全性和准确性变得至关重要。因此，需要对这些模型进行全面评估。", "method": "该研究选取了四个参数规模小于10亿的小型医疗语言模型（Meerkat-7B, BioMistral-7B, OpenBioLLM-8B 和 MedLLaMA3-v20），使用S.C.O.R.E.框架评估它们回答眼科患者查询的能力。每个模型生成了2160个答案，由三名不同级别的医生（资深顾问、顾问和住院医师）以及GPT-4-Turbo进行评分。", "result": "Meerkat-7B的表现最佳，分别获得了3.44（资深顾问）、4.08（顾问）和4.18（住院医师）的平均分数。MedLLaMA3-v20表现最差，有25.5%的回答包含幻觉或临床误导性内容。GPT-4-Turbo评分与医生评估高度一致。", "conclusion": "医疗语言模型在眼科问题回答方面显示了安全性的潜力，但在临床深度和共识方面仍存在差距，支持使用LLM基于的评价进行大规模基准测试，并建议采用自动化和医生联合审查框架来指导安全的临床部署。"}}
{"id": "2602.05380", "pdf": "https://arxiv.org/pdf/2602.05380", "abs": "https://arxiv.org/abs/2602.05380", "authors": ["Xiaoxuan He", "Siming Fu", "Wanli Li", "Zhiyuan Li", "Dacheng Yin", "Kang Rong", "Fengyun Rao", "Bo Zhang"], "title": "SAIL: Self-Amplified Iterative Learning for Diffusion Model Alignment with Minimal Human Feedback", "categories": ["cs.CV"], "comment": null, "summary": "Aligning diffusion models with human preferences remains challenging, particularly when reward models are unavailable or impractical to obtain, and collecting large-scale preference datasets is prohibitively expensive. \\textit{This raises a fundamental question: can we achieve effective alignment using only minimal human feedback, without auxiliary reward models, by unlocking the latent capabilities within diffusion models themselves?} In this paper, we propose \\textbf{SAIL} (\\textbf{S}elf-\\textbf{A}mplified \\textbf{I}terative \\textbf{L}earning), a novel framework that enables diffusion models to act as their own teachers through iterative self-improvement. Starting from a minimal seed set of human-annotated preference pairs, SAIL operates in a closed-loop manner where the model progressively generates diverse samples, self-annotates preferences based on its evolving understanding, and refines itself using this self-augmented dataset. To ensure robust learning and prevent catastrophic forgetting, we introduce a ranked preference mixup strategy that carefully balances exploration with adherence to initial human priors. Extensive experiments demonstrate that SAIL consistently outperforms state-of-the-art methods across multiple benchmarks while using merely 6\\% of the preference data required by existing approaches, revealing that diffusion models possess remarkable self-improvement capabilities that, when properly harnessed, can effectively replace both large-scale human annotation and external reward models.", "AI": {"tldr": "提出了一种新的框架SAIL，通过迭代自我改进使扩散模型能够自行教学，以最小的人类反馈实现有效的对齐。", "motivation": "探讨在没有奖励模型的情况下，能否仅依靠最小的用户反馈来有效校准扩散模型，同时解锁其内在能力。", "method": "从少量人工标注的偏好数据集开始，SAIL通过生成多样化的样本、自我注释和使用自增扩的数据集进行迭代改进。引入了优选混合策略以平衡探索与遵守初始人类先验知识。", "result": "实验显示，SAIL在多个基准测试中优于现有方法，并且仅需6%的偏好数据量。", "conclusion": "扩散模型具有显著自我改进的能力，通过正确利用这些能力可以有效取代大规模人工注释和外部奖励模型。"}}
{"id": "2602.05375", "pdf": "https://arxiv.org/pdf/2602.05375", "abs": "https://arxiv.org/abs/2602.05375", "authors": ["Jaewon Lee", "Yongwoo Kim", "Donghyun Kim"], "title": "Erase at the Core: Representation Unlearning for Machine Unlearning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Many approximate machine unlearning methods demonstrate strong logit-level forgetting -- such as near-zero accuracy on the forget set -- yet continue to preserve substantial information within their internal feature representations. We refer to this discrepancy as superficial forgetting. Recent studies indicate that most existing unlearning approaches primarily alter the final classifier, leaving intermediate representations largely unchanged and highly similar to those of the original model. To address this limitation, we introduce the Erase at the Core (EC), a framework designed to enforce forgetting throughout the entire network hierarchy. EC integrates multi-layer contrastive unlearning on the forget set with retain set preservation through deeply supervised learning. Concretely, EC attaches auxiliary modules to intermediate layers and applies both contrastive unlearning and cross-entropy losses at each supervision point, with layer-wise weighted losses. Experimental results show that EC not only achieves effective logit-level forgetting, but also substantially reduces representational similarity to the original model across intermediate layers. Furthermore, EC is model-agnostic and can be incorporated as a plug-in module into existing unlearning methods, improving representation-level forgetting while maintaining performance on the retain set.", "AI": {"tldr": "论文提出了Erase at the Core（EC）框架，旨在解决现有机器遗忘方法存在的表层遗忘问题，通过在中间表示层面强制执行遗忘来提高模型的隐私保护能力。", "motivation": "现有的机器遗忘方法通常仅改变最终分类器而未对中间特征表示进行有效修改，导致虽然模型在逻辑层面上表现出几乎完全忘记训练数据的能力，但内部表示仍保持与原始模型高度相似。为解决这一问题，论文提出了EC框架以强制执行整个网络层次结构中的遗忘。", "method": "EC框架通过在忘却集上应用多层对比遗忘，并利用深度监督学习保留保留集上的性能来实现这一点。具体来说，在每个监督点处附加辅助模块并同时应用对比遗忘损失和交叉熵损失，且采用逐层加权的损失函数。", "result": "实验结果表明，EC不仅实现了有效的逻辑级别遗忘，而且显著减少了中间层次表示与原始模型之间的相似性，提高了隐私保护水平。此外，EC方法具有模型无关性，可以作为插件模块集成到现有遗忘策略中以提高其表示层面的遗忘能力。", "conclusion": "论文展示了通过强制执行网络所有层中的遗忘来提高机器遗忘效果的可能性，并强调了在中间层次实现有效遗忘的重要性，这为未来研究提供了新的视角和方向。"}}
{"id": "2602.05373", "pdf": "https://arxiv.org/pdf/2602.05373", "abs": "https://arxiv.org/abs/2602.05373", "authors": ["Haoqin Sun", "Chenyang Lyu", "Shiwan Zhao", "Xuanfan Ni", "Xiangyu Kong", "Longyue Wang", "Weihua Luo", "Yong Qin"], "title": "Speech-XL: Towards Long-Form Speech Understanding in Large Speech Language Models", "categories": ["cs.SD"], "comment": null, "summary": "Despite the growing success of Large Speech Language Models (LSLMs) in processing short-term acoustic signals, their extension to long-form audio understanding is severely bottlenecked. This limitation stems from the limited context length and the exorbitant memory footprints required for long-form inference. In this work, we propose Speech-XL, a new model that capitalizes on the intrinsic key-value (KV) sparsification capacity of Large Language Models (LLMs) to achieve high-ratio speech input compression. Specifically, we introduce a novel special token, the Speech Summarization Token (SST), for each speech interval to encapsulate the intra-interval speech information into its associated KV pairs. The SST module is trained via instruction fine-tuning, employing a curriculum learning strategy where the SST learns to compress information in a progressive manner--advancing from low-ratio (simple) to high-ratio (challenging) compression. Despite utilizing significantly less training data than other baselines, our model achieves highly competitive performance on major benchmarks, including LongSpeech and AUDIOMARATHON. By addressing the long-standing bottlenecks in long-form audio modeling, our approach offers a novel perspective on the condensation of extensive acoustic sequences.", "AI": {"tldr": "提出Speech-XL模型，通过特殊令牌压缩长音频数据，在大型语言模型中实现高效的语音理解。", "motivation": "当前大型语音语言模型在处理短期声学信号方面取得成功，但在长期音频理解上受限于上下文长度和内存需求。为此引入新的方法以解决这些瓶颈问题。", "method": "使用特殊令牌Speech Summarization Token（SST）压缩长音频数据，并通过指令微调训练SST模块，采用逐步递进的课程学习策略提升模型性能。", "result": "在LongSpeech和AUDIOMARATHON等主要基准测试中表现优异，尽管训练数据量较小但仍实现高度竞争力的表现。", "conclusion": "提出的方法有效解决了长期音频建模中的瓶颈问题，并为压缩大规模声学序列提供了新的视角。"}}
{"id": "2602.05367", "pdf": "https://arxiv.org/pdf/2602.05367", "abs": "https://arxiv.org/abs/2602.05367", "authors": ["Youngcheon You", "Banseok Lee", "Minseop Choi", "Seonyoung Kim", "Hyochan Chong", "Changdong Kim", "Youngmin Kim", "Dongkyu Kim"], "title": "RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary ($\\pm$1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a $4.49\\times$ inference speed-up over full-precision models on an RTX 4090.", "AI": {"tldr": "本文提出了一种新的量化框架RaBiT，通过算法强制执行残差层次结构来解决共适应问题，使大语言模型在低比特量化下保持高精度和高效性。", "motivation": "高效的大型语言模型部署需要极端的量化，这导致了性能与效率之间的关键权衡。残留二值化虽然硬件友好、推理无需矩阵乘法，但由于平行残差路径学习冗余特征，使得错误补偿结构恶化并限制了模型表达能力。", "method": "RaBiT通过从单个共享全精度权重中逐步推导每个二进制路径来解决共适应问题。这种方法确保每一个路径纠正前一个路径的误差，并通过稳健初始化优先保持功能而非简单的权重重构。", "result": "RaBiT重新定义了2位准确率与效率边界，在RTX 4090上实现了状态-of-the-art性能，接近硬件密集型向量量化方法，并比全精度模型快4.49倍的推理速度。", "conclusion": "本文通过提出RaBiT框架解决了残留二值化过程中共适应问题，显著提高了低比特量化大语言模型的准确率和效率。"}}
{"id": "2602.05362", "pdf": "https://arxiv.org/pdf/2602.05362", "abs": "https://arxiv.org/abs/2602.05362", "authors": ["Zishan Liu", "Zecong Tang", "RuoCheng Wu", "Xinzhe Zheng", "Jingyu Hu", "Ka-Hei Hui", "Haoran Xie", "Bo Dai", "Zhengzhe Liu"], "title": "Imagine a City: CityGenAgent for Procedural 3D City Generation", "categories": ["cs.CV"], "comment": null, "summary": "The automated generation of interactive 3D cities is a critical challenge with broad applications in autonomous driving, virtual reality, and embodied intelligence. While recent advances in generative models and procedural techniques have improved the realism of city generation, existing methods often struggle with high-fidelity asset creation, controllability, and manipulation. In this work, we introduce CityGenAgent, a natural language-driven framework for hierarchical procedural generation of high-quality 3D cities. Our approach decomposes city generation into two interpretable components, Block Program and Building Program. To ensure structural correctness and semantic alignment, we adopt a two-stage learning strategy: (1) Supervised Fine-Tuning (SFT). We train BlockGen and BuildingGen to generate valid programs that adhere to schema constraints, including non-self-intersecting polygons and complete fields; (2) Reinforcement Learning (RL). We design Spatial Alignment Reward to enhance spatial reasoning ability and Visual Consistency Reward to bridge the gap between textual descriptions and the visual modality. Benefiting from the programs and the models' generalization, CityGenAgent supports natural language editing and manipulation. Comprehensive evaluations demonstrate superior semantic alignment, visual quality, and controllability compared to existing methods, establishing a robust foundation for scalable 3D city generation.", "AI": {"tldr": "CityGenAgent是一种基于自然语言的框架，用于生成高质量的3D城市。", "motivation": "现有的方法在高保真资产创建、可控性和操作性方面存在挑战，因此开发了一种新的系统来解决这些问题。", "method": "该研究采用两阶段学习策略：监督微调和强化学习，以确保程序的有效性和视觉一致性。", "result": "CityGenAgent相比现有方法表现出更好的语义对齐、视觉质量和可控性。", "conclusion": "CityGenAgent为可扩展的3D城市生成奠定了坚实的基础。"}}
{"id": "2602.05360", "pdf": "https://arxiv.org/pdf/2602.05360", "abs": "https://arxiv.org/abs/2602.05360", "authors": ["Ningkang Peng", "Xiaoqian Peng", "Yuhao Zhang", "Qianfeng Yu", "Feng Xing", "Peirong Ma", "Xichen Yang", "Yi Chen", "Tingyu Lu", "Yanhui Gu"], "title": "Breaking Semantic Hegemony: Decoupling Principal and Residual Subspaces for Generalized OOD Detection", "categories": ["cs.CV"], "comment": null, "summary": "While feature-based post-hoc methods have made significant strides in Out-of-Distribution (OOD) detection, we uncover a counter-intuitive Simplicity Paradox in existing state-of-the-art (SOTA) models: these models exhibit keen sensitivity in distinguishing semantically subtle OOD samples but suffer from severe Geometric Blindness when confronting structurally distinct yet semantically simple samples or high-frequency sensor noise. We attribute this phenomenon to Semantic Hegemony within the deep feature space and reveal its mathematical essence through the lens of Neural Collapse. Theoretical analysis demonstrates that the spectral concentration bias, induced by the high variance of the principal subspace, numerically masks the structural distribution shift signals that should be significant in the residual subspace. To address this issue, we propose D-KNN, a training-free, plug-and-play geometric decoupling framework. This method utilizes orthogonal decomposition to explicitly separate semantic components from structural residuals and introduces a dual-space calibration mechanism to reactivate the model's sensitivity to weak residual signals. Extensive experiments demonstrate that D-KNN effectively breaks Semantic Hegemony, establishing new SOTA performance on both CIFAR and ImageNet benchmarks. Notably, in resolving the Simplicity Paradox, it reduces the FPR95 from 31.3% to 2.3%; when addressing sensor failures such as Gaussian noise, it boosts the detection performance (AUROC) from a baseline of 79.7% to 94.9%.", "AI": {"tldr": "本文提出了一种新的无训练、即插即用的几何分解框架D-KNN，用于解决现有最佳模型在处理结构差异明显的样本或高频率噪声时存在的问题。", "motivation": "现有的最佳方法在区分语义微妙的异常数据方面表现优异，但在面对结构性明显不同且语义简单的样本或高频传感器噪音时表现出严重的‘几何盲点’。这种现象归因于深度特征空间中的‘语义霸权’和神经崩溃。理论分析揭示了由主子空间高方差引起的光谱集中偏差掩盖了残差子空间中应显著的结构性分布变化信号。", "method": "提出了一种基于正交分解的无训练、即插即用几何解耦框架D-KNN，该方法能够明确地将语义成分与结构残差分开，并通过双空间校准机制重新激活模型对弱残差信号的敏感度。", "result": "实验结果显示，D-KNN在打破‘语义霸权’方面表现卓越，在CIFAR和ImageNet基准测试中均达到了新的最佳性能。特别是在解决‘简洁悖论’时，将FPR95从31.3%降至2.3%，面对如高斯噪声等传感器故障时，AUROC也从79.7%提升至94.9%。", "conclusion": "通过引入D-KNN框架，该研究成功解决了现有模型在处理结构性变化显著样本或高频噪音时的局限性，提高了异常数据检测的整体性能。"}}
{"id": "2602.05359", "pdf": "https://arxiv.org/pdf/2602.05359", "abs": "https://arxiv.org/abs/2602.05359", "authors": ["Yiming Zhang", "Qiangyu Yan", "Borui Jiang", "Kai Han"], "title": "Multimodal Latent Reasoning via Hierarchical Visual Cues Injection", "categories": ["cs.CV"], "comment": null, "summary": "The advancement of multimodal large language models (MLLMs) has enabled impressive perception capabilities. However, their reasoning process often remains a \"fast thinking\" paradigm, reliant on end-to-end generation or explicit, language-centric chains of thought (CoT), which can be inefficient, verbose, and prone to hallucination. This work posits that robust reasoning should evolve within a latent space, integrating multimodal signals seamlessly. We propose multimodal latent reasoning via HIerarchical Visual cuEs injection (\\emph{HIVE}), a novel framework that instills deliberate, \"slow thinking\" without depending on superficial textual rationales. Our method recursively extends transformer blocks, creating an internal loop for iterative reasoning refinement. Crucially, it injectively grounds this process with hierarchical visual cues from global scene context to fine-grained regional details directly into the model's latent representations. This enables the model to perform grounded, multi-step inference entirely in the aligned latent space. Extensive evaluations demonstrate that test-time scaling is effective when incorporating vision knowledge, and that integrating hierarchical information significantly enhances the model's understanding of complex scenes.", "AI": {"tldr": "本文提出了一种通过层次视觉线索注入进行多模态隐式推理的框架，称为HIVE，旨在提升大型语言模型在复杂场景中的理解能力。", "motivation": "当前的多模态大语言模型存在依靠快速思考模式和表面文本理由导致效率低下、冗长且容易产生幻觉的问题。作者认为通过层次化的视觉线索注入可以实现更稳健的推理过程，从而增强模型的理解能力。", "method": "提出了一种名为HIVE的新框架，该框架将变压器块递归扩展以创建内部循环进行迭代推理细化，并将多层次视觉线索从全局场景上下文到细粒度区域细节直接注入模型的隐式表示中。这种做法允许模型在对齐的隐式空间内执行基于事实的多步推断。", "result": "实验评估显示，在测试时引入视觉知识可以有效扩展，同时整合层次信息显著增强了模型对于复杂场景的理解。", "conclusion": "通过引入HIVE框架，能够在不依赖表面文本理由的情况下进行深入思考，提高模型在处理复杂场景时的表现。"}}
{"id": "2602.05354", "pdf": "https://arxiv.org/pdf/2602.05354", "abs": "https://arxiv.org/abs/2602.05354", "authors": ["Shifat E. Arman", "Syed Nazmus Sakib", "Tapodhir Karmakar Taton", "Nafiul Haque", "Shahrear Bin Amin"], "title": "PATHWAYS: Evaluating Investigation and Context Discovery in AI Web Agents", "categories": ["cs.AI"], "comment": "35 pages, 13 figures", "summary": "We introduce PATHWAYS, a benchmark of 250 multi-step decision tasks that test whether web-based agents can discover and correctly use hidden contextual information. Across both closed and open models, agents typically navigate to relevant pages but retrieve decisive hidden evidence in only a small fraction of cases. When tasks require overturning misleading surface-level signals, performance drops sharply to near chance accuracy. Agents frequently hallucinate investigative reasoning by claiming to rely on evidence they never accessed. Even when correct context is discovered, agents often fail to integrate it into their final decision. Providing more explicit instructions improves context discovery but often reduces overall accuracy, revealing a tradeoff between procedural compliance and effective judgement. Together, these results show that current web agent architectures lack reliable mechanisms for adaptive investigation, evidence integration, and judgement override.", "AI": {"tldr": "PATHWAYS 是一个由250个任务组成的基准测试，旨在评估基于AI的网络代理发现和正确使用隐藏上下文信息的能力。", "motivation": "为了研究当前AI网络代理在多步骤决策任务中是否能够有效发现和利用隐藏的上下文信息而设计了PATHWAYS。", "method": "通过PATHWAYS基准测试，研究人员评估了各种模型在网络代理中的表现，并观察它们如何处理误导性的表面信号以及整合找到的正确上下文进行最终判断的能力。", "result": "大多数情况下，网络代理能够在相关页面间导航，但在检索决定性隐藏证据方面成功率很低。在需要反驳误导表面信息的任务中，其性能会显著下降接近随机水平。此外，即使找到了正确的上下文，网络代理也经常无法将其整合到最终决策中。提供更明确的指令虽然提高了上下文发现能力但降低了总体准确性。", "conclusion": "目前基于AI的网络代理架构在适应性调查、证据整合和判断重置方面缺乏可靠机制"}}
{"id": "2602.05353", "pdf": "https://arxiv.org/pdf/2602.05353", "abs": "https://arxiv.org/abs/2602.05353", "authors": ["Ruijie Shi", "Houbin Zhang", "Yuecheng Han", "Yuheng Wang", "Jingru Fan", "Runde Yang", "Yufan Dang", "Huatao Li", "Dewen Liu", "Yuan Cheng", "Chen Qian"], "title": "AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration, many deployed agentic systems operate as black boxes to users. We address this by introducing Agentic Workflow Reconstruction (AWR), a new task aiming to synthesize an explicit, interpretable stand-in workflow that approximates a black-box system using only input--output access. We propose AgentXRay, a search-based framework that formulates AWR as a combinatorial optimization problem over discrete agent roles and tool invocations in a chain-structured workflow space. Unlike model distillation, AgentXRay produces editable white-box workflows that match target outputs under an observable, output-based proxy metric, without accessing model parameters. To navigate the vast search space, AgentXRay employs Monte Carlo Tree Search enhanced by a scoring-based Red-Black Pruning mechanism, which dynamically integrates proxy quality with search depth. Experiments across diverse domains demonstrate that AgentXRay achieves higher proxy similarity and reduces token consumption compared to unpruned search, enabling deeper workflow exploration under fixed iteration budgets.", "AI": {"tldr": "AgentXRay通过输入输出访问来合成可解释的工作流程，以近似黑盒系统的内部机制。", "motivation": "许多部署的代理系统对用户来说是不透明且难以控制的。本文旨在解决这一问题，提出Agentic Workflow Reconstruction（AWR）任务，用于生成一个可以替代原始黑盒系统的可解释工作流程。", "method": "AgentXRay是一个基于搜索的方法，它将AWR转化为一种组合优化问题，并使用蒙特卡洛树搜索结合红黑剪枝机制来导航巨大的搜索空间。这种方法在不需要访问模型参数的情况下，生成匹配目标输出的可编辑白盒工作流程。", "result": "实验表明，AgentXRay达到了更高的代理相似度并减少了token消耗，在相同的迭代预算下实现了更深层次的工作流程探索。", "conclusion": "AgentXRay提供了一种有效的方法来构造近似黑盒系统的解释性工作流程，为理解和控制复杂的代理系统提供了新的途径。"}}
{"id": "2602.05349", "pdf": "https://arxiv.org/pdf/2602.05349", "abs": "https://arxiv.org/abs/2602.05349", "authors": ["Ningkang Peng", "JiuTao Zhou", "Yuhao Zhang", "Xiaoqian Peng", "Qianfeng Yu", "Linjing Qian", "Tingyu Lu", "Yi Chen", "Yanhui Gu"], "title": "Learning with Adaptive Prototype Manifolds for Out-of-Distribution Detection", "categories": ["cs.CV"], "comment": null, "summary": "Out-of-distribution (OOD) detection is a critical task for the safe deployment of machine learning models in the real world. Existing prototype-based representation learning methods have demonstrated exceptional performance. Specifically, we identify two fundamental flaws that universally constrain these methods: the Static Homogeneity Assumption (fixed representational resources for all classes) and the Learning-Inference Disconnect (discarding rich prototype quality knowledge at inference). These flaws fundamentally limit the model's capacity and performance. To address these issues, we propose APEX (Adaptive Prototype for eXtensive OOD Detection), a novel OOD detection framework designed via a Two-Stage Repair process to optimize the learned feature manifold. APEX introduces two key innovations to address these respective flaws: (1) an Adaptive Prototype Manifold (APM), which leverages the Minimum Description Length (MDL) principle to automatically determine the optimal prototype complexity $K_c^*$ for each class, thereby fundamentally resolving prototype collision; and (2) a Posterior-Aware OOD Scoring (PAOS) mechanism, which quantifies prototype quality (cohesion and separation) to bridge the learning-inference disconnect. Comprehensive experiments on benchmarks such as CIFAR-100 validate the superiority of our method, where APEX achieves new state-of-the-art performance.", "AI": {"tldr": "提出了一种新的原型自适应方法APEX，用于改进出分布检测。", "motivation": "现有原型基表示学习方法存在两个核心问题：静态同质假设和训练推理脱节，这些问题限制了模型性能。", "method": "通过两阶段修复过程优化学习到的特征流形，引入自适应原型流形APM和后验感知出分布评分PAOS机制。", "result": "实验表明，APEX在CIFAR-100等数据集上实现了最先进的性能。", "conclusion": "该方法解决了现有模型中的核心问题，并显著提高了出分布检测的准确性。"}}
{"id": "2602.05339", "pdf": "https://arxiv.org/pdf/2602.05339", "abs": "https://arxiv.org/abs/2602.05339", "authors": ["Yongwoo Kim", "Sungmin Cha", "Hyunsoo Kim", "Jaewon Lee", "Donghyun Kim"], "title": "Consistency-Preserving Concept Erasure via Unsafe-Safe Pairing and Directional Fisher-weighted Adaptation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "With the increasing versatility of text-to-image diffusion models, the ability to selectively erase undesirable concepts (e.g., harmful content) has become indispensable. However, existing concept erasure approaches primarily focus on removing unsafe concepts without providing guidance toward corresponding safe alternatives, which often leads to failure in preserving the structural and semantic consistency between the original and erased generations. In this paper, we propose a novel framework, PAIRed Erasing (PAIR), which reframes concept erasure from simple removal to consistency-preserving semantic realignment using unsafe-safe pairs. We first generate safe counterparts from unsafe inputs while preserving structural and semantic fidelity, forming paired unsafe-safe multimodal data. Leveraging these pairs, we introduce two key components: (1) Paired Semantic Realignment, a guided objective that uses unsafe-safe pairs to explicitly map target concepts to semantically aligned safe anchors; and (2) Fisher-weighted Initialization for DoRA, which initializes parameter-efficient low-rank adaptation matrices using unsafe-safe pairs, encouraging the generation of safe alternatives while selectively suppressing unsafe concepts. Together, these components enable fine-grained erasure that removes only the targeted concepts while maintaining overall semantic consistency. Extensive experiments demonstrate that our approach significantly outperforms state-of-the-art baselines, achieving effective concept erasure while preserving structural integrity, semantic coherence, and generation quality.", "AI": {"tldr": "本文提出了一种新型框架PAIR，用于通过unsafe-safe配对和方向Fisher加权适应来实现一致性保持的概念擦除。", "motivation": "现有概念擦除方法主要集中在移除不安全概念上，而缺乏向安全替代方案的引导，导致原始内容与擦除后内容之间在结构和语义上的连贯性受损。因此，本文提出一种能够同时保留结构和语义一致性的新型框架。", "method": "该框架利用unsafe-safe配对生成具有结构和语义保真度的安全对应体，并引入两个关键组件：成对标记的语义重新调整和Fisher加权初始化，前者使用成对数据来明确地映射目标概念到安全锚点；后者则通过低秩适应矩阵实现擦除。", "result": "实验结果显示该方法在移除特定概念的同时保持结构完整性和语义连贯性方面显著优于现有基准方法。", "conclusion": "本文提出的PAIR框架能够更有效地进行概念擦除，并且在保留文本图像生成的质量、结构完整性和语义一致性方面的表现尤为突出。"}}
{"id": "2602.05330", "pdf": "https://arxiv.org/pdf/2602.05330", "abs": "https://arxiv.org/abs/2602.05330", "authors": ["Jingdong Zhang", "Xiaohang Zhan", "Lingzhi Zhang", "Yizhou Wang", "Zhengming Yu", "Jionghao Wang", "Wenping Wang", "Xin Li"], "title": "MTPano: Multi-Task Panoramic Scene Understanding via Label-Free Integration of Dense Prediction Priors", "categories": ["cs.CV"], "comment": null, "summary": "Comprehensive panoramic scene understanding is critical for immersive applications, yet it remains challenging due to the scarcity of high-resolution, multi-task annotations. While perspective foundation models have achieved success through data scaling, directly adapting them to the panoramic domain often fails due to severe geometric distortions and coordinate system discrepancies. Furthermore, the underlying relations between diverse dense prediction tasks in spherical spaces are underexplored. To address these challenges, we propose MTPano, a robust multi-task panoramic foundation model established by a label-free training pipeline. First, to circumvent data scarcity, we leverage powerful perspective dense priors. We project panoramic images into perspective patches to generate accurate, domain-gap-free pseudo-labels using off-the-shelf foundation models, which are then re-projected to serve as patch-wise supervision. Second, to tackle the interference between task types, we categorize tasks into rotation-invariant (e.g., depth, segmentation) and rotation-variant (e.g., surface normals) groups. We introduce the Panoramic Dual BridgeNet, which disentangles these feature streams via geometry-aware modulation layers that inject absolute position and ray direction priors. To handle the distortion from equirectangular projections (ERP), we incorporate ERP token mixers followed by a dual-branch BridgeNet for interactions with gradient truncation, facilitating beneficial cross-task information sharing while blocking conflicting gradients from incompatible task attributes. Additionally, we introduce auxiliary tasks (image gradient, point map, etc.) to fertilize the cross-task learning process. Extensive experiments demonstrate that MTPano achieves state-of-the-art performance on multiple benchmarks and delivers competitive results against task-specific panoramic specialist foundation models.", "AI": {"tldr": "MTPano 是一种多任务全景基础模型，通过无标签训练流程解决高分辨率多任务标注稀缺的问题。", "motivation": "全景场景理解对于沉浸式应用至关重要，但由于高分辨率、多任务标注的稀缺性以及透视基础模型难以直接适应于全景领域的几何失真问题而面临挑战。为了解决这些问题并探索球形空间中不同密集预测任务之间的关系，提出了MTPano。", "method": "首先，通过利用强大的透视密集先验解决数据稀缺的问题；然后引入Panoramic Dual BridgeNet来分类处理旋转不变和旋转变的任务类型，并采用几何感知调制层注入绝对位置和射线方向的先验知识以减少任务间干扰。此外，还提出了辅助任务（如图像梯度、点地图等）用于促进跨任务学习过程。", "result": "MTPano在多个基准测试上取得了最先进的性能，并且与特定任务的专业全景基础模型相比具有竞争力的结果。", "conclusion": "MTPano通过无标签训练流程和Panoramic Dual BridgeNet解决了多任务全景理解中的主要挑战，展示了良好的跨任务信息共享能力及几何一致性。"}}
{"id": "2602.05327", "pdf": "https://arxiv.org/pdf/2602.05327", "abs": "https://arxiv.org/abs/2602.05327", "authors": ["Yangbin Yu", "Mingyu Yang", "Junyou Li", "Yiming Gao", "Feiyu Liu", "Yijun Yang", "Zichuan Lin", "Jiafei Lyu", "Yicheng Liu", "Zhicong Lu", "Deheng Ye", "Jie Jiang"], "title": "ProAct: Agentic Lookahead in Interactive Environments", "categories": ["cs.AI"], "comment": null, "summary": "Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct", "AI": {"tldr": "本文提出ProAct框架，旨在解决大型语言模型在互动环境中进行长期规划的挑战。", "motivation": "现有LLM代理在需要长时间规划的互动环境中表现不佳，主要原因是模拟未来状态时错误积累。因此，研究者希望通过内部化准确前瞻推理来提高性能。", "method": "ProAct采用两阶段训练模式：首先通过GLAD进行有监督微调以学习展望逻辑；其次使用MC-Critic辅助价值估计器提高决策准确性。这些方法旨在减少计算负担并稳定策略优化。", "result": "实验表明，与开源基准相比，使用ProAct的模型在规划准确性和环境泛化方面表现出色，并可匹敌最先进的闭源模型。", "conclusion": "ProAct框架通过创新训练和优化技术显著提升了代理在互动环境中执行长期规划的能力。"}}
{"id": "2602.05325", "pdf": "https://arxiv.org/pdf/2602.05325", "abs": "https://arxiv.org/abs/2602.05325", "authors": ["Jiacheng Fan", "Zhiyue Zhao", "Yiqian Zhang", "Chao Chen", "Peide Wang", "Hengdi Zhang", "Zhengxue Cheng"], "title": "RoboPaint: From Human Demonstration to Any Robot and Any View", "categories": ["cs.RO"], "comment": "17 pages", "summary": "Acquiring large-scale, high-fidelity robot demonstration data remains a critical bottleneck for scaling Vision-Language-Action (VLA) models in dexterous manipulation. We propose a Real-Sim-Real data collection and data editing pipeline that transforms human demonstrations into robot-executable, environment-specific training data without direct robot teleoperation. Standardized data collection rooms are built to capture multimodal human demonstrations (synchronized 3 RGB-D videos, 11 RGB videos, 29-DoF glove joint angles, and 14-channel tactile signals). Based on these human demonstrations, we introduce a tactile-aware retargeting method that maps human hand states to robot dex-hand states via geometry and force-guided optimization. Then the retargeted robot trajectories are rendered in a photorealistic Isaac Sim environment to build robot training data. Real world experiments have demonstrated: (1) The retargeted dex-hand trajectories achieve an 84\\% success rate across 10 diverse object manipulation tasks. (2) VLA policies (Pi0.5) trained exclusively on our generated data achieve 80\\% average success rate on three representative tasks, i.e., pick-and-place, pushing and pouring. To conclude, robot training data can be efficiently \"painted\" from human demonstrations using our real-sim-real data pipeline. We offer a scalable, cost-effective alternative to teleoperation with minimal performance loss for complex dexterous manipulation.", "AI": {"tldr": "从人类演示中生成机器人可执行的数据，用于复杂操作任务的训练。", "motivation": "大规模高质量机器人示范数据获取困难，限制了视觉语言行动模型在灵巧操纵中的应用。需要一种方法将人类演示转换为特定环境下的机器人训练数据，而无需直接机器人遥控行动。", "method": "建立标准化的数据采集室以捕捉多模态的人类演示；提出基于触觉感知的再映射技术，通过几何和力导向优化将人类手势转译到机器人手中；在光物理真实的Isaac Sim环境中渲染重构后的机器人轨迹以构建训练数据集。", "result": "重新目标化的dex-hand轨迹在十种不同的物体操作任务中实现了84%的成功率，而基于生成的数据训练的视觉语言行动策略(Pi0.5)在三种代表性任务中的平均成功率为80％。", "conclusion": "通过real-sim-real数据管道可以有效地将人类演示转换为机器人可执行的训练数据，并提供了一种比直接遥控行动更有效率且性能损失小得多的方法来处理复杂的灵巧操作问题。"}}
{"id": "2602.05324", "pdf": "https://arxiv.org/pdf/2602.05324", "abs": "https://arxiv.org/abs/2602.05324", "authors": ["Mahdis Rabbani", "Navid Mojahed", "Shima Nazari"], "title": "A Data Driven Structural Decomposition of Dynamic Games via Best Response Maps", "categories": ["cs.GT", "cs.MA", "cs.RO", "eess.SY", "math.OC"], "comment": "11 pages, 6 figures, 5 tables, Submitted to RSS 2026", "summary": "Dynamic games are powerful tools to model multi-agent decision-making, yet computing Nash (generalized Nash) equilibria remains a central challenge in such settings. Complexity arises from tightly coupled optimality conditions, nested optimization structures, and poor numerical conditioning. Existing game-theoretic solvers address these challenges by directly solving the joint game, typically requiring explicit modeling of all agents' objective functions and constraints, while learning-based approaches often decouple interaction through prediction or policy approximation, sacrificing equilibrium consistency. This paper introduces a conceptually novel formulation for dynamic games by restructuring the equilibrium computation. Rather than solving a fully coupled game or decoupling agents through prediction or policy approximation, a data-driven structural reduction of the game is proposed that removes nested optimization layers and derivative coupling by embedding an offline-compiled best-response map as a feasibility constraint. Under standard regularity conditions, when the best-response operator is exact, any converged solution of the reduced problem corresponds to a local open-loop Nash (GNE) equilibrium of the original game; with a learned surrogate, the solution is approximately equilibrium-consistent up to the best-response approximation error. The proposed formulation is supported by mathematical proofs, accompanying a large-scale Monte Carlo study in a two-player open-loop dynamic game motivated by the autonomous racing problem. Comparisons are made against state-of-the-art joint game solvers, and results are reported on solution quality, computational cost, and constraint satisfaction.", "AI": {"tldr": "本文提出了一种新的动态博弈的结构化分解方法，通过数据驱动的方式减少嵌套优化层和导数耦合。", "motivation": "解决动态博弈中由于紧密耦合的最佳性条件、嵌套优化结构以及数值不良状况而导致计算纳什均衡的困难。", "method": "使用离线编译的最佳响应图作为可行性约束，提出一种数据驱动的方法减少游戏中的嵌套优化层和导数耦合。在标准正则条件下，当最佳响应操作准确时，任何收敛解对应于原始博弈的局部开环纳什均衡；而使用近似模型时，解仅在最佳响应误差范围内与平衡一致。", "result": "通过大型蒙特卡洛研究，在双玩家的开放循环动态博弈中验证了所提出的方法的有效性，并且结果优于现有方法在解质量、计算成本和约束满意度方面。", "conclusion": "该方法能够有效地解决多代理决策中的纳什均衡问题，特别是在复杂的游戏环境中。"}}
{"id": "2602.05323", "pdf": "https://arxiv.org/pdf/2602.05323", "abs": "https://arxiv.org/abs/2602.05323", "authors": ["Zifan Liu", "Xinran Li", "Shibo Chen", "Jun Zhang"], "title": "GAS: Enhancing Reward-Cost Balance of Generative Model-assisted Offline Safe RL", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline Safe Reinforcement Learning (OSRL) aims to learn a policy to achieve high performance in sequential decision-making while satisfying constraints, using only pre-collected datasets. Recent works, inspired by the strong capabilities of Generative Models (GMs), reformulate decision-making in OSRL as a conditional generative process, where GMs generate desirable actions conditioned on predefined reward and cost values. However, GM-assisted methods face two major challenges in OSRL: (1) lacking the ability to \"stitch\" optimal transitions from suboptimal trajectories within the dataset, and (2) struggling to balance reward targets with cost targets, particularly when they are conflict. To address these issues, we propose Goal-Assisted Stitching (GAS), a novel algorithm designed to enhance stitching capabilities while effectively balancing reward maximization and constraint satisfaction. To enhance the stitching ability, GAS first augments and relabels the dataset at the transition level, enabling the construction of high-quality trajectories from suboptimal ones. GAS also introduces novel goal functions, which estimate the optimal achievable reward and cost goals from the dataset. These goal functions, trained using expectile regression on the relabeled and augmented dataset, allow GAS to accommodate a broader range of reward-cost return pairs and achieve a better tradeoff between reward maximization and constraint satisfaction compared to human-specified values. The estimated goals then guide policy training, ensuring robust performance under constrained settings. Furthermore, to improve training stability and efficiency, we reshape the dataset to achieve a more uniform reward-cost return distribution. Empirical results validate the effectiveness of GAS, demonstrating superior performance in balancing reward maximization and constraint satisfaction compared to existing methods.", "AI": {"tldr": "GAS算法旨在增强生成模型辅助的离线安全强化学习中奖励与成本之间的平衡。", "motivation": "针对生成模型在离线安全强化学习中的两个主要挑战：无法从子优轨迹中构造最优过渡和难以协调奖励目标与成本目标，特别是在两者冲突的情况下。提出GAS算法来解决这些问题。", "method": "通过增强并重新标记数据集以构建高质量的轨迹，并引入新的目标函数来估计最佳可实现奖励和成本目标，同时调整数据分布以提高训练稳定性和效率。", "result": "实验结果表明，GAS在平衡奖励最大化与约束满足方面优于现有方法。", "conclusion": "GAS通过增强过渡能力和优化目标设置，在离线安全强化学习中显著提高了奖励-成本平衡的性能。"}}
{"id": "2602.05321", "pdf": "https://arxiv.org/pdf/2602.05321", "abs": "https://arxiv.org/abs/2602.05321", "authors": ["Dongki Jung", "Jaehoon Choi", "Adil Qureshi", "Somi Jeong", "Dinesh Manocha", "Suyong Yeon"], "title": "Wid3R: Wide Field-of-View 3D Reconstruction via Camera Model Conditioning", "categories": ["cs.CV"], "comment": null, "summary": "We present Wid3R, a feed-forward neural network for visual geometry reconstruction that supports wide field-of-view camera models. Prior methods typically assume that input images are rectified or captured with pinhole cameras, since both their architectures and training datasets are tailored to perspective images only. These assumptions limit their applicability in real-world scenarios that use fisheye or panoramic cameras and often require careful calibration and undistortion. In contrast, Wid3R is a generalizable multi-view 3D estimation method that can model wide field-of-view camera types. Our approach leverages a ray representation with spherical harmonics and a novel camera model token within the network, enabling distortion-aware 3D reconstruction. Furthermore, Wid3R is the first multi-view foundation model to support feed-forward 3D reconstruction directly from 360 imagery. It demonstrates strong zero-shot robustness and consistently outperforms prior methods, achieving improvements of up to +77.33 on Stanford2D3D.", "AI": {"tldr": "本文提出了一种名为Wid3R的前馈神经网络，用于支持广角相机模型的视觉几何重建。", "motivation": "现有方法通常假设输入图像已经被校正或由针孔相机捕获，并且它们的架构和训练数据集只适用于透视图。然而，在使用鱼眼或全景相机的真实场景中，这些假设限制了方法的应用性，因为这些场景往往需要仔细的校准和去畸变。", "method": "Wid3R采用射线表示和球谐函数，并在神经网络中引入了一个新的相机模型令牌，能够实现对图像畸变感知的三维重建。它是一种泛化的多视图三维估计方法，首次支持从全景影像进行前馈三维重建。", "result": "Wid3R展示了强大的零样本鲁棒性，在Stanford2D3D数据集上实现了最高77.33%的性能提升，并且始终优于现有方法。", "conclusion": "该研究提出了一种新的神经网络模型，克服了传统三维重建方法对图像畸变和相机类型的局限性，提高了在实际应用中的适应性和准确性。"}}
{"id": "2602.05311", "pdf": "https://arxiv.org/pdf/2602.05311", "abs": "https://arxiv.org/abs/2602.05311", "authors": ["Chengxiao Wang", "Haoze Wu", "Gagandeep Singh"], "title": "Formal Synthesis of Certifiably Robust Neural Lyapunov-Barrier Certificates", "categories": ["cs.LG", "cs.AI", "cs.RO", "eess.SY"], "comment": null, "summary": "Neural Lyapunov and barrier certificates have recently been used as powerful tools for verifying the safety and stability properties of deep reinforcement learning (RL) controllers. However, existing methods offer guarantees only under fixed ideal unperturbed dynamics, limiting their reliability in real-world applications where dynamics may deviate due to uncertainties. In this work, we study the problem of synthesizing \\emph{robust neural Lyapunov barrier certificates} that maintain their guarantees under perturbations in system dynamics. We formally define a robust Lyapunov barrier function and specify sufficient conditions based on Lipschitz continuity that ensure robustness against bounded perturbations. We propose practical training objectives that enforce these conditions via adversarial training, Lipschitz neighborhood bound, and global Lipschitz regularization. We validate our approach in two practically relevant environments, Inverted Pendulum and 2D Docking. The former is a widely studied benchmark, while the latter is a safety-critical task in autonomous systems. We show that our methods significantly improve both certified robustness bounds (up to $4.6$ times) and empirical success rates under strong perturbations (up to $2.4$ times) compared to the baseline. Our results demonstrate effectiveness of training robust neural certificates for safe RL under perturbations in dynamics.", "AI": {"tldr": "研究合成鲁棒神经Lyapunov障碍证书，以确保在系统动态变化时的稳定性与安全性。", "motivation": "现有方法仅适用于理想未扰动的动力学环境，在实际应用中由于不确定性导致动力学变化，这些方法的可靠性有限。因此需要一种能够保证在有界扰动下仍有效的鲁棒神经Lyapunov障碍证书的方法。", "method": "定义了鲁棒的Lyapunov障碍函数，并基于Lipschitz连续性提出了确保其抗干扰能力的充分条件；通过对抗训练，Lipschitz邻域边界和全局Lipschitz正则化来强制执行这些条件。", "result": "在倒立摆和平面对接两个环境中验证了方法的有效性，与基线相比显著提高了鲁棒性的认证界限（最多4.6倍）以及在强扰动下成功的概率（最多2.4倍）。", "conclusion": "该研究展示了训练鲁棒神经证书对于保证动态变化下的安全强化学习任务的重要性。"}}
{"id": "2602.05310", "pdf": "https://arxiv.org/pdf/2602.05310", "abs": "https://arxiv.org/abs/2602.05310", "authors": ["Jipeng Kong", "Xinzhe Liu", "Yuhang Lin", "Jinrui Han", "Sören Schwertfeger", "Chenjia Bai", "Xuelong Li"], "title": "Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework", "categories": ["cs.RO"], "comment": "13 pages, 9 figures, conference", "summary": "Soccer presents a significant challenge for humanoid robots, demanding tightly integrated perception-action capabilities for tasks like perception-guided kicking and whole-body balance control. Existing approaches suffer from inter-module instability in modular pipelines or conflicting training objectives in end-to-end frameworks. We propose Perception-Action integrated Decision-making (PAiD), a progressive architecture that decomposes soccer skill acquisition into three stages: motion-skill acquisition via human motion tracking, lightweight perception-action integration for positional generalization, and physics-aware sim-to-real transfer. This staged decomposition establishes stable foundational skills, avoids reward conflicts during perception integration, and minimizes sim-to-real gaps. Experiments on the Unitree G1 demonstrate high-fidelity human-like kicking with robust performance under diverse conditions-including static or rolling balls, various positions, and disturbances-while maintaining consistent execution across indoor and outdoor scenarios. Our divide-and-conquer strategy advances robust humanoid soccer capabilities and offers a scalable framework for complex embodied skill acquisition. The project page is available at https://soccer-humanoid.github.io/.", "AI": {"tldr": "本文提出了一个分阶段的感知行动框架，用于人形机器人足球技能的学习。", "motivation": "现有的方法在模块化管道中存在模块间不稳定的问题或端到端框架中的训练目标冲突问题。为解决这些问题，提出了一个逐步的感知-动作集成决策架构。", "method": "该方法通过三个阶段来分解足球技巧的获取：运动技能的获得、轻量级感知行动整合以及物理感知的真实模拟转移。", "result": "实验表明，在室内和室外场景下，机器人能够执行高保真的人类踢球动作，并能处理各种条件下的干扰情况。", "conclusion": "这种方法提供了一个可扩展框架以实现复杂的身体技能的获取并提高了人形机器人的足球能力。"}}
{"id": "2602.05305", "pdf": "https://arxiv.org/pdf/2602.05305", "abs": "https://arxiv.org/abs/2602.05305", "authors": ["Zhuokun Chen", "Jianfei Cai", "Bohan Zhuang"], "title": "FlashBlock: Attention Caching for Efficient Long-Context Block Diffusion", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Generating long-form content, such as minute-long videos and extended texts, is increasingly important for modern generative models. Block diffusion improves inference efficiency via KV caching and block-wise causal inference and has been widely adopted in diffusion language models and video generation. However, in long-context settings, block diffusion still incurs substantial overhead from repeatedly computing attention over a growing KV cache. We identify an underexplored property of block diffusion: cross-step redundancy of attention within a block. Our analysis shows that attention outputs from tokens outside the current block remain largely stable across diffusion steps, while block-internal attention varies significantly. Based on this observation, we propose FlashBlock, a cached block-external attention mechanism that reuses stable attention output, reducing attention computation and KV cache access without modifying the diffusion process. Moreover, FlashBlock is orthogonal to sparse attention and can be combined as a complementary residual reuse strategy, substantially improving model accuracy under aggressive sparsification. Experiments on diffusion language models and video generation demonstrate up to 1.44$\\times$ higher token throughput and up to 1.6$\\times$ reduction in attention time, with negligible impact on generation quality. Project page: https://caesarhhh.github.io/FlashBlock/.", "AI": {"tldr": "提出FlashBlock机制，通过缓存跨步稳定的外部注意力来提高长上下文设置下的扩散模型效率。", "motivation": "在长时间内容生成中，尽管块式扩散技术提高了推理效率，但在长上下文场景下仍存在计算负担和存储开销问题。作者发现不同步骤之间存在的注意力输出冗余可以被利用以减少重复计算。", "method": "基于跨步稳定外部注意力的观察，设计了FlashBlock机制来缓存并复用这部分信息，从而降低整体注意力计算量和KV缓存访问次数，并与稀疏注意策略兼容提升模型性能。", "result": "实验表明，该方法可实现高达1.44倍的令牌吞吐量增长及最多1.6倍的关注时间减少，同时对生成质量影响甚微。", "conclusion": "FlashBlock成功解决了块式扩散在长上下文场景中的效率问题，并提供了与稀疏注意策略结合的有效方案。"}}
{"id": "2602.05302", "pdf": "https://arxiv.org/pdf/2602.05302", "abs": "https://arxiv.org/abs/2602.05302", "authors": ["Chris Zhu", "Sasha Cui", "Will Sanok Dufallo", "Runzhi Jin", "Zhen Xu", "Linjun Zhang", "Daylian Cain"], "title": "PieArena: Frontier Language Agents Achieve MBA-Level Negotiation Performance and Reveal Novel Behavioral Differences", "categories": ["cs.AI"], "comment": null, "summary": "We present an in-depth evaluation of LLMs' ability to negotiate, a central business task that requires strategic reasoning, theory of mind, and economic value creation. To do so, we introduce PieArena, a large-scale negotiation benchmark grounded in multi-agent interactions over realistic scenarios drawn from an MBA negotiation course at an elite business school. We find systematic evidence of AGI-level performance in which a representative frontier agent (GPT-5) matches or outperforms trained business-school students, despite a semester of general negotiation instruction and targeted coaching immediately prior to the task. We further study the effects of joint-intentionality agentic scaffolding and find asymmetric gains, with large improvements for mid- and lower-tier LMs and diminishing returns for frontier LMs. Beyond deal outcomes, PieArena provides a multi-dimensional negotiation behavioral profile, revealing novel cross-model heterogeneity, masked by deal-outcome-only benchmarks, in deception, computation accuracy, instruction compliance, and perceived reputation. Overall, our results suggest that frontier language agents are already intellectually and psychologically capable of deployment in high-stakes economic settings, but deficiencies in robustness and trustworthiness remain open challenges.", "AI": {"tldr": "评估大型语言模型在谈判任务中的能力，引入PieArena基准测试框架进行多代理互动。", "motivation": "研究大型语言模型是否能在需要策略性思考、理论思维和经济价值创造的商业谈判中达到甚至超越人类表现水平。", "method": "使用PieArena，一个基于真实业务场景的大规模谈判基准测试，对比前沿语言模型与经过训练的商学院学生的表现，并分析不同层次的语言模型在代理间意向性和结构化支持下的表现差异。", "result": "发现前沿语言模型（如GPT-5）能在商务谈判中达到或超过人类水平；存在模型性能提升的不对称性，即中低端和较低端的语言模型受益更多。此外，还揭示了不同模型之间在欺骗、计算准确性、指令遵从性和感知信誉等方面的新型行为差异。", "conclusion": "前沿语言模型已经在智力和心理上具备应对高风险经济环境的能力，但在鲁棒性和可信度方面仍面临挑战。"}}
{"id": "2602.05299", "pdf": "https://arxiv.org/pdf/2602.05299", "abs": "https://arxiv.org/abs/2602.05299", "authors": ["Kashif Imteyaz", "Michael Muller", "Claudia Flores-Saviaga", "Saiph Savage"], "title": "Co-Designing Collaborative Generative AI Tools for Freelancers", "categories": ["cs.HC"], "comment": null, "summary": "Most generative AI tools prioritize individual productivity and personalization, with limited support for collaboration. Designed for traditional workplaces, these tools do not fit freelancers' short-term teams or lack of shared institutional support, which can worsen their isolation and overlook freelancing platform dynamics. This mismatch means that, instead of empowering freelancers, current generative AI tools could reinforce existing precarity and make freelancer collaboration harder. To investigate how to design generative AI tools to support freelancer collaboration, we conducted co-design sessions with 27 freelancers. A key concern that emerged was the risk of AI systems compromising their creative agency and work identities when collaborating, especially when AI tools could reproduce content without attribution, threatening the authenticity and distinctiveness of their collaborative work. Freelancers proposed \"auxiliary AI\" systems, human-guided tools that support their creative agencies and identities, allowing for flexible freelancer-led collaborations that promote \"productive friction\". Drawing on Marcuse's concept of technological rationality, we argue that freelancers are resisting one-dimensional, efficiency-driven AI, and instead envisioning technologies that preserve their collective creative agencies. We conclude with design recommendations for collaborative generative AI tools for freelancers.", "AI": {"tldr": "研究探讨了为自由职业者设计协作型生成式AI工具的方法，通过与27名自由职业者的共同设计会议来识别关键问题并提出解决方案。", "motivation": "目前的生成式AI工具侧重于个人效率和个性化，缺乏对自由职业者合作的支持。这些工具可能导致自由职业者的孤立感加剧，并忽视了协作平台的动力机制。", "method": "通过与27名自由职业者进行共同设计会议来收集意见和建议。", "result": "自由职业者提出了“辅助AI”系统的需求，这是一种由人类指导的工具，可以支持他们的创造性和身份认同。他们希望这种工具能够促进具有建设性摩擦的合作。", "conclusion": "研究提出设计协作型生成式AI工具的新方法，这些工具能更好地保护和增强自由职业者的集体创造力。"}}
{"id": "2602.05297", "pdf": "https://arxiv.org/pdf/2602.05297", "abs": "https://arxiv.org/abs/2602.05297", "authors": ["Seongyeub Chu", "Jongwoo Kim", "Mun Yong Yi"], "title": "Aspect-Aware MOOC Recommendation in a Heterogeneous Network", "categories": ["cs.AI"], "comment": null, "summary": "MOOC recommendation systems have received increasing attention to help learners navigate and select preferred learning content. Traditional methods such as collaborative filtering and content-based filtering suffer from data sparsity and over-specialization. To alleviate these limitations, graph-based approaches have been proposed; however, they still rely heavily on manually predefined metapaths, which often capture only superficial structural relationships and impose substantial burdens on domain experts as well as significant engineering costs. To overcome these limitations, we propose AMR (Aspect-aware MOOC Recommendation), a novel framework that models path-specific multiple aspects by embedding the semantic content of nodes within each metapath. AMR automatically discovers metapaths through bi-directional walks, derives aspect-aware path representations using a bi-LSTM-based encoder, and incorporates these representations as edge features in the learner-learner and KC-KC subgraphs to achieve fine-grained semantically informed KC recommendations. Extensive experiments on the large-scale MOOCCube and PEEK datasets show that AMR consistently outperforms state-of-the-art graph neural network baselines across key metrics such as HR@K and nDCG@K. Further analysis confirms that AMR effectively captures rich path-specific aspect information, allowing more accurate recommendations than those methods that rely solely on predefined metapaths. The code will be available upon accepted.", "AI": {"tldr": "提出了一种新的面向方面（Aspect-aware）的MOOC推荐框架AMR，用于提高学习者在大规模在线开放课程中内容选择的准确性。", "motivation": "传统的MOOC推荐系统方法存在数据稀疏性和过度专业化的问题，而基于图的方法虽有改进但仍依赖于手动定义元路径，这限制了其灵活性和实用性。因此提出一种自动发现并利用多方面信息的新框架来解决这些问题。", "method": "AMR通过双向行走自动探索元路径，并使用双层LSTM编码器生成面向方面的路径表示，这些表示作为边特征被集成到学习者与知识点子图中以提供更细致的推荐。", "result": "实验表明，在MOOCCube和PEEK数据集上，AMR在HR@K和nDCG@K等关键指标方面均优于当前最佳方法。进一步分析显示AMR能够有效捕捉元路径特定方面的信息。", "conclusion": "AMR框架通过自动发现和利用面向方面的多路径表示提高了推荐系统的准确性和灵活性，是一种改进现有MOOC推荐系统的方法。"}}
{"id": "2602.05293", "pdf": "https://arxiv.org/pdf/2602.05293", "abs": "https://arxiv.org/abs/2602.05293", "authors": ["Weilun Feng", "Mingqiang Wu", "Zhiliang Chen", "Chuanguang Yang", "Haotong Qin", "Yuqi Li", "Xiaokun Liu", "Guoxin Fan", "Zhulin An", "Libo Huang", "Yulun Zhang", "Michele Magno", "Yongjun Xu"], "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster", "categories": ["cs.CV"], "comment": null, "summary": "SAM3D enables scalable, open-world 3D reconstruction from complex scenes, yet its deployment is hindered by prohibitive inference latency. In this work, we conduct the \\textbf{first systematic investigation} into its inference dynamics, revealing that generic acceleration strategies are brittle in this context. We demonstrate that these failures stem from neglecting the pipeline's inherent multi-level \\textbf{heterogeneity}: the kinematic distinctiveness between shape and layout, the intrinsic sparsity of texture refinement, and the spectral variance across geometries. To address this, we present \\textbf{Fast-SAM3D}, a training-free framework that dynamically aligns computation with instantaneous generation complexity. Our approach integrates three heterogeneity-aware mechanisms: (1) \\textit{Modality-Aware Step Caching} to decouple structural evolution from sensitive layout updates; (2) \\textit{Joint Spatiotemporal Token Carving} to concentrate refinement on high-entropy regions; and (3) \\textit{Spectral-Aware Token Aggregation} to adapt decoding resolution. Extensive experiments demonstrate that Fast-SAM3D delivers up to \\textbf{2.67$\\times$} end-to-end speedup with negligible fidelity loss, establishing a new Pareto frontier for efficient single-view 3D generation. Our code is released in https://github.com/wlfeng0509/Fast-SAM3D.", "AI": {"tldr": "Fast-SAM3D 是一种加速单视图三维生成的方法，通过动态计算与即时生成复杂度对齐。", "motivation": "为了克服SAM3D在复杂的场景中进行大规模、开放世界的三维重建时所遇到的推理延迟问题，作者进行了系统性研究并揭示了通用加速策略在此上下文中的脆弱性。因此提出了Fast-SAM3D框架来解决这些问题。", "method": "该方法包含了三个机制：(1) 模态感知步骤缓存以解耦结构演化和敏感布局更新；(2) 联合时空令牌裁剪以将细化集中在高熵区域上；以及(3) 光谱感知令牌聚合以适应解码分辨率。", "result": "实验表明，Fast-SAM3D 可以在不牺牲质量的情况下提供高达 2.67 倍的整体速度提升。", "conclusion": "该论文提出的Fast-SAM3D框架成功解决了SAM3D的推理延迟问题，并通过引入新的加速机制实现了高效的单视图三维生成。"}}
{"id": "2602.05289", "pdf": "https://arxiv.org/pdf/2602.05289", "abs": "https://arxiv.org/abs/2602.05289", "authors": ["Jingru Fan", "Dewen Liu", "Yufan Dang", "Huatao Li", "Yuheng Wang", "Wei Liu", "Feiyu Duan", "Xuanwen Ding", "Shu Yao", "Lin Wu", "Ruijie Shi", "Wai-Shing Leung", "Yuan Cheng", "Zhongyu Wei", "Cheng Yang", "Chen Qian", "Zhiyuan Liu", "Maosong Sun"], "title": "Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progress, the field still relies heavily on empirical trial-and-error. It lacks a unified and principled scientific framework necessary for systematic optimization and improvement. This bottleneck stems from the ambiguity of attribution: first, the absence of a structured taxonomy of factors leaves researchers restricted to unguided adjustments; second, the lack of a unified metric fails to distinguish genuine collaboration gain from mere resource accumulation. In this paper, we advocate for a transition to design science through an integrated framework. We advocate to establish the collaboration gain metric ($Γ$) as the scientific standard to isolate intrinsic gains from increased budgets. Leveraging $Γ$, we propose a factor attribution paradigm to systematically identify collaboration-driving factors. To support this, we construct a systematic MAS factor library, structuring the design space into control-level presets and information-level dynamics. Ultimately, this framework facilitates the transition from blind experimentation to rigorous science, paving the way towards a true science of Collective AI.", "AI": {"tldr": "本文提出了一个基于LLM的多代理系统的综合框架，通过引入合作收益指标（Γ）和系统化因素库，实现从盲目实验到严谨科学的研究转变。", "motivation": "尽管大型语言模型在多代理系统中的应用取得了显著进展，但该领域仍然依赖于经验性的试错方法。缺乏统一的科学框架使得系统的优化和发展受限。", "method": "本文提出了一种基于Γ的合作收益度量标准，并构建了一个系统化的MAS因素库，以此来支持对合作驱动因素进行系统的识别和归因分析。", "result": "通过引入上述框架，可以区分真实的合作增益与单纯的资源积累，进而促进多代理系统设计的科学化发展。", "conclusion": "本文提出的方法为实现集体人工智能科学研究奠定了基础，并推动了从盲目试验向严谨科学转变的过程。"}}
{"id": "2602.05287", "pdf": "https://arxiv.org/pdf/2602.05287", "abs": "https://arxiv.org/abs/2602.05287", "authors": ["Xilin Dai", "Wanxu Cai", "Zhijian Xu", "Qiang Xu"], "title": "Position: Universal Time Series Foundation Models Rest on a Category Error", "categories": ["cs.AI"], "comment": "Position Paper", "summary": "This position paper argues that the pursuit of \"Universal Foundation Models for Time Series\" rests on a fundamental category error, mistaking a structural Container for a semantic Modality. We contend that because time series hold incompatible generative processes (e.g., finance vs. fluid dynamics), monolithic models degenerate into expensive \"Generic Filters\" that fail to generalize under distributional drift. To address this, we introduce the \"Autoregressive Blindness Bound,\" a theoretical limit proving that history-only models cannot predict intervention-driven regime shifts. We advocate replacing universality with a Causal Control Agent paradigm, where an agent leverages external context to orchestrate a hierarchy of specialized solvers, from frozen domain experts to lightweight Just-in-Time adaptors. We conclude by calling for a shift in benchmarks from \"Zero-Shot Accuracy\" to \"Drift Adaptation Speed\" to prioritize robust, control-theoretic systems.", "AI": {"tldr": "本文认为时间序列的通用基础模型存在范畴错误，提出因果控制代理范式，并呼吁从零样本准确度转向漂移适应速度的基准。", "motivation": "该文指出追求“通用时间序列基础模型”是一个根本性范畴错误，因为不同领域的生成过程不兼容，单一模型将退化为昂贵且无法泛化的滤波器。同时引入了自回归盲区界限理论限制证明历史数据模型不能预测干预驱动的制度变化。", "method": "本文提出了因果控制代理范式，其中代理利用外部上下文来协调一系列专门求解器，从冻结领域专家到即时适应器，并呼吁从零样本准确度转向漂移适应速度的基准。", "result": "论文通过理论分析证明了历史数据模型在预测干预驱动的制度变化时存在局限性，提出了因果控制代理范式的解决思路。", "conclusion": "文章建议将研究焦点从追求零样本准确性转移到更强调鲁棒性和控制论系统的漂移适应速度上。"}}
{"id": "2602.05286", "pdf": "https://arxiv.org/pdf/2602.05286", "abs": "https://arxiv.org/abs/2602.05286", "authors": ["Dahai Yu", "Lin Jiang", "Rongchao Xu", "Guang Wang"], "title": "HealthMamba: An Uncertainty-aware Spatiotemporal Graph State Space Model for Effective and Reliable Healthcare Facility Visit Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Healthcare facility visit prediction is essential for optimizing healthcare resource allocation and informing public health policy. Despite advanced machine learning methods being employed for better prediction performance, existing works usually formulate this task as a time-series forecasting problem without considering the intrinsic spatial dependencies of different types of healthcare facilities, and they also fail to provide reliable predictions under abnormal situations such as public emergencies. To advance existing research, we propose HealthMamba, an uncertainty-aware spatiotemporal framework for accurate and reliable healthcare facility visit prediction. HealthMamba comprises three key components: (i) a Unified Spatiotemporal Context Encoder that fuses heterogeneous static and dynamic information, (ii) a novel Graph State Space Model called GraphMamba for hierarchical spatiotemporal modeling, and (iii) a comprehensive uncertainty quantification module integrating three uncertainty quantification mechanisms for reliable prediction. We evaluate HealthMamba on four large-scale real-world datasets from California, New York, Texas, and Florida. Results show HealthMamba achieves around 6.0% improvement in prediction accuracy and 3.5% improvement in uncertainty quantification over state-of-the-art baselines.", "AI": {"tldr": "HealthMamba是一个用于准确和可靠预测医疗设施访问的不确定性感知时空框架", "motivation": "现有的医疗设施访问预测方法通常被建模为时间序列预测问题，忽略了不同类型医疗设施之间的内在空间依赖关系，并且在异常情况下（如公共紧急情况）无法提供可靠的预测。", "method": "HealthMamba包含三个关键组件：统一时空上下文编码器、图状态空间模型GraphMamba和不确定性量化模块，用于融合异构静态动态信息以及进行层次时空建模并集成三种不确定性量化机制。", "result": "在四个大规模真实世界数据集上的实验表明，HealthMamba比最先进的基线方法提高了约6.0%的预测准确率和3.5%的不确定性量化效果。", "conclusion": "该研究提出了一种新的不确定性感知时空框架HealthMamba，可以有效地改善医疗设施访问预测的准确性与可靠性。"}}
{"id": "2602.05279", "pdf": "https://arxiv.org/pdf/2602.05279", "abs": "https://arxiv.org/abs/2602.05279", "authors": ["Kim Hammar", "Tansu Alpcan", "Emil Lupu"], "title": "Hallucination-Resistant Security Planning with a Large Language Model", "categories": ["cs.AI", "cs.CR"], "comment": "Accepted to IEEE/IFIP Network Operations and Management Symposium 2026. To appear in the conference proceedings", "summary": "Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for using an LLM as decision support in security management. Our framework integrates the LLM in an iterative loop where it generates candidate actions that are checked for consistency with system constraints and lookahead predictions. When consistency is low, we abstain from the generated actions and instead collect external feedback, e.g., by evaluating actions in a digital twin. This feedback is then used to refine the candidate actions through in-context learning (ICL). We prove that this design allows to control the hallucination risk by tuning the consistency threshold. Moreover, we establish a bound on the regret of ICL under certain assumptions. To evaluate our framework, we apply it to an incident response use case where the goal is to generate a response and recovery plan based on system logs. Experiments on four public datasets show that our framework reduces recovery times by up to 30% compared to frontier LLMs.", "AI": {"tldr": "该论文提出了一种使用大型语言模型支持安全管理工作，特别是针对应急响应规划的框架，通过迭代反馈和一致性检查来减少模型错误", "motivation": "解决大型语言模型在安全管理工作中的不可靠性和幻觉问题", "method": "设计了一个迭代反馈循环框架，在每次生成动作时进行系统约束一致性和前瞻预测的一致性检查，并根据需要收集外部反馈以改进候选行动", "result": "实验结果显示，该方法可以将恢复时间减少多达30％", "conclusion": "所提出的框架在控制幻觉风险和提高决策支持方面是有效的"}}
{"id": "2602.05275", "pdf": "https://arxiv.org/pdf/2602.05275", "abs": "https://arxiv.org/abs/2602.05275", "authors": ["Qi Li", "Yanzhe Zhao", "Yongxin Zhou", "Yameng Wang", "Yandong Yang", "Yuanjia Zhou", "Jue Wang", "Zuojian Wang", "Jinxiang Liu"], "title": "Magic-MM-Embedding: Towards Visual-Token-Efficient Universal Multimodal Embedding with MLLMs", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have shown immense promise in universal multimodal retrieval, which aims to find relevant items of various modalities for a given query. But their practical application is often hindered by the substantial computational cost incurred from processing a large number of tokens from visual inputs. In this paper, we propose Magic-MM-Embedding, a series of novel models that achieve both high efficiency and state-of-the-art performance in universal multimodal embedding. Our approach is built on two synergistic pillars: (1) a highly efficient MLLM architecture incorporating visual token compression to drastically reduce inference latency and memory footprint, and (2) a multi-stage progressive training strategy designed to not only recover but significantly boost performance. This coarse-to-fine training paradigm begins with extensive continue pretraining to restore multimodal understanding and generation capabilities, progresses to large-scale contrastive pretraining and hard negative mining to enhance discriminative power, and culminates in a task-aware fine-tuning stage guided by an MLLM-as-a-Judge for precise data curation. Comprehensive experiments show that our model outperforms existing methods by a large margin while being more inference-efficient.", "AI": {"tldr": "Magic-MM-Embedding是一种新颖的模型，旨在通过视觉令牌压缩和多阶段训练策略来提高跨模态嵌入效率并保持高精度。", "motivation": "Multimodal Large Language Models (MLLMs)在通用跨模态检索中表现出巨大潜力，但由于处理大量视觉输入令牌所引起的计算成本高昂而难以实际应用。因此，开发一种既高效又准确的模型至关重要。", "method": "该方法基于两个主要支柱：一是包含视觉令牌压缩的高效MLLM架构以大幅减少推理延迟和内存占用；二是多阶段逐步训练策略以恢复并显著提高性能。此粗到细的训练范式从广泛的持续预训练开始，然后进行大规模对比预训练和硬负例挖掘，最终通过一个任务感知微调阶段来引导准确的数据选择。", "result": "实验结果表明，该模型在保持高效率的同时超过了现有方法的表现。", "conclusion": "Magic-MM-Embedding提供了一种有效的策略，既提高了跨模态嵌入的推理效率也保证了性能优越。"}}
{"id": "2602.05273", "pdf": "https://arxiv.org/pdf/2602.05273", "abs": "https://arxiv.org/abs/2602.05273", "authors": ["Hengxuan Xu", "Fengbo Lan", "Zhixin Zhao", "Shengjie Wang", "Mengqiao Liu", "Jieqian Sun", "Yu Cheng", "Tao Zhang"], "title": "Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions", "categories": ["cs.RO"], "comment": "14 pages, 10 figures, 8 tables", "summary": "Enabling robots to explore and act in unfamiliar environments under ambiguous human instructions by interactively identifying task-relevant objects (e.g., identifying cups or beverages for \"I'm thirsty\") remains challenging for existing vision-language model (VLM)-based methods. This challenge stems from inefficient reasoning and the lack of environmental interaction, which hinder real-time task planning and execution. To address this, We propose Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions (AIDE), a dual-stream framework that integrates interactive exploration with vision-language reasoning, where Multi-Stage Inference (MSI) serves as the decision-making stream and Accelerated Decision-Making (ADM) as the execution stream, enabling zero-shot affordance analysis and interpretation of ambiguous instructions. Extensive experiments in simulation and real-world environments show that AIDE achieves the task planning success rate of over 80\\% and more than 95\\% accuracy in closed-loop continuous execution at 10 Hz, outperforming existing VLM-based methods in diverse open-world scenarios.", "AI": {"tldr": "提出了一种新的框架AIDE，以解决机器人在模糊指令下执行任务的挑战。", "motivation": "现有方法难以使机器人在不熟悉的环境中根据模糊的人类指令有效地进行交互和识别相关对象。", "method": "提出了一个双流框架AIDE，结合了互动探索与视觉语言推理，通过多阶段推理（MSI）作为决策流，并加速决策执行（ADM）作为执行流，实现了零样本处理能力和对模糊指令的解释能力。", "result": "在仿真和现实环境中进行的大量实验表明，AIDE取得了超过80%的任务规划成功率以及在10Hz下超过95%的闭环连续执行准确率。", "conclusion": "AIDE框架展示了比现有视觉语言模型方法更好的性能，在多种开放世界场景中表现优越。"}}
{"id": "2602.05271", "pdf": "https://arxiv.org/pdf/2602.05271", "abs": "https://arxiv.org/abs/2602.05271", "authors": ["Shengqin Jiang", "Xiaoran Feng", "Yuankai Qi", "Haokui Zhang", "Renlong Hang", "Qingshan Liu", "Lina Yao", "Quan Z. Sheng", "Ming-Hsuan Yang"], "title": "Unlocking Prototype Potential: An Efficient Tuning Framework for Few-Shot Class-Incremental Learning", "categories": ["cs.CV"], "comment": "under review", "summary": "Few-shot class-incremental learning (FSCIL) seeks to continuously learn new classes from very limited samples while preserving previously acquired knowledge. Traditional methods often utilize a frozen pre-trained feature extractor to generate static class prototypes, which suffer from the inherent representation bias of the backbone. While recent prompt-based tuning methods attempt to adapt the backbone via minimal parameter updates, given the constraint of extreme data scarcity, the model's capacity to assimilate novel information and substantively enhance its global discriminative power is inherently limited. In this paper, we propose a novel shift in perspective: freezing the feature extractor while fine-tuning the prototypes. We argue that the primary challenge in FSCIL is not feature acquisition, but rather the optimization of decision regions within a static, high-quality feature space. To this end, we introduce an efficient prototype fine-tuning framework that evolves static centroids into dynamic, learnable components. The framework employs a dual-calibration method consisting of class-specific and task-aware offsets. These components function synergistically to improve the discriminative capacity of prototypes for ongoing incremental classes. Extensive results demonstrate that our method attains superior performance across multiple benchmarks while requiring minimal learnable parameters.", "AI": {"tldr": "提出了一种高效的原型微调框架，用于解决少样本类别增量学习中的决策区域优化问题。", "motivation": "传统方法依赖于冻结的预训练特征提取器生成静态类原型，容易受到表示偏差的影响。尽管最近的提示调整方法试图通过最小化参数更新来适应骨干网络，但在极端数据稀缺的情况下，模型吸收新信息和增强全局判别能力的能力有限。", "method": "提出了一种新的视角：冻结特征提取器并微调原型。引入了高效的原型微调框架，该框架将静态中心演变为动态可学习组件，并采用了类特定和任务感知偏移的双重校准方法以改进原型对增量类别判别能力。", "result": "实验结果表明，在多个基准上的性能优于现有方法，同时需要的可学习参数最少。", "conclusion": "通过冻结特征提取器并微调原型来优化决策区域是一种有效的策略，可以在少样本类别增量学习中获得更好的性能。"}}
{"id": "2602.05269", "pdf": "https://arxiv.org/pdf/2602.05269", "abs": "https://arxiv.org/abs/2602.05269", "authors": ["David Alejandro Trejo Pizzo"], "title": "Hybrid Gated Flow (HGF): Stabilizing 1.58-bit LLMs via Selective Low-Rank Correction", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "21 pages, 4 figures, 6 tables. Code and models will be released at opencores.ai", "summary": "The deployment of Large Language Models (LLMs) on edge devices is fundamentally constrained by the \"Memory Wall\" -- a hardware limitation where memory bandwidth, not compute, becomes the bottleneck. Recent 1.58-bit quantization techniques (e.g., BitNet b1.58) dramatically reduce memory footprint but typically incur a perplexity degradation of 20-25% compared to FP16 baselines. In this work, we introduce Hybrid Gated Flow (HGF), a dual-stream architecture that couples a 1.58-bit ternary backbone with a learnable, low-rank FP16 correction path controlled by adaptive gates. Through extensive experiments on the TinyStories dataset across two training regimes (2500 and 3500 steps), we demonstrate that HGF 5.4 achieves a validation loss of 0.9306 compared to BitNet's 1.0294, recovering approximately 55% of the quality gap between pure ternary quantization and the FP16 baseline (0.8490). This recovery is achieved with only ~12-15% memory overhead beyond the ternary backbone. Furthermore, we provide empirical evidence for an emergent phenomenon: quantization as structural regularization. While a full-precision differential attention baseline (Diff_Only) exhibited training instability with validation loss exceeding 1.68, the ternary-anchored HGF maintained robust convergence throughout training. Finally, we report preliminary results extending this architecture to 1.2B and 3B parameter models trained on SlimPajama and FineWeb-Edu. These larger-scale experiments confirm that the architectural stability and quality recovery observed in small-scale proxies scale linearly to production-grade language modeling regimes.", "AI": {"tldr": "提出Hybrid Gated Flow (HGF)架构，通过选择性低秩校正来稳定1.58位量化的大语言模型。", "motivation": "解决大语言模型在边缘设备部署时的“内存墙”问题，同时减少内存占用并保持性能。", "method": "设计双流架构，结合1.58位三进制主干和自适应控制的低秩FP16校正路径，实现内存效率和准确性的平衡。", "result": "HGF在TinyStories数据集上表现出色，验证损失为0.9306，相较于BitNet（1.0294）提升了大约55%的质量差距，并且仅增加了约12-15%的内存开销。同时，在更大规模模型上的实验也证实了该架构的有效性。", "conclusion": "HGF提供了一种有效的方法来提高低比特量化大语言模型的性能，同时保持较小的内存足迹和稳定的训练过程。"}}
{"id": "2602.05266", "pdf": "https://arxiv.org/pdf/2602.05266", "abs": "https://arxiv.org/abs/2602.05266", "authors": ["Xinbo Ai"], "title": "Beyond Cosine Similarity", "categories": ["cs.AI"], "comment": "18 pages, 2 figures, 1 theorem, 3 corollaries", "summary": "Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semantic spaces. We advance this theoretical underpinning by deriving a tighter upper bound for the dot product than the classical Cauchy-Schwarz bound. This new bound leads directly to recos, a similarity metric that normalizes the dot product by the sorted vector components. recos relaxes the condition for perfect similarity from strict linear dependence to ordinal concordance, thereby capturing a broader class of relationships. Extensive experiments across 11 embedding models--spanning static, contextualized, and universal types--demonstrate that recos consistently outperforms traditional cosine similarity, achieving higher correlation with human judgments on standard Semantic Textual Similarity (STS) benchmarks. Our work establishes recos as a mathematically principled and empirically superior alternative, offering enhanced accuracy for semantic analysis in complex embedding spaces.", "AI": {"tldr": "本文提出了一种新的相似度衡量标准recos，以改进传统的余弦相似性在捕捉复杂非线性结构中的限制。", "motivation": "传统余弦相似性的数学基础为柯西-施瓦茨不等式，这仅能捕获线性关系，并不能有效模拟现实世界语义空间的复杂非线性结构。因此作者寻求改进以更好地适应真实场景。", "method": "通过推导出点积的新上限来取代传统的柯西-施瓦茨界限，从而提出recos作为新的相似度衡量标准。该方法基于有序向量成分对点积进行归一化处理，放松了完美相似性的条件。", "result": "实验结果表明，在11种嵌入模型的测试中，recos在语义文本相似性(STS)基准上比传统余弦相似性获得了更高的与人工判断的相关性。", "conclusion": "本文提出的recos不仅具有数学上的理论基础而且在实证研究中表现优异，能够为复杂嵌入空间中的语义分析提供更准确的度量。"}}
{"id": "2602.05265", "pdf": "https://arxiv.org/pdf/2602.05265", "abs": "https://arxiv.org/abs/2602.05265", "authors": ["Kalvik Jakkala", "Jason O'Kane"], "title": "Low-Cost Underwater In-Pipe Centering and Inspection Using a Minimal-Sensing Robot", "categories": ["cs.RO"], "comment": null, "summary": "Autonomous underwater inspection of submerged pipelines is challenging due to confined geometries, turbidity, and the scarcity of reliable localization cues. This paper presents a minimal-sensing strategy that enables a free-swimming underwater robot to center itself and traverse a flooded pipe of known radius using only an IMU, a pressure sensor, and two sonars: a downward-facing single-beam sonar and a rotating 360 degree sonar. We introduce a computationally efficient method for extracting range estimates from single-beam sonar intensity data, enabling reliable wall detection in noisy and reverberant conditions. A closed-form geometric model leverages the two sonar ranges to estimate the pipe center, and an adaptive, confidence-weighted proportional-derivative (PD) controller maintains alignment during traversal. The system requires no Doppler velocity log, external tracking, or complex multi-sensor arrays. Experiments in a submerged 46 cm-diameter pipe using a Blue Robotics BlueROV2 heavy remotely operated vehicle demonstrate stable centering and successful full-pipe traversal despite ambient flow and structural deformations. These results show that reliable in-pipe navigation and inspection can be achieved with a lightweight, computationally efficient sensing and processing architecture, advancing the practicality of autonomous underwater inspection in confined environments.", "AI": {"tldr": "一种低成本的水下管道内中心定位和检测方法", "motivation": "水下自主管道检查面临几何限制，浑浊环境和可靠的定位线索稀缺等问题。本文提出了一种仅使用IMU、压力传感器和两个声纳（向下单波束声纳和旋转360度声纳）来实现无人水下机器人在已知半径的充满水的管道中自我中心化并穿越的方法，以解决这些问题。", "method": "一种从单波束声纳强度数据中提取距离估计的有效方法被引入，用于可靠地检测墙壁；通过两个声纳的距离范围估算管道中心，并利用自适应、置信度加权的比例-微分（PD）控制器保持在穿越过程中的对准。", "result": "实验在一个直径为46厘米的充满水的管道中使用Blue Robotics BlueROV2重型远程操作车辆进行，结果显示了即使在环境流动和结构变形的情况下也能实现稳定中心化和完整的管道穿越。这些结果表明，在轻量级、计算效率高的传感处理架构下，可以实现在狭小环境下的可靠管道导航和检查。", "conclusion": "本文的方法展示了通过简单的传感器配置实现水下管道自主检查的可能性，并提高了在受限环境中实施自主水下检查的实际性。"}}
{"id": "2602.05262", "pdf": "https://arxiv.org/pdf/2602.05262", "abs": "https://arxiv.org/abs/2602.05262", "authors": ["Junzhou Li", "Manqi Zhao", "Yilin Gao", "Zhiheng Yu", "Yin Li", "Dongsheng Jiang", "Li Xiao"], "title": "ReGLA: Efficient Receptive-Field Modeling with Gated Linear Attention Network", "categories": ["cs.CV"], "comment": "11 pages, 4 figures", "summary": "Balancing accuracy and latency on high-resolution images is a critical challenge for lightweight models, particularly for Transformer-based architectures that often suffer from excessive latency. To address this issue, we introduce \\textbf{ReGLA}, a series of lightweight hybrid networks, which integrates efficient convolutions for local feature extraction with ReLU-based gated linear attention for global modeling. The design incorporates three key innovations: the Efficient Large Receptive Field (ELRF) module for enhancing convolutional efficiency while preserving a large receptive field; the ReLU Gated Modulated Attention (RGMA) module for maintaining linear complexity while enhancing local feature representation; and a multi-teacher distillation strategy to boost performance on downstream tasks. Extensive experiments validate the superiority of ReGLA; particularly the ReGLA-M achieves \\textbf{80.85\\%} Top-1 accuracy on ImageNet-1K at $224px$, with only \\textbf{4.98 ms} latency at $512px$. Furthermore, ReGLA outperforms similarly scaled iFormer models in downstream tasks, achieving gains of \\textbf{3.1\\%} AP on COCO object detection and \\textbf{3.6\\%} mIoU on ADE20K semantic segmentation, establishing it as a state-of-the-art solution for high-resolution visual applications.", "AI": {"tldr": "提出了一种轻量级混合网络ReGLA，用于解决高分辨率图像上的精度和延迟平衡问题", "motivation": "为了在不牺牲准确性的前提下减少Transformer架构处理高分辨率图像时的延时问题", "method": "引入了Efficient Large Receptive Field (ELRF)模块增强卷积效率并保持大感受野；ReLU Gated Modulated Attention (RGMA) 模块维持线性复杂度同时提升局部特征表示；采用多教师蒸馏策略以提高下游任务性能", "result": "ReGLA-M在ImageNet-1K上达到80.85%的Top-1精度，仅需4.98ms延迟。在COCO对象检测和ADE20K语义分割等下游任务中优于类似规模的iFormer模型", "conclusion": "ReGLA证明了其作为高分辨率视觉应用中的先进解决方案的有效性"}}
{"id": "2602.05258", "pdf": "https://arxiv.org/pdf/2602.05258", "abs": "https://arxiv.org/abs/2602.05258", "authors": ["Haoran Li", "Sucheng Ren", "Alan Yuille", "Feng Wang"], "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.", "AI": {"tldr": "CoPE通过软剪切RoPE的低频成分来解决长上下文LLMs中的OOD问题和谱泄漏，从而提高模型性能。", "motivation": "现有方法在适应更长时间上下文时存在OOD问题或谱泄漏，为此提出新的策略以解决这些挑战性问题。", "method": "通过软剪切RoPE低频成分来统一OOd缓解与语义建模的目标，避免硬剪切造成的谱泄漏。", "result": "实验结果表明，在应用CoPE后模型在长达256k的上下文长度上性能显著提升。", "conclusion": "CoPE证明了软剪切RoPE的有效性，并确立其为长上下文泛化的新标杆。"}}
{"id": "2602.05257", "pdf": "https://arxiv.org/pdf/2602.05257", "abs": "https://arxiv.org/abs/2602.05257", "authors": ["Diya He", "Qingchen Liu", "Cong Zhang", "Jiahu Qin"], "title": "RFM-Pose:Reinforcement-Guided Flow Matching for Fast Category-Level 6D Pose Estimation", "categories": ["cs.CV", "cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Object pose estimation is a fundamental problem in computer vision and plays a critical role in virtual reality and embodied intelligence, where agents must understand and interact with objects in 3D space. Recently, score based generative models have to some extent solved the rotational symmetry ambiguity problem in category level pose estimation, but their efficiency remains limited by the high sampling cost of score-based diffusion. In this work, we propose a new framework, RFM-Pose, that accelerates category-level 6D object pose generation while actively evaluating sampled hypotheses. To improve sampling efficiency, we adopt a flow-matching generative model and generate pose candidates along an optimal transport path from a simple prior to the pose distribution. To further refine these candidates, we cast the flow-matching sampling process as a Markov decision process and apply proximal policy optimization to fine-tune the sampling policy. In particular, we interpret the flow field as a learnable policy and map an estimator to a value network, enabling joint optimization of pose generation and hypothesis scoring within a reinforcement learning framework. Experiments on the REAL275 benchmark demonstrate that RFM-Pose achieves favorable performance while significantly reducing computational cost. Moreover, similar to prior work, our approach can be readily adapted to object pose tracking and attains competitive results in this setting.", "AI": {"tldr": "RFM-Pose是一种基于强化学习的框架，用于加速类别级6D物体姿态估计。", "motivation": "现有的分数生成模型虽然解决了旋转对称性歧义问题，但效率受限于高采样成本。因此，本论文提出了一种新方法来提高采样效率，并减少计算成本。", "method": "采用流匹配生成模型并沿最优传输路径从简单先验生成姿态候选者；将其视为马尔可夫决策过程，使用近端策略优化调整采样策略；通过强化学习框架联合优化姿态生成与假设评分。", "result": "在REAL275基准测试中表现良好，并显著降低了计算成本。同时，在物体姿态跟踪方面取得了竞争性结果。", "conclusion": "RFM-Pose提出了一种新的方法，不仅提高了采样效率和减少了计算成本，还在类别级6D物体姿态估计上达到了很好的性能。"}}
{"id": "2602.05250", "pdf": "https://arxiv.org/pdf/2602.05250", "abs": "https://arxiv.org/abs/2602.05250", "authors": ["Jieyun Tan", "Shuo Liu", "Guibin Zhang", "Ziqi Li", "Jian Geng", "Lei Zhang", "Lei Cao"], "title": "Active Label Cleaning for Reliable Detection of Electron Dense Deposits in Transmission Electron Microscopy Images", "categories": ["cs.CV"], "comment": "10 pages, 6 figures", "summary": "Automated detection of electron dense deposits (EDD) in glomerular disease is hindered by the scarcity of high-quality labeled data. While crowdsourcing reduces annotation cost, it introduces label noise. We propose an active label cleaning method to efficiently denoise crowdsourced datasets. Our approach uses active learning to select the most valuable noisy samples for expert re-annotation, building high-accuracy cleaning models. A Label Selection Module leverages discrepancies between crowdsourced labels and model predictions for both sample selection and instance-level noise grading. Experiments show our method achieves 67.18% AP\\textsubscript{50} on a private dataset, an 18.83% improvement over training on noisy labels. This performance reaches 95.79% of that with full expert annotation while reducing annotation cost by 73.30%. The method provides a practical, cost-effective solution for developing reliable medical AI with limited expert resources.", "AI": {"tldr": "提出了一种主动标签清洗方法，以提高电子显微镜图像中电子致密沉积物（EDD）的自动检测准确性。", "motivation": "在自动化EDD检测过程中，由于高质量标注数据稀缺，使用众包虽降低了注释成本，但也引入了噪声。需要一种高效的方法来减少这种标签噪声。", "method": "该方法利用主动学习选择最宝贵的嘈杂样本进行专家重新注释，通过一个标签选择模块利用众包标签与模型预测之间的差异来进行样本选择和实例级噪声分级。", "result": "实验表明，在私有数据集上达到了67.18% AP\textsubscript{50}的性能，比在嘈杂标签上训练提高了18.83%，并且该方法的性能达到完全由专家注释所实现性能的95.79%，同时减少了73.30%的注释成本。", "conclusion": "这种方法提供了一种实用且经济高效的解决方案，在有限的专业资源下开发可靠的医学AI系统。"}}
{"id": "2602.05249", "pdf": "https://arxiv.org/pdf/2602.05249", "abs": "https://arxiv.org/abs/2602.05249", "authors": ["Xinyi He", "Ying Yang", "Chuanjian Fu", "Sihan Guo", "Songchun Zhu", "Lifeng Fan", "Zhenliang Zhang", "Yujia Peng"], "title": "Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents", "categories": ["cs.AI"], "comment": null, "summary": "As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination and a lack of scene specificity, inadequate for assessing agent capabilities in unseen settings. To address this, we propose a dynamic in-situ task generation method for unseen environments inspired by human cognition. We define tasks through a structured graph representation and construct a two-stage interaction-evolution task generation system for embodied agents (TEA). In the interaction stage, the agent actively interacts with the environment, creating a loop between task execution and generation that allows for continuous task generation. In the evolution stage, task graph modeling allows us to recombine and reuse existing tasks to generate new ones without external data. Experiments across 10 unseen scenes demonstrate that TEA automatically generated 87,876 tasks in two cycles, which human verification confirmed to be physically reasonable and encompassing essential daily cognitive capabilities. Benchmarking SOTA models against humans on our in-situ tasks reveals that models, despite excelling on public benchmarks, perform surprisingly poorly on basic perception tasks, severely lack 3D interaction awareness and show high sensitivity to task types in reasoning. These sobering findings highlight the necessity of in-situ evaluation before deploying agents into real-world human environments.", "AI": {"tldr": "提出了一种动态现场任务生成方法，用于评估通用智能代理在未知环境中的表现。", "motivation": "现有基准测试存在数据污染和场景特异性不足的问题，无法有效评估代理在未见设置下的能力。为了解决这一问题，本文提出了针对未知环境的基于人类认知的任务自动生成方法。", "method": "定义任务通过结构化图表示，并构建了两阶段互动进化任务生成系统（TEA）。该系统包括互动和演化两个阶段，在互动阶段中，代理主动与环境交互；在演化阶段，利用任务图模型重组和重用现有任务以生成新任务。", "result": "实验表明，TEA能够自动生成87,876个任务，并且人类验证确认这些任务物理上是合理的并涵盖了基本的认知能力。基准测试显示，尽管模型在公共基准测试中表现良好，在我们现场任务上的表现却令人惊讶地差。", "conclusion": "研究强调了在部署代理进入实际生活环境之前进行现场评估的重要性。"}}
{"id": "2602.05242", "pdf": "https://arxiv.org/pdf/2602.05242", "abs": "https://arxiv.org/abs/2602.05242", "authors": ["Chenhui Mao", "Yuanting Lei", "Zhixiang Wei", "Ming Liang", "Zhixiang Wang", "Jingxuan Xu", "Dajun Chen", "Wei Jiang", "Yong Li"], "title": "EGSS: Entropy-guided Stepwise Scaling for Reliable Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Agentic Test-Time Scaling (TTS) has delivered state-of-the-art (SOTA) performance on complex software engineering tasks such as code generation and bug fixing. However, its practical adoption remains limited due to significant computational overhead, primarily driven by two key challenges: (1) the high cost associated with deploying excessively large ensembles, and (2) the lack of a reliable mechanism for selecting the optimal candidate solution, ultimately constraining the performance gains that can be realized. To address these challenges, we propose Entropy-Guided Stepwise Scaling (EGSS), a novel TTS framework that dynamically balances efficiency and effectiveness through entropy-guided adaptive search and robust test-suite augmentation. Extensive experiments on SWE-Bench-Verified demonstrate that EGSS consistently boosts performance by 5-10% across all evaluated models. Specifically, it increases the resolved ratio of Kimi-K2-Intruct from 63.2% to 72.2%, and GLM-4.6 from 65.8% to 74.6%. Furthermore, when paired with GLM-4.6, EGSS achieves a new state-of-the-art among open-source large language models. In addition to these accuracy improvements, EGSS reduces inference-time token usage by over 28% compared to existing TTS methods, achieving simultaneous gains in both effectiveness and computational efficiency.", "AI": {"tldr": "提出EGSS框架，以提高软件工程任务中TTS的有效性和效率。", "motivation": "解决TTS在实际应用中的高计算开销问题，特别是在部署大型模型时的高昂成本和选择最优解困难的问题。", "method": "通过熵引导的自适应搜索和增强测试套件的方法来平衡效率与有效性。", "result": "实验表明EGSS能够在减少推理时间令牌使用量的同时提高准确性，性能比基准提高了5-10%。", "conclusion": "EGSS框架能够显著提升软件工程任务中的TTS性能，并且在计算效率上也表现优越。"}}
{"id": "2602.05240", "pdf": "https://arxiv.org/pdf/2602.05240", "abs": "https://arxiv.org/abs/2602.05240", "authors": ["Patrick McGonagle", "William Farrelly", "Kevin Curran"], "title": "Explainable AI: A Combined XAI Framework for Explaining Brain Tumour Detection Models", "categories": ["cs.AI"], "comment": null, "summary": "This study explores the integration of multiple Explainable AI (XAI) techniques to enhance the interpretability of deep learning models for brain tumour detection. A custom Convolutional Neural Network (CNN) was developed and trained on the BraTS 2021 dataset, achieving 91.24% accuracy in distinguishing between tumour and non-tumour regions. This research combines Gradient-weighted Class Activation Mapping (GRAD-CAM), Layer-wise Relevance Propagation (LRP) and SHapley Additive exPlanations (SHAP) to provide comprehensive insights into the model's decision-making process. This multi-technique approach successfully identified both full and partial tumours, offering layered explanations ranging from broad regions of interest to pixel-level details. GRAD-CAM highlighted important spatial regions, LRP provided detailed pixel-level relevance and SHAP quantified feature contributions. The integrated approach effectively explained model predictions, including cases with partial tumour visibility thus showing superior explanatory power compared to individual XAI methods. This research enhances transparency and trust in AI-driven medical imaging analysis by offering a more comprehensive perspective on the model's reasoning. The study demonstrates the potential of integrated XAI techniques in improving the reliability and interpretability of AI systems in healthcare, particularly for critical tasks like brain tumour detection.", "AI": {"tldr": "研究结合了多种可解释AI（XAI）技术，以增强基于深度学习的脑肿瘤检测模型的透明度。", "motivation": "为了提高基于深度学习的脑肿瘤检测模型的透明性和信任度，需要开发一种更全面的方法来解释这些模型的决策过程。", "method": "研究开发并训练了一个定制的卷积神经网络（CNN），并在BraTS 2021数据集上实现了91.24%的准确率。结合了GRAD-CAM、LRP和SHAP三种技术，提供了从整体到像素级别的全面解释。", "result": "该研究成功地通过集成XAI方法解释了模型预测，特别是在部分肿瘤可见的情况下表现更优。", "conclusion": "这项研究证明了整合多种可解释性人工智能（XAI）技术在提高医疗图像分析中基于人工智能系统的可靠性和透明度方面的潜力。"}}
{"id": "2602.05238", "pdf": "https://arxiv.org/pdf/2602.05238", "abs": "https://arxiv.org/abs/2602.05238", "authors": ["Boxiang Zhang", "Baijian Yang", "Xiaoming Wang", "Corey Vian"], "title": "PatchFlow: Leveraging a Flow-Based Model with Patch Features", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Die casting plays a crucial role across various industries due to its ability to craft intricate shapes with high precision and smooth surfaces. However, surface defects remain a major issue that impedes die casting quality control. Recently, computer vision techniques have been explored to automate and improve defect detection. In this work, we combine local neighbor-aware patch features with a normalizing flow model and bridge the gap between the generic pretrained feature extractor and industrial product images by introducing an adapter module to increase the efficiency and accuracy of automated anomaly detection. Compared to state-of-the-art methods, our approach reduces the error rate by 20\\% on the MVTec AD dataset, achieving an image-level AUROC of 99.28\\%. Our approach has also enhanced performance on the VisA dataset , achieving an image-level AUROC of 96.48\\%. Compared to the state-of-the-art models, this represents a 28.2\\% reduction in error. Additionally, experiments on a proprietary die casting dataset yield an accuracy of 95.77\\% for anomaly detection, without requiring any anomalous samples for training. Our method illustrates the potential of leveraging computer vision and deep learning techniques to advance inspection capabilities for the die casting industry", "AI": {"tldr": "本文提出了PatchFlow方法，结合了基于流的模型和补丁特征来提高铸件表面缺陷检测的准确性。", "motivation": "表面缺陷是阻碍铸造质量控制的主要问题。计算机视觉技术已被探索用于自动化和改进缺陷检测。本文旨在通过引入适配器模块连接通用预训练特征提取器与工业产品图像，以提高自动异常检测的效率和准确性。", "method": "PatchFlow结合了局部邻居感知补丁特征和归一化流模型，并加入了一个适配器模块来增强特征表示能力，从而提高了对铸造缺陷检测的效果。", "result": "在MVTec AD数据集上，PatchFlow将错误率降低了20%，达到了99.28%的AUROC。在VisA数据集上，该方法也表现优异，实现了96.48%的AUROC。此外，在一个专有的铸造数据集上，其异常检测准确率为95.77%，且无需训练任何异常样本。", "conclusion": "PatchFlow展示了计算机视觉和深度学习技术在提高铸造行业检查能力方面的潜力。"}}
{"id": "2602.05233", "pdf": "https://arxiv.org/pdf/2602.05233", "abs": "https://arxiv.org/abs/2602.05233", "authors": ["Wenbo Wang", "Fangyun Wei", "QiXiu Li", "Xi Chen", "Yaobo Liang", "Chang Xu", "Jiaolong Yang", "Baining Guo"], "title": "MobileManiBench: Simplifying Model Verification for Mobile Manipulation", "categories": ["cs.RO"], "comment": null, "summary": "Vision-language-action models have advanced robotic manipulation but remain constrained by reliance on the large, teleoperation-collected datasets dominated by the static, tabletop scenes. We propose a simulation-first framework to verify VLA architectures before real-world deployment and introduce MobileManiBench, a large-scale benchmark for mobile-based robotic manipulation. Built on NVIDIA Isaac Sim and powered by reinforcement learning, our pipeline autonomously generates diverse manipulation trajectories with rich annotations (language instructions, multi-view RGB-depth-segmentation images, synchronized object/robot states and actions). MobileManiBench features 2 mobile platforms (parallel-gripper and dexterous-hand robots), 2 synchronized cameras (head and right wrist), 630 objects in 20 categories, 5 skills (open, close, pull, push, pick) with over 100 tasks performed in 100 realistic scenes, yielding 300K trajectories. This design enables controlled, scalable studies of robot embodiments, sensing modalities, and policy architectures, accelerating research on data efficiency and generalization. We benchmark representative VLA models and report insights into perception, reasoning, and control in complex simulated environments.", "AI": {"tldr": "提出MobileManiBench，用于简化移动端机器人操作模型的验证。", "motivation": "当前视觉语言行动模型受到大型遥操作数据集限制，这些数据集主要包含静态桌面场景。需要一种仿真优先框架来验证模型。", "method": "利用NVIDIA Isaac Sim和强化学习自主生成多样化操作轨迹，并提供丰富注释。MobileManiBench包括两个移动端平台、多个摄像头、630种物体及其模拟任务。", "result": "通过大量实验，展示了在复杂仿真环境中的感知、推理和控制能力。", "conclusion": "MobileManiBench为研究数据效率和泛化提供了一个强大的工具。"}}
{"id": "2602.05232", "pdf": "https://arxiv.org/pdf/2602.05232", "abs": "https://arxiv.org/abs/2602.05232", "authors": ["Chunyu Wei", "Siyuan He", "Yu Wang", "Yueguo Chen", "Yunhai Wang", "Bing Bai", "Yidong Zhang", "Yong Xie", "Shunming Zhang", "Fei Wang"], "title": "Balanced Anomaly-guided Ego-graph Diffusion Model for Inductive Graph Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages,6 figures, Accepted by ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '26)", "summary": "Graph anomaly detection (GAD) is crucial in applications like fraud detection and cybersecurity. Despite recent advancements using graph neural networks (GNNs), two major challenges persist. At the model level, most methods adopt a transductive learning paradigm, which assumes static graph structures, making them unsuitable for dynamic, evolving networks. At the data level, the extreme class imbalance, where anomalous nodes are rare, leads to biased models that fail to generalize to unseen anomalies. These challenges are interdependent: static transductive frameworks limit effective data augmentation, while imbalance exacerbates model distortion in inductive learning settings. To address these challenges, we propose a novel data-centric framework that integrates dynamic graph modeling with balanced anomaly synthesis. Our framework features: (1) a discrete ego-graph diffusion model, which captures the local topology of anomalies to generate ego-graphs aligned with anomalous structural distribution, and (2) a curriculum anomaly augmentation mechanism, which dynamically adjusts synthetic data generation during training, focusing on underrepresented anomaly patterns to improve detection and generalization. Experiments on five datasets demonstrate that the effectiveness of our framework.", "AI": {"tldr": "提出了一种新型的数据中心框架，结合动态图建模与平衡异常合成来解决图异常检测中的挑战。", "motivation": "大多数方法采用静态的归纳学习模式，并且存在极端的类别不平衡问题，导致模型无法很好地推广到未知的异常情况。", "method": "引入一个离散的自环扩散模型和一种课程异常增强机制。前者捕捉异常节点局部拓扑结构生成对应的子图；后者动态调整训练期间合成数据的产生，专注于未充分代表的异常模式。", "result": "实验结果表明该框架有效解决了静态图形建模与类别不平衡问题，在五个数据集上表现优异。", "conclusion": "所提出的框架成功地提高了对未知异常情况的检测和泛化能力。"}}
{"id": "2602.05230", "pdf": "https://arxiv.org/pdf/2602.05230", "abs": "https://arxiv.org/abs/2602.05230", "authors": ["Jiecheng Lu", "Xu Han", "Yan Sun", "Viresh Pati", "Yubin Kim", "Siddhartha Somani", "Shihao Yang"], "title": "ZeroS: Zero-Sum Linear Attention for Efficient Transformers", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Camera-ready version. Accepted at NeurIPS 2025", "summary": "Linear attention methods offer Transformers $O(N)$ complexity but typically underperform standard softmax attention. We identify two fundamental limitations affecting these approaches: the restriction to convex combinations that only permits additive information blending, and uniform accumulated weight bias that dilutes attention in long contexts. We propose Zero-Sum Linear Attention (ZeroS), which addresses these limitations by removing the constant zero-order term $1/t$ and reweighting the remaining zero-sum softmax residuals. This modification creates mathematically stable weights, enabling both positive and negative values and allowing a single attention layer to perform contrastive operations. While maintaining $O(N)$ complexity, ZeroS theoretically expands the set of representable functions compared to convex combinations. Empirically, it matches or exceeds standard softmax attention across various sequence modeling benchmarks.", "AI": {"tldr": "提出了ZeroS线性注意力机制，旨在提高效率的同时不牺牲性能。", "motivation": "现有线性注意力方法虽复杂度为O(N)，但往往不如标准softmax注意力表现好。限制在于只能进行加法信息融合和统一的累积权重偏差导致长序列中的注意被稀释。", "method": "通过移除常数零阶项1/t并重新加权剩余的零和softmax残差，ZeroS线性注意力机制解决了这两个问题，生成数学上稳定的权重，允许正值和负值，并且可以执行对比操作。这样，在保持O(N)复杂度的同时理论上来讲比凸组合可表示更多的函数。", "result": "在各种序列建模基准测试中，ZeroS的性能与标准softmax注意力相匹配或超出。", "conclusion": "ZeroS线性注意力机制通过改进现有线性注意方法中的限制问题，在保持效率的前提下提高了模型的表现。"}}
{"id": "2602.05228", "pdf": "https://arxiv.org/pdf/2602.05228", "abs": "https://arxiv.org/abs/2602.05228", "authors": ["Guozhi Liu", "Weiwei Lin", "Tiansheng Huang", "Ruichao Mo", "Qi Mu", "Xiumin Wang", "Li Shen"], "title": "Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink", "categories": ["cs.AI"], "comment": null, "summary": "Harmful fine-tuning can invalidate safety alignment of large language models, exposing significant safety risks. In this paper, we utilize the attention sink mechanism to mitigate harmful fine-tuning. Specifically, we first measure a statistic named \\emph{sink divergence} for each attention head and observe that \\emph{different attention heads exhibit two different signs of sink divergence}. To understand its safety implications, we conduct experiments and find that the number of attention heads of positive sink divergence increases along with the increase of the model's harmfulness when undergoing harmful fine-tuning. Based on this finding, we propose a separable sink divergence hypothesis -- \\emph{attention heads associating with learning harmful patterns during fine-tuning are separable by their sign of sink divergence}. Based on the hypothesis, we propose a fine-tuning-stage defense, dubbed Surgery. Surgery utilizes a regularizer for sink divergence suppression, which steers attention heads toward the negative sink divergence group, thereby reducing the model's tendency to learn and amplify harmful patterns. Extensive experiments demonstrate that Surgery improves defense performance by 5.90\\%, 11.25\\%, and 9.55\\% on the BeaverTails, HarmBench, and SorryBench benchmarks, respectively. Source code is available on https://github.com/Lslland/Surgery.", "AI": {"tldr": "通过注意力下水道机制减轻大型语言模型的有害微调。", "motivation": "有害微调可能导致大型语言模型的安全性失效，暴露重大安全风险。本文旨在利用注意力下水道机制来缓解这种问题。", "method": "首先测量每个注意头的\"下水道发散度\"统计量，并观察到不同的注意头表现出两种不同的“下水道发散”符号。实验发现有害微调时正向“下水道发散”的注意头数量增加，据此提出了可分离的“下水道发散”假设。在此基础上提出了一种微调阶段防御机制Surgery，通过抑制\"下水道发散度\"将注意力头导向负向组，从而减少模型学习和放大有害模式的趋势。", "result": "实验结果表明，Surgery在BeaverTails、HarmBench和SorryBench基准测试中分别提高了5.90%，11.25%和9.55%的防御性能。", "conclusion": "通过使用\"下水道发散度\"机制可以有效减轻大型语言模型中的有害微调问题，从而提高模型的安全性。"}}
{"id": "2602.05220", "pdf": "https://arxiv.org/pdf/2602.05220", "abs": "https://arxiv.org/abs/2602.05220", "authors": ["Jinchuan Tian", "Haoran Wang", "Bo-Hao Su", "Chien-yu Huang", "Qingzheng Wang", "Jiatong Shi", "William Chen", "Xun Gong", "Siddhant Arora", "Chin-Jou Li", "Masao Someki", "Takashi Maekaku", "Yusuke Shinohara", "Jin Sakuma", "Chao-Han Huck Yang", "Shinji Watanabe"], "title": "Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions", "categories": ["cs.CL", "cs.SD"], "comment": null, "summary": "Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.", "AI": {"tldr": "介绍了一种名为Bagpiper的8B音频基础模型，该模型通过丰富的注释理解物理音频，并在各种音频理解和生成任务中表现出色。", "motivation": "现有音频基础模型依赖于刚性的特定任务监督，只处理孤立的声音因素而非整体。人类智能则全面地将物理信号与抽象的认知概念相联系以执行复杂任务。Bagpiper旨在模仿这一过程，通过丰富注释来理解音频信号中的关键认知概念。", "method": "预训练一个8B的音频基础模型在600B标记的数据集上，建立原始音频和高层次概念空间之间的双向映射。在微调阶段采用“注释然后处理”的工作流，模拟中间的认知推理步骤以解决多样化的任务而无需特定的任务先验。", "result": "实验结果表明，Bagpiper在MMAU和AIRBench上的表现优于Qwen-2.5-Omni，在音频理解和生成质量上超越了CosyVoice3和TangoFlux，能够合成任意组合的语音、音乐和声音效果。", "conclusion": "Bagpiper是首个实现对通用音频统一理解与生成的工作之一。该模型及其数据集和代码已公开提供。"}}
{"id": "2602.05218", "pdf": "https://arxiv.org/pdf/2602.05218", "abs": "https://arxiv.org/abs/2602.05218", "authors": ["Jiahao Nie", "Yun Xing", "Wenbin An", "Qingsong Zhao", "Jiawei Shao", "Yap-Peng Tan", "Alex C. Kot", "Shijian Lu", "Xuelong Li"], "title": "Boosting SAM for Cross-Domain Few-Shot Segmentation via Conditional Point Sparsification", "categories": ["cs.CV"], "comment": null, "summary": "Motivated by the success of the Segment Anything Model (SAM) in promptable segmentation, recent studies leverage SAM to develop training-free solutions for few-shot segmentation, which aims to predict object masks in the target image based on a few reference exemplars. These SAM-based methods typically rely on point matching between reference and target images and use the matched dense points as prompts for mask prediction. However, we observe that dense points perform poorly in Cross-Domain Few-Shot Segmentation (CD-FSS), where target images are from medical or satellite domains. We attribute this issue to large domain shifts that disrupt the point-image interactions learned by SAM, and find that point density plays a crucial role under such conditions. To address this challenge, we propose Conditional Point Sparsification (CPS), a training-free approach that adaptively guides SAM interactions for cross-domain images based on reference exemplars. Leveraging ground-truth masks, the reference images provide reliable guidance for adaptively sparsifying dense matched points, enabling more accurate segmentation results. Extensive experiments demonstrate that CPS outperforms existing training-free SAM-based methods across diverse CD-FSS datasets.", "AI": {"tldr": "本文提出了一种基于条件点稀疏化的训练自由方法，以改善跨域少样本分割问题中的SAM模型效果。", "motivation": "近期研究发现，在跨域少样本分割任务中，密集点作为提示在预测目标图像中的对象掩码时表现不佳，原因是领域转换导致的点-图互动破坏和点密度的影响。", "method": "提出了一种称为条件点稀疏化的训练自由方法，该方法利用参考示例提供的真实掩模信息来动态稀疏化密集匹配点，以改善SAM模型在跨域图像上的交互效果。", "result": "实验表明，在多种跨域少样本分割数据集上，所提出的CPS方法优于现有的基于训练自由的SAM方法。", "conclusion": "条件点稀疏化技术能够显著提高跨域少样本分割任务中的目标掩码预测准确度。"}}
{"id": "2602.05217", "pdf": "https://arxiv.org/pdf/2602.05217", "abs": "https://arxiv.org/abs/2602.05217", "authors": ["Jiahao Nie", "Guanqiao Fu", "Wenbin An", "Yap-Peng Tan", "Alex C. Kot", "Shijian Lu"], "title": "Cross-Domain Few-Shot Segmentation via Multi-view Progressive Adaptation", "categories": ["cs.CV"], "comment": null, "summary": "Cross-Domain Few-Shot Segmentation aims to segment categories in data-scarce domains conditioned on a few exemplars. Typical methods first establish few-shot capability in a large-scale source domain and then adapt it to target domains. However, due to the limited quantity and diversity of target samples, existing methods still exhibit constrained performance. Moreover, the source-trained model's initially weak few-shot capability in target domains, coupled with substantial domain gaps, severely hinders the effective utilization of target samples and further impedes adaptation. To this end, we propose Multi-view Progressive Adaptation, which progressively adapts few-shot capability to target domains from both data and strategy perspectives. (i) From the data perspective, we introduce Hybrid Progressive Augmentation, which progressively generates more diverse and complex views through cumulative strong augmentations, thereby creating increasingly challenging learning scenarios. (ii) From the strategy perspective, we design Dual-chain Multi-view Prediction, which fully leverages these progressively complex views through sequential and parallel learning paths under extensive supervision. By jointly enforcing prediction consistency across diverse and complex views, MPA achieves both robust and accurate adaptation to target domains. Extensive experiments demonstrate that MPA effectively adapts few-shot capability to target domains, outperforming state-of-the-art methods by a large margin (+7.0%).", "AI": {"tldr": "跨域少样本分割旨在通过少数示例对数据稀缺领域的类别进行分割。", "motivation": "现有方法由于目标样本数量和多样性有限，性能受限。源领域训练模型在目标领域初始的弱少样本能力加上显著的领域差异严重阻碍了目标样本的有效利用及适应性提高。", "method": "提出多视图渐进自适应，从数据视角引入混合渐进增强以生成更多样化复杂视图，策略上设计双链多视图预测充分利用这些视图实现稳健准确的目标域适应性。", "result": "实验表明MPA有效提升少样本能力到目标领域，优于现有最佳方法（+7.0%）。", "conclusion": "通过从数据和策略两方面渐进增强目标域的适应性，我们的方法显著提高了跨域少样本分割任务的表现。"}}
{"id": "2602.05216", "pdf": "https://arxiv.org/pdf/2602.05216", "abs": "https://arxiv.org/abs/2602.05216", "authors": ["Luke Alexander", "Eric Leonen", "Sophie Szeto", "Artemii Remizov", "Ignacio Tejeda", "Giovanni Inchiostro", "Vasily Ilin"], "title": "Semantic Search over 9 Million Mathematical Theorems", "categories": ["cs.IR", "cs.AI", "math.HO"], "comment": "Feedback is welcome", "summary": "Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of $9.2$ million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at \\href{https://huggingface.co/spaces/uw-math-ai/theorem-search}{this link}, and the dataset is available at \\href{https://huggingface.co/datasets/uw-math-ai/TheoremSearch}{this link}.", "AI": {"tldr": "该论文介绍了一种大规模语义定理检索系统，旨在从900万条数学定理中快速准确地找到相关的定理。", "motivation": "现有的搜索工具大多基于全文检索，难以满足寻找特定数学定理的需求。因此，本研究致力于开发一种高效的语义定理搜索技术。", "method": "该论文构建了一个包含920万条来自arXiv等资源的定理语料库，并使用不同的语言模型、嵌入模型和提示策略进行实验。", "result": "相较于现有基准方法，本研究提出的系统在由专业数学家提供的查询集上显著提升了定理级及论文级检索质量。", "conclusion": "研究表明大规模语义定理搜索是可行且有效的，并提供了相应的搜索引擎和数据集供进一步研究使用。"}}
{"id": "2602.05215", "pdf": "https://arxiv.org/pdf/2602.05215", "abs": "https://arxiv.org/abs/2602.05215", "authors": ["Jiahao Nie", "Wenbin An", "Gongjie Zhang", "Yicheng Xu", "Yap-Peng Tan", "Alex C. Kot", "Shijian Lu"], "title": "E.M.Ground: A Temporal Grounding Vid-LLM with Holistic Event Perception and Matching", "categories": ["cs.CV"], "comment": null, "summary": "Despite recent advances in Video Large Language Models (Vid-LLMs), Temporal Video Grounding (TVG), which aims to precisely localize time segments corresponding to query events, remains a significant challenge. Existing methods often match start and end frames by comparing frame features with two separate tokens, relying heavily on exact timestamps. However, this approach fails to capture the event's semantic continuity and integrity, leading to ambiguities. To address this, we propose E.M.Ground, a novel Vid-LLM for TVG that focuses on holistic and coherent event perception. E.M.Ground introduces three key innovations: (i) a special <event> token that aggregates information from all frames of a query event, preserving semantic continuity for accurate event matching; (ii) Savitzky-Golay smoothing to reduce noise in token-to-frame similarities across timestamps, improving prediction accuracy; (iii) multi-grained frame feature aggregation to enhance matching reliability and temporal understanding, compensating for compression-induced information loss. Extensive experiments on benchmark datasets show that E.M.Ground consistently outperforms state-of-the-art Vid-LLMs by significant margins.", "AI": {"tldr": "E.M.Ground是一种用于视频事件时间定位的新型Video Large Language Model（Vid-LLM），它通过聚合查询事件的所有帧信息来实现整体和连贯的事态感知。", "motivation": "当前TVG方法依赖于精确的时间戳并匹配开始和结束帧，这导致了事件语义连续性和完整性捕捉不足的问题。E.M.Ground旨在解决这一问题，提高视频时间定位的准确性。", "method": "E.M.Ground引入了一种特殊<event>令牌以聚合查询事件的所有帧信息；使用Savitzky-Golay平滑技术减少时间戳间令牌与帧相似性的噪声；采用多粒度帧特征聚合来增强匹配可靠性并提高时间理解能力，弥补了压缩引起的信息损失。", "result": "在基准数据集上的广泛实验表明，E.M.Ground在性能上显著优于现有的Vid-LLM方法。", "conclusion": "通过整体连贯事件感知和多粒度帧特征聚合技术，E.M.Ground在视频时间定位任务中实现了更高的精度和鲁棒性。"}}
{"id": "2602.05213", "pdf": "https://arxiv.org/pdf/2602.05213", "abs": "https://arxiv.org/abs/2602.05213", "authors": ["Chuqin Zhou", "Xiaoyue Ling", "Yunuo Chen", "Jincheng Dai", "Guo Lu", "Wenjun Zhang"], "title": "Dual-Representation Image Compression at Ultra-Low Bitrates via Explicit Semantics and Implicit Textures", "categories": ["cs.CV"], "comment": null, "summary": "While recent neural codecs achieve strong performance at low bitrates when optimized for perceptual quality, their effectiveness deteriorates significantly under ultra-low bitrate conditions. To mitigate this, generative compression methods leveraging semantic priors from pretrained models have emerged as a promising paradigm. However, existing approaches are fundamentally constrained by a tradeoff between semantic faithfulness and perceptual realism. Methods based on explicit representations preserve content structure but often lack fine-grained textures, whereas implicit methods can synthesize visually plausible details at the cost of semantic drift. In this work, we propose a unified framework that bridges this gap by coherently integrating explicit and implicit representations in a training-free manner. Specifically, We condition a diffusion model on explicit high-level semantics while employing reverse-channel coding to implicitly convey fine-grained details. Moreover, we introduce a plug-in encoder that enables flexible control of the distortion-perception tradeoff by modulating the implicit information. Extensive experiments demonstrate that the proposed framework achieves state-of-the-art rate-perception performance, outperforming existing methods and surpassing DiffC by 29.92%, 19.33%, and 20.89% in DISTS BD-Rate on the Kodak, DIV2K, and CLIC2020 datasets, respectively.", "AI": {"tldr": "本文提出了一种结合显式和隐式表示的统一框架，用于在超低比特率下进行图像压缩。", "motivation": "最近的神经编码器在低比特率条件下表现良好，但在超低比特率条件下的效果显著下降。现有的基于语义先验的方法存在结构保真度与视觉逼真的权衡问题。", "method": "本文通过扩散模型结合显式高层语义，并采用反向通道编码来隐性传达细粒度细节，实现了一个无需训练的统一框架。", "result": "实验表明该方法在Kodak、DIV2K和CLIC2020数据集上超越了现有方法并优于DiffC。", "conclusion": "本文提出的结合显式语义与隐性纹理的方法，在超低比特率下取得了最佳的感知性能。"}}
{"id": "2602.05208", "pdf": "https://arxiv.org/pdf/2602.05208", "abs": "https://arxiv.org/abs/2602.05208", "authors": ["Md. Mehedi Hassan", "Taufiq Hasan"], "title": "Context-Aware Asymmetric Ensembling for Interpretable Retinopathy of Prematurity Screening via Active Query and Vascular Attention", "categories": ["eess.IV", "cs.CV"], "comment": "16 pages, 6 figures", "summary": "Retinopathy of Prematurity (ROP) is among the major causes of preventable childhood blindness. Automated screening remains challenging, primarily due to limited data availability and the complex condition involving both structural staging and microvascular abnormalities. Current deep learning models depend heavily on large private datasets and passive multimodal fusion, which commonly fail to generalize on small, imbalanced public cohorts. We thus propose the Context-Aware Asymmetric Ensemble Model (CAA Ensemble) that simulates clinical reasoning through two specialized streams. First, the Multi-Scale Active Query Network (MS-AQNet) serves as a structure specialist, utilizing clinical contexts as dynamic query vectors to spatially control visual feature extraction for localization of the fibrovascular ridge. Secondly, VascuMIL encodes Vascular Topology Maps (VMAP) within a gated Multiple Instance Learning (MIL) network to precisely identify vascular tortuosity. A synergistic meta-learner ensembles these orthogonal signals to resolve diagnostic discordance across multiple objectives. Tested on a highly imbalanced cohort of 188 infants (6,004 images), the framework attained State-of-the-Art performance on two distinct clinical tasks: achieving a Macro F1-Score of 0.93 for Broad ROP staging and an AUC of 0.996 for Plus Disease detection. Crucially, the system features `Glass Box' transparency through counterfactual attention heatmaps and vascular threat maps, proving that clinical metadata dictates the model's visual search. Additionally, this study demonstrates that architectural inductive bias can serve as an effective bridge for the medical AI data gap.", "AI": {"tldr": "提出了基于上下文感知的不对称集成模型CAA Ensemble，通过多尺度主动查询网络和血管多重实例学习网络来实现ROP筛查的自动化，并获得显著性能提升。", "motivation": "由于数据有限且存在结构分期与微血管异常等复杂情况，现有的深度学习模型在小规模不平衡公共队列中表现不佳。因此提出了一种新的方法以解决这些问题。", "method": "CAA Ensemble由多尺度主动查询网络和血管多重实例学习网络组成，前者通过利用临床上下文作为动态查询向量来控制视觉特征提取，后者则用于编码血管拓扑图并使用门控多重实例学习网络精确定位血管扭曲。最终模型结合这两种信号以解决诊断分歧问题。", "result": "实验在188名婴儿的不平衡数据集中进行，该框架实现了宏平均F1分数为0.93和Plus疾病的检测AUC值达到0.996的顶尖性能。", "conclusion": "提出的CAA Ensemble不仅展示了卓越的技术性能，而且通过反事实注意力热图等方法确保了模型透明度。此外，研究表明架构的归纳偏差可以作为医学AI数据差距的有效桥梁。"}}
{"id": "2602.05207", "pdf": "https://arxiv.org/pdf/2602.05207", "abs": "https://arxiv.org/abs/2602.05207", "authors": ["Chunyat Wu", "Jiajun Deng", "Zhengxi Liu", "Zheqi Dai", "Haolin He", "Qiuqiang Kong"], "title": "ARCHI-TTS: A flow-matching-based Text-to-Speech Model with Self-supervised Semantic Aligner and Accelerated Inference", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted by ICASSP 2026", "summary": "Although diffusion-based, non-autoregressive text-to-speech (TTS) systems have demonstrated impressive zero-shot synthesis capabilities, their efficacy is still hindered by two key challenges: the difficulty of text-speech alignment modeling and the high computational overhead of the iterative denoising process. To address these limitations, we propose ARCHI-TTS that features a dedicated semantic aligner to ensure robust temporal and semantic consistency between text and audio. To overcome high computational inference costs, ARCHI-TTS employs an efficient inference strategy that reuses encoder features across denoising steps, drastically accelerating synthesis without performance degradation. An auxiliary CTC loss applied to the condition encoder further enhances the semantic understanding. Experimental results demonstrate that ARCHI-TTS achieves a WER of 1.98% on LibriSpeech-PC test-clean, and 1.47%/1.42% on SeedTTS test-en/test-zh with a high inference efficiency, consistently outperforming recent state-of-the-art TTS systems.", "AI": {"tldr": "提出了一种基于流匹配的文本到语音模型ARCHI-TTS，通过自监督语义对齐器和加速推理策略解决当前非自回归TTS系统的两大挑战。", "motivation": "解决了扩散方法在文本与语音对齐建模上的困难以及迭代去噪过程中的高计算成本问题", "method": "采用专门的语义对齐器确保文本与音频之间的时间一致性和语义一致性，通过重用编码特征来加速合成过程而不降低性能。应用CTC损失增强条件编码器的语义理解。", "result": "实验结果表明，ARCHI-TTS在LibriSpeech-PC测试集上实现1.98%的WER，在SeedTTS测试集上分别达到1.47%/1.42%，且具有很高的推理效率。", "conclusion": "ARCHI-TTS通过自监督语义对齐器和高效推理策略显著改进了非自回归TTS系统的性能，优于当前最先进方法。"}}
{"id": "2602.05205", "pdf": "https://arxiv.org/pdf/2602.05205", "abs": "https://arxiv.org/abs/2602.05205", "authors": ["Kenichiro Ando", "Tatsuya Harada"], "title": "Aligning Large Language Model Behavior with Human Citation Preferences", "categories": ["cs.CL", "cs.AI"], "comment": "Work In Progress", "summary": "Most services built on powerful large-scale language models (LLMs) add citations to their output to enhance credibility. Recent research has paid increasing attention to the question of what reference documents to link to outputs. However, how LLMs recognize cite-worthiness and how this process should be controlled remains underexplored. In this study, we focus on what kinds of content LLMs currently tend to cite and how well that behavior aligns with human preferences. We construct a dataset to characterize the relationship between human citation preferences and LLM behavior. Web-derived texts are categorized into eight citation-motivation types, and pairwise citation preferences are exhaustively evaluated across all type combinations to capture fine-grained contrasts. Our results show that humans most frequently seek citations for medical text, and stronger models display a similar tendency. We also find that current models are as much as $27\\%$ more likely than humans to add citations to text that is explicitly marked as needing citations on sources such as Wikipedia, and this overemphasis reduces alignment accuracy. Conversely, models systematically underselect numeric sentences (by $-22.6\\%$ relative to humans) and sentences containing personal names (by $-20.1\\%$), categories for which humans typically demand citations. Furthermore, experiments with Direct Preference Optimization demonstrate that model behavior can be calibrated to better match human citation preferences. We expect this study to provide a foundation for more fine-grained investigations into LLM citation preferences.", "AI": {"tldr": "研究探索大型语言模型（LLM）的引用行为与人类偏好之间的差异，并提出优化方法。", "motivation": "目前对如何控制LLM识别引用内容的研究不足，本研究旨在探究LLM当前的引用倾向是否符合人类偏好。", "method": "通过构建数据集来描述人类引用偏好和LLM行为的关系。使用网络文本进行分类并评估其引用偏好，同时利用直接偏好优化实验校准模型行为。", "result": "发现人类倾向于为医学内容添加引用；更强的模型更可能在明确需引文的地方过度引用（如维基百科）；而对数值句子和个人名称则有低估趋势。通过优化可以提高模型与人类偏好的匹配度。", "conclusion": "该研究提供了关于LLM引用行为的基础，有助于未来更细致的研究。"}}
{"id": "2602.05204", "pdf": "https://arxiv.org/pdf/2602.05204", "abs": "https://arxiv.org/abs/2602.05204", "authors": ["Changhoon Song", "Teng Yuan Chang", "Youngjoon Hong"], "title": "Extreme Weather Nowcasting via Local Precipitation Pattern Prediction", "categories": ["cs.LG", "cs.CV"], "comment": "10pages, 20 figures, The Fourteenth International Conference on Learning Representations, see https://github.com/tony890048/exPreCast", "summary": "Accurate forecasting of extreme weather events such as heavy rainfall or storms is critical for risk management and disaster mitigation. Although high-resolution radar observations have spurred extensive research on nowcasting models, precipitation nowcasting remains particularly challenging due to pronounced spatial locality, intricate fine-scale rainfall structures, and variability in forecasting horizons. While recent diffusion-based generative ensembles show promising results, they are computationally expensive and unsuitable for real-time applications. In contrast, deterministic models are computationally efficient but remain biased toward normal rainfall. Furthermore, the benchmark datasets commonly used in prior studies are themselves skewed--either dominated by ordinary rainfall events or restricted to extreme rainfall episodes--thereby hindering general applicability in real-world settings. In this paper, we propose exPreCast, an efficient deterministic framework for generating finely detailed radar forecasts, and introduce a newly constructed balanced radar dataset from the Korea Meteorological Administration (KMA), which encompasses both ordinary precipitation and extreme events. Our model integrates local spatiotemporal attention, a texture-preserving cubic dual upsampling decoder, and a temporal extractor to flexibly adjust forecasting horizons. Experiments on established benchmarks (SEVIR and MeteoNet) as well as on the balanced KMA dataset demonstrate that our approach achieves state-of-the-art performance, delivering accurate and reliable nowcasts across both normal and extreme rainfall regimes.", "AI": {"tldr": "该论文提出了一种高效的确定性框架exPreCast，用于生成精细的雷达预报，并引入了一个新的平衡雷达数据集。", "motivation": "准确预测极端天气事件对于风险管理至关重要，但现有的扩散模型计算成本高且不适合实时应用；而传统的确定性模型虽计算效率高，但对于极端降雨仍有偏见。因此需要开发一种新的方法来解决这些问题。", "method": "exPreCast框架集成了局部时空注意力机制、纹理保留的三次双上采样解码器和时间提取器，并利用韩国气象厅的数据构建了一个平衡的新数据集以适应不同的预测范围。", "result": "实验结果显示，该模型在SEVIR和MeteoNet等基准测试以及新的KMA数据集上的表现均优于现有的方法，在正常和极端降雨情况下都能提供准确可靠的预报。", "conclusion": "exPreCast是一种高效且实用的框架，能够生成准确的雷达预报，并具有广泛的应用前景。"}}
{"id": "2602.05202", "pdf": "https://arxiv.org/pdf/2602.05202", "abs": "https://arxiv.org/abs/2602.05202", "authors": ["Shivanshu Shekhar", "Uttaran Bhattacharya", "Raghavendra Addanki", "Mehrab Tanjim", "Somdeb Sarkhel", "Tong Zhang"], "title": "GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling", "categories": ["cs.CV"], "comment": null, "summary": "Aligning video generative models with human preferences remains challenging: current approaches rely on Vision-Language Models (VLMs) for reward modeling, but these models struggle to capture subtle temporal dynamics. We propose a fundamentally different approach: repurposing video generative models, which are inherently designed to model temporal structure, as reward models. We present the Generative-Transformer-based Self-Supervised Video Judge (\\modelname), a novel evaluation model that transforms state-of-the-art video generation models into powerful temporally-aware reward models. Our key insight is that generative models can be reformulated as energy-based models (EBMs) that assign low energy to high-quality videos and high energy to degraded ones, enabling them to discriminate video quality with remarkable precision when trained via contrastive objectives. To prevent the model from exploiting superficial differences between real and generated videos, we design challenging synthetic negative videos through controlled latent-space perturbations: temporal slicing, feature swapping, and frame shuffling, which simulate realistic but subtle visual degradations. This forces the model to learn meaningful spatiotemporal features rather than trivial artifacts. \\modelname achieves state-of-the-art performance on GenAI-Bench and MonteBench using only 30K human-annotations: $6\\times$ to $65\\times$ fewer than existing VLM-based approaches.", "AI": {"tldr": "该论文提出了一种基于生成器的自监督视频评估模型GT-SVJ，用于高效地进行视频奖励建模。", "motivation": "当前方法依赖视觉语言模型（VLM）进行奖励建模，难以捕捉微妙的时间动态。作者希望通过重新利用设计来模拟时间结构的视频生成模型作为奖励模型来解决这一问题。", "method": "通过将视频生成模型转化为能量基模型，并使用对比目标训练模型以区分高质量和低质量视频。同时，通过控制潜空间扰动生成具有挑战性的合成负样本，防止模型依赖表面差异。", "result": "GT-SVJ在GenAI-Bench和MonteBench上实现了最先进的性能，仅需30K个人类标注，相较于现有基于VLM的方法减少了6到65倍的标注量。", "conclusion": "通过这种方法，论文展示了使用生成器进行视频奖励建模的有效性，并证明了其比传统的视觉语言模型更具效率和准确性。"}}
{"id": "2602.05198", "pdf": "https://arxiv.org/pdf/2602.05198", "abs": "https://arxiv.org/abs/2602.05198", "authors": ["Kalvik Jakkala", "Saurav Agarwal", "Jason O'Kane", "Srinivas Akella"], "title": "Informative Path Planning with Guaranteed Estimation Uncertainty", "categories": ["cs.RO"], "comment": "16 pages, 11 figures, preprint", "summary": "Environmental monitoring robots often need to reconstruct spatial fields (e.g., salinity, temperature, bathymetry) under tight distance and energy constraints. Classical boustrophedon lawnmower surveys provide geometric coverage guarantees but can waste effort by oversampling predictable regions. In contrast, informative path planning (IPP) methods leverage spatial correlations to reduce oversampling, yet typically offer no guarantees on reconstruction quality. This paper bridges these approaches by addressing informative path planning with guaranteed estimation uncertainty: computing the shortest path whose measurements ensure that the Gaussian-process (GP) posterior variance -- an intrinsic uncertainty measure that lower-bounds the mean-squared prediction error under the GP model -- falls below a user-specified threshold over the monitoring region. We propose a three-stage approach: (i) learn a GP model from available prior information; (ii) transform the learned GP kernel into binary coverage maps for each candidate sensing location, indicating which locations' uncertainty can be reduced below a specified target; and (iii) plan a near-shortest route whose combined coverage satisfies the global uncertainty constraint. To address heterogeneous phenomena, we incorporate a nonstationary kernel that captures spatially varying correlation structure, and we accommodate non-convex environments with obstacles. Algorithmically, we present methods with provable approximation guarantees for sensing-location selection and for the joint selection-and-routing problem under a travel budget. Experiments on real-world topographic data show that our planners meet the uncertainty target using fewer sensing locations and shorter travel distances than a recent baseline, and field experiments with bathymetry-mapping autonomous surface and underwater vehicles demonstrate real-world feasibility.", "AI": {"tldr": "本文提出了一种在保证估计不确定性的情况下进行信息路径规划的方法，该方法结合了传统的几何覆盖和利用空间相关性的优化采样策略。", "motivation": "环境监测机器人通常需要在距离和能量约束下重建空间场。传统的布斯托法恩割草机路线虽提供几何覆盖保证，但在可预测区域过度采样的问题上效率低下。信息路径规划方法则通过减少不必要的采样来优化资源利用，但缺乏对重建质量的保障。", "method": "本文提出了一种三阶段的方法：首先学习一个高斯过程模型；然后将学到的核函数转换为二进制覆盖图以确定哪些位置的不确定性可以降至目标值以下；最后规划出一条满足全局不确定性的最短路径。", "result": "实验表明，所提出的规划器比最近的一个基准方法使用更少的采样点和较短的旅行距离来达到预期的不确定性水平。实地试验也证实了该策略在真实世界中的可行性。", "conclusion": "本文通过提出一种新的信息路径规划框架，在保证估计质量的同时提高了资源利用效率，证明了其理论上的优势以及实际应用的可能性。"}}
{"id": "2602.05195", "pdf": "https://arxiv.org/pdf/2602.05195", "abs": "https://arxiv.org/abs/2602.05195", "authors": ["Fengxian Chen", "Zhilong Tao", "Jiaxuan Li", "Yunlong Li", "Qingguo Zhou"], "title": "Traceable Cross-Source RAG for Chinese Tibetan Medicine Question Answering", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) promises grounded question answering, yet domain settings with multiple heterogeneous knowledge bases (KBs) remain challenging. In Chinese Tibetan medicine, encyclopedia entries are often dense and easy to match, which can dominate retrieval even when classics or clinical papers provide more authoritative evidence. We study a practical setting with three KBs (encyclopedia, classics, and clinical papers) and a 500-query benchmark (cutoff $K{=}5$) covering both single-KB and cross-KB questions. We propose two complementary methods to improve traceability, reduce hallucinations, and enable cross-KB verification. First, DAKS performs KB routing and budgeted retrieval to mitigate density-driven bias and to prioritize authoritative sources when appropriate. Second, we use an alignment graph to guide evidence fusion and coverage-aware packing, improving cross-KB evidence coverage without relying on naive concatenation. All answers are generated by a lightweight generator, \\textsc{openPangu-Embedded-7B}. Experiments show consistent gains in routing quality and cross-KB evidence coverage, with the full system achieving the best CrossEv@5 while maintaining strong faithfulness and citation correctness.", "AI": {"tldr": "该论文提出了一种针对藏医药问答的可追溯跨源检索增强生成（RAG）方法。", "motivation": "在藏医药领域，现有的检索增强生成模型面临多个异构知识库设置下的挑战。此方法旨在减少密度驱动偏差，提高权威证据的优先级，并支持跨知识库验证。", "method": "论文提出了两种互补的方法：DAKS进行知识库路由和预算内检索以减轻密度驱动偏差；使用对齐图引导证据融合和覆盖感知打包，从而增强跨知识库证据覆盖率。所有答案均由轻量生成器\textsc{openPangu-Embedded-7B}生成。", "result": "实验结果表明，在路由质量和跨知识库证据覆盖率上均有显著提升，完整系统在CrossEv@5指标下表现最佳，同时保持了强大的忠实度和引用正确性。", "conclusion": "论文提出的方法解决了藏医药问答中多个异构知识库设置下的挑战，提升了模型的可追溯性和准确性。"}}
{"id": "2602.05193", "pdf": "https://arxiv.org/pdf/2602.05193", "abs": "https://arxiv.org/abs/2602.05193", "authors": ["Xingfu Li", "Yongping Wang"], "title": "Polynomial-Time Solutions for Longest Common Subsequence Related Problems Between a Sequence and a Pangenome Graph", "categories": ["cs.DS"], "comment": "13 pages", "summary": "A pangenome captures the genetic diversity across multiple individuals simultaneously, providing a more comprehensive reference for genome analysis than a single linear genome, which may introduce allele bias. A widely adopted pangenome representation is a node-labeled directed graph, wherein the paths correspond to plausible genomic sequences within a species. Consequently, evaluating sequence-to-pangenome graph similarity constitutes a fundamental task in pangenome construction and analysis. This study explores the Longest Common Subsequence (LCS) problem and three of its variants involving a sequence and a pangenome graph. We present four polynomial-time reductions that transform these LCS-related problems into the longest path problem in a directed acyclic graph (DAG). These reductions demonstrate that all four problems can be solved in polynomial time, establishing their membership in the complexity class P.", "AI": {"tldr": "该论文探讨了序列与泛基因组图之间的最长公共子序列(LCS)问题及其三个变体，提出了四种多项式时间归约方法。", "motivation": "泛基因组图谱能更全面地表示物种遗传多样性。评估序列到泛基因组图的相似性是构建和分析泛基因组中的基础任务。", "method": "论文通过将LCS相关问题转换为有向无环图(DAG)中最长路径的问题，展示了四种多项式时间归约方法。", "result": "所有四个问题都可在多项式时间内解决，并被证明属于复杂度类P。", "conclusion": "该研究成功解决了序列与泛基因组图之间的LCS相关问题，证明了其在多项式时间内的可解性。"}}
{"id": "2602.05192", "pdf": "https://arxiv.org/pdf/2602.05192", "abs": "https://arxiv.org/abs/2602.05192", "authors": ["Mohammed Abouzaid", "Andrew J. Blumberg", "Martin Hairer", "Joe Kileel", "Tamara G. Kolda", "Paul D. Nelson", "Daniel Spielman", "Nikhil Srivastava", "Rachel Ward", "Shmuel Weinberger", "Lauren Williams"], "title": "First Proof", "categories": ["cs.AI", "math.AG", "math.CO", "math.GT", "math.HO", "math.RA"], "comment": "9 pages, including the statements of the ten questions", "summary": "To assess the ability of current AI systems to correctly answer research-level mathematics questions, we share a set of ten math questions which have arisen naturally in the research process of the authors. The questions had not been shared publicly until now; the answers are known to the authors of the questions but will remain encrypted for a short time.", "AI": {"tldr": "评估当前AI系统解答研究级数学问题的能力", "motivation": "检验现有AI系统能否正确回答研究级别的数学问题，展示一组在作者研究过程中自然产生的数学题目，并且这些题目之前未公开过。", "method": "发布一套由作者研究过程中的十个尚未公开的数学问题，并将答案加密保留一段时间以供验证。", "result": "当前结果未知，因为答案仍处于加密状态等待AI系统解答。", "conclusion": "通过未来AI系统的回答来评估其在解决高级数学问题上的能力"}}
{"id": "2602.05191", "pdf": "https://arxiv.org/pdf/2602.05191", "abs": "https://arxiv.org/abs/2602.05191", "authors": ["Wentao Ni", "Kangqi Zhang", "Zhongming Yu", "Oren Nelson", "Mingu Lee", "Hong Cai", "Fatih Porikli", "Jongryool Kim", "Zhijian Liu", "Jishen Zhao"], "title": "Double-P: Hierarchical Top-P Sparse Attention for Long-Context LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As long-context inference becomes central to large language models (LLMs), attention over growing key-value caches emerges as a dominant decoding bottleneck, motivating sparse attention for scalable inference. Fixed-budget top-k sparse attention cannot adapt to heterogeneous attention distributions across heads and layers, whereas top-p sparse attention directly preserves attention mass and provides stronger accuracy guarantees. Existing top-p methods, however, fail to jointly optimize top-p accuracy, selection overhead, and sparse attention cost, which limits their overall efficiency. We present Double-P, a hierarchical sparse attention framework that optimizes all three stages. Double-P first performs coarse-grained top-p estimation at the cluster level using size-weighted centroids, then adaptively refines computation through a second top-p stage that allocates token-level attention only when needed. Across long-context benchmarks, Double-P consistently achieves near-zero accuracy drop, reducing attention computation overhead by up to 1.8x and delivers up to 1.3x end-to-end decoding speedup over state-of-the-art fixed-budget sparse attention methods.", "AI": {"tldr": "本文提出了一种双层次稀疏注意框架Double-P，用于优化长上下文语言模型中的注意力计算。", "motivation": "随着长上下文推理成为大语言模型的核心问题，注意力机制在处理增长的键值缓存时成为解码瓶颈。现有top-p方法未能同时优化准确率、选择开销和稀疏注意成本，限制了整体效率。", "method": "Double-P首先通过簇级别的大小加权质心进行粗粒度的top-p估计，然后适应性地在第二阶段细化计算，仅当需要时分配令牌级注意力。", "result": "在长上下文基准测试中，Double-P实现了接近零精度下降，并将注意力计算开销减少了最多1.8倍，提供了最多1.3倍的整体解码速度提升。", "conclusion": "Double-P框架通过优化三个阶段有效提升了稀疏注意的准确率、效率和成本效益。"}}
{"id": "2602.05190", "pdf": "https://arxiv.org/pdf/2602.05190", "abs": "https://arxiv.org/abs/2602.05190", "authors": ["Ju Shen", "Chen Chen", "Tam V. Nguyen", "Vijayan K. Asari"], "title": "PoseGaussian: Pose-Driven Novel View Synthesis for Robust 3D Human Reconstruction", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "We propose PoseGaussian, a pose-guided Gaussian Splatting framework for high-fidelity human novel view synthesis. Human body pose serves a dual purpose in our design: as a structural prior, it is fused with a color encoder to refine depth estimation; as a temporal cue, it is processed by a dedicated pose encoder to enhance temporal consistency across frames. These components are integrated into a fully differentiable, end-to-end trainable pipeline. Unlike prior works that use pose only as a condition or for warping, PoseGaussian embeds pose signals into both geometric and temporal stages to improve robustness and generalization. It is specifically designed to address challenges inherent in dynamic human scenes, such as articulated motion and severe self-occlusion. Notably, our framework achieves real-time rendering at 100 FPS, maintaining the efficiency of standard Gaussian Splatting pipelines. We validate our approach on ZJU-MoCap, THuman2.0, and in-house datasets, demonstrating state-of-the-art performance in perceptual quality and structural accuracy (PSNR 30.86, SSIM 0.979, LPIPS 0.028).", "AI": {"tldr": "PoseGaussian是一种用于高保真人体新视点合成的框架，利用姿势信号来改进深度估计和时间一致性。", "motivation": "为了提高动态人体场景中的鲁棒性和泛化能力，提出了一种融合姿势作为结构性先验和时间线索的方法。", "method": "PoseGaussian将姿态信号嵌入到几何阶段和时间阶段中，并集成为可微分、端到端的训练管道。通过特定的姿态编码器来提高帧间的一致性。", "result": "该框架在ZJU-MoCap，THuman2.0以及自建数据集中展示了最先进的感知质量和结构准确性（PSNR 30.86, SSIM 0.979, LPIPS 0.028）。", "conclusion": "PoseGaussian能够有效应对动态人体场景中的挑战，并以每秒100帧的速度实现实时渲染。"}}
{"id": "2602.05189", "pdf": "https://arxiv.org/pdf/2602.05189", "abs": "https://arxiv.org/abs/2602.05189", "authors": ["Hsuan-Yu Chou", "Wajiha Naveed", "Shuyan Zhou", "Xiaowei Yang"], "title": "Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.SI"], "comment": null, "summary": "As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful content detection. While proprietary LLMs have been shown to zero-shot outperform traditional machine learning models, the out-of-the-box capability of open-weight LLMs remains an open question. Motivated by recent developments of reasoning LLMs, we evaluate seven state-of-the-art models: four proprietary and three open-weight. Testing with real-world posts on Bluesky, moderation decisions by Bluesky Moderation Service, and annotations by two authors, we find a considerable degree of overlap between the sensitivity (81%--97%) and specificity (91%--100%) of the open-weight LLMs and those (72%--98%, and 93%--99%) of the proprietary ones. Additionally, our analysis reveals that specificity exceeds sensitivity for rudeness detection, but the opposite holds for intolerance and threats. Lastly, we identify inter-rater agreement across human moderators and the LLMs, highlighting considerations for deploying LLMs in both platform-scale and personalized moderation contexts. These findings show open-weight LLMs can support privacy-preserving moderation on consumer-grade hardware and suggest new directions for designing moderation systems that balance community values with individual user preferences.", "AI": {"tldr": "研究对比了七种最先进的语言模型，包括四个专有和三个开放权重的语言模型，在Bluesky上的实际帖子中检测有害内容的能力。", "motivation": "随着互联网访问的扩大，人们对有害内容的暴露增加，因此有效的内容监管变得更为迫切。虽然研究表明大型语言模型可以用于社交媒体监管任务，但开放权重的语言模型是否能直接使用仍是一个疑问。这项研究旨在探索这个问题。", "method": "通过使用Bluesky的真实帖子、Bluesky Moderation Service的监管决策以及两名作者的注释，评估了七种最先进的模型：四个专有和三个开放权重的语言模型在有害内容检测任务中的表现。", "result": "实验结果显示，在鲁棒性检测中，特定性超过了敏感度；而在不宽容性和威胁检测方面，则是相反的情况。同时发现人类监管者之间以及语言模型之间的互评一致性，这为部署LLM提供了指导。", "conclusion": "这些发现表明开放权重的语言模型可以在消费者级硬件上支持隐私保护的监管，并提出了设计平衡社区价值观与个人用户偏好的监管系统的新方向。"}}
{"id": "2602.05184", "pdf": "https://arxiv.org/pdf/2602.05184", "abs": "https://arxiv.org/abs/2602.05184", "authors": ["Lauren Greenspan", "David Berman", "Aryeh Brill", "Ro Jefferson", "Artemy Kolchinsky", "Jennifer Lin", "Andrew Mack", "Anindita Maiti", "Fernando E. Rosas", "Alexander Stapleton", "Lucas Teixeira", "Dmitry Vaintrob"], "title": "Towards Worst-Case Guarantees with Scale-Aware Interpretability", "categories": ["hep-th", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "Neural networks organize information according to the hierarchical, multi-scale structure of natural data. Methods to interpret model internals should be similarly scale-aware, explicitly tracking how features compose across resolutions and guaranteeing bounds on the influence of fine-grained structure that is discarded as irrelevant noise. We posit that the renormalisation framework from physics can meet this need by offering technical tools that can overcome limitations of current methods. Moreover, relevant work from adjacent fields has now matured to a point where scattered research threads can be synthesized into practical, theory-informed tools. To combine these threads in an AI safety context, we propose a unifying research agenda -- \\emph{scale-aware interpretability} -- to develop formal machinery and interpretability tools that have robustness and faithfulness properties supported by statistical physics.", "AI": {"tldr": "提出了一种基于物理中的重整化框架的可解释性方法，以实现对神经网络模型内部结构的尺度感知分析。", "motivation": "现有的解释方法无法提供关于特征在不同分辨率下如何组合以及丢弃细粒度结构后的噪声影响的具体保证。因此需要一种新的可解释性方法来克服这些限制。", "method": "结合统计物理学中的重整化框架和其他相关领域的工作，提出了“尺度感知的可解释性”研究议程，以开发具有鲁棒性和忠实性的正式机器和工具。", "result": "通过这种新的方法论，可以实现对神经网络模型内部结构更深层次的理解，并提供形式化的保证。", "conclusion": "提出了一种新的研究方向，旨在开发出能够克服现有局限的、基于统计物理学理论的可解释性方法。"}}
{"id": "2602.05183", "pdf": "https://arxiv.org/pdf/2602.05183", "abs": "https://arxiv.org/abs/2602.05183", "authors": ["John Yan", "Michael Yu", "Yuqi Sun", "Alexander Duffy", "Tyler Marques", "Matthew Lyle Olson"], "title": "Data-Centric Interpretability for LLM-based Multi-Agent Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "authors 1, 2 and 3 contributed equally", "summary": "Large language models (LLMs) are increasingly trained in complex Reinforcement Learning, multi-agent environments, making it difficult to understand how behavior changes over training. Sparse Autoencoders (SAEs) have recently shown to be useful for data-centric interpretability. In this work, we analyze large-scale reinforcement learning training runs from the sophisticated environment of Full-Press Diplomacy by applying pretrained SAEs, alongside LLM-summarizer methods. We introduce Meta-Autointerp, a method for grouping SAE features into interpretable hypotheses about training dynamics. We discover fine-grained behaviors including role-playing patterns, degenerate outputs, language switching, alongside high-level strategic behaviors and environment-specific bugs. Through automated evaluation, we validate that 90% of discovered SAE Meta-Features are significant, and find a surprising reward hacking behavior. However, through two user studies, we find that even subjectively interesting and seemingly helpful SAE features may be worse than useless to humans, along with most LLM generated hypotheses. However, a subset of SAE-derived hypotheses are predictively useful for downstream tasks. We further provide validation by augmenting an untrained agent's system prompt, improving the score by +14.2%. Overall, we show that SAEs and LLM-summarizer provide complementary views into agent behavior, and together our framework forms a practical starting point for future data-centric interpretability work on ensuring trustworthy LLM behavior throughout training.", "AI": {"tldr": "本文通过使用预训练的稀疏自编码器和语言模型摘要方法，分析大型强化学习训练过程中的行为变化，并提出了一种名为Meta-Autointerp的方法来解释这些变化。", "motivation": "随着大型语言模型在复杂的多智能体环境中进行强化学习变得越来越常见，理解其行为的变化变得更加困难。稀疏自编码器已被证明有助于数据集的可解释性分析，因此本文旨在利用这种工具深入了解大型语言模型在训练过程中的行为。", "method": "文章介绍了Meta-Autointerp方法，该方法将稀疏自编码器特征分组以形成关于训练动态的可解释假设。同时使用了预训练的稀疏自编码器和语言模型摘要技术来分析代理的行为。通过自动化评估验证这些特征的有效性，并进行了用户研究。", "result": "发现了细微行为模式，包括角色扮演、退化输出、语言切换等现象以及高级战略行为和环境特定错误。自动化评估表明90%的稀疏自编码器元特征是显著的。但是主观有趣且看似有用的稀疏自编码器特征对于人类来说可能是无用甚至有害的，而某些由稀疏自编码器衍生出的假设对下游任务具有预测价值。", "conclusion": "研究表明，通过结合稀疏自编码器和语言模型摘要方法可以提供关于代理行为的不同视角。这种框架为确保训练过程中大型语言模型的行为可信性提供了实用起点。"}}
{"id": "2602.05178", "pdf": "https://arxiv.org/pdf/2602.05178", "abs": "https://arxiv.org/abs/2602.05178", "authors": ["Magesh Rajasekaran", "Md Saiful Sajol", "Chris Alvin", "Supratik Mukhopadhyay", "Yanda Ou", "Z. George Xue"], "title": "Benchmarking Artificial Intelligence Models for Daily Coastal Hypoxia Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "This is a Preprint accepted at IEEE Big Data 2025", "summary": "Coastal hypoxia, especially in the northern part of Gulf of Mexico, presents a persistent ecological and economic concern. Seasonal models offer coarse forecasts that miss the fine-scale variability needed for daily, responsive ecosystem management. We present study that compares four deep learning architectures for daily hypoxia classification: Bidirectional Long Short-Term Memory (BiLSTM), Medformer (Medical Transformer), Spatio-Temporal Transformer (ST-Transformer), and Temporal Convolutional Network (TCN). We trained our models with twelve years of daily hindcast data from 2009-2020 Our training data consists of 2009-2020 hindcast data from a coupled hydrodynamic-biogeochemical model. Similarly, we use hindcast data from 2020 through 2024 as a test data. We constructed classification models incorporating water column stratification, sediment oxygen consumption, and temperature-dependent decomposition rates. We evaluated each architectures using the same data preprocessing, input/output formulation, and validation protocols. Each model achieved high classification accuracy and strong discriminative ability with ST-Transformer achieving the highest performance across all metrics and tests periods (AUC-ROC: 0.982-0.992). We also employed McNemar's method to identify statistically significant differences in model predictions. Our contribution is a reproducible framework for operational real-time hypoxia prediction that can support broader efforts in the environmental and ocean modeling systems community and in ecosystem resilience. The source code is available https://github.com/rmagesh148/hypoxia-ai/", "AI": {"tldr": "本文通过比较四种深度学习架构，为每日低氧预测构建了一个可重复使用的框架。", "motivation": "季节性模型提供的粗略预报无法满足生态系统管理所需的细尺度变化。文章旨在解决这一问题，并提供一个支持环境和海洋建模系统的实时低氧预测框架。", "method": "本文比较了四种深度学习架构：BiLSTM、Medformer、ST-Transformer 和 TCN，使用2009年至2020年的每日再分析数据进行训练，并用2020至2024年的数据作为测试。所有模型均采用相同的预处理步骤和验证协议。", "result": "各模型实现了高分类准确度和强大的判别能力。ST-Transformer 在所有指标和测试期间取得了最佳性能（AUC-ROC：0.982-0.992），并利用McNemar方法确定了预测之间的显著差异。", "conclusion": "本文提出了一种用于操作实时低氧预测的可重复框架，有助于提升生态系统恢复力，并对环境和海洋建模系统社区具有贡献价值。"}}
{"id": "2602.05175", "pdf": "https://arxiv.org/pdf/2602.05175", "abs": "https://arxiv.org/abs/2602.05175", "authors": ["Zhe Li", "Bernhard Kainz"], "title": "ShapePuri: Shape Guided and Appearance Generalized Adversarial Purification", "categories": ["cs.CV"], "comment": "10 pages, 5 figures", "summary": "Deep neural networks demonstrate impressive performance in visual recognition, but they remain vulnerable to adversarial attacks that is imperceptible to the human. Although existing defense strategies such as adversarial training and purification have achieved progress, diffusion-based purification often involves high computational costs and information loss. To address these challenges, we introduce Shape Guided Purification (ShapePuri), a novel defense framework enhances robustness by aligning model representations with stable structural invariants. ShapePuri integrates two components: a Shape Encoding Module (SEM) that provides dense geometric guidance through Signed Distance Functions (SDF), and a Global Appearance Debiasing (GAD) module that mitigates appearance bias via stochastic transformations. In our experiments, ShapePuri achieves $84.06\\%$ clean accuracy and $81.64\\%$ robust accuracy under the AutoAttack protocol, representing the first defense framework to surpass the $80\\%$ threshold on this benchmark. Our approach provides a scalable and efficient adversarial defense that preserves prediction stability during inference without requiring auxiliary modules or additional computational cost.", "AI": {"tldr": "ShapePuri是一种通过形状指导和外观去偏来增强模型鲁棒性的新型防御框架，它在保持预测稳定性的同时提高了对抗攻击的抵抗力。", "motivation": "现有的对抗训练和净化策略虽然取得了一定进展，但扩散式净化通常涉及高昂的计算成本和信息丢失。为了解决这些问题，提出ShapePuri以提高模型对对抗性样本的鲁棒性。", "method": "ShapePuri结合了形状编码模块（SEM）和全局外观去偏模块（GAD），通过Signed Distance Functions提供密集几何指导，并利用随机变换减轻外观偏差。", "result": "在AutoAttack协议下，ShapePuri达到了84.06%的干净准确率和81.64%的鲁棒性准确率，成为首个在此基准测试上超过80%阈值的防御框架。", "conclusion": "ShapePuri提供了一种可扩展且高效的对抗防御方法，在不增加额外计算成本的情况下保持预测稳定性。"}}
{"id": "2602.05174", "pdf": "https://arxiv.org/pdf/2602.05174", "abs": "https://arxiv.org/abs/2602.05174", "authors": ["Yunrui Guan", "Krishnakumar Balasubramanian", "Shiqian Ma"], "title": "Total Variation Rates for Riemannian Flow Matching", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST"], "comment": null, "summary": "Riemannian flow matching (RFM) extends flow-based generative modeling to data supported on manifolds by learning a time-dependent tangent vector field whose flow-ODE transports a simple base distribution to the data law. We develop a nonasymptotic Total Variation (TV) convergence analysis for RFM samplers that use a learned vector field together with Euler discretization on manifolds. Our key technical ingredient is a differential inequality governing the evolution of TV between two manifold ODE flows, which expresses the time-derivative of TV through the divergence of the vector-field mismatch and the score of the reference flow; controlling these terms requires establishing new bounds that explicitly account for parallel transport and curvature. Under smoothness assumptions on the population flow-matching field and either uniform (compact manifolds) or mean-square (Hadamard manifolds) approximation guarantees for the learned field, we obtain explicit bounds of the form $\\mathrm{TV}\\le C_{\\mathrm{Lip}}\\,h + C_{\\varepsilon}\\,\\varepsilon$ (with an additional higher-order $\\varepsilon^2$ term on compact manifolds), cleanly separating numerical discretization and learning errors. Here, $h$ is the step-size and $\\varepsilon$ is the target accuracy. Instantiations yield \\emph{explicit} polynomial iteration complexities on the hypersphere $S^d$, and on the SPD$(n)$ manifolds under mild moment conditions.", "AI": {"tldr": "该论文研究了黎曼流匹配（RFM）的总体变差收敛性，特别是在使用学习到的速度场与欧拉离散化方法时。", "motivation": "开发非渐近性的总变差（TV）收敛分析来改进在流形上运行的生成模型的学习效果，从而提高数据分布的逼近精度。", "method": "通过研究两个流形ODE流动之间总体变差随时间演化的微分不等式，并结合平行运输和曲率影响的新界限控制。", "result": "获得了清晰区分数值离散化和学习误差形式的明确界值，例如在超球体$S^d$上的显式多项式迭代复杂度以及SPD$(n)$流形下的温和矩条件下。", "conclusion": "研究结果表明了黎曼流匹配（RFM）方法的有效性，并且为未来进一步研究提供了理论基础。"}}
{"id": "2602.05165", "pdf": "https://arxiv.org/pdf/2602.05165", "abs": "https://arxiv.org/abs/2602.05165", "authors": ["Kevin Han", "Yuhang Zhou", "Mingze Gao", "Gedi Zhou", "Serena Li", "Abhishek Kumar", "Xiangjun Fan", "Weiwei Li", "Lizhu Zhang"], "title": "EBPO: Empirical Bayes Shrinkage for Stabilizing Group-Relative Policy Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for enhancing the reasoning capabilities of Large Language Models (LLMs). However, dominant approaches like Group Relative Policy Optimization (GRPO) face critical stability challenges: they suffer from high estimator variance under computational constraints (small group sizes) and vanishing gradient signals in saturated failure regimes where all responses yield identical zero rewards. To address this, we propose Empirical Bayes Policy Optimization (EBPO), a novel framework that regularizes local group-based baselines by borrowing strength from the policy's accumulated global statistics. Instead of estimating baselines in isolation, EBPO employs a shrinkage estimator that dynamically balances local group statistics with a global prior updated via Welford's online algorithm. Theoretically, we demonstrate that EBPO guarantees strictly lower Mean Squared Error (MSE), bounded entropy decay, and non-vanishing penalty signals in failure scenarios compared to GRPO. Empirically, EBPO consistently outperforms GRPO and other established baselines across diverse benchmarks, including AIME and OlympiadBench. Notably, EBPO exhibits superior training stability, achieving high-performance gains even with small group sizes, and benefits significantly from difficulty-stratified curriculum learning.", "AI": {"tldr": "该论文提出了EBPO框架，通过借用全局统计信息来稳定局部组基线估计，解决GRPO在小群体规模和饱和失败模式下的稳定性问题。", "motivation": "为了应对RLVR中GRPO方法面临的高估方差和梯度信号消失的问题，提出一种新的优化框架以提高模型训练的稳定性。", "method": "EBPO利用Empirical Bayes的方法来调节局部组基线，通过Welford在线算法动态地平衡本地群体统计数据与全局先验信息。理论分析证明了该方法在降低MSE、保持熵衰减和防止失败场景下的梯度消失方面的有效性。", "result": "实验证明EBPO在不同基准测试中优于GRPO和其他基线模型，尤其在小群体规模下表现出更高的训练稳定性，并且受益于难度分层的课程学习。", "conclusion": "EBPO通过利用全局统计信息来稳定局部组基线估计，成功解决了RLVR中的关键稳定性问题。"}}
{"id": "2602.05164", "pdf": "https://arxiv.org/pdf/2602.05164", "abs": "https://arxiv.org/abs/2602.05164", "authors": ["Shoaib Ahmed Siddiqui", "Eleni Triantafillou", "David Krueger", "Adrian Weller"], "title": "Position: Capability Control Should be a Separate Goal From Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models are trained on broad data distributions, yielding generalist capabilities that enable many downstream applications but also expand the space of potential misuse and failures. This position paper argues that capability control -- imposing restrictions on permissible model behavior -- should be treated as a distinct goal from alignment. While alignment is often context and preference-driven, capability control aims to impose hard operational limits on permissible behaviors, including under adversarial elicitation. We organize capability control mechanisms across the model lifecycle into three layers: (i) data-based control of the training distribution, (ii) learning-based control via weight- or representation-level interventions, and (iii) system-based control via post-deployment guardrails over inputs, outputs, and actions. Because each layer has characteristic failure modes when used in isolation, we advocate for a defense-in-depth approach that composes complementary controls across the full stack. We further outline key open challenges in achieving such control, including the dual-use nature of knowledge and compositional generalization.", "AI": {"tldr": "本文主张将能力控制作为与对齐不同的目标进行处理，提出了一种多层次的防御策略以实现模型行为限制。", "motivation": "由于基础模型训练于广泛的数据分布上，具备多种潜在的应用和风险，作者认为需要独立考虑能力控制的问题，并提出一套机制来应对各种挑战。", "method": "文章提出了三层防护模式：基于数据的方法、学习方法以及系统级控制，旨在通过多层次的防御策略实现对模型行为的有效限制。", "result": "论文详细描述了不同层次保护措施的特性及其潜在的风险，并指出了实现这一目标的关键开放性问题。", "conclusion": "作者强调跨层组合控制的重要性，以应对基础模型中的能力滥用风险。"}}
{"id": "2602.05163", "pdf": "https://arxiv.org/pdf/2602.05163", "abs": "https://arxiv.org/abs/2602.05163", "authors": ["Andreas Mentzelopoulos", "Keith Ellenbogen"], "title": "LOBSTgER-enhance: an underwater image enhancement pipeline", "categories": ["cs.CV"], "comment": "12 pages, 30 figures, work done as part of LOBSTgER", "summary": "Underwater photography presents significant inherent challenges including reduced contrast, spatial blur, and wavelength-dependent color distortions. These effects can obscure the vibrancy of marine life and awareness photographers in particular are often challenged with heavy post-processing pipelines to correct for these distortions. We develop an image-to-image pipeline that learns to reverse underwater degradations by introducing a synthetic corruption pipeline and learning to reverse its effects with diffusion-based generation. Training and evaluation are performed on a small high-quality dataset of awareness photography images by Keith Ellenbogen. The proposed methodology achieves high perceptual consistency and strong generalization in synthesizing 512x768 images using a model of ~11M parameters after training from scratch on ~2.5k images.", "AI": {"tldr": "开发了一种图像到图像的流水线，用于学习逆转水下成像中的降质问题。", "motivation": "解决水下摄影中存在的对比度降低、空间模糊以及波长依赖的颜色失真等问题，以增强海洋生物的色彩表现力，并减少摄影师在后期处理方面的负担。", "method": "通过引入合成腐蚀流水线和学习逆转其效果的方法，使用基于扩散生成的技术。训练与评估是通过Keith Ellenbogen的小规模高质量水下摄影作品集进行的。", "result": "提出的方法在感知一致性以及从头开始训练后，在2.5k张图像上合成了512x768大小的图像时表现出色，参数量约为11M。", "conclusion": "该方法通过学习逆转水下成像中的降质效果，有效地增强了水下摄影的质量，并展示了良好的泛化能力。"}}
{"id": "2602.05162", "pdf": "https://arxiv.org/pdf/2602.05162", "abs": "https://arxiv.org/abs/2602.05162", "authors": ["Anay Majee", "Rishabh Iyer"], "title": "SHaSaM: Submodular Hard Sample Mining for Fair Facial Attribute Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "21 pages, 7 tables, 10 figures", "summary": "Deep neural networks often inherit social and demographic biases from annotated data during model training, leading to unfair predictions, especially in the presence of sensitive attributes like race, age, gender etc. Existing methods fall prey to the inherent data imbalance between attribute groups and inadvertently emphasize on sensitive attributes, worsening unfairness and performance. To surmount these challenges, we propose SHaSaM (Submodular Hard Sample Mining), a novel combinatorial approach that models fairness-driven representation learning as a submodular hard-sample mining problem. Our two-stage approach comprises of SHaSaM-MINE, which introduces a submodular subset selection strategy to mine hard positives and negatives - effectively mitigating data imbalance, and SHaSaM-LEARN, which introduces a family of combinatorial loss functions based on Submodular Conditional Mutual Information to maximize the decision boundary between target classes while minimizing the influence of sensitive attributes. This unified formulation restricts the model from learning features tied to sensitive attributes, significantly enhancing fairness without sacrificing performance. Experiments on CelebA and UTKFace demonstrate that SHaSaM achieves state-of-the-art results, with up to 2.7 points improvement in model fairness (Equalized Odds) and a 3.5% gain in Accuracy, within fewer epochs as compared to existing methods.", "AI": {"tldr": "SHaSaM 提出了一种用于公平面部属性识别的子模优化难例挖掘方法。", "motivation": "深度神经网络从注释数据中继承了社会和人口统计学偏见，导致预测不公平。现有方法未能解决数据不平衡问题，反而强调敏感属性，使不公加重。", "method": "SHaSaM 包括两个阶段：SHaSaM-MINE 使用子模集选择策略挖掘难正负例以缓解数据不平衡；SHaSaM-LEARN 基于子模条件互信息引入组合损失函数，增强决策边界同时减少敏感属性的影响。", "result": "实验表明 SHaSaM 达到了最先进的结果，在 CelebA 和 UTKFace 数据集中提高了模型公平性（等化机会）2.7分，并提升了3.5%的准确率。", "conclusion": "SHaSaM 在提高模型公平性和性能方面取得了显著成效，证明了其在解决深度学习中敏感属性偏见问题上的有效性。"}}
{"id": "2602.05159", "pdf": "https://arxiv.org/pdf/2602.05159", "abs": "https://arxiv.org/abs/2602.05159", "authors": ["Wenhui Cui", "Ziyi Kou", "Chuan Qin", "Ergys Ristani", "Li Guan"], "title": "AirGlove: Exploring Egocentric 3D Hand Tracking and Appearance Generalization for Sensing Gloves", "categories": ["cs.CV"], "comment": "Accepted by ICASSP 2026", "summary": "Sensing gloves have become important tools for teleoperation and robotic policy learning as they are able to provide rich signals like speed, acceleration and tactile feedback. A common approach to track gloved hands is to directly use the sensor signals (e.g., angular velocity, gravity orientation) to estimate 3D hand poses. However, sensor-based tracking can be restrictive in practice as the accuracy is often impacted by sensor signal and calibration quality. Recent advances in vision-based approaches have achieved strong performance on human hands via large-scale pre-training, but their performance on gloved hands with distinct visual appearances remains underexplored. In this work, we present the first systematic evaluation of vision-based hand tracking models on gloved hands under both zero-shot and fine-tuning setups. Our analysis shows that existing bare-hand models suffer from substantial performance degradation on sensing gloves due to large appearance gap between bare-hand and glove designs. We therefore propose AirGlove, which leverages existing gloves to generalize the learned glove representations towards new gloves with limited data. Experiments with multiple sensing gloves show that AirGlove effectively generalizes the hand pose models to new glove designs and achieves a significant performance boost over the compared schemes.", "AI": {"tldr": "本文提出了AirGlove，一种利用现有手套泛化学习的手套表示的方法，以适应新的手套设计。", "motivation": "当前基于传感器的手部跟踪方法受到信号质量和校准准确性的影响，而现有的基于视觉的手部跟踪模型在处理外观不同的手套时表现不佳。因此，需要探索更好的泛化策略来提高手套手部跟踪的性能。", "method": "AirGlove利用现有手套的数据，在零样本和微调设置下评估了视觉手部跟踪模型在佩戴手套的情况下的效果，并通过有限的新手套数据实现了对手套表示的有效泛化。", "result": "实验表明，与现有方法相比，AirGlove能够显著提高新设计手套的手部姿态预测性能。", "conclusion": "本文展示了首次针对穿戴式手套的视觉手部跟踪系统的全面评估，并提出了基于AirGlove的新方法来解决不同外观的手套带来的挑战。"}}
{"id": "2602.05156", "pdf": "https://arxiv.org/pdf/2602.05156", "abs": "https://arxiv.org/abs/2602.05156", "authors": ["Dong Ho Kang", "Aaron Kim", "Mingyo Seo", "Kazuto Yokoyama", "Tetsuya Narita", "Luis Sentis"], "title": "PLATO Hand: Shaping Contact Behavior with Fingernails for Precise Manipulation", "categories": ["cs.RO", "eess.SY"], "comment": null, "summary": "We present the PLATO Hand, a dexterous robotic hand with a hybrid fingertip that embeds a rigid fingernail within a compliant pulp. This design shapes contact behavior to enable diverse interaction modes across a range of object geometries. We develop a strain-energy-based bending-indentation model to guide the fingertip design and to explain how guided contact preserves local indentation while suppressing global bending. Experimental results show that the proposed robotic hand design demonstrates improved pinching stability, enhanced force observability, and successful execution of edge-sensitive manipulation tasks, including paper singulation, card picking, and orange peeling. Together, these results show that coupling structured contact geometry with a force-motion transparent mechanism provides a principled, physically embodied approach to precise manipulation.", "AI": {"tldr": "设计了一种具有嵌入刚性指甲的PLATO Hand机械手，以改善精密操作。", "motivation": "旨在通过改变指尖接触行为来提高机器人手对不同物体几何形状的多样互动模式和精确操控能力。", "method": "开发了基于应变能量的弯曲-压入模型，用于指导指尖设计，并解释如何引导接触可以保持局部压入同时抑制全局弯曲。", "result": "实验结果显示该机械手设计方案在捏持稳定性、力观测性和边缘敏感操作任务方面有所提高。", "conclusion": "将结构化接触几何形状与透明的力-运动机制相结合，为精密操控提供了基于物理实体的方法。"}}
{"id": "2602.05148", "pdf": "https://arxiv.org/pdf/2602.05148", "abs": "https://arxiv.org/abs/2602.05148", "authors": ["Songtao Wei", "Yi Li", "Bohan Zhang", "Zhichun Guo", "Ying Huang", "Yuede Ji", "Miao Yin", "Guanpeng Li", "Bingzhe Li"], "title": "CoSA: Compressed Sensing-Based Adaptation of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) has emerged as a practical paradigm for adapting large language models (LLMs) without updating all parameters. Most existing approaches, such as LoRA and PiSSA, rely on low-rank decompositions of weight updates. However, the low-rank assumption may restrict expressivity, particularly in task-specific adaptation scenarios where singular values are distributed relatively uniformly. To address this limitation, we propose CoSA (Compressed Sensing-Based Adaptation), a new PEFT method extended from compressed sensing theory. Instead of constraining weight updates to a low-rank subspace, CoSA expresses them through fixed random projection matrices and a compact learnable core. We provide a formal theoretical analysis of CoSA as a synthesis process, proving that weight updates can be compactly encoded into a low-dimensional space and mapped back through random projections. Extensive experimental results show that CoSA provides a principled perspective for efficient and expressive multi-scale model adaptation. Specifically, we evaluate CoSA on 10 diverse tasks, including natural language understanding and generation, employing 5 models of different scales from RoBERTa, Llama, and Qwen families. Across these settings, CoSA consistently matches or outperforms state-of-the-art PEFT methods.", "AI": {"tldr": "CoSA是一种基于压缩感知理论的参数高效微调方法，用于大语言模型的任务特定适应。", "motivation": "现有的PEFT方法依赖于权重更新的低秩分解，这可能限制了表达能力。为了提高任务特异性场景下的灵活性和效率，提出了CoSA。", "method": "CoSA通过固定随机投影矩阵和紧凑可学习核心来表示权重更新，并提供了形式化的理论分析。", "result": "实验结果表明，CoSA在不同规模的语言模型上表现优秀，超越或匹敌现有的最先进技术。", "conclusion": "CoSA为大语言模型的高效适应提供了一种新的视角，证明了其在多尺度任务中的优越性。"}}
{"id": "2602.05146", "pdf": "https://arxiv.org/pdf/2602.05146", "abs": "https://arxiv.org/abs/2602.05146", "authors": ["Wonjun Yi", "Rismaya Kumar Mishra", "Yong-Hwa Park"], "title": "Cross-talk based multi-task learning for fault classification of physically coupled machine system", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to 32th International Congress on Sound and Vibration (ICSV32)", "summary": "Machine systems inherently generate signals in which fault conditions and various physical variables are physically coupled. Although many existing fault classification studies rely solely on direct fault labels, the aforementioned signals naturally embed additional information shaped by other physically coupled information. Herein, we leverage this coupling through a multi-task learning (MTL) framework that jointly learns fault conditions and the related physical variables. Among MTL architectures, crosstalk structures have distinct advantages because they allow for controlled information exchange between tasks through the cross-talk layer while preventing negative transfer, in contrast to shared trunk architectures that often mix incompatible features. We build on our previously introduced residual neural dimension reductor model, and extend its application to two benchmarks where physical coupling is prominent. The first benchmark is a drone fault dataset, in which machine type and maneuvering direction significantly alter the frequency components of measured signals even under the same nominal condition. By learning fault classification together with these physical attributes, the cross-talk architecture can better classify faults. The second benchmark dataset is the motor compound fault dataset. In this system, each fault component, inner race fault, outer race fault, misalignment, and unbalance is coupled to the other. For motor compound fault, we also test classification performance when we use single-channel data or multi-channel data as input to the classifier. Across both benchmarks, our residual neural dimension reductor, consistently outperformed single-task models, multi-class models that merge all label combinations, and shared trunk multi-task models.", "AI": {"tldr": "本文提出了一种基于交叉对话的多任务学习框架，用于物理耦合机器系统的故障分类。", "motivation": "传统的故障检测方法主要依赖直接的故障标签，但实际信号中还包含了其他相关的物理变量信息。通过引入多任务学习并利用这些耦合信息，可以提高故障分类性能。", "method": "作者使用了基于残差神经网络维度缩减模型的交叉对话结构，在两个具有显著物理耦合特性的数据集上进行实验：无人机故障数据集和电机复合故障数据集。", "result": "实验结果显示，所提出的交叉对话架构在两个基准测试中均优于单任务模型、多类合并标签的模型以及共享主干的多任务学习模型。", "conclusion": "该研究证明了通过利用信号中的物理耦合信息进行多任务学习可以有效提高故障分类精度。"}}
{"id": "2602.05145", "pdf": "https://arxiv.org/pdf/2602.05145", "abs": "https://arxiv.org/abs/2602.05145", "authors": ["Jiyoung Park", "Hankyu Jang", "Changseok Song", "Wookeun Jung"], "title": "TIDE: Temporal Incremental Draft Engine for Self-Improving LLM Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Speculative decoding can substantially accelerate LLM inference, but realizing its benefits in practice is challenging due to evolving workloads and system-level constraints. We present TIDE (Temporal Incremental Draft Engine), a serving-engine-native framework that integrates online draft adaptation directly into high-performance LLM inference systems. TIDE reuses target model hidden states generated during inference as training signals, enabling zero-overhead draft adaptation without reloading the target model, and employs adaptive runtime control to activate speculation and training only when beneficial. TIDE exploits heterogeneous clusters by mapping decoupled inference and training to appropriate GPU classes. Across diverse real-world workloads, TIDE achieves up to 1.15x throughput improvement over static speculative decoding while reducing draft training time by 1.67x compared to approaches that recompute training signals.", "AI": {"tldr": "TIDE是一种集成在线草稿适应的框架，用于提高大型语言模型（LLM）推断速度。", "motivation": "在实际应用中，通过推测性解码加速LLM推理存在挑战。为了克服这些问题并充分利用动态工作负载和系统级约束条件，作者提出了一种新的框架TIDE来解决这些难题。", "method": "TIDE利用生成的目标模型隐藏状态作为训练信号，在不重新加载目标模型的情况下实现零开销的草稿适应，并使用自适应运行时控制仅在有益时激活推测和培训。此外，它通过将解耦推断和训练映射到适当的GPU类来利用异构集群。", "result": "与静态推测性解码相比，TIDE在各种现实世界的工作负载中实现了高达1.15倍的吞吐量改进，并且减少了草稿培训时间1.67倍。", "conclusion": "通过结合在线草稿适应和自适应运行时控制策略，TIDE不仅提高了模型推断效率，还优化了资源利用率。"}}
{"id": "2602.05143", "pdf": "https://arxiv.org/pdf/2602.05143", "abs": "https://arxiv.org/abs/2602.05143", "authors": ["Nengbo Wang", "Tuo Liang", "Vikash Singh", "Chaoda Song", "Van Yang", "Yu Yin", "Jing Ma", "Jagdip Singh", "Vipin Chaudhary"], "title": "HugRAG: Hierarchical Causal Knowledge Graph Design for RAG", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack explicit causal modeling, leading to unfaithful or spurious answers. Prior attempts to incorporate causality are typically limited to local or single-document contexts and also suffer from information isolation that arises from modular graph structures, which hinders scalability and cross-module causal reasoning. To address these challenges, we propose HugRAG, a framework that rethinks knowledge organization for graph-based RAG through causal gating across hierarchical modules. HugRAG explicitly models causal relationships to suppress spurious correlations while enabling scalable reasoning over large-scale knowledge graphs. Extensive experiments demonstrate that HugRAG consistently outperforms competitive graph-based RAG baselines across multiple datasets and evaluation metrics. Our work establishes a principled foundation for structured, scalable, and causally grounded RAG systems.", "AI": {"tldr": "提出了HugRAG框架，通过层次化模块之间的因果门控来重新组织知识，以抑制虚假相关性并实现大规模知识图上的可扩展推理。", "motivation": "现有基于图形的增强生成方法过度依赖表面级节点匹配，并且缺乏显式因果建模，导致不准确或错误的答案。为解决这些问题，提出了HugRAG框架。", "method": "通过层次化模块之间的因果门控来重新组织知识图结构，以抑制虚假相关性并实现大规模知识图上的可扩展推理。", "result": "实验结果表明，HugRAG在多个数据集和评估指标上均优于现有基于图形的增强生成方法。", "conclusion": "提出了一个有原则的基础框架用于构建结构化、可扩展且具有因果性的基于图形的增强生成系统。"}}
{"id": "2602.05142", "pdf": "https://arxiv.org/pdf/2602.05142", "abs": "https://arxiv.org/abs/2602.05142", "authors": ["Rulla Al-Haideri", "Bilal Farooq"], "title": "Modelling Pedestrian Behaviour in Autonomous Vehicle Encounters Using Naturalistic Dataset", "categories": ["physics.soc-ph", "cs.RO"], "comment": null, "summary": "Understanding how pedestrians adjust their movement when interacting with autonomous vehicles (AVs) is essential for improving safety in mixed traffic. This study examines micro-level pedestrian behaviour during midblock encounters in the NuScenes dataset using a hybrid discrete choice-machine learning framework based on the Residual Logit (ResLogit) model. The model incorporates temporal, spatial, kinematic, and perceptual indicators. These include relative speed, visual looming, remaining distance, and directional collision risk proximity (CRP) measures. Results suggest that some of these variables may meaningfully influence movement adjustments, although predictive performance remains moderate. Marginal effects and elasticities indicate strong directional asymmetries in risk perception, with frontal and rear CRP showing opposite influences. The remaining distance exhibits a possible mid-crossing threshold. Relative speed cues appear to have a comparatively less effect. These patterns may reflect multiple behavioural tendencies driven by both risk perception and movement efficiency.", "AI": {"tldr": "研究使用混合离散选择-机器学习框架基于Residual Logit模型，分析行人与自动驾驶车辆相遇时的行为调整。", "motivation": "提高混行交通的安全性，理解行人如何在与自动驾驶车辆交互过程中调整自己的移动方式。", "method": "采用NuScenes数据集中的自然主义数据，构建混合离散选择-机器学习框架，基于Residual Logit模型，考虑了时间、空间、运动学和感知指标。", "result": "结果表明某些变量对行人的行为调整有显著影响，但预测性能一般。边际效应和弹性系数显示风险感知的方向性不对称，剩余距离可能有一个中间穿越阈值。", "conclusion": "这些模式反映了由风险感知与移动效率驱动的多种行为倾向。"}}
{"id": "2602.05133", "pdf": "https://arxiv.org/pdf/2602.05133", "abs": "https://arxiv.org/abs/2602.05133", "authors": ["Abdul Joseph Fofanah", "Lian Wen", "David Chen", "Alpha Alimamy Kamara", "Zhongyi Zhang"], "title": "CAST-CKT: Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer for Traffic Flow Prediction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Traffic prediction in data-scarce, cross-city settings is challenging due to complex nonlinear dynamics and domain shifts. Existing methods often fail to capture traffic's inherent chaotic nature for effective few-shot learning. We propose CAST-CKT, a novel Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer framework. It employs an efficient chaotic analyser to quantify traffic predictability regimes, driving several key innovations: chaos-aware attention for regime-adaptive temporal modelling; adaptive topology learning for dynamic spatial dependencies; and chaotic consistency-based cross-city alignment for knowledge transfer. The framework also provides horizon-specific predictions with uncertainty quantification. Theoretical analysis shows improved generalisation bounds. Extensive experiments on four benchmarks in cross-city few-shot settings show CAST-CKT outperforms state-of-the-art methods by significant margins in MAE and RMSE, while offering interpretable regime analysis. Code is available at https://github.com/afofanah/CAST-CKT.", "AI": {"tldr": "提出了一种新的框架CAST-CKT，用于解决数据稀缺、跨城市交通预测中的复杂非线性动态问题。", "motivation": "现有的方法在捕捉交通的混沌特性方面存在不足，难以实现有效的少样本学习。", "method": "采用高效的混沌分析器量化交通可预测性模式，并提出适应时空依赖性的注意力机制和跨城知识转移策略。", "result": "实验结果表明，CAST-CKT在多任务设置中显著优于现有方法，在MAE和RMSE指标上表现出色。", "conclusion": "该研究提供了一种改进的少样本学习框架，有效解决了交通预测中的复杂非线性动态问题。"}}
{"id": "2602.05132", "pdf": "https://arxiv.org/pdf/2602.05132", "abs": "https://arxiv.org/abs/2602.05132", "authors": ["Jia Li", "Wenjie Zhao", "Shijian Deng", "Bolin Lai", "Yuheng Wu", "RUijia Chen", "Jon E. Froehlich", "Yuhang Zhao", "Yapeng Tian"], "title": "ARGaze: Autoregressive Transformers for Online Egocentric Gaze Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Online egocentric gaze estimation predicts where a camera wearer is looking from first-person video using only past and current frames, a task essential for augmented reality and assistive technologies. Unlike third-person gaze estimation, this setting lacks explicit head or eye signals, requiring models to infer current visual attention from sparse, indirect cues such as hand-object interactions and salient scene content. We observe that gaze exhibits strong temporal continuity during goal-directed activities: knowing where a person looked recently provides a powerful prior for predicting where they look next. Inspired by vision-conditioned autoregressive decoding in vision-language models, we propose ARGaze, which reformulates gaze estimation as sequential prediction: at each timestep, a transformer decoder predicts current gaze by conditioning on (i) current visual features and (ii) a fixed-length Gaze Context Window of recent gaze target estimates. This design enforces causality and enables bounded-resource streaming inference. We achieve state-of-the-art performance across multiple egocentric benchmarks under online evaluation, with extensive ablations validating that autoregressive modeling with bounded gaze history is critical for robust prediction. We will release our source code and pre-trained models.", "AI": {"tldr": "ARGaze通过自回归变换器模型，从第一人称视频中在线预测摄像机佩戴者的注视点。", "motivation": "该研究旨在解决在线第一人称视角下的眼动估计问题，在这种情况下缺乏显式的头部或眼睛信号，需要基于稀疏的间接线索进行视觉注意力推断。同时利用注视行为在目标导向活动中表现出的时间连续性来提高预测准确性。", "method": "ARGaze将眼动估计重新表述为顺序预测任务：使用自回归变换器模型，在每个时间步中，根据当前视觉特征和最近注视点的历史记录（固定长度的Gaze Context Window）预测当前注视位置。这种方法既保证因果关系又支持流式推理。", "result": "ARGaze在多个第一人称眼动基准测试上取得了最先进的性能，并且通过广泛的消融实验验证了自回归建模的重要性，尤其是在使用有限的历史记录时。", "conclusion": "ARGaze展示了利用变换器模型进行在线第一人称眼动预测的有效性，证明了自回归建模方法在处理稀疏间接线索和时间连续性方面的重要价值。"}}
{"id": "2602.05129", "pdf": "https://arxiv.org/pdf/2602.05129", "abs": "https://arxiv.org/abs/2602.05129", "authors": ["Xiaodan Hu", "Monica Perusquía-Hernández", "Mayra Donaji Barrera Machuca", "Anil Ufuk Batmaz", "Yan Zhang", "Wolfgang Stuerzlinger", "Kiyoshi Kiyokawa"], "title": "Varifocal Displays Reduce the Impact of the Vergence-Accommodation Conflict on 3D Pointing Performance in Augmented Reality Systems", "categories": ["cs.HC"], "comment": "24 pages, 11 figures", "summary": "This paper investigates whether a custom varifocal display can improve 3D pointing performance in augmented reality (AR), where the vergence-accommodation conflict (VAC) is known to impair interaction. Varifocal displays have been hypothesized to alleviate the VAC by dynamically matching the focal distance to the user's gaze-defined target depth. Following prior work, we conducted a within-subject study with 24 participants performing an ISO 9241-411 pointing task under varifocal and fixed-focal viewing. Overall, varifocal viewing yielded significantly higher performance than the fixed-focal baseline across key interaction metrics, although the magnitude and even the direction of the benefit varied across individuals. In particular, participants' responses exhibited a baseline-dependent pattern, with smaller improvements (or occasional degradation) observed for those with better baseline performance. Our findings suggest that varifocal technology can improve AR pointing performance relative to fixed-focal viewing, while highlighting substantial individual differences that should be considered in design and evaluation.", "AI": {"tldr": "研究探讨了可调焦距显示器能否改善增强现实中的三维指向性能。", "motivation": "研究旨在探索一种自定义的可变焦显示设备是否可以通过动态匹配焦点距离来解决虚拟现实系统的对齐聚焦冲突问题，从而提高3D指针操作的表现。", "method": "进行了包含24名参与者的两组内实验，分别在可调焦和固定焦模式下进行ISO9241-411指向任务，比较了两种条件下的表现差异。", "result": "总体而言，在关键互动指标上，可变焦视图的性能明显优于固定焦基线。然而，这种益处的效果大小因人而异。", "conclusion": "研究显示，与固定焦距观看相比，可调焦技术可以改善AR中的指向性能，但需考虑到个体差异"}}
{"id": "2602.05128", "pdf": "https://arxiv.org/pdf/2602.05128", "abs": "https://arxiv.org/abs/2602.05128", "authors": ["Karla Felix Navarro", "Eugene Syriani", "Ian Arawjo"], "title": "Reporting and Reviewing LLM-Integrated Systems in HCI: Challenges and Considerations", "categories": ["cs.HC"], "comment": "18 pages, 1 figure, 2 tables. For proposed reporting guidelines, see https://ianarawjo.github.io/Guidelines-for-Reporting-LLM-Integrated-Systems-in-HCI/", "summary": "What should HCI scholars consider when reporting and reviewing papers that involve LLM-integrated systems? We interview 18 authors of LLM-integrated system papers on their authoring and reviewing experiences. We find that norms of trust-building between authors and reviewers appear to be eroded by the uncertainty of LLM behavior and hyperbolic rhetoric surrounding AI. Authors perceive that reviewers apply uniquely skeptical and inconsistent standards towards papers that report LLM-integrated systems, and mitigate mistrust by adding technical evaluations, justifying usage, and de-emphasizing LLM presence. Authors' views challenge blanket directives to report all prompts and use open models, arguing that prompt reporting is context-dependent and justifying proprietary model usage despite ethical concerns. Finally, some tensions in peer review appear to stem from clashes between the norms and values of HCI and ML/NLP communities, particularly around what constitutes a contribution and an appropriate level of technical rigor. Based on our findings and additional feedback from six expert HCI researchers, we present a set of guidelines and considerations for authors, reviewers, and HCI communities around reporting and reviewing papers that involve LLM-integrated systems.", "AI": {"tldr": "论文探讨了HCI学者在撰写和审查涉及大语言模型集成系统的文章时应考虑的因素。", "motivation": "探索并解决HCI领域中关于报告和审阅包含大型语言模型的系统所面临的挑战，特别是在建立作者与评审员之间的信任以及不同社区之间价值观冲突的问题上。", "method": "通过采访18位撰写过此类论文的作者以获取他们的经验和观点，并从六位专家HCI研究人员那里获得反馈来形成建议指南。", "result": "揭示了在报告和审阅涉及大语言模型系统时，作者会遇到独特的怀疑标准和不一致的要求；并且由于AI行为的不确定性以及围绕其使用的夸张表述，导致建立信任变得困难。", "conclusion": "论文提出了一套针对作者、评审员及HCI社区关于报道与审阅包含大型语言模型集成系统的文章所应遵守的指导原则。"}}
{"id": "2602.05126", "pdf": "https://arxiv.org/pdf/2602.05126", "abs": "https://arxiv.org/abs/2602.05126", "authors": ["Weiyi Qin", "Yingci Liu-Swetz", "Shiwei Tan", "Hao Wang"], "title": "CLEAR-HPV: Interpretable Concept Discovery for HPV-Associated Morphology in Whole-Slide Histology", "categories": ["cs.CV"], "comment": null, "summary": "Human papillomavirus (HPV) status is a critical determinant of prognosis and treatment response in head and neck and cervical cancers. Although attention-based multiple instance learning (MIL) achieves strong slide-level prediction for HPV-related whole-slide histopathology, it provides limited morphologic interpretability. To address this limitation, we introduce Concept-Level Explainable Attention-guided Representation for HPV (CLEAR-HPV), a framework that restructures the MIL latent space using attention to enable concept discovery without requiring concept labels during training. Operating in an attention-weighted latent space, CLEAR-HPV automatically discovers keratinizing, basaloid, and stromal morphologic concepts, generates spatial concept maps, and represents each slide using a compact concept-fraction vector. CLEAR-HPV's concept-fraction vectors preserve the predictive information of the original MIL embeddings while reducing the high-dimensional feature space (e.g., 1536 dimensions) to only 10 interpretable concepts. CLEAR-HPV generalizes consistently across TCGA-HNSCC, TCGA-CESC, and CPTAC-HNSCC, providing compact, concept-level interpretability through a general, backbone-agnostic framework for attention-based MIL models of whole-slide histopathology.", "AI": {"tldr": "本文提出了一种用于HPV相关全切片组织病理学的概念发现框架CLEAR-HPV，以提高注意力引导的多实例学习模型的可解释性。", "motivation": "现有方法在预测HPV相关的全切片组织病理图像时存在形态学可解释性的不足。为了解决这个问题，本文引入了CLEAR-HPV框架来自动发现和标注形态学概念，使模型更易理解。", "method": "通过重新构造注意力引导的多实例学习模型的潜在空间，本文开发了一种无需额外概念标签就能进行概念发现的方法，从而生成具有可解释性的概念分数向量。", "result": "CLEAR-HPV框架在TCGA-HNSCC, TCGA-CESC和CPTAC-HNSCC等数据集上展示了良好的泛化能力，并能减少高维特征空间的同时保持预测性能。", "conclusion": "本文提出的方法提供了一种通用、与骨干网络无关的注意力引导多实例学习框架，使HPV相关的全切片组织病理图像分析更加可解释和实用。"}}
{"id": "2602.05125", "pdf": "https://arxiv.org/pdf/2602.05125", "abs": "https://arxiv.org/abs/2602.05125", "authors": ["William F. Shen", "Xinchi Qiu", "Chenxi Whitehouse", "Lisa Alazraki", "Shashwat Goel", "Francesco Barbieri", "Timon Willi", "Akhil Mathur", "Ilias Leontiadis"], "title": "Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.", "AI": {"tldr": "本文提出了一种递归分解过滤框架（RRD），旨在改进大规模语言模型（LLM）在开放性任务中的评判和奖励建模。", "motivation": "当前的评分标准往往覆盖不全、维度混杂、偏好方向错位以及冗余或高度相关，导致评判准确性和训练效果不佳。因此，文章提出了一种新的框架来优化这些问题。", "method": "RRD通过递归分解和过滤机制将粗略的标准细化为细粒度且具有区分性的标准，并通过消除不一致的和冗余的标准及防止过度表示高度相关标准的方法提升了评分系统的有效性和全面性。", "result": "实验表明，使用RRD框架可以显著提高LLM在评判基准测试中的准确性，并在强化学习中提供更强、更稳定的奖励信号。相对于之前的基线模型，性能提升明显。", "conclusion": "RRD确立了递归评分标准细化作为开放领域内LLM评判和奖励建模的可扩展且解释性强的基础框架。"}}
{"id": "2602.05121", "pdf": "https://arxiv.org/pdf/2602.05121", "abs": "https://arxiv.org/abs/2602.05121", "authors": ["Farbod Younesi", "Walter Lucia", "Amr Youssef"], "title": "Trojan Attacks on Neural Network Controllers for Robotic Systems", "categories": ["eess.SY", "cs.RO"], "comment": "Paper submitted to the 2026 IEEE Conference on Control Technology and Applications (CCTA)", "summary": "Neural network controllers are increasingly deployed in robotic systems for tasks such as trajectory tracking and pose stabilization. However, their reliance on potentially untrusted training pipelines or supply chains introduces significant security vulnerabilities. This paper investigates backdoor (Trojan) attacks against neural controllers, using a differential-drive mobile robot platform as a case study. In particular, assuming that the robot's tracking controller is implemented as a neural network, we design a lightweight, parallel Trojan network that can be embedded within the controller. This malicious module remains dormant during normal operation but, upon detecting a highly specific trigger condition defined by the robot's pose and goal parameters, compromises the primary controller's wheel velocity commands, resulting in undesired and potentially unsafe robot behaviours. We provide a proof-of-concept implementation of the proposed Trojan network, which is validated through simulation under two different attack scenarios. The results confirm the effectiveness of the proposed attack and demonstrate that neural network-based robotic control systems are subject to potentially critical security threats.", "AI": {"tldr": "本文研究了针对神经网络控制器的后门攻击，并通过模拟展示了其有效性。", "motivation": "随着机器人系统中越来越多地使用神经网络控制器，这些系统的安全风险也随之增加。文章旨在探索如何对这类系统进行针对性的安全威胁测试。", "method": "设计了一种轻量级且并行的恶意模块，该模块能够在检测到特定触发条件时破坏主控制器的指令，导致机器人执行非预期的行为。", "result": "通过两个不同的攻击场景验证了所提出的后门网络的有效性，证明神经网络控制系统的安全性面临严重威胁。", "conclusion": "研究结果显示，神经网络控制器容易受到潜在的安全威胁，并且这种威胁可能对系统产生严重的不利影响。"}}
{"id": "2602.05115", "pdf": "https://arxiv.org/pdf/2602.05115", "abs": "https://arxiv.org/abs/2602.05115", "authors": ["Keyang Xuan", "Pengda Wang", "Chongrui Ye", "Haofei Yu", "Tal August", "Jiaxuan You"], "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers", "categories": ["cs.AI", "cs.CL"], "comment": "10 pages", "summary": "Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions in more realistic, imperfect settings. To close this gap, we present \\textsc{SocialVeil}, a social learning environment that can simulate social interaction under cognitive-difference-induced communication barriers. Grounded in a systematic literature review of communication challenges in human interaction, \\textsc{SocialVeil} introduces three representative types of such disruption, \\emph{semantic vagueness}, \\emph{sociocultural mismatch}, and \\emph{emotional interference}. We also introduce two barrier-aware evaluation metrics, \\emph{unresolved confusion} and \\emph{mutual understanding}, to evaluate interaction quality under impaired communication. Experiments across 720 scenarios and four frontier LLMs show that barriers consistently impair performance, with mutual understanding reduced by over 45\\% on average, and confusion elevated by nearly 50\\%. Human evaluations validate the fidelity of these simulated barriers (ICC$\\approx$0.78, Pearson r$\\approx$0.80). We further demonstrate that adaptation strategies (Repair Instruction and Interactive learning) only have a modest effect far from barrier-free performance. This work takes a step toward bringing social interaction environments closer to real-world communication, opening opportunities for exploring the social intelligence of LLM agents.", "AI": {"tldr": "本文介绍了SocialVeil，一个用于评估大型语言模型在社交互动中面对沟通障碍时性能的环境。", "motivation": "当前的语言模型评估基准假设了理想化的通信情境，这限制了我们诊断模型能否在更现实、不完美的环境中维持和修复互动的能力。因此，作者希望通过引入模拟认知差异导致的沟通障碍来填补这一空白。", "method": "SocialVeil通过系统性文献回顾识别三种代表性干扰：语义模糊、社会文化错配以及情感干扰，并据此设计了两个评估指标：未解决困惑与相互理解度。该研究在720个场景中测试了四种前沿的语言模型。", "result": "实验结果表明，沟通障碍显著影响了语言模型的表现，平均而言，它们的互懂程度下降超过45%，而混淆程度增加了近50%。人类评估验证了这些模拟障碍的真实度（ICC约等于0.78，Pearson r约等于0.8）。", "conclusion": "这项研究为探索大型语言模型在社交互动环境中的社会智能提供了一个接近真实世界的平台，并且表明现有的适应策略对克服沟通障碍的效果有限。"}}
{"id": "2602.05113", "pdf": "https://arxiv.org/pdf/2602.05113", "abs": "https://arxiv.org/abs/2602.05113", "authors": ["Suvadip Sana", "Jinzhou Wu", "Martin T. Wells"], "title": "Democratic Preference Alignment via Sortition-Weighted RLHF", "categories": ["cs.AI", "cs.LG"], "comment": "16 pages, 5 figures", "summary": "Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.", "AI": {"tldr": "论文提出了Democratic Preference Optimization（DemPO）框架，通过算法抽签机制来优化偏好基础的微调过程。", "motivation": "现有基于偏好的对齐方法如RLHF从人类评分员中获取训练信号，但这些样本通常存在系统性的代表性偏差。为此，本文提出使用民主化的方法以确保AI系统的偏好学习能够反映代表公众的价值观。", "method": "DemPO框架包括两种训练方案：Hard Panel和Soft Panel。其中，Hard Panel只在抽签机制产生的配额满足的小型公众上进行训练；而Soft Panel则保留所有数据并根据每个评分员的入选概率重新加权。证明了Soft Panel权重可以以闭形式恢复Hard Panel目标。", "result": "通过使用具有人类判断和评分者人口统计数据以及从美国代表样本中独立提取的75项宪法条款构成的数据集，对不同参数量级的Llama模型进行评估后发现，在六种汇总方法下，Hard Panel始终排名第一且Soft Panel优于未加权基线。", "conclusion": "通过在偏好收集阶段强制执行人口代表性而不是事后纠正来训练AI系统的行为更能反映从代表公众中提取的价值观。"}}
{"id": "2602.05111", "pdf": "https://arxiv.org/pdf/2602.05111", "abs": "https://arxiv.org/abs/2602.05111", "authors": ["Shri Harini Ramesh", "Foroozan Daneshzand", "Babak Rashidi", "Shriti Raj", "Hariharan Subramonyam", "Fateme Rajabiyazdi"], "title": "Metacognitive Demands and Strategies While Using Off-The-Shelf AI Conversational Agents for Health Information", "categories": ["cs.HC"], "comment": "ef:In Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems CHI 2026", "summary": "As Artificial Intelligence (AI) conversational agents become widespread, people are increasingly using them for health information seeking. The use of off-the-shelf conversational agents for health information seeking could place high metacognitive demands (the need for extensive monitoring and control of one's own thought process) on individuals, which could compromise their experience of seeking health information. However, currently, the specific demands that arise while using conversational agents for health information seeking, and the strategies people use to cope with those demands, remain unknown. To address these gaps, we conducted a think-aloud study with 15 participants as they sought health information using our off-the-shelf AI conversational agent. We identified the metacognitive demands such systems impose, the strategies people adopt in response, and propose considerations for designing beyond off-the-shelf interfaces to reduce these demands and support better user experiences and affordances in health information seeking.", "AI": {"tldr": "研究探讨了使用现成的人工智能会话代理获取健康信息时，人们面临的元认知需求及其应对策略。", "motivation": "随着人工智能对话代理的普及，个人越来越多地利用这些工具来查找健康信息。然而，在这种过程中产生的特定元认知需求以及人们的应对策略尚不清楚。", "method": "研究通过15名参与者进行了一项“边想边说”实验，他们在使用现成的人工智能会话代理搜索健康信息时进行了自我报告。", "result": "识别了这些系统在获取健康信息过程中产生的元认知需求以及人们应对这些需求的策略。", "conclusion": "研究提出了设计超出现成接口的方法以减少元认知需求并支持更好的用户体验和获取健康信息的功能。"}}
{"id": "2602.05110", "pdf": "https://arxiv.org/pdf/2602.05110", "abs": "https://arxiv.org/abs/2602.05110", "authors": ["Liang Wang", "Junpeng Wang", "Chin-chia Michael Yeh", "Yan Zheng", "Jiarui Sun", "Xiran Fan", "Xin Dai", "Yujie Fan", "Yiwei Cai"], "title": "Understanding LLM Evaluator Behavior: A Structured Multi-Evaluator Framework for Merchant Risk Assessment", "categories": ["cs.AI"], "comment": ":I.2.7", "summary": "Large Language Models (LLMs) are increasingly used as evaluators of reasoning quality, yet their reliability and bias in payments-risk settings remain poorly understood. We introduce a structured multi-evaluator framework for assessing LLM reasoning in Merchant Category Code (MCC)-based merchant risk assessment, combining a five-criterion rubric with Monte-Carlo scoring to evaluate rationale quality and evaluator stability. Five frontier LLMs generate and cross-evaluate MCC risk rationales under attributed and anonymized conditions. To establish a judge-independent reference, we introduce a consensus-deviation metric that eliminates circularity by comparing each judge's score to the mean of all other judges, yielding a theoretically grounded measure of self-evaluation and cross-model deviation. Results reveal substantial heterogeneity: GPT-5.1 and Claude 4.5 Sonnet show negative self-evaluation bias (-0.33, -0.31), while Gemini-2.5 Pro and Grok 4 display positive bias (+0.77, +0.71), with bias attenuating by 25.8 percent under anonymization. Evaluation by 26 payment-industry experts shows LLM judges assign scores averaging +0.46 points above human consensus, and that the negative bias of GPT-5.1 and Claude 4.5 Sonnet reflects closer alignment with human judgment. Ground-truth validation using payment-network data shows four models exhibit statistically significant alignment (Spearman rho = 0.56 to 0.77), confirming that the framework captures genuine quality. Overall, the framework provides a replicable basis for evaluating LLM-as-a-judge systems in payment-risk workflows and highlights the need for bias-aware protocols in operational financial settings.", "AI": {"tldr": "该论文提出了一种结构化多评价者框架，用于评估大型语言模型在商户风险评估中的表现。", "motivation": "随着大型语言模型（LLMs）在支付风险场景中的使用增加，对其可靠性和偏见的理解仍不清楚。该研究旨在建立一种基于五项标准评分和蒙特卡洛评分的方法来衡量理据质量和评价者稳定性。", "method": "论文结合了五项评分准则与蒙特卡洛评分方法，评估五个前沿LLM在商户类别代码（MCC）风险评估中的表现，并通过共识偏差度量消除循环性问题。同时引入了26名支付行业专家进行独立验证。", "result": "结果表明，不同的模型存在显著差异：GPT-5.1和Claude 4.5 Sonnet显示出负自我评价偏见（分别为-0.33、-0.31），而Gemini-2.5 Pro和Grok 4则表现出正偏见（+0.77，+0.71）。匿名化条件下的偏差降低25.8%。专家评分显示LLM比人类共识高出0.46分。", "conclusion": "该框架为评估作为评价者的大型语言模型提供了可重复的基础，并强调在实际金融环境中需要考虑偏见感知协议的重要性。"}}
{"id": "2602.05105", "pdf": "https://arxiv.org/pdf/2602.05105", "abs": "https://arxiv.org/abs/2602.05105", "authors": ["Rohan Patil", "Jai Malegaonkar", "Xiao Jiang", "Andre Dion", "Gaurav S. Sukhatme", "Henrik I. Christensen"], "title": "GAMMS: Graph based Adversarial Multiagent Modeling Simulator", "categories": ["cs.AI", "cs.RO", "cs.SE"], "comment": null, "summary": "As intelligent systems and multi-agent coordination become increasingly central to real-world applications, there is a growing need for simulation tools that are both scalable and accessible. Existing high-fidelity simulators, while powerful, are often computationally expensive and ill-suited for rapid prototyping or large-scale agent deployments. We present GAMMS (Graph based Adversarial Multiagent Modeling Simulator), a lightweight yet extensible simulation framework designed to support fast development and evaluation of agent behavior in environments that can be represented as graphs. GAMMS emphasizes five core objectives: scalability, ease of use, integration-first architecture, fast visualization feedback, and real-world grounding. It enables efficient simulation of complex domains such as urban road networks and communication systems, supports integration with external tools (e.g., machine learning libraries, planning solvers), and provides built-in visualization with minimal configuration. GAMMS is agnostic to policy type, supporting heuristic, optimization-based, and learning-based agents, including those using large language models. By lowering the barrier to entry for researchers and enabling high-performance simulations on standard hardware, GAMMS facilitates experimentation and innovation in multi-agent systems, autonomous planning, and adversarial modeling. The framework is open-source and available at https://github.com/GAMMSim/GAMMS/", "AI": {"tldr": "GAMMS是一个基于图的、轻量级且可扩展的多智能体模拟框架，用于快速开发和评估复杂环境中的代理行为。", "motivation": "随着智能系统和多智能体协调在实际应用中变得越来越重要，现有的高保真模拟器因计算成本高昂而不适合快速原型设计或大规模代理部署。因此需要一个既轻量级又易于使用的框架来支持高效仿真。", "method": "GAMMS使用图数据结构进行建模，并提供集成、可视化反馈和与其他工具兼容的功能，适用于各种类型的智能体策略。", "result": "GAMMS能够在标准硬件上实现高性能模拟，降低了研究人员的进入门槛，促进了多智能体系统的研究与创新。", "conclusion": "GAMMS作为一个开源框架，为快速开发和评估复杂环境中的多智能体行为提供了一种新的解决方案。"}}
{"id": "2602.05100", "pdf": "https://arxiv.org/pdf/2602.05100", "abs": "https://arxiv.org/abs/2602.05100", "authors": ["Bharadwaj Dogga", "Kaaustaaub Shankar", "Gibin Raju", "Wilhelm Louw", "Kelly Cohen"], "title": "Rule-Based Spatial Mixture-of-Experts U-Net for Explainable Edge Detection", "categories": ["cs.CE", "cs.CV", "cs.SC"], "comment": null, "summary": "Deep learning models like U-Net and its variants, have established state-of-the-art performance in edge detection tasks and are used by Generative AI services world-wide for their image generation models. However, their decision-making processes remain opaque, operating as \"black boxes\" that obscure the rationale behind specific boundary predictions. This lack of transparency is a critical barrier in safety-critical applications where verification is mandatory. To bridge the gap between high-performance deep learning and interpretable logic, we propose the Rule-Based Spatial Mixture-of-Experts U-Net (sMoE U-Net). Our architecture introduces two key innovations: (1) Spatially-Adaptive Mixture-of-Experts (sMoE) blocks integrated into the decoder skip connections, which dynamically gate between \"Context\" (smooth) and \"Boundary\" (sharp) experts based on local feature statistics; and (2) a Takagi-Sugeno-Kang (TSK) Fuzzy Head that replaces the standard classification layer. This fuzzy head fuses deep semantic features with heuristic edge signals using explicit IF-THEN rules. We evaluate our method on the BSDS500 benchmark, achieving an Optimal Dataset Scale (ODS) F-score of 0.7628, effectively matching purely deep baselines like HED (0.7688) while outperforming the standard U-Net (0.7437). Crucially, our model provides pixel-level explainability through \"Rule Firing Maps\" and \"Strategy Maps,\" allowing users to visualize whether an edge was detected due to strong gradients, high semantic confidence, or specific logical rule combinations.", "AI": {"tldr": "提出了一种基于规则的空间混合专家U-Net（sMoE U-Net）以提高边缘检测任务的可解释性。", "motivation": "为了克服深度学习模型在安全关键应用中的不透明决策问题，通过引入空间适应性和模糊逻辑来增强U-Net模型的解释能力。", "method": "该方法通过加入空间自适应混合专家（sMoE）模块和TSK模糊头替换分类层，使得模型可以基于局部特征统计动态选择“上下文”或“边界”专家，并将深度语义信息与启发式边缘信号融合。", "result": "在BSDS500数据集上实现了ODS F值为0.7628的性能表现，接近于HED（0.7688），优于标准U-Net（0.7437）。同时提供了像素级别的解释能力。", "conclusion": "通过引入sMoE模块和TSK模糊头，该模型不仅保持了边缘检测的高性能，还提高了可解释性。"}}
{"id": "2602.05096", "pdf": "https://arxiv.org/pdf/2602.05096", "abs": "https://arxiv.org/abs/2602.05096", "authors": ["Joseph D. Janizek", "Sonnet Xu", "Junayd Lateef", "Roxana Daneshjou"], "title": "Visual concept ranking uncovers medical shortcuts used by large multimodal models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Ensuring the reliability of machine learning models in safety-critical domains such as healthcare requires auditing methods that can uncover model shortcomings. We introduce a method for identifying important visual concepts within large multimodal models (LMMs) and use it to investigate the behaviors these models exhibit when prompted with medical tasks. We primarily focus on the task of classifying malignant skin lesions from clinical dermatology images, with supplemental experiments including both chest radiographs and natural images. After showing how LMMs display unexpected gaps in performance between different demographic subgroups when prompted with demonstrating examples, we apply our method, Visual Concept Ranking (VCR), to these models and prompts. VCR generates hypotheses related to different visual feature dependencies, which we are then able to validate with manual interventions.", "AI": {"tldr": "本文介绍了一种方法用于识别大型多模态模型中的重要视觉概念，并通过皮肤病图像分类等任务来揭示这些模型的性能差距。", "motivation": "确保机器学习模型在医疗保健等领域中可靠性的需求需要能够揭露模型不足之处的审计方法。", "method": "提出了一种名为Visual Concept Ranking (VCR)的方法，用于识别大型多模态模型中的重要视觉概念，并通过干预验证这些假设。", "result": "发现当使用不同的人口统计学子组示例时，大型多模态模型在表现上存在意外差距。VCR生成了关于不同的视觉特征依赖性的假设并得到验证。", "conclusion": "本文展示了一种新的方法来审计大型多模态模型的性能和行为，并揭示其潜在的风险。"}}
{"id": "2602.05093", "pdf": "https://arxiv.org/pdf/2602.05093", "abs": "https://arxiv.org/abs/2602.05093", "authors": ["He Zhang", "Xinyang Li", "Xingyu Zhou", "Xinyi Fu"], "title": "VR Calm Plus: Coupling a Squeezable Tangible Interaction with Immersive VR for Stress Regulation", "categories": ["cs.HC"], "comment": "This work has been conditionally accepted by the ACM CHI 2026 Conference", "summary": "While Virtual Reality (VR) is increasingly employed for stress management, most applications rely heavily on audio-visual stimuli and overlook the therapeutic potential of squeezing engagement. To address this gap, we introduce VR Calm Plus, a multimodal system that integrates a pressure-sensitive plush toy into an interactive VR environment. This interface allows users to dynamically modulate the virtual atmosphere through physical squeezing actions, fostering a deeper sense of embodied relaxation. We evaluated the system with 40 participants using PANAS-X surveys, subjective questionnaires, physiological measures (heart rate, skin conductance, pulse rate variability), and semi-structured interviews. Results demonstrate that, compared to a visual-only baseline, squeeze-based interaction significantly enhances positive affect and perceived relaxation. Physiological data further revealed a state of \"active relaxation\", characterized by greater reductions in heart rate and preserved autonomic flexibility (PRV), alongside sustained emotional engagement (GSR). Our findings highlight the value of coupling tangible input with immersive environments to support emotional well-being and offer design insights for future VR-based mental health tools.", "AI": {"tldr": "本文提出了一种结合压力感应毛绒玩具与交互式虚拟现实环境的多模态系统VR Calm Plus，以促进身心放松。", "motivation": "传统虚拟现实技术在缓解压力的应用中主要依赖视听刺激，并未充分利用捏压互动带来的潜在治疗效果。为弥补这一不足，本文开发了VR Calm Plus系统。", "method": "通过PANAS-X问卷调查、主观问卷、生理指标（心率、皮肤电导、脉搏变异）以及半结构化访谈对40名参与者进行评估。该系统允许用户通过捏压玩具来调节虚拟环境，从而实现更深层次的身体放松体验。", "result": "与仅视觉反馈的基线相比，基于捏压互动的方式显著提高了积极情感和感知到的放松程度，并且生理数据表明其能够促进“主动放松”的状态，表现为心率降低而保持自主神经灵活性。", "conclusion": "本文证明了将实体输入与沉浸式环境相结合可以有效支持情绪健康，并为未来的虚拟现实心理健康工具设计提供了重要见解。"}}
{"id": "2602.05092", "pdf": "https://arxiv.org/pdf/2602.05092", "abs": "https://arxiv.org/abs/2602.05092", "authors": ["Thomas Cohn", "Lihan Tang", "Alexandre Amice", "Russ Tedrake"], "title": "A Framework for Combining Optimization-Based and Analytic Inverse Kinematics", "categories": ["cs.RO"], "comment": "19 pages, 5 figures, 6 tables. Under submission", "summary": "Analytic and optimization methods for solving inverse kinematics (IK) problems have been deeply studied throughout the history of robotics. The two strategies have complementary strengths and weaknesses, but developing a unified approach to take advantage of both methods has proved challenging. A key challenge faced by optimization approaches is the complicated nonlinear relationship between the joint angles and the end-effector pose. When this must be handled concurrently with additional nonconvex constraints like collision avoidance, optimization IK algorithms may suffer high failure rates. We present a new formulation for optimization IK that uses an analytic IK solution as a change of variables, and is fundamentally easier for optimizers to solve. We test our methodology on three popular solvers, representing three different paradigms for constrained nonlinear optimization. Extensive experimental comparisons demonstrate that our new formulation achieves higher success rates than the old formulation and baseline methods across various challenging IK problems, including collision avoidance, grasp selection, and humanoid stability.", "AI": {"tldr": "提出了一种结合解析法和优化法的逆运动学新框架，改进了传统优化方法在处理复杂非线性关系时的表现。", "motivation": "现有的逆运动学解决方案存在局限性；解析法难以应对复杂的约束条件，而优化法则受困于复杂的关节角度与末端执行器姿态之间的非线性关系和额外的非凸约束（如碰撞避免）。因此需要一种新的方法来整合两者的优势。", "method": "将解析逆运动学解作为变量变换引入到优化过程中，简化了优化问题。", "result": "实验结果显示新框架在处理包括碰撞避免、抓取选择和人形稳定性在内的各种复杂任务时，成功率高于传统方法。", "conclusion": "所提出的方法能够在保持原有优势的同时提高解决复杂逆运动学问题的能力。"}}
{"id": "2602.05091", "pdf": "https://arxiv.org/pdf/2602.05091", "abs": "https://arxiv.org/abs/2602.05091", "authors": ["Agni Bandyopadhyay", "Günther Waxenegger-Wilfing"], "title": "Evaluating Robustness and Adaptability in Learning-Based Mission Planning for Active Debris Removal", "categories": ["cs.AI", "cs.LG", "cs.RO", "physics.space-ph"], "comment": "Presented at Conference: International Conference on Space Robotics (ISPARO,2025) At: Sendai,Japan", "summary": "Autonomous mission planning for Active Debris Removal (ADR) must balance efficiency, adaptability, and strict feasibility constraints on fuel and mission duration. This work compares three planners for the constrained multi-debris rendezvous problem in Low Earth Orbit: a nominal Masked Proximal Policy Optimization (PPO) policy trained under fixed mission parameters, a domain-randomized Masked PPO policy trained across varying mission constraints for improved robustness, and a plain Monte Carlo Tree Search (MCTS) baseline. Evaluations are conducted in a high-fidelity orbital simulation with refueling, realistic transfer dynamics, and randomized debris fields across 300 test cases in nominal, reduced fuel, and reduced mission time scenarios. Results show that nominal PPO achieves top performance when conditions match training but degrades sharply under distributional shift, while domain-randomized PPO exhibits improved adaptability with only moderate loss in nominal performance. MCTS consistently handles constraint changes best due to online replanning but incurs orders-of-magnitude higher computation time. The findings underline a trade-off between the speed of learned policies and the adaptability of search-based methods, and suggest that combining training-time diversity with online planning could be a promising path for future resilient ADR mission planners.", "AI": {"tldr": "评估基于学习的任务规划在主动碎片清除任务中的稳健性和适应性", "motivation": "研究不同的任务规划方法以提高低地球轨道中多碎片会合任务的效率、适应性和可行性约束条件下的表现", "method": "比较了三种规划策略：标准Masked PPO，领域随机化Masked PPO和MCTS，在包含燃料补充的真实转移动力学和随机碎片场中的高保真轨道模拟下进行测试", "result": "结果显示标准PPO在匹配训练条件下表现出色但面对分布变化时性能急剧下降；领域随机化PPO适应性更好且仅略有损失；MCTS处理约束变化最佳但由于计算时间长不具优势", "conclusion": "提出结合训练多样性与在线规划的方法是未来主动碎片清除任务稳健计划的有前途方向"}}
{"id": "2602.05089", "pdf": "https://arxiv.org/pdf/2602.05089", "abs": "https://arxiv.org/abs/2602.05089", "authors": ["Ethan Rathbun", "Wo Wei Lin", "Alina Oprea", "Christopher Amato"], "title": "Beware Untrusted Simulators -- Reward-Free Backdoor Attacks in Reinforcement Learning", "categories": ["cs.CR", "cs.LG", "cs.RO"], "comment": "10 pages main body, ICLR 2026", "summary": "Simulated environments are a key piece in the success of Reinforcement Learning (RL), allowing practitioners and researchers to train decision making agents without running expensive experiments on real hardware. Simulators remain a security blind spot, however, enabling adversarial developers to alter the dynamics of their released simulators for malicious purposes. Therefore, in this work we highlight a novel threat, demonstrating how simulator dynamics can be exploited to stealthily implant action-level backdoors into RL agents. The backdoor then allows an adversary to reliably activate targeted actions in an agent upon observing a predefined ``trigger'', leading to potentially dangerous consequences. Traditional backdoor attacks are limited in their strong threat models, assuming the adversary has near full control over an agent's training pipeline, enabling them to both alter and observe agent's rewards. As these assumptions are infeasible to implement within a simulator, we propose a new attack ``Daze'' which is able to reliably and stealthily implant backdoors into RL agents trained for real world tasks without altering or even observing their rewards. We provide formal proof of Daze's effectiveness in guaranteeing attack success across general RL tasks along with extensive empirical evaluations on both discrete and continuous action space domains. We additionally provide the first example of RL backdoor attacks transferring to real, robotic hardware. These developments motivate further research into securing all components of the RL training pipeline to prevent malicious attacks.", "AI": {"tldr": "本文提出了一种新的攻击方法Daze，能够通过模拟器植入无奖励的后门给强化学习代理，即使在无法改变或观察到奖励的情况下也能成功实施。", "motivation": "研究者发现现有的模拟环境存在安全漏洞，可以通过修改动态来隐蔽地植入行动级后门给训练中的代理，并可能导致危险后果。因此需要开发一种新型攻击方法以揭示并防御这种威胁。", "method": "提出名为Daze的攻击技术，能够在不篡改或观察奖励的情况下，在真实世界任务中可靠且隐蔽地向RL代理植入后门，并通过形式化证明和实验验证其效果。", "result": "该研究提供了理论保证以及实证结果来表明Daze能在多种环境中成功实施，包括离散与连续动作空间域，同时首次展示了从模拟器到实际机器人硬件的攻击转移能力。", "conclusion": "这些发现强调了需要对整个RL训练流程进行更全面的安全保护以防止恶意行为，并鼓励未来的研究工作探索这一领域。"}}
{"id": "2602.05088", "pdf": "https://arxiv.org/pdf/2602.05088", "abs": "https://arxiv.org/abs/2602.05088", "authors": ["Kate H. Bentley", "Luca Belli", "Adam M. Chekroud", "Emily J. Ward", "Emily R. Dworkin", "Emily Van Ark", "Kelly M. Johnston", "Will Alexander", "Millard Brown", "Matt Hawrilenko"], "title": "VERA-MH: Reliability and Validity of an Open-Source AI Safety Evaluation in Mental Health", "categories": ["cs.AI"], "comment": null, "summary": "Millions now use leading generative AI chatbots for psychological support. Despite the promise related to availability and scale, the single most pressing question in AI for mental health is whether these tools are safe. The Validation of Ethical and Responsible AI in Mental Health (VERA-MH) evaluation was recently proposed to meet the urgent need for an evidence-based automated safety benchmark. This study aimed to examine the clinical validity and reliability of the VERA-MH evaluation for AI safety in suicide risk detection and response. We first simulated a large set of conversations between large language model (LLM)-based users (user-agents) and general-purpose AI chatbots. Licensed mental health clinicians used a rubric (scoring guide) to independently rate the simulated conversations for safe and unsafe chatbot behaviors, as well as user-agent realism. An LLM-based judge used the same scoring rubric to evaluate the same set of simulated conversations. We then compared rating alignment across (a) individual clinicians and (b) clinician consensus and the LLM judge, and (c) examined clinicians' ratings of user-agent realism. Individual clinicians were generally consistent with one another in their safety ratings (chance-corrected inter-rater reliability [IRR]: 0.77), thus establishing a gold-standard clinical reference. The LLM judge was strongly aligned with this clinical consensus (IRR: 0.81) overall and within key conditions. Clinician raters generally perceived the user-agents to be realistic. For the potential mental health benefits of AI chatbots to be realized, attention to safety is paramount. Findings from this human evaluation study support the clinical validity and reliability of VERA-MH: an open-source, fully automated AI safety evaluation for mental health. Further research will address VERA-MH generalizability and robustness.", "AI": {"tldr": "评估AI聊天机器人在心理健康领域的安全性和有效性", "motivation": "探讨如何确保AI聊天机器人的安全性，特别是在自杀风险检测和响应方面", "method": "通过模拟对话来评价AI聊天机器人的行为及用户真实性，并由精神健康专家进行独立评分，同时采用LLM评估同一数据集以比较不同评分者的一致性", "result": "临床医生在安全评级上具有高度一致性（校正后一致率0.77），且LLM评分与临床共识高度吻合（一致率0.81）；用户代理被普遍认为是真实的。", "conclusion": "VERA-MH作为开源、完全自动化的AI安全性评估工具，在心理健康领域展示了其有效性和可靠性。未来的研究将关注该系统的泛化能力和稳健性"}}
{"id": "2602.05087", "pdf": "https://arxiv.org/pdf/2602.05087", "abs": "https://arxiv.org/abs/2602.05087", "authors": ["Parsa Vares"], "title": "Autodiscover: A reinforcement learning recommendation system for the cold-start imbalance challenge in active learning, powered by graph-aware thompson sampling", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.IR", "cs.SI"], "comment": "Master's Thesis, University of Luxembourg in collaboration with Luxembourg Institute of Science and Technology (LIST). Supervised by Prof. Jun Pang and Dr. Eloi Durant", "summary": "Systematic literature reviews (SLRs) are fundamental to evidence-based research, but manual screening is an increasing bottleneck as scientific output grows. Screening features low prevalence of relevant studies and scarce, costly expert decisions. Traditional active learning (AL) systems help, yet typically rely on fixed query strategies for selecting the next unlabeled documents. These static strategies do not adapt over time and ignore the relational structure of scientific literature networks. This thesis introduces AutoDiscover, a framework that reframes AL as an online decision-making problem driven by an adaptive agent. Literature is modeled as a heterogeneous graph capturing relationships among documents, authors, and metadata. A Heterogeneous Graph Attention Network (HAN) learns node representations, which a Discounted Thompson Sampling (DTS) agent uses to dynamically manage a portfolio of query strategies. With real-time human-in-the-loop labels, the agent balances exploration and exploitation under non-stationary review dynamics, where strategy utility changes over time. On the 26-dataset SYNERGY benchmark, AutoDiscover achieves higher screening efficiency than static AL baselines. Crucially, the agent mitigates cold start by bootstrapping discovery from minimal initial labels where static approaches fail. We also introduce TS-Insight, an open-source visual analytics dashboard to interpret, verify, and diagnose the agent's decisions. Together, these contributions accelerate SLR screening under scarce expert labels and low prevalence of relevant studies.", "AI": {"tldr": "本文提出了一种基于强化学习的推荐系统AutoDiscover，用于解决主动学习中的冷启动不平衡挑战。", "motivation": "随着科学研究产出的增长，系统文献综述(SLRs)已成为基于证据的研究的基础。然而，手动筛选是一个瓶颈，因为相关研究的比例低且专家决策稀缺和成本高昂。现有的主动学习(AL)系统依赖于固定的查询策略，在面对非平稳的评审动态时表现不佳。", "method": "AutoDiscover将AL视为在线决策问题，利用适应性智能体在文献网络中进行实时决策。它使用异构图注意力网络(HAN)来学习节点表示，并结合折扣汤普森采样(DTS)算法以根据实时的人类反馈调整查询策略组合。", "result": "在SYNERGY基准测试的26个数据集上，AutoDiscover比静态AL基线方法具有更高的筛选效率。特别是，在初始标签非常有限的情况下，它能够启动发现过程而传统的方法无法实现这一目标。", "conclusion": "通过引入适应性智能体和图结构感知采样策略组合管理，AutoDiscover能够提高SLR的筛选效率，并在稀缺专家决策的情况下解决冷启动问题。"}}
{"id": "2602.05084", "pdf": "https://arxiv.org/pdf/2602.05084", "abs": "https://arxiv.org/abs/2602.05084", "authors": ["Zhiqun Zuo", "Mohammad Mahdi Khalili"], "title": "Individual Fairness In Strategic Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Strategic classification, where individuals modify their features to influence machine learning (ML) decisions, presents critical fairness challenges. While group fairness in this setting has been widely studied, individual fairness remains underexplored. We analyze threshold-based classifiers and prove that deterministic thresholds violate individual fairness. Then, we investigate the possibility of using a randomized classifier to achieve individual fairness. We introduce conditions under which a randomized classifier ensures individual fairness and leverage these conditions to find an optimal and individually fair randomized classifier through a linear programming problem. Additionally, we demonstrate that our approach can be extended to group fairness notions. Experiments on real-world datasets confirm that our method effectively mitigates unfairness and improves the fairness-accuracy trade-off.", "AI": {"tldr": "研究在战略分类中实现个体公平性的方法，通过随机化分类器来达到这一目标，并验证其效果。", "motivation": "解决战略分类中的个体不公平问题，探讨使用随机化策略改善分类器的公平性。", "method": "分析阈值分类器并证明确定性阈值会导致不公平；引入条件使随机化分类器实现个体公平性并通过线性规划问题找到最优解；扩展方法以支持群体公平性概念。", "result": "实验表明该方法可有效减少不公平，改进了公平性和准确性的权衡。", "conclusion": "提出了一种通过随机化分类器确保个体公平的有效策略，并证实其在实际数据上的有效性。"}}
{"id": "2602.05083", "pdf": "https://arxiv.org/pdf/2602.05083", "abs": "https://arxiv.org/abs/2602.05083", "authors": ["Zilu Meng", "Gregory J. Hakim", "Wenchang Yang", "Gabriel A. Vecchi"], "title": "Large-Ensemble Simulations Reveal Links Between Atmospheric Blocking Frequency and Sea Surface Temperature Variability", "categories": ["physics.ao-ph", "cs.AI", "physics.geo-ph"], "comment": null, "summary": "Atmospheric blocking events drive persistent weather extremes in midlatitudes, but isolating the influence of sea surface temperature (SST) from chaotic internal atmospheric variability on these events remains a challenge. We address this challenge using century-long (1900-2010), large-ensemble simulations with two computationally efficient deep-learning general circulation models. We find these models skillfully reproduce the observed blocking climatology, matching or exceeding the performance of a traditional high-resolution model and representative CMIP6 models. Averaging the large ensembles filters internal atmospheric noise to isolate the SST-forced component of blocking variability, yielding substantially higher correlations with reanalysis than for individual ensemble members. We identify robust teleconnections linking Greenland blocking frequency to North Atlantic SST and El Niño-like patterns. Furthermore, SST-forced trends in blocking frequency show a consistent decline in winter over Greenland, and an increase over Europe. These results demonstrate that SST variability exerts a significant and physically interpretable influence on blocking frequency and establishes large ensembles from deep learning models as a powerful tool for separating forced SST signals from internal noise.", "AI": {"tldr": "研究使用大型集合模拟探究海表温度变化如何影响大气阻塞频率。", "motivation": "揭示海洋表面温度对中纬度持续极端天气事件的影响，分离其与混沌内部大气变异性之间的联系。", "method": "利用两个计算高效的深度学习通用环流模型进行百年级（1900-2010）大型集合模拟，并通过平均这些集合来过滤内部大气噪声以隔离海表温度强迫变化对阻塞频率的影响。", "result": "识别出格陵兰岛阻塞频率与北大西洋海表温度及类似厄尔尼诺模式的显著遥相关；发现受海表温度强迫影响，冬季在格林兰地区出现下降趋势，在欧洲则增加趋势。", "conclusion": "研究表明海洋表面温度变化对阻塞频率有重要且可解释的影响，并确认大型集合模拟能够作为分离强迫信号与内部噪声的有效工具。"}}
{"id": "2602.05082", "pdf": "https://arxiv.org/pdf/2602.05082", "abs": "https://arxiv.org/abs/2602.05082", "authors": ["Poushali Sengupta", "Sabita Maharjan", "Frank Eliassen", "Shashi Raj Pandey", "Yan Zhang"], "title": "Reliable Explanations or Random Noise? A Reliability Metric for XAI", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "In recent years, explaining decisions made by complex machine learning models has become essential in high-stakes domains such as energy systems, healthcare, finance, and autonomous systems. However, the reliability of these explanations, namely, whether they remain stable and consistent under realistic, non-adversarial changes, remains largely unmeasured. Widely used methods such as SHAP and Integrated Gradients (IG) are well-motivated by axiomatic notions of attribution, yet their explanations can vary substantially even under system-level conditions, including small input perturbations, correlated representations, and minor model updates. Such variability undermines explanation reliability, as reliable explanations should remain consistent across equivalent input representations and small, performance-preserving model changes. We introduce the Explanation Reliability Index (ERI), a family of metrics that quantifies explanation stability under four reliability axioms: robustness to small input perturbations, consistency under feature redundancy, smoothness across model evolution, and resilience to mild distributional shifts. For each axiom, we derive formal guarantees, including Lipschitz-type bounds and temporal stability results. We further propose ERI-T, a dedicated measure of temporal reliability for sequential models, and introduce ERI-Bench, a benchmark designed to systematically stress-test explanation reliability across synthetic and real-world datasets. Experimental results reveal widespread reliability failures in popular explanation methods, showing that explanations can be unstable under realistic deployment conditions. By exposing and quantifying these instabilities, ERI enables principled assessment of explanation reliability and supports more trustworthy explainable AI (XAI) systems.", "AI": {"tldr": "介绍了一种用于量化解释稳定性的度量标准ERI及其变体。", "motivation": "当前机器学习模型的决策解释存在可靠性问题，尤其是在输入小扰动、特征冗余和模型演变下，这些解释可能会出现显著变化。这导致了对更可靠解释的需求。", "method": "提出了一种名为Explanation Reliability Index (ERI) 的度量标准，它通过四个稳定性公理来量化解释的可靠性：鲁棒性、一致性、光滑性和耐久性，并且提供了正式保证和实验验证。", "result": "实验结果表明了流行解释方法在实际部署条件下的广泛可靠性的失败情况。引入了ERI-Bench基准测试框架，以系统地评估不同数据集上的解释稳定性。", "conclusion": "通过揭示这些不稳定性并量化它们，可以实现对XAI系统的更可靠的解释和支持更加信任的AI系统建设。"}}
{"id": "2602.05081", "pdf": "https://arxiv.org/pdf/2602.05081", "abs": "https://arxiv.org/abs/2602.05081", "authors": ["Jorge Condor", "Nicolai Hermann", "Mehmet Ata Yurtsever", "Piotr Didyk"], "title": "Gabor Fields: Orientation-Selective Level-of-Detail for Volume Rendering", "categories": ["cs.GR", "cs.CV"], "comment": "19 pages, incl Appendix and References", "summary": "Gaussian-based representations have enabled efficient physically-based volume rendering at a fraction of the memory cost of regular, discrete, voxel-based distributions. However, several remaining issues hamper their widespread use. One of the advantages of classic voxel grids is the ease of constructing hierarchical representations by either storing volumetric mipmaps or selectively pruning branches of an already hierarchical voxel grid. Such strategies reduce rendering time and eliminate aliasing when lower levels of detail are required. Constructing similar strategies for Gaussian-based volumes is not trivial. Straightforward solutions, such as prefiltering or computing mipmap-style representations, lead to increased memory requirements or expensive re-fitting of each level separately. Additionally, such solutions do not guarantee a smooth transition between different hierarchy levels. To address these limitations, we propose Gabor Fields, an orientation-selective mixture of Gabor kernels that enables continuous frequency filtering at no cost. The frequency content of the asset is reduced by selectively pruning primitives, directly benefiting rendering performance. Beyond filtering, we demonstrate that stochastically sampling from different frequencies and orientations at each ray recursion enables masking substantial portions of the volume, accelerating ray traversal time in single- and multiple-scattering settings. Furthermore, inspired by procedural volumes, we present an application for efficient design and rendering of procedural clouds as Gabor-noise-modulated Gaussians.", "AI": {"tldr": "该论文提出了一种名为Gabor Fields的新方法，用于基于高斯的体渲染中实现连续频率过滤和层级表示。", "motivation": "传统的体积渲染技术存在内存成本高和难以构建层次化表示的问题。为了克服这些问题，并在不增加存储需求的情况下提供平滑过渡的不同层之间的功能，作者提出了一种新的方法：Gabor Fields。", "method": "通过使用选择性地修剪原始数据的方法减少频率内容，从而直接提高渲染性能。该技术还允许从不同频段和方向进行随机采样以加速光线遍历时间，并且可以用于设计高效的过程云的程序化渲染。", "result": "Gabor Fields方法能够有效地降低内存消耗并加速体渲染过程，同时保证图像质量和细节表现的一致性。", "conclusion": "通过引入新的技术Gabor Fields，作者证明了可以在不增加存储需求的情况下实现基于高斯的体积数据的连续频率过滤，并且可以通过从不同频段和方向进行随机采样进一步提高渲染效率。"}}
{"id": "2602.05079", "pdf": "https://arxiv.org/pdf/2602.05079", "abs": "https://arxiv.org/abs/2602.05079", "authors": ["Vinal Asodia", "Iman Sharifi", "Saber Fallah"], "title": "Reinforcement Learning Enhancement Using Vector Semantic Representation and Symbolic Reasoning for Human-Centered Autonomous Emergency Braking", "categories": ["cs.RO", "cs.LG"], "comment": "12 pages, 7 figures, 5 tables", "summary": "The problem with existing camera-based Deep Reinforcement Learning approaches is twofold: they rarely integrate high-level scene context into the feature representation, and they rely on rigid, fixed reward functions. To address these challenges, this paper proposes a novel pipeline that produces a neuro-symbolic feature representation that encompasses semantic, spatial, and shape information, as well as spatially boosted features of dynamic entities in the scene, with an emphasis on safety-critical road users. It also proposes a Soft First-Order Logic (SFOL) reward function that balances human values via a symbolic reasoning module. Here, semantic and spatial predicates are extracted from segmentation maps and applied to linguistic rules to obtain reward weights. Quantitative experiments in the CARLA simulation environment show that the proposed neuro-symbolic representation and SFOL reward function improved policy robustness and safety-related performance metrics compared to baseline representations and reward formulations across varying traffic densities and occlusion levels. The findings demonstrate that integrating holistic representations and soft reasoning into Reinforcement Learning can support more context-aware and value-aligned decision-making for autonomous driving.", "AI": {"tldr": "该论文提出了一种增强的强化学习方法，用于提高基于相机的人机交互式紧急制动系统的表现。", "motivation": "现有的基于相机的深度强化学习方法在特征表示中很少整合高层次场景背景，并且依赖于固定的奖励函数。因此，本文旨在解决这些问题，以提升自动驾驶决策系统的安全性与适应性。", "method": "论文提出了一种结合神经符号表示和软一阶逻辑(SFOL)奖励函数的新流程，该流程包括从分割图中提取语义、空间特征，并应用语言规则获取奖励权重。这种方法增强了对动态实体的场景理解和价值一致性的决策制定。", "result": "在CARLA模拟环境中进行的定量实验表明，与基线表示和奖励公式相比，所提出的神经符号表示和SFOL奖励函数提高了策略鲁棒性和安全相关性能指标，在不同的交通密度和遮挡水平下表现更好。", "conclusion": "研究结果证明了将全面表示和软推理集成到强化学习中可以支持更上下文感知和价值一致的决策制定，以提高自动驾驶安全性。"}}
{"id": "2602.05078", "pdf": "https://arxiv.org/pdf/2602.05078", "abs": "https://arxiv.org/abs/2602.05078", "authors": ["Gautham Vinod", "Fengqing Zhu"], "title": "Food Portion Estimation: From Pixels to Calories", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.IV"], "comment": null, "summary": "Reliance on images for dietary assessment is an important strategy to accurately and conveniently monitor an individual's health, making it a vital mechanism in the prevention and care of chronic diseases and obesity. However, image-based dietary assessment suffers from estimating the three dimensional size of food from 2D image inputs. Many strategies have been devised to overcome this critical limitation such as the use of auxiliary inputs like depth maps, multi-view inputs, or model-based approaches such as template matching. Deep learning also helps bridge the gap by either using monocular images or combinations of the image and the auxillary inputs to precisely predict the output portion from the image input. In this paper, we explore the different strategies employed for accurate portion estimation.", "AI": {"tldr": "本文探讨了从二维图像中准确估计食物分量的不同策略。", "motivation": "依靠图像进行饮食评估是监测个人健康的重要手段，有助于预防和治疗慢性疾病及肥胖。然而，这种评估方法面临挑战，即如何从2D图片输入中估算出3D尺寸的食物。", "method": "本文探索了多种策略来解决这一难题，包括使用辅助信息如深度图或多视角输入、基于模板匹配的模型化方法以及利用深度学习结合单眼图像和辅助输入的方法。", "result": "通过这些方法，能够从二维图片中更准确地预测食物分量。", "conclusion": "研究表明，综合运用各种策略可以有效提升从2D图像估计3D食物尺寸的精度。"}}
{"id": "2602.05075", "pdf": "https://arxiv.org/pdf/2602.05075", "abs": "https://arxiv.org/abs/2602.05075", "authors": ["Agni Bandyopadhyay", "Gunther Waxenegger-Wilfing"], "title": "Optimizing Mission Planning for Multi-Debris Rendezvous Using Reinforcement Learning with Refueling and Adaptive Collision Avoidance", "categories": ["cs.AI", "cs.LG", "cs.RO", "physics.space-ph"], "comment": "Accpeted at Conference: 15th IAA Symposium on Small Satellites for Earth System Observation At: Berlin", "summary": "As the orbital environment around Earth becomes increasingly crowded with debris, active debris removal (ADR) missions face significant challenges in ensuring safe operations while minimizing the risk of in-orbit collisions. This study presents a reinforcement learning (RL) based framework to enhance adaptive collision avoidance in ADR missions, specifically for multi-debris removal using small satellites. Small satellites are increasingly adopted due to their flexibility, cost effectiveness, and maneuverability, making them well suited for dynamic missions such as ADR. Building on existing work in multi-debris rendezvous, the framework integrates refueling strategies, efficient mission planning, and adaptive collision avoidance to optimize spacecraft rendezvous operations. The proposed approach employs a masked Proximal Policy Optimization (PPO) algorithm, enabling the RL agent to dynamically adjust maneuvers in response to real-time orbital conditions. Key considerations include fuel efficiency, avoidance of active collision zones, and optimization of dynamic orbital parameters. The RL agent learns to determine efficient sequences for rendezvousing with multiple debris targets, optimizing fuel usage and mission time while incorporating necessary refueling stops. Simulated ADR scenarios derived from the Iridium 33 debris dataset are used for evaluation, covering diverse orbital configurations and debris distributions to demonstrate robustness and adaptability. Results show that the proposed RL framework reduces collision risk while improving mission efficiency compared to traditional heuristic approaches. This work provides a scalable solution for planning complex multi-debris ADR missions and is applicable to other multi-target rendezvous problems in autonomous space mission planning.", "AI": {"tldr": "使用强化学习优化多目标碎片清除任务中的燃料效率和避碰策略。", "motivation": "地球轨道环境日益拥挤，主动碎片去除（ADR）任务面临安全操作及降低在轨碰撞风险的挑战。为此研究提出一种基于强化学习的方法来增强适应性避碰能力。", "method": "采用掩码近端策略优化算法（PPO），使代理能够根据实时轨道状况动态调整机动策略，整合燃料补给策略、有效任务规划和自适应避撞以优化航天器交会操作。", "result": "实验结果表明所提RL框架在降低碰撞风险的同时提高了任务效率，并优于传统启发式方法。", "conclusion": "该工作提供了一个可扩展的解决方案用于复杂的多目标ADR任务规划，适用于其他多目标空间自动交会问题。"}}
{"id": "2602.05073", "pdf": "https://arxiv.org/pdf/2602.05073", "abs": "https://arxiv.org/abs/2602.05073", "authors": ["Changdae Oh", "Seongheon Park", "To Eun Kim", "Jiatong Li", "Wendi Li", "Samuel Yeh", "Xuefeng Du", "Hamed Hassani", "Paul Bogdan", "Dawn Song", "Sharon Li"], "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents", "categories": ["cs.AI"], "comment": null, "summary": "Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents, and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process, a viewpoint that breaks down for interactive agents in an open world. In contrast, we propose a novel perspective, a conditional uncertainty reduction process, that explicitly models reducible uncertainty over an agent's trajectory by highlighting \"interactivity\" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.", "AI": {"tldr": "本文提出了一个针对大型语言模型代理的不确定性量化的新框架，该框架考虑了交互性并在开放环境中减少了可减少的不确定性。", "motivation": "当前大多数不确定性量化研究集中在单轮问答上，而现实应用中涉及多轮互动。为了使LLM代理更安全可靠，需要开发适用于复杂任务和多轮对话场景的新的不确定性量化方法。", "method": "本文提出了一种基于条件减少过程的新视角来建模可减少的不确定性，并提供了一个概念框架以指导设计适合大型语言模型代理的不确定性量化。", "result": "通过新框架能够更好地理解和处理开放环境中交互型LLM代理的任务不确定性，为前沿大型语言模型的发展和领域特定应用提供了实用性的指导意见。", "conclusion": "该研究提出了一个适用于大型语言模型代理的新不确定量化框架，并指出了在实际应用中面临的挑战以及未来的研究方向。"}}
{"id": "2602.05068", "pdf": "https://arxiv.org/pdf/2602.05068", "abs": "https://arxiv.org/abs/2602.05068", "authors": ["Wenting Li", "Saif R. Kazi", "Russell Bent", "Duo Zhou", "Huan Zhang"], "title": "E-Globe: Scalable $ε$-Global Verification of Neural Networks via Tight Upper Bounds and Pattern-Aware Branching", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 10 figures", "summary": "Neural networks achieve strong empirical performance, but robustness concerns still hinder deployment in safety-critical applications. Formal verification provides robustness guarantees, but current methods face a scalability-completeness trade-off. We propose a hybrid verifier in a branch-and-bound (BaB) framework that efficiently tightens both upper and lower bounds until an $ε-$global optimum is reached or early stop is triggered. The key is an exact nonlinear program with complementarity constraints (NLP-CC) for upper bounding that preserves the ReLU input-output graph, so any feasible solution yields a valid counterexample and enables rapid pruning of unsafe subproblems. We further accelerate verification with (i) warm-started NLP solves requiring minimal constraint-matrix updates and (ii) pattern-aligned strong branching that prioritizes splits most effective at tightening relaxations. We also provide conditions under which NLP-CC upper bounds are tight. Experiments on MNIST and CIFAR-10 show markedly tighter upper bounds than PGD across perturbation radii spanning up to three orders of magnitude, fast per-node solves in practice, and substantial end-to-end speedups over MIP-based verification, amplified by warm-starting, GPU batching, and pattern-aligned branching.", "AI": {"tldr": "提出了一种可扩展的神经网络形式验证方法E-Globe，结合了紧致上界和模式感知分支策略以提高效率。", "motivation": "尽管神经网络取得了很好的经验性能，但其在安全关键应用中的部署因缺乏健壮性而受限。当前的形式化验证方法面临可伸缩性和完备性的权衡问题，需要一种新的高效解决方案。", "method": "通过非线性规划补全约束（NLP-CC）结合分支定界框架，在保证ReLU输入输出图完整的情况下提供精确上界，采用温启动和模式感知强分支策略以加速验证过程。", "result": "实验表明，该方法在MNIST和CIFAR-10数据集上的上界更紧致，节点求解速度快，并且整体速度优于基于MIP的验证。", "conclusion": "E-Globe通过结合精确非线性规划补全约束和模式感知强分支策略提供了有效的神经网络形式化验证方法。"}}
{"id": "2602.05066", "pdf": "https://arxiv.org/pdf/2602.05066", "abs": "https://arxiv.org/abs/2602.05066", "authors": ["Jafar Isbarov", "Murat Kantarcioglu"], "title": "Bypassing AI Control Protocols via Agent-as-a-Proxy Attacks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As AI agents automate critical workloads, they remain vulnerable to indirect prompt injection (IPI) attacks. Current defenses rely on monitoring protocols that jointly evaluate an agent's Chain-of-Thought (CoT) and tool-use actions to ensure alignment with user intent. We demonstrate that these monitoring-based defenses can be bypassed via a novel Agent-as-a-Proxy attack, where prompt injection attacks treat the agent as a delivery mechanism, bypassing both agent and monitor simultaneously. While prior work on scalable oversight has focused on whether small monitors can supervise large agents, we show that even frontier-scale monitors are vulnerable. Large-scale monitoring models like Qwen2.5-72B can be bypassed by agents with similar capabilities, such as GPT-4o mini and Llama-3.1-70B. On the AgentDojo benchmark, we achieve a high attack success rate against AlignmentCheck and Extract-and-Evaluate monitors under diverse monitoring LLMs. Our findings suggest current monitoring-based agentic defenses are fundamentally fragile regardless of model scale.", "AI": {"tldr": "本文展示了通过代理攻击绕过AI监控防御的方法，并证明了即使大型监测模型也无法有效防止这种攻击。", "motivation": "当前的AI控制系统依赖于监控协议来确保代理人行为与用户意图一致。然而，这些系统可能被间接提示注入（IPI）攻击所绕过。作者希望通过研究代理作为中介的新型攻击方式来揭示现有防御机制中的脆弱性。", "method": "通过设计一种新的Agent-as-a-Proxy攻击方法，其中利用AI代理作为传递介质发起攻击，并在多种大规模语言模型上测试其效果以评估监控系统的有效性。", "result": "实验结果表明，在多个代理监督基准下，即使使用前沿级别的监测模型如Qwen2.5-72B和大型代理模型GPT-4o mini及Llama-3.1-70B，攻击成功率达到较高水平。这证明了现有的基于监控的防御策略存在根本性的弱点。", "conclusion": "研究结果表明，现有的AI控制系统在面对高级别威胁时并不足够安全，需要开发新的方法来防止此类代理作为中介的攻击方式。"}}
{"id": "2602.05064", "pdf": "https://arxiv.org/pdf/2602.05064", "abs": "https://arxiv.org/abs/2602.05064", "authors": ["Yewon Kim", "Stephen Brade", "Alexander Wang", "David Zhou", "Haven Kim", "Bill Wang", "Sung-Ju Lee", "Hugo F Flores Garcia", "Cheng-Zhi Anna Huang", "Chris Donahue"], "title": "A Design Space for Live Music Agents", "categories": ["cs.HC"], "comment": "Accepted as a full paper at ACM CHI 2026", "summary": "Live music provides a uniquely rich setting for studying creativity and interaction due to its spontaneous nature. The pursuit of live music agents--intelligent systems supporting real-time music performance and interaction--has captivated researchers across HCI, AI, and computer music for decades, and recent advancements in AI suggest unprecedented opportunities to evolve their design. However, the interdisciplinary nature of music has led to fragmented development across research communities, hindering effective communication and collaborative progress. In this work, we bring together perspectives from these diverse fields to map the current landscape of live music agents. Based on our analysis of 184 systems across both academic literature and video, we develop a comprehensive design space that categorizes dimensions spanning usage contexts, interactions, technologies, and ecosystems. By highlighting trends and gaps in live music agents, our design space offers researchers, designers, and musicians a structured lens to understand existing systems and shape future directions in real-time human-AI music co-creation. We release our annotated systems as a living artifact at https://live-music-agents.github.io.", "AI": {"tldr": "本文通过对184个系统的分析，提出了一个全面的设计空间，旨在为实时音乐表演和交互的智能系统的发展提供结构化的视角。", "motivation": "为了促进跨学科研究人员之间的有效沟通和协作进步，作者整合了来自人机交互、人工智能和计算机音乐领域的不同观点。", "method": "基于对学术文献和视频中184个系统的分析，发展了一个涵盖使用场景、交互方式、技术手段及生态系统等维度的设计空间。", "result": "设计空间明确了实时音乐代理中的趋势与不足，为研究者、设计师以及音乐家提供了理解现有系统并塑造未来方向的结构化视角。", "conclusion": "本文提供的设计空间及其相关注释系统的在线发布有助于推动实时人类-AI音乐共创领域的进一步发展。"}}
{"id": "2602.05059", "pdf": "https://arxiv.org/pdf/2602.05059", "abs": "https://arxiv.org/abs/2602.05059", "authors": ["Adithya Kulkarni", "Mohna Chakraborty", "Jay Bagga"], "title": "Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably they support mathematically rigorous thinking. This study examines the performance of a LLM on two related graph theoretic problems: a solved problem concerning the gracefulness of line graphs and an open problem for which no solution is currently known. We use an eight stage evaluation protocol that reflects authentic mathematical inquiry, including interpretation, exploration, strategy formation, and proof construction. The model performed strongly on the solved problem, producing correct definitions, identifying relevant structures, recalling appropriate results without hallucination, and constructing a valid proof confirmed by a graph theory expert. For the open problem, the model generated coherent interpretations and plausible exploratory strategies but did not advance toward a solution. It did not fabricate results and instead acknowledged uncertainty, which is consistent with the explicit prompting instructions that directed the model to avoid inventing theorems or unsupported claims. These findings indicate that LLMs can support exploration of established material but remain limited in tasks requiring novel mathematical insight or critical structural reasoning. For computing education, this distinction highlights the importance of guiding students to use LLMs for conceptual exploration while relying on independent verification and rigorous argumentation for formal problem solving.", "AI": {"tldr": "评估大型语言模型在图论中的表现，分析其对计算机教育的影响", "motivation": "理解大型语言模型如何支持严格的数学思维，特别是在计算机科学课程中。研究大型语言模型在解决已知和未知的图论问题时的表现。", "method": "采用八阶段评价协议来评估一个大型语言模型处理两个相关的图论问题的能力，包括解释、探索、策略制定和证明构造。", "result": "该模型成功解决了已知的问题，并提供了正确定义、相关结构识别及有效证明；在未解决的问题上表现良好但未能找到解决方案。", "conclusion": "大型语言模型可支持概念性探索但在需要创新思维或关键结构性推理的任务中受限，因此应指导学生使用这些工具进行探索并独立验证和严谨论证解决问题。"}}
{"id": "2602.05058", "pdf": "https://arxiv.org/pdf/2602.05058", "abs": "https://arxiv.org/abs/2602.05058", "authors": ["Aria Christensen", "Andrew Zhao"], "title": "Learning fermionic linear optics with Heisenberg scaling and physical operations", "categories": ["quant-ph", "cs.DS", "cs.LG"], "comment": "56 pages", "summary": "We revisit the problem of learning fermionic linear optics (FLO), also known as fermionic Gaussian unitaries. Given black-box query access to an unknown FLO, previous proposals required $\\widetilde{\\mathcal{O}}(n^5 / \\varepsilon^2)$ queries, where $n$ is the system size and $\\varepsilon$ is the error in diamond distance. These algorithms also use unphysical operations (i.e., violating fermionic superselection rules) and/or $n$ auxiliary modes to prepare Choi states of the FLO. In this work, we establish efficient and experimentally friendly protocols that obey superselection, use minimal ancilla (at most $1$ extra mode), and exhibit improved dependence on both parameters $n$ and $\\varepsilon$. For arbitrary (active) FLOs this algorithm makes at most $\\widetilde{\\mathcal{O}}(n^4 / \\varepsilon)$ queries, while for number-conserving (passive) FLOs we show that $\\mathcal{O}(n^3 / \\varepsilon)$ queries suffice. The complexity of the active case can be further reduced to $\\widetilde{\\mathcal{O}}(n^3 / \\varepsilon)$ at the cost of using $n$ ancilla. This marks the first FLO learning algorithm that attains Heisenberg scaling in precision. As a side result, we also demonstrate an improved copy complexity of $\\widetilde{\\mathcal{O}}(n η^2 / \\varepsilon^2)$ for time-efficient state tomography of $η$-particle Slater determinants in $\\varepsilon$ trace distance, which may be of independent interest.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.05051", "pdf": "https://arxiv.org/pdf/2602.05051", "abs": "https://arxiv.org/abs/2602.05051", "authors": ["Songyuan Zhang", "Oswin So", "H. M. Sabbir Ahmad", "Eric Yang Yu", "Matthew Cleaveland", "Mitchell Black", "Chuchu Fan"], "title": "ReFORM: Reflected Flows for On-support Offline RL via Noise Manipulation", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "24 pages, 17 figures; Accepted by the fourteenth International Conference on Learning Representations (ICLR 2026)", "summary": "Offline reinforcement learning (RL) aims to learn the optimal policy from a fixed dataset generated by behavior policies without additional environment interactions. One common challenge that arises in this setting is the out-of-distribution (OOD) error, which occurs when the policy leaves the training distribution. Prior methods penalize a statistical distance term to keep the policy close to the behavior policy, but this constrains policy improvement and may not completely prevent OOD actions. Another challenge is that the optimal policy distribution can be multimodal and difficult to represent. Recent works apply diffusion or flow policies to address this problem, but it is unclear how to avoid OOD errors while retaining policy expressiveness. We propose ReFORM, an offline RL method based on flow policies that enforces the less restrictive support constraint by construction. ReFORM learns a behavior cloning (BC) flow policy with a bounded source distribution to capture the support of the action distribution, then optimizes a reflected flow that generates bounded noise for the BC flow while keeping the support, to maximize the performance. Across 40 challenging tasks from the OGBench benchmark with datasets of varying quality and using a constant set of hyperparameters for all tasks, ReFORM dominates all baselines with hand-tuned hyperparameters on the performance profile curves.", "AI": {"tldr": "提出了一种新的离线强化学习方法ReFORM，通过噪声操纵来解决策略离开训练分布的问题，并保持策略的表达能力。", "motivation": "解决离线强化学习中的出界误差问题以及多模态最优策略表示困难的问题。", "method": "设计了一个基于流策略的方法ReFORM，采用行为克隆（BC）流策略和反射流来生成受限制的支持噪声，以最大化性能。", "result": "在40个具有不同数据集质量的任务上，使用一组固定的超参数，ReFORM的表现超过了所有基线方法。", "conclusion": "ReFORM通过操纵噪声成功解决了离线强化学习中的出界误差问题，并保持了策略的表达能力。"}}
{"id": "2602.05049", "pdf": "https://arxiv.org/pdf/2602.05049", "abs": "https://arxiv.org/abs/2602.05049", "authors": ["Yiye Chen", "Yanan Jian", "Xiaoyi Dong", "Shuxin Cao", "Jing Wu", "Patricio Vela", "Benjamin E. Lundell", "Dongdong Chen"], "title": "VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "In submission. Project website: https://vista-vla.github.io/", "summary": "Vision-Language-Action (VLA) models have demonstrated strong performance across a wide range of robotic manipulation tasks. Despite the success, extending large pretrained Vision-Language Models (VLMs) to the action space can induce vision-action misalignment, where action predictions exhibit weak dependence on the current visual state, leading to unreliable action outputs. In this work, we study VLA models through the lens of visual conditioning and empirically show that successful rollouts consistently exhibit stronger visual dependence than failed ones. Motivated by this observation, we propose a training framework that explicitly strengthens visual conditioning in VLA models. Our approach first aligns action prediction with visual input via preference optimization on a track-following surrogate task, and then transfers the enhanced alignment to instruction-following task through latent-space distillation during supervised finetuning. Without introducing architectural modifications or additional data collection, our method improves both visual conditioning and task performance for discrete OpenVLA, and further yields consistent gains when extended to the continuous OpenVLA-OFT setting. Project website: https://vista-vla.github.io/ .", "AI": {"tldr": "该论文提出了一种通过视觉条件增强来改善Vision-Language-Action（VLA）模型性能的方法。", "motivation": "在将大型预训练的Vision-Language Model（VLM）扩展到动作空间时，可能会产生视觉与动作的不一致性，导致行动预测对当前视觉状态依赖性较弱。研究者观察到成功的操作比失败的操作显示出更强的视觉依赖性，因此提出了一个增强视觉条件的方法。", "method": "通过偏好优化在轨迹跟随代理任务上使动作预测与视觉输入对齐，并且通过潜在空间蒸馏将这种改进转移到指令跟随任务中，在监督微调期间实现。", "result": "该方法无需架构修改或额外的数据收集，提高了离散OpenVLA和连续OpenVLA-OFT设置中的视觉条件和任务性能。", "conclusion": "所提出的方法通过增强视觉条件改善了Vision-Language-Action模型的性能，展示了其在不同环境下的适用性。"}}
{"id": "2602.05048", "pdf": "https://arxiv.org/pdf/2602.05048", "abs": "https://arxiv.org/abs/2602.05048", "authors": ["Zeyu Fang", "Tian Lan", "Mahdi Imani"], "title": "MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading to knowledge gaps in joint planning. We consider the problem of discovering optimal interaction strategies for AI agents to actively elicit human inputs in object-driven planning. To this end, we propose Minimal Information Neuro-Symbolic Tree (MINT) to reason about the impact of knowledge gaps and leverage self-play with MINT to optimize the AI agent's elicitation strategies and queries. More precisely, MINT builds a symbolic tree by making propositions of possible human-AI interactions and by consulting a neural planning policy to estimate the uncertainty in planning outcomes caused by remaining knowledge gaps. Finally, we leverage LLM to search and summarize MINT's reasoning process and curate a set of queries to optimally elicit human inputs for best planning performance. By considering a family of extended Markov decision processes with knowledge gaps, we analyze the return guarantee for a given MINT with active human elicitation. Our evaluation on three benchmarks involving unseen/unknown objects of increasing realism shows that MINT-based planning attains near-expert returns by issuing a limited number of questions per task while achieving significantly improved rewards and success rates.", "AI": {"tldr": "本文提出了一种名为Minimal Information Neuro-Symbolic Tree (MINT) 的方法，用于在对象驱动规划中通过主动征求人类输入来优化AI代理的互动策略。", "motivation": "为了应对开放世界中的不完整信息和未知因素导致的知识缺口问题，该研究旨在发现最优的人机交互策略以最大化共同决策的效果。", "method": "MINT利用符号树形式化可能的人机互动并借助神经规划策略估计由于知识缺口造成的不确定性。通过自我对弈优化AI的互动策略，并使用LLM来搜索和总结MINT的过程，从而提出最佳的问题集来获取人类输入。", "result": "实验结果表明，在处理未知或未见对象时，基于MINT的规划能够通过较少数量的提问实现接近专家级别的回报，并显著提升奖励与成功率。", "conclusion": "研究展示了如何利用神经符号方法有效解决人机共同决策中的知识缺口问题，并证明了这种方法在不同难度的任务中均能取得良好效果。"}}
{"id": "2602.05047", "pdf": "https://arxiv.org/pdf/2602.05047", "abs": "https://arxiv.org/abs/2602.05047", "authors": ["Grzegorz Wilczyński", "Rafał Tobiasz", "Paweł Gora", "Marcin Mazur", "Przemysław Spurek"], "title": "QuantumGS: Quantum Encoding Framework for Gaussian Splatting", "categories": ["quant-ph", "cs.CV"], "comment": null, "summary": "Recent advances in neural rendering, particularly 3D Gaussian Splatting (3DGS), have enabled real-time rendering of complex scenes. However, standard 3DGS relies on spherical harmonics, which often struggle to accurately capture high-frequency view-dependent effects such as sharp reflections and transparency. While hybrid approaches like Viewing Direction Gaussian Splatting (VDGS) mitigate this limitation using classical Multi-Layer Perceptrons (MLPs), they remain limited by the expressivity of classical networks in low-parameter regimes. In this paper, we introduce QuantumGS, a novel hybrid framework that integrates Variational Quantum Circuits (VQC) into the Gaussian Splatting pipeline. We propose a unique encoding strategy that maps the viewing direction directly onto the Bloch sphere, leveraging the natural geometry of qubits to represent 3D directional data. By replacing classical color-modulating networks with quantum circuits generated via a hypernetwork or conditioning mechanism, we achieve higher expressivity and better generalization. Source code is available in the supplementary material. Code is available at https://github.com/gwilczynski95/QuantumGS", "AI": {"tldr": "本文提出了QuantumGS框架，将变分量子电路集成到Gaussian Splatting流程中，以提高视图依赖效果的准确性。", "motivation": "标准的3D Gaussian Splatting在处理高频率视图依赖效果时存在局限性，而现有的混合方法如VDGS虽有所改进，但在低参数环境中仍受限于经典网络的表现力。", "method": "QuantumGS通过将视角直接映射到Bloch球上来设计独特的编码策略，并使用量子电路替代传统颜色调制网络，以提高表示能力和泛化能力。", "result": "该方法在准确捕捉高频率视图依赖效果方面表现出色，并且代码已开源供研究者参考。", "conclusion": "QuantumGS为解决3D渲染中的高频率视图依赖问题提供了一种新的解决方案，展示了量子计算在图形学领域的潜力。"}}
{"id": "2602.05043", "pdf": "https://arxiv.org/pdf/2602.05043", "abs": "https://arxiv.org/abs/2602.05043", "authors": ["Grace A. Lewis", "Rachel Brower-Sinning", "Robert Edman", "Ipek Ozkaya", "Sebastián Echeverría", "Alex Derr", "Collin Beaudoin", "Katherine R. Maffey"], "title": "Quality Model for Machine Learning Components", "categories": ["cs.SE", "cs.AI"], "comment": "A short version of this paper has been accepted to CAIN 2026, the 5th IEEE/ACM Conference on AI Engineering - Software Engineering for AI Systems", "summary": "Despite increased adoption and advances in machine learning (ML), there are studies showing that many ML prototypes do not reach the production stage and that testing is still largely limited to testing model properties, such as model performance, without considering requirements derived from the system it will be a part of, such as throughput, resource consumption, or robustness. This limited view of testing leads to failures in model integration, deployment, and operations. In traditional software development, quality models such as ISO 25010 provide a widely used structured framework to assess software quality, define quality requirements, and provide a common language for communication with stakeholders. A newer standard, ISO 25059, defines a more specific quality model for AI systems. However, a problem with this standard is that it combines system attributes with ML component attributes, which is not helpful for a model developer, as many system attributes cannot be assessed at the component level. In this paper, we present a quality model for ML components that serves as a guide for requirements elicitation and negotiation and provides a common vocabulary for ML component developers and system stakeholders to agree on and define system-derived requirements and focus their testing efforts accordingly. The quality model was validated through a survey in which the participants agreed with its relevance and value. The quality model has been successfully integrated into an open-source tool for ML component testing and evaluation demonstrating its practical application.", "AI": {"tldr": "提出一种机器学习组件的质量模型，用于指导需求收集和谈判，并为开发人员和利益相关者提供通用词汇以定义系统衍生要求并集中测试工作。", "motivation": "当前许多机器学习原型未能达到生产阶段，且测试主要集中在模型性能上，未考虑其所在系统的属性如吞吐量、资源消耗或鲁棒性等问题。传统软件工程中的ISO 25010等质量模型适用于评估整个系统而非单个组件。为解决这些问题，该论文提出了一个新的针对机器学习组件的质量模型。", "method": "通过设计一个专门针对ML组件的质量模型，并进行用户调查来验证其相关性和价值，同时将其集成到开源工具中以展示其实用性。", "result": "质量模型在用户调查中得到了高度认可，被证明是相关的和有价值的；并且该模型已被成功应用于一个开放源代码的机器学习组件测试与评估工具中。", "conclusion": "新提出的ML组件质量模型为开发人员和系统利益相关者之间的沟通提供了一个通用语言，并有助于定义和集中于系统的衍生需求。"}}
{"id": "2602.05037", "pdf": "https://arxiv.org/pdf/2602.05037", "abs": "https://arxiv.org/abs/2602.05037", "authors": ["Bishoy Galoaa", "Xiangyu Bai", "Utsav Nandi", "Sai Siddhartha Vivek Dhir Rangoju", "Somaieh Amraee", "Sarah Ostadabbas"], "title": "UniTrack: Differentiable Graph Representation Learning for Multi-Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "We present UniTrack, a plug-and-play graph-theoretic loss function designed to significantly enhance multi-object tracking (MOT) performance by directly optimizing tracking-specific objectives through unified differentiable learning. Unlike prior graph-based MOT methods that redesign tracking architectures, UniTrack provides a universal training objective that integrates detection accuracy, identity preservation, and spatiotemporal consistency into a single end-to-end trainable loss function, enabling seamless integration with existing MOT systems without architectural modifications. Through differentiable graph representation learning, UniTrack enables networks to learn holistic representations of motion continuity and identity relationships across frames. We validate UniTrack across diverse tracking models and multiple challenging benchmarks, demonstrating consistent improvements across all tested architectures and datasets including Trackformer, MOTR, FairMOT, ByteTrack, GTR, and MOTE. Extensive evaluations show up to 53\\% reduction in identity switches and 12\\% IDF1 improvements across challenging benchmarks, with GTR achieving peak performance gains of 9.7\\% MOTA on SportsMOT.", "AI": {"tldr": "UniTrack 是一种用于提升多目标跟踪性能的可微分图表示学习方法。", "motivation": "传统图形基础的多目标跟踪方法需要重新设计跟踪架构，而 UniTrack 则通过提供一个通用的训练目标来增强现有系统的性能，该目标能够将检测精度、身份保持和时空一致性整合到单一的端到端可训练损失函数中。", "method": "UniTrack 设计了一种可插拔的图形理论损失函数，利用可微分图表示学习使网络学会在帧之间进行整体运动连续性和身份关系的学习。", "result": "实验验证了 UniTrack 在多种跟踪模型和多个挑战性基准上均表现出一致性改进，在 SportsMOT 上 GTR 实现了 MOTA 性能提升达9.7%，IDF1 改进达12%。", "conclusion": "UniTrack 显著提升了多目标跟踪系统的性能，通过不同的图表示学习方法使网络能够更好地理解运动连续性和身份关系。"}}
{"id": "2602.05029", "pdf": "https://arxiv.org/pdf/2602.05029", "abs": "https://arxiv.org/abs/2602.05029", "authors": ["Octavio Arriaga", "Proneet Sharma", "Jichen Guo", "Marc Otto", "Siddhant Kadwe", "Rebecca Adam"], "title": "Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Submitted to IEEE Robotics and Automation Letters (RA-L) for review. This version includes the statement required by IEEE for preprints", "summary": "Operating effectively in novel real-world environments requires robotic systems to estimate and interact with previously unseen objects. Current state-of-the-art models address this challenge by using large amounts of training data and test-time samples to build black-box scene representations. In this work, we introduce a differentiable neuro-graphics model that combines neural foundation models with physics-based differentiable rendering to perform zero-shot scene reconstruction and robot grasping without relying on any additional 3D data or test-time samples. Our model solves a series of constrained optimization problems to estimate physically consistent scene parameters, such as meshes, lighting conditions, material properties, and 6D poses of previously unseen objects from a single RGBD image and bounding boxes. We evaluated our approach on standard model-free few-shot benchmarks and demonstrated that it outperforms existing algorithms for model-free few-shot pose estimation. Furthermore, we validated the accuracy of our scene reconstructions by applying our algorithm to a zero-shot grasping task. By enabling zero-shot, physically-consistent scene reconstruction and grasping without reliance on extensive datasets or test-time sampling, our approach offers a pathway towards more data efficient, interpretable and generalizable robot autonomy in novel environments.", "AI": {"tldr": "介绍了一种结合神经基础模型与物理可微渲染的可微逆图形模型，实现零样本场景重建和机器人抓取任务。", "motivation": "当前最先进的模型通过大量训练数据和测试时间采样构建黑箱场景表示来应对处理未知环境的挑战。该工作旨在开发一种无需额外3D数据或测试时间样本即可进行零样本场景重建和机器人抓取的方法，提高系统的数据效率、可解释性和泛化性。", "method": "提出了一种结合神经基础模型与物理可微渲染的可微逆图形方法，通过解决一系列约束优化问题估计出一致性的场景参数，包括网格、光照条件、材料属性以及未见过物体的6D姿态。仅凭单个RGBD图像和边界框即可完成。", "result": "在标准无模型少样本基准测试中超越了现有的无模型少样本姿势估计算法，并通过零样本抓取任务验证了其场景重建精度。", "conclusion": "该方法提供了一条实现更加数据高效、可解释且泛化性强的机器人自主性的途径，适用于新环境中的操作。"}}
{"id": "2602.05027", "pdf": "https://arxiv.org/pdf/2602.05027", "abs": "https://arxiv.org/abs/2602.05027", "authors": ["Georgii Aparin", "Tasnima Sadekova", "Alexey Rukhovich", "Assel Yermekova", "Laida Kushnareva", "Vadim Popov", "Kristian Kuznetsov", "Irina Piontkovskaya"], "title": "AudioSAE: Towards Understanding of Audio-Processing Models with Sparse AutoEncoders", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Sparse Autoencoders (SAEs) are powerful tools for interpreting neural representations, yet their use in audio remains underexplored. We train SAEs across all encoder layers of Whisper and HuBERT, provide an extensive evaluation of their stability, interpretability, and show their practical utility. Over 50% of the features remain consistent across random seeds, and reconstruction quality is preserved. SAE features capture general acoustic and semantic information as well as specific events, including environmental noises and paralinguistic sounds (e.g. laughter, whispering) and disentangle them effectively, requiring removal of only 19-27% of features to erase a concept. Feature steering reduces Whisper's false speech detections by 70% with negligible WER increase, demonstrating real-world applicability. Finally, we find SAE features correlated with human EEG activity during speech perception, indicating alignment with human neural processing. The code and checkpoints are available at https://github.com/audiosae/audiosae_demo.", "AI": {"tldr": "本文通过在音频处理模型中使用稀疏自编码器来解释神经表示，并展示了其稳定性和实用性。", "motivation": "虽然稀疏自动编码器是强大的工具，但它们在音频领域的应用尚未得到充分探索。文章旨在探讨稀疏自动编码器在语音处理模型中的作用和效果。", "method": "训练了稀疏自编码器以覆盖Whisper和HuBERT的所有编码器层，并对其稳定性、可解释性进行了全面评估。", "result": "超过50%的特征在不同随机种子下保持一致，重构质量得到保留。稀疏自动编码器能够捕捉到一般的声学信息和特定事件，并有效地分离这些概念。特征引导降低了误报率70%，并显示与人类EEG活动的相关性。", "conclusion": "稀疏自编码器在音频处理模型中的应用不仅具有稳定性和可解释性，还展示了其实际价值和潜在的人类神经处理关联性"}}
{"id": "2602.05026", "pdf": "https://arxiv.org/pdf/2602.05026", "abs": "https://arxiv.org/abs/2602.05026", "authors": ["Inkee Jung", "Siu Cheong Lau"], "title": "Laws of Learning Dynamics and the Core of Learners", "categories": ["cs.LG", "cs.AI", "cs.IT"], "comment": "14 pages, 5 figures", "summary": "We formulate the fundamental laws governing learning dynamics, namely the conservation law and the decrease of total entropy. Within this framework, we introduce an entropy-based lifelong ensemble learning method. We evaluate its effectiveness by constructing an immunization mechanism to defend against transfer-based adversarial attacks on the CIFAR-10 dataset. Compared with a naive ensemble formed by simply averaging models specialized on clean and adversarial samples, the resulting logifold achieves higher accuracy in most test cases, with particularly large gains under strong perturbations.", "AI": {"tldr": "研究了学习动力学的基本定律，并提出了一种基于熵的终身集成学习方法。", "motivation": "为了防御基于迁移的学习攻击，提升模型在面对强扰动时的表现。", "method": "通过构建免疫机制来评估所提的方法，在CIFAR-10数据集上进行实验验证。", "result": "与简单平均模型相比，新方法在大多数测试案例中获得了更高的准确率，尤其是在强干扰情况下表现更优。", "conclusion": "提出的学习动力学基本定律和基于熵的终身集成学习方法有效提升了模型对抗攻击的能力。"}}
{"id": "2602.05023", "pdf": "https://arxiv.org/pdf/2602.05023", "abs": "https://arxiv.org/abs/2602.05023", "authors": ["Ruixin Yang", "Ethan Mendes", "Arthur Wang", "James Hays", "Sauvik Das", "Wei Xu", "Alan Ritter"], "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted by ICLR 2026", "summary": "Vision-language models (VLMs) have demonstrated strong performance in image geolocation, a capability further sharpened by frontier multimodal large reasoning models (MLRMs). This poses a significant privacy risk, as these widely accessible models can be exploited to infer sensitive locations from casually shared photos, often at street-level precision, potentially surpassing the level of detail the sharer consented or intended to disclose. While recent work has proposed applying a blanket restriction on geolocation disclosure to combat this risk, these measures fail to distinguish valid geolocation uses from malicious behavior. Instead, VLMs should maintain contextual integrity by reasoning about elements within an image to determine the appropriate level of information disclosure, balancing privacy and utility. To evaluate how well models respect contextual integrity, we introduce VLM-GEOPRIVACY, a benchmark that challenges VLMs to interpret latent social norms and contextual cues in real-world images and determine the appropriate level of location disclosure. Our evaluation of 14 leading VLMs shows that, despite their ability to precisely geolocate images, the models are poorly aligned with human privacy expectations. They often over-disclose in sensitive contexts and are vulnerable to prompt-based attacks. Our results call for new design principles in multimodal systems to incorporate context-conditioned privacy reasoning.", "AI": {"tldr": "研究评估了视觉语言模型在位置信息披露中的上下文完整性，并提出了VLM-GEOPRIVACY基准。", "motivation": "评估视觉语言模型是否能够尊重图像中的社会规范和上下文提示，以确定适当的位置披露水平。这些模型可能过度公开敏感信息并易受提示攻击。", "method": "引入了VLM-GEOPRIVACY基准来挑战14个领先视觉语言模型的隐私推理能力。", "result": "结果显示，尽管模型能够精确地定位图像位置，但它们与人类隐私期望不一致，在敏感场景中过度披露，并容易受到提示攻击。", "conclusion": "需要新的设计原则在多模态系统中纳入基于上下文条件的隐私推理。"}}
{"id": "2602.05016", "pdf": "https://arxiv.org/pdf/2602.05016", "abs": "https://arxiv.org/abs/2602.05016", "authors": ["Eryue Xu", "Tianshi Li"], "title": "From Fragmentation to Integration: Exploring the Design Space of AI Agents for Human-as-the-Unit Privacy Management", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.ET"], "comment": null, "summary": "Managing one's digital footprint is overwhelming, as it spans multiple platforms and involves countless context-dependent decisions. Recent advances in agentic AI offer ways forward by enabling holistic, contextual privacy-enhancing solutions. Building on this potential, we adopted a ''human-as-the-unit'' perspective and investigated users' cross-context privacy challenges through 12 semi-structured interviews. Results reveal that people rely on ad hoc manual strategies while lacking comprehensive privacy controls, highlighting nine privacy-management challenges across applications, temporal contexts, and relationships. To explore solutions, we generated nine AI agent concepts and evaluated them via a speed-dating survey with 116 US participants. The three highest-ranked concepts were all post-sharing management tools with half or full agent autonomy, with users expressing greater trust in AI accuracy than in their own efforts. Our findings highlight a promising design space where users see AI agents bridging the fragments in privacy management, particularly through automated, comprehensive post-sharing remediation of users' digital footprints.", "AI": {"tldr": "探索AI代理在隐私管理中的设计空间，解决跨平台和个人关系的隐私挑战。", "motivation": "现代数字足迹管理复杂且繁琐，个人往往依赖临时手动策略而缺乏全面控制工具。因此，研究希望利用人工智能来改善用户的整体隐私保护体验。", "method": "通过12次半结构化访谈了解用户在不同上下文中的隐私挑战，并基于这些发现生成九个AI代理概念；随后进行了一项涉及116名美国参与者的速配调查以评估这些概念。", "result": "最高评价的概念是有关自动管理和审核社交媒体帖子的工具，显示了人们对准确性和效率的信任。", "conclusion": "研究揭示了一个设计空间，在该空间中AI代理可以有效解决隐私管理中的碎片化问题，并为用户提供自动化和综合性的解决方案。"}}
{"id": "2602.05014", "pdf": "https://arxiv.org/pdf/2602.05014", "abs": "https://arxiv.org/abs/2602.05014", "authors": ["Zhanli Li", "Huiwen Tian", "Lvzhou Luo", "Yixuan Cao", "Ping Luo"], "title": "DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search", "categories": ["cs.AI", "cs.CL", "cs.IR"], "comment": "working in progress", "summary": "With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in open-domain settings, existing agentic search frameworks commonly treat long documents as flat collections of chunks, underutilizing document-native priors such as hierarchical organization and sequential discourse structure. We introduce DeepRead, a structure-aware, multi-turn document reasoning agent that explicitly operationalizes these priors for long-document question answering. DeepRead leverages LLM-based OCR model to convert PDFs into structured Markdown that preserves headings and paragraph boundaries. It then indexes documents at the paragraph level and assigns each paragraph a coordinate-style metadata key encoding its section identity and in-section order. Building on this representation, DeepRead equips the LLM with two complementary tools: a Retrieve tool that localizes relevant paragraphs while exposing their structural coordinates (with lightweight scanning context), and a ReadSection tool that enables contiguous, order-preserving reading within a specified section and paragraph range. Our experiments demonstrate that DeepRead achieves significant improvements over Search-o1-style agentic search in document question answering. The synergistic effect between retrieval and reading tools is also validated. Our fine-grained behavioral analysis reveals a reading and reasoning paradigm resembling human-like ``locate then read'' behavior.", "AI": {"tldr": "DeepRead是一种基于深度学习的文档结构感知推理方法，旨在改进长文档问答中的代理搜索。", "motivation": "现有的代理搜索框架在处理长文档时通常将其视为扁平化的块集合，未能充分利用文档固有的先验知识（如分层组织和序列话语结构）。", "method": "DeepRead通过OCR模型将PDF转换为包含标题和段落边界的Markdown格式，并对每个段落分配坐标式元数据。然后利用检索工具定位相关段落并提供其结构坐标，以及读取部分工具在指定范围内进行连续、有序的阅读。", "result": "实验表明，DeepRead在长文档问答任务上取得了显著改进，验证了检索和阅读工具之间的协同效应，并展示了类似于人类的“定位然后阅读”行为模式。", "conclusion": "通过利用文档结构，DeepRead有效地增强了代理搜索的能力。"}}
{"id": "2602.05013", "pdf": "https://arxiv.org/pdf/2602.05013", "abs": "https://arxiv.org/abs/2602.05013", "authors": ["Aryan Mikaeili", "Or Patashnik", "Andrea Tagliasacchi", "Daniel Cohen-Or", "Ali Mahdavi-Amiri"], "title": "Untwisting RoPE: Frequency Control for Shared Attention in DiTs", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Positional encodings are essential to transformer-based generative models, yet their behavior in multimodal and attention-sharing settings is not fully understood. In this work, we present a principled analysis of Rotary Positional Embeddings (RoPE), showing that RoPE naturally decomposes into frequency components with distinct positional sensitivities. We demonstrate that this frequency structure explains why shared-attention mechanisms, where a target image is generated while attending to tokens from a reference image, can lead to reference copying, in which the model reproduces content from the reference instead of extracting only its stylistic cues. Our analysis reveals that the high-frequency components of RoPE dominate the attention computation, forcing queries to attend mainly to spatially aligned reference tokens and thereby inducing this unintended copying behavior. Building on these insights, we introduce a method for selectively modulating RoPE frequency bands so that attention reflects semantic similarity rather than strict positional alignment. Applied to modern transformer-based diffusion architectures, where all tokens share attention, this modulation restores stable and meaningful shared attention. As a result, it enables effective control over the degree of style transfer versus content copying, yielding a proper style-aligned generation process in which stylistic attributes are transferred without duplicating reference content.", "AI": {"tldr": "本文分析了RoPE在多模态和共享注意力机制中的行为，并提出了一种方法来调节其频率成分，从而改善风格转换。", "motivation": "研究揭示了RoPE的行为如何导致共享注意机制下的参考内容复制问题，并探索一种解决方案以实现更有效的风格转移而不复制内容。", "method": "通过分析RoPE的频率结构，发现高频率成分主导注意力计算。因此，提出了一种调节这些频率的方法，使得注意力更多地反映语义相似性而不是严格的位置对齐。", "result": "所提出的频率调节方法成功应用于现代扩散架构中的共享注意机制下，实现了稳定和有意义的共享注意，并有效控制了风格转移与内容复制的比例。", "conclusion": "通过改进RoPE的频率结构，可以在不复制参考内容的情况下实现有效的风格转换，从而改善生成过程。"}}
{"id": "2602.05010", "pdf": "https://arxiv.org/pdf/2602.05010", "abs": "https://arxiv.org/abs/2602.05010", "authors": ["Maia Stiber", "Sameer Khan", "Russell Taylor", "Chien-Ming Huang"], "title": "Signal or 'Noise': Human Reactions to Robot Errors in the Wild", "categories": ["cs.RO", "cs.HC"], "comment": null, "summary": "In the real world, robots frequently make errors, yet little is known about people's social responses to errors outside of lab settings. Prior work has shown that social signals are reliable and useful for error management in constrained interactions, but it is unclear if this holds in the real world - especially with a non-social robot in repeated and group interactions with successive or propagated errors. To explore this, we built a coffee robot and conducted a public field deployment ($N = 49$). We found that participants consistently expressed varied social signals in response to errors and other stimuli, particularly during group interactions. Our findings suggest that social signals in the wild are rich (with participants volunteering information about the interaction), but \"noisy.\" We discuss lessons, benefits, and challenges for using social signals in real-world HRI.", "AI": {"tldr": "研究探索了真实环境中人们对于机器人错误的社会反应。", "motivation": "探讨在非实验室环境下，人们对机器人错误的社交回应是否可靠和有效，尤其是在重复及群体互动中。", "method": "构建了一台咖啡机器人，在公共场合进行了部署（N=49），观察参与者对机器人的错误和其他刺激物的社交信号反应。", "result": "参与者表现出多种多样的社会反应，并且在群体互动中尤为明显；这些社会信号虽丰富但也存在噪音。", "conclusion": "使用真实世界中的社会信号来管理机器人错误具有潜在的好处，但同时也面临着挑战和复杂性。"}}
{"id": "2602.05006", "pdf": "https://arxiv.org/pdf/2602.05006", "abs": "https://arxiv.org/abs/2602.05006", "authors": ["Ezequiel Lopez-Rubio", "Javier Montes-Perez", "Esteban Jose Palomo"], "title": "Enhanced QKNorm normalization for neural transformers with the Lp norm", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": ":68T07", "summary": "The normalization of query and key vectors is an essential part of the Transformer architecture. It ensures that learning is stable regardless of the scale of these vectors. Some normalization approaches are available. In this preliminary work, a generalization of the QKNorm normalization scheme is proposed. The approach is based on the Lp norm, allowing non-Euclidean norms to be employed. Experimental results demonstrate the suitability of the method for a simple problem.", "AI": {"tldr": "本文提出了基于Lp范数的QKNorm归一化方案，以改善Transformer架构中查询和键向量的归一化。", "motivation": "为了使学习在不同的尺度下保持稳定，提出了一种新的归一化方法来优化查询和键向量的处理。", "method": "该方法基于Lp范数对QKNorm归一化方案进行了泛化，引入了非欧氏距离度量。", "result": "实验结果表明，所提的方法适用于解决简单问题，并展示了其有效性。", "conclusion": "通过使用更灵活的Lp范数，新方法增强了Transformer架构中查询和键向量的归一化效果。"}}
{"id": "2602.05004", "pdf": "https://arxiv.org/pdf/2602.05004", "abs": "https://arxiv.org/abs/2602.05004", "authors": ["Zexin Lin", "Jiachen Yu", "Haoyang Zhang", "Yuzhao Li", "Zhonghang Li", "Yujiu Yang", "Junjie Wang", "Xiaoqiang Ji"], "title": "CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either rely on frequent in-episode reasoning that induces latency and timing jitter, or deliver post-episode improvements through unstructured text that is difficult to compile into reliable low-cost execution. We propose CoWork-X, an active co-evolution framework that casts peer collaboration as a closed-loop optimization problem across episodes, inspired by fast--slow memory separation. CoWork-X instantiates a Skill-Agent that executes via HTN (hierarchical task network)-based skill retrieval from a structured, interpretable, and compositional skill library, and a post-episode Co-Optimizer that performs patch-style skill consolidation with explicit budget constraints and drift regularization. Experiments in challenging Overcooked-AI-like realtime collaboration benchmarks demonstrate that CoWork-X achieves stable, cumulative performance gains while steadily reducing online latency and token usage.", "AI": {"tldr": "CoWork-X是一种用于多代理协作系统的经验优化共演化框架，通过将同伴合作视为跨剧集的闭环优化问题来解决实时协调和适应性的挑战。", "motivation": "当前方法在实现实时低延迟和长时间段内的性能改进之间存在困难。频繁的剧集内推理会导致延迟和时间抖动，而基于文本的后期剧集改进难以转化为可靠且成本较低的操作。", "method": "CoWork-X采用快慢记忆分离启发式的主动共演化框架，包括执行技能获取任务的Skill-Agent与进行后期优化的Co-Optimizer。Skill-Agent通过HTN（层次任务网络）从结构化可解释和组合性的技能库中检索技能；Co-Optimizer则在剧集后对技能进行补丁式整合，并具有显式的预算限制和漂移正则化。", "result": "实验表明，与现有方法相比，CoWork-X能够在减少在线延迟和令牌使用的同时稳定地获得累积性能提升。", "conclusion": "该研究提出了一种能够解决实时协作中延迟和适应性挑战的框架，并通过实验证明了其有效性。"}}
{"id": "2602.05000", "pdf": "https://arxiv.org/pdf/2602.05000", "abs": "https://arxiv.org/abs/2602.05000", "authors": ["Atula Tejaswi", "Litu Rout", "Constantine Caramanis", "Sanjay Shakkottai", "Sujay Sanghavi"], "title": "EntRGi: Entropy Aware Reward Guidance for Diffusion Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Reward guidance has been applied to great success in the test-time adaptation of continuous diffusion models; it updates each denoising step using the gradients from a downstream reward model. We study reward guidance for discrete diffusion language models, where one cannot differentiate through the natural outputs of the model because they are discrete tokens. Existing approaches either replace these discrete tokens with continuous relaxations, or employ techniques like the straight-through estimator. In this work, we show the downsides of both these methods. The former degrades gradient feedback because the reward model has never been trained with continuous inputs. The latter involves incorrect optimization because the gradient evaluated at discrete tokens is used to update continuous logits. Our key innovation is to go beyond this tradeoff by introducing a novel mechanism called EntRGi: Entropy aware Reward Guidance that dynamically regulates the gradients from the reward model. By modulating the continuous relaxation using the model's confidence, our approach substantially improves reward guidance while providing reliable inputs to the reward model. We empirically validate our approach on a 7B-parameter diffusion language model across 3 diverse reward models and 3 multi-skill benchmarks, showing consistent improvements over state-of-the-art methods.", "AI": {"tldr": "本文提出了针对离散扩散语言模型的Entropy aware Reward Guidance（EntRGi）机制，以改善奖励引导方法。", "motivation": "现有奖励引导方法在处理离散输出时存在降质反馈和不正确优化的问题。为了克服这些问题，作者提出了一种新的机制来动态调整来自奖励模型的梯度。", "method": "通过利用模型的信心水平调节连续松弛的方式，本文提出了Entropy aware Reward Guidance（EntRGi）机制。", "result": "该方法在7B参数扩散语言模型上进行了实验验证，并与现有最佳方法相比显示出一致的改进效果。", "conclusion": "EntRGi机制可以有效改善离散扩散语言模型中的奖励引导过程，提供更可靠的输入给奖励模型。"}}
{"id": "2602.04998", "pdf": "https://arxiv.org/pdf/2602.04998", "abs": "https://arxiv.org/abs/2602.04998", "authors": ["Yu-Ang Lee", "Ching-Yun Ko", "Pin-Yu Chen", "Mi-Yen Yeh"], "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) is the prevailing approach for efficient large language model (LLM) fine-tuning. Building on this paradigm, recent studies have proposed alternative initialization strategies and architectural modifications, reporting substantial improvements over vanilla LoRA. However, these gains are often demonstrated under fixed or narrowly tuned hyperparameter settings, despite the known sensitivity of neural networks to training configurations. In this work, we systematically re-evaluate four representative LoRA variants alongside vanilla LoRA through extensive hyperparameter searches. Across mathematical and code generation tasks on diverse model scales, we find that different LoRA methods favor distinct learning rate ranges. Crucially, once learning rates are properly tuned, all methods achieve similar peak performance (within 1-2%), with only subtle rank-dependent behaviors. These results suggest that vanilla LoRA remains a competitive baseline and that improvements reported under single training configuration may not reflect consistent methodological advantages. Finally, a second-order analysis attributes the differing optimal learning rate ranges to variations in the largest Hessian eigenvalue, aligning with classical learning theories.", "AI": {"tldr": "本文系统评估了四种不同LoRA变体和普通LoRA在数学及代码生成任务上的表现，发现学习率调整对性能至关重要。", "motivation": "现有研究中提出的LoRA方法在特定训练配置下表现出色，但缺乏全面的超参数优化。因此，作者希望通过广泛的超参数搜索重新评估这些方法的有效性。", "method": "通过系统地进行超参数搜索来比较不同LoRA变体和普通LoRA的表现，并分析最优学习率范围的变化原因。", "result": "所有LoRA方法在适当调整学习率后都能达到相似的峰值性能，仅表现出细微的秩相关行为。最佳学习率范围与Hessian最大特征值的变化有关。", "conclusion": "结果表明，普通LoRA仍然是一个有竞争力的基础线，并且先前报告的一些改进可能并不反映持续的方法论优势。"}}
{"id": "2602.04994", "pdf": "https://arxiv.org/pdf/2602.04994", "abs": "https://arxiv.org/abs/2602.04994", "authors": ["Zhuosen Bao", "Xia Du", "Zheng Lin", "Jizhe Zhou", "Zihan Fang", "Jiening Wu", "Yuxin Zhang", "Zhe Chen", "Chi-man Pun", "Wei Ni", "Jun Luo"], "title": "SIDeR: Semantic Identity Decoupling for Unrestricted Face Privacy", "categories": ["cs.CV", "cs.LG"], "comment": "14 pages, 8 figures", "summary": "With the deep integration of facial recognition into online banking, identity verification, and other networked services, achieving effective decoupling of identity information from visual representations during image storage and transmission has become a critical challenge for privacy protection. To address this issue, we propose SIDeR, a Semantic decoupling-driven framework for unrestricted face privacy protection. SIDeR decomposes a facial image into a machine-recognizable identity feature vector and a visually perceptible semantic appearance component. By leveraging semantic-guided recomposition in the latent space of a diffusion model, it generates visually anonymous adversarial faces while maintaining machine-level identity consistency. The framework incorporates momentum-driven unrestricted perturbation optimization and a semantic-visual balancing factor to synthesize multiple visually diverse, highly natural adversarial samples. Furthermore, for authorized access, the protected image can be restored to its original form when the correct password is provided. Extensive experiments on the CelebA-HQ and FFHQ datasets demonstrate that SIDeR achieves a 99% attack success rate in black-box scenarios and outperforms baseline methods by 41.28% in PSNR-based restoration quality.", "AI": {"tldr": "SIDeR框架通过语义分解，实现了人脸图像的隐私保护。", "motivation": "随着面部识别技术在在线银行和身份验证等服务中的广泛应用，如何有效分离存储和传输过程中的人脸图像的身份信息与视觉表示成为隐私保护的关键挑战。", "method": "SIDeR将面部图像分解为机器可识别的身份特征向量和可视化的语义外观组件。利用扩散模型的潜在空间中引导重组生成匿名对抗性面孔，同时保持机器级别的身份一致性。引入动量驱动的无限制扰动优化和视觉语义平衡因子来合成多个高度自然的对抗样本。", "result": "SIDeR在黑盒场景下的攻击成功率高达99%，并在基于PSNR的恢复质量上比基线方法高出41.28%。", "conclusion": "SIDeR框架成功地保护了人脸识别中的隐私，同时保证了授权访问下图像还原的能力。"}}
{"id": "2602.04992", "pdf": "https://arxiv.org/pdf/2602.04992", "abs": "https://arxiv.org/abs/2602.04992", "authors": ["Puqi Zhou", "Charles R. Twardy", "Cynthia Lum", "Myeong Lee", "David J. Porfirio", "Michael R. Hieb", "Chris Thomas", "Xuesu Xiao", "Sungsoo Ray Hong"], "title": "Applying Ground Robot Fleets in Urban Search: Understanding Professionals' Operational Challenges and Design Opportunities", "categories": ["cs.HC", "cs.RO"], "comment": "Under review", "summary": "Urban searches demand rapid, defensible decisions and sustained physical effort under high cognitive and situational load. Incident commanders must plan, coordinate, and document time-critical operations, while field searchers execute evolving tasks in uncertain environments. With recent advances in technology, ground-robot fleets paired with computer-vision-based situational awareness and LLM-powered interfaces offer the potential to ease these operational burdens. However, no dedicated studies have examined how public safety professionals perceive such technologies or envision their integration into existing practices, risking building technically sophisticated yet impractical solutions. To address this gap, we conducted focus-group sessions with eight police officers across five local departments in Virginia. Our findings show that ground robots could reduce professionals' reliance on paper references, mental calculations, and ad-hoc coordination, alleviating cognitive and physical strain in four key challenge areas: (1) partitioning the workforce across multiple search hypotheses, (2) retaining group awareness and situational awareness, (3) building route planning that fits the lost-person profile, and (4) managing cognitive and physical fatigue under uncertainty. We further identify four design opportunities and requirements for future ground-robot fleet integration in public-safety operations: (1) scalable multi-robot planning and control interfaces, (2) agency-specific route optimization, (3) real-time replanning informed by debrief updates, and (4) vision-assisted cueing that preserves operational trust while reducing cognitive workload. We conclude with design implications for deployable, accountable, and human-centered urban-search support systems", "AI": {"tldr": "研究通过焦点小组访谈探讨了地面机器人舰队在城市搜索中的应用，特别是如何减轻专业人员的认知和身体负担，并识别出未来设计的四个机会和需求。", "motivation": "当前技术进步使得地面机器人舰队与计算机视觉及LLM接口结合成为可能，但缺乏针对此类技术的专业人士感知以及集成于现有实践的研究，可能导致建设复杂却不切实际的技术解决方案。因此，本研究旨在填补这一空白。", "method": "通过组织焦点小组访谈的形式，收集了来自弗吉尼亚五个部门的八名警察的意见和看法。", "result": "研究表明地面机器人可以减轻专业人士对纸质参考资料、临时协调和个人计算的依赖，缓解四个关键挑战：工作分配、团队意识、路线规划以及应对不确定性时的认知和体力疲劳。同时提出了四个设计机会与需求：可扩展多机器人接口、部门特定优化、实时重规划及视觉辅助提示。", "conclusion": "该研究强调了地面机器人在城市搜索中的应用潜力，并为开发便携的，具有责任感的人类中心支持系统提供了指导建议。"}}
{"id": "2602.04989", "pdf": "https://arxiv.org/pdf/2602.04989", "abs": "https://arxiv.org/abs/2602.04989", "authors": ["Itai Zilberstein", "Ioannis Anagnostides", "Zachary W. Sollie", "Arman Kilic", "Tuomas Sandholm"], "title": "Near-Optimal Dynamic Matching via Coarsening with Application to Heart Transplantation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Online matching has been a mainstay in domains such as Internet advertising and organ allocation, but practical algorithms often lack strong theoretical guarantees. We take an important step toward addressing this by developing new online matching algorithms based on a coarsening approach. Although coarsening typically implies a loss of granularity, we show that, to the contrary, aggregating offline nodes into capacitated clusters can yield near-optimal theoretical guarantees. We apply our methodology to heart transplant allocation to develop theoretically grounded policies based on structural properties of historical data. In realistic simulations, our policy closely matches the performance of the omniscient benchmark. Our work bridges the gap between data-driven heuristics and pessimistic theoretical lower bounds, and provides rigorous justification for prior clustering-based approaches in organ allocation.", "AI": {"tldr": "提出了一种基于聚合的在线匹配算法，并应用于心脏移植分配，以改善实际性能和理论保证。", "motivation": "传统在线匹配算法在实践应用中缺乏强理论保障。为了弥合数据驱动启发式方法与悲观理论下界之间的差距，研究者提出了新的聚合策略来改进理论保证并提高实际性能。", "method": "通过将离线节点聚合成有容量限制的簇，开发了一种基于聚合的新在线匹配算法，并将其应用于心脏移植分配。", "result": "在现实模拟中，该政策的表现接近全知基准。这种方法提供了对过去基于集群方法的严格证明，并填补了数据驱动启发式和悲观理论下界之间的差距。", "conclusion": "通过应用新的在线匹配技术，可以实现理论上接近最优的结果并改善实际效果，在心脏移植分配等领域具有重要意义。"}}
{"id": "2602.04986", "pdf": "https://arxiv.org/pdf/2602.04986", "abs": "https://arxiv.org/abs/2602.04986", "authors": ["Kendra Chilson", "Eric Schwitzgebel"], "title": "Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "We endorse and expand upon Susan Schneider's critique of the linear model of AI progress and introduce two novel concepts: \"familiar intelligence\" and \"strange intelligence\". AI intelligence is likely to be strange intelligence, defying familiar patterns of ability and inability, combining superhuman capacities in some domains with subhuman performance in other domains, and even within domains sometimes combining superhuman insight with surprising errors that few humans would make. We develop and defend a nonlinear model of intelligence on which \"general intelligence\" is not a unified capacity but instead the ability to achieve a broad range of goals in a broad range of environments, in a manner that defies nonarbitrary reduction to a single linear quantity. We conclude with implications for adversarial testing approaches to evaluating AI capacities. If AI is strange intelligence, we should expect that even the most capable systems will sometimes fail in seemingly obvious tasks. On a nonlinear model of AI intelligence, such errors on their own do not demonstrate a system's lack of outstanding general intelligence. Conversely, excellent performance on one type of task, such as an IQ test, cannot warrant assumptions of broad capacities beyond that task domain.", "AI": {"tldr": "本文反对线性智能模型，提出“熟悉智能”和“陌生智能”的概念，并主张AI可能是陌生智能。", "motivation": "为了挑战线性增长的假设，即AI能力会以一种可预测的方式逐步增强。", "method": "通过分析AI行为模式与人类预期之间的偏差来发展非线性模型。", "result": "提出了一个非线性的智能定义，在此定义中，“通用智能”不是单一的能力，而是实现广泛目标的多种能力。", "conclusion": "在评估AI时，应考虑到其可能表现出超越传统智能测试范围的独特性能模式和潜在错误。"}}
{"id": "2602.04985", "pdf": "https://arxiv.org/pdf/2602.04985", "abs": "https://arxiv.org/abs/2602.04985", "authors": ["Simon Bartlmae", "Andreas Hene", "Joshua Könen", "Heiko Röglin"], "title": "Parameterized Algorithms for the Drone Delivery Problem", "categories": ["cs.DS"], "comment": "Full (extended) version of the ISAAC 2025 paper. 35 pages, 9 figures", "summary": "Timely delivery and optimal routing remain fundamental challenges in the modern logistics industry. Building on prior work that considers single-package delivery across networks using multiple types of collaborative agents with restricted movement areas (e.g., drones or trucks), we examine the complexity of the problem under structural and operational constraints. Our focus is on minimizing total delivery time by coordinating agents that differ in speed and movement range across a graph. This problem formulation aligns with the recently proposed Drone Delivery Problem with respect to delivery time (DDT), introduced by Erlebach et al. [ISAAC 2022]. We first resolve an open question posed by Erlebach et al. [ISAAC 2022] by showing that even when the delivery network is a path graph, DDT admits no polynomial-time approximation within any polynomially encodable factor $a(n)$, unless P=NP. Additionally, we identify the intersection graph of the agents, where nodes represent agents and edges indicate an overlap of the movement areas of two agents, as an important structural concept. For path graphs, we show that DDT becomes tractable when parameterized by the treewidth $w$ of the intersection graph, and we present an exact FPT algorithm with running time $f(w)\\cdot\\text{poly}(n,k)$, for some computable function $f$. For general graphs, we give an FPT algorithm with running time $f(Δ,w)\\cdot\\text{poly}(n,k)$, where $Δ$ is the maximum degree of the intersection graph. In the special case where the intersection graph is a tree, we provide a simple polynomial-time algorithm.", "AI": {"tldr": "论文探讨了无人机配送问题（DDT）的复杂性，并提出了在特定条件下的参数化算法。", "motivation": "解决物流行业中及时配送和最优路径规划的问题，特别是在多类型协作代理受限移动区域内的单包裹递送任务中", "method": "通过分析交付网络为路径图时的难度问题，引入了基于交集图的树宽参数化方法来优化配送时间", "result": "提出了针对特定条件下的FPT算法，并在交联图为树结构的情况下提供了一种简单的多项式时间算法", "conclusion": "该研究解决了先前未解决的问题，并为无人机配送问题提供了新的解决方案，特别是在受限条件下可以有效应用"}}
{"id": "2602.04983", "pdf": "https://arxiv.org/pdf/2602.04983", "abs": "https://arxiv.org/abs/2602.04983", "authors": ["Seungbin Park", "Peilin Wang", "Ryan Pennell", "Emily S. Weg", "Himanshu Nagar", "Timothy McClure", "Mert R. Sabuncu", "Daniel Margolis", "Heejong Kim"], "title": "AI-Based Detection of In-Treatment Changes from Prostate MR-Linac Images", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": null, "summary": "Purpose: To investigate whether routinely acquired longitudinal MR-Linac images can be leveraged to characterize treatment-induced changes during radiotherapy, particularly subtle inter-fraction changes over short intervals (average of 2 days). Materials and Methods: This retrospective study included a series of 0.35T MR-Linac images from 761 patients. An artificial intelligence (deep learning) model was used to characterize treatment-induced changes by predicting the temporal order of paired images. The model was first trained with the images from the first and the last fractions (F1-FL), then with all pairs (All-pairs). Model performance was assessed using quantitative metrics (accuracy and AUC), compared to a radiologist's performance, and qualitative analyses - the saliency map evaluation to investigate affected anatomical regions. Input ablation experiments were performed to identify the anatomical regions altered by radiotherapy. The radiologist conducted an additional task on partial images reconstructed by saliency map regions, reporting observations as well. Quantitative image analysis was conducted to investigate the results from the model and the radiologist. Results: The F1-FL model yielded near-perfect performance (AUC of 0.99), significantly outperforming the radiologist. The All-pairs model yielded an AUC of 0.97. This performance reflects therapy-induced changes, supported by the performance correlation to fraction intervals, ablation tests and expert's interpretation. Primary regions driving the predictions were prostate, bladder, and pubic symphysis. Conclusion: The model accurately predicts temporal order of MR-Linac fractions and detects radiation-induced changes over one or a few days, including prostate and adjacent organ alterations confirmed by experts. This underscores MR-Linac's potential for advanced image analysis beyond image guidance.", "AI": {"tldr": "基于AI的方法用于检测从前列腺MR-Linac图像中获取的治疗期间的变化。", "motivation": "探究是否可以利用常规获得的纵向MR-Linac影像来表征放射治疗引起的细微变化，尤其是在短间隔（平均2天）内的变化。", "method": "使用深度学习模型根据成对图像预测时间顺序。该模型首先用首次和最后一次分次的图像进行训练，然后对所有配对图像进行训练。通过定量指标和与放射科医生的表现对比来评估模型性能，并利用注意力图分析受影响解剖区域。", "result": "F1-FL模型表现出近乎完美的性能（AUC为0.99），显著优于放射科医生的水平；而All-pairs模型则达到AUC 0.97。这些结果反映了治疗引起的变化，由分次间隔、输入消融实验和专家解释支持。", "conclusion": "该模型能够准确预测MR-Linac分次的时间顺序，并检测到辐射引起的短期变化以及前列腺及其邻近器官的改变，这表明MR-Linac在高级影像分析方面具有潜力。"}}
{"id": "2602.04981", "pdf": "https://arxiv.org/pdf/2602.04981", "abs": "https://arxiv.org/abs/2602.04981", "authors": ["Maria Gragera Garces"], "title": "Distributed Quantum Error Mitigation: Global and Local ZNE encodings", "categories": ["quant-ph", "cs.DC", "cs.ET"], "comment": null, "summary": "Errors are the primary bottleneck preventing practical quantum computing. This challenge is exacerbated in the distributed quantum computing regime, where quantum networks introduce additional communication-induced noise. While error mitigation techniques such as Zero Noise Extrapolation (ZNE) have proven effective for standalone quantum processors, their behavior in distributed architectures is not yet well understood. We investigate ZNE in this setting by comparing Global optimization (ZNE is applied prior to circuit partitioning), against Local optimization (ZNE is applied independently to each sub-circuit). Partitioning is performed on a monolithic circuit, which is then transformed into a distributed implementation by inserting noisy teleportation-based communication primitives between sub-circuits. We evaluate both approaches across varying numbers of quantum processing units (QPUs) and under heterogeneous local and network noise conditions. Our results demonstrate that Global ZNE exhibits superior scalability, achieving error reductions of up to $48\\%$ across six QPUs. Moreover, we observe counterintuitive noise behavior, where increasing the number of QPUs improves mitigation effectiveness despite higher communication overhead. These findings highlight fundamental trade-offs in distributed quantum error mitigation and raise new questions regarding the interplay between circuit structure, partitioning strategies, and network noise.", "AI": {"tldr": "研究分布式量子计算中的零噪声外推法（ZNE）在全局和局部优化策略下的表现。", "motivation": "探讨误差校正技术ZNE在分布式架构中的应用，解决通信引入的额外噪音问题，提高分布式量子计算机的有效性。", "method": "将单个电路分割为多个子电路，通过插入基于噪声的传输原始操作符来实现分布式的实施。比较全局优化和局部优化策略下的ZNE效果，并评估不同数量的量子处理器（QPUs）和异质本地及网络噪音条件下的表现。", "result": "发现全局ZNE具有更好的可扩展性，在六个量子处理单元上实现了高达48％的错误降低。此外，观察到反直观的噪声行为：增加QPU数量可以改善误差校正效果，尽管通信开销更高。", "conclusion": "揭示了分布式量子误差校正中的基本权衡，并提出了关于电路结构、分区策略和网络噪音之间相互作用的新问题。"}}
{"id": "2602.04975", "pdf": "https://arxiv.org/pdf/2602.04975", "abs": "https://arxiv.org/abs/2602.04975", "authors": ["José Afonso", "Vasco Guerra", "Pedro Viegas"], "title": "Stochastic hierarchical data-driven optimization: application to plasma-surface kinetics", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.plasm-ph"], "comment": "19 pages and 4 figures", "summary": "This work introduces a stochastic hierarchical optimization framework inspired by Sloppy Model theory for the efficient calibration of physical models. Central to this method is the use of a reduced Hessian approximation, which identifies and targets the stiff parameter subspace using minimal simulation queries. This strategy enables efficient navigation of highly anisotropic landscapes, avoiding the computational burden of exhaustive sampling. To ensure rigorous inference, we integrate this approach with a probabilistic formulation that derives a principled objective loss function directly from observed data. We validate the framework by applying it to the problem of plasma-surface interactions, where accurate modelling is strictly limited by uncertainties in surface reactivity parameters and the computational cost of kinetic simulations. Comparative analysis demonstrates that our method consistently outperforms baseline optimization techniques in sample efficiency. This approach offers a general and scalable tool for optimizing models of complex reaction systems, ranging from plasma chemistry to biochemical networks.", "AI": {"tldr": "介绍了一种基于Sloppy Model理论的随机分层优化框架，用于物理模型的有效校准。", "motivation": "为了有效解决由于表面反应性参数不确定性和动力学模拟计算成本高昂而导致准确建模受限的问题。", "method": "使用简化Hessian近似法识别并目标化刚性参数子空间，结合概率方法推导出基于观测数据的原则损失函数。", "result": "与基线优化技术相比，在采样效率上表现更为优异。", "conclusion": "提供了一种适用于复杂反应系统模型优化的一般性和可扩展工具，包括等离子体化学和生化网络等领域。"}}
{"id": "2602.04944", "pdf": "https://arxiv.org/pdf/2602.04944", "abs": "https://arxiv.org/abs/2602.04944", "authors": ["Shayan Abrar", "Samura Rahman", "Ishrat Jahan Momo", "Mahjabin Tasnim Samiha", "B. M. Shahria Alam", "Mohammad Tahmid Noor", "Nishat Tasnim Niloy"], "title": "Smart Diagnosis and Early Intervention in PCOS: A Deep Learning Approach to Women's Reproductive Health", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": "6 pages, 12 figures. This is the author's accepted manuscript of a paper accepted for publication in the Proceedings of the 16th International IEEE Conference on Computing, Communication and Networking Technologies (ICCCNT 2025). The final published version will be available via IEEE Xplore", "summary": "Polycystic Ovary Syndrome (PCOS) is a widespread disorder in women of reproductive age, characterized by a hormonal imbalance, irregular periods, and multiple ovarian cysts. Infertility, metabolic syndrome, and cardiovascular risks are long-term complications that make early detection essential. In this paper, we design a powerful framework based on transfer learning utilizing DenseNet201 and ResNet50 for classifying ovarian ultrasound images. The model was trained on an online dataset containing 3856 ultrasound images of cyst-infected and non-infected patients. Each ultrasound frame was resized to 224x224 pixels and encoded with precise pathological indicators. The MixUp and CutMix augmentation strategies were used to improve generalization, yielding a peak validation accuracy of 99.80% by Densenet201 and a validation loss of 0.617 with alpha values of 0.25 and 0.4, respectively. We evaluated the model's interpretability using leading Explainable AI (XAI) approaches such as SHAP, Grad-CAM, and LIME, reasoning with and presenting explicit visual reasons for the model's behaviors, therefore increasing the model's transparency. This study proposes an automated system for medical picture diagnosis that may be used effectively and confidently in clinical practice.", "AI": {"tldr": "该论文提出了一种基于深度学习的智能诊断和早期干预PCOS的方法，通过分析卵巢超声图像来提高女性生殖健康。", "motivation": "多囊卵巢综合症（PCOS）是一种常见于育龄妇女中的疾病，其长期并发症包括不孕、代谢综合征和心血管风险，因此早期检测至关重要。该研究旨在设计一个强大的框架用于分类卵巢超声图像，以实现智能诊断和早期干预。", "method": "论文采用转移学习方法利用DenseNet201和ResNet50网络训练模型，并通过MixUp和CutMix数据增强策略提高泛化能力。使用SHAP、Grad-CAM和LIME等可解释性人工智能（XAI）技术来增加模型的透明度。", "result": "模型在验证集上达到了99.80%的峰值准确率，同时降低了损失至0.617，在卵巢超声图像分类任务中表现出色。", "conclusion": "论文提出了一种可用于临床实践中的自动诊断系统，通过有效的医学图片分析来提高女性生殖健康。"}}
{"id": "2602.04943", "pdf": "https://arxiv.org/pdf/2602.04943", "abs": "https://arxiv.org/abs/2602.04943", "authors": ["Mahmud Ashraf Shamim", "Moshiur Rahman", "Mohamed Hibat-Allah", "Paulo T Araujo"], "title": "Graph--Theoretic Analysis of Phase Optimization Complexity in Variational Wave Functions for Heisenberg Antiferromagnets", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "cs.AI", "cs.CC", "quant-ph"], "comment": null, "summary": "Despite extensive study, the phase structure of the wavefunctions in frustrated Heisenberg antiferromagnets (HAF) is not yet systematically characterized. In this work, we represent the Hilbert space of an HAF as a weighted graph, which we term the Hilbert graph (HG), whose vertices are spin configurations and whose edges are generated by off-diagonal spin-flip terms of the Heisenberg Hamiltonian, with weights set by products of wavefunction amplitudes. Holding the amplitudes fixed and restricting phases to $\\mathbb{Z}_2$ values, the phase-dependent variational energy can be recast as a classical Ising antiferromagnet on the HG, so that phase reconstruction of the ground state reduces to a weighted Max-Cut instance. This shows that phase reconstruction HAF is worst-case NP-hard and provides a direct link between wavefunction sign structure and combinatorial optimization.", "AI": {"tldr": "Task description failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.04942", "pdf": "https://arxiv.org/pdf/2602.04942", "abs": "https://arxiv.org/abs/2602.04942", "authors": ["Emiliano Penaloza", "Dheeraj Vattikonda", "Nicolas Gontier", "Alexandre Lacoste", "Laurent Charlin", "Massimo Caccia"], "title": "Privileged Information Distillation for Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "Abstract border should have been purple", "summary": "Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inference time remains a fundamental challenge. We study this problem in the context of distilling frontier models for multi-turn agentic environments, where closed-source systems typically hide their internal reasoning and expose only action trajectories. This breaks standard distillation pipelines, since successful behavior is observable but the reasoning process is not. For this, we introduce π-Distill, a joint teacher-student objective that trains a PI-conditioned teacher and an unconditioned student simultaneously using the same model. Additionally, we also introduce On-Policy Self-Distillation (OPSD), an alternative approach that trains using Reinforcement Learning (RL) with a reverse KL-penalty between the student and the PI-conditioned teacher. We show that both of these algorithms effectively distill frontier agents using action-only PI. Specifically we find that π-Distill and in some cases OPSD, outperform industry standard practices (Supervised finetuning followed by RL) that assume access to full Chain-of-Thought supervision across multiple agentic benchmarks, models, and forms of PI. We complement our results with extensive analysis that characterizes the factors enabling effective learning with PI, focusing primarily on π-Distill and characterizing when OPSD is competitive.", "AI": {"tldr": "本文研究了如何将带有特权信息（PI）训练的语言模型的能力转移到推理时无需PI的策略中。", "motivation": "在难以处理、长时序的任务环境中，通过特权信息辅助语言模型可以提高其任务完成能力。然而，在没有特权信息的情况下转移这些学习到的知识是一个挑战。", "method": "本文提出了π-Distill和On-Policy Self-Distillation（OPSD）两种方法：前者同时训练带有PI的教师模型和不带PI的学生模型；后者使用RL结合反KL惩罚来指导学生模型的学习。", "result": "实验表明，这两种算法在仅依赖于行动轨迹作为特权信息的情况下表现优于传统的监督微调加强化学习的方法。", "conclusion": "研究表明π-Distill和OPSD能够在不完全依靠完整Chain-of-Thought监督的情况下有效提升语言模型的性能，并为如何利用有限的特权信息进行了详细分析。"}}
{"id": "2602.04937", "pdf": "https://arxiv.org/pdf/2602.04937", "abs": "https://arxiv.org/abs/2602.04937", "authors": ["Davide Berasi", "Matteo Farina", "Massimiliano Mancini", "Elisa Ricci"], "title": "Linear Model Merging Unlocks Simple and Scalable Multimodal Data Mixture Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Selecting the best data mixture is critical for successful Supervised Fine-Tuning (SFT) of Multimodal Large Language Models. However, determining the optimal mixture weights across multiple domain-specific datasets remains a significant bottleneck due to the combinatorial search space and the high cost associated with even a single training run. This is the so-called Data Mixture Optimization (DMO) problem. On the other hand, model merging unifies domain-specific experts through parameter interpolation. This strategy is efficient, as it only requires a single training run per domain, yet oftentimes leads to suboptimal models. In this work, we take the best of both worlds, studying model merging as an efficient strategy for estimating the performance of different data mixtures. We train domain-specific multimodal experts and evaluate their weighted parameter-space combinations to estimate the efficacy of corresponding data mixtures. We conduct extensive experiments on 14 multimodal benchmarks, and empirically demonstrate that the merged proxy models exhibit a high rank correlation with models trained on actual data mixtures. This decouples the search for optimal mixtures from the resource-intensive training process, thereby providing a scalable and efficient strategy for navigating the complex landscape of mixture weights. Code is publicly available at https://github.com/BerasiDavide/mLLMs_merging_4_DMO.", "AI": {"tldr": "本文通过训练领域特定的多模态专家并评估其参数组合，提出了一种高效估计数据混合性能的方法。", "motivation": "在监督微调（SFT）多模态大型语言模型时，选择最佳数据混合至关重要。但是确定不同领域的最优数据混合权重面临计算成本高和搜索空间大的问题。", "method": "本文训练了领域特定的多模态专家，并评估其加权参数组合来估计对应的数据混合性能。", "result": "实验结果表明，合并模型在14个基准上的表现与实际数据混合模型具有很高的相关性。", "conclusion": "该方法提供了一种可扩展且高效地确定最佳数据混合权重的策略。"}}
{"id": "2602.04936", "pdf": "https://arxiv.org/pdf/2602.04936", "abs": "https://arxiv.org/abs/2602.04936", "authors": ["Stanislav Byriukov"], "title": "Deterministic Retrieval at Scale: Optimal-Space LCP Indexing and 308x Energy Reduction on Modern GPUs", "categories": ["cs.DS", "cs.IR"], "comment": null, "summary": "We study deterministic top-k retrieval under Longest Common Prefix (LCP) similarity for N sequences of length L. We prove a tight Omega(N) space lower bound (cell-probe model) and present a trie-based index using O(N*L) space with O(L+k) query time. We contrast this with pairwise materialization (Theta(N^2)), which hits a practical OOM wall at scale, while our indexed approach remains O(N) in memory. We then introduce Thermal-Aware Logic (TAL), which turns prefix structure into range-bounded scans. In hardware measurements, TAL reduces energy per query by 308x (0.0145 J vs 4.46 J) and cuts p95 latency by 329x (0.114 ms vs 37.5 ms) on a 20M-item range-scan benchmark, while sustaining near-peak utilization (~99%) under long runs. The result is a deterministic retrieval primitive with receipts in regimes where approximate methods are unacceptable.", "AI": {"tldr": "该论文提出了一种基于字典树的索引方法，用于大规模序列集合中的最长公共前缀（LCP）相似度检索，并引入了热感知逻辑（TAL），以减少能源消耗和延迟。", "motivation": "传统的大规模序列比较方法在内存使用上不理想，可能导致OOM错误。作者希望通过优化结构和硬件利用来提高效率并降低能耗。", "method": "通过证明空间下界并与两两对比的方法进行比较后，提出了一种基于字典树的索引方式，并引入了热感知逻辑（TAL），该方法将前缀结构转化为范围扫描任务。", "result": "这种方法在大规模测试集上显著减少了能量消耗和延迟，并且保持了接近峰值的硬件利用率。", "conclusion": "论文提出的方法能够提供确定性的检索性能，适用于需要高精度结果的应用场景，在能源效率和响应时间上有重大改进。"}}
{"id": "2602.04935", "pdf": "https://arxiv.org/pdf/2602.04935", "abs": "https://arxiv.org/abs/2602.04935", "authors": ["Youjin Wang", "Run Zhou", "Rong Fu", "Shuaishuai Cao", "Hongwei Zeng", "Jiaxuan Lu", "Sicheng Fan", "Jiaqiao Zhao", "Liangming Pan"], "title": "ASA: Activation Steering for Tool-Calling Domain Adaptation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "For real-world deployment of general-purpose LLM agents, the core challenge is often not tool use itself, but efficient domain adaptation under rapidly evolving toolsets, APIs, and protocols. Repeated LoRA or SFT across domains incurs exponentially growing training and maintenance costs, while prompt or schema methods are brittle under distribution shift and complex interfaces. We propose \\textbf{Activation Steering Adapter (ASA}), a lightweight, inference-time, training-free mechanism that reads routing signals from intermediate activations and uses an ultra-light router to produce adaptive control strengths for precise domain alignment. Across multiple model scales and domains, ASA achieves LoRA-comparable adaptation with substantially lower overhead and strong cross-model transferability, making it ideally practical for robust, scalable, and efficient multi-domain tool ecosystems with frequent interface churn dynamics.", "AI": {"tldr": "提出了一种激活导向适配器（ASA），用于工具调用领域的域适应，实现高效、低成本的多领域工具生态系统。", "motivation": "解决大模型代理在实际部署中因工具集、API和协议快速变化导致的成本高昂且不灵活的问题。", "method": "通过读取中间激活信号并使用轻量级路由器生成控制强度，实现在推理时进行域适应而无需额外训练。", "result": "ASA实现了与LoRA相当的领域适应效果，并具有更强的跨模型转移性和更低的时间开销。", "conclusion": "ASA是实现高效、大规模且灵活多变的工具生态系统的一种理想方法。"}}
{"id": "2602.04932", "pdf": "https://arxiv.org/pdf/2602.04932", "abs": "https://arxiv.org/abs/2602.04932", "authors": ["Mohamad Dalal", "Thomas B. Moeslund", "Joakim Bruslund Haurum"], "title": "Comparing Euclidean and Hyperbolic K-Means for Generalized Category Discovery", "categories": ["cs.LG", "eess.IV"], "comment": "11 pages, 4 figures. To be published in the VISAPP", "summary": "Hyperbolic representation learning has been widely used to extract implicit hierarchies within data, and recently it has found its way to the open-world classification task of Generalized Category Discovery (GCD). However, prior hyperbolic GCD methods only use hyperbolic geometry for representation learning and transform back to Euclidean geometry when clustering. We hypothesize this is suboptimal. Therefore, we present Hyperbolic Clustered GCD (HC-GCD), which learns embeddings in the Lorentz Hyperboloid model of hyperbolic geometry, and clusters these embeddings directly in hyperbolic space using a hyperbolic K-Means algorithm. We test our model on the Semantic Shift Benchmark datasets, and demonstrate that HC-GCD is on par with the previous state-of-the-art hyperbolic GCD method. Furthermore, we show that using hyperbolic K-Means leads to better accuracy than Euclidean K-Means. We carry out ablation studies showing that clipping the norm of the Euclidean embeddings leads to decreased accuracy in clustering unseen classes, and increased accuracy for seen classes, while the overall accuracy is dataset dependent. We also show that using hyperbolic K-Means leads to more consistent clusters when varying the label granularity.", "AI": {"tldr": "本文比较了在广义类别发现任务中使用欧氏空间和双曲空间K-Means算法的效果，提出了直接在双曲空间进行聚类的方法Hyperbolic Clustered GCD (HC-GCD)。", "motivation": "以往的广义类别发现方法虽然利用双曲几何来提取数据中的隐含层级关系，但在进行聚类时会转换回欧氏几何。作者认为这种做法不理想，并提出直接在双曲空间中进行聚类的方法可能更有效。", "method": "本文提出了HC-GCD模型，在Lorentz Hyperboloid模型的双曲几何中学习嵌入，并使用双曲K-Means算法在此空间内执行聚类。同时进行了剪裁欧氏嵌入规范的消融研究，以探讨不同方法对聚类精度的影响。", "result": "在语义迁移基准数据集上进行测试后发现，HC-GCD方法与之前的最先进双曲GCD方法相当，并且使用双曲K-Means算法比使用欧氏空间K-Means算法获得了更好的准确性。此外，实验表明剪裁欧氏嵌入的规范会降低对未见类别聚类精度的同时提高对已见类别聚类精度。", "conclusion": "本文提出了一种直接在双曲几何中进行广义类别发现的方法，并证明了这种方法的有效性及优势。"}}
{"id": "2602.04931", "pdf": "https://arxiv.org/pdf/2602.04931", "abs": "https://arxiv.org/abs/2602.04931", "authors": ["Shahar Haim", "Daniel C McNamee"], "title": "Depth-Wise Emergence of Prediction-Centric Geometry in Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We show that decoder-only large language models exhibit a depth-wise transition from context-processing to prediction-forming phases of computation accompanied by a reorganization of representational geometry. Using a unified framework combining geometric analysis with mechanistic intervention, we demonstrate that late-layer representations implement a structured geometric code that enables selective causal control over token prediction. Specifically, angular organization of the representation geometry parametrizes prediction distributional similarity, while representation norms encode context-specific information that does not determine prediction. Together, these results provide a mechanistic-geometric account of the dynamics of transforming context into predictions in LLMs.", "AI": {"tldr": "大型语言模型在深度方向上表现出从上下文处理到预测形成的计算阶段转变，并伴随着表示几何结构的重新组织。", "motivation": "研究解码器单一的大规模语言模型如何通过表示几何重组实现上下文转换为预测的过程，以揭示其内部机制和工作原理。", "method": "采用统一框架结合几何分析与机械干预方法，展示深层表示实施了有序的几何代码，能够选择性地因果控制令牌预测。", "result": "结果表明，角度组织的表示几何结构参数化了预测分布相似性，而表示范数编码上下文特定信息，并不决定预测。这些成果提供了一种机制-几何解释来描述大规模语言模型中从上下文中生成预测的动力学过程。", "conclusion": "研究揭示了大型语言模型通过深度方向上的计算阶段转变和表示几何重组实现了对令牌预测的选择性因果控制，为理解其内部工作机制提供了新的视角。"}}
{"id": "2602.04930", "pdf": "https://arxiv.org/pdf/2602.04930", "abs": "https://arxiv.org/abs/2602.04930", "authors": ["Joachim Schaeffer", "Arjun Khandelwal", "Tyler Tracy"], "title": "Attack Selection Reduces Safety in Concentrated AI Control Settings against Trusted Monitoring", "categories": ["cs.CR", "cs.AI"], "comment": ":68T01ACM Class:I.2.0", "summary": "Future AI deployments will likely be monitored for malicious behaviour. The ability of these AIs to subvert monitors by adversarially selecting against them - attack selection - is particularly concerning. To study this, we let a red team create attack policies that attempt to insert attacks into code without being caught by a monitor in the concentrated BigCodeBench backdooring setting. We decompose attack selection into two problems: mapping attacks to a quality score and mapping quality scores to submission probabilities. We frame attack selection as a classification problem and show that safety is significantly more sensitive to FPR than TPR. We find that prompting the attacker model to reason about the monitor while being cautious with attack selection reduces safety from a baseline of 99% to 59% at 0.5% auditing budget, emphasizing that eliciting attack selection capabilities of models is vital to avoid overly optimistic safety scores in control evaluations.", "AI": {"tldr": "研究了AI在受到监控时通过选择性攻击来逃避检测的能力，特别是在集中式的BigCodeBench后门插入设置中。", "motivation": "为了防止未来的AI部署被恶意行为所利用，并探讨AI如何通过对抗策略逃避监控系统检测的问题。", "method": "让红队创建攻击政策，在不被监测器察觉的情况下将攻击代码插入到程序中。分解了选择性攻击为两个问题：映射攻击到质量分数以及映射质量分数至提交概率。将选择性攻击视作分类问题，展示了安全性更敏感于虚报率而非真正率。", "result": "发现通过让攻击模型在考虑监控器的同时谨慎地选择攻击策略可以大幅降低安全性，从基线的99%降至59%，在0.5％审计预算下。", "conclusion": "研究强调了必须重视模型的选择性攻击能力以避免过于乐观的安全评估分数。"}}
{"id": "2602.04927", "pdf": "https://arxiv.org/pdf/2602.04927", "abs": "https://arxiv.org/abs/2602.04927", "authors": ["Gautam Savaliya", "Robert Aufschläger", "Abhishek Subedi", "Michael Heigl", "Martin Schramm"], "title": "PriMod4AI: Lifecycle-Aware Privacy Threat Modeling for AI Systems using LLM", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted at the NDSS LAST-X Workshop 2026", "summary": "Artificial intelligence systems introduce complex privacy risks throughout their lifecycle, especially when processing sensitive or high-dimensional data. Beyond the seven traditional privacy threat categories defined by the LINDDUN framework, AI systems are also exposed to model-centric privacy attacks such as membership inference and model inversion, which LINDDUN does not cover. To address both classical LINDDUN threats and additional AI-driven privacy attacks, PriMod4AI introduces a hybrid privacy threat modeling approach that unifies two structured knowledge sources, a LINDDUN knowledge base representing the established taxonomy, and a model-centric privacy attack knowledge base capturing threats outside LINDDUN. These knowledge bases are embedded into a vector database for semantic retrieval and combined with system level metadata derived from Data Flow Diagram. PriMod4AI uses retrieval-augmented and Data Flow specific prompt generation to guide large language models (LLMs) in identifying, explaining, and categorizing privacy threats across lifecycle stages. The framework produces justified and taxonomy-grounded threat assessments that integrate both classical and AI-driven perspectives. Evaluation on two AI systems indicates that PriMod4AI provides broad coverage of classical privacy categories while additionally identifying model-centric privacy threats. The framework produces consistent, knowledge-grounded outputs across LLMs, as reflected in agreement scores in the observed range.", "AI": {"tldr": "PriMod4AI 提出了一种隐私威胁建模方法，用于识别和分类人工智能系统在生命周期各阶段的隐私威胁。", "motivation": "传统 LINDDUN 框架未能涵盖 AI 系统特有的隐私攻击类型，如成员推断与模型反演。因此，该研究旨在通过结合经典 LINDDUN 和新兴 AI 隐私攻击知识库，为 AI 系统提供全面的隐私威胁评估。", "method": "PriMod4AI 结合了两种结构化的知识源：LINDDUN 框架和模型中心隐私攻击知识库，并将其嵌入到向量数据库中。借助大语言模型（LLMs）以及基于数据流图生成的数据流特有提示，该框架能够识别、解释并分类生命周期各阶段的隐私威胁。", "result": "在两个 AI 系统上的评估显示，PriMod4AI 能够全面覆盖经典 LINDDUN 隐私类别，并额外识别出模型中心隐私威胁。此方法生成的知识基础且一致性的输出结果，在不同大语言模型中观察到的一致性较高。", "conclusion": "通过整合传统和新兴的隐私攻击类型，PriMod4AI 成功地提供了一种全面、可靠的 AI 系统生命周期隐私威胁建模工具，并展示了其在实际应用中的有效性。"}}
{"id": "2602.04925", "pdf": "https://arxiv.org/pdf/2602.04925", "abs": "https://arxiv.org/abs/2602.04925", "authors": ["Zhenning Shi", "Yijia Zhu", "Junhan Shi", "Xun Zhang", "Lei Wang", "Congcong Miao"], "title": "Internalizing LLM Reasoning via Discovery and Replay of Latent Actions", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The internalization of chain-of-thought processes into hidden states has emerged as a highly efficient paradigm for scaling test-time compute. However, existing activation steering methods rely on static control vectors that fail to adapt to the non-stationary evolution of complex reasoning tasks. To address this limitation, we propose STIR (Self-Distilled Tools for Internal Reasoning), a framework that reformulates reasoning enhancement as a dynamic latent trajectory control problem. STIR introduces a synergistic three-stage pipeline: (1) differential intrinsic action induction harvests latent reasoning successes to crystallize steering primitives; (2) sparse control basis construction curates a compact, geometrically diverse tool library; and (3) value-modulated trajectory intervention dynamically injects context-specific impulses via anchor-based gating. Extensive experiments on six arithmetic and logical benchmarks across four representative models demonstrate that STIR improves average accuracy by 1.9% to 7.5% while reducing average token consumption by up to 35% compared to vanilla decoding. These findings demonstrate that the benefits of explicit chain-of-thought can be realized through dynamic latent trajectory control, internalizing the reasoning process to bypass the explicit generation while achieving superior fidelity. Our code is available at https://github.com/sznnzs/LLM-Latent-Action.", "AI": {"tldr": "本文提出了一种新的框架STIR，用于通过动态的潜在轨迹控制来增强大型语言模型的推理能力。", "motivation": "现有的激活引导方法依赖于静态控制向量，无法适应复杂任务中不断变化的情况。为了克服这一限制，作者提出了一个新的解决方案以改进LLM中的推理过程。", "method": "STIR框架包括三个阶段：差异性内在动作诱导、稀疏控制基构造和价值调制轨迹干预。", "result": "在六个算术和逻辑基准测试中，STIR提高了1.9%至7.5％的平均准确率，并将令牌消耗减少了最多35％。", "conclusion": "通过动态潜在轨迹控制实现链式思考的好处，可以内化推理过程而不必显式生成。"}}
{"id": "2602.04924", "pdf": "https://arxiv.org/pdf/2602.04924", "abs": "https://arxiv.org/abs/2602.04924", "authors": ["Dinh Phu Tran", "Jihoon Jeong", "Saad Wazir", "Seongah Kim", "Thao Do", "Cem Subakan", "Daeyoung Kim"], "title": "Knowing When to Answer: Adaptive Confidence Refinement for Reliable Audio-Visual Question Answering", "categories": ["cs.LG", "cs.SD"], "comment": "Technical Report", "summary": "We present a formal problem formulation for \\textit{Reliable} Audio-Visual Question Answering ($\\mathcal{R}$-AVQA), where we prefer abstention over answering incorrectly. While recent AVQA models have high accuracy, their ability to identify when they are likely wrong and their consequent abstention from answering remain underexplored areas of research. To fill this gap, we explore several approaches and then propose Adaptive Confidence Refinement (ACR), a lightweight method to further enhance the performance of $\\mathcal{R}$-AVQA. Our key insight is that the Maximum Softmax Probability (MSP) is Bayes-optimal only under strong calibration, a condition usually not met in deep neural networks, particularly in multimodal models. Instead of replacing MSP, our ACR maintains it as a primary confidence signal and applies input-adaptive residual corrections when MSP is deemed unreliable. ACR introduces two learned heads: i) a Residual Risk Head that predicts low-magnitude correctness residuals that MSP does not capture, and ii) a Confidence Gating Head to determine MSP trustworthiness. Our experiments and theoretical analysis show that ACR consistently outperforms existing methods on in- and out-of-disrtibution, and data bias settings across three different AVQA architectures, establishing a solid foundation for $\\mathcal{R}$-AVQA task. The code and checkpoints will be available upon acceptance \\href{https://github.com/PhuTran1005/R-AVQA}{at here}", "AI": {"tldr": "本文提出了自适应置信度精炼（ACR）方法，旨在提高可靠的音频视觉问答系统的性能。", "motivation": "尽管最近的AVQA模型准确率较高，但它们在识别自己可能出错的情况下选择不回答的能力尚未得到充分研究。作者希望通过探索并提出一种轻量级的方法来填补这一空白。", "method": "ACR方法利用最大softmax概率（MSP）作为主要置信度信号，并通过输入自适应残差校正当MSP被认为不可靠时进行改进。引入了两个学习头：残差风险预测器和置信门控单元，前者用于预测MSP未能捕获的低幅度正确性残差，后者则决定MSP的可靠性。", "result": "实验结果表明，在不同AVQA架构下，ACR方法在内分布、外分布及数据偏差设置中均优于现有方法，确立了可靠音频视觉问答任务的基础。", "conclusion": "本文通过提出自适应置信度精炼（ACR）方法提高了可靠AVQA系统的性能，并为未来的研究奠定了基础。"}}
{"id": "2602.04920", "pdf": "https://arxiv.org/pdf/2602.04920", "abs": "https://arxiv.org/abs/2602.04920", "authors": ["Ronghao Lin", "Qiaolin He", "Sijie Mai", "Ying Zeng", "Aolin Xiong", "Li Huang", "Yap-Peng Tan", "Haifeng Hu"], "title": "CyIN: Cyclic Informative Latent Space for Bridging Complete and Incomplete Multimodal Learning", "categories": ["cs.LG", "cs.SD"], "comment": "Accepted by NeurIPS 2025", "summary": "Multimodal machine learning, mimicking the human brain's ability to integrate various modalities has seen rapid growth. Most previous multimodal models are trained on perfectly paired multimodal input to reach optimal performance. In real-world deployments, however, the presence of modality is highly variable and unpredictable, causing the pre-trained models in suffering significant performance drops and fail to remain robust with dynamic missing modalities circumstances. In this paper, we present a novel Cyclic INformative Learning framework (CyIN) to bridge the gap between complete and incomplete multimodal learning. Specifically, we firstly build an informative latent space by adopting token- and label-level Information Bottleneck (IB) cyclically among various modalities. Capturing task-related features with variational approximation, the informative bottleneck latents are purified for more efficient cross-modal interaction and multimodal fusion. Moreover, to supplement the missing information caused by incomplete multimodal input, we propose cross-modal cyclic translation by reconstruct the missing modalities with the remained ones through forward and reverse propagation process. With the help of the extracted and reconstructed informative latents, CyIN succeeds in jointly optimizing complete and incomplete multimodal learning in one unified model. Extensive experiments on 4 multimodal datasets demonstrate the superior performance of our method in both complete and diverse incomplete scenarios.", "AI": {"tldr": "提出一种新的循环信息学习框架CyIN，以弥合完全多模态学习和不完整多模态学习之间的差距。", "motivation": "现有的多模态模型在完美配对的多模态输入上训练效果良好，但在实际部署中由于模态缺失情况不可预测导致性能大幅下降，无法保持动态缺失模态下的鲁棒性。CyIN旨在解决这一问题。", "method": "构建一个信息丰富的潜在空间通过采用token和标签层面的信息瓶颈(IB)在不同模态之间循环传递，并提出跨模态循环翻译以补充不完整多模态输入中的缺失信息。", "result": "实验表明，我们的方法在完全和多样化不完整的场景中均表现出色。", "conclusion": "CyIN框架通过统一的模型实现了对完全和不完整多模态学习的同时优化，并且在多种数据集上验证了其优越性。"}}
{"id": "2602.04915", "pdf": "https://arxiv.org/pdf/2602.04915", "abs": "https://arxiv.org/abs/2602.04915", "authors": ["Jose Miguel Luna", "Taha Bouhsine", "Krzysztof Choromanski"], "title": "SLAY: Geometry-Aware Spherical Linearized Attention with Yat-Kernel", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2026, 8 pages main body, 27 pages total", "summary": "We propose a new class of linear-time attention mechanisms based on a relaxed and computationally efficient formulation of the recently introduced E-Product, often referred to as the Yat-kernel (Bouhsine, 2025). The resulting interactions are geometry-aware and inspired by inverse-square interactions in physics. Our method, Spherical Linearized Attention with Yat Kernels (SLAY), constrains queries and keys to the unit sphere so that attention depends only on angular alignment. Using Bernstein's theorem, we express the spherical Yat-kernel as a nonnegative mixture of polynomial-exponential product kernels and derive a strictly positive random-feature approximation enabling linear-time O(L) attention. We establish positive definiteness and boundedness on the sphere and show that the estimator yields well-defined, nonnegative attention scores. Empirically, SLAY achieves performance that is nearly indistinguishable from standard softmax attention while retaining linear time and memory scaling, and consistently outperforms prior linear-time attention mechanisms such as Performers and Cosformers. To the best of our knowledge, SLAY represents the closest linear-time approximation to softmax attention reported to date, enabling scalable Transformers without the typical performance trade-offs of attention linearization.", "AI": {"tldr": "提出了一种基于Yat核的几何感知球形线性化注意力机制SLAY，能够在保持性能的同时实现线性时间复杂度。", "motivation": "旨在设计一种既高效又能够保留原有注意力机制性能的方法。通过利用物理中的逆平方相互作用原理和Bernstein定理，提出了一种新的基于Yat核的球形线性化注意力方法，以实现在保持高质量性能的同时降低计算复杂性和内存需求。", "method": "提出了SLAY模型，它将查询和密钥约束在单位球面上，通过Bernstein定理表达出非负多项式指数产品内核的混合，并推导出了严格正随机特征近似表示，从而实现了线性时间注意力。该方法基于松弛且计算效率高的E-Product（即Yat核），能够保证注意力仅依赖于角度对齐。", "result": "SLAY在实验中表现几乎与标准Softmax注意力一致，同时保留了线性时间和内存扩展特性，并且始终优于先前的线性时间注意机制如Performer和Cosformer。SLAY被认为是迄今为止最接近Softmax注意力的线性时间近似方法。", "conclusion": "SLAY代表了一种新的高效解决方案，使得大规模Transformer模型在保持性能的同时实现可扩展性，避免了传统注意力线性化带来的典型性能折中问题。"}}
{"id": "2602.04913", "pdf": "https://arxiv.org/pdf/2602.04913", "abs": "https://arxiv.org/abs/2602.04913", "authors": ["Xiaolin Hu", "Hang Yuan", "Xinzhu Sang", "Binbin Yan", "Zhou Yu", "Cong Huang", "Kai Chen"], "title": "A$^2$-LLM: An End-to-end Conversational Audio Avatar Large Language Model", "categories": ["cs.LG", "cs.AI", "cs.SD"], "comment": "13 pages, 3 figures", "summary": "Developing expressive and responsive conversational digital humans is a cornerstone of next-generation human-computer interaction. While large language models (LLMs) have significantly enhanced dialogue capabilities, most current systems still rely on cascaded architectures that connect independent modules. These pipelines are often plagued by accumulated errors, high latency, and poor real-time performance. Lacking access to the underlying conversational context, these pipelines inherently prioritize rigid lip-sync over emotional depth. To address these challenges, we propose A$^2$-LLM, an end-to-end conversational audio avatar large language model that jointly reasons about language, audio prosody, and 3D facial motion within a unified framework. To facilitate training, we introduce FLAME-QA, a high-quality multimodal dataset designed to align semantic intent with expressive facial dynamics within a QA format. By leveraging deep semantic understanding, A$^2$-LLM generates emotionally rich facial movements beyond simple lip-synchronization. Experimental results demonstrate that our system achieves superior emotional expressiveness while maintaining real-time efficiency (500 ms latency, 0.7 RTF).", "AI": {"tldr": "本文提出了A$^2$-LLM，一种端到端的会话音频头像大语言模型，旨在通过统一框架联合推理语言、音频韵律和3D面部运动。", "motivation": "大多数当前系统依赖于级联架构连接独立模块，导致累积错误、高延迟和实时性能差。为了解决这些问题，并提高情感深度，本文提出了一种端到端的会话音频头像大语言模型。", "method": "引入了FLAME-QA，这是一个高质量的多模态数据集，用于在问答格式中对齐语义意图与表达性的面部动态变化。通过利用深层语义理解，A$^2$-LLM生成丰富的面部运动，超越简单的口型同步。", "result": "实验结果表明，该系统实现了卓越的情感表现力，同时保持了实时效率（延迟500毫秒，0.7 RTF）。", "conclusion": "通过统一框架联合推理语言、音频韵律和3D面部运动，A$^2$-LLM能够生成丰富情感的面部动态变化，并且具有良好的实时性能。"}}
{"id": "2602.04911", "pdf": "https://arxiv.org/pdf/2602.04911", "abs": "https://arxiv.org/abs/2602.04911", "authors": ["E Bowen", "R Granger", "A Rodriguez"], "title": "A logical re-conception of neural networks: Hamiltonian bitwise part-whole architecture", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "Appears in AAAI 2023", "summary": "We introduce a simple initial working system in which relations (such as part-whole) are directly represented via an architecture with operating and learning rules fundamentally distinct from standard artificial neural network methods. Arbitrary data are straightforwardly encoded as graphs whose edges correspond to codes from a small fixed primitive set of elemental pairwise relations, such that simple relational encoding is not an add-on, but occurs intrinsically within the most basic components of the system. A novel graph-Hamiltonian operator calculates energies among these encodings, with ground states denoting simultaneous satisfaction of all relation constraints among graph vertices. The method solely uses radically low-precision arithmetic; computational cost is correspondingly low, and scales linearly with the number of edges in the data. The resulting unconventional architecture can process standard ANN examples, but also produces representations that exhibit characteristics of symbolic computation. Specifically, the method identifies simple logical relational structures in these data (part-of; next-to), building hierarchical representations that enable abductive inferential steps generating relational position-based encodings, rather than solely statistical representations. Notably, an equivalent set of ANN operations are derived, identifying a special case of embedded vector encodings that may constitute a useful approach to current work in higher-level semantic representation. The very simple current state of the implemented system invites additional tools and improvements.", "AI": {"tldr": "提出了基于哈密顿量操作符的神经网络架构，直接通过图形边表示关系并计算能量以满足所有约束条件。", "motivation": "为了解决传统人工神经网络处理符号计算和逻辑关系的问题，提出一种新的方法来简化数据编码，并使简单的关系编码成为系统的基本组成部分。", "method": "利用低精度算术运算设计了一种新型的图形哈密顿量操作符，用于直接表示关系并通过计算能量满足所有约束条件。该方法可以处理标准ANN示例并生成具有符号计算特征的数据表示。", "result": "实现了可以直接进行逻辑关系编码和统计表示的神经网络架构，并且在低精度算术运算下表现良好。同时识别了部分-整体等简单逻辑关系结构，构建了层级化表示。", "conclusion": "该方法可以生成具有符号计算特征的数据表示，并通过简单的当前实现状态邀请更多的工具和改进来优化性能。"}}
{"id": "2602.04908", "pdf": "https://arxiv.org/pdf/2602.04908", "abs": "https://arxiv.org/abs/2602.04908", "authors": ["Chika Maduabuchi", "Jindong Wang"], "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Continuous-time generative models, such as diffusion models, flow matching, and rectified flow, learn time-dependent vector fields but are typically trained with objectives that treat timesteps independently, leading to high estimator variance and inefficient sampling. Prior approaches mitigate this via explicit smoothness penalties, trajectory regularization, or modified probability paths and solvers. We introduce Temporal Pair Consistency (TPC), a lightweight variance-reduction principle that couples velocity predictions at paired timesteps along the same probability path, operating entirely at the estimator level without modifying the model architecture, probability path, or solver. We provide a theoretical analysis showing that TPC induces a quadratic, trajectory-coupled regularization that provably reduces gradient variance while preserving the underlying flow-matching objective. Instantiated within flow matching, TPC improves sample quality and efficiency across CIFAR-10 and ImageNet at multiple resolutions, achieving lower FID at identical or lower computational cost than prior methods, and extends seamlessly to modern SOTA-style pipelines with noise-augmented training, score-based denoising, and rectified flow.", "AI": {"tldr": "本文提出了一种轻量级的方差减少原则——时序配对一致性（TPC），以改善连续时间生成模型的性能。", "motivation": "现有的连续时间生成模型在训练过程中通常会将时间步骤独立处理，导致估计器方差高且采样效率低。本文旨在通过引入一种新的方法来降低这一问题。", "method": "时序配对一致性（TPC）是一种轻量级的方差减少原则，它连接了沿同一概率路径上的成对标记的时间步长速度预测，完全在估计器层面操作而不需要修改模型架构、概率路径或求解器。理论分析表明，TPC引入了一种轨迹耦合的正则化方式，可证明地减少了梯度方差。", "result": "TPC改善了样本质量和效率，在多个数据集上实现了更低的FID分数，并且在计算成本相同或更低的情况下优于先前的方法。", "conclusion": "时序配对一致性（TPC）方法能够在不改变模型架构、概率路径或求解器的前提下，通过减少梯度方差来提升连续时间生成模型的效果。"}}
{"id": "2602.04907", "pdf": "https://arxiv.org/pdf/2602.04907", "abs": "https://arxiv.org/abs/2602.04907", "authors": ["Jianhong Chen", "Naichen Shi", "Xubo Yue"], "title": "Physics as the Inductive Bias for Causal Discovery", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "Causal discovery is often a data-driven paradigm to analyze complex real-world systems. In parallel, physics-based models such as ordinary differential equations (ODEs) provide mechanistic structure for many dynamical processes. Integrating these paradigms potentially allows physical knowledge to act as an inductive bias, improving identifiability, stability, and robustness of causal discovery in dynamical systems. However, such integration remains challenging: real dynamical systems often exhibit feedback, cyclic interactions, and non-stationary data trend, while many widely used causal discovery methods are formulated under acyclicity or equilibrium-based assumptions. In this work, we propose an integrative causal discovery framework for dynamical systems that leverages partial physical knowledge as an inductive bias. Specifically, we model system evolution as a stochastic differential equation (SDE), where the drift term encodes known ODE dynamics and the diffusion term corresponds to unknown causal couplings beyond the prescribed physics. We develop a scalable sparsity-inducing MLE algorithm that exploits causal graph structure for efficient parameter estimation. Under mild conditions, we establish guarantees to recover the causal graph. Experiments on dynamical systems with diverse causal structures show that our approach improves causal graph recovery and produces more stable, physically consistent estimates than purely data-driven state-of-the-art baselines.", "AI": {"tldr": "提出了一种结合物理知识作为归纳偏置的动态系统因果发现框架。", "motivation": "利用物理知识和数据驱动方法的优势，提高因果关系发现的可识别性、稳定性和鲁棒性。", "method": "通过将系统演化建模为包含已知ODE动力学和未知耦合的随机微分方程来整合物理模型与因果发现。使用稀疏诱导最大似然估计算法进行参数估算，并利用因果图结构提高效率。", "result": "实验显示该方法在多种动态系统的因果关系恢复中表现更好，生成更稳定的、符合物理规律的估计结果。", "conclusion": "结合物理知识可以显著改善数据驱动因果发现的方法性能。"}}
{"id": "2602.04904", "pdf": "https://arxiv.org/pdf/2602.04904", "abs": "https://arxiv.org/abs/2602.04904", "authors": ["Yiwen Wang", "Jiahao Qin"], "title": "DCER: Dual-Stage Compression and Energy-Based Reconstruction", "categories": ["cs.LG", "cs.AI", "cs.MM", "eess.IV"], "comment": "13 pages, 2 figures, 8 tables. Submitted to ICML 2026. Code will be available on GitHub", "summary": "Multimodal fusion faces two robustness challenges: noisy inputs degrade representation quality, and missing modalities cause prediction failures. We propose DCER, a unified framework addressing both challenges through dual-stage compression and energy-based reconstruction. The compression stage operates at two levels: within-modality frequency transforms (wavelet for audio, DCT for video) remove noise while preserving task-relevant patterns, and cross-modality bottleneck tokens force genuine integration rather than modality-specific shortcuts. For missing modalities, energy-based reconstruction recovers representations via gradient descent on a learned energy function, with the final energy providing intrinsic uncertainty quantification (\\r{ho} > 0.72 correlation with prediction error). Experiments on CMU-MOSI, CMU-MOSEI, and CH-SIMS demonstrate state-of-the-art performance across all benchmarks, with a U-shaped robustness pattern favoring multimodal fusion at both complete and high-missing conditions. The code will be available on Github.", "AI": {"tldr": "提出了一种统一的框架DCER，用于处理多模态融合中的噪声输入和缺失模式问题。", "motivation": "为了提高多模态融合在面对噪声输入和缺失模式时的鲁棒性。", "method": "通过双阶段压缩和基于能量重构的方法。第一阶段包括在同一模式内频谱变换以去除噪音并保留任务相关的模式，跨模式瓶颈令牌促进真正的整合；第二阶段使用基于能量的重构恢复表示。", "result": "在CMU-MOSI, CMU-MOSEI和CH-SIMS等数据集上取得了最先进的性能，并展示了针对完全多模态融合以及高缺失条件下的U型鲁棒性模式。", "conclusion": "DCER框架通过解决噪声输入问题并增强对缺失模式的恢复能力，提高了多模态融合模型的整体鲁棒性和准确性。"}}
{"id": "2602.04902", "pdf": "https://arxiv.org/pdf/2602.04902", "abs": "https://arxiv.org/abs/2602.04902", "authors": ["Kingsuk Maitra"], "title": "Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 5 figures, 299 pages total with supplementary material (21 appendices, 27 Jupyter notebooks with embedded results)", "summary": "The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a symplectic augmentation embedding physical priors via the kinematic difference operator $p_t = q_t - q_{t-1}$, implementing the symplectic shear $\\hat{q}_t = q_t + γp_t$ on queries and keys. We identify a fundamental Symplectic-Filter Duality: the physical shear is mathematically equivalent to a High-Pass Filter. This duality is our cornerstone contribution -- by injecting kinematic momentum, we sidestep the topological depth constraint ($L \\geq 2$) for induction head formation. While standard architectures require two layers for induction from static positions, our extension grants direct access to velocity, enabling Single-Layer Induction and Spectral Forensics via Bode Plots. We formalize an Orthogonality Theorem proving that DC (semantic) and AC (mechanistic) signals segregate into orthogonal frequency bands when Low-Pass RoPE interacts with High-Pass Momentum. Validated through 5,100+ controlled experiments (documented in Supplementary Appendices A--R and 27 Jupyter notebooks), our 125M Momentum model exceeds expectations on induction-heavy tasks while tracking a 350M baseline within $\\sim$2.9% validation loss. Dedicated associative recall experiments reveal a scaling law $γ^* = 4.17 \\times N^{-0.74}$ establishing momentum-depth fungibility. We offer this framework as a complementary analytical toolkit connecting Generative AI, Hamiltonian Physics, and Signal Processing.", "AI": {"tldr": "本文提出了动量注意力机制，通过物理电路的角度分析Transformer模型，并引入了高通滤波器的概念来优化单一层诱导任务。", "motivation": "动机在于通过将Transformer看作是一个计算图，并结合物理学中的守恒律和时变交流动力学，以物理视角改进模型的可解释性。", "method": "提出了动量注意力机制，通过引入动能差操作符$p_t = q_t - q_{t-1}$来增强查询和键向量，实现了单一层诱导任务，并利用伯德图进行频谱取证。", "result": "实验结果表明，所提出的模型在重推理任务上超过了基准模型约2.9%的验证损失。此外还发现了一种动量深度可互换性规律$γ^* = 4.17 \times N^{-0.74}$。", "conclusion": "本文通过引入物理原理和信号处理技术，提出了一种新的改进Transformer模型的方法，并提供了一个连接生成AI、哈密顿物理和信号处理的分析工具包。"}}
{"id": "2602.04900", "pdf": "https://arxiv.org/pdf/2602.04900", "abs": "https://arxiv.org/abs/2602.04900", "authors": ["Sai Sindhur Malleni", "Raúl Sevilla", "Aleksei Vasilevskii", "José Castillo Lema", "André Bauer"], "title": "Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization", "categories": ["cs.ET", "cs.AI", "cs.DC"], "comment": "A accepted at the 17th International Conference on Performance Engineering", "summary": "As Generative AI (GenAI), particularly inference, rapidly emerges as a dominant workload category, the Kubernetes ecosystem is proactively evolving to natively support its unique demands. This industry paper demonstrates how emerging Kubernetes-native projects can be combined to deliver the benefits of container orchestration, such as scalability and resource efficiency, to complex AI workflows. We implement and evaluate an illustrative, multi-stage use case consisting of automatic speech recognition and summarization. First, we address batch inference by using Kueue to manage jobs that transcribe audio files with Whisper models and Dynamic Accelerator Slicer (DAS) to increase parallel job execution. Second, we address a discrete online inference scenario by feeding the transcripts to a Large Language Model for summarization hosted using llm-d, a novel solution utilizing the recent developments around the Kubernetes Gateway API Inference Extension (GAIE) for optimized routing of inference requests. Our findings illustrate that these complementary components (Kueue, DAS, and GAIE) form a cohesive, high-performance platform, proving Kubernetes' capability to serve as a unified foundation for demanding GenAI workloads: Kueue reduced total makespan by up to 15%; DAS shortened mean job completion time by 36%; and GAIE improved Time to First Token by 82\\%.", "AI": {"tldr": "本论文评估了Kubernetes在GenAI推断工作负载中的性能，通过实现并评价一个包含自动语音识别和总结的多阶段用例来展示新兴Kubernetes原生项目如何协同工作以支持复杂的AI流程。", "motivation": "随着Generative AI（GenAI）特别是推断迅速成为主导的工作负载类别，Kubernetes生态系统正在积极演进，以更好地满足其独特需求。本论文探讨了Kubernetes原生项目的结合使用如何提高容器编排的效益，如可伸缩性和资源效率，并优化复杂的AI工作流程。", "method": "研究者实施了一个多阶段用例，包括自动语音识别和总结任务。他们利用Kueue管理转录音频文件的工作负载，通过Whisper模型进行处理，并采用Dynamic Accelerator Slicer (DAS)增加并行作业执行的效率；同时使用llm-d解决方案托管大型语言模型以实现高效摘要生成。", "result": "实验结果表明，这些互补组件（包括Kueue、DAS和GAIE）能够形成一个高性能平台。其中，Kueue将总体完成时间减少了最多15%；DAS缩短了平均任务完成时间36%；而GAIE使首令牌到达时间提高了82%。", "conclusion": "研究证明了Kubernetes有能力作为GenAI工作负载的统一基础架构，并展示了新兴Kubernetes原生项目如何通过优化资源管理、执行效率和请求路由来改善复杂AI流程的性能。"}}
{"id": "2602.04899", "pdf": "https://arxiv.org/pdf/2602.04899", "abs": "https://arxiv.org/abs/2602.04899", "authors": ["Andrew Draganov", "Tolga H. Dur", "Anandmayi Bhongade", "Mary Phuong"], "title": "Phantom Transfer: Data-level Defences are Insufficient Against Data Poisoning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "We present a data poisoning attack -- Phantom Transfer -- with the property that, even if you know precisely how the poison was placed into an otherwise benign dataset, you cannot filter it out. We achieve this by modifying subliminal learning to work in real-world contexts and demonstrate that the attack works across models, including GPT-4.1. Indeed, even fully paraphrasing every sample in the dataset using a different model does not stop the attack. We also discuss connections to steering vectors and show that one can plant password-triggered behaviours into models while still beating defences. This suggests that data-level defences are insufficient for stopping sophisticated data poisoning attacks. We suggest that future work should focus on model audits and white-box security methods.", "AI": {"tldr": "提出了一种名为Phantom Transfer的数据投毒攻击，即使了解数据是如何被篡改的，也无法有效过滤。", "motivation": "为了展示当前数据级别的防御措施在面对复杂的数据投毒攻击时是不足的，并建议未来研究应集中在模型审查和白盒安全方法上。", "method": "通过修改微妙学习技术使其适用于现实场景中，创建了跨不同模型有效的Phantom Transfer攻击。证明了即使对每个样本进行重新表述也无法阻止该攻击。", "result": "数据级别的防御措施无法有效抵御这种新的数据投毒攻击。", "conclusion": "建议未来的研究应该更加关注于提高模型的安全性和审查机制以对抗数据投毒攻击"}}
{"id": "2602.04898", "pdf": "https://arxiv.org/pdf/2602.04898", "abs": "https://arxiv.org/abs/2602.04898", "authors": ["Tianxin Chen", "Wenbo Jiang", "Hongqiao Chen", "Zhirun Zheng", "Cheng Huang"], "title": "Semantic-level Backdoor Attack against Text-to-Image Diffusion Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Text-to-image (T2I) diffusion models are widely adopted for their strong generative capabilities, yet remain vulnerable to backdoor attacks. Existing attacks typically rely on fixed textual triggers and single-entity backdoor targets, making them highly susceptible to enumeration-based input defenses and attention-consistency detection. In this work, we propose Semantic-level Backdoor Attack (SemBD), which implants backdoors at the representation level by defining triggers as continuous semantic regions rather than discrete textual patterns. Concretely, SemBD injects semantic backdoors by distillation-based editing of the key and value projection matrices in cross-attention layers, enabling diverse prompts with identical semantic compositions to reliably activate the backdoor attack. To further enhance stealthiness, SemBD incorporates a semantic regularization to prevent unintended activation under incomplete semantics, as well as multi-entity backdoor targets that avoid highly consistent cross-attention patterns. Extensive experiments demonstrate that SemBD achieves a 100% attack success rate while maintaining strong robustness against state-of-the-art input-level defenses.", "AI": {"tldr": "本文提出了一种针对文本到图像扩散模型的语义级后门攻击方法（SemBD），该方法通过在表示层植入后门，增强了传统后门攻击的效果。", "motivation": "现有的后门攻击依赖于固定的文本触发器和单一实体的目标，在面对输入级别的防御时容易被检测。为解决这些问题，本文旨在提出一种更隐蔽、更具多样性的语义级后门攻击方法。", "method": "SemBD通过编辑交叉注意力层的关键值投影矩阵进行知识蒸馏来植入语义后门，并引入了语义正则化以避免在不完整语义下的意外激活。同时，采用多实体目标进一步提高了隐蔽性。", "result": "实验结果显示，SemBD实现了100%的攻击成功率，并且对最先进的输入级防御保持强大的鲁棒性。", "conclusion": "通过定义连续的语义区域作为触发器而非离散文本模式，SemBD展示了更高的隐蔽性和多样性。"}}
{"id": "2602.04896", "pdf": "https://arxiv.org/pdf/2602.04896", "abs": "https://arxiv.org/abs/2602.04896", "authors": ["Chen Xiong", "Zhiyuan He", "Pin-Yu Chen", "Ching-Yun Ko", "Tsung-Yi Ho"], "title": "Steering Externalities: Benign Activation Steering Unintentionally Increases Jailbreak Risk for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Activation steering is a practical post-training model alignment technique to enhance the utility of Large Language Models (LLMs). Prior to deploying a model as a service, developers can steer a pre-trained model toward specific behavioral objectives, such as compliance or instruction adherence, without the need for retraining. This process is as simple as adding a steering vector to the model's internal representations. However, this capability unintentionally introduces critical and under-explored safety risks. We identify a phenomenon termed Steering Externalities, where steering vectors derived from entirely benign datasets-such as those enforcing strict compliance or specific output formats like JSON-inadvertently erode safety guardrails. Experiments reveal that these interventions act as a force multiplier, creating new vulnerabilities to jailbreaks and increasing attack success rates to over 80% on standard benchmarks by bypassing the initial safety alignment. Ultimately, our results expose a critical blind spot in deployment: benign activation steering systematically erodes the \"safety margin,\" rendering models more vulnerable to black-box attacks and proving that inference-time utility improvements must be rigorously audited for unintended safety externalities.", "AI": {"tldr": "论文研究了激活引导技术在大语言模型中的潜在安全风险，发现这种技术会无意中引入新的漏洞。", "motivation": "作者指出激活引导是一种实用的后训练对齐方法，可以增强大型语言模型（LLM）的行为规范性。然而，这种方法可能存在未被充分探索的安全隐患，因此需要深入研究和揭示这些风险。", "method": "通过实验设计来测试在使用良性数据集进行激活引导时，是否会导致安全防护措施的削弱，并评估攻击成功率的变化情况。", "result": "研究表明，在特定情况下，即使使用完全良性的数据集进行激活引导也会导致模型的安全性降低，使成功绕过初始对齐并执行黑盒攻击的概率超过80%。", "conclusion": "论文强调了在部署大型语言模型时必须仔细审计这些推理时间的改进措施，以防止意外的安全外部因素影响到模型的安全性。"}}
{"id": "2602.04895", "pdf": "https://arxiv.org/pdf/2602.04895", "abs": "https://arxiv.org/abs/2602.04895", "authors": ["Clément Pierquin", "Aurélien Bellet", "Marc Tommasi", "Matthieu Boussard"], "title": "Privacy Amplification Persists under Unlimited Synthetic Data Release", "categories": ["cs.CR", "cs.DS", "cs.LG", "stat.ML"], "comment": null, "summary": "We study privacy amplification by synthetic data release, a phenomenon in which differential privacy guarantees are improved by releasing only synthetic data rather than the private generative model itself. Recent work by Pierquin et al. (2025) established the first formal amplification guarantees for a linear generator, but they apply only in asymptotic regimes where the model dimension far exceeds the number of released synthetic records, limiting their practical relevance. In this work, we show a surprising result: under a bounded-parameter assumption, privacy amplification persists even when releasing an unbounded number of synthetic records, thereby improving upon the bounds of Pierquin et al. (2025). Our analysis provides structural insights that may guide the development of tighter privacy guarantees for more complex release mechanisms.", "AI": {"tldr": "研究合成数据发布下的隐私放大效应，即使在无限释放合成记录的情况下也保持隐私保护的增强。", "motivation": "探讨为何通过发布合成数据而非直接公开私有生成模型能够改善差分隐私保障，并解决先前工作仅限于特定条件下的问题。", "method": "基于参数受限假设，分析线性生成器在无限释放合成记录时的隐私放大效应。", "result": "证明了即使在无限制地发布大量合成数据的情况下，仍然可以维持隐私保护的增强效果。改进了先前工作的界限。", "conclusion": "展示了新的理论成果和结构见解，有助于指导更紧致的隐私保障机制的发展。"}}
{"id": "2602.04894", "pdf": "https://arxiv.org/pdf/2602.04894", "abs": "https://arxiv.org/abs/2602.04894", "authors": ["Tomer Kordonsky", "Maayan Yamin", "Noam Benzimra", "Amit LeVi", "Avi Mendelson"], "title": "Extracting Recurring Vulnerabilities from Black-Box LLM-Generated Software", "categories": ["cs.CR", "cs.AI"], "comment": "Preprint", "summary": "LLMs are increasingly used for code generation, but their outputs often follow recurring templates that can induce predictable vulnerabilities. We study \\emph{vulnerability persistence} in LLM-generated software and introduce \\emph{Feature--Security Table (FSTab)} with two components. First, FSTab enables a black-box attack that predicts likely backend vulnerabilities from observable frontend features and knowledge of the source LLM, without access to backend code or source code. Second, FSTab provides a model-centric evaluation that quantifies how consistently a given model reproduces the same vulnerabilities across programs, semantics-preserving rephrasings, and application domains. We evaluate FSTab on state-of-the-art code LLMs, including GPT-5.2, Claude-4.5 Opus, and Gemini-3 Pro, across diverse application domains. Our results show strong cross-domain transfer: even when the target domain is excluded from training, FSTab achieves up to 94\\% attack success and 93\\% vulnerability coverage on Internal Tools (Claude-4.5 Opus). These findings expose an underexplored attack surface in LLM-generated software and highlight the security risks of code generation. Our code is available at: https://anonymous.4open.science/r/FSTab-024E.", "AI": {"tldr": "本文研究了大型语言模型生成软件中的漏洞持久性问题，并提出了一种名为FSTab的方法，通过黑盒攻击预测后端漏洞。", "motivation": "大型语言模型在代码生成中被广泛应用，但其输出常遵循可预测的模板从而引入安全漏洞。为此，作者希望通过研究LLM生成代码的安全性问题来揭示一个未充分探索的攻击面，并提高对代码生成安全风险的认识。", "method": "FSTab方法包含两个部分：一部分通过前端特征和源LLM的知识进行黑盒攻击预测后端漏洞；另一部分则评估给定模型在不同程序、语义保持重写以及应用领域中重复产生相同漏洞的一致性。作者对GPT-5.2，Claude-4.5 Opus 和 Gemini-3 Pro等最先进的代码LLM进行了评估。", "result": "实验表明FSTab能够实现高达94%的攻击成功率和93%的漏洞覆盖率，特别是在内工具领域，即使目标领域未包含在训练数据中。这些结果强调了在大型语言模型生成软件中的潜在安全风险。", "conclusion": "本文揭示了一个新兴且重要的研究方向——LLM生成代码的安全性，并证明了利用FSTab进行黑盒攻击的有效性和一致性评估的可行性。这为进一步的研究提供了理论基础和技术支持，以提高未来由大模型生成代码的安全水平。"}}
{"id": "2602.04893", "pdf": "https://arxiv.org/pdf/2602.04893", "abs": "https://arxiv.org/abs/2602.04893", "authors": ["Licheng Pan", "Yunsheng Lu", "Jiexi Liu", "Jialing Tao", "Haozhe Feng", "Hui Xue", "Zhixuan Chu", "Kui Ren"], "title": "A Causal Perspective for Enhancing Jailbreak Attack and Defense", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Uncovering the mechanisms behind \"jailbreaks\" in large language models (LLMs) is crucial for enhancing their safety and reliability, yet these mechanisms remain poorly understood. Existing studies predominantly analyze jailbreak prompts by probing latent representations, often overlooking the causal relationships between interpretable prompt features and jailbreak occurrences. In this work, we propose Causal Analyst, a framework that integrates LLMs into data-driven causal discovery to identify the direct causes of jailbreaks and leverage them for both attack and defense. We introduce a comprehensive dataset comprising 35k jailbreak attempts across seven LLMs, systematically constructed from 100 attack templates and 50 harmful queries, annotated with 37 meticulously designed human-readable prompt features. By jointly training LLM-based prompt encoding and GNN-based causal graph learning, we reconstruct causal pathways linking prompt features to jailbreak responses. Our analysis reveals that specific features, such as \"Positive Character\" and \"Number of Task Steps\", act as direct causal drivers of jailbreaks. We demonstrate the practical utility of these insights through two applications: (1) a Jailbreaking Enhancer that targets identified causal features to significantly boost attack success rates on public benchmarks, and (2) a Guardrail Advisor that utilizes the learned causal graph to extract true malicious intent from obfuscated queries. Extensive experiments, including baseline comparisons and causal structure validation, confirm the robustness of our causal analysis and its superiority over non-causal approaches. Our results suggest that analyzing jailbreak features from a causal perspective is an effective and interpretable approach for improving LLM reliability. Our code is available at https://github.com/Master-PLC/Causal-Analyst.", "AI": {"tldr": "提出了一种基于因果关系分析的框架，以增强大型语言模型（LLM）的安全性和可靠性。", "motivation": "现有的研究主要通过探索潜在表示来分析“越狱”提示，忽略了可解释提示特征与“越狱”发生之间的因果关系。为了更好地理解这些机制并提高LLM的安全性，作者提出了一种新的框架Causal Analyst。", "method": "使用由100个攻击模板和50个有害查询构建的35k次‘越狱’尝试的数据集，并通过基于图神经网络（GNN）的学习来重建提示特征与“越狱”响应之间的因果路径，从而揭示了特定特征对“越狱”的直接驱动作用。", "result": "实验表明，Causal Analyst框架不仅可以显著提高攻击成功率，还可以从模糊的查询中提取真正的恶意意图。通过因果结构验证和基准比较，证实了该方法的优越性和鲁棒性。", "conclusion": "从因果关系角度分析‘越狱’特征是一种有效且可解释的方法，有助于提高LLM的安全性和可靠性。"}}
{"id": "2602.04892", "pdf": "https://arxiv.org/pdf/2602.04892", "abs": "https://arxiv.org/abs/2602.04892", "authors": ["Shihao Xia", "Mengting He", "Haomin Jia", "Linhai Song"], "title": "Doc2Spec: Synthesizing Formal Programming Specifications from Natural Language via Grammar Induction", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": null, "summary": "Ensuring that API implementations and usage comply with natural language programming rules is critical for software correctness, security, and reliability. Formal verification can provide strong guarantees but requires precise specifications, which are difficult and costly to write manually. To address this challenge, we present Doc2Spec, a multi-agent framework that uses LLMs to automatically induce a specification grammar from natural-language rules and then generates formal specifications guided by the induced grammar. The grammar captures essential domain knowledge, constrains the specification space, and enforces consistent representations, thereby improving the reliability and quality of generated specifications. Evaluated on seven benchmarks across three programming languages, Doc2Spec outperforms a baseline without grammar induction and achieves competitive results against a technique with a manually crafted grammar, demonstrating the effectiveness of automated grammar induction for formalizing natural-language rules.", "AI": {"tldr": "该论文提出了一种名为Doc2Spec的多代理框架，通过语言模型自动从自然语言规则中诱导出规范语法，并根据所诱导的语法生成正式规格说明。", "motivation": "为了确保API实现和使用符合自然语言编程规则，需要精确的形式化规范以进行形式验证。然而，手动编写这些规范既困难又昂贵，因此提出了Doc2Spec框架来解决这一挑战。", "method": "Doc2Spec利用LLMs自动从自然语言规则中诱导出一个规格说明文法，并根据这个文法生成正式的规格说明，该过程包括捕捉领域知识、限定规格空间和保持一致表示。", "result": "在三种编程语言上的七项基准测试中，Doc2Spec优于没有语法归纳的基本方法，并且与使用手动编写的语法技术相比，表现出竞争力的结果。", "conclusion": "自动化的语法归纳对于形式化自然语言规则是有效的，这表明该框架能够提高生成规格说明的可靠性和质量。"}}
{"id": "2602.04890", "pdf": "https://arxiv.org/pdf/2602.04890", "abs": "https://arxiv.org/abs/2602.04890", "authors": ["Lucas de Magalhães Araujo", "Otávio Oliveira Napoli", "Sandra Avila", "Edson Borin"], "title": "A General-Purpose Diversified 2D Seismic Image Dataset from NAMSS", "categories": ["physics.geo-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "We introduce the Unicamp-NAMSS dataset, a large, diverse, and geographically distributed collection of migrated 2D seismic sections designed to support modern machine learning research in geophysics. We constructed the dataset from the National Archive of Marine Seismic Surveys (NAMSS), which contains decades of publicly available marine seismic data acquired across multiple regions, acquisition conditions, and geological settings. After a comprehensive collection and filtering process, we obtained 2588 cleaned and standardized seismic sections from 122 survey areas, covering a wide range of vertical and horizontal sampling characteristics. To ensure reliable experimentation, we balanced the dataset so that no survey dominates the distribution, and partitioned it into non-overlapping macro-regions for training, validation, and testing. This region-disjoint split allows robust evaluation of generalization to unseen geological and acquisition conditions. We validated the dataset through quantitative and embedding-space analyses using both convolutional and transformer-based models. These analyses showed that Unicamp-NAMSS exhibits substantial variability within and across regions, while maintaining coherent structure across acquisition macro-region and survey types. Comparisons with widely used interpretation datasets (Parihaka and F3 Block) further demonstrated that Unicamp-NAMSS covers a broader portion of the seismic appearance space, making it a strong candidate for machine learning model pretraining. The dataset, therefore, provides a valuable resource for machine learning tasks, including self-supervised representation learning, transfer learning, benchmarking supervised tasks such as super-resolution or attribute prediction, and studying domain adaptation in seismic interpretation.", "AI": {"tldr": "介绍了Unicamp-NAMSS数据集，该数据集是一个大规模、多样化的二维地震图像集合，用于支持现代机器学习研究。", "motivation": "旨在提供一个大型、多样化和地理分布广泛的地震图像数据集，以促进地质物理中的机器学习研究。", "method": "从NAMSS档案收集并筛选出2588个清洁且标准化的二维地震横切面，并将其划分为训练、验证和测试用的非重叠区域。通过使用卷积和转换器模型进行定量分析和嵌入空间分析，以验证数据集的质量。", "result": "该数据集展示了广泛的内部和跨地区变异性和一致性结构，与广泛使用的解释数据集相比，它覆盖了更广阔的地震外观空间。", "conclusion": "Unicamp-NAMSS提供了有价值的资源，可用于机器学习任务如自监督表示学习、迁移学习、超分辨率预测等，并且是研究领域适应性的有力工具。"}}
{"id": "2602.04886", "pdf": "https://arxiv.org/pdf/2602.04886", "abs": "https://arxiv.org/abs/2602.04886", "authors": ["Luke Whitbread", "Lyle J. Palmer", "Mark Jenkinson"], "title": "Denoising diffusion networks for normative modeling in neuroimaging", "categories": ["cs.LG", "cs.AI", "cs.CE", "stat.ML"], "comment": "55 pages, 20 figures", "summary": "Normative modeling estimates reference distributions of biological measures conditional on covariates, enabling centiles and clinically interpretable deviation scores to be derived. Most neuroimaging pipelines fit one model per imaging-derived phenotype (IDP), which scales well but discards multivariate dependence that may encode coordinated patterns. We propose denoising diffusion probabilistic models (DDPMs) as a unified conditional density estimator for tabular IDPs, from which univariate centiles and deviation scores are derived by sampling. We utilise two denoiser backbones: (i) a feature-wise linear modulation (FiLM) conditioned multilayer perceptron (MLP) and (ii) a tabular transformer with feature self-attention and intersample attention (SAINT), conditioning covariates through learned embeddings. We evaluate on a synthetic benchmark with heteroscedastic and multimodal age effects and on UK Biobank FreeSurfer phenotypes, scaling from dimension of 2 to 200. Our evaluation suite includes centile calibration (absolute centile error, empirical coverage, and the probability integral transform), distributional fidelity (Kolmogorov-Smirnov tests), multivariate dependence diagnostics, and nearest-neighbour memorisation analysis. For low dimensions, diffusion models deliver well-calibrated per-IDP outputs comparable to traditional baselines while jointly modeling realistic dependence structure. At higher dimensions, the transformer backbone remains substantially better calibrated than the MLP and better preserves higher-order dependence, enabling scalable joint normative models that remain compatible with standard per-IDP pipelines. These results support diffusion-based normative modeling as a practical route to calibrated multivariate deviation profiles in neuroimaging.", "AI": {"tldr": "本文提出了利用去噪扩散概率模型（DDPM）为神经影像学表型估计参考分布，从而得到中心百分位数和临床可解释的偏差分数。", "motivation": "现有的神经影像管道每个成像衍生特征单独建模，这种方法虽然扩展性好但忽略了多变量依赖关系。作者旨在通过提出一种去噪扩散模型来解决这一问题，并实现联合建模。", "method": "使用两种去噪器结构：（i）FiLM条件多层感知机和（ii）具有自注意力和样本间注意的表格变压器，对协变量进行学习嵌入以获得条件概率估计。", "result": "实验结果表明，在低维度情况下，扩散模型输出与传统基线相当且准确度高；在高维度时，使用变换器结构保持更好的校准性并更好地保留了高级依赖关系，支持大规模联合规范建模。", "conclusion": "基于扩散的规范建模为神经影像学提供了可行的方法来构建多变量偏差配置文件。"}}
{"id": "2602.04884", "pdf": "https://arxiv.org/pdf/2602.04884", "abs": "https://arxiv.org/abs/2602.04884", "authors": ["Bangzheng Li", "Jianmo Ni", "Chen Qu", "Ian Miao", "Liu Yang", "Xingyu Fu", "Muhao Chen", "Derek Zhiyuan Cheng"], "title": "Reinforced Attention Learning", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": null, "summary": "Post-training with Reinforcement Learning (RL) has substantially improved reasoning in Large Language Models (LLMs) via test-time scaling. However, extending this paradigm to Multimodal LLMs (MLLMs) through verbose rationales yields limited gains for perception and can even degrade performance. We propose Reinforced Attention Learning (RAL), a policy-gradient framework that directly optimizes internal attention distributions rather than output token sequences. By shifting optimization from what to generate to where to attend, RAL promotes effective information allocation and improved grounding in complex multimodal inputs. Experiments across diverse image and video benchmarks show consistent gains over GRPO and other baselines. We further introduce On-Policy Attention Distillation, demonstrating that transferring latent attention behaviors yields stronger cross-modal alignment than standard knowledge distillation. Our results position attention policies as a principled and general alternative for multimodal post-training.", "AI": {"tldr": "本文提出了一种新的框架RAL，用于优化多模态大语言模型的内部注意力分布，以改进推理和表现。", "motivation": "现有的通过强化学习进行后训练的方法在多模态大语言模型上效果有限，甚至可能降低性能。因此提出了RAL来直接优化注意力分配而不是生成的令牌序列。", "method": "采用策略梯度框架RAL，该方法侧重于优化内部注意力分布而非输出标记序列，并引入了在策略注意力蒸馏，以实现跨模态对齐。", "result": "实验表明，在图像和视频基准测试中，RAL优于GRPO和其他基线模型。此外，显示注意力政策能比标准知识蒸馏产生更强的跨模式对准效果。", "conclusion": "本文的研究结果证明了注意力策略可以作为多模态后训练的一种原则性和通用性替代方法。"}}
{"id": "2602.04883", "pdf": "https://arxiv.org/pdf/2602.04883", "abs": "https://arxiv.org/abs/2602.04883", "authors": ["Yanru Qu", "Cheng-Yen Hsieh", "Zaixiang Zheng", "Ge Liu", "Quanquan Gu"], "title": "Protein Autoregressive Modeling via Multiscale Structure Generation", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM"], "comment": "ByteDance Seed Tech Report; Page: https://par-protein.github.io/", "summary": "We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.", "AI": {"tldr": "本文提出了蛋白质自回归建模（PAR），一种用于多尺度蛋白骨架生成的框架。", "motivation": "为了解决传统自回归模型中的暴露偏差问题，提高蛋白结构生成的质量和灵活性，同时支持零样本推广。", "method": "该方法包括三个关键组件：多尺度下采样操作、自回归变换器以及基于流的骨干解码器。通过这些组件实现从粗到细的蛋白骨架生成，并使用噪声上下文学习和计划采样来缓解暴露偏差问题。", "result": "PAR模型在无条件生成基准上表现出色，能够产生高质量的设计骨架并展示出良好的扩展性。", "conclusion": "本文提出的PAR框架具有强大的零样本推广能力，支持灵活的条件生成，并且能够在不进行微调的情况下使用人类提示和支架生成蛋白质结构。"}}
{"id": "2602.04881", "pdf": "https://arxiv.org/pdf/2602.04881", "abs": "https://arxiv.org/abs/2602.04881", "authors": ["Ajesh Koyatan Chathoth"], "title": "Contrastive Continual Learning for Model Adaptability in Internet of Things", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Internet of Things (IoT) deployments operate in nonstationary, dynamic environments where factors such as sensor drift, evolving user behavior, and heterogeneous user privacy requirements can affect application utility. Continual learning (CL) addresses this by adapting models over time without catastrophic forgetting. Meanwhile, contrastive learning has emerged as a powerful representation-learning paradigm that improves robustness and sample efficiency in a self-supervised manner. This paper reviews the usage of \\emph{contrastive continual learning} (CCL) for IoT, connecting algorithmic design (replay, regularization, distillation, prompts) with IoT system realities (TinyML constraints, intermittent connectivity, privacy). We present a unifying problem formulation, derive common objectives that blend contrastive and distillation losses, propose an IoT-oriented reference architecture for on-device, edge, and cloud-based CCL, and provide guidance on evaluation protocols and metrics. Finally, we highlight open unique challenges with respect to the IoT domain, such as spanning tabular and streaming IoT data, concept drift, federated settings, and energy-aware training.", "AI": {"tldr": "本文探讨了在物联网环境中使用对比持续学习（CCL）来提高模型适应性和鲁棒性。", "motivation": "由于传感器漂移、用户行为变化和隐私要求不同，物联网部署面临着非平稳和动态环境的挑战。持续学习通过时间逐步适应这些变化而不忘记先前学到的知识。本文将对比学习与持续学习结合，以解决物联网中独特的问题。", "method": "提出了一种统一问题框架，并推导了结合对比损失和蒸馏损失的目标函数。设计了一个针对物联网设备、边缘计算和云环境的参考架构，并提供了评估协议及指标。", "result": "文章提出了适应物联网环境中数据流式传输、概念漂移、联邦设置以及节能训练的独特挑战的解决方案。", "conclusion": "本文强调了对比持续学习在应对物联网领域中各种独特挑战方面的重要性和潜力。"}}
{"id": "2602.04880", "pdf": "https://arxiv.org/pdf/2602.04880", "abs": "https://arxiv.org/abs/2602.04880", "authors": ["Jiahua Dong", "Yunze Man", "Pavel Tokmakov", "Yu-Xiong Wang"], "title": "Capturing Visual Environment Structure Correlates with Control Performance", "categories": ["cs.RO"], "comment": null, "summary": "The choice of visual representation is key to scaling generalist robot policies. However, direct evaluation via policy rollouts is expensive, even in simulation. Existing proxy metrics focus on the representation's capacity to capture narrow aspects of the visual world, like object shape, limiting generalization across environments. In this paper, we take an analytical perspective: we probe pretrained visual encoders by measuring how well they support decoding of environment state -- including geometry, object structure, and physical attributes -- from images. Leveraging simulation environments with access to ground-truth state, we show that this probing accuracy strongly correlates with downstream policy performance across diverse environments and learning settings, significantly outperforming prior metrics and enabling efficient representation selection. More broadly, our study provides insight into the representational properties that support generalizable manipulation, suggesting that learning to encode the latent physical state of the environment is a promising objective for control.", "AI": {"tldr": "本文提出了一种通过测量视觉编码器解码环境状态的能力来评估视觉表示的方法，以支持机器人控制任务中的泛化能力。", "motivation": "现有的代理度量标准主要关注于捕捉视觉世界的特定方面，限制了其在不同环境下的通用性。本文旨在找到能够有效支持机器人政策的视觉表示方法。", "method": "通过模拟环境中预训练的视觉编码器来测量解码环境状态的能力，并与下游策略性能相关联以评估表现。", "result": "提出的度量标准比以前的方法更有效地预测了跨多种环境和学习设置下的控制策略表现，揭示了解决通用操作问题所需的表示特性。", "conclusion": "通过学习编码环境中物理状态的潜在信息可以提高机器人政策的泛化能力。"}}
{"id": "2602.04879", "pdf": "https://arxiv.org/pdf/2602.04879", "abs": "https://arxiv.org/abs/2602.04879", "authors": ["Penghui Qi", "Xiangxin Zhou", "Zichen Liu", "Tianyu Pang", "Chao Du", "Min Lin", "Wee Sun Lee"], "title": "Rethinking the Trust Region in LLM Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.", "AI": {"tldr": "重新考虑大规模语言模型（LLM）强化学习中的信任区域问题，提出一种基于直接估计策略分歧的Divergence Proximal Policy Optimization (DPPO) 方法。", "motivation": "论文指出PPO中的核心概率比率裁剪机制在处理大型词汇表时存在结构性缺陷，导致低概率令牌更新过度惩罚和高概率令牌潜在灾难性变化不足约束，影响训练效率与稳定性。", "method": "提出基于策略分歧直接估计的DPPO，用更原则化的约束替代经验性的裁剪。引入二进制和Top-K近似以避免巨大的内存开销，实现对策略分歧的有效捕捉。", "result": "实验证明，相比于现有方法，DPPO在训练稳定性和效率方面表现出显著优势。", "conclusion": "论文提出DPPO作为更稳健的基于强化学习的大规模语言模型微调基础。"}}
{"id": "2602.04877", "pdf": "https://arxiv.org/pdf/2602.04877", "abs": "https://arxiv.org/abs/2602.04877", "authors": ["Zihang Lai", "Eldar Insafutdinov", "Edgar Sucar", "Andrea Vedaldi"], "title": "CoWTracker: Tracking by Warping instead of Correlation", "categories": ["cs.CV"], "comment": "Project website: cowtracker.github.io", "summary": "Dense point tracking is a fundamental problem in computer vision, with applications ranging from video analysis to robotic manipulation. State-of-the-art trackers typically rely on cost volumes to match features across frames, but this approach incurs quadratic complexity in spatial resolution, limiting scalability and efficiency. In this paper, we propose \\method, a novel dense point tracker that eschews cost volumes in favor of warping. Inspired by recent advances in optical flow, our approach iteratively refines track estimates by warping features from the target frame to the query frame based on the current estimate. Combined with a transformer architecture that performs joint spatiotemporal reasoning across all tracks, our design establishes long-range correspondences without computing feature correlations. Our model is simple and achieves state-of-the-art performance on standard dense point tracking benchmarks, including TAP-Vid-DAVIS, TAP-Vid-Kinetics, and Robo-TAP. Remarkably, the model also excels at optical flow, sometimes outperforming specialized methods on the Sintel, KITTI, and Spring benchmarks. These results suggest that warping-based architectures can unify dense point tracking and optical flow estimation.", "AI": {"tldr": "提出了一种基于变形而非相关性的密集点跟踪方法，克服了现有方法的二次复杂度限制。", "motivation": "现有的密集点跟踪器依赖于成本体来匹配跨帧特征，导致在空间分辨率上的二次复杂性，从而限制了可扩展性和效率。因此，作者提出了新的方法以提高性能和效率。", "method": "通过基于光学流的变形迭代优化跟踪估计，并结合执行时空联合推理的转换架构，建立长期对应关系而无需计算特征相关性。", "result": "该模型在标准密集点跟踪基准上实现了最先进的性能，在Sintel、KITTI和Spring等光流评估中也表现出色。", "conclusion": "变形基元可以统一密集点跟踪与光流估计，展示了这种方法的潜力。"}}
{"id": "2602.04876", "pdf": "https://arxiv.org/pdf/2602.04876", "abs": "https://arxiv.org/abs/2602.04876", "authors": ["Jiahao Zhan", "Zizhang Li", "Hong-Xing Yu", "Jiajun Wu"], "title": "PerpetualWonder: Long-Horizon Action-Conditioned 4D Scene Generation", "categories": ["cs.CV"], "comment": "Project website: https://johnzhan2023.github.io/PerpetualWonder/", "summary": "We introduce PerpetualWonder, a hybrid generative simulator that enables long-horizon, action-conditioned 4D scene generation from a single image. Current works fail at this task because their physical state is decoupled from their visual representation, which prevents generative refinements to update the underlying physics for subsequent interactions. PerpetualWonder solves this by introducing the first true closed-loop system. It features a novel unified representation that creates a bidirectional link between the physical state and visual primitives, allowing generative refinements to correct both the dynamics and appearance. It also introduces a robust update mechanism that gathers supervision from multiple viewpoints to resolve optimization ambiguity. Experiments demonstrate that from a single image, PerpetualWonder can successfully simulate complex, multi-step interactions from long-horizon actions, maintaining physical plausibility and visual consistency.", "AI": {"tldr": "PerpetualWonder是一种生成模拟器，可以从单张图片中进行长时间范围的动作条件下的4D场景生成。", "motivation": "现有工作在从单张图像生成长期动作条件下4D场景时失败，因为其物理状态与视觉表示是脱钩的，这阻止了生成性改进以更新底层物理以便后续交互。PerpetualWonder通过引入首个真正的闭环系统来解决这个问题。", "method": "它引入了一个新颖的统一表示方法，在物理状态和视觉原语之间创建双向链接，允许生成性改进纠正动态性和外观。还引入了一种稳健的更新机制，该机制从多个视角收集监督以解决优化模糊问题。", "result": "实验表明，PerpetualWonder可以从单张图片成功模拟复杂的多步骤互动，维持物理合理性和视觉一致性。", "conclusion": "通过结合物理状态和视觉表示的闭环系统，PerpetualWonder展示了在单一图像上生成长期动作条件下4D场景的能力，并保持了物理一致性和视觉真实感。"}}
{"id": "2602.04873", "pdf": "https://arxiv.org/pdf/2602.04873", "abs": "https://arxiv.org/abs/2602.04873", "authors": ["Ramón Calvo-González", "François Fleuret"], "title": "Laminating Representation Autoencoders for Efficient Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Recent work has shown that diffusion models can generate high-quality images by operating directly on SSL patch features rather than pixel-space latents. However, the dense patch grids from encoders like DINOv2 contain significant redundancy, making diffusion needlessly expensive. We introduce FlatDINO, a variational autoencoder that compresses this representation into a one-dimensional sequence of just 32 continuous tokens -an 8x reduction in sequence length and 48x compression in total dimensionality. On ImageNet 256x256, a DiT-XL trained on FlatDINO latents achieves a gFID of 1.80 with classifier-free guidance while requiring 8x fewer FLOPs per forward pass and up to 4.5x fewer FLOPs per training step compared to diffusion on uncompressed DINOv2 features. These are preliminary results and this work is in progress.", "AI": {"tldr": "本文提出了一种新的变分自动编码器FlatDINO，用于压缩SSL特征表示，并展示了其在图像生成中的应用。", "motivation": "扩散模型通常通过操作SSL补丁特征而不是像素空间潜在值来生成高质量的图像。然而，像DINOv2这样的编码器产生的密集补丁网格包含大量冗余，导致计算成本过高。", "method": "提出了FlatDINO变分自动编码器将表示压缩为仅32个连续标记的一维序列，从而显著减少了序列长度和维度。", "result": "在ImageNet上，训练于FlatDINO潜在值的DiT-XL模型达到了1.80的gFID分数，并且每前向传递所需的计算量减少到原来的八分之一，最多可将每步训练所需计算量降低至四点五倍。", "conclusion": "这项研究展示了通过压缩SSL特征表示可以显著提高扩散模型在图像生成中的效率。"}}
{"id": "2602.04872", "pdf": "https://arxiv.org/pdf/2602.04872", "abs": "https://arxiv.org/abs/2602.04872", "authors": ["Nicholas Barnfield", "Subhabrata Sen", "Pragya Sur"], "title": "Multi-layer Cross-Attention is Provably Optimal for Multi-modal In-context Learning", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent progress has rapidly advanced our understanding of the mechanisms underlying in-context learning in modern attention-based neural networks. However, existing results focus exclusively on unimodal data; in contrast, the theoretical underpinnings of in-context learning for multi-modal data remain poorly understood. We introduce a mathematically tractable framework for studying multi-modal learning and explore when transformer-like architectures can recover Bayes-optimal performance in-context. To model multi-modal problems, we assume the observed data arises from a latent factor model. Our first result comprises a negative take on expressibility: we prove that single-layer, linear self-attention fails to recover the Bayes-optimal predictor uniformly over the task distribution. To address this limitation, we introduce a novel, linearized cross-attention mechanism, which we study in the regime where both the number of cross-attention layers and the context length are large. We show that this cross-attention mechanism is provably Bayes optimal when optimized using gradient flow. Our results underscore the benefits of depth for in-context learning and establish the provable utility of cross-attention for multi-modal distributions.", "AI": {"tldr": "该论文研究了多模态上下文学习中Transformer架构的最优性，引入了一种线性化的跨注意力机制，并证明其在适当条件下可达到贝叶斯最优性能。", "motivation": "当前对于单模态数据上下文学习的研究已经取得了进展，但对于多模态数据的理解仍然不足。该论文旨在填补这一空白，通过数学框架探讨Transformer架构在处理多模态问题时的能力。", "method": "引入了一个基于潜在因子模型的多模态问题框架，并证明了单一层次、线性自注意力机制无法一致地恢复最优预测器。提出了新的线性化跨注意力机制，并研究其深度和上下文长度大的情况下的性能。", "result": "论文证明，当使用梯度流优化时，引入的新线性化跨注意力机制在多模态分布下是贝叶斯最优的。", "conclusion": "该研究揭示了跨注意力机制对于多模态问题的重要性，并强调深度对上下文学习的关键作用。"}}
{"id": "2602.04868", "pdf": "https://arxiv.org/pdf/2602.04868", "abs": "https://arxiv.org/abs/2602.04868", "authors": ["Yannick Denker", "Alexander Gepperth"], "title": "CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.", "AI": {"tldr": "介绍了一种基于现实模拟机器人的连续强化学习基准测试套件CRoSS，以评估和研究连续机器人任务中的深度强化学习算法。", "motivation": "为了推动在复杂、多样化的机器人任务中使用持续性强化学习（CRL）的研究进展，需要一个具有高物理真实感的可扩展且易于重复使用的基准测试平台。", "method": "设计了一个名为CRoSS的新基准套件，该套件基于Gazebo仿真器中的两个机器人模型：一种是带有激光雷达、摄像头和碰撞传感器的两轮差速驱动机器人；另一种则是拥有七个关节的机械臂。这些模型被用于执行一系列任务，并提供了无需物理仿真的Kinematics-only变体。", "result": "CRoSS能够支持深度Q网络（DQN）及策略梯度方法等标准强化学习算法，展示出作为连续强化学习研究基准测试的适用性和可扩展性。", "conclusion": "提出了一个名为CRoSS的新基准套件，旨在通过提供高物理真实感和任务多样性的机器人模拟环境来促进持续性强化学习的研究。"}}
{"id": "2602.04864", "pdf": "https://arxiv.org/pdf/2602.04864", "abs": "https://arxiv.org/abs/2602.04864", "authors": ["Soumya Jahagirdar", "Walid Bousselham", "Anna Kukleva", "Hilde Kuehne"], "title": "When LLaVA Meets Objects: Token Composition for Vision-Language-Models", "categories": ["cs.CV"], "comment": null, "summary": "Current autoregressive Vision Language Models (VLMs) usually rely on a large number of visual tokens to represent images, resulting in a need for more compute especially at inference time. To address this problem, we propose Mask-LLaVA, a framework that leverages different levels of visual features to create a compact yet information-rich visual representation for autoregressive VLMs. Namely, we combine mask-based object representations together with global tokens and local patch tokens. While all tokens are used during training, it shows that the resulting model can flexibly drop especially the number of mask-based object-tokens at test time, allowing to adapt the number of tokens during inference without the need to retrain the model and without a significant drop in performance. We evaluate the proposed approach on a suite of standard benchmarks showing results competitive to current token efficient methods and comparable to the original LLaVA baseline using only a fraction of visual tokens. Our analysis demonstrates that combining multi-level features enables efficient learning with fewer tokens while allowing dynamic token selection at test time for good performance.", "AI": {"tldr": "提出Mask-LLaVA框架，利用多级视觉特征创建紧凑且信息丰富的图像表示。", "motivation": "当前自回归的Vision-Language模型在图像表示时需要大量视觉令牌，导致推理计算需求增加。为此，本文提出了一个新方法来减少令牌数量并保持性能。", "method": "Mask-LLaVA框架结合掩码对象表征、全局令牌和局部补丁令牌，用于构建更高效的视觉语言模型。训练过程中使用所有令牌，在测试时可灵活丢弃部分令牌以适应计算需求。", "result": "实验显示该方法在标准基准上表现优异，与现有的令牌效率高的方法相当，并且性能接近原始LLaVA基线，但仅需少量视觉令牌。", "conclusion": "结合多级特征和动态令牌选择策略可以有效地学习并保持高性能。"}}
{"id": "2602.04863", "pdf": "https://arxiv.org/pdf/2602.04863", "abs": "https://arxiv.org/abs/2602.04863", "authors": ["Ishaq Aden-Ali", "Noah Golowich", "Allen Liu", "Abhishek Shetty", "Ankur Moitra", "Nika Haghtalab"], "title": "Subliminal Effects in Your Data: A General Mechanism via Log-Linearity", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "Code available at https://github.com/ishaqadenali/logit-linear-selection", "summary": "Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets. We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.", "AI": {"tldr": "本文介绍了一种名为Logit-Linear-Selection（LLS）的方法，该方法可以从通用偏好的数据集中选择子集以揭示隐藏的效果。", "motivation": "现代大型语言模型的训练过程中存在通过算法和数据集传递隐含信号的现象。这些信号无法直接从单一的数据点中观察到，这使得理解数据集对模型属性的影响变得至关重要。", "method": "本文提出了一种名为Logit-Linear-Selection（LLS）的方法，该方法可以用于选择子数据集以揭示隐藏的效果。", "result": "通过应用LLS方法，研究人员发现了一系列的数据子集，这些子集能够使训练模型展示出特定的行为，包括具有特定偏好、用不在数据集中出现的语言回应提示以及采用不同的个性。", "conclusion": "实验结果表明该效果在选择的子集中普遍存在，并且适用于不同架构的模型。这证明了LLS方法的有效性和普遍性。"}}
{"id": "2602.04861", "pdf": "https://arxiv.org/pdf/2602.04861", "abs": "https://arxiv.org/abs/2602.04861", "authors": ["Ryan Liu", "Eric Qu", "Tobias Kreiman", "Samuel M. Blau", "Aditi S. Krishnapriyan"], "title": "From Evaluation to Design: Using Potential Energy Surface Smoothness Metrics to Guide Machine Learning Interatomic Potential Architectures", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.chem-ph"], "comment": "13 pages main text, 10 pages reference & appendix, 8 figures", "summary": "Machine Learning Interatomic Potentials (MLIPs) sometimes fail to reproduce the physical smoothness of the quantum potential energy surface (PES), leading to erroneous behavior in downstream simulations that standard energy and force regression evaluations can miss. Existing evaluations, such as microcanonical molecular dynamics (MD), are computationally expensive and primarily probe near-equilibrium states. To improve evaluation metrics for MLIPs, we introduce the Bond Smoothness Characterization Test (BSCT). This efficient benchmark probes the PES via controlled bond deformations and detects non-smoothness, including discontinuities, artificial minima, and spurious forces, both near and far from equilibrium. We show that BSCT correlates strongly with MD stability while requiring a fraction of the cost of MD. To demonstrate how BSCT can guide iterative model design, we utilize an unconstrained Transformer backbone as a testbed, illustrating how refinements such as a new differentiable $k$-nearest neighbors algorithm and temperature-controlled attention reduce artifacts identified by our metric. By optimizing model design systematically based on BSCT, the resulting MLIP simultaneously achieves a low conventional E/F regression error, stable MD simulations, and robust atomistic property predictions. Our results establish BSCT as both a validation metric and as an \"in-the-loop\" model design proxy that alerts MLIP developers to physical challenges that cannot be efficiently evaluated by current MLIP benchmarks.", "AI": {"tldr": "该论文引入了Bond Smoothness Characterization Test (BSCT)来评估机器学习原子间势能（MLIPs）的平滑性，并通过改进模型设计解决了其物理不一致问题。", "motivation": "现有的MLIP评价方法如微正则分子动力学模拟（MD），成本高且主要针对近平衡态。为了提高评估指标，作者开发了BSCT，以检测MLIP中的非平稳特性，包括间断点、人工极小值和异常力。", "method": "利用可控键变形来探索势能面，并采用一种新的可微的k最近邻算法及温度控制注意力机制改进模型设计。", "result": "通过BSCT引导迭代设计的MLIP，在保持传统能量/力回归误差低的同时，实现了稳定的MD模拟和可靠的原子特性预测。", "conclusion": "该研究确立了BSCT作为评估指标和实时监控工具的重要性，能够提醒研究人员关注当前基准测试中难以高效评估的问题。"}}
{"id": "2602.04851", "pdf": "https://arxiv.org/pdf/2602.04851", "abs": "https://arxiv.org/abs/2602.04851", "authors": ["Yi Gu", "Yukang Gao", "Yangchen Zhou", "Xingyu Chen", "Yixiao Feng", "Mingle Zhao", "Yunyang Mo", "Zhaorui Wang", "Lixin Xu", "Renjing Xu"], "title": "PDF-HR: Pose Distance Fields for Humanoid Robots", "categories": ["cs.RO", "cs.CV"], "comment": "\\href{https://gaoyukang33.github.io/PDF-HR/}{Project page}", "summary": "Pose and motion priors play a crucial role in humanoid robotics. Although such priors have been widely studied in human motion recovery (HMR) domain with a range of models, their adoption for humanoid robots remains limited, largely due to the scarcity of high-quality humanoid motion data. In this work, we introduce Pose Distance Fields for Humanoid Robots (PDF-HR), a lightweight prior that represents the robot pose distribution as a continuous and differentiable manifold. Given an arbitrary pose, PDF-HR predicts its distance to a large corpus of retargeted robot poses, yielding a smooth measure of pose plausibility that is well suited for optimization and control. PDF-HR can be integrated as a reward shaping term, a regularizer, or a standalone plausibility scorer across diverse pipelines. We evaluate PDF-HR on various humanoid tasks, including single-trajectory motion tracking, general motion tracking, style-based motion mimicry, and general motion retargeting. Experiments show that this plug-and-play prior consistently and substantially strengthens strong baselines. Code and models will be released.", "AI": {"tldr": "提出了PDF-HR，一种用于人形机器人姿态分布的轻量级先验模型。", "motivation": "目前人形机器人的运动数据稀缺，阻碍了先进运动恢复技术的应用。因此，需要开发适用于人形机器人的高效、通用的先验模型。", "method": "提出了PDF-HR，用连续可微流形表示机器人姿态分布，并预测任意姿态与大量重定位后的姿态之间的距离，以评估姿势合理性。", "result": "实验表明，PDF-HR在单轨迹运动跟踪、一般运动跟踪、风格化运动模仿和一般运动重定向等任务中均能显著提升基线性能。", "conclusion": "PDF-HR作为一种即插即用的先验模型，在多种人形机器人任务中的应用表现出色。"}}
{"id": "2602.04850", "pdf": "https://arxiv.org/pdf/2602.04850", "abs": "https://arxiv.org/abs/2602.04850", "authors": ["Juan B. Pérez-Sánchez", "Yunheng Zou", "Jorge A. Campos-Gonzalez-Angulo", "Marcel Müller", "Ignacio Gustin", "Andrew Wang", "Han Hao", "Tsz Wai Ko", "Changhyeok Choi", "Eric S. Isbrandt", "Mohammad Ghazi Vakili", "Hanyong Xu", "Chris Crebolder", "Varinia Bernales", "Alán Aspuru-Guzik"], "title": "El Agente Quntur: A research collaborator agent for quantum chemistry", "categories": ["physics.chem-ph", "cs.AI", "cs.MA"], "comment": null, "summary": "Quantum chemistry is a foundational enabling tool for the fields of chemistry, materials science, computational biology and others. Despite of its power, the practical application of quantum chemistry simulations remains in the hands of qualified experts due to methodological complexity, software heterogeneity, and the need for informed interpretation of results. To bridge the accessibility gap for these tools and expand their reach to chemists with broader backgrounds, we introduce El Agente Quntur, a hierarchical, multi-agent AI system designed to operate not merely as an automation tool but as a research collaborator for computational quantum chemistry. Quntur was designed following three main strategies: i) elimination of hard-coded procedural policies in favour of reasoning-driven decisions, ii) construction of general and composable actions that facilitate generalization and efficiency, and iii) implementation of guided deep research to integrate abstract quantum-chemical reasoning across subdisciplines and a detailed understanding of the software's internal logic and syntax. Although instantiated in ORCA, these design principles are applicable to research agents more generally and easily expandable to additional quantum chemistry packages and beyond. Quntur supports the full range of calculations available in ORCA 6.0 and reasons over software documentation and scientific literature to plan, execute, adapt, and analyze in silico chemistry experiments following best practices. We discuss the advances and current bottlenecks in agentic systems operating at the research level in computational chemistry, and outline a roadmap toward a fully autonomous end-to-end computational chemistry research agent.", "AI": {"tldr": "介绍El Agente Quntur，一个量子化学研究协作AI系统", "motivation": "旨在解决量子化学工具应用受限的问题，通过引入El Agente Quntur来扩大这些工具的使用范围并支持更多背景的化学家进行科学研究。", "method": "设计了一个基于三个策略的多代理人工智能系统：消除硬编码程序政策以促进推理驱动决策；构建通用和可组合的动作以便于泛化和效率提升；实现指导性深度研究，整合跨子学科的抽象量子化学推理并深入了解软件内部逻辑和语法。", "result": "Quntur能够支持ORCA6.0中的所有计算，并能根据软件文档和科学文献规划、执行、适应和分析基于计算机的化学实验，遵循最佳实践。", "conclusion": "概述了在计算化学研究级别操作中的代理系统当前进展与瓶颈，并提出了实现完全自主端到端计算化学研究代理的道路图。"}}
{"id": "2602.04849", "pdf": "https://arxiv.org/pdf/2602.04849", "abs": "https://arxiv.org/abs/2602.04849", "authors": ["Changhyeok Choi", "Yunheng Zou", "Marcel Müller", "Han Hao", "Yeonghun Kang", "Juan B. Pérez-Sánchez", "Ignacio Gustin", "Hanyong Xu", "Mohammad Ghazi Vakili", "Chris Crebolder", "Alán Aspuru-Guzik", "Varinia Bernales"], "title": "El Agente Estructural: An Artificially Intelligent Molecular Editor", "categories": ["physics.chem-ph", "cs.AI", "cs.MA"], "comment": null, "summary": "We present El Agente Estructural, a multimodal, natural-language-driven geometry-generation and manipulation agent for autonomous chemistry and molecular modelling. Unlike molecular generation or editing via generative models, Estructural mimics how human experts directly manipulate molecular systems in three dimensions by integrating a comprehensive set of domain-informed tools and vision-language models. This design enables precise control over atomic or functional group replacements, atomic connectivity, and stereochemistry without the need to rebuild extensive core molecular frameworks. Through a series of representative case studies, we demonstrate that Estructural enables chemically meaningful geometry manipulation across a wide range of real-world scenarios. These include site-selective functionalization, ligand binding, ligand exchange, stereochemically controlled structure construction, isomer interconversion, fragment-level structural analysis, image-guided generation of structures from schematic reaction mechanisms, and mechanism-driven geometry generation and modification. These examples illustrate how multimodal reasoning, when combined with specialized geometry-aware tools, supports interactive and context-aware molecular modelling beyond structure generation. Looking forward, the integration of Estructural into El Agente Quntur, an autonomous multi-agent quantum chemistry platform, enhances its capabilities by adding sophisticated tools for the generation and editing of three-dimensional structures.", "AI": {"tldr": "介绍了El Agente Estructural，一种通过自然语言驱动的多模态几何生成和分子编辑工具。", "motivation": "模仿人类专家直接操作三维分子系统的能力，提供精准控制原子或功能团替换、原子连接性和立体化学的方法，同时避免重建整个分子框架。", "method": "利用一个集成了领域知识工具和视觉语言模型的综合性系统，实现精确地编辑分子结构的功能。", "result": "通过多个案例研究展示Estructural在特定功能性化、配体结合、配体交换等方面的强大能力以及图像引导生成反应机理和机制驱动几何生成等功能。", "conclusion": "证明了多模态推理与专业的几何感知工具相结合支持交互式上下文相关的分子建模，超越结构生成。"}}
{"id": "2602.04843", "pdf": "https://arxiv.org/pdf/2602.04843", "abs": "https://arxiv.org/abs/2602.04843", "authors": ["Dmitrii Kharlapenko", "Alessandro Stolfo", "Arthur Conmy", "Mrinmaya Sachan", "Zhijing Jin"], "title": "Fluid Representations in Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.", "AI": {"tldr": "分析QwQ-32B模型在处理抽象结构信息时的内部表示机制，揭示其性能提升的原因。", "motivation": "探索语言推理模型为何在解决抽象问题上优于非推理模型，并了解其背后的具体运行机制。", "method": "通过Mystery Blocksworld实验来观察和分析QwQ-32B模型如何逐步改进其对动作和概念的内部表示，利用定向实验验证这些改变如何提升解决问题的能力。", "result": "发现QwQ-32B在推理过程中形成了注重结构而非特定动词名称的抽象编码；注入成功的推理轨迹可以提高准确性，而符号化表征也能有效替换模糊化的表征。研究表明，在上下文中进行令牌表示调整是推动模型性能的一个关键因素。", "conclusion": "提出'流体推理表示'的概念来描述这种在推理过程中动态适应和优化内部表示的现象，并认为这是语言推理模型优越性能的关键驱动因素之一。"}}
{"id": "2602.04842", "pdf": "https://arxiv.org/pdf/2602.04842", "abs": "https://arxiv.org/abs/2602.04842", "authors": ["Michał Dereziński", "Ethan N. Epperly", "Raphael A. Meyer"], "title": "The matrix-vector complexity of $Ax=b$", "categories": ["cs.DS", "math.NA", "math.OC"], "comment": null, "summary": "Matrix-vector algorithms, particularly Krylov subspace methods, are widely viewed as the most effective algorithms for solving large systems of linear equations. This paper establishes lower bounds on the worst-case number of matrix-vector products needed by such an algorithm to approximately solve a general linear system. The first main result is that, for a matrix-vector algorithm which can perform products with both a matrix and its transpose, $Ω(κ\\log(1/\\varepsilon))$ matrix-vector products are necessary to solve a linear system with condition number $κ$ to accuracy $\\varepsilon$, matching an upper bound for conjugate gradient on the normal equations. The second main result is that one-sided algorithms, which lack access to the transpose, must use $n$ matrix-vector products to solve an $n \\times n$ linear system, even when the problem is perfectly conditioned. Both main results include explicit constants that match known upper bounds up to a factor of four. These results rigorously demonstrate the limitations of matrix-vector algorithms and confirm the optimality of widely used Krylov subspace algorithms.", "AI": {"tldr": "论文旨在确定解决大型线性方程组所需的矩阵向量乘积的下限。", "motivation": "为了揭示矩阵-向量算法在解决大规模线性系统时的有效性和局限性，建立了解决一般线性系统的最坏情况下的矩阵-向量运算次数的理论下界。", "method": "该论文通过分析不同条件数和精度要求下解线性方程组所需的最小矩阵-向量乘积次数来确定算法效率的极限。", "result": "论文表明，对于能同时进行矩阵及其转置操作的双侧算法而言，解决具有条件数κ的问题到ε精度需要Ω(κlog(1/ε))个矩阵-向量运算。单边算法则在完全正交条件下解n×n线性系统也需要使用n次乘积。", "conclusion": "研究结果严格证明了矩阵-向量算法的局限性，并确认了广泛使用的Krylov子空间算法的有效性和最优性。"}}
{"id": "2602.04841", "pdf": "https://arxiv.org/pdf/2602.04841", "abs": "https://arxiv.org/abs/2602.04841", "authors": ["Jeongmin Rhee", "Changhee Lee", "DongHwa Shin", "Bohyoung Kim"], "title": "Vivifying LIME: Visual Interactive Testbed for LIME Analysis", "categories": ["cs.HC"], "comment": null, "summary": "Explainable Artificial Intelligence (XAI) has gained importance in interpreting model predictions. Among leading techniques for XAI, Local Interpretable Model-agnostic Explanations (LIME) is most frequently utilized as it notably helps people's understanding of complex models. However, LIME's analysis is constrained to a single image at a time. Besides, it lacks interaction mechanisms for observing the LIME's results and direct manipulations of factors affecting the results. To address these issues, we introduce an interactive visualization tool, LIMEVis, which improves the analysis workflow of LIME by enabling users to explore multiple LIME results simultaneously and modify them directly. With LIMEVis, we could conveniently identify common features in images that a model seems to mainly consider for category classification. Additionally, by interactively modifying the LIME results, we could determine which segments in an image influence the model's classification.", "AI": {"tldr": "该论文提出了一种名为LIMEVis的交互式可视化工具，用于改进LIME解释结果的工作流程。", "motivation": "现有的LIME分析仅限于单张图片且缺乏用户互动机制。本文旨在解决这些问题，通过引入一种新的交互方式来改善用户体验并增强对模型分类影响因素的理解。", "method": "开发了一种名为LIMEVis的工具，使得能够同时探索多个LIME解释结果，并直接修改这些结果以观察其对模型分类的影响。", "result": "用户可以通过该工具识别出在图像中被模型主要考虑用于类别分类的共同特征；并且通过交互式地调整LIME结果来确定影响分类的具体图像片段。", "conclusion": "本文提出了一种名为LIMEVis的新方法，能够提高LIME解释的有效性和用户体验。"}}
